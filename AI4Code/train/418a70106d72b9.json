{"cell_type":{"1d0c296c":"code","69b08c58":"code","d0d4de75":"code","76401363":"code","2cbee2b0":"code","bf225ff3":"code","5c3b8238":"code","a4fed14a":"code","a4f53210":"code","ee8963a7":"code","b0b13f38":"code","6c93f477":"code","95aaf363":"code","537ed2ac":"code","6a7df248":"code","8b25c513":"code","ea7a9f69":"code","81169473":"code","3d4a00ec":"code","f4d01ab0":"code","d1a91c21":"code","d2e044bd":"code","582c0d93":"code","3494c5c0":"code","8641683b":"code","3d7022a3":"code","51cef603":"code","c4fe73b8":"code","746caf58":"code","b0b941cd":"code","edd5cd5c":"code","704ff9a2":"code","151bab27":"code","b090b920":"code","2356872d":"code","53a59577":"code","e6e96b8a":"code","56db17f5":"code","f2b13419":"code","3b8598fb":"code","0128c888":"code","7f94cb7f":"code","258e156c":"code","75774600":"code","c11110b7":"code","d8775ade":"code","7d2c8f2e":"code","54f8db52":"code","e15cacb9":"code","876dcfa8":"code","a2e6d194":"code","b78cb491":"code","bf647ca1":"code","ea2793b1":"code","a5d9b286":"code","b0602503":"code","48ab3eab":"code","cd75a618":"code","38df3a6c":"code","874a881a":"code","3866c1db":"code","cb73b13d":"code","37d1ef21":"code","998bf7b1":"code","09b8e2a3":"code","c1c7f665":"code","b2def795":"code","c7725fcd":"code","1ad4336a":"code","efeafe1c":"code","452e662f":"code","a52d27b4":"code","7d7edb70":"code","ab3c11fb":"code","7d6a859f":"code","483e0197":"code","0e3cca25":"code","fdf806f8":"code","7874dcae":"code","b710fc61":"code","e9c839be":"markdown","c7aba3a6":"markdown","4fee891a":"markdown","ac9921d2":"markdown","3608a4f3":"markdown","7bf08965":"markdown","8c4651bb":"markdown","a6702604":"markdown","f1350244":"markdown","eb1b0fdd":"markdown","f2508f86":"markdown","ca603da2":"markdown","2dbbc96a":"markdown","e4737d15":"markdown","0ed891c3":"markdown","97c4de90":"markdown","1b49bd90":"markdown","968ba34e":"markdown","0eaddac5":"markdown","d07cec44":"markdown","2968978c":"markdown"},"source":{"1d0c296c":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport missingno as msno\nimport yaml\nfrom collections import Counter\nimport plotly.graph_objects as go\nimport plotly.express as xp\n\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.manifold import TSNE\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier, ExtraTreesClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.metrics import accuracy_score\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\ncolormap = ['#050A30', '#000C66', '#0000FF', '#7EC8E3', '#D4F1F4']\nsns.palplot(colormap)","69b08c58":"# Let's read the files and check the info\nPATH = \"..\/input\/mymusicalprefrences\/\" \ntrain_data = pd.read_csv(f\"{PATH}train.csv\")\ntest_data = pd.read_csv(f\"{PATH}test.csv\")\ndescription = yaml.load(open(f\"{PATH}Description.yaml\",'r'),Loader=yaml.FullLoader)\n\n# We merge train- and test-data for now\ndf = pd.concat([train_data,test_data], axis = 0, ignore_index = True)\ntrain_mask = ~df.Category.isna()\ndf.info()","d0d4de75":"df","76401363":"df.describe()","2cbee2b0":"# Plot missing values\nmsno.bar(df, color=colormap)","bf225ff3":"df.columns","5c3b8238":"# Rename some features\n\n# Remove the space after 'Vocal '\ndf = df.rename(columns = {'Vocal ':'Vocal'})\n\n# (Optional) Remove '_'\ndf = df.rename(columns = {'Artists_Genres':'ArtistsGenres', 'Release_year':'ReleaseYear', 'Album_type':'AlbumType'})\n\n# (Optional) Correct spelling mistakes\ndf = df.rename(columns = {'Dancebility':'Danceability'})\ndf.columns","a4fed14a":"# Let's see the categorical and numerical features\n\ncategorical_features = {\"Artists\",\"Track\",\"Version\",\"ArtistsGenres\",\"Album\",\"AlbumType\",\"Labels\",\"Vocal\",\"Country\",\"Key\"}\nnumerical_features = {\"Duration\",\"ReleaseYear\",\"BPM\",\"Energy\",\"Danceability\",\"Happiness\"}\ndisplay(df[categorical_features].head())\ndisplay(df[numerical_features].head())","a4f53210":"# Let's check for some dependencies visually\nsns.pairplot(df[list(numerical_features)+[\"Category\"]],palette=colormap[2:4], hue=\"Category\")","ee8963a7":"# For more easy usage of the Category feature\ndf[\"Category\"] = df[\"Category\"].fillna(\"none\").replace({0:\"dislike\",1:\"like\"})","b0b13f38":"# Let's check the missing value(s) in 'Artists'\ndf.loc[df['Artists'].isna()==True]","6c93f477":"# We can drop this record as it has the least amount of parameters\ndf = df.drop([661])\ndf = df.reset_index(drop=True)\ndf.loc[df['Artists'].isna()==True]","95aaf363":"# Let's check the missing value(s) in 'Album'\ndf.loc[df['Album'].isna()==True]","537ed2ac":"# We replace it with 'none'\ndf[\"Album\"].replace(np.nan, \"none\", inplace=True)\ndf.loc[df['Album'].isna()==True]","6a7df248":"# Let's check the missing value(s) in 'Vocal'\ndf.loc[df['Vocal'].isna()==True]","8b25c513":"# We replace it with 'none'\ndf[\"Vocal\"].replace(np.nan, \"none\", inplace=True)\ndf.loc[df['Vocal'].isna()==True]","ea7a9f69":"# Let's check the missing value(s) in 'Country'\ndf.loc[df['Country'].isna()==True]","81169473":"# We replace it with 'none'\ndf[\"Country\"].replace(np.nan, \"none\", inplace=True)\ndf.loc[df['Country'].isna()==True]","3d4a00ec":"# Let's check the missing value(s) in 'Labels'\ndf.loc[df['Labels'].isna()]","f4d01ab0":"# We replace it with 'none'\ndf[\"Labels\"].replace(np.nan, \"none\", inplace=True)\ndf.loc[df['Labels'].isna()==True]","d1a91c21":"# Let's check the missing value(s) in 'Labels'\ndf.loc[df['Version'].isna()]","d2e044bd":"# We replace it with 'none'\ndf[\"Version\"].replace(np.nan, \"none\", inplace=True)\ndf.loc[df['Version'].isna()==True]","582c0d93":"# Let's check the missing value(s) in 'Labels'\ndf.loc[df['AlbumType'].isna()]","3494c5c0":"# We replace it with 'none'\ndf[\"AlbumType\"].replace(np.nan, \"none\", inplace=True)\ndf.loc[df['AlbumType'].isna()==True]","8641683b":"msno.bar(df, color=colormap)","3d7022a3":"def split_to_onehot(df, col):\n    \"\"\"\n    This method converts features separated by '|' into one-hot vectors.\n    Additionally it drops unnecessary values, which are only present in \n    test set \/ train set or have only one value.\n    \"\"\"\n    # Getting all unique genre values.\n    unique = []\n    for i in df.index:\n        unique.extend(df.loc[i,col].split(\"|\"))\n    if \"\" in unique:\n        unique.remove(\"\")\n    unique = list(set(unique))\n    \n    # Putting values into binary form \n    onehot = df.loc[:,[\"Category\"]]\n    onehot[unique] = np.zeros((len(unique),), dtype = np.int8)\n    for i in df.index:\n        g = set(df.loc[i,col].split(\"|\"))\n        for j in g:\n            if j!=\"\":\n                onehot.loc[i,j] = 1\n                \n    # Dropping unnecessary values            \n    _a = onehot.groupby(\"Category\").sum()\n    only_one = list(_a.sum()[_a.sum()==1].index)\n    only_train = list(_a.loc[\"none\"][_a.loc[\"none\"]==0].index)\n    only_test = list(_a.loc[[\"like\",'dislike']].sum()[_a.loc[[\"like\",'dislike']].sum()==0].index)\n    _a = set(only_one + only_train + only_test)\n    onehot = onehot.drop(_a, axis=1)\n    \n    return onehot\n\ndef onehot_to_tsne2(df, title):\n    \"\"\"\n    This method converts one-hot representation into two tsne values.\n    Such operation is needed to shrink the dimensionality of the dataset.\n    \"\"\"\n    onehot = df.drop(\"Category\",axis=1)\n    embedding = TSNE(n_components=2, init=\"pca\")\n    embedded = embedding.fit_transform(onehot)\n    embedded = pd.DataFrame(embedded,columns=[f\"{title}_tsne1\",f\"{title}_tsne2\"])\n    \n    return embedded\n\ndef plot_cumulative_onehot(onehot):\n    \"\"\"\n    Method of plotting commulative values of the one hot feature representation.\n    \"\"\"\n    _df = onehot.groupby(\"Category\").sum()\n    fig = go.Figure()\n    for i in range(len(_df.index)):\n        k = _df.index[i]\n        x,y=[],[]\n        for g in _df.columns:\n            if _df.loc[k,g]!=0:\n                x.append(g)\n                y.append(_df.loc[k,g])\n        fig.add_trace(go.Bar(x=x, y=y,name=k,marker=dict(color=colormap[i+1])))\n    fig.show()","51cef603":"# Let's see how the description\nprint(description[\"Country\"])","c4fe73b8":"# We split to onehot vector and plot the countries\ncountry_onehot = split_to_onehot(df, \"Country\")\nplot_cumulative_onehot(country_onehot)","746caf58":"# We drop the old column and replace it by the new onehot vector\ncountry_onehot = country_onehot.drop(\"Category\", axis=1)\ndf = pd.concat([df,country_onehot], axis=1)\ndf = df.drop([\"Country\", \"none\"], axis=1)\ndf.head()","b0b941cd":"# Let's check what is in 'Vocal'\nprint(description[\"Vocal\"])","edd5cd5c":"# Create a new array and split the vocal types\nonehot = np.zeros((len(df),2))\nfor i in range(len(df)):\n    v = df.iloc[i][\"Vocal\"]\n    if v == 'F':\n        onehot[i] = [1,0]\n    elif v == 'M':\n        onehot[i] = [0,1]\n    elif v == 'F|M':\n        onehot[i] = [1,1]\n        \n# We drop the old column and replace it by the new onehot vector\ndf[[\"FemaleVocal\",\"MaleVocal\"]] = onehot\ndf = df.drop(\"Vocal\",axis=1)\ndf.head()","704ff9a2":"# Let's check the key feature\ndescription[\"Key\"]","151bab27":"# Create a scatterplot\nxp.scatter(df, x=\"Key\", y=\"Track\",color=\"Category\", height=500, color_discrete_sequence=colormap[1:4])","b090b920":"# We correct some keys and replace them with the same value (C# = D\u266d, etc)\ndf[\"Major\"], df[\"Key\"] = df[\"Key\"].apply(lambda x: x.split(\" \")[1]), df[\"Key\"].apply(lambda x: x.split(\" \")[0])\ndf.loc[:,\"Key\"] = df[\"Key\"].replace({\"D\u266d\": \"C#\", \"E\u266d\": \"D#\", \"G\u266d\": \"F#\", \"A\u266d\": \"G#\",\"B\u266d\":\"A#\"})\n\n# Create a scatterplot\nxp.scatter(df, x=\"Key\", y=\"Track\",color=\"Category\", height=500, color_discrete_sequence=colormap[1:4])","2356872d":"# We put the Major\/Minor part into new feature, to make it more easy for our model in the fitting process\ndf.loc[:,\"Major\"] = (df[\"Major\"]==\"Major\").astype(int)\n_df = df.groupby([\"Major\",\"Category\"], as_index=False).count()\n\n# Create a bar chart\nxp.bar(_df,x=\"Major\", y=\"Track\",color=\"Category\", height=400, color_discrete_sequence=colormap[1:4])","53a59577":"# Let's plot a full overview (key + major\/minor)\n_df = df.copy(deep=True)\n_df[\"Key_precise\"] = _df[\"Key\"] +\"_major:\"+ _df[\"Major\"].astype(str)\n_df = _df.groupby([\"Key_precise\",\"Category\"], as_index=False).count()\n\n# Create a bar chart\nxp.bar(_df, x=\"Key_precise\", y=\"Track\", color=\"Category\", height=500, color_discrete_sequence=colormap[1:4])","e6e96b8a":"# Replace the old column with our onehot vector\ndf[list(set(df[\"Key\"].values))] = OneHotEncoder().fit_transform(df[[\"Key\"]]).toarray()\ndf = df.drop(\"Key\", axis=1)\ndf.head()","56db17f5":"# Check the description\nfor k in [\"Energy\",\"Happiness\",\"Dancebility\"]:\n    print(f\"{k}:{description[k]}\")","f2b13419":"# Let's scale energy, happiness and danceabilty down proportionally\ndf[['Energy%', 'Happiness%', 'Danceability%']] = df[['Energy', 'Happiness', 'Danceability']].apply(lambda x: x\/sum(x), axis=1)\ndf = df.drop([\"Energy\", \"Danceability\", \"Happiness\"], axis=1)\ndf.head()","3b8598fb":"# Let's see how the feature is structured\nprint(description[\"Artists\"])","0128c888":"# How many artists are there\nall_artists = []\nfor i in df.index:\n    all_artists.extend(df.loc[i, \"Artists\"].split(\"|\"))\nlen(set(all_artists))","7f94cb7f":"# We will put some threshold, not to put some rare artists into one-hot vector.\nthreshold = 3\nrare_artists = Counter(all_artists)\nrare_artists = [k for k in rare_artists if rare_artists[k]<=threshold]\nlen(rare_artists)","258e156c":"# Drop all artists who are only in the test-set or the train-set\nin_train, in_test = [], []\nfor i in df.loc[train_mask].index:\n    in_train.extend(df.loc[i, \"Artists\"].split(\"|\"))\nfor i in df.loc[~train_mask].index:\n    in_test.extend(df.loc[i, \"Artists\"].split(\"|\"))\n    \nonly_test = set(in_test) - set(in_train)\nonly_train = set(in_train) - set(in_test)\ndisplay(len(only_test))\ndisplay(len(only_train))","75774600":"all_artists = list(set(all_artists) - set(rare_artists) - only_test - only_train)\nprint(len(all_artists))\nrare_artists = set(rare_artists) | only_test | only_train\nprint(len(rare_artists))","c11110b7":"# Create onehot vector for artists\nresult = []\ndef prune(x):\n    vector = np.zeros(len(all_artists)+1) # for rare artists\n    x = [i for i in x.split(\"|\")]\n    for i in range(len(all_artists)):\n        vector[i]=1 if all_artists[i] in x else 0\n    if len(x)>sum(vector):\n        vector[-1]=1\n    result.append(vector)\n\ndf[\"Artists\"].apply(prune)\nonehot_artists = pd.DataFrame(result, columns = all_artists + [\"Others\"], index=df.index)\n\nonehot_artists","d8775ade":"# We drop the rare artists (Others) column, it's not really relevant.\nonehot_artists = onehot_artists.drop(\"Others\", axis=1)\n\n# Let's plot the artists\nonehot_artists[\"Category\"] = df[\"Category\"]\nplot_cumulative_onehot(onehot_artists)","7d2c8f2e":"# Since there are too many features in the onehot vector, we will apply tsne (dimensionality reduction)\nartists_embedded = onehot_to_tsne2(onehot_artists, \"Artists\")\n_df = artists_embedded.copy(deep=True)\n_df[[\"Category\",\"Artists\"]] = df[[\"Category\",\"Artists\"]]\n\n# Create scatterplot to visualize artists, now reduced to 2 tsne values\nxp.scatter(_df,x=\"Artists_tsne1\",y=\"Artists_tsne2\",color=\"Category\", hover_data=[\"Artists\"], height=500, color_discrete_sequence=colormap[1:4])","54f8db52":"# Replace the old artists column\ndf = pd.concat([df,artists_embedded[[\"Artists_tsne1\",\"Artists_tsne2\"]]], axis=1)\ndf = df.drop(\"Artists\", axis=1)\ndf.head()","e15cacb9":"# Check what's in the feature\ndescription[\"Release year\"]","876dcfa8":"# Let's create a scatterplot\nxp.scatter(df, x=\"ReleaseYear\", y=\"Track\",color=\"Category\", height=500, color_discrete_sequence=colormap[1:4])","a2e6d194":"# Let's create a decade feature, to detect some music of 80s, 90s etc. as a specific genre\ndf.loc[:,\"ReleaseDecade\"] = (df.loc[:,\"ReleaseYear\"]\/\/10 * 10)\n# Because of the small number of values, we will put all <80s values in the 80s genre\ndf.loc[df.loc[:,\"ReleaseDecade\"]<1990,\"ReleaseDecade\"] = 1980 \n_df = df.groupby([\"ReleaseDecade\",\"Category\"], as_index=False).count()\nxp.bar(_df,x=\"ReleaseDecade\", y=\"Track\",color=\"Category\",height=500, color_discrete_sequence=colormap[1:4])","b78cb491":"# Create onehot vector with the decades\ndf[list(set(df[\"ReleaseDecade\"].values))] = OneHotEncoder().fit_transform(df[[\"ReleaseDecade\"]]).toarray()\ndf = df.drop([\"ReleaseDecade\", \"ReleaseYear\"], axis=1)\ndf.head()","bf647ca1":"# Let's see the description\nprint(description[\"Labels\"])","ea2793b1":"# Split the lables into onehot vector\nlabels_onehot = split_to_onehot(df, \"Labels\")\nplot_cumulative_onehot(labels_onehot)","a5d9b286":"# Use tsne function to reduce dimensionality\nlabels_embedded = onehot_to_tsne2(labels_onehot, \"Labels\")\n_df = labels_embedded.copy(deep=True)\n_df[[\"Category\",\"Labels\"]] = df[[\"Category\",\"Labels\"]]\n\n# Create scatterplot\nxp.scatter(_df,x=\"Labels_tsne1\",y=\"Labels_tsne2\",color=\"Category\", hover_data=[\"Labels\"], height=500, color_discrete_sequence=colormap)","b0602503":"# Replace old column\ndf = pd.concat([df,labels_embedded[[\"Labels_tsne1\",\"Labels_tsne2\"]]], axis=1)\ndf = df.drop(\"Labels\", axis=1)\ndf.head()","48ab3eab":"# Read the description\ndescription[\"Artists Genres\"]","cd75a618":"# To onehot vector\ngenres_onehot = split_to_onehot(df, \"ArtistsGenres\")\nplot_cumulative_onehot(genres_onehot)","38df3a6c":"# We have too much values, so we reduce the dimensionality\ngenres_embedded = onehot_to_tsne2(genres_onehot, \"Genres\")\n_df = genres_embedded.copy(deep=True)\n_df[[\"Category\",\"ArtistsGenres\"]] = df[[\"Category\",\"ArtistsGenres\"]]\n\n# Create scatterplot\nxp.scatter(_df,x=\"Genres_tsne1\",y=\"Genres_tsne2\",color=\"Category\", hover_data=[\"ArtistsGenres\"], height=500, color_discrete_sequence=colormap)","874a881a":"# Replace the old column\ndf = pd.concat([df,genres_embedded], axis=1)\ndf = df.drop(\"ArtistsGenres\", axis=1)\ndf.head()","3866c1db":"# See description\nprint(description[\"Album\"])","cb73b13d":"# To onehot vector\nalbum_onehot = split_to_onehot(df, \"Album\")\nplot_cumulative_onehot(album_onehot)","37d1ef21":"# Again, too much values, so reduce to 2 tsne values\nalbum_embedded = onehot_to_tsne2(onehot_artists, \"Album\")\n_df = album_embedded.copy(deep=True)\n_df[[\"Category\",\"Album\"]] = df[[\"Category\",\"Album\"]]\n\n# Scatterplot\nxp.scatter(_df,x=\"Album_tsne1\",y=\"Album_tsne2\",color=\"Category\", hover_data=[\"Album\"], height=500, color_discrete_sequence=colormap)","998bf7b1":"# Replace column\ndf = pd.concat([df,album_embedded[[\"Album_tsne1\",\"Album_tsne2\"]]], axis=1)\ndf = df.drop(\"Album\", axis=1)\ndf.head()","09b8e2a3":"# Check the description\nfor i in [\"Track\", \"Version\", \"Album_type\"]:\n    print(description[i])","c1c7f665":"# We do not have features, so we use label encoder\ntrack_encoder = LabelEncoder()\ndf[\"Track\"] = track_encoder.fit_transform(df[\"Track\"])\ndf.head()","b2def795":"# Let's see if there is a dependency\n_df = df.groupby([\"Version\",\"Category\"], as_index=False).count()\n\n# Plot a bar chart\nxp.bar(_df,x=\"Version\",y=\"Id\",color=\"Category\", color_discrete_sequence=colormap)","c7725fcd":"# To onehot vector and replace column\nversions = set(df[\"Version\"])\ndf[list(versions)] = OneHotEncoder().fit_transform(df[[\"Version\"]]).toarray()\ndf = df.drop([\"Version\",\"none\"], axis=1)\ndf.head()","1ad4336a":"# Let's see for any relevance\n_df = df.groupby([\"AlbumType\",\"Category\"], as_index=False).count()\n\n# Create a bar chart\nxp.bar(_df,x=\"AlbumType\",y=\"Id\",color=\"Category\", color_discrete_sequence=colormap)","efeafe1c":"# Create onehot vector and replace old column\nalbumTypes = set(df[\"AlbumType\"])\ndf[list(albumTypes)] = OneHotEncoder().fit_transform(df[[\"AlbumType\"]]).toarray()\ndf = df.drop([\"AlbumType\",\"none\"], axis=1)\ndf.head()","452e662f":"# Check the description\nfor k in [\"Duration\",\"BPM\"]:\n    print(f\"{k}:{description[k]}\")","a52d27b4":"# Let's see if there is a dependency\n_df = df.groupby([\"Duration\",\"Category\"], as_index=False).count()\n\n# Create scatterplot\nxp.scatter(df, x=\"Track\", y=\"Duration\",color=\"Category\", height=500, color_discrete_sequence=colormap[1:4])","7d7edb70":"# No dependency really, so we leave duration as it is\n# We drop the column\ndf.drop('Duration', axis=1, inplace=True)","ab3c11fb":"# Let's see if there is a dependency between BPM and (no) likes\n_df = df.groupby([\"BPM\",\"Category\"], as_index=False).count()\n\n# Create scatterplot\nxp.scatter(df, x=\"Track\", y=\"BPM\",color=\"Category\", height=500, color_discrete_sequence=colormap[1:4])","7d6a859f":"# No dependency I guess, so we leave BPM as it is\n# We drop the column\ndf.drop('BPM', axis=1, inplace=True)","483e0197":"df","0e3cca25":"df.info()","fdf806f8":"# Let's select our features\nfeatures = df.columns[2:]\ndummies = pd.get_dummies(df[features])\nx = dummies[:-370]\nx_acc = dummies[-370:-300]\nx_test = dummies[-300:]\n\ntrain_data = df[:-370]\ny = train_data['Category']\ntrain_data_acc = df[-370:-300]\ny_test = train_data_acc[\"Category\"]","7874dcae":"# Try different models\nmodel = RandomForestClassifier(n_estimators = 1000, max_depth = 10, random_state = 42)\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with RandomForest is: ', accuracy)\n\nmodel = AdaBoostClassifier(n_estimators = 1000)\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with AdaBoost is: ', accuracy)\n\nmodel = GradientBoostingClassifier(n_estimators = 1000)\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with GradientBoosting is: ', accuracy)\n\nmodel = DecisionTreeClassifier()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with DecisionTree is: ', accuracy)\n\nmodel = LinearDiscriminantAnalysis()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with LinearDiscriminant is: ', accuracy)\n\nmodel = SVC()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with SupportVectorMachine: ', accuracy)\n\nmodel = ExtraTreesClassifier()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with ExtraTrees: ', accuracy)\n\nmodel = MLPClassifier()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with MLPClassifier: ', accuracy)\n\nmodel = GaussianProcessClassifier()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with GaussianProcess: ', accuracy)\n\nmodel = KNeighborsClassifier()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with KNeighbors: ', accuracy)\n\nmodel = CatBoostClassifier()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with CatBoost: ', accuracy)","b710fc61":"# RandomForest gives the best accuracy\n\nfinal_model = RandomForestClassifier(n_estimators = 1000, max_depth = 10, random_state = 42)\nfinal_model.fit(x, y)\n\nsample = pd.read_csv(\"..\/input\/mymusicalprefrences\/sample_submition.csv\")\nsample[\"Category\"] = final_model.predict(x_test)\nsample[\"Category\"] = (sample[\"Category\"]==\"like\").astype(int)\nsample.to_csv(\".\/submission.csv\", index=False)","e9c839be":"**3.10 TRACK, VERSION, ALBUM TYPE**","c7aba3a6":"Track","4fee891a":"AlbumType","ac9921d2":"Duration","3608a4f3":"***SOME USEFUL FUNCTIONS***","7bf08965":"BPM","8c4651bb":"**3.6 RELEASE YEAR**","a6702604":"Version","f1350244":"**3.3 KEY**","eb1b0fdd":"**3.2 VOCAL**","f2508f86":"**3.1 COUNTRY**","ca603da2":"# **2. DATA PREPARATION**","2dbbc96a":"**3.5 ARTISTS**  ","e4737d15":"# **3. FEATURE ENGINEERING**","0ed891c3":"**3.11 DURATION, BPM**","97c4de90":"# **1. DATA ANALYSIS**","1b49bd90":"**3.8 ARTISTS GENRES**","968ba34e":"# **4. MODEL SELECTION**","0eaddac5":"**3.4 ENERGY, HAPPINESS, DANCEABILITY**","d07cec44":"**3.7 LABELS**","2968978c":"**3.9 ALBUM**"}}