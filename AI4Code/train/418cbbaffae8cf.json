{"cell_type":{"66df1fa2":"code","2684f2e7":"code","eb7b7a1b":"code","690e4b6a":"code","b9972c4a":"code","c3699648":"code","0f3d74f4":"code","deec0767":"code","ba122558":"code","b69a2fa0":"code","80877171":"code","5e9e6242":"code","76cb7786":"code","b09ca13e":"code","f2beb527":"code","ab1a4bf3":"code","58af48ca":"code","f6444843":"code","50e823a0":"code","d0d87094":"code","a8f7d358":"code","6bcb7ed1":"code","fbd72f3e":"code","8b8f4874":"code","4c2d78b1":"code","b647f51f":"code","bf5b4fac":"code","6e136f25":"code","b9c3f6e3":"code","4dc0b99e":"code","500d4662":"code","ae1fb1ed":"code","e8ebcb3d":"code","199bdfe3":"code","ad9cab82":"code","7b3c15f2":"code","8ceb6313":"code","080f4638":"code","7d27ae9a":"code","274225ac":"code","b7d00b07":"code","11a7fa32":"code","df1c1e09":"code","f5cfab43":"code","c13a5bec":"code","55cf00b6":"code","19e882c2":"code","888a5686":"code","258e562e":"code","5652cf8d":"code","788261dc":"code","ae6813ea":"code","134b6b35":"code","7fb946ae":"code","de893935":"code","423be859":"code","aa50047d":"code","11839db1":"code","8485ba1a":"markdown","b93294a3":"markdown","324a2f87":"markdown","9c9825ab":"markdown","f7e76c07":"markdown","86225df2":"markdown","4c89e116":"markdown","0d65454e":"markdown","726bf9fe":"markdown","41de12e8":"markdown","3cd750da":"markdown","4c7fcbd9":"markdown","c3dfa1bc":"markdown","10987653":"markdown","a79e8370":"markdown","a84ce70f":"markdown","46296507":"markdown","05bcb879":"markdown","21aa8d22":"markdown","faf5c9a4":"markdown","4abd1637":"markdown","801dd2ad":"markdown","fceed3d4":"markdown","51313d3d":"markdown","314a6506":"markdown","279e466e":"markdown","3883df60":"markdown","38241a72":"markdown","45017af0":"markdown","8d69e39d":"markdown","3d73884e":"markdown","2a29559b":"markdown","224a6d86":"markdown","b9cbf0d1":"markdown"},"source":{"66df1fa2":"import numpy as np\nimport pandas as pd\nimport datetime as dt\nimport re\nfrom nltk.util import ngrams\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.dates as mdates\n\nfrom mlxtend.frequent_patterns import apriori\nfrom mlxtend.frequent_patterns import association_rules","2684f2e7":"Transaction_Data = pd.read_csv('..\/input\/transaction\/QVI_transaction_data.csv')\nCustomer_Data = pd.read_csv('..\/input\/customer-data\/QVI_purchase_behaviour.csv')\n","eb7b7a1b":"Transaction_Data.head()","690e4b6a":"Transaction_Data.dtypes","b9972c4a":"Transaction_Data.describe()","c3699648":"Customer_Data.head()","0f3d74f4":"\nTransaction_Data.DATE = pd.TimedeltaIndex(Transaction_Data.DATE, unit='d') + dt.datetime(1899, 12, 30)\nTransaction_Data","deec0767":"# get unique products\nTransaction_Data['PROD_NAME'].unique()","ba122558":"# Extracting product size\nTransaction_Data['PACK_SIZE'] = [re.search(r\"[0-9]+(g|G)\", i).group(0).replace('G','g') for i in Transaction_Data['PROD_NAME']]\n\nTransaction_Data.PROD_NAME = Transaction_Data.PROD_NAME.replace('\\d+g', \"\")\nTransaction_Data","b69a2fa0":"# replace & with space and remove multiple spaces\nTransaction_Data.PROD_NAME = [\" \".join(i.replace('&',' ').split()) for i in Transaction_Data.PROD_NAME]\n# remove digits that are followed by grams\nTransaction_Data.PROD_NAME = [re.sub(r\"\\s*[0-9]+(g|G)\", r\"\", i) for i in Transaction_Data.PROD_NAME]\nTransaction_Data","80877171":"def replaceWords(string):\n    # specific\n    string = re.sub(r\"SeaSalt\", \"Sea Salt\", string)\n    string = re.sub(r\"Frch\/Onin\", \"French Onion\", string)\n    string = re.sub(r\"Cheddr Mstrd\", \"Cheddar Mustard\", string)\n    string = re.sub(r\"Jlpno Chili\", \"Jalapeno Chilli\", string)\n    string = re.sub(r\"Swt\/Chlli Sr\/Cream\", \"Sweet Chilli Sour Cream\", string)\n    string = re.sub(r\"SourCream\", \"Sour Cream\", string)\n    string = re.sub(r\"Tmato Hrb Spce\", \"Tomato Herb Spice\", string)\n    string = re.sub(r\"S\/Cream\", \"Sour Cream\", string)\n    string = re.sub(r\"ChipsFeta\", \"Chips Feta\", string)\n    string = re.sub(r\"ChpsHny\", \"Chips Honey\", string)\n    string = re.sub(r\"FriedChicken\", \"Fried Chicken\", string)\n    string = re.sub(r\"OnionDip\", \"Onion Dip\", string)\n    string = re.sub(r\"SweetChili\", \"Sweet Chilli\", string)\n    string = re.sub(r\"PotatoMix\", \"Potato Mix\", string)\n    string = re.sub(r\"Seasonedchicken\", \"Seasoned Chicken\", string)\n    string = re.sub(r\"CutSalt\/Vinegr\", \"Cut Salt Vinegar\", string)\n    string = re.sub(r\"ChpsBtroot\", \"Chips Beetroot\", string)\n    string = re.sub(r\"ChipsBeetroot\", \"Chips Beetroot\", string)\n    string = re.sub(r\"ChpsFeta\", \"Chips Feta\", string)\n    string = re.sub(r\"OnionStacked\", \"Onion Stacked\", string)\n    string = re.sub(r\"Ched\", \"Cheddar\", string)\n    string = re.sub(r\"Strws\", \"Straws\", string)\n    string = re.sub(r\"Slt\", \"Salt\", string)\n    string = re.sub(r\"Chikn\", \"Chicken\", string)\n    string = re.sub(r\"Rst\", \"Roast\", string)\n    string = re.sub(r\"Vinegr\", \"Vinegar\", string)\n    string = re.sub(r\"Mzzrlla\", \"Mozzarella\", string)\n    string = re.sub(r\"Originl\", \"Original\", string)\n    string = re.sub(r\"saltd\", \"Salted\", string)\n    string = re.sub(r\"Swt\", \"Sweet\", string)\n    string = re.sub(r\"Chli\", \"Chilli\", string)\n    string = re.sub(r\"Hony\", \"Honey\", string)\n    string = re.sub(r\"Chckn\", \"Chicken\", string)\n    string = re.sub(r\"Chp\", \"Chips\", string)\n    string = re.sub(r\"Chip\", \"Chips\", string)\n    string = re.sub(r\"Btroot\", \"Beetroot\", string)\n    string = re.sub(r\"Chs\", \"Cheese\", string)\n    string = re.sub(r\"Crm\", \"Cream\", string)\n    string = re.sub(r\"Orgnl\", \"Original\", string)\n    string = re.sub(r\"Swt ChliS\/Cream\", \"Sweet Chilli Sour Cream\", string)\n    string = re.sub(r\"SnagSauce\", \"Snag Sauce\", string)\n    string = re.sub(r\"Compny\", \"Company\", string)\n    string = re.sub(r\"HoneyJalapeno\", \"Honey Jalapeno\", string)\n    string = re.sub(r\"Sweetspcy\", \"Sweet Spicy\", string)\n    string = re.sub(r\"BeetrootRicotta\", \"Beetroot Ricotta\", string)\n    string = re.sub(r\"Crn\", \"Corn\", string)\n    string = re.sub(r\"Crnchers\", \"Crunchers\", string)\n    string = re.sub(r\"CreamHerbs\", \"CreamHerbs\", string)\n    string = re.sub(r\"Tmato\", \"Tomato\", string)\n    string = re.sub(r\"BBQMaple\", \"Berbeque Maple\", string)\n    string = re.sub(r\"BBQ\", \"Berbeque\", string)\n\n\n    return string\n\nTransaction_Data['PROD_NAME'] = [replaceWords(s) for s in Transaction_Data['PROD_NAME']]\n\nTransaction_Data['PROD_NAME'].replace('Infzns Crn Crnchers Tangy Gcamole',\n'Infuzions Corn Crunchers Tangy Guacamole', inplace=True)","5e9e6242":"# Removing special characters, replace & with space\nTransaction_Data['PROD_NAME']=Transaction_Data['PROD_NAME'].replace('\\&','',regex=True)","76cb7786":"#Remove Salsa Products\n#Transaction_Data.drop([Transaction_Data.PROD_NAME == '\\Salsa'], inplace = True)\nTransaction_Data = Transaction_Data[~Transaction_Data['PROD_NAME'].str.contains('Salsa')]\n","b09ca13e":"#Transaction_Data Summary\nTransaction_Data.describe()","f2beb527":"Transaction_Data[Transaction_Data['PROD_QTY'] > 5]","ab1a4bf3":"Customer_Data = Customer_Data[Customer_Data['LYLTY_CARD_NBR'] != 226000]\nCustomer_Data","58af48ca":"#Remove Outliers\n#Transaction_Data Summary\nTransaction_Data = Transaction_Data[Transaction_Data['PROD_QTY'] < 200]\nTransaction_Data.describe()","f6444843":"#Transaction By Date\n\nTransaction_Count_By_Date = Transaction_Data.groupby('DATE').agg({'PROD_QTY': 'sum'}).reset_index()\n\nTransaction_Count_By_Date","50e823a0":"Transaction_Data.append({'DATE' : '2018-12-25'} , ignore_index=True)","d0d87094":"import datetime\nstart_date = '2018-07-01'\nend_date   = '2019-06-30'\n\nAll_Dates = pd.date_range(start_date, end_date).tolist()\nAll_Dates = pd.Series(All_Dates, name='NEW_DATE')\nAll_Dates","a8f7d358":"Transaction_Count_By_Date=Transaction_Count_By_Date.merge(All_Dates, how='outer', left_index=True, right_index=True)\nTransaction_Count_By_Date.tail(10)","6bcb7ed1":"Missing = Transaction_Count_By_Date[(Transaction_Count_By_Date['DATE'] >= '2018-12-01') & (Transaction_Count_By_Date['DATE'] <= '2018-12-31')]\nMissing","fbd72f3e":"December = Transaction_Data[(Transaction_Data['DATE'] >= '2018-12-01') & (Transaction_Data['DATE'] <= '2018-12-31')]\nDecember","8b8f4874":"Transactions_in_December = December.groupby('DATE').agg({'PROD_QTY': 'sum'}).reset_index()\nTransactions_in_December","4c2d78b1":"## Plot December quantities sold\n# filter december\nTransactions_in_December = Transaction_Count_By_Date[Transaction_Count_By_Date['DATE'].isin(pd.date_range(start=\"2018-12-01\",end=\"2018-12-31\").tolist())]\nTransaction_Count_By_Date\n# fill in missing dec data\n#Transaction_Count_By_Date = Transaction_Count_By_Date.set_index('DATE').reindex(pd.date_range(start=\"2018-12-01\",end=\"2018-12-31\"), fill_value=0)\n","b647f51f":"fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(20,5))\n\nax1=plt.subplot(121)\nsns.lineplot(x=\"DATE\", y=\"PROD_QTY\", data=Transaction_Count_By_Date, ax=ax1)\nax1.xaxis.set_major_formatter(mdates.DateFormatter(\"%b-%Y\"))\nsns.lineplot(x=\"DATE\", y=\"PROD_QTY\", data=Transaction_Count_By_Date[(Transaction_Count_By_Date['DATE'] > '2018-12-11') & (Transaction_Count_By_Date['DATE'] < '2018-12-28')], color='#2ca02c', ax=ax1)\nsns.lineplot(x=\"DATE\", y=\"PROD_QTY\", data=Transaction_Count_By_Date[(Transaction_Count_By_Date['DATE'] > '2018-08-12') & (Transaction_Count_By_Date['DATE'] < '2018-08-24')], color='red', ax=ax1)\nsns.lineplot(x=\"DATE\", y=\"PROD_QTY\", data=Transaction_Count_By_Date[(Transaction_Count_By_Date['DATE'] > '2019-05-10') & (Transaction_Count_By_Date['DATE'] < '2019-05-24')], color='red', ax=ax1)\nplt.ylabel('Quantities Sold')\nplt.title('Quantities Sold Throughout Whole Year')\n\n## Plot December quantities sold\n# filter december\nQTY_December = Transaction_Count_By_Date[Transaction_Count_By_Date['DATE'].isin(pd.date_range(start=\"2018-12-01\",end=\"2018-12-31\").tolist())]\n\n# fill in missing dec data\nQTY_December = QTY_December.set_index('DATE').reindex(pd.date_range(start=\"2018-12-01\",end=\"2018-12-31\"), fill_value=0)\n\nax2=plt.subplot(122)\nax2.bar(QTY_December.index,QTY_December['PROD_QTY'],color='#2ca02c')\nax2.set_xticks(QTY_December.index)\nax2.xaxis.set_major_formatter(mdates.DateFormatter(\"%b-%d\"))\nax2.xaxis.set_minor_formatter(mdates.DateFormatter(\"%b-%d\"))\nax2.tick_params(axis='x', rotation=90) \nplt.ylabel('Quantities Sold')\nplt.title('Quantities Sold in December')\nplt.show()","bf5b4fac":"Transaction_Data.PACK_SIZE","6e136f25":"# Product Size\n\nfig, axes = plt.subplots(nrows=1, ncols=1, figsize=(15,4))\n\nax1=plt.subplot(121)\nTransaction_Data.groupby('PACK_SIZE').agg({'PROD_QTY': 'sum'}).sort_values('PROD_QTY').reset_index().plot.barh(x='PACK_SIZE', legend=False, ax=ax1)\nax1.set_ylabel('Pack Size')\nax1.set_xlabel('Quantities Sold')\n\nplt.show()","b9c3f6e3":"\n\n# get brand name from first word\nTransaction_Data['BRAND_NAME'] = [i.split(' ')[0] for i in Transaction_Data['PROD_NAME']]\nTransaction_Data","4dc0b99e":"Transaction_Data.BRAND_NAME.unique()","500d4662":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n\n# Product quantity sales by brand\nax1=plt.subplot(121)\nTransaction_Data.groupby(['BRAND_NAME'], as_index=False).agg({'PROD_QTY': 'sum'}).sort_values('PROD_QTY').plot.barh(x='BRAND_NAME',legend=False, ax=ax1)\n\nax1.set_xlabel('Quantity Sold')\nax1.set_ylabel('BRAND_NAME')\nax1.set_title('Quantities Sold by Brand')\n\nax2=plt.subplot(122)\nTransaction_Data.groupby(['BRAND_NAME'], as_index=False)[['TXN_ID']].count().sort_values('TXN_ID').plot.barh(x='BRAND_NAME',color='#ff7f0e', legend=False, ax=ax2)\nax2.set_xlabel('Number of Transactions')\nax2.set_ylabel('BRAND_NAME')\nax2.set_title('Transactions by Brand')\n\nplt.show()","ae1fb1ed":"Customer_Data","e8ebcb3d":"#Analysis of customer class\nCustomer_Class = pd.pivot_table(data=Customer_Data[['LIFESTAGE','PREMIUM_CUSTOMER']],index=['PREMIUM_CUSTOMER'], aggfunc=np.size)\nCustomer_Class","199bdfe3":"sns.set()\nCustomer_Class.plot(kind='barh', alpha=.9, color=sns.color_palette(\"colorblind\"),title='Customer Class Analysis').invert_yaxis()\nplt.ylabel(\"Customer Class\")","ad9cab82":"# Customer lifestage counts\nCustomer_Data.LIFESTAGE.value_counts().plot(kind='barh', alpha=.9, color=sns.color_palette(\"colorblind\"), title='Customer Lifestage Analysis').invert_yaxis()","7b3c15f2":"# Merge Customer Data to Transaction Data using LYLTY_CARD as Primary Key\nMerged_Data = Transaction_Data.merge(Customer_Data, on='LYLTY_CARD_NBR')\n\n#export merged data as csv\nMerged_Data.to_csv(r'.\/Data.csv', index = False)\n# check for duplicates\nprint('No Duplicates:', len(Merged_Data) == len(Merged_Data)) \n# check for nulls\nprint('Number of Nulls:', Merged_Data.isnull().sum().sum()) ","8ceb6313":"Merged_Data.head(10)","080f4638":"# Sum up for Lifestage and Premium_Customer group \nPremium_Lifestyle = Merged_Data.groupby(['LIFESTAGE','PREMIUM_CUSTOMER']).agg({'TOT_SALES':'sum','PROD_QTY':'sum', 'TXN_ID':'count'}).reset_index().sort_values('TOT_SALES', ascending = False) \n\nPremium_Lifestyle\n","7d27ae9a":"pd.pivot_table(Merged_Data, values='TOT_SALES', index=['LIFESTAGE'], columns=['PREMIUM_CUSTOMER'], aggfunc=np.sum, margins=True,margins_name='Total')\n","274225ac":"pd.pivot_table(Merged_Data, values='TOT_SALES', index=['LIFESTAGE'], columns=['PREMIUM_CUSTOMER'], aggfunc=np.sum).plot( kind='barh')","b7d00b07":"\npd.pivot_table(Merged_Data, values='PROD_QTY', index=['LIFESTAGE'], columns=['PREMIUM_CUSTOMER'], aggfunc=np.size, margins=True,margins_name='Total')\n","11a7fa32":"pd.pivot_table(Merged_Data, values='PROD_QTY', index=['LIFESTAGE'], columns=['PREMIUM_CUSTOMER'], aggfunc=np.size).plot( kind='barh')","df1c1e09":"# Number of unique customers in each group\nPremium_Lifestyle_Customers = Merged_Data[['LYLTY_CARD_NBR','LIFESTAGE','PREMIUM_CUSTOMER']].drop_duplicates('LYLTY_CARD_NBR').reset_index(drop=True).groupby(['LIFESTAGE','PREMIUM_CUSTOMER']).size().reset_index(name='Count').sort_values('Count').merge(Premium_Lifestyle, on=['LIFESTAGE','PREMIUM_CUSTOMER'])\n\n\nPremium_Lifestyle_Customers['SALES_PER_Customer'] = Premium_Lifestyle_Customers['TOT_SALES']\/Premium_Lifestyle_Customers['TXN_ID']\nPremium_Lifestyle_Customers['SALES_PER_Unique_Customer'] = Premium_Lifestyle_Customers['TOT_SALES']\/Premium_Lifestyle_Customers['Count']\nPremium_Lifestyle_Customers = Premium_Lifestyle_Customers.sort_values('SALES_PER_Customer')\n\nPremium_Lifestyle_Customers","f5cfab43":"## Sales by each Segment per Customer and per Unique Customer\n#Sales per customer\npd.pivot_table(Premium_Lifestyle_Customers, values='SALES_PER_Customer', index=['LIFESTAGE'], columns=['PREMIUM_CUSTOMER'], aggfunc=np.sum).plot(kind='barh')\n","c13a5bec":"#Sales per Unique customer\npd.pivot_table(Premium_Lifestyle_Customers, values='SALES_PER_Unique_Customer', index=['LIFESTAGE'], columns=['PREMIUM_CUSTOMER'], aggfunc=np.sum).plot(kind='barh')","55cf00b6":"Premium_Lifestyle_Customers['QTY_PER_CUSTOMER'] =Premium_Lifestyle_Customers['PROD_QTY']\/Premium_Lifestyle_Customers['TXN_ID']\nPremium_Lifestyle_Customers['QTY_PER_UNIQUE_CUSTOMER'] = Premium_Lifestyle_Customers['PROD_QTY']\/Premium_Lifestyle_Customers['Count']\nPremium_Lifestyle_Customers = Premium_Lifestyle_Customers.sort_values('QTY_PER_CUSTOMER')\nPremium_Lifestyle_Customers","19e882c2":"## Sales Per Customer\npd.pivot_table(Premium_Lifestyle_Customers, values='QTY_PER_CUSTOMER', index=['LIFESTAGE'], columns=['PREMIUM_CUSTOMER'], aggfunc=np.sum).plot(kind='barh')","888a5686":"## Sales Per Unique Customer\npd.pivot_table(Premium_Lifestyle_Customers, values='QTY_PER_UNIQUE_CUSTOMER', index=['LIFESTAGE'], columns=['PREMIUM_CUSTOMER'], aggfunc=np.sum).plot(kind='barh')","258e562e":"#Price per unit\nMerged_Data['PRICE_PER_UNIT'] = Merged_Data['TOT_SALES']\/Merged_Data['PROD_QTY'] \n# get price per unit of each customer then groupby lifestage and premium_customer to get average per group\nprice_per_unit = Merged_Data.groupby('LYLTY_CARD_NBR').agg({'PRICE_PER_UNIT':'mean'}).reset_index().merge(Merged_Data[['LYLTY_CARD_NBR','LIFESTAGE','PREMIUM_CUSTOMER']], on='LYLTY_CARD_NBR').groupby(['LIFESTAGE','PREMIUM_CUSTOMER']).agg({'PRICE_PER_UNIT':'mean'}).reset_index().sort_values('PRICE_PER_UNIT')\nprice_per_unit","5652cf8d":"## Price per segment\npd.pivot_table(price_per_unit, values='PRICE_PER_UNIT', index=['LIFESTAGE'], columns=['PREMIUM_CUSTOMER'], aggfunc=np.sum).plot(kind='barh')","788261dc":"basket = (Merged_Data[(Merged_Data['LIFESTAGE']=='YOUNG SINGLES\/COUPLES') & (Merged_Data['PREMIUM_CUSTOMER']=='Mainstream')]\n        .groupby(['LYLTY_CARD_NBR','BRAND_NAME'])['PROD_QTY']\n        .sum().unstack().reset_index().fillna(0)\n        .set_index('LYLTY_CARD_NBR'))\n\ndef encode_units(x):\n    if x <= 0:\n        return 0\n    if x >= 1:\n        return 1\n\nbasket_sets = basket.applymap(encode_units)\nbasket_sets","ae6813ea":"frequent_itemsets = apriori(basket_sets, min_support=0.07, use_colnames=True)\nfrequent_itemsets","134b6b35":"rules = association_rules(frequent_itemsets, metric=\"lift\")\nrules.head()","7fb946ae":"young_mainstream = Merged_Data[(Merged_Data['LIFESTAGE']=='YOUNG SINGLES\/COUPLES') & (Merged_Data['PREMIUM_CUSTOMER']=='Mainstream')]\nquantity_bybrand = young_mainstream.groupby(['BRAND_NAME'])[['PROD_QTY']].sum().reset_index()\nquantity_bybrand.PROD_QTY = quantity_bybrand.PROD_QTY \/ young_mainstream.PROD_QTY.sum()\nquantity_bybrand = quantity_bybrand.rename(columns={\"PROD_QTY\": \"Targeted_Segment\"})\n\nother_segments = pd.concat([Merged_Data, young_mainstream]).drop_duplicates(keep=False) \n\n# remove young_mainsream\nquantity_bybrand_other = other_segments.groupby(['BRAND_NAME'])[['PROD_QTY']].sum().reset_index()\nquantity_bybrand_other.PROD_QTY = quantity_bybrand_other.PROD_QTY \/ other_segments.PROD_QTY.sum()\nquantity_bybrand_other = quantity_bybrand_other.rename(columns={\"PROD_QTY\": \"Other_Segment\"})\n\nquantity_bybrand = quantity_bybrand.merge(quantity_bybrand_other, on ='BRAND_NAME')\nquantity_bybrand['Affinitytobrand'] = quantity_bybrand['Targeted_Segment'] \/ quantity_bybrand['Other_Segment']\nquantity_bybrand = quantity_bybrand.sort_values('Affinitytobrand')\n\nquantity_bybrand.head()","de893935":"Merged_Data","423be859":"\n\nquantity_bysize = young_mainstream.groupby(['PACK_SIZE'])[['PROD_QTY']].sum().reset_index()\nquantity_bysize.PROD_QTY = quantity_bysize.PROD_QTY \/ young_mainstream.PROD_QTY.sum()\nquantity_bysize = quantity_bysize.rename(columns={\"PROD_QTY\": \"Targeted_Segment\"})\n\nquantity_bysize_other = other_segments.groupby(['PACK_SIZE'])[['PROD_QTY']].sum().reset_index()\nquantity_bysize_other.PROD_QTY = quantity_bysize_other.PROD_QTY \/ other_segments.PROD_QTY.sum()\nquantity_bysize_other = quantity_bysize_other.rename(columns={\"PROD_QTY\": \"Other_Segment\"})\n\nquantity_bysize = quantity_bysize.merge(quantity_bysize_other, on='PACK_SIZE')\nquantity_bysize['Affinitytosize'] = quantity_bysize['Targeted_Segment'] \/ quantity_bysize['Other_Segment']\nquantity_bysize = quantity_bysize.sort_values('Affinitytosize')","aa50047d":"# Function for Lollipop chart\ndef loll_plot(df1,x,y,xlabel,title,firstX):\n    \n    my_color=np.where(df1[x]==firstX, '#ff7f0e', '#1f77b4')\n    my_color[0] = 'red'\n    my_size=np.where(df1[x]==firstX, 70, 30)\n    my_size[0] = '70'\n\n    plt.hlines(y=np.arange(0,len(df1)),xmin=0,xmax=df1[y],color=my_color)\n    plt.scatter(df1[y], np.arange(0,len(df1)), color=my_color, s=my_size)\n    plt.yticks(np.arange(0,len(df1)), df1[x])\n    plt.xlabel(xlabel)\n    plt.title(title)","11839db1":"fig = plt.figure(figsize=(10,6))\nax1 = plt.subplot(121)\nloll_plot(quantity_bybrand,'BRAND_NAME','Affinitytobrand','Affinity','Affinity To Brand','Tyrrells')\n\nax2 = plt.subplot(122)\nloll_plot(quantity_bysize,'PACK_SIZE','Affinitytosize','Affinity','Affinity To Product Size','270')\n\nplt.suptitle('Young Singles\/Couples Mainstream')\nplt.show()","8485ba1a":"Budget(Older families),Mainstream(Retirees) and Mainstream(Young singles\/couples) purchased the highest number of products","b93294a3":"Analysing customers who spends the most on chips (total sales), describing customers by lifestage and\nhow premium their general purchasing behaviour is","324a2f87":"# **Load required libraries**","9c9825ab":"Total Number of Products Sold by Customer Segment","f7e76c07":"## Affinity to Brand and Size\n\nAs a final analysis, let us compute an affinity score for each of the product brand and sizes to see which brand and size `Mainstream Young Singles\/Couples` tend to buy more often.","86225df2":"Create brand names by extracting the first word in product name.","4c89e116":"# Total Sales and Quantity sold","0d65454e":"Total Sales by Customer Segment","726bf9fe":"**Brand Names**","41de12e8":"There are more Mainstream customers than Premium customers","3cd750da":"# **Exploratory Data Analysis**","4c7fcbd9":"There are more retirees, older and younger singles\/couples.","c3dfa1bc":"# **DATA PROCESSING**","10987653":"# **Load Datasets**","a79e8370":"**Examining transaction data**","a84ce70f":"Analysis of each of the datasets provided.","46296507":"Product Name Cleaning","05bcb879":"# **Market Basket and Affinity Analysis**","21aa8d22":"## Affinity to Size","faf5c9a4":"# **Total Quantity of Chips Purchased Per Customer and Per Unique Customer**","4abd1637":"Budget(Older families), Mainstream(Young singles\/couples), and Mainstream(Retirees) have the highest purchase","801dd2ad":"# Average chip price by customer segment","fceed3d4":"**Quantity sold throughout the year**","51313d3d":"The plot shows that Mainstream Young Singles\/Couples tend to buy more Tyrrells, Twisties, and Doritos, and prefer product sizes of 270g to 380g. The store can perhaps place more of these products near the shelves that tend to attract younger and mainstream customers.","314a6506":"**Quantity sold by product size**","279e466e":"#  Data analysis on customer segments ","3883df60":"We can see that the lift are all close to 1, suggesting that the antecedents of each of the itemsets makes no difference on the chances of purchasing the consequent. ","38241a72":"# Number of chips bought by customer segment","45017af0":"**Customer Data**","8d69e39d":"**Date format standardization**","3d73884e":"## Affinity to Brand","2a29559b":"# **EXPLORATORY ANALYSIS**","224a6d86":"# **Merging Customer Data to Transaction Data**","b9cbf0d1":"Here the focus will be on Mainstream Young Singles\/Couples and the purchases they made throughout the year to understand their affinity to the brands and product sizes of chips."}}