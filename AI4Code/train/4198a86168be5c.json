{"cell_type":{"4c4365e7":"code","d3820ee2":"code","cf5a9c75":"code","5686a95c":"code","f409a146":"code","4f9411eb":"code","4d3595f6":"code","15d8ff90":"code","71477eca":"code","f9a22e75":"code","90a02454":"code","e81a26e9":"code","83f6351a":"code","c575b3a4":"code","89b08731":"code","c8b29590":"code","704d6acb":"code","45dba648":"code","b8d5bbeb":"code","e8d66799":"code","c60c10df":"code","8bdef7c3":"code","6ad2682d":"code","d6b5c674":"markdown","77e901af":"markdown","c6c0ab71":"markdown","bc4d49b3":"markdown","805b1bcd":"markdown","750d4572":"markdown","718335a1":"markdown","66d737b6":"markdown","7bc259d7":"markdown"},"source":{"4c4365e7":"import warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n#\nimport tensorflow as tf\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import BatchNormalization, Activation, Flatten\nfrom tensorflow.keras.optimizers import Adam\n#\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d3820ee2":"# Load CIFAR10 Data\n(X_train_val, y_train_val), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\nprint('train images:', X_train_val.shape) # no.of samples * height * width * channels\nprint('test images:', X_test.shape) # no.of samples * height * width * channels\n\n# convert labels to onehot-encoding \ny_train_val = tf.keras.utils.to_categorical(y_train_val, num_classes = 10)\ny_test = tf.keras.utils.to_categorical(y_test, num_classes = 10)\nprint('train labels:', y_train_val.shape) # no.of samples * num_classes\nprint('test labels:', y_test.shape) # no.of samples * num_classes","cf5a9c75":"import matplotlib.pyplot as plt\nfor i in range(16):\n    # define subplot\n    plt.subplot(4, 4, i+1)\n    # plot raw pixel data\n    plt.imshow(X_train_val[i])\n# show the figure\nplt.show()","5686a95c":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = 0.1)\nX_train.shape, X_val.shape, y_train.shape, y_val.shape","f409a146":"def bn_relu_convolution(x, nb_channels, dropout_rate=None, bottleneck=False, weight_decay=1e-4):\n    \"\"\"\n    Creates a convolution layers consisting of BN-ReLU-Conv.\n    Optional: bottleneck, dropout\n    \n    \"\"\"\n    # Bottleneck\n    if bottleneck:\n        bottleneckWidth = 4\n        x = layers.BatchNormalization()(x)\n        x = layers.Activation('relu')(x)\n        x = layers.Conv2D(nb_channels * bottleneckWidth, (1, 1),\n                          kernel_regularizer=tf.keras.regularizers.l2(weight_decay))(x)\n        # Dropout\n        if dropout_rate:\n            x = layers.Dropout(dropout_rate)(x)\n\n    # BN-ReLU-Conv\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(nb_channels, (3, 3), padding='same')(x)\n\n    # Dropout\n    if dropout_rate:\n        x = layers.Dropout(dropout_rate)(x)\n\n    return x","4f9411eb":"def bn_relu_transition(x, nb_channels, dropout_rate=None, compression=1.0, weight_decay=1e-4):\n    \"\"\"\n    Creates a transition layer between dense blocks as transition, which do convolution and pooling.\n    Works as downsampling.\n    \"\"\"\n\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu',)(x)\n    x = layers.Convolution2D(int(nb_channels * compression), (1, 1), padding='same',\n                             kernel_regularizer=tf.keras.regularizers.l2(weight_decay))(x)\n\n    # Adding dropout\n    if dropout_rate:\n        x = layers.Dropout(dropout_rate)(x)\n\n    x = layers.AveragePooling2D((2, 2), strides=(2, 2))(x)\n    return x","4d3595f6":"def dense_block(x, num_layers, nb_channels, growth_rate, dropout_rate=None, bottleneck=False,\n                    weight_decay=1e-4):\n    \"\"\"\n    Creates a dense block and concatenates inputs\n    \"\"\"\n\n    for i in range(num_layers):\n        cb = bn_relu_convolution(x, growth_rate, dropout_rate, \n                                 bottleneck) # 1 conv if bottleneck = 0 else 2 conv if bottleneck = 1\n        nb_channels += growth_rate\n        x = layers.concatenate([cb, x])\n    return x, nb_channels","15d8ff90":" def DenseNet(input_shape, dense_blocks, dense_layers, growth_rate, compression, bottleneck, \n                     weight_decay, dropout_rate, num_classes, ):\n        \"\"\"\n        Build the model\n        Returns: tf Keras Model instance\n        \"\"\"\n\n        print('Creating DenseNet with Bottleneck = {}'.format(bottleneck))\n        print('#############################################')\n        print('No.of. dense blocks: %s' % dense_blocks)\n        print('Layers per dense block: %s' % dense_layers)\n        print('#############################################')\n\n        # Input Layer\n        img_input = layers.Input(shape=input_shape, name = 'img_input')\n        nb_channels = growth_rate\n\n        # Input-convolution layer\n        x = layers.Conv2D(2 * growth_rate, (3, 3), padding='same', strides=(1, 1),name='input_conv', \n                          kernel_regularizer= tf.keras.regularizers.l2(weight_decay))(img_input)\n\n        # Building dense blocks\n        for block in range(dense_blocks - 1):\n            # Add dense_block\n            x, nb_channels = dense_block(x, dense_layers[block], nb_channels, growth_rate,\n                                     dropout_rate, bottleneck, weight_decay) \n\n            # Add transition\n            x = bn_relu_transition(x, nb_channels, dropout_rate, compression, weight_decay) # 1 conv layer\n            nb_channels = int(nb_channels * compression)\n\n        # Add last dense block without transition but with only global average pooling\n        x, nb_channels = dense_block(x, dense_layers[-1], nb_channels,\n                                          growth_rate, dropout_rate, weight_decay)\n        \n        # prediction of class happens here\n        x = layers.BatchNormalization(name = 'prediction_bn')(x)\n        x = layers.Activation('relu',  name = 'prediction_relu', )(x)\n        x = layers.GlobalAveragePooling2D( name = 'prediction_pool', )(x)\n        prediction = layers.Dense(num_classes, name = 'prediction_dense', activation='softmax')(x)\n\n        return tf.keras.Model(inputs=img_input, outputs=prediction, name='densenet')","71477eca":"dense_net = DenseNet(input_shape = (32,32,3), dense_blocks = 3, dense_layers = [16]*3,\n                     growth_rate = 12, compression = 0.5, num_classes = 10, bottleneck = True, \n                     dropout_rate = None, weight_decay = 1e-5)\n# dense_net.summary()","f9a22e75":"class DenseNet(object):\n    \n    def __init__(self,input_shape=None, dense_blocks=3, dense_layers=-1, growth_rate=12, num_classes=None,\n                 dropout_rate=None, bottleneck=False, compression=1.0, weight_decay=1e-4, depth=40):\n        \n        # Parameters Check\n        if num_classes == None:\n            raise Exception(\n                'Please define number of classes (e.g. num_classes=10). This is required to create .')\n\n        if compression <= 0.0 or compression > 1.0:\n            raise Exception('Compression have to be a value between 0.0 and 1.0.')\n\n        if type(dense_layers) is list:\n            if len(dense_layers) != dense_blocks:\n                raise AssertionError('Number of dense blocks have to be same length to specified layers')\n        elif dense_layers == -1:\n            dense_layers = int((depth - 4) \/ 3)\n            if bottleneck:\n                dense_layers = int(dense_layers \/ 2)\n            dense_layers = [dense_layers for _ in range(dense_blocks)]\n        else:\n            dense_layers = [dense_layers for _ in range(dense_blocks)]\n\n        self.dense_blocks = dense_blocks\n        self.dense_layers = dense_layers\n        self.input_shape = input_shape\n        self.growth_rate = growth_rate\n        self.weight_decay = weight_decay\n        self.dropout_rate = dropout_rate\n        self.bottleneck = bottleneck\n        self.compression = compression\n        self.num_classes = num_classes\n        \n        \n    def build_model(self):\n        \"\"\"\n        Build the model\n        Returns: tf Keras Model instance\n        \"\"\"\n        if self.bottleneck:\n            print('Creating DenseNet with Bottlenecks')\n        else:\n            print('Creating DenseNet without Bottlenecks')\n        print('-' * 50)\n        print('No.of. dense blocks: %s' % self.dense_blocks)\n        print('Layers per dense block: %s' % self.dense_layers)\n        print('-'* 50)\n\n        # Input Layer\n        img_input = layers.Input(shape = self.input_shape, name = 'img_input')\n        nb_channels = self.growth_rate\n\n        # Input-convolution layer\n        x = layers.Conv2D(2 * self.growth_rate, (3, 3), padding='same', strides=(1, 1),name='input_conv', \n                          kernel_regularizer= tf.keras.regularizers.l2(self.weight_decay))(img_input)\n\n        # Building dense blocks\n        for block in range(self.dense_blocks - 1):\n            # Add dense_block\n            x, nb_channels = self.dense_block(x, self.dense_layers[block], nb_channels, self.growth_rate,\n                                      self.dropout_rate, self.bottleneck, self.weight_decay) \n\n            # Add transition\n            x = self.bn_relu_transition(x, nb_channels, self.dropout_rate, \n                                        self.compression, self.weight_decay) # 1 conv layer\n            nb_channels = int(nb_channels * self.compression)\n\n        # Add last dense block without transition but with only global average pooling\n        x, nb_channels = self.dense_block(x, self.dense_layers[-1], nb_channels,\n                                          self.growth_rate, self.dropout_rate, self.weight_decay)\n        \n        # prediction of class happens here\n        x = layers.BatchNormalization(name = 'prediction_bn')(x)\n        x = layers.Activation('relu',  name = 'prediction_relu', )(x)\n        x = layers.GlobalAveragePooling2D( name = 'prediction_pool', )(x)\n        prediction = layers.Dense(self.num_classes, name = 'prediction_dense', activation='softmax')(x)\n\n        return tf.keras.Model(inputs=img_input, outputs=prediction, name='DenseNet')\n        \n        \n    def dense_block(self, x, num_layers, nb_channels, growth_rate, dropout_rate=None, bottleneck=False,\n                    weight_decay=1e-4):\n        \"\"\"\n        Creates a dense block and concatenates inputs\n        \"\"\"\n\n        for i in range(num_layers):\n            cb = self.bn_relu_convolution(x, growth_rate, dropout_rate, \n                                     bottleneck) # 1 conv if bottleneck = 0 else 2 conv if bottleneck = 1\n            nb_channels += growth_rate\n            x = layers.concatenate([cb, x])\n        return x, nb_channels\n\n        \n    def bn_relu_convolution(self, x, nb_channels, dropout_rate=None, bottleneck=False, weight_decay=1e-4):\n        \"\"\"\n        Creates a convolution layers consisting of BN-ReLU-Conv.\n        Optional: bottleneck, dropout\n\n        \"\"\"\n        # Bottleneck\n        if bottleneck:\n            bottleneckWidth = 4\n            x = layers.BatchNormalization()(x)\n            x = layers.Activation('relu')(x)\n            x = layers.Conv2D(nb_channels * bottleneckWidth, (1, 1),\n                              kernel_regularizer=tf.keras.regularizers.l2(weight_decay))(x)\n            # Dropout\n            if dropout_rate:\n                x = layers.Dropout(dropout_rate)(x)\n\n        # BN-ReLU-Conv\n        x = layers.BatchNormalization()(x)\n        x = layers.Activation('relu')(x)\n        x = layers.Conv2D(nb_channels, (3, 3), padding='same')(x)\n\n        # Dropout\n        if dropout_rate:\n            x = layers.Dropout(dropout_rate)(x)\n\n        return x\n\n    def bn_relu_transition(self, x, nb_channels, dropout_rate=None, compression=1.0, weight_decay=1e-4):\n        \"\"\"\n        Creates a transition layer between dense blocks as transition, which do convolution and pooling.\n        Works as downsampling.\n        \"\"\"\n\n        x = layers.BatchNormalization()(x)\n        x = layers.Activation('relu',)(x)\n        x = layers.Convolution2D(int(nb_channels * compression), (1, 1), padding='same',\n                                 kernel_regularizer=tf.keras.regularizers.l2(weight_decay))(x)\n\n        # Adding dropout\n        if dropout_rate:\n            x = layers.Dropout(dropout_rate)(x)\n\n        x = layers.AveragePooling2D((2, 2), strides=(2, 2))(x)\n        return x","90a02454":"dense_net = DenseNet(input_shape = (32,32,3), dense_blocks = 3, dense_layers = [16]*3,\n                     growth_rate = 12, compression = 0.5, num_classes = 10, bottleneck = True, \n                     dropout_rate = None, weight_decay = 1e-6).build_model()\ndense_net.summary()","e81a26e9":"from tensorflow.keras.callbacks import *\n\n# to log results\ncsv_logger = CSVLogger('training_results.csv')\n\n# top 5 acc\ndef top5_acc(y_true, y_pred):\n    return tf.keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=5)\n\n\n# model checkpoint\nfile_path='dense_net_cifar10.h5'\ncheckpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose = 0, \n                             save_best_only=True, save_weights_only=True,\n                             mode='min')\n\n# reduce LR on plateau\nlr_reduced = ReduceLROnPlateau(monitor='val_loss', mode='min', verbose = 0,\n                               factor = 0.2, patience = 10, min_lr = 0.000001)\n\n# determine Loss function and Optimizer\ndense_net.compile(loss='categorical_crossentropy',\n                  optimizer=Adam(),\n                  metrics=['accuracy'],)","83f6351a":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale=1.\/255, shear_range=0.2, zoom_range=0.2, \n                                   horizontal_flip=True, vertical_flip=True)\ntrain_datagen.fit(X_train)\ntrain_data = train_datagen.flow(X_train, y_train, batch_size = 200)","c575b3a4":"val_datagen = ImageDataGenerator(rescale=1.\/255)\nval_datagen.fit(X_val)\nval_data = val_datagen.flow(X_val, y_val, batch_size = 200)","89b08731":"# fits the model on batches with real-time data augmentation:\nres_history = dense_net.fit_generator(train_data, epochs = 100,\n                                      validation_data = (X_val\/255.,y_val),\n                                      callbacks = [checkpoint, lr_reduced, csv_logger])","c8b29590":"import matplotlib.pyplot as plt\ndef draw_metric_plots(res):\n    import pandas as pd\n    df = pd.DataFrame()\n    df['train_loss'] = res.history['loss']\n    df['val_loss'] = res.history['val_loss']\n    df['train_acc'] = res.history['acc']\n    df['val_acc'] = res.history['val_acc']\n    df.index = np.arange(1,len(df)+1,1)\n    \n    # draw Loss\n    df[['train_loss', 'val_loss']].plot()\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.show()\n    \n    # draw Acc\n    df[['train_acc', 'val_acc']].plot()\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.show()\n    \n    return df","704d6acb":"res_df = draw_metric_plots(res_history)","45dba648":"# y_test_probas = dense_net.predict(X_test\/255.)\nscores = dense_net.evaluate(X_test\/255., y_test)\nprint(scores)","b8d5bbeb":"dense_net.fit(X_train_val\/255., y_train_val, epochs = 25)","e8d66799":"# y_test_probas = dense_net.predict(X_test\/255.)\nscores = dense_net.evaluate(X_test\/255., y_test)\nprint(scores)","c60c10df":"# from tensorflow.keras.utils import plot_model\n# plot_model(dense_net, to_file='DenseNet.png')","8bdef7c3":"#","6ad2682d":"#","d6b5c674":"#### transition = BatchNorm layer + activtion + convolution for compression + pooling layer (will used after each dense block)\n![image.png](attachment:image.png)","77e901af":"10 classes in CIFAR10 data: \n- airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck","c6c0ab71":"#### convolution (with bottleneck layer) = BatchNorm layer + activtion + bottleneck conv2D + conv2D with (3,3) filter (will used to produce dense_block).\n![image.png](attachment:image.png)","bc4d49b3":"#### dense_block = concatenated bn_relu_convolution layers.","805b1bcd":"### generalised logic to calculate no.of layers (equal) in network:\n  - This doesn't apply to DenseNet121 and Other DenseNet Architectures used for Imagenet DataSet - they have different no.of layers in dense block.\n  - `dense_layers in each dense_block  = (Total_Depth - (num_dense_blocks + 1))\/num_dense_blocks`\n  - if bottlenecks layers are present then each conv_block in dense_block will have two conv2D layers then\n    `dense_layers in each dense_block (for bottleneck) = (Total_Depth - (num_dense_blocks + 1))\/num_dense_blocks * 2`\n  \n##### for 100 layer network with bottleneck & 3 dense blocks:\n\n- num_layers in each dense_block:\n    `100 - (3+1)\/3*2 = 16`\n\n##### for 101 layer network with bottleneck & 4 dense blocks:\n\n- num_layers in each dense_block:\n     `101 - (4+1)\/8 = 12`","750d4572":"### Results\n\n- Altough the training obtained are comparable to official paper, there is slight overfitting of the model.","718335a1":"### DenseNet Model\n\n![image.png](attachment:image.png)\n\n- (Input + Convolution) layers : Each input image is convoluted to depth of (2*growth_rate) before giveing it to dense_block.\n- transition = (convolution + pooling) after each dense block except for last one where we use (pooling + dense) layers for prediction.","66d737b6":"#### Objective of this Notebook: \n\nReplicate the DenseNet Implentation and reproduce the (near) results obtained by the authors on CIFAR 10 image dataset using keras.\n\n- DenseNet Paper: https:\/\/arxiv.org\/pdf\/1608.06993.pdf\n- CIFAR10 Data : https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html\n\n#### Bullets(from the paper)\n\n- Superficially, DenseNets are quite similar to ResNets: The previous outputs from the convulation layers are concatenated instead of summed. However, the implications of this seemingly small modification lead to substantially different behaviors of the two network architectures.\n\n- Model compactness. As a direct consequence of the input concatenation, the feature-maps learned by any of the DenseNet layers can be accessed by all subsequent layers. This encourages feature reuse throughout the network, and leads to more compact models\n\n\n![image.png](attachment:image.png)","7bc259d7":"### Blocks of DenseNet"}}