{"cell_type":{"ee3bc039":"code","24f2ec6b":"code","ea6c3ed8":"code","8d132dd3":"code","88243e5c":"code","7c26002d":"code","f4b7ac70":"code","387b3de9":"code","7cd2017f":"code","c74456ac":"code","c44cf263":"code","3b85f722":"code","88f706f1":"code","dc4e4718":"code","bf5480c8":"code","85631921":"code","40fd142c":"code","f35256ee":"code","4ba07e91":"code","c6d74dbb":"code","2536f9db":"code","7bfcc128":"code","78b52e73":"code","197f36f8":"code","d87851a4":"code","d7b99518":"code","c2efbc7f":"code","378a0e1b":"markdown","5118659c":"markdown","c6d6c920":"markdown","7d3a736a":"markdown","50e2096c":"markdown","b68eebdf":"markdown","3b15def0":"markdown","79428ba3":"markdown","8e152d24":"markdown","a31b6d72":"markdown"},"source":{"ee3bc039":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n# from keras import layers\n# from tensorflow.keras.utils import np_utils\n\n# from tensorflow.keras.utils \n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models, utils\nfrom tensorflow.keras.datasets import mnist\n\nfrom tensorflow.keras.utils import to_categorical\n\nfrom tqdm import tqdm\n\nimport json\n\nimport os\n\nimport seaborn as sns\n\nprint (tf.__version__)\nprint (tf.keras.__version__)","24f2ec6b":"import os\nos.environ['CUDA_VISIBLE_DEVICES'] = '3' #\u0423\u043a\u0430\u0437\u0430\u0442\u044c \u043d\u043e\u043c\u0435\u0440(\u0430) GPU","ea6c3ed8":"(x_train, y_train), (x_test, y_test) = mnist.load_data()","8d132dd3":"x_train.shape, \\\ny_train.shape,","88243e5c":"x_test.shape, \\\ny_test.shape","7c26002d":"sns.countplot(x=y_train),\nx_train.shape","f4b7ac70":"fig, axes = plt.subplots(5, 5, figsize=(28, 28),\n    subplot_kw={'xticks':[], 'yticks':[]},\n    gridspec_kw=dict(hspace=0.05, wspace=0.05))\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(x_train[i], cmap='binary', interpolation='nearest')\n    ax.text(0.05, 0.05, str(y_train[i]),\n    transform=ax.transAxes, color='green')","387b3de9":"x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])\nx_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])\nx_train = x_train.astype(\"float32\")\nx_test = x_test.astype(\"float32\")\n\nx_train\/= 255\nx_test\/= 255","7cd2017f":"x_train.shape","c74456ac":"nb_classes=10\n\ny_train = to_categorical(y_train, nb_classes)\ny_test = to_categorical(y_test, nb_classes)\nprint(y_train[0])","c44cf263":"W = 28\nH = 28\nnb_classes=10","3b85f722":"X_train = x_train.reshape(-1, W, H, 1)\nX_train.shape","88f706f1":"from tensorflow.keras import optimizers","dc4e4718":"from tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D","bf5480c8":"x_test = x_test.reshape(-1, W, H, 1)","85631921":"input_shape = (W, H, 1)\n\n\nmodel = models.Sequential()\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = input_shape))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","40fd142c":"from tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","f35256ee":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X_train)","4ba07e91":"from tensorflow.keras.utils import plot_model\n#plot_model(model, to_file='model.png', show_shapes=True)","c6d74dbb":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.5, min_lr=0.00001)","2536f9db":"early_stopping = EarlyStopping(monitor='val_loss', patience=8, verbose=1, mode='min')\n#mcp_save = ModelCheckpoint('digit_recognizer.h5', save_best_only=True, monitor='val_loss', verbose=1, mode='auto')","7bfcc128":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","78b52e73":"epochs = 30\nbatch_size = 86","197f36f8":"history=model.fit(datagen.flow(X_train,y_train, batch_size=batch_size),\n                  epochs=epochs,\n#                   verbose=2,\n                  validation_data = (x_test,y_test),\n                  steps_per_epoch=x_train.shape[0] \/\/ batch_size,\n                  callbacks=[early_stopping, learning_rate_reduction]\n                 )","d87851a4":"def plotgraph(epochs, acc, val_acc):\n    plt.plot(epochs, acc, 'b')\n    plt.plot(epochs, val_acc, 'r')\n    plt.title('Model accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Val'], loc='upper left')\n    plt.show()","d7b99518":"accuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(accuracy))","c2efbc7f":"plotgraph(epochs, accuracy, val_accuracy)\nplotgraph(epochs, loss, val_loss)","378a0e1b":"## DataGEN\n","5118659c":"## \u0412\u0438\u0437\u0443\u043b\u0438\u0437\u0430\u0446\u0438\u044f 25 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439","c6d6c920":"## \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438","7d3a736a":"## \u041f\u043e\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0430 \u0437\u0430\u0434\u0430\u0447\u0438\n\u0420\u0435\u0448\u0435\u043d\u0438\u0435 \u0437\u0430\u0434\u0430\u0447\u0438 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 \u0440\u0443\u043a\u043e\u043f\u0438\u0441\u043d\u044b\u0445 \u0446\u0438\u0444\u0440 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e \u0441\u0432\u0435\u0440\u0442\u043e\u0447\u043d\u043e\u0439 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438 (CNN).\n\n**\u0418\u0441\u0445\u043e\u0434\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435:** DataSet MNIST + \u0441\u043e\u0431\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u0439 \u043d\u0430\u0431\u043e\u0440 \u0434\u0430\u043d\u043d\u044b\u0445\n\n\u041d\u0430\u0431\u043e\u0440 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u0442 60 000 \u0447\u0435\u0440\u043d\u043e-\u0431\u0435\u043b\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0440\u0430\u0437\u043c\u0435\u0440\u043e\u043c\n28x28, \u043d\u0430 \u043a\u0430\u0436\u0434\u043e\u043c \u0438\u0437 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0430 \u043e\u0434\u043d\u0430 \u0446\u0438\u0444\u0440\u0430 (\u043e\u0442 0 \u0434\u043e 9).\n\n\u041d\u0430\u0431\u043e\u0440 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0438 \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u0442 10 000 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0430\u043d\u0430\u043b\u043e\u0433\u0438\u0447\u043d\u044b\n\u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u043c \u0438\u0437 \u043d\u0430\u0431\u043e\u0440\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f.","50e2096c":"## \u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438","b68eebdf":"# CNN Handwritten digit analysis 0.99889%","3b15def0":"### \u041d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445","79428ba3":"## \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438","8e152d24":"## \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438 \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043d\u0430 \u0432\u044b\u0431\u043e\u0440\u043a\u0438","a31b6d72":"## \u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f"}}