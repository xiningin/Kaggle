{"cell_type":{"98a257bc":"code","8821e576":"code","b9a79e3a":"code","5d94ba5b":"code","cc189a29":"code","5b21b1cf":"code","6822bf1d":"code","cabff925":"code","1622b409":"code","cc114dfc":"code","2643a867":"code","a50bcac7":"code","e0b25adf":"code","4f9ca275":"code","7e2a7278":"code","b4793a87":"code","904dcb27":"code","286ad7b3":"code","38404c0d":"code","0a4a0a40":"code","318147a0":"code","b72c3f81":"code","3f7fa8d7":"code","eed90f1c":"code","0b02b5e3":"code","39c92076":"code","df92e5d4":"code","9929ef59":"code","8a81aa2d":"code","3b1879cc":"code","d55b514c":"code","38ef5580":"code","48847579":"code","75a80b45":"code","ce834229":"code","71ef9e59":"markdown","13858d31":"markdown"},"source":{"98a257bc":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport tensorflow as tf\nimport random","8821e576":"train_data = pd.read_csv(\"..\/input\/Kannada-MNIST\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/Kannada-MNIST\/test.csv\")\nDig_MNIST = pd.read_csv(\"..\/input\/Kannada-MNIST\/Dig-MNIST.csv\")","b9a79e3a":"train_data.head()","5d94ba5b":"len(train_data)","cc189a29":"test_data.head()","5b21b1cf":"len(test_data)","6822bf1d":"train_data[\"label\"].unique()","cabff925":"total = 0\ncounter_dict = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n\nfor i in train_data[\"label\"]:\n    counter_dict[i]+=1\nprint(counter_dict)","1622b409":"X = train_data.iloc[:, 1:].values\ny = train_data.iloc[:, 0].values","cc114dfc":"X.shape","2643a867":"y.shape","a50bcac7":"X = X.reshape((X.shape[0], 28, 28, 1))\nX.shape","e0b25adf":"y","4f9ca275":"y = tf.keras.utils.to_categorical(y, num_classes=10)\ny.shape","7e2a7278":"y","b4793a87":"from sklearn.model_selection import train_test_split\nX_train, X_valid, Y_train, Y_valid = train_test_split(X, y, test_size = 0.2, random_state=42) ","904dcb27":"def plot_random_digit():\n    random_index = np.random.randint(0, X_train.shape[0])\n    plt.figure(figsize=(2,2))\n    plt.imshow(X_train[random_index], cmap=\"gray\")\n    plt.title(np.argmax(y[random_index]))\n    plt.axis(\"Off\")\n    plt.show()  \nplot_random_digit()","286ad7b3":"plt.figure(figsize=(12, 8), dpi=200)\nfor i in range(50):\n    plt.subplot(5, 10, i+1)\n    index = np.random.randint(0, X_train.shape[0])\n    plt.imshow(X_train[index], cmap=\"gray\")\n    plt.title(np.argmax(y[index]))\n    plt.axis('off')","38404c0d":"learning_rate=0.001\nbatch_size = 32\nepochs = 30\nsteps_per_epoch = 100\nvalidation_steps = 50","0a4a0a40":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.losses import categorical_crossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation,BatchNormalization,Conv2D,Dense,Dropout,Flatten,MaxPooling2D\n\n# Set the seed\ntf.random.set_seed(42)\n\n# Preprocess data (get all of the pixel values between 1 and 0, also called scaling\/normalization)\ntrain_datagen = ImageDataGenerator(rescale=1.\/255)\nvalid_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_data = train_datagen.flow(X_train,Y_train,batch_size=batch_size)\nvalid_data = valid_datagen.flow(X_valid,Y_valid)\n\n# Create a CNN model (same as Tiny VGG - https:\/\/poloclub.github.io\/cnn-explainer\/)\nmodel_1 = tf.keras.models.Sequential([\n    Conv2D(64, 3, padding='same', input_shape=(28, 28, 1)),\n    BatchNormalization(scale=False, center=True),\n    Activation('relu'),\n    Conv2D(64, 3, padding='same'),\n    BatchNormalization(scale=False, center=True),\n    Activation('relu'),\n    MaxPooling2D(2,2),\n    Dropout(0.2),\n\n    Conv2D(128, 3, padding='same'),\n    BatchNormalization(scale=False, center=True),\n    Activation('relu'),\n    Conv2D(128, 3, padding='same'),\n    BatchNormalization(scale=False, center=True),\n    Activation('relu'),\n    MaxPooling2D(2,2),\n    Dropout(0.2),\n    \n    Flatten(),\n    Dense(512),\n    BatchNormalization(scale=False, center=True),\n    Activation('relu'),\n    Dense(128),\n    BatchNormalization(scale=False, center=True),\n    Activation('relu'),\n    Dense(10, activation='softmax')\n])\n\n# Compile the model\nmodel_1.compile(loss=tf.keras.losses.binary_crossentropy,\n                optimizer=tf.keras.optimizers.Adam(),\n                metrics=[\"accuracy\"])\n\n\n# Fit the model\n\nhistory = model_1.fit(\n      train_data,\n      steps_per_epoch=steps_per_epoch,\n      epochs=epochs,\n      validation_data=valid_data,\n      validation_steps=validation_steps)","318147a0":"model_1.summary()","b72c3f81":"# Plot the validation and training data separately\ndef plot_loss_curves(history):\n    \"\"\"\n    Returns separate loss curves for training and validation metrics.\n    \"\"\"\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    accuracy = history.history['accuracy']\n    val_accuracy = history.history['val_accuracy']\n\n    epochs = range(len(history.history['loss']))\n\n    # Plot loss\n    plt.plot(epochs, loss, label='training_loss')\n    plt.plot(epochs, val_loss, label='val_loss')\n    plt.title('Loss')\n    plt.xlabel('Epochs')\n    plt.legend()\n\n    # Plot accuracy\n    plt.figure()\n    plt.plot(epochs, accuracy, label='training_accuracy')\n    plt.plot(epochs, val_accuracy, label='val_accuracy')\n    plt.title('Accuracy')\n    plt.xlabel('Epochs')\n    plt.legend()","3f7fa8d7":"plot_loss_curves(history)","eed90f1c":"total = 0\ncounter_dict = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n\nfor i in Dig_MNIST[\"label\"]:\n    counter_dict[i]+=1\nprint(counter_dict)","0b02b5e3":"# X_extra = extra_data.iloc[:, 1:].values\n# X_extra = X_extra.reshape((X_extra.shape[0],28,28,1))\n# X_extra.shape\nx_dig=Dig_MNIST.drop('label',axis=1).iloc[:,:].values\nx_dig = x_dig.reshape(x_dig.shape[0], 28, 28,1)\nprint(f\"x_dig shape: {x_dig.shape}\")","39c92076":"# y_extra = extra_data.label\n# y_extra.shape\ny_dig=Dig_MNIST.label\nprint(f\"y_dig shape: {y_dig.shape}\")","df92e5d4":"preds_dig = model_1.predict(x_dig\/255)\npreds_dig = preds_dig.argmax(axis=1)","9929ef59":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_dig, preds_dig)\nimport seaborn as sns\nplt.figure(figsize=[7,6])\nsns.heatmap(cm, cmap=\"Reds\", annot=True, fmt='.0f')\nplt.show()","8a81aa2d":"from sklearn.metrics import classification_report\nprint(classification_report(y_dig, preds_dig))","3b1879cc":"sample_submission = pd.read_csv(\"..\/input\/Kannada-MNIST\/sample_submission.csv\")","d55b514c":"x_test=test_data.drop('id', axis=1).iloc[:,:].values\nx_test = x_test.reshape(x_test.shape[0], 28, 28,1)\nprint(f\"x_test shape: {x_test.shape}\")","38ef5580":"predictions = model_1.predict(x_test)\npredictions = predictions.argmax(axis=1)","48847579":"sample_submission[\"label\"] = predictions","75a80b45":"sample_submission.head()","ce834229":"sample_submission.to_csv(\"submission.csv\",index=False)","71ef9e59":"# Check whether data is balanced or not","13858d31":"# Data Exploration"}}