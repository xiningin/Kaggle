{"cell_type":{"d9af8aef":"code","c5ca9edf":"code","6eb0c9e7":"code","af71c456":"code","653ec4b7":"code","3f4a4ff9":"code","efc323ec":"code","2e5344a2":"code","ef3eb56f":"code","1ebd299c":"code","0d3102b1":"code","305c98eb":"code","f2dfcc44":"code","4f8bee0e":"code","cd006ccc":"code","459eb4d7":"code","2be700a6":"code","75550fd5":"code","21bc1388":"code","8ee694d3":"code","d5b6e661":"code","9bf1e52a":"markdown","2b389b0a":"markdown","5dff08f6":"markdown","4e1f4181":"markdown"},"source":{"d9af8aef":"import numpy as np \nimport pandas as pd \n\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","c5ca9edf":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import InputLayer, Dense, BatchNormalization, LeakyReLU, Dropout\nfrom keras.optimizers import Adam\nfrom keras.losses import MeanSquaredError","6eb0c9e7":"df = pd.read_csv(\"..\/input\/train-folds\/train_folds.csv\")\ndf_test = pd.read_csv(\"..\/input\/30-days-of-ml\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/30-days-of-ml\/sample_submission.csv\")\n\ndf1 = pd.read_csv(\"..\/input\/starter-stack\/train_pred_1.csv\")\ndf2 = pd.read_csv(\"..\/input\/starter-stack\/train_pred_2.csv\")\n\ndf_test1 = pd.read_csv(\"..\/input\/starter-stack\/test_pred_1.csv\")\ndf_test2 = pd.read_csv(\"..\/input\/starter-stack\/test_pred_2.csv\")\n\ndf = df.merge(df1, on=\"id\", how=\"left\")\ndf = df.merge(df2, on=\"id\", how=\"left\")\n\ndf_test = df_test.merge(df_test1, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test2, on=\"id\", how=\"left\")\n\ndf.head()","af71c456":"!pip install optuna","653ec4b7":"from sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nimport optuna","3f4a4ff9":"useful_features = [\"pred_1\", \"pred_2\"]\ndf_test = df_test[useful_features]","efc323ec":"# def run(trial):\n#     rmses = []\n#     for fold in range(5):\n#         learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 0.25, log=True)\n#         reg_lambda = trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0)\n#         reg_alpha = trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0)\n#         subsample = trial.suggest_float(\"subsample\", 0.1, 1.0)\n#         colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n#         max_depth = trial.suggest_int(\"max_depth\", 1, 7)\n\n#         xtrain = df[df.kfold != fold].reset_index(drop=True)\n#         xvalid = df[df.kfold == fold].reset_index(drop=True)\n\n#         ytrain = xtrain.target\n#         yvalid = xvalid.target\n\n#         xtrain = xtrain[useful_features]\n#         xvalid = xvalid[useful_features]\n\n#         model = XGBRegressor(\n#             random_state=42,\n#             tree_method=\"gpu_hist\",\n#             gpu_id=1,\n#             predictor=\"gpu_predictor\",\n#             learning_rate=learning_rate,\n#             reg_lambda=reg_lambda,\n#             reg_alpha=reg_alpha,\n#             subsample=subsample,\n#             colsample_bytree=colsample_bytree,\n#             max_depth=max_depth,\n#         )\n#         model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n#         preds_valid = model.predict(xvalid)\n#         rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n#         rmses.append(rmse)\n#     return np.mean(rmses)","2e5344a2":"# study = optuna.create_study(direction=\"minimize\")\n# study.optimize(run, n_trials=400)","ef3eb56f":"# study.best_params","1ebd299c":"from sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor","0d3102b1":"useful_features = [\"pred_1\", \"pred_2\"]\ndf_test = df_test[useful_features]\nfinal_test_predictions = []\nfinal_valid_predictions = {}\n# final_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    params = {\n        'learning_rate': 0.08837982506397186,\n        'reg_lambda': 1.5986606673969327e-06,\n        'reg_alpha': 4.844826299110059e-08,\n        'subsample': 0.4493238068204164,\n        'colsample_bytree': 0.9987937142187765,\n        'max_depth': 2,\n        'random_state':fold,\n        'num_parallel_tree':200,\n        'tree_method':'gpu_hist',\n        'gpu_id':0,\n        'predictor':'gpu_predictor'\n    }\n    \n    model = XGBRegressor(**params)\n    model.fit(xtrain, ytrain)\n    \n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_3\"]\nfinal_valid_predictions.to_csv(\"train_pred_3.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = [\"id\", \"pred_3\"]\nsample_submission.to_csv(\"test_pred_3.csv\", index=False)","305c98eb":"df = pd.read_csv(\"..\/input\/train-folds\/train_folds.csv\")\ndf_test = pd.read_csv(\"..\/input\/30-days-of-ml\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/30-days-of-ml\/sample_submission.csv\")\n\ndf1 = pd.read_csv(\"..\/input\/starter-stack\/train_pred_1.csv\")\ndf2 = pd.read_csv(\"..\/input\/starter-stack\/train_pred_2.csv\")\ndf3 = pd.read_csv(\"train_pred_3.csv\")\n\ndf_test1 = pd.read_csv(\"..\/input\/starter-stack\/test_pred_1.csv\")\ndf_test2 = pd.read_csv(\"..\/input\/starter-stack\/test_pred_2.csv\")\ndf_test3 = pd.read_csv(\"test_pred_3.csv\")\n\ndf = df.merge(df1, on=\"id\", how=\"left\")\ndf = df.merge(df2, on=\"id\", how=\"left\")\ndf = df.merge(df3, on=\"id\", how=\"left\")\n\ndf_test = df_test.merge(df_test1, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test2, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test3, on=\"id\", how=\"left\")\n\ndf.head()","f2dfcc44":"useful_features = [\"pred_1\", \"pred_2\",\"pred_3\"]\ndf_test = df_test[useful_features]\n\n# study = optuna.create_study(direction=\"minimize\")\n# study.optimize(run, n_trials=400)","4f8bee0e":"# study.best_params","cd006ccc":"useful_features = [\"pred_1\", \"pred_2\",\"pred_3\"]\ndf_test = df_test[useful_features]\nfinal_test_predictions = []\nfinal_valid_predictions = {}\n# final_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    model = Ridge(alpha=4)\n    model.fit(xtrain, ytrain)\n    \n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n\n\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_4\"]\nfinal_valid_predictions.to_csv(\"train_pred_4.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = [\"id\", \"pred_4\"]\nsample_submission.to_csv(\"test_pred_4.csv\", index=False)","459eb4d7":"df = pd.read_csv(\"..\/input\/train-folds\/train_folds.csv\")\ndf_test = pd.read_csv(\"..\/input\/30-days-of-ml\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/30-days-of-ml\/sample_submission.csv\")\n\ndf1 = pd.read_csv(\"..\/input\/starter-stack\/train_pred_1.csv\")\ndf2 = pd.read_csv(\"..\/input\/starter-stack\/train_pred_2.csv\")\ndf3 = pd.read_csv(\"train_pred_3.csv\")\ndf4 = pd.read_csv(\"train_pred_4.csv\")\n\ndf_test1 = pd.read_csv(\"..\/input\/starter-stack\/test_pred_1.csv\")\ndf_test2 = pd.read_csv(\"..\/input\/starter-stack\/test_pred_2.csv\")\ndf_test3 = pd.read_csv(\"test_pred_3.csv\")\ndf_test4 = pd.read_csv(\"test_pred_4.csv\")\n\ndf = df.merge(df1, on=\"id\", how=\"left\")\ndf = df.merge(df2, on=\"id\", how=\"left\")\ndf = df.merge(df3, on=\"id\", how=\"left\")\ndf = df.merge(df4, on=\"id\", how=\"left\")\n\ndf_test = df_test.merge(df_test1, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test2, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test3, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test4, on=\"id\", how=\"left\")\n\ndf.head()","2be700a6":"useful_features = ['pred_1','pred_2','pred_3','pred_4']\ndf_test = df_test[useful_features]\nfinal_test_predictions = []\nfinal_valid_predictions = {}\n# final_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    model = Ridge(0.0001)\n    model.fit(xtrain, ytrain)\n    \n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n\n\n    final_test_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))\n\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_5\"]\nfinal_valid_predictions.to_csv(\"train_pred_5.csv\", index=False)\n\nsample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.columns = [\"id\", \"pred_5\"]\nsample_submission.to_csv(\"test_pred_5.csv\", index=False)","75550fd5":"df = pd.read_csv(\"..\/input\/train-folds\/train_folds.csv\")\ndf_test = pd.read_csv(\"..\/input\/30-days-of-ml\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/30-days-of-ml\/sample_submission.csv\")\n\ndf1 = pd.read_csv(\"..\/input\/starter-stack\/train_pred_1.csv\")\ndf2 = pd.read_csv(\"..\/input\/starter-stack\/train_pred_2.csv\")\ndf3 = pd.read_csv(\"train_pred_3.csv\")\ndf4 = pd.read_csv(\"train_pred_4.csv\")\ndf5 = pd.read_csv(\"train_pred_5.csv\")\n\ndf_test1 = pd.read_csv(\"..\/input\/starter-stack\/test_pred_1.csv\")\ndf_test2 = pd.read_csv(\"..\/input\/starter-stack\/test_pred_2.csv\")\ndf_test3 = pd.read_csv(\"test_pred_3.csv\")\ndf_test4 = pd.read_csv(\"test_pred_4.csv\")\ndf_test5 = pd.read_csv(\"test_pred_5.csv\")\n\ndf = df.merge(df1, on=\"id\", how=\"left\")\ndf = df.merge(df2, on=\"id\", how=\"left\")\ndf = df.merge(df3, on=\"id\", how=\"left\")\ndf = df.merge(df4, on=\"id\", how=\"left\")\ndf = df.merge(df5, on=\"id\", how=\"left\")\n\ndf_test = df_test.merge(df_test1, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test2, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test3, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test4, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test5, on=\"id\", how=\"left\")\n\ndf_test.head()","21bc1388":"useful_features = [\"pred_1\", \"pred_2\",\"pred_3\",\"pred_4\",\"pred_5\"]\ndf_test = df_test[useful_features]\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    model = Ridge(0.0001)\n    model.fit(xtrain, ytrain)\n    \n    model.fit(xtrain, ytrain)\n    \n    \n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n\n\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n","8ee694d3":"sample_submission = pd.read_csv(\"..\/input\/30-days-of-ml\/sample_submission.csv\")\nsample_submission.head()","d5b6e661":"sample_submission.target = np.mean(np.column_stack(final_predictions), axis=1)\nsample_submission.to_csv(\"sub14.csv\", index=False)","9bf1e52a":"# Stack 4","2b389b0a":"# Stack 3","5dff08f6":"# Stack 2","4e1f4181":"# Stack 1"}}