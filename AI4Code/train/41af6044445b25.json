{"cell_type":{"b1bb427c":"code","bbf3aac3":"code","1283c298":"code","10b2ff9f":"code","d5012a20":"code","41a300f3":"code","985c0572":"code","79aba633":"code","fd76b420":"code","8f38875c":"code","08e17698":"code","f2cad1ce":"code","e43d4482":"code","79bf6146":"code","bdf7a54c":"code","e6dad8b2":"code","82bc3cf4":"code","3c602f55":"code","75878741":"code","c048dfa6":"code","c75a94ba":"code","17287748":"code","a5b06cee":"code","89bcfbbe":"markdown","9b4dbbfa":"markdown","a3f48878":"markdown","079be2e1":"markdown","9c7e6916":"markdown","461f1e6e":"markdown","a3c90976":"markdown","3b26c0d4":"markdown","ac570e30":"markdown","2d29bdac":"markdown","d8f80fd2":"markdown","087ee031":"markdown"},"source":{"b1bb427c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bbf3aac3":"# this function (replaces .info()) creates a dataframe with all info needed on a dataframe\ndef carac_df(df):\n    df_carac = pd.DataFrame(columns=['nom_col','cardinality','type', 'nbval'])\n    for col in df:\n        df_carac = df_carac.append(dict(zip(df_carac.columns,\n            [col,\n            len(pd.Index(df[col]).value_counts()),\n            df[col].dtypes,\n            df[col].notnull().sum()])\n            ),\n            ignore_index=True)\n    \n    nb_col = len(df.columns)\n    \n    pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n    return df_carac, nb_col\n\n# this is the function to use for printing it :\ndef print_carac_df(df):\n    df_carac, nb = carac_df(df)\n    print(\"nb of cols : \" + str(nb))\n    print(df_carac)\n    \n# this function to filter empty data :\ndef print_carac_df_empty(df):\n    df_carac, nb = carac_df(df)\n    df2 = df_carac[df_carac[\"nbval\"]<max(df_carac[\"nbval\"])]\n    nb = len(df2)\n    print(\"nb of cols : \" + str(nb))\n    print(df2)","1283c298":"df_train = pd.read_csv(\"\/kaggle\/input\/home-data-for-ml-course\/train.csv\")\ndf_train.head(3)","10b2ff9f":"df_test = pd.read_csv(\"\/kaggle\/input\/home-data-for-ml-course\/test.csv\")\ndf_test.head(3)","d5012a20":"# we can see here the columns that still have missing values in it. \nprint_carac_df_empty(df_train)","41a300f3":"# this function allow us to make all changes needed for qualitative and quantitative data.\n# for example, Age is a quantitative data that we change to qualitative, by giving labels\n# all quantitative data will be dropped at the end \ndef traitement(df):\n    # \"Cardinality\" means the number of unique values in a column\n    # Select categorical columns with relatively low cardinality \n    # (convenient but arbitrary)\n    low_cardinality_cols = [cname for cname in df.columns if df[cname].nunique() < 10 and \n                            df[cname].dtype == \"object\"]\n\n    # Select numeric columns\n    numeric_cols = [cname for cname in df.columns if df[cname].dtype in ['int64', 'float64']]\n\n    # Keep selected columns only\n    my_cols = low_cardinality_cols + numeric_cols\n    \n    df2 = df[my_cols]\n    df2.LotFrontage = df2.LotFrontage.fillna(df.LotFrontage.mean())\n    df2.GarageYrBlt = df2.GarageYrBlt.fillna(df.GarageYrBlt.mean())\n    df2 = df2.fillna(0)\n    \n    df_transf = pd.get_dummies(df2)\n    list_cols = list(df_transf.columns)\n    return df2, df_transf, list_cols\n    ","985c0572":"# here we use the previous functions to create the dataframes that can be used in \n# our models. the \"traitement\" function is used twice, for train and test dataframes\ndf2, df_transf, list_cols = traitement(df_train)\ndf_test2, df_test_transf, list_cols_test = traitement(df_test)","79aba633":"# the dataframe that we obtain here only contains the columns we need before \n# the transformation that gives us more columns from the qualitative features \n# (by using get_dummies)\ndf2.head()","fd76b420":"# here we can see the dataframe transformed. There's no more empty data, \n# and many new columns has been created from the previous qualitative features\nprint_carac_df_empty(df_transf)","8f38875c":"df_test_transf[\"GarageCars\"].value_counts(dropna=False)","08e17698":"# let's see here how many columns we get for the train and the test dataframes\n\nprint(len(list_cols))\nprint(list_cols)\nprint(len(list_cols_test))\nprint(list_cols_test)","f2cad1ce":"# so now, let's take only the columns that we have in both train and test dataframes,\n# and also concatenate that with the \"SalePrice\" column, so that we can use it\n# for the modelisation\ndf_transf2 = pd.concat([df_transf[[\"SalePrice\"]],df_transf[[x for x in list_cols_test if x in list_cols ]]],axis=1)\nprint(len(df_transf2.columns))\nprint(df_transf2.columns)\n","e43d4482":"# import all packages needed for modeling\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nimport warnings\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.linear_model import Lasso\nimport time","79bf6146":"# now let's split the data to have : data, target, X_train, X_test, y_train, y_test\ndata = df_transf2.drop(\"SalePrice\", axis=1)\ntarget = df_transf2.SalePrice\nX_train, X_test, y_train, y_test = train_test_split(data, target, test_size = 0.2,random_state=123)","bdf7a54c":"# RMSE is the mesure used for the leaderboard, so let's use it too\ndef rmse(y, y_pred):\n    return np.sqrt(mean_squared_error(np.log(y), np.log(y_pred)))","e6dad8b2":"# First, let's use simple models and try to improve the score\n# by adding some parameters\nstart = time.time()\n\nprint(\"1st try : DecisionTreeRegressor :\") \n# specify and fit model\nmodel_dtr = DecisionTreeRegressor(random_state=1)\nmodel_dtr.fit(X_train, y_train)\n# Make validation predictions and calculate mean absolute error\ny_pred = model_dtr.predict(X_test)\nval_mae = mean_absolute_error(y_pred, y_test)\nrmse_ = rmse(y_test, y_pred)\nprint(\"Validation MAE : {:,.0f}\".format(val_mae)+\"; rmse : \"+str(rmse_))\n\nprint(\"2nd try : DecisionTreeRegressor with 1 parameter :\") \n# specify and fit model\nmodel_dtr2 = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)\nmodel_dtr2.fit(X_train, y_train)\n# Make validation predictions and calculate mean absolute error\ny_pred = model_dtr2.predict(X_test)\nval_mae = mean_absolute_error(y_pred, y_test)\nrmse_ = rmse(y_test, y_pred)\nprint(\"Validation MAE : {:,.0f}\".format(val_mae)+\"; rmse : \"+str(rmse_))\n\n\nprint(\"3rd try : RandomForestRegressor :\")  \n# specify and fit model\nmodel_rfr = RandomForestRegressor(random_state=1)\nmodel_rfr.fit(X_train, y_train)\n# Make validation predictions and calculate mean absolute error\ny_pred = model_rfr.predict(X_test)\nval_mae = mean_absolute_error(y_pred, y_test)\nrmse_ = rmse(y_test, y_pred)\nprint(\"Validation MAE : {:,.0f}\".format(val_mae)+\"; rmse : \"+str(rmse_))\n\n\nprint(\"4th try : XGBRegressor :\") \n# specify and fit model\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    model_xgb =  XGBRegressor(random_state=0)\n    model_xgb.fit(X_train, y_train)\n# Make validation predictions and calculate mean absolute error\n    y_pred = model_xgb.predict(X_test)\n    val_mae = mean_absolute_error(y_pred, y_test)\n    rmse_ = rmse(y_test, y_pred)\n    print(\"Validation MAE : {:,.0f}\".format(val_mae)+\"; rmse : \"+str(rmse_))\n\n\nprint(\"5th try : XGBRegressor with 2 parameters :\") \n# specify and fit model\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    model_xgb2 =  XGBRegressor(n_estimators=1000, learning_rate=0.05)\n    model_xgb2.fit(X_train, y_train)\n# Make validation predictions and calculate mean absolute error\n    y_pred = model_xgb2.predict(X_test)\n    val_mae = mean_absolute_error(y_pred, y_test)\n    rmse_ = rmse(y_test, y_pred)\n    print(\"Validation MAE : {:,.0f}\".format(val_mae)+\"; rmse : \"+str(rmse_))\n\n\nend = time.time()\ndelai = (end - start)\/60 \nprint(\"dur\u00e9e execution : \" + str(round(delai,2))+\" mn\")\n    \n    ","82bc3cf4":"start = time.time()\n# Grid Search on RandomForest\nprint(\"Grid Search on RandomForest :\")\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    #outer_cv = StratifiedKFold(n_splits=3, shuffle=True)\n    rfr  = RandomForestRegressor(random_state=1)\n    params_rfr  = {'bootstrap': [True]\n                   ,'max_depth': [50]\n                   ,'max_features': [100]\n                   ,'min_samples_leaf': [2]\n                   ,'min_samples_split': [5]\n                   ,'n_estimators': [100]\n                  }\n    gridcv = GridSearchCV(rfr,\n                           param_grid=params_rfr,\n                           scoring='accuracy',\n                           cv=3)\n    \n    gridcv.fit(X_train, y_train)\n\n\n\n    rfr = RandomForestRegressor(random_state=1\n                                ,bootstrap=gridcv.best_params_[\"bootstrap\"]\n                                ,max_depth=gridcv.best_params_[\"max_depth\"]\n                                ,max_features=gridcv.best_params_[\"max_features\"]\n                                ,min_samples_leaf=gridcv.best_params_[\"min_samples_leaf\"]\n                                ,min_samples_split=gridcv.best_params_[\"min_samples_split\"]\n                                ,n_estimators=gridcv.best_params_[\"n_estimators\"]\n    \n                                \n    )\n    rfr.fit(X_train, y_train)\n    print(\"best params :\" )\n    print(gridcv.best_params_)\n    \n    # Make validation predictions and calculate mean absolute error\n    y_pred = rfr.predict(X_test)\n    val_mae = mean_absolute_error(y_pred, y_test)\n    rmse_ = rmse(y_test, y_pred)\n    print(\"Validation MAE : {:,.0f}\".format(val_mae)+\"; rmse : \"+str(rmse_))\n\nend = time.time()\ndelai = (end - start)\/60 \nprint(\"dur\u00e9e execution : \" + str(round(delai,2))+\" mn\")\n","3c602f55":"# Grid Search on Linear Regression with the Lasso Model\nstart = time.time()\n\nprint(\"Grid Search on Linear Regression with the Lasso Model :\")\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    \n    outer_cv = StratifiedKFold(n_splits=10, shuffle=True)\n    lasso  = Lasso()\n    params_lasso  = {'alpha': [0.15]\n                    }\n    gridcv = GridSearchCV(lasso,\n                           param_grid=params_lasso,\n                           scoring='accuracy',\n                           cv=3)\n    \n    gridcv.fit(X_train, y_train)\n\n\n\n    lasso = Lasso(\n    alpha=gridcv.best_params_[\"alpha\"]\n    )\n    lasso.fit(X_train, y_train)\n    print(gridcv.best_params_)\n\n# Make validation predictions and calculate mean absolute error\n    y_pred = lasso.predict(X_test)\n    val_mae = mean_absolute_error(y_pred, y_test)\n    rmse_ = rmse(y_test, y_pred)\n    print(\"Validation MAE : {:,.0f}\".format(val_mae)+\"; rmse : \"+str(rmse_))\n\nend = time.time()\ndelai = (end - start)\/60 \nprint(\"dur\u00e9e execution : \" + str(round(delai,2))+\" mn\")\n","75878741":"# Now, let's use GridSearch to find the best parameters for XGB\n\nstart = time.time()\n\nprint(\"XGB with Grid Search to find the best parameters :\")\n#Grid Search XGB\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    outer_cv = StratifiedKFold(n_splits=3, shuffle=True)\n    xgb  = XGBRegressor(use_label_encoder=False, verbosity=0)\n    params_xgb  = {'max_depth': [3],\n                  # 'objective':['reg:linear'],\n                   #'min_child_weight': [.0005],\n                   'n_estimators': [2000],\n                   'learning_rate' : [0.02],\n                   'subsample': [.8],\n                   'colsample_bytree': [.5],\n                  }\n    gridcv = GridSearchCV(xgb,\n                           param_grid=params_xgb,\n                           scoring='accuracy',\n                           cv=3)\n    \n    gridcv.fit(X_train, y_train)\n\n\n\n    gbm = XGBRegressor(verbosity=0,\n    use_label_encoder=False,\n    max_depth=gridcv.best_params_[\"max_depth\"],\n   # objective=gridcv.best_params_['objective'],\n    #min_child_weight= gridcv.best_params_['min_child_weight'],\n    n_estimators=gridcv.best_params_[\"n_estimators\"],\n    learning_rate=gridcv.best_params_[\"learning_rate\"],\n    subsample=gridcv.best_params_[\"subsample\"],\n    colsample_bytree=gridcv.best_params_[\"colsample_bytree\"]\n    )\n    gbm.fit(X_train, y_train)\n    print(\"best params :\" )\n    print(gridcv.best_params_)\n    \n    # Make validation predictions and calculate mean absolute error\n    y_pred = gbm.predict(X_test)\n    val_mae = mean_absolute_error(y_pred, y_test)\n    rmse_ = rmse(y_test, y_pred)\n    print(\"Validation MAE : {:,.0f}\".format(val_mae)+\"; rmse : \"+str(rmse_))\n\nend = time.time()\ndelai = (end - start)\/60 \nprint(\"dur\u00e9e execution : \" + str(round(delai,2))+\" mn\")\n","c048dfa6":"# now that we see the performances , we can try using the model that we consider best\n# let's try using : GBM\ndf_test_transf2 = df_test_transf[[x for x in list_cols_test if x in list_cols]]\ny_pred = gbm.predict(df_test_transf2)","c75a94ba":"# this is how the output has to be :\ndf_sample = pd.read_csv(\"\/kaggle\/input\/home-data-for-ml-course\/sample_submission.csv\")\ndf_sample.head(5)","17287748":"# Save test predictions to a dataframe\noutput = pd.DataFrame({'Id': df_test_transf2.Id,\n                       'SalePrice': y_pred})\noutput.head(5)","a5b06cee":"# Save test predictions to file\noutput.to_csv('submission.csv', index=False)","89bcfbbe":"## Choosing Model","9b4dbbfa":"# 1. Exploratory Data Analysis (EDA)","a3f48878":"Here is my best score on leaderboard (top 3% : 2618\/70221). I'll try to improve it further more. Thank you for your support.\n![image.png](attachment:12a5f7a9-6e20-4293-a3a6-62ed78eea2e7.png)","079be2e1":"Let's try to gridsearch with the Lasso linear regression model. ","9c7e6916":"The score with lasso regression wasn't enough.\nNow, let's see if we can improve our best score with XGB (0.1180).","461f1e6e":"# Overview\n\n1. Explatory Data Analysis (EDA)\n2. Feature Engineering\n3. Modeling\n4. Prediction\n","a3c90976":"# 3. Modeling","3b26c0d4":"With Grid Search, the XGB Model improves the score, we have 0.1028 rmse.","ac570e30":"# 2. Feature engineering","2d29bdac":"Here we can see that XGBRegressor has the best score with a RMSE of 0.1156. RandomForestRegressor also has a good score without parameters, maybe we can have better results by tuning hyperparameters for both of them.","d8f80fd2":"# 4. Prediction","087ee031":"Difficult to improve score with grid search in RandomForest. Previous score : 0.1323, New score : 0.1273."}}