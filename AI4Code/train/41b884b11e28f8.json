{"cell_type":{"16e6cfc2":"code","1a8fb196":"code","6218cbcd":"code","33d6f73e":"code","a53c7d80":"code","d2564ad6":"code","8bd6cb29":"code","816c57bc":"code","6938d40a":"code","207d6a4a":"code","da5e3010":"code","fb21702a":"code","8b731311":"code","0f9b88cf":"code","48ea277c":"code","4a4a142c":"code","c4cb7fc4":"code","2df1e0cd":"code","b9f3313f":"code","0c4979ec":"code","2d40feb4":"code","823bf1da":"code","54a54935":"code","2b0a5ceb":"code","21c2fa39":"code","9d5895e9":"code","de371257":"code","63488232":"code","96f4d78c":"code","c3c64bfe":"code","9e6795ce":"code","638ccb59":"code","58623ec6":"code","a54f6b6d":"markdown","0fd0affb":"markdown","6320a6cb":"markdown","87673554":"markdown","bd720a00":"markdown","2b30c14e":"markdown","f786223a":"markdown","955be1f7":"markdown","ba5752ce":"markdown","194d1c92":"markdown","da10e94a":"markdown","fb7c5514":"markdown","24c6c964":"markdown","fb987f3c":"markdown","f4c3d983":"markdown","f1efa6ee":"markdown","9499c403":"markdown","21296a66":"markdown","40c059a1":"markdown","d199b14f":"markdown"},"source":{"16e6cfc2":"import matplotlib.pyplot as plt \nimport numpy as np \nimport seaborn as sns\nimport pandas as pd\nfrom tabulate import tabulate\nplt.style.use('dark_background')","1a8fb196":"pip install category_encoders","6218cbcd":"dataset = pd.read_csv(\"..\/input\/cardiogoodfitness\/CardioGoodFitness.csv\")","33d6f73e":"dataset.head(10)","a53c7d80":"dataset.tail(10)","d2564ad6":"plt.figure(figsize=(8,8))  # on this line I just set the size of figure to 12 by 10.\np=sns.heatmap(dataset.corr(), annot=True)  # seaborn has very simple solution for heatmap","8bd6cb29":"dataset.shape","816c57bc":"dataset.info()","6938d40a":"dataset.describe()","207d6a4a":"p = dataset.hist(figsize = (10,10))","da5e3010":"dataset[['Income', 'Product']].groupby(['Product'], as_index=False).median().sort_values(by='Product', ascending=False)","fb21702a":"dataset[['Usage', 'Product']].groupby(['Product'], as_index=False).median().sort_values(by='Product', ascending=False)","8b731311":"dataset[['Miles', 'Product']].groupby(['Product'], as_index=False).median().sort_values(by='Product', ascending=False)","0f9b88cf":"dataset[['Fitness', 'Product']].groupby(['Product'], as_index=False).mean().sort_values(by='Product', ascending=False)","48ea277c":"z = dataset[['Age', 'Product']].groupby(['Product'], as_index=False).median().sort_values(by='Product', ascending=False)\nprint(z)\ng = sns.FacetGrid(dataset, col='Product')\ng.map(plt.hist, 'Age', bins=20)","4a4a142c":"z = dataset[['Education', 'Product']].groupby(['Product'], as_index=False).mean().sort_values(by='Product', ascending=False).round()\nprint(z)\ng = sns.FacetGrid(dataset, col='Product')\ng.map(plt.hist, 'Education', bins=20)\n#People with less education year were more interested in the lower model","c4cb7fc4":"g = sns.FacetGrid(dataset, col='Product')\ng.map(plt.hist, 'Gender', bins=20)\n#TM195 and TM498 preferred by both men and women while TM798 preferred more by men also with people who had greater income\n#sns.countplot(x='Product', hue = 'Gender', data = dataset)","2df1e0cd":"groups = dataset[['Gender','MaritalStatus','Product']].groupby(['Gender','MaritalStatus',]).count().sort_values(\"Product\",ascending=False )\n#Married males are more interested in buying than single people\n#and males in general are more interested in buying treadmills than females\nprint(groups)\ngroups.plot.bar(color=\"white\")\nplt.show()","b9f3313f":"dataset[['Gender','Income',]].groupby(['Gender',]).median().sort_values(\"Income\",ascending=False )","0c4979ec":"dataset = dataset.drop(\"Education\" , axis = 1)","2d40feb4":"import category_encoders as ce\n\nencoder = ce.OrdinalEncoder(cols=['Product' , 'Gender' , 'MaritalStatus'], return_df=True , verbose = None)\n\n# Assume our loan data has been imported as df already\n# and split into df_train and df_test\ndataset = encoder.fit_transform(dataset)","823bf1da":"dataset.head(10)","54a54935":"X = dataset.drop(\"Product\" , axis=1)\ny = dataset[\"Product\"]","2b0a5ceb":"#Import Libraries\nfrom sklearn.preprocessing import StandardScaler\n#----------------------------------------------------\n#Standard Scaler for Data\nscaler = StandardScaler(copy=True, with_mean=True, with_std=True)\nX = scaler.fit_transform(X)","21c2fa39":"from sklearn.model_selection import train_test_split\nX_train ,X_test , y_train , y_test = train_test_split(X,y , test_size = 0.1 , random_state = 42)","9d5895e9":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(solver = \"newton-cg\" , max_iter = 100 , C = 8)\nclassifier.fit(X_train, y_train)\nprint(\"logistic regression training score is \" + str(classifier.score(X_train , y_train)))\nprint(\"logistic regression test score is \" + str(classifier.score(X_test , y_test)))\nprint('----------------------------------------------------')\n# Making the Confusion Matrix\n\nfrom sklearn.metrics import confusion_matrix\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(5,5))\np=sns.heatmap(cm, annot=True)\n\n\nLogisticregressionscoretraining = classifier.score(X_train , y_train)\nLogisticregressionscoretest = classifier.score(X_test , y_test)","de371257":"#Import Libraries\nfrom sklearn.neural_network import MLPClassifier\n#----------------------------------------------------\n#Applying MLPClassifier Model \nMLPClassifierModel = MLPClassifier(activation='tanh',\n                                   solver='lbfgs',  \n                                   learning_rate='constant',\n                                   early_stopping= False,\n                                   alpha=0.03,hidden_layer_sizes=(256,128) , max_iter=10000)\nMLPClassifierModel.fit(X_train, y_train)\n#Calculating Details\nprint('MLPClassifierModel Train Score is : ' , MLPClassifierModel.score(X_train, y_train))\nprint('MLPClassifierModel Test Score is : ' , MLPClassifierModel.score(X_test, y_test))\nMLPClassifierModelTrainScore =  MLPClassifierModel.score(X_train, y_train)\nMLPClassifierModelTestScore = MLPClassifierModel.score(X_test, y_test)","63488232":"#Import Libraries\nfrom sklearn.svm import SVC\nSVCModel = SVC(kernel= 'linear')\nSVCModel.fit(X_train, y_train)\n#Calculating Details\nprint('SVCModel Train Score is : ' , SVCModel.score(X_train, y_train))\nprint('SVCModel Test Score is : ' , SVCModel.score(X_test, y_test))\nprint('----------------------------------------------------')\naccuracy = SVCModel.score(X_test, y_test)\n\n\ny_pred = SVCModel.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(5,5))\np=sns.heatmap(cm, annot=True)\n\nSVCModelscoretraining = SVCModel.score(X_train, y_train)\nSVCModelscoretest = SVCModel.score(X_test, y_test)","96f4d78c":"#Import Libraries\nfrom sklearn.naive_bayes import GaussianNB\nGaussianNBModel = GaussianNB()\nGaussianNBModel.fit(X_train, y_train)\nprint('GaussianNBModel Train Score is : ' , GaussianNBModel.score(X_train, y_train))\nprint('GaussianNBModel Test Score is : ' , GaussianNBModel.score(X_test, y_test))\nprint('----------------------------------------------------')\nGaussianNBModelscoretrain = GaussianNBModel.score(X_train, y_train)\nGaussianNBModelscoretest = GaussianNBModel.score(X_test, y_test)","c3c64bfe":"#Import Libraries\nfrom sklearn.neighbors import KNeighborsClassifier\nKNeighborsClassifierModel = KNeighborsClassifier(n_neighbors = 1, weights='distance',\n                                               algorithm = 'auto')    \nKNeighborsClassifierModel.fit(X_train, y_train)\nprint('KNeighborsclassifierModel Train Score is : ' , KNeighborsClassifierModel.score(X_train, y_train))\nprint('KNeighborsclassifierModel Test Score is : ' , KNeighborsClassifierModel.score(X_test, y_test))\nprint('----------------------------------------------------')\nKNeighborsClassifierModelscoretraining = KNeighborsClassifierModel.score(X_train, y_train)\nKNeighborsClassifierModelscoretest = KNeighborsClassifierModel.score(X_test, y_test)","9e6795ce":"#Import Libraries\nfrom sklearn.ensemble import RandomForestClassifier\n#----------------------------------------------------\n\n#Applying RandomForestClassifier Model \nRandomForestClassifierModel = RandomForestClassifier(criterion = 'gini',n_estimators=100,max_depth=2,random_state=33) #criterion can be also : entropy \nRandomForestClassifierModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('RandomForestClassifierModel Train Score is : ' , RandomForestClassifierModel.score(X_train, y_train))\nprint('RandomForestClassifierModel Test Score is : ' , RandomForestClassifierModel.score(X_test, y_test))\nprint('----------------------------------------------------')\nRandomForestClassifierModeltrain =  RandomForestClassifierModel.score(X_train, y_train)\nRandomForestClassifierModeltest = RandomForestClassifierModel.score(X_test, y_test)","638ccb59":"#Import Libraries\nfrom sklearn.ensemble import GradientBoostingClassifier\n#----------------------------------------------------\n\n#Applying GradientBoostingClassifier Model \n\nGBCModel = GradientBoostingClassifier(n_estimators=100,max_depth=3,random_state=33) \nGBCModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('GBCModel Train Score is : ' , GBCModel.score(X_train, y_train))\nprint('GBCModel Test Score is : ' , GBCModel.score(X_test, y_test))\nGBCModeltraining = GBCModel.score(X_train, y_train)\nGBCModeltesting =GBCModel.score(X_test, y_test)\n\n","58623ec6":"models = pd.DataFrame({\n                          'Model': ['logistic regression ',\n                                    'KNN', \n                                    'Naive Bayes', \n                                    'Linear SVC', \n                                    'Neural networks',\n                                    \"Random forest\",\n                                    \"Gradient boosting\"],\n                       \n                          'Scoretrain': [Logisticregressionscoretraining, \n                                         KNeighborsClassifierModelscoretraining, \n                                         GaussianNBModelscoretrain, \n                                         SVCModelscoretraining, \n                                         MLPClassifierModelTrainScore,\n                                         RandomForestClassifierModeltrain,\n                                         GBCModeltraining],\n                       \n                             'scoretest':[Logisticregressionscoretest,\n                                          KNeighborsClassifierModelscoretest,\n                                         GaussianNBModelscoretest,\n                                          SVCModelscoretest,\n                                          MLPClassifierModelTestScore,\n                                          RandomForestClassifierModeltest,\n                                          GBCModeltesting]})\n\n\nprint(tabulate(models , headers = ['Model' , 'Train' , 'Test'] , tablefmt = 'psql' , showindex =False)) ","a54f6b6d":"## **Comparison between Algorithms**","0fd0affb":"## **Applying machine learning classification models**\nto show which people will buy which product here i will try using more than one classification model, then i will show the training and testing scores in the end in a tabel.","6320a6cb":"The market research team at AdRight is assigned the task to identify the profile of the typical customer for each treadmill product offered by CardioGood Fitness. The market research team decides to investigate whether there are differences across the product lines with respect to customer characteristics. The team decides to collect data on individuals who purchased a treadmill at a CardioGoodFitness retail store during the prior three months. The data are stored in the CardioGoodFitness.csv file. The team identifies the following customer variables to study: product purchased, TM195, TM498, or TM798; gender; age, in years;education, in years; relationship status, single or partnered; annual household income ($); average number of times the customer plans to use the treadmill each week; average number of miles the customer expects to walk\/run each week; and self-rated fitness on an 1-to-5 scale, where 1 is poor shape and 5 is excellent shape. Perform descriptive analytics to create a customer profile for each CardioGood Fitness treadmill product line.","87673554":"## **Test**","bd720a00":"## **Applying Gradient boosting**","2b30c14e":"## **Applying logistic regression**","f786223a":"## **Assessing data**","955be1f7":"so the data was encoded in this pattern\n1. males:1 , females:2\n2. single:1 , partnered:2\n3. TM798:1, TM498:2 and TM195:3 \n\n","ba5752ce":"## **Applying KNN**","194d1c92":"## **Analyzing data**","da10e94a":"The three products we have here are TM798, TM498 and TM195 from the analysis and visualization done above we can find:\n1.  males in general are more interested in buying than females especially with the expensive model TM798.\n2.  we realize also that partnered males showed the most interest in buying a treadmill than partnered females.\n3. Couples in general are more interested in buying a treadmill than single people maybe because it will be used by two people so it is two people preference not only one.\n4. people with higher income showed more interest in the TM798  that shows us that it is the most expensive one while the other two  nearly the same price because people with similar incomes show interest in them equally.\n5. younger people are more interest in TM195 and as the age goes up people choose the other two treadmills.\n6. people with higher fitness level choose the TM798 but i dont think its trustworthy as it is self-rated.\n7. people who wanted to buy TM798, said that they will use it more often and run more miles on it than the other two. \n\n","fb7c5514":"## **Drawing Conclusion**","24c6c964":"First we need to encode the categorical data which is product,gender and marital status to be used by the algorithm using a package called category_encoders","fb987f3c":"## **Applying gaussian neural networks**","f4c3d983":"## **Importing libraries**","f1efa6ee":"## **Importing dataset**","9499c403":"## **Applying Randomforestclassifier**","21296a66":"## **Applying Support vector machine**","40c059a1":"## **Applying Neural networks**","d199b14f":"## **Splitting the data**"}}