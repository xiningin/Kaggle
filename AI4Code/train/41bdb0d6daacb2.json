{"cell_type":{"dbe2bfc3":"code","226c47b1":"code","7335ab04":"code","985988b5":"code","2d38c647":"code","fe0f1803":"code","e1eae6aa":"code","6161543f":"code","8b597c34":"code","4ee428ab":"code","ce483ed3":"code","a0261f85":"code","dd70dd92":"code","3d8657fa":"code","2bc0e901":"code","e85d10ac":"code","05e9fac5":"code","44d4911f":"code","0dcc5256":"code","5659e9ca":"code","a4f1c83d":"code","9f604caf":"code","7d0e6ddb":"code","0e4bf557":"code","2912b32c":"code","86e4d59f":"code","417a6a30":"code","8d3669fe":"code","916866ec":"code","29c9f537":"code","3b1dd1df":"code","4e72943c":"markdown","635e8f33":"markdown","7591590c":"markdown","4924b988":"markdown","a824db6b":"markdown","9e6d0574":"markdown","4cb3955d":"markdown","95afb818":"markdown","c7cb126d":"markdown","9c263cd9":"markdown","a4d65d8a":"markdown","cea243ec":"markdown","07133aeb":"markdown","c905c79f":"markdown","0ede6445":"markdown","76d0e5fd":"markdown","413e7278":"markdown","efc425c1":"markdown","34f57d5d":"markdown","c0c8e54a":"markdown","faeb8af6":"markdown","504411d9":"markdown","1c8f4ab8":"markdown","44284e2a":"markdown","ff58eaec":"markdown","7fbba4d5":"markdown","a086afd0":"markdown","83e76f4a":"markdown","20b1f3ab":"markdown","52e73416":"markdown","87fb6440":"markdown","d186e02b":"markdown","e3fe4bfb":"markdown","0957a0f9":"markdown","de77af48":"markdown","acf382ce":"markdown","71888d66":"markdown"},"source":{"dbe2bfc3":"from typing import List, Tuple\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport pathlib\nimport os\nimport seaborn as sns\nimport random\nfrom PIL import Image\nfrom sklearn.metrics import confusion_matrix, precision_recall_fscore_support\nfrom sklearn.utils import shuffle\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport glob\nimport cv2\nimport time\nfrom PIL import Image\n\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nfrom torchvision import models","226c47b1":"# Target size\nH, W, C = (224, 224, 1)\nBATCH_SIZE = 64\n# Number of repetitions of training\nREPEAT_TRAINING = 3\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Class labels\nBAD = 0.0\nNORMAL = 1.0\n# Path to data\nTRAIN_PATH = \"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train\"\nVAL_PATH = \"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/val\"\nTEST_PATH = \"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test\"\n# Define name of columns for DataFrame\nNAME_METHOD = 'name_method'                 # Name of a train method\nTYPE = 'type'                               # Type of metrics (precision\/recall\/fscore)\n# Additional string contants\nVALUE = 'value'\nPRECISION = 'precision'\nRECALL = 'recall'\nFSCORE = 'fscore'\n# DataFrame to store results with the specified column name\nRESULTS_DF = pd.DataFrame(columns=[NAME_METHOD, TYPE, VALUE])\n# Create additional DataFrame in order to store training time of all model\nSPEND_TIME = 'spend_time'                               # Training time\nTIME_DF = pd.DataFrame(columns=[NAME_METHOD, SPEND_TIME])\n\n\ndef pack_results(name, prec, rec, fscore):\n    \"\"\"\n    Write results from model into global DataFrame `RESULTS_DF`\n    \n    Parameters\n    ----------\n    name : str\n    prec : float\n    rec : float\n    fscore : float\n    time : float\n    \n    \"\"\"\n    global RESULTS_DF\n    # Write precision\/recall\/fscore values into final DataFrame\n    # Write precision data\n    RESULTS_DF = RESULTS_DF.append({\n        NAME_METHOD: name,\n        TYPE: PRECISION,\n        VALUE: prec,\n    }, ignore_index=True)\n    # Write recall data\n    RESULTS_DF = RESULTS_DF.append({\n        NAME_METHOD: name,\n        TYPE: RECALL,\n        VALUE: rec,\n    }, ignore_index=True)\n    # Write fscore data\n    RESULTS_DF = RESULTS_DF.append({\n        NAME_METHOD: name,\n        TYPE: FSCORE,\n        VALUE: fscore,\n    }, ignore_index=True)\n\n    \ndef pack_time_result(name, spend_time):\n    global TIME_DF\n    \n    TIME_DF = TIME_DF.append({\n        NAME_METHOD: name,\n        SPEND_TIME: spend_time\n    }, ignore_index=True)","7335ab04":"# Define Dataset class for our data\n# Which will load and transform our images \nclass XrayDataset(Dataset):\n\n    def __init__(\n            self, labels_and_path_to_images: list, transform = None, \n            H = 220, W = 220, map_to_rgb: bool = False):\n        self._labels_and_path_to_images = labels_and_path_to_images\n        self._transform = transform\n        self._map_to_rgb = map_to_rgb\n\n    def __getitem__(self, index) -> Tuple[torch.Tensor, torch.Tensor]:\n        image_path, label = self._labels_and_path_to_images[index]\n        image = Image.open(image_path).convert('RGB')\n        if self._transform is not None:\n            image = self._transform(image)\n            if not self._map_to_rgb:\n                # Keep only one dimension\n                image = image[0:1]\n                # In our case - 1\n        return image, torch.tensor(label, dtype=torch.float32)\n    \n    def __len__(self) -> int:\n        return len(self._labels_and_path_to_images)\n\ndef create_data_loader(\n        path_to_data: list, map_to_rgb: bool = False, \n        norm_for_pretrain: bool = False) -> DataLoader:\n    \"\"\"\n    Create a data loader that will gives data to the training pipeline\n    \n    \"\"\"\n    # Create transform list with different augmentation (aug) methods\n    # We will choose some simply augs\n    transform_m = [\n        transforms.Resize(size=(H, W)),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomVerticalFlip(p=0.5),\n        transforms.RandomRotation(degrees=(-45, 45)),\n        transforms.ToTensor(),\n        # Add noise, NOTICE! After `ToTensor` image will be in range(0, 1)\n        # After adding noise - values of the tensor can be slitly bigger than 1.0 or lower than 0.0\n        # Its okay - I have try training with different scales (except 190, I try 150, 200, 220 - and its work okay)\n        # The smaller divider of noise - the stronger noise we add to input values\n        transforms.Lambda(lambda x : x + torch.randn_like(x)\/190.0),\n        #transforms.Normalize(128, 128)\n    ]\n    # If data loader needed for preload model\n    # We must normalize data with certain mean\/std\n    if norm_for_pretrain:\n        transform_m += [transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]\n    # Create class which will load and transform data\n    train_set = XrayDataset(\n        path_to_data, \n        transform=transforms.Compose(transform_m),\n        H=H, W=W, map_to_rgb=map_to_rgb\n    )\n    # Create loader\n    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n    \n    return train_loader","985988b5":"def eval_dataset(\n        model, labels_and_path_to_images,\n        norm_for_pretrain: bool = False) -> Tuple[np.ndarray, np.ndarray, float, float, float]:\n    \"\"\"\n    Evaluate certain model on provided data\n    Returns labels and predictions arrays\n    \n    \"\"\"\n    # Turn on `evaluation` mode of the model\n    model.eval()\n    preds = []\n    labels = []\n\n    for img_path, label_ans in labels_and_path_to_images:\n        # cv2 load image with 3 color dimension\n        # Even if image itself saved as greyscale\n        loaded_img = cv2.imread(img_path)\n        loaded_img = cv2.resize(loaded_img, (W, H))\n        norm_img = np.expand_dims(loaded_img \/ 255.0, axis=0).astype(np.float32)\n        if norm_for_pretrain:\n            norm_img -= np.array([0.485, 0.456, 0.406], dtype=np.float32)\n            norm_img \/= np.array([0.229, 0.224, 0.225], dtype=np.float32)\n        else:\n            norm_img = norm_img[..., 0:1] # Save only 1 color dimension\n        # change shape: (N, H, W, C) --> (N, C, H, W)\n        norm_img = norm_img.transpose(0, 3, 1, 2)\n        answer_nn = model(torch.tensor(norm_img).to(device=device))\n        preds.append(int(np.round(answer_nn.cpu().detach().numpy().reshape(-1) )))\n        labels.append(int(label_ans))\n\n    pred_val_np = np.asarray(preds, dtype=np.int32).copy()\n    labels_val_np = np.asarray(labels, dtype=np.int32).copy()\n\n    precision, recall, fscore, _ = precision_recall_fscore_support(\n        labels_val_np, \n        pred_val_np, \n        average='binary', zero_division=1\n    )\n\n    print(f\"Precision: {precision}, Recall: {recall}, fscore: {fscore}\")\n    return preds, labels, precision, recall, fscore","2d38c647":"def create_labels_and_path_to_images(\n        path_to_data, scale_bad=1.0, scale_normal=1.0) -> Tuple[ List[Tuple[int, str]], int, int]:\n    \"\"\"\n    Create path to data and labels for them\n    \n    Parameters\n    ----------\n    path_to_data : str\n    scale_bad : float\n        Scale for bad samples. Final dataset (total number) of bad samples \n        will be increased according to this scale.\n        If value around 1.0 - then no scaling will be applied\n    scale_normal : float\n        Scale for normal samples. Final dataset (total number) of normal samples\n        will be increased according to this scale.\n        If value around 1.0 - then no scaling will be applied\n    \n    Returns\n    -------\n    list\n        List where each element - (path to data, label)\n    int \n        Number of bad samples\n    int \n        Number of normal samples\n    \n    \"\"\"\n    # Load `normal` class\n    normal_imgs = glob.glob(os.path.join(path_to_data, \"NORMAL\/*.jpeg\"))\n    if not (0.98 <= scale_normal <= 1.01):\n        normal_imgs = np.asarray(normal_imgs)\n        random_indx_pick = np.random.randint(\n            low=0, high=(len(normal_imgs)), \n            size=int(scale_normal * len(normal_imgs))\n        )\n        normal_imgs = normal_imgs[random_indx_pick]\n        normal_imgs = normal_imgs.tolist()\n    # Create label for `normal` class\n    normal_label = np.ones(len(normal_imgs), dtype=np.float32).tolist()\n    \n    # Load `bad` class\n    bad_imgs = glob.glob(os.path.join(path_to_data, \"PNEUMONIA\/*.jpeg\"))\n    if not (0.98 <= scale_bad <= 1.01):\n        bad_imgs = np.asarray(bad_imgs)\n        random_indx_pick = np.random.randint(\n            low=0, high=(len(bad_imgs)),\n            size=int(scale_bad * len(bad_imgs))\n        )\n        bad_imgs = bad_imgs[random_indx_pick]\n        bad_imgs = bad_imgs.tolist()\n    # Create label for `bad` class\n    bad_label = np.zeros(len(bad_imgs), dtype=np.float32).tolist()\n\n    # Connect two dataset into single list of tuples\n    full_data_imgs = normal_imgs + bad_imgs\n    full_labels = normal_label + bad_label\n    data_and_labels = shuffle(list(zip(full_data_imgs, full_labels)))\n    return data_and_labels, len(bad_imgs), len(normal_imgs)","fe0f1803":"labels_and_path_to_images, num_bad_train, num_normal_train = create_labels_and_path_to_images(TRAIN_PATH)\n\nsns.barplot(x=[\"Normal\",\"Bad (Pneumonia)\"],y=[num_normal_train,num_bad_train])\nprint(\n     'The ratio of Number of bad (with Pneumonia) images '\n    f'and number of Normal images is equal to: {round(num_bad_train \/ num_normal_train, 2)}'\n)\n\nlabels_and_path_to_images_val, _, _ = create_labels_and_path_to_images(VAL_PATH)\nlabels_and_path_to_images_test, _, _ = create_labels_and_path_to_images(TEST_PATH)","e1eae6aa":"fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\nindx = 0\nfor i, ax in enumerate(axes.flat):\n    img_path_s, label_s = labels_and_path_to_images[i]\n    img = cv2.imread(img_path_s)\n    img = cv2.resize(img, (W, H))\n    ax.imshow(img)\n    if label_s == BAD:\n        label_leg = \"Bad (Pneumonia)\"\n    else:\n        label_leg = \"Normal\"\n    ax.set_title(label_leg)\n    \nplt.show()","6161543f":"# Create loader\ntrain_loader = create_data_loader(labels_and_path_to_images)\n# Test loader\nbatch_d = next(iter(train_loader))[0]\ngrid = torchvision.utils.make_grid(batch_d, nrow=10)\n\nplt.figure(figsize=(15, 20))\nplt.imshow(np.transpose(grid, (1, 2, 0)).numpy())","8b597c34":"class VGG16_BNLikeModel(nn.Module):\n\n    def __init__(self, in_f):\n        super(VGG16_BNLikeModel, self).__init__()\n        \n        def conv_bn_relu(in_f, out_f, stride=1, padding=1, bias=False, kernel_size=3):\n            return [\n                nn.Conv2d(\n                    in_f, out_f, kernel_size=kernel_size, \n                    stride=stride, padding=padding, bias=bias\n                ),\n                nn.BatchNorm2d(out_f),\n                nn.ReLU(inplace=True),\n            ]\n        # VGG16 Like neural network\n        self._model_conv_part = nn.Sequential(\n            *conv_bn_relu(in_f, 64),\n            *conv_bn_relu(64, 64),\n            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),                 # 112\n            \n            *conv_bn_relu(64, 128),\n            *conv_bn_relu(128, 128),\n            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),                 # 56\n            \n            *conv_bn_relu(128, 256),\n            *conv_bn_relu(256, 256),\n            *conv_bn_relu(256, 256),\n            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),                 # 28\n            \n            *conv_bn_relu(256, 512),\n            *conv_bn_relu(512, 512),\n            *conv_bn_relu(512, 512),\n            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),                 # 14\n            \n            *conv_bn_relu(512, 512),\n            *conv_bn_relu(512, 512),\n            *conv_bn_relu(512, 512),\n            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),                 # 7\n        )\n        \n        self._model_dense_part = nn.Sequential(\n            nn.Flatten(),\n            nn.Dropout(p=0.4),\n            nn.Linear(512 * 7 * 7, 512),\n            nn.ReLU(inplace=True),\n            \n            nn.Dropout(p=0.4),\n            nn.Linear(512, 512),\n            nn.ReLU(inplace=True),\n            \n            nn.Dropout(p=0.5),\n            nn.Linear(512, 1),\n            nn.Sigmoid(),\n        )\n    \n    def forward(self, x):\n        x = self._model_conv_part(x)\n        x = self._model_dense_part(x)\n        return x","4ee428ab":"class_nn = VGG16_BNLikeModel(in_f=C)\nclass_nn.to(device=device)\nclass_nn.eval()\n\nin_np = np.random.randn(1, C, H, W).astype(np.float32)\nprint('in_x shape: ', in_np.shape)\ntest_answer = class_nn(torch.tensor(in_np).to(device=device))\ntest_answer.shape","ce483ed3":"class TrainClassificationController:\n    \n    def __init__(self, model, batch_size: int, device = None):\n        self._model = model\n        self._batch_size = batch_size\n\n        self._is_compiled = False\n        self._opt = None\n        self._loss = None\n        self._device = device\n    \n    def compile(\n            self, lr=2e-4, beta_params=(0.9, 0.999)):\n        \"\"\"\n        Compile model. Build loss and init optimizer\n        \n        \"\"\"\n        # Init opt\n        self._opt = torch.optim.Adam(\n            self._model.parameters(), lr=lr, betas=beta_params,\n            weight_decay=5e-4\n        )\n        # Losses\n        self._loss = nn.BCELoss().to(device=self._device)\n        # Set flag, in order to start train\n        self._is_compiled = True\n    \n    def train_step(self, model_input, label):\n        \"\"\"\n        Do single train step with `model_input` and `label`\n        \n        \"\"\"\n        assert self._is_compiled, \"Model seems to not compiled. Call `compile` method.\"\n        # For easy access\n        device = self._device\n        # Zero grads\n        self._model.zero_grad()\n        # Forward pass with model inputs through model\n        err_model = self._loss(self._model(model_input).view(-1), label)\n        err_model.backward()\n        self._opt.step()\n        return err_model.cpu().detach().numpy()\n\n    def fit(self, data_gen, epoch: int, print_it: int = 10):\n        \"\"\"\n        Start training process with certain number of `epoch`\n        on data from `data_gen`\n        \n        \"\"\"\n        for i_e in range(epoch):\n            for ii_it, (image_batch, label_batch) in enumerate(data_gen):\n                image_batch = image_batch.to(device=self._device)\n                label_batch = label_batch.to(device=self._device)\n                err_model = self.train_step(image_batch, label_batch)\n                if ii_it % print_it == 0:\n                    print(f'epoch: {i_e+1}\/{epoch}, it: {ii_it}\/{len(data_gen)}'\n                          f'|| Loss: {err_model}'\n                    )","a0261f85":"def do_training_several_times(\n        func_create_model: callable, \n        epoch: int, name_method: str, lr: float=2e-4, \n        norm_for_pretrain: bool = False):\n    precision_eval_list = []\n    recall_eval_list = []\n    fscore_eval_list = []\n\n    precision_test_list = []\n    recall_test_list = []\n    fscore_test_list = []\n\n    training_time_list = []\n\n\n    for i in range(REPEAT_TRAINING):\n        print(f'Training stage: {i+1}\/{REPEAT_TRAINING}')\n        # Create model\n        class_nn = func_create_model()\n        class_nn.to(device=device)\n        class_nn.train()\n        # Create instance of controller class and compile it\n        train_class_c = TrainClassificationController(class_nn, BATCH_SIZE, device=device)\n        train_class_c.compile(lr=lr)\n        # Start training\n        start_time = time.time()\n        train_class_c.fit(train_loader, epoch=epoch)\n        final_time = round(time.time() - start_time, 2) \n        training_time_list.append(final_time)\n        print(f'Time: {final_time}')\n        # Evaluate model\n        # Eval dataset\n        _, _, precision, recall, fscore = eval_dataset(\n            model=class_nn, \n            labels_and_path_to_images=labels_and_path_to_images_val,\n            norm_for_pretrain=norm_for_pretrain,\n        )\n        precision_eval_list.append(precision)\n        recall_eval_list.append(recall)\n        fscore_eval_list.append(fscore)\n        # Test dataset\n        _, _, precision, recall, fscore = eval_dataset(\n            model=class_nn, \n            labels_and_path_to_images=labels_and_path_to_images_test,\n            norm_for_pretrain=norm_for_pretrain,\n        )\n        precision_test_list.append(precision)\n        recall_test_list.append(recall)\n        fscore_test_list.append(fscore)\n        print('=' * 10)\n    # Calculate mean\n    precision_eval_mean = np.asarray(precision_eval_list).mean()\n    recall_eval_mean = np.asarray(recall_eval_list).mean()\n    fscore_eval_mean = np.asarray(fscore_eval_list).mean()\n\n    precision_test_mean = np.asarray(precision_test_list).mean()\n    recall_test_mean = np.asarray(recall_test_list).mean()\n    fscore_test_mean = np.asarray(fscore_test_list).mean()\n\n    training_time_mean = np.asarray(training_time_list).mean()\n    \n    print('Avg metric values on eval dataset:')\n    print(f'precision={precision_eval_mean} recall={recall_eval_mean} fscore={fscore_eval_mean}')\n    print('Avg metric values on test dataset:')\n    print(f'precision={precision_test_mean} recall={recall_test_mean} fscore={fscore_test_mean}')\n    print(f'Avg training time: {training_time_mean}')\n    # Write results into DataFrame\n    # Eval\n    pack_results(\n        name=name_method + '_eval',\n        prec=precision_eval_mean, \n        rec=recall_eval_mean, \n        fscore=fscore_eval_mean\n    )\n\n    # Test\n    pack_results(\n        name=name_method + '_test', \n        prec=precision_test_mean, \n        rec=recall_test_mean, \n        fscore=fscore_test_mean\n    )\n    # Training time\n    pack_time_result(\n        name=name_method,\n        spend_time=training_time_mean\n    )","dd70dd92":"EPOCH = 3\nNAME_IMBALANCE = 'imbalance'\nfunc_create_model = lambda: VGG16_BNLikeModel(in_f=C)\n\ndo_training_several_times(\n    func_create_model=func_create_model,\n    epoch=EPOCH, name_method=NAME_IMBALANCE,\n)","3d8657fa":"SCALE_BAD = 1.0\nSCALE_NORMAL = 3.0","2bc0e901":"labels_and_path_to_images, num_bad_train, num_normal_train = create_labels_and_path_to_images(\n    TRAIN_PATH, \n    scale_bad=SCALE_BAD, scale_normal=SCALE_NORMAL\n)\n\nsns.barplot(x=[\"Normal\",\"Bad (Pneumonia)\"],y=[num_normal_train,num_bad_train])\nprint(\n     'The ratio of (Number of bad (with Pneumonia) images) '\n    f'and (number of Normal images) is equal to: {round(num_bad_train \/ num_normal_train, 2)}'\n)\n\nlabels_and_path_to_images_val, _, _ = create_labels_and_path_to_images(\n    VAL_PATH, \n    scale_bad=SCALE_BAD, scale_normal=SCALE_NORMAL\n)\n\nlabels_and_path_to_images_test, _, _ = create_labels_and_path_to_images(\n    TEST_PATH, \n    scale_bad=SCALE_BAD, scale_normal=SCALE_NORMAL\n)","e85d10ac":"fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\nindx = 0\nfor i, ax in enumerate(axes.flat):\n    img_path_s, label_s = labels_and_path_to_images[i]\n    img = cv2.imread(img_path_s)\n    img = cv2.resize(img, (220,220))\n    ax.imshow(img)\n    if label_s == BAD:\n        label_leg = \"Bad (Pneumonia)\"\n    else:\n        label_leg = \"Normal\"\n    ax.set_title(label_leg)\n    \nplt.show()","05e9fac5":"# Create loader\ntrain_loader = create_data_loader(labels_and_path_to_images)\n# Test loader\nbatch_d = next(iter(train_loader))[0]\ngrid = torchvision.utils.make_grid(batch_d, nrow=10)\n\nplt.figure(figsize=(15, 20))\nplt.imshow(np.transpose(grid, (1, 2, 0)).numpy())","44d4911f":"EPOCH = 3\nNAME_RAND_OVERSAM = 'rand_oversam'\n\ndo_training_several_times(\n    func_create_model=func_create_model,\n    epoch=EPOCH, name_method=NAME_RAND_OVERSAM,\n)","0dcc5256":"labels_and_path_to_images, num_bad_train, num_normal_train = create_labels_and_path_to_images(TRAIN_PATH)\n\nsns.barplot(x=[\"Normal\",\"Bad (Pneumonia)\"],y=[num_normal_train, num_bad_train])\nprint(\n     'The ratio of Number of bad (with Pneumonia) images '\n    f'and number of Normal images is equal to: {round(num_bad_train \/ num_normal_train, 2)}'\n)\n\n\nlabels_and_path_to_images_val, _, _ = create_labels_and_path_to_images(VAL_PATH)\nlabels_and_path_to_images_test, _, _ = create_labels_and_path_to_images(TEST_PATH)","5659e9ca":"fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\nindx = 0\nfor i, ax in enumerate(axes.flat):\n    img_path_s, label_s = labels_and_path_to_images[i]\n    img = cv2.imread(img_path_s)\n    img = cv2.resize(img, (W, H))\n    ax.imshow(img)\n    if label_s == BAD:\n        label_leg = \"Bad (Pneumonia)\"\n    else:\n        label_leg = \"Normal\"\n    ax.set_title(label_leg)\n    \nplt.show()","a4f1c83d":"# Create loader\ntrain_loader = create_data_loader(labels_and_path_to_images, map_to_rgb=True, norm_for_pretrain=True)\n# Test loader\nbatch_d = next(iter(train_loader))[0]\ngrid = torchvision.utils.make_grid(batch_d, nrow=10)\n\nplt.figure(figsize=(15, 20))\nplt.imshow(np.transpose(grid, (1, 2, 0)).numpy())","9f604caf":"class ClassificatorPreloadVGG16(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        model_vgg16 = models.vgg16_bn(pretrained=True)\n        model_vgg16.to(device=device)\n        self._features = model_vgg16.features\n        \n        #for param in self._features.parameters():\n        #    param.requires_grad = False\n        \n        for layer in self._features.children():\n            for param in layer.parameters():\n                param.requires_grad = False\n            \n            print(f'Layer \"{layer}\" - frozen!')\n        \n        self._model_dense_part = nn.Sequential(\n            nn.Flatten(),\n            nn.Dropout(p=0.4),\n            nn.Linear(512 * 7 * 7, 512),\n            nn.ReLU(inplace=True),\n            \n            nn.Dropout(p=0.4),\n            nn.Linear(512, 512),\n            nn.ReLU(inplace=True),\n            \n            nn.Dropout(p=0.5),\n            nn.Linear(512, 1),\n            nn.Sigmoid(),\n        )\n    \n    def __call__(self, x):\n        x = self._features(x)\n        x = self._model_dense_part(x)\n        return x","7d0e6ddb":"model_vgg16 = ClassificatorPreloadVGG16()\nmodel_vgg16.to(device=device)\nmodel_vgg16.eval()\n\n\nin_np = np.random.randn(1, 3, H, W).astype(np.float32)\nprint('in_x shape: ', in_np.shape)\ntest_answer = model_vgg16(torch.tensor(in_np).to(device=device))\ntest_answer.shape","0e4bf557":"EPOCH = 1\nNAME_VGG16_IMBALANCE = 'vgg16_imbalance'\n\ndo_training_several_times(\n    func_create_model=ClassificatorPreloadVGG16,\n    epoch=EPOCH, name_method=NAME_VGG16_IMBALANCE,\n    lr=6e-5, norm_for_pretrain=True\n)","2912b32c":"model_vgg16 = ClassificatorPreloadVGG16()\nmodel_vgg16.to(device=device)\nmodel_vgg16.train()\n\n\nin_np = np.random.randn(1, 3, H, W).astype(np.float32)\nprint('in_x shape: ', in_np.shape)\ntest_answer = model_vgg16(torch.tensor(in_np).to(device=device))\ntest_answer.shape","86e4d59f":"labels_and_path_to_images, num_bad_train, num_normal_train = create_labels_and_path_to_images(\n    TRAIN_PATH, \n    scale_bad=SCALE_BAD, scale_normal=SCALE_NORMAL\n)\n\nsns.barplot(x=[\"Normal\",\"Bad (Pneumonia)\"],y=[num_normal_train,num_bad_train])\nprint(\n     'The ratio of Number of bad (with Pneumonia) images '\n    f'and number of Normal images is equal to: {round(num_bad_train \/ num_normal_train, 2)}'\n)\n\n\nlabels_and_path_to_images_val, _, _ = create_labels_and_path_to_images(\n    VAL_PATH, \n    scale_bad=SCALE_BAD, scale_normal=SCALE_NORMAL\n)\n\nlabels_and_path_to_images_test, _, _ = create_labels_and_path_to_images(\n    TEST_PATH, \n    scale_bad=SCALE_BAD, scale_normal=SCALE_NORMAL\n)","417a6a30":"fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(15,10), subplot_kw={'xticks':[], 'yticks':[]})\nindx = 0\nfor i, ax in enumerate(axes.flat):\n    img_path_s, label_s = labels_and_path_to_images[i]\n    img = cv2.imread(img_path_s)\n    img = cv2.resize(img, (W, H))\n    ax.imshow(img)\n    if label_s == BAD:\n        label_leg = \"Bad (Pneumonia)\"\n    else:\n        label_leg = \"Normal\"\n    ax.set_title(label_leg)\n    \nplt.show()","8d3669fe":"# Create loader\ntrain_loader = create_data_loader(labels_and_path_to_images, map_to_rgb=True, norm_for_pretrain=True)\n# Test loader\nbatch_d = next(iter(train_loader))[0]\ngrid = torchvision.utils.make_grid(batch_d, nrow=10)\n\nplt.figure(figsize=(15, 20))\nplt.imshow(np.transpose(grid, (1, 2, 0)).numpy())","916866ec":"EPOCH = 1\nNAME_VGG16_RAND_OVER = 'vgg16_rand_over'\n\ndo_training_several_times(\n    func_create_model=ClassificatorPreloadVGG16,\n    epoch=EPOCH, name_method=NAME_VGG16_RAND_OVER,\n    lr=6e-5, norm_for_pretrain=True\n)","29c9f537":"g = sns.catplot(data=RESULTS_DF, x=TYPE, y=VALUE, col=NAME_METHOD, col_wrap=4, kind='bar')\ng.fig.set_size_inches(15, 8)\ng.fig.subplots_adjust(top=0.9)\n\ng.fig.suptitle('Bar Count with Annotations')\n\n# iterate through axes\nfor ax in g.axes.ravel():\n    \n    # add annotations\n    for c in ax.containers:\n        labels = [round(v.get_height(), 2) for v in c]\n        ax.bar_label(c, labels=labels, label_type='edge')\n    ax.margins(y=0.2)","3b1dd1df":"sns.catplot(data=TIME_DF, x=NAME_METHOD, y=SPEND_TIME, kind='bar', aspect=2)","4e72943c":"### Define global contants","635e8f33":"# Conclusion\n### As we can see from the bars above, pretrained NNs with random oversampling give us in most cases the highest accuracy than configuration of the model without it. \n### In some cases, pretrained NN can give equal or grater accuracy than training from scratch. But we also must take in account that training time of pretrained model 3 time faster than training from scratch.","7591590c":"### Plot images from data loader with different augs","4924b988":"## Plot number of normal and bad (with Pneumonia) images in training dataset after scaling them","a824db6b":"# 3. Using preload VGG16-bn model with imbalance data.","9e6d0574":"### Start training for first model","4cb3955d":"## Plot number of normal and bad (with Pneumonia) images in training dataset","95afb818":"### We will create function that will train model several times (by default 3). Each run will do:\n> ### 1. Create model\n> ### 2. Create controller of the training\n> ### 3. Start training\n> ### 4. Evaluate model on eval and test datasets\n### At the end - we will calculate mean precision\/recall\/fscore on eval\/test datasets and write results into DataFrame","c7cb126d":"### In this run, model same as in the previous stage, so we just reuse function that create it","9c263cd9":"## Define model class. Model VGG16-bn.","a4d65d8a":"# Classification with imbalanced data using VGG16-bn model.\n#### We will apply random oversampling technique in order to resolve issue with data.\n#### Also, we will try Transfer Learning (TL) using VGG16-bn model.\n#### We will compare each model using precision\/recall\/f1score metrics.\n#### Also we will compare training time of each model.\n# So, What are we doing:\n### In this notebook we will train 4 neural networks (NNs):\n > #### 1. Train ***VGG16-bn from scratch***. With imbalanced data;\n > #### 2. Train ***VGG16-bn from scratch***. Using random oversampling technique;\n > #### 3. Using ***preload VGG16-bn*** model with imbalance data;\n > #### 4. Using ***preload VGG16-bn*** model with random oversampling;\n\n### At the end of all these training stuff, we are going to compare 4 models with each other using ***Precision\/Recall\/F1-score*** metrics.\n\n### Also we will take in account training time of each model.","cea243ec":"### Define controller which controls training of models","07133aeb":"### Plot images from data loader with different augs","c905c79f":"### Plot images from data loader with different augs","0ede6445":"### Import all necessary libraries that we will use in this notebook","76d0e5fd":"### Define method which grap train\/val\/test data ","413e7278":"## Prapare data and data loader\n## Plot number of normal and bad (with Pneumonia) images in training dataset","efc425c1":"### Define scales for random oversampling","34f57d5d":"## Plot few normal\/bad images from dataset","c0c8e54a":"### Let's try init our model and input some noise data","faeb8af6":"## Plot few normal\/bad images from dataset","504411d9":"### Init model. Enable train mode and test it on noise data.","1c8f4ab8":"# 0. Define common scripts","44284e2a":"# 1. Train VGG16-bn from scratch. With imbalanced data.","ff58eaec":"### Start training","7fbba4d5":"## Plot number of normal and bad (with Pneumonia) images in training dataset","a086afd0":"## Plot few normal\/bad images from dataset","83e76f4a":"### Plot images from data loader with different augs","20b1f3ab":"# 2. Train VGG16-bn from scratch. Using random oversampling technique.\n### For more details refer to: https:\/\/en.wikipedia.org\/wiki\/Oversampling_and_undersampling_in_data_analysis\n### There is a good description of this technique and others at this link","52e73416":"## Plot few normal\/bad images from dataset","87fb6440":"### Let's make sure that model is working and input some noise data","d186e02b":"# 4. Using preload VGG16-bn model with random oversampling.","e3fe4bfb":"## Create class in order to preload VGG16 and freeze first conv layers","0957a0f9":"### In most cases, pretrained model will be more\/equal accurate compare to training from zero.\n### We also should take in accound that training with pretrained model is much faster.","de77af48":"### Start training","acf382ce":"## Compare 4 trained models with calculated Precision\/Recall\/F1-score metrics","71888d66":"#### Lets compare training time (in seconds):"}}