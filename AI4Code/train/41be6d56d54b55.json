{"cell_type":{"d7742a25":"code","c1b85ba3":"code","89a95b87":"code","eca70e63":"code","eb0f57f2":"code","9b5acaf8":"code","59d04121":"code","2bab91bc":"code","482e237b":"code","f1554d6e":"code","c93d5de0":"code","6ffd8982":"code","7b70258a":"code","765d5070":"code","be3b7a7b":"code","cbe69093":"code","c3939d2f":"code","eeda8183":"markdown","1ef58dd7":"markdown","72bba7d5":"markdown","50836a79":"markdown","efc753dc":"markdown","1a493042":"markdown","70418725":"markdown","8ce3e087":"markdown","03a90321":"markdown","cd4c4df1":"markdown","ef93c577":"markdown","9f383df7":"markdown","0527c595":"markdown"},"source":{"d7742a25":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c1b85ba3":"def getStockData(tickers):\n    df = pd.DataFrame()\n    for ticker in tickers:\n        # loads data for each company\n        data = pd.read_csv(\"..\/input\/nasdaq-and-nyse-stocks-histories\/fh_20181104\/full_history\/\" + ticker + \".csv\")\n        data = data.sort_index(axis=0, ascending=False)\n        data = data.drop(['adjclose', 'high', 'low'], axis=1)\n        \n        data[\"date\"] = pd.to_datetime(data[\"date\"])\n        \n        # Cuts the first 10% of the historical data off\n        data = data[int(len(data)*.1):]\n        \n        # Features and Label:\n        data[\"ticker\"] = ticker\n        \n# --------- Stock Indicators ---------- #\n        \n        # Simple Moving Average (df, column for calculations, window)\n        SMA(data, 'open', 50)\n        SMA(data, 'open', 200)\n        \n        # Exponetial Moving Average\n        EMA(data, 'open', 12)\n        EMA(data, 'open', 26)\n        \n        # Moving Average Convergence Divergence (plus signal) (window1_EMA - window2_EMA) \n        MACD(data, 'open', 12, 26, 9, True)\n        \n        # Stochastic Oscillator (plus signal)\n        SO(data, 'open', 14, 3, True)\n        \n        # Relative Strength Index (EMA, SMA)\n        RSI(data, 'open', 14, True, True)\n        \n        # Bollinger Bands\n        BB(data, 'open', 20)\n\n        # Yesterday's close\n        data['close-1'] = data['close'].shift(1)  \n        \n        # Label Creation\n        close1 = data['close'].shift(-2)  #Tomorrow's close\n        data['log_label'] = np.where(close1 > (1.0 * data['close']), 1, 0) # is tomorrow going to close higher than today?\n        \n        \n        # drops any NaN values from stock indicator calculations\n        data = data.dropna()\n        \n        # Calls fundamental data function to add fundamentals\n        data = fundamentalData(data, ticker)\n        \n        df = df.append(data,ignore_index=True)\n        \n    \n    # one-hot encoding for company\n    df2 = pd.get_dummies(df[\"ticker\"])\n    df = pd.concat([df, df2], axis=1, join='outer')\n    return df","89a95b87":"# All indicators are typically done with close, but I'm doing open for everything\n\ndef SMA(df, dataColumn, window):\n    newColumn = str(window) + \"SMA\" + \"_\" + dataColumn\n    df[newColumn] = df[dataColumn].rolling(window=window).mean()\n    \ndef EMA(df, dataColumn, window):\n    newColumn = str(window) + \"EMA\" + \"_\" + dataColumn\n    # pandas ewm method for moving average (adjust set to false to equal stock website calculations)\n    df[newColumn] = df[dataColumn].ewm(span=window,min_periods=0,adjust=False,ignore_na=False).mean()\n\n# Moving Average Convergence Divergence (12, 26 are most common EMA windows)\ndef MACD(df, dataColumn, window1, window2, signal_window, isSignal):\n    EMA1 = df[dataColumn].ewm(span=window1,min_periods=0,adjust=False,ignore_na=False).mean()\n    EMA2 = df[dataColumn].ewm(span=window2,min_periods=0,adjust=False,ignore_na=False).mean()\n    MACD = EMA1 - EMA2\n    df[str(window1) + \"-\" + str(window2) + \"MACD\" + \"_\" + dataColumn] = MACD\n    if(isSignal):\n        df[\"MACD_\" + str(signal_window) + \"SMA\"] = MACD.ewm(span=signal_window,min_periods=0,adjust=False,ignore_na=False).mean()\n\n        \n# Stochastic Oscillator (14 is most common lookback window)\ndef SO(df, dataColumn, window, signal_window, isSignal):\n    # current open - lowest open \/ (highest open - lowest open) * 100\n    SO = ((df[dataColumn] - df[dataColumn].rolling(window=window).min()) \/\n              (df[dataColumn].rolling(window=window).max() - df[dataColumn].rolling(window=window).min())) * 100\n    df[str(window) + \"SO\" + \"_\" + dataColumn] = SO\n    # Signal line (SMA of Stochstic Oscillator, 3 is most common)\n    if(isSignal):\n        df[\"SO_\" + str(signal_window) + \"SMA\"] = SO.rolling(window=signal_window).mean()\n        \n# Relative Strength Index (14 is most common lookback window)\ndef RSI(df, dataColumn, window, isEMA, isSMA):\n        \n    data = df[dataColumn]\n    delta = data.diff()\n    # Get rid of the first row, which is NaN since it did not have a previous row to calculate the differences\n    delta = delta[1:] \n\n    # Make the positive gains (up) and negative gains (down)\n    up, down = delta.copy(), delta.copy()\n    up[up < 0] = 0\n    down[down > 0] = 0\n\n    if(isEMA):\n        # Calculate the EMAs\n        roll_up1 = up.ewm(span=window,min_periods=0,adjust=False,ignore_na=False).mean()\n        roll_down1 = down.abs().ewm(span=window,min_periods=0,adjust=False,ignore_na=False).mean()\n\n        # Calculate the RSI based on EMA\n        RS1 = roll_up1 \/ roll_down1\n        name1 = str(window) + \"RSI\" + \"_\" + \"EMA\" + \"_\" + dataColumn\n        df[name1] = 100.0 - (100.0 \/ (1.0 + RS1))\n\n    if(isSMA):\n        # Calculate the SMAs\n        roll_up2 = up.rolling(window=window).mean()\n        roll_down2 = down.abs().rolling(window=window).mean()\n\n        # Calculate the RSI based on SMA\n        RS2 = roll_up2 \/ roll_down2\n        name2 = str(window) + \"RSI\" + \"_\" + \"SMA\" + \"_\" + dataColumn\n        df[name2] = 100.0 - (100.0 \/ (1.0 + RS2))\n\n# Bollinger Bands\ndef BB(df, dataColumn, window):\n    SMA = df[dataColumn].rolling(window=window).mean()\n    std = df[dataColumn].rolling(window=window).std()\n    df[str(window) + \"upper_\" + dataColumn] = SMA + (2 * std)\n    df[str(window) + \"middle_\" + dataColumn] = SMA\n    df[str(window) + \"lower_\" + dataColumn] = SMA - (2 * std)","eca70e63":"# Adding Fundamental Data function\n\ndef fundamentalData(df, ticker):\n    data = pd.read_csv(\"\/kaggle\/input\/financial-ratios-1980-goog-aapl-amzn\/Fin Ratios 1980-Now AAPL_AMZN_GOOG.csv\")\n    \n    # Most tickers are GOOG, 41 of the most recent are GOOGL - so I changed all of them to GOOG\n    data.loc[data[\"TICKER\"] == 'GOOGL', 'TICKER'] = 'GOOG'\n    data[data[\"TICKER\"] == 'GOOG']\n    \n    data['public_date'] = pd.to_datetime(data[\"public_date\"])\n    data.set_index(\"TICKER\", inplace = True)\n    \n    data = data.loc[ticker]\n\n    data.set_index(\"public_date\", inplace = True)\n    #data = data.drop([ \"gvkey\", \"permno\", 'adate', 'qdate', 'public_date'], axis=1)\n    # forward fill to get a fundamental value for every day\n    data = data.asfreq(freq='D', method='ffill')\n    data[\"date\"] = data.index\n\n    \n    # removes any columns that have any NaN values or is an object\/string (quarter, reported\/reinstated date, etc.)\n    dropCols = []\n    for column in data.columns:\n        if data[column].isna().sum() > 0 or data[column].dtypes == np.object:\n            dropCols += [column]\n    data = data.drop(dropCols, axis=1)\n    #print(dropCols)\n\n    df = pd.merge(df, data, 'outer', on=\"date\")\n    df = df.dropna()\n    return df","eb0f57f2":"\nticker_list = [\"AAPL\", \"AMZN\", \"GOOG\"]\n#ticker_list = [\"AAPL\", \"AMZN\", \"GOOG\", \"MSFT\", \"FB\", 'IBM', 'HPQ']\n\n# Calls function to compile data and calculate features\ndf = getStockData(ticker_list)\n\n# this ensures (relatively) even mix of companies in each data split\ndf = df.sort_values(by=['date'])\n\n# drops columns with na values\ndropCols= []\nfor column in df.columns:\n    if df[column].isna().sum() > 0:\n        dropCols += [column]\ndf = df.drop(dropCols, axis=1)\n\ndf","9b5acaf8":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\ndata = df[int(.95 * len(df)):]\n\nplt.figure(figsize=(24,8))\n\nplt.subplot(1, 1, 1)\ngraph = plt.plot(data[data['AAPL'] == 1][\"date\"], data[data['AAPL'] == 1][\"close\"], label= \"Apple Close Price\", color=\"lightblue\")\ngraph = plt.plot(data[data['AMZN'] == 1][\"date\"], data[data['AMZN'] == 1][\"close\"], label= \"Amazon Close Price\", color=\"red\")\ngraph = plt.plot(data[data['GOOG'] == 1][\"date\"], data[data['GOOG'] == 1][\"close\"], label= \"Google Close Price\", color=\"green\")\nplt.title(\"Company Closing Stock Price\")\nplt.legend()\n\nplt.show()\n\n\n\n\nprint(\"AAPL Indicators\")\ndata = data[data['AAPL'] == 1]\n\nplt.figure(figsize=(24,7))\n\n# Simple Moving Average\nplt.subplot(1, 2, 1)\ngraph = plt.plot(data[\"date\"], data[\"open\"], label= \"Open price\")\ngraph = plt.plot(data[\"date\"], data[\"50SMA_open\"], label= \"50 day SMA\")\nplt.title(\"50 Day Simple Moving Average\")\nplt.legend()\n\nplt.subplot(1,2,2)\ngraph = plt.plot(data[\"date\"], data[\"12-26MACD_open\"], label= \"MACD\", color=\"purple\")\ngraph = plt.plot(data[\"date\"], data[\"MACD_9SMA\"], label= \"MACD Signal Line\", color=\"green\")\nplt.title(\"Moving Average Convergence Divergence Trend and Signal Line\")\nplt.axhline(y=0, color=\"grey\")\nplt.legend()\n\nplt.show()\n\n\n\n\nplt.figure(figsize=(24,4))\n\n# Stochastic Oscillator\nplt.subplot(1, 2, 1)\ngraph = plt.plot(data[\"date\"], data[\"SO_3SMA\"], label= \"Stochastic Oscillator\", color=\"brown\")\nplt.legend(loc = \"upper left\")\nplt.title(\"Stochastic Oscillator with 14 Day Window\")\n\n\nplt.subplot(1, 2, 2)\n# Relative Strength Index\ngraph = plt.plot(data[\"date\"], data[\"14RSI_SMA_open\"], label= \"RSI based off SMA\", color=\"blue\")\nplt.legend(loc = \"upper left\")\nplt.title(\"Relative Strength Index based off 14 day SMA\")\n\nplt.show()\n\n\n# Bollinger Bands\nplt.figure(figsize=(24,8))\n\nplt.subplot(1, 1, 1)\ngraph = plt.plot(data[\"date\"], data[\"20upper_open\"], label= \"Upper Band\", color=\"lightblue\")\ngraph = plt.plot(data[\"date\"], data[\"20middle_open\"], '--', label= \"Middle Band (20 SMA)\", color=\"lightblue\")\ngraph = plt.plot(data[\"date\"], data[\"open\"], label= \"Open price\", color=\"red\")\ngraph = plt.plot(data[\"date\"], data[\"20lower_open\"], label= \"Lower Band\", color=\"lightblue\")\n\nplt.legend(loc = \"upper left\")\nplt.title(\"Bollinger Bands with open price\")\n\n\nplt.show()","59d04121":"# split the data at 70%, 20%, and 10%\nn = len(df)\ntrain_df = df[0:int(n*0.7)]\nval_df = df[int(n*0.7):int(n*0.9)]\ntest_df = df[int(n*0.9):]\n\n# shuffles the data within each category to remove bias\ntrain_df = train_df.sample(frac=1)\nval_df = val_df.sample(frac=1)\ntest_df = test_df.sample(frac=1)\n\n# get labels for each data split\ntrain_y = train_df[\"log_label\"]\nval_y = val_df[\"log_label\"]\ntest_y = test_df[\"log_label\"]\n\n# seperate dates for later reference when graphing\ntrain_date = train_df['date']\nval_date = val_df['date']\ntest_date = test_df['date']\n\n# get features for each data split\ntrain_X = train_df.drop(['log_label', 'close', 'open', 'date', 'ticker', 'volume'], axis=1)\nval_X = val_df.drop(['log_label', 'close', 'open', 'date', 'ticker', 'volume'], axis=1)\ntest_X = test_df.drop(['log_label', 'close', 'open', 'date', 'ticker', 'volume'], axis=1)\n\ntrain_X.describe()","2bab91bc":"from sklearn.ensemble import ExtraTreesClassifier\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize = (20,10))\n\nmodel = ExtraTreesClassifier()\nmodel.fit(train_X,train_y)\n\n#plot graph of feature importances for better visualization\nfeat_importances = pd.Series(model.feature_importances_, index=train_X.columns)\n\nfeat_importances.nlargest(30).plot(kind='barh')\nplt.show()\n\n# 18 best features that have a weight above 0.01 (confirmed same for val and test data)\nfeatures = feat_importances.nlargest(18).index\nfeatures","482e237b":"# takes top features and adds company distinctions for training\nfeatures = features.tolist() + ticker_list\n\ntrain_X = train_df[features]\nval_X = val_df[features]\ntest_X = test_df[features]\n\ntrain_X","f1554d6e":"train_X = train_X.drop(columns=['ps', 'pcf', 'pe_inc', 'pe_exi'])\nval_X = val_X.drop(columns=['ps', 'pcf', 'pe_inc', 'pe_exi'])\ntest_X = test_X.drop(columns=['ps', 'pcf', 'pe_inc', 'pe_exi'])","c93d5de0":"from sklearn import linear_model\n\n#Intializes the model and fits it to the training data\nmodel = linear_model.LogisticRegression(random_state=0, penalty = 'l2', max_iter=5000)\n\nmodel.fit(train_X, train_y)\ny_val_pred = model.predict(val_X)\ny_test_pred = model.predict(test_X)\n\nimport math\nfrom sklearn.metrics import accuracy_score, mean_squared_error\n\n# function for displaying model evaluation scores\ndef eval_metrics(y_actual, y_predict, dataset):\n    print(\"\\nEvaluation metrics for \" + dataset + \":\\n\")\n    print(\"Accuracy score is: %.2f\" % accuracy_score(y_actual, y_predict))\n    print(\"Mean Squared Error: %.3f\" % mean_squared_error(y_actual, y_predict))\n    print(\"Root Mean Squared Error: %.3f\" % math.sqrt(mean_squared_error(y_actual, y_predict)))\n    print(\"-----------------------------------------\")","6ffd8982":"eval_metrics(val_y, y_val_pred, \"Val data\")\neval_metrics(test_y, y_test_pred, \"Test data\")\n\n\npred_df = pd.DataFrame(val_y)\npred_df[\"pred\"] = y_val_pred\npred_df['date'] = val_df['date']\npred_df['close'] = val_df['close']\nfor ticker in ticker_list:\n    pred_df[ticker] = val_X[ticker]\n\npred_df = pred_df.sort_values(by=['date'])\npred_df.describe()","7b70258a":"from sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(test_y, y_test_pred)\ncm_display = pd.DataFrame(cm)\ncm_display\n#X axis is predicted\n#y axis is actual","765d5070":"!pip install fastquant","be3b7a7b":"# back testing using a custom strategy (the predictions generated by my ML model)\n\nfrom fastquant import CustomStrategy, BaseStrategy\nfrom fastquant.indicators import MACD, CrossOver \nfrom fastquant.indicators.custom import CustomIndicator\nfrom fastquant import get_crypto_data, backtest, get_yahoo_data\n\n# Create a subclass of the BaseStrategy, \nclass MLStrategy(BaseStrategy):\n    \n    params = (\n        (\"pred_column\", \"pred\"),\n        (\"commission\",0)\n    )\n\n    def __init__(self):\n        \n        # Initialize global variables\n        super().__init__()\n        self.commission = self.params.commission\n\n        self.pred_column = self.params.pred_column\n    \n        self.pred = CustomIndicator(\n            self.data, custom_column=self.pred_column,\n        )\n        \n    # Buy\/sell based on model results\n    def buy_signal(self):\n        return self.pred == 1\n    \n    def sell_signal(self):\n        return self.pred == 0","cbe69093":"import time\n# %matplotlib inline\n# import matplotlib.pyplot as plt\n\n\ndef backTestTicker(ticker):\n    df1 = pd.DataFrame(val_y)\n    df1[\"pred\"] = y_val_pred\n    df1[\"dt\"] = val_df['date']\n    df1['close'] = val_df['close']\n    \n    # seperates data for specific company\n    df1[ticker] = val_X[ticker]\n    df1 = df1.loc[df1[ticker] == 1]\n    df1 = df1.drop(columns=['log_label', ticker])\n    df1 = df1.sort_values(by=['dt'])\n    \n    # runs backtest for company\n    print(\"Backtest for \" + ticker + \":\\n\")\n    #%matplotlib inline\n    result, history = backtest(MLStrategy,df1, verbose=False, return_history=True, commission = 0, buy_prop = .5, sell_prop = .5)\n    plt.show()\n    #print(\"\\n---------------------------\")\n    return result\n    \nfrom tabulate import tabulate # nicer looking tables when printed\n\n# prints prediction stats for company\ndef predByCompany(ticker):\n        df = pd.DataFrame(pred_df, columns=['log_label', 'pred', ticker])\n        print(tabulate(df[df[ticker] == 1].describe(), headers=['log_label', 'pred', ticker]))\n        print('\\n')\n\n#ticker_list = ['AAPL', 'AMZN']\nprofit = 0\nfor ticker in ticker_list:    \n    result = backTestTicker(ticker)\n    profit += result['pnl'][0]\n    time.sleep(5)\n    predByCompany(ticker)\n","c3939d2f":"percentage_return = (profit \/ (100000 * len(ticker_list))) * 100\nprint(\"Total Return over ~4 years: %.2f%%\" % percentage_return)\nprint(\"Average Annual Return: %.2f%%\" % (percentage_return \/ 4))","eeda8183":"# Model Fitting and Predicting\nThe next step is fitting the model to the data.  Then, it predicts for both the test and validation data so we can compare those two segments.","1ef58dd7":"# Semester 1 Logistic ML Model\n_________________________________________________\n**This notebook walks through the general steps of machine learning model creation while I develop a logistic model.\nEach step includes code that I've developed this semester and exemplifies some of the data analysis, \nfinance, machine learning, and programming skills I've learned.**\n\n<img align=\"left\" width=\"500\" height=\"800\" src=\"https:\/\/www.nasdaq.com\/sites\/acquia.prod\/files\/styles\/720x400\/public\/2020\/03\/16\/stocks-iamchamp-adobe.jpg?h=6acbff97&itok=8CjW1T_R\">","72bba7d5":"### Company Fundamental Data Function\nThis function adds data on company finnancials into our model.  Because there is normally more than 600 fundamentals per company, I accessed already calculated finnancial ratios to save time.  These ratios are meaningful than the raw data, similar to the stock indicators.\n\nThe documentation of the ratios can be found [here](https:\/\/wrds-www.wharton.upenn.edu\/documents\/793\/WRDS_Industry_Financial_Ratio_Manual.pdf?_ga=2.25016058.1798038680.1607698243-1727031239.1606232862)","50836a79":"Unfortunately, I discovered a (currently unfixed) issue fastquant with the fastquant plots today (12\/18).\nI will update this notebook when possible, but for now the combined return metrics are displayed below\n","efc753dc":"### Backtesting the Model\nIt's hard to tell what the accuracy score really means in this context.  To gain a better idea, the below code uses a package called fastquant to backtest our model.  Using our model's predictions (1=buy, 0=sell), we can determine the actual finnancial success of our model.","1a493042":"# Final Thoughts\nThe model has performed well, but it didn't really generate any novel insight into the stock market.  Regardless, my independent study continues to be an incredible (and fun!) learning oopportunity.  Next, I'm excited to progress to a more sophisticated machine learning approach: Deep Reinforcement Learning.","70418725":"### Stock Indicator Functions\nThe below functions calculate various stock indicators under the broad categories of trend following, momentum, mean reversion, and volume indicators.\n\n\n\nInitiallly coded and graphed [here](https:\/\/www.kaggle.com\/colinflueck\/apple-stock-indicators\/notebook?scriptVersionId=46331290)\n","8ce3e087":"# Model Evaluation\nNow we get to see how the model performs!  The below code shows common machine learning valuation metrics for both validation and test data.  Additonally, it shows the statistical breakdown of the validation data prediction and the actual classification of our test data in a confusion matrix.","03a90321":"### Compile Data and Features\nThe following code calls the above functions and outputs a dataframe with all our data, features, and labels!  It also cleans the data by dropping columns with missing values.","cd4c4df1":"# Feature Selection and Data Splitting\nWe have over 60 features, which is probably a little redundant and too much for our model to handle.  First, I split the data for training, validation, and testing the model.  Then, I employ one feature selection teqhnique of many to select the most impactful data for our model.","ef93c577":"# Data Visualization\nOften, its important to take a look at the data in order to get a deeper understanding of the problem.  I've included a few visualizations below, but I spent a lot more time throughout the semester graphing specific indicators, stocks, or other features.","9f383df7":"# Data Compiling\nThe first step of any ML project is to access the data that will be used.\n\n### Stock Data Function:\nThis function saves lots of time by compiling data from any number of stock tickers.  That data is then cleaned and pre-processed for easier usage later. Additonally, the function calls the indicators and fundamental functions (see below) to calculate features and add additonal data.","0527c595":"# Feature Engineering\nRaw data rarely provides meaninful insight for machine learning models.  The \"art\" of machine learning is combining the raw data into features that improve a model's accuracy."}}