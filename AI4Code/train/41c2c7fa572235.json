{"cell_type":{"3f443cf0":"code","9edb93af":"code","499e46d2":"code","6feb8380":"code","8802106d":"code","4c3524f2":"code","284a3dc9":"code","8625646f":"code","20835ca0":"code","c6b6ee5b":"code","25ff7de0":"code","5160578a":"code","6151bc71":"code","683e882b":"code","babeea0d":"code","b9bf076d":"code","9caebcd8":"code","b69fd06f":"code","f3ce7ec8":"code","8ada2445":"code","7e98c41c":"code","e36bef36":"code","4ebd1ce1":"code","9edc0000":"code","aaca5319":"code","f74a33df":"code","f9171749":"code","4c31677a":"code","57357a8a":"code","b1672dc8":"code","39a56da2":"code","eaf5fbd4":"code","4f70dd98":"code","21ded3c2":"code","130a2e9a":"code","e66c3e6c":"code","d39c4cd9":"code","dab5545b":"code","f30d52db":"code","471d50bc":"code","626cf688":"code","c470c098":"code","5abcb029":"code","24931778":"code","3f73a4b4":"code","f7176cf1":"code","ae2358ba":"code","3793add6":"code","2795f849":"code","f116be74":"code","c4b1c024":"code","2b313282":"code","d9ffbda3":"code","22c575e6":"code","899fea9c":"code","d1efcbd2":"code","4809421d":"code","747eb7a4":"code","a9d24564":"code","ee0cde6e":"code","eeb872b2":"code","51d8f097":"code","b50ffb4c":"code","d06442cf":"code","d2e23ea4":"code","e4364961":"code","021e50c6":"code","3cf7d925":"code","9a1f4d24":"code","a958c026":"code","6cd0aebb":"code","4c9e2390":"markdown","04bfede7":"markdown","be532d04":"markdown","500c8cfe":"markdown","b1c1c926":"markdown","2a4c6c26":"markdown","498cb4c2":"markdown","0c9fbb27":"markdown","b94e6f82":"markdown","00921f90":"markdown","535f70a7":"markdown","ddd6c5cf":"markdown","35635604":"markdown","b5a4de21":"markdown","e82c95d8":"markdown"},"source":{"3f443cf0":"#GENERAL\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nfrom keras.preprocessing import image\nfrom skimage.feature import hessian_matrix, hessian_matrix_eigvals\nfrom scipy.ndimage.filters import convolve\nfrom skimage import data, io, filters\nimport skimage\nfrom skimage.morphology import convex_hull_image, erosion\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN, LSTM, GlobalAveragePooling2D, SeparableConv2D,\\\nZeroPadding2D, Convolution2D, ZeroPadding2D, Conv2DTranspose,ReLU, UpSampling2D, Concatenate, Conv2DTranspose\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.models import load_model\nfrom keras import backend\n#SKLEARN CLASSIFIER\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","9edb93af":"Face_IMG_Path = Path(\"..\/input\/pretty-face\/face\/face\")\nFace_MASK_Path = Path(\"..\/input\/pretty-face\/layout\/layout\")","499e46d2":"IMG_List = list(Face_IMG_Path.glob(r\"*.png\"))\nMASK_List = list(Face_MASK_Path.glob(r\"*.png\"))","6feb8380":"print(\"LEN IMG LIST: \", len(IMG_List))\nprint(\"LEN MASK LIST: \", len(MASK_List))","8802106d":"IMG_Series = pd.Series(IMG_List,name=\"IMG\").astype(str)\nMASK_Series = pd.Series(MASK_List,name=\"MASK\").astype(str)","4c3524f2":"IMG_Series","284a3dc9":"MASK_Series","8625646f":"Main_Data = pd.concat([IMG_Series,MASK_Series],axis=1)","20835ca0":"Main_Data","c6b6ee5b":"print(\"CHECKING IMG NUMBER: \", Main_Data[\"IMG\"][0])\nprint(\"CHECKING MASK NUMBER: \", Main_Data[\"MASK\"][0])\nprint(\"---\"*20)\nprint(\"CHECKING IMG NUMBER: \", Main_Data[\"IMG\"][10])\nprint(\"CHECKING MASK NUMBER: \", Main_Data[\"MASK\"][10])\nprint(\"---\"*20)\nprint(\"CHECKING IMG NUMBER: \", Main_Data[\"IMG\"][2000])\nprint(\"CHECKING MASK NUMBER: \", Main_Data[\"MASK\"][2000])\nprint(\"---\"*20)","25ff7de0":"figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nExample_IMG = Main_Data[\"IMG\"][10]\nExample_MASK = Main_Data[\"MASK\"][10]\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Reading_MASK.shape)\naxis[1].set_title(\"MASK\")\naxis[1].imshow(Reading_MASK)\n\nplt.tight_layout()\nplt.show()","5160578a":"figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nExample_IMG = Main_Data[\"IMG\"][100]\nExample_MASK = Main_Data[\"MASK\"][100]\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Reading_MASK.shape)\naxis[1].set_title(\"MASK\")\naxis[1].imshow(Reading_MASK)\n\nplt.tight_layout()\nplt.show()","6151bc71":"figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nExample_IMG = Main_Data[\"IMG\"][10]\nExample_MASK = Main_Data[\"MASK\"][10]\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Reading_MASK.shape)\naxis[1].set_title(\"MASK\")\naxis[1].imshow(Reading_MASK,alpha=0.5)\n\nplt.tight_layout()\nplt.show()","683e882b":"figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nExample_IMG = Main_Data[\"IMG\"][100]\nExample_MASK = Main_Data[\"MASK\"][100]\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Reading_MASK.shape)\naxis[1].set_title(\"MASK\")\naxis[1].imshow(Reading_MASK,alpha=0.5)\n\nplt.tight_layout()\nplt.show()","babeea0d":"figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nExample_IMG = Main_Data[\"IMG\"][10]\nExample_MASK = Main_Data[\"MASK\"][10]\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Reading_MASK[:,:,0].shape)\naxis[1].set_title(\"MASK 2D\")\naxis[1].imshow(Reading_MASK[:,:,0])\n\nplt.tight_layout()\nplt.show()","b9bf076d":"figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nExample_IMG = Main_Data[\"IMG\"][100]\nExample_MASK = Main_Data[\"MASK\"][100]\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Reading_MASK[:,:,0].shape)\naxis[1].set_title(\"MASK 2D\")\naxis[1].imshow(Reading_MASK[:,:,0])\n\nplt.tight_layout()\nplt.show()","9caebcd8":"figure,axis = plt.subplots(1,2,figsize=(15,15))\n\nExample_IMG = Main_Data[\"IMG\"][10]\nExample_MASK = Main_Data[\"MASK\"][10]\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Reading_MASK[:,:,0].shape)\naxis[1].set_title(\"MASK 2D\")\nColorbar_Func = axis[1].imshow(Reading_MASK[:,:,0])\n\nfigure.colorbar(Colorbar_Func,shrink=0.5,label='LAYER')\nplt.tight_layout()\nplt.show()","b69fd06f":"figure,axis = plt.subplots(1,2,figsize=(15,15))\n\nExample_IMG = Main_Data[\"IMG\"][100]\nExample_MASK = Main_Data[\"MASK\"][100]\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Reading_MASK[:,:,0].shape)\naxis[1].set_title(\"MASK 2D\")\nColorbar_Func = axis[1].imshow(Reading_MASK[:,:,0])\n\nfigure.colorbar(Colorbar_Func,shrink=0.5,label='LAYER')\nplt.tight_layout()\nplt.show()","f3ce7ec8":"figure,axis = plt.subplots(1,2,figsize=(15,15))\n\nExample_IMG = Main_Data[\"IMG\"][10]\nExample_MASK = Main_Data[\"MASK\"][10]\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Reading_MASK[:,:,0].shape)\naxis[1].set_title(\"MASK 2D\")\nColorbar_Func = axis[1].imshow(Reading_MASK[:,:,0],cmap=\"hot\")\n\nfigure.colorbar(Colorbar_Func,shrink=0.5,label='LAYER')\nplt.tight_layout()\nplt.show()","8ada2445":"figure,axis = plt.subplots(1,2,figsize=(15,15))\n\nExample_IMG = Main_Data[\"IMG\"][100]\nExample_MASK = Main_Data[\"MASK\"][100]\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Reading_MASK[:,:,0].shape)\naxis[1].set_title(\"MASK 2D\")\nColorbar_Func = axis[1].imshow(Reading_MASK[:,:,0],cmap=\"hot\")\n\nfigure.colorbar(Colorbar_Func,shrink=0.5,label='LAYER')\nplt.tight_layout()\nplt.show()","7e98c41c":"Figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nExample_IMG = Main_Data[\"IMG\"][10]\nExample_MASK = Main_Data[\"MASK\"][10]\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Reading_MASK[:,:,0].shape)\naxis[1].set_title(\"ALL PERSON PATH\")\naxis[1].imshow(Reading_MASK[:,:,0] == 0)\n\nplt.tight_layout()\nplt.show()","e36bef36":"Figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nExample_IMG = Main_Data[\"IMG\"][100]\nExample_MASK = Main_Data[\"MASK\"][100]\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Reading_MASK[:,:,0].shape)\naxis[1].set_title(\"ALL PERSON PATH\")\naxis[1].imshow(Reading_MASK[:,:,0] == 0)\n\nplt.tight_layout()\nplt.show()","4ebd1ce1":"Figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nExample_IMG = Main_Data[\"IMG\"][10]\nExample_MASK = Main_Data[\"MASK\"][10]\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Reading_MASK[:,:,0].shape)\naxis[1].set_title(\"ONLY FACE\")\naxis[1].imshow(Reading_MASK[:,:,0] == 1)\n\nplt.tight_layout()\nplt.show()","9edc0000":"Figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nExample_IMG = Main_Data[\"IMG\"][100]\nExample_MASK = Main_Data[\"MASK\"][100]\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Reading_MASK[:,:,0].shape)\naxis[1].set_title(\"ONLY FACE\")\naxis[1].imshow(Reading_MASK[:,:,0] == 1)\n\nplt.tight_layout()\nplt.show()","aaca5319":"Figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nExample_IMG = Main_Data[\"IMG\"][10]\nExample_MASK = Main_Data[\"MASK\"][10]\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Reading_MASK[:,:,0].shape)\naxis[1].set_title(\"NOSE\")\naxis[1].imshow(Reading_MASK[:,:,0] == 10)\n\nplt.tight_layout()\nplt.show()","f74a33df":"Figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nExample_IMG = Main_Data[\"IMG\"][100]\nExample_MASK = Main_Data[\"MASK\"][100]\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Reading_MASK[:,:,0].shape)\naxis[1].set_title(\"NOSE\")\naxis[1].imshow(Reading_MASK[:,:,0] == 10)\n\nplt.tight_layout()\nplt.show()","f9171749":"Figure,axis = plt.subplots(1,3,figsize=(10,10))\n\nExample_IMG = Main_Data[\"IMG\"][10]\nExample_MASK = Main_Data[\"MASK\"][10]\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Reading_MASK[:,:,0].shape)\naxis[1].set_title(\"LEFT EYE\")\naxis[1].imshow(Reading_MASK[:,:,0] == 4)\n\naxis[2].set_xlabel(Reading_MASK[:,:,0].shape)\naxis[2].set_title(\"RIGHT EYE\")\naxis[2].imshow(Reading_MASK[:,:,0] == 5)\n\nplt.tight_layout()\nplt.show()","4c31677a":"Figure,axis = plt.subplots(1,3,figsize=(10,10))\n\nExample_IMG = Main_Data[\"IMG\"][100]\nExample_MASK = Main_Data[\"MASK\"][100]\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Reading_MASK[:,:,0].shape)\naxis[1].set_title(\"LEFT EYE\")\naxis[1].imshow(Reading_MASK[:,:,0] == 5)\n\naxis[2].set_xlabel(Reading_MASK[:,:,0].shape)\naxis[2].set_title(\"RIGHT EYE\")\naxis[2].imshow(Reading_MASK[:,:,0] == 4)\n\nplt.tight_layout()\nplt.show()","57357a8a":"Figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nExample_IMG = Main_Data[\"IMG\"][10]\nExample_MASK = Main_Data[\"MASK\"][10]\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\nAll_Person_Path = Reading_MASK[:,:,0] == 0\nFace_Path = Reading_MASK[:,:,0] == 1\n\nCopy_IMG = Reading_IMG.copy()\nCopy_IMG[All_Person_Path] = [255,0,0]\nCopy_IMG[Face_Path] = [0,0,255]\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Copy_IMG.shape)\naxis[1].set_title(\"LAYER TRANSFORMED\")\naxis[1].imshow(Copy_IMG)\n\nplt.tight_layout()\nplt.show()","b1672dc8":"Figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nExample_IMG = Main_Data[\"IMG\"][100]\nExample_MASK = Main_Data[\"MASK\"][100]\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\nAll_Person_Path = Reading_MASK[:,:,0] == 0\nFace_Path = Reading_MASK[:,:,0] == 1\n\nCopy_IMG = Reading_IMG.copy()\nCopy_IMG[All_Person_Path] = [255,0,0]\nCopy_IMG[Face_Path] = [0,0,255]\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Copy_IMG.shape)\naxis[1].set_title(\"LAYER TRANSFORMED\")\naxis[1].imshow(Copy_IMG)\n\nplt.tight_layout()\nplt.show()","39a56da2":"Figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nExample_IMG = Main_Data[\"IMG\"][10]\nExample_MASK = Main_Data[\"MASK\"][10]\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\nAll_Person_Path = Reading_MASK[:,:,0] == 0\nFace_Path = Reading_MASK[:,:,0] == 1\n\nCopy_IMG = Reading_IMG.copy()\nCopy_IMG[All_Person_Path == 0] = [255,0,0]\nCopy_IMG[Face_Path == 1] = [0,0,255]\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Copy_IMG.shape)\naxis[1].set_title(\"LAYER TRANSFORMED\")\naxis[1].imshow(Copy_IMG)\n\nplt.tight_layout()\nplt.show()","eaf5fbd4":"Figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nExample_IMG = Main_Data[\"IMG\"][100]\nExample_MASK = Main_Data[\"MASK\"][100]\n\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\n\nAll_Person_Path = Reading_MASK[:,:,0] == 0\nFace_Path = Reading_MASK[:,:,0] == 1\n\nCopy_IMG = Reading_IMG.copy()\nCopy_IMG[All_Person_Path == 0] = [255,0,0]\nCopy_IMG[Face_Path == 1] = [0,0,255]\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Copy_IMG.shape)\naxis[1].set_title(\"LAYER TRANSFORMED\")\naxis[1].imshow(Copy_IMG)\n\nplt.tight_layout()\nplt.show()","4f70dd98":"Figure,axis = plt.subplots(1,3,figsize=(10,10))\n\nExample_IMG = Main_Data[\"IMG\"][10]\nExample_MASK = Main_Data[\"MASK\"][10]\nAll_Person_Path = np.array(Reading_MASK[:,:,0] == 0,dtype=np.uint8)\nFace_Path = np.array(Reading_MASK[:,:,0] == 1,dtype=np.uint8)\n\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\n\nAll_Person_Path = np.array(Reading_MASK[:,:,0] == 0,dtype=np.uint8)\nFace_Path = np.array(Reading_MASK[:,:,0] == 1,dtype=np.uint8)\nTrans_Path = cv2.bitwise_and(Reading_IMG[:,:,0],Face_Path,mask=Face_Path)\nTrans_Path_Two = cv2.bitwise_and(Reading_IMG[:,:,0],All_Person_Path,mask=All_Person_Path)\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Trans_Path.shape)\naxis[1].set_title(\"LAYER TRANSFORMED\")\naxis[1].imshow(Trans_Path)\n\naxis[2].set_xlabel(Trans_Path_Two.shape)\naxis[2].set_title(\"LAYER TRANSFORMED\")\naxis[2].imshow(Trans_Path_Two)\n\nplt.tight_layout()\nplt.show()","21ded3c2":"Figure,axis = plt.subplots(1,3,figsize=(10,10))\n\nExample_IMG = Main_Data[\"IMG\"][100]\nExample_MASK = Main_Data[\"MASK\"][100]\nAll_Person_Path = np.array(Reading_MASK[:,:,0] == 0,dtype=np.uint8)\nFace_Path = np.array(Reading_MASK[:,:,0] == 1,dtype=np.uint8)\n\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\n\nTrans_Path = cv2.bitwise_and(Reading_IMG[:,:,0],Face_Path,mask=Face_Path)\nTrans_Path_Two = cv2.bitwise_and(Reading_IMG[:,:,0],All_Person_Path,mask=All_Person_Path)\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Trans_Path.shape)\naxis[1].set_title(\"LAYER TRANSFORMED\")\naxis[1].imshow(Trans_Path)\n\naxis[2].set_xlabel(Trans_Path_Two.shape)\naxis[2].set_title(\"LAYER TRANSFORMED\")\naxis[2].imshow(Trans_Path_Two)\n\nplt.tight_layout()\nplt.show()","130a2e9a":"Figure,axis = plt.subplots(1,5,figsize=(20,20))\n\nExample_IMG = Main_Data[\"IMG\"][100]\nExample_MASK = Main_Data[\"MASK\"][100]\n\nReading_IMG = cv2.cvtColor(cv2.imread(Example_IMG),cv2.COLOR_BGR2RGB)\nReading_MASK = cv2.cvtColor(cv2.imread(Example_MASK),cv2.COLOR_BGR2RGB)\n\nFace_Path = np.array(Reading_MASK[:,:,0] == 1,dtype=\"uint8\")\n\nNot_Bitwise = cv2.bitwise_not(Face_Path)\nOR_Bitwise = cv2.bitwise_or(Reading_IMG[:,:,0],Face_Path)\nAND_Bitwise = cv2.bitwise_and(Reading_IMG[:,:,0],Face_Path)\n\n\nCopy_IMG = Reading_IMG.copy()\nCopy_IMG[All_Person_Path] = [255,0,0]\nCopy_IMG[Face_Path] = [0,0,255]\n\naxis[0].set_xlabel(Reading_IMG.shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(Reading_IMG)\n\naxis[1].set_xlabel(Face_Path.shape)\naxis[1].set_title(\"FACE\")\naxis[1].imshow(Face_Path,cmap=\"gray\")\n\naxis[2].set_xlabel(Not_Bitwise.shape)\naxis[2].set_title(\"Not_Bitwise\")\naxis[2].imshow(Not_Bitwise,cmap=\"gray\")\n\naxis[3].set_xlabel(OR_Bitwise.shape)\naxis[3].set_title(\"OR_Bitwise\")\naxis[3].imshow(OR_Bitwise,cmap=\"gray\")\n\naxis[4].set_xlabel(AND_Bitwise.shape)\naxis[4].set_title(\"AND_Bitwise\")\naxis[4].imshow(AND_Bitwise,cmap=\"gray\")\n\nplt.tight_layout()\nplt.show()","e66c3e6c":"figure,axis = plt.subplots(8,8,figsize=(20,20))\n\nfor indexing,operations in enumerate(axis.flat):\n    \n    Target_IMG = Main_Data[\"IMG\"][indexing]\n    Target_MASK = Main_Data[\"MASK\"][indexing]\n    Reading_IMG = cv2.cvtColor(cv2.imread(Target_IMG),cv2.COLOR_BGR2RGB)\n    Reading_MASK = cv2.cvtColor(cv2.imread(Target_MASK),cv2.COLOR_BGR2RGB)\n    Face_Path = Reading_MASK[:,:,0] == 1\n    Copy_IMG = Reading_IMG.copy()\n    Copy_IMG[Face_Path == 1] = [255,0,0]\n    \n    operations.imshow(Copy_IMG)\n    operations.axis(\"off\")\n    \nplt.tight_layout()\nplt.show()","d39c4cd9":"figure,axis = plt.subplots(8,8,figsize=(20,20))\n\nfor indexing,operations in enumerate(axis.flat):\n    \n    Target_IMG = Main_Data[\"IMG\"][indexing]\n    Target_MASK = Main_Data[\"MASK\"][indexing]\n    Reading_IMG = cv2.cvtColor(cv2.imread(Target_IMG),cv2.COLOR_BGR2RGB)\n    Reading_MASK = cv2.cvtColor(cv2.imread(Target_MASK),cv2.COLOR_BGR2RGB)\n    Face_Path = Reading_MASK[:,:,0] == 1\n    Copy_IMG = Reading_IMG.copy()\n    Copy_IMG[Face_Path == 1] = [255,0,0]\n    \n    operations.imshow(Copy_IMG[:,:,0],cmap=\"jet\")\n    operations.axis(\"off\")\n    \nplt.tight_layout()\nplt.show()","dab5545b":"figure,axis = plt.subplots(8,8,figsize=(20,20))\n\nfor indexing,operations in enumerate(axis.flat):\n    \n    Target_IMG = Main_Data[\"IMG\"][indexing]\n    Target_MASK = Main_Data[\"MASK\"][indexing]\n    Reading_IMG = cv2.cvtColor(cv2.imread(Target_IMG),cv2.COLOR_BGR2RGB)\n    Reading_MASK = cv2.cvtColor(cv2.imread(Target_MASK),cv2.COLOR_BGR2RGB)\n    Face_Path = np.array(Reading_MASK[:,:,0] == 1,dtype=\"uint8\")\n    AND_Bitwise = cv2.bitwise_and(Reading_IMG[:,:,0],Face_Path)\n    \n    operations.imshow(AND_Bitwise,cmap=\"gray\")\n    operations.axis(\"off\")\n    \nplt.tight_layout()\nplt.show()","f30d52db":"New_IMG = []\nNew_MASK = []\n\n\nfor x_img,x_mask in zip(Main_Data.IMG,Main_Data.MASK):\n    \n    Reading_IMG = cv2.cvtColor(cv2.imread(x_img),cv2.COLOR_BGR2RGB)\n    Reading_MASK = cv2.cvtColor(cv2.imread(x_mask),cv2.COLOR_BGR2RGB)\n    \n    Face_Path = np.array(Reading_MASK[:,:,0] == 1,dtype=np.uint8)\n    \n    Resized_IMG = cv2.resize(Reading_IMG,(180,180))\n    Resized_Path = cv2.resize(Face_Path,(180,180))\n\n    \n    Resized_IMG = Resized_IMG \/ 255.\n    Resized_Path = Resized_Path \/ 255.\n\n    \n    New_IMG.append(Resized_IMG)\n    New_MASK.append(Resized_Path)\n","471d50bc":"Bitwise_And_List = []\n\nfor x_img,x_mask in zip(Main_Data.IMG,Main_Data.MASK):\n    \n    Reading_IMG = cv2.cvtColor(cv2.imread(x_img),cv2.COLOR_BGR2RGB)\n    Reading_MASK = cv2.cvtColor(cv2.imread(x_mask),cv2.COLOR_BGR2RGB)\n    \n    Face_Path = np.array(Reading_MASK[:,:,0] == 1,dtype=np.uint8)\n    AND_Bitwise = cv2.bitwise_and(Reading_IMG[:,:,0],Face_Path)\n    \n    Resized_Bit = cv2.resize(AND_Bitwise,(180,180))\n    \n    Resized_Bit = Resized_Bit \/ 255.\n    \n    Bitwise_And_List.append(Resized_Bit)","626cf688":"print(\"SHAPE IMG: \", np.shape(np.array(New_IMG)))\nprint(\"SHAPE MASK: \", np.shape(np.array(New_MASK)))\nprint(\"SHAPE BITWISE: \", np.shape(np.array(Bitwise_And_List)))\n","c470c098":"Figure,axis = plt.subplots(1,3,figsize=(10,10))\n\naxis[0].set_xlabel(New_IMG[0].shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(New_IMG[0])\n\naxis[1].set_xlabel(New_MASK[0].shape)\naxis[1].set_title(\"MASK\")\naxis[1].imshow(New_MASK[0])\n\naxis[2].set_xlabel(Bitwise_And_List[0].shape)\naxis[2].set_title(\"BITWISE\")\naxis[2].imshow(Bitwise_And_List[0])\n\nplt.tight_layout()\nplt.show()","5abcb029":"Figure,axis = plt.subplots(1,3,figsize=(10,10))\n\naxis[0].set_xlabel(New_IMG[10].shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(New_IMG[10])\n\naxis[1].set_xlabel(New_MASK[10].shape)\naxis[1].set_title(\"MASK\")\naxis[1].imshow(New_MASK[10])\n\naxis[2].set_xlabel(Bitwise_And_List[10].shape)\naxis[2].set_title(\"BITWISE\")\naxis[2].imshow(Bitwise_And_List[10])\n\nplt.tight_layout()\nplt.show()","24931778":"Figure,axis = plt.subplots(1,3,figsize=(10,10))\n\naxis[0].set_xlabel(New_IMG[2000].shape)\naxis[0].set_title(\"IMG\")\naxis[0].imshow(New_IMG[2000])\n\naxis[1].set_xlabel(New_MASK[2000].shape)\naxis[1].set_title(\"MASK\")\naxis[1].imshow(New_MASK[2000])\n\naxis[2].set_xlabel(Bitwise_And_List[2000].shape)\naxis[2].set_title(\"BITWISE\")\naxis[2].imshow(Bitwise_And_List[2000])\n\nplt.tight_layout()\nplt.show()","3f73a4b4":"Test_IMG = New_IMG[:2000]\nTest_MASK = New_MASK[:2000]","f7176cf1":"print(len(Test_IMG))\nprint(len(Test_MASK))","ae2358ba":"IMG_Array = np.array(Test_IMG,dtype=\"float32\")\nMASK_Array = np.array(Test_MASK,dtype=\"float32\")","3793add6":"Testing_IMG = np.array(New_IMG[2000:2010],dtype=\"float32\")","2795f849":"COMPILE_LOSS = \"binary_crossentropy\"\nCOMPILE_OPTIMIZER = Adam(lr=0.000001)\nCOMPILE_METRIC = [\"mse\"]\nOUTPUT_CLASS = 1","f116be74":"Checkpoint_Model = tf.keras.callbacks.ModelCheckpoint(monitor=\"val_accuracy\",\n                                                      save_best_only=True,\n                                                      save_weights_only=True,\n                                                      filepath=\".\/modelcheck\")\nReduce_Model = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",factor=0.1,patience=3)","c4b1c024":"Enc_M = Sequential()\nEnc_M.add(Conv2D(32,(2,2),kernel_initializer = 'he_normal',padding=\"same\"))\nEnc_M.add(BatchNormalization())\nEnc_M.add(ReLU())\n#\nEnc_M.add(Conv2D(64,(2,2),kernel_initializer = 'he_normal',padding=\"same\"))\nEnc_M.add(BatchNormalization())\nEnc_M.add(ReLU())\n#\nEnc_M.add(Conv2D(128,(2,2),kernel_initializer = 'he_normal',padding=\"same\"))\nEnc_M.add(BatchNormalization())\nEnc_M.add(ReLU())","2b313282":"Dec_M = Sequential()\nDec_M.add(Conv2DTranspose(64,(2,2),padding=\"same\"))\nDec_M.add(ReLU())\n#\nDec_M.add(Conv2DTranspose(32,(2,2),padding=\"same\"))\nDec_M.add(ReLU())\n#\nDec_M.add(Conv2DTranspose(OUTPUT_CLASS,(2,2),padding=\"same\"))\nDec_M.add(ReLU())","d9ffbda3":"Auto_Encoder = Sequential([Enc_M,Dec_M])","22c575e6":"Auto_Encoder.compile(loss=COMPILE_LOSS,optimizer=COMPILE_OPTIMIZER,metrics=COMPILE_METRIC)","899fea9c":"Auto_Encoder_Model = Auto_Encoder.fit(IMG_Array,MASK_Array,epochs=7,callbacks=[Reduce_Model,Checkpoint_Model])","d1efcbd2":"Prediction_IMG = Auto_Encoder.predict(IMG_Array[:30])","4809421d":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 1\n\nOriginal_Img = IMG_Array[prediction_img_number]\nPredict_Mask = Prediction_IMG[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","747eb7a4":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 2\n\nOriginal_Img = IMG_Array[prediction_img_number]\nPredict_Mask = Prediction_IMG[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","a9d24564":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 3\n\nOriginal_Img = IMG_Array[prediction_img_number]\nPredict_Mask = Prediction_IMG[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","ee0cde6e":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 4\n\nOriginal_Img = IMG_Array[prediction_img_number]\nPredict_Mask = Prediction_IMG[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","eeb872b2":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 7\n\nOriginal_Img = IMG_Array[prediction_img_number]\nPredict_Mask = Prediction_IMG[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","51d8f097":"Prediction_IMG_NONSEEN = Auto_Encoder.predict(Testing_IMG)","b50ffb4c":"figure = plt.figure(figsize=(10,10))\n\nprediction_img_number = 1\n\n\nPredict_Mask = Prediction_IMG_NONSEEN[prediction_img_number]\n\nplt.imshow(Predict_Mask)\nplt.xlabel(Predict_Mask.shape)\nplt.ylabel(Predict_Mask.size)\nplt.title(\"MASK\")","d06442cf":"figure = plt.figure(figsize=(10,10))\n\nprediction_img_number = 2\n\n\nPredict_Mask = Prediction_IMG_NONSEEN[prediction_img_number]\n\nplt.imshow(Predict_Mask)\nplt.xlabel(Predict_Mask.shape)\nplt.ylabel(Predict_Mask.size)\nplt.title(\"MASK\")","d2e23ea4":"figure = plt.figure(figsize=(10,10))\n\nprediction_img_number = 3\n\n\nPredict_Mask = Prediction_IMG_NONSEEN[prediction_img_number]\n\nplt.imshow(Predict_Mask)\nplt.xlabel(Predict_Mask.shape)\nplt.ylabel(Predict_Mask.size)\nplt.title(\"MASK\")","e4364961":"figure = plt.figure(figsize=(10,10))\n\nprediction_img_number = 4\n\n\nPredict_Mask = Prediction_IMG_NONSEEN[prediction_img_number]\n\nplt.imshow(Predict_Mask,cmap=\"jet\")\nplt.xlabel(Predict_Mask.shape)\nplt.ylabel(Predict_Mask.size)\nplt.title(\"MASK\")","021e50c6":"figure = plt.figure(figsize=(10,10))\n\nprediction_img_number = 5\n\n\nPredict_Mask = Prediction_IMG_NONSEEN[prediction_img_number]\n\nplt.imshow(Predict_Mask,cmap=\"jet\")\nplt.xlabel(Predict_Mask.shape)\nplt.ylabel(Predict_Mask.size)\nplt.title(\"MASK\")","3cf7d925":"figure = plt.figure(figsize=(10,10))\n\nprediction_img_number = 6\n\n\nPredict_Mask = Prediction_IMG_NONSEEN[prediction_img_number]\n\nplt.imshow(Predict_Mask,cmap=\"hot\")\nplt.xlabel(Predict_Mask.shape)\nplt.ylabel(Predict_Mask.size)\nplt.title(\"MASK\")","9a1f4d24":"figure = plt.figure(figsize=(10,10))\n\nprediction_img_number = 7\n\n\nPredict_Mask = Prediction_IMG_NONSEEN[prediction_img_number]\n\nplt.imshow(Predict_Mask,cmap=\"hot\")\nplt.xlabel(Predict_Mask.shape)\nplt.ylabel(Predict_Mask.size)\nplt.title(\"MASK\")","a958c026":"figure = plt.figure(figsize=(10,10))\n\nprediction_img_number = 8\n\n\nPredict_Mask = Prediction_IMG_NONSEEN[prediction_img_number]\n\nplt.imshow(Predict_Mask,cmap=\"hot\")\nplt.xlabel(Predict_Mask.shape)\nplt.ylabel(Predict_Mask.size)\nplt.title(\"MASK\")","6cd0aebb":"figure = plt.figure(figsize=(10,10))\n\nprediction_img_number = 9\n\n\nPredict_Mask = Prediction_IMG_NONSEEN[prediction_img_number]\n\nplt.imshow(Predict_Mask,cmap=\"hot\")\nplt.xlabel(Predict_Mask.shape)\nplt.ylabel(Predict_Mask.size)\nplt.title(\"MASK\")","4c9e2390":"#### LAYER TRANSFORMING","04bfede7":"# MODEL PROCESS","be532d04":"#### TO DATAFRAME","500c8cfe":"# PATH,LABEL,TRANSFORMATION PROCESS","b1c1c926":"#### IMAGE PATH","2a4c6c26":"#### SIMPLE","498cb4c2":"#### MAIN","0c9fbb27":"# DATA PROCESS","b94e6f82":"# VISION","00921f90":"# HISTORY\n\n#### Context\n* A generative adversarial network (GAN) is a class of machine learning frameworks that generate new fake data deceptively from real data. It was invented in just 2014, but its applications have increased rapidly. It has also been used successfully in lots of areas, including fashion, art, advertising, and science.\n\n* GANs can be used to achieve image-to-image translation, where the generation of the output image is conditional on an input. I think it would be interesting to use segmentation layouts or sketches as inputs to let the model generate pretty faces. Right, pretty or not is a matter of taste). Fortunately, I found one paper, Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation(Encoding in Style), which published recently has paved the road to this imaginary transformation\n\n#### Content\n* The benefit of GANs is that it can provide unlimited data. If I want to create a dataset with pretty-face, why not use a GAN pre-trained on celebrities. Why celebrities? Because it's heuristic that there are more good-looking people in the group of stars than in the group of ordinary people. Since a GAN learn the distribution of its training data, it masks sense to select stars as training data. Luckily, when I was searching for a proper dataset, I found someone has already trained a StyleGAN2 on an ideal dataset that has 95600 512*512 faces from 500 Chinese stars.\n\n* Since not all the stars in the training dataset have beautiful faces, the GAN images are not all pretty. A model's problem can be solved using another model. Here, I used the model to generate about 3000 pictures and manually selected those that look not bad. Using not bad images and the same number of other images, I prepared a dataset to train a binary classifier using MixNet-S as the backbone. This model can filter qualified faces from the GANs' products. Next, StyleGAN2 generated another 30,000 images, and the classifier selected 3318 not-bad from them. Finally, these images are collected as the dataset for the following training.","535f70a7":"#### 2-DIMENSION","ddd6c5cf":"# PACKAGES AND LIBRARIES","35635604":"#### TO SERIES","b5a4de21":"#### PART","e82c95d8":"#### ALPHA"}}