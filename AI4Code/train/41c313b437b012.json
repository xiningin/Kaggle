{"cell_type":{"e1a08590":"code","1282ee20":"code","435d7b6d":"code","5b32a1e6":"code","b51b4ba0":"code","3b3e3df8":"code","7d6e658e":"code","ac3275c8":"code","464a64c2":"code","dd9e841c":"code","59eccb69":"code","1aaf2648":"code","1e5416a2":"code","b7dd1d2b":"code","da96ee1b":"code","f7290ddb":"code","940fe585":"code","732e2056":"code","ac5dd8c5":"code","c2237e4c":"code","67688aa2":"code","ee47690d":"code","901b47f4":"code","567c9437":"code","757fcbcf":"code","6e214dee":"code","d6d49804":"code","ee10d3f5":"code","9bff3f79":"code","2d1104fd":"code","eef769ce":"code","1b5d22b5":"code","d7b8dddf":"code","72e74197":"code","c71e7724":"code","ebe4477f":"code","0046fb8a":"markdown","bd7b3041":"markdown","b8c2b7ca":"markdown","e423f60f":"markdown","c4dad0b9":"markdown"},"source":{"e1a08590":"#import all the libraries\nimport os\nimport string\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.optim import Adam\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\nimport torchvision\n#from torchvision import models\nfrom torchvision import transforms\nfrom torchvision.transforms import ToTensor, Normalize","1282ee20":"#ord('C') - ord('A')","435d7b6d":"#Train dataset config \n# Two mappings have been made here. \n#The first is from charachter to integer and the second is from integer to charachter. So first I did integer mapping from charachter.\nclass ASLDatasetTrain(Dataset):\n    char_to_int = {c: ord(c) - ord('A') for c in string.ascii_uppercase} #I have created a dictionary here.\n    char_to_int['del'] = 26\n    char_to_int['nothing'] = 27\n    char_to_int['space'] = 28\n    int_to_char = {value: key for key, value in char_to_int.items()}\n    #asci_uppercase mainly return the all upper case alphabet and i take e key value. Suppose if the alphabet 'A' then the outcome is zero.\n    #More explanation suppose if you run ord('A') then you get the A alphabet value but we need to sort out of all the values so \n    #what we've done here is we've got a key value for each alphabet.\n    #Where the value of A is zero then the value of B continuously is 2 and thus I have taken 26 key values of 26 alphabets.\n    #And thats the way to get the each key value - ord('B') - ord('A')\n    #Since I have taken the key value of our 27 alphabets as 26 (0-25), \n    #on the other hand I had 3 extra classes and I have taken those 3 classes as 26, 27, 28 respectively.\n    #And finally i convert to integer value to character value.\n        \n    def __init__(self, directory: str, transform=None, label_transform=None):\n        #I have given some parameters here where I have set the directory which means I have input the directory in which I have the dataset. \n        #Then I did no transformation for the dataset and did the label transformation none.\n        super().__init__()\n        \n        self.directory = directory #Since I have created separate functions for train and test, I have just given a directory here.\n        self.transform = transform\n        self.label_transform = label_transform\n        \n        self.x = None\n        self.y = None\n        # This portion I am setting the data as none and also setting the target as none.\n        self._load_images()\n        #And finally i call my helper function.\n    \n    def __getitem__(self, idx):\n        x, y = torchvision.io.read_image(self.x[idx]).type(torch.float32), self.y[idx]\n        \n        if self.transform:\n            x = self.transform(x)\n        if self.label_transform:\n            y = self.label_transform(y)\n        \n        return x, y\n    \n    def __len__(self):\n        return len(self.y)\n    \n    def _load_images(self):\n        self.x = []\n        self.y = []\n        \n        for c in os.listdir(self.directory):\n            class_name = c\n            class_dir = os.path.join(self.directory, class_name)\n            for img in os.listdir(class_dir):\n                self.x.append(os.path.join(class_dir, img))\n                self.y.append(self.char_to_int[class_name])\n                \n        self.y = torch.tensor(self.y, dtype=torch.int64)\n    #I set the directory which is train or test, whatever it is, I will run a loop in all the folders. \n    #I am running a list of all the folders that I have set in self.directory. We can see from the dataset that the name of the directory is the class name. \n    #Then the class name will be (C). Then we enter the class directory and return all the files \/ folders in that directory.\n    #At the end of in the load image function, \n    #all image paths are being stored in self.x and all image labels are being stored in self.y.\n    @staticmethod\n    def get_classname(idx: int) -> str:\n        return ASLDatasetTrain.int_to_char[idx] # This function mainly work, suppose if you take (0) id then it returns alphabet (A) mainly this function return integer to charachter value.","5b32a1e6":"#Test dataset config\nclass ASLDatasetTest(Dataset):\n    char_to_int = {c: ord(c) - ord('A') for c in string.ascii_uppercase}\n    char_to_int['del'] = 26\n    char_to_int['nothing'] = 27\n    char_to_int['space'] = 28\n    int_to_char = {value: key for key, value in char_to_int.items()}\n        \n    def __init__(self, directory: str, transform=None, label_transform=None):\n        super().__init__()\n        \n        self.directory = directory\n        self.transform = transform\n        self.label_transform = label_transform\n        \n        self.x = None\n        self.y = None\n        \n        self._load_images()\n    \n    def __getitem__(self, idx):\n        x, y = torchvision.io.read_image(self.x[idx]).type(torch.float32), self.y[idx]\n        \n        if self.transform:\n            x = self.transform(x)\n        if self.label_transform:\n            y = self.label_transform(y)\n        \n        return x, y\n    \n    def __len__(self):\n        return len(self.y)\n    \n    def _load_images(self):\n        self.x = []\n        self.y = []\n        \n        for img in os.listdir(self.directory):\n            class_name = img [:1]\n            if 'space' in img:\n                class_name = 'space'\n            elif 'nothing' in img:\n                class_name = 'nothing'\n            elif 'del' in img:\n                class_name = 'del'    \n            self.x.append(os.path.join(self.directory, img))\n            self.y.append(self.char_to_int[class_name])\n                \n        self.y = torch.tensor(self.y, dtype=torch.int64)\n    \n    @staticmethod\n    def get_classname(idx: int) -> str:\n        return ASLDatasetTest.int_to_char[idx]\n    #The DatasetTest function will work the same as the DatasetTrain function, but the load image function will change a bit because my test dataset was a little different. \n    #The test dataset contained all the images in a folder, so I used a condition in the load image function. \n    #In that condition if the name of the image is 'space', 'nothing' or 'dell' then the class name will be 'space', 'nothing' or 'dell'.","b51b4ba0":"#Transformation\nts = transforms.Compose([\n    transforms.Resize(256),\n    transforms.RandomCrop(224),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n])\n#Here's what I think, \n#resize has taken more than the required size of an image here (256) and taken randomly (224).\n#And also i think that are ratio issues thats why use the size 256.\n#Since I am using AlexNet, this value works best to normalize so I am using it.","3b3e3df8":"#All the data store in train and test\ntrain = ASLDatasetTrain('..\/input\/fingerdataset\/dataset\/train', transform=ts)\ntest = ASLDatasetTest('..\/input\/fingerdataset\/dataset\/test', transform=ts)\n#Now we will load the data as my test dataset is different so I have taken two functions to load.","7d6e658e":"#Train and test data print\nprint(len(train))\nprint(len(test))","ac3275c8":"#test path\ntest.x\n#to check the each data ","464a64c2":"#train path\ntrain.x\n#to check the each data","dd9e841c":"#sampler\ntrain_sampler = SubsetRandomSampler(np.arange(len(train)))\ntest_sampler = SubsetRandomSampler(np.arange(len(test)))","59eccb69":"#train and test loader using sampler\ntrain_loader = DataLoader(train, 32, sampler=train_sampler)\ntest_loader = DataLoader(test, 32, sampler=test_sampler)\n#we create data loader with 32-32","1aaf2648":"for x, y in train_loader:\n    print(x.shape)\n    print(y.shape)\n#To check the shape of the train loader\n#Each mini-batch has 32 images and 3 color channels and dimension 224 * 224.","1e5416a2":"class AlexNet(nn.Module):\n    def __init__(self, num_classes: int = 1000) -> None:\n        super(AlexNet, self).__init__()\n        \n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n        )\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n        \n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, num_classes),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x","b7dd1d2b":"model = AlexNet(29)\n#Initially there are 1000 classes here, \n#but since I have 29 classes here, I will define them in parameters.","da96ee1b":"#using adam optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = Adam(model.parameters(), lr=0.0001)\n","f7290ddb":"#print minibatch of the train data\nprint(len(train_loader.dataset))\nprint(len(train_loader))\n#to check total data and mini-batch","940fe585":"epochs = 20\n\nfor e in range(epochs):\n    running_loss = 0.0\n    \n    for i, (imgs, labels) in enumerate(train_loader):\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        if i % 13 == 12:\n            print('[Epoch %d, Step %5d] loss: %.3f' %\n                  (e + 1, i + 1, running_loss \/ 13))\n            running_loss = 0.0\n#I want the result after 13 mini-batch so I have set 13 in condition.","732e2056":"def test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    test_loss \/= num_batches\n    correct \/= size\n    print(f\"Test Error: \\nAccuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")","ac5dd8c5":"test(test_loader, model, nn.CrossEntropyLoss())","c2237e4c":"#each class wise accuracy\nclass_correct = list(0. for i in range(29))\nclass_total = list(0. for i in range(29))\n\nwith torch.no_grad():\n    for data in test_loader:\n        images, labels = data\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n        c = (predicted == labels).squeeze()\n        for i in range(len(labels)):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\n\nfor i in range(29):\n    print('Accuracy of %5s : %2d %%' % (\n        ASLDatasetTest.int_to_char[i], 100 * class_correct[i] \/ class_total[i]))","67688aa2":"from torchvision import models","ee47690d":"model = models.alexnet(pretrained=True)","901b47f4":"for param in model.parameters():\n    param.requires_grad = False","567c9437":"print(model)\n#To check the model","757fcbcf":"\nnew_clf = nn.Sequential(\n    nn.Dropout(p=0.5, inplace=False),\n    nn.Linear(in_features=9216, out_features=4096, bias=True),\n    nn.ReLU(inplace=True),\n    nn.Dropout(p=0.5, inplace=False),\n    nn.Linear(in_features=4096, out_features=4096, bias=True),\n    nn.ReLU(inplace=True),\n    nn.Linear(in_features=4096, out_features=1000, bias=True),\n    nn.ReLU(inplace=True),\n    nn.Linear(in_features=1000, out_features=29, bias=True),\n)\n#Initially they define 1000 feature\/class but i set the manually features 29","6e214dee":"model.classifier = new_clf\n#I have replaced the new classifier I created in the previous classifier.","d6d49804":"criterion = nn.CrossEntropyLoss()\noptimizer = Adam(model.parameters(), lr=0.0001)","ee10d3f5":"epochs = 20\n\nfor e in range(epochs):\n    running_loss = 0.0\n    for i, (imgs, labels) in enumerate(train_loader):\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        if i % 13 == 12:\n            print('[Epoch %d, Step %5d] loss: %.3f' %\n                  (e + 1, i + 1, running_loss \/ 13))\n            running_loss = 0.0","9bff3f79":"test(test_loader, model, nn.CrossEntropyLoss())","2d1104fd":"#Used resnet 101 instead of resnet 152\nmodel = models.resnet101(pretrained=True)","eef769ce":"print(model)","1b5d22b5":"#create new fully connected layer which is the initially features 1000 but i need 29 features so i set this value.\nnew_fc = torch.nn.Sequential(\n    nn.Linear(in_features=2048, out_features=1000, bias=True),\n    nn.ReLU(inplace=True),\n    nn.Linear(in_features=1000, out_features=29, bias=True),\n)","d7b8dddf":"#As usal replace new fully connected layer\nmodel.fc = new_fc","72e74197":"criterion = nn.CrossEntropyLoss()\noptimizer = Adam(model.parameters(), lr=0.0001)","c71e7724":"epochs = 5\n\nfor e in range(epochs):\n    running_loss = 0.0\n    for i, (imgs, labels) in enumerate(train_loader):\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        if i % 13 == 12:\n            print('[Epoch %d, Step %5d] loss: %.3f' %\n                  (e + 1, i + 1, running_loss \/ 12))\n            running_loss = 0.0\n#As usal i want the result after 13 mini-batch so I have set 13 in condition and set 5 iteration.","ebe4477f":"test(test_loader, model, nn.CrossEntropyLoss())","0046fb8a":"# **Alexnet**","bd7b3041":"# **Name: Md. Azharul Islam <br>\n# ID: 181-35-2329**\n","b8c2b7ca":"# **Pre-trained AlexNet**","e423f60f":"**Issue on kaggle anyone trying to download the model will fail if the internet option is off at the bottom right.**","c4dad0b9":"# ResNet101"}}