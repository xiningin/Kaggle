{"cell_type":{"885f3937":"code","48589dfc":"code","2a00560c":"code","16aaa574":"code","27c4d03d":"code","94394539":"code","d831c16e":"code","cfc18f5f":"code","ee64c1fd":"code","603cb6c7":"code","ed1763e7":"code","15bd6e8d":"code","3935754c":"code","091c2611":"code","b70bd6e7":"code","d3d78106":"code","36468a1f":"code","30cfb418":"code","988cc0c9":"code","c1cce06f":"code","931b49e8":"code","076915d0":"code","f9276eb3":"code","d25cf5f7":"code","97f76eb6":"code","8f1a1437":"code","f2646a06":"code","bdc5c7f7":"code","80d9bc18":"code","69fd4043":"code","658d3be4":"markdown","9d9a8f37":"markdown","1440908b":"markdown","69f2a8e8":"markdown"},"source":{"885f3937":"import numpy as np \nimport pandas as pd \n\nimport os\nimport time\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\n\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nimport torch\nfrom torch.nn import Module\nfrom torch.nn import Conv2d\nfrom torch.nn import Linear\nfrom torch.nn import MaxPool2d\nfrom torch.nn import ReLU\nfrom torch.nn import LogSoftmax\nfrom torch import flatten\nfrom torch.optim import Adam\nfrom torch import nn\n\nfrom sklearn.metrics import classification_report\nfrom torch.utils.data import random_split\n\n%matplotlib inline\n\n! pip install -q imutils\nfrom imutils import paths\nimport shutil\nfrom urllib.request import urlopen\nfrom PIL import Image","48589dfc":"mmm = Image.open(urlopen(\"https:\/\/i.postimg.cc\/zf4JqghM\/fooled-by-the-accuracy.png\"))\nmmm","2a00560c":"mmm = Image.open(urlopen(\"https:\/\/i.postimg.cc\/ZnBpC3sd\/fooled-by-the-accuracy-1.png\"))\nmmm","16aaa574":"# Initializing parameters \n\nPATH = '\/kaggle\/input\/asl-dataset\/asl_dataset\/asl_dataset'\n\nINPUT_HEIGHT = 28\nINPUT_WIDTH  = 28\n\nTRAIN = \"train\"\nVAL = \"val\"\n\nBATCH_SIZE = 8\nVAL_SPLIT  = 0.15\nEPOCHS = 50\nLR = 1e-3\n","27c4d03d":"def copy_images(imagePaths, folder):\n    \n    # Creating destination folder\n    if not os.path.exists(folder):\n        os.makedirs(folder)\n        \n    # loop over the image paths\n    for path in imagePaths:\n        # Fetching name and label if the image and saving the files in training and validation folders\n        imageName = path.split('\/')[-1]\n        label = path.split('\/')[-2]\n        labelFolder = os.path.join(folder, label)\n        \n        # Creating labelfolder if it doesn't exits\n        if not os.path.exists(labelFolder):\n            os.makedirs(labelFolder)\n            \n        # construct the destination image path and copy the current image to it\n        destination = os.path.join(labelFolder, imageName)\n        shutil.copy(path, destination)","94394539":"# load all the image paths and randomly shuffle them\n\nprint(\">>> Loading Image paths...\\n\")\n\nimagePaths = list(paths.list_images(PATH))\nnp.random.shuffle(imagePaths)\n\n# Generating train & val paths\n\nvalPathsLen = int(len(imagePaths) * VAL_SPLIT)\ntrainPathsLen = len(imagePaths) - valPathsLen\n\ntrainPaths = imagePaths[:trainPathsLen]\nvalPaths = imagePaths[trainPathsLen:]\n\n# Copying the training and validation images to their respective directories using the function above\n\nprint(\">>> Copying training and validation images...\")\ncopy_images(trainPaths, TRAIN)\ncopy_images(valPaths, VAL)","d831c16e":"def visualize_batch(batch, classes, dataset_type):\n    \n    fig = plt.figure(\"{} batch\".format(dataset_type), figsize=(BATCH_SIZE, BATCH_SIZE))\n    \n    # Looping over the batch size\n    for i in range(0, BATCH_SIZE):\n        \n        # Creating a subplot\n        ax = plt.subplot(int(BATCH_SIZE\/4), int(BATCH_SIZE\/2), i + 1)\n        \n        '''grab the image, convert it from channels first ordering to\n        channels last ordering, and scale the raw pixel intensities\n        to the range [0, 255]'''\n        \n        image = batch[0][i].cpu().numpy()\n        image = image.transpose((1, 2, 0))\n        image = (image * 255.0).astype(\"uint8\")\n        \n        # grab the label id and get the label from the classes list\n        idx = batch[1][i]\n        label = classes[idx]\n        \n        # show the image along with the label\n        plt.imshow(image)\n        plt.title(label)\n        plt.axis(\"off\")\n        \n    # show the plot\n    plt.tight_layout()\n    plt.show()","cfc18f5f":"# Initializing our transformations & augmentations\n\nresize = transforms.Resize(size=(INPUT_HEIGHT, INPUT_WIDTH))\nhFlip = transforms.RandomHorizontalFlip(p=0.25)\nvFlip = transforms.RandomVerticalFlip(p=0.25)\nrotate = transforms.RandomRotation(degrees=15)","ee64c1fd":"# Initializing our training and validation set data augmentation pipeline\n\ntrainTransforms = transforms.Compose([resize, hFlip, vFlip, rotate, transforms.ToTensor()])\nvalTransforms = transforms.Compose([resize, transforms.ToTensor()])","603cb6c7":"# initialize the training and validation dataset\n\nprint(\">>> Loading the training and validation dataset...\\n\")\n\ntrainDataset = ImageFolder(root = TRAIN, transform = trainTransforms)\nvalDataset = ImageFolder(root = VAL, transform = valTransforms)\n\nprint(\">>> Training dataset contains {} samples...\".format(len(trainDataset)))\nprint(\">>> Validation dataset contains {} samples...\".format(len(valDataset)))","ed1763e7":"# create training and validation set dataloaders\n\nprint(\">>> Creating training and validation set dataloaders...\")\n\ntrainDataLoader = DataLoader(trainDataset, batch_size = BATCH_SIZE, shuffle=True)\nvalDataLoader = DataLoader(valDataset, batch_size = BATCH_SIZE)","15bd6e8d":"# Fetching a batch from both training and validation dataloader\n\ntrainBatch = next(iter(trainDataLoader))\nvalBatch = next(iter(valDataLoader))\n\n# visualize the training and validation set batches using visualize_batch function defined above\n\nprint(\">>> Visualizing training and validation batch...\")\nvisualize_batch(trainBatch, trainDataset.classes, \"train\")\nvisualize_batch(valBatch, valDataset.classes, \"val\")","3935754c":"mmm = Image.open(urlopen(\"https:\/\/i.postimg.cc\/fTvY2xSM\/fooled-by-the-accuracy-2.png\"))\nmmm","091c2611":"# Steps per epoch \n\ntrainSteps = len(trainDataLoader.dataset) \/\/ BATCH_SIZE\nvalSteps = len(valDataLoader.dataset) \/\/ BATCH_SIZE","b70bd6e7":"class Net(Module):\n    def __init__(self, numChannels, classes):\n        super(Net, self).__init__()\n\n        self.conv1 = Conv2d(in_channels=numChannels,\n                            out_channels=20,\n                            kernel_size=(5, 5))\n        self.relu = ReLU()\n        self.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n\n        self.conv2 = Conv2d(in_channels=20,\n                            out_channels=50,\n                            kernel_size=(5, 5))      \n\n        self.maxpool2 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n\n        self.fc1 = Linear(in_features=800, out_features=500)\n        self.fc2 = Linear(in_features=500, out_features=classes)\n        self.logSoftmax = LogSoftmax(dim=1)\n        \n    def forward(self, x):\n\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.maxpool1(x)\n\n        x = self.conv2(x)\n        x = self.relu(x)\n        x = self.maxpool2(x)\n\n        x = flatten(x, 1)\n        x = self.fc1(x)\n        x = self.relu(x)\n\n        x = self.fc2(x)\n        output = self.logSoftmax(x)\n\n        return output","d3d78106":"print(\">>> Initializing the  model...\")\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = Net(numChannels=3, classes=len(trainDataLoader.dataset.classes)).to(device)\n\n\nopt = Adam(model.parameters(), lr=LR)\nlossFn = nn.NLLLoss()\n\nH = {\n    \"train_loss\": [],\n    \"train_acc\": [],\n    \"val_loss\": [],\n    \"val_acc\": []\n     }\n\nprint(\">>> Training the network...\")\nstartTime = time.time()","36468a1f":"for e in range(0, EPOCHS):\n    \n    # Training\n    model.train()\n\n    totalTrainLoss = 0\n    totalValLoss = 0\n\n    trainCorrect = 0\n    valCorrect = 0\n\n    for (x, y) in trainDataLoader:\n\n        (x, y) = (x.to(device), y.to(device))\n\n        pred = model(x)\n        loss = lossFn(pred, y)\n\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n\n        totalTrainLoss += loss\n        trainCorrect += (pred.argmax(1) == y).type(torch.float).sum().item()\n        \n    # Evaluation\n    with torch.no_grad():\n\n        model.eval()\n\n        for (x, y) in valDataLoader:\n\n            (x, y) = (x.to(device), y.to(device))\n\n            pred = model(x)\n            totalValLoss += lossFn(pred, y)\n\n            valCorrect += (pred.argmax(1) == y).type(torch.float).sum().item()\n\n    # Calculating the average training and validation loss\n    avgTrainLoss = totalTrainLoss \/ trainSteps\n    avgValLoss = totalValLoss \/ valSteps\n\n    # Calculating the training and validation accuracy\n    trainCorrect = trainCorrect \/ len(trainDataLoader.dataset) # like correcct\/total\n    valCorrect = valCorrect \/ len(valDataLoader.dataset)\n \n    # Updating training history\n    H[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n    H[\"train_acc\"].append(trainCorrect)\n    H[\"val_loss\"].append(avgValLoss.cpu().detach().numpy())\n    H[\"val_acc\"].append(valCorrect)\n \n    print(\"[INFO] EPOCH: {}\/{}\".format(e + 1, EPOCHS))\n    print(\"Train loss: {:.6f}, Train accuracy: {:.4f}\".format(avgTrainLoss, trainCorrect))\n    print(\"Val loss: {:.6f}, Val accuracy: {:.4f}\\n\".format(avgValLoss, valCorrect))","30cfb418":"endTime = time.time()\nprint(\"Total time taken to train the model: {:.2f}s\".format(endTime - startTime))","988cc0c9":"H = pd.DataFrame(H)\nH.head().style.applymap(lambda x : \"background-color: #fadcb4\")\\\n.set_table_styles([{'selector' : '', 'props' : [('border', '2px solid black')]}])","c1cce06f":"for col in H.columns:\n    H[col] = H[col].astype('float64')","931b49e8":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(x = H.index,\n                         y = H['train_loss'],\n                         name = 'train_loss',\n                         mode = 'lines',\n                         line = dict(dash='dot'),\n                         marker =  dict(color = '#05ad24')))\n\nfig.add_trace(go.Scatter(y = H['val_loss'],\n                         x = H.index,\n                         name = 'val_loss',\n                         mode = 'lines',\n                         line = dict(dash='dot'),\n                         marker =  dict(color = '#0688cf')))\n\nfig.add_trace(go.Scatter(y = H['val_acc'],\n                         x = H.index,\n                         name = 'val_acc',\n                         mode = 'lines',\n                         marker =  dict(color = '#0688cf')))\n\nfig.add_trace(go.Scatter(y = H['train_acc'],\n                         x = H.index,\n                         name = 'train_acc',\n                         mode = 'lines',\n                         marker =  dict(color = '#05ad24')))\n\nfig.update_xaxes(title = '# Epoch',\n        range = [0,51],\n        tickfont = dict(size=15),\n        tickmode = 'array',\n        showline = False,\n        showgrid = False,\n        ticks = 'outside')\n\nfig.update_yaxes(title = 'Loss\/Accuracy',\n        tickfont = dict(size=15),\n        tickmode = 'array',\n        showline = False,\n        showgrid = True,\n        ticks = 'outside')\n\nfig.update_layout(width=600,\n                  title = dict(text = 'Training Loss and Accuracy on Dataset',\n                               x = 0.5,\n                               font = dict(size = 16, color ='#27302a',\n                               family = 'monospace')),\n                  plot_bgcolor='#fadcb4',\n                  paper_bgcolor = '#fadcb4')\n\nfig.show()","076915d0":"# To save the model\n#torch.save(model, args[\"model\"])","f9276eb3":"mmm = Image.open(urlopen(\"https:\/\/i.postimg.cc\/Gm8Gc6Sm\/fooled-by-the-accuracy-3.png\"))\nmmm","d25cf5f7":"# Defining basic functions for later\n\ncalc = {\n    '0':'0',\n    '1':'1',\n    '2':'2',\n    '3':'3',\n    '4':'4',\n    '5':'5',\n    '6':'6',\n    '7':'7',\n    '8':'8',\n    '9':'9',    \n    'a':'+',\n    'c':')',\n    'd':'\/',\n    'e':'**',\n    'f':'\/\/',\n    'm':'*',\n    'o':'(',\n    'r':'%',\n    's':'-'  \n        }","97f76eb6":"mmm = Image.open(urlopen(\"https:\/\/i.postimg.cc\/SRR7cRVW\/fooled-by-the-accuracy-4.png\"))\nmmm","8f1a1437":"# Expression '14 * 3 ** 3 + 4'\n\nequation = [\ntrainDataset[71][0],\ntrainDataset[280][0],\ntrainDataset[1324][0],\ntrainDataset[220][0],\ntrainDataset[880][0],\ntrainDataset[220][0],\ntrainDataset[630][0],\ntrainDataset[280][0]\n]","f2646a06":"equation = torch.stack(equation)\npredicted_equation = []\n\neqLoader = DataLoader(equation, batch_size = 1)","bdc5c7f7":"with torch.no_grad():\n\n    for image in eqLoader:\n\n        origImage = image.numpy()#.squeeze(axis=(0, 1))\n\n        image = image.to(device)\n        pred = model(image)\n\n        idx = pred.argmax(axis=1).cpu().numpy()[0]\n        predLabel = valDataLoader.dataset.classes[idx]\n        predicted_equation.append(predLabel)","80d9bc18":"print('Predicted labels : ', predicted_equation)\n\nfor i in range(len(predicted_equation)):\n    predicted_equation[i] = calc[str(predicted_equation[i])]\n    \nprint('Modified labels : ', predicted_equation)\nexpression = ''.join(predicted_equation)\nanswer = eval(expression)\n\nprint('Calculation : ', answer)\nprint(14*3**3+4)","69fd4043":"mmm = Image.open(urlopen(\"https:\/\/i.postimg.cc\/Z5s9yH2D\/fooled-by-the-accuracy-5.png\"))\nmmm","658d3be4":"### ^^ Expand output to see Epoch training","9d9a8f37":"# 3. Simple Calculator","1440908b":"# 1. Loading and Visualizing data","69f2a8e8":"# 2. Training Model"}}