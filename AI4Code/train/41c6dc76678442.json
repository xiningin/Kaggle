{"cell_type":{"b5d54e44":"code","02484fb8":"code","ea17e63a":"code","d4249ab5":"code","d827c096":"code","2c0c11b0":"code","cd9899bb":"code","1973be2a":"code","27e4fb17":"code","7e744388":"code","e9de1a88":"code","3f147f7c":"code","6b6e436f":"code","1d1b5d48":"code","4af67c83":"code","7b655a15":"code","7be5017d":"code","28ba9b7b":"code","c596bfb9":"code","8cd6d8a0":"code","a2d436ac":"code","cd5298d3":"code","509f890d":"code","93b530b5":"code","2c592103":"code","a3f05f16":"code","f6e10d72":"code","0e693522":"code","2eb4ec49":"code","746cb16a":"markdown","b5962778":"markdown","dcac0977":"markdown","28f7ffc7":"markdown","dd2c7341":"markdown","b183af62":"markdown","861db344":"markdown"},"source":{"b5d54e44":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport plotly.express as px\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nimport sklearn.metrics as metrics\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n","02484fb8":"test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntemplate_submission = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\ncompiled_results = template_submission.drop('Survived', axis=1)\ntrain.head(10)","ea17e63a":"def aggregate_trainset(argument_array, df):\n    df_agg = df.groupby(argument_array).agg(\n        count_survived = pd.NamedAgg('Survived', 'sum'),\n        count_total = pd.NamedAgg('Survived', 'count')\n    ).reset_index()\n    df_agg['count_deaths'] = df_agg['count_total']-df_agg['count_survived']\n    df_agg['pct_survived'] = df_agg['count_survived']\/df_agg['count_total']\n    return df_agg\n\ndef categorize_age(age):\n    if age <= 15:\n        return '0 to 15', 1\n    if age <= 35:\n        return '16 to 35', 2\n    if age <= 55:\n        return '36 to 55', 3\n    if age > 55:\n        return '55+', 4\n    else:\n        return 'N\/A', 0\n    \ndef categorize_fare(fare):\n    if fare < 15:\n        return 'Under $15', 1\n    if fare < 35:\n        return '$15 to $35', 2\n    if fare < 100:\n        return '$35 to $100', 3\n    if fare > 100:\n        return 'Over $100', 4\n    else:\n        return 'N\/A', 0\n    \ndef return_train_test_sets(df, features_list, test_size, random_state):\n    df = conduct_feature_engineering(df)\n    \n    X = df[features_list].copy()\n    y = df[['Survived']].copy()\n\n    # Categorical boolean mask\n    categorical_feature_mask = X.dtypes==object\n    # filter categorical columns using mask and turn it into a list\n    categorical_cols = X.columns[categorical_feature_mask].tolist()\n\n    #encode categorical variables\n    le = LabelEncoder()\n    # apply label encoder on categorical feature columns\n    X[categorical_cols] = X[categorical_cols].apply(lambda col: le.fit_transform(col.astype(str)))\n\n    # # fill all NaN with -1\n    X.fillna(value=-1, inplace=True)\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n    return X_train, X_test, y_train, y_test\n\ndef return_final_train_test_sets(df_train, df_test, features_list, test_size, random_state , fillna=True):\n    df_test['Survived'] = -1\n    full_set = df_train.append(df_test, sort=False).reset_index(drop=True)\n    full_set = conduct_feature_engineering(full_set)\n\n    # Categorical boolean mask\n    categorical_feature_mask = full_set.dtypes==object\n    # filter categorical columns using mask and turn it into a list\n    categorical_cols = full_set.columns[categorical_feature_mask].tolist()\n\n    # encode categorical variables\n    le = LabelEncoder()\n    # apply label encoder on categorical feature columns\n    full_set[categorical_cols] = full_set[categorical_cols].apply(lambda col: le.fit_transform(col.astype(str)))\n\n    if fillna == True:\n        # fill all NaN with -1\n        full_set.fillna(value=-1, inplace=True)\n\n    # keep only necessary columns + Survived column\n    features_list = features_list+['Survived']\n    full_set = full_set[features_list]\n\n    #Create final datasets used to train model\n    final_X_train = full_set.loc[full_set['Survived']!=-1].drop('Survived', axis=1)\n    final_y_train = full_set.loc[full_set['Survived']!=-1, 'Survived'].values\n    final_X_test = full_set.loc[full_set['Survived']==-1].drop('Survived', axis=1)\n    return final_X_train, final_y_train, final_X_test\n\ndef conduct_feature_engineering(df):\n    df['age_category'] = df['Age'].apply(lambda x: categorize_age(x)[0])\n    df['age_cat_rank'] = df['Age'].apply(lambda x: categorize_age(x)[1])\n    df['fare_cat'] = df['Fare'].apply(lambda x: categorize_fare(x)[0])\n    df['fare_cat_rank'] = df['Fare'].apply(lambda x: categorize_fare(x)[1])\n    df['cabin_zone'] = df['Cabin'].astype(str).apply(lambda x: x[0:1] if x != 'nan' else None)\n    return df","d4249ab5":"fig = px.scatter(train, x='Fare', y='Age', color='Survived')\nfig.show()","d827c096":"fig = px.histogram(train, x='Fare', histfunc='count', histnorm='percent', color='Survived')\nfig.show()","2c0c11b0":"df = conduct_feature_engineering(train)\naggregation_criteria = ['fare_cat', 'fare_cat_rank']\ngraph_data = aggregate_trainset(aggregation_criteria, df)\nfig = px.bar(graph_data.sort_values('fare_cat_rank'), x='fare_cat', y='pct_survived')\nfig.show()","cd9899bb":"df = conduct_feature_engineering(train)\naggregation_criteria = ['Pclass']\ngraph_data = aggregate_trainset(aggregation_criteria, df)\nfig = px.bar(graph_data, x='Pclass', y='pct_survived')\nfig.show()","1973be2a":"df = conduct_feature_engineering(train)\naggregation_criteria = ['Embarked']\ngraph_data = aggregate_trainset(aggregation_criteria, df)\nfig = px.bar(graph_data, x='Embarked', y='pct_survived')\nfig.show()","27e4fb17":"df = conduct_feature_engineering(train)\naggregation_criteria = ['Sex']\ngraph_data = aggregate_trainset(aggregation_criteria, df)\nfig = px.bar(graph_data, x='Sex', y='pct_survived')\nfig.show()","7e744388":"df = conduct_feature_engineering(train)\naggregation_criteria = ['Parch']\ngraph_data = aggregate_trainset(aggregation_criteria, df)\nfig = px.bar(graph_data, x='Parch', y='pct_survived')\nfig.show()","e9de1a88":"df = conduct_feature_engineering(train)\naggregation_criteria = ['age_category', 'age_cat_rank', 'Sex']\ngraph_data = aggregate_trainset(aggregation_criteria, df)\nfig = px.bar(graph_data.sort_values('age_cat_rank'), x='age_category', y='pct_survived', facet_col='Sex')\nfig.show()","3f147f7c":"features_list = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'age_category', 'fare_cat', 'cabin_zone']\nX_train, X_test, y_train, y_test = return_train_test_sets(df=train, features_list=features_list, test_size=0.2, random_state=4)\nfinal_X_train, final_y_train, final_X_test = return_final_train_test_sets(df_train=train, df_test=test, features_list=features_list, test_size=0.2, random_state=4)","6b6e436f":"k_range = range(1, 25)\nscores = {}\nscores_list = []\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train,y_train['Survived'].values)\n    y_pred=knn.predict(X_test)\n    scores[k] = metrics.accuracy_score(y_test['Survived'].values,y_pred)\n    scores_list.append(metrics.accuracy_score(y_test['Survived'].values,y_pred))","1d1b5d48":"graph_data = pd.Series(scores).to_frame('accuracy').reset_index()\ngraph_data.rename(columns={'index':'k-factor'}, inplace=True)\n\nfig = px.bar(graph_data, x='k-factor', y='accuracy')\nfig.show()","4af67c83":"#solving test df based on best performing # neighbors\nfinal_knn = KNeighborsClassifier(n_neighbors=10)\nfinal_knn.fit(final_X_train, final_y_train)\ny_pred_final = final_knn.predict(final_X_test)","7b655a15":"submission = pd.Series(y_pred_final).to_frame('Survived').reset_index()\nsubmission.rename(columns={'index':'PassengerId'}, inplace=True)\nsubmission['PassengerId'] = submission['PassengerId']+892\ncompiled_results = pd.merge(compiled_results, submission[['PassengerId', 'Survived']], on='PassengerId', how='left')\ncompiled_results.rename(columns={'Survived':'Survived_KNN'}, inplace=True)\nsubmission.to_csv('submission_KNN.csv', index=False)","7be5017d":"features_list = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'age_category', 'fare_cat', 'cabin_zone']\nX_train, X_test, y_train, y_test = return_train_test_sets(df=train, features_list=features_list, test_size=0.2, random_state=4)\nfinal_X_train, final_y_train, final_X_test = return_final_train_test_sets(df_train=train, df_test=test, features_list=features_list, test_size=0.2, random_state=4)","28ba9b7b":"gnb = GaussianNB()\ngnb.fit(X_train, y_train['Survived'].values)\ny_pred = gnb.predict(X_test)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","c596bfb9":"#solving test set\nfinal_gnb = GaussianNB()\nfinal_gnb.fit(final_X_train, final_y_train)\ny_pred_final = final_gnb.predict(final_X_test)","8cd6d8a0":"submission = pd.Series(y_pred_final).to_frame('Survived').reset_index()\nsubmission.rename(columns={'index':'PassengerId'}, inplace=True)\nsubmission['PassengerId'] = submission['PassengerId']+892\ncompiled_results = pd.merge(compiled_results, submission[['PassengerId', 'Survived']], on='PassengerId', how='left')\ncompiled_results.rename(columns={'Survived':'Survived_GNB'}, inplace=True)\nsubmission.to_csv('submission_GNB.csv', index=False)","a2d436ac":"features_list = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'cabin_zone']\nX_train, X_test, y_train, y_test = return_train_test_sets(df=train, features_list=features_list, test_size=0.2, random_state=4)\nfinal_X_train, final_y_train, final_X_test = return_final_train_test_sets(df_train=train, df_test=test, features_list=features_list, test_size=0.2, random_state=4)","cd5298d3":"clf=RandomForestClassifier(n_estimators=1000, max_depth=6)\nclf.fit(X_train,y_train['Survived'].values)\ny_pred=clf.predict(X_test)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","509f890d":"#solving on test set\nfinal_clf = RandomForestClassifier(n_estimators=1000)\nfinal_clf.fit(final_X_train, final_y_train)\ny_pred_final = final_clf.predict(final_X_test)","93b530b5":"submission = pd.Series(y_pred_final).to_frame('Survived').reset_index()\nsubmission.rename(columns={'index':'PassengerId'}, inplace=True)\nsubmission['PassengerId'] = submission['PassengerId']+892\ncompiled_results = pd.merge(compiled_results, submission[['PassengerId', 'Survived']], on='PassengerId', how='left')\ncompiled_results.rename(columns={'Survived':'Survived_RF'}, inplace=True)\nsubmission.to_csv('submission_RF.csv', index=False)","2c592103":"features_list = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'cabin_zone']\nX_train, X_test, y_train, y_test = return_train_test_sets(df=train, features_list=features_list, test_size=0.2, random_state=4)\nfinal_X_train, final_y_train, final_X_test = return_final_train_test_sets(df_train=train, df_test=test, features_list=features_list, test_size=0.2, random_state=4)","a3f05f16":"abc = list(range(1,9))","f6e10d72":"hidden_layers = list(range(1, 9))\nneurons_per_layer = list(range(5,51))\nneural_net_testing = pd.DataFrame(columns=['nb_hidden_layers', 'nb_neurons', 'accuracy'])\nfor layer in hidden_layers:\n    for neurons in neurons_per_layer:   \n        mlpc = MLPClassifier(hidden_layer_sizes=(neurons, layer), max_iter=1500, alpha=1e-4,\n                            solver='sgd', verbose=False, tol=1e-4, random_state=1,\n                            learning_rate_init=.01)\n        mlpc.fit(X_train, y_train['Survived'].values)\n        y_pred=mlpc.predict(X_test)\n        neural_net_testing = neural_net_testing.append(pd.Series([layer, neurons, metrics.accuracy_score(y_test, y_pred)], index=neural_net_testing.columns ), ignore_index=True)\n        \nfig = px.scatter(neural_net_testing, x='nb_hidden_layers', y='nb_neurons', color='accuracy')\nfig.show()","0e693522":"print('Survival rate based on KNN: {}'.format(sum(compiled_results['Survived_KNN'].values)\/compiled_results.shape[0]))\nprint('Survival rate based on Gaussian Naive Bayes: {}'.format(sum(compiled_results['Survived_GNB'].values)\/compiled_results.shape[0]))\nprint('Survival rate based on Random Forests: {}'.format(sum(compiled_results['Survived_RF'].values)\/compiled_results.shape[0]))\nprint('Average surival rate in train set: {}'.format(sum(train['Survived'].values\/train.shape[0])))","2eb4ec49":"compiled_results['AverageSurvival'] = (compiled_results['Survived_KNN']+compiled_results['Survived_GNB']+compiled_results['Survived_RF'])\/3\ncompiled_results['AverageSurvival'].value_counts()","746cb16a":"# Compiled Results","b5962778":"# Neural Networks","dcac0977":"# Feature analysis","28f7ffc7":"# Library imports and preprocessing","dd2c7341":"# Naive Bayes Classifier","b183af62":"# Random Forests","861db344":"# KNN classifier"}}