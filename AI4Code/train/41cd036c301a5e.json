{"cell_type":{"7f060535":"code","cb89b287":"code","a882dd16":"code","0c40ba2d":"code","f7eb91d2":"code","74142eae":"code","56fd56c8":"code","d8620b36":"code","74259064":"code","e9cc9420":"code","07ebdb63":"code","001da0c4":"code","3014dd46":"code","4bada45e":"code","b3c87824":"code","e88edbae":"code","070de131":"code","e3a18836":"code","a5a752cb":"code","d91b3af1":"code","2632ccd3":"code","9d95d43a":"code","79eeeaa1":"code","d82f04ff":"code","b85f3f84":"code","4e4770f2":"code","142c35a7":"code","ec41a28d":"code","e302c519":"code","f8b1c667":"code","935c6719":"code","87995a59":"code","d8a6a7f9":"markdown","af7a297f":"markdown","29ade2d7":"markdown","b656e931":"markdown","24fcfc06":"markdown","fe83ceb4":"markdown","775661e2":"markdown","a24f5e72":"markdown","71d064c9":"markdown","ab8af3c8":"markdown","78080477":"markdown","62a1f545":"markdown","522e294d":"markdown","813aa20b":"markdown","bb840a3a":"markdown","4580038f":"markdown","3fea7cbb":"markdown","dc155d05":"markdown","0252ef1e":"markdown"},"source":{"7f060535":"!pip install imutils\n!pip install image-classifiers==1.0.0b1","cb89b287":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport random\nimport shutil\nimport cv2\nimport os\nfrom datetime import datetime\n%load_ext tensorboard","a882dd16":"import tensorflow as tf\nimport gc\nfrom tensorflow.keras.optimizers import SGD, RMSprop, Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.layers import Dropout,ZeroPadding2D, Add, GlobalAveragePooling2D, DepthwiseConv2D, Activation, BatchNormalization, Dropout, LSTM, ConvLSTM2D, AveragePooling2D, Flatten, Dense, Input,Conv2D, SeparableConv2D, MaxPool2D, LeakyReLU, Activation, LSTM, ConvLSTM2D, Lambda, Reshape, BatchNormalization, Bidirectional\n","0c40ba2d":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint,TensorBoard,TerminateOnNaN, LearningRateScheduler\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras import backend as K\nfrom sklearn.metrics import precision_recall_curve,  plot_precision_recall_curve,  classification_report,  confusion_matrix, roc_auc_score, roc_curve, auc\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, RepeatedStratifiedKFold\nfrom imutils import paths","f7eb91d2":"dataset_path = '.\/out'\nlog_path = '.\/logs'","74142eae":"%%bash\nrm -rf out\nmkdir -p out\nmkdir -p logs","56fd56c8":"ls ..\/input\/covid19-pneumonia-normal-chest-xray-pa-dataset","d8620b36":"df = pd.DataFrame(columns =['class', 'directory'])  \nfor path, names, filenames in os.walk('..\/input\/covid19-pneumonia-normal-chest-xray-pa-dataset\/normal'):\n    for filename in filenames:\n        df.loc[-1] = [\"normal\", ('normal\/' + filename)] \n        df.index = df.index + 1 \n        df = df.sort_index() \nfor path, names, filenames in os.walk('..\/input\/covid19-pneumonia-normal-chest-xray-pa-dataset\/covid'):\n    for filename in filenames:\n        df.loc[-1] = [\"covid\", ('covid\/' + filename)] \n        df.index = df.index + 1 \n        df = df.sort_index() \nfor path, names, filenames in os.walk('..\/input\/covid19-pneumonia-normal-chest-xray-pa-dataset\/pneumonia'):\n    for filename in filenames:\n        df.loc[-1] = [\"pneumonia\", ('pneumonia\/' + filename)] \n        df.index = df.index + 1 \n        df = df.sort_index() ","74259064":"df","e9cc9420":"df_y = df['class']\ndf_x = df['directory']","07ebdb63":"df_x\n","001da0c4":"df_y.value_counts()","3014dd46":"X_train, X_test, Y_train, Y_test = train_test_split(df_x, df_y, stratify= df_y, test_size=0.20, random_state=7)","4bada45e":"Y_train.value_counts()","b3c87824":"test = pd.concat([X_test, Y_test], axis = 1)\ntest.head()","e88edbae":"def copy_images(df, directory):\n    input_path = \"..\/input\/covid19-pneumonia-normal-chest-xray-pa-dataset\"\n    output_path = \"out\/\" + directory \n    \n    #if any old file exists in ouput path, it is removed\n    if os.path.exists(output_path):\n        shutil.rmtree(output_path)\n        \n    #creating folder inside output path\n    if not os.path.exists(output_path):\n        os.makedirs(output_path)\n    \n    #these three subfolders\n    classes = ['normal', 'covid', 'pneumonia']\n    for c in classes:\n        if not os.path.exists(output_path + '\/' + c):\n            os.makedirs(output_path + '\/' + c)\n    \n    #the original dataframe containing directory for each row, those directory are shifted from path_from to path_to\n    #(that is from input directory to ouput directory)\n    for i, row in df.iterrows():\n        path_from = \"{}\/{}\".format(input_path, row['directory'])\n        path_to = \"{}\/{}\".format(output_path, row['directory'])\n        shutil.copy(path_from, path_to)\n    ","070de131":"#copy_image function was created to move the test images from input to output directory\ncopy_images(test, 'test')\n","e3a18836":"!ls .\/out\/test","a5a752cb":"print(len(os.listdir('.\/out\/test\/normal')))\nprint(len(os.listdir('.\/out\/test\/covid')))\nprint(len(os.listdir('.\/out\/test\/pneumonia')))","d91b3af1":"train_datagen = ImageDataGenerator(rescale=1.\/255, rotation_range=15, fill_mode='nearest')\nval_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)","2632ccd3":"test_generator = test_datagen.flow_from_directory(\n    directory=r\".\/out\/test\/\",\n    target_size=(224, 224),\n    color_mode=\"rgb\",\n    batch_size=1,\n    class_mode=None,\n    shuffle=False,\n    seed=42\n)","9d95d43a":"class_to_label_map = {'pneumonia' : 2, 'covid' : 1, 'normal' : 0}","79eeeaa1":"def get_model():\n    \n    # Create Model..........................................\n    \n    # Input layer\n    baseModel = ResNet50(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n    for layer in baseModel.layers:\n        layer.trainable = False \n    x = baseModel.output\n\n    \n    # FC layer\n    x = Flatten(name=\"flatten\")(x)\n    \n    # fc1 layer\n    x = Dense(units=4096, activation='relu')(x)\n    x = BatchNormalization()(x)\n\n\n    # fc2 layer\n    x = Dense(units=4096, activation='relu')(x)\n    x = BatchNormalization()(x)\n\n    \n    # Output layer\n    output = Dense(units=3, activation='softmax')(x)\n\n    model = Model(inputs=baseModel.input, outputs=output)\n    opt = RMSprop(lr=0.0001, decay=1e-6)\n    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n    return model","d82f04ff":"from math import floor\nfrom time import time\nEPOCHS = 15\ndecay_rate = 0.95\ndecay_step = 1\nlearning_rate = 1e-4\n\ndef scheduler(lr):\n    if epoch > 9:\n        return lr\n    else:\n        global learning_rate\n        learning_rate *=  decay_rate\n        print('learning_rate: '+ str(learning_rate))\n        return learning_rate\ncallback3 = LearningRateScheduler(scheduler)\n\nskf = StratifiedKFold(n_splits = 5, random_state = 7, shuffle = True)\nlog_dir = \".\/logs\/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n\ncallbacks = [ModelCheckpoint(filepath='best_lstm_model.h5', monitor='val_loss',mode='min',verbose=1,save_best_only=True,save_weights_only=True),\n             callback3, tensorboard_callback]","b85f3f84":"submission_predictions = []\n\nfor epoch, (train_index, val_index) in enumerate(skf.split(df_x, df_y)):\n    x_train, x_val = df_x.iloc[train_index], df_x.iloc[val_index]\n    y_train, y_val = df_y.iloc[train_index], df_y.iloc[val_index]\n    \n    print(y_train.value_counts())\n    print(y_val.value_counts())\n\n    train = pd.concat([x_train, y_train], axis=1)\n    val = pd.concat([x_val, y_val], axis = 1)\n    \n    # copy the images according to the fold\n    copy_images(train, 'train')\n    copy_images(val, 'val')\n    \n    print('Running fold '+ str(epoch+1))\n    \n    # CREATE MODEL\n    model = get_model()\n\n    \n    # Load Model Weights\n    if epoch != 0:\n        model.load_weights('best_model.h5') \n    \n    train_generator = train_datagen.flow_from_directory(\n        directory=r\".\/out\/train\/\",\n        target_size=(224, 224),\n        color_mode=\"rgb\",\n        batch_size=16,\n        class_mode=\"categorical\",\n        shuffle=True,\n        seed=42\n    )\n    valid_generator = val_datagen.flow_from_directory(\n        directory=r\".\/out\/val\/\",\n        target_size=(224, 224),\n        color_mode=\"rgb\",\n        batch_size=16,\n        class_mode=\"categorical\",\n        shuffle=True,\n        seed=42\n    )\n    \n    startTrain = time()\n    history = model.fit_generator(\n                generator=train_generator,\n                steps_per_epoch=train_generator.n\/\/train_generator.batch_size,\n                validation_data=valid_generator,\n                validation_steps=valid_generator.n\/\/valid_generator.batch_size,\n                epochs=EPOCHS,\n                callbacks=callbacks\n    )\n    print(time()-startTrain)\n    \n    hist_df = pd.DataFrame(history.history) \n    hist_csv_file = 'history.csv'\n    \n\n    \n    test_generator.reset()\n    startTest = time()\n    predY=model.predict_generator(\n            test_generator,\n            steps=test_generator.n\/\/test_generator.batch_size,\n            verbose=1)\n    print(time()-startTest)\n    \n    if epoch >= 1:\n        submission_predictions.append(predY)\n        \n    testY = test_generator.classes\n    confusion__matrix=confusion_matrix(testY, np.argmax(predY, axis = -1))\n    cr=(classification_report(testY, np.argmax(predY, axis = -1), target_names=class_to_label_map, output_dict=True, digits=4))\n    print (cr)\n    print(confusion__matrix)\n    \n    cm_df = pd.DataFrame(confusion__matrix)\n    cr_df = pd.DataFrame(cr)\n    with open(hist_csv_file, mode='a') as f:\n        hist_df.to_csv(f)\n        cm_df.to_csv(f)\n        cr_df.to_csv(f)\n     \n    model.save('best_model.h5') \n    \n    del history\n    del model\n    gc.collect()","4e4770f2":"predY = np.average(submission_predictions, axis = 0, weights = [2**i for i in range(len(submission_predictions))])","142c35a7":"precision = dict()\nrecall = dict()\nhist_csv_file = 'history.csv'\n\ny_test_dummies = pd.get_dummies(testY, drop_first=False).values\nfor i in range(3):\n    precision[i], recall[i], _ = precision_recall_curve(y_test_dummies[:, i], predY[:, i])\n    plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n    \nplt.xlabel(\"recall\")\nplt.ylabel(\"precision\")\nplt.legend(loc=\"best\")\nplt.title(\"precision vs. recall curve\")\nplt.show()\nplt.savefig('prc.png')\n\nprecision_df = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in precision.items() ]))\nrecall_df = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in recall.items() ]))\nwith open(hist_csv_file, mode='a') as f:\n    precision_df.to_csv(f)\n    recall_df.to_csv(f)","ec41a28d":"roc_auc_score(testY, predY, multi_class='ovo') #one-vs-one for multiclass","e302c519":"\nclass_to_label = ['normal', 'covid', 'pneumonia']\nimport seaborn as sns\ndef plot_multiclass_roc(y_test, y_score, n_classes, figsize=(17, 6)):\n\n    # structures\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    plt.figure(figsize=(10, 10))\n    lw = 3\n\n    # calculate dummies once\n    y_test_dummies = pd.get_dummies(y_test, drop_first=False).values\n    for i in range(n_classes):\n        fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], y_score[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    colors = ['maroon', 'seagreen', 'darkorchid']\n    for i, color in zip(range(n_classes), colors):\n        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n                 label='ROC curve of class {0} (area = {1:0.4f})'\n                 ''.format(class_to_label[i], roc_auc[i]))\n\n    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n#     plt.title('Some extension of Receiver operating characteristic to multi-class')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\nplot_multiclass_roc(testY, predY, n_classes=3, figsize=(10, 10))","f8b1c667":"conf_matrix = confusion_matrix(testY, np.argmax(predY, axis = -1))","935c6719":"print(cr_df)","87995a59":"def plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=True):\n\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import itertools\n\n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Purples')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, fontsize = 'larger')\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45, fontsize = 'larger')\n        plt.yticks(tick_marks, target_names, fontsize = 'larger')\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n\n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"blue\", fontsize = 'larger')\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"blue\", fontsize = 'larger')\n\n\n    plt.tight_layout()\n    plt.ylabel('True label', fontsize = 'larger')\n    plt.xlabel('Predicted label', fontsize = 'larger')\n\n    plt.show()\n    \nplot_confusion_matrix(conf_matrix, \n                      normalize = False,\n                      target_names = ['Normal', 'COVID-19', 'Pneumonia'],\n                      title        = \"Confusion Matrix\")","d8a6a7f9":"imutils = Imutils are a series of convenience functions to make basic image processing functions such as translation, rotation, resizing, skeletonization, and displaying Matplotlib images easier with OpenCV and both Python 2.7 and Python 3.\n<\/br> ImageClassifier is a python package for creating Image classifiers with the help of CNNs.\n<\/br>Image classification is the process of taking an input (like a picture) and outputting a class","af7a297f":"gc = Invoking the garbage collector manually during the execution of a program can be a good idea on how to handle memory being consumed by reference cycles.\n<\/br>SGD = Stochastic Gradient Descent, it is an optimizer\n<\/br>RMSprop stands for Root Mean Square Propagation. Widely-known gradient descent optimization algorithm for mini-batch learning of neural networks.\n<\/br> ","29ade2d7":"below code shows a table showing the test class and directory\n<\/br> axis = 1 represents along the columns\npd.concat means X_test and Y_test is concatenated","b656e931":"flow_from_directory - reads from that folder and various operations can be done to the images in that folder\n<\/br> batch_size: No. of images to be yielded from the generator per batch.\n<\/br>seed: Random seed for applying random image augmentation and shuffling the order of the image.\n<\/br> for the test set, you should sample the images exactly once, no less or no more.","24fcfc06":"get_dummies() is used for data manipulation. It converts categorical data into dummy or indicator variables, similar to one hot encoding \n<\/br> * precision_recall_curve() is a sklearn function which creates the graph from the data \n","fe83ceb4":"Learning rate schedules = seek to adjust the learning rate during training by reducing the learning rate according to a pre-defined scheduler. \n<\/br>StratifiedKFold =  is a variation of KFold. First, StratifiedKFold shuffles your data, after that splits the data into n_splits parts, it is just like Kfold where the entire data is split for 5 times doing the epoch(1-15), see the output for the next block code, running fold keeps iterating everytime epoch 1-15 is completed\n<\/br> KFold is cross validation technique and Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample. \n<\/br> log_dir is all about showing time it took to run \n<\/br< ModelCheckpoint callback is used ito connect with training using model.fit() to save a model or weights (in a checkpoint file) at some interval, so the model or weights can be loaded later to continue the training from the state saved, and that is stored in variable called callback","775661e2":"After creating the model, we need to train the model\nfor each epoch the datas are splitted by skf\n<\/br>* enumerate() lets you write Pythonic for loops when you need a count and the value from an iterable. \n<\/br>* x_train, x_val, y_train, y_val is created\n<\/br> train and val are concatenated so that they can be trained differently\nand are copied to the ouput path\n<\/br>* confusion matrix, classification report and history of time are saved into a csv file \n<\/br>* A Classification report is used to measure the quality of predictions\n<\/br>* the augmented image of train and validation are passed into train_generator and val_generator and they are finally passed into model.fit_generator and here the model starts training, model.fit_generator() function first accepts a batch of the dataset, then performs backpropagation on it, and then updates the weights in our model.\n<\/br>* like how fit generator is used for training the given models, prediction_generator is then used to predict the model\n<\/br> classes of test generator is stored in testY","a24f5e72":"from the predicted value it's average value is taken for each column","71d064c9":"ResNet50 model is chosen for transfer learning which is stored in baseModel and layer.trainable = False means the layer is frozen so as to avoid destroying any of the information they contain during future training rounds. and finally the layer is flattened and is sent to 2 fully connected layers\noptimizer used is RMSprop\n\n\n<\/br> Batch normalization is a technique for training very deep neural networks that standardizes the inputs to a layer for each mini-batch. This has the effect of stabilizing the learning process and dramatically reducing the number of training epochs required to train deep networks.","ab8af3c8":"Splitting dataset into train, test and stratifying them in df_y(class) order","78080477":"ImageDataGenerator - It lets you augment your images in real-time while your model is still training! You can apply any random transformations on each training image as it is passed to the model.\n<\/br> Rescale 1.\/255 is to transform every pixel value from range [0,255] -> [0,1]. And the benefits are: Treat all images in the same manner: some images are high pixel range, some are low pixel range. ... Scaling every images to the same range [0,1] will make images contributes more evenly to the total loss.\n<\/br> fill mode- When your image shift by some % there is some space left over and to fill that ","62a1f545":"X_train and X_test = image directory\n<\/br> Y_test and Y_train = class label i.e covid, normal and pneumonia\n","522e294d":"Naming each class their respective label","813aa20b":"Those subfolders are created!","bb840a3a":"# Detection of Covid-19, Pneumonia and Normal using chest X-ray #","4580038f":"bash allows ls and other codes\n<\/br> rm -rf = can easily delete a folder\n<\/br> mkdir -p command you can create sub-directories of a directory.","3fea7cbb":"# Creating the model","dc155d05":"a function copy_images is created which takes test images from the input path and is passed onto the output path and they are created into three subfolders normal,covid and Penumonia","0252ef1e":"Creating a dataframe containing class and directory and updating the pneumonia\/covid\/normal and it's directory, appending index and sorting the index value in increasing order"}}