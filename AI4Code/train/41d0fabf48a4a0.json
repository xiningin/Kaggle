{"cell_type":{"8a9837df":"code","a645ecd8":"code","06e70776":"code","9155b6d0":"code","ac27cb7d":"code","bad8a838":"code","4ae4527d":"code","12b7e90c":"code","e0c8fad2":"code","c5f1dd6e":"code","5192e737":"code","f21e2bb0":"code","7db12c27":"markdown","570cce67":"markdown","edc2d449":"markdown","fbd91457":"markdown","ea5fe1ec":"markdown","da5c2701":"markdown","3f11e931":"markdown","b9a12c68":"markdown","3832aa54":"markdown","6623b44e":"markdown","42c0e1d2":"markdown","d45fa433":"markdown","d606d625":"markdown","5f0bb7c7":"markdown"},"source":{"8a9837df":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nfrom keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom pathlib import Path\nimport glob\nimport keras\nfrom sklearn.model_selection import train_test_split","a645ecd8":"path = '\/kaggle\/input\/animals10\/raw-img'\nfolder_names = os.listdir(path)\nprint(folder_names)","06e70776":"def plot_examples(folder_names, selected_folder, path):\n    \"\"\" Plot 5 examples of images with the same landmark_id \"\"\"\n    \n    fig, axs = plt.subplots(1, 5, figsize=(25, 12))\n    fig.subplots_adjust(hspace = .2, wspace=.2)\n    axs = axs.ravel()\n    file_names = os.listdir(path + '\/' + selected_folder)\n    for i in range(5):\n        print(file_names[i])\n        img = cv2.imread(path + '\/' + selected_folder + '\/' + file_names[i])\n        axs[i].imshow(img)\n        axs[i].set_xticklabels([])\n        axs[i].set_yticklabels([])\n        \nplot_examples(folder_names,'elefante', path)","9155b6d0":"X = []\ny = []\nfor folder in folder_names:\n    file_names = os.listdir(path + '\/' + folder)\n    count_img = 0\n    for file in file_names:\n        bw_img = image.load_img(path+'\/'+folder+'\/'+file, target_size=(100, 100))\n        img = image.img_to_array(bw_img)\n        y.append(img)\n        color_img = image.load_img(path+'\/'+folder+'\/'+file, target_size=(100, 100), color_mode=\"grayscale\")\n        img = image.img_to_array(color_img)\n        X.append(img)\n        count_img += 1\n        if count_img == 100:\n            break","ac27cb7d":"X = np.array(X).astype(\"float32\") \/ 255\ny = np.array(y).astype(\"float32\") \/ 255\nprint(X.shape, y.shape)","bad8a838":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","4ae4527d":"model_inputs = keras.Input(shape=(100, 100, 1))\nx = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(model_inputs)\nx = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\nx = layers.Flatten()(x)\nx = layers.Dense(100, activation=\"relu\")(x)\nx = layers.Dense(25 * 25 * 64, activation=\"relu\")(x)\nx = layers.Reshape((25, 25, 64))(x)\nx = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\nx = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\nmodel_outputs = layers.Conv2DTranspose(3, 3, activation=\"sigmoid\", padding=\"same\")(x)\nmodel = keras.Model(model_inputs, model_outputs, name=\"colorizer\")\nmodel.summary()","12b7e90c":"model.compile(optimizer='adam', loss='mse')\nmodel.fit(X_train, y_train, epochs=30, batch_size=64)","e0c8fad2":"y_pred = model.predict(X_test)","c5f1dd6e":"print(X_test[0].shape)\noriginal_img = image.img_to_array(X_test[0])\nplt.imshow(original_img)","5192e737":"print(y_test[100].shape)\npredicted_img = image.array_to_img(y_test[100])\nplt.imshow(predicted_img)","f21e2bb0":"print(y_pred[100].shape)\npredicted_img = image.array_to_img(y_pred[100])\nplt.imshow(predicted_img)","7db12c27":"# Image colorization\n\n#### Here we attempt to train a model to colorize black and white images ie. to reconstruct black and white images to color images","570cce67":"## Populating the data as arrays\n\n#### The input X is the set of black and white images and the output y is the color version of the respective images","edc2d449":"## View a sample of the color version in the test set","fbd91457":"## View a sample of the model-colorized image","ea5fe1ec":"## Function to plot five images from a particular folder","da5c2701":"## Checking the various folders available in the dataset","3f11e931":"## View a sample of grayscale image","b9a12c68":"#### As we can observe, the model is able to obtain the right colors in the output but the resolution is quite low. This can possibly be remedied by a deeper architecture, more training, or a better loss function","3832aa54":"## Importing necessary libraries","6623b44e":"## Training the model","42c0e1d2":"## CNN model architecture\n\n#### The architecture resembles an autoencoder, with only the number of channels in the input an output being different","d45fa433":"## Split data to form train and test sets","d606d625":"## Converting to Numpy arrays and normalizing","5f0bb7c7":"## Obtaining the predictions on the test set"}}