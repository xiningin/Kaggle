{"cell_type":{"8821d84a":"code","ac500367":"code","f1a6fc90":"code","eeac5994":"code","3d1ecd83":"code","95f3f648":"code","f1e670d0":"code","85cec43b":"code","ee193926":"code","4d23fef9":"code","665ee67a":"code","f3880149":"code","5f5af8e3":"code","06f1cbc0":"code","dc7495f5":"code","238f54f8":"code","86870206":"code","0cedba7c":"code","39caa6dc":"code","d6e57b6e":"code","1c8185ee":"markdown","5ba323d4":"markdown","ba82927e":"markdown","58fd0d6b":"markdown","6b128d37":"markdown","47bb1372":"markdown","cc91e7f1":"markdown","6bed14ed":"markdown"},"source":{"8821d84a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ac500367":"data = pd.read_csv('\/kaggle\/input\/insurance\/insurance.csv')\nprint(data)","f1a6fc90":"data.info()","eeac5994":"data.describe()","3d1ecd83":"data = pd.get_dummies(data)\ndata.head()","95f3f648":"data['charges'].plot(kind = 'hist')","f1e670d0":"data[\"log_charges\"] = np.log2(data[\"charges\"] + 0.1)\ndata[\"log_charges\"].plot(kind = 'hist')\ndata = data.drop([\"charges\"], axis=1)","85cec43b":"y = data['log_charges']\nX = data.drop(['log_charges'], axis=1)","ee193926":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.18, random_state = 1)","4d23fef9":"plt.scatter(data[\"age\"], data[\"bmi\"]);","665ee67a":"# Calculate and plot\nnumerical = list(\n    set(data.columns)\n    - {\n        \"sex_male\",\n        \"smoker_no\",\n        \"region_southwest\",\n        \"region_northwest\",\n        \"region_southeast\",\n        \"region_northeast\"\n    }\n)\ncorr_matrix = data[numerical].corr()\nsns.heatmap(corr_matrix, annot=True);","f3880149":"%config InlineBackend.figure_format = 'png'\nsns.pairplot(data[numerical]);","5f5af8e3":"sns.scatterplot(data=data, x=\"age\",y=\"log_charges\", hue=\"sex_male\")","06f1cbc0":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","dc7495f5":"from sklearn.linear_model import Ridge, LinearRegression\nfrom sklearn import metrics","238f54f8":"modelLinR= LinearRegression(normalize = True)\nmodelLinR.fit(X_train_scaled,y_train)\ny_pred_lin = modelLinR.predict(X_test_scaled)\nerror_LinR = metrics.mean_absolute_error(y_pred_lin, y_test)\nprint(error_LinR)","86870206":"modelRidR= Ridge()\nmodelRidR.fit(X_train_scaled,y_train)\ny_pred_rid = modelRidR.predict(X_test_scaled)\nerror_RidR = metrics.mean_absolute_error(y_pred_rid, y_test)\nprint(error_RidR)","0cedba7c":"from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, AdaBoostRegressor\nmodel_rf = RandomForestRegressor(max_depth=15, n_estimators=10, max_features=5)\nmodel_rf.fit(X_train_scaled, y_train)\ny_pred_rf = model_rf.predict(X_test_scaled)\nerror_rf = metrics.mean_absolute_error(y_pred_rf, y_test)\nprint(error_rf)","39caa6dc":"model_gb = GradientBoostingRegressor()\nmodel_gb.fit(X_train_scaled, y_train)\ny_pred_gb = model_gb.predict(X_test_scaled)\nerror_gb = metrics.mean_absolute_error(y_pred_gb, y_test)\nprint(error_gb)","d6e57b6e":"model_et = ExtraTreesRegressor()\nmodel_et.fit(X_train_scaled, y_train)\ny_pred_et = model_et.predict(X_test_scaled)\nerror_et = metrics.mean_absolute_error(y_pred_et, y_test)\nprint(error_et)","1c8185ee":"# **Ridge Regression:**","5ba323d4":"# Standard scaling","ba82927e":"# **Gradient Boosting Regression:**","58fd0d6b":"***From the above results, Gradient Boosting Regression works best for our dataset and has MAE equal to 0.245***","6b128d37":"# **Linear Regression:**","47bb1372":"# **Extra Trees Regression:**","cc91e7f1":"**From here we can conclude that smoking has direct correlation(0.67) with the medical charges, and then age has a correlation of 0.53**","6bed14ed":"# **Random Forest Regression:**"}}