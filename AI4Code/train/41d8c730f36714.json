{"cell_type":{"9c07a31c":"code","e5e4f2e7":"code","bfa01787":"code","06bdde70":"code","04520c83":"code","fe848be3":"code","a04589a6":"code","ab15a6da":"code","d594ae34":"code","e50f062b":"code","64e13ab8":"code","37ec2661":"code","7a387647":"code","03fa7f93":"code","0e838817":"code","f168a167":"code","9603b954":"code","a99396f2":"code","fd066c9d":"code","56d49f70":"code","9cc318df":"code","30806e3e":"code","77ba55b4":"code","a02c7aac":"code","761efc56":"code","64897b5c":"code","08dc893d":"code","0e5e0282":"code","702359f6":"code","df2d99f6":"code","28799d0b":"code","43de277a":"code","e62ed5a7":"code","eddd1ff4":"code","80f59ec0":"code","03bdc5c1":"code","0707613f":"code","caaf062e":"code","f4a7adab":"markdown","74ecdafb":"markdown","4f2168eb":"markdown","7672ac80":"markdown","5f488f81":"markdown","6de919c6":"markdown","912d62b7":"markdown","c51179a4":"markdown","7c6618d7":"markdown","980114de":"markdown","2a42a44d":"markdown","63e41efe":"markdown","b28a8c3a":"markdown","1d9f9d58":"markdown","74210678":"markdown","445451f2":"markdown","07b69d0f":"markdown","56b04770":"markdown"},"source":{"9c07a31c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e5e4f2e7":"#Reading the CSV file\ndf = pd.read_csv('\/kaggle\/input\/hr-analytics-job-change-of-data-scientists\/aug_train.csv')","bfa01787":"#Creating a function for the basic data exploration\ndef data_explore(dataframe):\n    print(\"DATA EXPLORATION\")\n    print('*'*80)\n    print(\"Shape of dataset : \",dataframe.shape)\n    print('*'*80)\n    print(dataframe.info())\n    print('*'*80)\n    print(\"STATISTICAL ANALYSIS OF NUMERICAL DATA\")\n    print('*'*80)\n    print(dataframe.describe().T)\n    print('*'*80)\n    print(\"STATISTICAL ANALYSIS OF CATEGORICAL DATA\")\n    print('*'*80)\n    print(dataframe.describe(exclude = ['float', 'int64']).T)\n    print('*'*80)\n    print(\"MISSING VALUES\")\n    print('*'*80)\n    print(dataframe.isna().sum().sort_values(ascending=False))\n    print('*'*80)\n    print(\"MISSING VALUES IN %\")\n    print('*'*80)\n    print(round(100* (dataframe.isnull().sum() \/ len(dataframe)).sort_values(ascending=False),2))\n    print('*'*80)","06bdde70":"data_explore(df)","04520c83":"df_countplot = df.drop(['target','training_hours','city_development_index','enrollee_id','city'], axis=1)\nvalues = {}\nlists =[]\nfor col in df_countplot.columns:\n    plt.figure(figsize=(12,4), dpi=150)\n    ax = sns.countplot(data=df,x=col, hue='target', palette='husl')\n    for p in ax.patches:\n        #ax.annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.05, p.get_height()+50))\n        lists.append(p.get_height())\n    values[col]=lists\n    lists=[]","fe848be3":"ser_df = {}\nfor col in df_countplot.columns:\n    counts = df[col].value_counts()\n    ser_df[col] = counts","a04589a6":"def get_insights(value, series):\n  ratio_list=[]\n  list_length = int(len(value)\/2)\n  for i in range(0, (int(list_length))):\n    sum = value[i]+value[i+list_length]\n    ratio = round(100 -(100*(value[i]\/sum)),2)\n    ratio_list.append(ratio)\n  #print(\"INSIGHTS FROM DATA\")\n  print('*'*80) \n  for i in range(0, list_length):\n    print(\"{} % from '{}' category are looking for job switch\".format(ratio_list[i], series.index[i]))\n  print('*'*80) ","ab15a6da":"for col in df_countplot.columns:\n    print(\"INSIGHTS FROM '{}' DATA\".format(col))\n    get_insights(values[col],ser_df[col])","d594ae34":"df.drop('company_size', axis=1, inplace=True)","e50f062b":"df.drop('gender',axis=1, inplace=True)","64e13ab8":"df.drop('enrollee_id', axis=1, inplace=True)","37ec2661":"plt.figure(figsize=(8,20), dpi=150)\nsns.countplot(data=df, y='city', hue='target')\nplt.xlim(0,1500)","7a387647":"city_df = pd.DataFrame({\"City\": df['city'].value_counts(),\n                        \"Ratio\": 100 * df['city'].value_counts() \/ len(df)})\ncity_df","03fa7f93":"df.drop('city', axis=1, inplace=True)","0e838817":"plt.figure(figsize=(6,3), dpi=150)\nsns.heatmap(df.corr(), annot=True)","f168a167":"plt.figure(figsize=(6,3), dpi=150)\nsns.kdeplot(data=df, x='city_development_index', hue='target', palette='husl')","9603b954":"plt.figure(figsize=(6,3), dpi=150)\nsns.kdeplot(data=df, x='training_hours', hue='target', palette='husl')","a99396f2":"#Creating a dataframe exclusively for categorical data\ncat_col_df = df.drop(['city_development_index','training_hours','target'], axis=1)","fd066c9d":"for col in cat_col_df.columns:\n    print(df[col].value_counts())","56d49f70":"for col in cat_col_df.columns:\n    df[col] = df[col].fillna(df[col].mode()[0])","9cc318df":"df.isna().sum()","30806e3e":"#Mapping experience values with symbols\ndf['experience']=df['experience'].replace('>20', '21')\ndf['experience']=df['experience'].replace('<1', '0')","77ba55b4":"#Mapping the last_new_job with numeric values\ndf['last_new_job'] = df['last_new_job'].replace('never','0')\ndf['last_new_job'] = df['last_new_job'].replace('>4','5')","a02c7aac":"df = pd.get_dummies(df)","761efc56":"#We drop the features, which have very less frequency, and would not make a significant impact\ndf.drop(['company_type_Other','major_discipline_No Major'], axis=1, inplace=True)","64897b5c":"#Preparing X and Y\nX = df.drop('target', axis=1)\ny = df['target']","08dc893d":"y.value_counts()","0e5e0282":"plt.figure(figsize=(6,3),dpi=150)\nsns.countplot(data=df,x='target', palette ='husl')","702359f6":"from imblearn.over_sampling import SMOTE\nsmote=SMOTE(sampling_strategy='not majority')\nX_sm , y_sm = smote.fit_resample(X,y)","df2d99f6":"y_sm.value_counts()","28799d0b":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, plot_confusion_matrix,classification_report","43de277a":"#Splitting the train-test\nX_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.15, random_state=42)","e62ed5a7":"#Scaling the data using standardization\nscaler = StandardScaler()\nscaled_X_train = scaler.fit_transform(X_train)\nscaled_X_test = scaler.transform(X_test)","eddd1ff4":"#Training the model with Logistic Regression\nmodel_lr = LogisticRegression()\nmodel_lr.fit(scaled_X_train, y_train)","80f59ec0":"pred_lr = model_lr.predict(scaled_X_test)","03bdc5c1":"accuracy_score(y_test,pred_lr)","0707613f":"plot_confusion_matrix(model_lr,scaled_X_test,y_test)","caaf062e":"print(classification_report(y_test,pred_lr))","f4a7adab":"#### From the counts, it makes sense to replace the missing values with the most frequent values, hence replacing the missing values,","74ecdafb":"#### From the % values, we find the following trends:\n#### 1. Gender does not show a clear trend in people looking for jobs\n#### 2. Company size also does not have a clear distinction among the people who may leave, and the unique values are high\n#### Hence we drop these features","4f2168eb":"![](http:\/\/images.app.goo.gl\/AG87ngHW1kCjzp2XA)\n\nThe data here is related to the HR analytics of a company, to estimate the candidates looking for a job change, and the factors influencing that\n\nWe have main keys points to note in this dataset:\n1. Most of the data is categorical\n2. There is an imbalance in the classes\n3. There are lots of missing values","7672ac80":"#### Now, from the plots, we might not get a clear idea as we know the data is imbalanced, and hence only count plots will not suffice in this case, let's check for some insights in % values","5f488f81":"# Handling Imbalance in Data","6de919c6":"#### We use SMOTE to oversample the imbalanced class","912d62b7":"#### We get an accuracy score of 83%.","c51179a4":"#### Both 'city development index' and 'training hours' seems to have a good correlation","7c6618d7":"#### Let's analyse the feature value counts","980114de":"#### Creating a function to get insights in % from the categorical data","2a42a44d":"#### We have only 'city' feature left to be explored in categorical features, so let's explore that ","63e41efe":"# Dealing with Missing values","b28a8c3a":"# Plotting Categorical Features","1d9f9d58":"#### From the plot, and the above table, we find that the 'city' feature has upto 123 unique values, and would not contribute much, hence we drop the feature","74210678":"#### Now, we need to map the values, and here we use the get_dummies method for that","445451f2":"#### Now let's focus on the numerical data, and check if we can find a trend there","07b69d0f":"# Logistic Regression","56b04770":"### We have a lots of categorical features in the dataset, and hence let's do some plotting to analyse any trends, in categorical features"}}