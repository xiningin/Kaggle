{"cell_type":{"9a0943b4":"code","4e694132":"code","bb2f6910":"code","eb013a39":"code","78324785":"code","e3d9aba9":"code","c95b929e":"code","214c0cd3":"code","d38bda95":"code","2356732e":"code","006f4d48":"code","37a41f98":"code","d059f474":"code","e72cd8fd":"code","569ec970":"code","061ce077":"code","782db1f3":"code","d3fcb7a6":"code","3d7f3bd3":"code","ba52314c":"code","a77ba626":"code","d4a82b7e":"code","78f4607e":"code","6d76c7f2":"code","72fb8271":"markdown","692230be":"markdown","76921b4b":"markdown","581e1c73":"markdown","0cbf7566":"markdown","137bfc81":"markdown"},"source":{"9a0943b4":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom sklearn.utils import shuffle\nfrom sklearn.utils import class_weight\nfrom sklearn.preprocessing import minmax_scale\nimport random\nimport cv2\nfrom imgaug import augmenters as iaa\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Input, BatchNormalization, GlobalAveragePooling2D\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.experimental import CosineDecay\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.applications import EfficientNetB4\nfrom tensorflow.keras.layers.experimental.preprocessing import RandomCrop,CenterCrop, RandomRotation\n\n##\ucd94\uac00\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import StratifiedKFold\nimport imgaug as ia\nimport imgaug.augmenters as iaa\nimport tensorflow_datasets as tfds\nimport json\nfrom tensorflow.keras.activations import softmax\nfrom tensorflow.keras.losses import CategoricalCrossentropy","4e694132":"training_folder = '..\/input\/cassava-leaf-disease-merged\/train\/' #\ud6c8\ub828\ud560 \uc774\ubbf8\uc9c0\ub4e4\uc774 \uc788\ub294 \ud3f4\ub354\nsamples_df = pd.read_csv('..\/input\/cassava-leaf-disease-merged\/merged.csv')#\ud6c8\ub828\ud560 \uc774\ubbf8\uc9c0\uc758 \uc774\ub984 \ubc0f \uac01 label \ub370\uc774\ud130 \ub85c\ub4dc\nsamples_df[\"filepath\"] = training_folder+samples_df[\"image_id\"] #\uc0ac\uc9c4\uc744 \ubd88\ub7ec\uc624\uae30 \uc27d\ub3c4\ub85d \ud3f4\ub354\uc640 \uc774\ubbf8\uc9c0\uc758 \uc774\ub984\uc744 \ud569\uccd0 \uacbd\ub85c\ub97c \uc0dd\uc131\nsamples_df = samples_df.drop(['image_id'],axis=1) #\ud544\uc694\uc5c6\ub294 \uc774\ubbf8\uc9c0 \uc774\ub984\uc744 \ubaa8\ub450 \ubc84\ub9bc","bb2f6910":"samples_df = samples_df.sort_values(by='source') #2019\ub144 \ub300\ud68c\uc758 \ub370\uc774\ud130\uc640 \uc774 \ub300\ud68c\uc758 \ub370\uc774\ud130\ub85c \ubd84\ub958","eb013a39":"\"\"\"\n\uc544\ub798\uc758 \ucf54\ub4dc\ub294 500x500\uc758 \ud06c\uae30\ubcf4\ub2e4 \ub354 \uc791\uc740 \uc0ac\uc9c4\ub4e4\uc744 \uc81c\uac70\ud558\uae30 \uc704\ud574\uc11c \uadf8\ub7ec\ud55c \uc0ac\uc9c4\ub4e4\uc744 \ucc3e\ub294 \ucf54\ub4dc\uc785\ub2c8\ub2e4. \n\uc544\ub798 small_list\uc758 \uac12\uacfc \ub3d9\uc77c\ud558\ub2c8 \uaf2d \uc2e4\ud589\ud560 \ud544\uc694\uac00 \uc5c6\uc2b5\ub2c8\ub2e4.\n\"\"\"\nsmall_list = []\nfor i in range (4940):\n    img = np.array(Image.open(samples_df.filepath.iloc[i])).shape\n    if (img[0] < 500 or img[1] < 500):\n        print(img)\n        small_list.append(samples_df.iloc[i].name)\nprint(small_list)","78324785":"small_list = [23219, 22850, 22832, 21743, 21982, 21932, 21419, 21697, 22125, 22036, 22308, 25510, 25270, 25319, 26274, 26301, 25771, 25964, 25988, 25898, 25882, 24104, 24897, 25080, 24959, 24592, 24496]\n#\uc774\ubbf8\uc9c0 \uc0ac\uc774\uc988\uac00 500x500\ubcf4\ub2e4 \uc791\uc740 \uc0ac\uc9c4\ub4e4","e3d9aba9":"samples_df = samples_df.drop(small_list, axis=0) #\uc774\ubbf8\uc9c0 \uc0ac\uc774\uc988\uac00 500x500\ubcf4\ub2e4 \uc791\uc740 \uc0ac\uc9c4\ub4e4\uc744 \ubc84\ub9bc","c95b929e":"samples_df = samples_df.drop(['source'],axis=1) #\ud544\uc694\uc5c6\uc5b4\uc9c4 source\ub97c \ubc84\ub9bc","214c0cd3":"samples_df = shuffle(samples_df, random_state=42) #\ub370\uc774\ud130\ub97c \ubb34\uc791\uc704\ub85c \uc11e\uc74c","d38bda95":"samples_df.groupby('label').label.count() #\uac01 label\ub4e4\uc758 \uac1c\uc218\ub97c \ucd9c\ub825","2356732e":"samples_df.head() #samples_df\uc758 \uc55e\ubd80\ubd84\uc744 \uc608\uc2dc\ub85c \ucd9c\ub825","006f4d48":"\"\"\"\n\uac01 label\ub4e4\uc758 \uac1c\uc218\uac00 \uc11c\ub85c \ub9ce\uc774 \ub2e4\ub974\uae30 \ub54c\ubb38\uc5d0, stratifiedKFold\ub97c \uc0ac\uc6a9\ud558\uc5ec train \ub370\uc774\ud130\uc640 validation \ub370\uc774\ud130\ub97c \ub098\ub204\uc5b4\uc90d\ub2c8\ub2e4.\n\uc5ec\uae30\uc11c\ub294 4 fold\ub97c \uc0ac\uc6a9\ud588\uc73c\uba70, \ud55c \ubc88\uc5d0 \ud55c fold\ub9cc\uc744 \ud6c8\ub828\ud569\ub2c8\ub2e4. (kaggle \ub178\ud2b8\ubd81\uc740 \ud55c \ubc88\uc5d0 \uc5f0\uc18d 9\uc2dc\uac04\uae4c\uc9c0\ub9cc \uc0ac\uc6a9\ud560 \uc218 \uc788\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4)\n\ud300\uc744 \uc774\ub8e8\uac70\ub098 \uc5ec\ub7ec \uacc4\uc815\uc744 \uc774\ub8e8\uc5b4 \uac01\uac01 \ub3cc\ub824\uc11c \ud569\uce58\ub294 \ubc29\ubc95\uc744 \ucd94\ucc9c\ub4dc\ub9bd\ub2c8\ub2e4. \n\ucc38\uace0 : https:\/\/sgmath.tistory.com\/61\n\"\"\"\nfinal_train_index = list() #\uc5b4\ub5a4 train \ub370\uc774\ud130\ub97c \uace0\ub97c\uc9c0 \uc800\uc7a5\ud558\ub294 list\ub97c \uc815\uc758\nfinal_test_index = list() #\uc5b4\ub5a4 test \ub370\uc774\ud130\ub97c \uace0\ub97c\uc9c0 \uc800\uc7a5\ud558\ub294 list\ub97c \uc815\uc758\nskf = StratifiedKFold(n_splits=4, random_state=42) #4 fold\ub97c \ud558\ub294 stratifiedKFold\ub97c \uc120\uc5b8 (validation 25%)\nfor train_index, test_index in skf.split(samples_df.filepath, samples_df.label): #stratifiedKFold\ub97c \uc791\ub3d9\ud558\ub294 \ubc18\ubcf5\ubb38\n    print(\"TRAIN:\", train_index.shape, \"TEST:\", test_index.shape) #\uac01 fold\uc5d0 \ud574\ub2f9\ud558\ub294 \ub370\uc774\ud130\ub97c \ucd9c\ub825\n    final_train_index.append(train_index) #final_train_index\uc5d0 \uac01 fold\uc5d0 \ud574\ub2f9\ud558\ub294 \ub370\uc774\ud130\ub97c \uc785\ub825\n    final_test_index.append(test_index) #final_test_index\uc5d0 \uac01 fold\uc5d0 \ud574\ub2f9\ud558\ub294 \ub370\uc774\ud130\ub97c \uc785\ub825","37a41f98":"\"\"\"\n0\uc73c\ub85c \ub418\uc5b4 \uc788\ub294 \uacf3\uc758 \uc22b\uc790\ub97c \ubc14\uafb8\ub294 \uac83\uc73c\ub85c \uba87 \ubc88\uc9f8 fold\uc758 \ub370\uc774\ud130\ub85c \ud6c8\ub828\uacfc validation\uc744 \ud560 \uac83\uc778\uc9c0 \uacb0\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \n\ud55c \ubc88 \ud6c8\ub828 \ud6c4 \uc22b\uc790\ub97c \ubc14\uafb8\uc5b4 \ucd1d 4\ubc88 (fold\uc758 \uac1c\uc218) \ud6c8\ub828\ud558\uba74 \ub429\ub2c8\ub2e4.\n\"\"\"\ntraining_df = samples_df.iloc[final_train_index[0]] #train \ub370\uc774\ud130\ub97c \ub9cc\ub4ec\nvalidation_df = samples_df.iloc[final_test_index[0]] #validation \ub370\uc774\ud130\ub97c \ub9cc\ub4ec","d059f474":"batch_size = 8 # \ubc30\uce58 \uc0ac\uc774\uc988\ub97c \uc124\uc815\nimage_size = 500 # \uc774\ubbf8\uc9c0\uc758 \ud06c\uae30\ub97c \uc124\uc815\ninput_shape = (500, 500, 3) #\uc774\ubbf8\uc9c0\uc758 \uc0ac\uc774\uc988 \uc815\uc758 (\uceec\ub7ec \uc774\ubbf8\uc9c0\uc774\uae30 \ub54c\ubb38\uc5d0 \ud55c \ud654\uc18c\ub2f9 3\uac1c\uc758 \ub370\uc774\ud130\uac00 \ud544\uc694)\ndropout_rate = 0.4 #\ub4dc\ub86d\uc544\uc6c3 \ube44\uc728 \uc815\uc758\nclasses_to_predict = sorted(training_df.label.unique()) #\uc608\uce21\ud574\uc57c \ud558\ub294 \ud074\ub798\uc2a4 \uc218 \uc815\uc758, \uc5ec\uae30\uc11c\ub294 5\uac1c","e72cd8fd":"\"\"\"\ntrain \ub370\uc774\ud130\uc640 validation \ub370\uc774\ud130\ub97c \ud150\uc11c\ud50c\ub85c\uc6b0 Dataset\uc73c\ub85c \uc815\uc758\ud569\ub2c8\ub2e4.\n\ud150\uc11c\ud50c\ub85c\uc6b0 Dataset\ub294 \ub3d9\uc801\uc73c\ub85c \ub370\uc774\ud130\ub97c \ubd88\ub7ec\uc640, \ub108\ubb34 \ub9ce\uc740 \ub370\uc774\ud130\uac00 \uba54\ubaa8\ub9ac\uc5d0 \uc4f0\uc5ec\uc9c0\ub294 \uc77c\uc744 \ubc29\uc9c0\ud558\uc5ec \ud37c\ud3ec\uba3c\uc2a4\uac00 \ud5a5\uc0c1\ub429\ub2c8\ub2e4.\n\ub354 \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 \uc544\ub798\uc758 \ub9c1\ud06c\ub97c \ucc38\uc870\ud558\uc138\uc694.\nhttps:\/\/www.tensorflow.org\/guide\/data_performance?hl=ko\n\"\"\"\ntraining_data = tf.data.Dataset.from_tensor_slices((training_df.filepath.values, training_df.label.values))\nvalidation_data = tf.data.Dataset.from_tensor_slices((validation_df.filepath.values, validation_df.label.values))","569ec970":"def load_image_and_label_from_path(image_path, label): #\uc774\ubbf8\uc9c0 \ub370\uc774\ud130\ub97c \ubd88\ub7ec\uc640 \ud150\uc11c (array\uc640 \ube44\uc2b7\ud55c \ud615\ud0dc)\ub85c \ubcc0\ud658\ud558\ub294 \ud568\uc218\n    img = tf.io.read_file(image_path) #\uc774\ubbf8\uc9c0 \uacbd\ub85c\uc758 \ud30c\uc77c\uc744 \uc77d\uc74c\n    img = tf.image.decode_jpeg(img, channels=3) #\uc774\ubbf8\uc9c0\ub97c array \ub370\uc774\ud130\ub85c \ubcc0\ud658\ud558\uc5ec \uc800\uc7a5\n    img = tf.image.random_crop(img, size=[image_size,image_size,3]) # \uc774\ubbf8\uc9c0\ub97c \ub79c\ub364\uc73c\ub85c \uc6d0\ud558\ub294 \uc0ac\uc774\uc988\ub85c \uc798\ub77c\uc90c. \uc911\uc559\ub9cc \uc790\ub974\uace0 \uc2f6\ub2e4\uba74 central_crop \uc0ac\uc6a9.\n    return img, label\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE #\uba54\ubaa8\ub9ac \ub3d9\uc801 \ud560\ub2f9\uc744 \uc704\ud55c AUTOTUNE\ntraining_data = training_data.map(load_image_and_label_from_path, num_parallel_calls=AUTOTUNE) #train \ub370\uc774\ud130\ub97c \ubd88\ub7ec\uc634\nvalidation_data = validation_data.map(load_image_and_label_from_path,num_parallel_calls=AUTOTUNE) #validation \ub370\uc774\ud130\ub97c \ubd88\ub7ec\uc634\n\n#train \ubc0f validation \ub370\uc774\ud130\ub97c \ud6c8\ub828\ud558\uae30 \uc88b\uac8c batch\ub85c \uc790\ub984\ntraining_data_batches = training_data.shuffle(buffer_size=1000).batch(batch_size).prefetch(buffer_size=AUTOTUNE)\nvalidation_data_batches = validation_data.shuffle(buffer_size=1000).batch(batch_size).prefetch(buffer_size=AUTOTUNE)","061ce077":"\"\"\"\nimgaug\ub97c \uc0ac\uc6a9\ud574\uc11c heavy\ud55c augmentation\uc744 \ud574\uc8fc\ub294 \ucf54\ub4dc. \uc2e4\ud589\ud558\uba74 \uc624\ud788\ub824 \uc131\ub2a5\uc774 \ub098\ube60\uc9c8 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \n\"\"\"\n\n\"\"\"augmenter = iaa.Sequential([\n    iaa.Fliplr(0.5),\n    iaa.Flipud(0.5),\n    iaa.CoarseDropout((0,0.03), size_percent=(0.02,0.25)),\n    iaa.Cutout(nb_iterations=(0,2), size=0.2, fill_mode=\"gaussian\", fill_per_channel=True),\n    iaa.GaussianBlur(sigma=(0,0.5)),\n    iaa.MultiplyBrightness((0.75,1.25)),\n    iaa.GammaContrast((0.75,1.25)),\n    iaa.PiecewiseAffine(scale=(0,0.03)),\n    \n], random_order=True)\"\"\"","782db1f3":"\"\"\"\nimgaug\ub97c tensorflow dataset\uc5d0 \uc801\uc6a9\uc2dc\ud0a4\ub294 \ud568\uc218\n\"\"\"\n\n\"\"\"def augment_fn():\n    def augment(images, labels):\n        img_dtype = images.dtype\n        img_shape = tf.shape(images)\n        images = tf.numpy_function(augmenter.augment_images,\n                                   [images],\n                                   img_dtype)\n        images = tf.reshape(images, shape = img_shape)\n        return images, labels\n    return augment\"\"\"","d3fcb7a6":"\"\"\"\nimgaug\ub85c augmentation\ud55c \uc774\ubbf8\uc9c0\ub97c \uc801\uc6a9\uc2dc\ucf1c\uc8fc\ub294 \ucf54\ub4dc\uc785\ub2c8\ub2e4\n\"\"\"\n#training_data_batches = training_data_batches.map(augment_fn())","3d7f3bd3":"\"\"\"\nimgaug\ub97c \uc801\uc6a9\ud55c \uc774\ubbf8\uc9c0\ub97c \ucd9c\ub825\ud574 \ubcfc \uc218 \uc788\ub294 \ucf54\ub4dc\uc785\ub2c8\ub2e4.\n\"\"\"\n\"\"\"def view_image(ds):\n    image, label = next(iter(ds)) # extract 1 batch from the dataset\n    image = image.numpy()\n    label = label.numpy()\n\n    fig = plt.figure(figsize=(22, 22))\n    for i in range(8):\n        ax = fig.add_subplot(2, 4, i+1, xticks=[], yticks=[])\n        ax.imshow(image[i])\n        ax.set_title(f\"Label: {label[i]}\")\nview_image(training_data_batches)\"\"\"","ba52314c":"\"\"\"\n\uc774\ubbf8\uc9c0\ub97c Augmentation \ud574\uc8fc\ub294 \ub808\uc774\uc5b4\ub97c \ub9cc\ub4e4\uc5b4\uc90d\ub2c8\ub2e4. \ubaa8\ub378\uc744 \ub9cc\ub4e4 \ub54c augmentation layer\uc744 \ub123\uc73c\uba74 \uc790\ub3d9\uc73c\ub85c \uc774\ubbf8\uc9c0\ub97c \ub2e4\uc591\ud558\uac8c \ubcc0\ud658\ud558\uc5ec \uc90d\ub2c8\ub2e4.\n\ub354 \ub9ce\uc740 augmentation\uc744 \uc801\uc6a9\ud574\ubcf4\uace0 \uc2f6\uc73c\uba74 https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/experimental\/preprocessing \uc774 \ub9c1\ud06c\ub97c \ucc38\uc870\ud558\uc138\uc694.\n\ub610\ud55c, imgaug, albumentation\uacfc \uac19\uc740 \uac15\ub825\ud55c augmentation \ub77c\uc774\ube0c\ub7ec\ub9ac\ub3c4 \uc0b4\ud3b4\ubcf4\uc138\uc694. \n\uc704\uc758 \uc228\uaca8\uc9c4 \ucf54\ub4dc\ub97c \uc5f4\uc5b4\ubcf4\uba74 \uc774 \ucf54\ub4dc\uc5d0 \uac15\ub825\ud55c augmentation\uc778 imgaug\ub97c \uc791\ub3d9\uc2dc\ud0ac \uc218 \uc788\ub294 \ucf54\ub4dc\uac00 \uc788\uc2b5\ub2c8\ub2e4. \n\"\"\"\ndata_augmentation_layers = tf.keras.Sequential(\n    [\n        layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),#\ub79c\ub364\uc73c\ub85c \uc774\ubbf8\uc9c0\ub97c \uc88c\uc6b0\ub85c \ub4a4\uc9d1\uc5b4\uc90c\n        layers.experimental.preprocessing.RandomRotation(0.25),#\uc774\ubbf8\uc9c0\ub97c \uc88c\uc6b0\ub85c 25% \uc774\ub0b4\ub85c \ub79c\ub364\uc73c\ub85c \ub3cc\ub9bc\n        layers.experimental.preprocessing.RandomZoom((-0.2, 0)),#\uc774\ubbf8\uc9c0\ub97c 0~20%\ub9cc\ud07c \ub79c\ub364\uc73c\ub85c \ucd95\uc18c\n        layers.experimental.preprocessing.RandomContrast((0.2,0.2))#\uc774\ubbf8\uc9c0\ub97c \ub300\ube44\ub97c \ub79c\ub364\uc73c\ub85c \uc870\uae08\uc529 \ubc14\uafc8\n    ]\n)\n","a77ba626":"\"\"\"\n\uc774 \ubca0\uc774\uc2a4\ub77c\uc778\uc5d0\uc11c\ub294 transfer learning\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \ubbf8\ub9ac \ud6c8\ub828\ub418\uc5b4 \uc788\ub294 \uc774\ubbf8\uc9c0\uc6a9 \ubaa8\ub378\uc744 \ubd88\ub7ec\uc640\uc11c \uadf8 \ubaa8\ub378\uc758 \ub4a4\ucabd\uc5d0 \ub098\ub9cc\uc758 \ubaa8\ub378\uc744 \ucd94\uac00\ud55c \ub4a4 \ud559\uc2b5\ud558\ub294 \ubc29\uc2dd\uc785\ub2c8\ub2e4.\n\uc9c1\uc811 \uc218\ub9ce\uc740 \ub808\uc774\uc5b4\uc758 \ubaa8\ub378\uc744 \ub514\uc790\uc778\ud558\ub294 \uac83\uc740 \uc5b4\ub835\uae30 \ub54c\ubb38\uc5d0 \uc774\ub7ec\ud55c \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n\uc5ec\uae30\uc11c\ub294 \uad6c\uae00\uc758 EfficientNetB4\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uc774 \ubaa8\ub378\uc5d0 \ub300\ud55c \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 https:\/\/arxiv.org\/pdf\/1905.11946.pdf \uc774 \ub17c\ubb38\uc744 \ucc38\uace0\ud558\uc138\uc694.\n\n\uc8fc\uc758!! imagenet \uac00\uc911\uce58 \uac12\uc744 \ub2e4\uc6b4\ubc1b\uae30 \uc704\ud558\uc5ec \uc6b0\uce21 \uc0c1\ub2e8 |< \ud45c\uc2dc\ub97c \ub204\ub974\uace0 setting\uc5d0\uc11c Internet\uc744 \ucf1c\uc918\uc57c\ud569\ub2c8\ub2e4.\n\"\"\"\nefficientnet = EfficientNetB4(weights=\"imagenet\", #\uc774\ubbf8\uc9c0\ub137 \uac00\uc911\uce58 \uac12\uc744 \ubd88\ub7ec\uc640 \uc801\uc6a9\n                              include_top=False, \n                              input_shape=input_shape, \n                              drop_connect_rate=dropout_rate)#efficientnetB4 \ubaa8\ub378\uc744 \ub85c\ub4dc\nefficientnet.trainable=True # efficientnetb4\uc758 \ud559\uc2b5\uc744 \ud5c8\uc6a9.","d4a82b7e":"model = Sequential() #\uc0c8 Sequential \ubaa8\ub378\uc744 \ub9cc\ub4ec \nmodel.add(Input(shape=input_shape)) #\uc778\ud48b\uc744 \uc774\ubbf8\uc9c0 \uc0ac\uc774\uc988\ub85c \uc124\uc815\nmodel.add(data_augmentation_layers) #\uc774\ubbf8\uc9c0 augumentation \ub808\uc774\uc5b4 \ucd94\uac00\nmodel.add(efficientnet) # efficientnetb0 \ucd94\uac00\nmodel.add(layers.GlobalAveragePooling2D()) # \ud480\ub9c1 \ub808\uc774\uc5b4\ub97c \ucd94\uac00\nmodel.add(layers.Dropout(dropout_rate)) # \ub4dc\ub86d\uc544\uc6c3 \ub808\uc774\uc5b4\ub97c \ucd94\uac00\nmodel.add(Dense(len(classes_to_predict), activation=\"softmax\")) #\ub9c8\uc9c0\ub9c9 \ub374\uc2a4 \ub808\uc774\uc5b4\ub97c \ucd94\uac00. \uc608\uce21\ud560 \ud074\ub798\uc2a4\uc758 \uac1c\uc218\ub9cc\ud07c\uc774 \uc544\uc6c3\ud48b\uc774 \ub41c\ub2e4. \nmodel.summary() #\ubaa8\ub378 \ud655\uc778","78f4607e":"epochs = 18#\uc5d0\ud3ed \uc218\ub97c \uc124\uc815\ndecay_steps = int(round(len(training_df)\/batch_size))*epochs\ncosine_decay = CosineDecay(initial_learning_rate=1e-4, decay_steps=decay_steps, alpha=0.3)#learning rate\ub97c \uc5d0\ud3ed\uc774 \uc9c0\ub0a0\uc218\ub85d \uc810\uc810 \uc904\uc5ec\ub098\uac00\ub294 cosine decay \ubc29\ubc95\uc744 \uc0ac\uc6a9\n\ncallbacks = [ModelCheckpoint(filepath='efficientnetb4_2019dataset.h5', monitor='val_loss', save_best_only=True),#\uac00\uc7a5 validation loss\uac00 \ub0ae\uc740 \uc5d0\ud3ed\uc758 \ubaa8\ub378\uc744 .h5 \ud30c\uc77c\ub85c \uc800\uc7a5 \n            EarlyStopping(monitor='val_loss', patience = 3, verbose=1)]#\uc815\ud574\uc9c4 \uc5d0\ud3ed\uc774 \ub418\uae30 \uc804\uc5d0 3\ubc88\uc758 \uc5d0\ud3ed\ub3d9\ud55c validation loss\uac00 \ud5a5\uc0c1\ub418\uc9c0 \uc54a\uc73c\uba74 \ud559\uc2b5\uc744 \uc885\ub8cc\n\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tfa.optimizers.Lookahead(Adam(cosine_decay)), metrics=[\"accuracy\"]) #loss\ub294 sparse_categorical_crossentropy, optimizer\ub294 Adam\uc744 \uc0ac\uc6a9. \uac01 \uc5d0\ud3ed\ub2f9 \uc815\ud655\ub3c4\ub97c \ud1b5\ud574 \ubaa8\ub378\uc758 \uc131\ub2a5\uc744 \ubaa8\ub2c8\ud130\ub9c1\ud568 ","6d76c7f2":"history = model.fit(training_data_batches,  #\ubaa8\ub378\uc744 \ud559\uc2b5\ud569\ub2c8\ub2e4. \n                  epochs = epochs, \n                  validation_data=validation_data_batches,\n                  callbacks=callbacks)","72fb8271":"# **\ubaa8\ub378 \ub9cc\ub4e4\uae30 \ubc0f \ud559\uc2b5**","692230be":"# **\uc5ec\ub7ec\uac00\uc9c0 loss**\n\uc704\uc5d0\uc11c \uc4f4 categorical crossentropy \ubfd0\ub9cc \uc544\ub2c8\ub77c \uc5ec\ub7ec\uac00\uc9c0 loss\ub97c \uc0ac\uc6a9\ud574 \ubcfc \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \ub300\ud68c\uc758 \uc0ac\uc9c4\ub4e4\uc740 \ud574\ub2f9\ud558\ub294 \ubcd1\uc774 \uc798\ubabb \uc785\ub825\uc774 \ub418\uc5b4\uc788\ub294 \uac83\ub4e4\uc774 \ub9ce\uc2b5\ub2c8\ub2e4. \uc774\uac83\uc744 noisy labels\ub77c\uace0 \ubd80\ub985\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uc0c1\ud669\uc5d0\uc11c \uc0ac\uc6a9\ud560 \uc218 \uc788\ub294 \uc5ec\ub7ec\uac00\uc9c0 \ubc29\ubc95\ub4e4\uc774 \uc18c\uac1c\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \n1. symmetric cross entropy --> \ub17c\ubb38 : https:\/\/arxiv.org\/abs\/1908.06112  \ucf54\ub4dc : https:\/\/www.kaggle.com\/c\/cassava-leaf-disease-classification\/discussion\/208324\n2. bi-tempered loss --> https:\/\/www.kaggle.com\/c\/cassava-leaf-disease-classification\/discussion\/209773\n3. taylor cross entropy loss --> https:\/\/www.kaggle.com\/c\/cassava-leaf-disease-classification\/discussion\/209782","76921b4b":"# **Cassava Competition**\n\uc774 competition\uc740 \uc5f4\ub300\uc5d0 \uc11c\uc2dd\ud558\ub294 \uce74\uc0ac\ubc14 \ub098\ubb34\uc5d0 \ubc1c\ubcd1\ud558\ub294 \uc9c8\ubcd1 4\uac1c\uc640 \uac74\uac15\ud55c \uc0c1\ud0dc, \uc989 5\uac00\uc9c0\uc758 class\ub4e4\uc744 \ubd84\ub958\ud558\ub294 classification \ubb38\uc81c\uc785\ub2c8\ub2e4. \uc8fc\uc5b4\uc9c0\ub294 \uc774\ubbf8\uc9c0\ub294 \ubaa8\ub450 600x800 \uc0ac\uc774\uc988\uc774\uace0, test set\uc740 \uacf5\uac1c\ub418\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4. \uac01 \uc9c8\ubcd1\ub4e4\uc758 \ud2b9\uc9d5 \ub4f1\uc740 \uc544\ub798\uc758 EDA\ub97c \ucc38\uace0\ud569\ub2c8\ub2e4. https:\/\/www.kaggle.com\/ihelon\/cassava-leaf-disease-exploratory-data-analysis\n\n\uc774 \ucf54\ub4dc\ub294 \uc774 \ubca0\uc774\uc2a4\ub77c\uc778 \ucf54\ub4dc\ub85c\ubd80\ud130 \uc5ec\ub7ec \ubc29\ubc95\ub4e4\uc744 \ud1b5\ud558\uc5ec \ub9ac\ub354\ubcf4\ub4dc \uc810\uc218\ub97c \ud5a5\uc0c1\ud55c \ucf54\ub4dc\uc785\ub2c8\ub2e4. https:\/\/www.kaggle.com\/vkehfdl1\/for-korean-cassava\n\n\uc8fc\uc11d\uc5d0 \uc790\uc138\ud55c \uc124\uba85\uc744 \uae30\uc7ac\ud558\uc600\uc2b5\ub2c8\ub2e4.\n\n\uc9c8\ubb38\uc740 \uc5b8\uc81c\ub4e0\uc9c0 \uc790\uc720\ub86d\uac8c \ud574\uc8fc\uc2dc\uba74 \ub429\ub2c8\ub2e4. tensorflow, numpy, pandas, scikit-learn\uc740 \uacf5\uc2dd \ubb38\uc11c\ub97c \ucc38\uace0\ud558\uba74 \ub354\uc6b1 \uc815\ud655\ud55c \uc815\ubcf4\ub97c \ube60\ub974\uac8c \ucc3e\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\n* Tensorflow - https:\/\/www.tensorflow.org\/api_docs\/python\/tf\n* numpy - https:\/\/numpy.org\/doc\/1.19\/\n* pandas - https:\/\/pandas.pydata.org\/pandasdocs\/stable\/reference\/index.html\n* scikit-learn - https:\/\/scikit-learn.org\/stable\/modules\/classes.html","581e1c73":"# **Submission**\n\nTTA \ubc0f \uc2e4\uc81c \ub370\uc774\ud130 submission\uc740 \uc774\uacf3\uc5d0\uc11c \ubcf4\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4! \nhttps:\/\/www.kaggle.com\/vkehfdl1\/for-korean-lb-0-895-submission\n\n**\ub3c4\uc6c0\uc774 \ub418\uc5c8\ub2e4\uba74 \uc5c5\ubcf4\ud2b8 upvote \ud55c \ubc88 \uc529 \ubd80\ud0c1\ub4dc\ub9bd\ub2c8\ub2e4! \uac10\uc0ac\ud569\ub2c8\ub2e4!**","0cbf7566":"\uc5ec\uae30\uc11c 2019 \ub370\uc774\ud130\uc14b\uacfc 2020 \ub370\uc774\ud130\uc14b\uc744 \ud569\uce5c \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. https:\/\/www.kaggle.com\/tahsin\/cassava-leaf-disease-merged","137bfc81":"# **\ub370\uc774\ud130 \uc804\ucc98\ub9ac (\uc774\ubbf8\uc9c0 \ub85c\ub4dc)**"}}