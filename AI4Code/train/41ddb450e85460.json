{"cell_type":{"fe5dcf75":"code","f0473d51":"code","f5b7f331":"code","1a7cc015":"code","b72c3b0d":"code","d21a56da":"code","93384319":"code","bc41986d":"code","76f97fce":"code","59872323":"code","68254981":"code","4c6b83ce":"code","48a7973d":"code","9b591fd6":"code","bd29327f":"code","149d24f7":"code","e4bf8835":"code","3cff5d62":"code","ca98ac15":"code","d53e0059":"code","d7508782":"code","88cfb9c4":"code","3d07aec3":"code","fb06b327":"code","1d2a0bc2":"code","ef9bf731":"code","e4ba80c9":"code","4b00f2ea":"code","035a960d":"code","3e02d2b7":"code","1d8d65c9":"code","774948a5":"code","d7410364":"code","8f4ec489":"markdown","b5d6c397":"markdown"},"source":{"fe5dcf75":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport sklearn # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport keras\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport pylab as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f0473d51":"train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv',sep = ',')\nsample = pd.read_csv('\/kaggle\/input\/digit-recognizer\/sample_submission.csv',sep = ',')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv',sep= ',')\n\nprint(\"Load dataset\/\/\/\/\")","f5b7f331":"train.head(-10)","1a7cc015":"test.head(-10)","b72c3b0d":"train.isnull().sum()","d21a56da":"test.isnull().sum()","93384319":"for i in range(0,784):\n    if train[train.columns[i]].isnull().sum()>0:\n        train[train.columns[i]].isnull().sum()\n        #print(train.columns[i],train[train.columns[i]].isnull().sum())\n        train[train.columns[i]] = train[train.columns[i]].fillna(train[train.columns[i]].mean())\n        print(train.columns[i],train[train.columns[i]].isnull().sum())","bc41986d":"X = train.drop(columns = [\"label\"])\nX.head()","76f97fce":"y = train.label\ny.head()","59872323":"train.columns","68254981":"y = train.label.values.astype('int32')","4c6b83ce":"train =train[train.columns[1:]].values.astype('float32')","48a7973d":"X_train , X_test , y_train , y_test = train_test_split(train , y , test_size = 0.2 , random_state = 100)\nprint ( X_train.shape , y_train.shape)","9b591fd6":"test = test.values.astype('float32')","bd29327f":"X_train = X_train.reshape( -1 , 28 , 28 , 1)\nX_test = X_test.reshape( -1 , 28 , 28 , 1)\ntest = test.reshape( -1 , 28 , 28 , 1)","149d24f7":"X_train.shape","e4bf8835":"train_new = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv',sep = ',')\ntrain_new = train_new.iloc[: , 1:]","3cff5d62":"plt.figure(figsize = [3, 3])\nplt.imshow(train_new.values[i].reshape(28,28), cmap='gray')","ca98ac15":"print(y_train.shape)\nprint(y_test.shape)","d53e0059":"X_train = X_train \/ 255\nX_test = X_test \/ 255\ntest = test \/ 255","d7508782":"y_train = keras.utils.to_categorical(y_train, 10)\ny_test = keras.utils.to_categorical(y_test, 10)  #  10 is used because we have to classify images in 10 groups","88cfb9c4":"print(train.shape , test.shape)","3d07aec3":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same',input_shape=(28 , 28 , 1)))\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\nmodel.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(100, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10, activation='softmax'))\nprint (model.summary())","fb06b327":"model.compile(optimizer = RMSprop(lr=0.001),loss='categorical_crossentropy', metrics=['accuracy'])","1d2a0bc2":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.0, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(X_train)","ef9bf731":"# compiling the sequential model\n","e4ba80c9":"batch_size=128\nepochs=50\nlr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=0.0001, patience=1, verbose=1)","4b00f2ea":"model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n                    steps_per_epoch=X_train.shape[0] \/\/ batch_size,\n                    callbacks=[lr_reduce],\n                    validation_data=(X_test, y_test),\n                    epochs = epochs, verbose = 1)","035a960d":"score = model.evaluate(X_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])\n#model.save(\"model.h5\")","3e02d2b7":"results = model.predict(test)","1d8d65c9":"results = np.argmax(results, axis = 1)\nresults = pd.Series(results, name = 'Label')","774948a5":"results","d7410364":"submission = pd.concat([pd.Series(range(1, 28001), name = 'ImageId'), results], axis = 1)\nsubmission.to_csv(\"MNIST_Dataset_Submissions.csv\", index = False)\nprint(\"save\")","8f4ec489":"   optimizer=\"rmsprop\",\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"sparse_categorical_accuracy\"],","b5d6c397":"loss='sparse_categorical_crossentropy'\n"}}