{"cell_type":{"e060999a":"code","4d18b009":"code","c98cd0a1":"code","f5dc6a0d":"code","239fbd41":"code","5abd405c":"code","39e75417":"code","e5deca16":"code","e950dbd8":"code","88ded2b2":"code","237f9e48":"code","10412601":"code","05248a79":"code","d10891d4":"code","d3c05b5c":"code","1e9cbd0b":"code","eefb05b4":"code","b5fdcaa5":"code","dc405eb2":"markdown","d76b7d9e":"markdown","96cd8499":"markdown","28fe9725":"markdown","fbdf47f8":"markdown","a2d01d2e":"markdown","981bb518":"markdown"},"source":{"e060999a":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn import svm\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline","4d18b009":"train = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")","c98cd0a1":"print(train.describe())\ntrain.info()","f5dc6a0d":"df1 = train.loc[:,['Time','Amount','Class']]\ndf1.head()","239fbd41":"df1.describe()","5abd405c":"#Class value classifies clients into\n#'normal' and 'fraudenlent'\nprint(df1.Class.value_counts())","39e75417":"rs = RobustScaler()\ntrain1=train\ntrain1['scaled_time'] = rs.fit_transform(train['Time'].values.reshape(-1,1))\ntrain1['scaled_amount'] = rs.fit_transform(train['Amount'].values.reshape(-1,1))\ntrain1.drop(['Time', 'Amount'], axis=1, inplace=True)","e5deca16":"train1.describe()","e950dbd8":"x = train1.drop([\"Class\"],axis = 1)\ny = train1[\"Class\"]","88ded2b2":"#70% for training and 30% for testing\n(x_train, x_test, y_train, y_test) = train_test_split(x, y, test_size= 0.3, random_state= 42)\nprint(\"Shape of train_X: \", x_train.shape)\nprint(\"Shape of test_X: \", x_test.shape)","237f9e48":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression","10412601":"dt = DecisionTreeClassifier()\ndt.fit(x_train, y_train)\ny_pred = dt.predict(x_test)\ncnf_matrix = confusion_matrix(y_test, y_pred)\nprint(classification_report(y_test,y_pred))\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True,cmap=\"YlGnBu\", fmt='g')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')","05248a79":"from imblearn.over_sampling import SMOTE\n\nsm = SMOTE(random_state=2)\nx_train_s, y_train_s = sm.fit_resample(x_train, y_train)\n\nprint(sum(y_train_s==1),sum(y_train_s==0))\n","d10891d4":"dt = DecisionTreeClassifier()\ndt.fit(x_train_s, y_train_s)\ndt_pred = dt.predict(x_test)\ncnf_matrix = confusion_matrix(y_test, dt_pred)\nprint(classification_report(y_test,dt_pred))\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\", fmt='g')\nplt.ylabel('Actual Label')\nplt.xlabel('Predicted Label')","d3c05b5c":"rfc = RandomForestClassifier()\nrfc.fit(x_train_s,y_train_s)\nrfc_pred = rfc.predict(x_test)\nprint(classification_report(y_test,rfc_pred))","1e9cbd0b":"rfc_cnf_matrix = confusion_matrix(y_test, rfc_pred)\nsns.heatmap(pd.DataFrame(rfc_cnf_matrix), annot=True, cmap=\"YlGnBu\", fmt='g')\nplt.ylabel('Actual Label')\nplt.xlabel('Predicted Label')","eefb05b4":"mlpc = MLPClassifier(hidden_layer_sizes=200,max_iter = 500)\nmlpc.fit(x_train_s,y_train_s)\nmlpc_pred =mlpc.predict(x_test)\nprint(classification_report(y_test,mlpc_pred))","b5fdcaa5":"rfc_cnf_matrix = confusion_matrix(y_test, mlpc_pred)\nsns.heatmap(pd.DataFrame(rfc_cnf_matrix), annot=True, cmap=\"YlGnBu\", fmt='g')\nplt.ylabel('Actual Label')\nplt.xlabel('Predicted Label')","dc405eb2":"# Models without SMOTE","d76b7d9e":"# Neural Network","96cd8499":"Luckily there is no null value in our data.","28fe9725":"The data is imbalanced and the result is bad and lack of accuracy. \\\nThus we will apply SMOTE to balance the data.","fbdf47f8":"# Random Forest Classifier","a2d01d2e":"The genuine transaction is way more than fraudenlent ones.\\\nAnd the numerical value of 'Time' and 'Amount' variable is not in the best form for classification models.\\\nLet\u2019s apply scaling techniques on the features \u201cAmount\" and \"Time\u201d to transform the range of values. We drop the original  columns and add new columns with the scaled values.","981bb518":"# Data info"}}