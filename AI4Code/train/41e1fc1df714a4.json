{"cell_type":{"dc3f2f0e":"code","32c0c831":"code","b76bf4c7":"code","91ebced2":"code","599c8c5a":"code","a42b2d8f":"code","a5ffcf0f":"code","bbe62107":"code","6ef0c1db":"code","70b821df":"code","dae15e39":"code","f5de7edd":"code","f534cd51":"code","2c06f0b5":"code","a37017a6":"code","f7f8605f":"code","73051c14":"code","677088d4":"code","8cac211d":"code","a1dc1c88":"code","314c412b":"code","e0626f02":"code","8d32d744":"code","bdc5d294":"code","5ba1c3d7":"code","365df3bd":"code","3a6fda7d":"code","2c960abf":"code","61e82426":"code","a9dcfe74":"code","b416f9dc":"code","22b03df2":"code","428021e9":"code","a9e64ece":"code","81a2d7b9":"code","5551af3b":"code","d5513da1":"code","5b6569c5":"code","b64cb6a3":"code","e3642c9c":"code","72927b0c":"code","abbfbad2":"code","b88e3d8f":"code","cb50bf3f":"code","e6ff620a":"code","5e2219e7":"code","a39daf0e":"markdown","e7cf7357":"markdown","087ad7ea":"markdown","aae26cf8":"markdown","90fe4c8d":"markdown","33e7d25f":"markdown","0cf2f02c":"markdown","13b1392a":"markdown","98bd63f6":"markdown","352e5e7c":"markdown","e9e149c8":"markdown","d673feeb":"markdown","5c119dea":"markdown","37160802":"markdown","2a079b87":"markdown","aab21c3c":"markdown","4a8157f5":"markdown"},"source":{"dc3f2f0e":"import numpy as np \nimport pandas as pd\nimport matplotlib\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline \nfrom wordcloud import WordCloud, STOPWORDS\nimport warnings\nwarnings.simplefilter(\"ignore\")","32c0c831":"tweets_df = pd.read_csv(\"\/kaggle\/input\/pfizer-vaccine-tweets\/vaccination_tweets.csv\")","b76bf4c7":"print(f\"data shape: {tweets_df.shape}\")","91ebced2":"tweets_df.info()","599c8c5a":"tweets_df.describe()","a42b2d8f":"tweets_df.head()","a5ffcf0f":"def missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()\/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    tt['Types'] = types\n    return(np.transpose(tt))","bbe62107":"missing_data(tweets_df)","6ef0c1db":"def unique_values(data):\n    total = data.count()\n    tt = pd.DataFrame(total)\n    tt.columns = ['Total']\n    uniques = []\n    for col in data.columns:\n        unique = data[col].nunique()\n        uniques.append(unique)\n    tt['Uniques'] = uniques\n    return(np.transpose(tt))","70b821df":"unique_values(tweets_df)","dae15e39":"def most_frequent_values(data):\n    total = data.count()\n    tt = pd.DataFrame(total)\n    tt.columns = ['Total']\n    items = []\n    vals = []\n    for col in data.columns:\n        itm = data[col].value_counts().index[0]\n        val = data[col].value_counts().values[0]\n        items.append(itm)\n        vals.append(val)\n    tt['Most frequent item'] = items\n    tt['Frequence'] = vals\n    tt['Percent from total'] = np.round(vals \/ total * 100, 3)\n    return(np.transpose(tt))","f5de7edd":"most_frequent_values(tweets_df)","f534cd51":"def plot_count(feature, title, df, size=1, ordered=True):\n    f, ax = plt.subplots(1,1, figsize=(4*size,4))\n    total = float(len(df))\n    if ordered:\n        g = sns.countplot(df[feature], order = df[feature].value_counts().index[:20], palette='Set3')\n    else:\n        g = sns.countplot(df[feature], palette='Set3')\n    g.set_title(\"Number and percentage of {}\".format(title))\n    if(size > 2):\n        plt.xticks(rotation=90, size=8)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()\/2.,\n                height,\n                '{:1.2f}%'.format(100*height\/total),\n                ha=\"center\") \n    plt.show()    ","2c06f0b5":"plot_count(\"user_name\", \"User name\", tweets_df,4)","a37017a6":"plot_count(\"user_location\", \"User location\", tweets_df,4)","f7f8605f":"plot_count(\"source\", \"Source\", tweets_df,4)","73051c14":"stopwords = set(STOPWORDS)\n\ndef show_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color='white',\n        stopwords=stopwords,\n        max_words=50,\n        max_font_size=40, \n        scale=5,\n        random_state=1\n    ).generate(str(data))\n\n    fig = plt.figure(1, figsize=(10,10))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize=20)\n        fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()","677088d4":"\nfrom wordcloud import WordCloud, STOPWORDS\ndef show_wordcloud(data, title=\"\"):\n    text = \" \".join(t for t in data.dropna())\n    stopwords = set(STOPWORDS)\n    stopwords.update([\"t\", \"co\", \"https\", \"amp\", \"U\"])\n    wordcloud = WordCloud(stopwords=stopwords, scale=4, max_font_size=50, max_words=500,background_color=\"black\").generate(text)\n    fig = plt.figure(1, figsize=(16,16))\n    plt.axis('off')\n    fig.suptitle(title, fontsize=20)\n    fig.subplots_adjust(top=2.3)\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.show()","8cac211d":"show_wordcloud(tweets_df['text'], title = 'Prevalent words in tweets')","a1dc1c88":"india_df = tweets_df.loc[tweets_df.user_location==\"India\"]\nshow_wordcloud(india_df['text'], title = 'Prevalent words in tweets from India')","314c412b":"us_df = tweets_df.loc[tweets_df.user_location==\"United States\"]\nshow_wordcloud(us_df['text'], title = 'Prevalent words in tweets from US')","e0626f02":"uk_df = tweets_df.loc[tweets_df.user_location==\"United Kingdom\"]\nshow_wordcloud(uk_df['text'], title = 'Prevalent words in tweets from UK')","8d32d744":"ca_df = tweets_df.loc[tweets_df.user_location==\"Canada\"]\nshow_wordcloud(ca_df['text'], title = 'Prevalent words in tweets from Canada')","bdc5d294":"def plot_features_distribution(features, title, df, isLog=False):\n    plt.figure(figsize=(12,6))\n    plt.title(title)\n    for feature in features:\n        if(isLog):\n            sns.distplot(np.log1p(df[feature]),kde=True,hist=False, bins=120, label=feature)\n        else:\n            sns.distplot(df[feature],kde=True,hist=False, bins=120, label=feature)\n    plt.xlabel('')\n    plt.legend()\n    plt.show()\n","5ba1c3d7":"tweets_df['hashtags'] = tweets_df['hashtags'].replace(np.nan, \"['None']\", regex=True)\ntweets_df['hashtags'] = tweets_df['hashtags'].apply(lambda x: x.replace('\\\\N',''))\ntweets_df['hashtags_count'] = tweets_df['hashtags'].apply(lambda x: len(x.split(',')))\nplot_features_distribution(['hashtags_count'], 'Hashtags per tweet (all data)', tweets_df)","365df3bd":"tweets_df['hashtags_individual'] = tweets_df['hashtags'].apply(lambda x: x.split(','))\nfrom itertools import chain\nall_hashtags = set(chain.from_iterable(list(tweets_df['hashtags_individual'])))\nprint(f\"There are totally: {len(all_hashtags)}\")","3a6fda7d":"tweets_df['hashtags_individual'].head()","2c960abf":"country_df = pd.read_csv(\"..\/input\/iso-country-codes-global\/wikipedia-iso-country-codes.csv\")","61e82426":"country_df.columns = [\"country\", \"alpha2\", \"alpha3\", \"numeric\", \"iso\"]\ncountry_df.head()","a9dcfe74":"tweets_df['country'] = tweets_df['user_location']","b416f9dc":"tweets_df = tweets_df.merge(country_df, on=\"country\")","22b03df2":"tweets_df.head(10)","428021e9":"tw_add_df = tweets_df.groupby([\"country\", \"iso\", \"alpha3\"])['text'].count().reset_index()\ntw_add_df.columns = [\"country\", \"iso\", \"alpha3\", \"tweets\"]","a9e64ece":"import plotly.express as px\n\ndef plot_map(dd_df, title):\n    hover_text = []\n    for index, row in dd_df.iterrows():\n        hover_text.append((f\"country: {row['country']}<br>tweets: {row['tweets']}\\\n                          <br>country code: {row['iso']}<br>country alpha3: {row['alpha3']}\"))\n    dd_df['hover_text'] = hover_text\n\n    fig = px.choropleth(dd_df, \n                        locations=\"alpha3\",\n                        hover_name='hover_text',\n                        color=\"tweets\",\n                        projection=\"natural earth\",\n                        color_continuous_scale=px.colors.sequential.Plasma,\n                        width=900, height=700)\n    fig.update_geos(   \n        showcoastlines=True, coastlinecolor=\"DarkBlue\",\n        showland=True, landcolor=\"LightGrey\",\n        showocean=True, oceancolor=\"LightBlue\",\n        showlakes=True, lakecolor=\"Blue\",\n        showrivers=True, rivercolor=\"Blue\",\n        showcountries=True, countrycolor=\"DarkBlue\"\n    )\n    fig.update_layout(title = title, geo_scope=\"world\")\n    fig.show()    ","81a2d7b9":"print(f\"tweets containing country information: {tw_add_df.tweets.sum()}\")\nprint(f\"tweets containing country information; distinct countries: {tw_add_df.country.shape[0]}\")","5551af3b":"plot_map(tw_add_df, \"Tweets per country (where country is specified)\")","d5513da1":"tweets_df['datedt'] = pd.to_datetime(tweets_df['date'])","5b6569c5":"tweets_df['year'] = tweets_df['datedt'].dt.year\ntweets_df['month'] = tweets_df['datedt'].dt.month\ntweets_df['day'] = tweets_df['datedt'].dt.day\ntweets_df['dayofweek'] = tweets_df['datedt'].dt.dayofweek\ntweets_df['hour'] = tweets_df['datedt'].dt.hour\ntweets_df['minute'] = tweets_df['datedt'].dt.minute\ntweets_df['dayofyear'] = tweets_df['datedt'].dt.dayofyear\ntweets_df['date_only'] = tweets_df['datedt'].dt.date","b64cb6a3":"tweets_agg_df = tweets_df.groupby([\"date_only\"])[\"text\"].count().reset_index()\ntweets_agg_df.columns = [\"date_only\", \"count\"]","e3642c9c":"def plot_time_variation(df, x='date_only', y='count', hue=None, size=1, title=\"\", is_log=False):\n    f, ax = plt.subplots(1,1, figsize=(4*size,3*size))\n    g = sns.lineplot(x=x, y=y, hue=hue, data=df)\n    plt.xticks(rotation=90)\n    if hue:\n        plt.title(f'{y} grouped by {hue} | {title}')\n    else:\n        plt.title(f'{y} | {title}')\n    if(is_log):\n        ax.set(yscale=\"log\")\n    ax.grid(color='black', linestyle='dotted', linewidth=0.75)\n    plt.show() ","72927b0c":"plot_time_variation(tweets_agg_df, title=\"Number of tweets \/ day of year\",size=3)","abbfbad2":"plot_count(\"dayofweek\", \"tweets \/ day of week\", tweets_df, size=3, ordered=False)","b88e3d8f":"plot_count(\"dayofyear\", \"tweets \/ day of year\", tweets_df, size=3, ordered=False)","cb50bf3f":"plot_count(\"date_only\", \"tweets \/ date\", tweets_df,size=4, ordered=False)","e6ff620a":"plot_count(\"hour\", \"tweets \/ hour\", tweets_df,size=4, ordered=False)","5e2219e7":"plot_count(\"minute\", \"tweets \/ minute\", tweets_df,size=5, ordered=False)","a39daf0e":"<h1>Explore Pfizer Vaccine Tweets<\/h1>\n\n\n# Introduction\n\n\nThe Dataset we are using here is collected using Twitter API, **tweepy** and Python package.\n","e7cf7357":"### Most frequent values","087ad7ea":"### Missing data","aae26cf8":"### Time variation","90fe4c8d":"### User location","33e7d25f":"### Text wordcloauds","0cf2f02c":"### Hashtags analysis","13b1392a":"### User name","98bd63f6":"# Data preparation\n\n## Load packages","352e5e7c":"### Extract country from location\n\nWe load the country list from the additional database we added to this Notebook. We also create a `country` column in the original dataset.","e9e149c8":"# Data exploration\n\n\n## Glimpse the data","d673feeb":"### Extract date and time features","5c119dea":"## Visualize the data distribution","37160802":"### Unique values","2a079b87":"### Tweet source","aab21c3c":"We merge the countries dataset with the tweets dataset.","4a8157f5":"## Load data"}}