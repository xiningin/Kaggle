{"cell_type":{"71cbc4db":"code","15b8af45":"code","84813cc1":"code","be830111":"code","2969fc62":"code","921b6dc1":"code","935624a5":"code","0f13bbf3":"code","8c832528":"code","6acf3315":"code","b2ae609d":"code","46dc7468":"code","65ab6d74":"code","4f26df08":"code","386afd9b":"code","74011c76":"code","9e183237":"code","1c781824":"code","091947b1":"code","f2fe0e79":"code","d51535f5":"code","d4a0d1c0":"code","95f4e992":"code","eba78fc8":"code","1ac4ab69":"code","51f7b474":"code","4bd57403":"code","322d1eb5":"markdown","9d282e5f":"markdown","64ab9677":"markdown","2cc9fb3b":"markdown","3437297b":"markdown","3b9b2cc6":"markdown","08886feb":"markdown","877ed405":"markdown","bfdde2fc":"markdown","83e83d06":"markdown","3b0faeb9":"markdown","147a68c4":"markdown","82967e54":"markdown","43254775":"markdown","bddeb881":"markdown","0c3f69ef":"markdown","2d2b36d7":"markdown","945a915b":"markdown","0d14bca4":"markdown","b3b08e9b":"markdown"},"source":{"71cbc4db":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","15b8af45":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.python.data import Dataset\nimport keras\nfrom keras.utils import to_categorical\nimport seaborn as sns\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\nfrom keras import models\nfrom keras import layers","84813cc1":"df=pd.read_csv('\/kaggle\/input\/forest-cover-type-dataset\/covtype.csv',index_col=0)","be830111":"df.head()","2969fc62":"df.info()\n# We can see all columns have diffrent data types , float64(47), int64(7).","921b6dc1":"df.describe()","935624a5":"print(df.shape)\n\n# We can see that there are 154340 instances having 55 attributes","0f13bbf3":"# Statistical description\n\npd.set_option('display.max_columns', None)\nprint(df.describe())\n\n# Learning :\n# No attribute is missing as count is 581012 for all attributes. Hence, all rows can be used\n# Negative value(s) present in Vertical_Distance_To_Hydrology. Hence, some tests such as chi-sq cant be used.\n# Wilderness_Area and Soil_Type are one hot encoded. Hence, they could be converted back for some analysis\n# Scales are not the same for all. Hence, rescaling and standardization may be necessary for some algos","8c832528":"# Skewness of the distribution\n\nprint(df.skew())\n\n# Values close to 0 show less skew\n# Several attributes in Soil_Type show a large skew. Hence, some algos may benefit if skew is corrected","6acf3315":"# Number of instances belonging to each class\n\ndf.groupby('Cover_Type').size()\n\n\n# We see that all classes not have an equal presence. So, class re-balancing is necessary","b2ae609d":"a=df['Cover_Type']\nsns.countplot(a)","46dc7468":"g = df.groupby('Cover_Type')\ng = pd.DataFrame(g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True)))\ng.head(8)","65ab6d74":"import matplotlib.pyplot as plt","4f26df08":"import numpy\n\n\n\n#sets the number of features considered\nsize = 10 \n\n#create a dataframe with only 'size' features\ndata=df.iloc[:,:size] \n\n#get the names of all the columns\ncols=data.columns \n\n# Calculates pearson co-efficient for all combinations\ndata_corr = data.corr()\n\n# Set the threshold to select only only highly correlated attributes\nthreshold = 0.5\n\n# List of pairs along with correlation above threshold\ncorr_list = []\n\n#Search for the highly correlated pairs\nfor i in range(0,size): #for 'size' features\n    for j in range(i+1,size): #avoid repetition\n        if (data_corr.iloc[i,j] >= threshold and data_corr.iloc[i,j] < 1) or (data_corr.iloc[i,j] < 0 and data_corr.iloc[i,j] <= -threshold):\n            corr_list.append([data_corr.iloc[i,j],i,j]) #store correlation and columns index\n\n#Sort to show higher ones first            \ns_corr_list = sorted(corr_list,key=lambda x: -abs(x[0]))\n\n#Print correlations and column names\nfor v,i,j in s_corr_list:\n    print (\"%s and %s = %.2f\" % (cols[i],cols[j],v))\n\n# Strong correlation is observed between the following pairs\n# This represents an opportunity to reduce the feature set through transformations such as PCA","386afd9b":"for v,i,j in s_corr_list:\n    sns.pairplot(df, hue=\"Cover_Type\", height=6, x_vars=cols[i],y_vars=cols[j] )\n    plt.show()\n\n","74011c76":"col_list = df.columns\ncol_list = [col for col in col_list if not col[0:4]=='Soil']\nfig, ax = plt.subplots(figsize=(10,10))  \nsns.heatmap(df[col_list].corr(),square=True,linewidths=1)\nplt.title('Correlation of Variables')\n\nplt.figure(figsize=(10,10))\nsns.boxplot(y='Slope',x='Cover_Type', data= df )\nplt.title('slope vs Cover_Type')\n\n\nsns.pairplot( df, hue='Cover_Type',vars=['Aspect','Slope','Hillshade_9am','Horizontal_Distance_To_Roadways','Horizontal_Distance_To_Hydrology','Horizontal_Distance_To_Fire_Points'],diag_kind=\"kde\")\nplt.show()","9e183237":"\nsns.lmplot(x='Horizontal_Distance_To_Hydrology', y='Vertical_Distance_To_Hydrology', data=df, hue='Soil_Type2',fit_reg=False)","1c781824":"sns.lmplot(x='Horizontal_Distance_To_Hydrology', y='Vertical_Distance_To_Hydrology', data=df, hue='Wilderness_Area1',fit_reg=False)","091947b1":"\n\n#names of all the attributes \ncols = df.columns\n\n#number of attributes (exclude target)\nsize = len(cols)-1\n\n#x-axis has target attribute to distinguish between classes\nx = cols[size]\n\n#y-axis shows values of an attribute\ny = cols[0:size]\n\n#Plot violin for all attributes\nfor i in range(0,size):\n    sns.violinplot(data=df,x=x,y=y[i])  \n    plt.show()\n\n#Elevation is has a separate distribution for most classes. Highly correlated with the target and hence an important attribute\n#Aspect contains a couple of normal distribution for several classes\n#Horizontal distance to road and hydrology have similar distribution\n#Hillshade 9am and 12pm display left skew\n#Hillshade 3pm is normal\n#Lots of 0s in vertical distance to hydrology\n#Wilderness_Area3 gives no class distinction. As values are not present, others gives some scope to distinguish\n#Soil_Type, 1,5,8,9,12,14,18-22, 25-30 and 35-40 offer class distinction as values are not present for many classes","f2fe0e79":"#Removal list initialize\nrem = []\n\n#Add constant columns as they don't help in prediction process\nfor c in df.columns:\n    if df[c].std() == 0: #standard deviation is zero\n        rem.append(c)\n\n#drop the columns        \ndf.drop(rem,axis=1,inplace=True)\n\nprint(rem)","d51535f5":"from sklearn import preprocessing\n\nx = df[df.columns[:55]]\ny = df.Cover_Type\nx_train, x_test, y_train, y_test = train_test_split(x, y , train_size = 0.7, random_state =  90)","d4a0d1c0":"\ntrain_norm = x_train[x_train.columns[0:10]]\ntest_norm = x_test[x_test.columns[0:10]]","95f4e992":"std_scale = preprocessing.StandardScaler().fit(train_norm)\nx_train_norm = std_scale.transform(train_norm)\n","eba78fc8":"training_norm_col = pd.DataFrame(x_train_norm, index=train_norm.index, columns=train_norm.columns) \nx_train.update(training_norm_col)\nprint (x_train.head())","1ac4ab69":"x_test_norm = std_scale.transform(test_norm)\ntesting_norm_col = pd.DataFrame(x_test_norm, index=test_norm.index, columns=test_norm.columns) \nx_test.update(testing_norm_col)\nprint (x_train.head())\n","51f7b474":"model = keras.Sequential([\n keras.layers.Dense(64, activation=tf.nn.relu,                  \n input_shape=(x_train.shape[1],)),\n keras.layers.Dense(64, activation=tf.nn.relu),\n keras.layers.Dense(8, activation=  'softmax')\n ])\n\nmodel.compile(optimizer=tf.optimizers.Adam(),\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\nhistory2 = model.fit(\n x_train, y_train,\n epochs=5, batch_size = 60,\n validation_data = (x_test, y_test))","4bd57403":"\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nimport matplotlib.pyplot as plt\nimport numpy\n\nhistory = model.fit(x_train, y_train, epochs=5,validation_split=0.7, shuffle=True)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","322d1eb5":"SKEWNESS","9d282e5f":"2) Scatter Plot(pairlot)\n\nThe plots show to which class does a point belong to. The class distribution overlaps in the plots.\n\nHillshade patterns give a nice ellipsoid patterns with each other\n\nAspect and Hillshades attributes form a sigmoid pattern\n\nHorizontal and vertical distance to hydrology give an almost linear pattern.","64ab9677":"**CLASS DISTRIBUTION**","2cc9fb3b":"**Visualize Training History**","3437297b":"* **Violin Plot** - a combination of box and density plots","3b9b2cc6":"#  Normalizing DataSet","08886feb":"* No Misssing values are presents","877ed405":"**LM PLOT**\n\n*  Horizontal_Distance_To_Hydrology & Vertical_Distance_To_Hydrology with Soil_Type2\n*  Horizontal_Distance_To_Hydrology & Vertical_Distance_To_Hydrologywith Wilderness_Area1\n\n","bfdde2fc":"**SHAPE**","83e83d06":" Normalize Testing Data by using mean and SD of training set","3b0faeb9":"As y variable is multi class categorical variable, hence using softmax as activation function and sparse-categorical cross entropy as loss function.","147a68c4":"\n\n*   HEAT MAP\n*   BOX PLOT\n*   PAIR PLOT\n\n","82967e54":"**Explorartory Data Analysis**","43254775":"Converting numpy array to dataframe","bddeb881":"\n*Normalize Training Data*\n\n","0c3f69ef":"# DATA VISUALIZATION","2d2b36d7":"DATA INTERGRATION\n\n1. Correlation\n \n* Correlation tells relation between two attributes.\n* Correlation requires continous data. Hence, ignore Wilderness_Area and Soil_Type as they are binary","945a915b":"# Data Cleaning \n\n*  Remove unnecessary columns","0d14bca4":"> ****Validating Data Through Relu Function****","b3b08e9b":"*Select numerical columns which needs to be normalized*"}}