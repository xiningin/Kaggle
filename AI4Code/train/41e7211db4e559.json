{"cell_type":{"4bcc5246":"code","e9d5ee77":"code","b42cc67d":"code","e19f9c83":"code","3ebb06c7":"code","01d15ccb":"code","c353c2df":"code","431ee879":"code","fa91d52e":"code","10786ef6":"code","c216fcee":"code","835d3458":"code","ec9e658e":"code","48282ccb":"code","942c1c4f":"code","9c55591c":"code","7dde8840":"code","100989b9":"code","4e377ef7":"code","5f9efa85":"code","811029fa":"code","e7ee2a24":"code","a9b2bcd7":"code","cb7de697":"code","e08658ff":"code","ea6fb5e3":"code","dc484f96":"code","6d553352":"code","b281e01a":"code","608bc56e":"code","1ca7bd08":"code","d39b6e99":"code","0dc40aa5":"code","9f8f5200":"code","d455809f":"code","ffc740d2":"code","6d65a081":"code","d9041b3f":"code","066a3169":"code","45a4fe77":"code","1ac2ad73":"code","b7d9ff39":"code","3d3b2327":"code","1748399d":"code","b89d1f67":"code","df268740":"code","4adad4e9":"code","74ee8c32":"code","cab65aae":"code","151585b4":"code","a60ded14":"code","eae55420":"code","12ed7640":"code","31814f25":"code","45a32b1a":"code","8fbe0a3c":"code","f7a208a8":"code","3124a9e9":"code","d8da67d7":"code","c2b75aee":"code","9563205d":"markdown","ace3da27":"markdown","0be37bcd":"markdown","93f23dcb":"markdown","7a3e2b5e":"markdown","be6ef101":"markdown","e1abb747":"markdown","470cfb16":"markdown","46406c5b":"markdown","6f933d3b":"markdown","771ee27e":"markdown","3f340cc5":"markdown","5539ae99":"markdown","4ac83b18":"markdown","5a3d0334":"markdown","1a0757c8":"markdown","9bf1c717":"markdown","4713e248":"markdown","b80383f2":"markdown","5f3aaa81":"markdown","62898b41":"markdown","0236e9e3":"markdown","78f3b13d":"markdown","8908dfc5":"markdown","81010407":"markdown","707c73ff":"markdown","3cc9502c":"markdown","486f0224":"markdown","9f7b6faf":"markdown","1f42d1fd":"markdown","b6d587f4":"markdown","eac90d2b":"markdown","628ebf7f":"markdown","fa2c86f0":"markdown","921166ce":"markdown","911cf121":"markdown","969f4169":"markdown","2237341f":"markdown","0370b92e":"markdown","0de1ee73":"markdown","4aac29b0":"markdown","15949add":"markdown","8df93c3a":"markdown","87094788":"markdown","f9f183c2":"markdown","5356c62a":"markdown","e763049d":"markdown","a6ab8880":"markdown","9354c183":"markdown","6150485b":"markdown","5fc21541":"markdown","6f2b091b":"markdown","f17f775d":"markdown","6892b07e":"markdown","47147af1":"markdown","63b0ca4a":"markdown","52d35a40":"markdown","b1ab1e6b":"markdown","0ef80c23":"markdown","44d435f2":"markdown"},"source":{"4bcc5246":"!pip install hvplot","e9d5ee77":"import time\nimport math\nimport numpy as np\nimport pandas as pd\n\nimport scipy.stats as stats\n\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import TruncatedSVD, PCA\n\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV, cross_val_predict\nfrom sklearn.metrics import (roc_curve, roc_auc_score, precision_recall_curve, classification_report, average_precision_score,\n                            PrecisionRecallDisplay)\n                            \n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport hvplot.pandas\n\nimport warnings\nwarnings.filterwarnings('ignore')","b42cc67d":"df = pd.read_csv('..\/input\/ibm-hr-analytics-attrition-dataset\/WA_Fn-UseC_-HR-Employee-Attrition.csv')\ndf.head()","e19f9c83":"df.iloc[0,:]","3ebb06c7":"df.describe()","01d15ccb":"print(df.Department.unique())\nprint(df.BusinessTravel.unique())\nprint(df.EducationField.unique())\nprint(df.Gender.unique())\nprint(df.JobRole.unique())\nprint(df.MaritalStatus.unique())\nprint(df.Attrition.unique())","c353c2df":"fig, ax = plt.subplots(1,2, figsize = (16,4))\nsns.distplot(df['DailyRate'], ax = ax[0])\nsns.distplot(df['HourlyRate'], ax = ax[1])\nplt.show()","431ee879":"dfs = df.groupby(['Attrition', 'Gender']).size().reset_index()\ndfs","fa91d52e":"df_plot_Gen = df.groupby(['Attrition', 'Gender']).size().reset_index().pivot(columns = 'Attrition', index = 'Gender', values = 0)\ndf_plot_Gen","10786ef6":"df_plot_Gen.plot(kind = 'bar', stacked = True, color = ['#45A7A3','y'])\nplt.show()","c216fcee":"df_plot_Dep = df.groupby(['Attrition', 'Department']).size().reset_index().pivot(columns = 'Attrition', index = 'Department', values = 0)\ndf_plot_Bus = df.groupby(['Attrition', 'BusinessTravel']).size().reset_index().pivot(columns = 'Attrition', index = 'BusinessTravel', values = 0)\ndf_plot_Edu = df.groupby(['Attrition', 'EducationField']).size().reset_index().pivot(columns = 'Attrition', index = 'EducationField', values = 0)\ndf_plot_Job = df.groupby(['Attrition', 'JobRole']).size().reset_index().pivot(columns = 'Attrition', index = 'JobRole', values = 0)\ndf_plot_Mar = df.groupby(['Attrition', 'MaritalStatus']).size().reset_index().pivot(columns = 'Attrition', index = 'MaritalStatus', values = 0)\ndf_plot_Env = df.groupby(['Attrition', 'EnvironmentSatisfaction']).size().reset_index().pivot(columns = 'Attrition', index = 'EnvironmentSatisfaction', values = 0)\ndf_plot_Inv = df.groupby(['Attrition', 'JobInvolvement']).size().reset_index().pivot(columns = 'Attrition', index = 'JobInvolvement', values = 0)\ndf_plot_Bln = df.groupby(['Attrition', 'WorkLifeBalance']).size().reset_index().pivot(columns = 'Attrition', index = 'WorkLifeBalance', values = 0)\n#df_plot_Pro = df.groupby(['Attrition', 'YearsSinceLastPromotion']).size().reset_index().pivot(columns = 'Attrition', index = 'YearsSinceLastPromotion', values = 0)","835d3458":"fig, ax = plt.subplots(3, 3, figsize = (24, 20))\ndf_plot_Gen.plot(kind = 'bar', stacked = True, color = ['#6B8E23','y'], ax = ax[0,0])\ndf_plot_Dep.plot(kind = 'bar', stacked = True, color = ['#6B8E23','y'], ax = ax[0,1])\ndf_plot_Bus.plot(kind = 'bar', stacked = True, color = ['#6B8E23','y'], ax = ax[0,2])\ndf_plot_Edu.plot(kind = 'bar', stacked = True, color = ['#6B8E23','y'], ax = ax[1,0])\ndf_plot_Job.plot(kind = 'bar', stacked = True, color = ['#6B8E23','y'], ax = ax[1,1])\ndf_plot_Mar.plot(kind = 'bar', stacked = True, color = ['#6B8E23','y'], ax = ax[1,2])\ndf_plot_Env.plot(kind = 'bar', stacked = True, color = ['#6B8E23','y'], ax = ax[2,0])\ndf_plot_Inv.plot(kind = 'bar', stacked = True, color = ['#6B8E23','y'], ax = ax[2,1])\ndf_plot_Bln.plot(kind = 'bar', stacked = True, color = ['#6B8E23','y'], ax = ax[2,2])\n#df_plot_Pro.plot(kind = 'bar', stacked = True, color = ['#45A7A3','y'], ax = ax[3,0])\nplt.show()","ec9e658e":"df_plot_Stock = df.groupby(['MaritalStatus', 'StockOptionLevel']).size().reset_index().pivot(columns = 'StockOptionLevel', index = 'MaritalStatus', values = 0)\ndf_plot_Stock","48282ccb":"fig, ax = plt.subplots(2, 3, figsize = (24, 8))\nsns.scatterplot(data = df, x = \"JobLevel\", y = \"YearsAtCompany\", hue=\"Attrition\", palette = ['r','#307D7E'], ax = ax[0,0])\nsns.scatterplot(data = df, x = \"YearsInCurrentRole\", y = \"YearsAtCompany\", hue=\"Attrition\", palette = ['r','#307D7E'], ax = ax[0,1])\nsns.scatterplot(data = df, x = \"YearsSinceLastPromotion\", y = \"YearsAtCompany\", hue=\"Attrition\", palette = ['r','#307D7E'], ax = ax[0,2])\nsns.scatterplot(data = df, x = \"TotalWorkingYears\", y = \"YearsAtCompany\", hue=\"Attrition\", palette = ['r','#307D7E'], ax = ax[1,0])\nsns.scatterplot(data = df, x = \"YearsWithCurrManager\", y = \"YearsAtCompany\", hue=\"Attrition\", palette = ['r','#307D7E'], ax = ax[1,1])\nsns.scatterplot(data = df, x = \"HourlyRate\", y = \"YearsAtCompany\", hue=\"Attrition\", palette = ['r','#307D7E'], ax = ax[1,2])\nplt.show()","942c1c4f":"df.isna().sum()","9c55591c":"def qr_outliers(col):\n    outliers = []\n    \n    q1 = col.quantile(0.25)\n    q3 = col.quantile(0.75)\n    inter_qr = q3 - q1\n    lower_limit = q1 - 1.5 * inter_qr\n    upper_limit = q3 + 1.5 * inter_qr\n    for val in col:\n        if val > upper_limit or val < lower_limit:\n            outliers.append(val)\n    return outliers","7dde8840":"col_outliers = []\nfor col in df.columns:\n    if df[col].dtype == 'O' : continue\n    else : \n        outliers = qr_outliers(df[col])\n        if outliers != []:\n            col_outliers.append(col)\n            print(col,':' ,outliers)","100989b9":"print('NumCompaniesWorked:', df.NumCompaniesWorked.unique())\nprint('PerformanceRating:', df.PerformanceRating.unique())\nprint('StockOptionLevel:', df.StockOptionLevel.unique())","4e377ef7":"constant_cols = col_outliers[1:4]\ncol_outliers[1:4] = []\ncol_outliers","5f9efa85":"def box_plot_outliers(cols, df):\n    fig, ax = plt.subplots(7,2, figsize = (8, 15))\n    \n    i = 0\n    j = 0\n    for col in cols:\n        #print(col)\n        sns.boxplot(df[col], ax = ax[i, j])\n\n        ax[i, j].tick_params(axis = 'both', which = 'major', labelsize = 8)\n        ax[i, j].set_xlabel('')\n        ax[i, j].set_ylabel(col)\n        j += 1\n\n        df.loc[df[col] > 0, col], fitted_lambda = stats.boxcox(df[df[col] > 0][col], lmbda = None)\n        sns.boxplot(df[col], ax = ax[i, j], color = '#FEE23E')\n        ax[i, j].tick_params(axis = 'both', which = 'major', labelsize = 8)\n        ax[i, j].set_xlabel('')\n        i += 1\n        j -= 1\n        \n    fig.suptitle('Before [left] and After [Right] BoxCox Transformation for Removing Outliers ', fontsize = 12)\n    fig.subplots_adjust(top = 0.98)\n    fig.tight_layout()\n    \n    plt.show()","811029fa":"box_plot_outliers(col_outliers, df)","e7ee2a24":"def constant_cols_outliers(cols, df):\n    fig, ax = plt.subplots(3,2, figsize = (8, 5))\n    \n    i = 0\n    j = 0\n    for col in cols:\n        #print(col)\n        \n        sns.distplot(df[col], ax = ax[i, j])\n        ax[i, j].tick_params(axis = 'both', which = 'major', labelsize = 8)\n        ax[i, j].set_xlabel('')\n        ax[i, j].set_ylabel(col)\n        j += 1\n        \n        if col == 'NumCompaniesWorked':\n            df.loc[df[col] == 9, col] = np.mean(df[col])\n        elif col == 'PerformanceRating':\n            df.loc[df[col] == 4, col] = np.mean(df[col])\n        else:\n            df.loc[df[col] == 3, col] = np.mean(df[col])\n        \n        sns.distplot(df[col], ax = ax[i, j], color = 'y')\n        ax[i, j].tick_params(axis = 'both', which = 'major', labelsize = 8)\n        ax[i, j].set_xlabel('')\n        i += 1\n        j -= 1\n        \n    fig.suptitle('Before [left] and After [Right] mean imputation for Removing Constant value Outliers ', fontsize = 12)\n    fig.subplots_adjust(top = 0.98)\n    fig.tight_layout()\n    \n    plt.show()","a9b2bcd7":"constant_cols_outliers(constant_cols, df)","cb7de697":"#onehotenc = OneHotEncoder() \n#dep = pd.DataFrame(onehotenc.fit_transform(df[['Department']]).toarray())\n#df = df.drop('Department', axis = 1).join(dep)\n#df.head()","e08658ff":"%%time\n#onehotenc = OneHotEncoder()\nlabelenc = LabelEncoder()\ndf['Attrition'] = labelenc.fit_transform(df['Attrition'])\ndf['Department'] = labelenc.fit_transform(df['Department'])\ndf['EducationField'] = labelenc.fit_transform(df['EducationField'])\ndf['Gender'] = labelenc.fit_transform(df['Gender'])\ndf['JobRole'] = labelenc.fit_transform(df['JobRole'])\ndf['MaritalStatus'] = labelenc.fit_transform(df['MaritalStatus'])\ndf['BusinessTravel'] = labelenc.fit_transform(df['BusinessTravel'])\ndf['OverTime'] = labelenc.fit_transform(df['OverTime'])","ea6fb5e3":"df.info()","dc484f96":"print(df.Over18.unique())\nprint(df.EmployeeCount.unique())\nprint(df.StandardHours.unique())","6d553352":"df.EmployeeNumber.unique()","b281e01a":"df.drop('Over18', axis = 1, inplace = True)\ndf.drop('EmployeeCount', axis = 1, inplace = True)\ndf.drop('StandardHours', axis = 1, inplace = True)\ndf.drop('EmployeeNumber', axis = 1, inplace = True)","608bc56e":"fig, ax = plt.subplots(1,1, figsize = (18,12))\nsns.heatmap(df.corr(), cmap = 'RdYlGn')\nplt.show()","1ca7bd08":"fig, ax = plt.subplots(figsize = (6,3))\ndf_plot_Stock.plot(kind = 'bar', stacked = True, color = ['#388E3C','#8BC34A','#DCE775', '#FFF59D'], ax = ax)\n#plt.legend(labels = 'StockOptionLevel')\nplt.show()","d39b6e99":"df.drop('Attrition', axis = 1).corrwith(df.Attrition).sort_values().hvplot.barh(c = 'g', height = 500)","0dc40aa5":"x = df.drop('Attrition', axis = 1)\ny = df['Attrition']\nx_tsne = TSNE(n_components = 2, random_state = 34).fit_transform(x)\nx_pca = PCA(n_components = 2, random_state = 34).fit_transform(x)\nx_svd = TruncatedSVD(n_components = 2, random_state = 34).fit_transform(x)","9f8f5200":"x_pca.shape","d455809f":"fig, ax = plt.subplots(1,3, figsize = (20,8))\nsns.scatterplot(x_tsne[:,0], x_tsne[:,1], hue = y, ax = ax[0], palette = 'mako_r')\nax[0].set_title('TSNE', weight =  'bold')\nsns.scatterplot(x_pca[:,0], x_pca[:,1], hue = y, ax = ax[1], palette = 'mako_r')\nax[1].set_title('PCA', weight =  'bold')\nsns.scatterplot(x_svd[:,0], x_svd[:,1], hue = y, ax = ax[2], palette = 'mako_r')\nax[2].set_title('SVD', weight =  'bold')\nfig.suptitle('Dimension Reduction Techniques', fontsize = 16, weight = 'bold') \nplt.show()","ffc740d2":"classifiers = {\n    'Logistic Regression' : LogisticRegression(),\n    'K Neighbors Classifier': KNeighborsClassifier(),\n    'Support Vector Classifier': SVC(),\n    'Decision Tree Classifier': DecisionTreeClassifier(),\n    'Random Forest Classifier': RandomForestClassifier(),\n    'XGB Classifier': XGBClassifier(eval_metric = 'logloss'),\n    'LGBM Classifier': LGBMClassifier(),\n    'AdaBoost Classifier': AdaBoostClassifier()\n}","6d65a081":"%%time\nskf = StratifiedKFold(n_splits = 5, random_state = None, shuffle = False)\nscaler = StandardScaler()\nd1 = []\n\n#indeces and columns for classification report\nind = ['precision', 'recall', 'f1-score', 'support']\ncols = ['0', '1', 'accuracy','macro avg', 'weighted avg']\n\nfor name, clf in classifiers.items(): \n    #del d1,d2\n    d1 = [] # a list to collect the classification report of imbalanced data\n    d2 = [] # a list to collect the classification report of oversampled data\n    for train_ind, valid_ind in skf.split(x, y):\n        \n        x.iloc[train_ind] = scaler.fit_transform(x.iloc[train_ind])\n        x.iloc[valid_ind] = scaler.transform(x.iloc[valid_ind])\n        \n        clf.fit(x.iloc[train_ind], y.iloc[train_ind])\n        y_train_pred = clf.predict(x.iloc[train_ind])\n        y_valid_pred = clf.predict(x.iloc[valid_ind])\n        \n        #resamples only minority class\n        x_oversampled, y_oversampled = SMOTE(\n            sampling_strategy = 'minority', random_state = 34).fit_resample(x.iloc[train_ind], y.iloc[train_ind])\n        clf.fit(x_oversampled, y_oversampled)\n        y_valid_pred_oversampled = clf.predict(x.iloc[valid_ind])\n        \n        d3 = classification_report(y.iloc[valid_ind], y_valid_pred, output_dict = True)\n        d4 = classification_report(y.iloc[valid_ind], y_valid_pred_oversampled, output_dict = True)\n        \n        d1.append(d3)\n        d2.append(d4)\n    \n    temp_df_1 = pd.DataFrame(d1, columns = cols) #Dataframe containing the classification report for all 5-folds for imbalanced data\n    temp_df_2 = pd.DataFrame(d2, columns = cols) #Dataframe containing the classification report for all 5-folds for oversampled data\n    \n    #del report_1, report_2\n    report_1 = pd.DataFrame(index = ind, columns = cols) #classification report for imbalanced data\n    report_2 = pd.DataFrame(index = ind, columns = cols) #classification report for oversampled data\n\n    for index in ind:\n        for col in temp_df_1:\n            #del g1, g2\n            g1 = [] #containing the values for each index(accuracy, precision, etc) in 5-folds for a speicific col in imbalanced data\n            g2 = [] #containing the values for each index(accuracy, precision, etc) in 5-folds for a speicific col in oversampled data\n            \n            if col == 'accuracy':\n                report_1.loc[index,col] = np.mean(temp_df_1[col])\n                report_2.loc[index,col] = np.mean(temp_df_2[col])\n                continue\n\n            g1.append(temp_df_1[col].apply(lambda x: x[index])) #exctracting the data for each index (accuracy, precison, etc)\n            g2.append(temp_df_2[col].apply(lambda x: x[index]))\n            \n            report_1.loc[index,col] = np.mean(g1) #Taking the mean for 5-folds\n            report_2.loc[index,col] = np.mean(g2)\n        \n    print('classification report for', name, 'with imbalanced data:' )\n    print(report_1)\n    print('')\n    print('classification report for', name, 'with oversampled data:' )\n    print(report_2)\n    print('')\n    print('===============================================================')","d9041b3f":"clf","066a3169":"x_train = x_oversampled\ny_train = y_oversampled\nprint('x_imbalanced shape:', x.iloc[train_ind].shape)\nprint('x_oversampled shape:', x_oversampled.shape)\nx_test = x.iloc[valid_ind]\ny_test = y.iloc[valid_ind]\nada_clf = AdaBoostClassifier()\nada_clf.fit(x_oversampled, y_oversampled)\ny_test_pred = ada_clf.predict(x_test)","45a4fe77":"precisions, recalls, thresholds = precision_recall_curve(y_test, y_test_pred)","1ac2ad73":"print(precisions, recalls, thresholds)","b7d9ff39":"fig, ax = plt.subplots(figsize = (5,3))\ncolor = 'indianred'\n\ny_pred_decision = ada_clf.decision_function(x_test)\nAP_score = average_precision_score(y_test, y_pred_decision)\nprint('Average precision recall score for AdaBoost classifier %.1f' %(AP_score * 100))\nprecision, recall, thresholds = precision_recall_curve(y_test, y_pred_decision)\n#precision, recall, _ = precision_recall_curve(original_ytest, original_y_pred_decision)\nsns.lineplot(recall, precision, ax = ax, color = color)\nax.fill_between(recall, precision, 0, alpha = 0.2, color = color)\n\nax.set_xlabel('Recall')\nax.set_ylabel('Precision')\nax.set_title('Recall Precsion for AdaBoost classifier')\nax.legend()\nplt.show()","3d3b2327":"y_pred_decision[:5], pd.DataFrame(y_pred_decision).describe()","1748399d":"print('Thresholds: ', thresholds[-5:])\nprint('Precision: ', precision[-5:])\nprint('Recall:', recall[-5:])\nprint('===========================================================================')\nprint('Thresholds: ', thresholds[:5])\nprint('Precision: ', precision[:5])\nprint('Recall:', recall[:5])","b89d1f67":"import sklearn\nprint('sklearn version:',sklearn.__version__)\n#plt.rcParams[\"figure.figsize\"] = (5,3) #Runs with no problem in sklearn 1.0 and onwards\n#PrecisionRecallDisplay.from_estimator(lr_clf, x_test, y_test) #Runs with no problem in sklearn 1.0 and onwards\ndisp = PrecisionRecallDisplay(precision = precision, recall = recall)\ndisp.plot()","df268740":"train_class_report = {}\ntest_class_report = {}\nAP_score = {}\nauc_score = {}\n\n#fig, ax = plt.subplots(4,2, figsize = (10,12)) #Runs with no problem in sklearn 1.0 and onwards\ni = 0\n    \nfor name, clf in classifiers.items():\n    clf.fit(x_train, y_train)\n    y_train_pred = clf.predict(x_train)\n    y_test_pred = clf.predict(x_test)\n    train_class_report[name] = pd.DataFrame(classification_report(y_train, y_train_pred, output_dict = True))\n    test_class_report[name] = pd.DataFrame(classification_report(y_test, y_test_pred, output_dict = True))\n    if (name != 'K Neighbors Classifier' and name != 'Decision Tree Classifier' and name != 'Random Forest Classifier' \n        and name != 'XGB Classifier' and name != 'LGBM Classifier'):\n        print(name)\n        y_pred_decision = clf.decision_function(x_test)\n        AP_score[name] = np.round(average_precision_score(y_test, y_pred_decision),3)\n    auc_score[name] = np.round(roc_auc_score(y_test, y_test_pred),3)\n    #PrecisionRecallDisplay.from_estimator(clf, x_test, y_test, ax = ax[i\/\/2, (i)%2]) #Runs with no problem in sklearn 1.0 and onwards\n\n    i += 1\n    \n#plt.show() #Runs with no problem in sklearn 1.0 and onwards","4adad4e9":"auc_score","74ee8c32":"%%time\nfig, ax = plt.subplots(figsize = (8,5))\nfor name, clf in classifiers.items():\n    #y_predict = cross_val_predict(clf, x_test, y_test, method = 'predict')\n    y_predict = clf.predict(x_test)\n    fpr, tpr, threshold = roc_curve(y_test, y_predict)\n    auc_score = roc_auc_score(y_test, y_predict)\n    ax.plot(fpr, tpr, label = (name +' :%.2f' %(auc_score)))\n    ax.legend()\n    ax.set_xlabel('fpr', fontsize = 16)\n    ax.set_ylabel('tpr', fontsize = 16)\n    ax.set_title('Area Under Curve Score', fontsize = 18)\nplt.show()","cab65aae":"train_class_report","151585b4":"test_class_report","a60ded14":"AP_score","eae55420":"hyperparameters = {\n    'Logistic Regression':{\n                            'penalty': ['l1', 'l2'], 'C':[0.01, 0.1, 1] \n                            }, #l1 referst to lasso regression and l2 to Ridge regression, C is the inverse of (lambda, strength of regularization)\n    'K Neighbors Classifier':{\n                            'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'], 'n_neighbors': list(range(3,8,1))\n                              },#\u2018auto\u2019 will attempt to decide the most appropriate algorithm based on the values passed to fit method.\n    'Support Vector Classifier':{\n           'C': [0.01, 0.1, 0.5], 'kernel': ['rbf', 'linear', 'poly','sigmoid']\n            #C is the inverse of (lambda, strength of regularization), higher C means higher trust in training set as if it is representative for the all data\n            #The default kernel to run the algorithm of SVC(support vector classification) is rbf\n    },\n    'Decision Tree Classifier':{\n                                'criterion': ['gini', 'entropy'], 'max_depth': list(range(2,5,1))\n                                #Criterion is the function to measure the quality of a split. Supported criteria are \u201cgini\u201d for the Gini impurity and \u201centropy\u201d for the information gain\n                                }\n}","12ed7640":"%%time\n\ncv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 34)\nclfs = []\n\nfor clf, hyperparam in hyperparameters.items():\n    estimator = classifiers.get(clf)\n    grid = GridSearchCV(estimator, hyperparam, cv = cv)\n    grid.fit(x_train, y_train)\n    best_hyperparams = grid.best_params_\n    clfs.append(grid.best_estimator_)\n    print('The best hyperparameters for', clf, ':', best_hyperparams, 'with r2 score: %0.1f' %(grid.best_score_))","31814f25":"lr_clf = LogisticRegression()\nlr_clf.fit(x_train, y_train)\ny_train_pred = lr_clf.predict(x_train)\ny_test_pred = lr_clf.predict(x_test)","45a32b1a":"feature_names = x.columns\nfeature_names","8fbe0a3c":"w = np.zeros((30,))\nw = lr_clf.coef_[0]","f7a208a8":"w","3124a9e9":"feature_importance = pd.DataFrame(feature_names, columns = [\"feature\"])\nfeature_importance[\"importance\"] = pow(math.e, w)\nfeature_importance = feature_importance.sort_values(by = [\"importance\"], ascending = False)\nfeature_importance[:7]","d8da67d7":"fig, ax = plt.subplots(figsize = (8,7))\nfeature_importance.plot.barh(x = 'feature', y = 'importance' , ax = ax, color = 'g')\n_ = ax.bar_label(ax.containers[0])\nplt.show()","c2b75aee":"ax = df_plot_Dep.plot(kind = 'bar', stacked = True, color = ['#6B8E23','y'])\nax.set_xticklabels(['HR', 'R&D', 'Sales'], rotation = 0)\nplt.show()","9563205d":"We'll tune the parameter for some of the classical models.","ace3da27":"I would like to plot the sorted feature importance for the linear regression model that we found. If you would like to learn about how to arrange feature importance for logistic regression models you may want to read [this](https:\/\/sefiks.com\/2021\/01\/06\/feature-importance-in-logistic-regression\/).","0be37bcd":"Since we have different solutions for handling constant columns versus columns with outliers, we seperate these two. so we store the constant columns in constant_cols and keep the outlier columns in col_outliers.","93f23dcb":"## b. Data visualizatoin","7a3e2b5e":"## d. Classification Report (last fold)","be6ef101":"Only one value. So we'll remove it!","e1abb747":"As you can see the classification report shows better results for oversampled data in compariciation to imbalanced data for all classifiers. <br>\nAdaboost gives the best f1-score for attriction = Yes class with 0.528. Logistic regression follows it as the second best classifier with 0.495.\nWe'll continute the analysis with considering the last iteration of split as our split for training set and test set.","470cfb16":"Lets have a look at the categorical data and their distributions between different categories.","46406c5b":"### b. Loding the dataset","6f933d3b":"Let's list different categories within our dataset.","771ee27e":"Here, we use decision_function. Recall that the functional form of logistic regression is\n\n$$f(x) = \\frac{1}{1+e^{\u2212(\u03b2_{0} + \u03b2_{1}x_{1} + \u22ef + \u03b2_{k}x_{k})}}$$\nThis is what is returned by predict_proba.<br>\nThe term inside the exponential\n$$d(x) = \u03b2_{0} + \u03b2_{1}x_{1} + \u22ef + \u03b2_{k}x_{k}$$\nis what is returned by decision_function. The \"hyperplane\" referred to in the documentation is $$ \u03b2_{0} + \u03b2_{1}x_{1} + \u22ef + \u03b2_{k}x_{k} = 0 $$ This terminology is a holdover from support vector machines, which literally estimate a separating hyperplane. For logistic regression this hyperplane is a bit of an artificial construct, it is the plane of equal probability, where the model has determined both target classes are equally likely.","3f340cc5":"Seems that sales department has the highest rate of attrition.","5539ae99":"## I. Missing values","4ac83b18":"## 6. Evaluation metrics\n## a. Classification Reports (mean values for k-folds)\nWe'll split the data to 5 folds. This gives us 5 classification report for validation data in each fold. We'll take the mean for the value of each cell in these classificaiton reports and print one classification report for each classifier (Logistic regression, SVM, etc). ","5a3d0334":"Outliers can affect the performance of the model terribly. Let's see how many outliers we have and try to remove\/reduce them. Here the criteria for being an outlier is to be outside the upper and lower limit defined below. To learn more about outliers I recommend you to have a look at [this notebook](https:\/\/www.kaggle.com\/nareshbhat\/outlier-the-silent-killer\/notebook).","1a0757c8":"## II. Outliers","9bf1c717":"## 4. Defining Classifiers","4713e248":"## a. Data cleaning ","b80383f2":"From the corrolation plot we learn:\n- Attrition has negative corrolation with monthly income, total working years, Stock option Level, years at company, years in current role, years with current manager, job satisfactoin, job involvement, environment satisfaction and age. <br>\n- Attrition has positive corrolation only with over time and no other parameter. <br>\n- There is a high corrolation between Percent salary hike and performance rating as well as job Level and monthly income. <br>\n- Stock otpion has strong negative corrolation with Marital Status. I will take a barplot to have a closer look on how they relate out of personal curiosity! <br>\n- Years at company, years in current role, years since last promotion, years with current manager, total working years, monthly income and job level are also corrolated. <br>","5f3aaa81":"Now we check unique values for some of these parameters.","62898b41":"A simpler way of handling it is to use PrecisionRecallDisplay to plot precision recall curve. Kaggle does not use the latest version of sklearn which is 1.0 as of today, and thus I had to put the code parts related to PrecisionRecallDisplay as comment in the following blocks. I however, post the plots we get when we run the code with the latest version of sklearn.","0236e9e3":"We use lanbel encoder to change the categorical data into numerical for simplicity. However, the algorithm might misunderstand the data. Since sequencing the categories doesn't mean any relationship between different categories. If the categories were something like low, medium and hight, then using label encoder would be reasonable. as there is a sequence relaitonship between these category values. but for categories such as HR, sales and R&D there is no such a relationship. \nAnother option would be to try the encoding with one-hot-vector. The problem with one-hoe-encoder is that it introduces a lot of columns to the data with value zeros causing sparsity. To avoid this problem, I chose the label encoding for this problem.","78f3b13d":"I find this plot very interesting! You can see which factors affect attrition more and which ones less. <br>\nIt is interesting to see that OverTime has such a big impact on attrition and monthly income is maybe the least important factor! :) <br>\nLet's see how department can affect attrition.","8908dfc5":"It's interesting to see how attrition changes for some of the numerical variables. We'll plot some of the parameters such as Job level, years in current role, years since last promotion, total working years, years with current manager and hourly rate versus years at the company. We would like to see if staying long in the company affects any of these parameters. and if the patterns are differnet for attrition group vs no attrition.","81010407":"## 6. Hyperparameter Tuning and Model Imporvement","707c73ff":"## 1. Prepare the data","3cc9502c":"Thresholds are made based on the decision funciton. It ranges from min to max value for the output of decision function of all samples.","486f0224":"## 2. Summerize data","9f7b6faf":"average_precision_score computes average precision (AP) from prediction scores.\n\nAP summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold, with the increase in recall from the previous threshold used as the weight:\n$$ AP = \\sum (R_{n} - R_{n-1}) P_{n}$$ where Rn and Pn are the precision and recall at the n-th threshold. This implementation is not interpolated and is different from computing the area under the precision-recall curve with the trapezoidal rule, which uses linear interpolation and can be too optimistic.\n","1f42d1fd":"Let's gain some intution about the data, about how the distribution looks for some of the variables. For example how many man\/woman leave the company out of how many man\/woman in the company.","b6d587f4":"Now lets get more numerical and see the sorted numbers for corrolations.","eac90d2b":"## d. Dimension Reduction","628ebf7f":"## a. Descriptive statistics","fa2c86f0":"The changes with the hyperparameter tuning in our case is trivial. This may be due to our small data set. <br>\nLogistic regression was the best classifiers among others. The grid search suggests that C = 1 and penalty = l2 gives the best results for this classifier. However, they are the default values for Logistic Regression model. Thus the best performance we get from our classifiers is auc = 68 and F1-score = 0.94 for no attrition and 0.49 for attrition.","921166ce":"## c. Feature Correlations","911cf121":"We still have some categorical column. lets look what values it take. ","969f4169":"## 3. Prepare Data","2237341f":"For imbalanced data, precision-recall curve is a good metric for comparing the performance of model. However, roc curve is not a good metric for imbalanced data. <br> To learn more about roc-curve and precision-recall curve you can check [roc curves vs precision recall curves](https:\/\/machinelearningmastery.com\/roc-curves-and-precision-recall-curves-for-classification-in-python\/)<br> \n[This notebook](https:\/\/www.kaggle.com\/lct14558\/imbalanced-data-why-you-should-not-use-roc-curve) explains why you should not use roc-curve and rely on precision recall curve instead. \n","0370b92e":"![image.png](attachment:dacb41d2-d768-4a54-84da-3b43f31402e9.png)","0de1ee73":"### a. Loading libraries","4aac29b0":"Let's have a look at the classification report for the last fold","15949add":"Now let's get the classification report for training set and test set as well as precision recall curve for all classifiers.","8df93c3a":"## 7. Feature importance","87094788":"## e. AP (Average Precision) Score","f9f183c2":"## c. auc_score (Area Under Curve)","5356c62a":"Reducing the dimensionality with neihter of the methods seems to be able to create clear clusters of with attrition and without attrition. Trying more number of components for dimension reduction (for example 3 and 4) doesn't help it. I tried it! <br>\nFor this analysis we will not apply dimensionality reduction techniques. ","e763049d":"Please note that K neigbbors classifier and Decision Tree Classifier has no decisoin funciton and thus no AP-score.","a6ab8880":"## b. Precision Recall Curve","9354c183":"There is no missing data. Data is fairly clean from that aspect!","6150485b":"As you can see in yellow plots above, the columns are cleaned from outliers and the distribution becomes smoother for them.","5fc21541":"## IV. Removing constant columns","6f2b091b":"It's hard to find patterns of attrition from the plots above. However, we learn from them that \n- the attrition is not directly corrolated with hourly rate. The number of attritions for low hourly rate people is as much as the number of attrition for high hourly rate people. \n- It seems that it is not directly corrolated with any of the variables shown above. Since the people with attrition are spread around the whole variable range. ","f17f775d":"Lets also try the case where we reduce the dimensions of our dataset with other methods such as TSNE, TruncatedSVD or PCA. We can later see which method gives us better results.","6892b07e":"With **shuffle = True**, the data is shuffled by our random_state. <br> <br>\n**Stratification** is the process of rearranging the data as to ensure each fold is a good representative of the whole. In other words the distribution of data for training and test set are similar. For example in a binary classification problem where each class comprises 50% of the data, it is best to arrange the data such that in every fold, each class comprises around half the instances. <br><br>\n**grid.best_score_** calculates the mean of r2 score across 5 folds of cross validation.\nBasically r2 squared calculates how must regression line is better than a mean line. This is shown in the formula: \n$$R^2 = 1- \\frac{SSr\\ } {SSm}$$<br>\n**SSr = squared sum error of regression line <br>\nSSm = squared sum error of mean line** <br>\nPlease note that r2 score can have negative values in sklearn library. To learn more about r2 score you can read [this](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.r2_score.html) and [this](https:\/\/www.geeksforgeeks.org\/ml-r-squared-in-regression-analysis\/).","47147af1":"## 5. Handling Imbalanced Data\nHaving imbalanced data can affect the performance of the model severly. A model with high accuracy for a very unbalanced data only gives a dillusion for having a good model. While high accuracy translates into the ability of model in prediction of one class (majarity class), it does not show the ability of model in prediction of the the other class(minority class). Therefore, it's quite easy to reach high accuracy with very unbalanced data. While the recall score may be very low, leading to a poor performance with the model. <br>\nTwo common ways to handle the imbalanced data is undersampling or oversampling. [RAFAEL ALENCAR](https:\/\/www.kaggle.com\/rafjaa) has a [great notebook](https:\/\/www.kaggle.com\/rafjaa\/resampling-strategies-for-imbalanced-datasets) about this topic I recommend you to read. \nHere I'll use SMOTE technique to oversample the minority class (attrition = Yes). You can see the visualization for how the oversampling works in picture below.<br>\n\n\n![image.png](attachment:e8e9591c-400f-4411-bebb-9a4740c6995b.png) <br>\n\n## a. SMOTE Technique for oversampling\n\nOne should be very careful about when to apply the oversampling to the data. [Janio Bachmann](https:\/\/www.kaggle.com\/janiobachmann) explains it very well in [his notebook](https:\/\/www.kaggle.com\/janiobachmann\/credit-fraud-dealing-with-imbalanced-datasets) how and why in that specific way the oversampling should be applied. <br> I'll put my learning from his notebook here.\n\n\n#### The Wrong Way\nThe most common mistake is to oversample the data and then apply the split between training set and validation set. This is not the right way of doing it, since the over sampling happens before the split and thus it will affect the distribution of data in the validation set. while validation set shall stay untouched! This is depicted in the figure below. <br>\nThis way of oversampling leads to awesome results for precision and recall for validation set. However, the results are not realistic and overfitting occurs. <br> <br>\n<img src=\"https:\/\/www.marcoaltini.com\/uploads\/1\/3\/2\/3\/13234002\/2639934.jpg?401\">\n\n\n### The Right Way:\nThe right way of doing it is to apply oversampling just after the split of data into training set and validation set. In other words oversampling happens only for the triaing set, after the split of data into training and validation set. This is implemented in the following code blocks. <br><br>\n<img src=\"https:\/\/www.marcoaltini.com\/uploads\/1\/3\/2\/3\/13234002\/9101820.jpg?372\"> <br>","63b0ca4a":"## III. Preprocessing and Encoding Categorical Columns","52d35a40":"## Attrition - Binary Classification for Imbalanced Data \n\n## Intro\nHigh performing employees are the investment of componies in their success and growth in future. Therefore it's important for businesses to find out about factors that are contributing more to employee attrition. <br>\nIn this report, we'll try to find out which employees tend to leave the company, what factors are the stronger contributers to this behaviour, which departments face the attrition problem and what type of measures could the company take in order to retain their employees. <br>\nHere I try to put the explanations for the steps we take through this analysis to help develop understanding in general topics of data science field. \nIn this notebook, I use different models, techniques and metircs such as: <br>\n- SMOTE (synthetic minority over-sampling technique)\n- Logistic Regression\n- K Neighbors Classifier\n- Support Vector Classifier\n- Decision Tree Classifier\n- Random Forest Classifier\n- XGB Classifier\n- LGBM Classifier\n- AdaBoost Classifier\n- Outliers handling\n- Precision-recall curve\n- Classification report\n- auc Score <br>\nTo see how much oversampling the data imporves the performance of differnet models you can compare the results and figures in this notebook with version 6 of this notebook, where I did not used any technique to overcome the data imbalance problem. \nI personally think that HR analysis for attrition is a very interesting example to learn about differnet data science topics. If you find this notebook helpful, please don't forget to put an upvote for it! Also I would appreciate your comments and feedback about it :-) \n\n\n### Objectiv\nPredicting the potential employees who would leave the company <br>\nFirst we'll do some EDA (Explanatory Data Analysis) to get some intuition about the data. <br>\nWe then try to build different models with different techniques and compare their scores with different evaluation metrics. <br>\nWe finally fine tune our model in the best pefroming technique. ","b1ab1e6b":"In this notebook we tried to find out what factors contribute to the choice of employees leaving the company. <br>\nOur best model is a logistic regression model with 89% accuracy, F1-score = 0.93 for no attrition and 0.66 for attrition class shown in the classification report for the test data. This model recognizes overtime as the most important factor for attrition as well as years since last promotion and number of companies worked after following it.","0ef80c23":"Now we'll arrang the table above in a more readable format.","44d435f2":"## 8. Summary"}}