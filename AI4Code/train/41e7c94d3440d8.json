{"cell_type":{"128ac340":"code","97c2aeb4":"code","ff6a84b5":"code","d56a1d11":"code","5724ad60":"code","062d2f1f":"code","39692134":"code","cb577ad0":"code","4e550e55":"code","55f1a3c3":"code","aeba5920":"code","c5cf44cb":"code","7860893f":"code","2eed8d80":"code","cf0d242b":"code","207e7ebb":"code","0f2754b6":"code","787c5d02":"code","37f3e3af":"code","6f896125":"code","cfb6b81a":"code","751ce40e":"code","1f764c2a":"code","991d28f4":"code","a29edae3":"code","99bf44d4":"code","a89974b5":"code","3729d2e8":"code","df542d23":"code","939b16f6":"code","e7c552e0":"code","7770ffc1":"markdown","27c652d8":"markdown","268096af":"markdown","b1aef009":"markdown","7eda2687":"markdown","094d8d70":"markdown","96aec102":"markdown","f5c3cbe5":"markdown","7e61a9a0":"markdown","96f4c3dc":"markdown","6b311a95":"markdown","80f508e9":"markdown","3d4f6fac":"markdown","31e690d1":"markdown","e4ca77b8":"markdown","114960ac":"markdown","e4c69872":"markdown","6ca1d17b":"markdown","e438431a":"markdown","6b253248":"markdown","c52782c0":"markdown","fa918523":"markdown","f7d0d24f":"markdown","c823cf3d":"markdown","7d782913":"markdown","8ebc9c39":"markdown","1884b4d0":"markdown","ee7d0a27":"markdown","fa508d40":"markdown","5ee2cdb9":"markdown","4b4bb856":"markdown","e30fb006":"markdown","544ccb05":"markdown","8dd153c6":"markdown","9fab76fc":"markdown","47ae3db6":"markdown","2f209b74":"markdown","ae7831c2":"markdown","96c2cc82":"markdown","9e6be751":"markdown","79732680":"markdown","b99c062e":"markdown"},"source":{"128ac340":"import warnings  \nwarnings.filterwarnings('ignore')\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport re as re\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","97c2aeb4":"def submission_generation(dataframe, name):\n    \"\"\"\n    Esta funci\u00f3n genera un csv a partir de un dataframe de pandas. \n    Con FileLink se genera un enlace desde el que poder descargar el fichero csv\n    \n    dataframe: DataFrame de pandas\n    name: nombre del fichero csv\n    \"\"\"\n    import os\n    from IPython.display import FileLink\n    os.chdir(r'\/kaggle\/working')\n    dataframe.to_csv(name, index = False)\n    return  FileLink(name)","ff6a84b5":"train = pd.read_csv(\"\/kaggle\/input\/rms2-titanic\/train.csv\", header = 0, dtype={'Age': np.float64})\ntest  = pd.read_csv(\"\/kaggle\/input\/rms2-titanic\/test.csv\" , header = 0, dtype={'Age': np.float64})\nprint (train.info())\n","d56a1d11":"train[\"Fare\"]= train[\"Fare\"].str.replace('.', '')\ntrain['Fare'] = pd.to_numeric(train['Fare'],errors='coerce')\ntest[\"Fare\"]= test[\"Fare\"].str.replace('.', '')\ntest['Fare'] = pd.to_numeric(test['Fare'],errors='coerce')\n\nprint (train.info())","5724ad60":"full_data = [train, test]","062d2f1f":"sns.set_style('whitegrid')\nsns.countplot(x='Survived',data=train,palette='RdBu_r')","39692134":"sns.set_style('whitegrid')\nsns.countplot(x='Survived',hue='Sex',data=train,palette='RdBu_r')","cb577ad0":"\nprint (train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean())\n","4e550e55":"print (train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())","55f1a3c3":"sns.countplot(x='Pclass',hue='Survived', data=train,palette='RdBu_r')\n","aeba5920":"train_survived = train[train['Survived'] == 1]\n\ntrain_died = train[train['Survived'] == 0]\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,8))\nax1.title.set_text('Supervivientes por clase')\nax2.title.set_text('Fallecidos por clase')\nsns.countplot(x='Pclass',hue='Sex', data=train_survived,palette='RdBu_r', ax = ax1)\nsns.countplot(x='Pclass',hue='Sex', data=train_died,palette='RdBu_r', ax = ax2)\n","c5cf44cb":"for dataset in full_data:\n    dataset['FamilySize'] = dataset['Sibsp'] + dataset['Parch'] + 1\nprint (train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean())","7860893f":"for dataset in full_data:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\nprint (train[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean())","2eed8d80":"for dataset in full_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')\nprint (train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean())","cf0d242b":"for dataset in full_data:\n    \n    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n    \ntrain['CategoricalFare'] = pd.qcut(train['Fare'], 4)\nprint (train[['CategoricalFare', 'Survived']].groupby(['CategoricalFare'], as_index=False).mean())\n","207e7ebb":"x_data = range(0, train.shape[0])\ny1 = train[train['Pclass'] == 1]['Age']\ny2 = train[train['Pclass'] == 2]['Age']\ny3 = train[train['Pclass'] == 3]['Age']\n\nx1 = range(0, len(y1))\nx2 = range(0, len(y2))\nx3 = range(0, len(y3))\n\n\nfig, ax = plt.subplots()\nax.plot(x1, y1, color = 'b')\nax.plot(x2, y2, color = 'g')\nax.plot(x3, y3, color = 'r')\nax.set_title('Age by class')\n\nax.grid()\nax.legend()\nplt.show()","0f2754b6":"fig=plt.gcf()\nfig.set_size_inches(10,7)\nfig=sns.boxplot(\n    x='Pclass', y='Age',\n    data=train, order=[1,2,3],\n    linewidth=2.5, orient='v', dodge=False\n)","787c5d02":"def impute_input(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        \n            return 1\n\n    else:\n        return 0\n    \ntrain['Input'] = train[['Age','Pclass']].apply(impute_input,axis=1)\ntest['Input'] = test[['Age','Pclass']].apply(impute_input,axis=1)   \nprint(train[['Age','Input', 'Survived']].head(10))","37f3e3af":"print (train[[\"Input\", \"Survived\"]].groupby(['Input'], as_index=False).mean())\n","6f896125":"def impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n\n        if Pclass == 1:\n            return 37\n\n        elif Pclass == 2:\n            return 29\n\n        else:\n            return 24\n\n    else:\n        return Age\n    \n    \ntrain['Age'] = train[['Age','Pclass']].apply(impute_age,axis=1)\ntest['Age'] = test[['Age','Pclass']].apply(impute_age,axis=1)   \nprint(train[['Age','Input', 'Survived']].head(10))\n","cfb6b81a":"for dataset in full_data:\n    dataset['Age'] = dataset['Age'].astype(int)\n    \ntrain['CategoricalAge'] = pd.cut(train['Age'], 5)\n\nprint (train[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index=False).mean())","751ce40e":"def get_title(name):\n\ttitle_search = re.search(' ([A-Za-z]+)\\.', name)\n\t# If the title exists, extract and return it.\n\tif title_search:\n\t\treturn title_search.group(1)\n\treturn \"\"\n\nfor dataset in full_data:\n    dataset['Title'] = dataset['Name'].apply(get_title)\n\nprint(pd.crosstab(train['Title'], train['Sex']))","1f764c2a":"for dataset in full_data:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n\nprint (train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())","991d28f4":"print (train.info())","a29edae3":"for dataset in full_data:\n    \n    # Mapping Sex\n    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n    \n    # Mapping titles\n    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n    \n    # Mapping Embarked\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n    \n    # Mapping Fare\n    dataset.loc[ dataset['Fare'] <= 78958.0, 'Fare'] \t\t\t\t\t\t        = 0\n    dataset.loc[(dataset['Fare'] > 78958.0) & (dataset['Fare'] <= 135000.0), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 135000.0) & (dataset['Fare'] <= 297000.0), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 297000.0, 'Fare'] \t\t\t\t\t\t\t        = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n    \n    # Mapping Age\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']                           = 4\n\n\n# Feature Selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'Sibsp',\\\n                 'Parch', 'FamilySize']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n\nTt=test\ntest  = test.drop(drop_elements, axis = 1)\n\ncols = train.columns.tolist()\ncols = cols[1:] + cols[:1]\ntrain = train[cols]\n\ncols = test.columns.tolist()\ncols = cols[1:] + cols[:1]\ntest = test[cols]\n\n\nprint (train.head(10))\n\n\n","99bf44d4":"sns.heatmap(train.corr(), annot=True)","a89974b5":"train = train.values\ntest  = test.values","3729d2e8":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\n\nclassifiers = [\n    KNeighborsClassifier(3),\n    SVC(probability=True),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n\tAdaBoostClassifier(),\n    GradientBoostingClassifier(),\n    GaussianNB(),\n    LinearDiscriminantAnalysis(),\n    QuadraticDiscriminantAnalysis(),\n    LogisticRegression()]\n\nlog_cols = [\"Classifier\", \"Accuracy\"]\nlog \t = pd.DataFrame(columns=log_cols)\n\nsss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n\nX = train[0::, 1::]\ny = train[0::, 0]\n\nacc_dict = {}\n\nfor train_index, test_index in sss.split(X, y):\n\tX_train, X_test = X[train_index], X[test_index]\n\ty_train, y_test = y[train_index], y[test_index]\n\t\n\tfor clf in classifiers:\n\t\tname = clf.__class__.__name__\n\t\tclf.fit(X_train, y_train)\n\t\ttrain_predictions = clf.predict(X_test)\n\t\tacc = accuracy_score(y_test, train_predictions)\n\t\tif name in acc_dict:\n\t\t\tacc_dict[name] += acc\n\t\telse:\n\t\t\tacc_dict[name] = acc\n\nfor clf in acc_dict:\n\tacc_dict[clf] = acc_dict[clf] \/ 10.0\n\tlog_entry = pd.DataFrame([[clf, acc_dict[clf]]], columns=log_cols)\n\tlog = log.append(log_entry)\n\nplt.xlabel('Accuracy')\nplt.title('Classifier Accuracy')\n\nsns.set_color_codes(\"muted\")\nsns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")","df542d23":"candidate_classifier = SVC(probability=True)\ncandidate_classifier.fit(train[0::, 1::], train[0::, 0])\nresult = candidate_classifier.predict(test)\n\n","939b16f6":"len(result)","e7c552e0":"Predicting = pd.DataFrame({\"PassengerId\": Tt.PassengerId, \n                                      \"Survived\": result})\nsubmission_generation(Predicting , \"TryPredict.csv\")","7770ffc1":"**6. Age**\n\nHay bastantes valores que faltan en esta categoria. Veamos en una grafica como se distribuyen\n","27c652d8":"A continuacion vamos a ver la cantidad personas que fallecieron","268096af":"Vemos que tienen diferenciados porcentajes de supervivencia asi que luego los separaremos en grupos.","b1aef009":"Veamos si esta nueva caracteristica tiene impacto alguno","7eda2687":"Entre los parametros mas correlados apreciamos Fare y PClass, Title y Sex, Fare y IsAlone y por ultimo y el que nos interesa Sex y Survived.\n","094d8d70":"Dividimos a los pasajeros en 5 grupos de edad diferente para ver su impacto. ","96aec102":"Veamos como se nos han quedado los datos ahora despues de investigarlos un poco. ","f5c3cbe5":"Ahora vamos a ver la correlacion de parametros","7e61a9a0":"Vemos que si tiene impacto, asi que inputamos la edad dependiendo de las clases y dejamos esta categoria.","96f4c3dc":"Esta grafica no nos da mucha informacion. Probemos con otra. ","6b311a95":"**LIMPIEZA DE DATOS**\n\nAhora vamos a limpiar nuestros datos y mapear las caracteristicas a valores numericos para luego poder utilizar diferentes tecnicas de Machine Learning. ","80f508e9":"Dise\u00f1amos una funcion para posterior mente generar el .csv entregable. ","3d4f6fac":"**3. SibSp y Parch**\n\nCon el numero de hermanos\/esposos y el numero de hijos\/padres podemos crear una nueva caracteristica que sea el tama\u00f1o de la familia.","31e690d1":"En esta grafica podemos ver mas informacion, vemos por ejemplo que cada clase tiene una edad media diferente. Vamos a imputar los valores de la edad dependiendo de la calse a la que pertenezcan. \nPero primero vamos creat una nueva caracteristica 'Input' que signifique que le hemos inputado el valor a la edad. ","e4ca77b8":"Fallecieron m\u00e1s de los que sobrevivieron","114960ac":"**7. Name**\n\nDentro de aqui podemos ver el titulos de las personas (Miss. Cap., etc.)","e4c69872":"Comprobamos la longitud de las predicciones para ver que corresponde con la longitud del test.csv que es 378.","6ca1d17b":"Parece que tiene un buen efecto prediciendo pero vamos mas alla y clasificamos a la gente para ver que pasa cuando van solo en el barco o no","e438431a":"**\u00bfQu\u00e9 enfoques probaste durante la competici\u00f3n?**\nInicialmente, hicimos un procesado de los datos, analizando aquellos datos faltantes, en concreto la edad, analizamos de qu\u00e9 manera podiamos imputar esos valores, asimismo calculamos las estadisticas sucesivas que permitian imputar nuevos valores para hacer divisiones, por ejemplo: los embarcados en Q ten\u00edan m\u00e1s probabilidades de sobrevivir que los embarcados en S, con lo cual a los primeros se les asignaba un 1 y al segundo un 2.","6b253248":"**\u00bfA qu\u00e9 problemas te enfrentaste? \u00bfComo los resolviste?**\nTras ver resultados de competici\u00f3n que no nos alegraban, probamos nuevas maneras de imputar datos y analizamos los mismos con mayor profundidad.","c52782c0":"Ahora que ya tenemos los titulos vamos a categorizarlos y ver el impacto que tienen en la supervivencia. ","fa918523":"\u00a1Bien! El impacto es considerable","f7d0d24f":"**4. Embarked**\n\nFaltan algunos valores en la caracteristica del el muelle donde embarcaron, vamos a rellenar estos huecos con el muelle donde mas gente embarco ('S').\n","c823cf3d":"Leemos los datos que tenemos, el dataset train y el test. ","7d782913":"Se observa que las mujeres sobrevivian en un porcentaje mayor que el de los hombres","8ebc9c39":"**Sugerencias para mejorar la asignatura.**\n- Me gusta bastante como esta planteada y felicito a los profesores por el trabajo que esto conlleva.\n- Resaltar\u00eda con especial ilusi\u00f3n la existencia de competiciones, me parece una forma fabulosa de fomentar la competitividad sana en el aula, ayud\u00e1ndonos a aprender, y analizando cada notebook realizado para poder aprender de nuestros errores. Esto consideramos que nos prepara para el mundo real.","1884b4d0":"**Prediccion**\n\nDe la grafica anterior vemos que Gradien tBoosting Classifier es el que mejor predice nuestro dataset. Sin embargo, tras probar nos hemos dado cuenta que SVC es el que mejor impacto tiene en el test de la competici\u00f3n y por eso lo usamos. ","ee7d0a27":"**\u00bfQu\u00e9 funcion\u00f3 y qu\u00e9 no funcion\u00f3?**\nFunciono eliminar parametros que no dan ninguna informacion como la Cabina.  ","fa508d40":"**1. Sex**\n\nVeamos el impacto que tiene el sexo sobre la supervivencia. Vamos a ver la cantidad de hombre y mujeres fallecidos y supervivientes.","5ee2cdb9":"**5. Fare**\n\nTambien faltan algunos valores para la categoria de 'Fare', los vamos a llenar con la media de este valor. Despues los vamos a dividir en cuatro subcategorias. \n","4b4bb856":"Creamos un vector con los dataset, para poder aplicarle el procesamiento de los datos a los dos a la vez","e30fb006":"**MEMORIA**","544ccb05":"Tenemos que pasar la columna Fare de Object a Float64","8dd153c6":"**\u00bfCreaste nuevos atributos\/ variables adicionales? \/ \u00bfQu\u00e9 limpieza de datos hiciste? outliers, imputaci\u00f3n de valores, ...**\n- Convertivos el sexo en 0 y 1.\n- Pasamos el atributo 'Fare' de objeto a float64. Inputamos el valor que faltaba con la media de esta columna. Dividimos a los pasajeros en 4 grupos de tarifas (del 0 al 3).\n- Nos olvidamos de 'SibSp' y 'Parch' para crear 'IsAlone' y 'Family Size'. Aunque al final nos desprendimos tambien de 'Family Size' para quedarnos solo con 'IsAlone'.\n- Inputamos valores a la edad vasandonos en las clases. Dividimos a los pasajeros en 5 grupos de edades dandoles un valor para la edad entre el 0 y el 4. \n- Ademas creamos un nuevo atributo llamado 'Input' que significaba que le hemos inputado la edad a ese pasajero\n- Creamos un nuevo atributo llamado 'Title' para eliminar asi el de 'Name'. Dividimos los 'Title' en 6 grupos (del 0 al 5).\n- Ademas, para el dataset de train, nos quitamos de en medio los atributos de 'PassengerId', 'Ticket' y 'Cabin' ya que no nos aportaban ninguna informaci\u00f3n.","9fab76fc":"Se observa que en todas las clases las mujeres sobreviv\u00edan m\u00e1s que los hombres, en la tercera clase esta tendencia no es tan matematica\n","47ae3db6":"**ESTUDIO DE LOS DATOS**","2f209b74":"**Comparacion de Clasificadores**\n\nVamos a dividir nuestro train data nuevamente en train y test para compara los diferentes clasificadores. ","ae7831c2":"Creamos el .csv entregable","96c2cc82":"**\u00bfCu\u00e1les son los enfoques que habr\u00edas intentado si hubieses tenido m\u00e1s tiempo?**\n\nLas diapositivas de Buenas Practicas.\n\n-One hot encoding\n\n-PCA\n\n-Comprobar la dimensionalidad, si nos faltan o nos sobran atributos\n\n-Plotear la convergencia de nuestro train y nuestro test para ver como se podria mejorar la predicion","9e6be751":"**2. Pclass**\n\nNo faltan valores para esta caracter\u00edstica y ya tiene valores numericos. Asi que lo unico que hacemos es ver el impacto que tiene en el dataset train.\n","79732680":"**COMPETICION TITANIC**","b99c062e":"Se aprecia como en la clase 1 hab\u00eda mayor numero de supervivientes, mientras que en la clase 2 y 3 se invierte la tendencia.\nA continuacion vamos a observar los supervivientes (hombre o mujer) por clases"}}