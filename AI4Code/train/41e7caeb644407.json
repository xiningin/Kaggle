{"cell_type":{"d030649c":"code","3a2e9612":"code","4838d4be":"code","1e31b9ec":"code","fc9cb961":"code","0fba2ae3":"code","4dc90910":"code","3bcaa778":"code","b7463ed9":"code","bef7e1b2":"code","462e810e":"code","b85ae4d3":"code","4ecbc5d3":"code","b540748f":"code","540e0bc0":"code","b5b730b3":"code","5dd53d69":"code","93a84878":"code","fc061469":"code","ac68349e":"code","01818ee6":"code","a9f0146b":"code","8575a00a":"code","fa7c693f":"code","b24385e3":"code","89995e47":"markdown","d8c8a802":"markdown","3a4a639c":"markdown","9a4ca671":"markdown","1fa6c735":"markdown","26a10459":"markdown","e10e4772":"markdown","fabf1436":"markdown","269d8a48":"markdown","390cc704":"markdown","ca7916c1":"markdown","5fbd3712":"markdown","c274e927":"markdown","8f7bc820":"markdown","6a5f19d2":"markdown","693a521c":"markdown","6f6bfdb0":"markdown","130cb868":"markdown","bd552846":"markdown","af5e5f92":"markdown"},"source":{"d030649c":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas_profiling\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nimport numpy as np","3a2e9612":"df = pd.read_csv('..\/input\/email-campaign-responses\/Open Mail.csv', index_col=0)\ndf.head()","4838d4be":"profile_result = pandas_profiling.ProfileReport(df)\nprofile_result","1e31b9ec":"df_mapped = df.copy()\n\ndf_mapped['rec_lifestyle'] = df_mapped['rec_lifestyle'].map({ 'active':0,\n                                                'healthy':1,\n                                                'cozily':2})\ndf_mapped['rec_familystatus'] = df_mapped['rec_familystatus'].map({'married':0,\n                                                     'single':1})\ndf_mapped['rec_car'] = df_mapped['rec_car'].map({'practical':0,\n                                   'expensive':1})\ndf_mapped['rec_sports'] = df_mapped['rec_sports'].map({'athletics':0,\n                                         'soccer':1,\n                                         'badminton':2})\ndf_mapped['outcome'] = df_mapped['outcome'].map({'no response':0,\n                                                 'response':1})\ndf_mapped","fc9cb961":"scaler = StandardScaler()\ndf_scaled = scaler.fit_transform(df_mapped)\ndf_scaled","0fba2ae3":"pca = PCA()\npca.fit(df_mapped)\n\nplt.figure(figsize = (12,9))\nplt.plot(range(1,8), pca.explained_variance_ratio_.cumsum(), marker = 'o', linestyle = '--')\nplt.title('Explained Variance by Components')\nplt.xlabel('Number of Components')\nplt.ylabel('Cumulative Explained Variance')","4dc90910":"pca = PCA(n_components = 2)\npca.fit(df_scaled)\ndf_pca_comp = pd.DataFrame(data = pca.components_,\n                           columns = df_mapped.columns.values,\n                           index = ['Component 1', 'Component 2'])\ndf_pca_comp","3bcaa778":"scores_pca = pca.transform(df_scaled)","b7463ed9":"wcss = []\nfor i in range(1,11):\n    kmeans_pca = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n    kmeans_pca.fit(scores_pca)\n    wcss.append(kmeans_pca.inertia_)\n    \nplt.figure(figsize = (10,8))\nplt.plot(range(1, 11), wcss, marker = 'o', linestyle = '--')\nplt.xlabel('Number of Clusters')\nplt.ylabel('WCSS')\nplt.title('K-means with PCA Clustering')\nplt.show()","bef7e1b2":"kmeans_pca = KMeans(n_clusters = 4, init = 'k-means++', random_state = 42)\nkmeans_pca.fit(scores_pca)\n\ndf_segm_pca_kmeans = pd.concat([df_mapped.reset_index(drop = True), pd.DataFrame(scores_pca)], axis = 1)\ndf_segm_pca_kmeans.columns.values[-2: ] = ['Component 1', 'Component 2']\ndf_segm_pca_kmeans['Segment K-means PCA'] = kmeans_pca.labels_\ndf_segm_pca_kmeans","462e810e":"df_segm_pca_kmeans_grouped = df_segm_pca_kmeans.groupby(['Segment K-means PCA']).mean()\ndf_segm_pca_kmeans_grouped['N Obs'] = df_segm_pca_kmeans[['Segment K-means PCA','rec_age']].groupby(['Segment K-means PCA']).count()\ndf_segm_pca_kmeans_grouped['Prop Obs'] = df_segm_pca_kmeans_grouped['N Obs'] \/ df_segm_pca_kmeans_grouped['N Obs'].sum()\ndf_segm_pca_kmeans_grouped","b85ae4d3":"df_segm_pca_kmeans_renamed = df_segm_pca_kmeans_grouped.rename({0:'Young and Well-off', \n                                                                1:'Middle Class Elderly',\n                                                                2:'Well-off Elderly',\n                                                                3:'Young Middle Class'})\ndf_segm_pca_kmeans_renamed","4ecbc5d3":"labels = df_segm_pca_kmeans_renamed.index\nsizes = df_segm_pca_kmeans_renamed['N Obs']\n\nfig1, ax1 = plt.subplots()\nplt.title('User Segments')\nax1.pie(sizes, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.show()","b540748f":"df_segm_pca_kmeans['Legend'] = df_segm_pca_kmeans['Segment K-means PCA'].map({0:'Young and Well-off', \n                                                                1:'Middle Class Elderly',\n                                                                2:'Well-off Elderly',\n                                                                3:'Young Middle Class'})\n\nx_axis = df_segm_pca_kmeans['Component 1']\ny_axis = df_segm_pca_kmeans['Component 2']\nplt.figure(figsize = (10, 8))\nsns.scatterplot(x_axis, y_axis, hue = df_segm_pca_kmeans['Legend'], palette = ['g', 'r', 'c', 'm'])\nplt.title('2D Represntation of Clusters by PCA Components')\nplt.show()","540e0bc0":"df_segment = pd.DataFrame(df_segm_pca_kmeans['Legend'])\ndf_segment['ID Email'] = df.index\ndf_segment = df_segment.set_index('ID Email')\ndf_summarized = df.join(df_segment, how='outer')\ndf_summarized","b5b730b3":"segment0_response =  len(df_summarized[(df_summarized['Legend']=='Young and Well-off')\n                                           & (df_summarized['outcome'] == \"response\")])\nsegment0_total = len(df_summarized[df_summarized['Legend']=='Young and Well-off'])\n\nsegment1_response =  len(df_summarized[(df_summarized['Legend']=='Middle Class Elderly')\n                                           & (df_summarized['outcome'] == \"response\")])\nsegment1_total = len(df_summarized[df_summarized['Legend']=='Middle Class Elderly'])\n\nsegment2_response =  len(df_summarized[(df_summarized['Legend']=='Well-off Elderly')\n                                           & (df_summarized['outcome'] == \"response\")])\nsegment2_total = len(df_summarized[df_summarized['Legend']=='Well-off Elderly'])\n\nsegment3_response =  len(df_summarized[(df_summarized['Legend']=='Young Middle Class')\n                                           & (df_summarized['outcome'] == \"response\")])\nsegment3_total = len(df_summarized[df_summarized['Legend']=='Young Middle Class'])\n\nsegment0_response_rate = segment0_response\/segment0_total\nsegment1_response_rate = segment1_response\/segment1_total\nsegment2_response_rate = segment2_response\/segment2_total\nsegment3_response_rate = segment3_response\/segment3_total\n\nsegment3_total\nprint('Response Rate from Young and Well-off Segment: ',  round((segment0_response_rate*100),2),'% (',segment0_response,'out of',segment0_total,')')\nprint('Response Rate from Middle Class Elderly Segment: ', round((segment1_response_rate*100),2),'% (',segment1_response,'out of',segment1_total,')')\nprint('Response Rate from Well-off Elderly Segment: ', round((segment2_response_rate*100),2),'% (',segment2_response,'out of', segment2_total,')')\nprint('Response Rate from Young Middle Class Segment: ', round((segment3_response_rate*100),2),'% (',segment3_response,'out of',segment3_total,')')","5dd53d69":"X = df_mapped.iloc[:,0:6]\ny = df_mapped['outcome']\n\nX_scaled = scaler.fit_transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=42, test_size=0.2, shuffle=True)\n\ntrain_size = X_train.shape[0]\ntest_size = X_test.shape[0]\nprint('Training Data has', train_size, 'number of rows')\nprint('Testing Data has', test_size, 'number of rows')","93a84878":"#Create the model\nlogreg = LogisticRegression().fit(X_train, y_train)\nlogreg100 = LogisticRegression(C=100).fit(X_train,y_train)\nlogreg001 = LogisticRegression(C=0.01).fit(X_train,y_train)\n#Evaluate Scores\nprint(\"C=1.0\")\nprint(\"Training set score: {:.3f}\".format(logreg.score(X_train,y_train)))\nprint(\"Test set score: {:.3f}\".format(logreg.score(X_test,y_test)))\n\nprint(\"C=100\")\nprint(\"Training set score: {:.3f}\".format(logreg100.score(X_train,y_train)))\nprint(\"Test set score: {:.3f}\".format(logreg100.score(X_test,y_test)))\n\nprint(\"C=0.01\")\nprint(\"Training set score: {:.3f}\".format(logreg001.score(X_train,y_train)))\nprint(\"Test set score: {:.3f}\".format(logreg001.score(X_test,y_test)))\n\n#Batch Prediction\nprediction_logreg = logreg.predict(X_test)\nplot_confusion_matrix(logreg,X_test, y_test, display_labels=['No Response', 'Response'] )","fc061469":"params_to_test = {\n    'n_estimators':[1,5,10,25,100],\n    'max_depth':[2,3,5]\n}\nRF_model = RandomForestClassifier(random_state=42)\nrf_fit = RF_model.fit(X_train,y_train)\nforest = GridSearchCV(RF_model, param_grid=params_to_test, cv=10, scoring='f1_macro')\nforest.fit(X_train,y_train)\nbest_params = forest.best_params_ \nbest_model = RandomForestClassifier(**best_params)\nbest_model","ac68349e":"print(\"Accuracy on training set: {:.3f}\".format(forest.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(forest.score(X_test, y_test)))\n\nprediction_forest = forest.predict(X_test)\nplot_confusion_matrix(forest,X_test, y_test, display_labels=['No Response', 'Response'] )","01818ee6":"params_to_test = {\n    'C':[0.01,0.1,1,5,10,25,50,100,1000]\n}\n\nSVC_model = SVC(random_state=42)\nsvc_grid = GridSearchCV(SVC_model, param_grid=params_to_test, cv=10, scoring='f1_macro')\nsvc_grid.fit(X_train,y_train)\nbest_params = svc_grid.best_params_ \nbest_model = SVC(**best_params)\nbest_model","a9f0146b":"print(\"Accuracy on training set: {:.3f}\".format(svc_grid.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(svc_grid.score(X_test, y_test)))\n\n#Batch Prediction\nprediction_svc_grid = svc_grid.predict(X_test)\nplot_confusion_matrix(svc_grid,X_test, y_test, display_labels=['No Response', 'Response'] )","8575a00a":"ml_list = ['Logistic Regression', 'Random Forest', 'SVM']\nresults = pd.DataFrame(ml_list, columns=['ML Algorithm'])\nresults['Train Score'] = [logreg.score(X_train,y_train), forest.score(X_train, y_train), svc_grid.score(X_train, y_train) ]\nresults['Test Score'] = [logreg.score(X_test,y_test), forest.score(X_test, y_test), svc_grid.score(X_test, y_test) ]\nresults\n                          ","fa7c693f":"plt.title('Train Scores by Algorithm')\nplt.bar(results['ML Algorithm'], results['Train Score'])\nplt.show()\n\nplt.title('Test Scores by Algorithm')\nplt.bar(results['ML Algorithm'], results['Test Score'], color='green')\nplt.show()","b24385e3":"def plot_feature_importances(model):\n    plt.figure(figsize=(12,8))\n    n_features=X_test.shape[1]\n    plt.barh(np.arange(n_features),model.feature_importances_,align='center')\n    plt.yticks(np.arange(n_features),X.columns)\n    plt.title('Feature Importance using Random Forest')\n    plt.xlabel(\"Feature Importance\")\n    plt.ylabel('Feature')\n    plt.ylim(-1,n_features)\n    plt.show()\n    \nplot_feature_importances(RF_model)","89995e47":"## Import Relevant Libraries ","d8c8a802":"## Train-test Split ","3a4a639c":"## Import the Dataset and perform Exploratory Data Analysis ","9a4ca671":"## Spot Checking ML Algorithms ","1fa6c735":"id_emailhash - Unique e-mail message ID\n\nrec_age - Age of recipient\n\nrec_lifestyle - Lifestyle segment of recipient \n\nrec_familystatus - Civil status of recipient\n\nrec_car - Value of car of recipient \n\nrec_sports - Sports type segment of recipient \n\nrec_earnings - Earnings per year of recipient \n\noutcome - Indicator of whether the customer has opened the email or not","26a10459":"## Creating a Classification Model to predict Outcome ","e10e4772":"# Conclusion: Based on both K-means Customer Segmentation and Random Forest Classification Model, it is most recommended to target elderly customers.\n\n# Also note that Response Rate also seem to be affected by earnings as customers with higher earnings tend to respond to the email campaigns more. ","fabf1436":"### Support Vector Machines ","269d8a48":"Based on the Random Forest Model, with the highest test score of 0.90, the most important features affecting the response rate of customers are Age and Earnings. ","390cc704":"# CUSTOMER PROFILING FOR E-MAIL CAMPAIGN TARGETING\t\t\t\t\t\t\t","ca7916c1":"## Segmenting Users using K-Means Clustering","5fbd3712":"# Dataset Description","c274e927":"## Scaling features","8f7bc820":"## Applying Principal Component Analysis to the Scaled Dataset ","6a5f19d2":"### Random Forest ","693a521c":"1. What is the profile of customers who are likely to respond to the e-mail campaign?  Given the characteristics of the responsive segment, what would you call or label them (e.g. for marketing purposes)?\n\n2. Create a Classification Model that can predict whether a customer will respond to the e-mail campaign or not","6f6bfdb0":"### Logistic Regression ","130cb868":"We are going to set id_emailhash as our index","bd552846":"## Mapping Categorical Variables ","af5e5f92":"Based from the Customer Segmentation using K-Means, the best segment to target are the 'Well-off Elderly' and 'Middle Class Elderly' segments with a response rate of 98.51% and 97.3% respectively. These are customers who are retired or close to retirement."}}