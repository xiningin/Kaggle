{"cell_type":{"e8b587ce":"code","488e393e":"code","e7da6a2a":"code","1e19b225":"code","970f9769":"code","2207610e":"code","81fac388":"code","0e028a8c":"code","72e4b831":"code","d5a493ef":"code","9aae0d85":"markdown","1192a75d":"markdown","732d3d1f":"markdown","a99cf79f":"markdown","726d1e57":"markdown","fe0717f5":"markdown"},"source":{"e8b587ce":"! pip install --no-deps \"..\/input\/imagededupcp37\/imagededup-0.2.2-cp37-cp37m-manylinux1_x86_64.whl\"","488e393e":"import numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\ntqdm.pandas()\n\nimport imagededup\nfrom imagededup.methods import CNN, PHash, DHash, WHash, AHash","e7da6a2a":"# %%time\n# cnn = CNN()\n# encodings = cnn.encode_images(image_dir=\"..\/input\/shopee-product-matching\/train_images\")\n# duplicates = cnn.find_duplicates(encoding_map=encodings)\n\n# # CV = 0.235","1e19b225":"# %%time\n# hashing_method = PHash()\n# encodings = hashing_method.encode_images(image_dir=\"..\/input\/shopee-product-matching\/train_images\")\n# duplicates = hashing_method.find_duplicates(encoding_map=encodings)\n\n# # CV = 0.192","970f9769":"# %%time\n# hashing_method = DHash()\n# encodings = hashing_method.encode_images(image_dir=\"..\/input\/shopee-product-matching\/train_images\")\n# duplicates = hashing_method.find_duplicates(encoding_map=encodings)\n\n# # CV = 0.166","2207610e":"# %%time\n# hashing_method = WHash()\n# encodings = hashing_method.encode_images(image_dir=\"..\/input\/shopee-product-matching\/train_images\")\n# duplicates = hashing_method.find_duplicates(encoding_map=encodings)\n\n# # CV = 0.081","81fac388":"%%time\nhashing_method = AHash()\nencodings = hashing_method.encode_images(image_dir=\"..\/input\/shopee-product-matching\/train_images\")\nduplicates = hashing_method.find_duplicates(encoding_map=encodings)\n\n# CV = 0.09","0e028a8c":"train = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')","72e4b831":"def getDuplicates(img_id):\n    dups = duplicates[img_id]\n    index = train[train.image.isin(dups)].index\n    return train.iloc[index].posting_id.values\n\ntrain['preds'] = train['image'].progress_apply(getDuplicates)","d5a493ef":"def getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]) )\n        return 2*n \/ (len(row.target)+len(row[col]))\n    return f1score\n\ndef combine_for_cv(row):\n    x = np.concatenate([row.preds])\n    return np.unique(x)\n\ntmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\ntrain['target'] = train.label_group.map(tmp)\ntrain['oof'] = train.apply(combine_for_cv, axis=1)\ntrain['f1'] = train.apply(getMetric('oof'), axis=1)\nprint('CV Score =', round(train.f1.mean(), 3) )","9aae0d85":"#### Step 2 : Use hashing method to match duplicates","1192a75d":"#### Step 4 : Evaluation","732d3d1f":"**The purpose of this notebook is to test the performance of the Imagededup library on train set.**\n\nThanks to @Tanay's notebook [Finding similar Images using Image Deduplicator \ud83d\udcbb](https:\/\/www.kaggle.com\/heyytanay\/finding-similar-images-using-image-deduplicator) and dataset [imagededup-cp37](https:\/\/www.kaggle.com\/heyytanay\/imagededupcp37).","a99cf79f":"#### Conclusion : so far its performance is not very satisfactory.\n\nGitHub : [imagededup](https:\/\/github.com\/idealo\/imagededup)","726d1e57":"#### Step 1 : Installation & Import","fe0717f5":"#### Step 3 : Inference result process"}}