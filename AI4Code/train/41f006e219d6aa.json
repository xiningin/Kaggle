{"cell_type":{"21531dee":"code","aa713d16":"code","066d7f42":"code","70d9aded":"code","b0f79e14":"code","dda69706":"code","136ce1ad":"code","b9f9f904":"code","3103545b":"code","4405505b":"code","80d51c27":"code","e67544bf":"code","efdb98d9":"code","c9272579":"code","2ade4a08":"code","972d4493":"code","38cf8a44":"code","ae67f1f4":"code","70f121a0":"code","0128036a":"code","5590d1c3":"markdown","0a5254cc":"markdown","61a32b82":"markdown","54b0a188":"markdown"},"source":{"21531dee":"import os\nimport math\nimport re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom functools import partial\n\nimport tensorflow as tf\n\nprint(\"Version Of Tensorflow used = \", tf.__version__)","aa713d16":"np.set_printoptions(precision = 3)","066d7f42":"IMAGE_SIZE = [256, 256]\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 64","70d9aded":"d = {\n     0: \"Cassava Bacterial Blight (CBB)\",\n     1: \"Cassava Brown Streak Disease (CBSD)\",\n     2: \"Cassava Green Mottle (CGM)\",\n     3: \"Cassava Mosaic Disease (CMD)\",\n     4: \"Healthy\"\n}","b0f79e14":"TRAINING_FILENAMES = tf.io.gfile.glob('..\/input\/augmented-cassava-tfrec\/train*.tfrec')\nVALIDATION_FILENAMES = tf.io.gfile.glob('..\/input\/augmented-cassava-tfrec\/val*.tfrec')\nTEST_FILENAMES = tf.io.gfile.glob('..\/input\/augmented-cassava-tfrec\/test*.tfrec')\n\nprint(\"Number of training files = \", len(TRAINING_FILENAMES))\nprint(\"Number of validation files = \", len(VALIDATION_FILENAMES))\nprint(\"Number of testing files = \", len(TEST_FILENAMES))","dda69706":"def get_training_dataset() : \n    dataset = load_dataset(TRAINING_FILENAMES, labeled = True, ordered = False)\n    dataset = dataset.map(image_augmentation, num_parallel_calls = AUTOTUNE)\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset","136ce1ad":"def get_validation_dataset() : \n    dataset = load_dataset(VALIDATION_FILENAMES, labeled = True, ordered = False)\n    dataset = dataset.map(image_augmentation, num_parallel_calls=AUTOTUNE)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTOTUNE) \n    return dataset","b9f9f904":"def get_testing_dataset() : \n    dataset = load_dataset(TEST_FILENAMES, labeled = False, ordered = True)\n    dataset = dataset.map(image_augmentation, num_parallel_calls = AUTOTUNE)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset","3103545b":"def load_dataset(filenames, labeled, ordered = False) : \n    ignore_order = tf.data.Options() # Represents options for tf.data.Dataset.\n    if ordered == False : \n        ignore_order.experimental_deterministic = False # disable order. This increases the speed.\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTOTUNE)\n    dataset = dataset.with_options(ignore_order)\n    dataset = dataset.map(partial(read_tfrecord, labeled = labeled), num_parallel_calls = AUTOTUNE)\n    return dataset","4405505b":"def read_tfrecord(example, labeled) : \n    if labeled == True : \n        tfrecord_format = {\n            \"image\" : tf.io.FixedLenFeature([], tf.string),\n            \"label\" : tf.io.FixedLenFeature([], tf.int64)\n        }\n    else:\n        tfrecord_format = {\n            \"image\" : tf.io.FixedLenFeature([], tf.string),\n            \"image_name\" : tf.io.FixedLenFeature([], tf.string)\n        }\n    \n    example = tf.io.parse_single_example(example, tfrecord_format) # analyze the passed example.\n    image = decode_image(example[\"image\"])\n    \n    if labeled == True : \n        label = tf.cast(example[\"label\"], tf.int32)\n        return image, label\n    else:\n        image_name = example[\"image_name\"]\n        return image, image_name","80d51c27":"def decode_image(image) : \n    image = tf.image.decode_jpeg(image, channels = 3)# Decode a JPEG-encoded image to a uint8 tensor.\n    image = tf.cast(image, tf.float32)# Casts a tensor to a new type.\n    image = image\/255.0 # normalizing pixels value in range [0,1]\n    image = tf.reshape(image, [IMAGE_SIZE[0], IMAGE_SIZE[1], 3]) # Reshapes a tensor. tf.cast recasts the type, not the tensor structure.\n    return image","e67544bf":"def image_augmentation(image, label) : \n    image = tf.image.resize(image, IMAGE_SIZE)\n    image = tf.image.random_flip_left_right(image)\n    return image, label","efdb98d9":"def batch_to_numpy(batch_data) : \n    images, labels = batch_data\n    numpy_images = images.numpy()\n    numpy_labels = labels.numpy()\n    if numpy_labels.dtype == object : \n        numpy_labels = [None for _ in enumerate(numpy_images)] # image_name is there. Not label.\n    return numpy_images, numpy_labels","c9272579":"def display_batch(batch_data, predictions = None) : \n    images, labels = batch_to_numpy(batch_data)\n    if all(labels == None) : \n        labels = [None for _ in enumerate(images)]\n    \n    rows = int(math.sqrt(len(images)))\n    columns = len(images)\/\/rows\n    \n    plt.figure(figsize = (20, 20))\n    for n in range(len(images)) : \n        ax = plt.subplot(rows,columns,n+1)\n        plt.imshow(images[n])\n        if labels[n] is not None : \n            plt.title(d[labels[n]], fontsize = 16)\n    plt.grid(False)\n    plt.tight_layout() ","2ade4a08":"training_dataset = get_training_dataset()\nvalidation_dataset = get_validation_dataset()\ntesting_dataset = get_testing_dataset()\n\nprint(\"Training dataset ||||| \", training_dataset)\nprint(\"Validation dataset ||||| \", validation_dataset)\nprint(\"Testing dataset ||||| \", testing_dataset)","972d4493":"def count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\nnum_training_images = count_data_items(TRAINING_FILENAMES)\nnum_validation_images = count_data_items(VALIDATION_FILENAMES)\nnum_testing_images = count_data_items(TEST_FILENAMES)\n\nSTEPS_PER_EPOCH_TRAIN = num_training_images \/\/ BATCH_SIZE\nSTEPS_PER_EPOCH_VAL = num_validation_images \/\/ BATCH_SIZE\n\nprint(\"Number of Training Images = \", num_training_images)\nprint(\"Number of validation Images = \", num_validation_images)\nprint(\"Number of Testing Images = \", num_testing_images)\nprint(\"\\n\")\nprint(\"Numer of steps per epoch in Train = \", STEPS_PER_EPOCH_TRAIN)\nprint(\"Numer of steps per epoch in Validation = \", STEPS_PER_EPOCH_VAL)","38cf8a44":"#train_iter = iter(training_dataset.unbatch().batch(8))","ae67f1f4":"#display_batch(next(train_iter))","70f121a0":"os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\ngpus = tf.config.list_physical_devices(\"GPU\")\nprint(gpus)\nif len(gpus) == 1 : \n    strategy = tf.distribute.OneDeviceStrategy(device = \"\/gpu:0\")\nelse:\n    strategy = tf.distribute.MirroredStrategy()","0128036a":"tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\" : True})\nprint(\"Mixed precision enabled\")","5590d1c3":"# Your Model From Here On...","0a5254cc":"## Thank you !","61a32b82":"# Basic TFRec Unloading-Loading Book\n\n## This book was created alongside the dataset : **https:\/\/www.kaggle.com\/fireheart7\/augmented-cassava-tfrec**\n\ncomposing : \n\n* 180,000+ training images - .tfrec format\n* 3000+ validation images - .tfrec format\n* 1 test image - the one provided by the competition itself\n\n![image.png](attachment:image.png)","54b0a188":"Here is the link to my previous cassava EDA and image processing book : **https:\/\/www.kaggle.com\/fireheart7\/nosedive-eda-cum-image-processing**"}}