{"cell_type":{"f79c6655":"code","d0d6282c":"code","9008d6ff":"code","e72d582a":"code","2ac985fb":"code","251179be":"code","f37c3bb4":"code","a2ff6e9a":"code","9b2102fc":"code","6deec68d":"code","eacfb8c3":"code","c77a216b":"code","6c730a0a":"code","37a4d9af":"code","e5c26cc1":"code","a814d3fb":"code","44e257ee":"code","828b6e5f":"code","4ed754f2":"code","ab3b1c9a":"markdown","1ce0cf3b":"markdown","5656898a":"markdown","a0a94342":"markdown","465007df":"markdown"},"source":{"f79c6655":"import os\n\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport shap\n%matplotlib inline\n\nfrom tsfresh import extract_features\nfrom tsfresh.feature_extraction.settings import MinimalFCParameters","d0d6282c":"np.random.seed(42)","9008d6ff":"data_folder = \"..\/input\/misalignment-fault-detection\/\"","e72d582a":"# Loading the train data\n\ndfs = []\n\nfor file in os.listdir(data_folder + \"train\/\"):\n    if not file.startswith(\"train\") or \"meta\" in file:\n        continue\n    df = pd.read_csv(data_folder + \"train\/\" + file)\n    df[\"id\"] = file\n    df.rename(columns={\"Unnamed: 0\": \"time\"}, inplace=True)\n    dfs.append(df)\n\ndf_train = pd.concat(dfs)\ndf_train.head(5)","2ac985fb":"# Loading the test data\n\ndfs = []\n\nfor file in os.listdir(data_folder + \"test\/\"):\n    if not file.startswith(\"test\") or \"meta\" in file:\n        continue\n    df = pd.read_csv(data_folder + \"test\/\" + file)\n    df[\"id\"] = file\n    df.rename(columns={\"Unnamed: 0\": \"time\"}, inplace=True)\n    dfs.append(df)\n\ndf_test = pd.concat(dfs)\ndf_test.head(5)","251179be":"df_train_meta = pd.read_csv(f\"{data_folder}\/train_meta.csv\")\ndf_train_meta.head(5)","f37c3bb4":"# The group is an identifier for the label (i.e., every group maps to 1 unique label)\ndf_train_meta.groupby(\"group\")[\"label\"].value_counts()","a2ff6e9a":"df_train_meta[\"label\"].value_counts().sort_index().plot(kind=\"bar\")","9b2102fc":"df_train_meta.groupby(\"direction\")[\"label\"].value_counts().unstack(0).plot(kind=\"bar\")","6deec68d":"df_train_meta.groupby(\"speed\")[\"label\"].value_counts().unstack(0).plot(kind=\"bar\")","eacfb8c3":"f, ax = plt.subplots(3, 2, figsize=(20, 15))\n\nneg_random_id = np.random.choice(df_train_meta[(df_train_meta['label'] == -0.5) & (df_train_meta['speed'] == 750)]['id'].values)\npos_random_id = np.random.choice(df_train_meta[(df_train_meta['label'] == +0.5) & (df_train_meta['speed'] == 750)]['id'].values)\n\nneg_data = df_train[df_train['id'] == f'train_{neg_random_id}.csv']\npos_data = df_train[df_train['id'] == f'train_{pos_random_id}.csv']\n\nax[0][0].plot(pos_data['0'].values)\nax[1][0].plot(pos_data['1'].values)\nax[2][0].plot(pos_data['2'].values)\nax[0][0].set_title('Misalignment of +0.5 mm')\n\nax[0][1].plot(neg_data['0'].values)\nax[1][1].plot(neg_data['1'].values)\nax[2][1].plot(neg_data['2'].values)\nax[0][1].set_title('Misalignment of -0.5 mm')\n\nplt.show()","c77a216b":"extraction_settings = MinimalFCParameters()","6c730a0a":"X = extract_features(df_train, column_id=\"id\", column_sort=\"time\", default_fc_parameters=extraction_settings)\nX.reset_index(inplace=True)\nX[\"index\"] = X[\"index\"].apply(lambda x: x.replace(\"train\", \"\").replace(\".csv\", \"\").replace(\"_\", \"\")).astype(int)","37a4d9af":"X = X.merge(df_train_meta[[\"id\", \"label\"]], left_on=\"index\", right_on=\"id\", how=\"left\").drop(columns=[\"id\", \"index\"])\nX.head(5)","e5c26cc1":"X_test = extract_features(df_test, column_id=\"id\", column_sort=\"time\", default_fc_parameters=extraction_settings)\nX_test.reset_index(inplace=True)\nX_test[\"index\"] = X_test[\"index\"].apply(lambda x: x.replace(\"test\", \"\").replace(\".csv\", \"\").replace(\"_\", \"\")).astype(int)\nX_test.head(5)","a814d3fb":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom catboost import CatBoostRegressor\nfrom sklearn.metrics import mean_absolute_error\n\nmaes = []\ntest_preds = []\n\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\nfor fold_ix, (train_idx, test_idx) in enumerate(kf.split(X, LabelEncoder().fit_transform(X[\"label\"].astype(str)))):\n   # Split data into train and test\n    X_train = X.drop(columns=[\"label\"]).iloc[train_idx, :]\n    X_test_cv = X.drop(columns=[\"label\"]).iloc[test_idx, :]\n    y_train = X[\"label\"][train_idx]\n    y_test_cv = X[\"label\"][test_idx]\n    \n    print('Training...')\n    \n    cat = CatBoostRegressor(iterations=100000, od_type='Iter', od_wait=100, \n                            learning_rate=0.03, task_type='CPU',\n                            random_state=42)\n    cat.fit(X_train, y_train, eval_set=(X_test_cv, y_test_cv), verbose=0)\n\n    \n    preds = cat.predict(X_train)    \n    print('[TRAIN] MAE =', mean_absolute_error(y_train, preds))\n\n\n    preds = cat.predict(X_test_cv)\n    val_mae = mean_absolute_error(y_test_cv, preds)\n    maes.append(val_mae)\n    print('[VALID] MAE =', val_mae)\n\n    preds = cat.predict(X_test)\n    test_preds.append(preds)\n    \n    plt.figure()\n        \n    explainer = shap.TreeExplainer(cat)\n    shap_values = explainer.shap_values(X.drop(columns=[\"label\"]))\n    shap.summary_plot(shap_values, X.drop(columns=[\"label\"]), max_display=50, \n                      auto_size_plot=True, show=False, color_bar=False)\n    plt.show()","44e257ee":"print(f'Estimated LB Score: {np.mean(maes)}+-{np.std(maes)}')","828b6e5f":"median_test_preds = np.median(test_preds, axis=0)","4ed754f2":"pd.DataFrame({\"id\": X_test[\"index\"].values, \"misalignment\": median_test_preds}).to_csv(\"median_preds_test.csv\", index=False)","ab3b1c9a":"# Generate our submission file.","1ce0cf3b":"# Modeling\n\nWe will use a modeling technique that works very well on tabular data in general: gradient boosting. There are other options out there, and some may be better suited for this type of data...\n\nWe fit our model in cross-validation, which allows us to locally estimate our LB score. For each fold of the cross-validation, we save the predictions on the test set. Our submission is then the median of these predictions across the different folds.\n\nShap is also included in this code cell, which is a cool technique to visualize feature importances (and much more).","5656898a":"# Minimal EDA\n\nAs a simple exploratory data analysis, let us visualize some samples from the most extreme cases: misalignment of -0.5 and misalignment of 0.5. ","a0a94342":"# Loading the data\n\nWe will just iterate over the files in a directory, use `read_csv`, add an `id` column, and rename the \"Unnamed: 0\" (which counts from 0 to len - 1) as \"time\", which is the format required by `tsfresh`. We also load our `train_meta.csv`","465007df":"# Feature extraction\n\nWe will use `tsfresh` with `MinimalFCParameters` as a simple baseline. There are many more features available in `tsfresh`, it is up to you to have a look at the documentation and add these! **Of course, you can try to come up with features on your own as well.** Once features are extracted, we merge the train features with train_meta in order to get the corresponding labels."}}