{"cell_type":{"c514093e":"code","b2325aa8":"code","6d860448":"code","9b2d2f44":"code","ed5f060e":"code","194417fb":"code","02b0a5be":"code","9cc13903":"code","b3b48557":"code","618cdc3e":"code","77fba910":"code","2078e35a":"code","d715e877":"code","bfd5ae2d":"code","428b9b4c":"code","e49bd428":"code","e3baaed9":"code","b0ce9451":"code","6a03c6af":"code","e77fdf76":"code","3fdfa5d8":"code","4dcde26c":"code","afae9ab1":"code","e0b15452":"code","ed793619":"code","5c8d1e0e":"code","99413570":"code","f164bb48":"code","eb84cf72":"code","7a3e365a":"code","8df42414":"markdown","613c845a":"markdown","810ec949":"markdown","0e07e7e7":"markdown","aefa7d92":"markdown","4db24ef1":"markdown","8a2769b2":"markdown","3801d8c5":"markdown","c135f4d4":"markdown","258c46b1":"markdown","2b804f05":"markdown","b1c41337":"markdown","0c3392f3":"markdown","fd2f9c0a":"markdown","0cb843b7":"markdown","2ec2d995":"markdown","60ca3edf":"markdown","12e09eec":"markdown","b30ce847":"markdown","cc984c1a":"markdown","810e9640":"markdown","475787fe":"markdown","9a4cb456":"markdown","301cf909":"markdown","84a5173d":"markdown","67e82dce":"markdown","ea89ba58":"markdown","0e33d912":"markdown","9c43e2a8":"markdown","61b92b71":"markdown"},"source":{"c514093e":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom keras.applications import MobileNet, MobileNetV2\nfrom keras.models import Sequential\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import Dropout, Dense, BatchNormalization\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau","b2325aa8":"path = '..\/input\/images\/dataset\/'","6d860448":"os.listdir(path)","9b2d2f44":"train_df = pd.read_csv(path + 'train.csv')\ntest_df = pd.read_csv(path + 'test.csv')\n\ntrain_df.head()","ed5f060e":"plt.figure(figsize=(10, 10))\n\nfor i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    img = mpimg.imread(path + '\/Train Images\/' + train_df[\"Image\"][i])\n    img = cv2.resize(img, (224, 224))\n    plt.imshow(img)\n    plt.title(train_df[\"Class\"][i])\n    plt.axis(\"off\")","194417fb":"train_df['Class'].unique()","02b0a5be":"class_map = {\n    'Food': 0,\n    'Attire': 1,\n    'Decorationandsignage': 2,\n    'misc': 3\n}\n\ninverse_class_map = {\n    0: 'Food',\n    1: 'Attire',\n    2: 'Decorationandsignage',\n    3: 'misc'\n}","9cc13903":"sns.countplot(train_df['Class'])","b3b48557":"train_df[\"Class\"].value_counts()","618cdc3e":"balance_attire = (2278 - 1691)\nbalance_decoration = (2278 - 743) \nbalance_misc = (2278 - 1271) \nbalance_food = 1000","77fba910":"recover_balance = { 'Image': [], 'Class': [] }\n\nwhile balance_food != 0:\n    for i in range(train_df.shape[0]):\n        if balance_food == 0:\n                break\n        if train_df.iloc[i][\"Class\"] == 'Food':\n            recover_balance[\"Image\"].append(train_df.iloc[i][\"Image\"])\n            recover_balance[\"Class\"].append(train_df.iloc[i][\"Class\"])\n            balance_food -= 1\n            \nwhile balance_attire != 0:\n    for i in range(train_df.shape[0]):\n        if balance_attire == 0:\n                break\n        if train_df.iloc[i][\"Class\"] == 'Attire':\n            recover_balance[\"Image\"].append(train_df.iloc[i][\"Image\"])\n            recover_balance[\"Class\"].append(train_df.iloc[i][\"Class\"])\n            balance_attire -= 1\n            \nwhile balance_decoration != 0:\n    for i in range(train_df.shape[0]):\n        if balance_decoration == 0:\n                break\n        if train_df.iloc[i][\"Class\"] == 'Decorationandsignage':\n            recover_balance[\"Image\"].append(train_df.iloc[i][\"Image\"])\n            recover_balance[\"Class\"].append(train_df.iloc[i][\"Class\"])\n            balance_decoration -= 1\n            \nwhile balance_misc != 0:\n    for i in range(train_df.shape[0]):\n        if balance_misc == 0:\n                break\n        if train_df.iloc[i][\"Class\"] == 'misc':\n            recover_balance[\"Image\"].append(train_df.iloc[i][\"Image\"])\n            recover_balance[\"Class\"].append(train_df.iloc[i][\"Class\"])\n            balance_misc -= 1","2078e35a":"balance_df = pd.DataFrame(recover_balance)\nbalance_df = balance_df.sample(frac = 1)\nbalance_df.head()","d715e877":"temp_df = pd.concat([balance_df, train_df])\n\nsns.countplot(temp_df['Class'])","bfd5ae2d":"train_df['Class'] = train_df['Class'].map(class_map).astype(np.uint8)\ntrain_df.head()","428b9b4c":"balance_df['Class'] = balance_df['Class'].map(class_map).astype(np.uint8)\nbalance_df.head()","e49bd428":"h, w = 224, 224\nbatch_size = 64\nepochs = 100","e3baaed9":"train_path = path + '\/Train Images\/'\ntest_path = path + '\/Test Images\/'","b0ce9451":"train_images, train_labels = [], []\n\nfor i in range(train_df.shape[0]):\n    train_image = cv2.imread(train_path + str(train_df.Image[i]))\n    train_image = cv2.cvtColor(train_image, cv2.COLOR_BGR2RGB)\n    train_image = cv2.resize(train_image, (h, w))\n    train_images.append(train_image)\n    train_labels.append(train_df.Class[i])\n\n# After adding the train_df data add balance_df inorder to balance the total training data\nfor i in range(balance_df.shape[0]):\n    train_image = cv2.imread(train_path + str(balance_df.Image[i]))\n    train_image = cv2.cvtColor(train_image, cv2.COLOR_BGR2RGB)\n    train_image = cv2.resize(train_image, (h, w))\n    train_images.append(train_image)\n    train_labels.append(balance_df.Class[i])\n\ntest_images = []\n\nfor i in range(test_df.shape[0]):\n    test_image = cv2.imread(test_path + str(test_df.Image[i]))\n    test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n    test_image = cv2.resize(test_image, (h, w))\n    test_images.append(test_image)\n\ntrain_images = np.array(train_images)\ntest_images = np.array(test_images)","6a03c6af":"X_train, X_test, y_train, y_test = train_test_split(train_images, to_categorical(train_labels), test_size=0.3, random_state=42)","e77fdf76":"base_model = MobileNet(\n    input_shape=(h, w, 3), \n    weights='imagenet',\n    include_top=False, \n    pooling='avg'\n)\n\nbase_model.summary()","3fdfa5d8":"base_model.trainable = False\n\noutput_class = 4\n\nmodel = Sequential([\n  base_model,\n  Dense(output_class, activation='softmax')\n])\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","4dcde26c":"earlystop = EarlyStopping(monitor='val_loss', patience=5)\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\ncallbacks = [earlystop, learning_rate_reduction]","afae9ab1":"datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)","e0b15452":"model.fit_generator(datagen.flow(X_train, y_train, batch_size = batch_size), validation_data = (X_test, y_test),\n                    steps_per_epoch = len(X_train) \/ batch_size, epochs = epochs, callbacks = callbacks)","ed793619":"labels = model.predict(test_images)\nprint(labels[:4])","5c8d1e0e":"label = [np.argmax(i) for i in labels]\nprint(label[:4])","99413570":"class_label = [inverse_class_map[x] for x in label]\nprint(class_label[:4])","f164bb48":"submission = pd.DataFrame({ 'Image': test_df.Image, 'Class': class_label })\nsubmission.head()","eb84cf72":"plt.figure(figsize=(10, 10))\n\nfor i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    img = mpimg.imread(path + '\/Test Images\/' + submission[\"Image\"][i])\n    img = cv2.resize(img, (224, 224))\n    plt.imshow(img)\n    plt.title(submission[\"Class\"][i])\n    plt.axis(\"off\")","7a3e365a":"# submission.to_csv('sub.csv', index=False)","8df42414":"The final dense layer of our CNN will have an activation function softmax. Here define the number of output classes, in this case it's 4 \n\n![image.png](attachment:image.png)\n\nknow more about softmax --> https:\/\/deepai.org\/machine-learning-glossary-and-terms\/softmax-layer#:~:text=The%20softmax%20function%20can%20be,be%20difficult%20to%20work%20with.","613c845a":"# Let's look at some of the predictions","810ec949":"Now we have created our base model","0e07e7e7":"# Predicting with our model","aefa7d92":"Check how many different classes of image are there","4db24ef1":"Always check the available files\/folders before starting","8a2769b2":"So our new dataframe is created which will balance the data.","3801d8c5":"# Creating train and test sets for training our model","c135f4d4":"Creating train and test set","258c46b1":"# Converting to numerical classes","2b804f05":"# Multiclass Image Classification","b1c41337":"In this notebook I will show -\n* how to read image files(located on different folders) from a .csv file\n* fix class imbalance\n* simple image preprocessing\n* how to use a prebuild model for training and testing\n\nLet's get started \ud83d\udd25\ud83d\udd25","0c3392f3":"The output shows the probability value of each class for an image.\n\nWe will take the class which has the maximum probability value.","fd2f9c0a":"Now since the **test_images** will be used for prediction we cannot use it as validation set during training of our model.\n\nSo we will create a train and test set by splitting the **train_images**","0cb843b7":"![image.png](attachment:image.png)","2ec2d995":"Now converting the numerical class to categorical class","60ca3edf":"# Check for class imbalance","12e09eec":"Check if we solve the imbalance","b30ce847":"Here we will see a simple, easy to use image preprocessing technique\n\nImageDataGenerator is an image augmentation process where rescaling, zooming, flips and other values are defined. Basically it helps to modify the image so that our model has a less chance of overfitting and underfitting","cc984c1a":"Yes the class imbalance is now fixed.","810e9640":"Clearly there is a class imbalance\n\nSo, we have to add some similar 'class' data to the other classes in a manner that the class imbalance of other classes will be fixed and also food will remain the most dominant class","475787fe":"Now just create the submission DataFrame and it's done","9a4cb456":"Comment your thoughts on this notebook  \ud83d\udc47 \ud83d\udc47","301cf909":"We will be using a prebuild model MobileNet to train our data\n\nBelow is a structure of a mobilenet\n\nknow more --> https:\/\/towardsdatascience.com\/review-mobilenetv1-depthwise-separable-convolution-light-weight-model-a382df364b69","84a5173d":"# Training the model","67e82dce":"Create a dictionary to convert the unique class names into numerical values","ea89ba58":"Let's look at some images on the train set","0e33d912":"Now the entire model is created.\n\nWe will now define some callbacks. Callbacks basically stops the training process(model is saved) if it detects an increase of loss or overfitting in our model. Callbacks also reduce the learning rate based on model performance.","9c43e2a8":"So class 0 has more data than other other classes, we have to fix this","61b92b71":"Now we have to add these number of images to the train_df for each class to remove the class imbalance"}}