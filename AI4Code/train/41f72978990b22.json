{"cell_type":{"1596e8a7":"code","05eee670":"code","c87356ed":"code","029bc328":"code","e9f8d0cd":"code","33a50735":"code","97b1731e":"code","3e1afd95":"code","b3d494f7":"code","3fe8544b":"code","97d18e4d":"code","65eaa698":"code","77b1d4d4":"code","c89a47b6":"code","c938fcc5":"code","2546ce38":"code","7d5a1557":"code","fc8276ed":"code","b5899a03":"code","96a1df19":"code","820883b1":"code","4818f89a":"code","e371d507":"code","75101902":"code","44f79b69":"code","a363045e":"code","6222e170":"code","a7af3c71":"code","5e3c7f15":"code","7857d7da":"code","20379770":"code","542ca3fa":"code","2f26934c":"code","6360f8db":"code","81617d88":"code","9592a5be":"code","e03e9e5b":"code","81b86a17":"code","2d44268d":"code","8fa9419a":"code","ed910560":"code","73413886":"markdown","2af9ac56":"markdown","28141460":"markdown","653bf888":"markdown","86ab61eb":"markdown","6498f2c4":"markdown","5dd92c58":"markdown","81b2e5aa":"markdown","75581d02":"markdown","f5b2a3bc":"markdown","154d6fd7":"markdown"},"source":{"1596e8a7":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf","05eee670":"data = pd.read_csv('..\/input\/lending-club\/accepted_2007_to_2018Q4.csv.gz', compression='gzip')","c87356ed":"data","029bc328":"# Cutting the data in half to avoid out-of-memory issues\n\ndata = data.sample(frac=0.5, axis=0, random_state=42).reset_index(drop=True)","e9f8d0cd":"data","33a50735":"data.isna().mean().sort_values()","97b1731e":"data = data.drop(data.loc[:, data.isna().mean().sort_values() > 0.3].columns, axis=1)","3e1afd95":"data","b3d494f7":"data = data.dropna(axis=0).reset_index(drop=True)","3fe8544b":"data.isna().sum().sum()","97d18e4d":"data","65eaa698":"unneeded_columns = ['id', 'sub_grade', 'emp_title', 'url', 'title', 'zip_code']","77b1d4d4":"{column: list(data[column].unique()) for column in data.drop(unneeded_columns, axis=1).columns if data.dtypes[column] == 'object'}","c89a47b6":"data = data.drop(unneeded_columns, axis=1)","c938fcc5":"date_columns = ['issue_d', 'earliest_cr_line', 'last_pymnt_d', 'last_credit_pull_d']","2546ce38":"data['issue_d']","7d5a1557":"data.loc[0, 'issue_d'][0:3]","fc8276ed":"data.loc[0, 'issue_d'][-4:]","b5899a03":"for column in date_columns:\n    data[column + '_month'] = data[column].apply(lambda x: x[0:3])\n    data[column + '_year'] = data[column].apply(lambda x: x[-4:])","96a1df19":"data","820883b1":"data = data.drop(date_columns, axis=1)","4818f89a":"data","e371d507":"month_ordering = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']","75101902":"for column in date_columns:\n    data[column + '_month'] = data[column + '_month'].apply(lambda x: month_ordering.index(x))","44f79b69":"data","a363045e":"for column in data.columns:\n    try:\n        data[column] = data[column].astype(np.float)\n    except:\n        pass","6222e170":"{column: list(data[column].unique()) for column in data.columns if data.dtypes[column] == 'object'}","a7af3c71":"target = 'grade'\n\n\nbinary_features = ['term', 'pymnt_plan', 'initial_list_status', 'application_type', 'hardship_flag', 'disbursement_method', 'debt_settlement_flag']\nbinary_positives = [' 60 months', 'y', 'w', 'Individual', 'Y', 'Cash', 'Y']\n\nordinal_features = ['emp_length']\nemp_ordering = [\n    '< 1 year',\n    '1 year',\n    '2 years',\n    '3 years',\n    '4 years',\n    '5 years',\n    '6 years',\n    '7 years',\n    '8 years',\n    '9 years',\n    '10+ years'\n]\n\nnominal_features = ['home_ownership', 'verification_status', 'loan_status', 'purpose', 'addr_state']","5e3c7f15":"# Encoding functions\n\ndef binary_encode(df, column, positive_value):\n    df[column] = df[column].apply(lambda x: 1 if x == positive_value else 0)\n\ndef ordinal_encode(df, column, ordering):\n    df[column] = df[column].apply(lambda x: ordering.index(x))\n\ndef onehot_encode(df, column):\n    dummies = pd.get_dummies(df[column])\n    df_new = pd.concat([df, dummies], axis=1)\n    df_new = df_new.drop(column, axis=1)\n    return df_new","7857d7da":"# Perform encoding\n\nfor feature, positive_value in zip(binary_features, binary_positives):\n    binary_encode(data, feature, positive_value)\n\nordinal_encode(data, 'emp_length', emp_ordering)\n\nfor feature in nominal_features:\n    data = onehot_encode(data, feature)","20379770":"(data.dtypes == 'object').sum()","542ca3fa":"data[target].value_counts()","2f26934c":"# Encoding label column\n\nlabel_encoder = LabelEncoder()\n\ndata[target] = label_encoder.fit_transform(data[target])\n\ntarget_mappings = {index: label for index, label in enumerate(label_encoder.classes_)}\ntarget_mappings","6360f8db":"data","81617d88":"y = data['grade']\nX = data.drop('grade', axis=1)","9592a5be":"scaler = StandardScaler()\n\nX = scaler.fit_transform(X)","e03e9e5b":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)","81b86a17":"X.shape","2d44268d":"inputs = tf.keras.Input(shape=(166,))\nx = tf.keras.layers.Dense(64, activation='relu')(inputs)\nx = tf.keras.layers.Dense(64, activation='relu')(x)\noutputs = tf.keras.layers.Dense(7, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\n\nmodel.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n\nbatch_size = 32\nepochs = 20\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    validation_split=0.2,\n    batch_size=batch_size,\n    epochs=epochs,\n    callbacks=[tf.keras.callbacks.ReduceLROnPlateau()]\n)","8fa9419a":"plt.figure(figsize=(14, 10))\n\nepochs_range = range(epochs)\ntrain_loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.plot(epochs_range, train_loss, label=\"Training Loss\")\nplt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Loss Over Time\")\nplt.legend()\n\nplt.show()","ed910560":"model.evaluate(X_test, y_test)","73413886":"# Preprocessing","2af9ac56":"## Splitting and Scaling","28141460":"## Dealing With Date Features","653bf888":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/h6cTpNxTN_I","86ab61eb":"## Encoding","6498f2c4":"# Modeling and Training","5dd92c58":"# Results","81b2e5aa":"# Task for Today  \n\n***\n\n## Loan Grade Classification  \n\nGiven *data about accepted LendingClub loans*, let's try to classify the **grade** of a particular loan.  \n  \nWe will use a TensorFlow ANN to make our predictions.","75581d02":"## Feature Selection","f5b2a3bc":"# Getting Started","154d6fd7":"## Missing Values"}}