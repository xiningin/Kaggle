{"cell_type":{"9750b461":"code","1c07cdc2":"code","10ac1a0a":"code","0fdb1444":"code","cea02ffc":"code","999a5ecf":"code","bb6d1d2d":"code","c54da9fc":"code","de45b874":"code","0ddd7e94":"code","584e34d7":"code","065bae66":"code","662db7e9":"code","f7045a14":"code","baf25cfe":"code","f8123eb1":"code","b040d5ab":"code","49bfbfd9":"code","5cb1cab4":"code","dd1b74e0":"code","6d1bf204":"code","7df914ae":"code","965e6647":"code","5bb545a3":"code","b904ba60":"code","cee2b471":"code","52c11b50":"code","6cd6ed40":"code","addcd6d2":"code","ea0d0fe0":"code","a627a5f2":"code","51adf614":"code","47e699cd":"code","87b230c7":"code","25229342":"code","3b6b7c07":"code","4af4d81f":"code","8ff2b586":"code","6a740200":"code","67df80ec":"code","94651206":"code","eed050b6":"code","6e361195":"code","bf7d23e7":"code","b5af2317":"code","22f59bdb":"code","2ad812f2":"code","fb9f3914":"code","f03bd0be":"code","5b9e0469":"code","30cd9355":"code","a1241352":"code","4a0be2a8":"code","e664e600":"markdown","a0f9df8d":"markdown","97a34f16":"markdown","2e876276":"markdown","e141869f":"markdown","f210a370":"markdown","baae64e6":"markdown","dcc5a4ba":"markdown","af94c8f2":"markdown","3cfb2602":"markdown","7892979f":"markdown","f4f956ad":"markdown","63948617":"markdown","018742e8":"markdown","33a52f2a":"markdown","cc7745a5":"markdown","136e52f7":"markdown","6513e8b0":"markdown","a953b3d6":"markdown"},"source":{"9750b461":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1c07cdc2":"import pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport re\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import  GridSearchCV,train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier","10ac1a0a":"train_df = pd.read_csv(\"..\/input\/titanic\/train.csv\")\nprint(train_df.shape)\ntrain_df.head()","0fdb1444":"test_df = pd.read_csv('..\/input\/titanic\/test.csv')\nprint(test_df.shape)\ntest_df.head()","cea02ffc":"train_df.info()","999a5ecf":"train_df.info()","bb6d1d2d":"train_df.describe()","c54da9fc":"sns.heatmap(train_df.corr(),annot=True)","de45b874":"survived = train_df[(train_df[\"Sex\"]==\"female\") & (train_df[\"Survived\"]==1)]\nprint(len(survived.index))","0ddd7e94":"print([train_df.groupby(\"Sex\")[\"Survived\"].value_counts(normalize = True)])","584e34d7":"pivot_table = train_df.pivot_table(index=\"Sex\",values=\"Survived\")\npivot_table.plot.bar()\nplt.show()","065bae66":"def bar_chart(feature):\n    survived = train_df[train_df['Survived']==1][feature].value_counts()\n    dead = train_df[train_df['Survived']==0][feature].value_counts()\n    df = pd.DataFrame([survived,dead])\n    df.index = ['Survived','Dead']\n    df.plot(kind='bar',stacked=True, figsize=(10,5))","662db7e9":"df = [train_df,test_df]   #Combininng Train and Test Dataset\nfor data in df:\n    data['Title'] = data['Name'].str.extract(r', (\\w+)\\.', expand=False)\npd.crosstab(train_df['Title'], train_df['Sex']).transpose()","f7045a14":"for data in df:\n    data['Title'] = data['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    data['Title'] = data['Title'].replace('Mlle', 'Miss')\n    data['Title'] = data['Title'].replace('Ms', 'Miss')\n    data['Title'] = data['Title'].replace('Mme', 'Mrs')\n    \ntrain_df[['Title', 'Survived']].groupby(['Title']).mean()\n\nlabels = {'Mr':1, 'Mrs':2, 'Master':3, 'Miss':4, 'Rare':5}\ntest_df.replace({'Title':labels}, inplace = True)\ntrain_df.replace({'Title':labels}, inplace = True)\ntrain_df['Title'] = train_df['Title'].fillna(0)\ntrain_df['Title'] = train_df['Title'].astype(int)                     # this is performed beacuse it was giving float values of title","baf25cfe":"pd.DataFrame({'Train':train_df.isnull().sum(), 'Test':test_df.isnull().sum()}).transpose()","f8123eb1":"bar_chart('Title')","b040d5ab":"#Drop unnecessary feature from dataset\ntrain_df.drop('Name', axis=1, inplace=True)\ntest_df.drop('Name', axis=1, inplace=True)","49bfbfd9":"train_df.head(1)","5cb1cab4":"sex_mapping = {\"male\":0,\"female\":1}\nfor data in df:\n    data['Sex']=data['Sex'].map(sex_mapping)","dd1b74e0":"bar_chart('Sex')","6d1bf204":"print('Missing Values in Age column: ',177\/len(train_df['Age'])*100)\nprint('Missing Values in Cabin column: ',687\/len(train_df['Cabin'])*100)\nprint('Missing Values in Embarked column: ',2\/len(train_df['Embarked'])*100)","7df914ae":"fig, (ax1, ax2) = plt.subplots(ncols = 2, figsize = (15,5))\nsns.heatmap(train_df.isnull(), cmap = 'coolwarm', ax = ax1)\nsns.heatmap(test_df.isnull(), cmap = 'mako_r', ax = ax2)","965e6647":"# fill missing age with median age for each title (Mr, Mrs, Miss, Others)\ntrain_df[\"Age\"].fillna(train_df.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\ntest_df[\"Age\"].fillna(test_df.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)","5bb545a3":"train_df.info()","b904ba60":"test_df.info()","cee2b471":"# fill missing age with median age for each title (Mr, Mrs, Miss, Rare)\ntrain_df[\"Age\"].fillna(train_df.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\ntest_df[\"Age\"].fillna(test_df.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)","52c11b50":"train_df.info()","6cd6ed40":"for data in df:\n    data.loc[ data['Age'] <= 16, 'Age'] = 0,\n    data.loc[(data['Age'] > 16) & (data['Age'] <= 26), 'Age'] = 1,\n    data.loc[(data['Age'] > 26) & (data['Age'] <= 36), 'Age'] = 2,\n    data.loc[(data['Age'] > 36) & (data['Age'] <= 62), 'Age'] = 3,\n    data.loc[ data['Age'] > 62, 'Age'] = 4","addcd6d2":"train_df.head(5)","ea0d0fe0":"bar_chart('Age')","a627a5f2":"Pclass1 = train_df[train_df['Pclass']==1]['Embarked'].value_counts()\nPclass2 = train_df[train_df['Pclass']==2]['Embarked'].value_counts()\nPclass3 = train_df[train_df['Pclass']==3]['Embarked'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))","51adf614":"train_df['Embarked'].fillna('S', inplace = True)\n\nlabel = {'S':1, 'C':2, 'Q':3}\ntrain_df.replace({'Embarked':label}, inplace = True)\ntest_df.replace({'Embarked':label}, inplace = True)","47e699cd":"bar_chart('Embarked')","87b230c7":"test_df['Fare'].fillna(test_df['Fare'].median(), inplace = True)\ntrain_df['Fare'].fillna(train_df['Fare'].median(), inplace = True)","25229342":"\ntrain_df['Fare'] = pd.qcut(train_df['Fare'], 4, labels = [1, 2, 3, 4])\ntest_df['Fare'] = pd.qcut(test_df['Fare'], 4, labels = [1, 2, 3, 4])","3b6b7c07":"df_m = train_df[train_df['Survived'] == 0]\ndf_f = train_df[train_df['Survived'] == 1]\ndf_m = df_m['Fare'].value_counts()\ndf_f = df_f['Fare'].value_counts()\n\ntrace1 = go.Bar(x = df_m.index[::-1], y = df_m.values[::-1], name = 'Not Survived', marker = dict(color = 'coral'))\ntrace2 = go.Bar(x = df_f.index[::-1], y = df_f.values[::-1], name = 'Survived', marker = dict(color = 'teal'))\ndata = [trace1, trace2]\nlayout = go.Layout(height = 400, width = 500, title='Fare Distribution')\nfig = go.Figure(data = data, layout= layout)\npy.iplot(fig)","4af4d81f":"train_df[\"CabinBool\"] = (train_df[\"Cabin\"].notnull().astype('int'))\ntest_df[\"CabinBool\"] = (test_df[\"Cabin\"].notnull().astype('int'))\n\n#calculate percentages of CabinBool vs. survived\nprint(\"Percentage of CabinBool = 1 who survived:\", train_df[\"Survived\"][train_df[\"CabinBool\"] == 1].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of CabinBool = 0 who survived:\", train_df[\"Survived\"][train_df[\"CabinBool\"] == 0].value_counts(normalize = True)[1]*100)\n#draw a bar plot of CabinBool vs. survival\nsns.barplot(x=\"CabinBool\", y=\"Survived\", data=train_df)\nplt.show()","8ff2b586":"train_df[\"FamilySize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1\ntest_df[\"FamilySize\"] = test_df[\"SibSp\"] + test_df[\"Parch\"] + 1","6a740200":"train_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)","67df80ec":"train_df.head(3)","94651206":"test_df.head(3)","eed050b6":"train_df.drop(['PassengerId','Ticket', 'Age', 'SibSp', 'Parch','Cabin'], axis = 1, inplace = True)\ntest_df.drop(['Ticket', 'Age', 'SibSp', 'Parch','Cabin'], axis = 1, inplace = True)","6e361195":"train_df.head(5)","bf7d23e7":"X = train_df.drop('Survived', axis = 1)\ny = train_df['Survived']","b5af2317":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)","22f59bdb":"lr = LogisticRegression()\nlr.fit(X_train, y_train)\ny_pred = lr.predict(X_test)\n\nprint('Classification Report: \\n', classification_report(y_pred, y_test))\nlr_train_acc = round(lr.score(X_train, y_train) * 100, 2)\nprint('Training Accuracy: ', lr_train_acc)\nlr_test_acc = round(lr.score(X_test, y_test) * 100, 2)\nprint('Testing Accuracy: ', lr_test_acc)","2ad812f2":"error_rate= []\nfor i in range(1,30):\n    knn = KNeighborsClassifier(n_neighbors = i)\n    knn.fit(X_train, y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))\n    \nplt.figure(figsize = (8,6))\nplt.plot(range(1,30), error_rate, color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)","fb9f3914":"knn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train,y_train)\ny_pred=knn.predict(X_test)\n\nprint('Classification Report: \\n',classification_report(y_pred,y_test))\nknn_train_acc = round(knn.score(X_train,y_train)*100,2)\nprint('Training Accuracy:',knn_train_acc)\nknn_test_acc = round(knn.score(X_test,y_test)*100,2)\nprint('Testing Accuracy:',knn_test_acc)","f03bd0be":"svc = SVC()\nsvc.fit(X_train,y_train)\ny_pred=svc.predict(X_test)\n\nprint('Classification Report: \\n',classification_report(y_pred,y_test))\nsvc_train_acc = round(svc.score(X_train,y_train)*100,2)\nprint('Training Accuracy:',svc_train_acc)\nsvc_test_acc = round(svc.score(X_test,y_test)*100,2)\nprint('Testing Accuracy:',svc_test_acc)","5b9e0469":"dt =DecisionTreeClassifier(min_samples_split=70,min_samples_leaf=10)\ndt.fit(X_train,y_train)\nprediction = dt.predict(X_test)\n\nprint('Classification Report: \\n',classification_report(y_pred,y_test))\ndt_train_acc = round(dt.score(X_train,y_train)*100,2)\nprint('Training Accuracy:',dt_train_acc)\ndt_test_acc = round(dt.score(X_test,y_test)*100,2)\nprint('Testing Accuracy:',dt_test_acc)","30cd9355":"rf = RandomForestClassifier(n_estimators=100)\nrf.fit(X_train,y_train)\nrf_pred = rf.predict(X_test)\n\nprint('Classification Report: \\n',classification_report(y_pred,y_test))\nrf_train_acc = round(rf.score(X_train,y_train)*100,2)\nprint('Training Accuracy:',rf_train_acc)\nrf_test_acc = round(rf.score(X_test,y_test)*100,2)\nprint('Testing Accuracy:',rf_test_acc)","a1241352":"test_df['Fare'] = pd.to_numeric(test_df['Fare'])","4a0be2a8":"test_df['Survived'] = rf.predict(test_df.drop(['PassengerId'], axis = 1))\ntest_df[['PassengerId', 'Survived']].to_csv('MySubmission.csv', index = False)","e664e600":"**Age Feature**","a0f9df8d":"More than 50% of 1st class are from S Embark.<br>\nMore than 50% of 2nd class are from S Embark.<br>\nMore than 50% of 3rd class are from S Embark.","97a34f16":"**Sex Feature**","2e876276":"Correlation in Data","e141869f":"**Logistic Regression**","f210a370":"**Decision Tree**","baae64e6":"**Age Distribution**","dcc5a4ba":"* Age column has 20% of missing values.Age Feature is important to survival,so we attemplt to fill these gaps.<br>\n* We will drop Cabin column because it is not possible to fill 77% missing values.<br>\n* Embarked column has 0.2% of missing values won't causing any issue. ","af94c8f2":"**SibSp and Parch Feature**","3cfb2602":"**Bar Chart For categorical Features**","7892979f":"**Cabin Feature**","f4f956ad":"**Random Forest**","63948617":"**K Nearest Neighbors**","018742e8":"1.Importing Libraries and Reading data<br>\n2.Feature Engineering and Data Visualization<br>\n* Some Visualization\n* Name Feature\n* Sex Feature\n* Age Feature\n* Embarked Feature\n* Cabin Feature\n* SibSp and Parch Feature\n\n\n3.Train and Predict\n* Logistic Regression\n* K Nearest Neighbors\n* Support Vector Machines\n* Decision Tree\n* Random Forest","33a52f2a":"**Embarked feature**","cc7745a5":"**Name Feature**","136e52f7":"**Fare feature**","6513e8b0":"**Support Vector Machines**","a953b3d6":"**Now it's time to train our data using different Algorithms**"}}