{"cell_type":{"32e70c5d":"code","a2068e89":"code","929ddef4":"code","8ca55a4a":"code","5c8e7ad3":"code","ebb27166":"code","3d701513":"code","bf27d6fd":"code","47362cc0":"code","c25c5abd":"code","58d50947":"code","62fdd327":"code","504eb710":"code","d214199c":"code","4ddff8a9":"code","09c2d00b":"code","41c4e5af":"code","afa456fb":"code","21a4acd4":"code","4a0430d5":"code","cc2d165f":"code","df44c5b0":"code","45303a2f":"code","a7e00e97":"code","0aac6750":"code","4adf68b2":"code","835b11eb":"code","d0196e72":"code","b7cebb59":"code","d970b19b":"code","9d2f3100":"code","864eac1e":"code","0a510725":"code","f51b0c22":"code","53da19f5":"code","12ff7470":"markdown","f0e1d739":"markdown","f166e7db":"markdown","a67fc3bc":"markdown","600135ad":"markdown","bb7ea612":"markdown","02952ffd":"markdown","eba4ff53":"markdown","fcb9da34":"markdown"},"source":{"32e70c5d":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport os.path\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport seaborn as sns\n","a2068e89":"# Create a list with the filepaths for training and testing\ntrain_dir = Path('..\/input\/fruits\/fruits-360\/Training')\ndata_filepaths = list(train_dir.glob(r'**\/*.jpg'))\nprint( len(data_filepaths))\n","929ddef4":"def proc_img(filepath):\n    \"\"\" Create a DataFrame with the filepath and the labels of the pictures\n    \"\"\"\n\n    labels = [str(filepath[i]).split(\"\/\")[-2] \\\n              for i in range(len(filepath))]\n\n    filepath = pd.Series(filepath, name='Filepath').astype(str)\n    labels = pd.Series(labels, name='Label')\n\n    # Concatenate filepaths and labels\n    df = pd.concat([filepath, labels], axis=1)\n\n    # Shuffle the DataFrame and reset index\n    df = df.sample(frac=1).reset_index(drop = True)\n    \n    return df","8ca55a4a":"df = proc_img(data_filepaths)","5c8e7ad3":"df.head()","ebb27166":"print(\"The dataframe have {} columns and {} rows\".format(df.shape[1],df.shape[0]))\nprint(\"We have {} differents species of fruits and vegetable\".format(df[\"Label\"].nunique()))\nprint(df[\"Label\"].unique())","3d701513":"s=df.copy()\npercent_dict={}\nN=s.shape[0]\nfor i in s[\"Label\"].unique():\n    d=s.loc[s[\"Label\"]==i]\n    n=d.shape[0]\n    p=n\/N*100\n    percent_dict[i]=p","bf27d6fd":"# Create a DataFrame with one Label of each category\ndf_unique = df.copy().drop_duplicates(subset=[\"Label\"]).reset_index()\n\n# Display some pictures of the dataset\n\nfig, axes = plt.subplots(nrows=4, ncols=10, figsize=(18, 10),\n                        subplot_kw={'xticks': [], 'yticks': []})\nfig.patch.set_facecolor('#E0E0E0')\nfig.patch.set_alpha(0.7)\nplt.suptitle(\"Exemple of species in the all dataset\",size=16)\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(df_unique.Filepath[i]))\n    ax.set_title(df_unique.Label[i]+\"\\n {} % \".format(round(percent_dict[df_unique.Label[i]],2))\n                 , fontsize = 12)\nplt.tight_layout(pad=0.5)\nplt.show()","47362cc0":"def get_sample(N,df):\n    total_label=list(df[\"Label\"].unique())\n    #the_label=np.random.choice(total_label, n_label)\n    #print(\"The selected species\")\n    #print(the_label)\n    \n    #df=df.loc[df[\"Label\"].isin(the_label)]\n    \n    n =df.shape[0]\n    \n    p =N\/n\n    sample=df.sample(frac=p, replace=True)\n    print(\"A {} rows sample as been extracted.\".format(N))\n    n_label=sample[\"Label\"].nunique()\n    return sample, n_label\n    \n\nsample,n=get_sample(4000,df)","c25c5abd":"s=sample.copy()\npercent_dict={}\nN=s.shape[0]\nfor i in s[\"Label\"].unique():\n    d=s.loc[s[\"Label\"]==i]\n    n=d.shape[0]\n    p=n\/N*100\n    percent_dict[i]=p","58d50947":"# Create a DataFrame with one Label of each category\ndf_unique = sample.copy().drop_duplicates(subset=[\"Label\"]).reset_index()\n\n# Display some pictures of the dataset\n\nfig, axes = plt.subplots(nrows=4, ncols=10, figsize=(18, 10),\n                        subplot_kw={'xticks': [], 'yticks': []})\nfig.patch.set_facecolor('#E0E0E0')\nfig.patch.set_alpha(0.7)\nplt.suptitle(\"Exemple of species in the sample\",size=16)\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(df_unique.Filepath[i]))\n    ax.set_title(df_unique.Label[i]+\"\\n {} % \".format(round(percent_dict[df_unique.Label[i]],2))\n                 , fontsize = 12)\nplt.tight_layout(pad=0.5)\nplt.show()","62fdd327":"import tensorflow as tf\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\nfrom tensorflow.keras.preprocessing.image import img_to_array\n\n","504eb710":"import pandas as pd\nfrom PIL import Image, ImageOps\nimport cv2\nimport numpy as np\nimport io\n\nfrom tensorflow.keras.preprocessing import image\n\ndef preprocess(path):\n    \"\"\"\n    Function applying different steps of image pre-processing.\n    \"\"\"\n    \n    img = cv2.imread(path)\n    #img=image.load_img(path)\n    #img=img.img_to_array()\n    img=cv2.resize(img,(224, 224),interpolation=cv2.INTER_CUBIC)   \n             \n    img = cv2.fastNlMeansDenoisingColored(img,None,10,10,7,21) \n    img = ImageOps.equalize(ImageOps.autocontrast(Image.fromarray(img),cutoff=5))\n    img=img_to_array(img)\n    blur_val = (5, 5)# Flou Gaussien\n    img = cv2.GaussianBlur(img,blur_val,0) \n    img=preprocess_input(img)\n    return img","d214199c":"model = ResNet50(weights='imagenet',include_top=False,pooling=\"avg\")\ndef preprocess2(img): \n    \n   \n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    #x = preprocess_input(x)\n    features = model.predict(x)\n    output = [p.flatten() for p in features]\n    return list(output[0])\n","4ddff8a9":"img = cv2.imread(sample[\"Filepath\"].values[0])\nimg= cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg2=cv2.resize(img,(224, 224),interpolation=cv2.INTER_CUBIC)   \n             \nimg3 = cv2.fastNlMeansDenoisingColored(img2,None,10,10,7,21) \nimg4 = np.array(ImageOps.equalize(ImageOps.autocontrast(Image.fromarray(img3),cutoff=5)))\n    \nblur_val = (5, 5)# Flou Gaussien\nimg5 = cv2.GaussianBlur(img4,blur_val,0) \n\narr = img_to_array(img5)\narr_2 = preprocess_input(arr)\n\n","09c2d00b":"fig=plt.figure(figsize=[18,5])\nfig.patch.set_facecolor('#E0E0E0')\nfig.patch.set_alpha(0.7)\nplt.suptitle(\"Preprocessing steps\",size=16)\nplt.subplot(1,6,1)\nplt.title(\"Orginal image\")\nplt.imshow(img)\n\nplt.subplot(1,6,2)\nplt.title(\"Image  resized\")\nplt.imshow(img2)\n\nplt.subplot(1,6,3)\nplt.title(\"Image  Denoised\")\nplt.imshow(img3)\n\nplt.subplot(1,6,4)\nplt.title(\"Image equalized \\n and autocontrasted\")\nplt.imshow(img4)\n\nplt.subplot(1,6,5)\nplt.title(\"GaussianBlur\")\nplt.imshow(img5)\n\n\nplt.subplot(1,6,6)\nplt.title(\"Resnet50 preprocessing\")\nplt.imshow(arr_2)","41c4e5af":"sample[\"Preprocessed images\"]=sample[\"Filepath\"].apply(preprocess)","afa456fb":"sample[\"Features\"]=sample[\"Preprocessed images\"].apply(preprocess2)","21a4acd4":"print(sample.shape)","4a0430d5":"\nfor i in range(0,len(sample[\"Features\"].values[0])):\n    def format_features(val):\n        x=val[i]\n        return x\n    sample[\"feature{}\".format(i+1)]=sample[\"Features\"].apply(format_features)","cc2d165f":"from sklearn import decomposition\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfeatures =sample.drop(columns=['Filepath', 'Label', 'Preprocessed images', 'Features'])\nscaler=StandardScaler() \nXs=scaler.fit_transform(features)\n    \n\n    # apply PCA\npca = decomposition.PCA(n_components=min(features.shape[1],\n                                             features.shape[0])).fit(Xs)\nnbr_pca=0\nscree = pca.explained_variance_ratio_\nfor i in range(features.shape[1]):\n    a = scree.cumsum()[i]\n    if a >= 0.8:\n        print(\"{} principal components explaines  80% of the total variance\".format(i))\n        print(\"Sum of variance explained :{}%\".format(round(a*100,2)))\n        nbr_pca=i\n        break\npca = decomposition.PCA(n_components=nbr_pca)","df44c5b0":"d=pca.fit_transform(Xs)","45303a2f":"d=pd.DataFrame(d, columns=[\"PCA n\u00b0{}\".format(i+1) for i in range(0,nbr_pca) ])","a7e00e97":"d[\"Label\"]=sample[\"Label\"].values","0aac6750":"d.head()","4adf68b2":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import cross_val_score\n\ndef lets_try(train, y):\n    results = {}\n    ss=StandardScaler()\n    scaled_train=ss.fit_transform(train)\n    \n   \n    def test_model(clf):\n        cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=1)\n        scores = cross_val_score(clf, train, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n        return scores\n\n    #for the model which needed standardized data \n    def test_model_scaler(clf):\n    \n        cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=1)\n        scores = cross_val_score(clf, scaled_train, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n        return scores\n    \n    clf = SVC(kernel=\"linear\")\n    results[\"SVC\"] = test_model_scaler(clf)\n    print(\"SVC done\")\n    \n    clf = LogisticRegression()\n    results[\"Logistic Regression\"] = test_model_scaler(clf)\n    print(\"Logistic Regression done\")\n\n    clf = KNeighborsClassifier()\n    results[\"Kneighbors\"] = test_model(clf)\n    print(\"Kneighbors done\")\n\n    clf = SVC(kernel=\"poly\")\n    results[\"SVC poly\"] = test_model_scaler(clf)\n    print(\"SVC poly done.\")\n\n    clf = RandomForestClassifier()\n    results[\"Random Forest Classifier\"] = test_model(clf)\n    print(\"Random Forest Classifier done\")\n\n\n    clf =SVC(kernel='rbf')\n    results[\"SVC RBF\"] = test_model_scaler(clf)\n    print(\"SVC rbf done\")\n\n   \n    return results ","835b11eb":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n\ny=d[\"Label\"]\nX=d.drop(columns=[\"Label\"])\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","d0196e72":"dic_results=lets_try(X_train, y_train)","b7cebb59":"fig=plt.figure(figsize=[10,10])\nfig.patch.set_facecolor('#E0E0E0')\nfig.patch.set_alpha(0.7)\nplt.title(\"Distribution of Cross-validation score  on the trainning set. \\n 3 folds\",size=16)\nplt.boxplot(dic_results.values(),labels=dic_results.keys(),showmeans=True)\nplt.ylabel(\"  Scores CV \\n (Accuracy)\",size=14)\nplt.ylim(0,1)\nplt.xticks(rotation=90)\nplt.grid()","d970b19b":"from sklearn.metrics import accuracy_score \n\nclf = SVC(kernel='linear')\nss=StandardScaler()\nscaled_train=ss.fit_transform(X_train)\nscaled_test=ss.fit_transform(X_test)\nclf.fit(scaled_train,y_train) \npred=clf.predict(scaled_test)\nscore= accuracy_score(y_test,pred)","9d2f3100":"print(\"Accuracy score:\", round(score,3),\" on the testing set with the logistic regression.\")","864eac1e":"dic_fail={}\nfor r,p in zip(list(y_test),pred):\n    if r!=p:\n        if r not in dic_fail.keys():\n      \n            dic_fail[r]=p\n        \n","0a510725":"def get_path(true_val,pred):\n    d=df.loc[df[\"Label\"]==true_val]\n    path_true=d[\"Filepath\"].values[0]\n    img_true = cv2.imread(path_true)\n    img_true= cv2.cvtColor(img_true, cv2.COLOR_BGR2RGB)\n    \n    d=df.loc[df[\"Label\"]==pred]\n    path_pred=d[\"Filepath\"].values[0]\n    img_pred = cv2.imread(path_pred)\n    img_pred= cv2.cvtColor(img_pred, cv2.COLOR_BGR2RGB)\n    \n    return img_true,img_pred","f51b0c22":"\ndef display_pred(true_val,pred):\n    path_true,path_pred=get_path(true_val,pred)\n    fig=plt.figure(1,figsize=[10,6])\n    fig.patch.set_facecolor('#E0E0E0')\n    fig.patch.set_alpha(0.7)\n    plt.suptitle(\"Prediction for {} on the testing set\".format(true_val),size=16)\n    plt.subplot(1,2,1)\n    plt.title(\"True Label:\")\n    plt.imshow(path_true)\n\n    plt.subplot(1,2,2)\n    plt.title(\"Prediction: \\n {}\".format(pred))\n    plt.imshow(path_pred)\n    plt.show()","53da19f5":"for t, p in zip(dic_fail.keys(),dic_fail.values()):\n    display_pred(t,p)","12ff7470":"# **Personnal project**: Recognition of fruit and vegetable species.\nIn this notebook I will use the **fruits-360\/Training** directory to train a classifier.\n\nI will use the Resnet 50 neural network pre-trained on the \"ImageNet\"  set to extract features, the apply a dimensional reduction on the extracted features.\n\nTo finish I will use classification models to distinguish the species\n\nthis notebook consist on 4 parts:\n\n1. **Load images**\n\n2. **Preprocessing and features extraction**\n\n3. **Dimensional reduction with PCA**\n\n4. **Classification**\n\nI was inspired by the Notebook available at https:\/\/www.kaggle.com\/databeru\/classify-131-fruits-1-epoch-acc-95 for some visualizations","f0e1d739":" * **Image pre-processing**","f166e7db":"* **Error check on the testing set**","a67fc3bc":"*  **Features Extraction**","600135ad":"# 1. Load images ","bb7ea612":"#  3. dimensional reduction with PCA","02952ffd":"# 4. Classification","eba4ff53":"# Conclusion:\nThe SVC model performs very well on the test set with an **accuracy of 98.3%**.\n\nThe features **extracted with Resnet50 can be used to distinguish**  fruit and vegetable species.\n\nUsing **PCA does not cause a big loss** of information.\n\n**Test set errors:** the model attribute a prediction which have  the same shape, color, or texture","fcb9da34":"# 2. Image preprocessing and features extraction with Resnet50"}}