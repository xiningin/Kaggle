{"cell_type":{"726138eb":"code","ebb450cd":"code","101b393d":"code","76e4743e":"code","1d2d5832":"code","82517e2d":"code","fbfbbe2d":"code","a486338e":"code","b1f77cf5":"code","8233d295":"code","94002ea9":"code","0c106e85":"code","a623401b":"code","bdc5f472":"code","bce2a2c0":"code","1daa9d0d":"code","85d9621d":"code","e4252d95":"code","7d844577":"code","bf092af4":"code","d12bc624":"markdown","088c3b95":"markdown","31eaf83b":"markdown","c1108b38":"markdown","e3e6447c":"markdown","a74a0837":"markdown","76a64872":"markdown","abc7086a":"markdown","9c585985":"markdown","ab0ad70f":"markdown","c3acaadc":"markdown","8e9c87cb":"markdown"},"source":{"726138eb":"%matplotlib inline\n\nimport os\nimport shutil\nimport random\nimport torch\nimport torchvision\nimport numpy as np\n\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\n\ntorch.manual_seed(0)\n\nprint('Using PyTorch version', torch.__version__)","ebb450cd":"class_names = ['normal', 'viral', 'covid']\n# root_dir = 'COVID-19 Radiography Database'\n#root_dir = '\/path\/to\/your\/downloaded\/COVID-19 Radiography Database'\nroot_dir = '..\/input\/covid19xrays\/COVID-19 Radiography Database'\nsource_dirs = ['NORMAL', 'Viral Pneumonia', 'COVID-19']\n\nif os.path.isdir(os.path.join(root_dir, source_dirs[1])):\n    os.mkdir(os.path.join(root_dir, 'test'))\n\n    for i, d in enumerate(source_dirs):\n        os.rename(os.path.join(root_dir, d), os.path.join(root_dir, class_names[i]))\n\n    for c in class_names:\n        os.mkdir(os.path.join(root_dir, 'test', c))\n\n    for c in class_names:\n        images = [x for x in os.listdir(os.path.join(root_dir, c)) if x.lower().endswith('png')]\n        selected_images = random.sample(images, 30)\n        for image in selected_images:\n            source_path = os.path.join(root_dir, c, image)\n            target_path = os.path.join(root_dir, 'test', c, image)\n            shutil.move(source_path, target_path)","101b393d":"class ChestXRayDataset(torch.utils.data.Dataset):\n    def __init__(self, image_dirs, transform):\n        def get_images(class_name):\n            images = [x for x in os.listdir(image_dirs[class_name]) if x.lower().endswith('png')]\n            print(f'Found {len(images)} {class_name} examples')\n            return images\n        \n        self.images = {}\n        self.class_names = ['normal', 'viral', 'covid']\n        \n        for class_name in self.class_names:\n            self.images[class_name] = get_images(class_name)\n            \n        self.image_dirs = image_dirs\n        self.transform = transform\n        \n    \n    def __len__(self):\n        return sum([len(self.images[class_name]) for class_name in self.class_names])\n    \n    \n    def __getitem__(self, index):\n        class_name = random.choice(self.class_names)\n        index = index % len(self.images[class_name])\n        image_name = self.images[class_name][index]\n        image_path = os.path.join(self.image_dirs[class_name], image_name)\n        image = Image.open(image_path).convert('RGB')\n        return self.transform(image), self.class_names.index(class_name)","76e4743e":"train_transform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize(size=(224, 224)),\n    torchvision.transforms.RandomHorizontalFlip(),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntest_transform = torchvision.transforms.Compose([\n    torchvision.transforms.Resize(size=(224, 224)),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","1d2d5832":"train_dirs = {\n    'normal': f'{root_dir}\/normal',\n    'viral': f'{root_dir}\/viral',\n    'covid': f'{root_dir}\/covid'\n}\n\ntrain_dataset = ChestXRayDataset(train_dirs, train_transform)","82517e2d":"test_dirs = {\n    'normal': f'{root_dir}\/test\/normal',\n    'viral': f'{root_dir}\/test\/viral',\n    'covid': f'{root_dir}\/test\/covid'\n}\n\ntest_dataset = ChestXRayDataset(test_dirs, test_transform)","fbfbbe2d":"batch_size = 6\n\ndl_train = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ndl_test = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n\nprint('Number of training batches', len(dl_train))\nprint('Number of test batches', len(dl_test))","a486338e":"class_names = train_dataset.class_names\n\n\ndef show_images(images, labels, preds):\n    plt.figure(figsize=(8, 4))\n    for i, image in enumerate(images):\n        plt.subplot(1, 6, i + 1, xticks=[], yticks=[])\n        image = image.numpy().transpose((1, 2, 0))\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n        image = image * std + mean\n        image = np.clip(image, 0., 1.)\n        plt.imshow(image)\n        col = 'green'\n        if preds[i] != labels[i]:\n            col = 'red'\n            \n        plt.xlabel(f'{class_names[int(labels[i].numpy())]}')\n        plt.ylabel(f'{class_names[int(preds[i].numpy())]}', color=col)\n    plt.tight_layout()\n    plt.show()","b1f77cf5":"images, labels = next(iter(dl_train))\nshow_images(images, labels, labels)","8233d295":"images, labels = next(iter(dl_test))\nshow_images(images, labels, labels)","94002ea9":"resnet18 = torchvision.models.resnet18(pretrained=False)\n#resnet18 = torchvision.models.resnet18(pretrained=True)\n\nprint(resnet18)","0c106e85":"resnet18.fc = torch.nn.Linear(in_features=512, out_features=3)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(resnet18.parameters(), lr=3e-5)","a623401b":"def show_preds():\n    resnet18.eval()\n    images, labels = next(iter(dl_test))\n    outputs = resnet18(images)\n    _, preds = torch.max(outputs, 1)\n    show_images(images, labels, preds)","bdc5f472":"show_preds()","bce2a2c0":"def train(epochs):\n    print('Starting training..')\n    for e in range(0, epochs):\n        print('='*20)\n        print(f'Starting epoch {e + 1}\/{epochs}')\n        print('='*20)\n\n        train_loss = 0.\n        val_loss = 0.\n\n        resnet18.train() # set model to training phase\n\n        for train_step, (images, labels) in enumerate(dl_train):\n            optimizer.zero_grad()\n            outputs = resnet18(images)\n            loss = loss_fn(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n            if train_step % 20 == 0:\n                print('Evaluating at step', train_step)\n\n                accuracy = 0\n\n                resnet18.eval() # set model to eval phase\n\n                for val_step, (images, labels) in enumerate(dl_test):\n                    outputs = resnet18(images)\n                    loss = loss_fn(outputs, labels)\n                    val_loss += loss.item()\n\n                    _, preds = torch.max(outputs, 1)\n                    accuracy += sum((preds == labels).numpy())\n\n                val_loss \/= (val_step + 1)\n                accuracy = accuracy\/len(test_dataset)\n                print(f'Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}')\n\n                show_preds()\n\n                resnet18.train()\n\n                if accuracy >= 0.95:\n                    print('Performance condition satisfied, stopping..')\n                    return\n\n        train_loss \/= (train_step + 1)\n\n        print(f'Training Loss: {train_loss:.4f}')\n    print('Training complete..')","1daa9d0d":"%%time\n\ntrain(epochs=1)","85d9621d":"show_preds()","e4252d95":"torch.save(resnet18.state_dict(), 'covid_classifier.pt')","7d844577":"# Load the model and set in eval\nresnet18 = torchvision.models.resnet18(pretrained=False)\n#resnet18 = torchvision.models.resnet18(pretrained=True)\nresnet18.fc = torch.nn.Linear(in_features=512, out_features=3)\n\nresnet18.load_state_dict(torch.load('covid_classifier.pt'))\nresnet18.eval()\n\n\ndef predict_image_class(image_path):\n    image = Image.open(image_path).convert('RGB')\n    image = test_transform(image)\n    # Please note that the transform is defined already in a previous code cell\n    image = image.unsqueeze(0)\n    output = resnet18(image)[0]\n    probabilities = torch.nn.Softmax(dim=0)(output)\n    probabilities = probabilities.cpu().detach().numpy()\n    predicted_class_index = np.argmax(probabilities)\n    predicted_class_name = class_names[predicted_class_index]\n    return probabilities, predicted_class_index, predicted_class_name","bf092af4":"#image_path = '\/path\/to\/image\/to\/test'\nimage_path = '{root_dir}\/test'\nprobabilities, predicted_class_index, predicted_class_name = predict_image_class(image_path)\nprint('Probabilities:', probabilities)\nprint('Predicted class index:', predicted_class_index)\nprint('Predicted class name:', predicted_class_name)","d12bc624":"# Inference on a Single Image","088c3b95":"# Creating Custom Dataset","31eaf83b":"# Preparing Training and Test Sets","c1108b38":"# Detecting COVID-19 with Chest X Ray using PyTorch\n\nImage classification of Chest X Rays in one of three classes: Normal, Viral Pneumonia, COVID-19\n\nNotebook created for the guided project [Detecting COVID-19 with Chest X Ray using PyTorch](https:\/\/www.coursera.org\/projects\/covid-19-detection-x-ray) on Coursera\n\nDataset from [COVID-19 Radiography Dataset](https:\/\/www.kaggle.com\/tawsifurrahman\/covid19-radiography-database) on Kaggle","e3e6447c":"# Image Transformations","a74a0837":"# Creating the Model","76a64872":"# Saving the Model","abc7086a":"# Final Results","9c585985":"# Importing Libraries","ab0ad70f":"# Prepare DataLoader","c3acaadc":"# Data Visualization","8e9c87cb":"# Training the Model"}}