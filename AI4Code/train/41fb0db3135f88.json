{"cell_type":{"4942ad17":"code","26601a52":"code","61bc3aa0":"code","d4d7c002":"code","99ee7df8":"code","846bf89f":"code","5da92a2c":"code","82c2f03f":"code","57698323":"code","861645bc":"code","11cefac2":"code","789b34a1":"code","9bf893b5":"code","f9949d73":"code","e19efae2":"code","4fa7071d":"code","a04fe170":"code","b660b87d":"code","504f9e4a":"code","625015b4":"code","2d763431":"code","ee9f0bff":"code","a6950b5f":"code","b69c9236":"markdown","0f75eb7b":"markdown","99451005":"markdown","82f1d1a4":"markdown","4645df20":"markdown"},"source":{"4942ad17":"import numpy as np\nimport pandas as pd \nfrom pathlib import Path\nimport os\nimport matplotlib.pyplot as plt\nfrom keras.layers import Conv2D,Dense,Dropout,Input,Flatten,MaxPooling2D\nfrom keras.models import Model\nfrom keras.utils import plot_model,to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing import image","26601a52":"from keras.preprocessing import image\np = Path('..\/input\/flowers-recognition\/flowers')\ndirs = p.glob('*')\nimage_data = []\nlabels = []\nlabel_dict = {'dandelion':0,'daisy':1,'flowers':2,'sunflower':3,'tulip':4,'rose':5}\nfor folder_dir in dirs:\n    label= str(folder_dir).split('\/')[-1]\n    cnt = 0\n    print(label)\n    for image_path in folder_dir.glob('*.jpg'):\n        img = image.load_img(image_path,target_size = (64,64))\n        img_array = image.img_to_array(img)\n        image_data.append(img_array)\n        labels.append(label_dict[label])\n    ","61bc3aa0":"print(len(image_data),len(labels))","d4d7c002":"x = np.array(image_data)\ny = np.array(labels)","99ee7df8":"x.shape","846bf89f":"y.shape","5da92a2c":"def draw_flower(img,label):\n    plt.imshow(img)\n    plt.title(label)","82c2f03f":"draw_flower(x[20]\/255.0,y[20])","57698323":"num_labels = len(np.unique(y))\n","861645bc":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.25)","11cefac2":"x_train.shape","789b34a1":"x_test.shape","9bf893b5":"image_size = x_train.shape[1]\nx_train = np.reshape(x_train,[-1,image_size,image_size,3])\nx_test = np.reshape(x_test,[-1,image_size,image_size,3])\nx_train = x_train\/255.0\nx_test = x_test\/255.0","f9949d73":"y_train = to_categorical(y_train)\n","e19efae2":"np.unique(y_test)","4fa7071d":"input_shape = (64,64,3)\ninputs = Input(shape = input_shape)\nx = inputs\nx = Conv2D(32,kernel_size = 2,activation = 'relu',strides = 1,padding = 'same')(x)\nx = MaxPooling2D(pool_size = (2,2))(x)\n\nx = Conv2D(64,kernel_size = 2,activation = 'relu',strides = 1,padding = 'same')(x)\nx = MaxPooling2D(pool_size = (2,2))(x)\n\n\nx = Conv2D(128,kernel_size = 2,activation = 'relu',strides = 1,padding = 'same')(x)\nx = Conv2D(256,kernel_size = 2,activation = 'relu',strides = 1,padding = 'same')(x)\nx = Dropout(0.25)(x)\nx = Flatten()(x)\noutputs = Dense(6,activation = 'softmax')(x)\nflower_classifier = Model(inputs,outputs)\n\nflower_classifier.summary()\nplot_model(flower_classifier)","a04fe170":"flower_classifier.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])","b660b87d":"y_train.shape","504f9e4a":"flower_classifier.fit(x_train,y_train,batch_size = 128,epochs = 30)\n","625015b4":"test_case = flower_classifier.predict(x_test)\ntest_case","2d763431":"y_test_pred = np.argmax(test_case,axis = 1)","ee9f0bff":"y_test_pred","a6950b5f":"for i in range(50):\n    print(\"actual\",y_test[i],\"predicted\",y_test_pred[i])","b69c9236":"# **Loading Images**","0f75eb7b":"# **Building a Convolutional Neural Network to Classify flowers**","99451005":"# Preprocessing","82f1d1a4":"# **Importing Required Libraries**","4645df20":"# Visualizing Images"}}