{"cell_type":{"6bb33334":"code","702cc367":"code","814fe35c":"code","ea97ef80":"code","b05e8f00":"code","ba22f53d":"code","13667009":"code","e92ddb45":"code","249469d9":"code","d55baf85":"code","a164fae2":"code","02678519":"code","bf8bb5f2":"code","9a63899d":"code","31f2afc6":"code","f16850e9":"code","f1f7dc1c":"code","0426956f":"code","6ab30b41":"code","9b40c09f":"code","83ee11a6":"code","a209b138":"code","dd58e1b4":"code","bc60bf6d":"code","0f6b780f":"code","84195774":"markdown","5c93e733":"markdown","ce8db765":"markdown","3b28c4dd":"markdown","03bb355d":"markdown","1b2f9268":"markdown","9e1b70b5":"markdown","9e336095":"markdown","505edf22":"markdown","efdeeb95":"markdown","5d9a2401":"markdown","c77afa1d":"markdown"},"source":{"6bb33334":"import numpy as np \nimport pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport tensorflow as tf\nfrom tensorflow.compat.v1 import ConfigProto\nfrom tensorflow.compat.v1 import InteractiveSession\n\n\nconfig = ConfigProto()\nconfig.gpu_options.allow_growth = True\nsession = InteractiveSession(config=config)","702cc367":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","814fe35c":"train_df = pd.read_csv(\"\/kaggle\/input\/heartbeat\/mitbih_train.csv\", header=None)\ntest_df = pd.read_csv(\"\/kaggle\/input\/heartbeat\/mitbih_test.csv\", header=None)\n\nprint(train_df.shape)\nprint(test_df.shape)","ea97ef80":"train_df.head()","b05e8f00":"test_df.head()","ba22f53d":"print(train_df[train_df.columns[-1]].unique())\nprint(train_df[test_df.columns[-1]].unique())","13667009":"train_x = np.array(train_df[train_df.columns[0:-1]], dtype=np.float32)\ntrain_y = np.array(train_df[train_df.columns[-1:]], dtype=np.float32)\n\ntest_x = np.array(train_df[test_df.columns[0:-1]], dtype=np.float32)\ntest_y = np.array(train_df[test_df.columns[-1:]], dtype=np.float32)\n\nprint(\"print train set is : x = {} y = {}\".format(train_x.shape, train_y.shape))\nprint(\"print test set is : x = {} y = {}\".format(test_x.shape, test_y.shape))","e92ddb45":"import matplotlib.pyplot as plt\n%matplotlib inline","249469d9":"fig = plt.figure(figsize=(20,5))\nax = fig.add_subplot(1,1,1)\nax.plot(train_x[0], color=\"r\")\nax.plot(train_x[1], color=\"g\")\nax.plot(train_x[2], color=\"b\")\nplt.show()","d55baf85":"# Return difference array\ndef return_diff_array_table(array, dur):\n  for idx in range(array.shape[1]-dur):\n    before_col = array[:,idx]\n    after_col = array[:,idx+dur]\n    new_col = ((after_col - before_col)+1)\/2\n    new_col = new_col.reshape(-1,1)\n    if idx == 0:\n      new_table = new_col\n    else :\n      new_table = np.concatenate((new_table, new_col), axis=1)\n#For concat add zero padding\n  padding_array = np.zeros(shape=(array.shape[0],dur))\n  new_table = np.concatenate((padding_array, new_table), axis=1)\n  return new_table\n#Concat\ndef return_merge_diff_table(df, diff_dur):\n  fin_table = df.reshape(-1,187,1,1)\n  for dur in diff_dur:\n    temp_table = return_diff_array_table(df, dur)\n    fin_table = np.concatenate((fin_table, temp_table.reshape(-1,187,1,1)), axis=2)\n  return fin_table\n\n#Use \"stratify\" option\nx_train, x_val, y_train, y_val = train_test_split(train_x, train_y, test_size=0.2, stratify=train_y)\n\n#Add Data\nx_train = return_merge_diff_table(df=x_train, diff_dur=[1])\nx_val = return_merge_diff_table(df=x_val, diff_dur=[1])\n\nprint(x_train.shape, y_train.shape, x_val.shape, y_val.shape)","a164fae2":"#For see a model's result\ndef return_result(model, x_train, x_test, y_train, y_test):\n    y_pred = model.predict(x_test)\n    train_pred = model.predict(x_train)\n    pred_list=[]\n    for x in y_pred:\n        pred_list.append(np.argmax(x))\n    train_pred_list=[]\n    for x in train_pred:\n        train_pred_list.append(np.argmax(x))\n    test_mat = confusion_matrix(y_test, pred_list)\n    train_mat = confusion_matrix(y_train, train_pred_list)\n    print(\"In train\")\n    print(accuracy_score(y_train, train_pred_list))\n    print(train_mat)\n    print(\"In test\")\n    print(accuracy_score(y_test, pred_list))\n    print(test_mat)","02678519":"def return_model1():\n    input_tens = tf.keras.Input(shape=(187,2,1))\n    x = tf.keras.layers.Conv2D(256, kernel_size=(10,2), strides=(5,1),padding='valid')(input_tens)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Conv2D(512, kernel_size=(5,1), padding='valid')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Conv2D(512, kernel_size=(5,1), padding='valid')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Conv2D(128, kernel_size=(5,1), padding='valid')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Conv2D(64, kernel_size=(5,1), padding='valid')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(5, activation=\"softmax\")(x)\n    model = tf.keras.Model(inputs=input_tens, outputs=x)\n    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n    print(model.summary())\n    return model","bf8bb5f2":"model1 = return_model1()","9a63899d":"#For saving best model\ncheckpoint_path_best = \".\/best_acc_v01.ckpt\"\ncp_callback_best = tf.keras.callbacks.ModelCheckpoint(checkpoint_path_best,monitor=\"val_accuracy\",save_weights_only=True,verbose=1,save_best_only=True)\n\nmodel1.fit(x_train,y_train, epochs=200, batch_size=128, validation_data=(x_val,y_val),callbacks=[cp_callback_best])","31f2afc6":"# Result is ========","f16850e9":"return_result(model1, x_train=x_train, x_test=x_val, y_train=y_train, y_test=y_val)","f1f7dc1c":"def return_model2():\n    input_tens = tf.keras.Input(shape=(187,2,1))\n    x = tf.keras.layers.Conv2D(256, kernel_size=(10,2), strides=(5,1),padding='valid')(input_tens)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Conv2D(512, kernel_size=(5,1), padding='valid')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Conv2D(512, kernel_size=(5,1), padding='valid')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Reshape((x.shape[1], x.shape[3]))(x)\n    x = tf.keras.layers.LSTM(64)(x)\n    x = tf.keras.layers.Dense(5, activation=\"softmax\")(x)\n    model = tf.keras.Model(inputs=input_tens, outputs=x)\n    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n    print(model.summary())\n    return model","0426956f":"model2 = return_model2()","6ab30b41":"#For saving best model\ncheckpoint_path_best2 = \".\/best_acc_v02.ckpt\"\ncp_callback_best2 = tf.keras.callbacks.ModelCheckpoint(checkpoint_path_best2, monitor=\"val_accuracy\", save_weights_only=True, verbose=1, save_best_only=True)\n\nmodel2.fit(x_train,y_train, epochs=200, batch_size=128, validation_data=(x_val,y_val), callbacks=[cp_callback_best2])","9b40c09f":"return_result(model2, x_train=x_train, x_test=x_val, y_train=y_train, y_test=y_val)","83ee11a6":"model1.load_weights(checkpoint_path_best)\nmodel2.load_weights(checkpoint_path_best2)\n\nreturn_result(model1, x_train=x_train, x_test=x_val, y_train=y_train, y_test=y_val)\nreturn_result(model2, x_train=x_train, x_test=x_val, y_train=y_train, y_test=y_val)\n\ntest_input = np.array(test_df[test_df.columns[0:-1]], dtype=np.float32)\ntest_target = np.array(test_df[test_df.columns[-1:]], dtype=np.float32)\n\ntest_input = return_merge_diff_table(df=test_input, diff_dur=[1])\n\nprint(test_input.shape, test_target.shape)","a209b138":"pred_1 = model1.predict(test_input)\npred_2 = model2.predict(test_input)","dd58e1b4":"pred_tot = (pred_1+pred_2)\/2\n\npred_idx_list=[]\nfor pred in pred_tot:\n    pred_idx_list.append(np.argmax(pred))\n    \npred_idx_arr = np.array(pred_idx_list, dtype=np.float32)","bc60bf6d":"print(accuracy_score(test_target, pred_idx_arr))\nprint(confusion_matrix(test_target, pred_idx_arr))","0f6b780f":"import seaborn as sns\n#From https:\/\/www.kaggle.com\/agungor2\/various-confusion-matrix-plots\ndef plot_cm(y_true, y_pred, figsize=(10,10)):\n    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n    cm_sum = np.sum(cm, axis=1, keepdims=True)\n    cm_perc = cm \/ cm_sum.astype(float) * 100\n    annot = np.empty_like(cm).astype(str)\n    nrows, ncols = cm.shape\n    for i in range(nrows):\n        for j in range(ncols):\n            c = cm[i, j]\n            p = cm_perc[i, j]\n            if i == j:\n                s = cm_sum[i]\n                annot[i, j] = '%.1f%%\\n%d\/%d' % (p, c, s)\n            elif c == 0:\n                annot[i, j] = ''\n            else:\n                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n    col = ['N','S','V','F','Q']\n    cm = pd.DataFrame(cm, index=col, columns=col)\n    cm.index.name = 'Actual'\n    cm.columns.name = 'Predicted'\n    fig, ax = plt.subplots(figsize=figsize)\n    sns.heatmap(cm, cmap= \"YlGnBu\", annot=annot, fmt='', ax=ax)\n    \nplot_cm(test_target, pred_idx_arr)","84195774":"# Make Model 2","5c93e733":"# Split data set","ce8db765":"# Loading Dataset","3b28c4dd":"In our dataset, last column has target index ['N': 0, 'S': 1, 'V': 2, 'F': 3, 'Q': 4]","03bb355d":"# Feature engineering?","1b2f9268":"# Check FIle Directory","9e1b70b5":"# Ensemble","9e336095":"# Make Model 1","505edf22":"# Printing result","efdeeb95":"### Calculate difference between t(unit time) with t+1\n\nWe usually analyze signal data using data's amplitude, frequency and shape of signal.\n\nNow, Let's use shape of graph as feature. So I assumed that difference between time interval(t and t+1 (t is unit time)) can be used.\n\n(x(t+1) - x(t)) \/ unit time -> means  gradient of graph.\n\nHow about we use this with value of specific time point?\n\nBecause graph can be drawed with value and gradient, we can assume that will be fitted to use.","5d9a2401":"Our data set looks like signal data(time series)","c77afa1d":"# Import lib"}}