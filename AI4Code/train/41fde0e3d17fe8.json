{"cell_type":{"7952da6f":"code","644a39b0":"code","8777ff70":"code","68160f5a":"code","88cfc505":"code","fd3c2918":"code","350d1117":"code","b66012ea":"code","65b09ca8":"code","af044379":"code","da9cb4a8":"code","bb55f187":"code","32595ee5":"code","0c319e4f":"code","d4e89ef6":"code","c97d5248":"code","b0b0c451":"code","7ad6f121":"code","ecf974be":"code","493ffeb7":"code","7d2e7544":"code","8d02bd73":"code","102cb825":"code","69080b6e":"code","bfa36011":"code","7b326870":"code","2138268b":"code","f885156d":"code","6b733b37":"code","bcf30592":"code","39899d1c":"code","2cacadff":"code","cc8db77a":"code","76e7f255":"code","5c465dbb":"code","b567af01":"code","5dec9b58":"code","dd862069":"code","2441283a":"code","6e802fb1":"code","67658866":"code","7ac4a761":"code","5128ac7d":"code","34addc09":"code","ba1284a9":"code","fa2f9e36":"code","5c2a4808":"code","4978d1e5":"code","af20dba1":"code","24d56f7d":"code","9209560f":"markdown","da96c10f":"markdown","a2208a2f":"markdown","19beea30":"markdown","16b3393f":"markdown","1983fab3":"markdown","19161e27":"markdown","e4a9e6ab":"markdown","214849c1":"markdown","e72af63e":"markdown","c54d8d40":"markdown","2ae42195":"markdown","1a9e2525":"markdown","4f927758":"markdown","37ea01bf":"markdown","bdefddd8":"markdown","da759845":"markdown","a3c1b15e":"markdown","2425eac1":"markdown","7b6eea98":"markdown","ced294f0":"markdown","bcd3541e":"markdown","33284cd1":"markdown","b78b647a":"markdown","53c486a1":"markdown","d37413d6":"markdown","bbc53ec0":"markdown","99726983":"markdown","adac8ab2":"markdown","83edf307":"markdown","bcdfccef":"markdown","f469b32c":"markdown","6a76e9ea":"markdown","0bceaebb":"markdown","5f417ee3":"markdown"},"source":{"7952da6f":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom scipy import stats\nfrom sklearn import preprocessing\nimport io","644a39b0":"df= pd.read_csv('..\/input\/house-prices-dataset\/train.csv')","8777ff70":"df.shape","68160f5a":"df.head()","88cfc505":"df.drop('Id',axis='columns',inplace= True)","fd3c2918":"df.info()","350d1117":"df.describe()","b66012ea":"df[df.columns[df.isnull().any()]].isnull().sum()","65b09ca8":"cols = ['Alley','MasVnrType','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','Electrical','FireplaceQu','GarageType','GarageYrBlt','GarageFinish','GarageQual','GarageCond','PoolQC','Fence','MiscFeature']\nmode= df.filter(cols).mode()","af044379":"df[cols]= df[cols].fillna(value= mode.iloc[0])","da9cb4a8":"num_cols= ['LotFrontage','MasVnrArea']\nmedian= df.filter(num_cols).median()","bb55f187":"df[num_cols]= df[num_cols].fillna(value= median.iloc[0])","32595ee5":"df[df.columns[df.isnull().any()]].isnull().sum()","0c319e4f":"numeric_data = df.select_dtypes(include=[np.number])\ncategorical_data = df.select_dtypes(exclude=[np.number])","d4e89ef6":"numeric_data.columns","c97d5248":"def box(variable):\n    plt.figure(figsize = (9,3))\n    plt.boxplot(numeric_data[variable])\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"{} distribution with hist\".format(variable))\n    plt.show()","b0b0c451":"numericVar = ['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n       'BsmtUnfSF', 'TotalBsmtSF', 'LowQualFinSF', 'GrLivArea', 'BsmtHalfBath',\n       'FullBath', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageArea',\n       'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n       'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SalePrice']\nfor n in numericVar:\n    box(n)","7ad6f121":"def outlier(col): \n    q1= numeric_data[col].quantile(0.25)\n    q3=numeric_data[col].quantile(0.75)\n    IQR= q3-q1\n    lower= q1-(IQR*1.5)\n    upper= q3+(IQR*1.5)\n    n= len(numeric_data.loc[np.where((numeric_data[col] > upper) | (numeric_data[col] < lower))])\n    perc= (n\/1460)*100\n    print(f'{col}= {perc}')\n        ","ecf974be":"for n in numericVar:  \n    outlier(n)","493ffeb7":"def his(variable):\n    plt.figure(figsize = (9,3))\n    plt.hist(numeric_data[variable],bins=50)\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"{} distribution with hist\".format(variable))\n    plt.show()","7d2e7544":"for n in numericVar:\n    his(n)","8d02bd73":"cor_num= numeric_data.corr()\ncor_num","102cb825":"sns.set_context(\"notebook\", font_scale=1.0, rc={\"lines.linewidth\": 2.5})\nplt.subplots(figsize=(30,30))\np = sns.heatmap(cor_num, annot=True, lw=1.5, fmt='.2f', cmap='seismic')\nrotxlabel = p.set_xticklabels(p.get_xticklabels(),fontdict={'fontsize':20}, rotation=90)\nrotylabel = p.set_yticklabels(p.get_yticklabels(),fontdict={'fontsize':20}, rotation=30)","69080b6e":"copy_num= numeric_data.copy()","bfa36011":"copy_num= copy_num.drop(columns= 'SalePrice')","7b326870":"copy_cor= copy_num.corr()","2138268b":"High_cor = (copy_cor.abs()).unstack()\nsorted_high_cor = High_cor.sort_values(kind=\"quicksort\")","f885156d":"sorted_high_cor[(sorted_high_cor>0.6) & (sorted_high_cor<1)]","6b733b37":"col_drop= ['HalfBath','2ndFlrSF','BsmtFullBath','BedroomAbvGr','GarageYrBlt','1stFlrSF','GarageCars']\nnumeric_data= numeric_data.drop(columns= col_drop)","bcf30592":"sns.set_context(\"notebook\", font_scale=1.0, rc={\"lines.linewidth\": 2.5})\nplt.subplots(figsize=(30,30))\np = sns.heatmap(numeric_data.corr(), annot=True, lw=1.5, fmt='.2f', cmap='seismic')\nrotxlabel = p.set_xticklabels(p.get_xticklabels(),fontdict={'fontsize':20}, rotation=90)\nrotylabel = p.set_yticklabels(p.get_yticklabels(),fontdict={'fontsize':20}, rotation=30)","39899d1c":"high_Cor_num = numeric_data[ numeric_data.corr().nlargest(10, 'SalePrice')['SalePrice'].index]","2cacadff":"sns.set_context(\"notebook\", font_scale=1.0, rc={\"lines.linewidth\": 2.5})\nplt.subplots(figsize=(30,30))\np = sns.heatmap(high_Cor_num.corr(), annot=True, lw=1.5, fmt='.2f', cmap='seismic')\nrotxlabel = p.set_xticklabels(p.get_xticklabels(),fontdict={'fontsize':20}, rotation=90)\nrotylabel = p.set_yticklabels(p.get_yticklabels(),fontdict={'fontsize':20}, rotation=30)","cc8db77a":"high_Cor_num.describe()","76e7f255":"sns.set_context(\"notebook\", font_scale=1.0, rc={\"lines.linewidth\": 2.5})\nplt.subplots(figsize=(20,10))\nsns.histplot(high_Cor_num.SalePrice)","5c465dbb":"np.sort(high_Cor_num.YearBuilt.unique())","b567af01":"high_Cor_num = high_Cor_num .apply(pd.to_numeric)","5dec9b58":"cat_year= high_Cor_num.copy()","dd862069":"cat_year['YearBuilt'] = list(map(lambda x : 1850 if x < 1900 else ( 1900 if x >= 1900 and x < 1950 else (1950 if x >= 1950 and x < 2000 else 2000)),cat_year['YearBuilt']))","2441283a":"sns.set_context(\"notebook\", font_scale=1.0, rc={\"lines.linewidth\": 2.5})\nplt.subplots(figsize=(20,10))\nsns.lineplot(data= cat_year,x= 'OverallQual', y='SalePrice',hue= 'YearBuilt',palette='Set1' )","6e802fb1":"sns.set_context(\"notebook\", font_scale=1.0, rc={\"lines.linewidth\": 2.5})\nplt.subplots(figsize=(15,10))\nsns.scatterplot(data= cat_year,x= 'GrLivArea', y='SalePrice',hue= 'OverallQual' )","67658866":"plt.subplots(figsize=(15,10))\nsns.scatterplot(data= cat_year,x= 'GrLivArea', y='SalePrice',hue= 'YearBuilt' )","7ac4a761":"num_new = high_Cor_num .loc[(high_Cor_num['YearBuilt']>1850) & (high_Cor_num['YearBuilt']< 1900)&(high_Cor_num['OverallQual']>=6)&(high_Cor_num['OverallQual']<=8)]","5128ac7d":"def line(var):\n    plt.subplots(figsize=(15,10))\n    sns.barplot(data= num_new,x= var, y= 'SalePrice',hue='OverallQual',palette='Set1' )","34addc09":"numericVar = ['GrLivArea', 'GarageArea', 'TotalBsmtSF',\n       'FullBath', 'TotRmsAbvGrd', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea']\nfor n in numericVar:\n    line(n)","ba1284a9":"categorical_data.info()","fa2f9e36":"categorical_data.columns","5c2a4808":"def bar_plot(variable):\n      \n    # get feature \n    var = categorical_data[variable]\n    # count number of feature \n    varValue = var.value_counts()\n    \n    # visualize\n    plt.figure(figsize=(9,3))\n    plt.bar(varValue.index,varValue)\n    plt.xticks(varValue.index,varValue.index.values)\n    plt.ylabel(\"Frequency\")\n    plt.title(variable)\n    plt.show()\n    print(\"{}:\\n{}\".format(variable,varValue))","4978d1e5":"category1 = categorical_data.columns\nfor c in category1:\n    bar_plot(c)","af20dba1":"def tar(var):\n    plt.subplots(figsize=(15,5))\n    sns.barplot(x= categorical_data[var], y= numeric_data['SalePrice'])\n    ","24d56f7d":"category = categorical_data.columns\nfor c in category:\n    tar(c)","9209560f":"# Numerical feature Analysis\n","da96c10f":"### Observation:\n- features with >0.6 correaltion among each other and having low or same correlation with the target feature can be dropped for the dataset as it would not have any significant affect on the target feature even after removal","a2208a2f":"### Observations:\n - maximum of the housed have living area within the range of 1000 to 2000 sq ft.\n - the size of the living area along with over all quality of the house seems to be directly proportional to Saleprice\n ","19beea30":"### Analysis of  numerical columns using histogram","16b3393f":"#### count of null values in each column","1983fab3":"#### Now lets do the same for numerical features with median","19161e27":"## 2) Analysis of the Target feature with respect to the highly correlated feature OverallQual with reference to YearBuilt","e4a9e6ab":"### As per the above heat map it can be concluded that not all features are strongly correlated to our target feature that is SalePrice and dropping the low correlation features will not make any major impact on our Aanalysis. Now, we just select the features with high corr to our target feature i.e. SalePrice\u00b6","214849c1":"####  lets fill the nulls for Categorical features with mode:","e72af63e":"### Conclusion drawn on basis on 6 point summary and histogram:\n- Right skewed graph obtained\n- The maximum and minimum prizes of the houses are 755000 and 34900 repectively\n- The average price is 180921\n- The price of maximum of the houses lie in the range of 13M to 21.4 M approximately\n- Very less number of houses have higher end Sale price\n","c54d8d40":"## Categorizing data set into Categorial features and Numerical features","2ae42195":"### Observations:\n\nHouses built in the year of 1872 and remodelled between 1987-1990 with 2 Bathrooms seems to be have a lesser SalePrice compared to other houses. ","1a9e2525":"### Removing features with high inter correlation","4f927758":"## Percentage of Outliers in each column","37ea01bf":"### For better visualization lets using heatmap","bdefddd8":"### Conclusions drawn:\n- 1850s: range from quality 4 to 10 with price spiking at quality 10 but a depression can be noticed in price at quality 8 and a spike at quality 6, which i think can be analyzed more.\n- 1900s: an increase price can be noticed woth increase in quality in houses\n- 1950s: a stable increase in price with quality till quality 9 and then a sudden spike makes houses with quality 10 in this year range the most expensive set of housing in the dataset with a price of 700k approx.\n- 2000s: the price gradually rises along with the quality and then at quality 9 and 10 houses the price range tends to become stangnant.\n- Thus we can conclude that except for houses that were built in 1950s any other 7+ quality house can be availed within a 400k-200k price range ","da759845":"### Visualization of outliers using Boxplot :","a3c1b15e":"### Individual Feature","2425eac1":"### Droping the id column as its not needed","7b6eea98":"### Observations:\n- the houses that were made between 1950-2000 seems to be have directly proportional relationship between the living area and   the Saleprice.\n- however for the rest of max of the houses built in other year ranges the living area is limited to under 3000 sq ft range. ","ced294f0":"### Heat map representation of the correlation with target feature after dimensional reducation ","bcd3541e":"## **Outlier Analysis**","33284cd1":"## Visualization of the categorical feature individually and vs the Target Feature","b78b647a":"## CATEGORICAL FEATURE ANALYSIS","53c486a1":"### Observing Correlation","d37413d6":"lets make a copy of the datframe so that we can remove the target feature and then work on dimentional rediction","bbc53ec0":"### Price range depression in the 1850s: Analysis","99726983":"## Dimentional Reduction of Numerical data","adac8ab2":"#### Handling of the null values by using Central tendency methods: Mode for categorical features and Median for Numerical features (we are not choosing Mean over Median is because mean is influenced by outliers thus. might change the pattern of the features from its original drasctically\n\n","83edf307":"### Categorial Features vs Target Feature","bcdfccef":"## 1) Analysis of the behaviour of our target feature by using a histogram","f469b32c":"##### now lets check again the number of null values to varify that our logic worked or not","6a76e9ea":"### Categorized the years for better visualization: below 1900 as 1850 as the min year is 1872 then an increment of 50 years i.e. 1900 1950 2000 ","0bceaebb":"## Using info() and describe() to understand the dataset better","5f417ee3":"# Now we can further analyze how are the outstanding features influencing the target feature:"}}