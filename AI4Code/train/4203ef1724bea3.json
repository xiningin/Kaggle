{"cell_type":{"3922b07d":"code","ee04f6d7":"code","810dd813":"code","01e33d50":"code","109a1ad1":"code","79d57a93":"code","569ac263":"code","15b697ae":"code","674afd59":"code","fc037c57":"code","5cc54856":"code","eff6ea6b":"code","d41b6ac4":"code","b1381cd5":"code","d113207a":"code","43d19e32":"code","a4a9a240":"code","12158e68":"code","4c679cb1":"code","1cd69cc9":"code","df07a390":"code","9d463f51":"code","9a8bf505":"code","6a6e551c":"code","79b62c4e":"code","8ecb9982":"code","b1eb3741":"code","6af90073":"code","9350b249":"code","68676e39":"code","488b6167":"code","a6302122":"code","a0bb6927":"code","9fa62569":"code","0db797ca":"code","fb7eafa2":"code","1ca4a217":"code","fe975bd2":"code","134058ef":"code","0c5c41a8":"code","f9cfb0c7":"code","e2c52501":"code","c63a84c4":"code","1c24ab2a":"code","ce2ac0ca":"code","7674652a":"code","965408c7":"code","bffa7c61":"code","8f7f6430":"code","fefdd16f":"code","df2242ea":"code","fd5f3398":"code","a2503e98":"code","fce07539":"code","70b8e5fa":"code","e77b0272":"markdown","3e491b5f":"markdown","f8ebada1":"markdown","daaf0809":"markdown","61a79296":"markdown","9a7fb443":"markdown","a3702fe5":"markdown","cca96899":"markdown","a1d5dff1":"markdown","e95e2419":"markdown","b546c792":"markdown","b1645afc":"markdown","42955103":"markdown","77c02371":"markdown","7435a66d":"markdown","1c0296eb":"markdown","49f1d7bd":"markdown","701739f9":"markdown","038fd073":"markdown","9aaa7384":"markdown","67a82ebc":"markdown","b8bfa6a2":"markdown","a011b55a":"markdown","8de72d95":"markdown","607344e7":"markdown","57a0ef27":"markdown","eb43509d":"markdown","83e22c3f":"markdown","6a6365f2":"markdown","78a4ad24":"markdown","45d532d6":"markdown","1c38dcdc":"markdown","56cb0f4b":"markdown","1fd029ce":"markdown","34a48405":"markdown","9cd271ca":"markdown","5b45baa4":"markdown","32739e89":"markdown","65c55d1d":"markdown","2b436f29":"markdown","f2fca245":"markdown","0ea9517f":"markdown","3a7d2050":"markdown","5cf91605":"markdown"},"source":{"3922b07d":"import numpy as np \nimport pandas as pd \n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nprint(os.listdir(\"..\/input\"))","ee04f6d7":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")","810dd813":"train['type_set'] = 'train'\ntest['type_set'] = 'test'\nsets = pd.concat([train,test],sort=False)\nprint('train.shape:', train.shape)\nprint('test.shape:', test.shape)\nprint('sets.shape:', sets.shape)\nsets.head()","01e33d50":"sets.info()","109a1ad1":"sets[sets.Embarked.isnull()==True]","79d57a93":"sets.Embarked.value_counts()","569ac263":"sets.Embarked.fillna('S', inplace = True)\nsets[sets.Embarked.isnull()==True]","15b697ae":"sets[sets.Fare.isnull()==True]","674afd59":"sets[sets.Pclass == 3].mean()['Fare']","fc037c57":"sets.Fare.fillna(13.30, inplace = True)","5cc54856":"sets.Cabin.fillna('N', inplace = True)\nsets.Cabin.unique()","eff6ea6b":"sets['Cabin_type'] = [i[0] for i in sets.Cabin]\nsets.Cabin_type.unique()","d41b6ac4":"a_table = sets[['Survived','Cabin_type']].groupby(['Cabin_type']).agg(['mean', 'count'])\na_table.columns = a_table.columns.droplevel(0)\na_table.sort_values(['mean'], ascending=False)","b1381cd5":"def feature(f):\n    if f == 'N': return 0\n    else: return 1\nsets['Has_cabin'] = sets['Cabin_type'].apply(lambda x: feature(x))\n\na_table = sets[['Survived','Has_cabin']].groupby(['Has_cabin']).agg(['mean', 'count'])\na_table.columns = a_table.columns.droplevel(0)\na_table.sort_values(['mean'], ascending=False)","d113207a":"def feature(f):\n    if f < 8: return 'infant'\n    #if f < 18: return 'child'\n    if f < 24: return 'young'\n    #if f < 45: return 'Adult'\n    if f < 60: return 'senior'\n    if f >= 60: return 'old'    \n\nsets['Age_group'] = sets['Age'].apply(lambda x: feature(x))\n\na_table = sets[['Survived','Age_group']].groupby(['Age_group']).agg(['mean', 'count'])\na_table.columns = a_table.columns.droplevel(0)\na_table.sort_values(['mean'], ascending=False)","43d19e32":"sets[\"title\"] = [i.split('.')[0] for i in sets.Name]\nsets[\"title\"] = [i.split(', ')[1] for i in sets.title]","a4a9a240":"sets[\"title\"].value_counts()","12158e68":"av_age = sets[['title','Age']].groupby(['title']).agg(['mean', 'count'])\nav_age.columns = av_age.columns.droplevel(0)\nav_age.reset_index(inplace = True)\nav_age.sort_values(['count'], ascending=False)","4c679cb1":"nul_age = sets[(sets.Age.isnull()==True)]\n\na_table = nul_age[['title','PassengerId']].groupby(['title']).agg(['count'])\na_table.columns = a_table.columns.droplevel(0)\na_table.reset_index(inplace = True)\na_table.sort_values(['count'], ascending=False)","1cd69cc9":"for i in list(a_table.title.unique()):\n    m1 = (sets['title'] == i) & (sets['Age'].isnull()==True)\n    sets.loc[m1,'Age'] = sets.loc[m1,'Age'].fillna(round(av_age[av_age.title == i]['mean'].iloc[0]))","df07a390":"sets['Age_group'] = sets['Age'].apply(lambda x: feature(x))","9d463f51":"sets.info()","9a8bf505":"a_table = sets[['Survived','Pclass']].groupby(['Pclass']).agg(['mean', 'count'])\na_table.columns = a_table.columns.droplevel(0)\na_table.sort_values(['mean'], ascending=False)","6a6e551c":"sets['len_name'] = [len(i) for i in sets.Name]\n\ndef feature(x):\n    if (x < 20): return 'short'\n    if (x < 27): return 'medium'\n    if (x < 32): return 'good'\n    else: return 'long'\n\nsets['len_name_g'] = sets['len_name'].apply(lambda x: feature(x))\n\n\na_table = sets[['Survived','len_name_g']].groupby(['len_name_g']).agg(['mean', 'count'])\na_table.columns = a_table.columns.droplevel(0)\na_table.sort_values(['mean'], ascending=False)","79b62c4e":"a_table = sets[['Survived','Sex']].groupby(['Sex']).agg(['mean', 'count'])\na_table.columns = a_table.columns.droplevel(0)\na_table.sort_values(['mean'], ascending=False)","8ecb9982":"a_table = sets[['Survived','SibSp']].groupby(['SibSp']).agg(['mean', 'count'])\na_table.columns = a_table.columns.droplevel(0)\na_table.sort_values(['mean'], ascending=False)","b1eb3741":"def feature(x):\n    if (x < 1): return '0'\n    if (x < 2): return '1'\n    #if (x < 32): return '1+'\n    else: return '1+'\n\nsets['SibSp_g'] = sets['SibSp'].apply(lambda x: feature(x))\n\na_table = sets[['Survived','SibSp_g']].groupby(['SibSp_g']).agg(['mean', 'count'])\na_table.columns = a_table.columns.droplevel(0)\na_table.sort_values(['mean'], ascending=False)","6af90073":"a_table = sets[['Survived','Parch']].groupby(['Parch']).agg(['mean', 'count'])\na_table.columns = a_table.columns.droplevel(0)\na_table.sort_values(['mean'], ascending=False)","9350b249":"def feature(x):\n    if (x < 1): return '0'\n    else: return '1+'\n\nsets['Parch_g'] = sets['Parch'].apply(lambda x: feature(x))\n\na_table = sets[['Survived','Parch_g']].groupby(['Parch_g']).agg(['mean', 'count'])\na_table.columns = a_table.columns.droplevel(0)\na_table.sort_values(['mean'], ascending=False)","68676e39":"#sets.Ticket.unique()","488b6167":"sets['len_Ticket'] = [len(i) for i in sets.Ticket]\n\na_table = sets[['Survived','len_Ticket']].groupby(['len_Ticket']).agg(['mean', 'count'])\na_table.columns = a_table.columns.droplevel(0)\na_table.sort_values(['len_Ticket'], ascending=False)","a6302122":"def feature(x):\n    if (x == 5 or x == 5): return '5and8'\n    else: return 'other'\n\nsets['len_Ticket_g'] = sets['len_Ticket'].apply(lambda x: feature(x))\n\n\na_table = sets[['Survived','len_Ticket_g']].groupby(['len_Ticket_g']).agg(['mean', 'count'])\na_table.columns = a_table.columns.droplevel(0)\na_table.sort_values(['mean'], ascending=False)","a0bb6927":"sets['Ticket_type'] = [i.split()[0] for i in sets.Ticket]\nsets['Ticket_type'].value_counts()\n\na_table = sets[['Survived','Ticket_type']].groupby(['Ticket_type']).agg(['mean', 'count'])\na_table.columns = a_table.columns.droplevel(0)\na_table.sort_values(['count'], ascending=False).head(10)","9fa62569":"def feature(x):\n    if (x == 'PC'): return 'PC'\n    else: return 'other'\n\nsets['Ticket_type_g'] = sets['Ticket_type'].apply(lambda x: feature(x))\n\n\na_table = sets[['Survived','Ticket_type_g']].groupby(['Ticket_type_g']).agg(['mean', 'count'])\na_table.columns = a_table.columns.droplevel(0)\na_table.sort_values(['mean'], ascending=False)","0db797ca":"def feature(x):\n    if (x < 10): return 'under10'\n    if (x < 50): return '10-50'\n    else: return '50+'\n\nsets['Fare_g'] = sets['Fare'].apply(lambda x: feature(x))\n\n\na_table = sets[['Survived','Fare_g']].groupby(['Fare_g']).agg(['mean', 'count'])\na_table.columns = a_table.columns.droplevel(0)\na_table.sort_values(['mean'], ascending=False)","fb7eafa2":"a_table = sets[['Survived','Embarked']].groupby(['Embarked']).agg(['mean', 'count'])\na_table.columns = a_table.columns.droplevel(0)\na_table.sort_values(['mean'], ascending=False)","1ca4a217":"list(sets)","fe975bd2":"train_set = sets[sets.type_set == 'train']\ntrain_set.drop(['PassengerId','Name','Age','SibSp', 'Parch','Ticket', 'Fare', 'Cabin','type_set','Cabin_type',\n               'title','len_name','len_Ticket','Ticket_type', ], axis=1, inplace=True)\nprint(train_set.shape)\ntrain_set.head() ","134058ef":"list(train_set)","0c5c41a8":"train_set = pd.get_dummies(train_set, columns=[ 'Pclass',\n 'Sex',\n 'Embarked',\n 'Has_cabin',\n 'Age_group',\n 'len_name_g',\n 'SibSp_g',\n 'Parch_g',\n 'len_Ticket_g',\n 'Ticket_type_g',\n 'Fare_g'], drop_first=True)","f9cfb0c7":"train_set.head()","e2c52501":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import mean_absolute_error, accuracy_score\nfrom sklearn.model_selection import train_test_split\n\ny = train_set[\"Survived\"]\nX = train_set.drop(['Survived'], axis = 1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.3, random_state=0)","c63a84c4":"logreg = LogisticRegression()\n\n# fit the model with \"train_x\" and \"train_y\"\nlogreg.fit(X_train,y_train)\n\ny_pred = logreg.predict(X_test)\n\nround(accuracy_score(y_pred, y_test),4)","1c24ab2a":"test_set = sets[sets.type_set == 'test']\ntest_set.drop(['Survived','PassengerId','Name','Age','SibSp', 'Parch','Ticket', 'Fare', 'Cabin','type_set','Cabin_type',\n               'title','len_name','len_Ticket','Ticket_type', ], axis=1, inplace=True)\ntest_set = pd.get_dummies(test_set, columns=[ 'Pclass',\n 'Sex',\n 'Embarked',\n 'Has_cabin',\n 'Age_group',\n 'len_name_g',\n 'SibSp_g',\n 'Parch_g',\n 'len_Ticket_g',\n 'Ticket_type_g',\n 'Fare_g'], drop_first=True)","ce2ac0ca":"logreg.fit(X,y)\n\n#predict test set\nset_pred = logreg.predict_proba(test_set)[:, 1]","7674652a":"submission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived':set_pred})\nsubmission.to_csv('submission.csv')","965408c7":"sets_W_I = sets.loc[(sets.Sex == 'female') | (sets.Age_group == 'infant')]\nsets_Otr = sets.loc[(sets.Sex != 'female') & (sets.Age_group != 'infant')]","bffa7c61":"sets_W_I[\"Survived\"].mean()","8f7f6430":"sets_Otr[\"Survived\"].mean()","fefdd16f":"#sets_W_I\ntrain_set_W_I = sets_W_I[sets_W_I.type_set == 'train']\ntrain_set_W_I.drop(['PassengerId','Name','Age','SibSp', 'Parch','Ticket', 'Fare', 'Cabin','type_set','Cabin_type',\n               'title','len_name','len_Ticket','Ticket_type', ], axis=1, inplace=True)\n\ntrain_set_W_I = pd.get_dummies(train_set_W_I, columns=[ 'Pclass',\n 'Sex',\n 'Embarked',\n 'Has_cabin',\n 'Age_group',\n 'len_name_g',\n 'SibSp_g',\n 'Parch_g',\n 'len_Ticket_g',\n 'Ticket_type_g',\n 'Fare_g'], drop_first=True)\n\ny = train_set_W_I[\"Survived\"]\nX = train_set_W_I.drop(['Survived'], axis = 1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.3, random_state=0)\n\nlogreg_W_I = LogisticRegression()\n\n# fit the model with \"train_x\" and \"train_y\"\nlogreg_W_I.fit(X_train,y_train)\n\ny_pred = logreg_W_I.predict(X_test)\n\nround(accuracy_score(y_pred, y_test),4)","df2242ea":"logreg_W_I.fit(X,y)","fd5f3398":"#sets_Otr\ntrain_set_Otr = sets_Otr[sets_Otr.type_set == 'train']\ntrain_set_Otr.drop(['PassengerId','Name','Age','SibSp', 'Parch','Ticket', 'Fare', 'Cabin','type_set','Cabin_type',\n               'title','len_name','len_Ticket','Ticket_type', ], axis=1, inplace=True)\n\ntrain_set_Otr = pd.get_dummies(train_set_Otr, columns=[ 'Pclass',\n 'Sex',\n 'Embarked',\n 'Has_cabin',\n 'Age_group',\n 'len_name_g',\n 'SibSp_g',\n 'Parch_g',\n 'len_Ticket_g',\n 'Ticket_type_g',\n 'Fare_g'], drop_first=True)\n\ny = train_set_Otr[\"Survived\"]\nX = train_set_Otr.drop(['Survived'], axis = 1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.3, random_state=0)\n\nlogreg_Otr = LogisticRegression()\n\n# fit the model with \"train_x\" and \"train_y\"\nlogreg_Otr.fit(X_train,y_train)\n\ny_pred = logreg_Otr.predict(X_test)\n\nround(accuracy_score(y_pred, y_test),4)","a2503e98":"logreg_Otr.fit(X,y)","fce07539":"#sets_W_I\ntest_set_W_I = sets_W_I[sets_W_I.type_set == 'test']\ntest_set_W_I.drop(['Survived','PassengerId','Name','Age','SibSp', 'Parch','Ticket', 'Fare', 'Cabin','type_set','Cabin_type',\n               'title','len_name','len_Ticket','Ticket_type', ], axis=1, inplace=True)\ntest_set_W_I = pd.get_dummies(test_set_W_I, columns=[ 'Pclass',\n 'Sex',\n 'Embarked',\n 'Has_cabin',\n 'Age_group',\n 'len_name_g',\n 'SibSp_g',\n 'Parch_g',\n 'len_Ticket_g',\n 'Ticket_type_g',\n 'Fare_g'], drop_first=True)\n\n#sets_Otr\ntest_set_Otr = sets_Otr[sets_Otr.type_set == 'test']\ntest_set_Otr.drop(['Survived','PassengerId','Name','Age','SibSp', 'Parch','Ticket', 'Fare', 'Cabin','type_set','Cabin_type',\n               'title','len_name','len_Ticket','Ticket_type', ], axis=1, inplace=True)\ntest_set_Otr = pd.get_dummies(test_set_Otr, columns=[ 'Pclass',\n 'Sex',\n 'Embarked',\n 'Has_cabin',\n 'Age_group',\n 'len_name_g',\n 'SibSp_g',\n 'Parch_g',\n 'len_Ticket_g',\n 'Ticket_type_g',\n 'Fare_g'], drop_first=True)\n\n\n#predict test sets\nset_pred_W_I = logreg_W_I.predict_proba(test_set_W_I)[:, 1]\nset_pred_Otr = logreg_Otr.predict_proba(test_set_Otr)[:, 1]","70b8e5fa":"submission_W_I = pd.DataFrame({'PassengerId': sets_W_I[sets_W_I.type_set == 'test']['PassengerId'], 'Survived':set_pred_W_I})\nsubmission_Otr = pd.DataFrame({'PassengerId': sets_Otr[sets_Otr.type_set == 'test']['PassengerId'], 'Survived':set_pred_Otr})\n\nsubmission_2models = pd.concat([submission_W_I, submission_Otr], ignore_index=True)\n\nsubmission_2models.to_csv('submission_2models.csv')","e77b0272":"**OK, Age is vary impotent, we need to fill it careful.\nLet's see names of passengers\nGet the title from the name**","3e491b5f":"**Sex is too strong feature.\nMaybe better separate all data on two sets female and infant and others**\n\n**SibSp**","f8ebada1":"**OK, all voids filled. let's see other feature**","daaf0809":"**refit model on all train set**","61a79296":"**let's see average age**","9a7fb443":"**this model give us 0.78468 score and 4129 place from 11185 (top 37%).**\n![image.png](attachment:image.png)","a3702fe5":"**Do the same on test set:**","cca96899":"**lets see how many empty Age values groupping by title**","a1d5dff1":"**fill a empty Age values average Age in group**","e95e2419":"**last feature with missing  value is age.\nLet's see depends age and Survived.\ngroup first**","b546c792":"**let's see surviving**","b1645afc":"**Ticket**","42955103":"**there're voids in Age and Cabin and 1 in Fare. we need to fill it**","77c02371":"**refit model on all train set**","7435a66d":"**very interesting depending fron len Name**\n\n**Sex**","1c0296eb":"**separate type cabin from number**","49f1d7bd":"**let's set the most frequent value**","701739f9":"**so, withuot cabin average surviving lower.\nMake new feature Has_cabin**","038fd073":"**load data**","9aaa7384":"**Pclass very paverfull feature.**\n\n**We can't group Name, maybe len of Name have value**","67a82ebc":"**Fare. grouppin first**","b8bfa6a2":"**Embarked**","a011b55a":"**to build model we try use groupping feature:**","8de72d95":"**set this value**","607344e7":"**refit model on all train set**","57a0ef27":"**Parch**","eb43509d":"**good enough. let's group it**","83e22c3f":"**let's separate sets on women and children and all others**","6a6365f2":"**save result**","78a4ad24":"**good enough. let's group it**","45d532d6":"**I dont like this groupping, its can be selection and our model will overfit**","1c38dcdc":"**preditc test sets and save results**","56cb0f4b":"**maybe try len**","1fd029ce":"**Embarked no so good.\nThat is all. Lets see what feature we generate**","34a48405":"**we have a lot missing value in Cabin.\nMaybe passengers didn't have cabin.\nlet's see surviving, but first fill null with 'N'**","9cd271ca":"**it seems len = 5 and 8 is better **","5b45baa4":"**if Ticket_type is PC it is mach better**","32739e89":"**build 2 model for this set**","65c55d1d":"**let's see average fare in 3 Pclass**","2b436f29":"**rewright Age_group feature**","f2fca245":"**join sets**","0ea9517f":"**load modules**","3a7d2050":"the result is not better ![image.png](attachment:image.png)\nand this with more then 0.70 probability","5cf91605":"**make dummies**"}}