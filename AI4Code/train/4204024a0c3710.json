{"cell_type":{"742cc011":"code","75036497":"code","615d8f0b":"code","ecfdac89":"code","b0cb7c77":"code","61ca93f2":"code","5ebf4a0a":"code","f5d62526":"code","9f5ecd8a":"code","033f9d3e":"code","a95f5aea":"code","15ef8f9f":"code","415a85ac":"code","dd0a096c":"code","0914769e":"code","51708c19":"code","e49dc997":"code","8e9cba18":"code","cc73d8a7":"code","9b3985b9":"code","c43b6526":"code","ea4afd53":"code","671796a4":"code","55aea9b7":"code","2bb3a667":"code","75f0d3bc":"code","0428320c":"code","cd41ce82":"code","9765a2e2":"code","da3a3d95":"code","4951d3f8":"code","7d940bed":"code","4c23c380":"code","b7d9161f":"code","ec96c07e":"code","0f18bf79":"code","a058fb08":"code","d27b3532":"code","1f99b697":"code","1a6d101b":"code","421d6a8b":"code","b5416478":"code","cfc95ec9":"code","4698afed":"code","96c0286c":"code","db4aacc5":"code","02e076ba":"code","422b3604":"code","615979e7":"code","df4e5b8a":"code","c185430a":"code","bfa311dc":"code","c787b769":"code","d2bd4db6":"code","89124852":"code","7c12215b":"code","df958a9e":"code","ed0123ed":"code","473f7ad0":"code","6421f3df":"code","545aca1d":"code","d42032c6":"code","7c999208":"code","8e63ef73":"code","bf0973b1":"code","410ad598":"code","2393fdb7":"code","831dc604":"code","ed1363bb":"code","afb821b9":"code","8f9e0314":"code","dd6a0cad":"code","1e3dbf12":"code","0fdc9c80":"code","8a1a0a7e":"code","6ae767eb":"code","a722b91c":"code","fc0a1c47":"code","75d71cee":"code","32d53301":"code","de967bb0":"code","a01b53d4":"code","2ff1a301":"code","71368512":"code","d70f588d":"code","d69a7cc7":"code","84897288":"code","e773a572":"code","fbdc4912":"code","37f5b9c6":"code","a99d48ca":"code","cb90fd2a":"code","5e797e38":"code","834048b9":"code","f1950ad2":"code","025fb211":"code","d82f353f":"code","1b592da3":"code","877a2e31":"code","1c633120":"code","379a66c2":"code","dc65ee4a":"code","5491ccc6":"code","ad20cd2d":"code","8bccb1e5":"code","9ab25356":"code","c48c69c1":"code","c18d31b4":"code","1a09627d":"code","70d686c2":"code","85cf614a":"code","a0b29b67":"code","9900e46d":"code","919f4584":"code","3c231545":"code","1a20e929":"code","7de681b1":"code","d9c657f8":"code","cecd6939":"code","2be5577d":"code","fb3dab9c":"code","fe4bc411":"code","f90ec1f9":"code","567cea16":"code","5e8c0c48":"code","bda1c0cd":"code","2afdede1":"code","10d2b4ef":"code","bc973f39":"code","9857266d":"code","3992a3da":"code","c25d1f2f":"code","6dff56ad":"code","4be5afd2":"code","363a72d0":"code","87cb6adb":"markdown","0c301e4e":"markdown","baa72850":"markdown","78061fc0":"markdown","1660c619":"markdown","17970a76":"markdown","28dc4c39":"markdown","4b21a5b8":"markdown","1789c101":"markdown","bb5267bb":"markdown","8ca99ae4":"markdown","2ff2e8c9":"markdown","684e5dee":"markdown","aa25b39f":"markdown","62de22b4":"markdown","379e3742":"markdown","d6e32fe0":"markdown","f1c47c7b":"markdown","e49bd778":"markdown","da48dd95":"markdown","20160700":"markdown","4de06037":"markdown","ac70b7b6":"markdown","ab6d44f2":"markdown","595ba866":"markdown","93a8f4b6":"markdown","220887bd":"markdown","96621f47":"markdown","34ce505b":"markdown","1065b18c":"markdown","cfb3656c":"markdown","8bd2ef06":"markdown","e6b5fe4a":"markdown","ca1ff777":"markdown","015faf53":"markdown","4ec280cc":"markdown","721f0206":"markdown","7bb74093":"markdown","3cce99d2":"markdown","f08d1f2c":"markdown","fa4ddbb4":"markdown","a36c3fa3":"markdown","020e3324":"markdown","d00f65fd":"markdown","d31ef601":"markdown","ad85bcb9":"markdown","37f7bcd1":"markdown","17a79c38":"markdown","b1e77f83":"markdown","5729860d":"markdown","3192c0da":"markdown","07fc0d23":"markdown","2d029beb":"markdown","b444ee66":"markdown","a06f3562":"markdown","e6e613e0":"markdown","6671a328":"markdown","35e7ef83":"markdown","16fbbc91":"markdown","3cb36cd6":"markdown","9462e411":"markdown","eb418c1d":"markdown","2a5d7a1f":"markdown","38d3161a":"markdown","b30902b9":"markdown","87f06390":"markdown","ed39f9b9":"markdown","c2d29879":"markdown","8ecbeee4":"markdown","892bc1c8":"markdown","308f261e":"markdown","36ec5d58":"markdown","02632ac3":"markdown","6f2d23b7":"markdown","4bdf755b":"markdown","05686279":"markdown","053b2ead":"markdown","04fc0b96":"markdown","a379be22":"markdown","a2815630":"markdown","72525829":"markdown","4a95556b":"markdown","55698f75":"markdown","4779763a":"markdown","c93d02a4":"markdown","ce047ec0":"markdown","36a2a780":"markdown","0b0f9222":"markdown","c222510d":"markdown","1c46baeb":"markdown","4897be80":"markdown","b26b4778":"markdown","6b98fb09":"markdown","ab97edfc":"markdown","b3a97239":"markdown","525bb900":"markdown"},"source":{"742cc011":"!pip install -U scikit-fuzzy","75036497":"## utilities\nimport os\nimport pandas as pd\n#pd.options.display.float_format = '{:.2f}'.format # to supress scientific notation\npd.options.display.float_format = lambda x : '{:.0f}'.format(x) if round(x,0) == x else '{:,.2f}'.format(x)\npd.set_option('max_colwidth', 150)\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.options.mode.chained_assignment = None  # default='warn'\nimport numpy as np\nimport math\nfrom collections import Counter\nimport itertools\nimport random  \nimport re\nfrom random import sample\n\n## visualization\nimport plotly.express as px\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n#import joypy\n\n\n## clustering and decomposition\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import confusion_matrix\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n#!pip install -U scikit-fuzzy\nimport skfuzzy as fuzz\n\n## text analysis (maybe)\n# !pip install yake\n#import yake # keyword extractor, unsupervised\n#from PIL import Image\n#from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n#import re","615d8f0b":"PATH = '..\/input\/cdp-unlocking-climate-solutions'\n\ncorp_dc_cl_2020_clean = \\\n    pd.read_csv(PATH + '\/Corporations\/Corporations Disclosing\/Climate Change\/2020_Corporates_Disclosing_to_CDP_Climate_Change.csv',\n                usecols=['account_number',\n                         'organization',\n                         'country',\n                         'selected_tier',\n                         'authority_types',\n                         'activities',\n                         'sectors',\n                         'industries',\n                         'primary_activity',\n                         'primary_sector',\n                         'primary_industry',\n                         'primary_questionnaire_sector',\n                         'tickers'], \n                low_memory=False)\n\nr_corp_cl_2020_clean = \\\n    pd.read_csv(PATH + '\/Corporations\/Corporations Responses\/Climate Change\/2020_Full_Climate_Change_Dataset.csv',\n                usecols =['account_number',\n                          'module_name',\n                          'question_number',\n                          'question_unique_reference',\n                          'column_number',\n                          'column_name',\n                          'row_number',\n                          'row_name',\n                          'response_value'],\n                low_memory=False)","ecfdac89":"## Corporations disclosing ##\ncorp_dc_cl_2020_clean.info()","b0cb7c77":"## Corporates Responses ##\nr_corp_cl_2020_clean.info()","61ca93f2":"print((609745-340766)\/609745 * 100 , '% of NAN rows in response_value')","5ebf4a0a":"## Understand hearchy of data\n\n## Extract List of all QUESTIONS\/TOPICS, \n## show to which module QUESTION belongs\n## how many rows of response_value it takes\n## how many of those rows are empty\n\nsummary = \\\n    r_corp_cl_2020_clean \\\n        [r_corp_cl_2020_clean \\\n             ['response_value'].isnull()]\\\n        .question_unique_reference.value_counts() \\\n        .rename_axis('question_unique_reference') \\\n        .reset_index(name='NAN_rows')\n\n## create {question:module} dictionary \nquestion_module_dict = \\\n    r_corp_cl_2020_clean \\\n        .set_index('question_unique_reference')\\\n        .to_dict()['module_name']\n\n## create {column:question} dictionary\ncolumn_question_dict = \\\n    r_corp_cl_2020_clean\\\n        .set_index('question_unique_reference')\\\n        .to_dict()['question_number']\n\n\n## insert module for each Question in summary \nsummary.insert(0,\n            'module_name', \n               summary['question_unique_reference'] \\\n                   .map(question_module_dict))\n\n## insert module for each Question in summary \nsummary.insert(1,\n            'question_number', \n               summary['question_unique_reference'] \\\n                   .map(column_question_dict))\n\n## calculate number of rows taken by each Question\nall_rows = r_corp_cl_2020_clean\\\n        .question_unique_reference\\\n            .value_counts() \\\n            .rename_axis('question_unique_reference') \\\n            .reset_index(name='all_rows')\n## add to summary\nsummary = summary.merge(all_rows)\n\nsummary['%_NAN_rows'] = \\\n    (summary['NAN_rows'] \/ summary['all_rows'] *100)\\\n        .apply(lambda x: round(x))\n\n## sort by module\nsummary.sort_values(by=['module_name'], ascending=True)\\\n    .reset_index()\\\n    .style.background_gradient(cmap='Wistia',\n                               subset=['%_NAN_rows']).set_properties(**{'text-align': 'left'})","f5d62526":"## to deal with sparsity and to facilitate EDA, \n## reshape data into 980 rows(accounts) x columns (feature)\n\n## write helper functions","9f5ecd8a":"modules = list(r_corp_cl_2020_clean.module_name.unique())\nquestion_number  = []\nquestion_unique_reference = []\ndatasets_dictionary = {}\n\nfor m in modules:\n    qn = r_corp_cl_2020_clean\\\n        [r_corp_cl_2020_clean['module_name']==m]\\\n        .question_number.unique()\n    question_number.append(qn)\n    qu = r_corp_cl_2020_clean\\\n        [r_corp_cl_2020_clean['module_name']==m]\\\n        .question_unique_reference.unique()\n    question_unique_reference.append(qu)\n    sub_dictionary = dict(zip(qn, qu))\n    datasets_dictionary[m] = sub_dictionary","033f9d3e":"sorted(datasets_dictionary.keys())","a95f5aea":"## pul data for question of interest \ndef PullDataCorpClimate2020(module, question):\n    \"\"\" \n    This function depends \n    on 'Corporations\/CorporationsResponses\/\n        ClimateChange\/2020_Full_Climate_Change_Dataset.csv'\n    dataset loaded as <r_corp_cl_2020_clean> dataframe,\n    which has to be run first.\n    \n    module shall be a string selected from generated list\n    modules = list(r_corp_cl_2020_clean.module_name.unique()).\n    \n    question shall be a string, selected KEY from composed \n    nested dictionary:\n    datasets_dictionary[module].\n    \n    Returns subset from <r_corp_cl_2020_clean> dataframe \n    for question of interest\n    \n    requires pandas as pd\n    \"\"\"\n    temp = r_corp_cl_2020_clean\\\n        [(r_corp_cl_2020_clean['module_name']==module) &\n         (r_corp_cl_2020_clean['question_number']==question)]\\\n    .drop(['module_name','question_number',\n           'column_number'], axis=1)\n    if len(temp['column_name'].value_counts())==1:\n        temp = temp.drop(['column_name'], axis=1)\n    #if temp.row_number.unique()[0]==0:\n        #temp = temp.drop(['row_number'], axis=1)\n    if pd.isnull(temp.row_name.unique()[0]):\n        temp = temp.drop(['row_name'], axis=1)\n    response_name = temp.question_unique_reference.unique()[0]\\\n                .replace(\"-\",\"_\").replace(\"\/\",\"_\")\\\n                .replace(\"&\",\"_\")\\\n                .replace(\".\",\"\").replace(\"(\",\"\")\\\n                .replace(\")\",\"\").replace(\",\",\"\")\\\n                .replace(\"and\",\"\").replace(\" \",\"_\")\n    temp = temp.rename({'response_value': response_name}, \n                       axis=1)\\\n    .drop(['question_unique_reference'], axis=1)\n    \n    ## add meta data from corporate disclosing dataset\n    temp2 = corp_dc_cl_2020_clean[['account_number', \n                                   'organization', \n                                   'country',\n                                   'primary_activity',\n                                   'primary_industry',\n                                   'tickers']]\n    \n    result = pd.merge(temp2, temp, on=\"account_number\")\n    \n    \n    return result","15ef8f9f":"## Reshape dataset\ndef DatasetReshape(dataset):\n    \"\"\"\n    When pulled subset is in 'long form',\n    it requires further reshaping.\n    dataset - result from PullDataCorpClimate2020 function\n    \"\"\"\n    \n    dfs = []\n    ## extract subsets and store in dfs list\n        \n    for col in sorted(dataset.column_name.unique()):\n        tempcol = dataset[dataset['column_name']== col]\n        tempcol = tempcol.rename({tempcol.columns[-1]: col}, axis=1)\n\n        if 'row_name' not in tempcol:\n            if 'row_number' not in tempcol:\n                tempcol = tempcol.drop(['column_name'], axis=1)\n                dfs.append(tempcol)\n            else:\n                for row in sorted(tempcol.row_number.unique()):\n                    temprow = tempcol[tempcol['row_number']== row]\n                    temprow = temprow.rename({temprow.columns[-1]:\n                                              temprow.columns[-1] + \"_\" + str(row)}, axis=1)\n                    temprow = temprow.drop(['column_name','row_number'], axis=1)\n                    dfs.append(temprow)\n        else:\n            for row in sorted(tempcol.row_name.unique()):\n                temprow = tempcol[tempcol['row_name']== row]\n                temprow = temprow.rename({temprow.columns[-1]:\n                                          temprow.columns[-1] + \"_\" + row}, axis=1)\n                temprow = temprow.drop(['column_name', 'row_number', 'row_name'], axis=1)\n                dfs.append(temprow)\n                \n    ## merge all dfs in one wide table \n    result = pd.DataFrame(corp_dc_cl_2020_clean[['account_number']])\n    \n    if 'row_name' not in dataset:\n        if 'row_number' not in dataset:\n             dfs_number = len(dataset.column_name.unique())\n        else:\n            dfs_number = len(dataset.column_name.unique()) * len(dataset.row_number.unique())\n    else:\n        dfs_number = len(dataset.column_name.unique()) * len(dataset.row_name.unique())\n\n    for n in range(dfs_number):\n         result = pd.merge(result,\n                           dfs[n][['account_number',dfs[n].columns[-1]]],\n                           on='account_number',\n                           how='left')\n\n    ## add columns [organization, primary activity]\n    result = pd.merge(corp_dc_cl_2020_clean[['account_number',\n                                         'organization',\n                                         'primary_activity',\n                                         'primary_industry']],\n                                   result, \n                                   on='account_number')\n\n    ## if there are columns with more than 90% NA, drop\n    #result = \\\n        #result.dropna(thresh=98, axis=1, how='all')\n\n    return result","415a85ac":"## Reshape dataset IF COLUMNS are none\ndef DatasetReshape2(dataset):\n    \"\"\"\n    When pulled subset is in 'long form',\n    it requires further reshaping.\n    dataset - result from PullDataCorpClimate2020 function\n    \"\"\"\n    \n    dfs = []\n    ## extract subsets and store in dfs list\n    \n    if 'row_name' not in dataset:\n        for row in sorted(dataset.row_number.unique()):\n            temprow = dataset[dataset['row_number'] == row]\n            temprow = temprow.rename({temprow.columns[-1]:\n                                      temprow.columns[-1] + \"_\" + str(row)}, axis=1)\n            temprow = temprow.drop(['row_number'], axis=1)\n            dfs.append(temprow)\n    else:\n        for row in sorted(dataset.row_name.unique()):\n            temprow = dataset[dataset['row_name']== row]\n            temprow = temprow.rename({temprow.columns[-1]:\n                                      temprow.columns[-1] + \"_\" + row}, axis=1)\n            temprow = temprow.drop(['row_number', 'row_name'], axis=1)\n            dfs.append(temprow)\n                \n    ## merge all dfs in one wide table \n    result = pd.DataFrame(corp_dc_cl_2020_clean[['account_number']])\n    \n    dfs_number =len(dataset.row_number.unique())\n\n    for n in range(dfs_number):\n         result = pd.merge(result,\n                           dfs[n][['account_number',dfs[n].columns[-1]]],\n                           on='account_number',\n                           how='left')\n\n    ## add columns [organization, primary activity]\n    result = pd.merge(corp_dc_cl_2020_clean[['account_number',\n                                         'organization',\n                                         'primary_activity',\n                                         'primary_industry']],\n                                   result, \n                                   on='account_number')\n\n    ## if there are columns with more than 90% NA, drop\n    #result = \\\n        #result.dropna(thresh=98, axis=1, how='all')\n\n    return result","dd0a096c":"corporations2020 = corp_dc_cl_2020_clean\n\n## This is the base, to which\n## other features\/columns will be\n## progressively mapped to\n## complete data representation","0914769e":"datasets_dictionary['C0. Introduction']","51708c19":"## pull data related to the Question\ngeneral = \\\n    PullDataCorpClimate2020('C0. Introduction','C0.1')\n\n#general.info()\ngeneral = general.drop('row_number', axis=1)\n\ngeneral.head(2)","e49dc997":"## Mapping this categorical feature 1\n## tickers\n## if no ticker - 0\n## if ticker - 1\ngeneral['Listed'] = \\\n    np.where((general\\\n              ['tickers'].isnull()), 0, 1)\n\n## 1st mapped value\nmapping_listed = dict(general[['account_number', 'Listed']].values)","8e9cba18":"## pull data related to the Question\nreporting_period = \\\n    PullDataCorpClimate2020('C0. Introduction','C0.2')\n\n## reshape\nreporting_period_reshaped = DatasetReshape(reporting_period)\n\n## change to date formtat\nreporting_period_reshaped[reporting_period_reshaped.columns[4]] = \\\n    pd.to_datetime(reporting_period_reshaped\\\n             [reporting_period_reshaped.columns[4]], \n                   format='%Y-%m-%d')\n\n## plot\nreporting_period_reshaped\\\n      [reporting_period_reshaped.columns[4]].value_counts().\\\n      to_frame().plot();","cc73d8a7":"## Mapping this categorical feature 2\n## C0.2_C1Start date_Reporting year\n## if no response - 0\n## if different from optimal - 1\n## if optimal report starts 2019-01 - 2\nreporting_period_reshaped['Year_2019'] = \\\n    np.where((reporting_period_reshaped\\\n              ['C0.2_C1Start date_Reporting year']=='2019-01-01'),\n             2, 1)\n\n#reporting_period_reshaped.head()","9b3985b9":"## 2nd mapped value\nmapping_report_year = dict(reporting_period_reshaped[['account_number', 'Year_2019']].values)","c43b6526":"## Mapping this categorical feature 3\n## C0.2_C3Indicate if you are providing emissions data for past reporting years_Reporting year\n## if no response - 0\n## if No - 1\n## if Yes - 2\n\nconditions3 = [\n    (reporting_period_reshaped\\\n     ['C0.2_C3Indicate if you are providing emissions data for past reporting years_Reporting year']\\\n         .isnull()),\n    (reporting_period_reshaped\\\n     ['C0.2_C3Indicate if you are providing emissions data for past reporting years_Reporting year']=='No'),\n    (reporting_period_reshaped\\\n    ['C0.2_C3Indicate if you are providing emissions data for past reporting years_Reporting year']=='Yes')]\nvalues3 = [0,1,2]\n\nreporting_period_reshaped['PastYearData'] = np.select(conditions3,values3)\n\n## 3d mapped value\nmapping_past_year_data = dict(reporting_period_reshaped\\\n                              [['account_number', 'PastYearData']].\\\n                              values)","ea4afd53":"## pull data related to the section Question\ncountries_covered = \\\n    PullDataCorpClimate2020('C0. Introduction',\n                            'C0.3')\n\n#countries_covered.head()","671796a4":"## Mapping this categorical feature 4\n## Select_the_countries_areas_for_which_you_will_be_supplying_data\n## no response - 0\n## if Single country - 1\n## if Multinational - 2\n\nconditions4 = [(countries_covered['Select_the_countries_areas_for_which_you_will_be_supplying_data'].isnull()),\n               (countries_covered['Select_the_countries_areas_for_which_you_will_be_supplying_data']=='Canada'),\n               (countries_covered['Select_the_countries_areas_for_which_you_will_be_supplying_data']=='United States of America'),\n               (countries_covered['Select_the_countries_areas_for_which_you_will_be_supplying_data']!='Canada'),\n               (countries_covered['Select_the_countries_areas_for_which_you_will_be_supplying_data']!='United States of America')]\n\nvalues4 = [0,1,1,2,2]\n\ncountries_covered['Multinational'] = np.select(conditions4, values4)\n\nmapping_multinational = \\\n    dict(countries_covered[['account_number',\n                            'Multinational']].values)","55aea9b7":"## pull data related to the section Question\ncurrency = \\\n    PullDataCorpClimate2020('C0. Introduction','C0.4')\n#currency[currency.columns[-1]].value_counts().to_frame()","2bb3a667":"## Mapping this categorical feature 5\n## Select_the_currency_used_for_all_financial_information_disclosed_throughout_your_response\n## if USD or CAD - 2\n## if Other - 1\n\nconditions5 = [(currency['Select_the_currency_used_for_all_financial_information_disclosed_throughout_your_response']=='USD'),\n               (currency['Select_the_currency_used_for_all_financial_information_disclosed_throughout_your_response']=='CAD'),\n               (currency['Select_the_currency_used_for_all_financial_information_disclosed_throughout_your_response']!='USD'),\n              (currency['Select_the_currency_used_for_all_financial_information_disclosed_throughout_your_response']!='CAD')]\n\nvalues5 = [2,2,1,1]\n\ncurrency['Currency'] = np.select(conditions5, values5)\n\nmapping_currency = \\\n    dict(currency[['account_number',\n                            'Currency']].values)","75f0d3bc":"## pull data related to the section Question\nreporting_boundary = \\\n    PullDataCorpClimate2020('C0. Introduction','C0.5')\n\n#reporting_boundary.info()","0428320c":"## Mapping this categorical feature 6\n## Select the option that describes the reporting boundary for which climate-related impacts on your business are being reported\n## if Operational control - 3\n## if Financial control - 2\n## if Equity share - 1\n## if NAN - 0\n\nconditions6 = [(reporting_boundary[reporting_boundary.columns[-1]]=='Operational control'),\n               (reporting_boundary[reporting_boundary.columns[-1]]=='Financial control'),\n               (reporting_boundary[reporting_boundary.columns[-1]]=='Equity share'),\n               (reporting_boundary[reporting_boundary.columns[-1]].isnull())]\n\nvalues6 = [3,2,1,0]\n\nreporting_boundary['Reporting_boundary'] = np.select(conditions6,values6)\n\nmapping_boundary = \\\n    dict(reporting_boundary[['account_number',\n                            'Reporting_boundary']].values)","cd41ce82":"## pull data related to the section Question\ntime_horizons = \\\n    PullDataCorpClimate2020('C2. Risks and opportunities','C2.1a')\n\n#time_horizons.info()\n\n##need to reshape\ntime_horizons_reshaped = \\\n    DatasetReshape(time_horizons)\n\n##concatenate col for each range (short,mid,long)\ntime_horizons_reshaped['Short_term'] = \\\n    time_horizons_reshaped[time_horizons_reshaped.columns[6]] \\\n    +'-'+ \\\n    time_horizons_reshaped[time_horizons_reshaped.columns[9]]\n\ntime_horizons_reshaped['Medium_term'] = \\\n    time_horizons_reshaped[time_horizons_reshaped.columns[5]] \\\n    +'-'+ \\\n    time_horizons_reshaped[time_horizons_reshaped.columns[8]]\n\ntime_horizons_reshaped['Long_term'] = \\\n    time_horizons_reshaped[time_horizons_reshaped.columns[4]] \\\n    +'-'+ \\\n    time_horizons_reshaped[time_horizons_reshaped.columns[7]]\n\ntime_horizons_reshaped = \\\n    time_horizons_reshaped.drop(['C2.1a_C1From (years)_Long-term',\n                                 'C2.1a_C1From (years)_Medium-term',\n                                 'C2.1a_C1From (years)_Short-term',\n                                 'C2.1a_C2To (years)_Long-term',\n                                 'C2.1a_C2To (years)_Medium-term',\n                                 'C2.1a_C2To (years)_Short-term'],\n                                axis=1)\n#time_horizons_reshaped.head()\n\n## Mapping this categorical feature 7\n## How does your organization define short-, medium- and long-term time horizons?\n## if responded to question - 1\n## if not responded - 0\n\ntime_horizons_reshaped['ShortTerm'] = np.where((time_horizons_reshaped['Short_term'].isnull()),0,1)\ntime_horizons_reshaped['MediumTerm'] = np.where((time_horizons_reshaped['Medium_term'].isnull()),0,1)\ntime_horizons_reshaped['LongTerm'] = np.where((time_horizons_reshaped['Long_term'].isnull()),0,1)\n\nmapping_short_term_defined = \\\n    dict(time_horizons_reshaped[['account_number',\n                            'ShortTerm']].values)\n\nmapping_medium_term_defined = \\\n    dict(time_horizons_reshaped[['account_number',\n                            'MediumTerm']].values)\n\nmapping_long_term_defined = \\\n    dict(time_horizons_reshaped[['account_number',\n                            'LongTerm']].values)","9765a2e2":"## pull data related to the section Question\nrisks_id_processes = \\\n    PullDataCorpClimate2020('C2. Risks and opportunities','C2.2')\n\n## reshape \nrisks_id_processes_reshaped = \\\n    DatasetReshape(risks_id_processes)\n\n#risks_id_processes_reshaped.head()\n\n## Mapping this categorical feature 8\n## Describe your process(es) for identifying, assessing and responding to climate-related risks and opportunities\n## if specific climate-related risk management process - 2\n## if itegrated - 1\n## if no response = 0\n\nconditions8 = [(risks_id_processes_reshaped['C2.2_C2Risk management process_1']=='A specific climate-related risk management process'),\n              (risks_id_processes_reshaped['C2.2_C2Risk management process_1']=='Integrated into multi-disciplinary company-wide risk management process'),\n              (risks_id_processes_reshaped['C2.2_C2Risk management process_1'].isnull())]\n\nvalues8 = [2,1,0]\n\nrisks_id_processes_reshaped['RiskManagementProcess'] = np.select(conditions8,values8)\n\nmapping_rmp = \\\n    dict(risks_id_processes_reshaped[['account_number',\n                            'RiskManagementProcess']].values)","da3a3d95":"## pull data related to the section Question\ntypes_of_risks = \\\n    PullDataCorpClimate2020('C2. Risks and opportunities',\n                            'C2.2a')\n## check structure\n#types_of_risks.info()\n\n## reshape \ntypes_of_risks_reshaped = \\\n    DatasetReshape(types_of_risks)\n\n#types_of_risks_reshaped.head()\n\n## Mapping this categorical feature 9 - 16\n## Risks Relevance & inclusion\n## Relevant, always included = 3\n## Not relevant, included = 3\n## Relevant, sometimes included = 2\n## Relevant, not included = 1\n## Not relevant, explanation provided = 1\n## Not evaluated = 1\n## nan = 0\n\n#Acute physical\nconditions9 = [(types_of_risks_reshaped[types_of_risks_reshaped.columns[4]]=='Relevant, always included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[4]]=='Not relevant, included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[4]]=='Relevant, sometimes included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[4]]=='Relevant, not included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[4]]=='Not relevant, explanation provided'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[4]]=='Not evaluated'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[4]].isnull())]\n                \nvalues9 = [3,3,2,1,2,1,0]\n   \ntypes_of_risks_reshaped['AcutephysicalRisk'] = np.select(conditions9,values9)\n\n# Chronic physical\nconditions10 = [(types_of_risks_reshaped[types_of_risks_reshaped.columns[5]]=='Relevant, always included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[5]]=='Not relevant, included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[5]]=='Relevant, sometimes included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[5]]=='Relevant, not included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[5]]=='Not relevant, explanation provided'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[5]]=='Not evaluated'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[5]].isnull())]\n                \nvalues10 = [3,3,2,1,2,1,0]\n\ntypes_of_risks_reshaped['ChronicPhysicalRisk'] = np.select(conditions10,values10)\n\n\n# Current regulation\nconditions11 = [(types_of_risks_reshaped[types_of_risks_reshaped.columns[6]]=='Relevant, always included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[6]]=='Not relevant, included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[6]]=='Relevant, sometimes included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[6]]=='Relevant, not included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[6]]=='Not relevant, explanation provided'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[6]]=='Not evaluated'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[6]].isnull())]\n                \nvalues11 = [3,3,2,1,2,1,0]\n\ntypes_of_risks_reshaped['CurrentRegulationRisk'] = np.select(conditions11,values11)\n\n\n# Emerging regulation\nconditions12 = [(types_of_risks_reshaped[types_of_risks_reshaped.columns[7]]=='Relevant, always included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[7]]=='Not relevant, included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[7]]=='Relevant, sometimes included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[7]]=='Relevant, not included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[7]]=='Not relevant, explanation provided'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[7]]=='Not evaluated'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[7]].isnull())]\n                \nvalues12 = [3,3,2,1,2,1,0]\n\ntypes_of_risks_reshaped['EmergingRegulationRisk'] = np.select(conditions12,values12)\n\n# Legal\nconditions13 = [(types_of_risks_reshaped[types_of_risks_reshaped.columns[8]]=='Relevant, always included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[8]]=='Not relevant, included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[8]]=='Relevant, sometimes included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[8]]=='Relevant, not included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[8]]=='Not relevant, explanation provided'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[8]]=='Not evaluated'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[8]].isnull())]\n                \nvalues13 = [3,3,2,1,2,1,0]\n\ntypes_of_risks_reshaped['LegalRisk'] = np.select(conditions13,values13)\n\n# Market\nconditions14 = [(types_of_risks_reshaped[types_of_risks_reshaped.columns[9]]=='Relevant, always included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[9]]=='Not relevant, included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[9]]=='Relevant, sometimes included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[9]]=='Relevant, not included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[9]]=='Not relevant, explanation provided'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[9]]=='Not evaluated'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[9]].isnull())]\n                \nvalues14 = [3,3,2,1,2,1,0]\n\ntypes_of_risks_reshaped['MarketRisk'] = np.select(conditions14,values14)\n\n# Reputation\nconditions15 = [(types_of_risks_reshaped[types_of_risks_reshaped.columns[10]]=='Relevant, always included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[10]]=='Not relevant, included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[10]]=='Relevant, sometimes included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[10]]=='Relevant, not included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[10]]=='Not relevant, explanation provided'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[10]]=='Not evaluated'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[10]].isnull())]\n                \nvalues15 = [3,3,2,1,2,1,0]\n\ntypes_of_risks_reshaped['ReputationRisk'] = np.select(conditions15,values15)\n\n\n# Technology\nconditions16 = [(types_of_risks_reshaped[types_of_risks_reshaped.columns[11]]=='Relevant, always included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[11]]=='Not relevant, included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[11]]=='Relevant, sometimes included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[11]]=='Relevant, not included'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[11]]=='Not relevant, explanation provided'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[11]]=='Not evaluated'),\n                (types_of_risks_reshaped[types_of_risks_reshaped.columns[11]].isnull())]\n                \nvalues16 = [3,3,2,1,2,1,0]\n\ntypes_of_risks_reshaped['TechnologyRisk'] = np.select(conditions16,values16)\n","4951d3f8":"mapping_acute_physical_risk = \\\n    dict(types_of_risks_reshaped[['account_number',\n                            'AcutephysicalRisk']].values)\n\nmapping_chronic_physical_risk = \\\n    dict(types_of_risks_reshaped[['account_number',\n                            'ChronicPhysicalRisk']].values)\n\nmapping_current_regulation_risk = \\\n    dict(types_of_risks_reshaped[['account_number',\n                            'CurrentRegulationRisk']].values)\n\nmapping_emerging_regulation_risk = \\\n    dict(types_of_risks_reshaped[['account_number',\n                            'EmergingRegulationRisk']].values)\n\nmapping_legal_risk = \\\n    dict(types_of_risks_reshaped[['account_number',\n                            'LegalRisk']].values)\n\nmapping_market_risk = \\\n    dict(types_of_risks_reshaped[['account_number',\n                            'MarketRisk']].values)\n\nmapping_reputation_risk = \\\n    dict(types_of_risks_reshaped[['account_number',\n                            'ReputationRisk']].values)\n\nmapping_technology_risk = \\\n    dict(types_of_risks_reshaped[['account_number',\n                            'TechnologyRisk']].values)","7d940bed":"## pull data related to the section Question\nidentified_impacts = \\\n    PullDataCorpClimate2020('C2. Risks and opportunities',\n                            'C2.3')\n\nidentified_impacts.head()\n\n## Mapping this categorical feature 17\n## Have you identified any inherent climate-related risks\n## Yes - 2\n## No - 1\n## Nan - 0\n\nconditions17 = [(identified_impacts[identified_impacts.columns[-1]]=='Yes'),\n               (identified_impacts[identified_impacts.columns[-1]]=='No'),\n               (identified_impacts[identified_impacts.columns[-1]].isnull())]\n\nvalues17 = [2,1,0]\n\nidentified_impacts['IdentifiedRiskImpact'] = np.select(conditions17, values17)\n\nmappig_risk_impacts = dict(identified_impacts[['account_number',\n                                              'IdentifiedRiskImpact']].values)","4c23c380":"## pull data related to the section Question\nidentified_risks = \\\n    PullDataCorpClimate2020('C2. Risks and opportunities',\n                            'C2.3a')\n## check structure\n#identified_risks.info()\n\n## reshape \nidentified_risks_reshaped = \\\n    DatasetReshape(identified_risks)\n\n#identified_risks_reshaped.head()\n\n## Mapping this categorical feature 18\n## Are you able to provide a potential financial impact figure?\n## Yes - 2\n## No - 1\n## Nan - 0\nconditions18 = [(identified_risks_reshaped[identified_risks_reshaped.columns[5]]=='Yes, an estimated range'),\n               (identified_risks_reshaped[identified_risks_reshaped.columns[5]]=='Yes, a single figure estimate'),\n               (identified_risks_reshaped[identified_risks_reshaped.columns[5]]=='No, we do not have this figure'),\n               (identified_risks_reshaped[identified_risks_reshaped.columns[5]].isnull())]\n\nvalues18 = [2, 2, 1, 0]\n\nidentified_risks_reshaped['Risk1PotentialFinancialImpact'] = np.select(conditions18,values18)\n\nmapping_risk_financial_impact = dict(identified_risks_reshaped[['account_number',\n                                                                'Risk1PotentialFinancialImpact']].values)","b7d9161f":"identified_opportunities = \\\n    PullDataCorpClimate2020('C2. Risks and opportunities',\n                            'C2.4')\n#identified_opportunities.head(1)\n\n## Mapping this categorical feature 19\n## Have_you_identified_any_climate_related_opportunities?\n## Yes - 2\n## No - 1\n## Nan - 0\nconditions19 = [(identified_opportunities[identified_opportunities.columns[-1]]=='Yes'),\n               (identified_opportunities[identified_opportunities.columns[-1]]=='No'),\n               (identified_opportunities[identified_opportunities.columns[-1]].isnull())]\n\nvalues19 = [2, 1, 0]\n\nidentified_opportunities['IdentifiedOppImpact'] = np.select(conditions19,values19)\n\nmapping_opp_impact = dict(identified_opportunities[['account_number',\n                                                                'IdentifiedOppImpact']].values)","ec96c07e":"details_opportunities = \\\n    PullDataCorpClimate2020('C2. Risks and opportunities',\n                            'C2.4a')\n## check structure\n## reshape \ndetails_opportunities_reshaped = \\\n    DatasetReshape(details_opportunities)\n\n#details_opportunities_reshaped.head(2)\n\n## Mapping this categorical feature 20\n## Are you able to provide a potential financial impact figure?\n## Yes - 2\n## No - 1\n## Nan - 0\nconditions20 = [(details_opportunities_reshaped[details_opportunities_reshaped.columns[5]]=='Yes, a single figure estimate'),\n               (details_opportunities_reshaped[details_opportunities_reshaped.columns[5]]=='Yes, an estimated range'),\n               (details_opportunities_reshaped[details_opportunities_reshaped.columns[5]]=='No, we do not have this figure'),\n               (details_opportunities_reshaped[details_opportunities_reshaped.columns[5]].isnull())]\n\nvalues20 = [2, 2, 1, 0]\n\ndetails_opportunities_reshaped['Risk1PotentialFinancialImpact'] = np.select(conditions20,values20)\n\nmapping_opp_financial_impact = dict(details_opportunities_reshaped[['account_number',\n                                                                'Risk1PotentialFinancialImpact']].values)","0f18bf79":"datasets_dictionary['C4. Targets and performance']","a058fb08":"## pull data related to the section Question\nemission_targets_setting = \\\n    PullDataCorpClimate2020('C4. Targets and performance',\n                            'C4.1')\n\n#emission_targets_setting.head()\n\n## Mapping this categorical feature 21\n## Did_you_have_an_emissions_target_that_was_active_in_the_reporting_year?\n## Absolute target, Intensity target,Both absolute and intensity targets - 2\n## No target - 1\n## Nan - 0\n\nconditions21 = [(emission_targets_setting[emission_targets_setting.columns[-1]]=='Absolute target'),\n                (emission_targets_setting[emission_targets_setting.columns[-1]]=='Intensity target'),\n                (emission_targets_setting[emission_targets_setting.columns[-1]]=='Both absolute and intensity targets'),\n                (emission_targets_setting[emission_targets_setting.columns[-1]]=='No target'),\n                (emission_targets_setting[emission_targets_setting.columns[-1]].isnull())]\n                \nvalues21 = [2, 2, 2, 1, 0]    \n\nemission_targets_setting['EmissionTargetSetting'] = np.select(conditions21, values21)\n\nmapping_emission_target_setting = dict(emission_targets_setting[['account_number',\n                                                                 'EmissionTargetSetting']].values)","d27b3532":"## pull data related to the section Question\nemission_targets_details = \\\n    PullDataCorpClimate2020('C4. Targets and performance',\n                            'C4.1a')\n## check structure\n#emission_targets_details.info()\n\n## reshape\nemission_targets_details_reshaped = \\\n    DatasetReshape(emission_targets_details)\n\n#emission_targets_details_reshaped.head(1)\n\n## Mapping this categorical feature 22\n## C4.1a_C13Target status in reporting year_1\n\n## convert to numerical, replace NAN with 0\nemission_targets_details_reshaped\\\n    ['C4.1a_C9Targeted reduction from base year (%)_1'] = \\\n        pd.to_numeric(emission_targets_details_reshaped\\\n                    ['C4.1a_C9Targeted reduction from base year (%)_1']).\\\n                        fillna(0)\n\n## numerical value, mapping without encoding\n\nmapping_emission_target1_reduction = \\\n    dict(emission_targets_details_reshaped[['account_number',\n                                        'C4.1a_C9Targeted reduction from base year (%)_1']].values)\n\n## Mapping this categorical feature 23\n## Underway - 2\n## Achieved - 3 \n## New -2\n## Revised -1\n## Replaced -1\n## Expired -1\n## Retired -1\n## NAN - 0 \n\nconditions23 = [(emission_targets_details_reshaped['C4.1a_C13Target status in reporting year_1']=='Underway'),\n                (emission_targets_details_reshaped['C4.1a_C13Target status in reporting year_1']=='Achieved'),\n                (emission_targets_details_reshaped['C4.1a_C13Target status in reporting year_1']=='New'),\n                (emission_targets_details_reshaped['C4.1a_C13Target status in reporting year_1']=='Revised'),\n                (emission_targets_details_reshaped['C4.1a_C13Target status in reporting year_1']=='Replaced'),\n                (emission_targets_details_reshaped['C4.1a_C13Target status in reporting year_1']=='Expired'),\n                (emission_targets_details_reshaped['C4.1a_C13Target status in reporting year_1']=='Retired'),\n                (emission_targets_details_reshaped['C4.1a_C13Target status in reporting year_1'].isnull())]\n\nvalues23 = [2, 3, 2, 1, 1, 1, 1, 0]\n\nemission_targets_details_reshaped['Target1Status'] = np.select(conditions23, values23)\n\nmapping_target1_status = dict(emission_targets_details_reshaped[['account_number',\n                                                                 'Target1Status']].values)","1f99b697":"## pull data related to the section Question\nintensity_targets = \\\n    PullDataCorpClimate2020('C4. Targets and performance',\n                            'C4.1b')\n## reshape\nintensity_targets_reshaped = \\\n    DatasetReshape(intensity_targets)\n#intensity_targets_reshaped.head(1)\n\n## Mapping this categorical feature 24\n## C4.1b_C10Targeted reduction from base year (%)_1\n\nintensity_targets_reshaped['C4.1b_C10Targeted reduction from base year (%)_1'] = \\\n    pd.to_numeric(intensity_targets_reshaped['C4.1b_C10Targeted reduction from base year (%)_1']).\\\n    fillna(0)\n\nmapping_intensity_targeted_reduction = dict(intensity_targets_reshaped[['account_number',\n                                            'C4.1b_C10Targeted reduction from base year (%)_1']].values)","1a6d101b":"## pull data related to the section Question\nno_targets_reason = \\\n    PullDataCorpClimate2020('C4. Targets and performance',\n                            'C4.1c')\n##reshape\nno_targets_reason_reshaped = \\\n    DatasetReshape(no_targets_reason)\n\n#no_targets_reason_reshaped.head(1)\n\n## Will not map this feature, as \n## already have feature Did You Have a Target\n## However this \"textual data\" 'Please explain' can be useful \n## for text analysis, if time will allow","421d6a8b":"## pull data related to the section Question\nother_climate_targets = \\\n    PullDataCorpClimate2020('C4. Targets and performance',\n                            'C4.2b')\n#other_climate_targets.info()\n##reshape\nother_climate_targets_reshaped = \\\n    DatasetReshape(other_climate_targets)\n\n#other_climate_targets_reshaped[other_climate_targets_reshaped.columns[4:40]].info() 76% null\n#other_climate_targets_reshaped[other_climate_targets_reshaped.columns[40:80]].info() 76% null\n#other_climate_targets_reshaped[other_climate_targets_reshaped.columns[80:120]].info() 76% null\n#other_climate_targets_reshaped[other_climate_targets_reshaped.columns[120:148]].info() 76% null\n\n## This feature is extremly sparse, about 76% null value, it might bias outcome \n## for time being will not include it in clustering model","b5416478":"## pull data related to the section Question\nemission_reduction_initiatives = \\\n    PullDataCorpClimate2020('C4. Targets and performance',\n                            'C4.3')\n\n#emission_reduction_initiatives.head(1)\n\n## Mapping this categorical feature 25\n## Did_you_have_emissions_reduction_initiatives\n## Yes - 2\n## No - 1\n## NAN - 0\n\nconditions25 = [(emission_reduction_initiatives[emission_reduction_initiatives.columns[-1]]=='Yes'),\n               (emission_reduction_initiatives[emission_reduction_initiatives.columns[-1]]=='No'),\n               (emission_reduction_initiatives[emission_reduction_initiatives.columns[-1]].isnull())]\n\nvalues25 = [2, 1, 0]\n\nemission_reduction_initiatives['EmissionReductionInitiative'] = np.select(conditions25,\n                                                                         values25)\nmapping_emission_reduction_initiative = dict(emission_reduction_initiatives[['account_number',\n                                                                             'EmissionReductionInitiative']].values)","cfc95ec9":"## pull data related to the section Question\nemission_reduction_initiatives_details = \\\n    PullDataCorpClimate2020('C4. Targets and performance',\n                            'C4.3a')\n\n#emission_reduction_initiatives_details.info()\n\n##reshape\nemission_reduction_initiatives_details_reshaped =\\\n    DatasetReshape(emission_reduction_initiatives_details)\n\n#emission_reduction_initiatives_details_reshaped.head()\n\n## Mapping this categorical feature 26\n## Number of initiatives commenced\n\n## convert to numerical\nemission_reduction_initiatives_details_reshaped\\\n    ['C4.3a_C1Number of initiatives_Implementation commenced*'] = pd.to_numeric(\nemission_reduction_initiatives_details_reshaped\\\n    ['C4.3a_C1Number of initiatives_Implementation commenced*']).fillna(0)\n\nmapping_no_initiatives_commenced = dict\\\n    (emission_reduction_initiatives_details_reshaped\\\n     [['account_number',\n       'C4.3a_C1Number of initiatives_Implementation commenced*']].values)\n\n## Mapping this categorical feature 27\n## Number of initiatives_Implemented\n\n## convert to numerical\nemission_reduction_initiatives_details_reshaped\\\n    ['C4.3a_C1Number of initiatives_Implemented*'] = pd.to_numeric(\nemission_reduction_initiatives_details_reshaped\\\n    ['C4.3a_C1Number of initiatives_Implemented*']).fillna(0)\n\nmapping_no_initiatives_implemented = dict\\\n    (emission_reduction_initiatives_details_reshaped\\\n     [['account_number',\n       'C4.3a_C1Number of initiatives_Implemented*']].values)","4698afed":"## pull data related to the Question\nintroduction = \\\n    PullDataCorpClimate2020('C0. Introduction','C0.1')\n\n#introduction.head()","96c0286c":"##THIS RUNS LONG\n## pull data related to the section Question\nimplemented_initiatives = \\\n    PullDataCorpClimate2020('C4. Targets and performance',\n                            'C4.3b')\n#implemented_initiatives.info()\n\n## reshape\nimplemented_initiatives_reshaped = \\\n    DatasetReshape(implemented_initiatives)\n#implemented_initiatives_reshaped.head()\n\n## This feature to be addressed in Analysis section\n## encoding will result in loss of usefull information\n## like concreate initiatives taken by organizations","db4aacc5":"## pull data related to the section Question\ninvestment_methods = \\\n    PullDataCorpClimate2020('C4. Targets and performance',\n                            'C4.3c')\n\n#investment_methods.info()\ninvestment_methods_reshaped = \\\n    DatasetReshape(investment_methods)\n#investment_methods_reshaped.head()\n\n## This feature to be addressed in Analysis section\n## encoding will result in loss of usefull information\n## like concreate methods used by organizations","02e076ba":"## pull data related to the section Question\nclassify_lowcarbon_output = \\\n    PullDataCorpClimate2020('C4. Targets and performance',\n                            'C4.5')\n#classify_lowcarbon_output.head()\n\n## Mapping this categorical feature 28\n##Do_you_classify_any_of_your_existing_goods__or_services_as_low_carbon_products?\n## Yes - 2\n## No - 1\n## No response - 0\n\nconditions28 = [(classify_lowcarbon_output[classify_lowcarbon_output.columns[-1]]=='Yes'),\n                (classify_lowcarbon_output[classify_lowcarbon_output.columns[-1]]=='No'),\n                (classify_lowcarbon_output[classify_lowcarbon_output.columns[-1]].isnull())]\n\nvalues28 = [2, 1, 0]\n\nclassify_lowcarbon_output['LowcarbonOutputs'] = np.select(conditions28, values28)\n\nmapping_lowcarbon_output = dict(classify_lowcarbon_output[['account_number','LowcarbonOutputs']].values)","422b3604":"## pull data related to the section Question\nlow_carbon_output = \\\n    PullDataCorpClimate2020('C4. Targets and performance',\n                            'C4.5a')\n#low_carbon_output.info()\n## reshape\nlow_carbon_output_reshaped = \\\n    DatasetReshape(low_carbon_output)\n\n#low_carbon_output_reshaped.head()\n## This feature to be addressed in Analysis section\n## encoding will result in loss of usefull information\n## like concreate low carbon outputs by organizations","615979e7":"## pull data related to the section Question\nemissions = \\\n    PullDataCorpClimate2020('C6. Emissions data',\n                            'C6.1')\n## check structure\n#emissions.info()\n\n## reshape\nemissions_reshaped = \\\n    DatasetReshape(emissions)\n\n## interested in current reporting year\nscope1 = \\\n    emissions_reshaped[['account_number','organization',\n                        'primary_activity','primary_industry',\n                        'C6.1_C1Gross global Scope 1 emissions (metric tons CO2e)_Reporting year']]\n\n## change to numerical\nscope1[scope1.columns[-1]] = \\\n        pd.to_numeric(scope1[scope1.columns[-1]]).fillna(0)\n\n#scope1.head()\n\n## Mapping this feature 28\nmapping_scope1 = dict(scope1[['account_number',\n                              'C6.1_C1Gross global Scope 1 emissions (metric tons CO2e)_Reporting year']].values)","df4e5b8a":"## pull data related to the section Question\nemissions2 = \\\n    PullDataCorpClimate2020('C6. Emissions data',\n                            'C6.3')\n#emissions2.info()\n\n## reshape\nemissions2_reshaped = DatasetReshape(emissions2)\nemissions2_reshaped.head()\n\n## interested only in reporting year\nscope2 = emissions2_reshaped[['account_number',\n                              'organization',\n                              'primary_activity',\n                              'primary_industry',\n                              'C6.3_C1Scope 2, location-based_Reporting year',\n                              'C6.3_C2Scope 2, market-based (if applicable)_Reporting year']]\n#scope2.head()\n\n## Mapping this feature 29\nscope2['C6.3_C1Scope 2, location-based_Reporting year'] = \\\n    pd.to_numeric(scope2['C6.3_C1Scope 2, location-based_Reporting year']).fillna(0)\n\nmapping_scope2_loc = dict(scope2[['account_number',\n                                  'C6.3_C1Scope 2, location-based_Reporting year']].values)\n\n## Mapping this feature 30\nscope2['C6.3_C2Scope 2, market-based (if applicable)_Reporting year'] = \\\n    pd.to_numeric(scope2['C6.3_C2Scope 2, market-based (if applicable)_Reporting year']).fillna(0)\n\nmapping_scope2_mar = dict(scope2[['account_number',\n                                  'C6.3_C2Scope 2, market-based (if applicable)_Reporting year']].values)","c185430a":"## pull data related to the section Question\nemissions3 = \\\n    PullDataCorpClimate2020('C6. Emissions data','C6.5')\n\n## check structure\n#emissions3.info()\n\n## reshape\nemissions3_reshaped = \\\n    DatasetReshape(emissions3)\nemissions3_reshaped.head(1)\n\n## This dataset is less informative than actual information\n## about scope 3 emissions, extracted next\n\n## extract columns related to C6.5_C2\ncols = np.r_[0:4, 21:37]\nscope3 = emissions3_reshaped[emissions3_reshaped.columns[cols]]\n\n##convert to numerical\nfor i in (list(range(4,20))):\n    scope3[list(scope3.columns)[i]] = \\\n    pd.to_numeric(scope3[list(scope3.columns)[i]]).fillna(0)\n\n##add total\nscope3['Total_Scope3_CO2e_mt'] = scope3[scope3.columns[4:20]].sum(axis=1)\n\n#scope3.head()\n\n## Mapping this feature 31\nmapping_scope3_Business_travel = \\\n    dict(scope3[['account_number','C6.5_C2Metric tonnes CO2e_Business travel']].values)\n\nmapping_scope3_Capital_goods = \\\n    dict(scope3[['account_number','C6.5_C2Metric tonnes CO2e_Capital goods']].values)\n\nmapping_scope3_Downstream_leased_assets = \\\n    dict(scope3[['account_number','C6.5_C2Metric tonnes CO2e_Downstream leased assets']].values)\n\nmapping_scope3_transportation_and_distribution = \\\n    dict(scope3[['account_number','C6.5_C2Metric tonnes CO2e_Downstream transportation and distribution']].values)\n\nmapping_scope3_Employee_commuting = \\\n    dict(scope3[['account_number','C6.5_C2Metric tonnes CO2e_Employee commuting']].values)\n\nmapping_scope3_End_of_life_treatment_of_sold_products = \\\n    dict(scope3[['account_number','C6.5_C2Metric tonnes CO2e_End of life treatment of sold products']].values)\n\nmapping_scope3_Franchises = \\\n    dict(scope3[['account_number','C6.5_C2Metric tonnes CO2e_Franchises']].values)\n\nmapping_scope3_energy_related_activities = \\\n    dict(scope3[['account_number','C6.5_C2Metric tonnes CO2e_Fuel-and-energy-related activities (not included in Scope 1 or 2)']].values)\n\nmapping_scope3_Investments = \\\n    dict(scope3[['account_number','C6.5_C2Metric tonnes CO2e_Investments']].values)\n\nmapping_scope3_Downstream_other = \\\n    dict(scope3[['account_number','C6.5_C2Metric tonnes CO2e_Other (downstream)']].values)\n\nmapping_scope3_Upstream_other = \\\n    dict(scope3[['account_number','C6.5_C2Metric tonnes CO2e_Other (upstream)']].values)\n\nmapping_scope3_processing_sold_products = \\\n    dict(scope3[['account_number','C6.5_C2Metric tonnes CO2e_Processing of sold products']].values)\n\nmapping_scope3_purchased_goods_services = \\\n    dict(scope3[['account_number','C6.5_C2Metric tonnes CO2e_Purchased goods and services']].values)\n\nmapping_scope3_upstream_leased_assets = \\\n    dict(scope3[['account_number','C6.5_C2Metric tonnes CO2e_Upstream leased assets']].values)\n\nmapping_scope3_upstream_transportation_and_distribution = \\\n    dict(scope3[['account_number','C6.5_C2Metric tonnes CO2e_Upstream transportation and distribution']].values)\n\nmapping_scope3_sold_products = \\\n    dict(scope3[['account_number','C6.5_C2Metric tonnes CO2e_Use of sold products']].values)","bfa311dc":"## pull data related to the section Question\nintensity_metrics = \\\n    PullDataCorpClimate2020('C6. Emissions data','C6.10')\n\n## check structure\n#intensity_metrics.info()\n\n## reshape \nintensity_metrics_reshaped = \\\n    DatasetReshape(intensity_metrics)\nintensity_metrics_reshaped.head(1)\n\n## reindex columns\nnew_index3 = ['account_number','organization','primary_activity','primary_industry',\n             'C6.10_C1Intensity figure_1',\n             'C6.10_C2Metric numerator (Gross global combined Scope 1 and 2 emissions, metric tons CO2e)_1',\n             'C6.10_C3Metric denominator_1',\n             'C6.10_C4Metric denominator: Unit total_1',\n             'C6.10_C5Scope 2 figure used_1',\n             'C6.10_C6% change from previous year_1',\n             'C6.10_C7Direction of change_1',\n             'C6.10_C8Reason for change_1',\n             'C6.10_C1Intensity figure_2',\n             'C6.10_C2Metric numerator (Gross global combined Scope 1 and 2 emissions, metric tons CO2e)_2',\n             'C6.10_C3Metric denominator_2',\n             'C6.10_C4Metric denominator: Unit total_2',\n             'C6.10_C5Scope 2 figure used_2',\n             'C6.10_C6% change from previous year_2',\n             'C6.10_C7Direction of change_2',\n             'C6.10_C8Reason for change_2']\n\nintensity_metrics_reshaped = \\\n    intensity_metrics_reshaped.reindex(new_index3, axis=1)\n\nintensity_metrics_reshaped['C6.10_C4Metric denominator: Unit total_1'] = \\\n    pd.to_numeric(intensity_metrics_reshaped['C6.10_C4Metric denominator: Unit total_1']).fillna(0)\n\n## metric numerator and intensity figure\n## are derived from other already mapped\n## subsets\n\n## but scaler is interesting\n## Mapping this feature 32\nmapping_intensity_scaler_value = \\\n    dict(intensity_metrics_reshaped[['account_number','C6.10_C4Metric denominator: Unit total_1']].values)\n\n## and direction of change\n## Mapping this feature 33\n## Decreased - 3\n## Increased - 1\n## No change - 2\n## - NAN - 0\n\nconditions33 = [(intensity_metrics_reshaped['C6.10_C7Direction of change_1']=='Decreased'),\n                (intensity_metrics_reshaped['C6.10_C7Direction of change_1']=='No change'),\n                (intensity_metrics_reshaped['C6.10_C7Direction of change_1']=='Increased'),\n                (intensity_metrics_reshaped['C6.10_C7Direction of change_1'].isnull())]\n\nvalues33 = [3, 2, 1, 0]\n\nintensity_metrics_reshaped['IntensityChange'] = np.select(conditions33,values33)\n\nmapping_intensity_change = \\\n    dict(intensity_metrics_reshaped[['account_number','IntensityChange']].values)","c787b769":"## pull data related to the section Question\nscope1_breakdown_gh = \\\n    PullDataCorpClimate2020('C7. Emissions breakdowns',\n                            'C7.1')\n## check structure\n#scope1_breakdown_gh.head()\n\n## Mapping this feature 34\n## Does_your_organization_break_down_its_Scope_1_emissions_by_greenhouse_gas_type?\n\nconditions34 = [(scope1_breakdown_gh[scope1_breakdown_gh.columns[-1]]=='Yes'),\n               (scope1_breakdown_gh[scope1_breakdown_gh.columns[-1]]=='No'),\n               (scope1_breakdown_gh[scope1_breakdown_gh.columns[-1]].isnull())]\n\nvalues34 = [2, 1, 0]\n\nscope1_breakdown_gh['Scope1_by_GH_gas_type'] = np.select(conditions34, values34)\n\nmapping_scope1_breakdown_gh = dict(scope1_breakdown_gh[['account_number',\n                                                        'Scope1_by_GH_gas_type']].values)","d2bd4db6":"## pull data related to the section Question\nscope1_breakdown_business_unit = \\\n    PullDataCorpClimate2020('C7. Emissions breakdowns',\n                            'C7.3')\n## check structure\n#scope1_breakdown_business_unit.head()\n\n## Mapping this feature 35\n## Indicate which gross global Scope 1 emissions breakdowns you are able to provide\n## By business division - 1\n## By activity - 1\n## By facility - 1\n## By activity; By business division - 2\n## By activity; By facility - 2\n## By business division; By facility - 2\n## By activity; By business division; By facility - 3\n## NAN - 0 \n\nconditions35 = [(scope1_breakdown_business_unit\\\n                [scope1_breakdown_business_unit.columns[-1]]=='By business division'),\n                (scope1_breakdown_business_unit\\\n                [scope1_breakdown_business_unit.columns[-1]]=='By activity'),\n                (scope1_breakdown_business_unit\\\n                [scope1_breakdown_business_unit.columns[-1]]=='By facility'),\n                (scope1_breakdown_business_unit\\\n                [scope1_breakdown_business_unit.columns[-1]]=='By activity; By business division'),\n                (scope1_breakdown_business_unit\\\n                [scope1_breakdown_business_unit.columns[-1]]=='By activity; By facility'),\n                (scope1_breakdown_business_unit\\\n                [scope1_breakdown_business_unit.columns[-1]]=='By business division; By facility'),\n                (scope1_breakdown_business_unit\\\n                [scope1_breakdown_business_unit.columns[-1]]=='By activity; By business division; By facility'),\n                (scope1_breakdown_business_unit\\\n                [scope1_breakdown_business_unit.columns[-1]].isnull())]\n                \nvalues35 = [1, 1, 1, 2, 2, 2, 3, 0]\n\nscope1_breakdown_business_unit['BusinessUnit'] = np.select(conditions35,values35)\n\nmapping_scope1_business_unit = dict(scope1_breakdown_business_unit[['account_number',\n                                                                    'BusinessUnit']].values)","89124852":"## pull data related to the section Question\nenergy_os \\\n    = PullDataCorpClimate2020('C8. Energy',\n                              'C8.1')\n\n## will add two columns for upper and lower limit\n## strip lower figure, strip %, convert to numerical\nenergy_os['OP_spend%_on_energy_lower'] = \\\n    energy_os['What_percentage_of_your_total_operational_spend_in_the_reporting_year_was_on_energy?']\\\n        .str[:-30].str[-3:].str.strip('%').str.strip('n').str.strip()\nenergy_os['OP_spend%_on_energy_lower'] = pd.to_numeric(energy_os['OP_spend%_on_energy_lower'], errors='coerce').fillna(0)\n\nenergy_os['OP_spend%_on_energy_upper'] = \\\n    energy_os['What_percentage_of_your_total_operational_spend_in_the_reporting_year_was_on_energy?']\\\n        .str[-4:].str.strip('now').str.strip('k').str.rstrip('%').str.strip()\nenergy_os['OP_spend%_on_energy_upper'] = pd.to_numeric(energy_os['OP_spend%_on_energy_upper']).fillna(0)\n\nenergy_os_reshaped = energy_os.drop(['row_number','What_percentage_of_your_total_operational_spend_in_the_reporting_year_was_on_energy?'],\n              axis=1)\n## Mapping this feature 36\nmapping_OP_spend_on_energy_lower = \\\n    dict(energy_os[['account_number',\n                    'OP_spend%_on_energy_lower']].values)\n\nmapping_OP_spend_on_energy_upper = \\\n    dict(energy_os[['account_number',\n                    'OP_spend%_on_energy_upper']].values)","7c12215b":"## pull data related to the section Question\nenergy_activities = \\\n    PullDataCorpClimate2020('C8. Energy','C8.2')\n\n## reshape\nenergy_activities_reshaped = \\\n    DatasetReshape2(energy_activities)\n\n#energy_activities_reshaped.head()\n\n## Mapping this feature 37 - 43\n## Select_which_energy_related_activities_your_organization_has_undertaken\n## Yes - 2\n## No - 1\n## NAN - 0\n\n##Fuel\nconditions37 = [(energy_activities_reshaped[energy_activities_reshaped.columns[4]]=='Yes'),\n               (energy_activities_reshaped[energy_activities_reshaped.columns[4]]=='No'),\n               (energy_activities_reshaped[energy_activities_reshaped.columns[4]].isnull())]\nvalues37 = [2, 1, 0]\n\nenergy_activities_reshaped['fuel'] = np.select(conditions37,values37)\n\n##Cooling\nconditions38 = [(energy_activities_reshaped[energy_activities_reshaped.columns[5]]=='Yes'),\n               (energy_activities_reshaped[energy_activities_reshaped.columns[5]]=='No'),\n               (energy_activities_reshaped[energy_activities_reshaped.columns[5]].isnull())]\nvalues38 = [2, 1, 0]\n\nenergy_activities_reshaped['cooling'] = np.select(conditions38,values38)\n\n##electricity\nconditions39 = [(energy_activities_reshaped[energy_activities_reshaped.columns[6]]=='Yes'),\n               (energy_activities_reshaped[energy_activities_reshaped.columns[6]]=='No'),\n               (energy_activities_reshaped[energy_activities_reshaped.columns[6]].isnull())]\nvalues39 = [2, 1, 0]\n\nenergy_activities_reshaped['electricity'] = np.select(conditions39,values39)\n\n##heat\nconditions40 = [(energy_activities_reshaped[energy_activities_reshaped.columns[7]]=='Yes'),\n               (energy_activities_reshaped[energy_activities_reshaped.columns[7]]=='No'),\n               (energy_activities_reshaped[energy_activities_reshaped.columns[7]].isnull())]\nvalues40 = [2, 1, 0]\n\nenergy_activities_reshaped['heat'] = np.select(conditions40,values40)\n\n##steam\nconditions41 = [(energy_activities_reshaped[energy_activities_reshaped.columns[8]]=='Yes'),\n               (energy_activities_reshaped[energy_activities_reshaped.columns[8]]=='No'),\n               (energy_activities_reshaped[energy_activities_reshaped.columns[8]].isnull())]\nvalues41 = [2, 1, 0]\n\nenergy_activities_reshaped['steam'] = np.select(conditions41,values41)\n\n##generation\nconditions42 = [(energy_activities_reshaped[energy_activities_reshaped.columns[9]]=='Yes'),\n               (energy_activities_reshaped[energy_activities_reshaped.columns[9]]=='No'),\n               (energy_activities_reshaped[energy_activities_reshaped.columns[9]].isnull())]\nvalues42 = [2, 1, 0]\n\nenergy_activities_reshaped['energy_generation'] = np.select(conditions42,values42)\n\nmapping_energy_activity_consumption_fuel = \\\n    dict(energy_activities_reshaped[['account_number','fuel']].values)\n\nmapping_energy_activity_consumption_cooling = \\\n    dict(energy_activities_reshaped[['account_number','cooling']].values)\n\nmapping_energy_activity_consumption_electricity = \\\n    dict(energy_activities_reshaped[['account_number','electricity']].values)\n\nmapping_energy_activity_consumption_heat = \\\n    dict(energy_activities_reshaped[['account_number','heat']].values)\n\nmapping_energy_activity_consumption_steam = \\\n    dict(energy_activities_reshaped[['account_number','steam']].values)\n\nmapping_energy_activity_generation = \\\n    dict(energy_activities_reshaped[['account_number','energy_generation']].values)","df958a9e":"## pull data related to the section Question\nenergy_consumption = \\\n    PullDataCorpClimate2020('C8. Energy',\n                            'C8.2a')\n#energy_consumption.head()\n\n## reshape\nenergy_consumption_reshaped = \\\n    DatasetReshape(energy_consumption)\n\n## convert to numeric\nfor col in (list(range(11,32))):\n    energy_consumption_reshaped[list(energy_consumption_reshaped.columns)[col]]\\\n     = pd.to_numeric(energy_consumption_reshaped\\\n                    [list(energy_consumption_reshaped.columns)[col]]).fillna(0)\n\n#energy_consumption_reshaped.head()\n\n## Mapping this feature 44\n## subset all MWh consumption data to map\ncolumns_to_drop = np.r_[1:11]\nmapping_energy_comsumption = \\\n    energy_consumption_reshaped.\\\n        drop(energy_consumption_reshaped.columns[columns_to_drop], \n             axis=1)","ed0123ed":"## pull data related to the section Question\nfuel_consumption_applications = \\\n    PullDataCorpClimate2020('C8. Energy',\n                            'C8.2b')\n\nfuel_consumption_applications_reshaped = \\\n    DatasetReshape2(fuel_consumption_applications)\n\n#fuel_consumption_applications_reshaped.head()\n\n## Mapping this feature 45 - 49\n## Select_the_applications_of_your_organization's_consumption_of_fuel\n## Yes - 2\n## No - 1\n## NAN - 0\n\n##for co-generation or tri-generation\nconditions45 = [(fuel_consumption_applications_reshaped[fuel_consumption_applications_reshaped.columns[4]]=='Yes'),\n               (fuel_consumption_applications_reshaped[fuel_consumption_applications_reshaped.columns[4]]=='No'),\n               (fuel_consumption_applications_reshaped[fuel_consumption_applications_reshaped.columns[4]].isnull())]\nvalues45 = [2, 1, 0]\n\nfuel_consumption_applications_reshaped['co_generation'] = np.select(conditions45,values45)\n\n##generation of cooling\nconditions46 = [(fuel_consumption_applications_reshaped[fuel_consumption_applications_reshaped.columns[5]]=='Yes'),\n               (fuel_consumption_applications_reshaped[fuel_consumption_applications_reshaped.columns[5]]=='No'),\n               (fuel_consumption_applications_reshaped[fuel_consumption_applications_reshaped.columns[5]].isnull())]\nvalues46 = [2, 1, 0]\n\nfuel_consumption_applications_reshaped['generation_cooling'] = np.select(conditions46,values46)\n\n##generation of electricity\nconditions47 = [(fuel_consumption_applications_reshaped[fuel_consumption_applications_reshaped.columns[6]]=='Yes'),\n               (fuel_consumption_applications_reshaped[fuel_consumption_applications_reshaped.columns[6]]=='No'),\n               (fuel_consumption_applications_reshaped[fuel_consumption_applications_reshaped.columns[6]].isnull())]\nvalues47 = [2, 1, 0]\n\nfuel_consumption_applications_reshaped['generation_electricity'] = np.select(conditions47,values47)\n\n##generation of heat\nconditions48 = [(fuel_consumption_applications_reshaped[fuel_consumption_applications_reshaped.columns[7]]=='Yes'),\n               (fuel_consumption_applications_reshaped[fuel_consumption_applications_reshaped.columns[7]]=='No'),\n               (fuel_consumption_applications_reshaped[fuel_consumption_applications_reshaped.columns[7]].isnull())]\nvalues48 = [2, 1, 0]\n\nfuel_consumption_applications_reshaped['generation_heat'] = np.select(conditions48,values48)\n\n##steam\nconditions49 = [(fuel_consumption_applications_reshaped[fuel_consumption_applications_reshaped.columns[8]]=='Yes'),\n               (fuel_consumption_applications_reshaped[fuel_consumption_applications_reshaped.columns[8]]=='No'),\n               (fuel_consumption_applications_reshaped[fuel_consumption_applications_reshaped.columns[8]].isnull())]\nvalues49 = [2, 1, 0]\n\nfuel_consumption_applications_reshaped['generation_steam'] = np.select(conditions49,values49)\n\nmapping_fuel_consumption_co_generation = \\\n    dict(fuel_consumption_applications_reshaped[['account_number','co_generation']].values)\n\nmapping_fuel_consumption_generation_cooling = \\\n    dict(fuel_consumption_applications_reshaped[['account_number','generation_cooling']].values)\n\nmapping_fuel_consumption_generation_electricity = \\\n    dict(fuel_consumption_applications_reshaped[['account_number','generation_electricity']].values)\n\nmapping_fuel_consumption_generation_heat = \\\n    dict(fuel_consumption_applications_reshaped[['account_number', 'generation_heat']].values)\n\nmapping_fuel_consumption_generation_steam = \\\n    dict(fuel_consumption_applications_reshaped[['account_number','generation_steam']].values)","473f7ad0":"## pull data related to the section Question\nfuel_consumption_MWh = \\\n    PullDataCorpClimate2020('C8. Energy','C8.2c')\n\n## reshape\nfuel_consumption_MWh_reshaped = \\\n    DatasetReshape(fuel_consumption_MWh)\n#fuel_consumption_MWh_reshaped.head()\n\n##this will be useful in analysis but not in clustering","6421f3df":"## pull data related to the section Question\nenergy_generated_consumed = \\\n    PullDataCorpClimate2020('C8. Energy','C8.2d')\n\n## reshape\nenergy_generated_consumed_reshaped =\\\n    DatasetReshape(energy_generated_consumed)\n\n## convert to numeric\nfor col in (list(range(4,20))):\n    energy_generated_consumed_reshaped[list(energy_generated_consumed_reshaped.columns)[col]]\\\n     = pd.to_numeric(energy_generated_consumed_reshaped\\\n                    [list(energy_generated_consumed_reshaped.columns)[col]]).fillna(0)\n    \n## Mapping this feature 50\n## subset all MWh energy generated consumed\nmapping_energy_generated_consumed = \\\n    energy_generated_consumed_reshaped.\\\n    drop(energy_generated_consumed_reshaped.columns[1:4],\n         axis=1)","545aca1d":"## pull data related to the section Question\nzero_factor_emissions = \\\n    PullDataCorpClimate2020('C8. Energy',\n                            'C8.2e')\n\n#zero_factor_emissions.head()\n\n## reshape\nzero_factor_emissions_reshaped = \\\n    DatasetReshape(zero_factor_emissions)\n#zero_factor_emissions_reshaped.head()\n\n## this information will be usefull in analysis \n## but not in clustering I think","d42032c6":"## pull data related to the section Question\nengagement_with_vc = \\\n    PullDataCorpClimate2020('C12. Engagement','C12.1')\n\n#engagement_with_vc.head()\n\n## Mapping this feature 51\n## Do you engage with your value chain on climate-related issues?\n## Yes - 2\n## No - 1\n## Nan - 0\n\nconditions51 = [(engagement_with_vc[engagement_with_vc.columns[-1]]=='No, we do not engage'),\n                (engagement_with_vc[engagement_with_vc.columns[-1]]=='Yes, our customers; Yes, our suppliers'),\n                (engagement_with_vc[engagement_with_vc.columns[-1]]=='Yes, other partners in the value chain; Yes, our customers; Yes, our suppliers'),\n                (engagement_with_vc[engagement_with_vc.columns[-1]]=='Yes, our customers'),\n                (engagement_with_vc[engagement_with_vc.columns[-1]]=='Yes, our suppliers'),\n                (engagement_with_vc[engagement_with_vc.columns[-1]]=='Yes, other partners in the value chain; Yes, our suppliers'),\n                (engagement_with_vc[engagement_with_vc.columns[-1]]=='Yes, other partners in the value chain; Yes, our customers'),\n                (engagement_with_vc[engagement_with_vc.columns[-1]]=='Yes, other partners in the value chain'),\n                (engagement_with_vc[engagement_with_vc.columns[-1]]=='Yes, other partners in the value chain; Yes, our customers; Yes, our investee companies; Yes, our suppliers'),\n                (engagement_with_vc[engagement_with_vc.columns[-1]]=='Yes, our customers; Yes, our investee companies; Yes, our suppliers'),\n                (engagement_with_vc[engagement_with_vc.columns[-1]]=='Yes, our investee companies; Yes, our suppliers'),\n                (engagement_with_vc[engagement_with_vc.columns[-1]]=='Yes, other partners in the value chain; Yes, our customers; Yes, our investee companies'),\n                (engagement_with_vc[engagement_with_vc.columns[-1]]=='Yes, our customers; Yes, our investee companies'),\n                (engagement_with_vc[engagement_with_vc.columns[-1]]=='Yes, our investee companies'),\n                (engagement_with_vc[engagement_with_vc.columns[-1]]=='Yes, other partners in the value chain; Yes, our investee companies'),\n                (engagement_with_vc[engagement_with_vc.columns[-1]].isnull())]\n                \nvalues51 = [1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0]\n\nengagement_with_vc['ValueChainEngagement'] = np.select(conditions51,values51)\n\nmapping_engagement_vc = dict(engagement_with_vc[['account_number',\n                                                 'ValueChainEngagement']].values)","7c999208":"## pull data related to the section Question\nvc_engagement_strategy = \\\n    PullDataCorpClimate2020('C12. Engagement','C12.1a')\n\n##reshape\nvc_engagement_strategy_reshaped = \\\n    DatasetReshape(vc_engagement_strategy)\n\n#vc_engagement_strategy_reshaped.head()\n\n## this info will be useful in analysis section","8e63ef73":"## I will concatenate all NUMERICAL FEATURES with base to run clustering algorithm\n\n## collect extracted features in list\nmapping_numerical_features = [mapping_scope1,\n                              mapping_scope2_loc,\n                              mapping_scope2_mar,\n                              mapping_scope3_Business_travel,\n                              mapping_scope3_Capital_goods,\n                              mapping_scope3_Downstream_leased_assets,\n                              mapping_scope3_transportation_and_distribution,\n                              mapping_scope3_Employee_commuting,\n                              mapping_scope3_End_of_life_treatment_of_sold_products,\n                              mapping_scope3_Franchises,\n                              mapping_scope3_energy_related_activities,\n                              mapping_scope3_Investments,\n                              mapping_scope3_Downstream_other,\n                              mapping_scope3_Upstream_other,\n                              mapping_scope3_processing_sold_products,\n                              mapping_scope3_purchased_goods_services,\n                              mapping_scope3_upstream_leased_assets,\n                              mapping_scope3_upstream_transportation_and_distribution,\n                              mapping_scope3_sold_products,\n                              mapping_intensity_scaler_value,\n                              mapping_intensity_change,\n                              mapping_OP_spend_on_energy_lower,\n                              mapping_OP_spend_on_energy_upper]\n\n#mapping_energy_comsumption #- this is pd.df\n#mapping_energy_generated_consumed #- this is pd.df\n\n## initiate new dataframe\ncorporations2020_numerical = pd.DataFrame(corp_dc_cl_2020_clean['account_number'])","bf0973b1":"## loop to concatanate all numerical features\nfor i in range(len(mapping_numerical_features)):\n    corporations2020_numerical[i] = corporations2020_numerical['account_number'].map(mapping_numerical_features[i])\n    \n## merge dfs\ncorporations2020_numerical = \\\n    pd.merge(corporations2020_numerical, mapping_energy_comsumption, on='account_number').\\\n    merge(mapping_energy_generated_consumed, on='account_number')","410ad598":"corporations2020_numerical.shape","2393fdb7":"### Will keep encoded categorical features to run another clustering \nmapping_features_categorical = [mapping_listed,\n                    mapping_report_year,\n                    mapping_past_year_data,\n                    mapping_multinational,\n                    mapping_currency,\n                    mapping_boundary,\n                    mapping_short_term_defined,\n                    mapping_medium_term_defined,\n                    mapping_long_term_defined,\n                    mapping_rmp,\n                    mapping_acute_physical_risk,\n                    mapping_chronic_physical_risk,\n                    mapping_current_regulation_risk,\n                    mapping_emerging_regulation_risk,\n                    mapping_legal_risk,\n                    mapping_market_risk,\n                    mapping_reputation_risk,\n                    mapping_technology_risk,\n                    mappig_risk_impacts,\n                    mapping_risk_financial_impact,\n                    mapping_opp_impact,\n                    mapping_opp_financial_impact,\n                    mapping_emission_target_setting,\n                    mapping_target1_status,\n                    mapping_emission_reduction_initiative,\n                    mapping_no_initiatives_commenced,\n                    mapping_no_initiatives_implemented,\n                    mapping_lowcarbon_output,\n                    mapping_scope1_breakdown_gh,\n                    mapping_scope1_business_unit,\n                    mapping_energy_activity_consumption_fuel,\n                    mapping_energy_activity_consumption_cooling,\n                    mapping_energy_activity_consumption_electricity,\n                    mapping_energy_activity_consumption_heat,\n                    mapping_energy_activity_consumption_steam,\n                    mapping_energy_activity_generation,\n                    mapping_engagement_vc]\n\n## initiate new dataframe\ncorporations2020_categorical = pd.DataFrame(corp_dc_cl_2020_clean['account_number'])","831dc604":"## loop to concatanate all encoded features\nfor i in range(len(mapping_features_categorical)):\n    corporations2020_categorical[i] = corporations2020_categorical['account_number'].map(mapping_features_categorical[i])","ed1363bb":"corporations2020_categorical.shape","afb821b9":"## combine categorical and numerical\n\ncorporations2020_all_features = pd.DataFrame(corp_dc_cl_2020_clean['account_number'])\n\nmapping_features_all = mapping_features_categorical + mapping_numerical_features\nfor i in range(len(mapping_features_all)):\n    corporations2020_all_features[i] = corporations2020_all_features['account_number'].map(mapping_features_all[i])\n    \n## merge dfs\ncorporations2020_all_features = \\\n    pd.merge(corporations2020_all_features, mapping_energy_comsumption, on='account_number').\\\n    merge(mapping_energy_generated_consumed, on='account_number')","8f9e0314":"## Fuzzy C-mean clustering, unsupervised learning\n## ON NUMERICAL DATA\n\n#################### Preprocessing #####################\ndf_fuzzy = corporations2020_numerical\ncolumns = list(df_fuzzy.columns)\n## selecy feature columns\nx = df_fuzzy[columns[13:len(columns)]]\n## keep 'account_number' to reasign clusters\ny = df_fuzzy[columns[0]]\n\n## feature normalization\nscaler = StandardScaler()\nX_std = scaler.fit_transform(x)\n\n## diamensionality reduction \nlsa = TruncatedSVD(2, algorithm = 'arpack')\ndtm_lsa = lsa.fit_transform(X_std)\n\n## Scaling inputs to unit norms\ndtm_lsa = Normalizer(copy=False).fit_transform(dtm_lsa)\n\n## Store components in dataframe\na= pd.DataFrame(dtm_lsa, columns = [\"component_1\",\"component_2\"])\n\n## Bind to account number\na['account_number']= y\n\n## for visualizing first try of clustering our data several times, \n## with between 2 and 9 clusters\nfig1, axes1 = plt.subplots(3, 3, figsize=(8, 8))\n\n## reshape into array to feed to clustering algorithm\nalldata_num = np.vstack((a['component_1'], a['component_2']))\n\n## fpc - fuzzy partition coefficients\nfpcs_num = []\n\n## to color points\ncolors = ['b', 'orange', 'g', 'r', 'c', 'm', 'y', 'k', 'Brown', 'ForestGreen']\n\n#################### CLUSTER & PLOT ##################\n\nfor ncenters, ax in enumerate(axes1.reshape(-1), 2):\n    cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n        alldata_num, ncenters, 2, error=0.005, maxiter=1000, init=None)\n    \n    # Store fpc values for later plots\n    fpcs_num.append(fpc)\n\n    # Plot assigned clusters, for each data point\n    cluster_membership = np.argmax(u, axis=0)\n    for j in range(ncenters):\n        ax.plot(a['component_1'][cluster_membership == j],\n                a['component_2'][cluster_membership == j], '.', color=colors[j])\n\n   # Mark the center of each fuzzy cluster\n    for pt in cntr:\n        ax.plot(pt[0], pt[1], 'rs')\n\n    ax.set_title('Centers = {0}; FPC = {1:.2f}'.format(ncenters, fpc))\n    ax.axis('off')\n\nfig1.tight_layout() ","dd6a0cad":"## plot the fuzzy partition coefficient. \n## When the FPC is maximized, our data is described best.\nfig2, ax2 = plt.subplots()\nax2.plot(np.r_[2:11], fpcs_num)\nax2.set_xlabel(\"Number of centers\")\nax2.set_ylabel(\"Fuzzy partition coefficient\")\n## set ylim from 0.6 to better see the difference between results\nplt.ylim((0.6,1));\n\n## Optimal number of clusters (highest FCP) is 2,\n## however there is no large difference with 3 clusters","1e3dbf12":"########## Run Clustering Algorithm on ENCODED CATEGORICAL ##########\n\n#################### Preprocessing #####################\ndf_fuzzy = corporations2020_categorical\ncolumns = list(df_fuzzy.columns)\n## selecy feature columns\nx = df_fuzzy[columns[13:len(columns)]]\n## keep 'account_number' to reasign clusters\ny = df_fuzzy[columns[0]]\n\n## feature normalization\nscaler = StandardScaler()\nX_std = scaler.fit_transform(x)\n\n## diamensionality reduction \nlsa = TruncatedSVD(2, algorithm = 'arpack')\ndtm_lsa = lsa.fit_transform(X_std)\n\n## Scaling inputs to unit norms\ndtm_lsa = Normalizer(copy=False).fit_transform(dtm_lsa)\n\n## Store components in dataframe\na= pd.DataFrame(dtm_lsa, columns = [\"component_1\",\"component_2\"])\n\n## Bind to account number\na['account_number']= y\n\n## for visualizing first try of clustering our data several times, \n## with between 2 and 9 clusters\nfig1, axes1 = plt.subplots(3, 3, figsize=(8, 8))\n\n## reshape into array to feed to clustering algorithm\nalldata_cat = np.vstack((a['component_1'], a['component_2']))\n\n## fpc - fuzzy partition coefficients\nfpcs_cat = []\n\n## to color points\ncolors = ['b', 'orange', 'g', 'r', 'c', 'm', 'y', 'k', 'Brown', 'ForestGreen']\n\n#################### CLUSTER & PLOT ##################\n\nfor ncenters, ax in enumerate(axes1.reshape(-1), 2):\n    cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n        alldata_cat, ncenters, 2, error=0.005, maxiter=1000, init=None)\n    \n    # Store fpc values for later plots\n    fpcs_cat.append(fpc)\n\n    # Plot assigned clusters, for each data point\n    cluster_membership = np.argmax(u, axis=0)\n    for j in range(ncenters):\n        ax.plot(a['component_1'][cluster_membership == j],\n                a['component_2'][cluster_membership == j], '.', color=colors[j])\n\n   # Mark the center of each fuzzy cluster\n    for pt in cntr:\n        ax.plot(pt[0], pt[1], 'rs')\n\n    ax.set_title('Centers = {0}; FPC = {1:.2f}'.format(ncenters, fpc))\n    ax.axis('off')\n\nfig1.tight_layout() ","0fdc9c80":"########### Run Clustering on NUMERICAL and CATEGORICAL (encoded) ##################\n\n#################### Preprocessing #####################\ndf_fuzzy = corporations2020_all_features\ncolumns = list(df_fuzzy.columns)\n## selecy feature columns\nx = df_fuzzy[columns[13:len(columns)]]\n## keep 'account_number' to reasign clusters\ny = df_fuzzy[columns[0]]\n\n## feature normalization\nscaler = StandardScaler()\nX_std = scaler.fit_transform(x)\n\n## diamensionality reduction \nlsa = TruncatedSVD(2, algorithm = 'arpack')\ndtm_lsa = lsa.fit_transform(X_std)\n\n## Scaling inputs to unit norms\ndtm_lsa = Normalizer(copy=False).fit_transform(dtm_lsa)\n\n## Store components in dataframe\na= pd.DataFrame(dtm_lsa, columns = [\"component_1\",\"component_2\"])\n\n## Bind to account number\na['account_number']= y\n\n## for visualizing first try of clustering our data several times, \n## with between 2 and 9 clusters\nfig1, axes1 = plt.subplots(3, 3, figsize=(8, 8))\n\n## reshape into array to feed to clustering algorithm\nalldata_all = np.vstack((a['component_1'], a['component_2']))\n\n## fpc - fuzzy partition coefficients\nfpcs_all = []\n\n## to color points\ncolors = ['b', 'orange', 'g', 'r', 'c', 'm', 'y', 'k', 'Brown', 'ForestGreen']\n\n#################### CLUSTER & PLOT ##################\n\n## discussion of parameters https:\/\/pythonhosted.org\/scikit-fuzzy\/api\/skfuzzy.cluster.html \n\nfor ncenters, ax in enumerate(axes1.reshape(-1), 2):\n    cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n        alldata_all, ncenters, 2, error=0.005, maxiter=1000, init=None)\n    \n    # Store fpc values for later plots\n    fpcs_all.append(fpc)\n\n    # Plot assigned clusters, for each data point\n    cluster_membership = np.argmax(u, axis=0)\n    for j in range(ncenters):\n        ax.plot(a['component_1'][cluster_membership == j],\n                a['component_2'][cluster_membership == j], '.', color=colors[j])\n\n   # Mark the center of each fuzzy cluster\n    for pt in cntr:\n        ax.plot(pt[0], pt[1], 'rs')\n\n    ax.set_title('Centers = {0}; FPC = {1:.2f}'.format(ncenters, fpc))\n    ax.axis('off')\n\nfig1.tight_layout() ","8a1a0a7e":"## PLOT 2 CLUSTER MODEL, numerical features\n\ncntr, u, u0, d, jm, p, fpc_n = fuzz.cluster.cmeans(\n    alldata_num, 2, 2, error=0.005, maxiter=1000)\n\n# Show 2-cluster model\nfig2, ax2 = plt.subplots()\nax2.set_title('On numercial features only')\ncluster_membership = np.argmax(u, axis=0)\nfor j in range(2):\n    ax2.plot(alldata_num[0, u.argmax(axis=0) == j],\n             alldata_num[1, u.argmax(axis=0) == j], 'o',\n             label='cluster' + str(j))\nax2.legend();","6ae767eb":"print('FCP: ', fpc_n *100,'%')","a722b91c":"## PLOT 2 CLUSTER MODEL, categorical features\n\ncntr, u, u0, d, jm, p, fpc_c = fuzz.cluster.cmeans(\n    alldata_cat, 2, 2, error=0.005, maxiter=1000)\n\n# Show 2-cluster model\nfig2, ax2 = plt.subplots()\nax2.set_title('On categorical features only')\ncluster_membership = np.argmax(u, axis=0)\nfor j in range(2):\n    ax2.plot(alldata_cat[0, u.argmax(axis=0) == j],\n             alldata_cat[1, u.argmax(axis=0) == j], 'o',\n             label='cluster' + str(j))\nax2.legend();","fc0a1c47":"print('FCP: ', fpc_c *100,'%')","75d71cee":"## PLOT 2 CLUSTER MODEL, all features\n\ncntr, u, u0, d, jm, p, fpc_a = fuzz.cluster.cmeans(\n    alldata_all, 2, 2, error=0.005, maxiter=1000)\n\n# Show 2-cluster model\nfig2, ax2 = plt.subplots()\nax2.set_title('On all features')\ncluster_membership = np.argmax(u, axis=0)\nfor j in range(2):\n    ax2.plot(alldata_all[0, u.argmax(axis=0) == j],\n             alldata_all[1, u.argmax(axis=0) == j], 'o',\n             label='cluster' + str(j))\nax2.legend();","32d53301":"print('FCP: ', fpc_a *100,'%')","de967bb0":"## Based on the above results\n## I have decided to cluster based on numercial feature only and using two clusters\n\n######## Input Data ########\nclustering_data = corporations2020_numerical\n\n## select feature columns \ncolumns = list(clustering_data.columns)\nfeatures = clustering_data[columns[13:len(columns)]]\n\n## Standardize features by removing the mean and scaling to unit variance\nscaler = StandardScaler()\nX_features_std = scaler.fit_transform(features)\n\n## Dimensionality reduction using truncated SVD \nlsa = TruncatedSVD(2, algorithm = 'arpack')\ndtm_lsa = lsa.fit_transform(X_features_std)\n\n## Normalize each row of the data matrix individually to unit norm\ndtm_lsa = Normalizer(copy=False).fit_transform(dtm_lsa)\n\n## Store normaliazed and scaled features in dataframe\nfeatures_normalized = pd.DataFrame(dtm_lsa, columns = [\"component_1\",\"component_2\"])\n\n## Add 'account number' as the primary key for subsequent cluster mapping\nfeatures_normalized['account_number'] = clustering_data[columns[0]]\n\n## reshape into array to feed to clustering algorithm\nalldata = np.vstack((features_normalized['component_1'],\n                     features_normalized['component_2']))\n\n######## Save Model based on 2 clusters ########\ncorporates2clusters = fuzz.cluster.cmeans(alldata, 2, 2, error=0.005, maxiter=1000)\n\n######## Outputs of the trained model ########\ncluster_centers = corporates2clusters[0]\nfinal_fuzzy_c_partitioned_matrix = corporates2clusters[1]\nnumber_of_iterations = corporates2clusters[5]\nfuzzy_partitioned_coefficient = corporates2clusters[6]\n\n##Assign cluster based on index of max membership\ncluster_membership = np.argmax(final_fuzzy_c_partitioned_matrix, axis=0)\n\n##Map clusters to dataframe of normalized features\nfeatures_normalized['cluster'] = cluster_membership\n\n###Finally map clusters to original (base) dataframe\ncorporations2020 = pd.merge(corporations2020, features_normalized, on='account_number')","a01b53d4":"### visualize\ncntr, u, u0, d, jm, p, fpc = corporates2clusters\n\n# Show 2-cluster model\nfig2, ax2 = plt.subplots()\nax2.set_title('On Numerical Features')\ncluster_membership = np.argmax(u, axis=0)\nfor j in range(2):\n    ax2.plot(alldata[0, u.argmax(axis=0) == j],\n             alldata[1, u.argmax(axis=0) == j], 'o',\n             label='cluster' + str(j))\nax2.legend();","2ff1a301":"### related datasets\n#general.head()\n#corporations2020.head()","71368512":"### Corporations by industry in cluster 0\n\n#corporations2020 = pd.merge(corporations2020, \n                           # corporations2020_all_features[['account_number','cluster']],\n                          # on='account_number')\n\ndata1 = corporations2020[corporations2020['cluster'] == 0]\n\nfig = plt.figure(figsize = (8,6))\n#sns.set_theme(style=\"white\")\nax = fig.add_subplot(111)\n\nax.set_title(\"Corporations in cluster <<0>> aggregated by industry\", fontsize=14)\nax.set_ylabel(\"\")\nax.set_xlabel(\"\") \nax.tick_params(axis='both', which='major', labelsize=12)\nax.spines['right'].set_visible(False)\nax.spines['top'].set_visible(False)\n\nindustry = data1['primary_industry'].value_counts()\nindustry = (list(industry.index), list(industry.values))\nbar = ax.barh(industry[0], industry[1], color='steelblue')\n\ntotal = len(data1)\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))   ","d70f588d":"### Corporations by industry in cluster 1\n\ndata2 = corporations2020[corporations2020['cluster'] == 1]\n\nfig = plt.figure(figsize = (8,6))\n#sns.set_theme(style=\"white\")\nax = fig.add_subplot(111)\n\nax.set_title(\"Corporations in cluster <<1>> aggregated by industry\", fontsize=14)\nax.set_ylabel(\"\")\nax.set_xlabel(\"\") \nax.tick_params(axis='both', which='major', labelsize=12)\nax.spines['right'].set_visible(False)\nax.spines['top'].set_visible(False)\n\nindustry = data2['primary_industry'].value_counts()\nindustry = (list(industry.index), list(industry.values))\nbar = ax.barh(industry[0], industry[1], color='steelblue')\n\ntotal = len(data2)\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))   ","d69a7cc7":"##check\n#len(data2) + len(data1)\n\nprint('Total corporations clustered in <<0>>: ',len(corporations2020[corporations2020['cluster']==0]))\nprint('Total corporations clustered in <<1>>: ',len(corporations2020[corporations2020['cluster']==1]))","84897288":"fig = plt.figure(figsize = (12, 8))\nfig.subplots_adjust(top=0.85, wspace=0.5)\nfig.tight_layout()\n#sns.set_theme(style=\"darkgrid\")\n\n## Plot Activities represented in Manufacturing Industry for corporations in cluster <<0>>######################\ndata3 = corporations2020[(corporations2020['cluster'] == 0) &\n                        (corporations2020['primary_industry'] == 'Manufacturing')]\n\nax1 = fig.add_subplot(1,2,1)\n\nax1.set_title(\"Activities represented in Manufacturing \\nIndustry for corporations in cluster <<0>>\",fontsize=12)\nax1.set_xlabel(\"\") \nax1.tick_params(axis='both', which='major', labelsize=10)\nax1.spines['right'].set_visible(False)\nax1.spines['top'].set_visible(False)\n\npr_m = data3['primary_activity'].value_counts()\npr_m = (list(pr_m.index), list(pr_m.values))\nbar = ax1.barh(pr_m[0], pr_m[1], color='brown')\n\n## Plot Activities represented in Manufacturing Industry for corporations in cluster <<1>>#######################\ndata4 = corporations2020[(corporations2020['cluster'] == 1) &\n                        (corporations2020['primary_industry'] == 'Manufacturing')]\n\nax2 = fig.add_subplot(1,2,2)\n\nax2.set_title(\"Activities represented in Manufacturing \\nIndustry for corporations in cluster <<1>>\", fontsize=12)\nax2.set_xlabel(\"\")\nax2.tick_params(axis='both', which='major', labelsize=10)\nax2.spines['right'].set_visible(False)\nax2.spines['top'].set_visible(False)\n\npr_s = data4['primary_activity'].value_counts()\npr_s = (list(pr_s.index), list(pr_s.values))\nbar = ax2.barh(pr_s[0], pr_s[1], color='orange')","e773a572":"fig = plt.figure(figsize = (12, 8))\nfig.subplots_adjust(top=0.85, wspace=0.5)\nfig.tight_layout()\n#sns.set_theme(style=\"darkgrid\")\n\n## Plot Activities represented in Service Industry for corporations in cluster <<0>>######################\ndata5 = corporations2020[(corporations2020['cluster'] == 0) &\n                        (corporations2020['primary_industry'] == 'Services')]\n\nax1 = fig.add_subplot(1,2,1)\n\nax1.set_title(\"Activities represented in Service \\nIndustry for corporations in cluster <<0>>\",fontsize=12)\nax1.set_xlabel(\"\") \nax1.tick_params(axis='both', which='major', labelsize=10)\nax1.spines['right'].set_visible(False)\nax1.spines['top'].set_visible(False)\n\npr_m = data5['primary_activity'].value_counts()\npr_m = (list(pr_m.index), list(pr_m.values))\nbar = ax1.barh(pr_m[0], pr_m[1], color='#295b78')\n\n## Plot Activities represented in Manufacturing Industry for corporations in cluster <<1>>#######################\ndata6 = corporations2020[(corporations2020['cluster'] == 1) &\n                        (corporations2020['primary_industry'] == 'Services')]\n\nax2 = fig.add_subplot(1,2,2)\n\nax2.set_title(\"Activities represented in Service \\nIndustry for corporations in cluster <<1>>\", fontsize=12)\nax2.set_xlabel(\"\")\nax2.tick_params(axis='both', which='major', labelsize=10)\nax2.spines['right'].set_visible(False)\nax2.spines['top'].set_visible(False)\n\npr_s = data6['primary_activity'].value_counts()\npr_s = (list(pr_s.index), list(pr_s.values))\nbar = ax2.barh(pr_s[0], pr_s[1], color='#042436')","fbdc4912":"### related datasets\n## r_corp_cl_2020_clean - original ds prior cleaning and reshaping, contains original info\n## general - contains general description of corporations\n## reporting_period_reshaped - subset contains period reporting dates\n## corporations2020 - reshaped with clusters information added\n## energy_os_reshaped\n## energy_activities_reshaped\n## energy_consumption_reshaped","37f5b9c6":"energy_os_reshaped['OP_spend%_on_energy_upper'].hist();","a99d48ca":"## not running on kaggle platform\n#import seaborn as sns; sns.set()\n\n#sns.set_theme(style=\"darkgrid\")\n#sns.displot(energy_os_reshaped_cluster,\n           # x=\"OP_spend%_on_energy_upper\", \n           # col=\"cluster\", \n           # binwidth=1, height=4, facet_kws=dict(margin_titles=True));","cb90fd2a":"#energy_activities_reshaped.head()","5e797e38":"## Plot Number of responses to energy question \n## 'Select Which Energy \\nrelated activities your \n## organization has undertaken'\n## Responses encoded as: No reponse - 0, \n## No - 1, \n## Yes -2'\n\n#energy_activities_reshaped\n\n## reshape to plot\nenergy_activities_reshaped_chart = \\\n    pd.melt(energy_activities_reshaped.drop\\\n            (energy_activities_reshaped.columns[0:10],\n             axis=1))\n\n## group by variable and produce count of values for each\nenergy_activities_reshaped_heatmap = \\\n    energy_activities_reshaped_chart.\\\n    groupby('variable')['value'].value_counts().unstack()\n\n\n##Annotated heatmaps\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#sns.set_theme()\n\n# Draw a heatmap with the numeric values in each cell\nf, ax = plt.subplots(figsize=(9, 6))\nsns.heatmap(energy_activities_reshaped_heatmap, \n            annot=True, \n            fmt=\"d\", \n            linewidths=.5, \n            ax=ax, \n            cmap='Blues')\nax.tick_params(axis='both', \n               which='major', \n               labelsize=14)\nplt.xlabel(\"\")\nplt.ylabel(\"\")\nplt.title(\"\"\"\n            Number of corporations responding to question:\n            Select Which Energy related activities \n            your organization has undertaken \n            No reponse - 0, No - 1, Yes - 2\n          \"\"\",\n         size=14)\nplt.show();","834048b9":"## adding cluster information\nenergy_activities_reshaped_cluster = \\\n    pd.merge(energy_activities_reshaped,\n             corporations2020[['account_number',\n                               'selected_tier',\n                               'authority_types',\n                               'cluster', \n                               'tickers']], \n             on='account_number')\n\n\n## companies that did not respond\nenergy_activities_reshaped_cluster_NAN = \\\n    energy_activities_reshaped_cluster\\\n        [energy_activities_reshaped_cluster['electricity']==0]\n\n## collect account references for further analysis\nlist_accounts_non_responding_C8_2 = energy_activities_reshaped_cluster_NAN['account_number'].tolist()\nenergy_activities_reshaped_cluster_NAN.tail(30)","f1950ad2":"#energy_consumption_reshaped.head(3).style.set_properties(**{'text-align': 'left'})\nenergy_consumption_reshaped_cluster = pd.merge(energy_consumption_reshaped,\n                                              corporations2020[['account_number',\n                                                                'cluster']],\n                                              on='account_number')","025fb211":"## Prepare data for ploting distribution of energy consumption\n## by type from Renewable resources\n\ncolumns_to_drop = np.r_[1,4:11]\nenergy_consumption_reshaped_density_plot = \\\n        energy_consumption_reshaped_cluster.\\\n            drop(energy_consumption_reshaped_cluster.columns\\\n                 [columns_to_drop], \n                 axis=1)\n\n### melt all types of energy consumption from renewables\nenergy_consumption_reshaped_density_plot_1 = \\\n    pd.melt(energy_consumption_reshaped_density_plot,\n            id_vars = ['account_number','primary_activity', 'cluster'])","d82f353f":"## list of variable to plot\nenergy_con_from_rn = ['C8.2a_C2MWh from renewable sources_Consumption of fuel (excluding feedstock)',\n                  'C8.2a_C2MWh from renewable sources_Consumption of purchased or acquired cooling',\n                  'C8.2a_C2MWh from renewable sources_Consumption of purchased or acquired electricity',\n                  'C8.2a_C2MWh from renewable sources_Consumption of purchased or acquired heat',\n                  'C8.2a_C2MWh from renewable sources_Consumption of purchased or acquired steam',\n                  'C8.2a_C2MWh from renewable sources_Consumption of self-generated non-fuel renewable energy']\n\nimport seaborn as sns\n#sns.set_theme(style=\"ticks\", palette=\"pastel\")\nsns.boxplot(y='variable', \n            x=\"value\",\n            data=energy_consumption_reshaped_density_plot_1\\\n                [energy_consumption_reshaped_density_plot_1['variable'].isin(energy_con_from_rn)])\n\nsns.despine(offset=10, trim=True)","1b592da3":"## check outlier\nenergy_consumption_reshaped_density_plot.\\\n    sort_values(by='C8.2a_C2MWh from renewable sources_Consumption of purchased or acquired electricity', \n                ascending=False)\\\n[['account_number','primary_activity','cluster',\n  'C8.2a_C2MWh from renewable sources_Consumption of purchased or acquired electricity']].head()\n\n## account 8634 reported 939,184,788 MWh from renewable sources","877a2e31":"from matplotlib.pyplot import figure\nfigure(figsize=(12,3))\n\nplt.boxplot(energy_consumption_reshaped_density_plot\\\n            ['C8.2a_C2MWh from renewable sources_Consumption of purchased or acquired electricity'],\n            vert=False, patch_artist=True)\n\nplt.xlabel(\"<-MWh_from_renewable_Consumption_electricity->\", fontsize=14)\n\nplt.text(11,1.3, \"The extreme value represents account 8634 from Other non-ferrous ore mining\", \n         fontsize=14,\n        bbox={'facecolor': 'yellow', 'edgecolor': 'yellow', 'alpha': 0.2, 'pad': 8});","1c633120":"## it is highly unlikely value\n# (939184788\/energy_consumption_reshaped_density_plot['MWh_from_renewable_Consumption_electricity'].sum())*100\n## 71% of total reported consumed electricity that came from Renewable Sources reported by sample\ncorporations2020[corporations2020['account_number']==8634]","379a66c2":"## droping outlier acc 8634\ndata10 = \\\n    energy_consumption_reshaped_density_plot\\\n        [energy_consumption_reshaped_density_plot['account_number']!=8634]\\\n        [['primary_activity','cluster', 'primary_industry',\n          'C8.2a_C2MWh from renewable sources_Consumption of purchased or acquired electricity']]\n\ndata10.groupby(['primary_activity','primary_industry','cluster']).\\\n    agg(sum_ = pd.NamedAgg(column=\\\n                           'C8.2a_C2MWh from renewable sources_Consumption of purchased or acquired electricity',\n                           aggfunc=np.sum),\n        mean_ = pd.NamedAgg(column=\\\n                            'C8.2a_C2MWh from renewable sources_Consumption of purchased or acquired electricity', \n                            aggfunc=np.mean),\n        median_ = pd.NamedAgg(column=\\\n                              'C8.2a_C2MWh from renewable sources_Consumption of purchased or acquired electricity', \n                              aggfunc=np.median)).\\\n                        nlargest(40, 'sum_').\\\n                            reset_index().\\\n                                round(decimals=0).\\\n                                    style.bar(subset=['sum_','mean_','median_'], color='#d65f5f')","dc65ee4a":"## check outlier\nenergy_consumption_reshaped_density_plot.\\\n    sort_values(by='C8.2a_C2MWh from renewable sources_Consumption of fuel (excluding feedstock)', \n                ascending=False)\\\n[['account_number','primary_activity','cluster',\n  'C8.2a_C2MWh from renewable sources_Consumption of fuel (excluding feedstock)']].head(20)\n\n## account 9352 reported 96,670,410.47 MWh of consumed fuel from renewable sources","5491ccc6":"from matplotlib.pyplot import figure\nfigure(figsize=(12,3))\n\nplt.boxplot(energy_consumption_reshaped_density_plot\\\n            ['C8.2a_C2MWh from renewable sources_Consumption of fuel (excluding feedstock)'],\n            vert=False, patch_artist=True)\n\nplt.xlabel(\"<-MWh_from_renewable_Consumption_electricity->\", fontsize=14)\n\nplt.text(11,1.3, \"The extreme value represents account 9352 from Paper packaging activity\", \n         fontsize=14,\n        bbox={'facecolor': 'yellow', 'edgecolor': 'yellow', 'alpha': 0.2, 'pad': 8});","ad20cd2d":"## list of variable to plot\nenergy_con_from_NONrn = ['C8.2a_C3MWh from non-renewable sources_Consumption of fuel (excluding feedstock)',\n       'C8.2a_C3MWh from non-renewable sources_Consumption of purchased or acquired cooling',\n       'C8.2a_C3MWh from non-renewable sources_Consumption of purchased or acquired electricity',\n       'C8.2a_C3MWh from non-renewable sources_Consumption of purchased or acquired heat',\n       'C8.2a_C3MWh from non-renewable sources_Consumption of purchased or acquired steam',\n       'C8.2a_C3MWh from non-renewable sources_Consumption of self-generated non-fuel renewable energy']\n\nimport seaborn as sns\n#sns.set_theme(style=\"ticks\", palette=\"pastel\")\nsns.boxplot(y='variable', \n            x=\"value\",\n            data=energy_consumption_reshaped_density_plot_1\\\n                [energy_consumption_reshaped_density_plot_1['variable'].isin(energy_con_from_NONrn)])\n\nsns.despine(offset=10, trim=True)","8bccb1e5":"## check outlier\nenergy_consumption_reshaped_density_plot.\\\n    sort_values(by='C8.2a_C3MWh from non-renewable sources_Consumption of purchased or acquired electricity', \n                ascending=False)\\\n[['account_number','primary_activity','cluster',\n  'C8.2a_C3MWh from non-renewable sources_Consumption of purchased or acquired electricity']].head()","9ab25356":"## want to check all info on these \"outliers\"\noutliers_electricity_non_rn = [3848, 46940, 8634, 699, 35322]\n\npd.merge(general[general['account_number'].isin(outliers_electricity_non_rn)],\n         reporting_period_reshaped[reporting_period_reshaped['account_number']\\\n                                   .isin(outliers_electricity_non_rn)]\\\n         [['account_number','C0.2_C1Start date_Reporting year']], on='account_number')\n         \n## all (outliers) organization report for year 2019, so dates are not reason\n\n## at least '3848' reported figure is unlikely","c48c69c1":"## droping outlier acc 8634\ndata12 = \\\n    energy_consumption_reshaped_density_plot\\\n        [energy_consumption_reshaped_density_plot['account_number']!=3848]\\\n        [['primary_activity','cluster', 'primary_industry',\n          'C8.2a_C3MWh from non-renewable sources_Consumption of purchased or acquired electricity']]\n\ndata12.groupby(['primary_activity','primary_industry','cluster']).\\\n    agg(sum_ = pd.NamedAgg(column=\\\n                           'C8.2a_C3MWh from non-renewable sources_Consumption of purchased or acquired electricity',\n                           aggfunc=np.sum),\n        mean_ = pd.NamedAgg(column=\\\n                            'C8.2a_C3MWh from non-renewable sources_Consumption of purchased or acquired electricity', \n                            aggfunc=np.mean),\n        median_ = pd.NamedAgg(column=\\\n                              'C8.2a_C3MWh from non-renewable sources_Consumption of purchased or acquired electricity', \n                              aggfunc=np.median)).\\\n                        nlargest(20, 'sum_').\\\n                            reset_index().\\\n                                round(decimals=0).\\\n                                    style.bar(subset=['sum_','mean_','median_'], color='#d65f5f')","c18d31b4":"(2364460000 + 700963342)\/(data12['C8.2a_C3MWh from non-renewable sources_Consumption of purchased or acquired electricity']\\\n                          .sum())*100\n\nprint(\"\"\"\nChecking information on account 46940 on the company website, it appears \nmore accurate classification of nature of their business is Manufacturing of industrial solutions. \nThis might explain inconsistency with such high reported consumption of electricity \n\"\"\")\nprint(2364460000\/(data12['C8.2a_C3MWh from non-renewable sources_Consumption of purchased or acquired electricity'].sum())*100, '% of total and printing services as primary activity')","1a09627d":"## check outlier\nenergy_consumption_reshaped_density_plot.\\\n    sort_values(by='C8.2a_C3MWh from non-renewable sources_Consumption of fuel (excluding feedstock)', \n                ascending=False)\\\n[['account_number','primary_activity','cluster',\n  'C8.2a_C3MWh from non-renewable sources_Consumption of fuel (excluding feedstock)']].head()","70d686c2":"## it is more likely than not that reported figures are good estimates, \n## as all accounts are in category of Environment Sensitve Industries.","85cf614a":"## Drop outliers as discussed above,\n## These values are likely to be errors and will\n## bias analysis\n\n## Organizations that did not respond to questionnaire: \nlist_accounts_non_responding_C8_2\nunlikely_high_values_C8_2a = [8634,3848,46940]\naccounts_to_drop_energy_C_8_2a = list_accounts_non_responding_C8_2 + unlikely_high_values_C8_2a\n\n#energy_consumption_reshaped_density_plot.columns","a0b29b67":"## list of variable to plot\nenergy_con_Total = ['C8.2a_C2MWh from renewable sources_Total energy consumption',\n       'C8.2a_C3MWh from non-renewable sources_Total energy consumption',\n       'C8.2a_C4Total (renewable and non-renewable) MWh_Total energy consumption']\n\nenergy_consumption_reshaped_density_plot_1_dropped_acc = \\\n    energy_consumption_reshaped_density_plot_1\\\n    [energy_consumption_reshaped_density_plot_1\\\n     ['account_number'].isin(accounts_to_drop_energy_C_8_2a) == False]\n\n\nimport seaborn as sns\n#sns.set_theme(style=\"ticks\", palette=\"pastel\")\nsns.boxplot(y='variable', \n            x=\"value\",\n            data=energy_consumption_reshaped_density_plot_1\\\n                [energy_consumption_reshaped_density_plot_1['variable'].isin(energy_con_Total)])\n\nsns.despine(offset=10, trim=True)","9900e46d":"## drop outliers\nenergy_consumption_reshaped_density_plot_drop_acc = \\\n    energy_consumption_reshaped_density_plot\\\n    [energy_consumption_reshaped_density_plot['account_number']\\\n     .isin(accounts_to_drop_energy_C_8_2a) == False]\n\n## drop very small values <100\nenergy_consumption_reshaped_density_plot_drop_acc = \\\n    energy_consumption_reshaped_density_plot_drop_acc\\\n    [energy_consumption_reshaped_density_plot_drop_acc\\\n     ['C8.2a_C4Total (renewable and non-renewable) MWh_Total energy consumption']>100]\n\n\nenergy_consumption_reshaped_density_plot_drop_acc.\\\n    sort_values(by='C8.2a_C4Total (renewable and non-renewable) MWh_Total energy consumption', \n                ascending=False)\\\n[['account_number','primary_activity','cluster',\n  'C8.2a_C2MWh from renewable sources_Total energy consumption',\n 'C8.2a_C3MWh from non-renewable sources_Total energy consumption',\n 'C8.2a_C4Total (renewable and non-renewable) MWh_Total energy consumption']].head(10)","919f4584":"import squarify\nplt.figure(figsize=(15, 8))\n\ndata14 = energy_consumption_reshaped_density_plot_drop_acc\n\ndata15 = data14.groupby('primary_activity').\\\n    agg(MWh_Total_energy_consumption = \\\n        pd.NamedAgg(column=\\\n                    'C8.2a_C4Total (renewable and non-renewable) MWh_Total energy consumption',\n                           aggfunc=np.sum),\n        mean_ = \\\n        pd.NamedAgg(column=\\\n                    'C8.2a_C4Total (renewable and non-renewable) MWh_Total energy consumption', \n                            aggfunc=np.mean)).\\\n        nlargest(10, 'MWh_Total_energy_consumption').\\\n        reset_index().round(decimals=0)\n\n\n#(data15['MWh_Total_energy_consumption'].sum()) \/ (data14['C8.2a_C4Total (renewable and non-renewable) MWh_Total energy consumption'].sum())\n\nlabels = data15['primary_activity']\n\ncolors = [plt.cm.Spectral(i\/float(len(labels))) for i in range(len(labels))]\n\nsquarify.plot(sizes=(data15['MWh_Total_energy_consumption']),label=labels, color=colors)\n\nplt.title(\"Ten top activities by energy consumption reported 68% of total energy consumed MWh\",\n         fontsize=14);","3c231545":"data16 = data14.groupby('primary_activity').\\\n    agg(MWh_Total_EC_from_Renewable_sources = \\\n        pd.NamedAgg(column=\\\n                    'C8.2a_C2MWh from renewable sources_Total energy consumption',\n                           aggfunc=np.sum),\n        mean_ = \\\n        pd.NamedAgg(column=\\\n                    'C8.2a_C2MWh from renewable sources_Total energy consumption', \n                            aggfunc=np.mean)).\\\n        nlargest(10, 'MWh_Total_EC_from_Renewable_sources').\\\n        reset_index().round(decimals=0)","1a20e929":"data14['Perc_of_renewable_sourcing'] = data14\\\n['C8.2a_C2MWh from renewable sources_Total energy consumption']\/data14['C8.2a_C4Total (renewable and non-renewable) MWh_Total energy consumption'] *100","7de681b1":"data14[['account_number','primary_activity','cluster',\n        'C8.2a_C2MWh from renewable sources_Total energy consumption',\n        'C8.2a_C4Total (renewable and non-renewable) MWh_Total energy consumption',\n        'Perc_of_renewable_sourcing']].\\\n        nlargest(20,'C8.2a_C4Total (renewable and non-renewable) MWh_Total energy consumption').\\\n        style.bar(subset=['C8.2a_C4Total (renewable and non-renewable) MWh_Total energy consumption',\n                          'Perc_of_renewable_sourcing'], color='darkorange')","d9c657f8":"#Interesting exception Paper packaging companies\n#general[general['primary_activity']=='Paper packaging']","cecd6939":"### related datasets\n## r_corp_cl_2020_clean - original ds prior cleaning and reshaping, contains original info\n## general - contains general description of corporations\n## reporting_period_reshaped - subset contains period reporting dates\n## corporations2020 - reshaped with clusters information added\n## energy_consumption_reshaped\n## scope1\n## intensity_metrics_reshaped","2be5577d":"data_C6_1_C1 = scope1[scope1[scope1.columns[-1]]!=0]\ndata_C6_1_C1.groupby('primary_activity').\\\n    agg(sum_CO2e_Scope1_mt = pd.NamedAgg(column=scope1.columns[-1], aggfunc=np.sum),\n        mean_ = pd.NamedAgg(column=scope1.columns[-1], aggfunc=np.mean),\n        median_ = pd.NamedAgg(column=scope1.columns[-1], aggfunc=np.median)).\\\n                        nlargest(30, 'sum_CO2e_Scope1_mt').\\\n                            reset_index().\\\n                                round(decimals=0).\\\n                                    style.bar(subset=['sum_CO2e_Scope1_mt','mean_','median_'], color='#ada49a')","fb3dab9c":"## will sum up first 30 groups of activities\nscope1_top_30 = data_C6_1_C1.groupby('primary_activity').\\\n    agg(sum_ = pd.NamedAgg(column=scope1.columns[-1], aggfunc=np.sum),\n        mean_ = pd.NamedAgg(column=scope1.columns[-1], aggfunc=np.mean),\n        median_ = pd.NamedAgg(column=scope1.columns[-1], aggfunc=np.median)).\\\n                        nlargest(30, 'sum_').\\\n                            reset_index().\\\n                                round(decimals=0)\n\nscope1_top_30['sum_'].sum()\nscope1_top_30\nprint('30 groups of activities contribute ',\n      scope1_top_30['sum_'].sum()\/ data_C6_1_C1[scope1.columns[-1]].sum() * 100,\n      '% of reported Scope 1 CO2e mt emissions')","fe4bc411":"#### this code does not run on kaggle platform\n\n## filter organizations in this 40 groups as subset for analysis\n#activities = scope1_top_30.primary_activity.unique()\n#largest_by_scope1 = data_C6_1_C1[data_C6_1_C1['primary_activity'].isin(activities)]\n#largest_by_scope1 = \\\n    #largest_by_scope1.sort_values(by='C6.1_C1Gross global Scope 1 emissions (metric tons CO2e)_Reporting year')\n\n#import seaborn as sns\n#fig = plt.figure(figsize=(12,6))\n#ax = sns.kdeplot(largest_by_scope1\\\n                 #['C6.1_C1Gross global Scope 1 emissions (metric tons CO2e)_Reporting year'],\n                 #hue=largest_by_scope1['primary_industry'],\n                 #multiple='fill')\n\n#ax.set_title(\"Density of reported Scope 1 CO2e emissions (mt) aggregated by industry\",\n            #fontsize=14)\n#ax.set_xlabel(\"\")\n#plt.savefig('scope1_plot.png')\n#plt.show();","f90ec1f9":"energy_and_direct_emissions = \\\n    pd.merge(energy_consumption_reshaped_cluster\\\n             [['account_number',\n              'organization',\n              'primary_activity',\n              'primary_industry',\n               'cluster',\n              'C8.2a_C2MWh from renewable sources_Total energy consumption',\n              'C8.2a_C4Total (renewable and non-renewable) MWh_Total energy consumption']],\n            scope1[['account_number',\n                    'C6.1_C1Gross global Scope 1 emissions (metric tons CO2e)_Reporting year']],\n            on='account_number')","567cea16":"data20 = energy_and_direct_emissions.sort_values\\\n    (by='C6.1_C1Gross global Scope 1 emissions (metric tons CO2e)_Reporting year',\n     ascending=False).head(15).\\\n    style.bar(subset=['C6.1_C1Gross global Scope 1 emissions (metric tons CO2e)_Reporting year',\n                      'C8.2a_C4Total (renewable and non-renewable) MWh_Total energy consumption'], \n              color='#e7ed95')\n\ndata20","5e8c0c48":"# importing necessary libraries \nfrom sklearn import linear_model \nfrom sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error \nfrom sklearn.model_selection import train_test_split\n\n# prepare data, drop list of accounts likely errors and non-reported\naccounts_to_drop_energy_C_8_2a\ndf = energy_and_direct_emissions\\\n    [energy_and_direct_emissions['account_number'].\\\n         isin(accounts_to_drop_energy_C_8_2a)==False]\n\ndf = df.rename({'C8.2a_C4Total (renewable and non-renewable) MWh_Total energy consumption': 'TotalEnergyConsumedMWh',\n               'C6.1_C1Gross global Scope 1 emissions (metric tons CO2e)_Reporting year': 'DirectEmissionsCO2e_mt'},axis=1)\n\n\n# features into variables \nenergy = df[['TotalEnergyConsumedMWh']] \nco2eq = df[['DirectEmissionsCO2e_mt']]","bda1c0cd":"# spliting data in train and test with train_test_split \nenergy_treino, energy_test, co2eq_treino, co2eq_test = train_test_split(energy, co2eq, test_size=0.2, random_state=42)\n\n# ploting the correlation between features on train dataset\nplt.scatter(energy_treino, co2eq_treino, color='#2d3001')\nplt.xlabel('energy')\nplt.ylabel('co2eq direct emission')\nplt.show()","2afdede1":"# creating a linear regression model\nmodel_ee = linear_model.LinearRegression()\nmodel_ee.fit(energy_treino, co2eq_treino)\nprint(f'(A) intercept: {model_ee.intercept_} | (B) regression coefficient: {model_ee.coef_}')","10d2b4ef":"# run on TEST dataset\nplt.scatter(energy_test, co2eq_test, color='#27112e')\nplt.plot(energy_test, model_ee.coef_[0][0]*energy_test + model_ee.intercept_[0], '-r')\nplt.ylabel('Direct CO2eq emissions mt')\nplt.xlabel('Energy consumption MWh')\nplt.show()","bc973f39":"#check the accuracy of model\n# The coefficients\nco2eq_pred = model_ee.predict(co2eq_test)\nprint('Coefficients: \\n', model_ee.coef_)\n\n# The mean squared error\nprint('Mean squared error: %.2f'\n      % mean_squared_error(co2eq_test, co2eq_pred))\n\n# The coefficient of determination: 1 is perfect prediction\nprint('Coefficient of determination: %.2f'\n      % r2_score(co2eq_test, co2eq_pred))","9857266d":"test_data = data14[['account_number',\n                    'primary_activity',\n                    'primary_industry',\n                    'cluster',\n                    'C8.2a_C2MWh from renewable sources_Total energy consumption',\n                    'C8.2a_C4Total (renewable and non-renewable) MWh_Total energy consumption',\n                    'Perc_of_renewable_sourcing']]\n\n#test_data.sort_values(by='Perc_of_renewable_sourcing', ascending=False)","3992a3da":"## draw from sample of accounts\nimport random  \nfrom random import sample\nrandom.seed(42) \nrandom.sample(list(test_data['account_number']), 1)","c25d1f2f":"test_data[test_data['account_number']==56728]","6dff56ad":"test_data[(test_data['primary_activity']=='Automobiles') &\n          (test_data['primary_industry']=='Manufacturing')]['Perc_of_renewable_sourcing'].describe()","4be5afd2":"corporations2020[corporations2020['primary_activity']=='Passenger airlines']['cluster']","363a72d0":"pd.merge(intensity_metrics_reshaped[['account_number', \n                            'C6.10_C4Metric denominator: Unit total_1', \n                            'C6.10_C3Metric denominator_1']],corporations2020[['account_number',\n                                                                              'organization',\n                                                                              'primary_activity','cluster']],\n         on='account_number').nlargest(20,'C6.10_C4Metric denominator: Unit total_1')","87cb6adb":"#### <span style='color:#808000'>Operational Spend on Energy<\/span>\n\n*The response is in the form: more than...(OP_spend%_on_energy_lower) but less than or equal to...(OP_spend%_on_energy_upper)*","0c301e4e":"C2.1a': 'How does your organization define short-, medium- and long-term time horizons?","baa72850":"#### <span style='color:#808000'>C12. Engagement<\/span>","78061fc0":"#### <span style='color:#808000'>C8. Energy<\/span>","1660c619":"###  <span style='color: #001A8C'>Final Clustering Model<\/span>","17970a76":"#### <span style='color:#808000'>C7. Emissions breakdowns<\/span>","28dc4c39":"### Data Preprocessing <a class=\"anchor\" id=\"data\"><\/a>\n\n- Import Libraries\n\n- Load (truncated) dataset\n\n- Data Summarization\n\n- Helper functions and dictionaries\n\n- Data extraction for each main question, cleaning and mapping\n\n- Data Preprocessing Output","4b21a5b8":"<center>*\u201cAs complexity rises, precise statements lose meaning and meaningful statements lose precision\u201d*<\/center>\n\n<center>Lotfi A. Zadeh (Artificial  Intelligence  expert  and  father  of Fuzzy  Mathematical  Logic)<\/center>","1789c101":"**C7.1': 'Does your organization break down its Scope 1 emissions by greenhouse gas type?**","bb5267bb":"**Global Scope1 emissions reported by corporations**","8ca99ae4":"**C2.2:Describe your process(es) for identifying, assessing and responding to climate-related risks and opportunities.**","2ff2e8c9":"**Energy Consumption and Emissions**","684e5dee":"Majority of corporations in sample spend upto 20% of operational expense on their energy consumption. Is there difference between clusters?","aa25b39f":"**C8.1': 'What percentage of your total operational spend in the reporting year was on energy?**","62de22b4":"**C8.2c': 'State how much fuel in MWh your organization has consumed (excluding feedstocks) by fuel type**","379e3742":"**C12.1': 'Do you engage with your value chain on climate-related issues?**","d6e32fe0":"**'C0.2': 'State the start and end date of the year for which you are reporting data.'**","f1c47c7b":"**C4.3b': 'Provide details on the initiatives implemented in the reporting year in the table below.**","e49bd778":"**C6.3': 'What were your organization's gross global Scope 2 emissions in metric tons CO2e?**","da48dd95":"**Consumption of energy by type from RENEWABLE sources**","20160700":"###  <span style='color: #001A8C'>Analysis of Corporations Energy Consumption<\/span>","4de06037":"### Conclusion and KPI proposal <a class=\"anchor\" id=\"kpi\"><\/a>","ac70b7b6":"**C8.2b': 'Select the applications of your organization's consumption of fuel.**","ab6d44f2":"**C4.1b': 'Provide details of your emissions intensity target(s) and progress made against those target(s).**","595ba866":">Regression model explains about 26% of variations, not very good result. As it is known fact that energy consumption drives increase in emissions, one can conclude that data on which model is run is not very accurate.","93a8f4b6":"**'C0.5': 'Select the option that describes the reporting boundary for which climate-related impacts on your business are being reported.**","220887bd":"### <span style='color: #001A8C'>Data extraction for each main question<\/span>","96621f47":"**How -  to use dictionary and function to pull data from the main dataframe**\n*(energy module as an example)*\n\n1. Run all above cells: imports, data loading, dictionaries and helper functions\n2. Run **datasets_dictionary.keys()** to get exact name of section (module) of interest\n3. Run **datasets_dictionary['C8. Energy'].keys()** to get Question Numbers for each table in the section\n4. Run **datasets_dictionary['C8. Energy']['C8.1']** to read a Question\/ subject of responses and choose one of interest\n5. Run **PullDataCorpClimate2020('C8. Energy','C8.1')** to pull data related to section\/question of analysis\n6. If pulled df is NOT in 'one record per account (980 rows) form' still, one can use DatasetReshape()to reshape\n7. Concatenate resultant subsets via mapping progressivly into one final table of important features - output of this section.","34ce505b":"###  <span style='color: #001A8C'>Data Summarization<\/span>","1065b18c":"**<span style='color: #001A8C'>Commitment to decarbonization measured by the ratio of Total consumed Energy obtained from Renewable sources to the Total Energy consumed in the reporting period.** This measure is scalable to different entities, ESI industries with 'higher' energy bills and greater impact on 'decarbonization' will be penalized by 'low ratio'. Derived ratios then can be compared among corporations with similar characteristics to benchmark best performance or to identify unlikely outlier.<\/span>**","cfb3656c":"**C4.3': 'Did you have emissions reduction initiatives that were active within the reporting year? Note that this can include those in the planning and\/or implementation phases.**","8bd2ef06":"*Fuel from renewable sources*","e6b5fe4a":"#### Base - corporate metadata","ca1ff777":"###  <span style='color: #001A8C'>Load data (truncated)<\/span>","015faf53":"#### <span style='color:#808000'>Regression model <\/span>","4ec280cc":"**'C0.1': 'Give a general description and introduction to your organization.'**","721f0206":"#### <span style='color:#808000'>C0. Introduction<\/span>","7bb74093":"*Electricity from renewable sources, let us check outlier*","3cce99d2":"**'C4.3c': 'What methods do you use to drive investment in emissions reduction activities?'**","f08d1f2c":"**C4.1c': 'Explain why you did not have an emissions target, and forecast how your emissions will change over the next five years.**","fa4ddbb4":"<center>End of notebook<\/center>","a36c3fa3":"**C6.5': 'Account for your organization's gross global Scope 3 emissions, disclosing and explaining any exclusions.**","020e3324":"### [Introduction](#intro)\n\n### [Methodology](#method)\n\n### [Data Preprocessing](#data)\n\n### [Clustering model](#cluster)\n\n### [Analysis and visualizations](#analysis)\n\n### [Conclusion and KPI proposal](#kpi)","d00f65fd":"**C8.2': 'Select which energy-related activities your organization has undertaken.**","d31ef601":"![os_plot.png](attachment:os_plot.png)","ad85bcb9":"###  <span style='color: #001A8C'>Data preprocessing output<\/span>","37f7bcd1":"**C6.10': 'Describe your gross global combined Scope 1 and 2 emissions for the reporting year in metric tons CO2e per unit currency total revenue and provide any additional intensity metrics that are appropriate to your business operations.'**","17a79c38":"![IMG-20201130-WA0000.jpg](attachment:IMG-20201130-WA0000.jpg)","b1e77f83":"Our sample account is an average performer excluding outlier reported 100% ","5729860d":"**Total Energy Consumption from renewable and nonrenewable sources**","3192c0da":"**C2.3a': 'Provide details of risks identified with the potential to have a substantive financial or strategic impact on your business.**","07fc0d23":"![scope1_plot.png](attachment:scope1_plot.png)","2d029beb":"> At least visually there is a cleaner partition of membership when clustering by all features only.","b444ee66":"**C4.5a': 'Provide details of your products and\/or services that you classify as low-carbon products or that enable a third party to avoid GHG emissions.'**","a06f3562":"**'C0.4': 'Select the currency used for all financial information disclosed throughout your response.'**","e6e613e0":"**C2.4': 'Have you identified any climate-related opportunities with the potential to have a substantive financial or strategic impact on your business?**","6671a328":"###  <span style='color: #001A8C'>Helper functions and dictionaries<\/span>","35e7ef83":"**C8.2a': 'Report your organization's energy consumption totals (excluding feedstocks) in MWh.**","16fbbc91":"**C12.1a': 'Provide details of your climate-related supplier engagement strategy.**","3cb36cd6":"###  <span style='color: #001A8C'>What activities are represented in two clusters<\/span>","9462e411":"*Electricity consumption from Non renewable sources*","eb418c1d":"**C8.2d': 'Provide details on the electricity, heat, steam, and cooling your organization has generated and consumed in the reporting year.**","2a5d7a1f":"### Clustering model <a class=\"anchor\" id=\"cluster\"><\/a>","38d3161a":"**C4.3a': 'Identify the total number of initiatives at each stage of development, and for those in the implementation stages, the estimated CO2e savings.**","b30902b9":"**C2.4a': 'Provide details of opportunities identified with the potential to have a substantive financial or strategic impact on your business.**","87f06390":"**C8.2e: Provide details on the electricity, heat, steam, and\/or cooling amounts that were accounted for at a zero emission factor in the market-based Scope 2 figure reported in C6.3.**","ed39f9b9":"**C6.1': 'What were your organization's gross global Scope 1 emissions in metric tons CO2e?**","c2d29879":"**Consumption of energy by type from NON RENEWABLE sources**","8ecbeee4":"### Introduction <a class=\"anchor\" id=\"intro\"><\/a>","892bc1c8":"*Fuel consumption from Non renewable sources*","308f261e":"**C4.1a': 'Provide details of your absolute emissions target(s) and progress made against those targets.**","36ec5d58":"**C4.5': 'Do you classify any of your existing goods and\/or services as low-carbon products or do they enable a third party to avoid GHG emissions?**","02632ac3":"###  <span style='color: #001A8C'>Regression of direct CO2eq mt emissions on total energy consumed MWh<\/span>","6f2d23b7":"### Methodology <a class='anchor' id='method'><\/a>","4bdf755b":"> Corporations in 'Service Industry' are represented differently by % in both clusters. What distinguishes these two groups?","05686279":"**C2.3': 'Have you identified any inherent climate-related risks with the potential to have a substantive financial or strategic impact on your business?**","053b2ead":"#### <span style='color:#808000'>Energy consumption<\/span>","04fc0b96":"###  <span style='color: #001A8C'>Import Libraries<\/span>","a379be22":"#### <span style='color:#808000'>C6. Emissions data<\/span>","a2815630":"**C7.3': 'Indicate which gross global Scope 1 emissions breakdowns you are able to provide.**","72525829":"**Run example**","4a95556b":"**C2.2a': \"Which risk types are considered in your organization's climate-related risk assessments?\"**","55698f75":"The work consists of four steps:\n\n1. Data cleaning and preprocessing\n\n2. Applying unsupervised clustering algorithm to identify similar groups\n\n3. Analysis of partitioned data \n\n4. Key findings and derivation of KPI\n\n\nThe driving hypothesis: As it stands information reported by corporations is not verified for accuracy, therefore use of absolute figures from supplied data to formulate performance measures is not optimal. Instead my goal is to identify a verifiable and measurable proxy. By analysing data from similar groups it might be possible to deduce common features of 'decarbonization commitment'. \n\nAfter considering other clustering methods, I have decided to use Fuzzy C-means clustering. \n\n\nReferences:\n\nhttps:\/\/www.sciencedirect.com\/science\/article\/abs\/pii\/S0020025519307194\n\nhttps:\/\/www.researchgate.net\/publication\/221460808_What_Is_Fuzzy_about_Fuzzy_Clustering_Understanding_and_Improving_the_Concept_of_the_Fuzzifier\n\nhttps:\/\/dspace.cvut.cz\/bitstream\/handle\/10467\/85075\/F2-BP-2019-Bystricky-Krystof-ClusteringMethodsForDataAnalysis.pdf?sequence=-1&isAllowed=y\n\nhttps:\/\/pythonhosted.org\/scikit-fuzzy\/","4779763a":"**'C0.3': 'Select the countries\/areas for which you will be supplying data.'**","c93d02a4":"#### <span style='color:#808000'>C4. Targets and performance<\/span>","ce047ec0":"The distribution of consumed fuel from renewable resources is less skewed, and it is noticable that Paper packaging and Pulp & paper mills are largest contributors to this type of consumption.","36a2a780":"### Corporations in dataset<a class=\"anchor\" id=\"2\"><\/a>\n\n1. Description \n\n2. Reporting period\n\n3. Countries(multinational operations) covered\n\n4. Currency used in report\n\n5. Reporting boundary","0b0f9222":"#### <span style='color:#808000'>C2. Risks and opportunities<\/span>","c222510d":"The ratio is 15%, how good it compares to other organizations with similar charactetistics?","1c46baeb":"### ANALYSIS <a class=\"anchor\" id=\"analysis\"><\/a>","4897be80":"- It is possible that improved classification of survey participants by nature of their business will facilitate better analysis of their impact on the sustainability issues. Companies that did not respond to many questions might be small with limited budgets, unable to undertake costly measurement or employ specialist consultants. More applicable questionnaires scaled to main characteristic of segmented groups could improve quality of survey data and reduce 'non response' bias.\n\n\n- As it stands reported emission figures are not very reliable, and there is more certainty in reported energy consumption. Hence building performance metric on this feature could be more indicative of the **Decarbonization effort** undertaken by organizations. One method to reduce emissions without compromising our living conditions and industrial progress is to increase use of energy from renewable sources. Indead many organizations committed to 100% renewable energy sourcing, including Google global operations. ","b26b4778":"**C4.2b': 'Provide details of any other climate-related targets, including methane reduction targets.**","6b98fb09":"> Corporations in 'Manufacturing Industry' are represented in both clusters by large %. What distinguishes these two groups?","ab97edfc":"#### <span style='color:#808000'>Energy Activities<\/span>","b3a97239":">Electricity followed by fuel are most frequent energy related activities reported by the sample organizations. Cooling is the least reported energy related activity perhaps due to geographical representation. Subset of companies did not respond to question at all (encoded as 0).","525bb900":"The objective of this study is to identify patterns in the data supplied by Corporations in Climate2020 Survey conducted by CDP and to conjecture useful performance indicator related to sustainability goals.\n\n\nCDP made available surveyed data on 980 organizations with official registration licenses in United States and Canada. Sample also includes multinationals that report data for their global operations. The reporting period of disclosure varies among participants but majority cover 2019.\n\n*Disclosure of information*\n\nTo stress the importance of sustainability reporting it suffices to cite United nations goal on Sustainable Development Goals (SDG2030) that includes target on information disclosure:\n\n| Goal 12:          | Ensure sustainable consumption and production patterns                                                                                                                   |\n|-------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Target 12.6:      | Encourage companies, especially large and transnational companies, to adopt sustainable practices and to integrate sustainability information into their reporting cycle |\n| Indicator 12.6.1: | Number of companies publishing sustainability reports                                                                                                                    |"}}