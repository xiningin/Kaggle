{"cell_type":{"85a6a954":"code","4891f58c":"code","595d49a4":"code","cc4d9948":"code","9cb6f74f":"code","39be20ae":"code","3a501dce":"code","1bb3e47c":"code","e893d177":"code","732bb790":"code","4d8d0e2a":"code","f4c5a439":"code","92def6e3":"code","75ffd313":"code","b199c974":"code","74e82a56":"code","9ad27e87":"code","93d398c0":"code","cb2895c8":"code","62a63627":"code","cc7bdaaa":"code","06d770ba":"code","0c0d05d6":"code","7ed8dcdc":"code","a0e81e5a":"code","c149197b":"code","4d075ba8":"code","b835e3df":"code","e1113f1e":"code","9833c12b":"code","9a424c7e":"code","8c846a0b":"code","574626c3":"markdown","74b518af":"markdown"},"source":{"85a6a954":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns","4891f58c":"path = '..\/input\/air-passengers\/AirPassengers.csv'\ndf = pd.read_csv(path)\nprint(df.dtypes)\nprint(df.head())","595d49a4":"df['Month'] = pd.to_datetime(df['Month'])\nprint(df.dtypes)\nprint(df.head())","cc4d9948":"df.set_index('Month', inplace=True) \nprint(df.tail())\nplt.plot(df['#Passengers'])","9cb6f74f":"df['year'] = [d.year for d in df.index]\nprint(df.tail())\ndf['month'] = [d.strftime('%b') for d in df.index]\nprint(df.tail())\nyears = df['year'].unique()\nprint(years)","39be20ae":"#Plot yearly and monthly values as boxplot\nsns.boxplot(x='year', y='#Passengers', data=df)\nplt.figure()\nsns.boxplot(x='month', y='#Passengers', data=df)","3a501dce":"from statsmodels.tsa.seasonal import seasonal_decompose \ndecomposed = seasonal_decompose(df['#Passengers'],model ='additive')","1bb3e47c":"trend = decomposed.trend\nseasonal = decomposed.seasonal #Cyclic behavior may not be seasonal!\nresidual = decomposed.resid\n\nplt.figure(figsize=(12,8))\nplt.subplot(411)\nplt.plot(df['#Passengers'], label='Original', color='red')\nplt.legend(loc='upper left')\nplt.subplot(412)\nplt.plot(trend, label='Trend', color='red')\nplt.legend(loc='upper left')\nplt.subplot(413)\nplt.plot(seasonal, label='Seasonal', color='red')\nplt.legend(loc='upper left')\nplt.subplot(414)\nplt.plot(residual, label='Residual', color='red')\nplt.legend(loc='upper left')\nplt.show()","e893d177":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error","732bb790":"dataset = df['#Passengers'].values\ndataset = dataset.astype('float32')\ndataset = np.expand_dims(dataset,axis=-1)\nprint(dataset.shape)","4d8d0e2a":"plt.plot(dataset)","f4c5a439":"scaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)","92def6e3":"plt.plot(dataset)","75ffd313":"train_size = int(len(dataset) * 0.66)\ntest_size = len(dataset) - train_size\ntrain, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\nprint(len(dataset), train_size, test_size)","b199c974":"def to_sequences(dataset, seq_size):\n    x = []\n    y = []\n\n    for i in range(len(dataset)-seq_size-1):\n#         print(i)\n        window = dataset[i:(i+seq_size), 0]\n        x.append(window)\n        y.append(dataset[i+seq_size, 0])\n        \n    return np.array(x),np.array(y)","74e82a56":"seq_size = 20 # Number of time steps to look back \ntrainX, trainY = to_sequences(train, seq_size);\ntestX, testY = to_sequences(test, seq_size);","9ad27e87":"print(\"Shape of training set:\", trainX.shape, trainY.shape)\nprint(\"Shape of test set: \", testX.shape, testY.shape)\nprint(trainX[11], trainY[11])","93d398c0":"import tensorflow as tf\nimport tensorflow.keras","cb2895c8":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(64, input_dim=seq_size, activation='relu'), #12\n    tf.keras.layers.Dense(32, activation='relu'), #8\n    tf.keras.layers.Dense(1),\n])\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nprint(model.summary()) \ntf.keras.utils.plot_model(model, show_shapes=True)","62a63627":"model.fit(trainX, trainY, validation_data=(testX, testY),verbose=2, epochs=100)","cc7bdaaa":"trainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)","06d770ba":"trainPredict = scaler.inverse_transform(trainPredict) # predicted \ntrainY_inverse = scaler.inverse_transform([trainY]) # original\ntestPredict = scaler.inverse_transform(testPredict)\ntestY_inverse = scaler.inverse_transform([testY])","0c0d05d6":"import math\ntrainScore = math.sqrt(mean_squared_error(trainY_inverse[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\n\ntestScore = math.sqrt(mean_squared_error(testY_inverse[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore))","7ed8dcdc":"trainPredictPlot = np.empty_like(dataset)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[seq_size:len(trainPredict)+seq_size, :] = trainPredict   # answer will start from seq_size\n\n# shift test predictions for plotting\ntestPredictPlot = np.empty_like(dataset)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(trainPredict)+(seq_size*2)+1:len(dataset)-1, :] = testPredict\n\n# plot baseline and predictions\nplt.figure(figsize = (16,16))\nplt.plot(scaler.inverse_transform(dataset))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.show()","a0e81e5a":"from keras.layers import LSTM, Flatten","c149197b":"# Reshape input to be [samples, time steps, features]\nseq_size = 20 # Number of time steps to look back \ntrainX, trainY = to_sequences(train, seq_size);\ntestX, testY = to_sequences(test, seq_size);","4d075ba8":"trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))","b835e3df":"print(trainX.shape)","e1113f1e":"# Single LSTM with hidden Dense\nmodel = Sequential()\nmodel.add(LSTM(16, activation='relu', input_shape=(None, seq_size)))\nmodel.add(Dense(32))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\n\nprint(model.summary()) \ntf.keras.utils.plot_model(model, show_shapes=True)","9833c12b":"model.fit(trainX, trainY, validation_data=(testX, testY), verbose=2, epochs=100)","9a424c7e":"trainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\n\ntrainPredict = scaler.inverse_transform(trainPredict)\ntrainY = scaler.inverse_transform([trainY])\ntestPredict = scaler.inverse_transform(testPredict)\ntestY = scaler.inverse_transform([testY])\n\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\n\ntestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore))\n\n# shift train predictions for plotting\n#we must shift the predictions so that they align on the x-axis with the original dataset. \ntrainPredictPlot = np.empty_like(dataset)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[seq_size:len(trainPredict)+seq_size, :] = trainPredict\n\n# shift test predictions for plotting\ntestPredictPlot = np.empty_like(dataset)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(trainPredict)+(seq_size*2)+1:len(dataset)-1, :] = testPredict\n\n# plot baseline and predictions\nplt.plot(scaler.inverse_transform(dataset))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.show()","8c846a0b":"plt.figure(figsize = (12,12))\nplt.plot(scaler.inverse_transform(dataset))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.show()","574626c3":"Inspired by \n\nhttps:\/\/youtu.be\/tKM5d8Ll1k0\n\nhttps:\/\/github.com\/bnsreenu\/python_for_microscopists.git","74b518af":"# Comparison between ANN and LSTM result for Air Passengers Dataset using Tensorflow\n"}}