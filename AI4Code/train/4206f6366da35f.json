{"cell_type":{"668a9db4":"code","6a41df49":"code","36a32dcc":"code","6ed32451":"code","754117a3":"code","85535f0e":"code","9eb981e0":"code","53f6199a":"code","c3e08956":"code","a70ecf0e":"code","0d5e0fc2":"code","a9d9e90e":"code","bf509189":"code","66101bdb":"code","b68022ae":"code","591d1651":"code","718bf566":"code","e8124fdd":"code","ac56e3b5":"code","050d914b":"code","76c3a444":"code","597ef513":"code","3b8a4ab7":"code","8e205030":"code","6d7a6df5":"code","f7b47162":"code","59e25f5b":"code","194a7e90":"code","6da47d88":"code","fe556e19":"code","d346ac46":"code","6c2418be":"code","e237ac3a":"code","415bf0a2":"code","eb975f13":"code","5b1be2d6":"code","64e7c671":"code","c53174a7":"code","d2c8084a":"code","24a1fdc7":"markdown","cdfddc37":"markdown","a17e32dc":"markdown","1dc6b8cd":"markdown","ab7a90af":"markdown","70cf758a":"markdown","ff869fea":"markdown","792b589b":"markdown","3afc7be7":"markdown","eef77c95":"markdown","9f18fdbe":"markdown","a346bda4":"markdown"},"source":{"668a9db4":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport os\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_colwidth', -1)\nplt.style.use('fivethirtyeight')\nplt.rcParams['figure.figsize'] = [18, 8]","6a41df49":"rating = pd.read_csv('\/kaggle\/input\/anime-recommendations-database\/rating.csv')\nanime_df = pd.read_csv('\/kaggle\/input\/anime-recommendations-database\/anime.csv')\n\nprint('rating shape:', rating.shape)\nprint('anime_df shape:', anime_df.shape)","36a32dcc":"anime_df.head()","6ed32451":"null_features = anime_df.columns[anime_df.isna().any()]\nanime_df[null_features].isna().sum()","754117a3":"anime_df.dropna(inplace=True)","85535f0e":"# Perhaps anime name uses japanese or special character so the dataframe couldn't read that\n# I just cleaned some error for better names for recommendation\n\ndef text_cleaning(text):\n    text = re.sub(r'&quot;', '', text)\n    text = re.sub(r'.hack\/\/', '', text)\n    text = re.sub(r'&#039;', '', text)\n    text = re.sub(r'A&#039;s', '', text)\n    text = re.sub(r'I&#039;', 'I\\'', text)\n    text = re.sub(r'&amp;', 'and', text)\n    \n    return text\n\nanime_df['name'] = anime_df['name'].apply(text_cleaning)","9eb981e0":"type_count = anime_df['type'].value_counts()\n\nsns.barplot(x=type_count.values,\n            y=type_count.index,\n            palette='muted').set_title('Anime Types')\n\nplt.tight_layout()\nplt.show()","53f6199a":"from collections import defaultdict\n\nall_genres = defaultdict(int)\n\nfor genres in anime_df['genre']:\n    for genre in genres.split(','):\n        all_genres[genre.strip()] += 1","c3e08956":"from wordcloud import WordCloud\n\ngenres_cloud = WordCloud(width=800, height=400, background_color='white', colormap='gnuplot').generate_from_frequencies(all_genres)\n\nplt.imshow(genres_cloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","a70ecf0e":"anime_df[anime_df['episodes'] == 'Unknown']['name'][:5]","0d5e0fc2":"episodes_count = anime_df[anime_df['episodes'] != 'Unknown'][['name', 'episodes']]\nepisodes_count['episodes'] = pd.to_numeric(episodes_count['episodes'])\n\nepisodes_count.query('episodes>1500')","a9d9e90e":"anime_df[['name', 'rating', 'members', 'type']].sort_values(by='rating', ascending=False).query('members>500000')[:5]","bf509189":"anime_df[anime_df['type'] == 'Movie'][['name', 'rating', 'members', 'type']].sort_values(by='rating', ascending=False).query('members>200000')[:5]","66101bdb":"anime_df[anime_df['type'] == 'OVA'][['name', 'rating', 'members', 'type']].sort_values(by='rating', ascending=False).query('members>100000')[:5]","b68022ae":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ngenres_str = anime_df['genre'].str.split(',').astype(str)\n\ntfidf = TfidfVectorizer(analyzer='word', ngram_range=(1, 4), min_df=0)\ntfidf_matrix = tfidf.fit_transform(genres_str)\n\ntfidf_matrix.shape\n# tfidf.get_feature_names()","591d1651":"from sklearn.metrics.pairwise import linear_kernel\n\ncosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)","718bf566":"indices = pd.Series(anime_df.index, index=anime_df['name'])\n\ndef genre_recommendations(title, similarity=False):\n    \n    if similarity == False:\n        \n        idx = indices[title]\n        sim_scores = list(enumerate(cosine_sim[idx]))\n        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n        sim_scores = sim_scores[1:11]\n        \n        anime_indices = [i[0] for i in sim_scores]\n        \n        return pd.DataFrame({'Anime name': anime_df['name'].iloc[anime_indices].values,\n                             'Type': anime_df['type'].iloc[anime_indices].values})\n    \n    elif similarity == True:\n        \n        idx = indices[title]\n        sim_scores = list(enumerate(cosine_sim[idx]))\n        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n        sim_scores = sim_scores[1:11]\n        \n        anime_indices = [i[0] for i in sim_scores]\n        similarity_ = [i[1] for i in sim_scores]\n        \n        return pd.DataFrame({'Anime name': anime_df['name'].iloc[anime_indices].values,\n                             'similarity': similarity_,\n                             'Type': anime_df['type'].iloc[anime_indices].values})","e8124fdd":"indices = pd.Series(anime_df.index, index=anime_df['name'])\n\ndef genre_recommendations(title, highest_rating=False, similarity=False):\n    \n    if highest_rating == False:\n        if similarity == False:\n        \n            idx = indices[title]\n            sim_scores = list(enumerate(cosine_sim[idx]))\n            sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n            sim_scores = sim_scores[1:11]\n        \n            anime_indices = [i[0] for i in sim_scores]\n        \n            return pd.DataFrame({'Anime name': anime_df['name'].iloc[anime_indices].values,\n                                 'Type': anime_df['type'].iloc[anime_indices].values})\n    \n        elif similarity == True:\n        \n            idx = indices[title]\n            sim_scores = list(enumerate(cosine_sim[idx]))\n            sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n            sim_scores = sim_scores[1:11]\n        \n            anime_indices = [i[0] for i in sim_scores]\n            similarity_ = [i[1] for i in sim_scores]\n        \n            return pd.DataFrame({'Anime name': anime_df['name'].iloc[anime_indices].values,\n                                 'Similarity': similarity_,\n                                 'Type': anime_df['type'].iloc[anime_indices].values})\n        \n    elif highest_rating == True:\n        if similarity == False:\n        \n            idx = indices[title]\n            sim_scores = list(enumerate(cosine_sim[idx]))\n            sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n            sim_scores = sim_scores[1:11]\n        \n            anime_indices = [i[0] for i in sim_scores]\n        \n            result_df = pd.DataFrame({'Anime name': anime_df['name'].iloc[anime_indices].values,\n                                 'Type': anime_df['type'].iloc[anime_indices].values,\n                                 'Rating': anime_df['rating'].iloc[anime_indices].values})\n            \n            return result_df.sort_values('Rating', ascending=False)\n    \n        elif similarity == True:\n        \n            idx = indices[title]\n            sim_scores = list(enumerate(cosine_sim[idx]))\n            sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n            sim_scores = sim_scores[1:11]\n        \n            anime_indices = [i[0] for i in sim_scores]\n            similarity_ = [i[1] for i in sim_scores]\n        \n            result_df = pd.DataFrame({'Anime name': anime_df['name'].iloc[anime_indices].values,\n                                 'Similarity': similarity_,\n                                 'Type': anime_df['type'].iloc[anime_indices].values,\n                                 'Rating': anime_df['rating'].iloc[anime_indices].values})\n            \n            return result_df.sort_values('Rating', ascending=False)","ac56e3b5":"genre_recommendations('Doraemon (1979)', highest_rating=True, similarity=True)","050d914b":"genre_recommendations('Naruto: Shippuuden', highest_rating=False, similarity=False)","76c3a444":"rating.head()","597ef513":"rating_count = rating['rating'].value_counts().sort_index()\n\nsns.barplot(x=rating_count.index,\n            y=rating_count.values,\n            palette='magma').set_title('Comparison of the number of ratings from -1 to 10');","3b8a4ab7":"### step 1 - filter only rating from 6 to 10\n\nmask = (rating['rating'] == -1) | (rating['rating'] == 1) | (rating['rating'] == 2) | (rating['rating'] == 3) | (rating['rating'] == 4) | (rating['rating'] == 5)\n\nrating = rating.loc[~mask]","8e205030":"### step 2 - changed rating value from 6 - 10, to 1 - 5\n\ndef change_rating(rating):\n    if rating == 6:\n        return 1\n    elif rating == 7:\n        return 2\n    elif rating == 8:\n        return 3\n    elif rating == 9:\n        return 4\n    elif rating == 10:\n        return 5\n    \nrating['rating'] = rating['rating'].apply(change_rating)","6d7a6df5":"### step 3 - filter user_id from 1 to 10000 only\n\nrating = rating[rating['user_id'] < 10000]","f7b47162":"from sklearn.preprocessing import LabelEncoder\n\nuser_enc = LabelEncoder()\nrating['user_id'] = user_enc.fit_transform(rating['user_id'])\n\nanime_enc = LabelEncoder()\nrating['anime_id'] = anime_enc.fit_transform(rating['anime_id'])","59e25f5b":"userid_nunique = rating['user_id'].nunique()\nanime_nunique = rating['anime_id'].nunique()\n\nprint('User_id total unique:', userid_nunique)\nprint('Anime_id total unique:', anime_nunique)","194a7e90":"import tensorflow as tf\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Input, Embedding, Reshape, Dot, Flatten, concatenate, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\nfrom tensorflow.keras.utils import model_to_dot\nfrom IPython.display import SVG\n\nprint('Using tensorflow version:', tf.__version__)","6da47d88":"def RecommenderV2(n_users, n_movies, n_dim):\n    \n    # User\n    user = Input(shape=(1,))\n    U = Embedding(n_users, n_dim)(user)\n    U = Flatten()(U)\n    \n    # Anime\n    movie = Input(shape=(1,))\n    M = Embedding(n_movies, n_dim)(movie)\n    M = Flatten()(M)\n    \n    # Gabungkan disini\n    merged_vector = concatenate([U, M])\n    dense_1 = Dense(128, activation='relu')(merged_vector)\n    dropout = Dropout(0.5)(dense_1)\n    final = Dense(1)(dropout)\n    \n    model = Model(inputs=[user, movie], outputs=final)\n    \n    model.compile(optimizer=Adam(0.001),\n                  loss='mean_squared_error')\n    \n    return model","fe556e19":"model = RecommenderV2(userid_nunique, anime_nunique, 100)\n\nSVG(model_to_dot(model, show_shapes=True, show_layer_names=True).create(prog='dot', format='svg'))","d346ac46":"model.summary()","6c2418be":"from sklearn.model_selection import train_test_split\n\nX = rating.drop(['rating'], axis=1)\ny = rating['rating']\n\nX_train, X_val, y_train, y_val = train_test_split(X, y,\n                                                  test_size=.1,\n                                                  stratify=y,\n                                                  random_state=2020)\n\nX_train.shape, X_val.shape, y_train.shape, y_val.shape","e237ac3a":"checkpoint = ModelCheckpoint('model1.h5', monitor='val_loss', verbose=0, save_best_only=True)","415bf0a2":"history = model.fit(x=[X_train['user_id'], X_train['anime_id']],\n                    y=y_train,\n                    batch_size=64,\n                    epochs=20,\n                    verbose=1,\n                    validation_data=([X_val['user_id'], X_val['anime_id']], y_val),\n                    callbacks=[checkpoint])","eb975f13":"# Get training and test loss histories\ntraining_loss2 = history.history['loss']\ntest_loss2 = history.history['val_loss']\n\n# Create count of the number of epochs\nepoch_count = range(1, len(training_loss2) + 1)\n\n# Visualize loss history\nplt.plot(epoch_count, training_loss2, 'r--')\nplt.plot(epoch_count, test_loss2, 'b-')\nplt.legend(['Training Loss', 'Test Loss'])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.show()","5b1be2d6":"from tensorflow.keras.models import load_model\n\nmodel = load_model('model1.h5')","64e7c671":"def make_pred(user_id, anime_id, model):\n    return model.predict([np.array([user_id]), np.array([anime_id])])[0][0]","c53174a7":"def get_topN_rec(user_id, model):\n    \n    user_id = int(user_id) - 1\n    user_ratings = rating[rating['user_id'] == user_id]\n    recommendation = rating[~rating['anime_id'].isin(user_ratings['anime_id'])][['anime_id']].drop_duplicates()\n    recommendation['rating_predict'] = recommendation.apply(lambda x: make_pred(user_id, x['anime_id'], model), axis=1)\n    \n    final_rec = recommendation.sort_values(by='rating_predict', ascending=False).merge(anime_df[['anime_id', 'name', 'type', 'members']],\n                                                                                       on='anime_id').head(10)\n    \n    return final_rec.sort_values('rating_predict', ascending=False)[['name', 'type', 'rating_predict']]","d2c8084a":"get_topN_rec(23, model)","24a1fdc7":"## Make a recommendation based on cosine-similarity\n\n- you can choose to prioritize similarity or rating values on your recommendation functions","cdfddc37":"### How about movie and OVA (Original Animated Video)?\n\n> OVA is Japanese animated films and series made specially for release in home video formats without prior showings on television or in theatres","a17e32dc":"Also you can check my final project kernel (about recommendation system) if you're interested, \u8c22\u8c22\u4f60\n\nhttps:\/\/www.kaggle.com\/indralin\/movielens-project-1-1-content-based\n\nhttps:\/\/www.kaggle.com\/indralin\/movielens-project-1-2-collaborative-filtering\n\nhttps:\/\/www.kaggle.com\/indralin\/movielens-project-1-3-deep-learning","1dc6b8cd":"## What genres are in the anime dataset?","ab7a90af":"## Content-Based Recommendation-System","70cf758a":"## Data Cleaning\n\n- First, it easier for us to create a Recommendation System if the dataset doesn't have a NULL values\n- So we'll remove NULL values","ff869fea":"## EDA","792b589b":"## Which anime has a longest episodes?\n\n- If you check, why episodes dtype is object, not integer?\n- Because episodes has an Unknown values, from my opinion this means countless episodes\n- If you're more than 20 years old, most likely you know some of famous anime below","3afc7be7":"## Deep Learning for collaborative filtering\n\n- Neural networks are fundamentally matrix operations.\n- Matrix factorization techniques for recommendation systems also doing something similar.\n- For example: in SVD, We find matrices using weights calculated by SGD, Which is similar to Deep Learning\n- Even though by small margins, in some researches Deep Learning can outperformed SVD!","eef77c95":"## Which anime has the highest rating?\n\n- Here, i only included anime that have more than 500000 of community members\n- All top 5 anime are TV series","9f18fdbe":"# Computational efficiency strategy\n\n- In real world, many users don't want to give a rating for any reason, maybe because they're lazy (like me)\n- Although we can include all ratings (with Null rating), i only use rating values from 6 to 10 for computational efficiency\n    - -1 means the user watched it but didn't assign a rating, so i decided to remove this, including 1,2,3,4,5\n- Last, we filter user_id from 1 - 10.000\n\n**Computational efficiency measures the amount of time or memory required for a given step in a calculation**","a346bda4":"## Closing\n\n- If you're interested, you can tuning model hyperparameter for better accuracy\n- BUT REMEMBER, accuracy isn't indicator whether this model can provide good recommendations or not\n- We should focus on TopN recommendation; you can upgrade a function to not only give recommendation based on rating (predict), but also based on members, episodes etc"}}