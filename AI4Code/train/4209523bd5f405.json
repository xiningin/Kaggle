{"cell_type":{"5835247f":"code","2f0bae8f":"code","f4fd20b9":"code","f7b642ba":"code","c9635e6c":"code","0bab3e7a":"code","1b219cf7":"code","2167d255":"code","0ff7f007":"code","582fe650":"code","a5ad10f6":"code","c3e4785e":"code","7256bf68":"code","a5c81239":"code","7aacbc7e":"code","fd411a18":"code","889c732c":"code","d8c8a917":"code","bc281bbf":"code","104dbd9d":"code","9be0e07e":"code","9da65ff2":"code","cd69898c":"code","5f03a5f9":"code","5fb9be9c":"markdown","53b10a10":"markdown","98c613f9":"markdown","15ef19af":"markdown","2bba89bc":"markdown","bfa11929":"markdown","dc6d4c53":"markdown","3dff9f3f":"markdown","0abfaaf4":"markdown","02aa80d0":"markdown","d4e4d61b":"markdown","ffb4c3a2":"markdown","3934659a":"markdown","4c4fc97a":"markdown","8e6c4c7a":"markdown","b53bb833":"markdown","e98969af":"markdown","4c90a9af":"markdown","b98b7a44":"markdown","f01c3806":"markdown","cee82d87":"markdown","317b2763":"markdown"},"source":{"5835247f":"from IPython.display import Image\nImage(\"..\/input\/lumiereimages\/header.png\",\n     width = 400)","2f0bae8f":"Image(\"..\/input\/lumiereimages\/lumiere_map.png\",\n     width = 900)","f4fd20b9":"import pandas as pd\nimport numpy as np\n\npd.set_option('display.max_rows', 300) # specifies number of rows to show\npd.options.display.float_format = '{:40,.0f}'.format # specifies default number format to 4 decimal places\npd.options.display.max_colwidth\npd.options.display.max_colwidth = 1000","f7b642ba":"installation_data = pd.read_csv('..\/input\/lumierelondon\/installation_data.csv')\ninstallation_data.head()","c9635e6c":"installation_data = installation_data.fillna(value=0)","0bab3e7a":"twitter_data = pd.read_csv('..\/input\/lumierelondon\/LumiereLDN_Twitter_clean.csv')\ntwitter_data.head(2)","1b219cf7":"twitter_data = twitter_data.fillna(value=0)\n\ntwitter_data['DateTime'] = pd.to_datetime(twitter_data['DateTime'])\ntwitter_data.dtypes","2167d255":"twitter_data['Hour'] = twitter_data['DateTime'].apply(lambda x: x.hour)\ntwitter_data['Month'] = twitter_data['DateTime'].apply(lambda x: x.month)\ntwitter_data['Day'] = twitter_data['DateTime'].apply(lambda x: x.day)\ntwitter_data['Year'] = twitter_data['DateTime'].apply(lambda x: x.year)","0ff7f007":"twitter_data.head(3)","582fe650":"twitter_data.columns","a5ad10f6":"twitter = twitter_data[['DateTime', 'Hour', 'Day', 'Month', 'Year', 'UserId', 'UserHandle', 'Text',\n       'UserFollowers', 'UserFriends', 'GeogCoordinates', 'Long', 'Lat',\n       'UserLocation', 'UserLanguage', 'TweetURL','source', 'profile_image_url']]\n\ntwitter.head(3)","c3e4785e":"from plotly import __version__\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n\nimport plotly.graph_objs as go\nfrom plotly.graph_objs import *\n\n#You can also plot your graphs offline inside a Jupyter Notebook Environment. \n#First you need to initiate the Plotly Notebook mode as below:\ninit_notebook_mode(connected=True)","7256bf68":"#which areas had the most instalations\n\ninstallation_data['freq'] = installation_data.groupby('Location')['Location'].transform('count')\n\n#make graph\ndata = [Bar(x=installation_data['Location'],\n            y=installation_data['freq'])]\n\nlayout = Layout(\n    title=\"Number of Lumiere Installations by Location\",\n    xaxis=dict(title='Location'),\n    yaxis=dict(title='Number of Installations'),\n    width = 500,\n    \n)\n\nfig = Figure(data=data, layout=layout)\n\niplot(fig, filename='jupyter\/basic_bar')","a5c81239":"Image(\"..\/input\/lumiereimages\/installations1.png\",\n     width = 900)","7aacbc7e":"Image(\"..\/input\/lumiereimages\/installations2.png\",\n     width = 900)","fd411a18":"twitter.describe()","889c732c":"top10_twitterUsers = twitter[['UserHandle','UserFollowers','Text','DateTime']]\ntop10_twitterUsers = top10_twitterUsers.set_index(['DateTime'])\n\ntop10_twitterUsers = top10_twitterUsers.sort_values(['UserFollowers'],ascending=False).head(10)","d8c8a917":"top10_twitterUsers","bc281bbf":"print(top10_twitterUsers['UserHandle'])","104dbd9d":"twitter_data['DailyFreq'] = twitter_data.groupby('Day')['Day'].transform('count')\n\ndata = [Bar(x=twitter_data['Day'],  #change back to location_freq['Location']\n            y=twitter_data['DailyFreq'])] #change back to location_freq['Frequency']\n\nlayout = Layout(\n    title=\"Number of Tweets by Day\",\n    xaxis=dict(title='Day in January'),\n    yaxis=dict(title='Number of Tweets'),\n    width = 700\n)\n\nfig = Figure(data=data, layout=layout)\n\niplot(fig, filename='jupyter\/basic_bar')","9be0e07e":"twitter_data['HourlyFreq'] = twitter_data.groupby('Hour')['Hour'].transform('count')\n\ndata = [Bar(x=twitter_data['Hour'],  #change back to location_freq['Location']\n            y=twitter_data['HourlyFreq'])] #change back to location_freq['Frequency']\n\nlayout = Layout(\n    title=\"Number of Tweets by Hour\",\n    xaxis=dict(title='Hour of Day'),\n    yaxis=dict(title='Number of Tweets'),\n    width = 700\n)\n\nfig = Figure(data=data, layout=layout)\n\niplot(fig, filename='jupyter\/basic_bar')","9da65ff2":"twitter_data['LanguageFreq'] = twitter_data.groupby('UserLanguage')['UserLanguage'].transform('count')","cd69898c":"df_lan = twitter_data[['UserLanguage','LanguageFreq']]\ndf_lan = df_lan.drop_duplicates()\ndf_lan = df_lan.sort_values('LanguageFreq', ascending=False)\ndf_lan = df_lan.reset_index(drop=True)\ndf_lan = df_lan.head(10)\n\ndf_lan","5f03a5f9":"data = [\n    go.Bar(\n        x=df_lan['LanguageFreq'], # assign x as the dataframe column 'x'\n        y=df_lan['UserLanguage'],\n        orientation='h',\n    )\n]\n\nlayout = Layout(\n    title=\"Frequency of Language by Twitter User\",\n    xaxis=dict(title='Number of Users'),\n    yaxis=dict(title='User Language'),\n    width = 700\n)\n\nfig = Figure(data=data, layout=layout)\n\niplot(fig)","5fb9be9c":"According to the Twitter data I got from TAGS, the most popular Lumiere London day in terms of the number of tweets was Day 2, 19th January 2018, with a total of 2,449 unique tweets. Again, scroll over the bars to see the number of tweets per day.","53b10a10":"### Lumiere London Installation Data","98c613f9":"### Number of tweets by hour","15ef19af":"The `twitter_data` DataFrame has a variety of columns, however, I am only interested in a subset of these columns in order to answer my main questions. I am going to use the below code to select the columns that I am most interested in, rearrange them in an order I prefer, and create a new, smaller DataFrame called `twitter`.","2bba89bc":"### Who are the top 10 twitter profiles?","bfa11929":" # <a id='7'>Preliminary Analysis<\/a>\n \n This section presents pelimary analysis on the various data sets to get a better understanding of the what happened during Lumeire London 2018.","dc6d4c53":"#  <a id='1'>Introduction<\/a>\n\nLumiere London 2018 was a four-day light festival and public art initiative which took place across the entire city of London between 18th to 21st January 2018. Lumiere London was commissioned by the Mayor of London and was programmed, produced and curated by Artichoke Trust, an arts charity. \n\nIn total, there were 54 public art installations from 53 artists across in six main locations \u2013 see the image below for how the installations were divided by location: King\u2019s Cross (11), Fitzrovia (5), Mayfair (10), London\u2019s West End (15), Westminster & Victoria (6), and Southbank & Waterloo (10) - see map below, taken from the official Lumiere London programme.\n\nThe event was free-to-attent and was mainly supported by London & Partners, King's Cross and the West End. According to the press release (11th September 2017), additional funding and support was provided by a whole host of partners including Bloomberg Philanthropies, Wellcome, The Fitzrovia Partnership and South Bank and Waterloo BIDs.\n\nBuilding on the phenomenal success of Lumiere London 2016, which was attended by 1.3 million people over four nights and generated \u00a322 million for the local economy (Press Releass), Lumiere London 2018 is a successful example of integrating culture within the smart city framework. ","3dff9f3f":"As expected, english was overwhelmingly the most popular language of the tweets.","0abfaaf4":"# <a id='5'>Step 1: Required Libraries <\/a>\n\nThe primary libraries that will be used to undertake the analysis are:\n\n1. NumPy: Provides a fast numerical array structure and helper functions.\n2. pandas: Provides a DataFrame structure to store data in memory and work with it easily and efficiently.\n","02aa80d0":"# Lumiere London 2018 - Exploratory Data Analysis\n\n#### by Vishal Kumar\n","d4e4d61b":"This notebook provide an EDA of 11,000 tweets about Lumiere London 2018 collected using the Twitter API.","ffb4c3a2":"The most popular time of the for tweets during the festival was 6pm; there is a cumulative total of 781 tweets for the 18th hour (6pm) of each the day. The second most popular time was the 21st hour (9 pm), with a cumulative 773 tweets. ","3934659a":"### Twitter Data\n\nNext we will look at the Twitter data which I got from using the Twitter API.","4c4fc97a":"### Number of tweets per day\n\nIn order to count the frequency of tweets by day, we need to perform a count function on the `Day` column of the orginal `twitter_data` DataFrame. I will then use the Plotly graphing library to create a bar graph to visulise tweets by day.","8e6c4c7a":"The below code will create a simle bar graph with the frequency of installation by location area. Hover over the graphs to view the data points.","b53bb833":"In total we have 10,709 tweets. The users had an average number of followers of 16,039, with one Twitter profile who has a max number of followers of 16,784,087. Let's try find out who these Twitter profiles are and perhaps some of the top ones.","e98969af":"## Twitter Data Analysis\n\nNow, let's take a quick look at the twitter data by using the `describe` function; I will also create some graphs.","4c90a9af":"Moreover, I want to split out `DateTime` column into its various components - `Year`, `Month`, `Day`, `Hour` - this will be useful for future analysis when I want to view how the frequency of tweets evolved through time.","b98b7a44":"The West End had the most installations with 15 in total; King's Cross came in second with 11 installations in total, and Fitzrovia had the least number of insallations with 4 - it seems like the areas which donated and contributed to more funding to Lumiere London recived more installations. Please see the images below to see what the installaitons looked like - this information was taken from the official Lumiere London programme.","f01c3806":"There are a lot of NaN values which I am going to change to 0 using the below code `fillna()` function.\n\nI also want to convert the `DateTime` column to have a data type of `datetime64` - this is done by the using the below code. ","cee82d87":"## Lumiere London Installation Data Analysis\n\nLets look at how many installations were in each area. We are fist going to import Plotly, a data visualisation tool to help us interactively visualise the data.","317b2763":"# <a id='6'>Step 2: Checking and cleaning the Data <\/a>\n\nNow that the relevant packages are installed, the next step is to take a look at the data we are working with. It's important to do this so that we can spot errors and clean the data to make subsequent analysis is easier and smoother.\n\nWe will start by reading all the data as Pandas DataFrames."}}