{"cell_type":{"ff1ea09f":"code","01c40079":"code","70cc40d2":"code","822ee1ad":"code","6e69813a":"code","64d04087":"code","10678e72":"code","be02f51d":"code","9214e962":"code","fc4b94ce":"code","698aea0f":"code","d989c955":"code","0ea8de4f":"code","089ab7da":"code","2adbbdc5":"code","b9b39620":"code","bb6a23fb":"code","1127d94f":"code","438baef1":"code","a2281c58":"code","ce2d7353":"code","23a5d8bb":"code","05a7d725":"code","9d31e68c":"markdown","29d72eb9":"markdown","0e69549a":"markdown","ced2d60d":"markdown","280ed74d":"markdown","c578be03":"markdown","27517d74":"markdown","77d74d0a":"markdown"},"source":{"ff1ea09f":"%matplotlib inline\nfrom pathlib import Path\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom IPython.display import display, FileLink\nimport seaborn as sns\n\nimport doctest\nimport copy\nimport functools\n# tests help notebooks stay managable\ndef autotest(func):\n    globs = copy.copy(globals())\n    globs.update({func.__name__: func})\n    doctest.run_docstring_examples(\n        func, globs, verbose=True, name=func.__name__)\n    return func","01c40079":"fl_ds_url = 'https:\/\/dataset.floodlightopen.com\/public-blobs-prod\/complete_dataset.csv'\n!wget {fl_ds_url}","70cc40d2":"fl_df = pd.read_csv(fl_ds_url.split('\/')[-1])\nfl_df['participantCreatedOn'] = pd.to_datetime(fl_df['participantCreatedOn'], errors='coerce')\nfl_df['testResultMetricCreatedOn'] = pd.to_datetime(fl_df['testResultMetricCreatedOn'], errors='coerce')\nfl_df['measurementDate'] = fl_df['testResultMetricCreatedOn'].dt.strftime('%B %d, %Y')\nfl_df['full_test_name'] = fl_df.apply(lambda x: '{testName}-{testMetricName}'.format(**x), 1)\nprint(fl_df.shape, fl_df.columns)\ndisplay(fl_df.head(3))\n","822ee1ad":"# clean up types\nfor c_col in ['testResultMetricValue', 'participantWeightLbs', \n              'participantHeightCms', 'participantBirthYear']:\n    fl_df[c_col] = pd.to_numeric(fl_df[c_col],errors='coerce')\ndisplay(fl_df.describe())","6e69813a":"ds_overview_df = fl_df.groupby(['floodlightOpenId', 'participantIsControl', \n                                'participantSex', 'participantBirthYear']).\\\n  size().reset_index(name='count').sort_values('count', ascending=False)\nds_overview_df.head(5)","64d04087":"part_cols = [x for x in fl_df.columns if x.startswith('participant')]\ntest_cols = [x for x in fl_df.columns if x.startswith('test')]\nprint('User', part_cols)\nprint('Test', test_cols)","10678e72":"raw_measurement_df = fl_df.pivot_table(index=['floodlightOpenId', 'measurementDate']+part_cols,\n            columns=['full_test_name'],\n            values='testResultMetricValue')\nraw_measurement_df.sample(3)","be02f51d":"pred_names = raw_measurement_df.index.names\nx_vars = raw_measurement_df.columns","9214e962":"measurement_df = raw_measurement_df.reset_index()\nmeasurement_df['participantIsControl'] = measurement_df['participantIsControl'].str.strip().\\\n    map(lambda x:    x.upper().startswith('T') if isinstance(x, str) else x).\\\n    map(lambda x: 1.0 if x else 0)\nmeasurement_df.to_csv('clean_measure_table.csv', index=False)","fc4b94ce":"part_df = measurement_df[pred_names].copy()\npart_df['IsFemale'] = part_df['participantSex'].map(lambda x: x=='female')\npart_df['participantIsControl'] = part_df['participantIsControl'].map(lambda x: 'Healthy' if x else 'MS')\nsns.pairplot(data=part_df, hue='participantIsControl', diag_kind=\"kde\")","698aea0f":"from scipy.interpolate import interp1d, pchip\nfrom scipy import interpolate\nfrom collections import defaultdict\nfrom sklearn.linear_model import LinearRegression\nday_steps = 24*3600*np.linspace(0, 300, 40)\nout_vec_dict = defaultdict(dict)\nsmall_df = fl_df[['floodlightOpenId','participantIsControl', 'full_test_name', \n                  'testResultMetricCreatedOn','testResultMetricValue']].copy()\ni=0\ndebug_plot=0\nfancy_inter = False\nfor (test_name, is_control), c_rows in small_df.dropna().groupby(['full_test_name', \n                                                         'participantIsControl']):\n    x_vals = []\n    y_vals = []\n    y_all_std = c_rows['testResultMetricValue'].dropna().std()\n    y_all_mean = c_rows['testResultMetricValue'].dropna().mean()\n    for _, n_rows in c_rows.groupby('floodlightOpenId'):\n        t_rows = n_rows.sort_values('testResultMetricCreatedOn').dropna()\n        t_vec = t_rows['testResultMetricCreatedOn']\n        x_vals += [(t_vec-t_vec.iloc[0]).dt.total_seconds().values]\n        y_vec = t_rows['testResultMetricValue'].values\n        y_vals += [(y_vec-y_all_mean)\/y_all_std]\n    x_vals = np.concatenate(x_vals, 0)\n    x_vals += np.random.uniform(0, 5, size=x_vals.shape)\n    y_vals = np.concatenate(y_vals, 0)\n    i_vals = np.argsort(x_vals)\n    x_vals = x_vals[i_vals]\n    y_vals = y_vals[i_vals]\n    if fancy_inter:\n        p_xy = interpolate.interp1d(x=x_vals, y=y_vals, \n                                    kind='linear', \n                                    fill_value=\"extrapolate\",\n                                    assume_sorted=False)\n    else:\n        lr_model = LinearRegression().fit(x_vals.reshape((-1, 1)), y_vals)\n        p_xy = lambda x: lr_model.predict(x.reshape((-1, 1)))\n  \n  \n    out_vec_dict[is_control][test_name] = p_xy(day_steps)\n    if debug_plot>0:\n        fig, ax1 = plt.subplots(1, 1)\n        ax1.plot(x_vals\/(24*3600),  y_vals , '.', alpha=0.1)\n        ax1.plot(day_steps\/(24*3600),  p_xy(day_steps) , '-')\n\n        ax1.set_title('{}'.format((is_control, test_name)))\n        i+=1\n        if i==debug_plot:\n            break","d989c955":"sns.set_style(\"whitegrid\", {'axes.grid' : False})\nshow_traces=False\nfig, m_axs = plt.subplots(len(out_vec_dict), 2 if show_traces else 1, \n                          figsize=(30 if show_traces else 20, 10))\nfor n_axs, (k1, v1) in zip(m_axs, out_vec_dict.items()):\n    if show_traces:\n        c_ax, d_ax = n_axs\n        d_ax.plot(out_img.T)\n        d_ax.set_ylim(-2, 2)\n    else:\n        c_ax = n_axs\n    \n    v1k = sorted(v1.keys())\n    c_ax.set_title('Is Control: {}'.format(k1))\n    out_img = np.stack([v1[k2] for k2 in v1k], 0)\n    c_ax.imshow(out_img, cmap='RdBu', vmin=-2, vmax=2)\n    c_ax.set_yticks(range(len(v1k)))\n    c_ax.set_yticklabels(v1k)\n    c_ax.set_xticks(range(day_steps.shape[0]))\n    c_ax.set_xticklabels(['{:2.0f}'.format(x) for x in day_steps\/(24*3600)])\n    c_ax.set_xlabel('Days')\n  ","0ea8de4f":"fig, m_axs = plt.subplots(3, 4, figsize=(15, 20))\nfor c_ax, k1 in zip(m_axs.flatten(), out_vec_dict[True].keys()):\n    c_ax.set_title(k1.replace('-', '\\n'))\n    for k2, v2 in out_vec_dict.items():\n        c_ax.plot(day_steps\/(24*3600), v2[k1], label='Is Control: {}'.format(k2) )\n    c_ax.legend()\n    c_ax.set_ylim(-2, 2)","089ab7da":"from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.metrics import roc_auc_score, roc_curve\ndef two_way_roc(gt, pred_val):\n    if roc_auc_score(gt, pred_val)<0.5:\n        return roc_curve(gt, -pred_val)[:2]+(roc_auc_score(gt, -pred_val),)\n    else:\n        return roc_curve(gt, pred_val)[:2]+(roc_auc_score(gt, pred_val),)","2adbbdc5":"scaled_lr = make_pipeline(RobustScaler(), # scale the values\n                          SimpleImputer(missing_values=np.nan, strategy='mean'), # fix missing values\n                          LogisticRegression() \n                         )","b9b39620":"scaled_lr.fit(measurement_df[x_vars], measurement_df['participantIsControl'])","bb6a23fb":"pred_ms = scaled_lr.predict_proba(measurement_df[x_vars])\nsns.violinplot(x=measurement_df['participantIsControl'], \n               y=pred_ms[:, 1])","1127d94f":"fig, ax1 = plt.subplots(1, 1, figsize=(6, 5))\ntpr, fpr, _ = roc_curve(measurement_df['participantIsControl'], pred_ms[:, 1])\nax1.plot(tpr, fpr, 'k.-', label='LR Model AUC:{:2.1%}'.format(roc_auc_score(measurement_df['participantIsControl'], pred_ms[:, 1])))\nc_df = measurement_df.ffill().bfill()\n\nfor x in sorted(x_vars, key = lambda x: -1*two_way_roc(measurement_df['participantIsControl'], c_df[x])[2]):\n  tpr, fpr, auc = two_way_roc(measurement_df['participantIsControl'],  c_df[x])\n  ax1.plot(tpr, fpr, '-', label='{} AUC:{:2.1%}'.format(x, auc))\nax1.legend(bbox_to_anchor=(1.1, 1.05))","438baef1":"fig, ax1 = plt.subplots(1, 1, figsize=(18, 8))\nlr_model = scaled_lr.steps[-1][1]\nax1.bar(range(len(x_vars)), lr_model.coef_[0])\nax1.set_xticks(range(len(x_vars)))\nax1.set_xticklabels([x.replace('-', '\\n') for x in x_vars], rotation=90);","a2281c58":"var_df = pd.DataFrame([{'Variable': x, 'Coefficient': v} for x, v in zip(x_vars, lr_model.coef_[0])])\nvar_df.assign(energy=np.power(var_df['Coefficient'], 2)).\\\n  sort_values('energy', ascending=False).\\\n  drop(['energy'],1)","ce2d7353":"scaled_nb = make_pipeline(RobustScaler(), # scale the values\n                          SimpleImputer(missing_values=np.nan, strategy='mean'), # fix missing values\n                          BernoulliNB()\n                         )\nscaled_nb.fit(measurement_df[x_vars], measurement_df['participantIsControl'])","23a5d8bb":"pred_nb_ms = scaled_lr.predict_proba(measurement_df[x_vars])\nsns.boxplot(x=measurement_df['participantIsControl'], \n               y=pred_nb_ms[:, 1])","05a7d725":"fig, ax1 = plt.subplots(1, 1, figsize=(6, 5))\ntpr, fpr, _ = roc_curve(measurement_df['participantIsControl'], pred_ms[:, 1])\nax1.plot(tpr, fpr, '-', label='LR Model AUC:{:2.1%}'.format(roc_auc_score(measurement_df['participantIsControl'], pred_ms[:, 1])))\ntpr, fpr, _ = roc_curve(measurement_df['participantIsControl'], pred_nb_ms[:, 1])\nax1.plot(tpr, fpr, 'k.-', label='Naive Bayes AUC:{:2.1%}'.format(roc_auc_score(measurement_df['participantIsControl'], pred_nb_ms[:, 1])))\n\nc_df = measurement_df.ffill().bfill()\n\nfor x in sorted(x_vars, key = lambda x: -1*two_way_roc(measurement_df['participantIsControl'], c_df[x])[2]):\n  tpr, fpr, auc = two_way_roc(measurement_df['participantIsControl'],  c_df[x])\n  ax1.plot(tpr, fpr, '-', label='{} AUC:{:2.1%}'.format(x, auc))\nax1.legend(bbox_to_anchor=(1.1, 1.05))","9d31e68c":"### Time change","29d72eb9":"## Compare Positive and Control Groups","0e69549a":"### Native Bayes","ced2d60d":"Show the predictions vs the real values","280ed74d":"### Logistic Regression","c578be03":"# Setup\n## Download the latest table from the floodlight page","27517d74":"## Build a Simple Model","77d74d0a":"## Process and Reformat"}}