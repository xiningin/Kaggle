{"cell_type":{"2c0f695c":"code","8028b971":"code","85568e0a":"code","8b421834":"code","8a1bad70":"code","65ca75b4":"code","7fb8d4fa":"code","f0629b32":"code","67814efe":"code","05b94a2f":"code","164be8ff":"code","b6df7ba8":"code","b4039f0c":"code","e50022ae":"markdown","24d9e77f":"markdown","a61891e4":"markdown","cd7e185d":"markdown","0728311f":"markdown"},"source":{"2c0f695c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8028b971":"!pip install music21\n","85568e0a":"from music21 import *\nimport glob\nimport pickle\nimport joblib\nfrom collections import Counter\nfrom matplotlib import pyplot as plt\n","8b421834":"# def read_midi(file):\n    \n#     print(\"Loading Music File:\",file)\n    \n#     notes=[]\n#     notes_to_parse = None\n    \n#     #parsing a midi file\n#     midi = converter.parse(file)\n  \n#     #grouping based on different instruments\n#     s2 = instrument.partitionByInstrument(midi)\n#     print(type(s2))\n\n#     #Looping over all the instruments\n#     for part in s2.parts:\n#         #select elements of only piano\n#         if 'Piano' in str(part): \n        \n#             notes_to_parse = part.recurse() \n      \n#             #finding whether a particular element is note or a chord\n#             for element in notes_to_parse:\n                \n#                 #note\n#                 if isinstance(element, note.Note):\n#                     notes.append(str(element.pitch))\n                \n#                 #chord\n#                 elif isinstance(element, chord.Chord):\n#                     notes.append('.'.join(str(n) for n in element.normalOrder))\n\n#     return np.array(notes)\ndef read_midi(file):\n    \n    print(\"Loading Music File:\",file)\n    \n    notes=[]\n    notes_to_parse = None\n    \n    #parsing a midi file\n    midi = converter.parse(file)\n  \n    #grouping based on different instruments\n    s2 = instrument.partitionByInstrument(midi)\n\n    #Looping over all the instruments\n    for part in s2.parts:\n        #select elements of only piano\n#         if 'Piano' in str(part): \n        \n        notes_to_parse = part.recurse() \n\n        #finding whether a particular element is note or a chord\n        for element in notes_to_parse:\n\n            #note\n            if isinstance(element, note.Note):\n                notes.append(str(element.pitch))\n\n            #chord\n            elif isinstance(element, chord.Chord):\n                notes.append('.'.join(str(n) for n in element.normalOrder))\n\n    return np.array(notes)\n\n\ndef convert_to_midi(prediction_output,name):\n   \n    offset = 0\n    output_notes = []\n\n    # create note and chord objects based on the values generated by the model\n    for pattern in prediction_output:\n        \n        # pattern is a chord\n        if ('.' in pattern) or pattern.isdigit():\n            notes_in_chord = pattern.split('.')\n            notes = []\n            for current_note in notes_in_chord:\n                \n                cn=int(current_note)\n                new_note = note.Note(cn)\n                new_note.storedInstrument = instrument.Piano()\n                notes.append(new_note)\n                \n            new_chord = chord.Chord(notes)\n            new_chord.offset = offset\n            output_notes.append(new_chord)\n            \n        # pattern is a note\n        else:\n            \n            new_note = note.Note(pattern)\n            new_note.offset = offset\n            new_note.storedInstrument = instrument.Piano()\n            output_notes.append(new_note)\n\n        # increase offset each iteration so that notes do not stack\n        offset += 1\n    midi_stream = stream.Stream(output_notes)\n    midi_stream.write('midi', fp=name+'.mid')","8a1bad70":"# name2note = {}\n# for file in glob.glob('\/kaggle\/input\/anime-music-midi\/*'):\n#     print(file)\n#     try:\n#         file_name = file.split('\/')[-1].split('.')[0]\n#         res = read_midi(file)\n#         name2note[file_name] = res\n#     except:\n#         pass","65ca75b4":"# I have saved name2note \nname2note = joblib.load('\/kaggle\/input\/name2note\/name2note.jb')\nname2note_reg = {x:['.'.join(sound.split('.')[:2]) for sound in name2note[x]] for x in name2note}","7fb8d4fa":"all_notes = [x for sound in name2note_reg.values() for x in sound]\nc = Counter(all_notes)\nc.most_common()","f0629b32":"id2notes= {i+1:x for i,x in enumerate(list({note for note in all_notes}))}\nnotes2id = {x:i for i,x in id2notes.items()}\nmusic = list(name2note_reg.values())\nids = [[notes2id[x] for x in song] for song in music]\nmax_len = max([len(x) for x in ids])\nids_pad = [x[:max_len]+[0]*max(0,max_len-len(x)) for x in ids]\ninputs_x = [x[:-1] for x in ids_pad]\ninputs_y = [x[1:] for x in ids_pad]\n\n","67814efe":"import tensorflow as tf\n# from tensorflow.data import Dataset\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense\nfrom tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\n\nnotes_number = len(id2notes)+1\n\nmusic_maker = Sequential()\nmusic_maker.add(Embedding(notes_number, 100,mask_zero=True))\nmusic_maker.add(LSTM(256, return_sequences=True))\nmusic_maker.add(Dense(notes_number))\nmusic_maker.compile(\n    optimizer='Adam', loss=SparseCategoricalCrossentropy(from_logits=True))\n\n\nmusic_maker.fit(x=inputs_x,\n                y=inputs_y, epochs=100,batch_size=8)\n","05b94a2f":"import random\nmusics = []\nfor tone in random.sample(list(id2notes.keys()),2):\n    last_tone = ''\n    tones = str(tone)\n    while tone != 0 and len(tones)<500:\n        pred = music_maker.predict([tone])\n        tone_candidates = tf.argsort(pred, -1,direction='DESCENDING')\n        for x in tone_candidates[0][0][:3]:\n            tone = int(x)\n            if tones[-5:]+'|'+str(tone) not in tones:\n#             last_tone != str(tone)  and last_tone+'|'+str(tone) not in tones[-100:] and \n            \n                break\n            tone = None\n            \n        if not tone:\n            tone = int(random.choice(tone_candidates[0][0][:5]))\n        last_tone = str(tone)\n        \n        tones += '|'+str(tone)\n    musics.append([int(x) for x in tones.split('|')])\n    music_maker.reset_states()","164be8ff":"musics[1]","b6df7ba8":"for i,tones in enumerate(musics):\n    gen_music = [id2notes[x] for x in tones]\n    convert_to_midi(gen_music,'gen_'+str(i))","b4039f0c":"starts = [x[0] for x in inputs_x]","e50022ae":"### I have no experience about music generation and I only want to build and play with a simple model. The following code is a simple lstm model to generate music.","24d9e77f":"# save results","a61891e4":"# load data","cd7e185d":"# model","0728311f":"# preprocess"}}