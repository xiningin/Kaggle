{"cell_type":{"d5cb3194":"code","9d3b8eba":"code","8f040d26":"code","b7c1e0cc":"code","0ce00891":"code","50ffa309":"code","1e3ec359":"code","19865835":"code","74999bea":"code","0da0ad56":"code","7cabca48":"code","debc0906":"code","abd4b598":"code","29453195":"code","30b9463a":"code","b72dbfa1":"code","878786f4":"code","41b26dce":"code","622e3422":"code","998d5d2a":"code","06f02e92":"code","80931739":"code","d845ced1":"code","0e0dfc60":"code","d5e5dd07":"code","422b9b1f":"code","e9c4569d":"code","6232e8a8":"code","c00527c5":"code","dfaa276e":"code","2c06d971":"code","abfff790":"code","542833d5":"code","36bd4040":"code","2336340e":"code","3ecdf8c0":"code","41c8620d":"code","8f9d1992":"code","d95b1b90":"code","4a600319":"code","0b51fea6":"code","306ea86f":"code","2551d51b":"code","0d396dd3":"code","c415183b":"code","92e9ca37":"code","5a4312d0":"code","43c4a41e":"code","31227a61":"code","9843f735":"code","1feead44":"code","99a4fd86":"code","a8495520":"code","da01487d":"code","c77d4fb4":"code","4927a338":"code","e94c60ea":"code","4288fd63":"code","11eb2f04":"code","b9a79fb2":"code","3df3f9f6":"code","4390599f":"code","05d68f61":"code","39f32c7b":"code","b15f6b12":"code","ead3b033":"code","3da86308":"code","1fe10771":"code","7c256332":"code","9c6581eb":"code","f990be5e":"code","50e43290":"code","5611d601":"code","ce078222":"code","955f43dc":"code","8002537d":"code","0682c685":"code","dfdb7451":"code","4dbb83f2":"code","bc53db87":"code","4d7f7225":"markdown","255f49ba":"markdown","e8d56ac9":"markdown","9b41f8db":"markdown","67f32a66":"markdown","3023281c":"markdown","beff8a69":"markdown","18916dab":"markdown","a53ffb90":"markdown","c5c10662":"markdown","9f4766b1":"markdown","80d5de51":"markdown","9765fec4":"markdown","8c5bf931":"markdown","b2ccfd20":"markdown","0e0b9da0":"markdown","c78f48d7":"markdown","54727936":"markdown","1962b222":"markdown","ba894894":"markdown","7c609094":"markdown","55fb90bf":"markdown","67657079":"markdown","f334e664":"markdown","7cc3b59e":"markdown","2b69d210":"markdown"},"source":{"d5cb3194":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt # data visualisation\nimport seaborn as sns \n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor #Random forest libraries\nfrom sklearn.model_selection import cross_validate #cross validation\nfrom sklearn.impute import SimpleImputer           #Treatment of missing values\nfrom sklearn.preprocessing import OrdinalEncoder   #Ordinal Encoder package\nfrom sklearn.preprocessing import LabelEncoder     #For Label Encoding\nfrom sklearn.metrics import mean_squared_log_error #Mean Squared Log Error metric from sklearn\nimport xgboost as xgb                              #XGboost package\nfrom sklearn.model_selection import GridSearchCV   #Grid search for finding out the best package\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","9d3b8eba":"train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\n\ntestID = test[\"Id\"]","8f040d26":"train.head()","b7c1e0cc":"test.head()","0ce00891":"train.info()","50ffa309":"train.describe()","1e3ec359":"numcols=train._get_numeric_data().columns\n\nfor cols in numcols:\n    plt.figure()\n    sns.scatterplot(x = cols,y = 'SalePrice',data = train)\n\ndata_num = train[numcols]\nplt.show()","19865835":"train = train.drop(train[(train['LotFrontage']> 200)|(train['LotArea']> 100000)|(train['BsmtFinSF1']> 2000)|(train['BsmtFinSF2']> 1200)\n                        | (train['1stFlrSF']> 3000)|(train['GrLivArea']> 4000)].index)","74999bea":"train.describe()","0da0ad56":"catcols = list(set(train.columns) - set(numcols))\n\n#for cols in catcols:\n#    plt.figure()\n#    sns.violinplot(x = cols, y = 'SalePrice',data = train)\n\n","7cabca48":"train.info()","debc0906":"test.info()","abd4b598":"train['LotFrontage'].fillna(train['LotFrontage'].median(), inplace = True)\ntrain['Alley'].fillna('None', inplace = True)\ntrain['MasVnrType'].fillna('None',inplace = True)\ntrain['MasVnrArea'].fillna(0,inplace = True)\n\ntrain['BsmtExposure'].fillna('NA',inplace = True)\n\ntrain['BsmtFinType1'].fillna('NA',inplace = True)\ntrain['BsmtFinType2'].fillna('NA',inplace = True)\ntrain['Electrical'].fillna('SBrkr',inplace = True)\ntrain['GarageType'].fillna('Attchd',inplace = True)\ntrain['GarageYrBlt'].fillna(2005,inplace = True)\ntrain['GarageFinish'].fillna('NA',inplace = True)\n\ntrain['Fence'].fillna('NA',inplace = True)\ntrain['MiscFeature'].fillna('NA',inplace = True)\n\n\ntest['LotFrontage'].fillna(train['LotFrontage'].median(), inplace = True)\ntest['Alley'].fillna('None', inplace = True)\ntest['MasVnrType'].fillna('None',inplace = True)\ntest['MasVnrArea'].fillna(0,inplace = True)\n\ntest['BsmtExposure'].fillna('NA',inplace = True)\n\ntest['BsmtFinType1'].fillna('NA',inplace = True)\ntest['BsmtFinType2'].fillna('NA',inplace = True)\ntest['Electrical'].fillna('SBrkr',inplace = True)\ntest['GarageType'].fillna('Attchd',inplace = True)\ntest['GarageYrBlt'].fillna(2005,inplace = True)\ntest['GarageFinish'].fillna('NA',inplace = True)\n\ntest['Fence'].fillna('NA',inplace = True)\ntest['MiscFeature'].fillna('NA',inplace = True)\n\ntest['TotalBsmtSF'].fillna(0,inplace = True)\ntest['Functional'].fillna('Typ',inplace = True)\ntest['TotalBsmtSF'].fillna(0,inplace = True)\ntest['BsmtFullBath'].fillna(0,inplace = True)\ntest['BsmtHalfBath'].fillna(0,inplace = True)\ntest['Exterior1st'].fillna('VinylSd', inplace = True)\ntest['Exterior2nd'].fillna('VinylSd', inplace = True)\ntest['MSZoning'].fillna('RL',inplace = True)\ntest['SaleType'].fillna('WD',inplace = True)\ntest['Utilities'].fillna('AllPub',inplace = True)\ntest['BsmtFinSF1'].fillna(0,inplace = True)\ntest['BsmtFinSF2'].fillna(0,inplace = True)\ntest['BsmtUnfSF'].fillna(0,inplace = True)\ntest['GarageCars'].fillna(2,inplace = True)\ntest['GarageArea'].fillna(400,inplace = True)","29453195":"train.isnull().sum().sort_values(ascending = False).head(10)","30b9463a":"test.isnull().sum().sort_values(ascending = False).head(10)","b72dbfa1":"mapping = {\"NA\":0, \"Po\": 1, \"Fa\":2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5}\n\nquality_cols = ['ExterQual','ExterCond','BsmtQual','BsmtCond','HeatingQC','KitchenQual','GarageQual','GarageCond','PoolQC','FireplaceQu']\n\n\n\nfor cols in quality_cols:\n    cols1 = cols + 'o'\n    train[cols].fillna('NA',inplace = True)\n    train[cols1] = train[cols].apply(lambda x: mapping[x])\n    test[cols].fillna('NA',inplace = True)\n    test[cols1] = test[cols].apply(lambda x: mapping[x])","878786f4":"train.info()","41b26dce":"neighborhoods = train.groupby('Neighborhood')['SalePrice'].median().sort_values()","622e3422":"neighborhoods.head()","998d5d2a":"plt.figure(figsize = (20,10))\nsns.barplot(neighborhoods.index,neighborhoods.values)","06f02e92":"neighborhoods_mean = train.groupby('Neighborhood')['SalePrice'].mean().sort_values()\n\nplt.figure(figsize = (20,10))\nsns.barplot(neighborhoods_mean.index,neighborhoods_mean.values)","80931739":"neighborhood = pd.DataFrame(neighborhoods)","d845ced1":"neighborhood.loc[neighborhood.SalePrice >= 50000,'NFlag'] = 0\nneighborhood.loc[neighborhood.SalePrice >= 150000,'NFlag'] = 1\nneighborhood.loc[neighborhood.SalePrice >= 200000,'NFlag'] = 2\nneighborhood.loc[neighborhood.SalePrice >= 250000,'NFlag'] = 3","0e0dfc60":"#neighborhood['Neighborhood'] = neighborhood.index\nneighborhood = neighborhood.drop(labels = ['SalePrice'], axis = 1)","d5e5dd07":"neighborhood.reset_index()","422b9b1f":"train = pd.merge(train,neighborhood, left_on = 'Neighborhood', right_on = 'Neighborhood')","e9c4569d":"train.info()","6232e8a8":"test = pd.merge(test,neighborhood, left_on = 'Neighborhood', right_on = 'Neighborhood')","c00527c5":"test.info()","dfaa276e":"def add_features(train):\n    train['YrBuildSold'] = train['YrSold'] - train['YearBuilt']\n    train['TotalArea'] = train['GrLivArea'] + train['TotalBsmtSF'] \n    train['AreabyRooms'] = train['GrLivArea']\/train['TotRmsAbvGrd']\n    train['GarageAreaCar'] = train['GarageArea']\/train['GarageCars']\n    train[\"TotalBath\"] = train[\"FullBath\"] + 0.5*train[\"HalfBath\"] + train[\"BsmtFullBath\"] + 0.5*train[\"BsmtHalfBath\"]\n    train['roomsbath'] = train['TotRmsAbvGrd']\/train['TotalBath']\n    \n    train['GarageAreaCar'].fillna(0, inplace = True)","2c06d971":"add_features(train)\nadd_features(test)","abfff790":"train['GarageAreaCar'].fillna(0, inplace = True)\ntest['GarageAreaCar'].fillna(0, inplace = True)","542833d5":"train['PricePerSF'] = train['SalePrice']\/train['GrLivArea']\n\nneighborhood_price = train.groupby('Neighborhood')['PricePerSF'].median().sort_values(ascending = False)","36bd4040":"plt.figure(figsize = (20,10))\nsns.barplot(neighborhood_price.index,neighborhood_price.values)","2336340e":"npriceSF = pd.DataFrame(neighborhood_price.reset_index())","3ecdf8c0":"npriceSF.rename(columns = {'PricePerSF': 'MedianPricePerSF'}, inplace = True)","41c8620d":"train= pd.merge(train,npriceSF, left_on = 'Neighborhood', right_on = 'Neighborhood')\ntest = pd.merge(test,npriceSF, left_on = 'Neighborhood', right_on = 'Neighborhood')","8f9d1992":"train.drop(columns = ['PricePerSF'], inplace = True)\n","d95b1b90":"train.info()","4a600319":"numcols=train._get_numeric_data().columns\ntrain_num=train.loc[:,numcols]\n\ncorr = train_num.corr(method='pearson')","0b51fea6":"df_all_corr = train.corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\ndf_all_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}, inplace=True)\ndf_all_corr[df_all_corr['Feature 1'] == 'SalePrice']","306ea86f":"k=corr.unstack().sort_values().drop_duplicates()\nk[(k>0.8) | (k<-0.8)]","2551d51b":"train_len = len(train)\n\n","0d396dd3":"train.drop(columns = quality_cols, axis = 1, inplace = True)\ntest.drop(columns = quality_cols, axis = 1, inplace = True)","c415183b":"y_train = np.log(train['SalePrice'])","92e9ca37":"train.drop(columns = ['SalePrice','Fireplaces'], axis = 1, inplace = True)\ntest.drop(columns = ['Fireplaces'], axis = 1, inplace = True)","5a4312d0":"train.describe()","43c4a41e":"test.info()","31227a61":"dataset = pd.concat([train,test],sort = True).reset_index(drop = True)","9843f735":"numcols = dataset._get_numeric_data().columns\n\ncatcols = list(set(train.columns) - set(numcols))\n\ndataset = pd.get_dummies(dataset,catcols)\n","1feead44":"dataset.drop(columns = ['GarageCars','PoolArea','MSSubClass','YearBuilt'])","99a4fd86":"for col in numcols:\n    dataset[col] = (dataset[col] - np.mean(dataset[col]))\/np.std(dataset[col])","a8495520":"dataset.describe()","da01487d":"train_len = len(train)\nx_train = dataset[:train_len]\nx_competition = dataset[train_len:]","c77d4fb4":"x_competition.sort_values('Id', inplace = True)\nx_competition.drop(columns = ['Id'])\nx_train.drop(columns = ['Id'])","4927a338":"X_train, X_test, Y_train, Y_test = train_test_split(x_train,y_train, test_size = 0.2, random_state = 1)","e94c60ea":"\nregressor = RandomForestRegressor(n_estimators=100, random_state=1,max_depth=10,max_features=10,min_samples_leaf=5)  \n#feature_list=x_train.columns\n\n# # fit the regressor with X and Y data \nmodel=regressor.fit(X_train,Y_train) \n\n#Make predictions on test dataset\npred_rf=model.predict(X_test)\n\n\n#Calculate Cross Validation results\ncv_results = cross_validate(regressor, X_train, Y_train, cv=5,scoring='r2')\nsorted(cv_results.keys())\n\nscoreOfModel = model.score(X_test, Y_test)\nprint(\"RSquared value for Model\",scoreOfModel)\n\nprint(\"RMSLE for RFR Model\",np.sqrt(mean_squared_log_error(np.exp(Y_test),np.exp(pred_rf) )))","4288fd63":"param_grid = {\n    'bootstrap': [True],\n    'max_depth': [5, 3,7,10,15],\n    'max_features': [5, 12,10,8],\n  #  'max_leaf_nodes': [4, 8, 16,32],\n    'min_samples_split': [5, 10, 8,3],\n    'n_estimators': [100, 200,150,300]\n}\nrf = RandomForestRegressor()\ngrid_search_rf = GridSearchCV(estimator = rf, param_grid = param_grid, \n                          cv = 5, n_jobs = -1, verbose = 2)\n# Fit the grid search to the data\ngrid_search_rf.fit(X_train,Y_train)\ngrid_search_rf.best_params_\n\nbest_grid_rf = grid_search_rf.best_estimator_\n\npred_gs_rf=best_grid_rf.predict(X_test)\n\nscoreOfModel = best_grid_rf.score(X_test, Y_test)\nprint(\"Rqusared for the Model\",scoreOfModel)\n\npred_gs_rf=best_grid_rf.predict(X_test)\n\nprint(\"RMSLE for the Random Forest Model\",np.sqrt(mean_squared_log_error(np.exp(Y_test),np.exp(pred_gs_rf) )))","11eb2f04":"\n\nactuals=np.exp(Y_test)\npredictions=np.exp(pred_gs_rf)\nresiduals=predictions-actuals\n\n\nplt.scatter(predictions, residuals)\nplt.xlabel(\"Predicted SalePrice\")\nplt.ylabel(\"Residuals\")\nplt.show()","b9a79fb2":"plt.scatter(predictions,actuals)\nplt.xlabel(\"Predicted SalePrice\")\nplt.ylabel(\"Actual SalePrice\")\nplt.show()","3df3f9f6":"param_grid = {\n    'max_depth': [8],\n    'learning_rate': [0.05, 0.1],\n    'colsample_bytree': [0.7],\n    'lambda':[0.75],\n    'max_leaves':[4,8,16],\n    'min_child_weight':[2,4,6],\n    'subsample': [0.7, 0.8],\n    'n_estimators': [150,250]\n}\nxg = xgb.XGBRegressor()\ngrid_search_xg = GridSearchCV(estimator = xg, param_grid = param_grid, \n                          cv = 2, n_jobs = -1, verbose = 2)\ngrid_search_xg.fit(X_train,Y_train)\nbest_grid_xg=grid_search_xg.best_params_\n\n\n\nbest_estimator_xg = grid_search_xg.best_estimator_\npred_gs_xg = best_estimator_xg.predict(X_test)\nprint(\"RMSLE for the xgboost Model\",np.sqrt(mean_squared_log_error(np.exp(Y_test),np.exp(pred_gs_xg) )))","4390599f":"print(grid_search_xg.best_params_)","05d68f61":"from sklearn.linear_model import Lasso, LassoCV\n\nlasso = Lasso(max_iter = 10000)\n\nparameters = {'alpha': [  1e-3, 1e-2, 1e-1]}\n\nlasso_regressor=GridSearchCV(lasso,parameters,scoring='r2',cv=5)\nlasso_regressor.fit(X_train,Y_train)\n\nprint(lasso_regressor.best_params_)\n\nbest_estimator_lr = lasso_regressor.best_estimator_\n\npred_gs_lr = best_estimator_lr.predict(X_test)\nprint(\"RMSLE for the Lasso Model\",np.sqrt(mean_squared_log_error(np.exp(Y_test),np.exp(pred_gs_lr) )))","39f32c7b":"from sklearn.linear_model import Ridge, RidgeCV\n\nridge = Ridge(max_iter = 10000)\n\nparameters = {'alpha': [ 1e-1, 3e-1, 1, 3, 5, 10, 30, 50, 100]}\n\nridge_regressor=GridSearchCV(ridge,parameters,scoring='r2',cv=5)\nridge_regressor.fit(X_train,Y_train)\n\nprint(ridge_regressor.best_params_)\n\nbest_estimator_rr = ridge_regressor.best_estimator_\n\npred_gs_rr = best_estimator_rr.predict(X_test)\nprint(\"RMSLE for the ridge Model\",np.sqrt(mean_squared_log_error(np.exp(Y_test),np.exp(pred_gs_rr) )))\n","b15f6b12":"from sklearn.linear_model import ElasticNet, ElasticNetCV\n\nelastic = ElasticNet(max_iter = 10000)\n\nparameters = {'alpha': [1e-3,1e-2,1e-1,1,3,5,10],\n              'l1_ratio': [0.1,0.3,0.5,0.7,0.9]\n             }\n\nelasticnet_regressor = GridSearchCV(elastic,parameters,scoring = 'r2',cv=5)\nelasticnet_regressor.fit(X_train,Y_train)\n\nprint(elasticnet_regressor.best_params_)\n\nbest_estimator_enr = elasticnet_regressor.best_estimator_\n\npred_gs_enr = best_estimator_enr.predict(X_test)\nprint(\"RMSLE for the elasticnet Model\",np.sqrt(mean_squared_log_error(np.exp(Y_test),np.exp(pred_gs_enr) )))","ead3b033":"pred_agg = (pred_gs_rr + pred_gs_lr + pred_gs_xg + pred_gs_enr)\/4\nprint(\"RMSLE for Mean Values\",np.sqrt(mean_squared_log_error(np.exp(Y_test),np.exp(pred_agg) )))\n","3da86308":"\n\nbest_estimator_xg = grid_search_xg.best_estimator_.fit(x_train,y_train)\nbest_estimator_lr = lasso_regressor.best_estimator_.fit(x_train,y_train)\nbest_estimator_rr = ridge_regressor.best_estimator_.fit(x_train,y_train)\nbest_estimator_enr = elasticnet_regressor.best_estimator_.fit(x_train,y_train)\n\n","1fe10771":"import tensorflow as tf\nfrom tensorflow.keras import layers","7c256332":"x_train.isnull().sum().sort_values(ascending= False)","9c6581eb":"model = tf.keras.Sequential([\n    layers.Dense(128, activation = 'relu', input_shape=[len(x_train.keys())]),\n    #layers.Dropout(0.15),\n    #layers.Dense(64, activation='relu'),\n    #layers.Dropout(0.2),\n    #layers.Dense(32, activation='relu'),\n    layers.Dense(1),\n    \n  ])\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n\nmodel.compile(loss='mse',\n                optimizer=optimizer,\n                metrics=[tf.keras.metrics.MeanSquaredLogarithmicError()])","f990be5e":"history = model.fit(\n  x_train,y_train,\n  epochs=100, validation_split = 0.1, verbose=1)","50e43290":"acc = np.sqrt(history.history['mean_squared_logarithmic_error'])\nval_acc = np.sqrt(history.history['val_mean_squared_logarithmic_error'])\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training Mae')\nplt.plot(epochs, val_acc, 'b', label='Validation Mae')\nplt.title('Training and validation Mae')\nplt.legend(loc=0)\n\nplt.ylim(0,.2)\n\nplt.show()","5611d601":"pred_nn = model.predict(x_competition)","ce078222":"#nn_output = np.exp(pred_agg)\nout = pred_nn.reshape([-1])\nprediction_nn = pd.Series(np.exp(out), name = 'SalePrice')\n\nresults_nn = pd.concat([testID,prediction_nn],axis=1)\n\nresults_nn.to_csv(\"prediction_nn.csv\",index=False)","955f43dc":"test = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntestID = test[\"Id\"]\n\n","8002537d":"len(test)","0682c685":"pred_rr = best_estimator_rr.predict(x_competition)\npred_xg = best_estimator_xg.predict(x_competition)\npred_lr = best_estimator_lr.predict(x_competition)\npred_enr = best_estimator_enr.predict(x_competition)\n\npred_agg = np.mean([pred_rr,pred_xg,pred_lr], axis = 0)\nlen(pred_agg)\n","dfdb7451":"prediction = pd.Series(np.exp(pred_agg), name = 'SalePrice')\n\nresults = pd.concat([testID,prediction],axis=1)\n\nresults.to_csv(\"prediction3.csv\",index=False)","4dbb83f2":"results.info()","bc53db87":"x_competition.to_csv('testing.csv', index = False)","4d7f7225":"**Training the model on the entire training data**","255f49ba":"# Using Neural Networks in Tensorflow","e8d56ac9":"**Dropping outlier rows**","9b41f8db":"**Ridge Linear Regressor (L2 Regularization)**","67f32a66":"# House Pricing Prediction modelling using SciKit Learn and Tensorflow","3023281c":"# Modelling using tree based methods","beff8a69":"3) Adding other features based on intuition:","18916dab":"Dropping redundant columns","a53ffb90":"# Exploratory Data Analysis","c5c10662":"**Normalizing the numerical values**","9f4766b1":"**Filling in the empty values in the dataset**","80d5de51":"# Submission","9765fec4":"**Xgboost**","8c5bf931":"**Lasso Linear Regressor (L1 Regularization)**","b2ccfd20":"\n1) The variables for quality can be mapped into numerical values from 1 to 5:","0e0b9da0":"**Aggregating all the scores**","c78f48d7":"**One hot encoding the categorical columns**","54727936":"# Feature Engineering","1962b222":" Creating pandas dataframes for train and test data","ba894894":"2) The neighbourhoods can be grouped into ones with a similar mean, and assigned a numerical variable from 0 to 3","7c609094":"**Conclusions from initial scatter plots:**\n* Outliers in LotFrontage, need to remove values greater than 200 by clipping\n* Outliers in LotArea, need to remove values greater than 100,000\n* OverallQual has a stronger correlation with SalePrice than OverallCond\n* Outliers in BsmtFinSF1 need to be clipped at 2000\n* Outliers in BsmtFinSF2 need to be clipped at 1200\n* Outliers in TotalBsmtSF need to be clipped at 3500\n* Outliers in 1stFlrSF need to be clipped at 3000\n* LowQualFinSF does not seem to be a useful feature\n* Outliers in GrLivArea need to be cropped to 4000\n* 3SsnPorch does not seem to be a useful feature\n* MoSold does not seem to be an important feature\n\n**Categorical Features:**\n\n* MSSubClass\n* Fireplaces \n","55fb90bf":"Univariate Analysis - Relationship between independent numeric variables and SalePrice","67657079":"4) Adding a new feature that calculates price per square foot in a particular neighborhood","f334e664":"Univariate Analysis - Relation between independent categorical variables and SalePrice","7cc3b59e":"**RandomForestRegressor**","2b69d210":"This notebook is a solution for the \"House Prices: Advanced Regression Techniques\" on Kaggle. The use of both Tree based models and Neural Networks is explored, and it was concluded that Tree-Based models that have been ensembled offer far greater accuracy than Neural Networks, perhaps due to the limited number of data points available. \n\nThis notebook goes over initial Exploratory Data Analysis, data cleaning and preparation, model architecture as well as hyperparameter tuning. Please feel free to edit this notebook and experiment with the features, modelling method, model architecture, etc. Thanks :) "}}