{"cell_type":{"36067722":"code","8717380f":"code","76afd218":"code","5b80d603":"code","824c7bc7":"code","145f832c":"code","ecc46dc7":"code","8e3f6e13":"code","b2675caf":"code","c8a9e8ed":"code","4d19cb0e":"code","d5dac26e":"code","dc7c1fd6":"code","790ea95a":"code","cb744c2e":"code","ea2647b4":"code","9058dde8":"code","6190c2ca":"code","9b9ed5de":"code","93b8425d":"code","7c0a684a":"code","53515378":"code","429e3a92":"code","3526b12f":"code","1fd4f867":"code","fd109ba7":"code","da60aa99":"code","c68cac43":"code","6fe64e2c":"code","3473f415":"code","e63afeeb":"code","658f7cd0":"code","51e1adc1":"code","10f5c01f":"code","bbc7d19d":"code","a94d6df4":"code","c707d776":"code","69b181b5":"code","1715d621":"code","5eea4f9b":"code","fdd8660c":"markdown","e68717c1":"markdown","fb3edade":"markdown","1b6753e8":"markdown","48bfd050":"markdown","c7bf3f87":"markdown","302d9efe":"markdown","10221148":"markdown","368cd52d":"markdown","c65ce9da":"markdown","8bee5172":"markdown","9e3ef8ea":"markdown","6a992135":"markdown"},"source":{"36067722":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","8717380f":"# Importing libraries\n\nimport pandas as pd\nimport numpy as np\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem.wordnet import WordNetLemmatizer\n#To track function execution\nfrom tqdm import tqdm\nfrom bs4 import BeautifulSoup\n\n#Libraries for Sentimental analysis\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\n#Libraries for visualization\nfrom os import path\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n#Libraries for ML\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_curve, auc","76afd218":"# Reading dataframe\ndf = pd.read_csv(\"..\/input\/amazon-fine-food-reviews\/Reviews.csv\")","5b80d603":"#Looking at top 5 rows\ndf.head(5)","824c7bc7":"# Checking for null values in the dataframe.\ndf.isnull().sum()","145f832c":"# Inspecting entries with Null value in profileName column \ndf[df[\"ProfileName\"].isnull()]","ecc46dc7":"# Dropping Null values\ndf.dropna(inplace=True)","8e3f6e13":"# Checking if null value exist again\ndf.isnull().sum()","b2675caf":"# Checking the columns of the reviews.\ndf.columns\n","c8a9e8ed":"#Checking the shape of the dataframe.\ndf.shape","4d19cb0e":"# Checking for the info of the dataframe.\ndf.info()","d5dac26e":"# Statistical analysis of the dataframe.\ndf.describe()","dc7c1fd6":"# Checking number of reviews for each score.\ndf[\"Score\"].value_counts()","790ea95a":"total = df[\"Score\"].count()\nprint(total)","cb744c2e":"percent_plot = pd.DataFrame({\"Total\":df[\"Score\"].value_counts()})\npercent_plot.reset_index(inplace = True)\npercent_plot.rename(columns={\"index\":\"Rating\"},inplace=True)","ea2647b4":"percent_plot","9058dde8":"sns.barplot(x=\"Rating\",y=\"Total\", data=percent_plot)","6190c2ca":"percent_plot[\"Percent\"] = percent_plot[\"Total\"].apply(lambda x: (x\/total)*100)","9b9ed5de":"#percent_plot.drop(['percent'],axis=1, inplace = True)","93b8425d":"percent_plot","7c0a684a":"sns.barplot(x=\"Rating\", y=\"Percent\", data = percent_plot)","53515378":"df.columns","429e3a92":"df[\"word_count\"] = df[\"Text\"].apply(lambda x: len(str(x).split(\" \")))\ndf[[\"Text\",\"word_count\"]].head()","3526b12f":"# Checking the statistics of word count to check for range and average number of the words in each article.\ndf[\"word_count\"].describe()","1fd4f867":"#Checking for top 20 most repeated words - Gives insights on data specific stop words.\n\ncommon_words = pd.Series(' '.join(df[\"Text\"]).split()).value_counts()\ncommon_words[:20]","fd109ba7":"# Checking 20 most uncommon words\ncommon_words[-20:]","da60aa99":"# Removing Stopwords\nstop_words = set(stopwords.words(\"english\"))\n\n# Adding common words from our document to stop_words\n\nadd_words = [\"the\",\"I\",\"and\",\"a\",\"to\",\"of\",\"is\",\"it\",\"for\",\"in\",\"this\",\"that\",\"my\",\"with\",     \n\"have\",     \n\"but\",      \n\"are\",      \n\"was\",      \n\"not\",      \n\"you\"]\n\nstop_words = stop_words.union(add_words)","c68cac43":"#Below Function is to clean the text and prepare it for the next phase.\n\nfrom tqdm import tqdm\ncorpus = []\n\ndef clean_content(df):\n    cleaned_content = []\n    \n    for sent in tqdm(df[\"Text\"]):\n        \n        #Removing HTML comtent\n        review_content = BeautifulSoup(sent).get_text()\n        \n        #Removing non-alphabetic charecters\n        review_content = re.sub(\"[^a-zA-Z]\",\" \", review_content)\n        \n        #Tokenize the sentences\n        words = word_tokenize(review_content.lower())\n        \n        #Removing the stop words\n        sto_words_removed = [word for word in words if not word in stop_words]\n        sto_words_removed = \" \".join(sto_words_removed)\n        corpus.append(sto_words_removed)\n        cleaned_content.append(sto_words_removed)\n        \n    return (cleaned_content)","6fe64e2c":"df[\"cleaned_text\"] = clean_content(df)","3473f415":"df.head()","e63afeeb":"wordcloud = WordCloud(\n                    background_color = \"white\",\n                    stopwords = stop_words,\n                    max_words = 100,\n                    max_font_size = 50).generate(str(corpus))","658f7cd0":"# Displaying the word cloud\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()\n#fig.savefig(\"word1.png\", dpi=900)","51e1adc1":"# Initializing the sentimental Intenity Analyzer\nsid = SentimentIntensityAnalyzer()","10f5c01f":"\n# checking the polarity scores for first 5 articles\nfor i in range(0,5):\n    print(sid.polarity_scores(df.loc[i][\"Text\"]))","bbc7d19d":"#df[\"Text\"][2]","a94d6df4":"df[\"sentimental_scores\"] = df[\"Text\"].apply(lambda x: sid.polarity_scores(x))","c707d776":"df[\"compound_sentiment\"] = df[\"sentimental_scores\"].apply(lambda score_dict: score_dict[\"compound\"]) ","69b181b5":"df.head()","1715d621":"df[\"sentiment\"] = df[\"compound_sentiment\"].apply(lambda x: 1 if x >= 0 else 0)\ndf.head()","5eea4f9b":"sns.countplot(x=\"sentiment\", order = [1,0], data=df, palette='RdBu')\nplt.xlabel(\"Sentiment\")\nplt.show()","fdd8660c":"# **Text Exploration**","e68717c1":"Below is the plot of Ratings and its percentage.","fb3edade":"# **Exploratory Data Analysis**","1b6753e8":"Not that we have 10 features and 568454 data points. There are some missing values in 'PROFILENAME' & 'SUMMARY' column. ","48bfd050":"Building a wordcloud to visualize most frequently used words after Text pre-processing stage  ","c7bf3f87":"We can observe that the dataset mostly consists of positive sentiments which is shown in the below graph.","302d9efe":"Below is the plot of number of ratings each score has received.","10221148":"# **Text Preprocessing**","368cd52d":"Note that more than 75% of our data is belonging to positive class(Score=4,5), i.e. we have imbalanced dataset.","c65ce9da":"We can see that 5-star reviews constitute a large proportion (63.88%) of all reviews. The next most prevalent rating is 4-stars(14.18%), followed by 1-star (9.19%), 3-star (7.50%), and finally 2-star reviews (5.23%).","8bee5172":"# **Sentimental Analysis**","9e3ef8ea":"# **Data Exploration**","6a992135":"Performed Sentiment Analysis to classify the Reviews into Positive or negative reviews.\n\nInput:\n\nText column of the dataFrame. \n\nOutput:\n\nSentimental score report card with percentage of negative, positive, neutral and compound sentiment.\nUsing this score report card, classified the sentence into possitive or negative sentence.\n0 - Negative Sentence\n1 - Positive Sentence"}}