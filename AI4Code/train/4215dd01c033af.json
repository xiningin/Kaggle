{"cell_type":{"91b19fcd":"code","bb2b1775":"code","b166499a":"code","e7091e2b":"code","00cedf05":"code","a05380b8":"code","0a92c301":"code","e465206e":"code","87d17a20":"code","5f07582f":"code","2d57aa8e":"code","4a7995a3":"markdown","d13cf4f3":"markdown","965f31a3":"markdown","5e0c3b74":"markdown","04bf408d":"markdown","281633c6":"markdown","b2d3f1fa":"markdown","f4f9363f":"markdown","a798d1ce":"markdown","fd581617":"markdown","e6abd6f1":"markdown","d96ca678":"markdown","53994337":"markdown","7932aa3c":"markdown","9fac1101":"markdown","e563be79":"markdown","2d26ed44":"markdown","57098fdf":"markdown","9a9372bd":"markdown","452f9fc5":"markdown","d0aeb7a0":"markdown","b43f3533":"markdown","61b70fe2":"markdown","fa816a88":"markdown"},"source":{"91b19fcd":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\n# import tf2_0_baseline_w_bert as tf2baseline # old script\nimport tf2_0_baseline_w_bert_translated_to_tf2_0 as tf2baseline # Oliviera's script\nimport bert_modeling as modeling\nimport bert_optimization as optimization\nimport bert_tokenization as tokenization\nimport json\nimport absl\nimport sys\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","bb2b1775":"def del_all_flags(FLAGS):\n    flags_dict = FLAGS._flags()\n    keys_list = [keys for keys in flags_dict]\n    for keys in keys_list:\n        FLAGS.__delattr__(keys)\n\ndel_all_flags(absl.flags.FLAGS)\n\nflags = absl.flags\n\nflags.DEFINE_string(\n    \"bert_config_file\", \"\/kaggle\/input\/bertjointbaseline\/bert_config.json\",\n    \"The config json file corresponding to the pre-trained BERT model. \"\n    \"This specifies the model architecture.\")\n\nflags.DEFINE_string(\"vocab_file\", \"\/kaggle\/input\/bertjointbaseline\/vocab-nq.txt\",\n                    \"The vocabulary file that the BERT model was trained on.\")\n\nflags.DEFINE_string(\n    \"output_dir\", \"outdir\",\n    \"The output directory where the model checkpoints will be written.\")\n\nflags.DEFINE_string(\"train_precomputed_file\", None,\n                    \"Precomputed tf records for training.\")\n\nflags.DEFINE_integer(\"train_num_precomputed\", None,\n                     \"Number of precomputed tf records for training.\")\n\nflags.DEFINE_string(\n    \"output_prediction_file\", \"predictions.json\",\n    \"Where to print predictions in NQ prediction format, to be passed to\"\n    \"natural_questions.nq_eval.\")\n\nflags.DEFINE_string(\n    \"init_checkpoint\", \"\/kaggle\/input\/bertjointbaseline\/bert_joint.ckpt\",\n    \"Initial checkpoint (usually from a pre-trained BERT model).\")\n\nflags.DEFINE_bool(\n    \"do_lower_case\", True,\n    \"Whether to lower case the input text. Should be True for uncased \"\n    \"models and False for cased models.\")\n\nflags.DEFINE_integer(\n    \"max_seq_length\", 384,\n    \"The maximum total input sequence length after WordPiece tokenization. \"\n    \"Sequences longer than this will be truncated, and sequences shorter \"\n    \"than this will be padded.\")\n\nflags.DEFINE_integer(\n    \"doc_stride\", 128,\n    \"When splitting up a long document into chunks, how much stride to \"\n    \"take between chunks.\")\n\nflags.DEFINE_integer(\n    \"max_query_length\", 64,\n    \"The maximum number of tokens for the question. Questions longer than \"\n    \"this will be truncated to this length.\")\n\nflags.DEFINE_bool(\"do_train\", False, \"Whether to run training.\")\n\nflags.DEFINE_bool(\"do_predict\", True, \"Whether to run eval on the dev set.\")\n\nflags.DEFINE_integer(\"train_batch_size\", 32, \"Total batch size for training.\")\n\nflags.DEFINE_integer(\"predict_batch_size\", 8,\n                     \"Total batch size for predictions.\")\n\nflags.DEFINE_float(\"learning_rate\", 5e-5, \"The initial learning rate for Adam.\")\n\nflags.DEFINE_float(\"num_train_epochs\", 3.0,\n                   \"Total number of training epochs to perform.\")\n\nflags.DEFINE_float(\n    \"warmup_proportion\", 0.1,\n    \"Proportion of training to perform linear learning rate warmup for. \"\n    \"E.g., 0.1 = 10% of training.\")\n\nflags.DEFINE_integer(\"save_checkpoints_steps\", 1000,\n                     \"How often to save the model checkpoint.\")\n\nflags.DEFINE_integer(\"iterations_per_loop\", 1000,\n                     \"How many steps to make in each estimator call.\")\n\nflags.DEFINE_integer(\n    \"n_best_size\", 20,\n    \"The total number of n-best predictions to generate in the \"\n    \"nbest_predictions.json output file.\")\n\nflags.DEFINE_integer(\n    \"verbosity\", 1, \"How verbose our error messages should be\")\n\nflags.DEFINE_integer(\n    \"max_answer_length\", 30,\n    \"The maximum length of an answer that can be generated. This is needed \"\n    \"because the start and end predictions are not conditioned on one another.\")\n\nflags.DEFINE_float(\n    \"include_unknowns\", -1.0,\n    \"If positive, probability of including answers of type `UNKNOWN`.\")\n\nflags.DEFINE_bool(\"use_tpu\", False, \"Whether to use TPU or GPU\/CPU.\")\nflags.DEFINE_bool(\"use_one_hot_embeddings\", False, \"Whether to use use_one_hot_embeddings\")\n\nabsl.flags.DEFINE_string(\n    \"gcp_project\", None,\n    \"[Optional] Project name for the Cloud TPU-enabled project. If not \"\n    \"specified, we will attempt to automatically detect the GCE project from \"\n    \"metadata.\")\n\nflags.DEFINE_bool(\n    \"verbose_logging\", False,\n    \"If true, all of the warnings related to data processing will be printed. \"\n    \"A number of warnings are expected for a normal NQ evaluation.\")\n\nflags.DEFINE_boolean(\n    \"skip_nested_contexts\", True,\n    \"Completely ignore context that are not top level nodes in the page.\")\n\nflags.DEFINE_integer(\"task_id\", 0,\n                     \"Train and dev shard to read from and write to.\")\n\nflags.DEFINE_integer(\"max_contexts\", 48,\n                     \"Maximum number of contexts to output for an example.\")\n\nflags.DEFINE_integer(\n    \"max_position\", 50,\n    \"Maximum context position for which to generate special tokens.\")\n\n\n## Special flags - do not change\n\nflags.DEFINE_string(\n    \"predict_file\", \"\/kaggle\/input\/tensorflow2-question-answering\/simplified-nq-test.jsonl\",\n    \"NQ json for predictions. E.g., dev-v1.1.jsonl.gz or test-v1.1.jsonl.gz\")\nflags.DEFINE_boolean(\"logtostderr\", True, \"Logs to stderr\")\nflags.DEFINE_boolean(\"undefok\", True, \"it's okay to be undefined\")\nflags.DEFINE_string('f', '', 'kernel')\nflags.DEFINE_string('HistoryManager.hist_file', '', 'kernel')\n\nFLAGS = flags.FLAGS\nFLAGS(sys.argv) # Parse the flags","b166499a":"bert_config = modeling.BertConfig.from_json_file(FLAGS.bert_config_file)\n\ntf2baseline.validate_flags_or_throw(bert_config)\ntf.io.gfile.makedirs(FLAGS.output_dir)\n\ntokenizer = tokenization.FullTokenizer(\n    vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)\n\nrun_config = tf.estimator.RunConfig(\n    model_dir=FLAGS.output_dir,\n    save_checkpoints_steps=FLAGS.save_checkpoints_steps)\n\nnum_train_steps = None\nnum_warmup_steps = None\n\nmodel_fn = tf2baseline.model_fn_builder(\n    bert_config=bert_config,\n    init_checkpoint=FLAGS.init_checkpoint,\n    learning_rate=FLAGS.learning_rate,\n    num_train_steps=num_train_steps,\n    num_warmup_steps=num_warmup_steps,\n    use_tpu=FLAGS.use_tpu,\n    use_one_hot_embeddings=FLAGS.use_one_hot_embeddings)\n\nestimator = tf.estimator.Estimator(\n    model_fn=model_fn,\n    config=run_config,\n    params={'batch_size':FLAGS.train_batch_size})\n\n\nif FLAGS.do_predict:\n  if not FLAGS.output_prediction_file:\n    raise ValueError(\n        \"--output_prediction_file must be defined in predict mode.\")\n    \n  eval_examples = tf2baseline.read_nq_examples(\n      input_file=FLAGS.predict_file, is_training=False)\n\n  print(\"FLAGS.predict_file\", FLAGS.predict_file)\n\n  eval_writer = tf2baseline.FeatureWriter(\n      filename=os.path.join(FLAGS.output_dir, \"eval.tf_record\"),\n      is_training=False)\n  eval_features = []\n\n  def append_feature(feature):\n    eval_features.append(feature)\n    eval_writer.process_feature(feature)\n\n  num_spans_to_ids = tf2baseline.convert_examples_to_features(\n      examples=eval_examples,\n      tokenizer=tokenizer,\n      is_training=False,\n      output_fn=append_feature)\n  eval_writer.close()\n  eval_filename = eval_writer.filename\n\n  print(\"***** Running predictions *****\")\n  print(f\"  Num orig examples = %d\" % len(eval_examples))\n  print(f\"  Num split examples = %d\" % len(eval_features))\n  print(f\"  Batch size = %d\" % FLAGS.predict_batch_size)\n  for spans, ids in num_spans_to_ids.items():\n    print(f\"  Num split into %d = %d\" % (spans, len(ids)))\n\n  predict_input_fn = tf2baseline.input_fn_builder(\n      input_file=eval_filename,\n      seq_length=FLAGS.max_seq_length,\n      is_training=False,\n      drop_remainder=False)\n\n  all_results = []\n\n  for result in estimator.predict(\n      predict_input_fn, yield_single_examples=True):\n    if len(all_results) % 1000 == 0:\n      print(\"Processing example: %d\" % (len(all_results)))\n\n    unique_id = int(result[\"unique_ids\"])\n    start_logits = [float(x) for x in result[\"start_logits\"].flat]\n    end_logits = [float(x) for x in result[\"end_logits\"].flat]\n    answer_type_logits = [float(x) for x in result[\"answer_type_logits\"].flat]\n\n    all_results.append(\n        tf2baseline.RawResult(\n            unique_id=unique_id,\n            start_logits=start_logits,\n            end_logits=end_logits,\n            answer_type_logits=answer_type_logits))\n\n  print (\"Going to candidates file\")\n\n  candidates_dict = tf2baseline.read_candidates(FLAGS.predict_file)\n\n  print (\"setting up eval features\")\n\n  raw_dataset = tf.data.TFRecordDataset(eval_filename)\n  eval_features = []\n  for raw_record in raw_dataset:\n    eval_features.append(tf.train.Example.FromString(raw_record.numpy()))\n    \n  print (\"compute_pred_dict\")\n\n  nq_pred_dict = tf2baseline.compute_pred_dict(candidates_dict, eval_features,\n                                   [r._asdict() for r in all_results])\n  predictions_json = {\"predictions\": list(nq_pred_dict.values())}\n\n  print (\"writing json\")\n\n  with tf.io.gfile.GFile(FLAGS.output_prediction_file, \"w\") as f:\n    json.dump(predictions_json, f, indent=4)","e7091e2b":"test_answers_df = pd.read_json(\"\/kaggle\/working\/predictions.json\")","00cedf05":"def create_short_answer(entry):\n    # if entry[\"short_answers_score\"] < 1.5:\n    #     return \"\"\n    \n    answer = []    \n    for short_answer in entry[\"short_answers\"]:\n        if short_answer[\"start_token\"] > -1:\n            answer.append(str(short_answer[\"start_token\"]) + \":\" + str(short_answer[\"end_token\"]))\n    if entry[\"yes_no_answer\"] != \"NONE\":\n        answer.append(entry[\"yes_no_answer\"])\n    return \" \".join(answer)\n\ndef create_long_answer(entry):\n   # if entry[\"long_answer_score\"] < 1.5:\n   # return \"\"\n\n    answer = []\n    if entry[\"long_answer\"][\"start_token\"] > -1:\n        answer.append(str(entry[\"long_answer\"][\"start_token\"]) + \":\" + str(entry[\"long_answer\"][\"end_token\"]))\n    return \" \".join(answer)","a05380b8":"test_answers_df[\"long_answer_score\"] = test_answers_df[\"predictions\"].apply(lambda q: q[\"long_answer_score\"])\ntest_answers_df[\"short_answer_score\"] = test_answers_df[\"predictions\"].apply(lambda q: q[\"short_answers_score\"])","0a92c301":"test_answers_df[\"long_answer_score\"].describe()","e465206e":"test_answers_df.predictions.values[0]","87d17a20":"test_answers_df[\"long_answer\"] = test_answers_df[\"predictions\"].apply(create_long_answer)\ntest_answers_df[\"short_answer\"] = test_answers_df[\"predictions\"].apply(create_short_answer)\ntest_answers_df[\"example_id\"] = test_answers_df[\"predictions\"].apply(lambda q: str(q[\"example_id\"]))\n\nlong_answers = dict(zip(test_answers_df[\"example_id\"], test_answers_df[\"long_answer\"]))\nshort_answers = dict(zip(test_answers_df[\"example_id\"], test_answers_df[\"short_answer\"]))","5f07582f":"sample_submission = pd.read_csv(\"\/kaggle\/input\/tensorflow2-question-answering\/sample_submission.csv\")\n\nlong_prediction_strings = sample_submission[sample_submission[\"example_id\"].str.contains(\"_long\")].apply(lambda q: long_answers[q[\"example_id\"].replace(\"_long\", \"\")], axis=1)\nshort_prediction_strings = sample_submission[sample_submission[\"example_id\"].str.contains(\"_short\")].apply(lambda q: short_answers[q[\"example_id\"].replace(\"_short\", \"\")], axis=1)\n\nsample_submission.loc[sample_submission[\"example_id\"].str.contains(\"_long\"), \"PredictionString\"] = long_prediction_strings\nsample_submission.loc[sample_submission[\"example_id\"].str.contains(\"_short\"), \"PredictionString\"] = short_prediction_strings","2d57aa8e":"sample_submission.to_csv(\"submission.csv\", index=False)\nsample_submission.head()","4a7995a3":"**This is a translated version of the baseline [script](https:\/\/www.kaggle.com\/philculliton\/using-tensorflow-2-0-w-bert-on-nq) from the Tensorflow team**\n\n**Oliviera\u306f\u30b9\u30af\u30ea\u30d7\u30c8\u3092Tensorflow 2.0\u30d0\u30fc\u30b8\u30e7\u30f3\u306b\u5909\u63db\u3057\u307e\u3057\u305f\u3002\u3053\u308c\u306b\u3088\u308a\u3001TF2\u8cde\u306b\u53c2\u52a0\u3067\u304d\u3001\u4f5c\u696d\u3092\u6539\u5584\u3059\u308b\u305f\u3081\u306b\u3053\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u4f7f\u7528\u3067\u304d\u307e\u3059\u3002**\n\n**A few notes:**\n- **flags**\u3068**logging**\u3092\u4f7f\u3044\u7d9a\u3051\u305f\u3044\u5834\u5408\u306f\u3001**absl** lib\u3092\u4f7f\u7528\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\uff08TF\u30c1\u30fc\u30e0\u304c\u63a8\u5968\u3057\u307e\u3059\uff09\u3002\n- \u30ab\u30fc\u30cd\u30eb\u3067\u306f\u4f7f\u7528\u3057\u306a\u3044\u306e\u3067\u3001\u8907\u96d1\u3055\u3092\u8efd\u6e1b\u3059\u308b\u305f\u3081\u306b**TPU**\u95a2\u9023\u306e\u3082\u306e\u306e\u307b\u3068\u3093\u3069\u3092\u524a\u9664\u3057\u307e\u3057\u305f\u3002\n- Tensorflow2\u3067\u306f\u30b0\u30ed\u30fc\u30d0\u30eb\u5909\u6570\u3092\u4f7f\u7528\u3067\u304d\u307e\u305b\u3093**(tf.compat.v1.trainable_variables())**\n- Tensorflow2\u306e\u7d4c\u9a13\u304c\u3042\u308b\u5834\u5408\u3001\u307e\u305f\u306f\u4fee\u6b63\/\u6539\u5584\u304c\u3042\u308b\u5834\u5408\u306f\u3001\u77e5\u3089\u305b\u3066\u304f\u3060\u3055\u3044\n\n\u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3067\u306f\u3001Tensorflow\u306eBert\u30d9\u30fc\u30b9\u30e9\u30a4\u30f3\u3092\u4f7f\u7528\u3057\u3066\u3001Natural Questions\u30c6\u30b9\u30c8\u30bb\u30c3\u30c8\u306e\u4e88\u6e2c\u3092\u4f5c\u6210\u3057\u307e\u3059\u3002 \u3053\u308c\u306f\u3001\u4e8b\u524d\u306b\u8a13\u7df4\u3055\u308c\u305f\u30e2\u30c7\u30eb\u3092\u4f7f\u7528\u3057\u3066\u3044\u308b\u3053\u3068\u306b\u6ce8\u610f\u3057\u3066\u304f\u3060\u3055\u3044-\u3053\u3053\u3067\u306f\u63a8\u8ad6\u306e\u307f\u3092\u884c\u3063\u3066\u3044\u307e\u3059\u3002 GPU\u304c\u5fc5\u8981\u3067\u3059\u3002\u3053\u308c\u306b\u306f1\u301c2\u6642\u9593\u304b\u304b\u308a\u307e\u3059\u3002\n\nThe original script can be found [here](https:\/\/github.com\/google-research\/language\/blob\/master\/language\/question_answering\/bert_joint\/run_nq.py).\nThe supporting modules were drawn from the [official Tensorflow model repository](https:\/\/github.com\/tensorflow\/models\/tree\/master\/official). The bert-joint-baseline data is described [here](https:\/\/github.com\/google-research\/language\/tree\/master\/language\/question_answering\/bert_joint).\n\n**Note:** \u3000\u3053\u306e\u30d9\u30fc\u30b9\u30e9\u30a4\u30f3\u306f\u3001TF1.x\u304b\u3089\u79fb\u884c\u3055\u308c\u305f\u30b3\u30fc\u30c9\u3092\u4f7f\u7528\u3057\u307e\u3059\u3002 tf.compat.v1\u306e\u4f7f\u7528\u304c\u542b\u307e\u308c\u3066\u3044\u308b\u3053\u3068\u306b\u6ce8\u610f\u3057\u3066\u304f\u3060\u3055\u3044\u3002tf.compat.v1\u306f\u3001\u3053\u306e\u30b3\u30f3\u30da\u30c6\u30a3\u30b7\u30e7\u30f3\u306eTF2.0\u8cde\u306e\u5bfe\u8c61\u3068\u306a\u308b\u3053\u3068\u306f\u8a31\u53ef\u3055\u308c\u3066\u3044\u307e\u305b\u3093(https:\/\/www.kaggle.com\/c\/tensorflow2-question-answering\/overview\/prizes). ","d13cf4f3":"An example of what each sample's answers look like in `prediction.json`:","965f31a3":"# Code Implementation in Tensorflow 2.0\n\n> **Note:** The code for this notebook is taken from the [translated version](https:\/\/www.kaggle.com\/dimitreoliveira\/using-tf-2-0-w-bert-on-nq-translated-to-tf2-0) posted by [Dimitre Oliviera](https:\/\/www.kaggle.com\/dimitreoliveira)","5e0c3b74":"\u6b21\u306b\u3001\u305d\u308c\u3089\u3092\u30b5\u30f3\u30d7\u30eb\u9001\u4fe1\u306b\u8ffd\u52a0\u3057\u307e\u3059\u3002 \u5404\u30b5\u30f3\u30d7\u30eb\u306b\u306f\u3001\u56de\u7b54\u306e\u30bf\u30a4\u30d7\u3054\u3068\u306b1\u3064\u305a\u3064\u3001\u30b5\u30f3\u30d7\u30eb\u9001\u4fe1\u306b`_long`\u3068`_short`\u306e\u4e21\u65b9\u306e\u30a8\u30f3\u30c8\u30ea\u304c\u3042\u308b\u3053\u3068\u3092\u601d\u3044\u51fa\u3057\u3066\u304f\u3060\u3055\u3044\u3002","04bf408d":"[BERT for Humans: Tutorial+Baseline](https:\/\/www.kaggle.com\/abhinand05\/bert-for-humans-tutorial-baseline)\u306e\u65e5\u672c\u8a9e\u8a33\u3067\u3059\u3002(\u3060\u3044\u3076google\u7ffb\u8a33\u3067\u3059)","281633c6":"\u305d\u3057\u3066\u6700\u5f8c\u306b\u3001submission\u3092CSV\u3067\u51fa\u529b\u3057\u307e\u3059\uff01","b2d3f1fa":"## 3. Why BERT matters?\n\nBERT\u304c\u6709\u80fd\u3067\u3042\u308b\u8981\u56e0\u3092\u898b\u3066\u3044\u304d\u307e\u3057\u3087\u3046\uff0e\n\n![stats](https:\/\/miro.medium.com\/max\/1200\/0*-k_fjBnCuByNye4v)\n\n\u3059\u3079\u3066\u306eGLUE\u30bf\u30b9\u30af\u304c\u975e\u5e38\u306b\u6709\u610f\u7fa9\u306aTransformer\uff08Open-GPT\u3001BERT\u3001BigBird\uff09\u3068\u3044\u3046\u30a8\u30f3\u30b3\u30fc\u30c0\u30fc\u306b\u57fa\u3065\u304f\u6c4e\u7528\u30e2\u30c7\u30eb\u3067\u3042\u308b\u3053\u3068\u306f\u660e\u3089\u304b\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u304c\u3001\u305f\u3063\u305f\u4e00\u5e74\u3067\u30bf\u30b9\u30af\u5c02\u7528\u30e2\u30c7\u30eb\u3068\u4eba\u9593\u306e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u306e\u30ae\u30e3\u30c3\u30d7\u3092\u57cb\u3081\u307e\u3057\u305f\u3002","f4f9363f":"<font size=4 color='red'>If you like this approach please give this kernel an UPVOTE to show your appreciation<\/font>","a798d1ce":"**Now, we turn `predictions.json` into a `submission.csv` file.**","fd581617":"## 1. The BERT Landscape\n\n> BERT\u306f\u3001\u3055\u307e\u3056\u307e\u306a\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\u30bf\u30b9\u30af\u3067SOTA\u3092\u9054\u6210\u3057\u3066\u3044\u308bDL\u30e2\u30c7\u30eb\u3067\u3059\u3002 BERT\u306f **Bidirectional Encoder Representations for Transformers**\u306e\u7565\u3067\u3059\u3002 \u30a6\u30a3\u30ad\u30da\u30c7\u30a3\u30a2\u3068BooksCorpus\u3067\u4e8b\u524d\u306b\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3055\u308c\u3066\u3044\u3066\u3001\uff08\u7279\u5b9a\u306e\uff09\u30bf\u30b9\u30af\u56fa\u6709\u306e\u5fae\u8abf\u6574\u304c\u5fc5\u8981\u3067\u3059\u3002\n \n **Question Answering\uff08SQuAD v1.1\uff09**\u3001**Natural Language Inference\uff08MNLI\uff09**\u306a\u3069\u3001\u3055\u307e\u3056\u307e\u306aNLP\u30bf\u30b9\u30af\u3067SOTA\u3092\u9054\u6210\u3057\u3001\u6a5f\u68b0\u5b66\u7fd2\u30b3\u30df\u30e5\u30cb\u30c6\u30a3\u306b\u5927\u304d\u306a\u885d\u6483\u3092\u4e0e\u3048\u307e\u3057\u305f\u3002\n \n BERT\u304cNLP\u306e\u72b6\u6cc1\u3092\u5927\u304d\u304f\u5909\u3048\u305f\u3068\u8a00\u3063\u3066\u3082\u904e\u8a00\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u3002 11\u306e\u500b\u3005\u306eNLP\u30bf\u30b9\u30af\u3067\u3001\u5927\u304d\u306a\u30e9\u30d9\u30eb\u306e\u306a\u3044\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3055\u308c\u305f\u30e2\u30c7\u30eb\u3092\u4f7f\u7528\u3057\uff0cSOTA\u3092\u3092\u9054\u6210\u3057\u307e\u3057\u305f\u3002\u30e2\u30c7\u30eb\u306e\u518d\u5b66\u7fd2\u3082\u307b\u3068\u3093\u3069\u884c\u3063\u3066\u3044\u307e\u305b\u3093\uff0e \u3053\u308c\u306f\u3001NLP\u30e2\u30c7\u30eb\u306e\u8a2d\u8a08\u65b9\u6cd5\u306e\u69cb\u9020\u7684\u5909\u5316\u3092\u793a\u3057\u3066\u3044\u307e\u3059\u3002\n\nBERT\u306f\u3001Google\u306eTransformerXL\u3001OpenAI\u306eGPT-2\u3001XLNet\u3001ERNIE2.0\u3001RoBERTa\u306a\u3069\u3001\u6700\u8fd1\u306e\u591a\u304f\u306eNLP\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u3001\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30a2\u30d7\u30ed\u30fc\u30c1\u3001\u304a\u3088\u3073\u8a00\u8a9e\u30e2\u30c7\u30eb\u306b\u5f71\u97ff\u3092\u4e0e\u3048\u307e\u3057\u305f\u3002","e6abd6f1":"submission\u306e\u8981\u4ef6\u306b\u4e00\u81f4\u3059\u308b\u3088\u3046\u306bJSON\u56de\u7b54\u3092\u518d\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3057\u307e\u3059\u3002","d96ca678":"## 5. Fine Tuning Techniques for BERT\n\u7279\u5b9a\u306e\u30bf\u30b9\u30af\u306bBERT\u3092\u4f7f\u7528\u3059\u308b\u306e\u306f\u6bd4\u8f03\u7684\u7c21\u5358\u3067\u3059\u3002 BERT\u306f\u3001\u30b3\u30a2\u30e2\u30c7\u30eb\u306b\u5c0f\u3055\u306a\u30ec\u30a4\u30e4\u30fc\u3092\u8ffd\u52a0\u3059\u308b\u3060\u3051\u3067\u3001\u3055\u307e\u3056\u307e\u306a\u8a00\u8a9e\u30bf\u30b9\u30af\u306b\u4f7f\u7528\u3067\u304d\u307e\u3059\u3002\n\n### 5.1 Sequence Classification Tasks\n**[CLS]** \u30c8\u30fc\u30af\u30f3\u306e\u6700\u7d42\u7684\u306ahidden state\u306f\u3001\u5165\u529b\u30b7\u30fc\u30b1\u30f3\u30b9\u306e\u56fa\u5b9a\u6b21\u5143\u30d7\u30fc\u30eb\u8868\u73fe\u3068\u3057\u3066\u53d6\u5f97\u3055\u308c\u307e\u3059\u3002 \u3053\u308c\u306f\u5206\u985e\u30ec\u30a4\u30e4\u30fc\u306b\u9001\u3089\u308c\u307e\u3059\u3002 \u5206\u985e\u30ec\u30a4\u30e4\u30fc\u306f\u3001\u8ffd\u52a0\u3055\u308c\u308b\u552f\u4e00\u306e\u65b0\u3057\u3044\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u3067\u3042\u308a\u3001K x H\u306e\u6b21\u5143\u3092\u6301\u3061\u307e\u3059\u3002\u3053\u3053\u3067\u3001K\u306f\u5206\u985e\u30e9\u30d9\u30eb\u306e\u6570\u3001H\u306fhidden state\u306e\u30b5\u30a4\u30ba\u3067\u3059\u3002 \u30e9\u30d9\u30eb\u78ba\u7387\u306f\u3001softmax\u3067\u8a08\u7b97\u3055\u308c\u307e\u3059\u3002\n\n![](https:\/\/yashuseth.files.wordpress.com\/2019\/06\/fig1-1.png?w=460&h=400)\n\n### 5.2 Sentence Pair Classification Tasks\n\u3053\u306e\u624b\u9806\u306f\u3001\u5358\u4e00\u30b7\u30fc\u30b1\u30f3\u30b9\u5206\u985e\u30bf\u30b9\u30af\u3068\u307e\u3063\u305f\u304f\u540c\u3058\u3067\u3059\u3002 \u552f\u4e00\u306e\u9055\u3044\u306f\u30012\u3064\u306e\u6587\u304c\u9023\u7d50\u3055\u308c\u308b\u5165\u529b\u8868\u73fe\u3067\u3059\u3002\n\n![](https:\/\/yashuseth.files.wordpress.com\/2019\/06\/fig2-1.png?w=443&h=398)\n\n### 5.3 Question-Answering Tasks (Goal of this competition)\n\u8cea\u554f\u3078\u306e\u56de\u7b54\u306f\u4e88\u6e2c\u30bf\u30b9\u30af\u3067\u3059\u3002 \u8cea\u554f\u3068\u6587\u8108paragraph\u304c\u4e0e\u3048\u3089\u308c\u308b\u3068\u3001\u30e2\u30c7\u30eb\u306f\u3001\u8cea\u554f\u306b\u56de\u7b54\u3059\u308b\u53ef\u80fd\u6027\u304c\u6700\u3082\u9ad8\u3044paragraph\u304b\u3089\u958b\u59cb\u30c8\u30fc\u30af\u30f3\u3068\u7d42\u4e86\u30c8\u30fc\u30af\u30f3\u3092\u4e88\u6e2c\u3057\u307e\u3059\u3002\n\n![](https:\/\/yashuseth.files.wordpress.com\/2019\/06\/fig6.png?w=389&h=297)\n\n\u6587\u306e\u30da\u30a2\u306e\u30bf\u30b9\u30af\u3068\u540c\u69d8\u306b\u3001\u8cea\u554f\u306f\u5165\u529b\u30b7\u30fc\u30b1\u30f3\u30b9\u306e\u6700\u521d\u306e\u6587\u306b\u306a\u308a\u3001paragraph\u306f2\u756a\u76ee\u306e\u6587\u306b\u306a\u308a\u307e\u3059\u3002 \u96a0\u3055\u308c\u305f\u5f62\u72b6\u30b5\u30a4\u30ba\u306b\u7b49\u3057\u3044\u30b5\u30a4\u30ba\u306e\u958b\u59cb\u30d9\u30af\u30c8\u30eb\u3068\u7d42\u4e86\u30d9\u30af\u30c8\u30eb\u306e\u5fae\u8abf\u6574\u4e2d\u306b\u5b66\u7fd2\u3055\u308c\u308b2\u3064\u306e\u65b0\u3057\u3044\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u306e\u307f\u304c\u3042\u308a\u307e\u3059\u3002 \u30c8\u30fc\u30af\u30f3i\u304c\u5fdc\u7b54\u30b9\u30d1\u30f3\u306e\u958b\u59cb\u3067\u3042\u308b\u78ba\u7387\u306f\u3001softmax\uff08S . K\uff09\u3068\u3057\u3066\u8a08\u7b97\u3055\u308c\u307e\u3059\u3002\u3053\u3053\u3067\u3001S\u306f\u958b\u59cb\u30d9\u30af\u30c8\u30eb\u3067\u3001K\u306f\u30c8\u30fc\u30af\u30f3i\u306e\u6700\u7d42\u7684\u306a\u30c8\u30e9\u30f3\u30b9\u51fa\u529b\u3067\u3059\u3002 \u540c\u3058\u3053\u3068\u304c\u7d42\u4e86\u30c8\u30fc\u30af\u30f3\u306b\u3082\u5f53\u3066\u306f\u307e\u308a\u307e\u3059\u3002\n\n![](https:\/\/yashuseth.files.wordpress.com\/2019\/06\/fig3.png?w=452&h=380)\n\n### 5.4 Single Sentence Tagging Tasks\n\u540d\u524d\u4ed8\u304d\u30a8\u30f3\u30c6\u30a3\u30c6\u30a3\u8a8d\u8b58\u306a\u3069\u306e\u5358\u4e00\u6587\u306e\u30bf\u30b0\u4ed8\u3051\u30bf\u30b9\u30af\u3067\u306f\u3001\u5165\u529b\u5185\u306e\u3059\u3079\u3066\u306e\u5358\u8a9e\u306b\u5bfe\u3057\u3066\u30bf\u30b0\u3092\u4e88\u6e2c\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002 \u3059\u3079\u3066\u306e\u5165\u529b\u30c8\u30fc\u30af\u30f3\u306e\u6700\u7d42\u7684\u306ahidden states\uff08\u30c8\u30e9\u30f3\u30b9\u30d5\u30a9\u30fc\u30de\u30fc\u51fa\u529b\uff09\u304c\u5206\u985e\u30ec\u30a4\u30e4\u30fc\u306b\u4f9b\u7d66\u3055\u308c\u3001\u3059\u3079\u3066\u306e\u30c8\u30fc\u30af\u30f3\u306e\u4e88\u6e2c\u304c\u53d6\u5f97\u3055\u308c\u307e\u3059\u3002 WordPiece\u30c8\u30fc\u30af\u30ca\u30a4\u30b6\u30fc\u306f\u4e00\u90e8\u306e\u5358\u8a9e\u3092\u30b5\u30d6\u30ef\u30fc\u30c9\u306b\u5206\u5272\u3059\u308b\u305f\u3081\u3001\u5358\u8a9e\u306e\u6700\u521d\u306e\u30c8\u30fc\u30af\u30f3\u306e\u307f\u306e\u4e88\u6e2c\u304c\u8003\u616e\u3055\u308c\u307e\u3059\u3002\n\n![](https:\/\/yashuseth.files.wordpress.com\/2019\/06\/fig4.png?w=441&h=389)\n\n### 5.5 Hyperparameter Tuning\n\u6700\u9069\u306a\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u5024\u306f\u30bf\u30b9\u30af\u56fa\u6709\u3067\u3059\u3002 \u3057\u304b\u3057\u3001\u8457\u8005\u306f\u3001\u6b21\u306e\u7bc4\u56f2\u306e\u5024\u304c\u3059\u3079\u3066\u306e\u30bf\u30b9\u30af\u3067\u3046\u307e\u304f\u6a5f\u80fd\u3059\u308b\u3053\u3068\u3092\u767a\u898b\u3057\u307e\u3057\u305f\n\n* **Dropout** \u2013 0.1\n* **Batch Size** \u2013 16, 32\n* **Learning Rate (Adam)** \u2013 5e-5, 3e-5, 2e-5\n* **Number of epochs** \u2013 3, 4 (yeah you read it right)\n\n\u8457\u8005\u306f\u307e\u305f\u3001\u5927\u304d\u306a\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\uff08> 100k\u306e\u30e9\u30d9\u30eb\u4ed8\u304d\u30b5\u30f3\u30d7\u30eb\uff09\u306f\u3001\u5c0f\u3055\u306a\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3088\u308a\u3082\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u306e\u9078\u629e\u306b\u5bfe\u3059\u308b\u611f\u5ea6\u304c\u4f4e\u3044\u3053\u3068\u3092\u767a\u898b\u3057\u307e\u3057\u305f\u3002","53994337":"<font size=4 color='#57467B'>Please give this kernel an UPVOTE to show your appreciation, if you find it useful.<\/font>\n<br>\n<br>\n<font size=4 color='#57467B'>Also don't forget to upvote Dimitre's kernel <a href='https:\/\/www.kaggle.com\/dimitreoliveira\/using-tf-2-0-w-bert-on-nq-translated-to-tf2-0'>here<\/a><\/font>","7932aa3c":"## 6. BERT Benchmarks on Question Answering tasks\n> Standford Question Answering Dataset\uff08SQuAD\uff09\u306f\u3001\u30af\u30e9\u30a6\u30c9\u30bd\u30fc\u30b7\u30f3\u30b0\u3055\u308c\u305f10\u4e07\u306e\u8cea\u554f\/\u56de\u7b54\u30da\u30a2\u306e\u30b3\u30ec\u30af\u30b7\u30e7\u30f3\u3067\u3059(Rajpurkar et al., 2016)\u3002 \u8cea\u554f\u3068\u56de\u7b54\u3092\u542b\u3080\u30a6\u30a3\u30ad\u30da\u30c7\u30a3\u30a2\u304b\u3089\u306eparagraph\u304c\u4e0e\u3048\u3089\u308c\u305f\u5834\u5408\u3001\u30bf\u30b9\u30af\u306fparagraph\u5185\u306e\"answer text span\"\u3092\u4e88\u6e2c\u3059\u308b\u3053\u3068\u3067\u3059\u3002\n\nSQUAD\u3067\u306f\u3001BERT\u30e9\u30fc\u30b8\u306b\u3088\u3063\u3066\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u306e\u5927\u304d\u306a\u6539\u5584\u304c\u9054\u6210\u3055\u308c\u307e\u3057\u305f\u3002 \u6700\u9ad8\u306e\u30b9\u30b3\u30a2\u3092\u9054\u6210\u3057\u305f\u30e2\u30c7\u30eb\u306f\u3001BERT\u30e9\u30fc\u30b8\u30e2\u30c7\u30eb\u306e\u30a2\u30f3\u30b5\u30f3\u30d6\u30eb\u3067\u3001TriviaQA\u3067\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u5897\u5f37\u3057\u307e\u3057\u305f\u3002\n\n![](https:\/\/miro.medium.com\/max\/558\/1*CYzIm-u1-JUR2jDyPRHlQg.png)","9fac1101":"**Tensorflow flags\u306f\u3001TF\u30b7\u30b9\u30c6\u30e0\u5185\u3067\u6e21\u3059\u3053\u3068\u304c\u3067\u304d\u308b\u5909\u6570\u3067\u3059\u3002 \u4ee5\u4e0b\u306e\u3059\u3079\u3066\u306e\u30d5\u30e9\u30b0\u306b\u306f\u3001\u30d5\u30e9\u30b0\u306e\u5185\u5bb9\u3068\u4f7f\u7528\u65b9\u6cd5\u306b\u95a2\u3059\u308b\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u304c\u63d0\u4f9b\u3055\u308c\u3066\u3044\u307e\u3059\u3002**\n\n**\u3053\u308c\u3089\u306e\u307b\u3068\u3093\u3069\u306f\u3001\u4e0b\u90e8\u306b\u3042\u308b\u7279\u5225\u306a\u30d5\u30e9\u30b0\u3092\u9664\u304d\u3001\u5fc5\u8981\u306b\u5fdc\u3058\u3066\u5909\u66f4\u3067\u304d\u307e\u3059\u3002\u7279\u5225\u306a\u30d5\u30e9\u30b0\u306f\u3001Kaggle\u30d0\u30c3\u30af\u30a8\u30f3\u30c9\u3067\u52d5\u4f5c\u3059\u308b\u3088\u3046\u306b\u305d\u306e\u307e\u307e\u7dad\u6301\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002**","e563be79":"## 2. What is BERT?\n\nBERT\u306f\u57fa\u672c\u7684\u306b\u3001Transformer\u30a8\u30f3\u30b3\u30fc\u30c0\u30fc\u3092\u7a4d\u307f\u91cd\u306d\u305f\u3082\u306e\u3067\u3059\uff08Transformer\u5168\u4f53\u3067\u306f\u306a\u304f\u3001\u30a8\u30f3\u30b3\u30fc\u30c0\u30fc\u306e\u307f\u3067\u3059\uff09\u3002 \u53cc\u65b9\u5411\u6027\u306e\u6982\u5ff5\u306f\u3001BERT\u3068\u305d\u306e\u524d\u8eab\u3067\u3042\u308bOpenAI GPT\u306e\u4e3b\u306a\u9055\u3044\u3067\u3059\u3002 BERT\u306f\u53cc\u65b9\u5411\u6027\u3067\u3059\u3002\u3053\u308c\u306f\u3001self-attention\u5c64\u304c\u53cc\u65b9\u5411\u3067self-attention\u3092\u5b9f\u884c\u3059\u308b\u305f\u3081\u3067\u3059\u3002\n\n\u3053\u306e\u30bb\u30c3\u30b7\u30e7\u30f3\u3067\u3044\u304f\u3064\u304b\u8aac\u660e\u3057\u305f\u3044\u3053\u3068\u304c\u3042\u308a\u307e\u3059\uff0e\n\n1. BERT\u306f\u3001Transformers\u306eBidirectional Encoder Representations\u306e\u7565\u3067\u3059\u3002 \u305d\u308c\u305e\u308c\u306e\u8a00\u8449\u306b\u306f\u610f\u5473\u304c\u3042\u308a\u3001\u7406\u89e3\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002 \u4eca\u306e\u3068\u3053\u308d\u3001**\u3053\u306etopic\u306e\u91cd\u8981\u306a\u30dd\u30a4\u30f3\u30c8\u306f\u6b21\u306e\u3068\u304a\u308a\u3067\u3059\u3002BERT\u306fTransformer\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306b\u57fa\u3065\u3044\u3066\u3044\u307e\u3059\u3002**\n\n2. BERT\u306f** Wikipedia\u5168\u4f53\uff0825\u5104\u8a9e\uff01\uff09\u3068Book Corpus\uff088\u5104\u8a9e\uff09\u3092\u542b\u3080\u3001\u30e9\u30d9\u30eb\u306e\u306a\u3044\u30c6\u30ad\u30b9\u30c8\u306e\u5927\u898f\u6a21\u306a\u30b3\u30fc\u30d1\u30b9\u3067\u4e8b\u524d\u306b\u8a13\u7df4\u3055\u308c\u3066\u3044\u307e\u3059**\u3002 \u3053\u306e\u4e8b\u524d\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u624b\u9806\u306f\u3001BERT\u306e\u6210\u529f\u306b\u3068\u3063\u3066\u975e\u5e38\u306b\u91cd\u8981\u3067\u3059\u3002 \u5927\u304d\u306a\u30c6\u30ad\u30b9\u30c8\u30b3\u30fc\u30d1\u30b9\u3067\u30e2\u30c7\u30eb\u3092\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3059\u308b\u3068\u3001\u30e2\u30c7\u30eb\u304c\u8a00\u8a9e\u306e\u3057\u304f\u307f\u3092\u3088\u308a\u6df1\u304f\u5bc6\u63a5\u306b\u7406\u89e3\u3057\u59cb\u3081\u308b\u305f\u3081\u3067\u3059\u3002 \u3053\u306e\u77e5\u8b58\u306f\u3001\u307b\u3068\u3093\u3069\u3059\u3079\u3066\u306eNLP\u30bf\u30b9\u30af\u306b\u5f79\u7acb\u3061\u307e\u3059\u3002\n\n3. BERT\u306f**deeply bidirectional**\u306e\u30e2\u30c7\u30eb\u3067\u3059\u3002 \u53cc\u65b9\u5411\u3068\u306f\u3001BERT\u304c\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30d5\u30a7\u30fc\u30ba\u4e2d\u306b\u30c8\u30fc\u30af\u30f3\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u306e\u5de6\u5074\u3068\u53f3\u5074\u306e\u4e21\u65b9\u304b\u3089\u60c5\u5831\u3092\u5b66\u7fd2\u3059\u308b\u3053\u3068\u3092\u610f\u5473\u3057\u307e\u3059\u3002\n\n\u3053\u306e\u53cc\u65b9\u5411\u6027\u306e\u7406\u89e3\u306f\u3001NLP\u30e2\u30c7\u30eb\u3092\u6b21\u306e\u30ec\u30d9\u30eb\u306b\u5f15\u304d\u4e0a\u3052\u308b\u305f\u3081\u306b\u4e0d\u53ef\u6b20\u3067\u3059\u3002 \u305d\u308c\u304c\u672c\u5f53\u306b\u4f55\u3092\u610f\u5473\u3059\u308b\u304b\u3092\u7406\u89e3\u3059\u308b\u305f\u3081\u306e\u4f8b\u3092\u898b\u3066\u307f\u307e\u3057\u3087\u3046\u3002 \u540c\u3058\u5358\u8a9e\u3092\u6301\u30642\u3064\u306e\u6587\u304c\u3042\u308b\u5834\u5408\u3082\u3042\u308a\u307e\u3059\u304c\u3001\u305d\u306e\u610f\u5473\u306f\u3001\u4ee5\u4e0b\u306b\u793a\u3059\u3088\u3046\u306b\u524d\u5f8c\u306b\u57fa\u3065\u3044\u3066\u5b8c\u5168\u306b\u7570\u306a\u308b\u5834\u5408\u304c\u3042\u308a\u307e\u3059\u3002\n\n![bidirectionalexample](https:\/\/s3-ap-south-1.amazonaws.com\/av-blog-media\/wp-content\/uploads\/2019\/09\/sent_context.png)\n\n\u3053\u308c\u3089\u306e\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u3092\u8003\u616e\u3057\u306a\u3044\u3068\u3001DL\u30e2\u30c7\u30eb\u304c\u771f\u306b\u610f\u5473\u3092\u7406\u89e3\u3059\u308b\u3053\u3068\u306f\u4e0d\u53ef\u80fd\u3067\u3042\u308a\u3001\u4f55\u5ea6\u3082\u4f55\u5ea6\u3082\u7121\u99c4\u306a\u5fdc\u7b54\u3092\u6295\u3052\u308b\u3053\u3068\u304c\u3042\u308a\uff0c\u826f\u3044\u3053\u3068\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u3002\n\nBut BERT fixes this. Yes it does. That was one of the game changing aspect of BERT.\n\n\u3057\u304b\u3057\u3001BERT\u306f\u3053\u308c\u3092\u4fee\u6b63\u3057\u307e\u3059\u3002\n\n4. \u6700\u5f8c\u306b\u3001BERT\u306e\u6700\u5927\u306e\u5229\u70b9\u306f\u3001**ImageNet\u306e\u3088\u3046\u306a\u885d\u6483**\u3092\u3082\u305f\u3089\u3059\u3053\u3068\u3067\u3059\u3002BERT\u306e\u6700\u3082\u5370\u8c61\u7684\u306a\u5074\u9762\u306f\u3001\u3044\u304f\u3064\u304b\u306e\u8ffd\u52a0\u306e\u51fa\u529b\u30ec\u30a4\u30e4\u30fc\u3092\u8ffd\u52a0\u3057\u3066\u72b6\u614b\u3092\u4f5c\u6210\u3059\u308b\u3053\u3068\u3067\u5fae\u8abf\u6574\u3067\u304d\uff0c\u3055\u307e\u3056\u307e\u306aNLP\u30bf\u30b9\u30af\u306eSOTA\u3092\u9054\u6210\u3057\u307e\u3057\u305f\uff0e\n","2d26ed44":"The Bert model produces a `confidence` score, which the Kaggle metric does not use. You, however, can use that score to determine which answers get submitted. See the limits commented out in `create_short_answer` and `create_long_answer` below for an example.\n\nValues for `confidence` will range between `1.0` and `2.0`.","57098fdf":"## 8. Conclusion\nBERT\u306f\u3001\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\u306e\u305f\u3081\u306e\u6a5f\u68b0\u5b66\u7fd2\u306e\u4f7f\u7528\u306b\u304a\u3051\u308b\u9593\u9055\u3044\u306a\u304f\u30d6\u30ec\u30fc\u30af\u30b9\u30eb\u30fc\u3067\u3059\u3002 \u3053\u308c\u306f\u89aa\u3057\u307f\u3084\u3059\u304f\u3001\u9ad8\u901f\u306a\u5fae\u8abf\u6574\u304c\u53ef\u80fd\u306a\u305f\u3081\u3001\u5c06\u6765\u7684\u306b\u306f\u5e45\u5e83\u3044\u5b9f\u7528\u7684\u306a\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u304c\u53ef\u80fd\u306b\u306a\u308b\u3067\u3057\u3087\u3046\u3002 \u3053\u306e\u8981\u7d04\u3067\u306f\u3001\u904e\u5ea6\u306e\u6280\u8853\u7684\u8a73\u7d30\u306bdr\u308c\u305a\u306b\u3001\u8ad6\u6587\u306e\u4e3b\u8981\u306a\u30a2\u30a4\u30c7\u30a2\u3092\u8aac\u660e\u3057\u3088\u3046\u3068\u3057\u307e\u3057\u305f\u3002 \u3055\u3089\u306b\u6df1\u304f\u6398\u308a\u4e0b\u3052\u305f\u3044\u5834\u5408\u306f\u3001\u8a18\u4e8b\u5168\u4f53\u3068\u305d\u306e\u4e2d\u3067\u53c2\u7167\u3055\u308c\u3066\u3044\u308b\u88dc\u52a9\u7684\u306a\u8a18\u4e8b\u3092\u8aad\u3080\u3053\u3068\u3092\u5f37\u304f\u304a\u52e7\u3081\u3057\u307e\u3059\u3002\n\n> **\u30b3\u30e1\u30f3\u30c8\u30bb\u30af\u30b7\u30e7\u30f3\u3067\u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3092\u6539\u5584\u3059\u308b\u305f\u3081\u306e\u63d0\u6848\u3092\u304a\u6c17\u8efd\u306b\u304a\u5bc4\u305b\u304f\u3060\u3055\u3044\uff08\u3082\u3057\u3042\u308c\u3070\uff09**","9a9372bd":"![](http:\/\/)<font size=4 color='#25171A'>This is a two part Notebook<\/font>\n\n<a href=\"#Comprehensive-BERT-Tutorial\">1. Comprehensive BERT Tutorial<\/a> <br>\n<a href=\"#Code-Implementation-in-Tensorflow-2.0\">2. Implementation in Tensorflow 2.0<\/a>\n<br>\n\n> **Note:** \u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u306e\u4e3b\u306a\u76ee\u7684\u306f\u3001**\u3053\u306e\u30b3\u30f3\u30c6\u30b9\u30c8\u306e\u30d9\u30fc\u30b9\u30e9\u30a4\u30f3\u3068\u3001BERT\u306b\u3064\u3044\u3066\u306e\u8aac\u660e**\u3092\u63d0\u4f9b\u3059\u308b\u3053\u3068\u3067\u3059\u3002 NLP\u30b3\u30f3\u30da\u30c6\u30a3\u30b7\u30e7\u30f3\u3067\u4ed5\u4e8b\u3092\u59cb\u3081\u305f\u3068\u304d\u3001\u3053\u306e\u3088\u3046\u306a\u30ce\u30fc\u30c8\u3092\u898b\u3064\u3051\u3089\u308c\u306a\u304b\u3063\u305f\u306e\u3067\u3001\u79c1\u306f\u305d\u306e\u3088\u3046\u306a\u30ce\u30fc\u30c8\u3092\u4f7f\u3044\u305f\u3044\u3068\u601d\u3044\u307e\u3057\u305f\u3002 \u521d\u5fc3\u8005\u304c\u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u306e\u6069\u6075\u3092\u53d7\u3051\u308b\u3053\u3068\u3092\u9858\u3063\u3066\u3044\u307e\u3059\u3002 \u3042\u306a\u305f\u304c\u521d\u5fc3\u8005\u3067\u3042\u3063\u3066\u3082\u3001\u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u306b\u8208\u5473\u304c\u3042\u308b\u304b\u3082\u3057\u308c\u306a\u3044\u8981\u7d20\u304c\u3042\u308b\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u3002\n\n<br>","452f9fc5":"## 4. How BERT Works?\nBERT\u3092\u5c11\u3057\u8a73\u3057\u304f\u898b\u3066\u3001\u305d\u308c\u304c\u306a\u305c\u8a00\u8a9e\u3092\u30e2\u30c7\u30eb\u5316\u3059\u308b\u306e\u306b\u52b9\u679c\u7684\u306a\u306e\u304b\u3092\u898b\u3066\u3044\u304d\u307e\u3057\u3087\u3046\u3002 BERT\u304c\u3067\u304d\u308b\u3053\u3068\u306f\u65e2\u306b\u898b\u3066\u304d\u307e\u3057\u305f\u304c\u3001\u3069\u3046\u3059\u308c\u3070\u305d\u308c\u304c\u3067\u304d\u307e\u3059\u304b\uff1f \u3053\u306e\u30bb\u30af\u30b7\u30e7\u30f3\u3067\u306f\u3001\u3053\u306e\u95a2\u9023\u3059\u308b\u8cea\u554f\u306b\u7b54\u3048\u307e\u3059\u3002\n\n### 1. Architecture of BERT\nBERT\u306f\u3001\u591a\u5c64\u53cc\u65b9\u5411\u30c8\u30e9\u30f3\u30b9\u30d5\u30a9\u30fc\u30de\u30fc\u30a8\u30f3\u30b3\u30fc\u30c0\u30fc\u3067\u3059\u3002 \u3053\u306e\u8ad6\u6587\u3067\u306f2\u3064\u306e\u30e2\u30c7\u30eb\u304c\u7d39\u4ecb\u3055\u308c\u3066\u3044\u307e\u3059\u3002\n\n* BERT base \u2013 12 layers (transformer blocks), 12 attention heads, and 110 million parameters.\n* BERT Large \u2013 24 layers, 16 attention heads and, 340 million parameters.\n\nBERT\uff08\u5225\u540d\u30c8\u30e9\u30f3\u30b9\u30d5\u30a9\u30fc\u30de\u30fc\uff09\u306e\u69cb\u6210\u8981\u7d20\u3092\u6df1\u304f\u7406\u89e3\u3059\u308b\u306b\u306f\u3001\u5fc5\u305a\u78ba\u8a8d\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n\n[this awesome post](http:\/\/jalammar.github.io\/illustrated-transformer\/) \u2013 The Illustrated Transformers.\n\n*\u4e0b\u56f3\u304cBERT\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u3092\u8868\u3057\u3066\u3044\u307e\u3059\u3002*\n![arch](https:\/\/s3-ap-south-1.amazonaws.com\/av-blog-media\/wp-content\/uploads\/2019\/09\/bert_encoder.png)\n\n### 2. Preprocessing Text for BERT\n\nBERT\u3067\u4f7f\u7528\u3055\u308c\u308b\u5165\u529b\u8868\u73fe\u306f\u3001\u30c8\u30fc\u30af\u30f3\u306e\u5358\u4e00\u30b7\u30fc\u30b1\u30f3\u30b9\u5185\u306e\u5358\u4e00\u306e\u30c6\u30ad\u30b9\u30c8\u6587\u30681\u7d44\u306e\u6587\uff08\u8cea\u554f\u3001\u56de\u7b54\u306a\u3069\uff09\u3092\u8868\u3059\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\n* \u3059\u3079\u3066\u306e\u5165\u529b\u30b7\u30fc\u30b1\u30f3\u30b9\u306e\u6700\u521d\u306e\u30c8\u30fc\u30af\u30f3\u306f\u3001\u7279\u5225\u306a\u5206\u985e\u30c8\u30fc\u30af\u30f3**[CLS]** \u3067\u3059\u3002 \u3053\u306e\u30c8\u30fc\u30af\u30f3\u306f\u3001\u5206\u985e\u30bf\u30b9\u30af\u3067\u30b7\u30fc\u30b1\u30f3\u30b9\u8868\u73fe\u5168\u4f53\u306e\u96c6\u7d04\u3068\u3057\u3066\u4f7f\u7528\u3055\u308c\u307e\u3059\u3002 \u975e\u5206\u985e\u30bf\u30b9\u30af\u3067\u306f\u7121\u8996\u3055\u308c\u307e\u3059\u3002\n\n* \u5358\u4e00\u30c6\u30ad\u30b9\u30c8\u6587\u306e\u30bf\u30b9\u30af\u306e\u5834\u5408\u3001\u3053\u306e**[CLS]** \u30c8\u30fc\u30af\u30f3\u306e\u5f8c\u306b\u306f\u3001WordPiece\u30c8\u30fc\u30af\u30f3\u3068\u533a\u5207\u308a\u30c8\u30fc\u30af\u30f3**[SEP]** \u304c\u7d9a\u304d\u307e\u3059\u3002\n\n![](https:\/\/yashuseth.files.wordpress.com\/2019\/06\/fig7.png)\n\n* \u6587\u30da\u30a2\u30bf\u30b9\u30af\u306e\u5834\u5408\u30012\u3064\u306e\u6587\u306eWordPiece\u30c8\u30fc\u30af\u30f3\u306f\u5225\u306e[SEP]\u30c8\u30fc\u30af\u30f3\u3067\u533a\u5207\u3089\u308c\u307e\u3059\u3002 \u3053\u306e\u5165\u529b\u30b7\u30fc\u30b1\u30f3\u30b9\u306f\u3001**[SEP]** \u30c8\u30fc\u30af\u30f3\u3067\u3082\u7d42\u4e86\u3057\u307e\u3059\u3002\n\n* \u6587A\u307e\u305f\u306f\u6587B\u3092\u793a\u3059\u57cb\u3081\u8fbc\u307f\u6587\u304c\u5404\u30c8\u30fc\u30af\u30f3\u306b\u8ffd\u52a0\u3055\u308c\u307e\u3059\u3002 \u6587\u306e\u57cb\u3081\u8fbc\u307f\u306f\u3001\u8a9e\u5f59\u304c2\u306e\u30c8\u30fc\u30af\u30f3\/\u5358\u8a9e\u306e\u57cb\u3081\u8fbc\u307f\u306b\u4f3c\u3066\u3044\u307e\u3059\u3002\n\n* \u30b7\u30fc\u30b1\u30f3\u30b9\u5185\u306e\u4f4d\u7f6e\u3092\u793a\u3059\u305f\u3081\u306b\u3001\u4f4d\u7f6e\u57cb\u3081\u8fbc\u307f\u3082\u5404\u30c8\u30fc\u30af\u30f3\u306b\u8ffd\u52a0\u3055\u308c\u307e\u3059\u3002\n\nBERT\u958b\u767a\u8005\u306f\u3001\u30e2\u30c7\u30eb\u306b\u5165\u529b\u3059\u308b\u524d\u306b\u8a00\u8a9e\u3092\u8868\u3059\u7279\u5b9a\u306e\u30eb\u30fc\u30eb\u30bb\u30c3\u30c8\u3092\u8a2d\u5b9a\u3057\u307e\u3057\u305f\u3002\n\n![](https:\/\/s3-ap-south-1.amazonaws.com\/av-blog-media\/wp-content\/uploads\/2019\/09\/bert_emnedding.png)\n\n\u307e\u305a\u7b2c\u4e00\u306b\u3001\u3059\u3079\u3066\u306e\u5165\u529b\u57cb\u3081\u8fbc\u307f\u306f3\u3064\u306e\u57cb\u3081\u8fbc\u307f\u306e\u7d44\u307f\u5408\u308f\u305b\u3067\u3059\u3002\uff1a\n\n* **\u4f4d\u7f6e\u306e\u57cb\u3081\u8fbc\u307f(Position Embeddings)**\uff1aBERT\u306f\u3001\u4f4d\u7f6e\u306e\u57cb\u3081\u8fbc\u307f\u3092\u5b66\u7fd2\u304a\u3088\u3073\u4f7f\u7528\u3057\u3066\u3001\u6587\u4e2d\u306e\u5358\u8a9e\u306e\u4f4d\u7f6e\u3092\u8868\u73fe\u3057\u307e\u3059\u3002 \u3053\u308c\u3089\u306f\u3001RNN\u3068\u306f\u7570\u306a\u308a\u3001\u300c\u30b7\u30fc\u30b1\u30f3\u30b9\u300d\u307e\u305f\u306f\u300c\u9806\u5e8f\u300d\u60c5\u5831\u3092\u30ad\u30e3\u30d7\u30c1\u30e3\u3067\u304d\u306a\u3044Transformer\u306e\u5236\u9650\u3092\u514b\u670d\u3059\u308b\u305f\u3081\u306b\u8ffd\u52a0\u3055\u308c\u307e\u3059\n\n* **\u30bb\u30b0\u30e1\u30f3\u30c8\u306e\u57cb\u3081\u8fbc\u307f**\uff1aBERT\u306f\u3001\u30bf\u30b9\u30af\u306e\u5165\u529b\u3068\u3057\u3066\u6587\u306e\u30da\u30a2\u3092\u53d7\u3051\u53d6\u308b\u3053\u3068\u3082\u3067\u304d\u307e\u3059\uff08\u8cea\u554f-\u56de\u7b54\uff09\u3002 \u305d\u306e\u305f\u3081\u3001\u30e2\u30c7\u30eb\u304c1\u756a\u76ee\u30682\u756a\u76ee\u306e\u6587\u3092\u533a\u5225\u3067\u304d\u308b\u3088\u3046\u306b\u30011\u756a\u76ee\u30682\u756a\u76ee\u306e\u6587\u306b\u72ec\u81ea\u306e\u57cb\u3081\u8fbc\u307f\u3092\u5b66\u7fd2\u3057\u307e\u3059\u3002 \u4e0a\u8a18\u306e\u4f8b\u3067\u306f\u3001EA\u3068\u3057\u3066\u30de\u30fc\u30af\u3055\u308c\u305f\u3059\u3079\u3066\u306e\u30c8\u30fc\u30af\u30f3\u306f\u6587A\u306b\u5c5e\u3057\u3066\u3044\u307e\u3059\uff08EB\u306b\u3064\u3044\u3066\u3082\u540c\u69d8\uff09\n\n* **\u30c8\u30fc\u30af\u30f3\u306e\u57cb\u3081\u8fbc\u307f(Token Embeddings)**\uff1a\u3053\u308c\u3089\u306f\u3001WordPiece\u30c8\u30fc\u30af\u30f3\u30dc\u30ad\u30e3\u30d6\u30e9\u30ea\u30fc\u304b\u3089\u7279\u5b9a\u306e\u30c8\u30fc\u30af\u30f3\u306b\u3064\u3044\u3066\u5b66\u7fd2\u3057\u305f\u57cb\u3081\u8fbc\u307f\u3067\u3059\u3002\n\n\u6307\u5b9a\u3055\u308c\u305f\u30c8\u30fc\u30af\u30f3\u306b\u3064\u3044\u3066\u3001\u305d\u306e\u5165\u529b\u8868\u73fe\u306f\u3001**\u5bfe\u5fdc\u3059\u308b\u30c8\u30fc\u30af\u30f3\u3001\u30bb\u30b0\u30e1\u30f3\u30c8\u3001\u304a\u3088\u3073\u4f4d\u7f6e\u306e\u57cb\u3081\u8fbc\u307f\u3092\u5408\u8a08\u3059\u308b**\u3053\u3068\u306b\u3088\u3063\u3066\u69cb\u7bc9\u3055\u308c\u307e\u3059\u3002\n\n\u3053\u306e\u3088\u3046\u306a\u5305\u62ec\u7684\u306a\u57cb\u3081\u8fbc\u307f\u30b9\u30ad\u30fc\u30e0\u306b\u306f\u3001\u30e2\u30c7\u30eb\u306b\u5f79\u7acb\u3064\u591a\u304f\u306e\u60c5\u5831\u304c\u542b\u307e\u308c\u3066\u3044\u307e\u3059\u3002\n\n\u524d\u51e6\u7406\u30b9\u30c6\u30c3\u30d7\u306e\u3053\u308c\u3089\u306e\u7d44\u307f\u5408\u308f\u305b\u306b\u3088\u308a\u3001BERT\u306f\u975e\u5e38\u306b\u7528\u9014\u304c\u5e83\u304c\u308a\u307e\u3059\u3002 \u3053\u308c\u306f\u3001\u30e2\u30c7\u30eb\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u306b\u5927\u304d\u306a\u5909\u66f4\u3092\u52a0\u3048\u308b\u3053\u3068\u306a\u304f\u3001\u8907\u6570\u306e\u7a2e\u985e\u306eNLP\u30bf\u30b9\u30af\u3067\u30e2\u30c7\u30eb\u3092\u7c21\u5358\u306b\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3067\u304d\u308b\u3053\u3068\u3092\u610f\u5473\u3057\u307e\u3059\u3002\n\n**\u30c8\u30fc\u30af\u30f3\u5316(Tokenization)**\nBERT\u306fWordPiece\u30c8\u30fc\u30af\u30f3\u5316\u3092\u4f7f\u7528\u3057\u307e\u3059\u3002 \u8a9e\u5f59\u306f\u3001\u8a00\u8a9e\u5185\u306e\u3059\u3079\u3066\u306e\u500b\u3005\u306e\u6587\u5b57\u3067\u521d\u671f\u5316\u3055\u308c\u3001\u305d\u306e\u5f8c\u3001\u8a9e\u5f59\u5185\u306e\u65e2\u5b58\u306e\u5358\u8a9e\u306e\u6700\u3082\u983b\u7e41\/\u53ef\u80fd\u6027\u306e\u9ad8\u3044\u7d44\u307f\u5408\u308f\u305b\u304c\u7e70\u308a\u8fd4\u3057\u8ffd\u52a0\u3055\u308c\u307e\u3059\u3002\n\n### 3. Pre Training\n\u30e2\u30c7\u30eb\u306f2\u3064\u306e\u30bf\u30b9\u30af\u3067\u540c\u6642\u306b\u8a13\u7df4\u3055\u308c\u307e\u3057\u305f:\n\n**1. Masked\u8a00\u8a9e\u30e2\u30c7\u30eb(Masked Language Model)** \n\n**2. \u6b21\u306e\u6587\u7ae0\u4e88\u6e2c(Next Sentence Prediction.)**\n\n**Note:** \u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3067\u306f\u3001\u3053\u308c\u3089\u306e2\u3064\u306e\u624b\u6cd5\u306b\u3064\u3044\u3066\u306f\u8aac\u660e\u3057\u307e\u305b\u3093\u3002\u30aa\u30f3\u30e9\u30a4\u30f3\u3067\u8aad\u3080\u3053\u3068\u3092\u304a\u52e7\u3081\u3057\u307e\u3059\u3002\n","d0aeb7a0":"## 7. Key Takeaways\n\n> 1) \u5de8\u5927\u306a\u898f\u6a21\u3067\u3042\u3063\u3066\u3082\u3001\u30e2\u30c7\u30eb\u306e\u30b5\u30a4\u30ba\u306f\u91cd\u8981\u3067\u3059\u3002 BERT_large\u306f\u3001345\u767e\u4e07\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u3092\u6301\u3061\u3001\u3053\u306e\u7a2e\u306e\u6700\u5927\u306e\u30e2\u30c7\u30eb\u3067\u3059\u3002 \u5c0f\u898f\u6a21\u306a\u30bf\u30b9\u30af\u3067\u306f\u30011\u51041\u5343\u4e07\u306e\u300c\u308f\u305a\u304b\u300d\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3067\u540c\u3058\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u3092\u4f7f\u7528\u3059\u308bBERT_base\u3088\u308a\u3082\u660e\u3089\u304b\u306b\u512a\u308c\u3066\u3044\u307e\u3059\u3002\n\n> 2) \u5341\u5206\u306a\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30c7\u30fc\u30bf\u304c\u3042\u308c\u3070\u3001\u3088\u308a\u591a\u304f\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u30b9\u30c6\u30c3\u30d7\u304c\u3088\u308a\u9ad8\u3044\u7cbe\u5ea6\u306b\u3064\u306a\u304c\u308a\u307e\u3059\u3002 \u305f\u3068\u3048\u3070\u3001MNLI\u30bf\u30b9\u30af\u3067\u306f\u3001\u540c\u3058\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u306e500K\u30b9\u30c6\u30c3\u30d7\u3068\u6bd4\u8f03\u3057\u3066\u30011M\u30b9\u30c6\u30c3\u30d7\uff08128,000\u30ef\u30fc\u30c9\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\uff09\u3067\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3059\u308b\u3068\u3001BERT_base\u306e\u7cbe\u5ea6\u304c1.0\uff05\u5411\u4e0a\u3057\u307e\u3059\u3002\n\n> 3) BERT\u306e\u53cc\u65b9\u5411\u30a2\u30d7\u30ed\u30fc\u30c1\uff08MLM\uff09\u306f\u3001\u5de6\u304b\u3089\u53f3\u3078\u306e\u30a2\u30d7\u30ed\u30fc\u30c1(left-to-right approaches)\u3088\u308a\u3082\u53ce\u675f\u304c\u9045\u304f\u306a\u308a\u307e\u3059\uff08\u5404\u30d0\u30c3\u30c1\u3067\u4e88\u6e2c\u3055\u308c\u308b\u306e\u306f\u5358\u8a9e\u306e15\uff05\u306e\u307f\u3067\u3042\u308b\u305f\u3081\uff09\n\n![](https:\/\/miro.medium.com\/max\/1576\/0*KONsqvDohE7ytu_E.png)","b43f3533":"<font size=5 color='green'>Please give this kernel an UPVOTE to show your appreciation, if you find it useful.<\/font>","61b70fe2":"# Comprehensive BERT Tutorial\n\n## Introduction\n<font size=\"3\" color='#003249'>\u6570\u304b\u6708\u304b\u3051\u3066\u521d\u5fc3\u8005\u3068\u3057\u3066Computer Vision\u30e2\u30c7\u30eb\u3092\u4f5c\u6210\u3057\u3066\u304b\u3089NLP\u3092\u59cb\u3081\u305f\u3070\u304b\u308a\u306a\u3089\u3001\u3053\u306e\u30ab\u30fc\u30cd\u30eb\u306f\u304d\u3063\u3068\u3042\u306a\u305f\u306b\u3074\u3063\u305f\u308a\u306e\u3082\u306e\u3067\u3059.<\/font>\n<br>\n\n\u3053\u306e\u6700\u65b0\u306e\u6700\u5148\u7aef\u306eNLP\u30e2\u30c7\u30ebBERT\u3092\u7406\u89e3\u3059\u308b\u306e\u306b\u82e6\u52b4\u3057\u307e\u3057\u305f\u3002BERT\u3068\u306f\u4f55\u304b\u3092\u672c\u5f53\u306b\u628a\u63e1\u3059\u308b\u305f\u3081\u306b\u3001\u591a\u304f\u306e\u8a18\u4e8b\u3092\u6398\u308a\u4e0b\u3052\u306a\u3051\u308c\u3070\u306a\u308a\u307e\u305b\u3093\u3067\u3057\u305f\u3002 \u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3067BERT\u306e\u79c1\u306e\u7406\u89e3\u3092\u5171\u6709\u3057\u307e\u3059\u3002\n\n![](https:\/\/cdn-images-1.medium.com\/max\/1000\/1*-oQKmzvHrzqeSQEnM9f_kQ.png)\n\n## Contents\n<a href=\"#The-BERT-Landscape\">1. The BERT Landscape<\/a>  \n<a href=\"#What-is-BERT?\">2. What is BERT?<\/a>  \n<a href=\"#Why-BERT-matters?\">3. Why BERT Matters?<\/a>\n<br>\n<a href=\"#How-BERT-Works?\">4. How BERT works?<\/a> <br>\n&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#1.-Architecture-of-BERT\">4.1 Architecture of BERT<\/a>   \n&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#2.-Preprocessing-Text-for-BERT\">4.2 Preprocessing text for BERT<\/a>   \n&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#3.-Pre-training\">4.3 Pre-training<\/a>   \n<a href=\"#5.-Fine-Tuning_Techniques-for-BERT\">5. Fine Tuning Techniques for BERT<\/a> <br>\n&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#5.1-Sequence-Classification-Tasks\">5.1 Sequence Classification Tasks<\/a>   \n&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#5.2-Sentence-Pair-Classification-Tasks\">5.2 Sentence Pair Classification Tasks<\/a>   \n&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#5.3-Question-Answering-Tasks\">5.3 Question Answering Tasks<\/a><br>\n&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#5.4-Single-Sentence-Tagging-Tasks\">5.4 Single Sentence Tagging  Tasks<\/a><br> \n&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#5.5-Hyperparameter-Tuning\">5.5 Hyperparameter Tuning<\/a><br>\n<a href=\"#6.-BERT-Benchmarks-on-Question-Answering-Tasks\">6. BERT Benchmarks on Question\/Answering Tasks<\/a> <br>\n<a href=\"#7.-Key-Takeaways\">7. Key Takeaways<\/a> <br>\n<a href=\"#8.-Conclusion\">8. Conclusion<\/a>","fa816a88":"**Here, we:**\n1. Set up Bert\n2. Read in the test set\n3. Run it past the pre-built Bert model to create embeddings\n4. Use those embeddings to make predictions\n5. Write those predictions to `predictions.json`\n\n\u4ee5\u4e0b\u306e\u30b3\u30fc\u30c9\u3092\u81ea\u7531\u306b\u5909\u66f4\u3057\u3066\u304f\u3060\u3055\u3044\u3002 `tf2baseline` functions\u306f `tf2_0_baseline_w_bert`\u30e6\u30fc\u30c6\u30a3\u30ea\u30c6\u30a3\u30b9\u30af\u30ea\u30d7\u30c8\u306b\u542b\u307e\u308c\u3066\u304a\u308a\u3001\u30e6\u30fc\u30c6\u30a3\u30ea\u30c6\u30a3\u30b9\u30af\u30ea\u30d7\u30c8\u3092\u30d5\u30a9\u30fc\u30af\u3057\u3066\u66f4\u65b0\u3059\u308b\u304b\u3001\u3053\u306e\u30ab\u30fc\u30cd\u30eb\u3067\u72ec\u81ea\u306e\u975e` tf2baseline`\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u4f5c\u6210\u3059\u308b\u3053\u3068\u3067\u30ab\u30b9\u30bf\u30de\u30a4\u30ba\u3067\u304d\u307e\u3059\u3002\n\n\u6ce8\u610f\uff1a `tf2_0_baseline_w_bert`\u30e6\u30fc\u30c6\u30a3\u30ea\u30c6\u30a3\u30b9\u30af\u30ea\u30d7\u30c8\u306b\u306f\u3001\u72ec\u81ea\u306e\u57cb\u3081\u8fbc\u307f\u3092\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3059\u308b\u305f\u3081\u306e\u30b3\u30fc\u30c9\u304c\u542b\u307e\u308c\u3066\u3044\u307e\u3059\u3002 \u3053\u3053\u3067\u305d\u306e\u30b3\u30fc\u30c9\u306f\u524a\u9664\u3055\u308c\u307e\u3059\u3002"}}