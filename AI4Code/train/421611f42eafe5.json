{"cell_type":{"a82c62de":"code","28607a11":"code","d6435995":"code","b8c20536":"code","2e205245":"code","314abe46":"code","0e2c3d01":"code","86d5cd84":"code","2ab66ca2":"code","9a2dcac9":"code","696e1fbb":"code","1ec1a8e2":"code","cb97b92a":"code","39e39489":"code","d9eeab18":"code","8a03307f":"code","843b79a4":"code","aad3d636":"code","4da6d3f9":"code","a2f98005":"code","6dc6e613":"code","721622d4":"code","45ed4333":"code","f7c2b64f":"code","af2c630f":"markdown","84b1296d":"markdown","04de9755":"markdown","8074266b":"markdown","ef9fdf36":"markdown","a76a7706":"markdown","f57e8e18":"markdown","db234609":"markdown","0cbe7c88":"markdown","ca7820b7":"markdown"},"source":{"a82c62de":"import pandas as pd\nimport numpy as np\n","28607a11":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","d6435995":"df = pd.read_csv(\"..\/input\/knn-data1\/KNN_Project_Data\")","b8c20536":"df.head()","2e205245":"sns.pairplot(df,hue=\"TARGET CLASS\",palette=\"coolwarm\")","314abe46":"from sklearn.preprocessing import StandardScaler","0e2c3d01":"scaler=StandardScaler()","86d5cd84":"scaler.fit(df.drop('TARGET CLASS', axis=1))","2ab66ca2":"scaled_features=scaler.transform(df.drop('TARGET CLASS',axis=1))","9a2dcac9":"df_feat = pd.DataFrame(scaled_features, columns=df.columns[:-1])\ndf_feat.head()","696e1fbb":"from sklearn.model_selection import train_test_split","1ec1a8e2":"X = df_feat\ny = df['TARGET CLASS']","cb97b92a":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","39e39489":"from sklearn.neighbors import KNeighborsClassifier","d9eeab18":"knn = KNeighborsClassifier(n_neighbors=1)","8a03307f":"knn.fit(X_train, y_train)","843b79a4":"pred = knn.predict(X_test)","aad3d636":"from sklearn.metrics import classification_report, confusion_matrix","4da6d3f9":"print(confusion_matrix(y_test,pred))","a2f98005":"print(classification_report(y_test,pred))","6dc6e613":"error_rate = []\nfor i in range(1,60):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))","721622d4":"plt.figure(figsize=(10,6))\nplt.plot(range(1,60),error_rate,color='blue',linestyle=\"--\",marker=\"o\", markerfacecolor='red',markersize=10)\nplt.title(\"Error Rate Vs K\")\nplt.xlabel(\"K\")\nplt.ylabel(\"Error Rate\")","45ed4333":"knn = KNeighborsClassifier(n_neighbors=30)\nknn.fit(X_train, y_train)\npred = knn.predict(X_test)\nprint(confusion_matrix(y_test,pred))","f7c2b64f":"print(classification_report(y_test,pred))","af2c630f":"# **Standardize the Variables**","84b1296d":"# **Predictions and Evaluations**\nLet's evaluate our KNN Model","04de9755":"# **K Nearest Neighbors Project**","8074266b":"# **Using KNN**","ef9fdf36":"# **Train Test Split**","a76a7706":"# **Exploratory Data Analysis**","f57e8e18":"Import required libraries","db234609":"# **Choosing a K Value**\nLet's go ahead and pick up a good K value using the elbow method","0cbe7c88":"# **Retrain with new K Value**","ca7820b7":"Get the data"}}