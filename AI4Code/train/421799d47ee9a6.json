{"cell_type":{"70294baa":"code","9e14fc19":"code","de059220":"code","bef8019f":"code","d5d2f288":"code","e8eee409":"code","0b7474bb":"code","feceff40":"code","81ba395f":"code","7c6f66be":"code","cbbf9665":"code","47eedaa7":"code","3736ff77":"code","42de9ee6":"code","7af07ae1":"code","47a6f831":"code","897f8b81":"code","2788578f":"code","e70d2ac5":"code","b6ae6365":"code","2fff50a7":"code","699ca0ac":"code","76d0af64":"code","53da6fc4":"code","53366034":"code","525b4f37":"code","64dea5cb":"code","8d0c7165":"code","50a5d258":"code","c1d24064":"code","e4f16bcf":"code","1d28dc1d":"code","95373bbf":"code","12a95aef":"code","35012e1c":"code","bea9cc86":"code","04164f90":"code","e3daf0ac":"code","7cfcda84":"code","a6da87d8":"code","27ce1e0a":"code","97c83235":"code","9f52855c":"markdown","5b3ea271":"markdown","828a7945":"markdown","fa7d3317":"markdown","74539817":"markdown","02ab185f":"markdown","f22b940d":"markdown","adaf21b5":"markdown"},"source":{"70294baa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","9e14fc19":"#importing all the library\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport nltk\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelBinarizer\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize,sent_tokenize\nfrom bs4 import BeautifulSoup\nimport re,string,unicodedata\nfrom nltk.tokenize.toktok import ToktokTokenizer\nfrom nltk.stem import LancasterStemmer,WordNetLemmatizer","de059220":"train = pd.read_csv(\"\/kaggle\/input\/hackerearth-effectiveness-of-std-drugs\/dataset\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/hackerearth-effectiveness-of-std-drugs\/dataset\/train.csv\")","bef8019f":"train.head()","d5d2f288":"#checking for null\ntrain.isna().sum()","e8eee409":"# Taking the required columns\ntrain_new=train[['patient_id','effectiveness_rating','number_of_times_prescribed','review_by_patient','base_score']]","0b7474bb":"from nltk.corpus.reader.wordnet import WordNetError\nfrom nltk.corpus import sentiwordnet as swn, wordnet","feceff40":"stop = set(stopwords.words('english'))\npunctuation = list(string.punctuation)\nstop.update(punctuation)","81ba395f":"def get_simple_pos(tag):\n    if tag.startswith('J'):\n        return wordnet.ADJ\n    elif tag.startswith('V'):\n        return wordnet.VERB\n    elif tag.startswith('N'):\n        return wordnet.NOUN\n    elif tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return wordnet.NOUN","7c6f66be":"from nltk import pos_tag, word_tokenize","cbbf9665":"lemmatizer = WordNetLemmatizer()\ndef lemmatize_words(review_by_patient):\n    final_text = []\n    for i in review_by_patient.split():\n        if i.strip().lower() not in stop:\n            pos = pos_tag([i.strip()])\n            word = lemmatizer.lemmatize(i.strip(),get_simple_pos(pos[0][1]))\n            final_text.append(word.lower())\n    return \" \".join(final_text)","47eedaa7":"train_new.review_by_patient = train_new.review_by_patient.apply(lemmatize_words)","3736ff77":"train_new.head()","42de9ee6":"from sklearn.feature_extraction.text import TfidfVectorizer","7af07ae1":"from sklearn_pandas import DataFrameMapper, cross_val_score","47a6f831":"data2 = train_new.copy()","897f8b81":"data2 = data2.fillna('')","2788578f":"mapper = DataFrameMapper([\n     ('patient_id',None),\n     ('effectiveness_rating',None),\n     ('number_of_times_prescribed', None),\n     ('review_by_patient', TfidfVectorizer()),\n ])","e70d2ac5":"features = mapper.fit_transform(data2)","b6ae6365":"features.shape","2fff50a7":"train_new.dtypes","699ca0ac":"pred_base_score = train_new['base_score']","76d0af64":"from sklearn.model_selection import train_test_split","53da6fc4":"# Split the data between train and test\nx_train, x_test, y_train, y_test = train_test_split(features,pred_base_score,test_size=0.2,train_size=0.8, random_state = 0)\n","53366034":"x_train.shape","525b4f37":"x_test.shape","64dea5cb":"y_train","8d0c7165":"y_train_new=y_train","50a5d258":"y_train_new.shape","c1d24064":"from sklearn import preprocessing\nfrom sklearn import utils\n\nlab_enc = preprocessing.LabelEncoder()\nencoded = lab_enc.fit_transform(y_train_new)","e4f16bcf":"from sklearn.linear_model import LogisticRegression","1d28dc1d":"model=LogisticRegression()","95373bbf":"x_train.shape","12a95aef":"x_hlf=x_train[0:500, :]","35012e1c":"x_hlf.shape","bea9cc86":"encoded.shape","04164f90":"y_hlf=encoded[0:500]","e3daf0ac":"y_hlf.shape","7cfcda84":"model.fit(x_hlf,y_hlf)","a6da87d8":"prediction=model.predict(x_test)","27ce1e0a":"final_prediction=(prediction\/100)","97c83235":"final_prediction","9f52855c":"AS for test dataset you have to follow the similar manner first preprocessing of the test dataset as you have done on train dataset\n \n And than do the prediction part and create a submission file.","5b3ea271":"**PreProcessing of the REVIEW column using NATURAL LANGUAGE PROCESSING**","828a7945":"DataFrameMapper is used to combined the dataset of different types\n\nlike here we have combine text data along with other columns","fa7d3317":"As the the y target data is float type we will convert it into integer type using label encoder","74539817":"**NOW we will create a dataframe of rest all numeric column along with review column**","02ab185f":"**Now we will prepare the data for train and test split**","f22b940d":"**AS DUE to memory issue of the kernel try to use google colab for faster execution **\n\nAs due to memory issue I have done the model fitting using only 500 rows but you should fit the model for all the rows of X_train.So that you can get better accuracy.\n\nmodel.fit(x_train,encoded)\n\nprediction=model.predict(x_test)","adaf21b5":"**Importing the logistic model for prediction**\n\n\n"}}