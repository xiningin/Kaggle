{"cell_type":{"e793f8ec":"code","b1809629":"code","9c150a55":"code","a8fdefed":"code","90c3584a":"code","d20d3540":"code","8513df60":"code","137b47f0":"code","18c5aaeb":"code","ba279552":"code","7fef3542":"code","4b98f7d2":"code","82365cac":"code","52039f68":"code","4606ddf2":"code","17cd4697":"code","a17adb64":"markdown","0ab09a78":"markdown","b353e8a7":"markdown","c4ea2727":"markdown"},"source":{"e793f8ec":"import numpy as np, pandas as pd, os, gc\nimport matplotlib.pyplot as plt, time\nfrom PIL import Image \nimport warnings\nwarnings.filterwarnings(\"ignore\")","b1809629":"path      = '..\/input\/severstal-steel-defect-detection\/'\nmodelFile = '..\/input\/simplistic-unet-for-metal-defect-segmentation\/modelend.hdf5'","9c150a55":"print(os.listdir(path))\nprint(os.path.isfile(modelFile))","a8fdefed":"os.listdir('..\/working\/')","90c3584a":"# https:\/\/www.kaggle.com\/ateplyuk\/pytorch-starter-u-net-resnet\n# https:\/\/stanford.edu\/~shervine\/blog\/keras-how-to-generate-data-on-the-fly\nimport keras\n\nclass DataGenerator(keras.utils.Sequence):\n    def __init__(self, df, batch_size = 16, subset=\"train\", shuffle=False, preprocess=None, info={}, viewTest=False):\n        super().__init__()\n        self.df = df\n        self.shuffle = shuffle\n        self.subset = subset\n        self.batch_size = batch_size\n        self.preprocess = preprocess\n        self.info = info\n        self.viewTest = viewTest\n        \n        if self.subset == \"train\":\n            self.data_path = path + 'train_images\/'\n        elif self.subset == \"test\":\n            self.data_path = path + 'test_images\/'\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.ceil(len(self.df)*1. \/ self.batch_size))\n    \n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.df))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    \n    def __getitem__(self, index): \n                \n        begin = index*self.batch_size\n        end   = min((index+1)*self.batch_size,len(self.indexes))\n        bsize = end - begin\n        indexes = self.indexes[begin:end]\n        \n        \n        \n        X = np.empty((bsize,256,1600,3),dtype=np.float32)\n        if self.subset == 'train' or self.viewTest: \n            y = np.empty((bsize,256,1600,4),dtype=np.int8)\n        \n        for i,f in enumerate(self.df['ImageId'].iloc[indexes]):\n            self.info[index*self.batch_size+i]=f\n            X[i,] = Image.open(self.data_path + f)\n            if self.subset == 'train' or self.viewTest: \n                for j in range(4):\n                    y[i,:,:,j] = rle2mask(self.df['e'+str(j+1)].iloc[indexes[i]])\n        if self.preprocess!=None: X = self.preprocess(X)\n            \n        assert not np.any(np.isnan(X))\n        if self.subset == 'train' or self.viewTest: \n            assert not np.any(np.isnan(y))\n            return X, y\n        else: return X","d20d3540":"# https:\/\/www.kaggle.com\/titericz\/building-and-visualizing-masks\ndef rle2mask(rle):\n    # CONVERT RLE TO MASK \n    if (pd.isnull(rle))|(rle==''): \n        return np.zeros((256,1600) ,dtype=np.uint8)\n    \n    height= 256\n    width = 1600\n    mask= np.zeros( width*height ,dtype=np.uint8)\n\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]-1\n    lengths = array[1::2]    \n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n    return mask.reshape( (height,width), order='F' )[::1,::1]\n\ndef mask2rle(mask):\n    startEnd = np.diff(np.concatenate(([0],mask.T.flatten(),[0])))\n    starts   = np.where(startEnd== 1)[0]\n    if len(starts) == 0:\n        return ''\n    ends     = np.where(startEnd==-1)[0]\n    length   = ends - starts\n    starts  += 1    # it seems the data set pixel index starts at 1\n    return ' '.join(['{} {}'.format(s,l) for s,l in zip(starts,length)])\n\ndef rle2maskResize(rle):\n    # CONVERT RLE TO MASK \n    if (pd.isnull(rle))|(rle==''): \n        return np.zeros((128,800) ,dtype=np.uint8)\n    \n    height= 256\n    width = 1600\n    mask= np.zeros( width*height ,dtype=np.uint8)\n\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]-1\n    lengths = array[1::2]    \n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n    return mask.reshape( (height,width), order='F' )[::2,::2]\n\n\ndef mask2contour(mask, width=3):\n    # CONVERT MASK TO ITS CONTOUR\n    w = mask.shape[1]\n    h = mask.shape[0]\n    mask2 = np.concatenate([mask[:,width:],np.zeros((h,width))],axis=1)\n    mask2 = np.logical_xor(mask,mask2)\n    mask3 = np.concatenate([mask[width:,:],np.zeros((width,w))],axis=0)\n    mask3 = np.logical_xor(mask,mask3)\n    return np.logical_or(mask2,mask3) \n\ndef mask2pad(mask, pad=2):\n    # ENLARGE MASK TO INCLUDE MORE SPACE AROUND DEFECT\n    w = mask.shape[1]\n    h = mask.shape[0]\n    \n    # MASK UP\n    for k in range(1,pad,2):\n        temp = np.concatenate([mask[k:,:],np.zeros((k,w))],axis=0)\n        mask = np.logical_or(mask,temp)\n    # MASK DOWN\n    for k in range(1,pad,2):\n        temp = np.concatenate([np.zeros((k,w)),mask[:-k,:]],axis=0)\n        mask = np.logical_or(mask,temp)\n    # MASK LEFT\n    for k in range(1,pad,2):\n        temp = np.concatenate([mask[:,k:],np.zeros((h,k))],axis=1)\n        mask = np.logical_or(mask,temp)\n    # MASK RIGHT\n    for k in range(1,pad,2):\n        temp = np.concatenate([np.zeros((h,k)),mask[:,:-k]],axis=1)\n        mask = np.logical_or(mask,temp)\n    \n    return mask ","8513df60":"from keras import backend as K\n# https:\/\/www.kaggle.com\/xhlulu\/severstal-simple-keras-u-net-boilerplate\n\n# COMPETITION METRIC\ndef dice_coef(y_true, y_pred, smooth=1.0):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef neg_dice_coef(y_true, y_pred, smooth=1.0):\n    return - dice_coef(y_true, y_pred, smooth=smooth)","137b47f0":"#from segmentation_models import Unet\n#from segmentation_models.backbones import get_preprocessing\n\n# LOAD UNET WITH PRETRAINING FROM IMAGENET\n#preprocess = get_preprocessing('resnet34') # for resnet, img = (img-110.0)\/1.0\npreprocess = lambda x:x","18c5aaeb":"# LOAD MODEL\nfrom keras.models import load_model\nmodel = load_model(modelFile,custom_objects={'dice_coef':dice_coef})","ba279552":"# PREDICT 1 BATCH TEST DATASET\ntest            = pd.read_csv(path + 'sample_submission.csv')\ntest['ImageId'] = test['ImageId_ClassId'].map(lambda x: x.split('_')[0])","7fef3542":"outputs = []\n\n#the test set run after submission is different from the test set we download. The count of picutres are perhaps also different.\nblockLength = 2000\nassert blockLength % 4 == 0\n\nfor begin in np.arange(0,len(test),blockLength):\n    test_batches = DataGenerator(test.iloc[begin:begin+blockLength:4],subset='test',batch_size=16,preprocess=preprocess)\n    test_preds   = model.predict_generator(test_batches,steps=None,verbose=1)\n    for i in range(len(test_preds)):\n        for t in range(4):\n            thresholded                          = np.zeros_like(test_preds[i,:,:,t])\n            thresholded[test_preds[i,:,:,t]>0.5] = 1\n            outputs.append(mask2rle(thresholded))\n            if i < 100:\n                print(i,t,np.sum(thresholded))\n                \nassert len(test) == len(outputs)\n                \ntest['EncodedPixels'] = outputs     ","4b98f7d2":"test","82365cac":"test.drop(columns='ImageId').to_csv('submission.csv',index=False)","52039f68":"test2 = pd.DataFrame({'ImageId':test['ImageId'][::4]})\ntest2['e1'] = test['EncodedPixels'][::4].values\ntest2['e2'] = test['EncodedPixels'][1::4].values\ntest2['e3'] = test['EncodedPixels'][2::4].values\ntest2['e4'] = test['EncodedPixels'][3::4].values","4606ddf2":"test2 = test2.sample(20,random_state=0).copy().reset_index(drop=True)\ntest2.fillna('',inplace=True); ","17cd4697":"\nfilenames = {}\n# defects  = list(train2[train2['e1']!=''].sample(3).index)\n# defects += list(train2[train2['e2']!=''].sample(3).index)\n# defects += list(train2[train2['e3']!=''].sample(7).index)\n# defects += list(train2[train2['e4']!=''].sample(3).index)\n\n# defects  = list(train2[train2['e4']!=''].sample(20).index)\n# defects += list(train2[train2['e2']!=''].sample(3).index)\n# defects += list(train2[train2['e3']!=''].sample(7).index)\n# defects += list(train2[train2['e4']!=''].sample(3).index)\n\n# DATA GENERATOR\ntrain_batches = DataGenerator(test2,shuffle=False,info=filenames,subset='test',viewTest=True)\nprint('Images and masks from our Data Generator')\nprint('KEY: yellow=defect1, green=defect2, blue=defect3, magenta=defect4')\n\n# DISPLAY IMAGES WITH DEFECTS\nfor i,batch in enumerate(train_batches):\n    plt.figure(figsize=(14,50)) #20,18\n    for k in range(len(batch[0])):\n        plt.subplot(16,1,k+1)\n        img = batch[0][k,]\n        img = Image.fromarray(img.astype('uint8'))\n        img = np.array(img)\n        extra = '  has defect'\n        for j in range(4):\n            msk = batch[1][k,:,:,j]\n            #msk = mask2pad(msk,pad=3)\n            msk = mask2contour(msk,width=2)\n            if np.sum(msk)!=0: extra += ' '+str(j+1)\n            if j==0: # yellow\n                img[msk==1,0] = 235 \n                img[msk==1,1] = 235\n            elif j==1: img[msk==1,1] = 210 # green\n            elif j==2: img[msk==1,2] = 255 # blue\n            elif j==3: # magenta\n                img[msk==1,0] = 255\n                img[msk==1,2] = 255\n        plt.title(filenames[16*i+k]+extra)\n        plt.axis('off') \n        plt.imshow(img)\n    plt.subplots_adjust(wspace=0.05)\n    plt.show()","a17adb64":"test = test.iloc[:4*50].reset_index(drop=True)","0ab09a78":"# modified from https:\/\/www.kaggle.com\/cdeotte\/keras-unet-with-eda of Chris Deotte, from which kernel I learned a lot.\n\nThis Kernel does not produce competitive results, but is at least successfully submittable, which took me couple of hours of work :)","b353e8a7":"! pip install segmentation-models","c4ea2727":"### view if the packaging is correct"}}