{"cell_type":{"d6432fb5":"code","7fa23ba4":"code","90b46b7e":"code","6bfaa5e3":"code","2f56906d":"code","9a0ecd87":"code","b34f5c8e":"code","655163df":"code","0ed2417f":"code","31b65e1c":"code","2af35208":"code","e66968d3":"code","7a6c27fb":"code","4fb39ba6":"code","a9f9263f":"code","1d440878":"code","08a13645":"code","5ee32f17":"code","4646ef38":"code","3a17db7a":"code","947b524d":"code","4bfad52f":"code","c1d9e66b":"code","34036e9f":"code","85c3e3e4":"code","fab4935b":"code","02221ee1":"code","91f4a1a4":"code","edf67350":"code","1bf2f2e2":"code","b7e3a1e4":"code","e0a39901":"markdown","09fafcde":"markdown","2ca4a405":"markdown","678dd09e":"markdown","b1426ee4":"markdown","1dcd330b":"markdown","894deeea":"markdown","12a2eaf6":"markdown","44da5f16":"markdown","bf960fa1":"markdown","4e8d6f41":"markdown","b29bf502":"markdown","3a871f51":"markdown","9e49ae4b":"markdown","ce69a8ef":"markdown","073bfe3e":"markdown","07bd19f1":"markdown","5053cc8f":"markdown","d65973c7":"markdown","6bd32521":"markdown","34447846":"markdown","5048cd3c":"markdown"},"source":{"d6432fb5":"import os\nimport gc\nimport cv2\nimport math\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport itertools\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.models import Sequential,load_model, Model\nfrom tensorflow.keras.applications import EfficientNetB3 as Net\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input","7fa23ba4":"#print('TensorFlow version: %s' % tf.__version__)","90b46b7e":"ROOT = '..\/input\/bee-vs-wasp\/kaggle_bee_vs_wasp\/'\nSEED = 42\nEPOCHS = 50\nBATCH_SIZE = 42\nIMG_SIZE = 250","6bfaa5e3":"df = pd.read_csv(ROOT+'labels.csv')\ndf.head()","2f56906d":"df = df.query(\"(label=='bee') or (label=='wasp')\")\ndf = df.query(\"photo_quality == 1\")\ndf.head()","9a0ecd87":"df['label'].value_counts()","b34f5c8e":"#Substituindo '\\' por '\/' nos paths contidos no dataframe e complementando o path.\n\nfor index in tqdm(df.index):    \n    df.loc[index,'path']=df.loc[index,'path'].replace('\\\\', '\/') \n\ndf['path'] = ROOT + df['path']\ndf.head()","655163df":"def display_img(row, pos):\n    #Read image from path\n    img = cv2.imread(row['path'])\n    #Resize all images with the same size\n    img = cv2.resize(img, (128, 128))\n    #Set RGB color for image\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    #Display image, and set title\n    plt.subplot(4, 5, pos)\n    plt.imshow(img)\n    plt.title(row['label'])\n    #Remove ticks\n    plt.xticks([])\n    plt.yticks([])","0ed2417f":"bee = df.query(\"(label == 'bee') and (photo_quality == 1)\").sample(5, random_state=42)\nwasp = df.query(\"(label == 'wasp') and (photo_quality == 1)\").sample(5, random_state=42)\n\nplt.figure(figsize=(15,10))\npos = 1\n# Display bee\nfor idx, row in bee.iterrows():\n    display_img(row, pos)\n    pos += 1\n# Display wasp    \nfor idx, row in wasp.iterrows():\n    display_img(row, pos)\n    pos += 1\n    \nplt.show()","31b65e1c":"def set_train_type(row):\n    if row['is_validation'] == 0 and row['is_final_validation'] == 0:\n        return 'train'\n    if row['is_validation'] == 1:\n        return 'validation'\n    return 'test'\n\ndf['type'] = df.apply(set_train_type, axis=1)\nprint('Distribui\u00e7\u00e3o de Qntd. de R\u00f3tulos por Split:')\ndf['type'].value_counts()","2af35208":"plt.figure(figsize=(7,7))\ng = sns.countplot(x='label', hue='type', data=df, palette=\"pastel\")\ng.set(xlabel='', ylabel='', title=\"Qntd. de R\u00f3tulos por Categorias x Treino\/Valida\u00e7\u00e3o\/Teste\")\nsns.despine()\nplt.show()","e66968d3":"#Divis\u00e3o inicial do dataset  reduzido, em conjuntos de treino, teste e valida\u00e7\u00e3o.\ntrain_df = df[df['type'] == 'train']\nvalid_df = df[df['type'] == 'validation']\ntest_df = df[df['type'] == 'test']","7a6c27fb":"# Subdivision in test\/validation\ndata_generator = ImageDataGenerator(rescale=1.\/255, validation_split=0.2)\n#val_data_generator = ImageDataGenerator(rescale=1.\/255, validation_split=0.2)","4fb39ba6":"# Generator para parte train\ntrain_generator = data_generator.flow_from_dataframe(train_df, target_size=(IMG_SIZE,IMG_SIZE), shuffle=True, seed=SEED,\n                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"training\",\n                                                    x_col = 'path', y_col = 'label')\n# Generator para parte valida\u00e7\u00e3o\n\nvalidation_generator = data_generator.flow_from_dataframe(train_df, target_size=(IMG_SIZE,IMG_SIZE), shuffle=True, \n                                                              seed=SEED,class_mode='categorical', batch_size=BATCH_SIZE, \n                                                              subset=\"validation\", x_col = 'path', y_col = 'label')        \n\n# Generator para dataset de teste\ntest_generator = data_generator.flow_from_dataframe(test_df, target_size=(IMG_SIZE,IMG_SIZE), shuffle=False, seed=SEED,\n                                                     class_mode='categorical', batch_size=BATCH_SIZE, x_col = 'path', \n                                                    y_col = 'label') \n\nnb_train_samples = train_generator.samples\nnb_validation_samples = validation_generator.samples\nnb_test_samples = test_generator.samples\nclasses = list(train_generator.class_indices.keys())\nprint('Classes: '+str(classes))\nnum_classes = len(classes)","a9f9263f":"# Visualizing some examples\nplt.figure(figsize=(15,15))\nfor i in range(9):\n    #gera subfigures\n    plt.subplot(330 + 1 + i)\n    batch = train_generator.next()[0]*255\n    image = batch[0].astype('uint8')\n    plt.imshow(image)\nplt.show()","1d440878":"model = Sequential()\nmodel.add(Conv2D(10, kernel_size=(5, 5),\n                 activation='relu',\n                 input_shape=(IMG_SIZE,IMG_SIZE,3)))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2), padding='same'))\nmodel.add(Conv2D(30, kernel_size=(2,2), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(80, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(30, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(num_classes, activation='softmax'))\nmodel.summary()","08a13645":"model.compile(loss='categorical_crossentropy',\n              optimizer = 'adam',\n              metrics=['accuracy'])","5ee32f17":"#Salvar o melhor modelo \ncallbacks_list = [\n    keras.callbacks.ModelCheckpoint(\n        filepath='model_activity2.h5',\n        monitor='val_loss', \n        save_best_only=True, \n        verbose=1),\n    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,verbose=1)\n]\n\n#Training\nhistory = model.fit(train_generator,\n                    steps_per_epoch = nb_train_samples \/\/ BATCH_SIZE,\n                    epochs = EPOCHS,\n                    callbacks = callbacks_list,\n                    validation_data = validation_generator,\n                    verbose = 1,\n                    validation_steps = nb_validation_samples \/\/ BATCH_SIZE)","4646ef38":"history_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\n\nepochs_x = range(1, len(loss_values) + 1)\nplt.figure(figsize=(10,10))\nplt.subplot(2,1,1)\nplt.plot(epochs_x, loss_values, 'bo', label='Training loss')\nplt.plot(epochs_x, val_loss_values, 'b', label='Validation loss')\nplt.title('Training and validation Loss and Acc')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.subplot(2,1,2)\nacc_values = history_dict['accuracy']\nval_acc_values = history_dict['val_accuracy']\nplt.plot(epochs_x, acc_values, 'bo', label='Training acc')\nplt.plot(epochs_x, val_acc_values, 'b', label='Validation acc')\n#plt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Acc')\nplt.legend()\nplt.show()","3a17db7a":"# Carregando o melhor modelo salvo\nmodel = load_model('model_activity2.h5')","947b524d":"# Checando os valores com o dataset de valida\u00e7\u00e3o\nscore = model.evaluate_generator(validation_generator)\nprint('Val loss:', score[0])\nprint('Val accuracy:', score[1])","4bfad52f":"# Checando os valores com o dataset de teste\nscore = model.evaluate_generator(test_generator)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","c1d9e66b":"#Plot the confusion matrix. Set Normalize = True\/False\ndef plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize=(10,10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        cm = np.around(cm, decimals=2)\n        cm[np.isnan(cm)] = 0.0\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","34036e9f":"#On test dataset\nY_pred = model.predict_generator(test_generator)\ny_pred = np.argmax(Y_pred, axis=1)\ntarget_names = classes\n\n#Confution Matrix\ncm = confusion_matrix(test_generator.classes, y_pred)\nplot_confusion_matrix(cm, target_names, normalize=False, title='Confusion Matrix')\n\n#Classification Report\nprint('Classification Report')\nprint(classification_report(test_generator.classes, y_pred, target_names=target_names))","85c3e3e4":"base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n#base_model = Net(weights=\"imagenet\", input_shape=(IMG_SIZE,IMG_SIZE, 3), include_top=False)\n\nx = base_model.output\nx = Flatten()(x)\nx = Dense(200, activation='elu')(x)\nx = Dropout(0.5)(x)\nx = Dense(150, activation='relu')(x)\nx = Dropout(0.4)(x)\nx = Dense(120, activation='relu')(x)\nx = Dropout(0.4)(x)\nx = Dense(50, activation='relu')(x)\nx = Dropout(0.3)(x)\nx = Dense(30, activation='relu')(x)\nx = Dropout(0.3)(x)\nx = Dense(20, activation='relu')(x)\nx = Dropout(0.3)(x)\nx = Dense(10, activation='relu')(x)\nx = Dropout(0.3)(x)\npredictions = Dense(num_classes, activation='softmax', kernel_initializer='random_uniform')(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Freezing pretrained layers\nfor layer in base_model.layers:\n    layer.trainable=False\n\n#Congelando o peso da base convolucional (evita a destrui\u00e7\u00e3o das representa\u00e7\u00f5es aprendidas)\n#model.trainable = False\n    \n\nmodel.compile(optimizer=SGD(),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n#model.summary()","fab4935b":"classic_callbacks_list = [\n    keras.callbacks.ModelCheckpoint(\n        filepath='basemodel_activity2.h5',\n        monitor='val_loss', save_best_only=True, verbose=1),\n    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,verbose=1)\n]\n\nclassic_history = model.fit(\n        train_generator,\n        steps_per_epoch=nb_train_samples \/\/ BATCH_SIZE,\n        epochs = EPOCHS,\n        callbacks = classic_callbacks_list,\n        validation_data = validation_generator,\n        verbose = 1,\n        validation_steps = nb_validation_samples \/\/ BATCH_SIZE)","02221ee1":"history_dict = classic_history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\n\nepochs_x = range(1, len(loss_values) + 1)\nplt.figure(figsize=(10,10))\nplt.subplot(2,1,1)\nplt.plot(epochs_x, loss_values, 'bo', label='Training loss')\nplt.plot(epochs_x, val_loss_values, 'b', label='Validation loss')\nplt.title('Training and validation Loss and Accuracy') \nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.subplot(2,1,2)\nacc_values = history_dict['accuracy']\nval_acc_values = history_dict['val_accuracy']\nplt.plot(epochs_x, acc_values, 'bo', label='Training acc')\nplt.plot(epochs_x, val_acc_values, 'b', label='Validation acc')\n#plt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Acc')\nplt.legend()\nplt.show()","91f4a1a4":"# Carregando o melhor modelo salvo\nbase_model = load_model('basemodel_activity2.h5')","edf67350":"# Checando os valores com o dataset de valida\u00e7\u00e3o\nscore = base_model.evaluate_generator(validation_generator)\nprint('Val loss:', score[0])\nprint('Val accuracy:', score[1])","1bf2f2e2":"# Checando os valores com o dataset de teste\nscore = base_model.evaluate_generator(test_generator)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","b7e3a1e4":"#Confution Matrix and Classification Report\nY_pred = base_model.predict_generator(test_generator)#, nb_test_samples \/\/ BATCH_SIZE, workers=1)\ny_pred = np.argmax(Y_pred, axis=1)\ntarget_names = classes\n\n#Confution Matrix\ncm = confusion_matrix(test_generator.classes, y_pred)\nplot_confusion_matrix(cm, target_names, normalize=False, title='Confusion Matrix')\nprint('Classification Report')\nprint(classification_report(test_generator.classes, y_pred, target_names=target_names))","e0a39901":"Uma r\u00e1pida verifica\u00e7\u00e3o mostra que o dataset atual para treino deve possui por volta de 200+ r\u00f3tulos a mais de abelhas, em compara\u00e7\u00e3o com de vespas. Para valida\u00e7\u00e3o e para teste, as quantidade de amostras s\u00e3o pr\u00f3ximas umas das outras. ","09fafcde":"Atividade 2 da disciplina Deep Learning, do curso de especializa\u00e7\u00e3o em Ci\u00eancias de Dados ofertado pela Universidade Estadual do Amazonas (Turma 1 - 2020). Atividade criada no Google Classroom.\n\nEste notebook \u00e9 uma c\u00f3pia de [Bee or wasp?_base line using ResNet50](https:\/\/www.kaggle.com\/zihanli1\/bee-or-wasp-base-line-using-resnet50) e se baseia no notebook [Fruit Classification with Transfer Learning](https:\/\/www.kaggle.com\/mauriciofigueiredo\/fruit-classification-with-transfer-learning). O dataset utilizado se encontra [nesta](https:\/\/www.kaggle.com\/jerzydziewierz\/bee-vs-wasp) fonte.\n\nNotebook desenvolvido por Tammy Gusm\u00e3o.","2ca4a405":"O modelo IncepctionResNetV2 foi escolhido para servir de modelo base para o *Transfer Learning*. As vers\u00f5es 0, 3 e 4 do EfficientNet foram experimentadas, mas foram descartadas por motivo de performances baix\u00edssimas. ","678dd09e":"Este modelo claramente mostra a exist\u00eancia de *overfitting*, como pode ser observado nos gr\u00e1ficos acima. ","b1426ee4":"## Split dos R\u00f3tulos","1dcd330b":"Aqui, os r\u00f3tulos recebem \"tags\" de acordo com o indicativo das colunas *is_validation* e *is_final_validation*. ","894deeea":"### Avaliando o Modelo Original","12a2eaf6":"## Modelo Original (from scratch)","44da5f16":"O modelo com base em uma arquitetura cl\u00e1ssica n\u00e3o apresenta um *overfitting* bem definido. Com acur\u00e1cia de 93%, o modelo consegue diferenciar as classes com mais facilidade se o compararmos ao modelo criado de forma manual. Este modelo, no entanto, confundiu algumas vespas com abelhas - mais que a situa\u00e7\u00e3o inversa.","bf960fa1":"## Modelo de Arquitetura Cl\u00e1ssica: Transfer Learning com InceptionResNetV2","4e8d6f41":"Como podemos verificar no *classification report* e na matriz de confus\u00e3o, o modelo confunde identifica melhor as vespas, por\u00e9m, classificou uma por\u00e7\u00e3o de abelhas como vespas. N\u00e3o se descarta a possibilidade de algumas imagens de abelhas n\u00e3o estarem com um *frame* muito bom, dificultando a localiza\u00e7\u00e3o delas. Assim como algumas imagens de vespas: se observarmos no plot de imagens das vespas (in\u00edcio do notebook), algumas n\u00e3o possuem *frames* t\u00e3o bom quanto as das abelhas. Em algumas imagens, a vespa n\u00e3o est\u00e1 muito bem vis\u00edvel - seu tamanho \u00e9 pequeno comparado a outros objetos presentes nas imagens. H\u00e1 ainda aquelas imagens que mostram mais de um inseto.","b29bf502":"## Lendo o dataset","3a871f51":"## Configura\u00e7\u00f5es","9e49ae4b":"## Preprocessamento e plots","ce69a8ef":"Abaixo, os *paths* das imagens s\u00e3o adequados para a busca das mesmas.","073bfe3e":"## Image Data Generator","07bd19f1":"Para esta atividade, foram selecionadas apenas as imagens de boa qualiade das abelhas e vespas. Esta decis\u00e3o foi tomada por conta da baixa performance dos modelos criados quando eram utilziadas as seguintes combina\u00e7\u00f5es separadamente: (1) todas classes de boa qualidade, (2) todas as classes independente do da qualidade, (3) as classes abelha, vespa e outros insetos, de boa qualidade. ","5053cc8f":"ImageDataGenerator fui utilizado sem o *augmentation*. Seu uso impactava negativamente na performance dos modelos. ","d65973c7":"## Imports","6bd32521":"<h1><font size=\"6\">Bee or Wasp?<\/font><\/h1>","34447846":"## Descri\u00e7\u00e3o da Atividade:\n\n*No Kaggle, procure um dataset de imagens interessante (prefer\u00eancia com tasks - submiss\u00e3o - ranking), \u00e0 sua escolha, e implemente modelos de deep learning para classifica\u00e7\u00e3o considerando a melhor avalia\u00e7\u00e3o de acur\u00e1cia poss\u00edvel. Compare um modelo totalmente desenvolvido manualmente e um modelo baseado em arquiteturas cl\u00e1ssicas e transfer learning.*","5048cd3c":"Este dataset possui 3 colunas que indicam se o r\u00f3tulo \u00e9 para treino, teste ou valida\u00e7\u00e3o. Se \u00e9 para treino, \"is_validation\" = 0 e \"is_final_validation\" = 0. Se \u00e9 para teste, \"is_validation\" = 1 e \"is_final_validation\" = 0. Se \u00e9 para valida\u00e7\u00e3o, \"is_validation\" = 0 e \"is_final_validation\" = 1.\n\nAinda possui uma coluna que indica a qualidade da imagem, a \"photo_quality\": se 0, a imagem \u00e9 de baixa qualidade e, se 1, a imagem \u00e9 de boa qualidade. \n\nO dataset possui 4 classes: abelhas (*bee*), vespas (*wasp*), outros insetos (*other insect*) e outros (*other*). A classe *other* inclui outros animais como mam\u00edferos. "}}