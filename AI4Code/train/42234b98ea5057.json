{"cell_type":{"6d294d12":"code","e7f0e5ba":"code","983935a0":"code","82be6a19":"code","b3423f2b":"code","40b3cd0c":"code","50e96a6d":"code","16e98991":"code","83765429":"code","74911944":"markdown","f0e0f5ed":"markdown","ae7036e0":"markdown","6dcc946d":"markdown","38375259":"markdown","e08ff4f9":"markdown","5db16690":"markdown","a5d65148":"markdown","7ba2fd6c":"markdown","c534ee8e":"markdown","271ee8ed":"markdown","edfcac4d":"markdown","eb73d72b":"markdown","5190f2a6":"markdown","f079bdf5":"markdown"},"source":{"6d294d12":"from __future__ import print_function\n#%matplotlib inline\nimport argparse\nimport os\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nimport torch.utils.data\nimport torchvision\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom IPython.display import HTML\n","e7f0e5ba":"transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrainset = torchvision.datasets.CIFAR10(root='.\/data', train=True,\n                                        download=True,transform=transform)\n\n#choosing only one dataset (cars)\nidx = []\nfor i,k in enumerate(trainset.targets):\n    if k==1:\n        idx.append(i)\n\ntrainset.targets=list( trainset.targets[i] for i in idx )\ntrainset.data = trainset.data[idx]\n\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n                                          shuffle=True)\n\n\nimgs,label = next(iter(trainloader))\n\n#decide which device you'll be using\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nplt.figure(figsize=(12,12))\nplt.axis(\"off\")\nplt.title(\"Training Images\")\nplt.imshow(np.transpose(vutils.make_grid(imgs.to(device)[:32], padding=2, normalize=True).cpu(),(1,2,0)))","983935a0":"def weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)","82be6a19":"class Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.main = nn.Sequential(\n            nn.ConvTranspose2d( 100, 128, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(128),\n            nn.ReLU(True),\n            \n            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(True),\n            \n            nn.ConvTranspose2d( 64, 32, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(32),\n            nn.ReLU(True),\n            \n            nn.ConvTranspose2d( 32, 3, 4, 2, 1, bias=False),\n            nn.Tanh()\n        \n        )\n\n    def forward(self, input):\n        return self.main(input)\n\nnetG = Generator().to(device)\nnetG.apply(weights_init)","b3423f2b":"\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.main = nn.Sequential(\n            nn.Conv2d(3, 32, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(32, 64, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(128, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input):\n        return self.main(input)\n\nnetD = Discriminator().to(device)\nnetD.apply(weights_init)","40b3cd0c":"# Binary Cross Entropy loss function as our criterion\ncriterion = nn.BCELoss()\n\n#  the progression of the generator\nfixed_noise = torch.randn(32, 100, 1, 1, device=device)\n\nreal_label = 1\nfake_label = 0\n\n# Using Adam optimizer as our optimizer\noptimizerD = optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\noptimizerG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))","50e96a6d":"def display_images(n=5,m=5):\n    sample = []\n    figure, axes = plt.subplots(n, m)\n    k=0\n    for i in range(n):\n        for j in range(m):\n            noise = torch.randn(1, 100, 1, 1, device=device)\n            gen_image = netG(noise).to(\"cpu\").clone().detach().squeeze(0)\n            gen_image = gen_image.numpy().transpose(1, 2, 0)\n            sample.append(gen_image)\n            axes[i,j].imshow(sample[k])\n            axes[i,j].axis('off')\n            k+=1\n    plt.show()\n    plt.close()","16e98991":"\n# Training Loop\nG_losses = []\nD_losses = []\niters = 0\nnum_epochs=1000\n\nprint(\"Starting Training Loop...\")\n# For each epoch\nfor epoch in range(num_epochs):\n    # For each batch in the dataloader\n    for i, data in enumerate(trainloader, 0):\n\n        ############################\n        # maximizing log(D(x)) + log(1 - D(G(z)))\n        ###########################\n        ## Train with all-real batch\n        netD.zero_grad()\n        real = data[0].to(device)\n        b_size = real.size(0)\n        label = torch.full((b_size,), real_label, device=device)\n        output = netD(real).view(-1)\n        errD_real = criterion(output, label)\n        errD_real.backward()\n        D_x = output.mean().item()\n\n        ## Train with all-fake batch\n        noise = torch.randn(b_size, 100, 1, 1, device=device)\n        fake = netG(noise)\n        label.fill_(fake_label)\n        output = netD(fake.detach()).view(-1)\n        errD_fake = criterion(output, label)\n        errD_fake.backward()\n        D_G_z1 = output.mean().item()\n        errD = errD_real + errD_fake\n        optimizerD.step()\n\n        ############################\n        # maximizing log(D(G(z)))\n        ###########################\n        netG.zero_grad()\n        label.fill_(real_label) \n        output = netD(fake).view(-1)\n        errG = criterion(output, label)\n        errG.backward()\n        D_G_z2 = output.mean().item()\n        optimizerG.step()\n\n        # Output training stats\n        if i % 500 == 0:\n            print('[%d\/%d][%d\/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f'\n                  % (epoch, num_epochs, i, len(trainloader),\n                     errD.item(), errG.item()))\n\n        G_losses.append(errG.item())\n        D_losses.append(errD.item())\n\n        # Displaying generated images\n        if iters % 1000 == 0:\n            display_images()\n\n        iters += 1","83765429":"plt.figure(figsize=(10,5))\nplt.title(\"Generator and Discriminator Loss\")\nplt.plot(G_losses,label=\"G\")\nplt.plot(D_losses,label=\"D\")\nplt.xlabel(\"iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","74911944":"## Discriminator","f0e0f5ed":"In short:\n   * <b>Generator<\/b> - produces new images as best as it cans\n   * <b>Discriminator<\/b> - Classifies if images are real or fake","ae7036e0":"## Generative Adversarial Networks\nGANs are type of unsupervised machine learning method where they try to generate new, synthetic instances of data that mimics the real data. They are extremely popular in image, video (Deepfake) and voice generation. GANs were invented by Ian Goodfellow and his colleagues in 2014. and quickly rose to fame. They are constructed of two neural networks: Generator and Discriminator.","6dcc946d":" <h1><center><font size=\"30\">Suns out GANs out<\/font><\/center><\/h1>\n![](https:\/\/www.dailydot.com\/wp-content\/uploads\/2020\/02\/elon-bezos-star-trek-deepfake.jpg.webp)","38375259":" ## Process of training\n   *  <b>Generator<\/b> takes an input (in most cases random noise) and returns an image\n   *  Generators output (image) is handed to discriminator together with some instances of the real dataset\n   *  <b>Discriminator<\/b> takes images from both, Generator and real dataset and returns probabilites (0 being fake, 1 being authentic)\n   \n   \n   <img src=\"https:\/\/pathmind.com\/images\/wiki\/GANs.png\" alt=\"Drawing\" style=\"width: 600px;\"\/>\n   \n   \n   <b>But how exactly do Generator and Discriminator learn?<\/b> Here we come to the very important part. Both, Discriminator and Generator are trained separtly. What this means is that when we train one neural network, other stays constant.\n   \n   <b>DISCRIMINATOR TRAINING<\/b>\n   \n   * Discriminator classifies data (both real and fake from the generator)\n   * Discriminator loss penalizes the Discriminator (for classifying authentic images as generated or generated as authentic)\n   * Discriminator updates its weights with regards to its loss (backpropagation)\n   \n   \n   <b>GENERATOR TRAINING<\/b>\n   \n   * Discriminator classifies data\n   * Generator loss penalizes the Generator (for classifying synthetic images as synthetic)\n   * We backpropagate through both Discriminant and Generator but update only Generator weights\n   \n<b>Let's make a summary.<\/b> GANs consist of two neural networks: Generator and Discriminator. Generator produces new images from random noise and Discriminator is a classifier that tries to classify those produced images as false. We train those NNs separately through backpropagation with regards to their loss. When we train one neural network the other stays constant. Generator learns to generate new images more realistically only from loss that has been given by the Discriminator when it classified it as fake. We play this game of cat and mouse until we come to the point where Discriminator can't tell if the image is real or fake.","e08ff4f9":"## Starting literature\n* [Generative Adversarial Networks, paper by Ian Goodfellow](http:\/\/papers.nips.cc\/paper\/5423-generative-adversarial-nets.pdf)\n* [Generative Adversarial Networks, Google's guide](https:\/\/developers.google.com\/machine-learning\/gan)\n* [A Beginner's Guide to Generative Adversarial Networks (GANs)](https:\/\/pathmind.com\/wiki\/generative-adversarial-network-gan)\n","5db16690":"## Weight Initialization\n","a5d65148":"## Training","7ba2fd6c":"## Generator","c534ee8e":"## Plot","271ee8ed":"# Data\nI have chosen CIFAR-10 dataset, which is a dataset consisting of 10 different classes. Each class has 5000 images in training set and 1000 in test set. We will use DCGANs, which is just one version of GANs. You can read more [<b>here<\/b>](https:\/\/pytorch.org\/tutorials\/beginner\/dcgan_faces_tutorial.html).\n","edfcac4d":"# Introduction to GANs\n   * Generative Adversarial Networks\n   * How GANs work\n   * Process of training\n   * Starting literature","eb73d72b":"# Implementation","5190f2a6":"## How GANs work\nLet's take an example dataset and explain the theory of GANs on that specific dataset. For our example we will use dataset <b>MNIST<\/b> (dataset of handwritten digits). Neural network Generator generates new instances of handwritten digits and Neural network Discriminator tries to evaluate if those images are real or fake. We can look at those two NNs as enemies trying to win against each other (that's where the name adversarial comes from).The goal of Generator is to produce the best possible hand-written digits that Discriminator will classify as real and the goal of Discriminator is identify those synthetic images coming from a Generator as fake. What that means is that we will have two losses (Generator loss and Discriminator loss). It is interesting how good generator sometimes performs and in some instances can also trick a human eye. Example (generating new faces):\n\n<img src=\"https:\/\/miro.medium.com\/max\/800\/1*mdoXOnJmAgvMzfs7W9fnmA.jpeg\" alt=\"Drawing\" style=\"width: 400px;\"\/>","f079bdf5":"## Loss function and optimizers\n\nWe will be using Binary Cross Entropy loss function as our loss function."}}