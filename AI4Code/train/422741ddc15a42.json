{"cell_type":{"23e0084f":"code","d93fcf7b":"code","4114b949":"code","09e4fbd2":"code","c994ec93":"code","7f5851f2":"code","1e6f19bd":"code","b6f7b762":"code","1d620a75":"code","1c09ade7":"code","be0fed95":"code","80840786":"code","29c879cf":"code","015c159c":"code","d10c0030":"code","ffca2e6a":"code","1e5626eb":"code","09e336b4":"code","e6441b63":"code","a7dee856":"code","99b1a619":"code","5998d138":"code","9d33fa73":"code","af8bb5f0":"markdown","ecd6c089":"markdown","9c31cd58":"markdown","faa81de0":"markdown","d1e4d904":"markdown","4aea73e2":"markdown","bbf75975":"markdown","d20b060d":"markdown","878c1e12":"markdown","ed78f616":"markdown","91556045":"markdown","856a57b7":"markdown","8c5a57e7":"markdown","d3173354":"markdown","a3c322f2":"markdown","6f19ca1d":"markdown","c07165b3":"markdown","26bf2a5d":"markdown","e2f0e607":"markdown","1653ba1f":"markdown","02d9d786":"markdown","18f78598":"markdown","e7fffb3e":"markdown","52e2d818":"markdown"},"source":{"23e0084f":"import pandas as pd\nfrom pandas import Grouper\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nfrom math import log\nfrom math import exp\n\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom statsmodels.graphics.gofplots import qqplot\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.arima_model import ARIMAResults\nfrom scipy.stats import boxcox\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","d93fcf7b":"dados = pd.read_csv(\"\/kaggle\/input\/corona-virus-brazil\/brazil_covid19_macro.csv\")\ndados.head()","4114b949":"covid = pd.DataFrame(data=dados.deaths.values, index=dados.date, columns=[\"deaths\"])\ncovid","09e4fbd2":"split_point = len(covid) - 56\ndataset, validation = covid[0:split_point], covid[split_point:]\n\nprint('Dataset %d, Validation %d' % (len(dataset), len(validation)))","c994ec93":"# prepare data\nX = dataset.values\nX = X.astype('int64')\n\ntrain_size = int(len(X) * 0.5)\ntrain, test = X[0:train_size], X[train_size:]","7f5851f2":"# walk-forward validation\nhistory = [x for x in train]\npredictions = list()\nfor i in range(len(test)):\n    # predict\n    yhat = history[-1]\n    predictions.append(yhat)\n    \n    # observation\n    obs = test[i]\n    history.append(obs)\n    print('>Predicted=%.3f, Expected=%.3f' % (yhat, obs))\n\n# report performance\nrmse = sqrt(mean_squared_error(test, predictions))\nprint('RMSE: %.3f' % rmse)","1e6f19bd":"print(f\"The persistence model achieved an RMSE of {rmse}\")","b6f7b762":"dataset.describe()","1d620a75":"# line plots of time series\ndataset.plot()\nplt.tight_layout()\nplt.xticks(rotation=45)\nplt.show()","1c09ade7":"plt.figure()\ndataset.hist(edgecolor='k')\ndataset.plot(kind='kde')\nplt.show()","be0fed95":"# create a differenced time series\ndef difference(dataset):\n    diff = list()\n    for i in range(1, len(dataset)):\n        value = dataset[i] - dataset[i-1]\n        diff.append(value)\n    return pd.Series(diff)\n\n# difference data\nstationary = difference(X)\nstationary.index = dataset.index[1:]\n\n# check if stationary\nresult = adfuller(stationary)\nprint('ADF Statistic: %f' % result[0])\nprint('p-value: %f' % result[1])\nprint('Critical Values:')\nfor key, value in result[4].items():\n    print('\\t%s: %.3f' % (key, value))","80840786":"# ACF and PACF plots of time series\nplt.figure()\nplt.subplot(211)\nplot_acf(dataset, lags=50, ax=plt.gca())\nplt.subplot(212)\nplot_pacf(dataset, lags=50, ax=plt.gca())\nplt.tight_layout()\nplt.show()","29c879cf":"# evaluate manually configured ARIMA model\n\nX = dataset.values\nX = X.astype('float32')\ntrain_size = int(len(X) * 0.50)\ntrain, test = X[0:train_size], X[train_size:]\n# walk-forward validation\nhistory = [x for x in train]\npredictions = list()\nfor i in range(len(test)):\n    model = ARIMA(history, order=(0,2,2))\n    model_fit = model.fit(disp=0)\n    yhat = model_fit.forecast()[0]\n    predictions.append(yhat)\n    # observation\n    obs = test[i]\n    history.append(obs)\n    print('>Predicted=%.3f, Expected=%.3f' % (yhat, obs))\n# report performance\nrmse = sqrt(mean_squared_error(test, predictions))\nprint('RMSE: %.3f' % rmse)","015c159c":"# evaluate an ARIMA model for a given order (p,d,q) and return RMSE\ndef evaluate_arima_model(X, arima_order):\n    # prepare training dataset\n    X = X.astype('float32')\n    train_size = int(len(X) * 0.50)\n    train, test = X[0:train_size], X[train_size:]\n    history = [x for x in train]\n    # make predictions\n    predictions = list()\n    for t in range(len(test)):\n        model = ARIMA(history, order=arima_order)\n        model_fit = model.fit(disp=0)\n        yhat = model_fit.forecast()[0]\n        predictions.append(yhat)\n        history.append(test[t])\n    # calculate out of sample error\n    rmse = sqrt(mean_squared_error(test, predictions))\n    return rmse","d10c0030":"# evaluate combinations of p, d and q values for an ARIMA model\ndef evaluate_models(dataset, p_values, d_values, q_values):\n    dataset = dataset.astype('float32')\n    best_score, best_cfg = float(\"inf\"), None\n    for p in p_values:\n        for d in d_values:\n            for q in q_values:\n                order = (p,d,q)\n                try:\n                    rmse = evaluate_arima_model(dataset, order)\n                    if rmse < best_score:\n                        best_score, best_cfg = rmse, order\n                    print('ARIMA%s RMSE=%.3f' % (order,rmse))\n                except:\n                    continue\n    print('Best ARIMA%s RMSE=%.3f' % (best_cfg, best_score))","ffca2e6a":"# evaluate parameters\np_values = range(0,5)\nd_values = range(0,2)\nq_values = range(0,5)\n\nevaluate_models(dataset.values, p_values, d_values, q_values)","1e5626eb":"# walk-forward validation\nhistory = [x for x in train]\npredictions = list()\nfor i in range(len(test)):\n    # predict\n    model = ARIMA(history, order=(4,1,2))\n    model_fit = model.fit(disp=0)\n    yhat = model_fit.forecast()[0]\n    predictions.append(yhat)\n    # observation\n    obs = test[i]\n    history.append(obs)","09e336b4":"# errors\nresiduals = [test[i]-predictions[i] for i in range(len(test))]\nresiduals = pd.DataFrame(residuals)\nplt.figure()\nplt.subplot(211)\nresiduals.hist(ax=plt.gca())\nplt.subplot(212)\nresiduals.plot(kind='kde', ax=plt.gca())\nplt.show()","e6441b63":"plt.figure()\nplt.subplot(211)\nplot_acf(residuals, lags=50, ax=plt.gca())\nplt.subplot(212)\nplot_pacf(residuals, lags=50, ax=plt.gca())\nplt.show()","a7dee856":"X = dataset.values\nX = X[(X!=0).any(axis=1)]\ntransformed, lam = boxcox(X.flatten())\nprint('Lambda: %f' % lam)\nplt.figure(1)\n# line plot\nplt.subplot(311)\nplt.plot(transformed)\n# histogram\nplt.subplot(312)\nplt.hist(transformed)\n# q-q plot\nplt.subplot(313)\nqqplot(transformed, line='r', ax=plt.gca())\nplt.show()","99b1a619":"# invert box-cox transform\ndef boxcox_inverse(value, lam):\n    if lam == 0:\n        return exp(value)\n    return exp(log(lam * value + 1) \/ lam)\n\nX = dataset.values\nX = X[(X!=0).any(axis=1)]\nX = X.flatten()\ntrain_size = int(len(X) * 0.50)\ntrain, test = X[0:train_size], X[train_size:]\n# walk-forward validation\nhistory = [x for x in train]\npredictions = list()\nfor i in range(len(test)):\n    # transform\n    transformed, lam = boxcox(history)\n    if lam < -5:\n        transformed, lam = history, 1\n    # predict\n    model = ARIMA(transformed, order=(4,1,2))\n    model_fit = model.fit(disp=0)\n    yhat = model_fit.forecast()[0]\n    # invert transformed prediction\n    yhat = boxcox_inverse(yhat, lam)\n    predictions.append(yhat)\n    # observation\n    obs = test[i]\n    history.append(obs)\n    print('>Predicted=%.3f, Expected=%.3f' % (yhat, obs))\n# report performance\nrmse = sqrt(mean_squared_error(test, predictions))\nprint('RMSE: %.3f' % rmse)","5998d138":"# prepare data\nX = dataset.values\nX = X[(X!=0).any(axis=1)]\nX = X.flatten()\n# transform data\ntransformed, lam = boxcox(X)\n# fit model\nmodel = ARIMA(transformed, order=(4,1,2))\nmodel_fit = model.fit(disp=0)\n# save model\nmodel_fit.save('model.pkl')\nnp.save('model_lambda.npy', [lam])","9d33fa73":"# invert box-cox transform\ndef boxcox_inverse(value, lam):\n    if lam == 0:\n        return exp(value)\n    return exp(log(lam * value + 1) \/ lam)\n\n# load and prepare datasets\nX = dataset.values\nX = X[(X!=0).any(axis=1)]\nX = X.flatten()\nhistory = [x for x in X]\ny = validation.values\ny = y[(y!=0).any(axis=1)]\ny = y.flatten()\n# load model\nmodel_fit = ARIMAResults.load('model.pkl')\nlam = np.load('model_lambda.npy')\n# make first prediction\npredictions = list()\nyhat = model_fit.forecast()[0]\nyhat = boxcox_inverse(yhat, lam)\npredictions.append(yhat)\nhistory.append(y[0])\nprint('>Predicted=%.3f, Expected=%.3f' % (yhat, y[0]))\n# rolling forecasts\nfor i in range(1, len(y)):\n    # transform\n    transformed, lam = boxcox(history)\n    if lam < -5:\n        transformed, lam = history, 1\n    # predict\n    model = ARIMA(transformed, order=(4,1,2))\n    model_fit = model.fit(disp=0)\n    yhat = model_fit.forecast()[0]\n    # invert transformed prediction\n    yhat = boxcox_inverse(yhat, lam)\n    predictions.append(yhat)\n    # observation\n    obs = y[i]\n    history.append(obs)\n    print('>Predicted=%.3f, Expected=%.3f' % (yhat, obs))\n# report performance\nrmse = sqrt(mean_squared_error(y, predictions))\nprint('RMSE: %.3f' % rmse)\nplt.plot(y)\nplt.plot(predictions, color='red')\nplt.show()","af8bb5f0":"## 5.2 Line Plot","ecd6c089":"## 7.2 Validate Model","9c31cd58":"# 4. Persistence\n\nBefore getting bogged down in data analysis and modeling is to establish a baseline of performance. This will provide both a template for evaluating models using the proposed\ntest harness and a performance measure by which all more elaborate predictive models can be compared. The baseline prediction for time series forecasting is called the naive forecast, or persistence. This is where the observation from the previous time step is used as the prediction for the observation at the next time step.","faa81de0":"## 7.1 Finalize Model","d1e4d904":"## 5.1 Summary Statistics","4aea73e2":"## 6.1 Manually Configured ARIMA","bbf75975":"* There is an increasing trend of robberies over time.\n\n* The trend means the dataset is almost certainly non-stationary and the apparent change in fluctuation may also contribute.","d20b060d":"* The ACF shows a significant lag for 30-32 months.\n\n* The PACF shows a significant lag for perhaps 2 months.\n\n* A good starting point for the p and q values are 31 and 2.\n\nSome experimentation shows that the model does not appear to be stable, with non-zero AR and MA orders defined at the same time. The model can be simplified to ARIMA(0,2,2).","878c1e12":"## 5.3 Density Plot","ed78f616":"# 5. Data Analysis","91556045":"# 2. Problem Description\n\n### The problem is to predict the number of deaths by covid-19 in Brazil.","856a57b7":"The distribution of residual errors is a Gaussian with a zero mean. It's the ideal. It is also a good idea to check the time series of the residual errors for any type of autocorrelation. If present, it would suggest that the model has more opportunity to model the temporal structure in the data.","8c5a57e7":"# 7. Model Validation","d3173354":"The results show that the best configuration discovered was ARIMA(4,1,2)","a3c322f2":"# 1. Importing Libraries and Dataset","6f19ca1d":"## 6.2 Grid Search ARIMA \n\nWe will search all combinations of the following parameters:\n\n* p: 0 to 5.\n* d: 0 to 2.\n* q: 0 to 5.","c07165b3":"The results suggest that what little autocorrelation is present in the time series has been captured by the model.","26bf2a5d":"The results show that the test statistic value 0.747134 is bigger than the critical value at 5% of -2.869. This suggests that we can not reject the null hypothesis. Accepting the null hypothesis means that time series is no-stationary or have time-dependent structure.","e2f0e607":"## 6.3 Review Residual Errors","1653ba1f":"# 3. Test Harness","02d9d786":"Evaluate ARIMA models with box-cox transformed time series","18f78598":"* The distribution is not Gaussian, but is pretty close.\n\n* The distribution may be exponential or a double Gaussian.","e7fffb3e":"# 6. Arima Models","52e2d818":"## 6.4 Box-Cox Transformed Dataset\n\nThe Box-Cox transform is a method that is able to evaluate a suite of power transforms, including, but not limited to, log, square root, and reciprocal transforms of the data."}}