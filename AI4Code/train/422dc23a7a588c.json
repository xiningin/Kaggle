{"cell_type":{"c11f15ed":"code","8be8006e":"code","6fe3ddac":"code","47b5cb78":"code","8905cadc":"code","f176a989":"code","5f5301ce":"code","8bdf76a0":"code","63fe3107":"code","ebe9b293":"code","ab525486":"code","409d8f9a":"code","e5db968b":"code","6d22343c":"code","1606a8a1":"code","9a7b848a":"code","9374763b":"code","e14b1b46":"code","f7659b63":"code","7dfbac7b":"code","0eee580c":"code","f6123539":"code","1a4347d4":"code","e3cba3ac":"code","ffaa8ad8":"code","e0f0d678":"code","dbef2223":"code","530c228a":"code","91d19a27":"code","cb6f8eb7":"code","c690a588":"code","5de2311d":"code","1321ed21":"code","7ff6a1b3":"code","56f2ce5f":"code","3b0c3b1f":"code","520fb1ff":"code","177e27f7":"code","9ae2e61d":"code","b42bd985":"code","c84968bc":"code","13c41191":"code","a356e1f8":"code","0aada21a":"markdown","e12d1845":"markdown","9e337933":"markdown","31b8d142":"markdown","e9c5ee02":"markdown","4dc65453":"markdown","bc850c6a":"markdown","6cb8f630":"markdown","5b7f3e60":"markdown"},"source":{"c11f15ed":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline","8be8006e":"import os\nfrom tqdm import tqdm\nimport random\nfrom itertools import chain","6fe3ddac":"import cv2\nfrom glob import glob\n\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom skimage.color import rgb2gray","47b5cb78":"from sklearn.model_selection import train_test_split","8905cadc":"import tensorflow as tf\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model,save_model\nfrom tensorflow.keras.layers import (Input, Activation,\n                                     BatchNormalization, \n                                     Dropout, Lambda, Conv2D,\n                                     Conv2DTranspose, MaxPooling2D,\n                                     concatenate)\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\nfrom tensorflow.keras import backend as K\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","f176a989":"from skimage import io\nfrom tensorflow.keras.layers import *\nfrom sklearn.preprocessing import StandardScaler, normalize\n","5f5301ce":"os.listdir('..\/input\/lgg-mri-segmentation\/kaggle_3m\/')","8bdf76a0":"root = '..\/input\/lgg-mri-segmentation\/kaggle_3m\/'","63fe3107":"WIDTH = HEIGHT = 256","ebe9b293":"\n# data containing path to Brain MRI and their corresponding mask\nbrain_df = pd.read_csv('..\/input\/lgg-mri-segmentation\/kaggle_3m\/data.csv')\n","ab525486":"brain_df.info","409d8f9a":"brain_df.head(10)","e5db968b":"data_map = []\nfor sub_dir_path in glob(\"\/kaggle\/input\/lgg-mri-segmentation\/kaggle_3m\/\"+\"*\"):\n    #if os.path.isdir(sub_path_dir):\n    try:\n        dir_name = sub_dir_path.split('\/')[-1]\n        for filename in os.listdir(sub_dir_path):\n            image_path = sub_dir_path + '\/' + filename\n            data_map.extend([dir_name, image_path])\n    except Exception as e:\n        print(e)","6d22343c":"df = pd.DataFrame({\"patient_id\" : data_map[::2],\n                   \"path\" : data_map[1::2]})\ndf.head()","1606a8a1":"df_imgs = df[~df['path'].str.contains(\"mask\")]\ndf_masks = df[df['path'].str.contains(\"mask\")]\n\n# File path line length images for later sorting\nBASE_LEN = 89 # len(\/kaggle\/input\/lgg-mri-segmentation\/kaggle_3m\/TCGA_DU_6404_19850629\/TCGA_DU_6404_19850629_ <-!!!43.tif)\nEND_IMG_LEN = 4 # len(\/kaggle\/input\/lgg-mri-segmentation\/kaggle_3m\/TCGA_DU_6404_19850629\/TCGA_DU_6404_19850629_43 !!!->.tif)\nEND_MASK_LEN = 9 # (\/kaggle\/input\/lgg-mri-segmentation\/kaggle_3m\/TCGA_DU_6404_19850629\/TCGA_DU_6404_19850629_43 !!!->_mask.tif)\n\n# Data sorting\nimgs = sorted(df_imgs[\"path\"].values, key=lambda x : int(x[BASE_LEN:-END_IMG_LEN]))\nmasks = sorted(df_masks[\"path\"].values, key=lambda x : int(x[BASE_LEN:-END_MASK_LEN]))\n\n# Sorting check\nidx = random.randint(0, len(imgs)-1)\nprint(\"Path to the Image:\", imgs[idx], \"\\nPath to the Mask:\", masks[idx])","9a7b848a":"# Final dataframe\nbrain_df = pd.DataFrame({\"patient_id\": df_imgs.patient_id.values,\n                         \"image_path\": imgs,\n                         \"mask_path\": masks\n                        })\ndef pos_neg_diagnosis(mask_path):\n    value = np.max(cv2.imread(mask_path))\n    if value > 0 : \n        return 1\n    else:\n        return 0\n    \nbrain_df['mask'] = brain_df['mask_path'].apply(lambda x: pos_neg_diagnosis(x))\nbrain_df","9374763b":"brain_df['mask'].value_counts().index","e14b1b46":"# Use plotly to plot interactive bar chart\nimport plotly.graph_objects as go\n\nfig = go.Figure([go.Bar(x = brain_df['mask'].value_counts().index, y = brain_df['mask'].value_counts())])\nfig.update_traces(marker_color = 'rgb(0,200,0)', marker_line_color = 'rgb(0,255,0)',\n                  marker_line_width = 7, opacity = 0.6)\nfig.show()","f7659b63":"# loading images\nmask_files = glob(root +'*\/*_mask*')\nimg_files = list(map(lambda x: x.replace('_mask',''),mask_files))\n","7dfbac7b":"len(img_files)","0eee580c":"plt.imshow(cv2.imread(brain_df.image_path[623]))","f6123539":"plt.imshow(cv2.imread(brain_df.mask_path[623]))","1a4347d4":"cv2.imread(brain_df.mask_path[623]).max()","e3cba3ac":"# Basic visualizations: Visualize the images (MRI and Mask) in the dataset separately \nimport random\nfig, axs = plt.subplots(4,2, figsize=(10,18))\ncount = 0\nfor x in range(4):\n    i = random.randint(0, len(brain_df)) # select a random index\n    axs[count][0].title.set_text(\"Brain MRI\") # set title\n    axs[count][0].imshow(cv2.imread(brain_df.image_path[i])) # show MRI \n    axs[count][1].title.set_text(\"Mask - \" + str(brain_df['mask'][i])) # plot title on the mask (0 or 1)\n    axs[count][1].imshow(cv2.imread(brain_df.mask_path[i])) # Show corresponding mask\n    count += 1\n\nfig.tight_layout()\n\n","ffaa8ad8":"# display random iteration of images from the dataset with their masks\n#fig = plt.figure(figsize=(13, 13))\n#rnd_no = np.random.randint(0,len(img_files)-9)\n#for ind, i in enumerate(range(rnd_no, rnd_no+9)):\n    \n #   fig.add_subplot(3,3,ind+1)\n    \n    # get image & mask file paths\n  #  img_path = img_files[i]\n   # msk_path = mask_files[i]\n    \n    # read images\n    #img = cv2.imread(img_path)\n    #img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n    #msk = cv2.imread(msk_path)\n    \n    # display images\n    #plt.imshow(img)\n   # plt.imshow(msk, alpha=0.5)\n    #plt.title(img_path.split('\/')[-1].split('.')[0])#\n#plt.show()","e0f0d678":"\nfrom skimage import io\ncount = 0\nfig, axs = plt.subplots(12, 3, figsize = (20, 50))\nfor i in range(len(brain_df)):\n    if brain_df['mask'][i] ==1 and count <12:\n        img = io.imread(brain_df.image_path[i])\n        axs[count][0].title.set_text('Brain MRI')\n        axs[count][0].imshow(img, cmap='hot')\n\n        mask = io.imread(brain_df.mask_path[i])\n        axs[count][1].title.set_text('Mask')\n        axs[count][1].imshow(mask, cmap = 'hot')\n\n\n        img[mask == 255] = (255, 0, 0)\n        axs[count][2].title.set_text('MRI with Mask')\n        axs[count][2].imshow(img, cmap='hot')\n        count+=1\n\nfig.tight_layout()\n\n","dbef2223":"# loading the dataset paths\ndf = pd.DataFrame(data={\"images\": img_files,\n                     \"masks\": mask_files})\n\n# train-valid-test split\ndf_train, df_test = train_test_split(df, test_size=.1)\ndf_train, df_val = train_test_split(df_train, test_size=.2)","530c228a":"# Augmentation\ndef train_generator(df, batch_size, aug_dict,\n                   image_color_mode = \"rgb\",\n                   mask_color_mode = \"grayscale\",\n                   image_save_prefix = \"image\",\n                   mask_save_prefix = \"mask\",\n                   save_to_dir = None,\n                   target_size = (256, 256),\n                   seed=1):\n    \"\"\"\n    Returns sequence of Augmented images\n    by reading the path names from the dataframe\n    \"\"\"\n    \n    image_datagen = ImageDataGenerator(**aug_dict)\n    mask_datagen = ImageDataGenerator(**aug_dict)\n    \n    image_generator = image_datagen.flow_from_dataframe(\n                        df,\n                        x_col='images',\n                        class_mode=None,\n                        color_mode = image_color_mode,\n                        target_size = target_size,\n                        batch_size = batch_size,\n                        save_to_ir = save_to_dir,\n                        save_prefix = image_save_prefix,\n                        seed = seed\n    )\n    \n    mask_generator = mask_datagen.flow_from_dataframe(\n                        df,\n                        x_col='masks',\n                        class_mode=None,\n                        color_mode = mask_color_mode,\n                        target_size = target_size,\n                        batch_size = batch_size,\n                        save_to_ir = save_to_dir,\n                        save_prefix = image_save_prefix,\n                        seed = seed\n    )\n    \n    train_gen = zip(image_generator, mask_generator)\n    \n    for (img, mask) in train_gen:\n        img, mask = adjust_data(img, mask)\n        yield (img, mask)","91d19a27":"def adjust_data(img, mask):\n    \"\"\"\n    Preprocessing function: \n    Normalizes Image arrays.\n    Normalizes and thresholds Mask arrays.\n    \"\"\"\n    img = img \/ 255\n    \n    mask = mask \/ 255\n    mask[mask > 0.5] = 1\n    mask[mask <= 0.5] = 0\n    \n    return (img, mask)","cb6f8eb7":"# Sorenson-Dice loss\nsmooth = 100\n\ndef dice_coef(y_true, y_pred):\n    \n    return ((2* K.sum(y_true*y_pred))\/\n            (K.sum(y_true) + K.sum(y_pred) + smooth))\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\n# Jaccard Distance\ndef iou(y_true, y_pred):\n    intersection = K.sum(y_true * y_pred)\n    sum_ = K.sum(y_true + y_pred)\n    jac = (intersection + smooth)\/(sum_ - intersection + smooth)\n    \n    return jac\n\ndef jac_distance(y_true, y_pred):\n    y_true = K.flatten(y_true)\n    y_pred = K.flatten(y_pred)\n    \n    return -iou(y_true, y_pred)","c690a588":"def unet(input_size=(HEIGHT, WIDTH, 3)):\n    inputs = Input(input_size)\n    \n    # block 1 - Downscaling\n    conv1 = Conv2D(64, (3,3), padding='same')(inputs)\n    bn1 = Activation('relu')(conv1)\n    conv1 = Conv2D(64, (3,3), padding='same')(bn1)\n    bn1 = BatchNormalization(axis=3)(conv1)\n    bn1 = Activation('relu')(bn1)\n    pool1 = MaxPooling2D(pool_size=(2,2))(bn1)\n    \n    # block 2 - Downscaling\n    conv2 = Conv2D(128, (3,3), padding='same')(pool1)\n    bn2 = Activation('relu')(conv2)\n    conv2 = Conv2D(128, (3,3), padding='same')(bn2)\n    bn2 = BatchNormalization(axis=3)(conv2)\n    bn2 = Activation('relu')(bn2)\n    pool2 = MaxPooling2D(pool_size=(2,2))(bn2)\n    \n    # block 3 - Downscaling\n    conv3 = Conv2D(256, (3,3), padding='same')(pool2)\n    bn3 = Activation('relu')(conv3)\n    conv3 = Conv2D(256, (3,3), padding='same')(bn3)\n    bn3 = BatchNormalization(axis=3)(conv3)\n    bn3 = Activation('relu')(bn3)\n    pool3 = MaxPooling2D(pool_size=(2,2))(bn3)\n    \n    # block 4 - Downscaling\n    conv4 = Conv2D(512, (3,3), padding='same')(pool3)\n    bn4 = Activation('relu')(conv4)\n    conv4 = Conv2D(128, (3,3), padding='same')(bn4)\n    bn4 = BatchNormalization(axis=3)(conv4)\n    bn4 = Activation('relu')(bn4)\n    pool4 = MaxPooling2D(pool_size=(2,2))(bn4)\n    \n    # block 5\n    conv5 = Conv2D(1024, (3,3), padding='same')(pool4)\n    bn5 = Activation('relu')(conv5)\n    conv5 = Conv2D(1024, (3,3), padding='same')(bn5)\n    bn5 = BatchNormalization(axis=3)(conv5)\n    bn5 = Activation('relu')(bn5)\n    \n    # block 6 - Upscaling\n    up6 = concatenate(\n        [Conv2DTranspose(512, (2,2),\n                         strides=(2,2),\n                         padding='same')(bn5), conv4], axis=3)\n    conv6 = Conv2D(512, (3,3), padding='same')(up6)\n    bn6 = Activation('relu')(conv6)\n    conv6 = Conv2D(512, (3,3), padding='same')(bn6)\n    bn6 = BatchNormalization(axis=3)(conv6)\n    bn6 = Activation('relu')(bn6)\n    \n    # block 7 - Upscaling\n    up7 = concatenate(\n        [Conv2DTranspose(256, (2,2),\n                         strides=(2,2),\n                         padding='same')(bn6), conv3], axis=3)\n    conv7 = Conv2D(256, (3,3), padding='same')(up7)\n    bn7 = Activation('relu')(conv7)\n    conv7 = Conv2D(256, (3,3), padding='same')(bn7)\n    bn7 = BatchNormalization(axis=3)(conv7)\n    bn7 = Activation('relu')(bn7)\n    \n    # block 8 - Upscaling\n    up8 = concatenate(\n        [Conv2DTranspose(128, (2,2),\n                         strides=(2,2),\n                         padding='same')(bn7), conv2], axis=3)\n    conv8 = Conv2D(128, (3,3), padding='same')(up8)\n    bn8 = Activation('relu')(conv8)\n    conv8 = Conv2D(128, (3,3), padding='same')(bn8)\n    bn8 = BatchNormalization(axis=3)(conv8)\n    bn8 = Activation('relu')(bn8)\n    \n    # block 9 - Upscaling\n    up9 = concatenate(\n        [Conv2DTranspose(64, (2,2),\n                         strides=(2,2),\n                         padding='same')(bn8), conv1], axis=3)\n    conv9 = Conv2D(64, (3,3), padding='same')(up9)\n    bn9 = Activation('relu')(conv9)\n    conv9 = Conv2D(64, (3,3), padding='same')(bn9)\n    bn9 = BatchNormalization(axis=3)(conv9)\n    bn9 = Activation('relu')(bn9)\n    \n    # block 10 - Output layer\n    conv10 = Conv2D(1, (1,1), activation='sigmoid')(bn9)\n    \n    return Model(inputs=[inputs], outputs=[conv10])\n    \n    ","5de2311d":"model = unet()\nmodel.summary()","1321ed21":"# Training parameters\nEPOCHS = 100\nBATCH_SIZE = 32\nALPHA = 0.0001 # learning rate\nDECAY_RATE = ALPHA\/EPOCHS","7ff6a1b3":"df_train.iloc[726]['images']","56f2ce5f":"df_train.iloc[726]['masks']","3b0c3b1f":"train_generator_args = dict(\n    rotation_range=.2,\n    width_shift_range=.05,\n    height_shift_range=.05,\n    shear_range=.05,\n    zoom_range=.05,\n    horizontal_flip=True,\n    fill_mode='nearest')","520fb1ff":"train_gen = train_generator(df_train, BATCH_SIZE,\n                           train_generator_args,\n                           target_size=(HEIGHT, WIDTH))\n\nval_gen = train_generator(df_val, BATCH_SIZE,\n                           dict(),\n                           target_size=(HEIGHT, WIDTH))","177e27f7":"# Setting Model parameters and compiling\nmodel = unet(input_size=(HEIGHT, WIDTH, 3))\nOPTIMIZER = Adam(lr=ALPHA, epsilon=None, decay=DECAY_RATE)\nmodel.compile(\n    optimizer=OPTIMIZER,\n    loss=dice_coef_loss,\n    metrics=['binary_accuracy', iou, dice_coef]    \n)","9ae2e61d":"# Saving Models\n\ncallbacks = [ModelCheckpoint('brain_seg_unet.hdf5',\n                             verbose=1,\n                             save_best_only=True), EarlyStopping(monitor='val_loss', verbose=1, patience=4)]","b42bd985":"history = model.fit(train_gen,\n                   steps_per_epoch=len(df_train)\/BATCH_SIZE,\n                   epochs=EPOCHS,\n                   callbacks=callbacks,\n                   validation_data=val_gen,\n                   validation_steps=len(df_val)\/BATCH_SIZE)","c84968bc":"a = history.history\n\nlist_traindice = a['dice_coef']\nlist_testdice = a['val_dice_coef']\n\nlist_trainjaccard = a['iou']\nlist_testjaccard = a['val_iou']\n\nlist_trainloss = a['loss']\nlist_testloss = a['val_loss']\nplt.figure(1)\n\nplt.plot(list_trainloss,'ro-')\nplt.plot(list_testloss, 'bo-')\nplt.xlabel('iteration')\nplt.ylabel('loss')\nplt.title('loss graph', fontsize = 15)\nplt.figure(2)\nplt.plot(list_traindice, 'ro-')\nplt.plot(list_testdice, 'bo-')\nplt.xlabel('iteration')\nplt.ylabel('dice score')\nplt.title('dice score graph', fontsize = 15)\nplt.legend(['Training','Testing'])\nplt.show()","13c41191":"model = load_model('brain_seg_unet.hdf5', custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef})","a356e1f8":"for i in range(30):\n    index=np.random.randint(1,len(df_test.index))\n    img = cv2.imread(df_test['images'].iloc[index])\n    img = cv2.resize(img ,(256, 256))\n    img = img \/ 255\n    img = img[np.newaxis, :, :, :]\n    pred=model.predict(img)\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,3,1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n    plt.subplot(1,3,2)\n    plt.imshow(np.squeeze(cv2.imread(df_test['masks'].iloc[index])))\n    plt.title('Original Mask')\n    plt.subplot(1,3,3)\n    plt.imshow(np.squeeze(pred) > .5)\n    plt.title('Prediction')\n    plt.show()","0aada21a":"### Image augmentation ","e12d1845":"### Loading dataset paths and slitting into train, valid and test sets","9e337933":"### Initilializing 'train' and 'valid' augmented image generators","31b8d142":"### Setting Model parameters","e9c5ee02":"### Importing necessary modules","4dc65453":"### Visualizing Images","bc850c6a":"### Model Architecture: U-NET","6cb8f630":"### Loss Metrics: Sorenson-Dice Loss & Jaccard Distance","5b7f3e60":"## Training model"}}