{"cell_type":{"98c7eb21":"code","97a1747a":"code","b91fc646":"code","fe43eafb":"code","503ae0d7":"code","a09cbd2d":"code","51de81b6":"code","b4c9982e":"code","371dbf13":"code","9b85e7e4":"code","3304d6fc":"code","9256fdb8":"markdown","12d05672":"markdown","eb866555":"markdown","ff18b746":"markdown","9db3a422":"markdown","5c7220f6":"markdown","c90a5c40":"markdown","24eeb8ef":"markdown","b0aed300":"markdown","5cf01890":"markdown","874c36e2":"markdown","a4dcc951":"markdown","78d0088d":"markdown","bf22c006":"markdown","3df767a0":"markdown","cfd9b89b":"markdown","e3dabd58":"markdown","a722796f":"markdown","102ad162":"markdown","021791a4":"markdown","aaa95286":"markdown","dc92e26a":"markdown"},"source":{"98c7eb21":"import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer as skTfidfVectorizer\ntrain_pd = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')\n# Submission time we have 70k records. Since train has 35k, appending it to itself for having 70k records.\ntrain_pd = train_pd.append(train_pd)","97a1747a":"%%time\nmodel = skTfidfVectorizer(stop_words='english', binary=True, max_features=25_000)\ntext_embeddings_pd = model.fit_transform(train_pd['title'])","b91fc646":"import cudf, cuml\nfrom cuml.feature_extraction.text import TfidfVectorizer as cuTfidfVectorizer\ntrain_cu = cudf.read_csv('..\/input\/shopee-product-matching\/train.csv')\n# Submission time we have 70k records. Since train has 35k, appending it to itself for having 70k records.\ntrain_cu = train_cu.append(train_cu)","fe43eafb":"%%time\nmodel = cuTfidfVectorizer(stop_words='english', binary=True, max_features=25_000)\ntext_embeddings_cu = model.fit_transform(train_cu['title']).toarray()","503ae0d7":"from cuml.neighbors import NearestNeighbors\nKNN = 50\nmodel = NearestNeighbors(n_neighbors=KNN)","a09cbd2d":"# try:\n#     # Compare every record against every other record and five 50 nearest records for each\n#     model.fit(text_embeddings_cu.get())\n#     distances, indices = model.kneighbors(text_embeddings_cu)\n# except Exception as e:\n#     print(e)","51de81b6":"predictions = []\noneChunkLen = 1024 * 4\ntotalChunks = len(text_embeddings_cu)\/\/oneChunkLen\nif len(text_embeddings_cu)%oneChunkLen != 0: totalChunks += 1  ","b4c9982e":"import cupy, gc","371dbf13":"%%time\nfor i in range(totalChunks):\n    a = i*oneChunkLen\n    b = (i+1)*oneChunkLen\n    b = min(b, len(text_embeddings_cu))\n#     print('chunk',a,'to',b)\n    \n    #COSINE Similarity\n    cSim = cupy.matmul(text_embeddings_cu, text_embeddings_cu[a:b].T).T\n    #Now cSim will be an array of size [oneChunkLen X len(text_embeddings_cu)]\n    #That is, for each row in the chunk, it provides the distance to every other row in text_embeddings_cu\n    #Distance in between 0 to 1. Values closer to 1 means more similar.\n    \n    for j in range(b-a):\n        matchIndices = cupy.where(cSim[j,]>0.7)[0]\n        posting_ids = train_pd.iloc[cupy.asnumpy(matchIndices)].posting_id.values\n        predictions.append(posting_ids)\n        \ndel model,text_embeddings_cu\n_ = gc.collect()","9b85e7e4":"import torch\nimport numpy as np","3304d6fc":"%%time\npredictions = []\n#Move to GPU\ntext_embeddings_tch = torch.from_numpy(text_embeddings_pd.toarray().astype(np.float16)).to('cuda:0')\n\nfor i in range(totalChunks):\n    a = i*oneChunkLen\n    b = (i+1)*oneChunkLen\n    b = min(b, len(text_embeddings_tch))\n#     print('chunk',a,'to',b)\n    \n    #COSINE Similarity using PyTorch\n    cSim = torch.matmul(text_embeddings_tch, text_embeddings_tch[a:b].T).T\n    \n    for j in range(b-a):\n        matchIndices = torch.where(cSim[j,]>0.7)[0].cpu().numpy()\n        posting_ids = train_pd.iloc[matchIndices].posting_id.values\n        predictions.append(posting_ids)\n        \ndel text_embeddings_tch\ngc.collect()","9256fdb8":"As a ML beginner, I found this compeition very useful in learning various concepts around data science and thought of documenting in this notebook.","12d05672":"To compare an image to another image or a sentence to another sentence, we need to represent these objects in numbers (vectors).    \nWe can use pre-trained EfficientNet layers (last but one layer) for getting a representative vector from an image. You can actually use any other pretrained neural net image models as well for this.   \nSimilarly, for sentenses\/text (titles here), you can use TFidfVectorizer which is available in cuML library for getting vectors from each of the ","eb866555":"### Text processing using RAPIDS","ff18b746":"As we see creating embeddings itslef is not a memory intensive task. CPU takes just around a second and we see RAPIDS saves 80% of time. So I do not think using RAPIDS is **not really a major help for creating embeddings.**","9db3a422":"##### Chunking using Pytorch","5c7220f6":"Instead of comparing EVERY record with every other record in ONE GO,    \nwe will compare only a CHUNK of records with every other record. This technique is called as chunking.","c90a5c40":"Hash is another set of techniques that create a fingerprint of a media file and widely used to compare media to find out piracy. Small changes to the image (resolution, hue, rotation) do not alter the fingerprint thus you can use it to check if images are same\/similar. \n\nThere are several algorithms here aHash, pHash, dHash and wHash. As part of our training data pHash is provided so we can use it to find out the duplicate images.","24eeb8ef":"### Comparing titles for similarity","b0aed300":"### Compare embeddings speed","5cf01890":"RAPIDS is by Nvidia and it provides several libraries for making use of GPU capabilities. Important one for our task are   \n**CUDF**: This is supposed to be a replacement for Pandas. Though not as extensive as Pandas in its APIs, it is catching up,    \n**CUML**: This is supposed to be a replacement for scikit-learn. Again not all functionality of Scikit-Learn is there but we have enough for this competition.   ","874c36e2":"### Acknowledgements","a4dcc951":"### Hash for an image","78d0088d":"### Image and Text Embeddings","bf22c006":"#### CUDF","3df767a0":"Once you have the vecor representation of titles, you can use various algorithms to compare the distance between the vectors so as to find if they are same\/similar. One such algorithm is consine distance between the vectors.    \nUsing cpu for comparing 70k records will take a very long time and would timeout on Kaggle. So we have to use GPU here. Here we have two options (that I know). Either to use RAPIDS or PyTorch. Let us compare them.","cfd9b89b":"Code around RAPIDS AI is from [Chris Deotte](https:\/\/www.kaggle.com\/cdeotte). [This](https:\/\/www.kaggle.com\/cdeotte\/part-2-rapids-tfidfvectorizer-cv-0-700) notebook.   \nCode around PyTorch is from [Nick](https:\/\/www.kaggle.com\/nicksergievskiy\/pytorch-is-all-you-need-tfidf) from [this](https:\/\/www.kaggle.com\/nicksergievskiy\/pytorch-is-all-you-need-tfidf) notebook.","e3dabd58":"So pytorch could run this in 1min 37secs, and RAPIDS couls run this in 1min 19secs. There is a catch though. In PyTorch, I had to use FP16 using *.astype(np.float16)*, otherwise it resulted in CUDA out of memory (you may try reducing the chunk size). **In Summary, if you are not too familar with you can do this with PyTorch.**","a722796f":"### Chunking","102ad162":"##### Chunking using CUML","021791a4":"Traditionally we used GPU for neural network processing due to its huge need for memory and matrix operations. However in this case we need to compare title of 70,000 products (while submission) with each other to find similar ones. Using Pandas or scikit-learn would force us doing this on CPU, eventhough we have GPUs available. Doing this computation on CPU would time out the submission. So we need to do this on GPU. Enter 'RAPIDS'.","aaa95286":"As we see above, we get **GPU out of memory** error. So that means that we cannot use this approach for submission. Sowe need a technique called as chunking.","dc92e26a":"#### scikit-learn"}}