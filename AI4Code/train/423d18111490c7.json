{"cell_type":{"a0207bbf":"code","ab31a746":"code","f9f25691":"code","10811a85":"code","f04be98e":"code","3ce0c878":"code","66258bc2":"code","85d86c04":"markdown"},"source":{"a0207bbf":"import numpy as np\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport math\nimport pandas as pd\nfrom sklearn import model_selection\nimport glob\nimport os\nfrom zipfile import ZipFile\nimport shutil\nimport tqdm.notebook as tqdm\n\nimport logging\ntf.get_logger().setLevel(logging.ERROR)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ngpus = tf.config.experimental.list_physical_devices('GPU')\nnum_gpus = len(gpus)\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n        print(num_gpus, \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n    except RuntimeError as e:\n        print(e)\n#     policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n#     tf.keras.mixed_precision.experimental.set_policy(policy)\n#     print('Compute dtype: %s' % policy.compute_dtype)\n#     print('Variable dtype: %s' % policy.variable_dtype)\n\n    \nif num_gpus == 0:\n    strategy = tf.distribute.OneDeviceStrategy(device='CPU')\n    print(\"Setting strategy to OneDeviceStrategy(device='CPU')\")\nelif num_gpus == 1:\n    strategy = tf.distribute.OneDeviceStrategy(device='GPU')\n    print(\"Setting strategy to OneDeviceStrategy(device='GPU')\")\nelse:\n    strategy = tf.distribute.MirroredStrategy()\n    print(\"Setting strategy to MirroredStrategy()\")","ab31a746":"config = {\n    'learning_rate': 1e-3,\n    'momentum': 0.9,\n    'K': 4,\n    'margin': 0.3,\n    'clip_grad': 10.0,\n    'n_epochs': 4,\n    'batch_size': 16,\n    'input_size': (256, 256, 3),\n    'dense_units': 1024,\n    'dropout_rate': 0.0,\n}","f9f25691":"def read_df(input_path):\n    files_paths = glob.glob(input_path + 'train\/*\/*\/*\/*')\n    mapping = {}\n    for path in files_paths:\n        mapping[path.split('\/')[-1].split('.')[0]] = path\n    df = pd.read_csv(input_path + 'train.csv')\n    df['path'] = df['id'].map(mapping)\n    \n    df = (\n        df\n        .groupby('landmark_id')['path']\n        .agg(lambda x: ','.join(x))\n        .reset_index()\n    )\n    return df\n\ndf = read_df('..\/input\/landmark-retrieval-2020\/')\ndf.head(10)","10811a85":"def _get_transform_matrix(rotation, shear, hzoom, wzoom, hshift, wshift):\n\n    def get_3x3_mat(lst):\n        return tf.reshape(tf.concat([lst],axis=0), [3,3])\n\n    # convert degrees to radians\n    rotation = math.pi * rotation \/ 360.\n    shear    = math.pi * shear    \/ 360.\n\n    one  = tf.constant([1],dtype='float32')\n    zero = tf.constant([0],dtype='float32')\n\n    c1   = tf.math.cos(rotation)\n    s1   = tf.math.sin(rotation)\n    rot_mat = get_3x3_mat([c1,    s1,   zero ,\n                           -s1,   c1,   zero ,\n                           zero,  zero, one ])\n\n    c2 = tf.math.cos(shear)\n    s2 = tf.math.sin(shear)\n    shear_mat = get_3x3_mat([one,  s2,   zero ,\n                             zero, c2,   zero ,\n                             zero, zero, one ])\n\n    zoom_mat = get_3x3_mat([one\/hzoom, zero,      zero,\n                            zero,      one\/wzoom, zero,\n                            zero,      zero,      one])\n\n    shift_mat = get_3x3_mat([one,  zero, hshift,\n                             zero, one,  wshift,\n                             zero, zero, one   ])\n\n    return tf.matmul(\n        tf.matmul(rot_mat, shear_mat),\n        tf.matmul(zoom_mat, shift_mat)\n    )\n\ndef _spatial_transform(image,\n                       rotation=3.0,\n                       shear=2.0,\n                       hzoom=8.0,\n                       wzoom=8.0,\n                       hshift=8.0,\n                       wshift=8.0):\n\n    ydim = tf.gather(tf.shape(image), 0)\n    xdim = tf.gather(tf.shape(image), 1)\n    xxdim = xdim % 2\n    yxdim = ydim % 2\n\n    # random rotation, shear, zoom and shift\n    rotation = rotation * tf.random.normal([1], dtype='float32')\n    shear = shear * tf.random.normal([1], dtype='float32')\n    hzoom = 1.0 + tf.random.normal([1], dtype='float32') \/ hzoom\n    wzoom = 1.0 + tf.random.normal([1], dtype='float32') \/ wzoom\n    hshift = hshift * tf.random.normal([1], dtype='float32')\n    wshift = wshift * tf.random.normal([1], dtype='float32')\n\n    m = _get_transform_matrix(\n        rotation, shear, hzoom, wzoom, hshift, wshift)\n\n    # origin pixels\n    y = tf.repeat(tf.range(ydim\/\/2, -ydim\/\/2,-1), xdim)\n    x = tf.tile(tf.range(-xdim\/\/2, xdim\/\/2), [ydim])\n    z = tf.ones([ydim*xdim], dtype='int32')\n    idx = tf.stack([y, x, z])\n\n    # destination pixels\n    idx2 = tf.matmul(m, tf.cast(idx, dtype='float32'))\n    idx2 = tf.cast(idx2, dtype='int32')\n    # clip to origin pixels range\n    idx2y = tf.clip_by_value(idx2[0,], -ydim\/\/2+yxdim+1, ydim\/\/2)\n    idx2x = tf.clip_by_value(idx2[1,], -xdim\/\/2+xxdim+1, xdim\/\/2)\n    idx2 = tf.stack([idx2y, idx2x, idx2[2,]])\n\n    # apply destinations pixels to image\n    idx3 = tf.stack([ydim\/\/2-idx2[0,], xdim\/\/2-1+idx2[1,]])\n    d = tf.gather_nd(image, tf.transpose(idx3))\n    image = tf.reshape(d, [ydim, xdim, 3])\n    return image\n\ndef _pixel_transform(image,\n                     saturation_delta=0.3,\n                     contrast_delta=0.1,\n                     brightness_delta=0.2):\n    image = tf.image.random_saturation(\n        image, 1-saturation_delta, 1+saturation_delta)\n    image = tf.image.random_contrast(\n        image, 1-contrast_delta, 1+contrast_delta)\n    image = tf.image.random_brightness(\n        image, brightness_delta)\n    return image\n\ndef _random_fliplr(image, p=0.25):\n    r = tf.random.uniform(())\n    mirror_cond = tf.math.less(r, p)\n    image = tf.cond(\n        mirror_cond,\n        lambda: tf.reverse(image, [1]),\n        lambda: image\n    )\n    return image\n\ndef preprocess_input(image, target_size, augment=False):\n    \n    image = tf.image.resize(\n        image, target_size, method='bilinear')\n\n    image = tf.cast(image, tf.uint8)\n    if augment:\n        image = _spatial_transform(image)\n        image = _random_fliplr(image)\n        image = _pixel_transform(image)\n    image = tf.cast(image, tf.float32)\n    image \/= 255.\n    return image\n\ndef create_triplet_dataset(df, training, batch_size, input_size, K):\n    \n    def sample_input(image_paths, label, K):\n        image_paths = tf.strings.split(image_paths, sep=',')\n        labels = tf.tile([label], [K,])\n        if K-len(image_paths) > 0:\n            image_paths = tf.random.shuffle(image_paths)\n            for i in tf.range(K-len(image_paths)):\n                image_paths = tf.concat(\n                    [image_paths, [tf.gather(image_paths, i)]], axis=0)\n            return image_paths, labels\n        idx = tf.argsort(tf.random.uniform(tf.shape(image_paths)))\n        idx = tf.gather(idx, tf.range(K))\n        image_paths = tf.gather(image_paths, idx)\n        return image_paths, labels\n\n    def read_image(image_path):\n        image = tf.io.read_file(image_path)\n        return tf.image.decode_jpeg(image, channels=3)\n\n    def reshape(x, y):\n        x = tf.reshape(x, (-1, *input_size))\n        y = tf.reshape(y, (-1,))\n        return x, y\n    \n    @tf.autograph.experimental.do_not_convert # to silence warning\n    def nested(x, y):\n        return (tf.data.Dataset.from_tensor_slices((x, y))\n                .map(lambda x, y: (read_image(x), y),\n                    tf.data.experimental.AUTOTUNE)\n                .map(lambda x, y: (preprocess_input(\n                        x, input_size[:2], True), y),\n                     tf.data.experimental.AUTOTUNE)\n                .batch(K))\n\n    image_paths, labels = df.path, df.index\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n    if training:\n        dataset = dataset.shuffle(10_000)\n    dataset = dataset.map(\n        lambda x, y: sample_input(x, y, K), tf.data.experimental.AUTOTUNE)\n    dataset = dataset.flat_map(nested)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.map(\n        lambda x, y: reshape(x, y), tf.data.experimental.AUTOTUNE)\n    return dataset","f04be98e":"def create_model(input_shape, dense_units=512, dropout_rate=0.0):\n\n    backbone = tf.keras.applications.ResNet50(\n        include_top=False,\n        input_shape=input_shape,\n        weights=('..\/input\/imagenet-weights\/' +\n                 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n    )\n\n    pooling = tf.keras.layers.GlobalAveragePooling2D(name='head\/pooling')\n    dropout = tf.keras.layers.Dropout(dropout_rate, name='head\/dropout')\n    dense = tf.keras.layers.Dense(dense_units, name='head\/dense', dtype='float32')\n\n    image = tf.keras.layers.Input(input_shape, name='input\/image')\n    \n    x = backbone(image)\n    x = pooling(x)\n    x = dropout(x)\n    x = dense(x)\n    return tf.keras.Model(\n        inputs=image, outputs=x)\n\n\nclass DistributedModel:\n\n    def __init__(self,\n                 input_size,\n                 batch_size,\n                 finetuned_weights,\n                 dense_units,\n                 dropout_rate,\n                 margin,\n                 optimizer,\n                 strategy,\n                 mixed_precision,\n                 clip_grad):\n\n        self.model = create_model(\n            input_shape=input_size,\n            dense_units=dense_units,\n            dropout_rate=dropout_rate)\n\n        self.input_size = input_size\n\n        if finetuned_weights:\n            self.model.load_weights(finetuned_weights)\n\n        self.mixed_precision = mixed_precision\n        self.optimizer = optimizer\n        self.strategy = strategy\n        self.clip_grad = clip_grad\n\n        # loss function\n        self.loss_object = tfa.losses.TripletSemiHardLoss(\n            margin=margin,\n            distance_metric='L2',\n        )\n        # metrics\n        self.mean_loss_train = tf.keras.metrics.Mean()\n\n        if self.optimizer and self.mixed_precision:\n            self.optimizer = \\\n                tf.keras.mixed_precision.experimental.LossScaleOptimizer(\n                    optimizer, loss_scale='dynamic')\n\n    def _compute_loss(self, labels, embedding):\n        per_example_loss = self.loss_object(labels, embedding)\n        return per_example_loss \/ strategy.num_replicas_in_sync\n\n    def _backprop_loss(self, tape, loss, weights):\n        gradients = tape.gradient(loss, weights)\n        if self.mixed_precision:\n            gradients = self.optimizer.get_unscaled_gradients(gradients)\n        clipped, _ = tf.clip_by_global_norm(gradients, clip_norm=self.clip_grad)\n        self.optimizer.apply_gradients(zip(clipped, weights))\n\n    def _train_step(self, inputs):\n        with tf.GradientTape() as tape:\n            embedding = self.model(inputs[0], training=True)\n            loss = self._compute_loss(inputs[1], embedding)\n            self.mean_loss_train.update_state(loss)\n            if self.mixed_precision:\n                loss = self.optimizer.get_scaled_loss(loss)\n        self._backprop_loss(tape, loss, self.model.trainable_weights)\n\n    @tf.function\n    def _distributed_train_step(self, dist_inputs):\n        per_replica_loss = self.strategy.run(self._train_step, args=(dist_inputs,))\n        return self.strategy.reduce(\n            tf.distribute.ReduceOp.SUM, per_replica_loss, axis=None)\n\n    def train(self, train_ds, epochs, save_path):\n        for epoch in range(epochs):\n            dist_train_ds = self.strategy.experimental_distribute_dataset(train_ds)\n            dist_train_ds = tqdm.tqdm(dist_train_ds)\n            for i, inputs in enumerate(dist_train_ds):\n                loss = self._distributed_train_step(inputs)\n                dist_train_ds.set_description(\n                    \"Loss {:.5f}\".format(self.mean_loss_train.result().numpy())\n                )\n            if save_path:\n                self.model.save_weights(save_path)\n\n            self.mean_loss_train.reset_states()","3ce0c878":"train_ds = create_triplet_dataset(\n    df=df,\n    training=True,\n    batch_size=config['batch_size'],\n    input_size=config['input_size'],\n    K=config['K']\n)\n\nwith strategy.scope():\n\n    optimizer = tf.keras.optimizers.SGD(\n        config['learning_rate'], momentum=config['momentum'])\n\n    dist_model = DistributedModel(\n        input_size=config['input_size'],\n        batch_size=config['batch_size'],\n        finetuned_weights=None,\n        dense_units=config['dense_units'],\n        dropout_rate=config['dropout_rate'],\n        margin=config['margin'],\n        optimizer=optimizer,\n        strategy=strategy,\n        mixed_precision=False,\n        clip_grad=config['clip_grad'])\n\n    dist_model.train(\n        train_ds=train_ds, \n        epochs=config['n_epochs'], \n        save_path='model.h5')","66258bc2":"newmodel = tf.keras.Model(\n    inputs=dist_model.model.get_layer('input\/image').input,\n    outputs=dist_model.model.get_layer('head\/dense').output)\n\n\n@tf.function(input_signature=[\n        tf.TensorSpec(\n            shape=[None, None, 3],\n            dtype=tf.uint8,\n            name='input_image')\n    ])\ndef serving(input_image):\n    input_image = preprocess_input(\n        input_image, target_size=config['input_size'][:2])\n    outputs = newmodel(input_image[tf.newaxis])\n    features = tf.math.l2_normalize(outputs[0])\n    return {\n        'global_descriptor': tf.identity(features, name='global_descriptor')\n    }\n\n\ntf.saved_model.save(\n    obj=newmodel,\n    export_dir='model',\n    signatures={'serving_default': serving})\n\n\nfilepaths = []\nfor dirpath, _, filepath in os.walk('model'):\n    for fp in filepath:\n        filepaths.append(os.path.join(dirpath, fp))\n\nwith ZipFile('submission.zip', 'w') as zip:\n    for fp in filepaths:\n        print(fp, '\/'.join(fp.split('\/')[1:]))\n        zip.write(fp, arcname='\/'.join(fp.split('\/')[1:]))","85d86c04":"### Work in progress\/incomplete\n\n#### Feel free to give feedback!"}}