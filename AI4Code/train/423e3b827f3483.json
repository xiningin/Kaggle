{"cell_type":{"694f4278":"code","2df4f8c2":"code","ef12d3aa":"code","7e2cdc38":"code","e4dd1c7a":"code","ab02e280":"code","d9a5ef5c":"code","b97ba85d":"code","32c49823":"code","01cb4c16":"code","af7e6ad6":"code","f28adf97":"code","49b9ffe0":"code","0c7fad3b":"code","9a9c6c08":"code","e3859060":"code","d0d8cd4c":"code","d789b728":"code","d5757915":"code","2a2d00c6":"code","302dc831":"code","27fe4811":"code","228558b4":"code","81d04986":"code","6473e584":"code","2ec58ec5":"code","103b266a":"markdown","bade91a7":"markdown","cb11dc9d":"markdown","1a85898c":"markdown"},"source":{"694f4278":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport time \n\nimport matplotlib.pyplot as plt\n\nfrom keras import Sequential\nfrom keras.layers import Dense, Dropout, InputLayer, Lambda, Input\nfrom keras.preprocessing.image import load_img, img_to_array\n\nfrom sklearn.model_selection import train_test_split","2df4f8c2":"labels_df = pd.read_csv('\/kaggle\/input\/dog-breed-identification\/labels.csv')\nsample = pd.read_csv('\/kaggle\/input\/dog-breed-identification\/sample_submission.csv')","ef12d3aa":"print('no of images in train dataset: {}'.format(len(labels_df)))\nprint('no of images in test dataset: {}'.format(len(sample)))","7e2cdc38":"def images_to_array(directory, label_dataframe, target_size = (331, 331, 3)):\n    images = np.zeros([len(label_dataframe), target_size[0], target_size[1], target_size[2]], dtype=np.uint8)\n    img = ''\n    for ix, image_name in enumerate(label_dataframe['id'].values):\n        img_dir = os.path.join(directory, image_name + '.jpg')\n        img = load_img(img_dir, target_size = target_size)\n        images[ix] = img_to_array(img)\n    del img\n    label_dict = dict(enumerate(label_dataframe['breed'].unique()))\n    return images, label_dict","e4dd1c7a":"t = time.time()\ntrain_images, labels = images_to_array('\/kaggle\/input\/dog-breed-identification\/train', labels_df[:])\nprint('runtime in seconds: {}'.format(time.time() - t))","ab02e280":"plt.figure(figsize = (20, 10))\nfor ix, image in enumerate(train_images[:16]):\n    plt.subplot(4, 8, ix + 1)\n    plt.imshow(image \/ 255.0)\n    plt.xticks([])\n    plt.yticks([])    ","d9a5ef5c":"def get_feature(model_name, preprocess_input, images, target_size = (331,331,3)):\n    base_model = model_name(input_shape = target_size, include_top=False, pooling = 'avg')\n\n    model = Sequential()\n    model.add(InputLayer(input_shape = target_size))\n    model.add(Lambda(preprocess_input))\n    model.add(base_model)\n\n    feature = model.predict(images)\n    \n    print('feature-map shape: {}'.format(feature.shape))\n    return feature","b97ba85d":"from keras.applications.inception_v3 import InceptionV3, preprocess_input\n\ninception_preprocess = preprocess_input\ninception_feature = get_feature(InceptionV3, preprocess_input, train_images)","32c49823":"from keras.applications.nasnet import NASNetLarge, preprocess_input\nnasnet_preprocessor = preprocess_input\nnasnet_features = get_feature(NASNetLarge, nasnet_preprocessor, train_images)","01cb4c16":"from keras.applications.xception import Xception, preprocess_input\n\nxception_preprocess = preprocess_input\nxception_feature = get_feature(Xception, xception_preprocess, train_images)","af7e6ad6":"from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n\nresnet_preprocess = preprocess_input\nresnet_feature = get_feature(InceptionResNetV2, resnet_preprocess, train_images)","f28adf97":"final_features = np.concatenate([inception_feature, nasnet_features, xception_feature, resnet_feature], axis = 1)\nprint('final features shape: {}'.format(final_features.shape))\ndel train_images, inception_feature, nasnet_features, xception_feature, resnet_feature","49b9ffe0":"class_to_index = dict({labels[ix]:ix for ix in labels.keys()})\nindex_to_class = labels","0c7fad3b":"labels = labels_df['breed'].map(class_to_index)","9a9c6c08":"def create_model(features_shape = 1024):\n    model = Sequential()\n    model.add(InputLayer(input_shape = (features_shape, )))\n    #model.add(Dense(4096, activation = 'relu'))\n    model.add(Dropout(0.7))\n    model.add(Dense(len(class_to_index), activation = 'softmax'))\n    \n    model.compile(loss = 'sparse_categorical_crossentropy', optimizer ='Adam', metrics = ['accuracy'])\n    return model","e3859060":"#drop_neuron = [0.1, 0.2, 0.3]\n\n#param_grid = dict(drop_neuron = drop_neuron)\n#model = KerasClassifier(build_fn=create_model, epochs = 10, batch_size = 32)\n#grid_search = GridSearchCV(estimator=model, param_grid=param_grid)\n#result = grid_search.fit(x_train, y_train)","d0d8cd4c":"#means = result.cv_results_['mean_test_score']\n#stds = result.cv_results_['std_test_score']\n#params = result.cv_results_['params']\n#print('best param: {}'.format(result.best_params_))\n#for mean, stdev, param in zip(means, stds, params):\n#    print(\"%f (%f) with: %r\" % (mean, stdev, param))","d789b728":"model = create_model(final_features.shape[1])\nmodel.summary()","d5757915":"model.fit(final_features, labels, epochs = 6, validation_split = 0.2)","2a2d00c6":"del final_features, labels","302dc831":"def images_to_array(directory, label_dataframe, target_size = (331, 331,3)):\n    images = np.zeros([len(label_dataframe), target_size[0], target_size[1], target_size[2]], dtype=np.uint8)\n    img = ''\n    for ix, image_name in enumerate(label_dataframe['id'].values):\n        img_dir = os.path.join(directory, image_name + '.jpg')\n        img = load_img(img_dir, target_size = target_size)\n        images[ix] = img_to_array(img)\n    del img\n    return images","27fe4811":"t = time.time()\ntest_images = images_to_array('\/kaggle\/input\/dog-breed-identification\/test', sample)\nprint('runtime in seconds: {}'.format(time.time() - t))","228558b4":"resnet_feature = get_feature(InceptionResNetV2, resnet_preprocess, test_images)\nxception_feature = get_feature(Xception, xception_preprocess, test_images)\nnasnet_features = get_feature(NASNetLarge, nasnet_preprocessor, test_images)\ninception_feature = get_feature(InceptionV3, preprocess_input, test_images)","81d04986":"final_features = np.concatenate([inception_feature, nasnet_features, xception_feature, resnet_feature], axis = 1)\nprint('final features shape: {}'.format(final_features.shape))\ndel test_images, inception_feature, nasnet_features, xception_feature, resnet_feature","6473e584":"prediction = model.predict(final_features)\nsubmission = pd.DataFrame({'id':sample.id})\nprediction = pd.DataFrame(prediction)\nprediction.columns = class_to_index.keys()","2ec58ec5":"submission = pd.concat([submission, prediction], axis = 1)\nsubmission.to_csv('submission.csv', index = False)","103b266a":"### inception model","bade91a7":"### Xception model","cb11dc9d":"### NASNetLarge model","1a85898c":"### ResNet50V2 model"}}