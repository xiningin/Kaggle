{"cell_type":{"4c62ca76":"code","6c4118bf":"code","7f66d31a":"code","b78c772c":"code","37d02689":"code","b84d8e75":"code","e0ecfaaa":"code","9edd1ce5":"code","be602b29":"code","58e5498c":"code","77ee822b":"code","35c50086":"code","9dd77d46":"code","39e40e1f":"code","196ceee6":"code","e9285c1f":"code","c9e07cf0":"markdown","8b9ee769":"markdown","b344419d":"markdown"},"source":{"4c62ca76":"import re\nimport numpy as np\nimport pandas as pd\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import sent_tokenize, word_tokenize \nimport xgboost as xgb\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.feature_extraction.text import TfidfVectorizer","6c4118bf":"# Load the train and test data\ntrain_df = pd.read_csv(\"..\/input\/commonlitreadabilityprize\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/commonlitreadabilityprize\/test.csv\")\n\nresult = pd.DataFrame()\nresult['id'] = test_df['id']\n\ntrain_df = train_df[['excerpt', 'target']]\ntest_df = test_df[['excerpt']]","7f66d31a":"test_df.head()","b78c772c":"train_df.head()","37d02689":"train_df.iloc[1,0]","b84d8e75":"# Create a preprocessing function to handle the text data\ndef preprocess(text):\n    text = re.sub(\"[^a-zA-Z]\" , \" \", text)\n    text = text.lower()\n    \n    # tokenize into words\n    tokens = [word for sent in sent_tokenize(text) for word in word_tokenize(sent)]\n    \n    # remove punctuation\n    interpunctuations = ['``', ',', '.', ':', ';', '?', '(', ')', '[', ']', '&', '!', '*', '@', '#', '$', '%']\n    tokens = [token for token in tokens if token not in interpunctuations]\n    \n    # lower capitalization\n    tokens = [word.lower() for word in tokens]\n    \n    # lemmatize\n    lemma = nltk.WordNetLemmatizer()\n    tokens = [lemma.lemmatize(word) for word in tokens]\n    preprocessed_text = \" \".join(tokens)\n    return preprocessed_text\n\ntrain_df[\"excerpt\"] = train_df[\"excerpt\"].apply(preprocess)\ntest_df[\"excerpt\"] = test_df[\"excerpt\"].apply(preprocess)","e0ecfaaa":"train_df.iloc[1,0]","9edd1ce5":"train_text = train_df[[\"excerpt\"]]\ntest_text = test_df[[\"excerpt\"]]\nfinal_text = pd.concat([train_text , test_text])","be602b29":"final_text[\"excerpt\"][0]","58e5498c":"word_vectorizer = TfidfVectorizer()\nword_vectorizer.fit(final_text[\"excerpt\"])\ntrain_word_features = word_vectorizer.transform(train_df[\"excerpt\"])\ntest_word_features = word_vectorizer.transform(test_df[\"excerpt\"])","77ee822b":"train_word_features.shape","35c50086":"# Split the X_train , y_train ,X_test\nX_train = train_word_features\ny_train = train_df[\"target\"]\nX_test = test_word_features\n\n\n# I use the XGBRegressor for our problem\nxgb_model = XGBRegressor(learning_rate = 0.1,n_estimators = 200,\n                        max_depth = 5, min_child_weight = 1,\n                        gamma = 0 , subsample = 0.8,\n                        colsample_bytree = 0.8,\n                        objective = \"reg:squarederror\",\n                        seed = 10)\n\nxgb_model.fit(X_train , y_train)","9dd77d46":"predictions = xgb_model.predict(X_test)\npredictions[:10]","39e40e1f":"result[\"target\"] = predictions","196ceee6":"result.head()","e9285c1f":"# make submission\n\nresult.to_csv(\"submission.csv\" , index = False)","c9e07cf0":"## Predictions","8b9ee769":"## Import Libraries","b344419d":"# CommonLit Readability Price : Simple Way"}}