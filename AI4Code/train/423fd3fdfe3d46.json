{"cell_type":{"1452cb53":"code","dac2ea19":"code","b3ede5ba":"code","7a019ee5":"code","b2be0a61":"code","07d55ff5":"code","fb446a73":"code","26c3b10e":"code","200e7971":"markdown","49af8277":"markdown","e6782d99":"markdown","a9b1dcbd":"markdown","c90e280c":"markdown","fe9e90e4":"markdown","b1e79f17":"markdown","69d8f677":"markdown","5a222bd2":"markdown","714ba863":"markdown"},"source":{"1452cb53":"!pip install visdom","dac2ea19":"!git clone https:\/\/github.com\/GMvandeVen\/class-incremental-learning\n%cd class-incremental-learning","b3ede5ba":"!python preprocess_core50.py","7a019ee5":"#!.\/main_generative.py --iters 30 --batch 128 --experiment MNIST","b2be0a61":"# DGR\n!.\/main_cl.py --replay=generative --experiment MNIST","07d55ff5":"# LDA\n!.\/main_cl.py --slda --experiment MNIST","fb446a73":"# Generative classifier\n!.\/main_generative.py --experiment MNIST --iters 30 --batch 128","26c3b10e":"## the following runs exceed 9 hours of kaggle limitation !\n#!.\/compare_all.py --experiment=MNIST --n-seeds=10 --seed=11 --c=1000 --lambda=1000000. --omega-max=0.01 --ar1-c=10\n#!.\/compare_all.py --experiment=CIFAR10 --tasks=5 --n-seeds=10 --seed=11 --c=1 --lambda=10 --omega-max=0.1 --ar1-c=100 --conv-type=resNet --fc-layers=1 --iters=5000 --reducing-layers=3 --depth=5 --global-pooling --channels=20 --lr=0.001 --deconv-type=resNet --z-dim=100\n#!.\/compare_all.py --experiment=CIFAR10 --tasks=5 --n-seeds=10 --seed=11 --c=1 --lambda=10 --omega-max=0.1 --ar1-c=100 --conv-type=resNet --fc-layers=1 --iters=5000 --reducing-layers=3 --depth=5 --global-pooling --channels=20 --lr=0.001 --deconv-type=resNet --z-dim=100\n#!.\/compare_all.py --experiment=CIFAR100 --pre-convE --hidden --iters=5000 --n-seeds=10 --seed=11 --c=1. --lambda=100. --omega-max=0.01 --ar1-c=100 --dg-prop=0.7 --bir-c=0.6 --si-dg-prop=100000000\n#!.\/compare_all.py --experiment=CIFAR100 --pre-convE --iters=5000 --n-seeds=10 --seed=11 --c=1. --lambda=100. --omega-max=10. --ar1-c=100 --no-bir\n#!.\/compare_all.py --experiment=CORe50 --n-seeds=10 --seed=11 --single-epochs --batch=1 --fc-layers=2 --z-dim=200 --fc-units=1024 --lr=0.0001 --c=10 --lambda=10 --omega-max=0.1 --ar1-c=1. --dg-prop=0. --bir-c=0.01 --si-dg-prop=0.6","200e7971":"## On-the-fly plots during training\n`python -m visdom.server`\n\nThe visdom server is now alive and can be accessed at http:\/\/localhost:8097 in your browser.\nThe flag `--visdom` should then be added when calling `.\/main_generative.py` or `.\/main_cl.py` to run the experiments with on-the-fly plots.\n\nFor more information on [visdom](https:\/\/github.com\/facebookresearch\/visdom)","49af8277":"### Generative classifier\nIndividual experiments with the VAE-based generative classifier can be run with main_generative.py. The main options for this script are:\n* `--experiment`: which dataset? (`MNIST`|`CIFAR10`|`CIFAR100`|`CORe50`)\n* `--iters`: how many iterations per class?\n* `--batch`: what mini-batch size to use? \n\nFor information on further options: `.\/main_generative.py -h`","e6782d99":"# Class Incremental Learning","a9b1dcbd":"### Final test accuracy of all compared methods on the different benchmarks\n![image.png](attachment:7867c020-7164-4c51-bff4-9331788b0b9b.png)","c90e280c":"## Paper: [Class-Incremental Learning with Generative Classifiers](https:\/\/openaccess.thecvf.com\/content\/CVPR2021W\/CLVision\/papers\/van_de_Ven_Class-Incremental_Learning_With_Generative_Classifiers_CVPRW_2021_paper.pdf)","fe9e90e4":"## Running comparisons from the paper\ncommands.sh\n### run all methods compared against (--> rest of Table 2) ","b1e79f17":"## Running custom experiments","69d8f677":"## Repro [Github](https:\/\/github.com\/GMvandeVen\/class-incremental-learning)","5a222bd2":"## Load & Preprocess CORe50 dataset","714ba863":"### Other class-incremental learning methods\nUsing `main_cl.py`, it is possible to run custom individual experiments with other class-incremental learrning methods. It is also possible to combine some of the methods together. The main options for this script are:\n* `--experiment`: which dataset? (`MNIST`|`CIFAR10`|`CIFAR100`|`CORe50`)\n* `--tasks`: how many tasks?\n* `--iters`: how many iterations per task? \n* `--batch`: what mini-batch size to use?\n\nTo run specific methods, the following can be used:\n* **Synaptic intelligenc (SI):** `.\/main_cl.py --si --c=0.1`\n* **Elastic weight consolidation (EWC):** `.\/main_cl.py --ewc --lambda=5000`\n* **Deep Generative Replay (DGR):** `.\/main_cl.py --replay=generative`\n* **Brain-Inspired Replay (BI-R):** `.\/main_cl.py --replay=generative --brain-inspired`\n* **CopyWeights with Re-init (CWR):** `.\/main_cl.py --cwr --freeze-after-first --freeze-fcE --freeze-convE`\n* **CWR+:** `.\/main_cl.py --cwr-plus --freeze-after-first --freeze-fcE --freeze-convE`\n* **AR1:** `.\/main_cl.py --cwr-plus --si --reg-only-hidden --c=0.1 --omega-max=0.1`\n* **The 'labels trick':** `.\/main_cl.py --neg-samples=current`\n* **Streaming LDA:** `.\/main_cl.py --slda`\n\nTo information on further options: `.\/main_cl.py -h`"}}