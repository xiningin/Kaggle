{"cell_type":{"78e4655e":"code","f460dc4b":"code","c3930f86":"code","65f8b388":"code","6cb6b26d":"code","bb0fcc96":"code","67b93df0":"code","6faa2adc":"markdown","f7ba9c1b":"markdown"},"source":{"78e4655e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nwarnings.filterwarnings('ignore')\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f460dc4b":"import numpy as np\nimport pandas as pd\nimport cv2\nfrom PIL import Image\nimport scipy\n\nimport tensorflow as tf\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.losses import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras.preprocessing.image import *\nfrom tensorflow.keras.utils import *\n# import pydot\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import *\nfrom sklearn.model_selection import *\nimport tensorflow.keras.backend as K\n\nfrom tqdm import tqdm, tqdm_notebook\nfrom colorama import Fore\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom glob import glob\nfrom skimage.io import *\n%config Completer.use_jedi = False\nimport time\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nimport lightgbm as lgb\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.neighbors import *\nprint(\"All modules have been imported\")\n","c3930f86":"# Image Augmentation\nno_angles = 10\nurl = '\/kaggle\/input\/mias-mammography\/all-mias\/'\n\ndef save_dictionary(path,data):\n        print('saving catalog...')\n        #open('u.item', encoding=\"utf-8\")\n        import json\n        with open(path,'w') as outfile:\n            json.dump(str(data), fp=outfile)\n        # save to file:\n        print(' catalog saved')\n# train_test_split_datagen=ImageDataGenerator(\"augmentations such as flip,brightness range,etc....\")\n# val_datagen=ImageDataGenerator(\"augmentations such as flip,brightness range,etc....\")\n# test_datagen=ImageDataGenerator(\"augmentations such as flip,brightness range,etc....\")\ndef read_image():\n        print(\"Reading images\")\n        import cv2\n        info = {}\n        for i in range(322):\n            if i<9:\n                image_name='mdb00'+str(i+1)\n            elif i<99:\n                image_name='mdb0'+str(i+1)\n            else:\n                image_name = 'mdb' + str(i+1)\n            image_address= url+image_name+'.pgm'\n            img = cv2.imread(image_address,1)\n            img = cv2.resize(img, (224,224))\n            rows, cols,channel = img.shape\n            info[image_name]={}\n            for angle in range(0,no_angles,8):\n                M = cv2.getRotationMatrix2D((cols \/ 2, rows \/ 2), angle, 1) \n                img_rotated = cv2.warpAffine(img, M, (cols, rows))\n                info[image_name][angle]=img_rotated\n        return (info)\nimport os #Operating System\nimport sys #System\n# train_generator = train_datagen.flow(x_train, y_train, batch_size =)\n# val_generator = val_datagen.flow(x_val, y_val, batch_size = 64)\n# test_generator=test_datagen.flow(x_test,y_test,batch_size = 64)\n\ndef get_script_path():\n    return os.path.dirname(os.path.realpath(sys.argv[0]))    \n\ndef read_lable():\n    filename = url+'Info.txt'\n    text_all = open(filename).read()\n    #print(text_all)\n    lines=text_all.split('\\n')\n    info={}\n    for line in lines:\n        words=line.split(' ')\n        if len(words)>1:\n            if (words[1] == 'G'):\n                info[words[0]] = {}\n                for angle in range(no_angles):\n                    info[words[0]][angle] = 2\n            if (words[1] == 'D'):\n                info[words[0]] = {}\n                for  angle in range(no_angles):\n                    info[words[0]][angle] = 1\n            if (words[1] == 'F'):\n                info[words[0]] = {}\n                for  angle in range(no_angles):\n                    info[words[0]][angle] = 0\n            \n    return (info)","65f8b388":"import numpy as np\nlable_info=read_lable()\nimage_info=read_image()\nids=lable_info.keys() \n#del lable_info['Truth-Data:']\nX=[]\nY=[]\nfor id in ids:\n    for angle in range(0,no_angles,8):\n        X.append(image_info[id][angle])\n        Y.append(lable_info[id][angle])\nX=np.array(X)\nY=np.array(Y)\n#Y=to_categorical(Y,3)\nx_train, x_test1, y_train, y_test1 = train_test_split(X, Y, test_size=0.3, random_state=42)\nx_val, x_test, y_val, y_test = train_test_split(x_test1, y_test1, test_size=0.3, random_state=42)\nprint(len(x_train),len(x_val),len(x_test))","6cb6b26d":"base_model= ResNet50(input_shape=(224,224,3), weights='imagenet', include_top=False)\nx = base_model.output\nx = Dropout(0.5)(x)\nx = Flatten()(x)\nx = BatchNormalization()(x)\nx = Dense(16,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = Dropout(0.5)(x)\npredictions = Dense(3, activation='softmax')(x)\n\nmodel_feat = Model(inputs=base_model.input,outputs=predictions)\n\ntrain_features = model_feat.predict(x_train)\nval_features=model_feat.predict(x_val)\ntest_features=model_feat.predict(x_test)\n\n# nca=NeighborhoodComponentsAnalysis(random_state=42,n_components=0.99)\n\n# train_features=pca.fit_transform(train_features)\n# val_features=pca.transform(val_features)\n# test_features=pca.transform(test_features)\n\n","bb0fcc96":"from xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nrf=RandomForestClassifier()\nxgb=XGBClassifier(objective='mlogloss',eval_metric='mlogloss',use_label_encoder=False)\nknn=KNeighborsClassifier(n_neighbors=3)\nlgbm=LGBMClassifier()\nabc=AdaBoostClassifier()\nsv=SVC()\n\nprint('---------------------------NCA Report------------------------------')\nnca=NeighborhoodComponentsAnalysis(random_state=42,n_components=3)\n\nprint(' ')\nprint('-----------Performance of NCA-KNN Classifier-------------------')\nnca.fit(train_features,y_train)\nknn.fit(nca.transform(train_features), y_train)\nacc_knn_val = knn.score(nca.transform(val_features), y_val)\nacc_knn_test = knn.score(nca.transform(test_features), y_test)\nprint('Validation accuracy :{}'.format(acc_knn_val))\nprint('Test accuracy :{}'.format(acc_knn_test))\nprint(' ')\n\nprint('-----------Performance of NCA-XGBBOST Classifier-------------------')\nnca.fit(train_features,y_train)\nxgb.fit(nca.transform(train_features), y_train)\nacc_xgb_val = xgb.score(nca.transform(val_features), y_val)\nacc_xgb_test = xgb.score(nca.transform(test_features), y_test)\nprint('Validation accuracy :{}'.format(acc_xgb_val))\nprint('Test accuracy :{}'.format(acc_xgb_test))\nprint(' ')\n\nprint('-----------Performance of NCA-Random Forest Classifier-------------------')\nnca.fit(train_features,y_train)\nrf.fit(nca.transform(train_features), y_train)\nacc_rf_val = rf.score(nca.transform(val_features), y_val)\nacc_rf_test = rf.score(nca.transform(test_features), y_test)\nprint('Validation accuracy :{}'.format(acc_rf_val))\nprint('Test accuracy :{}'.format(acc_rf_test))\nprint(' ')\n\nprint('-----------Performance of NCA-AdaBoost Classifier-------------------')\nnca.fit(train_features,y_train)\nabc.fit(nca.transform(train_features), y_train)\nacc_abc_val = abc.score(nca.transform(val_features), y_val)\nacc_abc_test = abc.score(nca.transform(test_features), y_test)\nprint('Validation accuracy :{}'.format(acc_abc_val))\nprint('Test accuracy :{}'.format(acc_abc_test))\nprint(' ')\n\nprint('-----------Performance of NCA-LightGBM Classifier-------------------')\nnca.fit(train_features,y_train)\nlgbm.fit(nca.transform(train_features), y_train)\nacc_lgb_val = lgbm.score(nca.transform(val_features), y_val)\nacc_lgb_test = lgbm.score(nca.transform(test_features), y_test)\nprint('Validation accuracy :{}'.format(acc_lgb_val))\nprint('Test accuracy :{}'.format(acc_lgb_test))\nprint(' ')\n\nprint('-----------Performance of NCA-SVC Classifier-------------------')\nnca.fit(train_features,y_train)\nsv.fit(nca.transform(train_features), y_train)\nacc_svc_val = sv.score(nca.transform(val_features), y_val)\nacc_svc_test = sv.score(nca.transform(test_features), y_test)\n\nprint('Validation accuracy :{}'.format(acc_svc_val))\nprint('Test accuracy :{}'.format(acc_svc_test))\n\n\n\n","67b93df0":"from mlxtend.plotting import plot_decision_regions\nfrom sklearn.decomposition import *\ndef knn_comparison(data1,data2, k):\n x = data1\n y = data2\n pca=PCA(n_components=2,random_state=42)\n x=pca.fit_transform(x)\n clf =KNeighborsClassifier(n_neighbors=k)\n clf.fit(x, y)\n# Plotting decision region\n plot_decision_regions(x, y, clf=clf, legend=2)\n# Adding axes annotations\n plt.title(\"Knn with K=\"+ str(k))\n plt.show()\nfor i in [1,3,5,10,20,30,40,80]:\n    knn_comparison(train_features,y_train, i)","6faa2adc":"# Using PCA and reducing dimensionality to 2 Components","f7ba9c1b":"# Applying NCA on features extracted from ResNet50 and using Standard Classifiers"}}