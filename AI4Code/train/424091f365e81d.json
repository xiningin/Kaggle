{"cell_type":{"6eb17b77":"code","f4dcb738":"code","1a676569":"code","71310738":"code","e2a6e4ee":"code","9ba5a351":"code","4d54239a":"code","37d478c5":"code","aabc2b4c":"code","e86c65f3":"code","b4582948":"code","cca23864":"code","9c2d42ce":"code","e1d5dedb":"code","77e99b32":"code","dafba9df":"code","8c254d69":"code","39950223":"code","89fa1950":"code","bacd847a":"code","099114c8":"code","327df363":"code","7e4c11ac":"code","a30e5fe5":"code","bebcbc5e":"code","ed57699b":"code","c9140056":"code","2ce3c501":"code","0a0914d6":"code","e62c5df1":"code","e8effaf9":"code","7fdfa01d":"code","53d22ecc":"code","b94bd258":"code","dfb039ad":"code","09d7f330":"code","fbc4359d":"code","ad992cd2":"code","e801ebfd":"code","2c6ce792":"code","e3b10435":"code","92093e30":"code","e4c435db":"code","bdf2e506":"code","40221ae3":"code","5b6773fd":"code","834d6915":"code","d93a00c4":"code","ddb31079":"markdown","1cf7572b":"markdown","b7971483":"markdown","2439f948":"markdown","eb4b5b0d":"markdown","a585b030":"markdown","8d5d3fe1":"markdown","b8b47f52":"markdown","7f2ffc56":"markdown","5419b3dd":"markdown","b1f1ec7c":"markdown","d32853f8":"markdown","c52d57c8":"markdown","eb046e4c":"markdown"},"source":{"6eb17b77":"# Supress Warnings\n\nimport warnings\nwarnings.filterwarnings('ignore')","f4dcb738":"import numpy as np\nimport pandas as pd","1a676569":"housing = pd.read_csv(r'\/kaggle\/input\/housing-simple-regression\/Housing.csv')","71310738":"# Check the head of the dataset\nhousing.head()","e2a6e4ee":"housing.shape","9ba5a351":"housing.info()","4d54239a":"housing.describe()","37d478c5":"import matplotlib.pyplot as plt\nimport seaborn as sns","aabc2b4c":"sns.pairplot(housing)\nplt.show()","e86c65f3":"plt.figure(figsize=(20, 12))\nplt.subplot(2,3,1)\nsns.violinplot(x = 'mainroad', y = 'price', data = housing)\nplt.subplot(2,3,2)\nsns.violinplot(x = 'guestroom', y = 'price', data = housing)\nplt.subplot(2,3,3)\nsns.violinplot(x = 'basement', y = 'price', data = housing)\nplt.subplot(2,3,4)\nsns.violinplot(x = 'hotwaterheating', y = 'price', data = housing)\nplt.subplot(2,3,5)\nsns.violinplot(x = 'airconditioning', y = 'price', data = housing)\nplt.subplot(2,3,6)\nsns.violinplot(x = 'furnishingstatus', y = 'price', data = housing)\nplt.show()","b4582948":"plt.figure(figsize = (10, 5))\nsns.violinplot(x = 'furnishingstatus', y = 'price', hue = 'airconditioning', data = housing)\nplt.show()","cca23864":"# List of variables to map\n\nvarlist =  ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n\n# Defining the map function\ndef binary_map(x):\n    return x.map({'yes': 1, \"no\": 0})\n\n# Applying the function to the housing list\nhousing[varlist] = housing[varlist].apply(binary_map)","9c2d42ce":"# Check the housing dataframe now\n\nhousing.head()","e1d5dedb":"# Get the dummy variables for the feature 'furnishingstatus' and store it in a new variable - 'status'\nstatus = pd.get_dummies(housing['furnishingstatus'])","77e99b32":"# Check what the dataset 'status' looks like\nstatus.head()","dafba9df":"# Let's drop the first column from status df using 'drop_first = True'\n\nstatus = pd.get_dummies(housing['furnishingstatus'], drop_first = True)","8c254d69":"# Add the results to the original housing dataframe\n\nhousing = pd.concat([housing, status], axis = 1)","39950223":"# Now let's see the head of our dataframe.\n\nhousing.head()","89fa1950":"# Drop 'furnishingstatus' as we have created the dummies for it\n\nhousing.drop(['furnishingstatus'], axis = 1, inplace = True)","bacd847a":"housing.head()","099114c8":"from sklearn.model_selection import train_test_split\n\n# We specify this so that the train and test data set always have the same rows, respectively\nnp.random.seed(0)\ndf_train, df_test = train_test_split(housing, train_size = 0.75, random_state = 100)","327df363":"from sklearn.ensemble import RandomForestRegressor","7e4c11ac":"rf = RandomForestRegressor(random_state=42)","a30e5fe5":"df_train.shape","bebcbc5e":" df_test.shape","ed57699b":"df_test.head()","c9140056":"y_train = df_train.pop(\"price\")\nX_train = df_train\nX_train.shape","2ce3c501":"y_test = df_test.pop(\"price\")\nX_test = df_test\nX_test.shape","0a0914d6":"rf.fit(X_train, y_train)","e62c5df1":"from sklearn import tree\nfor i in range(5):\n    sample_tree = rf.estimators_[i]\n    fig = plt.figure(figsize=(25,20))\n    _ = tree.plot_tree(sample_tree,\n                   feature_names=X_train.columns,\n                   filled=True)","e8effaf9":"from sklearn.metrics import r2_score","7fdfa01d":"r2_score_rf_train=round(r2_score(y_train, rf.predict(X_train)),2)\nprint(\"R-squared Train:\",r2_score_rf_train)","53d22ecc":"r2_score_rf_test=round(r2_score(y_test, rf.predict(X_test)),2)\nprint(\"R-squared Test:\",r2_score_rf_test)","b94bd258":"rf.feature_importances_","dfb039ad":"imp_df = pd.DataFrame({\n    \"Varname\": X_train.columns,\n    \"Imp\": rf.feature_importances_})","09d7f330":"imp_df.sort_values(by=\"Imp\", ascending=False)","fbc4359d":"from sklearn.model_selection import GridSearchCV","ad992cd2":"params = {\n    'max_depth': [2,3,5,10,20],\n    'min_samples_leaf': [5,10,20,50,100,200],\n    'n_estimators': [10, 25, 50, 100]\n}","e801ebfd":"grid_search = GridSearchCV(estimator=rf,\n                           param_grid=params,\n                           cv=4,\n                           n_jobs=-1, verbose=1)","2c6ce792":"%%time\ngrid_search.fit(X_train, y_train)","e3b10435":"grid_search.best_score_","92093e30":"rf_best = grid_search.best_estimator_\nrf_best","e4c435db":"from sklearn import tree\nfor i in range(5):\n    sample_tree = rf_best.estimators_[i]\n    fig = plt.figure(figsize=(25,20))\n    _ = tree.plot_tree(sample_tree,\n                   feature_names=X_train.columns,\n                   filled=True)","bdf2e506":"r2_score_rf_train=round(r2_score(y_train,rf_best.predict(X_train)),2)\nprint(\"R-squared Train:\",r2_score_rf_train)","40221ae3":"r2_score_rf_test=round(r2_score(y_test, rf_best.predict(X_test)),2)\nprint(\"R-squared Test:\",r2_score_rf_test)","5b6773fd":"rf_best.feature_importances_","834d6915":"imp_df = pd.DataFrame({\n    \"Varname\": X_train.columns,\n    \"Imp\": rf_best.feature_importances_})","d93a00c4":"imp_df.sort_values(by=\"Imp\", ascending=False)","ddb31079":"Now, you don't need three columns. You can drop the `furnished` column, as the type of furnishing can be identified with just the last two columns where \u2014 \n- `00` will correspond to `furnished`\n- `01` will correspond to `unfurnished`\n- `10` will correspond to `semi-furnished`","1cf7572b":"#### Visualising Numeric Variables\n\nLet's make a pairplot of all the numeric variables","b7971483":"## Step 4: Splitting the Data into Training and Testing Sets\n\nAs you know, the first basic step for regression is performing a train-test split.","2439f948":"- You can see that your dataset has many columns with values as 'Yes' or 'No'.\n\n- But in order to fit a regression line, we would need numerical values and not string. Hence, we need to convert them to 1s and 0s, where 1 is a 'Yes' and 0 is a 'No'.","eb4b5b0d":"Inspect the various aspects of the housing dataframe","a585b030":"## Step 3: Data Preparation","8d5d3fe1":"## Step 2: Visualising the Data\n\nLet's now spend some time doing what is arguably the most important step - **understanding the data**.\n- If there is some obvious multicollinearity going on, this is the first place to catch it\n- Here's where you'll also identify if some predictors directly have a strong association with the outcome variable\n\nWe'll visualise our data using `matplotlib` and `seaborn`.","b8b47f52":"We can also visualise some of these categorical features parallely by using the `hue` argument. Below is the plot for `furnishingstatus` with `airconditioning` as the hue.","7f2ffc56":"Following Features which can be used focus to predict Housing Price keeping best R2 values for test & train:\n- area\n- bathrooms\n- airconditioning\n- prefarea\n- parking\n","5419b3dd":"### Dummy Variables","b1f1ec7c":"The variable `furnishingstatus` has three levels. We need to convert these levels into integer as well. \n\nFor this, we will use something called `dummy variables`.","d32853f8":"Any 5 Decison Trees used in the equation","c52d57c8":"## Step 1: Reading and Understanding the Data\n\nLet us first import NumPy and Pandas and read the housing dataset","eb046e4c":"#### Visualising Categorical Variables\n\nAs you might have noticed, there are a few categorical variables as well. Let's make a boxplot for some of these variables."}}