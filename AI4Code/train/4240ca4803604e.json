{"cell_type":{"4ef1796c":"code","b0851d7f":"code","497a88b9":"code","5138f0ca":"code","5bb5b450":"code","6cfc9a38":"code","41e0074f":"code","7971853b":"code","855ef000":"markdown","5a27caa3":"markdown","4b3c96de":"markdown","013468c5":"markdown","09f2de76":"markdown","2e29d195":"markdown","9b904ca7":"markdown","ce05bf23":"markdown"},"source":{"4ef1796c":"import numpy as np \nimport pandas as pd \n\ntrain = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/tabular-playground-series-apr-2021\/sample_submission.csv')","b0851d7f":"# Combine train and test\ntest['Survived'] = -1\nall_data = pd.concat([train, test])\n\n# Fill 'Age', 'Embarked'\nfor col in ['Age']:\n    all_data[col] = all_data[col].fillna(all_data[col].mean())\n    \nfor col in ['Embarked']:\n    all_data[col] = all_data[col].fillna('X') \n\n# Fill 'Fare'\nall_data['Fare'] = all_data.groupby('Pclass')['Fare'].transform(lambda x: x.fillna(x.mean()))\n    \n# New feature 'Cabin_filled', drop 'Cabin'\nall_data['Cabin_type'] = all_data['Cabin'].fillna('X').map(lambda x: x[0].split()[0])    \nall_data.drop('Cabin', axis = 1, inplace = True)\n\n# New feature 'Ticket_type', drop 'Ticket'\nimport re\n\ndef fn1(x):\n    if isinstance(x, str):\n        if len(re.findall(\"^\\d+$\", x))>0:\n            return 'type1'\n        if len(re.findall(\"^(A\\.|A\/S|A\/5|A\/4|AQ\/4|AQ\/3|A4)\", x))>0:\n            return 'type2'\n        if len(re.findall(\"^(C|CA|CA\\.|C\\.A\\.)\", x))>0:\n            return 'type3'\n        if len(re.findall(\"^(SC|S\\.C\\.|SC\/PARIS|S\\.C\\.\/PARIS|SC\/Paris|SC\/AH|S\\.C\\.\/A\\.4)\", x))>0:\n            return 'type4'\n        if len(re.findall(\"^(PC|PP|P\\.P|P\/PP)\", x))>0:\n            return 'type5'\n        if len(re.findall(\"^(W\\.C\\.|W.\/C\\.|W\/C)\", x))>0:\n            return 'type6'\n        if len(re.findall(\"^(SOTON\/O\\.Q|SOTON\/OQ|STON\/O|STON\/O2|SOTON\/O2)\", x))>0:\n            return 'type7'\n        if len(re.findall(\"^(WE\/P|W\\.E\\.P)\", x))>0:\n            return 'type8'\n        if len(re.findall(\"^(F\\.C|F\\.C\\.C|Fa)\", x))>0:\n            return 'type9'\n        if len(re.findall(\"^(LP)\", x))>0:\n            return 'type10'\n        if len(re.findall(\"^(S\\.O\\.C|S\\.P|S\\.O|P\\.P|SO\/C)\", x))>0:\n            return 'type11'\n        if len(re.findall(\"^(S\\.W\\.\/PP|SW\/PP)\", x))>0:\n            return 'type12'\n        \n        else:\n            return x\n    else:\n        return 'type1'\n    \nall_data['Ticket_type'] = all_data['Ticket'].apply(lambda x: fn1(x))\nall_data.drop('Ticket', axis = 1, inplace = True)\n\n# New feature 'total_members', drop 'SibSp' and 'Parch'\nall_data['total_members'] = all_data['SibSp'] + all_data['Parch'] + 1\nall_data.drop(['SibSp', 'Parch'], axis = 1, inplace = True)\n\n# drop 'Name' and 'PassengerId'\nall_data.drop(['Name', 'PassengerId'], axis = 1, inplace = True)\n\n# Check missing values\nprint(\"% Missing values in each column :\")\nprint(all_data.isnull().sum()\/len(train)*100)\n\n# Get the categorical columns\ncols = [col for col in all_data.columns if all_data[col].dtype == 'object']\n\n# One-hot-encode\nall_data = pd.get_dummies(all_data, drop_first = True)\n\n# all_data --> train, test\nn_train = len(train)\ntrain = all_data.iloc[:n_train].copy()   # This will create copy of the df. Done to avoid future warnings\ntest = all_data.iloc[n_train:].copy()\n\n# Remove 'Survived' column from test data\ntest.drop('Survived', axis = 1,inplace = True)","497a88b9":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n\n\nmodels = [\n          LogisticRegression(solver = 'liblinear', random_state = 42), \n          RidgeClassifier(random_state = 42),\n          SGDClassifier(random_state = 42),\n          DecisionTreeClassifier(random_state = 42),\n          RandomForestClassifier(random_state = 42),\n          ExtraTreesClassifier(random_state = 42),\n          LGBMClassifier(verbose = -1),\n          XGBClassifier(verbosity = 0, use_label_encoder = False),\n          CatBoostClassifier(verbose = 0)\n]\n\nmodel_names = []           #store the names of all the models.\n\nfor model in models:\n    model_names.append(type(model).__name__)\n    print(f\"{type(model).__name__} :- {model}\")","5138f0ca":"# Get the feature and target data\nX = train.drop('Survived', axis = 1)\ny = train['Survived'].copy()","5bb5b450":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nimport joblib\nimport time\n\naccuracy = []  \ntime_taken = []\n\nfor model in models:\n    \n    print(f\"\\nTraining {type(model).__name__} : \")\n       \n    skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n\n    acc = 0\n    \n    start = time.time()\n\n    for fold, (train_idx, valid_idx) in enumerate(skf.split(X, y)):\n        X_train, X_valid = X.iloc[train_idx, :], X.iloc[valid_idx, :]\n        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n        model.fit(X_train.values, y_train)\n        y_pred = model.predict(X_valid.values)\n        acc += accuracy_score(y_valid, y_pred)\n        \n        print(f\"Fold : {fold}, Accuracy : {accuracy_score(y_valid, y_pred)}\")\n        joblib.dump(model, f\"base_{type(model).__name__}_{fold}\")        # save all the models\n    \n    end = time.time()\n    \n    time_taken.append((end-start)\/5)  \n    accuracy.append(acc\/5*100)                # get the average accuracy of 5 folds\n    \n    print(f\"Average accuracy : {acc\/5: 0.4f},  Average time taken per fold: {(end-start)\/5: 0.3f} s\")","6cfc9a38":"df = pd.DataFrame()\ndf['Model'] = model_names\ndf['Accuracy'] = accuracy\ndf['Time per fold'] = time_taken\n_ = df.sort_values('Accuracy', ascending = False).reset_index(drop = True)\n_.index+=1\n_","41e0074f":"model_name = model_names[np.argmax(accuracy)]\nprint(f\"Predicting using {model_name}...\")\n\npreds = []\n\nfor fold in range(5):\n    model = joblib.load(f\"base_{model_name}_{fold}\")\n    preds.append(model.predict_proba(test.values)[:, 1])\n\npreds = np.mean(preds, axis = 0)    # Average probabilities of 5 models\ny_pred = np.where(preds>0.5, 1, 0)  # Predictions\n\nprint(\"Predictions saved.\")","7971853b":"submission.loc[:, 'Survived'] = y_pred\nsubmission.to_csv('submission_base_models.csv', index = False)\npd.read_csv(\"submission_base_models.csv\")","855ef000":"<a id='tag4'><\/a>\n## 4) [Print accuracy values](#content-table)\n- Print accuracy values in descending order","5a27caa3":"<a id='tag2'><\/a>\n## 2) [Define all the models to test](#content-table)\n\n- Import libraries\n- Create a list of models","4b3c96de":"______________","013468c5":"<a id='tag1'><\/a>\n## 1) [Fill Missing values, EDA and FE](#content-table)\n\n- All missing values filled\n- Created 3 new features : 'Cabin_type', 'Ticket_type', 'total_member'\n- Dropped 6 features : 'Cabin', 'Ticket', 'SibSp', 'Parch', 'Name', 'PassengerId'\n- One hot encoding ","09f2de76":"______________________\n# Summary\n- **Test different models for their base score and select best model for further optimization**\n\n*Note : To understand Preprocessing, EDA and Feature Engeering done in this notebook : [EDA & FE](https:\/\/www.kaggle.com\/abhinavnayak\/eda-4-insights-fe-2-new-features)*\n\n<a id='content-table'><\/a>\n## Table of Contents\n1. [Fill Missing values, EDA and FE](#tag1)\n2. [Define all the models to test](#tag2)   \n3. [Using 5-fold cross validation to get accuracy scores](#tag3)      \n4. [Print accuracy values](#tag4)\n5. [Use best model to predict on test data](#tag5)\n6. [Submit your prediction](#tag6)","2e29d195":"<a id='tag6'><\/a>\n## 5) [Submit your prediction](#content-table)","9b904ca7":"<a id='tag3'><\/a>\n## 3. [Using 5-fold cross validation to get accuracy scores](#content-table)\n- Use stratified k fold to train and get accuracy score\n- Save all the models in each fold to use later for prediction of test data","ce05bf23":"<a id='tag5'><\/a>\n## 5) [Use best model to predict on test data](#content-table)\n- Load the best model \n- Predict on test data"}}