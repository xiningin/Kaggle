{"cell_type":{"daa5f2b1":"code","e98935e9":"code","b1a39e4a":"code","79980b45":"code","22b7a11e":"code","2697cf83":"code","05e974a6":"code","17b00177":"code","0b9ac3fe":"code","10e96c3d":"code","ccb471b8":"code","4f67bc86":"code","5bff3230":"code","d0b04a01":"code","3c17d436":"code","7a83fea7":"code","788eaa62":"code","2e503f63":"code","b346f3d0":"code","a193f378":"code","1173dd66":"code","4ce76019":"code","4d75a464":"code","e6ad98b1":"code","a54b146c":"code","a889631c":"code","eae5aed6":"code","d0e3c00e":"code","52ec47e3":"code","e830c0df":"code","55a1d4b6":"code","b6b3f138":"code","9909ea96":"code","b0cba01a":"code","c1d154c1":"code","4db7368c":"code","9f75f889":"code","f03caf5c":"code","78c5d858":"code","b727214f":"code","f71d09a6":"code","9c5403e0":"code","a1c8674c":"code","bcfb6891":"code","b43995ad":"code","2af4d5b4":"code","ef8cb258":"code","6ba15d3a":"code","52465a53":"code","e615fbb5":"code","a0f2c966":"code","406e5039":"code","e632a6d9":"code","fa27551f":"code","ca2b2917":"code","1dfc80ac":"code","a918460b":"code","b8baaf12":"code","c83c42dd":"code","f43efa5d":"code","ac66fc17":"code","83763578":"code","ce7506db":"code","a4172b64":"code","ebbcdcce":"code","0d29f99b":"code","81e648c7":"code","9321236f":"code","4951f812":"code","7c31758c":"code","eac79e5c":"code","6ef75444":"code","d436a555":"code","677f8d9d":"code","60ebbe4d":"code","55748161":"code","585aed87":"code","0e9249f2":"code","8699bdd0":"code","fdd697c2":"code","d45ca42f":"code","4fcfc04f":"code","02000b67":"code","da160d54":"code","0679cdd3":"code","9caf0d73":"code","0baac612":"code","734146a5":"code","81a3da32":"code","df6d1d48":"code","0afc523f":"code","46da6461":"code","3117f868":"code","dff73705":"code","077e8420":"code","a1b5e5c6":"code","1d8a39ca":"code","5844aa06":"code","3ad18275":"code","1a31878d":"code","50e30ab9":"code","8dbee031":"code","a20839e1":"code","633aec59":"code","914f9ef2":"code","3fe61669":"code","84ca60f6":"code","8efadb97":"code","553d7c9f":"code","4e4fbc30":"code","b1a7daeb":"code","c3bed8b2":"code","d740e701":"code","fa9ffbaa":"markdown","876da88d":"markdown","ce940d39":"markdown","b51e403a":"markdown","7bae1e8d":"markdown","d5e70ecc":"markdown","b827b8b7":"markdown","997f3428":"markdown","f1ef333f":"markdown","9ec429c1":"markdown","ce875784":"markdown","fec95a54":"markdown","564b3eb2":"markdown","27321195":"markdown","e75d135c":"markdown","1216322f":"markdown","bca1624e":"markdown","bcb81f6e":"markdown","a973a435":"markdown","f5c3e471":"markdown","139dc962":"markdown","4fa817ca":"markdown","a0d7463b":"markdown","09990c01":"markdown","3d07e89b":"markdown","e5c6b09e":"markdown","6d65bba7":"markdown","1d86758a":"markdown","a5108ee1":"markdown","e1710dcd":"markdown","64443893":"markdown","efbd9da1":"markdown","4a33bbfe":"markdown","6aa222e0":"markdown","90a7c34a":"markdown","314b562c":"markdown","802efb17":"markdown","3ce6a8e4":"markdown","23509d36":"markdown","cffe7e2b":"markdown","aacdd54d":"markdown","eea0d001":"markdown","88dfe543":"markdown","8979dd12":"markdown","639c2ab8":"markdown","fa00e08a":"markdown","65f84a4a":"markdown","f291e3e8":"markdown","2e8c90f3":"markdown","1b72aa7a":"markdown","e521b6f5":"markdown","dcb39402":"markdown","7a478410":"markdown","459787e8":"markdown","6a617b28":"markdown","d5d475e3":"markdown","1ac9c1aa":"markdown","c8c1c900":"markdown","3681fd34":"markdown","73082b71":"markdown","bd31bfd8":"markdown","dfef0665":"markdown","c030ff5a":"markdown","124776bb":"markdown","ed9420cc":"markdown","cd3759fc":"markdown"},"source":{"daa5f2b1":"# Libraries for data loading and manipulation\nimport pandas as pd\nimport numpy as np\nimport json\nimport pickle\n\n\n# Libraries for data visualization and EDA\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('fivethirtyeight')\nimport seaborn as sns\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud, STOPWORDS\n\n\n# Libraries for text preprocessing\nimport re, nltk, spacy, string\nnlp = spacy.load(\"en_core_web_sm\")\n# from subprocess import check_output\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\nfrom sklearn.decomposition import NMF\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\n\n\n# Libraries for machine learning models\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n\n\n# Libraries for evaluating models\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import confusion_matrix, f1_score, classification_report\n","e98935e9":"# Suppress Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","b1a39e4a":"## Set limits for displaying rows and columns\n\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)","79980b45":"# Opening JSON file \nf = open('..\/input\/automatic-ticket-classification-data\/complaints-2021-05-14_08_16.json',)\n  \n# Returns JSON object as a dictionary \ndata = json.load(f)\n\n# Create a dataframe out of dictionary \ndf = pd.json_normalize(data)","22b7a11e":"# Inspect the dataframe to understand the given data\ndf.head()","2697cf83":"# View the dimensions of dataframe\ndf.shape","05e974a6":"# Print the column names\nlist(df.columns)","17b00177":"# View the info of all columns\ndf.info()","0b9ac3fe":"# View statistical info of the numerical column\ndf.describe()","10e96c3d":"# Inspect the number of missing values\ndf.isna().sum(0)","ccb471b8":"# Remove the leading underscores from all column names\ndf.columns = [re.sub('^_', '', col) for col in df.columns]\nlist(df.columns)","4f67bc86":"## Remove 'source' from column names beginning with 'source.'\ndf.columns = [re.sub(r\"^\\bsource\\b\\.\", \"\", col) for col in df.columns]\nlist(df.columns)","5bff3230":"# View dataframe with corrected column names\ndf.head()","d0b04a01":"# Counting number of rows with blank under complaints column \nlen(df[df['complaint_what_happened'] == \"\"])","3c17d436":"# Assign nan in place of blanks in the complaints column\ndf['complaint_what_happened'].replace(\"\", np.nan, inplace=True)\n\n#Remove all rows where complaints column is nan\ndf.dropna(subset=['complaint_what_happened'], inplace=True)\n\n# Again counting number of rows with blank under complaints column \nlen(df[df['complaint_what_happened'] == \"\"])","7a83fea7":"## View the shape of modified dataframe\ndf.shape","788eaa62":"## View first five rows of complaint column\ndf['complaint_what_happened'].head()","2e503f63":"# Function here to clean the text and remove all the unnecessary elements.\ndef clean_text(text):\n    '''This function \n        - makes the given text lowercase\n        - removes text in square brackets\n        - removes punctuation and \n        - removes words containing numbers.\n    :param text: text to be cleaned\n    :return: cleaned text\n    '''\n    \n    # Make the text lowercase\n    text = text.lower()\n    \n    # Remove text in square brackets\n    text = re.sub(r'\\[.*?\\]', '', text)\n    \n    # Remove punctuation\n    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)\n    \n    # Remove words containing numbers\n    text = re.sub(r'\\w*\\d\\w*', '', text)\n    \n    return text","b346f3d0":"# Apply the above function to complaint column and make a new dataframe containing text-cleaned complaints\ndf_clean = pd.DataFrame(df['complaint_what_happened'].apply(lambda x: clean_text(x)))\n\n# View first five rows of text-cleaned dataframe\ndf_clean.head()","a193f378":"#Write your function to Lemmatize the texts\ndef lemmatizer(text):     \n    \"\"\"\n    This function lemmatizes the given input text.\n    :param text: given text\n    :return: lemmatized text\n    \"\"\"\n    \n    # Initialize empty list to store lemmas\n    sent = []\n    \n    # Extract lemmas of given text and add to the list 'sent'\n    doc = nlp(text)\n    for word in doc:\n        sent.append(word.lemma_)\n        \n    # return string converted form of the list of lemmas\n    return \" \".join(sent)","1173dd66":"# Add a column for lemmatized complaints to the dataframe\ndf_clean[\"lemmatized_complaint\"] =  df_clean.apply(lambda x: lemmatizer(x['complaint_what_happened']), axis=1)\n\n# View the dataframe\ndf_clean.head()","4ce76019":"# Extract singular nouns\ndef get_singular_nouns(text):\n    \"\"\"\n    This function extracts the singular nouns from given text\n    :param: input text\n    :return: extracted nouns from the input text\n    \"\"\"\n    \n    # Create a textblob object\n    blob = TextBlob(text)\n    \n    # extract words with tags 'NN', join them and return\n    return ' '.join([ word for (word,tag) in blob.tags if tag == \"NN\"])\n\n# Apply the function to create a new column containing only singular nouns \n# We don't have plural nouns as the text is already lemmatized\ndf_clean[\"complaint_POS_removed\"] =  df_clean.apply(lambda x: get_singular_nouns(x['lemmatized_complaint']), axis=1)\n\n# View the dataframe\ndf_clean.head()","4d75a464":"# Create list of lengths of pre-processed complaints\ndoc_lens = [len(d) for d in df_clean['complaint_POS_removed']]\ndoc_lens[:5]","e6ad98b1":"# Plot the data according to character length of complaints\nplt.figure(figsize=(10,6))\nplt.hist(doc_lens, edgecolor='black', bins = 50)\nplt.title('Distribution of Complaint character length', fontsize=25)\nplt.ylabel('Number of Complaint', fontsize=20)\nplt.xlabel('Complaint character length', fontsize=20)\nsns.despine()\nplt.show()","a54b146c":"#Using a word cloud, we plot the top 40 words by frequency among all the articles after processing the text\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(\n                          background_color='lemonchiffon',\n                          stopwords=stopwords,\n                          max_words=40,\n                          max_font_size=40, \n                          random_state=42\n                         ).generate(str(df_clean['complaint_POS_removed']))\n\nfig = plt.figure(figsize=(20,15))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","a889631c":"#Removing -PRON- from the text corpus\ndf_clean['complaint_POS_removed'] = df_clean['complaint_POS_removed'].str.replace('-PRON-', '')","eae5aed6":"# We now find the top 30 unigram frequency among the complaints in the cleaned dataframe(df_clean). \ndef get_top_n_words(corpus, n=None):\n    \"\"\"\n    This function takes a corpus of words (text) and returns the top n words(unigrams) among the words in the corpus according \n    to their frequency of occurence.\n    :param corpus: input text\n    :param n: number of top words(unigrams) to find\n    :return: list of tuples with two elements each: the word and its frequency\n    \"\"\"\n    vec = CountVectorizer(stop_words='english').fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","d0e3c00e":"# Top 30 unigrams by frequency among all the complaints\ncommon_words = get_top_n_words(df_clean['complaint_POS_removed'].values.astype('U'), 30)\ndf2 = pd.DataFrame(common_words, columns = ['unigram' , 'count'])\n\n# Plot the top 30 unigrams\nplt.figure(figsize=(15,6))\nsns.barplot(x='unigram', y='count', data=df2, palette=\"coolwarm\")\nplt.xticks(rotation=90)\nplt.title(\"Top 30 unigrams in the Complaint text after removing stop words and lemmatization\", fontsize=20)\nplt.show()","52ec47e3":"# View top 10 unigrams\ndf2.head(10)","e830c0df":"# We now find the top 30 bigram frequency among the complaints in the cleaned dataframe(df_clean). \ndef get_top_n_bigram(corpus, n=None):\n    \"\"\"\n    This function takes a corpus of words (text) and returns the top n bigrams among the words in the corpus according \n    to their frequency of occurence.\n    :param corpus: input text\n    :param n: number of top bigrams to find\n    :return: list of tuples with two elements each: the bigram and its frequency\n    \"\"\"\n    vec = CountVectorizer(ngram_range=(2, 2), stop_words='english').fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","55a1d4b6":"# Top 30 bigrams by frequency among all the complaints\ncommon_words = get_top_n_bigram(df_clean['complaint_POS_removed'].values.astype('U'), 30)\ndf3 = pd.DataFrame(common_words, columns = ['bigram' , 'count'])\n\n# Plot the top 30 bigrams\nplt.figure(figsize=(15,6))\nsns.barplot(x='bigram', y='count', data=df3, palette=\"coolwarm\")\nplt.xticks(rotation=90)\nplt.title(\"Top 30 bigrams in the Complaint text after removing stop words and lemmatization\", fontsize=20)\nplt.show()","b6b3f138":"#Print the top 10 words in the bigram frequency\ndf3.head(10)","9909ea96":"# We now find the top 30 trigram frequency among the complaints in the cleaned dataframe(df_clean). \ndef get_top_n_trigram(corpus, n=None):\n    \"\"\"\n    This function takes a corpus of words (text) and returns the top n trigrams among the words in the corpus according \n    to their frequency of occurence.\n    :param corpus: input text\n    :param n: number of top trigrams to find\n    :return: list of tuples with two elements each: the trigram and its frequency\n    \"\"\"\n    vec = CountVectorizer(ngram_range=(3, 3), stop_words='english').fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","b0cba01a":"# Top 30 trigrams by frequency among all the complaints\ncommon_words = get_top_n_trigram(df_clean['complaint_POS_removed'].values.astype('U'), 30)\ndf4 = pd.DataFrame(common_words, columns = ['trigram' , 'count'])\n\n# Plot the top 30 unigrams\nplt.figure(figsize=(15,6))\nsns.barplot(x='trigram', y='count', data=df4, palette=\"coolwarm\")\nplt.xticks(rotation=90)\nplt.title(\"Top 30 trigrams in the Complaint text after removing stop words and lemmatization\", fontsize=20)\nplt.show()","c1d154c1":"# Print the top 10 words in the trigram frequency\ndf4.head(10)","4db7368c":"# Remove masks 'xxxx' from complaints\ndf_clean['complaint_POS_removed'] = df_clean['complaint_POS_removed'].str.replace('xxxx','')","9f75f889":"# View final pre-processed data\ndf_clean.head()","f03caf5c":"# Initialize the TfidfVectorizer \ntfidf = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')","78c5d858":"# Create the Document Term Matrix by transforming the complaints column present in df_clean.\ndtm = tfidf.fit_transform(df_clean['complaint_POS_removed'])","b727214f":"# Use Coherence model to find best number of topics\nfrom gensim.corpora.dictionary import Dictionary\nfrom gensim.models.nmf import Nmf\nfrom gensim.models.coherencemodel import CoherenceModel\nfrom operator import itemgetter\n\n# Use Gensim's NMF to get the best num of topics via coherence score\ntexts = df_clean['complaint_POS_removed']\ndataset = [d.split() for d in texts]\n\n# Create a dictionary\n# In gensim a dictionary is a mapping between words and their integer id\ndictionary = Dictionary(dataset)\n\n# Filter out extremes to limit the number of features\ndictionary.filter_extremes(\n    no_below=3,\n    no_above=0.85,\n    keep_n=5000\n)\n\n# Create the bag-of-words format (list of (token_id, token_count))\ncorpus = [dictionary.doc2bow(text) for text in dataset]\n\n# Create a list of the topic numbers we want to try\ntopic_nums = list(np.arange(5, 10, 1))\n\n# Run the nmf model and calculate the coherence score\n# for each number of topics\ncoherence_scores = []\n\nfor num in topic_nums:\n    nmf = Nmf(\n        corpus=corpus,\n        num_topics=num,\n        id2word=dictionary,\n        chunksize=2000,\n        passes=5,\n        kappa=.1,\n        minimum_probability=0.01,\n        w_max_iter=300,\n        w_stop_condition=0.0001,\n        h_max_iter=100,\n        h_stop_condition=0.001,\n        eval_every=10,\n        normalize=True,\n        random_state=42\n    )\n    \n    # Run the coherence model to get the score\n    cm = CoherenceModel(\n        model=nmf,\n        texts=texts,\n        dictionary=dictionary,\n        coherence='c_v'\n    )\n    \n    coherence_scores.append(round(cm.get_coherence(), 5))\n\n# Get the number of topics with the highest coherence score\nscores = list(zip(topic_nums, coherence_scores))\nbest_num_topics = sorted(scores, key=itemgetter(1), reverse=True)[0][0]\n\nprint(best_num_topics)","f71d09a6":"# Load nmf_model with the n_components set to 5\nnmf_model = NMF(n_components=5, random_state=40)","9c5403e0":"# Fit the model on document term matrix\nnmf_model.fit(dtm)\n\n# View the number of features\nlen(tfidf.get_feature_names())","a1c8674c":"# Print the top word of a sample component\nsingle_topic = nmf_model.components_[0]\nsingle_topic.argsort()\ntop_word_indices = single_topic.argsort()[-10:]\nfor index in top_word_indices:\n    print(tfidf.get_feature_names()[index])","bcfb6891":"# Print the Top 15 words for each of the topics\nfor index,topic in enumerate(nmf_model.components_):\n    print(f'THE TOP 15 WORDS FOR TOPIC #{index}')\n    print([tfidf.get_feature_names()[i] for i in topic.argsort()[-15:]])\n    print('\\n')","b43995ad":"# Create the best topic for each complaint in terms of integer value 0,1,2,3 & 4\n\ntopic_results = nmf_model.transform(dtm)\ntopic_results[0].round(2)\ntopic_results[0].argmax()\ntopic_results.argmax(axis=1)","2af4d5b4":"# Create a new 'Topic' column and assign the best topic to each of the complaints\n\ndf_clean['Topic'] = topic_results.argmax(axis=1)\n\n# View the feature matrix\ndf_clean.head()","ef8cb258":"# Print the first 5 Complaint for each of the Topics\ndf_clean5 = df_clean.groupby('Topic').head(5)\n\ndf_clean5.sort_values('Topic')","6ba15d3a":"#Create the dictionary of Topic names and Topics\nTopic_names = {0:\"Bank Account services\",\n               1:\"Credit card or prepaid card\", \n               2:\"Others\",\n               3:\"Theft\/Dispute Reporting\",\n               4:\"Mortgage\/Loan\"}\n\n#Replace Topics with Topic Names\ndf_clean['Topic'] = df_clean['Topic'].map(Topic_names)","52465a53":"# View the feature matrix\ndf_clean.head()","e615fbb5":"# Create the dictionary again of Topic names and Topic numbers\nTopic_names = {\"Bank Account services\":0,\n               \"Credit card or prepaid card\":1,\n               \"Others\":2,\n               \"Theft\/Dispute Reporting\":3,\n               \"Mortgage\/Loan\":4}\n\n# Replace Topic Names with Topic numbers\ndf_clean['Topic'] = df_clean['Topic'].map(Topic_names)\n\n# View the dataframe\ndf_clean.head()","a0f2c966":"# Keep the columns\"complaint_what_happened\" & \"Topic\" only in the new dataframe --> training_data\ntraining_data = df_clean[[\"complaint_what_happened\",\"Topic\"]]\n\n# View the training data\ntraining_data.head()","406e5039":"# View dimensions of training data\ntraining_data.shape","e632a6d9":"# View value counts of the five topics\ntraining_data['Topic'].value_counts()","fa27551f":"# Plot a histogram of classes (i.e. topics)\nsns.histplot(data=training_data, x='Topic')\nplt.title(\"Distribution of Topics\", fontsize=20)\nplt.show()","ca2b2917":"# Get the Vector count\ncount_vect = CountVectorizer()\nX_train_counts = count_vect.fit_transform(training_data['complaint_what_happened'])\n","1dfc80ac":"# Save Word Vector\npickle.dump(count_vect.vocabulary_, open(\"count_vector.pkl\",\"wb\"))","a918460b":"# Transform the word vector to tf-idf\ntfidf_transformer = TfidfTransformer()\nX_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)","b8baaf12":"# Save TF-IDF\npickle.dump(tfidf_transformer, open(\"tfidf.pkl\",\"wb\"))","c83c42dd":"# Perform Train-Test split\nX_train, X_test, y_train, y_test = train_test_split(X_train_tfidf, training_data.Topic, test_size=0.25, random_state=42)\n\nprint(f\"Shape of X_train: {X_train.shape}\")\nprint(f\"Shape of y_train: {y_train.shape}\")\nprint(f\"Shape of X_test: {X_test.shape}\")\nprint(f\"Shape of y_test: {y_test.shape}\")","f43efa5d":"# Create a function to evaluate models\ndef eval_model(y_test, y_pred, model_name):\n    \"\"\"\n    This function prints the classification report of a classifier \n    and plots the confusion martrix\n    :param y_test: actual labels\n    :param y_pred: predicted labels\n    :param model_name: the name of the model being evaluated\n    :return: None\n    \"\"\"\n    \n    # print classification report of classifier\n    print(f\"CLASSIFICATION REPORT for {model_name}\\n\")\n    print(classification_report(y_test, y_pred, target_names=[\"Bank Account services\", \"Credit card or prepaid card\", \"Others\", \"Theft\/Dispute Reporting\",\n\"Mortgage\/Loan\"]))\n    \n    # plot confusion matrix of the classifier\n    plt.figure(figsize=(10,6))\n    plt.title(f\"CONFUSION MATRIX for {model_name}\\n\")\n    matrix = confusion_matrix(y_test, y_pred)\n    sns.heatmap(matrix, annot=True, cbar=None, cmap=\"Blues\", fmt='d', xticklabels=[\"Bank Account services\", \"Credit card or prepaid card\", \"Others\", \"Theft\/Dispute Reporting\",\n\"Mortgage\/Loan\"], yticklabels=[\"Bank Account services\", \"Credit card or prepaid card\", \"Others\", \"Theft\/Dispute Reporting\",\n\"Mortgage\/Loan\"])\n    plt.show()\n    \n    return","ac66fc17":"# Run the Multinomial Naive Bayes with default parameters\nmodel_name = 'NAIVE BAYES'\nclf_nb = MultinomialNB()\n%time \nclf_nb.fit(X_train, y_train)\ny_pred_nb = clf_nb.predict(X_test)","83763578":"# Calculate F1 Score using weighted average method\nf1_nb = f1_score(y_test, y_pred_nb, average=\"weighted\")\nf1_nb","ce7506db":"# # Hyperparameter tuning to improve Naive Bayes performance\n# param_grid_nb = {\n#     'alpha': (1, 0.1, 0.01, 0.001, 0.0001, 0.00001),\n#     'fit_prior':[True, False]\n# }\n\n# grid_nb = GridSearchCV(estimator=clf_nb, \n#                        param_grid=param_grid_nb,\n#                        verbose=1,\n#                        scoring='f1_weighted',\n#                        n_jobs=-1,\n#                        cv=10)\n# grid_nb.fit(X_train, y_train)\n# print(grid_nb.best_params_)","a4172b64":"# Run Multinomial Naive Bayes on tuned hyperparameters\nclf_nb_tuned = MultinomialNB(alpha=0.1, fit_prior=False)\n%time \nclf_nb_tuned.fit(X_train, y_train)\ny_pred_nb_tuned = clf_nb_tuned.predict(X_test)","ebbcdcce":"# Calculate F1 Score of tuned model using weighted average method\nf1_nb_tuned = f1_score(y_test, y_pred_nb_tuned, average=\"weighted\")\nf1_nb_tuned","0d29f99b":"# Evaluate the tuned Naive Bayes classifier\neval_model(y_test, y_pred_nb_tuned, model_name)","81e648c7":"# Create a dataframe to store F1 Scores of all models we will build\nsummary = pd.DataFrame([{'Model': 'Naive Bayes','F1 Score (untuned)': round(f1_nb, 2), 'F1 Score (tuned)': round(f1_nb_tuned, 2)}])\nsummary","9321236f":"# Run the Logistic Regression model\nmodel_name = 'LOGISTIC REGRESSION'\nclf_lr = LogisticRegression(solver='liblinear')\n%time \nclf_lr.fit(X_train, y_train)\ny_pred_lr = clf_lr.predict(X_test)","4951f812":"# Calculate F1 Score using weighted average method\nf1_lr = f1_score(y_test, y_pred_lr, average=\"weighted\")\nf1_lr","7c31758c":"# # Hyperparameter tuning to improve Logistic Regression performance\n# param_grid_lr = {\n#     'penalty': ['l1', 'l2','elasticnet', 'none'],\n#     'C': [0.001,0.01,0.1,1,10,100],\n#     'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n# }\n\n# grid_lr = GridSearchCV(estimator=clf_lr, \n#                        param_grid=param_grid_lr,\n#                        verbose=1,\n#                        scoring='f1_weighted',\n#                        n_jobs=-1,\n#                        cv=5)\n# grid_lr.fit(X_train, y_train)\n# print(grid_lr.best_params_)","eac79e5c":"# Run Logistic Regression on tuned hyperparameters\nclf_lr_tuned = LogisticRegression(C=1, \n                                  penalty='l1', \n                                  solver='saga')\n%time \nclf_lr_tuned.fit(X_train, y_train)\ny_pred_lr_tuned = clf_lr_tuned.predict(X_test)","6ef75444":"# Calculate F1 Score of tuned model using weighted average method\nf1_lr_tuned = f1_score(y_test, y_pred_lr_tuned, average=\"weighted\")\nf1_lr_tuned","d436a555":"# Evaluate the tuned Logistic Regression classifier\neval_model(y_test, y_pred_lr_tuned, model_name)","677f8d9d":"# Update the summary table\nsummary.loc[len(summary.index)] = ['Logistic Regression', round(f1_lr, 2), round(f1_lr_tuned, 2)]\nsummary","60ebbe4d":"# Run Decision Tree on default hyperparameters\nmodel_name = 'DECISION TREE'\nclf_dt = DecisionTreeClassifier()\n%time \nclf_dt.fit(X_train, y_train)\ny_pred_dt = clf_dt.predict(X_test)","55748161":"# Calculate F1 Score using weighted average method\nf1_dt = f1_score(y_test, y_pred_dt, average=\"weighted\")\nf1_dt","585aed87":"# # Hyperparameter tuning to improve Decision Tree performance\n# param_grid_dt = {\n#     'criterion': ['gini', 'entropy'],\n#     'max_depth' : [5, 10, 15, 20, 25, 30],\n#     'min_samples_leaf':[1,5,10,15, 20, 25],\n#     'max_features':['auto','log2','sqrt',None],\n# }\n\n# grid_dt = GridSearchCV(estimator=clf_dt, \n#                        param_grid=param_grid_dt,\n#                        verbose=1,\n#                        scoring='f1_weighted',\n#                        n_jobs=-1,\n#                        cv=5)\n# grid_dt.fit(X_train, y_train)\n# print(grid_dt.best_params_)","0e9249f2":"# Run Decision Tree on tuned hyperparameters\nclf_dt_tuned = DecisionTreeClassifier(criterion='gini', \n                                      max_depth=30, \n                                      min_samples_leaf=15, \n                                      max_features=None)\n%time \nclf_dt_tuned.fit(X_train, y_train)\ny_pred_dt_tuned = clf_dt_tuned.predict(X_test)","8699bdd0":"# Calculate F1 Score of tuned model using weighted average method\nf1_dt_tuned = f1_score(y_test, y_pred_dt_tuned, average=\"weighted\")\nf1_dt_tuned","fdd697c2":"# Evaluate the tuned Decision Tree classifier\neval_model(y_test, y_pred_dt_tuned, model_name)","d45ca42f":"# Update the summary table\nsummary.loc[len(summary.index)] = ['Decision Tree', round(f1_dt, 2), round(f1_dt_tuned, 2)]\nsummary","4fcfc04f":"# Run the Random Forest model on default hyperparameters\nmodel_name = 'RANDOM FOREST'\nclf_rf = RandomForestClassifier()\n%time \nclf_rf.fit(X_train, y_train)\ny_pred_rf = clf_rf.predict(X_test)","02000b67":"# Calculate F1 Score using weighted average method\nf1_rf = f1_score(y_test, y_pred_rf, average=\"weighted\")\nf1_rf","da160d54":"# # Hyperparameter tuning to improve Random Forest performance\n# param_grid_rf = {\n#     'n_estimators': [100, 200, 300, 500, 800],\n#     'criterion':['gini','entropy'],\n#     'max_depth': [10, 30, 40],\n#     'min_samples_split': [1, 5, 10],\n#     'min_samples_leaf': [1, 5, 10],\n#     'max_features': ['log2', 'sqrt', None]    \n# }\n\n# grid_rf = RandomizedSearchCV(estimator=clf_rf, \n#                        param_distributions=param_grid_rf,\n#                        scoring='f1_weighted',\n#                        verbose=1,\n#                        n_jobs=-1,\n#                        cv=5)\n# grid_rf.fit(X_train, y_train)\n# print(grid_rf.best_params_)","0679cdd3":"# Run Random Forest on tuned hyperparameters\nclf_rf_tuned = RandomForestClassifier(n_estimators=100, \n                                      min_samples_split=5, \n                                      min_samples_leaf=5, \n                                      max_features=None, \n                                      max_depth=30, \n                                      criterion='gini'\n)\n%time \nclf_rf_tuned.fit(X_train, y_train)\ny_pred_rf_tuned = clf_rf_tuned.predict(X_test)","9caf0d73":"# Calculate F1 Score of tuned model using weighted average method\nf1_rf_tuned = f1_score(y_test, y_pred_rf_tuned, average=\"weighted\")\nf1_rf_tuned","0baac612":"# Evaluate the tuned Random Forest classifier\neval_model(y_test, y_pred_rf_tuned, model_name)","734146a5":"# Update the summary table\nsummary.loc[len(summary.index)] = ['Random Forest', round(f1_rf, 2), round(f1_rf_tuned, 2)]\nsummary","81a3da32":"# Run the Support Vector Machine (SVM) model on default hyperparameters\nmodel_name = 'SUPPORT VECTOR MACHINE'\nclf_svm = SVC()\n%time \nclf_svm.fit(X_train, y_train)\ny_pred_svm = clf_svm.predict(X_test)","df6d1d48":"# Calculate F1 Score using weighted average method\nf1_svm = f1_score(y_test, y_pred_svm, average=\"weighted\")\nf1_svm","0afc523f":"# # Hyperparameter tuning to improve SVM performance\n# param_grid_svm = {\n#     'C': [10, 15],\n#     'gamma': ['scale', 0.01],\n#     'kernel': ['linear', 'rbf']\n# }\n\n# grid_svm = GridSearchCV(estimator=clf_svm, \n#                        param_grid=param_grid_svm,\n#                        scoring='f1_weighted',\n#                        verbose=1,\n#                        n_jobs=-1,\n#                        cv=2)\n# grid_svm.fit(X_train, y_train)\n# print(grid_svm.best_params_)","46da6461":"# Run SVM on tuned hyperparameters\nclf_svm_tuned = SVC(C=10,\n                    gamma='scale',\n                    kernel='rbf')\n%time \nclf_svm_tuned.fit(X_train, y_train)\ny_pred_svm_tuned = clf_svm_tuned.predict(X_test)","3117f868":"# Calculate F1 Score of tuned model using weighted average method\nf1_svm_tuned = f1_score(y_test, y_pred_svm_tuned, average=\"weighted\")\nf1_svm_tuned","dff73705":"# Evaluate the SVM classifier\neval_model(y_test, y_pred_svm_tuned, model_name)","077e8420":"# Update the summary table\nsummary.loc[len(summary.index)] = ['Support Vector Machine', round(f1_svm, 2), round(f1_svm_tuned, 2)]\nsummary","a1b5e5c6":"# Run XGBoost model on default hyperparameters \n################\n# This uses GPU\n################\nmodel_name = 'XGBOOST'\nclf_xgb = XGBClassifier(tree_method='gpu_hist', \n                        gpu_id=0, \n                        predictor=\"gpu_predictor\")\n%time\nclf_xgb.fit(X_train, y_train)\ny_pred_xgb = clf_xgb.predict(X_test)","1d8a39ca":"# Calculate F1 Score using weighted average method\nf1_xgb = f1_score(y_test, y_pred_xgb, average=\"weighted\")\nf1_xgb","5844aa06":"# # Hyperparameter tuning to improve XGBoost performance\n# param_grid_xgb = {\n#     'learning_rate': [0.1, 0.2],\n#     'max_depth': [2, 6, 10],\n#     'min_child_weight': [7, 11, 19],\n#     'scale_pos_weight': [10, 12],\n#     'n_estimators': [300, 500]\n# }\n\n# grid_xgb = RandomizedSearchCV(estimator=clf_xgb, \n#                               param_distributions=param_grid_xgb,\n#                               scoring='f1_weighted',\n#                               verbose=1,\n#                               n_jobs=-1,\n#                               cv=3)\n# grid_xgb.fit(X_train, y_train)\n# print(grid_xgb.best_params_)","3ad18275":"# Run XGBoost on tuned hyperparameters\nclf_xgb_tuned = XGBClassifier(scale_pos_weight=12, \n                              n_estimators=500, \n                              min_child_weight=11, \n                              max_depth=2, \n                              learning_rate=0.1, \n                              tree_method='gpu_hist', \n                              gpu_id=0, \n                              predictor=\"gpu_predictor\"\n)\n%time \nclf_xgb_tuned.fit(X_train, y_train)\ny_pred_xgb_tuned = clf_xgb_tuned.predict(X_test)","1a31878d":"# Calculate F1 Score of tuned model using weighted average method\nf1_xgb_tuned = f1_score(y_test, y_pred_xgb_tuned, average=\"weighted\")\nf1_xgb_tuned","50e30ab9":"# Evaluate the tuned XGBoost classifier\neval_model(y_test, y_pred_xgb_tuned, model_name)","8dbee031":"# Update the summary table\nsummary.loc[len(summary.index)] = ['XGBoost', round(f1_xgb, 2), round(f1_xgb_tuned, 2)]\nsummary","a20839e1":"# Run the CatBoost model on default hyperparameters\n################\n# This uses GPU\n################\nmodel_name = 'CATBOOST'\nclf_cb = CatBoostClassifier(task_type=\"GPU\",\n                           loss_function='MultiClass')\n%time\nclf_cb.fit(X_train, y_train)\ny_pred_cb = clf_cb.predict(X_test)","633aec59":"# Calculate F1 Score using weighted average method\nf1_cb = f1_score(y_test, y_pred_cb, average=\"weighted\")\nf1_cb","914f9ef2":"# # Hyperparameter tuning to improve CatBoost performance\n# param_grid_cb = {\n#         'depth':[2, 3, 4],\n#         'l2_leaf_reg':np.logspace(-20, -19, 3)\n# }\n\n# grid_cb = RandomizedSearchCV(estimator=clf_cb, \n#                               param_distributions=param_grid_cb,\n#                               scoring='f1_weighted',\n#                               verbose=1,\n#                               n_jobs=-1,\n#                               cv=2)\n# grid_cb.fit(X_train, y_train)\n# print(grid_cb.best_params_)","3fe61669":"# Run CatBoost on tuned hyperparameters\nclf_cb_tuned = CatBoostClassifier(task_type=\"GPU\",\n                                  l2_leaf_reg=1e-20,\n                                  depth=2\n)\n%time \nclf_cb_tuned.fit(X_train, y_train)\ny_pred_cb_tuned = clf_cb_tuned.predict(X_test)","84ca60f6":"# Calculate F1 Score of tuned model using weighted average method\nf1_cb_tuned = f1_score(y_test, y_pred_cb_tuned, average=\"weighted\")\nf1_cb_tuned","8efadb97":"# Evaluate the untuned CatBoost classifier (as it performed better)\neval_model(y_test, y_pred_cb, model_name)","553d7c9f":"# Update the summary table\nsummary.loc[len(summary.index)] = ['CatBoost', round(f1_cb, 2), round(f1_cb_tuned, 2)]\nsummary","4e4fbc30":"# Save tuned Logistic Regression model as pickle file\npickle.dump(clf_lr_tuned, open(\"logreg_model.pkl\", \"wb\"))","b1a7daeb":"# Function to predict a topic for given text\n\ndef predict_topic(text):\n    \n    target_names = [\"Bank Account services\", \"Credit card or prepaid card\", \"Others\", \"Theft\/Dispute Reporting\", \"Mortgage\/Loan\"]\n\n    loaded_vec = CountVectorizer(vocabulary=pickle.load(open(\"count_vector.pkl\", \"rb\")))\n    loaded_tfidf = pickle.load(open(\"tfidf.pkl\",\"rb\"))\n    loaded_model = pickle.load(open(\"logreg_model.pkl\",\"rb\"))\n\n    X_new_counts = loaded_vec.transform(text)\n    X_new_tfidf = loaded_tfidf.transform(X_new_counts)\n    predicted = loaded_model.predict(X_new_tfidf)\n\n    return target_names[predicted[0]]","c3bed8b2":"# Create a dataframe of some sample customer complaints\ndf_new = pd.DataFrame({'complaints': [\"I can not get from chase who services my mortgage, who owns it and who has original loan docs\", \n                                  \"The bill amount of my credit card was debited twice. Please look into the matter and resolve at the earliest.\",\n                                  \"I want to open a salary account at your downtown branch. Please provide me the procedure.\",\n                                  \"Yesterday, I received a fraudulent email regarding renewal of my services.\",\n                                  \"What is the procedure to know my CIBIL score?\",\n                                  \"I need to know the number of bank branches and their locations in the city of Dubai\"]})\ndf_new","d740e701":"# Create a new column of predicted topics of each complaint, predicted using the tuned Logistic Regression model\ndf_new['predicted topic'] = df_new['complaints'].apply(lambda x: predict_topic([x]))\ndf_new","fa9ffbaa":"### \ud83d\udccc The tuned Logistic Regression model gives a pretty high F1 score of 0.94.\n### \ud83d\udccc This model performs well on all topics.","876da88d":"### \ud83d\udccc We have removed 78,313 - 21,072  =  57,241 rows that contained blank under complaints column","ce940d39":"## `Model #1`: Naive Bayes \ud83d\ude2f","b51e403a":"### \ud83d\udccc After looking carefully at the first 5 complaints for each topics, we can assign names to topics as below\n- `Topic 0`: **Bank Account services**\n- `Topic 1`: **Credit card or prepaid card**\n- `Topic 2`: **Others**\n- `Topic 3`: **Theft\/Dispute Reporting**\n- `Topic 4`: **Mortgage\/Loan**\n\n### \ud83d\udca0 We create a dictionary and map the above names to the 5 topics","7bae1e8d":"# `Task 4`: Data Visualization (EDA) \ud83d\udcca","d5e70ecc":"### \ud83d\udccc The tuned Decision Tree model gives a decent F1 score of 0.80.\n### \ud83d\udccc However, this model is not able to perform well on classifying `Others` and `Theft\/Dispute Reporting` topics.","b827b8b7":"### \ud83d\udccc There are a lot of missing values. However, they are in columns that will not be required in model building, so we leave them untreated.","997f3428":"### \ud83d\udca0 Next, we remove the complaint rows that are blank","f1ef333f":"### \ud83d\udca0 Next, we find the top unigrams, bigrams and trigrams by frequency among all the complaints after processing the text.","9ec429c1":"# \ud83d\udcda Importing the necessary libraries","ce875784":"### \ud83d\udccc The SVM model gives a pretty high F1 score of 0.92.\n### \ud83d\udccc This model performs quite well on all topics.","fec95a54":"### \ud83d\udccc Best Estimator parameters\n\n{'scale_pos_weight': 12, 'n_estimators': 500, 'min_child_weight': 11, 'max_depth': 2, 'learning_rate': 0.1}\n","564b3eb2":"### \ud83d\udccc Best Estimator parameters\n{'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': None, 'max_depth': 30, 'criterion': 'gini'}","27321195":"### \ud83d\udca0 After performing cleaning operations, we do the following:\n\n- Lemmatize the texts\n- Use POS tags to get relevant words from the texts. ","e75d135c":"### \ud83d\udccc Best Estimator parameters\n\n\n{'alpha': 0.1, 'fit_prior': False}","1216322f":"### \ud83d\udccc The `score` column has all values as 0.0","bca1624e":"# `Task 2`: Data Cleaning \ud83e\uddf9","bcb81f6e":"### \ud83d\udca0 Selection of Evaluation Metric \n\n- As the distribution of target variable is not normal and there is imbalance of classes, we select **F1 Score** as our evaluation metric for comparing the performance of various models we will build.\n- Moreover, we will use a **weighted average** method for evaluating `F1 Score` due to the imbalance of classes","a973a435":"### \ud83d\udca0 Now, we convert the raw texts to a matrix of TF-IDF features\n\n***Note***: Here, we use following parameters of TfidfVectorizer:-\n\n**`max_df`** is used for removing terms that appear too frequently, also known as \"corpus-specific stop words\"\nmax_df = 0.95 means \"ignore terms that appear in more than 95% of the complaints\"\n\n**`min_df`** is used for removing terms that appear too infrequently\nmin_df = 2 means \"ignore terms that appear in less than 2 complaints\"","f5c3e471":"### \ud83d\udccc From the above summary table, we observe that the `tuned Logistic Regression` performs the best among all that we tried.","139dc962":"## Problem Statement \n\nYou need to build a model that is able to classify customer complaints based on the products\/services. By doing so, you can segregate these tickets into their relevant categories and, therefore, help in the quick resolution of the issue.\n\nYou will be doing topic modelling on the <b>.json<\/b> data provided by the company. Since this data is not labelled, you need to apply NMF to analyse patterns and classify tickets into the following five clusters based on their products\/services:\n\n* Credit card \/ Prepaid card\n\n* Bank account services\n\n* Theft\/Dispute reporting\n\n* Mortgages\/loans\n\n* Others\u00a0\n\n\nWith the help of topic modelling, you will be able to map each ticket onto its respective department\/category. You can then use this data to train any supervised model such as logistic regression, decision tree or random forest. Using this trained model, you can classify any new customer complaint support ticket into its relevant department.","4fa817ca":"## `Model #6`: XGBoost \ud83d\udca8","a0d7463b":"### \ud83d\udca0 Here, we do the following steps of Exploratory Data Analysis (EDA) to get familiar with the data.\n\n-   Visualise the data according to the 'Complaint' character length\n-   Using a word cloud find the top 40 words by frequency among all the articles after processing the text\n-   Find the top unigrams, bigrams and trigrams by frequency among all the complaints after processing the text.","09990c01":"### \ud83d\udccc Best Estimator parameters\n\n\n{'criterion': 'gini', 'max_depth': 30, 'max_features': None, 'min_samples_leaf': 15}","3d07e89b":"### \ud83d\udccc The tuned Naive Bayes model gives a moderately well F1 score of 0.78.\n\n### \ud83d\udccc However, this model performs a bit poor on classifying `Others` compared to remaining four topics.","e5c6b09e":"### \ud83d\udca0 Now that we have a label column, we can build Supervised model to predict any new complaints and assign them the relevant Topic.\n\n### \ud83d\udca0 Since we will be using supervised learning technique, we have to convert the topic names to numbers (numpy arrays only understand numbers)","6d65bba7":"### \ud83d\udca0 First, we rename the column headers","1d86758a":"### \ud83d\udca0 To select best number of Topics, we will use `Coherence Model`\n\n- With the Coherence Model we will see how to automatically select the best number of topics. ","a5108ee1":"### \ud83d\udccc 57,241 rows in the data have blanks under complaints column.\n### \ud83d\udca0 To remove the rows containing blanks, we first replace them by NaNs and then remove missing values.","e1710dcd":"### \ud83d\udccc The distribution of word counts is skewed a little positie but overall it is a pretty mormal distribution.\n### \ud83d\udca0 Now, we plot the top 40 words by frequency using a word cloud","64443893":"## `Model #7`: CatBoost \ud83d\ude85","efbd9da1":"# `Task 8`: Model Inference \u2611\ufe0f","4a33bbfe":"# \ud83d\udcdd Tasks to be performed:\n\n1. **Data loading and understanding**\n\n\n2. **Data Cleaning**\n\n\n3. **Data preprocessing**\n\n\n4. **Data Visualization (EDA)**\n\n\n5. **Feature extraction**\n\n\n6. **Topic modelling**\n\n\n7. **Model building**\n\n\n8. **Model inference**","6aa222e0":"### \ud83d\udccc Best Estimator parameters\n\n\n{'C': 1, 'penalty': 'l1', 'solver': 'saga'}","90a7c34a":"### \ud83d\udccc Thus, we can conclude that our model performs very well in classifying any new text.","314b562c":"# `Task 3`: Data Preprocessing \ud83d\udee0\ufe0f","802efb17":"### \ud83d\udccc Note that spaCy gives `-PRON-` as the pos tag of any personal pronoun.\n\n<br>\n\n\n### \ud83d\udca0 Now, we will use `Chunking` to extract singular nouns from the lemmatized complaints \n### \ud83d\udca0 We extract only nouns because we are interested in finding `topics`, which are mostly nouns.","3ce6a8e4":"## `Model #2`: Logistic Regression \ud83d\udcc8","23509d36":"###  \ud83d\udca0 Manual Topic Modeling\n\n- With the Coherence Model we got the **best number of topics = 5**.\n\n- The hard work is already done at this point so all we need to do is run the model.\n\n- The only parameter that is required is the number of components i.e. the number of topics we want. \n- This is the most crucial step in the whole topic modeling process and will greatly affect how good your final topics are.","cffe7e2b":"### \ud83d\udccc There are many columns with missing values.\n### \ud83d\udccc There is only one numerical column: `score`.","aacdd54d":"### \ud83d\udca0 Create a function to evaluate the classifiers","eea0d001":"## `Model #3`: Decision Tree \ud83c\udf34","88dfe543":"### \ud83d\udccc Best Estimator parameters\n\n{'l2_leaf_reg': 1e-20, 'depth': 2}","8979dd12":"# `Task 1`: Data Loading \ud83d\ude9a and Understanding \ud83d\udca1\n\n### \ud83d\udca0 The data is in JSON format, so first we convert it to a dataframe.","639c2ab8":"### \ud83d\udccc The personal details of customer has been masked in the dataset with `xxxx`. \n### \ud83d\udca0 We will remove the masked text as this will be of no use for our analysis.","fa00e08a":"# `Task 7`: Model Building \ud83c\udfd7\ufe0f","65f84a4a":"## `Model #5`: Support Vector Machine \ud83c\udff9","f291e3e8":"### \ud83d\udccc The tuned XGBoost model gives a pretty high F1 score of 0.92.\n### \ud83d\udccc This model performs quite well on all topics.","2e8c90f3":"### \ud83d\udccc We will have to rename the column names since they have changed due to normalization of JSON.","1b72aa7a":"### \ud83d\udccc The tuned Random Forest model gives a pretty high F1 score of 0.85.\n### \ud83d\udccc This model performs quite well on all topics.","e521b6f5":"### \ud83d\udca0 Create a summary table to store and compare F1 Scores of all models","dcb39402":"###  \ud83d\udca0 We can now apply the supervised models on the training data created. \n\n- In this process, we will do the following:\n    * Create the vector counts using Count Vectorizer\n    * Transform the word vector to tf-idf\n    * Create the train & test data using the train_test_split on the tf-idf & topics","7a478410":"### \ud83d\udca0 Now, we will try the following models one by one and evaluate them to select the best performing one\n\n1. Naive Bayes (this will serve as a baseline model)\n2. Logistic regression\n3. Decision Tree\n4. Random Forest\n5. Support Vector Machine\n6. XGBoost\n7. CatBoost","459787e8":"### \ud83d\udccc Best Estimator parameters\n{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}","6a617b28":"### \ud83d\udca0 Now, we use this tuned Logistic Regression model - `clf_lr_tuned` to predict some new custom text.","d5d475e3":"<div class=\"alert alert-success\">\n<h1> AUTOMATIC TICKET CLASSIFICATION - CASE STUDY<\/h1>\n\n<h2>Submitted by: Praveersinh Parmar & Ketaki Samanta<\/h2>\n<\/div>","1ac9c1aa":"# `Task 5`: Feature Extraction \u2728","c8c1c900":"### \ud83d\udccc The dataset has 78,313 customer complaints and 22 features.\n### \ud83d\udccc The customer complaint is in \"`_source.complaint_what_happened`\" column","3681fd34":"### \ud83d\udccc The untuned CatBoost model gives a pretty high F1 score of 0.91. (Note that CatBoost is designed in a way that tuning is not necessary.) \n### \ud83d\udccc This model performs quite well on all topics.","73082b71":"### \ud83d\udca0 Next, we create a document term matrix using fit_transform\n\n- The contents of a document term matrix are tuples of (complaint_id,token_id) tf-idf score:\n- The tuples that are not there have a tf-idf score of 0","bd31bfd8":"## `Model #4`: Random Forest \ud83c\udf33\ud83c\udf33\ud83c\udf33","dfef0665":"### \ud83d\udca0 We now perform Topic Modelling using NMF\n\n- `Non-Negative Matrix Factorization (NMF)` is an unsupervised technique so there are no labeling of topics that the model will be trained on. The way it works is that, NMF decomposes (or factorizes) high-dimensional vectors into a lower-dimensional representation. These lower-dimensional vectors are non-negative which also means their coefficients are non-negative.\n\n\n\n- We will perform the following steps:\n\n    * Find the best number of clusters\/topics\n    * Apply the best number to create word clusters\/topics\n    * Inspect & validate the correction of each cluster for each complaint\n    * Correct the labels if needed \n    * Map the clusters to topics\/cluster names","c030ff5a":"### \ud83d\udca0 Now that we have assigned a topic to each complaint, we can select these two columns as our training data","124776bb":"### \ud83d\udca0 Now, we prepare the text for topic modeling\n\n### \ud83d\udca0 Here, we do the following preprocessing on the text of complaints:\n\n- Make the text lowercase\n- Remove text in square brackets\n- Remove punctuation\n- Remove words containing numbers","ed9420cc":"### \ud83d\udca0 View the distribution of target variable `Topic`","cd3759fc":"# `Task 6`: Topic Modelling \ud83c\udff7\ufe0f"}}