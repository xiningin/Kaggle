{"cell_type":{"60842b1e":"code","4136dbbf":"code","622ea182":"code","b8b508d1":"code","87f4dba1":"code","b7405f42":"code","f78879eb":"code","e87b81fe":"code","c3f5183d":"code","d62e136f":"code","fb3ce168":"code","9a8cc7af":"code","b5be221a":"code","07ea9e66":"code","09ea6154":"code","e0757c1e":"code","956340c4":"code","ccd0d951":"code","3a1a2412":"code","41cd6686":"code","4e7d385e":"code","8ba871bc":"code","247f52e9":"code","d8e22cdb":"code","b7767e38":"code","5f6c2171":"code","f12c83bf":"code","4c3e02a4":"code","7f0067f0":"code","0204de49":"code","964e08b0":"code","6c70b701":"code","977e2bbf":"markdown","37faf82d":"markdown","0028f763":"markdown","92f53bcd":"markdown","ee807021":"markdown"},"source":{"60842b1e":"import os, sys, time\nimport numpy as np\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nimport torchvision.transforms.functional as TF","4136dbbf":"img_dir = '..\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/CXR_png'\nmask_dir = '..\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/masks'\nmask_names = os.listdir (mask_dir)\n\nprint (len (os.listdir (img_dir)))\nprint (len (os.listdir (mask_dir)))","622ea182":"mask_names = os.listdir (mask_dir)","b8b508d1":"print (os.listdir (img_dir) [-4])\nprint (os.listdir (mask_dir) [-4])","87f4dba1":"print (os.listdir (img_dir) [-3])\nprint (os.listdir (mask_dir) [-3])","b7405f42":"def shuffle_split (mask_names, val_pct = 0.15, seed = 99):\n    \"\"\" shuffling dataset with random state and split to tran and valid\"\"\"\n    n_val = int (len (mask_names) * val_pct)\n    np.random.seed (seed)\n    idx = np.random.permutation (len (mask_names))\n    mask_names = np.array (mask_names) [idx]\n    \n    return mask_names [n_val:], mask_names [:n_val]","f78879eb":"class lungDataset (Dataset):\n    \"\"\" create a dataset and transform it to tensor and resize it to 512*512\"\"\"\n    def __init__ (self, image_dir, mask_dir, mask_names, transform = None):\n        self.image_dir = image_dir\n        self.mask_dir = mask_dir\n        self.mask_names = mask_names\n        self.transform = transform\n        \n    def __getitem__ (self, index):\n        mask_path = os.path.join (self.mask_dir, self.mask_names [index])\n        image_path = os.path.join (self.image_dir, self.mask_names [index].replace ('_mask.png', '.png') if 'mask' in self.mask_names [index] else self.mask_names [index])\n        \n        image = np.array (Image.open (image_path).convert ('L'), dtype = np.float32) #3 * 8byte True pixels\n        mask = np.array (Image.open (mask_path).convert ('L'), dtype = np.float32) # 8 byte black & white pixels\n\n        mask [mask == 255] = 1\n        \n        if self.transform is not None:\n            augmentations = self.transform (image = image, mask =  mask)\n            image = augmentations ['image']\n            mask = augmentations ['mask']\n            \n        return image, mask\n    \n    def __len__ (self):\n        return len (self.mask_names)","e87b81fe":"trn_tfms = A.Compose (\n[\n    A.Resize (height = 512, width = 512),\n#     A.Rotate (limit = 35, p = 1.0),\n#     A.HorizontalFlip (p = 0.5),\n#     A.VerticalFlip (p = 0.1),\n    A.Normalize (0, 1, max_pixel_value = 255.0),\n    ToTensorV2 ()\n])\n\nval_tfms = A.Compose (\n[\n    A.Resize (height = 512, width = 512),\n    A.Normalize (0, 1, max_pixel_value = 255.0),\n    ToTensorV2 ()\n])","c3f5183d":"# create dataset and dataloader\ntrn_mask_names, val_mask_names = shuffle_split (mask_names, seed = 1)\n\ntrain_ds = lungDataset (img_dir, mask_dir, trn_mask_names, trn_tfms)\nvalid_ds = lungDataset (img_dir, mask_dir, val_mask_names, val_tfms)\n\ntrain_dl = DataLoader (train_ds, batch_size = 4, shuffle = True, num_workers = 2, pin_memory = True)\nvalid_dl = DataLoader (train_ds, batch_size = 4, shuffle = False, num_workers = 2, pin_memory = True)","d62e136f":"def imshow (img, title = None):\n    \"\"\" a function to show tensor images\"\"\"\n    img = img.numpy ().transpose (1, 2, 0)\n    mean = 0\n    std = 1\n    img = img * std + mean\n    img = np.clip (img, 0, 1)\n    \n    plt.figure (figsize = (10, 8))\n    plt.axis ('off')\n    plt.imshow (img)\n    if title:\n        plt.title (title)","fb3ce168":"print('image shape: ',train_ds [0][0].shape)\nprint('mask shape: ',train_ds [0][1].shape)","9a8cc7af":"img, msk = next (iter (train_dl))\nimg = torchvision.utils.make_grid (img, nrow = 2)\nmsk = msk.unsqueeze (1)\nmsk = torchvision.utils.make_grid (msk, nrow = 2)","b5be221a":"imshow (img, 'random baych of images')","07ea9e66":"imshow (msk, 'random baych of masks')","09ea6154":"class InitBlock (nn.Module):\n    def __init__ (self, in_channels = 3, out_channels = 64, stride = 1):\n        super(InitBlock, self).__init__()\n\n        self.conv_block = nn.Sequential(\n            nn.Conv2d (in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n            nn.BatchNorm2d (out_channels),\n            nn.ReLU (),\n            nn.Conv2d (out_channels, out_channels, kernel_size = 3, padding = 1),\n        )\n        self.conv_skip = nn.Sequential(\n            nn.Conv2d (in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n            nn.BatchNorm2d (out_channels),\n        )\n\n    def forward(self, x):\n\n        return self.conv_block(x) + self.conv_skip(x)","e0757c1e":"class ResBlock (nn.Module):\n    def __init__ (self, in_channels, out_channels, stride = 2):\n        super(ResBlock, self).__init__()\n\n        self.conv_block = nn.Sequential(\n            nn.BatchNorm2d (in_channels),\n            nn.ReLU (),\n            nn.Conv2d (in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n            nn.BatchNorm2d (out_channels),\n            nn.ReLU (),\n            nn.Conv2d (out_channels, out_channels, kernel_size = 3, padding = 1),\n        )\n        self.conv_skip = nn.Sequential(\n            nn.Conv2d (in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n            nn.BatchNorm2d (out_channels),\n        )\n\n    def forward(self, x):\n\n        return self.conv_block(x) + self.conv_skip(x)","956340c4":"class ResUnet(nn.Module):\n    def __init__(self, in_channels = 3, out_channels = 1, features = [64, 128, 256]):\n        super(ResUnet, self).__init__()\n\n        # input layer of resunet\n        self.input = InitBlock (in_channels, features [0])\n        \n        self.downs = nn.ModuleList ()\n        self.ups   = nn.ModuleList ()\n        \n        # down part of resunet & bridge part\n        for feature in features:\n            self.downs.append (ResBlock (feature, feature * 2, stride = 2))\n            feature *= 2\n            \n        # up part of resunet\n        for feature in reversed (features):\n            self.ups.append (nn.ConvTranspose2d (2 * feature, 2 * feature, kernel_size = 2, stride = 2))\n            self.ups.append (ResBlock (2 * feature + feature, feature, stride = 1))\n            \n        self.output = nn.Conv2d(features [0], out_channels, kernel_size = 1)\n        \n    def forward (self, x):\n        skip_connections = []\n        x = self.input (x)\n        skip_connections.append (x)\n        \n        for i, down in enumerate (self.downs):\n            x = down (x)\n            if i < 2:\n                skip_connections.append (x)\n        \n        skip_connections = skip_connections [::-1]\n        \n        for idx in range (0, len (self.ups), 2):\n            x = self.ups [idx] (x)\n            skip_connection = skip_connections [idx \/\/ 2]\n            \n            if x.shape != skip_connection.shape:\n                x = TF.resize (x, skip_connection.shape [2:])\n                \n            concat_skip = torch.cat ((skip_connection, x), dim = 1)\n            x = self.ups [idx + 1] (concat_skip)\n            \n        return self.output (x)","ccd0d951":"class lungLoss (nn.Module):\n    \"\"\" BCE , jaccard_loss and dice_loss \"\"\"\n    def __init__ (self, weight = None, size_average = True):\n        super (lungLoss, self).__init__ ()\n        \n    def forward (self, outputs, targets, smooth = 1e-8):\n        # comment out if your model contains a sigmoid or equivalent activation loss\n        outputs = torch.sigmoid (outputs)\n        \n        # flatten label and prediction tensors\n        outputs = outputs.view (-1)\n        targets = targets.view (-1)\n        \n        intersection = (outputs * targets).sum ()\n        union = (outputs.sum () + targets.sum ()) - intersection\n        \n        jaccard_loss = 1 - (intersection \/ (union + smooth))\n        dice_loss = 1 - (2. * intersection) \/ (outputs.sum () + targets.sum () + smooth)\n        BCE = F.binary_cross_entropy (outputs, targets, reduction = 'mean')\n        \n        loss = BCE + jaccard_loss + dice_loss\n        \n        return loss","3a1a2412":"def calculate_metrics (outputs, targets, smooth = 1e-8):\n    \"\"\" calculate accuracy dice and jaccard \"\"\"\n    outputs = torch.sigmoid (outputs)\n    preds = (outputs > 0.5).float ()\n    intersection = (preds * targets).sum ()\n    \n    accuracy = (preds == targets).sum () \/ torch.numel (preds)\n    dice = (intersection * 2.) \/ ((preds + targets).sum () + smooth)\n    iou = (intersection) \/ ((preds + targets).sum () - intersection + smooth)\n    \n    return accuracy, dice, iou","41cd6686":"def save_checkpoint (state, filename):\n    \"\"\" saving model's weights \"\"\"\n    print ('=> saving checkpoint')\n    torch.save (state, filename)\n\n\ndef load_checkpoint (checkpoint, model):\n    \"\"\" loading model's weights \"\"\"\n    print ('=> loading checkpoint')\n    model.load_state_dict (checkpoint ['state_dict'])","4e7d385e":"def train (model, loader, loss_fn, optimizer, metric_fn, device):\n    \"\"\" training one epoch and calculate loss and metrics \"\"\"\n    \n    # Training model\n    model.train ()\n    losses = 0.0\n    accuracy = 0.0\n    dice_scores = 0.0\n    iou_scores = 0.0\n    steps = len (loader)\n\n    for i, (inputs, targets) in enumerate (loader):\n        # Place to gpu\n        inputs = inputs.to(device)\n        targets = targets.float ().unsqueeze (1).to(device)\n\n        outputs = model (inputs)\n\n        # Calculate loss\n        loss = loss_fn (outputs, targets)\n        losses += loss\n\n        # Backpropagation and update weights\n        optimizer.zero_grad ()\n        loss.backward ()\n        optimizer.step ()\n\n\n        # Calculate metrics\n        acc, dice, iou = metric_fn (outputs, targets)\n        accuracy += acc\n        dice_scores += dice\n        iou_scores += iou\n\n        # report\n        sys.stdout.flush ()\n        sys.stdout.write ('\\r Step: [%2d\/%2d], loss: %.4f - acc: %.4f - dice: %.4f - iou: %.4f' \n                          % (i, steps, loss.item (), acc, dice, iou))\n    sys.stdout.write ('\\r')\n    return losses.item () \/ len (loader), accuracy \/ len (loader), dice_scores \/ len (loader), iou_scores \/ len (loader)","8ba871bc":"def evaluate (model, loader, loss_fn, metric_fn, device):\n    \"\"\" Evaluate trained weights using calculate loss and metrics \"\"\"\n    # Evaluate model\n    model.eval ()\n    losses = 0.0\n    accuracy = 0.0\n    dice_scores = 0.0\n    iou_scores = 0.0\n\n    with torch.no_grad ():\n        for inputs, targets in loader:\n            inputs = inputs.to(device)\n            targets = targets.float ().unsqueeze (1).to(device)\n\n            outputs = model (inputs)\n            loss = loss_fn (outputs, targets)\n            losses += loss\n\n            # Calculate metrics\n            acc, dice, iou = metric_fn (outputs, targets)\n            accuracy += acc\n            dice_scores += dice\n            iou_scores += iou\n\n    return losses.item () \/ len (loader), accuracy \/ len (loader), dice_scores \/ len (loader), iou_scores \/ len (loader)","247f52e9":"def fit (model, train_dl, valid_dl, loss_fn, optimizer, num_epochs, metric_fn, device, checkpoint_path, scheduler = None, load_model = False):\n    \"\"\" fiting model to dataloaders, saving best weights and showing results \"\"\"\n    losses, val_losses, accs, val_accs, dices, val_dices, ious, val_ious = [], [], [], [], [], [], [], []\n    best_loss = 10000\n\n    # to continue training from saved weights\n#     if load_model:\n#         load_checkpoint (torch.load (checkpoint_path), model)\n\n    since = time.time ()\n\n    for epoch in range (num_epochs):\n\n        loss, acc, dice, iou = train (model, train_dl, loss_fn, optimizer, metric_fn, device)\n        val_loss, val_acc, val_dice, val_iou = evaluate (model, valid_dl, loss_fn, metric_fn, device)\n\n        \n        losses.append (loss)\n        accs.append (acc)\n        val_losses.append (val_loss)\n        val_accs.append (val_acc)\n        dices.append (dice)\n        val_dices.append (val_dice)\n        ious.append (iou)\n        val_ious.append (val_iou)\n        \n        # learning rate scheduler\n        if scheduler is not None:\n            scheduler.step (val_acc)\n\n        # save weights if improved\n        if val_loss < best_loss:\n            checkpoint = {'state_dict': model.state_dict (), 'optimizer': optimizer.state_dict ()}\n            save_checkpoint (checkpoint, checkpoint_path)\n            best_loss = val_loss\n\n        print ('Epoch [{}\/{}], loss: {:.4f} - acc: {:.4f} - dice: {:.4f} - iou: {:.4f} | val_loss: {:.4f} - val_acc: {:.4f} - val_dice: {:.4f} - val_iou: {:.4f}'\n               .format (epoch + 1, num_epochs, loss, acc, dice, iou, val_loss, val_acc, val_dice, val_iou))\n\n    period = time.time () - since\n    print ('Training complete in {:.0f}m {:.0f}s'.format (period \/\/ 60, period % 60))\n\n    return dict (loss = losses, val_loss = val_losses, acc = accs, val_acc = val_accs, dice = dices, val_dice = val_dices, iou = ious, val_iou = val_ious)","d8e22cdb":"device = torch.device ('cuda' if torch.cuda.is_available() else 'cpu')\n# Hyper functions\nmodel =  ResUnet (in_channels = 1, out_channels = 1).to(device)\nloss_fn = lungLoss ().to(device)\noptimizer = optim.Adam (model.parameters (), lr = 1e-4)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau (optimizer, factor = 0.1, patience = 3)\ncheckpoint_path = 'LungResUnet.pth'","b7767e38":"history = fit (model, train_dl, valid_dl, loss_fn, optimizer, 20, calculate_metrics, device, checkpoint_path, scheduler)","5f6c2171":"# save full model\ntorch.save (model, 'FullLungResUnet.pth')","f12c83bf":"loss = history ['loss']\nval_loss = history ['val_loss']\nacc = history ['acc']\nval_acc = history ['val_acc']\ndice = history ['dice']\nval_dice = history ['val_dice']\niou = history ['iou']\nval_iou = history ['val_iou']","4c3e02a4":"def plot_metrics (loss, val_loss, acc, val_acc, dice, val_dice, iou, val_iou):\n    \"\"\" ploting each of metric in one line \"\"\"\n    \n    fig, ax = plt.subplots (1, 4, figsize = (20, 4))\n    ax [0].plot (range (len (loss)), loss, 'b-', label = 'Training')\n    ax [0].plot (range (len (loss)), val_loss, 'bo-', label = 'Validation')\n    ax [0].set_title ('Loss')\n    ax [0].legend ()\n    \n    ax [1].plot (range (len (loss)), acc, 'b-', label = 'Training')\n    ax [1].plot (range (len (loss)), val_acc, 'bo-', label = 'Validation')\n    ax [1].set_title ('Accuracy')\n    ax [1].legend ()\n    \n    ax [2].plot (range (len (loss)), dice, 'b-', label = 'Training')\n    ax [2].plot (range (len (loss)), val_dice, 'bo-', label = 'Validation')\n    ax [2].set_title ('Dice Score')\n    ax [2].legend ()\n    \n    ax [3].plot (range (len (loss)), iou, 'b-', label = 'Training')\n    ax [3].plot (range (len (loss)), val_iou, 'bo-', label = 'Validation')\n    ax [3].set_title ('IOU Score')\n    ax [3].legend ()\n    \n    plt.show ()","7f0067f0":"plot_metrics (loss, val_loss, acc, val_acc, dice, val_dice, iou, val_iou)","0204de49":"def tensor_to_array (img):\n    return img.cpu ().numpy ().transpose (1, 2, 0)","964e08b0":"def show_results (model, valid_dl, checkpoint_path = None):\n    \"\"\" showing image, mask and predicted mask for one batch \"\"\"\n    if checkpoint_path is not None:\n        load_checkpoint (torch.load (checkpoint_path), model)\n    \n    images, masks = next (iter (valid_dl))\n    images = images.to(device)\n    masks = masks.unsqueeze (1).to(device)\n    outputs = model (images)\n    preds = (outputs > 0.5).float ()\n    \n    plt.figure (figsize = (15, 20))\n    for i in range (len (preds)):\n        plt.subplot (4, 3, 3 * i + 1)\n        plt.title ('Orginal Image')\n        image = images [i]\n        plt.imshow (tensor_to_array (image), cmap = 'gray')\n        \n        plt.subplot (4, 3, 3 * i + 2)\n        plt.title ('True Mask')\n        mask = masks [i]\n        plt.imshow (tensor_to_array (mask), cmap = 'gray')\n        \n        plt.subplot (4, 3, 3 * i + 3)\n        plt.title ('Predicted Mask')\n        pred = preds [i]\n        plt.imshow (tensor_to_array (pred), cmap = 'gray')\n        \n    plt.show ()","6c70b701":"show_results (model, valid_dl)","977e2bbf":"# Train","37faf82d":"# Visualize","0028f763":"# PreProcess","92f53bcd":"# Model","ee807021":"# Training"}}