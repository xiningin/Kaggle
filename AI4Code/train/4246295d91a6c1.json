{"cell_type":{"67f82a23":"code","8354f433":"code","0a9aeb6f":"code","60161ed2":"code","3d539df1":"code","7959c5a6":"code","99e2cd1b":"code","051e40c5":"code","49cf43a4":"code","a2279162":"code","f62245e5":"code","4ebfed7e":"code","b5e441f3":"code","84c48bb3":"code","c239a69b":"code","4cab0397":"code","fbdf50b9":"code","171ea708":"code","da14a95c":"code","4ef07295":"code","dec0fa0b":"code","9f0aec8b":"code","06dcc811":"code","373a065a":"code","024a1165":"code","6f7e8b33":"code","b7a8fb7e":"code","56a7e011":"code","7420d82c":"code","d5dc506e":"code","8e9fd2c6":"code","858eab13":"code","7da15313":"code","b22f7403":"code","12033263":"code","347deaa6":"code","240b8755":"code","688d7f49":"markdown","613c8f32":"markdown","e76cba11":"markdown","52c773c7":"markdown"},"source":{"67f82a23":"!pip install -q --upgrade pip\n!pip install -q transformers\n!pip install -q pythainlp","8354f433":"import pandas as pd\nimport numpy as np\nimport torch\nimport os","0a9aeb6f":"path = \"..\/input\/super-ai-engineer-scg-thai-qa-individual\/\"\ntrain_df = pd.read_csv(path+\"train.csv\")\ntest_df = pd.read_csv(path+\"test.csv\")","60161ed2":"train_df","3d539df1":"test_df","7959c5a6":"import re\ndef deEmojify(text):\n    regrex_pattern = re.compile(pattern = \"[\"\n        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           \"]+\", flags = re.UNICODE)\n    return regrex_pattern.sub(r'',text).replace('  ','')","99e2cd1b":"from pythainlp.tokenize import word_tokenize\ndef read_data(df, have_a = True):\n    contexts = []\n    questions = []\n    answers = []\n    for idx, row in df.iterrows():\n        with open(\"..\/input\/super-ai-engineer-scg-thai-qa-individual\/\" + row['article_path']) as f:\n            contexts.append(' '.join(word_tokenize(deEmojify(f.read()))).replace('  ',''))\n        questions.append(' '.join(word_tokenize(row['question'])).replace('  ',''))\n        if have_a:\n            answers.append(' '.join(word_tokenize(row['answer'])).replace('  ',''))\n    return contexts, questions, answers\ntrain_contexts, train_questions, train_answers_text = read_data(train_df)\ntest_contexts, test_questions, _ = read_data(test_df, have_a=False)","051e40c5":"print(f\"contexts :{train_contexts[0]}\")\nprint(f\"questions :{train_questions[0]}\")\nprint(f\"answers :{train_answers_text[0]}\")","49cf43a4":"print(f\"contexts :{test_contexts[0]}\")\nprint(f\"questions :{test_questions[0]}\")","a2279162":"def ans_inx_search(contexts,answers):\n    ans_starts = []\n    ans_ends = []\n    count = 0\n    for answer, context in zip(answers, contexts):\n        for i in range(len(context)):\n            if answer == context[i: i + len(answer)]:\n                ans_starts.append(i)\n                ans_ends.append(i+len(answer)-1)\n                break\n        count = count + 1\n        if count != len(ans_starts):\n            print(f\"context : {context}\")\n            print(f\"answer : {answer}\")\n            print(count)\n            break\n    return ans_starts, ans_ends","f62245e5":"train_answers_text[259] = \"Strategic Project\"","4ebfed7e":"answers_start , answers_end = ans_inx_search(train_contexts, train_answers_text)","b5e441f3":"answers = []\nfor i in range(len(train_answers_text)):\n    answers.append({\"text\":train_answers_text[i], \"answer_start\":answers_start[i], \"answer_end\":answers_end[i]})","84c48bb3":"from transformers import RobertaTokenizerFast\nfrom transformers import RobertaForQuestionAnswering\nfrom transformers import AlbertTokenizerFast\nfrom transformers import AlbertForQuestionAnswering\nfrom transformers import BertTokenizerFast\nfrom transformers import BertForQuestionAnswering\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering\n\npretrained = \"Geotrend\/bert-base-en-th-cased\"\ntokenizer = BertTokenizerFast.from_pretrained(pretrained)\nmodel = BertForQuestionAnswering.from_pretrained(pretrained)","c239a69b":"train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)","4cab0397":"answers[8]","fbdf50b9":"train_encodings.char_to_token(0)","171ea708":"def add_token_positions(encodings, answers):\n    start_positions = []\n    end_positions = []\n    for i in range(len(answers)):\n        j = 1\n        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']+1))\n\n        # if start position is None, the answer passage has been truncated\n        if start_positions[-1] is None:\n            start_positions[-1] = tokenizer.model_max_length\n\n        # if end position is None, the 'char_to_token' function points to the space before the correct token - > add + 1\n        while end_positions[-1] is None:\n            end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end'] + j)\n            j = j + 1\n            if j == tokenizer.model_max_length:\n                end_positions[-1] = tokenizer.model_max_length\n                break\n    print(start_positions)\n    print(len(start_positions))\n    print(end_positions)\n    print(len(end_positions))\n    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})","da14a95c":"add_token_positions(train_encodings, answers)","4ef07295":"class SquadDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n\n    def __getitem__(self, idx):\n        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n\n    def __len__(self):\n        return len(self.encodings.input_ids)","dec0fa0b":"train_dataset = SquadDataset(train_encodings)","9f0aec8b":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel.to(device)","06dcc811":"from torch.utils.data import DataLoader\nfrom transformers import AdamW","373a065a":"model.train()\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n\noptim = AdamW(model.parameters(), lr=1e-5)\nepochs = 50\nloss_save = []\nfor epoch in range(epochs):\n    train_loss = 0.0\n    for batch in train_loader:\n        optim.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        start_positions = batch['start_positions'].to(device)\n        end_positions = batch['end_positions'].to(device)\n        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n        loss = outputs[0]\n        train_loss += loss.item()*batch['input_ids'].size(0)\n        loss.backward()\n        optim.step()\n    train_loss = train_loss\/len(train_loader.dataset)\n    loss_save.append(train_loss)\n    print(f\"loss:{train_loss}, epochs:{epoch+1}\/{epochs}\")","024a1165":"import matplotlib.pyplot as plt\nx_plot = range(len(loss_save))\n\nplt.plot(x_plot, loss_save)\n\nplt.xlabel('Epoch')\nplt.ylabel('loss')\nplt.title('Loss plot')\n\nplt.legend()\nplt.show()","6f7e8b33":"test_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\ntest_dataset = SquadDataset(test_encodings)\ntest_loader = DataLoader(test_dataset, batch_size=1)","b7a8fb7e":"model.eval()","56a7e011":"count = 0\nfor batch in test_loader:\n    input_ids = batch['input_ids'].to(device)\n    attention_mask = batch['attention_mask'].to(device)\n    output =  model(input_ids, attention_mask=attention_mask, return_dict=True)\n    input_list = input_ids.tolist()[0]\n    answer_start = list(torch.argmax(output.start_logits,dim=1).cpu().numpy())[0]\n    answer_end = list(torch.argmax(output.end_logits,dim=1).cpu().numpy())[0]\n    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_list[answer_start:answer_end]))\n    print(f\"q : {train_questions[count]}\")\n    print(f\"a : {answer}\" )\n    print(f\"Atual : {train_answers_text[count]}\")\n    count = count + 1","7420d82c":"test_encodings = tokenizer(test_contexts, test_questions, truncation=True, padding=True)\ntest_dataset = SquadDataset(test_encodings)\ntest_loader = DataLoader(test_dataset, batch_size=1)","d5dc506e":"predict = []\ncount = 0\nfor batch in test_loader:\n    input_ids = batch['input_ids'].to(device)\n    attention_mask = batch['attention_mask'].to(device)\n    output =  model(input_ids, attention_mask=attention_mask, return_dict=True)\n    input_list = input_ids.tolist()[0]\n    answer_start = list(torch.argmax(output.start_logits,dim=1).cpu().numpy())[0]\n    answer_end = list(torch.argmax(output.end_logits,dim=1).cpu().numpy())[0]\n    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_list[answer_start:answer_end]))\n    print(f\"q : {test_questions[count]}\")\n    print(f\"a : {answer}\")\n    predict.append(answer)\n    count = count + 1","8e9fd2c6":"submit = pd.read_csv(\"..\/input\/super-ai-engineer-scg-thai-qa-individual\/sampleSubmission.csv\")","858eab13":"submit['Predicted'] = predict","7da15313":"submit['Predicted'] = submit['Predicted'].apply(lambda x : x.replace('[UNK]','\\\"'))","b22f7403":"submit['Predicted'] = submit['Predicted'].apply(lambda x : x.replace('<s>',''))","12033263":"submit.to_csv(\"22p21c0775_submission.csv\", index=False)","347deaa6":"submit.tail(50)","240b8755":"submit.head(50)","688d7f49":"Full-test","613c8f32":"test on train set","e76cba11":"Finetune","52c773c7":"Read data"}}