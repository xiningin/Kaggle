{"cell_type":{"7ceec422":"code","1598dc0b":"code","b70a557b":"code","ad8ef928":"code","44ef3248":"code","ae811219":"code","9278f674":"code","85e564a2":"markdown","187cd0ba":"markdown","00687fc6":"markdown","9d49932f":"markdown","4ce18be0":"markdown","b8d11917":"markdown","19feee69":"markdown"},"source":{"7ceec422":"import numpy as np\nimport pandas as pd\n\nfrom collections import Counter\n\nfrom sklearn.model_selection import cross_validate\n\nfrom catboost import CatBoostClassifier\n\nfrom sklearn.metrics import accuracy_score","1598dc0b":"TRAIN_PATH = \"..\/input\/titanic\/train.csv\"\nTEST_PATH = \"..\/input\/titanic\/test.csv\"\nSAMPLE_SUBMISSION_PATH = \"..\/input\/titanic\/gender_submission.csv\"\nSUBMISSION_PATH = \"submission.csv\"\n\nID = \"PassengerId\"\nTARGET = \"Survived\"\nTASTK_TYPE = 'GPU'\n\nSEED_LIST = [0,1,42,2021,1004,7,77,777,1234,123]","b70a557b":"train = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)","ad8ef928":"def getLabelCount(df,target):\n    return [( labelValue,len(train.loc[df[target] == labelValue]) ) for labelValue in df[target].unique()]\n\nlabelCount = getLabelCount(train,TARGET)\nlabelCount","44ef3248":"# Outlier detection \n\ndef detect_outliers(df,n,features):\n    \"\"\"\n    Takes a dataframe df of features and returns a list of the indices\n    corresponding to the observations containing more than n outliers according\n    to the Tukey method.\n    \"\"\"\n    outlier_indices = []\n    \n    # iterate over features(columns)\n    for col in features:\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[col], 25)\n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[col],75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5 * IQR\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        \n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    \n    return multiple_outliers   \n\n\n# 1.detect outliers from Age, SibSp , Parch and Fare\nOutliers_to_drop = detect_outliers(train,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])\ntrain = train.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)\n\n# 2.get train row size \ntrain_len = len(train)\n\n# 3.concat train + test \ndataset =  pd.concat(objs=[train, test], axis=0).reset_index(drop=True)\n\n# 4. empty data => np.nan\ndataset = dataset.fillna(np.nan)\n\n# 5.column encoding and create new features\n# 5.1.Fare\ndataset[\"Fare\"] = dataset[\"Fare\"].fillna(dataset[\"Fare\"].mean())\n# dataset[\"Fare\"] = dataset[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)\n\n# 5.2.Embarked\ndataset[\"Embarked\"] = dataset[\"Embarked\"].fillna(dataset[\"Fare\"].mode()[0])\ndataset = pd.get_dummies(dataset, columns = [\"Embarked\"], prefix=\"Em\")\n\n# 5.3.Sex\ndataset[\"Sex\"] = dataset[\"Sex\"].map({\"male\": 0, \"female\":1})\n# dataset = pd.get_dummies(dataset, columns = [\"Sex\"])\n\n# 5.4.Age\nindex_NaN_age = list(dataset[\"Age\"][dataset[\"Age\"].isnull()].index)\nfor i in index_NaN_age :\n    age_med = dataset[\"Age\"].mean()\n    dataset['Age'].iloc[i] = age_med\n#     age_pred = dataset[\"Age\"][((dataset['SibSp'] == dataset.iloc[i][\"SibSp\"]) & (dataset['Parch'] == dataset.iloc[i][\"Parch\"]) & (dataset['Pclass'] == dataset.iloc[i][\"Pclass\"]))].median()\n#     if not np.isnan(age_pred) :\n#         dataset['Age'].iloc[i] = age_pred\n#     else :\n#         dataset['Age'].iloc[i] = age_med\n        \n        \n# 5.5.Name         \n# dataset_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in dataset[\"Name\"]]\n# dataset[\"Title\"] = pd.Series(dataset_title)\n# dataset[\"Title\"] = dataset[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n# dataset[\"Title\"] = dataset[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\n# dataset[\"Title\"] = dataset[\"Title\"].astype(int)\n# dataset.drop(labels = [\"Name\"], axis = 1, inplace = True)\n# dataset = pd.get_dummies(dataset, columns = [\"Title\"])\n\n# 5.6.SibSp(Number of Siblings\/Spouses Aboard) + Parch(Number of Parents\/Children Aboard) =>Fsize\ndataset[\"FamilySize\"] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1\ndataset['IsSingle'] = dataset['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n# dataset['IsSmallFamily'] = dataset['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\n# dataset['IsMedFamily'] = dataset['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n# dataset['IsLargeFamily'] = dataset['FamilySize'].map(lambda s: 1 if s >= 5 else 0)\n\n# #5.7.Cabin\ndataset[\"Cabin\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in dataset['Cabin'] ])\ndataset = pd.get_dummies(dataset, columns = [\"Cabin\"],prefix=\"Cabin\")\n\n# #5.8.Ticket \nTicket = []\nfor i in list(dataset.Ticket):\n    if not i.isdigit() :\n        Ticket.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(' ')[0]) #Take prefix\n    else:\n        Ticket.append(\"X\")\n        \ndataset[\"Ticket\"] = Ticket\ndataset = pd.get_dummies(dataset, columns = [\"Ticket\"], prefix=\"T\")\n\n# 5.9.Pclass\ndataset[\"Pclass\"] = dataset[\"Pclass\"].astype(\"category\")\ndataset = pd.get_dummies(dataset, columns = [\"Pclass\"],prefix=\"Pc\")\n\n# 5.10.PassengerId\ndataset.drop(labels = [\"Name\",\"PassengerId\"], axis = 1, inplace = True)\n\n# 6.devide train test \ntrain = dataset[:train_len]\ntest = dataset[train_len:]\ntest.drop(labels=[\"Survived\"],axis = 1,inplace=True)","ae811219":"y = train[TARGET]\nX = train.drop([TARGET],axis=1)\nX_test = test","9278f674":"for seed in SEED_LIST:\n    print(\"seed =\",seed,\"predict start\")\n    \n    model = CatBoostClassifier(task_type=TASTK_TYPE,random_state=seed) \n    model.fit(X, y,verbose=False)\n\n    pred_test = model.predict(X_test)\n\n    submission = pd.read_csv(SAMPLE_SUBMISSION_PATH)\n    submission[TARGET] = pred_test.astype(int)\n    \n    SUBMISSION_PATH = f\"submission_seednumber_{seed}.csv\"\n    submission.to_csv(SUBMISSION_PATH,index=False)\n    \n    print(\"seed =\",seed,\"predict end\")","85e564a2":"# preprocess","187cd0ba":"# check label count","00687fc6":"# import","9d49932f":"# training + predict + make submission csv","4ce18be0":"# variables","b8d11917":"# split data (input and label)","19feee69":"# load data"}}