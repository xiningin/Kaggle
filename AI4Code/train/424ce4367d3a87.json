{"cell_type":{"58246293":"code","14448ab3":"code","223662d8":"code","140e4b21":"code","02afddae":"code","d1e394f5":"code","632f294e":"code","fa301975":"code","cadd8164":"code","ed002059":"code","1c1bb029":"code","97f04f48":"code","3acbff97":"code","97156dd8":"code","8e92dbcc":"code","b51ced06":"code","de30c067":"code","369263e5":"code","62d7444a":"code","8ea5e633":"code","f8145ee5":"code","5c761a2e":"code","28c381da":"code","d42f5437":"code","81743e4c":"code","54a29cd9":"code","91743af3":"code","f5f4538c":"code","27c8cc76":"code","fd29ba2b":"code","8d780450":"code","1dba73c7":"code","dfcd52ba":"code","6fea9b28":"code","e595f2b1":"code","38f10a19":"code","df4f2e6b":"code","72dd45cb":"code","40ff1cac":"markdown","fe5e744a":"markdown","47c5a918":"markdown","fa2f8b45":"markdown","f03cd8db":"markdown","f96d9ed4":"markdown","652404ec":"markdown","b295261d":"markdown","000eb3bc":"markdown","18012150":"markdown","46138cda":"markdown","fab73ace":"markdown","1304c331":"markdown","cce6efd5":"markdown","3ddea74b":"markdown","8c3ccf0f":"markdown"},"source":{"58246293":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n###for dirname, _, filenames in os.walk('\/kaggle\/input'):\n###    for filename in filenames:\n###        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","14448ab3":"# !pip install -q efficientnet >> \/dev\/null","223662d8":"import pandas as pd, numpy as np\nfrom kaggle_datasets import KaggleDatasets\nimport tensorflow as tf, re, math\nimport tensorflow.keras.backend as K\n#import efficientnet.tfkeras as efn\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nimport matplotlib.pyplot as plt\n\nimport cv2","140e4b21":"DEVICE = \"TPU\" #or \"GPU\" # \n\n# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD\nSEED = 42\n\n# NUMBER OF FOLDS. USE 3, 5, OR 15 \nFOLDS = 3\n\n# WHICH IMAGE SIZES TO LOAD EACH FOLD\n# CHOOSE 128, 192, 256, 384, 512, 768, 1024, 1536 \n#IMG_SIZES = [384,384,384,384,384]\n#IMG_SIZES = [128,128,128,128,128]\nSIZE = 1024\nIMG_SIZES = [SIZE]*FOLDS\n\n# INCLUDE OLD COMP DATA? YES=1 NO=0\n#TOKEN = 0\n#INC2019 = [TOKEN,TOKEN,TOKEN,TOKEN,TOKEN]\n#INC2018 = [TOKEN,TOKEN,TOKEN,TOKEN,TOKEN]\n\n# BATCH SIZE AND EPOCHS\n# Original batch size \n#BATCH_SIZES = [32]*FOLDS\n\n# YG \n# Experimental batch sizes for EfficientNetB7\n# BAD\n#BATCH_SIZES = [4]*FOLDS # for 768 - VERY LONG - stops after 2 folds only, ~4 hours per fold\n#BATCH_SIZES = [8]*FOLDS # for 768 - VERY LONG - 3 hours per fold\n#BATCH_SIZES = [12]*FOLDS # for 768 - BAD, not enough resources \n# GOOD\n#BATCH_SIZES = [32]*FOLDS # for 384 - GOOD - ~1 hour per fold\n#BATCH_SIZES = [16]*FOLDS # for 512\n\n# GPU: Experimental batch sizes for EfficientNetB0\n# BATCH_SIZES = [2]*FOLDS # SIZE = 1024\n\n# Experimental batch sizes for EfficientNetB1\nBATCH = 1\nBATCH_SIZES = [BATCH]*FOLDS # SIZE = 768\n\n# YG \n# NASNetLarge\n# BAD\n#BATCH_SIZES = [4]*FOLDS # for 768 - VERY LONG - ~3.5-4 hours per fold \n#BATCH_SIZES = [8]*FOLDS # for 768 - BAD - not enough resources\n# GOOD\n#BATCH_SIZES = [16]*FOLDS # for 384 - GOOD - ~1 hour per fold\n#BATCH_SIZES = [8]*FOLDS # for 512\n\n#EPOCHS = [12]*FOLDS\nEPOCH = 32\nEPOCHS = [EPOCH]*FOLDS\n\n# EfficientNet\n# WHICH EFFICIENTNET B? TO USE\nmodel_name = 'EfficientNet'\n#MODEL = 7 # EfficientNetB7\nMODEL = 0 # EfficientNetB3\n#MODEL = 0 # EfficientNetB0\nEFF_NETS = [MODEL]*FOLDS\nSPECIFIC_SIZE = SIZE\n\n# MobileNetV2\n#MODEL = 'MobileNetV2'\n#SPECIFIC_SIZE = SIZE\n\n#model_name = 'NASNetMobile'\n#MODEL = 'NASNetMobile'\n#SPECIFIC_SIZE = SIZE # 224 only at the moment!\n\n#model_name = 'NASNetLarge'\n#MODEL = 'NASNetLarge'\n#SPECIFIC_SIZE = SIZE # 331 only at the moment!\n\n# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST\nWGTS = [1\/FOLDS]*FOLDS\n\n# TEST TIME AUGMENTATION STEPS\nTTA = 11\n\n# make the weights and biases of the base model non-trainable\n# by \"freezing\" each layer of the BASE network\nTRAINABLE = True\n\nAUGMENTATION = True\n\nAUG_LOSSLESS = False","02afddae":"# Time estimation - 1 epoch\n\n# Model = EfficientNetB0\n# MODEL = 0\n\n########################################################\n# Image Size\n# SIZE = 1536\n# BATCH = 1\n\n# Fold Times:\n# FOLDS = 3\n# 1it [03:29, 209.24s\/it]\n# 2it [06:58, 209.25s\/it]\n# 3it [10:25, 208.61s\/it]\n# CPU times: user 2min 11s, sys: 13.6 s, total: 2min 25s\n# Wall time: 10min 25s\n\n# + 5 min for testing\n\n########################################################\n# Image Size\n# SIZE = 1024\n# BATCH = 8\n\n# CPU times: user 2min 18s, sys: 13.8 s, total: 2min 32s\n# Wall time: 6min 57s\n\n########################################################\n\n\n########################################################\n# Image Size\n# SIZE = 768\n# BATCH = 16\n\n# CPU times: user 2min 15s, sys: 12.9 s, total: 2min 28s\n# Wall time: 6min 20s\n","d1e394f5":"# Time estimation - 1 epoch\n\n# Model = EfficientNetB7\n# MODEL = 7\n\n######################################################## MIN\n# Image Size\n# SIZE = 128\n# BATCH = 32\n\n# CPU times: user 7min 4s, sys: 46.5 s, total: 7min 50s\n# Wall time: 13min 25s\n\n######################################################## MAX\n# Image Size\n# SIZE = 1024\n# BATCH = 1\n\n# CPU times: user 7min 19s, sys: 47.8 s, total: 8min 6s\n# Wall time: 18min 27s\n\n########################################################\n# Image Size\n# SIZE = 768\n# BATCH = 4\n\n# CPU times: user 7min 27s, sys: 49.2 s, total: 8min 16s\n# Wall time: 17min 40s\n\n########################################################\n# Image Size\n# SIZE = 512\n# BATCH = 16\n\n# CPU times: user 7min 11s, sys: 47.5 s, total: 7min 58s\n# Wall time: 15min 50s\n\n########################################################\n# Image Size\n# SIZE = 256\n# BATCH = 16\n\n# CPU times: user 4min 43s, sys: 40.4 s, total: 5min 24s\n# Wall time: 7min 9s\n\n########################################################\n# TRAINABLE = False\n########################################################\n# Image Size\n# SIZE = 256\n# BATCH = 16\n\n# CPU times: user 4min 51s, sys: 41.1 s, total: 5min 32s\n# Wall time: 7min 12s\n\n########################################################\n# TRAINABLE = False\n# AUGMENTATION = False\n########################################################\n# Image Size\n# SIZE = 256\n# BATCH = 16\n\n# CPU times: user 4min 35s, sys: 38.1 s, total: 5min 13s\n# Wall time: 6min 56s","632f294e":"if DEVICE == \"TPU\":\n    print(\"connecting to TPU...\")\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        print(\"Could not connect to TPU\")\n        tpu = None\n\n    if tpu:\n        try:\n            print(\"initializing  TPU ...\")\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print(\"TPU initialized\")\n        except _:\n            print(\"failed to initialize TPU\")\n    else:\n        DEVICE = \"GPU\"\n\nif DEVICE != \"TPU\":\n    print(\"Using default strategy for CPU and single GPU\")\n    strategy = tf.distribute.get_strategy()\n\nif DEVICE == \"GPU\":\n    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n    \n\nAUTO     = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')","fa301975":"! ls ..\/input\/lyme-disease-rashes-in-tfrecords","cadd8164":"print(KaggleDatasets().get_gcs_path('lyme-disease-rashes-in-tfrecords'))","ed002059":"%%time\n\nGCS_PATH = [None]*FOLDS \n#GCS_PATH2 = [None]*FOLDS\nfor i,k in enumerate(IMG_SIZES):\n    #GCS_PATH[i] = KaggleDatasets().get_gcs_path('melanoma-%ix%i'%(k,k))\n    #GCS_PATH2[i] = KaggleDatasets().get_gcs_path('isic2019-%ix%i'%(k,k))\n    GCS_PATH[i] = KaggleDatasets().get_gcs_path('lyme-disease-rashes-in-tfrecords')\n\nfiles_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '\/train_%d_*.tfrec'%SIZE)))\nfiles_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '\/test_%d_*.tfrec'%SIZE)))","1c1bb029":"files_train","97f04f48":"files_test","3acbff97":"ROT_ = 180.0\nSHR_ = 2.0\nHZOOM_ = 8.0\nWZOOM_ = 8.0\nHSHIFT_ = 8.0\nWSHIFT_ = 8.0","97156dd8":"def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n    # returns 3x3 transformmatrix which transforms indicies\n        \n    # CONVERT DEGREES TO RADIANS\n    rotation = math.pi * rotation \/ 180.\n    shear    = math.pi * shear    \/ 180.\n\n    def get_3x3_mat(lst):\n        return tf.reshape(tf.concat([lst],axis=0), [3,3])\n    \n    # ROTATION MATRIX\n    c1   = tf.math.cos(rotation)\n    s1   = tf.math.sin(rotation)\n    one  = tf.constant([1],dtype='float32')\n    zero = tf.constant([0],dtype='float32')\n    \n    rotation_matrix = get_3x3_mat([c1,   s1,   zero, \n                                   -s1,  c1,   zero, \n                                   zero, zero, one])    \n    # SHEAR MATRIX\n    c2 = tf.math.cos(shear)\n    s2 = tf.math.sin(shear)    \n    \n    shear_matrix = get_3x3_mat([one,  s2,   zero, \n                                zero, c2,   zero, \n                                zero, zero, one])        \n    # ZOOM MATRIX\n    zoom_matrix = get_3x3_mat([one\/height_zoom, zero,           zero, \n                               zero,            one\/width_zoom, zero, \n                               zero,            zero,           one])    \n    # SHIFT MATRIX\n    shift_matrix = get_3x3_mat([one,  zero, height_shift, \n                                zero, one,  width_shift, \n                                zero, zero, one])\n    \n    return K.dot(K.dot(rotation_matrix, shear_matrix), \n                 K.dot(zoom_matrix,     shift_matrix))\n\n\ndef transform(image, DIM=256):    \n    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n    # output - image randomly rotated, sheared, zoomed, and shifted\n    XDIM = DIM%2 #fix for size 331\n    \n    rot = ROT_ * tf.random.normal([1], dtype='float32')\n    shr = SHR_ * tf.random.normal([1], dtype='float32') \n    h_zoom = 1.0 + tf.random.normal([1], dtype='float32') \/ HZOOM_\n    w_zoom = 1.0 + tf.random.normal([1], dtype='float32') \/ WZOOM_\n    h_shift = HSHIFT_ * tf.random.normal([1], dtype='float32') \n    w_shift = WSHIFT_ * tf.random.normal([1], dtype='float32') \n\n    # GET TRANSFORMATION MATRIX\n    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n\n    # LIST DESTINATION PIXEL INDICES\n    x   = tf.repeat(tf.range(DIM\/\/2, -DIM\/\/2,-1), DIM)\n    y   = tf.tile(tf.range(-DIM\/\/2, DIM\/\/2), [DIM])\n    z   = tf.ones([DIM*DIM], dtype='int32')\n    idx = tf.stack( [x,y,z] )\n    \n    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n    idx2 = K.dot(m, tf.cast(idx, dtype='float32'))\n    idx2 = K.cast(idx2, dtype='int32')\n    idx2 = K.clip(idx2, -DIM\/\/2+XDIM+1, DIM\/\/2)\n    \n    # FIND ORIGIN PIXEL VALUES           \n    idx3 = tf.stack([DIM\/\/2-idx2[0,], DIM\/\/2-1+idx2[1,]])\n    d    = tf.gather_nd(image, tf.transpose(idx3))\n        \n    return tf.reshape(d,[DIM, DIM,3])","8e92dbcc":"def read_labeled_tfrecord(example):\n    tfrec_format = {\n        'image'                        : tf.io.FixedLenFeature([], tf.string),\n        'image_name'                   : tf.io.FixedLenFeature([], tf.string),\n        #'patient_id'                   : tf.io.FixedLenFeature([], tf.int64),\n        #'sex'                          : tf.io.FixedLenFeature([], tf.int64),\n        #'age_approx'                   : tf.io.FixedLenFeature([], tf.int64),\n        #'anatom_site_general_challenge': tf.io.FixedLenFeature([], tf.int64),\n        #'diagnosis'                    : tf.io.FixedLenFeature([], tf.int64),\n        'target'                       : tf.io.FixedLenFeature([], tf.int64)\n    }           \n    example = tf.io.parse_single_example(example, tfrec_format)\n    return example['image'], example['target']\n\n\ndef read_unlabeled_tfrecord(example, return_image_name):\n    tfrec_format = {\n        'image'                        : tf.io.FixedLenFeature([], tf.string),\n        'image_name'                   : tf.io.FixedLenFeature([], tf.string),\n    }\n    example = tf.io.parse_single_example(example, tfrec_format)\n    return example['image'], example['image_name'] if return_image_name else 0\n\n \ndef prepare_image(img, augment=True, aug_lossless=True, dim=256):    \n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.cast(img, tf.float32) \/ 255.0\n    \n    if augment:\n        if aug_lossless:\n            img = transform(img,DIM=dim)\n            img = tf.image.random_flip_left_right(img)\n            img = tf.image.random_flip_up_down(img)\n            img = tf.image.rot90(img, tf.random.uniform(shape=[], minval=0, maxval=3, dtype=tf.int32))\n        else:\n            img = transform(img,DIM=dim)\n            img = tf.image.random_flip_left_right(img)\n            img = tf.image.random_flip_up_down(img)\n            img = tf.image.rot90(img, tf.random.uniform(shape=[], minval=0, maxval=3, dtype=tf.int32))\n           \n            img = tf.image.random_hue(img, 0.01)\n            img = tf.image.random_saturation(img, 0.7, 1.3)\n            img = tf.image.random_contrast(img, 0.8, 1.2)\n            img = tf.image.random_brightness(img, 0.1)\n            img = tf.image.random_jpeg_quality(img, 75, 95)\n\n    # YG - just for adaptation to NASNet ... and other families\n#    else:\n#        if(MODEL == 'NASNetMobile' or MODEL == 'NASNetLarge'):\n#            img = transform(img,DIM=dim)    \n    \n    #img = cv2.resize(img, (dim, dim),interpolation = cv2.INTER_CUBIC)\n                              \n    img = tf.reshape(img, [dim,dim, 3])\n    #img = tf.image.resize(img, [224, 224, 3])\n            \n    return img\n\ndef count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) \n         for filename in filenames]\n    return np.sum(n)","b51ced06":"def get_dataset(files, augment = False, aug_lossless = True, shuffle = False, repeat = False, \n                labeled=True, return_image_names=True, batch_size=16, dim=256):\n    \n    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n    ds = ds.cache()\n    \n    if repeat:\n        ds = ds.repeat()\n    \n    if shuffle: \n        ds = ds.shuffle(1024*8)\n        opt = tf.data.Options()\n        opt.experimental_deterministic = False\n        ds = ds.with_options(opt)\n        \n    if labeled: \n        ds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n    else:\n        ds = ds.map(lambda example: read_unlabeled_tfrecord(example, return_image_names), \n                    num_parallel_calls=AUTO)      \n    \n    ds = ds.map(lambda img, imgname_or_label: (prepare_image(img, augment=augment, aug_lossless = aug_lossless, dim=dim), \n                                               imgname_or_label), \n                num_parallel_calls=AUTO)\n    \n    ds = ds.batch(batch_size * REPLICAS)\n    ds = ds.prefetch(AUTO)\n    return ds","de30c067":"# YG\n# These models HAVE PASSED the initial test!\n\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications import NASNetMobile\nfrom tensorflow.keras.applications import NASNetLarge\nfrom tensorflow.keras.applications import DenseNet121\n\nfrom tensorflow.keras.applications import EfficientNetB0\n\ndim=SPECIFIC_SIZE\n\n#if(model_name =='EfficientNet'):\n\n# These should be checked:\n#from tensorflow.keras.applications import InceptionV3\n#model_name = 'InceptionV3'\n#from tensorflow.keras.applications import InceptionResNetV2\n#model_name = 'InceptionResNetV2'\n#from tensorflow.keras.applications import MobileNetV2\n#model_name = 'MobileNetV2'\n#from tensorflow.keras.applications import ResNet101\n#model_name = 'ResNet101'\n#from tensorflow.keras.applications import ResNet101V2\n#model_name = 'ResNet101V2'\n#from tensorflow.keras.applications import VGG16\n#model_name = 'VGG16'\n#from tensorflow.keras.applications import Xception\n#model_name = 'Xception'\n\n\n\ndef build_model(model_name=model_name, dim=SPECIFIC_SIZE, trainable=False):\n    inp = tf.keras.layers.Input(shape=(dim,dim,3))\n    \n    if(model_name =='EfficientNet'):\n#        EFNS = [efn.EfficientNetB0, efn.EfficientNetB1, efn.EfficientNetB2, efn.EfficientNetB3, \n#            efn.EfficientNetB4, efn.EfficientNetB5, efn.EfficientNetB6, efn.EfficientNetB7]\n#        base = EFNS[MODEL](input_shape=(dim,dim,3),weights='imagenet',include_top=False)\n        if(MODEL==0):\n            base = EfficientNetB0(input_shape=(dim,dim,3),weights='imagenet',include_top=False)\n            model_name = 'EfficientNetB' + str(MODEL)\n        else:\n            print('ERROR: This code is prepared for EfficientNetB, version' + str(MODEL) + ', BUT other version is used!')\n        \n    if(model_name =='MobileNetV2'):\n        base = MobileNetV2(input_shape=(dim,dim,3),weights='imagenet',include_top=False)\n    \n    if(model_name =='NASNetMobile'):\n        base = NASNetMobile(input_shape=(dim,dim,3),weights='imagenet',include_top=False)\n\n    if(model_name =='NASNetLarge'):    \n        base = NASNetLarge(input_shape=(dim,dim,3),weights='imagenet',include_top=False)    \n\n    if(model_name == 'DenseNet121'):\n        base = DenseNet121(input_shape=(dim,dim,3),weights='imagenet',include_top=False)       \n    \n    # make the weights and biases of the base model non-trainable\n    # by \"freezing\" each layer of the BASE network\n    for layer in base.layers:\n        layer.trainable = trainable\n\n    x = base(inp)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n    model = tf.keras.Model(inputs=inp,outputs=x)\n    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.05) \n    model.compile(optimizer=opt,loss=loss,metrics=['AUC'])\n    return model","369263e5":"def get_lr_callback(batch_size=8):\n    lr_start   = 0.000005\n    lr_max     = 0.00000125 * REPLICAS * batch_size\n    lr_min     = 0.000001\n    lr_ramp_ep = 5\n    lr_sus_ep  = 0\n    lr_decay   = 0.8\n   \n    def lrfn(epoch):\n        if epoch < lr_ramp_ep:\n            lr = (lr_max - lr_start) \/ lr_ramp_ep * epoch + lr_start\n            \n        elif epoch < lr_ramp_ep + lr_sus_ep:\n            lr = lr_max\n            \n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n            \n        return lr\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n    return lr_callback","62d7444a":"from tqdm import tqdm","8ea5e633":"! nvidia-smi","f8145ee5":"%%time\n# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit\nVERBOSE = 1\nDISPLAY_PLOT = True\n\nskf = KFold(n_splits=FOLDS,shuffle=True,random_state=SEED)\noof_pred = []; oof_tar = []; oof_val = []; oof_names = []; oof_folds = [] \npreds = np.zeros((count_data_items(files_test),1))\n\nfor fold,(idxT,idxV) in tqdm(enumerate(skf.split(np.arange(14)))):\n    \n    # DISPLAY FOLD INFO\n    if DEVICE=='TPU':\n        if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n    print('#'*25); print('#### FOLD',fold+1)\n# YG    \n#    print('#### Image Size %i with EfficientNet B%i and batch_size %i'%\n#          (IMG_SIZES[fold],EFF_NETS[fold],BATCH_SIZES[fold]*REPLICAS))\n    print('#### Image Size %i with %s and batch_size %i'%\n          (IMG_SIZES[fold],model_name,BATCH_SIZES[fold]*REPLICAS))\n    \n    # CREATE TRAIN AND VALIDATION SUBSETS\n    #files_train = tf.io.gfile.glob([GCS_PATH[fold] + '\/train%.2i*.tfrec'%x for x in idxT])\n    print('SIZE:',SIZE)\n    filename_core = GCS_PATH[fold] + '\/train_%i_'%(SIZE)\n    files_train = tf.io.gfile.glob([filename_core + '%.2i*.tfrec'%x for x in idxT])\n    #print([GCS_PATH[fold]])\n    #print([GCS_PATH[fold] + '\/train_128_%.2i*.tfrec'%x for x in idxT])\n    print('Files for TRAIN:')\n    print(files_train)\n\n#    if INC2019[fold]:\n#        files_train += tf.io.gfile.glob([GCS_PATH2[fold] + '\/train%.2i*.tfrec'%x for x in idxT*2+1])\n#        print('#### Using 2019 external data')\n#    if INC2018[fold]:\n#        files_train += tf.io.gfile.glob([GCS_PATH2[fold] + '\/train%.2i*.tfrec'%x for x in idxT*2])\n#        print('#### Using 2018+2017 external data')\n        \n    np.random.shuffle(files_train); print('#'*25)\n    \n    filename_core = GCS_PATH[fold] + '\/train_%i_'%(SIZE)\n    files_valid = tf.io.gfile.glob([filename_core + '%.2i*.tfrec'%x for x in idxV])\n    print('Files for VALIDATION:')\n    print(files_valid)\n    \n    files_test = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[fold] + '\/test_%i_*.tfrec'%(SIZE))))\n    print('Files for TEST:')\n    print(files_test)\n    \n    # BUILD MODEL\n    K.clear_session()\n    with strategy.scope():\n        model = build_model(model_name=model_name, dim=SPECIFIC_SIZE, trainable=TRAINABLE)   \n        model.summary() # YG\n        \n    # SAVE BEST MODEL EACH FOLD\n    sv = tf.keras.callbacks.ModelCheckpoint(\n        DEVICE + '_' + str(MODEL) + '_' + str(SIZE) + '_fold-%i.h5'%fold, monitor='val_loss', verbose=0, save_best_only=True,\n        save_weights_only=True, mode='min', save_freq='epoch')\n   \n    # TRAIN\n    print('Training...')\n    history = model.fit(\n        get_dataset(files_train, augment=True, aug_lossless = AUG_LOSSLESS, shuffle=True, repeat=True,\n                    #dim=IMG_SIZES[fold], \n                    dim=SPECIFIC_SIZE, batch_size = BATCH_SIZES[fold]), \n        epochs=EPOCHS[fold], callbacks = [sv,get_lr_callback(BATCH_SIZES[fold])], \n        steps_per_epoch=count_data_items(files_train)\/BATCH_SIZES[fold]\/\/REPLICAS,\n        validation_data=get_dataset(files_valid,augment=False,shuffle=False,\n                repeat=False,\n                #dim=IMG_SIZES[fold]\n                dim=SPECIFIC_SIZE), #class_weight = {0:1,1:2},\n        verbose=VERBOSE\n    )\n    \n    print('Loading best model...')\n    model.load_weights(DEVICE + '_' + str(MODEL) + '_' + str(SIZE) + '_fold-%i.h5'%fold)\n    \n    # PREDICT OOF USING TTA\n    print('Predicting OOF with TTA...')\n    ds_valid = get_dataset(files_valid,labeled=False, return_image_names=False,\n                           augment=AUGMENTATION, aug_lossless = AUG_LOSSLESS, \n            repeat=True,shuffle=False,dim=SPECIFIC_SIZE,                        \n            #dim=IMG_SIZES[fold],\n            batch_size=BATCH_SIZES[fold]*4)\n    ct_valid = count_data_items(files_valid); STEPS = TTA * ct_valid\/BATCH_SIZES[fold]\/4\/REPLICAS\n    pred = model.predict(ds_valid,steps=STEPS,verbose=VERBOSE)[:TTA*ct_valid,] \n    oof_pred.append( np.mean(pred.reshape((ct_valid,TTA),order='F'),axis=1) )                 \n    #oof_pred.append(model.predict(get_dataset(files_valid,dim=IMG_SIZES[fold]),verbose=1))\n    \n    # GET OOF TARGETS AND NAMES\n    ds_valid = get_dataset(files_valid, \n                           augment=False, aug_lossless = False, \n                           repeat=False, dim=SPECIFIC_SIZE,                        \n            #dim=IMG_SIZES[fold],\n            labeled=True, return_image_names=True)\n    oof_tar.append( np.array([target.numpy() for img, target in iter(ds_valid.unbatch())]) )\n    oof_folds.append( np.ones_like(oof_tar[-1],dtype='int8')*fold )\n    ds = get_dataset(files_valid, \n                     augment=False, aug_lossless = False, \n                     repeat=False, dim=SPECIFIC_SIZE,\n                     #dim=IMG_SIZES[fold],\n                labeled=False, return_image_names=True)\n    oof_names.append( np.array([img_name.numpy().decode(\"utf-8\") for img, img_name in iter(ds.unbatch())]))\n    \n    # PREDICT TEST USING TTA\n    print('Predicting Test with TTA...')\n    ds_test = get_dataset(files_test,labeled=False,return_image_names=False,\n                          augment=True, aug_lossless = AUG_LOSSLESS, \n            repeat=True,shuffle=False,dim=SPECIFIC_SIZE,                        \n            #dim=IMG_SIZES[fold],\n            batch_size=BATCH_SIZES[fold]*4)\n    ct_test = count_data_items(files_test); STEPS = TTA * ct_test\/BATCH_SIZES[fold]\/4\/REPLICAS\n    pred = model.predict(ds_test,steps=STEPS,verbose=VERBOSE)[:TTA*ct_test,] \n    preds[:,0] += np.mean(pred.reshape((ct_test,TTA),order='F'),axis=1) * WGTS[fold]\n    \n    # REPORT RESULTS\n    ### BUG - YG\n    list_length = min(len(oof_tar[-1]),len(oof_pred[-1]))\n    \n    auc = roc_auc_score(oof_tar[-1][:list_length],oof_pred[-1][:list_length])\n    oof_val.append(np.max( history.history['val_auc'] ))\n    print('#### FOLD %i OOF AUC without TTA = %.3f, with TTA = %.3f'%(fold+1,oof_val[-1],auc))\n    \n    # PLOT TRAINING\n    if DISPLAY_PLOT:\n        plt.figure(figsize=(15,5))\n        plt.plot(np.arange(EPOCHS[fold]),history.history['auc'],'-o',label='Train AUC',color='#ff7f0e')\n        plt.plot(np.arange(EPOCHS[fold]),history.history['val_auc'],'-o',label='Val AUC',color='#1f77b4')\n        x = np.argmax( history.history['val_auc'] ); y = np.max( history.history['val_auc'] )\n        xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n        plt.scatter(x,y,s=200,color='#1f77b4'); plt.text(x-0.03*xdist,y-0.13*ydist,'max auc\\n%.2f'%y,size=14)\n        plt.ylabel('AUC',size=14); plt.xlabel('Epoch',size=14)\n        plt.legend(loc=2)\n        plt2 = plt.gca().twinx()\n        plt2.plot(np.arange(EPOCHS[fold]),history.history['loss'],'-o',label='Train Loss',color='#2ca02c')\n        plt2.plot(np.arange(EPOCHS[fold]),history.history['val_loss'],'-o',label='Val Loss',color='#d62728')\n        x = np.argmin( history.history['val_loss'] ); y = np.min( history.history['val_loss'] )\n        ydist = plt.ylim()[1] - plt.ylim()[0]\n        plt.scatter(x,y,s=200,color='#d62728'); plt.text(x-0.03*xdist,y+0.05*ydist,'min loss',size=14)\n        plt.ylabel('Loss',size=14)\n# YG        \n#        plt.title('FOLD %i - Image Size %i, EfficientNet B%i, inc2019=%i, inc2018=%i'%\n#                (fold+1,IMG_SIZES[fold],EFF_NETS[fold],INC2019[fold],INC2018[fold]),size=18)\n#        plt.title('FOLD %i - Image Size %i, %s, inc2019=%i, inc2018=%i'%\n#                (fold+1,IMG_SIZES[fold],model_name,INC2019[fold],INC2018[fold]),size=18)\n        plt.title('FOLD %i - Image Size %i, %s, Device=%s, TTA=%i'%\n                (fold+1,IMG_SIZES[fold],model_name,DEVICE,TTA),size=18)\n\n\n        plt.legend(loc=3)\n        plt.savefig('AUC_' + DEVICE + '_model' + str(MODEL) + '_' + str(SIZE) + '_fold' + str(fold) + '.png' ,bbox_inches='tight', dpi=300)\n        plt.show()  ","5c761a2e":"# COMPUTE OVERALL OOF AUC\noof = np.concatenate(oof_pred); true = np.concatenate(oof_tar);\nnames = np.concatenate(oof_names); folds = np.concatenate(oof_folds)\n\n### BUG - YG\nlist_length = min(len(true),len(oof))\n\nauc = roc_auc_score(true[:list_length],oof[:list_length])\nprint('Overall OOF AUC with TTA = %.3f'%auc)\n\n# SAVE OOF TO DISK\ndf_oof = pd.DataFrame(dict(\n    image_name = names, target=true[:list_length], pred = oof[:list_length], fold=folds))\ndf_oof.to_csv(DEVICE + '_' + str(MODEL) + '_oof.csv',index=False)\ndf_oof.tail()","28c381da":"import time\nimport statistics\n\nVERBOSE = 1","d42f5437":"%%time\n\ndef AUC_time(print_verbose=False, augment=True, aug_lossless = True, TTA=1):\n\n    predict_time_list = []\n    AUC_list = []\n\n    oof_pred = []; oof_tar = []\n\n    for fold,(idxT,idxV) in enumerate(skf.split(np.arange(15))):\n        if print_verbose: print('Fold %i. Loading the current fold model...'%fold)\n        model.load_weights(DEVICE + '_' + str(MODEL) + '_' + str(SIZE) + '_fold-%i.h5'%fold)\n        #model.load_weights(DEVICE + '_fold-%i.h5'%fold)\n\n        # PREDICT with TTA # augment=True, aug_lossless = True,\n        ds_valid = get_dataset(files_valid,labeled=False,return_image_names=False,\n                           augment=True, aug_lossless = True,\n                           repeat=True,shuffle=False,dim=SPECIFIC_SIZE,\n                           #dim=IMG_SIZES[fold],\n                           batch_size=BATCH_SIZES[fold]*4)\n        ct_valid = count_data_items(files_valid); STEPS = TTA * ct_valid\/BATCH_SIZES[fold]\/4\/REPLICAS\n        if print_verbose: print('Predicting Test with TTA_LL for %i files...'%(ct_valid))     \n    \n        # Start timer\n        ts_eval = time.time()\n        pred = model.predict(ds_valid,steps=STEPS,verbose=VERBOSE)[:TTA*ct_valid,] \n        # End timer\n        te_eval = time.time()\n    \n        test_time = (te_eval-ts_eval)\/ct_valid\n        predict_time_list.append(test_time)\n        if print_verbose: print('Fold %i, test_time=%.6f seconds.'%(fold,test_time))\n    \n        # Add predictions to list\n        oof_pred.append( np.mean(pred.reshape((ct_valid,TTA),order='F'),axis=1) )     \n        # GET OOF TARGETS AND NAMES\n        ds_valid = get_dataset(files_valid, augment=False, aug_lossless = True, repeat=False,dim=SPECIFIC_SIZE,\n                           #dim=IMG_SIZES[fold],\n            labeled=True, return_image_names=True)\n        # Add targets to list\n        oof_tar.append( np.array([target.numpy() for img, target in iter(ds_valid.unbatch())]) )    \n        # Calculate AUC\n        auc = roc_auc_score(oof_tar[-1],oof_pred[-1])\n        # Add AUC to list\n        AUC_list.append(auc)\n        if print_verbose: print('Fold %i, AUC=%.6f'%(fold,auc))\n\n    # Calculate AUC mean value to list \n    AUC_mean = statistics.mean(AUC_list) # mean\n    # Calculate AUC standard deviation value to list\n    AUC_std = statistics.stdev(AUC_list) # standard devition\n    print('#### TTA = %d'%TTA)\n    print('#### OOF AUC with TTA_LL: mean = %.6f, stdev = %.6f.'%(AUC_mean,AUC_std))\n\n    # Add AUC mean value to list \n    predict_time_mean = statistics.mean(predict_time_list) # mean\n    # Add AUC standard deviation value to list\n    predict_time_std = statistics.stdev(predict_time_list) # standard devition\n    print('#### Time without TTA_LL: mean = %.6f, stdev = %.6f seconds.'%(predict_time_mean,predict_time_std)) \n    \n    return AUC_mean, AUC_std, predict_time_mean, predict_time_std","81743e4c":"%%time\n\n# _withTTA_LL_\n\nVERBOSE = 0\n\nTTA_list = [1,2,4,8,16,32,64,128]\n\nwithTTA_LL_AUC_mean_list = []\nwithTTA_LL_AUC_std_list = []\n\nwithTTA_LL_time_mean_list = []\nwithTTA_LL_time_std_list = []\n\nfor i in tqdm(TTA_list):\n    AUC_mean, AUC_std, predict_time_mean, predict_time_std = AUC_time(print_verbose=False,augment=True, aug_lossless = True, TTA=i)\n    \n    withTTA_LL_AUC_mean_list.append(AUC_mean)\n    withTTA_LL_AUC_std_list.append(AUC_std) \n    withTTA_LL_time_mean_list.append(predict_time_mean)\n    withTTA_LL_time_std_list.append(predict_time_std)","54a29cd9":"# PLOT: AUC - withTTA_LL\nplt.style.use('seaborn-whitegrid')\nplt.figure(figsize=(10,5))\n#plt.plot(TTA_list,withTTA_LL_AUC_mean_list,'-o',label='AUC mean',color='#ff7f0e')\nplt.errorbar(np.log2(TTA_list),withTTA_LL_AUC_mean_list,yerr=withTTA_LL_AUC_std_list, fmt='-o', label='AUC mean',color='#1f77b4');\n#plt.plot(TTA_list,withTTA_LL_AUC_std_list,'-o',label='AUC std',color='#1f77b4')\nx = np.argmax(withTTA_LL_AUC_mean_list); y = np.max(withTTA_LL_AUC_mean_list)\nxdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\nplt.scatter(x,y,s=200,color='red'); plt.text(x-0.03*xdist,y-0.13*ydist,'max auc\\n%.3f'%y,size=14,color='red')\nplt.ylabel('AUC',size=14); plt.xlabel('log2(TTA steps)',size=14)\nplt.title('withTTA_LL, Image Size=%i, %s, Device=%s, Epochs=%i'%\n                (IMG_SIZES[fold],model_name,DEVICE,EPOCH),size=14)\n#plt.legend(loc='best')\nplt.savefig('AUC_' + 'withTTA_LL' + DEVICE + '_' + str(MODEL) + '_' + str(SIZE) + '_ep' + str(EPOCH) + '.png' ,bbox_inches='tight', dpi=300)\nplt.show()  ","91743af3":"# PLOT: PREDICTION TIME - withTTA_LL\nplt.style.use('seaborn-whitegrid')\nplt.figure(figsize=(10,5))\n#plt.plot(TTA_list,withTTA_LL_AUC_mean_list,'-o',label='AUC mean',color='#ff7f0e')\nplt.errorbar(TTA_list,withTTA_LL_time_mean_list,yerr=withTTA_LL_time_std_list, fmt='-o', label='lossless',color='#1f77b4');\n#plt.plot(TTA_list,withTTA_LL_AUC_std_list,'-o',label='AUC std',color='#1f77b4')\nx = np.argmin(withTTA_LL_time_mean_list); y = np.min(withTTA_LL_time_mean_list)\nxdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\nplt.scatter(x,y,s=200,color='red'); plt.text(x-0.03*xdist,y-0.13*ydist,'min time\\n%.3f'%y,size=14,color='red')\nplt.ylabel('Prediction Time',size=14); plt.xlabel('TTA steps',size=14)\nplt.title('withTTA_LL, Image Size=%i, %s, Device=%s, Epochs=%i'%\n                (IMG_SIZES[fold],model_name,DEVICE,EPOCH),size=14)\n#plt.legend(loc='best')\nplt.savefig('TIME_' + 'withTTA_LL' + '_' + DEVICE + '_' + str(MODEL) + '_' + str(SIZE) + '_ep' + str(EPOCH) + '.png' ,bbox_inches='tight', dpi=300)\nplt.show()  ","f5f4538c":"%%time\n\n# withTTA_\n\nVERBOSE = 0\n\nTTA_list = [1,2,4,8,16,32,64,128]\n\nwithTTA_AUC_mean_list = []\nwithTTA_AUC_std_list = []\n\nwithTTA_time_mean_list = []\nwithTTA_time_std_list = []\n\nfor i in tqdm(TTA_list):\n    AUC_mean, AUC_std, predict_time_mean, predict_time_std = AUC_time(print_verbose=False, augment=True, aug_lossless = False, TTA=i)\n    \n    withTTA_AUC_mean_list.append(AUC_mean)\n    withTTA_AUC_std_list.append(AUC_std) \n    withTTA_time_mean_list.append(predict_time_mean)\n    withTTA_time_std_list.append(predict_time_std)","27c8cc76":"# PLOT: AUC - withTTA_LL\nplt.style.use('seaborn-whitegrid')\nplt.figure(figsize=(10,5))\n#plt.plot(TTA_list,withTTA_LL_AUC_mean_list,'-o',label='AUC mean',color='#ff7f0e')\nplt.errorbar(np.log2(TTA_list),withTTA_AUC_mean_list,yerr=withTTA_AUC_std_list, fmt='-o', label='full',color='#1f77b4');\n#plt.plot(TTA_list,withTTA_LL_AUC_std_list,'-o',label='AUC std',color='#1f77b4')\nx = np.argmax(withTTA_AUC_mean_list); y = np.max(withTTA_AUC_mean_list)\nxdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\nplt.scatter(x,y,s=200,color='red'); plt.text(x-0.03*xdist,y-0.13*ydist,'max auc\\n%.3f'%y,size=14,color='red')\nplt.ylabel('AUC',size=14); plt.xlabel('log2(TTA steps)',size=14)\nplt.title('withTTA_full, Image Size=%i, %s, Device=%s, Epochs=%i'%\n                (IMG_SIZES[fold],model_name,DEVICE,EPOCH),size=14)\n#plt.legend(loc='best')\nplt.savefig('AUC_' + 'withTTA_full' + '_' + DEVICE + '_' + str(MODEL) + '_' + str(SIZE) + '_ep' + str(EPOCH) + '.png' ,bbox_inches='tight', dpi=300)\nplt.show()  ","fd29ba2b":"# PLOT: PREDICTION TIME - withTTA_LL\nplt.style.use('seaborn-whitegrid')\nplt.figure(figsize=(10,5))\n#plt.plot(TTA_list,withTTA_LL_AUC_mean_list,'-o',label='AUC mean',color='#ff7f0e')\nplt.errorbar(TTA_list,withTTA_time_mean_list,yerr=withTTA_time_std_list, fmt='-o', label='full',color='#1f77b4');\n#plt.plot(TTA_list,withTTA_LL_AUC_std_list,'-o',label='AUC std',color='#1f77b4')\nx = np.argmin(withTTA_LL_time_mean_list); y = np.min(withTTA_LL_time_mean_list)\nxdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\nplt.scatter(x,y,s=200,color='red'); plt.text(x-0.03*xdist,y-0.13*ydist,'min time\\n%.3f'%y,size=14,color='red')\nplt.ylabel('Prediction Time',size=14); plt.xlabel('TTA steps',size=14)\nplt.title('withTTA, Image Size=%i, %s, Device=%s, Epochs=%i'%\n                (IMG_SIZES[fold],model_name,DEVICE,EPOCH),size=14)\n#plt.legend(loc='best')\nplt.savefig('TIME_' + 'withTTA_full' + '_' + DEVICE + '_' + str(MODEL) + '_' + str(SIZE) + '_ep' + str(EPOCH) + '.png' ,bbox_inches='tight', dpi=300)\nplt.show()  ","8d780450":"# PLOT: AUC - withTTA_LL - lossless\nplt.style.use('seaborn-whitegrid')\nplt.figure(figsize=(10,5))\n#plt.plot(TTA_list,withTTA_LL_AUC_mean_list,'-o',label='AUC mean',color='#ff7f0e')\nplt.errorbar(np.log2(TTA_list),withTTA_LL_AUC_mean_list,yerr=withTTA_LL_AUC_std_list, fmt='-o', label='lossless',color='blue');\n#plt.plot(TTA_list,withTTA_LL_AUC_std_list,'-o',label='AUC std',color='#1f77b4')\nx = np.argmax(withTTA_LL_AUC_mean_list); y = np.max(withTTA_LL_AUC_mean_list)\n\nwithTTA_LL_AUC_mean_max = np.max(withTTA_LL_AUC_mean_list)\nwithTTA_LL_AUC_std_max = withTTA_LL_AUC_std_list[np.argmax(withTTA_LL_AUC_mean_list)]\nwithTTA_LL_AUC_mean_TTA = np.argmax(withTTA_LL_AUC_mean_list)\nprint('i=%d,'%withTTA_LL_AUC_mean_TTA, 'withTTA_LL_AUC_max=%.3f'%withTTA_LL_AUC_mean_max, '(+-%.3f)'%withTTA_LL_AUC_std_max)\n\nxdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\nplt.scatter(x,y,s=200,color='red'); plt.text(x-0.03*xdist,y-0.13*ydist,'max auc\\n%.3f'%y,size=14,color='blue')\n\n# PLOT: AUC - withTTA - full\nplt.errorbar(np.log2(TTA_list),withTTA_AUC_mean_list,yerr=withTTA_AUC_std_list, fmt='-o', label='full',color='green');\n#plt.plot(TTA_list,withTTA_LL_AUC_std_list,'-o',label='AUC std',color='#1f77b4')\nx = np.argmax(withTTA_AUC_mean_list); y = np.max(withTTA_AUC_mean_list)\n\nwithTTA_AUC_mean_max = np.max(withTTA_AUC_mean_list)\nwithTTA_AUC_std_max = withTTA_AUC_std_list[np.argmax(withTTA_AUC_mean_list)]\nwithTTA_AUC_mean_TTA = np.argmax(withTTA_AUC_mean_list)\nprint('i=%d,'%withTTA_AUC_mean_TTA, 'withTTA_AUC_max=%.3f'%withTTA_AUC_mean_max, '(+-%.3f)'%withTTA_AUC_std_max)\n\nxdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\nplt.scatter(x,y,s=200,color='red'); plt.text(x-0.03*xdist,y-0.13*ydist,'max auc\\n%.3f'%y,size=14,color='green')\n\nplt.ylabel('AUC',size=14); plt.xlabel('log2(TTA steps)',size=14)\nplt.title('Image Size=%i, %s, Device=%s, Epochs=%i'%\n                (IMG_SIZES[fold],model_name,DEVICE,EPOCH),size=14)\nplt.legend(loc='best')\nplt.savefig('AUC_both_TTA_' + DEVICE + '_' + str(MODEL) + '_' + str(SIZE) + '_ep' + str(EPOCH) + '.png' ,bbox_inches='tight', dpi=300)\nplt.show()  ","1dba73c7":"# PLOT: PREDICTION TIME - withTTA_LL - lossless\nplt.style.use('seaborn-whitegrid')\nplt.figure(figsize=(10,5))\n#plt.plot(TTA_list,withTTA_LL_AUC_mean_list,'-o',label='AUC mean',color='#ff7f0e')\nplt.errorbar(TTA_list,withTTA_LL_time_mean_list,yerr=withTTA_LL_time_std_list, fmt='-o', label='lossless',color='blue');\n#plt.plot(TTA_list,withTTA_LL_AUC_std_list,'-o',label='AUC std',color='#1f77b4')\nx = np.argmin(withTTA_LL_time_mean_list); y = np.min(withTTA_LL_time_mean_list)\n\nwithTTA_LL_time_mean_max = withTTA_LL_time_mean_list[np.argmax(withTTA_LL_AUC_mean_list)]\nwithTTA_LL_time_std_max = withTTA_LL_time_std_list[np.argmax(withTTA_LL_AUC_mean_list)]\nwithTTA_LL_time_mean_TTA = np.argmax(withTTA_LL_AUC_mean_list)\nprint('i=%d,'%withTTA_LL_time_mean_TTA, 'withTTA_LL_time_mean_max=%.3f'%withTTA_LL_time_mean_max, '(+-%.3f)'%withTTA_LL_time_std_max)\n\nxdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\nplt.scatter(x,y,s=200,color='red'); plt.text(x-0.03*xdist,y-0.13*ydist,'min time\\n%.3f'%y,size=14,color='blue')\n\n# PLOT: PREDICTION TIME - withTTA - full\nplt.errorbar(TTA_list,withTTA_time_mean_list,yerr=withTTA_time_std_list, fmt='-o', label='full',color='green');\n#plt.plot(TTA_list,withTTA_LL_AUC_std_list,'-o',label='AUC std',color='#1f77b4')\nx = np.argmin(withTTA_time_mean_list); y = np.min(withTTA_time_mean_list)\n\nwithTTA_time_mean_max = withTTA_time_mean_list[np.argmax(withTTA_AUC_mean_list)]\nwithTTA_time_std_max = withTTA_time_std_list[np.argmax(withTTA_AUC_mean_list)]\nwithTTA_time_mean_TTA = np.argmax(withTTA_AUC_mean_list)\nprint('i=%d,'%withTTA_time_mean_TTA, 'withTTA_time_mean_max=%.3f'%withTTA_time_mean_max, '(+-%.3f)'%withTTA_time_std_max)\n\nxdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\nplt.scatter(x,y,s=200,color='red'); plt.text(x-0.03*xdist,y+0.1*ydist,'min time\\n%.3f'%y,size=14,color='green')\n\nplt.ylabel('Prediction Time',size=14); plt.xlabel('TTA steps',size=14)\nplt.title('withTTA_LL, Image Size=%i, %s, Device=%s, Epochs=%i'%\n                (IMG_SIZES[fold],model_name,DEVICE,EPOCH),size=14)\nplt.legend(loc='best')\nplt.savefig('TIME_both_TTA_' + DEVICE + '_' + str(MODEL) + '_' + str(SIZE) + '_ep' + str(EPOCH) + '.png' ,bbox_inches='tight', dpi=300)\nplt.show()  ","dfcd52ba":"%%time\n\nTTA = 1\npredict_woTTA_time_list = []\nAUC_woTTA_list = []\n\noof_pred = []; oof_tar = []\n\nfor fold,(idxT,idxV) in enumerate(skf.split(np.arange(15))):\n    print('Fold %i. Loading the current fold model...'%fold)\n    model.load_weights(DEVICE + '_' + str(MODEL) + '_' + str(SIZE) + '_fold-%i.h5'%fold)\n    #model.load_weights(DEVICE + '_fold-%i.h5'%fold)\n\n    # PREDICT without TTA # augment=False\n    ds_valid = get_dataset(files_valid,labeled=False,return_image_names=False,augment=False,\n            repeat=True,shuffle=False,dim=SPECIFIC_SIZE,\n                           #dim=IMG_SIZES[fold],\n                           batch_size=BATCH_SIZES[fold]*4)\n    ct_valid = count_data_items(files_valid); STEPS = TTA * ct_valid\/BATCH_SIZES[fold]\/4\/REPLICAS\n    print('Predicting Test without TTA for %i files...'%(ct_valid))     \n    \n    # Start timer\n    ts_eval = time.time()\n    pred = model.predict(ds_valid,steps=STEPS,verbose=VERBOSE)[:TTA*ct_valid,] \n    # End timer\n    te_eval = time.time()\n    \n    test_time = (te_eval-ts_eval)\/ct_valid\n    predict_woTTA_time_list.append(test_time)\n    print('Fold %i, test_time=%.6f seconds.'%(fold,test_time))\n    \n    # Add predictions to list\n    oof_pred.append( np.mean(pred.reshape((ct_valid,TTA),order='F'),axis=1) )     \n    # GET OOF TARGETS AND NAMES\n    ds_valid = get_dataset(files_valid, augment=False, repeat=False,dim=SPECIFIC_SIZE,\n                           #dim=IMG_SIZES[fold],\n            labeled=True, return_image_names=True)\n    # Add targets to list\n    oof_tar.append( np.array([target.numpy() for img, target in iter(ds_valid.unbatch())]) )    \n    # Calculate AUC\n    auc = roc_auc_score(oof_tar[-1],oof_pred[-1])\n    # Add AUC to list\n    AUC_woTTA_list.append(auc)\n    print('Fold %i, AUC=%.6f'%(fold,auc))\n\n# Calculate AUC mean value to list \nAUC_woTTA_mean = statistics.mean(AUC_woTTA_list) # mean\n# Calculate AUC standard deviation value to list\nAUC_woTTA_std = statistics.stdev(AUC_woTTA_list) # standard devition\nprint('#### OOF AUC without TTA: mean = %.6f, stdev = %.6f.'%(AUC_woTTA_mean,AUC_woTTA_std))\n\n# Add AUC mean value to list \npredict_woTTA_time_mean = statistics.mean(predict_woTTA_time_list) # mean\n# Add AUC standard deviation value to list\npredict_woTTA_time_std = statistics.stdev(predict_woTTA_time_list) # standard devition\nprint('#### Time without TTA: mean = %.6f, stdev = %.6f seconds.'%(predict_woTTA_time_mean,predict_woTTA_time_std))","6fea9b28":"import os\nmodel_size = os.path.getsize(DEVICE + '_' + str(MODEL) + '_' + str(SIZE) + '_fold-0.h5') # >> 20\nprint(str(model_size) + ' Bytes')","e595f2b1":"results = pd.DataFrame(data=[[MODEL, model_size, TRAINABLE, AUGMENTATION, AUG_LOSSLESS,\n                              EPOCHS[0], SIZE,\n                              withTTA_LL_time_mean_max, withTTA_LL_time_std_max, withTTA_LL_AUC_mean_max, withTTA_LL_AUC_std_max,\n                              withTTA_time_mean_max, withTTA_time_std_max, withTTA_AUC_mean_max, withTTA_AUC_std_max,\n                              predict_woTTA_time_mean, predict_woTTA_time_std, AUC_woTTA_mean, AUC_woTTA_std]],\n                       columns=['model', 'model_size', 'trainable', 'augmentation', 'aug_lossless',\n                                'epochs', 'image_size',\n                                'TTA_LL_time_mean','TTA_LL_time_std','TTA_LL_AUC_mean','TTA_LL_AUC_std',\n                                'TTA_time_mean','TTA_time_std','TTA_AUC_mean','TTA_AUC_std',\n                                'woTTA_time_mean','woTTA_time_std', 'woTTA_AUC_mean', 'woTTA_AUC_std'])\nexperiment_title = DEVICE + '_' + str(MODEL) + '_s' + str(SIZE) + '_ep' + str(EPOCHS[0]) + '_train' + str(TRAINABLE) + '_aug' + str(AUGMENTATION) + '_loss' + str(AUG_LOSSLESS) + '_time_AUC'\nresults.to_csv(experiment_title + '.csv', index=False)\nresults.head()","38f10a19":"!ls -all","df4f2e6b":"from zipfile import ZipFile\nfrom os.path import basename\n\n# Zip the files from given directory that matches the filter\ndef zipFilesInDir(dirName, zipFileName, filter):\n   # create a ZipFile object\n   with ZipFile(zipFileName, 'w') as zipObj:\n       # Iterate over all the files in directory\n       for folderName, subfolders, filenames in os.walk(dirName):\n           for filename in filenames:\n               if filter(filename):\n                   # create complete filepath of file in directory\n                   filePath = os.path.join(folderName, filename)\n                   # Add file to zip\n                   zipObj.write(filePath, basename(filePath))\nprint('*** Create a zip archive of *.png *.ipynb *.csv files form a directory ***')\nzipFilesInDir('.', experiment_title+'_csv_.zip', lambda name : 'csv' in name)\nzipFilesInDir('.', experiment_title+'_ipynb_.zip', lambda name : 'ipynb' in name)\nzipFilesInDir('.', experiment_title+'_png_.zip', lambda name : 'png' in name)\nzipFilesInDir('.', experiment_title+'_all.zip', lambda name : '_.zip' in name)","72dd45cb":"! ls -all *.zip","40ff1cac":"## Configuration\nIn order to be a proper cross validation with a meaningful overall CV score (aligned with LB score), **you need to choose the same** `IMG_SIZES`, `INC2019`, `INC2018`, and `EFF_NETS` **for each fold**. If your goal is to just run lots of experiments, then you can choose to have a different experiment in each fold. Then each fold is like a holdout validation experiment. When you find a configuration you like, you can use that configuration for all folds. \n* DEVICE - is GPU or TPU\n* SEED - a different seed produces a different triple stratified kfold split.\n* FOLDS - number of folds. Best set to 3, 5, or 15 but can be any number between 2 and 15\n* IMG_SIZES - is a Python list of length FOLDS. These are the image sizes to use each fold\n* INC2019 - This includes the new half of the 2019 competition data. The second half of the 2019 data is the comp data from 2018 plus 2017\n* INC2018 - This includes the second half of the 2019 competition data which is the comp data from 2018 plus 2017\n* BATCH_SIZES - is a list of length FOLDS. These are batch sizes for each fold. For maximum speed, it is best to use the largest batch size your GPU or TPU allows.\n* EPOCHS - is a list of length FOLDS. These are maximum epochs. Note that each fold, the best epoch model is saved and used. So if epochs is too large, it won't matter.\n* EFF_NETS - is a list of length FOLDS. These are the EfficientNets to use each fold. The number refers to the B. So a number of `0` refers to EfficientNetB0, and `1` refers to EfficientNetB1, etc.\n* WGTS - this should be `1\/FOLDS` for each fold. This is the weight when ensembling the folds to predict the test set. If you want a weird ensemble, you can use different weights.\n* TTA - test time augmentation. Each test image is randomly augmented and predicted TTA times and the average prediction is used. TTA is also applied to OOF during validation.","fe5e744a":"# Step 2: Data Augmentation\nThis notebook uses rotation, sheer, zoom, shift augmentation first shown in this notebook [here][1] and successfully used in Melanoma comp by AgentAuers [here][2]. This notebook also uses horizontal flip, hue, saturation, contrast, brightness augmentation similar to last years winner and also similar to AgentAuers' notebook.\n\nAdditionally we can decide to use external data by changing the variables `INC2019` and `INC2018` in the preceeding code section. These variables respectively indicate whether to load last year 2019 data and\/or year 2018 + 2017 data. These datasets are discussed [here][3]\n\nConsider experimenting with different augmenation and\/or external data. The code to load TFRecords is taken from AgentAuers' notebook [here][2]. Thank you AgentAuers, this is great work.\n\n[1]: https:\/\/www.kaggle.com\/cdeotte\/rotation-augmentation-gpu-tpu-0-96\n[2]: https:\/\/www.kaggle.com\/agentauers\/incredible-tpus-finetune-effnetb0-b6-at-once\n[3]: https:\/\/www.kaggle.com\/c\/siim-isic-melanoma-classification\/discussion\/164910","47c5a918":"### Measure model file size","fa2f8b45":"# Initialize Environment","f03cd8db":"#### Both TTAs on the same plot - AUC and TIME","f96d9ed4":"### Save to file","652404ec":"## Calculate OOF AUC\nThe OOF (out of fold) predictions are saved to disk. If you wish to ensemble multiple models, use the OOF to determine what are the best weights to blend your models with. Choose weights that maximize OOF CV score when used to blend OOF. Then use those same weights to blend your test predictions.","b295261d":"### Without TTA","000eb3bc":"### With TTA","18012150":"#### FULL TTA - withTTA","46138cda":"# Step 1: Preprocess\nPreprocess has already been done and saved to TFRecords. Here we choose which size to load. We can use either 128x128, 192x192, 256x256, 384x384, 512x512, 768x768 by changing the `IMG_SIZES` variable in the preceeding code section. These TFRecords are discussed [here][1]. The advantage of using different input sizes is discussed [here][2]\n\n[1]: https:\/\/www.kaggle.com\/c\/siim-isic-melanoma-classification\/discussion\/155579\n[2]: https:\/\/www.kaggle.com\/c\/siim-isic-melanoma-classification\/discussion\/160147","fab73ace":"#### LOSSLESS TTA - withTTA_LL","1304c331":"# Step 5: Post process\n## Measure prediction times, AUC, model file size","cce6efd5":"# Step 3: Build Model\nThis is a common model architecute. Consider experimenting with different backbones, custom heads, losses, and optimizers. Also consider inputing meta features into your CNN.","3ddea74b":"## Train Model\nOur model will be trained for the number of FOLDS and EPOCHS you chose in the configuration above. Each fold the model with lowest validation loss will be saved and used to predict OOF and test. Adjust the variables `VERBOSE` and `DISPLOY_PLOT` below to determine what output you want displayed. The variable `VERBOSE=1 or 2` will display the training and validation loss and auc for each epoch as text. The variable `DISPLAY_PLOT` shows this information as a plot. ","8c3ccf0f":"# Step 4: Train Schedule\nThis is a common train schedule for transfer learning. The learning rate starts near zero, then increases to a maximum, then decays over time. Consider changing the schedule and\/or learning rates. Note how the learning rate max is larger with larger batches sizes. This is a good practice to follow."}}