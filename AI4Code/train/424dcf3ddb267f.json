{"cell_type":{"76a5cfef":"code","a28c84d6":"code","f28893e5":"code","fd21fc9f":"code","05762d5e":"code","f8fd8da8":"code","fdbd031e":"code","e2fe95cd":"code","55e403ae":"code","26e5c500":"code","3950178e":"code","b26d239d":"code","4f66547b":"code","716d85ba":"code","c4601879":"code","1affeb6d":"code","97b9dd7d":"code","4b58b0d5":"code","bf49c735":"code","1c4e9cec":"code","30aa3433":"code","e632fab9":"code","c1ccf02e":"code","7ec8f074":"code","8c71f862":"code","9fc81b32":"code","6024b622":"code","e76d3c3a":"code","119da34e":"code","44102c4f":"code","8dacae94":"code","782ca439":"code","da0c7451":"code","3d99a273":"code","41a1aad3":"code","11c3da3e":"markdown","f7c58b50":"markdown","739db69b":"markdown","eb3bbb6d":"markdown","5b4704e1":"markdown","b4600fd5":"markdown","8225525c":"markdown","59d9fdf0":"markdown","8d05b44c":"markdown","37a6a76f":"markdown","7fc2d6ad":"markdown","1ee42af0":"markdown","0f33e4ce":"markdown","23089086":"markdown","3f5a5da3":"markdown","ad42b7c9":"markdown"},"source":{"76a5cfef":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a28c84d6":"df = pd.read_csv(\"..\/input\/Autism-Adult-Data.csv\")\ndf.head()","f28893e5":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use(\"bmh\")","fd21fc9f":"#Collection information about dataset\ndf.info()","05762d5e":"print(df[\"Class\/ASD\"].describe())\nplt.figure(figsize=(9,8))\nsns.countplot(x=\"Class\/ASD\",data=df)","f8fd8da8":"#Numeric ve Categorical featurelar\u0131 tek tek inceleyece\u011fiz.\n#A\u015fa\u011f\u0131daki g\u00f6rece\u011fimiz \u00fczere int64 ve Object tipinde iki t\u00fcr feature\u0131m\u0131z var\nlist(set(df.dtypes.tolist()))","fdbd031e":"df_numeric = df.select_dtypes(include=[\"int64\"])\ndf_numeric.head()","e2fe95cd":"df_numeric.hist(figsize=(16,20),bins=50,xlabelsize=8,ylabelsize=8)","55e403ae":"df_numeric_correlation = df_numeric.corr()[\"result\"][:-1]\ngolden_features_list = df_numeric_correlation[abs(df_numeric_correlation) > 0.5].sort_values(ascending=False)\nprint(\"There is {} strongly correlated values with class :\\n{}\".format(len(golden_features_list),golden_features_list))","26e5c500":"df_objects = df.select_dtypes(include=[\"O\"])\ndf_objects.head()","3950178e":"plt.figure(figsize = (20,20))\ndf_for_count = df.copy()\n# delete = df_for_count[df_for_count[\"age\"]==\"?\"]\ndf_for_count.drop(df_for_count.loc[df_for_count[\"age\"]==\"?\",\"age\"].index,inplace=True)\ndf_for_count[\"age\"] = [\"under 35\" if age<=35 else \"higher 35\" if age>=35 else \"None\" for age in df_for_count[\"age\"].astype(\"int64\")]\n\n# [\"under 35\" if type(age) == \"int64\" and age <= 35 else 'higher 35' if v == 2 else 'None' for v in l]\n    \nax = sns.countplot(x=\"Class\/ASD\",hue=\"age\",data=df_for_count)\nplt.setp(ax.artists,alpha=.5,linewidth=2,edgecolor=\"k\")\nplt.xticks(rotation=45)","b26d239d":"plt.figure(figsize = (20,20))\ndf_for_count = df.copy()\n# delete = df_for_count[df_for_count[\"age\"]==\"?\"]\ndf_for_count.drop(df_for_count.loc[df_for_count[\"gender\"]==\"?\",\"gender\"].index,inplace=True)\n\n# [\"under 35\" if type(age) == \"int64\" and age <= 35 else 'higher 35' if v == 2 else 'None' for v in l]\n    \nax = sns.countplot(x=\"Class\/ASD\",hue=\"gender\",data=df_for_count)\nplt.setp(ax.artists,alpha=.5,linewidth=2,edgecolor=\"k\")\nplt.xticks(rotation=45)","4f66547b":"plt.figure(figsize = (20,20))\ndf_for_count = df.copy()\ndf_for_count.drop(df_for_count.loc[df_for_count[\"ethnicity\"]==\"?\",\"ethnicity\"].index,inplace=True)    \nax = sns.countplot(x=\"Class\/ASD\",hue=\"ethnicity\",data=df_for_count)\nplt.setp(ax.artists,alpha=.5,linewidth=2,edgecolor=\"k\")\nplt.xticks(rotation=45)","716d85ba":"plt.figure(figsize = (35,35))\ndf_for_count = df.copy()\ndf_for_count.drop(df_for_count.loc[df_for_count[\"contry_of_res\"]==\"?\",\"contry_of_res\"].index,inplace=True)    \nax = sns.countplot(x=\"Class\/ASD\",hue=\"contry_of_res\",data=df_for_count,order = df_for_count['Class\/ASD'].value_counts().index)\nplt.setp(ax.artists,alpha=.5,linewidth=2,edgecolor=\"k\")\nplt.xticks(rotation=45)\n","c4601879":"df.head()","1affeb6d":"df = df.replace('?', np.nan)\ndf.head()","97b9dd7d":"df = df.fillna(df.mode().iloc[0])\ndf.head()\n","4b58b0d5":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf['ethnicity'] = le.fit_transform(df['ethnicity'])\ndf['jundice'] = le.fit_transform(df['jundice'])\ndf['austim'] = le.fit_transform(df['austim'])\ndf['contry_of_res'] = le.fit_transform(df['contry_of_res'])\ndf['age_desc'] = le.fit_transform(df['age_desc'])\ndf['relation'] = le.fit_transform(df['relation'])\ndf['Class\/ASD'] = le.fit_transform(df['Class\/ASD'])\ndf['used_app_before'] = le.fit_transform(df['used_app_before'])\ndf['gender'] = le.fit_transform(df['gender'])\ndf['age'] = le.fit_transform(df['age'])\ndf.head()","bf49c735":"df.info()","1c4e9cec":"X = df.drop(\"Class\/ASD\",axis=1)\nY = df[\"Class\/ASD\"]\nX,Y","30aa3433":"from sklearn.preprocessing import OneHotEncoder\n\nohe = OneHotEncoder(categories=\"auto\")\nX = ohe.fit_transform(X).toarray()\nX\n","e632fab9":"print(\"Our Sample Len : {} and Features of NN {}\".format(X.shape[0],X.shape[1]))\nprint(\"Our Outputs Len : {}\".format(Y.shape[0]))","c1ccf02e":"import tensorflow as tf","7ec8f074":"def build_model():\n    inputs = tf.keras.Input(shape=(169,))\n    x = tf.keras.layers.Dense(128,activation=tf.nn.relu)(inputs)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Dense(256,activation=tf.nn.relu)(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Dense(512,activation=tf.nn.relu)(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    x = tf.keras.layers.Dense(1024,activation=tf.nn.relu)(x)\n    x = tf.keras.layers.Dropout(rate=0.5)(x)\n    logits = tf.keras.layers.Dense(1,activation=tf.nn.sigmoid)(x)\n\n    model = tf.keras.Model(inputs=inputs,outputs=logits)\n    optimizer = tf.keras.optimizers.Adam(lr=1e-4)\n    loss = tf.keras.losses.binary_crossentropy\n    model.compile(optimizer=optimizer,loss=loss,metrics=[\"accuracy\"])\n    return model\n","8c71f862":"from sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state = 42)","9fc81b32":"X_train.shape,X_test.shape,Y_train.shape,Y_test.shape","6024b622":"Y_train = Y_train.values.reshape(-1,1)","e76d3c3a":"Y_test = Y_test.values.reshape(-1,1)","119da34e":"X_train.shape,X_test.shape,Y_train.shape,Y_test.shape","44102c4f":"from sklearn.model_selection import StratifiedKFold\nskf = StratifiedKFold(n_splits=5, shuffle=True)\nfor index, (train_indices, val_indices) in enumerate(skf.split(X_train, Y_train)):\n    print(\"Training on fold\" + str(index+1) + \"\/10...\")\n    # Generate batches from indices\n    xtrain, xval = X_train[train_indices], X_train[val_indices]\n    ytrain, yval = Y_train[train_indices], Y_train[val_indices]\n    # Clear model, and create it\n    model = None\n    model = build_model()\n    \n    # Debug message I guess\n    print( \"Training new iteration on \" + str(xtrain.shape[0]) + \" training samples, \" + str(xval.shape[0]) + \" validation samples, this may be a while...\")\n    \n    history = model.fit(xtrain,ytrain,epochs=20,batch_size=32,validation_data=(xval,yval))\n    accuracy_history = history.history['acc']\n    val_accuracy_history = history.history['val_acc']\n    print(\"Last training accuracy: \" + str(accuracy_history[-1]) + \", last validation accuracy: \" + str(val_accuracy_history[-1]))","8dacae94":"scores = model.evaluate(x=X_test,y=Y_test,batch_size=32)\nprint(scores)\ny_head = model.predict(X_test)\n","782ca439":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(Y_test,y_head.round())","da0c7451":"print(cm)","3d99a273":"TP , FP , FN , TN = cm[0][0] ,cm[0][1] , cm[1][0] , cm[1][1]","41a1aad3":"print(\"Class 0 Prediction Accuracy {:.1f}\".format(TP \/ (TP+FP) * 100))\nprint(\"Class 1 Prediction Accuracy {:.1f}\".format(TN \/ (FN+TN) * 100))","11c3da3e":"**\u015eimdi Categorical valuelar\u0131m\u0131z\u0131 numerical valuelara \u00e7evirece\u011fiz ard\u0131ndan numerical valuelar\u0131m\u0131z\u0131 da OneHotEncoder ile dummy variables haline getirece\u011fiz**","f7c58b50":"**Burada g\u00f6rd\u00fc\u011f\u00fcm\u00fcz \u00fczere Others class\u0131nda en y\u00fcksek evet oran\u0131 var fakat bunun hangi etnik k\u00f6kenler oldu\u011funu bilmiyoruz.Bildi\u011fimiz k\u00f6ken \u00fczerine konu\u015facak olursak veri setimizde black ve Asian k\u00f6kenlerinde daha fazla otizm g\u00f6r\u00fcnd\u00fc\u011f\u00fcn\u00fc s\u00f6yleyebiliriz.**","739db69b":"**35 ya\u015f ve alt\u0131nda daha fazla otozim g\u00f6r\u00fcn\u00fcyor fakat 35 ya\u015f ve alt\u0131nda 35 ve ya\u015f \u00fcst\u00fcne g\u00f6re daha az otizim g\u00f6r\u00fcnd\u00fc\u011f\u00fcn\u00fc g\u00f6rebiliriz.**","eb3bbb6d":"G\u00f6rd\u00fc\u011f\u00fcm\u00fcz \u00fczere int64 olan verilerimiz asl\u0131nda boolean verilerdir 0 lar False 1 ler Trueyu temsil ediyor.\nResult ise testimizin sonucunu temsil etti\u011fi i\u00e7in 0 dan 10 a kadar bir de\u011ferlendirme sonucunu veriyor.\nResultun Mod'unun 4 oldu\u011funu a\u00e7\u0131kca g\u00f6r\u00fcyoruz.","5b4704e1":"**\u015eimdi burada Bizim Class\u0131m\u0131z ile bu featurelar aras\u0131ndaki correlationa bakaca\u011f\u0131z ki verisetimizi ona g\u00f6re d\u00fczenleyece\u011fiz**","b4600fd5":"***Burada yapabilece\u011fimiz yorum ise \u015fu ki : United State, Brazil ve Spain de en y\u00fcksek otizm oran\u0131 g\u00f6r\u00fclmekte.***","8225525c":"**Evet verimizi inceledi\u011fimize g\u00f6re verimiz \u00fczerinde baz\u0131 preprocess i\u015flemleri yapal\u0131m.**","59d9fdf0":"Burada incelememizi ya\u015f , cinsiyet ,etnik k\u00f6ken , sar\u0131l\u0131k , austim , \u00fclke , daha \u00f6nce bu tedavi y\u00f6ntemini tan\u0131d\u0131m\u0131 , ya\u015f aral\u0131\u011f\u0131, formu kim doldurdu gibi featurelar\u0131n classdaki de\u011fi\u015fimlerine bakaca\u011f\u0131z.","8d05b44c":"**Burada g\u00f6rd\u00fc\u011f\u00fcm\u00fcz \u00fczere kad\u0131nlarda erkeklerin yan\u0131 s\u0131ra daha  fazla otizm g\u00f6r\u00fcn\u00fcyor**","37a6a76f":"***G\u00f6r\u00fclen \u00fczere b\u00fct\u00fcn verilerimizi int64 tipine \u00e7evirdik yani numerical veriler oldular \u015fimdi bu verilerimize onehotencoder uygulayarak modelimize uygun hale getirece\u011fiz.***","7fc2d6ad":"***Verimiz Sinir A\u011f\u0131m\u0131zda Kullanmak i\u00e7in uygun hale geldi \u015fimdi S\u0131ra sinir a\u011f\u0131m\u0131z\u0131 in\u015fa etmekte.\n    Sinir A\u011f\u0131m\u0131z\u0131 \u0130n\u015fa ederken Tensorflow K\u00fct\u00fcphanesinin Keras HIGH-Level API'ni kullanaca\u011f\u0131z.***","1ee42af0":"***Yapay sinir a\u011f\u0131 k\u00fct\u00fcphanemiz input verilerini (1,) \u015feklinde kabul etmedi\u011fi i\u00e7in label vectorumuzu matrise \u00e7evirece\u011fiz***","0f33e4ce":"**Dataset Description from UCI**\n\n** I will add English translation for this kernel later :) **\n\n**Data Set Name**: Autistic Spectrum Disorder Screening Data for Adult\n\n**Abstract**: Autistic Spectrum Disorder (ASD) is a neurodevelopment  condition associated with significant healthcare costs, and early diagnosis can significantly reduce these. Unfortunately, waiting times for an ASD diagnosis are lengthy and procedures are not cost effective. The economic impact of autism and the increase in the number of ASD cases across the world reveals an urgent need for the development of easily implemented and effective screening methods. Therefore, a time-efficient and accessible ASD screening is imminent to help health professionals and inform individuals whether they should pursue formal clinical diagnosis.  The rapid growth in the number of ASD cases worldwide necessitates datasets related to behaviour traits. However, such datasets are rare making it difficult to perform thorough analyses to improve the efficiency, sensitivity, specificity and predictive accuracy of the ASD screening process. Presently, very limited autism datasets associated with clinical or screening are available and most of them are genetic in nature. Hence, we propose a new dataset related to autism screening of adults that contained 20 features to be utilised for further analysis especially in determining influential autistic traits and improving the classification of ASD cases. In this dataset, we record ten behavioural features (AQ-10-Adult) plus ten individuals characteristics that have proved to be effective in detecting the ASD cases from controls in behaviour science. \n\n\n**Source**: Fadi Fayez Thabtah\nDepartment of Digital Technology\nManukau Institute of Technology,\nAuckland, New Zealand\nfadi.fayez@manukau.ac.nz\n\n\n**Data Type:** Multivariate OR Univariate OR Sequential OR Time-Series OR Text OR Domain-Theory\nNominal \/ categorical, binary and continuous \n\n\n**Task**: Classification\n\n\n**Attribute Type**: Categorical, continuous and binary  \n\n\n**Area**: Medical, health and social science\n\n\n**Format Type**: Non-Matrix\n\n\n**Does your data set contain missing values?** Yes\n\n\n**Number of Instances (records in your data set)**: 704\n\n\n**Number of Attributes (fields within each record)**: 21\n\n\n**Relevant Information**: For Further information about the attributes\/feature see below  table.\n\n\n\n![image.png](attachment:image.png)","23089086":"df = df.fillna(df.mode().iloc[0]) kod par\u00e7as\u0131 ile her columndaki most frequent item ile o columndaki NaN valuelar\u0131 doldurduk.","3f5a5da3":"***We can see that our model's accuracy is so good.Accuracy 0.98 and Loss 0.05 for unseen data.***","ad42b7c9":"***Now time to evualute and see the results***"}}