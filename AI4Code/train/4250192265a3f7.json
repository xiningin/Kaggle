{"cell_type":{"4468ae52":"code","341a6418":"code","df9aecff":"code","c805431b":"code","4af1bb3f":"code","1bbe40b7":"code","7a6435b2":"code","4307acf7":"code","a638292c":"code","7f797c52":"code","6c67658c":"code","c3e63e4e":"code","7924fdf1":"code","21bf5c11":"code","61b230c9":"code","0cce2c8f":"code","ba4747b8":"code","9f31e4f1":"code","f8434200":"code","cba20412":"code","776a1548":"code","70649549":"code","7420ccbf":"code","d11f2a88":"code","fb921c60":"code","9c9d8ed1":"code","cceacfd3":"code","bc9e77a9":"code","563f392a":"markdown","b1aef772":"markdown","da115585":"markdown","da69fae2":"markdown","56deee22":"markdown","00c32002":"markdown","89a4ffcb":"markdown","d69d6bff":"markdown","b91b047b":"markdown","318d9052":"markdown"},"source":{"4468ae52":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import class_weight\n\nimport tensorflow as tf","341a6418":"data = pd.read_csv('..\/input\/gas-prices-in-brazil\/2004-2019.tsv', delimiter='\\t')","df9aecff":"data","c805431b":"data.info()","4af1bb3f":"unneeded_columns = ['Unnamed: 0', 'DATA INICIAL', 'DATA FINAL']\n\ndata = data.drop(unneeded_columns, axis=1)","1bbe40b7":"data","7a6435b2":"data.isna().sum()","4307acf7":"data['PRODUTO'].value_counts()","a638292c":"plt.figure(figsize=(12, 12))\nplt.pie(\n    x=data['PRODUTO'].value_counts(),\n    labels=data['PRODUTO'].value_counts().index,\n    autopct='%.1f%%',\n    colors=sns.color_palette('rocket')\n)\nplt.show()","7f797c52":"data","6c67658c":"label_encoder = LabelEncoder()\n\ndata['PRODUTO'] = label_encoder.fit_transform(data['PRODUTO'])","c3e63e4e":"dict(enumerate(label_encoder.classes_))","7924fdf1":"{column: list(data[column].unique()) for column in ['REGI\u00c3O', 'ESTADO', 'UNIDADE DE MEDIDA']}","21bf5c11":"def onehot_encode(df, columns, prefixes):\n    df = df.copy()\n    for column, prefix in zip(columns, prefixes):\n        dummies = pd.get_dummies(df[column], prefix=prefix)\n        df = pd.concat([df, dummies], axis=1)\n        df = df.drop(column, axis=1)\n    return df","61b230c9":"data = onehot_encode(\n    data,\n    ['REGI\u00c3O', 'ESTADO', 'UNIDADE DE MEDIDA'],\n    ['R', 'E', 'U']\n)","0cce2c8f":"data","ba4747b8":"data.isin(['-']).sum()","9f31e4f1":"data = data.replace('-', np.NaN)\n\nfor column in data.columns:\n    data[column] = data[column].fillna(data[column].astype(np.float).mean())","f8434200":"data.isna().sum().sum()","cba20412":"data","776a1548":"y = data.loc[:, 'PRODUTO']\nX = data.drop('PRODUTO', axis=1)","70649549":"scaler = StandardScaler()\n\nX = scaler.fit_transform(X)","7420ccbf":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=34)","d11f2a88":"X.shape","fb921c60":"num_classes = len(y.unique())","9c9d8ed1":"class_weights = dict(\n    enumerate(\n        class_weight.compute_class_weight(\n            'balanced',\n            y_train.unique(),\n            y_train\n        )\n    )\n)\n\nclass_weights","cceacfd3":"inputs = tf.keras.Input(shape=(49,))\nx = tf.keras.layers.Dense(64, activation='relu')(inputs)\nx = tf.keras.layers.Dense(64, activation='relu')(x)\noutputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs, outputs)\n\n\nmodel.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n\nbatch_size = 32\nepochs = 100\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    validation_split=0.2,\n    class_weight=class_weights,\n    batch_size=batch_size,\n    epochs=epochs,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True,\n            verbose=1\n        )\n    ]\n)","bc9e77a9":"model.evaluate(X_test, y_test)","563f392a":"# Results","b1aef772":"# Task for Today  \n\n***\n\n## Gas Product Type Prediction  \n\nGiven *weekly reports of gas sales*, let's try to classify the **type** of a given product.  \n  \nWe will use a TensorFlow ANN to make our predictions.","da115585":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/bPjwevN7MgI","da69fae2":"# Splitting and Scaling","56deee22":"# Class Visualization","00c32002":"# Training","89a4ffcb":"# Getting Started","d69d6bff":"# Cleaning","b91b047b":"# Missing Values","318d9052":"# Encoding"}}