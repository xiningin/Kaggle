{"cell_type":{"1ae9cc93":"code","51b903ef":"code","ce4c69b5":"code","329152ea":"code","0ebe1a1e":"code","200eb06b":"code","4b46059d":"code","e6bb288e":"code","e17e415b":"code","0619552c":"code","9e253d26":"code","2990abd1":"code","f842d047":"code","4e99fb3d":"code","118fc9d3":"code","231f0411":"code","8a68b8c0":"code","4f8380a4":"code","48f62758":"code","afa02d8b":"code","6237c9b3":"code","ec14c21f":"code","4a182e82":"code","9f64fd96":"code","c184e9b3":"code","43baba92":"code","4b8af67e":"code","f48c41cb":"code","940f3c34":"code","1e8d3e72":"code","64be77a9":"code","568116ec":"code","d01a4ba1":"code","b91dea38":"code","d01c31f3":"code","f31de425":"code","97f636af":"code","f318dba7":"code","f196fff3":"code","bc240f1c":"code","002966fd":"code","f7440f0e":"code","324257c3":"code","d740ddab":"code","62d59847":"code","6698b812":"code","bb71f129":"code","e2f1211b":"code","03d10755":"code","6fc54c06":"code","5bb09dfb":"code","38ba0047":"code","66006c90":"code","f616b685":"code","4dfc73ac":"code","11886007":"code","5d66c059":"code","9a63b62f":"code","e7325360":"code","20abeb30":"code","7c676bec":"code","fb777fb4":"code","bd368f9b":"code","dec41c21":"code","049d61e6":"code","fa8b8966":"code","f446d1b6":"code","9c2ea150":"code","517d2533":"code","37d87278":"code","1f584902":"code","4ae148c3":"code","da18908b":"code","2d751f38":"code","2e268534":"code","9ba9c742":"code","a87b401f":"code","ba071567":"code","ce3ea8c6":"code","fcf90b61":"code","a2b99ddc":"code","357e0552":"code","4b1e8216":"code","afe0e9df":"code","59870b6d":"code","26ad4778":"code","2f43de0a":"code","a538a974":"code","46854ebc":"code","b97c59e4":"code","7a6dae35":"code","c288002b":"code","6d76b85a":"code","33e2fb6b":"code","ac890e3e":"markdown","642c1d7f":"markdown","525b8187":"markdown","92fe9d3b":"markdown","11f0c921":"markdown","0b76d17b":"markdown","1169a2b6":"markdown","5fdb3a92":"markdown","184c24a4":"markdown","a9470b0c":"markdown","03bd92ae":"markdown","ddcc5157":"markdown","90ca4a9c":"markdown","2ca25465":"markdown","57a92bbe":"markdown","100056b1":"markdown","16a2ef56":"markdown","7fccfce8":"markdown","a4249c67":"markdown"},"source":{"1ae9cc93":"!pip install -q calmap","51b903ef":"!pip install -q pycountry_convert","ce4c69b5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","329152ea":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math as m\nfrom pathlib import Path\nfrom datetime import datetime\nimport calmap\n\nimport os\nimport glob\nimport copy\n\nimport folium \n\nimport geopandas\nimport pycountry_convert as pc\nfrom google.cloud import bigquery\nfrom folium import plugins\nfrom folium import Marker,GeoJson,Choropleth, Circle\nfrom folium.plugins import HeatMap\nfrom folium.plugins import HeatMap, MarkerCluster\nfrom scipy.spatial.distance import cdist\n","0ebe1a1e":"#pd.set_option('max_columns', 100)\n#pd.set_option('max_rows', 500)\nimport warnings\nwarnings.filterwarnings('ignore')","200eb06b":"# Code for displaying plotly express plot\ndef configure_plotly_browser_state():\n  import IPython\n  display(IPython.core.display.HTML('''\n        <script src=\"\/static\/components\/requirejs\/require.js\"><\/script>\n        <script>\n          requirejs.config({\n            paths: {\n              base: '\/static\/base',\n              plotly: 'https:\/\/cdn.plot.ly\/plotly-latest.min.js?noext',\n            },\n          });\n        <\/script>\n        '''))","4b46059d":"from plotly import tools\nimport plotly.offline as py\n\npy.init_notebook_mode(connected = True)\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\n\nfrom plotly.subplots import make_subplots\nconfigure_plotly_browser_state()\nfrom IPython.display import IFrame\nfrom IPython.display import Javascript\nfrom IPython.core.display import display\nfrom IPython.core.display import HTML\n\nfrom IPython.display import display\nfrom IPython.core.interactiveshell import InteractiveShell\n#InteractiveShell.ast_node_interactivity = \"all\"","e6bb288e":"IFrame('https:\/\/www.arcgis.com\/apps\/opsdashboard\/index.html#\/bda7594740fd40299423467b48e9ecf6', width='90%', height=600)\n","e17e415b":"from sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error","0619552c":"# Building and fitting Random Forest\nfrom sklearn.metrics import r2_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import GridSearchCV","9e253d26":"## for Deep-learing:\nimport keras\nfrom keras.layers import Dense\nfrom keras.models import Sequential\nfrom keras.utils import to_categorical\nfrom keras.optimizers import SGD \nfrom keras.callbacks import EarlyStopping\nfrom keras.utils import np_utils\nimport itertools\nfrom keras.layers import LSTM\nfrom keras.layers.convolutional import Conv1D\nfrom keras.layers.convolutional import MaxPooling1D\nfrom keras.layers import Dropout","2990abd1":"# Retriving Dataset\nconfirmed_df = pd.read_csv('https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_confirmed_global.csv')\ndeaths_df = pd.read_csv('https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_deaths_global.csv')\nrecovered_df = pd.read_csv('https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_recovered_global.csv')\n\n\ncasescountry_df = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/web-data\/data\/cases_country.csv\")\ncasestime_df = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/web-data\/data\/cases_time.csv\",parse_dates=['Last_Update'])","f842d047":"#Country\ncountry_df=pd.read_csv(\"..\/input\/countryinfo\/covid19countryinfo.csv\")\ncovidtests_df = pd.read_csv(\"..\/input\/countryinfo\/covid19tests.csv\")\n","4e99fb3d":"confirmed_df.rename(columns={'Country\/Region':'Country'}, inplace=True)\ndeaths_df.rename(columns={'Country\/Region':'Country'}, inplace=True)\nrecovered_df.rename(columns={'Country\/Region':'Country'}, inplace=True)\ncasescountry_df.rename(columns={'Country_Region':'Country'}, inplace=True)\ncasestime_df.rename(columns={'Country_Region':'Country'}, inplace=True)","118fc9d3":"# Changing the conuntry names as required by pycountry_convert Lib\n\n\nconfirmed_df.loc[confirmed_df[\"Country\"] == \"US\", \"Country\"] = \"USA\"\n\nconfirmed_df.loc[confirmed_df['Country'] == 'Korea, South', \"Country\"] = 'South Korea'\nconfirmed_df.loc[confirmed_df['Country'] == 'Taiwan*', \"Country\"] = 'Taiwan'\nconfirmed_df.loc[confirmed_df['Country'] == 'Congo (Kinshasa)', \"Country\"] = 'Democratic Republic of the Congo'\nconfirmed_df.loc[confirmed_df['Country'] == \"Cote d'Ivoire\", \"Country\"] = \"C\u00f4te d'Ivoire\"\nconfirmed_df.loc[confirmed_df['Country'] == \"Reunion\", \"Country\"] = \"R\u00e9union\"\nconfirmed_df.loc[confirmed_df['Country'] == 'Congo (Brazzaville)', \"Country\"] = 'Republic of the Congo'\nconfirmed_df.loc[confirmed_df['Country'] == 'Bahamas, The', \"Country\"] = 'Bahamas'\nconfirmed_df.loc[confirmed_df['Country'] == 'Gambia, The', \"Country\"] = 'Gambia'\n\n\n\ndeaths_df.loc[deaths_df['Country'] == \"US\", \"Country\"] = \"USA\"\ndeaths_df.loc[deaths_df['Country'] == 'Korea, South', \"Country\"] = 'South Korea'\ndeaths_df.loc[deaths_df['Country'] == 'Taiwan*', \"Country\"] = 'Taiwan'\ndeaths_df.loc[deaths_df['Country'] == 'Congo (Kinshasa)', \"Country\"] = 'Democratic Republic of the Congo'\ndeaths_df.loc[deaths_df['Country'] == \"Cote d'Ivoire\", \"Country\"] = \"C\u00f4te d'Ivoire\"\ndeaths_df.loc[deaths_df['Country'] == \"Reunion\", \"Country\"] = \"R\u00e9union\"\ndeaths_df.loc[deaths_df['Country'] == 'Congo (Brazzaville)', \"Country\"] = 'Republic of the Congo'\ndeaths_df.loc[deaths_df['Country'] == 'Bahamas, The', \"Country\"] = 'Bahamas'\ndeaths_df.loc[deaths_df['Country'] == 'Gambia, The', \"Country\"] = 'Gambia'\n\n\n\nrecovered_df.loc[recovered_df['Country'] == \"US\", \"Country\"] = \"USA\"\nrecovered_df.loc[recovered_df['Country'] == 'Korea, South', \"Country\"] = 'South Korea'\nrecovered_df.loc[recovered_df['Country'] == 'Taiwan*', \"Country\"] = 'Taiwan'\nrecovered_df.loc[recovered_df['Country'] == 'Congo (Kinshasa)', \"Country\"] = 'Democratic Republic of the Congo'\nrecovered_df.loc[recovered_df['Country'] == \"Cote d'Ivoire\", \"Country\"] = \"C\u00f4te d'Ivoire\"\nrecovered_df.loc[recovered_df['Country'] == \"Reunion\", \"Country\"] = \"R\u00e9union\"\nrecovered_df.loc[recovered_df['Country'] == 'Congo (Brazzaville)', \"Country\"] = 'Republic of the Congo'\nrecovered_df.loc[recovered_df['Country'] == 'Bahamas, The', \"Country\"] = 'Bahamas'\nrecovered_df.loc[recovered_df['Country'] == 'Gambia, The', \"Country\"] = 'Gambia'\n\n\ncasescountry_df.loc[casescountry_df['Country'] == \"US\", \"Country\"] = \"USA\"\ncasescountry_df.loc[casescountry_df['Country'] == 'Korea, South', \"Country\"] = 'South Korea'\ncasescountry_df.loc[casescountry_df['Country'] == 'Taiwan*', \"Country\"] = 'Taiwan'\ncasescountry_df.loc[casescountry_df['Country'] == 'Congo (Kinshasa)', \"Country\"] = 'Democratic Republic of the Congo'\ncasescountry_df.loc[casescountry_df['Country'] == \"Cote d'Ivoire\", \"Country\"] = \"C\u00f4te d'Ivoire\"\ncasescountry_df.loc[casescountry_df['Country'] == \"Reunion\", \"Country\"] = \"R\u00e9union\"\ncasescountry_df.loc[casescountry_df['Country'] == 'Congo (Brazzaville)', \"Country\"] = 'Republic of the Congo'\ncasescountry_df.loc[casescountry_df['Country'] == 'Bahamas, The', \"Country\"] = 'Bahamas'\ncasescountry_df.loc[casescountry_df['Country'] == 'Gambia, The', \"Country\"] = 'Gambia'\n\n\n\ncasestime_df.loc[casestime_df['Country'] == \"US\", \"Country\"] = \"USA\"\ncasestime_df.loc[casestime_df['Country'] == 'Korea, South', \"Country\"] = 'South Korea'\ncasestime_df.loc[casestime_df['Country'] == 'Taiwan*', \"Country\"] = 'Taiwan'\ncasestime_df.loc[casestime_df['Country'] == 'Congo (Kinshasa)', \"Country\"] = 'Democratic Republic of the Congo'\ncasestime_df.loc[casestime_df['Country'] == \"Cote d'Ivoire\", \"Country\"] = \"C\u00f4te d'Ivoire\"\ncasestime_df.loc[casestime_df['Country'] == \"Reunion\", \"Country\"] = \"R\u00e9union\"\ncasestime_df.loc[casestime_df['Country'] == 'Congo (Brazzaville)', \"Country\"] = 'Republic of the Congo'\ncasestime_df.loc[casestime_df['Country'] == 'Bahamas, The', \"Country\"] = 'Bahamas'\ncasestime_df.loc[casestime_df['Country'] == 'Gambia, The', \"Country\"] = 'Gambia'","231f0411":"# getting all countries\ncountries = np.asarray(confirmed_df[\"Country\"])\ncountries1 = np.asarray(casescountry_df[\"Country\"])\n\n# Continent_code to Continent_names\ncontinents = {\n    'NA': 'North America',\n    'SA': 'South America', \n    'AS': 'Asia',\n    'OC': 'Australia',\n    'AF': 'Africa',\n    'EU' : 'Europe',\n    'na' : 'Others'\n}\n\n# Defininng Function for getting continent code for country.\ndef country_to_continent_code(Country):\n    try:\n        return pc.country_alpha2_to_continent_code(pc.country_name_to_country_alpha2(Country))\n    except :\n        return 'na'\n\n#Collecting Continent Information\nconfirmed_df.insert(2,\"continent\", [continents[country_to_continent_code(Country)] for Country in countries[:]])\ndeaths_df.insert(2,\"continent\",  [continents[country_to_continent_code(Country)] for Country in countries[:]])\nrecovered_df.insert(2,\"continent\",  [continents[country_to_continent_code(Country)] for Country in recovered_df[\"Country\"].values] )   \ncasescountry_df.insert(1,\"continent\",  [continents[country_to_continent_code(Country)] for Country in countries1[:]])\ncasestime_df.insert(1,\"continent\",  [continents[country_to_continent_code(Country)] for Country in casestime_df[\"Country\"].values])\n\n\ncasescountry_df['Active'] = casescountry_df['Confirmed']-casescountry_df['Deaths']-casescountry_df['Recovered']\ncasescountry_df[\"Mortality Rate (per 100)\"] = np.round(100*casescountry_df[\"Deaths\"]\/casescountry_df[\"Confirmed\"],2)","8a68b8c0":"casescountry_df.style.background_gradient(cmap='Purples',subset=[\"Confirmed\"])\\\n                        .background_gradient(cmap='Reds',subset=[\"Deaths\"])\\\n                        .background_gradient(cmap='Greens',subset=[\"Recovered\"])\\\n                        .background_gradient(cmap='Blues',subset=[\"Active\"])\\\n                        .background_gradient(cmap='Oranges',subset=[\"Mortality Rate (per 100)\"])","4f8380a4":"countrywise_df = casescountry_df.copy().drop(['Lat','Long_','continent','Last_Update'],axis =1)\ncountrywise_df.index = countrywise_df[\"Country\"]\ncountrywise_df = countrywise_df.drop(['Country'],axis=1)\n\ncontinentwise_df = casescountry_df.copy().drop(['Lat','Long_','Country','Last_Update'],axis =1)\ncontinentwise_df = continentwise_df.groupby([\"continent\"]).sum()","48f62758":"continentwise_df[\"Mortality Rate (per 100)\"] = np.round(100*continentwise_df[\"Deaths\"]\/continentwise_df[\"Confirmed\"],2)\ncontinentwise_df.sort_values('Mortality Rate (per 100)', ascending= False).style.background_gradient(cmap='Blues',subset=[\"Confirmed\"])\\\n                        .background_gradient(cmap='Reds',subset=[\"Deaths\"])\\\n                        .background_gradient(cmap='Greens',subset=[\"Recovered\"])\\\n                        .background_gradient(cmap='Purples',subset=[\"Active\"])\\\n                        .background_gradient(cmap='Oranges',subset=[\"Mortality Rate (per 100)\"])","afa02d8b":"fig = px.bar(continentwise_df,\n            x=continentwise_df.index, y=\"Confirmed\",\n            text = continentwise_df.index,\n            hover_name=continentwise_df.index,\n            hover_data=[\"Confirmed\",\"Deaths\",\"Recovered\",\"Active\",\"Mortality Rate (per 100)\"],\n            color_continuous_scale=px.colors.cyclical.IceFire,\n            title='COVID-19: Continentwise Details'\n)\nfig.update_xaxes(title_text=\"Continent\")","6237c9b3":"countrywise_df[\"Mortality Rate (per 100)\"] = np.round(100*countrywise_df[\"Deaths\"]\/countrywise_df[\"Confirmed\"],0)\ncountrywise_df.sort_values('Confirmed', ascending= False).style.background_gradient(cmap='Oranges',subset=[\"Confirmed\"])\\\n                        .background_gradient(cmap='Reds',subset=[\"Deaths\"])\\\n                        .background_gradient(cmap='Greens',subset=[\"Recovered\"])\\\n                        .background_gradient(cmap='Purples',subset=[\"Active\"])\\\n                        .background_gradient(cmap='RdPu',subset=[\"Mortality Rate (per 100)\"])","ec14c21f":"f = plt.figure(figsize=(20,10))\nf.add_subplot(2,1,1)\ncalmap.yearplot(casestime_df.groupby('Last_Update')['Confirmed'].sum().diff(), fillcolor='white', cmap='RdPu', linewidth=0.5,linecolor=\"#fafafa\",year=2020,)\nplt.title(\"Daily Confirmed Cases\",fontsize=20)\nplt.tick_params(labelsize=15)\n\nf.add_subplot(2,1,2)\ncalmap.yearplot(casestime_df.groupby('Last_Update')['Deaths'].sum().diff(), fillcolor='white', cmap='Oranges', linewidth=1,linecolor=\"#fafafa\",year=2020,)\nplt.title(\"Daily Deaths Cases\",fontsize=20)\nplt.tick_params(labelsize=15)\nplt.show()","4a182e82":"world_map = folium.Map(location=[10,0], tiles=\"cartodbpositron\", zoom_start=2,max_zoom=8,min_zoom=2)\nfor i in range(0,len(confirmed_df)):\n    folium.Circle(\n        location=[confirmed_df.iloc[i]['Lat'], confirmed_df.iloc[i]['Long']],\n        tooltip = \"<h5 style='text-align:center;font-weight: bold'>\"+confirmed_df.iloc[i]['Country']+\"<\/h5>\"+\n                    \"<div style='text-align:center;'>\"+str(np.nan_to_num(confirmed_df.iloc[i]['Province\/State']))+\"<\/div>\"+\n                    \"<hr style='margin:10px;'>\"+\n                    \"<ul style='color: #444;list-style-type:circle;align-item:left;padding-left:20px;padding-right:20px'>\"+\n                    \"<li>Confirmed: \"+str(confirmed_df.iloc[i,-1])+\"<\/li>\"+\n                    \"<li>Deaths:   \"+str(deaths_df.iloc[i,-1])+\"<\/li>\"+\n                    \"<li>Mortality Rate:   \"+str(np.round(deaths_df.iloc[i,-1]\/(confirmed_df.iloc[i,-1]+1.00001)*100,2))+\"<\/li>\"+\n                    \"<\/ul>\",\n        radius=(int((np.log(confirmed_df.iloc[i,-1]+1.00001)))+0.2)*50000,\n        color='#bb66ff',\n        fill_color='#ff8533',\n        fill=True).add_to(world_map)\n\nworld_map","9f64fd96":"# Dictionary to get the state codes from state names for US\nus_states = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}\n\nus_data = casestime_df[casestime_df[\"Country\"]==\"USA\"]\nus_data['Last_Update'] = us_data['Last_Update'].astype(str)\nus_data['state_code'] = us_data.apply(lambda x: us_states.get(x.Province_State,float('nan')), axis=1)\n#us_data.tail()","c184e9b3":"fig = px.choropleth(us_data, \n                    locations=\"state_code\", \n                    locationmode='USA-states',\n                    scope='usa',\n                    color=np.power(us_data[\"Confirmed\"],0.3) ,  \n                    hover_name=\"Province_State\",\n                    hover_data=['Confirmed'],\n                    #range_color=[1,2000],\n                    color_continuous_scale=px.colors.sequential.Emrld,\n                    animation_frame = 'Last_Update',\n                    title='US with cases',  height=600)\n#fig.update(layout_coloraxis_showscale=False)\nfig.update_coloraxes(colorbar_title=\"confirmed\",colorscale=\"tropic\")\nfig.show()\n\n","43baba92":"europe_data = casescountry_df[casescountry_df[\"continent\"]==\"Europe\"]\nfig = px.choropleth(europe_data, locations=\"Country\", \n                    locationmode='country names', color=\"Country\", \n                    hover_name=\"Confirmed\", range_color=[1,2000], \n                    color_continuous_scale=px.colors.sequential.Inferno, \n                    title='European Countries with Confirmed Cases', scope='europe', height=600)\n# fig.update(layout_coloraxis_showscale=False)\nfig.update_coloraxes(colorbar_title=\"Country\",colorscale=\"RdPu\")\nfig.show()","4b8af67e":"df = pd.DataFrame(countrywise_df['Confirmed'])\ndf = df.reset_index()\nfig = px.choropleth(df, locations=\"Country\",\n                    color=np.log10(df[\"Confirmed\"]), # lifeExp is a column of gapminder\n                    hover_name=\"Country\", # column to add to hover information\n                    hover_data=[\"Confirmed\"],\n                    color_continuous_scale=px.colors.sequential.Plasma,locationmode=\"country names\")\nfig.update_geos(fitbounds=\"locations\", visible=False)\nfig.update_layout(title_text=\"Worldwide Confirmed Cases\")\nfig.update_coloraxes(colorbar_title=\"Confirmed Cases(Log Scale)\",colorscale=\"RdPu\")\n# fig.to_image(\"Global Heat Map confirmed.png\")\nfig.show()","f48c41cb":"df = pd.DataFrame(countrywise_df['Deaths'])\ndf = df.reset_index()\nfig = px.choropleth(df, locations=\"Country\",\n                    color=np.log10(df[\"Deaths\"]), \n                    hover_name=\"Country\", # column to add to hover information\n                    hover_data=[\"Deaths\"],\n                    color_continuous_scale=px.colors.sequential.Plasma,locationmode=\"country names\")\nfig.update_geos(fitbounds=\"locations\", visible=False)\nfig.update_layout(title_text=\"Worldwide Fatalities\")\nfig.update_coloraxes(colorbar_title=\"FATALITIES(Log Scale)\",colorscale=\"viridis\")\n# fig.to_image(\"Global Heat Map confirmed.png\")\nfig.show()","940f3c34":"df = pd.DataFrame(countrywise_df['Recovered'])\ndf = df.reset_index()\nfig = px.choropleth(df, locations=\"Country\",\n                    color=np.log10(df[\"Recovered\"]), \n                    hover_name=\"Country\", # column to add to hover information\n                    hover_data=[\"Recovered\"],\n                    color_continuous_scale=px.colors.sequential.Plasma,locationmode=\"country names\")\nfig.update_geos(fitbounds=\"locations\", visible=False)\nfig.update_layout(title_text=\"Worldwide Recovered\")\nfig.update_coloraxes(colorbar_title=\"Recovered(Log Scale)\",colorscale=\"curl\")\nfig.show()","1e8d3e72":"asia_data = casescountry_df[casescountry_df[\"continent\"]==\"Asia\"]\nfig = px.choropleth(asia_data, locations=\"Country\", \n                    locationmode='country names', color=\"Country\", \n                    hover_name=\"Confirmed\", range_color=[1,2000], \n                    color_continuous_scale='Reds', \n                    title='Asian nations with Confirmed Cases', scope='asia', height=600)\nfig.update_coloraxes(colorbar_title=\"Countries Affected\",colorscale=\"sunsetdark\")\nfig.show()","64be77a9":"temp = casescountry_df.groupby('Last_Update')['Recovered', 'Deaths', 'Confirmed'].sum().reset_index()\ntemp = temp.melt(id_vars=\"Last_Update\", value_vars=['Recovered', 'Deaths', 'Confirmed'],\n                 var_name='case', value_name='count')\n\n\n#fig = px.line(temp, x=\"Last_Update\", y=\"count\", color='case',\n#             title='Cases over time: Line Plot', color_discrete_sequence = ['cyan', 'red', 'orange'])\n#fig.show()\n\n\nfig = px.area(temp, x=\"Last_Update\", y=\"count\", color='case',\n             title='Cases over time: Area Plot', color_discrete_sequence = ['cyan', 'red', 'orange'])\nfig.show()","568116ec":"#px.set_mapbox_access_token(open(\".mapbox_token\").read())\n\n#px.scatter_mapbox(casescountry_df, lat=\"Lat\", lon=\"Long_\",     color=np.power(casescountry_df[\"Confirmed\"],0.3)-2 , \n#                        size= np.power(casescountry_df[\"Confirmed\"]+1,0.3)-1,\n#                  color_continuous_scale=px.colors.cyclical.IceFire, size_max=15, zoom=10)\n#fig.show()\n\nafrica_data = casescountry_df[casescountry_df[\"continent\"]==\"Africa\"]\nfig = px.choropleth(africa_data, locations=\"Country\", \n                    locationmode='country names', color=\"Country\", \n                    hover_name=\"Confirmed\", range_color=[1,12], \n                    color_continuous_scale='Oranges', \n                    title='African Countries with Confirmed Cases', scope='africa', height=600)\nfig.show()","d01a4ba1":"df = casescountry_df\ndf[\"world\"] = \"world\" # in order to have a single root node\nfig = px.treemap(df, path=['world', 'continent', 'Country'], values='Confirmed',\n                  color='Country', hover_data=['Deaths'],\n                  title=' COVID-19 Affected Countries ',\n                  color_continuous_scale=px.colors.diverging.Tealrose,\n                  color_continuous_midpoint=np.average(df['Active'], weights=df['Confirmed']))\nfig.show()","b91dea38":"import math\nmap_ = folium.Map(location=[54,15], tiles='cartodbpositron', zoom_start=2)\n\n# Add points to the map\nmc = MarkerCluster()\nfor idx, row in casescountry_df.iterrows():\n    if not math.isnan(row['Long_']) and not math.isnan(row['Lat']):\n        mc.add_child(Marker([row['Lat'], row['Long_']]))\nmap_.add_child(mc)\n\n# Display the map\n#map_","d01c31f3":"continentwise_df_tmp = continentwise_df\ncontinentwise_df_tmp[\"continent\"] = continentwise_df_tmp.index\npx.area(continentwise_df_tmp, x=\"Confirmed\", y=\"Deaths\", color=\"continent\", line_group=\"continent\")","f31de425":"df_data = casestime_df.groupby(['Last_Update', 'Country'])['Confirmed', 'Deaths'].max().reset_index()\ndf_data[\"Last_Update\"] = pd.to_datetime( df_data[\"Last_Update\"]).dt.strftime('%m\/%d\/%Y')\n\npx.scatter_geo(df_data, locations=\"Country\", locationmode='country names', \n                     color=np.power(df_data[\"Confirmed\"],0.3)-2 , size= np.power(df_data[\"Confirmed\"]+1,0.3)-1, hover_name=\"Country\",\n                     hover_data=[\"Confirmed\"],\n                     range_color= [0, max(np.power(df_data[\"Confirmed\"],0.3))], \n                     projection=\"natural earth\", animation_frame=\"Last_Update\", \n                     color_continuous_scale=px.colors.cyclical.IceFire,\n                     title='COVID-19: Progression of spread'\n                    )\n","97f636af":"import math\nmap_ = folium.Map(location=[54,15], tiles='cartodbpositron', zoom_start=2)\n\n# Add points to the map\nmc = MarkerCluster()\nfor idx, row in confirmed_df.iterrows():\n    if not math.isnan(row['Long']) and not math.isnan(row['Lat']):\n        mc.add_child(Marker([row['Lat'], row['Long']]))\nmap_.add_child(mc)\n\n# Display the map\nmap_","f318dba7":"data_path = Path('\/kaggle\/input\/covid19-global-forecasting-week-4\/')\nwk4train_df = pd.read_csv(data_path \/ 'train.csv')\nwk4test_df = pd.read_csv(data_path \/ 'test.csv')","f196fff3":"print ('Training Data provided from', wk4train_df['Date'].min(),'to ', wk4train_df['Date'].max() )\n\nprint ('Test Data provided from', wk4test_df['Date'].min(),'to ', wk4test_df['Date'].max() )\n","bc240f1c":"traintest_df = pd.concat([wk4train_df, wk4test_df])\nprint(wk4train_df.shape, wk4test_df.shape, traintest_df.shape)","002966fd":"wk4train_df.rename(columns={'Province_State':'Province','Country_Region':'Country'}, inplace=True)\nwk4test_df.rename(columns={'Province_State':'Province','Country_Region':'Country'}, inplace=True)\n#clean_df.rename(columns={'Province\/State':'Province','Country\/Region':'Country'}, inplace=True)\ntraintest_df.rename(columns={'Province_State':'Province','Country_Region':'Country'}, inplace=True)","f7440f0e":"wk4train_df['Date'] = pd.to_datetime(wk4train_df['Date'])\nwk4test_df['Date'] = pd.to_datetime(wk4test_df['Date'])\ntraintest_df['Date'] = pd.to_datetime(traintest_df['Date'])","324257c3":"def create_time_features(df):\n    \"\"\"\n    Creates time series features from datetime index\n    \"\"\"\n    #df['date'] = df.index\n    df['hour'] = df['Date'].dt.hour\n    df['dayofweek'] = df['Date'].dt.dayofweek\n    df['quarter'] = df['Date'].dt.quarter\n    df['month'] = df['Date'].dt.month\n    df['year'] = df['Date'].dt.year\n    df['dayofyear'] = df['Date'].dt.dayofyear\n    df['dayofmonth'] = df['Date'].dt.day\n    df['weekofyear'] = df['Date'].dt.weekofyear\n    \n    X = df[['hour','dayofweek','quarter','month','year',\n           'dayofyear','dayofmonth','weekofyear']]\n    return X","d740ddab":"create_time_features(wk4train_df).head()\ncreate_time_features(wk4test_df).head()\ncreate_time_features(traintest_df).head()","62d59847":"print(wk4train_df[\"Date\"].min(), \"-\", wk4train_df[\"Date\"].max())\nprint(wk4test_df[\"Date\"].min(), \"-\", wk4test_df[\"Date\"].max())","6698b812":"traintest_df.loc[traintest_df['Country'] == 'US', \"Country\"] = 'USA'\n\ntraintest_df.loc[traintest_df['Country'] == 'Korea, South', \"Country\"] = 'South Korea'\ntraintest_df.loc[traintest_df['Country'] == 'Taiwan*', \"Country\"] = 'Taiwan'\ntraintest_df.loc[traintest_df['Country'] == 'Congo (Kinshasa)', \"Country\"] = 'Democratic Republic of the Congo'\ntraintest_df.loc[traintest_df['Country'] == \"Cote d'Ivoire\", \"Country\"] = \"C\u00f4te d'Ivoire\"\ntraintest_df.loc[traintest_df['Country'] == \"Reunion\", \"Country\"] = \"R\u00e9union\"\ntraintest_df.loc[traintest_df['Country'] == 'Congo (Brazzaville)', \"Country\"] = 'Republic of the Congo'\ntraintest_df.loc[traintest_df['Country'] == 'Bahamas, The', \"Country\"] = 'Bahamas'\ntraintest_df.loc[traintest_df['Country'] == 'Gambia, The', \"Country\"] = 'Gambia'\ntraintest_df.loc[traintest_df[\"Country\"] == \"Burma\", \"Country\"] = \"Myanmar\"\n\ntraintest_df['Province'] = traintest_df['Province'].replace(np.nan,'')\ntraintest_df['Country_Province'] = traintest_df['Country'] + \".\" + traintest_df['Province']","bb71f129":"train_copy = wk4train_df.copy()\ntest_copy = wk4test_df.copy()\ntraintest_copy = traintest_df.copy()","e2f1211b":"#Mobility\nmobility_df=pd.read_csv(\"..\/input\/google-cummunity-mobility-cv-19\/2020-03-29-reports.csv\")\n\nmobility_df[\"mob_date\"] = \"\"\nmobility_df[\"country_alpha_2_code\"] =\"\"\nmobility_df[\"country_alpha_3_code\"] =\"\"\nmobility_df[\"Province\"] =\"\"\nmobility_df[\"Country\"] = \"\"\n#mobility_df[\"continent\"] = \"\"\n\nfor i in range(0, mobility_df.shape[0]):\n    mobility_df[\"mob_date\"][i] = mobility_df[\"file_name\"][i][0:10]\n    mobility_df[\"country_alpha_2_code\"][i] = mobility_df[\"file_name\"][i][11:13]   #l = len(mobility_df[\"file_name\"][i])\n    x = mobility_df['file_name'][i].split('.')    #x[0]\n    pos = x[0].find('_Mobility')\n    mobility_df[\"Province\"][i] = mobility_df[\"file_name\"][i][14:pos]\n    mobility_df[\"Country\"][i] = pc.country_alpha2_to_country_name(mobility_df['country_alpha_2_code'][i])\n    mobility_df[\"country_alpha_3_code\"][i] = pc.country_name_to_country_alpha3(mobility_df['Country'][i])\n\n    \n#mobility_df.tail(2)    \n\n#mobility_df[mobility_df[\"Country\"]==\"United States\"]\nmobility_df.rename(columns={'Country_Region':'Country', 'Province_State':'Province'}, inplace=True)\nmobility_df.loc[mobility_df[\"Country\"] == \"United States\", \"Country\"] = \"USA\"\n#mobility_df[mobility_df[\"Country\"]==\"USA\"].head(3)\n\nmobility_df.loc[mobility_df['Country'] == 'Korea, South', \"Country\"] = 'South Korea'\nmobility_df.loc[mobility_df['Country'] == 'Taiwan*', \"Country\"] = 'Taiwan'\nmobility_df.loc[mobility_df['Country'] == 'Congo (Kinshasa)', \"Country\"] = 'Democratic Republic of the Congo'\nmobility_df.loc[mobility_df['Country'] == \"Cote d'Ivoire\", \"Country\"] = \"C\u00f4te d'Ivoire\"\nmobility_df.loc[mobility_df['Country'] == \"Reunion\", \"Country\"] = \"R\u00e9union\"\nmobility_df.loc[mobility_df['Country'] == 'Congo (Brazzaville)', \"Country\"] = 'Republic of the Congo'\nmobility_df.loc[mobility_df['Country'] == 'Bahamas, The', \"Country\"] = 'Bahamas'\nmobility_df.loc[mobility_df['Country'] == 'Gambia, The', \"Country\"] = 'Gambia'\n\nmobility_df['Province'] = mobility_df['Province'].replace(np.nan,'')\nmobility_df['Country_Province'] = mobility_df['Country'] + \".\" + mobility_df['Province']","03d10755":"# getting all countries\ncountries = np.asarray(mobility_df[\"Country\"])\n\n# Continent_code to Continent_names\ncontinents = {\n    'NA': 'North America',\n    'SA': 'South America', \n    'AS': 'Asia',\n    'OC': 'Australia',\n    'AF': 'Africa',\n    'EU' : 'Europe',\n    'na' : 'Others'\n}\n\n# Defininng Function for getting continent code for country.\ndef country_to_continent_code(Country):\n    try:\n        return pc.country_alpha2_to_continent_code(pc.country_name_to_country_alpha2(Country))\n    except :\n        return 'na'\n\n#Collecting Continent Information\nmobility_df.insert(1,\"continent\", [continents[country_to_continent_code(Country)] for Country in countries[:]])","6fc54c06":"mobility_df_tmp = mobility_df.copy()\nmobility_df_tmp = mobility_df_tmp.drop(['Country','Province'],  axis=1)\n\ntraintest_df = pd.merge(traintest_df, mobility_df_tmp, on='Country_Province', how='left')\n\ntraintest_df[\"mob_date\"] = pd.to_datetime(traintest_df[\"mob_date\"])\ntraintest_df.head(2)","5bb09dfb":"politics_governance_df = pd.read_csv('\/kaggle\/input\/global-politcs-and-governance-data-apr-2020\/politics_apr2020.csv')\n\npolitics_governance_df.rename(columns={'country':'Country'}, inplace=True)\npolitics_governance_df.head(2)\n\npolitics_governance_df.loc[politics_governance_df['Country'] == 'US', \"Country\"] = 'USA'\n\npolitics_governance_df.loc[politics_governance_df['Country'] == 'Korea, South', \"Country\"] = 'South Korea'\npolitics_governance_df.loc[politics_governance_df['Country'] == 'Taiwan*', \"Country\"] = 'Taiwan'\npolitics_governance_df.loc[politics_governance_df['Country'] == 'Congo (Kinshasa)', \"Country\"] = 'Democratic Republic of the Congo'\npolitics_governance_df.loc[politics_governance_df['Country'] == \"Cote d'Ivoire\", \"Country\"] = \"C\u00f4te d'Ivoire\"\npolitics_governance_df.loc[politics_governance_df['Country'] == \"Reunion\", \"Country\"] = \"R\u00e9union\"\npolitics_governance_df.loc[politics_governance_df['Country'] == 'Congo (Brazzaville)', \"Country\"] = 'Republic of the Congo'\npolitics_governance_df.loc[politics_governance_df['Country'] == 'Bahamas, The', \"Country\"] = 'Bahamas'\npolitics_governance_df.loc[politics_governance_df['Country'] == 'Gambia, The', \"Country\"] = 'Gambia'\npolitics_governance_df.loc[politics_governance_df[\"Country\"] == \"Burma\", \"Country\"] = \"Myanmar\"\n\n","38ba0047":"traintest_df = pd.merge(traintest_df, politics_governance_df, on='Country', how='left')\ntraintest_df.head()","66006c90":"data_release_df = pd.read_csv ('\/kaggle\/input\/covid19-country-data-wk3-release\/Data Join - RELEASE.csv')\n#data_release_df.isnull().sum()\n\ndata_release_df['temperature']=data_release_df['temperature'].replace(np.nan,'')\ndata_release_df['humidity']=data_release_df['humidity'].replace(np.nan,'')\ndata_release_df['Personality_pdi']=data_release_df['Personality_pdi'].replace(np.nan,'')\ndata_release_df['Personality_idv']=data_release_df['Personality_idv'].replace(np.nan,'')\ndata_release_df['Personality_mas']=data_release_df['Personality_mas'].replace(np.nan,'')\ndata_release_df['Personality_uai']=data_release_df['Personality_uai'].replace(np.nan,'')\ndata_release_df['Personality_ltowvs']=data_release_df['Personality_ltowvs'].replace(np.nan,'')\ndata_release_df['personality_perform']=data_release_df['personality_perform'].replace(np.nan,'')\n\ndata_release_df.rename(columns={'Country_Region':'Country', 'Province_State':'Province'}, inplace=True)\n\ndata_release_df.loc[data_release_df['Country'] == 'Korea, South', \"Country\"] = 'South Korea'\ndata_release_df.loc[data_release_df['Country'] == 'Taiwan*', \"Country\"] = 'Taiwan'\ndata_release_df.loc[data_release_df['Country'] == 'Congo (Kinshasa)', \"Country\"] = 'Democratic Republic of the Congo'\ndata_release_df.loc[data_release_df['Country'] == \"Cote d'Ivoire\", \"Country\"] = \"C\u00f4te d'Ivoire\"\n#data_release_df.loc[data_release_df['Country'] == \"Reunion\", \"Country\"] = \"R\u00e9union\"\ndata_release_df.loc[data_release_df['Country'] == 'Congo (Brazzaville)', \"Country\"] = 'Republic of the Congo'\n\ndata_release_df.loc[data_release_df[\"Country\"] == \"Burma\", \"Country\"] = \"Myanmar\"\n\ndata_release_df['Province'] = data_release_df['Province'].replace(np.nan,'')\ndata_release_df['Country_Province'] = data_release_df['Country'] + \".\" + data_release_df['Province']","f616b685":"data_release_df_tmp = data_release_df.copy()\ndata_release_df_tmp = data_release_df_tmp.drop(['Country','Province'],  axis=1)\n\ntraintest_df = pd.merge(traintest_df, data_release_df_tmp, on='Country_Province', how='left')\ntraintest_df.shape","4dfc73ac":"#WDI reports\nwdi_df = pd.read_csv('..\/input\/world-bank-wdi-212-health-systems\/2.12_Health_systems.csv')\n\n# Display NaN records\nwdi_nan_df = (wdi_df[wdi_df['Country_Region'].isna()])\nwdi_nan_df.head(3)\n#Drop those NaN records\nwdi_df = wdi_df.drop(wdi_df[wdi_df['Country_Region'].isna()].index, axis = 0)\n#wdi_df.shape\n#wdi_df.head(3)\n\nwdi_df['Health_exp_pct_GDP_2016']=wdi_df['Health_exp_pct_GDP_2016'].replace(np.nan,'')\nwdi_df['Health_exp_public_pct_2016']=wdi_df['Health_exp_public_pct_2016'].replace(np.nan,'')\nwdi_df['Health_exp_out_of_pocket_pct_2016']=wdi_df['Health_exp_out_of_pocket_pct_2016'].replace(np.nan,'')\nwdi_df['Health_exp_per_capita_USD_2016']=wdi_df['Health_exp_per_capita_USD_2016'].replace(np.nan,'')\nwdi_df['per_capita_exp_PPP_2016']=wdi_df['per_capita_exp_PPP_2016'].replace(np.nan,'')\nwdi_df['External_health_exp_pct_2016']=wdi_df['External_health_exp_pct_2016'].replace(np.nan,'')\nwdi_df['Physicians_per_1000_2009-18']=wdi_df['Physicians_per_1000_2009-18'].replace(np.nan,'')\n\nwdi_df['Nurse_midwife_per_1000_2009-18']=wdi_df['Nurse_midwife_per_1000_2009-18'].replace(np.nan,'')\nwdi_df['Specialist_surgical_per_1000_2008-18']=wdi_df['Specialist_surgical_per_1000_2008-18'].replace(np.nan,'')\nwdi_df['Completeness_of_birth_reg_2009-18']=wdi_df['Completeness_of_birth_reg_2009-18'].replace(np.nan,'')\nwdi_df['Completeness_of_death_reg_2008-16']=wdi_df['Completeness_of_death_reg_2008-16'].replace(np.nan,'')\n\n\nwdi_df.rename(columns={'Country_Region':'Country', 'Province_State':'Province'}, inplace=True)\n#wdi_df[wdi_df[\"Country\"]==\"US\"]\nwdi_df.loc[wdi_df[\"Country\"] == \"US\", \"Country\"] = \"USA\"\n#wdi_df[wdi_df[\"Country\"]==\"USA\"]\n\nwdi_df.loc[wdi_df['Country'] == 'Korea, South', \"Country\"] = 'South Korea'\nwdi_df.loc[wdi_df['Country'] == 'Taiwan*', \"Country\"] = 'Taiwan'\nwdi_df.loc[wdi_df['Country'] == 'Congo (Kinshasa)', \"Country\"] = 'Democratic Republic of the Congo'\nwdi_df.loc[wdi_df['Country'] == \"Cote d'Ivoire\", \"Country\"] = \"C\u00f4te d'Ivoire\"\nwdi_df.loc[wdi_df['Country'] == \"Reunion\", \"Country\"] = \"R\u00e9union\"\nwdi_df.loc[wdi_df['Country'] == 'Congo (Brazzaville)', \"Country\"] = 'Republic of the Congo'\nwdi_df.loc[wdi_df['Country'] == 'Bahamas, The', \"Country\"] = 'Bahamas'\nwdi_df.loc[wdi_df['Country'] == 'Gambia, The', \"Country\"] = 'Gambia'\nwdi_df.loc[wdi_df[\"Country\"] == \"Burma\", \"Country\"] = \"Myanmar\"\n\nwdi_df['Province'] = wdi_df['Province'].replace(np.nan,'')\nwdi_df['Country_Province'] = wdi_df['Country'] + \".\" + wdi_df['Province']","11886007":"wdi_df_tmp = wdi_df.copy()\nwdi_df_tmp = wdi_df_tmp.drop(['Country','Province'],  axis=1)\n\ntraintest_df = pd.merge(traintest_df, wdi_df_tmp, on='Country_Province', how='left')\ntraintest_df.head()","5d66c059":"lockdown_df = pd.read_csv('\/kaggle\/input\/covid19-lockdown-dates-by-country\/countryLockdowndates.csv')\nlockdownJHU_df = pd.read_csv('\/kaggle\/input\/covid19-lockdown-dates-by-country\/countryLockdowndatesJHUMatch.csv')\nlockdownJHU_df.rename(columns={'Country\/Region':'Country'}, inplace=True)\n\nlockdownJHU_df.loc[lockdownJHU_df[\"Country\"] == \"US\", \"Country\"] = \"USA\"\n#lockdownJHU_df[lockdownJHU_df[\"Country\"]==\"USA\"]\n\nlockdownJHU_df.loc[lockdownJHU_df['Country'] == 'Korea, South', \"Country\"] = 'South Korea'\nlockdownJHU_df.loc[lockdownJHU_df['Country'] == 'Taiwan*', \"Country\"] = 'Taiwan'\nlockdownJHU_df.loc[lockdownJHU_df['Country'] == 'Congo (Kinshasa)', \"Country\"] = 'Democratic Republic of the Congo'\nlockdownJHU_df.loc[lockdownJHU_df['Country'] == \"Cote d'Ivoire\", \"Country\"] = \"C\u00f4te d'Ivoire\"\nlockdownJHU_df.loc[lockdownJHU_df['Country'] == \"Reunion\", \"Country\"] = \"R\u00e9union\"\n#lockdownJHU_df.loc[lockdownJHU_df['Country'] == 'Congo (Brazzaville)', \"Country\"] = 'Democratic Republic of the Congo'\n#lockdownJHU_df.loc[lockdownJHU_df['Country'] == 'DR Congo', \"Country\"] = 'Republic of the Congo'\nlockdownJHU_df.loc[lockdownJHU_df['Country'] == 'Bahamas, The', \"Country\"] = 'Bahamas'\nlockdownJHU_df.loc[lockdownJHU_df['Country'] == 'Gambia, The', \"Country\"] = 'Gambia'\nlockdownJHU_df.loc[lockdownJHU_df[\"Country\"] == \"Burma\", \"Country\"] = \"Myanmar\"\n\nlockdownJHU_df.rename(columns={'Date':'lockdown_date'}, inplace=True)\n\ntraintest_df = pd.merge(traintest_df, lockdownJHU_df, on='Country', how='left')\ntraintest_df['lockdown_date'] = pd.to_datetime(traintest_df['lockdown_date'])\ntraintest_df.head()","9a63b62f":"#week4\nday_before_valid = 78 + 7 # 3-11 day  before of validation\nday_before_public = 85 +7 # 3-18 last day of train\nday_before_launch = 92 + 7# 4-1 last day before launch\nday_before_private = traintest_df['dayofyear'][pd.isna(traintest_df['ForecastId'])].max() # last day of train","e7325360":"print ('Training Data provided from', wk4train_df['Date'].min(),'to ', wk4train_df['Date'].max() )\n\nprint ('Test Data provided from', wk4test_df['Date'].min(),'to ', wk4test_df['Date'].max() )","20abeb30":"def calc_score(y_true, y_pred):\n    y_true[y_true<0] = 0\n    score = metrics.mean_squared_error(np.log(y_true.clip(0, 1e10)+1), np.log(y_pred[:]+1))**0.5\n    return score","7c676bec":"# covert object type to float\ndef func(x):\n    x_new = 0\n    try:\n        x_new = float(x.replace(\",\", \"\"))\n    except:\n#         print(x)\n        x_new = np.nan\n    return x_new\ncols = [\n   'TRUE POPULATION', \n    ' TFR ', 'pct_in_largest_city', \n    ' Avg_age ', 'humidity',\n    'temperature'  ,                                 \n    'Personality_pdi', 'Personality_idv', 'Personality_mas',\n       'Personality_uai', 'Personality_ltowvs', \n      'personality_perform', 'personality_agreeableness',\n      'AIR_AVG',\n       'Health_exp_pct_GDP_2016', 'Health_exp_public_pct_2016',\n       'Health_exp_out_of_pocket_pct_2016', 'Health_exp_per_capita_USD_2016',\n       'per_capita_exp_PPP_2016', 'External_health_exp_pct_2016',\n       'Physicians_per_1000_2009-18', 'Nurse_midwife_per_1000_2009-18',\n       'Specialist_surgical_per_1000_2008-18',\n       'Completeness_of_birth_reg_2009-18',\n       'Completeness_of_death_reg_2008-16'                                                                      \n]\nfor col in cols:\n    traintest_df[col] = traintest_df[col].apply(lambda x: func(x))  \nprint(traintest_df['AIR_AVG'].dtype)","fb777fb4":"traintest_df['country_alpha_2_code'] = traintest_df['country_alpha_2_code'].astype(str)\ntraintest_df['country_alpha_3_code'] = traintest_df['country_alpha_3_code'].astype(str)\ntraintest_df['leader'] = traintest_df['leader'].astype(str)\ntraintest_df['government'] = traintest_df['government'].astype(str)\ntraintest_df['World_Bank_Name'] = traintest_df['World_Bank_Name'].astype(str)\ntraintest_df['Type'] = traintest_df['Type'].astype(str)","bd368f9b":"traintest_df.dtypes","dec41c21":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\n\ntraintest_df['country_encoded'] = labelencoder.fit_transform(traintest_df['Country'])\ntraintest_df['province_encoded'] = labelencoder.fit_transform(traintest_df['Province'])\ntraintest_df['cnpn_encoded'] = labelencoder.fit_transform(traintest_df['Country_Province'])\ntraintest_df['cn_alp2_encoded'] = labelencoder.fit_transform(traintest_df['country_alpha_2_code'])\ntraintest_df['cn_alp3_encoded'] = labelencoder.fit_transform(traintest_df['country_alpha_3_code'])\ntraintest_df['leader_encoded'] = labelencoder.fit_transform(traintest_df['leader'])\ntraintest_df['gn_encoded'] = labelencoder.fit_transform(traintest_df['government'])\ntraintest_df['wbn_encoded'] = labelencoder.fit_transform(traintest_df['World_Bank_Name'])\ntraintest_df['Type_encoded'] = labelencoder.fit_transform(traintest_df['Type'])","049d61e6":"#traintest_df.loc[traintest_df[\"Date\"]<\"2020-03-20\", \"split\"] = \"train\"\n#traintest_df.loc[traintest_df[\"Date\"]>=\"2020-03-20\", \"split\"] = \"test\"","fa8b8966":"traintest_df.shape","f446d1b6":"'''\nplt.figure(figsize=(35,20))\na = sns.heatmap(traintest_df.dropna().corr(), annot = True, cmap = 'cubehelix')\na.Title = ' Week3 - COVID19 - Data Correlation';\nrotx = a.set_xticklabels(a.get_xticklabels(), rotation=90)\nroty = a.set_yticklabels(a.get_yticklabels(), rotation=45)\nplt.show()\n'''","9c2ea150":"# get place list\nplaces = np.sort(traintest_df['Country_Province'].unique())\nprint(len(places))","517d2533":"# calc cases, fatalities per day\ntraintest_df1 = copy.deepcopy(traintest_df)\ntraintest_df1['cases\/day'] = 0\ntraintest_df1['fatal\/day'] = 0\ntmp_list = np.zeros(len(traintest_df1))\nfor place in places:\n    tmp = traintest_df1['ConfirmedCases'][traintest_df1['Country_Province']==place].values\n    tmp[1:] -= tmp[:-1]\n    traintest_df1['cases\/day'][traintest_df1['Country_Province']==place] = tmp\n    tmp = traintest_df1['Fatalities'][traintest_df1['Country_Province']==place].values\n    tmp[1:] -= tmp[:-1]\n    traintest_df1['fatal\/day'][traintest_df1['Country_Province']==place] = tmp\nprint(traintest_df1.shape)\ntraintest_df1[traintest_df1['Country_Province']=='Italy.'].head()","37d87278":"# aggregate cases and fatalities\ndef do_aggregation(df, col, mean_range):\n    df_new = copy.deepcopy(df)\n    col_new = '{}_({}-{})'.format(col, mean_range[0], mean_range[1])\n    df_new[col_new] = 0\n    tmp = df_new[col].rolling(mean_range[1]-mean_range[0]+1).mean()\n    df_new[col_new][mean_range[0]:] = tmp[:-(mean_range[0])]\n    df_new[col_new][pd.isna(df_new[col_new])] = 0\n    return df_new[[col_new]].reset_index(drop=True)\n\ndef do_aggregations(df):\n    df = pd.concat([df, do_aggregation(df, 'cases\/day', [1,1]).reset_index(drop=True)], axis=1)\n    df = pd.concat([df, do_aggregation(df, 'cases\/day', [1,7]).reset_index(drop=True)], axis=1)\n    df = pd.concat([df, do_aggregation(df, 'cases\/day', [8,14]).reset_index(drop=True)], axis=1)\n    df = pd.concat([df, do_aggregation(df, 'cases\/day', [15,21]).reset_index(drop=True)], axis=1)\n    df = pd.concat([df, do_aggregation(df, 'fatal\/day', [1,1]).reset_index(drop=True)], axis=1)\n    df = pd.concat([df, do_aggregation(df, 'fatal\/day', [1,7]).reset_index(drop=True)], axis=1)\n    df = pd.concat([df, do_aggregation(df, 'fatal\/day', [8,14]).reset_index(drop=True)], axis=1)\n    df = pd.concat([df, do_aggregation(df, 'fatal\/day', [15,21]).reset_index(drop=True)], axis=1)\n    for threshold in [1, 10, 100]:\n        days_under_threshold = (df['ConfirmedCases']<threshold).sum()\n        tmp = df['dayofyear'].values - 22 - days_under_threshold\n        tmp[tmp<=0] = 0\n        df['days_since_{}cases'.format(threshold)] = tmp\n            \n    for threshold in [1, 10, 100]:\n        days_under_threshold = (df['Fatalities']<threshold).sum()\n        tmp = df['dayofyear'].values - 22 - days_under_threshold\n        tmp[tmp<=0] = 0\n        df['days_since_{}fatal'.format(threshold)] = tmp\n    \n    # process China\/Hubei\n    if df['Country_Province'][0]=='China\/Hubei':\n        df['days_since_1cases'] += 35 # 2019\/12\/8\n        df['days_since_10cases'] += 35-13 # 2019\/12\/8-2020\/1\/2 assume 2019\/12\/8+13\n        df['days_since_100cases'] += 4 # 2020\/1\/18\n        df['days_since_1fatal'] += 13 # 2020\/1\/9\n    return df","1f584902":"traintest_df_cc = copy.deepcopy(traintest_df)","4ae148c3":"traintest_df1[traintest_df1['Country_Province']=='Italy.'].head(2)","da18908b":"traintest_df2 = []\nfor place in places[:]:\n    df_tmp = traintest_df1[traintest_df1['Country_Province']==place].reset_index(drop=True)\n    df_tmp = do_aggregations(df_tmp)\n    traintest_df2.append(df_tmp)\ntraintest_df2 = pd.concat(traintest_df2).reset_index(drop=True)\ntraintest_df2[traintest_df2['Country_Province']=='Italy.'].head()","2d751f38":"traintest_df2['cases\/day'] = traintest_df2['cases\/day'].astype(np.float)\ntraintest_df2['fatal\/day'] = traintest_df2['fatal\/day'].astype(np.float)","2e268534":"traintest_df2.shape","9ba9c742":"import xgboost as xgb\nparams = {\"objective\":\"reg:squaredlogerror\",'colsample_bytree': 0.3,'learning_rate': 0.015,\n                'max_depth': 5, 'alpha': 0.15}\n\n#cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3,\n#                    num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)","a87b401f":"# train model to predict fatalities\/day\n# features are selected manually based on valid score\ncol_target = 'fatal\/day'\ncol_var = [\n 'ForecastId' ,                                \n'Id',                                            \n'hour',                                            \n'dayofweek',                                       \n'quarter',                                         \n'month',                                        \n'year',                                           \n'dayofyear',                                       \n'dayofmonth',                                      \n'weekofyear',                                      \n'retail_recreation',                             \n'grocery_pharmacy',                              \n'parks',                                         \n'transit_station',                               \n'workplaces',                                    \n'residential',                                   \n'ccode',                                         \n'elected',                                      \n'age',                                          \n'male',                                          \n'militarycareer',                                \n'tenure_months',                                 \n'anticipation',                                  \n'ref_ant',                                       \n'leg_ant',                                       \n'exec_ant',                                      \n'irreg_lead_ant',                                \n'election_now',                                \n'election_recent',                               \n'leg_recent',                                   \n'exec_recent',                                   \n'lead_recent',                                  \n'ref_recent',                                    \n'direct_recent',                                 \n'indirect_recent',                             \n'victory_recent',                                \n'defeat_recent',                                 \n'change_recent',                             \n'nochange_recent',                              \n'delayed',                                      \n'prev_conflict',                                 \n'GDP_region',                                    \n'latitude',                                      \n'longitude',                                     \n'abs_latitude',                                  \n'murder',                                        \n'High_rises',                                    \n'max_high_rises',                                \n'AIR_CITIES',                                                                           \n'continent_gdp_pc',                              \n'continent_happiness',                           \n'continent_generosity',                          \n'continent_corruption',                         \n'continent_Life_expectancy',                      \n     'days_since_1cases', \n     'days_since_10cases', \n     'days_since_100cases',\n     'days_since_1fatal', \n     'days_since_10fatal', 'days_since_100fatal',\n    'cases\/day_(1-1)', \n    'cases\/day_(1-7)', \n     'cases\/day_(8-14)',  \n     'cases\/day_(15-21)',     \n     'fatal\/day_(1-1)', \n    'fatal\/day_(1-7)', \n    'fatal\/day_(8-14)', \n    'fatal\/day_(15-21)', \n  'TRUE POPULATION', \n    ' TFR ', 'pct_in_largest_city', \n    ' Avg_age ', 'humidity',\n    'temperature'  ,                                 \n    'Personality_pdi', 'Personality_idv', 'Personality_mas',\n       'Personality_uai', 'Personality_ltowvs', 'Personality_assertive',\n      'personality_perform', 'personality_agreeableness',\n      'AIR_AVG',\n       'Health_exp_pct_GDP_2016', 'Health_exp_public_pct_2016',\n       'Health_exp_out_of_pocket_pct_2016', 'Health_exp_per_capita_USD_2016',\n       'per_capita_exp_PPP_2016', 'External_health_exp_pct_2016',\n       'Physicians_per_1000_2009-18', 'Nurse_midwife_per_1000_2009-18',\n        'Type_encoded', 'leader_encoded',\n    'country_encoded','province_encoded',\n    'cnpn_encoded','cn_alp2_encoded',\n    'cn_alp3_encoded','gn_encoded','wbn_encoded',\n       'Specialist_surgical_per_1000_2008-18',\n       'Completeness_of_birth_reg_2009-18',\n      'Completeness_of_death_reg_2008-16'   \n]\ncol_cat = []\ndf_train = traintest_df2[(pd.isna(traintest_df2['ForecastId'])) & (traintest_df2['dayofyear']<=day_before_valid)]\ndf_valid = traintest_df2[(pd.isna(traintest_df2['ForecastId'])) & (day_before_valid<traintest_df2['dayofyear']) & (traintest_df2['dayofyear']<=day_before_public)]\ndf_test = traintest_df2[pd.isna(traintest_df2['ForecastId'])==False]\nX_train = df_train[col_var]\nX_valid = df_valid[col_var]\ny_train = np.log(df_train[col_target].values.clip(0, 1e10)+1)\ny_valid = np.log(df_valid[col_target].values.clip(0, 1e10)+1)\n\ntrain_data = xgb.DMatrix(np.asarray(X_train), y_train)\nvalid_data = xgb.DMatrix(np.asarray(X_valid), y_valid)\nxgb0 = xgb.train( params, train_data, evals=[(train_data, 'train')], num_boost_round=10000,early_stopping_rounds=10,verbose_eval=False ) \n","ba071567":"y_true = df_valid['fatal\/day'].values\ny_pred = np.exp(xgb0.predict(valid_data))-1\nscore = calc_score(y_true, y_pred)\nprint(\"{:.6f}\".format(score))","ce3ea8c6":"# train with all data before public\ndf_train = traintest_df2[(pd.isna(traintest_df2['ForecastId'])) & (traintest_df2['dayofyear']<=day_before_public)]\ndf_valid = traintest_df2[(pd.isna(traintest_df2['ForecastId'])) & (traintest_df2['dayofyear']<=day_before_public)]\ndf_test = traintest_df2[pd.isna(traintest_df2['ForecastId'])==False]\nX_train = df_train[col_var]\nX_valid = df_valid[col_var]\ny_train = np.log(df_train[col_target].values.clip(0, 1e10)+1)\ny_valid = np.log(df_valid[col_target].values.clip(0, 1e10)+1)\n\ntrain_data = xgb.DMatrix(np.asarray(X_train), y_train)\nvalid_data = xgb.DMatrix(np.asarray(X_valid), y_valid)\n\nxgb1 = xgb.train( params, train_data, evals=[(train_data, 'train')], num_boost_round=10000,early_stopping_rounds=10,verbose_eval=False ) ","fcf90b61":"# train model to predict cases\/day\ncol_target2 = 'cases\/day'\ncol_var2 = [\n 'ForecastId' ,                                \n'Id',                                            \n'hour',                                            \n'dayofweek',                                       \n'quarter',                                         \n'month',                                        \n'year',                                           \n'dayofyear',                                       \n'dayofmonth',                                      \n'weekofyear',                                      \n'retail_recreation',                             \n'grocery_pharmacy',                              \n'parks',                                         \n'transit_station',                               \n'workplaces',                                    \n'residential',                                   \n'ccode',                                         \n'elected',                                      \n'age',                                          \n'male',                                          \n'militarycareer',                                \n'tenure_months',                                 \n'anticipation',                                  \n'ref_ant',                                       \n'leg_ant',                                       \n'exec_ant',                                      \n'irreg_lead_ant',                                \n'election_now',                                \n'election_recent',                               \n'leg_recent',                                   \n'exec_recent',                                   \n'lead_recent',                                  \n'ref_recent',                                    \n'direct_recent',                                 \n'indirect_recent',                             \n'victory_recent',                                \n'defeat_recent',                                 \n'change_recent',                             \n'nochange_recent',                              \n'delayed',                                      \n'prev_conflict',                                 \n'GDP_region',                                    \n'latitude',                                      \n'longitude',                                     \n'abs_latitude',                                  \n'murder',                                        \n'High_rises',                                    \n'max_high_rises',                                \n'AIR_CITIES',                                                                           \n'continent_gdp_pc',                              \n'continent_happiness',                           \n'continent_generosity',                          \n'continent_corruption',                         \n'continent_Life_expectancy',                      \n     'days_since_1cases', \n     'days_since_10cases', \n     'days_since_100cases',\n     'days_since_1fatal', \n     'days_since_10fatal', 'days_since_100fatal',\n    'cases\/day_(1-1)', \n    'cases\/day_(1-7)', \n     'cases\/day_(8-14)',  \n     'cases\/day_(15-21)',     \n     'fatal\/day_(1-1)', \n    'fatal\/day_(1-7)', \n    'fatal\/day_(8-14)', \n    'fatal\/day_(15-21)', \n  'TRUE POPULATION', \n    ' TFR ', 'pct_in_largest_city', \n    ' Avg_age ', 'humidity',\n    'temperature'  ,                                 \n    'Personality_pdi', 'Personality_idv', 'Personality_mas',\n       'Personality_uai', 'Personality_ltowvs', 'Personality_assertive',\n      'personality_perform', 'personality_agreeableness',\n      'AIR_AVG',\n       'Health_exp_pct_GDP_2016', 'Health_exp_public_pct_2016',\n       'Health_exp_out_of_pocket_pct_2016', 'Health_exp_per_capita_USD_2016',\n       'per_capita_exp_PPP_2016', 'External_health_exp_pct_2016',\n       'Physicians_per_1000_2009-18', 'Nurse_midwife_per_1000_2009-18',\n        'Type_encoded', 'leader_encoded',\n    'country_encoded','province_encoded',\n    'cnpn_encoded','cn_alp2_encoded',\n    'cn_alp3_encoded','gn_encoded','wbn_encoded',\n       'Specialist_surgical_per_1000_2008-18',\n       'Completeness_of_birth_reg_2009-18',\n      'Completeness_of_death_reg_2008-16'  \n]\ncol_cat = []\ndf_train = traintest_df2[(pd.isna(traintest_df2['ForecastId'])) & (traintest_df2['dayofyear']<=day_before_valid)]\ndf_valid = traintest_df2[(pd.isna(traintest_df2['ForecastId'])) & (day_before_valid<traintest_df2['dayofyear']) & (traintest_df2['dayofyear']<=day_before_public)]\nX_train = df_train[col_var2]\nX_valid = df_valid[col_var2]\ny_train = np.log(df_train[col_target2].values.clip(0, 1e10)+1)\ny_valid = np.log(df_valid[col_target2].values.clip(0, 1e10)+1)\n\ntrain_data = xgb.DMatrix(np.asarray(X_train), y_train)\nvalid_data = xgb.DMatrix(np.asarray(X_valid), y_valid)\n\nxgb2 = xgb.train( params, train_data, evals=[(train_data, 'train')], num_boost_round=10000,early_stopping_rounds=10, verbose_eval=False ) \n","a2b99ddc":"y_true = df_valid['cases\/day'].values\ny_pred = np.exp(xgb2.predict(valid_data))-1\nscore = calc_score(y_true, y_pred)\nprint(\"{:.6f}\".format(score))","357e0552":"df_train = traintest_df2[(pd.isna(traintest_df2['ForecastId'])) & (traintest_df2['dayofyear']<=day_before_public)]\ndf_valid = traintest_df2[(pd.isna(traintest_df2['ForecastId'])) & (traintest_df2['dayofyear']<=day_before_public)]\nX_train = df_train[col_var2]\nX_valid = df_valid[col_var2]\ny_train = np.log(df_train[col_target2].values.clip(0, 1e10)+1)\ny_valid = np.log(df_valid[col_target2].values.clip(0, 1e10)+1)\n\ntrain_data = xgb.DMatrix(np.asarray(X_train), y_train)\nvalid_data = xgb.DMatrix(np.asarray(X_valid), y_valid)\n\nxgb3 = xgb.train( params, train_data,  evals=[(train_data, 'train')], num_boost_round=10000,early_stopping_rounds=10, verbose_eval=False ) \n","4b1e8216":"# train model to predict fatalities\/day\ndf_train = traintest_df2[(pd.isna(traintest_df2['ForecastId'])) & (traintest_df2['dayofyear']<=day_before_public)]\ndf_valid = traintest_df2[(pd.isna(traintest_df2['ForecastId'])) & (day_before_public<traintest_df2['dayofyear'])]\ndf_test = traintest_df2[pd.isna(traintest_df2['ForecastId'])==False]\nX_train = df_train[col_var]\nX_valid = df_valid[col_var]\ny_train = np.log(df_train[col_target].values.clip(0, 1e10)+1)\ny_valid = np.log(df_valid[col_target].values.clip(0, 1e10)+1)\ntrain_data = xgb.DMatrix(np.asarray(X_train), y_train)\nvalid_data = xgb.DMatrix(np.asarray(X_valid), y_valid)\n\nxgb4 = xgb.train( params, train_data, evals=[(train_data, 'train')], num_boost_round=10000,early_stopping_rounds=10, verbose_eval=False ) \n","afe0e9df":"# train with all data\ndf_train = traintest_df2[(pd.isna(traintest_df2['ForecastId']))]\ndf_valid = traintest_df2[(pd.isna(traintest_df2['ForecastId']))]\nX_train = df_train[col_var]\nX_valid = df_valid[col_var]\ny_train = np.log(df_train[col_target].values.clip(0, 1e10)+1)\ny_valid = np.log(df_valid[col_target].values.clip(0, 1e10)+1)\n\ntrain_data = xgb.DMatrix(np.asarray(X_train), y_train)\nvalid_data = xgb.DMatrix(np.asarray(X_valid), y_valid)\n\nxgb5 = xgb.train( params, train_data, evals=[(train_data, 'train')], num_boost_round=10000,early_stopping_rounds=10, verbose_eval=False ) \n\n","59870b6d":"# train model to predict cases\/day\ndf_train = traintest_df2[(pd.isna(traintest_df2['ForecastId'])) & (traintest_df2['dayofyear']<=day_before_public)]\ndf_valid = traintest_df2[(pd.isna(traintest_df2['ForecastId'])) & (day_before_public<traintest_df2['dayofyear'])]\nX_train = df_train[col_var2]\nX_valid = df_valid[col_var2]\ny_train = np.log(df_train[col_target2].values.clip(0, 1e10)+1)\ny_valid = np.log(df_valid[col_target2].values.clip(0, 1e10)+1)\n\ntrain_data = xgb.DMatrix(np.asarray(X_train), y_train)\nvalid_data = xgb.DMatrix(np.asarray(X_valid), y_valid)\n\nxgb6 = xgb.train( params, train_data, evals=[(train_data, 'train')], num_boost_round=10000,early_stopping_rounds=10, verbose_eval=False ) \n\n","26ad4778":"# train with all data\ndf_train = traintest_df2[(pd.isna(traintest_df2['ForecastId']))]\ndf_valid = traintest_df2[(pd.isna(traintest_df2['ForecastId']))]\nX_train = df_train[col_var2]\nX_valid = df_valid[col_var2]\ny_train = np.log(df_train[col_target2].values.clip(0, 1e10)+1)\ny_valid = np.log(df_valid[col_target2].values.clip(0, 1e10)+1)\n\n\ntrain_data = xgb.DMatrix(np.asarray(X_train), y_train)\nvalid_data = xgb.DMatrix(np.asarray(X_valid), y_valid)\n\nxgb7 = xgb.train( params, train_data, evals=[(train_data, 'train')], num_boost_round=10000,early_stopping_rounds=10, verbose_eval=False ) \n\n\n","2f43de0a":"# remove overlap for public LB prediction\ndf_tmp = traintest_df2[\n    ((traintest_df2['dayofyear']<=day_before_public)  & (pd.isna(traintest_df2['ForecastId'])))\n    | ((day_before_public<traintest_df2['dayofyear']) & (pd.isna(traintest_df2['ForecastId'])==False))].reset_index(drop=True)\ndf_tmp\ndf_tmp = df_tmp.drop([\n    'cases\/day_(1-1)', 'cases\/day_(1-7)', 'cases\/day_(8-14)', 'cases\/day_(15-21)', \n    'fatal\/day_(1-1)', 'fatal\/day_(1-7)', 'fatal\/day_(8-14)', 'fatal\/day_(15-21)',\n    'days_since_1cases', 'days_since_10cases', 'days_since_100cases',\n    'days_since_1fatal', 'days_since_10fatal', 'days_since_100fatal'\n                               ],  axis=1)\ntraintest_df3 = []\nfor i, place in enumerate(places[:]):\n    df_tmp2 = df_tmp[df_tmp['Country_Province']==place].reset_index(drop=True)\n    df_tmp2 = do_aggregations(df_tmp2)\n    traintest_df3.append(df_tmp2)\ntraintest_df3 = pd.concat(traintest_df3).reset_index(drop=True)\ntraintest_df3[traintest_df3['dayofyear']>day_before_public-2].head()","a538a974":"# remove overlap for private LB prediction\ndf_tmp = traintest_df2[\n    ((traintest_df2['dayofyear']<=day_before_private)  & (pd.isna(traintest_df2['ForecastId'])))\n    | ((day_before_private<traintest_df2['dayofyear']) & (pd.isna(traintest_df2['ForecastId'])==False))].reset_index(drop=True)\n\ndf_tmp\ndf_tmp = df_tmp.drop([\n    'cases\/day_(1-1)', 'cases\/day_(1-7)', 'cases\/day_(8-14)', 'cases\/day_(15-21)', \n    'fatal\/day_(1-1)', 'fatal\/day_(1-7)', 'fatal\/day_(8-14)', 'fatal\/day_(15-21)',\n    'days_since_1cases', 'days_since_10cases', 'days_since_100cases',\n    'days_since_1fatal', 'days_since_10fatal', 'days_since_100fatal'\n                               ],  axis=1)\ntraintest_df4 = []\nfor i, place in enumerate(places[:]):\n    df_tmp2 = df_tmp[df_tmp['Country_Province']==place].reset_index(drop=True)\n    df_tmp2 = do_aggregations(df_tmp2)\n    traintest_df4.append(df_tmp2)\ntraintest_df4 = pd.concat(traintest_df4).reset_index(drop=True)\ntraintest_df4[traintest_df4['dayofyear']>day_before_private-2].head()","46854ebc":"# predict test data in public\n# predict the cases and fatatilites one day at a time and use the predicts as next day's feature recursively.\ndf_preds = []\nfor i, place in enumerate(places[:]):\n    df_interest = copy.deepcopy(traintest_df3[traintest_df3['Country_Province']==place].reset_index(drop=True))\n    df_interest['cases\/day'][(pd.isna(df_interest['ForecastId']))==False] = -1\n    df_interest['fatal\/day'][(pd.isna(df_interest['ForecastId']))==False] = -1\n    len_known = (df_interest['dayofyear']<=day_before_public).sum()\n    len_unknown = (day_before_public<df_interest['dayofyear']).sum()\n    for j in range(len_unknown): # use predicted cases and fatal for next days' prediction\n        X_valid = df_interest[col_var].iloc[j+len_known]\n        X_valid2 = df_interest[col_var2].iloc[j+len_known]\n        validata = xgb.DMatrix(X_valid)\n        pred_f = xgb0.predict(validata)\n        #xgb.plot_importance()\n        validata2 = xgb.DMatrix(X_valid2)\n        pred_c = xgb2.predict(validata2)\n        pred_c = (np.exp(pred_c)-1).clip(0, 1e10)\n        pred_f = (np.exp(pred_f)-1).clip(0, 1e10)\n        df_interest['fatal\/day'][j+len_known] = pred_f\n        df_interest['cases\/day'][j+len_known] = pred_c\n        df_interest['Fatalities'][j+len_known] = df_interest['Fatalities'][j+len_known-1] + pred_f\n        df_interest['ConfirmedCases'][j+len_known] = df_interest['ConfirmedCases'][j+len_known-1] + pred_c\n#         print(df_interest['ConfirmedCases'][j+len_known-1], df_interest['ConfirmedCases'][j+len_known], pred_c)\n        df_interest = df_interest.drop([\n            'cases\/day_(1-1)', 'cases\/day_(1-7)', 'cases\/day_(8-14)', 'cases\/day_(15-21)', \n            'fatal\/day_(1-1)', 'fatal\/day_(1-7)', 'fatal\/day_(8-14)', 'fatal\/day_(15-21)',\n            'days_since_1cases', 'days_since_10cases', 'days_since_100cases',\n            'days_since_1fatal', 'days_since_10fatal', 'days_since_100fatal'\n\n                                       ],  axis=1)\n        df_interest = do_aggregations(df_interest)\n    if (i+1)%5==0:\n        print(\"{:3d}\/{}  {}, len known: {}, len unknown: {}\".format(i+1, len(places), place, len_known, len_unknown), df_interest.shape)\n    df_interest['fatal_pred'] = np.cumsum(df_interest['fatal\/day'].values)\n    df_interest['cases_pred'] = np.cumsum(df_interest['cases\/day'].values)\n    df_preds.append(df_interest)\ndf_preds = pd.concat(df_preds)","b97c59e4":"# predict test data in public\ndf_preds_pri = []\nfor i, place in enumerate(places[:]):\n    df_interest = copy.deepcopy(traintest_df4[traintest_df4['Country_Province']==place].reset_index(drop=True))\n    df_interest['cases\/day'][(pd.isna(df_interest['ForecastId']))==False] = -1\n    df_interest['fatal\/day'][(pd.isna(df_interest['ForecastId']))==False] = -1\n    len_known = (df_interest['dayofyear']<=day_before_private).sum()\n    len_unknown = (day_before_private<df_interest['dayofyear']).sum()\n    for j in range(len_unknown): # use predicted cases and fatal for next days' prediction\n        X_valid = df_interest[col_var].iloc[j+len_known]\n        X_valid2 = df_interest[col_var2].iloc[j+len_known]\n        validata = xgb.DMatrix(X_valid)\n        pred_f = xgb5.predict(validata)\n        validata2 = xgb.DMatrix(X_valid)\n        pred_c = xgb7.predict(validata2)\n        pred_c = (np.exp(pred_c)-1).clip(0, 1e10)\n        pred_f = (np.exp(pred_f)-1).clip(0, 1e10)\n        df_interest['fatal\/day'][j+len_known] = pred_f\n        df_interest['cases\/day'][j+len_known] = pred_c\n        df_interest['Fatalities'][j+len_known] = df_interest['Fatalities'][j+len_known-1] + pred_f\n        df_interest['ConfirmedCases'][j+len_known] = df_interest['ConfirmedCases'][j+len_known-1] + pred_c\n#         print(df_interest['ConfirmedCases'][j+len_known-1], df_interest['ConfirmedCases'][j+len_known], pred_c)\n        df_interest = df_interest.drop([\n            'cases\/day_(1-1)', 'cases\/day_(1-7)', 'cases\/day_(8-14)', 'cases\/day_(15-21)', \n            'fatal\/day_(1-1)', 'fatal\/day_(1-7)', 'fatal\/day_(8-14)', 'fatal\/day_(15-21)',\n            'days_since_1cases', 'days_since_10cases', 'days_since_100cases',\n            'days_since_1fatal', 'days_since_10fatal', 'days_since_100fatal'\n                                       ],  axis=1)\n        df_interest = do_aggregations(df_interest)\n    if (i+1)%5==0:\n        print(\"{:3d}\/{}  {}, len known: {}, len unknown: {}\".format(i+1, len(places), place, len_known, len_unknown), df_interest.shape)\n    df_interest['fatal_pred'] = np.cumsum(df_interest['fatal\/day'].values)\n    df_interest['cases_pred'] = np.cumsum(df_interest['cases\/day'].values)\n    df_preds_pri.append(df_interest)\ndf_preds_pri = pd.concat(df_preds_pri)","7a6dae35":"# merge 2 preds\ndf_preds[df_preds['dayofyear']>day_before_private] = df_preds_pri[df_preds['dayofyear']>day_before_private]","c288002b":"#df_preds.to_csv(\"df_preds.csv\", index=None)","6d76b85a":"# load sample submission\ndf_sub = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-4\/submission.csv\")\nprint(len(df_sub))\ndf_sub.head()\n# merge prediction with sub\ndf_sub = pd.merge(df_sub, traintest_df3[['ForecastId', 'Country_Province', 'dayofyear']])\ndf_sub = pd.merge(df_sub, df_preds[['Country_Province', 'dayofyear', 'cases_pred', 'fatal_pred']], on=['Country_Province', 'dayofyear',], how='left')\ndf_sub.head(10)","33e2fb6b":"# save\ndf_sub['ConfirmedCases'] = df_sub['cases_pred']\ndf_sub['Fatalities'] = df_sub['fatal_pred']\ndf_sub = df_sub[['ForecastId', 'ConfirmedCases', 'Fatalities']]\ndf_sub.to_csv(\"submission.csv\", index=None)\ndf_sub.head(10)","ac890e3e":"### COVID WEEK 4 PREDICTION","642c1d7f":"## Thanks to [this](https:\/\/www.kaggle.com\/osciiart\/covid-19-lightgbm-no-leak) great kernal, helped me for my model building ","525b8187":"### XGBoost Regressor","92fe9d3b":"### Politics and Governance Data","11f0c921":"> * Few external datasets for analysis","0b76d17b":"## Datasets used\n\nhttps:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\n\nhttps:\/\/www.kaggle.com\/danevans\/world-bank-wdi-212-health-systems\n\nhttps:\/\/www.kaggle.com\/lunatics\/global-politcs-and-governance-data-apr-2020\n\nhttps:\/\/www.kaggle.com\/koryto\/countryinfo\n\nhttps:\/\/www.kaggle.com\/david1013\/covid19-country-data-wk3-release\n\nhttps:\/\/www.kaggle.com\/jcyzag\/covid19-lockdown-dates-by-country\n\nhttps:\/\/www.kaggle.com\/jontyvani\/google-cummunity-mobility-cv-19\n\n\n","1169a2b6":"### Google Community Mobility Data","5fdb3a92":"### WDI Data","184c24a4":"### Thanks for reading, Suggestions and comments are most welcome.","a9470b0c":"## Clustering of COVID affected countries","03bd92ae":"### Continent wise and countrywise grouping","ddcc5157":"### Read the competition data and build model","90ca4a9c":"## Acknowledgement","2ca25465":"### Train for Private LB","57a92bbe":"### Lockdown details","100056b1":"week4\n\nPublic Leaderboard Period - 2020-04-01 - 2020-04-15\n\nPrivate Leaderboard Period - 2020-04-16 - 2020-05-14\n\ntrain\n2020-01-22 00:00:00 - 2020-04-11 00:00:00\n\ntest\n2020-04-02 00:00:00 - 2020-05-14 00:00:00","16a2ef56":"## Confirmed cases - all over the world","7fccfce8":"# EDA and Visualization","a4249c67":"### Country Data"}}