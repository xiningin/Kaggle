{"cell_type":{"9c589945":"code","5a85b651":"code","05ec0025":"markdown","963d4026":"markdown"},"source":{"9c589945":"import math\nimport time\nimport csv\nimport os\nimport numpy as np\nimport pandas as pd\nimport scipy.constants\n\n# Global parameters\nTRAIN_SIZE = 1e4\nTEST_SIZE = 1e3\nSEED = 2048\nFAIL_ON_NAN = False\n\nPATH = '\/kaggle\/working\/'\n\n# Holds the data for the experiments.  \nclass DataHolder:\n    def __init__(self, training, validation):\n        self.x_train = training[0]\n        self.x_validate = validation[0]\n        self.y_train = training[1]\n        self.y_validate = validation[1]\n\n    # Dump data to CSV files for examination.\n    def dump(self, base):\n        header = \",\".join([\"x\" + str(x)\n                           for x in range(1, 1 + self.x_train.shape[1])])\n        header += \",y1\"\n\n        self.y_train = np.reshape(self.y_train,(self.y_train.shape[0],1))\n        self.y_validate = np.reshape(self.y_validate,(self.y_validate.shape[0],1))\n        \n        np.savetxt(base + \"_train.csv\",\n                   np.hstack((self.x_train, self.y_train)),\n                   fmt='%10.5f', delimiter=',', header=header, comments=\"\")\n\n        np.savetxt(base + \"_validate.csv\",\n                   np.hstack((self.x_validate, self.y_validate)),\n                   fmt='%10.5f', delimiter=',', header=header, comments=\"\")\n\n# Generate data for the counts experiment.\ndef generate_data_counts(rows):\n    x_array = []\n    y_array = []\n\n    i = 0\n    while i < rows:\n        i += 1\n        x = [0] * 50\n        y = np.random.randint(0, len(x))\n\n        remaining = y\n        while remaining > 0:\n            idx = np.random.randint(0, len(x) - 1)\n            if x[idx] == 0:\n                x[idx] = 1\n                remaining -= 1\n\n        x_array.append(x)\n        y_array.append(y)\n\n    return np.array(x_array, dtype=np.float32), np.array(y_array, dtype=np.float32)\n\n\n# Generate data for the quadradic experiment, distance between polynomial roots.\ndef generate_data_quad(rows):\n    x_array = []\n    y_array = []\n\n    while len(x_array) < rows:\n        a = float(np.random.randint(-10, 10))\n        b = float(np.random.randint(-10, 10))\n        c = float(np.random.randint(-10, 10))\n        y = [0, 0]\n\n        try:\n            y = [\n                (-b + math.sqrt((b * b) - (4 * a * c))) \/ (2 * a),\n                (-b - math.sqrt((b * b) - (4 * a * c))) \/ (2 * a)]\n        except (ValueError, ZeroDivisionError):\n            pass\n\n        x_array.append([a, b, c])\n        y_array.append(abs(y[0] - y[1]))\n\n    return np.array(x_array, dtype=np.float32), np.array(y_array, dtype=np.float32)\n\n\n# Generate data for a BMI-like feature.\ndef generate_data_bmi(rows):\n    x_array = []\n    y_array = []\n\n    while len(x_array) < rows:\n        m = float(np.random.randint(25, 200))\n        h = float(np.random.uniform(1.5, 2.0))\n        y = m \/ (h * h)\n\n        x_array.append([h, m])\n        y_array.append(y)\n\n    return np.array(x_array, dtype=np.float32), np.array(y_array, dtype=np.float32)\n\n\n# Generate data for the provided function, usually a lambda.\ndef generate_data_fn(cnt, x_low, x_high, fn):\n    return lambda rows: generate_data_fn2(rows, cnt, x_low, x_high, fn)\n\n\n# Used internally for generate_data_fn\ndef generate_data_fn2(rows, cnt, x_low, x_high, fn):\n    x_array = []\n    y_array = []\n\n    while len(x_array) < rows:\n        args = np.random.uniform(x_low, x_high, cnt)\n\n        try:\n            y = fn(*args)\n            if not math.isnan(y):\n                x_array.append(args)\n                y_array.append(y)\n        except (ValueError, ZeroDivisionError):\n            pass\n\n    return np.array(x_array, dtype=np.float32), np.array(y_array, dtype=np.float32)\n\n\n# Generate data for the ratio experiment\ndef generate_data_ratio(rows):\n    x_array = []\n    y_array = []\n\n    while len(x_array) < rows:\n        x = [\n            np.random.uniform(0, 1),\n            np.random.uniform(0.01, 1)]\n\n        try:\n            y = x[0] \/ x[1]\n            x_array.append(x)\n            y_array.append(y)\n        except (ValueError, ZeroDivisionError):\n            pass\n\n    return np.array(x_array, dtype=np.float32), np.array(y_array, dtype=np.float32)\n\n\n# Generate data for the difference experiment\ndef generate_data_diff(rows):\n    x_array = []\n    y_array = []\n\n    while len(x_array) < rows:\n        x = [\n            np.random.uniform(0, 1),\n            np.random.uniform(0.01, 1)]\n\n        try:\n            y = x[0] - x[1]\n            x_array.append(x)\n            y_array.append(y)\n        except (ValueError, ZeroDivisionError):\n            pass\n\n    return np.array(x_array, dtype=np.float32), np.array(y_array, dtype=np.float32)\n\n\n# Run an experiment over all model types\ndef write_dataset(summary, name, generate_data):\n    print(f\"Generating {name}\")\n    np.random.seed(SEED)\n\n    data = DataHolder(\n        generate_data(TRAIN_SIZE),\n        generate_data(TEST_SIZE))\n\n    data.dump(os.path.join(PATH,name))\n    summary.append([name,np.min(data.y_train),np.max(data.y_train),\n                    np.mean(data.y_train),np.std(data.y_train)])\n\nsummary = []\nwrite_dataset(summary, \"counts\", generate_data_counts)  # 1\nwrite_dataset(summary, \"quad\", generate_data_quad)  # 2\nwrite_dataset(summary, \"sqrt\", generate_data_fn(\n    1, 1.0, 100.0, math.sqrt))  # 3\nwrite_dataset(summary, \"log\", generate_data_fn(\n    1, 1.0, 100.0, math.log))  # 4\nwrite_dataset(summary, \"pow\", generate_data_fn(\n    1, 1.0, 10.0, lambda x: x ** 2))  # 5\nwrite_dataset(summary, \"ratio\", generate_data_ratio)  # 6\nwrite_dataset(summary, \"diff\", generate_data_diff)  # 7\nwrite_dataset(summary, \"r_poly\", generate_data_fn(\n    1, 1.0, 10.0, lambda x: 1 \/ (5 * x + 8 * x ** 2)))  # 8\nwrite_dataset(summary, \"poly\", generate_data_fn(\n    1, 0.0, 2.0, lambda x: 1 + 5 * x + 8 * x ** 2))  # 9\nwrite_dataset(summary, \"r_diff\", generate_data_fn(\n    4, 1.0, 10.0, lambda a, b, c, d: ((a - b) \/ (c - d))))  # 10\n\n# Others added to the original the paper.\nwrite_dataset(summary, \"sum\", generate_data_fn(10, 0.0, 10.0, lambda *args: np.sum(args)))\nwrite_dataset(summary, \"max\", generate_data_fn(10, 0.0, 100.0, lambda *args: np.max(args)))\nwrite_dataset(summary, \"dev\", generate_data_fn(10, 0.0, 100.0, lambda *args: np.std(args)))\nwrite_dataset(summary, \"bmi\", generate_data_bmi)\n\nwrite_dataset(summary, \"dist\", generate_data_fn(\n    4, 1.0, 10.0, lambda a, b, c, d: np.sqrt((a - b)**2 + (c - d)**2)  ))\nwrite_dataset(summary, \"rel\", generate_data_fn(\n    3, 1.0, 10.0, lambda a, b, c: ((a*b)\/c**2) ))\n\n# Write summary\ndf_summary = pd.DataFrame(summary)\ndf_summary.columns = ['name', 'min', 'max', 'mean', 'std']\ndf_summary.to_csv(os.path.join(PATH,\"summary.csv\"),index=False)","5a85b651":"df_summary","05ec0025":"## Summary","963d4026":"## An Empirical Analysis of Feature Engineering for Predictive Modeling\nWe used this Python script to generate the data for the following conference paper. The code has been updated and converted to work with Kaggle.\n\nHeaton, J. (2016, April). [An Empirical Analysis of Feature Engineering for Predictive Modeling](https:\/\/arxiv.org\/abs\/1701.07852). In *SoutheastCon 2016* (pp. 1-6). IEEE.\n\n## Paper Abstract\n\nMachine learning models, such as neural networks, decision trees, random forests, and gradient boosting machines, accept a feature vector, and provide a prediction.  These models learn in a supervised fashion where we provide feature vectors with the expected output.  It is common practice to engineer new features from the provided feature set.  Such engineered features will either augment or replace portions of the existing feature vector.  These engineered features are essentially calculated fields based on the values of the other features.  \n\nEngineering such features is primarily a manual, time-consuming task.  Additionally, each type of model will respond differently to different kinds of engineered features.  This paper reports empirical research to demonstrate what kinds of engineered features are best suited to various machine learning model types.  We provide this recommendation by generating several datasets that we designed to benefit from a particular type of engineered feature.  The experiment demonstrates to what degree the machine learning model can synthesize the needed feature on its own.  If a model can synthesize a planned feature, it is not necessary to provide that feature.  The research demonstrated that the studied models do indeed perform differently with various types of engineered features. "}}