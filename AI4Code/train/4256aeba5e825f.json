{"cell_type":{"dfef3fe7":"code","226da3ca":"code","2c7af81a":"code","0811ab4b":"code","97b30ffd":"code","ac379b30":"code","ed6193db":"code","a7f78e78":"code","4f168189":"code","f775b61b":"code","9fca5904":"code","a6ed6c22":"code","3ced3364":"code","ba729bb5":"code","c126a560":"code","d2cb3739":"code","7928aaae":"code","7fb8b910":"code","78f0e7f2":"code","0787e2e8":"code","834e625c":"code","5646bc2d":"code","3fba0d9c":"code","8628ae5f":"code","730c1ca1":"code","bebf4eb3":"code","60f8708c":"code","77cb2b3e":"code","6d4f8613":"code","5b1e1a75":"code","4a4f9b5b":"code","bace3795":"code","5d092810":"code","4ae550e1":"code","14bad358":"markdown"},"source":{"dfef3fe7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","226da3ca":"import keras\nprint(keras.__version__)\n\nimport sklearn as sk\nprint(sk.__version__)\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nprint(matplotlib.__version__)\n%matplotlib inline\n\nimport seaborn as sns\nprint(sns.__version__)\n\nimport warnings\n\nwarnings.simplefilter('ignore')","2c7af81a":"ks_2018 = pd.read_csv(\"\/kaggle\/input\/kickstarter-projects\/ks-projects-201801.csv\", header = 0)\nks_2018.head(10)","0811ab4b":"ks_2018.describe()","97b30ffd":"#\u3044\u3089\u306a\u3044\u884c\u3092\u6d88\u3059\nindices = [i == \"failed\" or i == \"successful\" for i in ks_2018.state]\nks_2018 = ks_2018[indices].copy()\n#\u3044\u3089\u306a\u3044\u5217\u3092\u6d88\u3059\nks_2018_modified = ks_2018[[\"category\", \"state\", \"usd_goal_real\", \"country\", \"usd_pledged_real\", \"deadline\", \"currency\"]]\nks_2018_modified[\"launched\"] = pd.to_datetime(ks_2018['launched']).dt.date\nks_2018_modified['period'] = pd.to_datetime(ks_2018['deadline']).dt.date - ks_2018_modified[\"launched\"]\nks_2018_modified['period'] = ks_2018_modified['period'] \/ np.timedelta64(1,'D')\nks_2018_modified[\"percentage\"] = (ks_2018[\"usd_pledged_real\"] \/ ks_2018[\"usd_goal_real\"]) * 100\nks_2018_modified[\"launched_d\"] = [(pd.to_datetime(i) - pd.to_datetime(\"2009-01-01\")) \/ np.timedelta64(1, 'D') for i in ks_2018_modified[\"launched\"]]\nks_2018_modified[\"deadline_d\"] = [(pd.to_datetime(i) - pd.to_datetime(\"2009-01-01\")) \/ np.timedelta64(1, 'D') for i in ks_2018_modified[\"deadline\"]]\n#country\u3068currency\u3092\u5408\u4f53\nks_2018_modified[\"currency_country\"] = list(zip(ks_2018_modified.currency, ks_2018_modified.country))\nks_2018_modified.describe()","ac379b30":"ks_2018_modified.head()","ed6193db":"ks_2018_modified.describe()","a7f78e78":"print(ks_2018_modified.isnull().any())\nprint(ks_2018_modified.isnull().sum())","4f168189":"states = ks_2018[\"state\"].unique()\ncategories = ks_2018_modified[\"category\"].unique()\nnum_categories = len(categories)\nprint(states)\nprint(categories)\nprint(num_categories, \"categoies\")","f775b61b":"#\u76ee\u7684\u5909\u6570\u3068\u8aac\u660e\u5909\u6570\u306e\u95a2\u4fc2\u3092\u78ba\u8a8d\u3059\u308b\u305f\u3081\u306e\u30b0\u30e9\u30d5\u3092\u4f5c\u6210\u3059\u308b\npd.plotting.scatter_matrix(ks_2018_modified, figsize=(10, 10))\nplt.show()","9fca5904":"#\u76ee\u7684\u5909\u6570\u3092\u8aac\u660e\u3059\u308b\u306e\u306b\u6709\u52b9\u305d\u3046\u306a\u8aac\u660e\u5909\u6570\u3092\u898b\u3064\u3051\u308b\nks_2018_modified.corr()","a6ed6c22":"sns.catplot(x = \"country\", y = \"percentage\", data = ks_2018_modified,  height = 10)\nplt.show()","3ced3364":"plt.figure(figsize = (15, 5))\nv = sns.violinplot(x = \"country\", y = \"percentage\", data = ks_2018_modified,  width = 1.5, bw = \"silverman\")\nv.set(ylim = (0, 400))\nplt.show()\n\n#\u56fd\u3054\u3068\u306b\u50be\u5411\u304c\u9055\u3046\u3001\u305f\u3068\u3048\u3070\u65e5\u672c\u306f\u5931\u6557\u304c\u591a\u3044","ba729bb5":"sns.distplot([i for i in ks_2018_modified[\"percentage\"] if i >= 100], hist=False, color=\"g\", kde_kws={\"shade\": True})\n#\u6210\u529f\u3057\u3066\u3044\u308b\u3082\u306e\u306e\u9054\u6210\u7387\u306e\u5206\u5e03","c126a560":"# from pandas.plotting import register_matplotlib_converters\n# register_matplotlib_converters()\n# plt.figure(figsize = (15, 10))\n# s = sns.distplot(ks_2018_modified[\"launched_d\"], y = \"percentage\", data = ks_2018_modified, hue = \"currency\")\n# plt.show()\n# #\u958b\u59cb\u6642\u671f\u306b\u3088\u3063\u3066Kickstarter\u304c\u30d0\u30ba\u3063\u305f\u308a\u3059\u308b\u3053\u3068\u3067\u6210\u529f\u7387\u304c\u4e0a\u304c\u3063\u3066\u3044\u308b\u3068\u3044\u3046\u3088\u3046\u306a\u50be\u5411\u304c\u306a\u3044\u304b\u3055\u3050\u3063\u3066\u307f\u305f\u304b\u3063\u305f\u3001\u3042\u3068\u901a\u8ca8\u306b\u3088\u308b\u5f71\u97ff\u304c\u3042\u308b\u304b\n# #\u958b\u59cb\u6642\u671f\u304c\u304a\u304b\u3057\u3044\u3084\u3064\u304c\u3042\u3063\u305f\u306e\u3067\u3001\u6642\u671f\u3092\u6307\u5b9a\u3057\u305f","d2cb3739":"# ax = sns.jointplot((pd.to_datetime(ks_2018_modified[\"launched\"] - pd.to_datetime(\"2009-01-01\")).dt.date, ks_2018_modified[\"percentage\"], xlim = (0, 3500), ylim = (0, 15000), color = \"g\")\n\n# #\u958b\u59cb\u6642\u671f\uff082009-01-01\u304b\u3089\u306e\u65e5\u6570\uff09\u3068\u9054\u6210\u7387","7928aaae":"# ax = sns.kdeplot(ks_2018_modified[\"usd_goal_real\"], ks_2018_modified[\"percentage\"], n_levels = 10,\n#                  xlim = (0, 500000), ylim = (0, 25000), cmap=\"Blues\", shade=True, shade_lowest=False)\n# #\u76ee\u6a19\u91d1\u984d\u3068\u9054\u6210\u7387\u3001kde\u91cd\u3059\u304e\u3066\u52d5\u304b\u306a\u3044(;_;)\n\n# import itertools\n# li_combi = list(itertools.combinations(df_wine.columns[1:], 2))\n# for X,Y in li_combi:\n#     print(\"X=%s\"%X,\"Y=%s\"%Y)\n#     df_wine.plot(kind=\"scatter\",x=X,y=Y,alpha=0.7,s=10,c=\"Class label\",colormap=\"winter\")#\u6563\u5e03\u56f3\u306e\u4f5c\u6210\n#     plt.xlabel(X)\n#     plt.ylabel(Y)\n#     plt.tight_layout()\n#     plt.show()#\u30b0\u30e9\u30d5\u3092\u3053\u3053\u3067\u63cf\u753b\u3055\u305b\u308b\u305f\u3081\u306e\u884c","7fb8b910":"# # category\u3054\u3068\u306estate\u306e\u51fa\u73fe\u983b\u5ea6\u3092\u78ba\u8a8d\n# # \u30c7\u30fc\u30bf\u5185\u306ecategory\u3092\u62bd\u51fa\u3057category\u306b\u683c\u7d0d\n# category=df_cloudfound_sct.groupby('category')\n# # state\u3092\u76f8\u5bfe\u7684\u306a\u983b\u5ea6\u306b\u5909\u63db\n# category=category['state'].value_counts(normalize=True).unstack() \n# # successful\u306e\u964d\u9806\u30bd\u30fc\u30c8\n# category=category.sort_values(by=['successful'],ascending=False)\n# # \u7e26\u68d2\u30b0\u30e9\u30d5\uff08\u7a4d\u307f\u4e0a\u3052\uff09\u3067\u30b0\u30e9\u30d5\u4f5c\u6210\n# category[['successful','failed','canceled','live','suspended','undefined']].plot(kind='bar',stacked=True,figsize=(20,20))","78f0e7f2":"# plt.figure(figsize = (15, 10))\n# p = sns.scatterplot(x = \"period\", y = \"percentage\", data = ks_2018_modified, hue = \"category\")\n# p.set(ylim = (0, 1000))\n# p.set(xlim = (0, 100))\n# plt.show()\n# #\u30ab\u30c6\u30b4\u30ea\u30fc\u3054\u3068\u306e\u671f\u9593\u3068\u9054\u6210\u7387\n# #\u4e0b\u306b\u30aa\u30ec\u30f3\u30b8\u304c\u591a\u304f\u3066\u3001\u4e0a\u306b\u7dd1\u304c\u591a\u3044\uff1f","0787e2e8":"\"\"\"\n\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u5229\u7528\u3059\u308b\n    \u56de\u5e30\u306e\u5834\u5408\u306f\u7dda\u5f62\u56de\u5e30\u3001\u5206\u985e\u306e\u5834\u5408\u306f\u30ed\u30b8\u30b9\u30c6\u30a3\u30c3\u30af\u56de\u5e30\n    \u8cea\u7684\u5909\u6570\u304c\u6271\u3048\u306a\u3044\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u4f7f\u3046\u5834\u5408\u306f\u3001\u30c0\u30df\u30fc\u5909\u6570\u306b\u7f6e\u304d\u63db\u3048\u308b\n\"\"\"\n!pip install pydotplus\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet, LassoCV\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix, accuracy_score, f1_score, r2_score\nfrom sklearn.model_selection import train_test_split, KFold, GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\nimport pydotplus\nfrom IPython.display import Image\nfrom sklearn.externals.six import StringIO\nfrom sklearn.feature_selection import SelectFromModel\nfrom keras.models import Sequential, Model, load_model\nfrom keras.layers import Dropout, Dense\nfrom keras.optimizers import SGD, RMSprop, Adam\nfrom keras.callbacks import History\n\n\nX = pd.get_dummies(ks_2018_modified[[\"category\", \"launched_d\", \"usd_goal_real\", \"currency_country\", \"period\"]], columns = [\"category\", \"currency_country\"])\n\nX.head()","834e625c":"X.describe()","5646bc2d":"#\u76ee\u6a19\u9054\u6210\u7387\uff08\u56de\u5e30\uff09\nY1 = ks_2018_modified[\"percentage\"]\nY1 = pd.DataFrame(Y1, columns = [\"percentage\"])\nX1_train, X1_test, Y1_train, Y1_test = train_test_split(X, Y1, test_size = 0.3, random_state = 0)\n\n\n#\u6210\u529f\u3059\u308b\u304b\u3069\u3046\u304b\uff08\u5206\u985e\uff09\nY2 = [1 if i == \"successful\" else 0 for i in ks_2018[\"state\"]]\n\nX2_train, X2_test, Y2_train, Y2_test = train_test_split(X, Y2, test_size = 0.3, random_state = 0)\n\nY1_train.head(10)","3fba0d9c":"from sklearn.preprocessing import StandardScaler\n\n#\u8a13\u7df4\u30c7\u30fc\u30bf\u306e\u52a0\u5de5\n\n#\u76ee\u6a19\u9054\u6210\u7387\uff08\u56de\u5e30\uff09\n#period\u306e\u6a19\u6e96\u5316\nstdsc_period_1 = StandardScaler()\nX1_train[\"period\"] = stdsc_period_1.fit_transform(X1_train[[\"period\"]] .values)\n#goal\u306e\u6a19\u6e96\u5316\nstdsc_goal_1 = StandardScaler()\nX1_train[\"usd_goal_real\"] = stdsc_goal_1.fit_transform(X1_train[[\"usd_goal_real\"]] .values)\n#launched_d\u306e\u6a19\u6e96\u5316\nstdsc_launched_1 = StandardScaler()\nX1_train[\"launched_d\"] = stdsc_launched_1.fit_transform(X1_train[[\"launched_d\"]] .values)\n#launched\u3068period\u306e\u767d\u8272\u5316\ncov = np.cov(X1_train[[\"launched_d\", \"period\"]], rowvar=0) # \u5206\u6563\u30fb\u5171\u5206\u6563\u3092\u6c42\u3081\u308b\n_, S1 = np.linalg.eig(cov)           # \u5206\u6563\u5171\u5206\u6563\u884c\u5217\u306e\u56fa\u6709\u30d9\u30af\u30c8\u30eb\u3092\u7528\u3044\u3066\nlaunched_period = np.dot(S1.T, X1_train[[\"launched_d\", \"period\"]].T).T #\u30c7\u30fc\u30bf\u3092\u7121\u76f8\u95a2\u5316\nstdsc_ld_1 = StandardScaler()\nlaunched_period  = stdsc_ld_1.fit_transform(launched_period) # \u7121\u76f8\u95a2\u5316\u3057\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u3001\u3055\u3089\u306b\u6a19\u6e96\u5316\n\n#\u6210\u529f\u3059\u308b\u304b\u3069\u3046\u304b\uff08\u5206\u985e\uff09\n#period\u306e\u6a19\u6e96\u5316\nstdsc_period_2 = StandardScaler()\nX2_train[\"period\"] = stdsc_period_2.fit_transform(X2_train[[\"period\"]] .values)\n#goal\u306e\u6a19\u6e96\u5316\nstdsc_goal_2 = StandardScaler()\nX2_train[\"usd_goal_real\"] = stdsc_goal_2.fit_transform(X2_train[[\"usd_goal_real\"]] .values)\n#launched_d\u306e\u6a19\u6e96\u5316\nstdsc_launched_2 = StandardScaler()\nX2_train[\"launched_d\"] = stdsc_launched_2.fit_transform(X2_train[[\"launched_d\"]] .values)\n#launched\u3068period\u306e\u767d\u8272\u5316\ncov = np.cov(X2_train[[\"launched_d\", \"period\"]], rowvar=0) # \u5206\u6563\u30fb\u5171\u5206\u6563\u3092\u6c42\u3081\u308b\n_, S2 = np.linalg.eig(cov)           # \u5206\u6563\u5171\u5206\u6563\u884c\u5217\u306e\u56fa\u6709\u30d9\u30af\u30c8\u30eb\u3092\u7528\u3044\u3066\nlaunched_period = np.dot(S2.T, X2_train[[\"launched_d\", \"period\"]].T).T #\u30c7\u30fc\u30bf\u3092\u7121\u76f8\u95a2\u5316\nstdsc_ld_2 = StandardScaler()\nlaunched_period  = stdsc_ld_2.fit_transform(launched_period) # \u7121\u76f8\u95a2\u5316\u3057\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u3001\u3055\u3089\u306b\u6a19\u6e96\u5316","8628ae5f":"Y1_train.describe()","730c1ca1":"plt.hist(Y1_train[\"percentage\"], color = \"pink\")","bebf4eb3":"#\u30c7\u30fc\u30bf\u306b\u76f8\u95a2\u95a2\u4fc2\u304c\u306a\u3044\u3053\u3068\u3092\u78ba\u8a8d\nX1_train.corr().style.background_gradient().format('{:.2f}')","60f8708c":"#\u7279\u5fb4\u9078\u629e\nestimator = LassoCV(normalize = True, cv = 20)\nsfm = SelectFromModel(estimator, threshold = 1e-5)\n\nsfm.fit(X1_train.values, Y1_train.values)\n# print(sfm.get_support())\n# print(~sfm.get_support())\nnew_index = sfm.get_support()\nprint(X1_train.columns[new_index])\nnew_X1_train = X1_train[X1_train.columns[new_index]]\nnew_X1_test  = X1_test[X1_train.columns[new_index]]","77cb2b3e":"#\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u52a0\u5de5\n\n#\u76ee\u6a19\u9054\u6210\u7387\uff08\u56de\u5e30\uff09\n#period\u306e\u6a19\u6e96\u5316\nX1_test[\"period\"] = stdsc_period_1.transform(X1_test[[\"period\"]].values)\n#goal\u306e\u6a19\u6e96\u5316\nX1_test[\"usd_goal_real\"] = stdsc_goal_1.transform(X1_test[[\"usd_goal_real\"]].values)\n#launched_d\u306e\u6a19\u6e96\u5316\nX1_test[\"launched_d\"] = stdsc_launched_1.transform(X1_test[[\"launched_d\"]].values)\n#launched\u3068deadline\u306e\u767d\u8272\u5316\nlaunched_period = np.dot(S1.T, X1_test[[\"launched_d\", \"period\"]].T).T #\u30c7\u30fc\u30bf\u3092\u7121\u76f8\u95a2\u5316\nlaunched_period  = stdsc_ld_1.transform(launched_period) # \u7121\u76f8\u95a2\u5316\u3057\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u3001\u3055\u3089\u306b\u6a19\u6e96\u5316\n\n#\u6210\u529f\u3059\u308b\u304b\u3069\u3046\u304b\uff08\u5206\u985e\uff09\n#period\u306e\u6a19\u6e96\u5316\nX2_test[\"period\"] = stdsc_period_2.transform(X2_test[[\"period\"]].values)\n#goal\u306e\u6a19\u6e96\u5316\nX2_test[\"usd_goal_real\"] = stdsc_goal_2.transform(X2_test[[\"usd_goal_real\"]].values)\n#launched_d\u306e\u6a19\u6e96\u5316\nX2_test[\"launched_d\"] = stdsc_launched_2.transform(X2_test[[\"launched_d\"]].values)\n#launched\u3068deadline\u306e\u767d\u8272\u5316\nlaunched_period = np.dot(S2.T, X2_test[[\"launched_d\", \"period\"]].T).T #\u30c7\u30fc\u30bf\u3092\u7121\u76f8\u95a2\u5316\nlaunched_period  = stdsc_ld_2.transform(launched_period) # \u7121\u76f8\u95a2\u5316\u3057\u305f\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066\u3001\u3055\u3089\u306b\u6a19\u6e96\u5316","6d4f8613":"Y1_test.describe()","5b1e1a75":"plt.hist(Y1_test[\"percentage\"], color = \"skyblue\")","4a4f9b5b":"#\u76ee\u6a19\u9054\u6210\u7387\uff08\u56de\u5e30\uff09\n!pip install optuna\nimport optuna \n\n#NN\n#optuna\u306b\u3088\u308b\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u30aa\u30d7\u30c6\u30a3\u30de\u30a4\u30bc\u30fc\u30b7\u30e7\u30f3\ndef create_model(num_layer, num_shape, use_dropout, activation):\n    model = Sequential()\n    model.add(Dense(num_shape, input_dim = len(X1_train.columns), activation = activation))\n    for layer in range (2, num_layer):\n        model.add(Dense(num_shape, input_dim = num_shape, activation = activation))\n        if use_dropout == \"true\":\n            model.add(Dropout(0.2))\n    model.add(Dense(1, activation = activation))\n#     model.summary()\n#     plot_model(model)\n#     SVG(model_to_dot(model).create(prog='dot', format='svg'))\n    return model\n\ndef train(model, optimizer, learning_rate, num_shape, num_layer, use_dropout, activation, trial):\n    kf = KFold(n_splits = 5, shuffle = True, random_state = 0)\n    for train, valid in kf.split(X1_train, Y1_train):\n        if optimizer == \"sgd\":\n            model.compile(loss = 'mean_absolute_percentage_error', optimizer = SGD())\n        elif optimizer == \"rmsprop\":\n            model.compile(loss = 'mean_absolute_percentage_error', optimizer = RMSprop())\n        elif optimizer == \"adam\":\n            model.compile(loss = 'mean_absolute_percentage_error', optimizer = Adam())\n        history = History()\n        model.fit(X1_train.values[train], Y1_train.values[train], callbacks = [history], verbose=0)\n        scores = model.evaluate(X1_train.values[valid], Y1_train.values[valid], verbose=0)   \n        model.save(\"model_{}.h5\".format(trial.number))\n        del model\n        return history\n\ndef objective(trial):\n    optimizer = trial.suggest_categorical(\"optimizer\", [\"sgd\", \"rmsprop\", \"adam\"])\n    activation = trial.suggest_categorical(\"activation\", [\"relu\", \"tanh\", \"softplus\"])\n    use_dropout = trial.suggest_categorical(\"use_dropout\", [\"true\", \"false\"])\n    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-7, 1e0)\n    num_layer = trial.suggest_int(\"num_layer\", 1, 10)\n    num_shape = trial.suggest_int(\"num_shape\", 5, 20)\n    model = create_model(num_layer, num_shape, use_dropout, activation)\n    hist = train(model, optimizer, learning_rate, num_shape, num_layer, use_dropout, activation, trial)\n    \n    return np.min(hist.history[\"loss\"])\n\nstudy = optuna.create_study()\nstudy.optimize(objective, n_trials = 10)\nhist_df = study.trials_dataframe()\nhist_df.to_csv(\"optuna_results.csv\")\nprint(\"Best Parameters: \", study.best_params)\nprint(\"Best Value: \", study.best_value)\nprint(\"Best Trial\", study.best_trial)\n\n#\u6210\u529f\u3059\u308b\u304b\u3069\u3046\u304b\uff08\u5206\u985e\uff09\n#Decision Tree\nclf = DecisionTreeClassifier(criterion = \"gini\", max_depth = None, min_samples_leaf = 3, random_state = 0)\nclf = clf.fit(X2_train, Y2_train)\nprint(\"training score(Decision Tree)= \", clf.score(X2_train, Y2_train))\n# \u6c7a\u5b9a\u6728\u306e\u63cf\u753b\ndot_data = StringIO() #dot\u30d5\u30a1\u30a4\u30eb\u60c5\u5831\u306e\u683c\u7d0d\u5148\nexport_graphviz(clf, out_file = dot_data,  \n                     feature_names = X2_train.columns,  \n                     class_names = [\"successful\", \"failed\"],  \n                     filled = True, rounded = True,  \n                     special_characters = True) \ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue()) \n# Image(graph.create_png())\n\n#Random Forest\nn_estimators = 100\nrf_clf = RandomForestClassifier(n_estimators = n_estimators, random_state = 0)\nrf_clf.fit(X2_train, Y2_train)\nprint(\"training score(Random Forest)= \", rf_clf.score(X2_train, Y2_train))\n# print(rf_clf.feature_importances_)\npd.DataFrame(rf_clf.feature_importances_, index = X2_train.columns).plot.bar(figsize = (25, 10))\nplt.ylabel(\"Importance\")\nplt.xlabel(\"Features\")\nplt.show()\n# for i, est in enumerate(rf_clf.estimators_):\n#     print(i)\n#     # \u6c7a\u5b9a\u6728\u306e\u63cf\u753b\n#     dot_data = StringIO() #dot\u30d5\u30a1\u30a4\u30eb\u60c5\u5831\u306e\u683c\u7d0d\u5148\n#     export_graphviz(est, out_file=dot_data,  \n#                          feature_names = X2_train.columns,  \n#                          class_names = [\"successful\", \"failed\"],  \n#                          filled=True, rounded=True,  \n#                          special_characters=True) \n#     graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) \n#     display(Image(graph.create_png()))\n    \n#AdaBoost\nab_clf = AdaBoostClassifier(random_state = 0, n_estimators = n_estimators)\nab_clf.fit(X2_train, Y2_train)\nprint(\"training score(Adaboost)= \", ab_clf.score(X2_train, Y2_train))\n# print(ab_clf.feature_importances_)\npd.DataFrame(ab_clf.feature_importances_, index = X2_train.columns).plot.bar(figsize = (25, 10))\nplt.ylabel(\"Importance\")\nplt.xlabel(\"Features\")\nplt.show()\n# for i, est in enumerate(ab_clf.estimators_):\n#     print(i)\n#     # \u6c7a\u5b9a\u6728\u306e\u63cf\u753b\n#     dot_data = StringIO() #dot\u30d5\u30a1\u30a4\u30eb\u60c5\u5831\u306e\u683c\u7d0d\u5148\n#     export_graphviz(est, out_file=dot_data,  \n#                          feature_names = X2_train.columns,  \n#                          class_names = [\"successful\", \"failed\"],    \n#                          filled=True, rounded=True,  \n#                          special_characters=True) \n#     graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) \n#     display(Image(graph.create_png()))","bace3795":"\"\"\"\n\u4e88\u6e2c\u7cbe\u5ea6\u307e\u305f\u306f\u8b58\u5225\u7cbe\u5ea6\u3092\u78ba\u8a8d\u3059\u308b\n    \u56de\u5e30\u554f\u984c\u306e\u5834\u5408\u306f\u3001MSE\u3001RMSE\u3001MAE\u3092\u6c42\u3081\u308b\n    \u5206\u985e\u554f\u984c\u306e\u5834\u5408\u306f\u3001\u6df7\u540c\u884c\u5217\u3092\u4f5c\u6210\u3057\u3001Accuracy\u3001Recall\u3001Precision\u3092\u6c42\u3081\u308b\n\"\"\"\n#\u76ee\u6a19\u9054\u6210\u7387\uff08\u56de\u5e30\uff09\n# Y1_estimated = lr1.predict(X1_test)\n\n\nbest_model = load_model(\"model_{}.h5\".format(study.best_trial.number))\nY1_pred = best_model.predict(X1_test)\nprint(\"R^2(test): \" , r2_score(Y1_test, Y1_pred))\nmape = np.mean(np.abs((Y1_test - Y1_pred) \/ Y1_test)) * 100\nprint(\"Mean Absolute Percentage Error(test): \", mape, \"%\")\nmse = mean_squared_error(Y1_test, Y1_pred)\nrmse = np.sqrt(mse)\nmae = mean_absolute_error(Y1_test, Y1_pred)\nprint(\"MSE: {}, RMSE: {}, MAE: {}\".format(mse, rmse, mae))\nprint(Y1_pred[:20], \"\\n\", Y1_test[:20])","5d092810":"#\u6210\u529f\u3059\u308b\u304b\u3069\u3046\u304b\uff08\u5206\u985e\uff09-- Decicion Tree, Random Forest, Adaboost\nprint(\"Evaluation on Test Dataset:\")\naccuracy6 = accuracy_score(clf.predict(X2_test), Y2_test)\nprint(\"Accuracy(Decision Tree): \",             accuracy6)\naccuracy7 = accuracy_score(rf_clf.predict(X2_test), Y2_test)\nprint(\"Accuracy(RandomForest): \",        accuracy7)\naccuracy8 = accuracy_score(ab_clf.predict(X2_test), Y2_test)\nprint(\"Accuracy(AdaBoost): \",            accuracy8)","4ae550e1":"Y2_estimated = ab_clf.predict(X2_test)\nc_matrix = pd.DataFrame(confusion_matrix(Y2_test, Y2_estimated), \n                        index=['\u6b63\u89e3 = \u6210\u529f', '\u6b63\u89e3 = \u5931\u6557'], \n                        columns=['\u4e88\u6e2c = \u6210\u529f', '\u4e88\u6e2c = \u5931\u6557'])\n#Recall\uff08\u5b9f\u969b\u306b\u6b63\u3057\u3044\u3082\u306e\u306e\u3046\u3061\u3001\u6b63\u3067\u3042\u308b\u3068\u4e88\u6e2c\u3055\u308c\u305f\u5272\u5408\uff09\nrecall = c_matrix[\"\u4e88\u6e2c = \u6210\u529f\"][0] \/ (c_matrix[\"\u4e88\u6e2c = \u6210\u529f\"][0] + c_matrix[\"\u4e88\u6e2c = \u5931\u6557\"][0])\n#Precision\uff08\u6b63\u3068\u4e88\u6e2c\u3057\u305f\u3082\u306e\u306e\u3046\u3061\u3001\u3069\u308c\u304f\u3089\u3044\u6b63\u3057\u304b\u3063\u305f\u304b\uff09\nprecision = c_matrix[\"\u4e88\u6e2c = \u6210\u529f\"][0] \/ (c_matrix[\"\u4e88\u6e2c = \u6210\u529f\"][0] + c_matrix[\"\u4e88\u6e2c = \u6210\u529f\"][1])\n#F1\nf1 = f1_score(Y2_test, Y2_estimated)\nprint(\"AdaBoost\\n Recall: {}, Precioin: {}, F1: {}\".format(recall, precision, f1))\nc_matrix","14bad358":"**\u524d\u56de\u306e\u7d50\u679c\uff1a**\n\n\u56de\u5e30 \nMSE: 294.7480641877117, RMSE: 17.16822833572852, MAE: 16.232300744366476   \n \n \n \n\u5206\u985e\n* Accuracy(Logistic Regression):  0.5961167390255668 \n* Accuracy(L1):  0.5961167390255668 \n* Accuracy(L2):  0.5961167390255668 \n* Accuracy(ElasticNet):  0.5961167390255668 \n* Accuracy(Bagging):  0.5961167390255668 \n* Accuracy(RandomForest):  0.6784852870236372 \n* Accuracy(AdaBoost):  0.6772793053545586 \n \nAdaBoost \nRecall: 0.7767550070807202, Precioin: 0.7094419807834442, F1: 0.5703965323486916 "}}