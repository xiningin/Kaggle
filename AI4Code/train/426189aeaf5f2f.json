{"cell_type":{"b805f1c1":"code","58bc63e4":"code","6a748836":"code","82a6b1c1":"code","b7e90bb7":"code","a91c0186":"code","72d2dab7":"code","4ee584f3":"code","5f12a163":"code","5533fc58":"code","fdc3c82d":"code","d73a973f":"code","61687942":"code","3f43d2c8":"code","9c39ada9":"code","4b75eaae":"code","e7261df8":"code","b2578bd8":"code","42b57947":"code","57802a28":"code","b236ccef":"code","04a05ad0":"code","5397e314":"code","8904e99e":"code","a5588e36":"code","9e2f2433":"code","57d00606":"code","80085a36":"code","41d0934f":"markdown","d766a96c":"markdown","5272e21d":"markdown","31eba029":"markdown","0506da1c":"markdown","765d1769":"markdown","9a7503e4":"markdown","65c77ed5":"markdown","90545835":"markdown","6fa1942d":"markdown","d818d805":"markdown","63dc5b97":"markdown","ef46d7d5":"markdown","cdbd8d11":"markdown","efe78ce4":"markdown","6049baf6":"markdown","66aa69c0":"markdown","f30603f8":"markdown","f01ab6d5":"markdown","8507e2c6":"markdown","2611bfb1":"markdown","72908a28":"markdown","4921b965":"markdown","096440a5":"markdown","7f3ecc21":"markdown","bf735edf":"markdown","e72c37f4":"markdown","ce98c33c":"markdown","2cc5b357":"markdown","313616c6":"markdown","eb0b0e53":"markdown","016bdd84":"markdown"},"source":{"b805f1c1":"import datetime as dt\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom mpl_toolkits.basemap import Basemap\nfrom sklearn.model_selection import TimeSeriesSplit\nplt.style.use('ggplot')\n%config InlineBackend.figure_format = 'retina'\nimport warnings\nwarnings.filterwarnings('ignore')","58bc63e4":"accidents = pd.read_csv('..\/input\/dft-accident-data\/Accidents0515.csv',index_col='Accident_Index')\ncasualties=pd.read_csv('..\/input\/dft-accident-data\/Casualties0515.csv' , error_bad_lines=False,index_col='Accident_Index',warn_bad_lines=False)\nvehicles=pd.read_csv('..\/input\/dft-accident-data\/Vehicles0515.csv', error_bad_lines=False,index_col='Accident_Index',warn_bad_lines=False)\n#general_info = pd.read_csv('ukTrafficAADF.csv')","6a748836":"accidents.head()","82a6b1c1":"accidents = accidents.join(vehicles, how='outer')","b7e90bb7":"accidents.drop(['Location_Easting_OSGR', 'Location_Northing_OSGR','LSOA_of_Accident_Location',\n                'Junction_Control' ,'2nd_Road_Class'], axis=1, inplace=True)\naccidents['Date_time'] =  accidents['Date'] +' '+ accidents['Time']\n\nfor col in accidents.columns:\n    accidents = (accidents[accidents[col]!=-1])\n    #print(col ,' ' , x)\nfor col in casualties.columns:\n    casualties = (casualties[casualties[col]!=-1])\n\n    accidents['Date_time'] = pd.to_datetime(accidents.Date_time)\naccidents.drop(['Date','Time'],axis =1 , inplace=True)\naccidents.dropna(inplace=True)","a91c0186":"plt.figure(figsize=(12,6))\naccidents.Date_time.dt.dayofweek.hist(bins=7,rwidth=0.55,alpha=0.5, color= 'orange')\nplt.title('Accidents on the day of a week' , fontsize= 30)\nplt.grid(False)\nplt.ylabel('Accident count' , fontsize = 20)\nplt.xlabel('0 - Sunday ,  1 - Monday  ,2 - Tuesday , 3 - Wednesday , 4 - Thursday , 5 - Friday , 6 - Saturday' , fontsize = 13)","72d2dab7":"plt.figure(figsize=(12,6))\naccidents.Date_time.dt.hour.hist(rwidth=0.75,alpha =0.50, color= 'orange')\nplt.title('Time of the day\/night',fontsize= 30)\nplt.grid(False)\nplt.xlabel('Time 0-23 hours' , fontsize = 20)\nplt.ylabel('Accident count' , fontsize = 15)\n","4ee584f3":"objects = ['0','0-5','6-10','11-15','16-20','21-25','26-35',\n          '36-45', '46-55','56-65','66-75','75+']\n\nplt.figure(figsize=(12,6))\ncasualties.Age_Band_of_Casualty.hist(bins = 11,alpha=0.5,rwidth=0.90, color= 'red',)\nplt.title('Age of people involved in the accidents', fontsize = 25)\nplt.grid(False)\ny_pos = np.arange(len(objects))\nplt.xticks(y_pos , objects)\nplt.ylabel('Accident count' , fontsize = 15)\nplt.xlabel('Age of Drivers', fontsize = 15,)","5f12a163":"speed_zone_accidents = accidents.loc[accidents['Speed_limit'].isin(['20' ,'30' ,'40' ,'50' ,'60' ,'70'])]\nspeed  = speed_zone_accidents.Speed_limit.value_counts()\n\nexplode = (0.0, 0.0, 0.0 , 0.0 ,0.0,0.0) \nplt.figure(figsize=(10,8))\nplt.pie(speed.values,  labels=None, \n        autopct='%.1f',pctdistance=0.8, labeldistance=1.9 ,explode = explode, shadow=False, startangle=160,textprops={'fontsize': 15})\n \nplt.axis('equal')\nplt.legend(speed.index, bbox_to_anchor=(1,0.7), loc=\"center right\", fontsize=15, \n           bbox_transform=plt.gcf().transFigure)\nplt.figtext(.5,.9,'Accidents percentage in Speed Zone', fontsize=25, ha='center')\nplt.show()","5533fc58":"corr =  accidents.corr()\nplt.subplots(figsize=(20,9))\nsns.heatmap(corr)","fdc3c82d":"accidents_2014 = accidents[accidents.Date_time.dt.year ==2014]\naccidents_2014_01 = accidents_2014[accidents_2014.Accident_Severity == 1]\naccidents_2014_02 = accidents_2014[accidents_2014.Accident_Severity == 2]\naccidents_2014_03 = accidents_2014[accidents_2014.Accident_Severity == 3]","d73a973f":"#import gmaps\n#from ipywidgets.embed import embed_minimal_html\n#gmaps.configure(api_key='AIzaSyDFOjxJ23DfYRLTqEuNsgnqwP0E79Aybpk')\n\n#fig = gmaps.figure(center=(53.0, 1.0), zoom_level=6)\n#3heatmap_layer = gmaps.heatmap_layer(accidents_2014_01[[\"Latitude\", \"Longitude\"]],\n                                    #max_intensity=30,point_radius=5)\n#heatmap_layer = gmaps.heatmap_layer(accidents_2014_02[[\"Latitude\", \"Longitude\"]],\n                                    #max_intensity=5,point_radius=3)\n#heatmap_layer = gmaps.heatmap_layer(accidents_2014_03[[\"Latitude\", \"Longitude\"]],\n                                    #max_intensity=1,point_radius=1)\n#fig.add_layer(heatmap_layer)\n#fig\n#embed_minimal_html('export1.html', views=[fig])","61687942":"import matplotlib.image as mpimg\nplt.figure(figsize=(18,8))\nimg=mpimg.imread('..\/input\/photos\/map1.png')\nimgplot = plt.imshow(img)\nplt.grid(False)\nplt.show()","3f43d2c8":"#import gmaps\n#gmaps.configure(api_key=\"AIzaSyDFOjxJ23DfYRLTqEuNsgnqwP0E79Aybpk\") \n\n#maps_df = accidents_2014_01[['Latitude', 'Longitude']]\n#maps_layer = gmaps.symbol_layer(\n   #maps_df, fill_color=\"green\", stroke_color=\"red\", scale=1\n#)\n#fig = gmaps.figure()\n#fig.add_layer(maps_layer)\n#fig","9c39ada9":"import matplotlib.image as mpimg\nplt.figure(figsize=(18,8))\nimg=mpimg.imread('..\/input\/photos\/map2.png')\nimgplot = plt.imshow(img)\nplt.grid(False)\nplt.show()","4b75eaae":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.metrics import log_loss","e7261df8":"sns.distplot(accidents['Age_of_Driver']);\nfig = plt.figure()\nsns.distplot(accidents['Age_of_Vehicle']);\nfig = plt.figure()","b2578bd8":"accidents['Age_of_Driver'] = np.log(accidents['Age_of_Driver'])\naccidents['Age_of_Vehicle'] = np.log(accidents['Age_of_Vehicle'])\nsns.distplot(accidents['Age_of_Driver']);\nfig = plt.figure()\nsns.distplot(accidents['Age_of_Vehicle']);\nfig = plt.figure()","42b57947":"accident_ml = accidents.drop('Accident_Severity' ,axis=1)\naccident_ml = accident_ml[['Did_Police_Officer_Attend_Scene_of_Accident' , 'Age_of_Driver' ,'Vehicle_Type', 'Age_of_Vehicle','Engine_Capacity_(CC)','Day_of_Week' , 'Weather_Conditions' , 'Road_Surface_Conditions'\n                          , 'Light_Conditions', 'Sex_of_Driver' ,'Speed_limit']]\n\n# Split the data into a training and test set.\nX_train, X_test, y_train, y_test = train_test_split(accident_ml.values, \n                                              accidents['Accident_Severity'].values,test_size=0.20, random_state=99)","57802a28":"random_forest = RandomForestClassifier(n_estimators=200)\nrandom_forest.fit(X_train,y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_test, y_test)\nacc_random_forest1 = round(random_forest.score(X_test, y_test) * 100, 2)\n\nsk_report = classification_report(\n    digits=6,\n    y_true=y_test, \n    y_pred=Y_pred)\nprint(\"Accuracy\" , acc_random_forest1)\nprint(sk_report)\npd.crosstab(y_test, Y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)","b236ccef":"lr = LogisticRegression()\n# Fit the model on the trainng data.\nlr.fit(X_train, y_train)\ny_pred = lr.predict(X_test)\nsk_report = classification_report(\n    digits=6,\n    y_true=y_test, \n    y_pred=y_pred)\nprint(\"Accuracy\", round(accuracy_score(y_pred, y_test)*100,2))\nprint(sk_report)\npd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)","04a05ad0":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree1 = round(decision_tree.score(X_test, y_test) * 100, 2)\nsk_report = classification_report(\n    digits=6,\n    y_true=y_test, \n    y_pred=Y_pred)\nprint(\"Accuracy\", acc_decision_tree1)\nprint(sk_report)\n### Confusion Matrix \npd.crosstab(y_test, Y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)","5397e314":"from sklearn.linear_model import LogisticRegressionCV\nlr = LogisticRegressionCV(cv=3, random_state=0,multi_class='multinomial')\n# Fit the model on the trainng data.\nlr.fit(X_train, y_train)\ny_pred = lr.predict(X_test)\nsk_report = classification_report(\n    digits=6,\n    y_true=y_test, \n    y_pred=y_pred)\nprint(\"Accuracy\", round(accuracy_score(y_pred, y_test)*100,2))\nprint(sk_report)\npd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)","8904e99e":"decision_tree = DecisionTreeClassifier(min_samples_leaf=12, max_features=4)\ndecision_tree.fit(X_train, y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree1 = round(decision_tree.score(X_test, y_test) * 100, 2)\nsk_report = classification_report(\n    digits=6,\n    y_true=y_test, \n    y_pred=Y_pred)\nprint(\"Accuracy\", acc_decision_tree1)\nprint(sk_report)\n### Confusion Matrix \npd.crosstab(y_test, Y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)","a5588e36":"random_forest.get_params()","9e2f2433":"from sklearn.model_selection import RandomizedSearchCV\nparam_grid = {\n    'bootstrap': [True],\n    'max_depth': [80, 90, 100, 110],\n    'max_features': [4, 5],\n    'min_samples_leaf': [5, 10, 15],\n    'min_samples_split': [8, 10, 12],\n    'n_estimators': [100, 200, 300]\n}\n# Create a based model\nrandom_f = RandomForestClassifier()\n# Instantiate the grid search model\ngrid_search = RandomizedSearchCV(estimator = random_f, param_distributions = param_grid, \n                          cv = 3, n_jobs = -1, verbose = 2)\n\ngrid_search.fit(X_train,y_train)\n","57d00606":"plt.figure(figsize=(12,6))\nfeat_importances = pd.Series(random_forest.feature_importances_, index=accident_ml.columns)\nfeat_importances.nlargest(5).plot(kind='barh')","80085a36":"Y_pred = grid_search.predict(X_test)\nacc_random_forest1 = round(grid_search.score(X_test, y_test) * 100, 2)\n\nsk_report = classification_report(\n    digits=6,\n    y_true=y_test, \n    y_pred=Y_pred)\nprint(\"Accuracy\" , acc_random_forest1)\nprint(sk_report)\npd.crosstab(y_test, Y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)","41d0934f":"### Introduction\n\nThis project is analysis on U.K accidents data from year 2005 to 2015. There are some questions that can be answered using this data such as -\n- What are the regions or areas with most frequent accidents?\n- What kind of street or highways are more liekly to have accidents?\n- What are the age group are most likely to be involved in accidents?\n- What are the areas with higher accident severity or lower accident severity?\n   \nThere are endless questions that can be answered with this dataset. We will be answering few of the questions as I mentioned above. We will also figure out some way to implement the machine learning on this dataset and see what we can come up with.\n\n\nThe data comes from governemnt website www.data.gov.uk. UK police forces collect the accidents data using the form called Stats19. The data consists of all kind of vehicle collisons from 2005 to 2015. Every column of the dataset is in numerical format. A supporting document to understand each numerical category in accidents datset is provided on the www.data.gov.uk website as well. There is another dataset available to get general average traffic report for all the regions. ","d766a96c":"## Importing Data and cleaning\n- We import three files to perform analysis on this data. This data is consist of three files that are accidents, casualities and vehicles. However, we have one more file which is general information about the traffic count for year 2000 to 2015. We can use general traffic information data for machine learning part.","5272e21d":"###  Random Forest Hyperparameter tuning\nFirst, we will see the default parameters of the random forest model before we tune the parameters.","31eba029":"## Conclusion\nAs we have implemented the Logistic Regression, Decision Tree and Random Forest algorithms to predict the accident severity. There are two things that we can conclude from this learning.\n\n#### Machine Learning Conclusion\nAs we have tried three different algorithms to predict the accident severity. It was clear that Decision tree and Random Forest performed much better in terms of predicting all the classes of accident severity. Logistic regression has better accuracy but it does not mean it did better than other algorithm. We even tried multi-nomial to predict all the classes in hyperparameter tuning section. It still predicted only one of the higher occuring class.\n\n#### Recommendation for Public or Law Enforcement\nThere are two things that were clear from this project. First, the most of the accidents occured locally. Secondly, we used feature importance and vehicle engine and age of the driver are the biggest factor in accident severity. We already know that the car insurances are expensive for the young age people and this is one of the reasons.","0506da1c":"## Random Forest","765d1769":"We will implement the grid search using sklearn library. ","9a7503e4":"Random forest took lots of time to tune the hyperparameter. Most of the algorithm works well only with default values except decision tree.","65c77ed5":"# Analysis of UK Traffic Accidents and Predicting the Accident Severity\n###### Ravinder Singh          \n","90545835":"## Spliting the data into training data and test data\nWe will also consider few features as predictors for machine learning algorithm.","6fa1942d":"As we see that there is not so much strong correlations between any variables. I was expecting weather condition to be strong correlation with any of the variable. \n- There is only one postiive strong correlation between speed limit and Urban or Rural Area. ","d818d805":"## Feature importance\nWe can use Sklearn's random forest library to find out the most important features. We will be plotting in  ascending order so we know what features are most important to predict the accident severity.","63dc5b97":"### Logistic Regression with Hyperparameter tuning\n","ef46d7d5":"Most of the accidents occured on the road where the speed limit is 30. I was expecting more accidents on highway or major roadways. Some of the accidents could be cause of stop sign, changing lanes or turning into parking lot etc.","cdbd8d11":"Our dataset is clean to do some analysis. We would be using very few columns to do analysis since the dataset is fairly large.","efe78ce4":"#### The first thing we can do is to find out about accidents time to get intution and some driver's age who are involved in the accident.\n- We can find out the number of accidents on the days of a week.\n- We can find out about the accidents number using hours of the day.\n- Finding out about the age of driver can tell us more about the accidents.","6049baf6":"## Plotting accidents Location on Google Maps\n\nNow we will be using google maps to plot the accidents. Using longitude and latitude information, we can see what area has the most accidents. However, it actually depends on how much traffic the area has. We can also get the idea of busiest area even if we do not want to look at just accidents. The accident plots acan give us really good idea about traffic in any area of the UK.\n\nAlso, I have taken the screenshot of output plots so it can be seen when saved in html or pdf format.","66aa69c0":"# Hyperparameters tuning for the models\n","f30603f8":"As we can see that most of fatal accidents happened locally within cities instead on highways. It could be the reason of the traffic is more congested locally than on highways.","f01ab6d5":"As we can see that Logistic regression did pretty well in terms of number. If we look carefully at the confusion matrix. We can definitely tell that Decision tree algorithm did much better. It predicted more fatal and serious injuries as true positive. The accuracy score is lower compare to another algorithm because other algorithm predicted majority of slightly accidents and those numbers are really high overall in the dataset. Confusion matrix helps us to understand what algorithm actually worked better in terms of looking at all different prediction of each class.","8507e2c6":"## Co-relation between variables\n\nSince our dataset is in numeric values. We can findout correlation between columns.","2611bfb1":"## Normalize the Data\nThere are few columns that we will standarize, so it would not effect negatively on our machine learning algorithms. Age of driver is from 18 to 88 in the dataset and we can normalize it. Also, the age of vehicle is also from 0 to 100 and it can skew the performance of your machine learning algorithm and we will normalize this predictor too.","72908a28":"This is very interesting fact about this dataset. Most of the drivers age is around 225 to 35 who are involved in the accident. However, we do not know the number of drivers with age 25 to 35 on the road compare to other ages. Intutively, I would assume that the driver with age 25 to 35 are more in the number of drivers with different age.","4921b965":"As we can see that thursday has the highest amount of accidents in this dataset from 2005 to 2015. We have to keep in mind that accidents numbers could be depending on traffic amount on particular day.","096440a5":"## Identifying Missing Values\n\nIn this particular dataset, there are two types of missing values '-1' and 'Nan'. We will invesitigate each column with total missing values.\nWe will not be imputing any mean or median value since the dataset is big enough to perform analysis.","7f3ecc21":"## Machine Learning\n\nWe will be looking at different columns to figure out predicting about the accidents severity. After we can predict the accident severity, we can make some recommendation to law enforcement for looking into this and be prepared for the future. We can also have more emergency medical services available for those situations.","bf735edf":"### Decision Tree hyperparameters tuning\n\nAll we are going to do is find the best values for mininum sample leaf and maximum features to get the best score.","e72c37f4":"We found out that the most of accidents happened around after noon. We can assume that this time of the day has the most traffic moving such as people leaving from work.\n\n\n#### Age band of casualities\n\nIn this dataset, age band is grouped in 11 different codes. We will create the labels and pass it to the plot as xticks so we can have idea about the bins representation.","ce98c33c":"As we can see that Logistic regression still didn't predict two classes of accident severity out of 3. Even though it is showing the 86.2% accuracy. ","2cc5b357":"We really didn't see much difference in Accident severity 1 and 2. However we did improve the accuracy of Accident severity 3. It jumped the accuracy from 75.1% to 85.8%.","313616c6":"## Logistic Regression ","eb0b0e53":"# Data Visualization","016bdd84":"## Decision Tree"}}