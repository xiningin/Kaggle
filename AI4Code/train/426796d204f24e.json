{"cell_type":{"8760cd48":"code","ae584518":"code","f51acb2c":"code","aee0ad16":"code","deefcb26":"code","a693646c":"code","7bb30956":"code","c3ba1c56":"code","47d5e064":"code","91128b0b":"code","45ce6f1f":"code","213679d7":"code","c4af088b":"code","2af79c62":"code","732c309b":"code","843e0582":"code","4d582ec4":"code","b88494aa":"code","9f7479a2":"code","c24a13cb":"code","7eef36d7":"code","8a245cb8":"code","0cdf4d66":"code","2664960d":"code","94579845":"code","207c6ac1":"code","14c263c0":"code","a04c536d":"code","b88369ca":"code","dcbe1c88":"markdown","51b54ced":"markdown","a331c689":"markdown","b32914fe":"markdown","8e435d7d":"markdown","e8918e7d":"markdown","22ac73fa":"markdown","78f48b80":"markdown","73001a99":"markdown","87e86c46":"markdown","6cf12b9b":"markdown","83ff5648":"markdown","3f697ece":"markdown","9b8ca8c3":"markdown","15cba922":"markdown","67c16198":"markdown","ba0eadfb":"markdown"},"source":{"8760cd48":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")","ae584518":"# loading training data and reading top 5 records\n\ndf = pd.read_csv('..\/input\/hr-analytics-analytics-vidya\/train.csv')\ndf.head()","f51acb2c":"### Reading bottom 5 records\n\ndf.tail()","aee0ad16":"print(\"There are {} rows and {} columns in the training dataset.\".format(df.shape[0],df.shape[1]))","deefcb26":"# To know the datatypes of the column\n\ndf.info()","a693646c":"print(\"There are {} duplicate records.\".format(df.shape[0] - len(df['employee_id'].unique())))","7bb30956":"# Droping employee_id column as it doesnot provide any information\n\ndf.drop('employee_id',axis=1,inplace=True)","c3ba1c56":"# Name of the columns\n\nprint(\"Column Names: {}\".format(list(df.columns)))","47d5e064":"# Column names into list\n\ncol_name = df.columns.to_list()","91128b0b":"# To find out number of unique values and unique vales of a perticular column\n\nfor i in col_name:\n    print(\"In the column - {}:\".format(i))\n    print(\"There are {0} Unique values\".format(len(df[i].unique())))\n    print(\"Unique vales in the column are - \\n{}\".format(list(df[i].unique())))\n    print(\"\")","45ce6f1f":"df.info()","213679d7":"# Correlation Matrix\n\nplt.figure(figsize=(10,5))\nsns.heatmap(df.corr(), annot=True)\nplt.show()","c4af088b":"# Count of each values in column\nfor i in col_name:\n    plt.figure(figsize=(15,5))\n    plt.title(\"Count of each values in column '{}'\".format(i))\n    sns.countplot(df[i])\n    plt.show()","2af79c62":"# Pair plot\n\nsns.pairplot(df)\nplt.show()","732c309b":"print(\"There are totally {} missing values in the dataset.\".format(df.isnull().sum().sum()))","843e0582":"# Count of missing values in column\n\nfor i in col_name:\n    if df[i].isnull().sum() > 0:\n        print(\"There are {} missing values in the '{}' column.\\n\".format(df[i].isnull().sum(),i))","4d582ec4":"# Imputing missing values in column education with forwardfill\n\ndf['education'] = df['education'].ffill()","b88494aa":"# Value count for column \"length_of_service\" when \"previous_year_rating\" isnull\n\ndf[df[\"previous_year_rating\"].isnull() == True]['length_of_service'].value_counts()","9f7479a2":"# Imputing missing values in column \"previous_year_rating\" with \"0\" as length of service is 1 for missing values \n\ndf['previous_year_rating'] = df['previous_year_rating'].fillna(0.0)","c24a13cb":"# Binning the age column\n\ndf['age'] = pd.cut(x=df['age'], bins=[20, 29, 39, 49], \n                    labels=['20 to 30', '30 to 40', '40+']) ","7eef36d7":"# Changing datatype 'category' to 'object'\n\ndf['age'] = df['age'].astype('object')","8a245cb8":"X = df.drop('is_promoted',axis=1)\ny = df['is_promoted']","0cdf4d66":"X_encode = pd.get_dummies(X,drop_first=True)","2664960d":"from sklearn import preprocessing \n\nscaler = preprocessing.RobustScaler() \nX_standard = scaler.fit_transform(X_encode) \nX_standard = pd.DataFrame(X_standard, columns =X_encode.columns) ","94579845":"from xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\n\n\nClassifiers = {'0._XGBoost' : XGBClassifier(learning_rate =0.1, n_estimators=500, max_depth=5,subsample = 0.70,\n                                            verbosity = 0, scale_pos_weight = 2.5,updater =\"grow_histmaker\",\n                                            base_score  = 0.2),\n               \n               '1.CatBoost' : CatBoostClassifier(learning_rate=0.15, n_estimators=500, subsample=0.085, max_depth=5,\n                                                 scale_pos_weight=2.5),\n               \n               '2.LightGBM' : LGBMClassifier(subsample_freq = 2, objective =\"binary\",importance_type = \"gain\",verbosity = -1,\n                                             max_bin = 60,num_leaves = 300, boosting_type = 'dart',learning_rate=0.15, \n                                             n_estimators=500, max_depth=5, scale_pos_weight=2.5)}","207c6ac1":"from sklearn.ensemble import VotingClassifier\n\nvc_model = VotingClassifier(estimators=[('XGBoost_Best', list(Classifiers.values())[0]), \n                                        ('CatBoost_Best', list(Classifiers.values())[1]),\n                                        ('LightGBM_Best', list(Classifiers.values())[2]),\n                                       ], \n                            voting='soft',weights=[2, 1, 3])\n\nvc_model.fit(X_standard,y)","14c263c0":"# Loading test dataset\n\ndf1 = pd.read_csv('..\/input\/hr-analytics-analytics-vidya\/test.csv')\ndf1.head()","a04c536d":"# Performing all the step on the unseen data that was performed on historical data\n\ndf2 = df1.copy()\n\ndf1.drop('employee_id',axis=1,inplace=True)\n\ndf1['education'] = df1['education'].ffill()\n\ndf1['previous_year_rating'] = df1['previous_year_rating'].fillna(0.0)\n\ndf1['age'] = pd.cut(x=df1['age'], bins=[20, 29, 39, 49], labels=['20 to 30', '30 to 40', '40+']) \ndf1['age'] = df1['age'].astype('object')\n\ndf1_encode = pd.get_dummies(df1,drop_first=True)\n\nscaler = preprocessing.RobustScaler() \ndf_standard = scaler.fit_transform(df1_encode) \ndf_standard = pd.DataFrame(df_standard, columns =df1_encode.columns)","b88369ca":"df2['is_promoted'] = vc_model.predict(df_standard)\n\ndf1=df2[['employee_id','is_promoted']]\ndf1.to_csv('Predict19.csv')","dcbe1c88":"### Importing Basic libraries:","51b54ced":"- 'length_of_service' is highly correlated with 'age'\n- 'KPIs_met >80%' is slightly correlated with 'previous_year_rating'","a331c689":"### Improving Model with Voting Classifier with MODEL Evaluation METRIC - \"F1\" and Predict Target \"is_promoted\":","b32914fe":"### Predicting and storing the submission file:","8e435d7d":"- Parameters values are taken from tuning and trail and error method.","e8918e7d":"### Spliting train data into Predictors(Independent) & Target(Dependent):","22ac73fa":"### Not dividing train dataset to train_test_split as it gives less value of F-1 score.","78f48b80":"### Data encoding using OneHot encoding technique:","73001a99":"### Exploratory Data Analysis:","87e86c46":"### Featuring Engineering:","6cf12b9b":"### Data scaling using RobustScalar:","83ff5648":"- Weights are taken from tuning.","3f697ece":"## Scoring:","9b8ca8c3":"**In this kernel I am going to use VotingClassifier as ensemble technique. And the algorithms used are XGBoost, LGBM and Catboost.**","15cba922":"##### Finding missing values and imputing it:","67c16198":"### Creating Baseline ML Model for Binary Classification Problem:","ba0eadfb":"### Dataset Description:\n\n- employee_id : Unique ID for employee\n- department : Department of employee\n- region : Region of employment (unordered)\n- education : Education Level\n- gender : Gender of Employee\n- recruitment_channel : Channel of recruitment for employee\n- no_of_trainings : no of other trainings completed in previous year on soft skills, technical skills etc.\n- age : Age of Employee\n- previous_year_rating : Employee Rating for the previous year\n- length_of_service : Length of service in years\n- KPIs_met >80% : if Percent of KPIs(Key performance Indicators) >80% then 1 else 0\n- awards_won? : if awards won during previous year then 1 else 0\n- avg_training_score : Average score in current training evaluations\n- is_promoted : (Target) Recommended for promotion"}}