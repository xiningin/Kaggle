{"cell_type":{"847337c9":"code","2da77583":"code","abb6e811":"code","15b36095":"code","84d06eb8":"code","601218a4":"code","e916e010":"code","56702133":"code","c5a8e761":"code","f3362f5d":"code","a7148405":"code","4c50e1f9":"code","39b96c8a":"code","b5a5210c":"code","5fd69263":"code","e7d65296":"code","28acfcb9":"code","d34d389a":"code","b0315bf9":"code","e25233a7":"code","e5c7e24f":"code","bb5805de":"code","3d314d6c":"code","c5fb88ce":"markdown","15e3ad82":"markdown","9a7b3d36":"markdown","dc462821":"markdown","a16992ca":"markdown","2c095b31":"markdown","456d72e8":"markdown","b96a7c82":"markdown","8a2dd74c":"markdown","fa33cf3d":"markdown","ee587242":"markdown","aa820141":"markdown","c2aa7651":"markdown","b9a2ee31":"markdown","85de91c9":"markdown","7fecba54":"markdown","f6e57546":"markdown","f4adccda":"markdown","3ff96cb8":"markdown","af3113ff":"markdown","7bb59b89":"markdown"},"source":{"847337c9":"# Ignore warning messages\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn\n\n# Handle table-like data and matrices\nimport numpy as np\nimport pandas as pd\n\n# Computations\nimport itertools\n\n# Modelling Algorithms\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import PassiveAggressiveClassifier\n\n# Modelling Helpers\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn import metrics\n\n# Visualization\nimport matplotlib.pyplot as plt","2da77583":"train = pd.read_csv(\"\/kaggle\/input\/fake-news\/train.csv\")\ntest  = pd.read_csv (\"\/kaggle\/input\/fake-news\/test.csv\")\n","abb6e811":"train.head()","15b36095":"print(f\"Train Shape : {train.shape}\")\nprint(f\"Test Shape : {test.shape}\")\n","84d06eb8":"train.info()","601218a4":"train.isnull().sum()","e916e010":"train.dtypes.value_counts()","56702133":"# Handle missing values\ntest=test.fillna(' ')\ntrain=train.fillna(' ')","c5a8e761":"# Create a column with all the data available\ntest['total']=test['title']+' '+test['author']+' '+test['text']\ntrain['total']=train['title']+' '+train['author']+' '+train['text']","f3362f5d":"# Have a glance at our training set\ntrain.info()\ntrain.head()","a7148405":"# Dividing the training set by using train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train['total'], train.label, test_size=0.20, random_state=0)","4c50e1f9":"# Initialize the `count_vectorizer` \ncount_vectorizer = CountVectorizer(ngram_range=(1, 2), stop_words='english') \n# Fit and transform the training data.\ncount_train = count_vectorizer.fit_transform(X_train)\n# Transform the test set \ncount_test = count_vectorizer.transform(X_test)","39b96c8a":"#Initialize the `tfidf_vectorizer` \ntfidf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))\n#Fit and transform the training data \ntfidf_train = tfidf_vectorizer.fit_transform(X_train)\n#Transform the test set \ntfidf_test = tfidf_vectorizer.transform(X_test)","b5a5210c":"nb_classifier = MultinomialNB(alpha = 0.1)\nnb_classifier.fit(count_train, y_train)\npred_nb_count = nb_classifier.predict(count_test)\nacc_nb_count = metrics.accuracy_score(y_test, pred_nb_count)\nprint(acc_nb_count)","5fd69263":"# tune the hyperparameter alpha for the naive bayes classifier\nfor alpha in np.arange(0,1,.05):\n    nb_classifier_tune = MultinomialNB(alpha=alpha)\n    nb_classifier_tune.fit(count_train, y_train)\n    pred_tune = nb_classifier_tune.predict(count_test)\n    score = metrics.accuracy_score(y_test, pred_tune)\n    print(\"Alpha: {:.2f} Score: {:.5f}\".format(alpha, score))","e7d65296":"# Let's re-run our fine-tuned model and plot the confusion matrix\nnb_classifier = MultinomialNB(alpha = 0.15)\nnb_classifier.fit(count_train, y_train)\npred_nb_count = nb_classifier.predict(count_test)\ncm = metrics.confusion_matrix(y_test, pred_nb_count, labels=[0,1])\n\n# Creating a function that outputs a confusion matrix\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \n    \nplot_confusion_matrix(cm, classes=['TRUE','FAKE'], title ='Confusion matrix for a MultinomialNB with Count Vectorizer')","28acfcb9":"nb_classifier = MultinomialNB(alpha = 0.1)\nnb_classifier.fit(tfidf_train, y_train)\npred_nb_tfidf = nb_classifier.predict(tfidf_test)\nacc_nb_tfidf = metrics.accuracy_score(y_test, pred_nb_tfidf)\nprint(acc_nb_tfidf)","d34d389a":"# tune the hyperparameter alpha for the naive bayes classifier\nfor alpha in np.arange(0,0.1,.01):\n    nb_classifier_tune = MultinomialNB(alpha=alpha)\n    nb_classifier_tune.fit(tfidf_train, y_train)\n    pred_tune = nb_classifier_tune.predict(tfidf_test)\n    score = metrics.accuracy_score(y_test, pred_tune)\n    print(\"Alpha: {:.2f}  Score: {:.5f}\".format(alpha, score))","b0315bf9":"# Let's run the optimized model with best value of hyperparameter and check the confusion matrix\nnb_classifier = MultinomialNB(alpha = 0.01)\nnb_classifier.fit(tfidf_train, y_train)\npred_nb_tfidf = nb_classifier.predict(tfidf_test)\ncm2 = metrics.confusion_matrix(y_test, pred_nb_tfidf, labels=[0,1])\nplot_confusion_matrix(cm2, classes=['TRUE','FAKE'], title ='Confusion matrix for a MultinomialNB with Tf-IDF')","e25233a7":"from sklearn.linear_model import PassiveAggressiveClassifier\nlinear_classifier = PassiveAggressiveClassifier(max_iter=10)\nlinear_classifier.fit(count_train, y_train)\npred_linear_count = linear_classifier.predict(count_test)\nacc_linear_count = metrics.accuracy_score(y_test, pred_linear_count)\nprint(acc_linear_count)\ncm6 = metrics.confusion_matrix(y_test, pred_linear_count, labels=[0,1])\nplot_confusion_matrix(cm6, classes=['TRUE','FAKE'], title ='Confusion matrix for a PA Classifier with Count Vectorizer')","e5c7e24f":"linear_classifier = PassiveAggressiveClassifier(max_iter=10)\nlinear_classifier.fit(tfidf_train, y_train)\npred_linear_tfidf = linear_classifier.predict(tfidf_test)\nacc_linear_tfidf = metrics.accuracy_score(y_test, pred_linear_tfidf)\nprint(acc_linear_tfidf)\ncm5 = metrics.confusion_matrix(y_test, pred_linear_tfidf, labels=[0,1])\nplot_confusion_matrix(cm5, classes=['TRUE','FAKE'], title ='Confusion matrix for a PA Classifier with Tf-IDF')","bb5805de":"logreg = LogisticRegression(C=1e5)\nlogreg.fit(tfidf_train, y_train)\npred_logreg_tfidf = logreg.predict(tfidf_test)\npred_logreg_tfidf_proba = logreg.predict_proba(tfidf_test)[:,1]\nacc_logreg_tfidf = metrics.accuracy_score(y_test,pred_logreg_tfidf)\nprint(acc_logreg_tfidf)\ncm4 = metrics.confusion_matrix(y_test, pred_logreg_tfidf, labels=[0,1])\nplot_confusion_matrix(cm4, classes=['TRUE','FAKE'], title ='Confusion matrix for a Logistic Regression with Tf-IDF')","3d314d6c":"logreg = LogisticRegression(C=1e5)\nlogreg.fit(count_train, y_train)\npred_logreg_count = logreg.predict(count_test)\nacc_logreg_count = metrics.accuracy_score(y_test,pred_logreg_count)\nprint(acc_logreg_count)\ncm3 = metrics.confusion_matrix(y_test, pred_logreg_count, labels=[0,1])\nplot_confusion_matrix(cm3, classes=['TRUE','FAKE'], title ='Confusion matrix for a Logistic Regression with Count Vectorizer')","c5fb88ce":"### 5. Logistic Regression with TF-IDF Vectorizer ","15e3ad82":"We get much better results than with the MultinomialNB model, both in terms of accuracy and in terms of false negative. Only 60 fake news were labeled as true news this time.\nLet's try with the Tf-IDF method.","9a7b3d36":"It's THE BEST MODEL YAY ! This is our favorite model so far. Indeed, even though the accuracy score is a bit lower, we have less fake news labeled as true news ie. only 44. Therefore, I choose this model because it seems to maximize the accuracy while minimizing the false negative rate!","dc462821":"### 2. Tf-IDF Vectorizer ","a16992ca":"This model has a very high accuracy score, and only 58 records were misclassified. So far, Logistic Regression played it best ! Let's see the same with CountVectorizer ie. Bag of Words concept.","2c095b31":"## Vectorizing our Data","456d72e8":"## Some Data Analysis and Data Preprocessing","b96a7c82":"### 1. Count Vectorizer ","8a2dd74c":"### 1. Multinomial Naive Bayes with Count Vectorizer (BagofWords)","fa33cf3d":"## Import all the necessary libraries","ee587242":"If model is trained on a concatenation of the title, the author and the main text, the model would be more generalized because adding more words to the input might increase the reliablity of the model.","aa820141":"### 4. Passive Agressive Classifier With TF-IDF Vectorizer","c2aa7651":"## Load the Data ","b9a2ee31":"### 3. Passive Agressive Classifier With Count Vectorizer","85de91c9":"### 6.  Logistic Regression with CountVectorizer","7fecba54":"The best score is obtained for alpha = 0.15, and is equal to 0.94279.","f6e57546":"### 2. Multinomial Naive Bayes with TF-IDF Vectorizer ","f4adccda":"# Use Suitable Machine Learning Models with Count Vectorizer and TF-IDF Vectorizer","3ff96cb8":"This confusion matrix above confirms that this new model is slightly better (and its accuracy score is 94.4 %).\nHowever, too many fake news are still labeled as true news.\nLet's try with another model called PassiveAgressive Classifier which is special for text classification purposes. ","af3113ff":"Although we observe more false negative, the overall accuracy is much better, hence so far this is our best model.\nLet's try with Logistic Regression now !","7bb59b89":"We see that although our model has a general accuracy of 94.3 %, which is good, but it does not really score well in view of number of false negative. 223 fake news are classified as true news with this model, which is not pleasing to see. So we will try to use the Tf-IDF vectorizer on this same model to see if it performs better."}}