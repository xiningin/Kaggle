{"cell_type":{"51754f45":"code","dc2f2c9f":"code","ecf9caaa":"code","9773384a":"code","aa9140a8":"code","b10e484c":"code","1fe6626a":"code","aa3395da":"code","fbfe301e":"code","e939b92e":"code","d8fd85cd":"code","3b18332e":"code","9877923d":"code","c541bbf2":"code","57bfbaa3":"markdown","b6887976":"markdown","4ef8c710":"markdown","fdcc0ec5":"markdown","538338bf":"markdown","46daf25f":"markdown","bb749bb1":"markdown","6d3248f9":"markdown"},"source":{"51754f45":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm as tqdm\n\nfrom ipywidgets import widgets, interactive, interact\nimport ipywidgets as widgets\nfrom IPython.display import display\n\nimport os\nfor dirname, _, filenames in os.walk('input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","dc2f2c9f":"train_sales = pd.read_csv('\/kaggle\/input\/m5-forecasting-uncertainty\/sales_train_validation.csv')\ncalendar_df = pd.read_csv('\/kaggle\/input\/m5-forecasting-uncertainty\/calendar.csv')\nsubmission_file = pd.read_csv('\/kaggle\/input\/m5-forecasting-uncertainty\/sample_submission.csv')\nsell_prices = pd.read_csv('\/kaggle\/input\/m5-forecasting-uncertainty\/sell_prices.csv')","ecf9caaa":"total = ['Total']\ntrain_sales['Total'] = 'Total'\ntrain_sales['state_cat'] = train_sales.state_id + \"_\" + train_sales.cat_id\ntrain_sales['state_dept'] = train_sales.state_id + \"_\" + train_sales.dept_id\ntrain_sales['store_cat'] = train_sales.store_id + \"_\" + train_sales.cat_id\ntrain_sales['store_dept'] = train_sales.store_id + \"_\" + train_sales.dept_id\ntrain_sales['state_item'] = train_sales.state_id + \"_\" + train_sales.item_id\ntrain_sales['item_store'] = train_sales.item_id + \"_\" + train_sales.store_id","9773384a":"val_eval = ['validation', 'evaluation']\n\n# creating lists for different aggregation levels\ntotal = ['Total']\nstates = ['CA', 'TX', 'WI']\nnum_stores = [('CA',4), ('TX',3), ('WI',3)]\nstores = [x[0] + \"_\" + str(y + 1) for x in num_stores for y in range(x[1])]\ncats = ['FOODS', 'HOBBIES', 'HOUSEHOLD']\nnum_depts = [('FOODS',3), ('HOBBIES',2), ('HOUSEHOLD',2)]\ndepts = [x[0] + \"_\" + str(y + 1) for x in num_depts for y in range(x[1])]\nstate_cats = [state + \"_\" + cat for state in states for cat in cats]\nstate_depts = [state + \"_\" + dept for state in states for dept in depts]\nstore_cats = [store + \"_\" + cat for store in stores for cat in cats]\nstore_depts = [store + \"_\" + dept for store in stores for dept in depts]\nprods = list(train_sales.item_id.unique())\nprod_state = [prod + \"_\" + state for prod in prods for state in states]\nprod_store = [prod + \"_\" + store for prod in prods for store in stores]","aa9140a8":"print(\"Departments: \", depts)\nprint(\"Categories by state: \", state_cats)","b10e484c":"quants = ['0.005', '0.025', '0.165', '0.250', '0.500', '0.750', '0.835', '0.975', '0.995']\ndays = range(1, 1913 + 1)\ntime_series_columns = [f'd_{i}' for i in days]","1fe6626a":"def create_sales(name_list, group):\n    '''\n    This function returns a dataframe (sales) on the aggregation level given by name list and group\n    '''\n    rows_ve = [(name + \"_X_\" + str(q) + \"_\" + ve, str(q)) for name in name_list for q in quants for ve in val_eval]\n    sales = train_sales.groupby(group)[time_series_columns].sum() #would not be necessary for lowest level\n    return sales","aa3395da":"total = ['Total']\ntrain_sales['Total'] = 'Total'\ntrain_sales['state_cat'] = train_sales.state_id + \"_\" + train_sales.cat_id\ntrain_sales['state_dept'] = train_sales.state_id + \"_\" + train_sales.dept_id\ntrain_sales['store_cat'] = train_sales.store_id + \"_\" + train_sales.cat_id\ntrain_sales['store_dept'] = train_sales.store_id + \"_\" + train_sales.dept_id\ntrain_sales['state_item'] = train_sales.state_id + \"_\" + train_sales.item_id\ntrain_sales['item_store'] = train_sales.item_id + \"_\" + train_sales.store_id","fbfe301e":"#example usage of CreateSales\nsales_by_state_cats = create_sales(state_cats, 'state_cat')\nsales_by_state_cats","e939b92e":"def create_quantile_dict(name_list = stores, group = 'store_id' ,X = False):\n    '''\n    This function writes creates sales data on given aggregation level, and then writes predictions to the global dictionary my_dict\n    '''\n    sales = create_sales(name_list, group)\n    sales = sales.iloc[:, 1675:] #using the last few months data only\n    sales_quants = pd.DataFrame(index = sales.index)\n    for q in quants:\n        sales_quants[q] = np.quantile(sales, float(q), axis = 1)\n    full_mean = pd.DataFrame(np.mean(sales, axis = 1))\n    daily_means = pd.DataFrame(index = sales.index)\n    for i in range(7):\n        daily_means[str(i)] = np.mean(sales.iloc[:, i::7], axis = 1)\n    daily_factors = daily_means \/ np.array(full_mean)\n\n    daily_factors = pd.concat([daily_factors, daily_factors, daily_factors, daily_factors], axis = 1)\n    daily_factors_np = np.array(daily_factors)\n\n    factor_df = pd.DataFrame(daily_factors_np, columns = submission_file.columns[1:])\n    factor_df.index = daily_factors.index\n\n    for i,x in enumerate(tqdm(sales_quants.index)):\n        for q in quants:\n            v = sales_quants.loc[x, q] * np.array(factor_df.loc[x, :])\n            if X:\n                my_dict[x + \"_X_\" + q + \"_validation\"] = v\n                my_dict[x + \"_X_\" + q + \"_evaluation\"] = v\n            else:\n                my_dict[x + \"_\" + q + \"_validation\"] = v\n                my_dict[x + \"_\" + q + \"_evaluation\"] = v","d8fd85cd":"my_dict = {}\n#adding prediction to my_dict on all 12 aggregation levels\ncreate_quantile_dict(total, 'Total', X=True) #1\ncreate_quantile_dict(states, 'state_id', X=True) #2\ncreate_quantile_dict(stores, 'store_id', X=True) #3\ncreate_quantile_dict(cats, 'cat_id', X=True) #4\ncreate_quantile_dict(depts, 'dept_id', X=True) #5\ncreate_quantile_dict(state_cats, 'state_cat') #6\ncreate_quantile_dict(state_depts, 'state_dept') #7\ncreate_quantile_dict(store_cats, 'store_cat') #8\ncreate_quantile_dict(store_depts, 'store_dept') #9\ncreate_quantile_dict(prods, 'item_id', X=True) #10\ncreate_quantile_dict(prod_state, 'state_item') #11\ncreate_quantile_dict(prod_store, 'item_store') #12","3b18332e":"pred_df = pd.DataFrame(my_dict)\npred_df = pred_df.transpose()\npred_df_reset = pred_df.reset_index()\nfinal_pred = pd.merge(pd.DataFrame(submission_file.id), pred_df_reset, left_on = 'id', right_on = 'index')\ndel final_pred['index']\nfinal_pred = final_pred.rename(columns={0: 'F1', 1: 'F2', 2: 'F3', 3: 'F4', 4: 'F5', 5: 'F6', 6: 'F7', 7: 'F8', 8: 'F9',\n                                        9: 'F10', 10: 'F11', 11: 'F12', 12: 'F13', 13: 'F14', 14: 'F15', 15: 'F16',\n                                        16: 'F17', 17: 'F18', 18: 'F19', 19: 'F20', 20: 'F21', 21: 'F22', \n                                        22: 'F23', 23: 'F24', 24: 'F25', 25: 'F26', 26: 'F27', 27: 'F28'})\nfinal_pred = final_pred.fillna(0)","9877923d":"final_pred.to_csv('submission.csv', index=False)","c541bbf2":"final_pred.head()","57bfbaa3":"## Variables to help with aggregation","b6887976":"# Simple Historical Quantiles","4ef8c710":"If you like this simple model, please upvote:)","fdcc0ec5":"## Getting quantiles adjusted by day-of-week","538338bf":"## Reading data","46daf25f":"For some reason, the Uncertainty part of the M5 forecasting competition received much lower attention than Accuracy, so much so that at the time of making this notebook (late March), only one competitor's LB score beats the best benchmark model of the organizers.\n\nThe goal of this notebook is to show that simply taking the historical quantiles on different aggregation levels is actually a good idea to start with. Sales data also has a weekly periodicity, to the predictions are adjusted by a day-of-week factor in an elementary way.\n\nWhile currently this model achieves a top25 (well, this was only true until early April) score by itself, there is obviously a lot of room for improvement.","bb749bb1":"## Getting aggregated sales","6d3248f9":"## Creating valid prediction df from my_dict"}}