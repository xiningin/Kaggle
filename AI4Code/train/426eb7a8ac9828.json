{"cell_type":{"479c0876":"code","b57cf8ad":"code","bba0becc":"code","5e4436e1":"code","6c0f9005":"code","bd621361":"code","55ef5651":"code","8bec399c":"code","6c7f8a33":"code","052778e0":"code","7d890f24":"code","7bf5e65a":"code","5d3c6df7":"code","f72a5dc5":"code","bd8d5465":"code","ee66097d":"code","73acbbad":"code","d1fd946a":"code","33ae7028":"code","4ef756e6":"code","d4423c6b":"code","7b19be89":"code","26bdfe6b":"markdown"},"source":{"479c0876":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport statsmodels.api as sm\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\nimport seaborn as sns\nfrom math import sqrt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import Ridge\nfrom yellowbrick.datasets import load_concrete\nfrom yellowbrick.regressor import ResidualsPlot\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b57cf8ad":"rng= np.random.RandomState(1)\nrng","bba0becc":"df1 =pd.DataFrame({'x1': [rng.randint(500,2000) for i in rng.rand(50)],'x2': [rng.randint(100,500) for i in rng.rand(50)]})\n\n\nx3df = pd.DataFrame({'x3': [rng.randint(0,50) for i in rng.rand(50)]+df1['x1']*3})\n\ndf1['x3']=x3df['x3']\n\ny= df1['x3']+df1['x2']\n\ndf1['y']=y\n\n\ndf1","5e4436e1":"df1['x1'].corr(df1['y'])","6c0f9005":"df1['x2'].corr(df1['y'])","bd621361":"df1['x3'].corr(df1['y'])","55ef5651":"corr = df1.corr(method='pearson')\ncorr.head()","8bec399c":"\ndf1.plot(kind=\"scatter\", # or `us_gdp.plot.scatter(`\n    x='x1',\n    y='y',\n    title=\"Graph of Y vs X1\",\n    figsize=(12,8)\n)\nplt.title(\"From %d to %d\" % (\n    df1['x1'].min(),\n    df1['x1'].max()\n),size=8)\nplt.suptitle(\"Graph of Y vs X1\",size=12)\nplt.ylabel(\"Y\")","6c7f8a33":"df1.plot(kind=\"scatter\",\n    x='x2',\n    y='y',\n    title=\"Graph of Y vs X2\",\n    figsize=(12,8)\n)\nplt.title(\"From %d to %d\" % (\n    df1['x2'].min(),\n    df1['x2'].max()\n),size=8)\nplt.suptitle(\"Graph of Y vs X2\",size=12)\nplt.ylabel(\"Y\")\n\n","052778e0":"#independent and dependent vars\nX_data = df1[['x1','x2',]]\nY_data = df1['y']\n\n#import train-test split\nfrom sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.30)","7d890f24":"reg = linear_model.LinearRegression()\nreg.fit(X_train,y_train)","7bf5e65a":"print(\"Regression Coefficients\")\npd.DataFrame(reg.coef_,index=X_train.columns,columns=[\"Coefficient\"])","5d3c6df7":"\n# Make predictions using the testing set\ntest_predicted = reg.predict(X_test)\ntest_predicted","f72a5dc5":"df2 = X_test.copy()\ndf2['predicted Y']=test_predicted\ndf2['Actual Y']=y_test\n","bd8d5465":"#shouldnt this graph show a stronger link between test and actual?\nsns.residplot(test_predicted, y_test, lowess=True, color=\"g\")","ee66097d":"#trying to see if this plot gives better results\n# it does, whats the diff\n\ndf2.plot.scatter(\n    x='predicted Y',\n    y='Actual Y',\n    figsize=(12,8)\n)\n\nplt.suptitle(\"Predicted Y vs Actual Y\",size=12)\nplt.ylabel(\"Actual Y\")\nplt.xlabel(\"Predicted Y\")","73acbbad":"print('R squared score is %.2f' % r2_score(y_test, test_predicted))\n\n#this shows how stong the relationship between the dependent and independent vars are. A higher score implies (1) \n#high strong relationship","d1fd946a":"# x1 and x2 combined can determine with a large degree of accuracy, the value of  Y","33ae7028":"reg.intercept_\n","4ef756e6":"#mean absolute error\nmean_absolute_error(y_test, test_predicted)","d4423c6b":"#root mean square errpr\nrmse = sqrt( mean_squared_error(y_test, test_predicted))\nrmse","7b19be89":" mean_squared_error(y_test, test_predicted)","26bdfe6b":"Regression formula\n\nY = 18.41 + 3.0*x1+ 1.0*x2\n\n\nx1=30\nx2=40\n\nY= 18.41+ (3*30) + 40\nY= 148.41"}}