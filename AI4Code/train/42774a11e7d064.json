{"cell_type":{"a9a61b63":"code","76781f9b":"code","279ef66e":"code","0b9c7815":"code","13572e9d":"code","9b935d66":"code","859294ec":"code","48616a20":"code","123466ea":"code","1303908a":"code","5f32fc2e":"code","518ab623":"code","51252aba":"code","c6997c4d":"code","0e02abe6":"code","81b30cd6":"code","45be9641":"code","cbf39de1":"code","4e91d2ef":"code","4637d681":"code","d745dd5a":"code","d5540db8":"code","59ec7774":"code","685ba172":"code","9a2fa2a6":"code","cb8a99d0":"code","758c41b0":"code","f0f5fc0e":"code","cb2c929c":"code","48b698d2":"code","6588d438":"markdown","fba73be3":"markdown","6435fa21":"markdown","e72c7629":"markdown","4c9dc038":"markdown","0cec5fc2":"markdown","cd606eec":"markdown","acdaedd6":"markdown","4a0c630d":"markdown","d29f86f0":"markdown","3980bfd9":"markdown","d391814e":"markdown","c2177ffe":"markdown","f29299d8":"markdown","4556c4d2":"markdown","add74426":"markdown","549bdb99":"markdown"},"source":{"a9a61b63":"# for numerical analysis\nimport numpy as np \n# to store and process in a dataframe\nimport pandas as pd \n\n# for ploting graphs\nimport matplotlib.pyplot as plt\n# advancec ploting\nimport seaborn as sns\n\n# image processing\nimport matplotlib.image as mpimg\n\n# train test split\nfrom sklearn.model_selection import train_test_split\n# model performance metrics\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# utility functions\nfrom tensorflow.keras.utils import to_categorical\n# sequential model\nfrom tensorflow.keras.models import Sequential\n# layers\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n\n\n# from keras.optimizers import RMSprop\n# from keras.preprocessing.image import ImageDataGenerator\n# from keras.callbacks import ReduceLROnPlateau","76781f9b":"# list of files\n! ls ..\/input\/digit-recognizer","279ef66e":"# import train and test dataset\ntrain = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","0b9c7815":"# training dataset\ntrain.head()","13572e9d":"# test dataset\ntest.head()","9b935d66":"# looking for missing values\nprint(train.isna().sum().sum())\nprint(test.isna().sum().sum())","859294ec":"plt.figure(figsize=(8, 5))\nsns.countplot(train['label'], palette='Dark2')\nplt.title('Train labels count')\nplt.show()","48616a20":"train['label'].value_counts().sort_index()","123466ea":"# first few train images with labels\nfig, ax = plt.subplots(figsize=(18, 8))\nfor ind, row in train.iloc[:8, :].iterrows():\n    plt.subplot(2, 4, ind+1)\n    plt.title(row[0])\n    img = row.to_numpy()[1:].reshape(28, 28)\n    fig.suptitle('Train images', fontsize=24)\n    plt.axis('off')\n    plt.imshow(img, cmap='magma')","1303908a":"# first few test images\nfig, ax = plt.subplots(figsize=(18, 8))\nfor ind, row in test.iloc[:8, :].iterrows():\n    plt.subplot(2, 4, ind+1)\n    img = row.to_numpy()[:].reshape(28, 28)\n    fig.suptitle('Test images', fontsize=24)\n    plt.axis('off')\n    plt.imshow(img, cmap='magma')","5f32fc2e":"# split into image and labels and convert to numpy array\nX = train.iloc[:, 1:].to_numpy()\ny = train['label'].to_numpy()\n\n# test dataset\ntest = test.loc[:, :].to_numpy()\n\nfor i in [X, y, test]:\n    print(i.shape)","518ab623":"# normalize the data\n# ==================\n\nX = X \/ 255.0\ntest = test \/ 255.0","51252aba":"# reshape dataset\n# ===============\n\n# shape of training and test dataset\nprint(X.shape)\nprint(test.shape)\n\n# reshape the dataframe to 3x3 matrix with 1 channel grey scale values\nX = X.reshape(-1,28,28,1)\ntest = test.reshape(-1,28,28,1)\n\n# shape of training and test dataset\nprint(X.shape)\nprint(test.shape)","c6997c4d":"# one hot encode target\n# =====================\n\n# shape and values of target\nprint(y.shape)\nprint(y[0])\n\n# convert Y_train to categorical by one-hot-encoding\ny_enc = to_categorical(y, num_classes = 10)\n\n# shape and values of target\nprint(y_enc.shape)\nprint(y_enc[0])","0e02abe6":"# train test split\n# ================\n\n# random seed\nrandom_seed = 2\n\n# train validation split\nX_train, X_val, y_train_enc, y_val_enc = train_test_split(X, y_enc, test_size=0.3)\n\n# shape\nfor i in [X_train, y_train_enc, X_val, y_val_enc]:\n    print(i.shape)","81b30cd6":"g = plt.imshow(X_train[0][:,:,0])\nprint(y_train_enc[0])","45be9641":"g = plt.imshow(X_train[9][:,:,0])\nprint(y_train_enc[9])","cbf39de1":"INPUT_SHAPE = (28,28,1)\nOUTPUT_SHAPE = 10\nBATCH_SIZE = 128\nEPOCHS = 10\nVERBOSE = 2","4e91d2ef":"model = Sequential()\n\nmodel.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=INPUT_SHAPE))\nmodel.add(MaxPool2D((2,2)))\n\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPool2D((2,2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(10, activation='softmax'))","4637d681":"model.compile(optimizer='adam', \n              loss='categorical_crossentropy', \n              metrics=['accuracy'])","d745dd5a":"model.summary()","d5540db8":"history = model.fit(X_train, y_train_enc,\n                    epochs=EPOCHS,\n                    batch_size=BATCH_SIZE,\n                    verbose=VERBOSE,\n                    validation_split=0.3)","59ec7774":"plt.figure(figsize=(14, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\n\nplt.savefig('.\/foo.png')\nplt.show()","685ba172":"# model loss and accuracy on validation set\nmodel.evaluate(X_val, y_val_enc, verbose=False)","9a2fa2a6":"# predicted values\ny_pred_enc = model.predict(X_val)\n\n# actual\ny_act = [np.argmax(i) for i in y_val_enc]\n\n# decoding predicted values\ny_pred = [np.argmax(i) for i in y_pred_enc]\n\nprint(y_pred_enc[0])\nprint(y_pred[0])","cb8a99d0":"print(classification_report(y_act, y_pred))","758c41b0":"fig, ax = plt.subplots(figsize=(7, 7))\nsns.heatmap(confusion_matrix(y_act, y_pred), annot=True, \n            cbar=False, fmt='1d', cmap='Blues', ax=ax)\nax.set_title('Confusion Matrix', loc='left', fontsize=16)\nax.set_xlabel('Predicted')\nax.set_ylabel('Actual')\nplt.show()","f0f5fc0e":"# predicted values\ny_pred_enc = model.predict(test)\n\n# decoding predicted values\ny_pred = [np.argmax(i) for i in y_pred_enc]\n\nprint(y_pred_enc[0])\nprint(y_pred[0])","cb2c929c":"# predicted targets of each images\n# (labels above the images are predicted labels)\nfig, ax = plt.subplots(figsize=(18, 12))\nfor ind, row in enumerate(test[:15]):\n    plt.subplot(3, 5, ind+1)\n    plt.title(y_pred[ind])\n    img = row.reshape(28, 28)\n    fig.suptitle('Predicted values', fontsize=24)\n    plt.axis('off')\n    plt.imshow(img, cmap='cividis')","48b698d2":"# X_train, X_val, y_train_enc, y_val_enc","6588d438":"# CNN","fba73be3":"### Label count","6435fa21":"### Compile model","e72c7629":"### Model parameters","4c9dc038":"# Libraries","0cec5fc2":"### Predicting on test","cd606eec":"# Preprocessing","acdaedd6":"### Define CNN Model","4a0c630d":"### Accurayc and loss","d29f86f0":"# Data","3980bfd9":"## About the Dataset\n> * MNIST (\"Modified National Institute of Standards and Technology\") is the de facto \u201chello world\u201d dataset of computer vision.   \n> * Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. \n> * As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n\n## Task\n> * To correctly identify digits from a dataset of tens of thousands of handwritten images in the test dataset","d391814e":"### Evaluating on validationa dataset","c2177ffe":"### Model fitting","f29299d8":"> Test images doesn't have labels  \n> We need to create a model to predict them","4556c4d2":"# EDA","add74426":"### Model summary","549bdb99":"## Plot images"}}