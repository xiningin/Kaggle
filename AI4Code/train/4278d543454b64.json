{"cell_type":{"90995d9b":"code","810e1588":"code","f3607b14":"code","98c308c3":"code","c0028dca":"code","415d8440":"code","9033fe39":"code","b32d8d3b":"code","36895ec5":"code","acae9f16":"code","f7bf93c8":"code","1cf8f44b":"code","e841057d":"markdown","e23f3ecc":"markdown","3ba9db55":"markdown","5e6d420c":"markdown","d557f0be":"markdown","137b2398":"markdown","16790eb9":"markdown","e8149602":"markdown","13e1e591":"markdown","e5bbe8d4":"markdown"},"source":{"90995d9b":"import numpy as np\nimport pandas as pd \nimport os\nimport cv2\nfrom matplotlib import pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers as L\nfrom tensorflow.keras.utils import to_categorical\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn import metrics\n\n%matplotlib inline","810e1588":"# \n# TPU\u306e\u521d\u671f\u5316\n# \ntry:\n#     TPU\u306e\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\u60c5\u5831\u3092\u7372\u5f97\u3002TPU\u304c\u5229\u7528\u3067\u304d\u306a\u3044\u74b0\u5883\u3067\u306f\u30a8\u30e9\u30fc\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n#     TPU\u5229\u7528\u53ef\u80fd\u306e\u78ba\u8a8d\n    print('Running on TPU:', tpu.master())\n# \u4e0a\u8a18\u3067\u30a8\u30e9\u30fc\uff08\u4f8b\u5916\uff09\u304c\u51fa\u305f\u5834\u5408\u306e\u51e6\u7406\nexcept ValueError:\n    tpu = None\n\n# TPU\u304c\u5229\u7528\u3067\u304d\u308b\u5834\u5408\uff08Accelerator TPU\uff09\nif tpu:\n#   \u30ea\u30e2\u30fc\u30c8\u30af\u30e9\u30b9\u30bf\u306b\u63a5\u7d9a\u3057\u3066TPU\u3092\u521d\u671f\u5316\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n#   \u30c7\u30fc\u30bf\u306e\u4e26\u5217\u51e6\u7406\u3092\u4f7f\u7528\u3057\u3066\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u3092\u5206\u6563\u3059\u308b\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n# TPU\u304c\u5229\u7528\u3067\u304d\u306a\u3044\u5834\u5408\uff08Accelerator None\uff09\nelse:\n    strategy = tf.distribute.get_strategy()\n\n# \u4e26\u5217\u51e6\u7406\u306e\u30ec\u30d9\u30eb\u306b\u95a2\u3059\u308b\u6c7a\u5b9a\u3092AUTO\u3067\u884c\u3046\nAUTO = tf.data.experimental.AUTOTUNE\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()\n\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\nIMG_SIZE = 768\n\nprint('Batch size:', BATCH_SIZE)","f3607b14":"train = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/test.csv')\nsub = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/sample_submission.csv')\n\nprint(train.head())\n\ntrain_path = train.image_id.apply(lambda x: f'{GCS_DS_PATH}\/images\/{x}.jpg').values\ntest_path = test.image_id.apply(lambda x: f'{GCS_DS_PATH}\/images\/{x}.jpg').values\ntrain_label = train.loc[:, 'healthy':].values","98c308c3":"class_weight = compute_class_weight('balanced', np.unique(np.argmax(train_label, axis=1)), np.argmax(train_label, axis=1))\nplt.bar(range(4), class_weight)","c0028dca":"# 2\u00d72\u3067\u8868\u793a\nfig, ax = plt.subplots(2, 2)\n# \u30b5\u30f3\u30d7\u30eb\u8aad\u307f\u8fbc\u307f\nimg = cv2.imread('\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/Train_0.jpg')\nimg1 = cv2.imread('\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/Train_1.jpg')\nimg2 = cv2.imread('\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/Train_2.jpg')\nimg3 = cv2.imread('\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/Train_3.jpg')\n# \u5834\u6240\u6307\u5b9a\u3057\u305f\u66f8\u304d\u51fa\u3057\nax[0, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nax[0, 1].imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\nax[1, 0].imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\nax[1, 1].imshow(cv2.cvtColor(img3, cv2.COLOR_BGR2RGB))","415d8440":"# \u30c7\u30fc\u30bf\u5909\u63db\uff08\u30c7\u30b3\u30fc\u30c9\uff09\u306e\u5b9a\u7fa9\ndef decode_image(filename, label=None, image_size=(IMG_SIZE, IMG_SIZE)):\n#     \u751f\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u307f\n    bits = tf.io.read_file(filename)\n#     \u753b\u50cf\u306e\u30c6\u30f3\u30bd\u30eb\u306b\u30c7\u30b3\u30fc\u30c9\n    image = tf.image.decode_jpeg(bits, channels=3)\n#     0-255\u306eRGB\u30920-1\u306b\u5909\u63db\u3059\u308b\uff08normalize\uff09\n    image = tf.cast(image, tf.float32) \/ 255.0\n#     \u753b\u50cf\u30b5\u30a4\u30ba\u30921365\u00d72048\u304b\u3089768\u00d7768\u306b\u3059\u308b\n    image = tf.image.resize(image, image_size)\n    \n#     image\u3092return\n    if label is None:\n        return image\n    else:\n        return image, label\n\n# \u30c7\u30fc\u30bf\u5909\u63db\uff08\u5897\u5e45\uff09\u306e\u5b9a\u7fa9\ndef data_augment(image, label=None):\n#     \u30e9\u30f3\u30c0\u30e0\u306b\u6c34\u5e73\u65b9\u5411\u306b\u53cd\u8ee2\n    image = tf.image.random_flip_left_right(image)\n#     \u30e9\u30f3\u30c0\u30e0\u306b\u5782\u76f4\u65b9\u5411\u306b\u53cd\u8ee2\n    image = tf.image.random_flip_up_down(image)\n    \n#     image\u3092return\n    if label is None:\n        return image\n    else:\n        return image, label","9033fe39":"# \u6559\u5e2b\u30c7\u30fc\u30bf\u3092\u30c7\u30b3\u30fc\u30c9\ntrain_dataset = (\n#     TFR\u5f62\u5f0f\u3067\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u66f8\u304d\u3059\u308b\n    tf.data.TFRecordDataset\n#     \u914d\u5217\u3092\u30b9\u30e9\u30a4\u30b9\u3057\u3066\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u69cb\u7bc9\u3059\u308b\n    .from_tensor_slices((train_path, train_label))\n#     \u30c7\u30fc\u30bf\u5909\u63db\uff08\u30c7\u30b3\u30fc\u30c9\uff09\u3092\u4e26\u5217\u5316\u3057\u3066\u884c\u3046\n    .map(decode_image, num_parallel_calls=AUTO)\n#     \u30c7\u30fc\u30bf\u5909\u63db\uff08\u5897\u5e45\uff09\u3092\u4e26\u5217\u5316\u3057\u3066\u884c\u3046\n    .map(data_augment, num_parallel_calls=AUTO)\n    .cache()\n    .repeat()\n    .shuffle(1024) #\u30e9\u30f3\u30c0\u30e0\u8981\u7d20\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\n# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u30c7\u30b3\u30fc\u30c9\ntest_dataset = (\n    tf.data.TFRecordDataset\n    .from_tensor_slices(test_path)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","b32d8d3b":"EPOCHS = 40\nLR_START = 0.0001\nLR_MAX = 0.00005 * strategy.num_replicas_in_sync\nLR_MIN = 0.0001\nLR_RAMPUP_EPOCHS = 10\nLR_SUSTAIN_EPOCHS = 4\nLR_EXP_DECAY = .8\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) \/ LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr\n\nlr = tf.keras.callbacks.LearningRateScheduler(lrfn)\n\ny = [lrfn(x) for x in range(EPOCHS)]\nplt.plot(y)","36895ec5":"# DenseNet121,DenseNet169,DenseNet201\u304c\u4f7f\u7528\u53ef\u80fd\nfrom tensorflow.keras.applications import DenseNet121\n\nwith strategy.scope():\n    dnn121 = DenseNet121(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n    model_dnn121 = Sequential()\n    model_dnn121.add(dnn121)\n    model_dnn121.add(L.GlobalAveragePooling2D())\n    model_dnn121.add(L.Dense(4, activation='softmax'))\n    model_dnn121.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    print(model_dnn121.summary())","acae9f16":"mc_dnn121 = tf.keras.callbacks.ModelCheckpoint('weights_dnn121.h5', monitor='loss', save_best_only=True, save_weights_only=True)\nhistory = model_dnn121.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_dnn121], steps_per_epoch=train_label.shape[0] \/\/ BATCH_SIZE)","f7bf93c8":"with strategy.scope():\n    model_dnn121.load_weights('weights_dnn121.h5')","1cf8f44b":"probs_dnn121 = model_dnn121.predict(test_dataset, verbose=1)\nsub_dnn121 = sub\nsub_dnn121.loc[:, 'healthy':] = probs_dnn121\nsub_dnn121.to_csv('submission_dnn121.csv', index=False)\nsub_dnn121.head()","e841057d":"# Import Libraries","e23f3ecc":"# Get class weights","3ba9db55":"# TPU setup","5e6d420c":"# Decode images","d557f0be":"# DenseNet","137b2398":"# Predict","16790eb9":"# Define the parameters","e8149602":"# Model","13e1e591":"# Get train and test data","e5bbe8d4":"# Lets see some images"}}