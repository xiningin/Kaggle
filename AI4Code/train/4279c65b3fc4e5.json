{"cell_type":{"d84477d9":"code","a871f4f4":"code","cde9cb6c":"code","d6d7ba16":"code","ff998f74":"code","fce7ffe1":"code","dd1c3cfc":"code","66519a0d":"code","a4d51a31":"code","0ac99fe4":"code","035e4784":"markdown","d7a1ae6c":"markdown","9625994a":"markdown","58e3a995":"markdown","1de98769":"markdown","e685b2ae":"markdown","ee59c315":"markdown","4b7edc44":"markdown"},"source":{"d84477d9":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\n#print(os.listdir(\"..\/input\"))\n\nfrom keras.datasets import mnist\nfrom keras.layers import Input, Dense, Reshape, Flatten\nfrom keras.layers import BatchNormalization, Activation\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam","a871f4f4":"class GAN():\n    def __init__(self):\n        #mnist input size\n        self.img_rows = 28 \n        self.img_cols = 28\n        self.channels = 1 # black and white\n        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n        \n        # size of Latent Variable (input to generator)\n        self.z_dim = 100\n\n        optimizer = Adam(0.0002, 0.5)\n\n        # discriminator model\n        self.discriminator = self.build_discriminator() # take mnist data shape as input, and output sigmoid - [0,1]\n        self.discriminator.compile(loss='binary_crossentropy',\n            optimizer=optimizer,\n            metrics=['accuracy'])\n\n        # Generator model (no need to compile, as we don't train generator by itself)\n        self.generator = self.build_generator()\n\n        # Combined model to use in training Generator\n        self.combined = self.build_combined1()\n        #self.combined = self.build_combined2()\n        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)","cde9cb6c":"    def build_generator(self):\n        # The Generator takes noise as input and generate images\n        noise_shape = (self.z_dim,)\n        \n        # Use Sequential for starting\n        model = Sequential()\n\n        # Add Dense Layer\n        model.add(Dense(256, input_shape=noise_shape))\n        model.add(LeakyReLU(alpha=0.2))\n        # Normalize (mean=0, std=1, momentum: moving average momentum)\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(512))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(1024))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n        model.add(Reshape(self.img_shape))\n        model.summary()\n        return model\n\n    def build_discriminator(self):\n        img_shape = (self.img_rows, self.img_cols, self.channels)\n        model = Sequential()\n\n        model.add(Flatten(input_shape=img_shape))\n        model.add(Dense(512))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dense(256))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dense(1, activation='sigmoid'))\n        model.summary()\n        return model","d6d7ba16":"    def build_combined1(self): #simpler to write\n        self.discriminator.trainable = False\n        model = Sequential([self.generator, self.discriminator]) # connect models by using a list of model names\n        return model\n\n    def build_combined2(self): #suitable for building more complex network structure in the future\n        z = Input(shape=(self.z_dim,)) #define latent variable\n        img = self.generator(z) #use it to generate image\n        self.discriminator.trainable = False\n        valid = self.discriminator(img) #sigmoid output [0-1]\n        model = Model(z, valid) # use Model method using the first input and the last output\n        model.summary()\n        return model","ff998f74":"x = np.linspace(0.01, 1, 100);\nplt.figure(0)\nplt.plot(x, np.log(x))\nplt.xlabel(\"D(x)\")\nplt.ylabel(\"log(D(x)\")\nplt.show()","fce7ffe1":"x = np.linspace(0, 0.99, 100);\nplt.figure(0)\nplt.plot(x, np.log(1-x))\nplt.xlabel(\"D(G(z))\")\nplt.ylabel(\"log(1-D(G(z)))\")\nplt.show()","dd1c3cfc":"    def train(self, epochs, batch_size=128, save_interval=50):\n        # load the dataset\n        (X_train, _), (_, _) = mnist.load_data()\n\n        # rescale to -1 - 1\n        X_train = (X_train.astype(np.float32) - 127.5) \/ 127.5\n        X_train = np.expand_dims(X_train, axis=3)\n\n        # use later to make half real - half fake set of images\n        half_batch = int(batch_size \/ 2)\n\n        num_batches = int(X_train.shape[0] \/ half_batch)\n        print('Number of batches:', num_batches)\n        \n        for epoch in range(epochs):\n\n            for iteration in range(num_batches):\n\n                # ---------------------\n                #  train Discriminator\n                # ---------------------\n\n                # Generate image for half of the training set to use\n                noise = np.random.normal(0, 1, (half_batch, self.z_dim))\n                gen_imgs = self.generator.predict(noise)\n\n                # Select a random batch of images (for the other half of the training set)\n                idx = np.random.randint(0, X_train.shape[0], half_batch)\n                imgs = X_train[idx]\n\n                # train discriminator \/ use real images and fake images separetely\n                #np.ones > ground truth for real images\n                d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n                #np.zeros > ground truth for fake images\n                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n                # Take average of both loss function\n                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n                # ---------------------\n                #  train Generator\n                # ---------------------\n\n                noise = np.random.normal(0, 1, (batch_size, self.z_dim))\n\n                # Labels for generated images (for training generator) are 1 \n                valid_y = np.array([1] * batch_size)\n\n                # train generator\n                g_loss = self.combined.train_on_batch(noise, valid_y)\n\n                # print progress\n                print (\"epoch:%d, iter:%d,  [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, iteration, d_loss[0], 100*d_loss[1], g_loss))","66519a0d":"class GAN():\n    def __init__(self): # Build basic structure of GANs in constructor\n        #mnist input size\n        self.img_rows = 28 \n        self.img_cols = 28\n        self.channels = 1 # black and white\n        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n        \n        # size of Latent Variable (input to generator)\n        self.z_dim = 100\n\n        optimizer = Adam(0.0002, 0.5)\n\n        # discriminator model\n        self.discriminator = self.build_discriminator() # take mnist data shape as input, and output sigmoid - [0,1]\n        self.discriminator.compile(loss='binary_crossentropy',\n            optimizer=optimizer,\n            metrics=['accuracy'])\n\n        # Generator model (no need to compile, as we don't train generator by itself)\n        self.generator = self.build_generator()\n\n        # Combined model to use in training generator\n        self.combined = self.build_combined1()\n        #self.combined = self.build_combined2()\n        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n\n    def build_generator(self):\n        # The Generator takes noise as input and generate images\n        noise_shape = (self.z_dim,)\n        \n        # Use Sequential for starting\n        model = Sequential()\n\n        # Add Dense Layer\n        model.add(Dense(256, input_shape=noise_shape))\n        model.add(LeakyReLU(alpha=0.2))\n        # Normalize (mean=0, std=1, momentum: moving average momentum)\n        # this doesn't affect much for this case, but BatchNorm can lead to efficient learning\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(512))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(1024))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n        model.add(Reshape(self.img_shape))\n        model.summary()\n        return model\n\n    def build_discriminator(self):\n        img_shape = (self.img_rows, self.img_cols, self.channels)\n        model = Sequential()\n\n        model.add(Flatten(input_shape=img_shape))\n        model.add(Dense(512))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dense(256))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dense(1, activation='sigmoid'))\n        model.summary()\n        return model\n    \n    def build_combined1(self): #simpler to write\n        self.discriminator.trainable = False\n        model = Sequential([self.generator, self.discriminator]) # connect models by using a list of model names\n        return model\n\n    def build_combined2(self): #suitable for building more complex network structure in the future\n        z = Input(shape=(self.z_dim,)) #define latent variable\n        img = self.generator(z) #use it to generate image\n        self.discriminator.trainable = False\n        valid = self.discriminator(img) #sigmoid output [0-1]\n        model = Model(z, valid) # use Model method using the first input and the last output\n        model.summary()\n        return model\n\n    def train(self, epochs, batch_size=128, save_interval=50):\n        # load the dataset\n        (X_train, _), (_, _) = mnist.load_data()\n\n        # rescale to -1 - 1\n        X_train = (X_train.astype(np.float32) - 127.5) \/ 127.5\n        X_train = np.expand_dims(X_train, axis=3)\n\n        # use later to make half real - half fake set of images\n        half_batch = int(batch_size \/ 2)\n\n        num_batches = int(X_train.shape[0] \/ half_batch)\n        print('Number of batches:', num_batches)\n        \n        for epoch in range(epochs):\n\n            for iteration in range(num_batches):\n\n                # ---------------------\n                #  train Discriminator\n                # ---------------------\n\n                # Generate image for half of the training set to use\n                noise = np.random.normal(0, 1, (half_batch, self.z_dim))\n                gen_imgs = self.generator.predict(noise)\n\n                # Select a random batch of images (for the other half of the training set)\n                idx = np.random.randint(0, X_train.shape[0], half_batch)\n                imgs = X_train[idx]\n\n                # train discriminator \/ use real images and fake images separetely\n                #np.ones > ground truth for real images\n                d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n                #np.zeros > ground truth for fake images\n                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n                # Take average of both loss function\n                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n                # ---------------------\n                #  train Generator\n                # ---------------------\n\n                noise = np.random.normal(0, 1, (batch_size, self.z_dim))\n\n                # Labels for generated images (for training generator) are 1 \n                valid_y = np.array([1] * batch_size)\n\n                # train generator\n                g_loss = self.combined.train_on_batch(noise, valid_y)\n\n                # print progress\n                print (\"epoch:%d, iter:%d,  [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, iteration, d_loss[0], 100*d_loss[1], g_loss))\n\n                # if at save interval > save generated image samples\n                if epoch % save_interval == 0:\n                    self.save_imgs(epoch)\n\n    def save_imgs(self, epoch):\n        # number of rows and columns for displaying generated images\n        r, c = 5, 5\n\n        noise = np.random.normal(0, 1, (r * c, self.z_dim))\n        gen_imgs = self.generator.predict(noise)\n\n        # Rescale images to 0 - 1\n        gen_imgs = 0.5 * gen_imgs + 0.5\n\n        fig, axs = plt.subplots(r, c)\n        cnt = 0\n        for i in range(r):\n            for j in range(c):\n                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n                axs[i,j].axis('off')\n                cnt += 1\n        fig.savefig(\"mnist_%d.png\" % epoch)\n        plt.close()","a4d51a31":"gan = GAN()","0ac99fe4":"gan.train(epochs=1, batch_size=1200, save_interval=1)","035e4784":"Having that in mind, let's write training method!","d7a1ae6c":"# Generated Image\nAfter 400 iterations\n![400](https:\/\/i.imgur.com\/4Js02jt.png)\n\nAfter 1000 iterations\n![1000](https:\/\/i.imgur.com\/iZa9jKx.png)\n\nAfter 5000 iterations\n![5000](https:\/\/i.imgur.com\/3EzEc0A.png)\n\nAfter 15000 iterations\n![15000](https:\/\/i.imgur.com\/WKeqIFK.png)\n\n# Conclusion\nCongratulations! Now you understand the basic concept and building blocks of GANs.\n\nBut there is still much more journey ahead of you. How can you improve this program? Maybe you can try different network structures or different loss functions?\n\nYou may notice white pixels in random places in generated images. This is because we used full connected layers. Simple MLP doesn't really take the relations between pixels into account. Maybe we can use a network that does consider them to generate better images.\n\nAlso you may notice that you cannot specify which digit to generate. How do we make our program to generate, say 2 or 7 specifically?\n\nIn the following tutorial, we will learn how to do those things! Stay tuned;)\n\n### References\n- https:\/\/arxiv.org\/pdf\/1406.2661.pdf Generative Adversarial Nets paper, Goodfellow et al, 2014\n- http:\/\/www.deeplearningbook.org\/ by Goodfellow, part3 20 > Deep Generative Models\n- https:\/\/www.youtube.com\/watch?v=9JpdAg6uMXs Introduction to GANs, NIPS 2016\n- https:\/\/github.com\/soumith\/ganhacks How to Train a GAN? Tips and tricks to make GANs work\n- https:\/\/github.com\/eriklindernoren\/Keras-GAN\/tree\/master\/gan Reference code that I used (and edit as I see fit) for this notebook, thanks!","9625994a":"Later in this notebook, I will introduce two ways of building Generator-Discriminator combined network for training Generator. (build_combined1 and build_combined2 methods)\n\nBefore that, let's write build_generator and build_discriminator methods.","58e3a995":"BatchNorm doesn't affect much in this case, but it can make learning more efficient in some cases.\n\nIn this code I use BatchNorm only in Generator, because I don't want to normalize mixture of real image and noisy fake image especially on early learning stage.","1de98769":"Then there are two ways of writing combined networks.\n\nbuild_combined1 uses Sequential method and simpler to write. You can connect models by just using a list of model names.\n\nOn the other hand, build_combined2 uses Model method using the first input and the last output.\n\nIt looks more complicated compared to build_combined1, but suitable for building more complex network structure in the future.\n\n## Training\nLet's move on to write training code.\n\nThe loss function introduced in GANs original paper https:\/\/arxiv.org\/abs\/1406.2661 is below.\n\n![loss func](https:\/\/i.imgur.com\/VvtT1Vu.jpg)\n\nG is for Generator, and D is for Discriminator.\n\nIn the right formula, the first term is used when using real image, and the second term is used when using fake image came from Generator.\n\n### Loss function for Discriminator\n\nD(x) represents the probability that x came from real image set. We train D to maximize the probability of assigning the correct label to both real images and fake images from Generator.\n\nThat means:\n\n- when using real image > training procedure is to maximize log(D(x)), thus to output D(x) = 1.\n- when using fake image > training procedure is to maximize log(1-D(G(z))), thus to output D(x) = 0.\n\n### Loss function for Generator\n\nThe training procedure for G is to maximize the probability of D making a mistake, thus to output D(G(z)) = 1.\n\nSee below","e685b2ae":"Here it goes!\n\nNow we implemented a complete set of GANs program.\n\nLet's combine those methods to complete GAN() class.","ee59c315":"Now we are all good to go executing the program.","4b7edc44":"# Introduction\nGANs are powerful tools, and this tutorial will help you start using them, as well as introduce you to some important concepts.\n\n## What will you learn?\n\nBy time you finish this tutorial, you will:\n\n- Understand basic concepts and building blocks of GANs\n  - e.g. Network Structure, input data, labels to use, and Cost Function\n- Build GANs model to generate hand-written digits\n\n## What do I need to know before getting started?\n\nThis tutorial will assume that you're familiar with some basic MLP\/deep learning concepts, along with basics of numpy and Keras. If you're brand new to deep learning, I recommend you work through Course 1 and Couse 2 of this series (https:\/\/www.deeplearning.ai\/deep-learning-specialization\/), which doesn't assume deep learning background, before getting started.\n\n# Basic Concept\n![GAN Concept](https:\/\/sthalles.github.io\/assets\/dcgan\/GANs.png)\nimage from https:\/\/sthalles.github.io\/intro-to-gans\/\n\nHere is the basic structure of GANs.\n\nGenerator receives input called Latent Variables. For mnist work, this is a set of random values with around 100 dimension. This is going to be a seed for generating image.\n\nDiscriminator receives an image as input, and try to classify if that image is real or genarated one. Output is a continuous value from 0 to 1, 0 representing a generated image, 1 representing a real image.\n\n## Training Discriminator\n![Discriminator](https:\/\/i.imgur.com\/7e8Ga74.png)\n\nTraining set will be a set of images and labels. If the image is real one, the label is going to be 1. Otherwise, the label is goint to be 0.\n\nIn programming code, we use noise as input for Generator, and use predict method to generate images.\n\nThen we are going to use that image as input for Discriminator.\n\nWhile you are training Discriminator, you are not touching Generator. We only use Generator to generate images here.\n\n## Training Generator\n![Generater](https:\/\/i.imgur.com\/2mNi2DN.png)\n\nAs the output of GANs is a value represents probability of the input image came from real image set, we are going to use Combined network of [Generator + Discriminator] in training Generator.\n\nHowever, when you trian Generator, you don't want to update weights in Discriminator. This can be done by setting [trainable = False].\n\nAs usual, input for Generator is a set of generated noise.\n\n### Labeling in training Generator\nTricky part of GANs is labeling in training Generator. Since the image we use here is obviously a fake one, the label should be 0.\n\nHowever, we label them 1 in training Generator. This is because the purpose of Generator is to deceive Discriminator.\n\nSo for Generator, loss function should be lower when the Discriminator classifies fake image as real.\n\nSince both training is binary classification task, we can use binary crossentropy for loss function.\n\n# Let's Get Started\n\n## Basic Network Structure\nFirst, we define GAN class and build a basic GANs structure in constructor."}}