{"cell_type":{"e61db898":"code","0a861e85":"code","1131412c":"code","78eeec8f":"code","2598a586":"code","04e9bc94":"code","efd859b4":"code","6eb3ef23":"code","20433937":"code","146bbcd2":"code","063e82e7":"code","4c184b59":"code","ba469f23":"code","808f9c25":"code","4fcc1dc6":"code","37920615":"code","1e8a7469":"code","62485a07":"code","2261a2ac":"code","0192eb33":"code","3f496d29":"code","822ce8c3":"code","d857e8e0":"code","38548c1d":"code","35478398":"code","d9da4a75":"code","207b0bdc":"code","c45a02ca":"code","3235871f":"code","9ecc02d6":"code","091f0a9b":"code","9a180ddd":"code","abcb5411":"code","f858ec53":"code","95b5fadc":"code","818c4274":"code","49a8e09f":"code","7f7da6fb":"code","e3d16f3b":"code","2c72d13c":"code","8027996d":"code","97ec0414":"code","5fea4cfb":"code","adcc29f8":"markdown","ea804c28":"markdown","f419d893":"markdown","d3d7e801":"markdown","fd08e621":"markdown","3541cf39":"markdown","07ce718e":"markdown","b3f43a26":"markdown","27449af6":"markdown","c35c4f32":"markdown","96b5def7":"markdown","65f5a1f9":"markdown","31ef7d45":"markdown","9400f6a1":"markdown","c63ad2e8":"markdown","2a94aef7":"markdown","8b30bb1b":"markdown","bd5e334d":"markdown","d0ee1f2b":"markdown","8e8650bb":"markdown","68fb1e8a":"markdown","9063537b":"markdown","9896565e":"markdown","6e67c055":"markdown","4c9dbcd7":"markdown","2a00b9c4":"markdown","b541aaa7":"markdown","696e339e":"markdown","ba08a2e8":"markdown","72a592ad":"markdown"},"source":{"e61db898":"import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","0a861e85":"import numpy as np\nimport pandas as pd \nimport imageio\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom PIL import Image, ImageOps\nimport scipy.ndimage as ndi\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, Activation, BatchNormalization, ReLU\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing import image\nfrom keras.utils import plot_model","1131412c":"dirname = '\/kaggle\/input'\ntrain_path = os.path.join(dirname, 'chest-xray-pneumonia\/chest_xray\/chest_xray\/train')\ntrain_nrml_pth = os.path.join(train_path, 'NORMAL')\ntrain_pnm_pth = os.path.join(train_path, 'PNEUMONIA')\ntest_path = os.path.join(dirname, 'chest-xray-pneumonia\/chest_xray\/chest_xray\/test')\ntest_nrml_pth = os.path.join(test_path, 'NORMAL')\ntest_pnm_pth = os.path.join(test_path, 'PNEUMONIA')\nval_path = os.path.join(dirname, 'chest-xray-pneumonia\/chest_xray\/chest_xray\/test')\nval_nrml_pth = os.path.join(val_path, 'NORMAL')\nval_pnm_pth = os.path.join(val_path, 'PNEUMONIA')","78eeec8f":"def plot_imgs(item_dir, num_imgs=25):\n    all_item_dirs = os.listdir(item_dir)\n    item_files = [os.path.join(item_dir, file) for file in all_item_dirs][:num_imgs]\n\n    plt.figure(figsize=(10, 10))\n    for idx, img_path in enumerate(item_files):\n        plt.subplot(5, 5, idx+1)\n\n        img = plt.imread(img_path)\n        plt.imshow(img)\n\n    plt.tight_layout()","2598a586":"plot_imgs(train_nrml_pth)","04e9bc94":"plot_imgs(train_pnm_pth)","efd859b4":"\ndef plot_img_hist(item_dir, num_img=6):\n  all_item_dirs = os.listdir(item_dir)\n  item_files = [os.path.join(item_dir, file) for file in all_item_dirs][:num_img]\n  \n  #plt.figure(figsize=(10, 10))\n  for idx, img_path in enumerate(item_files):\n    fig1 = plt.figure(idx,figsize=(10, 10))\n    fig1.add_subplot(2, 2, 1)\n    img = mpimg.imread(img_path, )\n    plt.imshow(img)\n    fig1.add_subplot(2, 2, 2)\n    plt.hist(img.ravel(),bins=256, fc='k', ec='k')\n  \n  plt.tight_layout()","6eb3ef23":"plot_img_hist(train_pnm_pth,2)","20433937":"def plot_img_hist_ndi(item_dir, num_img=6):\n  all_item_dirs = os.listdir(item_dir)\n  item_files = [os.path.join(item_dir, file) for file in all_item_dirs][:num_img]\n  \n  #plt.figure(figsize=(10, 10))\n  for idx, img_path in enumerate(item_files):\n    im = imageio.imread(img_path)\n    hist = ndi.histogram(im, min=0, max=255, bins=256)\n    cdf = hist.cumsum() \/ hist.sum()\n    \n    fig1 = plt.figure(idx,figsize=(10, 10))\n    fig1.add_subplot(2, 3, 1)\n    img = mpimg.imread(img_path, )\n    plt.title(\"No. {}\".format(idx))\n    plt.imshow(img)\n    fig1.add_subplot(2, 3, 2)\n    plt.title(\"Histogram\")\n    plt.plot(hist)\n    fig1.add_subplot(2, 3, 3)\n    plt.title(\"CDF\")\n    plt.plot(cdf)\n\n  plt.tight_layout()","146bbcd2":"plot_img_hist_ndi(train_pnm_pth,2)","063e82e7":"dirname_work = '\/kaggle'\ndir_chest_xray = os.path.join('\/kaggle', 'chest_xray')\nos.mkdir('\/kaggle\/chest_xray\/')\nos.mkdir('\/kaggle\/chest_xray\/train')\nos.mkdir('\/kaggle\/chest_xray\/train\/NORMAL')\nos.mkdir('\/kaggle\/chest_xray\/train\/PNEUMONIA')\ntrain_path_work = os.path.join(dir_chest_xray, 'train')\ntrain_nrml_pth_work = os.path.join(train_path_work, 'NORMAL')\ntrain_pnm_pth_work = os.path.join(train_path_work, 'PNEUMONIA')\n\n\nos.mkdir('\/kaggle\/chest_xray\/test')\nos.mkdir('\/kaggle\/chest_xray\/test\/NORMAL')\nos.mkdir('\/kaggle\/chest_xray\/test\/PNEUMONIA')\ntest_path_work = os.path.join(dir_chest_xray, 'test')\ntest_nrml_pth_work = os.path.join(test_path_work, 'NORMAL')\ntest_pnm_pth_work = os.path.join(test_path_work, 'PNEUMONIA')\n\n\n# os.mkdir('\/kaggle\/chest_xray\/val')\n# os.mkdir('\/kaggle\/chest_xray\/val\/NORMAL')\n# os.mkdir('\/kaggle\/chest_xray\/val\/PNEUMONIA')\n# val_path = os.path.join(dirname, '\/chest_xray\/val')\n# val_nrml_pth = os.path.join(val_path, 'NORMAL')\n# val_pnm_pth = os.path.join(val_path, 'PNEUMONIA')\n","4c184b59":"def image_resizing(path_from, path_to, height=500, width=500):\n    size = height, width\n    i=1\n    files = os.listdir(path_from)\n    for file in files: \n        try:\n            file_dir = os.path.join(path_from, file)\n            file_dir_save = os.path.join(path_to, file)\n            img = Image.open(file_dir)\n            img = img.resize(size, Image.ANTIALIAS)\n            img = img.convert(\"RGB\")\n            img.save(file_dir_save) \n            i=i+1\n        except:\n            continue","ba469f23":"image_resizing(train_nrml_pth, train_nrml_pth_work, 300, 300)","808f9c25":"image_resizing(train_pnm_pth, train_pnm_pth_work, 300, 300)","4fcc1dc6":"image_resizing(test_nrml_pth, test_nrml_pth_work, 300, 300)\nimage_resizing(test_pnm_pth, test_pnm_pth_work, 300, 300)","37920615":"plot_imgs(train_nrml_pth_work)","1e8a7469":"plot_imgs(train_pnm_pth_work)","62485a07":"def  hist_equal(path_from, path_to):\n    i=1\n    files = os.listdir(path_from)\n    for file in files: \n        try:\n            file_dir = os.path.join(path_from, file)\n            file_dir_save = os.path.join(path_to, file)\n            img = Image.open(file_dir)\n            img = ImageOps.equalize(img)\n            #img = img.convert(\"RGB\") #konwersja z RGBA do RGB, usuniecie kana\u0142u alfa zeby zapisa\u0107 do jpg\n            img.save(file_dir_save) \n            i=i+1\n        except:\n            continue","2261a2ac":"hist_equal(train_pnm_pth_work, train_pnm_pth_work)\nhist_equal(train_nrml_pth_work, train_nrml_pth_work)\n\nhist_equal(test_pnm_pth_work, test_pnm_pth_work)\nhist_equal(test_nrml_pth_work, test_nrml_pth_work)","0192eb33":"plot_img_hist(train_pnm_pth_work, 2)","3f496d29":"plot_img_hist_ndi(train_pnm_pth_work, 2)","822ce8c3":"def plot_hist_comparison(item_dir_before,item_dir_after, num_img=1):\n    all_item_dirs = os.listdir(item_dir_before)\n    item_files_before = [os.path.join(item_dir_before, file) for file in all_item_dirs][:num_img]\n    item_files_after = [os.path.join(item_dir_after, file) for file in all_item_dirs][:num_img]\n  \n  #plt.figure(figsize=(10, 10))\n    for idx, img_path in enumerate(item_files_before):\n        im_b = imageio.imread(img_path)\n        hist_b = ndi.histogram(im_b, min=0, max=255, bins=256)\n        cdf_b = hist_b.cumsum() \/ hist_b.sum()\n        \n        img_path_a = item_files_after[idx]\n        im_a = imageio.imread(img_path_a)\n        hist_a = ndi.histogram(im_a, min=0, max=255, bins=256)\n        cdf_a = hist_a.cumsum() \/ hist_a.sum()\n\n        fig1 = plt.figure(idx,figsize=(10, 10))\n        fig1.add_subplot(2, 4, 1)\n        img_b = mpimg.imread(img_path, )\n        plt.title(\"Before. {}\".format(idx))\n        plt.imshow(img_b, cmap='gray')\n        fig1.add_subplot(2, 4, 3)\n        plt.title(\"Histogram before\")\n        plt.plot(hist_b)\n        fig1.add_subplot(2, 4, 4)\n        plt.title(\"CDF before\")\n        plt.plot(cdf_b)\n        \n        fig2 = plt.figure(idx,figsize=(10, 10))\n        fig2.add_subplot(2, 4, 2)\n        img_a = mpimg.imread(img_path_a, )\n        plt.title(\"Before. {}\".format(idx))\n        plt.imshow(img_a)\n        fig2.add_subplot(2, 4, 3)\n        plt.title(\"Histogram before\")\n        plt.plot(hist_a)\n        fig1.add_subplot(2, 4, 4)\n        plt.title(\"CDF before\")\n        plt.plot(cdf_a)\n\n    plt.tight_layout()","d857e8e0":"plot_hist_comparison(train_nrml_pth, train_nrml_pth_work,2);","38548c1d":"img_size_h = 300\nimg_size_w = 300\n\ninput_shape = (img_size_h, img_size_w, 1) ","35478398":"model = Sequential([\n    Conv2D(32, (3,3), input_shape=input_shape),\n    MaxPool2D((2, 2)),\n    \n    Conv2D(32, (3,3)),\n    MaxPool2D((2, 2)),\n    \n    Conv2D(64, (3,3)),\n    MaxPool2D((2, 2)),\n    \n    Conv2D(64, (3,3)),\n    MaxPool2D((2, 2)),\n    \n    Flatten(),\n    \n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')\n    \n    \n])\n","d9da4a75":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","207b0bdc":"plot_model(model) #you can save picture with addin option to_file='model.png'","c45a02ca":"train_datagen = ImageDataGenerator(\n    rescale=1.\/255,    \n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=45,\n    width_shift_range=0.5,\n    height_shift_range=0.5,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\nval_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=45,\n    width_shift_range=0.5,\n    height_shift_range=0.5,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n","3235871f":"batch_size = 32\ntrain_generator = train_datagen.flow_from_directory(\n    train_path_work,\n    target_size=(img_size_h, img_size_w),\n    color_mode='grayscale', #we use grayscale images I think\n    batch_size=batch_size,\n    class_mode='binary',\n    shuffle=True, #we shuffle our images for better performance\n    seed=8)\n\nvalidation_generator = val_datagen.flow_from_directory(\n    test_path_work,\n    target_size=(img_size_h, img_size_w),\n    color_mode='grayscale',\n    batch_size=batch_size,\n    class_mode='binary',\n    shuffle=True,\n    seed=8)","9ecc02d6":"#we don't need it right now\n# training_examples = 5216\n# validation_examples = 624","091f0a9b":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.0001) #0.00001\ncallback = [learning_rate_reduction]","9a180ddd":"history = model.fit_generator(\n    train_generator,\n    epochs=20,\n    validation_data=validation_generator,\n    callbacks = callback\n    )","abcb5411":"# Plot training & validation accuracy values\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","f858ec53":"img_test_path = os.path.join(test_nrml_pth, 'NORMAL2-IM-0337-0001.jpeg')\nimg_train_path_ill = os.path.join(train_pnm_pth, 'person1787_bacteria_4634.jpeg')\nimg_p = image.load_img(img_test_path, target_size=(img_size_h, img_size_w), color_mode='grayscale')\nimg_arr_p = np.array(img_p)\nimg_arr_p = np.expand_dims(img_arr_p, axis=0)\nimg_arr_p = np.expand_dims(img_arr_p, axis=3)\nimages_p = np.vstack([img_arr_p])","95b5fadc":"def predict_illness(image_path):\n    imge = plt.imread(image_path)\n    plt.imshow(imge)\n\n    img = image.load_img(image_path, target_size=(img_size_h, img_size_w), color_mode='grayscale')\n    x = image.img_to_array(img) \n    x = np.expand_dims(x, axis=0)\n    images = np.vstack([x])\n\n    classes = model.predict_classes(images, batch_size=10)\n    if classes[0][0] == 0:\n        print(\"They got healthy!\")\n    else:\n        print(\"They got pneumonia!\")\n","818c4274":"predict_illness(img_train_path_ill)","49a8e09f":"predict_illness(img_test_path)","7f7da6fb":"from keras.models import Model\nlayer_outputs = [layer.output for layer in model.layers[:len(model.layers)]]","e3d16f3b":"activation_model = Model(inputs=model.input, outputs=layer_outputs)","2c72d13c":"activations = activation_model.predict(images_p)\n\nfirst_layer_activation = activations[0]\nplt.matshow(first_layer_activation[0, :, :, 4], cmap='viridis')","8027996d":"model.layers[:-1]# Droping The Last Dense Layer","97ec0414":"layer_names = []\nfor layer in model.layers[:-1]:\n    layer_names.append(layer.name) \nimages_per_row = 16\nzipped_layers = zip(layer_names, activations)\nfor layer_name, layer_activation in zipped_layers: #this loop     \n    if layer_name.startswith('conv'):\n        n_features = layer_activation.shape[-1]\n        size = layer_activation.shape[1]\n        n_cols = n_features \/\/ images_per_row\n        display_grid = np.zeros((size * n_cols, images_per_row * size))\n        for col in range(n_cols):\n            for row in range(images_per_row):\n                channel_image = layer_activation[0,:, :, col * images_per_row + row]\n                channel_image -= channel_image.mean()\n                channel_image \/= channel_image.std()\n                channel_image *= 64\n                channel_image += 128\n                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n                display_grid[col * size : (col + 1) * size,\n                             row * size : (row + 1) * size] = channel_image\n        scale = 1. \/ size\n        plt.figure(figsize=(scale * display_grid.shape[1],\n                            scale * display_grid.shape[0]))\n        plt.title(layer_name)\n        plt.grid(False)\n        plt.imshow(display_grid, aspect='auto', cmap='viridis')","5fea4cfb":"layer_names = []\nfor layer in model.layers[:-1]:\n    layer_names.append(layer.name) \nimages_per_row = 16\nfor layer_name, layer_activation in zip(layer_names, activations):\n    if layer_name.startswith('max'):\n        n_features = layer_activation.shape[-1]\n        size = layer_activation.shape[1]\n        n_cols = n_features \/\/ images_per_row\n        display_grid = np.zeros((size * n_cols, images_per_row * size))\n        for col in range(n_cols):\n            for row in range(images_per_row):\n                channel_image = layer_activation[0,:, :, col * images_per_row + row]\n                channel_image -= channel_image.mean()\n                channel_image \/= channel_image.std()\n                channel_image *= 64\n                channel_image += 128\n                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n                display_grid[col * size : (col + 1) * size,\n                             row * size : (row + 1) * size] = channel_image\n        scale = 1. \/ size\n        plt.figure(figsize=(scale * display_grid.shape[1],\n                            scale * display_grid.shape[0]))\n        plt.title(layer_name)\n        plt.grid(False)\n        plt.imshow(display_grid, aspect='auto', cmap='viridis')","adcc29f8":"Some photos of healthy people.","ea804c28":"First I needed to create paths to folders in `\/kaggle\/input` where our images are stored. \nNotice that all folders and files in this directory are 'read-only' so I can't modify them or save them here but we deal with this problem later.","f419d893":"Here you can see how this network performed. ","d3d7e801":"# Plots and predictions","fd08e621":"I created variables with path to every folder using `os.path.join()` in my opinion it is really nice way to create and store paths.","3541cf39":"Then I found that I can also do it with scipy and I found out how to calculate Cumulative Distribution Function. \nI found out about `scipy.ndimage` on Data Camp Image Processing course. It is really nice module to use with images.\nHere you can find out for yourself: https:\/\/docs.scipy.org\/doc\/scipy\/reference\/ndimage.html. ","07ce718e":"After some tries and seeing no progress in learning of my net I decided to try and manually resize all images into specific dimensions and also equalize histograms hoping it will improve performance of my network and it will finally start to learn something. \nSpoiler...\n.\n.\n.\nIt didn't help. :( \nBut we can use this code anyway. ;)","b3f43a26":"# Histogram equalization","27449af6":"Now I prepared a simple model of Convolutional Neural Network. I tried a lot of different models and still didn't find the best one for those images. ","c35c4f32":"Now I can see what is hidden in these folders. ","96b5def7":"# Model","65f5a1f9":"# Activation layers","31ef7d45":"# Histograms and resizing","9400f6a1":"# Image preprocessing","c63ad2e8":"Firstly I decided to see some histograms using matplotlib. ","2a94aef7":"Then photos of sick patients.","8b30bb1b":"# Plotted images","bd5e334d":"Then it was only matter of finding suitable function in PIL. ;) Try\/except is used because there is one file which is not an image and therefore it can't be resized. :P","d0ee1f2b":"After equalizing all images we can compare some of them with those before the process. ","8e8650bb":"# Image resizing","68fb1e8a":"Visualisation of activation layers are made with code based on one you can find in Francois Chollet's book.","9063537b":"Model got from:\nMery, Domingo, and Carlos Arteta. \"Automatic defect recognition in x-ray testing using computer vision.\" 2017 IEEE winter conference on applications of computer vision (WACV). IEEE, 2017.","9896565e":"# Histograms with matplotlib","6e67c055":"Then I tried to resize our images. As I mentioned before I was a little bit tricky because I had to create new folders. I didn't get to create new folder in `\/kaggle\/working`. There were some errors, maybe caused by my mistakes. I'm not sure. Finally, I managed to use totally new folder simply created on `\/kaggle`.","4c9dbcd7":"# Histograms with scipy + cumulative distribution function","2a00b9c4":"# Training","b541aaa7":"And now it is time for histogram equalization. \nI thought about used this code: https:\/\/github.com\/torywalker\/histogram-equalizer\/blob\/master\/HistogramEqualization.ipynb\nfrom this article https:\/\/hackernoon.com\/histogram-equalization-in-python-from-scratch-ebb9c8aa3f23 but eventually I used histogram equalization from PIL: `PIL.ImageOps.equalize(image)`.\n\n\n","696e339e":"With this lots of images I had to use image generator from Keras to feed them into my model.","ba08a2e8":"# Intro\nHello! I need to learn something about image processing and Convolutional Neural Networks so I decided to do a little project. \nI chose this dataset to try out some code and some tricks to see if I can create a CNN for classification purpose. \nLet's learn something together. \n\n(btw this is one of my first kernels, I hope you enjoy it ;) )","72a592ad":"Now I need to prepare two images to see if network works."}}