{"cell_type":{"6d959465":"code","7eb04f2f":"code","f98cd13c":"code","c0445a1a":"code","883d9613":"code","d7e9ec71":"code","78c1073e":"code","6194db13":"code","843f52b7":"code","cd04e2ca":"code","f4f54f76":"code","85d7962a":"code","dff1012d":"code","3ed6437b":"code","3a8e47a3":"code","fdd688d8":"code","83b1c521":"code","89d45d5c":"code","4a146a58":"code","e757c4dd":"code","4c0e8a7e":"code","5275c130":"code","b3554a9e":"code","549600bc":"code","32dc9802":"code","ea580556":"code","c7810645":"code","d5379f5e":"code","c0a1a4a1":"code","7bf349d1":"code","f4b23157":"code","44813931":"code","5e889d1b":"code","b69003c5":"code","051b1365":"code","292d4331":"code","f909b060":"code","aff5f223":"code","cc60cb03":"code","90106fa9":"code","518283cd":"code","1bd43a5d":"code","e55108b8":"code","77a3c442":"code","9a713a50":"code","b9011c59":"code","d8380c96":"code","fb3a5d5a":"code","a994a7a6":"code","f4514299":"code","7046f210":"code","2ba1b19f":"code","52c54e41":"code","da56509e":"code","01d21c1d":"code","37d167f6":"code","5b31970b":"code","d64388e0":"code","facb9c41":"code","f417e6df":"code","de01457a":"code","6cfc6486":"code","14bf2908":"code","42192ac4":"code","a3d9f31b":"code","3080f682":"code","e5f49f40":"markdown","1ad3a281":"markdown","ebed4678":"markdown","ba5afad8":"markdown","f2e02e4a":"markdown","1bc90880":"markdown","d8195487":"markdown","6434751c":"markdown","292dac6d":"markdown","c5209c74":"markdown","98f0ece1":"markdown","f1169b4c":"markdown","79e81002":"markdown","1c0eb92e":"markdown","1a1be424":"markdown","23f6cd77":"markdown","f9b39941":"markdown","9d67fb33":"markdown","6ee65a95":"markdown","1cf4cabf":"markdown","f720f332":"markdown","0d858360":"markdown","54b20052":"markdown","c8930002":"markdown","f4331b04":"markdown","be5a130f":"markdown","ce090e4b":"markdown","58dfa374":"markdown","c5609aa2":"markdown","3e216bf6":"markdown","abfa1387":"markdown","fad0cd25":"markdown","819243cd":"markdown","c1df7bd5":"markdown"},"source":{"6d959465":"import numpy as np # linear algebra\nimport pandas as pd # data processing\nimport time\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.metrics import confusion_matrix\nfrom subprocess import check_output\nfrom sklearn import tree\nfrom IPython.display import Image as PImage\nfrom subprocess import check_call\nfrom PIL import Image, ImageDraw, ImageFont\nimport re\nimport matplotlib.pyplot as plt","7eb04f2f":"#read dataset\ndata = pd.read_csv('..\/input\/mushrooms.csv')\n   # chose path where .data file present","f98cd13c":"data.head()  #to find first 5 values","c0445a1a":"data.columns ","883d9613":"data.info()","d7e9ec71":"data.describe()","78c1073e":"data['stalk-root'].value_counts(dropna=False)","6194db13":"#data[\"stalk-root\"].replace([\"?\"], [\"b\"], inplace= True)   # use b(it is mode) ","843f52b7":"from sklearn.preprocessing import LabelEncoder\n\nlabelencoder=LabelEncoder()\nfor column in data.columns:\n    data[column] = labelencoder.fit_transform(data[column])","cd04e2ca":"data['stalk-root'].value_counts(dropna=False)","f4f54f76":"data['stalk-root'].describe()","85d7962a":"data[\"stalk-root\"] = data[\"stalk-root\"].astype(object)","dff1012d":"#data[\"stalk-root\"][::].replace(0, 1.109565) \n#1.109565 = mean ","3ed6437b":"data[\"stalk-root\"] = data[\"stalk-root\"].astype(int)","3a8e47a3":"import seaborn as sns\nplt.figure(figsize=(16,10))\nsns.heatmap(data.corr(), annot=True);","fdd688d8":"data = data.drop('veil-type', axis=1)\n","83b1c521":"data=data.drop([\"stalk-root\"],axis=1)","89d45d5c":"data.head()","4a146a58":"data.info()","e757c4dd":"X = data.drop(['class'], axis=1)  #remove target from train dataset\ny = data['class'] # test dataset with target ","4c0e8a7e":" # divide dataset into 50% train, and other 50% test.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)","5275c130":"clf1 = DecisionTreeClassifier(criterion = \"gini\",                # model design \n            random_state = 100,max_depth=2, min_samples_leaf=5, ) \n# split dataset into depth 2(0,1,2)\n# stop dataset when leaf is 5 . ","b3554a9e":"clf1 = clf1.fit(X_train, y_train)  #training the model ","549600bc":"y_pred = clf1.predict(X_test)  # prediction on test dataset ","32dc9802":"print('accuracy of train dataset is',clf1.score(X_train, y_train))","ea580556":"print('accuracy of test dataset is',clf1.score(X_test, y_test))","c7810645":"from sklearn.metrics import classification_report\nprint(\"Decision tree Classification report\", classification_report(y_test, y_pred))","d5379f5e":"confusion_matrix(y_test, y_pred)","c0a1a4a1":"cfm=confusion_matrix(y_test, y_pred)\nsns.heatmap(cfm, annot=True, linewidth=5, cbar=None)\nplt.title('Decision Tree Classifier confusion matrix')\nplt.ylabel('True label')\nplt.xlabel('predicted label')","7bf349d1":"import graphviz\nimport os\nos.environ[\"PATH\"] += os.pathsep + 'C:\/Program Files (x86)\/Graphviz2.38\/bin'","f4b23157":"from sklearn.tree import DecisionTreeClassifier, export_graphviz\nimport graphviz\ndot_data = export_graphviz(clf1, out_file='tree1.dot',\n                          feature_names=X.columns,\n                          filled=True, rounded = True, \n                          special_characters= True,\n             class_names=['0','1']  )\ngraph = graphviz.Source(dot_data)\n\n","44813931":"os.system('dot -Tpng tree1.dot -o tree1.png')","5e889d1b":"from IPython.display import Image\nImage(filename=\"tree1.png\", height=1000, width=1000)","b69003c5":"clf2 = DecisionTreeClassifier(criterion = \"gini\", \n            random_state = 100,max_depth=5, min_samples_leaf=15, ) \nclf2 = clf2.fit(X_train, y_train)   \n# split dataset into depth 5\n# stop dataset when leaf is 15. ","051b1365":"y_pred = clf2.predict(X_test)","292d4331":"print('accuracy of train dataset is',clf2.score(X_train, y_train))","f909b060":"print('accuracy of test dataset is',clf2.score(X_test, y_test))","aff5f223":"from sklearn.metrics import classification_report\nprint(\"Decision tree Classification report\", classification_report(y_test, y_pred))","cc60cb03":"confusion_matrix(y_test, y_pred)","90106fa9":"cfm=confusion_matrix(y_test, y_pred)\nsns.heatmap(cfm, annot=True, linewidth=5, cbar=None)\nplt.title('Decision Tree Classifier confusion matrix')\nplt.ylabel('True label')\nplt.xlabel('predicted label')","518283cd":"import graphviz\nimport os\nos.environ[\"PATH\"] += os.pathsep + 'C:\/Program Files (x86)\/Graphviz2.38\/bin'","1bd43a5d":"from sklearn.tree import DecisionTreeClassifier, export_graphviz\nimport graphviz\ndot_data = export_graphviz(clf2, out_file='tree2.dot',\n                          feature_names=X.columns,\n                          filled=True, rounded = True, \n                          special_characters= True,\n             class_names=['0','1']  )\ngraph = graphviz.Source(dot_data)\n\n","e55108b8":"os.system('dot -Tpng tree2.dot -o tree2.png')","77a3c442":"from IPython.display import Image\nImage(filename=\"tree2.png\", height=1000, width=1000)","9a713a50":"clf3 = DecisionTreeClassifier( \n            criterion = \"entropy\", random_state = 100, \n            max_depth = 3, min_samples_leaf = 10) \nclf3 = clf3.fit(X_train, y_train)\n# split dataset into depth 3(0,1,2,3)\n# stop dataset when leaf is 10 . ","b9011c59":"y_pred = clf3.predict(X_test)","d8380c96":"print('accuracy of train dataset is',clf3.score(X_train, y_train))","fb3a5d5a":"print('accuracy of test dataset is',clf3.score(X_test, y_test))","a994a7a6":"print(\"Decision tree Classification report\", classification_report(y_test, y_pred))","f4514299":"confusion_matrix(y_test, y_pred)","7046f210":"cfm=confusion_matrix(y_test, y_pred)\nsns.heatmap(cfm, annot=True, linewidth=5, cbar=None)\nplt.title('Decision Tree Classifier confusion matrix')\nplt.ylabel('True label')\nplt.xlabel('predicted label')","2ba1b19f":"import graphviz\nimport os\nos.environ[\"PATH\"] += os.pathsep + 'C:\/Program Files (x86)\/Graphviz2.38\/bin'","52c54e41":"from sklearn.tree import DecisionTreeClassifier, export_graphviz\nimport graphviz\ndot_data = export_graphviz(clf3, out_file='tree3.dot',\n                          feature_names=X.columns,\n                          filled=True, rounded = True, \n                          special_characters= True,\n             class_names=['0','1']  )\ngraph = graphviz.Source(dot_data)\n\n","da56509e":"os.system('dot -Tpng tree3.dot -o tree3.png')","01d21c1d":"from IPython.display import Image\nImage(filename=\"tree3.png\", height=1000, width=1000)","37d167f6":"clf4 = DecisionTreeClassifier( \n            criterion = \"entropy\", random_state = 100, \n            max_depth = 10, min_samples_leaf = 20) \nclf4 = clf4.fit(X_train, y_train)\n# split dataset into depth 3(0,1,2,3)\n# stop dataset when leaf is 10 . ","5b31970b":"y_pred = clf4.predict(X_test)","d64388e0":"print('accuracy of train dataset is',clf4.score(X_train, y_train))","facb9c41":"print('accuracy of test dataset is',clf4.score(X_test, y_test))","f417e6df":"print(\"Decision tree Classification report\", classification_report(y_test, y_pred))","de01457a":"confusion_matrix(y_test, y_pred)","6cfc6486":"cfm=confusion_matrix(y_test, y_pred)\nsns.heatmap(cfm, annot=True, linewidth=5, cbar=None)\nplt.title('Decision Tree Classifier confusion matrix')\nplt.ylabel('True label')\nplt.xlabel('predicted label')","14bf2908":"import graphviz\nimport os\nos.environ[\"PATH\"] += os.pathsep + 'C:\/Program Files (x86)\/Graphviz2.38\/bin'","42192ac4":"from sklearn.tree import DecisionTreeClassifier, export_graphviz\nimport graphviz\ndot_data = export_graphviz(clf4, out_file='tree4.dot',\n                          feature_names=X.columns,\n                          filled=True, rounded = True, \n                          special_characters= True,\n             class_names=['0','1']  )\ngraph = graphviz.Source(dot_data)\n\n","a3d9f31b":"os.system('dot -Tpng tree4.dot -o tree4.png')","3080f682":"from IPython.display import Image\nImage(filename=\"tree4.png\", height=1000, width=1000)","e5f49f40":"2048  are classify in class 0 , 1656  classify in class 1 and 358 items does not classify on any class. ","1ad3a281":"# Feature selection","ebed4678":" Recall score of class 0 is 0.97, and class1 is 0.85","ba5afad8":" precision score of class 0 is 0.97, and class 1 is 0.94","f2e02e4a":"now we can see that 'stalk-root' has 2480 missing value.\n    ","1bc90880":" Decision Tree classifier accuracy is 100%, this is the problem of overfitting-->\n    \n this problem salved by K-Fold.    ","d8195487":" in class 0 for 'edible' and 1 for 'poisonous'.","6434751c":"# iii)The entropy impurity: ","292dac6d":"# Data Preprocessing: ","c5209c74":"1983  are classify in class 0 , 1896  classify in class 1 and 183 items does not classify on any class. ","98f0ece1":"# iv)The entropy impurity","f1169b4c":" precision score of class 0 is 0.98, and class 1 is 0.96","79e81002":"in class e for 'edible', and p for 'poisonous'.","1c0eb92e":"we use **BINARY SPLITS**.","1a1be424":"dataset does not included any object, now we are ready to build our model.","23f6cd77":" recall score of class 0 is 0.96 and class 1 is 0.98","f9b39941":"# ii)The GINI Impurity:","9d67fb33":" precision score of class 0 is 0.87, and class 1 is 0.96","6ee65a95":"2111  are classify in class 0 , 1949  classify in class 1 and only 2  items does not classify on any class. ","1cf4cabf":"# strategy 1):","f720f332":"f1 score of class 0 and class 1 is 0.97","0d858360":"2034  are classify in class 0 , 1913  classify in class 1 and 115 items does not classify on any class. ","54b20052":"# Strategy 3)","c8930002":"F1-score score of class 0 is 0.96, and class 1 is 0.95","f4331b04":"# Import libraries","be5a130f":" f1- score of class 0  is 0.92 and class1 is 0.90. ","ce090e4b":"# How to handle this missing value?","58dfa374":" recall score of class 0 is 0.94, and class 1 is 0.97","c5609aa2":"by observing heatmap, we can see that veil-type is not contributing to dataset.\n","3e216bf6":"# i )The Gini impurity","abfa1387":"# Strategy 2):","fad0cd25":"# Decision Tree classifier","819243cd":"MISSING ATTRIBUTE: In the dataset, there is an attribute with missing values. Its name is stalk-root. The missing value is represented by \"?\". \n","c1df7bd5":"Precision, recall and f1 score is 1.00 which is 100%"}}