{"cell_type":{"b7237948":"code","131ee525":"code","4ec00528":"code","3266a6b8":"code","57973a04":"code","af9360f1":"code","d7078a0d":"markdown","9f024b2d":"markdown"},"source":{"b7237948":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","131ee525":"data=pd.read_csv(\"..\/input\/musteriler.csv\") #import data\ndata.head()","4ec00528":"X=data.iloc[:,3:].values","3266a6b8":"from sklearn.cluster import KMeans\nkmeans= KMeans(n_clusters=3, init=\"k-means++\")\nkmeans.fit(X)\n\nprint(kmeans.cluster_centers_)\nsonuclar=[]\nfor i in range(1,11):\n    kmeans= KMeans(n_clusters=i, init= \"k-means++\", random_state=42)\n    kmeans.fit(X)\n    sonuclar.append(kmeans.inertia_) #give us WSCC values\n\nplt.plot(range(1,11),sonuclar) #draw and find elbow point\nplt.show()\n\nkmeans= KMeans(n_clusters=4, init= \"k-means++\", random_state=42)\nY_tahmin=kmeans.fit_predict(X)\nprint(Y_tahmin)\nplt.scatter(X[Y_tahmin==0,0], X[Y_tahmin==0,1], s=100, c=\"red\")\nplt.scatter(X[Y_tahmin==1,0], X[Y_tahmin==1,1], s=100, c=\"blue\")\nplt.scatter(X[Y_tahmin==2,0], X[Y_tahmin==2,1], s=100, c=\"green\")\nplt.scatter(X[Y_tahmin==3,0], X[Y_tahmin==3,1], s=100, c=\"yellow\")\nplt.title(\"KMeans\")\nplt.show()","57973a04":"from sklearn.cluster import AgglomerativeClustering\nac= AgglomerativeClustering(n_clusters=3, affinity=\"euclidean\", linkage=\"ward\")\nY_tahmin=ac.fit_predict(X)\nprint(Y_tahmin)\n\nplt.scatter(X[Y_tahmin==0,0], X[Y_tahmin==0,1], s=100, c=\"red\")\nplt.scatter(X[Y_tahmin==1,0], X[Y_tahmin==1,1], s=100, c=\"blue\")\nplt.scatter(X[Y_tahmin==2,0], X[Y_tahmin==2,1], s=100, c=\"green\")\nplt.title(\"Hierarchical Clustering\")\nplt.show()","af9360f1":"import scipy.cluster.hierarchy as sch\ndendrogram= sch.dendrogram(sch.linkage(X, method=\"ward\"))\nplt.show()","d7078a0d":"# Hierarchical Clustering","9f024b2d":"THAT'S ALL"}}