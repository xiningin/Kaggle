{"cell_type":{"7e71a9cb":"code","d4140dd3":"code","98474af7":"code","8452f318":"code","4765b8f1":"code","868a24cb":"code","ff5feff4":"code","29645445":"code","0491ff8e":"code","2bbcfdd0":"code","d28d6a34":"code","3b8d8672":"code","31b8ad78":"code","f1baa743":"code","3699cee8":"code","be609d9a":"code","c7d86f42":"code","f75e6f8b":"code","4b0b6766":"code","2c8ee605":"code","7acdf74c":"code","b9afe3f3":"code","8f6e19b2":"markdown","45baa8b1":"markdown","bbd666f6":"markdown","f7b6b265":"markdown","2728a313":"markdown","f7b5d670":"markdown"},"source":{"7e71a9cb":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","d4140dd3":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.cuda as tc","98474af7":"dt = pd.read_pickle('..\/input\/cifar-100\/train')\ndf = pd.DataFrame.from_dict(dt, orient='index')\ndf = df.T","8452f318":"df.head()","4765b8f1":"labels = list(pd.read_pickle('..\/input\/cifar-100\/meta')['fine_label_names'])","868a24cb":"labels_idx = {v:k for (k,v) in enumerate(labels)}\nidx_labels = {k:v for (k,v) in enumerate(labels)}","ff5feff4":"img = np.array(df[df['fine_labels'] == 15].iloc[10]['data']).reshape(3,32,32)\nplt.imshow(img.transpose(1,2,0).astype(\"uint8\"), interpolation='nearest')","29645445":"features = np.array(np.stack(df['data'].values, axis=0)).reshape(len(df['data'].values), 3, 32, 32).astype('float32')\nlabels = np.array(df['fine_labels'].values).astype('float32')","0491ff8e":"# swap from 3, 32, 32 to 32, 32, 3\nfeatures = features.swapaxes(1, 3)\n\n# normalize\nfeatures = features \/ 255.0","2bbcfdd0":"features = torch.from_numpy(features).cuda()\nlabels = torch.from_numpy(labels).cuda()","d28d6a34":"X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)","3b8d8672":"class Conv:\n    '''\n    This class applies conv2d operation using torch cuda tensors\n    '''\n\n    def __init__(self, input_of_layer, kernel_number, kernel_size=3, stride_size=1):\n        '''\n        This function create Conv instance wtih given parameters\n        :param input_of_layer: input of convolution layer\n        :param kernel_number: number of kernel that will be applied\n        :param kernel_size: kernel size for convolution operation\n        :param stride_size: stride size for convolution operation\n        '''\n        # initialize parameters\n        self.input = tc.FloatTensor(input_of_layer)\n        if len(self.input.shape) != 4:\n            raise ValueError('Input size is ' + len(\n                self.input.shape) + \" Should at least 4 dimension (batch_size, channel_size, width, height\")\n        self.kernel_number = kernel_number\n        self.kernel_size = kernel_size\n        self.stride_size = stride_size\n        # get dimensions\n        self.batch_size = self.input.shape[0]\n        self.channel_size = self.input.shape[1]\n        self.width_size = self.input.shape[2]\n        self.height_size = self.input.shape[3]\n        # conv2d operation for forward pass, we are using torch.Conv2d for only fast speed\n        self.layer = nn.Conv2d(self.channel_size, self.kernel_number, self.kernel_size, self.stride_size,\n                               self.padding_size()).cuda().type(torch.float32)\n        # initialized weights and biases wtih xavier initializiation\n        nn.init.xavier_uniform_(self.layer.weight)\n\n        # terms for momentum saving\n        self.delta_w = 0\n        self.delta_b = 0\n\n    def forward(self, input=tc.FloatTensor(0)):\n        '''\n        This function runs forward propagation for Convolution operation\n        :param input: output of previous layer\n        :return: output of convolution of input with relu activation function\n        '''\n        self.input = input\n        self.act_output = self.relu(self.layer.forward(tc.FloatTensor(self.input)))\n        return self.act_output\n\n    def padding_size(self):\n        '''\n        This function finds padding size for maintain sizess\n        :return: return padding size\n        '''\n        return (self.kernel_size - 1) \/\/ 2\n\n    def relu(self, xa, derive=False):\n        '''\n        This function applies relu forward and back propagation via determining derive parameter\n        :param xa: output of previous layer\n        :param derive: if it is True, the function runs backprop for relu, otherwise, it runs forwardprop\n        :return: according derive parameter, it change but give relu operation results\n        '''\n        # back prop\n        if derive:\n            return torch.ceil(torch.clamp(xa, min=0, max=1)).detach()\n        # forward prop\n        return torch.clamp(xa, min=0).detach()\n\n    def backward(self, lr_rate, momentum_rate, next_layer_grad, isInput=False):\n        '''\n        This function runs backprop for convolution layer\n        :param lr_rate: learning rate for weight updates\n        :param momentum_rate: momentum rate for momentum operations\n        :param next_layer_grad: gradients from next layer\n        :param isInput: check whether input of the layer is input, if it is, then there is no need for gradient calculation\n        otherwise, calculate input gradient\n        :return: gradient of the input\n        '''\n        # found gradient of activation function operation\n        self.act_output = torch.mul(next_layer_grad, self.relu(self.act_output, derive=True)).detach()\n\n        # this convolution operation for calculating gradient of weights\n        dw_layer = nn.Conv2d(self.batch_size, self.kernel_number, self.act_output.shape[2], 1,\n                             self.padding_size()).cuda().type(torch.float32)\n        # copying activation gradient\n        gradx = self.act_output.clone().detach()\n        # flipping for convolution operation\n        gradx = gradx.cpu().detach().numpy()[:, :, ::-1, ::-1]\n        # set weight and bias with 0  with activation gradient\n        dw_layer.weight.data = tc.FloatTensor(gradx.copy()).transpose(0, 1).detach()\n        del gradx\n        dw_layer.bias.data = tc.FloatTensor(np.zeros(self.kernel_number)).detach()\n        # momentum update\n        self.delta_w = momentum_rate * self.delta_w + (\n                dw_layer.forward(self.input.transpose(0, 1)).transpose(0, 1).detach() \/ (self.batch_size)).detach()\n        self.delta_b = momentum_rate * self.delta_b + (torch.sum(self.act_output, dim=[0, 2, 3]).detach() \/ (\n                self.act_output.shape[0] * self.batch_size * self.act_output.shape[2] * self.act_output.shape[\n            3])).detach()\n        # weight and bias update\n        self.layer.weight.data -= lr_rate * self.delta_w.detach()\n        self.layer.bias.data -= lr_rate * self.delta_b.detach()\n\n        # if it is not input that initially given model then calculate input gradient as well\n        if (isInput == False):\n            # convolution operation for calculating input gradient\n            dx_layer = nn.Conv2d(self.kernel_number, self.channel_size, self.kernel_size, self.stride_size,\n                                 self.padding_size()).cuda().type(torch.float32)\n            # get weight from conv layer\n            temp_weight = self.layer.weight.data.clone().cpu().numpy()\n            # flip kernel for convolution operation\n            temp_weightx = temp_weight[:, :, ::-1, ::-1]\n            #set weight with flipped kernel\n            dx_layer.weight.data = tc.FloatTensor(temp_weightx.copy()).transpose(0, 1).detach()\n            #set bias with zero\n            dx_layer.bias.data = tc.FloatTensor(np.zeros(self.channel_size)).detach()\n            #input gradient\n            out = dx_layer.forward(self.act_output)\n\n            del temp_weight\n            del temp_weightx\n\n            return out\n        else:\n            #return input itself\n            # del self.act_output\n            return self.input","31b8ad78":"class MaxPooling:\n    '''\n    This class applies maxpooling operation\n    '''\n    def __init__(self, input, kernel_size=2, stride_size=2):\n        '''\n        This function create instance for maxpooling layer\n        :param input: output of previous layer\n        :param kernel_size: to apply max pooling\n        :param stride_size: stride size for max pooling\n        '''\n        self.input = input.detach()\n        self.kernel_size = kernel_size\n        self.stride_size = stride_size\n        #this applies max pooling\n        self.layer = nn.MaxPool2d(self.kernel_size, self.stride_size, return_indices=True).cuda().type(torch.float32)\n\n    def forward(self, input=tc.FloatTensor(0)):\n        '''\n        This function runs forward propagation of maxpooling\n        :param input: output of previous layer\n        :return: max pooling operation result\n        '''\n\n        self.input = input.detach()\n        self.output, self.indices = self.layer.forward(self.input)\n        return self.output\n\n    def backward(self, next_layer_grad):\n        '''\n        This function runs backprop for maxpooling\n        :param next_layer_grad: gradient of next layer\n        :return: backprop of max pooling\n        '''\n        #unpool operation for back propagation\n        back_layer = nn.MaxUnpool2d(self.kernel_size, self.stride_size).cuda().type(torch.float32)\n        #output of backpropagation\n        out = back_layer.forward(next_layer_grad, self.indices, output_size=self.input.shape).type(\n            torch.float32).detach()\n        del back_layer\n\n        return out","f1baa743":"class Dense:\n    '''\n    This class applies fully connected layer\n    '''\n\n    def __init__(self, input, dense_number):\n        '''\n        This function creates dense instance with given dense size\n        :param input: output of previous layer\n        :param dense_number: number of dense layer\n        '''\n\n        self.input = input.detach()\n        self.dense_number = dense_number\n\n        self.batch_size = self.input.shape[0]\n        self.input_size = self.input.shape[1]\n        #initialize weights and biases\n        self.weight = tc.FloatTensor(\n            np.random.normal(size=(self.input_size, self.dense_number), loc=0, scale=0.01).astype(np.float32)).type(\n            torch.float32).detach()\n        self.bias = tc.FloatTensor(np.zeros((1, dense_number))).type(torch.float32).detach()\n        #momentum terms\n        self.delta_w = 0\n        self.delta_b = 0\n\n    def forward(self, input=tc.FloatTensor(0).detach()):\n        '''\n        This function runs forward prop fully connected layer\n        :param input: the previous layer of output\n        :return: the activation function output applied dense operation\n        '''\n\n        self.input = input.detach()\n        self.act_output = self.relu(torch.mm(self.input, self.weight) + self.bias).detach()\n        return self.act_output\n\n    def relu(self, xa, derive=False):\n        '''\n        This function applies relu forward and back propagation via determining derive parameter\n        :param xa: output of previous layer\n        :param derive: if it is True, the function runs backprop for relu, otherwise, it runs forwardprop\n        :return: according derive parameter, it change but give relu operation results\n        '''\n        # back prop\n        if derive:\n            return torch.ceil(torch.clamp(xa, min=0, max=1)).detach()\n        # forward prop\n        return torch.clamp(xa, min=0).detach()\n\n    def backward(self, lr_rate, momentum_rate, next_layer_grad, isInput=False):\n        '''\n        This function runs back prop of fully connected layer\n        :param lr_rate: learning rate\n        :param momentum_rate: momentum rate\n        :param next_layer_grad: gradient from next layer\n        :param isInput: check whether input is data\n        :return: return input gradient\n        '''\n        #find gradient activation functions\n        self.act_output = torch.mul(next_layer_grad, self.relu(self.act_output, derive=True)).type(\n            torch.float32).detach()\n        #find momentum terms\n        self.delta_w = momentum_rate * self.delta_w + (\n                torch.mm(self.input.transpose(0, 1), self.act_output).detach() \/ self.batch_size).detach()\n        self.delta_b = momentum_rate * self.delta_b + (\n                torch.sum(self.act_output, dim=0, keepdim=True).detach() \/ self.batch_size).detach()\n        #update weight and bias\n        self.weight -= lr_rate * self.delta_w.detach()\n        self.bias -= lr_rate * self.delta_b.detach()\n        #check whether input is data, if it is not, then find input gradient\n        if isInput == False:\n            #gradient operation for input\n            out = torch.mm(self.act_output, self.weight.transpose(0, 1)).type(torch.float32).detach()\n            return out\n        else:\n            #return input itself\n            return self.input","3699cee8":"class Flatten:\n    '''\n    This classes flattens the data from prevoius layer\n    '''\n    def __init__(self, input):\n        '''\n        This function creates Flatten instance\n        :param input: the out put of previous layer\n        '''\n        #set input and sizes\n        self.input = input.detach()\n        self.batch_size = self.input.shape[0]\n        self.channel_size = self.input.shape[1]\n        self.width = self.input.shape[2]\n        self.height = self.input.shape[3]\n\n    def forward(self, input=tc.FloatTensor(0).detach()):\n        '''\n        This function runs forward prop flatten operation from 4d  to 2d\n        :param input: the previous layer output\n        :return: 2d matrix\n        '''\n        self.input = input.detach()\n        self.batch_size = self.input.shape[0]\n        self.channel_size = self.input.shape[1]\n        self.width = self.input.shape[2]\n        self.height = self.input.shape[3]\n\n        self.output = self.input.view(self.batch_size, -1).detach()\n        return self.output\n\n    def backward(self, next_layer_grad):\n        '''\n        This function runs backprop with reshaping 2d matrix to 4d tensor\n        :param next_layer_grad: gradient from next layer\n        :return: 4d tensor\n        '''\n        return next_layer_grad.view(self.batch_size, self.channel_size, self.width, self.height).detach()","be609d9a":"class Dropout:\n    '''\n    This class applies dropout to fully connected layer\n    '''\n    def __init__(self, input, dropout):\n        '''\n        This function create instance for Dropout layer\n        :param input: the output from previous layer\n        :param dropout: dropout layer probability rate\n        '''\n        #check the input that has dimension of two\n        if len(input.shape) != 2:\n            raise ValueError('Input shape should be 2 dimensional')\n        #initialize class attributes\n        self.input = input.detach()\n        self.dropout = dropout\n        self.batch_size = self.input.shape[0]\n        self.kernel_number = self.input.shape[1]\n        #create dropout matrix\n        self.dropout_matrix = tc.FloatTensor(np.zeros(self.input.shape)).detach()\n\n    def forward(self, input):\n        '''\n        This function runs forward prop for dropout\n        :param input: the output of the previous layer\n        :return: dropout result\n        '''\n        self.input = input.detach()\n        #create mask\n        self.dropout_matrix = tc.FloatTensor(\n            np.random.binomial(1, 1 - self.dropout, size=self.kernel_number)).expand_as(\n            self.input).detach()\n        #apply mask\n        self.output = torch.mul(self.input, self.dropout_matrix).detach() \/ (1 - self.dropout + np.exp(-32))\n        return self.output\n\n    def backward(self, next_layer_grad):\n        '''\n        This function runs backprop of dropout layer\n        :param next_layer_grad: the gradient of next layer\n        :return: the gradient of the input\n        '''\n        return torch.mul(next_layer_grad, self.dropout_matrix).detach() \/ (1 - self.dropout + np.exp(-32))","c7d86f42":"class Output:\n    '''\n    This class applies categorical cross entropy with softmax activation function, it should be used last layer of the model\n    '''\n    def __init__(self, input, target):\n        '''\n        This function create instance for last layer of the model\n        :param input: the output of previous layer\n        :param target: target or labels\n        '''\n        #initialize attributes\n        self.input = input.detach()\n        self.target = target\n        self.y = None\n        self.class_number = self.input.shape[1]\n\n    def forward(self, input=tc.FloatTensor(0).detach(), target=tc.FloatTensor(0).detach()):\n        '''\n        This function runs forward pass with softmax and categorical cross entropy\n        :param input: the previous layer output\n        :param target: the labels\n        :return: the prediction\n        '''\n        self.input = input.detach()\n\n        self.target = target\n        self.output, self.loss = self.softmax_with_cross_entropy(self.input, self.target)\n\n        return self.output\n\n    def softmax_with_cross_entropy(self, x, target, derive=False):\n        '''\n        This function applies softmax activation function and categorical cross entropy\n        :param x: the input\n        :param target: label\n        :param derive: if it is true it returns derivative of operation, otherwise it runs opeartion\n        :return: according to derive parameters it runs either operation result or back prop result\n        '''\n        if derive == True:\n            return x - target\n        #softmax\n        self.y = torch.eye(self.class_number)[tc.FloatTensor(target).type(torch.long).view(-1).detach(), :].cuda().type(\n            torch.float32)\n\n        maximum = torch.max(x, dim=1, keepdim=True)[0].detach()\n        self.pred = torch.exp(x - maximum).detach()\n        self.pred = self.pred.detach() \/ torch.sum(self.pred, 1, keepdim=True).detach()\n        #categorical cross entropy\n        self.loss = -torch.sum(self.y * torch.log(self.pred + np.exp(-32))).type(torch.float32).detach() \/ \\\n                    self.pred.shape[0]\n\n        return self.pred, self.loss\n\n    def backward(self):\n        '''\n        This function runs back prop for output layer\n        :return: the gradient of input\n        '''\n        return self.softmax_with_cross_entropy(self.output, self.y, derive=True)","f75e6f8b":"mini_batches = np.array_split(np.arange(len(X_train)), (len(X_train) \/ 100))","4b0b6766":"# Initialize variables\nx_part = X_train[mini_batches[0]]\na01 = Conv(tc.FloatTensor(x_part).detach(), 32)\na01.forward(tc.FloatTensor(x_part).detach())\na001 = Conv(a01.act_output, 32)\na001.forward(a01.act_output)\na02 = MaxPooling(a001.act_output)\na02.forward(a001.act_output)\na1 = Flatten(a02.output)\na1.forward(a02.output)\na = Dense(a1.output, 512)\na.forward(a1.output)\na10 = Dropout(a.act_output, 0.05)\na10.forward(a.act_output)\nb = Dense(a10.output, 128)\nb.forward(a10.output)\nb1 = Dropout(b.act_output, 0.15)\nb1.forward(b.act_output)\nc = Dense(b1.output, 100)\nc.forward(b1.output)\nd = Output(c.act_output, y_train[mini_batches[0]])\nd.forward(c.act_output, y_train[mini_batches[0]])","2c8ee605":"# parameters\nlearning_rate = 0.001\nmomentum = 0.9\nepochs = 150\n\n# losses array\nlosses = []","7acdf74c":"for epoch in range(epochs + 1):\n\n    for batch in mini_batches:\n        \n        # Forward Propagation\n        x_part = X_train[batch]\n        torch.cuda.synchronize()\n        torch.cuda.empty_cache()\n        a01.forward(tc.FloatTensor(x_part).detach())\n        a001.forward(a01.act_output)\n        a02.forward(a001.act_output)\n        a1.forward(a02.output)\n        a.forward(a1.output)\n        a10.forward(a.act_output)\n        b.forward(a10.output)\n        b1.forward(b.act_output)\n        c.forward(b1.output)\n        d.forward(c.act_output, y_train[batch])\n        \n        # Loss\n        losses.append(np.mean(d.loss.cpu().numpy()))\n        \n        # Background Propagation\n        e = c.backward(learning_rate, momentum, d.backward().detach()).detach()\n        e1 = b1.backward(e)\n        f = b.backward(learning_rate, momentum, e1).detach()\n        f1 = a10.backward(f)\n        g = a.backward(learning_rate, momentum, f1, ).detach()\n        h = a1.backward(g).detach()\n        k = a02.backward(h).detach()\n        k1 = a001.backward(learning_rate, momentum, k).detach()\n        m = a01.backward(learning_rate, momentum, k1, True).detach()\n        del e, f, g, h, k, m\n        \n\n    if(epoch % 10 == 0):\n        print('Epoch:{0}, Lost:{1}'.format(epoch, losses[-1]))","b9afe3f3":"plt.plot([losses[i] for i in range(0, len(losses), 400)])","8f6e19b2":"<a id='training'><\/a>\n# 3. Training","45baa8b1":"# CIFAR-100 PyTorch from Scratch","bbd666f6":"<a id='implementation'><\/a>\n# 2. Implementation","f7b6b265":"<a id='prepare'><\/a>\n# 1. Prepare Data","2728a313":"<a id='lost'><\/a>\n# 4. Plot Losses","f7b5d670":"## Table Content\n1. [Prepare Data](#prepare)\n2. [Implementation](#implementation)\n3. [Training](#training)\n4. [Plot Losses](#lost)"}}