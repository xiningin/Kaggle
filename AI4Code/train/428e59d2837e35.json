{"cell_type":{"e38604a2":"code","dbcac6be":"code","e168d586":"code","d8dd6de0":"code","c4069792":"code","744b8a6d":"code","9bc0a7f5":"code","49bc0643":"code","ece2f87b":"code","3052ae75":"code","32a0be87":"code","8fe1db14":"code","7a5492d3":"code","e4c66694":"code","6239e92e":"code","c0cef5ce":"code","eba2c8a5":"code","e843ba2c":"code","96889e59":"code","d5927102":"code","bc7007fd":"code","0be41416":"code","1cde9195":"code","c35c4257":"code","5b2b7d75":"code","d68a2418":"code","bc7b431b":"code","c4a0d9b0":"code","23139fb3":"code","c14367f6":"code","1d3981bc":"code","cd8f84dd":"code","aea7c79c":"code","084f44c0":"code","0b4c711f":"code","1ff4d231":"code","367ef04f":"code","1fd29c10":"code","6f57dc7d":"code","70f98900":"code","9d670015":"code","aef2ad81":"code","969cb8eb":"code","d81880a4":"code","bc0ab5b3":"code","75876b9a":"code","49e2236b":"code","a0035d48":"code","645716b4":"code","d8cc61c3":"code","fe77b3eb":"code","cf47c43d":"code","03ed5375":"code","e537b76e":"code","088665fd":"code","fe8d0d4c":"code","c428139a":"code","f262eecb":"code","47056a57":"code","73e17717":"code","020f9d63":"code","5bf9af91":"code","c43c0555":"code","7de091ce":"code","4748ff47":"code","a0fbba2e":"code","b0c32804":"code","84494cfb":"code","52aca022":"code","77cc481e":"code","9aad4e9e":"code","d2293d40":"code","835ba4e2":"code","ec5cb681":"code","7a8b9f17":"code","8194fe7c":"code","c5091b3b":"code","e699cc02":"code","cf1adf93":"code","ccd9af8e":"code","9d4dbdcc":"code","a6e5f0b6":"markdown","c2fe4ab1":"markdown","aa1b6610":"markdown","e8b6cd5f":"markdown","7d2e1f7a":"markdown","6c7e59b2":"markdown","21e46e57":"markdown","84d10873":"markdown","7128b4fa":"markdown","e3ca8bca":"markdown","6293c853":"markdown","96a3eb6b":"markdown","914eb800":"markdown","3ee470f3":"markdown","1d7f6b74":"markdown","92762803":"markdown","f7aed584":"markdown","e9143865":"markdown","739ce202":"markdown"},"source":{"e38604a2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dbcac6be":"import pandas as pd\nimport numpy as np\nimport pylab as py\nimport scipy.optimize as opt\nfrom sklearn import preprocessing\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\n%matplotlib inline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import tree","e168d586":"# Open and define the data sets using the pandas' library:\ndf=pd.read_csv(\"..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv\")","d8dd6de0":"# We use several commands to check the loaded date set:\n# Show the first 5 data to check out the data\ndf.head()","c4069792":"# Show the columns names of the data sets and type of data\ndf.columns","744b8a6d":"# Show the columns names of the data sets and type of data and amount \n# of non-null(not missed) values.\ndf.info()","9bc0a7f5":"# For a column in the data set columns show and print column name - number of \n# unique values and number of total values. If there are too many unique values \n# out of total numbers, we can easily drop out this variable.\n# But our data set have good quolity and a lots of dummy variables =>\n# we leave it unchanged for now.\ndf.info()\nfor col in df.columns:\n    print(col, df[col].nunique(), len(df))","49bc0643":"# For each of the variables we need to check the mistakes.\n# For that we print all unique values and look for mistakes.\n# As we can see, all values are okay and no mistake exists\nfor col in df.columns:\n    print(col, df[col].unique(), len(df))","ece2f87b":"# Next, let's collect descriptive statistics for each variable: \nstatistic = df.describe(include='all')\nprint(statistic)\n# Results we can see in 'variable explorer'.\n# Based on this, in the future, we will need to normalize or standardize \n# the data (optional) in order for the analysis to be more accurate.","3052ae75":"# Next, we use correlation, in this case Pearson. We also build a correlation \n# matrix to display the result. Correlation analysis will help us determine \n# whether variables interact strongly with each other or not. If variables \n# interact strongly with each other, it will damage the analysis and make it \n# non-faithful. But as we can observe, all the variables do not \n# influence each other much.","32a0be87":"import seaborn as sns\ncorr = df.corr(method ='pearson')\nax = sns.heatmap(\n    corr, vmin=-1, vmax=1, center=0,cmap=sns.diverging_palette(10, 200, n=200),square=True)\nax.set_xticklabels(ax.get_xticklabels(),rotation=45, horizontalalignment='right');","8fe1db14":"fig ,ax = plt.subplots(2,2,figsize=(32,32))\nax1,ax2,ax3,ax4 = ax.flatten()\nsns.countplot(data=df,x='anaemia',hue='DEATH_EVENT',palette='viridis',ax=ax1)\nsns.countplot(data=df,x='diabetes',hue='DEATH_EVENT',palette='Set1_r',ax=ax2)\nsns.countplot(data=df,x='high_blood_pressure',hue='DEATH_EVENT',palette='gist_ncar_r',ax=ax3)\nsns.countplot(data=df,x='smoking',hue='DEATH_EVENT',palette='autumn_r',ax=ax4)","7a5492d3":"plt.figure(figsize=(32,16))\nsns.countplot(data=df,x='age',hue='DEATH_EVENT',palette='gist_rainbow')","e4c66694":"plt.figure(figsize=(32,16))\nsns.countplot(data=df,x='serum_creatinine',hue='DEATH_EVENT',palette='YlGnBu')","6239e92e":"plt.figure(figsize=(32,16))\nsns.countplot(data=df,x='serum_sodium',hue='DEATH_EVENT',palette='Oranges_r')","c0cef5ce":"plt.figure(figsize= (16,4))\nsns.countplot(data=df,x='sex',hue='DEATH_EVENT',palette='Set2_r')","eba2c8a5":"fig,ax = plt.subplots(2,2,figsize=(16,16))\nax1,ax2,ax3,ax4 = ax.flatten()\nsns.distplot(df['age'],bins=20,color='r',ax=ax1)\nsns.boxplot(y='age',x='DEATH_EVENT',data=df,ax=ax2)\nsns.pointplot(y='age',x='DEATH_EVENT',data=df,ax=ax3)\nsns.violinplot(y='age',x='DEATH_EVENT',data=df,ax=ax4)","e843ba2c":"male = df[df[\"sex\"]==1]\nfemale = df[df[\"sex\"]==0]\n\nmale_survi = male[df[\"DEATH_EVENT\"]==0]\nmale_not = male[df[\"DEATH_EVENT\"]==1]\nfemale_survi = female[df[\"DEATH_EVENT\"]==0]\nfemale_not = female[df[\"DEATH_EVENT\"]==1]\n\nlabels = ['Male - Survived','Male - Not Survived', \"Female -  Survived\", \"Female - Not Survived\"]\nvalues = [len(male[df[\"DEATH_EVENT\"]==0]),len(male[df[\"DEATH_EVENT\"]==1]),\n         len(female[df[\"DEATH_EVENT\"]==0]),len(female[df[\"DEATH_EVENT\"]==1])]\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.3)])\nfig.update_layout(\n    title_text=\"Analysis on Survival - Gender\")\nfig.show()","96889e59":"# We need to predict the chance of DEATH_EVENT => for that goal we have to use\n# logistic regression. Types of Logistic Regression:\n# 1. Binary Logistic Regression: The target variable has \n# only two possible outcomes.\n# 2. Multinomial Logistic Regression: The target variable has three or more \n# nominal categories.\n# 3. Ordinal Logistic Regression: the target variable has three or \n# more ordinal categories. \n# Hence our regression method is obviously Binary Logistic Regression.","d5927102":"# Is to divide all variables into two groups: target variable(dependent) and others (independent) variables:\nfeature_cols = ['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes', \n                'ejection_fraction', 'high_blood_pressure', 'platelets', \n                'serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'time']\nX = df[feature_cols] # Features\ny = df.DEATH_EVENT # Target variable","bc7007fd":"# Understand model performance, dividing the dataset into\n# a training set and a test set\n# split X and y into training and testing sets.\n# Here, the Dataset is broken into two parts in a ratio of 80:20.\n# It means 80% data will be used for model training \n# and 20% for model testing.","0be41416":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2, random_state=0)","1cde9195":"cor = X_train.corr()\nplt.figure(figsize=(12,6))\nsns.heatmap(cor,cmap='Set1',annot=True)","c35c4257":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train_st = scaler.fit_transform(X_train)\nX_test_st = scaler.fit_transform(X_test)","5b2b7d75":"X_train_st","d68a2418":"X_test_st","bc7b431b":"# First, import the Logistic Regression module and \n# create a Logistic Regression classifier object using\n# LogisticRegression() function.\n# Then, fit our model on the train set using fit() and\n# perform prediction on the test set using predict().","c4a0d9b0":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(random_state=0)\nlogreg.fit(X_train_st,y_train)\ny_pred=logreg.predict(X_test_st)\nprint(y_pred)","23139fb3":"logreg.coef_","c14367f6":"# A confusion matrix is a table that is used to evaluate the performance \n# of a classification model. We can also visualize the performance of an \n# algorithm. The fundamental of a confusion matrix is the number of correct\n# and incorrect predictions are summed up class-wise.\nfrom sklearn import metrics\ncnf_matrix = metrics.confusion_matrix(y_test, y_pred)\ncnf_matrix","1d3981bc":"# Create a matrix 2x2 with a code:\nclass_names=[0,1] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","cd8f84dd":"# Confusion Matrix Evaluation Metrics\n# evaluate the model using model evaluation metrics \n# such as accuracy, precision, and recall\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))","aea7c79c":"# ROC Curve:\n# Receiver Operating Characteristic(ROC) curve is a plot of the true \n# positive rate against the false positive rate. It shows the tradeoff \n# between sensitivity and specificity.\ny_pred_proba = logreg.predict_proba(X_test_st)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\nauc_logreg = metrics.roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc_logreg))\nplt.legend(loc=4)\nplt.show()","084f44c0":"# ROC Curve: 0.857\n# AUC score for the case is 0.857. AUC score 1 represents perfect classifier, \n# and 0.5 represents a worthless classifier.","0b4c711f":"help(RandomForestClassifier)","1ff4d231":"from sklearn.ensemble import RandomForestClassifier\nr_clf = RandomForestClassifier(max_features=0.5, max_depth=10, random_state=0)\nr_clf.fit(X_train_st, y_train)\nr_pred = r_clf.predict(X_test_st)","367ef04f":"print(r_clf.max_depth)","1fd29c10":"print(r_clf.max_features)","6f57dc7d":"print(\"Accuracy:\",metrics.accuracy_score(y_test, r_pred))\nprint(\"Precision:\",metrics.precision_score(y_test, r_pred))\nprint(\"Recall:\",metrics.recall_score(y_test, r_pred))","70f98900":"from sklearn import metrics\ncnf_matrix = metrics.confusion_matrix(y_test, r_pred)\ncnf_matrix\nimport matplotlib.pyplot as plt\nclass_names=[0,1] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","9d670015":"y_pred_proba_r_clf = r_clf.predict_proba(X_test_st)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba_r_clf)\nauc_r_clf = metrics.roc_auc_score(y_test, y_pred_proba_r_clf)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc_r_clf))\nplt.legend(loc=4)\nplt.show()","aef2ad81":"help(DecisionTreeClassifier)","969cb8eb":"decision_tree = tree.DecisionTreeClassifier(criterion='entropy', max_depth = 10, random_state=0)\ndecision_tree.fit(X_train_st, y_train)\nd_pred = decision_tree.predict(X_test_st)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, d_pred))\nprint(\"Precision:\",metrics.precision_score(y_test, d_pred))\nprint(\"Recall:\",metrics.recall_score(y_test, d_pred))","d81880a4":"print(decision_tree.tree_.max_depth)","bc0ab5b3":"from sklearn import metrics\ncnf_matrix = metrics.confusion_matrix(y_test, d_pred)\ncnf_matrix\nimport matplotlib.pyplot as plt\nclass_names=[0,1] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","75876b9a":"y_pred_proba_decision_tree = decision_tree.predict_proba(X_test_st)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba_decision_tree)\nauc_decision_tree = metrics.roc_auc_score(y_test, y_pred_proba_decision_tree)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc_decision_tree))\nplt.legend(loc=4)\nplt.show()","49e2236b":"from IPython.display import Image as PImage\nfrom subprocess import check_call\nfrom PIL import Image, ImageDraw\nimport graphviz  \nfrom sklearn.tree import export_graphviz\n\n# Export our trained model as a .dot file\nwith open(\"tree1.dot\", 'w') as f:\n     f = export_graphviz(decision_tree, out_file=f, max_depth = 10,\n                         impurity = True, feature_names = X_train.columns,\n                         rounded = True, filled= True )\n#Convert .dot to .png to allow display in web notebook\ncheck_call(['dot','-Tpng','tree1.dot','-o','tree.png'])\n# Annotating chart with PIL\nimg = Image.open(\"tree.png\")\ndraw = ImageDraw.Draw(img)\nimg.save('sample-out.png')\nPImage(\"sample-out.png\")","a0035d48":"from sklearn.model_selection import GridSearchCV,StratifiedKFold\nlogreg5 = LogisticRegression(class_weight='balanced')\nparam = {'C':[0.001,0.003,0.005,0.01,0.03,0.05,0.08, 0.1, 0.3,0.5,1,2,3,3,4,5,10,20]}\nclf = GridSearchCV(logreg5,param,scoring='roc_auc',refit=True,cv=10)\nclf.fit(X_train_st,y_train)\nprint('Best roc_auc: {:.4}, with best C: {}'.format(clf.best_score_, clf.best_params_))","645716b4":"from sklearn.linear_model import LogisticRegression\nlogreg2 = LogisticRegression(C=0.1)\nlogreg2.fit(X_train_st,y_train)\ny_pred2=logreg2.predict(X_test_st)\nprint(y_pred2)","d8cc61c3":"from sklearn import metrics\ncnf_matrix = metrics.confusion_matrix(y_test, y_pred2)\ncnf_matrix","fe77b3eb":"import matplotlib.pyplot as plt\nclass_names=[0,1] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","cf47c43d":"print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred2))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred2))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred2))","03ed5375":"y_pred_proba_logreg2 = logreg2.predict_proba(X_test_st)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba_logreg2)\nauc_logreg2 = metrics.roc_auc_score(y_test, y_pred_proba_logreg2)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc_logreg2))\nplt.legend(loc=4)\nplt.show()","e537b76e":"#Since it provides sparse solutions, it is generally the model of choice (or some variant of this concept) for modelling cases where the \n#features are in millions or more. In such a case, getting a sparse solution is of great computational advantage as the features \n#with zero coefficients can simply be ignored.\n#It arbitrarily selects any one feature among the highly correlated ones and reduced the coefficients of the rest to zero. \n#Also, the chosen variable changes randomly with change in model parameters. This generally doesn\u2019t work that well as compared to ridge regression.","088665fd":"from sklearn.linear_model import LogisticRegression\nlog_l1 = LogisticRegression(random_state=0, penalty='l1', solver='saga')\nlog_l1.fit(X_train_st,y_train)\ny_pred_l1=log_l1.predict(X_test_st)\nprint(y_pred_l1)","fe8d0d4c":"from sklearn import metrics\ncnf_matrix = metrics.confusion_matrix(y_test, y_pred_l1)\ncnf_matrix","c428139a":"class_names=[0,1] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","f262eecb":"print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_l1))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred_l1))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred_l1))","47056a57":"y_pred_proba_log_l1 = log_l1.predict_proba(X_test_st)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba_log_l1)\nauc_log_l1 = metrics.roc_auc_score(y_test, y_pred_proba_log_l1)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc_log_l1))\nplt.legend(loc=4)\nplt.show()","73e17717":"log_l1.coef_","020f9d63":"#Ridge: It is majorly used to prevent overfitting. \n#Since it includes all the features, it is not very useful in case of exorbitantly high #features, say in millions, as it will pose computational challenges.\n#It generally works well even in presence of highly correlated features as it will include all of them in the model\n#but the coefficients will be distributed among them depending on the correlation.","5bf9af91":"from sklearn.linear_model import LogisticRegression\nlog_l2 = LogisticRegression(random_state=0, penalty='l2', solver='saga')\nlog_l2.fit(X_train_st,y_train)\ny_pred_l2=log_l2.predict(X_test_st)\nprint(y_pred_l2)","c43c0555":"from sklearn import metrics\ncnf_matrix = metrics.confusion_matrix(y_test, y_pred_l2)\ncnf_matrix","7de091ce":"class_names=[0,1] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","4748ff47":"print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_l2))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred_l2))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred_l2))","a0fbba2e":"y_pred_proba_log_l2 = log_l2.predict_proba(X_test_st)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba_log_l2)\nauc_log_l2 = metrics.roc_auc_score(y_test, y_pred_proba_log_l2)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc_log_l2))\nplt.legend(loc=4)\nplt.show()","b0c32804":"log_l2.coef_","84494cfb":"from sklearn.linear_model import Lasso\nfrom sklearn import linear_model\nlasso = Lasso()\nlasso.fit(X_train_st,y_train)\ntrain_score=lasso.score(X_train_st,y_train)\ntest_score=lasso.score(X_test_st,y_test)\ncoeff_used = np.sum(lasso.coef_!=0)\n\nprint (\"Training score:\", train_score) \nprint (\"Test score:\", test_score)\nprint (\"Number of features used:\", coeff_used)\nprint (\"____________________________________________________________________________\")\nprint()\n\n\nlasso001 = Lasso(alpha=0.01, max_iter=10e5)\nlasso001.fit(X_train_st,y_train)\ntrain_score001=lasso001.score(X_train_st,y_train)\ntest_score001=lasso001.score(X_test_st,y_test)\ncoeff_used001 = np.sum(lasso001.coef_!=0)\n\nprint (\"Training score for alpha = 0.01:\", train_score001)\nprint (\"Test score for alpha = 0.01:\", test_score001)\nprint (\"Number of features used: for alpha = 0.01:\", coeff_used001)\nprint (\"____________________________________________________________________________\")\nprint()\n\n\nlasso00001 = Lasso(alpha=0.0001, max_iter=10e5)\nlasso00001.fit(X_train_st,y_train)\ntrain_score00001=lasso00001.score(X_train_st,y_train)\ntest_score00001=lasso00001.score(X_test_st,y_test)\ncoeff_used00001 = np.sum(lasso00001.coef_!=0)\n\nprint (\"Training score for alpha = 0.0001:\", train_score00001)\nprint (\"Test score for alpha = 0.0001:\", test_score00001)\nprint (\"Number of features used: for alpha = 0.0001:\", coeff_used00001)\nprint (\"____________________________________________________________________________\")\nprint()\n\n\nlr = LogisticRegression()\nlr.fit(X_train_st,y_train)\nlr_train_score=lr.score(X_train_st,y_train)\nlr_test_score=lr.score(X_test_st,y_test)\nprint (\"Logistic Regression training score:\", lr_train_score)\nprint (\"Logistic Regression test score:\", lr_test_score)\nprint (\"____________________________________________________________________________\")\nprint()\n\nlr = LogisticRegression(random_state=0)\nlr.fit(X_train_st,y_train)\n# plot\nplt.subplot(1,2,1)\nplt.plot(lasso.coef_,alpha=0.7,linestyle='none',marker='*',markersize=6,color='red',label=r'Lasso; $\\alpha = 1$',zorder=7) # alpha here is for transparency\nplt.plot(lasso001.coef_,alpha=0.5,linestyle='none',marker='d',markersize=7,color='blue',label=r'Lasso; $\\alpha = 0.01$')\n\nplt.xlabel('Coefficient Index',fontsize=16)\nplt.ylabel('Coefficient Magnitude',fontsize=16)\nplt.legend(fontsize=13,loc=4)\nplt.subplot(1,2,2)\nplt.plot(lasso.coef_,alpha=0.7,linestyle='none',marker='*',markersize=6,color='red',label=r'Lasso; $\\alpha = 1$',zorder=7)\nplt.plot(lasso001.coef_,alpha=0.5,linestyle='none',marker='d',markersize=7,color='blue',label=r'Lasso; $\\alpha = 0.01$')\nplt.plot(lasso00001.coef_,alpha=0.8,linestyle='none',marker='v',markersize=7,color='black',label=r'Lasso; $\\alpha = 0.00001$')\nplt.plot(lr.coef_,alpha=0.7,linestyle='none',marker='o',markersize=6,color='green',label='Linear Regression',zorder=2)\nplt.xlabel('Coefficient Index',fontsize=16)\nplt.ylabel('Coefficient Magnitude',fontsize=16)\nplt.legend(fontsize=6,loc=4)\nplt.tight_layout()\nplt.show()","52aca022":"accuracy_list = []","77cc481e":"accuracy_list.append(auc_logreg)\naccuracy_list.append(auc_r_clf)\naccuracy_list.append(auc_decision_tree)\naccuracy_list.append(auc_logreg2)\naccuracy_list.append(auc_log_l1)\naccuracy_list.append(auc_log_l2)","9aad4e9e":"model_list=['Logistic Regression','Random Forest Classifier','Decision Tree Classifier','LR validation','LR L1','LR L2']","d2293d40":"plt.rcParams['figure.figsize']=20,8\nsns.set_style('darkgrid')\nax = sns.barplot(x=model_list, y=accuracy_list, palette = \"husl\", saturation =2)\nplt.xlabel('Classifier Models', fontsize = 20 )\nplt.ylabel('Value of ROC', fontsize = 20)\nplt.title('Receiver Operating Characteristic(ROC) value of different Classifier Models', fontsize = 20)\nplt.xticks(fontsize = 12, horizontalalignment = 'center', rotation = 8)\nplt.yticks(fontsize = 12)\nfor i in ax.patches:\n    width, height = i.get_width(), i.get_height()\n    x, y = i.get_xy() \n    ax.annotate(f'{round(height,4)}', (x + width\/2, y + height*1.02), ha='center', fontsize = 'x-large')\nplt.show()","835ba4e2":"accuracy_list2 = []","ec5cb681":"accuracy_list2.append(metrics.accuracy_score(y_test, y_pred))\naccuracy_list2.append(metrics.accuracy_score(y_test, r_pred))\naccuracy_list2.append(metrics.accuracy_score(y_test, d_pred))\naccuracy_list2.append(metrics.accuracy_score(y_test, y_pred2))\naccuracy_list2.append(metrics.accuracy_score(y_test, y_pred_l1))\naccuracy_list2.append(metrics.accuracy_score(y_test, y_pred_l2))","7a8b9f17":"model_list2=['Logistic Regression','Random Forest Classifier','Decision Tree Classifier','LR validation','LR L1','LR L2']","8194fe7c":"plt.rcParams['figure.figsize']=20,8\nsns.set_style('darkgrid')\nax = sns.barplot(x=model_list2, y=accuracy_list2, palette = \"husl\", saturation = 2)\nplt.xlabel('Classifier Models', fontsize = 20 )\nplt.ylabel('Value of accurancy', fontsize = 20)\nplt.title('Accurancy value of different Classifier Models', fontsize = 20)\nplt.xticks(fontsize = 12, horizontalalignment = 'center', rotation = 8)\nplt.yticks(fontsize = 12)\nfor i in ax.patches:\n    width, height = i.get_width(), i.get_height()\n    x, y = i.get_xy() \n    ax.annotate(f'{round(height,4)}', (x + width\/2, y + height*1.02), ha='center', fontsize = 'x-large')\nplt.show()","c5091b3b":"my_list_coef = []","e699cc02":"my_list_coef.append(logreg.coef_)\nmy_list_coef.append(logreg2.coef_)\nmy_list_coef.append(log_l1.coef_)\nmy_list_coef.append(log_l2.coef_)","cf1adf93":"my_list_coef.insert(0, 'Coef for Logistic Regression')\nmy_list_coef.insert(2, 'Coef for Logistic Regression with validation')\nmy_list_coef.insert(4, 'Coef for Logistic Regression with L1 penalty')\nmy_list_coef.insert(6, 'Coef for Logistic Regression with L2 penalty')","ccd9af8e":"my_list_coef","9d4dbdcc":"import itertools\n\ncolumn_names = ['Coef for Logistic Regression','Coef for Logistic Regression with validation','Coef for Logistic Regression with L1 penalty',\n               'Coef for Logistic Regression with L2 penalty']\nvalues = [logreg.coef_, logreg2.coef_, log_l1.coef_, log_l2.coef_]\n\nL = zip(itertools.cycle(column_names), values)\n\nfor g, v in itertools.groupby(sorted(L), lambda x: x[0]):\n    print(\"{} = {}\".format(g, [i[1] for i in v]))","a6e5f0b6":"# Split data to test and train","c2fe4ab1":"# Decision Tree Classifier","aa1b6610":"# Data visualization before analysis","e8b6cd5f":"# Standardization","7d2e1f7a":"# Loading base libraries","6c7e59b2":"# Logistic Regression","21e46e57":"# Random Forest Classifier","84d10873":"# Comparison of different Classifier Models","7128b4fa":"# Standard Imports of data","e3ca8bca":"Make a visualisation of 'age' variable in the same plot with the dependent variable.","6293c853":"# Pearson correlation","96a3eb6b":"# Validation","914eb800":"Looking at others independent variable in the same plot with the dependent variable.","3ee470f3":"Lasso regression","1d7f6b74":"# Visualizing the Decision Tree","92762803":"Looking at binaries independent variable in the same plot with the dependent variable.","f7aed584":"# L1 Regularization\/Lasso regression","e9143865":"Making a correlation between X train (independent) variables.","739ce202":"# L2 Regularization\/Ridge regression"}}