{"cell_type":{"7f1002e4":"code","f2ef8e5a":"code","963cd5b4":"code","cb314964":"code","c0a47505":"code","49d8e601":"code","b10f5807":"code","1ddd93f1":"code","2c301fb4":"code","f265841a":"code","73bc48ea":"code","39e0c2f0":"code","b5bbe58d":"code","e956378c":"code","375d4185":"code","582235bc":"code","01d62f28":"code","ec4fa8bc":"code","624480bd":"code","73e59bbe":"code","15e23cb0":"code","9334f147":"code","f3a71119":"code","c689ab79":"code","c1f15cf9":"code","8da9cca8":"code","8ba1ddbb":"code","8fc12bca":"code","4d05cd68":"code","20c89240":"code","29654a50":"code","05c6302a":"code","2cc00308":"code","3911b64c":"code","123cc3fb":"code","7f27de63":"code","9d47d365":"code","12b49f5c":"code","1c4c5eb2":"code","6118b20d":"code","81077051":"code","b3b5fd99":"code","d505e316":"code","19542352":"code","60482cfb":"code","22df53d8":"code","8fd60adc":"code","5e94b85c":"markdown","c5952d07":"markdown","c0821067":"markdown","0230bf0c":"markdown","be39d0a7":"markdown","591ab0c9":"markdown","aace9e51":"markdown","c78671b8":"markdown","8dda65bf":"markdown","46546c35":"markdown","18521efe":"markdown","abf9fbef":"markdown"},"source":{"7f1002e4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport math\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport time\n\nfrom datetime import timedelta\nfrom sklearn.linear_model import LinearRegression\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f2ef8e5a":"N = 3 # Number of previous data points to use to forecast confirmedcases\nN_ft = 5 # Number of previous data points to use to forecast fatalities\nN_rc = 3 # Number of previous data points to use to forecast recoveries\nz_val = 1.645 # For 90% confidence interval","963cd5b4":"def get_preds_lin_reg(series, pred_min, H):\n    \"\"\"\n    Given a dataframe, get prediction at timestep t using values from t-1, t-2, ..., t-N.\n    Inputs\n        series     : series to forecast\n        pred_min   : all predictions should be >= pred_min\n        H          : forecast horizon\n    Outputs\n        result: the predictions. The length of result is H. numpy array of shape (H,)\n    \"\"\"\n    # Create linear regression object\n    regr = LinearRegression(fit_intercept=True)\n\n    pred_list = []\n\n    X_train = np.array(range(len(series))) # e.g. [0 1 2 3 4]\n    y_train = np.array(series) # e.g. [2944 3088 3226 3335 3436]\n    X_train = X_train.reshape(-1, 1)     # e.g X_train = \n                                             # [[0]\n                                             #  [1]\n                                             #  [2]\n                                             #  [3]\n                                             #  [4]]\n    # X_train = np.c_[np.ones(N), X_train]              # add a column\n    y_train = y_train.reshape(-1, 1)\n    regr.fit(X_train, y_train)            # Train the model\n    pred = regr.predict(np.array(range(len(series),len(series)+H)).reshape(-1,1))\n    pred = pred.reshape(H,)\n    \n    # If the values are < pred_min, set it to be pred_min\n    pred[pred < pred_min] = pred_min\n        \n    return np.around(pred)","cb314964":"train = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-5\/train.csv')\n\n# Change column names to lower case\ntrain.columns = [col.lower() for col in train.columns]\n\n# Change to date format\ntrain['date'] = pd.to_datetime(train['date'], format='%Y-%m-%d')\n\ntrain","c0a47505":"test = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-5\/test.csv')\n\n# Change column names to lower case\ntest.columns = [col.lower() for col in test.columns]\n\n# Change to date format\ntest['date'] = pd.to_datetime(test['date'], format='%Y-%m-%d')\n\ntest","49d8e601":"submission = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-5\/submission.csv')\nsubmission","b10f5807":"# Get recovery data\n# url = 'https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_recovered_global.csv'\n# recov = pd.read_csv(url, error_bad_lines=False)\n\nrecov = pd.read_csv('..\/input\/time-series-covid19-recovered-global\/time_series_covid19_recovered_global.csv')\nrecov","1ddd93f1":"# Convert recoveries to the right format\nprovince_state = []\ncountry_region = []\ndate = []\nrecoveries = []\n\ndates = list(recov.columns[4:])\nfor index, row in recov.iterrows():\n    province_state = province_state + [row['Province\/State']]*len(dates)\n    country_region = country_region + [row['Country\/Region']]*len(dates)\n    date = date + dates\n    recoveries = recoveries + list(row[4:])\n    \nrecoveries_df = pd.DataFrame({'province_state': province_state,\n                              'country_region': country_region,\n                              'date': date,\n                              'recoveries_tot': recoveries})\n\n# Change to date format\nrecoveries_df['date'] = pd.to_datetime(recoveries_df['date'], format='%m\/%d\/%y')\n\n# Add a column 'county'\nrecoveries_df['county'] = 'nil'\n\n# Change NaN to nil\nrecoveries_df['province_state'] = recoveries_df['province_state'].fillna(value = 'nil')\n\nrecoveries_df","2c301fb4":"# Count number of nulls for each column\ntrain.isnull().sum(axis=0)","f265841a":"# Count number of nulls for each column\nrecoveries_df.isnull().sum(axis=0)","73bc48ea":"# Get the counties\nprint(len(train['county'].unique()))\nprint(train['county'].unique().tolist())","39e0c2f0":"# Get the province_states\nprint(len(train['province_state'].unique()))\ntrain['province_state'].unique()","b5bbe58d":"# Get the country_regions\nprint(len(train['country_region'].unique()))\ntrain['country_region'].unique()","e956378c":"# Get amount of data per country\ntrain['country_region'].value_counts()","375d4185":"train[train['country_region']=='Singapore']","582235bc":"# Plot the confirmed cases (daily) and fatalities (daily) in SEA\ncountries_list = ['Singapore', 'Malaysia', 'Indonesia', 'Thailand', 'Philippines', 'Brunei', 'Laos', 'Cambodia', 'New Zealand']\ncolor_list = ['r', 'g', 'b', 'k', 'c', 'y', 'm', '0.75', 'tab:blue']\n\nfig, axes = plt.subplots(2,1)\nax = train[(train['country_region']==countries_list[0]) & (train['target']=='ConfirmedCases') & (train['county'].isnull()) & (train['province_state'].isnull())].plot(ax=axes[0], x='date', y='targetvalue', color=color_list[0], marker='.', grid=True, figsize=(16, 8))\nax1 = train[(train['country_region']==countries_list[0]) & (train['target']=='Fatalities') & (train['county'].isnull()) & (train['province_state'].isnull())].plot(ax=axes[1], x='date', y='targetvalue', color=color_list[0], marker='.', grid=True)\n\ni = 1\nfor country in countries_list[1:]:\n    ax = train[(train['country_region']==country) & (train['target']=='ConfirmedCases') & (train['county'].isnull()) & (train['province_state'].isnull())].plot(x='date', y='targetvalue', color=color_list[i%len(color_list)], marker='.', grid=True, ax=ax)\n    ax1 = train[(train['country_region']==country) & (train['target']=='Fatalities') & (train['county'].isnull()) & (train['province_state'].isnull())].plot(x='date', y='targetvalue', color=color_list[i%len(color_list)], marker='.', grid=True, ax=ax1)\n    i = i + 1\n    \nax.set_xlabel(\"date\")\nax.set_ylabel(\"confirmedcases (daily)\")\nax.legend(countries_list, loc=2)\n\nax1.set_xlabel(\"date\")\nax1.set_ylabel(\"fatalities (daily)\")\nax1.legend(countries_list, loc=2)","01d62f28":"# Plot the confirmed cases (daily) and fatalities (daily) in big countries\ncountries_list = ['China', 'US', 'India', 'Italy', 'France', 'Iran']\ncolor_list = ['r', 'g', 'b', 'k', 'c', 'y', 'm', '0.75', 'tab:blue']\n\nfig, axes = plt.subplots(2,1)\nax = train[(train['country_region']==countries_list[0]) & (train['target']=='ConfirmedCases') & (train['county'].isnull()) & (train['province_state'].isnull())].plot(ax=axes[0], x='date', y='targetvalue', color=color_list[0], marker='.', grid=True, figsize=(16, 8))\nax1 = train[(train['country_region']==countries_list[0]) & (train['target']=='Fatalities') & (train['county'].isnull()) & (train['province_state'].isnull())].plot(ax=axes[1], x='date', y='targetvalue', color=color_list[0], marker='.', grid=True)\n\ni = 1\nfor country in countries_list[1:]:\n    ax = train[(train['country_region']==country) & (train['target']=='ConfirmedCases') & (train['county'].isnull()) & (train['province_state'].isnull())].plot(x='date', y='targetvalue', color=color_list[i%len(color_list)], marker='.', grid=True, ax=ax)\n    ax1 = train[(train['country_region']==country) & (train['target']=='Fatalities') & (train['county'].isnull()) & (train['province_state'].isnull())].plot(x='date', y='targetvalue', color=color_list[i%len(color_list)], marker='.', grid=True, ax=ax1)\n    i = i + 1\n    \nax.set_xlabel(\"date\")\nax.set_ylabel(\"confirmedcases (daily)\")\nax.legend(countries_list, loc=2)\n\nax1.set_xlabel(\"date\")\nax1.set_ylabel(\"fatalities (daily)\")\nax1.legend(countries_list, loc=2)","ec4fa8bc":"# Fill nans in province_state and county with ''\ntrain['province_state'] = train['province_state'].fillna(value = 'nil')\ntrain['county'] = train['county'].fillna(value = 'nil')\ntest['province_state'] = test['province_state'].fillna(value = 'nil')\ntest['county'] = test['county'].fillna(value = 'nil')","624480bd":"# Get unique combinations of province_state and country_region\nct_ps_cr_unique = train[['county', 'province_state', 'country_region']].drop_duplicates()\nct_ps_cr_unique","73e59bbe":"# Get number of days we need to predict\ndate_max_train = train[(train['province_state']=='nil') & \n                       (train['county']=='nil') & \n                       (train['country_region']=='Singapore')]['date'].max()\n\ndate_max_test = test[(test['province_state']=='nil') &\n                     (test['county']=='nil') &\n                     (test['country_region']=='Singapore')]['date'].max()\n\npred_days = (date_max_test - date_max_train).days\nprint(date_max_train, date_max_test, pred_days)","15e23cb0":"# Split train set\ntrain_cc = train[train['target']=='ConfirmedCases']\ntrain_ft = train[train['target']=='Fatalities']\ntrain_cc","9334f147":"# Do cumsum to get total cases\ntic = time.time()\ntrain_cc_tot = train_cc[(train_cc['county']==ct_ps_cr_unique.iloc[0]['county']) & \n                          (train_cc['province_state']==ct_ps_cr_unique.iloc[0]['province_state']) & \n                          (train_cc['country_region']==ct_ps_cr_unique.iloc[0]['country_region'])].copy()\ntrain_cc_tot.loc[:, 'targetvalue_tot'] = train_cc_tot['targetvalue'].cumsum()\n\ntrain_ft_tot = train_ft[(train_ft['county']==ct_ps_cr_unique.iloc[0]['county']) & \n                          (train_ft['province_state']==ct_ps_cr_unique.iloc[0]['province_state']) & \n                          (train_ft['country_region']==ct_ps_cr_unique.iloc[0]['country_region'])].copy()\ntrain_ft_tot.loc[:, 'targetvalue_tot'] = train_ft_tot['targetvalue'].cumsum()\n\nfor index, row in ct_ps_cr_unique[1:].iterrows():\n    train_cc_temp = train_cc[(train_cc['county']==row['county']) & \n                          (train_cc['province_state']==row['province_state']) & \n                          (train_cc['country_region']==row['country_region'])].copy()\n    train_cc_temp.loc[:, 'targetvalue_tot'] = train_cc_temp['targetvalue'].cumsum()\n    train_cc_tot = pd.concat([train_cc_tot, train_cc_temp], axis=0)\n    \n    train_ft_temp = train_ft[(train_ft['county']==row['county']) & \n                          (train_ft['province_state']==row['province_state']) & \n                          (train_ft['country_region']==row['country_region'])].copy()\n    train_ft_temp.loc[:, 'targetvalue_tot'] = train_ft_temp['targetvalue'].cumsum()\n    train_ft_tot = pd.concat([train_ft_tot, train_ft_temp], axis=0)\n\ntoc = time.time()\nprint(\"Time taken = \" + str((toc-tic)\/60.0) + \" mins\")\ntrain_cc_tot","f3a71119":"# Merge recoveries_df with train\ntrain_cc_tot_merged = train_cc_tot.merge(recoveries_df,\n                           left_on=['county', 'province_state', 'country_region', 'date'], \n                           right_on=['county', 'province_state', 'country_region', 'date'], \n                           how='left')\ntrain_cc_tot_merged","c689ab79":"# Count number of nulls for each column\ntrain_cc_tot_merged.isnull().sum(axis=0)","c1f15cf9":"# Fill recoveries nans with 0\ntrain_cc_tot_merged['recoveries_tot'] = train_cc_tot_merged['recoveries_tot'].fillna(value = 0)","8da9cca8":"# # Specify the country here\n# ct = 'nil'\n# ps = 'nil'\n# cr = 'Singapore'","8ba1ddbb":"# train_sgp = train_cc_tot[(train_cc_tot['county']==ct) & (train_cc_tot['province_state']==ps) & (train_cc_tot['country_region']==cr)]\n# train_sgp[-5:]","8fc12bca":"# # Get predictions \n# preds = get_preds_lin_reg(train_sgp['targetvalue_tot'][-N:], 0, pred_days)\n# preds","4d05cd68":"# # Put into dataframe\n# date_list = []\n# date = pd.date_range(date_max_train+timedelta(days=1), date_max_test)\n# results = pd.DataFrame({'date': date, 'preds':preds})\n# results.head()","20c89240":"# # Plot the confirmed cases in Singapore and the predictions\n# ax = train_cc_tot[(train_cc_tot['county']==ct) & (train_cc_tot['province_state']==ps) & (train_cc_tot['country_region']==cr)].plot(x='date', y='targetvalue_tot', style = 'r.-', grid=True, figsize=(10, 6))\n# ax = results.plot(x='date', y='preds', style = 'r.', grid=True, figsize=(10, 6), ax=ax)\n    \n\n# ax.set_xlabel(\"date\")\n# ax.set_ylabel(\"confirmed cases total\")\n# ax.legend([cr])","29654a50":"ct_list = []\nps_list = []\ncr_list = []\ndate_list = []\nconfirmedcasespred_list = []\nfatalities_list = []\nrecoveries_list = []\n\ntic = time.time()\nfor index, row in ct_ps_cr_unique.iterrows():\n    train_cc_temp = train_cc_tot[(train_cc_tot['county']==row['county']) &\n                                 (train_cc_tot['province_state']==row['province_state']) & \n                                 (train_cc_tot['country_region']==row['country_region'])]\n    preds = get_preds_lin_reg(train_cc_temp['targetvalue_tot'][-N:], 0, pred_days)\n    confirmedcasespred_list = confirmedcasespred_list + list(preds)\n    \n    train_ft_temp = train_ft_tot[(train_ft_tot['county']==row['county']) &\n                                 (train_ft_tot['province_state']==row['province_state']) & \n                                 (train_ft_tot['country_region']==row['country_region'])]\n    preds = get_preds_lin_reg(train_ft_temp['targetvalue_tot'][-N_ft:], 0, pred_days)\n    fatalities_list = fatalities_list + list(preds)\n    \n    train_cc_temp = train_cc_tot_merged[(train_cc_tot_merged['county']==row['county']) &\n                                        (train_cc_tot_merged['province_state']==row['province_state']) & \n                                        (train_cc_tot_merged['country_region']==row['country_region'])]\n    preds = get_preds_lin_reg(train_cc_temp['targetvalue_tot'][-N_rc:], 0, pred_days)\n    recoveries_list = recoveries_list + list(preds)\n    \n    ct_list = ct_list + ([row['county']]*pred_days)\n    ps_list = ps_list + ([row['province_state']]*pred_days)\n    cr_list = cr_list + ([row['country_region']]*pred_days)\n    date_list = date_list + list(pd.date_range(date_max_train+timedelta(days=1), date_max_test).strftime(\"%Y-%m-%d\"))\n    \n\nresults = pd.DataFrame({'county': ct_list,\n                        'province_state': ps_list,\n                        'country_region': cr_list,\n                        'date': date_list,\n                        'confirmedcases_tot': confirmedcasespred_list, \n                        'fatalities_tot': fatalities_list,\n                        'recoveries_tot': recoveries_list})\nresults['date'] = pd.to_datetime(results['date'], format='%Y-%m-%d')\n\ntoc = time.time()\nprint(\"Time taken = \" + str((toc-tic)\/60.0) + \" mins\")\nresults","05c6302a":"# Get rows where recoveries > confirmedcases\nx = results[results['recoveries_tot'] > results['confirmedcases_tot']]\nprint(x.to_string())","2cc00308":"# For each country, if recoveries > confirmedcases, confirmedcases should stop increasing.\n# e.g.\n# province          country     date        confirmedcases     fatalities      recoveries\n# South Australia\tAustralia\t2020-04-20\t439.0              4.0             425.0\n# South Australia\tAustralia\t2020-04-21\t440.0              4.0             460.0\n# South Australia\tAustralia\t2020-04-22\t441.0              4.0             494.0\n# should become\n# province          country     date        confirmedcases     fatalities      recoveries\n# South Australia\tAustralia\t2020-04-20\t439.0              4.0             425.0\n# South Australia\tAustralia\t2020-04-21\t440.0              4.0             460.0\n# South Australia\tAustralia\t2020-04-22\t440.0              4.0             494.0       # here confirmedcases stopped increasing\ndef confirmedcases_stop(df):\n    # Check if any rows where recoveries > confirmedcases\n    if len(df[df['recoveries_tot']>df['confirmedcases_tot']])==0:\n        return df\n    else:\n        # Extract the confirmedcases at the date where recoveries > confirmedcases\n        confirmedcases_sat = df[df['recoveries_tot']>df['confirmedcases_tot']]['confirmedcases_tot'].iloc[0]\n        \n        # For all rows where recoveries > confirmedcases, set confirmedcases = confirmedcases_max\n        df.loc[df['recoveries_tot']>df['confirmedcases_tot'], 'confirmedcases_tot'] = confirmedcases_sat\n        \n        return df\n\ntemp = results[(results['county']==ct_ps_cr_unique.iloc[0]['county']) & \n               (results['province_state']==ct_ps_cr_unique.iloc[0]['province_state']) & \n               (results['country_region']==ct_ps_cr_unique.iloc[0]['country_region'])].copy()\nresults_sat = confirmedcases_stop(temp)\n    \ntic = time.time()\nfor index, row in ct_ps_cr_unique[1:].iterrows():\n    temp = results[(results['county']==row['county']) & \n                   (results['province_state']==row['province_state']) & \n                   (results['country_region']==row['country_region'])].copy()\n    ps_cr_df = confirmedcases_stop(temp)\n    results_sat = pd.concat([results_sat, ps_cr_df], axis=0) \ntoc = time.time()\nprint(\"Time taken = \" + str((toc-tic)\/60.0) + \" mins\")\n    \nresults_sat","3911b64c":"train_cc_tot","123cc3fb":"# Get daily ConfirmedCases, Fatalities\nresults_sat_daily = pd.DataFrame()\n\nfor index, row in ct_ps_cr_unique.iterrows():\n    temp = results_sat[(results_sat['county']==row['county']) & \n                   (results_sat['province_state']==row['province_state']) & \n                   (results_sat['country_region']==row['country_region'])].copy()\n    \n    temp['ConfirmedCases'] = temp['confirmedcases_tot'].diff()\n    temp['Fatalities'] = temp['fatalities_tot'].diff()\n    \n    # Get first value for ConfirmedCases\n    train_cc_temp = train_cc_tot[(train_cc_tot['county']==row['county']) &\n                                 (train_cc_tot['province_state']==row['province_state']) & \n                                 (train_cc_tot['country_region']==row['country_region'])]    \n    temp.loc[temp.index[0], 'ConfirmedCases'] = temp.loc[temp.index[0], 'confirmedcases_tot'] - \\\n                                                train_cc_temp.loc[train_cc_temp.index[-1], 'targetvalue_tot']\n    \n    # Get first value for Fatalities\n    train_ft_temp = train_ft_tot[(train_ft_tot['county']==row['county']) &\n                                 (train_ft_tot['province_state']==row['province_state']) & \n                                 (train_ft_tot['country_region']==row['country_region'])]    \n    temp.loc[temp.index[0], 'Fatalities'] = temp.loc[temp.index[0], 'fatalities_tot'] - \\\n                                                train_ft_temp.loc[train_ft_temp.index[-1], 'targetvalue_tot']\n    \n    results_sat_daily = results_sat_daily.append(temp)\n    \nresults_sat_daily","7f27de63":"# Use 20% of train_cc_tot to calculate the std dev of the pred error\ndate_max_train = train[(train['province_state']=='nil') & \n                       (train['county']=='nil') & \n                       (train['country_region']=='Singapore')]['date'].max()\n\ndate_min_train = train[(train['province_state']=='nil') &\n                     (train['county']=='nil') &\n                     (train['country_region']=='Singapore')]['date'].min()\n\ndiff_days = (date_max_train - date_min_train).days\ntrain_size = int(0.8*diff_days)\nval_size = diff_days - train_size\ntrain_size, val_size","9d47d365":"def saturate(cc, rc):\n    \"\"\"\n    If rc > cc, then cc should saturate\n    e.g.\n    cc = np.array([1, 2, 3])\n    rc = np.array([1, 3, 4])\n    Return np.array([1, 2, 2])\n    \"\"\"\n    if sum(rc>cc)==0:\n        return cc\n    else:\n        sat_value = rc[np.argmax((rc>cc)==True)]\n        cc[rc>cc] = sat_value\n        return cc\n    ","12b49f5c":"ct_list = []\nps_list = []\ncr_list = []\ncc_stddev_list = []\nft_stddev_list = []\n\ntic = time.time()\nfor index, row in ct_ps_cr_unique.iterrows():\n    # Predict confirmedcases\n    train_cc_tr = train_cc_tot[(train_cc_tot['county']==row['county']) &\n                               (train_cc_tot['province_state']==row['province_state']) & \n                               (train_cc_tot['country_region']==row['country_region'])][:train_size]\n    train_cc_val = train_cc_tot[(train_cc_tot['county']==row['county']) &\n                                (train_cc_tot['province_state']==row['province_state']) & \n                                (train_cc_tot['country_region']==row['country_region'])][train_size:]\n    preds = get_preds_lin_reg(train_cc_tr['targetvalue_tot'][-N:], 0, len(train_cc_val))\n    \n    # Predict recoveries\n    train_cc_tr = train_cc_tot_merged[(train_cc_tot_merged['county']==row['county']) &\n                               (train_cc_tot_merged['province_state']==row['province_state']) & \n                               (train_cc_tot_merged['country_region']==row['country_region'])][:train_size]\n    preds_recov = get_preds_lin_reg(train_cc_tr['recoveries_tot'][-N_rc:], 0, len(train_cc_val))\n    preds = saturate(preds, preds_recov)\n    cc_stddev_list = cc_stddev_list + [np.std(preds - train_cc_val['targetvalue_tot'])]\n\n    # Predict fatalities\n    train_ft_tr = train_ft_tot[(train_ft_tot['county']==row['county']) &\n                               (train_ft_tot['province_state']==row['province_state']) & \n                               (train_ft_tot['country_region']==row['country_region'])][:train_size]\n    train_ft_val = train_ft_tot[(train_ft_tot['county']==row['county']) &\n                                (train_ft_tot['province_state']==row['province_state']) & \n                                (train_ft_tot['country_region']==row['country_region'])][train_size:]\n    preds = get_preds_lin_reg(train_ft_tr['targetvalue_tot'][-N_ft:], 0, len(train_ft_val))\n    ft_stddev_list = ft_stddev_list + [np.std(preds - train_ft_val['targetvalue_tot'])]\n\n    ct_list = ct_list + [row['county']]\n    ps_list = ps_list + [row['province_state']]\n    cr_list = cr_list + [row['country_region']]\n    \n\nresults = pd.DataFrame({'county': ct_list,\n                        'province_state': ps_list,\n                        'country_region': cr_list,\n                        'cc_stddev': cc_stddev_list, \n                        'ft_stddev': ft_stddev_list})\ntoc = time.time()\nprint(\"Time taken = \" + str((toc-tic)\/60.0) + \" mins\")\nresults","1c4c5eb2":"results_sat_daily_ci = pd.DataFrame()\n\ntic = time.time()\nfor index, row in ct_ps_cr_unique.iterrows():\n    temp = results_sat_daily[(results_sat_daily['county']==row['county']) & \n                             (results_sat_daily['province_state']==row['province_state']) & \n                             (results_sat_daily['country_region']==row['country_region'])].copy()\n    \n    cc_stddev = results[(results['county']==row['county']) & \n                        (results['province_state']==row['province_state']) & \n                        (results['country_region']==row['country_region'])]['cc_stddev']\n    \n    ft_stddev = results[(results['county']==row['county']) & \n                        (results['province_state']==row['province_state']) & \n                        (results['country_region']==row['country_region'])]['ft_stddev']\n    \n    results_sat_daily_ci = pd.concat([results_sat_daily_ci, temp], axis=0) \n\ntoc = time.time()\nprint(\"Time taken = \" + str((toc-tic)\/60.0) + \" mins\")\nresults_sat_daily_ci","6118b20d":"# Melt the dataframe from a wide dataframe to a long dataframe\nresults_sat_daily_ci_melt = pd.melt(results_sat_daily_ci, \n                                    id_vars=['county', 'province_state', 'country_region', 'date'], \n                                    value_vars=['ConfirmedCases', 'Fatalities'])\nresults_sat_daily_ci_melt.sort_values(['country_region', 'date'], inplace=True)\nresults_sat_daily_ci_melt","81077051":"# Merge test with results\ntest_merged = test.merge(results_sat_daily_ci_melt,\n                           left_on=['county', 'province_state', 'country_region', 'date', 'target'], \n                           right_on=['county', 'province_state', 'country_region', 'date', 'variable'], \n                           how='left')\ntest_merged.drop(['variable', 'population', 'weight'], axis=1, inplace=True)\ntest_merged","b3b5fd99":"# Merge test with train\ntest_merged2 = test_merged.merge(train,\n                           left_on=['county', 'province_state', 'country_region', 'date', 'target'], \n                           right_on=['county', 'province_state', 'country_region', 'date', 'target'], \n                           how='left')\ntest_merged2.drop(['id', 'population', 'weight'], axis=1, inplace=True)\ntest_merged2","d505e316":"# Create column TargetValue\ntest_merged2['TargetVal'] = test_merged2.apply(lambda row: row['targetvalue'] if pd.isnull(row['value']) else row['value'], axis=1)\ntest_merged2.drop(['value', 'targetvalue'], axis=1, inplace=True)\ntest_merged2","19542352":"# Get 90% CI\ntest_merged2_ci = pd.DataFrame()\n\ntic = time.time()\nfor index, row in ct_ps_cr_unique.iterrows():\n    temp_cc = test_merged2[(test_merged2['county']==row['county']) & \n                             (test_merged2['province_state']==row['province_state']) & \n                             (test_merged2['country_region']==row['country_region']) & \n                             (test_merged2['target']=='ConfirmedCases')].copy()\n    \n    temp_ft = test_merged2[(test_merged2['county']==row['county']) & \n                             (test_merged2['province_state']==row['province_state']) & \n                             (test_merged2['country_region']==row['country_region']) & \n                             (test_merged2['target']=='Fatalities')].copy()\n    \n    cc_stddev = results[(results['county']==row['county']) & \n                        (results['province_state']==row['province_state']) & \n                        (results['country_region']==row['country_region'])]['cc_stddev']\n    \n    ft_stddev = results[(results['county']==row['county']) & \n                        (results['province_state']==row['province_state']) & \n                        (results['country_region']==row['country_region'])]['ft_stddev']\n    \n    temp_cc['low'] = (temp_cc['TargetVal'] - (z_val*cc_stddev.values[0]\/math.sqrt(val_size))).astype(int)\n    temp_cc['low'] = temp_cc['low'].apply(lambda row: max(0, row))\n    \n    temp_cc['high'] = (temp_cc['TargetVal'] + (z_val*cc_stddev.values[0]\/math.sqrt(val_size))).astype(int)\n    \n    temp_ft['low'] = (temp_ft['TargetVal'] - (z_val*ft_stddev.values[0]\/math.sqrt(val_size))).astype(int)\n    temp_ft['low'] = temp_ft['low'].apply(lambda row: max(0, row))\n    \n    temp_ft['high'] = (temp_ft['TargetVal'] + (z_val*ft_stddev.values[0]\/math.sqrt(val_size))).astype(int)\n    \n    temp = pd.concat([temp_cc, temp_ft], axis=0)\n    temp.sort_values(['date', 'target'], inplace=True)\n    \n    test_merged2_ci = pd.concat([test_merged2_ci, temp], axis=0) \n\ntoc = time.time()\nprint(\"Time taken = \" + str((toc-tic)\/60.0) + \" mins\")\ntest_merged2_ci","60482cfb":"# Create ForecastID_Quantile column\ntest_merged2_ci['ForecastID_Quantile'] = test_merged2_ci.apply(lambda row: [str(row['forecastid'])+'_0.05', str(row['forecastid'])+'_0.5', str(row['forecastid'])+'_0.95'], axis=1)\ntest_merged2_ci['TargetValue'] = test_merged2_ci.apply(lambda row: [row['low'], row['TargetVal'], row['high']], axis=1)\ntest_merged2_ci","22df53d8":"# Explode \nsubmission = test_merged2_ci[['ForecastID_Quantile', 'TargetValue']].apply(pd.Series.explode)\nsubmission","8fd60adc":"# Test submission\nsubmission.to_csv(\"submission.csv\", index=False)","5e94b85c":"# Pre-process train, test","c5952d07":"# Prepare submission file","c0821067":"# Load data","0230bf0c":"# Load recoveries data","be39d0a7":"# Predictions for confirmedcases, fatalities, recoveries","591ab0c9":"# EDA","aace9e51":"# Prediction for one country","c78671b8":"# Get 90% confidence intervals of the predictions","8dda65bf":"# Get std dev of the predictions for confirmedcases, fatalities, recoveries","46546c35":"# Common functions","18521efe":"# Problem Statement\n\nThis is week 5 of Kaggle's COVID19 forecasting series.\n\nHere we also forecast each country's recovery rate. If forecasted recoveries > forecasted confirmed cases, this means the curve for forecasted confirmedcases have flattened and will be adjusted.","abf9fbef":"Why are there negative values in the targetvalues?"}}