{"cell_type":{"95faf410":"code","1290351d":"code","98c57bba":"code","ea6f6f9e":"code","a93d7e9d":"code","86751b72":"code","fb959335":"code","dcd809d0":"code","b07e7057":"code","0bc97ea7":"code","75aa5729":"code","5da60b01":"code","e89e5751":"code","5b63ddb0":"code","7298f445":"code","247c596d":"code","2b4f6e68":"code","7eca9aca":"markdown","0023e8d1":"markdown","7ebc3237":"markdown","0064486e":"markdown","3e940016":"markdown","7ed6006e":"markdown","a8f6fe0f":"markdown","e0d4b0de":"markdown"},"source":{"95faf410":"#shap!!\nimport shap\n\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, MaxPool2D, BatchNormalization","1290351d":"train_df = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","98c57bba":"X = (train_df.iloc[:,1:].values).astype('float32')\nY = train_df.iloc[:,0].values.astype('int32')\ntest = test_df.values.astype('float32')","ea6f6f9e":"X = X.reshape(X.shape[0], 28, 28, 1)\nY = to_categorical(Y)\ntest = test.reshape(test.shape[0], 28, 28, 1)","a93d7e9d":"#Confirm the image.\nplt.imshow(X[0].reshape(28,28))\nplt.show()","86751b72":"X = X.astype(\"float32\") \/ 255\ntest = test.astype(\"float32\") \/ 255","fb959335":"X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.1, random_state=0)","dcd809d0":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(X_train)","b07e7057":"model = Sequential()\n\nmodel.add(Conv2D(32, kernel_size = 4, activation=\"relu\", input_shape=(28,28,1)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(64, kernel_size = 3, activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(64, kernel_size = 2, activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\", metrics=['accuracy'])\n\nmodel.summary()","0bc97ea7":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","75aa5729":"batch_size = 64\nepochs = 30\n\nhist = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val),\n                              verbose = 2, steps_per_epoch=X_train.shape[0] \/\/ batch_size\n                              , callbacks=[learning_rate_reduction])","5da60b01":"plt.figure(figsize=(8, 4))\nplt.plot(hist.history[\"loss\"])\nplt.title(\"Loss\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Train\", \"Test\"])\nplt.show()\n\npred = model.predict(X_val)\n\ntest_loss, test_acc = model.evaluate(X_val, Y_val, verbose=0)\nprint(f'\\nTest accuracy: {test_acc}')","e89e5751":"Y_pred_classes = np.argmax(pred,axis = 1) \nY_true = np.argmax(Y_val,axis = 1)","5b63ddb0":"errors = (Y_pred_classes - Y_true != 0)\n\nY_pred_classes_errors = Y_pred_classes[errors]\nY_pred_errors = pred[errors]\nY_true_errors = Y_true[errors]\nX_val_errors = X_val[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 10 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 5\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True,figsize=(20, 8))\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n    plt.show()\n    \nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\nmost_important_errors = sorted_dela_errors[-10:]\n\ndisplay_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)","7298f445":"#When describing Deep Learning, we use DeepExplainer.\nexplainer = shap.DeepExplainer(model, (X[0:1000]))\n\n#Check out the 10 data that the model has mistakenly predicted.\nfor i in most_important_errors:\n    \n    #Calculates the SHAP value.\n    shap_values = explainer.shap_values(X_val_errors[[i]])\n    \n    #The following two lines are extras. It works even if you turn it off.\n    index_names = np.array([str(x) + \"\\n\" + '{:>7.3%}'.format(Y_pred_errors[i][x]) for x in range(10)]).reshape(1,10)\n    print(\"Predicted label :{}\\nTrue label :{}\".format(Y_pred_classes_errors[i],Y_true_errors[i]))\n    \n    #Displays the results.\n    shap.image_plot(shap_values, X_val_errors[[i]] ,index_names ,show=False)\n    plt.show()","247c596d":"results = model.predict(test)\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")","2b4f6e68":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"cnn_mnist_datagen.csv\",index=False)","7eca9aca":"# 4, Check error\nCheck the prediction results that were wrong.","0023e8d1":"# 2, Load data\nThe process is the same as usual.","7ebc3237":"# 5, SHAP value\nNow it's time for the SHAP, to calculate the SHAP value and see where the model sees it and what it expects.","0064486e":"The blue areas are pixels that were not what model would have expected as its label. The red areas are the opposite of that.\n\nFocusing on these areas may help to further improve the accuracy of the model.","3e940016":"# 6, submission\nI'm going to submit it. Thank you for taking the time to watch it to the end.","7ed6006e":"# 0, Introduction\nThe MNIST data are predicted using CNN and then the predicted results are explained using SHAP.\n\n**I won't go into how it works. Usage only.**\n\nIf you only want to see how to use SHAP, please refer to 5, as it is basically the same as usual until the model is created.","a8f6fe0f":"# 3, Define the CNN model\nBy the way, When I use the BATCH NORMARIZER, which is very popular nowadays, I get an error when I get a shap value...\n\n(\u21d2LookupError: gradient registry has no entry for: shap_FusedBatchNormV3)\n\nThat's why I don't use BATCH NORMARIZER.","e0d4b0de":"# 1, import library\nThe only library required by shap is \"shap\". It's simple."}}