{"cell_type":{"b8c4f1de":"code","9a81b1eb":"code","7026db22":"code","46b85e29":"code","d52fcdfc":"code","0884447d":"code","9117384e":"code","4f9be8c9":"code","6dcba249":"code","412ff8e3":"code","53621363":"code","531cfb08":"code","9c4ffcf2":"code","559e4c28":"code","83aee7c1":"code","b1c0c146":"code","bcfe92f7":"code","18a83526":"markdown","cf1cd0ec":"markdown","b87ba034":"markdown","cad9f23f":"markdown","f537388c":"markdown"},"source":{"b8c4f1de":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9a81b1eb":"df=pd.read_csv('\/kaggle\/input\/cusersmarildownloadsgermancsv\/german.csv',encoding ='ISO-8859-1',sep=\";\")\ndf.head()","7026db22":"#Code by Ram Seshadri (RSESHA) https:\/\/www.kaggle.com\/rsesha\/elo-with-deep-autoviml-dropping-inf-rows\/notebook\n\nimport copy\ndef FE_drop_rows_with_infinity(df, fill_value=None):\n    # first you must drop rows that have inf in them ####\n    corr_list_copy = copy.deepcopy(df.columns)\n    init_rows = df.shape[0]\n    if fill_value:\n        for col in corr_list_copy:\n            df.loc[df[col]==np.inf, col] = fill_value\n            df.loc[df[col]==-np.inf, col] = -fill_value\n        print('All rows with infinite values filled with %s' %fill_value)\n    else:\n        for col in corr_list_copy:\n            df = df[df[col]!=np.inf]\n            df = df[df[col]!=-np.inf]\n        dropped_rows = init_rows - df.shape[0]\n        print('Dropped %d rows due to infinite values in data' %dropped_rows)\n    print('Shape of dataset remaining: %s' %(df.shape,))\n    return df","46b85e29":"df.max()","d52fcdfc":"#train = FE_drop_rows_with_infinity(train, 1000)   We don`t need that since we don`t have infinite numbers","0884447d":"!pip install deep_autoviml --upgrade","9117384e":"target = \"Creditability\"","4f9be8c9":"from deep_autoviml import deep_autoviml as deepauto","6dcba249":"#Code by Ram Seshadri (RSESHA) https:\/\/www.kaggle.com\/rsesha\/elo-with-deep-autoviml-dropping-inf-rows\/notebook\n\n#D E F A U L T S    S E T T I N G S   F O R   D E E P    A U T O  V I M L \nkeras_model_type =  \"fast1\" ## always try \"fast\" first, then \"fast2\", \"auto\", etc.\n### always set early_stopping to True first and then change it to False\n#### You always need 15 max_trials to get something decent #####\n#### always set tuner to \"storm\" and then \"optuna\". \n### NLP char limit kicks off NLP processing. Feature Cross later.\nproject_name = \"Elo\"\nmodel_options = {'nlp_char_limit':50, 'cat_feat_cross_flag':False,\n                 'max_trials': 10, \"tuner\": \"storm\"}\nkeras_options = {\"patience\":10, 'class_weight': True, 'early_stopping': True, \n                 'lr_scheduler': '', \"optimizer\": 'RMS'}","412ff8e3":"#Code by Ram Seshadri (Rsesha) https:\/\/www.kaggle.com\/rsesha\/elo-with-deep-autoviml-dropping-inf-rows\/notebook\n\n#I reduced the number of features, just to see how the model operates with Deep AutoViML.\n\nnumcols = ['Account_Balance', 'Duration_of_Credit_monthly', 'Payment_Status_of_Previous_Credit', 'Credit_Amount', 'Sex_Marital_Status', 'Guarantors', 'Most_valuable_available_asset', 'Age_years',\n           'Occupation', 'No_of_dependents']\nlen(numcols)","53621363":"#Code by Ram Seshadri (Rsesha) https:\/\/www.kaggle.com\/rsesha\/elo-with-deep-autoviml-dropping-inf-rows\/notebook\n\nfor col in numcols:\n    df[col] = df[col].astype(float)\n    #test[col] = test[col].astype(float)","531cfb08":"#Code by Ram Seshadri (Rsesha) https:\/\/www.kaggle.com\/rsesha\/elo-with-deep-autoviml-dropping-inf-rows\/notebook\n\nmodel, cat_vocab_dict = deepauto.fit(df, target, keras_model_type=keras_model_type,\n                                     project_name=project_name, keras_options=keras_options,  \n                                     model_options=model_options, save_model_flag=False, use_my_model='',\n                                     model_use_case='', verbose=1)","9c4ffcf2":"#Code by Ram Seshadri (Rsesha) https:\/\/www.kaggle.com\/rsesha\/elo-with-deep-autoviml-dropping-inf-rows\/notebook\n\n#We don't have test (test_dataset=df)\n\npredictions = deepauto.predict(model, project_name, test_dataset=df,\n                                 keras_model_type=keras_model_type, \n                                 cat_vocab_dict=cat_vocab_dict)","559e4c28":"y_preds = predictions[-1]\ny_preds[:15]","83aee7c1":"#Code by Ram Seshadri (Rsesha) https:\/\/www.kaggle.com\/rsesha\/elo-with-deep-autoviml-dropping-inf-rows\/notebook\n\npreds = pd.Series(y_preds)\npreds.loc[pd.Series(y_preds).isnull()] = 0\npreds","b1c0c146":"#sample_submission = pd.read_csv('\/kaggle\/input\/elo-merchant-category-recommendation\/sample_submission.csv')","bcfe92f7":"#sample_submission['target'] = preds.values\n#sample_submission.to_csv('submission_2.csv', index=False)","18a83526":" <h1 style=\"background-color:#DC143C; font-family:'Brush Script MT',cursive;color:white;font-size:200%; text-align:center;border-radius: 50% 20% \/ 10% 40%\">Deep_Autoviml by Ram Seshadri<\/h1>\n \n Deep_Autoviml is a powerful new deep learning library with a very simple design goal: \n \n \"Make it as easy as possible for novices and experts alike to experiment with and build tensorflow.keras preprocessing pipelines and models in as few lines of code as possible.\"\n \n\"Deep_Autoviml is a tensorflow >2.4-enabled, keras-ready, model and pipeline building utility. deep autoviml is meant for data engineers, data scientists and ml engineers to quickly prototype and build tensorflow 2.4.1+ models and pipelines for any data set, any size using a single line of code. It can build models for structured data, NLP and image datasets. It can also handle time series data sets. You can either choose deep_autoviml to automatically buid a custom Tensorflow model or you can \"bring your own model\" (\"BYOM\" option) model to attach keras data pipelines to your model. Additionally, you can choose any Tensorflow Hub model (TFHub) to train on your data. Just see the instructions below in \"Tips for using deep_autoviml\" section.\"\n\nhttps:\/\/pypi.org\/project\/deep-autoviml\/","cf1cd0ec":"#Thank you Ram Seshadri (RSESHA) for the script and for developing Deep AutoViML.","b87ba034":"Only credit_amount has high values.","cad9f23f":"#Deep AutoViML - End to End AutoML for Deep Learning with Ram Seshadri (RSESHA)\n\n![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcTavwkH0hAoks0Bcjf1iQU7aAAWuEfQ8ZVsJfwIStX5Dvkx32KDh_DKmerjHulpOvHB2H4&usqp=CAU)youtube.com","f537388c":"#Code by Ram Seshadri (Rsesha)  https:\/\/www.kaggle.com\/rsesha\/elo-with-deep-autoviml-dropping-inf-rows\/notebook"}}