{"cell_type":{"7dc89044":"code","66a08fe0":"code","e8437d39":"code","1b0207d2":"code","30919a12":"code","176fb196":"code","ac3433b8":"code","9075ec6a":"code","41c50dd4":"code","c222a513":"code","0f7b02d6":"code","65604a95":"markdown","90e0c900":"markdown","e3baea94":"markdown","39d697f1":"markdown","133fb33d":"markdown","704f8225":"markdown","b4f0a993":"markdown"},"source":{"7dc89044":"import json\nwith open(\"\/kaggle\/input\/medical-ner\/Corona2.json\") as f:\n    annotation = json.load(f)","66a08fe0":"TRAIN_DATA  = []\nfor e in annotation[\"examples\"]:\n    content = e[\"content\"]\n    entities = []\n    for an in e[\"annotations\"]:        \n        if len(an[\"value\"]) == len(an[\"value\"].strip()):          \n            if len(an['human_annotations']) == 0:\n                continue\n            info = (an[\"start\"],an[\"end\"],an[\"tag_name\"])\n            entities.append(info)\n            #print(an[\"start\"],an[\"end\"],an[\"tag_name\"])\n    if len(entities) > 0:\n        TRAIN_DATA.append(([content,{\"entities\":entities}]))    ","e8437d39":"from __future__ import unicode_literals, print_function\nimport random\nfrom pathlib import Path\nfrom spacy.util import minibatch, compounding\nimport spacy\nimport sys","1b0207d2":"spacy.util.use_gpu(0)\ndef train_model(model=None, output_dir=\"\/kaggle\/working\/medical-ner\", n_iter=1000):\n    if model is not None:\n        nlp = spacy.load(model)  # load existing spaCy model\n        print(\"Loaded model '%s'\" % model)\n    else:\n        nlp = spacy.blank(\"en\")  # create blank Language class\n        print(\"Created blank 'en' model\")\n\n    if \"ner\" not in nlp.pipe_names:\n        ner = nlp.create_pipe(\"ner\")\n        nlp.add_pipe(ner, last=True)\n    else:\n        ner = nlp.get_pipe(\"ner\")\n\n    for _, annotations in TRAIN_DATA:\n        for ent in annotations.get(\"entities\"):\n            ner.add_label(ent[2])\n\n    pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n    with nlp.disable_pipes(*other_pipes):  # only train NER\n        if model is None:\n            nlp.begin_training(device=0)\n        for itn in range(n_iter):\n            random.shuffle(TRAIN_DATA)\n            losses = {}\n            batches = minibatch(TRAIN_DATA, size=compounding(4.0, 64.0, 1.2))\n            for batch in batches:\n                texts, annotations = zip(*batch)\n                nlp.update(\n                    texts,  \n                    annotations,  \n                    drop=0.20, \n                    losses=losses\n                   \n                )\n            print(\"Losses\", losses)\n\n    # save model to output directory\n    if output_dir is not None:\n        output_dir = Path(output_dir)\n        if not output_dir.exists():\n            output_dir.mkdir()\n        nlp.to_disk(output_dir)\n        print(\"Saved model to\", output_dir)","30919a12":"train_model()","176fb196":"nlp2 = spacy.load(\"\/kaggle\/working\/medical-ner\")","ac3433b8":"import numpy as np\nimport pandas as pd\nimport os\nimport json\nimport random\n\nfiles = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/CORD-19-research-challenge\/'):\n    for filename in filenames:\n        if \".json\" in filename:           \n            fpath = os.path.join(dirname, filename)\n            if len(files) < 300:\n                files.append(fpath)\nrandom.shuffle(files)","9075ec6a":"output = []\nentities = []\nfor i in range(0,len(files)):\n    if i%100 == 0:\n        print('completed ', i)\n    with open(files[i]) as f:\n        file_data = json.load(f)        \n    for o in file_data[\"body_text\"]: \n            doc = nlp2(o[\"text\"],disable=['parser','tagger'])\n            for ent in doc.ents:\n                if len(ent.text) > 2:\n                    entities.append((ent.text, ent.label_))","41c50dd4":"from collections import Counter\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams['figure.figsize'] = [12, 6]\npathogens = [l[0] for l in entities if l[1] == 'Pathogen']\ncounts = Counter(pathogens)\ncounts = {x : counts[x] for x in counts if counts[x] >= 20}\nplt.title(\"Pathogens detected so far !\")\nplt.xticks(rotation='vertical')\nplt.bar(counts.keys(),counts.values())\nplt.show()\nplt.savefig('path.png')","c222a513":"medical_conds = [l[0] for l in entities if l[1] == 'MedicalCondition']\ncounts = Counter(medical_conds)\ncounts = {x : counts[x] for x in counts if counts[x] >=20 and len(x) > 4}\nplt.xticks(rotation='vertical')\nplt.title(\"Medical Conditions detected so far !\")\nplt.bar(counts.keys(),counts.values(),color =\"g\")\nplt.show()\nplt.savefig('mc.png')","0f7b02d6":"medicines = [l[0] for l in entities if l[1] == 'Medicine']\ncounts = Counter(medicines)\ncounts = {x : counts[x] for x in counts if counts[x] >=35 and len(x) > 4}\n#plt.xticks(counts.keys(),rotation='vertical')\nplt.xticks(rotation='vertical')\nplt.title(\"Medicines detected so far !\")\nplt.bar(counts.keys(),counts.values(),color=\"y\")\nplt.show()\nplt.savefig('med.png')","65604a95":"# Things to improve upon\n\n* An accurate NER tagger is key to my approach. However, it is difficult to create a manually tagged corpus single handedly. Need to collobrate on this with community !\n\n* Create a scheme to augument the manually labelled data and expand training data\n\n* Spacy does not give any 'confidence' measure along with NER tagging. This makes it impossible to apply a threshould and filter out unimportant or wrongly identified entities. Maybe using some library as a base may help !\n\n* Implement mechanisms to check the accuracy of NER tagging after training. Currently it does work, but not sure how well !","90e0c900":"# Introduction\n> This book is part of a detailed writeup on analyzing the [CORD 19 Research Challenge](https:\/\/www.kaggle.com\/allen-institute-for-ai\/CORD-19-research-challenge) dataset . Please [visit this link](https:\/\/www.kaggle.com\/finalepoch\/cord-19-research-dataset-analysis-visualization) for the main page which contains more information and context.\n\nIn this notebook I have tried to create a Named Entity Recognition system for analyzing the [CORD 19 Research Challenge](https:\/\/www.kaggle.com\/allen-institute-for-ai\/CORD-19-research-challenge) dataset. I am tyring to use Spacy's [custom named entity recognition](https:\/\/spacy.io\/usage\/training\/) to train a model that can detect mentions of three things in text:\n* MedicalCondition\n* Medicine\n* Pathogen\n\nI have currently used [LightTag](https:\/\/www.lighttag.io\/) for creating a manually tagged corpus from randomly selected text from Wikipedia. The dataset is available here : [https:\/\/www.kaggle.com\/finalepoch\/medical-ner](https:\/\/www.kaggle.com\/finalepoch\/medical-ner)\n","e3baea94":"## Plot the results on sample dataset (where count > n)","39d697f1":"## Train Spacy model\nI am currently using a blank spacy model. I have tried using 'en_core_web_sm' and 'en_core_web_lg', but it doesnt result in any dramatic improvement. \n\n> There is a lot of scope for experimenting here. When I get time, I will try out more things !","133fb33d":"## Make predections on CORD-19-research-challenge dataset","704f8225":"## Load the annotated corpus","b4f0a993":"Convert the tagged data to a format understood by Spacy. Remove anything that has spaces and does **not** have   *\"human_annotations\"* . LightTag gui has bugs which give overlapping entites that results in error during training"}}