{"cell_type":{"03624d83":"code","3aa57e1f":"code","0c00faa8":"code","62106c51":"code","3fde222b":"code","4ea14859":"code","11926e6f":"code","9d6cf94a":"code","01eacf36":"code","5b34549c":"code","4df865e4":"code","ed76c64e":"code","38fcc01a":"code","aace4860":"code","0c31a9d6":"code","b3cfeee7":"code","ff1bd4e0":"code","c51f16ad":"code","d180d6b4":"code","04997fb1":"code","496d4e36":"code","7122dae1":"markdown","e8b6905e":"markdown","515c7e6f":"markdown","ea1c5d95":"markdown","5c558ec1":"markdown","2694964f":"markdown"},"source":{"03624d83":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","3aa57e1f":"# Libraries for decision tree modelling, viewing the decision tree etc\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import plot_tree\n","0c00faa8":"# Read the csv file into dataframe\ndf = pd.read_csv(\"\/kaggle\/input\/iris\/Iris.csv\")","62106c51":"#Check the dataframe information\ndf.info()","3fde222b":"# There are 4 - Numerical Features and one categorical column.\n# There are totally 150 rows or observations are in data","4ea14859":"# Check to see if any missing values in the df\npd.isnull(df).sum()","11926e6f":"# Observed No missing values in the file","9d6cf94a":"df = df.drop('Id', axis = 1)","01eacf36":"# Splitting the data into train and test sets\ny= df[\"Species\"]\nx= df.drop(\"Species\",axis=1)\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3, random_state= 42)\n","5b34549c":"# Let us explore how after splitting the files look like\ny.head()","4df865e4":"# How many rows. \nlen(y)","ed76c64e":"# Complete categorical column is y","38fcc01a":"x.info()","aace4860":"x_train.head()","0c31a9d6":"# Complete non categorical columns (All predictors) are in x_train","b3cfeee7":"y_train","ff1bd4e0":"x.info()","c51f16ad":"dt = DecisionTreeClassifier(random_state = 43)\ndt.fit(x_train, y_train)","d180d6b4":"plt.figure(figsize=(30,20))\nplt.title(\"Decision Tree\")\nplot_tree(dt, feature_names=x_train.columns, class_names= y, filled=True, rounded = True,fontsize= 16)","04997fb1":"y_pred = dt.predict(x_test)","496d4e36":"y_actual = pd.DataFrame(y_test.value_counts())\ny_actual = y_actual.reset_index()\ny_actual.columns = ['Condition', 'AcutalCnt']\n\ny_predicted = pd.DataFrame(y_pred, columns=[\"Predicted\"])[\"Predicted\"]\ny_predicted = pd.DataFrame(y_predicted.value_counts())\ny_predicted = y_predicted.reset_index()\ny_predicted.columns = [\"Condition\",\"PredictCnt\"]\ny_predicted\n\nconfusion_df = pd.merge(y_actual, y_predicted, on='Condition', how='outer')\nconfusion_df['Error'] = abs(confusion_df['AcutalCnt']-confusion_df['PredictCnt'])\nconfusion_df\naccuracy = (confusion_df.AcutalCnt.sum()-confusion_df.Error.sum())\/confusion_df.AcutalCnt.sum()*100\nprint(confusion_df)\nprint(\"Model Accuracy is\", accuracy)","7122dae1":"## Predicting the test file ","e8b6905e":"### Removing the id column from the dataframe","515c7e6f":"## Confusion Matrix and Model accuracy","ea1c5d95":"## Python Decision Tree Model with Iris Data Set and Sklearn library","5c558ec1":"## Split the given data set to Train and Test dataframes","2694964f":"## Classfier Model fitting"}}