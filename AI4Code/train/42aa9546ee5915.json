{"cell_type":{"5b00f1c6":"code","c3a49c88":"code","0d768865":"code","9bad579e":"code","c8862fd4":"code","b5504c17":"code","ef8f862e":"code","21821cd9":"code","ea4cfdf0":"code","d416c51d":"code","6e3ddaf5":"code","17a6cc75":"code","1b40ff28":"code","6477d792":"code","c5cad5ee":"code","c36e7d43":"code","90aea16b":"code","4fb0bb02":"code","241df387":"code","7c8bcc66":"code","108d9670":"code","94e404a5":"code","a28d115d":"code","5ffa9976":"code","235ddf3b":"code","43072ca3":"code","aa5862c8":"code","d404c1bf":"code","c8fd8972":"code","cbad172b":"code","3ac55b00":"code","3a86c863":"code","1b1b9d87":"code","5890c139":"code","790e9659":"code","7934cd7d":"code","7309919c":"code","cc68229e":"code","f26369a4":"code","8888b0f7":"code","65d29357":"code","c01bd4c6":"code","ae7fe61a":"code","12a5badb":"code","0918a1b1":"code","7563b11b":"code","43da0524":"code","0002e491":"code","1c89f9b6":"markdown","9f29da0e":"markdown","566c23b8":"markdown","83b2bc75":"markdown","d8bd9eaf":"markdown","901da045":"markdown","c4665ccc":"markdown","d2614ba6":"markdown","94704387":"markdown","460f73ea":"markdown","b9a90033":"markdown","6a5c65cb":"markdown","4a2437f8":"markdown","3c0944b2":"markdown","a705454b":"markdown","b14c2447":"markdown","cc4811af":"markdown","5f905461":"markdown","e91bdf5f":"markdown","7cd148d8":"markdown","f9ca8e8b":"markdown","1c49b21c":"markdown","55e808af":"markdown","3e485ca4":"markdown","e53068db":"markdown","b619e987":"markdown"},"source":{"5b00f1c6":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport os\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import RobustScaler\n\nimport category_encoders as ce\n\nplt.style.use('seaborn-colorblind')\n%matplotlib inline","c3a49c88":"data = pd.read_csv('\/kaggle\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\nprint(data.shape)\ndata.head(8)","0d768865":"data.info()","9bad579e":"data.dtypes","c8862fd4":"data.describe()","b5504c17":"data.describe(include=['object'])","ef8f862e":"data.isna().any()","21821cd9":"for feature in data.columns[1:]:\n    fig = px.histogram(data, x = feature, color=\"Churn\", nbins=60)\n    fig.update_layout(\n        autosize=False,\n        width=800,\n        height=400,)\n    fig.show()","ea4cfdf0":"fig, ax = plt.subplots(figsize = (10,7))\ndata.tenure[data.Churn == 'Yes'].hist(bins=20, color = \"palevioletred\")\ndata.tenure[data.Churn == 'No'].hist(bins=20, alpha=0.5, color = \"darksalmon\")\nplt.legend(['Churn', 'Non-Churn'])\nplt.title('Customer Tenure')\nplt.xlabel('Tenure')\nplt.ylabel('Amount of Customers')","d416c51d":"sns.pairplot(data, hue=\"Churn\", palette='pastel')\nplt.show();","6e3ddaf5":"data.columns","17a6cc75":"data['TotalCharges'] = data['TotalCharges'].apply(lambda x: x.strip()).replace('', np.nan)\ndata.fillna(0, inplace = True)\ndata['TotalCharges'] = pd.to_numeric(data['TotalCharges'])","1b40ff28":"data.groupby('Churn')[['MonthlyCharges', 'tenure', 'TotalCharges']].agg(['min', 'max', 'mean'])","6477d792":"data.boxplot(column=['MonthlyCharges','tenure'])","c5cad5ee":"data.boxplot(column=['TotalCharges'])","c36e7d43":"yes_no_list = ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'Churn']\ncategorical = ['gender', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n               'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaymentMethod', 'TotalCharges']\n\ncontinuos = ['MonthlyCharges', 'TotalCharges']","90aea16b":"def no_to_zero_yes_to_one(data, columns_given):\n    for column in columns_given:\n        data.loc[data[column] == 'No', column] = 0\n        data.loc[data[column] == 'Yes', column] = 1\n        data[column] = pd.to_numeric(data[column], errors='ignore')\n\nno_to_zero_yes_to_one(data, yes_no_list)","4fb0bb02":"from sklearn.preprocessing import LabelEncoder","241df387":"encoder = LabelEncoder()\nfrom sklearn.preprocessing import LabelEncoder\nfor label in categorical:\n    data[label] = encoder.fit_transform(data[label])","7c8bcc66":"data.drop('customerID', axis=1, inplace=True)","108d9670":"data.head()","94e404a5":"corr = data.corr()\nplt.figure(figsize=(30,20));\nsns.heatmap(corr, annot=True, fmt='.2f');","a28d115d":"CorField = []\nfor i in corr:\n    for j in corr.index[corr[i] > 0.65]:\n        if i != j and j not in CorField and i not in CorField:\n            CorField.append(j)\n            print (i, j, corr[i][corr.index == j].values[0])","5ffa9976":"data['extra_charges'] = data['TotalCharges'] - (data['MonthlyCharges'] * data['tenure'])","235ddf3b":"data['extra_charges'].hist(color = \"darksalmon\")","43072ca3":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nimport sklearn.metrics as metrics\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import make_scorer\nfrom sklearn.ensemble import (RandomForestClassifier,\n                              AdaBoostClassifier,\n                              GradientBoostingClassifier)\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier","aa5862c8":"X_train, X_test, y_train, y_test = train_test_split(\n    data.drop(['Churn'], axis=1), data['Churn'], test_size=0.3, random_state=42, stratify=data['Churn']\n)","d404c1bf":"model = GradientBoostingClassifier()\nmodel.fit(X_train, y_train)\npreds = model.predict(X_test)\nprint(classification_report(y_test, preds, zero_division = 0))","c8fd8972":"cm = confusion_matrix(y_test, preds)\nsns.heatmap(cm, annot=True,fmt='g')\nplt.xlabel('Predicted')\nplt.ylabel('True Value')\nplt.show()","cbad172b":"from xgboost import XGBClassifier\nmodel = XGBClassifier()\nmodel.fit(X_train, y_train)\npreds = model.predict(X_test)\nprint(classification_report(y_test, preds, zero_division = 0))","3ac55b00":"cm = confusion_matrix(y_test, preds)\nsns.heatmap(cm, annot=True,fmt='g')\nplt.xlabel('Predicted')\nplt.ylabel('True Value')\nplt.show()","3a86c863":"model = LGBMClassifier()\nmodel.fit(X_train, y_train)\npreds = model.predict(X_test)\nprint(classification_report(y_test, preds, zero_division = 0))","1b1b9d87":"cm = confusion_matrix(y_test, preds)\nsns.heatmap(cm, annot=True,fmt='g')\nplt.xlabel('Predicted')\nplt.ylabel('True Value')\nplt.show()","5890c139":"model = CatBoostClassifier()\nmodel.fit(X_train, y_train)\npreds = model.predict(X_test)\nprint(classification_report(y_test, preds, zero_division = 0))","790e9659":"cm = confusion_matrix(y_test, preds)\nsns.heatmap(cm, annot=True,fmt='g')\nplt.xlabel('Predicted')\nplt.ylabel('True Value')\nplt.show()","7934cd7d":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\n\nmodels = {\n    \"GradientBoostingClassifier\": GradientBoostingClassifier(),\n    \"XGBClassifier\": XGBClassifier(),\n    \"LightGBM\": LGBMClassifier(),\n    \"CatBoost\": CatBoostClassifier()\n}\n\n\n\nrandom_state = 42\nn_splits = 5\nscoring_method = make_scorer(lambda prediction, true_target: f1_score(true_target, prediction, average=\"weighted\"))\n\nmodel_parameters = {\n    \"GradientBoostingClassifier\": {\n        'loss': [\"deviance\", \"exponential\"],\n        'n_estimators': [150, 160, 200, 250]\n    },\n    \"XGBClassifier\": {\n        'learning_rate': [0.6, 0.8], \n        'max_depth': [1, 2],\n        'subsample': [0.5, 0.7, 0.9],\n        'min_child_weight': [1, 2],\n        'n_estimators':[50, 80]\n    },\n    \"LightGBM\": {\n        'colsample_bytree':[0.2, 0.6],\n        'learning_rate':[0.05,0.1,0.15],\n        'max_depth':[1, 2, 3, 5],\n        'n_estimators':[300, 400, 520, 600]\n    },\n    \"CatBoost\": {\n        'rsm':[0.2, 0.6, 0.8, 0.9],\n        'learning_rate':[0.05,0.1,0.15],\n        'max_depth':[1,3,5],\n        'n_estimators':[200, 400, 800, 900]\n    } \n}\n\nfor model_name, parameters in model_parameters.items():\n    model = models[model_name]\n    \n    cv = StratifiedKFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n    grid_search = GridSearchCV(model, parameters, cv=cv, n_jobs=-1, verbose=False, scoring=scoring_method).fit(X_train, y_train)\n\n    best_score = grid_search.best_score_\n    best_params = grid_search.best_params_\n    \n    print(model_name)\n    print(\"- best_score =\", best_score)\n    print(\"best paramters:\")\n    for k,v in best_params.items():\n        print(\"-\", k, v)","7309919c":"gb = GradientBoostingClassifier(loss = 'deviance', n_estimators = 160)\ngb.fit(X_train, y_train)\npreds = gb.predict(X_test)\nprint(classification_report(y_test, preds, zero_division = 0))","cc68229e":"cm = confusion_matrix(y_test, preds)\nsns.heatmap(cm, annot=True,fmt='g')\nplt.xlabel('Predicted')\nplt.ylabel('True Value')\nplt.show()","f26369a4":"probs = gb.predict_proba(X_test)\npreds = probs[:,1]\n\nfpr, tpr, threshold = metrics.roc_curve(y_test, preds)\nroc_auc = metrics.auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","8888b0f7":"xgb = XGBClassifier(learning_rate = 0.6, max_depth = 1, min_child_weight = 1, n_estimators = 50, subsample = 0.7)\nxgb.fit(X_train, y_train)\npreds = xgb.predict(X_test)\nprint(classification_report(y_test, preds, zero_division = 0))","65d29357":"cm = confusion_matrix(y_test, preds)\nsns.heatmap(cm, annot=True,fmt='g')\nplt.xlabel('Predicted')\nplt.ylabel('True Value')\nplt.show()","c01bd4c6":"probs = xgb.predict_proba(X_test)\npreds = probs[:,1]\n\nfpr, tpr, threshold = metrics.roc_curve(y_test, preds)\nroc_auc = metrics.auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","ae7fe61a":"lgbm = LGBMClassifier(colsample_bytree = 0.6, learning_rate = 0.05, max_depth = 1, n_estimators = 400)\nlgbm.fit(X_train, y_train)\npreds = lgbm.predict(X_test)\nprint(classification_report(y_test, preds, zero_division = 0))","12a5badb":"cm = confusion_matrix(y_test, preds)\nsns.heatmap(cm, annot=True,fmt='g')\nplt.xlabel('Predicted')\nplt.ylabel('True Value')\nplt.show()","0918a1b1":"probs = lgbm.predict_proba(X_test)\npreds = probs[:,1]\n\nfpr, tpr, threshold = metrics.roc_curve(y_test, preds)\nroc_auc = metrics.auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","7563b11b":"cat = CatBoostClassifier(learning_rate = 0.05, max_depth = 1, n_estimators = 800, rsm = 0.9)\ncat.fit(X_train, y_train)\npreds = cat.predict(X_test)\nprint(classification_report(y_test, preds, zero_division = 0))\n\n","43da0524":"cm = confusion_matrix(y_test, preds)\nsns.heatmap(cm, annot=True,fmt='g')\nplt.xlabel('Predicted')\nplt.ylabel('True Value')\nplt.show()","0002e491":"probs = cat.predict_proba(X_test)\npreds = probs[:,1]\n\nfpr, tpr, threshold = metrics.roc_curve(y_test, preds)\nroc_auc = metrics.auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","1c89f9b6":"#### Correlation","9f29da0e":"#### K-Fold & GridSearch","566c23b8":"- `tenure` and `TotalCharges` are highly correlated features;\n- `tenure` and `Contract` are highly correlated features.","83b2bc75":"#### GradientBoostingClassifier","d8bd9eaf":"#### CatBoostClassifier","901da045":"Model with the best score is CatBoostClassifier with auc-roc 0.85.","c4665ccc":"## Exploratory Data Analysis","d2614ba6":"#### Encoding","94704387":"## Conclusion","460f73ea":"#### LGBMClassifier","b9a90033":"#### XGBClassifier","6a5c65cb":"#### Total Charges type","4a2437f8":"The goal is to predict behaviors of churn or not churn to help retain customers. \nEach row represents a customer, each column contains a customer\u2019s attribute.","3c0944b2":"#### CatBoostClassifier","a705454b":"## Machine Learning","b14c2447":"#### Outlier Detection","cc4811af":"# Telco Customer Churn","5f905461":"## Task","e91bdf5f":"#### GradientBoostingClassifier","7cd148d8":"#### Extra Feature","f9ca8e8b":"#### XGBClassifier","1c49b21c":"The longer a customer stays, the less likely they are to churn","55e808af":"Without parameter tuning GradientBoostingClassifier and CatBoostClassifier showed the best results.","3e485ca4":"#### LGBMClassifier","e53068db":"## Feature Engineering","b619e987":"Some of the findings:\n\n- If customers have no dependents, they are more likely to churn;\n- Customers that have internet service with Fiber Optic service have almost a triple the rate of churn than those with DSL;\n- Customers that have internet service, ones without online security have a triple the churn rate than those with online security;\n- Out of the customers that have internet service, customers with Onlinr Backup have half the rate of churn than those that without;\n- Customers on one-year or two-years contract have lower churn rates than those that are on month-to-month contract;\n- Customers on paperless billing have more than three times higher rates of churn;\n- Customers that use Electronic Check  as Payment Method have double the rate of churn than those using other Payment Methods."}}