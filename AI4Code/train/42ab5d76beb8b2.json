{"cell_type":{"7666c0ab":"code","6704edf2":"code","97008ea5":"code","b045e5c7":"code","1552c6ad":"code","a65bdc43":"code","f4399dcd":"markdown","03efdef5":"markdown","0b0682d8":"markdown","b096c4a2":"markdown","c546de56":"markdown","97d5808f":"markdown","8e336ac7":"markdown","3ba0548f":"markdown","dc3ad37f":"markdown"},"source":{"7666c0ab":"import pandas as pd\n\n# Read the data\ndata = pd.read_csv('..\/input\/melbourne-housing-snapshot\/melb_data.csv')\n\n# Select subset of predictors\nfeatures_cols = ['Rooms', 'Distance', 'Landsize', 'BuildingArea', 'YearBuilt']\nX = data[features_cols]\n\n# Select target\ny = data.Price","6704edf2":"X.head()","97008ea5":"y.head()","b045e5c7":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\n# defining pipeline \nmy_pipeline = Pipeline(steps = [\n    ('preprocessor', SimpleImputer()),\n    ('model', RandomForestRegressor(n_estimators = 50, random_state = 0))\n])","1552c6ad":"from sklearn.model_selection import cross_val_score\n\n# cv is the number of folds (k actually)\nmy_scores = -1 * cross_val_score(my_pipeline,\n                                X,\n                                y,\n                                cv = 5,\n                                scoring  = 'neg_mean_absolute_error')\n\nprint('MAE scores:\\n', my_scores)\n","a65bdc43":"print(\"Average MEA of our scores:\")\nprint(my_scores.mean())","f4399dcd":"**Yes! We're done with corss-validation**<br>\nThe good thing is that using cross-validation we no longer need to keep track of separate training and validation sets. <br>\nSo, especially for small datasets...right!!\n\n","03efdef5":"# Stratified k-Fold\nIn this particular process, we're going to use this process as it provides train\/test indices to split data in train\/test sets.<br>\nSo, it takes care the ratio of positive or negative data exaples in each folds. [Click here]( https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.StratifiedKFold.html) to learn more.","0b0682d8":"See! We got our mean absolute error from each validation set (k = 5). <br>\nIt is a little surprising that we specify negative MAE. Scikit-learn has a convention where all metrics are defined so a high number is better. Using negatives here allows them to be consistent with that convention, though negative MAE is almost unheard of elsewhere.<br>\nNow, just averaging the scores to get mean value of them.","b096c4a2":"Now, we'll be using the *cross_val_score()* ([click here](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.cross_val_score.html) to see documentation) function to obtain cross validation scores. Here, we'll use *neg_mean_absolute_error*.<br>\nFor this, we need to multiply our function with **-1**. Again, inside the function, we'll be passing the whole X and y as it'll do all the fold for us from the given dataset.","c546de56":"let's print X, and y so see how these they look like.","97d5808f":"In this particular notebook, we're gonna learn about *cross-validation* and it's working.<br>\nFor this reason, we choose the dataset from [Melbourne Housing Snapshot](https:\/\/www.kaggle.com\/dansbecker\/melbourne-housing-snapshot)<br>\nBeofore that, what do you mean by the term **CROSS-VALIDATION** in machine learning models?<br>\nCross means shuffling here, and corss validation means the shuffling in main dataset due to the validation dataset which belongs into it.<br>\nThere are some types of problems who generally face while choosing validation dataset. Some approaches could be-\n* k-Fold\n* Stratified k-Fold\n* Leave one out\nand some others. Let's know some ideas how these are actually doing on dataset.","8e336ac7":"# K-Fold\nIn this process, we choose random part of the dataset to set as validation dataset e.g 20% most of the time.<br>\nIf we have been declared 20% for the validation dataset from 5000 examples, then random 1000 examples would be there to get selected.<br>\nThen we find out the prediction for each of the fold *imagine this one {v1, v2, v3, v4, v5}* have been selected  as validation set such as \nBut the problem is, having a perfect ratio of 90% positive and 10% negative examples in the main dataset doesn't surely maintained by the k-Fold technique.<br>\nMore specificly,  each fold doesn't necessarily balanced with 90% +ve and 10% -ve ratio as like as the main dataset. [Click here](https:\/\/scikit-learn.org\/stable\/modules\/cross_validation.html) to learn more.","3ba0548f":"It is possible to do cross-validatio without doing pipelining! But it is not a good decision.<br>\nHowever, pipeline will make the code remarkably straightforward. So, we're gonna a pipeline.<br>\nFor this reason, we'll use an imputer for missing values as the preprocessor, and RandomForestRegressor while defining the model.","dc3ad37f":"# Leave one Out\nThis process is only applicable if there's only 1 validation data in each fold of our entire dataset while the remaining samples form the training set..[Click here](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.LeaveOneOut.html)<br>\nSo, now we're gonna start our code here. As usual let's load the input data in X and the output data in y."}}