{"cell_type":{"3c168e12":"code","5f65baac":"code","12c38f42":"code","fe678ba4":"code","fafde160":"code","dbbb9960":"code","af5b1fa9":"code","82e04ca8":"code","9343a5e9":"code","8055ea9c":"code","70421669":"code","74b37cbc":"code","5b72afe6":"code","4c32509e":"code","8d4c39a4":"code","8c4b95fe":"code","515d725d":"code","778b6a3b":"code","ee7aadea":"markdown","89a11f0d":"markdown","13eb4c66":"markdown","744beb2a":"markdown","05c285b7":"markdown","a00ebbcc":"markdown","9152841a":"markdown"},"source":{"3c168e12":"import os\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))","5f65baac":"from scipy.stats import rankdata\nimport glob\nLABELS = [\"sirna\"]\nall_files = glob.glob(\"..\/input\/cellstack\/*.csv\")\nall_files","12c38f42":"outs = [pd.read_csv(f, index_col=0) for f in all_files]\nconcat_sub = pd.concat(outs, axis=1)\ncols = list(map(lambda x: \"m\" + str(x), range(len(concat_sub.columns))))\nconcat_sub.columns = cols\nconcat_sub.reset_index(inplace=True)","fe678ba4":"rank = np.tril(concat_sub.iloc[:,1:].corr().values,-1)\nm = (rank>0).sum()\nm_gmean, s = 0, 0\nfor n in range(min(rank.shape[0],m)):\n    mx = np.unravel_index(rank.argmin(), rank.shape)\n    w = (m-n)\/(m+n\/10)\n    print(w)\n    m_gmean += w*(np.log(concat_sub.iloc[:,mx[0]+1])+np.log(concat_sub.iloc[:,mx[1]+1]))\/2\n    s += w\n    rank[mx] = 1\nm_gmean = np.exp(m_gmean\/s).clip(0.0,1.0)","fafde160":"predict_list = []\npredict_list.append(pd.read_csv(\"..\/input\/cellstack\/submission-174.csv\")[LABELS].values)\npredict_list.append(pd.read_csv(\"..\/input\/cellstack\/submission-201.csv\")[LABELS].values)\npredict_list.append(pd.read_csv(\"..\/input\/cellstack\/submission-231.csv\")[LABELS].values)","dbbb9960":"import warnings\nwarnings.filterwarnings(\"ignore\")\nprint(\"Rank averaging on \", len(predict_list), \" files\")\npredictions = np.zeros_like(predict_list[0])\nfor predict in predict_list:\n    for i in range(1):\n        predictions[:, i] = np.add(predictions[:, i], rankdata(predict[:, i])\/predictions.shape[0])  \n\npredictions = predictions \/len(predict_list)\n\nsubmission = pd.read_csv('..\/input\/recursion-cellular-image-classification\/sample_submission.csv')\nsubmission[LABELS] = predictions\nsubmission.to_csv('AggStacker.csv', index=False)","af5b1fa9":"sub_path = \"..\/input\/cellstack\"\nall_files = os.listdir(sub_path)\nall_files","82e04ca8":"import warnings\nwarnings.filterwarnings(\"ignore\")\nouts = [pd.read_csv(os.path.join(sub_path, f), index_col=0) for f in all_files]\nconcat_sub = pd.concat(outs, axis=1)\ncols = list(map(lambda x: \"var\" + str(x), range(len(concat_sub.columns))))\nconcat_sub.columns = cols\nconcat_sub.reset_index(inplace=True)\nconcat_sub.head()\nncol = concat_sub.shape[1]","9343a5e9":"# check correlation\nconcat_sub.iloc[:,1:ncol].corr()","8055ea9c":"corr = concat_sub.iloc[:,1:7].corr()\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","70421669":"# get the data fields ready for stacking\nconcat_sub['m_max'] = concat_sub.iloc[:, 1:ncol].max(axis=1)\nconcat_sub['m_min'] = concat_sub.iloc[:, 1:ncol].min(axis=1)\nconcat_sub['m_median'] = concat_sub.iloc[:, 1:ncol].median(axis=1)","74b37cbc":"concat_sub.describe()","5b72afe6":"cutoff_lo = 0.8\ncutoff_hi = 0.2","4c32509e":"concat_sub['sirna'] = m_gmean.astype(int)\nconcat_sub[['id_code','sirna']].to_csv('stack_mean.csv', \n                                        index=False, float_format='%.6f')","8d4c39a4":"concat_sub['sirna']  = concat_sub['m_median'].astype(int)\nconcat_sub[['id_code','sirna']].to_csv('stack_median.csv', \n                                        index=False, float_format='%.6f')","8c4b95fe":"concat_sub['sirna']  = np.where(np.all(concat_sub.iloc[:,1:ncol] > cutoff_lo, axis=1), 1, \n                                    np.where(np.all(concat_sub.iloc[:,1:ncol] < cutoff_hi, axis=1),\n                                             0, concat_sub['m_median']))\nconcat_sub[['id_code','sirna']].to_csv('stack_pushout_median.csv', \n                                        index=False, float_format='%.6f')","515d725d":"concat_sub['m_mean'] = m_gmean.astype(int)\nconcat_sub['sirna']  = np.where(np.all(concat_sub.iloc[:,1:ncol] > cutoff_lo, axis=1), \n                                    concat_sub['m_max'], \n                                    np.where(np.all(concat_sub.iloc[:,1:ncol] < cutoff_hi, axis=1),\n                                             concat_sub['m_min'], \n                                             concat_sub['m_mean'])).astype(int)\nconcat_sub[['id_code','sirna']].to_csv('stack_minmax_mean.csv', \n                                        index=False, float_format='%.6f')","778b6a3b":"concat_sub['sirna'] = np.where(np.all(concat_sub.iloc[:,1:ncol] > cutoff_lo, axis=1), \n                                    concat_sub['m_max'], \n                                    np.where(np.all(concat_sub.iloc[:,1:ncol] < cutoff_hi, axis=1),\n                                             concat_sub['m_min'], \n                                             concat_sub['m_median'])).astype(int)\nconcat_sub[['id_code','sirna']].to_csv('stack_minmax_median.csv', \n                                        index=False, float_format='%.6f')","ee7aadea":"# Mean Stacking","89a11f0d":"## Stacking the Best Models\n<pre><b>\nThis Kernel shows how the scores can be improved using Stacking Method.\nCredit Goes to the following kernels\nref:\n1. https:\/\/www.kaggle.com\/zaharch\/keras-model-boosted-with-plates-leak\n2. https:\/\/www.kaggle.com\/xhlulu\/recursion-2-headed-efficientnet-2-stage-training\n3. https:\/\/www.kaggle.com\/antgoldbloom\/doing-inference-using-google-automl\n<\/b><\/pre>","13eb4c66":"# MinMax + Median Stacking","744beb2a":"# Median Stacking","05c285b7":"# MinMax + Mean Stacking\n>* MinMax seems more gentle and it outperforms the previous one","a00ebbcc":"# Pushout + Median Stacking\n>* Pushout strategy is bit aggresive","9152841a":"## Stat Stack"}}