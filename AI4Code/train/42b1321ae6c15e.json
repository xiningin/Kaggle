{"cell_type":{"0109ebce":"code","f2ce5aea":"code","e1f08fdc":"code","53f11314":"code","6975f802":"code","caba07f0":"code","1cf20ebe":"code","0329bc10":"code","9722ed83":"code","52a8bd1e":"code","eb3b38f0":"code","2e8b49e4":"code","5794e636":"code","8d88e4b3":"code","c72bf38b":"code","81105c7c":"code","4ee22d4e":"code","f8ac91e3":"code","d5fb20a1":"code","d03c007f":"code","1aa743e1":"code","1b9dee33":"code","978c899d":"code","badffad1":"code","8d2b9b3d":"code","5f6440fc":"code","d7a38b4a":"code","ce425ae1":"code","faa613e8":"code","d508b88d":"code","35edefac":"code","5f6840a9":"code","3d938496":"code","97cb6c5b":"markdown","36b73930":"markdown","aa4e9850":"markdown","24d14a77":"markdown","4d402a0b":"markdown","b8594e4e":"markdown","3d05d6db":"markdown"},"source":{"0109ebce":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session ## ","f2ce5aea":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR\nfrom  xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,BaggingRegressor,GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.model_selection import train_test_split,cross_validate\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV,StratifiedKFold\nfrom sklearn.tree import DecisionTreeRegressor\nimport time","e1f08fdc":"train_df = pd.read_csv('..\/input\/bike-sharing-demand\/train.csv')\ntest_df = pd.read_csv('..\/input\/bike-sharing-demand\/test.csv')\n","53f11314":"test_df","6975f802":"train_df","caba07f0":"print(train_df.isnull().values.any() ,'\\n',test_df.isnull().values.any())","1cf20ebe":"print(train_df.info() ,'\\n',test_df.info())\n","0329bc10":"test = pd.DataFrame(test_df)\ntest","9722ed83":"train = pd.DataFrame(train_df)\ntrain","52a8bd1e":"train['datetime'] = pd.to_datetime(train['datetime'], format = '%Y-%m-%dT%H:%M:%S')\ntrain['year'] = train['datetime'].dt.year\ntrain['month'] = train['datetime'].dt.month\ntrain['day'] = train['datetime'].dt.day\ntrain['hour'] = train['datetime'].dt.hour\n\n#Get days names\n# train_df['weekday']=pd.DatetimeIndex(train_df['datetime']).day_name()\ntrain","eb3b38f0":"train = train_df.drop('datetime' , axis=1)\ntrain","2e8b49e4":"\ntrain[[\"season\", \"count\"]].groupby(['season'], as_index=False).sum().sort_values(by='count', ascending=False)","5794e636":"train[[\"holiday\", \"count\"]].groupby(['holiday'], as_index=False).sum().sort_values(by='count', ascending=False)","8d88e4b3":"train[[\"workingday\", \"count\"]].groupby(['workingday'], as_index=False).sum().sort_values(by='count', ascending=False)","c72bf38b":"test['datetime'] = pd.to_datetime(test['datetime'], format = '%Y-%m-%dT%H:%M:%S')\ntest['year'] = test['datetime'].dt.year\ntest['month'] = test['datetime'].dt.month\ntest['day'] = test['datetime'].dt.day\ntest['hour'] = test['datetime'].dt.hour\n\ntest","81105c7c":"plt.subplots(figsize=(15,15))\nsns.heatmap(train.corr(), mask=np.zeros_like(train.corr(), dtype=bool),\n            square=True, annot=True)\nplt.show()","4ee22d4e":"train = pd.DataFrame(train)\ntrain.drop(['casual' , 'registered' ],axis=1,inplace=True)\n","f8ac91e3":"plt.bar(train['hour'], train['count'])\n\nplt.xlabel('hour')\nplt.ylabel('Number of bikes')\nplt.show()\n","d5fb20a1":"c=[]\nfor i in test['hour']:\n    \n    if i>= 6 or i<= 1 :\n        c.append(\"Day\")\n    else:\n        c.append(\"Night\")\ntest['DayorNight']=c\ntest['DayorNight']=pd.factorize(test['DayorNight'])[0].reshape(-1, 1)\nc=[]\n\n\ntest = test.drop('datetime' , axis =1)\ntest","d03c007f":"c=[]\nfor i in train['hour']:\n    \n    if i>= 6 or i<= 1 :\n        c.append(\"Day\")\n    else:\n        c.append(\"Night\")\ntrain['DayorNight']=c\ntrain['DayorNight']=pd.factorize(train['DayorNight'])[0].reshape(-1, 1)\nc=[]\ntrain.head(2)","1aa743e1":"x = train\nx =x.drop('count',axis=1)\nx","1b9dee33":"test","978c899d":"# y= train['count']\n\ny=np.log1p(train['count'])\ny = pd.DataFrame(y)\ny.var()\n\nsns.histplot(y);\nplt.title(\"Bike Count\");\n","badffad1":"from sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(x , y, train_size=0.8, test_size=0.2, random_state = 0)","8d2b9b3d":"# ! pip install lazypredict\n","5f6440fc":"# from lazypredict.Supervised import LazyRegressor\n# reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)\n# models , predictions = reg.fit(x_train, x_val, y_train, y_val)\n\n# print(models) ","d7a38b4a":"import xgboost as xgb\nfrom sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_log_error\n","ce425ae1":"# from sklearn.experimental import enable_hist_gradient_boosting  \n# from sklearn.ensemble import HistGradientBoostingRegressor\n\n\n# est = HistGradientBoostingRegressor()\n\n# est.fit(x_train, y_train)\n\n# score_train_est = est.score(x_train, np.ravel(y_train,order='C'))  \n# print(\"Training score: \", score_train_est)\n\n# scores_est = cross_val_score(est, x_train, y_train,cv=10)\n# print(\"Mean cross-validation score: %.2f\" % scores_est.mean())\n\n\n# y_pred_est = est.predict(x_val)\n# print('Validation score' , est.score(x_val , y_val))\n\n# from sklearn.metrics import mean_squared_error\n# from sklearn.metrics import mean_squared_log_error\n\n\n# rmsle_est = mean_squared_log_error(y_pred_est ,y_val )\n# print(\"RMSLE: %.2f\" % rmsle_est)","faa613e8":"xgbr = xgb.XGBRegressor(verbosity=0) \n# print(xgbr)\n\nxgbr.fit(x_train, y_train)\n\nscore_xgbr = xgbr.score(x_train, y_train)  \nprint(\"Training score: \", score_xgbr)\n\nscores_xgbr = cross_val_score(xgbr, x_train, y_train,cv=10)\nprint(\"Mean cross-validation score: %.2f\" % scores_xgbr.mean())\n\n \ny_pred_xgbr = xgbr.predict(x_val)\nprint('Validation score' , xgbr.score(x_val , y_val))\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_squared_log_error\n\n\nrmsle_xgbr = mean_squared_log_error(y_pred_xgbr ,y_val )\nprint(\"RMSLE: %.2f\" % rmsle_xgbr)\n","d508b88d":"# from sklearn.ensemble import ExtraTreesRegressor\n\n# et = ExtraTreesRegressor() \n# # print(et)\n\n# et.fit(x_train, y_train)\n\n# score_train_et = et.score(x_train, y_train)  \n# print(\"Training score: \", score_train_et)\n\n# scores_et = cross_val_score(et, x_train, y_train,cv=10)\n# print(\"Mean cross-validation score: %.2f\" % scores_et.mean())\n\n\n# y_pred_et = et.predict(x_val)\n# print('Validation score' , et.score(x_val , y_val))\n\n# from sklearn.metrics import mean_squared_error\n# from sklearn.metrics import mean_squared_log_error\n\n\n# rmsle_et = mean_squared_log_error(y_pred_et ,y_val )\n# print(\"RMSLE: %.2f\" % rmsle_et)","35edefac":"# y_pred_est_test = xgbr.predict(test_final) #to be saved\n\npred =np.round(np.expm1(xgbr.predict(test))).astype(int)\npred = pd.DataFrame({\"datetime\": test_df[\"datetime\"],\"count\": np.fix(pred)})\npred.shape","5f6840a9":"pred","3d938496":"# y_pred_est_test = y_pred_est_test.drop('datetime' , axis=1)\npred.to_csv('submission.csv', index=False)  #","97cb6c5b":"**Test data**","36b73930":"# **Compare models using LazyPredict Library**","aa4e9850":"**Drop the columns that most correlated to the 'count' column to avoid redundancy**","24d14a77":"**HistGradientBoostingRegressor**","4d402a0b":"From the previous plot we can see the bikes rental demands ratio is higher at day hours more than the night hours","b8594e4e":"**Train data**","3d05d6db":"# EDA"}}