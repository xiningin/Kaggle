{"cell_type":{"954eb59e":"code","0388f138":"code","f36c78c4":"code","2b9ce039":"code","00ac8d18":"code","5d8cec25":"code","de2a29ea":"code","09560e4d":"code","32916de3":"code","97833c39":"code","a5358e80":"code","8938e5cf":"code","3d061f29":"code","4a25c802":"code","03aa6d03":"code","68042395":"code","8ddc49c5":"code","d380043e":"code","5f8c9854":"code","033df0bd":"code","ed6c5137":"code","37fdf354":"code","7149dcf5":"code","8695800a":"code","3557bacd":"code","cb88ecfc":"code","d4809c7a":"code","6d5938b9":"code","3bbf19ea":"code","509b47f3":"code","984c5150":"code","418edb1c":"code","7ab72a73":"code","e359a25e":"code","0c22ca2c":"code","49a6523c":"code","269687e1":"code","93e50f9e":"code","d4391f8e":"code","7df345d9":"code","72a60585":"code","adce565a":"code","17c5161b":"code","7a0f8e5b":"code","13086b33":"markdown","facefebb":"markdown","9afdeea0":"markdown","2d5b2701":"markdown","a9864e5e":"markdown","6d346e06":"markdown","0108de63":"markdown","97bcae92":"markdown","7e3ce103":"markdown","18aac6cb":"markdown","2d700266":"markdown","8464246a":"markdown","c6dab770":"markdown","e1a05954":"markdown","ce458283":"markdown","f836e71a":"markdown","94b49a32":"markdown","e008496b":"markdown","d9417fa5":"markdown","8068cf49":"markdown","eed7d247":"markdown","7ddef9c1":"markdown","f2ec92a2":"markdown","ac495f64":"markdown","6a0fdb66":"markdown","4cb30555":"markdown","8f2b160d":"markdown","efd7ab60":"markdown","736fd1b1":"markdown","da43bf73":"markdown","38ab50a1":"markdown","434fde39":"markdown"},"source":{"954eb59e":"import numpy as np \nimport pandas as pd\nimport os\n#fast ai\nfrom fastai.imports import *\nfrom pandas_summary import DataFrameSummary\n#Model\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\n# Suppress warnings\nimport warnings\nwarnings.filterwarnings('ignore')","0388f138":"#import data\nin_path = '..\/input\/datafiles\/'\nRegularSeasonDetailedResults = pd.read_csv(in_path + 'RegularSeasonDetailedResults.csv')\nRegularSeasonDetailedResults.shape","f36c78c4":"def display_all(df):\n    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000):\n        display(df)","2b9ce039":"display_all(RegularSeasonDetailedResults.describe(include='all').T)","00ac8d18":"RegularSeasonDetailedResults.head(5)","5d8cec25":"def setWinAndLoseTeamsRecords(RegularSeasonDetailedResults):\n    #Convert the data frame from one record per game to one record per team-game\n    regSesW = RegularSeasonDetailedResults.rename(columns = {'WTeamID': 'TEAMID',\n                                                             'WScore': 'SCORE',\n                                                             'WFGM': 'FGM',\n                                                             'WFGA': 'FGA',\n                                                             'WFGM3': 'FGM3',\n                                                             'WFGA3': 'FGA3',\n                                                             'WFTM': 'FTM',\n                                                             'WFTA': 'FTA',\n                                                             'WOR': 'OR',\n                                                             'WDR': 'DR',\n                                                             'WAst': 'AST',\n                                                             'WTO': 'TO',\n                                                             'WStl': 'STL',\n                                                             'WBlk': 'BLK',\n                                                             'WPF': 'PF',\n                                                             'LTeamID': 'O_TEAMID',\n                                                             'LScore': 'O_SCORE',\n                                                             'LFGM': 'O_FGM',\n                                                             'LFGA': 'O_FGA',\n                                                             'LFGM3': 'O_FGM3',\n                                                             'LFGA3': 'O_FGA3',\n                                                             'LFTM': 'O_FTM',\n                                                             'LFTA': 'O_FTA',\n                                                             'LOR': 'O_OR',\n                                                             'LDR': 'O_DR',\n                                                             'LAst': 'O_AST',\n                                                             'LTO': 'O_TO',\n                                                             'LStl': 'O_STL',\n                                                             'LBlk': 'O_BLK',\n                                                             'LPF': 'O_PF'\n                                                            })\n\n    regSesL = RegularSeasonDetailedResults.rename(columns = {'LTeamID': 'TEAMID',\n                                                             'LScore': 'SCORE',\n                                                             'LFGM': 'FGM',\n                                                             'LFGA': 'FGA',\n                                                             'LFGM3': 'FGM3',\n                                                             'LFGA3': 'FGA3',\n                                                             'LFTM': 'FTM',\n                                                             'LFTA': 'FTA',\n                                                             'LOR': 'OR',\n                                                             'LDR': 'DR',\n                                                             'LAst': 'AST',\n                                                             'LTO': 'TO',\n                                                             'LStl': 'STL',\n                                                             'LBlk': 'BLK',\n                                                             'LPF': 'PF',\n\n                                                             'WTeamID': 'O_TEAMID',\n                                                             'WScore': 'O_SCORE',\n                                                             'WFGM': 'O_FGM',\n                                                             'WFGA': 'O_FGA',\n                                                             'WFGM3': 'O_FGM3',\n                                                             'WFGA3': 'O_FGA3',\n                                                             'WFTM': 'O_FTM',\n                                                             'WFTA': 'O_FTA',\n                                                             'WOR': 'O_OR',\n                                                             'WDR': 'O_DR',\n                                                             'WAst': 'O_AST',\n                                                             'WTO': 'O_TO',\n                                                             'WStl': 'O_STL',\n                                                             'WBlk': 'O_BLK',\n                                                             'WPF': 'O_PF',\n                                                             })\n\n    regSes = (regSesW, regSesL)\n    regSes = pd.concat(regSes, ignore_index = True, sort = False)\n    regSes = regSes[['Season','TEAMID', 'DayNum', 'SCORE', 'O_TEAMID', 'O_SCORE',\n                 'FGM', 'FGA', 'FGM3', 'FGA3', 'FTM', 'FTA', 'OR', 'DR',\n                 'AST', 'TO', 'STL', 'BLK', 'PF', 'NumOT',\n                 'O_FGM', 'O_FGA', 'O_FGM3', 'O_FGA3', 'O_FTM', 'O_FTA', 'O_OR', 'O_DR',\n                 'O_AST', 'O_TO', 'O_STL', 'O_BLK', 'O_PF'\n                 ]]\n    return regSes","de2a29ea":"regSes = setWinAndLoseTeamsRecords(RegularSeasonDetailedResults)\nprint ('RegularSeasonDetailedResults shape: ', RegularSeasonDetailedResults.shape)\nprint ('regSes shape after rearranging: ', regSes.shape)","09560e4d":"#Add GameNum so it can later help derive the game mins within Section 4- Derive Advanced Stats\nregSes['GameNum'] = 1","32916de3":"def aggregateRawData(regSes):    \n    regSes_Avg = regSes.groupby(['Season', 'TEAMID'])['SCORE','O_SCORE',  'FGM', 'FGA', 'FGM3', 'FGA3', 'FTM', 'FTA', 'OR', 'DR', \n                 'AST', 'TO', 'STL', 'BLK', 'PF',\n                 'O_FGM', 'O_FGA', 'O_FGM3', 'O_FGA3', 'O_FTM', 'O_FTA', 'O_OR', 'O_DR', \n                 'O_AST', 'O_TO', 'O_STL', 'O_BLK', 'O_PF', 'NumOT', 'GameNum'\n                               ].agg('sum').reset_index()\n    return regSes_Avg","97833c39":"regSes_aggregate = aggregateRawData(regSes)\nregSes_aggregate.shape","a5358e80":"def GetAdvancedStats(NCAA_features):\n    NCAA_features ['EFG']       = (NCAA_features ['FGM'] + (NCAA_features ['FGM3']*0.5))\/NCAA_features ['FGA']\n    NCAA_features ['TOV']       = NCAA_features ['TO']\/((NCAA_features ['FGA'] + 0.44) + (NCAA_features ['FTA']+NCAA_features ['TO']))\n    NCAA_features ['ORB']       = NCAA_features ['OR']\/(NCAA_features ['OR'] + NCAA_features ['O_DR'])\n    NCAA_features ['DRB']       = NCAA_features ['DR']\/(NCAA_features ['DR'] + NCAA_features ['O_OR'])\n    NCAA_features ['FTAR']      = NCAA_features ['FTA']\/(NCAA_features ['FGA'])\n    NCAA_features ['TS']        = NCAA_features ['SCORE']\/((NCAA_features ['FGA']*2) + (0.88 * NCAA_features ['FTA']))\n    NCAA_features ['ASTTO']     = (NCAA_features ['AST']\/(NCAA_features ['TO']))\n    NCAA_features ['ASTR']      = (NCAA_features ['AST'] * 100) \/ ( (NCAA_features ['FGA'] + (NCAA_features ['FTA']*0.44)) + NCAA_features ['AST'] + NCAA_features ['TO'] )\n    NCAA_features ['TR']        = NCAA_features ['OR'] + NCAA_features ['DR']\n    NCAA_features ['O_TR']      = NCAA_features ['O_OR'] + NCAA_features ['O_DR']\n    NCAA_features ['REBP']      = 100 * (NCAA_features ['TR']) \/ (NCAA_features ['TR'] + NCAA_features ['O_TR'])\n    NCAA_features ['POSS']      = 0.5 * ((NCAA_features ['FGA'] + 0.4 * NCAA_features ['FTA'] - 1.07 * (NCAA_features ['OR'] \/ (NCAA_features ['OR'] + NCAA_features ['O_DR'])) * (NCAA_features ['FGA'] - NCAA_features ['FGM']) + NCAA_features ['TO']) + (NCAA_features ['O_FGA'] + 0.4 * NCAA_features ['O_FTA'] - 1.07 * (NCAA_features ['O_OR'] \/ (NCAA_features ['O_OR'] + NCAA_features ['DR'])) * (NCAA_features ['O_FGA'] - NCAA_features ['O_FGM']) + NCAA_features ['O_TO']))\n    NCAA_features ['O_POSS']    = 0.5 * ((NCAA_features ['O_FGA'] + 0.4 * NCAA_features ['O_FTA'] - 1.07 * (NCAA_features ['O_OR'] \/ (NCAA_features ['O_OR'] + NCAA_features ['DR'])) * (NCAA_features ['O_FGA'] - NCAA_features ['O_FGM']) + NCAA_features ['O_TO']) + (NCAA_features ['FGA'] + 0.4 * NCAA_features ['FTA'] - 1.07 * (NCAA_features ['OR'] \/ (NCAA_features ['OR'] + NCAA_features ['O_DR'])) * (NCAA_features ['FGA'] - NCAA_features ['FGM']) + NCAA_features ['TO']))\n    NCAA_features ['GM']        = (40*NCAA_features ['GameNum']) + (5*NCAA_features ['NumOT'])\n    NCAA_features ['PACE']      = 40 * ((NCAA_features ['POSS'] ) \/ (2 * (NCAA_features ['GM'] \/ 5)))\n    NCAA_features ['DRTG']      = 100* (NCAA_features ['O_SCORE']\/NCAA_features ['POSS'])\n    NCAA_features ['ORTG']      = 100* (NCAA_features ['SCORE']\/(NCAA_features ['O_POSS']))\n    NCAA_features ['OFF3']      = (NCAA_features ['FGM3']\/(NCAA_features ['FGA3']))\n    NCAA_features ['DEF3']      = (NCAA_features ['O_FGM3']\/(NCAA_features ['O_FGA3']))\n    NCAA_features ['O_EFG']     = (NCAA_features ['O_FGM'] + (NCAA_features ['O_FGM3']*0.5))\/NCAA_features ['O_FGA']\n    NCAA_features ['O_TOV']     = NCAA_features ['O_TO']\/((NCAA_features ['O_FGA'] + 0.44) + (NCAA_features ['O_FTA']+NCAA_features ['O_TO']))\n    NCAA_features ['DEFRTG']    = 100*NCAA_features ['O_SCORE']\/(NCAA_features ['O_FGA'] + NCAA_features ['O_TO'] + (0.44* NCAA_features ['O_FTA']) - NCAA_features ['O_OR'])\n    NCAA_features ['OFFRTG']    = 100*NCAA_features ['SCORE']\/(NCAA_features ['FGA'] + NCAA_features ['TO'] + (0.44*NCAA_features ['FTA']) - NCAA_features ['OR'])\n    NCAA_features ['TOR']       = (NCAA_features ['TO'] * 100) \/ (NCAA_features ['FGA'] + (NCAA_features ['FTA'] * 0.44) + NCAA_features ['AST'] + NCAA_features ['TO'])\n    NCAA_features ['STLTO']     = NCAA_features ['STL']\/NCAA_features ['TO']\n    NCAA_features ['PIE']       = (NCAA_features ['SCORE'] + NCAA_features ['FGM'] + NCAA_features ['FTM'] - NCAA_features ['FGA']  - NCAA_features ['FTA']  + NCAA_features ['DR'] + (.5 * NCAA_features ['OR']) + NCAA_features ['AST'] + NCAA_features ['STL'] + (.5 * NCAA_features ['BLK']) - NCAA_features ['PF'] - NCAA_features ['TO']) \/ ((NCAA_features ['SCORE'] + NCAA_features ['FGM'] + NCAA_features ['FTM'] - NCAA_features ['FGA']  - NCAA_features ['FTA']  + NCAA_features ['DR'] + (.5 * NCAA_features ['OR']) + NCAA_features ['AST'] + NCAA_features ['STL'] + (.5 * NCAA_features ['BLK']) - NCAA_features ['PF'] - NCAA_features ['TO'])  + (NCAA_features ['O_SCORE'] + NCAA_features ['O_FGM'] + NCAA_features ['O_FTM'] - NCAA_features ['O_FGA'] - NCAA_features ['O_FTA'] + NCAA_features ['O_DR'] + (.5 * NCAA_features ['O_OR']) + NCAA_features ['O_AST'] + NCAA_features ['O_STL'] + (.5 * NCAA_features ['O_BLK']) - NCAA_features ['O_PF'] - NCAA_features ['O_TO']))\n    NCAA_features ['O_STLTO']   = NCAA_features ['O_STL']\/NCAA_features ['O_TO']\n    NCAA_features ['O_TOR']     = (NCAA_features ['O_TO'] * 100) \/ (NCAA_features ['O_FGA'] + (NCAA_features ['O_FTA'] * 0.44) + NCAA_features ['O_AST'] + NCAA_features ['O_TO'])\n    NCAA_features ['O_FTAR']    = NCAA_features ['O_FTA']\/(NCAA_features ['O_FGA'])\n    NCAA_features ['O_TS']      =  NCAA_features ['O_SCORE']\/((NCAA_features ['O_FGA']*2) + (0.88 * NCAA_features ['O_FTA']))\n    NCAA_features ['O_ASTTO']   = (NCAA_features ['O_AST']\/(NCAA_features ['O_TO']))\n    NCAA_features ['O_ASTR']    = (NCAA_features ['O_AST'] * 100) \/ ( (NCAA_features ['O_FGA'] + (NCAA_features ['O_FTA']*0.44)) + NCAA_features ['O_AST'] + NCAA_features ['O_TO'] )\n    return NCAA_features","8938e5cf":"regSes_adStats = GetAdvancedStats(regSes_aggregate)\nregSes_adStats.shape","3d061f29":"#Remove raw features\nregSes_adStats = regSes_adStats.drop(['SCORE', 'O_SCORE', \n                 'FGM', 'FGA', 'FGM3', 'FGA3', 'FTM', 'FTA', 'OR', 'DR', \n                 'AST', 'TO', 'STL', 'BLK', 'PF', 'NumOT',  \n                 'O_FGM', 'O_FGA', 'O_FGM3', 'O_FGA3', 'O_FTM', 'O_FTA', 'O_OR', 'O_DR', \n                 'O_AST', 'O_TO', 'O_STL', 'O_BLK', 'O_PF','GameNum','POSS','GM','O_POSS' ], axis=1)\nregSes_adStats.shape","4a25c802":"def NCAASetWinAndLoseTeamsRecords(NCAATourneyCompactResults):\n    #Convert the data frame from one record per game to one record per team-game\n    NCAA_res_w = NCAATourneyCompactResults.rename(columns = {'WTeamID': 'NCAA_TEAMID',\n                                                           'LTeamID': 'NCAA_O_TEAMID',\n                                                           'WScore':'NCAA_SCORE',\n                                                           'LScore':'NCAA_O_SCORE'\n                                                             })\n    NCAA_res_l = NCAATourneyCompactResults.rename(columns = {'LTeamID': 'NCAA_TEAMID',\n                                                           'WTeamID': 'NCAA_O_TEAMID',\n                                                           'LScore':'NCAA_SCORE',\n                                                           'WScore':'NCAA_O_SCORE'\n                                                             })\n\n    NCAA_Ses = (NCAA_res_w, NCAA_res_l)\n    NCAA_Ses = pd.concat(NCAA_Ses, ignore_index = True, sort = False)\n    #Derive the outcome of who won[1] or loss[0]\n    NCAA_Ses ['OUTCOME'] = np.where(NCAA_Ses['NCAA_SCORE']>NCAA_Ses['NCAA_O_SCORE'], 1, 0)\n    NCAA_Ses = NCAA_Ses[['Season','NCAA_TEAMID', 'NCAA_O_TEAMID', 'OUTCOME']]\n    return NCAA_Ses","03aa6d03":"NCAATourneyCompactResults = pd.read_csv(in_path + 'NCAATourneyCompactResults.csv')\nNCAA_Ses = NCAASetWinAndLoseTeamsRecords(NCAATourneyCompactResults)\nNCAA_Ses.shape","68042395":"#join ncaa and regSes_adStats ses data for primary team\nNCAA_reg = pd.merge(NCAA_Ses, regSes_adStats, how='inner', \n                   left_on=['Season', 'NCAA_TEAMID'], \n                   right_on=['Season', 'TEAMID'])\n#join to add your opponent's regSes_adStats \nNCAA_reg = pd.merge(NCAA_reg, regSes_adStats, how='inner',\n                    left_on=['Season', 'NCAA_O_TEAMID'],\n                    right_on=['Season', 'TEAMID'], suffixes =['', '_op'] )\nNCAA_reg.shape","8ddc49c5":"NCAATourneySeeds = pd.read_csv(in_path + 'NCAATourneySeeds.csv')\nSeeds = NCAATourneySeeds.copy()\nSeeds['Seed'] = Seeds.Seed.str.replace('[a-zA-Z]', '')\nSeeds['Seed']=Seeds['Seed'].astype('int64')\nSeeds.head(5)","d380043e":"NCAA_reg = pd.merge(NCAA_reg, Seeds, how='inner',\n                    left_on=['Season', 'NCAA_TEAMID'],\n                    right_on=['Season', 'TeamID'])\nNCAA_reg = pd.merge(NCAA_reg, Seeds, how='inner',\n                    left_on=['Season', 'NCAA_O_TEAMID'],\n                    right_on=['Season', 'TeamID'], suffixes =['', '_op'] )\nNCAA_reg.shape","5f8c9854":"cols_to_drop = ['TEAMID', 'TeamID', 'TeamID_op']\nNCAA_features = NCAA_reg.drop(cols_to_drop, axis=1)\nNCAA_features.shape","033df0bd":"NCAA_features.head(5)","ed6c5137":"NCAA_features.to_feather('NCAA_features')","37fdf354":"NCAA_features = pd.read_feather('NCAA_features')\nNCAA_features.shape","7149dcf5":"train = NCAA_features[NCAA_features.Season <= 2016]\nvalid = NCAA_features[NCAA_features.Season == 2017]\ntest = NCAA_features[NCAA_features.Season == 2018]\nprint(\"train shape = \", train.shape)\nprint (\"valid shape = \", test.shape)\nprint (\"test shape = \", test.shape)","8695800a":"X_train = train.drop(['Season', 'NCAA_TEAMID', 'NCAA_O_TEAMID', 'OUTCOME'], axis=1)\ny_train = train[['OUTCOME']]\nX_valid = valid.drop(['Season', 'NCAA_TEAMID', 'NCAA_O_TEAMID', 'OUTCOME'], axis=1)\ny_valid = valid[['OUTCOME']]\nX_test = test.drop(['Season', 'NCAA_TEAMID', 'NCAA_O_TEAMID', 'OUTCOME'], axis=1)\ny_test = test[['OUTCOME']]","3557bacd":"def print_score(m):\n    print (\"train score :\", m.score(X_train, y_train))\n    print (\"valid score :\", m.score(X_valid, y_valid))\n    if hasattr(m, 'oob_score_'): print (\"oob_score : \", m.oob_score_)","cb88ecfc":"m = RandomForestClassifier(n_jobs=-1)\nm.fit(X_train, y_train)\nprint_score(m)","d4809c7a":"m = RandomForestClassifier(n_estimators=1, max_depth=3, bootstrap=False, n_jobs=-1)\nm.fit(X_train, y_train)\nprint_score(m)","6d5938b9":"from sklearn.tree import export_graphviz\nimport IPython\nimport graphviz\ndef draw_tree(t, df, size=10, ratio=0.6, precision=0):\n    \"\"\" Draws a representation of a random forest in IPython.\n    Parameters:\n    -----------\n    t: The tree you wish to draw\n    df: The data used to train the tree. This is used to get the names of the features.\n    \"\"\"\n    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True,\n                      special_characters=True, rotate=True, precision=precision)\n    IPython.display.display(graphviz.Source(re.sub('Tree {',\n       f'Tree {{ size={size}; ratio={ratio}', s)))","3bbf19ea":"draw_tree(m.estimators_[0], X_train, size=7, precision=3)","509b47f3":"m = RandomForestClassifier(n_estimators=100, n_jobs=-1, oob_score=True, random_state=0)\nm.fit(X_train, y_train)\nprint_score(m)","984c5150":"m = RandomForestClassifier(n_estimators=500, n_jobs=-1, oob_score=True, random_state=0)\nm.fit(X_train, y_train)\nprint_score(m)","418edb1c":"m = RandomForestClassifier(n_estimators=700, n_jobs=-1, oob_score=True, random_state=0)\nm.fit(X_train, y_train)\nprint_score(m)","7ab72a73":"m = RandomForestClassifier(n_estimators=800, n_jobs=-1, oob_score=True, random_state=0)\nm.fit(X_train, y_train)\nprint_score(m)","e359a25e":"m = RandomForestClassifier(n_estimators=700, min_samples_leaf=3, n_jobs=-1, oob_score=True, \n                           random_state=0)\nm.fit(X_train, y_train)\nprint_score(m)","0c22ca2c":"for m_f in (0.5, 'sqrt', 'log2', 25, 50):\n    print (\"max_features = \", m_f)\n    m = RandomForestClassifier(n_estimators=700, min_samples_leaf=3, n_jobs=-1, \n                              oob_score=True, random_state=0, \n                              max_features=m_f)\n    m.fit(X_train, y_train)\n    print_score(m)\n    print (\" \")","49a6523c":"def print_score_test(m):\n    print (\"train score :\", m.score(X_train, y_train))\n    print (\"test score :\", m.score(X_test, y_test))\n    if hasattr(m, 'oob_score_'): print (\"oob_score : \", m.oob_score_)","269687e1":"m = RandomForestClassifier(n_estimators=600, min_samples_leaf=3, max_features=25, \n                           n_jobs=-1, oob_score=True, random_state=0)\nm.fit(X_train, y_train)\nprint_score_test(m)","93e50f9e":"print (\"X_train shape before append: \", X_train.shape)\nprint (\"X_valid shape: \", X_valid.shape)\nprint (\"y_train shape before append: \", y_train.shape)\nprint (\"y_valid shape: \", y_valid.shape)\nX_train = X_train.append(X_valid)\ny_train = y_train.append(y_valid)\nprint (\"X_train shape after append: \", X_train.shape)\nprint (\"y_train shape after append: \", y_train.shape)","d4391f8e":"m = RandomForestClassifier(n_estimators=600, min_samples_leaf=3, max_features=25, \n                           n_jobs=-1, oob_score=True, random_state=0)\nm.fit(X_train, y_train)\nprint_score_test(m)","7df345d9":"def rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)","72a60585":"fi = rf_feat_importance(m, X_valid)\nfi[:10]","adce565a":"fi.plot('cols', 'imp', figsize=(10,6), legend=False);","17c5161b":"def plot_fi(fi): return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)","7a0f8e5b":"plot_fi(fi[:10]);","13086b33":"Lets look at our generated features dataframe","facefebb":"**Summary of model parameters **\n\n* n_estimators = 700\n* min_samples_leaf = 3\n* max_features = 25\n\n*Note - as we add or edit additional features, we need to go through this exercise again to pick the best parameters*","9afdeea0":"**Add Seed data**","2d5b2701":"Lets drop some of the demographic features we dont need for the model","a9864e5e":"**Section 3 - Tune for number of trees**","6d346e06":"**Section 5 - Get NCAA Tourney data and pre process it**\n\nThe plan is to join all the features we just generated from the reg season games with the NCAA tourney games, along with the NCAA tourney outcome. All available tournament games will be used within our model.","0108de63":"**Part 2 - Model**\n\nNow that we have our feature set, lets use that to train a RandomForest Model","97bcae92":"*Method to print model scores. We will use this to determine how our model is performing as we make changes.  Out-of-bag (OOB) score is used to calculate error on the training set, but only include the trees in the calculation of a row's error where that row was not included in training that tree.  This allows us to see whether the model is over-fitting, without needing a separate validation set.*","7e3ce103":"We observe that 25 gives us the best score. ","18aac6cb":"**Section 1 - Get a train test split**\n\nLet's split our data based on a time series. Let's use data between 2003-2016 to train our model; 2017 for validation; and use 2018 to test our model.  As a rationale, it is good practice to do a train, validation, and test split.  We will use the validation dataset to incrementally train our dataset while tuning. We will use test dataset as an unbiased evaluation of a final model fit on the training dataset.","2d700266":"Im going to keep the number of trees at 700. \n\n*Note - you could use a library like GridSearchCV and\/or tune for the exact number of trees between 500 and 700 to see how high the score can get, but Im going to leave this at 700 for now.*","8464246a":"**Section 4 - Derive Advanced Stats**\n\nDerive NCAA advanced stats - Reference - https:\/\/www.basketball-reference.com\/about\/glossary.html","c6dab770":"As we can see in the first few examples, this dataframe is structured to have data for both winning (WTeamID) and losing(LTeamID) team features in the same row. In the next section, lets split that into one row per team per game and its opponent. ","e1a05954":"**Section 4 - Number of samples per leaf\/node**\n\nOne way to reduce over-fitting is to grow our trees less deeply. We do this by specifying (with min_samples_leaf) that we require some minimum number of rows in every leaf node. This has two benefits:\n\n* There are less decision rules for each leaf node; simpler models should generalize better\n* The predictions are made by averaging more rows in the lead node, resulting in less volatility\n\nLets set that we require a minimum of 3 samples per leaf\/node","ce458283":"Lets save this file for now using a 'feather' format as recommended per fastai","f836e71a":"As expected we get a very good training score, but not so good validation score on a basic model. ","94b49a32":"**Section 5 - Tune for max features**\n\nWe can also increase the amount of variation amongst the trees by not only using a sample of rows for each tree, but to also using a sample of columns for each split. We do this by specying max_features, which is the proportion of features to randomly select from at each split. \n\nLets try the following options - \n\n* 0.5\n* sqrt\n* log2\n* 25, 50, 80","e008496b":"The first split is based on Offensive rating. Which makes sense, as the primary team's performance will depend on its offensive rating. However, this is just a single tree. \n\nLets keep building the tree, and eventually we will look at this using feature importances. ","d9417fa5":"**Section 1 - Imports and import data**\n\nIn addition to the basics such as numpy and pandas, we will also import the fastai library","8068cf49":"**Introduction** \n\nThis notebook is intended for people who are looking for ways to generate meaningful advanced features for both the primary team and opponent. \nWe will also start with a basic RandomForest model, and tune some hyper parameters to hopefully improve the prediction score. \n\n**Contents** \n\n> **Part 1 - Features and Advanced Stats**\n\t1. Import data\n\t2. Rearrange the data structure to enable feature generation for the primary and opposition teams\n\t3. Aggregate raw stats per season-team\n    4. Derive Advanced Stats\n\t5. Get NCAA Tourney data and pre process it\n\n> **Part 2 - Model**\n\t1. Get a train, valid test split\n\t2. Basic RandomForest Model\n\t3. Tune for number of trees\n\t4. Number of samples per leaf\/node\n\t5. Tune for max features\n    6. Run model on test data\n   \n> **References** - \n> 1. fast.ai\n> 2. https:\/\/www.basketball-reference.com\/about\/glossary.html\n> 3. https:\/\/stats.nba.com","eed7d247":"This makes a lot more sense than the features we saw in the single tree earlier in this notebook. \n\nSeed and Seed_op are inherently a model in itself, to show which teams are better ranked. Therefore it makes sense they are the top important features. \n\nPIE and PIE_op are also comprehensive stats, therefore make sense they are in the top list. Per NBA stats website (https:\/\/stats.nba.com), a team's PIE rating and a team's winning percentage correlate at a R2 of 0.908. ","7ddef9c1":"Lets actually combine the train and valid data into one train dataset, and use that to train our model. And get a test prediction score with that. ","f2ec92a2":"**Section 2 - Basic RandomForest Model**\n\nLet's start with a tree based model.","ac495f64":"**Summary**\n\nThis is our take on a starter set of advanced features, and basic model tuning. The scores arent as high yet, but the plan is to continue to work on building more\/better features, and better models. ","6a0fdb66":"**Feature Importance**\n\nWe want to know how the model is making predictions. The best way to see this is with feature importance.","4cb30555":"We will drop all of the raw aggregated features as teams will play a different number of games per season as the advanced features are all inherently normalized.  Eg Defensive Rating is the number of points given up per 100 possessions.  ","8f2b160d":"Below is the function from fastai, which makes getting feature importances easier","efd7ab60":"**Section 6 - Run model on test data**\n\nLets see how our model performs on the test data","736fd1b1":"**Draw Tree**\n\nLets look at single tree (n_estimators=1) to get an idea of where the features are split.\n\nFastAI V1.0 doesn't have the draw tree method, so I'm using it from its previous version here. ","da43bf73":"**Section 3 - Aggregate raw stats per season-team**\n\nWe'll be performing a sum per season and team for all raw features we can then use in the next section to derive advanced features.","38ab50a1":"**Section 2 - Re arrange dataframe**\n\nIn this section, lets rearrange to show stats for each team against its opponent.  This should double the row count from the original dataframe.\n","434fde39":"Lets look at a quick summary of the variables in the dataframe"}}