{"cell_type":{"76b84525":"code","e1151739":"code","f070ac5c":"code","386232ed":"code","98f0c348":"code","a91603cd":"code","c619a702":"code","0a4f83e2":"code","56bbd4de":"code","ce54a7d3":"code","2360ae56":"code","9aee81cc":"code","f7808dd8":"code","8456f857":"code","b1f72374":"code","3a3166f6":"code","1a4e3597":"markdown","36010776":"markdown","965a2736":"markdown","1325f5d1":"markdown","03efa6a2":"markdown","6abaa009":"markdown","878889e9":"markdown","1c7bbb2e":"markdown","24bf3bd9":"markdown","ab3b5b6a":"markdown","9322190d":"markdown","8773737b":"markdown","3316f6d8":"markdown","6efe314e":"markdown","a81cea29":"markdown","b891c66c":"markdown","bbdcd98a":"markdown","12c68b30":"markdown","9c1c29f6":"markdown","9865b5ad":"markdown","a7390ac0":"markdown","dba5630b":"markdown","ce01b7b2":"markdown","b8cf95a0":"markdown"},"source":{"76b84525":"from IPython.display import clear_output\n!pip install keras-ocr\nclear_output()","e1151739":"import pytesseract\nimport keras_ocr\nimport easyocr\nimport matplotlib.pyplot as plt\nimport cv2\n%matplotlib inline","f070ac5c":"url = [\n    \"https:\/\/raw.githubusercontent.com\/sanskar-hasija\/ocr-comparision\/main\/test_images\/image1.png\",\n    \"https:\/\/raw.githubusercontent.com\/sanskar-hasija\/ocr-comparision\/main\/test_images\/image2.png\",\n    \"https:\/\/raw.githubusercontent.com\/sanskar-hasija\/ocr-comparision\/main\/test_images\/image3.png\",\n    \"https:\/\/raw.githubusercontent.com\/sanskar-hasija\/ocr-comparision\/main\/test_images\/image4.png\"\n]\nimages = [ keras_ocr.tools.read(i) for i in url]","386232ed":"fig = plt.figure(figsize=(16,10))\nrows = 2\ncolumns = 2\n\nfig.add_subplot(rows, columns, 1)\nplt.imshow(images[0])\nplt.axis('off')\nplt.title(\"First Image\")\n\nfig.add_subplot(rows, columns, 2)\nplt.imshow(images[1])\nplt.axis('off')\nplt.title(\"Second Image\")\n\nfig.add_subplot(rows, columns, 3)\nplt.imshow(images[2])\nplt.axis('off')\nplt.title(\"Third Image\")\n\nfig.add_subplot(rows, columns, 4)\nplt.imshow(images[3])\nplt.axis('off')\nplt.title(\"Fourth Image\");","98f0c348":"pipline = keras_ocr.pipeline.Pipeline() #Creting a pipline \nkerasocr_preds = pipline.recognize(images)","a91603cd":"fig,axs = plt.subplots(nrows = 4 , figsize = (30,30))\nfor ax , image,  prediction in zip(axs , images , kerasocr_preds):\n    keras_ocr.tools.drawAnnotations(image, prediction, ax)","c619a702":"text_reader = easyocr.Reader(['en']) #Initialzing the ocr","0a4f83e2":"results = text_reader.readtext(images[0] )\nfor (bbox, text, prob) in results:\n    print(text)\nplt.imshow(images[0])\nplt.title(\"First Image\");","56bbd4de":"results = text_reader.readtext(images[1] )\nfor (bbox, text, prob) in results:\n    print(text)\nplt.imshow(images[1])\nplt.title(\"Second Image\");","ce54a7d3":"results = text_reader.readtext(images[2] )\nfor (bbox, text, prob) in results:\n    print(text)\nplt.imshow(images[2])\nplt.title(\"Third Image\");","2360ae56":"results = text_reader.readtext(images[3] )\nfor (bbox, text, prob) in results:\n    print(text)\nplt.imshow(images[3])\nplt.title(\"Fourth Image\");","9aee81cc":"tesseract_preds = []\nfor img in images:\n    tesseract_preds.append(pytesseract.image_to_string(img))","f7808dd8":"print(tesseract_preds[0])\nplt.imshow(images[0])\nplt.title(\"First Image\");","8456f857":"print(tesseract_preds[1])\nplt.imshow(images[1])\nplt.title(\"Second Image\");","b1f72374":"print(tesseract_preds[2])\nplt.imshow(images[2])\nplt.title(\"Third Image\");","3a3166f6":"print(tesseract_preds[3])\nplt.imshow(images[3])\nplt.title(\"Fourth Image\");","1a4e3597":"### Third Image","36010776":"### Fourth Image","965a2736":"## Installing Keras-ocr","1325f5d1":"<a id=\"pytesseract\"><\/a>\n# Pytesseract","03efa6a2":"## TEST IMAGES","6abaa009":"### * Keras-OCR is image specific OCR tool. If text is inside the image and their fonts and colors are unorganized, Keras-ocr consumes time if used on CPU\n### * EasyOCR is lightweight model which is giving a good performance for receipt or PDF conversion. It is giving more accurate results with organized texts like pdf files, receipts, bills. EasyOCR also performs well on noisy images\n### * Pytesseract is performing well for high-resolution images. Certain morphological operations such as dilation, erosion, OTSU binarization can help increase pytesseract performance. It also provides better results on handwritten text as compared to EasyOCR\n### * All these results can be further improved by performing specific image operations.","878889e9":"## Results of Keras-OCR","1c7bbb2e":"<a id=\"easyocr\"><\/a>\n# EASYOCR","24bf3bd9":"<a id=\"kerasocr\"><\/a>\n# KERAS_OCR","ab3b5b6a":"### Image 2","9322190d":"## Results of EASY OCR","8773737b":"### Image 1 ","3316f6d8":"##  Results of Pytesseract","6efe314e":"### Second Image","a81cea29":"<a id=\"conclusions\"><\/a>\n# CONCLUSIONS","b891c66c":"# <center> Keras-OCR VS EasyOCR VS PYTESSERACT <\/center>","bbdcd98a":"## Image 4","12c68b30":"### Keras-ocr plots boxes of detected text with annotations on the input image.","9c1c29f6":"\n**Created by Sanskar Hasija**\n\n**Keras-OCR VS EasyOCR VS PYTESSERACT**\n\n**24 August 2021**\n","9865b5ad":"## IMPORTS","a7390ac0":"### [1. KERAS-OCR](#kerasocr) ###\n### [2. EASYOCR](#easyocr) ###\n### [3. PYTESSERACT](#pytesseract) ###\n##    [Conclusions](#conclusions) ##","dba5630b":"## Image 3","ce01b7b2":"### First Image","b8cf95a0":"# <center>If you find this notebook useful, support with an upvote!<\/center>"}}