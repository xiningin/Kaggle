{"cell_type":{"191e776e":"code","7e2e52c4":"code","28e8f1ed":"code","bf47d3d2":"code","eee3594f":"code","5bab272a":"code","cbe891b2":"code","dd767fef":"code","2b6d40e3":"code","00e77201":"code","341a23a7":"code","36675b66":"code","8ee2606c":"code","4759d382":"code","8095c074":"code","392d959b":"code","0a5af15d":"code","b6807a9c":"code","3d355c66":"code","569d2df0":"code","1061258d":"markdown","fc7b83e9":"markdown","2764b228":"markdown","75b0240e":"markdown","1c986634":"markdown","12388c8d":"markdown","ddfd6e84":"markdown","6764e754":"markdown","ea061d4d":"markdown","06073e3d":"markdown"},"source":{"191e776e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","7e2e52c4":"# Load the data into DataFrames\ntrain_users = pd.read_csv('..\/input\/airbnb-recruiting-new-user-bookings\/train_users_2.csv')\ntest_users = pd.read_csv('..\/input\/airbnb-recruiting-new-user-bookings\/test_users.csv')","28e8f1ed":"print(\"Number of users in training set =\", train_users.shape[0] )\nprint(\"Number of users in test set =\",test_users.shape[0])","bf47d3d2":"train_users.head()","eee3594f":"train_users.describe(include = 'all')","5bab272a":"test_users.head()","cbe891b2":"test_users.describe(include = 'all')","dd767fef":"labels = train_users['country_destination'].values\ntrain_users = train_users.drop(['country_destination', 'date_first_booking'], axis=1)\ntest_users = test_users.drop(['date_first_booking'], axis=1)\nid_test = test_users['id']\n\n# Merge train and test users\nall_users = pd.concat((train_users, test_users), axis=0, ignore_index=True)\n\n# Remove ID's since now we are not interested in making predictions\nall_users.drop('id',axis=1, inplace=True)\n\nall_users.head()","2b6d40e3":"from datetime import datetime\nall_users['date_account_created'] = pd.to_datetime(all_users['date_account_created'])\nall_users['timestamp_first_active'] = pd.to_datetime((all_users.timestamp_first_active \/\/ 1000000), format='%Y%m%d')\n\nall_users['date_account_created'] = [datetime.timestamp(d) for d in all_users['date_account_created']]\nall_users['timestamp_first_active'] = [datetime.timestamp(d) for d in all_users['timestamp_first_active']]","00e77201":"all_users.age.describe()","341a23a7":"sns.distplot(all_users.age.dropna())\nplt.xlabel('Age')","36675b66":"sns.distplot(all_users.age.loc[all_users['age'] < 70].dropna())\nplt.xlabel('Age')","8ee2606c":"all_users['age'] = np.where(all_users['age']<=14, 14, all_users['age'])\nall_users['age'] = np.where(all_users['age']>=70, 70, all_users['age'])\nall_users['age'] = all_users['age'].fillna(all_users['age'].dropna().values.mean())\nall_users['age'].describe()","4759d382":"all_users['age'].values.mean()","8095c074":"categorical_features = [\n    'affiliate_channel',\n    'affiliate_provider',\n    'first_affiliate_tracked',\n    'first_browser',\n    'first_device_type',\n    'gender',\n    'language',\n    'signup_app',\n    'signup_method'\n]\n\n# one-hot-encoding\nfor categorical_feature in categorical_features:\n    all_users_dummies = pd.get_dummies(all_users[categorical_feature], prefix=categorical_feature)\n    all_users = all_users.drop([categorical_feature], axis=1)\n    all_users = pd.concat((all_users, all_users_dummies), axis=1)","392d959b":"all_users.head()","0a5af15d":"from sklearn.preprocessing import LabelEncoder\n\ntrain_users_n = train_users.shape[0]\nX_train = all_users.values[:train_users_n]\nle = LabelEncoder()\ny_train = le.fit_transform(labels)   \nX_test = all_users.values[train_users_n:]","b6807a9c":"def generate_answer(y_pred, classifer_name):\n    #Taking the 5 classes with highest probabilities\n    ids = []  #list of ids\n    cts = []  #list of countries\n    for i in range(len(id_test)):\n        idx = id_test[i]\n        ids += [idx] * 5\n        cts += le.inverse_transform(np.argsort(y_pred[i])[::-1])[:5].tolist()\n    \n    sub = pd.DataFrame(np.column_stack((ids, cts)), columns=['id', 'country'])\n    sub.to_csv(classifer_name+'.csv',index=False)\n    return sub","3d355c66":"from sklearn.neural_network import MLPClassifier\nmlp = MLPClassifier()\nmlp.fit(X_train, y_train)\ny_pred_mlp = mlp.predict_proba(X_test)\ngenerate_answer(y_pred_mlp, 'MLP')","569d2df0":"from xgboost.sklearn import XGBClassifier\n\nxgb = XGBClassifier(max_depth=6, learning_rate=0.3, n_estimators=25,\n                    objective='multi:softprob', subsample=0.5, colsample_bytree=0.5, seed=0)                  \nxgb.fit(X_train, y_train)\ny_pred_xgb = xgb.predict_proba(X_test)\ngenerate_answer(y_pred_xgb, 'XGB')","1061258d":"## Loading The DataSet","fc7b83e9":"As we can see above, the common age to travel is between 14 and 70. So I will smooth Age distribution by remove all values bellow 14 and above 70.","2764b228":"## Import Libraries","75b0240e":"# Airbnb New User Bookings","1c986634":"## Classification","12388c8d":"## Feature Engineering","ddfd6e84":"### MLP Classifier","6764e754":"From above, We can see that date_first_booking feature is allways NaN in test dataset so I will remove it from both training and testing.","ea061d4d":"## Data Cleaning","06073e3d":"### XGBClassifier"}}