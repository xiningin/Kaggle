{"cell_type":{"8890df95":"code","ddc5cddb":"code","0367e702":"code","6da2e2a7":"code","a7cc99de":"code","03ac94b7":"code","f63edd52":"code","b9ab3813":"code","5509042d":"code","1bee4ea6":"code","1af88d3b":"code","6f5712e1":"code","162c690d":"code","5aa9d5a2":"code","99bd7175":"code","91b9bca0":"markdown","dfdbcd7e":"markdown","b899df3c":"markdown","0bf31ef3":"markdown","c80e0c57":"markdown"},"source":{"8890df95":"from nltk.corpus import subjectivity\n\nsubjectivity.fileids()","ddc5cddb":"subjectivity.sents('plot.tok.gt9.5000')","0367e702":"subjectivity.sents('quote.tok.gt9.5000')","6da2e2a7":"subjectivity.categories() # The mapping between documents and categories does not depend on the file structure.","a7cc99de":"subjectivity.sents(categories='obj')","03ac94b7":"subjectivity.sents(categories='subj')","f63edd52":"from nltk.classify import NaiveBayesClassifier\nfrom nltk.sentiment import SentimentAnalyzer # SentimentAnalyzer is a tool to implement and facilitate Sentiment Analysis.\nfrom nltk.sentiment.util import (mark_negation, extract_unigram_feats) # mark_negation(): Append _NEG suffix to words that appear in the scope between a negation and a punctuation mark. extract_unigram_feats(): Populate a dictionary of unigram features, reflecting the presence\/absence in the document of each of the tokens in unigrams.\n\nn_instances = 100\nobj_docs = [(sent, 'obj') for sent in subjectivity.sents(categories='obj')[:n_instances]]\nsubj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')[:n_instances]]\nlen(obj_docs), len(subj_docs)","b9ab3813":"obj_docs[0]","5509042d":"train_obj_docs = obj_docs[:80]\ntest_obj_docs = obj_docs[80:100]\ntrain_subj_docs = subj_docs[:80]\ntest_subj_docs = subj_docs[80:100]\n\ntraining_docs = train_obj_docs + train_subj_docs\ntesting_docs = test_obj_docs + test_subj_docs\n\nsentim_analyzer = SentimentAnalyzer()\nall_words_neg = sentim_analyzer.all_words([mark_negation(doc) for doc in training_docs])","1bee4ea6":"unigram_feats = sentim_analyzer.unigram_word_feats(all_words_neg, min_freq=4)\nlen(unigram_feats)","1af88d3b":"sentim_analyzer.add_feat_extractor(extract_unigram_feats, unigrams=unigram_feats)","6f5712e1":"training_set = sentim_analyzer.apply_features(training_docs)\ntest_set = sentim_analyzer.apply_features(testing_docs)\ntraining_set[0]","162c690d":"trainer = NaiveBayesClassifier.train\nclassifier = sentim_analyzer.train(trainer, training_set)","5aa9d5a2":"for key,value in sorted(sentim_analyzer.evaluate(test_set).items()):\n    print('{0}: {1}'.format(key, value))","99bd7175":"from nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nsentences = [\n    \"You are a piece of shit, and I will step on you.\",\n    \"THIS SUX!!!\",\n    \"This kinda sux...\",\n    \"You're good, man\",\n    \"HAHAHA YOU ARE THE BEST!!!!! VERY FUNNY!!!\"\n            ]\n\n\nsid = SentimentIntensityAnalyzer()\n\nfor sentence in sentences:\n    print('\\n' + sentence)\n    ss = sid.polarity_scores(sentence)\n    for k in sorted(ss):\n        print('{0}: {1}, '.format(k, ss[k]), end='')","91b9bca0":"## 2. Building and testing a classifier with `SentimentAnalyzer`","dfdbcd7e":"## 3. Sentiment analysis with `nltk.sentiment.vader.SentimentIntensityAnalyzer`","b899df3c":"Above, `compound` represents the aggregated, final score.","0bf31ef3":"## 1. Exploring the `subjectivity` corpus","c80e0c57":"# Sentiment Analysis with `nltk.sentiment.SentimentAnalyzer` and VADER tools"}}