{"cell_type":{"7545ede1":"code","3f3ba1b8":"code","f112bbdd":"code","4b45172d":"code","3b8c39de":"code","4e80013b":"code","7000bae4":"code","91972f8f":"code","71a14169":"code","26542d1f":"code","904964f2":"code","c7eebddb":"code","afbdd627":"code","b32c0b1b":"code","3799801e":"code","29c83bdf":"code","ad5ba1d5":"code","b15baedd":"code","d08e13ac":"markdown","686763ee":"markdown","e7050606":"markdown"},"source":{"7545ede1":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.tree import DecisionTreeClassifier\nimport optuna","3f3ba1b8":"from warnings import filterwarnings\nfilterwarnings('ignore')","f112bbdd":"df_train = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/train.csv')\ndf_test  = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/test.csv')\nss       = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv')","4b45172d":"X = df_train.drop(columns=['id','claim']).copy()\ny = df_train['claim'].copy()\nX_test = df_test.drop(columns=['id']).copy()","3b8c39de":"X['NaN_row'] = X.isna().sum(axis=1)\nX_test['NaN_row'] = X_test.isna().sum(axis=1)","4e80013b":"pipeline = Pipeline([\n    ('impute', SimpleImputer(strategy='constant')),\n    ('scale', StandardScaler())\n])\n\nX = pd.DataFrame(columns=X.columns, data=pipeline.fit_transform(X))\nX_test = pd.DataFrame(columns=X_test.columns, data=pipeline.transform(X_test))","7000bae4":"X.head()","91972f8f":"def objective(trial, data=X, target=y):\n    train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.2,random_state=42)\n    \n    params = {\n        'loss' : 'binary_crossentropy',\n        'learning_rate' : trial.suggest_uniform('learning_rate',0.02,1),\n        'max_iter' : trial.suggest_categorical('max_iter', [20, 30, 50, 100, 150, 200, 500, 1000]),\n        'max_leaf_nodes' : trial.suggest_int('max_leaf_nodes', 2, 256),\n        'max_depth' : trial.suggest_categorical('max_depth',[1, 2, 4, 5, 7, 9, 11, 13, 15]),\n        'min_samples_leaf' : trial.suggest_int('min_sample_leaf', 1, 200),\n        'l2_regularization' : trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n        'random_state' : 2021,\n        'verbose' : 0,\n        'early_stopping' : 100\n    }\n    \n    model = HistGradientBoostingClassifier(**params)\n    model.fit(train_x,train_y)\n    \n    preds = model.predict_proba(test_x)[:,1]\n    fpr, tpr, _ = roc_curve(test_y, preds)\n    score = auc(fpr, tpr)\n    \n    return score","71a14169":"study = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=30)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","26542d1f":"optuna.visualization.plot_optimization_history(study)","904964f2":"optuna.visualization.plot_edf(study)","c7eebddb":"optuna.visualization.plot_param_importances(study)","afbdd627":"optuna.visualization.plot_slice(study)","b32c0b1b":"optuna.visualization.plot_parallel_coordinate(study)","3799801e":"optuna.visualization.plot_contour(study)","29c83bdf":"params=study.best_params\nparams['min_samples_leaf'] = params['min_sample_leaf']\nparams.pop('min_sample_leaf')\nparams['l2_regularization'] = params['reg_lambda']\nparams.pop('reg_lambda')\nprint(params)","ad5ba1d5":"%%time\nkf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n\npreds = []\nscores = []\n\nfor fold, (idx_train, idx_valid) in enumerate(kf.split(X, y)):\n    X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n    X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n    \n    model = HistGradientBoostingClassifier(**params)\n    model.fit(X_train,y_train)\n    \n    pred_valid = model.predict_proba(X_valid)[:,1]\n    fpr, tpr, _ = roc_curve(y_valid, pred_valid)\n    score = auc(fpr, tpr)\n    scores.append(score)\n    \n    print(f\"Fold: {fold + 1} Score: {score}\")\n    print('-'*25)\n    \n    test_preds = model.predict_proba(X_test)[:,1]\n    preds.append(test_preds)\n    \nprint(f\"Overall Validation Score: {np.mean(scores)}\")","b15baedd":"predictions = np.mean(np.column_stack(preds),axis=1)\n\nss['claim'] = predictions\nss.to_csv('.\/gbhist.csv', index=False)\nss.head()","d08e13ac":"**Note:-** If a parameter containing missing values, then trial with missing values will not be plotted in case of ***plot_parallel_coordinate*** and ***plot_slice***.","686763ee":"# Visualization","e7050606":"**Note:-** Since (*HistGradientBoosting*) is inspired by (*LightGBM*) so some parameter names like **min_samples_leaf** and **l2_regularization** will get changed to **min_sample_leaf** and **reg_lambda** respectively. So change it otherwise it will throw an error."}}