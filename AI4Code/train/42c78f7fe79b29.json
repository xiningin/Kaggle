{"cell_type":{"cc1db1c6":"code","f232b003":"code","5c3c58ed":"code","4c77f481":"code","8608ce0b":"code","cd34f847":"code","f7c985e3":"code","196f8261":"code","73a98b2d":"code","e00b2755":"code","ebfb8ddb":"code","0496a680":"code","6eb96456":"code","c112be40":"code","e6065204":"code","dad90fd3":"code","d6f72a05":"code","d7e7bbed":"code","dfb955a5":"code","ed3254a7":"markdown","d72866f2":"markdown","f3d20ece":"markdown","73a65f71":"markdown","bd696682":"markdown","3d9d39bc":"markdown","a42925f2":"markdown","5fe827ab":"markdown","5ec81a67":"markdown","6fbe7944":"markdown","a5903f27":"markdown","1678c0d2":"markdown","b2184a15":"markdown","28ffacd1":"markdown","01f84422":"markdown"},"source":{"cc1db1c6":"from tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential","f232b003":"from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input","5c3c58ed":"num_class = 6\n\nmodel = Sequential([ResNet50(include_top=False,\n                             weights='imagenet',\n                             pooling='avg'),\n                    Dense(num_class, activation='softmax')])\n\nmodel.layers[0].trainable = False","4c77f481":"from tensorflow.keras.optimizers import SGD","8608ce0b":"lr = 0.01\nmomentum = 0.001\nopt = SGD(learning_rate=lr, momentum=momentum)\n\nmodel.compile(optimizer=opt,\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.summary()","cd34f847":"data_path = \"..\/input\/split-garbage-dataset\/split-garbage-dataset\"\n\ndata_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n\nimg_shape = 224\ntrain_gen = data_generator.flow_from_directory(data_path + '\/train',\n                                               target_size=(img_shape, img_shape),\n                                               batch_size=64,\n                                               class_mode='categorical')\n\nval_gen = data_generator.flow_from_directory(data_path + '\/valid',\n                                             target_size=(img_shape, img_shape),\n                                             batch_size=1,\n                                             class_mode='categorical',\n                                             shuffle=False)","f7c985e3":"from tensorflow.keras.callbacks import ModelCheckpoint","196f8261":"n_epoch = 50\n\nmodel_name = 'resnet50_batch64_sgd01m001'\ncheckpoint = ModelCheckpoint('.\/' +  model_name + '.h5',\n                             monitor='val_loss',\n                             save_best_only=True,\n                             verbose=1)\n\nhistory = model.fit_generator(train_gen,\n                              steps_per_epoch=train_gen.samples\/train_gen.batch_size,\n                              validation_data=val_gen,\n                              validation_steps=val_gen.samples\/val_gen.batch_size,\n                              epochs=n_epoch,\n                              callbacks=[checkpoint])","73a98b2d":"import matplotlib.pyplot as plt\nimport seaborn as sns","e00b2755":"val_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\nacc = history.history['accuracy']\nloss = history.history['loss']","ebfb8ddb":"plt.plot(range(n_epoch), acc, 'b*-', label = 'Training accuracy')\nplt.plot(range(n_epoch), val_acc, 'r', label = 'Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()","0496a680":"plt.plot(range(n_epoch), loss, 'b*-', label = 'Training loss')\nplt.plot(range(n_epoch), val_loss, 'r', label = 'Validation loss')\nplt.title('Training and validation loss')\nplt.legend()","6eb96456":"data_path = \"..\/input\/split-garbage-dataset\/split-garbage-dataset\"\n\ndata_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n\ntest_gen = data_generator.flow_from_directory(data_path + '\/test',\n                                              target_size=(img_shape, img_shape),\n                                              batch_size=1,\n                                              class_mode='categorical',\n                                              shuffle=False)","c112be40":"from tensorflow.keras.models import load_model\nimport numpy as np","e6065204":"eval_model = load_model('.\/' + model_name + '.h5')\neval_model.summary()","dad90fd3":"y_pred = eval_model.predict_generator(test_gen)\ny_pred = np.argmax(y_pred, axis=1)","d6f72a05":"from sklearn.metrics import classification_report, confusion_matrix","d7e7bbed":"print(classification_report(test_gen.classes, y_pred))","dfb955a5":"cf_matrix = confusion_matrix(test_gen.classes, y_pred)\n\nplt.figure(figsize=(8,5))\nheatmap = sns.heatmap(cf_matrix, annot=True, fmt='d', color='blue')\nplt.xlabel('Predicted class')\nplt.ylabel('True class')\nplt.title('Confusion matrix of model')","ed3254a7":"We then add the architecture with additional `Dense` layer consisting of `num_class` nodes, according to number of classes in the dataset","d72866f2":"If you have the saved model somewhere in your PC, you could load the model back using `load_model` function provided","f3d20ece":"As we can see from above, the general performance of the model can be seen on the 'accuracy' row. We can also see how good the model performs wrt. each classes in the data, and also which class the model might be bias to.","73a65f71":"Inside `ModelCheckpoint`, we could configure the callback according to the behaviour we needed, such as\n* filename of the saved model\n* what metric will the callback monitor to execute the process, this will helps in optimizing the process of saving model\n* do we need to `save_best_only`, which will overwrite saved model with better one (if the monitored metric improves)","bd696682":"## Load the dataset\n\nLater then, we could start importing the data to be used in training. In this case, we use `ImageDataGenerator` to gather the data whilst applying preprocessing steps on the data before entering the model.\n\n`ImageDataGenerator` also provides easier method of reading data by using `flow_from_directory`, which will read data from certain directory. If a subsequent subdirs found inside the directory, `ImageDataGenerator` will consider it as the class label of the data inside said subdir.","3d9d39bc":"To evaluate the prediction result, we can use `classification_report` to get statistic of it and `confusion_matrix` for further analysis of the prediction","a42925f2":"After loaded the model, we can start feeding the model with test data and get the prediction result.","5fe827ab":"## Test model\n\nTesting the model are step to measure model capability when facing data not from what it have learned. This step provides us with information on how good the model has learned the data\n\nIn this case, we could also provide the data in the format of `ImageDataGenerator` iterator, similar to training phase","5ec81a67":"Using the confusion matrix we got from `scikit_learn`, we could plot it using `seaborn`'s heatmap visualization for better insight one the model.\n\nWe can see which part in each classes the model predicted. Using this matrix, we can also analyze which class the model still confuses and which class does the model performs better. With this analysis, we could develop a better training strategies to get a better-performed model in the future","6fbe7944":"1. For better visualization, we can use `matplotlib` to plot the values into graphs","a5903f27":"## Train the model\n\nAfter the model and the data needed are ready, we can start training our model. \n\nKeras also provides us with callbacks, a set of functions which will be executed during certain time in training (before an epoch ends, before an iteration finished, etc). These callbacks provide features that could be beneficial in monitoring the performance of model during training phase.\n\nIn this one, we will use `ModelCheckpoint`, a built-in callback that provide automated checkpointing of trained model.","1678c0d2":"## Build the model\n\nFirst of all, we build the model by importing Resnet architecture available. In this one, we will use Resnet50 available from `tensorflow.keras.applications`. ","b2184a15":"After training the model, `fit_generator` dumps all the recorded metrics inside a `History` object. We could access these metrics by loading the object with index name of the metric we would like to see, such as `accuracy` or `loss`. You can also add `val_` prefix in front of each if you want to access the validation metrics (only if you provided validation data for your training process)","28ffacd1":"# Waste Classification using ResNet50\n\nThis implementation is inspired from [Transfer Learning tutorial](https:\/\/www.kaggle.com\/dansbecker\/transfer-learning) by Dans Becker and another notebook by [Gianluca Pagliara](https:\/\/www.kaggle.com\/gianpgl\/garbage-classification-vgg16\/output)","01f84422":"After creating the architecture, we compiled the model by providing another required items, such as \n* the optimizer method to be used\n* loss function used to calculate losses\n* additional metric that we would like to measure"}}