{"cell_type":{"c52a444f":"code","ca6fd446":"code","8589de34":"code","25e40204":"code","23158516":"code","22c59faa":"code","d27de2a1":"code","1c51a3bd":"code","b87c5f16":"code","076a4efd":"code","fd26ba7d":"code","3d50639a":"code","0023d20d":"code","9545b4b7":"code","42ce369a":"code","5493f262":"code","661ae363":"code","a9f0488a":"code","bd0f507b":"code","e824201e":"code","cc58a43b":"code","6b02f574":"code","7c1d04b1":"code","33b12e8b":"code","a27f5663":"markdown"},"source":{"c52a444f":"# import the necessary packages\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport os\nimport random\nimport matplotlib.pyplot as plt\nimport PIL\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.initializers import glorot_uniform\nfrom tensorflow.keras.utils import plot_model\nfrom IPython.display import display\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler \nfrom random import sample","ca6fd446":"train = {}\ntest = {}\n\npath = \"..\/input\/food11-image-dataset\"\n\n# Make dictionary storing images for each category under train data.\npath_train = os.path.join(path, \"training\")\nfor i in os.listdir(path_train):\n    train[i] = os.listdir(os.path.join(path_train, i))\n\n# Make dictionary storing images for each category under test data.\npath_test = os.path.join(path, \"validation\")\nfor i in os.listdir(path_test):\n    test[i] = os.listdir(os.path.join(path_test, i))","8589de34":"# View the number of images in the entire training and testing datasets respectively.\nlen_train = np.concatenate(list(train.values())).shape[0]\nlen_test = np.concatenate(list(test.values())).shape[0]\n\nprint(\"Number of images in training data : {}\".format(len_train))\nprint(\"Number of images in testing data : {}\".format(len_test))","25e40204":"# Randomly display 5 images under each of the 6 categories from the training data.\n# You will see different images each time.\nfig, axs = plt.subplots(len(train.keys()), 5, figsize = (15, 15))\nfor i, item in enumerate(os.listdir(path_train)):\n    images = sample(train[item], 5)\n    \n    for j, image in enumerate(images):\n        img = PIL.Image.open(os.path.join(path_train, item, image))\n        axs[i, j].imshow(img)\n        axs[i, j].set(xlabel = item, xticks = [], yticks = [])\n\nfig.tight_layout()","23158516":"# View the number of images in each of the 6 categories in the training data.\nfor item in train.keys():\n    print(item, len(train[item]))","22c59faa":"# Make a pie-chart to visualize the percentage contribution of each category.\n# This is often useful when you want your dataset to be balanced.\nfig, ax = plt.subplots()\nax.pie(\n    [len(train[item]) for item in train],\n    labels = train.keys(),\n    autopct = \"%1.1f%%\"\n)\nfig.show()","d27de2a1":"# Create an Image Generator and specify the type of data augmentation you want to apply.\n# Here we go with zooming, flipping (horizontally and vertically), and rescaling.\ntrain_datagen = ImageDataGenerator(\n    zoom_range = 0.2,\n    horizontal_flip = True,\n    vertical_flip = True,\n    rescale=1.\/255\n)\n\n# For test data we only rescale the data.\n# Never augment test data!!!\ntest_datagen = ImageDataGenerator(rescale=1.\/255)","1c51a3bd":"# Create a generator for the images. \n# This will make images (including augmented ones) start flowing from the directory to the model.\n# Note that augmented images are not stored along with the original images. The process happens in memory.\n\n# Train generator\ntrain_generator = train_datagen.flow_from_directory(\n    path_train,\n    target_size=(256, 256),\n    batch_size=32,\n    class_mode='categorical'\n)\n\n# Test generator\ntest_generator = test_datagen.flow_from_directory(\n    path_test,\n    target_size=(256, 256),\n    batch_size=32,\n    class_mode='categorical'\n)","b87c5f16":"# Load the inception resnetv2 model\nbasemodel = InceptionResNetV2(\n    weights = \"imagenet\",\n    include_top = False, # Classification layer (output layer- sigmoid activations)\n    input_tensor = Input((256, 256, 3))\n)","076a4efd":"# print the model summary\nbasemodel.summary()","fd26ba7d":"# Freeze the basemodel weights, so these weights won't change during training\nbasemodel.trainable = False","3d50639a":"# Add classification head to the model\nheadmodel = basemodel.output\nheadmodel = GlobalAveragePooling2D(name = \"Global_Average_Pool\")(headmodel)\nheadmodel = Flatten(name = \"flatten\")(headmodel)\nheadmodel = Dense(256, activation = \"relu\", name = \"dense_1\")(headmodel)\nheadmodel = Dropout(0.3)(headmodel)\nheadmodel = Dense(128, activation = \"relu\", name = \"dense_2\")(headmodel)\nheadmodel = Dropout(0.3)(headmodel)\nheadmodel = Dense(11, activation = \"softmax\", name = \"output\")(headmodel)\n\nmodel = Model(inputs = basemodel.input, outputs = headmodel)","0023d20d":"# Compile the model\nmodel.compile(\n    loss = \"categorical_crossentropy\",\n    optimizer = SGD(\n        lr = 0.01,\n        momentum = 0.9\n    ),\n    metrics = [\"accuracy\"]\n)","9545b4b7":"# Using early stopping to exit training if validation loss is not decreasing even after certain epochs (patience)\nearlystopping = EarlyStopping(\n    monitor = 'loss', \n    verbose = 1, \n    patience = 20\n)\n\n# save the best model with lower loss\ncheckpointer = ModelCheckpoint(\n    filepath = \"weights.hdf5\", \n    verbose = 1, \n    save_best_only = True\n)","42ce369a":"# Finally, fit the neural network model to the data.\nhistory = model.fit(\n    train_generator, \n    steps_per_epoch = train_generator.n \/\/ 32, \n    epochs = 1,  \n    callbacks = [checkpointer, earlystopping]\n)","5493f262":"# Unfreeze the weights in the base model, now these weights will be changed during training\nbasemodel.trainable = True","661ae363":"# Using early stopping to exit training if validation loss is not decreasing even after certain epochs (patience)\nearlystopping = EarlyStopping(\n    monitor = 'loss', \n    verbose = 1, \n    patience = 20\n)\n\n# Save the best model with lower loss\ncheckpointer = ModelCheckpoint(\n    filepath = \"weights_fine.hdf5\", \n    verbose = 1, \n    save_best_only = True\n)","a9f0488a":"# fine tune the model with very low learning rate\nhistory = model.fit(\n    train_generator, \n    steps_per_epoch = train_generator.n \/\/ 32, \n    epochs = 5, \n    callbacks = [checkpointer, earlystopping]\n)","bd0f507b":"# Evaluate the performance of the model\nevaluate = model.evaluate_generator(\n    test_generator, \n    steps = test_generator.n \/\/ 32, \n    verbose = 1\n)\n\nprint('Accuracy Test : {}'.format(evaluate[1]))","e824201e":"# Assigning label names to the corresponding indexes\nlabels = {\n    0: 'Bread', \n    1: 'Dairy product', \n    2: 'Dessert', \n    3: 'Egg', \n    4: 'Fried food', \n    5: 'Meat',\n    6: 'Noodles-Pasta',\n    7: 'Rice', \n    8: 'Seafood',\n    9: 'Soup',\n    10: 'Vegetable-Fruit'\n}","cc58a43b":"# Loading images and their predictions \nprediction = []\noriginal = []\nimage = []\ncount = 0\npath_eval = \"..\/input\/food11-image-dataset\/evaluation\"\nfor i in os.listdir(path_eval):\n    for item in os.listdir(os.path.join(path_eval, i)):\n        #code to open the image\n        img= PIL.Image.open(os.path.join(path_eval, i, item))\n        #resizing the image to (256,256)\n        img = img.resize((256,256))\n        #appending image to the image list\n        image.append(img)\n        #converting image to array\n        img = np.asarray(img, dtype= np.float32)\n        #normalizing the image\n        img = img \/ 255\n        #reshaping the image in to a 4D array\n        img = img.reshape(-1,256,256,3)\n        #making prediction of the model\n        predict = model.predict(img)\n        #getting the index corresponding to the highest value in the prediction\n        predict = np.argmax(predict)\n        #appending the predicted class to the list\n        prediction.append(labels[predict])\n        #appending original class to the list\n        original.append(i)","6b02f574":"# Visualizing the results\nfig=plt.figure(figsize = (100,100))\nfor i in range(20):\n    j = random.randint(0,len(image))\n    fig.add_subplot(20,1,i+1)\n    plt.xlabel(\"Prediction -\" + prediction[j] +\"   Original -\" + original[j])\n    plt.imshow(image[j])\nfig.tight_layout()\nplt.show()","7c1d04b1":"# Check out the Classification Report \nprint(classification_report(np.asarray(prediction), np.asarray(original)))\n\n# Based on these values, you can try t improve your model.\n# For the sake of simplicity, hyperparameter tuning and model improvement was not done.","33b12e8b":"# View the 6x6 confusion matrix\nplt.figure(figsize = (7, 5))\ncm = confusion_matrix(np.asarray(prediction), np.asarray(original))\nsns.heatmap(\n    cm, \n    annot = True, \n    fmt = \"d\"\n)\nplt.show()","a27f5663":"### Fine tuning"}}