{"cell_type":{"f78b2350":"code","3f891961":"code","6fcf80f4":"code","fb5d804c":"code","9e9f371c":"code","1d5cdaa0":"code","38976897":"code","f5c3d0a9":"code","3ddacf80":"code","c55932a2":"code","078c829a":"code","9e6e9162":"code","9bf53c6f":"code","79d30b2f":"code","5a6614ec":"code","c6c8e8b6":"code","1d7d01bc":"code","6e00bef5":"code","19c3221e":"code","5510a4aa":"code","a9b677fd":"code","f3bb0f25":"code","5ca52845":"code","7fc0a9c3":"code","b60e5930":"code","d532cc28":"code","1a17b651":"code","7bd27e6b":"code","587d8d9f":"code","f5f6d94e":"code","1061b327":"code","0f534e75":"code","32e74c71":"code","25d694fa":"code","2ac35b08":"code","8b137804":"code","7946ffa2":"code","223cc2ac":"code","0de21baf":"code","30109937":"markdown","bf548dde":"markdown","de068584":"markdown","a2df061d":"markdown","ff64e784":"markdown","754e39a5":"markdown","d2d84511":"markdown","c0284ecf":"markdown","f589ef99":"markdown","fa27ebf6":"markdown","8e0394b7":"markdown","501796ad":"markdown","50723059":"markdown","fb03b47c":"markdown","8ef0f9e2":"markdown"},"source":{"f78b2350":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport os\nimport zipfile\n\nimport tensorflow as tf\n%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\nimport matplotlib.pyplot as plt \nfrom sklearn.model_selection import KFold\nimport pandas as pd\nimport numpy as np \nsns.set()\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n'''import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))'''\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3f891961":"df = pd.read_csv('\/kaggle\/input\/siim-isic-melanoma-classification\/train.csv')\ndf.tail()","6fcf80f4":"sns.countplot(df['sex'])","fb5d804c":"sns.countplot(y = df['anatom_site_general_challenge'], hue =df['sex'])","9e9f371c":"sns.distplot(df['age_approx'], bins=20, kde=False, rug=True);","1d5cdaa0":"sns.countplot(y = df['diagnosis'], hue =df['sex'])","38976897":"sns.countplot(y = df['anatom_site_general_challenge'], hue =df['sex'])","f5c3d0a9":"sns.countplot(x = df['benign_malignant'],  hue =df['sex'] )","3ddacf80":"sns.countplot(x = df['target'])","c55932a2":"a = np.sum(df['target'].values)","078c829a":"# count 1s \nprint ('number of one in target are:', a)\nprint ('% of one in target are:', (a\/(len(df)))*100, '%')\n# count 0s \nprint ('number of zeros in target are:', len(df)-a)\nprint ('% of zeros in target are:', ((len(df)-a)\/len(df))*100, '%')\n\n","9e6e9162":"\n# for malignant image \nPath_train=\"\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/train\/\"\ntrain_dir=os.listdir(Path_train)\nimport cv2\nfor i in range(len(df)):\n    \n    if df['benign_malignant'].values[i] == 'malignant' :\n        \n        plt.figure(figsize = [10,19])\n        #print(df.iloc[i])\n        a = df['image_name'].values[i]\n\n        raw_image = cv2.imread(Path_train+a+'.jpg')\n        #print(raw_image)\n        plt.imshow(raw_image)\n        #plt.colorbar()\n        plt.title('Raw Image (malignant)')\n        print(f\"The dimensions of the image are {raw_image.shape[0]} pixels width and {raw_image.shape[1]} pixels height, one single color channel\")\n        print(f\"The maximum pixel value is {raw_image.max():.4f} and the minimum is {raw_image.min():.4f}\")\n        print(f\"The mean value of the pixels is {raw_image.mean():.4f} and the standard deviation is {raw_image.std():.4f}\")\n        break ","9bf53c6f":"# for malignant image \nPath_train=\"\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/train\/\"\ntrain_dir=os.listdir(Path_train)\nimport cv2\nfor i in range(len(df)):\n    \n    if df['benign_malignant'].values[i] == 'benign' :\n        \n        plt.figure(figsize = [10,19])\n        #print(df.iloc[i])\n        a = df['image_name'].values[i]\n\n        raw_image = cv2.imread(Path_train+a+'.jpg')\n        #print(raw_image)\n        plt.imshow(raw_image)\n        #plt.colorbar()\n        plt.title('Raw Image (benign)')\n        print(f\"The dimensions of the image are {raw_image.shape[0]} pixels width and {raw_image.shape[1]} pixels height, one single color channel\")\n        print(f\"The maximum pixel value is {raw_image.max():.4f} and the minimum is {raw_image.min():.4f}\")\n        print(f\"The mean value of the pixels is {raw_image.mean():.4f} and the standard deviation is {raw_image.std():.4f}\")\n        break ","79d30b2f":"# Directory with our training horse pictures\ntrain_dir = os.path.join('\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/train\/')\ntrain_names = os.listdir(train_dir)\nprint(train_names[:10])","5a6614ec":"\n# Parameters for our graph; we'll output images in a 4x4 configuration\nnrows = 2\nncols = 4\n\n# Index for iterating over images\npic_index = 0","c6c8e8b6":"# Set up matplotlib fig, and size it to fit 4x4 pics\nfig = plt.gcf()\nfig.set_size_inches(ncols * 4, nrows * 4)\n\npic_index += 16\nnext_pix = [os.path.join(train_dir, fname) \n                for fname in train_names[pic_index-8:pic_index]]\n\n\nfor i, img_path in enumerate(next_pix):\n  # Set up subplot; subplot indices start at 1\n  sp = plt.subplot(nrows, ncols, i + 1)\n  sp.axis('Off') # Don't show axes (or gridlines)\n\n  img = mpimg.imread(img_path)\n  plt.imshow(img)\n\nplt.show()\n","1d7d01bc":"\n'''class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get(tf.keras.metrics.AUC())>0.99):\n            print(\"\\nReached 99% accuracy so cancelling training!\")\n            self.model.stop_training = True\ncallbacks = myCallback()  '''","6e00bef5":"\nmodel = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n    # This is the first convolution\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    # The second convolution\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The third convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The fourth convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The fifth convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(),\n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'),\n    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])","19c3221e":"model.summary()","5510a4aa":"tf.keras.utils.plot_model(model,show_layer_names=True,show_shapes=True)","a9b677fd":"from tensorflow.keras.optimizers import RMSprop\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=RMSprop(lr=0.001),\n              metrics=[tf.keras.metrics.AUC()])","f3bb0f25":"# All images will be rescaled by 1.\/255\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n","5ca52845":"\nImage_path='\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/'\n# dtype string because its reads in string format\ntrain_csv=pd.read_csv('\/kaggle\/input\/siim-isic-melanoma-classification\/train.csv',dtype=str)\ntest_csv=pd.read_csv('\/kaggle\/input\/siim-isic-melanoma-classification\/test.csv',dtype=str)","7fc0a9c3":"train_augmenter=ImageDataGenerator(\n    rescale=1.\/255, \n    #rotation range and fill mode only\n    samplewise_center=True, \n    samplewise_std_normalization=True, \n    horizontal_flip = True, \n    vertical_flip = True, \n    height_shift_range= 0.05, \n    width_shift_range=0.1, \n    rotation_range=45, \n    shear_range = 0.1,\n    fill_mode = 'nearest',\n    zoom_range=0.10,\n    #preprocessing_function=function_name,\n    )\n\ntest_augmenter=ImageDataGenerator(\n    rescale=1.\/255\n    )","b60e5930":"def jpg_tag(image_name):\n    return image_name+'.jpg'\n\ntrain_csv['image_name']=train_csv['image_name'].apply(jpg_tag)\ntest_csv['image_name']=test_csv['image_name'].apply(jpg_tag)","d532cc28":"from keras.utils.data_utils import Sequence\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.tensorflow import balanced_batch_generator\n\nclass BalancedDataGenerator(Sequence):\n    \"\"\"ImageDataGenerator + RandomOversampling\"\"\"\n    def __init__(self, x, y, datagen, batch_size=32):\n        self.datagen = datagen\n        self.batch_size = batch_size\n        self._shape = x.shape        \n        datagen.fit(x)\n        self.gen, self.steps_per_epoch = balanced_batch_generator(x.reshape(x.shape[0], -1), y, sampler=RandomOverSampler(), batch_size=self.batch_size, keep_sparse=True)\n\n    def __len__(self):\n        return self._shape[0] \/\/ self.batch_size\n\n    def __getitem__(self, idx):\n        x_batch, y_batch = self.gen.__next__()\n        x_batch = x_batch.reshape(-1, *self._shape[1:])\n        return self.datagen.flow(x_batch, y_batch, batch_size=self.batch_size).next()","1a17b651":"batch_size=16\nIMG_size=224\ntrain_generator=train_augmenter.flow_from_dataframe(\ndataframe=train_csv,\ndirectory=Image_path+'train',\n#save_to_dir='augmented',\n#save_prefix='_aug'\n#save_format='jpg'\nx_col='image_name',\ny_col='target',\nbatch_size=batch_size,\nseed=42,\nshuffle=True,\nclass_mode='binary',\ntarget_size=(300, 300),\n)\n\n\n\ntest_generator=test_augmenter.flow_from_dataframe(\ndataframe=test_csv,\ndirectory=Image_path+'test',\nx_col='image_name',\nbatch_size=batch_size, #preffered 1\nshuffle=False,\nclass_mode=None,\ntarget_size=(300, 300)\n)","7bd27e6b":"history = model.fit(\n      train_generator,\n      steps_per_epoch=10,\n        \n      epochs=5,\n      verbose=1)","587d8d9f":"import numpy as np\nimport random\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\n\n# Let's define a new Model that will take an image as input, and will output\n# intermediate representations for all layers in the previous model after\n# the first.\nsuccessive_outputs = [layer.output for layer in model.layers[1:]]\n#visualization_model = Model(img_input, successive_outputs)\nvisualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n# Let's prepare a random input image from the training set.\nimg_files = [os.path.join(train_dir, f) for f in train_names]\nimg_path = random.choice(img_files)\n\nimg = load_img(img_path, target_size=(300, 300))  # this is a PIL imagea\nx = img_to_array(img)  # Numpy array with shape (150, 150, 3)\nx = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n\n# Rescale by 1\/255\nx \/= 255\n\n# Let's run our image through our network, thus obtaining all\n# intermediate representations for this image.\nsuccessive_feature_maps = visualization_model.predict(x)\n\n# These are the names of the layers, so can have them as part of our plot\nlayer_names = [layer.name for layer in model.layers[1:]]\n\n# Now let's display our representations\nfor layer_name, feature_map in zip(layer_names, successive_feature_maps):\n  if len(feature_map.shape) == 4:\n    # Just do this for the conv \/ maxpool layers, not the fully-connected layers\n    n_features = feature_map.shape[-1]  # number of features in feature map\n    # The feature map has shape (1, size, size, n_features)\n    size = feature_map.shape[1]\n    # We will tile our images in this matrix\n    display_grid = np.zeros((size, size * n_features))\n    for i in range(n_features):\n      # Postprocess the feature to make it visually palatable\n      x = feature_map[0, :, :, i]\n      x -= x.mean()\n      x \/= x.std()\n      x *= 64\n      x += 128\n      x = np.clip(x, 0, 255).astype('uint8')\n      # We'll tile each filter into this big horizontal grid\n      display_grid[:, i * size : (i + 1) * size] = x\n    # Display the grid\n    scale = 20. \/ n_features\n    plt.figure(figsize=(scale * n_features, scale))\n    plt.title(layer_name)\n    plt.grid(False)\n    plt.imshow(display_grid, aspect='auto', cmap='viridis')","f5f6d94e":"submission = pd.read_csv('\/kaggle\/input\/siim-isic-melanoma-classification\/sample_submission.csv')\nsubmission.head()","1061b327":"name = submission['image_name'].values \nname ","0f534e75":"Path_test=\"\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/test\/\"\ntest_dir=os.listdir(Path_test)\nad = Path_test+name[0]+'.jpg'","32e74c71":"img = mpimg.imread(ad)\nplt.imshow(img)","25d694fa":"array = []\nfor i in range(len(submission)):\n    from keras.preprocessing import image\n    ad = Path_test+name[i]+'.jpg'\n    img = image.load_img(ad, target_size=(300, 300))\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n\n    images = np.vstack([x])\n    classes = model.predict(images, batch_size=10)\n    '''print(classes[0])'''\n    array.append(classes[0])\nprint(array)","2ac35b08":"for k in range(len(array)):\n    if array==1:\n        print('yes')\nprint ('finish')","8b137804":"er = pd.DataFrame(array)","7946ffa2":"er.columns = ['target']\ner","223cc2ac":"submission = submission.drop(columns='target')\nsubmission ","0de21baf":"submission['target'] =  er\nsubmission.to_csv('submission.csv') \n","30109937":"# I have directly copied this Image Augmentation code from https:\/\/www.kaggle.com\/yash612\/simple-image-augmentation-and-pipelining","bf548dde":"# Let us predict the results ","de068584":"# now prepare the model ","a2df061d":"# Currently the AUC is very low so the next step is to select the correct los function, (In previoius version of this code  Accuracy was very high, becasue of imbalanced dataset)","ff64e784":"# Show one benign image  ","754e39a5":"# show one malignant image ","d2d84511":"# Load training dataset ","c0284ecf":"# balanced data generator ","f589ef99":"# Let us see some images ","fa27ebf6":"# Let us see the test image ","8e0394b7":"# EDA of training dataset","501796ad":"# The data set is highly imballenced So let us try the simple approaches","50723059":"# now impliment callback ","fb03b47c":"# layer visualization ","8ef0f9e2":"# Currently the AUC is very low so the next step is to select the correct los function "}}