{"cell_type":{"7f393f7d":"code","1124d333":"code","89bae583":"code","bae5ef83":"code","944c0faa":"code","c047bb7c":"code","cc5eea63":"code","44ca7c82":"code","ab102520":"markdown","dcbb196a":"markdown","585f0215":"markdown","2fc1097a":"markdown"},"source":{"7f393f7d":"import numpy as np\nimport pandas as pd \nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\ndirectory = '\/kaggle\/input\/skin-cancer\/dataset'","1124d333":"train_datagen= ImageDataGenerator(\n                rotation_range=20,\n                width_shift_range=0.4,\n                height_shift_range=0.4,\n                shear_range=0.2,\n                zoom_range=0.2,\n                fill_mode=\"nearest\",\n                horizontal_flip=True,\n                vertical_flip=True,\n                rescale=1.\/255,\n                preprocessing_function=None)\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n                    '\/kaggle\/input\/skin-cancer\/dataset\/train',\n                    target_size=(224, 224),\n                    color_mode='rgb',\n                    shuffle=True,\n                    batch_size=16)\n\nvalidation_generator = test_datagen.flow_from_directory(\n                    '\/kaggle\/input\/skin-cancer\/dataset\/valid',\n                    target_size=(224, 224),\n                    color_mode='rgb'\n                    batch_size=16)\n","89bae583":"from keras.applications import InceptionV3,vgg16,resnet50\nfrom keras.models import Model, Sequential\nfrom keras.layers import Dense, Dropout, Input, Concatenate\nfrom keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\n\ndef build_model():\n    model = Sequential()\n    model.add(InceptionV3(weights='imagenet', include_top=True))\n\n    for layer in model.layers:\n        layer.trainable = False\n\n    model.add(Dense(256,activation='relu'))\n    model.add(Dropout(0.4))\n    model.add(Dense(7, activation='softmax'))\n    return model","bae5ef83":"model = build_model()\nmodel.summary()","944c0faa":"from keras.optimizers import Adam,SGD,Nadam,RMSprop\nfrom keras.optimizers.schedules import ExponentialDecay\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n\n\nlr_schedule = ExponentialDecay(initial_learning_rate=1e-2,\n                                    decay_steps=1000,\n                                    decay_rate=0.6)\ndef schedule(epoch,lr):\n    if epoch <=2 :\n        return lr\n    elif epoch > 2 and epoch <=4 :\n        return lr\/2\n    elif epoch > 4 and epoch < 7 :\n        return lr\/3\n    else:\n        return lr\/4\n\noptimizer1 = Adam(learning_rate = 0.014)\noptimizer2 = SGD(learning_rate = lr_schedule)\noptimizer3 = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.4)\noptimizer4 = Nadam(learning_rate=0.002)\n\ncb1 = EarlyStopping(monitor='val_loss', patience = 10)\ncb2 = LearningRateScheduler(schedule,verbose=1)\n\nmodel_checkpoint_callback = ModelCheckpoint(\n                                    filepath='\/kaggle\/working\/model1.h5',\n                                    save_weights_only=True,\n                                    monitor='val_acc',\n                                    mode='max',\n                                    save_best_only=True)\n\n'''\n# LR SCHEDULING FOR TPUs\n\nLR_START = 0.00001\nLR_MAX = 0.00005 * strategy.num_replicas_in_sync\nLR_MIN = 0.00001\nLR_RAMPUP_EPOCHS = 5\nLR_SUSTAIN_EPOCHS = 0\nLR_EXP_DECAY = .8\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) \/ LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr\n    \nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n'''\n","c047bb7c":"model.compile(optimizer=optimizer2,\n              loss='categorical_crossentropy',\n              metrics = ['accuracy'])\n\nmodel.load_weights('\/kaggle\/working\/model1.h5')\n\nSTEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID=validation_generator.n\/\/validation_generator.batch_size\nmodel.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=validation_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=20, callbacks =[model_checkpoint_callback])","cc5eea63":"model.evaluate_generator(generator=validation_generator,\nsteps=STEP_SIZE_VALID)","44ca7c82":"model.save_weights('model1.h5')\n","ab102520":"# 1. Importing images and applying some basic augmentation\n\nUsing ImageDataGenerator class from keras.preprocessing.image - \nwhich allows us to get images directly from their folders and automatically label them according to subfolders.","dcbb196a":"Define Optimizers and Callbacks before Complile\/Fit","585f0215":"# 2. Making a model using Transfer Learning","2fc1097a":"Compile the model and Fit data generators."}}