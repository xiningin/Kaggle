{"cell_type":{"6077d582":"code","1149ea43":"code","dbf7edee":"code","402fdc53":"code","6d9df638":"code","716f81b2":"code","9f530643":"code","3e6c7995":"code","971ddfb2":"code","f62dd4ae":"code","6216f956":"code","1fd9870c":"code","e7927d2e":"code","2b9c8c08":"code","ce1e6fd0":"code","5c963df5":"code","eefe3970":"code","42ecb473":"code","be3a7749":"code","9c986819":"code","46cfa62c":"code","4a3eb647":"code","cc216f2c":"code","46a7f6f5":"code","9946fbbb":"code","9c2fa4a5":"markdown","8421a7ea":"markdown","8ffded91":"markdown","f2fb79d1":"markdown","b26b6727":"markdown","b598dceb":"markdown","d0980aa8":"markdown","22fa82e8":"markdown","e4bc0641":"markdown","6ef61f57":"markdown","d3d336b2":"markdown","134d3663":"markdown","08113afb":"markdown","48b5200f":"markdown","35f1966d":"markdown","32f527cd":"markdown","74456e30":"markdown","5299d6ce":"markdown","f5b114f3":"markdown","0fdd3c73":"markdown","c4827d07":"markdown","4700eef2":"markdown","41e93080":"markdown","46e2fb51":"markdown"},"source":{"6077d582":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1149ea43":"# Import the libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import r2_score,mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nimport warnings\nwarnings.filterwarnings('ignore')","dbf7edee":"# Import the dataset \n# Medical Cost Personal Dataset\ndataset = pd.read_csv('\/kaggle\/input\/insurance\/insurance.csv')","402fdc53":"dataset.head()","6d9df638":"dataset.isnull().sum()","716f81b2":"# Encode categorical data\n# Create instance\nencode = LabelEncoder()\n\n# Gender of the benificiary\nencode.fit(dataset.sex.drop_duplicates()) \ndataset.sex = encode.transform(dataset.sex)\n\n# Is the benificiary smoker or non-smoker\nencode.fit(dataset.smoker.drop_duplicates()) \ndataset.smoker = encode.transform(dataset.smoker)\n\n# Residence of benificiary\nencode.fit(dataset.region.drop_duplicates()) \ndataset.region = encode.transform(dataset.region)","9f530643":"dataset.head()","3e6c7995":"dataset.corr()['charges'].sort_values()\nf, ax = plt.subplots(figsize=(10, 8))\ncorr = dataset.corr()\nsns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap='Greens',\n            square=True, ax=ax)","971ddfb2":"plt.figure(figsize=(12,7))\nplt.title(\"Distribution\")\nsns.distplot(dataset,color='r')","f62dd4ae":"sns.pairplot(dataset)","6216f956":"sns.catplot(x=\"smoker\", kind=\"count\",hue = 'sex', palette=\"pastel\", data=dataset)","1fd9870c":"sns.catplot(x=\"smoker\", kind=\"count\",hue = 'children', palette=\"rainbow\", data=dataset)","e7927d2e":"plt.figure(figsize=(12,7))\nplt.title(\"BMI\")\nsns.distplot(dataset[\"bmi\"], color = 'c')","2b9c8c08":"plt.figure(figsize=(12,7))\nplt.title(\"Children\")\nsns.distplot(dataset[\"children\"], color = 'r')","ce1e6fd0":"plt.figure(figsize=(12,7))\nplt.title(\"Age\")\nsns.distplot(dataset[\"age\"], color = 'g')","5c963df5":"sns.catplot(x=\"children\", kind=\"count\", palette=\"rainbow\", data=dataset)","eefe3970":"# Get feature matrix and label vector\nX = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values","42ecb473":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","be3a7749":"# Train the Multiple Linear Regression model on the Training set\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)\n\n# Predict the Test set results\ny_pred = regressor.predict(X_test)","9c986819":"print(regressor.score(X_test,y_test))","46cfa62c":"from sklearn.tree import DecisionTreeRegressor\ndtr = DecisionTreeRegressor(random_state = 0)\ndtr.fit(X_train, y_train)\ndtr_y_pred = dtr.predict(X_test)","4a3eb647":"print('MSE test data: %.3f' % (mean_squared_error(y_test,dtr_y_pred)))\nprint('R2 test data: %.3f' % (r2_score(y_test,dtr_y_pred)))","cc216f2c":"from sklearn.ensemble import RandomForestRegressor\nrfr = RandomForestRegressor(n_estimators = 10, random_state = 0)\nrfr.fit(X_train, y_train)\nrfr_y_pred = rfr.predict(X_test)","46a7f6f5":"print('MSE test data: %.3f' % (mean_squared_error(y_test,rfr_y_pred)))\nprint('R2 test data: %.3f' % (r2_score(y_test,rfr_y_pred)))","9946fbbb":"plt.figure(figsize=(12,7))\nplt.title(\"FINAL PREDICTION\")\nplt.scatter(rfr.predict(X_train),rfr.predict(X_train)- y_train,c = 'red', marker = 'o', s = 30, alpha = 0.6,label = 'Train data')\nplt.scatter(rfr_y_pred,rfr_y_pred - y_test,c = 'cyan', marker = 'o', s = 30, alpha = 0.8,label = 'Test data')\nplt.xlabel('Predicted values')\nplt.ylabel('Tailings')\nplt.legend()\nplt.hlines(y = 0, xmin = 0, xmax = 60000, lw = 2, color = 'black')\nplt.show()","9c2fa4a5":"Yes!!","8421a7ea":"**Visualization**","8ffded91":"**Thank you!**","f2fb79d1":"**Time to create feature matrix and label vector:)**","b26b6727":"**We have three features which have string values.Ofcourse we cannot feed them directly to our model.**\nTo take care of these categorical features we will encode them:)","b598dceb":"**That is quite impressive.We do not have any missing data in the dataset.So we don't need to worry about that.**","d0980aa8":"We already noticed there is some strong relation of smokers and people who have higher charges.Let us do some more research about this.","22fa82e8":"**Linear Regression Model**","e4bc0641":"**If you like this then please consider upvoting!**","6ef61f57":"**Now let's visualize correlation between these features and label.**","d3d336b2":"Hope this one will give us better result:)","134d3663":"**Let us quickly check what features and label do we have**","08113afb":"**Decision Tree Model**","48b5200f":"**We need to check if we have NaN in the dataset.If there is any missing data then we need to take care of theat.**","35f1966d":"**Let us split our dataset into training set and test set.**","32f527cd":"The size of our training set is 80% of the whole set.","74456e30":"**Let us check how our dataset looks like now:)**","5299d6ce":"**We have few information about each beneficiary like what is his\/her age,if that person has children or not,if he\/she is a smoker etc.The very last column is our label vector.**","f5b114f3":"Well not that bad!","0fdd3c73":"**Let us have some more fun with visualization part:)**","c4827d07":"**Strong correlation between smoking and higher charges as expected.**","4700eef2":"**Random Forest Model**","41e93080":"Not that impressive:(","46e2fb51":"**Distribution**"}}