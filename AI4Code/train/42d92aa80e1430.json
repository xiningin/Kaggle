{"cell_type":{"e266d34b":"code","13799c91":"code","228e44ff":"code","65bb758d":"code","b0c21a02":"code","0d1c66d5":"code","637e671c":"code","960f22c5":"code","ab4746ec":"code","59a55aef":"code","454925ae":"code","02adf2e8":"code","a06fefcf":"code","b487aae8":"code","b32239bc":"code","c0f9caad":"code","c375a7fc":"code","a11366d4":"markdown","8810af3a":"markdown","bd0f3cd8":"markdown","77469e9a":"markdown","4726b6de":"markdown","fbeb45be":"markdown","254f1997":"markdown","8650f408":"markdown","52dde256":"markdown","3085933b":"markdown"},"source":{"e266d34b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input\/messy-vs-clean-room\/images\/train\/messy\/'):\n #   for filename in filenames:\n  #      print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","13799c91":"# Load everything that may be needed\nimport numpy as np\nimport copy\nimport matplotlib.pyplot as plt\nimport h5py\nimport scipy\nimport imageio\nfrom PIL import Image\nfrom scipy import ndimage\nfrom scipy import misc\n\n%matplotlib inline\n%load_ext autoreload\n%autoreload 2","228e44ff":"# Function to load dataset\ndef load_dataset():\n    train_set_x_orig_list,train_set_y_list, test_set_x_orig_list, test_set_y_list=[],[],[],[]\n    train_clean_path=\"..\/input\/clean-messy-rooms\/Clean_Rooms\/train\/\"\n    train_messy_path=\"\/..\/input\/clean-messy-rooms\/Messy_Rooms\/train\/\"\n    test_clean_path=\"..\/input\/clean-messy-rooms\/Messy_Rooms\/train\/\"\n    test_messy_path=\"..\/input\/clean-messy-rooms\/Messy_Rooms\/test\/\"\n    for dirname, _, filenames in os.walk(train_messy_path):\n        for filename in filenames:\n            train_set_x_orig_list.append(imageio.imread(os.path.join(dirname, filename), as_gray=False, pilmode=\"RGB\") )\n            train_set_y_list.append(0)\n   \n    for dirname, _, filenames in os.walk(train_clean_path):\n        for filename in filenames:\n            train_set_x_orig_list.append(imageio.imread(os.path.join(dirname, filename), as_gray=False, pilmode=\"RGB\") )\n            train_set_y_list.append(1)\n            \n    \n    for dirname, _, filenames in os.walk(test_messy_path):\n        for filename in filenames:\n            test_set_x_orig_list.append(imageio.imread(os.path.join(dirname, filename), as_gray=False, pilmode=\"RGB\") )\n            test_set_y_list.append(0)\n    for dirname, _, filenames in os.walk(test_clean_path):\n        for filename in filenames:\n            test_set_x_orig_list.append(imageio.imread(os.path.join(dirname, filename), as_gray=False, pilmode=\"RGB\") )\n            test_set_y_list.append(1)\n    \n    train_set_x_orig=np.array(train_set_x_orig_list)\n    train_set_y=np.array(train_set_y_list)\n    train_set_y=train_set_y.reshape((1,train_set_y.shape[0]))\n    \n    test_set_x_orig=np.array(test_set_x_orig_list)\n    test_set_y=np.array(test_set_y_list)\n    test_set_y=test_set_y.reshape((1,test_set_y.shape[0]))\n    \n    classes_list=[b'messy',b'clean']\n    classes=np.array(classes_list)\n    return train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes","65bb758d":"#calling function to load the dataset\ntrain_set_x_orig, train_set_y, test_set_x_orig, test_set_y,classes=load_dataset()","b0c21a02":"#Printing a sample from the set\nindex = 0\nplt.imshow(train_set_x_orig[index])\nprint (\"y = \" + str(train_set_y[:, index]) + \", it's a '\" + classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") +  \"' picture.\")","0d1c66d5":"m_train = train_set_x_orig.shape[0]\nm_test = test_set_x_orig.shape[0]\nnum_px = test_set_x_orig[0].shape[0]\n\nprint (\"Number of training examples: m_train = \" + str(m_train))\nprint (\"Number of testing examples: m_test = \" + str(m_test))\nprint (\"Height\/Width of each image: num_px = \" + str(num_px))\nprint (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\nprint (\"train_set_x shape: \" + str(train_set_x_orig.shape))\nprint (\"train_set_y shape: \" + str(train_set_y.shape))\nprint (\"test_set_x shape: \" + str(test_set_x_orig.shape))\nprint (\"test_set_y shape: \" + str(test_set_y.shape))","637e671c":"\ntrain_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0],num_px*num_px*3).T\ntest_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0],num_px*num_px*3).T\n\nprint (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\nprint (\"train_set_y shape: \" + str(train_set_y.shape))\nprint (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\nprint (\"test_set_y shape: \" + str(test_set_y.shape))","960f22c5":"train_set_x = train_set_x_flatten \/ 255.\ntest_set_x = test_set_x_flatten \/ 255.","ab4746ec":"def sigmoid(z):\n    s = 1\/(1+np.exp(-z))\n    return s","59a55aef":"\ndef initialize_with_zeros(dim):\n    w = np.zeros((dim,1))\n    b = 0.\n    return w, b","454925ae":"def propagate(w, b, X, Y):\n    m = X.shape[1]\n    \n    A = sigmoid(np.dot(w.T,X)+b)\n    A = A.astype(np.float64)\n    cost = -1\/m*np.sum(np.nan_to_num(Y*np.log(A)+(1-Y)*np.log(1-A)),axis=1)\n    \n    dw = 1\/m*np.dot(X,(A-Y).T)\n    db = 1\/m*np.sum(A-Y)\n    \n    cost = np.squeeze(np.array(cost))\n\n    grads = {\"dw\": dw,\n             \"db\": db}\n    \n    return grads, cost","02adf2e8":"def optimize(w, b, X, Y, num_iterations=100, learning_rate=0.009, print_cost=False):\n    \n    w = copy.deepcopy(w)\n    b = copy.deepcopy(b)\n    \n    costs = []\n    \n    for i in range(num_iterations):\n        \n        grads, cost = propagate(w,b,X,Y)\n        \n        dw = grads[\"dw\"]\n        db = grads[\"db\"]\n        \n        w = w-learning_rate*dw\n        b = b-learning_rate*db\n        \n        if i % 100 == 0:\n            costs.append(cost)\n            if print_cost:\n                print (\"Cost after iteration %i: %f\" %(i, cost))\n    \n    params = {\"w\": w,\n              \"b\": b}\n    \n    grads = {\"dw\": dw,\n             \"db\": db}\n    \n    return params, grads, costs","a06fefcf":"def predict(w, b, X):\n    m = X.shape[1]\n    Y_prediction = np.zeros((1, m))\n    w = w.reshape(X.shape[0], 1)\n\n    A = sigmoid(np.dot(w.T,X)+b)\n        \n    for i in range(A.shape[1]):\n        if A[0,i]<=0.5:\n            Y_prediction[0,i]=0\n        else:\n            Y_prediction[0,i]=1\n    return Y_prediction","b487aae8":"def model(X_train, Y_train, X_test, Y_test, num_iterations=2000, learning_rate=0.5, print_cost=False):\n   \n    w, b = initialize_with_zeros(X_train.shape[0])\n    parameters, grads, costs = optimize(w,b,X_train,Y_train,num_iterations,learning_rate,print_cost)\n    w = parameters[\"w\"]\n    b = parameters[\"b\"]\n    Y_prediction_test = predict(w,b,X_test)\n    Y_prediction_train = predict(w,b,X_train)\n    \n    if print_cost:\n        print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n        print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n\n    \n    d = {\"costs\": costs,\n         \"Y_prediction_test\": Y_prediction_test, \n         \"Y_prediction_train\" : Y_prediction_train, \n         \"w\" : w, \n         \"b\" : b,\n         \"learning_rate\" : learning_rate,\n         \"num_iterations\": num_iterations}\n    \n    return d","b32239bc":"logistic_regression_model = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations=1500, learning_rate=0.01, print_cost=True)","c0f9caad":"costs = np.squeeze(logistic_regression_model['costs'])\nplt.plot(costs)\nplt.ylabel('cost')\nplt.xlabel('iterations (per hundreds)')\nplt.title(\"Learning rate =\" + str(logistic_regression_model[\"learning_rate\"]))\nplt.show()","c375a7fc":"# change this to the name of your image file\nmy_image = \"wending_machine.jpeg\"   \n\n# We preprocess the image to fit your algorithm.\nfname = \"..\/input\/clean-messy-rooms\/Clean_Rooms\/981.jpg\"\nimage = np.array(Image.open(fname).resize((num_px, num_px)))\nplt.imshow(image)\nimage = image \/ 255.\nimage = image.reshape((1, num_px * num_px * 3)).T\nmy_predicted_image = predict(logistic_regression_model[\"w\"], logistic_regression_model[\"b\"], image)\n\nprint(\"y = \" + str(np.squeeze(my_predicted_image)) + \", your algorithm predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") +  \"\\\" picture.\")","a11366d4":"# Function to load dataset\ndef load_dataset():\n    train_set_x_orig_list,train_set_y_list, test_set_x_orig_list, test_set_y_list=[],[],[],[]\n    train_clean_path=\"\/kaggle\/input\/messy-vs-clean-room\/images\/train\/clean\/\"\n    train_messy_path=\"\/kaggle\/input\/messy-vs-clean-room\/images\/train\/messy\/\"\n    test_clean_path=\"\/kaggle\/input\/messy-vs-clean-room\/images\/val\/clean\/\"\n    test_messy_path=\"\/kaggle\/input\/messy-vs-clean-room\/images\/val\/messy\/\"\n    for dirname, _, filenames in os.walk(train_messy_path):\n        for filename in filenames:\n            train_set_x_orig_list.append(imageio.imread(os.path.join(dirname, filename), as_gray=False, pilmode=\"RGB\") )\n            train_set_y_list.append(0)\n    for dirname, _, filenames in os.walk(\"..\/input\/messy-neat-rooms\/messy_room\"):\n        for filename in filenames:\n            train_set_x_orig_list.append(imageio.imread(os.path.join(dirname, filename), as_gray=False, pilmode=\"RGB\") )\n            train_set_y_list.append(0)\n            \n    for dirname, _, filenames in os.walk(train_clean_path):\n        for filename in filenames:\n            train_set_x_orig_list.append(imageio.imread(os.path.join(dirname, filename), as_gray=False, pilmode=\"RGB\") )\n            train_set_y_list.append(1)\n            \n    for dirname, _, filenames in os.walk(\"..\/input\/messy-neat-rooms\/clean_room\"):\n        for filename in filenames:\n            train_set_x_orig_list.append(imageio.imread(os.path.join(dirname, filename), as_gray=False, pilmode=\"RGB\") )\n            train_set_y_list.append(1)\n            \n    for dirname, _, filenames in os.walk(test_messy_path):\n        for filename in filenames:\n            test_set_x_orig_list.append(imageio.imread(os.path.join(dirname, filename), as_gray=False, pilmode=\"RGB\") )\n            test_set_y_list.append(0)\n    for dirname, _, filenames in os.walk(test_clean_path):\n        for filename in filenames:\n            test_set_x_orig_list.append(imageio.imread(os.path.join(dirname, filename), as_gray=False, pilmode=\"RGB\") )\n            test_set_y_list.append(1)\n    \n    train_set_x_orig=np.array(train_set_x_orig_list)\n    train_set_y=np.array(train_set_y_list)\n    train_set_y=train_set_y.reshape((1,train_set_y.shape[0]))\n    \n    test_set_x_orig=np.array(test_set_x_orig_list)\n    test_set_y=np.array(test_set_y_list)\n    test_set_y=test_set_y.reshape((1,test_set_y.shape[0]))\n    \n    classes_list=[b'messy',b'clean']\n    classes=np.array(classes_list)\n    return train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes","8810af3a":"Normalise data\nThere are different ways\nA basic way is to divide by 255. for images","bd0f3cd8":"Logistic regression for messy and clean room","77469e9a":"Flatten the data into vectors of training examples","4726b6de":"1) Load Data","fbeb45be":"Plot the costs during the optimization process","254f1997":"Run the logistic regression model","8650f408":"Checking a sample image","52dde256":"**A bunch of functions**\n1) Sigmoid\n\n2) Initialise parameters w and b: Initialized parameters with 0\n\n3) Propogate(Back propagation): calculates dw\n\n4) Optimize: runs gradient descent to optimize the parameters\n\n5) Predict: Using parameters classifies an image\n\n6) Model: Puts all of the above functions together","3085933b":"Extract Dimensions of the image"}}