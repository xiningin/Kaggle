{"cell_type":{"b4e633cc":"code","17a4e256":"code","1702e90b":"code","f6cde3c8":"code","edecaa55":"code","62111c82":"code","ce14c6dd":"code","4ae9b762":"code","dad21234":"code","60f6ae7b":"code","02351476":"code","60b4e5c6":"code","f407cc38":"code","0f8ff3b2":"code","e4418cd2":"code","83dbfb28":"code","c4268af6":"code","8a6483aa":"code","0ff515d4":"code","8fbdca1e":"code","9f0f5fdf":"code","959728c5":"code","b1f250ee":"code","a944f7e1":"code","b315a25b":"code","38283eeb":"code","aac658d2":"code","6ab79cc7":"code","58872e2f":"code","361eb390":"code","10436500":"code","b5701647":"code","3e48584c":"code","427d475f":"code","edd6ff88":"code","1642bc24":"code","6f3f5d6c":"code","8a13db3e":"code","e93f3df5":"code","213125f5":"code","54a0f1c9":"code","b86d66cd":"code","ba89923e":"code","428aa419":"code","1a355c26":"code","a8875755":"markdown","867bf6e7":"markdown","f3331be1":"markdown","f1bd8cd9":"markdown","9bb5b874":"markdown","02598bdd":"markdown","0529dd68":"markdown","2b36308d":"markdown","3e955bf0":"markdown","cb493250":"markdown","320b1a21":"markdown","15c8dddf":"markdown","d26ba424":"markdown","335cd487":"markdown","b1dc5dd6":"markdown","9805d570":"markdown","2431f6cb":"markdown","33264b00":"markdown","d2f0b993":"markdown","40e1e92b":"markdown","547fe874":"markdown"},"source":{"b4e633cc":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","17a4e256":"# check tha the last version of Jovian is installed\n!pip install jovian --upgrade --quiet\n","1702e90b":"\n# Imports\n\nimport torch\nimport jovian\nimport torchvision\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torchvision.datasets.utils import download_url\nfrom torch.utils.data import DataLoader, TensorDataset, random_split","f6cde3c8":"# Other constants\nDATASET_URL = \"..\/input\/calcofi\/bottle.csv\"\nDATA_FILENAME = \"bottle.csv\"","edecaa55":"dataframe = pd.read_csv(DATASET_URL)\n# I take the first 700 data points to examine more in detail\ndf = dataframe[:][:700]\n#df.iloc[0:3,8:25]\ndf.head()\n\n# I get a warning because of the different datatypes on import. I will clean up my dataset in the next steps","62111c82":"df['Salnty'].head()","ce14c6dd":"# I first take the rows where temperature and the salinity is not NaN:\n\ndf = df[df['Salnty'].notna()]\nprint(\"rows are now \", len(df))\ndf.head()\n","4ae9b762":"\ndf = df[df['T_degC'].notna()]\nprint(\"rows are now \", len(df))\ndf.head()\n","dad21234":"# will drop any columns (axis= 1) with a NaN value. I can do that, since we already made sure that the temperature and salinity columns have no NaNs values.\ndf = df.dropna(axis = 1, how = 'any') \ndf.head()","60f6ae7b":"# Also, I want to have only the columns with numerical data. I am not interested in Strings and ID's for this dataset.\ndf = df._get_numeric_data()\n\ndf.head()\n# The three variables that interest me the most are 'Depthm, T_degC, Salnty', for water depth of the sample, the salinity and the temperature. \n# the temperature is my output\n","02351476":"# I define my output column\noutput_cols = ['T_degC']\n\n# The inputs will be all my columns except the temperature column:\ninput_cols = df.columns[df.columns!='T_degC']\n# so finally I have my pandas inputs and outputs\ninput_cols,output_cols\n","60b4e5c6":"# these are my input columns\nlen(input_cols)","f407cc38":"df[['T_degC']].head()","0f8ff3b2":"# I make a scatter plot to see any visual relationship between the data \nsns.lmplot(x=\"Salnty\", y=\"T_degC\", data=df,\n           order=2, ci=None);","e4418cd2":"sns.lmplot(x=\"Depthm\", y=\"T_degC\", data=df,\n           order=2, ci=None);","83dbfb28":"inputs_array = df[input_cols].to_numpy()\ntargets_array = df[output_cols].to_numpy()\ninputs_array, targets_array","c4268af6":"dtype = torch.float32\ninputs = torch.from_numpy(inputs_array).type(dtype)\ntargets = torch.from_numpy(targets_array).type(dtype)\ninputs.shape, targets.shape","8a6483aa":"inputs.dtype, targets.dtype","0ff515d4":"jovian.commit(project='jovian-Assignment-2', environment=None)\n","8fbdca1e":"dataset = TensorDataset(inputs, targets)","9f0f5fdf":"val_percent = 0.1 # between 0.1 and 0.2\nnum_rows = len(df)\nnum_cols = len(df.columns)\nval_size = int(num_rows * val_percent)\n\ntrain_size = num_rows - val_size\n\n\ntrain_ds, val_ds = random_split(df,(train_size, val_size)) # Use the random_split function to split dataset into 2 parts of the desired length","959728c5":"batch_size = 32","b1f250ee":"train_loader = DataLoader(train_ds, batch_size, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size)","a944f7e1":"train_loader","b315a25b":"for xb, yb in train_loader:\n    print(\"inputs:\", xb)\n    print(\"targets:\", yb)\n    break","38283eeb":"jovian.commit(project='jovian-Assignment-2', environment=None) ","aac658d2":"input_size = len(input_cols)\nprint(input_size)\noutput_size = len(output_cols)\nprint(output_size)","6ab79cc7":"class TempModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(input_size, output_size)                  # fill this (hint: use input_size & output_size defined above)\n        \n    def forward(self, xb):\n        out = self.linear(xb)                          # fill this\n        return out\n    \n    def training_step(self, batch):\n        inputs, targets = batch \n        # Generate predictions\n        out = self(inputs)          \n        # Calcuate loss\n        loss = F.l1_loss(out,targets)                         # fill this\n        return loss\n    \n    def validation_step(self, batch):\n        inputs, targets = batch\n        # Generate predictions\n        out = self(inputs)\n        # Calculate loss\n        loss = F.l1_loss(out,targets)                     # fill this    \n        return {'val_loss': loss.detach()}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        return {'val_loss': epoch_loss.item()}\n    \n    def epoch_end(self, epoch, result, num_epochs):\n        # Print result every 20th epoch\n        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))","58872e2f":"model = TempModel()","361eb390":"list(model.parameters())","10436500":"model.linear.weight.dtype,model.linear.bias.dtype","b5701647":"jovian.commit(project='jovian-Assignment-2', environment=None) ","3e48584c":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result, epochs)\n        history.append(result)\n    return history","427d475f":"result = evaluate (model,val_loader)\nprint(result)","edd6ff88":"epochs = 100\nlr = 1e-6\nhistory1 = fit(epochs, lr, model, train_loader, val_loader)","1642bc24":"epochs = 100\nlr = 1e-6\nhistory2 = fit(epochs, lr, model, train_loader, val_loader)","6f3f5d6c":"epochs = 500\nlr = 1e-6\nhistory3 = fit(epochs, lr, model, train_loader, val_loader)","8a13db3e":"epochs = 500\nlr = 1e-8\nhistory4 = fit(epochs, lr, model, train_loader, val_loader)","e93f3df5":"val_loss = 1.0058\njovian.log_metrics(val_loss=val_loss)","213125f5":"loss = []\nfor value in history1+history2+history3+history4:\n    loss.append(value['val_loss'])\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.title('loss vs. No. of epochs');\nplt.plot(loss)","54a0f1c9":"def predict_single(input, target, model):\n    inputs = input.unsqueeze(0)\n    predictions = model(inputs)                # fill this\n    prediction = predictions[0].detach()\n    print(\"Input:\", input)\n    print(\"Target:\", target)\n    print(\"Prediction:\", prediction)","b86d66cd":"input, target = val_ds[0]\npredict_single(input, target, model)","ba89923e":"input, target = val_ds[10]\npredict_single(input, target, model)","428aa419":"input, target = val_ds[23]\npredict_single(input, target, model)","1a355c26":"jovian.commit(project='jovian-Assignment-2', environment=None) \njovian.commit(project='jovian-Assignment-2', environment=None) ","a8875755":"# Assignment 2\n# CalCOFI: predict the water temperature based on salinity\n\nCalCOFI: Over 60 years of oceanographic data: Is there a relationship between water salinity & water temperature? Can you predict the water temperature based on salinity?\n\nI took the data from the Kaggle website: [https:\/\/www.kaggle.com\/sohier\/calcofi\/kernels](https:\/\/www.kaggle.com\/sohier\/calcofi\/kernels) and ran the notebook on Kaggle with the CalCOFI data files provided.\n\n","867bf6e7":"## Download and explore my dataset","f3331be1":"I can see that I have some columns which are not numeric which are ID's and some which have many missing values in it shown as 'NaN' in the dataset","f1bd8cd9":"Pick a number between 0.1 and 0.2 to determine the fraction of data that will be used for creating the validation set. Then use random_split to create training & validation datasets.\n\n","9bb5b874":"Let's check out the weights and biases of the model using model.parameters.","02598bdd":"Let's save our work by committing to Jovian.","0529dd68":"## Make predictions using the trained model","2b36308d":"The data will first be loaded as a Pandas dataframe.","3e955bf0":"## Preparing the workspace","cb493250":"## Inspect relationships between the data \n\nI am interested in the relationship of the data I extracted from the dataset. The inputs are the saltiness of the water and the depth. I want to create a model able to predict the temperature.","320b1a21":"Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a TensorDataset.","15c8dddf":"What is the final validation loss of your model?","d26ba424":"Next I remove the columns containing NaN values. I think for this dataset it will not impact the results. ","335cd487":"We are now ready to train the model.","b1dc5dd6":"I had a few rows with NaNs in the temperature and salinity columns which I now have taken out, I get now 675 rows","9805d570":"## Create a Linear Regression Model","2431f6cb":"Let us create a model using the TempModel class. ","33264b00":"I convert the numpy arrays inputs_array and targets_array into PyTorch tensors. I make sure that the data type is torch.float32.","d2f0b993":"Let's look at a batch of data to verify everything is working fine so far.","40e1e92b":"## Train the model to fit the data","547fe874":"Pick a batch size for the data loader."}}