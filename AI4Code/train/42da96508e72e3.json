{"cell_type":{"de9ccf3d":"code","5b6875b3":"code","2baff20a":"code","bae27e64":"code","2c8d83d7":"code","e1579972":"code","801c6177":"code","a9e43c6f":"code","82313a4f":"code","721c8117":"code","eb460d10":"code","570dbc8c":"code","f842cfda":"code","b561928e":"code","2e23c9df":"code","8c9c8214":"code","6b19f9e1":"code","ca7c03a5":"code","6fba71e0":"code","1c554d07":"code","b35a80b3":"code","eab1f72d":"code","5af35142":"code","95faa81e":"code","343446ed":"code","a6c1243e":"code","8eda68c9":"code","f43147de":"code","caea9f88":"code","f6465060":"code","a0db0b5f":"code","5a4ca681":"code","f6e856db":"code","e04d9a3c":"code","a3a285ac":"code","ec14c735":"code","9268ab4b":"code","6c500619":"code","5ace1c58":"code","55800f30":"code","9203849c":"code","55f89712":"code","934384a5":"code","27cdb2b9":"code","cdf6f561":"code","e94742ff":"code","5aa0cdca":"code","9aeedeff":"code","970e79bc":"code","c67d89a4":"code","1ba3dd8a":"markdown","ab6be582":"markdown","902950d6":"markdown","35e5a5ba":"markdown","0d1890f1":"markdown","f3da4a78":"markdown","42e94d04":"markdown","a0e9303c":"markdown","3b7f2947":"markdown","36d25bf9":"markdown","3a3126c2":"markdown","2a6d3aec":"markdown","d32177e6":"markdown","6a15bc1e":"markdown","3c2b9f01":"markdown","13083f5b":"markdown","3dd33a91":"markdown","12d29487":"markdown","0b6f88d6":"markdown","ade72b37":"markdown","cf7d9719":"markdown","7c0adadd":"markdown","4b86fb2f":"markdown","ea241f19":"markdown","e57a3ed4":"markdown","6969fb54":"markdown","9bf9cd56":"markdown"},"source":{"de9ccf3d":"import pandas as pd; import numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport plotly\nfrom plotly.subplots import make_subplots\nimport os\nfrom catboost import CatBoostClassifier,CatBoostRegressor\nfrom sklearn.feature_selection import SelectKBest,f_regression\nfrom xgboost import plot_importance,XGBClassifier,XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import preprocessing\nimport seaborn as sns\nimport shap\nfrom scipy import stats\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom sklearn.base import BaseEstimator,TransformerMixin\n\n%matplotlib inline\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Helper Functions located below","5b6875b3":"''' Various Helper Functions '''\n\n'''Plot Correlation Matrix'''\ndef corrMat(df,id=False,figsize=(10,10)):\n    \n    corr_mat = df.corr().round(2)\n    f, ax = plt.subplots(figsize=figsize)\n    mask = np.triu(np.ones_like(corr_mat, dtype=np.bool))\n    mask = mask[1:,:-1]\n    corr = corr_mat.iloc[1:,:-1].copy()\n    sns.heatmap(corr,mask=mask,vmin=-0.3,vmax=0.3,center=0, \n                cmap='Blues',square=False,lw=2,annot=True,cbar=False)\n\n'''Plot Correlation to Target Variable only'''\ndef corrMat2(df,target='demand',figsize=(9,0.5),ret_id=False):\n    \n    corr_mat = df.corr().round(2);shape = corr_mat.shape[0]\n    corr_mat = corr_mat.transpose()\n    corr = corr_mat.loc[:, df.columns == target].transpose().copy()\n    \n    if(ret_id is False):\n        f, ax = plt.subplots(figsize=figsize)\n        sns.heatmap(corr,vmin=-0.3,vmax=0.3,center=0, \n                     cmap=cmap,square=False,lw=2,annot=True,cbar=False)\n        plt.title(f'Feature Correlation to {target}')\n    \n    if(ret_id):\n        return corr\n    \n'''Correlation plot w\/ Plotly'''\ndef plotlyoff_corr(corr,size=None):\n    \n    xcols = corr.columns.tolist();ycols = xcols\n    if(size is None):\n        width = 700; height = 500\n    else:\n        width = size[0]; height = size[1]\n    \n    layout = dict(\n        width = width,height = height,\n        yaxis= dict(tickangle=-30,side = 'left'),\n        xaxis= dict(tickangle=-30,side = 'top'))\n    fig = ff.create_annotated_heatmap(\n        z=corr.values,x= xcols,y= ycols,\n        colorscale='viridis',showscale=False)\n    fig['layout'].update(layout)\n    fig.update_layout(margin={\"r\":0,\"t\":60,\"l\":0,\"b\":0})\n    \n    return py.iplot(fig)\n\n''' Draw a Bivariate Seaborn Pairgrid \/w KDE density w\/ '''\ndef snsPairGrid(df):\n\n    ''' Plots a Seaborn Pairgrid w\/ KDE & scatter plot of df features'''\n    g = sns.PairGrid(df,diag_sharey=False)\n    g.fig.set_size_inches(14,13)\n    g.map_diag(sns.kdeplot, lw=2) # draw kde approximation on the diagonal\n    g.map_lower(sns.scatterplot,s=15,edgecolor=\"k\",linewidth=1,alpha=0.4) # scattered plot on lower half\n    g.map_lower(sns.kdeplot,cmap='plasma',n_levels=10) # kde approximation on lower half\n    plt.tight_layout()\n\n'''Basic Transformer'''\nclass transformer(BaseEstimator,TransformerMixin):\n    \n    def __init__(self,drop_nan=False,select_dtype=False,show_nan=False,title='Title',show_counts=False,figsize=None):\n        self.drop_nan = drop_nan\n        self.select_dtype = select_dtype\n        self.show_nan = show_nan\n        self.title = title\n        self.show_counts = show_counts\n        self.figsize = figsize\n        \n    # Apply Fit\n    def fit(self,X,y=None):\n        return self\n        \n    # Apply Some Transformation to the Feature Matrix\n    def transform(self,X):\n        \n        # show NaN % in DataFrame\n        if(self.show_nan):\n            \n            fig, ax = plt.subplots(figsize = self.figsize)\n            nan_val = (X.isnull().sum()\/len(X)*100).sort_values(ascending = False)\n            cmap = sns.color_palette(\"plasma\")\n            for i in ['top', 'right', 'bottom', 'left']:\n                ax.spines[i].set_color('black')\n            ax.spines['top'].set_visible(True);ax.spines['right'].set_visible(False)\n            ax.spines['bottom'].set_visible(False);ax.spines['left'].set_visible(False)\n            sns.barplot(x=nan_val,y=nan_val.index, edgecolor='k',palette = 'rainbow')\n            plt.title(self.title);ax.grid(ls='--',alpha = 0.9);plt.show()\n            return\n        \n        ''' Plot df.value_counts '''\n        if(self.show_counts):\n        \n            tdf = X.value_counts()\n            cmap = sns.color_palette(\"plasma\")\n            fig, ax = plt.subplots(figsize = self.figsize)\n            for i in ['top', 'right', 'bottom', 'left']:\n                ax.spines[i].set_color('black')\n            ax.spines['top'].set_visible(True);ax.spines['right'].set_visible(False)\n            ax.spines['bottom'].set_visible(False);ax.spines['left'].set_visible(False)\n            sns.barplot(tdf.index,tdf.values,edgecolor='k',palette = 'rainbow',ax=ax);\n            plt.title(self.title);ax.grid(ls='--',alpha = 0.9);plt.show()\n        \n        ''' Drop All NAN values in DataFrame'''\n        if(self.drop_nan):\n            X = X.dropna(); print(X.shape) # drop NaN values in df\n            return X\n            \n        ''' Split DataFrame into Numerical\/Object features'''\n        if(self.select_dtype):\n            X1 = X.select_dtypes(include=['float64','int64'])     # return only numerical features from df\n            X2 = X.select_dtypes(exclude=['float64','int64'])\n            return X1,X2\n        \n        \ndef function(ldf,id=None):\n\n    if(id is 'boxplot'):\n        # 1. Univariate Boxplots\n        fig, axs = plt.subplots(ncols=5, nrows=3, figsize=(14,4))\n        index = 0\n        axs = axs.flatten()\n        for k,v in X.items():\n\n            flierprops = dict(marker='o', mfc='k',ms=3,ls='none', mec='k')\n            ax = sns.boxplot(x=k,data=ldf, orient='h',flierprops=flierprops,\n                             ax=axs[index], width=.5)\n            index += 1\n        plt.tight_layout()\n\n    elif(id is 'outiers'):\n#       2. Define Outliers\n        for k, v in ldf.items():\n            q1 = v.quantile(0.25); q3 = v.quantile(0.75); irq = q3 - q1\n            v_col = v[(v <= q1 - 1.5 * irq) | (v >= q3 + 1.5 * irq)]\n            perc = np.shape(v_col)[0] * 100.0 \/ np.shape(ldf)[0]\n            print(\"Column %s outliers = %.2f%%\" % (k, perc))\n    \n    elif(id is 'histograms'):\n        # 3. Histograms \n        fig, axs = plt.subplots(ncols=5, nrows=3, figsize=(14, 8))\n        index = 0\n        axs = axs.flatten()\n        for k,v in ldf.items():\n            sns.histplot(v,ax=axs[index],bins=20)\n            index += 1\n        plt.tight_layout()\n        \n    elif(id is 'correlation'):\n        # 4. Correlation Matrix\n        cmap = sns.diverging_palette(220, 10, as_cmap=True)\n        # Bivariate Correlation Matrix\n        def corrMat(df,id=False):\n\n            corr_mat = df.corr().round(2)\n            f, ax = plt.subplots(figsize=(9,7))\n            mask = np.triu(np.ones_like(corr_mat, dtype=np.bool))\n            mask = mask[1:,:-1]\n            corr = corr_mat.iloc[1:,:-1].copy()\n            sns.heatmap(corr,mask=mask,vmin=-0.3,vmax=0.3,center=0, \n                        cmap='Blues',square=False,lw=2,annot=True,cbar=False)\n\n        corrMat(ldf)\n        \n''' Draw a Bivariate Seaborn Pairgrid \/w KDE density w\/ '''\ndef snsPairGrid(df):\n\n    ''' Plots a Seaborn Pairgrid w\/ KDE & scatter plot of df features'''\n    g = sns.PairGrid(df,diag_sharey=False)\n    g.fig.set_size_inches(14,13)\n    g.map_diag(sns.kdeplot, lw=2) # draw kde approximation on the diagonal\n    g.map_lower(sns.scatterplot,s=15,edgecolor=\"k\",linewidth=1,alpha=0.4) # scattered plot on lower half\n    g.map_lower(sns.kdeplot,cmap='plasma',n_levels=10) # kde approximation on lower half\n    plt.tight_layout()\n    \n    \n# Class to Visualise Things Only\nclass visualise(BaseEstimator,TransformerMixin):\n    \n    def __init__(self,vis_mean_AUD=None,model_name=None,target=None,eval_fi=False,vis_box=False,\n                 vis_compare_mean_AUD=False,vis_compare_bar=False,top_scat=50,top_bar=None,\n                 option=False):\n        self.vis_mean_AUD = vis_mean_AUD # [T\/F] trigger for mean AUD visualisation \n        self.model_name = model_name     # define which model plot in vis_mean_AUD\n        self.target = target             # target varable [str]\n        self.vis_box = vis_box # boxplots for univariate analysis\n        self.vis_compare_mean_AUD = vis_compare_mean_AUD\n        self.top_scat = top_scat # export only top n number of suburbs for scatter matrix\n        self.top_bar = top_bar   # show only top cases for bar sort\n        self.vis_compare_bar = vis_compare_bar # compare two bar plots (general)\n        self.option = option\n\n    @staticmethod \n    def corrMat2(df,target='demand',figsize=(9,0.5),ret_id=False):\n\n        corr_mat = df.corr().round(2);shape = corr_mat.shape[0]\n        corr_mat = corr_mat.transpose()\n        corr = corr_mat.loc[:, df.columns == target].transpose().copy()\n\n        if(ret_id is False):\n            f, ax = plt.subplots(figsize=figsize)\n            sns.heatmap(corr,vmin=-0.3,vmax=0.3,center=0, \n                         cmap=cmap,square=False,lw=2,annot=True,cbar=False)\n            plt.title(f'Feature Correlation to {target}')\n\n        if(ret_id):\n            return corr\n        \n    def fit(self):\n        return self\n    \n    # X -> Numerical (feature matrix + target variable)\n    def transform(self,X):\n        \n        if(self.option is 'histogram'):\n            vdf_perth1_num,_ = transformer(select_dtype=True).transform(X=X)\n            vdf_perth1_num.hist(bins=60, figsize=(20,15));plt.show()\n        \n        ''' show suburb based mean price prediction\/price '''\n        if(self.vis_mean_AUD is not None):\n            \n            # Combine Numerical & Object Features\n            if(self.vis_mean_AUD is 'error'):\n                tdfx = X.groupby(['suburb']).mean().sort_values(by=self.model_name+'_error',ascending=False)\n                \n                if(self.top_bar is not None):\n                    dfx = X.groupby(['suburb']).mean().sort_values(by=self.model_name+'_error',ascending=False)[:self.top_bar]\n                else:\n                    dfx = tdfx\n                    \n                fig = px.bar(dfx,x=dfx.index, y=[self.model_name+'_error'],template='plotly_white',height=400)\n                fig.update_layout(barmode=\"group\",title='Suburb Based Mean Error |(y_pred-y_target)|',showlegend=True)\n                \n            elif(self.vis_mean_AUD is 'value'):\n                tdfx = X.groupby(['suburb']).mean().sort_values(by=self.model_name+'_error',ascending=False)                \n                if(self.top_bar is not None):\n                    dfx = X.groupby(['suburb']).mean().sort_values(by=self.model_name+'_error',ascending=False)[:self.top_bar]\n                else:\n                    dfx = tdfx\n                \n                fig = px.bar(dfx,x=dfx.index, y=[self.model_name,self.target],template='plotly_white',height=400)\n                fig.update_layout(barmode=\"group\",title='Suburb-Based Mean Prediction\/Target Variable',showlegend=True)\n\n            # Used for Scatter Matrix Import \n            fig.show() # stack\/overlay\/group\n            tdfx.loc[:,'group_id2'] = 0\n            tdfx.loc[:self.top_scat,'group_id2'] = 1\n            \n            return tdfx\n        \n        ''' Compare Mean Groupby Suburb Error Bars '''\n        # X -> List of Pandas DataFrames\n        if(self.vis_compare_mean_AUD):\n            \n            dfx1 = X[0].groupby(['suburb']).mean().sort_values(by=self.model_name+'_error',ascending=False)\n            dfx2 = X[1].groupby(['suburb']).mean().sort_values(by=self.model_name+'_error',ascending=False)\n            dfx1.rename(columns = {self.model_name+'_error':'A'}, inplace = True)\n            dfx2.rename(columns = {self.model_name+'_error':'B'}, inplace = True)\n            dfx_all = pd.concat([dfx1['A'],dfx2['B']],axis=1)               \n            fig = px.bar(dfx_all,x=dfx_all.index, y=['A','B'],template='plotly_white',height=400)\n            fig.update_layout(barmode=\"group\",title='Suburb Based Mean Error |(y_pred-y_target)|',showlegend=True)\n            fig.show()\n            \n        ''' Compare Two Error Bars (general)'''\n        # X -> List of Pandas DataFrames\n        if(self.vis_compare_bar):\n            \n            X[0].rename(columns = {self.model_name+'_error':'A'}, inplace = True)\n            X[1].rename(columns = {self.model_name+'_error':'B'}, inplace = True)\n            dfx_all = pd.concat([dfx1['A'],dfx2['B']],axis=1)               \n            fig = px.bar(dfx_all,x=dfx_all.index, y=['A','B'],template='plotly_white',height=400)\n            fig.update_layout(barmode=\"group\",title='Suburb Based Mean Error |(y_pred-y_target)|',showlegend=True)\n            fig.show()\n            \n        ''' Plot Univariate Boxplots for Data Distribution '''\n        if(self.vis_box):\n            \n            lX,_ = transformer(select_dtype=True).transform(X=X)\n            fig,axs = plt.subplots(ncols=5,nrows=3,figsize=(14,4))\n            index = 0\n            axs = axs.flatten()\n            for k,v in lX.items():\n                flierprops = dict(marker='o',mfc='k',ls='none',mec='k')\n                ax = sns.boxplot(x=k,data=lX,orient='h',flierprops=flierprops,\n                                ax=axs[index],width=0.5)\n                index += 1\n            plt.tight_layout()  \n            \n        if(self.option is 'outliers'):\n            \n    #       2. Define Outliers\n            lX,_ = transformer(select_dtype=True).transform(X=X)\n            for k, v in lX.items():\n                q1 = v.quantile(0.25); q3 = v.quantile(0.75); irq = q3 - q1\n                v_col = v[(v <= q1 - 1.5 * irq) | (v >= q3 + 1.5 * irq)]\n                perc = np.shape(v_col)[0] * 100.0 \/ np.shape(lX)[0]\n                print(\"Column %s outliers = %.2f%%\" % (k, perc))     ","2baff20a":"df_perth0 = pd.read_csv('\/kaggle\/input\/perth-house-prices\/all_perth_310121.csv')\ndf_perth0.columns = map(str.lower, df_perth0.columns)\ndf_perth0 = df_perth0.drop(['longitude','latitude'],axis=1)\ndf_perth0.rename({'cbd_dist':'CBD_dist'},axis=1,inplace=True)\ndf_perth0.columns","bae27e64":"df0 = pd.read_csv('\/kaggle\/input\/auspostGPS\/australian_postcodes.csv')\ndf0.head()","2c8d83d7":"df_gps = pd.read_csv('\/kaggle\/input\/php-gps2\/PHP_GPS2.csv')\ndf_gps.columns","e1579972":"df_perth = pd.concat([df_perth0,df_gps[['long','lat']]],axis=1)\ndf_perth.head()","801c6177":"df_perth.info()","a9e43c6f":"# Some Data Cleaning \ndf_perth.drop_duplicates(subset=['address'],inplace=True) # Some addresses actually have multiple entries\ndf_perth.index = df_perth['address'] # set dataframe index, since it's not really a useful feature \ndel df_perth['address'] # let's also delete the column","82313a4f":"''' Remove Missing Data '''\ntransformer(show_nan=True,figsize=(8,3),title='Feature (NaN) %').transform(X=df_perth)","721c8117":"transformer(show_counts=True,title='Garage Value_Counts',figsize=(13,2)).transform(X=df_perth['garage'])","eb460d10":"print(df_perth.shape)\ndf_perth['garage'] = df_perth['garage'].fillna(0)  # fill missing data with 0\ndf_perth = transformer(drop_nan=True).transform(X=df_perth)  # drop the rest","570dbc8c":"df_perth.columns","f842cfda":"# Split the features into categorical\/ordinal features\ndf_num,df_cat = transformer(select_dtype=True).transform(X=df_perth)","b561928e":"df_cat.columns","2e23c9df":"# df_perth3 = df_perth1.copy()\ndf_num[['sold_month', 'sold_year']] = df_cat['date_sold'].str.split('-', 1, expand=True).astype('float64')\ndf_cat.drop(['date_sold'],axis=1,inplace=True)","8c9c8214":"# df used for EDA\ndf_EDA = pd.concat([df_num,df_cat],axis=1)","6b19f9e1":"df_EDA.info()","ca7c03a5":"def px_stats(df, n_cols=4, to_plot='box',height=800):\n    \n    ldf,_ = transformer(select_dtype=True).transform(X=df)\n    numeric_cols = ldf.columns\n    n_rows = -(-len(numeric_cols) \/\/ n_cols)  # math.ceil in a fast way, without import\n    row_pos, col_pos = 1, 0\n    fig = make_subplots(rows=n_rows, cols=n_cols,subplot_titles=numeric_cols.to_list())\n    \n    for col in numeric_cols:\n        if(to_plot is 'histogram'):\n            trace = go.Histogram(x=ldf[col],showlegend=False)\n        else:\n            trace = getattr(px, to_plot)(ldf[col],x=ldf[col])[\"data\"][0]\n            \n        if col_pos == n_cols: \n            row_pos += 1\n        col_pos = col_pos + 1 if (col_pos < n_cols) else 1\n        fig.add_trace(trace, row=row_pos, col=col_pos)\n\n    fig.update_layout(template='plotly_white');fig.update_layout(margin={\"r\":0,\"t\":60,\"l\":0,\"b\":0})\n#     if(to_plot is 'histogram'):\n#         fig.update_traces(marker=dict(line=dict(width=1, color='white')))\n    fig.update_layout(height=height);fig.show()","6fba71e0":"px_stats(df_EDA, to_plot='histogram')","1c554d07":"px_stats(df_EDA, to_plot='box',height=400)","b35a80b3":"ldf = df_EDA.sort_values(by='suburb')\nfig = px.box(ldf, x=\"suburb\", y=\"price\",template='plotly_white',\n             title=\"Suburb Based Price Range (Alphabetically Arranged)\",height=600)\nfig.update_layout(yaxis={'categoryorder':'total ascending'},margin=dict(l=80, r=80, t=100, b=80))\nfig.update_traces(marker=dict(size=4));fig.update_layout(xaxis=dict(rangeslider=dict(visible=True)));fig.show()","eab1f72d":"df_submed = df_EDA.groupby(['suburb']).median()\ndf_submin = df_EDA.groupby(['suburb']).min()\ndf_submax = df_EDA.groupby(['suburb']).max()","5af35142":"df_submed.head()","95faa81e":"dfx = df_submed.sort_values(by=['CBD_dist'],ascending=True)\nfig = px.bar(dfx, x=dfx.index, y='price',template='plotly_white',text='CBD_dist',height=300)\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig.update_layout(margin={\"r\":0,\"t\":60,\"l\":0,\"b\":0});fig.show()","343446ed":"dfx = df_EDA.groupby(['suburb']).median().sort_values(by=['nearest_stn_dist'],ascending=True)\nfig = px.bar(dfx, x=dfx.index, y='price',template='plotly_white',hover_data=['nearest_stn_dist','price'],height=300)\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig.update_layout(margin={\"r\":0,\"t\":60,\"l\":0,\"b\":0});fig.show()","a6c1243e":"dfx = df_EDA.groupby(['build_year']).median().sort_values(by=['price'],ascending=True)\ndfx2 = df_EDA.groupby(['build_year']).min().sort_values(by=['price'],ascending=True)\ndfx3 = df_EDA.groupby(['build_year']).max().sort_values(by=['price'],ascending=True)\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x=dfx3.index, y=dfx3['price'],name='max price',marker_color='rgb(27,38,49)'))\nfig.add_trace(go.Bar(x=dfx.index, y=dfx['price'],name='median price',marker=dict(color='#566573')))\nfig.add_trace(go.Bar(x=dfx2.index, y=dfx2['price'],name='lowest price',marker_color='#CACFD2'))\nfig.update_layout(barmode='overlay',template='plotly_white',height=300,title='Property Build Year Grouped House Prices')\nfig.update_layout(margin={\"r\":0,\"t\":60,\"l\":0,\"b\":0});fig.show()","8eda68c9":"# Plot Relative Feature Importance\ndef feature_importance(tldf,feature='price',n_est=500):\n    \n    # X : Numerical \/ Object DataFrame\n    ldf,ldf2 = transformer(select_dtype=True).transform(X=tldf)\n     \n    # Input dataframe containing feature & target variable\n    X = ldf.copy()\n    y = ldf[feature].copy()\n    del X[feature]\n    \n#   CORRELATION\n    imp = corrMat2(ldf,feature,figsize=(15,0.5),ret_id=True)\n    del imp[feature]\n    s1 = imp.squeeze(axis=0);s1 = abs(s1)\n    s1.name = 'Correlation'\n#     display(s1)\n        \n#   SHAP\n    model = CatBoostRegressor(silent=True,n_estimators=n_est).fit(X,y)\n    explainer = shap.TreeExplainer(model)\n    shap_values = explainer.shap_values(X)\n    shap_sum = np.abs(shap_values).mean(axis=0)\n    s2 = pd.Series(shap_sum,index=X.columns,name='Cat_SHAP').T\n#     display(s2)\n    \n#   RANDOMFOREST\n    model = RandomForestRegressor(n_est,random_state=0, n_jobs=-1)\n    fit = model.fit(X,y)\n    rf_fi = pd.DataFrame(model.feature_importances_,index=X.columns,\n                                         columns=['RandForest']).sort_values('RandForest',ascending=False)\n    s3 = rf_fi.T.squeeze(axis=0)\n#     display(s3)\n\n#   XGB \n    model=XGBRegressor(n_estimators=n_est,learning_rate=0.5,verbosity = 0)\n    model.fit(X,y)\n    data = model.feature_importances_\n    s4 = pd.Series(data,index=X.columns,name='XGB').T\n#     display(s4)\n    \n#   KBEST\n    model = SelectKBest(k=X.shape[1], score_func=f_regression)\n    fit = model.fit(X,y)\n    data = fit.scores_\n    s5 = pd.Series(data,index=X.columns,name='K_best')\n#     display(s5)\n\n    # Combine Scores\n    df0 = pd.concat([s1,s2,s3,s4,s5],axis=1)\n    df0.rename(columns={'target':'lin corr'})\n\n    x = df0.values \n    min_max_scaler = preprocessing.MinMaxScaler()\n    x_scaled = min_max_scaler.fit_transform(x)\n    df = pd.DataFrame(x_scaled,index=df0.index,columns=df0.columns)\n    df = df.rename_axis('Feature Importance via', axis=1)\n    df = df.rename_axis('Feature', axis=0)\n    \n    pd.options.plotting.backend = \"plotly\"\n    fig = df.plot(kind='bar',title='Scaled Feature Importance')\n    fig.update_layout(template='plotly_white');fig.update_layout(margin={\"r\":0,\"t\":60,\"l\":0,\"b\":0});fig.show()","f43147de":"feature_importance(df_EDA)","caea9f88":"plotlyoff_corr(df_EDA.corr().round(2))","f6465060":"titles = ['Floor Area','Land Area']\nfig = make_subplots(rows=1, cols=2,shared_yaxes=True,subplot_titles=titles,horizontal_spacing = 0.05)\n\nfig.add_trace(go.Scattergl(y=df_EDA['price'].values,x=df_EDA['floor_area'].values,mode='markers',name='Floor Area',text=df_EDA.index,opacity=0.1),row=1, col=1)\nfig.add_trace(go.Scattergl(y=df_EDA['price'].values,x=df_EDA['land_area'].values,mode='markers',name='Land Area',text=df_EDA.index,opacity=0.1),row=1, col=2)\n\nfig.update_traces(marker=dict(size=4,line=dict(width=1.2,color='black')))\nfig.update_layout(template='plotly_white',title='Area Feature Relation to Property Sold Price',height=500,showlegend=False)\nfig.update_layout(margin={\"r\":0,\"t\":60,\"l\":0,\"b\":0});fig.show()","a0db0b5f":"df_EDA[(df_EDA.index == '60 Semerwater Crescent') \n         | (df_EDA.index == '12 Gailey Way') \n         | (df_EDA.index == '3 Longstaff Avenue')\n         | (df_EDA.index == '11 Semerwater Crescent')] ","5a4ca681":"df_EDA.loc['60 Semerwater Crescent','land_area'] = 375 # m^2\ndf_EDA.loc['12 Gailey Way','land_area'] = 375\ndf_EDA.loc['3 Longstaff Avenue','land_area'] = 574 \ndf_EDA.loc['11 Semerwater Crescent','land_area'] = 375 # m^2","f6e856db":"df_EDA_smlland = df_EDA[df_EDA['land_area'] < 1200].copy()\ndf_EDA_bigland = df_EDA[(df_EDA['land_area'] >= 1200)].copy()","e04d9a3c":"titles = ['Land_Area < 1200','Land_Area > 1000 | Land_Area < 30000']\nfig = make_subplots(rows=1, cols=2,shared_yaxes=True,subplot_titles=titles,horizontal_spacing = 0.05)\n\nfig.add_trace(go.Scattergl(y=df_EDA_smlland['price'],x=df_EDA_smlland['land_area'],mode='markers',name='Land Area',text=df_EDA_smlland.index,opacity=0.05),row=1, col=1)\nfig.add_trace(go.Scattergl(y=df_EDA_bigland['price'],x=df_EDA_bigland['land_area'],mode='markers',name='Land Area',text=df_EDA_bigland.index,opacity=0.05),row=1, col=2)\n\nfig.update_traces(marker=dict(size=4,line=dict(width=1.2,color='black')))\nfig.update_layout(template='plotly_white',title='Land Area Subset Data',height=500,showlegend=False)\nfig.update_layout(margin={\"r\":0,\"t\":60,\"l\":0,\"b\":0});fig.show()","a3a285ac":"feature_importance(df_EDA_smlland)","ec14c735":"feature_importance(df_EDA_bigland)","9268ab4b":"titles= ['CBD_dist','nearest_stn_dist']\nfig = make_subplots(rows=1, cols=2,shared_yaxes=True,subplot_titles=titles,horizontal_spacing = 0.05)\n\nfig.add_trace(go.Scattergl(y=df_EDA['price'],x=df_EDA['CBD_dist'],mode='markers',name='CBD_dist',text=df_EDA.index,opacity=0.05),row=1, col=1)\nfig.add_trace(go.Scattergl(y=df_EDA['price'],x=df_EDA['nearest_stn_dist'],mode='markers',name='nearest_stn_dist',text=df_EDA.index,opacity=0.05),row=1, col=2)\n\nfig.update_traces(marker=dict(size=3,line=dict(width=1.2,color='black')))\nfig.update_layout(template='plotly_white',barmode='stack',title='Distance Feature Relations to Price',height=500,showlegend=False)\nfig.update_layout(margin={\"r\":0,\"t\":60,\"l\":0,\"b\":0});fig.show()","6c500619":"import geopandas as gpd\n\ndef plot_geo(ldf,feature,title=None,lst_val=None):\n    \n    # Load Geometry File\n    wa_gdf = gpd.read_file('\/kaggle\/input\/wa-gda2020\/WA_LOCALITY_POLYGON_SHP-GDA2020.shp')    # Load the data using \n    wa_gdf.drop(['POSTCODE','PRIM_PCODE','LOCCL_CODE','DT_GAZETD','STATE_PID','DT_RETIRE','DT_CREATE','LOC_PID'],axis=1,inplace=True)\n\n    wa_gdf.index = wa_gdf['NAME']\n    median_price = ldf.groupby(['suburb']).median()\n    median_price.index = median_price.index.str.upper()\n    df_merged = wa_gdf.join(median_price).dropna() # some perth suburbs don't have data & drop other WA region suburbs to speed up map load\n\n    # Convert geometry to GeoJSON\n    df_merged = df_merged.to_crs(epsg=4327)\n    lga_json = df_merged.__geo_interface__\n\n    MAPBOX_ACCESSTOKEN = 'pk.eyJ1Ijoic2h0cmF1c3NhcnQiLCJhIjoiY2t0eXhzdGFpMWlscTJ1cDg3ZGhocmptayJ9.7TepS9eN6iKXwYjPHu44Tg'\n\n    if(lst_val is None):\n        lst_val = [df_merged[feature].min(),df_merged[feature].max()]\n\n    # Set the data for the map\n    data = go.Choroplethmapbox(geojson = lga_json,\n                               locations = df_merged.index,    \n                               z = df_merged[feature], \n                               text = title,\n                               colorbar=dict(thickness=20, ticklen=3,outlinewidth=0),\n                               marker_line_width=1, marker_opacity=0.8, colorscale=\"viridis\",\n                               zmin=lst_val[0], zmax=lst_val[1])\n\n    layout = go.Layout(mapbox1 = dict(domain = {'x': [0, 1],'y': [0, 1]},center = dict(lat=-31.95, lon=115.8),\n                       accesstoken = MAPBOX_ACCESSTOKEN,zoom = 9),\n                       autosize=True,height=650)\n\n    # Generate the map\n    fig=go.Figure(data=data, layout=layout)\n    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n    fig.show()","5ace1c58":"plot_geo(ldf=df_EDA,feature='price',title='Median House Price')\nplot_geo(ldf=df_EDA,feature='floor_area',title='Median Floor Area',lst_val=[0,250])\nplot_geo(ldf=df_EDA,feature='land_area',title='Median Land Area',lst_val=[0,1000])\nplot_geo(ldf=df_EDA,feature='build_year',title='Median Build Year')\nplot_geo(ldf=df_EDA,feature='nearest_stn_dist',title='Median Nearest Station Distance',lst_val=[0,10000])","55800f30":"df_EDA_low = df_EDA[df_EDA['price']<350000]\ndf_EDA_low.shape","9203849c":"# Let's look at only a few in this suburb\ndisplay(df_EDA_low[df_EDA_low['suburb']=='Mardella'].head())","55f89712":"plot_geo(ldf=df_EDA_low,feature='price',title='Median House Price')","934384a5":"df_EDA_low2 = df_EDA[(df_EDA['price']<350000) & (df_EDA['build_year'] >= 2010)]\ndf_EDA_low2.shape","27cdb2b9":"df_EDA_low2[df_EDA_low2['suburb']=='Westminster'].sort_values(by='price')","cdf6f561":"plot_geo(ldf=df_EDA_low2,feature='price',title='Median House Price')","e94742ff":"# Let's add to df_perth3\ndf_EDA_presold = df_EDA.copy()\ndf_EDA_presold['presold'] = df_EDA_presold['sold_year'].astype('int') < df_EDA_presold['build_year']\ndf_EDA_presold['presold'].value_counts()","5aa0cdca":"dfx = df_EDA_presold.groupby(['sold_year']).sum()\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x=dfx.index, y=dfx['presold'],name='Presold Properties by Year'))\nfig.update_layout(barmode='overlay',template='plotly_white',height=300,title='Presold Properties by Year')\nfig.update_layout(margin={\"r\":0,\"t\":60,\"l\":0,\"b\":0});fig.show()","9aeedeff":"# Plot Scatter Matrix using Plotly Express\ndef scat_mat(ldf,dim=None,colour=None,hov_name=None,title=None):\n    \n    fig = px.scatter_matrix(ldf,dimensions=dim,opacity=0.5,color=colour,hover_name=hov_name,height=1000)\n    fig.update_traces(marker=dict(size=6,line=dict(width=1,color='black')))\n    fig.update_layout(template='plotly_white',title=title) # stack\/overlay\/group\n    fig.show()","970e79bc":"tlist = ['price','bedrooms','bathrooms','land_area','floor_area']\nscat_mat(ldf=df_EDA_presold,dim=tlist,colour='presold',hov_name=df_EDA_presold.index,title='Presold Property Scatter Matrix Relations')","c67d89a4":"plot_geo(ldf=df_EDA_presold[df_EDA_presold['presold']==True],feature='price',title='Presold Properties Median House Price')","1ba3dd8a":"- Comparing <b>presold<\/b> properties to <b>non presold<\/b>, through a scatter matrix, we can generally get an idea they don't tend be very different when it comes to basic features like <code>bedrooms<\/code>,<code>bathrooms<\/code>,<code>land_area<\/code> & <code>floor_area<\/code>. \n- The prices of the current set of presold properties, on the otherhand are certainly on the lower end.","ab6be582":"#### <b><span style='color:#2779d2'>EDA - SUBURB MEDIAN PROPERTY PRICES SORTED BY nearest_stn_dist<\/span><\/b>\n\nWe can look at which suburbs would be cheapest, if you wanted to live near public transport, <code>Armadale<\/code>, <code>Parmelia<\/code>, <code>Warnbro<\/code> among the cheaper suburbs overall.","902950d6":"- We can note that for smaller <code>land_value<\/code> properties and for larger ones, we have quite a different set of feature that are more impactful.\n- Whilst Perth may not be the most concentrated city when it comes to area values\/population near the CBD (compared to other cities in general), there certainly is a difference between a property that are used only for building a house on & properties that allow one to build cottages, farms and alike. It may be beneficial to classify these properties, with the addition of a categorical feature that would define the property type.\n- Let's also create models for these two property types separately in the models section.","35e5a5ba":"For a start, we have the following features as we start some <b>EDA<\/b>, more features would be useful to add.","0d1890f1":"#### <b><span style='color:#2779d2'>EDA - PROPERTY BUILD YEAR MIN\/MED\/MAX PROPERTY PRICES<\/span><\/b>\n\n- Despite the market <code>median house price<\/code> being not exactly very low, hovering in the region of 400-500k in the last 60 years or so, there has tended to be properties that are \"relatively affordable\" built every year in the range 100-300k range, which is a positive thing, given the number people near the poverty line will only likely to increase as stated in the [Canberra Times](https:\/\/www.canberratimes.com.au\/story\/6641748\/one-in-eight-australians-living-in-poverty\/?cs=14231), (which likely is an indicator that more and more people will not be able to afford housing in general & is backed by an article from [Melbourne Uni](https:\/\/fbe.unimelb.edu.au\/exchange\/edition1\/house-prices-outpacing-income-growth) which states that many would-be first time buyers are priced out of the market).  \n- Interesting to also note that nothing was built in 1944 (at least accoriding to this data) & there tends to be a <b>common trend of median price reducing<\/b>, the newer the property is in the dataset, a similar trend can be observed for the <b>minimum price<\/b>.","f3da4a78":"## <b><span style='color:#2779d2'> 2<\/span> | EXPLORATORY DATA ANALYSIS<\/b>\n### <b><span style='color:#2779d2'>2.1<\/span> | UNIVARIATE ANALYSES<\/b>\n\n#### <b><span style='color:#2779d2'>EDA - FEATURE DISTRIBUTIONS<\/span><\/b>\n\nThe number of <code>bedrooms<\/code> & <code>bathrooms<\/code>, are most certainly one of the most important features of a property, alongside with the number of <code>garages<\/code> (car slots), some oservations:\n- We can note how uncommon __1 bedroom appartment__ properties are in Perth (at least acording to this dataset), most common being a __4 bedroom property__, typically having __1 or 2 bathrooms__ & having a __garage__ with __two car slots__.\n- We can see a very rapid __increase in property sales__ in the last 6 years or so.  I'm guessing real estate agents in Perth are kept busy. \n- A steady increase in properties built since the 1950s can also be noted.\n- Some of the properties have a very large number of garages slots, so it could make sense to just remove them but lets just keep them anyway.","42e94d04":"#### <b><span style='color:#2779d2'>EDA - AREA FEATURE RELATIONS TO PRICE<\/span><\/b>\n\n<code>Floor_area<\/code> & <code>Land_area<\/code> have a relatively high <b>feature importance<\/b> as we saw previousy, let's look at the bivariate relations to <code>price<\/code>.","a0e9303c":"Let's also take a look where these properties were built; we can note that quite a lot of them are further away from Perth, and some probably even closer to <b>Mandurah<\/b> than <b>Perth<\/b> itself, and upon reviewing some properties, there it seems to be [quite more affordable](https:\/\/www.realestate.com.au\/buy\/property-house-in-mandurah\/list-1?activeSort=price-asc&source=refinement) and in close proximity to the oceans.","3b7f2947":"### <b><span style='color:#2779d2'>2.2<\/span> | BIVARIATE ANALYSES<\/b>\n#### <b><span style='color:#2779d2'>EDA - PEARSON CORRELATION<\/span><\/b>\n\n<b>Linear correlation<\/b> can be useful to understand how our variables change relative to one another in the input dataset, most feature related to price in an expected manner, perhaps most suprising out of the lot was <code>land_area<\/code> having a much smaller value than expected<\/code>, in compa","36d25bf9":"#### <b><span style='color:#2779d2'>GDE - LOWER PRICE PROPERTIES : ALL built_year<\/span><\/b>\n\n- This dataset includes around 4.5k properties that cost less than 350,000 AUD <b>at time of purchase<\/b>. \n- This includes properties sold a while back as well, and is <b>not necessarily a reflection of \"current market price values\"<\/b>, which is likely to have changed over time. \n- This is a significant issue that can affect the model accuracy, since some of our <b>price<\/b> data is \"frozen in time\", and <b>we need features that can correct for this on top of some more obvious features like floor_area<\/b>. \n- As an example, <code>10 Mardja Loop<\/code> , a 5 bedroom house was apparently sold for 87k in 2003 ( not too long after the suburb was officially formed ), [realestate](https:\/\/www.realestate.com.au\/property\/10-mardja-loop-mardella-wa-6125) attemps to evaluate the property in the current market by comparing it to similarly sized houses & suburb based sales. ie. somewhere in the region of perhaps 500k... So there would potentially be a significant shift in price, if the property was to be sold now.\n- We now should have a clear indication that our model, if trained on the curret set of data, will be predicting the property 'price' based on the evolution of sales data, in case that wasn't already clear. ","3a3126c2":"### <b><span style='color:#2779d2'>1.5<\/span> | CATEGORICAL & ORDINAL FEATURES<\/b>\n\nWe have a few <b>categorical features<\/b> & we should decide how we will go about them; we can use it during <b>EDA<\/b>.\n- Let's split the feature <code>date_sold<\/code> into two features; <code>sold_month<\/code> & <code>sold_year<\/code>.\n- <code>suburb<\/code>, <code>nearest_stn<\/code> are quite interesting features for which we can use <b>mapping<\/b>; we might consider introducing some form of scoring system & attempt to influence the model accuracy this way, mapping will be introduced in this <b>models<\/b> section.","2a6d3aec":"#### <b><span style='color:#2779d2'>EDA - SUBURB MEDIAN PROPERTY PRICES SORTED BY CBD_dist<\/span><\/b>\n\nLooking at the top 100 suburbs that are on average closest to the CBD, <code>West Perth<\/code>,<code>Glendalough<\/code> & <code>Nollamara<\/code> are amongst the cheaper alternatives, but we can can see a trend of higher property <code>price<\/code>, the closer to the the city centre we get as well.","d32177e6":"#### <b><span style='color:#2779d2'>EDA - SUBURB SORTED PRICE RANGES<\/span><\/b>\n\n- We can visualise the statistics data of <code>Price<\/code> in different <code>suburbs<\/code> (sorted alphabetically) if we are interested, in a particular suburb it is quicker to find it by name when required.\n- We can see that there a quite a number of property <code>price<\/code> cases which exceed the <b>q1<\/b> & <b>q3<\/b> threshold, even in different suburbs; which is an indicator that we have a number of 'outlier' cases. \n- Ideally we should be looking them, as they are likely going to complicate the fitting process for our models, especially if our <b>features<\/b> aren't chosen very well.","6a15bc1e":"#### <b><span style='color:#2779d2'>EDA - DISTANCE FEATURE RELATION TO PROPERTY PRICE<\/span><\/b>\n\n- <code>CBD_dist<\/code> as we saw above, has a significant weight according to the <b>feature importance<\/b>, however <code>nearest_stn_dist<\/code> is slightly less impactful, let's view the scatter relation.\n- Distance based features usually are very informative for models, let's take a look at two related features here (<code>CBD_dist<\/code> & <code>nearest_stn_dist<\/code>)\n- Lowering the opacity of the scatter data, we can get a sense of the <b>general trend<\/b> of increasing price as the <code>CBD_dist<\/code> reduces, with an accute increase very close to the CBD.\n- <code>nearest_stn_dist<\/code>, on the other hand is slightly more scatted, showing no visible linear relation in the scater data, however there tends to be a two direction scatter realation in addition to the central scatter region.","3c2b9f01":"#### <b><span style='color:#2779d2'>EDA - DATA DISTRIBUTION BOXPLOTS<\/span><\/b>\n\n- Let's take a look at the distribution of our feature data again. \n- This time using boxplots; <b>boxplots<\/b> give us a good indication of how our data is distributed & outliers in the data. \n- Whilst it is often stated that <b>tree based<\/b>, such as RF are not sensitive to outliers, such as this article on [medium](https:\/\/arsrinevetha.medium.com\/ml-algorithms-sensitivity-towards-outliers-f3862a13c94d), it might be woth taking it into account, as there are good references that state otherwise as shown on [stackexchange](https:\/\/stats.stackexchange.com\/questions\/187200\/how-are-random-forests-not-sensitive-to-outliers). So we'll have to look into the effect of these outliers as well, when getting to the model generation stage.","13083f5b":"#### <b><span style='color:#2779d2'>GDE - LOWER PRICE PROPERTIES : build_year >= 2015<\/span><\/b>\n\n- Let's look at properties which were built after 2014 (over a period of three years here), it's actually quite interesting to know if low cost properties are actually available these days in Perth. We saw roughly 10 years earlier, it was quite possible, what about more recently?\n- So, over a period of a several years, 338 properties that are more or less affordable were built. Is that enough? Defnitely an intersting  question to explore ... \n- Most of them are located <b>north and south of Perth<\/b> & some further to the east of Perth & the Indian Ocean, tough nuggies to those wanting to live by the ocean in close proximity central Perth. <code>Waikiki<\/code> , <code>Alkimos<\/code>, <code>Jindalee<\/code>, <code>Eglinton<\/code> are among some suburbs with relatively affordable property prices.\n\nJust some intersting propeties that caught my attention:\n- [1A Forster Avenue](https:\/\/www.realestate.com.au\/property\/1a-forster-ave-lathlain-wa-6100), which was sold at a very big loss.\n- [1 Eastfield Count](https:\/\/www.realestate.com.au\/property\/1-eastfield-ct-ferndale-wa-6148), which was originally built in 1997, rebuilt in 2017 via, once again sold before being rebuilt, and not being too far form the CBD.\n- [101 Pine Crest Way](https:\/\/www.realestate.com.au\/property\/101-pine-crest-way-gnangara-wa-6077), which was sold much earlier, and perhaps only had a property built more recently.","3dd33a91":"- We have two features with missing data, <code>garage<\/code> probably makes sense to set to zero, whilst <code>build_year<\/code> is a little more tricky. \n- Ideally it would be best to obtain this data & not try to predict it using imputation, let's drop it here.","12d29487":"- <code>land_area<\/code> is one of the features that contains quite a large number of outliers. For smaller <code>land_area<\/code> proprties, this feature might not be the most impactful since they are all very similar, however the land area value does increase quite exponentially, thus it should be impactful only for a specific subset of properties, let's take a look at two subset groups.\n- Somewhere after the region of 1100-1300 (m^2), the values start to very rapidly increase, so lets make a division somewhere there.","0b6f88d6":"- We can see a very big difference between the two feature relations, when it comes to <code>price<\/code> value. \n- <code>floor_area<\/code> relation to <code>price<\/code> tends to be quite straightforward, whilst <code>land area<\/code> tends to be quite spread out.\n- If we actually zoom into <code>land_area<\/code> realation to <code>price<\/code>, we can note some lines at 10k, 20k & 40k, the relation as the <b>correlation<\/b> value suggests is quite spreadout and seemindly inconsistent, apart from these noted patterns.\n- Both relations contain a lot of outlier properties. \n\nA good rule of thumb it to <b>verify the data<\/b> if possible, some things that can be noted:\n- 60 Semerwater Crescent which has a value of 365k is likely an error according to [realestate](https:\/\/www.realestate.com.au\/property\/60-semerwater-cres-aveley-wa-6069?pid=p4ep-pdp|sold-pdp:property-history-cta#timeline) \n- Similarly; 12 Gailey Way on [reiwa](https:\/\/reiwa.com.au\/12-gailey-way-aveley-4382054\/)\n- Similarly; 3 Longstaff Avenue on [reiwa](https:\/\/reiwa.com.au\/3-longstaff-avenue-alkimos-3732905\/)\n- 1264 Chittering Road (554,500m^2) on [reiwa](https:\/\/reiwa.com.au\/1264-chittering-road-bullsbrook-wa-3781179\/) is probably an indicator anything below would probably be genuine, even though different sources do vary the value a little.\n\nOf course, many realistic datasets require a thorough investigation, which is unfortunately quite a labourious task, so I'll limit my efforts here.","ade72b37":"As far as these features are concerned, they are quite self explanatory:\n- <code>address<\/code> : Physical address of the property ( we will set to index )\n- <code>suburb<\/code> : Specific locality in Perth; a list of all Perth suburb can be found [here](https:\/\/www.homely.com.au\/find-suburb-by-region\/perth-greater-western-australia)\n- <code>price<\/code> : Price at which a property was sold (AUD)\n- <code>bedrooms<\/code> : Number of bedrooms\n- <code>bathrooms<\/code> : Number of bathrooms\n- <code>garage<\/code> : Number of garage places\n- <code>land_area<\/code> : Total land area (m^2)\n- <code>floor_area<\/code> : Internal floor area (m^2)\n- <code>buil_year<\/code> : Year in which the property was built\n- <code>CBD_dist<\/code> : Distance from the centre of Perth (m)\n- <code>nearest_stn<\/code> : The nearest public transport station from the property\n- <code>nearest_stn_dst<\/code> : The nearest station distance (m)\n- <code>date_sold<\/code> : Month & year in which the property was sold\n\n### <b><span style='color:#2779d2'>1.3<\/span> | ADDITIONAL DATASET w\/ LATITUDE & LONGITUDE<\/b>\n\n- Aside from <code>CBD_dist<\/code> (distance to some point in the centre of Perth), we don't have other geographical information; two identical <code>CBD_dist<\/code> values don't necessarily mean they are located near each other, which is why even rough estimates of GPS locations can be beneficial to include in order to improve our models.\n- I've loaded some data which contains some approximate GPS coodinates for each suburb (averaged coordinates within a suburb), ideally each property would have been more useful.\n- You can download the dataset containing [Australian Postcodes](https:\/\/www.matthewproctor.com\/australian_postcodes) & create your own, the <code>long,lat<\/code> values can be extracted based on two conditions <code>state == WA<\/code> & corresponding <code>suburbs<\/code>, which are included in column <code>locality<\/code>.  I don't own the dataset, so I will not upload it, the code to get the coordinates is included below.","cf7d9719":"- We can see that a lot housing in this area was sold before being built, which is a common way to buy more affordable housing, usully associated with early sales before prices hikes, backed up by this [article](https:\/\/www.newhomesource.com\/learn\/why-buy-into-new-community-early\/). It's also a nice way to increase the value of the property very early on if the construction projects are sucessfull. We can see some smart owners got a sizable return on their investment within a short period of time; [18 Mardja Loop](https:\/\/www.domain.com.au\/property-profile\/18-mardja-loop-mardella-wa-6125), as an example. \n- We can see that if there is a need to build affordble housing, the cost associated with building quite a sizable house actually is not very high at all, as we can see some built in 2005. The question these days really is why would a contractor sell a house and not attempt to cash in, since the buyer most likely will be able to. Only at a government level is this issue tackleable (which it can if it really wanted to), as we can see the Australian Government does attempt to address home ownership rights in general; [reference](https:\/\/www.dss.gov.au\/housing-support\/programmes-services\/housing).","7c0adadd":"### <b><span style='color:#2779d2'>2.3<\/span> | GEOSPATIAL DATA EXPLORATION (GDE)<\/b>\n\n- In this dataset, we have each individual address as our index, but don't have the individual GPS coordinates. \n- Let's look at <b>suburb<\/b> based data instead using <b>Choropeth Maps<\/b>, some examples of how to create them shown in notebook; [Australian Geographic Data Plots](https:\/\/www.kaggle.com\/shtrausslearning\/australian-geographic-data-plots).\n- We'll use the <b>General District Area<\/b> datafile for <b>Western Australia<\/b>, where Perth is located. The geographic data is available in this source [data.gov](https:\/\/data.gov.au\/dataset\/ds-dga-6a0ec945-c880-4882-8a81-4dbcb85e74e5\/distribution\/dist-dga-9fff5439-7af5-42f4-9102-42c4199c5c1c\/details?q=).\n\n#### <b><span style='color:#2779d2'>GDE - ENTIRE DATASET<\/span><\/b>\n\nLet's take a look at the suburb based median data, <code>price<\/code>, <code>floor_area<\/code>, <code>land_area<\/code>, <code>nearest_stn_dist<\/code> & <code>build_year<\/code>. Noting ","4b86fb2f":"### <b><span style='color:#2779d2'>1.4<\/span> | DATA ASSEMBLY & CLEANING<\/b>\n\n- The scrapped data needs quite a bit of cleaning; containing ocassional errors due to incorrect data, as well as standard NaN missing data.\n- Let's do some more obvious data cleaning here; dealing with <b>missing data<\/b> & <b>repetitive addresses.<\/b>","ea241f19":"#### <b><span style='color:#2779d2'>EDA - PRESOLD PROPERTIES<\/span><\/b>\n\n- We saw that in early 2000s, some properties were constantly being built and purchased at a very affordable price, as a result of <b>prepurchasing the property<\/b> before it was built ([Presold Homes](https:\/\/ibcbuilt.com\/pre-sold-homes)) \n- Preselling, generally is a way that allows buyers to purchase properties at more reasonable prices, especially with early upfront payments.\n- This practice was still noted to exist more recently as well. Let's take a look at a year by year basis, see how many properties were sold before they were built.\n- We can note that <b>only 633 properties out of 30000 were prebuilt<\/b>, which is not quite a lot. More importantly, they are probably acting like outliers having been sold under \"market value\" prices.\n- As the data shows, this kind of practice didn't really exist in Perth before 2000. 2013 & 2014 being the busiest years. ","e57a3ed4":"![](https:\/\/images-wixmp-ed30a86b8c4ca887773594c2.wixmp.com\/f\/8cc1eeaa-4046-4c4a-ae93-93d656f68688\/deogdrn-5d90efc3-ff4d-4793-9978-361a212b41f3.jpg?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ1cm46YXBwOjdlMGQxODg5ODIyNjQzNzNhNWYwZDQxNWVhMGQyNmUwIiwiaXNzIjoidXJuOmFwcDo3ZTBkMTg4OTgyMjY0MzczYTVmMGQ0MTVlYTBkMjZlMCIsIm9iaiI6W1t7InBhdGgiOiJcL2ZcLzhjYzFlZWFhLTQwNDYtNGM0YS1hZTkzLTkzZDY1NmY2ODY4OFwvZGVvZ2Rybi01ZDkwZWZjMy1mZjRkLTQ3OTMtOTk3OC0zNjFhMjEyYjQxZjMuanBnIn1dXSwiYXVkIjpbInVybjpzZXJ2aWNlOmZpbGUuZG93bmxvYWQiXX0.XjawmWiLz0CEYyx7uo_hqqrYXkB4qg7a3NamnjT4h2c)\nPhotography of <b>Perth<\/b> by [@harrycunningham](https:\/\/unsplash.com\/photos\/pNN9i2tR_8w)\n\n## <b><span style='color:#2779d2'> 1<\/span> | INTRODUCTION<\/b>\n### <b><span style='color:#2779d2'>1.1<\/span> | NOTEBOOK AIM<\/b>\n\n- I've decided to split the notebook into two parts __(I) EDA notebook (this)__ & __(II) ML models to predict price.__\n- The aim of this notebook is to build some models that can predict [Perth](https:\/\/www.australia.com\/en\/places\/perth-and-surrounds\/guide-to-perth.html) (located in Western Australia) housing prices based on a set of scrapped features made available in the [Perth Housing Dataset](https:\/\/www.kaggle.com\/syuzai\/perth-house-prices). \n\n#### <b><span style='color:#2779d2'>PART I - EDA<\/span><\/b>\n\n- Having learned how to use <b>Plotly<\/b> for geographic data analysis, thanks to a great article by Dr.Halupka, found on [towardsdatascience](https:\/\/towardsdatascience.com\/how-to-create-maps-in-plotly-with-non-us-locations-ca974c3bc997), we'll take a look at suburb based data as well. Let's see what we can learn about the dataset, whilst we try to reach our goal of predicting the target varaible <code>price<\/code>.\n- The division is mainly done due to the heavy load the plots have on the notebook loading performance.\n\n#### <b><span style='color:#2779d2'>PART II - PREDICTION MODELS<\/span><\/b>\n\n- Let's also use our own sklearn compatible class, here a simplistilc <b>XGBoost<\/b> models (tree ensemble approaches) are used, which is one of the more powerful models, and it might be interesting to see how well it perform compared to the [XGBoost Library](https:\/\/xgboost.ai) as well.\n- The follow-up notebook can be found at [Models | Perth Housing Price Prediction](https:\/\/www.kaggle.com\/shtrausslearning\/models-perth-housing-price-prediction\/)\n\n### <b><span style='color:#2779d2'>1.2<\/span> | PERTH HOUSING DATASET<\/b>\n\nAs far as [Perth Housing Dataset](https:\/\/www.kaggle.com\/syuzai\/perth-house-prices) goes, the current dataset is relatively extensive from an informative point of view, we would probably benefit from some form of <b>geotagging<\/b> especially if we had <code>address<\/code> coordinates, however we will limit outselves to <b>suburb<\/b> locations only, which will be extracted from a separate dataset.","6969fb54":"- We can that after 2014, there was a sudden drop in prebuilt properties. Our data also seems to be lacking properties built after 2016, despite containing sold data. \n- It might also be interesting to create separate models for <b>prebuilt<\/b> & non <b>prebuilt properties<\/b> on top of a general model, as they tend to be in a category of their own.","9bf9cd56":"#### <b><span style='color:#2779d2'>EDA - FEATURE IMPORTANCES<\/span><\/b>\n\n- We can use various <b>feature importance<\/b> approaches, including (<b>SHAP<\/b> values (with <b>CatBoost<\/b>), <b>RandomForest()<\/b> Feature Importance, <b>XGB<\/b> Feature Importance & <b>KBest<\/b> ) to get a quick idea of which features are quite influential in our models.\n- Interstingly enough, other <b>feature importance<\/b> methods also evaluated garage as a less impactful feature, we can see also see that <code>long<\/code> (longitudinal coodinates) is quite impactful in <b>XGB<\/b> & <b>CAT<\/b> models."}}