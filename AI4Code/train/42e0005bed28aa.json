{"cell_type":{"ef44fd13":"code","357fdebd":"code","e1853ace":"code","9f2d1a98":"code","1ce9d7bc":"code","bc2a8f29":"code","c55b5a00":"code","74ac01ba":"code","e17f8fd3":"code","824375f5":"code","951c55df":"code","a5282a86":"code","5bc81c2d":"code","9653a5d4":"code","3fb4a4f3":"code","dade5088":"code","2fc7e2f6":"code","87c961ba":"code","49938ac5":"code","b3434308":"code","1de4b0fe":"code","c3a550ab":"code","ff1dd74d":"code","37e2f8fc":"code","df615773":"code","89f569f3":"code","b45464d3":"code","82f24ed9":"code","a5eb1746":"code","2cddc409":"code","e88b7262":"code","d72cb008":"code","581fc0e1":"code","6417a847":"code","5c2b7c42":"code","d482c6f6":"code","600e3bdb":"markdown","2ffb12d1":"markdown","8d817ef4":"markdown","22ed4c9b":"markdown","b7cb4e00":"markdown","9b924fc6":"markdown","46f6ddf1":"markdown","24104660":"markdown","3fc70205":"markdown"},"source":{"ef44fd13":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\nimport random\nimport pickle\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","357fdebd":"df = pd.read_csv(\"..\/input\/ocular-disease-recognition-odir5k\/full_df.csv\")\ndf.head()","e1853ace":"def has_cataract(text):\n    if \"cataract\" in text:\n        return 1\n    else:\n        return 0","9f2d1a98":"df[\"left_cataract\"] = df[\"Left-Diagnostic Keywords\"].apply(lambda x: has_cataract(x))\ndf[\"right_cataract\"] = df[\"Right-Diagnostic Keywords\"].apply(lambda x: has_cataract(x))","1ce9d7bc":"df[\"right_cataract\"][1:5]","bc2a8f29":"left_cataract = df.loc[(df.C ==1) & (df.left_cataract == 1)][\"Left-Fundus\"].values","c55b5a00":"right_cataract = df.loc[(df.C ==1) & (df.right_cataract == 1)][\"Right-Fundus\"].values\nright_cataract[:15]","74ac01ba":"print(\"Number of images in left cataract: {}\".format(len(left_cataract)))\nprint(\"Number of images in right cataract: {}\".format(len(right_cataract)))","e17f8fd3":"left_normal = df.loc[(df.C ==0) & (df[\"Left-Diagnostic Keywords\"] == \"normal fundus\")][\"Left-Fundus\"].sample(250,random_state=42).values\nright_normal = df.loc[(df.C ==0) & (df[\"Right-Diagnostic Keywords\"] == \"normal fundus\")][\"Right-Fundus\"].sample(250,random_state=42).values\nright_normal[:15]","824375f5":"cataract = np.concatenate((left_cataract,right_cataract),axis=0)\nnormal = np.concatenate((left_normal,right_normal),axis=0)","951c55df":"print(len(cataract),len(normal))","a5282a86":"from tensorflow.keras.preprocessing.image import load_img,img_to_array\ndataset_dir = \"..\/input\/ocular-disease-recognition-odir5k\/preprocessed_images\"\nimage_size=224\nlabels = []\ndataset = []\ndef create_dataset(image_category,label):\n    for img in tqdm(image_category):\n        image_path = os.path.join(dataset_dir,img)\n        try:\n            image = cv2.imread(image_path,cv2.IMREAD_COLOR)\n            image = cv2.resize(image,(image_size,image_size))\n\n        except:\n            continue\n        \n        dataset.append([np.array(image),np.array(label)])\n    random.shuffle(dataset)\n    return dataset\n        ","5bc81c2d":"dataset = create_dataset(cataract,1)","9653a5d4":"dataset = create_dataset(normal,0)","3fb4a4f3":"len(dataset)","dade5088":"plt.figure(figsize=(12,7))\nfor i in range(10):\n    sample = random.choice(range(len(dataset)))\n    image = dataset[sample][0]\n    category = dataset[sample][1]\n    if category== 0:\n        label = \"Normal\"\n    else:\n        label = \"Cataract\"\n    plt.subplot(2,5,i+1)\n    plt.imshow(image)\n    plt.xlabel(label)\nplt.tight_layout()    ","2fc7e2f6":"x = np.array([i[0] for i in dataset]).reshape(-1,image_size,image_size,3)\ny = np.array([i[1] for i in dataset])","87c961ba":"x.shape","49938ac5":"x[1][223][223][0]","b3434308":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)","1de4b0fe":"from tensorflow.keras.applications.vgg19 import VGG19\nvgg = VGG19(weights=\"imagenet\",include_top = False,input_shape=(image_size,image_size,3))","c3a550ab":"for layer in vgg.layers:\n    layer.trainable = False","ff1dd74d":"from tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Flatten,Dense\nmodel = Sequential()\nmodel.add(vgg)\nmodel.add(Flatten())\nmodel.add(Dense(1,activation=\"sigmoid\"))","37e2f8fc":"model.summary()","df615773":"model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])","89f569f3":"from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\ncheckpoint = ModelCheckpoint(\"vgg19.h5\",monitor=\"val_acc\",verbose=1,save_best_only=True,\n                             save_weights_only=False,period=1)\nearlystop = EarlyStopping(monitor=\"val_acc\",patience=5,verbose=1)","b45464d3":"history = model.fit(x_train,y_train,batch_size=32,epochs=1,validation_data=(x_test,y_test),\n                    verbose=1,callbacks=[checkpoint,earlystop])","82f24ed9":"loss,accuracy = model.evaluate(x_test,y_test)\nprint(\"loss:\",loss)\nprint(\"Accuracy:\",accuracy)","a5eb1746":"from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\ny_pred = model.predict_classes(x_test)","2cddc409":"accuracy_score(y_test,y_pred)","e88b7262":"print(classification_report(y_test,y_pred))","d72cb008":"from mlxtend.plotting import plot_confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\nplot_confusion_matrix(conf_mat = cm,figsize=(8,7),class_names = [\"Normal\",\"Cataract\"],\n                      show_normed = True);","581fc0e1":"plt.figure(figsize=(12,7))\nfor i in range(10):\n    sample = random.choice(range(len(x_test)))\n    image = x_test[sample]\n    category = y_test[sample]\n    pred_category = y_pred[sample]\n    \n    if category== 0:\n        label = \"Normal\"\n    else:\n        label = \"Cataract\"\n        \n    if pred_category== 0:\n        pred_label = \"Normal\"\n    else:\n        pred_label = \"Cataract\"\n        \n    plt.subplot(2,5,i+1)\n    plt.imshow(image)\n    plt.xlabel(\"Actual:{}\\nPrediction:{}\".format(label,pred_label))\nplt.tight_layout() ","6417a847":"model.save(\"my_model\")\n","5c2b7c42":"model.save('models\/medical_trial_model.h5')","d482c6f6":"import tensorflow as tf\ntf.keras.models.save_model(model,'model_final.hdf5')","600e3bdb":"# Accuracy Metrics","2ffb12d1":">Normal Images","8d817ef4":"><h3>Dividing dataset into x(features) & y(target)<\/h3>","22ed4c9b":"><h3>Prediction:<\/h3>","b7cb4e00":"><h3>Creating Dataset from images<\/h3>","9b924fc6":"---\n\n\n<center><h1 class=\"list-group-item list-group-item-success\">Cataract Prediction<\/center>\n\n---","46f6ddf1":"# Description\nOcular Disease Intelligent Recognition (ODIR) is a structured ophthalmic database of 5,000 patients with age, color fundus photographs from left and right eyes and doctors' diagnostic keywords from doctors.\n\nThis dataset is meant to represent \u2018\u2018real-life\u2019\u2019 set of patient information collected by Shanggong Medical Technology Co., Ltd. from different hospitals\/medical centers in China. In these institutions, fundus images are captured by various cameras in the market, such as Canon, Zeiss and Kowa, resulting into varied image resolutions.\nAnnotations were labeled by trained human readers with quality control management. They classify patient into two labels:\n\n<li>Normal (N)<\/li><br>\n<li>Cataract (C)<\/li>\n","24104660":"# Creating Model","3fc70205":"> <h3> Extracting Cataract & Normal information from the Dataset <\/h3>"}}