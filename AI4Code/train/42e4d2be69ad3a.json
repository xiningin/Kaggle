{"cell_type":{"f9907393":"code","61c48858":"code","c9de2934":"code","2a286412":"code","a99585df":"code","ae53babe":"code","39a110b7":"code","ed4db202":"code","e3aa1361":"code","f23080cc":"code","694aa374":"code","403f5fd1":"code","35e95cb4":"code","051f9f29":"code","49f0c1b6":"code","e7aedb9e":"code","5f732256":"code","cbd3c0e4":"code","c49661da":"code","cb836ded":"code","7f585d20":"code","eb0f2de0":"code","5eac00b4":"code","bddd21b2":"code","0e02b1d3":"code","240fcec2":"code","4fa6b3e7":"code","2cb24a16":"code","400a3dbb":"markdown","17e544f1":"markdown","07e0b429":"markdown","c903478c":"markdown","5c9f304e":"markdown","ac1355ee":"markdown","95d370b5":"markdown","4ee23caa":"markdown","25e0170d":"markdown","adb6efbd":"markdown","458a318d":"markdown","66942e51":"markdown","5ab77583":"markdown","337d72f7":"markdown","6664ca49":"markdown","a6d51ce3":"markdown","eaae5c28":"markdown","e7441e88":"markdown","a57f0b59":"markdown","80b08f3b":"markdown","ffb49a09":"markdown","903969b1":"markdown"},"source":{"f9907393":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","61c48858":"import numpy as np \nimport cv2\nimport os\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport seaborn as sns\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n%matplotlib inline","c9de2934":"benign_train = '\/kaggle\/input\/skin-cancer-malignant-vs-benign\/train\/benign\/'\nmalignant_train = '\/kaggle\/input\/skin-cancer-malignant-vs-benign\/train\/malignant\/'\n\nbenign_test = '\/kaggle\/input\/skin-cancer-malignant-vs-benign\/test\/benign\/'\nmalignant_test = '\/kaggle\/input\/skin-cancer-malignant-vs-benign\/test\/malignant\/'\n\n\nread = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\"))\nims_benign = [read(os.path.join(benign_train, filename)) for filename in os.listdir(benign_train)]\nX_benign = np.array(ims_benign, dtype='uint8')\nims_malignant = [read(os.path.join(malignant_train, filename)) for filename in os.listdir(malignant_train)]\nX_malignant = np.array(ims_malignant, dtype='uint8')\n\nims_benign = [read(os.path.join(benign_test, filename)) for filename in os.listdir(benign_test)]\nX_benign_test = np.array(ims_benign, dtype='uint8')\nims_malignant = [read(os.path.join(malignant_test, filename)) for filename in os.listdir(malignant_test)]\nX_malignant_test = np.array(ims_malignant, dtype='uint8')\n","2a286412":"y_benign = np.zeros(X_benign.shape[0])\ny_malignant = np.ones(X_malignant.shape[0])\ny_benign_test = np.zeros(X_benign_test.shape[0])\ny_malignant_test = np.ones(X_malignant_test.shape[0])","a99585df":"X_train = np.concatenate((X_benign, X_malignant), axis = 0)\ny_train = np.concatenate((y_benign, y_malignant), axis = 0)\n\nX_test = np.concatenate((X_benign_test, X_malignant_test), axis = 0)\ny_test = np.concatenate((y_benign_test, y_malignant_test), axis = 0)\n","ae53babe":"s = np.arange(X_train.shape[0])\nnp.random.shuffle(s)\nX_train = X_train[s]\ny_train = y_train[s]\n\ns = np.arange(X_test.shape[0])\nnp.random.shuffle(s)\nX_test = X_test[s]\ny_test = y_test[s]\n","39a110b7":"w=30\nh=30\nfig=plt.figure(figsize=(12, 8))\ncolumns = 5\nrows = 2\n\nfor i in range(1, columns*rows +1):\n    ax = fig.add_subplot(rows, columns, i)\n    if y_train[i] == 0:\n        ax.title.set_text('Benign')\n    else:\n        ax.title.set_text('Malignant')\n    plt.imshow(X_train[i], interpolation='nearest')\nplt.show()\n\n\n","ed4db202":"blue,green,red = cv2.split(X_train[i])\nprint(blue,green,red)\n","e3aa1361":"pca = PCA(10)\npca1=PCA(50)\npca2=PCA(200)\n \n#Applying to red channel and then applying inverse transform to transformed array.\nred_transformed = pca.fit_transform(red)\nred_inverted = pca.inverse_transform(red_transformed)\n\nred_transformed1 = pca1.fit_transform(red)\nred_inverted1 = pca1.inverse_transform(red_transformed1)\n\nred_transformed2 = pca2.fit_transform(red)\nred_inverted2 = pca2.inverse_transform(red_transformed2)\n\n \n#Applying to Green channel and then applying inverse transform to transformed array.\ngreen_transformed = pca.fit_transform(green)\ngreen_inverted = pca.inverse_transform(green_transformed)\n \ngreen_transformed1 = pca1.fit_transform(green)\ngreen_inverted1 = pca1.inverse_transform(green_transformed1)\n\ngreen_transformed2 = pca2.fit_transform(green)\ngreen_inverted2 = pca2.inverse_transform(green_transformed2)\n \n#Applying to Blue channel and then applying inverse transform to transformed array.\nblue_transformed = pca.fit_transform(blue)\nblue_inverted = pca.inverse_transform(blue_transformed)\n\nblue_transformed1 = pca1.fit_transform(blue)\nblue_inverted1 = pca1.inverse_transform(blue_transformed1)\n\nblue_transformed2 = pca2.fit_transform(blue)\nblue_inverted2 = pca2.inverse_transform(blue_transformed2)","f23080cc":"img_compressed = (np.dstack((red_inverted, red_inverted, red_inverted))).astype(np.uint8)\nimg_compressed1 = (np.dstack((red_inverted1, red_inverted1, red_inverted1))).astype(np.uint8)\nimg_compressed2 = (np.dstack((red_inverted2, red_inverted2, red_inverted2))).astype(np.uint8)","694aa374":"fig=plt.figure(figsize=(14, 10))\nplt.subplot(2,3,1)\nplt.imshow(img_compressed)\nplt.subplot(2,3,2)\nplt.imshow(img_compressed1)\nplt.subplot(2,3,3)\nplt.imshow(img_compressed2)","403f5fd1":"print(X_train.shape)\nprint(X_train.size)\nprint(len(X_train))\n","35e95cb4":"from tensorflow.keras.utils import to_categorical\n\ny_train=to_categorical(\n    y_train, num_classes=2, dtype='float32'\n)\ny_test=to_categorical(\n    y_test, num_classes=2, dtype='float32'\n)\n","051f9f29":"import numpy as np\nX_train = X_train\/ 255\nX_test = X_test\/ 255\n","49f0c1b6":"import keras\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, ReLU, BatchNormalization, Dropout, Dense, InputLayer, Flatten\nfrom keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom keras import regularizers","e7aedb9e":"    model = Sequential()\n    model.add(Conv2D(32, kernel_size=(3, 3),padding = 'Same',input_shape=(224,224,3),\n                     activation= \"sigmoid\", kernel_initializer='he_uniform'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size = (2, 2)))\n \n    model.add(Dropout(0.3))\n\n   \n    model.add(Conv2D(64, kernel_size=(3, 3),padding = 'Same', \n                     activation =\"sigmoid\", kernel_initializer = 'he_uniform'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size = (2, 2)))\n  \n    model.add(Dropout(0.3))\n\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(2, activation='softmax'))\n    model.compile(loss= BinaryCrossentropy(),optimizer=Adam(0.001), metrics=['accuracy'])","5f732256":"model.summary()","cbd3c0e4":"tf.keras.utils.plot_model(\n    model, to_file='model.png', show_shapes=True,\n    show_layer_names=True,\n)","c49661da":"from keras import utils, callbacks\nearlystopping = callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", \n                                        patience=5, restore_best_weights = True)","cb836ded":"history = model.fit(X_train,y_train,verbose=1,epochs=10,callbacks = [earlystopping],validation_split=0.2)","7f585d20":"plt.figure(figsize=(15,5))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='loss')\nplt.plot(history.history['val_loss'], label = 'val_loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')\n","eb0f2de0":"print(\"Loss of the model is - \" , model.evaluate(X_test,y_test)[0])\nprint(\"Accuracy of the model is - \" , model.evaluate(X_test,y_test)[1]*100 , \"%\")","5eac00b4":"from keras.models import load_model\nmodel.save('skincancer.h5')","bddd21b2":"from sklearn.metrics import confusion_matrix\nY_pred=model.predict(X_test) \nY_pred=np.argmax(Y_pred, axis=1)\ny_test=np.argmax(y_test, axis=1)\ncm = confusion_matrix(y_test, Y_pred)\nprint(cm)","0e02b1d3":"from sklearn.metrics import classification_report,confusion_matrix\nprint(classification_report(y_test, Y_pred, target_names = ['Benign (Class 0)','Malignant(Class 1)']))","240fcec2":"correct = np.nonzero(Y_pred == y_test)[0]\nincorrect = np.nonzero(Y_pred != y_test)[0]","4fa6b3e7":"i = 0\nfor c in correct[:6]:\n    plt.subplot(3,2,i+1)\n    plt.imshow(X_test[c].reshape(224,672), cmap=\"gray\", interpolation='none')\n    plt.title(\"Predicted Class {},Actual Class {}\".format(Y_pred[c], y_test[c]))\n    plt.tight_layout()\n    i +=1\n    ","2cb24a16":"i = 0\nfor c in incorrect[:6]:\n    plt.subplot(3,2,i+1)\n    plt.imshow(X_test[c].reshape(224,672), cmap=\"gray\", interpolation='none')\n    plt.title(\"Predicted Class {},Actual Class {}\".format(Y_pred[c], y_test[c]))\n    plt.tight_layout()\n    i += 1","400a3dbb":"**Model plot**","17e544f1":"**Principal Component Analysis for Image Data Compression**\n\n**Splitting the Image in R,G,B Arrays**\n\n*As we know a digital colored image is a combination of R, G, and B arrays stacked over each other. Therefore,splitting each channel from the image and extracting principal components from each of them.*","07e0b429":"**Creating labels**","c903478c":"**Data merging**","5c9f304e":"**Some of the correctly predicted class**","ac1355ee":"**Conclusion:** Output image got clearer by increasing the number of principal components. ","95d370b5":"**Importing necessary libraries**","4ee23caa":"**INTRODUCTION**","25e0170d":"**Compressing the image**\n\n*Inverse Transformation is necessary to recreate the original dimensions of the base image.*","adb6efbd":"In deep learning, a convolutional neural network (CNN\/ConvNet) is a class of deep neural networks, most commonly applied to analyze visual imagery.\nSimilar to the Convolutional Layer, the Pooling layer is responsible for reducing the spatial size of the Convolved Feature. This is to decrease the computational power required to process the data through dimensionality reduction.\n\nThere are two types of Pooling: Max Pooling and Average Pooling. \nMax Pooling returns the maximum value from the portion of the image covered by the Kernel. On the other hand, Average Pooling returns the average of all the values from the portion of the image covered by the Kernel.\n\nAdding a Fully-Connected layer is a (usually) cheap way of learning non-linear combinations of the high-level features as represented by the output of the convolutional layer. Over a series of epochs, the model is able to distinguish between dominating and certain low-level features in images and classify them using the Softmax Classification technique.\nHere, I used the Binary cross entropy, which compares each of the predicted probabilities to actual class output which can be either 0 or 1. \n\nDropouts are the regularization technique that is used to prevent overfitting in the model. Dropouts are added to randomly switching some percentage of neurons of the network.It is always good to only switch off the neurons to 50%. If we switched off more than 50% then there can be chances when the model leaning would be poor and the predictions will not be good.\n\nA batch normalization layer looks at each batch as it comes in, first normalizing the batch with its own mean and standard deviation, and then also putting the data on a new scale with two trainable rescaling parameters. Batchnorm, in effect, performs a kind of coordinated rescaling of its inputs.","458a318d":"**Training the model**","66942e51":"**Some of the incorrectly predicted class**","5ab77583":"**Applying PCA to each array**","337d72f7":"*Too many epochs can lead to overfitting of the training dataset, whereas too few may result in an underfit model. Early stopping is a method that allows you to specify an arbitrary large number of training epochs and stop training once the model performance stops improving on a hold out validation dataset.*","6664ca49":"**Data shuffling**","a6d51ce3":"**Loading pictures and reading multiple RGB images to numpy array**","eaae5c28":"**Categorical labels**","e7441e88":"**Viewing the compressed image**","a57f0b59":"**Plotting accuracy and loss**","80b08f3b":"Skin cancer is an abnormal growth of skin cells. It generally develops in areas that are exposed to the sun, but it can also form in places that don\u2019t normally get sun exposure.\nThe two main categories of skin cancers are defined by the cells involved.\nBasal and squamous cell carcinomas are the two most common types of skin cancer. They begin in the basal and squamous layers of the skin, respectively. Melanoma, the third most common type of skin cancer, begins in the melanocytes.\n\nGoal: To create a model, which can classify a mole visually into benign and malignant using Convolutional Neural Network.\n","ffb49a09":"**Displaying first 10 images of moles**","903969b1":"**Pixel Normalization:** Scaling pixel values to the range 0-1."}}