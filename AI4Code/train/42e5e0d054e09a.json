{"cell_type":{"1180c799":"code","c1d0d2a0":"code","c19211af":"code","fecee9c2":"code","8b0da5d0":"code","40b8d55e":"code","bf9f4f9e":"code","3f00a435":"code","031394ae":"code","75e1b5d4":"code","b2a33068":"code","7ca424c5":"code","9243e5c3":"markdown","f070e66c":"markdown","9ee3ec9b":"markdown","f178f199":"markdown","038307be":"markdown","7d05d692":"markdown","fa66ba2a":"markdown","2b7ed635":"markdown","35207a3d":"markdown","4f5810bb":"markdown","0df4158c":"markdown"},"source":{"1180c799":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c1d0d2a0":"filepath = \"..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv\"\ndata = pd.read_csv(filepath)\ndata.shape\ndata.head()","c19211af":"data.isnull().sum()","fecee9c2":"idx_death = (data['DEATH_EVENT']==1)\nidx_live = (data['DEATH_EVENT']==0)\ndata[idx_death]\n\nage_norm = (data['age'] - np.mean(data['age']))\/np.std(data['age'])\nserum_creatinine = (data['serum_creatinine']-np.mean(data['serum_creatinine']))\/np.std(data['serum_creatinine'])\nplt.figure(figsize=(10,6))\nsns.regplot(x=age_norm,y=data['DEATH_EVENT'],label=\"age\")\nplt.ylabel(\"death events\")\nplt.legend()\n\n","8b0da5d0":"plt.figure(figsize=(12,12))\nsns.heatmap(data=data.corr(),annot=True)\ndata.columns","40b8d55e":"plt.figure(figsize=(8,8))\nsns.barplot(x=data['sex'],y=data['smoking'])\nplt.ylabel(\"Smoking\")","bf9f4f9e":"from sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\n\ndata2 = data.drop(['DEATH_EVENT'],axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(\n                data2, data['DEATH_EVENT'], stratify=data['DEATH_EVENT'], random_state=0)\ntree = DecisionTreeClassifier(max_depth=4,random_state=0)\ntree.fit(X_train, y_train)\nprint(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train))) \nprint(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))\n","3f00a435":"#Plotting the scores with diferrent max depth\n\nn = 12\ntraining_score = np.zeros(n)\ntesting_score = np.zeros(n)\ndiff_score = np.zeros(n)\nfor i in range(1,n):\n    tree = DecisionTreeClassifier(max_depth=i,random_state=0)\n    tree.fit(X_train, y_train)\n    training_score[i]= tree.score(X_train, y_train)\n    testing_score[i] = tree.score(X_test, y_test)\n    diff_score[i] = np.abs(training_score[i]-testing_score[i])\n    \n    \nplt.figure(figsize=(8,5))    \nsns.lineplot(x=range(n),y=training_score,label=\"training score\")\nsns.lineplot(x=range(n),y=testing_score,label=\"testing score\")\nplt.ylabel(\"Testing Score\")\nplt.xlabel(\"Maximum depth\")\nplt.legend()","031394ae":"tree = DecisionTreeClassifier(max_depth=4,random_state=0)\ntree.fit(X_train, y_train)","75e1b5d4":"feature_names =['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes',\n       'ejection_fraction', 'high_blood_pressure', 'platelets',\n       'serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'time']","b2a33068":"from sklearn.tree import export_graphviz\n\nexport_graphviz(tree, out_file=\"tree.dot\", class_names=[\"live\", \"deceased\"],\n            feature_names=feature_names, impurity=False, filled=True)\n\nimport graphviz\nwith open(\"tree.dot\") as f: \n    dot_graph = f.read()\n      \ngraphviz.Source(dot_graph)","7ca424c5":"print(\"Feature importances:\\n{}\".format(tree.feature_importances_))","9243e5c3":"<font size=4>There is a positive correlation as expected.<\/font>","f070e66c":"#### Seeing if there's any empty entries.","9ee3ec9b":"#### there is none.\n***","f178f199":"## Visualizing the procedure of our decision tree","038307be":"<font size=4>Quite a discepancy in female and male ratio of smokers<\/font>","7d05d692":"### the features that exhibit some form of importance are creatinine phosphokinase, ejection fraction, serum sodium and time. ","fa66ba2a":"<font size=\"5\">Regression Line of Age and Death<\/font>","2b7ed635":"## Loading our data. \n\n> ###  Displaying the first five rows.","35207a3d":"At maxdepth of 4, the difference between training score and testing score is the least. And subsequently they diverge.","4f5810bb":"<font size=3> Let's see whether there is any other correlation between the other variables. <\/font>","0df4158c":"<br>"}}