{"cell_type":{"c1840ab4":"code","5ca64717":"code","65783a36":"code","cdc3b159":"code","8df90734":"code","ab3d0a3f":"code","a5d34da7":"code","1f392210":"code","ed071e51":"code","2dd807ee":"code","dbd363ed":"code","9b86765a":"code","e78ee74f":"code","8694edc0":"code","94c6fbfa":"code","9c3aa1c5":"code","148c554a":"code","42922604":"code","3830cb0c":"code","d65d802a":"markdown","6e324a49":"markdown"},"source":{"c1840ab4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5ca64717":"from keras.models import Sequential, load_model\nfrom keras.layers import Dense, Conv2D, MaxPool2D, Dropout, Flatten\nfrom keras import backend as K\n\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\nfrom keras.preprocessing.image import ImageDataGenerator\n# graph\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\n","65783a36":"modelpath='.\/digit.h5'\n","cdc3b159":"SEED=1234\ndef seed_All():\n    np.random.seed(SEED)\n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    config = tf.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n    tf.set_random_seed(SEED)\n    sess = tf.Session(graph=tf.get_default_graph(), config=config)\n    K.set_session(sess)\nseed_All()","8df90734":"dftrain = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ndftest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","ab3d0a3f":"dftrain.head()\n# pixel 784\n# label.\ny_org = dftrain['label'].values\nx_org = dftrain.iloc[:,1:].values\nx_test = dftest.values","a5d34da7":"print(y_org.shape, x_org.shape, x_test.shape)","1f392210":"sns.countplot(y_org)","ed071e51":"# pd.Series(x_org.flatten()).value_counts()\n# pd.Series(x_org[0]).value_counts()","2dd807ee":"x_org = dftrain.iloc[:,1:].values \/ 255.0\nx_test = dftest.values \/ 255.0\n# reshape\nx_org = x_org.reshape(-1, 28, 28, 1)\nx_test = x_test.reshape(-1, 28, 28, 1)\n# one-hot encoding\ny_org = to_categorical(dftrain['label'].values, num_classes=10)","dbd363ed":"# split\nx_train, x_val, y_train, y_val = train_test_split(x_org, y_org, test_size=0.1)\nprint(x_train.shape, y_train.shape, x_val.shape, y_val.shape)","9b86765a":"plt.figure()\nfor i in range(4):\n    ix = random.randint(0, len(x_train))\n    plt.subplot(1,4,i+1)\n    plt.title( str(np.argmax(y_train[ix])))\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(x_train[ix].reshape(28,28), cmap='gray')\nplt.show()\n","e78ee74f":"model = Sequential()\nmodel.add( Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same', input_shape=(28,28,1)))\nmodel.add( Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'))\nmodel.add( MaxPool2D(pool_size=(2,2)))\nmodel.add( Dropout(0.25))\n\nmodel.add( Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))\nmodel.add( Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))\nmodel.add( MaxPool2D(pool_size=(2,2)))\nmodel.add( Dropout(0.25))\n\nmodel.add( Flatten())\nmodel.add( Dense(256, activation='relu'))\nmodel.add( Dropout(0.25))\nmodel.add( Dense(10, activation='softmax'))\n\n\nmodel.summary()","8694edc0":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n\nlrr = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=5, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\nckpt = ModelCheckpoint(modelpath, monitor='val_acc', verbose=1, save_best_only=True)\nes = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\ncallbacklist = [lrr, ckpt, es]","94c6fbfa":"# ref : https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n","9c3aa1c5":"datagen.fit(x_train)\n\nif os.path.exists(modelpath):\n    print('load model')\n    model = load_model(modelpath)","148c554a":"epochs=100\nbatch_size=50\n\nhistory = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (x_val,y_val),\n                              verbose = 1, steps_per_epoch=x_train.shape[0] \/\/ batch_size\n                              , callbacks=callbacklist)","42922604":"if os.path.exists(modelpath):\n    print('load model')\n    model = load_model(modelpath) # use best model.","3830cb0c":"results = model.predict(x_test)\nresults = np.argmax(results, axis=1)\nresults = pd.Series(results, name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"cnn_mnist_datagen.csv\",index=False)\n","d65d802a":"## Normalization","6e324a49":"# Train"}}