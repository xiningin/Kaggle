{"cell_type":{"a4280b32":"code","d4d8206e":"code","b16d32fd":"code","3fcb208b":"code","b8b08416":"code","98888f30":"code","3265031e":"code","f78daa09":"code","6fba9c60":"code","6ede94fb":"code","aca65eb7":"markdown","05948a3f":"markdown","1dbe706a":"markdown","e97039a6":"markdown","249fce43":"markdown","05fdd670":"markdown","2c9ee12e":"markdown"},"source":{"a4280b32":"from __future__ import print_function, division\n\nfrom keras.datasets import mnist\nfrom keras.layers import Input, Dense, Reshape, Flatten, Dropout, Bidirectional, LSTM, Reshape, RepeatVector, TimeDistributed\nfrom keras.layers import BatchNormalization, Activation\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers.convolutional import UpSampling2D, Conv2D\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam\n\nimport matplotlib.pyplot as plt\n\nimport sys\n\nimport numpy as np\n\nimport os\n\nfrom PIL import Image","d4d8206e":"def load_data():\n    x_train = np.load(r'..\/input\/blues-genre-midi-melodies\/answers.npy',allow_pickle=True)\n    x_train = x_train.reshape(721,4,4)\n    return x_train","b16d32fd":"class LSTMGAN():\n    def __init__(self):\n        # Input shape\n        self.img_rows = 4\n        self.img_cols = 4\n        self.img_shape = (self.img_rows, self.img_cols)\n        self.latent_dim = 16\n\n        optimizer = Adam(0.0001, 0.4)\n\n        # Build and compile the discriminator\n        self.discriminator = self.build_discriminator()\n        self.discriminator.compile(loss='binary_crossentropy',\n            optimizer=optimizer,\n            metrics=['accuracy'])\n\n        # Build the generator\n        self.generator = self.build_generator()\n\n        # The generator takes noise as input and generates song\n        z = Input(shape=(4,4))\n        img = self.generator(z)\n\n        # For the combined model we will only train the generator\n        self.discriminator.trainable = False\n\n        # The discriminator takes generated images as input and determines validity\n        valid = self.discriminator(img)\n\n        # The combined model  (stacked generator and discriminator)\n        # Trains the generator to fool the discriminator\n        self.combined = Model(z, valid)\n        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n\n    def build_generator(self):\n\n        model = Sequential()\n        model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(4, 4)))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Bidirectional(LSTM(128, return_sequences=True)))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Bidirectional(LSTM(128)))\n        model.add(LeakyReLU(alpha=0.2))\n        #specifying output to have 40 timesteps\n        model.add(RepeatVector(16))\n        #specifying 1 feature as the output\n        model.add(Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2)))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2)))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2)))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.3))   \n        model.add(TimeDistributed(Dense(128)))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.4))\n        model.add(TimeDistributed(Dense(128)))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.4))\n        model.add(TimeDistributed(Dense(1)))\n        model.add(LeakyReLU(alpha=0.2))\n        model.summary()\n\n        noise = Input(shape=(4,4))\n        img = model(noise)\n\n        return Model(noise, img)\n\n    def build_discriminator(self):\n\n        model = Sequential()\n\n        model.add(Bidirectional(LSTM(128, activation = 'relu', return_sequences=True), input_shape=(16, 1)))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Bidirectional(LSTM(128, activation = 'relu')))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.4))\n        model.add(RepeatVector(1))\n        model.add(TimeDistributed(Dense(128, activation = 'sigmoid')))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.4))\n        model.add(TimeDistributed(Dense(128, activation = 'relu')))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.4))\n        model.add(TimeDistributed(Dense(1, activation = 'linear')))\n        model.summary()\n\n        img = Input(shape=(16,1))\n        validity = model(img)\n\n        return Model(img, validity)\n    \n\n    def train(self, epochs, batch_size=128, save_interval=50):\n\n        # Load the dataset\n        X_train = load_data()\n\n        # Rescale 0 to 1\n        X_train = X_train \/ 128\n\n        # Adversarial ground truths\n        valid = np.ones((batch_size,1,1))\n        fake = np.zeros((batch_size,1,1))\n\n        for epoch in range(epochs):\n\n            # ---------------------\n            #  Train Discriminator\n            # ---------------------\n\n            # Select a random half of songs\n            idx = np.random.randint(0, X_train.shape[0], batch_size)\n            imgs = X_train[idx]\n            imgs = np.array(imgs)\n            imgs = imgs.reshape(len(imgs),16,1)\n\n            # Sample noise and generate a batch of new songs\n            noise = np.random.normal(0, 1, (batch_size,4,4))\n            gen_imgs = self.generator.predict(noise)\n\n            # Train the discriminator (real classified as ones and generated as zeros)\n            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n            # ---------------------\n            #  Train Generator\n            # ---------------------\n\n            # Train the generator (wants discriminator to mistake songs as real)\n            g_loss = self.combined.train_on_batch(noise, valid)\n\n            # Plot the progress\n            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n\n            # If at save interval => save model\n            if epoch % save_interval == 0:\n                self.generator.save(\"LSTM_generator.h5\")","3fcb208b":"lstmgan = LSTMGAN()\n#lstmgan.train(epochs=1000, batch_size=20, save_interval=100)","b8b08416":"from keras.models import load_model\nmodel = load_model(r'..\/input\/bilstm-gan\/LSTM_generator.h5')","98888f30":"!pip install mido","3265031e":"import mido # easy to use python MIDI library\nfrom mido import MidiFile, MidiTrack, Message","f78daa09":"random = np.random.normal(0,1,(1,4,4))\n\npredict = model.predict(random)\n\n#adjusting for normalization\npredict = predict * 128","6fba9c60":"print(predict)","6ede94fb":"midler = MidiFile()\ntrack = MidiTrack()\nmidler.tracks.append(track)\ntrack.append(Message('program_change', program=2, time=0))\nfor x in range(16):\n    track.append(Message('note_on', note=int(predict[0][x][0]), velocity=64, time=20))\n    track.append(Message('note_off', note=int(predict[0][x][0]), velocity=64, time=20))\n    midler.save('new_song.mid')","aca65eb7":"Installinging Mido Library","05948a3f":"# Back to MIDI\nSave generated melody back to a .mid file","1dbe706a":"# Creating GAN","e97039a6":"# Model Summary\nI couldn't train the model on this online notebook so I trained it locally for 1000 epochs and uploaded the h5 file.","249fce43":"# Load Data\nLoading from preprocessed numpy array","05fdd670":"# Generating Melody\nGenerating random input and letting model predict output","2c9ee12e":"Loading pretrained model"}}