{"cell_type":{"0ae9bdd0":"code","7b9d8bbe":"code","cfda3281":"code","8159e711":"code","4ff5b515":"code","2ef5b3ec":"code","e97a364c":"code","a09bf050":"code","c51aac00":"code","c418b730":"markdown"},"source":{"0ae9bdd0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","7b9d8bbe":"from sklearn.svm import SVC\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.decomposition import PCA\nfrom matplotlib import pyplot as plt","cfda3281":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\n\nY = train[\"label\"]\nX = train.drop(labels = [\"label\"], axis = 1) \nX_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.3)\nX_test = test","8159e711":"covar_matrix = PCA()\nscaler = StandardScaler()\nX_new = covar_matrix.fit_transform(scaler.fit_transform(X))\n\n# Percentage of variance explained by each of the selected components.\nvariance_ratio = covar_matrix.explained_variance_ratio_\ncumulative_var_ratio = np.cumsum(np.round(variance_ratio, decimals=2))","4ff5b515":"%matplotlib inline\nplt.ylabel('% Variance Explained')\nplt.xlabel('# of Features')\nplt.title('PCA Analysis')\nplt.plot(cumulative_var_ratio)","2ef5b3ec":"# Pipeline with: StandardScaler | PCA with n_components set to 50, quadratic SVM\nmodel = SVC(kernel='poly', degree=2, C=1.0, gamma='scale', coef0=1.0)\ncovar_matrix = PCA(n_components=50)\n\npipeline = Pipeline(steps=[\n        ('scale', StandardScaler()),\n        ('reduce_dim', covar_matrix),\n        #('preprocessor', preprocessor),\n        ('model', model)])","e97a364c":"# pipeline.fit -> scale | reduce_dim| preprocess | fit\npipeline.fit(X_train, Y_train)\n\n#n_features_to_test = np.arange(1, 11)\n#params = {'reduce_dim__n_components': n_features_to_test}\n#gridsearch = GridSearchCV(pipeline, params, cv=3, verbose=1).fit(X_train, Y_train)\n#print('Final score is: ', gridsearch.score(X_val, Y_val))\n\n# pipeline.score ->  scale | preprocess | predict | score\nprint('Final score with 50 scaled features: ', pipeline.score(X_val, Y_val))","a09bf050":"# pipeline.predict -> scale | reduce_dim| preprocess | predict\npreds_test = pipeline.predict(X_test)","c51aac00":"# Save test predictions to file\noutput = pd.DataFrame({'ImageId': X_test.index+1,\n                       'Label': preds_test})\noutput.to_csv('submission.csv', index=False)","c418b730":"# SVM for handwritten digit classification"}}