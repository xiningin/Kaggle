{"cell_type":{"d36d0968":"code","d118e2fc":"code","2a81d99d":"code","84c3191f":"code","325bfa38":"code","91014140":"code","398883d4":"code","5b8da902":"code","33cb8b2d":"code","2ae1646f":"code","6786c5f0":"code","0f727dc1":"code","1b1f7c16":"code","29fffd06":"code","10f8ec9f":"code","20da48d7":"code","c6cc15a7":"code","a783fb58":"code","fa592235":"code","d15ef837":"code","11016017":"code","4ea98c77":"code","c8177d94":"code","14b473c3":"code","e9ef5a56":"markdown","7ef92864":"markdown"},"source":{"d36d0968":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport PIL\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport random\nfrom tqdm import tqdm\nimport tensorflow_addons as tfa\nimport random\nfrom sklearn.preprocessing import MultiLabelBinarizer\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, smart_resize\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\nfrom keras.constraints import maxnorm\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam\nimport cv2\nfrom PIL import Image\nfrom keras.preprocessing.image import load_img, img_to_array\nfrom keras.models import load_model\nfrom keras.metrics import AUC\nfrom tqdm.auto import tqdm\nsns.set_style('darkgrid')\npd.set_option(\"display.max_columns\", None)","d118e2fc":"train_dir= '..\/input\/resized-plant2021\/img_sz_384'\ntest_dir =  '..\/input\/plant-pathology-2021-fgvc8\/test_images'\ntrain = pd.read_csv('..\/input\/plant-pathology-2021-fgvc8\/train.csv')","2a81d99d":"train['labels'] = train['labels'].apply(lambda string: string.split(' '))","84c3191f":"s = list(train['labels'])\nmlb = MultiLabelBinarizer()\ntrainx = pd.DataFrame(mlb.fit_transform(s), columns=mlb.classes_, index=train.index)\nprint(trainx.columns)","325bfa38":"labels = pd.concat([train['image'], trainx], axis=1)\nlabels.head()","91014140":"image_datagen = ImageDataGenerator(\n    rescale=1\/255.0,\n    rotation_range=5,\n    zoom_range=0.1,\n    shear_range=0.05,\n    horizontal_flip=True,\n    validation_split=0.1\n    \n)\nIMAGE = (256, 256)\nBATCH_SIZE = 64","398883d4":"train_data = image_datagen.flow_from_dataframe(\n    dataframe=labels,\n    directory= '..\/input\/resized-plant2021\/img_sz_512',\n    x_col=\"image\",\n    y_col=labels.columns.tolist()[1:],\n    color_mode=\"rgb\",\n    target_size = IMAGE,\n    class_mode=\"raw\",\n    subset = \"training\",\n    batch_size=BATCH_SIZE\n)\n\ntest_data = image_datagen.flow_from_dataframe(\n    dataframe=labels,\n    directory= '..\/input\/resized-plant2021\/img_sz_512',\n    x_col=\"image\",\n    y_col=labels.columns.tolist()[1:],\n    color_mode=\"rgb\",\n    target_size = IMAGE,\n    class_mode=\"raw\",\n    subset = \"validation\",\n    batch_size=BATCH_SIZE\n)","5b8da902":"inputs = tf.keras.Input(shape=(256, 256, 3))\nx = tf.keras.applications.MobileNetV2(include_top=False)(inputs)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\noutputs = tf.keras.layers.Dense(6, activation='sigmoid')(x)\n\nmodel = tf.keras.models.Model(inputs, outputs)\nmodel.summary()\ntf.keras.utils.plot_model(model, show_shapes=True)","33cb8b2d":"model.compile(loss='binary_crossentropy', \n              optimizer=tf.keras.optimizers.Adam(lr=1e-4),\n              metrics=[\"accuracy\"])","2ae1646f":"rlp = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n                                           mode='min',\n                                           patience=2, \n                                           verbose=0, \n                                           factor=0.01)\nearlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n                                             patience=5, \n                                             verbose=1, \n                                             restore_best_weights=True)\ncallbacks=[rlp,earlystop]","6786c5f0":"model_history = model.fit(train_data, \n                          validation_data=test_data, \n                          validation_steps = test_data.n \/\/ BATCH_SIZE,\n                          epochs=30, \n                          callbacks=callbacks)","0f727dc1":"fix, ax = plt.subplots(figsize=(20, 6))\npd.DataFrame(model_history.history)[['loss', 'val_loss']].plot(ax=ax, title='Model Loss Curve')","1b1f7c16":"model.save('mobilenetv2image512.h5')","29fffd06":"from sklearn.metrics import classification_report","10f8ec9f":"submissions = pd.read_csv('..\/input\/plant-pathology-2021-fgvc8\/sample_submission.csv')\nsubmissions.head()","20da48d7":"test_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255)\n\ntest_generator = test_data_generator.flow_from_dataframe(\n    submissions,\n    directory = '..\/input\/plant-pathology-2021-fgvc8\/test_images',\n    x_col=\"image\",\n    y_col=None,\n    target_size=(256, 256),\n    color_mode=\"rgb\",\n    classes=None,\n    class_mode=None,\n    shuffle=False,\n    batch_size=32\n)\n\npredictions = model.predict(test_generator)","c6cc15a7":"verdict = (predictions>0.25)","a783fb58":"for x in verdict:\n    count = 0\n    for i in range(len(x)):\n        if x[i]==False:\n            count=count+1\n    if count==len(x):\n        x[2]=True","fa592235":"for x in verdict:\n    if x[2]:\n        for i in range(len(x)):\n            x[i]=False\n        x[2]=True","d15ef837":"label = labels.columns.tolist()[1:]\nlabel","11016017":"pred_lists = []\nfor i in range(verdict.shape[0]):\n    tmp = []\n    for j, c in enumerate(label):\n        if verdict[i, j]:\n            tmp.append(c)\n    pred_lists.append(tmp)\n\npred_lists = [' '.join(t) for t in pred_lists]\npred_lists","4ea98c77":"submissions['labels'] = np.array(pred_lists)","c8177d94":"submissions","14b473c3":"submissions.to_csv('submission.csv', index=False)  ","e9ef5a56":"# Modeling","7ef92864":"# Submission"}}