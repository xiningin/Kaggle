{"cell_type":{"abf01f6b":"code","d7589c49":"code","93adb0a6":"code","4429829e":"code","517f7fe2":"code","8a2aa87f":"code","e060ac13":"code","1bdd9b57":"code","68091ffd":"code","970a2d38":"code","77fd490f":"code","320591dd":"code","602db853":"code","6e9ff867":"code","8c388ed6":"code","1a40694c":"code","fa136c4a":"code","28022d1d":"markdown","e59d073b":"markdown","c919663c":"markdown","d0a056b1":"markdown","b311e5a2":"markdown","242cf399":"markdown","6d19656c":"markdown","9a6ef020":"markdown","6fcc2643":"markdown","cbc15340":"markdown","5a7b2287":"markdown","6995172d":"markdown","22789951":"markdown","767b74f9":"markdown","582c6729":"markdown","e253c90c":"markdown","c63cdab9":"markdown","f25b1a6b":"markdown","49f0b86a":"markdown","3cfd7fb8":"markdown","4a530326":"markdown","8ff387bc":"markdown","79264a97":"markdown","c934b9b6":"markdown","b9d6424b":"markdown","c2373109":"markdown","1187ee44":"markdown","b92e97c5":"markdown","416c01c5":"markdown","1e17367b":"markdown","9e3153a6":"markdown","8b9d16ca":"markdown","83cb3c87":"markdown","b229cf48":"markdown","2ef9927b":"markdown","f64b25c5":"markdown"},"source":{"abf01f6b":"!git clone https:\/\/github.com\/tkeldenich\/PyTorch_Load_Image_FromRepository.git &> \/dev\/null","d7589c49":"import torchvision\n\ntsr_img =  torchvision.io.read_image('\/content\/PyTorch_Load_Image_FromRepository\/data\/image-dog\/bobby.jpg')\ntsr_img.shape","93adb0a6":"import matplotlib.pyplot as plt\n\nplt.imshow(tsr_img.permute((1,2,0)))","4429829e":"import imageio\n\nimg_arr = imageio.imread('\/content\/PyTorch_Load_Image_FromRepository\/data\/image-dog\/bobby.jpg')\nimg_arr.shape","517f7fe2":"import matplotlib.pyplot as plt\n\nplt.imshow(img_arr)","8a2aa87f":"import os\n\ndata_dir = '\/content\/PyTorch_Load_Image_FromRepository\/data\/image-cats\/'\n\nfilenames = [name for name in os.listdir(data_dir) if os.path.splitext(name)[-1] == '.png']","e060ac13":"import torch\n\nbatch_size = len(filenames)\nbatch = torch.zeros(batch_size, 3, 256, 256, dtype=torch.uint8)","1bdd9b57":"for i, filename in enumerate(filenames):\n  batch[i] = torchvision.io.read_image(os.path.join(data_dir, filename))","68091ffd":"import matplotlib.pyplot as plt\n\nfig = plt.figure(figsize=(8, 2))\nfor i in range(batch.shape[0]) :\n  ax = fig.add_subplot(1, 3, i+1)\n  ax.imshow(batch[i].permute(1, 2, 0))","970a2d38":"import matplotlib.pyplot as plt\n\nplt.imshow(batch[0].permute(1, 2, 0))","77fd490f":"batch = batch.float()\n\nn_images = batch.shape[1]\n\nfor c in range(n_images):\n  mean = torch.mean(batch[:, c])\n  std = torch.std(batch[:, c])\n  batch[:, c] = (batch[:, c] - mean) \/ std","320591dd":"import imageio\n\ndir_path = \"\/content\/PyTorch_Load_Image_FromRepository\/data\/volumetric-dicom\/2-LUNG 3.0  B70f-04083\"\nvol_arr = imageio.volread(dir_path, 'DICOM')","602db853":"vol_arr.shape","6e9ff867":"vol = torch.from_numpy(vol_arr)\nvol = vol.float()","8c388ed6":"vol = torch.unsqueeze(vol, 0)\nvol.shape","1a40694c":"plt.imshow(vol[0,10])","fa136c4a":"import matplotlib.pyplot as plt\n\nfig = plt.figure(figsize=(20, 4))\nfor i in range(6) :\n  ax = fig.add_subplot(1, 6, i+1)\n  ax.imshow(vol[0, i+i*10])","28022d1d":"**Note :** if we are sure that **all the files in our folder are images** we can write :\n\n```\nfilenames = [name for name in os.listdir(data_dir)]\n```","e59d073b":"# **Easy PyTorch to load image and volume from folder**\n\n- [read the article (in English)](https:\/\/inside-machinelearning.com\/en\/easy-pytorch-to-load-image-and-volume-from-folder\/)\n- [read the article (in French)](https:\/\/inside-machinelearning.com\/charger-rapidement-des-images-depuis-un-dossier-avec-pytorch\/)","c919663c":"**To realize Deep Learning** it may be interesting **to normalize the data.**\n\nIn fact, Artificial Intelligence researchers have found that **neural networks perform better** when the input data is in **float format** but also when the data is **between 0 and 1**, or **between -1 and 1**.\n\nTherefore, we usually **convert our tensors** to the scale of **0 to 1** or **-1 to 1**, this is called **normalisation**.\n\nEn fait les chercheurs en Intelligence Artificielle se sont aper\u00e7us que les r\u00e9seaux de neurones affichent de meilleures performancesd\u2019apprentissage lorsque les donn\u00e9es d\u2019entr\u00e9e sont d\u2019une part au format float (chiffres \u00e0 virgules) mais aussi lorsque les donn\u00e9es sont comprises entre 0 et 1, ou entre -1 et 1.\n\nOne possibility is to simply **divide** the values of each **pixel** in our image **by 255** (the maximum number representable in 8-bit):\n\n```\nbatch = batch.float()\nbatch \/= 255.0\n```\n\nWith this method, our pixels will be **between 0 and 1**.\n\nThe other possibility, -1 and 1, consists of subtracting from each pixel **the mean** and dividing by **the standard deviation**, this on **each image**.\n\nThis allows us **to modify the scale** so that the modified pixels have **a mean of 0** and **a standard deviation of 1** :","d0a056b1":"We may also **load images** using the *imageio* **library**.\n\nIn fact this library is not related to **PyTorch** but it will be **useful for some types of images**\u2026 that\u2019s what we will see later in this article.\n\nInstead of creating a tensor, *imageio* **creates an array**.\n\nThe difference between a tensor and an array is **in the way the data is stored in memory**.\n\nWe use the *imread()* function **to read an image** :","b311e5a2":"#### **Load image with torchvision tensor**","242cf399":"In order for PyTorch to understand that **our set of images actually represents a 3D image** we need to add a dimension.\n\nWe will then have **four dimensions :**\n\n- width\n- height\n- number of DICOM images\n- number of volumetric images","6d19656c":"## **2D Image \u2013 RGB Image**","9a6ef020":"We will therefore load **a volume sample of a lung** obtained by CAT-scan or CT scan.\n\nThis **volume** is located in the folder *\u201cvolumetric-dicom\/2-LUNG 3.0 B70f-04083\u201d*. The directory contains **a set of images in DICOM** (Digital Imaging and Communications in Medicine) format, which is **standard format** for computer management of data from **medical imaging**.\n\n**The combination of all** these DICOM images is **the volume**.","6fcc2643":"We may **load image** with *torchvision*. As the name suggests, it is **a sub-library of PyTorch**.\n\nThis **package** contains several things like :\n- **datasets**\n- **model architectures**\n- **functions to read and transform** images and videos\n- and many more\u2026\n\nIn fact this package is the **Computer Vision part of PyTorch !**\n\nFeel free to [read the documentation](https:\/\/pytorch.org\/vision\/stable\/index.html) for **more information** \ud83d\ude09","cbc15340":"Here, as explained in the previous section, **the dimensions of the image are** [720, 1280, 3].\n\nWe can therefore **directly display the image** with matplotlib without applying any transformation !","5a7b2287":"## **3D image \u2013 Volume**","6995172d":"We\u2019 ve learned to load and **represent 2D images**, **the most common images** taken with **cameras**.\n\nIn some contexts, however, such as in medicine with **medical imaging**, we are dealing with 3D images.\n\nThis **type of image** is called a **volume**.\n\nThe image consists of a **sequence of 2D** slices that represent the object being analysed (usually **the human body** or **an organ**).\n\nEach slice is represented by **an image**, a matrix of pixels (X and Y coordinates). The Z coordinate indicates **the number of the slice**.\n\nIn fact these 3D images are **sequences of images**. Each of the sequences corresponds to **a slice of the human body**.\n\nThey are called **3D images** because they provide **a 3-dimensional view of the human body**.","22789951":"### **What is medical imagery ?**","767b74f9":"We have **99 images** with height and width **512\u00d7512 pixels**.\n\nThen, we can easily transform this array into a PyTorch tensor with *from_numpy()*.\n\nWe then **transform the pixels of this tensor** into *float()* for more convenience in future transformations.","582c6729":"**To load this volume** we use a very specific function, volread() from the *imageio* **library**.","e253c90c":"#### **Normalizing the data**","c63cdab9":"It is **interesting** to note that **the shape of the image** is [3, 720, 1280] whereas in most **image formats on Python** we would have had a shape [720, 1280, 3].\n\n3 representing **the colour** dimension, 720 **the width** and 1280 **the height**.\n\nIf we want **to display our image** with matplotlib we need **to transform the image format** from [3, 720, 1280] to [720, 1280, 3].\n\nTo do this we use the *permute()* function which allows us **to move the dimensions of a tensor.**\n\nOnce this is done we could **display our image :**","f25b1a6b":"Or **display a single image :**","49f0b86a":"We can **display one of the images :**","3cfd7fb8":"#### **Storing data**","4a530326":"**For this tutorial** we will use a dataset provided by the authors of *Deep Learning with PyTorch*.\n\nThis dataset is composed of **various datasets** distributed in different directories.\n\n**First** we load the dataset from [GitHub](https:\/\/github.com\/tkeldenich\/PyTorch_Load_Image_FromRepository) :","8ff387bc":"Once our dataset is loaded, we have **two options to retrieve the images** in Python :\n\n- directly in **PyTorch tensor** format\n- via an array, for example **NumPy array**","79264a97":"In this notebook, we\u2019ll explore *PyTorch* **library** to easily **load image and volume** from folder.\n\nThere are **many different types of images** in IT and at least **as many different ways to load them.**\n\nHere we will focus on **the most common types**, photographs, and then **explore medical images**\u2026 a bit more complex than the first ones.\n\nFor this we will use **two complementary libraries :**\n- *PyTorch*\n- *imageio*","c934b9b6":"#### **Retrieving data**","b9d6424b":"It may be interesting **to store several images in the same variable**, particularly for [Deep Learning](https:\/\/inside-machinelearning.com\/le-deep-learning-cest-quoi\/).\n\n**This type of variable** containing several images in the form of a tensor is called **a batch.**\n\nWe can **create a batch** using the *stack()* function.\n\nTo do so, we need **to read the images in tensor format** and then use the *stack()* function on all the tensors created.\n\nThis will look like :\n\n```\ntsr_img1 = torchvision.io.read_image('image1.jpg')\ntsr_img2 = torchvision.io.read_image('image2.jpg')\n...\ntsr_img100 = torchvision.io.read_image('image100.jpg')\n\nbatch = torch.stack([tsr_img1, tsr_img2, ..., tsr_img100])\n```\n\n**A more convenient method** to avoid writing 50 lines of repetitive code is **to store all the PNG images directly in a single tensor.**\n\nTo do this we import the *os* **library** which will allow us to interact with our files.\n\nWe indicate **the path of the folder** where our images are located in *data_dir*.\n\nThen we recover **the name of all the files** ending in \u201c.png\u201d, the images thus :","c2373109":"We can then **display the images** by browsing **our batch tensor :**\n","1187ee44":"### **Two ways to upload image**","b92e97c5":"Once we have **the name of each image**, we need to create an empty tensor.\n\nIn fact **this empty tensor** will contain all our images. It\u2019s **a batch of images**.\n\nThe only thing to do is to give it **an appropriate format to contain our images**.\n\nHere we have **four dimensions :**\n\n- **Number of images** to add to the batch (called batch_size)\n- **Image colours** (here we have 3 colours: red, green, blue)\n- **Width** (256)\n- **Height** (256)\n\nWe will use *zeros()* to create an **\u201cempty\u201d tensor** (filled only with zero), which gives us :","416c01c5":"### **Storing multiple images in a variable**","1e17367b":"#### **Load image with imageio array**","9e3153a6":"**Note :**\n\n- We will have **a batch of 3 images** (batch_size = 3) in fact we took the total number of images contained in the folder thanks to *len(filename)*\n- the tensor will contain **8-bit integer** (as in most of the photographic formats of standard consumer cameras), we specify dtype=torch.uint8\n\nOnce the empty tensor is created, **it must be filled up !**\n\nWe therefore create a *for* **loop** which allows us **to add each of the images** to the batch tensor.","8b9d16ca":"### **Using medical images**","83cb3c87":"**Did you notice ?** Both libraries contain \u201c**io**\u201c.\n\n- *torchvision.io.read_image*\n- *imageio*\n\nThis actually means that they apply **IO operations**. These are operations that allow you **to manage input and output streams.**\n\nio is the default module for handling **these types of streams in Python 3.**\n\nI\/O stands for \u201c**Input\/Output**\u201c.","b229cf48":"Or **display various ones :**","2ef9927b":"Torchvision is **separate from the PyTorch library** so you don\u2019t even need to import *torch*, only *torchvision*.\n\nWe use the *torchvision.io.read_image()* function **to load our image into a tensor :**","f64b25c5":"We can check **the dimensions of our volume** using *shape()* :"}}