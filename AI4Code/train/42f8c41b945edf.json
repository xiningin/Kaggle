{"cell_type":{"fca0a550":"code","d52da189":"code","f193d609":"code","1d477533":"code","6aabff34":"code","6219bee7":"code","0d0bd30b":"code","65872d05":"code","dc8080db":"code","431a873a":"code","388dc175":"code","d9ab00d7":"code","d550c8d2":"code","fe0b66fd":"code","4dd9f549":"code","ca861b09":"code","1ee70c49":"code","0c3704cf":"code","bb925f23":"code","71989b3f":"code","d2965ffc":"code","038855a1":"code","7df3f31a":"code","cf743c3c":"code","42c6e0ae":"code","e23d7c2e":"code","1af8a4d2":"code","4ceaa9c9":"markdown","de8b712b":"markdown","e193bc85":"markdown","ba4d62ca":"markdown","f1323c47":"markdown","a4b31c4e":"markdown","c82e2606":"markdown","1dc9307a":"markdown","d11f1208":"markdown","365d628a":"markdown","21138021":"markdown","9b6f3223":"markdown"},"source":{"fca0a550":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d52da189":"df = pd.read_csv('\/kaggle\/input\/mydataset\/IRIS.csv')\ndf_copy = pd.read_csv('\/kaggle\/input\/mydataset\/IRIS.csv')\n\ndf","f193d609":"from sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\ndf['species'] = label_encoder.fit_transform(df['species'])\ndf","1d477533":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","6aabff34":"tf.__version__","6219bee7":"df_val = df.sample(frac=0.2,random_state=1)\ndf_train = df.drop(df_val.index)\n####################################\nprint(df_val.shape)\nprint(df_train.shape)","0d0bd30b":"# A utility method to create a tf.data dataset from a Pandas Dataframe\ndef df_to_dataset(dataframe, target, shuffle=True, batch_size=10):\n  dataframe = dataframe.copy()\n  labels = dataframe.pop(target)\n  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n  if shuffle:\n    ds = ds.shuffle(buffer_size=len(dataframe))\n  ds = ds.batch(batch_size)\n  return ds","65872d05":"train_ds = df_to_dataset(df_train,'species')\nval_ds = df_to_dataset(df_val,'species')","dc8080db":"for b in train_ds.take(1):\n    print(b)","431a873a":"from tensorflow import feature_column\n\nfeature_columns = []\n# numeric cols\nfor col in df.columns:\n  if col == 'species':\n    continue\n  feature_columns.append(feature_column.numeric_column(col, dtype=tf.float16)) \nfeature_columns","388dc175":"model = tf.keras.models.Sequential()","d9ab00d7":"model.add(tf.keras.layers.DenseFeatures(feature_columns))\nmodel.add(tf.keras.layers.Dense(32,activation='relu'))\nmodel.add(tf.keras.layers.Dense(3,activation='softmax'))","d550c8d2":"#tf.keras.losses.binary_crossentropy\nmodel.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])","fe0b66fd":"model.evaluate(val_ds)","4dd9f549":"model.fit(train_ds,validation_data=val_ds,epochs=100)","ca861b09":"model.evaluate(val_ds)","1ee70c49":"model.summary()","0c3704cf":"#pred = model.predict(val_ds)[:10]\npred = model.predict(val_ds)","bb925f23":"#for i in pred:\n #   print(np.argmax(i))\nprediction = np.argmax(pred,axis=1)\nprediction","71989b3f":"len(prediction)","d2965ffc":"df.columns","038855a1":"new_data = {\n    'sepal_length': [5.0],\n    'sepal_width': [1.2], \n    'petal_length': [3.5],\n    'petal_width': [0.7]\n}\nnew_data","7df3f31a":"input_dict = {name: tf.convert_to_tensor([value]) for name, value in new_data.items()}\ninput_dict","cf743c3c":"pred_example = model.predict(input_dict)\nvaluIs = np.argmax(pred_example)","42c6e0ae":"df_copy['species'].unique()","e23d7c2e":"result = ['Iris-setosa','Iris-versicolor','Iris-virginica']","1af8a4d2":"result[valuIs]","4ceaa9c9":"# Get pridictions as 0,1,2 ","de8b712b":"# split data into train and val","e193bc85":"# convert dataframe to tensor data","ba4d62ca":"# Evaluate before training (evalute on random wieghts)","f1323c47":"# * Info...\n## 160 -> layers.Dense 32 * feature_columns 4 + 32 bais for all neuron\n## 99 -> 32 * 3 + 3","a4b31c4e":"# Train the model using fit fucntion","c82e2606":"# predict a new example...","1dc9307a":"# Convert to input dictionary","d11f1208":"# Get predict","365d628a":"# compile model\n1. optimizer\n1. loss\n1. metircs","21138021":"# prepare input layer","9b6f3223":"# Define model"}}