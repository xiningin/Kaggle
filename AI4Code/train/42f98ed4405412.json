{"cell_type":{"6e13cae8":"code","1a472174":"code","d4389f54":"code","4fd0bb2f":"code","93c0a1fa":"code","3c0d1a63":"code","ae877b43":"code","279cf866":"code","1300155a":"code","c95b3fe2":"code","dbb549dc":"code","c4eb2780":"code","e162ef0c":"code","3b39a112":"code","bad9a238":"code","81d90176":"code","365d9bbc":"code","7335ba68":"markdown","fbef9d54":"markdown","6cf67b6a":"markdown","636e4498":"markdown","a08e8017":"markdown","9daecb22":"markdown","85423f3f":"markdown","e2b901c0":"markdown","4a428531":"markdown","3e0c8d21":"markdown","46ab32b6":"markdown","cabbc94e":"markdown","62e95211":"markdown","5b8e9b5e":"markdown","856a7748":"markdown","dd6e27df":"markdown"},"source":{"6e13cae8":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Input,Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport transformers\nfrom transformers import TFAutoModel, AutoTokenizer\nfrom sklearn.model_selection import StratifiedKFold\nplt.style.use('fivethirtyeight')\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os","1a472174":"path=\"..\/input\/contradictory-my-dear-watson\"\nos.listdir(path)\n","d4389f54":"df_train=pd.read_csv(os.path.join(path,\"train.csv\"))\ndf_test=pd.read_csv(os.path.join(path,\"test.csv\"))","4fd0bb2f":"print('there are {} rows and {} columns in the train'.format(df_train.shape[0],df_train.shape[1]))\nprint('there are {} rows and {} columns in the test'.format(df_test.shape[0],df_test.shape[1]))","93c0a1fa":"df_train.head(3)","3c0d1a63":"\nplt.figure(figsize=(10,5))\nplt.subplot(1,2,1)\nx=df_train.language.value_counts()\nsns.barplot(x.index,x.values)\nplt.gca().set_xticklabels(x.index,rotation='45')\n\nplt.subplot(1,2,2)\nx=df_test.language.value_counts()\nsns.barplot(x.index,x.values)\nplt.gca().set_xticklabels(x.index,rotation='45')\nplt.show()","ae877b43":"\nplt.figure(figsize=(7,5))\nx=df_train.label.value_counts()\nsns.barplot(x.index,x.values)\nplt.gca().set_xticklabels(x.index,rotation='45')","279cf866":"# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","1300155a":"MODEL = 'jplu\/tf-xlm-roberta-large'\nEPOCHS = 10\nMAX_LEN = 96\n\n# Our batch size will depend on number of replic\nBATCH_SIZE= 16 * strategy.num_replicas_in_sync\nAUTO = tf.data.experimental.AUTOTUNE\ntokenizer = AutoTokenizer.from_pretrained(MODEL)","c95b3fe2":"def quick_encode(df,maxlen=100):\n    \n    values = df[['premise','hypothesis']].values.tolist()\n    tokens=tokenizer.batch_encode_plus(values,max_length=maxlen,pad_to_max_length=True)\n    \n    return np.array(tokens['input_ids'])\n\nx_train = quick_encode(df_train)\nx_test = quick_encode(df_test)\ny_train = df_train.label.values\n    ","dbb549dc":"\n\ndef create_dist_dataset(X, y,val,batch_size= BATCH_SIZE):\n    \n    \n    dataset = tf.data.Dataset.from_tensor_slices((X,y)).shuffle(len(X))\n          \n    if not val:\n        dataset = dataset.repeat().batch(batch_size).prefetch(AUTO)\n    else:\n        dataset = dataset.batch(batch_size).prefetch(AUTO)\n\n    \n    \n    return dataset\n\n\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((x_test))\n    .batch(BATCH_SIZE)\n)\n","c4eb2780":"def build_model(transformer,max_len):\n    \n    input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n    sequence_output = transformer(input_ids)[0]\n    cls_token = sequence_output[:, 0, :]\n    cls_token = Dropout(0.4)(cls_token)\n    cls_token = Dense(32,activation='relu')(cls_token)\n    cls_token = Dropout(0.4)(cls_token)\n    out = Dense(3, activation='softmax')(cls_token)\n\n    # It's time to build and compile the model\n    model = Model(inputs=input_ids, outputs=out)\n    model.compile(\n        Adam(lr=1e-5), \n        loss='sparse_categorical_crossentropy', \n        metrics=['accuracy']\n    )\n    \n    return model\n","e162ef0c":"pred_test=np.zeros((df_test.shape[0],3))\nskf = StratifiedKFold(n_splits=5,shuffle=True,random_state=777)\nval_score=[]\nhistory=[]\n\n\nfor fold,(train_ind,valid_ind) in enumerate(skf.split(x_train,y_train)):\n    \n    if fold < 4:\n    \n        print(\"fold\",fold+1)\n        \n       \n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        \n        train_data = create_dist_dataset(x_train[train_ind],y_train[train_ind],val=False)\n        valid_data = create_dist_dataset(x_train[valid_ind],y_train[valid_ind],val=True)\n    \n        Checkpoint=tf.keras.callbacks.ModelCheckpoint(f\"roberta_base.h5\", monitor='val_loss', verbose=0, save_best_only=True,\n        save_weights_only=True, mode='min')\n        \n        with strategy.scope():\n            transformer_layer = TFAutoModel.from_pretrained(MODEL)\n            model = build_model(transformer_layer, max_len=MAX_LEN)\n            \n        \n\n        n_steps = len(train_ind)\/\/BATCH_SIZE\n        print(\"training model {} \".format(fold+1))\n\n        train_history = model.fit(\n        train_data,\n        steps_per_epoch=n_steps,\n        validation_data=valid_data,\n        epochs=EPOCHS,callbacks=[Checkpoint],verbose=1)\n        \n        print(\"Loading model...\")\n        model.load_weights(f\"roberta_base.h5\")\n        \n        \n\n        print(\"fold {} validation accuracy {}\".format(fold+1,np.mean(train_history.history['val_accuracy'])))\n        print(\"fold {} validation loss {}\".format(fold+1,np.mean(train_history.history['val_loss'])))\n        \n        history.append(train_history)\n\n        val_score.append(np.mean(train_history.history['val_accuracy']))\n        \n        print('predict on test....')\n        preds=model.predict(test_dataset,verbose=1)\n\n        pred_test+=preds\/4\n        ","3b39a112":"\nplt.figure(figsize=(15,10))\n\nfor i,hist in enumerate(history):\n\n    plt.subplot(2,2,i+1)\n    plt.plot(np.arange(EPOCHS),hist.history['accuracy'],label='train accu')\n    plt.plot(np.arange(EPOCHS),hist.history['val_accuracy'],label='validation acc')\n    plt.gca().title.set_text(f'Fold {i+1} accuracy curve')\n    plt.legend()\n\n\n    ","bad9a238":"\nplt.figure(figsize=(15,10))\n\nfor i,hist in enumerate(history):\n\n    plt.subplot(2,2,i+1)\n    plt.plot(np.arange(EPOCHS),hist.history['loss'],label='train loss')\n    plt.plot(np.arange(EPOCHS),hist.history['val_loss'],label='validation loss')\n    plt.gca().title.set_text(f'Fold {i+1} loss curve')\n    plt.legend()\n\n","81d90176":"submission = pd.read_csv(os.path.join(path,'sample_submission.csv'))\nsubmission['prediction'] = np.argmax(pred_test,axis=1)\nsubmission.head()","365d9bbc":"submission.to_csv('submission.csv',index=False)","7335ba68":"## <font size='4' color='blue'>Stratified Kfold<\/font>","fbef9d54":"- The majoity of both the train and test set is in English.\n- All other language samples are under 100 per language.","6cf67b6a":"## <font size='4' color='blue'>Dataset <\/font>","636e4498":"### <font size='3' color='blue'>Class distribution<\/font>\n","a08e8017":"## <font size='4' color='blue'>Submission<\/font>","9daecb22":"## <font size='4' color='blue'>Fast Encoder<\/font>","85423f3f":"- The distribution of targets seems to be almost equal.","e2b901c0":"## <font size='4' color='blue'>Import Important packages<\/font>","4a428531":"In this notebook, I just changed the network forked from XLM Kfold TPU:https:\/\/www.kaggle.com\/leoisleo1\/fork-from-contradiction-xlm-kfold-tpu\n","3e0c8d21":"### <font size='3' color='blue'>Language distribution<font>","46ab32b6":"## <font size='4' color='blue'>Model<\/font>","cabbc94e":"## <font size='4' color='blue'>TPU Config<\/font>","62e95211":"## <font size='4' color='blue'>Evaluation<\/font>","5b8e9b5e":"## <font size='4' color='red'>Work in Progress! Please upvote if you think this was helpful.<\/font>","856a7748":"## <font size='5' color='red'>Introduction<\/font>","dd6e27df":"## <font size='4' color='blue'>Getting Basic Idea<\/font>"}}