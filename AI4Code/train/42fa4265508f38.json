{"cell_type":{"466c67c6":"code","ec243e74":"code","517ccef7":"code","19197132":"code","73528277":"code","22da6d29":"code","591d3a35":"code","bf37c3fe":"code","4152192b":"code","9fb378ae":"code","b67c7272":"code","0aee5801":"code","5144cd6c":"code","0f8a05f2":"code","2a50f73b":"code","8e3ffc62":"code","8725c351":"code","b27dd2d4":"code","3dd4cc9f":"code","17199cc6":"code","7f0608f0":"code","b8344b6a":"code","1f942d09":"code","fdf436b2":"code","3709d8aa":"code","d5a072f0":"code","6102932a":"code","3b6271d2":"code","032838ee":"code","5c7eeb99":"code","3a49f04c":"code","7c2c2be0":"code","ae9665c2":"code","867ad8c3":"code","f55cf9d7":"code","ddd8f579":"code","0f6fde21":"code","23dbf628":"code","d2df6cda":"code","8e189881":"code","78c82891":"code","122e2f6a":"code","f90d07fe":"code","a81a1ea8":"code","c50c6695":"code","43e1e2d2":"code","2bb2afba":"code","6bad063b":"code","61debce2":"code","e5fc6d65":"code","c7ac2eba":"code","c04bd39b":"code","ae41fb13":"code","96dd80e7":"code","a3379c14":"code","c8e95ef6":"code","497c63e2":"code","4f31f106":"code","cec3dd7b":"code","ec30312c":"code","87c64112":"code","f49b0cb8":"code","16ed6c08":"code","d6fbd170":"code","77a1a28e":"code","5e48d713":"code","2995ace6":"code","8236c8a2":"code","b8d305fa":"code","ecccba56":"code","f74e158e":"code","03b8f84b":"code","9bacbe31":"code","872947df":"code","c6f6bd4e":"code","85272a4a":"markdown"},"source":{"466c67c6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","ec243e74":"import os, glob\nimport numpy as np\nimport pandas as pd\nimport math\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nimport cv2","517ccef7":"path = '..\/input\/chest_xray\/chest_xray'","19197132":"print (path)\nprint (os.listdir(path))\nprint (os.listdir('..\/input\/chest_xray\/chest_xray\/train'))","73528277":"train_path = path + '\/train\/'\ntest_path = path + '\/test\/'\nval_path = path + '\/val\/'","22da6d29":"norimg = glob.glob(train_path + 'NORMAL\/*.jpeg')","591d3a35":"train_datagen = ImageDataGenerator(rescale=1.\/255,\n                                   horizontal_flip=True)   #horizontal_flip \u5c07\u5716\u7247\u6c34\u5e73\u7ffb\u8f49","bf37c3fe":"train_generator = train_datagen.flow_from_directory(train_path,\n                                                    target_size=(224, 224),\n                                                    batch_size=128,\n                                                    class_mode='binary',\n                                                    seed=9)","4152192b":"train_generator.image_shape, train_generator.n, train_generator.batch_size","9fb378ae":"test_datagen = ImageDataGenerator(rescale=1.\/255)","b67c7272":"val_generator = test_datagen.flow_from_directory(val_path,\n                                                 target_size=(224, 224),\n                                                 batch_size=64,\n                                                 class_mode='binary',\n                                                 seed=9)","0aee5801":"test_generator = test_datagen.flow_from_directory(test_path,\n                                                  target_size=(224, 224),\n                                                  batch_size=64,\n                                                  class_mode='binary',\n                                                  shuffle=False,\n                                                  seed=9)","5144cd6c":"from keras.models import Sequential, Model\nfrom keras import regularizers\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, ZeroPadding2D\nfrom keras.optimizers import Adam, RMSprop, SGD\nfrom keras.callbacks import EarlyStopping, LearningRateScheduler","0f8a05f2":"model = Sequential()","2a50f73b":"model.add(Conv2D(filters=64,\n                 input_shape=train_generator.image_shape,\n                 kernel_size=(3, 3),\n                 padding='same',\n                 activation='relu'))","8e3ffc62":"model.add(Conv2D(filters=64,\n                 kernel_size=(3, 3),\n                 padding='same',\n                 activation='relu'))","8725c351":"model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))","b27dd2d4":"model.summary()","3dd4cc9f":"model.add(Conv2D(filters=128,\n                 kernel_size=(3, 3),\n                 padding='same',\n                 activation='relu'))","17199cc6":"model.add(Conv2D(filters=128,\n                 kernel_size=(3, 3),\n                 padding='same',\n                 activation='relu'))","7f0608f0":"model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))","b8344b6a":"model.summary()","1f942d09":"model.add(Conv2D(filters=256,\n                 kernel_size=(3, 3),\n                 padding='same',\n                 activation='relu'))","fdf436b2":"model.add(Conv2D(filters=256,\n                 kernel_size=(3, 3),\n                 padding='same',\n                 activation='relu'))","3709d8aa":"model.add(Conv2D(filters=256,\n                 kernel_size=(3, 3),\n                 padding='same',\n                 activation='relu'))","d5a072f0":"model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))","6102932a":"model.summary()","3b6271d2":"model.add(Conv2D(filters=512,\n                 kernel_size=(3, 3),\n                 padding='same',\n                 activation='relu'))","032838ee":"model.add(Conv2D(filters=512,\n                 kernel_size=(3, 3),\n                 padding='same',\n                 activation='relu'))","5c7eeb99":"model.add(Conv2D(filters=512,\n                 kernel_size=(3, 3),\n                 padding='same',\n                 activation='relu'))","3a49f04c":"model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))","7c2c2be0":"model.summary()","ae9665c2":"model.add(Conv2D(filters=512,\n                 kernel_size=(3, 3),\n                 padding='same',\n                 activation='relu'))","867ad8c3":"model.add(Conv2D(filters=512,\n                 kernel_size=(3, 3),\n                 padding='same',\n                 activation='relu'))","f55cf9d7":"model.add(Conv2D(filters=512,\n                 kernel_size=(3, 3),\n                 padding='same',\n                 activation='relu'))","ddd8f579":"model.add(MaxPooling2D(pool_size=(2, 2), strides=(2 ,2)))","0f6fde21":"model.summary()","23dbf628":"model.add(Flatten())","d2df6cda":"model.add(Dense(units=4096, kernel_regularizer=regularizers.l2(0.01), activation='relu'))","8e189881":"model.add(Dropout(rate=0.4))","78c82891":"model.add(Dense(units=4096, kernel_regularizer=regularizers.l2(0.01), activation='relu'))","122e2f6a":"model.add(Dropout(rate=0.4))","f90d07fe":"model.add(Dense(units=1000, kernel_regularizer=regularizers.l2(0.01), activation='relu'))","a81a1ea8":"model.add(Dense(units=1, activation='sigmoid'))","c50c6695":"model.summary()","43e1e2d2":"opt = Adam(lr=0.0001)","2bb2afba":"model.compile(loss='binary_crossentropy',\n              optimizer=opt, metrics=['acc'])","6bad063b":"callback = EarlyStopping(monitor='loss', patience=15, verbose=2, mode='auto', restore_best_weights=True)","61debce2":"train_history = model.fit_generator(train_generator,\n                                    steps_per_epoch=train_generator.n \/\/ train_generator.batch_size,\n                                    validation_data=val_generator,\n                                    validation_steps=32,\n                                    epochs=100, callbacks=[callback], verbose=2, shuffle=True)","e5fc6d65":"score = model.evaluate_generator(test_generator, steps=32)\nprint (score)","c7ac2eba":"plt.plot(train_history.history['loss'], label = 'loss')\nplt.plot(train_history.history['val_loss'], label = 'val_loss')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend()\nplt.show()","c04bd39b":"plt.plot(train_history.history['acc'], label = 'acc')\nplt.plot(train_history.history['val_acc'], label = 'val_acc')\nplt.xlabel('epoch')\nplt.ylabel('acc')\nplt.legend()\nplt.show()","ae41fb13":"def display_img_label_predict(img, label, predict, idx=0, num=10):\n    fig = plt.gcf()\n    fig.set_size_inches(12, 14)\n    if num > 25 :num = 25\n    for i in range(0, num):\n        ax = plt.subplot(5, 5, i+1)\n        read_img = cv2.imread(img[idx])\n        ax.imshow(read_img, cmap='binary')\n        title = 'Label=' + str(test_y[idx])\n        if len(predict) > 0:\n            title += ' Predict=' + str(predict[idx][0])\n        ax.set_title(title, fontsize=10)\n        ax.set_xticks([])\n        ax.set_yticks([])\n        idx += 1","96dd80e7":"label_dict = {0:'Normal', 1:'Pneumonia'}","a3379c14":"display_img_label_predict(test_data_path, test_y, prediction, 223, 25)","c8e95ef6":"test_nor = glob.glob(test_path + 'NORMAL\/*.jpeg')\ntest_pneumonia = glob.glob(test_path + 'PNEUMONIA\/*.jpeg')","497c63e2":"test_data_path = test_nor + test_pneumonia","4f31f106":"def img_preprocessing(img_data):\n    test_data = []\n    for i in range(len(img_data)):\n        read_img = cv2.imread(img_data[i])\n        resize_img = cv2.resize(read_img, (224, 224))\n        sc_img = resize_img.astype('float') \/ 255\n        test_data.append(np.asarray(sc_img))\n    return np.asarray(test_data)","cec3dd7b":"test_x = img_preprocessing(test_data_path)","ec30312c":"test_x.shape","87c64112":"test_y = ([0]*234+ [1]*390)\ntest_y = np.asarray(test_y)","f49b0cb8":"test_y.shape","16ed6c08":"def single_img_preprocessing(img_data):\n    read_img = cv2.imread(img_data)\n    resize_img = cv2.resize(read_img, (224, 224))\n    sc_img = resize_img.astype('float') \/ 255\n    return np.asarray(sc_img)","d6fbd170":"layer_outputs = [layer.output for layer in model.layers]\nactivation_model = Model(inputs=model.input, outputs=layer_outputs)\nactivation_predict = activation_model.predict(test_x[10].reshape(1, 224, 224, 3)) #activation_predict \u6703\u8fd4\u56de\u4e00\u500bList\u5305\u542b\u6a21\u578b\u7684\u5168\u90e8\u67b6\u69cb\u5171 23 \u5c64","77a1a28e":"def display_activation(activation_predict, rowsize, colsize, act_index):\n    activation = activation_predict[act_index] #act_index \u70ba\u9078\u64c7\u6a21\u578b\u7684\u7b2c\u5e7e\u5c64\n    filter_index = 0 #\u6b64\u70ba\u6ffe\u93e1\u6578\uff0c0\u70ba\u7b2c1\u500b\u6ffe\u93e1\n    fig, ax = plt.subplots(rowsize, colsize, figsize=(rowsize*2.5, colsize*1.5))\n    for row in range(0, rowsize):\n        for col in range(0, colsize):\n            ax[row][col].imshow(activation[0, :, :, filter_index])\n            ax[row][col].axis('off')\n            filter_index += 1","5e48d713":"cv2.imshow('Normal',test_x[10])","2995ace6":"display_activation(activation_predict, 4, 4, 15) #\u7b2c16\u5c64\u72c0\u6cc1","8236c8a2":"display_activation(activation_predict, 4, 4, 5) #\u7b2c6\u5c64\u72c0\u6cc1","b8d305fa":"act_2 = activation_predict[0]\nact_2.shape","ecccba56":"activation_predict[0][0][0][0]","f74e158e":"plt.plot(train_history.history['loss'], label='loss')\nplt.plot(train_history.history['val_loss'], label='val_loss')\nplt.xlabel('epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","03b8f84b":"plt.plot(train_history.history['acc'])\nplt.plot(train_history.history['val_acc'])\nplt.xlabel('epoch')\nplt.ylabel('Accuracy')\nplt.legend(['acc', 'val_acc'])\nplt.show()","9bacbe31":"model.layers","872947df":"type(model.input)","c6f6bd4e":"td_path = '..\/input\/chest_xray\/chest_xray\/test'\nimg_P = glob.glob(td_path + '\/PNEUMONIA\/*.jpeg')\nimg_N = glob.glob(td_path + '')","85272a4a":"[0.1809103893689238, 0.9471153846153846]"}}