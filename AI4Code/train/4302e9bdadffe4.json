{"cell_type":{"d5a08828":"code","65f08c38":"code","35c1cd53":"code","30d09a03":"code","f4713ae7":"code","9498350e":"code","b7fcd6c1":"code","e0ae4fbb":"code","b892e21f":"code","122f4956":"code","38a540e7":"code","5ee29c9c":"code","be9a47bb":"code","15c91c24":"code","a60c342b":"code","ed509a51":"code","600a150e":"code","b229748c":"code","9748cba3":"code","a4c1293a":"code","cf0984ad":"code","b9876632":"code","d51bf337":"code","c10196a4":"code","841f9501":"code","8ae5bf41":"code","6541d708":"code","16126023":"code","cedfd6c7":"code","ef5521e9":"code","dde4fd7f":"code","8da6db59":"code","a876a56d":"code","cda1f6f4":"code","bba7403c":"code","dcaf9f9b":"code","e1607edc":"code","413082ed":"code","3347bb75":"code","f2561050":"code","fcff862b":"code","d6b5eb52":"code","6df8ae22":"code","eb5e234c":"code","b9819c2e":"code","ebb8bc88":"markdown","91f62703":"markdown","73eab991":"markdown","ca3f7392":"markdown","b29ddc67":"markdown","fc2346d1":"markdown","3a43dbc9":"markdown","4a9dbb73":"markdown","df092da7":"markdown","1fdd71c7":"markdown","809aa319":"markdown","76750057":"markdown","fb1bcacc":"markdown","477e9a5c":"markdown","dff3acea":"markdown","963c123c":"markdown","041e2ec9":"markdown","4257e1ac":"markdown"},"source":{"d5a08828":"# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","65f08c38":"## Import data\ntrain_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')","35c1cd53":"# preview the data\ntrain_df.head()","30d09a03":"train_df.info()\nprint('_'*40)\ntest_df.info()","f4713ae7":"train_df.describe()","9498350e":"train_df.describe(include='O')","b7fcd6c1":"sns.countplot(x='Pclass', data=train_df)\nsns.factorplot('Pclass','Survived',order=[1,2,3], data=train_df, size=5)","e0ae4fbb":"train_df['Pclass'].value_counts()","b892e21f":"print (train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())","122f4956":"sns.countplot(x='Sex', data=train_df)","38a540e7":"train_df['Sex'].value_counts()","5ee29c9c":"sns.barplot(x='Sex', y='Survived', data=train_df)","be9a47bb":"print (train_df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean())","15c91c24":"## combine influence of sex and pclass\ng = sns.FacetGrid(train_df, col=\"Sex\")\ng = g.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')","a60c342b":"## Understand the age distribution of passengers.\ntrain_df['Age'].hist(bins=70)","ed509a51":"g = sns.FacetGrid(train_df, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","600a150e":"train_df['Parch'].value_counts()","b229748c":"train_df['SibSp'].value_counts()","9748cba3":"train_df['Family'] =  train_df[\"Parch\"] + train_df[\"SibSp\"]\ntrain_df['Family'].value_counts()","a4c1293a":"print (train_df[['Family', 'Survived']].groupby(['Family'], as_index=False).mean())","cf0984ad":"train_df['Fare'].plot(kind='hist', figsize=(15,3),bins=100)","b9876632":"train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\ntrain_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)","d51bf337":"train_df['Embarked'].value_counts()","c10196a4":"print (train_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean())","841f9501":"grid = sns.FacetGrid(train_df, col='Embarked', size=3, aspect=1.6)\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\ngrid.add_legend()","8ae5bf41":"## Drop unnecessary columns\n\ntrain_df = train_df.drop(['PassengerId','Name','Ticket','Cabin','FareBand'], axis=1)\ntest_df    = test_df.drop(['Name','Ticket','Cabin'], axis=1)","6541d708":"## Sex\n\n## Converting categorical feature Sex into numerical values where female = 1 and male = 0.\ntrain_df.loc[train_df['Sex']=='male','Sex'] = 0\ntrain_df.loc[train_df['Sex']=='female','Sex'] = 1\ntest_df.loc[test_df['Sex']=='male','Sex'] = 0\ntest_df.loc[test_df['Sex']=='female','Sex'] = 1","16126023":"## Age\n\n## generate random numbers between (mean - std) and (mean + std) to replace missing value.\n\naverage_age_train   = train_df[\"Age\"].mean()\nstd_age_train      = train_df[\"Age\"].std()\ncount_nan_age_train = train_df[\"Age\"].isnull().sum()\n\naverage_age_test   = test_df[\"Age\"].mean()\nstd_age_test       = test_df[\"Age\"].std()\ncount_nan_age_test = test_df[\"Age\"].isnull().sum()\n\nrand_1 = np.random.randint(average_age_train - std_age_train, average_age_train + std_age_train, size = count_nan_age_train)\nrand_2 = np.random.randint(average_age_test - std_age_test, average_age_test + std_age_test, size = count_nan_age_test)\n\ntrain_df[\"Age\"][np.isnan(train_df[\"Age\"])] = rand_1\ntest_df[\"Age\"][np.isnan(test_df[\"Age\"])] = rand_2\n\ntrain_df['Age'] = train_df['Age'].astype(int)\ntest_df['Age']    = test_df['Age'].astype(int)\n\n","cedfd6c7":"## Family\n\n## Use family feature to replace Parch and SibSp.\n\ntrain_df['Family'] =  train_df[\"Parch\"] + train_df[\"SibSp\"]\ntrain_df['Family'].loc[train_df['Family'] > 0] = 1\ntrain_df['Family'].loc[train_df['Family'] == 0] = 0\n\ntest_df['Family'] =  test_df[\"Parch\"] + test_df[\"SibSp\"]\ntest_df['Family'].loc[test_df['Family'] > 0] = 1\ntest_df['Family'].loc[test_df['Family'] == 0] = 0\n\ntrain_df = train_df.drop(['SibSp','Parch'], axis=1)\ntest_df    = test_df.drop(['SibSp','Parch'], axis=1)\n","ef5521e9":"## Embarked\n\n## Fill the missing values with the most common occurrence(S).\n\ntrain_df['Embarked'] = train_df['Embarked'].fillna('S')\n\n## Convert the Embarked feature by creating a new numeric feature.\n\ntrain_df['Embarked'] = train_df['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\ntest_df['Embarked'] = test_df['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\n","dde4fd7f":"## Fare \n\n## There is a missing value in test dataset. We use median to replace it.\n\ntest_df[\"Fare\"].fillna(test_df[\"Fare\"].median(), inplace=True)\n","8da6db59":"train_df.head()","a876a56d":"test_df.head()","cda1f6f4":"# Pearson Correlation of Features\n\n# The plot indicts that there are not too many features strongly correlated with one another. \n\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train_df.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","bba7403c":"# define training and testing sets\n\nX_train = train_df.drop(\"Survived\",axis=1)\nY_train = train_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\",axis=1).copy()","dcaf9f9b":"# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\n\nY_pred = logreg.predict(X_test)\n\nlogreg.score(X_train, Y_train)","e1607edc":"coeff_df = pd.DataFrame(train_df.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False)","413082ed":"# Support Vector Machines\n\nsvc = SVC()\nsvc.fit(X_train, Y_train)\n\nY_pred = svc.predict(X_test)\n\nsvc.score(X_train, Y_train)","3347bb75":"# Random Forests\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\n\nY_pred = random_forest.predict(X_test)\n\nrandom_forest.score(X_train, Y_train)","f2561050":"# KNN\n\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\n\nY_pred = knn.predict(X_test)\n\nknn.score(X_train, Y_train)","fcff862b":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\n\nY_pred = gaussian.predict(X_test)\n\ngaussian.score(X_train, Y_train)","d6b5eb52":"# Model evaluation\nmodels = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Support Vector Machines', 'Random Forest','KNN', 'Naive Bayes'],\n    'Score': [ logreg.score(X_train, Y_train),svc.score(X_train, Y_train), random_forest.score(X_train, Y_train), knn.score(X_train, Y_train), gaussian.score(X_train, Y_train)]})\nmodels.sort_values(by='Score', ascending=False)","6df8ae22":"# Random Forest model feature importance \n\nimportances = random_forest.feature_importances_\nindices = np.argsort(importances)\nfeatures = X_train.columns\nplt.figure(1)\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), features[indices])\nplt.xlabel('Relative Importance')","eb5e234c":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\n\nY_pred = random_forest.predict(X_test)","b9819c2e":"submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('titanic_prediction.csv', index=False)","ebb8bc88":"## Family ","91f62703":"*   Categorical feature: Survived, Sex, and Embarked. Ordinal: Pclass.\n*   Continous feature: Age, Fare. Discrete: SibSp, Parch.\n*   Notice that there is a lot of null value in Cabin(77% missing in trainig dataset, 78% missing in test dataset).\n*   Age and Embarked columns are incomplete in training dataset. Age feature is incomplete in test dataset.\n*   We decide to drop unnecessary columns(PassengerId, Name, Ticket) and Cabin columns for future analysis and prediction.\n\n\n\n\n\n\n","73eab991":"* Most passengers embarked at S(72.4%).\n* Male passengers who embarked at C had higher survival rate than female \n* Ports of embarkation have varying survival rates for Pclass=3 among male passengers. ","ca3f7392":"## Sex","b29ddc67":"* 64.8% of the passengers are male.\n* Female passengers have a high survival rate(74.2%) while only 18.8% male passengers survived. ","fc2346d1":"* Fares varied significantly with few passengers (<1%) paying as high as $512.\n* Higher fare paying passengers had better survival. This feature is similar to Pclass.\n","3a43dbc9":"*  Most passengers are in 15-40 age range.\n*  Few elderly passengers (<1%) within age range 65-80. The oldest passengers (Age = 80) survived.\n*  Children (Age <= 8) were more likely to have survived(Over 60% survival rate).\n* Age group 8-12 have the lowest survival rate(Under 30%).\n*  For female, they have a high survival rate regardless of age while male passengers have a pretty low survival rate expect for children.\n\n\n\n","4a9dbb73":"# Data Cleaning","df092da7":"*   Total samples are 891, which is 40% of the actual number of passengers on board(2,224).\n*   38.3% sample survival rate while the actual survival rate was 32.5%(722 out of 2224).\n\n","1fdd71c7":"# Modeling and prediction","809aa319":"# **Exploratory data analysis**","76750057":"## Fare","fb1bcacc":"## Pclass\n","477e9a5c":"*   Over half of the passengers were in Class 3(55.1%).\n*   Upper-class(Pclass = 1) passengers were more likely to survive with  62.9% survival rate.\n*   Class 3 passengers only had 24.2% survival rate.\n\n\n","dff3acea":"# **Aquire data**","963c123c":"* Most passengers did not travel with family members. Less than 25% of the passengers traveled with parents or children. Only 31.7% of the passengers had siblings and\/or spouse aboard.\n* Passengers who travel with family member were more likely to survive.","041e2ec9":"## Embarked\n","4257e1ac":"## Age"}}