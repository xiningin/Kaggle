{"cell_type":{"5c53ac16":"code","2b90f2a3":"code","a08b4be5":"code","223c2aa9":"code","ce85d4f8":"code","715e7166":"code","287d94b5":"code","a0e5a61d":"code","88451441":"code","d7e7ef44":"code","7334f376":"code","47918ae1":"code","1b9aaed0":"code","c20bb7bc":"code","8312ed2a":"code","595a3a1b":"code","54f068e8":"code","01e1a6d2":"code","9321214f":"code","4e420474":"code","19f5e614":"code","5004a516":"code","9fe72e12":"code","86312b33":"code","912308b1":"code","44ba5078":"code","527a5747":"code","98b510ba":"code","9174d681":"code","1b7c3a0c":"code","2fbffe72":"code","a9ccbc3c":"code","d4e568d1":"code","65000b2a":"code","68a5f684":"code","0cb7983e":"code","d61435c4":"code","34254237":"code","fd3f87cc":"code","d36e19f2":"code","4101567b":"code","1068624b":"code","1a21a2e7":"code","12ae757a":"code","e4230ec7":"code","3de43e1b":"code","1a314b24":"code","862e72d2":"code","a827704d":"code","8f5f0380":"code","507d8c47":"code","7021932c":"code","aeabb1c2":"code","07069ef8":"code","f7084461":"code","8cd9ae71":"markdown","7ce3499b":"markdown","dc65ef79":"markdown","f6ba20fd":"markdown","4edac36a":"markdown","665ac228":"markdown","c139255e":"markdown","ac81c2b8":"markdown","d666cfd6":"markdown","0f0b082a":"markdown","eb19c562":"markdown","d011caf0":"markdown","8778ba64":"markdown","52557fae":"markdown","efe87547":"markdown","090bba79":"markdown","fe9f0409":"markdown","a33adf10":"markdown","9bf3ccf8":"markdown","b0415a7d":"markdown","7d7bed88":"markdown","0d5de561":"markdown"},"source":{"5c53ac16":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2b90f2a3":"# Importan Lib\nimport pandas as pd\n\n# Libraries for Visualization\nimport plotly.express as px\nimport matplotlib.pyplot as plt \n# data viz lib\nimport seaborn as sns # not used in this code\n# data viz lib\nimport numpy as np \n# numneric calculation\n\n# Library for splitting the data in Train and Test\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\n#Library for getting mutual info\nfrom sklearn.feature_selection import mutual_info_regression\n\n# Library for the metric required to evaluate the model\nfrom sklearn.metrics import r2_score,mean_absolute_error\nfrom sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score,confusion_matrix,roc_auc_score\n#from sklearn.metrics import mean_absolute_error\n\n# Library required for the Linear Regression Algorithm\nfrom sklearn.linear_model import LinearRegression\n\n#Library for scaling the data\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n#from sklearn.preprocessing import MinMaxScaler\n\n%matplotlib inline \n# allow to plot the charts inline","a08b4be5":"import os\nos.getcwd()\ndf = pd.read_csv('\/kaggle\/input\/house-data\/kc_house_data.csv')","223c2aa9":"df.head()","ce85d4f8":"df.sample(10)","715e7166":"# to check the data type of each column\ndf.dtypes","287d94b5":"# to check the data type and no. of non null of each column\ndf.info()","a0e5a61d":"#No. of Rows and columns\ndf.shape","88451441":"# No. of null values in each column\ndf.isnull().sum()","d7e7ef44":"# In case the no. of column is very high, just check for columns which have any null value\ndf[[i for i in df.columns if df[i].isnull().sum()>0]].isnull().sum()","7334f376":"# to get summary of each column\ndf.describe()","47918ae1":"# to check if any duplicate rows are present in the DF. \ndf.duplicated().sum()","1b9aaed0":"# in case any duplicate is found, to remove duplicate rows,\ndf.drop_duplicates()\n# in case we want to drop duplicate as per a specific columm\n#df.drop_duplicates(['Column name'])\nprint(df.shape)\ndf.head(2)","c20bb7bc":"# Removing un-nessesary columns\ndf.columns","8312ed2a":"df_new = df.copy()","595a3a1b":"#Only taking those columns which are required\ndf_new = df_new[['price', 'bedrooms', 'bathrooms', 'sqft_living',\n       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode']]\ndf_new.head(2)","54f068e8":"feature_cols = ['bedrooms', 'bathrooms', 'sqft_living',\n       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode']\nX = df_new[feature_cols]\nY = df_new['price']\n# Divide the data into test and train data set\nX_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.3,random_state=1)","01e1a6d2":"X_test.shape","9321214f":"Standardscaler = StandardScaler()\nX_train_colmn = X_train.columns\nX_train_SS = pd.DataFrame(Standardscaler.fit_transform(X_train),columns = X_train_colmn )\nX_train_SS.head(2)","4e420474":"# get the mutual information\nmutual_info = mutual_info_regression(X_train_SS.fillna(0), y_train)\nmutual_info = pd.Series(mutual_info)\nmutual_info.index = X_train_SS.columns\nmutual_info.sort_values(ascending=False)\n","19f5e614":"#Considering the columns for training the model which are atleast 10% of information shared with dependent variable\/feature\nReq_Columns = list(mutual_info[mutual_info>0.05].index)\nReq_Columns","5004a516":"Train_SS = X_train_SS[Req_Columns]\nTrain_SS.head(3)","9fe72e12":"#Applying Scaling technique to Test Dataset\nStandardscaler = StandardScaler()\nX_test_columns = X_test.columns\nX_test_SS = pd.DataFrame(Standardscaler.fit_transform(X_test),columns = X_test_columns )\n#--------------------\n#Creating the Testing ADS with selected columns\nTest_SS = X_test_SS[Req_Columns]\nprint(Test_SS.shape)\nTest_SS.head(3)","86312b33":"def evaluation(Y_test,Y_pred):\n    acc=accuracy_score(Y_test,np.round(Y_pred))\n    rcl=recall_score(Y_test,Y_pred, average='weighted')\n    f1=f1_score(Y_test,Y_pred, average='weighted')\n    auc_score=roc_auc_score(Y_test,Y_pred, average='weighted')\n    prec_score=precision_score(Y_test,Y_pred, average='weighted')\n    r2 = r2_score(Y_test, Y_pred)\n    \n    metric_dict={'accuracy': round(acc,3),\n               'recall': round(rcl,3),\n               'F1 score': round(f1,3),\n               'auc score': round(auc_score,3),\n               'precision': round(prec_score,3),\n               'R2 Score' : round(r2,3)\n              }\n    return print(metric_dict)","912308b1":"decTree_reg = DecisionTreeRegressor()\n#Train the model with train data set\ndecTree_reg = decTree_reg.fit(Train_SS, y_train)\n\n# Predict the data\ny_pred = decTree_reg.predict(Test_SS)\nr2_dt = r2_score(y_test, y_pred)\n#evaluation(y_test, y_pred)\nprint(\"Accuracy on Training set: \",decTree_reg.score(Train_SS,y_train))\nprint(\"Accuracy on Testing set: \",decTree_reg.score(Test_SS,y_test))\nprint(\"R2 score\", r2_dt)","44ba5078":"linear_reg = LinearRegression()\nlinear_reg.fit(Train_SS, y_train)\ny_pred= linear_reg.predict(Test_SS)\nr2_ln=r2_score(y_test,y_pred)\nprint(\"Accuracy on Training set: \",linear_reg.score(Train_SS,y_train))\nprint(\"Accuracy on Testing set: \",round(linear_reg.score(Test_SS,y_test),2))\nprint(\"R2 score\", r2_ln)","527a5747":"from sklearn.neighbors import KNeighborsRegressor\nneigh = KNeighborsRegressor(n_neighbors=2)\nneigh.fit(Train_SS, y_train)\ny_pred= neigh.predict(Test_SS)\nr2_KN=r2_score(y_test,y_pred)\nprint(\"Accuracy on Training set: \",neigh.score(Train_SS,y_train))\nprint(\"Accuracy on Testing set: \",neigh.score(Test_SS,y_test))\nprint(\"R2 score\", r2_KN)","98b510ba":"score = []\nfor i in range(1,40):\n    knn = KNeighborsRegressor(n_neighbors=i)\n    knn.fit(Train_SS, y_train)\n    pred_i = knn.predict(Test_SS)\n    r2_KN_i=r2_score(y_test,pred_i)\n    score.append(r2_KN_i)\n\nplt.figure(figsize=(10,6))\nplt.plot(range(1,40),score,color='blue', linestyle='dashed', \n         marker='o',markerfacecolor='red', markersize=1)\nplt.title('Accuracy vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Accuracy')\nprint(\"Max Accuracy error:-\",max(score),\"at K =\",score.index(max(score))+1)\n","9174d681":"reg_rf = RandomForestRegressor()\nreg_rf.fit(Train_SS, y_train)\ny_pred= reg_rf.predict(Test_SS)\nr2_rf=r2_score(y_test,y_pred)\nprint(\"Accuracy on Training set: \",reg_rf.score(Train_SS,y_train))\nprint(\"Accuracy on Testing set: \",reg_rf.score(Test_SS,y_test))\nprint(\"R2 score\", r2_rf)","1b7c3a0c":"#from sklearn.model_selection import RandomizedSearchCV\n#Randomized Search CV\n# Number of trees in random forest\n#n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 40)]\n# Number of features to consider at every split\n#max_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\n#max_depth = [int(x) for x in np.linspace(5, 40, num = 6)]\n# Minimum number of samples required to split a node\n#min_samples_split = [2, 5, 10, 15, 20,25,30,35,40,100]\n# Minimum number of samples required at each leaf node\n#min_samples_leaf = [1, 2, 5, 10]\n\n#random_grid = {'n_estimators': n_estimators,\n#               'max_features': max_features,\n#               'max_depth': max_depth,\n#               'min_samples_split': min_samples_split,\n#               'min_samples_leaf': min_samples_leaf}\n\n#rf_random = RandomizedSearchCV(estimator = reg_rf, param_distributions = random_grid,scoring='neg_mean_squared_error',\n                       #        n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)\n\n#rf_random.fit(Train_SS, y_train)","2fbffe72":"#rf_random.best_params_","a9ccbc3c":"reg_rf = RandomForestRegressor(n_estimators=587,min_samples_split=5,min_samples_leaf=5,max_features='auto',max_depth=40)\nreg_rf.fit(Train_SS, y_train)\ny_pred= reg_rf.predict(Test_SS)\nr2_rf_bp=r2_score(y_test,y_pred)\nprint(\"Accuracy on Training set: \",reg_rf.score(Train_SS,y_train))\nprint(\"Accuracy on Testing set: \",reg_rf.score(Test_SS,y_test))\nprint(\"R2 score\", r2_rf_bp)","d4e568d1":"import xgboost as XGB","65000b2a":"xgb_model = XGB.XGBRegressor()\nxgb_model.fit(Train_SS, y_train)\ny_pred= xgb_model.predict(Test_SS)\nr2_XG=r2_score(y_test,y_pred)\nprint(\"Accuracy on Traing set: \",xgb_model.score(Train_SS,y_train))\nprint(\"Accuracy on Testing set: \",xgb_model.score(Test_SS,y_test))\nprint(\"R2 score\", r2_XG)","68a5f684":"#learning_rate = [0.01, 0.1]\n#max_depth = [int(x) for x in np.linspace(5, 40, num = 6)]\n#min_child_weight = [int(x) for x in np.linspace(1, 20, num = 6)]\n#subsample =  [0.5, 0.7]\n#colsample_bytree = [0.5, 0.7]\n#objective = ['reg:squarederror']\n#n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 40)]\n\n\n#random_grid = {'learning_rate': learning_rate,\n#               'max_depth': max_depth,\n#               'min_child_weight': min_child_weight,\n#               'subsample': subsample,\n#               'colsample_bytree': colsample_bytree,\n#               'objective': objective,\n#              'n_estimators': n_estimators}\n\n\n#rf_random = RandomizedSearchCV(estimator = xgb_model, param_distributions = random_grid,scoring='neg_mean_squared_error',\n#                               n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)\n\n#rf_random.fit(Train_SS, y_train)","0cb7983e":"#rf_random.best_params_","d61435c4":"xgb_model = XGB.XGBRegressor(subsample=0.5, objective='reg:squarederror', n_estimators=1561, \n                             min_child_weight=16, max_depth=12, learning_rate=0.01, colsample_bytree=0.5)\nxgb_model.fit(Train_SS, y_train)\ny_pred= xgb_model.predict(Test_SS)\nr2_XG_bp=r2_score(y_test,y_pred)\nprint(\"Accuracy on Training set: \",xgb_model.score(Train_SS,y_train))\nprint(\"Accuracy on Testing set: \",xgb_model.score(Test_SS,y_test))\nprint(\"R2 score\", r2_XG_bp)","34254237":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier","fd3f87cc":"bagging_model=BaggingClassifier(oob_score=True,n_jobs=None,n_estimators=10,random_state=1,\n                      base_estimator=DecisionTreeClassifier())\n\n","d36e19f2":"bagging_model.fit(Train_SS, y_train)","4101567b":"y_pred= bagging_model.predict(Test_SS)\nr2_bc=r2_score(y_test,y_pred)\nprint(\"Accuracy on Training set: \",bagging_model.score(Train_SS,y_train))\nprint(\"Accuracy on Testing set: \",bagging_model.score(Test_SS,y_test))\nprint(\"R2 score\", r2_bc)","1068624b":"from sklearn.ensemble import RandomForestClassifier","1a21a2e7":"RFC_model=RandomForestClassifier(n_estimators=10,oob_score=True,n_jobs=None,random_state=400)","12ae757a":"RFC_model.fit(Train_SS, y_train)","e4230ec7":"y_pred= RFC_model.predict(Test_SS)\nr2_rfc=r2_score(y_test,y_pred)\nprint(\"Accuracy on Training set: \",RFC_model.score(Train_SS,y_train))\nprint(\"Accuracy on Testing set: \",RFC_model.score(Test_SS,y_test))\nprint(\"R2 score\", r2_rfc)","3de43e1b":"from sklearn.ensemble import GradientBoostingClassifier","1a314b24":"GBC_model=RandomForestClassifier(n_estimators=10,oob_score=True,n_jobs=-1,random_state=400)","862e72d2":"GBC_model.fit(Train_SS, y_train)","a827704d":"y_pred= GBC_model.predict(Test_SS)\nr2_gbc=r2_score(y_test,y_pred)\nprint(\"Accuracy on Training set: \",GBC_model.score(Train_SS,y_train))\nprint(\"Accuracy on Testing set: \",GBC_model.score(Test_SS,y_test))\nprint(\"R2 score\", r2_gbc)","8f5f0380":"def mape(actual, pred): \n    actual, pred = np.array(actual), np.array(pred)\n    return np.mean(np.abs((actual - pred) \/ actual)) * 100","507d8c47":"mape(y_test, y_pred)","7021932c":"Req_Columns","aeabb1c2":"# Defining variable 'y' with given data\ndata = {'bedrooms':[4,3], 'bathrooms':[3,2], 'sqft_living':[4000,3200], 'sqft_lot': [9000,7200], 'floors':[3,5], 'view':[1,2], 'grade':[3,4], 'sqft_above':[1180,1200],\n        'sqft_basement':[0,1121], \n        'yr_built':[1965, 1970], 'zipcode':[98125, 98125]}\n\ntest_df = pd.DataFrame(data, columns= ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'view', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'zipcode'])\ntest_df.head(2)","07069ef8":"test_columns = test_df.columns\n\ntest_SS = pd.DataFrame(Standardscaler.fit_transform(test_df),columns = test_columns )\nprint(test_SS.shape)\ntest_SS.head(2)","f7084461":"# Predicting on the basis of the value in 'y'\npred_y = xgb_model.predict(test_SS)\npred_y","8cd9ae71":"# Step 2 : Reading the data into a Pandas Dataframe","7ce3499b":"#### In RandomForest Regressor, accuracy is comparitively better than than above three models. To improve the accuracy, hyperparameter tuing is performed","dc65ef79":"# Calculation MAPE","f6ba20fd":"# Step 3 : Understanding the data","4edac36a":"## GradientBoostingClassifier","665ac228":"### XGBoost Regressor","c139255e":"## Random Forest Classifier","ac81c2b8":"# Predict the value","d666cfd6":"# Exploring the data","0f0b082a":"Scaling the data","eb19c562":"## Linear regression","d011caf0":"# Task 1 - Prediction price of plot as per all Variable\n## Given Problem Statement\n-- A simple linear regression task involving 2 variables, we need to predict the price as per sqrft area.\n-- What will be predicted price if a the plot size is 3000, with all the dependent variable","8778ba64":"# Step 1 : Importing required libraries","52557fae":"Compare with Linear regressor, accuracy for KNN with K=2 is better. So performing hyper parameter tunning to find the optimal K value","efe87547":"### Create a function for evaluating metrics","090bba79":"## KNeighbors Regressor","fe9f0409":"#### Creating the Training data set with selected columns","a33adf10":"## RandomForest Regressor","9bf3ccf8":"## BaggingClassifier","b0415a7d":"## DecisionTreeRegressor","7d7bed88":"['bedrooms',\n 'bathrooms',\n 'sqft_living',\n 'sqft_lot',\n 'floors',\n 'view',\n 'grade',\n 'sqft_above',\n 'sqft_basement',\n 'yr_built',\n 'zipcode']","0d5de561":"##### Getting test train data"}}