{"cell_type":{"883a7f74":"code","8545272c":"code","1a6739b6":"code","9cd581ff":"code","76a137cf":"code","abf051fe":"code","f87b4f7b":"code","5d738505":"code","1ebfc426":"code","ff7ecf75":"code","54722760":"code","527c0362":"code","ba72dc6e":"code","9dbe2c24":"code","12b5ebf8":"code","f1bad625":"code","5c1debfd":"code","9374637b":"code","28144829":"code","254d7ded":"code","6c3143aa":"code","469da339":"code","eff1f214":"code","e1a783e3":"code","bce312f5":"markdown","d22c242d":"markdown","15529010":"markdown","5fd37057":"markdown","84c5bd7d":"markdown","96973999":"markdown","2f509830":"markdown","a3f55cad":"markdown","0da36496":"markdown"},"source":{"883a7f74":"import glob\nimport cv2\nimport matplotlib.pyplot as plt\nimport random\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import confusion_matrix,classification_report","8545272c":"lst_fire_img = glob.glob('\/kaggle\/input\/fire-dataset\/fire_dataset\/fire_images\/*.png')\nlst_non_fire_img = glob.glob('\/kaggle\/input\/fire-dataset\/fire_dataset\/non_fire_images\/*.png')","1a6739b6":"lst_non_fire_img","9cd581ff":"print('Number of images with fire : {}'.format(len(lst_fire_img)))\nprint('Number of images with fire : {}'.format(len(lst_non_fire_img)))","76a137cf":"lst_images_random = random.sample(lst_fire_img,10) + random.sample(lst_non_fire_img,10)\nrandom.shuffle(lst_images_random)\n\nplt.figure(figsize = (20,20))\n\nfor i in range(len(lst_images_random)):\n    \n    plt.subplot(4,5,i+1)\n\n\n    if \"non_fire\" in lst_images_random[i]:\n        img = cv2.imread(lst_images_random[i])\n        img = cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n        plt.imshow(img,cmap = 'gray')\n        plt.title('Image without fire')\n\n    else:\n        img = cv2.imread(lst_images_random[i])\n        img = cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n        plt.imshow(img,cmap = 'gray')\n        plt.title(\"Image with fire\")\n\n\n\nplt.show()","abf051fe":"lst_fire = []\nfor x in lst_fire_img:\n  lst_fire.append([x,1])\nlst_nn_fire = []\nfor x in lst_non_fire_img:\n  lst_nn_fire.append([x,0])\nlst_complete = lst_fire + lst_nn_fire\nrandom.shuffle(lst_complete)","f87b4f7b":"df = pd.DataFrame(lst_complete,columns = ['files','target'])\ndf.head(10)","5d738505":"filepath_img = '\/kaggle\/input\/fire-dataset\/fire_dataset\/non_fire_images\/non_fire.189.png'\ndf = df.loc[~(df.loc[:,'files'] == filepath_img),:]","1ebfc426":"df.shape","ff7ecf75":"plt.figure(figsize = (10,10))\n\n\nsns.countplot(x = \"target\",data = df)\n\nplt.show()","54722760":"def preprocessing_image(filepath):\n  img = cv2.imread(filepath) #read\n  img = cv2.cvtColor(img,cv2.COLOR_RGB2BGR) #convert\n  img = cv2.resize(img,(196,196))  # resize\n  img = img \/ 255 #scale\n  return img ","527c0362":"def create_format_dataset(dataframe):\n  X = []\n  y = []\n  for f,t in dataframe.values:\n    X.append(preprocessing_image(f))\n    y.append(t)\n  \n  return np.array(X),np.array(y)","ba72dc6e":"X, y = create_format_dataset(df)","9dbe2c24":"X.shape,y.shape","12b5ebf8":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,stratify = y)","f1bad625":"X_train.shape,X_test.shape,y_train.shape,y_test.shape","5c1debfd":"model = Sequential()\n\nmodel.add(Conv2D(128,(2,2),input_shape = (196,196,3),activation='relu'))\nmodel.add(Conv2D(64,(2,2),activation='relu'))\nmodel.add(MaxPooling2D())\nmodel.add(Conv2D(32,(2,2),activation='relu'))\nmodel.add(MaxPooling2D())\n\nmodel.add(Flatten())\nmodel.add(Dense(128))\nmodel.add(Dense(1,activation= \"sigmoid\"))","9374637b":"model.summary()","28144829":"callbacks = [EarlyStopping(monitor = 'val_loss',patience = 10,restore_best_weights=True)]\nmodel.compile(optimizer='adam',loss = 'binary_crossentropy',metrics=['accuracy'])\nmodel.fit(X_train,y_train,validation_data=(X_test,y_test),epochs = 30,batch_size = 32,callbacks = callbacks)","254d7ded":"y_pred = model.predict(X_test)","6c3143aa":"y_pred = y_pred.reshape(-1)\ny_pred[y_pred<0.5] = 0\ny_pred[y_pred>=0.5] = 1\ny_pred = y_pred.astype('int')","469da339":"y_pred","eff1f214":"plt.figure(figsize = (20,10))\n\nsns.heatmap(confusion_matrix(y_test,y_pred),annot = True)\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\n\nplt.show()","e1a783e3":"print(classification_report(y_test,y_pred))","bce312f5":"We preprocess all the images ","d22c242d":"We create a dataframe with filepath images and label (1 = fire , 0 = without fire)","15529010":"Import ","5fd37057":"We have a problem with image 189 in non_fire_images so we drop it","84c5bd7d":"We plot 20 images to see how are the data","96973999":"we split the data in train and test ","2f509830":"We can see that the dataset is unbalanced, but we don't use ImageDataGenerator because the result are pretty good despite this","a3f55cad":"We load the data with glob","0da36496":"We create numpy array X and y . X are 998 images with (196,196,3) shape, y the target is (998,) shape"}}