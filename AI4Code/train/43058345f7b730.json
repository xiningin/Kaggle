{"cell_type":{"69c055f8":"code","ed69bf4a":"code","a77d700f":"code","60b15849":"code","a43e19cf":"code","cede2594":"code","e70bc1af":"code","2c07bf87":"code","088243b8":"code","7bb5f009":"code","cf6addf1":"code","17671d53":"code","11991835":"code","27ce03f7":"code","f94ea912":"code","be6e3e2c":"code","52a16b5a":"code","9655401d":"code","16f21d36":"code","7eabc85b":"code","4a164c13":"code","3255d1ff":"code","aca3741b":"code","fd504604":"code","6353e0c0":"code","605ab190":"code","32250261":"code","60beea5e":"code","8f1e41d0":"code","edb1523f":"code","6c7803e1":"code","f1884e9c":"code","c44ec57a":"code","e6eb9c7a":"code","99a7b8b9":"code","c7bceca0":"code","0d1c62d1":"code","1883694e":"code","8049d7b2":"code","f419003a":"code","e711bcf6":"code","b4519c48":"code","61674b0d":"code","aaa41da9":"markdown","3d01c1d9":"markdown","8448a7f4":"markdown","b22b0616":"markdown","fd6f7c14":"markdown","f0b83ca2":"markdown","04be3ffb":"markdown","5ba09706":"markdown","2777b9bc":"markdown","fbf99719":"markdown","16fa6cc3":"markdown","3c430097":"markdown","cd7f003a":"markdown","c9d54a29":"markdown","7313ed85":"markdown"},"source":{"69c055f8":"# \ubd84\uc11d \uae30\ubcf8 \ub3c4\uad6c\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('bmh')\n\n# \ud1b5\uacc4 \ubd84\uc11d \ub3c4\uad6c\nfrom scipy import stats\n\n# \uc2dc\uac01\ud654 \ub3c4\uad6c\nimport folium\nimport geojson\nfrom folium import plugins\nfrom shapely.geometry import shape, Point, multipolygon\nfrom shap import TreeExplainer, summary_plot\n\n# \uc804\ucc98\ub9ac \ub3c4\uad6c\nfrom sklearn.preprocessing import LabelEncoder\n\n# \ud559\uc2b5 \ub3c4\uad6c\n#from sklearn.ensemble import RandomForestRegressor\n#from sklearn.ensemble import GradientBoostingRegressor\n#import lightgbm as lgb\nimport xgboost as xgb\n\n# \uac80\uc99d \ub3c4\uad6c\n#from sklearn.model_selection import KFold\n#from sklearn.model_selection import cross_val_score\n#from sklearn.metrics import make_scorer\n#from sklearn.metrics import mean_squared_error\n\n# \uacbd\uace0\ubb38 \ubb34\uc2dc(seaborn)\nimport warnings\nwarnings.filterwarnings('ignore')","ed69bf4a":"ls ..\/input\/2019-2nd-ml-month-with-kakr","a77d700f":"train = pd.read_csv('..\/input\/2019-2nd-ml-month-with-kakr\/train.csv')\n\nprint(train.shape)\ntrain.head()","60b15849":"test = pd.read_csv('..\/input\/2019-2nd-ml-month-with-kakr\/test.csv')\n\nprint(test.shape)\ntest.head()","a43e19cf":"train.info()","cede2594":"test.info()","e70bc1af":"data = pd.merge(train, test, how='outer')\n\nprint(data.shape)\ndata.head()","2c07bf87":"# Check our columns\ndata.columns","088243b8":"data['year'] = data['date'].apply(lambda x:x[:4]).astype(int)\ndata['month'] = data['date'].apply(lambda x:x[4:6]).astype(int)\ndata['day'] = data['date'].apply(lambda x:x[6:8]).astype(int)","7bb5f009":"data['yr_built'].min()","cf6addf1":"count_info = ['year', 'month', 'day', 'bedrooms', 'bathrooms', 'floors', 'waterfront', 'view', 'condition', 'grade']\nfig, axes = plt.subplots(3, 4, figsize=(20, 15))\n\nfor r in range(3):\n    for c in range(4):\n        index = 4 * r + c\n        if index == len(count_info):\n            break\n        sns.countplot(data=data, x=count_info[index], ax=axes[r, c])\n        axes[r, c].set_xlabel('')\n        axes[r, c].set_title(count_info[index], fontsize=20)","17671d53":"fig, axes = plt.subplots(nrows=8, figsize=(15, 40))\n\nsns.pointplot(data=data, x='day', y='price', hue='year', ax=axes[0])\nsns.pointplot(data=data, x='month', y='price', hue='year', ax=axes[1])\nsns.pointplot(data=data, x='grade', y='price', hue='waterfront', ax=axes[2])\nsns.pointplot(data=data, x='view', y='price', hue='waterfront', ax=axes[3])\nsns.pointplot(data=data, x='condition', y='price', hue='waterfront', ax=axes[4])\nsns.pointplot(data=data, x='floors', y='price', hue='waterfront', ax=axes[5])\nsns.pointplot(data=data, x='bathrooms', y='price', hue='waterfront', ax=axes[6])\nsns.pointplot(data=data, x='bedrooms', y='price', hue='waterfront', ax=axes[7])\n\ntitle = ['Day', 'Month', 'Grade', 'View', 'Condition', 'Floors', 'Bathrooms', 'Bedrooms']\nfor i in range(8):\n    axes[i].set_xlabel('')\n    axes[i].set_title(title[i], fontsize=15)\nplt.show()","11991835":"corrMatt = train[['price', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'sqft_living15', 'sqft_lot15']]\ncorrMatt = corrMatt.corr()\n\nprint(corrMatt)\n\nmask = np.array(corrMatt)\nmask[np.tril_indices_from(mask)] = False","27ce03f7":"fig, ax = plt.subplots(figsize=(10, 8))\n\nsns.heatmap(corrMatt, mask=mask, vmax=0.8, square=True, annot=True)\nax.set_title('Correlation Matters', fontsize=20)\nplt.show()","f94ea912":"fig, axes = plt.subplots(ncols=2, figsize=(10, 4))\n\nsns.distplot(train['price'], ax=axes[0])\naxes[0].set_title('Before Log Scaling', fontsize=15)\nsns.distplot(np.log1p(train['price']), ax=axes[1])\naxes[1].set_title('After Log Scaling', fontsize=15)\nplt.show()","be6e3e2c":"fig, axes = plt.subplots(ncols=2, figsize=(10, 4))\n\nreg = stats.probplot(train['price'], plot=axes[0])\naxes[0].set_title('Before Log Scaling', fontsize=15)\nreg = stats.probplot(np.log1p(train['price']), plot=axes[1])\naxes[1].set_title('After Log Scaling', fontsize=15)\nplt.show()","52a16b5a":"fig, axes = plt.subplots(ncols=2, figsize=(10, 4))\n\nsns.regplot(data=train, x='long', y='lat',\n           fit_reg=False,\n           scatter_kws={'s': 15},\n           ax=axes[0])\naxes[0].grid(False)\naxes[0].set_title('Location of train data', fontsize=15)\n\nsns.regplot(data=test, x='long', y='lat',\n           fit_reg=False,\n           scatter_kws={'s': 15},\n           ax=axes[1])\naxes[1].grid(False)\naxes[1].set_title('Location of test data', fontsize=15)\n\nplt.show()","9655401d":"train[(train['long'] > -121.8) & (train['lat'] < 47.2)]","16f21d36":"test[(test['long'] > -121.6) & (test['lat'] < 47.5)]","7eabc85b":"map_count = folium.Map(location=[train['lat'].mean(), train['long'].mean()],\n                      min_zoom=8,\n                      #max_zoom=11,\n                      width=960,  # map size scaling\n                      height=540)\n\nlat_long_data = train[['lat', 'long']].values.tolist()\nh_cluster = folium.plugins.FastMarkerCluster(lat_long_data).add_to(map_count)\n\nmap_count","4a164c13":"zipcode_data = train.loc[:, ['price', 'lat', 'long', 'zipcode']]\nzipcode_data['coord'] = [(round(x,6), round(y,6)) for x, y in zip(train['long'], train['lat'])]\ndel zipcode_data['lat']\ndel zipcode_data['long']\n\nprint(zipcode_data.shape)\nzipcode_data.head()","3255d1ff":"geo_zipcode = geojson.load(open('..\/input\/geodata\/zipcode_king_county.geojson', encoding='utf-8'))","aca3741b":"def zipcode(coord):\n    point = Point(coord)\n    for feature in geo_zipcode['features']:\n        polygon = shape(feature['geometry'])\n        if polygon.contains(point):\n            return feature['properties']['ZCTA5CE10']\n    return 'Outlier'","fd504604":"# \uc0dd\uc131\n# zipcode_data['zipcode'] = zipcode_data.coord.apply(zipcode) #\uacbd\uace0: 2~3\ubd84 \uac78\ub9bd\ub2c8\ub2e4.\n# zipcode_data.head()\n\n# \uc800\uc7a5\n# zipcode_data.to_csv('..\/input\/savefiles\/zipcode_data.csv', index=None, encoding='utf-8')\n\n# \ubd88\ub7ec\uc624\uae30\nzipcode_data = pd.read_csv('..\/input\/savefile\/zipcode_data.csv', index_col=None, header=0, encoding='utf-8')\n\nprint(zipcode_data.shape)\nzipcode_data.head()","6353e0c0":"zipcode = pd.pivot_table(zipcode_data, index=['zipcode'])\n\nprint(zipcode.shape)\nzipcode.head()","605ab190":"map_price = folium.Map(location=[train['lat'].mean(), train['long'].mean()],\n                       min_zoom=8, # \uace0\uc815\n                       max_zoom=10,\n                       tiles='OpenStreetMap',\n                       width=960,\n                       height=540,\n                      )\n\nfolium.Choropleth(\n    geo_data=geo_zipcode, \n    data=zipcode['price'],\n    columns=[zipcode.index, zipcode['price']],\n    fill_color='Reds',\n    fill_opacity=0.5,\n    line_opacity=0.8,\n    key_on='feature.properties.ZCTA5CE10',\n).add_to(map_price)\n\nmap_price","32250261":"le = LabelEncoder()\nle.fit(train['zipcode'])\nle.fit(test['zipcode'])\n\ntrain['zipcode'] = le.transform(train['zipcode'])\ntest['zipcode'] = le.transform(test['zipcode'])","60beea5e":"train['price_per_land_area'] = train['price'] \/ (train['sqft_living'])\nprice_per_ft = train.groupby(['zipcode'])['price_per_land_area'].agg({'mean', 'std', 'count'}).reset_index()\n\ntrain = pd.merge(train, price_per_ft, how='left', on='zipcode')\ntest = pd.merge(test, price_per_ft, how='left', on='zipcode')\n\ndel train['price_per_land_area']","8f1e41d0":"X_train = train.drop(['id', 'price'], axis=1)\ny_train = train['price']\ny_train = np.log1p(y_train)\nX_test = test.drop(['id'], axis=1)","edb1523f":"train.columns","6c7803e1":"# Adding features\nfor df in [X_train, X_test]:\n    df['date(new)'] = df['date'].apply(lambda x: int(x[4:8])+800 if x[:4] == '2015' else int(x[4:8])-400)\n    df['how_old'] = df['date'].apply(lambda x: x[:4]).astype(int) - df[['yr_built', 'yr_renovated']].max(axis=1)\n    del df['date']\n    del df['yr_renovated']\n    df['yr_built'] = df['yr_built'] - 1900\n    df['sqft_floor'] = df['sqft_above'] \/ df['floors']\n    df['floor_area_ratio'] = df['sqft_living'] \/ df['sqft_lot']\n    del df['sqft_lot15']","f1884e9c":"rows = (X_train.shape[1]+3) \/\/ 4\nfig, axes = plt.subplots(rows, 4, figsize=(20, rows*5))\ncols = X_train.columns\n\nfor r in range(rows):\n    for c in range(4):\n        index = 4 * r + c\n        if index == len(cols):\n            break\n        reg = stats.probplot(X_train[cols[index]], plot=axes[r, c])\n        axes[r, c].set_title(cols[index], fontsize=20)","c44ec57a":"# Log Scaling\nlog_features = ['bedrooms', 'bathrooms', 'sqft_lot', 'sqft_living', 'sqft_above', 'sqft_basement', 'sqft_living15', 'sqft_floor', 'mean', 'floor_area_ratio', 'floor_area_ratio']\nfor feature in log_features:\n    for df in [X_train, X_test]:\n        df[feature] = np.log1p(df[feature])","e6eb9c7a":"rows = (X_train.shape[1]+3) \/\/ 4\nfig, axes = plt.subplots(rows, 4, figsize=(20, rows*5))\ncols = X_train.columns\n\nfor r in range(rows):\n    for c in range(4):\n        index = 4 * r + c\n        if index == len(cols):\n            break\n        reg = stats.probplot(X_train[cols[index]], plot=axes[r, c])\n        axes[r, c].set_title(cols[index], fontsize=20)","99a7b8b9":"# feval function\uc5d0 \uc0ac\uc6a9\ud558\uae30 \uc704\ud574\ndef rmse_exp(predictions, dmat):\n    labels = dmat.get_label()\n    error = np.expm1(predictions) - np.expm1(labels)\n    squared_error = np.square(error)\n    mean = np.mean(squared_error)\n    return ('rmse_exp', np.sqrt(mean))","c7bceca0":"xgb_params = {\n    'eta': 0.02,\n    'max_depth': 6,\n    'subsample': 0.8,\n    'colsample_bytree': 0.4,\n#     'tree_method': 'gpu_hist',    # \ucd5c\uc801\ud654\ub41c \ubd84\ud560 \uc9c0\uc810\uc744 \ucc3e\uae30 \uc704\ud55c algorithm \uc124\uc815 + \uce90\uae00\uc758 GPU \uc0ac\uc6a9\n#     'predictor': 'gpu_predictor', # \uc608\uce21 \uc2dc\uc5d0\ub3c4 GPU\uc0ac\uc6a9\n    'objective': 'reg:linear',    # \ud68c\uadc0\n    'eval_metric': 'rmse',        # kaggle\uc5d0\uc11c \uc694\uad6c\ud558\ub294 \uac80\uc99d\ubaa8\ub378\n    'silent': True,               # \ud559\uc2b5 \ub3d9\uc548 \uba54\uc138\uc9c0 \ucd9c\ub825\ud560\uc9c0 \ub9d0\uc9c0\n    'seed': 4777,\n}","0d1c62d1":"%%time\n# transforming\ndtrain = xgb.DMatrix(X_train, y_train)\ndtest = xgb.DMatrix(X_test)\n\n# cross validation\ncv_output = xgb.cv(xgb_params,\n                   dtrain,                        \n                   num_boost_round=5000,         # the number of boosting trees\n                   early_stopping_rounds=100,    # val loss\uac00 \uacc4\uc18d \uc0c1\uc2b9\ud558\uba74 \uc911\uc9c0\n                   nfold=5,                      # set folds of the closs validation\n                   verbose_eval=100,             # \uba87 \ubc88\uc9f8\ub9c8\ub2e4 \uba54\uc138\uc9c0\ub97c \ucd9c\ub825\ud560 \uac83\uc778\uc9c0\n                   feval=rmse_exp,               # price \uc18d\uc131\uc744 log scaling \ud588\uae30 \ub54c\ubb38\uc5d0, \ub2e4\uc2dc exponential\n                   maximize=False,\n                   show_stdv=False,              # \ud559\uc2b5 \ub3d9\uc548 std(\ud45c\uc900\ud3b8\ucc28) \ucd9c\ub825\ud560\uc9c0 \ub9d0\uc9c0\n                   )\n\n# scoring\nbest_rounds = cv_output.index.size\nscore = round(cv_output.iloc[-1]['test-rmse_exp-mean'], 2)\n\nprint(f'\\nBest Rounds: {best_rounds}')\nprint(f'Best Score: {score}')\n\n\n# plotting\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14,5))\ncv_output[['train-rmse-mean', 'test-rmse-mean']].plot(ax=ax1)\nax1.set_title('RMSE_log', fontsize=20)\ncv_output[['train-rmse_exp-mean', 'test-rmse_exp-mean']].plot(ax=ax2)\nax2.set_title('RMSE', fontsize=20)\n\nplt.show()","1883694e":"model = xgb.train(xgb_params, dtrain, num_boost_round=best_rounds)\ny_pred = model.predict(dtest)\ny_pred = np.expm1(y_pred)","8049d7b2":"fig, ax = plt.subplots(figsize=(10,10))\nxgb.plot_importance(model, ax=ax)\n\nplt.show()","f419003a":"explainer = TreeExplainer(model)\nshap_values = explainer.shap_values(X_train)\nsummary_plot(shap_values, X_train, title='Train')","e711bcf6":"sample_submission = pd.read_csv('..\/input\/2019-2nd-ml-month-with-kakr\/sample_submission.csv')\n\nprint(sample_submission.shape)\nsample_submission.head()","b4519c48":"submission = pd.DataFrame(data = {'id': test['id'], 'price': y_pred})\n\nprint(submission.shape)\nsubmission.head()","61674b0d":"submission.to_csv('submission.csv', index=False)","aaa41da9":"## Learning\n\n- xgboost \ud558\ub098\uc758 \ubaa8\ub378\ub9cc\uc744 \uc774\uc6a9\ud574 \ud559\uc2b5\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n- \ud3c9\uac00 \ucc99\ub3c4\ub294 RMSE(Root Mean Square Error)\uc774\uba70, \uc218\uc2dd\uc740 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4.\n$$\nRMSE(y, \\bar{y}) = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (y_i - \\bar{y}_i)^2}\n$$\nwhere $y=(y_1, y_2, \\ldots, y_n)$ and $\\bar{y}=(\\bar{y}_1, \\bar{y}_2, \\ldots, \\bar{y}_n)$ denote the vector of actual values and the vector of our predicted values, respectively.","3d01c1d9":"### 2. Correlation between Discrete Variables\n\n- \ub370\uc774\ud130\ub294 2014\ub144 5\uc6d4\ubd80\ud130 2015\ub144 5\uc6d4\uae4c\uc9c0\uc758 \uc9d1 \uc815\ubcf4\uc640 \uac00\uaca9 \uc815\ubcf4\ub97c \ub2f4\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n- grade, view, condition\uc5d0 \ube44\ub840\ud558\uc5ec \uc9d1 \uac00\uaca9\uc774 \ub192\uc544\uc9c0\uace0 \uc788\uc74c\uc744 \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n- waterfront\uc778\uc9c0 \uc544\ub2cc\uc9c0\uc5d0 \ub530\ub978 \uac00\uaca9 \ucc28\uc774\uac00 \uc874\uc7ac\ud569\ub2c8\ub2e4.\n- floors\uc758 \uc18c\uc218\uc810\uc740 \ub2e4\ub77d\ubc29 \ub4f1\uc744 \uc758\ubbf8\ud558\ub294 \uac83\uc73c\ub85c \ubcf4\uc785\ub2c8\ub2e4.\n- bathrooms\ub294 Taemyung Heo\ub2d8\uc758 [discussion](https:\/\/www.kaggle.com\/c\/2019-2nd-ml-month-with-kakr\/discussion\/83533)\ub97c \ucc38\uace0\ud558\uba74 \uc88b\uc2b5\ub2c8\ub2e4.","8448a7f4":"### 2. Validation\n\n- \uc6b0\ub9ac\ub294 price \ub300\uc2e0 $\\log(\\text{price}+1)$\uc744 \uc0ac\uc6a9\ud588\uc73c\ubbc0\ub85c, scoring\uc744 \ud560 \ub54c feval function\uc744 \uc774\uc6a9\ud558\uc5ec $\\exp(\\bar{y})-1$\ub97c \ucde8\ud574\uc90d\ub2c8\ub2e4.","b22b0616":"## Data Load","fd6f7c14":"## Submission\n\n- submission sample\ub97c \ud655\uc778\ud558\uace0 \uadf8 \uc591\uc2dd\uc5d0 \ub9de\uac8c submission \ud30c\uc77c\uc744 \ub9cc\ub4e4\uc5b4 \uc81c\ucd9c\ud569\ub2c8\ub2e4.","f0b83ca2":"### 4. Feature Importance\n\n- waterfront\ub294 feature importance\uac00 \ub0ae\uc740\ub370\ub3c4 \ubd88\uad6c\ud558\uace0 \uc2dc\uac01\ud654\ub098 \uc2e4\ud5d8\ub2e8\uacc4\uc5d0\uc11c \uc9d1 \uac00\uaca9\uc5d0 \uc0c1\ub2f9\ud55c \uc601\ud5a5\uc744 \ubbf8\uce58\ub294 \uac83\uc744 \ud655\uc778\ud558\uc600\ub294\ub370, \uc774\ub294 waterfront\uc778 \uc9d1\uacfc \uc544\ub2cc \uc9d1\uc758 \uc218 \ucc28\uc774\uac00 \ub9ce\uc774 \ub098\uae30 \ub54c\ubb38\uc73c\ub85c \uc0dd\uac01\ud569\ub2c8\ub2e4.\n- EDA\uc5d0\uc11c sqft_lot \uc18d\uc131\uc740 price\uc640 \ub0ae\uc740 \uad00\uacc4\uc131\uc744 \ubcf4\uc600\ub294\ub370, feature importance\uc5d0\uc11c\ub294 \uad49\uc7a5\ud788 \ub192\uc740 \uc911\uc694\ub3c4\ub97c \ub755\ub2c8\ub2e4.","04be3ffb":"\uccab \uce90\uae00 \ucee4\ub110\uc785\ub2c8\ub2e4. \uc798 \ubd80\ud0c1\ub4dc\ub9bd\ub2c8\ub2e4 :)\n\n\ubaa9\ucc28\n\n- [\ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30](#Data-Load)\n- [\ud0d0\ud5d8\uc801 \ub370\uc774\ud130 \ubd84\uc11d](#EDA)\n    - [1. \ub370\uc774\ud130 \ud655\uc778](#1.-Check-Features)\n    - [2. \uc774\uc0b0\uc218\uce58 \uc18d\uc131\ub4e4 \uac04\uc758 \uc0c1\uad00\uad00\uacc4](#2.-Correlation-between-Discrete-Variables)\n    - [3. \uc5f0\uc18d\uc218\uce58 \uc18d\uc131\ub4e4 \uac04\uc758 \uc0c1\uad00\uad00\uacc4](#3.-Correlation-between-Continuous-Variables)\n    - [4. \uac00\uaca9 \ubd84\ud3ec \ud655\uc778](#4.-Distribution-of-Price)\n    - [5. Geometry](#5.-Geometry)\n- [\uc804\ucc98\ub9ac](#Preprocessing)\n    - [1. Feature Engineering](#1.-Feature-Engineering)\n    - [2. Log Scaling](#2.-Log-Scaling)\n    - [3. Label Encoding](#3.-Label-Encoding)\n- [\ud559\uc2b5](#Learning)\n    - [1. Hyperparameter](#1.-Hyperparameter)\n    - [2. Validation](#2.-Validation)\n    - [3. Prediction](#3.-Prediction)\n    - [4. Feature Importance](#4.-Feature-Importance)\n- [\uc81c\ucd9c](#Submission)","5ba09706":"### 4. Distribution of Price\n\n- log scaling(1\uc744 \ub354\ud55c \ud6c4 log)\ud55c \ud6c4\uc5d0 normal distribution\uc5d0 \ub354\uc6b1 \uac00\uae4c\uc6cc\uc9c0\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.","2777b9bc":"### 1. Hyperparameter\n\n- \ud29c\ub2dd\uc5d0\ub294 Grid Search\ub97c \uc774\uc6a9\ud558\uc600\uc2b5\ub2c8\ub2e4.","fbf99719":"### 3. Correlation between Continuous Variables\n\n- sqft_living\uc740 \uc2e4\uc9c8\uc801\uc73c\ub85c \uc0b4 \uc218\uc788\ub294 \uacf5\uac04\uc744 \ub73b\ud569\ub2c8\ub2e4.\n\n- sqft_living > sqft_lot\uc778 \uc9d1\uc774 \ub9ce\uc740 \uac83\uc73c\ub85c \ubcf4\uc544, sqft_living\uc740 gross floor area\ub85c \uacc4\uc0b0\uc774 \ub418\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n    - \ub9cc\uc57d \uc5b4\ub5a4 \uc8fc\ud0dd\uc758 1\uce35\uc758 \uba74\uc801\uc774 500\uc774\uace0 2\uce35\uc758 \uba74\uc801\uc774 300\uc774\ub77c\uba74, sqft_living\uc740 800\uc73c\ub85c \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n    - [\ucc38\uace0 \ub9c1\ud06c](https:\/\/www.zillow.com\/blog\/how-to-measure-your-homes-square-footage-92175\/)\n    - \ucd94\uac00\uc801\uc73c\ub85c, sqft_living = sqft_above + sqft_basement\uc774\uba70, sqft_basement\ub294 \uc9c0\ud558\uc2e4\uc758 \uba74\uc801\uc785\ub2c8\ub2e4.\n    - sqft_above = \uc5f0\uba74\uc801(\ubbf8\uad6d\uc5d0\uc120 \ubc14\ub2e5\uba74\uc801)\n    - sqft_living\uc744 \uce35 \uc218\ub85c \ub098\ub204\uc5b4\ub3c4 \uc5ec\uc804\ud788 sqft_lot\ubcf4\ub2e4 \ud070 \uc9d1\ub4e4\uc774 \uc788\uc2b5\ub2c8\ub2e4.\n\n- \uac74\ucd95 \uad00\ub828 \uc218\uce58\ub4e4: \n    - \uac74\ud3d0\uc728(building coverage) = \uac74\ucd95\uba74\uc801 \/ \ub300\uc9c0\uba74\uc801\n    - \uc5f0\uba74\uc801(floor area ratio) = \uc5f0\uba74\uc801(\ubc14\ub2e5\uba74\uc801) \/ \ub300\uc9c0\uba74\uc801\n\n- sqft_lot\uacfc sqft_lot15\uc740 \ub2e8\uc77c \uc18d\uc131\uc73c\ub85c\uc11c price\uc640 \uc0c1\uad00\uad00\uacc4\uac00 \uc801\uc740 \uac83\uc73c\ub85c \ubcf4\uc785\ub2c8\ub2e4.","16fa6cc3":"## EDA\n\n### 1. Check Features","3c430097":"## Preprocessing\n\n- \uc800 \uac19\uc740 \uacbd\uc6b0\uc5d0\ub294 \uc774\uc0c1\uce58\ub97c \uc81c\uac70\ud558\uc9c0 \uc54a\uace0 \ud559\uc2b5\uc744 \uc2dc\ud589\ud558\uc600\uc2b5\ub2c8\ub2e4.\n\n### 1. Feature Engineering\n\n- \uc88c\ud45c\uc640 \uac00\uaca9\ub9cc\uc744 \uac00\uc9c0\uace0 clustering\ud558\ub358 \uc911\uc5d0, __zipcode__\ub97c \uc774\uc6a9\ud55c __\ud3c9\ubc29 \ub300\ube44 \uac00\uaca9(price per footage)__\uc744 \ub2e4\ub8ec Hyun woo Kim\ub2d8\uc758 [kernel](https:\/\/www.kaggle.com\/chocozzz\/house-price-prediction-eda-updated-2019-03-12)\uc744 \ucc38\uace0\ud558\uac8c \ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uac10\uc0ac\ub4dc\ub9bd\ub2c8\ub2e4!\n\n- \uc5f0\ub3c4\ub97c \uc4f0\uc9c0 \uc54a\uace0 2014\ub144 5\uc6d4\ubd80\ud130 2015\ub144 5\uc6d4\uae4c\uc9c0\uc758 \uc2dc\uac04\uc744 \uc5f4 \uc138\ub2ec(1~13)\ub85c \ucabc\uac1c\uc5b4 \uc7ac\uc815\ub82c $\\rightarrow$\n\n- \uac74\ucd95 \uad00\ub828 \uc218\uce58 \ucd94\uac00\n    - floor_area_ratio(sqft_living \/ sqft_lot) \ucd94\uac00 $\\rightarrow$ \uc131\ub2a5 \uc0c1\uc2b9\n    - building_coverage(sqft_above \/ (floor * sqft_lot)) \ucd94\uac00 $\\rightarrow$ \ud6a8\uacfc \uc5c6\uc5c8\uc74c\n    - \uadf8 \uc678 \uc5ec\ub7ec\uac00\uc9c0 \uc2dc\ub3c4\n \n- \uc9c0\ud558\uc2e4 \uc720\ubb34, \ub2e4\ub77d\ubc29 \uc720\ubb34, \uc7ac\uac74\ucd95 \uc720\ubb34 \ub4f1\uc5d0 \ub300\ud55c feature\ub97c \ucd94\uac00\ud560 \uc218\ub3c4 \uc788\uc73c\ub098 \ud6a8\uacfc \uc5c6\uc5c8\uc74c\n    - feature\uc758 \uac1c\uc218\uac00 \ub9ce\uc544\uc838\uc11c model complexity\uac00 \uc99d\uac00\ud558\uba74 overfitting\uc774 \uac15\ub825\ud574\uc9c0\uae30 \ub54c\ubb38\uc73c\ub85c \ucd94\uce21\n    \n- \ubc29 \uad00\ub828 feature \ucd94\uac00\n    - \ubc29 \ucd1d \uac1c\uc218 \ucd94\uac00 $\\rightarrow$ \ud6a8\uacfc \uc5c6\uc5c8\uc74c\n    \n- sqft_lot15 \uc81c\uac70 $\\rightarrow$ **\uc0c1\ud669\ub9c8\ub2e4 \ub2e4\ub978 \uac78\ub85c \uacb0\ub860**\n\n- how_old: \uac74\ubb3c\uc774 \uac74\ucd95\ub418\uace0 \ub9ac\ubaa8\ub378\ub9c1 \ub41c \ud6c4, \ud314\ub9ac\uae30\uae4c\uc9c0 \uac78\ub9b0 \uc2dc\uac04\n\n- yr_renovated \uc81c\uac70\n\n### 2. Log Scaling\n\n- \ud3c9\ubc29 \uad00\ub828 \uc218\uce58\uc5d0 \ub300\ud574 log scaling\n\n### 3. Label Encoding\n\n- zipcode\uc5d0 Label Encoding\n- yr_built = yr_built - 1900 \uc801\uc6a9","cd7f003a":"### 5. Geometry\n\n- Map Visualizing\uc5d0 \ub300\ud574\uc11c TaeJin Kim\ub2d8\uc758 [kernel](https:\/\/www.kaggle.com\/fulrose\/map-visualization-with-folium-ing)\uc744 \ucc38\uace0\ud558\uc600\uc2b5\ub2c8\ub2e4. \ud2b9\ud788 Seattle geojson \ud30c\uc77c \ub9c1\ud06c\uac00 \ub3c4\uc6c0\uc774 \ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uac10\uc0ac\ub4dc\ub9bd\ub2c8\ub2e4!\n- \ud2b9\uc815 \uc9c0\uc5ed\uc758 \uc9d1 \uac00\uaca9\uc774 \ub192\uc74c\uc744 \uad00\ucc30\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.","c9d54a29":"- Shap \ub77c\uc774\ube0c\ub7ec\ub9ac\ub97c \uc774\uc6a9\ud558\uc5ec \uac01 Feature\ub9c8\ub2e4 \ud68c\uadc0\uc5d0 \uc5b4\ub5bb\uac8c \uc601\ud5a5\uc744 \uc8fc\ub294\uc9c0 \ud655\uc778\ud569\ub2c8\ub2e4.\n- \uc8fc\uc758: \ud604\uc7ac Shap \ub77c\uc774\ube0c\ub7ec\ub9ac\uc640 GPU\ub97c \ud568\uaed8 \uc0ac\uc6a9\ud558\uba74 kernel\uc774 \uaebc\uc9c0\ub294 \ud604\uc0c1\uc774 \ubc1c\uc0dd\ud569\ub2c8\ub2e4. Shap\ub97c \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uace0 parameter \ub2e8\uacc4\uc5d0\uc11c \uc8fc\uc11d\ucc98\ub9ac\ub41c tree_method\ub97c \ud65c\uc131\ud654\uc2dc\ud0a4\uba74 GPU\ub97c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.","7313ed85":"### 3. Prediction\n\n- \ub9c8\ucc2c\uac00\uc9c0\ub85c \uc608\uce21\uac12\uc5d0\ub3c4 $\\exp(\\bar{y})-1$\ub97c \ucde8\ud574\uc90d\ub2c8\ub2e4."}}