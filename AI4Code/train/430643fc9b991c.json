{"cell_type":{"750e7a0a":"code","e35219c1":"code","5dfa1701":"code","1d584537":"code","382d9c20":"code","b5c534a8":"code","83742517":"code","a9944aa7":"code","28ccfef1":"code","81b02edb":"code","a9180cba":"code","b2a4b23a":"code","94e67920":"code","678385f5":"code","a5f37d0a":"code","e23d3a0d":"code","eebf3d89":"code","3e689c70":"code","f3348645":"code","9c298123":"code","28ad3f2d":"code","ce3d9d55":"code","275eab34":"code","b5ef67f7":"code","0c72279e":"code","ea4fd5bd":"code","325278be":"code","767eb1e7":"code","a69bc2bf":"code","98c18050":"code","1474bdc9":"code","1fc35e28":"code","ea1383f7":"code","3aa97f8a":"code","f9037bb6":"code","c44d1139":"code","f0561d88":"code","49d121af":"code","60a9e4d7":"code","740ff225":"code","c20b8289":"code","584d1757":"code","ceaeb82c":"code","cbd4ba14":"code","deb49e07":"code","fe670146":"code","0fbfa605":"code","ecddc3dc":"code","3530c1dd":"code","59c69f7b":"code","25372090":"code","31461c04":"code","a8560e9d":"code","9e9117d0":"code","2f7bf785":"code","71e83e18":"code","ec91f2e1":"code","5008f338":"code","076a9532":"code","b9362262":"code","bb0f59ed":"code","65b5fdc0":"code","d553294e":"code","f873abdf":"code","640fdbe5":"code","59d286c4":"code","7d3b1d94":"code","feda1c7c":"code","59473790":"code","8558a40e":"code","b49c8709":"code","6ef73f28":"code","1199f1c0":"code","fcde8b57":"code","bbc0c3cc":"markdown","7bfb62c0":"markdown","bf713c63":"markdown","a804a6ae":"markdown","5f3c3ef2":"markdown","99e6d416":"markdown","10ace214":"markdown","05e4a50b":"markdown","de2ce000":"markdown","e25eb33c":"markdown","8efdccdf":"markdown","0e13e58f":"markdown","11610f9a":"markdown","26cdf70a":"markdown","7df4d580":"markdown","fa26a9a1":"markdown","cb0767b9":"markdown","012e93eb":"markdown","cdec0270":"markdown","15207692":"markdown","642c9d9d":"markdown","f64c968a":"markdown","f20d525e":"markdown","9ef5ee46":"markdown","477fc4c6":"markdown","1d825900":"markdown","d82a8142":"markdown","f78b88e6":"markdown","50c6563f":"markdown"},"source":{"750e7a0a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","e35219c1":"data=pd.read_csv('..\/input\/ilpd-indian-liver-patient-dataset-data-set\/Indian Liver Patient Dataset (ILPD).csv',skiprows = 1)","5dfa1701":"pd.options.display.max_columns=None\npd.options.display.max_rows=None\nnp.set_printoptions(suppress=True)\n","1d584537":"data","382d9c20":"data.shape","b5c534a8":"data.columns","83742517":"data.size","a9944aa7":"data.describe()","28ccfef1":"catcols=['Age','Selector']","81b02edb":"cols = ['Age','Gender','TB_total_bilirubin', 'DB_Direct_Bilirubin',\n       'Alkphos_Alkaline_Phosphotase', 'Sgpt_Alamine_Aminotransferase',\n       'Sgot_Aspartate_Aminotransferase', 'TP_Total_Protiens', 'ALB_Albumin',\n       'A\/G_Ratio','Selector']","a9180cba":"len(cols)","b2a4b23a":"data.columns = cols","94e67920":"data","678385f5":"print(\"The Categorical Columns in this dataset are:\")\nfor i in catcols:\n    print(i)","a5f37d0a":"data.columns","e23d3a0d":"numcols=['TB_total_bilirubin', 'DB_Direct_Bilirubin',\n       'Alkphos_Alkaline_Phosphotase', 'Sgpt_Alamine_Aminotransferase',\n       'Sgot_Aspartate_Aminotransferase', 'TP_Total_Protiens', 'ALB_Albumin',\n       'A\/G_Ratio']","eebf3d89":"print('The numerical columns in this dataset are:')\nfor i in numcols:\n    print(i,end=' ')","3e689c70":"for i in numcols:\n    print('\\n',i)\n    print(\"1st quantile:\",data[i].quantile(0.25),\"\\nThird quantile:\",data[i].quantile(0.75),\"\\nMedian:\",data[i].quantile(0.5),\"\\nIQR:\",data[i].quantile(0.75)-data[i].quantile(0.25),'\\nUpper Whisker:',data[i].quantile(0.75)+1.5*(data[i].quantile(0.75)-data[i].quantile(0.25)),'\\nLower Whisker:',data[i].quantile(0.25)-1.5*(data[i].quantile(0.75)-data[i].quantile(0.25)))","f3348645":"pd.crosstab(data['Gender'],data['Selector'])","9c298123":"print('The number of Male observations are:',len(data[data['Gender']=='Male']),'\\nThe number of Female observations are:',len(data[data['Gender']=='Female']))","28ad3f2d":"print('The number of patients with liver disease are:',len(data[data['Selector']==1]),'\\nThe number of patients without liver disease are:',len(data[data['Selector']==2]))","ce3d9d55":"data.isnull().sum()","275eab34":"print(round(data['A\/G_Ratio'].mean(),2))\nprint(round(data['A\/G_Ratio'].median(),2))","b5ef67f7":"data['A\/G_Ratio'].fillna(round(data['A\/G_Ratio'].mean(),2),inplace=True)","0c72279e":"data.isnull().sum()","ea4fd5bd":"data['Gender']=data['Gender'].map(lambda x: 0 if x=='Female' else 1)\n","325278be":"data['Gender'].value_counts()","767eb1e7":"data['Selector']=data['Selector'].map(lambda x: 0 if x==2 else x)","a69bc2bf":"features=list(data.select_dtypes(exclude=['object']))\nfeatures","98c18050":"data_columns=list(data.select_dtypes(exclude=['object']))\ndata_columns.pop(0)\ndata_columns.pop(-1)\nfig=plt.subplots(figsize=(15,30))\nfor i, j in enumerate(data_columns):\n    plt.subplot(4, 2, i+1),\n    plt.subplots_adjust(hspace = 1.0)\n    sns.boxplot(data[j])\n    plt.title(j)","1474bdc9":"pd.crosstab(data['Gender'],data['Selector']).plot(kind='bar')","1fc35e28":"data['Gender'].value_counts()","ea1383f7":"X=data.drop('Selector',axis=1)\ny=data['Selector']","3aa97f8a":"from sklearn.model_selection import train_test_split","f9037bb6":"Xtrain,Xtest,ytrain,ytest=train_test_split(X,y,test_size=0.3,random_state=1)","c44d1139":"len(ytrain[ytrain==1])","f0561d88":"len(ytrain[ytrain==2])","49d121af":"sns.kdeplot(data['Age'],shade=True)","60a9e4d7":"data.columns","740ff225":"\nfacet= sns.FacetGrid(data,hue=\"Selector\", aspect=3)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, data['Age'].max()))\nfacet.add_legend()\nplt.xlim(-10)\n\nfacet= sns.FacetGrid(data,hue=\"Selector\", aspect=3)\nfacet.map(sns.kdeplot,'TB_total_bilirubin',shade= True)\nfacet.set(xlim=(0, data['TB_total_bilirubin'].max()))\nfacet.add_legend()\nplt.xlim(-5)\n\nfacet= sns.FacetGrid(data,hue=\"Selector\", aspect=3)\nfacet.map(sns.kdeplot,'DB_Direct_Bilirubin',shade= True)\nfacet.set(xlim=(0, data['DB_Direct_Bilirubin'].max()))\nfacet.add_legend()\nplt.xlim(-5)\n\nfacet= sns.FacetGrid(data,hue=\"Selector\", aspect=3)\nfacet.map(sns.kdeplot,'Alkphos_Alkaline_Phosphotase',shade= True)\nfacet.set(xlim=(0, data['Alkphos_Alkaline_Phosphotase'].max()))\nfacet.add_legend()\nplt.xlim(0)\n\nfacet= sns.FacetGrid(data,hue=\"Selector\", aspect=3)\nfacet.map(sns.kdeplot,'Sgpt_Alamine_Aminotransferase',shade= True)\nfacet.set(xlim=(0, data['Sgpt_Alamine_Aminotransferase'].max()))\nfacet.add_legend()\nplt.xlim(0)\n\nfacet= sns.FacetGrid(data,hue=\"Selector\", aspect=3)\nfacet.map(sns.kdeplot,'Sgot_Aspartate_Aminotransferase',shade= True)\nfacet.set(xlim=(0, data['Sgot_Aspartate_Aminotransferase'].max()))\nfacet.add_legend()\nplt.xlim(0)\n\nfacet= sns.FacetGrid(data,hue=\"Selector\", aspect=3)\nfacet.map(sns.kdeplot,'TP_Total_Protiens',shade= True)\nfacet.set(xlim=(0, data['TP_Total_Protiens'].max()))\nfacet.add_legend()\nplt.xlim(0)\n\nfacet= sns.FacetGrid(data,hue=\"Selector\", aspect=3)\nfacet.map(sns.kdeplot,'ALB_Albumin',shade= True)\nfacet.set(xlim=(0, data['ALB_Albumin'].max()))\nfacet.add_legend()\nplt.xlim(0)\n\nfacet= sns.FacetGrid(data,hue=\"Selector\", aspect=3)\nfacet.map(sns.kdeplot,'A\/G_Ratio',shade= True)\nfacet.set(xlim=(0, data['A\/G_Ratio'].max()))\nfacet.add_legend()\nplt.xlim(0)","c20b8289":"sns.pairplot(data,hue='Selector')","584d1757":"plt.subplots(figsize=(15,10))\nsns.heatmap(data.corr(),annot=True)","ceaeb82c":"plt.subplots(figsize=(15,10))\nsns.heatmap(data.corr(),annot=True)","cbd4ba14":"from sklearn.model_selection import train_test_split\n","deb49e07":"data","fe670146":"X=data.drop('Selector',axis=1)\ny=data['Selector']","0fbfa605":"Xtrain,Xtest,ytrain,ytest=train_test_split(X,y,test_size=0.3,random_state=1)","ecddc3dc":"from scipy.stats import f_oneway\n","3530c1dd":"f_oneway(y,ytrain,ytest)","59c69f7b":"from sklearn.linear_model import LogisticRegression","25372090":"logreg=LogisticRegression()","31461c04":"base_model=logreg.fit(Xtrain,ytrain)","a8560e9d":"ypredtest=base_model.predict(Xtest)\nypredtrain=base_model.predict(Xtrain)","9e9117d0":"from sklearn import metrics","2f7bf785":"print(metrics.accuracy_score(ytrain,ypredtrain))\nprint(metrics.accuracy_score(ytest,ypredtest))","71e83e18":"print('TRAIN')\nprint(metrics.classification_report(ytrain,ypredtrain))\nprint(\"TEST\")\nprint(metrics.classification_report(ytest,ypredtest))","ec91f2e1":"print('TRAIN')\nprint(metrics.confusion_matrix(ytrain,ypredtrain))\nprint('TEST')\nprint(metrics.confusion_matrix(ytest,ypredtest))","5008f338":"f,ax=plt.subplots(1,2,figsize=(18,6))\nsns.heatmap(metrics.confusion_matrix(ytrain,ypredtrain),annot=True,ax=ax[0])\n\nsns.heatmap(metrics.confusion_matrix(ytest,ypredtest),annot=True,ax=ax[1])\nplt.title('Test')","076a9532":"cm = metrics.confusion_matrix(ytest, ypred) \nprint('Confusion matrix:\\n',cm)\nconf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\nconf_matrix","b9362262":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\n# scaling the train set\nXtrainScaled = sc.fit_transform(Xtrain)\n# scaling the test set\nXtestScaled = sc.fit_transform(Xtest)\n\nfrom sklearn.linear_model import LogisticRegression\nmodel_scaled = LogisticRegression()\nmodel_scaled.fit(XtrainScaled, ytrain)\n\nypred_scaled = model_scaled.predict(XtestScaled)","bb0f59ed":"print(\"Accuracy Score\\n\")\nprint(metrics.accuracy_score(ytest,ypred_scaled))\nprint(\"\\nClassification Report\\n\")\nprint(metrics.classification_report(ytest,ypred_scaled))\nprint(\"\\nConfusion Matrix\\n\")\nprint(metrics.confusion_matrix(ytest,ypred_scaled))\nprint('\\nKappa Score\\n')\nmetrics.cohen_kappa_score(ytest,ypred_scaled)","65b5fdc0":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_curve, auc\n\nfpr, tpr, thresholds = roc_curve(ytest,ypred_scaled)\nroc_auc = auc(fpr, tpr)\n\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()","d553294e":" from sklearn.tree import DecisionTreeClassifier\n    \nfrom sklearn.tree import export_graphviz\nfrom IPython.display import Image  \n\n!pip install graphviz\n\nclf = DecisionTreeClassifier(criterion='entropy' or 'gini')\nmodel_tree = clf .fit(Xtrain, ytrain)","f873abdf":"#Predict the response for test dataset\nypredTree = model_tree.predict(Xtest)\n\n","640fdbe5":"print(\"Accuracy Score\\n\")\nprint(metrics.accuracy_score(ytest,ypredTree))\nprint(\"\\nClassification Report\\n\")\nprint(metrics.classification_report(ytest,ypredTree))\nprint(\"\\nConfusion Matrix\\n\")\nprint(metrics.confusion_matrix(ytest,ypredTree))\nprint('\\nKappa Score\\n')\nmetrics.cohen_kappa_score(ytest,ypredTree)","59d286c4":"from sklearn.ensemble import RandomForestClassifier\n\n#Create a Gaussian Classifier\nRandomForest_model=RandomForestClassifier(n_estimators=100)\n\nRandomForest_model.fit(Xtrain,ytrain)\ny_pred_Forest=RandomForest_model.predict(Xtest)\n","7d3b1d94":"print(\"Accuracy Score\\n\")\nprint(metrics.accuracy_score(ytest,y_pred_Forest))\nprint(\"\\nClassification Report\\n\")\nprint(metrics.classification_report(ytest,y_pred_Forest))\nprint(\"\\nConfusion Matrix\\n\")\nprint(metrics.confusion_matrix(ytest,y_pred_Forest))\nprint('\\nKappa Score\\n')\nmetrics.cohen_kappa_score(ytest,y_pred_Forest)","feda1c7c":"from xgboost import XGBClassifier\nXGBmodel=XGBClassifier(random_state=10, n_jobs=-1, learning_rate=0.1,\n                  n_estimators=100, max_depth=3)\nXGBmodel = XGBmodel.fit(Xtrain,ytrain)\ny_pred_XGB = XGBmodel.predict(Xtest)","59473790":"print(\"Accuracy Score\\n\")\nprint(metrics.accuracy_score(ytest,y_pred_XGB))\nprint(\"\\nClassification Report\\n\")\nprint(metrics.classification_report(ytest,y_pred_XGB))\nprint(\"\\nConfusion Matrix\\n\")\nprint(metrics.confusion_matrix(ytest,y_pred_XGB))\nprint('\\nKappa Score\\n')\nmetrics.cohen_kappa_score(ytest,y_pred_XGB)","8558a40e":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state = 1)\nfrom sklearn.neighbors import KNeighborsClassifier\nmodel_KNN = KNeighborsClassifier(n_neighbors = 3)\n\nmodel_KNN.fit(X,y)\nypred_KNN = model_KNN.predict(X)\n","b49c8709":"print(\"Accuracy Score\\n\")\nprint(metrics.accuracy_score(y,ypred_KNN))\nprint(\"\\nClassification Report\\n\")\nprint(metrics.classification_report(y,ypred_KNN))\nprint(\"\\nConfusion Matrix\\n\")\nprint(metrics.confusion_matrix(y,ypred_KNN))\nprint('\\nKappa Score\\n')\nmetrics.cohen_kappa_score(y,ypred_KNN)","6ef73f28":"XScaled = sc.fit_transform(X)","1199f1c0":"model_KNN_scaled = KNeighborsClassifier(n_neighbors = 3)\n\nmodel_KNN_scaled.fit(XScaled,y)\nypred_KNN_scaled = model_KNN_scaled.predict(XScaled)","fcde8b57":"print(\"Accuracy Score\\n\")\nprint(metrics.accuracy_score(y,ypred_KNN_scaled))\nprint(\"\\nClassification Report\\n\")\nprint(metrics.classification_report(y,ypred_KNN_scaled))\nprint(\"\\nConfusion Matrix\\n\")\nprint(metrics.confusion_matrix(y,ypred_KNN_scaled))\nprint('\\nKappa Score\\n')\nmetrics.cohen_kappa_score(y,ypred_KNN_scaled)","bbc0c3cc":"**Changes from the Base Model**: From the base model we have scaled the data for better performance of the KNN model to validate.","7bfb62c0":"We will now try to improvise our model.","bf713c63":"From the above Correlation plot,we can see that the variables \n\nTB_total_bilirubin and DB_direct_Bilirubin,\n\nALB_albumin and TP_total_proteins,\n\nA\/G_Ratio and ALB_albumin,\n\nsgot_Aspartate_Aminotransferase and Sgpt_Alamine_Aminotransferase have a strong positive relationship.","a804a6ae":"From the above contingency table,\n\nThe number of females who are affected by liver disease are 92, and the females who are not affected are 50\n\nThe number of males who are affected by liver disease are 324, and the males who are not affected are 117","5f3c3ef2":"## KNN Scaled","99e6d416":"**Business Interpretation**: The health industry can concentrate more on reducing the true negatives of the instances. Here, in our model. 5% of the patients are misclassified as true negatives and it can be further reduced using a better infrastructure, more instances of the patients and better algorithms.\n\n","10ace214":"## XGBoost","05e4a50b":"#### Since the p-value is close to 1, it proves that the both Train and test represents the overall data.","de2ce000":"Now, lets change the target variable value to 1 and 0 instead of 1 and 2, to make it binary","e25eb33c":"### 4.Summarize relationships among variables","8efdccdf":"**Key Risks**: Although Our model has an accuracy of 85% with a recall score of 92%, we have not eliminated all of the True Negatives(Type II Error). 5 out of 100 instances would be misclassified and it is a situation which needs to be taken care of.","0e13e58f":"Our accuracy and other parameters have gone down,but Kappa score has shown a rise with Decisions Tree.","11610f9a":"### 3.Check for defects in the data. Perform necessary actions to \u2018fix\u2019 these defects","26cdf70a":"The target is distributed almost evenly with 70-30 split of the target variable","7df4d580":"In this model, we will try to get rid of the TRUE NEGATIVES(8) since it is the most dangerously misclassified. Our model has predicted that the patient doesnt have a liver disease, but the patient is having a liver disease. This mioght leas to the death and is a serious thing to be considered.","fa26a9a1":"## Decision Tree","cb0767b9":"### Summarize as follows","012e93eb":"#### We got a training accuracy of 74% and a test accuracy of 71%\nThis is a base model and we cannot rely on this. This is a very moderate model.","cdec0270":"Our model has improved on the accuracy, but we will proceed with other algorithms to find out the best.","15207692":"With KNN, we have got the highest accuracy and we have eliminated more True negatives with a recall score of 91%. The Kappa Score has also shown a good valuev of 0.58\n\nNow, We will try to improvise KNN with scaled Data\n","642c9d9d":"***From the above plot, we will talk about each and every feature which are associated with our target variable***\n\n**Age**: Patients with Age above 20 are found to be having liver disease, this is probably due to the drinking habits.\n\n**TB_total_bilirubin**: Healthy patients are observed to be having lesser TB_total_bilirubin value(less than 10). For patients with liver disease, the value ranges from 0 to 70 and beyond. So higher TB_total_bilirubin value for a patient will cause a liver disease.\n\n**DB_Direct_Bilirubin**: This is the same case as the above. Where, lesser value indicates a healthy patient and a higher value indicates a patient with lvier disease\n\n**Alkphos_Alkaline_Phosphotase**: Higher value of Alkphos_Alkaline_Phosphotase indicates a problem with the liver of a patient.\n\n**Sgpt_Alamine_Aminotransferase**: SGPT levels are increased when there is a damage in the liver. Here, in our plot, patients with liver disease have higher value and patients with lower value(<250) are not affected\n\n**Sgot_Aspartate_Aminotransferase**: Higher SGOT value suggests a damage in the liver. Our graph clearly displays the difference in the values of a patient with and without liver disease\n\n**TP_Total_Protiens,ALB_Albumin,A\/G_Ratio**: All these value show a similar distribution with small changes. Still we are considering this in our analysis.","f64c968a":"We now, fill the null value with mean of 'A\/G_Ratio'","f20d525e":"## Random Forest","9ef5ee46":"From the above observation, we can see that there are four null values in the column 'A\/G_Ratio'","477fc4c6":"**Overall Fit of the model**:After scaling the data, we have got the highest accuracy with KNN and we have eliminated more True negatives with a recall score of 92%. The Kappa Score has also shown a good rise from the KNN model without scaled, where we can completely rely on the model\n\nHence, We can conclude that the KNN(scaled) has performed the best out of all the algorithms.","1d825900":"The Cohen Kappa Score is found to be very less(0.18) and we can slightly agree on the predictions from the model.","d82a8142":"## K Nearest Neighbors","f78b88e6":"Now, the null values as been removed. We will now check for the outliers.","50c6563f":"### Split dataset into train and test (70:30)"}}