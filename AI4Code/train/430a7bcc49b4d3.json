{"cell_type":{"0a2ea278":"code","eb707480":"code","ac72dc38":"code","1e35f63f":"code","df2b915b":"code","06246dc2":"code","c5d78af9":"code","e82c3a73":"code","7e69e231":"code","73f8fc9c":"code","9ae59efe":"code","6a18e82e":"code","cea5abb7":"code","f381f21d":"code","fb43d30a":"code","e7ce1f34":"markdown","1e96ad22":"markdown","5679da7d":"markdown","c9431944":"markdown","0a9a4d3d":"markdown","2a2a04bc":"markdown","898943f8":"markdown","1aa9bc92":"markdown","cabe8d24":"markdown","a90b209c":"markdown","f16f9b34":"markdown","85732820":"markdown"},"source":{"0a2ea278":"import numpy as np\nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib import patches\nfrom PIL import Image\n\nimport os\nfrom tqdm import tqdm\nfrom IPython.display import clear_output\n\nimport torch\nimport torchvision\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor","eb707480":"DATA_PATH = '..\/input\/nfl-impact-detection'","ac72dc38":"def add_bboxes(ax, img, img_df):\n    img_data = img_df[img_df['image'] == img]\n    for i in range(img_data.shape[0]):\n        data = img_data.iloc[i]\n        bbox = patches.Rectangle((\n            data['left'],\n            data['top']),\n            data['width'],\n            data['height'],\n            linewidth=1,\n            edgecolor='r',\n            facecolor='None',\n            alpha=0.7\n        )\n        ax.add_patch(bbox)\n    return\n\ndef plot_random_images(root_path, plot_bboxes=True, verbose=True):\n   \n    images_path = root_path + '\/images\/'\n    img_labels_df = pd.read_csv(root_path + '\/image_labels.csv')\n    \n    images_list = os.listdir(images_path)\n    n_images = len(images_list)\n    endzone_images = [image for image in images_list if 'Endzone' in image]\n    sideline_images = [image for image in images_list if 'Sideline' in image]\n\n    if verbose:\n        print(f'There are {n_images} images in the `images` folder.')\n        print(f'  {len(endzone_images)} - images from endzone.')\n        print(f'  {len(sideline_images)} - images from sideline.')\n\n    fig, ax = plt.subplots(4, 2, figsize=(14, 12))\n    for i in range(4):\n        for j in range(2):\n            if j == 0:\n                random_idx = np.random.randint(len(endzone_images))\n                random_img_name = endzone_images[random_idx]\n                random_img = Image.open(images_path + random_img_name)\n            else:\n                random_idx = np.random.randint(len(sideline_images))\n                random_img_name = sideline_images[random_idx]\n                random_img = Image.open(images_path + random_img_name)\n            ax[i][j].imshow(random_img)\n            ax[i][j].set_axis_off()\n            if plot_bboxes:\n                add_bboxes(ax[i][j], random_img_name, img_labels_df)\n\n    ax[0][0].set_title('Endzone images')\n    ax[0][1].set_title('Sideline images')\n    fig.tight_layout()","1e35f63f":"plot_random_images(DATA_PATH, plot_bboxes=True, verbose=True)","df2b915b":"img_labels_df = pd.read_csv(DATA_PATH + '\/image_labels.csv')\nplt.figure(figsize=(12, 6))\nimg_labels_df.label.hist()","06246dc2":"class HelmetsDataset(object):\n    \n    def __init__(self, root_path):\n        self.root_path = root_path\n        self.images_list = os.listdir(os.path.join(root_path, 'images'))\n        self.images_df = pd.read_csv(os.path.join(root_path, 'image_labels.csv'))\n        self.labels_dict = {'Helmet': 1,\n                           'Helmet-Blurred': 2,\n                           'Helmet-Difficult': 3,\n                           'Helmet-Sideline': 4,\n                           'Helmet-Partial': 5}\n        \n    def __getitem__(self, idx):\n        img_path = os.path.join(self.root_path, 'images', self.images_list[idx])\n        img = np.array(Image.open(img_path)) \/ 255\n        img = np.moveaxis(img, 2, 0) # to [C, H, W]\n        \n        # Collect data about boxes and helmet labels from `image_labels.csv`\n        img_data_df = self.images_df[self.images_df['image'] == self.images_list[idx]]     \n        n_bboxes = img_data_df.shape[0]\n        bboxes = []\n        labels = []\n        for i in range(n_bboxes):\n            img_data = img_data_df.iloc[i]\n            x_min = img_data.left\n            x_max = img_data.left + img_data.width\n            y_min = img_data.top\n            y_max = img_data.top + img_data.height\n            bboxes.append([x_min, y_min, x_max, y_max])\n            label = self.labels_dict[img_data.label]\n            labels.append(label)\n         \n        # Convert data to tensors\n        img = torch.as_tensor(img, dtype=torch.float32)    \n        bboxes = torch.as_tensor(bboxes, dtype=torch.float32)\n        labels = torch.as_tensor(labels, dtype=torch.int64)\n        image_id = torch.tensor([idx])\n        \n        target = {}\n        target['boxes'] = bboxes\n        target['labels'] = labels\n        target['image_id'] = image_id\n        \n        return img, target\n    \n    def __len__(self):\n        return len(self.images_list)","c5d78af9":"def get_model(n_classes=6):\n    # model pretrained on COCO dataset\n    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n    # original number of features in classifier head\n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n    # adapting number of classes\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, n_classes)\n    return model","e82c3a73":"def forward_train(model, data, device):\n    imgs, targets = data\n    imgs = [image.to(device) for image in imgs]\n    targets = [{k: v.to(device) for k, v in tgt.items()} for tgt in targets]\n    \n    loss_dict = model(imgs, targets) \n    losses = sum(loss for loss in loss_dict.values())\n    \n    return losses","7e69e231":"# One more helper function in order to handle batches with different shapes\ndef collate_fn(batch):\n    return tuple(zip(*batch))","73f8fc9c":"BATCH_SIZE = 8 # Here I am use small batch size in order to avoid kernel crash\nN_TEST = 100\n\ndataset = HelmetsDataset(DATA_PATH)\n\n\n# train and test split\nidxs = torch.randperm(len(dataset)).tolist()\ndataset_train = torch.utils.data.Subset(dataset, idxs[:-N_TEST])\ndataset_test = torch.utils.data.Subset(dataset, idxs[-N_TEST:])\n                      \ntrain_dataloader = torch.utils.data.DataLoader(dataset_train,\n                                               batch_size=BATCH_SIZE,\n                                               shuffle=True,\n                                               num_workers=4,\n                                               collate_fn=collate_fn)\n                      \ntest_dataloader = torch.utils.data.DataLoader(dataset_test,\n                                               batch_size=BATCH_SIZE,\n                                               shuffle=True,\n                                               num_workers=4,\n                                               collate_fn=collate_fn)","9ae59efe":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nprint(f'Device: {device}')\nmodel = get_model()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\nmodel.to(device)","6a18e82e":"N_ITERS = 100\n\n\nprogress_bar = tqdm(range(N_ITERS))\ntr_it = iter(train_dataloader)\nloss_log = []\niterations = []\n\nfor i in progress_bar:\n    try:\n        data = next(tr_it)\n    except StopIteration:\n        tr_it = iter(train_dataloader)\n        data = next(tr_it)\n    model.train()\n    torch.set_grad_enabled(True)\n    \n    losses = forward_train(model, data, device)\n    \n    optimizer.zero_grad()\n    losses.backward()\n    optimizer.step()\n        \n    loss_log.append(losses.item())\n    iterations.append(i)\n    progress_bar.set_description(f'batch loss: {losses.item()}, average loss: {np.mean(loss_log)}.')\n    \n    clear_output(True)\n    plt.plot(iterations, loss_log)\n    plt.show()","cea5abb7":"def plot_detected_bboxes(test_img, predictions, n_to_plot=2, score_threshold=0.5):\n    \n    n = min(len(test_img), n_to_plot)\n    \n    fig, ax = plt.subplots(1, n, figsize=(16, 8))\n    \n    for i in range(n):\n        img = np.asarray(test_img[i].cpu().numpy() * 255, dtype=np.int64)\n        img = np.moveaxis(img, 0, 2)\n        img = Image.fromarray(np.uint8(img)).convert('RGB')\n        ax[i].imshow(img)\n        ax[i].set_axis_off()\n\n        bboxes = predictions[i]['boxes'].cpu().numpy()\n        scores = predictions[i]['scores'].cpu().numpy()\n        scores_mask = scores > score_threshold\n        for bbox in bboxes[scores_mask]:\n            patch = patches.Rectangle(\n                (bbox[0], bbox[1]),\n                bbox[2] - bbox[0], bbox[3] - bbox[1],\n                linewidth=1,\n                edgecolor='b',\n                facecolor='None',\n                alpha=0.8)\n            ax[i].add_patch(patch)  \n        \n    fig.tight_layout()\n    return ","f381f21d":"model.eval()\ntorch.set_grad_enabled(False)\n\ntest_it = iter(test_dataloader)","fb43d30a":"test_img, test_gt  = next(test_it)\ntest_img = [image.to(device) for image in test_img]\n\npredictions = model(test_img)\n\nplot_detected_bboxes(test_img, predictions,\n                     n_to_plot=4,\n                     score_threshold=0.6)","e7ce1f34":"## Possible steps to continue:\n1. Explore helmets visibility labels influence on model performance (try training only on a nicely visible helmets or not separating visibility at all).\n2. Try another backbone model.\n3. Experiment with optimizer, learning rate schedule, batch size, number or iterations, etc.\n4. Add data augmentations.\n5. Try RetinaNet, YOLO or some different detector arcitecture.\n6. Optimize data loader to make it faster.","1e96ad22":"## 1. Brief images exploration:\nFirst let's plot some random images with corresponding helmet bounding-boxes.","5679da7d":"## 2. Finetune Faster R-CNN","c9431944":"Now let's prepare train and test datasets:","0a9a4d3d":"Now let's write a helper function to build a model that fits our number of classes. Notice that here are 5 classes of helmets and class 0 that corresponds to the background, which makes 6 classes in total. <br>\nAs we are aiming to finetune, we can use Faster R-CNN pretrained on COCO dataset, change number of classes in its head and train it:","2a2a04bc":"# In these notebook I am going to finetune Faster R-CNN model for helmets detection.\n\n* In the first part I briefly explore the images data.\n* Next I finetune baseline helmet detection model based on Faster R-CNN in PyTorch.\n* Finally I evaluate and visualize some results of the detection model.","898943f8":"## 3. Model evaluation:\nAfter small training we can inspect result of helmet detection on test data. ","1aa9bc92":"First let's implement class for data handling that fits PyTorch Faster R-CNN implementation's needs:","cabe8d24":"Now let's check the helmet visibility classes distribution:","a90b209c":"Seems it works fine even after such a small training. <br>\nPlease upvote if you find it helpful.\n","f16f9b34":"So, for the baseline we are going to detect 5 helmet classes, but it may be better to drop some of the rare classes or not to separate them at all. This is a question for further investigation. ","85732820":"---"}}