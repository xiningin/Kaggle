{"cell_type":{"9c75976e":"code","7daf6fb1":"code","05dfa237":"code","b4ff6fd5":"code","7086dd22":"code","1d6db14e":"code","0bed839d":"code","fc66a396":"code","7e448391":"code","f6d3d89e":"code","5b660246":"code","30c3b9c8":"code","9947ff22":"code","9fd36606":"code","a176153a":"code","bacc1577":"code","33c6bb6b":"code","0646fcac":"code","58469543":"code","ad70decf":"code","3bda3f2a":"code","d2e5e786":"code","a4758b5f":"code","93c2710b":"code","fd1c2e81":"code","ff81ce2e":"code","e1c77c5b":"code","22858ad9":"code","d5d657e5":"code","b3aebe5a":"code","1bfffeb6":"code","6c77fc24":"code","1b206eb6":"code","593df764":"code","4ac44114":"code","9ec5b395":"code","ca6cdf39":"code","65094db1":"code","d0f08fdd":"code","a14776d0":"code","61548f7a":"code","567b5fa4":"code","8468d935":"code","220bf794":"code","3a58c908":"code","c7a18c6c":"code","18f6ce54":"code","8f0a5cb0":"code","231d1901":"code","205e40b0":"code","a67f754f":"code","d1266626":"code","63cbb98e":"code","549fb60d":"code","92cfbce2":"markdown","12003da3":"markdown","adc2e728":"markdown","c6072693":"markdown","34c22510":"markdown","98a5595a":"markdown","347f8037":"markdown","50a6e06c":"markdown","f300dc4d":"markdown","2d67036c":"markdown"},"source":{"9c75976e":"!pip install bert-for-tf2","7daf6fb1":"import numpy as np\nimport math\nimport re\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nimport random\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras import layers\nimport bert\nimport plotly.express as px\nfrom wordcloud import WordCloud\nfrom sklearn.model_selection import train_test_split\nimport spacy","05dfa237":"data = pd.read_csv('..\/input\/trip-advisor-hotel-reviews\/tripadvisor_hotel_reviews.csv')\ndata","b4ff6fd5":"sns.heatmap(data.isnull());","7086dd22":"temp = data.describe()\ntemp.style.background_gradient(cmap='Oranges')","1d6db14e":"total = len(data)\nax1 = plt.figure(figsize=(12,5))\n\ng = sns.countplot(x='Rating', data=data)\ng.set_title(\"Evaluation\", fontsize=20)\ng.set_xlabel(\"Evaluation\", fontsize=17)\ng.set_ylabel(\"Values\", fontsize=17)\nsizes = []\nfor p in g.patches:\n    height = p.get_height()\n    sizes.append(height)\n    g.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}%'.format(height\/total*100),\n            ha=\"center\", fontsize=10) \ng.set_ylim(0, max(sizes) * 1.1)","0bed839d":"data['Rating'] = data['Rating'].apply(lambda x: 1 if x >= 2 else 0) ","fc66a396":"positive = data[data['Rating'] == 1 ]\nnegative = data[data['Rating'] == 0]","7e448391":"plt.rcParams['figure.figsize'] = (10, 10)\nplt.style.use('fast')\n\nwc = WordCloud(background_color = 'orange', width = 1500, height = 1500).generate(str(positive['Review']))\nplt.title('Description Positive', fontsize = 15)\n\nplt.imshow(wc)\nplt.axis('off')\nplt.show()","f6d3d89e":"plt.rcParams['figure.figsize'] = (10, 10)\nplt.style.use('fast')\n\nwc = WordCloud(background_color = 'orange', width = 1500, height = 1500).generate(str(negative['Review']))\nplt.title('Description Negative', fontsize = 15)\n\nplt.imshow(wc)\nplt.axis('off')\nplt.show()","5b660246":"data.head()","30c3b9c8":"def clean_t(t):\n  t = BeautifulSoup(t, 'lxml').get_text()\n  t = re.sub(r\"@[A-Za-z0-9]+\", ' ', t)\n  t = re.sub(r\"https?:\/\/[A-Za-z0-9.\/]+\", ' ', t)\n  t = re.sub(r\"[^a-zA-Z.!?]\", ' ', t)\n  t = re.sub(r\" +\", ' ', t)\n  return t","9947ff22":"test = '99 ' + data.Review[0]\ntest","9fd36606":"result = clean_t(test)\nresult","a176153a":"data_clean = [clean_t(t) for t in data.Review]","bacc1577":"data_clean[0:4]","33c6bb6b":"FullTokenizer = bert.bert_tokenization.FullTokenizer\nbert_layer = hub.KerasLayer('https:\/\/tfhub.dev\/tensorflow\/bert_en_uncased_L-24_H-1024_A-16\/1', trainable=False)\nvocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\ndo_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\ntokenizer = FullTokenizer(vocab_file, do_lower_case)","0646fcac":"vocab_file","58469543":"len(tokenizer.vocab)","ad70decf":"tokenizer.tokenize('My dog likes strawberries.')","3bda3f2a":"tokenizer.convert_tokens_to_ids(tokenizer.tokenize('My dog likes strawberries.'))","d2e5e786":"def encode_sentence(sent):\n  return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sent))","a4758b5f":"encode_sentence('my dog likes strawberries')","93c2710b":"data_inputs = [encode_sentence(sentence) for sentence in data_clean]","fd1c2e81":"data_inputs[1]","ff81ce2e":"data_labels = data.iloc[:,1].values","e1c77c5b":"data_labels","22858ad9":"data_with_len = [[sent, data_labels[i], len(sent)]\n                 for i, sent in enumerate(data_inputs)]","d5d657e5":"data_with_len[0:2]","b3aebe5a":"random.shuffle(data_with_len)\ndata_with_len.sort(key=lambda x: x[2])\nsorted_all = [(sent_lab[0], sent_lab[1])\n              for sent_lab in data_with_len if sent_lab[2] > 7]","1bfffeb6":"sorted_all[3000:3005]","6c77fc24":"all_dataset = tf.data.Dataset.from_generator(lambda: sorted_all,\n                                             output_types = (tf.int32, tf.int32))","1b206eb6":"next(iter(all_dataset))","593df764":"BATCH_SIZE = 32\nall_batched = all_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))","4ac44114":"next(iter(all_batched))","9ec5b395":"len(sorted_all)","ca6cdf39":"NB_BATCHES = len(sorted_all) \/\/ BATCH_SIZE\nNB_BATCHES","65094db1":"NB_BATCHES_TEST = NB_BATCHES \/\/ 10\nNB_BATCHES_TEST","d0f08fdd":"all_batched.shuffle(NB_BATCHES)\ntest_dataset = all_batched.take(NB_BATCHES_TEST)\ntrain_dataset = all_batched.skip(NB_BATCHES_TEST)","a14776d0":"next(iter(test_dataset))","61548f7a":"next(iter(train_dataset))","567b5fa4":"class DCNN(tf.keras.Model):\n\n  def __init__(self,\n               vocab_size,\n               emb_dim=128,\n               nb_filters = 50,\n               FFN_units=512,\n               nb_classes=2,\n               dropout_rate=0.1,\n               training=False,\n               name=\"dcnn\"):\n    super(DCNN, self).__init__(name=name)\n\n    self.embedding = layers.Embedding(vocab_size, emb_dim)\n\n    self.bigram = layers.Conv1D(filters = nb_filters,\n                                kernel_size = 2,\n                                padding='valid',\n                                activation='relu')\n    self.trigram = layers.Conv1D(filters = nb_filters,\n                                kernel_size = 3,\n                                padding='valid',\n                                activation='relu')\n    self.fourgram = layers.Conv1D(filters = nb_filters,\n                                kernel_size = 4,\n                                padding='valid',\n                                activation='relu')\n    \n    self.pool = layers.GlobalMaxPool1D()\n\n    self.dense_1 = layers.Dense(units = FFN_units, activation='relu')\n    self.dropout = layers.Dropout(rate=dropout_rate)\n    if nb_classes == 2:\n      self.last_dense = layers.Dense(units=1, activation='sigmoid')\n    else:\n      self.last_dense = layers.Dense(units=nb_classes, activation='softmax')\n\n  def call(self, inputs, training):\n    x = self.embedding(inputs)\n    x_1 = self.bigram(x)\n    x_1 = self.pool(x_1)\n    x_2 = self.trigram(x)\n    x_2 = self.pool(x_2)\n    x_3 = self.fourgram(x)\n    x_3 = self.pool(x_3)\n\n    merged = tf.concat([x_1, x_2, x_3], axis = -1)\n    merged = self.dense_1(merged)\n    merged = self.dropout(merged, training)\n    output = self.last_dense(merged)\n\n    return output","8468d935":"VOCAB_SIZE = len(tokenizer.vocab)\nEMB_DIM = 200\nNB_FILTERS = 100\nFFN_UNITS = 256\nNB_CLASSES = 2\nDROPOUT_RATE = 0.2\nNB_EPOCHS = 12","220bf794":"Dcnn = DCNN(vocab_size=VOCAB_SIZE,\n            emb_dim=EMB_DIM,\n            nb_filters = NB_FILTERS,\n            FFN_units = FFN_UNITS,\n            nb_classes = NB_CLASSES,\n            dropout_rate = DROPOUT_RATE)","3a58c908":"if NB_CLASSES == 2:\n  Dcnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nelse:\n  Dcnn.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['sparse_categorical_accuracy'])","c7a18c6c":"history = Dcnn.fit(train_dataset,\n                   epochs=NB_EPOCHS)","18f6ce54":"history.history.keys()","8f0a5cb0":"plt.plot(history.history['loss'])\nplt.title('Loss progress');","231d1901":"plt.plot(history.history['accuracy'])\nplt.title('Accuracy progress');","205e40b0":"results = Dcnn.evaluate(test_dataset)\nprint(results)","a67f754f":"def get_prediction(sentence):\n  tokens = encode_sentence(sentence)\n  inputs = tf.expand_dims(tokens, 0)\n  output = Dcnn(inputs, training=False)\n  sentiment = math.floor(output*2)\n  if sentiment == 0:\n    print('negative')\n  elif sentiment == 1:\n    print('positive')","d1266626":"get_prediction('This movie was pretty interesting')","63cbb98e":"get_prediction(\"I'd rather not do that again\")","549fb60d":"get_prediction(\"I don't like you\")","92cfbce2":"# Training","12003da3":"# Processing","adc2e728":"# Database creation","c6072693":"# **Description**\n\n# Abstract\n\nExplore Hotel aspects and Predict the rating of each review.\n\n# About this dataset\n\nHotels play a crucial role in traveling and with the increased access to information new pathways of selecting the best ones emerged.\nWith this dataset, consisting of 20k reviews crawled from Tripadvisor, you can explore what makes a great hotel and maybe even use this model in your travels!\n\n# How to use\n\nPredict Review Rating\nTopic Modeling on Reviews\nExplore key aspects that make hotels good or bad\nAcknowledgements\nIf you use this dataset in your research, please credit the authors.\n\n# Citation\n\nAlam, M. H., Ryu, W.-J., Lee, S., 2016. Joint multi-grain topic sentiment: modeling semantic aspects for online reviews. Information Sciences 339, 206\u2013223.\nDOI\n\n# License\n\nCC BY NC 4.0\n\n# Splash banner\n\nPhoto by Rhema Kallianpur on Unsplash.\n\n# Splash icon\n\nLogo by Tripadvisor.","34c22510":"Now it will depend on the analysis of standards, based on the assessment scores what could be considered a negative assessment.\n\nLet's consider a score less than 2 will be negative, we can consider it to be below 50%.","98a5595a":"# Analyzing the Data","347f8037":"# **If you find this notebook useful, support with an upvote** \ud83d\udc4d","50a6e06c":"# Importing Libraries","f300dc4d":"# Evaluation","2d67036c":"# Model building"}}