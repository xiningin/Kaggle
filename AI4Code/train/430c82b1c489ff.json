{"cell_type":{"cb199502":"code","4268dd86":"code","b8b9e24b":"code","108a47dd":"code","ad6c7f33":"code","75413a01":"code","f48b4da7":"code","7bb1864b":"code","099cc20c":"code","11181ce4":"code","b3e2ed29":"code","a6b17596":"code","ccfd62df":"code","e4c49561":"code","c91cc13c":"code","8ac4cdf8":"code","1c838b34":"markdown","c8229a58":"markdown","6007d2c0":"markdown","61b70fd5":"markdown","9204ab35":"markdown","2f441344":"markdown","2bf62a77":"markdown","19433828":"markdown","5b4b2097":"markdown","121e3050":"markdown","582009d2":"markdown","24d09dac":"markdown","3223f06d":"markdown"},"source":{"cb199502":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4268dd86":"dataframe = pd.read_csv('\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv')\ndataframe.head()","b8b9e24b":"plt.figure(figsize=(12,10))\nsns.heatmap(dataframe.iloc[:,1:32].corr())","108a47dd":"\nX = dataframe.iloc[: ,2:32].values\ny = dataframe.iloc[: ,1].values","ad6c7f33":"print(X)","75413a01":"print(y)","f48b4da7":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values = np.nan, strategy = \"mean\")\nimputer.fit(X)\nX = imputer.transform(X)\nX","7bb1864b":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny = le.fit_transform(y)\ny","099cc20c":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)","11181ce4":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","b3e2ed29":"print(X_train)","a6b17596":"print(X_test)","ccfd62df":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import AdaBoostClassifier\nclassifier = LogisticRegression()\nclassifier_boost = AdaBoostClassifier(n_estimators = 10, base_estimator = classifier, learning_rate = 1)\nboost = classifier_boost.fit(X_train, y_train)","e4c49561":"from sklearn.metrics import accuracy_score\nprint(accuracy_score(boost.predict(X_train),y_train))","c91cc13c":"from sklearn.metrics import accuracy_score, confusion_matrix,classification_report\ncm = confusion_matrix(boost.predict(X_test),y_test)\nprint(\"Confusion Matrix: \\n\",cm,\"\\n\")\nprint(\"Score = \",accuracy_score(y_test,boost.predict(X_test)),\"\\n\")\nprint(classification_report(y_test,boost.predict(X_test)))","8ac4cdf8":"import seaborn as sns\nsns.heatmap(cm, annot=True)","1c838b34":"Importing Libraries","c8229a58":"Logistic regression with adaptive boosting gives a total score of 98.6% which is around 1% more than just LR","6007d2c0":"Importing the file using pandas","61b70fd5":"Train the model using LR and boost the score using Adaptive boost ","9204ab35":"Depending and Independent variable","2f441344":"Analysing the correlation","2bf62a77":"Feature Scaling","19433828":"Train accuracy","5b4b2097":"Filling with missing Data","121e3050":"Encoding Categorical data","582009d2":"## Breast Cancer Diagnosis using Logistic regression","24d09dac":"Test Score","3223f06d":"Split the train and test data"}}