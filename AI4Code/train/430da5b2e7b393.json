{"cell_type":{"2634bf49":"code","e73f89ae":"code","eabd3d5f":"code","ce47b009":"code","1d63c9a6":"code","7d366f36":"code","1919a2e3":"code","98367bae":"code","a5701247":"code","bb2d1eef":"code","6b23ef4b":"code","74d1172d":"code","d93b3e94":"code","2436d22d":"code","27dc13bd":"code","c4afeaa4":"code","b4298b8a":"code","2e4163c3":"code","8ff54157":"code","eee74044":"code","555c7ed1":"code","5d1c5e24":"code","5ab62dcc":"code","556342c0":"code","12a7dbc2":"code","5ba1f7c2":"code","0d645f36":"code","6f7219f9":"code","18dd37b6":"code","b3cbed71":"code","33b91fc1":"code","b26bb6b9":"code","e37da06e":"code","47ec9f8b":"code","9775f782":"code","2a143159":"markdown","e98062e1":"markdown","549542c3":"markdown","1f15adf9":"markdown","dfd36859":"markdown","9404382d":"markdown","0460dd96":"markdown","7e034ead":"markdown","0c8f152e":"markdown","ef228ed7":"markdown","ac51c0c5":"markdown","d37dce67":"markdown","c50651ce":"markdown","7efe86a1":"markdown","4a45828f":"markdown","0c256da8":"markdown","3d0ffda5":"markdown","2faed2e4":"markdown","29774aa9":"markdown","7d08214c":"markdown","106e299a":"markdown","f1de7f9b":"markdown","3ce4fde1":"markdown","b2d214c3":"markdown","e25769a8":"markdown","30ad3e4f":"markdown"},"source":{"2634bf49":"import numpy as np \nimport pandas as pd \nimport sklearn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.datasets import load_digits\nfrom sklearn import metrics\n%matplotlib inline\n\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\n","e73f89ae":"cancer = load_breast_cancer()\ndigits = load_digits()\n\ndata = cancer","eabd3d5f":"data","ce47b009":"df = pd.DataFrame(data= np.c_[data['data'], data['target']],\n                     columns= list(data['feature_names']) + ['target'])\ndf['target'] = df['target'].astype('uint16')","1d63c9a6":"df","7d366f36":"df.head()","1919a2e3":"# adaboost experiments\n# create x and y train\nX = df.drop('target', axis=1)\ny = df[['target']]\n\n# split data into train and test\/validation sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","98367bae":"# check the average cancer occurence rates in train and test data, should be comparable\ny_train.mean(),y_test.mean()","a5701247":"# base estimator: a weak learner with max_depth=2\nshallow_tree = DecisionTreeClassifier(max_depth=2, random_state = 142)","bb2d1eef":"# fit the shallow decision tree \nshallow_tree.fit(X_train, y_train)\n\n# test error\ny_pred = shallow_tree.predict(X_test)\nscore = metrics.accuracy_score(y_test, y_pred)\nscore","6b23ef4b":"# adaboost with the tree as base estimator\n\nestimators = list(range(1, 50, 3))\n\nabc_scores = []\nfor n_est in estimators:\n    ABC = AdaBoostClassifier(base_estimator=shallow_tree, n_estimators = n_est, random_state=101)\n    \n    ABC.fit(X_train, y_train)\n    y_pred = ABC.predict(X_test)\n    score = metrics.accuracy_score(y_test, y_pred)\n    abc_scores.append(score)","74d1172d":"estimators = list(range(1, 50, 3))\n\nabc_scores_train = []\nfor n_est in estimators:\n    ABC = AdaBoostClassifier(base_estimator=shallow_tree, n_estimators = n_est, random_state=101)\n    \n    ABC.fit(X_train, y_train)\n    y_pred = ABC.predict(X_train)\n    score = metrics.accuracy_score(y_train, y_pred)\n    abc_scores_train.append(score)","d93b3e94":"plt.figure(figsize = (10,5))\nplt.grid()\nplt.plot(estimators, abc_scores,label='Test')\nplt.plot(estimators, abc_scores_train,label='Train')\nplt.xlabel('n_estimators')\nplt.ylabel('accuracy')\nplt.ylim([0.85, 1.10])\nplt.legend()\nplt.show()","2436d22d":"import sklearn.metrics\n\nsklearn.metrics.accuracy_score(y_test,ABC.predict(X_test))","27dc13bd":"fpr, tpr, thresholds = sklearn.metrics.roc_curve(y_test,ABC.predict(X_test))\nsklearn.metrics.auc(fpr, tpr)","c4afeaa4":"sklearn.metrics.average_precision_score(y_test,ABC.predict(X_test))","b4298b8a":"sklearn.metrics.balanced_accuracy_score(y_test,ABC.predict(X_test))","2e4163c3":"sklearn.metrics.brier_score_loss(y_test,ABC.predict(X_test))","8ff54157":"print(sklearn.metrics.classification_report(y_test,ABC.predict(X_test)))\n","eee74044":"sklearn.metrics.cohen_kappa_score(y_test,ABC.predict(X_test))","555c7ed1":"print(sklearn.metrics.confusion_matrix(y_test,ABC.predict(X_test)))","5d1c5e24":"sklearn.metrics.f1_score(y_test,ABC.predict(X_test))","5ab62dcc":"sklearn.metrics.fbeta_score(y_test,ABC.predict(X_test),beta=.5)","556342c0":"sklearn.metrics.hamming_loss(y_test,ABC.predict(X_test))","12a7dbc2":"sklearn.metrics.hinge_loss(y_test,ABC.predict(X_test))","5ba1f7c2":"sklearn.metrics.jaccard_score(y_test,ABC.predict(X_test))","0d645f36":"sklearn.metrics.log_loss(y_test,ABC.predict(X_test))","6f7219f9":"sklearn.metrics.matthews_corrcoef(y_test,ABC.predict(X_test))","18dd37b6":"sklearn.metrics.precision_recall_curve(y_test,ABC.predict(X_test))","b3cbed71":"sklearn.metrics.precision_recall_fscore_support(y_test,ABC.predict(X_test))","33b91fc1":"sklearn.metrics.precision_score(y_test,ABC.predict(X_test))","b26bb6b9":"sklearn.metrics.recall_score(y_test,ABC.predict(X_test))","e37da06e":"sklearn.metrics.roc_auc_score(y_test,ABC.predict(X_test))","47ec9f8b":"sklearn.metrics.roc_curve(y_test,ABC.predict(X_test))","9775f782":"sklearn.metrics.zero_one_loss(y_test,ABC.predict(X_test))","2a143159":"# **This Notebook contains all evaluation matrixes available in Scikit-learn python library for a Binary Classification**","e98062e1":"# Average hinge loss","549542c3":"We will use the breast cancer dataset in which the target variable has 1 if the person has cancer and 0 otherwise. Let's load the data.","1f15adf9":"# Accuracy classification score.","dfd36859":"# Precision, Recall, F-measure and Support","9404382d":"# Cohen\u2019s kappa","0460dd96":"# Area Under the Curve (AUC) using the trapezoidal rule","7e034ead":"# Average precision (AP) from prediction scores","0c8f152e":"# Recall","ef228ed7":"# Classification Report","ac51c0c5":"# Balanced accuracy","d37dce67":"# Hamming loss","c50651ce":"# Precision-Recall pairs for different probability thresholds","7efe86a1":"**After particular n_estimators, test accuracy doesn't improve, rather it decreases with n more feature added**","4a45828f":"# Receiver operating Characteristic (ROC)","0c256da8":"# Jaccard similarity coefficient score","3d0ffda5":"# F-beta score","2faed2e4":"#  Area Under the Receiver Operating Characteristic Curve (ROC AUC) ","29774aa9":"# Precision","7d08214c":"# Brier score","106e299a":"# Log loss \/ logistic Loss \/ Cross-Entropy Loss.","f1de7f9b":"# Matthews correlation coefficient (MCC)","3ce4fde1":"# Confusion matrix","b2d214c3":"# F1 score \/ Balanced F-score or F-measure","e25769a8":"# **Evaluation Matrix**","30ad3e4f":"# Zero-one classification loss"}}