{"cell_type":{"b65806e4":"code","43fc79e1":"code","af6bed15":"code","08bc1133":"code","54e34e3b":"code","b6577609":"code","d57225b3":"code","c330e268":"code","37869c61":"code","246fd2fb":"code","ad672bb0":"code","6c532939":"code","500c11e2":"code","5a6bfe0a":"code","574dc4a5":"code","e69199c3":"code","d0922b8b":"code","339af04e":"code","ed6eee66":"code","17fdf578":"code","25d574dd":"code","ad2cc33c":"code","57e358fc":"code","1b4915fd":"code","9ec1d104":"code","cfe3e724":"code","43a8d18c":"code","f08ffda0":"code","ee0b4ce8":"code","db4dbd68":"code","2d326549":"code","77fc37c9":"code","ec32a2f0":"code","7aec1af5":"code","9dae128b":"code","e147e3a8":"code","8c1ecfbe":"code","764fef2d":"code","7c3321ce":"code","6717a58a":"code","cdc1fb9b":"code","91b49f98":"code","030bca65":"code","e2c77d35":"code","65986c6c":"code","fca575c0":"code","a31a8dc8":"code","a698eab5":"code","f690ac26":"code","12d427d7":"code","a9f6ef32":"code","5f3ff3de":"code","3fcd5311":"code","a75225df":"code","3c25a8c6":"code","0146324d":"code","0bf9ad62":"code","14f92b12":"code","dec3de50":"code","d7318590":"code","97467d6a":"code","07933c5d":"code","0240470c":"code","ff2b5e21":"code","c8543c97":"code","5d09ca68":"code","998f2f68":"code","737d67c4":"code","14f441fa":"code","c255a578":"code","0ad887c5":"markdown","5df0935c":"markdown","8c1a3198":"markdown","c377e333":"markdown","81f5bbd0":"markdown","c07db9c9":"markdown","c90cb780":"markdown","6a84d5dd":"markdown","584fc97c":"markdown","9f28df98":"markdown","00de15c5":"markdown","0525fb1e":"markdown","751c4ad7":"markdown","c9c26451":"markdown","2ce1d87c":"markdown","1c5cd24b":"markdown","73ad08d3":"markdown","8cfff34d":"markdown","45f9943f":"markdown","5dafa966":"markdown","8737bcc0":"markdown"},"source":{"b65806e4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings(\"ignore\") # ignore the warnings about file size\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\n%matplotlib inline\nimport seaborn as sns\nfrom time import process_time\n\n# calling our libraries for our models\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import KFold\nfrom math import sqrt\nfrom sklearn import metrics\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.model_selection import validation_curve\nfrom sklearn import preprocessing\nfrom sklearn.dummy import DummyRegressor\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","43fc79e1":"import pandas as pd\n# set option to be able to get each column and row of our dataframes\npd.set_option(\"display.max_columns\", None)\ndata = pd.read_csv('..\/input\/sea-building-energy-benchmarking\/clean_p3 (1).csv',sep='\\t', low_memory=False, index_col=[0])\ndata.tail()","af6bed15":"enc = data[['BuildingType','PrimaryPropertyType','Neighborhood']]\ndata = data.drop(columns=['BuildingType','PrimaryPropertyType','Neighborhood'])","08bc1133":"from sklearn.preprocessing import OneHotEncoder\n\nencoder=OneHotEncoder(handle_unknown='ignore',sparse=False)\n\n# passing our categorical columns (label encoded values)\n\ncategorical_features = pd.DataFrame(encoder.fit_transform(enc))\n\n# label the encoded columns with the features of the original variables\n\ncategorical_features.columns = encoder.get_feature_names(['BuildingType','PrimaryPropertType','Neighborhood'])\n\n# merge with main dataframe\n\nenc_data = data.join(categorical_features, how=\"inner\")\nenc_data","54e34e3b":"# Create the dataframe that will contain all our features for modeling\n\nX = pd.concat([enc_data.loc[:,'PropertyGFATotal':'PropertyGFABuilding(s)'],enc_data.loc[:,'LargestPropertyUseTypeGFA':'NaturalGas(kBtu)'],enc_data.loc[:,'GHGEmissionsIntensity':'Neighborhood_SOUTHWEST']],1).copy()\nX = pd.DataFrame(X)\nX.head()","b6577609":"y = enc_data.loc[:,'TotalGHGEmissions']\ny = pd.DataFrame(y).astype('int32')","d57225b3":"# correlation matrix\nfig, ax = plt.subplots(figsize=(24, 24))\ncorrMatrix = data.corr()\nsns.heatmap(corrMatrix, annot=True)\nplt.show()","c330e268":"X = X.drop(columns=['PropertyGFATotal', 'LargestPropertyUseTypeGFA', 'SiteEnergyUse(kBtu)', 'SteamUse(kBtu)', 'Electricity(kWh)', 'NaturalGas(therms)', 'GHGEmissionsIntensity'])\nX.head()","37869c61":"X = X.drop(columns=['SiteEUI(kBtu\/sf)', 'SiteEUIWN(kBtu\/sf)', 'SourceEUI(kBtu\/sf)', 'SourceEUIWN(kBtu\/sf)', 'SiteEnergyUseWN(kBtu)', 'Electricity(kBtu)', 'NaturalGas(kBtu)'])\nX.head()","246fd2fb":"def plot_feature_importance(importance,names,model_type):\n    \n    #Create arrays from feature importance and feature names\n    feature_importance = np.sort(importance)\n    feature_names = np.array(names)\n    \n    #Create a DataFrame using a Dictionary\n    data={'feature_names':feature_names,'feature_importance':feature_importance}\n    fi_df = pd.DataFrame(data)\n    \n    #Sort the DataFrame in order decreasing feature importance and get the top 10\n    fi_df10 = fi_df.nlargest(10, 'feature_importance')[:10]\n    fi_df10.sort_values(by=['feature_importance'], ascending=False, inplace=True)\n    \n    \n    #Define size of bar plot\n    plt.figure(figsize=(10,8))\n    \n    #Plot Searborn bar chart\n    sns.barplot(x=fi_df10['feature_importance'], y=fi_df10['feature_names'])\n    \n    \n    #Add chart labels\n    plt.title(model_type +  ' FEATURE IMPORTANCE')\n    plt.xlabel('FEATURE IMPORTANCE')\n    plt.ylabel('FEATURE NAMES') ","ad672bb0":"# adding a dummy baseline to our cross-validation\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20)\n\ndummy = DummyRegressor(strategy = 'mean').fit(X_train, y_train)\ny_predict_dummy = dummy.predict(X_test)\n\n# dummy statistical metrics\n\ndummy_test_mse = mean_squared_error(y_test, y_predict_dummy)\ndummy_test_mae = mean_absolute_error(y_test, y_predict_dummy)\ndummy_test_r2 = r2_score(y_test, y_predict_dummy)\ndummy_test_rmse = sqrt(mean_squared_error(y_test, y_predict_dummy))\n\n# cross-validation\n\ncv_dummy = cross_val_score(dummy, X_test, y_predict_dummy, cv=KFold(n_splits=5,shuffle=True), scoring ='neg_mean_squared_error')","6c532939":"from sklearn.linear_model import Ridge\n\n# split our dataset for prediction\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n\n# start timer\nt1_start = process_time()\n\n# call the model\nridge = Ridge(random_state = 20)\n\n# hyperparameters\nridge_params = {'alpha':(0.1, 1, 10, 100)}\n\n# cross validation to tune hyperparameter\ng_ridge = GridSearchCV(ridge, param_grid = ridge_params, cv=KFold(n_splits=5,shuffle=True))\n\n# perform the search\ng_ridge.fit(X_train, y_train)\n\n#Predict the response for test and train datasets\ny_ridge_test_pred = g_ridge.predict(X_test)\ny_ridge_train_pred = g_ridge.predict(X_train)\n\n# mean error square\nridge_test_mae = mean_absolute_error(y_test, y_ridge_test_pred)\nridge_train_mae = mean_absolute_error(y_train, y_ridge_train_pred)\n\n# best hyperparameter\ng_ridge_param = g_ridge.best_params_\n\n# The mean squared error\nridge_test_mse = mean_squared_error(y_test, y_ridge_test_pred)\nridge_train_mse = mean_squared_error(y_train, y_ridge_train_pred)\n\n# The coefficient of determination: 1 is perfect prediction\nridge_test_r2 = r2_score(y_test, y_ridge_test_pred)\nridge_train_r2 = r2_score(y_train, y_ridge_train_pred)\n\n# The root mean squared error\nridge_test_rmse = sqrt(mean_squared_error(y_test, y_ridge_test_pred))\nridge_train_rmse = sqrt(mean_squared_error(y_train, y_ridge_train_pred))\n\n# stop timer\nt1_stop = process_time()\n\n# Elapsed time\nridge_time = t1_stop-t1_start\n\nprint(\"Elapsed time in seconds to run Ridge:\", ridge_time) ","500c11e2":"import optuna\n\ndef objective(trial):\n\n    \n    fit_intercept = trial.suggest_categorical(\"fit_intercept\",choices=[True, False])\n    max_iter = trial.suggest_int(\"n_estimators\", 1, 1000)\n    tol = trial.suggest_float(\"tol\", 0, 0.5)\n    alpha = trial.suggest_float(\"alpha\", 0, 1000)\n    solver = trial.suggest_categorical(\"solver\",choices=[\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"])\n    \n    \n    ## Create Model\n\n    optuna_ridge  = Ridge(fit_intercept=fit_intercept, max_iter=max_iter, tol=tol, alpha=alpha, solver=solver)\n   \n    ## Fit Model\n    \n    optuna_ridge.fit(X_train, y_train)\n\n    return mean_squared_error(y_test, optuna_ridge.predict(X_test))\n    \n\nt1_start = process_time()\n\n\nstudy10 = optuna.create_study(study_name=\"RidgeRegression\")\nstudy10.optimize(objective, n_trials=47)\n\n# evaluation metrics\n\noptuna_ridge_rmse = sqrt(study10.best_value)\noptuna_ridge_mse = study10.best_value\noptuna_ridge_params = study10.best_params\n\n# stop timer\nt1_stop = process_time()\n\n# Elapsed time\nridge_time = t1_stop-t1_start\n\nprint(\"Elapsed time in seconds to run Ridge Regression with Optuna tuning hyperparameters:\", ridge_time)\n\nprint(\"Best Params : {}\".format(optuna_ridge_params))\nprint(\"\\nBest MSE : {}\".format(optuna_ridge_mse))\nprint(\"\\nBest RMSE : {}\".format(optuna_ridge_rmse))\n","5a6bfe0a":"# cross validation\n\ncv_ridge_train = cross_val_score(g_ridge, X_train, y_ridge_train_pred, cv=KFold(n_splits=5,shuffle=True), scoring ='neg_mean_squared_error')\ncv_ridge_test = cross_val_score(g_ridge, X_test, y_ridge_test_pred, cv=KFold(n_splits=5,shuffle=True), scoring ='neg_mean_squared_error')\ncv_ridge_results = pd.DataFrame([-cv_ridge_train, -cv_ridge_test, -cv_dummy]).transpose()\ncv_ridge_results.columns = ['Training Dataset', 'Test Dataset', 'Dummy']\ncv_ridge_results","574dc4a5":"plt.style.use('ggplot')\nsns.set_style('darkgrid')\nbins = np.linspace(start=0, stop=0.1, num=50)\nhist = cv_ridge_results.plot.hist(bins=bins, density=True, edgecolor=\"black\")\nplt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\nplt.xlabel(\"Mean squared error\", size=18)\nplt.ylabel(\"Frequency\", size=18)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n_ = plt.title(\"Cross-validation testing errors\", size=28, y=1.03) # the underscore avoid to have a line of code displayed above the graph\nplt.show()","e69199c3":"pd.set_option(\"display.max_colwidth\", -1) # display the whole cell for best hyperparameter column\nridge_results = pd.DataFrame(['Ridge Regression', ridge_time, g_ridge_param, optuna_ridge_params, ridge_train_mae, ridge_test_mae, dummy_test_mae, ridge_train_mse, ridge_test_mse, optuna_ridge_mse, dummy_test_mse, ridge_train_rmse, ridge_test_rmse, optuna_ridge_rmse, dummy_test_rmse, ridge_train_r2, ridge_test_r2, dummy_test_r2]).transpose()\nridge_results.columns = ['Method', 'Elapsed Time','GridSearch Hyperparameters', 'Optuna Hyperparameters', 'Training MAE', 'Test MAE', 'Dummy MAE', 'Training MSE', 'Test MSE', 'Optuna Test MSE', 'Dummy MSE', 'Training RMSE', 'Test RMSE', 'Optuna Test RMSE', 'Dummy RMSE', 'Training R2', 'Test R2', 'Dummy R2']\nresults = pd.concat([ridge_results], axis = 0).reset_index().drop(columns='index')\nresults.style.apply(lambda x: ['background: lightblue' if x.name == 'Optuna Test RMSE' else '' for i in x])","d0922b8b":"# We'll start by doing a Linear Regression using one variable to predict our variable TotalGHGEmissions\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import linear_model\n\n\n# split our dataset for prediction\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 20)\n\n# start timer\nt1_start = process_time()\n\n# call the model\nlr = linear_model.LinearRegression()\n\n# train our model\nlr.fit(X_train, y_train)\n\n# Predict the response for test and train datasets\ny_lr_test_pred = lr.predict(X_test)\ny_lr_train_pred = lr.predict(X_train)\n\n# mean error square\nlr_test_mae = mean_absolute_error(y_test, y_lr_test_pred)\nlr_train_mae = mean_absolute_error(y_train, y_lr_train_pred)\n\n# The mean squared error\nlr_test_mse = mean_squared_error(y_test, y_lr_test_pred)\nlr_train_mse = mean_squared_error(y_train, y_lr_train_pred)\n\n# The coefficient of determination: 1 is perfect prediction\nlr_test_r2 = r2_score(y_test, y_lr_test_pred)\nlr_train_r2 = r2_score(y_train, y_lr_train_pred)\n\n# The root mean squared error\nlr_test_rmse = sqrt(mean_squared_error(y_test, y_lr_test_pred))\nlr_train_rmse = sqrt(mean_squared_error(y_train, y_lr_train_pred))\n\n# stop timer\nt1_stop = process_time()\n\n# Elapsed time\nlr_time = t1_stop-t1_start\n\nprint(\"Elapsed time in seconds to run Least Squares:\", lr_time) ","339af04e":"import optuna\n\ndef objective(trial):\n    \n    fit_intercept = trial.suggest_categorical(\"fit_intercept\",choices=[True, False])\n    \n\n    ## Create Model\n    \n    optuna_lr  = LinearRegression(fit_intercept=fit_intercept)\n    \n    ## Fit Model\n    \n    optuna_lr.fit(X_train, y_train)\n\n    return mean_squared_error(y_test, optuna_lr.predict(X_test))\n    \n\nt1_start = process_time()\n\n\nstudy4 = optuna.create_study(study_name=\"LinearRegression\")\nstudy4.optimize(objective, n_trials=47)\n\n# evaluation metrics\n\noptuna_lr_rmse = sqrt(study4.best_value)\noptuna_lr_mse = study4.best_value\noptuna_lr_params = study4.best_params\n\n# stop timer\nt1_stop = process_time()\n\n# Elapsed time\nlr_time = t1_stop-t1_start\n\nprint(\"Elapsed time in seconds to run Linear Regression with Optuna tuning hyperparameters:\", lr_time)\n\nprint(\"Best Params : {}\".format(optuna_lr_params))\nprint(\"\\nBest MSE : {}\".format(optuna_lr_mse))\nprint(\"\\nBest RMSE : {}\".format(optuna_lr_rmse))\n","ed6eee66":"# cross validation\n\ncv_lr_train = cross_val_score(lr, X_train, y_lr_train_pred, cv=KFold(n_splits=5,shuffle=True), scoring ='neg_mean_squared_error')\ncv_lr_test = cross_val_score(lr, X_test, y_lr_test_pred, cv=KFold(n_splits=5,shuffle=True), scoring ='neg_mean_squared_error')\ncv_lr_results = pd.DataFrame([-cv_lr_train, -cv_lr_test, -cv_dummy]).transpose()\ncv_lr_results.columns = ['Training Dataset', 'Test Dataset', 'Dummy']\ncv_lr_results","17fdf578":"plt.style.use('ggplot')\nsns.set_style('darkgrid')\nbins = np.linspace(start=0, stop=400, num=50)\nhist = cv_lr_results.plot.hist(bins=bins, density=True, edgecolor=\"black\")\nplt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\nplt.xlabel(\"Mean squared error\", size=18)\nplt.ylabel(\"Frequency\", size=18)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n_ = plt.title(\"Cross-validation testing errors\", size=28, y=1.03) # the underscore avoid to have a line of code displayed above the graph\nplt.show()","25d574dd":"pd.set_option(\"display.max_colwidth\", -1) # display the whole cell for best hyperparameter column\nlr_results = pd.DataFrame(['Least Squares Regression', lr_time, optuna_lr_params, lr_train_mae, lr_test_mae, dummy_test_mae, lr_train_mse, lr_test_mse, optuna_lr_mse, dummy_test_mse, lr_train_rmse, lr_test_rmse, optuna_lr_rmse, dummy_test_rmse, lr_train_r2, lr_test_r2, dummy_test_r2]).transpose()\nlr_results.columns = ['Method', 'Elapsed Time', 'Optuna Hyperparameters', 'Training MAE', 'Test MAE', 'Dummy MAE', 'Training MSE', 'Test MSE', 'Optuna Test MSE', 'Dummy MSE', 'Training RMSE', 'Test RMSE', 'Optuna Test RMSE', 'Dummy RMSE', 'Training R2', 'Test R2', 'Dummy R2']\nresults = pd.concat([ridge_results, lr_results], axis = 0).reset_index().drop(columns='index')\nresults.style.apply(lambda x: ['background: lightblue' if x.name == 'Optuna Test RMSE' else '' for i in x])","ad2cc33c":"from sklearn.ensemble import GradientBoostingRegressor\n\n# split our dataset for prediction\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n\n# start timer\nt1_start = process_time()\n\n# creating a gradient boost classifier\ngrad_boosting = GradientBoostingRegressor(validation_fraction=0.2, n_iter_no_change=5, tol=0.01) # creation of early stopping to avoid future overfitting in our model\n\n# define values for hyperparameters\nlearning_rate = [0.6, 0.75, 0.8]\nn_estimators = [20]\nmax_features = [12]\nalpha = [0.85]\nmax_leaf_nodes = [20]\nmin_samples_leaf = [4]\nmin_weight_fraction_leaf = [0.39]\nmax_depth = [7]\nmin_impurity_decrease = [0.5]\n\n# Create the random grid\ngboosting_grid = {'learning_rate': learning_rate, 'n_estimators': n_estimators, 'max_features': max_features, 'alpha': alpha, 'max_leaf_nodes':max_leaf_nodes, 'min_samples_leaf':min_samples_leaf, 'min_weight_fraction_leaf':min_weight_fraction_leaf, 'max_depth':max_depth, 'min_impurity_decrease':min_impurity_decrease}\n\n# cross validation to tune hyperparameter\ng_boosting = GridSearchCV(grad_boosting, param_grid = gboosting_grid, cv=KFold(n_splits=5,shuffle=True))\n\n# train the model using the classifier\ngrad_boosting.fit(X_train, y_train)\n \n# performing predictions on the test dataset\ny_grad_boosting_test_pred = grad_boosting.predict(X_test)\ny_grad_boosting_train_pred = grad_boosting.predict(X_train)\n\n# fit the grid\ng_boosting.fit(X_train, y_train)\n\n# best hyperparameter\ng_boosting_param = g_boosting.best_params_\n\n# The mean absolute error\ngrad_boosting_test_mae = mean_absolute_error(y_test, y_grad_boosting_test_pred)\ngrad_boosting_train_mae = mean_absolute_error(y_train, y_grad_boosting_train_pred)\n\n# The mean squared error\ngrad_boosting_test_mse = mean_squared_error(y_test, y_grad_boosting_test_pred)\ngrad_boosting_train_mse = mean_squared_error(y_train, y_grad_boosting_train_pred)\n\n# The coefficient of determination: 1 is perfect prediction\ngrad_boosting_test_r2 = r2_score(y_test, y_grad_boosting_test_pred)\ngrad_boosting_train_r2 = r2_score(y_train, y_grad_boosting_train_pred)\n\n# The root mean squared error\ngrad_boosting_test_rmse = sqrt(mean_squared_error(y_test, y_grad_boosting_test_pred))\ngrad_boosting_train_rmse = sqrt(mean_squared_error(y_train, y_grad_boosting_train_pred))\n\n# stop timer\nt1_stop = process_time()\n\n# Elapsed time\ngrad_boosting_time = t1_stop-t1_start\n\nprint(\"Elapsed time in seconds to run Gradient Boosting Regressor:\", grad_boosting_time)","57e358fc":"import optuna\n\ndef objective(trial):\n    \n    learning_rate = trial.suggest_float(\"learning_rate\", 0, 1)\n    n_estimators = trial.suggest_int(\"n_estimators\", 1, 100)\n    max_features = trial.suggest_int(\"max_features\", 1, 20)\n    alpha = trial.suggest_float(\"alpha\", 0, 1)\n    max_leaf_nodes = trial.suggest_int(\"max_leaf_nodes\", 2, 25)\n    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n    min_weight_fraction_leaf = trial.suggest_float(\"min_weight_fraction_leaf\", 0, 0.5)\n    max_depth = trial.suggest_int(\"max_depth\", 1, 15)\n    min_impurity_decrease = trial.suggest_float(\"min_impurity_decrease\", 0, 1)\n    validation_fraction= trial.suggest_float(\"validation_fraction\", 0.1, 1)\n    n_iter_no_change= trial.suggest_int(\"n_iter_no_change\", 0.1, 25)\n    tol= trial.suggest_float(\"tol\", 0.1, 10)\n    \n\n    ## Create Model\n    \n    optuna_grad_boosting  = GradientBoostingRegressor(learning_rate=learning_rate, n_estimators=n_estimators, max_features=max_features, alpha=alpha, max_leaf_nodes=max_leaf_nodes, min_samples_leaf=min_samples_leaf, min_weight_fraction_leaf=min_weight_fraction_leaf, max_depth=max_depth, min_impurity_decrease=min_impurity_decrease, validation_fraction=validation_fraction, n_iter_no_change=n_iter_no_change, tol=tol)\n    \n    ## Fit Model\n    \n    optuna_grad_boosting.fit(X_train, y_train)\n\n    return mean_squared_error(y_test, optuna_grad_boosting.predict(X_test))\n    \n\nt1_start = process_time()\n\n\nstudy1 = optuna.create_study(study_name=\"GradientBoostingRegressor\")\nstudy1.optimize(objective, n_trials=47)\n\n# evaluation metrics\n\noptuna_grad_boosting_rmse = sqrt(study1.best_value)\noptuna_grad_boosting_mse = study1.best_value\noptuna_grad_boosting_params = study1.best_params\n\n# stop timer\nt1_stop = process_time()\n\n# Elapsed time\ngrad_boosting_time = t1_stop-t1_start\n\nprint(\"Elapsed time in seconds to run Gradient Boosting Regressor with Optuna tuning hyperparameters:\", grad_boosting_time)\n\nprint(\"Best Params : {}\".format(optuna_grad_boosting_params))\nprint(\"\\nBest MSE : {}\".format(optuna_grad_boosting_mse))\nprint(\"\\nBest RMSE : {}\".format(optuna_grad_boosting_rmse))\n","1b4915fd":"# cross validation\n\ncv_grad_boosting_train = cross_val_score(grad_boosting, X_train, y_grad_boosting_train_pred, cv=KFold(n_splits=5,shuffle=True), scoring ='neg_mean_squared_error')\ncv_grad_boosting_test = cross_val_score(grad_boosting, X_test, y_grad_boosting_test_pred, cv=KFold(n_splits=5,shuffle=True), scoring ='neg_mean_squared_error')\ncv_grad_boosting_results = pd.DataFrame([-cv_grad_boosting_train, -cv_grad_boosting_test, -cv_dummy]).transpose()\ncv_grad_boosting_results.columns = ['Training Dataset', 'Test Dataset', 'Dummy']\ncv_grad_boosting_results","9ec1d104":"plt.style.use('ggplot')\nsns.set_style('darkgrid')\nbins = np.linspace(start=0, stop=70000, num=50)\nhist = cv_grad_boosting_results.plot.hist(bins=bins, density=True, edgecolor=\"black\")\nplt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\nplt.xlabel(\"Mean squared error\", size=18)\nplt.ylabel(\"Frequency\", size=18)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n_ = plt.title(\"Cross-validation testing errors\", size=28, y=1.03) # the underscore avoid to have a line of code displayed above the graph\nplt.show()","cfe3e724":"pd.set_option(\"display.max_colwidth\", -1) # display the whole cell for best hyperparameter column\ngrad_boosting_results = pd.DataFrame(['Gradient Boosting', grad_boosting_time, g_boosting_param, optuna_grad_boosting_params, grad_boosting_train_mae, grad_boosting_test_mae, dummy_test_mae, grad_boosting_train_mse, grad_boosting_test_mse, optuna_grad_boosting_mse, dummy_test_mse, grad_boosting_train_rmse, grad_boosting_test_rmse, optuna_grad_boosting_rmse, dummy_test_rmse, grad_boosting_train_r2, grad_boosting_test_r2, dummy_test_r2]).transpose()\ngrad_boosting_results.columns = ['Method', 'Elapsed Time', 'GridSearch Hyperparameters', 'Optuna Hyperparameters', 'Training MAE', 'Test MAE', 'Dummy MAE', 'Training MSE', 'Test MSE', 'Optuna Test MSE', 'Dummy MSE', 'Training RMSE', 'Test RMSE', 'Optuna Test RMSE', 'Dummy RMSE', 'Training R2', 'Test R2', 'Dummy R2']\nresults = pd.concat([ridge_results, lr_results, grad_boosting_results], axis = 0).reset_index().drop(columns='index')\nresults.style.apply(lambda x: ['background: lightblue' if x.name == 'Optuna Test RMSE' else '' for i in x])","43a8d18c":"from sklearn.linear_model import ElasticNet\n\n# split our dataset for prediction\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 20)\n\n# start timer\nt1_start = process_time()\n\n# call the model\nelastic_net = ElasticNet()\n\n# hyperparameters\nelasticnet_params = {'alpha':(0, 1, 10, 100, 1000, 10000)}\n\n# cross validation to tune hyperparameter\ng_elasticnet = GridSearchCV(elastic_net, param_grid = elasticnet_params, cv=KFold(n_splits=5,shuffle=True))\n\n# perform the search\ng_elasticnet.fit(X_train, y_train)\n\n#Predict the response for test and train datasets\ny_elastic_test_pred = g_elasticnet.predict(X_test)\ny_elastic_train_pred = g_elasticnet.predict(X_train)\n\n# mean error square\nelastic_test_mae = mean_absolute_error(y_test, y_elastic_test_pred)\nelastic_train_mae = mean_absolute_error(y_train, y_elastic_train_pred)\n\n# best hyperparameter\ng_elasticnet_param = g_elasticnet.best_params_\n\n# The mean squared error\nelastic_test_mse = mean_squared_error(y_test, y_elastic_test_pred)\nelastic_train_mse = mean_squared_error(y_train, y_elastic_train_pred)\n\n# The coefficient of determination: 1 is perfect prediction\nelastic_test_r2 = r2_score(y_test, y_elastic_test_pred)\nelastic_train_r2 = r2_score(y_train, y_elastic_train_pred)\n\n# The root mean squared error\nelastic_test_rmse = sqrt(mean_squared_error(y_test, y_elastic_test_pred))\nelastic_train_rmse = sqrt(mean_squared_error(y_train, y_elastic_train_pred))\n\n# stop timer\nt1_stop = process_time()\n\n# Elapsed time\nelastic_time = t1_stop-t1_start\n\nprint(\"Elapsed time in seconds to run Elastic Net:\", elastic_time)","f08ffda0":"import optuna\n\ndef objective(trial):\n    \n    fit_intercept = trial.suggest_categorical(\"fit_intercept\",choices=[True, False])\n    max_iter = trial.suggest_int(\"n_estimators\", 1, 1000)\n    tol = trial.suggest_float(\"tol\", 0, 0.5)\n    alpha = trial.suggest_float(\"alpha\", 0, 1000)\n    warm_start = trial.suggest_categorical(\"warm_start\",choices=[True, False])\n    selection = trial.suggest_categorical(\"selection\",choices=[\"cyclic\",\"random\"])\n    l1_ratio = trial.suggest_float(\"l1_ratio\", 0, 1)\n    \n    \n\n    ## Create Model\n\n    optuna_elastic  = ElasticNet(fit_intercept=fit_intercept, max_iter=max_iter, tol=tol, alpha=alpha, warm_start=warm_start, selection=selection, l1_ratio=l1_ratio)\n    \n    \n    ## Fit Model\n    \n    optuna_elastic.fit(X_train, y_train)\n\n    return mean_squared_error(y_test, optuna_elastic.predict(X_test))\n    \nt1_start = process_time()\n\n\nstudy6 = optuna.create_study(study_name=\"ElasticNetRegression\")\nstudy6.optimize(objective, n_trials=47)\n\n# evaluation metrics\n\noptuna_elastic_rmse = sqrt(study6.best_value)\noptuna_elastic_mse = study6.best_value\noptuna_elastic_params = study6.best_params\n\n# stop timer\nt1_stop = process_time()\n\n# Elapsed time\nelastic_time = t1_stop-t1_start\n\nprint(\"Elapsed time in seconds to run Elastic Net Regression with Optuna tuning hyperparameters:\", elastic_time)\n\nprint(\"Best Params : {}\".format(optuna_elastic_params))\nprint(\"\\nBest MSE : {}\".format(optuna_elastic_mse))\nprint(\"\\nBest RMSE : {}\".format(optuna_elastic_rmse))\n","ee0b4ce8":"# cross validation\n\ncv_elasticnet_train = cross_val_score(g_elasticnet, X_train, y_elastic_train_pred, cv=KFold(n_splits=5,shuffle=True), scoring ='neg_mean_squared_error')\ncv_elasticnet_test = cross_val_score(g_elasticnet, X_test, y_elastic_test_pred, cv=KFold(n_splits=5,shuffle=True), scoring ='neg_mean_squared_error')\ncv_elasticnet_results = pd.DataFrame([-cv_elasticnet_train, -cv_elasticnet_test, -cv_dummy]).transpose()\ncv_elasticnet_results.columns = ['Training Dataset', 'Test Dataset', 'Dummy']\ncv_elasticnet_results","db4dbd68":"plt.style.use('ggplot')\nsns.set_style('darkgrid')\nbins = np.linspace(start=0, stop=0.0004, num=50)\nhist = cv_elasticnet_results.plot.hist(bins=bins, density=True, edgecolor=\"black\")\nplt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\nplt.xlabel(\"Mean squared error\", size=18)\nplt.ylabel(\"Frequency\", size=18)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n_ = plt.title(\"Cross-validation testing errors\", size=28, y=1.03) # the underscore avoid to have a line of code displayed above the graph\nplt.show()","2d326549":"pd.set_option(\"display.max_colwidth\", -1) # display the whole cell for best hyperparameter column\nelastic_results = pd.DataFrame(['Elastic Net Regression', elastic_time, g_elasticnet_param, optuna_elastic_params, elastic_train_mae, elastic_test_mae, dummy_test_mae, elastic_train_mse, elastic_test_mse, optuna_elastic_mse, dummy_test_mse, elastic_train_rmse, elastic_test_rmse, optuna_elastic_rmse, dummy_test_rmse, elastic_train_r2, elastic_test_r2, dummy_test_r2]).transpose()\nelastic_results.columns = ['Method', 'Elapsed Time','GridSearch Hyperparameters', 'Optuna Hyperparameters', 'Training MAE', 'Test MAE', 'Dummy MAE', 'Training MSE', 'Test MSE', 'Optuna Test MSE', 'Dummy MSE', 'Training RMSE', 'Test RMSE', 'Optuna Test RMSE', 'Dummy RMSE', 'Training R2', 'Test R2', 'Dummy R2']\nresults = pd.concat([ridge_results, lr_results, grad_boosting_results, elastic_results], axis = 0).reset_index().drop(columns='index')\nresults.style.apply(lambda x: ['background: lightblue' if x.name == 'Optuna Test RMSE' else '' for i in x])","77fc37c9":"from sklearn.linear_model import Lasso\n\n# split our dataset for prediction\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 20)\n\n# start timer\nt1_start = process_time()\n\n# call the model\nlasso = Lasso()\n\n# hyperparameters\nlasso_params = {'alpha':(0.1, 1, 10, 100)}\n\n# cross validation to tune hyperparameter\ng_lasso = GridSearchCV(lasso, param_grid = lasso_params, cv=KFold(n_splits=5,shuffle=True))\n\n# perform the search\ng_lasso.fit(X_train, y_train)\n\n#Predict the response for test and train datasets\ny_lasso_test_pred = g_lasso.predict(X_test)\ny_lasso_train_pred = g_lasso.predict(X_train)\n\n# mean error square\nlasso_test_mae = mean_absolute_error(y_test, y_lasso_test_pred)\nlasso_train_mae = mean_absolute_error(y_train, y_lasso_train_pred)\n\n# best hyperparameter\ng_lasso_param = g_lasso.best_params_\n\n# The mean squared error\nlasso_test_mse = mean_squared_error(y_test, y_lasso_test_pred)\nlasso_train_mse = mean_squared_error(y_train, y_lasso_train_pred)\n\n# The coefficient of determination: 1 is perfect prediction\nlasso_test_r2 = r2_score(y_test, y_lasso_test_pred)\nlasso_train_r2 = r2_score(y_train, y_lasso_train_pred)\n\n# The root mean squared error\nlasso_test_rmse = sqrt(mean_squared_error(y_test, y_lasso_test_pred))\nlasso_train_rmse = sqrt(mean_squared_error(y_train, y_lasso_train_pred))\n\n# stop timer\nt1_stop = process_time()\n\n# Elapsed time\nlasso_time = t1_stop-t1_start\n\nprint(\"Elapsed time in seconds to run Lasso:\", lasso_time) ","ec32a2f0":"import optuna\n\ndef objective(trial):\n    \n    fit_intercept = trial.suggest_categorical(\"fit_intercept\",choices=[True, False])\n    max_iter = trial.suggest_int(\"n_estimators\", 1, 1000)\n    tol = trial.suggest_float(\"tol\", 0, 0.5)\n    alpha = trial.suggest_float(\"alpha\", 0, 1000)\n    warm_start = trial.suggest_categorical(\"warm_start\",choices=[True, False])\n    selection = trial.suggest_categorical(\"selection\",choices=[\"cyclic\",\"random\"])\n    \n    \n\n    ## Create Model\n    \n    optuna_lasso  = Lasso(fit_intercept=fit_intercept, max_iter=max_iter, tol=tol, alpha=alpha, warm_start=warm_start, selection=selection)\n    \n    ## Fit Model\n    \n    optuna_lasso.fit(X_train, y_train)\n\n    return mean_squared_error(y_test, optuna_lasso.predict(X_test))\n    \nt1_start = process_time()\n\n\nstudy5 = optuna.create_study(study_name=\"LassoRegression\")\nstudy5.optimize(objective, n_trials=47)\n\n# evaluation metrics\n\noptuna_lasso_rmse = sqrt(study5.best_value)\noptuna_lasso_mse = study5.best_value\noptuna_lasso_params = study5.best_params\n\n# stop timer\nt1_stop = process_time()\n\n# Elapsed time\nlasso_time = t1_stop-t1_start\n\nprint(\"Elapsed time in seconds to run Lasso Regression with Optuna tuning hyperparameters:\", lasso_time)\n\nprint(\"Best Params : {}\".format(optuna_lasso_params))\nprint(\"\\nBest MSE : {}\".format(optuna_lasso_mse))\nprint(\"\\nBest RMSE : {}\".format(optuna_lasso_rmse))\n","7aec1af5":"# cross validation\n\ncv_lasso_train = cross_val_score(g_lasso, X_train, y_lasso_train_pred, cv=KFold(n_splits=5,shuffle=True), scoring ='neg_mean_squared_error')\ncv_lasso_test = cross_val_score(g_lasso, X_test, y_lasso_test_pred, cv=KFold(n_splits=5,shuffle=True), scoring ='neg_mean_squared_error')\ncv_lasso_results = pd.DataFrame([-cv_lasso_train, -cv_lasso_test, -cv_dummy]).transpose()\ncv_lasso_results.columns = ['Training Dataset', 'Test Dataset', 'Dummy']\ncv_lasso_results","9dae128b":"plt.style.use('ggplot')\nsns.set_style('darkgrid')\nbins = np.linspace(start=0, stop=0.9, num=50)\nhist = cv_lasso_results.plot.hist(bins=bins, density=True, edgecolor=\"black\")\nplt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\nplt.xlabel(\"Mean squared error\", size=18)\nplt.ylabel(\"Frequency\", size=18)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n_ = plt.title(\"Cross-validation testing errors\", size=28, y=1.03) # the underscore avoid to have a line of code displayed above the graph\nplt.show()","e147e3a8":"pd.set_option(\"display.max_colwidth\", -1) # display the whole cell for best hyperparameter column\nlasso_results = pd.DataFrame(['Lasso Regression', lasso_time, g_lasso_param, optuna_lasso_params, lasso_train_mae, lasso_test_mae, dummy_test_mae, lasso_train_mse, lasso_test_mse, optuna_lasso_mse, dummy_test_mse, lasso_train_rmse, lasso_test_rmse, optuna_lasso_rmse, dummy_test_rmse, lasso_train_r2, lasso_test_r2, dummy_test_r2]).transpose()\nlasso_results.columns = ['Method', 'Elapsed Time','GridSearch Hyperparameters', 'Optuna Hyperparameters', 'Training MAE', 'Test MAE', 'Dummy MAE', 'Training MSE', 'Test MSE', 'Optuna Test MSE', 'Dummy MSE', 'Training RMSE', 'Test RMSE', 'Optuna Test RMSE', 'Dummy RMSE', 'Training R2', 'Test R2', 'Dummy R2']\nresults = pd.concat([ridge_results, lr_results, grad_boosting_results, elastic_results, lasso_results], axis = 0).reset_index().drop(columns='index')\nresults.style.apply(lambda x: ['background: lightblue' if x.name == 'Optuna Test RMSE' else '' for i in x])","8c1ecfbe":"from sklearn.tree import DecisionTreeRegressor\n\n# split our dataset for prediction\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20)\n\n# start timer\nt1_start = process_time()\n\n# Call the model \ntree = DecisionTreeRegressor()\n\n# define values for hyperparameters\nmax_features = [20]\nmax_depth = [7]\nmin_samples_split = [4]\nmin_samples_leaf = [3]\nmax_leaf_nodes = [5]\nmin_impurity_decrease = [0.685]\n\n# Create the random grid\ntree_grid = {'max_features': max_features, 'max_depth': max_depth, 'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf, 'max_leaf_nodes': max_leaf_nodes, 'min_impurity_decrease':min_impurity_decrease}\n\n# cross validation to tune hyperparameter\ng_tree = GridSearchCV(tree, param_grid = tree_grid, cv=KFold(n_splits=5,shuffle=True))\n\n# Performing training\ntree.fit(X_train, y_train)\n\n#Predict the response for test and train datasets\ny_tree_test_pred = tree.predict(X_test)\ny_tree_train_pred = tree.predict(X_train)\n\n# mean error square\ntree_test_mae = mean_absolute_error(y_test, y_tree_test_pred)\ntree_train_mae = mean_absolute_error(y_train, y_tree_train_pred)\n\n# fit the grid\ng_tree.fit(X_train, y_train)\n\n# best hyperparameter\ng_tree_param = g_tree.best_params_\n\n# The mean squared error\ntree_test_mse = mean_squared_error(y_test, y_tree_test_pred)\ntree_train_mse = mean_squared_error(y_train, y_tree_train_pred)\n\n\n# The coefficient of determination: 1 is perfect prediction\ntree_test_r2 = r2_score(y_test, y_tree_test_pred)\ntree_train_r2 = r2_score(y_train, y_tree_train_pred)\n\n# The root mean squared error\ntree_test_rmse = sqrt(mean_squared_error(y_test, y_tree_test_pred))\ntree_train_rmse = sqrt(mean_squared_error(y_train, y_tree_train_pred))\n\n# stop timer\nt1_stop = process_time()\n\n# Elapsed time\ntree_time = t1_stop-t1_start\n\nprint(\"Elapsed time in seconds to run Decision Trees:\", tree_time)","764fef2d":"import optuna\n\ndef objective(trial):\n    \n    \n    max_features = trial.suggest_int(\"max_features\", 1, 20)\n    max_leaf_nodes = trial.suggest_int(\"max_leaf_nodes\", 2, 25)\n    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n    min_weight_fraction_leaf = trial.suggest_float(\"min_weight_fraction_leaf\", 0, 0.5)\n    max_depth = trial.suggest_int(\"max_depth\", 1, 15)\n    min_impurity_decrease = trial.suggest_float(\"min_impurity_decrease\", 0, 1)\n    splitter= trial.suggest_categorical(\"splitter\",choices=[\"best\", \"random\"]) \n    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20) \n    \n\n    ## Create Model\n    \n    optuna_tree  = DecisionTreeRegressor(max_features=max_features, max_leaf_nodes=max_leaf_nodes, min_samples_leaf=min_samples_leaf, min_weight_fraction_leaf=min_weight_fraction_leaf, max_depth=max_depth, min_impurity_decrease=min_impurity_decrease, min_samples_split=min_samples_split, splitter=splitter)\n    \n    ## Fit Model\n    \n    optuna_tree.fit(X_train, y_train)\n\n    return mean_squared_error(y_test, optuna_tree.predict(X_test))\n    \n\nt1_start = process_time()\n\n\nstudy7 = optuna.create_study(study_name=\"DecisionTreeRegressor\")\nstudy7.optimize(objective, n_trials=47)\n\n# evaluation metrics\n\noptuna_tree_rmse = sqrt(study7.best_value)\noptuna_tree_mse = study7.best_value\noptuna_tree_params = study7.best_params\n\n# stop timer\nt1_stop = process_time()\n\n# Elapsed time\nrtree_time = t1_stop-t1_start\n\nprint(\"Elapsed time in seconds to run Decision Tree Regressor with Optuna tuning hyperparameters:\", tree_time)\n\nprint(\"Best Params : {}\".format(optuna_tree_params))\nprint(\"\\nBest MSE : {}\".format(optuna_tree_mse))\nprint(\"\\nBest RMSE : {}\".format(optuna_tree_rmse))\n","7c3321ce":"# cross validation\n\ncv_tree_train = cross_val_score(g_tree, X_train, y_tree_train_pred, cv=KFold(n_splits=5,shuffle=True), scoring ='neg_mean_squared_error')\ncv_tree_test = cross_val_score(g_tree, X_test, y_tree_test_pred, cv=KFold(n_splits=5,shuffle=True), scoring ='neg_mean_squared_error')\ncv_tree_results = pd.DataFrame([-cv_tree_train, -cv_tree_test, -cv_dummy]).transpose()\ncv_tree_results.columns = ['Training Dataset', 'Test Dataset', 'Dummy']\ncv_tree_results","6717a58a":"plt.style.use('ggplot')\nsns.set_style('darkgrid')\nbins = np.linspace(start=0, stop=400000, num=50)\nhist = cv_tree_results.plot.hist(bins=bins, density=True, edgecolor=\"black\")\nplt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\nplt.xlabel(\"Mean squared error\", size=18)\nplt.ylabel(\"Frequency\", size=18)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n_ = plt.title(\"Cross-validation testing errors\", size=28, y=1.03) # the underscore avoid to have a line of code displayed above the graph\nplt.show()","cdc1fb9b":"pd.set_option(\"display.max_colwidth\", -1) # display the whole cell for best hyperparameter column\ntree_results = pd.DataFrame(['Decision Trees Regressor', tree_time, g_tree_param, optuna_tree_params, tree_train_mae, tree_test_mae, dummy_test_mae, tree_train_mse, tree_test_mse, optuna_tree_mse, dummy_test_mse, tree_train_rmse, tree_test_rmse, optuna_tree_rmse, dummy_test_rmse, tree_train_r2, tree_test_r2, dummy_test_r2]).transpose()\ntree_results.columns = ['Method', 'Elapsed Time','GridSearch Hyperparameters', 'Optuna Hyperparameters', 'Training MAE', 'Test MAE', 'Dummy MAE', 'Training MSE', 'Test MSE', 'Optuna Test MSE', 'Dummy MSE', 'Training RMSE', 'Test RMSE', 'Optuna Test RMSE', 'Dummy RMSE', 'Training R2', 'Test R2', 'Dummy R2']\nresults = pd.concat([ridge_results, lr_results, grad_boosting_results, elastic_results, lasso_results, tree_results], axis = 0).reset_index().drop(columns='index')\nresults.style.apply(lambda x: ['background: lightblue' if x.name == 'Optuna Test RMSE' else '' for i in x])","91b49f98":"plot_feature_importance(tree.feature_importances_,X.columns,' DECISION TREE')","030bca65":"# revoir les hyperparam\u00e8tres de la random forest afin de r\u00e9duire le temps de run\n\nfrom sklearn.ensemble import RandomForestRegressor\n\n# split our dataset for prediction\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20)\n\n# start timer\nt1_start = process_time()\n\n# create the model\nrf = RandomForestRegressor() \n\n# define values for hyperparameters\nn_estimators = [250]\nmax_features = [10]\nmax_depth = [8]\nmin_samples_split = [4]\nmin_samples_leaf = [3]\nmax_leaf_nodes = [7]\nmin_impurity_decrease = [0.65]\n\n# Create the random grid\nrf_grid = {'n_estimators': n_estimators, 'max_features': max_features, 'max_depth': max_depth, 'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf, 'max_leaf_nodes':max_leaf_nodes, 'min_impurity_decrease':min_impurity_decrease}\n\n# cross validation to tune hyperparameter\ng_rf = GridSearchCV(rf, param_grid = rf_grid, cv=KFold(n_splits=5,shuffle=True))\n\n# train the model \nrf.fit(X_train, y_train)\n \n# performing predictions on the test dataset\ny_rf_test_pred = rf.predict(X_test)\ny_rf_train_pred = rf.predict(X_train)\n\n# fit the grid\ng_rf.fit(X_train, y_train)\n\n# best hyperparameter\ng_rf_param = g_rf.best_params_\n\n# The mean absolute error\nrf_test_mae = mean_absolute_error(y_test, y_rf_test_pred)\nrf_train_mae = mean_absolute_error(y_train, y_rf_train_pred)\n\n# The mean squared error\nrf_test_mse = mean_squared_error(y_test, y_rf_test_pred)\nrf_train_mse = mean_squared_error(y_train, y_rf_train_pred)\n\n# The coefficient of determination: 1 is perfect prediction\nrf_test_r2 = r2_score(y_test, y_rf_test_pred)\nrf_train_r2 = r2_score(y_train, y_rf_train_pred)\n\n# The root mean squared error\nrf_test_rmse = sqrt(mean_squared_error(y_test, y_rf_test_pred))\nrf_train_rmse = sqrt(mean_squared_error(y_train, y_rf_train_pred))\n\n# stop timer\nt1_stop = process_time()\n\n# Elapsed time\nrf_time = t1_stop-t1_start\n\nprint(\"Elapsed time in seconds to run Random Forest:\", rf_time)","e2c77d35":"import optuna\n\ndef objective(trial):\n    \n    n_estimators = trial.suggest_int(\"n_estimators\", 1, 100)\n    max_features = trial.suggest_int(\"max_features\", 1, 20)\n    max_leaf_nodes = trial.suggest_int(\"max_leaf_nodes\", 2, 25)\n    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n    min_weight_fraction_leaf = trial.suggest_float(\"min_weight_fraction_leaf\", 0, 0.5)\n    max_depth = trial.suggest_int(\"max_depth\", 1, 15)\n    min_impurity_decrease = trial.suggest_float(\"min_impurity_decrease\", 0, 1)\n    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20) \n    max_samples = trial.suggest_int(\"max_samples\", 1, 100)\n    bootstrap = trial.suggest_categorical(\"bootstrap\",choices=[True, False]) \n    \n\n    ## Create Model\n    \n    optuna_rf  = RandomForestRegressor(n_estimators=n_estimators, max_features=max_features, max_leaf_nodes=max_leaf_nodes, min_samples_leaf=min_samples_leaf, min_weight_fraction_leaf=min_weight_fraction_leaf, max_depth=max_depth, min_impurity_decrease=min_impurity_decrease, min_samples_split=min_samples_split, max_samples=max_samples, bootstrap=bootstrap)\n    \n    ## Fit Model\n    \n    optuna_rf.fit(X_train, y_train)\n\n    return mean_squared_error(y_test, optuna_rf.predict(X_test))\n    \n\nt1_start = process_time()\n\n\nstudy2 = optuna.create_study(study_name=\"RandomForestsRegressor\")\nstudy2.optimize(objective, n_trials=47)\n\n# evaluation metrics\n\noptuna_rf_rmse = sqrt(study2.best_value)\noptuna_rf_mse = study2.best_value\noptuna_rf_params = study2.best_params\n\n# stop timer\nt1_stop = process_time()\n\n# Elapsed time\nrf_time = t1_stop-t1_start\n\nprint(\"Elapsed time in seconds to run Random Forests Regressor with Optuna tuning hyperparameters:\", rf_time)\n\nprint(\"Best Params : {}\".format(optuna_rf_params))\nprint(\"\\nBest MSE : {}\".format(optuna_rf_mse))\nprint(\"\\nBest RMSE : {}\".format(optuna_rf_rmse))\n","65986c6c":"# cross validation\n\ncv_rf_train = cross_val_score(g_rf, X_train, y_rf_train_pred, cv=KFold(n_splits=5,shuffle=True), scoring ='neg_mean_squared_error')\ncv_rf_test = cross_val_score(g_rf, X_test, y_rf_test_pred, cv=KFold(n_splits=5,shuffle=True), scoring ='neg_mean_squared_error')\ncv_rf_results = pd.DataFrame([-cv_rf_train, -cv_rf_test, -cv_dummy]).transpose()\ncv_rf_results.columns = ['Training Dataset', 'Test Dataset', 'Dummy']\ncv_rf_results","fca575c0":"plt.style.use('ggplot')\nsns.set_style('darkgrid')\nbins = np.linspace(start=0, stop=600000, num=50)\nhist = cv_rf_results.plot.hist(bins=bins, density=True, edgecolor=\"black\")\nplt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\nplt.xlabel(\"Mean squared error\", size=18)\nplt.ylabel(\"Frequency\", size=18)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n_ = plt.title(\"Cross-validation testing errors\", size=28, y=1.03) # the underscore avoid to have a line of code displayed above the graph\nplt.show()","a31a8dc8":"pd.set_option(\"display.max_colwidth\", -1) # display the whole cell for best hyperparameter column\nrf_results = pd.DataFrame(['Random Forest', rf_time, g_rf_param, optuna_rf_params, rf_train_mae, rf_test_mae, dummy_test_mae, rf_train_mse, rf_test_mse, optuna_rf_mse, dummy_test_mse, rf_train_rmse, rf_test_rmse, optuna_rf_rmse, dummy_test_rmse, rf_train_r2, rf_test_r2, dummy_test_r2]).transpose()\nrf_results.columns = ['Method', 'Elapsed Time', 'GridSearch Hyperparameters', 'Optuna Hyperparameters', 'Training MAE', 'Test MAE', 'Dummy MAE', 'Training MSE', 'Test MSE', 'Optuna Test MSE', 'Dummy MSE', 'Training RMSE', 'Test RMSE', 'Optuna Test RMSE', 'Dummy RMSE', 'Training R2', 'Test R2', 'Dummy R2']\nresults = pd.concat([ridge_results, lr_results, grad_boosting_results, elastic_results, lasso_results, tree_results, rf_results], axis = 0).reset_index().drop(columns='index')\nresults.style.apply(lambda x: ['background: lightblue' if x.name == 'Optuna Test RMSE' else '' for i in x])","a698eab5":"# features importance for random forest\nplt.style.use('ggplot')\nsns.set_style('darkgrid')\nplot_feature_importance(rf.feature_importances_,X.columns,'RANDOM FOREST')\nplt.savefig('rffeatures.png', dpi=300, format='png', bbox_inches='tight') # don't crop the legend while saving the figure\nplt.show()","f690ac26":"from sklearn.svm import SVR\n\n# split our dataset for prediction\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20)\n\n# start timer\nt1_start = process_time()\n\n#call the model\nsvr = SVR()\n\n# define values for hyperparameters\nkernel = ['poly']\ndegree = [1] # linear\nC = [200]\n\n# Create the random grid\nsvr_grid = {'kernel': kernel, 'degree': degree, 'C': C}\n\n# cross validation to tune hyperparameter\ngsvr = GridSearchCV(svr, param_grid = svr_grid, cv=KFold(n_splits=5,shuffle=True))\n\n# train our models with the parameters we indicated\ngsvr.fit(X_train, y_train)\n\n#Predict the response for test dataset\ny_svr_test_pred = gsvr.predict(X_test)\ny_svr_train_pred = gsvr.predict(X_train)\n\n# mean error square\nsvr_test_mae = mean_absolute_error(y_test, y_svr_test_pred)\nsvr_train_mae = mean_absolute_error(y_train, y_svr_train_pred)\n\n# best hyperparameter\ngsvr_param = gsvr.best_params_\n\n# The mean squared error\nsvr_test_mse = mean_squared_error(y_test, y_svr_test_pred)\nsvr_train_mse = mean_squared_error(y_train, y_svr_train_pred)\n\n# The coefficient of determination: 1 is perfect prediction\nsvr_test_r2 = r2_score(y_test, y_svr_test_pred)\nsvr_train_r2 = r2_score(y_train, y_svr_train_pred)\n\n# The root mean squared error\nsvr_test_rmse = sqrt(mean_squared_error(y_test, y_svr_test_pred))\nsvr_train_rmse = sqrt(mean_squared_error(y_train, y_svr_train_pred))\n\n# stop timer\nt1_stop = process_time()\n\n# Elapsed time\nsvr_time = t1_stop-t1_start\n\nprint(\"Elapsed time in seconds to run SVR:\", svr_time) ","12d427d7":"import optuna\n\ndef objective(trial):\n\n    gamma = trial.suggest_categorical(\"gamma\", choices=[\"auto\", \"scale\"])\n    verbose = trial.suggest_categorical(\"verbose\", choices=[True, False])\n    C = trial.suggest_float(\"C\", 1, 100)\n    epsilon = trial.suggest_float(\"epsilon\", 0, 1)\n    shrinking = trial.suggest_categorical(\"shrinking\",choices=[True,False]) \n\n    ## Create Model\n    \n    optuna_svr = SVR(epsilon=epsilon, gamma=gamma, C=C, shrinking=shrinking, verbose=verbose)\n    \n    ## Fit Model\n    \n    optuna_svr.fit(X_train, y_train)\n\n    return mean_squared_error(y_test, optuna_svr.predict(X_test))\n    \n\nt1_start = process_time()\n\n\nstudy9 = optuna.create_study(study_name=\"SupportVectorRegressor\")\nstudy9.optimize(objective, n_trials=47)\n\n# evaluation metrics\n\noptuna_svr_rmse = sqrt(study9.best_value)\noptuna_svr_mse = study9.best_value\noptuna_svr_params = study9.best_params\n\n# stop timer\nt1_stop = process_time()\n\n# Elapsed time\nsvr_time = t1_stop-t1_start\n\nprint(\"Elapsed time in seconds to run Support Vector Regressor with Optuna tuning hyperparameters:\", svr_time)\n\nprint(\"Best Params : {}\".format(optuna_svr_params))\nprint(\"\\nBest MSE : {}\".format(optuna_svr_mse))\nprint(\"\\nBest RMSE : {}\".format(optuna_svr_rmse))\n","a9f6ef32":"# cross validation\n\ncv_svr_train = cross_val_score(gsvr, X_train, y_svr_train_pred, cv=KFold(n_splits=5,shuffle=True), scoring ='neg_mean_squared_error')\ncv_svr_test = cross_val_score(gsvr, X_test, y_svr_test_pred, cv=KFold(n_splits=5,shuffle=True), scoring ='neg_mean_squared_error')\ncv_svr_results = pd.DataFrame([-cv_svr_train, -cv_svr_test, -cv_dummy]).transpose()\ncv_svr_results.columns = ['Training Dataset', 'Test Dataset', 'Dummy']\ncv_svr_results","5f3ff3de":"plt.style.use('ggplot')\nsns.set_style('darkgrid')\nbins = np.linspace(start=0, stop=0.05, num=50)\nhist = cv_svr_results.plot.hist(bins=bins, density=True, edgecolor=\"black\")\nplt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\nplt.xlabel(\"Mean squared error\", size=18)\nplt.ylabel(\"Frequency\", size=18)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n_ = plt.title(\"Cross-validation testing errors\", size=28, y=1.03) # the underscore avoid to have a line of code displayed above the graph\nplt.show()","3fcd5311":"pd.set_option(\"display.max_colwidth\", -1) # display the whole cell for best hyperparameter column\nsvr_results = pd.DataFrame(['SVR', svr_time, gsvr_param, optuna_svr_params, svr_train_mae, svr_test_mae, dummy_test_mae, svr_train_mse, svr_test_mse, optuna_svr_mse, dummy_test_mse, svr_train_rmse, svr_test_rmse, optuna_svr_rmse, dummy_test_rmse,  svr_train_r2, svr_test_r2, dummy_test_r2]).transpose()\nsvr_results.columns = ['Method', 'Elapsed Time','GridSearch Hyperparameters', 'Optuna Hyperparameters', 'Training MAE', 'Test MAE', 'Dummy MAE', 'Training MSE', 'Test MSE', 'Optuna Test MSE', 'Dummy MSE', 'Training RMSE', 'Test RMSE', 'Optuna Test RMSE', 'Dummy RMSE', 'Training R2', 'Test R2', 'Dummy R2']\nresults = pd.concat([ridge_results, lr_results, grad_boosting_results, elastic_results, lasso_results, tree_results, rf_results, svr_results], axis = 0).reset_index().drop(columns='index')\nresults.style.apply(lambda x: ['background: lightblue' if x.name == 'Optuna Test RMSE' else '' for i in x])","a75225df":"from sklearn.ensemble import BaggingRegressor\n\n# split our dataset for prediction\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20)\n\n# start timer\nt1_start = process_time()\n\n# creating a RF classifier\nreg_bagging = BaggingRegressor() \n\n# define values for hyperparameters\nn_estimators = [200]\nmax_features = [30]\nmax_samples = [100]\n\n# Create the random grid\nrbag_grid = {'n_estimators': n_estimators, 'max_features': max_features, 'max_samples':max_samples}\n\n# cross validation to tune hyperparameter\ng_rbag = GridSearchCV(reg_bagging, param_grid = rbag_grid, cv=KFold(n_splits=5,shuffle=True))\n\n# train the model using the classifier\nreg_bagging.fit(X_train, y_train)\n \n# performing predictions on the test dataset\ny_reg_bagging_test_pred = reg_bagging.predict(X_test)\ny_reg_bagging_train_pred = reg_bagging.predict(X_train)\n\n# fit the grid\ng_rbag.fit(X_train, y_train)\n\n# best hyperparameter\ng_rbag_param = g_rbag.best_params_\n\n# The mean absolute error\nreg_bagging_test_mae = mean_absolute_error(y_test, y_reg_bagging_test_pred)\nreg_bagging_train_mae = mean_absolute_error(y_train, y_reg_bagging_train_pred)\n\n# The mean squared error\nreg_bagging_test_mse = mean_squared_error(y_test, y_reg_bagging_test_pred)\nreg_bagging_train_mse = mean_squared_error(y_train, y_reg_bagging_train_pred)\n\n# The coefficient of determination: 1 is perfect prediction\nreg_bagging_test_r2 = r2_score(y_test, y_reg_bagging_test_pred)\nreg_bagging_train_r2 = r2_score(y_train, y_reg_bagging_train_pred)\n\n# The root mean squared error\nreg_bagging_test_rmse = sqrt(mean_squared_error(y_test, y_reg_bagging_test_pred))\nreg_bagging_train_rmse = sqrt(mean_squared_error(y_train, y_reg_bagging_train_pred))\n\n# stop timer\nt1_stop = process_time()\n\n# Elapsed time\nrbagging_time = t1_stop-t1_start\n\nprint(\"Elapsed time in seconds to run Bagging Regressor:\", rbagging_time)","3c25a8c6":"import optuna\n\ndef objective(trial):\n    \n    n_estimators = trial.suggest_int(\"n_estimators\", 1, 200)\n    max_features = trial.suggest_int(\"max_features\", 1, 30)\n    max_samples = trial.suggest_int(\"max_samples\", 1, 100)\n    bootstrap = trial.suggest_categorical(\"bootstrap\",choices=[True, False])\n    bootstrap_features = trial.suggest_categorical(\"bootstrap_features\",choices=[True, False])\n    warm_start = trial.suggest_categorical(\"warm_start\",choices=[True, False])\n    \n\n    ## Create Model\n    \n    optuna_bagging  = BaggingRegressor(n_estimators=n_estimators, max_features=max_features, max_samples=max_samples, bootstrap=bootstrap, bootstrap_features=bootstrap_features, warm_start=warm_start)\n    \n    ## Fit Model\n    \n    optuna_bagging.fit(X_train, y_train)\n\n    return mean_squared_error(y_test, optuna_bagging.predict(X_test))\n    \n\nt1_start = process_time()\n\n\nstudy3 = optuna.create_study(study_name=\"BaggingRegressor\")\nstudy3.optimize(objective, n_trials=47)\n\n# evaluation metrics\n\noptuna_bagging_rmse = sqrt(study3.best_value)\noptuna_bagging_mse = study3.best_value\noptuna_bagging_params = study3.best_params\n\n# stop timer\nt1_stop = process_time()\n\n# Elapsed time\nbagging_time = t1_stop-t1_start\n\nprint(\"Elapsed time in seconds to run Bagging Regressor with Optuna tuning hyperparameters:\", bagging_time)\n\nprint(\"Best Params : {}\".format(optuna_bagging_params))\nprint(\"\\nBest MSE : {}\".format(optuna_bagging_mse))\nprint(\"\\nBest RMSE : {}\".format(optuna_bagging_rmse))\n","0146324d":"# cross validation\n\ncv_bagging_train = cross_val_score(g_rbag, X_train, y_reg_bagging_train_pred, cv=KFold(n_splits=5,shuffle=True), scoring ='neg_mean_squared_error')\ncv_bagging_test = cross_val_score(g_rbag, X_test, y_reg_bagging_test_pred, cv=KFold(n_splits=5,shuffle=True), scoring ='neg_mean_squared_error')\ncv_bagging_results = pd.DataFrame([-cv_bagging_train, -cv_bagging_test, -cv_dummy]).transpose()\ncv_bagging_results.columns = ['Training Dataset', 'Test Dataset', 'Dummy']\ncv_bagging_results","0bf9ad62":"plt.style.use('ggplot')\nsns.set_style('darkgrid')\nbins = np.linspace(start=0, stop=600000, num=50)\nhist = cv_bagging_results.plot.hist(bins=bins, density=True, edgecolor=\"black\")\nplt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\nplt.xlabel(\"Mean squared error\", size=18)\nplt.ylabel(\"Frequency\", size=18)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n_ = plt.title(\"Cross-validation testing errors\", size=28, y=1.03) # the underscore avoid to have a line of code displayed above the graph\nplt.show()","14f92b12":"pd.set_option(\"display.max_colwidth\", -1) # display the whole cell for best hyperparameter column\nbagging_results = pd.DataFrame(['Bagging Regressor', rbagging_time, g_rbag_param, optuna_bagging_params, reg_bagging_train_mae, reg_bagging_test_mae, dummy_test_mae, reg_bagging_train_mse, reg_bagging_test_mse, optuna_bagging_mse, dummy_test_mse, reg_bagging_train_rmse, reg_bagging_test_rmse, optuna_bagging_rmse, dummy_test_rmse, reg_bagging_train_r2, reg_bagging_test_r2, dummy_test_r2]).transpose()\nbagging_results.columns = ['Method', 'Elapsed Time', 'GridSearch Hyperparameters', 'Optuna Hyperparameters', 'Training MAE', 'Test MAE', 'Dummy MAE', 'Training MSE', 'Test MSE', 'Optuna Test MSE', 'Dummy MSE', 'Training RMSE', 'Test RMSE', 'Optuna Test RMSE', 'Dummy RMSE', 'Training R2', 'Test R2', 'Dummy R2']\nresults = pd.concat([ridge_results, lr_results, grad_boosting_results, elastic_results, lasso_results, tree_results, rf_results, svr_results, bagging_results], axis = 0).reset_index().drop(columns='index')\nresults.style.apply(lambda x: ['background: lightblue' if x.name == 'Optuna Test RMSE' else '' for i in x])","dec3de50":"import xgboost as xgb\nimport xgboost as XGBRegressor\n\n# split our dataset for prediction\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20)\n\n# start timer\nt1_start = process_time()\n\n# creating a gradient boost classifier\nxg_boosting = xgb.XGBRegressor() \n\n# define values for hyperparameters\neta = [0.2] \nalpha = [0.7]\ngamma = [3]\nmax_depth = [12]\nmax_leaves = [4]\nmin_child_weight = [3]\n\n# Create the random grid\nxgboosting_grid = {'eta': eta, 'alpha': alpha, 'gamma': gamma, 'max_depth':max_depth, 'max_leaves':max_leaves, 'min_child_weight':min_child_weight}\n\n# cross validation to tune hyperparameter\ng_xg_boosting = GridSearchCV(xg_boosting, param_grid = xgboosting_grid, cv=KFold(n_splits=5,shuffle=True))\n\n# train the model using the classifier\nxg_boosting.fit(X_train, y_train)\n \n# performing predictions on the test dataset\ny_xg_boosting_test_pred = xg_boosting.predict(X_test)\ny_xg_boosting_train_pred = xg_boosting.predict(X_train)\n\n# fit the grid\ng_xg_boosting.fit(X_train, y_train)\n\n# best hyperparameter\ng_xgboosting_param = g_xg_boosting.best_params_\n\n# The mean absolute error\nxg_boosting_test_mae = mean_absolute_error(y_test, y_xg_boosting_test_pred)\nxg_boosting_train_mae = mean_absolute_error(y_train, y_xg_boosting_train_pred)\n\n# The mean squared error\nxg_boosting_test_mse = mean_squared_error(y_test, y_xg_boosting_test_pred)\nxg_boosting_train_mse = mean_squared_error(y_train, y_xg_boosting_train_pred)\n\n# The coefficient of determination: 1 is perfect prediction\nxg_boosting_test_r2 = r2_score(y_test, y_xg_boosting_test_pred)\nxg_boosting_train_r2 = r2_score(y_train, y_xg_boosting_train_pred)\n\n# The root mean squared error\nxg_boosting_test_rmse = sqrt(mean_squared_error(y_test, y_xg_boosting_test_pred))\nxg_boosting_train_rmse = sqrt(mean_squared_error(y_train, y_xg_boosting_train_pred))\n\n# stop timer\nt1_stop = process_time()\n\n# Elapsed time\nxg_boosting_time = t1_stop-t1_start\n\nprint(\"Elapsed time in seconds to run XGBoosting Regressor:\", xg_boosting_time)","d7318590":"import optuna\n\ndef objective(trial):\n    \n    \n    colsample_bylevel = trial.suggest_float(\"colsample_bylevel\", 0, 1)\n    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0, 1)\n    booster= trial.suggest_categorical(\"booster\",choices=[\"gbtree\", \"gblinear\"])\n    gamma = trial.suggest_float(\"gamma\", 0, 1000)\n    learning_rate = trial.suggest_float(\"learning_rate\", 0, 1)\n    max_delta_step = trial.suggest_float(\"max_delta_step\", 0, 1000)\n    max_depth = trial.suggest_int(\"max_depth\", 1, 25)\n    min_child_weights = trial.suggest_float(\"min_child_weights\", 0, 100)\n    n_estimators = trial.suggest_int(\"n_estimators\", 10, 2000)\n    reg_alpha = trial.suggest_float(\"reg_alpha\", 0, 1000)\n    reg_lambda = trial.suggest_float(\"reg_lambda\", 0, 1000)\n    \n\n    ## Create Model\n    \n    optuna_xgboost  = xgb.XGBRegressor(n_estimators=n_estimators, reg_alpha=reg_alpha, reg_lambda=reg_lambda, colsample_bylevel=colsample_bylevel, colsample_bytree=colsample_bytree, booster=booster, gamma=gamma, max_depth=max_depth, learning_rate=learning_rate, max_delta_step=max_delta_step, min_child_weights=min_child_weights)\n    \n    ## Fit Model\n    \n    optuna_xgboost.fit(X_train, y_train)\n\n    return mean_squared_error(y_test, optuna_xgboost.predict(X_test))\n    \n\nt1_start = process_time()\n\n\nstudy8 = optuna.create_study(study_name=\"XGBoost\")\nstudy8.optimize(objective, n_trials=47)\n\n# evaluation metrics\n\noptuna_xgboost_rmse = sqrt(study8.best_value)\noptuna_xgboost_mse = study8.best_value\noptuna_xgboost_params = study8.best_params\n\n# stop timer\nt1_stop = process_time()\n\n# Elapsed time\nxgboost_time = t1_stop-t1_start\n\nprint(\"Elapsed time in seconds to run XGBoost Regressor with Optuna tuning hyperparameters:\", xgboost_time)\n\nprint(\"Best Params : {}\".format(optuna_xgboost_params))\nprint(\"\\nBest MSE : {}\".format(optuna_xgboost_mse))\nprint(\"\\nBest RMSE : {}\".format(optuna_xgboost_rmse))\n","97467d6a":"# cross validation\n\ncv_xg_boosting_train = cross_val_score(g_xg_boosting, X_train, y_xg_boosting_train_pred, cv=KFold(n_splits=5,shuffle=True), scoring ='neg_mean_squared_error')\ncv_xg_boosting_test = cross_val_score(g_xg_boosting, X_test, y_xg_boosting_test_pred, cv=KFold(n_splits=5,shuffle=True), scoring ='neg_mean_squared_error')\ncv_xg_boosting_results = pd.DataFrame([-cv_xg_boosting_train, -cv_xg_boosting_test, -cv_dummy]).transpose()\ncv_xg_boosting_results.columns = ['Training Dataset', 'Test Dataset', 'Dummy']\ncv_xg_boosting_results","07933c5d":"plt.style.use('ggplot')\nsns.set_style('darkgrid')\nbins = np.linspace(start=0, stop=400000, num=50)\nhist = cv_xg_boosting_results.plot.hist(bins=bins, density=True, edgecolor=\"black\")\nplt.legend(bbox_to_anchor=(1.05, 0.8), loc=\"upper left\")\nplt.xlabel(\"Mean squared error\", size=18)\nplt.ylabel(\"Frequency\", size=18)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\n_ = plt.title(\"Cross-validation testing errors\", size=28, y=1.03) # the underscore avoid to have a line of code displayed above the graph\nplt.show()","0240470c":"pd.set_option(\"display.max_colwidth\", -1) # display the whole cell for best hyperparameter column\nxg_boosting_results = pd.DataFrame(['XGBoost', xg_boosting_time, g_xgboosting_param, optuna_xgboost_params, xg_boosting_train_mae, xg_boosting_test_mae, dummy_test_mae, xg_boosting_train_mse, xg_boosting_test_mse, optuna_xgboost_mse, dummy_test_mse, xg_boosting_train_rmse, xg_boosting_test_rmse, optuna_xgboost_rmse, dummy_test_rmse, xg_boosting_train_r2, xg_boosting_test_r2, dummy_test_r2]).transpose()\nxg_boosting_results.columns = ['Method', 'Elapsed Time','GridSearch Hyperparameters', 'Optuna Hyperparameters', 'Training MAE', 'Test MAE', 'Dummy MAE', 'Training MSE', 'Test MSE', 'Optuna Test MSE', 'Dummy MSE', 'Training RMSE', 'Test RMSE', 'Optuna Test RMSE', 'Dummy RMSE', 'Training R2', 'Test R2', 'Dummy R2']\nresults = pd.concat([ridge_results, lr_results, grad_boosting_results, elastic_results, lasso_results, tree_results, rf_results, svr_results, bagging_results, xg_boosting_results], axis = 0).reset_index().drop(columns='index')\nresults.style.apply(lambda x: ['background: lightblue' if x.name == 'Optuna Test RMSE' else '' for i in x])","ff2b5e21":"# features importance for random forest\nplt.style.use('ggplot')\nsns.set_style('darkgrid')\nplot_feature_importance(xg_boosting.feature_importances_,X.columns,'XGBoost')\nplt.savefig('xgboostfeatures.png', dpi=300, format='png', bbox_inches='tight') # don't crop the legend while saving the figure\nplt.show()","c8543c97":"# Training MSE\n\nfig = plt.figure(figsize =([15, 15]))\nplt.style.use('ggplot')\nsns.set_style('darkgrid')\nsplot = sns.barplot(data=results, x=results[\"Training MSE\"], y=results[\"Method\"], orient = 'h').set(ylabel=None)\nplt.xticks(fontsize=18)\nplt.yticks(fontsize=22)\nplt.title(\"Training MSE per Model\", size=24, y=1.01)\nplt.xlabel(\"Training MSE\", size=22)\nplt.savefig('msetrain.png', dpi=300, format='png', bbox_inches='tight') # don't crop the legend while saving the figure\nplt.show()","5d09ca68":"# Test MSE\n\nfig = plt.figure(figsize =([15, 15]))\nplt.style.use('ggplot')\nsns.set_style('darkgrid')\nsplot = sns.barplot(data=results, x=results[\"Test MSE\"], y=results[\"Method\"], orient = 'h').set(ylabel=None)\nplt.xticks(fontsize=18)\nplt.yticks(fontsize=22)\nplt.title(\"Test MSE per Model using GridSearch\", size=24, y=1.01)\nplt.xlabel(\"Test MSE\", size=22)\nplt.savefig('msetestgrid.png', dpi=300, format='png', bbox_inches='tight') # don't crop the legend while saving the figure\nplt.show()","998f2f68":"# Test MSE\n\nfig = plt.figure(figsize =([15, 15]))\nplt.style.use('ggplot')\nsns.set_style('darkgrid')\nsplot = sns.barplot(data=results, x=results[\"Optuna Test MSE\"], y=results[\"Method\"], orient = 'h').set(ylabel=None)\nplt.xticks(fontsize=18)\nplt.yticks(fontsize=22)\nplt.title(\"Test MSE per Model using Optuna\", size=24, y=1.01)\nplt.xlabel(\"Test MSE\", size=22)\nplt.savefig('msetestoptuna.png', dpi=300, format='png', bbox_inches='tight') # don't crop the legend while saving the figure\nplt.show()","737d67c4":"# Training RMSE\n\nfig = plt.figure(figsize =([15, 15])) \nplt.style.use('ggplot')\nsns.set_style('darkgrid')\nsplot = sns.barplot(data=results, x=results[\"Training RMSE\"], y=results[\"Method\"], orient = 'h').set(ylabel=None)\nplt.xticks(fontsize=18)\nplt.yticks(fontsize=22)\nplt.title(\"Training RMSE per Model\", size=36, y=1.01)\nplt.xlabel(\"Training RMSE\", size=28)\nplt.savefig('rmsetrain.png', dpi=300, format='png', bbox_inches='tight') # don't crop the legend while saving the figure\nplt.show()","14f441fa":"# Test RMSE\n\nfig = plt.figure(figsize =([15, 15])) \nplt.style.use('ggplot')\nsns.set_style('darkgrid')\nsplot = sns.barplot(data=results, x=results[\"Test RMSE\"], y=results[\"Method\"], orient = 'h').set(ylabel=None)\nplt.xticks(fontsize=18)\nplt.yticks(fontsize=22)\nplt.title(\"Test RMSE per Model using GridSearch\", size=36, y=1.01)\nplt.xlabel(\"Test RMSE\", size=28)\nplt.savefig('rmsetestgrid.png', dpi=300, format='png', bbox_inches='tight') # don't crop the legend while saving the figure\nplt.show()","c255a578":"# Test RMSE\n\nfig = plt.figure(figsize =([15, 15])) \nplt.style.use('ggplot')\nsns.set_style('darkgrid')\nsplot = sns.barplot(data=results, x=results[\"Optuna Test RMSE\"], y=results[\"Method\"], orient = 'h').set(ylabel=None)\nplt.xticks(fontsize=18)\nplt.yticks(fontsize=22)\nplt.title(\"Test RMSE per Model using Optuna\", size=36, y=1.01)\nplt.xlabel(\"Test RMSE\", size=28)\nplt.savefig('rmsetestoptuna.png', dpi=300, format='png', bbox_inches='tight') # don't crop the legend while saving the figure\nplt.show()","0ad887c5":"# Linear Regression (Ridge)","5df0935c":"# Set up Environment\n\nWe import all the relevant librairies to display our models.","8c1a3198":"# Mathematical Considerations\n\nIn order to define the best predictive model in the frame of our project, we'll use some scoring metrics for each model.\nWe are using **regression** models to predict our output because we work with continuous data.\n\nThe **Mean Squared Error**, **Mean Absolute error**, **Root Mean Squared Error**, and **R-Squared or Coefficient of determination** metrics are used to evaluate the performance of the model in regression analysis.\n\n**Mean Absolute Error** represents the average of the absolute difference between the actual and predicted values in the dataset. It measures the average of the residuals in the dataset.\n\n<div style=\"width:100%;text-align: center;\">\n<img align=middle src=\"https:\/\/i.imgur.com\/BmBC8VW.jpg\" width=\"350\"\/>\n    \n \n**Mean Squared Error** represents the average of the squared difference between the original and predicted values in the data set. It measures the variance of the residuals.\n\n<div style=\"width:100%;text-align: center;\">\n<img align=middle src=\"https:\/\/d1zx6djv3kb1v7.cloudfront.net\/wp-content\/media\/2019\/11\/Differences-between-MSE-and-RMSE-1-i2tutorials.jpg\" width=\"330\"\/>\n    \n \n**Root Mean Squared Error** is the **square root of Mean Squared error**. It measures the standard deviation of residuals.\n \n<div style=\"width:100%;text-align: center;\">\n<img align=middle src=\"https:\/\/miro.medium.com\/max\/966\/1*lqDsPkfXPGen32Uem1PTNg.png\" width=\"300\"\/>\n   \n\n**The coefficient of determination or R-squared** represents the proportion of the variance in the dependent variable which is explained by the linear regression model. It is a scale-free score i.e. irrespective of the values being small or large, the value of R square will be less than one.\n    \n<div style=\"width:100%;text-align: center;\">\n<img align=middle src=\"https:\/\/miro.medium.com\/max\/1400\/0*8rFYfZJfJZpW2cEV.png\" width=\"440\"\/>","c377e333":"# Features Importance\n\nhttps:\/\/scikit-learn.org\/stable\/auto_examples\/ensemble\/plot_forest_importances.html\n\nFeature importances are provided by the fitted attribute feature_importances_ and they are computed as the mean and standard deviation of accumulation of the impurity decrease within each tree.\n\nMDI = Mean Decrease in Impurity ","81f5bbd0":"# Linear Regression Model (Simple\/Least Squares)\n\nMore details here: https:\/\/realpython.com\/linear-regression-in-python\/\n\nThere are five basic steps when you\u2019re implementing linear regression:\n\n1. Import the packages and classes you need.\n2. Provide data to work with and eventually do appropriate transformations.\n3. Create a regression model and fit it with existing data.\n4. Check the results of model fitting to know whether the model is satisfactory.\n5. Apply the model for predictions.\n\nSimple linear regression is used to estimate the relationship between **two quantitative variables**. ","c07db9c9":"# Final Model Decision\n\nThe **XGBoost model** returns us with the best accuracy on the Test Set using Optuna hyperparameter based on MSE and RMSE metrics. We use a the feature importance attribute to notice the importance of the *ENERGYSTARScore* and we can see that the variable scores far from the top 10 variables which make it not important in the decision of the model design. ","c90cb780":"# Notes about Cross Validation\n\nTo start creating ML models, we gotta do cross-validation of our data which means dividing our dataset into a training set and a testing set.\nTo do so, usually, we divide our data into a certain number of blocks, for instance:\n\n- Ten Fold Blocks Cross Validation (10 blocks)\n- Four Fold Blocks Cross Validation (4 blocks)\n\nThen we can use our different models (logistic regression, KNN, SVM...) on our training set, compare them and see which one is the most fittable to our data.\n\n- The C parameter trades off correct classification of training examples against maximization of the decision function\u2019s margin. For larger values of C, a smaller margin will be accepted if the decision function is better at classifying all training points correctly. A lower C will encourage a larger margin, therefore a simpler decision function, at the cost of training accuracy. In other words C behaves as a regularization parameter in the SVM.\n\n- Kernel is the mathematical function used to define the hyperparameter and it can be: linear, polynomial, rbf for instance.\n\nGenerally cross validation is used for two purposes:\n\n- Defining the best hyperparameters for the model\n\n- Test the model on different data points","6a84d5dd":"# Support Vector Regression\n\nSupport Vector Regression (SVR) uses the same principle as SVM, but for regression problems. Let\u2019s spend a few minutes understanding the idea behind SVR.\n\n","584fc97c":"# Random Forests","9f28df98":"# Bagging for Regression","00de15c5":"# Decision Trees","0525fb1e":"# Correlation Matrix\n\nWe re-insert our correlation matrix from our exploratory phase because we notice some overfitting between our test and training datasets while creating the models.\n\nWe're working on predicting the variable *TotalGHGEmissions* so we want to define a threshold by which we'll not take in consideration the variables in our X features to not give too many degrees of freedom to our models.\n\nBy observing the correlation matrix, we gather the variables that are correlated to our predictive variable with a correlation above 40%.\n\n- PropertyGFATotal\n- PropertyGFABuilding(s)\n- LargestPropertyUseTypeGFA\n- SiteEnergyUse(kBtu)\n- SiteEnergyUseWN(kBtu)\n- SteamUse(kBtu)\n- Electricity(kWh)\n- Electricity(kBtu)\n- NaturalGas(therms)\n- NaturalGas(kBtu)\n- GHGEmissionsIntensity\n\nFrom this list, we also notice that some variables are highly correlated between them such as:\n\n- **PropertyGFATotal**, **PropertyGFABuilding(s)** and **LargestPropertyUseTypeGFA**\n- **SiteEnergyUse(kBtu)** and **SiteEnergyUseWN(kBtu)**\n- **Electricity(kWh)** and **Electricity(kBtu)**\n- **NaturalGas(therms)** and **NaturalGas(kBtu)**\n\nWe decide to keep **PropertyGFABuilding(s)** because it get a more accurate description of the building GFA and drop the two other correlated variables.\nWe decide to keep  **SiteEnergyUseWN(kBtu)** over SiteEnergyUse(kBtu).\nWe decide to keep the **Electricity(kBtu)** and **NaturalGas(kBtu)** because of there are measured in the same units so we keep a certain homogeneity in our data.\n\nFinally, we decide to drop the following variables that are too coreelated to one another:\n\n- PropertyGFATotal\n- LargestPropertyUseTypeGFA\n- SiteEnergyUse(kBtu)\n- SteamUse(kBtu)\n- Electricity(kWh)\n- NaturalGas(therms)\n- GHGEmissionsIntensity","751c4ad7":"# Features and Predictive Variable for CO2 Emissions\n\nWe import our features in a dataframe called X which will contain all the numerical (discrete) variables that do predict our predictive variable.\n\nAs predictive variable to predict the total CO2 emissions of a property in Seattle, we decide to pick *TotalGHGEmissions* that seems the most representative of our real case study, which means that the lower *TotalGHGEmissions* is, the lower the consumption of the building will be.\n\n*TotalGHGEmissions* is contained in our y dataframe for predictions","c9c26451":"# Convert Continuous Variables into Discrete Values\n\nAt the difference of LabelEncoder(), **OneHotEncoder()** does not create a hierarchy in the numerical values. In our case, we don't have hierarchy in our modalities, so we'll definitely use this class to convert the string into numerical values. \n\nWe're going to use on the categorical variables that did interest us during the exploratory phase:\n\n- BuildingType\n- PrimaryPropertyType\n- Neighborhood","2ce1d87c":"# Elastic Net","1c5cd24b":"# Naive Baseline Creation\n\nUsing the mean strategy, we create a baseline to compare our ML models\n","73ad08d3":"# XGBoost","8cfff34d":"# Statistical Results","45f9943f":"# Linear Regression (Lasso)","5dafa966":"# Removing the variables from the consumption bill for our predictions\n\nThere are certain variables that we don't want to work with because they depend on existing buildings.\nWe want to make our predictions for future buildings. ","8737bcc0":"# Gradient Boosting\n\nWe're going to use two cross-validation methods to define our hyperparameters. To define metrics on our training set we'll use GridSearchCV and for our test set, we'll use **Optuna** library."}}