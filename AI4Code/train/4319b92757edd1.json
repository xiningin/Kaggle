{"cell_type":{"d3b3a586":"code","fc6a2389":"code","dae52d96":"code","c0cac641":"code","d6f78bcc":"code","2629d638":"code","bf5d135e":"code","a79a98eb":"code","df26737a":"code","76153e4d":"code","7c59e0e3":"code","9ac7b898":"code","b04391d8":"code","5e709fac":"code","3ffd9d10":"code","6048806c":"code","a1185c8c":"code","54056863":"code","adc677db":"code","4b616411":"markdown","dac12190":"markdown","4cb146e6":"markdown","1b36b60c":"markdown","bd87be88":"markdown","fa403627":"markdown","858efb80":"markdown"},"source":{"d3b3a586":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom yellowbrick.cluster import KElbowVisualizer\nfrom scipy.stats import mode","fc6a2389":"data = pd.read_csv('..\/input\/seed-from-uci\/Seed_Data.csv')","dae52d96":"y = data['target']","c0cac641":"data = data.drop(columns = 'target')\ndata.rename(columns= {'A':'area', 'P':'perimeter', 'C':'compactness', 'LK':'length of kernel', 'WK':'width of kernel', 'LKG':'length of kernel groove'}, inplace=True)\ndata.head()","d6f78bcc":"sns.heatmap(data.corr(), square=True, annot=True, cbar=False, cmap='BuGn');","2629d638":"data_drop = data.drop(columns=['perimeter','width of kernel'])\ndata_drop","bf5d135e":"kmeans = KMeans(random_state=42)","a79a98eb":"visualizer = KElbowVisualizer(kmeans, k=(7))\nvisualizer.fit(data_drop)        # Fit the data to the visualizer\nvisualizer.show();        # Finalize and render the figure","df26737a":"kmeans = KMeans(n_clusters=3, random_state=1)\nclusters = kmeans.fit_predict(data_drop)","76153e4d":"def make_labels(y, clusters):\n    labels = np.zeros_like(clusters)\n    for i in range(3):\n        mask = (clusters == i)\n        labels[mask] = mode(y[mask])[0]\n    return labels","7c59e0e3":"labels = make_labels(y, clusters)","9ac7b898":"accuracy_score(y, labels)","b04391d8":"matrix = confusion_matrix(y, labels)\nsns.heatmap(matrix.T, square=True, annot=True, fmt='d', cbar=False)\nplt.xlabel('true label')\nplt.ylabel('predicted label');","5e709fac":"from sklearn.mixture import GaussianMixture as GMM\nmodel_gmm = GMM(n_components=3, random_state=42)#.fit(data_drop)\nmodel_gmm.fit(data_drop)\nlabels = model_gmm.predict(data_drop)\nplt.scatter(data['area'], data['A_Coef'], c=y, s=40, cmap='viridis'); # true","3ffd9d10":"labels = make_labels(y, labels)","6048806c":"from matplotlib.patches import Ellipse\n\ndef draw_ellipse(position, covariance, ax=None, **kwargs):\n    ax = ax or plt.gca()\n    \n    if covariance.shape == (2, 2): #Convert covariance to principal axes\n        U, s, Vt = np.linalg.svd(covariance)\n        angle = np.degrees(np.arctan2(U[1, 0], U[0, 0]))\n        width, height = 2 * np.sqrt(s)\n    \n    for nsig in range(1, 4): # Draw the Ellipse\n        ax.add_patch(Ellipse(position, nsig * width, nsig * height,\n                             angle, **kwargs)) \n    \ndef plot_gmm(gmm, X, labels, label=True, ax=None):\n    ax = ax or plt.gca()\n#     labels = gmm.fit(X).predict(X)\n    if label:\n        ax.scatter(X['area'], X['A_Coef'], c=labels, s=40, cmap='viridis', zorder=2)\n    else:\n        ax.scatter(X['area'], X['A_Coef'], s=40, zorder=2)\n    ax.axis('equal')\n    \n    w_factor = 0.2 \/ gmm.weights_.max()\n    for pos, covar, w in zip(gmm.means_, gmm.covariances_, gmm.weights_):\n        \n        covar = covar[np.ix_([0,3],[0,3])]\n        pos = pos[np.ix_([0,3])]\n        draw_ellipse(pos, covar, alpha=w * w_factor)\n\nplot_gmm(model_gmm, data_drop, labels)","a1185c8c":"accuracy_score(y, labels)","54056863":"matrix = confusion_matrix(y, labels)\nsns.heatmap(matrix.T, square=True, annot=True, fmt='d', cbar=False)\nplt.xlabel('true label')\nplt.ylabel('predicted label');","adc677db":"pd.options.display.max_rows = (len(y))\ndf = pd.DataFrame ({'Actual': y, 'Predicted': labels})\ndf","4b616411":"Yes, we got better result = 95.24% accuracy.\nTwo of the three classes were defined exactly 100%. The most problem for the definition for class 0, there many seeds predicted as class 2.\n\n#### Happy coding ###","dac12190":"Let's try to determine how many clusters we need for data analysis.\nWe saw that k = 3. \n(And this is rigth)","4cb146e6":"So we got 89.52% accuracy.\nHmm, maybe we can do it better...\nUse for our analysis Gaussian mixture model.\n","1b36b60c":"### Gaussian mixture model ###","bd87be88":"From the plot data we can see that parameters 'area', 'perimeter' and 'width' depend each other. \nSelect for data only: area.\nAnd stay independed parameters:\n* area\n* compactness\n* length of kernel\n* A_Coef\n* length of kernel groove","fa403627":"Because *k*-means don`t knows correct the identity of the cluster, labels 0-2 may be permuted.\nFix every learned cluster label with the true labels found in them:","858efb80":"Next function that will help visualize the locations and shapes of the GMM clusters by drawing ellipses based on the GMM parameters.\nAnd we can take a look at what our model predict for data."}}