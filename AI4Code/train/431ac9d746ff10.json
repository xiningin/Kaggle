{"cell_type":{"2dbfa708":"code","5235c431":"code","e5daac53":"code","97b866a2":"code","15ec3c9a":"code","ff35322d":"code","c81279d7":"code","d4372d0a":"code","e6823e16":"code","81acc87e":"code","c313d83f":"code","330b32e5":"code","720cc5f8":"code","3ead444e":"code","80a9d245":"code","8ecd2ae3":"code","cd0b1887":"code","084907d0":"code","d82509dd":"code","3efada2e":"code","3bcb2784":"code","75d28f1e":"code","68a5143e":"code","6072bd0e":"code","859b580d":"code","81d7417d":"code","8aabd440":"code","bc4f63c3":"code","394718e0":"code","6baed501":"code","364cb469":"code","e7f08859":"code","dde8be10":"code","569b2258":"code","e4c50051":"code","1b6b2a3b":"markdown","cf0d5c69":"markdown","f58d1e62":"markdown","2d95ec37":"markdown","53ab7bce":"markdown","7ee88e2e":"markdown","496e33da":"markdown","1adfb750":"markdown","afa92332":"markdown","1fb13799":"markdown","cae4f9e3":"markdown","7c98db9e":"markdown","9935a351":"markdown","0bab091c":"markdown","2e247a10":"markdown","cd9dda79":"markdown","ec3fd604":"markdown","94f7a03c":"markdown"},"source":{"2dbfa708":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, roc_auc_score, precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n\nimport glob\nimport cv2\nimport random\n\nimport tensorflow as tf\n\n#print versions\nprint('tensorflow version',tf.__version__)","5235c431":"def print_results(y_test, y_pred):\n    print('Accuracy   : {:.5f}'.format(accuracy_score(y_pred , y_test))) \n    print('AUC        : {:.5f}'.format(roc_auc_score(y_test , y_pred)))\n    print('Precision  : {:.5f}'.format(precision_score(y_test , y_pred)))\n    print('Recall     : {:.5f}'.format(recall_score(y_test , y_pred)))\n    print('F1         : {:.5f}'.format(f1_score(y_test , y_pred)))\n    print('Confusion Matrix : \\n', confusion_matrix(y_test, y_pred))","e5daac53":"train_path = '..\/input\/chest-xray-pneumonia\/chest_xray\/train'\nval_path = '..\/input\/chest-xray-pneumonia\/chest_xray\/val'\ntest_path = '..\/input\/chest-xray-pneumonia\/chest_xray\/test'","97b866a2":"train_files_original = glob.glob(train_path+'\/*\/*')\nval_files_original = glob.glob(val_path+'\/*\/*')\ntest_files = glob.glob(test_path+'\/*\/*')\n\nprint('number of train samples across classes:', len(train_files_original))\nprint('number of val samples across classes:', len(val_files_original))\nprint('number of test samples across classes:', len(test_files))","15ec3c9a":"files = np.unique(train_files_original + val_files_original)\ntrain_files, val_files = train_test_split(files, test_size=0.3, shuffle=True)\n\nprint('number of train samples:', len(train_files))\nprint('number of val samples:', len(val_files))","ff35322d":"count_normal = len([x for x in train_files if 'NORMAL' in x])\ncount_pneumonia = len([x for x in train_files if 'PNEUMONIA' in x])\n\nprint('Count of NORMAL images in train:', count_normal)\nprint('Count of PNEUMONIA images in train:', count_pneumonia)","c81279d7":"IMG_SIZE = 180\ndef process_inputs(files_list):\n  data = []\n  for file in files_list:\n    try:\n      # figure out label\n      parts = file.split('\/')\n      assert parts[-2] in ['NORMAL', 'PNEUMONIA']\n      label = 1 if parts[-2] == \"PNEUMONIA\" else 0\n\n      # figure out image pixel array\n      img_arr = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n      resized_arr = cv2.resize(img_arr, (IMG_SIZE, IMG_SIZE))\n    except Exception as e:\n      raise Exception(e)\n    data.append([resized_arr, label])\n  return np.array(data)","d4372d0a":"train = process_inputs(train_files)\nval = process_inputs(val_files)\ntest = process_inputs(test_files)","e6823e16":"x_train = []\ny_train = []\n\nx_val = []\ny_val = []\n\nx_test = []\ny_test = []\n\nfor feature, label in train:\n  x_train.append(feature)\n  y_train.append(label)\n\nfor feature, label in val:\n  x_val.append(feature)\n  y_val.append(label)\n\nfor feature, label in test:\n  x_test.append(feature)\n  y_test.append(label)","81acc87e":"# see one sample\nx_train[0]","c313d83f":"x_train = np.array(x_train) \/ 255.\nx_val = np.array(x_val) \/ 255.\nx_test = np.array(x_test) \/ 255.","330b32e5":"x_train = x_train.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\ny_train = np.array(y_train)\n\nx_val = x_val.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\ny_val = np.array(y_val)\n\nx_test = x_test.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\ny_test = np.array(y_test)","720cc5f8":"plt.imshow(x_train[0].reshape(180,180), cmap='gray')\nprint('label = ', y_train[0])","3ead444e":"print(len(x_train))\nprint(len(x_val))\nprint(len(x_test))","80a9d245":"fig, ax = plt.subplots(3, 3, figsize=(10, 7))\nax = ax.ravel()\nplt.tight_layout()\n\nfor i in range(3):\n  random_index = random.randint(0, min(len(x_train), len(x_val), len(x_test)))\n  ax[i].imshow(x_train[random_index].reshape(180,180), cmap='gray')\n  ax[i].set_title('Set: train, label (Pneumonia =) {}'.format(y_train[random_index]))\n\n  ax[i+3].imshow(x_val[random_index].reshape(180,180), cmap='gray')\n  ax[i+3].set_title('Set: val, label (Pneumonia =) {}'.format(y_val[random_index]))\n\n  ax[i+6].imshow(x_test[random_index].reshape(180,180), cmap='gray')\n  ax[i+6].set_title('Set: test, label (Pneumonia =) {}'.format(y_test[random_index]))","8ecd2ae3":"def conv_block(filters):\n  block = tf.keras.Sequential([\n    tf.keras.layers.SeparableConv2D(filters, (3,3), activation='relu', padding='same'),\n    tf.keras.layers.SeparableConv2D(filters, (3,3), activation='relu', padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D(),    \n  ])\n  return block","cd0b1887":"def dense_block(units, dropout_rate):\n  block = tf.keras.Sequential([\n    tf.keras.layers.Dense(units, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(dropout_rate),\n  ])\n  return block","084907d0":"def build_model():\n  model = tf.keras.Sequential([\n    tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 1)),\n    \n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same'),\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same'),\n    tf.keras.layers.MaxPool2D(),\n\n    conv_block(32),\n    conv_block(64),\n    \n    conv_block(128),\n    tf.keras.layers.Dropout(0.2),\n\n    conv_block(256),\n    tf.keras.layers.Dropout(0.2),\n\n    tf.keras.layers.Flatten(),\n    dense_block(256, 0.7),\n    dense_block(128, 0.5),\n    dense_block(64, 0.3),\n    \n    tf.keras.layers.Dense(1, activation='sigmoid')\n  ])\n  return model","d82509dd":"weight_for_normal = len(x_train) \/ (2 * count_normal)\nweight_for_pneumonia = len(x_train) \/ (2 * count_pneumonia)\n\nclass_weight = {0:weight_for_normal, 1:weight_for_pneumonia}\n\nprint('weight for class 0 (normal): {:.3f}'.format(weight_for_normal))\nprint('weight for class 1 (pneumonia): {:.3f}'.format(weight_for_pneumonia))","3efada2e":"# compile a vanilla model\n\nmodel_vanilla = build_model()\n\nmetrics = [\n  'accuracy', \n  tf.keras.metrics.Precision(name='precision'),\n  tf.keras.metrics.Recall(name='recall'),\n]\n\nmodel_vanilla.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics)","3bcb2784":"epochs = 30\nbatch_size = 100","75d28f1e":"history_vanilla = model_vanilla.fit(\n    x=x_train, \n    y=y_train, \n    epochs=epochs, \n    batch_size=batch_size, \n    validation_data=(x_val,y_val), \n    class_weight=class_weight\n)","68a5143e":"epochs_array = [i for i in range(epochs)]\nfig, ax = plt.subplots(1,3)\ntrain_precision = history_vanilla.history['precision']\ntrain_recall = history_vanilla.history['recall']\ntrain_loss = history_vanilla.history['loss']\n\nval_precision = history_vanilla.history['val_precision']\nval_recall = history_vanilla.history['val_recall']\nval_loss = history_vanilla.history['val_loss']\nfig.set_size_inches(20,5)\n\nax[0].plot(epochs_array, train_loss, 'g-o', label='Training Loss')\nax[0].plot(epochs_array, val_loss, 'r-o', label='Validation Loss')\nax[0].set_title('Training & Validation Loss')\nax[0].legend()\nax[0].set_xlabel('Epochs')\nax[0].set_ylabel('Loss')\nax[0].grid(True)\n\nax[1].plot(epochs_array, train_precision, 'go-', label='Training Precision')\nax[1].plot(epochs_array, val_precision, 'ro-', label='Validation Precision')\nax[1].set_title('Training & Validation Precision')\nax[1].legend()\nax[1].set_xlabel('Epochs')\nax[1].set_ylabel('Precision')\nax[1].grid(True)\n\nax[2].plot(epochs_array, train_recall, 'go-', label='Training Recall')\nax[2].plot(epochs_array, val_recall, 'ro-', label='Validation Recall')\nax[2].set_title('Training & Validation Recall')\nax[2].legend()\nax[2].set_xlabel('Epochs')\nax[2].set_ylabel('Recall')\nax[2].grid(True)\n\nplt.show()","6072bd0e":"predictions = model_vanilla.predict(x=x_test)\ny_pred = np.round(predictions).reshape(1,-1)[0]","859b580d":"print_results(y_test, y_pred)","81d7417d":"# compile fine tuned model\n\nmodel_ft = build_model()\n\nmetrics = [\n  'accuracy', \n  tf.keras.metrics.Precision(name='precision'),\n  tf.keras.metrics.Recall(name='recall'),\n]\n\nmodel_ft.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics)","8aabd440":"checkpoint_cb = tf.keras.callbacks.ModelCheckpoint('xray_model.h5', save_best_only=True)\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, mode='min', verbose=1, restore_best_weights=True)","bc4f63c3":"def exponential_decay(lr0, s):\n    def exponential_decay_fn(epoch):\n        return lr0 * 0.1 **(epoch \/ s)\n    return exponential_decay_fn\n\nexponential_decay_fn = exponential_decay(0.01, 20)\n\nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)","394718e0":"epochs = 50\nbatch_size = 64","6baed501":"history_ft = model_ft.fit(\n    x=x_train, \n    y=y_train, \n    epochs=epochs, \n    batch_size=batch_size, \n    validation_data=(x_val,y_val), \n    class_weight=class_weight,\n    callbacks = [checkpoint_cb, early_stopping_cb, lr_scheduler]\n)","364cb469":"epochs_array = [i for i in range(len(history_ft.history['accuracy']))]\nfig, ax = plt.subplots(1,3)\ntrain_precision = history_ft.history['precision']\ntrain_recall = history_ft.history['recall']\ntrain_loss = history_ft.history['loss']\n\nval_precision = history_ft.history['val_precision']\nval_recall = history_ft.history['val_recall']\nval_loss = history_ft.history['val_loss']\nfig.set_size_inches(20,5)\n\nax[0].plot(epochs_array, train_loss, 'g-o', label='Training Loss')\nax[0].plot(epochs_array, val_loss, 'r-o', label='Validation Loss')\nax[0].set_title('Training & Validation Loss')\nax[0].legend()\nax[0].set_xlabel('Epochs')\nax[0].set_ylabel('Loss')\nax[0].grid(True)\n\nax[1].plot(epochs_array, train_precision, 'go-', label='Training Precision')\nax[1].plot(epochs_array, val_precision, 'ro-', label='Validation Precision')\nax[1].set_title('Training & Validation Precision')\nax[1].legend()\nax[1].set_xlabel('Epochs')\nax[1].set_ylabel('Precision')\nax[1].grid(True)\n\nax[2].plot(epochs_array, train_recall, 'go-', label='Training Recall')\nax[2].plot(epochs_array, val_recall, 'ro-', label='Validation Recall')\nax[2].set_title('Training & Validation Recall')\nax[2].legend()\nax[2].set_xlabel('Epochs')\nax[2].set_ylabel('Recall')\nax[2].grid(True)\nplt.show()","e7f08859":"predictions = model_ft.predict(x=x_test)\ny_pred = np.round(predictions).reshape(1,-1)[0]","dde8be10":"print_results(y_test, y_pred)","569b2258":"incorrect = np.nonzero(y_test != y_pred)[0]","e4c50051":"fig, ax = plt.subplots(3, 2, figsize=(15,15))\nax = ax.ravel()\nplt.subplots_adjust(wspace=0.25, hspace=0.75)\nplt.tight_layout()\ni = 0\nfor c in incorrect[:6]:\n    ax[i].set_xticks([])\n    ax[i].set_yticks([])\n    ax[i].imshow(x_test[c].reshape(IMG_SIZE,IMG_SIZE), cmap='gray', interpolation='none')\n    ax[i].set_title('Predicted Class: {}, Actual Class: {}'.format(y_pred[c], y_test[c]))\n    i += 1 ","1b6b2a3b":"Utility function to assess accuracy metrics:","cf0d5c69":"Check distribution of classes in train set","f58d1e62":"As seen above, our fine tuned model is able to correctly identify almost all pneumonia positive cases (~99.5% recall). Precision has improved as well - on the flip side, ~74% precision means that out of all patients diagnosed as pneumoniatic by our model, a false alarm is generated for ~26% healthy patients. In an ideal situation, we would prefer even higher precision keeping recall at current levels, but there is a trade off between precision and recall...If you have thoughts about how to improve precision while keeping high recall, please let me know in comments.","2d95ec37":"While loading data we noticed that there is a class imbalance between normal vs pneumonia samples - pneumonia samples are approximately 3x normal samples. Let's utilize 'class_weight' to counter class imbalance","53ab7bce":"## 1. Load Data","7ee88e2e":"Lastly, here are the resources \/ notebooks I referred while building my model:\n1. https:\/\/www.kaggle.com\/amyjang\/tensorflow-pneumonia-classification-on-x-rays\/comments\n2. https:\/\/towardsdatascience.com\/deep-learning-for-detecting-pneumonia-from-x-ray-images-fc9a3d9fdba8\n3. https:\/\/www.kaggle.com\/aakashnain\/beating-everything-with-depthwise-convolution","496e33da":"### 4.1. Fine Tune Model","1adfb750":"There appears to be imbalance in number of normal and pneumonia cases, we'll handle it through class_weight during model building","afa92332":"## 2. Process Inputs","1fb13799":"As you can see, there are only 16 samples in validation set (~0.3%), we would prefer to have a greater proportion of samples included in validation set. Let's create a 80:30 split between train and test","cae4f9e3":"To make the code easier to understand, let's define functions to add Conv layers and Dense layers","7c98db9e":"## 4. Build and Train CNN","9935a351":"The images originally have values that range from [0, 255]. CNNs work better with smaller numbers so we will scale this down.","0bab091c":"### 4.2. Look at incorrectly classified cases\n","2e247a10":"Since normal samples are less, there will be a higher penalty (proportional to weight) to mis-classify normal sample","cd9dda79":"Checklist for me to try in future:\n1. Use Data Augmentation techniques as an alternative to class_weight to handle class imbalance\n2. Try other optimizers\n3. Transfer Learning","ec3fd604":"The recall on test set is impressive - and is according to our preference, we would like to identify all pneumonia cases. Let's fine tune the model to see if precision could be better...","94f7a03c":"## 3. Visualize"}}