{"cell_type":{"c3d60884":"code","a8a84d3a":"code","e289b9d0":"code","124ed62c":"code","67c5eeb8":"code","38794dbb":"code","2580f6b4":"code","fedb57e9":"code","2ff5da33":"code","71d077ba":"code","78c6bd17":"code","12b5af1a":"code","7dd06e4f":"code","b1d1bf30":"code","0c861546":"code","02de2353":"code","b130457a":"code","a2df8042":"code","991c9ac7":"code","ea2ca2ed":"code","af4911ac":"code","4b4e7c95":"code","365db5e7":"code","a357ed0c":"code","2d1aa60e":"code","81759149":"code","af06928e":"code","b58bb607":"code","6f667a89":"code","180e1653":"code","e622333d":"code","5f4d2b1e":"code","e7dd3524":"code","d73a41d8":"code","771f52a9":"code","3fc26fc9":"code","1a1566cc":"code","d04dff9f":"markdown","21f33435":"markdown","d92962d9":"markdown","69e2f4eb":"markdown","31b1cce0":"markdown","5ebb2a6b":"markdown","821cb511":"markdown","aa436d6f":"markdown","cd921290":"markdown","89f4b970":"markdown","d33f4351":"markdown","0faad6bd":"markdown","4937cfb9":"markdown","091d1658":"markdown","3831771b":"markdown","1893784b":"markdown","0df86cce":"markdown","3c6f44c5":"markdown","ed482ae4":"markdown","a4373518":"markdown","e95a0e48":"markdown","daa4ae68":"markdown","9d7428aa":"markdown","c9d66166":"markdown","417b9cef":"markdown","cf352406":"markdown","8b9e20ef":"markdown","8688ac36":"markdown","b79e8bf4":"markdown","1a78025c":"markdown","23b64ddc":"markdown","006b0d8f":"markdown","904f9980":"markdown","6f50a3c3":"markdown","8283d04f":"markdown","c9202219":"markdown","1593cb8e":"markdown","ef8acbad":"markdown","f98febee":"markdown","8756e85f":"markdown"},"source":{"c3d60884":"!pip install librosa","a8a84d3a":"from plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nimport matplotlib.pyplot as plt\nimport IPython.display as ipd\nimport plotly.express as px\nimport librosa.display\nimport pandas as pd\nimport numpy as  np\nimport librosa\nimport warnings\nimport IPython\nimport os\n\nplt.style.use(\"ggplot\")","e289b9d0":"warnings.filterwarnings(action='ignore')","124ed62c":"\ntrain = pd.read_csv(\"..\/input\/birdsong-recognition\/train.csv\")","67c5eeb8":"train.info()","38794dbb":"train.head(3)","2580f6b4":"print(\"Train dataset has {} rows and {} columns\".format(*train.shape))","fedb57e9":"print(\"There are {} unique species of birds in train dataset\".format(train.species.nunique()))","2ff5da33":"species=train.species.value_counts()","71d077ba":"\nfig = go.Figure(data=[\n    go.Bar(y=species.values, x=species.index,marker_color='deeppink')\n])\n\nfig.update_layout(title='Distribution of Bird Species')\nfig.show()\n","78c6bd17":"country = train.country.value_counts()[:20]\nfig = go.Figure(data=[\n    go.Bar(x=country.index, y=country.values,marker_color='deeppink')\n])\n\nfig.update_layout(title='Countries from which data is obtained')\nfig.show()","12b5af1a":"plt.figure(figsize=(12, 8))\ntrain['date'].value_counts().sort_index().plot(color='pink',alpha=1)","7dd06e4f":"\n\nhist_data = pd.to_datetime(train.time,errors='coerce').dropna().dt.hour.values.tolist()\nfig = go.Figure(data=[go.Histogram(x=hist_data, histnorm='probability',marker_color='deeppink')])\nfig.update_layout(title='Time of the day at which data is obtained')\n\nfig.show()\n\n","b1d1bf30":"\n\nhist_data = train.duration.values.tolist()\nfig = go.Figure(data=[go.Histogram(x=hist_data,marker_color='deeppink')])\nfig.update_layout(title='Duration of the observation')\n\nfig.show()\n","0c861546":"\nhist_data = train.rating.values.tolist()\nfig = go.Figure(data=[go.Histogram(x=hist_data,marker_color='deeppink')])\nfig.update_layout(title='Rating of the observation')\n\nfig.show()\n","02de2353":"colors = ['gold', 'mediumturquoise', 'darkorange', 'lightgreen']\ndf = train.bird_seen.value_counts()\nfig = px.pie(df,df.index,df.values,labels={'index':'Bird Seen'})\nfig.update_traces(hoverinfo='label+percent', textinfo='value', textfont_size=20,\n                  marker=dict(colors=colors, line=dict(color='#000000', width=2)))\nfig.update_layout(title='Bird Seen')\n\nfig.show()","b130457a":"\nfig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\ndf = train.volume.value_counts()\nfig.add_trace(go.Pie(labels=df.index, values=df.values, name=\"Volume\"),\n              1, 1)\n\ndf = train.pitch.value_counts()\nfig.add_trace(go.Pie(labels=df.index ,values=df.values, name=\"Pitch\"),\n              1, 2)\n\n# Use `hole` to create a donut-like pie chart\nfig.update_traces(hole=.4, hoverinfo=\"label+percent+name\")\nfig.update_traces(hoverinfo='label+percent', textinfo='value', textfont_size=20,\n                  marker=dict(colors=colors, line=dict(color='#000000', width=2)))\n\nfig.update_layout(\n    title_text=\"Volume and Pitch of Observation\",\n    # Add annotations in the center of the donut pies.\n    annotations=[dict(text='Volume', x=0.18, y=0.5, font_size=20, showarrow=False),\n                 dict(text='Pitch', x=0.82, y=0.5, font_size=20, showarrow=False)])\nfig.show()","a2df8042":"rec = train.sampling_rate.value_counts()\nfig = go.Figure(data=[\n    go.Bar(x=rec.index, y=rec.values,marker_color='deeppink')\n])\n\nfig.update_layout(title='Top Recordists')\nfig.show()","991c9ac7":"rec = train.channels.value_counts()\nfig = go.Figure(data=[\n    go.Bar(x=rec.index, y=rec.values,marker_color='deeppink')\n])\n\nfig.update_layout(title='Top Recordists')\nfig.show()","ea2ca2ed":"df=train.length.value_counts()\nfig = px.pie(df,df.index,df.values,labels={'index':'length of audio'})\nfig.update_layout(title='Length of audio signal')\nfig.update_traces(hoverinfo='label+percent', textinfo='value', textfont_size=20,\n                  marker=dict(colors=colors, line=dict(color='#000000', width=2)))\n\nfig.show()","af4911ac":"df=train.groupby(['latitude','longitude'],as_index=False)['ebird_code'].agg('count')","4b4e7c95":"df=df[df.latitude!='Not specified']\nfig = go.Figure()\nfig.add_trace(go.Scattergeo(\n        lon = df['longitude'],\n        lat = df['latitude'],\n        text = df['ebird_code'],\n        marker = dict(\n            size = df['ebird_code'],\n            line_color='rgb(40,40,40)',\n            line_width=0.5,\n            sizemode = 'area'\n        )))\n\n\nfig.update_layout(\n        title_text = 'Bird Samples collected From Parts of World',\n        showlegend = True,\n        geo = dict(\n            landcolor = 'rgb(217, 217, 217)',\n        )\n    )\n\nfig.show()\n","365db5e7":"fig = go.Figure()\nfig.add_trace(go.Scattergeo(\n        locationmode = 'USA-states',\n        lon = df['longitude'],\n        lat = df['latitude'],\n        text = df['ebird_code'],\n        marker = dict(\n            size = df['ebird_code'],\n            line_color='rgb(40,40,40)',\n            line_width=0.5,\n            sizemode = 'area'\n        )))\n\n\nfig.update_layout(\n        title_text = 'Bird Samples collected From USA',\n        showlegend = True,\n        geo = dict(\n            scope = 'usa',\n            landcolor = 'rgb(217, 217, 217)',\n        )\n    )\n\nfig.show()\n","a357ed0c":"path=\"..\/input\/birdsong-recognition\/train_audio\/\"\nbirds=train.ebird_code.unique()[:6]\nfile=train[train.ebird_code==birds[0]]['filename'][0]","2d1aa60e":"\nfor i in range(0,2):\n    file=train[train.ebird_code==birds[i]]['filename'].values[0]\n    audio_path=os.path.join(path,birds[i],file)\n    print(birds[i])\n    IPython.display.display(ipd.Audio(audio_path))\n","81759149":"\nplt.figure(figsize=(17,20 ))\n\n\nfor i in range(0,6):\n    file=train[train.ebird_code==birds[i]]['filename'].values[0]\n    audio_path=os.path.join(path,birds[i],file)\n    plt.subplot(6,2,i+1)\n    x , sr = librosa.load(audio_path)\n    librosa.display.waveplot(x, sr=sr,color='r')\n    plt.gca().set_title(birds[i])\n    plt.gca().get_xaxis().set_visible(False)\n\n","af06928e":"plt.figure(figsize=(17,20 ))\n\n\nfor i in range(0,6):\n    file=train[train.ebird_code==birds[i]]['filename'].values[0]\n    audio_path=os.path.join(path,birds[i],file)\n    plt.subplot(6,2,i+1)\n    x , sr = librosa.load(audio_path)\n    x = librosa.stft(x)\n    Xdb = librosa.amplitude_to_db(abs(x))\n    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n    plt.gca().set_title(birds[i])\n    plt.gca().get_xaxis().set_visible(False)\n    plt.colorbar()","b58bb607":"import sklearn\n# Normalising the spectral centroid for visualisation\ndef normalize(x, axis=0):\n    return sklearn.preprocessing.minmax_scale(x, axis=axis)","6f667a89":"\nplt.figure(figsize=(17,20 ))\n\n\nfor i in range(0,6):\n    file=train[train.ebird_code==birds[i]]['filename'].values[0]\n    audio_path=os.path.join(path,birds[i],file)\n    plt.subplot(6,2,i+1)\n    x , sr = librosa.load(audio_path)\n    spectral_centroids = librosa.feature.spectral_centroid(x, sr=sr)[0]\n    frames = range(len(spectral_centroids))\n    t = librosa.frames_to_time(frames)\n    librosa.display.waveplot(x, sr=sr, alpha=0.4)\n    plt.plot(t, normalize(spectral_centroids), color='b')\n    plt.gca().set_title(birds[i])\n    plt.gca().get_xaxis().set_visible(False)\n    \n\n","180e1653":"plt.figure(figsize=(17,20 ))\n\n\nfor i in range(0,6):\n    file=train[train.ebird_code==birds[i]]['filename'].values[0]\n    audio_path=os.path.join(path,birds[i],file)\n    plt.subplot(6,3,i+1)\n    x , sr = librosa.load(audio_path)\n    spectral_centroids = librosa.feature.spectral_centroid(x, sr=sr)[0]\n    frames = range(len(spectral_centroids))\n    t = librosa.frames_to_time(frames)\n    spectral_rolloff = librosa.feature.spectral_rolloff(x+0.01, sr=sr)[0]\n    librosa.display.waveplot(x, sr=sr, alpha=0.4)\n    plt.plot(t, normalize(spectral_rolloff), color='r')\n    plt.gca().set_title(birds[i])\n    plt.gca().get_xaxis().set_visible(False)\n    ","e622333d":"\nplt.figure(figsize=(17,20 ))\n\n\nfor i in range(0,6):\n    file=train[train.ebird_code==birds[i]]['filename'].values[0]\n    audio_path=os.path.join(path,birds[i],file)\n    plt.subplot(6,3,i+1)\n    x , sr = librosa.load(audio_path)\n    spectral_centroids = librosa.feature.spectral_centroid(x, sr=sr)[0]\n    frames = range(len(spectral_centroids))\n    t = librosa.frames_to_time(frames)\n    spectral_bandwidth_2 = librosa.feature.spectral_bandwidth(x+0.01, sr=sr)[0]\n    spectral_bandwidth_3 = librosa.feature.spectral_bandwidth(x+0.01, sr=sr, p=3)[0]\n    spectral_bandwidth_4 = librosa.feature.spectral_bandwidth(x+0.01, sr=sr, p=4)[0]\n    librosa.display.waveplot(x, sr=sr, alpha=0.4)\n    plt.plot(t, normalize(spectral_bandwidth_2), color='r')\n    plt.plot(t, normalize(spectral_bandwidth_3), color='g')\n    plt.plot(t, normalize(spectral_bandwidth_4), color='y')\n    plt.gca().set_title(birds[i])\n    plt.gca().get_xaxis().set_visible(False)\n    plt.legend(('p = 2', 'p = 3', 'p = 4'))","5f4d2b1e":"x , sr = librosa.load(audio_path)\nplt.figure(figsize=(14, 5))\nlibrosa.display.waveplot(x, sr=sr)\n# Zooming in\nn0 = 9000\nn1 = 9100\nplt.figure(figsize=(14, 5))\nplt.plot(x[n0:n1])\nplt.grid()","e7dd3524":"zero_crossings = librosa.zero_crossings(x[n0:n1], pad=False)\nprint(sum(zero_crossings))","d73a41d8":"plt.figure(figsize=(17, 20))\n\nfor i in range(0,6):\n    file=train[train.ebird_code==birds[i]]['filename'].values[0]\n    audio_path=os.path.join(path,birds[i],file)\n    plt.subplot(6,2,i+1)\n    x , sr = librosa.load(audio_path)\n    mfccs = librosa.feature.mfcc(x, sr=sr)\n    librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n    plt.gca().set_title(birds[i])\n    plt.gca().get_xaxis().set_visible(False)\n    ","771f52a9":"plt.figure(figsize=(17, 20))\n\nfor i in range(0,6):\n    file=train[train.ebird_code==birds[i]]['filename'].values[0]\n    audio_path=os.path.join(path,birds[i],file)\n    plt.subplot(6,3,i+1)\n    x , sr = librosa.load(audio_path)\n    chromagram = librosa.feature.chroma_stft(x, sr=sr)\n    librosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', cmap='coolwarm')\n    plt.gca().set_title(birds[i])\n    plt.gca().get_xaxis().set_visible(False)\n    ","3fc26fc9":"fig=plt.figure(figsize=(15,15))\nk=1\nfor i in range(5):\n    \n    file=train[train.ebird_code==birds[i]]['filename'].values[0]\n    audio_path=os.path.join(path,birds[i],file)\n    plt.subplot(5,3,k)\n    k+=1\n    x , sr = librosa.load(audio_path)\n    librosa.display.waveplot(x, sr=sr)\n    plt.gca().set_title('Spectral Centroid')\n    plt.gca().set_ylabel(birds[i])\n    plt.gca().get_xaxis().set_visible(False)\n\n    plt.subplot(5,3,k)\n    k+=1\n    spectral_centroids = librosa.feature.spectral_centroid(x, sr=sr)[0]\n    frames = range(len(spectral_centroids))\n    t = librosa.frames_to_time(frames)\n    spectral_rolloff = librosa.feature.spectral_rolloff(x+0.01, sr=sr)[0]\n    librosa.display.waveplot(x, sr=sr, alpha=0.4)\n    plt.plot(t, normalize(spectral_rolloff), color='r')\n    plt.gca().set_title('Spectral Rolloff ')\n    plt.gca().get_xaxis().set_visible(False)\n\n    plt.subplot(5,3,k)\n    k+=1\n    #spectral_centroids = librosa.feature.spectral_centroid(x, sr=sr)[0]\n    #frames = range(len(spectral_centroids))\n    #t = librosa.frames_to_time(frames)\n    spectral_bandwidth_2 = librosa.feature.spectral_bandwidth(x+0.01, sr=sr)[0]\n    spectral_bandwidth_3 = librosa.feature.spectral_bandwidth(x+0.01, sr=sr, p=3)[0]\n    spectral_bandwidth_4 = librosa.feature.spectral_bandwidth(x+0.01, sr=sr, p=4)[0]\n    librosa.display.waveplot(x, sr=sr, alpha=0.4)\n    plt.plot(t, normalize(spectral_bandwidth_2), color='r')\n    plt.plot(t, normalize(spectral_bandwidth_3), color='g')\n    plt.plot(t, normalize(spectral_bandwidth_4), color='y')\n    plt.gca().set_title('Spectral Bandwidth')\n    plt.gca().get_xaxis().set_visible(False)\n    plt.legend(('p = 2', 'p = 3', 'p = 4'))\n\n    \n#plt.gca().set_title('Comparing audio features for bird species')\nplt.tight_layout()\nplt.show()","1a1566cc":"fig=plt.figure(figsize=(15,15))\nk=1\nfor i in range(5):\n    \n    file=train[train.ebird_code==birds[i]]['filename'].values[0]\n    audio_path=os.path.join(path,birds[i],file)\n    plt.subplot(5,3,k)\n    k+=1\n    x , sr = librosa.load(audio_path)\n    s = librosa.stft(x)\n    Xdb = librosa.amplitude_to_db(abs(s))\n    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n    plt.gca().set_title('Spectrogram')\n    plt.gca().set_ylabel(birds[i])\n    plt.gca().get_xaxis().set_visible(False)\n\n    plt.subplot(5,3,k)\n    k+=1\n    mfccs = librosa.feature.mfcc(x, sr=sr)\n    librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n    plt.gca().set_title('MFFC features ')\n    plt.gca().get_xaxis().set_visible(False)\n\n    plt.subplot(5,3,k)\n    k+=1\n    chromagram = librosa.feature.chroma_stft(x, sr=sr)\n    librosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', cmap='coolwarm')\n    plt.gca().set_title('Chroma feature')\n    plt.gca().get_xaxis().set_visible(False)\n  \n\n    \n#fig.suptitle('Comparing audio features for bird species')\nplt.tight_layout()\nplt.show()","d04dff9f":"Zooming in...","21f33435":"### <font size='4' color='red'>Mel-Frequency Cepstral Coefficients(MFCCs)<\/font>\nThe Mel frequency cepstral coefficients (MFCCs) of a signal are a small set of features (usually about 10\u201320) which concisely describe the overall shape of a spectral envelope. It models the characteristics of the human voice.\n","d92962d9":"## <font size='5' color='red'>Objective<\/font>\nIn this competition the researchers from Cornell Lab of Ornithology\u2019s Center for Conservation Bioacoustics (CBC) wants the kaggle community to help them build an AI solution to identify bird species using their bird call audio.Birds are excellent indicators of deteriorating habitat quality and environmental pollution.If successful, your work will help researchers better understand changes in habitat quality, levels of pollution, and the effectiveness of restoration efforts.\n\n![](https:\/\/i.ytimg.com\/vi\/0LJY0a1dmhg\/maxresdefault.jpg)","69e2f4eb":"## <font size='4' color='red'>Sampling rate<\/font>\nSampling rate (audio) Sampling rate or sampling frequency defines the number of samples per second.\n","31b1cce0":"### <font size='4' color='red'>Chroma feature<\/font>\nA chroma feature or vector is typically a 12-element feature vector indicating how much energy of each pitch class, {C, C#, D, D#, E, \u2026, B}, is present in the signal. In short, It provides a robust way to describe a similarity measure between music pieces.\n\n","5ebb2a6b":"### <font size='3' color='red'>Samples from USA<\/font>","821cb511":"- Much of the bird samples are collected from USA,SO let's have a look at USA states","aa436d6f":"## <font size='4' color='blue'>Compare features for Species<\/font><a id='4'><\/a>","cd921290":"## <font size='4' color='red'>Playing some audio<\/font><a id='2'><\/a>","89f4b970":"###  Zero-Crossing Rate\nA very simple way for measuring the smoothness of a signal is to calculate the number of zero-crossing within a segment of that signal. A voice signal oscillates slowly \u2014 for example, a 100 Hz signal will cross zero 100 per second \u2014 whereas an unvoiced fricative can have 3000 zero crossings per second.\n![](https:\/\/miro.medium.com\/max\/1400\/1*E_XSqizmLNksjknrD8oV2w.png)","d33f4351":"## <font size='4' color='red'>Pitch and Volume<\/font>\nPitch and Volume of the recording","0faad6bd":"- 80% of time,the bird is visually seen while recoring the audio.","4937cfb9":"## <font size='4' color='red'>Spectrogram<\/font>\n\nA spectrogram is a visual way of representing the signal strength, or \u201cloudness\u201d, of a signal over time at various frequencies present in a particular waveform. Not only can one see whether there is more or less energy at, for example, 2 Hz vs 10 Hz, but one can also see how energy levels vary over time.A spectrogram is usually depicted as a heat map.","091d1658":"In this section,we will just visualize our audio signals in a 2D plot.","3831771b":"## <font size='3' color='red'>Channel<\/font>\nChannel is the passage way a signal or data is transported.One Channel is usually referred to as mono, while more Channels could either indicate stereo, surround sound and the like.","1893784b":"## <font size='4' color='red'>Bird Species<\/font>\n\nBird species name ( target col name )","0df86cce":"## <font size='5' color='blue'>Contents<\/font> \n\n\n* [Basic Exploratory Data analysis](#1)  \n    * [Getting started]()\n    * [Bird species in data]()\n    * [Countries from which samples are taken]()\n    * [Dates on which samples are collected]()\n    * [Popular time of the day]()\n    * [Duration of samples]()\n    * [Pitch and Volume]()\n    * [Sampling rate]()\n    * [Channels]()\n \n \n* [Audio Data analysis](#2)   \n     * [Playing audio]()\n     * [Visualizing audio in 2D]()\n     * [Spectrogram analysis]()\n \n \n* [Feature Extraction](#3)    \n     * [Spectral Centroid]()\n     * [Spectral Bandwidth]()\n     * [Spectral Rolloff]()\n     * [Zero-Crossing Rate]()\n     * [Mel-Frequency Cepstral Coefficients(MFCCs)]()\n     * [Chroma feature]()\n     \n* [Compare sound features](#4)","3c6f44c5":"## <font size='4' color='red'>Getting a Basic Idea<\/font><a id='2'><\/a>\n","ed482ae4":"## <font size='4' color='red'>Geographical Analysis<\/font>","a4373518":"\n<font size='5' color='blue'>Leave an upvote if you think this was helpful!<\/font>","e95a0e48":"### <font size='4' color='red'>Spectral Rolloff<\/font>\nIt is a measure of the shape of the signal. It represents the frequency at which high frequencies decline to 0. To obtain it, we have to calculate the fraction of bins in the power spectrum where 85% of its power is at lower frequencies.","daa4ae68":"## <font size='4' color='red'>Importing Libraries<\/font><a id='1'><\/a>\n","9d7428aa":"- We can see that there is exactly 100 samples for almost half number of species.\n- The min number of samples is for `Redhead`,it has only 9 samples.","c9d66166":"### <font size='4' color='red'>Spectral Centroid<\/font>\n\nThe spectral centroid indicates at which frequency the energy of a spectrum is centered upon or in other words It indicates where the \u201d center of mass\u201d for a sound is located. This is like a weighted mean:\n![](https:\/\/miro.medium.com\/max\/710\/1*DkT47WzLrjigT_KVhDoMuQ.png)\n\nwhere S(k) is the spectral magnitude at frequency bin k, f(k) is the frequency at bin k.","417b9cef":"There are seven points in which the wave crosses zero.","cf352406":"## <font size='4' color='red'>Duration<\/font>\nDuration of the observation\n\n","8b9e20ef":"## <font size='4' color='red'>Visualizing Audio<\/font>","8688ac36":"## <font size='4' color='red'>Bird Seen<\/font>\nIf the bird was seen during the recording.","b79e8bf4":"###  <font size='4' color='red'>Spectral Bandwidth<\/font>\nThe spectral bandwidth is defined as the width of the band of light at one-half the peak maximum (or full width at half maximum [FWHM]) and is represented by the two vertical red lines and \u03bbSB on the wavelength axis.\n![](https:\/\/miro.medium.com\/max\/1030\/1*oUtYY0-j6iEc78Dew3d0uA.png)","1a78025c":"## <font size='4' color='red'>Time<\/font>\nTime of the day in which the observation is made (in 24hrs format)","23b64ddc":"## <font size='4' color='red'>Country<\/font>\n\nCountry in which the observation is made","006b0d8f":"- Most number of samples are taken from USA.\n- North American countries dominates the list.","904f9980":"- 8.00 am seems to the peak time of observation.\n- Most samples are recoring in the morning time.","6f50a3c3":"- 44kHz is the common sampling rate used.","8283d04f":"## <font size='4' color='red'>Date<\/font>\nDate in which the observation is made","c9202219":"Now,let's compare spectrogram,MFFC feature and chroma feature for some bird species.","1593cb8e":"## <font size='5' color='blue'>Feature extraction from Audio signal<\/font><a id='3'><\/a>\n\n\nThe spectral features (frequency-based features), which are obtained by converting the time-based signal into the frequency domain using the Fourier Transform, like fundamental frequency, frequency components, spectral centroid, spectral flux, spectral density, spectral roll-off, etc.\n","ef8acbad":"## <font size='4' color='red'>Rating<\/font>\nRating given to the observation ( 0-5)","f98febee":"## <font size='4' color='red'>Length<\/font>\nlength of the the audio signal ","8756e85f":"- Date starts from 1992 to 2019.\n- Most number of samples where taken between 2013-2015."}}