{"cell_type":{"3867116d":"code","8fa207e0":"code","724700c4":"code","944e1307":"code","a3a2eef3":"code","4f69b54b":"code","8831c70c":"code","a3c7da40":"code","6024ea23":"code","f2ef75c8":"code","156a5384":"code","ca54f774":"code","a93d7016":"code","1aeb786e":"code","3a4e4f28":"code","2cfb536b":"code","83efd11f":"code","457b6da0":"code","0a8c8b09":"code","e40463da":"code","936f9483":"code","c0ee0a7f":"code","930ffc09":"code","8b87099b":"code","6294ced0":"code","cef1c379":"code","facbd29a":"code","207cc0d3":"code","654b4610":"code","e20a0beb":"code","d93e22ed":"code","ea3e81a4":"code","8b3c10da":"code","7b473e08":"code","0f3c9169":"code","67bcbe46":"code","1e1071e3":"code","fffffd2b":"code","a60bf086":"code","99c7fb7a":"code","2cd2617d":"code","5cefc1d0":"code","64c6aad1":"code","ec26b958":"code","e6a429e5":"code","d379ba88":"code","f8e69226":"code","8f281448":"code","008a6278":"code","e68cb9a7":"code","8a21aa8e":"markdown","e6b28787":"markdown","907fe2b9":"markdown","e02b6a5f":"markdown","70ddd2e5":"markdown","805a5e80":"markdown","748ecea4":"markdown","9be6f320":"markdown","58494da3":"markdown","07f8dd17":"markdown","fd3e4326":"markdown","3d68ed2a":"markdown","89ea50cf":"markdown"},"source":{"3867116d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8fa207e0":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport plotly.express as px\nimport tensorflow as tf\nimport plotly.graph_objects as go","724700c4":"data1=pd.read_csv('\/kaggle\/input\/graduate-admissions\/Admission_Predict.csv')\ndata2=pd.read_csv('\/kaggle\/input\/graduate-admissions\/Admission_Predict_Ver1.1.csv')","944e1307":"data1","a3a2eef3":"data2","4f69b54b":"data1.isnull().sum()","8831c70c":"data2.isnull().sum()","a3c7da40":"data1.info()","6024ea23":"data2.info()","f2ef75c8":"dataset=pd.DataFrame()","156a5384":"dataset=data1.append(data2)\ndataset","ca54f774":"dataset=dataset.drop(['Serial No.'],axis=1)\ndataset","a93d7016":"px.bar(dataset,x='University Rating',y='Chance of Admit ')","1aeb786e":"px.bar(dataset,x='GRE Score',y='Chance of Admit ',color='Research')","3a4e4f28":"px.scatter(dataset,y='CGPA',x='Chance of Admit ',color='University Rating')","2cfb536b":"sns.heatmap(dataset.corr(),annot=True)","83efd11f":"px.histogram(dataset,x='University Rating')","457b6da0":"px.histogram(dataset,x='GRE Score',color='Research')","0a8c8b09":"sns.lineplot(data=dataset,y='Chance of Admit ',x='GRE Score',hue='Research')","e40463da":"res=dataset['Research'].value_counts()","936f9483":"trace=go.Pie(values=res.values,\n            labels=res.index)\n\n\nfig=go.Figure(data=[trace])\n\nfig.show()","c0ee0a7f":"univ_rat=dataset['University Rating'].value_counts()","930ffc09":"trace=go.Pie(values=univ_rat.values,\n            labels=univ_rat.index)\n\n\nfig=go.Figure(data=[trace])\n\nfig.show()","8b87099b":"fig = px.scatter_matrix(dataset)\nfig.show()","6294ced0":"x=dataset.iloc[:,:-1].values\ny=dataset.iloc[:,-1].values","cef1c379":"x.shape","facbd29a":"y.shape","207cc0d3":"y=y.reshape(900,1)","654b4610":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,random_state=0,test_size=0.2)","e20a0beb":"from sklearn.preprocessing import PowerTransformer\nscaler =PowerTransformer()\nx_train=scaler.fit_transform(x_train)\nx_test=scaler.transform(x_test)\ny_train=scaler.fit_transform(y_train)\ny_test=scaler.transform(y_test)","d93e22ed":"ann=tf.keras.models.Sequential()","ea3e81a4":"ann.add(tf.keras.layers.Dense(units=7,activation='relu'))\n","8b3c10da":"ann.add(tf.keras.layers.Dense(units=4,activation='relu'))","7b473e08":"ann.add(tf.keras.layers.Dense(units=1))","0f3c9169":"ann.compile(optimizer='adam',loss='mean_squared_error')","67bcbe46":"ann.fit(x_train,y_train,batch_size=32,epochs=100)","1e1071e3":"y_pred=ann.predict(x_test)","fffffd2b":"y_pred","a60bf086":"from sklearn.metrics import r2_score\nacc=r2_score(y_test,y_pred)\nacc","99c7fb7a":"y_pred=ann.predict(x_test)\nnp.set_printoptions(precision=2)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))","2cd2617d":"from sklearn.ensemble import RandomForestRegressor\nrfg=RandomForestRegressor(n_estimators=300,random_state=0)\nrfg.fit(x_train,y_train)","5cefc1d0":"rfg_pred=rfg.predict(x_test)","64c6aad1":"from sklearn.metrics import r2_score\nacc1=r2_score(y_test,rfg_pred)\nacc1","ec26b958":"from sklearn.tree import DecisionTreeRegressor\ndtr=DecisionTreeRegressor(random_state=0)\ndtr.fit(x_train,y_train)","e6a429e5":"dtr_pred=dtr.predict(x_test)","d379ba88":"acc2=r2_score(y_test,dtr_pred)\nacc2","f8e69226":"from sklearn.linear_model import LinearRegression\nlr=LinearRegression()\nlr.fit(x_train,y_train)","8f281448":"lr_pred=lr.predict(x_test)","008a6278":"acc3=r2_score(y_test,lr_pred)\nacc3","e68cb9a7":"print(\"Accuracy for Random Forest Regression is {:.2%}\".format(acc1))\nprint(\"Accuracy for Neural Network is {:.2%}\".format(acc))\nprint(\"Accuracy for Decision Tree Regression is {:.2%}\".format(acc2))\nprint(\"Accuracy for Linear Regression is {:.2%}\".format(acc3))","8a21aa8e":"3. Decision Tree Regressor ","e6b28787":"2. Random Forest Regressor ","907fe2b9":"# Training ANN model","e02b6a5f":"# Splitting dataset ","70ddd2e5":"# Importing dataset","805a5e80":"# Results","748ecea4":"# Compiling ANN","9be6f320":"1. Neural Network","58494da3":"# Importing libraries","07f8dd17":"# Exploratory Data Analysis","fd3e4326":"4. Linear Regressor ","3d68ed2a":"# Making ANN model","89ea50cf":"# Feature Scaling"}}