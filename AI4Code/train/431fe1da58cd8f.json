{"cell_type":{"7dfd9da8":"code","266e0ac4":"code","c6dc00aa":"code","60322c0c":"code","b1c2c491":"code","8e4d4436":"code","352d9fde":"code","ca913005":"code","9164435e":"code","b2be3604":"code","b0e8d87a":"code","7e78e88b":"code","83172635":"code","705aacec":"code","b3549d86":"code","5af4cbc1":"code","c2f47c98":"code","ab076e43":"code","2b6bcdb9":"code","8cc5937b":"code","d690903b":"code","8474e197":"code","41525026":"code","c42fc82f":"code","30c51e51":"code","aef5acd6":"markdown","a1496ee5":"markdown","2e91584a":"markdown","9bf469f2":"markdown","0f8da55a":"markdown","89aaee13":"markdown","524650e7":"markdown"},"source":{"7dfd9da8":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")","266e0ac4":"df = pd.read_csv(\"..\/input\/heart-attack-analysis-prediction-dataset\/heart.csv\")","c6dc00aa":"df.head().T","60322c0c":"df.isnull().any()","b1c2c491":"df.output.value_counts()","8e4d4436":"df.isnull().any()","352d9fde":"for column in df.columns:\n    if column != \"output\":\n        sns.jointplot(x = column, y = \"output\", data = df, color=\"purple\")","ca913005":"## Correlation\n\ncorr=df.corr()\ncorr.style.background_gradient(cmap=\"inferno\")","9164435e":"end = df.shape[1] - 1\narray = df.values\n\nX = array[:,0:end]\ny = array[:,end]","b2be3604":"## Import ML Libraries\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, recall_score, precision_score\\\n\nfrom sklearn.preprocessing import StandardScaler","b0e8d87a":"scaler = StandardScaler()\n\nX = scaler.fit_transform(X)","7e78e88b":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.3, random_state = 1)","83172635":"## Measuring Model Accuracy\ndef evaluate_model(clf, X_test, y_test, model_name, oversample_type):\n    print('--------------------------------------------')\n    print('Model ', model_name)\n    print('Data Type ', oversample_type)\n    y_pred = clf.predict(X_test)\n    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n    recall = recall_score(y_test, y_pred, average=\"weighted\")\n    precision = precision_score(y_test, y_pred, average=\"weighted\")\n    \n    print('Confusion Matrix', end = \"\\n\")\n    cm = confusion_matrix(y_test, y_pred)\n    print(cm)\n    print('Classification Report')\n    print(classification_report(y_test, y_pred))\n    print('Returns the f1 Score, Recall Score and Precision Score')\n    return [model_name, oversample_type, f1, recall, precision]","705aacec":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import f1_score, classification_report, recall_score, precision_score\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV","b3549d86":"### Models\nmodels = []\n\n# models.append(('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis()))\nmodels.append(('DecisionTrees', DecisionTreeClassifier(random_state=42)))\nmodels.append(('RandomForest', RandomForestClassifier(random_state=42)))\nmodels.append(('LinearSVC', LinearSVC(random_state=0)))\nmodels.append(('AdaBoostClassifier', AdaBoostClassifier(random_state=42)))\nmodels.append(('SGD', SGDClassifier(random_state = 42)))\nmodels.append((\"CART\",  DecisionTreeClassifier(random_state = 42)))","5af4cbc1":"### Evaluate Models\nresults = []\nnames = []\n\n# evaluate each model in turn\nresults = []\nnames = []\nfor name, model in models:\n        kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n        cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n        results.append(cv_results)\n        names.append(name)\n        print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))","c2f47c98":"## Plot Performance\nplt.boxplot(results, labels = names)\nplt.title(\"Algorithm Comparism\")\nplt.xticks(rotation=45)\nplt.show()","ab076e43":"params_grid = {'bootstrap': [True, False],\n 'max_depth': [10, 50, None],\n 'max_features': ['auto', 'sqrt'],\n 'min_samples_leaf': [1, 2, 4],\n 'min_samples_split': [2, 5, 10],\n 'n_estimators': [200, 500]}","2b6bcdb9":"rfc = RandomForestClassifier(random_state=42)\n\nkfold = StratifiedKFold(n_splits=10,\n                        random_state=1,\n                        shuffle=True)\n\nrfc_cv = GridSearchCV(estimator=rfc,\n                       param_grid=params_grid,\n                       cv=kfold, verbose=0)\nrfc_cv.fit(X_train, y_train)","8cc5937b":"rfc_cv.best_params_","d690903b":"params_grid['bootstrap']","8474e197":"### PIPELINE\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import MinMaxScaler\n\nmodel = make_pipeline(MinMaxScaler(),\n                      RandomForestClassifier(bootstrap=True,\n                                             max_depth=10,\n                                             max_features=\"auto\",\n                                             min_samples_leaf=2,\n                                             min_samples_split=2,\n                                             n_estimators=20\n                                             ))\n\nmodel.fit(X_train, y_train)","41525026":"y_pred = model.predict(X_val)","c42fc82f":"evaluate_model(model, X_val, y_val, RandomForestClassifier, \"min_max_SCALED\")","30c51e51":"rfc_model = RandomForestClassifier(bootstrap=True,\n                                             max_depth=10,\n                                             max_features=\"auto\",\n                                             min_samples_leaf=2,\n                                             min_samples_split=2,\n                                             n_estimators=20\n                                             )\n\nevaluate_model(model, X_val, y_val, RandomForestClassifier, \"UN_SCALED Dataset\")","aef5acd6":"Age : Age of the patient\n\nSex : Sex of the patient\n\nexang: exercise induced angina (1 = yes; 0 = no)\n\nca: number of major vessels (0-3)\n\ncp : Chest Pain type chest pain type\n\nValue 1: typical angina\nValue 2: atypical angina\nValue 3: non-anginal pain\nValue 4: asymptomatic\ntrtbps : resting blood pressure (in mm Hg)\n\nchol : cholestoral in mg\/dl fetched via BMI sensor\n\nfbs : (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)\n\nrest_ecg : resting electrocardiographic results\n\nValue 0: normal\nValue 1: having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of > 0.05 mV)\nValue 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\nthalach : maximum heart rate achieved\n\ntarget : 0= less chance of heart attack 1= more chance of heart attack","a1496ee5":"## Setting Up for ML","2e91584a":"Quite balanced Outputs.","9bf469f2":"**** The accuracy from the Unscaled Dataset peforms better with a greater accuracy than when we apply the min max scaler. ****","0f8da55a":"No Null Values.","89aaee13":"The RandomForestClassifier model performs best here, in the next chunk, we would explore how to get the best from this model - by tuning the parameters.\n\n### Hyper-parameter Tuning","524650e7":"params_grid = {'bootstrap': [True, False],\n 'max_depth': [10, 50, 100, None],\n 'max_features': ['auto', 'sqrt'],\n 'min_samples_leaf': [1, 2, 4],\n 'min_samples_split': [2, 5, 10],\n 'n_estimators': [200, 500, 800]}"}}