{"cell_type":{"879b7a7d":"code","bc2796a1":"code","fab76b8a":"code","8c021dea":"code","47335e7d":"code","94daabec":"code","6adce58c":"code","367c072d":"code","0df3bef9":"code","caed6b53":"code","26e2520e":"code","a9a5cf8b":"code","7c93040f":"code","429c8661":"code","d1a052e9":"code","be7f92d5":"code","4bb07e10":"code","62a64d0a":"code","80be4c2b":"code","8a407fbd":"code","c50c10a0":"code","96f83ae1":"code","da0620ed":"code","47d3b03a":"code","ff8c8854":"code","f19aa4c5":"code","58904b13":"code","ea014d2b":"code","467cfb70":"code","2430cc9c":"markdown","e363ba8e":"markdown","157314af":"markdown","1a0c6279":"markdown","64852993":"markdown","4aff34a4":"markdown","c086d2a8":"markdown","50c20927":"markdown","103df099":"markdown","b5eeeb46":"markdown","f1b8a682":"markdown","bc1da83c":"markdown","5d45970d":"markdown","66b81b88":"markdown","522b07f6":"markdown","13d7c41e":"markdown","54a26c40":"markdown","71855c79":"markdown","b1954a52":"markdown","5513812e":"markdown","38d7ead1":"markdown","108b507a":"markdown","94fe97da":"markdown","f7972d4e":"markdown","0059c4c3":"markdown","788c2351":"markdown"},"source":{"879b7a7d":"# Let's install ignite as a custom package:\n!pip install git+https:\/\/github.com\/pytorch\/ignite.git --prefix=\/kaggle\/working\n    \nimport sys\nsys.path.insert(0, \"\/kaggle\/working\/lib\/python3.6\/site-packages\")","bc2796a1":"from pathlib import Path\n\nimport numpy as np\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.dataset import Subset\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import Compose, RandomResizedCrop, RandomVerticalFlip, RandomHorizontalFlip\nfrom torchvision.transforms import ColorJitter, ToTensor, Normalize\n\n\nFRUIT360_PATH = Path(\".\").resolve().parent \/ \"input\" \/ \"fruits-360_dataset\" \/ \"fruits-360\"\n\nimg_size = 64\n\ndevice = \"cuda\"\nif not torch.cuda.is_available():\n    device = \"cpu\"\n\ntrain_transform = Compose([\n    RandomHorizontalFlip(),    \n    RandomResizedCrop(size=img_size),\n    ColorJitter(brightness=0.12),\n    ToTensor(),\n    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\nval_transform = Compose([\n    RandomResizedCrop(size=img_size),\n    ToTensor(),\n    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\nbatch_size = 128\nnum_workers = 8\n\ntrain_dataset = ImageFolder((FRUIT360_PATH \/\"Training\").as_posix(), transform=train_transform, target_transform=None)\nval_dataset = ImageFolder((FRUIT360_PATH \/\"Test\").as_posix(), transform=val_transform, target_transform=None)\n\npin_memory = \"cuda\" in device\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, \n                          drop_last=True, pin_memory=pin_memory)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, \n                        drop_last=False, pin_memory=pin_memory)\n","fab76b8a":"print(\"PyTorch version: {} | Device: {}\".format(torch.__version__, device))\nprint(\"Train loader: num_batches={} | num_samples={}\".format(len(train_loader), len(train_loader.sampler)))\nprint(\"Validation loader: num_batches={} | num_samples={}\".format(len(val_loader), len(val_loader.sampler)))","8c021dea":"import torch.nn as nn\nfrom torchvision.models.squeezenet import squeezenet1_1\nfrom torch.optim import SGD","47335e7d":"model = squeezenet1_1(pretrained=False, num_classes=81)\nmodel.classifier[-1] = nn.AdaptiveAvgPool2d(1)\nmodel = model.to(device)","94daabec":"optimizer = SGD(model.parameters(), lr=0.01, momentum=0.5)\ncriterion = nn.CrossEntropyLoss()","6adce58c":"from ignite.engine import Engine, _prepare_batch, create_supervised_trainer\n\ndef model_update(engine, batch):\n    model.train()\n    optimizer.zero_grad()\n    x, y = _prepare_batch(batch, device=device)\n    y_pred = model(x)\n    loss = criterion(y_pred, y)\n    loss.backward()\n    optimizer.step()\n    return loss.item()\n\ntrainer = Engine(model_update)","367c072d":"from ignite.engine import Events\n\nlog_interval = 50 \nif 'cpu' in device:\n    log_interval = 5 \n\n@trainer.on(Events.ITERATION_COMPLETED)\ndef log_training_loss(engine):\n    iteration = (engine.state.iteration - 1) % len(train_loader) + 1\n    if iteration % log_interval == 0:\n        print(\"Epoch[{}] Iteration[{}\/{}] Loss: {:.4f}\".format(engine.state.epoch, iteration, len(train_loader), engine.state.output))\n","0df3bef9":"output = trainer.run(train_loader, max_epochs=1)","caed6b53":"from ignite.metrics import Loss, CategoricalAccuracy, Precision, Recall\n\n\nmetrics = {\n    'avg_loss': Loss(criterion),\n    'avg_accuracy': CategoricalAccuracy(),\n    'avg_precision': Precision(average=True), \n    'avg_recall': Recall(average=True)\n}","26e2520e":"from ignite.engine import create_supervised_evaluator\n\ntrain_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\nval_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)","a9a5cf8b":"import numpy as np\nfrom torch.utils.data.dataset import Subset\n\nrandom_indices = np.random.permutation(np.arange(len(train_dataset)))[:len(val_dataset)]\ntrain_subset = Subset(train_dataset, indices=random_indices)\n\ntrain_eval_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=num_workers, \n                               drop_last=True, pin_memory=\"cuda\" in device)","7c93040f":"@trainer.on(Events.EPOCH_COMPLETED)\ndef compute_and_display_offline_train_metrics(engine):\n    epoch = engine.state.epoch\n    print(\"Compute train metrics...\")\n    metrics = train_evaluator.run(train_eval_loader).metrics\n    print(\"Training Results - Epoch: {}  Average Loss: {:.4f} | Accuracy: {:.4f} | Precision: {:.4f} | Recall: {:.4f}\"\n          .format(engine.state.epoch, metrics['avg_loss'], metrics['avg_accuracy'], metrics['avg_precision'], metrics['avg_recall']))\n    \n    \n@trainer.on(Events.EPOCH_COMPLETED)\ndef compute_and_display_val_metrics(engine):\n    epoch = engine.state.epoch\n    print(\"Compute validation metrics...\")\n    metrics = val_evaluator.run(val_loader).metrics\n    print(\"Validation Results - Epoch: {}  Average Loss: {:.4f} | Accuracy: {:.4f} | Precision: {:.4f} | Recall: {:.4f}\"\n          .format(engine.state.epoch, metrics['avg_loss'], metrics['avg_accuracy'], metrics['avg_precision'], metrics['avg_recall']))    ","429c8661":"output = trainer.run(train_loader, max_epochs=1)","d1a052e9":"from torch.optim.lr_scheduler import ExponentialLR\n\n\nlr_scheduler = ExponentialLR(optimizer, gamma=0.8)\n\n\n@trainer.on(Events.EPOCH_STARTED)\ndef update_lr_scheduler(engine):\n    lr_scheduler.step()\n    # Display learning rate:\n    if len(optimizer.param_groups) == 1:\n        lr = float(optimizer.param_groups[0]['lr'])\n        print(\"Learning rate: {}\".format(lr))\n    else:\n        for i, param_group in enumerate(optimizer.param_groups):\n            lr = float(param_group['lr'])\n            print(\"Learning rate (group {}): {}\".format(i, lr))    ","be7f92d5":"from ignite.handlers import ModelCheckpoint\n\n\ndef score_function(engine):\n    val_avg_accuracy = engine.state.metrics['avg_accuracy']\n    # Objects with highest scores will be retained.\n    return val_avg_accuracy\n\n\nbest_model_saver = ModelCheckpoint(\"best_models\",  # folder where to save the best model(s)\n                                   filename_prefix=\"model\",  # filename prefix -> {filename_prefix}_{name}_{step_number}_{score_name}={abs(score_function_result)}.pth\n                                   score_name=\"val_accuracy\",  \n                                   score_function=score_function,\n                                   n_saved=3,\n                                   atomic=True,  # objects are saved to a temporary file and then moved to final destination, so that files are guaranteed to not be damaged\n                                   save_as_state_dict=True,  # Save object as state_dict\n                                   create_dir=True)\n\nval_evaluator.add_event_handler(Events.COMPLETED, best_model_saver, {\"best_model\": model})","4bb07e10":"training_saver = ModelCheckpoint(\"checkpoint\",\n                                 filename_prefix=\"checkpoint\",\n                                 save_interval=1000,\n                                 n_saved=1,\n                                 atomic=True,\n                                 save_as_state_dict=True,\n                                 create_dir=True)\n\nto_save = {\"model\": model, \"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler} \ntrainer.add_event_handler(Events.ITERATION_COMPLETED, training_saver, to_save)","62a64d0a":"from ignite.handlers import EarlyStopping\n\nearly_stopping = EarlyStopping(patience=10, score_function=score_function, trainer=trainer)\n\nval_evaluator.add_event_handler(Events.EPOCH_COMPLETED, early_stopping)","80be4c2b":"max_epochs = 10\n\noutput = trainer.run(train_loader, max_epochs=max_epochs)","8a407fbd":"!ls best_models\/","c50c10a0":"!ls checkpoint\/","96f83ae1":"class TestDataset(Dataset):\n    \n    def __init__(self, ds):\n        self.ds = ds\n        \n    def __len__(self):\n        return len(self.ds)\n    \n    def __getitem__(self, index):\n        return self.ds[index][0], index\n\n    \ntest_dataset = TestDataset(val_dataset)\n\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, \n                         drop_last=False, pin_memory=\"cuda\" in device)","da0620ed":"import torch.nn.functional as F\nfrom ignite._utils import convert_tensor\n\n\ndef _prepare_batch(batch):\n    x, index = batch\n    x = convert_tensor(x, device=device)\n    return x, index\n\n\ndef inference_update(engine, batch):\n    x, indices = _prepare_batch(batch)\n    y_pred = model(x)\n    y_pred = F.softmax(y_pred, dim=1)\n    return {\"y_pred\": convert_tensor(y_pred, device='cpu'), \"indices\": indices}\n\n    \nmodel.eval()\ninferencer = Engine(inference_update)    ","47d3b03a":"@inferencer.on(Events.EPOCH_COMPLETED)\ndef log_tta(engine):\n    print(\"TTA {} \/ {}\".format(engine.state.epoch, n_tta))\n\n    \nn_tta = 3\nnum_classes = 81\nn_samples = len(val_dataset)\n\n# Array to store prediction probabilities\ny_probas_tta = np.zeros((n_samples, num_classes, n_tta), dtype=np.float32)\n\n# Array to store sample indices\nindices = np.zeros((n_samples, ), dtype=np.int)\n    \n\n@inferencer.on(Events.ITERATION_COMPLETED)\ndef save_results(engine):\n    output = engine.state.output\n    tta_index = engine.state.epoch - 1\n    start_index = ((engine.state.iteration - 1) % len(test_loader)) * batch_size\n    end_index = min(start_index + batch_size, n_samples)\n    batch_y_probas = output['y_pred'].detach().numpy()\n    y_probas_tta[start_index:end_index, :, tta_index] = batch_y_probas\n    if tta_index == 0:\n        indices[start_index:end_index] = output['indices']","ff8c8854":"inferencer.run(test_loader, max_epochs=n_tta)","f19aa4c5":"y_probas = np.mean(y_probas_tta, axis=-1)\ny_preds = np.argmax(y_probas, axis=-1)","58904b13":"from sklearn.metrics import accuracy_score\n\ny_test_true = [y for _, y in val_dataset]","ea014d2b":"accuracy_score(y_test_true, y_preds)","467cfb70":"# Remove output to be able to commit\n!rm -R best_models\/ checkpoint\/ lib\/","2430cc9c":"and we need to define a train subset and its data loader:","e363ba8e":"### Events and Handlers\n\nIn order to accomplish above todo list *ignite* provides an event system that facilitates interaction at each step of the run:\n- *engine is started\/completed*\n- *epoch is started\/completed*\n- *batch iteration is started\/completed*\n\nSo that user can execute a custom code as an event handler.\n\n#### Training batch loss logging\n\nWe just define a function and add this function as a handler to the trainer. There are two ways to add a handler: via `add_event_handler`, via `on` decorator:","157314af":"### Final words\n\nThat's all for this kernel. If you liked it - please upvote. \n\nIf you liked *ignite*, please visit its [documentation site](https:\/\/pytorch.org\/ignite\/), [github code](https:\/\/github.com\/pytorch\/ignite) and checkout [examples](https:\/\/github.com\/pytorch\/ignite\/tree\/master\/examples) with `tensorboard`, `visdom` integration and how to train dcgan. Some other examples can be found [here](https:\/\/github.com\/vfdev-5\/ignite-examples). \n\nWe are actively working on it and appreciate all contributions and feedbacks. As always, PR are very welcome! \n\n","1a0c6279":"----\n\n##### More details\n\n\n\nLet's explain some details in the above code. Maybe you've remarked the following\n```python\nmetrics = train_evaluator.run(train_eval_loader).metrics\n```\nand you have a question what is the object returned by `train_evaluator.run(train_eval_loader)` that has `metrics` as attribute. \n\nActually, `Engine` contains a structure called `State` to pass data between handlers. Basically, `State` contains information on the current \nepoch, iteration, max epochs, etc and also can be used to pass some custom data, such as metrics. Thus, the above code can be rewritten as \n```python\nstate = train_evaluator.run(train_eval_loader)\nmetrics = state.metrics\n# or just\ntrain_evaluator.run(train_eval_loader)\nmetrics = train_evaluator.state.metrics\n```\n\n-----","64852993":"Let's check saved 3 best models and the checkpoint:","4aff34a4":"# Fruits 360 dataset with PyTorch and Ignite\n\nIn this kernel I would like to present recently released the first version of high-level library [*ignite*](https:\/\/github.com\/pytorch\/ignite) to help training neural networks in PyTorch.\n\n\n## Why to use *ignite* ?\n\n- ignite helps you write compact but full-featured training loops in a few lines of code\n- you get a training loop with metrics, early-stopping, model checkpointing and other features without the boilerplate\n\n## Installation\n\nJust run the following command:\n```bash\npip install pytorch-ignite\n```\nor with conda\n```bash\nconda install ignite -c pytorch\n```\n\nThe latest version can be installed from the [github](https:\/\/github.com\/pytorch\/ignite.git):\n```bash\ngit clone https:\/\/github.com\/pytorch\/ignite.git\ncd ignite && python setup.py install\n```","c086d2a8":"and that's it. A trainer is setup, so we can just simply execute `run` method and our model will be silently trained. We could also use a helper method `ignite.engine.create_supervised_trainer` to create a trainer without explicitly coding `model_update` function:\n```python\nfrom ignite.engine import create_supervised_trainer\n\ntrainer = create_supervised_trainer(model, optimizer, criterion, device)\n```\n\n\n> **Note:** update function should have two inputs : `engine` and `batch`\n\n\n\nLet's add more interaction with our created trainer:\n- add logging of loss function value every 50 iterations\n- run offline metrics computation on a subset of the training dataset\n- run metrics computation on the validation dataset once epoch is finished\n- checkpoint trained model every epoch\n- save 3 best models\n- add LR scheduling\n- add early stopping","50c20927":"#### Training checkpointing\n\nAs we move on training, we would like to store the best model, last trained model, optimizer and learning rate scheduler. With *ignite* it is not a problem, there is a special class `ModelCheckpoint` for these purposes. \n\nLet's use `ModelCheckpoint` handler to store the best model defined by validation accuracy. In this case we define a `score_function` that provides validation accuracy to the handler and it decides (max value - better) whether to save or not the model.","103df099":"## Run training\n\nNow we can just call `run` method and train model during a number of epochs ","b5eeeb46":"Looks good! \n\n> add logging of loss function value every 50 iterations\n\nDone!\n\n#### Offline training metrics and validation metrics\n\nNow let's add some code to compute metrics: average accuracy, precision, recall over a subset of the training dataset and validation dataset. What is *offline* training metrics and why ? By offline, I mean that we compute training metrics using a fixed model vs online when metrics are computed batchwise over model that keep changing every iteration.\n\nAt first we define metrics we want to compute:","f1b8a682":"Next we can define engines using a helper method `ignite.engine.create_supervised_evaluator`:","bc1da83c":"Now let's define another `ModelCheckpoint` handler to store trained model, optimizer and lr scheduler every 1000 iterations:","5d45970d":"Now let's define when to execute metrics computation and display results","66b81b88":"#### Learning rate scheduling\n\nThere are several ways to perform learning rate scheduling with *ignite*, here we will use the most simple one by calling `lr_scheduler.step()` every epoch:","522b07f6":"Before we starts with *ignite*, let's define essential things: \n- dataflow :\n    - train data loader\n    - validation data loader\n- model :\n   - let's take a small network SqueezeNet \n- optimizer : \n   - let's take SGD\n- loss function :\n    - Cross-Entropy","13d7c41e":"And let us begin\n\n## Ignite quickstart with Fruits 360 dataset\n\n### Engine\n\nThe base of the framework is `ignite.engine.Engine`, an object that loops a given number of times over provided data, executes a processing function and returns a result:\n```python\nwhile epoch < max_epochs:\n    # run once on data\n    for batch in data:\n        output = process_function(batch)\n```\n\nSo, a model trainer is simply an engine that loops multiple times over the training dataset and updates model parameters. \nSimilarly, model evaluation can be done with an engine that runs a single time over the validation dataset and computes metrics.","54a26c40":"Before running the inference, we may want to load the best model from the storage:\n```python\nmodel = squeezenet1_1(pretrained=False, num_classes=64)\nmodel.classifier[-1] = nn.AdaptiveAvgPool2d(1)  # Adapt the last average pooling to our data\nmodel = model.to(device)\n\nmodel_state_dict = torch.load(\"best_models\/model_best_model_N_val_accuracy=0.XYZ.pth\")\nmodel.load_state_dict(model_state_dict)\n```","71855c79":"Next step can be to create a submission using `indices` and `y_probas`. Here we will just compute accuracy on our test=validation dataset","b1954a52":"We are almost done with preparations and a cherry on top\n\n#### Early stopping\n\nLet's add another handler to stop training if model fails to improve a score defined by a `score_function` during 10 epochs:","5513812e":"## Inference\n\nLet's first create a test dataloader from validation dataset such that provided batch is composed of `(samples, sample_indices)`:","38d7ead1":"Let's check it again","108b507a":"Next let's define a handler to log steps during the inference and a handler to store predictions","94fe97da":"The same can be done with `add_event_handler` like this:\n```python\ntrainer.add_event_handler(Events.ITERATION_COMPLETED, log_training_loss)\n```\n\n\n> **Note:** handlers can also pass `args` and `kwargs`, so in general a handler can be defined as \n\n```python\n    def custom_handler(engine, *args, **kwargs):\n        pass\n\n    trainer.add_event_handler(Events.ITERATION_COMPLETED, custom_handler, *args, **kwargs)\n    # or \n    @trainer.on(Events.ITERATION_COMPLETED, *args, **kwargs)\n    def custom_handler(engine, *args, **kwargs):\n        pass\n```\n\nLet's see what happens if we run the trainer for a single epoch","f7972d4e":"Final probability aggregation can be done using mean or gmean","0059c4c3":"Nice !\n\n> run offline metrics computation on a subset of the training dataset\n\n> run metrics computation on the validation dataset once epoch is finished\n\nDone !","788c2351":"With ignite to implement an engine that inference on data is simple. Similarly when we created an evaluation engine, now we modify the update function to store output results. We will also perform what is called test time augmentation (TTA)."}}