{"cell_type":{"d9bd7d8e":"code","85e1c5e8":"code","1c188154":"code","0443f1b3":"code","3f0a77e6":"code","f92644a9":"code","fa85dbb8":"code","ed1b5388":"code","5701d04e":"code","9f5108e5":"code","8adf11cd":"code","8ffd8d0c":"code","34d02d64":"code","1eada12f":"code","f4fa1217":"code","f52d3f72":"code","c4578e4c":"code","83a5807c":"code","710b8ac8":"code","b81ff0d8":"code","5a4328ff":"code","eba47615":"code","8aefb842":"markdown","3454b19e":"markdown","b73d7997":"markdown","4dbe8bf5":"markdown","ec1b6afe":"markdown","4a8fe6b5":"markdown","47eec4a9":"markdown","60c39c43":"markdown","c5b84d1b":"markdown","be3f4b21":"markdown","10cf06f6":"markdown","81362a82":"markdown","d3c8ccf0":"markdown","e868da43":"markdown","62196563":"markdown","0ba6bfa8":"markdown"},"source":{"d9bd7d8e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport statsmodels.api as sm\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nimport itertools\n\nfrom fbprophet import Prophet  # for forecasting\nfrom fbprophet.plot import plot_plotly, plot_components_plotly\nfrom fbprophet.diagnostics import cross_validation, performance_metrics\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\ndf_train = pd.read_csv('..\/input\/daily-climate-time-series-data\/DailyDelhiClimateTrain.csv')\ndf_train.tail()","85e1c5e8":"df_test = pd.read_csv('..\/input\/daily-climate-time-series-data\/DailyDelhiClimateTest.csv')\ndf_test.head()","1c188154":"# based on the test size, set some parameters\ndf_test.shape\ntest_period = df_test.shape[0]\nhorizon = '120 days'","0443f1b3":"df_train = df_train[~(df_train['date'] == '2017-01-01')]\ndf_train.tail()","3f0a77e6":"fig = px.line(df_train, x=\"date\", y=\"meantemp\", title=\"Mean temperature\")\nfig.show()","f92644a9":"fig = px.line(df_train, x=\"date\", y=\"humidity\", title=\"Humidity\")\nfig.show()","fa85dbb8":"fig = px.line(df_train, x=\"date\", y=\"wind_speed\", title=\"Wind speed\")\nfig.show()","ed1b5388":"fig = px.line(df_train, x=\"date\", y=\"meanpressure\", title=\"Mean pressure\")\nfig.show()","5701d04e":"fig = px.imshow(df_train.iloc[:, 1:].corr())\nfig.show()","9f5108e5":"df_train[\"date\"] = pd.to_datetime(df_train[\"date\"])\ndecomp = sm.tsa.seasonal_decompose(df_train.set_index(\"date\")[\"meantemp\"], period=365)\ndf_decomp = pd.concat([decomp.trend, decomp.seasonal, decomp.resid], axis=1)","8adf11cd":"fig = px.line(df_decomp, y=\"trend\", title=\"Trend\")\nfig.show()","8ffd8d0c":"fig = px.line(df_decomp, y=\"seasonal\", title=\"Seasonality\")\nfig.show()","34d02d64":"fig = px.line(df_decomp, y=\"resid\", title=\"Residuals\")\nfig.show()","1eada12f":"df_prophet = df_train.rename(columns={'date': 'ds', 'meantemp': 'y'})\n\nm_bsl = Prophet(holidays_prior_scale=False)\nm_bsl.fit(df_prophet)\nfuture = m_bsl.make_future_dataframe(periods=365)\nforecast_bsl = m_bsl.predict(future)\n\nfig1 = plot_plotly(m_bsl, forecast_bsl, changepoints=True, changepoints_threshold=0.05)\nfig1.show()\n\nfig2 = plot_components_plotly(m_bsl, forecast_bsl)\nfig2.show()","f4fa1217":"x1 = np.random.laplace(0, 0.05, 10000)\nx2 = np.random.laplace(0, 0.01, 10000)\nx3 = np.random.laplace(0, 0.1, 10000)\n\nhist_data = [x1, x2, x3]\ngroup_labels = ['\u03c4 = 0.05', '\u03c4 = 0.01', '\u03c4 = 0.1']\n\nfig = ff.create_distplot(hist_data, group_labels, bin_size=0.001, show_rug=False)\nfig.update_layout(title_text='Laplace distribution with varying \u03c4')\nfig.show()","f52d3f72":"x1 = np.random.normal(0, 0.05, 10000)\nx2 = np.random.normal(0, 0.01, 10000)\nx3 = np.random.normal(0, 0.1, 10000)\n\nhist_data = [x1, x2, x3]\ngroup_labels = ['\u03c3 = 0.05', '\u03c3 = 0.01', '\u03c3 = 0.1']\n\nfig = ff.create_distplot(hist_data, group_labels, bin_size=0.001, show_rug=False)\nfig.update_layout(title_text='Gaussian distribution with varying \u03c3')\nfig.show()","c4578e4c":"cutoffs = pd.to_datetime(['2016-01-01', '2016-05-01', '2016-09-01'])\ndf_cv_bsl = cross_validation(m_bsl, cutoffs=cutoffs, horizon=horizon)","83a5807c":"param_grid = {\n    'changepoint_prior_scale': [0.001, 0.01, 0.1],\n    'seasonality_prior_scale': [0.1, 1.0, 10.0],\n}\n\n# Generate all combinations of parameters\nall_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\nrmses = []  # Store the RMSEs for each params here\n\n# Use cross validation to evaluate all parameters\nfor params in all_params:\n    m = Prophet(**params).fit(df_prophet)  # Fit model with given params\n    df_cv = cross_validation(m, cutoffs=cutoffs, horizon=horizon, parallel=\"processes\")\n    df_p = performance_metrics(df_cv, rolling_window=1)\n    rmses.append(df_p['rmse'].values[0])\n\n# Find the best parameters\ntuning_results = pd.DataFrame(all_params)\ntuning_results['rmse'] = rmses\nbest_params = all_params[np.argmin(rmses)]\nprint(best_params)","710b8ac8":"m_tuned = Prophet(changepoint_prior_scale=0.001, seasonality_prior_scale=10.0, holidays_prior_scale=False)\nm_tuned.fit(df_prophet)\nfuture = m_tuned.make_future_dataframe(periods=365)\nforecast_tuned = m_tuned.predict(future)\n\nfig1 = plot_plotly(m_tuned, forecast_tuned, changepoints=True, changepoints_threshold=0.001)\nfig1.show()\n\nfig2 = plot_components_plotly(m_tuned, forecast_tuned)\nfig2.show()","b81ff0d8":"df_cv_tuned = cross_validation(m_tuned, cutoffs=cutoffs, horizon=horizon)\n\ndf_results = df_cv_bsl[['ds', 'y']]\ndf_results['yhat_bsl'] = df_cv_bsl['yhat']\ndf_results['yhat_tuned'] = df_cv_tuned['yhat']\ndf_results['err_bsl'] = np.abs(df_results['y'] - df_results['yhat_bsl'])\/df_results['y']\ndf_results['err_tuned'] = np.abs(df_results['y'] - df_results['yhat_tuned'])\/df_results['y']\ndf_results['err_diff'] = df_results['err_bsl'] - df_results['err_tuned']\n\ndf_results = df_results.iloc[:365]  # just get results from first horizon\n\nfig = px.bar(df_results, x=\"ds\", y=\"err_diff\", title='Error difference (values > 0 favor tuned model)', labels={'err_diff': 'Baseline - tuned model error'})\nfig.show()","5a4328ff":"future = m_bsl.make_future_dataframe(periods=test_period)\nforecast_bsl = m_bsl.predict(future)\nforecast_tuned = m_tuned.predict(future)\ny_true = df_test['meantemp']\ny_pred_bsl = forecast_bsl['yhat'].tail(test_period)\ny_pred_tuned = forecast_tuned['yhat'].tail(test_period)","eba47615":"from sklearn.metrics import mean_absolute_percentage_error\n\nmape_bsl = mean_absolute_percentage_error(y_true, y_pred_bsl)\nmape_tuned = mean_absolute_percentage_error(y_true, y_pred_tuned)\ndiff = mape_bsl - mape_tuned\n\nmape_bsl = np.round(mape_bsl*100, 1)\nmape_tuned = np.round(mape_tuned*100, 1)\ndiff = np.round(diff*100, 1)\n\nprint(f\"Baseline MAPE: {mape_bsl}%, tuned MAPE: {mape_tuned}%, difference: {diff}%\")","8aefb842":"As we can see, our tuned model yields much better accuracy on nearly all points overall. Variability is quite high during the summer months, which is fine, although there are some notable differences in January and Feburary, which could be points to further investigate.\n\n# Testing the models\nFinally, let's compare the baseline and tuned Prophet models against the test set.","3454b19e":"We can see that the output is fairly similar to the original model, but with some subtle differences. Notably, the trend is completely inflexible - it's just a straight line! This suggests that a linear increase in temperature over time is a better fit to the data, which probably represents the effects of climate change more accurately during this period.\n\n# Comparing the tuned model with the baseline model\n\nNow let's compare our tuned model with our baseline model, to assure ourselves that this is a genuine improvement over the original. We calculate the absolute percentage error for each prediction for both models, then compare them against each other.","b73d7997":"We can see that the best parameters are `changepoint_prior_scale=0.001` and `seasonality_prior_scale=10.0`. This implies that we need to heavily increase the regularization on our changepoints.\n\n# Tuned model","4dbe8bf5":"# Load data and packages","ec1b6afe":"Let's jump right into forecasting with Facebook's Prophet. Prophet uses a simple decomposable time series model with trend, seasonality, and holidays:\n\n$$y(t) = g(t) + s(t) + h(t) + \\epsilon_t.$$\n\nHere, the time series $y$ at time $t$ is an additive function composed of non-periodic trend segments, $g(t)$, periodic changes (i.e., seasonal components, occurring on a weekly or yearly cycle), $s(t)$, holidays, $h(t)$, and an error term, $\\epsilon_t$, which represent random effects not captured by previous terms. Importantly, $\\epsilon_t$ is a parametric term and is assumed to be normally distributed.\n\nWe can immediately see that we can simplify this model by setting $h(t) = 0$, since temperature is a physical quantity, rather than a social one (unless the climate takes holidays?). This allows us to focus solely on the trend and seasonal components of the model.","4a8fe6b5":"As we can see, draws from a Gaussian distribution yield much smoother distributions than corresponding Laplace distributions, and values of $\\sigma$ can be tuned within a greater range than $\\tau$.\n\n\n# Tuning hyperparameters with cross-validation\n\nNow that we understand the adjustable parameters of the trend ($\\tau$ or `changepoint_prior_scale`) and seasonal ($\\sigma$ or `seasonality_prior_scale`) components of a Prophet model, we can adjust them to better fit our data. By default, our baseline Prophet model was fit with `changepoint_prior_scale=0.05` and `seasonality_prior_scale=10.0`. We do so by separating the last 360 days of data to test the model. We then further divide that into four month chunks (~120 days), yielding 3 test sets for that model. Using our initial model, let's create some baseline scores.","47eec4a9":"## Descriptives","60c39c43":"We can see that our baseline Prophet model performed admirably, with a mean absolute percentage error of 12.0%. Our tuned model percentage error was 10.6%, which is a 1.3% reduction in error. Nice!","c5b84d1b":"## Correlation plots","be3f4b21":"## Cleaning data\nSeems like some of our train data has leaked into the test set - there are duplicate values for 2017-01-01. Let's drop it from the train set since it doesn't look realistic.","10cf06f6":"# Visualize data","81362a82":"As we can see, small changes in $\\tau$ can substantially change the resulting Laplace distribution. As values of $\\tau$ decrease, the potential range of numbers that can be drawn from that distribution becomes increasingly narrow. Therefore, smaller values of `changepoint_prior_scale` will yield increasingly rigid estimates of trend.\n\n## Seasonality\nSeasonal effects are periodic and can occur on multiple scales. Any arbitrary periodic function can be approximated using the Fourier series, which is the weighted sum of several sine and cosine functions:\n\n$$s(t) = \\sum_{n=1}^N \\bigg(a_n \\cos \\bigg(\\frac{2\\pi nt}{P}\\bigg) + b_n \\sin \\bigg(\\frac{2\\pi nt}{P}\\bigg)  \\bigg).$$\n\nHere $P$ corresponds to the period of the time series we wish to model. For example, if we had data sampled on a daily basis, $P = 7$ would correspond to a weekly cycle and $P = 365.25$ would correspond to an annual cycle (the .25 is to account for leap years). $N$ represents the number of seasonal parameters we want to estimate. If we wanted to model a weekly seasonality with $N = 10$, the corresponding vector would be:\n\n$$X(t) = \\bigg[\\cos \\bigg(\\frac{2\\pi (1)t}{7}\\bigg),...,\\sin \\bigg(\\frac{2\\pi (10)t}{7}\\bigg) \\bigg].$$\n\nThe seasonal component can therefore be calculated as,\n\n$$s(t) = X(t)\\beta,$$\n\nwhere $\\beta$ determines the seasonal smoothing prior drawn from a standard (Gaussian) distribution, $\\beta \\sim \\text{Gaussian}(0, \\sigma^2)$. Here, $\\sigma$ is an adjustable parameter corresponding to `seasonality_prior_scale`.","d3c8ccf0":"## Additive decomposition of mean temperature","e868da43":"# Univariate forecasting of temperature with Prophet","62196563":"We can see that Prophet has produced a pretty good forecast right out of the box, predicting reasonable daily temperatures into the next year. More informative are the individual components of the forecast. We can see that the trend component is fairly static from 2013-2015, then begins increasing from mid-2015 onwards, with an  increase of $\\approx1^{\\circ}\\text{C} \/ \\text{year}$. This is likely a reflection of the increasing burden of climate change, which is likely to accelerate over time if left unchecked. The yearly seasonal component is less informative - temperatures are warmer during summer months and colder during winter months. The weekly component, however, is interesting, as there appear to be slightly warmer temperatures in the middle of the week and slightly lower temperatures on the weekend. Note that the observed magnitude of this variation is quite small, $[-0.2, 0.2]$, and is unlikely to have a substantial influence on the overall forecast.\n\n## Trend changepoints\nBy visually inspecting the forecast plot, we can see red lines, which are changepoints. These correspond to points where the overall trend of temperatures changes. When this happens, Prophet will attempt to fit a different trend to the time series, allowing for greater flexibility. Suppose our time series has $S$ changepoints at $s_j$, where $j = 1, 2,...,S$. Each $s_j$ is associated with a change in rate, $\\delta_j$. The rate of change at any $t$ is therefore some base rate of change, $k$, with all trend adjustments up until that point, $k + \\sum_{j:t>s_{j}}\\delta_{j}$. This is easier to visualize using a vector, $a(t) \\in \\{0, 1\\}^S$, where\n\n$$a_j(t) = \\begin{cases} \n  1,& \\text{if } t\\geq s_j,\\\\\n  0,              & \\text{otherwise}.\n\\end{cases}$$\n\nIf $\\delta$ is a vector of $\\delta_j$ at each timepoint, then the trend rate at $t$ is $k + a(t)^\\top\\delta$. This formulation makes it easy to see the piecewise nature of the trend. Suppose that we are at $t=1$, with $\\delta_1=1$. The corresponding value $a_1 = 1$. The trend at this point is therefore $g(1) = k + 1$. Note that piecewise functions are discontinuous at break points, so we must add an offset parameter, $m$, which is adjusted by some value at each changepoint, $\\gamma_j$, in order to connect the lines. The final equation for a linear trend with changepoints is therefore:\n\n$$g(t) = (k + a(T)^\\top\\delta)t + (m + a(t)^\\top\\gamma).$$\n\n## Changepoint selection\nUnderstanding the math behind trend fitting in Prophet is all well and good, but where do we decide to put changepoints? These could be set manually, based on pre-existing knowledge of where trends may change. For instance, if we knew that a company with a big pollution record set up a factory in India on a certain day, we might delineate that day with a changepoint, as we expect temperatures to gradually increase in a way that they previously hadn't.\n\nIn practice, however, these factors may be hidden or opaque. In these cases, Prophet can decide on changepoints automatically, as it has done in the above example. These can be selected using by putting a sparse prior on $\\delta$ like the Laplace prior, such that $\\delta_j \\sim \\text{Laplace}(0, \\tau)$. The adjustable parameter $\\tau$ corresponds to `changepoint_prior_scale` in Prophet, and controls the flexibility of the model by altering its rate. The closer $\\tau$ is to 0, the more the model will approximate a standard linear, rather than piecewise, growth model. By contrast, larger values of $\\tau$ will increase the ability of the model to fit arbitrary trends, which may result in overfitting. We must therefore carefully balance values of $S$ and $\\tau$ to result in adequate model fitting. We can directly examine how different values of $\\tau$ can influence the sparse prior by plotting the Laplace distributions: ","0ba6bfa8":"Now let's test the model on a range of parameters using a grid search. We calculate the root mean squared error (RMSE) for each combination of parameters, then pick the one that yields the lowest RMSE on the test set."}}