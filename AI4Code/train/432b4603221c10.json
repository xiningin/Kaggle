{"cell_type":{"c6834043":"code","6756e0a2":"code","22f82a49":"code","efa9091a":"code","17bd5c78":"code","8a4aa963":"code","8fc6ac0f":"code","ce41f059":"code","9a744c4e":"code","2407b5e2":"code","17129efa":"code","1dc0b498":"code","55b104b8":"code","62ff1d7b":"code","4c16b59d":"code","6bbf4ade":"code","6e9a5a7e":"code","959b3b0b":"code","bd15b576":"code","c75aa5a2":"code","c56b084f":"code","fca5d79c":"code","5614d809":"code","4b9678c1":"code","1c902753":"code","9ed79437":"code","ee35e492":"code","8c707e40":"code","ed3c9d06":"code","886e0327":"code","0b4cd5b5":"code","6311c92f":"code","da5ea587":"code","8ad064c9":"code","67313582":"code","fc687706":"code","a9a964f5":"code","43298783":"code","bd51270b":"code","fabcfd8c":"code","14584ad8":"code","ab8bf96c":"code","353f04e9":"markdown","f7417c41":"markdown","7ad26255":"markdown","1ecd1ee0":"markdown","13faf077":"markdown","fbe6d4dd":"markdown","18619d31":"markdown","0d1f2b5b":"markdown","8120763e":"markdown","a20cb8cb":"markdown","252607d2":"markdown","67ccd80c":"markdown","4c796e39":"markdown","3049712a":"markdown","a06dd520":"markdown","729380de":"markdown","303b56b8":"markdown","fa4ba2cc":"markdown","95ab4cc6":"markdown","453168d5":"markdown","d1e7668d":"markdown","5229c7d0":"markdown","a29426cb":"markdown","ef380869":"markdown","897d5edb":"markdown","98484e08":"markdown","f52767f1":"markdown","11b09efa":"markdown","557a6a90":"markdown","bbe94026":"markdown","e5a110c8":"markdown","d1ad6464":"markdown","a07c000f":"markdown","1aa764fd":"markdown","6bbd2c68":"markdown","8b7dd54a":"markdown","83266d01":"markdown","dadaf141":"markdown","94e5990b":"markdown","eee75f96":"markdown","47e01be1":"markdown","bfb4e1e3":"markdown","4acdec50":"markdown","974159d4":"markdown","9fc2e5b3":"markdown","7b91d436":"markdown"},"source":{"c6834043":"# importing libararies\n\n# Warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# for Data\nimport pandas as pd\nimport numpy as np\nimport math\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(style='whitegrid')\nsns.set(font_scale=1.5);\n%matplotlib inline\n\n\n# Preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler; std_scaler = StandardScaler()\n\n# Splitting\nfrom sklearn.model_selection import train_test_split\n\n\n# Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier as RandomForest\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\n\n# Metrics\nfrom sklearn.metrics import fbeta_score, accuracy_score, make_scorer, classification_report\nfrom sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\n","6756e0a2":"# reading dataset\ndata = pd.read_csv('..\/input\/WA_Fn-UseC_-Telco-Customer-Churn.csv')","22f82a49":"data.head()","efa9091a":"# information about the dataset structure\ndata.info()","17bd5c78":"data['TotalCharges'] = data['TotalCharges'].convert_objects(convert_numeric=True)\ndata['TotalCharges'].dtype","8a4aa963":"# Numerical features stats\ndata.describe()","8fc6ac0f":"data.describe(include=['object'])","ce41f059":"for dataset in [data]:\n    dataset['MultipleLines'] = dataset['MultipleLines'].replace({'No phone service':'No'})\n    dataset['OnlineSecurity'] = dataset['OnlineSecurity'].replace({'No internet service':'No'})\n    dataset['DeviceProtection'] = dataset['DeviceProtection'].replace({'No internet service':'No'})\n    dataset['TechSupport'] = dataset['TechSupport'].replace({'No internet service':'No'})\n    dataset['StreamingTV'] = dataset['StreamingTV'].replace({'No internet service':'No'})\n    dataset['OnlineBackup'] = dataset['OnlineBackup'].replace({'No internet service':'No'})\n    dataset['StreamingMovies'] = dataset['StreamingMovies'].replace({'No internet service':'No'})\n    \nprint (\"Number of unique values in each column\\n\")\nfor col_name in data.columns:\n print(col_name,\": \" ,data[col_name].nunique())","9a744c4e":"# count of customers churn\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20,7))\nax = data['Churn'].value_counts().plot(kind='pie',autopct='%.1f%%', ax=axes[0])\nax.set_title('Number of customer churn', fontsize=15)\n\n\nax = sns.countplot(y='Churn', data=data, ax=axes[1]);\nfor i,j in enumerate(data[\"Churn\"].value_counts().values) : \n    ax.text(.1,i,j,fontsize = 20,color = \"k\")\n\nax.set_title('Number of customer churn', fontsize=15)\n","2407b5e2":"ig, ax = plt.subplots(figsize=(15,9))\nsns.violinplot(x=\"gender\", y=\"tenure\", hue='Churn', data=data, split=True, bw=0.05 , palette='husl', ax=ax)\nplt.title('Churn by gender ')\nplt.show()","17129efa":"g = sns.factorplot(x=\"InternetService\", y=\"tenure\", hue=\"Churn\", col=\"gender\", data=data, kind=\"swarm\", dodge=True, palette='husl', size=8, aspect=.9, s=8)","1dc0b498":"fig, ax = plt.subplots(figsize=(12, 5))\n\nax = sns.distplot(data[data['Churn']=='Yes']['MonthlyCharges'],label='Churn', bins= 10, kde=True)\n#ax = sns.distplot(data[data['Churn']=='No']['MonthlyCharges'],label='Not Churn', bins= 18, kde=False)\n\nax.legend()\nax.set_title('Monthly Charges distrobution for Churn cutomers')\nplt.show()","55b104b8":"fig, ax = plt.subplots(figsize=(20,12))\nax =  sns.stripplot('InternetService', 'MonthlyCharges', 'Churn', data=data,\n                        palette=\"husl\", size=15, marker=\"D\",\n                        edgecolor=\"red\", alpha=.30)","62ff1d7b":"FacetGrid = sns.FacetGrid(data, hue='Churn', aspect=4)\nFacetGrid.map(sns.kdeplot, 'tenure', shade=True)\nFacetGrid.set(xlim=(0, data['tenure'].max()))\nFacetGrid.add_legend()","4c16b59d":"FacetGrid = sns.FacetGrid(data, hue='Churn', aspect=4)\nFacetGrid.map(sns.kdeplot, 'TotalCharges', shade=True)\nFacetGrid.set(xlim=(0, data['TotalCharges'].max()))\nFacetGrid.add_legend()","6bbf4ade":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 7))\n\n# count of churn customers by payment method\nax = sns.countplot(y='PaymentMethod', hue='Churn', data=data, palette=\"husl\", ax=axes[0]);\n\nax.set_yticklabels(ax.get_yticklabels(), rotation=30, ha=\"right\")\nax.set_xlabel('Payment Method', fontsize = 12)\nax.set_ylabel('Number of Customers', fontsize = 12)\n\nax.set_title('Count of churn customers by Payment Method', fontsize=15)\n\n\n\n\n\n# count of customers by payment method\nax = sns.countplot(x='PaymentMethod', data=data, palette=\"husl\", ax=axes[1]);\n\nax.set_xticklabels(ax.get_xticklabels(), rotation=30, ha=\"right\")\nax.set_xlabel('Payment Method', fontsize = 12)\nax.set_ylabel('Number of Customers', fontsize = 12)\n\nax.set_title('Count customers by Payment Method', fontsize=15)\n","6e9a5a7e":"fig, axes = plt.subplots(nrows=5, ncols=3, figsize=(26, 24))\n\nplot = ['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n        'PhoneService', 'MultipleLines', 'InternetService', 'TechSupport',\n       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'Contract',\n       'StreamingTV', 'StreamingMovies', 'PaperlessBilling']\nindex = 0\nfor i in range(5):\n    for j in range(3):\n\n        ax = sns.countplot(x=plot[index], hue='Churn', data=data, palette=\"husl\", ax=axes[i,j]);\n        index+=1\n\n","959b3b0b":"df = data.copy()","bd15b576":"df = df.drop('customerID', axis=1)","c75aa5a2":"# Getting dummy variables for these columns\n# using drop_first=True in order to avoid the dummy variables trap\n\ndf = pd.get_dummies(data = df,columns = ['InternetService', 'Contract', 'PaymentMethod'], drop_first=True )","c56b084f":"enc = LabelEncoder()\ndf = df.apply(enc.fit_transform)\ndf.head()","fca5d79c":"X = df.drop('Churn', axis=1)\ny= df['Churn']","5614d809":"X = std_scaler.fit_transform(X)","4b9678c1":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25,random_state=42)","1c902753":"log_reg = LogisticRegression()\nlog_reg.fit(X_train, y_train)\ny_pred = log_reg.predict(X_test)\nacc_log_reg = log_reg.score(X_test, y_test)*100\nprint(\"{:.2f}\".format(acc_log_reg))","9ed79437":"print (classification_report(y_test, y_pred))","ee35e492":"lr_conf = confusion_matrix(y_test, y_pred)\nsns.heatmap(lr_conf, annot=True, fmt=\"d\")\nplt.show","8c707e40":"false_positive_rate, true_positive_rate, threshold = roc_curve(y_test, y_pred)\n\n# plotting them against each other\ndef plot_roc_curve(false_positive_rate, true_positive_rate, label=None):\n    plt.plot(false_positive_rate, true_positive_rate, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'r', linewidth=4)\n    plt.axis([0, 1, 0, 1])\n    plt.xlabel('False Positive Rate (FPR)', fontsize=16)\n    plt.ylabel('True Positive Rate (TPR)', fontsize=16)\n\nplt.figure(figsize=(14, 7))\nplot_roc_curve(false_positive_rate, true_positive_rate)\nplt.show()","ed3c9d06":"lr_auc = roc_auc_score(y_test, y_pred)\nprint(\"Roc score: \", round(lr_auc,2)*100, \"%\")","886e0327":"#Random Forest\nrf = RandomForest(random_state=42)\nrf.fit(X_train, y_train)\ny_pred_rf = rf.predict(X_test)\nacc_rf = rf.score(X_test, y_test) * 100\nprint(\"{:.2f}\".format(acc_rf))","0b4cd5b5":"RF_conf = confusion_matrix(y_test, y_pred_rf)\nsns.heatmap(RF_conf, annot=True, fmt=\"d\")\nplt.show","6311c92f":"# Ada Boost\nAdaBoost = AdaBoostClassifier(random_state=42)\nAdaBoost.fit(X_train, y_train)\ny_pred = AdaBoost.predict(X_test)\nacc_AdaBoost = AdaBoost.score(X_test, y_test) * 100\nprint(\"{:.2f}\".format(acc_AdaBoost))","da5ea587":"Ada_conf = confusion_matrix(y_test, y_pred)\nsns.heatmap(Ada_conf, annot=True, fmt=\"d\")\nplt.show","8ad064c9":"# LGBM Classifier\nlgbm = LGBMClassifier(random_state=42)\nlgbm.fit(X_train, y_train)\ny_pred = lgbm.predict(X_test)\nacc_lgbm = lgbm.score(X_test, y_test) * 100\nprint(\"{:.2f}\".format(acc_lgbm))","67313582":"LGBM_conf = confusion_matrix(y_test, y_pred)\nsns.heatmap(LGBM_conf, annot=True, fmt=\"d\")\nplt.show","fc687706":"# XGBoost\nxg = XGBClassifier(random_state=42)\nxg.fit(X_train, y_train)\ny_pred = xg.predict(X_test)\nacc_xg = xg.score(X_test, y_test) * 100\nprint(\"{:.2f}\".format(acc_xg))","a9a964f5":"XG_conf = confusion_matrix(y_test, y_pred)\nsns.heatmap(XG_conf, annot=True, fmt=\"d\")\nplt.show","43298783":"clf = AdaBoostClassifier(random_state=42)\n\nparam_grid = {\"n_estimators\": [50, 100, 300, 500],\\\n              \"learning_rate\" : [1, 0.0001, 0.5]}\n\ngrid_obj = GridSearchCV(clf, param_grid=param_grid, cv=10)\n\n\ngrid_fit = grid_obj.fit(X_train, y_train)\n\nprint(\"Best parameter: \", grid_obj.best_params_)\n\n# Get the estimator\/ clf\nbest_clf = grid_fit.best_estimator_\n\ngrid_y_pred = best_clf.predict(X_test)\n\nprint(\"Optimal accuracy score on the testing data: {:.2f}\".format(accuracy_score(y_test, grid_y_pred)*100))\n","bd51270b":"print (classification_report(y_test, grid_y_pred))","fabcfd8c":"Grid_conf = confusion_matrix(y_test, grid_y_pred)\nsns.heatmap(Grid_conf, annot=True, fmt=\"d\")\nplt.show","14584ad8":"false_positive_rate, true_positive_rate, threshold = roc_curve(y_test, grid_y_pred)\n\n# plotting them against each other\ndef plot_roc_curve(false_positive_rate, true_positive_rate, label=None):\n    plt.plot(false_positive_rate, true_positive_rate, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'r', linewidth=4)\n    plt.axis([0, 1, 0, 1])\n    plt.xlabel('False Positive Rate (FPR)', fontsize=16)\n    plt.ylabel('True Positive Rate (TPR)', fontsize=16)\n\nplt.figure(figsize=(14, 7))\nplot_roc_curve(false_positive_rate, true_positive_rate)\nplt.show()","ab8bf96c":"grid_auc = roc_auc_score(y_test, grid_y_pred)\nprint(\"Roc score: {:.2f}\".format((grid_auc)*100), \"%\")","353f04e9":"# 1. Exploratory Data Analysis (EDA)","f7417c41":"#### preparing dataa before visual data exoloration","7ad26255":"##### ROC Curve\/Score","1ecd1ee0":"##### cusotomers tend to churn after the first few years of their subscribtion so, the company may need to target new customers with marketing campaign and offers.","13faf077":"# 4. Splitting dataset and scaling it","fbe6d4dd":"##### It's obvious that customers who pay by Electronic check have a high tendency to check","18619d31":"# 2. Visual Data Analysis (VDA)","0d1f2b5b":"# 6. Validating Model","8120763e":"- The dataset contains 21 columns and 7043 rows.\n- There are no missing values to impute.\n- The dataset contains 18 columns of the datatype Object which indicated that it will need a lot of labeling and encoding during the preprocessing step.","a20cb8cb":"##### splitting dataset into training and testing","252607d2":"#### Choosing the best model","67ccd80c":"# Table of Contents\n1. Exploratory Data Analysis (EDA).\n2. Visual Data Analysis (VDA).\n3. Data Preprocessing.\n4. Splitting Data and Scaling it.\n5. Building Benchmark model.\n6. Building and Evaluating models.\n7. Model Validation.\n8. Optimization and Hyper-parameter tuning.","4c796e39":"#### Removing `customerID` as it doesn't contribute to the prediction of churn.","3049712a":"- __gender__: Females have a very small tendency to churn other than men, I guess there is no much impact for the gender on churn.\n- __SeniorCitizen__: Seniors are more likely to churn.\n- __Partner__: customers who have no partners are more likely to churn.\n- __Dependents__: having dependents makes customers less likely to churn.\n- __MultipleLines__: having multiple lines makes customers more likely to churn.\n- __Contract__: Month_to_Month contracts are more likely to churn.\n- __PaperlessBilling__: A lot of customers who have paperless billing have churned so, the company need to investigate it's system searching for the problem.","a06dd520":"#### Confusion matrix","729380de":"#### Getting Statistical insights","303b56b8":"# Telecom Churn Modelling","fa4ba2cc":"#### Dataset Information","95ab4cc6":"# 5. Building Benchmark model (Logistic regression)","453168d5":"Type I Error in our confusion matrix is when the customer is going to churn (1) but the model have predicted that he\/she is not going to churn(0) so Type I Error is the **left bottom** cell in our confusion matrix.","d1e7668d":"> please let me know if you have any suggestions to further improve my kernel and upvote it If you have found it useful. :)","5229c7d0":"`SeniorCitizen` feature is a binary categorical feature so looking at it's stats is nonesense.\n","a29426cb":"#### Encoding categorical variables","ef380869":"##### Logistic Regression Classification report","897d5edb":"##### Confusion matrix ","98484e08":"###### It seems like the dataset is partially imbalanced","f52767f1":"##### customers with low Total charges are more likely to churn.","11b09efa":"#### Fixing `TotalCharges` datatype","557a6a90":"The 2 common error types in Churn Prediction:\n\n   > **Type I Error\u200a\u2014\u200aFalse Negative: Failing to identify a customer who has a high propensity to unsubscribe.**\n\nFrom a business perspective, this is the __least desirable error__ as the customer is very likely to quit\/cancel\/abandon the business, thus adversely affecting its revenue.\n\n   > **Type II Error\u200a\u2014\u200aFalse Positive: Classifying a good, satisfied customer as one likely to Churn.**\n\nFrom a business perspective, this is __acceptable__ as it does not impact revenue.\n\nAny Predictive Algorithm going into Production will have to be **the one with the least Type I error.**\n\nSource: [Building Predictive Models for Customer Churn in Telecom](https:\/\/medium.com\/@Experfy\/building-predictive-models-for-customer-churn-in-telecom-4864d759ebf8)\n","bbe94026":"##### Scaling features","e5a110c8":"##### Customers who have Fiber Optic internet service are more likely to churn which is kind of weird because fiber optics mean that the quality and speed of internet is very high so I am assuming that customers who have Fiber optic internet service have hifh payments or monthly charges and customers who have high total charges are more likely to churn so, I will investigate this in the following graphs.","d1ad6464":"# 3. Data Preprocessing","a07c000f":"in the `MultipleLines` feature a customer who has no phone service still has no multiple lines so I will replace the 'No Phone Service' values with just 'No' similarly, in `OnlineSecurity`, `OnlineBackup`, `DeviceProtection`,\n`TechSupport`,`StreamingTV`, `StreamingMovies` 'No internet servive' will be replaced by 'No'","1aa764fd":"##### Customers have higher probability to churn when monthly charges are high which agrees with my hypothesis, now  the last part of my hypothesis is tht to show that Fiber Optic customers pay high monthly charges combared to other internet services which eventually leads to their churn.","6bbd2c68":"##### Getting dummy variables for categorical columns of mare than two values","8b7dd54a":"##### Now this confirms my hypithesis, as you see the Fiber optic internet service is the most expensixe one  and customers who have high monthly charges have higher tendency to leave the company, this is why customers who subscribe to the Fiber optic service are more likely to leave the company although they have high quality and internet speed service.\n\n###### This observation is very important for the company as they might target this customer segment and try to make offers to decrease the monthly charges on the fiber optics service or suggest them to use DSL for example if they can't afford the fiber optic service for so long. ","83266d01":"##### Ada Boost Classification report","dadaf141":"##### ROC Curve\/Score","94e5990b":"==========================================================================================================\n===========================================================================================================","eee75f96":" ##### Evaluating our benchmark model","47e01be1":"It seems like the default parameters achieve the highest performance.","bfb4e1e3":"#### A glance at the dataset","4acdec50":"![](https:\/\/drive.google.com\/file\/d\/1brxIhmq4Fo7fLbR1jmT6W4oyFTVo5Jeh\/view?usp=sharing) ","974159d4":"# 7. Optimization - Hyper Parameter tuning","9fc2e5b3":"### Ada Boost has the least Type I Error of 224 so it will be our final model.\nAda Boost has beaten our benchmark model which have Type I Error of 232.","7b91d436":"# 6. Bulding And Evaluating Models"}}