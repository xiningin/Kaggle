{"cell_type":{"f0d9fafd":"code","fd410dab":"code","f037be09":"code","741f6a31":"code","562ad0b6":"code","09920133":"code","aa99c568":"code","47e73560":"code","51fe9754":"code","4e986b2d":"code","82666fd2":"code","8adba05f":"code","893faea8":"code","87c2042c":"code","a111f160":"code","87e71655":"code","b9fa3855":"code","e8be365e":"code","5544ef39":"code","0b5a884b":"code","35902978":"code","f7431d6b":"code","0bbac7f1":"code","56db0340":"code","c154f732":"code","04edd8b3":"code","5cf05409":"code","86cc74c4":"code","109a15a9":"code","936f0a4a":"code","b75b009b":"code","8e645931":"code","b4329d1f":"markdown","6ac03520":"markdown","7e8a4d1d":"markdown","1f3c864e":"markdown","da9fe167":"markdown","a02ed90d":"markdown","31a8afc8":"markdown","4988021d":"markdown","c7a4def8":"markdown"},"source":{"f0d9fafd":"# pip install seaborn --upgrade","fd410dab":"# pip install transformers4rec[pytorch,tensorflow,nvtabular]","f037be09":"import os, gc\nimport json\n\nfrom ast import literal_eval\nfrom glob import glob\nfrom tqdm import tqdm\nfrom typing import Dict, Union, Optional, Any, Iterable\nfrom datetime import datetime\n\nimport random as rd\nimport math as m\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\n\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nimport matplotlib.dates as dates\nimport matplotlib.pyplot as plt","741f6a31":"from sklearn.model_selection import train_test_split as split_data\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, RobustScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, fbeta_score\nfrom sklearn.utils import resample","562ad0b6":"import sys\n\nsys.path.append('..\/input\/transformers-for-recsys')","09920133":"dataset_dir = '..\/input\/userbehavior-ecommerce-sequential-session-data'\n\ndf = pd.read_csv(dataset_dir+'\/dataset_1week.csv')\ndf.columns = ['user_session', 'user_id', 'item_ids', 'num_items', 'category_ids', \n              'session_initial_time', 'session_initial_timestamp', 'session_weekday_sin', 'session_weekday_cos', 'session_recency', 'session_actions', \n              'brand_ids', 'prices', 'relative_prices', 'day_index',]\ndf","aa99c568":"def clean_list(arrays: list or str):\n    if isinstance(arrays, str):\n        arrays = arrays.replace(\"nan, \", \"0, \")\n        arrays = arrays.replace(\", nan\", \", 0\")\n        arrays = literal_eval(arrays)\n    else:\n        arrays = [0 if not i else i for i in arrays]\n    return arrays\n\nlist_cols = ['category_ids', 'brand_ids', 'item_ids', 'prices', 'relative_prices',\n             'session_weekday_sin', 'session_weekday_cos', 'session_recency', 'session_actions']\nfor col in tqdm(list_cols):\n    df[col] = df[col].apply(clean_list)","47e73560":"df = df[df.num_items<=20]","51fe9754":"df.num_items.hist(bins=50)","4e986b2d":"df.drop(columns=['num_items', 'day_index', \n                 'session_initial_time', 'session_initial_timestamp'], inplace=True)\ndf.info()","82666fd2":"df.set_index(keys=['user_id', 'user_session'], inplace=True)\ndf","8adba05f":"import functools\nimport operator\n\n\ndef flatten_nested_list(arr: list):\n    return functools.reduce(operator.iconcat, arr, [])\n\n\nclass NpEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, np.integer):\n            return int(obj)\n        if isinstance(obj, np.floating):\n            return float(obj)\n        if isinstance(obj, np.ndarray):\n            return obj.tolist()\n        return super(NpEncoder, self).default(obj)","893faea8":"schema = {}\n\ncat_feats = [\"item_ids\", \"brand_ids\", \"category_ids\", \"session_actions\"]\nnum_feats = [\"prices\", \"relative_prices\", \n             \"session_weekday_sin\", \"session_weekday_cos\", \"session_recency\"]\n\nfor feat in cat_feats+num_feats:\n    print(f'Schema for {feat}')\n    if feat in cat_feats:\n        df[feat] = df[feat].apply(lambda x: np.array(x).astype(int))\n        schema[feat] = {'type': \"categorical\",}\n    else:\n        df[feat] = df[feat].apply(lambda x: np.array(x).astype(float))\n        schema[feat] = {'type': \"numerical\",}\n    values = flatten_nested_list(df[feat].values.tolist())\n    if feat == 'category_ids':\n        encoder = LabelEncoder()\n        encoder.fit(values)\n        values = encoder.transform(values)\n        df[feat] = df[feat].apply(lambda x: encoder.transform(x))\n    schema[feat].update({'min_val': min(values), \n                         'max_val': max(values),\n                   'embedding_dim': int(np.log(max(values))),})\n\nprint(json.dumps(schema, cls=NpEncoder, indent=4))","87c2042c":"import torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, Dataset\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","a111f160":"class TabularSequentialDataset(Dataset):\n\n    def __init__(self, df: pd.DataFrame, schema: dict, max_seq_len: int=20, batch_size: int=16):\n        self.schema = schema\n        self.dataset = self.seq_pad(df, max_seq_len)\n        self.indices = list(self.dataset.index)\n        self.batch_size = batch_size\n        self.num_batches = int(m.ceil(len(self.dataset) \/ batch_size))\n        self.max_seq_len = max_seq_len\n        \n    def seq_pad(self, df: pd.DataFrame, max_seq_len: int):\n        num_cols = len(df.columns)\n        for rid, rdata in tqdm(df.iterrows(), total=len(df)):\n            rdata = np.stack(rdata.values, axis=-1)\n            rdata_padded = np.zeros((max_seq_len, num_cols))\n            rdata_padded[-len(rdata):, :] = rdata\n            df.loc[rid] = rdata_padded.T.tolist()\n        return df\n\n    def __len__(self):\n        return self.num_batches\n    \n    def shuffle(self):\n        rd.shuffle(self.indices)\n\n    def __getitem__(self, batch_id: int):\n        indices = self.indices[batch_id*self.batch_size:(batch_id+1)*self.batch_size]\n        data = self.dataset.loc[indices]\n        tensors = dict()\n        for col in data.columns:\n            array = np.stack(data[col].values, axis=0)\n            tensors[col] = torch.tensor(array, \n                                        dtype=torch.int if self.schema[col]['type']=='categorical' else torch.half, \n                                        device=device)\n        return tensors","87e71655":"dataset = TabularSequentialDataset(df, schema, max_seq_len=20, batch_size=8)\nbatch_data = dataset[0]\nbatch_data","b9fa3855":"class FeaturePreprocessing(nn.Module):\n    \n    def __init__(self, schema: Dict[str, str], hidden_dim: int=64, training: bool=True):\n        super(FeaturePreprocessing, self).__init__()\n        self.training = training\n        self.embedding = dict()\n        self.hidden_dim = hidden_dim\n        self.features_dim = 0\n        self.features_order = list()\n        for feat, stats in schema.items():\n            if stats['type'] == 'categorical':\n                self.embedding[feat] = nn.Embedding(num_embeddings=stats['max_val']+1, \n                                                     embedding_dim=stats['embedding_dim'])\n                self.features_dim += stats['embedding_dim']\n            else:\n                self.features_dim += 1\n            self.features_order.append(feat)\n        self.normalize = nn.BatchNorm1d(num_features=self.features_dim)\n        self.regularize = nn.Dropout(p=0.1369)\n        self.full_connect = nn.Linear(in_features=self.features_dim, \n                                     out_features=self.hidden_dim, bias=True)\n        self.activation = nn.Mish()\n            \n    def forward(self, tensors: Dict[str, torch.Tensor]):\n        features = []\n        for feat in self.features_order:\n            if feat in self.embedding.keys():\n                feat_tensor = self.embedding[feat](tensors[feat])\n                feat_tensor = torch.swapaxes(feat_tensor, axis0=1, axis1=2)\n            else:\n                feat_tensor = torch.unsqueeze(tensors[feat], dim=1)\n            features.append(feat_tensor)\n        features = torch.cat(features, dim=1)\n        features = self.normalize(features) # shape: (B, Df, L)\n        features = torch.swapaxes(features, axis0=1, axis1=2)\n        features = self.regularize(features) # shape: (B, L, Df)\n        features = self.full_connect(features) # shape: (B, L, Dh)\n        features = self.activation(features) \n        return features","e8be365e":"feature_processor = FeaturePreprocessing(schema)\nfeature_processor.embedding","5544ef39":"features = feature_processor(batch_data)\nfeatures","0b5a884b":"from dataclasses import dataclass\n\n@dataclass\nclass MaskingInfo:\n    schema: torch.Tensor\n    targets: torch.Tensor\n        \n        \nclass MaskSequence(nn.Module):\n    \"\"\"\n    Base class to prepare masked items inputs\/labels for language modeling tasks.\n    \n    Transformer architectures can be trained in different ways. Depending of the training method,\n    there is a specific masking schema. The masking schema sets the items to be predicted (labels)\n    and mask (hide) their positions in the sequence so that they are not used by the Transformer\n    layers for prediction.\n    We currently provide 4 different masking schemes out of the box:\n        - Causal LM (clm)\n        - Masked LM (mlm)\n        - Permutation LM (plm)\n        - Replacement Token Detection (rtd)\n    This class can be extended to add different a masking scheme.\n    \n    Parameters\n    ----------\n    hidden_size:\n        The hidden dimension of input tensors, needed to initialize trainable vector of\n        masked positions.\n    pad_token: int, default = 0\n        Index of the padding token used for getting batch of sequences with the same length\n    \"\"\"\n\n    def __init__(self, hidden_size: int,\n                       padding_idx: int = 0,\n            eval_on_last_item_only: bool = True, **kwargs):\n        super(MaskSequence, self).__init__()\n        self.padding_idx = padding_idx\n        self.hidden_size = hidden_size\n        self.eval_on_last_item_only = eval_on_last_item_only\n        self.mask_schema: Optional[torch.Tensor] = None\n        self.masked_targets: Optional[torch.Tensor] = None\n\n        # Create a trainable embedding to replace masked interactions\n        self.masked_item_embedding = nn.Parameter(torch.Tensor(self.hidden_size))\n        torch.nn.init.normal_(self.masked_item_embedding, mean=0, std=.001)\n\n    def compute_masked_targets(self, item_ids: torch.Tensor, training=False) -> MaskingInfo:\n        \"\"\"\n        Method to prepare masked labels based on the sequence of item ids.\n        It returns the true labels of masked positions and the related boolean mask.\n        And the attributes of the class `mask_schema` and `masked_targets` are updated to be re-used in other modules.\n        \n        Parameters\n        ----------\n        item_ids: torch.Tensor\n            The sequence of input item ids used for deriving labels of next item prediction task.\n        training: bool\n            Flag to indicate whether we are in `Training` mode or not.\n            During training, the labels can be any items within the sequence based on the selected masking task.\n            During evaluation, we are predicting the last item in the sequence.\n        \n        Returns\n        -------\n        Tuple[MaskingSchema, MaskedTargets]\n        \"\"\"\n        assert item_ids.ndim == 2, \"`item_ids` must have 2 dimensions.\"\n        masking_info = self._compute_masked_targets(item_ids, training=training)\n        self.mask_schema, self.masked_targets = masking_info.schema, masking_info.targets\n        return masking_info\n\n    def apply_mask_to_inputs(self, inputs: torch.Tensor, schema: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Control the masked positions in the inputs by replacing the true interaction\n        by a learnable masked embedding.\n        \n        Parameters\n        ----------\n        inputs: torch.Tensor\n            The 3-D tensor of interaction embeddings resulting from the ops: TabularFeatures + aggregation + projection(optional)\n        schema: MaskingSchema\n            The boolean mask indicating masked positions.\n        \"\"\"\n        inputs = torch.where(schema.unsqueeze(-1).bool(),\n                             self.masked_item_embedding.to(inputs.dtype),\n                             inputs)\n        return inputs\n\n    def predict_all(self, item_ids: torch.Tensor) -> MaskingInfo:\n        \"\"\"\n        Prepare labels for all next item predictions instead of last-item predictions \n                in a user's sequence.\n            \n        Returns\n        -------\n        Tuple[MaskingSchema, MaskedTargets]\n        \"\"\"\n        # shift sequence of item-ids\n        labels = item_ids[:, 1:]\n        \n        # As after shifting the sequence length will be subtracted by one, adding a masked item in\n        # the sequence to return to the initial sequence.\n        labels = torch.cat([labels,\n                            torch.zeros((labels.shape[0], 1), dtype=labels.dtype).to(item_ids.device)], axis=-1)\n        \n        # apply mask on input where target is on padding index\n        mask_labels = labels != self.padding_idx\n        return MaskingInfo(mask_labels, labels)\n\n    def forward(self, inputs: torch.Tensor, item_ids: torch.Tensor, training: bool=False) -> torch.Tensor:\n        \"\"\"\n        Parameters\n        ----------\n        inputs: torch.Tensor 3D\n            Interaction embeddings from: TabularFeatures + aggregation + projection(optional)\n        item_ids: torch.Tensor\n            Sequence of input item ids used for deriving labels of next item prediction task.\n        \"\"\"\n        mask_info = self.compute_masked_targets(item_ids=item_ids, training=training)\n        if mask_info.schema is None:\n            raise ValueError(\"`mask_schema must be set.`\")\n        return self.apply_mask_to_inputs(inputs, mask_info.schema)\n\n    def forward_output_size(self, input_size):\n        return input_size\n\n    def transformer_required_arguments(self) -> Dict[str, Any]:\n        return {}\n\n    def transformer_optional_arguments(self) -> Dict[str, Any]:\n        return {}\n\n    @property\n    def transformer_arguments(self) -> Dict[str, Any]:\n        \"\"\"\n        Prepare additional arguments to pass to the Transformer forward methods.\n        \"\"\"\n        return {**self.transformer_required_arguments(), \n                **self.transformer_optional_arguments()}\n    \n    \nclass MaskedLanguageModeling(MaskSequence):\n    \"\"\"\n    In Masked Language Modeling (mlm) you randomly select some positions of the sequence to be predicted, which are masked.\n    During training, the Transformer layer is allowed to use positions on the right (future info).\n    During inference, all past items are visible for the Transformer layer, which tries to predict the next item.\n    \n    Parameters\n    ----------\n    {mask_sequence_parameters}\n    mlm_probability: Optional[float], default = 0.15\n        Probability of an item to be selected (masked) as a label of the given sequence.\n        p.s. We enforce that at least one item is masked for each sequence, so that the network can\n        learn something with it.\n    \"\"\"\n\n    def __init__(self, hidden_size: int,\n                       padding_idx: int = 0,\n                   mlm_probability: float = 0.15,\n            eval_on_last_item_only: bool = True, **kwargs):\n        super(MaskedLanguageModeling, self).__init__(hidden_size=hidden_size,\n                                                     padding_idx=padding_idx,\n                                          eval_on_last_item_only=eval_on_last_item_only,\n                                                          kwargs=kwargs)\n        self.mlm_probability = mlm_probability\n\n    def _compute_masked_targets(self, item_ids: torch.Tensor, training=False) -> MaskingInfo:\n        \"\"\"\n        Prepare sequence with mask schema for masked language modeling prediction\n        the function is based on HuggingFace's transformers\/data\/data_collator.py\n        \n        Parameters\n        ----------\n        item_ids: torch.Tensor\n            Sequence of input itemid (target) column\n        \n        Returns\n        -------\n        labels: torch.Tensor\n            Sequence of masked item ids.\n        mask_labels: torch.Tensor\n            Masking schema for masked targets positions.\n        \"\"\"\n\n        labels = torch.full(item_ids.shape, self.padding_idx, dtype=item_ids.dtype, device=item_ids.device)\n        non_padded_mask = item_ids != self.padding_idx\n\n        rows_ids = torch.arange(item_ids.size(0), dtype=torch.long, device=item_ids.device)\n        \n        # During training, masks labels to be predicted according to a probability, \n        #     ensuring that each session has at least 1 label to predict\n        if training:\n            # Selects a percentage of items to be masked (selected as labels)\n            probability_matrix = torch.full(item_ids.shape, self.mlm_probability, device=item_ids.device)\n            mask_labels = torch.bernoulli(probability_matrix).bool() & non_padded_mask\n            labels = torch.where(mask_labels, item_ids, torch.full_like(item_ids, self.padding_idx))\n\n            # Set at least 1 item in the sequence to mask\n            random_index_by_session = torch.multinomial(non_padded_mask.float(), num_samples=1).squeeze()\n            labels[rows_ids, random_index_by_session] = item_ids[rows_ids, random_index_by_session]\n            mask_labels = labels != self.padding_idx\n\n            # If a sequence has only masked labels, unmasks 1 of the labels\n            sequences_with_only_labels = mask_labels.sum(dim=1) == non_padded_mask.sum(dim=1)\n            sampled_labels_to_unmask = torch.multinomial(mask_labels.float(), num_samples=1).squeeze()\n\n            labels_to_unmask = torch.masked_select(sampled_labels_to_unmask, sequences_with_only_labels)\n            rows_to_unmask = torch.masked_select(rows_ids, sequences_with_only_labels)\n\n            labels[rows_to_unmask, labels_to_unmask] = self.padding_idx\n            mask_labels = labels != self.padding_idx\n\n        else:\n            if self.eval_on_last_item_only:\n                last_item_sessions = non_padded_mask.sum(dim=1) - 1\n                labels[rows_ids, last_item_sessions] = item_ids[rows_ids, last_item_sessions]\n                mask_labels = labels != self.padding_idx\n            else:\n                masking_info = self.predict_all(item_ids)\n                mask_labels, labels = masking_info.schema, masking_info.targets\n\n        return MaskingInfo(mask_labels, labels)","35902978":"sequence_mask = MaskedLanguageModeling(hidden_size=feature_processor.hidden_dim,\n                                       padding_idx=0,\n                                   mlm_probability=0.69)\nfeatures_masked = sequence_mask(inputs=feature_processor(batch_data), \n                              item_ids=batch_data['item_ids'])\nfeatures_masked.shape","f7431d6b":"def generate_square_subsequent_mask(dim):\n    mask = (torch.triu(torch.ones(dim, dim))==1).transpose(0, 1)\n    mask = mask.float().masked_fill(mask==0, float('-inf'))\\\n                       .masked_fill(mask==1, float(0.))\n    return mask\n\ngenerate_square_subsequent_mask(10)","0bbac7f1":"pip install transformers","56db0340":"import inspect\nimport transformers\n\n\nclass XLNetConfig(transformers.XLNetConfig):\n    @classmethod\n    def build(cls, d_model,\n                   n_head,\n                   n_layer,\n            total_seq_length=None,\n                   attn_type=\"bi\",\n                  hidden_act=\"gelu\",\n           initializer_range=0.01,\n              layer_norm_eps=0.03,\n                     dropout=0.3,\n                   pad_token=0,\n       log_attention_weights=False,\n                     mem_len=1, **kwargs):\n        return cls(d_model=d_model,\n                   d_inner=d_model * 4,\n                   n_layer=n_layer,\n                    n_head=n_head,\n                 attn_type=attn_type,\n             ff_activation=hidden_act,\n         initializer_range=initializer_range,\n            layer_norm_eps=layer_norm_eps,\n                   dropout=dropout,\n              pad_token_id=pad_token,\n         output_attentions=log_attention_weights,\n                vocab_size=1,\n                   mem_len=mem_len,\n                   **kwargs)\n    \n    \nclass GPT2Prepare(nn.Module):\n    \n    def __init__(self, transformer, masking):\n        super().__init__()\n        self.transformer = transformer\n        self.masking = masking\n\n    def forward(self, inputs_embeds) -> Dict[str, Any]:\n        seq_len = inputs_embeds.shape[1]\n        \n        # head_mask has shape n_layer x batch x n_heads x N x N\n        head_mask = torch.tril(\n            torch.ones((seq_len, seq_len), dtype=torch.uint8, device=inputs_embeds.device)\n        ).view(1, 1, 1, seq_len, seq_len).repeat(self.transformer.config.num_hidden_layers, 1, 1, 1, 1)\n        return {\"inputs_embeds\": inputs_embeds, \n                    \"head_mask\": head_mask}\n\n    \nclass TransformerBlock(nn.Module):\n\n    def __init__(self, transformer,\n                       masking=None,\n                prepare_module=None, \n                     output_fn=lambda model_outputs: model_outputs[0],):\n        super().__init__()\n\n        model_cls = transformers.MODEL_MAPPING[transformer.__class__]\n        self.transformer = model_cls(transformer)\n\n        if masking is not None:\n            required = list(masking.transformer_required_arguments().keys())\n            check = all(param in inspect.signature(self.transformer.forward).parameters for param in required)\n            if not check:\n                raise ValueError(f\"{masking.__class__.__name__} requires the parameters: \"\n                                 f\"{', '.join(required)} in the {type(self.transformer)} signature\")\n\n        self.masking = masking\n        self.output_fn = output_fn\n\n    def forward(self, inputs_embeds, **kwargs):\n        transformer_kwargs = {\"inputs_embeds\": inputs_embeds}\n        if self.masking:\n            masking_kwargs = self.masking.transformer_arguments\n            if masking_kwargs:\n                transformer_kwargs.update(masking_kwargs)\n\n        filtered_transformer_kwargs = {}\n        for param in inspect.signature(self.transformer.forward).parameters:\n            if param in transformer_kwargs:\n                filtered_transformer_kwargs[param] = transformer_kwargs[param]\n        outputs = self.transformer(**filtered_transformer_kwargs)\n        outputs = self.output_fn(outputs)\n        return outputs\n\n    def _get_name(self):\n        return \"TransformerBlock\"\n\n    def forward_output_size(self, input_size):\n        assert len(input_size) == 3\n        return torch.Size([input_size[0], input_size[1], self.transformer.config.hidden_size])","c154f732":"backbone_config = XLNetConfig.build(d_model=feature_processor.hidden_dim, n_head=8, n_layer=3)\nbackbone_config","04edd8b3":"backbone = TransformerBlock(backbone_config, masking=sequence_mask)\nbackbone","5cf05409":"features_attentioned = backbone(features_masked)\nfeatures_attentioned.shape","86cc74c4":"import torchmetrics as tm\nfrom abc import abstractmethod\n\n\ndef check_inputs(ks, scores, labels):\n    if len(ks.shape) > 1:\n        raise ValueError(\"ks should be a 1-D tensor\")\n\n    if len(scores.shape) != 2:\n        raise ValueError(\"scores must be a 2-D tensor\")\n\n    if len(labels.shape) != 2:\n        raise ValueError(\"labels must be a 2-D tensor\")\n\n    if scores.shape != labels.shape:\n        raise ValueError(\"scores and labels must be the same shape\")\n\n    return (ks.to(dtype=torch.int32, device=scores.device), scores, labels,)\n\ndef extract_topk(ks, scores, labels):\n    max_k = int(max(ks))\n    topk_scores, topk_indices = torch.topk(scores, max_k)\n    topk_labels = torch.gather(labels, 1, topk_indices)\n    return topk_scores, topk_indices, topk_labels\n\ndef create_output_placeholder(scores, ks):\n    return torch.zeros(scores.shape[0], len(ks)).to(device=scores.device, dtype=torch.float32)\n\ndef tranform_label_to_onehot(labels, vocab_size):\n    return one_hot_1d(labels.reshape(-1), vocab_size, dtype=torch.float32).detach()\n\n\nclass RankingMetric(tm.Metric):\n    \"\"\"\n    Metric wrapper for computing ranking metrics@K for session-based task.\n    \n    Parameters\n    ----------\n    top_ks : list, default [2, 5])\n        list of cutoffs\n    labels_onehot : bool\n        Enable transform the labels to one-hot representation\n    \"\"\"\n\n    def __init__(self, top_ks=None, labels_onehot=False):\n        super(RankingMetric, self).__init__()\n        self.top_ks = top_ks or [2, 5]\n        self.labels_onehot = labels_onehot\n        # Store the mean of the batch metrics (for each cut-off at topk)\n        self.add_state(\"metric_mean\", default=[], dist_reduce_fx=\"cat\")\n\n    def update(self, preds: torch.Tensor, target: torch.Tensor, **kwargs):  # type: ignore\n        # Computing the metrics at different cut-offs\n        if self.labels_onehot:\n            target = torch_utils.tranform_label_to_onehot(target, preds.size(-1))\n        metric = self._metric(torch.LongTensor(self.top_ks), preds.view(-1, preds.size(-1)), target)\n        self.metric_mean.append(metric)  # type: ignore\n\n    def compute(self):\n        # Computing the mean of the batch metrics (for each cut-off at topk)\n        return torch.cat(self.metric_mean, axis=0).mean(0)\n\n    @abstractmethod\n    def _metric(self, ks: torch.Tensor, preds: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Compute a ranking metric over a predictions and one-hot targets.\n        This method should be overridden by subclasses.\n        \n        Parameters\n        ----------\n        ks : torch.Tensor or list\n            list of cutoffs\n        scores : torch.Tensor\n            predicted item scores\n        labels : torch.Tensor\n            true item labels\n        \n        Returns\n        -------\n        torch.Tensor:\n            list of precisions at cutoffs\n        \"\"\"\n\n\nclass PrecisionAt(RankingMetric):\n    def __init__(self, top_ks=None, labels_onehot=False):\n        super(PrecisionAt, self).__init__(top_ks=top_ks, labels_onehot=labels_onehot)\n\n    def _metric(self, ks: torch.Tensor, scores: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n        \"\"\" Compute precision@K for each of the provided cutoffs \"\"\"\n        ks, scores, labels = check_inputs(ks, scores, labels)\n        _, _, topk_labels = extract_topk(ks, scores, labels)\n        precisions = create_output_placeholder(scores, ks)\n\n        for index, k in enumerate(ks):\n            precisions[:, index] = torch.sum(topk_labels[:, : int(k)], dim=1) \/ float(k)\n        return precisions\n\n\nclass RecallAt(RankingMetric):\n    def __init__(self, top_ks=None, labels_onehot=False):\n        super(RecallAt, self).__init__(top_ks=top_ks, labels_onehot=labels_onehot)\n\n    def _metric(self, ks: torch.Tensor, scores: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n        \"\"\" Compute recall@K for each of the provided cutoffs \"\"\"\n        ks, scores, labels = check_inputs(ks, scores, labels)\n        _, _, topk_labels = extract_topk(ks, scores, labels)\n        recalls = create_output_placeholder(scores, ks)\n\n        # Compute recalls at K\n        num_relevant = torch.sum(labels, dim=-1)\n        rel_indices = (num_relevant != 0).nonzero()\n        rel_count = num_relevant[rel_indices].squeeze()\n\n        if rel_indices.shape[0] > 0:\n            for index, k in enumerate(ks):\n                rel_labels = topk_labels[rel_indices, : int(k)].squeeze()\n                recalls[rel_indices, index] = torch.div(torch.sum(rel_labels, dim=-1), rel_count) \\\n                                                   .reshape(len(rel_indices), 1) \\\n                                                   .to(dtype=torch.float32)  # Ensuring type is double, because it can be float if --fp16\n        return recalls\n\n\nclass AvgPrecisionAt(RankingMetric):\n    def __init__(self, top_ks=None, labels_onehot=False):\n        super(AvgPrecisionAt, self).__init__(top_ks=top_ks, labels_onehot=labels_onehot)\n        self.precision_at = PrecisionAt(top_ks)._metric\n\n    def _metric(self, ks: torch.Tensor, scores: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n        \"\"\" Compute average precision at K for provided cutoffs \"\"\"\n        ks, scores, labels = check_inputs(ks, scores, labels)\n        topk_scores, _, topk_labels = extract_topk(ks, scores, labels)\n        avg_precisions = create_output_placeholder(scores, ks)\n\n        # Compute average precisions at K\n        num_relevant = torch.sum(labels, dim=1)\n        max_k = ks.max().item()\n\n        precisions = self.precision_at(1+torch.arange(max_k), topk_scores, topk_labels)\n        rel_precisions = precisions * topk_labels\n\n        for index, k in enumerate(ks):\n            total_prec = rel_precisions[:, : int(k)].sum(dim=1)\n            avg_precisions[:, index] = total_prec \/ num_relevant.clamp(min=1, max=k).to(dtype=torch.float32,\n                                                                                        device=scores.device)  \n            # Ensuring type is double, because it can be float if --fp16\n        return avg_precisions\n\n\nclass DCGAt(RankingMetric):\n    def __init__(self, top_ks=None, labels_onehot=False):\n        super(DCGAt, self).__init__(top_ks=top_ks, labels_onehot=labels_onehot)\n\n    def _metric(self, ks: torch.Tensor, scores: torch.Tensor, labels: torch.Tensor, log_base: int=2) -> torch.Tensor:\n        \"\"\" Compute discounted cumulative gain at K for provided cutoffs (ignoring ties) \"\"\"\n        ks, scores, labels = check_inputs(ks, scores, labels)\n        topk_scores, topk_indices, topk_labels = extract_topk(ks, scores, labels)\n        dcgs = create_output_placeholder(scores, ks)\n\n        # Compute discounts\n        discount_positions = torch.arange(ks.max().item()).to(device=scores.device,\n                                                              dtype=torch.float32)\n        discount_log_base = torch.log(torch.Tensor([log_base]).to(device=scores.device,\n                                                                  dtype=torch.float32)).item()\n        discounts = 1 \/ (torch.log(discount_positions + 2) \/ discount_log_base)\n\n        # Compute DCGs at K\n        for index, k in enumerate(ks):\n            dcgs[:, index] = torch.sum(\n                (topk_labels[:, :k] * discounts[:k].repeat(topk_labels.shape[0], 1)), dim=1\n            ).to(dtype=torch.float32, device=scores.device)  # Ensuring type is double, because it can be float if --fp16\n        return dcgs\n\n\nclass NDCGAt(RankingMetric):\n    def __init__(self, top_ks=None, labels_onehot=False):\n        super(NDCGAt, self).__init__(top_ks=top_ks, labels_onehot=labels_onehot)\n        self.dcg_at = DCGAt(top_ks)._metric\n\n    def _metric(self, ks: torch.Tensor, scores: torch.Tensor, labels: torch.Tensor, log_base: int = 2) -> torch.Tensor:\n        \"\"\" Compute normalized discounted cumulative gain at K for provided cutoffs (ignoring ties) \"\"\"\n        ks, scores, labels = check_inputs(ks, scores, labels)\n        topk_scores, topk_indices, topk_labels = extract_topk(ks, scores, labels)\n        # ndcgs = _create_output_placeholder(scores, ks) #TODO track if this line is needed\n\n        # Compute discounted cumulative gains\n        gains            = self.dcg_at(ks, topk_scores, topk_labels)\n        gains_normalized = self.dcg_at(ks, topk_labels, topk_labels)\n\n        # Prevent divisions by zero\n        relevant_pos   = (gains_normalized != 0).nonzero(as_tuple=True)\n        irrelevant_pos = (gains_normalized == 0).nonzero(as_tuple=True)\n\n        gains[irrelevant_pos] = 0\n        gains[  relevant_pos] \/= gains_normalized[relevant_pos]\n        return gains","109a15a9":"class NextItemPredictionBlock(nn.Module):\n    \"\"\"\n    Predict the interacted item-id probabilities.\n    - During inference, the task consists of predicting the next item.\n    - During training, the class supports the following Language modeling tasks:\n        Causal LM, Masked LM, Permutation LM and Replacement Token Detection\n        \n    Parameters:\n    -----------\n    input_size: int\n        Input size of this module.\n    target_dim: int\n        Dimension of the target.\n    weight_tying: bool\n        The embedding table weights are shared with the prediction network layer.\n    embedding_table: torch.nn.Module\n        Module that's used to store the embedding table for the item.\n    softmax_temperature: float\n        Softmax temperature, used to reduce model overconfidence, so that softmax(logits \/ T).\n        Value 1.0 is equivalent to regular softmax.\n    \"\"\"\n\n    def __init__(self, input_size: int,\n                       target_dim: int,\n                     weight_tying: bool = False,\n                  embedding_table: Optional[nn.Module] = None,\n              softmax_temperature: float = 0.):\n        super().__init__()\n        self.input_size = input_size\n        self.target_dim = target_dim\n        self.weight_tying = weight_tying\n        self.embedding_table = embedding_table\n        self.softmax_temperature = softmax_temperature\n        self.activation = nn.LogSoftmax(dim=-1)\n\n        if self.weight_tying:\n            self.output_layer_bias = nn.Parameter(torch.Tensor(self.target_dim))\n            torch.nn.init.zeros_(self.output_layer_bias)\n        else:\n            self.output_layer = nn.Linear(self.input_size[-1], self.target_dim)\n\n    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n        if self.weight_tying:\n            logits = F.linear(inputs,\n                              weight=self.embedding_table.weight, \n                              bias=self.output_layer_bias,)\n        else:\n            logits = self.output_layer(inputs)\n\n        if self.softmax_temperature > 0:\n            # Softmax temperature to reduce model overconfidence\n            logits = torch.div(logits, self.softmax_temperature)\n\n        predictions = self.activation(logits)\n        return predictions\n\n    def _get_name(self) -> str:\n        return \"NextItemPredictionTask\"\n    \n    \nclass NextItemPredictionTask(nn.Module):\n    \"\"\"\n    Next-item prediction task.\n    \n    Parameters\n    ----------\n    loss: torch.nn.Module\n        Loss function to use. Defaults to NLLLos.\n    metrics: Iterable[torchmetrics.Metric]\n        List of ranking metrics to use for evaluation.\n    task_block:\n        Module to transform input tensor before computing predictions.\n    task_name: str, optional\n        Name of the prediction task, if not provided a name will be automatically constructed based\n        on the target-name & class-name.\n    weight_tying: bool\n        The embedding table weights are shared with the prediction layer.\n    softmax_temperature: float\n        Softmax temperature, to reduce model overconfidence --> softmax(logits \/ Temp)\n        Value 1.0 is equivalent to regular softmax.\n    padding_idx: int\n        pad token id.\n    target_dim: int\n        vocabulary size of item ids\n    \"\"\"\n\n    DEFAULT_METRICS = (\n        # default metrics suppose labels are int encoded\n                NDCGAt(top_ks=[10, 20], labels_onehot=True),\n              RecallAt(top_ks=[10, 20], labels_onehot=True),\n        AvgPrecisionAt(top_ks=[10, 20], labels_onehot=True),\n    )\n\n    def __init__(self, loss: nn.Module = nn.NLLLoss(ignore_index=0),\n                    metrics: Iterable[tm.Metric] = DEFAULT_METRICS,\n                 task_block: Optional[nn.Module] = None,\n                  task_name: str = \"next-item\",\n               weight_tying: bool = False,\n        softmax_temperature: float = 1.,\n                padding_idx: int = 0,\n                 target_dim: int = None,):\n        super(NextItemPredictionTask, self).__init__()\n        self.loss = loss\n        self.metrics = metrics\n        self.task_name = task_name\n        self.task_block = task_block\n        self.softmax_temperature = softmax_temperature\n        self.embedding_table = None\n        self.weight_tying = weight_tying\n        self.padding_idx = padding_idx\n        self.target_dim = target_dim\n        self.masking = None\n\n    def build(self, input_size, masking=None, device=None, \n                    embedding_block=None, task_block=None, predict_block=None):\n        if not len(input_size) == 3 or isinstance(input_size, dict):\n            raise ValueError(\"NextItemPredictionTask needs a 3-D tensor as input, found:\" f\"{input_size}\")\n        self.device = device\n\n        # Retrieve the embedding module to get the name of item id col and its related table\n        self.task_block = task_block\n        self.embedding_block = embedding_block\n        if not self.target_dim:\n            self.target_dim = self.embedding_block.num_embeddings\n        if self.weight_tying:\n            self.item_embedding = self.embedding_block\n            item_dim = self.item_embedding.weight.shape[1]\n            if input_size[-1] != item_dim and not task_block:\n                self.task_block = nn.Linear(in_features=input_size[-1], \n                                           out_features=item_dim)\n\n        # Retrieve the masking if used in the model block\n        self.masking = masking\n        if self.masking:\n            self.padding_idx = self.masking.padding_idx\n\n        self.predict_block = NextItemPredictionBlock(input_size=input_size[-1], \n                                                     target_dim=self.target_dim,\n                                                   weight_tying=self.weight_tying,\n                                                embedding_table=self.item_embedding,\n                                            softmax_temperature=self.softmax_temperature)\n\n    def forward(self, inputs: torch.Tensor, **kwargs):\n        if isinstance(inputs, (tuple, list)):\n            inputs = inputs[0]\n        x = inputs.float()\n        print(1, x.shape)\n\n        if self.task_block:\n            x = self.task_block(x)\n        print(2, x.shape)\n\n        # Retrieve labels from masking\n        labels = self.masking.masked_targets\n        print(0, labels.shape)\n\n        # remove padded items\n        target_flat = labels.flatten()\n        non_pad_mask = target_flat != self.padding_idx\n        labels_all = torch.masked_select(target_flat, non_pad_mask)\n        print(0, labels_all.shape)\n        x = self.remove_pad_3d(x, non_pad_mask)\n        print(3, x.shape)\n\n        # Compute predictions probs\n        x = self.predict_block(x) \n        print(4, x.shape)\n\n        return x\n\n    def remove_pad_3d(self, inp_tensor, non_pad_mask):\n        # inp_tensor: (n_batch x seq_len x emb_dim)\n        inp_tensor = inp_tensor.flatten(end_dim=1)\n        inp_tensor_fl = torch.masked_select(inp_tensor, non_pad_mask.unsqueeze(1).expand_as(inp_tensor))\n        out_tensor = inp_tensor_fl.view(-1, inp_tensor.size(1))\n        return out_tensor\n\n    def calculate_metrics(self, predictions, targets, mode=\"val\", forward=True, **kwargs) -> Dict[str, torch.Tensor]:\n        if isinstance(targets, dict) and self.target_name:\n            targets = targets[self.target_name]\n\n        outputs = {}\n        if forward:\n            predictions = self(predictions)\n        predictions = self.forward_to_prediction_fn(predictions)\n\n        for metric in self.metrics:\n            outputs[self.metric_name(metric)] = metric(predictions, targets)\n\n        return outputs\n\n    def compute_metrics(self):\n        metrics = {self.metric_name(metric): metric.compute()\n                   for metric in self.metrics\n                   if getattr(metric, \"top_ks\", None)}\n        \n        # Explode metrics for each cut-off\n        topks = {self.metric_name(metric): metric.top_ks for metric in self.metrics}\n        results = {}\n        for name, metric in metrics.items():\n            for measure, k in zip(metric, topks[name]):\n                results[f\"{name}_{k}\"] = measure\n        return ","936f0a4a":"prediction_head = NextItemPredictionTask(weight_tying=True, \n                                              metrics=[NDCGAt(top_ks=[10, 20], labels_onehot=True),  \n                                                     RecallAt(top_ks=[10, 20], labels_onehot=True),])\nprediction_head.build(input_size=list(features_attentioned.shape),\n                         masking=sequence_mask, \n                 embedding_block=feature_processor.embedding['item_ids'])\nprediction_head","b75b009b":"predictions = prediction_head(features_attentioned)\npredictions","8e645931":"predictions.shape","b4329d1f":"# Schema","6ac03520":"## Feature Preprocessing","7e8a4d1d":"## Head","1f3c864e":"## Sequence Processing\n#### with **Transformer** variants","da9fe167":"## Dataset","a02ed90d":"## Sequence Masking","31a8afc8":"# Model","4988021d":"# Evaluation","c7a4def8":"# Load Data"}}