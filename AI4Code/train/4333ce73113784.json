{"cell_type":{"6fa62d4f":"code","3ca35b97":"code","642475ae":"code","9497ab36":"code","9d142f9e":"code","d3a1b701":"code","5aafd89f":"code","b2032307":"code","30272fc0":"code","aa061050":"code","ef8fb340":"code","bfc18105":"code","0bd31d25":"markdown"},"source":{"6fa62d4f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3ca35b97":"df = pd.read_csv(\"\/kaggle\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv\")\n\nprint(df.shape)\n# drop rows with null values for bmi\ndf = df.dropna()\ndf.drop(columns=['id'], inplace=True)\n\nprint(df.shape)","642475ae":"df.columns","9497ab36":"df.nunique()","9d142f9e":"df.head()","d3a1b701":"# one hot encoding \nfrom sklearn.preprocessing import OneHotEncoder\n\ndef one_hot_encode(feature, dataf):\n    feature_array = dataf[feature].to_numpy().reshape(-1,1)\n    enc_feature = OneHotEncoder(handle_unknown = 'ignore').fit(feature_array)\n    enc_feature.fit(feature_array)\n    encoded_array = enc_feature.transform(feature_array).toarray()\n    col_names = [feature + \"_\" + v for v in enc_feature.categories_[0].tolist()]\n    df_feature = pd.DataFrame(encoded_array, columns = col_names)  \n    columns = dataf.columns.tolist() + (df_feature.columns.tolist()) \n    new_df = pd.concat([dataf.reset_index(drop=True), df_feature.reset_index(drop=True)], axis=1)\n    new_df.columns = columns\n    return new_df, enc_feature\n\n#########################################################################################################\n\none_hot_features = ['gender', 'ever_married','work_type', 'Residence_type']\n\nencoders = []\n\nfor feature in one_hot_features:\n    df_copy = df.copy()\n    df_copy_new, enc = one_hot_encode(feature, df_copy)\n    encoders.append(enc)\n    df_copy_new.drop(columns=[feature], inplace=True)\n    df = df_copy_new\n    \n# label encoding smoking status\nfrom sklearn.preprocessing import LabelEncoder\nsmoking_label_encoder = LabelEncoder()\ndf['smoking_status'] = smoking_label_encoder.fit_transform(df['smoking_status'])","5aafd89f":"# X and y for training\nX = df.drop(columns=['stroke'])\ny = df['stroke']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","b2032307":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nclf = LogisticRegression().fit(X_train, y_train)\ny_pred = clf.predict(X_test)\naccuracy_score(y_test, y_pred)","30272fc0":"# example\nage = 87.0\nhypertension = 0\nheart_disease = 1\navg_glucose_level = 668.69 \nbmi = 36.6\nsmoking_status = 'formerly smoked'\ngender = 'Male'\never_married = 'Yes'\nwork_type = 'Private'\nResidence_type = 'Urban'\n\nsmoking = smoking_label_encoder.transform([smoking_status])\nsmoking_status = smoking[0]\n\ninput_list = [age,hypertension,heart_disease, avg_glucose_level, bmi, smoking_status]\n\ninput_cat_features = [gender, ever_married, work_type, Residence_type]\none_hot_encoded_feature_values = []\n\n# one_hot_features = ['gender', 'ever_married','work_type', 'Residence_type']\n\nans = []\n\nfor i in range(0,len(one_hot_features)):\n    enc = encoders[i]\n    val = enc.transform(np.array(input_cat_features[i]).reshape(-1,1)).toarray()[0].tolist()\n    ans.append(val)\n    print(val)\n\nresult = sum(ans, [])\n\ninput_list = input_list + result\n\nprint(input_list)","aa061050":"y_pred = clf.predict(np.array(input_list).reshape(1,-1))\nprint(y_pred[0])\n\nprint(clf.predict_proba(np.array(input_list).reshape(1,-1)))","ef8fb340":"y_pred = clf.predict(np.array(input_list).reshape(1,-1))\nprint(\"Prediction for stroke = \", y_pred[0])\n\nprint(\"Percent of prediction = \", clf.predict_proba(np.array(input_list).reshape(1,-1))[:,y_pred[0]][0])","bfc18105":"# Save model and encoders\nfrom joblib import dump, load\n\nfor i in range(len(one_hot_features)):\n    dump(encoders[i], one_hot_features[i] + '.joblib')\n    \ndump(smoking_label_encoder,'smoking_label_encoder.joblib')\n\ndump(clf,'classifier.joblib')","0bd31d25":"### Stroke Prediction using Logistic Regression\n\nTry the app at [stroke-prediction heroku](https:\/\/stroke-prediction.herokuapp.com\/)"}}