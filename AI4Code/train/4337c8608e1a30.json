{"cell_type":{"edcb05c6":"code","4808a6c0":"code","9559d5d4":"code","88163163":"code","38bd4aac":"code","4ec2a09f":"code","a93fe38a":"code","e4f7d977":"code","0bb81ff7":"code","9680b897":"code","2eac2b6d":"code","eeeb4583":"code","25446626":"code","81512943":"code","f5a0e710":"code","152196c8":"code","a327c3fd":"code","807abd00":"markdown","d6240561":"markdown","bc8866d5":"markdown","2f61a81e":"markdown","04458dbb":"markdown","f2ce2b6a":"markdown","ba68be43":"markdown"},"source":{"edcb05c6":"import pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport os\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")","4808a6c0":"data_path = '..\/input\/g-research-crypto-forecasting'\nassets = pd.read_csv(os.path.join(data_path, 'asset_details.csv'))\ntrain_df = pd.read_csv(os.path.join(data_path, 'train.csv'))\ntrain_df['asset_name'] = train_df.Asset_ID.map(assets.set_index('Asset_ID').Asset_Name)\nprint(f'There are {len(train_df)} rows in the dataset')\ntrain_df.head()","9559d5d4":"import time\ntotimestamp = lambda s: np.int32(time.mktime(datetime.strptime(s, \"%d\/%m\/%Y\").timetuple()))","88163163":"bit = train_df[train_df.Asset_ID == 1].set_index('timestamp')\nbit = bit.loc[totimestamp('01\/01\/2021'):totimestamp('01\/04\/2021')]\nbit.head()","38bd4aac":"#Installing and importing the package\n!pip install stockstats\nfrom stockstats import StockDataFrame","4ec2a09f":"#Preparing the columns \nbit.drop(['Asset_ID','asset_name', 'VWAP', 'Target'], axis=1, inplace=True)\nbit.rename(columns = {'Count':'amount','Open':'open','High':'high','Low':'low',\n                     'Close':'close','Volume':'volume'}, inplace=True)\nbit.head()","a93fe38a":"stock = StockDataFrame.retype(bit)","e4f7d977":"KDJ_WINDOW = 10\nBOLL_WINDOW = 10\nMACD_EMA_SHORT = 10\nPDI_SMMA = 10\nMDI_SMMA = 10\nDX_SMMA = 10\nADX_EMA = 5\nADXR_EMA = 10\nTRIX_EMA_WINDOW = 10\nTEMA_EMA_WINDOW = 10\n","0bb81ff7":"#Creating the features\nbit['volume_delta'] = stock['volume_delta']\nbit['open_-2_r'] = stock['open_-2_r']\nbit['cr']= stock['cr']\nbit['kdjk'] = stock['kdjk']\nbit['open_2_sma'] = stock['open_2_sma']\nbit['macd'] = stock['macd']\nbit['boll'] = stock['boll']\nbit['boll_ub'] = stock['boll_ub']\nbit['boll_lb'] = stock['boll_lb']\nbit['rsi_12'] = stock['rsi_12']\nbit['wr_10'] = stock['wr_10']\nbit['cci'] = stock['cci']\nbit['tr'] = stock['tr']\nbit['atr'] = stock['atr']\nbit['dma'] = stock['dma']\nbit['pdi'] = stock['pdi']\nbit['dx'] = stock['dx']\nbit['adx'] = stock['adx']\nbit['adxr'] = stock['adxr']\nbit['trix'] = stock['trix']\nbit['tema'] = stock['tema']\nbit['vr'] = stock['vr']","9680b897":"bit.head()","2eac2b6d":"#Creating new target\nbit['target'] = bit.open.shift(-1) - bit.close\nbit['target'] = bit.target.apply(lambda x:1 if x>0 else 0)\nbit.head()","eeeb4583":"bit.target.value_counts()","25446626":"X = bit.drop(['target'],axis=1).values\ny = bit.target.values","81512943":"train_size = int(len(X)*0.70)\ntrain, test = X[0:train_size], X[train_size:len(X)]\ny_train, y_test = y[0:train_size], y[train_size:len(X)]\nprint('Observations: %d' % (len(X)))\nprint('Training Observations: %d' % (len(train)))\nprint('Testing Observations: %d' % (len(test)))","f5a0e710":"from xgboost import XGBClassifier\nmodel = XGBClassifier( learning_rate=0.05, n_estimators=500, \n                      subsample=1.0,alpha=0, tree_method = 'gpu_hist')\nmodel.fit(train, y_train)","152196c8":"y_pred = model.predict(test)","a327c3fd":"from sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'model accuracy is :{accuracy}')\n\nfrom sklearn.metrics import precision_score\nprecision = precision_score(y_test, y_pred, average='binary')\nprint(f'model precision is :{precision}')\n\nfrom sklearn.metrics import recall_score\nrecall = recall_score(y_test, y_pred, average='binary')\nprint(f'model recall is :{recall}')","807abd00":"I wanted to see how these features would perform in a model, so I built a small model to see if there's any improvement while using these features. Instead of building a model to predict the target as we're doing in this competition, I created a new target for a classification problem as was done in the paper stated above. A '1' corresponds to a price increase and '0' to a decrease. So, essentially this model will predict if the price of bitcoin will increase or decrease in the next minute. ","d6240561":"Now, to extract these features we'll be using the stockstats package. You can find the documentation [here](https:\/\/pypi.org\/project\/stockstats\/). It is essentially a wrapper to a pandas DataFrame that is preloaded with formulas for about 30 indicators. \n\nAll you have to do is use the *retype* function to cast your pandas DataFrame into a *StockDataFrame*.\n\nThis package assumes that your data is sorted by time and contains certain columns. You also have to make sure your column names match what it expects. Here are the columns it requires:\n\n* open: corresponding to Open in our dataset\n* close: corresponding to Close in our dataset\n* high: corresponding to High in our dataset\n* low: corresponding to Low in our dataset\n* volume: corresponding to Volume in our dataset\n* amount: corresponding to Count in our dataset\n","bc8866d5":"This is a short notebook to show a simple way to extract trade indicators from the given data for those, who like myself, aren't very knowledgable about this domain. This method is based on the methodology as described in [this paper by Ortu et al](https:\/\/arxiv.org\/pdf\/2102.08189.pdf)\n\nThe authors categorize the features to their model as:\n* Technical indicators: Such as those already provided to us in this competition\n* Trade indicators: Additional features calculated from the technical indicators such as Relative Strength Index(RSI), price momentum index etc. \n* Social indicators: These include features obtained through sentiment analysis of social media posts\n\nDue to the constraints of this competition, we cannot add social indicators, but we can compute the trade indicators from data already provided. This notebook will show you how. ","2f61a81e":"Before you calculate the features you can tune the default values as I have done below. For complete list of options that are available for tuning and extraction refer the docs.","04458dbb":"To demonstrate this method I'm going to choose only a small subset of the data. Here I'm extracting only data from bitcoin for a three month period. ","f2ce2b6a":"Import all the usual packages and read the data as you usually do.","ba68be43":"This is a 3% increase in model accuracy while using these newly extracted features(Run this notebook while commenting out the extracted features to obtain the score without). \n\nNote: This is not a definitive evaluation, I have not stress tested this with bigger data, optimised the algorithm or even evaluated which of, or even all, these features affect the model score. The goal of this notebook was purely to show the feature extraction.\n\nI hope you have enjoyed this notebook and that this helps you in building better models for yourselves. "}}