{"cell_type":{"fa2fb4c9":"code","6201146c":"code","b41ec932":"code","ea42df9b":"code","11d6da41":"code","ef4b7737":"code","f9b0ffd3":"code","66563bad":"code","91cb89e4":"code","62dd102d":"code","567cf3cb":"code","fd444726":"code","932c625e":"code","b5fb0cb3":"code","c9e04604":"code","7b301d20":"code","edbc2c17":"code","5f3d23c8":"code","4eed5c28":"code","fc4170e6":"code","f39c54fe":"code","3769378f":"code","7822a2cc":"code","8df13fe1":"code","fe4c8bde":"code","be132786":"code","1075a46a":"code","1ae2ee7b":"code","a9b2d521":"code","41bce851":"code","2d38f56b":"code","2f1533a5":"code","88e442c9":"code","7c855ae3":"code","d2888ae9":"code","425dffba":"code","49b34d7e":"code","ee30ddc2":"code","f03fc2de":"code","588295fa":"code","d608c963":"code","f2377cf7":"code","83efa5b9":"code","a134a201":"code","cc149ede":"code","e63e9375":"code","f7d4af5b":"code","2fed7250":"code","89204969":"code","39a298d2":"code","25c78259":"code","6675b9ef":"code","dd7dace9":"code","b6041d36":"code","a58b2f61":"code","4e4646e7":"code","09ae8c71":"code","963a3ec4":"code","931a61ee":"code","de18610a":"code","f18a4606":"code","c0f97aec":"code","ee767a01":"code","f896d6d5":"code","f0b56147":"code","2644ada5":"code","0ad7586b":"markdown","512e3fb4":"markdown","bf378b89":"markdown","1e4f6e05":"markdown","e1a48435":"markdown","50a78140":"markdown","0ff164d0":"markdown","587af120":"markdown","ea829cb3":"markdown","c54db90f":"markdown","badaca36":"markdown","45e109ad":"markdown","74c05c37":"markdown","beea60ca":"markdown","c9f619f2":"markdown","ddb9d4ae":"markdown","1a239c12":"markdown","40daa766":"markdown","f57c3d9f":"markdown","d8d0aa78":"markdown","b2b5590e":"markdown","6f1d6509":"markdown","f487e096":"markdown","69a7379a":"markdown","e7efeddd":"markdown","f17c180a":"markdown","6831db17":"markdown","bc9a7a90":"markdown","aef8e2fa":"markdown","9184483a":"markdown","df7abb20":"markdown","a915de07":"markdown","0ff651f0":"markdown"},"source":{"fa2fb4c9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport folium\nfrom folium.plugins import MarkerCluster # for clustering the markers\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport fbprophet\nfrom scipy.stats import mode\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6201146c":"df1 = pd.read_csv('..\/input\/atlanta-crime-data2020\/COBRA-2020-OldRMS-09292020 (Corrected 11_25_20)\/COBRA-2020-OldRMS-09292020.csv')\ndf2 = pd.read_csv('..\/input\/atlanta-crime-data2020\/COBRA-2020 (Updated 12_10_2020)\/COBRA-2020.csv')\ndf3 = pd.read_csv('..\/input\/atlanta-crime-data2020\/COBRA-2009-2019 (Updated 1_9_2020)\/COBRA-2009-2019.csv')","b41ec932":"df1 = df1.drop(columns = ['apartment_office_prefix','apartment_number','watch','location_type','UCR_Number'])\ndf2 = df2.drop(columns = ['ibr_code'])\ndf3 = df3.drop(columns = ['Apartment Office Prefix','Apartment Number','Shift Occurence','Location Type','UCR #','IBR Code'])","ea42df9b":"df3.columns = df1.columns","11d6da41":"df3 = df3[df3['occur_time'].apply(lambda x: str(x).isdecimal())]","ef4b7737":"# def isNotDecimal(x):\n#     if str(x).isdecimal():\n#         return False\n#     else:\n#         return True\n# df3[df3['occur_hour'].apply(isNotDecimal)]","f9b0ffd3":"df3['occur_time'].value_counts()","66563bad":"df1['rpt_month'] = df1['rpt_date'].str.split('\/').str[0]\ndf1['rpt_day'] = df1['rpt_date'].str.split('\/').str[1]\ndf1['rpt_year'] = df1['rpt_date'].str.split('\/').str[2]\ndf1['occur_month'] = df1['occur_date'].str.split('\/').str[0]\ndf1['occur_day'] = df1['occur_date'].str.split('\/').str[1]\ndf1['occur_year'] = df1['occur_date'].str.split('\/').str[2]\ndf1['occur_hour'] = df1['occur_time'].str.split(':').str[0]\n\ndf2['rpt_month'] = df2['rpt_date'].str.split('\/').str[0]\ndf2['rpt_day'] = df2['rpt_date'].str.split('\/').str[1]\ndf2['rpt_year'] = df2['rpt_date'].str.split('\/').str[2]\ndf2['occur_month'] = df2['occur_date'].str.split('\/').str[0]\ndf2['occur_day'] = df2['occur_date'].str.split('\/').str[1]\ndf2['occur_year'] = df2['occur_date'].str.split('\/').str[2]\ndf2['occur_hour'] = df2['occur_time'].str.split(':').str[0]\n\ndf3['rpt_month'] = df3['rpt_date'].str.split('-').str[1]\ndf3['rpt_day'] = df3['rpt_date'].str.split('-').str[2]\ndf3['rpt_year'] = df3['rpt_date'].str.split('-').str[0]\ndf3['occur_month'] = df3['occur_date'].str.split('-').str[1]\ndf3['occur_day'] = df3['occur_date'].str.split('-').str[2]\ndf3['occur_year'] = df3['occur_date'].str.split('-').str[0]\ndf3['occur_hour'] = df3['occur_time'].astype(str).str[:-2]","91cb89e4":"df3 = df3[df3['occur_hour'].apply(lambda x: str(x).isnumeric())]","62dd102d":"keys = df1.columns\ndf1 = df1.dropna(subset = keys).reset_index(drop = True)\ndf2 = df2.dropna(subset = keys).reset_index(drop = True)\ndf3 = df3.dropna(subset = keys).reset_index(drop = True)","567cf3cb":"df = pd.concat([df1,df2, df3]).reset_index(drop = True)\ndf","fd444726":"df = df.astype({'beat' : 'int32', 'occur_year' : 'int32', 'occur_month' : 'int32', 'occur_day' : 'int32', 'occur_hour' : 'int32', 'rpt_year' : 'int32', 'rpt_month' : 'int32', 'rpt_day' : 'int32'})\ndf['occur_date'] = pd.to_datetime(df['occur_date'])\ndf['rpt_date'] = pd.to_datetime(df['rpt_date'])","932c625e":"df.info()","b5fb0cb3":"df.to_csv('df.csv', index=False)","c9e04604":"df","7b301d20":"df.loc[df['rpt_year'] - df['occur_year'] > 4][['offense_id', 'occur_year','rpt_year']]","edbc2c17":"df.isnull().sum()","5f3d23c8":"mode(df['rpt_month'])","4eed5c28":"df.groupby(['rpt_month']).size()","fc4170e6":"df.loc[df['rpt_year'] == 2020, : ]","f39c54fe":"pd.crosstab(df['rpt_year'], df['UC2_Literal'])","3769378f":"df.groupby(['rpt_year', 'UC2_Literal']).size().unstack(level = 1).plot(figsize=(12,10))","7822a2cc":"df.info()","8df13fe1":"df.dtypes","fe4c8bde":"print(df)","be132786":"df['occur_year'].value_counts().sort_index()","1075a46a":"df = df[(df['occur_year'] >= 2009) & (df['occur_year'] <= 2020)]","1ae2ee7b":"df['occur_year'].value_counts().sort_index()","a9b2d521":"df['occur_month'].value_counts().sort_index()","41bce851":"df['occur_day'].value_counts().sort_index()","2d38f56b":"df['occur_hour'].value_counts().sort_index()","2f1533a5":"def updateOccurHour(hour):\n    if hour == 24:\n        return 0\n    else:\n        return hour\ndf['occur_hour'] = df['occur_hour'].apply(updateOccurHour)","88e442c9":"df['occur_hour'].value_counts().sort_index()","7c855ae3":"df.info()","d2888ae9":"df['rpt_month'].value_counts().sort_index()","425dffba":"df['rpt_day'].value_counts().sort_index()","49b34d7e":"df['rpt_year'].value_counts().sort_index()","ee30ddc2":"df['lat'].describe()","f03fc2de":"df['long'].describe()","588295fa":"df['offense_id'].isna().sum()","d608c963":"df['beat'].describe()","f2377cf7":"df['UC2_Literal'].value_counts()","83efa5b9":"df['neighborhood'].value_counts() ","a134a201":"df['npu'].value_counts().sort_index()","cc149ede":"df.groupby(['occur_year', 'UC2_Literal']).size().unstack(level=1).plot.bar(stacked=True)","e63e9375":"df.groupby(['occur_year', 'UC2_Literal']).size().unstack(level=0).plot.barh(stacked=True)","f7d4af5b":"df.groupby(['occur_year', 'UC2_Literal']).size().unstack(level=0).plot.hist(stacked=True, bins=20)","2fed7250":"df.groupby(['occur_year', 'UC2_Literal']).size().unstack(level=0).plot.box(vert=False, sym='r+')","89204969":"df.groupby(['occur_year', 'UC2_Literal']).size().unstack(level=1).plot.area()","39a298d2":"df.plot.hexbin(x='occur_year', y='occur_month', gridsize=25)","25c78259":"df[df['occur_year'] == 2020].groupby(['occur_year', 'UC2_Literal']).size().plot.pie()","6675b9ef":"df.groupby(['occur_year']).size().plot(figsize=(12,6))","dd7dace9":"df.groupby(['occur_year', 'UC2_Literal']).size().unstack(level=1).plot(figsize=(12,6))","b6041d36":"df.groupby(['occur_month']).size().plot(figsize=(12,6))","a58b2f61":"df.groupby(['occur_month', 'UC2_Literal']).size().unstack(level=1).plot(figsize=(12,6))","4e4646e7":"df.groupby(['occur_hour']).size().plot(figsize=(12,6))","09ae8c71":"df.groupby(['occur_hour', 'UC2_Literal']).size().unstack(level=1).plot(figsize=(12,6))","963a3ec4":"ax = df.groupby(['UC2_Literal']).size().plot.bar(figsize=(12,6), title = '# of Incident Over Incident Category')\nax.set_xlabel(\"# of Incident\")\nax.set_ylabel(\"Incident Category\")","931a61ee":"df.groupby(['occur_month']).size()","de18610a":"df","f18a4606":"map = folium.Map(location=[df['lat'].mean(), df['long'].mean()], default_zoom_start=12)\n# add a marker for every record in the filtered data, use a clustered view\nmarker_cluster = MarkerCluster().add_to(map) # create marker clusters\nfor i in range(500): # we can choose any number of incidents to plot on the map, eg: df.shape[0]\n    location = [df['lat'][i],df['long'][i]]\n    tooltip = \"Neighborhood: {}<br> Click for more\".format(df[\"neighborhood\"][i])\n    folium.Marker(location, \n                  popup=\"\"\"<i>Crime Address: <\/i> <br> <b>{}<\/b> <br>\"\"\".format(df['location'][i]), \n                  tooltip=tooltip).add_to(marker_cluster)\nmap.save('map.html')\nmap","c0f97aec":"data = df.groupby(['occur_year']).size().reset_index()\nX = data.iloc[:, :-1].values\ny = data.iloc[:, 1].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nreg = LinearRegression()\nreg.fit(X_train, y_train)","ee767a01":"print(reg.intercept_)\nprint(reg.coef_)","f896d6d5":"y_pred = reg.predict(X_test)\nr = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\nr","f0b56147":"print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","2644ada5":"data.plot(x='occur_year', y=0, style='o')\nplt.plot(X_train, reg.predict(X_train), color = \"r\")\nplt.title('# of Incidents Over Years')\nplt.xlabel('Years')\nplt.ylabel('# of Incidents')\nplt.show()","0ad7586b":"# 4. Machine Learning","512e3fb4":"**2.9 Deal with datatype.**","bf378b89":"**Q: What is 'npu' ?**","1e4f6e05":"# 3. EDA","e1a48435":"Number of incidents over hours.","50a78140":"**2.1 Read each dataset.**","0ff164d0":"**2.7 Drop null data.******","587af120":"**Deal with occur_hour: 24**","ea829cb3":"Conditional filter:::::","c54db90f":"# 2. Dataset Preparation.","badaca36":"# 1. Packages Loading.","45e109ad":"**Visualize the results.**","74c05c37":"**2.5 Check 'occur_time' field.**","beea60ca":"'Mode' is broadly used for fillna() functionality, as mode stands for the most common values for a specific field.","c9f619f2":"**2.6 Add necessary columns for visualization purpose.**","ddb9d4ae":"Crosstab is important for EDA, useful for initial 'feel'.","1a239c12":"**Geocoded location data for visualization.**","40daa766":"The above figure shows the number of incidents has been all the way going down.","f57c3d9f":"**2.10 Save the dataset to a csv file.**","d8d0aa78":"**Practice:::::::::**","b2b5590e":"A pick hour of crime would be around 8 and 12, so we can assume that is breakfast\/lunch time. When they are out for food, then something happens.","6f1d6509":"It looks like the number of incidents has been generally decreasing over years since 2009, which is a good sign of having a safer communities. However, one thing to notice is: 'LARCENY-FROM VEHICLE' incident has a slight increase trend. We need to pay attention to that.","f487e096":"**2.8 Concatenate the 3 datasets.**","69a7379a":"**Use plot functions coming with Pandas.**","e7efeddd":"**Note: Until here, the 'occur_hour' turns to 'int64'.**","f17c180a":"**Evaluate the Algorithm**","6831db17":"Febburary seems to be the safest month, it may bacause the crime-related ppl have a better financial status temporarily, by assuming they involve crimes due to financial cause. To make it cleaer, we can tell probably the stipend from government at the end of year can decrease the number of incidents.","bc9a7a90":"**Deploy number of incidents over years**","aef8e2fa":"**2.3 Rename df3 column name to maintain consistency with df1 and df2.******","9184483a":"**2.2 Drop unmatching and unnecessary columns for consistency.**","df7abb20":"**Q: What is 'beat' ?**","a915de07":"**2.4 Drop the special row data.** with 'T' in 'Occur_time' field.","0ff651f0":"The number of crime over months."}}