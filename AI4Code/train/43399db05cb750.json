{"cell_type":{"c2bf3398":"code","060a4622":"code","22608aff":"code","75c3bef7":"code","6ff99e39":"code","abc4573d":"code","4ffaa84d":"code","a99164d9":"code","898ba38c":"code","d7fecff3":"markdown","7c12955a":"markdown","2fbbda29":"markdown","fdfbd1db":"markdown","6773e897":"markdown","1f9bd2b6":"markdown"},"source":{"c2bf3398":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","060a4622":"import sys\nsys.path.append(\"..\/input\/siim-acr-pneumothorax-segmentation\")\nfrom mask_functions import mask2rle, rle2mask","22608aff":"from glob import glob\ndcm_files = {f.split(\"\/\")[-1]:f for f in list(glob('..\/input\/siimacr-pneumothorax-segmentation-downloaded-file\/siim\/train\/*\/*\/*.dcm'))\\\n             +list(glob('..\/input\/siimacr-pneumothorax-segmentation-downloaded-file\/siim\/test\/*\/*\/*.dcm'))}","75c3bef7":"import tensorflow as tf\n\nclass UNet:\n    def __init__(self, size=(128, 128), l2_reg=None):\n        self.model = self.create_model(size, l2_reg)\n\n    @staticmethod\n    def create_model(size, l2_reg, n_unit=64):\n        inputs = tf.placeholder(tf.float32, [None, size[0], size[1], 1], name=\"inputs\")\n        teacher = tf.placeholder(tf.float32, [None, size[0], size[1], 1], name=\"teacher\")\n        is_training = tf.placeholder(tf.bool, name=\"is_training\")\n\n        conv1_1 = UNet.conv(inputs, filters=n_unit, l2_reg_scale=l2_reg, istraining=is_training)\n        conv1_2 = UNet.conv(conv1_1, filters=n_unit, l2_reg_scale=l2_reg, istraining=is_training)\n        pool1 = UNet.pool(conv1_2)\n\n        conv2_1 = UNet.conv(pool1, filters=n_unit\/\/2, l2_reg_scale=l2_reg, istraining=is_training)\n        conv2_2 = UNet.conv(conv2_1, filters=n_unit\/\/2, l2_reg_scale=l2_reg, istraining=is_training)\n        pool2 = UNet.pool(conv2_2)\n\n        conv3_1 = UNet.conv(pool2, filters=n_unit\/\/4, l2_reg_scale=l2_reg, istraining=is_training)\n        conv3_2 = UNet.conv(conv3_1, filters=n_unit\/\/4, l2_reg_scale=l2_reg, istraining=is_training)\n        pool3 = UNet.pool(conv3_2)\n\n        conv4_1 = UNet.conv(pool3, filters=n_unit\/\/8, l2_reg_scale=l2_reg, istraining=is_training)\n        conv4_2 = UNet.conv(conv4_1, filters=n_unit\/\/8, l2_reg_scale=l2_reg, istraining=is_training)\n        pool4 = UNet.pool(conv4_2)\n\n        conv5_1 = UNet.conv(pool4, filters=n_unit\/\/16, l2_reg_scale=l2_reg)\n        conv5_2 = UNet.conv(conv5_1, filters=n_unit\/\/16, l2_reg_scale=l2_reg)\n        concated1 = tf.concat([UNet.conv_transpose(conv5_2, filters=n_unit\/\/16, l2_reg_scale=l2_reg), conv4_2], axis=3)\n\n        conv_up1_1 = UNet.conv(concated1, filters=n_unit\/\/8, l2_reg_scale=l2_reg)\n        conv_up1_2 = UNet.conv(conv_up1_1, filters=n_unit\/\/8, l2_reg_scale=l2_reg)\n        concated2 = tf.concat([UNet.conv_transpose(conv_up1_2, filters=n_unit\/\/8, l2_reg_scale=l2_reg), conv3_2], axis=3)\n\n        conv_up2_1 = UNet.conv(concated2, filters=n_unit\/\/4, l2_reg_scale=l2_reg)\n        conv_up2_2 = UNet.conv(conv_up2_1, filters=n_unit\/\/4, l2_reg_scale=l2_reg)\n        concated3 = tf.concat([UNet.conv_transpose(conv_up2_2, filters=n_unit\/\/4, l2_reg_scale=l2_reg), conv2_2], axis=3)\n\n        conv_up3_1 = UNet.conv(concated3, filters=n_unit\/\/2, l2_reg_scale=l2_reg)\n        conv_up3_2 = UNet.conv(conv_up3_1, filters=n_unit\/\/2, l2_reg_scale=l2_reg)\n        concated4 = tf.concat([UNet.conv_transpose(conv_up3_2, filters=n_unit\/\/2, l2_reg_scale=l2_reg), conv1_2], axis=3)\n\n        conv_up4_1 = UNet.conv(concated4, filters=n_unit, l2_reg_scale=l2_reg)\n        conv_up4_2 = UNet.conv(conv_up4_1, filters=n_unit, l2_reg_scale=l2_reg)\n        outputs = UNet.conv(conv_up4_2, filters=1, kernel_size=[1, 1], activation=None)\n\n        return Model(inputs, outputs, teacher, is_training)\n\n    @staticmethod\n    def conv(inputs, filters, kernel_size=[3, 3], activation=tf.nn.relu, l2_reg_scale=None, istraining=None):\n        if l2_reg_scale is None:\n            regularizer = None\n        else:\n            regularizer = tf.contrib.layers.l2_regularizer(scale=l2_reg_scale)\n        conved = tf.layers.conv2d(\n            inputs=inputs,\n            filters=filters,\n            kernel_size=kernel_size,\n            padding=\"same\",\n            activation=activation,\n            kernel_regularizer=regularizer\n        )\n        if istraining is not None:\n             conved = UNet.dropout(conved, istraining)\n\n        return conved\n\n    @staticmethod\n    def dropout(inputs, is_training):\n        droped = tf.layers.dropout(\n            inputs=inputs,\n            rate=0.1\n        )\n        return droped\n\n    @staticmethod\n    def pool(inputs):\n        pooled = tf.layers.max_pooling2d(inputs=inputs, pool_size=[2, 2], strides=2)\n        return pooled\n\n    @staticmethod\n    def conv_transpose(inputs, filters, l2_reg_scale=None):\n        if l2_reg_scale is None:\n            regularizer = None\n        else:\n            regularizer = tf.contrib.layers.l2_regularizer(scale=l2_reg_scale)\n        conved = tf.layers.conv2d_transpose(\n            inputs=inputs,\n            filters=filters,\n            strides=[2, 2],\n            kernel_size=[2, 2],\n            padding='same',\n            activation=tf.nn.relu,\n            kernel_regularizer=regularizer\n        )\n        return conved\n\nclass Model:\n    def __init__(self, inputs, outputs, teacher, is_training):\n        self.inputs = inputs\n        self.outputs = outputs\n        self.teacher = teacher\n        self.is_training = is_training\n","6ff99e39":"import cv2\nimport pydicom\ndef load_batch(indexs, df_load, train=True, imgsize=128):\n    target_image = np.zeros((len(indexs),imgsize,imgsize,1),dtype=np.float32)\n    target_mask = np.zeros((len(indexs),imgsize,imgsize,1),dtype=np.int32)\n    original_size = []\n    for ie,i in enumerate(indexs):\n        file = dcm_files[df_load.iloc[i][\"ImageId\"]+\".dcm\"]\n        img = pydicom.read_file(file).pixel_array\n        stdim = np.std(img)\n        menim = np.mean(img)\n        img = np.clip(128 + 100 * (img - menim) \/ stdim, 0, 255)\n        org_size = img.shape\n        original_size.append(org_size)\n        img = cv2.resize(img,(imgsize,imgsize),interpolation=cv2.INTER_NEAREST)\n        target_image[ie,:,:,0] = img.astype(np.float32)\n        if train:\n            rle = df_load.iloc[i][\" EncodedPixels\"]\n            if \"-1\" == str(rle).strip():\n                mask = np.zeros((imgsize,imgsize))\n            else:\n                mask = rle2mask(rle,org_size[0],org_size[1])\n                mask = cv2.resize(mask,(imgsize,imgsize),interpolation=cv2.INTER_NEAREST)\n            # rotate mask image --- I seem this is correct for rle2mask. in siim sample, maybe are x and y swapped?\n            mask = cv2.flip(cv2.warpAffine(mask, cv2.getRotationMatrix2D((imgsize\/\/2,imgsize\/\/2), 270, 1.0), (imgsize,imgsize), flags=cv2.INTER_LINEAR),1)\n            target_mask[ie,:,:,0] = (mask != 0).astype(np.int32)\n    return target_image, target_mask, original_size","abc4573d":"from matplotlib import pyplot as plt\ndef show_train(imgsize = 128):\n    df_train = pd.read_csv(\"..\/input\/siimacr-pneumothorax-segmentation-downloaded-file\/train-rle.csv\")[:10]\n    X, y, _ = load_batch(list(range(10)), df_train)\n    for j in range(10):\n            _x = X.astype(np.int32).reshape((-1,imgsize,imgsize))\n            im = np.zeros((imgsize,imgsize*2))\n            im[:,0:imgsize] = _x[j]\n            im[:,imgsize:imgsize*2] = np.clip(_x[j]*0.5 + y[j].reshape((-1,imgsize,imgsize)) * 255, 0, 255)\n            plt.imshow(im, cmap='bone')\n            plt.axis('off')\n            plt.show()\nshow_train(128)","4ffaa84d":"from tqdm import tqdm_notebook as tqdm\nmodel_unet = UNet(l2_reg=0.0001).model\nloss_func = tf.reduce_mean(tf.losses.sigmoid_cross_entropy(multi_class_labels=model_unet.teacher, logits=model_unet.outputs))\ntrain_step = tf.train.AdamOptimizer(0.001).minimize(loss_func)\n\ndef train(sess):\n    df_train = pd.read_csv(\"..\/input\/siimacr-pneumothorax-segmentation-downloaded-file\/train-rle.csv\")[:640]\n    tf.global_variables_initializer().run()\n\n    epochs = 20\n    batch_size = 2\n\n    for epoch in tqdm(range(epochs)):\n        indexs = np.random.permutation(len(df_train))\n        for i in range(len(df_train) \/\/ batch_size + 1):\n            sp = i * batch_size\n            ep = min(len(df_train), sp + batch_size)\n\n            X, y, _ = load_batch(indexs[sp:ep], df_train)\n\n            # Training\n            sess.run(train_step, feed_dict={model_unet.inputs: X, model_unet.teacher: y, model_unet.is_training: True})","a99164d9":"from matplotlib import pyplot as plt\ndef sigmoid(x):\n    return 1 \/ (1 + np.exp(-x))\ndef pred(sess, spos=0.5):\n    df_test = pd.read_csv(\"..\/input\/siim-acr-pneumothorax-segmentation\/sample_submission.csv\")\n    batch_size = 64\n    imgsize = 128\n\n    print(\"predict:\")\n    pred_masks = [\"-1\"] * len(df_test)\n    for i in range(len(df_test) \/\/ batch_size + 1):\n        sp = i * batch_size\n        ep = min(len(df_test), sp + batch_size)\n\n        X, _, org_size = load_batch(list(range(sp,ep,1)), df_test, False)\n\n        y = sess.run(model_unet.outputs, feed_dict={model_unet.inputs: X, model_unet.is_training: False})\n        y = sigmoid(y)\n        y = ((y > spos).astype(np.int32) * 255).reshape((-1,imgsize,imgsize)).astype(np.uint8)\n        if i == 0:\n            for j in range(min(20,batch_size)):\n                _x = X.reshape((-1,imgsize,imgsize)).astype(np.int32)\n                im = np.zeros((imgsize,imgsize*2))\n                im[:,0:imgsize] = _x[j]\n                im[:,imgsize:imgsize*2] = np.clip(_x[j]*0.5 + y[j].reshape((-1,imgsize,imgsize)), 0, 255)\n                plt.imshow(im, cmap='bone')\n                plt.axis('off')\n                plt.show()\n        for j in range(len(y)):\n            a = y[j].reshape((imgsize, imgsize, 1))\n            s = org_size[j]\n            mask = cv2.warpAffine(cv2.flip(a,1), cv2.getRotationMatrix2D((imgsize\/\/2,imgsize\/\/2), 90, 1.0), (imgsize,imgsize), flags=cv2.INTER_LINEAR)\n            mask = cv2.resize(mask, s, interpolation=cv2.INTER_NEAREST)\n            mask = mask2rle((mask!=0).astype(np.int32)*255, s[0], s[1])\n            if len(mask) == 0:\n                mask = \"-1\"\n            pred_masks[sp + j] = mask\n    df_test[\"EncodedPixels\"] = pred_masks\n    df_test.to_csv(\"submission.csv\",index=False)","898ba38c":"with tf.Session() as sess:\n    train(sess)\n    pred(sess, spos=0.2)","d7fecff3":"### show training data\n\nmask image is 270 rotated. Put the mask image on the 50% train image.","7c12955a":"## make model","2fbbda29":"## Training model","fdfbd1db":"## Make predictions","6773e897":"# **Unet**\n\n> The u-net is convolutional network architecture for fast and precise segmentation of images.\n\nhttps:\/\/lmb.informatik.uni-freiburg.de\/people\/ronneber\/u-net\/\n\n![](https:\/\/lmb.informatik.uni-freiburg.de\/people\/ronneber\/u-net\/u-net-architecture.png)\n\nWith Improvement based on the report by Kenji Kondo et al.\n\nhttps:\/\/confit.atlas.jp\/guide\/event-img\/jsai2018\/2J4-04\/public\/pdf?type=in\n","1f9bd2b6":"## data loader\n\nLoad file for each batch due to memory limitation\n(If you run it locally, you can speed it up by loading it in advance)"}}