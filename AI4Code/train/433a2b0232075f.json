{"cell_type":{"b3c8b59e":"code","b53add0c":"code","d776519f":"code","c9131c28":"code","3bdfa727":"code","ab3c8863":"code","a2b04040":"code","3d167967":"code","97899b8d":"code","63eab6f4":"code","c9ca0c5e":"code","fafc51e6":"code","abcfcce3":"code","25531516":"code","ac890f64":"code","d3a730d2":"code","949cddbd":"code","00801a99":"code","ec14bc50":"code","5dcb2648":"code","24c62ab1":"code","d3d0778f":"code","5ea5db07":"code","86fb054f":"code","1be3cf8a":"markdown","e33d1e9b":"markdown","efae4b34":"markdown","df4e3489":"markdown","227577e4":"markdown","76f23b1c":"markdown","4552314e":"markdown"},"source":{"b3c8b59e":"import numpy as np\nimport pandas as pd\nimport itertools\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.manifold import MDS, TSNE\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras import  backend as K\nfrom keras.optimizers import Adam ,RMSprop\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","b53add0c":"train =  pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\nprint(train.shape)\ntrain.head()","d776519f":"test = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\nprint(test.shape)\ntest.head()","c9131c28":"Y_train = train[\"label\"]\nX_train = train.drop(labels = [\"label\"],axis = 1) \nX_train = X_train \/ 255.0\ntest = test \/ 255.0","3bdfa727":"X_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","ab3c8863":"Y_train = keras.utils.to_categorical(Y_train, 10)","a2b04040":"X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1)","3d167967":"def visualize_input(img, ax):\n    ax.imshow(img, cmap='gray')\n    width, height = img.shape\n    thresh = img.max()\/2.5\n    for x in range(width):\n        for y in range(height):\n            ax.annotate(str(round(img[x][y],2)), xy=(y,x),\n                        horizontalalignment='center',\n                        verticalalignment='center',\n                        color='white' if img[x][y]<thresh else 'black')\n\nfig = plt.figure(figsize = (10,10)) \nax = fig.add_subplot(111)\nvisualize_input(X_train[27].reshape(28,28), ax)","97899b8d":"batch_size = 86\nnum_classes = 10\nepochs = 10\ninput_shape = (28, 28, 1)","63eab6f4":"'''#there are more 1 image samples\nsns.barplot(x = y_train.unique(), y=y_train.value_counts())\nplt.xlabel('Digits')\nplt.ylabel('Number of image samples')'''","c9ca0c5e":"batch_size = 86\nnum_classes = 10\nepochs = 10\ninput_shape = (28, 28, 1)\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal',input_shape=input_shape))\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.RMSprop(),\n              metrics=['accuracy'])\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.0001)","fafc51e6":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(X_train)","abcfcce3":"mnist_test = pd.read_csv(\"..\/input\/mnist-in-csv\/mnist_test.csv\")\nmnist_train = pd.read_csv(\"..\/input\/mnist-in-csv-train\/mnist_train.csv\")","25531516":"sample_submission = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")","ac890f64":"cols = test.columns","d3a730d2":"test['dataset'] = 'test'","949cddbd":"train['dataset'] = 'train'","00801a99":"dataset = pd.concat([train.drop('label', axis=1), test]).reset_index()","ec14bc50":"mnist = pd.concat([mnist_train, mnist_test]).reset_index(drop=True)\nlabels = mnist['label'].values\nmnist.drop('label', axis=1, inplace=True)\nmnist.columns = cols","5dcb2648":"idx_mnist = mnist.sort_values(by=list(mnist.columns)).index\ndataset_from = dataset.sort_values(by=list(mnist.columns))['dataset'].values\noriginal_idx = dataset.sort_values(by=list(mnist.columns))['index'].values","24c62ab1":"train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest_images = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\n\n#extract the label value from the training dataset, not required from test data as labels are not given for this test dataset\ntrain_label = np.array(train['label'])\ntrain_images = train.drop('label', axis=1)\n\n#training dataset is in 784 pixels which needs to be reshaped usign the re-shape function\ntrain_images_arr = np.array(train_images).reshape(42000,28,28)\ntest_images_arr = np.array(test_images).reshape(28000,28,28)\n\nplt.figure(figsize =(9,9))\nfor i in range(20):\n    plt.subplot(5,5,1+i)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(train_images_arr[i])\n    plt.xlabel(train_label[i])","d3d0778f":"for i in range(len(idx_mnist)):\n    if dataset_from[i] == 'test':\n        sample_submission.loc[original_idx[i], 'Label'] = labels[idx_mnist[i]]","5ea5db07":"sample_submission","86fb054f":"sample_submission.to_csv('submission.csv', index=False)","1be3cf8a":"# Importing train and test data","e33d1e9b":"![image.png](attachment:image.png)","efae4b34":"# Testing the data","df4e3489":"# Making the submission","227577e4":"#  Lets identify digits from thousands of hand written numbers!","76f23b1c":"# Import all required libraries","4552314e":"# If you like this notebook, please give an Upvote! Don't forget to check out my other notebooks too!\n\n* [ConnectX Baseline](https:\/\/www.kaggle.com\/brendan45774\/connectx-baseline)\n* [Countries Life Expectancy Animation](https:\/\/www.kaggle.com\/brendan45774\/countries-life-expectancy-animation)\n* [Data Visuals - Matplotlib](http:\/\/www.kaggle.com\/brendan45774\/data-visuals-matplotlib)\n* [Digit Recognizer Solution](http:\/\/www.kaggle.com\/brendan45774\/digit-recognizer-solution)\n* [Dictionary and Pandas Cheat sheet](https:\/\/www.kaggle.com\/brendan45774\/dictionary-and-pandas-cheat-sheet)\n* [EDA Tutorial Hollywood Movies](https:\/\/www.kaggle.com\/brendan45774\/eda-tutorial-hollywood-movies)\n* [Getting Started with Manifold Learning - Isomap](https:\/\/www.kaggle.com\/brendan45774\/getting-started-with-manifold-learning-isomap)\n* [Getting started with Matplotlib](http:\/\/www.kaggle.com\/brendan45774\/getting-started-with-matplotlib)\n* [Guide to Matplotlib Image](https:\/\/www.kaggle.com\/brendan45774\/guide-to-matplotlib-image)\n* [HOG features - Histogram of Oriented Gradients](https:\/\/www.kaggle.com\/brendan45774\/hog-features-histogram-of-oriented-gradients)\n* [How to get the lowest score](https:\/\/www.kaggle.com\/brendan45774\/how-to-get-the-lowest-score)\n* [House predict solution](http:\/\/www.kaggle.com\/brendan45774\/house-predict-solution)\n* [K-Means Clustering (Image Compression)](https:\/\/www.kaggle.com\/brendan45774\/k-means-clustering-image-compression)\n* [Kuzushiji-MNIST Panda](http:\/\/www.kaggle.com\/brendan45774\/kuzushiji-mnist-panda)\n* [Plotly Coronavirus (Covid-19)](https:\/\/www.kaggle.com\/brendan45774\/plotly-coronavirus-covid-19)\n* [Titanic Top Solution](http:\/\/www.kaggle.com\/brendan45774\/titanic-top-solution)\n* [Titanic Data Solution](http:\/\/www.kaggle.com\/brendan45774\/titanic-data-solution)\n* [Topic Modeling (LDA)](https:\/\/www.kaggle.com\/brendan45774\/topic-modeling-lda)\n* [Word Cloud - Analyzing Names](https:\/\/www.kaggle.com\/brendan45774\/word-cloud-analyzing-names)"}}