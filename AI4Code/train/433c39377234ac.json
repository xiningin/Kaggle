{"cell_type":{"129b5cc8":"code","c10f31d1":"code","16e37911":"code","f1401c61":"code","8dde63ee":"code","2009e1b8":"code","749e2178":"code","1b2a309f":"markdown","9c985679":"markdown","a97fd60d":"markdown"},"source":{"129b5cc8":"# Import the required modules\nimport datetime\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\nmatplotlib.rcParams['font.size'] = 8\nimport tensorflow as tf\n\nimport warnings\nwarnings.simplefilter('ignore')","c10f31d1":"# Set all the related path\nPATH_DATASET = '..\/input\/covid19-radiography-database\/COVID-19_Radiography_Dataset'","16e37911":"# Image generator for training (include augmentation)\n# we're not using rescaling, since EfficientNetB7 included rescaling in its bottom layer.\nimgTrainGen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rotation_range = 45,\n    zoom_range = 0.2,\n    shear_range = 0.2,\n    featurewise_center = True,\n    featurewise_std_normalization = True,\n    width_shift_range = 0,\n    height_shift_range = 0,\n    vertical_flip = False,\n    validation_split = 0.2,\n    fill_mode = 'nearest'\n)\n# Image generator for testing (didn't include augmentation)\nimgTestGen = tf.keras.preprocessing.image.ImageDataGenerator(\n    validation_split = 0.2\n)\n\n# Build the generator with flow from directory\n# Build for training\ntrainGeneratorBuild = imgTrainGen.flow_from_directory(\n    PATH_DATASET,\n    subset = 'training',\n    target_size = (224, 224),\n    class_mode = 'categorical',\n    batch_size = 32\n)\n# Build for test\ntestGeneratorBuild = imgTestGen.flow_from_directory(\n    PATH_DATASET,\n    subset = 'validation',\n    target_size = (224, 224),\n    class_mode = 'categorical',\n    batch_size = 32\n)","f1401c61":"# Import the mobilenet pretrained base\npretrained_base = tf.keras.applications.EfficientNetB7(\n    include_top = False,\n    input_shape = (224, 224, 3),\n    weights = 'imagenet'\n)\n# Freeze the pretrained base\npretrained_base.trainable = False;\n\nmodel = tf.keras.Sequential([\n    pretrained_base,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(128, activation='relu'), # This is our head\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(4, activation='softmax')\n])\nmodel.summary()\n\n# Create our model","8dde63ee":"model.compile(\n    optimizer = tf.keras.optimizers.Adam(0.001),\n    loss='categorical_crossentropy',\n    metrics='accuracy'\n)\n\n# Training process. This sample only train for 5 Epochs\n# Increase the training epoch for potentially better trainiing results\nstart = datetime.datetime.now()\nhistory = model.fit(trainGeneratorBuild,\n                    epochs = 5, \n                    validation_data = testGeneratorBuild,\n                    workers = 8, # Higher worker count to potentially speed up our training\n                    verbose = 1)\n\nend = datetime.datetime.now()\nprint(f'Total Training Time: {end - start}')","2009e1b8":"# Plotting training loss and validation loss\nplt.plot(history.history['loss'], 'r', label='Loss Training')\nplt.plot(history.history['val_loss'], 'b', label='Loss Validation')\nplt.title('Loss Training and Validation')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(loc=0)\nplt.show()","749e2178":"# Save the history as dataframe\nhistory_df = pd.DataFrame(history.history)\nhistory_df.to_csv('history.csv')","1b2a309f":"# 2. Prepare the data for training","9c985679":"# 3. Create the Model","a97fd60d":"# 1. Initialize"}}