{"cell_type":{"8208082a":"code","9bcc7431":"code","85417676":"code","4e15813a":"code","28ae0ad0":"code","16893d7d":"code","30797bc1":"code","a55878ab":"code","40309350":"code","85642494":"code","dedf31b2":"code","c306ea5f":"code","6f217aad":"code","5f6c3d67":"code","61ddfa29":"code","8e6795cd":"code","d1811393":"code","a75f9db1":"code","6e32db8d":"code","f823f50e":"code","243fdab6":"code","cc2e5f7f":"code","20658684":"code","ddffcc1d":"code","bff9cded":"code","e4423136":"code","2ab632b1":"code","bd003d7a":"code","e0435465":"code","b270f2f8":"code","6ecf7ce2":"code","b9c07444":"code","77ce7776":"code","336ae8c9":"code","787fac20":"code","8801a0c0":"code","4eb64564":"code","f21ab842":"code","ffde52db":"code","bdccbe72":"code","f0af3929":"code","affcb607":"code","a0614c5a":"code","2c6a362d":"code","8cc51d6e":"code","3202530a":"code","14423494":"markdown","88e8a76b":"markdown","0df782f9":"markdown","c0efcb84":"markdown","71e02389":"markdown","e50a45fc":"markdown","6ec44acc":"markdown","41de9fa7":"markdown","7bd7004e":"markdown","964240db":"markdown","0cf26826":"markdown","06b983e3":"markdown","92a7ec3c":"markdown","d74cc66d":"markdown","7897b680":"markdown","6ec0ab1b":"markdown","31970b1e":"markdown","68c445dd":"markdown","d1b504a6":"markdown","6af2e91b":"markdown","91c411a8":"markdown","208b0de3":"markdown","7d108a16":"markdown","561da898":"markdown","e9acdae3":"markdown","eb229a5a":"markdown","527d4a6d":"markdown","894ada87":"markdown","e37330a0":"markdown","2bc9b239":"markdown","19897345":"markdown","13753908":"markdown","362474da":"markdown","79abc8b9":"markdown","1c3396fa":"markdown"},"source":{"8208082a":"!pip install proplot\nimport warnings\nwarnings.filterwarnings('ignore') ","9bcc7431":"import pandas as pd\nimport numpy as np\n\ntrain = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntrain.head()","85417676":"# Defining plots design\ndef plots_design():\n    fig.patch.set_facecolor('black')\n    ax.patch.set_facecolor('black')\n    ax.tick_params(axis='both', which='major', labelsize=8)\n    ax.yaxis.set_label_coords(0, 0)\n    ax.grid(color='white', linewidth=2)\n    # Remove ticks\n    ax.xaxis.set_ticks_position('none')\n    ax.yaxis.set_ticks_position('none')\n    # Remove axes splines\n    for i in ['top', 'bottom', 'left', 'right']:\n        ax.spines[i].set_visible(False)\n    ax.tick_params(axis='x', colors='white')\n    ax.tick_params(axis='y', colors='white')\n    # Font\n    mpl.rcParams['font.family'] = 'Source Sans Pro'","4e15813a":"import matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nimport proplot as pplt\n\ncorr = train[train.columns].corr()['SalePrice'][:].sort_values(ascending=True).to_frame()\ncorr = corr.drop(corr[corr.SalePrice > 0.99].index)\n\n# Visualization\nfig, ax = plt.subplots(figsize =(9, 9))\n\nax.barh(corr.index, corr.SalePrice, align='center', color = np.where(corr['SalePrice'] < 0, 'crimson', '#89CFF0'))\n\nplots_design()\n\nplt.text(-0.12, 39, \"Correlation\", size=24, color=\"grey\", fontweight=\"bold\");\nplt.text(0.135, 39, \"of\", size=24, color=\"grey\");\nplt.text(0.185, 39, \"SalePrice\", size=24, color=\"#89CFF0\", fontweight=\"bold\");\nplt.text(0.4, 39, \"to\", size=24, color=\"grey\");\nplt.text(0.452, 39, \"Other Features\", size=24, color=\"grey\", fontweight=\"bold\");\n\n# Author\nplt.text(0.9, -7, \"@miguelfzzz\", fontsize=11, ha=\"right\", color='grey');","28ae0ad0":"# pairplot top 10 correlation features + target\ntop_corr = corr['SalePrice'].sort_values(ascending=False).head(10).index\ntop_corr = top_corr.union(['SalePrice'])\n\nsns.pairplot(train[top_corr]);","16893d7d":"print('Training Shape:', train.shape)\nprint('Test Shape:', test.shape)","30797bc1":"# let's save the ID of each dataset\ntrain_id = train['Id']\ntest_id = test['Id']\ndel train['Id']\ndel test['Id']","a55878ab":"train1 = train.copy()\ntrain1 = train1.drop(train1[(train1['GarageArea']>1200) & (train1['SalePrice']<300000)].index)\ntrain1 = train1.drop(train1[(train1['GrLivArea']>4000) & (train1['SalePrice']<300000)].index)\ntrain1 = train1.drop(train1[(train1['TotalBsmtSF']>5000)].index)","40309350":"print('Outliers removed =' , train.shape[0] - train1.shape[0])","85642494":"# Split X and y (in train dataset)\nX = train1.drop('SalePrice', axis=1)\ny = train1['SalePrice'].to_frame()\n\n# Add variable\nX['train'] = 1\ntest['train'] = 0\n\n# Combining train and test for data cleaning \ndf = pd.concat([test, X])","dedf31b2":"print('Count of Features per Data Type:')\ndf.dtypes.value_counts()  ","c306ea5f":"# Do we have duplicates?\nprint('Number of Duplicates:', len(df[df.duplicated()]))\n\n# Do we have missing values?\nprint('Number of Missing Values:', df.isnull().sum().sum())","6f217aad":"print('Missing Values per Column:')\ndf.isnull().sum().sort_values(ascending=False).head(25)","5f6c3d67":"df['PoolQC'] = df['PoolQC'].fillna('None')","61ddfa29":"df['MiscFeature'] = df['MiscFeature'].fillna('None')","8e6795cd":"df['Alley'] = df['Alley'].fillna('None')","d1811393":"df['Fence'] = df['Fence'].fillna('None')","a75f9db1":"df['FireplaceQu'] = df['FireplaceQu'].fillna('None')","6e32db8d":"df['LotFrontage'] = df.groupby('Neighborhood')['LotFrontage'].transform(lambda i: i.fillna(i.median()))","f823f50e":"# Let's take a look at the \"Garage\" features\ngarage_cols = [col for col in df if col.startswith('Garage')]\ndf[garage_cols]","243fdab6":"# For the numerical features:\nfor i in df[garage_cols].select_dtypes(exclude='object').columns:\n    df[i] = df[i].fillna(0)\n\n# For the categorical features:\nfor i in df[garage_cols].select_dtypes(include='object').columns:\n    df[i] = df[i].fillna('None')","cc2e5f7f":"bsmt_cols = [col for col in df if col.startswith('Bsmt')]\n\n# For the numerical features:\nfor i in df[bsmt_cols].select_dtypes(exclude='object').columns:\n    df[i] = df[i].fillna(0)\n\n# For the categorical features:\nfor i in df[bsmt_cols].select_dtypes(include='object').columns:\n    df[i] = df[i].fillna('None')","20658684":"mas_cols = [col for col in df if col.startswith('Mas')]\n\n# For the numerical features:\nfor i in df[mas_cols].select_dtypes(exclude='object').columns:\n    df[i] = df[i].fillna(0)\n\n# For the categorical features:\nfor i in df[mas_cols].select_dtypes(include='object').columns:\n    df[i] = df[i].fillna('None')","ddffcc1d":"df['MSZoning'] = df.groupby('Neighborhood')['MSZoning'].transform(lambda i: i.fillna(i.value_counts().index[0]))","bff9cded":"print('Missing Values left:')\ndf.isnull().sum().sort_values(ascending=False).head(10)","e4423136":"# replace missing values for mode of each column\ndf = df.fillna(df.mode().iloc[0])","2ab632b1":"df.describe().T","bd003d7a":"df['MSSubClass'] = df['MSSubClass'].astype(str)\ndf['MoSold'] = df['MoSold'].astype(str)           # months is always categorical\ndf['YrSold'] = df['YrSold'].astype(str)           # year sold just have 5 years","e0435465":"df['Total_House_SF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\ndf['Total_Home_Quality'] = (df['OverallQual'] + df['OverallCond'])\/2\ndf['Total_Bathrooms'] = (df['FullBath'] + (0.5 * df['HalfBath']) + df['BsmtFullBath'] + (0.5 * df['BsmtHalfBath']))","b270f2f8":"numeric_cols = df.select_dtypes(exclude='object').columns\n\nskew_limit = 0.5\nskew_vals = df[numeric_cols].skew()\n\nskew_cols = (skew_vals\n             .sort_values(ascending=False)\n             .to_frame()\n             .rename(columns={0:'Skew'})\n             .query('abs(Skew) > {0}'.format(skew_limit)))\n\nskew_cols","6ecf7ce2":"# Font\nmpl.rcParams['font.family'] = 'Source Sans Pro'\nmpl.rcParams['font.size'] = 12\n\nfig, (ax_positive, ax_negative) = plt.subplots(1, 2, figsize=(10, 5))\nfig.patch.set_facecolor('black')\nax_positive.patch.set_facecolor('black')\nax_negative.patch.set_facecolor('black')\n\nsns.histplot(df['BsmtUnfSF'],kde=True, stat='density', linewidth=0, color = '#236AB9', ax=ax_positive)\nsns.histplot(df['YearBuilt'], kde=True, stat='density', linewidth=0,color='#B85B14', ax=ax_negative)\n\nax_positive.tick_params(axis='x', colors='white')\nax_positive.tick_params(axis='y', colors='white')\nax_negative.tick_params(axis='x', colors='white')\nax_negative.tick_params(axis='y', colors='white')\n\nax_positive.set(ylabel='Frequency', xlabel='Value');\nax_negative.set(ylabel='Frequency', xlabel='Value');\n\nax_positive.xaxis.label.set_color('white')\nax_positive.yaxis.label.set_color('white')\nax_negative.xaxis.label.set_color('white')\nax_negative.yaxis.label.set_color('white')\n\nax_positive.set_title('Positive Skew (BsmtUnfSF)', color='white', fontsize= 15)\nax_negative.set_title('Negative Skew (YearBuilt)', color='white', fontsize= 15)\n\n\n\n# Remove axes splines\nfor i in ['top', 'bottom', 'left', 'right']:\n    ax_positive.spines[i].set_visible(False)\n\nfor i in ['top', 'bottom', 'left', 'right']:\n    ax_negative.spines[i].set_visible(False)","b9c07444":"from scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\n# Normalize skewed features\nfor col in skew_cols.index:\n    df[col] = boxcox1p(df[col], boxcox_normmax(df[col] + 1))","77ce7776":"import matplotlib.ticker as ticker\n\n# Font\nmpl.rcParams['font.family'] = 'Source Sans Pro'\nmpl.rcParams['font.size'] = 10\n\n# Visualization\nfig, ax = plt.subplots(figsize =(9, 6))\nfig.patch.set_facecolor('black')\nax.patch.set_facecolor('black')\n\nsns.histplot(y['SalePrice'], stat='density', linewidth=0, color = '#ff7f50', kde=True, alpha=0.3);\n\n# Remove ticks\nax.xaxis.set_ticks_position('none')\nax.yaxis.set_ticks_position('none')\n\n# Remove axes splines\nfor i in ['top', 'bottom', 'left', 'right']:\n    ax.spines[i].set_visible(False)\n\n# Remove grid\nplt.grid(b=None)\n\n# Setting thousands with k\nax.xaxis.set_major_formatter(ticker.EngFormatter())\n\nax.tick_params(axis='x', colors='white')\nax.tick_params(axis='y', colors='white')\nax.xaxis.label.set_color('white')\nax.yaxis.label.set_color('white')\n\n# Font\nmpl.rcParams['font.family'] = 'Source Sans Pro'\n\nplt.xlabel('SalePrice', fontsize=11);\n\nplt.text(230000, 0.0000088, \"SalePrice\", size=22, color=\"#ff7f50\", fontweight=\"bold\");\nplt.text(380000, 0.0000088, \"Distribution\", size=22, color=\"grey\", fontweight=\"bold\");","336ae8c9":"# log(1+x) transform\ny[\"SalePrice\"] = np.log1p(y[\"SalePrice\"])","787fac20":"import matplotlib.ticker as ticker\n\n# Font\nmpl.rcParams['font.family'] = 'Source Sans Pro'\nmpl.rcParams['font.size'] = 10\n\n# Visualization\nfig, ax = plt.subplots(figsize =(9, 6))\nfig.patch.set_facecolor('black')\nax.patch.set_facecolor('black')\n\nsns.histplot(y['SalePrice'], stat='density', linewidth=0, color = '#ff7f50', kde=True, alpha=0.3);\n\n# Remove ticks\nax.xaxis.set_ticks_position('none')\nax.yaxis.set_ticks_position('none')\n\n# Remove axes splines\nfor i in ['top', 'bottom', 'left', 'right']:\n    ax.spines[i].set_visible(False)\n\n# Remove grid\nplt.grid(b=None)\n\n# Setting thousands with k\nax.xaxis.set_major_formatter(ticker.EngFormatter())\n\nax.tick_params(axis='x', colors='white')\nax.tick_params(axis='y', colors='white')\nax.xaxis.label.set_color('white')\nax.yaxis.label.set_color('white')\n\n# Font\nmpl.rcParams['font.family'] = 'Source Sans Pro'\n\nplt.xlabel('SalePrice', fontsize=11);\n\nplt.text(11.27, 1.25, \"SalePrice\", size=22, color=\"#ff7f50\", fontweight=\"bold\");\nplt.text(11.92, 1.25, \"Distribution\", size=22, color=\"grey\", fontweight=\"bold\");","8801a0c0":"categ_cols = df.dtypes[df.dtypes == np.object]        # filtering by categorical variables\ncateg_cols = categ_cols.index.tolist()                # list of categorical fields\n\ndf_enc = pd.get_dummies(df, columns=categ_cols, drop_first=True)   # One hot encoding","4eb64564":"X = df_enc[df_enc['train']==1]\ntest = df_enc[df_enc['train']==0]\nX.drop(['train'], axis=1, inplace=True)\ntest.drop(['train'], axis=1, inplace=True)","f21ab842":"from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)","ffde52db":"def rmse(ytrue, ypredicted):\n    return np.sqrt(mean_squared_error(ytrue, ypredicted))","bdccbe72":"lasso = Lasso(max_iter = 100000, normalize = True)\n\nlassocv = LassoCV(alphas = None, cv = 10, max_iter = 100000, normalize = True)\nlassocv.fit(X_train, y_train)\n\nlasso.set_params(alpha=lassocv.alpha_)\nlasso.fit(X_train, y_train)\n\nprint('The Lasso I:')\nprint(\"Alpha =\", lassocv.alpha_)\nprint(\"RMSE =\", rmse(y_test, lasso.predict(X_test)))","f0af3929":"# Let's try the same. This time setting up alpha...\nalpha = np.geomspace(1e-5, 1e0, num=6)\nlasso_cv_model = LassoCV(alphas = alpha, cv = 10, max_iter = 100000, normalize = True).fit(X_train,y_train)\nlasso_tuned = Lasso(max_iter = 100000, normalize = True).set_params(alpha = lasso_cv_model.alpha_).fit(X_train,y_train)\nprint('The Lasso II:')\nprint(\"Alpha =\", lasso_cv_model.alpha_)\nprint(\"RMSE =\", rmse(y_test, lasso_tuned.predict(X_test)))","affcb607":"alphas = np.geomspace(1e-9, 5, num=100)\n\nridgecv = RidgeCV(alphas = alphas, scoring = 'neg_mean_squared_error', normalize = True)\nridgecv.fit(X_train, y_train)\n\nridge = Ridge(alpha = ridgecv.alpha_, normalize = True)\nridge.fit(X_train, y_train)\n\nprint('Ridge Regression:')\nprint(\"Alpha =\", ridgecv.alpha_)\nprint(\"RMSE =\", rmse(y_test, ridge.predict(X_test)))","a0614c5a":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import KFold\nfrom sklearn.svm import SVR\n\n\nkf = KFold(shuffle=True, random_state=1234, n_splits=10)\n\nX_train_scale = RobustScaler().fit_transform(X_train)\nX_test_scale = RobustScaler().fit_transform(X_test)\n\nparameters = {'C':[20, 30, 40], 'gamma': [1e-4, 3e-4, 5e-4],'epsilon':[0.1, 0.01, 0.05]}\nsvr = SVR(kernel='rbf')\nclf = GridSearchCV(svr, parameters, cv=kf)\nclf.fit(X_train_scale,y_train)\nclf.best_params_","2c6a362d":"svr = SVR(kernel ='rbf', C= 20, epsilon= 0.01, gamma=0.0003)\nsvr.fit(X_train_scale,y_train)\n\nprint('SVR Regression:')\nprint(\"RMSE =\", rmse(y_test, svr.predict(X_test_scale)))","8cc51d6e":"print('Out of {} coefficients, {} are non-zero with Lasso.'\n     .format(len(lasso_tuned.coef_), len(lasso_tuned.coef_.nonzero()[0])))","3202530a":"# Selecting features importance\ncoefs = pd.Series(lasso_tuned.coef_, index = test.columns)\n\nlasso_coefs = pd.concat([coefs.sort_values().head(10),\n                         coefs.sort_values().tail(10)])\n\nlasso_coefs = pd.DataFrame(lasso_coefs, columns=['importance'])\n\n# Visualization\nfig, ax = plt.subplots(figsize =(11, 9))\n\nax.barh(lasso_coefs.index, lasso_coefs.importance, align='center', \n        color = np.where(lasso_coefs['importance'] < 0, 'crimson', '#89CFF0'))\n\nplots_design()\n\nplt.text(-0.22, 20.5, \"Feature Importance\", size=24, color=\"grey\", fontweight=\"bold\");\nplt.text(-0.063, 20.5, \"using\", size=24, color=\"grey\");\nplt.text(-0.0182, 20.5, \"Lasso Model\", size=24, color=\"#89CFF0\", fontweight=\"bold\");\n\n# Author\nplt.text(0.2, -3.3, \"@miguelfzzz\", fontsize=12, ha=\"right\", color='grey');","14423494":"## <center style=\"font-family:Arial\">Importing the Data <\/center>\n\n","88e8a76b":"## <center style=\"font-family:Arial\">Transforming some numerical categories into categorical<\/center>\n\n<div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\">Reading the data description shows very clearly that some numerical features represent a specific category.<\/div>","0df782f9":"## <center style=\"font-family:Arial\">Lasso Regression + Cross-Validation<\/center>\n    \n* <div style=\"font-size:120%\">Lasso Regression is a linear model that minimizes its cost function.<\/div>\n\n* <div style=\"font-size:120%\">The cost funtion has a regularization parameter -<b>L1 penalty<\/b>- with an alpha that tunes the intensity of this penalty term. <\/div>\n\n* <div style=\"font-size:120%\">This penalty reduces some features to zero, which makes it easier to understand and interpret the prediction.<\/div>\n\n* <div style=\"font-size:120%\">The larger the value of alpha, the more coefficients are forced to be zero.<\/div>\n\n* <div style=\"font-size:120%\">The Lasso regression helps reduce over-fitting and feature selection.<\/div>\n\n","c0efcb84":"## <center style=\"font-family:Arial\">Split X and y<\/center>","71e02389":"## <center style=\"font-family:Arial\">Skewed features<\/center>\n\n<div style=\"font-size:120%\">Outliers are silent killers in prediction models. In this section, I'll imput the features that are not normally distributed.<\/div>\n\n* <div style=\"font-size:120%\">First, I'll select the features that have a skew higher than 0.5.<\/div>","e50a45fc":"# <center style=\"font-family:Arial\">2. EDA <\/center>","6ec44acc":"## <center style=\"font-family:Arial\">Transforming target<\/center>","41de9fa7":"* <div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\"><code>Fence<\/code> refers to the type of fencing around the property. Data description says that having a NaN in this category means that the house doesn't have a fence.<\/div>\n","7bd7004e":"<div style=\"font-size:120%\">All the features in blue positively affect the sale price of the house, which means this characteristic increases the price of the house. Vice versa, all the features in red negatively affect the sale price of the house.<\/div>","964240db":"* <div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\"><code>PoolQC<\/code> refers to the pool quality of the house. Data description says that having a NaN in this category means that the house doesn't have a pool.<\/div>","0cf26826":"# <center style=\"font-family:Arial\">5. Modelling <\/center>","06b983e3":"# <center style=\"font-family:Arial\">6. Interpretation <\/center>\n\n<div style=\"font-size:120%\">As mentioned previously, the Lasso regression is a very easy model to interpret, and that's why for this notebook I'll base the features importance on the <b>Lasso model<\/b>.<\/div>","92a7ec3c":"* <div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\">All the features that start with <code>Bsmt<\/code> and contain NaN means that those houses don't have a basement.<\/div>","d74cc66d":"<div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\">We can see that some features are categorical and others numerical. Let's replace the NaN with None in the categorical features and in the numerical features with 0.<\/div>","7897b680":"## <center style=\"font-family:Arial\">Encoding categorical features<\/center>","6ec0ab1b":"<div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\">The rest of the <b>missing values<\/b> are minimal. I'm going to transform the remaining NaN to the mode of each column.<\/div>","31970b1e":"* <div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\"><code>Alley<\/code> refers to the type of alley access to the property. Data description says that having a NaN in this category means that the house doesn't have any.<\/div>","68c445dd":"## <center style=\"font-family:Arial\">Ridge Regression + Cross-Validation<\/center>\n\n* <div style=\"font-size:120%\">The Ridge Regression is similar to the Lasso Regression: it's also a linear model that minimizes its cost function and has a regularization parameter -<b>L2 penalty<\/b>-.<\/div>\n\n* <div style=\"font-size:120%\">The lower the value of the alpha, the more linear the model will be.<\/div>\n\n* <div style=\"font-size:120%\">This model doesn't force some features to zero. <\/div>\n\n* <div style=\"font-size:120%\">The Ridge Regression shrinks the coefficients, and it helps to reduce the model complexity and multi-collinearity.<\/div>","d1b504a6":"## <center style=\"font-family:Arial\">Support Vector Regression (SVR) + Cross-Validation<\/center>","6af2e91b":"<center style=\"font-size: 24px\">If you liked this notebook, please don't forget to comment and upvote. Thank you!<\/center>","91c411a8":"# <center style=\"font-family:Arial\">3. Data Processing and Cleaning <\/center>","208b0de3":"## <center style=\"font-family:Arial\">Outliers<\/center>","7d108a16":"# <center style=\"font-family:Arial\">4. Feature Engineering <\/center>","561da898":"* <div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\"><code>MSZoning<\/code> refers to the general zoning classification of the sale. Let's impute the missing values with the most common category of the neighborhood.<\/div>","e9acdae3":"* <div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\"><code>FireplaceQu<\/code> refers to the quality of the fireplace. Data description says that having a NaN in this category means that the house doesn't have a fireplace.<\/div>","eb229a5a":"<div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\">Focusing on the target variable (SalePrice), we can see that there are some outliers in features such as <code>GarageArea<\/code>, <code>GrLivArea<\/code> and <code>TotalBsmtSF<\/code>. <\/div>","527d4a6d":"<div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\">In my case, I'll use the Box-Cox transformation to transform all the skew features into a normal distribution.<\/div>","894ada87":"* <div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\"><code>MiscFeature<\/code> refers to miscellaneous features of the house. Data description says that having a NaN in this category means that the house doesn't have any.<\/div>","e37330a0":"# <center style=\"font-family:Arial\">1. Introduction <\/center>\n\n<div class=\"alert alert-block alert-info\"\n     style=\"color:black;\n           display:fill;\n           background-color:#e8f4f8;\n           font-size:130%;\n           font-family:Arial\"><center>\n<b> \ud83d\udccc My goal is to predict, in the best possible way, the sales price of the houses based on their characteristics using different linear regression models.<\/b><\/center>\n    <\/div>\n    \n <div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\">\nIn this notebook, I'll be working with the Ames Housing dataset, a complete dataset containing every aspect of residential homes in Ames, Iowa. If you want to know more about the data, you can click <a href=\"https:\/\/www.kaggle.com\/c\/house-prices-advanced-regression-techniques\/data\" target=\"_blank\"> here<\/a>.\n<\/div>\n\n<hr style=\"height: 0.5px; border: 0; background-color: 'Black'\">\n\n\n![imageHouses](https:\/\/static.vecteezy.com\/system\/resources\/previews\/002\/197\/652\/original\/house-hand-drawn-set-design-illustration-isolated-on-white-background-free-vector.jpg)\n","2bc9b239":"## <center style=\"font-family:Arial\">Missing values<\/center>","19897345":"* <div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\">All the features that start with <code>Mas<\/code> and contain NaN means that those houses don't have a masonry veneer.<\/div>","13753908":"* <div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\">All the features that start with <code>Garage<\/code> and contain NaN means that those houses don't have a garage.<\/div>","362474da":"<div style=\"font-size:120%\">In this plot, we can see the correlation of sales price with the rest of the numerical features. These are the highest positive correlations:<\/div>\n\n* <div style=\"font-size:120%\"><code>OverallQual<\/code>: Overall material and finish quality<\/div>\n* <div style=\"font-size:120%\"><code>GrLivArea<\/code>: Above grade (ground) living area in square feet<\/div>\n* <div style=\"font-size:120%\"><code>GarageCars<\/code>: Size of garage by car capacity<\/div>\n* <div style=\"font-size:120%\"><code>GarageArea<\/code>: Size of garage in square feet<\/div>\n* <div style=\"font-size:120%\"><code>TotalBsmtSF<\/code>: Total square feet of basement area<\/div>\n* <div style=\"font-size:120%\"><code>1stFlrSF<\/code>: First Floor square feet<\/div>","79abc8b9":"* <div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\"><code>LotFrontage<\/code> refers to the distance in feet between the street and the property. Let's impute the missing values with the median of the neighborhood.<\/div>","1c3396fa":"## <center style=\"font-family:Arial\">Adding relevant features<\/center>\n\n<div style=\"color:black;\n           font-size:120%;\n           font-family:Arial\">Adding relevant features can increase the accuracy of the prediction.<\/div>"}}