{"cell_type":{"961bf32a":"code","144cd766":"code","43b90873":"code","f5964cf5":"code","8781147b":"code","0d9b6e76":"code","9b3ca5b5":"code","56df6172":"code","7f76c0b0":"code","10257164":"code","1a6659d4":"code","3b4e9788":"code","2c760163":"code","c3338a04":"markdown"},"source":{"961bf32a":"from __future__ import print_function\nimport lime\nimport sklearn\nfrom sklearn import feature_extraction\nimport numpy as np\nimport pandas as pd\nimport sklearn\nimport sklearn.ensemble\nimport sklearn.metrics\nfrom sklearn.model_selection import train_test_split","144cd766":"train_data = pd.read_csv('..\/input\/sentiment140\/result.csv',\n                         encoding='latin-1',\n                         skiprows = lambda x : x > 20000 and x <= 800000,\n                         nrows=40000)\n\ntrain_data = train_data.dropna()\n\ntrain_data.columns = [\"polarity\",\"text\"]\n\ntrain_sentences = train_data[\"text\"].fillna(\"fillna\").str.lower()\n\ny = train_data[\"polarity\"].values\n\nfor i in range(len(y)):\n    value = y[i]\n    if value > 0.5:y[i]=1\n    elif value < -0.5:y[i]=-1\n    else: y[i]=0","43b90873":"from nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nimport string\nimport re\n\nlemma = WordNetLemmatizer()\n\nstop = list(stopwords.words(\"english\"))\npunctuation = list(string.punctuation)\nsw_pun = stop + punctuation\n\ndef preprocess(tweet):\n    tweet = re.sub(r\"https?:\\\/\\\/t.co\\\/[A-Za-z0-9]+\", \"\", tweet) \n    tweet = re.sub('[^\\w]',' ',tweet)          \n    tweet = tweet.lower()\n    words = tweet.split()  \n    sentence = \"\"\n    for word in words:     \n        if word not in (sw_pun):                 \n            word = lemma.lemmatize(word,pos = 'v')  \n            if len(word) > 3:\n                sentence = sentence + word + ' '             \n    return(sentence)\n\ntrain_sentences = train_sentences.apply(lambda s : preprocess(s))","f5964cf5":"from collections import Counter\n\ndef create_vocab(df):\n    vocab = Counter()\n    for i in range(df.shape[0]):\n        vocab.update(df[i].split())\n    return(vocab)\n\nvocab = create_vocab(train_sentences.reset_index(drop=True))\nprint(len(vocab))\n\nfinal_vocab = []\nmin_occur = 4\nfor k,v in vocab.items():\n    if v >= min_occur:\n        final_vocab.append(k)\n        \nprint(len(final_vocab))\n\ndef filter(tweet):\n    sentence = \"\"\n    for word in tweet.split():  \n        if word in final_vocab:\n            sentence = sentence + word + ' '\n    return(sentence)\n\ntrain_sentences = train_sentences.apply(lambda s : filter(s))","8781147b":"X_train, X_val, y_train, y_val = train_test_split(train_sentences, y, test_size=0.2, \n                                                  random_state=1)","0d9b6e76":"vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=False)\ntrain_vectors = vectorizer.fit_transform(X_train)\ntest_vectors = vectorizer.transform(X_val)","9b3ca5b5":"rf = sklearn.ensemble.RandomForestClassifier(n_estimators=500)\nrf.fit(train_vectors, y_train)","56df6172":"pred = rf.predict(test_vectors)\nsklearn.metrics.f1_score(y_val, pred, average='binary')","7f76c0b0":"from lime import lime_text\nfrom sklearn.pipeline import make_pipeline\nfrom lime.lime_text import LimeTextExplainer\n\nc = make_pipeline(vectorizer, rf)\n\nclass_names=['N\u00e9gatif','Positif']\nexplainer = LimeTextExplainer(class_names=class_names)","10257164":"text='btc is up'\n#rf.predict(text)\nc.predict_proba([text])[0][1]","1a6659d4":"for idx in range (130,140):\n    exp = explainer.explain_instance(X_val.values.tolist()[idx], c.predict_proba, num_features=6)\n    print('Probability (positif) =', c.predict_proba([X_val.values.tolist()[idx]])[0,1])\n    print('True class: %s' % class_names[y_val[idx]])\n    exp.show_in_notebook(text=True)\n    exp.save_to_file(str(idx) + '.html')","3b4e9788":"import pickle\n\n# saving    \nwith open('vectorizer.pk', 'wb') as fin:\n    pickle.dump(vectorizer, fin)","2c760163":"import joblib\n#joblib.dump(rf, \".\/random_forest.joblib\")\njoblib.dump(rf, \".\/RF_uncompressed.joblib\", compress=9)","c3338a04":"# Lime part"}}