{"cell_type":{"297bd0d6":"code","60d26b72":"code","7515a7c6":"code","43c82118":"code","869b7105":"code","7c9c10cd":"code","99f94448":"code","5de25127":"code","cfad0e47":"code","25cdbed1":"code","9adb0c87":"code","b888fafe":"code","97f9cdce":"code","31c3e40c":"code","c8853071":"code","80ac1d56":"code","b59959bb":"code","3ddf84b0":"code","2b21b24e":"code","2ead52f9":"code","6fe0f9c6":"code","41759d88":"code","941a46fb":"code","0e376b46":"code","bed3de97":"markdown","ae1ae40d":"markdown","cec212e7":"markdown","3012c85a":"markdown","b6b06e84":"markdown","e0a3a8c2":"markdown","08444b7e":"markdown","401e6c88":"markdown","83436522":"markdown","c6f03be9":"markdown"},"source":{"297bd0d6":"!pip install numerapi duckdb halo","60d26b72":"import os\nimport glob\nimport gc\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport pyarrow.parquet as pq\nimport numerapi\n\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","7515a7c6":"napi = numerapi.NumerAPI(verbosity=\"info\")\ncurrent_round = napi.get_current_round(tournament=8)\n\ntrain_pq_path = \"numerai_training_data.parquet\"\ntournament_pq_path = \"numerai_tournament_data.parquet\"\nvalid_pq_path = \"numerai_validation_data.parquet\"\nvalid_preds_pq_path = \"example_validation_predictions.parquet\"\n\nnapi.download_dataset(\"numerai_training_data_int8.parquet\", train_pq_path)\nnapi.download_dataset(\"numerai_tournament_data_int8.parquet\", tournament_pq_path)\nnapi.download_dataset(\"numerai_validation_data_int8.parquet\", valid_pq_path)\nnapi.download_dataset(valid_preds_pq_path, valid_preds_pq_path)\n","43c82118":"EXAMPLE_PREDS_COL = \"example_preds\"\nTARGET_COL = \"target\"\nERA_COL = \"era\"","869b7105":"train_pq = pq.ParquetFile(train_pq_path)\ntournament_pq = pq.ParquetFile(tournament_pq_path)\nvalid_pq = pq.ParquetFile(valid_pq_path)","7c9c10cd":"print('train metadata')\nprint(train_pq.metadata)\n\nprint('tournament metadata')\nprint(tournament_pq.metadata)\n\nprint('valid metadata')\nprint(valid_pq.metadata)","99f94448":"col_names = train_pq.schema.names\nfeature_cols = [col for col in col_names if \"feature\" in col]\ntarget_cols = [col for col in col_names if \"target\" in col]\n\nprint(col_names[:5])\nprint(feature_cols[:5])\nprint(target_cols[:5])","5de25127":"class PandasDriver:\n    def __init__(self, pq_path: str, splits=4):\n        self.pq_path = pq_path\n        self.splits = splits\n        \n        self.df = pd.read_parquet(pq_path)\n        self.df['era'] = self.df['era'].astype('int')\n    \n    def get_by_group(self, group_id: int, cols=None):\n        if group_id == self.splits:\n            group_id = 0\n        return self.df[self.df['era'] % self.splits == group_id]\n\n\nimport duckdb\n\nclass DuckDBDriver:\n    def __init__(self, pq_path: str, splits=4):\n        self.pq_path = pq_path\n        self.splits = splits\n        self.conn = duckdb.connect(\":memory:\")\n        \n    def _gen_select_statement(self) -> str:\n        return f\"SELECT * FROM parquet_scan('{self.pq_path}') \"\n    \n    def _query(self, expression: str):\n        return self. conn.execute(expression)\n    \n    def _fetch(self, ret_query, fetch_type, cols):\n        if fetch_type == \"pandas\":\n            return ret_query.fetchdf()\n        elif fetch_type == \"numpy\":\n            return ret_query.fetchdf()[cols].values\n        \n    def get_by_era(self, era: str, cols=None, fetch_type=\"pandas\"):\n        expression = self._gen_select_statement()\n        expression += f\"WHERE era = '{era}'\"\n        ret_query = self._query(expression)\n        return self._fetch(ret_query, fetch_type, cols)\n    \n    def get_by_group(self, group_id: int, cols=None, fetch_type=\"pandas\"):\n        if group_id == self.splits:\n            group_id = 0\n        expression = self._gen_select_statement()\n        expression += f\"WHERE CAST(era AS INT) % {self.splits} = {group_id}\"\n        ret_query = self._query(expression)\n        return self._fetch(ret_query, fetch_type, cols)","cfad0e47":"#driver = DuckDBDriver(train_pq_path)\ndriver = PandasDriver(train_pq_path)","25cdbed1":"df = driver.get_by_group(1)","9adb0c87":"df.head()","b888fafe":"df['era'].unique()[:10]","97f9cdce":"del df\ngc.collect()","31c3e40c":"from lightgbm import LGBMRegressor","c8853071":"params = {\n    \"n_estimators\": 2000,\n    \"learning_rate\": 0.01,\n    \"max_depth\": 5,\n    \"num_leaves\": 2 ** 5,\n    \"colsample_bytree\": 0.1,\n}\nmodels = []\nfor group_id in tqdm(range(1, 5)):\n    df = driver.get_by_group(group_id)\n    model = LGBMRegressor(**params)\n    model.fit(df[feature_cols].values, df[TARGET_COL].values)\n    models.append(model)\n    del df\n    gc.collect()\n\n'''\n# This is training a single model while changing era group, such that era boost training.\n# But validation performance is not good.\n\nnum_iters = 50\nn_groups = 4\nn_estimators = 10\n\nparams = {\n    \"n_estimators\": n_estimators,\n    \"learning_rate\": 0.01,\n    \"max_depth\": 5,\n    \"num_leaves\": 2 ** 5,\n    \"colsample_bytree\": 0.1,\n}\n\nmodel = LGBMRegressor(**params)\nfor epoch in tqdm(range(num_iters)):\n    for group_id in range(1, n_groups+1):\n        df = driver.get_by_group(group_id)\n        # Caution: except all\n        try:\n            booster = model.booster_\n            model.fit(\n                X=df[feature_cols].values, \n                y=df[TARGET_COL].values,\n                init_model=booster,\n                verbose=1\n            )\n        except:\n            model.fit(\n                X=df[feature_cols].values, \n                y=df[TARGET_COL].values,\n                verbose=1\n            )\n        del df\n        gc.collect()\nmodels = [model]     \n'''","80ac1d56":"show_cols = 20\nsns.set(font_scale = 2)\n\nfor i, model in enumerate(models):\n    feature_imp = pd.DataFrame(sorted(zip(model.feature_importances_,feature_cols)), columns=['Value','Feature'])\n    plt.figure(figsize=(10, 10))\n    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False).iloc[:show_cols])\n    plt.title(f'model {i+1} feature importance')\nplt.show()","b59959bb":"validation_data = pd.read_parquet(valid_pq_path)\nvalidation_preds = pd.read_parquet(valid_preds_pq_path)\nvalidation_data[EXAMPLE_PREDS_COL] = validation_preds[\"prediction\"]\ndel validation_preds\ngc.collect()","3ddf84b0":"!git clone https:\/\/github.com\/numerai\/example-scripts.git\n%cd example-scripts\nfrom utils import validation_metrics","2b21b24e":"for i, model in enumerate(models):\n    validation_data.loc[:, f\"preds_{i+1}\"] = model.predict(validation_data.loc[:, feature_cols].values)\nvalidation_stats = validation_metrics(validation_data, [f\"preds_{i+1}\" for i in range(len(models))] + [EXAMPLE_PREDS_COL], example_col=EXAMPLE_PREDS_COL, fast_mode=True)","2ead52f9":"print(validation_stats[[\"mean\", \"sharpe\", \"mmc_mean\", \"corr_plus_mmc_sharpe\"]].to_markdown())","6fe0f9c6":"%cd ..\n\nmodel_to_submit = \"preds_4\"\nvalidation_data[\"prediction\"] = validation_data[model_to_submit].rank(pct=True)\nvalidation_data[\"prediction\"].to_csv(f\"validation_predictions.csv\")","41759d88":"del validation_data\ngc.collect()","941a46fb":"tournament_data = pd.read_parquet(tournament_pq_path, columns=['id'])","0e376b46":"batch_size=2000\ntournament_preds = np.zeros((len(tournament_data), len(models)))\n\ntournament_batches = tournament_pq.iter_batches(batch_size)\nfor i, batch in tqdm(enumerate(tournament_batches)):\n    features = batch.to_pandas()[feature_cols]\n    for j, model in enumerate(models):\n        tournament_preds[i*batch_size:(i+1)*batch_size, j] = model.predict(features)\ntournament_data[[ f\"preds_{i+1}\" for i in range(4)]] = tournament_preds\n\ndel tournament_preds\n\ntournament_data[\"prediction\"] = tournament_data[model_to_submit].rank(pct=True)\ntournament_data[\"prediction\"].to_csv(f\"tournament_predictions.csv\")","bed3de97":"# Example reading data by era\nWe want to get data on a monthly , so we will get data at 4era intervals.  \nThe following is an example that read the data like eras = [0001, 0005, 0009, ... ]","ae1ae40d":"# Training LightGBM using New Tournament Dataset for Low Memory  \nThis notebook is a BaseLine for LightGBM using the newly released Numerai tournament dataset.     \nhttps:\/\/forum.numer.ai\/t\/super-massive-data-release-deep-dive\/4053  \nThe modeling for this data set is available at  \nhttps:\/\/github.com\/numerai\/example-scripts  \nHowever, since the dataset is large, modeling using the all dataset requires a considerable amount of machine resources, such as Google Colab Pro+.  \nIn this case, I train LightGBM with monthly samples of era so that it can be run on Kaggle Notebook.    \n\n### This Notebook can \n- **train LightGBM using all feature monthly era data**\n\n### Because of OOM, This Notebook can't\n- **train all data in 1 batch**","cec212e7":"# Read ParquetFile","3012c85a":"# Install Libraries","b6b06e84":"## Download dataset","e0a3a8c2":"# Setup Query Driver\nIt is diffucult to train all data in 1 batch because of OOM(Out of Memory), so this notebook use mini batch training.  \nFor mini batch training, set up era query driver.  \n\nBefore int8 dataset was released,\u3000I was using DuckDB because of memory errors when loading it.\u3000\u3000  \nDuckDB allows you to read data from a query.    \nThis is especially useful when you want to get data for each *era*.  ","08444b7e":"# Validation\n## Loading Example Script\nLoad Example Script to use validation_metrics","401e6c88":"# Test Prediction\n## Dump Sumission CSV","83436522":"# Training","c6f03be9":"best validation model is preds_4 training in eras = [ 0004, 0008, 00012, ...]"}}