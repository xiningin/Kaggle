{"cell_type":{"362c6929":"code","3bbcdccc":"code","93056853":"code","902118a3":"code","355da803":"code","ce2c2bfb":"code","2233f508":"code","f5094304":"code","d9015c3e":"code","b26c6039":"code","3548847b":"code","dcffb5a1":"code","bc25f07c":"code","6f88f80e":"code","aaa88cb7":"code","c7d6d6b7":"code","1358fd80":"code","a3ee872f":"code","524dd484":"code","a951c294":"code","bb1b7788":"code","050652e7":"code","6a4a50af":"code","2ab62ac8":"code","60c118fe":"code","68760880":"code","cd53705c":"code","a01e59a9":"code","46f339e1":"code","0a867eed":"code","c97ae63d":"code","11dc7dc3":"code","8d4ea225":"code","7daa14a2":"code","02e55e7c":"code","b22317db":"code","0e312786":"code","bd5ed64c":"markdown","2a89cfb6":"markdown","4fead057":"markdown","f8bca03b":"markdown","6a4caf81":"markdown","70f4f52e":"markdown","c094646d":"markdown","405780dd":"markdown","889efbba":"markdown","5c2f0de6":"markdown","9479a510":"markdown","0e3f6943":"markdown"},"source":{"362c6929":"import numpy as np\nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nimport tensorflow.keras.layers as Layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom PIL import Image\n\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\nwarnings.filterwarnings('ignore')","3bbcdccc":"BASE_URL = '..\/input\/chest-xray-pneumonia\/chest_xray'\nFOLDERS = ['test', 'val', 'train']\nCATEGORIES = ['NORMAL', 'PNEUMONIA']","93056853":"#get all the image filenames on normal class and create a dataframe\nclass_normal = []\n\nfor f in FOLDERS:\n    folder = os.path.join(BASE_URL, f)\n\n    for path in os.listdir(os.path.join(folder, 'NORMAL')):\n        class_normal.append([os.path.join(folder, 'NORMAL\/'+path), 0])\nnormal_df = pd.DataFrame(class_normal, columns=['filepaths', 'labels'])","902118a3":"#get all the image filenames on pneumonia class and create a dataframe\n\nclass_pneumonia = []\n\nfor f in FOLDERS:\n    folder = os.path.join(BASE_URL, f)\n\n    for path in os.listdir(os.path.join(folder, 'PNEUMONIA')):\n        class_pneumonia.append([os.path.join(folder, 'PNEUMONIA\/'+path), 1])\npneumonia_df = pd.DataFrame(class_pneumonia, columns=['filepaths', 'labels'])","355da803":"#concatenate the two dataframes we created above\ndf = pd.concat([normal_df, pneumonia_df], axis=0).reset_index()\ndf.drop('index', axis=1, inplace=True)\ndf.head()","ce2c2bfb":"#show dataframe shape\nprint('DATAFRAME SHAPE: ',df.shape)\nprint(df.labels.value_counts())","2233f508":"#show countplot\nplt.style.use('ggplot')\nplt.figure(figsize=(10,5))\nsns.countplot(df.labels);","f5094304":"#function to load images and convert them to array\ndef read_img(path, target_size):\n    img = image.load_img(path, target_size=target_size)\n    img = image.img_to_array(img) \/255.\n    return img","d9015c3e":"#show sample image from normal_class\n\nfig, ax = plt.subplots(1,6,figsize=(14,3));\nplt.suptitle('XRAY IMAGES FROM NORMAL CLASS')\n\nfor i,path in enumerate(normal_df.filepaths[:6].values):\n    ax[i].imshow(read_img(path, (255,255)))\n","b26c6039":"#show sample image from pneumonia_class\n\nfig, ax = plt.subplots(1,6,figsize=(14,3));\nplt.suptitle('XRAY IMAGES FROM PNEUMONIA CLASS')\n\nfor i,path in enumerate(pneumonia_df.filepaths[:6].values):\n    ax[i].imshow(read_img(path, (255,255)))\n","3548847b":"#create a imagegenerator\ndatagen = ImageDataGenerator(\n    shear_range=0.2,\n    zoom_range=0.2\n)\n\n#load a sample image\nsample_image = (read_img(normal_df.filepaths[0], (255,255)))\n\nplt.figure(figsize=(10,10))\nplt.suptitle('SAMPLE AUGMENTATION', fontsize=25)\n\ni = 0\n\n#generate and show\nfor batch in datagen.flow(tf.expand_dims(sample_image,0), batch_size=32):\n    plt.subplot(3,3, i+1)\n    plt.grid(False)\n    plt.imshow(tf.squeeze(batch, 0));\n    \n    if i == 8:\n        break\n    i = i+1\nplt.show();","dcffb5a1":"augmented_img = []\n\n#function for augmentation\ndef augment(path):\n    #load images then transform\n    img = tf.image.decode_jpeg(tf.io.read_file(path), channels=3)\n    img = tf.cast(img, tf.float32)\n    img = img \/ 255.\n    img = tf.image.resize(img, (150,150))\n    i=0\n    for batch in datagen.flow(tf.expand_dims(img, 0), batch_size=32):\n        augmented_img.append(tf.squeeze(batch, 0))\n        \n        if i == 2:\n            break\n        i = i+1\n\n#apply the augmentation function\nnormal_df['filepaths'].apply(augment)","bc25f07c":"#convert the generated images as tensors\nnormal_tensor =  tf.convert_to_tensor(augmented_img)\nnormal_tensor.shape","6f88f80e":"#same function but without augmentation\npneumonia_tensor = []\nIMAGE_SIZE = 150\ndef map_fn(path):\n    img = tf.image.decode_jpeg(tf.io.read_file(path), channels=3)\n    img = tf.cast(img, tf.float32)\n    img = img \/ 255.\n    img = tf.image.resize(img, (IMAGE_SIZE,IMAGE_SIZE))\n    pneumonia_tensor.append(img)\npneumonia_df.filepaths.apply(map_fn)","aaa88cb7":"#convert to tensor\npneumonia_tensor = tf.convert_to_tensor(pneumonia_tensor)\npneumonia_tensor.shape","c7d6d6b7":"#generate labels\nnormal_labels = tf.zeros(len(normal_tensor), dtype = np.int64)\npneumonia_labels = tf.ones(len(pneumonia_tensor), dtype=np.int64)","1358fd80":"tensor_dataset = tf.data.Dataset.from_tensor_slices( (tf.concat([normal_tensor, pneumonia_tensor], axis=0),\n                                                      tf.concat([normal_labels, pneumonia_labels], axis=0)))","a3ee872f":"# TRAIN_SIZE = int(len(tensor_dataset) *0.7)\n#BUFFER_SIZE = 101\n#tensor_dataset = tensor_dataset.shuffle(BUFFER_SIZE)\n# train_data = tensor_dataset.take(TRAIN_SIZE)\n# test_data = tensor_dataset.skip(TRAIN_SIZE)\n\ndef is_test(x, y):\n    return x % 4 == 0\n\ndef is_train(x, y):\n    return not is_test(x, y)\n\nrecover = lambda x,y: y\n\ntest_dataset = tensor_dataset.enumerate() \\\n                    .filter(is_test) \\\n                    .map(recover)\n\ntrain_dataset = tensor_dataset.enumerate() \\\n                    .filter(is_train) \\\n                    .map(recover)","524dd484":"#just storing the labels for future use\ntrain_labels = []\nfor i,l in train_dataset.take(-1):\n    train_labels.append(l)\n    \ntest_labels = []\nfor i,l in test_dataset.take(-1):\n    test_labels.append(l)","a951c294":"#value counts on datasets\nprint('TRAIN DATA VALUE COUNTS: ',np.bincount(np.array(test_labels)))\nprint('TRAIN DATA VALUE COUNTS: ',np.bincount(np.array(train_labels)))","bb1b7788":"#Looks good! the data is balanced now","050652e7":"#you can try 16, but it will slow down the training\nBATCH_SIZE = 32\n\n#shuffle the train data\ntrain_data = train_dataset.shuffle(10000).batch(BATCH_SIZE)\ntest_data = test_dataset.batch(BATCH_SIZE)","6a4a50af":"#check the labels per batch if they are truly shuffled, haha i have trust issues though\nfor i,l in train_data.take(20):\n    print(l)","2ab62ac8":"#check the shape per batch\nfor i,l in train_data.take(1):\n    print(i.shape)","60c118fe":"#define the input shape\nINPUT_SHAPE = (150,150,3)\n\n#i'll use mobilenetv2 and you try anything you want.\nbase_model = tf.keras.applications.MobileNetV2(input_shape=INPUT_SHAPE,\n                                            include_top=False,\n                                            weights='imagenet')\n\n#freeze the weights of convolutional layer\nbase_model.trainable = False\nbase_model.summary()","68760880":"#check the output shape of convolutional layer\nfor i, l in train_data.take(1):\n    print(base_model(i).shape)","cd53705c":"model = Sequential()\nmodel.add(base_model)\n#you can try Flatten instead of GlobalAveragePooling\nmodel.add(Layers.GlobalAveragePooling2D())\nmodel.add(Layers.Dense(128, activation='relu'))\nmodel.add(Layers.Dropout(0.2))\nmodel.add(Layers.Dense(1, activation = 'sigmoid'))\nmodel.summary()","a01e59a9":"#set a callback\ncallbacks = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n\n#compile the model\nmodel.compile(loss = 'binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","46f339e1":"#Throw the data\nhistory = model.fit(train_data, epochs=4, validation_data= test_data, callbacks=[callbacks])","0a867eed":"#Owww Bingo!","c97ae63d":"#show model training accuracy and loss\nfig, ax = plt.subplots(1,2, figsize=(14,5))\nax[0].set_title('MODEL ACCURACY')\nax[1].set_title('MODEL TRANING LOSS')\nax[0].plot(history.history['accuracy'], color= 'steelblue', lw=2);\nax[1].plot(history.history['loss'], color='salmon');","11dc7dc3":"#get the predictions\npredictions = model.predict_classes(test_data)","8d4ea225":"#print a classification report\nfrom sklearn.metrics import classification_report, confusion_matrix\nprint(classification_report(test_labels, predictions))","7daa14a2":"#here is our favorite, the confusion matrix!\nconf_mat = confusion_matrix(np.array(test_labels), predictions)\nplt.figure(figsize=(8,8))\nplt.title('CONFUSION MATRIX')\nsns.heatmap(conf_mat, annot=True, \n            yticklabels=['Normal', 'PNEUMONIA'],\n            xticklabels=['Normal', 'PNEUMONIA'],\n            square=True, cmap='magma');","02e55e7c":"for img, label in test_data.take(1):\n    sample_img = img[1]\n    img_true_label = label[1]","b22317db":"pred = np.array(model.predict_classes(tf.expand_dims(sample_img, 0))).flatten()[0]\nplt.title(CATEGORIES[pred])\nplt.imshow(sample_img);","0e312786":"#show image true label\nprint('IMAGE TRUE LABEL: ', CATEGORIES[img_true_label])","bd5ed64c":"### ADD A DENSE LAYER FOR IMAGE CLASSIFICATION","2a89cfb6":"### LOAD NECESSARY LIBRARIES","4fead057":"#### LOAD THE XRAY IMAGES WITH PNEUMONIA","f8bca03b":"#### NOW AUGMENT ALL THE IMAGES IN THE NORMAL CLASS","6a4caf81":"### CREATE A TENSOR DATASET","70f4f52e":"### SPLIT THE DATA","c094646d":"### BATCH THE IMAGES","405780dd":"### TRANSFER LEARNING","889efbba":"* As you can see from the plot above, the data is imbalanced,\n* We can balance the data by augmenting the images from normal class.","5c2f0de6":"### DATA UTILITIES","9479a510":"### MODEL TESTING","0e3f6943":"### IMAGE AUGMENTATION"}}