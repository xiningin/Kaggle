{"cell_type":{"3238a985":"code","a0e3ac56":"code","5036a06e":"code","9951d64a":"code","10aa3c08":"code","83a2e793":"code","b52c005d":"code","858bbe7a":"code","c1546b42":"code","b9ce783c":"code","61452e57":"code","2b56a01d":"code","ae2e4017":"code","1ac3581e":"code","13550802":"code","929bed8a":"code","9cd3a2f4":"code","e3ee4835":"code","cd8a7196":"code","fa79df9c":"code","e6098833":"code","5de7a58d":"code","4b6895c2":"code","bfff0094":"code","44ce6dcd":"code","474f67c5":"code","26fe2ea8":"code","ece2ecb5":"code","798c5dfd":"code","a9a82f47":"code","65856656":"code","703b7bf1":"code","e5485184":"code","8fdf988c":"code","3001fbb6":"code","95e56b1d":"code","8991b062":"code","69282749":"code","8cc82ab6":"code","18a790e3":"code","e3b2ffa1":"code","597e4586":"code","537385f7":"code","e708dc1c":"code","56969c73":"code","66042e10":"code","e340b52d":"code","2811dca7":"code","c135adbc":"code","e930ec84":"code","810ac2e1":"code","e796fc7c":"code","60691812":"markdown","1d0cd254":"markdown","db8a9c99":"markdown","53ccd527":"markdown","6792eed6":"markdown","6e6f84b2":"markdown","fbde08c5":"markdown"},"source":{"3238a985":"#!conda update -c pytorch -c fastai fastai","a0e3ac56":"import fastai\nimport fastai.utils.collect_env\nfastai.utils.collect_env.show_install(1)","5036a06e":"%matplotlib inline\nfrom fastai import *\nfrom fastai.vision import *","9951d64a":"path = untar_data(URLs.MNIST)","10aa3c08":"path.ls()","83a2e793":"il = ImageItemList.from_folder(path, convert_mode='L')","b52c005d":"il.items[0]","858bbe7a":"defaults.cmap='binary'","c1546b42":"il","b9ce783c":"il[0].show()","61452e57":"sd = il.split_by_folder(train='training', valid='testing')","2b56a01d":"sd","ae2e4017":"(path\/'training').ls()","1ac3581e":"ll = sd.label_from_folder()","13550802":"ll","929bed8a":"x,y = ll.train[0]","9cd3a2f4":"x.show()\nprint(y,x.shape)","e3ee4835":"tfms = ([*rand_pad(padding=3, size=28, mode='zeros')], [])","cd8a7196":"ll = ll.transform(tfms)","fa79df9c":"bs = 128","e6098833":"# not using imagenet_stats because not using pretrained model\ndata = ll.databunch(bs=bs).normalize()","5de7a58d":"x,y = data.train_ds[0]","4b6895c2":"x.show()\nprint(y)","bfff0094":"def _plot(i,j,ax): data.train_ds[0][0].show(ax, cmap='gray')\nplot_multi(_plot, 3, 3, figsize=(8,8))","44ce6dcd":"xb,yb = data.one_batch()\nxb.shape,yb.shape","474f67c5":"data.show_batch(rows=3, figsize=(5,5))","26fe2ea8":"def conv(ni,nf): return nn.Conv2d(ni, nf, kernel_size=3, stride=2, padding=1)","ece2ecb5":"model = nn.Sequential(\n    conv(1, 8), # 14\n    nn.BatchNorm2d(8),\n    nn.ReLU(),\n    conv(8, 16), # 7\n    nn.BatchNorm2d(16),\n    nn.ReLU(),\n    conv(16, 32), # 4\n    nn.BatchNorm2d(32),\n    nn.ReLU(),\n    conv(32, 16), # 2\n    nn.BatchNorm2d(16),\n    nn.ReLU(),\n    conv(16, 10), # 1\n    nn.BatchNorm2d(10),\n    Flatten()     # remove (1,1) grid\n)","798c5dfd":"learn = Learner(data, model, loss_func = nn.CrossEntropyLoss(), metrics=accuracy)","a9a82f47":"learn.summary()","65856656":"xb = xb.cuda()","703b7bf1":"model(xb).shape","e5485184":"learn.lr_find(end_lr=100)","8fdf988c":"learn.recorder.plot()","3001fbb6":"learn.fit_one_cycle(3, max_lr=0.1)","95e56b1d":"def conv2(ni,nf): return conv_layer(ni,nf,stride=2)","8991b062":"model = nn.Sequential(\n    conv2(1, 8),   # 14\n    conv2(8, 16),  # 7\n    conv2(16, 32), # 4\n    conv2(32, 16), # 2\n    conv2(16, 10), # 1\n    Flatten()      # remove (1,1) grid\n)","69282749":"learn = Learner(data, model, loss_func = nn.CrossEntropyLoss(), metrics=accuracy)","8cc82ab6":"learn.fit_one_cycle(10, max_lr=0.1)","18a790e3":"from fastai.layers import *","e3b2ffa1":"class ResBlock(nn.Module):\n    def __init__(self, nf):\n        super().__init__()\n        self.conv1 = conv_layer(nf,nf)\n        self.conv2 = conv_layer(nf,nf)\n        \n    def forward(self, x): return x + self.conv2(self.conv1(x))","597e4586":"help(res_block)","537385f7":"class SequentialEx(nn.Module):\n    \"Like `nn.Sequential`, but with ModuleList semantics, and can access module input\"\n    def __init__(self, *layers):\n        super().__init__()\n        self.layers = nn.ModuleList(layers)\n\n    def forward(self, x):\n        res = x\n        for l in self.layers:\n            res.orig = x\n            nres = l(res)\n            # We have to remove res.orig to avoid hanging refs and therefore memory leaks\n            res.orig = None\n            res = nres\n        return res\n\n    def __getitem__(self,i): return self.layers[i]\n    def append(self,l): return self.layers.append(l)\n    def extend(self,l): return self.layers.extend(l)\n    def insert(self,i,l): return self.layers.insert(i,l)","e708dc1c":"class MergeLayer(nn.Module):\n    \"Merge a shortcut with the result of the module by adding them or concatenating thme if `dense=True`.\"\n    def __init__(self, dense:bool=False):\n        super().__init__()\n        self.dense=dense\n\n    def forward(self, x): return torch.cat([x,x.orig], dim=1) if self.dense else (x+x.orig)","56969c73":"def res_block(nf, dense:bool=False, norm_type:Optional[NormType]=NormType.Batch, bottle:bool=False, **kwargs):\n    \"Resnet block of `nf` features.\"\n    norm2 = norm_type\n    if not dense and (norm_type==NormType.Batch): norm2 = NormType.BatchZero\n    nf_inner = nf\/\/2 if bottle else nf\n    return SequentialEx(conv_layer(nf, nf_inner, norm_type=norm_type, **kwargs),\n                      conv_layer(nf_inner, nf, norm_type=norm2, **kwargs),\n                      MergeLayer(dense))","66042e10":"model = nn.Sequential(\n    conv2(1, 8),\n    res_block(8),\n    conv2(8, 16),\n    res_block(16),\n    conv2(16, 32),\n    res_block(32),\n    conv2(32, 16),\n    res_block(16),\n    conv2(16, 10),\n    Flatten()\n)","e340b52d":"def conv_and_res(ni,nf): return nn.Sequential(conv2(ni, nf), res_block(nf))","2811dca7":"model = nn.Sequential(\n    conv_and_res(1, 8),\n    conv_and_res(8, 16),\n    conv_and_res(16, 32),\n    conv_and_res(32, 16),\n    conv2(16, 10),\n    Flatten()\n)","c135adbc":"learn = Learner(data, model, loss_func = nn.CrossEntropyLoss(), metrics=accuracy)","e930ec84":"learn.lr_find(end_lr=100)\nlearn.recorder.plot()","810ac2e1":"learn.fit_one_cycle(12, max_lr=0.05)","e796fc7c":"learn.summary()","60691812":"## MNIST CNN","1d0cd254":"[Lesson Video Link](https:\/\/course.fast.ai\/videos\/?lesson=7)\n\n[Lesson resources and updates](https:\/\/forums.fast.ai\/t\/lesson-7-official-resources\/32553)\n\n[Lesson chat](https:\/\/forums.fast.ai\/t\/lesson-7-in-class-chat\/32554\/118)\n\n[Further discussion thread](https:\/\/forums.fast.ai\/t\/lesson-7-further-discussion\/32555)\n\nNote: This is a mirror of the FastAI Lesson 7 Nb. \nPlease thank the amazing team behind fast.ai for creating these, I've merely created a mirror of the same here\nFor complete info on the course, visit course.fast.ai","db8a9c99":"### Resnet-ish","53ccd527":"### Basic CNN with batchnorm","6792eed6":"## fin","6e6f84b2":"### Data","fbde08c5":"### Refactor"}}