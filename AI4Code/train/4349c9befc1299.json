{"cell_type":{"231aefac":"code","5074fd98":"code","fd0d740d":"code","3f75226a":"code","be2e9d21":"code","e5238b67":"code","ce5b4c6b":"code","479cb240":"code","86302a36":"code","6c6a4ee4":"code","203dc68c":"code","6a89b4cf":"code","4eee6c03":"code","fe4cde9a":"code","785d2317":"code","60972eca":"code","3d144231":"code","b0a9d666":"code","242a6056":"code","a9aaff5c":"markdown","646dd6cc":"markdown","1f10ce0a":"markdown","0f568d2d":"markdown","c3668ca7":"markdown","b8603f07":"markdown","e89a91ec":"markdown","65d12697":"markdown","b62f04ff":"markdown","3f68948e":"markdown"},"source":{"231aefac":"import pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\ndf = pd.read_csv('..\/input\/BreadBasket_DMS.csv')","5074fd98":"df['Item']=df['Item'].str.lower()","fd0d740d":"x=df['Item']== 'none'\nprint(x.value_counts())","3f75226a":"df=df.drop(df[df.Item == 'none'].index)","be2e9d21":"len(df['Item'].unique())","e5238b67":"df_for_top10_Items=df['Item'].value_counts().head(10)\nItem_array= np.arange(len(df_for_top10_Items))","ce5b4c6b":"import matplotlib.pyplot as plt\nplt.figure(figsize=(15,5))\nItems_name=['coffee','bread','tea','cake','pastry','sandwich','medialuna','hot chocolate','cookies','brownie']\nplt.bar(Item_array,df_for_top10_Items.iloc[:])\nplt.xticks(Item_array,Items_name)\nplt.title('Top 5 most selling items')\nplt.show()","479cb240":"df['Date'] = pd.to_datetime(df['Date'])\ndf['Time'] = pd.to_datetime(df['Time'],format= '%H:%M:%S' ).dt.hour\ndf['day_of_week'] = df['Date'].dt.weekday\nd=df.loc[:,'Date']","86302a36":"weekday_names=[ 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\nWeekday_number=[0,1,2,3,4,5,6]\nweek_df = d.groupby(d.dt.weekday).count().reindex(Weekday_number)\nItem_array_week= np.arange(len(week_df))\n","6c6a4ee4":"plt.figure(figsize=(15,5))\nmy_colors = 'rk'\nplt.bar(Item_array_week,week_df, color=my_colors)\nplt.xticks(Item_array_week,weekday_names)\nplt.title('Number of Transactions made based on Weekdays')\nplt.show()","203dc68c":"dt=df.loc[:,'Time']\nHour_names=[ 7, 8, 9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]\ntime_df=dt.groupby(dt).count().reindex(Hour_names)\nItem_array_hour= np.arange(len(time_df))","6a89b4cf":"plt.figure(figsize=(15,5))\nmy_colors = 'rb'\nplt.bar(Item_array_hour,time_df, color=my_colors)\nplt.xticks(Item_array_hour,Hour_names)\nplt.title('Number of Transactions made based on Hours')\nplt.show()","4eee6c03":"from mlxtend.frequent_patterns import apriori\nfrom mlxtend.frequent_patterns import association_rules","fe4cde9a":"hot_encoded_df=df.groupby(['Transaction','Item'])['Item'].count().unstack().reset_index().fillna(0).set_index('Transaction')","785d2317":"def encode_units(x):\n    if x <= 0:\n        return 0\n    if x >= 1:\n        return 1\nhot_encoded_df = hot_encoded_df.applymap(encode_units)\n","60972eca":"frequent_itemsets = apriori(hot_encoded_df, min_support=0.01, use_colnames=True)","3d144231":"rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\nrules.head(10)","b0a9d666":"rules[ (rules['lift'] >= 1) &\n       (rules['confidence'] >= 0.5) ]","242a6056":"support=rules.as_matrix(columns=['support'])\nconfidence=rules.as_matrix(columns=['confidence'])\nimport seaborn as sns\n \nfor i in range (len(support)):\n    support[i] = support[i] \n    confidence[i] = confidence[i] \n     \nplt.title('Association Rules')\nplt.xlabel('support')\nplt.ylabel('confidence')    \nsns.regplot(x=support, y=confidence, fit_reg=False)\n ","a9aaff5c":"Above line of code is transfrom data to make items as columns and each transaction as a row and count same Items bought in one transaction but fill other cloumns of the row with 0 to represent item which are not bought.","646dd6cc":"This graph gives us clear insight that people shop\/make transactions more towards the weekends.Now lets see in which hours of a day people make more transactions.","1f10ce0a":"We only want to see the rules where confidence is greater than or equal to 50% so:","0f568d2d":"Now, we need to run apriori algorithm to get insight that if a customer buys one item which item he\/she buys next .","c3668ca7":"Wow! Didn't thought the amount of coffee sold is this much over other stuff\n\n![Coffee](https:\/\/media.giphy.com\/media\/h5LHSr2Sgd4xq\/giphy.gif)","b8603f07":"Using Datetime i created a new column called \"day_of_week\" which can give us insights on which weekday has more transactions","e89a91ec":"For instance from the last rule we can see that toast and coffee are commonly bought together. This makes sense since people who purchase toast would like to have coffee with it. i.e some people buy baggle\/toast\/cookie\/scone and coffee togather\n\nThe support value for the this rule is 0.023666. This number is calculated by dividing the number of transactions containing toast divided by total number of transactions. The confidence level for the rule is 0.704403 which shows that out of all the transactions that contain toast , 70.44% of the transactions also contain coffee. Finally, the lift of 1.47 tells us that coffee is 1.47 times more likely to be bought by the customers who buy toast compared to the default likelihood of the sale of coffee.","65d12697":"There are 94 different unique items sold by bakery or simply only these items are present in the Items column.","b62f04ff":"This means that there rows where transaction is made but item is \"none\" and number of such rows are 786. which will be removed to take in consideration only those rows where transaction is made with an item.","3f68948e":"Support is an indication of how frequently the itemset appears in the dataset.\n\nConfidence is an indication of how often the rule has been found to be true."}}