{"cell_type":{"e2b75048":"code","8ad16280":"code","c092e82a":"code","29c4f4dd":"code","df5ff858":"code","f2d21b11":"code","3f21cf11":"code","0d7fe908":"code","8c5593f3":"code","35d01ed0":"code","0d30239b":"code","22c3658b":"code","c8df1dfc":"code","07871cbf":"code","4f1a864b":"code","2e3d2dd7":"code","3679caf2":"code","3ccefeb1":"code","5b6bf187":"code","e6c66a23":"code","9bcf1ad2":"code","80b59cd3":"code","8827c2ce":"code","f0608083":"code","ff038c43":"code","f892888a":"code","6cb2362f":"code","a2639188":"code","b44bfdaa":"code","401d597f":"code","37d7ad7e":"code","efa837a4":"code","6be397b4":"code","4ffee2f1":"code","744d0c58":"code","ccc0594c":"code","d0983412":"code","560d62d7":"code","1ee622db":"code","e2f41924":"code","b67a3004":"code","4bc1e86b":"code","793ca1d9":"code","c67baf9c":"code","cfbe02be":"code","0652907e":"code","22f15740":"code","fb873608":"code","d6875603":"code","3a4868a8":"code","e4585db1":"code","87a43987":"code","0b767269":"code","4c343535":"code","d5cbc57f":"code","33bd46a6":"code","92e7b8a0":"code","310fb825":"code","0a1ae3c0":"code","a4684c7a":"code","97f9fd3a":"code","cc4c0a1b":"code","b4541051":"code","ed991886":"code","9aef4fd5":"code","03b91b79":"code","83451db5":"code","ed513b0b":"code","f903392b":"code","1b2c58d3":"markdown","c4a34c6f":"markdown","dcd53f18":"markdown","4a7b3ada":"markdown","5608e7b4":"markdown","bc997d01":"markdown","ef1c169c":"markdown","70769905":"markdown","b1956c9e":"markdown","8b96d79c":"markdown","6e784ee5":"markdown","7cfaa0cd":"markdown","8ce36b29":"markdown","3525a02e":"markdown","230d6c2e":"markdown","f96c75fc":"markdown","4b48f608":"markdown","69b1cb3e":"markdown","6672602e":"markdown","48c9de59":"markdown"},"source":{"e2b75048":"from __future__ import print_function\nimport lime\nimport lime.lime_tabular\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom time import time\nfrom collections import Counter\nfrom sklearn.inspection import permutation_importance \nimport sklearn.datasets\nimport sklearn.ensemble\n\n\n## Libraries for various models like Decision Tree,SVM,KNN,MLP,LR,RF and HRFLM\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import model_selection\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\n\n## Libraries for Upsampling and splitting of dataset into train and test\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE\n\n## Libraries for Checking various model performances like Confusion Matrix,Accuracy_Score etc\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score","8ad16280":"######################## Data Selection ###################################\n# Reading the data from csv\ndata = pd.read_csv(\"..\/input\/framingham-dataset\/framingham.csv\")","c092e82a":"# Check First 5 rows of dataset\ndata.head()","29c4f4dd":"# Check the data shape by rows vs columns\ndata.shape","df5ff858":"## Checking data types of all the Parameters\ndata.info()","f2d21b11":"data.describe()","3f21cf11":"## Data quality verification step-1\ndata.TenYearCHD.unique()","0d7fe908":"## Data quality verification step-2\ndata.TenYearCHD.value_counts()","8c5593f3":"############################## Data preparation ######################################","35d01ed0":"# Deleting the ID column\ndel data['ID']","0d30239b":"# Displaying all the rows with Null values\n\ndata.isna().sum()\nnull = data[data.isna().any(axis=1)]\nnull","22c3658b":"## Checking for total number of null values in each variable\ndata.isna().sum()","c8df1dfc":"# Deleting the rows with nulls in education\ndata = data.dropna(axis=0, subset=['education'])","07871cbf":"# check for dupicate values in dataset\nduplicate_data = data[data.duplicated()]\nduplicate_data","4f1a864b":"############################### Data Cleansing #######################################\n\n# Check for Missing values after deletion of education\ndata.isna().sum()\nnull = data[data.isna().any(axis=1)]\nnull","2e3d2dd7":"## Checking for total number of null values in each variable\n\ndata.isna().sum()","3679caf2":"## From the results it is clear that \n#cigsPerDay has 27 null values,\n#BPMeds has 53 null values,\n#totChol has 49 null values,\n#BMI has 18 null values,\n#glucose has 380 null values\n#heartRate has 1 null value.","3ccefeb1":"## Check mean of the data \nprint(\"Mean of each variable:\\n \",data.mean())\n\n## Check median of the data \nprint(\"\\n Median of each variable:\\n \",data.median())\n\n## Check mode of the data \nprint(\"\\n Mode of each variable:\\n \",data.mode())\n","5b6bf187":"############################### Data Manipulation ###############################\n\n## Repacing null values in data with their mean, median and mode\n\ndata['BPMeds'].fillna(data.BPMeds.median(), inplace=True)\ndata['cigsPerDay'].fillna(data.cigsPerDay.median(), inplace=True)\ndata['totChol'].fillna(data.totChol.mean(), inplace=True)\ndata['heartRate'].fillna(data.heartRate.median(), inplace=True)\ndata['BMI'].fillna(data.BMI.mean(), inplace=True)\ndata['glucose'].fillna(data.glucose.mean(), inplace=True)","e6c66a23":"## Checking for total number of null values in each variable after data manipulation\ndata.isna().sum()","9bcf1ad2":"## Checking the shape of the dataset before performing dummy encoding\ndata.shape","80b59cd3":"## Dummy Encoding education Variable\ndata = pd.get_dummies(data,columns=['education']) ","8827c2ce":"## Checking the newly added columns of the dataset after performing dummy encoding\nfor col in data.columns: \n    print(col)","f0608083":"## Checking the shape of the dataset after performing dummy encoding\ndata.shape","ff038c43":"## Checking for duplicate values of dataset\nduplicate_data = data[data.duplicated()]\nduplicate_data","f892888a":"## Checking the correlation between output and input fields through a heatmap by the help of correlation function\ncorrelation = data.corr()\nplt.figure(figsize=(14,14))\ng = sns.heatmap(correlation, vmax=1, square=True,cmap='coolwarm',annot= True,xticklabels=True,yticklabels=True, fmt='.1g')\ng.set_yticklabels(g.get_yticklabels(), rotation =0)\ng.set_xticklabels(g.get_yticklabels(), rotation =90)\nplt.title('Correlation between different fearures')","6cb2362f":"## Checking Glucose Outliers with the help of boxplot by putting the Glucose greater than 300,considering as outlier\nsns.boxplot(data.glucose,color='green')\nOutlier_sysBP = data[(data['glucose'] > 300)] \nOutlier_sysBP","a2639188":"## Dropping of Glucose outliers with the help of drop function\ndata = data.drop(data[data.glucose > 300].index)\nsns.boxplot(data.glucose,color='green')","b44bfdaa":"## Checking Systolic BP other Outliers with the help of boxplot by putting the systolic BP greater than 220,considering as outlier\nsns.boxplot(data.sysBP,color='red')\nOutlier_sysBP = data[(data['sysBP'] > 250)] \nOutlier_sysBP","401d597f":"## Dropping of Systolic BP outliers with the help of drop function\ndata = data.drop(data[data.sysBP > 250].index)\nsns.boxplot(data.sysBP,color='red')","37d7ad7e":"## Checking total cholestrol other Outliers with the help of boxplot by putting the total cholestrol greater than 500,considering as outlier\nsns.boxplot(data.totChol,color='yellow')\nOutlier_totChol = data[(data['totChol'] > 500)] ","efa837a4":"## Dropping of total cholestrol outliers with the help of drop function\ndata = data.drop(data[data.totChol > 500].index)\nsns.boxplot(data.totChol,color='yellow')","6be397b4":"## Checking BMI other Outliers with the help of boxplot by putting the BMI greater than 50,considering as outlier\nsns.boxplot(data.BMI,color='blue')\nOutlier_BMI = data[(data['BMI'] > 50)] \nOutlier_BMI.head()","4ffee2f1":"## Dropping of BMI outliers with the help of drop function\ndata = data.drop(data[data.BMI > 50].index)\nsns.boxplot(data.BMI,color='blue')","744d0c58":"## Checking Systolic BP other Outliers with the help of boxplot by putting the systolic BP greater than 220,considering as outlier\nsns.boxplot(data.diaBP,color='red')\nOutlier_diaBP = data[(data['diaBP'] > 150)] \nOutlier_diaBP","ccc0594c":"## Defining the Independant and Dependant variable\n\ny = data['TenYearCHD']\nx = data.drop(['TenYearCHD'], axis = 1)","d0983412":"## Divide framingham dataset into train and test set as 75% and 25 % ratio respectively by using split function\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25,random_state=27)\nprint (x_train.shape, y_train.shape)\nprint (x_test.shape, y_test.shape)","560d62d7":"## Upsampling the Training set\n\nsm = SMOTE(random_state=23, sampling_strategy='minority')\nx_train_sm, y_train_sm = sm.fit_resample(x_train, y_train)\nprint(len(x_train_sm), len(y_train_sm))","1ee622db":"## Printing the shapes of training set after Upsampling\nprint(x_train_sm.shape)\nprint(y_train_sm.shape)","e2f41924":"## Distinguishing the count of classes of label TenYearCHD in training set\nprint(Counter(y_train_sm))","b67a3004":"## Upsampling the Testing set\nsm_test = SMOTE(random_state=23, sampling_strategy='minority')\nx_test_sm, y_test_sm = sm_test.fit_resample(x_test, y_test)\nprint(len(x_test_sm), len(y_test_sm))","4bc1e86b":"## Printing the shapes of testing set after Upsampling\nprint(x_test_sm.shape)\nprint(y_test_sm.shape)","793ca1d9":"## Distinguishing the count of classes of label TenYearCHD in testing set\nprint(Counter(y_test_sm))","c67baf9c":"############# Support Vector Machines #############\nSVM_classifier = SVC(random_state = 0,probability=True)\n\nresults = {}\n#Training the model \nstart = time()\nSVM_classifier.fit(x_train_sm, y_train_sm)\nend = time()\nresults['training_time'] = end - start\n\n#Testing the model \nstart = time()\nSVM_Prediction = SVM_classifier.predict(x_test_sm)\nend = time()\nresults['testing_time'] = end - start\n\nprint(\"MODELLING TIMES(ms) OF SVM ARE:\")\nprint(\"********************************************\")\nprint(\"Training time: \"+\"{:.2f}\".format(results['training_time']))\nprint(\"Testing time: \"+\"{:.2f}\".format(results['testing_time']))\nprint(\"********************************************\\n\")\n\n## Accuracy Score\nSVM_Accuracy = accuracy_score(y_test_sm, SVM_Prediction)\nprint(\"The accuracy score for SVM in percentage is as follows: \"+\"{:.2f}\".format(SVM_Accuracy*100))\n\n## Precision\nSVM_Precision = precision_score(y_test_sm, SVM_Prediction)\nprint(\"The precision score for SVM is as follows: \"+\"{:.2f}\".format(SVM_Precision))\n\n## Recall Feature\nSVM_Recall = recall_score(y_test_sm, SVM_Prediction)\nprint(\"The recall score for SVM is as follows: \"+\"{:.2f}\".format(SVM_Recall))\n\n## F1 Score\nSVM_F1Score = f1_score(y_test_sm, SVM_Prediction)\nprint(\"The F1 Score for SVM is as follows: \"+\"{:.2f}\".format(SVM_F1Score))\n\n## Confusion Matrix \nSVM_Confusion_Matrix=confusion_matrix(y_test_sm,SVM_Prediction)\nprint(\"Confusion_Matrix: \\n\\n\",SVM_Confusion_Matrix, \"\\n\" )\n\n## Classification Report\ntarget_names =['class 0', 'class 1']\nprint(classification_report(y_test_sm,SVM_Prediction,zero_division=1,target_names=target_names))\n\n## Cross Validation\nSVM_accuracies = cross_val_score(estimator = SVM_classifier, X= x_train_sm, y = y_train_sm, cv = 10)\nprint(\"Cross Validation Accuracy: {:.2f} %\".format(SVM_accuracies.mean()*100))\nprint(\"Cross Validation Standard Deviation: {:.2f} %\".format(SVM_accuracies.std()*100))","cfbe02be":"## Plotting the ROC Curve\nSVM_pred_proba = SVM_classifier.predict_proba(x_test_sm)[:,1]\nfpr_SVM, tpr_SVM, thresholds_SVM = roc_curve(y_test_sm, SVM_pred_proba)\n\nplt.figure(figsize=(10,10))\nplt.plot(fpr_SVM, tpr_SVM, marker='.', label='SVM')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('SVM ROC Curve')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","0652907e":"## Calculating AUC score of SVM from the roc curve\nSVM_AUC_Score = roc_auc_score(y_test_sm, SVM_pred_proba)\nSVM_AUC_Score","22f15740":"############# Decission Tree ############# \n\nDT_classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n\nresults = {}\n#Training the model \nstart = time()\nDT_classifier.fit(x_train_sm, y_train_sm)\nend = time()\nresults['training_time'] = end - start\n\n#Testing the model \nstart = time()\nDT_Prediction = DT_classifier.predict(x_test_sm)\nend = time()\nresults['testing_time'] = end - start\n\nprint(\"MODELLING TIMES(ms) OF DECISSION TREE ARE:\")\nprint(\"********************************************\")\nprint(\"Training time: \"+\"{:.2f}\".format(results['training_time']))\nprint(\"Testing time: \"+\"{:.2f}\".format(results['testing_time']))\nprint(\"********************************************\\n\")\n\n## Accuracy Score\nDT_Accuracy = accuracy_score(y_test_sm, DT_Prediction)\nprint(\"The accuracy score for Decission tree in percentage is: \"+\"{:.2f}\".format(DT_Accuracy*100))\n\n## Precision\nDT_Precision = precision_score(y_test_sm, DT_Prediction)\nprint(\"The precision score for Decission tree is: \"+\"{:.2f}\".format(DT_Precision))\n\n## Recall Feature\nDT_Recall = recall_score(y_test_sm, DT_Prediction)\nprint(\"The recall score for Decission tree is: \"+\"{:.2f}\".format(DT_Recall))\n\n## F1 Score\nDT_F1Score = f1_score(y_test_sm, DT_Prediction)\nprint(\"The F1 Score for Decission tree is: \"+\"{:.2f}\".format(DT_F1Score))\n\n## Confusion Matrix \nDT_Confusion_Matrix=confusion_matrix(y_test_sm,DT_Prediction)\nprint(\"Confusion_Matrix: \\n\\n\",DT_Confusion_Matrix, \"\\n\" )\n\n## Classification Report\ntarget_names =['class 0', 'class 1']\nprint(classification_report(y_test_sm,DT_Prediction,zero_division=1,target_names=target_names))\n\n## Cross Validation\nDT_accuracies = cross_val_score(estimator = DT_classifier, X = x_train_sm, y = y_train_sm, cv = 10)\nprint(\"Cross Validation Accuracy: {:.2f} %\".format(DT_accuracies.mean()*100))\nprint(\"Cross Validation Standard Deviation: {:.2f} %\".format(DT_accuracies.std()*100))","fb873608":"## Plotting the ROC Curve\nDT_pred_proba = DT_classifier.predict_proba(x_test_sm)[:,1]\nfpr_DT, tpr_DT, thresholds_DT = roc_curve(y_test_sm, DT_pred_proba)\n\nplt.figure(figsize=(10,10))\nplt.plot(fpr_DT, tpr_DT, marker='.', label='Decision Tree')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Decision Tree ROC Curve')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","d6875603":"## Calculating AUC score of Decision Tree from the roc curve\nDT_AUC_Score = roc_auc_score(y_test_sm, DT_pred_proba)\nDT_AUC_Score","3a4868a8":"#############  K-Nearest Neighbour  #############\nKNN_classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n\nresults = {}\n#Training the model \nstart = time()\nKNN_classifier.fit(x_train_sm, y_train_sm)\nend = time()\nresults['training_time'] = end - start\n\n#Testing the model \nstart = time()\nKNN_Prediction = KNN_classifier.predict(x_test_sm)\nend = time()\nresults['testing_time'] = end - start\n\nprint(\"MODELLING TIMES(ms) OF KNN ARE:\")\nprint(\"********************************************\")\nprint(\"Training time: \"+\"{:.2f}\".format(results['training_time']))\nprint(\"Testing time: \"+\"{:.2f}\".format(results['testing_time']))\nprint(\"********************************************\\n\")\n\n## Accuracy Score\nKNN_Accuracy = accuracy_score(y_test_sm, KNN_Prediction)\nprint(\"The accuracy score for KNN in percentage is: \"+\"{:.2f}\".format(KNN_Accuracy*100))\n\n## Precision\nKNN_Precision = precision_score(y_test_sm, KNN_Prediction)\nprint(\"The precision score for KNN is: \"+\"{:.2f}\".format(KNN_Precision))\n\n## Recall Feature\nKNN_Recall = recall_score(y_test_sm, KNN_Prediction)\nprint(\"The recall score for KNN is: \"+\"{:.2f}\".format(KNN_Recall))\n\n## F1 Score\nKNN_F1Score = f1_score(y_test_sm, KNN_Prediction)\nprint(\"The F1 Score for KNN is: \"+\"{:.2f}\".format(KNN_F1Score))\n\n## Confusion Matrix \nKNN_Confusion_Matrix=confusion_matrix(y_test_sm,KNN_Prediction)\nprint(\"Confusion_Matrix: \\n\\n\",KNN_Confusion_Matrix, \"\\n\" )\n\n## Classification Report\ntarget_names =['class 0', 'class 1']\nprint(classification_report(y_test_sm,KNN_Prediction,zero_division=1,target_names=target_names))\n\n## Cross Validation\nKNN_accuracies = cross_val_score(estimator = KNN_classifier, X = x_train_sm, y = y_train_sm, cv = 10)\nprint(\"Cross Validation Accuracy: {:.2f} %\".format(KNN_accuracies.mean()*100))\nprint(\"Cross Validation Standard Deviation: {:.2f} %\".format(KNN_accuracies.std()*100))","e4585db1":"## Plotting the ROC Curve\nKNN_pred_proba = KNN_classifier.predict_proba(x_test_sm)[:,1]\nfpr_KNN, tpr_KNN, thresholds_KNN = roc_curve(y_test_sm, KNN_pred_proba)\n\nplt.figure(figsize=(10,10))\nplt.plot(fpr_KNN, tpr_KNN, marker='.', label='KNN')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('KNN ROC Curve')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","87a43987":"## Calculating AUC score of KNN from the roc curve\nKNN_AUC_Score = roc_auc_score(y_test_sm, KNN_pred_proba)\nKNN_AUC_Score","0b767269":"############# Multi layer Perceptron #############\n\nMLP_classifier = MLPClassifier(hidden_layer_sizes=(8,8,8), activation= 'relu',max_iter=500, random_state=0)\n\n\nresults = {}\n#Training the model \nstart = time()\nMLP_classifier.fit(x_train_sm, y_train_sm)\nend = time()\nresults['training_time'] = end - start\n\n#Testing the model \nstart = time()\nMLP_Prediction = MLP_classifier.predict(x_test_sm)\nend = time()\nresults['testing_time'] = end - start\n\nprint(\"MODELLING TIMES(ms) OF MLP ARE:\")\nprint(\"********************************************\")\nprint(\"Training time: \"+\"{:.2f}\".format(results['training_time']))\nprint(\"Testing time: \"+\"{:.2f}\".format(results['testing_time']))\nprint(\"********************************************\\n\")\n\n## Accuracy Score\nMLP_Accuracy = accuracy_score(y_test_sm, MLP_Prediction)\nprint(\"The accuracy score for MLP in percentage is as follows:\"+\"{:.2f}\".format(MLP_Accuracy*100))\n\n## Precision\nMLP_Precision = precision_score(y_test_sm, MLP_Prediction)\nprint(\"The precision score for MLP is: \"+\"{:.2f}\".format(MLP_Precision))\n\n## Recall Feature\nMLP_Recall = recall_score(y_test_sm, MLP_Prediction)\nprint(\"The recall score for MLP is as follows:\"+\"{:.2f}\".format(MLP_Recall))\n\n## F1 Score\nMLP_F1Score = f1_score(y_test_sm, MLP_Prediction)\nprint(\"The F1 Score for MLP is: \"+\"{:.2f}\".format(MLP_F1Score))\n\n## Confusion Matrix \nMLP_Confusion_Matrix=confusion_matrix(y_test_sm,MLP_Prediction)\nprint(\"Confusion_Matrix: \\n\\n\",MLP_Confusion_Matrix, \"\\n\" )\n\n## Classification Report\ntarget_names =['class 0', 'class 1']\nprint(classification_report(y_test_sm,MLP_Prediction,zero_division=1,target_names=target_names))\n\n## Cross Validation\nMLP_accuracies = cross_val_score(estimator = MLP_classifier, X = x_train_sm, y = y_train_sm, cv = 10)\nprint(\"Cross Validation Accuracy: {:.2f} %\".format(MLP_accuracies.mean()*100))\nprint(\"Cross Validation Standard Deviation: {:.2f} %\".format(MLP_accuracies.std()*100))","4c343535":"## Plotting the ROC Curve\nMLP_pred_proba = MLP_classifier.predict_proba(x_test_sm)[:,1]\nfpr_MLP, tpr_MLP, thresholds_MLP = roc_curve(y_test_sm, MLP_pred_proba)\n\nplt.figure(figsize=(10,10))\nplt.plot(fpr_MLP, tpr_MLP, marker='.', label='MLP')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('MLP ROC Curve')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","d5cbc57f":"## Calculating AUC score of MLP from the roc curve\nMLP_AUC_Score = roc_auc_score(y_test_sm, MLP_pred_proba)\nMLP_AUC_Score","33bd46a6":"############# LOGISTIC REGRESSION #############\n\nLR_classifier = LogisticRegression(max_iter=10000,random_state = 0)\n\nresults = {}\n#Training the model \nstart = time()\nLR_classifier.fit(x_train_sm, y_train_sm)\nend = time()\nresults['training_time'] = end - start\n\n#Testing the model \nstart = time()\nLR_Prediction = LR_classifier.predict(x_test_sm)\nend = time()\nresults['testing_time'] = end - start\n\nprint(\"MODELLING TIMES(ms) OF LOGISTIC REGRESSION ARE:\")\nprint(\"********************************************\")\nprint(\"Training time: \"+\"{:.2f}\".format(results['training_time']))\nprint(\"Testing time: \"+\"{:.2f}\".format(results['testing_time']))\nprint(\"********************************************\\n\")\n\n\n## Accuracy Score\nLR_Accuracy = accuracy_score(y_test_sm, LR_Prediction)\nprint(\"The accuracy score for Logistic Regression in percentage is: \"+\"{:.2f}\".format(LR_Accuracy*100))\n\n## Precision\nLR_Precision = precision_score(y_test_sm, LR_Prediction)\nprint(\"The precision score for Logistic Regression is: \"+\"{:.2f}\".format(LR_Precision))\n\n## Recall Feature\nLR_Recall = recall_score(y_test_sm, LR_Prediction)\nprint(\"The recall score for Logistic Regression is: \"+\"{:.2f}\".format(LR_Recall))\n\n## F1 Score\nLR_F1Score = f1_score(y_test_sm, LR_Prediction)\nprint(\"The F1 Score for Logistic Regression is: \"+\"{:.2f}\".format(LR_F1Score))\n\n## Confusion Matrix \nLR_Confusion_Matrix=confusion_matrix(y_test_sm,LR_Prediction)\nprint(\"Confusion_Matrix: \\n\\n\",LR_Confusion_Matrix, \"\\n\" )\n\n## Classification Report\ntarget_names =['class 0', 'class 1']\nprint(classification_report(y_test_sm,LR_Prediction,zero_division=1,target_names=target_names))\n\n## Cross Validation\nLR_accuracies = cross_val_score(LR_classifier, X = x_train_sm, y = y_train_sm, cv = 10)\nprint(\"Cross Validation Accuracy: {:.2f} %\".format(LR_accuracies.mean()*100))\nprint(\"Cross Validation Standard Deviation: {:.2f} %\".format(LR_accuracies.std()*100))","92e7b8a0":"## Plotting the ROC Curve\nLR_pred_proba = LR_classifier.predict_proba(x_test_sm)[:,1]\nfpr_LR, tpr_LR, thresholds_LR = roc_curve(y_test_sm, LR_pred_proba)\n\nplt.figure(figsize=(10,10))\nplt.plot(fpr_LR, tpr_LR, marker='.', label='LR')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('LR ROC Curve')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","310fb825":"## Calculating AUC score of Logistic Regression from the roc curve\nLR_AUC_Score = roc_auc_score(y_test_sm, LR_pred_proba)\nLR_AUC_Score","0a1ae3c0":" #############  Random Forest Classifier ############# \nRF_classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy',random_state = 0)\n\nresults = {}\n#Training the model \nstart = time()\nRF_classifier.fit(x_train_sm, y_train_sm)\nend = time()\nresults['training_time'] = end - start\n\n#Testing the model \nstart = time()\nRF_Prediction = RF_classifier.predict(x_test_sm)\nend = time()\nresults['testing_time'] = end - start\n\nprint(\"MODELLING TIMES(ms) OF RANDOM FOREST ARE:\")\nprint(\"********************************************\")\nprint(\"Training time: \"+\"{:.2f}\".format(results['training_time']))\nprint(\"Testing time: \"+\"{:.2f}\".format(results['testing_time']))\nprint(\"********************************************\\n\")\n\n## Accuracy Score\nRF_Accuracy = accuracy_score(y_test_sm, RF_Prediction)\nprint(\"The accuracy score for Random Forest in percentage is: \"+\"{:.2f}\".format(RF_Accuracy*100))\n\n## Precision\nRF_Precision = precision_score(y_test_sm, RF_Prediction)\nprint(\"The precision score for Random Forest is: \"+\"{:.2f}\".format(RF_Precision))\n\n## Recall Feature\nRF_Recall = recall_score(y_test_sm, RF_Prediction)\nprint(\"The recall score for Random Forest is: \"+\"{:.2f}\".format(RF_Recall))\n\n## F1 Score\nRF_F1Score = f1_score(y_test_sm, RF_Prediction)\nprint(\"The F1 Score for Random Forest is: \"+\"{:.2f}\".format(RF_F1Score))\n\n## Confusion Matrix \nRF_Confusion_Matrix=confusion_matrix(y_test_sm,RF_Prediction)\nprint(\"Confusion_Matrix: \\n\\n\",RF_Confusion_Matrix, \"\\n\" )\n\n## Classification Report\ntarget_names =['class 0', 'class 1']\nprint(classification_report(y_test_sm,RF_Prediction,zero_division=1,target_names=target_names))\n\n## Cross Validation\nRF_accuracies = cross_val_score(estimator = RF_classifier, X= x_train_sm, y = y_train_sm, cv = 10)\nprint(\"Cross Validation Accuracy: {:.2f} %\".format(RF_accuracies.mean()*100))\nprint(\"Cross Validation Standard Deviation: {:.2f} %\".format(RF_accuracies.std()*100))","a4684c7a":"## Plotting the ROC Curve\nRF_pred_proba = RF_classifier.predict_proba(x_test_sm)[:,1]\nfpr_RF, tpr_RF, thresholds_RF = roc_curve(y_test_sm, RF_pred_proba)\n\nplt.figure(figsize=(10,10))\nplt.plot(fpr_RF, tpr_RF, marker='.', label='RF')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('RF ROC Curve')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","97f9fd3a":"## Calculating AUC score of Random Forest from the roc curve\nRF_AUC_Score = roc_auc_score(y_test_sm, RF_pred_proba)\nRF_AUC_Score","cc4c0a1b":"############# Hybrid Random Forest Linear Model (HRFLM) #############\n\n# Create the sub-model\nHRFLM_estimators = []\n\n# Defining 1 Logistic Regression Model\nmodel11 = LogisticRegression(random_state = 0,C=1, max_iter=10000)\nHRFLM_estimators.append(('logistic1', model11))\n\n\n# Defining 3 Random Forest Models\nmodel21 = RandomForestClassifier(random_state = 0)\nHRFLM_estimators.append(('RF1', model21))\n\nmodel22 = RandomForestClassifier(random_state = 0) \nHRFLM_estimators.append(('RF2', model22))\n\nmodel23 = RandomForestClassifier(random_state = 0)\nHRFLM_estimators.append(('RF3', model23))\n\n\n# Defining the HRFLM ensemble model\nHRFLM_ensemble = VotingClassifier(HRFLM_estimators,voting='soft')\n\nresults = {}\n#Training the model \nstart = time()\nHRFLM_ensemble.fit(x_train_sm, y_train_sm)\nend = time()\nresults['training_time'] = end - start\n\n#Testing the model \nstart = time()\nHRFLM_Prediction = HRFLM_ensemble.predict(x_test_sm)\nend = time()\nresults['testing_time'] = end - start\n\nprint(\"MODELLING TIMES(ms) OF HRFLM ARE:\")\nprint(\"********************************************\")\nprint(\"Training time: \"+\"{:.2f}\".format(results['training_time']))\nprint(\"Testing time: \"+\"{:.2f}\".format(results['testing_time']))\nprint(\"********************************************\\n\")\n\n\n## Accuracy Score\nHRFLM_Accuracy = accuracy_score(y_test_sm, HRFLM_Prediction)\nprint(\"The accuracy score for HRFLM in percentage is: \"+\"{:.2f}\".format(HRFLM_Accuracy*100))\n\n## Precision\nHRFLM_Precision = precision_score(y_test_sm, HRFLM_Prediction)\nprint(\"The precision score for HRFLM is: \"+\"{:.2f}\".format(HRFLM_Precision))\n\n## Recall Feature\nHRFLM_Recall = recall_score(y_test_sm, HRFLM_Prediction)\nprint(\"The recall score for HRFLM is as follows: \"+\"{:.2f}\".format(HRFLM_Recall))\n\n## F1 Score\nHRFLM_F1Score = f1_score(y_test_sm, HRFLM_Prediction)\nprint(\"The F1 Score for HRFLM is: \"+\"{:.2f}\".format(HRFLM_F1Score))\n\n## Confusion Matrix \nHRFLM_Confusion_Matrix=confusion_matrix(y_test_sm,HRFLM_Prediction)\nprint(\"Confusion_Matrix: \\n\\n\",HRFLM_Confusion_Matrix, \"\\n\" )\n\n## Classification Report\ntarget_names =['class 0', 'class 1']\nprint(classification_report(y_test_sm,HRFLM_Prediction,zero_division=1,target_names=target_names))\n\n\n## Cross Validation\nstart = time()\nHRFLM_accuracies = cross_val_score(HRFLM_ensemble, X = x_train_sm, y = y_train_sm, cv = 10)\nprint(\"Cross Validation Accuracy: {:.2f} \".format(HRFLM_accuracies.mean()))\nprint(\"Cross Validation Standard Deviation: {:.2f} %\".format(HRFLM_accuracies.std()*100))\nend = time()\nresults['Cross_Validation time'] = end - start\nprint(\"Cross_Validation time: \"+\"{:.2f}\".format(results['Cross_Validation time']))","b4541051":"## Plotting the ROC Curve\nHRFLM_pred_proba = HRFLM_ensemble.predict_proba(x_test_sm)[:,1]\nfpr_HRFLM, tpr_HRFLM, thresholds_HRFLM = roc_curve(y_test_sm, HRFLM_pred_proba)\n\nplt.figure(figsize=(10,10))\nplt.plot(fpr_HRFLM, tpr_HRFLM, marker='.', label='HRFLM')\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('HRFLM ROC Curve')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","ed991886":"## Calculating AUC score of HRFLM from the roc curve\nHRFLM_AUC_Score = roc_auc_score(y_test_sm, HRFLM_pred_proba)\nHRFLM_AUC_Score","9aef4fd5":"result = permutation_importance(HRFLM_ensemble, x_train_sm, y_train_sm, n_repeats=10,\n                                random_state=0)\n## Feature names in training set\nfeature_names= ['male', 'age', 'currentSmoker', 'cigsPerDay', 'BPMeds',\n       'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol', 'sysBP',\n       'diaBP', 'BMI', 'heartRate', 'glucose', 'education_1.0',\n       'education_2.0', 'education_3.0', 'education_4.0']\n\n## Printing the features based on their importance\nfor i in result.importances_mean.argsort()[::-1]:\n    if result.importances_mean[i] - 2 * result.importances_std[i] > 0:\n        print(f\"{feature_names[i]:<8}\"  \n              f\"{result.importances_mean[i]:.3f}\"\n              f\" +\/- {result.importances_std[i]:.3f}\")","03b91b79":"# generate a no skill prediction (majority class)\nns_probs = [0 for _ in range(len(y_test_sm))]\nns_auc = roc_auc_score(y_test_sm, ns_probs)\nfpr_NS, tpr_NS, thresholds_NS = roc_curve(y_test_sm, ns_probs)\n\nplt.figure(figsize=(10,10))\nplt.plot(fpr_NS, tpr_NS, linestyle='--', label='No Skill')\nplt.plot(fpr_SVM, tpr_SVM, marker='.', label='SVM', color='violet')\nplt.plot(fpr_DT, tpr_DT, marker='.', label='Decision Tree', color='yellow')\nplt.plot(fpr_KNN, tpr_KNN, marker='.', label='KNN', color='orange')\nplt.plot(fpr_MLP, tpr_MLP, marker='.', label='MLP', color='blue')\nplt.plot(fpr_LR, tpr_LR, marker='.', label='GLM', color='green')\nplt.plot(fpr_RF, tpr_RF, marker='.', label='Random Forest', color='pink')\nplt.plot(fpr_HRFLM, tpr_HRFLM, marker='.', label='HRFLM', color='red')\n\n\n# axis labels\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Comparision of All Models')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","83451db5":"feature_names= ['male', 'age', 'currentSmoker', 'cigsPerDay', 'BPMeds',\n       'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol', 'sysBP',\n       'diaBP', 'BMI', 'heartRate', 'glucose', 'education_1.0',\n       'education_2.0', 'education_3.0', 'education_4.0']\n\nmy_array = np.asarray(feature_names)\n\nexplainer = lime.lime_tabular.LimeTabularExplainer(x_train_sm.values,feature_names = my_array,class_names=['0','1'],\n                                                   kernel_width=3)\n\ni = np.random.randint(0,x_test_sm.shape[0])\nexp = explainer.explain_instance(x_test_sm.iloc[i],HRFLM_ensemble.predict_proba,num_features=x_train_sm.shape[1],top_labels=None)\n\nexp.show_in_notebook()\n\nfig = exp.as_pyplot_figure()","ed513b0b":"y_CHD_Predicted=pd.DataFrame(HRFLM_Prediction)\ny_CHD_Predicted\n\nx1=x_test_sm.reset_index()\ny1=y_test_sm.reset_index()\n\ndata_Merged = pd.concat([x1, y1,y_CHD_Predicted], axis=1, join=\"inner\")\ndata_Merged\n\ndata_Merged.columns = data_Merged.columns.map(str)\ndata_Merged = data_Merged.rename(columns={\"TenYearCHD\": \"TenYearCHD_Actual\", \"0\": \"TenYearCHD_Predicted\"})\n\ndel data_Merged['index']\n\ndata_Merged = data_Merged.reset_index()\n\ndata_Merged.head()","f903392b":"data_Merged.to_csv(r'D:\\DBS\\Final Dissertation\\CODE\\framingham_Mergerd_actualVSpredicted.csv', index = False)","1b2c58d3":"### Comparing ROC Curves of all the Models","c4a34c6f":"### SMOTE Upsampling ","dcd53f18":"### K-Nearest Neighbour","4a7b3ada":"## Data Preprocessing","5608e7b4":"### Train\/Test Splitting","bc997d01":"### Hybrid Random Forest Linear Model (HRFLM)","ef1c169c":"## Importing Framingham Dataset","70769905":"### Support Vector Machines","b1956c9e":"### Logistic Regression","8b96d79c":"### Decision Tree","6e784ee5":"### Exporting the above Dataset","7cfaa0cd":"### Multi layer Perceptron (MLP)","8ce36b29":"## IMPORTING LIBRARIES","3525a02e":"### Random Forest Classifier","230d6c2e":"   # MODELLING","f96c75fc":"### Dummy Encoding Categorical Variable","4b48f608":"## LIME","69b1cb3e":"### Outlier Detection","6672602e":"### HRFLM Feature Importance","48c9de59":"### Merging the Datasets for future Visualizations"}}