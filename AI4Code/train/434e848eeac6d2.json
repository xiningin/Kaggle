{"cell_type":{"4acec464":"code","a76c50b4":"code","530a0cc4":"code","6b627fd9":"code","ea4098b0":"code","3afaf45d":"code","7945c27c":"code","7d962bbe":"code","91a14d04":"code","ca3dc6da":"code","4a427b37":"code","e217f957":"code","4db50106":"code","d095e5a4":"code","f7c3ee64":"code","4213ef01":"code","6d13c361":"code","bb459601":"code","eefdf475":"code","6ddf165a":"code","51146b47":"code","62e563d9":"code","e600d0c1":"code","8299fe38":"code","9950c7f0":"code","61cfde1e":"code","ba6df1ec":"code","f567d297":"code","2e343164":"code","706cedb6":"code","66984795":"code","65fcaa46":"code","d651d556":"code","a42a46e0":"code","2635f0cf":"code","716cd8bc":"code","0e83d862":"code","39ad25bb":"code","a6723486":"code","fe239841":"code","7a5ed908":"code","a3be7f72":"code","39c038a5":"code","de673547":"code","8b1a735f":"code","0fdb195f":"code","c73fcedd":"code","0d441775":"code","37090fea":"code","53742931":"code","6e7a3364":"code","203f2799":"code","e04f9026":"code","a568b3d7":"code","8fe17e52":"code","24888f9d":"code","d8634d6e":"code","c55f020d":"code","079cc15e":"code","c616b730":"code","d01e02dc":"code","8b47a07e":"code","37abb9ec":"code","5538d226":"code","2f370ed3":"code","6f0a6737":"code","e551ebb8":"code","c0efbc94":"code","b342066b":"code","02f4cfcb":"code","5e322ed7":"code","0b654015":"code","d113bed2":"code","62032228":"code","132f96c1":"code","43c7fc29":"code","d9727b0c":"code","a9898d42":"code","d810730e":"code","82b33740":"code","e5016723":"code","d2998494":"code","4db40f48":"code","dddcfcd0":"code","fa71486a":"code","27fc6e69":"code","4ef621c8":"code","2ba7b0aa":"code","6ea0067d":"code","02829ccc":"code","15cf97ba":"code","62d5e57b":"code","96a471ee":"markdown","373b4351":"markdown","bc917e4a":"markdown","8d10d54c":"markdown","c450f77a":"markdown","740cf0dd":"markdown","0be06f10":"markdown","d87dd389":"markdown","ab8a1f96":"markdown","af898b25":"markdown","17e86909":"markdown","65586245":"markdown","f7e545ba":"markdown","7f693fcb":"markdown","358decb3":"markdown","71747fa7":"markdown","5980e45c":"markdown","a0440560":"markdown","3dfa0220":"markdown","5227920b":"markdown","9fc6e459":"markdown","53844f8e":"markdown","73e01d11":"markdown","0606d412":"markdown","23e5b0ae":"markdown","ffc4e4a9":"markdown","d950fc47":"markdown","85accc22":"markdown","e84ae007":"markdown","01142505":"markdown","0da3bda0":"markdown","f3b37f6c":"markdown","4ca42423":"markdown","8ff5fb97":"markdown","325cc4d2":"markdown","dca05389":"markdown","6135b37e":"markdown","08a30c2a":"markdown","13f16032":"markdown","01361228":"markdown","be855bcf":"markdown","c99471f5":"markdown","e76988fa":"markdown","2fecc72b":"markdown","4a86b500":"markdown","60306087":"markdown","c59bbf85":"markdown","e7041ab6":"markdown","fb747081":"markdown","72858efe":"markdown","6574be0d":"markdown","218711ee":"markdown","60613c25":"markdown","e34bde13":"markdown","353b7a47":"markdown","20fffd92":"markdown","6ffbee88":"markdown","04aed858":"markdown","bde716d7":"markdown","b88ec101":"markdown","d0f7da6c":"markdown","7333f7c3":"markdown","6e46503b":"markdown","ad5c5eb8":"markdown","17e796ce":"markdown","afb80eaf":"markdown","aed24f86":"markdown","6202fbc4":"markdown","5981339b":"markdown","c3fa2026":"markdown","1112d9a4":"markdown","bec04e6e":"markdown","ad8042b6":"markdown","99b93c52":"markdown","2e1fb986":"markdown"},"source":{"4acec464":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom scipy.stats import zscore\nimport fasttext\nimport os\n%matplotlib inline","a76c50b4":"# read the data\ndata = pd.read_csv('..\/input\/prediction-of-music-genre\/music_genre.csv')","530a0cc4":"data.info()","6b627fd9":"data[data.isnull().any(axis=1)]","ea4098b0":"data.dropna(inplace=True)\ndata.reset_index(drop=True, inplace=True)\ndata.info()","3afaf45d":"data.head()","7945c27c":"data.describe()","7d962bbe":"data.describe(include=['O'])","91a14d04":"# check if the data is balanced\ndata['music_genre'].value_counts()","ca3dc6da":"data = data.drop(columns=['instance_id'])","4a427b37":"print(f\"There are {data['artist_name'].nunique()} unique artists in the set\")","e217f957":"data['artist_name'].describe()","4db50106":"missing_artist = data[data['artist_name'] == 'empty_field']\nmissing_artist.head()","d095e5a4":"print(f\"Percent of missing artist names: {(missing_artist.shape[0]\/data.shape[0])*100:2.4}%\")","f7c3ee64":"data[data['artist_name'] != 'empty_field'].groupby('artist_name')['music_genre'].nunique().value_counts(normalize=True)","4213ef01":"# find the length of the artists names\ndata['length_name'] = data['artist_name'].str.len()","6d13c361":"data[data['artist_name'] != 'empty_field'].groupby('music_genre')['length_name'].describe()","bb459601":"plt.figure(figsize=(16,8))\nsns.boxplot(data=data[data['artist_name'] != 'empty_field'], x='music_genre', y='length_name')\nplt.show()","eefdf475":"data['track_name'].describe()","6ddf165a":"# generate track name length\ndata['length_track_name'] = data['track_name'].str.len()","51146b47":"data.groupby('music_genre')['length_track_name'].describe()","62e563d9":"plt.figure(figsize=(16,8))\nsns.boxplot(data=data, x='music_genre', y='length_track_name')\nplt.show()","e600d0c1":"# drop 'length_name' feature\ndata = data.drop(columns = ['length_name'])","8299fe38":"data[data['music_genre'] == 'Anime'].head()","9950c7f0":"# download pretrained language identification model\nos.system(f\"wget https:\/\/dl.fbaipublicfiles.com\/fasttext\/supervised-models\/lid.176.ftz\")","61cfde1e":"PRETRAINED_MODEL_PATH = 'lid.176.ftz'\nmodel = fasttext.load_model(PRETRAINED_MODEL_PATH)","ba6df1ec":"def find_japanese(df):\n    '''\n    returns a 1D-array of 0's ans 1's, as well as the confidence of each prediction.\n    1 - if either the artist or track name is written in japanese.\n    0 - otherwise\n    ''' \n    jap = []\n    confidence = []\n    \n    for _, row in df.iterrows():      \n        pred_track, confidence_track = model.predict(row['track_name'])\n        pred_track = pred_track[0].split('__')[-1]\n        pred_artist, confidence_artist = model.predict(row['artist_name'])\n        pred_artist = pred_artist[0].split('__')[-1]\n\n        # check the confidence of the language detection\n        if (pred_track == 'ja') or (pred_artist == 'ja'):\n            jap.append(1)\n            confidence.append(np.max([confidence_track[0], confidence_artist[0]]))\n        else:\n            jap.append(0)\n    \n    return jap, np.array(confidence)\n            ","f567d297":"data['Japanese'], confidence = find_japanese(data[['artist_name', 'track_name']])","2e343164":"print(f\"The average confidence level for the japanese predictions is {confidence.mean():1.2} +\\- {confidence.std():1.2}\")","706cedb6":"data.groupby('music_genre')['Japanese'].value_counts(normalize=True)","66984795":"data = data.drop(columns=['artist_name', 'track_name'])","65fcaa46":"data.groupby('music_genre')['popularity'].describe()","d651d556":"plt.figure(figsize=(16,8))\nsns.boxplot(data=data, x='music_genre', y='popularity')\nplt.show()","a42a46e0":"data.groupby('music_genre')['acousticness'].describe()","2635f0cf":"plt.figure(figsize=(16,8))\nsns.boxplot(data=data, x='music_genre', y='acousticness')\nplt.show()","716cd8bc":"data.groupby('music_genre')['danceability'].describe()","0e83d862":"plt.figure(figsize=(16,8))\nsns.boxplot(data=data, x='music_genre', y='danceability')\nplt.show()","39ad25bb":"data.groupby('music_genre')['duration_ms'].describe()","a6723486":"miss_duration = data[data['duration_ms'] == -1].shape[0]\nnum_obs_tot = data.shape[0]\nprint(f\"There are {miss_duration} missing values, which accounts for {(miss_duration\/num_obs_tot)*100:2.4}% of the data points.\")","fe239841":"plt.figure(figsize=(16,8))\nsns.boxplot(data=data[data['duration_ms'] != -1], x='music_genre', y='duration_ms')\nplt.show()","7a5ed908":"# fill in median for missing values\nmask_duration = data['duration_ms'] != -1\nmedian_duration = data.loc[mask_duration, 'duration_ms'].median()\ndata.loc[~mask_duration, 'duration_ms'] = median_duration","a3be7f72":"data.groupby('music_genre')['energy'].describe()","39c038a5":"plt.figure(figsize=(16,8))\nsns.boxplot(data=data, x='music_genre', y='energy')\nplt.show()","de673547":"data.groupby('music_genre')['instrumentalness'].describe()","8b1a735f":"plt.figure(figsize=(16,8))\nsns.boxplot(data=data, x='music_genre', y='instrumentalness')\nplt.show()","0fdb195f":"sns.histplot(x='instrumentalness',data=data);","c73fcedd":"inst_0 = data[data['instrumentalness'] == 0].shape[0]\nnum_obs = data.shape[0]\nprint(f\"There are {inst_0} observations with 0.0 instrumentalness, which accounts for {(inst_0\/num_obs)*100:2.4}% of the data points\")","0d441775":"data = data.drop(columns=['instrumentalness'])","37090fea":"data['key'].unique()","53742931":"sns.catplot(x=\"music_genre\", hue=\"key\",data=data, kind=\"count\",height=5, aspect=3.0, palette = 'Set1');","6e7a3364":"data.groupby('music_genre')['key'].describe()","203f2799":"# One Hot Encoding\ndata = pd.get_dummies(data, drop_first=True, prefix='key', columns=['key'])","e04f9026":"data.groupby('music_genre')['liveness'].describe()","a568b3d7":"plt.figure(figsize=(16,8))\nsns.boxplot(data=data, x='music_genre', y='liveness')\nplt.show()","8fe17e52":"data.groupby('music_genre')['liveness'].plot.kde()\nplt.legend()\nplt.xlim([0,1])\nplt.show()","24888f9d":"data.groupby('music_genre')['loudness'].describe()","d8634d6e":"plt.figure(figsize=(16,8))\nsns.boxplot(data=data, x='music_genre', y='loudness')\nplt.show()","c55f020d":"data['mode'].unique()","079cc15e":"data.groupby('music_genre')['mode'].describe()","c616b730":"plt.figure(figsize=(10,5))\nsns.countplot(x=\"music_genre\", hue=\"mode\",data=data)\nplt.legend(loc=0)\nplt.show()","d01e02dc":"# One Hot Encoding\ndata = pd.get_dummies(data, drop_first=True, columns=['mode'])","8b47a07e":"data.groupby('music_genre')['speechiness'].describe()","37abb9ec":"plt.figure(figsize=(16,8))\nsns.boxplot(data=data, x='music_genre', y='speechiness')\nplt.show()","5538d226":"data.groupby('music_genre')['tempo'].describe()","2f370ed3":"print(f\"This feature contains {(data[data['tempo'] == '?'].shape[0]\/data.shape[0])*100:2.4}% missing values\")","6f0a6737":"# replace \"?\" with np.nan and correctly classify the feature:\ndata.loc[data['tempo'] == '?', 'tempo'] = np.nan\ndata = data.astype({'tempo': np.float64})","e551ebb8":"data.groupby('music_genre')['tempo'].describe()","c0efbc94":"plt.figure(figsize=(16,8))\nsns.boxplot(data=data, x='music_genre', y='tempo')\nplt.show()","b342066b":"median_tempo = data['tempo'].median()\ndata['tempo'] = data['tempo'].fillna(median_tempo)","02f4cfcb":"data['obtained_date'].unique()","5e322ed7":"data.groupby('music_genre')['obtained_date'].describe()","0b654015":"data = data.drop(columns=['obtained_date'])","d113bed2":"data.groupby('music_genre')['valence'].describe()","62032228":"plt.figure(figsize=(16,8))\nsns.boxplot(data=data, x='music_genre', y='valence')\nplt.show()","132f96c1":"data['music_genre'] = data['music_genre'].astype('category')\ny = data['music_genre'].cat.codes\ny_names = list(data['music_genre'].cat.categories)\n\nX = data.drop(columns=['music_genre'])","43c7fc29":"scaler = RobustScaler()\nscaler.fit(X)\nX_scaled = pd.DataFrame(scaler.transform(X), columns=X.columns, index=X.index)","d9727b0c":"X_scaled.describe()","a9898d42":"numerical_feats = ['popularity', 'acousticness', 'danceability', 'duration_ms', 'energy',\n                   'liveness', 'loudness', 'speechiness', 'tempo', 'valence', 'length_track_name']\n\nplt.figure(figsize=(16,8))\nsns.boxplot(data=X_scaled[numerical_feats])\nplt.show()","d810730e":"X_no_outliers = X_scaled[(np.abs(zscore(X_scaled[numerical_feats])) < 4).all(axis=1)]\ny_no_outliers = y[X_no_outliers.index]","82b33740":"plt.figure(figsize=(16,8))\nsns.boxplot(data=X_no_outliers[numerical_feats])\nplt.show()","e5016723":"plt.figure(figsize=(10,8))\nsns.heatmap(X_no_outliers.corr(), annot=False)\nplt.show()","d2998494":"plt.figure(figsize=(10,8))\nsns.heatmap(X_no_outliers.iloc[:,:11].corr(), annot=True)\nplt.show()","4db40f48":"pca = PCA().fit(X_no_outliers)\n\n# find the first n components that account for 95% of the variance \ncum_exp_var = np.cumsum(pca.explained_variance_ratio_)\nn_components = (cum_exp_var <= 0.95).sum()\n\nX_pca = pca.transform(X_no_outliers)[:,:n_components]","dddcfcd0":"x_train, x_test, y_train, y_test = train_test_split(X_pca, y_no_outliers, test_size=0.3)","fa71486a":"def get_metrics(model, X, y, y_names):\n    clf = model\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y,test_size=0.3)\n\n    clf.fit(X_train, y_train)\n\n    predict_train = clf.predict(X_train)\n    predict_valid = clf.predict(X_valid)\n\n    print(f\"Train accuracy score: {accuracy_score(y_train, predict_train)*100:2.4}%\")\n    print(f\"Validation accuracy score: {accuracy_score(y_valid, predict_valid)*100:2.4}%\\n\")\n\n    print('Classification Report for the validation set:\\n')\n    print(classification_report(y_valid, predict_valid, target_names=y_names))\n    print('Confusion Matrix:\\n')\n    plt.figure(figsize=(8,6))\n    sns.heatmap(confusion_matrix(y_valid, predict_valid), annot = True, fmt = \".0f\", \n                cmap = \"coolwarm\", linewidths = 1, linecolor = \"white\",\n                xticklabels = y_names, yticklabels = y_names)\n    plt.show()","27fc6e69":"get_metrics(SVC(), x_train, y_train, y_names)","4ef621c8":"get_metrics(KNeighborsClassifier(), x_train, y_train, y_names)","2ba7b0aa":"get_metrics(RandomForestClassifier(), x_train, y_train, y_names)","6ea0067d":"X_reduced = X_scaled.drop(['duration_ms', 'liveness', 'tempo', 'length_track_name', 'Japanese'], axis=1)\nx_train_check, x_test_check, y_train_check, y_test_check = train_test_split(X_reduced, y, test_size=0.3)\n\nget_metrics(SVC(), x_train_check, y_train_check, y_names)\n","02829ccc":"# 1 - Anime, 2 - Classical, 3 - Rap and Hip-Hop, 0 - all the rest\ny_train_combined_1 = y_train.map({0:0, 1:1, 2:0, 3:2, 4:0, 5:0, 6:3, 7:0, 8:3, 9:0})\ny_names_comb_1 = ['All', 'Anime', 'Classical', 'Rap and Hip-Hop']\nget_metrics(SVC(), x_train, y_train_combined_1, y_names_comb_1)","15cf97ba":"# 0 - Rock, Alternative and country, 1 - Anime, 2 - Classical, 3 - Rap and Hip-Hop, 4 - Jazz, Blues and Electronic \ny_train_combined_2 = y_train.map({0:0, 1:1, 2:4, 3:2, 4:0, 5:4, 6:3, 7:4, 8:3, 9:0})\ny_names_comb_2 = ['Rock, Alternative and Country', 'Anime', 'Classical', 'Rap and Hip-Hop', 'Jazz, Blues and Electronic']\nget_metrics(SVC(), x_train, y_train_combined_2, y_names_comb_2)","62d5e57b":"final_mod = SVC().fit(x_train, y_train_combined_2)\npredictions = final_mod.predict(x_test)\n\ny_test_combined = y_test.map({0:0, 1:1, 2:4, 3:2, 4:0, 5:4, 6:3, 7:4, 8:3, 9:0})\n\nprint('Classification Report for the test set:\\n')\nprint(classification_report(predictions, y_test_combined, target_names=y_names_comb_2))\nprint('Confusion Matrix:\\n')\nplt.figure(figsize=(8,6))\nsns.heatmap(confusion_matrix(y_test_combined, predictions), annot = True, fmt = \".0f\", \n            cmap = \"coolwarm\", linewidths = 1, linecolor = \"white\",\n            xticklabels = y_names_comb_2, yticklabels = y_names_comb_2)\nplt.show()","96a471ee":"#### Almost 10% of the entries are missing a duration. We don't want to remove such a large amount of observations, so we'll fill in the missing values with the median, but consider removing the feature entirely in the future. \n#### Also of note is the fact that this feature contains extreme outliers. They could be important for classification, but we'll consider removing them at a later stage","373b4351":"#### We can see that there are 17 features and one label column (music_genre). Out of the features, 12 are numerical (one of which, tempo, is missclassified and will be dealt with later), and 5 are categorical.\n\n#### We can also already see hints to hidden missing values in 3 features ('tempo', 'artist_name' and 'duration_ms'). Those will be dealt with shortly one by one.","bc917e4a":"#### Interestingly, classical music is once again quite the outlier. (Also Jazz, to a lesser extant)","8d10d54c":"#### More than 20% of the Anime tracks are indeed written in Japanese, a much higher percentage than all the other music genres combined. This could indeed help us identify the Anime genre.","c450f77a":"#### We grouped the Elecrtronic genre with Jazz and Blues, and the Country genre with Rock and Alternative. These are not intuitive combinations, but the missclassification seen in the confusion matrices seems to hint at this.\n#### The f1-scores for these groupings are on par and better than that of the Anime genre, so this appears to be a good choice.","740cf0dd":"#### There are 10 different genres with equal distribution (balanced data). This means the accuracy score will be a good metric to use.","0be06f10":"## Modeling Summary:\n\nSVM, KNN, and Random Forest models were used on the data set, but all yielded bad results (40-50% accuracy). SVM was the best out of a bad bunch. \n\nPossible effects of outliers, dimensionality reduction and missing values were tested and discarded.\n\nThe next section will analyze the results in more depth and propose a solution.","d87dd389":"# Preface\n\nIn this notebook you will find a very thorough EDA of the given music database, followed by the use of several models (mainly SVM) to predict music genres.\n\nThe notebook is divided into 5 parts. Those who wish to skip a certain part can **jump to the end** of that part where you'll **find a summary** of that section.\n\n**1. Data Exploration:** here we go through the features one by one, determine their usefulness, and clean them for future use.\n\n**2. Fianl Preprocessing:** normalizing, removing outliers, train-test splitting etc.\n\n**3. Modeling:** here we use a few simple models on the train set and examine the results. Spoiler alert, they're not good.\n\n**4. Consolidating Classes:** here you'll find an attempt to improve the model's prediction ability by consolidating appropriate genres.\n\n**5. Final Test Results:** what it says on the tin.","ab8a1f96":"#### All genres seem to have a prefererence for the \"Major\" mode, but to different degrees. It is the most pronounced in the Country genre. We'll use this feature after one hot encoding.","af898b25":"#### Such a large number of 0.0 entries likely indicates missing values rather than real data points. Since this is a 3rd of our observations, we won't fill in missing values. Instead, we'll discard this feature entirely.","17e86909":"## Energy:","65586245":"#### The classical genre also has longer track names. The difference is much more pronounced than for the artist's name. This is a better feature for us to use, since it doesn't have the missing values problem. We'll use this and not the artist name length feature.","f7e545ba":"#### Different genres have noticeably different spreads. We'll keep this feature, but use One Hot Encoding to make it useful.","7f693fcb":"## Speechiness:","358decb3":"#### Again, only classical music truly stands out from the rest.","71747fa7":"#### Next we'll make a feature out off the sample's language. Specifically, whether it's written in Japanese. This may help us identify the Anime genre, which is likely to contain track\/artist names written in the Japanese alphabet, as shown below:","5980e45c":"## Final Preprocessing Summary\n\n1. The features and labels (music genres) were separated and the **labels were encoded**.\n2. The features were **normalized** using RobustScaler.\n3. Extreme **outliers were removed** based on z-score.\n4. PCA was used for **dimensionality reduction**.\n5. The dataset was **devided to train and test sets**.","a0440560":"#### After engineering new features from the artist\/track names, we can drop the original features.","3dfa0220":"#### As can be clearly seen, some features, especially the duration feature, contain extreme ouliers. These outliers can hinder the success of all models, so we'll remove them.","5227920b":"# 1. Data Exploration","9fc6e459":"# 2. Final Preprocessing","53844f8e":"#### The variation between genres is not great. We'll fill missing values with the median, but consider dropping the feature altogether in the future.","73e01d11":"## Normalize our new features:","0606d412":"#### This feature shows a nice spread of distributions for the different genres. Could definitely be useful for classification.\n#### Rap, Hip-Hop and Rock seem to be the most popular genres, while Anime, Blues and Classical are the least popular. The other 4 genres are somewhere in between.","23e5b0ae":"## Danceability:","ffc4e4a9":"## Outlier Removal:","d950fc47":"#### There are only 5 rows that contain NaN values. We'll remove them:","85accc22":"#### 5% of the observations are missing the artist's names (marked as 'empty_field'), but these entries are still valid otherwise. we will not drop these observations.","e84ae007":"## Class Consolidation Summary:\nIt would appear that our best course of action is to rearange the data into 5 separate categories: Classical music, Anime, Hip-Hop and Rap (together), Jazz, Blues and Electronic (together), and Rock, Alternative and Country (together). This will give us relatively good recall\/precision results for these genres, especially Classical and Rap\/Hip-Hop.\n\nWe might not be able to identify everything perfectly down to the exact genre, but at least we're able to narrow the options significantly!\nTo identify the rest, more feature engineering (additional data) is required.","01142505":"## Popularity:","0da3bda0":"## Mode:","f3b37f6c":"## KNN:","4ca42423":"#### It would appear that all of the models we tried were almost equaly as ineffective (~40-50% accuracy), but SVC does better than the rest and avoids overfitting.\n#### Before we'll analyze further, we'll do a short sanity check and see if this is related to the use of PCA, outlier removal, or if it has to do with the features that we engineered\/filled missing values in.","8ff5fb97":"#### Only gives the 4 dates at which the data was obtained. Not useful to us, so we'll drop it.","325cc4d2":"#### From the above statistics it seems that classical music tends to have noticeably longer names. Could potentialy be a useful feature. We'll keep it in for now.","dca05389":"## EDA Summary:\n\n### Labels:\nThere are 10 equally likely musical genres (balanced dataset): \n1. Alternative \n2. Anime\n3. Blues\n4. Classical\n5. Country\n6. Electronic\n7. Hip-Hop\n8. Jazz\n9. Rap\n10. Rock\n\n### Features:\n\n**Useful features:**\n1. popularity - left as is.\n2. acousticness - left as is.\n3. danceability - left as is.\n4. duration_ms - 10% of the entries had missing values, they were filled in with the median.\n5. energy - left as is.\n6. key - a categorical column containing 12 unique categories. One hot encoding was used.\n7. liveness - left as is with a caveat: may be removed later on due to a lack of variance between genres.\n8. loudness - left as is.\n9. mode - a categorical column containing only 2 unique categories. One hot encoding was used.\n10. speechiness - left as is.\n11. tempo - contained 10% missing values and missclassified as catagorical. The missing values were filled in with the median and the feature was correctly classified as numerical. Caveat: contains very similar distributions between the genres. might be removed later on.           \n12. valence - left as is.\n\n**Unhelpful Features that where removed:**\n1. instance_id - only an index.\n2. obtained_date - only contains the 4 consecutive dates of data aquisition.\n3. instrumentalness - contains 30% missing values.\n4. artist_name and track_name - were used to obtain new features (see below) and then discarded.\n\n**New features:**\n1. length_track_name - the track_name feature has essentially been converted to the length of the name. This feature helps identify the classic genre.\n2. Japanese - This feature indicates wether the track\/artist name is written in Japanese. This helps identify the Anime genre.\n\n**General observations:** \n\nIt would appear that most genres tend to have very similar distributions in most features, making it hard for any model to distinguish between them. The obviouse exception is classical music, which has very different distributions in many features.\nThe Anime genre also shows some distinguishing characteristics, as well as Jazz, to a much lesser extent. Hip-Hop and Rap are extremely similar to one another in all features, but are separate from the rest of the genres in some features. They might be easier to identify as one joint genre.\nAll in all, The current features are unlikely to give great predictions for all genres. We'll find out if this is true soon enough.","6135b37e":"The model has a high confidence level for Japanese\/non-Japanese predictions, likely due to the unique alphabet.","08a30c2a":"#### This feature should contribute especially to identifying Hip-Hop and Rap.","13f16032":"#### It would appear that putting Hip-Hop and Rap together greatly improves their result, putting the joint genre on par with classical music when it comes to precision\/recall. \n\n#### The next step is to try to separate out the other genres into smaller groups according to the missclassification seen in the confusion matrices in section 3.","01361228":"## Exploring the features one by one:","be855bcf":"#### Loudness, Acousticness and energy are highly correlated. PCA will address this while also reducing the dimesionality of our data set.","c99471f5":"## Try with less fetures, without PCA, and keeping the outliers in:","e76988fa":"## Random Forest:","2fecc72b":"# 4. Consolidating classes\n\nAn important thing to note is that as we hypothesized from the EDA, one genre, classical music, has much higher precision\/recall scores than all the rest. This is also true to a lesser extent regarding the Anime genre.\n\nMeanwhile, Hip-Hop and Rap seem to be interchangeable and can't be distinguished from one another, but they are relatively well separated from the rest of the genres (as evidenced by the confusion matrix).\n\nRock, Alternative and maybe Country also seem to have some similarity resulting in missclassification. Same goes for Blues and Jazz and maybe Electronic. These combinations are much more tentative, though.\n\n#### **Proposed solution:** combine similar genres into one, while keeping the classical genre (and perhaps Anime) separate.","4a86b500":"## Valence:","60306087":"## Obtained date:","c59bbf85":"*Note the obviouse overfitting appearant in this case (and in KNN to a lesser degree).","e7041ab6":"## Split the data to train and test:","fb747081":"(Note: Some of the features are clearly skewed. However, using log\/boxcox on them did not improve the final results, and so it is ommitted here)","72858efe":"## Tempo:","6574be0d":"#### This had no effect on the poor performance.\n#### It's not shown here for brevity, but removing all samples with missing values (instead of a whole feature) also did nothing to improve the results.","218711ee":"## Check correlation and reduce dimensionality with PCA:","60613c25":"## Duration:","e34bde13":"## SVC:","353b7a47":"#### This feature should be numeric. The \"?\" is a missing value.","20fffd92":"## Separate features from labels and encode labels:","6ffbee88":"#### The distributions seem similarly skewed for all genres, so this feature will likely not contribute much to the model. We'll try both with and without this feature.","04aed858":"#### As usual, classical music is far from the rest, with Jazz (and Blues) also differing from the rest somewhat.","bde716d7":"## Liveness:","b88ec101":"#### This is just an index. We'll drop it.","d0f7da6c":"## Artist's Names:","7333f7c3":"#### As usual, classical music stands out (and Jazz to a much lesser degree). Rap and Hip-Hop still match each other.","6e46503b":"## Key:","ad5c5eb8":"#### For the entries that do contain an artist's name, it seems that a song that comes from a particular artist has an ~80% chance of belonging to one specific genre.\n#### However, in it's current form it's not helpful for classifying songs from artists outside the training set. We'll need to extract more general features, starting with the simplest - name length.","17e796ce":"## Instance_id:","afb80eaf":"# 3. Modeling:\n\nWe will test 3 basic, unoptimized models to see how well they do with our data set.","aed24f86":"## Instrumentalness:","6202fbc4":"#### Let's zoom in on the upper left corner where there are some noticeable correlations:","5981339b":"# 5. Final Test results","c3fa2026":"## Track names:","1112d9a4":"#### -1.0 is obvously not a valid time measurement. These are missing values.","bec04e6e":"#### Classical music sticks out again, but Rap and Hip-Hop can also be distinguished from the rest (they seem to go together often).","ad8042b6":"## acousticness:","99b93c52":"## Loudness:","2e1fb986":"*Note that the data is now imbalanced, so we focus on the precision\/recall\/f1-score and not the accuracy."}}