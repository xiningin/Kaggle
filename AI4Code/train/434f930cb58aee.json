{"cell_type":{"b97e239a":"code","90d9f624":"code","23fe36b1":"code","397e424f":"code","095c92a5":"code","68097403":"code","218d4377":"code","f877a8c4":"code","1a24884a":"code","26139e48":"code","79992961":"code","5c7521c8":"code","d41174b8":"code","0dd492b5":"code","f0eac481":"code","c8f51648":"code","3ea0038d":"code","d0c90dc0":"code","baae4a8f":"code","bbc3aca3":"code","e077bfab":"code","1b3cd0bb":"code","f4029b1a":"code","3a5c19f2":"code","40cd08eb":"code","20bc0b22":"code","fa5856ee":"code","eb0260b8":"code","58aa9937":"code","9629368e":"code","52c8be59":"code","b34c7b1d":"code","ecd9a090":"code","14b7e785":"code","7422c25b":"code","dad30f17":"code","f5f9a733":"code","80299cda":"code","690e5bc2":"code","186d00eb":"code","72f7aaf0":"code","77f5c6d3":"code","b629015a":"code","37871a78":"code","7b458033":"code","b8fe537a":"code","590103e1":"markdown","38a0b46c":"markdown","237266b4":"markdown","543c790f":"markdown","fa5d2320":"markdown","f2db5579":"markdown","6f974981":"markdown","3eac5c2b":"markdown","ea2480b5":"markdown","5456f462":"markdown","a7231dbf":"markdown","56b6133c":"markdown"},"source":{"b97e239a":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","90d9f624":"# Common libs\nimport pandas as pd\nimport numpy as np\nimport sys\nimport os\nimport random\nfrom pathlib import Path\n\n# Charts\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\n\n\n# Tensorflow\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\n\n# Settings\nplt.style.use('fivethirtyeight')\n#plt.style.use('seaborn')","23fe36b1":"data_dir = Path('..\/input\/jovian-pytorch-z2g\/Human protein atlas')\ntest_dir = data_dir\/'test'\ntrain_dir = data_dir\/'train'\ncsv_dir = data_dir\/'train.csv'\nsubmission_dir = '..\/input\/jovian-pytorch-z2g\/submission.csv'","397e424f":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    \ndef F_score(output, label, threshold=0.5, beta=1):\n    prob = output > threshold\n    label = label > threshold\n    TP = tf.reduce_sum(tf.cast(prob&label, float), axis=0)\n    TN = tf.reduce_sum(tf.cast((~prob)&(~label), float), axis=0)\n    FP = tf.reduce_sum(tf.cast((prob)&(~label), float), axis=0)\n    FN = tf.reduce_sum(tf.cast((~prob)&label, float), axis=0)\n    precision = tf.reduce_mean(TP\/(TP+FP+(1e-12)))\n    recall = tf.reduce_mean(TP\/(TP+FN+(1e-12)))\n    F2 = (1 + beta**2) * precision *recall \/((beta**2) *precision + recall + (1e-12))\n    return tf.reduce_mean(F2)\n\nlabels = {\n    0: 'Mitochondria',\n    1: 'Nuclear bodies',\n    2: 'Nucleoli',\n    3: 'Golgi apparatus',\n    4: 'Nucleoplasm',\n    5: 'Nucleoli fibrillar center',\n    6: 'Cytosol',\n    7: 'Plasma membrane',\n    8: 'Centrosome',\n    9: 'Nuclear speckles'\n}\n\nindxes = {str(v):k for k,v in labels.items()}","095c92a5":"batch_size = 32\nseed = 2020\nval_split = 0.2\nimg_size = (224,224,3)\nnfolds = 5","68097403":"seed_everything(seed)","218d4377":"data = pd.read_csv(csv_dir)\ndata.head()","f877a8c4":"# data['Label'] = data['Label'].apply((lambda x: x.split(\" \")))","1a24884a":"# from sklearn.preprocessing import MultiLabelBinarizer\n# binarizer = MultiLabelBinarizer()\n# df = pd.DataFrame(binarizer.fit_transform(data['Label']),columns=binarizer.classes_)","26139e48":"# data = pd.concat([data, df], axis=1)","79992961":"# data","5c7521c8":"def fill_targets(row):\n    row.Label = np.array(row.Label.split(\" \")).astype(np.int)\n    for num in row.Label:\n        name = labels[int(num)]\n        row.loc[name] = 1\n    return row","d41174b8":"for key in labels.keys():\n    data[labels[key]] = 0","0dd492b5":"data = data.apply(fill_targets, axis=1)\ndata.head()","f0eac481":"data['Image'] = data['Image'].apply(lambda x: str(x)+'.png')\ndata.head()","c8f51648":"test_data = pd.read_csv(submission_dir)\ntest_data['Image'] = test_data['Image'].apply(lambda x: str(x)+'.png')\ntest_data.head()","3ea0038d":"y = list(data.columns[2:])","d0c90dc0":"test_names = test_data.Image.values\ntest_labels = pd.DataFrame(data=test_names, columns=[\"Image\"])\nfor col in data.columns.values:\n    if col != \"Image\":\n        test_labels[col] = 0\ntest_labels.head(1)","baae4a8f":"class Generators:\n    \"\"\"\n    Train, validation and test generators\n    \"\"\"\n    def __init__(self, train_df, test_df):\n        self.batch_size=50\n        self.img_size=(224,224)\n        \n        # Base train\/validation generator\n        train_datagen = ImageDataGenerator(\n            rescale=1.\/255.,\n            validation_split=0.20,\n            featurewise_center=False,\n            featurewise_std_normalization=False,\n            rotation_range=90,\n            width_shift_range=0.2,\n            height_shift_range=0.2,\n            horizontal_flip=True,\n            vertical_flip=True\n            )\n        test_datagen = ImageDataGenerator(rescale = 1.\/255.)\n        # Train generator\n        self.train_generator = train_datagen.flow_from_dataframe(\n            dataframe=data,\n            directory=train_dir,\n            x_col='Image',\n            y_col=y,\n            has_ext=True,\n            subset=\"training\",\n            batch_size=self.batch_size,\n            seed=42,\n            shuffle=True,\n            class_mode=\"raw\",\n            target_size=self.img_size)\n        print('Train generator created')\n        # Validation generator\n        self.val_generator = train_datagen.flow_from_dataframe(\n            dataframe=data,\n            directory=train_dir,\n            x_col=\"Image\",\n            y_col=y,\n            has_ext=True,\n            subset=\"validation\",\n            batch_size=self.batch_size,\n            seed=42,\n            shuffle=True,\n            class_mode=\"raw\",\n            target_size=self.img_size)    \n        print('Validation generator created')\n        #test generator \n        self.test_generator = test_datagen.flow_from_dataframe(\n            dataframe=test_labels,\n            directory=test_dir,\n            x_col='Image',\n            y_col=y,\n            has_ext=True,\n            class_mode=\"raw\",\n            batch_size= batch_size,\n            shuffle=False,\n            target_size=(224,224))\n        print('Test generator created')\n         \n# Create generators        \ngenerators = Generators(data, test_data)\nprint(\"Generators created\")","bbc3aca3":"def show_batch(image_batch, label_batch):\n  plt.figure(figsize=(20,10))\n  for n in range(9):\n      ab =[]\n      for i, label in enumerate(label_batch[n]):\n            if label ==1:\n                ab.append(labels[i])\n      ax = plt.subplot(3,3,n+1)\n      plt.imshow(image_batch[n])\n      plt.title((ab))\n      plt.axis('off')\n#       plt.tight_layout()","e077bfab":"image_batch, label_batch = next(generators.train_generator)\nshow_batch(image_batch, label_batch)","1b3cd0bb":"import tensorflow_hub as hub","f4029b1a":"feature_extractor_url = \"https:\/\/tfhub.dev\/google\/imagenet\/mobilenet_v2_100_224\/feature_vector\/4\"\nfeature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n                                         input_shape=(224,224,3))","3a5c19f2":"feature_extractor_layer.trainable = False","40cd08eb":"base_model = tf.keras.applications.ResNet50(input_shape=(224,224,3),\n                                              include_top=False,\n                                              weights='imagenet')","20bc0b22":"import tensorflow_addons as tfa\nfbeta=tfa.metrics.FBetaScore(num_classes=10, average=\"micro\", threshold = 0.5)","fa5856ee":"class ModelTrainer:\n    \"\"\"\n    Create and fit the model\n    \"\"\"\n    \n    def __init__(self, generators):\n        self.generators = generators\n        self.img_width = generators.img_size[0]\n        self.img_height = generators.img_size[1]\n    \n    def create_model(self,\n                    kernel_size = (3,3),\n                    pool_size= (2,2),\n                    first_filters = 32,\n                    second_filters = 64,\n                    third_filters = 128,\n                    first_dense=256,\n                    second_dense=128,\n                    dropout_conv = 0.3,\n                    dropout_dense = 0.3):\n\n        model = Sequential(\n#             [feature_extractor_layer,\n#                           keras.layers.GlobalAveragePooling2D()]\n        )\n#         # First conv filters\n#         model.add(Conv2D(first_filters, kernel_size, activation = 'relu', padding=\"same\",\n#                          input_shape = (self.img_width, self.img_height,3)))\n#         model.add(Conv2D(first_filters, kernel_size, padding=\"same\", activation = 'relu'))\n#         model.add(Conv2D(first_filters, kernel_size, padding=\"same\", activation = 'relu'))\n#         model.add(MaxPooling2D(pool_size = pool_size)) \n#         model.add(Dropout(dropout_conv))\n\n#         # Second conv filter\n#         model.add(Conv2D(second_filters, kernel_size, padding=\"same\", activation ='relu'))\n#         model.add(Conv2D(second_filters, kernel_size, padding=\"same\", activation ='relu'))\n#         model.add(Conv2D(second_filters, kernel_size, padding=\"same\", activation ='relu'))\n#         model.add(MaxPooling2D(pool_size = pool_size))\n#         model.add(Dropout(dropout_conv))\n\n#         # Third conv filter\n#         model.add(Conv2D(third_filters, kernel_size, padding=\"same\", activation ='relu'))\n#         model.add(Conv2D(third_filters, kernel_size, padding=\"same\", activation ='relu'))\n#         model.add(Conv2D(third_filters, kernel_size, padding=\"same\", activation ='relu'))\n#         model.add(MaxPooling2D(pool_size = pool_size))\n#         model.add(Dropout(dropout_conv))\n\n#         model.add(Flatten())\n        model.add(feature_extractor_layer)\n        # First dense\n        model.add(Dense(first_dense, activation = \"relu\"))\n        model.add(Dropout(dropout_dense))\n        \n        # Second dense\n        model.add(Dense(second_dense, activation = \"relu\"))\n        model.add(Dropout(dropout_dense))\n        \n        # Out layer\n        model.add(Dense(10, activation = \"sigmoid\"))\n\n        model.compile(optimizer=Adam(lr=0.0001), \n                      loss='binary_crossentropy', metrics=[fbeta])\n        return model\n        \n    \n    def train(self, model):\n        \"\"\"\n        Train the model\n        \"\"\"\n    \n        epochs=5\n        steps_per_epoch=15389\/\/50\n        validation_steps=3847\/\/50\n            \n        # We'll stop training if no improvement after some epochs\n        earlystopper = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, \n                                   verbose=1, mode='max', min_lr=0.00001)\n        # Save the best model during the traning\n        checkpointer = ModelCheckpoint(\"classfication.h5\"\n                                        ,monitor='val_loss'\n                                        ,verbose=1\n                                        ,save_best_only=True\n                                        ,save_weights_only=True)\n        # Train\n        training = model.fit(self.generators.train_generator\n                                ,epochs=epochs\n                                ,steps_per_epoch=steps_per_epoch\n                                ,validation_data=self.generators.val_generator\n                                ,validation_steps=validation_steps\n                                ,callbacks=[earlystopper, reduce_lr, checkpointer])\n        # Get the best saved weights\n#         model.load_weights('classfication.h5')\n        return training\n    \n# Create and train the model\ntrainer = ModelTrainer(generators)\n\nmodel = trainer.create_model(kernel_size = (3,3),\n#                     pool_size= (2,2),\n#                     first_filters = 128,\n#                     second_filters = 256,\n#                     third_filters = 512,\n                    first_dense=1024,\n                    second_dense=512,\n                    dropout_conv = 0.3,\n                    dropout_dense = 0.2)\n\nmodel.summary()","eb0260b8":"training=trainer.train(model)\nprint(\"Trained\")","58aa9937":"training.history.keys()","9629368e":"def plot_history(training):\n        \"\"\"\n        Plot training history\n        \"\"\"\n        ## Trained model analysis and evaluation\n        f, ax = plt.subplots(1,2, figsize=(12,3))\n        ax[0].plot(training.history['loss'], label=\"Loss\")\n        ax[0].plot(training.history['val_loss'], label=\"Validation loss\")\n        ax[0].set_title('Loss')\n        ax[0].set_xlabel('Epoch')\n        ax[0].set_ylabel('Loss')\n        ax[0].legend()\n\n        # Accuracy\n        ax[1].plot(training.history['fbeta_score'], label=\"F_score\")\n        ax[1].plot(training.history['val_fbeta_score'], label=\"Val F_score\")\n        ax[1].set_title('F_score')\n        ax[1].set_xlabel('Epoch')\n        ax[1].set_ylabel('F_score')\n        ax[1].legend()\n        plt.tight_layout()\n        plt.show()","52c8be59":"plot_history(training)","b34c7b1d":"preds = model.predict(generators.test_generator)","ecd9a090":"print(len(preds))\nprint(preds[:3])","14b7e785":"bool_preds = preds.round()\nbool_preds[:3]","7422c25b":"sub = pd.DataFrame(bool_preds, columns = y)","dad30f17":"sub.head()","f5f9a733":"def transform_to_target(row):\n    target_list = []\n    for col in sub.columns:\n        if row[col] == 1:\n            target_list.append(str(indxes[col]))\n    if len(target_list) == 0:\n        return None\n    return \" \".join(target_list)","80299cda":"sub[\"Predicted\"] = sub.apply(lambda l: transform_to_target(l), axis=1)\nsub.head()","690e5bc2":"a = pd.Series(sub.Predicted)\na[:3]","186d00eb":"b = pd.Series(generators.test_generator.filenames)\nb[:3]","72f7aaf0":"final_df = pd.concat([b, a], axis=1)","77f5c6d3":"final_df.columns = ['Image', 'Label']","b629015a":"final_df['Label'] = final_df['Label'].apply(lambda x: str(x).strip('[').strip(']').strip(','))","37871a78":"final_df['Label'] = final_df['Label'].apply(lambda x: str(x).replace(',', ' '))","7b458033":"final_df['Image'] = final_df['Image'].apply(lambda x: x.strip('png'))","b8fe537a":"final_df.to_csv('final_csv', index=False) ","590103e1":"# Introduction and Acknowledgement\n\n\nHello, I am a beginner in the field of deep learning and I'm still learning new things everyday. In this challenge of multilabel image classification, we will try to indentify various types human proteins present in the given image. Before starting with the code, I would to like to say thanks to [aakash](https:\/\/www.kaggle.com\/aakashns) and [jovian](https:\/\/jovian.ml\/) for conducting very helpful course and competition in for deep learning with pytorch. It really helped me to understand core programming concepts to build various deep learning models. As the course was focused on the programming with pytorch, majority of people used to pytorch for this competitions. I would like to say thanks to [nachiket273](https:\/\/www.kaggle.com\/nachiket273), [ronaldo](https:\/\/www.kaggle.com\/ronaldokun),[Mimi Cheng](https:\/\/www.kaggle.com\/mimicheng) for sharing their work. I have learned lots of new concepts by studying there kernels.\n\nAs a beginner, I really had a tough time chosing between which framework to use for deep learning. I started with tesnorflow-keras and a rookie programmer it saved a lot of lines of code for me. Tensorflow is really good when someone has less experience of programming. Unlike, pytorch, it does a lot of things for you. In addition, various type api helps in handling complext tasks like data pipeline, deployment, etc. However, pytorch is gaining more popularity since last year because of its flexibility in code and for being more pythonic. \n\nI am creating this notebook to help someone who is interested in the tensorflow implementation of the classification challenge. I want to express gratitude to [Dmitry](https:\/\/www.kaggle.com\/dmitrypukhov) and [Laura](https:\/\/www.kaggle.com\/allunia) sharing there work related to[ datagenerator with keras](https:\/\/www.kaggle.com\/dmitrypukhov\/cnn-with-imagedatagenerator-flow-from-dataframe) and [multilabel classification](https:\/\/www.kaggle.com\/allunia\/protein-atlas-exploration-and-baseline) respectively.\n","38a0b46c":"We will define a class **Generators** to create train, test and validation generators. In this generator we will use the keras ImageDataGenerator class to preprocess and generating batches of data. As we are accessing the filenames of the images from a csv file, we will *flow_from_dataframe* method. Keras provide various such [Image data processing methods](https:\/\/keras.io\/api\/preprocessing\/image\/). ","237266b4":"Now it is time to define to **ModelTrainer** class. In this class, we will create the top layer of our model architecture. Then we will compile our model with loss and optimzer fallowed by fit method. We will also callback such as *EarlyStopping* and *ReduceLROnPlateau* to make our learning process more efficient.","543c790f":"There are lots of things which I want to try out in this notiebook. I will try to update the notebook at least once or twice in a week based on how much time I get for this notebook. Version 8 successfully runs all the classification. In addition, Some of the things which I want to try are as fallows:\n\n* Use of tf.data to build dataset\n* Use of tf.autotune for optimal use of GPU and CPU\n* a loss function based on the F1_score \n* EDA related to data which is available \n* variable thresholding for different classes","fa5d2320":"Initializing path to various data directories using pathlib module.","f2db5579":"We will use the pretrained  Resnet50 model as the base of our model. ","6f974981":"We will use a function to split the Labels into separate columns of the dataframe.","3eac5c2b":"While doing some research, I found out the tensorflow provides a built-in F-score metric in [tensorflow-addons](ttps:\/\/www.tensorflow.org\/addons) module. Therefore I decided to use that one instead of the custom metric we defined earlier. tesnorflow-addons provides really helpful metric and loss functions. I am also planning to use loss function related to f-score. May be afterwards I will use it.","ea2480b5":"Not lets start with the notebook. First we will use [autoreload](https:\/\/ipython.org\/ipython-doc\/3\/config\/extensions\/autoreload.html) extension to reload imported modules before executing the code in the cell","5456f462":"After generaing data in required size and format, it is always nice to take a look at the data. Therefore we will use a simple function to display some images along with labels.","a7231dbf":"To get the same output everytime, we will use seed function. In addition, we define a metric call 'F-score' to monitor the performance of the model. In the case of multilabel classification, it is advised to use 'F-score' instead of 'Accuracy'.","56b6133c":"Now we will import some of the common useful libraries along with tensorflow."}}