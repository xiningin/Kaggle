{"cell_type":{"2a27b9e2":"code","20d79449":"code","faa6a043":"code","758427db":"code","2cfbaf6c":"code","28e5a997":"code","49c46220":"code","b524a795":"code","b25d3efb":"code","8e930cbc":"code","1bac98a0":"code","b405f687":"code","6b1e278e":"code","ffb0d0b9":"code","1511cb6d":"code","73ed5dd8":"code","a87132ae":"code","e7b53484":"code","e23181ff":"code","65a2ec12":"code","89c71bb6":"code","994736c2":"code","2cb6cbfd":"code","f7eb05c1":"code","44efca17":"code","cf0c03cd":"code","2070e55e":"code","a1ab8ad1":"code","79be674f":"code","cb2f51de":"code","7e415343":"code","8e4f6bed":"code","d912fbf7":"code","8bb283d3":"code","d1040582":"markdown","d708a475":"markdown","6234068a":"markdown","25e4ecf3":"markdown","036638cc":"markdown","eca5e758":"markdown","491ba16e":"markdown","af141745":"markdown","573f9702":"markdown","485fb352":"markdown","343ed6a5":"markdown","b7209ce6":"markdown","0ecdb155":"markdown","e899ea8a":"markdown","78ff734f":"markdown","b9aac24e":"markdown","0af0959d":"markdown","1028cb39":"markdown","5d423b43":"markdown"},"source":{"2a27b9e2":"import pandas as pd\nimport numpy as np\nimport os,cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom IPython.display import SVG\nfrom keras.utils import model_to_dot\nfrom keras.utils import plot_model\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam,SGD\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout\nfrom keras.models import Sequential, Model, Input\n\nfrom keras.initializers import *","20d79449":"datasets = [\"..\/input\/plant-seedlings-classification\/train\"]\n\nclass_names = [\"Black-grass\",\"Charlock\",\"Cleavers\",\"Common Chickweed\",\"Common wheat\",\"Fat Hen\",\"Loose Silky-bent\",\"Maize\",\"Scentless Mayweed\",\"Shepherds Purse\",\"Small-flowered Cranesbill\",\"Sugar beet\"]\n\nclass_name_labels = {class_name:i for i,class_name in enumerate(class_names)}\n\nnb_classes = len(class_names)\nclass_name_labels","faa6a043":"from tqdm import tqdm\n\ndef load_data():\n    images,labels = [],[]\n    for dataset in datasets:\n\n        for folder in os.listdir(dataset):\n            label = class_name_labels[folder]\n            \n            for file in tqdm(os.listdir(os.path.join(dataset,folder))):\n                \n                img_path = os.path.join(os.path.join(dataset,folder),file)\n                img = cv2.imread(img_path)\n                img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n                img = cv2.resize(img,(150,150))\n                \n                images.append(img)\n                labels.append(label)\n                pass\n            pass\n        \n        images = np.array(images,dtype=np.float32)\n        labels = np.array(labels,dtype=np.float32)\n        \n        pass\n    \n    return images,labels\n    pass","758427db":"(train_images),(train_labels) = load_data()","2cfbaf6c":"n_train = train_labels.shape[0]\n\n_, train_count = np.unique(train_labels,return_counts=True)\n\ndf = pd.DataFrame(data = train_count)\n# df = df.T\ndf['Index'] = class_names\ndf.columns = ['Train','Name']\ndf","28e5a997":"df.set_index(\"Name\").plot.bar()\nplt.xlabel(\"Type of seedling\")\nplt.ylabel(\"Count\")\nplt.title(\"Number of different type of seedlings\");","49c46220":"plt.pie(train_count,\n       explode=(0,0,0,0,0,0,0,0,0,0,0,0),\n       labels = class_names,\n       autopct = \"%1.1f%%\")\nplt.axis('equal')\nplt.title(\"Proportion of each observed category in the train dataset\")\nplt.show();","b524a795":"def show_final_history(history):\n    fig, ax = plt.subplots(1,2,figsize=(15,5))\n    ax[0].set_title(\"Loss\")\n    ax[1].set_title(\"Accuracy\")\n    ax[0].plot(history.history[\"loss\"],label=\"Loss\")\n    ax[0].plot(history.history[\"val_loss\"],label=\"Test Loss\")\n    ax[1].plot(history.history[\"accuracy\"],label=\"Accuracy\")\n    ax[1].plot(history.history[\"val_accuracy\"],label=\"Test Accuracy\")\n    \n    ax[0].legend(loc=\"upper right\")\n    ax[1].legend(loc=\"lower right\")","b25d3efb":"train_labels","8e930cbc":"train_labels = to_categorical(train_labels,num_classes=nb_classes)","1bac98a0":"train_labels.shape","b405f687":"X_train,X_val,y_train,y_val = train_test_split(train_images,train_labels,test_size=0.3)","6b1e278e":"train_dir = \"..\/input\/plant-seedlings-classification\/train\"\n\nbatch_size = 16\n\nIGD = ImageDataGenerator(rescale=1.\/255,\n                        horizontal_flip=True,\n                        vertical_flip=True,\n                        rotation_range=20)\n#                         validation_split=0.3)\n\ntrain_generator = IGD.flow(x=X_train,\n                          y=y_train,\n                          batch_size=batch_size,\n                          shuffle=True,\n                          seed=42)\n#                           subset=\"training\")\n\nvalidation_generator = IGD.flow(x=X_val,\n                               y=y_val,\n                               batch_size=batch_size,\n                               shuffle=True,\n                               seed=42)\n#                                subset=\"validation\")","ffb0d0b9":"def conv_block(X,k,filters,stage,block,s=2):\n    \n    conv_base_name = 'res_' + str(stage) + block + '_branch'\n    bn_base_name = 'bn_' + str(stage) + block + \"_branch\"\n    \n    F1 = filters\n    \n    X = Conv2D(filters=F1,kernel_size=(k,k),strides=(s,s),\n              padding='same',name=conv_base_name,\n              kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(name=bn_base_name)(X)\n#     X = MaxPooling2D((3,3))(X)\n    X = Activation('relu')(X)\n    \n    return X\n    pass","1511cb6d":"def conv_model(input_shape,classes):\n    \n    X_input = Input(input_shape)\n    \n    # Stage 1\n    X = Conv2D(64,(5,5),strides=(2,2),name='conv1')(X_input)\n    X = BatchNormalization(name='bn_conv1')(X)\n#     X = MaxPooling2D((3,3))(X)\n#     X = Activation('relu')(X)\n#     X = Dropout(0.1)(X)\n    \n    # Stage 2\n    X = conv_block(X,5,64,2,block='A',s=1)\n    X = MaxPooling2D((2,2))(X)\n    X = Dropout(0.1)(X)\n    \n    # Stage 3 \n    X = conv_block(X,3,128,3,block='A',s=1)\n    X = MaxPooling2D((3,3))(X)\n    X = Dropout(0.1)(X)\n    \n    # Stage 4\n    X = conv_block(X,5,256,4,block='A',s=1)\n    X = Dropout(0.1)(X)\n    \n    # Output Layer\n    X = Flatten()(X)\n    X = Dense(256)(X)\n    X = Dense(256)(X)\n    X = Activation('relu')(X)\n    X = Dense(classes,activation='softmax',name='fc'+str(classes))(X)\n    \n    model = Model(inputs=X_input,outputs=X,name='CNN')\n    \n    return model\n    pass","73ed5dd8":"model = conv_model(input_shape=(150,150,3),classes=nb_classes)","a87132ae":"plot_model(model,to_file='conv_model.png')\nSVG(model_to_dot(model).create(prog='dot',format='svg'))\n\nmodel.summary()","e7b53484":"opt = SGD(lr=0.0001,momentum=0.95)\nmodel.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])","e23181ff":"checkpoint = ModelCheckpoint(\"model_weights.h5\",monitor='val_accuracy',verbose=1,\n                             save_best_only=True,mode=\"max\")\ncallbacks_list = [checkpoint]","65a2ec12":"epochs = 125\n\nhistory = model.fit_generator(generator=train_generator,\n                              steps_per_epoch=train_generator.n\/\/batch_size,\n                              epochs=epochs,\n                              validation_data=validation_generator,\n                              validation_steps=validation_generator.n\/\/batch_size,\n                              callbacks=callbacks_list,\n                              verbose=1)","89c71bb6":"show_final_history(history)","994736c2":"class_name_labels","2cb6cbfd":"y_test = np.argmax(y_val,axis=1)\ny_test.shape,validation_generator.n","f7eb05c1":"val_pred = model.predict_generator(generator=validation_generator)\ny_pred = [np.argmax(probas) for probas in val_pred]","44efca17":"y_pred = np.argmax(val_pred,axis=1)\ny_pred.shape","cf0c03cd":"import itertools\n\ndef plot_confusion_matrix(cm,classes,title='Confusion Matrix',cmap=plt.cm.Blues):\n    \n    cm = cm.astype('float')\/cm.sum(axis=1)[:,np.newaxis]\n    plt.figure(figsize=(10,10))\n    plt.imshow(cm,interpolation='nearest',cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes,rotation=90)\n    plt.yticks(tick_marks, classes)\n    \n    fmt = '.2f'\n    thresh = cm.max()\/2.\n    for i,j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n        plt.text(j,i,format(cm[i,j],fmt),\n                horizontalalignment=\"center\",\n                color=\"white\" if cm[i,j] > thresh else \"black\")\n        pass\n    \n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    pass\n\ncnf_mat = confusion_matrix(y_test,y_pred)\nnp.set_printoptions(precision=2)\n\n\nplt.figure()\nplot_confusion_matrix(cnf_mat,classes=class_names)\nplt.show()","2070e55e":"test_dir = [\"..\/input\/plant-seedlings-classification\/test\"]\n\ndef load_test():\n    \n    images,names = [],[]\n    for dataset in test_dir:\n\n        for file in tqdm(os.listdir(dataset)):\n            \n            img_path = os.path.join(dataset,file)\n            img = cv2.imread(img_path)\n            img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n            img = cv2.resize(img,(150,150))\n\n            images.append(img)\n            names.append(file)\n            pass\n        \n        images = np.array(images,dtype=np.float32)\n        pass\n    \n    return images,names\n    pass","a1ab8ad1":"(test_images),(test_names) = load_test()","79be674f":"for (label),(i) in class_name_labels.items():\n    print(label,i)","cb2f51de":"test_images[0].shape","7e415343":"from keras.preprocessing.image import img_to_array\n\npredicted_class = []\nclass_labels = dict((i,label) for label,i in class_name_labels.items())\nfor image in tqdm(test_images):\n    \n    image = np.expand_dims(image, axis=0)\n    test_result = model.predict(image)\n    pred_class = np.argmax(test_result,axis=1)\n    prediction = [class_labels[k] for k in pred_class][0]\n    predicted_class.append(prediction)\n    pass\n\nresults = pd.DataFrame({\"file\":test_names,\n                        \"species\":predicted_class})","8e4f6bed":"results.head()","d912fbf7":"results.to_csv(\"submission.csv\",index=False)","8bb283d3":"model_json = model.to_json()\nwith open(\"model.json\",\"w\") as json_file:\n    json_file.write(model_json)\n    pass","d1040582":"Running the model for 50 epochs","d708a475":"The model is yet to reach the global minimum yet. At least the model is not overfitting which is a good thing. But its too bumpy, may need to change the momentum and learning rate for the optimizer.","6234068a":"# Visualising the Loss and Accuracy of Model\n\nDisplaying the loss and accuracy versus epochs graph.\n\nThis graph allows the user to see whether the model needs to run for some more epochs or not.","25e4ecf3":"As can be seen from the above bar chart that the maximum number of images belong to the class *Loose Silky-bent*, whatever that is. There is class imbalance with 5 classes having really low number of images while 2 classes have a high number of images with the rest around the median. ","036638cc":"Counting the number of images associated with each label.","eca5e758":"# Creating the model\n\nThe current model consists of 4 convolutional layers and one fully connected layer, divided into various stages.\n\n`Stage 1: Taking the input with kernel size = (5,5) and number of filters = 32.`\n`Stage 2: Consists of 1 convolutional layer with a Relu activation and BatchNormalization.`\n`Stage 3: Consists of 1 convolutional layer with a Relu activation and BatchNormalization.`\n`Stage 4: Consists of 1 convolutional layer with a Relu activation and BatchNormalization.`","491ba16e":"# Predicting the Test Images and making a submission\n\nThe test images are preprocessed via ImageDataGenerator and passed to the predict_generator function of the model for prediction. ","af141745":"Saving the model architecture as a flowchart for better understanding to *`conv_model.png`*","573f9702":"Using the Adam optimiser with learning rate set at 0.001 as this is currently giving the most optimal model.","485fb352":"Creating a helper function for displaying the loss and accuracy versus epochs","343ed6a5":"Creating a bar chart of train data using pandas *bar* function.","b7209ce6":"Loading the train data into 2 lists *images* and *labels*, each storing the image and its corresponding labels. The labels in this case are the type of seedlings as recorded in the dataset.","0ecdb155":"# Plotting a Confusion Matrix\n\nA confusion matrix is plotted below to see how well the model fared with respect to the train dataset. It will allow one to realize towards which class is the model biased against.\n\nA threshold is set at half of the maximum correlation. Above that values are shown in white while below that are shown in black.\n\nBluer the shade of the block stronger the correlation between the predicted value and actual value. This type of matrix can also be shown for train data to show how the model fared there.\n\nThe model can be changed using this confusion matrix as a base calculation.","e899ea8a":"The model is biased towards *Loose Silky Bent*","78ff734f":"# Visualisation of dataset\n\nTo get a feel of the data, exploratory data analysis is done.\n\nThe total number of train images from each subdirectory are stored and used in the bar and pie charts","b9aac24e":"# Loading and Splitting Train Images\n\nImageDataGenerator from Keras is used for making the train dataset. Fora augmentation of images horizontal and vertical flip along with random rotation is used due to the low number of training images.","0af0959d":"Storing the model's weights to *`model_weights.h5`*. This stores the best weights possible.","1028cb39":"# Convolutional Block\n\nCreating a Convolutional block for the model to make it easier to add more layers to the model without making major changes. This also allows for change in architecture without changing every line in the model. It also takes advantage of Python's OOP structure.\n\nThe block consists of:\n\n`One convolutional layer with the user specifed filter size,kernel size, and lenght of strides.`\n`One BatchNormalization Layer.`\n`One Relu Activation Layer`","5d423b43":"The class imbalance can also be inferred from the above pie chart, but this shows that it is not as steep as compared to the bar chart. It is advisable to normalize the count to give a better representation of the data present."}}