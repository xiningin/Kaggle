{"cell_type":{"bdd0b5d2":"code","c9ce3a26":"code","cdbd35ec":"code","fc3bd898":"code","a9701d44":"code","b6e87d72":"code","8066efec":"code","2353a972":"code","8197e3ff":"code","20be3bca":"code","b769a5ae":"code","70c12075":"code","4c1ff31e":"code","e3208eab":"code","1facb156":"markdown","367fc4d0":"markdown","b25ab9c3":"markdown","a710c0c7":"markdown","f3e2f432":"markdown","92004a62":"markdown"},"source":{"bdd0b5d2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c9ce3a26":"\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nplt.style.use('ggplot')\n\ndf = pd.read_csv(\"\/kaggle\/input\/factors-affecting-campus-placement\/Placement_Data_Full_Class.csv\")\ndf.head()","cdbd35ec":"df = df.drop(['sl_no'], axis = 1)\ndf = pd.DataFrame(df)\n","fc3bd898":"sns.countplot(x=\"status\",data=df)","a9701d44":"df[\"salary\"].plot.hist(bins=200,figsize=(20,10))","b6e87d72":"sns.countplot(x=\"status\",hue=\"hsc_s\",data=df)","8066efec":"hsc_s=pd.get_dummies(df[\"hsc_s\"])\ndegree_t=pd.get_dummies(df[\"degree_t\"])\ngender=pd.get_dummies(df[\"gender\"])\nworkex=pd.get_dummies(df[\"workex\"])\nspecialisation=pd.get_dummies(df[\"specialisation\"])\n\ndf = df.drop([\"gender\",\"hsc_s\",\"degree_t\",\"workex\",\"specialisation\",\"ssc_b\",\"hsc_b\",\"salary\"], axis = 1)\ndf\n","2353a972":"df=pd.concat([df,gender\t,hsc_s,degree_t,workex,specialisation],axis=1)\ndf","8197e3ff":"X = df.drop(['status',], axis = 1)\ny = df['status']\n\n\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 43)\n\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\ns=0\na=[]\nfor i in range(2,9):\n    classifier = KNeighborsClassifier(n_neighbors = i)\n    classifier.fit(X_train, y_train)\n\n\n    y_pred = classifier.predict(X_test)\n\n\n\n\n    result2 = accuracy_score(y_test,y_pred)\n    if result2>s:\n        s=result2\n        a=[i,result2]\n        \nprint(\"Highest Accuracy is for n=\",a[0],\"and accuracy is ==\",a[1])\n","20be3bca":"X = df.drop(['status',], axis = 1)\n\ny=pd.get_dummies(df[\"status\"],drop_first=True)\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 43)\n\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\n\nfrom sklearn.linear_model import *\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.svm import SVC # \"Support Vector Classifier\" \n\n\nclassifier = SVC(kernel='linear')\nclassifier.fit(X_train, y_train)\n\n\ny_pred = classifier.predict(X_test)\n\n\n\n\nresult2 = accuracy_score(y_test,y_pred)\n\nprint(\"Accuracy==\",result2)\n","b769a5ae":"X = df.drop(['status',], axis = 1)\n\ny=pd.get_dummies(df[\"status\"],drop_first=True)\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 43)\n\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\n\nfrom sklearn.linear_model import *\nfrom sklearn.metrics import accuracy_score\n\nclassifier = LogisticRegression()\nclassifier.fit(X_train, y_train)\n\n\ny_pred = classifier.predict(X_test)\n\n\n\n\nresult2 = accuracy_score(y_test,y_pred)\n\nprint(\"Accuracy==\",result2)\n","70c12075":"X = df.drop(['status',], axis = 1)\n\ny=pd.get_dummies(df[\"status\"],drop_first=True)\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 43)\n\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n\nclassifier = DecisionTreeClassifier()\nclassifier.fit(X_train, y_train)\n\n\ny_pred = classifier.predict(X_test)\n\n\n\n\nresult2 = accuracy_score(y_test,y_pred)\n\nprint(\"Accuracy==\",result2)\n\n\n\n","4c1ff31e":"X = df.drop(['status',], axis = 1)\n\ny=pd.get_dummies(df[\"status\"],drop_first=True)\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 43)\n\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\nclassifier = RandomForestClassifier()\nclassifier.fit(X_train, y_train)\n\n\ny_pred = classifier.predict(X_test)\n\n\n\n\nresult2 = accuracy_score(y_test,y_pred)\n\nprint(\"Accuracy==\",result2)\n\n\n\n","e3208eab":"X = df.drop(['status',], axis = 1)\n\ny=pd.get_dummies(df[\"status\"],drop_first=True)\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 43)\n\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\n\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)\n\n\ny_pred = classifier.predict(X_test)\n\n\n\n\nresult2 = accuracy_score(y_test,y_pred)\n\nprint(\"Accuracy==\",result2)\n\n\n\n","1facb156":"# # # # # # # # # # # # **naive_bayes**","367fc4d0":"# # # # # # # # # # # # # # # # * **SVM**","b25ab9c3":"# # # # # # # # # # **KNN******","a710c0c7":"# # # # # # # # # # # # **LogisticRegression**","f3e2f432":"# # # # # # # # # **DecisionTreeClassifier**","92004a62":"# # # # # # # # # # **RandomForest**"}}