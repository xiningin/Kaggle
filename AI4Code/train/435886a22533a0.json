{"cell_type":{"ccc5932a":"code","7173c5f1":"code","0c6d850d":"code","734cf536":"code","ce9c71d6":"code","5235c01a":"code","65aaa1c5":"code","1188a660":"code","ec58620c":"code","645b3d57":"code","931cb184":"code","1031fd9e":"code","88fbfd78":"markdown","24025e75":"markdown","ccaae65e":"markdown","bd5fc107":"markdown","891e7856":"markdown","4c27073d":"markdown","7c0bcbbc":"markdown","81836aff":"markdown","d2b47d1a":"markdown","7e72ba6a":"markdown","dd3b4236":"markdown","c67761be":"markdown","87c4a594":"markdown","780cd23f":"markdown"},"source":{"ccc5932a":"import torch\nimport torchvision\nimport torchvision.transforms as transforms","7173c5f1":"transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrainset = torchvision.datasets.CIFAR10(root='.\/data', train=True,\n                                        download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=6,\n                                          shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='.\/data', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=6,\n                                         shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')","0c6d850d":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# functions to show an image\n\n\ndef imshow(img):\n    img = img \/ 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\n# get some random training images\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\n\n# show images\nimshow(torchvision.utils.make_grid(images))\n# print labels\nprint(' '.join('%5s' % classes[labels[j]] for j in range(4)))","734cf536":"import torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\nnet = Net()","ce9c71d6":"import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)","5235c01a":"for epoch in range(5):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 2000 == 1999:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss \/ 2000))\n            running_loss = 0.0\n\nprint('Finished Training')","65aaa1c5":"PATH = '.\/cifar_net.pth'\ntorch.save(net.state_dict(), PATH)","1188a660":"dataiter = iter(testloader)\nimages, labels = dataiter.next()\n\n# print images\nimshow(torchvision.utils.make_grid(images))\nprint('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))","ec58620c":"outputs = net(images)","645b3d57":"_, predicted = torch.max(outputs, 1)\n\nprint('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n                              for j in range(4)))","931cb184":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the 10000 test images: %d %%' % (\n    100 * correct \/ total))","1031fd9e":"class_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = net(images)\n        _, predicted = torch.max(outputs, 1)\n        c = (predicted == labels).squeeze()\n        for i in range(4):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\n\nfor i in range(10):\n    print('Accuracy of %5s : %2d %%' % (\n        classes[i], 100 * class_correct[i] \/ class_total[i]))","88fbfd78":"# Now we will save our model","24025e75":"# Loading and normalizing images using TorchVision\n","ccaae65e":"# Displaying some images","bd5fc107":"![cifar10.png](attachment:cifar10.png)","891e7856":"**The outputs are energies for the 10 classes. The higher the energy for a class, the more the network thinks that the image is of the particular class. So, let\u2019s get the index of the highest energy:**","4c27073d":"# Defining a Convolutional Neural Network","7c0bcbbc":"**Let us look at how the network performs on the whole dataset.**","81836aff":"# Finally we will train our neural network","d2b47d1a":"**Displaying an image from test set**","7e72ba6a":"# Defining a Loss Function and optimizer\n**We will use a classification Cross-Entropy loss and Stochastic Gradient Descent(SGD) with momentum**","dd3b4236":"**We will now see how the neural network predicts the above image**","c67761be":"# Let's test the accuracy of the model","87c4a594":"**Let's see which classes performed well individually**","780cd23f":"> CIFAR10 dataset has 10 classes - \u2018airplane\u2019, \u2018automobile\u2019, \u2018bird\u2019, \u2018cat\u2019, \u2018deer\u2019, \u2018dog\u2019, \u2018frog\u2019, \u2018horse\u2019, \u2018ship\u2019, \u2018truck\u2019. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size."}}