{"cell_type":{"b8df3d48":"code","2bafb0e6":"code","5660fd8e":"code","7f5acf47":"code","a94c9ca0":"code","a8737471":"code","a0fa4498":"code","332b5030":"code","efccca5e":"code","5cb419b1":"code","552a947b":"code","e9ac3cf0":"code","714c8097":"code","fdcbd69c":"code","07209707":"code","94b2b1fd":"code","509bf792":"code","b33d9d7f":"code","89ca9a1d":"code","0b097c76":"code","4c0aadeb":"code","6807ce54":"code","6d12b59d":"code","b3575a36":"code","4413990c":"code","414ab0b5":"code","89688551":"markdown","ebe371b4":"markdown","1cfec06a":"markdown"},"source":{"b8df3d48":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2bafb0e6":"import numpy as np\nimport pandas as pd \nfrom sklearn.model_selection import train_test_split\nimport csv\nfrom sklearn.feature_extraction.text import CountVectorizer,  TfidfVectorizer, HashingVectorizer\nfrom sklearn.ensemble import RandomForestClassifier \nimport nltk\nfrom sklearn.metrics import accuracy_score, confusion_matrix,classification_report\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud","5660fd8e":"train_df = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\ntrain_df.head()","7f5acf47":"test_df = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")\ntest_df.head()","a94c9ca0":"train_df.isnull().sum()","a8737471":"X = train_df.drop([\"id\"],axis=1)\nX.head()","a0fa4498":"key = X[\"keyword\"].value_counts().index[0]\nprint(key)\nloc = X[\"location\"].value_counts().index[0]\nprint(loc)","332b5030":"train_df['keyword'] = train_df['keyword'].fillna(train_df['keyword'].value_counts().idxmax())\ntrain_df['location'] = train_df['location'].fillna(train_df['location'].value_counts().idxmax())\ntrain_df.isnull().sum()","efccca5e":"X_new = train_df.drop([\"target\"],axis=1)\nX_new.head()","5cb419b1":"y = train_df[\"target\"]\ny.shape","552a947b":"test_df.isnull().sum()","e9ac3cf0":"test_df['keyword'] = test_df['keyword'].fillna(test_df['keyword'].value_counts().idxmax())\ntest_df['location'] = test_df['location'].fillna(test_df['location'].value_counts().idxmax())\ntest_df.isnull().sum()\n","714c8097":"X_new = X_new.drop([\"id\"],axis=1)\nX_new.head()","fdcbd69c":"X_new.replace(\"[^a-zA-Z]\", \" \",regex = True, inplace = True)\nX_new.head()","07209707":"for i in X_new.columns:\n    X_new[i] = X_new[i].str.lower()\nX_new.head()","94b2b1fd":"from nltk.corpus import stopwords\nstop = stopwords.words('english')","509bf792":"X_new['keyword'].apply(lambda x: [item for item in x if item not in stop])\nX_new['location'].apply(lambda x: [item for item in x if item not in stop])\nX_new['text'].apply(lambda x: [item for item in x if item not in stop])\nprint(X_new.shape)","b33d9d7f":"ori_test = test_df.drop([\"id\"],axis=1)","89ca9a1d":"ori_test.replace(\"[^a-zA-Z]\", \" \",regex = True, inplace = True)\nori_test.head()","0b097c76":"for i in ori_test.columns:\n    ori_test[i] = ori_test[i].str.lower()\n\nori_test['keyword'].apply(lambda x: [item for item in x if item not in stop])\nori_test['location'].apply(lambda x: [item for item in x if item not in stop])\nori_test['text'].apply(lambda x: [item for item in x if item not in stop])\nprint(ori_test.shape)","4c0aadeb":"X_new[\"sentence\"] = X_new['keyword'] + \" \" + X_new['text']\ntrain_text = np.array(X_new[\"sentence\"])\nprint(train_text[0])\n\n# test dataset\nori_test[\"sentence\"] = ori_test['keyword'] + \" \" + ori_test['text']\ntest_text = np.array(ori_test[\"sentence\"])\nprint(test_text[0])","6807ce54":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(train_text,y,test_size=0.25,random_state=0)\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","6d12b59d":"vectorizer = TfidfVectorizer()\nvectorizer.fit_transform(x_train)\n\nkeyword = vectorizer.get_feature_names()\nX_train = vectorizer.transform(x_train)\nX_test = vectorizer.transform(x_test)\nX_test_new = vectorizer.transform(test_text)","b3575a36":"print(x_train[0])\nprint(\"\\n\")\nprint(X_train[0])","4413990c":"rc = RandomForestClassifier(max_depth = 400 ,random_state=0, n_estimators = 300)\nrc.fit(X_train,y_train) \n\npred1 = rc.predict(X_test)\nmatrix = confusion_matrix(y_test,pred1)\nprint(matrix)\nscore = accuracy_score(y_test,pred1)\nprint(score)\nreport = classification_report(y_test,pred1)\nprint(report)\nprediction1 = rc.predict(X_test_new)\nprediction1\n","414ab0b5":"data = {'id':test_df[\"id\"],'target':prediction1}\noutput = pd.DataFrame(data, columns = ['id','target'])\noutput.index = test_df.index\n\noutput.to_csv(\"submission.csv\", index = False)    \n\n\na = pd.read_csv(\"submission.csv\")\na","89688551":"Text PreProcessing in Test Data\u00b6\n","ebe371b4":"Data PreProcessing\n","1cfec06a":"Text PreProcessing"}}