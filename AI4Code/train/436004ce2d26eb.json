{"cell_type":{"5206ec2b":"code","fe4279dc":"code","8cb13c44":"code","b1fafa49":"code","434ab3da":"code","f76818ca":"code","6856e9a4":"code","3df213f3":"code","cdbfd00c":"code","7a12c5b4":"code","492fd694":"code","cfa64e45":"code","ee7a334a":"code","deaaaa0b":"code","c7e3ffc0":"code","28fe1fa2":"code","d7b5a55c":"code","221c3c13":"code","db4fd270":"code","5ec4a09c":"code","460ae28e":"code","5c05e9fa":"code","efef19e0":"code","fcd4b0d4":"code","427b7a25":"code","30f3c228":"code","98c67687":"code","04bb8cc7":"code","25aa7796":"markdown","1310a18f":"markdown"},"source":{"5206ec2b":"import pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport random\nimport re\nimport math\nimport time\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')","fe4279dc":"!pip install -q efficientnet","8cb13c44":"import tensorflow as tf\nimport tensorflow.keras.backend as K\nimport efficientnet.tfkeras as efn\nfrom kaggle_datasets import KaggleDatasets","b1fafa49":"train = pd.read_csv(\"\/kaggle\/input\/siim-isic-melanoma-classification\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/siim-isic-melanoma-classification\/test.csv\")\nsample = pd.read_csv(\"\/kaggle\/input\/siim-isic-melanoma-classification\/sample_submission.csv\")","434ab3da":"train.head()","f76818ca":"GCS_PATH = KaggleDatasets().get_gcs_path('melanoma-384x384')\nGCS_PATH2 = KaggleDatasets().get_gcs_path('malignant-v2-384x384')\nGCS_PATH3 = KaggleDatasets().get_gcs_path('isic2019-384x384')\nfilenames_train1 = tf.io.gfile.glob(GCS_PATH + '\/train*.tfrec')\nfilenames_train2 = tf.io.gfile.glob(GCS_PATH2 + '\/train%.2i*.tfrec'%(2*x) for x in range(15))\nfilenames_train3 = tf.io.gfile.glob(GCS_PATH3 + '\/train%.2i*.tfrec'%(2*x) for x in range(15))\nfilenames_test = np.array(tf.io.gfile.glob(GCS_PATH + '\/test*.tfrec'))","6856e9a4":"filenames_train = np.array(filenames_train1+filenames_train2+filenames_train3)\nnp.random.shuffle(filenames_train)","3df213f3":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","cdbfd00c":"AUTO = tf.data.experimental.AUTOTUNE","7a12c5b4":"cfg = dict(\n           batch_size=32,\n           img_size=384,\n    \n           lr_start=0.000005,\n           lr_max=0.00000125,\n           lr_min=0.000001,\n           lr_rampup=5,\n           lr_sustain=0,\n           lr_decay=0.8,\n           epochs=12,\n    \n           transform_prob=1.0,\n           rot=180.0,\n           shr=2.0,\n           hzoom=8.0,\n           wzoom=8.0,\n           hshift=8.0,\n           wshift=8.0,\n    \n           optimizer='adam',\n           label_smooth_fac=0.05,\n           tta_steps=20\n            \n        )","492fd694":"def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n\n    # CONVERT DEGREES TO RADIANS\n    rotation = math.pi * rotation \/ 180.\n    shear = math.pi * shear \/ 180.\n\n    # ROTATION MATRIX\n    c1 = tf.math.cos(rotation)\n    s1 = tf.math.sin(rotation)\n    one = tf.constant([1], dtype='float32')\n    zero = tf.constant([0], dtype='float32')\n    rotation_matrix = tf.reshape(\n        tf.concat([c1, s1, zero, -s1, c1, zero, zero, zero, one], axis=0),\n        [3, 3])\n\n    # SHEAR MATRIX\n    c2 = tf.math.cos(shear)\n    s2 = tf.math.sin(shear)\n    shear_matrix = tf.reshape(\n        tf.concat([one, s2, zero, zero, c2, zero, zero, zero, one], axis=0),\n        [3, 3])\n\n    # ZOOM MATRIX\n    zoom_matrix = tf.reshape(\n        tf.concat([\n            one \/ height_zoom, zero, zero, zero, one \/ width_zoom, zero, zero,\n            zero, one\n        ],axis=0), [3, 3])\n\n    # SHIFT MATRIX\n    shift_matrix = tf.reshape(\n        tf.concat(\n            [one, zero, height_shift, zero, one, width_shift, zero, zero, one],\n            axis=0), [3, 3])\n\n    return K.dot(K.dot(rotation_matrix, shear_matrix),\n                 K.dot(zoom_matrix, shift_matrix))\n","cfa64e45":"def transform(image, cfg):\n    \n    DIM = cfg['img_size']\n    XDIM = DIM % 2  # fix for size 331\n\n    rot = cfg['rot'] * tf.random.normal([1], dtype='float32')\n    shr = cfg['shr'] * tf.random.normal([1], dtype='float32')\n    h_zoom = 1.0 + tf.random.normal([1], dtype='float32') \/ cfg['hzoom']\n    w_zoom = 1.0 + tf.random.normal([1], dtype='float32') \/ cfg['wzoom']\n    h_shift = cfg['hshift'] * tf.random.normal([1], dtype='float32')\n    w_shift = cfg['wshift'] * tf.random.normal([1], dtype='float32')\n\n    # GET TRANSFORMATION MATRIX\n    m = get_mat(rot, shr, h_zoom, w_zoom, h_shift, w_shift)\n\n    # LIST DESTINATION PIXEL INDICES\n    x = tf.repeat(tf.range(DIM \/\/ 2, -DIM \/\/ 2, -1), DIM)\n    y = tf.tile(tf.range(-DIM \/\/ 2, DIM \/\/ 2), [DIM])\n    z = tf.ones([DIM * DIM], dtype='int32')\n    idx = tf.stack([x, y, z])\n\n    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n    idx2 = K.dot(m, tf.cast(idx, dtype='float32'))\n    idx2 = K.cast(idx2, dtype='int32')\n    idx2 = K.clip(idx2, -DIM \/\/ 2 + XDIM + 1, DIM \/\/ 2)\n\n    # FIND ORIGIN PIXEL VALUES\n    idx3 = tf.stack([DIM \/\/ 2 - idx2[0, ], DIM \/\/ 2 - 1 + idx2[1, ]])\n    d = tf.gather_nd(image, tf.transpose(idx3))\n\n    return tf.reshape(d, [DIM, DIM, 3])","ee7a334a":"def dropout(image, DIM=384, PROBABILITY = 0.75, CT = 8, SZ = 0.2):\n    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n    # output - image with CT squares of side size SZ*DIM removed\n    \n    # DO DROPOUT WITH PROBABILITY DEFINED ABOVE\n    P = tf.cast( tf.random.uniform([],0,1)<PROBABILITY, tf.int32)\n    if (P==0)|(CT==0)|(SZ==0): return image\n    \n    for k in range(CT):\n        # CHOOSE RANDOM LOCATION\n        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n        # COMPUTE SQUARE \n        WIDTH = tf.cast( SZ*DIM,tf.int32) * P\n        ya = tf.math.maximum(0,y-WIDTH\/\/2)\n        yb = tf.math.minimum(DIM,y+WIDTH\/\/2)\n        xa = tf.math.maximum(0,x-WIDTH\/\/2)\n        xb = tf.math.minimum(DIM,x+WIDTH\/\/2)\n        # DROPOUT IMAGE\n        one = image[ya:yb,0:xa,:]\n        two = tf.zeros([yb-ya,xb-xa,3]) \n        three = image[ya:yb,xb:DIM,:]\n        middle = tf.concat([one,two,three],axis=1)\n        image = tf.concat([image[0:ya,:,:],middle,image[yb:DIM,:,:]],axis=0)\n            \n    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR \n    image = tf.reshape(image,[DIM,DIM,3])\n    return image","deaaaa0b":"def prepare_image(img, cfg=None,droprate=0.5,dropct=8,dropsize=0.2):\n    \n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, [cfg['img_size'], cfg['img_size']],\n                          antialias=True)\n    img = tf.cast(img, tf.float32) \/ 255.0\n\n    if cfg['transform_prob'] > tf.random.uniform([1], minval=0, maxval=1):\n        img = transform(img, cfg)\n    \n    if (tf.random.uniform([1], minval=0, maxval=1) > 0.5) & (droprate!=0)&(dropct!=0)&(dropsize!=0):\n        img = dropout(img, DIM=384, PROBABILITY=droprate, CT=dropct, SZ=dropsize)\n\n    img = tf.image.random_flip_left_right(img)\n    img = tf.image.random_saturation(img, 0.7, 1.3)\n    img = tf.image.random_contrast(img, 0.8, 1.2)\n    img = tf.image.random_brightness(img, 0.1)\n\n    return img","c7e3ffc0":"def read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'image_name': tf.io.FixedLenFeature([], tf.string),\n        'target': tf.io.FixedLenFeature([], tf.int64)\n    }\n\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    return example['image'], example['target']\n","28fe1fa2":"def read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'image_name': tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    return example['image'], example['image_name']\n\n","d7b5a55c":"def count_data_items(filenames):\n    n = [\n        int(re.compile(r'-([0-9]*)\\.').search(filename).group(1))\n        for filename in filenames\n    ]\n    return np.sum(n)","221c3c13":"def getTrainDataset(files, cfg):\n    \n    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n    ds = ds.cache()\n\n    opt = tf.data.Options()\n    opt.experimental_deterministic = False\n    ds = ds.with_options(opt)\n\n    ds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n    ds = ds.repeat()\n    \n    ds = ds.shuffle(2048)\n    ds = ds.map(lambda img, label:\n                (prepare_image(img, cfg=cfg), label),\n                num_parallel_calls=AUTO)\n    ds = ds.batch(cfg['batch_size'] * strategy.num_replicas_in_sync)\n    ds = ds.prefetch(AUTO)\n    return ds\n","db4fd270":"\ndef getTestDataset(files, cfg, augment=False, repeat=False):\n    \n    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n    ds = ds.cache()\n    if repeat:\n        ds = ds.repeat()\n    ds = ds.map(read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n    ds = ds.map(lambda img, idnum:\n                (prepare_image(img, cfg=cfg), idnum),\n                num_parallel_calls=AUTO)\n    ds = ds.batch(cfg['batch_size'] * strategy.num_replicas_in_sync)\n    ds = ds.prefetch(AUTO)\n    return ds","5ec4a09c":"def getLearnRateCallback(cfg):\n    \n    lr_start = cfg['lr_start']\n    lr_max = cfg['lr_max'] * strategy.num_replicas_in_sync * cfg['batch_size']\n    lr_min = cfg['lr_min']\n    lr_rampup = cfg['lr_rampup']\n    lr_sustain = cfg['lr_sustain']\n    lr_decay = cfg['lr_decay']\n\n    def lrfn(epoch):\n        if epoch < lr_rampup:\n            lr = (lr_max - lr_start) \/ lr_rampup * epoch + lr_start\n        elif epoch < lr_rampup + lr_sustain:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_rampup -\n                                                lr_sustain) + lr_min\n        return lr\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n    return lr_callback","460ae28e":"with strategy.scope():\n    model_input = tf.keras.Input(shape=(cfg['img_size'], cfg['img_size'], 3),\n                                 name='img_input')\n\n    dummy = tf.keras.layers.Lambda(lambda x: x)(model_input)\n\n    outputs = []\n\n    x = efn.EfficientNetB3(include_top=False,\n                           weights='noisy-student',\n                           input_shape=(cfg['img_size'], cfg['img_size'], 3),\n                           pooling='avg')(dummy)\n    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n    outputs.append(x)\n\n    x = efn.EfficientNetB4(include_top=False,\n                           weights='noisy-student',\n                           input_shape=(cfg['img_size'], cfg['img_size'], 3),\n                           pooling='avg')(dummy)\n    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n    outputs.append(x)\n\n    x = efn.EfficientNetB5(include_top=False,\n                           weights='noisy-student',\n                           input_shape=(cfg['img_size'], cfg['img_size'], 3),\n                           pooling='avg')(dummy)\n    x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n    outputs.append(x)\n    \n    model = tf.keras.Model(model_input, outputs, name='aNetwork')\n\n    model.compile(optimizer=cfg['optimizer'],\n                  loss=[\n                      tf.keras.losses.BinaryCrossentropy(\n                          label_smoothing=cfg['label_smooth_fac']),\n                      tf.keras.losses.BinaryCrossentropy(\n                          label_smoothing=cfg['label_smooth_fac']),\n                      tf.keras.losses.BinaryCrossentropy(\n                          label_smoothing=cfg['label_smooth_fac'])\n                  ],\n                  metrics=[tf.keras.metrics.AUC(name='auc')])\n","5c05e9fa":"model.summary()","efef19e0":"ds_train = getTrainDataset(filenames_train, cfg).map(lambda img, label: (img, (label, label, label)))\n\nstepsTrain = count_data_items(filenames_train) \/(cfg['batch_size'] * strategy.num_replicas_in_sync)","fcd4b0d4":"callbacks = [getLearnRateCallback(cfg)]\n\nhistory = model.fit(ds_train,\n                    validation_data=None,\n                    verbose=1,\n                    steps_per_epoch=stepsTrain,\n                    validation_steps=0,\n                    epochs=10,\n                    callbacks=callbacks)","427b7a25":"steps = count_data_items(filenames_test) \/ (cfg['batch_size'] * strategy.num_replicas_in_sync)\nz = np.zeros((cfg['batch_size'] * strategy.num_replicas_in_sync))\n\nds_testAug = getTestDataset(filenames_test, cfg, augment=True,\n    repeat=True).map(lambda img, label: (img, (z, z, z)))\n\nprobs = model.predict(ds_testAug, verbose=1, steps=steps * cfg['tta_steps'])","30f3c228":"probs = np.stack(probs)\nprobs = probs[:, :count_data_items(filenames_test) * cfg['tta_steps']]\nprobs = np.stack(np.split(probs, cfg['tta_steps'], axis=1), axis=1)\nprobs = np.mean(probs, axis=1)","98c67687":"y_test_sorted = np.zeros((3, probs.shape[1]))\ntest = test.reset_index()\ntest = test.set_index('image_name')\n\ni = 0\nds_test = getTestDataset(filenames_test, cfg)\nfor img, imgid in tqdm(iter(ds_test.unbatch())):\n    imgid = imgid.numpy().decode('utf-8')\n    y_test_sorted[:, test.loc[imgid]['index']] = probs[:, i, 0]\n    i += 1\n\nfor i in range(y_test_sorted.shape[0]):\n    submission = sample\n    submission['target'] = y_test_sorted[i]\n    submission.to_csv('model_%s.csv' % i, index=False)\n\nsubmission = sample\nsubmission['target'] = np.mean(y_test_sorted, axis=0)\nsubmission.to_csv('ensembled.csv', index=False)","04bb8cc7":"!gzip model_0.csv\n!gzip model_1.csv\n!gzip model_2.csv\n!gzip ensembled.csv","25aa7796":"In this notebook I have used Chris deotte's 4000 Malignant images as well as ISIC 2019 data for traning\n1. TTA (Test Time augmentation) - 20 steps\n2. EfficientNetB3, EfficientNetB4 and EfficientB5.\n3. coarse dropout [refer here for dropout explanation](https:\/\/www.kaggle.com\/cdeotte\/tfrecord-experiments-upsample-and-coarse-dropout)\n3. Ensembled output of B3,B4 and B5.","1310a18f":"# SIMM - ISIC Melanoma"}}