{"cell_type":{"d4089dd6":"code","f21ecb08":"code","d43682a2":"code","327efc0a":"code","11ca40f7":"code","fa024ac0":"code","31cd935f":"code","8e461d20":"code","e74c2677":"code","e53e27d5":"code","f5592059":"code","2b5da197":"code","b291d88f":"code","2d06688c":"code","534db61b":"markdown","3f2bc32e":"markdown","3cc3d55d":"markdown","486eaf29":"markdown","a44ed480":"markdown","49707b8c":"markdown","6a2d35dc":"markdown","0da13249":"markdown","3f8f6134":"markdown","3fdbb087":"markdown","a1f1f5b7":"markdown","a3e8b584":"markdown"},"source":{"d4089dd6":"import os\nimport sys\nimport time\nimport glob\nfrom pathlib import Path\n\nimport pandas as pd\nimport numpy as np\n\n# Parallel processing\nfrom joblib import Parallel\nfrom joblib import delayed\n\n# Preprocess\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\n\n# Evaluation\nfrom sklearn.metrics import r2_score\n\n# Visullize\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Modeling\nimport lightgbm as lgb\n\n# Others\nimport warnings\nwarnings.simplefilter(\"ignore\")\n","f21ecb08":"# Dataset path\ndata_path = Path('..\/input\/optiver-realized-volatility-prediction')\n\n# setting display option\npd.options.display.max_columns = 50","d43682a2":"# Objective variable\ntarget = 'target'\n\n# submission file setting\nsubmit_file = 'submission.csv'\nId_column = 'row_id'","327efc0a":"#\u3000Log Return\ndef log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff() \n\n# Realized Volatility\ndef realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))","11ca40f7":"# WAP calculation\ndef wap_calculation1(df):\n    return (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) \/ (df['bid_size1'] + df['ask_size1'])\n\ndef wap_calculation2(df):\n    return (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']) \/ (df['bid_size2'] + df['ask_size2'])","fa024ac0":"# RMSPE\ndef rmspe(y_true, y_pred):\n    return  (np.sqrt(np.mean(np.square((y_true - y_pred) \/ y_true))))","31cd935f":"def book_preprocessing(stock_id : int, data_type = 'train'):\n    # read data\n    df = pd.read_parquet(data_path \/ f'book_{data_type}.parquet\/stock_id={stock_id}\/')\n    \n    # set stock_id\n    df['stock_id'] = stock_id\n    \n    # WAP calculation\n    df['wap1'] = wap_calculation1(df)\n    df['wap2'] = wap_calculation2(df)\n    \n    # log return calculation\n    df['log_return1'] = df.groupby(['time_id'])['wap1'].apply(log_return).fillna(0)\n    df['log_return2'] = df.groupby(['time_id'])['wap2'].apply(log_return).fillna(0)    \n    # Log_return calculation each stock_id and time_id\n    df_realized_vol_per_stock = pd.DataFrame(df.groupby(['stock_id','time_id'])[['log_return1','log_return2']].agg(realized_volatility)).reset_index()\n    \n    return df_realized_vol_per_stock","8e461d20":"df_book = book_preprocessing(97, 'train')\ndf_book.head()","e74c2677":"def trade_preprocessing(stock_id : int, data_type = 'train'):\n    # read data\n    df = pd.read_parquet(data_path \/ f'trade_{data_type}.parquet\/stock_id={stock_id}\/')\n    \n    df = df.sort_values(by=['time_id', 'seconds_in_bucket']).reset_index(drop=True)\n    \n    # set stock_id\n    df['stock_id'] = stock_id\n    \n    # log return calculation\n    df['trade_log_return1'] = df.groupby(by = ['time_id'])['price'].apply(log_return).fillna(0)\n    \n    # Log_return calculation each stock_id and time_id\n    df = pd.DataFrame(df.groupby(['stock_id','time_id'])[['trade_log_return1']].agg(realized_volatility).reset_index())\n    \n    return df","e53e27d5":"df_trade = trade_preprocessing(0,'train')\ndf_trade.head()","f5592059":"def get_stock_stat(stock_id : int, data_type = 'train'):\n    \n    # parquet data processing\n    book_stat = book_preprocessing(stock_id, data_type)\n    trade_stat = trade_preprocessing(stock_id, data_type)\n    \n    #Merge book and trade features\n    stock_stat = book_stat.merge(trade_stat, on=['stock_id', 'time_id'], how='left').fillna(-999)\n    \n    return stock_stat","2b5da197":"def get_dataSet(stock_ids : list, data_type = 'train'):\n    # Parallel process of get_stock_stat \n    stock_stat = Parallel(n_jobs=-1)(\n        delayed(get_stock_stat)(stock_id, data_type) \n        for stock_id in stock_ids\n    )\n    # concat several stock_stats in vertical direction, axis=0(default)\n    stock_stat_df = pd.concat(stock_stat, ignore_index = True)\n\n    return stock_stat_df","b291d88f":"train=pd.read_csv(data_path \/ 'train.csv')\ntrain['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\ndisplay(train.head())\nprint('train data shape:', train.shape)","2d06688c":"train_stock_stat_df = get_dataSet(stock_ids = train['stock_id'].unique(), data_type = 'train')\n\n# Merge train with train_stock_stat_df\ntrain = pd.merge(train, train_stock_stat_df, on = ['stock_id', 'time_id'], how = 'left')\nprint(f'Train shape: {train.shape}')\ndisplay(train.head(5))\n\ntrain.to_pickle('train.pkl')","534db61b":"# 4. Preprocessing dataset","3f2bc32e":"# Agenda\n\n1. Import modules  \n2. Common settings\n3. Function Definition\n4. Preprocessing  \n  4-1. Book parquet data processing  \n  4-2. Trade parquet data processing  \n  4-3. Merge book and trade data  \n  4-4. Train data preprocessing  \n  4-5. Test data preprocessing  \n5. Training  \n  5-1. Training function1 - Light GBM  \n  5-2. Cross Validation  \n6. Evaluation\n7. Prediction  \n8. Submission\n","3cc3d55d":"This notebook shows simple flow to deep dive into the competition.I appreciate community of kaggle.\nI refered to following notebooks.\n\n(Reference)  \n**Introduction to financial concepts and data**  \nhttps:\/\/www.kaggle.com\/jiashenliu\/introduction-to-financial-concepts-and-data  \n\n**LGB Starter**  \nhttps:\/\/www.kaggle.com\/manels\/lgb-starter\/notebook","486eaf29":"## 4-2. Trade parquet data processing","a44ed480":"## 4-3. Merge book and trade data  \nMerge two data created by preprocessed with book_preprocessing and trade_preprocessing function","49707b8c":"# 3. Functions Definition  ","6a2d35dc":"Check data content of one sample with trade_preprocessing function\ne.g. stock_id = 0","0da13249":"# 2. Common Settings","3f8f6134":"## 4-1. Book parquet data processing","3fdbb087":"# 1. Import modules","a1f1f5b7":"Check data content of one sample with book_preprocessing function  \ne.g. stock_id = 97","a3e8b584":"## 4-4. Train data preprocessing"}}