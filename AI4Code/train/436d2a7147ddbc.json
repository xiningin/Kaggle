{"cell_type":{"3379895d":"code","fab568c0":"code","fccc2978":"code","4f381cde":"code","26bedfe8":"code","09d46cbf":"code","6b039af7":"code","8020b299":"code","2969e653":"code","816e019d":"code","dba059d2":"code","54da152f":"code","ac0fbf22":"code","476f210c":"markdown","3bd598e2":"markdown","26ca4f09":"markdown","48a95cc4":"markdown","f8cac13d":"markdown","4ab0cd64":"markdown","fa016b63":"markdown"},"source":{"3379895d":"!git clone https:\/\/github.com\/tonyduan\/matrix-completion.git\nimport numpy as np\nimport pandas as pd\nimport random\nimport sys\nimport os\n\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.sparse.linalg import svds\n\nsys.path.insert(1, '\/kaggle\/working\/matrix-completion')\nfrom matrix_completion import svt_solve, calc_unobserved_rmse\n\nrandom.seed(123)","fab568c0":"ratings_list = [i.strip().split(\"::\") for i in open('\/kaggle\/input\/movielens-1m-dataset\/ratings.dat', 'r').readlines()]\nratings_df = pd.DataFrame(ratings_list, columns = ['UserID', 'MovieID', 'Rating', 'Timestamp'], dtype = int)\nratings_df['Rating']=ratings_df['Rating'].apply(pd.to_numeric)\nratings_df.head(3)","fccc2978":"R_df = ratings_df.pivot(index = 'UserID', columns ='MovieID', values = 'Rating').fillna(0)\nR_df.head(3)","4f381cde":"R = R_df.values\nuser_ratings_mean = np.mean(R, axis = 1)\nR_demeaned = R - user_ratings_mean.reshape(-1, 1)","26bedfe8":"def create_test_set(R_demeaned):\n    rated_indices = np.argwhere(R_demeaned>0)\n    test_set = random.sample(list(rated_indices),2500)\n    test_ratings = []\n    for i in range(len(test_set)):\n        test_ratings.append(R_demeaned[test_set[i][0],test_set[i][1]])\n        R_demeaned[test_set[i][0],test_set[i][1]]=0\n    return test_ratings, test_set\n\ntest_ratings, test_set = create_test_set(R_demeaned)","09d46cbf":"U, sigma, Vt = svds(R_demeaned, k = 50)\nsigma = np.diag(sigma)","6b039af7":"def create_results_df(R_hat, user_ratings_mean, test_set, R_df):\n    predicted_ratings = R_hat + user_ratings_mean.reshape(-1, 1)\n    pred_df = pd.DataFrame(predicted_ratings, columns = R_df.columns)\n    pred_set = [max(predicted_ratings[x[0], x[1]],0) for x in test_set]\n    res_df = pd.DataFrame()\n    res_df[\"act\"] = test_ratings\n    res_df[\"pred\"] = pred_set\n    return res_df, pred_set\nres_df, pred_set = create_results_df(np.dot(np.dot(U,sigma),Vt), user_ratings_mean, test_set, R_df)\nres_df.head()","8020b299":"def calculate_rmse(test_ratings,pred_set):\n    return np.sqrt(mean_squared_error(test_ratings,pred_set))\ncalculate_rmse(test_ratings,pred_set)","2969e653":"mask = np.ones_like(R_demeaned)\nfor i in range(len(test_set)):\n        mask[test_set[i][0],test_set[i][1]]=0\nR_hat = svt_solve(R_demeaned, mask,tau=None, \n        delta=None, \n        epsilon=1e-2,\n        rel_improvement=-0.01,\n        max_iterations=100,\n        algorithm='arpack')\n","816e019d":"res_df, pred_set = create_results_df(R_hat, user_ratings_mean, test_set, R_df)\ncalculate_rmse(test_ratings,pred_set)","dba059d2":"n = min(R_df.shape)\ntaus = [3*n, 4*n, 5*n] # Parameter\n# deltas = [0.5,1,1.5] # Step size\ndeltas = [0.5] # Step size\n# epsilons = [1e-2,1e-3,1e-4] # Tolerance\nepsilons = [1e-3] # Tolerance\n\n# rel_improvements = [-0.01,-0.005,-0.001] # Increment\nrel_improvements = [-0.01] # Increment\n# max_itterations = [10,50,100,150,200]\nmax_itterations = [150]\n# algorithms = ['randomized', 'arpack']\nalgorithms = ['randomized']\n\nrmse_results = np.zeros((len(taus),len(deltas),len(epsilons),len(rel_improvements),len(max_itterations),len(algorithms)))","54da152f":"for tau in range(len(taus)):\n    for delta in range(len(deltas)):\n        for epsilon in range(len(epsilons)):\n            for rel_improvement in range(len(rel_improvements)):\n                for max_itteration in range(len(max_itterations)):\n                    for algorithm in range(len(algorithms)):\n                        R_hat = svt_solve(R_demeaned,\n                                          mask,\n                                          tau=taus[tau],\n                                          delta=deltas[delta],\n                                          epsilon=epsilons[epsilon],\n                                          rel_improvement=rel_improvements[rel_improvement],\n                                          max_iterations=max_itterations[max_itteration],\n                                          algorithm=algorithms[algorithm])\n                        res_df, pred_set = create_results_df(R_hat, user_ratings_mean, test_set, R_df)\n                        rmse_results[tau,delta,epsilon,rel_improvement,max_itteration,algorithm] = calculate_rmse(test_ratings,pred_set)\n                        print(\"tau: %d, delta: %.2f, epsilon: %f, rel_improvement: %f, max_itterations: %d, algorithm: %s\" % (taus[tau], deltas[delta], epsilons[epsilon], rel_improvements[rel_improvement], max_itterations[max_itteration], algorithms[algorithm]))\n                        print(rmse_results[tau,delta,epsilon,rel_improvement,max_itteration,algorithm])\n                        print(\"\")","ac0fbf22":"rmse_results","476f210c":"The SVT algorithm has a few hyperparameters that can be tuned.\nI will test a matrix of these six parameters:","3bd598e2":"# Netflix Problem - Matrix Completion using Singular Value Thresholding\nSay we want to reconstruct a large, mostly sparse matrix, and do it efficiently, one way of doing so will be to use SVT. That is, iterating and recalculating SVD or other algorithm.\n\nI will use the [Lightweight Python library for in-memory matrix completion](https:\/\/github.com\/tonyduan\/matrix-completion#lightweight-python-library-for-in-memory-matrix-completion) implemented by [Tony Duan](https:\/\/github.com\/tonyduan).\n\n","26ca4f09":"As expected, most of it is populated by zeros.\n\nNow let's substruct the mean per every user in order to make sure they are all to scale.","48a95cc4":"Then, let's prepare the test set - 2500 pairs of (user, movie) that would serve as a test set of rating.","f8cac13d":"## Conclusions:\n* It seems that the choice of algorithm does not make any measurable difference.\n* It seems that more itterations do yeild a better result, up to some extent, and then worsen it.\n* Neither rel_improvement nor the choce of epsilon yeild any improvment.\n* Delta should not be larger than 0.5","4ab0cd64":"> Cai, Jian-Feng, Emmanuel J. Cand\u00e8s, and Zuowei Shen. \"A singular value thresholding algorithm for matrix completion.\" SIAM Journal on optimization 20.4 (2010): 1956-1982.\u200f","fa016b63":"Now pivot the rating from the original table to our desired matric:"}}