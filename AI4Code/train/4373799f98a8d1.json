{"cell_type":{"1285cd7d":"code","9b803c16":"code","609b93de":"code","7a1212da":"code","4a242de9":"code","98695d50":"code","30acaa47":"code","5dade5c9":"code","4d7c4d0f":"code","818e04c7":"code","76f755a8":"code","73b11ab8":"code","f2d4da27":"code","fa55619f":"code","3e0f47a2":"code","c537a585":"code","48f60e4b":"code","2b613319":"code","732adc97":"code","6abda81b":"code","c8196c23":"code","65ea7890":"code","e6bdf52d":"code","f92deb59":"code","0c2d15fd":"code","746006da":"code","e429378f":"code","f78215b0":"code","41f40163":"code","d47c8049":"code","33a0c761":"code","82afc630":"code","9bf6f454":"code","565051bd":"code","2239acbd":"code","e22cfcd8":"code","88034b76":"code","c698eb99":"code","9b57cefa":"code","718ce037":"code","b9a67240":"code","cc5aaf60":"code","e6ff5e45":"code","ffbe9a88":"code","43d4038e":"code","9c1fa0a6":"code","6c3c9360":"code","74918756":"code","b3d3e80c":"code","60ace366":"code","4539c8e7":"code","47705ed2":"code","b3171a75":"code","68b3d13f":"code","f94fa2ee":"code","867f4184":"code","407cdb00":"code","11ca4ac8":"code","a6803ba0":"code","15d35c8c":"code","7af4739b":"code","8f31ff38":"code","3807b35c":"code","2c6e5c37":"code","abae1f87":"code","929a633c":"code","efdd95c9":"code","4e85a610":"code","9b250f62":"code","45cc4284":"code","0296f489":"code","6f128e27":"code","904b0df0":"code","279995c7":"code","55641145":"code","4e0b783a":"code","2371c655":"code","13568f7c":"code","5fcbf850":"code","62140626":"code","cf1dbccd":"code","d24bdd92":"code","a3cf795f":"code","fae5178c":"code","ba5c17be":"code","d5597d56":"code","dacb9408":"code","05e3afd0":"code","3b8689a1":"code","342e4713":"code","fb0118e8":"code","aa0c1a27":"code","edf993f8":"code","d62063a5":"code","f28f4a5f":"code","d3993496":"code","ec3f8096":"code","53e4c3b4":"code","cbfa092d":"code","9a8437ae":"code","7365829b":"code","4447feb7":"code","6e1c3e71":"code","1fb4ecb1":"code","09cfc958":"code","f8744581":"code","d39b25f7":"code","d6fd4b9b":"code","2f7d0bd5":"code","023add32":"code","bb75c0d8":"code","85dc5dc3":"code","cd3e0a93":"code","680ea0d0":"code","f4b4d728":"code","733c6824":"code","dc732c0f":"code","90372e02":"code","23fb30e0":"code","23b54ee6":"code","8c19c944":"code","1b1413ff":"code","b179e5e0":"code","6710af58":"code","c7e52a43":"code","32fccdfc":"code","90db7bdc":"code","10c07153":"code","c923f57b":"code","b6c232c2":"code","9c5bab1f":"code","74e1d675":"code","6a7479b8":"code","46115134":"code","7aa55803":"code","3db16a37":"code","1dcc85c5":"code","f608e2dd":"code","78e70fbb":"code","56bef8b2":"code","1680f1a3":"code","978332d4":"code","b125b64c":"code","bc302b32":"code","1bea3529":"code","f0d7f87a":"code","942789a6":"code","992654e9":"code","dd6f51d8":"code","ebee9c3e":"code","ba6f61ba":"code","b207676e":"code","4a492282":"code","0f2d29ae":"code","c81880b1":"code","8608d880":"code","1607d83b":"code","9d92400e":"code","a4ea4692":"code","2217bcb4":"code","781ddca3":"code","1da2f65f":"code","e6f23ddd":"code","848e68ad":"code","70a8d2b4":"code","370193f2":"code","8c77287c":"code","b0cace8d":"code","068bd4c7":"code","225462cc":"code","4d1f4860":"code","ee4f2bd6":"code","d0a9662c":"code","8836f866":"code","74f04eae":"code","4c7934cb":"code","81f9cac7":"code","fcaa7b8d":"code","1e21ff27":"code","f7357fb8":"code","80e8f9b5":"code","a373c875":"code","21795428":"code","4d45bff2":"code","038fde2c":"code","e4d6b8fe":"code","c701a883":"code","b4ca505b":"code","8fdf4a8c":"code","ede9cbe6":"code","19e54085":"code","f33aac0d":"code","45e436e4":"code","6fba826c":"code","b4c10091":"code","3eaf0b12":"code","28aefeac":"code","f06325c5":"code","656d0996":"code","791bdd9b":"code","8cd80513":"code","30eebd3b":"code","e09b9624":"code","dd1e9401":"code","19332828":"code","cdae5654":"code","390d6452":"code","f9051344":"code","3fe7be9f":"code","293e24c7":"code","10cc0f3f":"code","75f76e89":"code","ecee6178":"markdown","635a4f61":"markdown","26dfb5b8":"markdown","73123586":"markdown","1ad811c4":"markdown","6c83ab11":"markdown","d5622ab0":"markdown","3090e69d":"markdown","8c9993fa":"markdown","a4c5973e":"markdown","77ed098c":"markdown","2282e2ea":"markdown","4afc6e3a":"markdown","8bb9326f":"markdown","fe2973a5":"markdown","283226d3":"markdown","24b07bea":"markdown","cbec57e8":"markdown","67904e8b":"markdown","3fe44736":"markdown","56cdf8c5":"markdown","1f8d60b5":"markdown","10bed0b0":"markdown","ebb1cda6":"markdown","3d1dd01f":"markdown","6d803885":"markdown","23d7036b":"markdown","05baa7b3":"markdown","ff85ed07":"markdown","f4d1c915":"markdown","0e4b3158":"markdown","d20b3b80":"markdown","5f3181b4":"markdown","a66b33d3":"markdown","d73273ae":"markdown","6527f0b1":"markdown","8a792498":"markdown","6fbdee86":"markdown","75e22668":"markdown","99d2f405":"markdown","d48efb5b":"markdown","659e7f01":"markdown","d98f0a3a":"markdown","bf5e1b74":"markdown","1e19c5da":"markdown","dd993c0e":"markdown","2510a601":"markdown","903974bc":"markdown","4c471708":"markdown","bca93c36":"markdown","5781dda9":"markdown","6040b10d":"markdown","96404abb":"markdown","ec96cbb4":"markdown","b456f7e6":"markdown","6ca48261":"markdown","646ac514":"markdown","93291fe3":"markdown","51db1c9c":"markdown","b5dbe086":"markdown","cfff9c29":"markdown","2237348e":"markdown"},"source":{"1285cd7d":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport math as mt\nimport missingno as msno\n\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.cluster import KMeans\nimport yellowbrick\nfrom yellowbrick.cluster import KElbowVisualizer\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\n\nfrom sklearn.linear_model import Ridge, Lasso, ElasticNet\nfrom sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV\n\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier , AdaBoostClassifier, ExtraTreesClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\nfrom sklearn.model_selection import train_test_split, cross_val_score,  cross_validate, GridSearchCV , validation_curve, RandomizedSearchCV\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler\nfrom sklearn.metrics import mean_squared_error,r2_score \n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score,roc_auc_score, roc_curve, plot_roc_curve\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom yellowbrick.cluster import KElbowVisualizer\n\n# Geocode Libraries\nfrom geopy.geocoders import Nominatim\nfrom geopy.exc import GeocoderTimedOut\n\nimport warnings\nfrom warnings import simplefilter\nfrom sklearn.exceptions import ConvergenceWarning\nsimplefilter(\"ignore\", category=ConvergenceWarning)\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n\n\n# Configurations:\npd.set_option('display.max_columns', 1500)\npd.set_option('display.float_format', lambda x: '%.6f' % x)\npd.set_option('display.max_rows', 500)\npd.set_option('display.width', 1500)\n\n!pip install openpyxl","9b803c16":"churn = pd.read_excel(\"..\/input\/telco-datasets\/Telco\/Telco_customer_churn.xlsx\") \nchurn.rename(columns={'CustomerID': 'Customer ID'}, inplace=True)\n\ndemographics = pd.read_excel(\"..\/input\/telco-datasets\/Telco\/Telco_customer_churn_demographics.xlsx\")  \n\nlocation = pd.read_excel(\"..\/input\/telco-datasets\/Telco\/Telco_customer_churn_location.xlsx\") \n\npopulation = pd.read_excel(\"..\/input\/telco-datasets\/Telco\/Telco_customer_churn_population.xlsx\")  \n\nservices = pd.read_excel(\"..\/input\/telco-datasets\/Telco\/Telco_customer_churn_services.xlsx\")  \n\nstatus = pd.read_excel(\"..\/input\/telco-datasets\/Telco\/Telco_customer_churn_status.xlsx\")  ","609b93de":"churn.head()","7a1212da":"demographics.head()","4a242de9":"location.head()","98695d50":"population.head()","30acaa47":"services.head()","5dade5c9":"status.head()","4d7c4d0f":"# Merge all tables for creating final data set:\n \ndf_1 = churn.merge(demographics, on='Customer ID', how='inner', suffixes=('', '_drop'))\ndf_2 = df_1.merge(location, on='Customer ID', how='inner', suffixes=('', '_drop'))\ndf_3 = df_2.merge(population, on='Zip Code', how='left', suffixes=('', '_drop'))\ndf_4 = df_3.merge(services, on='Customer ID', how='inner', suffixes=('', '_drop'))\ndf_5 = df_4.merge(status, on='Customer ID', how='inner', suffixes=('', '_drop'))","818e04c7":"df_5.head()","76f755a8":"df_5.drop([col for col in df_5.columns if '_drop' in col], axis=1, inplace=True)\ndf = df_5.copy()","73b11ab8":"df_5.drop(columns=\"Total Charges\", axis=0, inplace=True)\ndf_5.rename(columns={\"Total Charges_drop\": \"Total Charges\"}, inplace=True)","f2d4da27":"df.groupby(['Device Protection',  'Device Protection Plan']).agg({\"Customer ID\": \"count\"})","fa55619f":"df.drop(columns=\"Device Protection Plan\", axis=1, inplace=True)","3e0f47a2":"df[df['Monthly Charge'] - df['Monthly Charges'] >0].head()","c537a585":"df.drop(columns=\"Monthly Charges\", axis=1, inplace=True)","48f60e4b":"df[df['Tenure in Months'] - df['Tenure Months'] >0][['Tenure Months','Tenure in Months']].count()","2b613319":"df = df[~(df['Tenure in Months'] - df['Tenure Months'] >0)]\ndf.drop(columns=\"Tenure in Months\", axis=1, inplace=True)","732adc97":"df.drop(columns=[\"Count\", \"Churn Score\", \"Churn Category\", \"Churn Reason\",\"CLTV\" ], inplace=True)","6abda81b":"df.head()","c8196c23":"df.shape","65ea7890":"df.isnull().sum()","e6bdf52d":"# Selection of Categorical and Numerical Variables:\ndef grab_col_names(dataframe, cat_th=10, car_th=20):\n\n    # cat_cols, cat_but_car\n    location_cols = [col for col in dataframe.columns if (\"zip\" in col.lower() or \"longitude\" in col.lower() or \"latitude\" in col.lower())]\n\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n    \n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n\n    cat_cols = cat_cols + num_but_cat\n\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    # num_cols\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\" and \"ID\" not in col]\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n    num_cols = [col for  col in num_cols if col not in location_cols]\n    \n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'location_cols: {len(location_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n\n    return cat_cols, num_cols, cat_but_car,location_cols\n\ncat_cols, num_cols, cat_but_car, location_cols = grab_col_names(df)","f92deb59":"print(location_cols)","0c2d15fd":"print(cat_cols)","746006da":"print(num_cols)","e429378f":"print(cat_but_car)","f78215b0":"colors  = ( \"darkseagreen\",  \"lightsteelblue\", \"coral\",  \"mediumaquamarine\",\"palegoldenrod\")\nexplodes = [0.05, 0.05]\n\ndf[\"Churn Label\"].value_counts(sort=False).plot.pie(colors=colors,\n                                                    textprops={'fontsize':10}, \n                                                    autopct = '%4.1f',\n                                                    startangle= 90, \n                                                    radius =1, \n                                                    rotatelabels=True,\n                                                    shadow = True, \n                                                    explode = explodes)\nplt.ylabel(\"Churn Distribution\");\n","41f40163":"def cat_summary(dataframe, col_name, plot=False):\n    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n                        \"Ratio\": 100 * dataframe[col_name].value_counts() \/ len(dataframe)}))\n    print(\"##########################################\")\n    if plot:\n        sns.countplot(x=dataframe[col_name], data=dataframe)\n        plt.show()\n\n\nfor col in cat_cols:\n    cat_summary(df, col, plot=True)        ","d47c8049":"df.drop(columns=[\"Country\", \"State\", \"Quarter\"], axis=1, inplace=True)","33a0c761":"def num_summary(dataframe, numerical_col, plot=False):\n    quantiles = [0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99]\n    print(dataframe[numerical_col].describe(quantiles).T)\n    if plot:\n        dataframe[numerical_col].hist(bins=20)\n        plt.xlabel(numerical_col)\n        plt.title(numerical_col)\n        plt.show()\n\nfor col in num_cols:\n    num_summary(df, col, plot=True)         ","82afc630":"# Gender vs Churn\ngb = df.groupby(\"Gender\")[\"Churn Label\"].value_counts().to_frame().rename({\"Churn Label\": \"Number of Customers\"}, axis = 1).reset_index()\n\nsns.barplot(x = \"Gender\",\n            y = \"Number of Customers\", \n            data = gb, hue = \"Churn Label\", \n            palette = sns.color_palette(\"Set2\", 15)).set_title(\"Churn Rates by Gender\");\nplt.show()","9bf6f454":"# Dependents vs Churn\ngb = df.groupby(\"Gender\")[\"Churn Label\"].value_counts().to_frame().rename({\"Churn Label\": \"Number of Customers\"}, axis = 1).reset_index()\n\nsns.barplot(x = \"Gender\",\n            y = \"Number of Customers\", \n            data = gb, hue = \"Churn Label\", \n            palette = sns.color_palette(\"Set2\", 15)).set_title(\"Churn Rates by Dependents\");\nplt.show()","565051bd":"# Contract Types vs Churn\ngb = df.groupby(\"Gender\")[\"Churn Label\"].value_counts().to_frame().rename({\"Churn Label\": \"Number of Customers\"}, axis = 1).reset_index()\n\nsns.barplot(x = \"Gender\",\n            y = \"Number of Customers\", \n            data = gb, hue = \"Churn Label\", \n            palette = sns.color_palette(\"Set2\", 15)).set_title(\"Churn Rates by Contract Types\");\nplt.show()","2239acbd":"\n# Partner Types vs Churn\ngb = df.groupby(\"Gender\")[\"Churn Label\"].value_counts().to_frame().rename({\"Churn Label\": \"Number of Customers\"}, axis = 1).reset_index()\n\nsns.barplot(x = \"Gender\",\n            y = \"Number of Customers\", \n            data = gb, hue = \"Churn Label\", \n            palette = sns.color_palette(\"Set2\", 15)).set_title(\"Churn Rates by Partner\");\nplt.show()","e22cfcd8":"# Referred a Friend vs Churn\ngb = df.groupby(\"Gender\")[\"Churn Label\"].value_counts().to_frame().rename({\"Churn Label\": \"Number of Customers\"}, axis = 1).reset_index()\n\nsns.barplot(x = \"Gender\",\n            y = \"Number of Customers\", \n            data = gb, hue = \"Churn Label\", \n            palette = sns.color_palette(\"Set2\", 15)).set_title(\"Churn Rates by if Referred a Friend or not referred\");\nplt.show()","88034b76":"# Internet Service usage vs Churn\ngb = df.groupby(\"Gender\")[\"Churn Label\"].value_counts().to_frame().rename({\"Churn Label\": \"Number of Customers\"}, axis = 1).reset_index()\n\nsns.barplot(x = \"Gender\",\n            y = \"Number of Customers\", \n            data = gb, hue = \"Churn Label\", \n            palette = sns.color_palette(\"Set2\", 15)).set_title(\"Churn Rates by Internet Service usage\");\nplt.show()","c698eb99":"# Senior Citizens of Churn Rate\ngb = df.groupby(\"Gender\")[\"Churn Label\"].value_counts().to_frame().rename({\"Churn Label\": \"Number of Customers\"}, axis = 1).reset_index()\n\nsns.barplot(x = \"Gender\",\n            y = \"Number of Customers\", \n            data = gb, hue = \"Churn Label\", \n            palette = sns.color_palette(\"Set2\", 15)).set_title(\"Churn Rates of Senior Citizens \");\nplt.show()","9b57cefa":"!pip install lifelines \n\nfrom lifelines.statistics import multivariate_logrank_test\nfrom lifelines import CoxPHFitter\nfrom lifelines import KaplanMeierFitter\nfrom lifelines.statistics import (logrank_test,\n                                  pairwise_logrank_test,\n                                  multivariate_logrank_test,\n                                  survival_difference_at_fixed_point_in_time_test)\n\nplt.style.use('seaborn')","718ce037":"eventvar = df['Churn Value']\ntimevar = df['Tenure Months']\nkmf = KaplanMeierFitter()\n\n\n# Calculate the K-M curve for all groups\nkmf.fit(timevar,event_observed = eventvar,label = \"All Customers\")\n#Plot the curve and assign labels\nkmf.plot()\nplt.ylabel('Probability of Customer Survival')\nplt.xlabel('Tenure')\nplt.title('Kaplan-Meier Curve');\nplt.show()","b9a67240":"# Survival Analysis by Tech Support\n\nno_internetService = (df['Tech Support'] == \"No internet service\")\nTechSupport = (df['Tech Support'] == \"Yes\")\nno_TechSupport = (df['Tech Support'] == \"No\")\n\nplt.figure()\nax = plt.subplot(1, 1, 1)\n\nkmf.fit(timevar[no_internetService], event_observed=eventvar[no_internetService], label=\"No Internet Service\")\nplot1 = kmf.plot(ax=ax)\n\nkmf.fit(timevar[TechSupport], event_observed=eventvar[TechSupport], label=\"Tech Support\")\nplot2 = kmf.plot(ax=plot1)\n\nkmf.fit(timevar[no_TechSupport], event_observed=eventvar[no_TechSupport], label=\"No Tech Support\")\nplot3 = kmf.plot(ax=plot2)\n\nplt.title('Survival of customers: Tech Support')\nplt.xlabel('Tenure')\nplt.ylabel('Survival Probability')\nplt.yticks(np.linspace(0, 1, 11))\ntwoplusgroups_logrank = multivariate_logrank_test(df['Tenure Months'], df['Tech Support'], df['Churn Value'], alpha=0.95)\ntwoplusgroups_logrank.print_summary()\nplt.show() ","cc5aaf60":"# Survival Analysis by Contract Types:\n\nContract_One_year = (df['Contract'] == \"One year\")\nContract_Two_year = (df['Contract'] == \"Two year\")\nContract_month_to_month = (df['Contract'] == \"Month-to-month\")\n\nplt.figure()\nax = plt.subplot(1, 1, 1)\n\nkmf.fit(timevar[Contract_One_year], event_observed=eventvar[Contract_One_year], label=\"One year Contract\")\nplot1 = kmf.plot(ax=ax)\n\nkmf.fit(timevar[Contract_Two_year], event_observed=eventvar[Contract_Two_year], label=\"Two year Contract\")\nplot2 = kmf.plot(ax=plot1)\n\nkmf.fit(timevar[Contract_month_to_month], event_observed=eventvar[Contract_month_to_month],\n        label=\"Month to month Contract\")\nplot3 = kmf.plot(ax=plot2)\n\nplt.title('Survival of customers: Contract')\nplt.xlabel('Tenure')\nplt.ylabel('Survival Probability')\nplt.yticks(np.linspace(0, 1, 11))\ntwoplusgroups_logrank = multivariate_logrank_test(df['Tenure Months'], df['Contract'], df['Churn Value'], alpha=0.95)\ntwoplusgroups_logrank.print_summary()\nplt.show()","e6ff5e45":"# Survival Analysis by Gender \n\nmale = (df[\"Gender\"] == \"Male\")\nfemale = (df[\"Gender\"] == \"Female\")\n\nplt.figure()\nax = plt.subplot(1, 1, 1)\n\nkmf.fit(timevar[male], event_observed=eventvar[male], label=\"Male\")\nplot1 = kmf.plot(ax=ax)\n\nkmf.fit(timevar[female], event_observed=eventvar[female], label=\"Female\")\nplot2 = kmf.plot(ax=plot1)\n\nplt.title('Survival of customers: Gender')\nplt.xlabel('Tenure')\nplt.ylabel('Survival Probability')\nplt.yticks(np.linspace(0, 1, 11))\ngroups = logrank_test(timevar[male], timevar[female], event_observed_A=eventvar[male],\n                      event_observed_B=eventvar[female])\ngroups.print_summary()\nplt.show()","ffbe9a88":"# Survival Analysis of Senior Citizen \n\nSeniorCitizen = (df['Senior Citizen'] == \"Yes\")\nno_SeniorCitizen = (df['Senior Citizen'] == \"No\")\n\nplt.figure()\nax = plt.subplot(1, 1, 1)\n\nkmf.fit(timevar[SeniorCitizen], event_observed=eventvar[SeniorCitizen], label=\"Senior Citizen\")\nplot1 = kmf.plot(ax=ax)\n\nkmf.fit(timevar[no_SeniorCitizen], event_observed=eventvar[no_SeniorCitizen], label=\"Not a Senior Citizen\")\nplot2 = kmf.plot(ax=plot1)\n\nplt.title('Survival of customers: Senior Citizen')\nplt.xlabel('Tenure')\nplt.ylabel('Survival Probability')\nplt.yticks(np.linspace(0, 1, 11))\ngroups = logrank_test(timevar[SeniorCitizen], timevar[no_SeniorCitizen], event_observed_A=eventvar[SeniorCitizen],\n                      event_observed_B=eventvar[no_SeniorCitizen])\ngroups.print_summary()\nplt.show()","43d4038e":"# Survival Analysis by Internet Service\n\nFiber_optic = (df['Internet Service'] == \"Fiber optic\")\nNo_Service = (df['Internet Service'] == \"No\")\nDSL = (df['Internet Service']== \"DSL\")\n\nplt.figure()\nax = plt.subplot(1, 1, 1)\n\nkmf.fit(timevar[Fiber_optic], event_observed=eventvar[Fiber_optic], label=\"Fiber optic\")\nplot1 = kmf.plot(ax=ax)\n\nkmf.fit(timevar[No_Service], event_observed=eventvar[No_Service], label=\"No Service\")\nplot2 = kmf.plot(ax=plot1)\n\nkmf.fit(timevar[DSL], event_observed=eventvar[DSL], label=\"DSL\")\nplot3 = kmf.plot(ax=plot2)\n\nplt.title('Survival of customers: Internet Service')\nplt.xlabel('Tenure')\nplt.ylabel('Survival Probability')\nplt.yticks(np.linspace(0, 1, 11))\ntwoplusgroups_logrank = multivariate_logrank_test(df['Tenure Months'], df['Internet Service'], df['Churn Value'], alpha=0.95)\ntwoplusgroups_logrank.print_summary()\nplt.show()\n","9c1fa0a6":"# Survival Analysis by Payment Method:\n\nautomatic_Credit_Card = (df['Payment Method'] == \"Credit card (automatic)\")\nelectronic_check = (df['Payment Method'] == \"Electronic check\")\nmailed_check = (df['Payment Method'] == \"Mailed check\")\nautomatic_Bank_Transfer = (df['Payment Method'] == \"Bank transfer (automatic)\")\n\nplt.figure()\nax = plt.subplot(1, 1, 1)\n\nkmf.fit(timevar[automatic_Credit_Card], event_observed=eventvar[automatic_Credit_Card],label=\"Automatic Credit card Payment\")\nplot1 = kmf.plot(ax=ax)\n\nkmf.fit(timevar[electronic_check], event_observed=eventvar[electronic_check], label=\"Electronic Check\")\nplot2 = kmf.plot(ax=plot1)\n\nkmf.fit(timevar[mailed_check], event_observed=eventvar[mailed_check], label=\"Mailed_check\")\nplot3 = kmf.plot(ax=plot2)\n\nkmf.fit(timevar[automatic_Bank_Transfer], event_observed=eventvar[automatic_Bank_Transfer],\n        label=\"Automatic Bank Transfer\")\nplot4 = kmf.plot(ax=plot3)\n\nplt.title('Survival of customers: PaymentMethod')\nplt.xlabel('Tenure Months')\nplt.ylabel('Survival Probability')\nplt.yticks(np.linspace(0, 1, 11))\ntwoplusgroups_logrank = multivariate_logrank_test(df['Tenure Months'], df['Payment Method'], df['Churn Value'], alpha=0.95)\ntwoplusgroups_logrank.print_summary()\nplt.show()","6c3c9360":"# Missing Values :  Check the features containing NaN values\n\ndef missing_values_df(dataframe, na_name=False):\n    na_column = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0] # missing de\u011fer iceren kolon ad\u0131\n    n_miss = dataframe[na_column].isnull().sum().sort_values(ascending=False) # bo\u015f g\u00f6zlem say\u0131s\u0131\n    ratio = (dataframe[na_column].isnull().sum() * 100\/ dataframe.shape[0]).sort_values(ascending=False)\n    missing_df = pd.DataFrame({\"n_miss\":n_miss, \"n_miss_ratio\":ratio})\n    # missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])\n    print(missing_df, end=\"\\n\")\n    if na_name:\n        return na_column\n    \nmissing_values_df(df)","74918756":"def outlier_thresholds(dataframe, col_name, q1=0.05, q3=0.95):\n    q1 = dataframe[col_name].quantile(q1)  # 1.\u00c7eyrek\n    q3 = dataframe[col_name].quantile(q3)  # 3.\u00c7eyrek\n    interquantile_range = q3 - q1  # range'i hesaplayal\u0131m\n    low_limit = q1 - 1.5 * interquantile_range # low & up limit:\n    up_limit = q3 + 1.5 * interquantile_range\n    return low_limit, up_limit","b3d3e80c":"# Let's check if features include outliers :\n\ndef check_outlier(dataframe, col_name, q1=0.10, q3=0.90):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n        return True\n    else:\n        return False\n    \n    \nfor col in num_cols:\n    print(col, \":\", check_outlier(df, col))\n","60ace366":"outlier_variables = [\"Number of Dependents\", \"Total Refunds\"]","4539c8e7":"for  var in outlier_variables:\n    sns.distplot(df[var], kde=True, bins=10)\n    plt.show();\n","47705ed2":"# for  var in outlier_variables:\nfor var in outlier_variables:\n    sns.violinplot(var, data=df, linewidth = 3, palette=\"Set2\", split=True)\n    fig = plt.figure(figsize =(1, 1));\n    plt.show();","b3171a75":"num_cols = grab_col_names(df)[1]","68b3d13f":"cat_cols, num_cols, cat_but_car, location_cols = grab_col_names(df)\n\nexclude_cols = [\"Zip Code\",\"Latitude\", \"Longitude\", \"ID\", \"Churn Value\"]\nnum_cols = [col for col in num_cols if  col  not in exclude_cols]\n\ndf_ = df[num_cols]\ndf_.head(10)","f94fa2ee":"clf = LocalOutlierFactor(n_neighbors=5)\nclf.fit_predict(df_)","867f4184":"df_scores = clf.negative_outlier_factor_\ndf_scores[0:10]","407cdb00":"# LOF Visualization: \n\nscores = pd.DataFrame(np.sort(df_scores))\nscores[0:5]","11ca4ac8":"scores.plot(stacked=True, xlim=[0, 10], style='.-')\nplt.show()","a6803ba0":"scores[0:2]","15d35c8c":"# Let's look at the observations which are below selected LOF threshold value and then remove this observations:\n\nth = -1.961516\ndf[df_scores < th].head()","7af4739b":"df.drop(df[df_scores < th].index, inplace=True)","8f31ff38":"df.head(2)","3807b35c":"df[\"City\"].nunique()","2c6e5c37":"geolocator = Nominatim(user_agent=\"geoapiExercises\")\n\ndf['New_Location_Coordinate'] = df.apply(lambda x: str(x['Latitude']) + \",\"+ str(x['Longitude']),axis = 1)  \ndf['New_Location_Coordinate'].head(2)","abae1f87":"lc_unique =  pd.DataFrame({\"LC\":df[\"New_Location_Coordinate\"].unique()} )\nlc_unique.shape","929a633c":"# Address Detail:\n\nlc_unique['New_Location'] =  lc_unique.apply(lambda x: geolocator.reverse(x['LC'], timeout=10000000),axis = 1)","efdd95c9":"lc_unique.head(10)","4e85a610":"lc_unique['New_Location_Address'] =  lc_unique.apply(lambda x: x['New_Location'].raw['address'],axis = 1)\n\nlc_unique.head()","9b250f62":"lc_unique[\"New_Address_Aeroway\"] = lc_unique.apply(lambda x:  x['New_Location_Address'].get('aeroway', ''),axis = 1)\nlc_unique[\"New_Address_Highway\"] = lc_unique.apply(lambda x:  x['New_Location_Address'].get('highway', ''),axis = 1)\nlc_unique[\"New_Address_Road\"] = lc_unique.apply(lambda x: x['New_Location_Address'].get('road', ''),axis = 1)\n\nlc_unique[\"New_Address_Amenity\"] = lc_unique.apply(lambda x: x['New_Location_Address'].get('amenity', ''),axis = 1)\nlc_unique[\"New_Address_Hamlet\"] = lc_unique.apply(lambda x: x['New_Location_Address'].get('hamlet', ''),axis = 1)\n\nlc_unique[\"New_Address_Village\"] = lc_unique.apply(lambda x: x['New_Location_Address'].get('village', ''),axis = 1)\nlc_unique[\"New_Address_Town\"] = lc_unique.apply(lambda x: x['New_Location_Address'].get('town', ''),axis = 1)\nlc_unique[\"New_Address_Suburb\"] = lc_unique.apply(lambda x: x['New_Location_Address'].get('suburb', ''),axis = 1)\n\nlc_unique[\"New_Address_Residential\"] = lc_unique.apply(lambda x: x['New_Location_Address'].get('residential', ''),axis = 1)\nlc_unique[\"New_Address_Neighbourhood\"] = lc_unique.apply(lambda x: x['New_Location_Address'].get('neighbourhood', ''),axis = 1)\nlc_unique[\"New_Address_Building\"] = lc_unique.apply(lambda x:  x['New_Location_Address'].get('building', ''),axis = 1)\n\nlc_unique[\"New_Address_Shop\"] = lc_unique.apply(lambda x: x['New_Location_Address'].get('shop', ''),axis = 1)\nlc_unique[\"New_Address_Tourism\"] = lc_unique.apply(lambda x: x['New_Location_Address'].get('tourism', ''),axis = 1)\nlc_unique[\"New_Address_Leisure\"] = lc_unique.apply(lambda x: x['New_Location_Address'].get('leisure', ''),axis = 1)","45cc4284":"lc_unique.rename(columns={'LC':'New_Location_Coordinate'},inplace=True) ","0296f489":"df_final = df.merge(lc_unique, on='New_Location_Coordinate', how='left', suffixes=('', '_drop'))\n\ndf_final.head(2)","6f128e27":"\ndf_final[\"New_Is_Aeroway\"] = np.where(df_final[\"New_Address_Aeroway\"]==\"\", 0, 1)\ndf_final[\"New_Is_Amenity_Tourism\"] = np.where( ( (df_final[\"New_Address_Amenity\"] ==\"\") & (df_final[\"New_Address_Tourism\"] == \"\")), 0, 1)\n\ndf_final[\"New_Address_Is_Shop\"] = np.where(df_final[\"New_Address_Shop\"]==\"\",0,1)\ndf_final[\"New_Address_Is_Neighbourhood\"] = np.where(df_final[\"New_Address_Neighbourhood\"]==\"\",0,1)\ndf_final[\"New_Address_Is_Highway\"] = np.where(df_final[\"New_Address_Highway\"]==\"\",0,1)\n\ndf_final[\"New_Is_Village\"] = np.where(  ( ( df_final[\"New_Address_Hamlet\"] ==\"\")   &\n                                        (df_final[\"New_Address_Village\"] ==\"\") & \n                                        (df_final[\"New_Address_Town\"] == \"\") &\n                                        (df_final[\"New_Address_Suburb\"] ==\"\")\n                                        ), 0, 1)\n\n\ndf_final[\"New_Region\"] = np.where(df_final[\"New_Address_Village\"] !=\"\",df_final[\"New_Address_Village\"],np.NaN) \ndf_final[\"New_Region\"] = np.where(df_final[\"New_Address_Town\"] !=\"\",df_final[\"New_Address_Town\"],df_final[\"New_Region\"]) \ndf_final[\"New_Region\"] = np.where(df_final[\"New_Address_Suburb\"] !=\"\",df_final[\"New_Address_Suburb\"],df_final[\"New_Region\"]) \ndf_final[\"New_Region\"] = np.where(df_final[\"New_Address_Hamlet\"] !=\"\",df_final[\"New_Address_Hamlet\"],df_final[\"New_Region\"]) \ndf_final[\"New_Region\"] = np.where(df_final[\"New_Address_Road\"] !=\"\",df_final[\"New_Address_Road\"],df_final[\"New_Region\"]) \ndf_final[\"New_Region\"] = np.where(df_final[\"New_Address_Neighbourhood\"] !=\"\",df_final[\"New_Address_Neighbourhood\"],df_final[\"New_Region\"]) \ndf_final[\"New_Region\"] = np.where(df_final[\"New_Address_Residential\"] !=\"\",df_final[\"New_Address_Residential\"],df_final[\"New_Region\"])","904b0df0":"df_final[\"New_Region\"].head(10)","279995c7":"df_final[\"New_City_NewRegion\"] = df_final[\"City\"] + '-'+ df_final[\"New_Region\"]\ndf_final.head(3)","55641145":"df_location_summary = df_final.groupby(\"New_City_NewRegion\").agg({\"Population\":\"sum\",\n                                                                  \"Satisfaction Score\":\"mean\"})\n\ndf_location_summary.head()","4e0b783a":"df_location_summary.reset_index(inplace=True)\ndf_location_summary.head()","2371c655":"df_location_inf = df_location_summary[[\"Population\", \"Satisfaction Score\"]]\ndf_location_inf.head()","13568f7c":"# Standart Scaler:\n\nsc = MinMaxScaler((0, 1))\ndf_location_inf = sc.fit_transform(df_location_inf)","5fcbf850":"# Fit model:\n\nkmeans = KMeans()\nk_fit = kmeans.fit(df_location_inf)","62140626":"k_fit.get_params()","cf1dbccd":"# Optimum Number of Cluster:\n\nvisu = KElbowVisualizer(kmeans, k=(2,20))\nvisu.fit(df_location_inf)       # Fit the data to the visualizer\nvisu.poof()                     # Finalize and render the figure\nvisu.show();","d24bdd92":"print(\"Optimum k value:\", visu.elbow_value_)","a3cf795f":"# Assigning clusters:\n\nkmeans = KMeans(n_clusters=visu.elbow_value_).fit(df_location_inf)\nclusters = kmeans.labels_\n\ndf_location_summary[\"cluster_no\"] = clusters\ndf_location_summary.head()","fae5178c":"df_location_summary[\"cluster_no\"].value_counts()","ba5c17be":"df_location_summary[\"cluster_no\"] = df_location_summary[\"cluster_no\"] + 1\n\ndf_location_summary.groupby(\"cluster_no\").agg({\"Population\" : [\"mean\", \"count\"]})","d5597d56":"df_location_summary.head()","dacb9408":"# df_location_summary.reset_index(\"New_City_NewRegion\", inplace=True)","05e3afd0":"# Visualization: \n\ncenters = kmeans.cluster_centers_\n\nplt.scatter(df_location_summary.iloc[:, 0],\n            df_location_summary.iloc[:, 1],\n            c=clusters,\n            s=50,\n            cmap=\"viridis\");","3b8689a1":"# Assigning Clusters to main dataframe (df)\n\ndf_final[\"New_City_NewRegion\"] = df_final[\"City\"] + '-'+ df_final[\"New_Region\"]","342e4713":"df_location_summary.head()","fb0118e8":"# Merge dataframes:\n\ndf_final = df_final.merge(df_location_summary[[\"New_City_NewRegion\", \"cluster_no\"]], on =\"New_City_NewRegion\",how='left') \ndf_final.head(2)","aa0c1a27":"df_final.rename(columns={'cluster_no':'New_Region_ClusterNo'},inplace=True)\ndf_final[\"New_Region_ClusterNo\"].unique()","edf993f8":"# Let's fill nan values with \"7\" :\n\ndf_final[\"New_Region_ClusterNo\"]  = np.where(df_final[\"New_Region_ClusterNo\"].isnull()>0, 7, df_final[\"New_Region_ClusterNo\"])","d62063a5":"df_final.groupby(\"New_Region_ClusterNo\").agg({\"Population\": \"mean\",\n                                              \"Satisfaction Score\" : \"mean\",\n                                              \"Customer ID\": \"count\"}).sort_values(\"Satisfaction Score\",ascending=False)","f28f4a5f":"df_segments = df_final.groupby(\"New_Region_ClusterNo\").agg({\"Population\": \"mean\",\n                                                            \"Satisfaction Score\" : \"mean\",\n                                                            \"Customer ID\": \"count\"})","d3993496":"df_segments.sort_values(\"Population\", ascending=False)","ec3f8096":"very_high_population = df_segments.sort_values(\"Population\", ascending=False).head(2).reset_index()[\"New_Region_ClusterNo\"].unique()\n\nhigh_population = df_segments.sort_values(\"Population\", ascending=False).head(5).reset_index()[\"New_Region_ClusterNo\"].unique()\nhigh_population = [i for i in high_population if i not in very_high_population]\n\nlow_population = df_segments.sort_values(\"Population\", ascending=False).reset_index()[\"New_Region_ClusterNo\"].unique()\nlow_population = [i for i in low_population if (i not in very_high_population and i not in high_population)]\n\nprint(very_high_population)\nprint(high_population)\nprint(low_population)","53e4c3b4":"df_segments.sort_values(\"Satisfaction Score\", ascending=False)","cbfa092d":"very_high_score =  df_segments.sort_values(\"Satisfaction Score\", ascending=False).head(3).reset_index()[\"New_Region_ClusterNo\"].unique()\n\nhigh_score = df_segments.sort_values(\"Satisfaction Score\", ascending=False).head(5).reset_index()[\"New_Region_ClusterNo\"].unique()\nhigh_score = [i for i in high_score if i not in very_high_score]\n\nlow_score = df_segments.sort_values(\"Satisfaction Score\", ascending=False).reset_index()[\"New_Region_ClusterNo\"].unique()\nlow_score = [i for i in low_score if (i not in very_high_score and i not in high_score)]\n\nprint(very_high_score)\nprint(high_score)\nprint(low_score)","9a8437ae":"df_final.loc[df_final['New_Region_ClusterNo'].isin(very_high_population), \"New_Population_Level\" ] = \"VeryHigh_Population\"\ndf_final.loc[df_final['New_Region_ClusterNo'].isin(high_population), \"New_Population_Level\" ] = \"High_Population\"\ndf_final.loc[df_final['New_Region_ClusterNo'].isin(low_population), \"New_Population_Level\" ] = \"Low_Population\"\n\ndf_final.loc[df_final['New_Region_ClusterNo'].isin(very_high_score), \"New_Satisfaction_Level\" ] = \"VeryHigh_Satisfaction\"\ndf_final.loc[df_final['New_Region_ClusterNo'].isin(high_score), \"New_Satisfaction_Level\" ] = \"High_Satisfaction\"\ndf_final.loc[df_final['New_Region_ClusterNo'].isin(low_score), \"New_Satisfaction_Level\" ] = \"Low_Satisfaction\"","7365829b":"df_final[['New_Region_ClusterNo','New_Population_Level']].value_counts().sort_values()","4447feb7":"df_final[['New_Region_ClusterNo','New_Satisfaction_Level']].value_counts().sort_values()","6e1c3e71":"df_final[\"New_Region_Cluster\"] = df_final[['New_Population_Level', 'New_Satisfaction_Level' ]].agg('_'.join, axis=1)","1fb4ecb1":"df_final[\"New_Region_ClusterNo\"] =  df_final[\"New_Region_ClusterNo\"].astype(\"int\")","09cfc958":"df_final.head()","f8744581":"# Scaling:\n\nmms = MinMaxScaler()\n \ndf_final[\"Scaled_Tenure_Months\"] = mms.fit_transform(df_final[[\"Tenure Months\"]])\ndf_final[\"Scaled_Total_Revenue\"] = mms.fit_transform(df_final[[\"Total Revenue\"]])\n\ndf_segment = df_final[[\"Scaled_Total_Revenue\",\"Scaled_Tenure_Months\"]]\n","d39b25f7":"# Elbow Method - Visualization:\n\nkmeans = KMeans()\nelbow = KElbowVisualizer(kmeans, k=(2, 10))\nelbow.fit(df_final[[\"Scaled_Tenure_Months\",\"Scaled_Total_Revenue\"]])\nelbow.show();","d6fd4b9b":"# Optimimum k-value:\n\nelbow.elbow_value_","2f7d0bd5":"# Fit the model:\n  \nkmeans = KMeans(n_clusters=elbow.elbow_value_).fit(df_final[[\"Scaled_Tenure_Months\",\"Scaled_Total_Revenue\"]])\nclusters_ =   kmeans.labels_","023add32":"# Assigning labels:\n\ndf_final[\"New_Tenure_Revenue_Segment\"] = clusters_\n\ndf_final[\"New_Tenure_Revenue_Segment\"].unique()","bb75c0d8":"df_final[\"New_Tenure_Revenue_Segment\"] = df_final[\"New_Tenure_Revenue_Segment\"] + 1","85dc5dc3":"# Visualization of Clusters \n\ncenters = kmeans.cluster_centers_\nplt.scatter(df_final[[\"Scaled_Tenure_Months\",\"Scaled_Total_Revenue\"]].iloc[:, 0],\n            df_final[[\"Scaled_Tenure_Months\",\"Scaled_Total_Revenue\"]].iloc[:, 1],\n            c=clusters_,\n            s=50,\n            cmap=\"viridis\")\n\nplt.scatter(centers[:, 0],\n            centers[:, 1],\n            c=\"red\",\n            s=200,\n            alpha=0.8)\nplt.show()","cd3e0a93":"df_final.groupby(\"New_Tenure_Revenue_Segment\").agg({\"Total Revenue\":\"mean\",\n                                                    \"Tenure Months\":\"mean\"})","680ea0d0":"# Average Revenue :  Total Revenue by Tenure\ndf_final[\"New_Average_Revenue\"] = np.where(df_final[\"Tenure Months\"] ==0, df_final[\"Total Revenue\"], df_final[\"Total Revenue\"] \/ df_final[\"Tenure Months\"] )\n\ndf_final.groupby(\"New_Tenure_Revenue_Segment\").agg({\"New_Average_Revenue\": \"mean\" ,\n                                                    \"Total Revenue\":\"mean\",\n                                                    \"Tenure Months\":\"mean\"})","f4b4d728":"# Assigning Segments:\n\ndf_final[\"New_Tenure_Revenue_Segment\"] = df_final[\"New_Tenure_Revenue_Segment\"].astype(str).replace(to_replace =['1','2','3','4'],\n                                                 value = ['New_Customer', 'Low_Profit', 'High_Potential', 'Champions'])","733c6824":"df_final.groupby(\"New_Tenure_Revenue_Segment\").agg({\"New_Average_Revenue\": \"mean\" ,\n                                                    \"Total Revenue\":\"mean\",\n                                                    \"Tenure Months\":\"mean\"})","dc732c0f":"df_final[\"Senior Citizen\"].replace(to_replace =\"No\", value =\"Young\", inplace = True)\ndf_final[\"Senior Citizen\"].replace(to_replace =\"Yes\", value =\"Senior\", inplace = True)","90372e02":"df_final[\"Streaming Music\"].unique()","23fb30e0":"## Additional Services\ndf_final[\"Online Security\"].replace(to_replace =\"Yes\", value =1, inplace = True)\ndf_final[\"Online Security\"].replace(to_replace =[\"No internet service\",\"No\"], value =0, inplace = True)\n\ndf_final[\"Online Backup\"].replace(to_replace =\"Yes\", value =1, inplace = True)\ndf_final[\"Online Backup\"].replace(to_replace =[\"No internet service\",\"No\"], value = 0, inplace = True)\n\ndf_final[\"Phone Service\"].replace(to_replace =\"Yes\", value =1, inplace = True)\ndf_final[\"Phone Service\"].replace(to_replace =\"No\", value = 0, inplace = True)\n\ndf_final[\"Device Protection\"].replace(to_replace =\"Yes\", value =1, inplace = True)\ndf_final[\"Device Protection\"].replace(to_replace =  [\"No internet service\",\"No\"], value = 0, inplace = True)\n \ndf_final[\"Premium Tech Support\"].replace(to_replace =\"Yes\", value =1, inplace = True)\ndf_final[\"Premium Tech Support\"].replace(to_replace =[\"No internet service\",\"No\"], value = 0, inplace = True)\n\ndf_final[\"Streaming TV\"].replace(to_replace =\"Yes\", value =1, inplace = True)\ndf_final[\"Streaming TV\"].replace(to_replace =[\"No internet service\",\"No\"], value = 0, inplace = True)\n\ndf_final[\"Streaming Movies\"].replace(to_replace =\"Yes\", value =1, inplace = True)\ndf_final[\"Streaming Movies\"].replace(to_replace =[\"No internet service\",\"No\"], value = 0, inplace = True)\n\ndf_final[\"Unlimited Data\"].replace(to_replace =\"Yes\", value =1, inplace = True)\ndf_final[\"Unlimited Data\"].replace(to_replace = \"No\", value = 0, inplace = True)\n\ndf_final[\"Streaming Music\"].replace(to_replace =\"Yes\", value =1, inplace = True)\ndf_final[\"Streaming Music\"].replace(to_replace = \"No\", value = 0, inplace = True)\n\ndf_final[\"New_Internet_Service\"] = df_final[\"Internet Service\"] \ndf_final[\"New_Internet_Service\"].replace(to_replace =[\"No internet service\",\"No\"], value = 0, inplace = True)\ndf_final[\"New_Internet_Service\"].replace(to_replace = [\"DSL\",\"Fiber optic\"], value = 1, inplace = True)","23b54ee6":"df_final[\"New_Additional_Services\"] =  df_final[\"Phone Service\"] +    df_final[\"New_Internet_Service\"] + df_final[\"Online Security\"] +  df_final[\"Online Backup\"] +  df_final[\"Streaming TV\"] +  df_final[\"Streaming Movies\"] +  df_final[\"Streaming Music\"] +   df_final[\"Device Protection\"] +  df_final[\"Premium Tech Support\"] +   df_final[\"Unlimited Data\"]\n\ndf_final[\"New_Entertainment_Lovers\"] = np.where(df_final[\"Streaming TV\"] + df_final[\"Streaming Movies\"] + df_final[\"Streaming Music\"] >0,1,0)\n\ndf_final[\"New_Technology_Lovers\"] = np.where(df_final[\"Online Security\"] + df_final[\"Online Backup\"]  + df_final[\"Device Protection\"] + df_final[\"Premium Tech Support\"] >0,1,0)\ndf_final[\"New_Guaranteed_Customers\"] = np.where( df_final[\"Device Protection\"] + df_final[\"Premium Tech Support\"] >0,1,0)","8c19c944":"# New_Entertainment_Lovers\n\nsns.countplot(y ='Churn Value',hue= df_final[\"New_Entertainment_Lovers\"], data = df_final)\nplt.show();","1b1413ff":"# New_Additional_Services\n\nsns.countplot(y = 'Churn Value',hue= df_final[\"New_Additional_Services\"], data = df_final)\nplt.show();","b179e5e0":"df_final[\"New_Total_Extra_Data_Charges_Ratio_InRevenue\"] = df_final[\"Total Extra Data Charges\"] \/ ( df_final[\"Total Revenue\"] - df_final [\"Total Refunds\"])\ndf_final[\"New_Total_Extra_Data_Charges_Ratio_InTotalBill\"] = df_final[\"Total Extra Data Charges\"] \/ df_final[\"Total Charges\"]\ndf_final[\"New_Total_Long_Distance_Charges_Ratio_InRevenue\"] = df_final[\"Total Long Distance Charges\"] \/ ( df_final[\"Total Revenue\"] - df_final [\"Total Refunds\"])\ndf_final[\"New_Total_Long_Distance_Ratio_InTotalBill\"] = df_final[\"Total Long Distance Charges\"] \/ df_final[\"Total Charges\"]\ndf_final[\"New_Total_Refund_Ratio_InRevenue\"] = df_final[\"Total Refunds\"] *100 \/ df_final[\"Total Revenue\"]\ndf_final[\"New_Total_Refund_Ratio_TotalExtraCharges\"] = df_final[\"Total Refunds\"] *100 \/ (df_final[\"Total Extra Data Charges\"] + df_final[\"Total Long Distance Charges\"])\ndf_final[\"New_Total_Refund_Ratio_InTotalBill\"] = df_final[\"Total Refunds\"] *100 \/  df_final[\"Total Charges\"]","6710af58":"# Avg Monthly GB Download\n\ndf_final.loc[(df_final[\"Avg Monthly GB Download\"] < 5), \"New_Avg_Monthly_GB_Download\"] = \"low\"\ndf_final.loc[(df_final[\"Avg Monthly GB Download\"] >= 5) & (df_final[\"Avg Monthly GB Download\"]< 20), \"New_Avg_Monthly_GB_Download\"] = \"medium\"\ndf_final.loc[(df_final[\"Avg Monthly GB Download\"]>= 20) & (df_final[\"Avg Monthly GB Download\"]< 50), \"New_Avg_Monthly_GB_Download\"] = \"good\"\ndf_final.loc[(df_final[\"Avg Monthly GB Download\"]>= 50), \"New_Avg_Monthly_GB_Download\"] = \"plus\"\n","c7e52a43":"# Population\n\ndf_final.loc[(df_final[\"Population\"] < 1000), \"New_Population\"] = \"village\"\ndf_final.loc[(df_final[\"Population\"]>= 1000) & (df_final[\"Population\"] < 8000), \"New_Population\"] = \"town\"\ndf_final.loc[(df_final[\"Population\"]>= 8000) & (df_final[\"Population\"] < 20000), \"New_Population\"] = \"district\"\ndf_final.loc[(df_final[\"Population\"]>= 20000) & (df_final[\"Population\"] < 70000), \"New_Population\"] = \"province\"\ndf_final.loc[(df_final[\"Population\"]>= 70000), \"New_Population\"] = \"metropolis\"","32fccdfc":"# Tenure Months\n\ndf_final[\"New_Tenure_Months_Age\"] = df_final[\"Tenure Months\"] \/ df_final[\"Age\"]\n\ndf_final.loc[(df_final[\"Tenure Months\"] <=3), \"New_Tenure_Cat\"] = \"New_Customer\"\ndf_final.loc[(df_final[\"Tenure Months\"]<= 6) & (df_final[\"Tenure Months\"] >3), \"New_Tenure_Cat\"] = \"Onboarding\"\ndf_final.loc[(df_final[\"Tenure Months\"]<= 36) & (df_final[\"Tenure Months\"] > 6), \"New_Tenure_Cat\"] = \"Old_Customer\"\ndf_final.loc[df_final[\"Tenure Months\"] > 36, \"New_Tenure_Cat\"] = \"Loyal_Customer\"","90db7bdc":"# New_Tenure_Months_Age\n\nsns.boxplot(y='New_Tenure_Months_Age',x = 'Churn Value', hue = 'Churn Value',data = df_final)\nplt.ylim(-1, 1)\nplt.show()","10c07153":"df_final.groupby(\"Senior Citizen\").agg({\"New_Technology_Lovers\":\"mean\"})","c923f57b":"df_final[\"New_Senior_Entertainment_Lovers\"] = np.where( (df_final[\"Senior Citizen\"] ==\"Senior\") & (df_final[\"New_Entertainment_Lovers\"] ==1),\"Crazy_Seniors\" ,\"Normal\")\ndf_final[\"New_Senior_Tech_Lovers\"] = np.where( (df_final[\"Senior Citizen\"] ==\"Senior\") & (df_final[\"New_Technology_Lovers\"] ==1),\"Tech_Followers_Seniors\" ,\"Normal\")\n\ndf_final['New_Total_Revenue_Cat'] = pd.qcut(x=df_final['Total Revenue'], q=5, labels=[1,2,3,4,5]) ","b6c232c2":"# Alone \/ Not Alone: \n\ndf_final['New_NumofDependents_Cat'] = pd.qcut(x=df_final['Number of Dependents'].rank(method=\"first\"), q=2, labels=[1,2]) ","9c5bab1f":"df_final['New_Monthly_Charge_Cat'] = pd.qcut(x=df_final['Monthly Charge'], q=3, labels=[1,2,3]) \ndf_final['New_Total_Monthly_Charge_Cat'] = pd.qcut(x=df_final['Total Charges'], q=3, labels=[1,2,3])\n\ndf_final[\"New_Tenure_Contract_Relation\"] = np.where(df_final[\"Contract\"] == \"Month-to-month\", df_final[\"Tenure Months\"]\/1, np.NaN)\ndf_final[\"New_Tenure_Contract_Relation\"] = np.where(df_final[\"Contract\"] == \"One year\", df_final[\"Tenure Months\"]\/12, df_final[\"New_Tenure_Contract_Relation\"])\ndf_final[\"New_Tenure_Contract_Relation\"] = np.where(df_final[\"Contract\"] =='Two year' , df_final[\"Tenure Months\"]\/24, df_final[\"New_Tenure_Contract_Relation\"])\n\ndf_final[\"New_HasChild\"] = np.where( ((df_final[\"Married\"] =='Yes')  & (df_final[\"Dependents\"] =='Yes') ) , 1, 0) \n\ndf_final[\"New_AvgRevenue_Per_Services\"] =  (df_final[\"Total Revenue\"]  - df_final[\"Total Refunds\"]  ) \/df_final[\"New_Additional_Services\"]\n\ndf_final[\"New_IsAlone\"] = np.where( ((df_final[\"Dependents\"] =='Yes')|(df_final[\"Partner\"] =='Yes') ) , 1, 0) \n\ndf_final['New_NumberofReferrals'] = pd.qcut(x=df_final['Number of Referrals'].rank(method=\"first\"), q=3, labels=[1,2,3]) \n\ndf_final[\"New_Avg_MonthlyLongDistanceChar_Ratio\"] = df_final[\"Avg Monthly Long Distance Charges\"]\/ df_final[\"Monthly Charge\"]\n\ndf_final['New_Has_Promotion_Or_Complaint'] = np.where(df_final['Total Refunds'] >0 ,1,0)\n\n# Has_Complaint\n\ndf_final[\"New_Has_Complaint\"] = np.where( ( (df_final[\"New_Has_Promotion_Or_Complaint\"] ==1 ) & (df_final[\"Satisfaction Score\"] <=2) ), 1,0)\n\n# Has_Promotion\n\ndf_final[\"New_Has_Promotion\"] = np.where( ( (df_final[\"New_Has_Promotion_Or_Complaint\"] ==1 ) & (df_final[\"Satisfaction Score\"] >=4) ), 1,0)\n\n# New_Payment_Method \n\ndf_final[\"New_Payment_Method_Automatic\"] = np.where( (df_final[\"Payment Method\"] == 'Bank transfer (automatic)') | (df_final[\"Payment Method\"] ==  'Credit card (automatic)'), 1,0)\n\n# Age & Gender Features:\n\ndf_final.loc[(df_final['Gender'] == 'Male') & (df_final['Age'] <= 21), 'New_Gender_Age_Cat'] = 'Youngmale'\ndf_final.loc[(df_final['Gender'] == 'Male') & ((df_final['Age'] > 21) & (df_final['Age']) < 50), 'New_Gender_Age_Cat'] = 'Maturemale'\ndf_final.loc[(df_final['Gender'] == 'Male') & (df_final['Age'] > 50), 'New_Gender_Age_Cat'] = 'Seniormale'\ndf_final.loc[(df_final['Gender'] == 'Female') & (df_final['Age'] <= 21), 'New_Gender_Age_Cat'] = 'Youngfemale'\ndf_final.loc[(df_final['Gender'] == 'Female') & ((df_final['Age'] > 21) & (df_final['Age']) < 50), 'New_Gender_Age_Cat'] = 'Maturefemale'\ndf_final.loc[(df_final['Gender'] == 'Female') & (df_final['Age'] > 50), 'New_Gender_Age_Cat'] = 'Seniorfemale'\n\ndf_final.head(2)","74e1d675":"drop_col_list = [ 'City', 'Zip Code', 'Lat Long', 'Latitude', 'Longitude', 'ID', 'Scaled_Tenure_Months',\n                 'Scaled_Total_Revenue', 'Customer Status', 'New_Location_Coordinate', 'New_Location', 'New_Location_Address',\n                 'New_Address_Aeroway', 'New_Address_Highway', 'New_Address_Road', 'New_Address_Amenity', 'New_Address_Hamlet',\n                 'New_Address_Village',   'New_Address_Town', 'New_Address_Suburb', 'New_Address_Residential', 'New_Address_Neighbourhood',\n                 'New_Address_Building', 'New_Address_Shop', 'New_Address_Tourism', 'New_Address_Leisure', 'New_Is_Aeroway',\n                 'New_Is_Amenity_Tourism', 'New_Address_Is_Shop', 'New_Address_Is_Neighbourhood', 'New_Address_Is_Highway',\n                 'New_Is_Village', 'New_Region', 'New_City_NewRegion', 'New_Population_Level', 'New_Satisfaction_Level',\n                 'New_Region_ClusterNo']","6a7479b8":"df_final.drop(columns=drop_col_list, axis=1, inplace=True)","46115134":"# Let's define variables again:\n\ncat_cols, num_cols, cat_but_car,location_cols = grab_col_names(df_final)","7aa55803":"# Rare Analysing:\n\ndef rare_analyser(dataframe, target, cat_cols):\n    for col in cat_cols:\n        print(col, \":\", len(dataframe[col].value_counts()))\n        print(pd.DataFrame({\"COUNT\": dataframe[col].value_counts(),\n                            \"RATIO\": dataframe[col].value_counts() \/ len(dataframe),\n                            \"TARGET_MEAN\": dataframe.groupby(col)[target].mean()}), end=\"\\n\\n\\n\")\n\n\nrare_analyser(df_final, \"Churn Value\", cat_cols)","3db16a37":"df_final.head()","1dcc85c5":"useless_cols = [col for col in df_final.columns if ( ( df_final[col].nunique() == 2  and (df_final[col].value_counts() \/ len(df_final) < 0.01).any(axis=None))\n                                            | df_final[col].nunique() == 1 )]\ndf.drop( useless_cols, axis = 1,inplace=True)","f608e2dd":"# Rare Encoding:\n\ndef rare_encoder(dataframe, rare_perc, cat_cols):\n\n    rare_columns = [col for col in cat_cols if (dataframe[col].value_counts() \/ len(dataframe) <= rare_perc).sum() > 1]\n\n    for col in rare_columns:\n        tmp = dataframe[col].value_counts() \/ len(dataframe) # th alt\u0131nda kalan s\u0131n\u0131f\u0131 olan de\u011fi\u015fkenlerin s\u0131n\u0131f frekanslar\u0131ndan olusan df yarat\n        rare_labels = tmp[tmp <= rare_perc].index # s\u0131n\u0131f frekans\u0131 < th olanlar\u0131n indexlerini bul\n        dataframe[col] = np.where(dataframe[col].isin(rare_labels), 'Rare', dataframe[col]) # th alt\u0131nda kalan de\u011ferleri Rare olarak grupla\n\n    return dataframe","78e70fbb":"cat_cols, num_cols, cat_but_car,location_cols = grab_col_names(df_final)\ncat_cols","56bef8b2":"rare_analyser(df_final, \"Churn Value\", cat_cols)","1680f1a3":"# cat_cols, num_cols, cat_but_car,location_cols = grab_col_names(df_final)\ndf_final = rare_encoder(df_final, 0.01, cat_cols)","978332d4":"df_final.head(3)","b125b64c":"cat_cols, num_cols, cat_but_car,location_cols = grab_col_names(df_final)\ncat_cols","bc302b32":"df_final.dtypes","1bea3529":"#  One-Hot Encoding:\n\n# Let's define cat cols for one-hot-encoding:\n\ndef ohe_cols(dataframe):\n    ohe_col_names = [col for col in dataframe.columns if (dataframe[col].dtype not in [\"float64\", \"int64\"] and 10 >= dataframe[col].nunique() >= 2)]\n    return ohe_col_names\n\n\ndef one_hot_encoder(dataframe, ohe_col_names, drop_first=True):\n    dms = pd.get_dummies(dataframe[ohe_col_names], drop_first=drop_first)   \n    df_ = dataframe.drop(columns=ohe_col_names, axis=1)                      \n    dataframe = pd.concat([df_, dms],axis=1)                                 \n    return dataframe","f0d7f87a":"ohe_col_list = ohe_cols(df_final)\nohe_col_list","942789a6":"df_final = one_hot_encoder(df_final, ohe_col_list)","992654e9":"df_final[df_final.isin([np.nan, np.inf, -np.inf]).any(axis=1)].shape[0]","dd6f51d8":"df_final = df_final.replace([np.inf, -np.inf], np.nan)\ndf_final[df_final.isin([np.inf, -np.inf]).any(axis=1)].shape[0]","ebee9c3e":"missing_values_df(df_final)","ba6f61ba":"df_final[df_final[[\"New_Total_Refund_Ratio_TotalExtraCharges\"]].isnull().any(axis=1)][[\"New_Total_Refund_Ratio_TotalExtraCharges\",\"Total Refunds\", \"Total Extra Data Charges\", \"Total Long Distance Charges\"]].head()","b207676e":"df_final[\"New_Total_Refund_Ratio_TotalExtraCharges\"] = df_final[\"New_Total_Refund_Ratio_TotalExtraCharges\"].fillna(0)","4a492282":"missing_values_df(df_final)","0f2d29ae":"df_final[df_final.isin([np.inf, -np.inf, np.NaN]).any(axis=1)].shape[0]","c81880b1":"df_final.dtypes","8608d880":"conv_cols = [col for col in df_final.columns if df_final[col].dtype == \"uint8\"]\ndf_final[conv_cols] = df_final[conv_cols].astype(\"int64\")","1607d83b":"df_final.dtypes.unique()","9d92400e":"cat_cols, num_cols, cat_but_car,location_cols = grab_col_names(df_final)","a4ea4692":"location_cols","2217bcb4":"cat_cols","781ddca3":"cat_but_car","1da2f65f":"num_cols","e6f23ddd":"\ndef StandartScaling(dataframe, col_name):\n    ss = StandardScaler()\n    dataframe[col_name] = ss.fit_transform(dataframe[col_name])\n    return dataframe\n\ndef MinMaxScaling(dataframe, col_name):\n    mms = MinMaxScaler()\n    dataframe[col_name] = mms.fit_transform(dataframe[col_name])\n    return dataframe\n\ndef RobustScaling(dataframe, col_name):\n    rs = RobustScaler()\n    dataframe[col_name] = rs.fit_transform(dataframe[col_name])\n    return dataframe\n\n\ndef Scaling(dataframe, method):\n    numerical_cols = grab_col_names(dataframe)[1]\n    if method == \"StandartScaling\":\n        StandartScaling(dataframe, numerical_cols)\n    elif method == \"MinMaxScaling\":\n        MinMaxScaling(dataframe, numerical_cols)\n    else:\n        RobustScaling(dataframe, numerical_cols)\n    return dataframe\n","848e68ad":"df_final[num_cols] = (Scaling(df_final[num_cols], \"RobustScaling\"))","70a8d2b4":"df_final.head()","370193f2":"df_final_ = df_final.copy()","8c77287c":"# Correlation matrix\n\ndef high_correlated_cols(dataframe, plot=False, corr_th=0.90):\n    num_cols = grab_col_names(dataframe)[1]\n    corr = dataframe[num_cols].corr()\n    cor_matrix = corr.abs()\n    upper_triangle_matrix = cor_matrix.where(np.triu(np.ones(cor_matrix.shape), k=1).astype(np.bool))\n    drop_list = [col for col in upper_triangle_matrix.columns if any(upper_triangle_matrix[col] > corr_th)]\n    if plot:\n        sns.set(rc={'figure.figsize': (15, 15)})\n        sns.heatmap(corr, cmap=\"RdBu\",  annot=True, annot_kws={\"size\": 9}, fmt= '.2f')\n        plt.show()\n    return drop_list","b0cace8d":"# Let's observe the high correlated features:\n\nhigh_correlated_cols(df_final, plot=True, corr_th=0.70)","068bd4c7":"high_correlated_col_df =  high_correlated_cols(df_final, corr_th=0.70)\ndf_final.drop(columns=high_correlated_col_df, axis=1, inplace=True)","225462cc":"df_final.isnull().sum().sum()","4d1f4860":"df_final.head()\n\ndf_final.drop(columns = [\"Satisfaction Score\", \"Population\"], inplace=True)","ee4f2bd6":"# Defining dependent and independent variables:\n\nX = df_final.drop([\"Customer ID\",\"Churn Value\", 'Churn Label_Yes'], axis=1)\ny = df_final[[\"Churn Value\"]] ","d0a9662c":"# Train- test split:\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.20, random_state = 112)","8836f866":"classifiers = [ ('KNN', KNeighborsClassifier()),\n               (\"SVC\", SVC()),\n               (\"CART\", DecisionTreeClassifier()),\n               (\"RF\", RandomForestClassifier()),\n               ('ExtraTrees', ExtraTreesClassifier()),\n               ('Adaboost', AdaBoostClassifier()),\n               ('GBM', GradientBoostingClassifier()),\n               ('XGBoost', XGBClassifier(eval_metric='mlogloss',verbosity = 0)),\n               ('LightGBM', LGBMClassifier()),\n               ('CatBoost', CatBoostClassifier(verbose=False))\n               ]\n\nfor name, classifier in classifiers:\n    cv_results = cross_validate(classifier, X_train, y_train, cv=5, scoring=[\"roc_auc\"])\n    print(f\"AUC: {round(cv_results['test_roc_auc'].mean(),4)} ({name}) \")","74f04eae":"cart_params = {'max_depth': [5, 8, 10],\n               \"min_samples_split\": [10, 20, 50]}\n\n\nlightgbm_params = {\"learning_rate\": [0.01, 0.1],\n                   \"n_estimators\": [ 500, 750],\n                   \"colsample_bytree\": [0.5, 0.7]}\n\n\nrf_params = {\"max_depth\": [5, 8, None],\n             \"max_features\": [ 7, \"sqrt\", \"auto\"],\n             \"min_samples_split\": [8, 15, 20],\n             \"n_estimators\": [500, 1000]}\n\ngbm_params= {\"learning_rate\": [0.01,0.001],\n            \"max_depth\": [5,None],\n            \"max_features\": [\"auto\",\"sqrt\"],\n            \"n_estimators\": [500, 1000]} \n\n\nclassifiers = [(\"CART\", DecisionTreeClassifier(), cart_params),\n               (\"RF\", RandomForestClassifier(), rf_params),\n               (\"LightGBM\", LGBMClassifier(), lightgbm_params),\n               (\"GBM\", GradientBoostingClassifier(), gbm_params) ]\n\n\nbest_models = {}\nfor name, classifier, params in classifiers:\n    print(f\"########## {name} ##########\")\n    cv_results = cross_validate(classifier, X_train, y_train, cv=5, scoring=[\"roc_auc\"])\n    print(f\"AUC (Before): {round(cv_results['test_roc_auc'].mean(),4)}\")\n\n\n    gs_best = GridSearchCV(classifier, params, cv=5, verbose=False).fit(X_train,  y_train.values.ravel())\n    final_model = classifier.set_params(**gs_best.best_params_)\n\n    cv_results = cross_validate(final_model, X_train,  y_train, cv=5, scoring=[\"roc_auc\"])\n    print(f\"AUC (After): {round(cv_results['test_roc_auc'].mean(), 4)}\")\n    print(f\"{name} best params: {gs_best.best_params_}\", end=\"\\n\\n\")\n\n    best_models[name] = final_model","4c7934cb":"best_models","81f9cac7":"# Feature Importances of 4 Models (Random Forest, LGBM, GBM, ExtraTrees)\nfeature_imp_all = pd.DataFrame({'Model': np.NaN, \n                                'AUC_Score': np.NaN,\n                                'Feature': np.NaN, \n                                'Value': np.NaN, \n                                'Weighted_Score': np.NaN}, index=[0])\n   \nfor model, classifier in best_models.items():\n \n    final_model = classifier.fit(X_train, y_train.values.ravel())\n    cv_results = cross_validate(final_model, X_train,  y_train, cv=5, scoring=[\"roc_auc\"])\n    score_final =  round(cv_results['test_roc_auc'].mean(), 4)\n    # rmse_final = np.mean(np.sqrt(-cross_val_score(final_model, X, y, cv=5, scoring=\"neg_mean_squared_error\")))\n\n    feature_imp = pd.DataFrame({ 'Model' : model,\n                                 'AUC_Score': score_final * 100,\n                                 'Feature': X_train.columns,\n                                 'Value': final_model.feature_importances_, \n                                 'Weighted_Score': score_final * 100 * final_model.feature_importances_ })\n    \n    feature_imp_all = pd.concat([feature_imp_all, feature_imp], axis = 0)\n    feature_imp_all.dropna(inplace=True)\n","fcaa7b8d":"feature_imp_all.sort_values(\"Weighted_Score\", ascending=False).head()","1e21ff27":"feature_imp_all[\"Model\"].unique()","f7357fb8":"feature_imp_all.groupby(\"Model\").agg({\"AUC_Score\": \"mean\"})","80e8f9b5":"feature_imp_all = feature_imp_all.pivot_table(values = \"Weighted_Score\", \n                                             columns=\"Model\", \n                                             index=['Feature'],\n                                             aggfunc=np.mean).reset_index()","a373c875":"feature_imp_all.head()","21795428":"# Let's scale CV Score values for all models:\n\nscaled_cols = [col for col in feature_imp_all.columns if feature_imp_all[col].dtypes == \"float64\"]\n\nscaler = MinMaxScaler()\nfeature_imp_all[scaled_cols] = scaler.fit_transform(feature_imp_all[scaled_cols])","4d45bff2":"feature_imp_all.head()","038fde2c":"# Average Feature Importance based on Selected Models:\n\nfeature_imp_all[\"Avg_Importance_Value\"] = ( (feature_imp_all[\"CART\"] + \n                                           feature_imp_all[\"GBM\"] +\n                                           feature_imp_all[\"LightGBM\"] +\n                                           feature_imp_all[\"RF\"] ) \/4 )* 100 ","e4d6b8fe":"feature_imp_all.sort_values(\"Avg_Importance_Value\", ascending=False).head()","c701a883":"# Let's show the hybrid feature importance values with the plot:\n\nplt.figure(figsize=(10, 10))\nsns.set(font_scale=1)\nsns.barplot(x=\"Avg_Importance_Value\", \n            y=\"Feature\", \n            data=feature_imp_all.sort_values(by=\"Avg_Importance_Value\", ascending=False)[0:50])\nplt.title('Hybrid Features Importance')\nplt.tight_layout()\nplt.show();","b4ca505b":"len(X_train.columns)","8fdf4a8c":"selected_cols = list (feature_imp_all.loc[feature_imp_all[\"Avg_Importance_Value\"] >=1, \"Feature\"].values)\n\nselected_cols","ede9cbe6":"model_results_all = pd.DataFrame({'Model': np.NaN, \n                                  'AUC_Score': np.NaN}, index=[0])\n   \nfor model, classifier in best_models.items():\n    \n    final_model = classifier.fit(X_train[selected_cols], y_train.values.ravel())\n    cv_results = cross_validate(final_model, X_train[selected_cols], y_train, cv=5, scoring=[\"roc_auc\"])\n    score_final =  round(cv_results['test_roc_auc'].mean(), 4)\n    \n    model_results = pd.DataFrame({ 'Model' : model,\n                                   'AUC_Score': score_final} , index=[0])\n    \n    model_results_all = pd.concat([model_results_all, model_results], axis = 0)\n    model_results_all.dropna(inplace=True)","19e54085":"model_results_all.sort_values(\"AUC_Score\", ascending=False).head(3)","f33aac0d":"#  Ensemble Modelling : GBM & Light GBM & RF\n\nvoting_classifier_model = VotingClassifier(estimators= [('GBM',best_models['GBM']),\n                                                        ('LGBM',best_models['LightGBM']),\n                                                        ('RF',best_models['RF'])],voting ='soft')\n\n# Model Fit:\nvoting_classifier_model.fit(X_train[selected_cols], y_train)","45e436e4":"cv_results_train = cross_validate(voting_classifier_model, X_train[selected_cols], y_train, cv=5, scoring=[\"accuracy\", \"f1\", \"roc_auc\",\"precision\",\"recall\"])\ncv_results_train","6fba826c":"print(\"AUC Score for Train Set:\", cv_results_train['test_roc_auc'].mean())\n\nprint(\"Accuracy Score for Train Set:\", cv_results_train['test_accuracy'].mean())\n\nprint(\"F1 Score for Train Set:\", cv_results_train['test_f1'].mean())\n\nprint(\"Precision Score for Train Set:\", cv_results_train['test_precision'].mean())\n\nprint(\"Recall Score for Train Set:\", cv_results_train['test_recall'].mean())","b4c10091":"cv_results_test = cross_validate(voting_classifier_model, X_test[selected_cols], y_test, cv=5, scoring=[\"accuracy\", \"f1\", \"roc_auc\",\"precision\",\"recall\"])","3eaf0b12":"print(\"AUC Score for Test Set:\", cv_results_test['test_roc_auc'].mean())\n\nprint(\"Accuracy Score for Test Set:\", cv_results_test['test_accuracy'].mean())\n\nprint(\"F1 Score for Test Set:\", cv_results_test['test_f1'].mean())\n\nprint(\"Precision Score for Test Set:\", cv_results_test['test_precision'].mean())\n\nprint(\"Recall Score for Test Set:\", cv_results_test['test_recall'].mean())","28aefeac":"def plot_confusion_matrix(y, y_pred):\n    acc = round(accuracy_score(y, y_pred), 2)\n    cm = confusion_matrix(y, y_pred)\n    sns.heatmap(cm, annot=True, fmt=\".0f\")\n    sns.set(rc = {'figure.figsize':(3, 3)})\n    plt.xlabel('y_pred')\n    plt.ylabel('y')\n    plt.title('Accuracy Score: {0}'.format(acc), size=10)\n    plt.show()","f06325c5":"y_pred = voting_classifier_model.predict(X_test[selected_cols])\nplot_confusion_matrix(y_test, y_pred)","656d0996":"y_prob = voting_classifier_model.predict_proba(X_test[selected_cols])\ny_prob = pd.DataFrame(y_prob ,index= X_test.index)\ny_prob[0:5]","791bdd9b":"y_prob[\"New_Churn_Value\"] = y_prob[1].apply(lambda x: 1 if x > 0.50 else 0)\ny_prob","8cd80513":"y_test_ =  y_test.merge(y_prob, left_index=True, right_index=True)\ny_test_[0:5]","30eebd3b":"y_test_[\"New_Churn_Value\"].unique()","e09b9624":"y_test_.groupby(\"New_Churn_Value\").agg({\"New_Churn_Value\": \"count\"})","dd1e9401":"y_prob_all = voting_classifier_model.predict_proba(X[selected_cols])\ny_prob_all = pd.DataFrame(y_prob_all ,index= X.index)\n\ny_prob_all[\"New_Churn_Value\"] = y_prob_all[1].apply(lambda x: 1 if x > 0.50 else 0)\ny_prob_all[0:5]","19332828":"y_ =  y.merge(y_prob_all, left_index=True, right_index=True)\ny_.shape","cdae5654":"target_df = pd.concat([df_final ,y_[[\"New_Churn_Value\", 1]]],axis=1)\ntarget_df.head()","390d6452":"target_df = target_df.rename(columns={1:\"New_Churn_Prob\"})","f9051344":"target_df.head()","3fe7be9f":"target_df[\"New_Churn_Prob_Cat\"] = np.where(target_df[\"New_Churn_Prob\"] >=0.90,\"Very High\",np.NaN)\ntarget_df[\"New_Churn_Prob_Cat\"] = np.where(( (target_df[\"New_Churn_Prob\"] <0.90) & (target_df[\"New_Churn_Prob\"] >=0.80)),\"High\",target_df[\"New_Churn_Prob_Cat\"])\ntarget_df[\"New_Churn_Prob_Cat\"] = np.where(( (target_df[\"New_Churn_Prob\"] <0.80) & (target_df[\"New_Churn_Prob\"] >=0.45)),\"Medium\",target_df[\"New_Churn_Prob_Cat\"])\ntarget_df[\"New_Churn_Prob_Cat\"] = np.where(( (target_df[\"New_Churn_Prob\"] <0.45) & (target_df[\"New_Churn_Prob\"] >=0.10)),\"Low\",target_df[\"New_Churn_Prob_Cat\"])\ntarget_df[\"New_Churn_Prob_Cat\"] = np.where(target_df[\"New_Churn_Prob\"] <0.10,\"Very_Low\",target_df[\"New_Churn_Prob_Cat\"])","293e24c7":"summary_df = target_df.groupby(\"New_Churn_Prob_Cat\").agg({\"New_Churn_Prob\": \"mean\",\n                                                          \"Customer ID\": \"count\"}).reset_index()\nsummary_df.sort_values(\"New_Churn_Prob\", ascending=False)","10cc0f3f":"summary_df.rename(columns={'Customer ID': 'Number_of_Customers'}, inplace=True)\nsummary_df.head()","75f76e89":"sns.barplot(y= summary_df[\"Number_of_Customers\"], x = 'New_Churn_Prob_Cat', data = summary_df)\nsns.set(rc = {'figure.figsize':(8, 6)})\nplt.show();","ecee6178":"<a id=\"section-nine\"><\/a>\n# **Hybrid Feature Selection**","635a4f61":"Now, let's observe churn probabilites based calculated with Ensemble Modelling:","26dfb5b8":"* ***General Exploration for Categorical Variables:***","73123586":"Now, let's merge \"lc_unique\" dataframe with main dataframe (df)","1ad811c4":"Now, let's check df_final if it contains \"NaN\" or \"inf\" values","6c83ab11":"<a id=\"section-one\"><\/a>\n# **Dataset Story**\n\n\n* The data set has been provided by IBM Cognos Analytics, the data module that is named Telco Customer Churn\n\n* This data set contains detailed information about customers of a fictional Telecom company in California.\n \n*  7,043 observations & 47 independent variables.\n\n* The Telco customer churn data module is composed of 5 data set: \n    * Demographics\n    * Location\n    * Population\n    * Services\n    * Status\n    \n* The target variable is \"Churn Label(Churn Value)\", where \"YES\" indicates the retained customers and \"NO\" indicates the churn customers.\n \n\n<a id=\"section-two\"><\/a>\n# **Features**\n\n***Demographics***\n\n* CustomerID: A unique ID that identifies each customer.\n\n* Count: A value used in reporting\/dashboarding to sum up the number of customers in a filtered set.\n\n* Gender: The customer\u2019s gender: Male, Female\n\n* Age: The customer\u2019s current age, in years, at the time the fiscal quarter ended.\n\n* Senior Citizen: Indicates if the customer is 65 or older: Yes, No\n\n* Married: Indicates if the customer is married: Yes, No\n\n* Dependents: Indicates if the customer lives with any dependents: Yes, No. Dependents could be children, parents, grandparents, etc.\n\n* Number of Dependents: Indicates the number of dependents that live with the customer.\n\n***Location***\n \n* CustomerID: A unique ID that identifies each customer.\n \n* Count: A value used in reporting\/dashboarding to sum up the number of customers in a filtered set.\n \n* Country: The country of the customer\u2019s primary residence.\n \n* State: The state of the customer\u2019s primary residence.\n \n* City: The city of the customer\u2019s primary residence.\n\n* Zip Code: The zip code of the customer\u2019s primary residence.\n \n* Lat Long: The combined latitude and longitude of the customer\u2019s primary residence.\n \n* Latitude: The latitude of the customer\u2019s primary residence.\n \n* Longitude: The longitude of the customer\u2019s primary residence.\n\n***Population***\n\n* ID: A unique ID that identifies each row.\n\n* Zip Code: The zip code of the customer\u2019s primary residence.\n \n* Population: A current population estimate for the entire Zip Code area.\n \n***Services***\n\n* CustomerID: A unique ID that identifies each customer.\n\n* Count: A value used in reporting\/dashboarding to sum up the number of customers in a filtered set.\n\n* Quarter: The fiscal quarter that the data has been derived from (e.g. Q3).\n\n* Referred a Friend: Indicates if the customer has ever referred a friend or family member to this company: Yes, No\n\n* Number of Referrals: Indicates the number of referrals to date that the customer has made.\n\n* Tenure in Months: Indicates the total amount of months that the customer has been with the company by the end of the quarter specified above.\n\n* Offer: Identifies the last marketing offer that the customer accepted, if applicable. Values include None, Offer A, Offer B, Offer C, Offer D, and Offer E.\n\n* Phone Service: Indicates if the customer subscribes to home phone service with the company: Yes, No\n\n* Avg Monthly Long Distance Charges: Indicates the customer\u2019s average long distance charges, calculated to the end of the quarter specified above.\n\n* Multiple Lines: Indicates if the customer subscribes to multiple telephone lines with the company: Yes, No\n\n* Internet Service: Indicates if the customer subscribes to Internet service with the company: No, DSL, Fiber Optic, Cable.\n\n* Avg Monthly GB Download: Indicates the customer\u2019s average download volume in gigabytes, calculated to the end of the quarter specified above.\n\n* Online Security: Indicates if the customer subscribes to an additional online security service provided by the company: Yes, No\n\n* Online Backup: Indicates if the customer subscribes to an additional online backup service provided by the company: Yes, No\n\n* Device Protection Plan: Indicates if the customer subscribes to an additional device protection plan for their Internet equipment provided by the company: Yes, No\n\n* Premium Tech Support: Indicates if the customer subscribes to an additional technical support plan from the company with reduced wait times: Yes, No\n\n* Streaming TV: Indicates if the customer uses their Internet service to stream television programing from a third party provider: Yes, No. The company does not charge an additional fee for this service.\n\n* Streaming Movies: Indicates if the customer uses their Internet service to stream movies from a third party provider: Yes, No. The company does not charge an additional fee for this service.\n\n* Streaming Music: Indicates if the customer uses their Internet service to stream music from a third party provider: Yes, No. The company does not charge an additional fee for this service.\n\n* Unlimited Data: Indicates if the customer has paid an additional monthly fee to have unlimited data downloads\/uploads: Yes, No\n\n* Contract: Indicates the customer\u2019s current contract type: Month-to-Month, One Year, Two Year.\n\n* Paperless Billing: Indicates if the customer has chosen paperless billing: Yes, No\n\n* Payment Method: Indicates how the customer pays their bill: Bank Withdrawal, Credit Card, Mailed Check\n\n* Monthly Charge: Indicates the customer\u2019s current total monthly charge for all their services from the company.\n\n* Total Charges: Indicates the customer\u2019s total charges, calculated to the end of the quarter specified above.\n\n* Total Refunds: Indicates the customer\u2019s total refunds, calculated to the end of the quarter specified above.\n\n* Total Extra Data Charges: Indicates the customer\u2019s total charges for extra data downloads above those specified in their plan, by the end of the quarter specified above.\n\n* Total Long Distance Charges: Indicates the customer\u2019s total charges for long distance above those specified in their plan, by the end of the quarter specified above.\n\n***Status***\n\n* CustomerID: A unique ID that identifies each customer.\n\n* Count: A value used in reporting\/dashboarding to sum up the number of customers in a filtered set.\n\n* Quarter: The fiscal quarter that the data has been derived from (e.g. Q3).\n\n* Satisfaction Score: A customer\u2019s overall satisfaction rating of the company from 1 (Very Unsatisfied) to 5 (Very Satisfied).\n\n* Satisfaction Score Label: Indicates the text version of the score (1-5) as a text string.\n\n* Customer Status: Indicates the status of the customer at the end of the quarter: Churned, Stayed, or Joined\n\n* Churn Label: Yes = the customer left the company this quarter. No = the customer remained with the company. Directly related to Churn Value.\n\n* Churn Value: 1 = the customer left the company this quarter. 0 = the customer remained with the company. Directly related to Churn Label.\n\n* Churn Score: A value from 0-100 that is calculated using the predictive tool IBM SPSS Modeler. The model incorporates multiple factors known to cause churn. The higher the score, the more likely the customer will churn.\n\n* Churn Score Category: A calculation that assigns a Churn Score to one of the following categories: 0-10, 11-20, 21-30, 31-40, 41-50, 51-60, 61-70, 71-80, 81-90, and 91-100\n\n* CLTV: Customer Lifetime Value. A predicted CLTV is calculated using corporate formulas and existing data. The higher the value, the more valuable the customer. High value customers should be monitored for churn.\n\n* CLTV Category: A calculation that assigns a CLTV value to one of the following categories: 2000-2500, 2501-3000, 3001-3500, 3501-4000, 4001-4500, 4501-5000, 5001-5500, 5501-6000, 6001-6500, and 6501-7000.\n\n* Churn Category: A high-level category for the customer\u2019s reason for churning: Attitude, Competitor, Dissatisfaction, Other, Price. When they leave the company, all customers are asked about their reasons for leaving. Directly related to Churn Reason.\n\n* Churn Reason: A customer\u2019s specific reason for leaving the company. Directly related to Churn Category.\n\n\n**Reference:**\n\nhttps:\/\/community.ibm.com\/community\/user\/businessanalytics\/blogs\/steven-macko\/2019\/07\/11\/telco-customer-churn-1113\n\n","d5622ab0":"Now, let's derive new dataframe with \"Population\" & \"Satisfaction Score\" before applying clustering: ","3090e69d":"**Import Libraries & Setting Configurations**","8c9993fa":"Let's apply ensemble modelling to all data set:","a4c5973e":"We add \"_drop\" as suffix, so we can drop dublicated columns by using this specified suffix.Let's remove dublicated columns now:","77ed098c":"Now we' ll use the Tenure Months and Total Revenue to derive customer segments based  on  K- Means Clustering:","2282e2ea":"We've created new features, so we can remove useless cols:","4afc6e3a":"Let's analyze the segments:","8bb9326f":"***LOF(Local Outliers Factor) method:***","fe2973a5":"<a id=\"section-ten\"><\/a>\n# **Ensemble Learning**\n","283226d3":"<a id=\"section-seven\"><\/a>\n# **Modelling**\n","24b07bea":"* When the Tenure and Tech support variables are examined, it is observed that a breakdown started to be observed in the 2nd month and those who did not receive technical support service churn faster.\n\n* The churn speeds of people who receive technical support and those who do not receive internet service differ from the 30th month.","cbec57e8":"Let's fit model by using optimum k value:","67904e8b":"The three best-performing models were ensembled with the Voting Classifier:","3fe44736":"* ***General Exploration for Numerical Variables:***","56cdf8c5":"\n<a id=\"section-four\"><\/a>\n# **Methodology**\n\n* [Data Understanding](#section-five)\n* [Data Preprocessing & Feature Engineering](#section-six)\n* [Modelling](#section-seven)\n* [Automated Hyperparameter Optimization](#section-eight)\n* [Hybrid Feature Selection](#section-nine)\n* [Ensemble Modelling](#section-ten)\n* [Retention Plan](#section-eleven)","1f8d60b5":"*** Confusion Matrix:**","10bed0b0":"Both columns are exactly the same, so we can remove one of them:","ebb1cda6":"<a id=\"section-six\"><\/a>\n# **Data Preprocessing & Feature Engineering**\n\nThis part consists of 4 steps which are below:\n\n1. Missing Values  \n2. Outliers \n3. Rare Encoding, Label Encoding, One-Hot Encoding \n4. Feature Scaling  ","3d1dd01f":"Deriving \"New Region Cluster\" by combining \"New_Population_Level\" & \"New_Satisfaction_Level\":","6d803885":"We have 94 features, now let's fit the hybrid model by using features whose Importance Values are higher than 1: ","23d7036b":"* **The Relations of Categorical Variables with Target Variable:**","05baa7b3":"**2. Outliers:**","ff85ed07":"* **Base Models**","f4d1c915":"* **Target Distribution:**","0e4b3158":"Let's create clusters by using k-Means method:","d20b3b80":"***4. Feature Scaling:***","5f3181b4":"<a id=\"section-eight\"><\/a>\n# **Automated Hyperparameter Optimization**\n","a66b33d3":"**CHURN SEGMENTS**\n\nLet's assign churn segments according to the following probabilites of churn in order to determine marketing strategies and plan different actions for customers in different churn scores: \n \n \n![image.png](attachment:4126290e-02e5-4b97-a52f-7f56d3f12135.png)","d73273ae":"**Let's observe the 5-Fold CV Scores of each models by using selected features which have been obtained with hybrid features selection method:**","6527f0b1":"* ***Kaplan-Meier Curves:***\n\nNow, we'll build Kaplan-Meier Curves and also using Log-Rank test, we'll compare survival curves:\n\nSurvival analysis represents the probability that an individual (or example) will survive from time \"t\" to a time beyond. Kaplan \u2013 Meier method is generally used in this estimation process. The Log-Rank Test provides a statistical comparison of two groups, on the other hand, determines whether there is a statistically significant difference between the groups.\n","8a792498":"* ***Model Performance Metrics for Test Set***","6fbdee86":"Let's assign micro segments based on \"Population\" & \"Satisfaction Score\" by using \"New_Region_ClusterNo\":","75e22668":"<a id=\"section-five\"><\/a>\n# **Data Understanding**","99d2f405":"\n<a id=\"section-three\"><\/a>\n# **Goal**\n\n\nThe purposes of this project can be seen below:\n\n* Predicting customer churn by using information of customer behaviors, product usage characteristics, demographics. \n* Increasing customer retention rate and customer satisfaction,\n* Providing customer loyalty,\n* Increasing customer lifetime value,\n* Cost optimization and increased profitability.","d48efb5b":"***1. Missing Values***","659e7f01":"**** Segment Based on Tenure & Total Revenue***","d98f0a3a":"* ***Model Performance Metrics for Train Set***","bf5e1b74":"The default for most algorithms proba threshold is 0.50. That is, if a customer has a probability greater than 50% they are predicted as churn, if a customer has a probability less than 50% they are predicted as retained customer:","1e19c5da":"As \"Country\",\"State\" and \"Quarter\" variables  do not carry information we can remove these features:","dd993c0e":"* The group with the Churn probability class \"Very High\" and \"High\" especially prefers the monthly contract type. In order to direct these customers to a long-term contract, the first 3 months of free streaming music service can be provided.\n\n* It has been observed that the probability of churn in customers with a maximum number of services of 4 is 2 times higher than in customers with 8 or more products. Discounted additional service offer within the scope of promotion to these customers\n* can be done.\n\n* X% refund for one of the services used on birthdays and customer anniversaries to retain customers in the \"Medium\" category with a Churn probability\n\n* It has been observed that the probability of churn is 40% lower in customers who receive movie and music services compared to other customers. Providing annual contracted film and music services to customers with a high probability of Churn,\n\n* Making technical infrastructure improvements in line with customer complaints by making periodic customer surveys.","2510a601":"***FEATURE ENGINEERING:***","903974bc":"* As \"Count\" variable represents the number of records, there is no need to use this varible as a input of model prediction:\n\n* Churn Score, Churn Category, Churn Reason, CLTV will not create an input to the model as these variables are the result of the churn state.\n","4c471708":"<a id=\"section-eleven\"><\/a>\n# **Retention Plan**\n","bca93c36":"**** Location-Based Segments: K-Means Clustering***\n\n\"City\" and \"Region\" are variables with very high cardinality, so we will use K-Means Clustering to create  location-based segments to use as an input.","5781dda9":"Tenure information is \"0\" in one of these 2 columns, let's delete these records due to information inconsistency and then remove one of the columns:","6040b10d":"As can be seen above, the observations which includes NaN values are based on the features that used to calculate \"New_Total_Refund_Ratio_TotalExtraCharges\" have zero values, so we cann fill that observations with zero:","96404abb":"As can be seen, both columns about \"Device Protection\" nearly carry same information, however \"Device Protection\"  has additional information that those who do not have a protection plan do not receive internet service,  so we can drop \"Device Protection Plan\".\n ","ec96cbb4":"***3. Rare Encoding , Label & One-Hot Encoding:***","b456f7e6":"Let's convert \"unint8\" to \"int64\":","6ca48261":"**** Other Features:***","646ac514":"As can be seen,  data set includes 1129 different city. Since it will not be effective to encode these variables and also to use Latitude - Longtitude variables as  inputs directly, we can derive new variables to compose segments based on location.\n\nFor this purpose, let's try to obtain address details by using priority latitude-longitude information:","93291fe3":"* By comparing Tenure and Contract variable, probabilities of churn belonging to 3 different contract types are given. The churn rate of people who make month to month contracts is very large compared to other variables. After the 2nd month, there is a big break in the month to month variable.\n\n* The abandonment rate of customers with one-year and two-year contracts diverges after 52 months.","51db1c9c":"A rapid decrease is observed in periods when the customer tenurse is low, but the decrease continues gradually over time. To deal with this, strategies can be developed to ensure that our longtime customers subscribe to long-term plans. ","b5dbe086":"* We'll handle the **\"LOF (Local Outlier Factor)\"** method for the solution of outliers: ","cfff9c29":"**Import Data**","2237348e":"The default for most algorithms proba threshold is 0.50. That is, if a customer has a probability greater than 50% they are predicted as churn, if a customer has a probability less than 50% they are predicted as retained customer:\nThe default for most algorithms proba threshold is 0.50. That is, if a customer has a probability greater than 50% they are predicted as churn, if a customer has a probability less than 50% they are predicted as retained customer:\n\n\n![image.png](attachment:485662be-9260-4276-8e4b-4065fbf9eb19.png)"}}