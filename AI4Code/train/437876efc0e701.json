{"cell_type":{"2e4dfbdf":"code","a3eaf637":"code","135d0b2d":"code","bf830cc5":"code","4c0821b9":"code","6692dddd":"code","8fea0569":"code","f6dbead9":"code","dc91dd9c":"code","4d1db038":"code","7de40c3d":"code","17cd6d37":"code","230afaf2":"code","55099741":"code","fe337f64":"code","f4137f84":"markdown","137ed539":"markdown","2764c85f":"markdown","5e9807ca":"markdown","0c3ef52b":"markdown","d0205338":"markdown","4bed71f1":"markdown","2d6b99cc":"markdown"},"source":{"2e4dfbdf":"# ---- <import library> ----\nimport numpy as np\nimport pandas as pd\n\nfrom math import log\nimport re\n\nimport nltk\n# nltk.download('punkt')\n# nltk.download('averaged_perceptron_tagger')\n\n# for cosine similarity\nfrom numpy import dot\nfrom numpy.linalg import norm\ndef cos_sim(A, B):\n       return dot(A, B)\/(norm(A)*norm(B))\n\npd.set_option(\"display.max_columns\",None)","a3eaf637":"# ---- <read dataset> ----\ndf = pd.read_csv(\"..\/input\/netflix-shows\/netflix_titles.csv\")","135d0b2d":"# ---- <data preprocessing> ----\n# we need columns below. \n# [type, title, cast, country, rating, listed_in, description]\n\n# delete unnecessary columns\ndf1 = df.copy()\ndf1.drop(columns=['show_id','date_added','release_year','director'],axis=1, inplace=True)\n\n# handle with null data\ndf1.isnull().sum()\n\ndfv1 = df1.copy()\nncol=['cast','country','rating']\nvalues = {'cast': 'nodata', 'country': 'nodata', 'rating': 'nodata'}\ndfv1.fillna(value=values,inplace=True)\n\n","bf830cc5":"# A.1 TF-IDF \n# listed_in\n\n# exclude word 'Movies', 'TV' because we have type field \n# generage new columns for tf-idf\nexclude_wd = set(['movies','tv','&'])\nf = lambda x: ' '.join(w for w in x.split() if not w in exclude_wd)\n# generate new column 'genre'\ndfv1['genre'] = dfv1['listed_in'].str.lower().replace(',','',regex=True)\ndfv1['genre'] = dfv1['genre'].apply(f)\n\n# count per term of genre\n# each index would be the order of titles\ndef tf(t, d):\n    return d.count(t)\narr_g = dfv1['genre']\nvoc_g = sorted(list(set(w for i in arr_g for w in i.split())))\n\nvoc_g_count = []\nfor i in range(len(arr_g)): \n    voc_g_count.append([])\n    d = arr_g[i]\n    for j in range(len(voc_g)):\n        t = voc_g[j]        \n        voc_g_count[-1].append(tf(t, d))\n\ntf_g = pd.DataFrame(voc_g_count, columns = voc_g)\nprint('term count')\ndisplay(tf_g.head(5))\n\n# tf-idf: how important the word is to a document(per each title)\n# it doesn't recognize '-' as word, so 'sci-fi' would be splited into 'sci' and 'fi'\n# each index would be the order of titles\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntfidfv_g = TfidfVectorizer().fit(arr_g)\ntfidfv_g_r = tfidfv_g.transform(arr_g).toarray() # get tf-idf\n# get each word list\ntfidfv_g_v = sorted(tfidfv_g.vocabulary_.items(), key=lambda x: x[1]) \nvoc_gt = []\nfor i in tfidfv_g_v:\n    voc_gt.append(i[0])\n# get dataframe with tf-idf\ntfidfv_g_df = pd.DataFrame(tfidfv_g_r , columns = voc_gt)\n# tfidfv_g_df = tfidfv_g_df.reindex(sorted(tfidfv_g_df.columns), axis=1)\nprint('tf-idf')\ndisplay(tfidfv_g_df.head(5))","4c0821b9":"# A.2. one-hot-encoding with TF: description, cast, country\n# 1) description\n# too many description so extract only NOUN(NN)\n# but too many time spent\n\nimport nltk\narr_d = dfv1['description']\n\nvoc_d = []\nfor text in arr_d:\n    term = nltk.word_tokenize(text)\n    qu = nltk.pos_tag(term)\n    for e in qu:\n        if e[1]=='NN':\n            voc_d.append(e[0])\n            \nvoc_ds=list(set(voc_d))\n\n# tf\nvoc_d_count = []\nfor i in range(len(arr_d)): \n    voc_d_count.append([])\n    d = arr_d[i]\n    for j in range(len(voc_ds)):\n        t = voc_ds[j]        \n        voc_d_count[-1].append(tf(t, d))\n\ntf_d = pd.DataFrame(voc_d_count, columns = voc_ds)\nprint('term count')\ndisplay(tf_d.head(5))","6692dddd":"# 2) cast ; too many cast so catch only first cast\nfirst_cast = []\nfor i in dfv1['cast']:\n    a = i.split(',')[0]\n    first_cast.append(a)\n    \nvoc_cast=list(set(first_cast))\narr_c = dfv1['cast']\n\nvoc_c_count = []\nfor i in range(len(arr_c)): \n    voc_c_count.append([])\n    d = arr_c[i]\n    for j in range(len(voc_cast)):\n        t = voc_cast[j]        \n        voc_c_count[-1].append(tf(t, d))\n\ntf_c = pd.DataFrame(voc_c_count, columns = voc_cast)\nprint(\"first cast count\")\ndisplay(tf_c.head())","8fea0569":"# 3) country; catch only first country\nfirst_cnt = []\nfor i in dfv1['country']:\n    a = i.split(',')[0]\n    first_cnt.append(a)\n\nvoc_cnt=list(set(first_cnt))\narr_ct = dfv1['country']\n\nvoc_ct = []\nfor i in range(len(arr_ct)): \n    voc_ct.append([])\n    d = arr_ct[i]\n    for j in range(len(voc_cnt)):\n        t = voc_cnt[j]        \n        voc_ct[-1].append(tf(t, d))\n\ntf_ct = pd.DataFrame(voc_ct, columns = voc_cnt)\nprint('first country count')\ndisplay(tf_ct.head())","f6dbead9":"# A.3. categorical: type, rating\n\n#  type: Movie = 0 \/ TV Show = 1 (nominal)\ndfv1['type'] = dfv1['type'].apply(lambda x: 0 if x=='Movie' else 1)\n\n# rating: more audlt, get higher number (ordinary)\ndfv1['rating'] = dfv1['rating'].apply(lambda x: 0 if x=='UR' or x=='nodata' or x=='NR'\n                                      else 1 if x=='TV-Y' else 2 if x=='TV-Y7'\n                                     else 3 if x=='TV-Y7-FV' else 4 if x=='G' or x=='TV-G'\n                                     else 5 if x=='PG' or x=='TV-PG' else 6 if x=='TV-14' or x=='PG-13'\n                                     else 7 if x=='R' else 8 if x=='TV-MA' or x=='NC-17' else 9)\n        ","dc91dd9c":"# B. get cosine similarity \n# drop unnecessary column\ndfv2 =dfv1.drop(columns=['cast','country','duration','listed_in','description','genre'],axis=1)\n\n# B.1 TF-IDF(listed_in) & one-hot(country) & categorical(type,rating) (without cast)\n# B.2 TF-IDF(description) & one-hot(country) & categorical\n# B.3 one-hot encoding & categorical\n\n# listed_in = tfidfv_g_df \/ description = tfidfv_d_df\n# one-hot(country) = tf_ct \/ one-hot(cast) = tf_c\n# categorical = dfv1['type'] , dfv1['rating'] ","4d1db038":"# B.1 TF-IDF(listed_in) & one-hot(country) & categorical (without cast)\nresult_B1 = pd.concat([dfv2, tfidfv_g_df, tf_ct], join='outer', axis=1)\ndisplay(result_B1.head(5))","7de40c3d":"def recommend_genre(title):\n    if title in list(result_B1['title']):\n        mov= result_B1[result_B1['title']==title]\n        dfn= result_B1[result_B1['title']!=title]\n        new_df = dfn.copy()\n        new_df.loc[1, 'cos'] = 'ok' #to avoid pandas copywarning\n        n0 = new_df.shape[0]\n        n1 = new_df.shape[1]\n        t = np.array(mov.iloc[0,np.r_[0,2:n1-1]])\n        for i in range(n0):\n            c = cos_sim(np.array(new_df.iloc[i,np.r_[0,2:n1-1]]),t)\n            new_df.loc[i+1, 'cos'] = c\n\n        sort = new_df.sort_values('cos',ascending=False)\n        title_5 = sort.head(5)\n        return title_5[['title','cos']]\n    else: return ('cannont find title you want')\n\n# for example = print 5 movies similar to movie called '3%'\nrecommend_genre('3%')","17cd6d37":"# B.2 one-hot TF(description, country) & categorical(type, rating) (without cast)\n# because columns are duplicated with word of description, rename column of dfv2\ndfv3=dfv2.rename(columns={'title': 'mov_title','type':'tvmovtype','rating': 'aged_type'})\nresult_B2 = pd.concat([dfv3,tf_d, tf_ct], join='inner', axis=1)\ndisplay(result_B2.head(5))","230afaf2":"# it would take time because of over 5000 words \ndef recommend_description(title):\n    if title in list(result_B2['mov_title']):\n        mov=result_B2[result_B2['mov_title']==title]\n        dfn= result_B2[result_B2['mov_title']!=title]\n        new_df = dfn.copy()\n        new_df.loc[1, 'cos'] = 'ok' # to avoid pandas copywarning\n        n0 = new_df.shape[0]\n        n1 = new_df.shape[1]\n        t = np.array(mov.iloc[0,np.r_[0,2:n1-1]])\n        for i in range(n0):\n            c = cos_sim(np.array(new_df.iloc[i,np.r_[0,2:n1-1]]),t)\n            new_df.loc[i+1, 'cos'] = c\n\n        sort = new_df.sort_values('cos',ascending=False)\n        title_5 = sort.iloc[:5,:]\n        return title_5[['mov_title','cos']]\n    else: return ('cannont find title you want')\n# for example = print 5 movies similar to movie called '3%'\nrecommend_description('3%')","55099741":"# B.3 one-hot encoding & categorical\n# one-hot encoding = cast, country\n# categorical=type, rating\nresult_B3 = pd.concat([dfv2, tf_c, tf_ct], join='outer', axis=1)\ndisplay(result_B3.head(5))","fe337f64":"# it would take time \ndef recommend_cast_country(title):\n    if title in list(result_B3['title']):\n        mov=result_B3[result_B3['title']==title]\n        dfn= result_B3[result_B3['title']!=title]\n        new_df = dfn.copy()\n        new_df.loc[1, 'cos'] = 'ok' # to avoid pandas copywarning\n        n0 = new_df.shape[0]\n        n1 = new_df.shape[1]\n        t = np.array(mov.iloc[0,np.r_[0,2:n1-1]])\n        for i in range(n0):\n            c = cos_sim(np.array(new_df.iloc[i,np.r_[0,2:n1-1]]),t)\n            new_df.loc[i+1, 'cos'] = c\n\n        sort = new_df.sort_values('cos',ascending=False)\n        title_5 = sort.iloc[:5,:]\n        return title_5[['title','cos']]\n    else: return ('cannont find title you want')\n# for example = print 5 movies similar to movie called '3%'\nrecommend_cast_country('3%')","f4137f84":"### 1. import library","137ed539":"### 4.1 recommend_genre(title)","2764c85f":"### calculate matching score for content-based filtering with cosine similarity \n#### there would be three recommender\n- 1. **recommend_genre(title)**\n   : TF-IDF(listed_in) & one-hot(country) & categorical (without cast)\n- 2. **recommend_description(title)**\n   : one-hot TF(description, country) & categorical(type, rating) (without cast) \n- 3. **recommend_cast_country(title)**\n   : one-hot encoding(cast, country) & categorical(type, rating)\n","5e9807ca":"### 4. NLP and cosine similarity\n#### A. convert to numerical <br>\nA.1. TF-IDF :  listed_in(what is [TF-IDF](https:\/\/en.wikipedia.org\/wiki\/Tf\u2013idf))<br>\nA.2. one-hot-encoding with TF: description, cast, country<br>\nA.3. categorical: type, rating<br>\n\n#### B. get cosine similarity<br>\nB.1 TF-IDF(listed_in) & one-hot(country) & categorical<br>\nB.2 TF-IDF(description) & one-hot(country) & categorical<br>\nB.3 one-hot encoding & categorical<br>","0c3ef52b":"### 2. read dataset","d0205338":"### 4.3 recommend_cast_country","4bed71f1":"### 4.2 recommend_description","2d6b99cc":"### 3. data preprocessing"}}