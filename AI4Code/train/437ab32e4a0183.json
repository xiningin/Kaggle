{"cell_type":{"b39c776b":"code","eb6ddf29":"code","e6a77fc4":"code","9f73b459":"code","d2905369":"code","320d37a2":"code","16ca0a66":"code","13aa759f":"code","619bf3f2":"code","319fc871":"code","93713316":"code","1b5b5749":"code","63d6659c":"code","0c6c85d5":"code","7f87d9d0":"code","83cd8764":"code","f972df64":"code","d9c1c41b":"code","b77c2f73":"code","40e1d92e":"code","21649583":"code","23dd425b":"code","0db10f84":"code","28e09722":"code","d2fe5316":"code","c4631e8f":"code","aa636962":"code","5ef0618e":"code","6409b915":"code","046697c4":"code","80211f6a":"code","32fc62b9":"code","5cd07091":"code","653745be":"code","a27eb74e":"code","f8ca0813":"code","6c6d443a":"code","d6402f77":"code","b11d1e65":"code","58fcdeb2":"code","e404fac7":"code","f4b1468e":"code","17db5246":"code","43e2c98b":"code","b64fa97e":"code","ff1b252b":"code","a33fe4d5":"markdown","bc4b1a2e":"markdown","24f01011":"markdown","281d624c":"markdown","9d258042":"markdown","8bea17f8":"markdown"},"source":{"b39c776b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import Callback\nimport os, cv2, json,sys\nfrom PIL import Image\n# from keras.models import load_model\n\nfrom sklearn.model_selection import train_test_split\nimport tensorflow.keras.applications.efficientnet as efn\n\nfrom tensorflow.keras import backend as K\n# ignoring warnings\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\nseed = 2021\n\ntf.random.set_seed(seed)\nnp.random.seed(seed)\nos.environ['PYTHONSEED'] =str(seed)","eb6ddf29":"# For easy acces to files\nWORK_DIR = \"..\/input\/cassava-leaf-disease-classification\/\"\nos.listdir(WORK_DIR)","e6a77fc4":"with open('..\/input\/cassava-leaf-disease-classification\/label_num_to_disease_map.json', 'r') as file:\n    labels = json.load(file)\n    \nlabels","9f73b459":"CLASSES = ['0', '1', '2', '3', '4']","d2905369":"data = pd.read_csv(WORK_DIR + \"train.csv\")","320d37a2":"data.head()","16ca0a66":"data.dtypes","13aa759f":"#change for the ImageDatagen and flow_from_dataframe\ndata.label = data.label.astype(\"str\")","619bf3f2":"data.dtypes","319fc871":"data.shape[0]","93713316":"data.label.value_counts()","1b5b5749":"BATCH_SIZE = 32\nIMG_SIZE = 256\nCHANNELS = 3\nimg_size = (IMG_SIZE, IMG_SIZE)","63d6659c":"plt.figure(figsize=(15,12))\ndata_sample = data.sample(9).reset_index(drop=True)\n\nfor i in range(8):\n    plt.subplot(2,4,i+1)\n    \n    img = cv2.imread(WORK_DIR + \"train_images\/\" + data_sample.image_id[i])\n    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    plt.axis(\"off\")\n    plt.imshow(img)\n    plt.title(labels.get(data_sample.label[i]))\n    \nplt.tight_layout()\nplt.show()","0c6c85d5":"labels.get(\"0\")","7f87d9d0":"plt.figure(figsize=(15,12))\ndata_sample = data[data.label==\"0\"].sample(4).reset_index(drop=True)\nfor i in range(4):\n    plt.subplot(1,4,i+1)\n    \n    img = cv2.imread(WORK_DIR + \"train_images\/\" + data_sample.image_id[i])\n    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    plt.axis(\"off\")\n    plt.imshow(img)\n    plt.title(labels.get(data_sample.label[i]))\n    \nplt.tight_layout()\nplt.show()","83cd8764":"labels.get(\"1\")","f972df64":"plt.figure(figsize=(15,12))\ndata_sample = data[data.label==\"1\"].sample(4).reset_index(drop=True)\nfor i in range(4):\n    plt.subplot(1,4,i+1)\n    \n    img = cv2.imread(WORK_DIR + \"train_images\/\" + data_sample.image_id[i])\n    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    plt.axis(\"off\")\n    plt.imshow(img)\n    plt.title(labels.get(data_sample.label[i]))\n    \nplt.tight_layout()\nplt.show()","d9c1c41b":"labels.get(\"2\")","b77c2f73":"plt.figure(figsize=(15,12))\ndata_sample = data[data.label==\"2\"].sample(4).reset_index(drop=True)\nfor i in range(4):\n    plt.subplot(1,4,i+1)\n    \n    img = cv2.imread(WORK_DIR + \"train_images\/\" + data_sample.image_id[i])\n    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    plt.axis(\"off\")\n    plt.imshow(img)\n    plt.title(labels.get(data_sample.label[i]))\n    \nplt.tight_layout()\nplt.show()","40e1d92e":"labels.get(\"3\")","21649583":"plt.figure(figsize=(15,12))\ndata_sample = data[data.label==\"3\"].sample(4).reset_index(drop=True)\nfor i in range(4):\n    plt.subplot(1,4,i+1)\n    \n    img = cv2.imread(WORK_DIR + \"train_images\/\" + data_sample.image_id[i])\n    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    plt.axis(\"off\")\n    plt.imshow(img)\n    plt.title(labels.get(data_sample.label[i]))\n    \nplt.tight_layout()\nplt.show()","23dd425b":"labels.get(\"4\")","0db10f84":"plt.figure(figsize=(15,12))\ndata_sample = data[data.label==\"4\"].sample(4).reset_index(drop=True)\nfor i in range(4):\n    plt.subplot(1,4,i+1)\n    \n    img = cv2.imread(WORK_DIR + \"train_images\/\" + data_sample.image_id[i])\n    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    plt.axis(\"off\")\n    plt.imshow(img)\n    plt.title(labels.get(data_sample.label[i]))\n    \nplt.tight_layout()\nplt.show()","28e09722":"train, valid = train_test_split(data, test_size = 0.1, \\\n                              random_state = seed, stratify = data['label'])\n\ntrain = train.reset_index(drop= True)\nvalid = valid.reset_index(drop= True)","d2fe5316":"print(train.shape, valid.shape)","c4631e8f":"train_generator = ImageDataGenerator(\n                                    preprocessing_function = tf.keras.applications.efficientnet.preprocess_input,\n                                    rotation_range=40,\n                                    width_shift_range=0.2,\n                                    height_shift_range=0.2,\n                                    brightness_range=[0.1,0.9],\n                                    shear_range=25,\n                                    zoom_range=0.2,\n                                    horizontal_flip=True,\n                                    vertical_flip=True,\n                                    fill_mode= 'nearest'\n) \\\n        .flow_from_dataframe(\n                            train,\n                            directory = WORK_DIR + \"train_images\",\n                            x_col = \"image_id\",\n                            y_col = \"label\",\n                            target_size = img_size,\n                            class_mode = \"categorical\",\n                            interpolation = \"nearest\",\n                            batch_size = BATCH_SIZE,\n                            shuffle = True,\n                            seed = seed,    \n)\n","aa636962":"valid_generator = ImageDataGenerator(preprocessing_function = tf.keras.applications.efficientnet.preprocess_input\n) \\\n        .flow_from_dataframe(\n                            valid,\n                            directory = WORK_DIR + \"train_images\",\n                            x_col = \"image_id\",\n                            y_col = \"label\",\n                            target_size = (260,260),\n                            class_mode = \"categorical\",\n                            batch_size = BATCH_SIZE,\n                            interpolation = \"nearest\",\n                            shuffle = False,\n                            )","5ef0618e":"valid_generator.class_indices","6409b915":"\nclass CosineAnnealingScheduler(Callback):\n    \"\"\"Cosine annealing scheduler.\n    \"\"\"\n\n    def __init__(self, T_max, eta_max, eta_min=0, verbose=0):\n        super(CosineAnnealingScheduler, self).__init__()\n        self.T_max = T_max\n        self.eta_max = eta_max\n        self.eta_min = eta_min\n        self.verbose = verbose\n\n    def on_epoch_begin(self, epoch, logs=None):\n        if not hasattr(self.model.optimizer, 'lr'):\n            raise ValueError('Optimizer must have a \"lr\" attribute.')\n        lr = self.eta_min + (self.eta_max - self.eta_min) * (1 + math.cos(math.pi * epoch \/ self.T_max)) \/ 2\n        K.set_value(self.model.optimizer.lr, lr)\n        if self.verbose > 0:\n            print('\\nEpoch %05d: CosineAnnealingScheduler setting learning '\n                  'rate to %s.' % (epoch + 1, lr))\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        logs['lr'] = K.get_value(self.model.optimizer.lr)","046697c4":"lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=3e-5, \n    decay_steps=10000, \n    decay_rate=0.9)","80211f6a":"weights_path = '..\/input\/keras-efficientnetb3-noisy-student\/noisy_student_efficientnet_b4.h5'\n\ndef build_model():\n    \n    input_img = layers.Input(shape=(IMG_SIZE,IMG_SIZE,CHANNELS), name='input_image')\n    \n#     img_bn = layers.BatchNormalization()(input_img)\n    \n    x = efn.EfficientNetB4(include_top = False,\n                        weights = weights_path,\n                        drop_connect_rate=0.5\n                        )(input_img)\n    \n    avg_pool = layers.GlobalAveragePooling2D()(x)\n    \n    \n    h1 = layers.Dense(1792, activation='relu', name='h1', \\\n                     bias_regularizer = tf.keras.regularizers.L1L2(l1 = 0.01, l2 = 0.001))(avg_pool)\n      \n    h2 = layers.add([avg_pool, h1])\n    h3 = layers.add([h2, layers.Dense(1792, activation='relu',name='h3')(h2)])\n\n    drop = layers.Dropout(rate= 0.25, name ='drop')(h3)\n\n    predictions = layers.Dense(len(CLASSES), activation='softmax',kernel_regularizer= \\\n                               tf.keras.regularizers.L2(0.01))(drop)\n    \n    model = models.Model(inputs = input_img , outputs = predictions)\n    \n    return model","32fc62b9":"print(build_model().summary())","5cd07091":"def symmetric_cross_entropy(alpha, beta):\n    def loss(y_true, y_pred):\n        y_true_1 = y_true\n        y_pred_1 = y_pred\n\n        y_true_2 = y_true\n        y_pred_2 = y_pred\n\n        y_pred_1 = tf.clip_by_value(y_pred_1, 1e-7, 1.0)\n        y_true_2 = tf.clip_by_value(y_true_2, 1e-4, 1.0)\n\n        return alpha*tf.reduce_mean(-tf.reduce_sum(y_true_1 * tf.math.log(y_pred_1), axis = -1)) + beta*tf.reduce_mean(-tf.reduce_sum(y_pred_2 * tf.math.log(y_true_2), axis = -1))\n    return loss","653745be":"loss_fn = symmetric_cross_entropy(alpha=1.0,beta=1.0)","a27eb74e":"# with strategy.scope():\nmodel = build_model()\n    \nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate= lr_schedule, epsilon=0.001),\n\nloss= tf.keras.losses.CategoricalCrossentropy(\n        from_logits = False,\n        label_smoothing=0.0001,\n        name='categorical_crossentropy'\n    ),  \nmetrics=['accuracy'])","f8ca0813":"from tensorflow.keras import utils\n\nutils.plot_model(model)","6c6d443a":"model_check = ModelCheckpoint(\n                            \".\/best_model.h5\",\n                            monitor = \"val_loss\",\n                            verbose = 1,\n                            save_best_only = True,\n                            save_weights_only = True,\n                            mode = \"min\")\n\nearly_stop= EarlyStopping(\n                        monitor = \"val_loss\",\n                        min_delta=0.001,\n                        patience=5,\n                        verbose=1,\n                        mode=\"min\",\n                        restore_best_weights=True)","d6402f77":"EPOCHS = 20\nSTEP_SIZE_TRAIN = train_generator.n \/\/ train_generator.batch_size\nSTEP_SIZE_VAL = valid_generator.n \/\/ valid_generator.batch_size","b11d1e65":"history = model.fit_generator(train_generator,\n                                epochs = EPOCHS,\n                                validation_data = valid_generator,\n                                steps_per_epoch = STEP_SIZE_TRAIN,\n                                validation_steps = STEP_SIZE_VAL,\n                                callbacks = [model_check,early_stop])\n\n# model.save('leaf_disease_model.h5')","58fcdeb2":"plt.figure(figsize=(15, 5))\nplt.plot(history.history['accuracy'], 'b*-', label=\"train_acc\")\nplt.plot(history.history['val_accuracy'], 'r*-', label=\"val_acc\")\nplt.grid()\nplt.title(\"train_acc vs val_acc\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.legend()\nplt.show()","e404fac7":"plt.figure(figsize=(15, 5))\nplt.plot(history.history['loss'], 'b*-', label=\"train_loss\")\nplt.plot(history.history['val_loss'], 'r*-', label=\"val_loss\")\nplt.grid()\nplt.title(\"train_loss - val_loss\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epochs\")\nplt.legend()\nplt.show()","f4b1468e":"# model = load_model('.\/best_model.h5')","17db5246":"TEST_DIR = '..\/input\/cassava-leaf-disease-classification\/test_images\/'\ntest_images = os.listdir(TEST_DIR)\npredictions = []\n\nfor image in test_images:\n    img = Image.open(TEST_DIR + image)\n    img = img.resize(img_size)\n    img = np.expand_dims(img, axis=0)\n    predictions.extend(model.predict(img).argmax(axis = 1))","43e2c98b":"# model.save('model.h5')","b64fa97e":"# model.save('model_weights.h5')","ff1b252b":"sub = pd.DataFrame({'image_id': test_images, 'label': predictions})\ndisplay(sub)\nsub.to_csv('submission.csv', index = False)","a33fe4d5":"**Cassava Bacterial Blight (CBB)**","bc4b1a2e":"**Cassava Green Mottle (CGM)**","24f01011":"**Cassava Brown Streak Disease (CBSD)**","281d624c":"**Healthy**","9d258042":"Split data","8bea17f8":"**Cassava Mosaic Disease (CMD)**"}}