{"cell_type":{"4fa5cf40":"code","549ca718":"code","723377c4":"code","213c198c":"code","1199450d":"code","72c8a2c1":"code","a84f6b94":"code","e8d4ba0d":"code","15c07f05":"code","0c372db3":"code","d553a110":"code","6358af58":"code","f7f212c4":"code","e73a0ba6":"code","4a65c4cf":"code","6c8f7ef9":"code","85a255c7":"code","130c09fc":"code","4717c8c9":"code","93831391":"code","5e1ceaf1":"code","041bca29":"code","ba145b50":"code","316ea5b0":"code","ec3ee721":"code","244a3983":"code","1aee207d":"code","575bb7a6":"code","a89eb495":"code","0df12539":"code","4f2af6d9":"code","7c52ad97":"code","58de5c93":"code","f42b9422":"code","d3098dcd":"code","b6bfd3cc":"code","03d906ee":"code","af72b627":"code","82cd6a41":"code","e8c5b9a4":"markdown","1e46c06a":"markdown","777d33ec":"markdown","41166e68":"markdown","47fff621":"markdown","2a9ce510":"markdown","1f590d3f":"markdown","d9fd0f6f":"markdown"},"source":{"4fa5cf40":"# Loading necessary libraries\n\n# Loading numpy and pandas\nimport numpy as np \nimport pandas as pd \nfrom numpy.random import seed\n\n# Loading libraries to read images\nfrom PIL import Image\nfrom skimage.io import imread\nimport cv2\n\n# Loading necessary libraries from sklearns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn import metrics\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Loading keras for CNN\nfrom keras.utils import to_categorical\nfrom keras import optimizers\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n\n# Loading libraries for visualization\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport seaborn as sns\n\n# Loading other required libraries\nimport random\nimport time\nimport datetime","549ca718":"# Setting seed\n\nseed(111)","723377c4":"# loading train data\n\ntrain = pd.read_csv('\/kaggle\/input\/gtsrb-german-traffic-sign\/Train.csv')\ntrain.head()","213c198c":"# loading test data\n\ntest = pd.read_csv('\/kaggle\/input\/gtsrb-german-traffic-sign\/Test.csv')\ntest.head()","1199450d":"# Loading train images and their respective classes\n\ntrain_x=[]\ntrain_x_vis=[]\np='\/kaggle\/input\/gtsrb-german-traffic-sign\/'\nfor i in train['Path']:\n    try:\n        img = Image.fromarray(cv2.imread(p+i), 'RGB')\n        train_x.append(np.array(img.resize((32, 32))))\n        train_x_vis.append(np.array(img.resize((1,1)))) #For data visualization\n    except AttributeError:\n        print(\"Error in loading image\")\ntrain_x=np.array(train_x)\ntrain_x_vis=np.array(train_x_vis)\ntrain_y = np.array(train['ClassId'].values)\ntrain_x.shape","72c8a2c1":"# Loading train images and their respective classes\n\ntest_x=[]\np='\/kaggle\/input\/gtsrb-german-traffic-sign\/'\nfor i in test['Path']:\n    try:\n        img = Image.fromarray(cv2.imread(p+i), 'RGB')\n        test_x.append(np.array(img.resize((32, 32))))\n    except AttributeError:\n        print(\"Error in loading image\")\ntest_x=np.array(test_x)\ntest_y = np.array(test['ClassId'].values)\ntest_x.shape","a84f6b94":"# Loading random images to check if images have been stored in correct format\nplot1 = plt\nplot1.figure(figsize=(5,5))\nplot1.subplot(221), plot1.imshow(train_x[100])\nplot1.subplot(222), plot1.imshow(train_x[500])\nplot1.subplot(223), plot1.imshow(train_x[1400])\nplot1.subplot(224), plot1.imshow(train_x[6000])\n","e8d4ba0d":"# Number of images per class in train data\n\nunique_class, counts_class = np.unique(train_y, return_counts=True)\nfig = plt.figure()\nax = fig.add_axes([0,0,1.5,1.5])\nax.bar(unique_class,counts_class)\nax.set_xlabel('Classes', fontsize='large')\nax.set_ylabel('Count', fontsize='large')\nax.set_title('Total number of train images for each class', fontsize='large', pad=20)\nfor i in ax.patches:\n    ax.text(i.get_x(), i.get_height()+.03,str(round((i.get_height()), 1)), fontsize=10,color='black')\nplt.show()","15c07f05":"# Visualization of images on 3-D plot with classes\n\n# Creating array for all 3 axes\nx=[]\ny=[]\nz=[]\n\nfor i in range(0,train_x_vis.shape[0]):\n    temp = train_x_vis[i][0][0]\n    x.append(temp[0])\n    y.append(temp[1])\n    z.append(temp[2])\n\n# Plotting 3-D graph\n\n%matplotlib notebook\nfig = plt.figure(figsize=(9, 6))\nax = fig.add_subplot(111, projection='3d')\n\nax.scatter(x, y, z, c = train_y,s=1, alpha=0.8,cmap=\"gist_ncar\",marker=',')\n\nax.set_xlabel('X')\nax.set_ylabel('Y')\nax.set_zlabel('Z')\nax.set_title('Image data on 3-D plot with different color representing different classes', fontsize='large', pad=20)\n\nplt.show()","0c372db3":"# Creating copy of train and test set for cnn\n\ntrain_x_cnn = np.copy(train_x)\ntest_x_cnn = np.copy(test_x)","d553a110":"# Dimensions of train and test data\n\nprint(train_x.shape,train_y.shape,test_x.shape,test_y.shape) ","6358af58":"# Resizing images to fit SVM and RF\n\ntrain_x.resize(39209,3072)\ntest_x.resize(12630,3072)","f7f212c4":"# Normaliazing data for SVM and RF\n\ntrain_x = preprocessing.scale(train_x)\ntest_x = preprocessing.scale(test_x)","e73a0ba6":"# Normalizing data for CNN\n\ntrain_x_min = train_x_cnn.min(axis=(0, 1), keepdims=True)\ntrain_x_max = train_x_cnn.max(axis=(0, 1), keepdims=True)\ntrain_x_cnn=(train_x_cnn - train_x_min)\/(train_x_max - train_x_min)\n\ntest_x_min = test_x_cnn.min(axis=(0, 1), keepdims=True)\ntest_x_max = test_x_cnn.max(axis=(0, 1), keepdims=True)\ntest_x_cnn=(test_x_cnn - test_x_min)\/(test_x_max - test_x_min)","4a65c4cf":"# Spliting data into train and validation set for CNN\n\nx_train, x_val, y_train, y_val = train_test_split(train_x_cnn, train_y, test_size=0.1, random_state=121)\nprint(x_train.shape, x_val.shape, y_train.shape, y_val.shape)","6c8f7ef9":"#Converting the class labels into categorical variables for CNN\n\ny_train = to_categorical(y_train, 43)\ny_val = to_categorical(y_val, 43)","85a255c7":"# Creating blank dataframe to store model scores\n\ndf_scores  = pd.DataFrame(columns = ['Model', 'Score', 'Value'])\ndf_model = pd.DataFrame(columns = ['Model','Accuracy (%)','Time (mins)'])","130c09fc":"# Defining SVM model\n\nsvm_clf = svm.NuSVC(nu=0.05,kernel='rbf',gamma=0.00001,random_state=121)","4717c8c9":"# Fitting SVM\n\ntic = time.perf_counter()\n\nsvm_clf.fit(train_x, train_y)\n\ntoc = time.perf_counter()\nm_svm, s_svm = divmod((toc - tic), 60)\ntime_svm=float(str(str(int(m_svm))+\".\"+str(int(m_svm))))\n","93831391":"# Predicting values for test data\n\ny_pred_svm = svm_clf.predict(test_x)\n","5e1ceaf1":"# Calculating recall, precision, f1 score and accuracy of SVM\n\nrecall_svm = metrics.recall_score(test_y, y_pred_svm,average='macro')\ndf_scores.loc[len(df_scores)] = [\"SVM\",\"Recall\",recall_svm]\n\nprecision_svm = metrics.precision_score(test_y, y_pred_svm,average='macro')\ndf_scores.loc[len(df_scores)] = [\"SVM\",\"Precision\",precision_svm]\n\nf1_svm = metrics.f1_score(test_y, y_pred_svm,average='macro')\ndf_scores.loc[len(df_scores)] = [\"SVM\",\"F1\",f1_svm]\n\nacc_svm=metrics.accuracy_score(test_y,y_pred_svm)\ndf_scores.loc[len(df_scores)] = [\"SVM\",\"Accuracy\",acc_svm]\n\ndf_model.loc[len(df_model)] = [\"SVM\",acc_svm*100,time_svm]\nacc_svm","041bca29":"# Classification report for SVM\n\nprint(\"Classification report for SVM classifier %s:\\n%s\\n\"\n      % (svm_clf, metrics.classification_report(test_y, y_pred_svm)))","ba145b50":"# Creating list of number of trees\n\ntree_list = [50,100,200,300,500]","316ea5b0":"y_pred_list=[]\ntime_rf_list=[]\nrf_accuracy=[]\nfor n in tree_list:\n    \n    # Defining RF model with 'n' trees\n    rf_clf = RandomForestClassifier(n_estimators=n, random_state=121,criterion='entropy')\n    tic = time.perf_counter()\n    \n    # Fitting RF\n    rf_clf.fit(train_x, train_y)\n    toc = time.perf_counter()\n    \n    # Predicting values for test data\n    y_pred_list.append(rf_clf.predict(test_x))\n    \n    # Calculating time taken\n    m_rf, s_rf = divmod((toc - tic), 60)\n    time_rf_list.append(float(str(str(int(m_rf))+\".\"+str(int(m_rf)))))\n    \n    # Calculating accuracy of RF\n    rf_accuracy.append(metrics.accuracy_score(test_y,rf_clf.predict(test_x)))","ec3ee721":"# Plotting time and accuracy for all RF models\n# Epochs vs Accuracy\n%matplotlib inline\nfig = plt.figure(figsize=(10,7))\nax = plt.axes()\nax.plot(time_rf_list,rf_accuracy,'bo')\nax.plot(time_rf_list,rf_accuracy)\n\nax.set_title('Time taken by RF for n trees with Accuracy',pad=20)\nax.set_xlabel('Time')  \nax.set_ylabel('Accuracy')\n\nfor x,y,i in zip(time_rf_list,rf_accuracy,tree_list):\n\n    label = \"n= {},\\n Time = {} mins,\\n Accuracy = {} \".format(i,round(x,4),round(y,4))\n    ax.text(x-2,y,label, fontsize=10)\nplt.show()  ","244a3983":"# Selecting best RF model\n\nrf_clf = RandomForestClassifier(n_estimators=300, random_state=121,criterion='entropy')\ny_pred_rf = y_pred_list[3]\ntime_rf = time_rf_list[3]\n\nacc_rf = rf_accuracy[3]\ndf_scores.loc[len(df_scores)] = [\"RF\",\"Accuracy\",acc_rf]\n\ndf_model.loc[len(df_model)] = [\"RF\",acc_rf*100,time_rf]\nacc_rf","1aee207d":"# Calculating recall, precision and f1 score for RF\n\nrecall_rf = metrics.recall_score(test_y, y_pred_rf,average='macro')\ndf_scores.loc[len(df_scores)] = [\"RF\",\"Recall\",recall_rf]\n\nprecision_rf = metrics.precision_score(test_y, y_pred_rf,average='macro')\ndf_scores.loc[len(df_scores)] = [\"RF\",\"Precision\",precision_rf]\n\nf1_rf = metrics.f1_score(test_y, y_pred_rf,average='macro')\ndf_scores.loc[len(df_scores)] = [\"RF\",\"F1\",f1_rf]\n","575bb7a6":"# Classification report for RF\n\nprint(\"Classification report for RF classifier %s:\\n%s\\n\"\n      % (rf_clf, metrics.classification_report(test_y, y_pred_rf)))","a89eb495":"# Defining CNN model\n\ncnn_clf = Sequential()\ncnn_clf.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=x_train.shape[1:]))\ncnn_clf.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\ncnn_clf.add(MaxPool2D(pool_size=(2, 2)))\ncnn_clf.add(Dropout(rate=0.2))\ncnn_clf.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\ncnn_clf.add(MaxPool2D(pool_size=(2, 2)))\ncnn_clf.add(Dropout(rate=0.2))\ncnn_clf.add(Conv2D(filters=128, kernel_size=(2, 2), activation='relu'))\ncnn_clf.add(MaxPool2D(pool_size=(2, 2)))\ncnn_clf.add(Dropout(rate=0.2))\ncnn_clf.add(Flatten())\ncnn_clf.add(Dense(256, activation='relu'))\ncnn_clf.add(Dropout(rate=0.2))\ncnn_clf.add(Dense(128, activation='relu'))\ncnn_clf.add(Dropout(rate=0.2))\ncnn_clf.add(Dense(43, activation='softmax'))","0df12539":"# Compilation of the model\n\ncnn_clf.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n","4f2af6d9":"# Fitting CNN\n\nepochs = 10\ntic = time.perf_counter()\n\ncnn_fit = cnn_clf.fit(x_train, y_train, batch_size=128, epochs=epochs, validation_data=(x_val, y_val))\n\ntoc = time.perf_counter()\n\nm_cnn, s_cnn = divmod((toc - tic), 60)\ntime_cnn=float(str(str(int(m_cnn))+\".\"+str(int(m_cnn))))","7c52ad97":"# Epochs vs Accuracy\nfig = plt.figure(figsize=(7,4))\nax = plt.axes()\nep=list(range(1, 11))\nax.plot(ep,cnn_fit.history['accuracy'],label=\"Train Accuracy\");\nax.plot(ep,cnn_fit.history['val_accuracy'],label=\"Validation Accuracy\")\nax.set_title('Train, Validation Accuracy')\nax.set_xlabel('Epochs')  \nax.set_ylabel('Accuracy')\nax.legend()\nplt.show()  ","58de5c93":"# Epochs vs Loss\nfig = plt.figure(figsize=(7,4))\nax = plt.axes()\nep=list(range(1, 11))\nax.plot(ep,cnn_fit.history['loss'],label=\"Train Loss\");\nax.plot(ep,cnn_fit.history['val_loss'],label=\"Validation Loss\")\nax.set_title('Train, Validation Loss')\nax.set_xlabel('Epochs')  \nax.set_ylabel('Loss')\nax.legend()\nplt.show() ","f42b9422":"# Predicting values for test data\n\ny_pred_cnn = cnn_clf.predict_classes(test_x_cnn)\n","d3098dcd":"# Calculating and storing recall, precision, f1 score and accuracy of CNN\n\nrecall_cnn = metrics.recall_score(test_y, y_pred_cnn,average='macro')\ndf_scores.loc[len(df_scores)] = [\"CNN\",\"Recall\",recall_cnn]\n\nprecision_cnn = metrics.precision_score(test_y, y_pred_cnn,average='macro')\ndf_scores.loc[len(df_scores)] = [\"CNN\",\"Precision\",precision_cnn]\n\nf1_cnn = metrics.f1_score(test_y, y_pred_cnn,average='macro')\ndf_scores.loc[len(df_scores)] = [\"CNN\",\"F1\",f1_cnn]\n\nacc_cnn=metrics.accuracy_score(test_y,y_pred_cnn)\ndf_scores.loc[len(df_scores)] = [\"CNN\",\"Accuracy\",acc_cnn]\n\ndf_model.loc[len(df_model)] = [\"CNN\",acc_cnn*100,time_cnn]\nacc_cnn","b6bfd3cc":"# Classification report for CNN\n\nprint(\"Classification report for CNN classifier %s:\\n%s\\n\"\n      % (cnn_clf, metrics.classification_report(test_y, y_pred_cnn)))","03d906ee":"df_model","af72b627":"\nfig = plt.figure(figsize=(11,8))\nax = plt.axes()\nax = sns.barplot(x=\"Model\", y=\"Value\", hue=\"Score\", data=df_scores, palette=\"ch:.25\",edgecolor=\"1\")\nax.set_title('Comparision of SVM, RF, CNN for Traffic Signs')\n\nfor i in ax.patches:\n    ax.text(i.get_x(), i.get_height()+.02,str(round((i.get_height()), 4)), fontsize=10,color='dimgrey')\nplt.show() ","82cd6a41":"# Saving CNN model\n\ncnn_clf.save('cnn_classifier.h5')","e8c5b9a4":"## 1. Loading necessary libraries and data","1e46c06a":"## 2. Exploring the data","777d33ec":"# A Comparison of Classification models for Traffic Signs\n\n","41166e68":"### 4.3 Convolution Neural Network (CNN)","47fff621":"## 4. Implementation of Algorithms","2a9ce510":"### 4.2 Random Forest","1f590d3f":"## 3. Processing Data","d9fd0f6f":"### 4.1 Support Vector Machine (SVM)"}}