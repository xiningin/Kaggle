{"cell_type":{"cb832335":"code","b1e7ce18":"code","b08f7d8f":"code","843d5c47":"code","921c4bb9":"code","7ccdcdc8":"code","186f5e2b":"code","329956c9":"code","5b2878a9":"code","2ed66b0a":"code","c48b7dad":"code","d16ddd61":"code","1085da4c":"code","7ea7cefd":"code","e1961ea3":"code","bda68f04":"code","cdb350f5":"code","19762b0d":"code","c67f110c":"code","8f7fa401":"code","2d841083":"code","d862c80d":"code","6f4dcdb3":"code","bfb196b8":"code","8fbeccb0":"markdown","f3e2f954":"markdown","6d8bb6e0":"markdown"},"source":{"cb832335":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b1e7ce18":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\n#Libraries for Linear regression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error\n\n#Library for RFR\nfrom sklearn.ensemble import RandomForestRegressor\n\n#Library for Lasso,Ridge, Elastic\nfrom sklearn.linear_model import Ridge,Lasso,ElasticNet\n\n#Library for Decision Tree\nfrom sklearn import tree\n\n#Library for XGBoost\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier\n\n#For doing scaling\nfrom sklearn.preprocessing import StandardScaler\n","b08f7d8f":"MSE_Train=[]\nRMSE_Train=[]\nMAE_Train=[]\nMSE_Test=[]\nRMSE_Test=[]\nMAE_Test=[]\nHyper=[]\nrfestimator=[]\ntree_depth=[]","843d5c47":"def ModelFlow1():\n    \n    CreditScoreData=[]\n    CreditTrain=pd.read_csv('\/kaggle\/input\/credit-score-prediction\/CreditScore_train.csv')\n    \n    CreditTest=pd.read_csv('\/kaggle\/input\/credit-score-prediction\/CreditScore_test.csv')\n    \n    #Concatenate both Train & Test\n    CreditScoreMerge=pd.concat([CreditTrain,CreditTest],axis=0)\n    print(CreditScoreMerge.shape)\n    \n   \n    #for i in CreditScoreMerge.columns:\n        #print(i + '-' + str(CreditScoreMerge[i].isnull().sum()))\n    ","921c4bb9":"def ModelFlow():\n    CreditTrain=pd.read_csv('\/kaggle\/input\/credit-score-prediction\/CreditScore_train.csv')\n    \n    CreditTest=pd.read_csv('\/kaggle\/input\/credit-score-prediction\/CreditScore_test.csv')\n    \n    #Concatenate both Train & Test\n    CreditScoreMerge=pd.concat([CreditTrain,CreditTest],axis=0)\n    \n    print(\"CreditScoreTrain:\",CreditTrain.head())\n    print(\"CreditScoreTest:\",CreditTest.head())\n    print(\"CreditScoreMerge:\",CreditScoreMerge.head())\n    \n    #calling the function KnowTheData\n    KnowTheData(CreditScoreMerge)\n    \n    print('******************************************')\n    print(\"Linear Model Starts\")\n    \n    CreditTrainTestLinear=ModelType(CreditScoreMerge,modeltype='Linear')\n    \n    \n    #Splitting from merged Data Train & Test\n    CreditTrain1=CreditScoreMerge.head(80000)\n    CreditTest1=CreditScoreMerge.tail(20000)\n    \n    #ModelSelection\n    print(\"Model Selection Starts for Linear...\")\n    \n    \n    X_train,X_test,Y_train,Y_test,CreditTest1=ModelSelection(CreditTrain1,CreditTest1)\n    \n    print(\"Model Selection Ends for Linear...\")\n    \n    #BuildLinearModel\n    LinearReg(X_train,X_test,Y_train,Y_test,CreditTest1)\n    \n    print(\"Linear Model Type Build Process ends.....\")\n    print('**********************************************')\n    \n    #Add Other Models below\n    \n    #Build Ridge Model\n    RidgeReg(X_train,X_test,Y_train,Y_test,CreditTest1)\n    \n    #Tree Model\n    print('**********************************************')\n    print(\"Tree Model Type Build Process starts.....\")\n    \n    CreditScoreMergeTree = ModelType(CreditScoreMerge,modeltype = 'Tree')\n    \n    #split the dataset into train and test after data cleaning and select the important features for the model\n    CreditTrain1=CreditScoreMergeTree.head(80000)\n    CreditTest1=CreditScoreMergeTree.tail(20000)\n    \n    print(\"Model Selection Starts for Tree.....\")\n    \n    #Model Selection\n    X_train,X_test,Y_train,Y_test,CreditTest1=ModelSelection(CreditTrain1,CreditTest1)\n    \n    print(\"Model Selection Ends for Tree.....\")\n    \n    #Build DSRegressor Model\n    DSReg(X_train,X_test,Y_train,Y_test,CreditTest1)\n    \n    #Build RandomForest Regressor Model\n    #RandomForestReg(X_train,X_test,Y_train,Y_test,CreditTest1)\n    \n    #Build XGBoost Regressor Model\n    #XGBoost(X_train,X_test,Y_train,Y_test,CreditTest1)\n    \n    print('**********************************************')\n    print(\"Tree Model Type Build Process ends.....\")\n","7ccdcdc8":"def TrainShape(CreditTrain):\n    display(\"Shape of CreditScoreTrain\")\n    CreditTrain.shape\n","186f5e2b":"def TestShape(CreditTest):\n    display(\"Shape of CreditScoreTest\")\n    CreditTest.shape\n","329956c9":"def KnowTheData(CreditScoreMerge):\n    display(\"Shape of the Merged Dataframe\")\n    CreditScoreMerge.shape\n    \n    CreditScoreData=[]\n    CreditScoreData.append(['FeatureName','DataType','No.ofMiss_Values','Percent_of_Miss_Values'])\n    for col in CreditScoreMerge.columns:\n        CreditScoreData.append([col,CreditScoreMerge[col].dtypes,CreditScoreMerge[col].isnull().sum(),(CreditScoreMerge[col].isnull().sum()\/len(CreditScoreMerge)*100)])\n        \n    display(CreditScoreData)\n        \n","5b2878a9":"def ModelType(CreditScoreMerge,modeltype):\n    if modeltype=='Linear':\n        CreditScoreMerge=DataCleaning(CreditScoreMerge,modeltype)\n        CreditScoreMerge=Feature_Selection(CreditScoreMerge)\n    else:\n        CreditScoreMerge=DataCleaning(CreditScoreMerge,modeltype)\n   \n        \n    return CreditScoreMerge\n\n","2ed66b0a":"def DataCleaning(CreditScoreMerge,modeltype):\n    DuplicatedData(CreditScoreMerge)\n    if modeltype==\"Linear\":\n        print(\"Data Cleaning Process starts for Linear..........\")\n        CreditScoreMerge=DataForImputation(CreditScoreMerge,modeltype)\n        CreditScoreMerge=Imputation(CreditScoreMerge,modeltype)\n        print(\"DataCleaning Process Ends For Linear.....\")\n    else:\n        print(\"DataCleaning Process Starts For Tree.....\")\n        CreditScoreMerge = Imputation(CreditScoreMerge,modeltype)\n        print(\"DataCleaning Process Ends For Tree.....\")\n    \n    \n    return CreditScoreMerge","c48b7dad":"def DuplicatedData(CreditScoreMerge):\n    display(\"Finding Duplicated Data....\")\n    display(\"Total number of Duplicated Records:\", CreditScoreMerge.duplicated().sum())\n    ","d16ddd61":"def DataForImputation(CreditScoreMerge,modeltype):\n    Feature_For_Model=[]\n    Missing_Count=0.0\n    \n    if modeltype == \"Linear\":\n        print('DataAnalysis for Imputation starts for Linear...')\n        print(\"Drop the features whose null % greater than or equal to 50% of Missing Values:\")\n        #print('Before Err')\n        for col in CreditScoreMerge.columns:\n            Missing_Count=((CreditScoreMerge[col].isnull().sum()\/len(CreditScoreMerge))*100)\n            #print('Before IF')\n            if Missing_Count < 50:\n                Feature_For_Model.append(col)\n            else:\n                CreditScoreMerge.drop(col,axis=1,inplace=True)\n\n    #print(\"After FOR\")\n    Feature_For_Model\n    display(np.array(Feature_For_Model).T)\n    \n    print(\"DataAnalysis For Imputation Ends For Linear...\")\n    \n    return CreditScoreMerge\n    ","1085da4c":"#ImputeMissingValues\n\ndef Imputation(CreditScoreMerge,modeltype):\n    if modeltype == 'Linear':\n        print(\"Imputation starts for Linear...\")\n        for col in CreditScoreMerge.columns:\n            CreditScoreMerge[col].fillna(CreditScoreMerge[col].mean(),inplace=True)\n            print(\"Shape of the Dataframe after Imputation...\")\n            display(CreditScoreMerge.shape)\n            \n        print(\"Imputation ends for Linear.....\")\n    else:\n        print(\"Imputation starts for Tree.....\")\n        display(CreditScoreMerge.shape)\n        CreditScoreMerge.fillna(0,inplace=True)\n        print(\"Imputation ends for Tree.....\")\n\n    \n    return CreditScoreMerge","7ea7cefd":"def Feature_Selection(CreditScoreMerge):\n    print(\"Identifying the relationship of independent and dependent variables for Linear\")\n    CreditScoreCorr=CreditScoreMerge.corr(method='pearson')[['y']].T\n    CreditScoreCorr=CreditScoreCorr[CreditScoreCorr>0.3]\n    ImportantFeatures=[]\n    for col in CreditScoreCorr.columns:\n        if CreditScoreCorr[col].isnull()[0]!=True:\n            ImportantFeatures.append(col)\n    \n    print(\"Important Features from Correlation for Linear\")\n    display(ImportantFeatures)\n    \n   \n    \n    return CreditScoreMerge[ImportantFeatures]\n        \n","e1961ea3":"def ModelSelection(CreditTrain1,CreditTest1):\n    print(\"Model Selection Starts..\")\n    X=CreditTrain1.drop('y',axis=1)\n    Y=CreditTrain1['y']\n    \n    CreditTest1.drop('y',axis=1,inplace=True)\n    \n    X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=10)\n    \n    \n    print(\"X_train shape:\", X_train.shape)\n    print(\"X_test shape:\",X_test.shape)\n    print(\"Y_train shape:\",Y_train.shape)\n    print(\"Y_test shape:\",Y_test.shape)\n    \n    print(\"Model Selection Ends.....\")\n    \n    return X_train,X_test,Y_train,Y_test,CreditTest1\n    ","bda68f04":"def LinearReg(X_train,X_test,Y_train,Y_test,CreditTest1):\n    algo=\"Linear\"\n    model=LinearRegression()\n    model.fit(X_train,Y_train)\n    print(\"Linear Regression...\")\n    \n    Y_train_predict=model.predict(X_train)\n    Y_test_predict=model.predict(X_test)\n    \n    Y_Credit_test_predict=model.predict(CreditTest1)\n    print(\"*********Linear Regression Measures************\")\n    \n    Measures(Y_train,Y_train_predict,Y_test,Y_test_predict,Y_Credit_test_predict)\n    \n    LinearAccuracy=pd.DataFrame({\"MSE-Train\":MSE_Train,\"MSE-Test\":MSE_Test,\"RMSE-Train\":RMSE_Train,\"RMSE-Test\":RMSE_Test,\"MAE-Train\":MAE_Train,\"MAE-Test\":MAE_Test})\n    ModelPerformance(algo,LinearAccuracy)\n    ","cdb350f5":"def RidgeReg(X_train,X_test,Y_train,Y_test,Credit_Test):\n    global Hyper\n    algo='Ridge'\n    print(\"Ridgeregression:\")\n    print(\"********Ridge Regression Measures*************\")\n    \n    for alpha in range(0,10):\n        model=Ridge(alpha,normalize=True)\n        Hyper.append(alpha)\n        model.fit(X_train,Y_train)\n        Y_train_predict=model.predict(X_train)\n        Y_test_predict=model.predict(X_test)\n        Y_Credit_test_predict=model.predict(Credit_Test)\n        Measures(Y_train,Y_train_predict,Y_test,Y_test_predict,Y_Credit_test_predict)\n        \n    Ridge_optimize=pd.DataFrame({\"Penalty\":Hyper,\"MSE-Train\":MSE_Train,\"MSE-Test\":MSE_Test,\"RMSE-Train\":RMSE_Train,\"RMSE-Test\":RMSE_Test,\"MAE-Train\":MAE_Train,\"MAE-Test\":MAE_Test})\n    ModelPerformance(algo, Ridge_optimize)\n","19762b0d":"def DSReg(X_train,X_test,Y_train,Y_test,CreditTest1):\n    global Hyper\n    algo='ds'\n    print('Decision Tree')\n    print(\"***********Decision Tree Regression Measures*****************\")\n    for depth in range(1,20):\n        dsmodel=tree.DecisionTreeRegressor(max_depth=depth)\n        Hyper.append(depth)\n        dsmodel.fit(X_train,Y_train)\n        Y_train_predict=dsmodel.predict(X_train)\n        Y_test_predict=dsmodel.predict(X_test)\n        Y_Credit_test_predict = dsmodel.predict(CreditTest1)\n        Measures(Y_train,Y_train_predict,Y_test,Y_test_predict,Y_Credit_test_predict)\n    \n    ds_optimize = pd.DataFrame({\"TreeDepth\":Hyper,\"MSE-Train\":MSE_Train,\"MSE-Test\":MSE_Test,\"RMSE-Train\":RMSE_Train,\"RMSE-Test\":RMSE_Test,\"MAE-Train\":MAE_Train,\"MAE-Test\":MAE_Test})\n    \n    ModelPerformance(algo,ds_optimize)","c67f110c":"def RandomForestReg(X_train,X_test,Y_train,Y_test,CreditTest1):\n    global rfestimator, tree_depth\n    algo=\"RandomForest\"\n    print(\"**************Random Forest Regressor*****************\")\n    \n    for estimator in range(10,21):\n        for depth in range(1,10):\n            rfestimator.append(estimator)\n            tree_depth.append(depth)\n            random_model=RandomForestRegressor(n_estimators=estimator,max_depth=depth,random_state=0)\n            random_model.fit(X_train,Y_train)\n            \n            Y_train_predict=random_model.predict(X_train)\n            Y_test_predict=random_model.predict(X_test)\n            Y_Credit_test_predict=random_model.predict(CreditTest1)\n            \n            Measures(Y_train,Y_train_predict,Y_test,Y_test_predict,Y_Credit_test_predict)\n            \n    random_accuracy = pd.DataFrame({\"No of Trees\":rfestimator,\"Tree Depth\": tree_depth,\"MSE-Train\":MSE_Train,\"MSE-Test\":MSE_Test,\"RMSE-Train\":RMSE_Train,\"RMSE-Test\":RMSE_Test,\"MAE-Train\":MAE_Train,\"MAE-Test\":MAE_Test})\n    \n    ModelPerformance(algo,random_accuracy)\n    rfestimator = []\n    tree_depth = []\n            ","8f7fa401":"def XGBoost(X_train,X_test,Y_train,Y_test,CreditTest1):\n    print(\"**********XGBoost**************\")\n    global rfestimator, tree_depth\n    algo = \"XGBoost\"\n    depth=9\n    \n    for estimator in range(100,1001,100):\n        rfestimator.append(estimator)\n        tree_depth.append(depth)\n        xgb_model=xgb.XGBRegressor(n_estimators=estimator,learning_rate=0.1,subsample=0.75,colsample_bytree=1,max_depth=depth,random_state=10,gamma=1)\n        xgb_model.fit(X_train,Y_train)\n        Y_train_predict=xgb_model.predict(X_train)\n        Y_test_predict=xgb_model.predict(X_test)\n        Y_Credit_test_predict=xgb_model.predict(CreditTest1)\n        \n        Measures(Y_train,Y_train_predict,Y_test,Y_test_predict,Y_Credit_test_predict)\n    xgb_accuracy = pd.DataFrame({\"No of Trees\":rfestimator,\"Tree Depth\": tree_depth,\"MSE-Train\":MSE_Train,\"MSE-Test\":MSE_Test,\"RMSE-Train\":RMSE_Train,\"RMSE-Test\":RMSE_Test,\"MAE-Train\":MAE_Train,\"MAE-Test\":MAE_Test})\n        \n    ModelPerformance(algo,xgb_accuracy)\n    rfestimator = []\n    tree_depth = []\n    ","2d841083":"def Measures(Y_train,Y_train_predict,Y_test,Y_test_predict,Y_Credit_test_predict):\n    global MSE_Train,RMSE_Train,MAE_Train,MSE_Test,RMSE_Test,MAE_Test,Hyper\n    \n    MSE=mean_squared_error(Y_train,Y_train_predict)\n    RMSE=np.sqrt(mean_squared_error(Y_train,Y_train_predict))\n    MAE=mean_absolute_error(Y_train,Y_train_predict)\n    \n    MSE_Train.append(MSE)\n    RMSE_Train.append(RMSE)\n    MAE_Train.append(MAE)\n    \n    MSE = mean_squared_error(Y_test,Y_test_predict)\n    RMSE = np.sqrt(mean_squared_error(Y_test,Y_test_predict))\n    MAE = mean_absolute_error(Y_test,Y_test_predict)\n    \n    MSE_Test.append(MSE)\n    RMSE_Test.append(RMSE)\n    MAE_Test.append(MAE)\n    \n    \n    ","d862c80d":"def ModelPerformance(algo,performance):\n    print(\"Performance of the model:\", algo)\n    global Hyper, MSE_Train, RMSE_Train,MAE_Train,MSE_Test, RMSE_Test,MAE_Test\n    \n    display(performance)\n    if algo=='XGBoost':\n        plt.figure(figsize=(10,5))\n        sns.lineplot(x=performance[\"No of Trees\"],y=performance[\"MSE-Train\"])\n        sns.lineplot(x=performance[\"No of Trees\"],y=performance[\"MSE-Test\"])\n        plt.xlabel(\"No of Trees\")\n        plt.ylabel(\"MSE-Error\")\n        \n        plt.show()\n        \n    Hyper = []\n    MSE_Train = []\n    RMSE_Train = []\n    MAE_Train = []\n    MSE_Test = []\n    RMSE_Test = []\n    MAE_Test = []\n","6f4dcdb3":"def Measures1(Y_train,Y_train_predict,Y_test,Y_test_predict,Y_Credit_test_predict,algo):\n    if algo==\"Linear\":\n        print(\"MSE Train:\",mean_squared_error(Y_train,Y_train_predict))\n        print(\"RMSE Train:\", np.sqrt(mean_squared_error(Y_train,Y_train_predict)))\n        print(\"MAE Train:\",mean_absolute_error(Y_train,Y_train_predict))\n        print(\"********************************************************\")\n        print(\"MSE Test:\",mean_squared_error(Y_test,Y_test_predict))\n        print(\"RMSE Test:\",np.sqrt(mean_squared_error(Y_test,Y_test_predict)))\n        print(\"MAE Test:\",mean_absolute_error(Y_test,Y_test_predict))\n        print(\"********************************************************\")\n        print(\"Credit Score Test Final Result\")\n        print(Y_Credit_test_predict)\n    \n    elif algo=='Random':\n        rfr = RandomForestRegressor(n_jobs=-1)\n        estimators=np.arange(10,200,10)\n        scores=[]\n        for n in estimators:\n            rfr,set_params(n_estimators=n)\n            rfr.fit(X_train,Y_train)\n            rfr.append(rfr.score(X_test,Y_test))\n        plt.title(\"Effect of n_estimators\")\n        plt.xlabel(\"n_estimator\")\n        plt.ylabel(\"score\")\n        plt.plot(estimators, scores)\n        ","bfb196b8":"ModelFlow()","8fbeccb0":"**Importing the Libraries**","f3e2f954":"**Reading CreditScore_train.csv & CreditScore_test.csv file.**","6d8bb6e0":"**TrainShape TestShape: This function will give shape of CreditScore_train.csv & CreditScore_test.csv file.**"}}