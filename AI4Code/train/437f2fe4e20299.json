{"cell_type":{"229f5b12":"code","4363e784":"code","59ce4fb5":"code","40df08ba":"code","fda8ecac":"code","cfe0845d":"code","6f54f476":"code","bf4dbfc4":"code","26a18c55":"code","623c6adc":"code","0abda0f3":"code","b1ff5ac0":"code","b80ebb12":"code","cd087691":"code","8d18d8d7":"code","a04de95b":"markdown","ada90697":"markdown","d4941c63":"markdown","8a5048f4":"markdown","cd49a4f3":"markdown"},"source":{"229f5b12":"#import the necessary libraries\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom skimage.io import imshow\n\nfrom keras.layers import Dense\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dropout\nfrom keras.models import Sequential","4363e784":"#Reading dataset\nX = pd.read_csv(\"..\/input\/deepsat-sat4\/X_test_sat4.csv\") #values are in DataFrame format\nY = pd.read_csv(\"..\/input\/deepsat-sat4\/y_test_sat4.csv\") #values are in DataFrame format\nX = np.array(X) # converting Dataframe to numpy array\nY = np.array(Y) # converting Dataframe to numpy array","59ce4fb5":"#Shape of data used\nprint(\"Train data shape: \",X.shape)","40df08ba":"#reshaping (99999, 3136) to (99999, 28, 28, 4)\nX = X.reshape([99999,28,28,4]).astype(float)\nprint(\"Reshaped data format: \",X.shape)","fda8ecac":"#splitting data into train and test\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.20, random_state = 0) ","cfe0845d":"#format of train and test data\nprint(\"X train data shape: \",x_train.shape)\nprint(\"Y train data shape: \",y_train.shape)\nprint(\"X test data shape: \",x_test.shape)\nprint(\"Y test data shape: \",y_test.shape)","6f54f476":"#normalizing train and test data\nx_train = x_train\/255\nx_test = x_test\/255","bf4dbfc4":"#Images in the data with its label(reduced image)\nimg_no = 1276 #type a random number in inclusive range 0 to 79999\nimshow(np.squeeze(x_train[img_no,:,:,0:3]).astype(float)) #taking only RGB format\nplt.show()\nprint ('Ground Truth: ',end='')\nif y_train[img_no, 0] == 1:\n    print ('Barren Land')\nelif y_train[img_no, 1] == 1:\n    print ('Forest Land')\nelif y_train[img_no, 2] == 1:\n    print ('Grassland')\nelse:\n    print ('Other')","26a18c55":"#defining layers\nnum_classes = 4\nfrom keras.layers.advanced_activations import LeakyReLU\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(28,28,4),padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D((2, 2),padding='same'))\nmodel.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\nmodel.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))                  \nmodel.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='linear'))\nmodel.add(LeakyReLU(alpha=0.1))                  \nmodel.add(Dense(num_classes, input_shape=(3136,), activation='softmax'))\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","623c6adc":"#CNN Model summary\nmodel.summary()","0abda0f3":"#fitting the data into the model\nmodel.fit(x_train,y_train,batch_size=64, epochs=20, verbose=1, validation_split=0.20)","b1ff5ac0":"#predicting model performance\npreds = model.predict(x_test, verbose=1)","b80ebb12":"img_no = 587#Type a number between 0 and 20000 inclusive\nimshow(np.squeeze(x_test[img_no,:,:,0:3]).astype(float)) #Only seeing the RGB channels\nplt.show()\n#Predicted classification\nprint ('Predicted Label: ',end='')\nif preds[img_no, 0]*100  >= 80:\n    print ('Barren Land')\nelif preds[img_no, 1]*100 >= 80:\n    print ('Forest Land')\nelif preds[img_no, 2]*100 >= 80:\n    print ('Grassland')\nelse:\n    print ('Other')\n\n#Acutal classification\nprint ('Actual label: ',end='')\nif y_test[img_no, 0] == 1:\n    print ('Barren Land')\nelif y_test[img_no, 1] == 1:\n    print ('Forest Land')\nelif y_test[img_no, 2] == 1:\n    print ('Grassland')\nelse:\n    print ('Other')","cd087691":"#model performance evaluation\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nprint(\"Accuracy score: \",accuracy_score(y_test, np.round_(preds)))\nprint(\"Classification report:\")\nprint(classification_report(y_test, np.round_(preds)))","8d18d8d7":"print(\"Accuracy of CNN model is: \", accuracy_score(y_test,np.round_(preds))*100)","a04de95b":"**Mini project Implementation**  \n* 1MS17CS025  D.S Rahul https:\/\/www.kaggle.com\/dsrhul\n* 1MS17CS053  M Chandan https:\/\/www.kaggle.com\/chandanvirat18\n* 1MS17CS056  Mahantesh Shivanand Shivakale https:\/\/www.kaggle.com\/mahantesh8\n* 1MS17CS153  Harini K.R\nunder guidance of Dr. Shilpa Chaudhari, Associate Professor at department of CSE, MSRIT","ada90697":"**AGRICULTURAL DROUGHT PREDICTION with 98.925**","d4941c63":"** Using the dataset from https:\/\/www.kaggle.com\/crawford\/deepsat-sat4**\n\nThe input data was encoded into CSV files. The X_test_sat4.csv flattened the images that were 28 x 28 x 4 that were taken from space. The first three channels are the standard red, green, and blue channels in normal images. The 4th is a near-infrared band. We are using the smaller test set because the training set is too big. After extracting the data from the csv files, we can reshape it into the original images. Then, we can see the images before we train on them. The second file we are loading are the labels for each image. They can be one of 4: barren land, trees, grassland and other. Each row in the file looks like this [1,0,0,0], where only one of the 4 value is 1. If it is one, then it is that class respective to the order I showed above. If it was the above values, the image is a picture of barren land. If it was [0,1,0,0], then it would be forest land. If it was [0,0,1,0], then it would be grassland and so on.","8a5048f4":"**Four type of classification is possible i.e**\n* if y_train[x] == [1,0,0,0] Barren land(Drought)\n* if y_train[x] == [0,1,0,0] Forest land\n* if y_train[x] == [0,0,1,0] Grassland\n* if y_train[x] == [0,0,0,1] Others","cd49a4f3":"Using **Convulutional Neural Network**"}}