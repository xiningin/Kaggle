{"cell_type":{"4534c97f":"code","9e942139":"code","eadc0aa6":"code","774b4e84":"code","6deff0a2":"code","611b8d0c":"code","400f8af1":"code","cfaaf751":"code","7615d6d8":"code","1648d1ab":"code","5bbbd651":"code","51344181":"code","f3ed3e07":"code","3a746d9e":"code","54d0a578":"code","613c2d5c":"code","79866aba":"code","994b690e":"code","02f1f1ef":"code","b4027846":"code","130cd65d":"code","90fea69d":"code","353a2082":"code","8626d9a3":"code","6cd2ddd3":"code","e826b8e0":"code","addc5e9b":"code","50f1ded7":"code","0900f62b":"code","8682a78a":"code","c37227d9":"code","7af9c013":"code","aa78af5b":"code","af6ec372":"code","71e6471e":"code","d1030e96":"markdown","b08db963":"markdown","7d39da2f":"markdown","15d7cc83":"markdown","c1c0b72b":"markdown","65dcc6ff":"markdown","338cd2b1":"markdown","fa8bb4c5":"markdown","d6940107":"markdown","e838070c":"markdown","fd365e2f":"markdown","ebc7f145":"markdown","96b179d7":"markdown","d17cdeb1":"markdown"},"source":{"4534c97f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","9e942139":"from __future__ import division, print_function\n\nimport h5py\n\n# \u0418\u043c\u043f\u043e\u0440\u0442\u0438\u0440\u0443\u0435\u043c TensorFlow \u0438 tf.keras\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#%matplotlib inline\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.simplefilter('ignore')\nsns.set(rc={'figure.figsize' : (12, 6)})\nsns.set_style(\"darkgrid\", {'axes.grid' : True})\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_auc_score\n\n# Display all columns of dataframe\npd.set_option('display.max_columns', None)","eadc0aa6":"data1 = pd.read_csv(\"..\/input\/letters.csv\")\ndata2 = pd.read_csv(\"..\/input\/letters2.csv\")\ndata3 = pd.read_csv(\"..\/input\/letters3.csv\")\nprint(\"First dataset shape: {0}, \\nSecond dataset shape: {1}, \\nThird dataset shape: {2}\".format(data1.shape, data2.shape, data3.shape))","774b4e84":"data1.head()","6deff0a2":"# Read the h5 file\nf = h5py.File('..\/input\/LetterColorImages_123.h5', 'r')\n# List all groups\nkeys = list(f.keys())\nkeys ","611b8d0c":"# Create tensors and targets of images\nimg_backgrounds = np.array(f[keys[0]])\nimg_tensors = np.array(f[keys[1]])\ntargets = np.array(f[keys[2]])\nprint ('Tensor shape:', img_tensors.shape)\nprint ('Target shape', targets.shape)\nprint ('Background shape:', img_backgrounds.shape)","400f8af1":"# Concatenate series\nletters = pd.concat((data1[\"letter\"], data2[\"letter\"]), axis=0, ignore_index=True)\nletters = pd.concat((letters, data3[\"letter\"]), axis=0, ignore_index=True)\nlen(letters)","cfaaf751":"# Normalize the tensors\nimg_tensors = img_tensors\/255\nimg_tensors[0][0][0][0]","7615d6d8":"sns.countplot(x=\"label\", data=data1)","1648d1ab":"sns.countplot(x=\"background\", data=data1)","5bbbd651":"# Read and display a tensor using Matplotlib\nsns.set_style(\"darkgrid\", {'axes.grid' : False})\nprint('Label: ', letters[100])\nplt.figure(figsize=(3,3))\nplt.imshow(img_tensors[100]);","51344181":"type(img_tensors[0])","f3ed3e07":"img_tensors[0].shape","3a746d9e":"# Display the first image of each label.\ndef display_images_and_labels(images, labels):\n    unique_labels = set(labels)\n    plt.figure(figsize=(15, 15))\n    i = 1\n    labels = labels.tolist()\n    for label in unique_labels:\n        # Pick the first image for each label.\n        image = images[labels.index(label)]\n        plt.subplot(8, 8, i)  # A grid of 8 rows x 8 columns\n        plt.axis('off')\n        plt.title(\"Label {0} ({1})\".format(label, labels.count(label)))\n        i += 1\n        _ = plt.imshow(image)\n    plt.show()\ndisplay_images_and_labels(img_tensors, targets)","54d0a578":"# Display images of a specific label.\ndef display_label_images(images, labels, label):\n    limit = 24  # show a max of 24 images\n    plt.figure(figsize=(15, 5))\n    i = 1\n    labels = labels.tolist()\n    start = labels.index(label)\n    end = start + labels.count(label)\n    for image in images[start:end][:limit]:\n        plt.subplot(3, 8, i)  # 3 rows, 8 per row\n        plt.axis('off')\n        i += 1\n        plt.imshow(image)\n    plt.show()\n\ndisplay_label_images(img_tensors, targets, 21)","613c2d5c":"# Display images of a specific label.\ndef display_images_grayscale(images, labels, label):\n    limit = 24  # show a max of 24 images\n    plt.figure(figsize=(15, 5))\n    i = 1\n    labels = labels.tolist()\n    start = labels.index(label)\n    end = start + labels.count(label)\n    for image in images[start:end][:limit]:\n        plt.subplot(3, 8, i)  # 3 rows, 8 per row\n        plt.axis('off')\n        i += 1\n        plt.imshow(image)\n    plt.show()","79866aba":"# Make dictionary to decode index to letters\ndictionary = {'num': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33], \\\n              'letter': ['\u0430','\u0431','\u0432','\u0433','\u0434','\u0435','\u0451','\u0436','\u0437','\u0438','\u0439','\u043a','\u043b','\u043c','\u043d','\u043e','\u043f','\u0440','\u0441', \\\n                         '\u0442','\u0443','\u0444','\u0445','\u0446','\u0447','\u0448','\u0449','\u044a','\u044b','\u044c','\u044d','\u044e','\u044f']}\nletter_dict = pd.DataFrame.from_dict(dictionary)\nletter_dict = letter_dict.set_index(\"num\")\nletter_dict.head()","994b690e":"# One-hot encoding the targets, started from the zero label\nfrom keras.utils import to_categorical\ncoded_targets = to_categorical(np.array(targets-1), 33)\ncoded_targets.shape","02f1f1ef":"from tensorflow import image\nfrom tensorflow.image import rgb_to_grayscale\nimg_tensors_gs_tf = rgb_to_grayscale(img_tensors)\n\nsess = tf.Session()\nwith sess.as_default():\n    print(img_tensors_gs_tf.eval().shape)\n    arr_img_tensors_gs_tf = img_tensors_gs_tf.eval()","b4027846":"img_tensors_gs = arr_img_tensors_gs_tf\nfor image in img_tensors_gs[:5]:\n    print(\"shape: {0}, min: {1}, max: {2}\".format(image.shape, image.min(), image.max()))","130cd65d":"# from skimage.color import rgb2grey\n# # img_tensors_gs = np.asarray(images32)\n# img_tensors_gs = rgb2grey(img_tensors)\n# for image in img_tensors_gs[:5]:\n#     print(\"shape: {0}, min: {1}, max: {2}\".format(image.shape, image.min(), image.max()))","90fea69d":"img_tensors_gs.shape","353a2082":"# Split the data to test and train\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(img_tensors_gs, coded_targets, test_size = 0.2, random_state = 1)\nprint(\"Train dataset shape: {0}, \\nTest dataset shape: {1}\".format(X_train.shape, X_test.shape))","8626d9a3":"# Split the test data to validation and test sets\nX_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state = 1)\nprint(\"Validation dataset shape: {0}, \\nTest dataset shape: {1}\".format(X_valid.shape, X_test.shape))","6cd2ddd3":"from keras.preprocessing import image as keras_image\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras.metrics import top_k_categorical_accuracy, categorical_accuracy\n\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, LSTM, GlobalAveragePooling1D, GlobalAveragePooling2D\nfrom keras.layers.advanced_activations import PReLU, LeakyReLU, Softmax\nfrom keras.layers import Activation, Flatten, Dropout, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n\ndef top_3_categorical_accuracy(y_true, y_pred):\n    return top_k_categorical_accuracy(y_true, y_pred, k=3)","e826b8e0":"def model():\n    model = Sequential()\n    \n    # Define a model architecture    \n    model.add(Conv2D(32, (5, 5), padding='same', input_shape=X_train.shape[1:]))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n    \n    model.add(Conv2D(64, (3, 3), padding='same'))\n    model.add(LeakyReLU(alpha=0.02))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(128, (3, 3), padding='same'))\n    model.add(LeakyReLU(alpha=0.02))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n    \n    # Global max pooling is ordinary max pooling layer with pool size equals to the size of the input (minus filter size + 1, to be precise). \n    model.add(GlobalMaxPooling2D())\n    \n    model.add(Dense(1024))\n    model.add(LeakyReLU(alpha=0.02))\n    model.add(Dropout(0.2)) \n    \n    model.add(Dense(33))\n    model.add(Activation('softmax'))\n\n    # Compile the model\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[categorical_accuracy, top_3_categorical_accuracy])\n    return model\n\nmodel = model()\nmodel.summary()","addc5e9b":"# Create callbacks\ncheckpointer = ModelCheckpoint(filepath='weights.best.model.hdf5', verbose=1, save_best_only=True)\nlr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=5, verbose=1, factor=0.75)\n# early_stoping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\ncallbacks = [checkpointer, lr_reduction]                            ","50f1ded7":"# Train the model\n# batch size = 473 as it divides X_train size, X_test and X_valid sizes evenly\nhistory = model.fit(X_train, y_train, epochs=200, batch_size=473, verbose=1, validation_data=(X_valid, y_valid), callbacks=callbacks)                    ","0900f62b":"# Plot the Neural network fitting history\ndef history_plot(fit_history, n):\n    plt.figure(figsize=(18, 12))\n    \n    plt.subplot(211)\n    plt.plot(fit_history.history['loss'][n:], color='slategray', label = 'train')\n    plt.plot(fit_history.history['val_loss'][n:], color='#4876ff', label = 'valid')\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.title('Loss Function');  \n    \n    plt.subplot(212)\n    plt.plot(fit_history.history['categorical_accuracy'][n:], color='slategray', label = 'train')\n    plt.plot(fit_history.history['val_categorical_accuracy'][n:], color='#4876ff', label = 'valid')\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy\")    \n    plt.legend()\n    plt.title('Accuracy');","8682a78a":"# Plot the training history\nhistory_plot(history, 0)","c37227d9":"# Load the model with the best validation accuracy\nmodel.load_weights('weights.best.model.hdf5')\n# Calculate classification accuracy on the testing set\nscore = model.evaluate(X_test, y_test)\nscore","7af9c013":"# Model predictions for the testing dataset\ny_test_predict = model.predict_classes(X_test)","aa78af5b":"# Create a list of symbols\nsymbols = ['\u0430','\u0431','\u0432','\u0433','\u0434','\u0435','\u0451','\u0436','\u0437','\u0438','\u0439',\n           '\u043a','\u043b','\u043c','\u043d','\u043e','\u043f','\u0440','\u0441','\u0442','\u0443','\u0444',\n           '\u0445','\u0446','\u0447','\u0448','\u0449','\u044a','\u044b','\u044c','\u044d','\u044e','\u044f']","af6ec372":"# Display true labels and predictions\nfig = plt.figure(figsize=(14, 14))\nfor i, idx in enumerate(np.random.choice(X_test.shape[0], size=16, replace=False)):\n    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(X_test[idx]), cmap=\"gray\")\n    pred_idx = y_test_predict[idx]\n    true_idx = np.argmax(y_test[idx])\n    ax.set_title(\"{} ({})\".format(symbols[pred_idx], symbols[true_idx]),\n                 color=(\"#4876ff\" if pred_idx == true_idx else \"darkred\"))","71e6471e":"# Save model\nmodel.save('HW_best_model.h5')","d1030e96":"## Make & Display Predictions","b08db963":"## Pre-Proccessing data","7d39da2f":"## Visualization\nLets see the distributions of data in dataset to find out if there are any unbalanced classes:","15d7cc83":"### Simple Convolutional Neural Network","c1c0b72b":"## Load Data","65dcc6ff":"## Save the final model\nThen we can use model.save(filepath) to save a Keras model into a single HDF5 file which will contain:\n\n* the architecture of the model, allowing to re-create the model\n* the weights of the model\n* the training configuration (loss, optimizer)\n* the state of the optimizer, allowing to resume training exactly where you left off.","338cd2b1":"## Explore the data\n### About Dataset\n**The main dataset (letters.zip)**\n* 1650 (50x33) color images (32x32x3) with 33 letters and the file with labels letters.txt.\n* Photo files are in the .png format and the labels are integers and values.\n* Additional letters.csv file.\n* The file LetterColorImages.h5 consists of preprocessing images of this set: image tensors and targets (labels).\n\n**The additional dataset (letters2.zip)**\n* 5940 (180x33) color images (32x32x3) with 33 letters and the file with labels letters2.txt.\n* Photo files are in the .png format and the labels are integers and values.\n* Additional letters2.csv file.\n* The file LetterColorImages2.h5 consists of preprocessing images of this set: image tensors and targets (labels).\n\n**The additional dataset (letters3.zip)**\n* 6600 (200x33) color images (32x32x3) with 33 letters and the file with labels letters2.txt.\n* Photo files are in the .png format and the labels are integers and values.\n* Additional letters3.csv file.\n* The file LetterColorImages3.h5 consists of preprocessing images of this set: image tensors and targets (labels).\n\nLetter Symbols => Letter Labels:   \n\u0430=>1, \u0431=>2, \u0432=>3, \u0433=>4, \u0434=>5, \u0435=>6, \u0451=>7, \u0436=>8, \u0437=>9, \u0438=>10, \u0439=>11, \u043a=>12, \u043b=>13, \u043c=>14, \u043d=>15, \u043e=>16, \u043f=>17, \u0440=>18, \u0441=>19, \u0442=>20, \u0443=>21, \u0444=>22, \u0445=>23, \u0446=>24, \u0447=>25, \u0448=>26, \u0449=>27, \u044a=>28, \u044b=>29, \u044c=>30, \u044d=>31, \u044e=>32, \u044f=>33\n\nImage Backgrounds => Background Labels:   \nstriped=>0, gridded=>1, no background=>2, graph paper=>3","fa8bb4c5":"Lets convert RGB image to Grayscale to simplify structure of model of neuron network.","d6940107":"## Imports","e838070c":"### Create callbacks\nA callback is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training.\n* **ModelCheckpoint** - Save the model after every epoch.\n* **ReduceLROnPlateau** - Reduce learning rate when a metric has stopped improving.Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced.\n* **EarlyStopping** - Stop training when a monitored quantity has stopped improving.","fd365e2f":"## Build the model\nThe neural network is created by stacking layers\u2014this requires two main architectural decisions:\n\n1. How many layers to use in the model?\n2. How many hidden units to use for each layer?\n\nIn this example, the input data consists of tensors with images of each letter. The labels to predict are numbers from 1 to 33.   \nLet's build a model for this problem with few different architectures:\n\n*  Simple Convolutional Neural Network\n*  A Convolutional Neural Network using Estimators API","ebc7f145":"As we can see, 21th letter is hardly seen on the first picture of dataset.\nSo lets try to look on others variants of spelling letter 21:","96b179d7":"The tf.layers module contains methods to create each of the three layer types above:\n* **conv2d()**. Constructs a two-dimensional convolutional layer. Takes **number of filters, filter kernel size, padding, activation function, kernel, bias regularizers and input shape** as arguments.   \n*'Same' padding* means the size of output feature-maps are the same as the input feature-maps (under the assumption of stride=1). For instance, if input is nin channels with feature-maps of size 28\u00d728, then in the output you expect to get nout feature maps each of size 28\u00d728 as well.\n* **max_pooling2d()**. Constructs a two-dimensional pooling layer using the max-pooling algorithm. Takes **pooling filter size and stride** as arguments.\n* **dense().** Constructs a dense layer. Takes **number of neurons and activation function** as arguments.   \n\nEach of these methods accepts a tensor as input and returns a transformed tensor as output. This makes it easy to connect one layer to another: just take the output from one layer-creation method and supply it as input to another.\n\n### Compile the model\nBefore the model is ready for training, it needs a few more settings. These are added during the model's compile step:\n\n* **Loss function** \u2014This measures how accurate the model is during training. We want to minimize this function to \"steer\" the model in the right direction.\n* **Optimizer** \u2014This is how the model is updated based on the data it sees and its loss function.\n* **Metrics** \u2014Used to monitor the training and testing steps. The following example uses accuracy, the fraction of the images that are correctly classified.","d17cdeb1":"## Train the model"}}