{"cell_type":{"967446b2":"code","58a2a2dc":"code","72722ff5":"code","a272f5d4":"code","520470c8":"code","0be9d5e7":"code","ddd4af28":"code","62df5bfe":"code","3d1d0386":"code","ba35c2c7":"code","45bc67cc":"code","7f1abf26":"code","73a1891a":"markdown","a941294a":"markdown","8c650a65":"markdown","49bc0670":"markdown","c4e55f00":"markdown","9ee7851d":"markdown","38de21a5":"markdown","c9a8bfa7":"markdown","af9969ef":"markdown","c7200dfc":"markdown","594a1ee3":"markdown","f44cc898":"markdown"},"source":{"967446b2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport os\nimport numpy as np\nimport pandas as pd\nimport pyarrow.parquet as pq\nimport matplotlib.pyplot as plt\nfrom scipy import signal as sps\nfrom sklearn.model_selection import train_test_split\nfrom statistics import mode\n\nplt.style.use('ggplot')\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","58a2a2dc":"# PARAMETERS\nBATCH_SIZE = 8\nEPOCHS = 10","72722ff5":"PARENT_DATA_DIR_PATH = '..\/input'\nMETADATA_TRAIN_FILE_PATH = os.path.join(PARENT_DATA_DIR_PATH, \"metadata_train.csv\")\nTRAIN_DATA_FILE_PATH = os.path.join(PARENT_DATA_DIR_PATH, \"train.parquet\")","a272f5d4":"metadata_train = pd.read_csv(METADATA_TRAIN_FILE_PATH)\nprint(\"#samples:\", len(metadata_train))\nmetadata_train.head()","520470c8":"# For equal number of samples for each class\ntarget0DF = metadata_train[metadata_train.target == 0]\ntarget1DF = metadata_train[metadata_train.target == 1]\nmetadata_train = pd.concat([target0DF.iloc[:len(target1DF), :], target1DF])\nmetadata_train.target.value_counts()","0be9d5e7":"gridDF = metadata_train.groupby('id_measurement')\nmetadataList = []\nfor name, group in gridDF:\n    if len(group.signal_id) == 3:\n    #     print(name, group)\n        ids = list(map(lambda x: str(x), group.signal_id))\n        target = mode(group.target)\n    #     print(\"IDs:\", ids)\n    #     print(\"Target:\", target)\n        metadataList.append({'IDs':ids, 'target': target})\nmetadataList[:5]","ddd4af28":"trainMeta, valMeta = train_test_split(metadataList, test_size=.10)\nprint(\"trainMDDF shape:\", len(trainMeta))\nprint(\"valMDDF shapeL\", len(valMeta))","62df5bfe":"# VERIFY THAT TRAIN AND VALIDATION SET HAVE BOTH CLASSES DATA.\nt0 = 0\nt1 = 0\nfor pair in trainMeta:\n    if pair['target'] == 0:\n        t0 += 1\n    else:\n        t1 += 1\nprint(\"train set: #t0={}, #t1={}\".format(t0, t1))\nt0 = 0\nt1 = 0\nfor pair in valMeta:\n    if pair['target'] == 0:\n        t0 += 1\n    else:\n        t1 += 1\nprint(\"val set: #t0={}, #t1={}\".format(t0, t1))","3d1d0386":"data = pq.read_pandas(TRAIN_DATA_FILE_PATH).to_pandas()\ndata.head()","ba35c2c7":"def get_data_batch(dataDF, metaList, batchsize=2, loop=False, denoise=True, combine_phases=True):\n    \"\"\"\n    Args:\n    dataDF (pandas.DataFrame): The train.parquet file dataframe\n    metaList(pandas.DataFrame): The training metadata file\n    batchsize(int): Number of samples in a batch\n    loop(boolean): True, For training with keras fit_generator; False, for validation.\n    denoise(boolean): True, reduce signal noise\n    combine_phase(boolean): True, return shape:(batchsize, 800000, 1); False, return shape:(batchsize, 800000, 3)\n    \"\"\"\n    # set filter\n    b, a = sps.butter(3, 0.5, btype='highpass', analog=False)\n    while True:\n        counter = 0\n        signals_list = []\n        target_list = []\n        try:\n            for index in range(len(metaList)):\n                counter += 1\n                sample_ids = metaList[index]['IDs']\n                sample_target = metaList[index]['target']\n                # OneHot encoding\n                sample_targetOH = np.zeros(2)\n                sample_targetOH[sample_target] = 1\n                sample_signal = dataDF[sample_ids]\n                if denoise:\n                    # DeNoise\n                    for colname in sample_signal:\n                        noisy_signal = sample_signal[colname]\n                        sample_signal[colname] = sps.filtfilt(b, a, noisy_signal)\n                if combine_phases:\n                    # combine phases to one signal\n                    sample_signal = sample_signal.mean(1)\n                    signals_list.append(np.expand_dims(sample_signal.values.reshape(-1, 1), 0))\n                    target_list.append(np.expand_dims(sample_targetOH, 0))\n                    if counter == batchsize:\n                        yield np.concatenate(signals_list), np.concatenate(target_list)\n                        counter = 0\n                        signals_list.clear()\n                        target_list.clear()\n                else:\n                    signals_list.append(np.expand_dims(sample_signal.values, 0))\n                    target_list.append(np.expand_dims(sample_targetOH, 0))\n                    if counter == batchsize:\n                        yield np.concatenate(signals_list), np.concatenate(target_list)\n                        counter = 0\n                        signals_list.clear()\n                        target_list.clear()\n        except:\n            pass\n        if not loop:\n            break","45bc67cc":"sb, tb = next(get_data_batch(data, trainMeta, batchsize=BATCH_SIZE, loop=False))\nfor sample_signal, sample_target in zip(sb, tb):\n    plt.figure(figsize=(15,5))\n    plt.plot(sample_signal);\n    plt.title(\"Label: \"+str(np.argmax(sample_target)))\n    plt.show()","7f1abf26":"sb, tb = next(get_data_batch(data, trainMeta, batchsize=BATCH_SIZE, loop=False))\nprint(\"Sample signal batch:\", sb.shape)\nprint(\"Sample target batch:\", tb.shape) # Target are OneHot encodeed","73a1891a":"    Target:\n        0 : undamaged\n        1 : fault","a941294a":"### Combine 3 phases to one signal","8c650a65":"### Get data in batches","49bc0670":"Title:  Power line fault detection pre processing  \nData source: https:\/\/www.kaggle.com\/c\/vsb-power-line-fault-detection  \nAuthor: [Virksaab](https:\/\/www.kaggle.com\/virksaab)   \nDate:   30 December, 2018","c4e55f00":"### Train metadata","9ee7851d":"### Paths to data and metadata","38de21a5":"## Thanks for reading.","c9a8bfa7":"### Load data","af9969ef":"### Train-val split","c7200dfc":"### Your algorithm....","594a1ee3":"### Sample data fetching from batch","f44cc898":"### Visualize"}}