{"cell_type":{"64fc61f8":"code","8113b8be":"code","3875f736":"code","d4bdd873":"code","b47f1e2d":"code","85a0a73b":"code","3824c721":"code","1e0f0a5d":"code","89b9c5c0":"code","c1c51004":"code","70cef046":"code","cfd9e586":"code","17a6036b":"code","de88050c":"code","33498a93":"code","4714cf05":"code","6b7c2fb7":"code","48fd3694":"code","c7d56609":"code","772c8e86":"code","da8592bb":"code","e1fbc6d5":"code","72c0da11":"code","a5742dd7":"code","678538d9":"code","1c0599e9":"code","9e11872e":"code","065a2f01":"code","c9dbc75a":"code","87cc6288":"code","a7ae97f1":"code","4c1a0aff":"markdown","5d07642e":"markdown","f877d7c0":"markdown","cfe805de":"markdown","11fb825c":"markdown","0c5392dd":"markdown","8dc6d523":"markdown","20558f85":"markdown","2427fdcc":"markdown","cfe6e74b":"markdown","d3de26be":"markdown","d0ac8878":"markdown"},"source":{"64fc61f8":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport seaborn as sns\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.feature_selection import SelectKBest, f_regression\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.svm import SVR\n\nimport statsmodels.api as sm\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max.columns', None)","8113b8be":"df = pd.read_csv('..\/input\/regression\/Advertising.csv')\ndf.head()","3875f736":"df.info()","d4bdd873":"df.describe().T","b47f1e2d":"df.isnull().sum()","85a0a73b":"sns.distplot(df['TV'])","3824c721":"sns.distplot(df['Radio'])","1e0f0a5d":"sns.distplot(df['Newspaper'])","89b9c5c0":"sns.distplot(df['Sales'])","c1c51004":"sns.boxplot(data = df)","70cef046":"sns.boxplot(x = 'TV', data = df)","cfd9e586":"sns.boxplot(x = 'Radio', data = df)","17a6036b":"sns.boxplot(x = 'Newspaper', data = df)","de88050c":"sns.boxplot(x = 'Sales', data = df)","33498a93":"df = df.drop('Unnamed: 0', axis = 1)\ndf.head()","4714cf05":"f, ax = plt.subplots(figsize=(10,8))\ncorr = df.corr()\nsns.heatmap(corr, annot=True, mask=np.zeros_like(corr, dtype=np.bool),\n           cmap = sns.diverging_palette(240, 10, as_cmap = True), \n           square = True, ax = ax)","6b7c2fb7":"df.corr()['Sales'].sort_values()","48fd3694":"std = StandardScaler()\ndf_std = std.fit_transform(df)\ndf_std = pd.DataFrame(df_std, columns = df.columns)","c7d56609":"df_std.head()","772c8e86":"X_train, X_test, y_train, y_test = train_test_split(df_std.drop(columns = ['Sales']), df_std[['Sales']], test_size = 0.3, random_state = 42)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","da8592bb":"regressor = sm.OLS(y_train, X_train).fit()\nprint(regressor.summary())\n\nX_train_dropped = X_train.copy()","e1fbc6d5":"while True:\n    if max(regressor.pvalues) > 0.05:\n        drop_variable = regressor.pvalues[regressor.pvalues == max(regressor.pvalues)]\n        print(\"Dropping \" + drop_variable.index[0] + \" and running regression again because pvalue is: \" + str(drop_variable[0]))\n        X_train_dropped = X_train_dropped.drop(columns = [drop_variable.index[0]])\n        regressor = sm.OLS(y_train, X_train_dropped).fit()\n    else:\n        print(\"All p values less than 0.05\")\n        break\n","72c0da11":"print(regressor.summary())\n","a5742dd7":"X_train_dropped.shape","678538d9":"column_names = df.drop(columns = ['Sales']).columns\n\nno_of_features = []\nr_squared_train = []\nr_squared_test = []\n\n#look at X_train_dropped shape\nfor k in range(1, 4):\n    selector = SelectKBest(f_regression, k = k)\n    X_train_transformed = selector.fit_transform(X_train, y_train)\n    X_test_transformed = selector.transform(X_test)\n    regressor = LinearRegression()\n    regressor.fit(X_train_transformed, y_train)\n    no_of_features.append(k)\n    r_squared_train.append(regressor.score(X_train_transformed, y_train))\n    r_squared_test.append(regressor.score(X_test_transformed, y_test))\n    \nsns.lineplot(x = no_of_features, y = r_squared_train, legend = 'full')\nsns.lineplot(x = no_of_features, y = r_squared_test, legend = 'full')","1c0599e9":"# k = 2 because we have only 2 features\nselector = SelectKBest(f_regression, k = 2)\nX_train_transformed = selector.fit_transform(X_train, y_train)\nX_test_transformed = selector.transform(X_test)\ncolumn_names[selector.get_support()]\n","9e11872e":"def regression_model(model):\n    \"\"\"\n    Will fit the regression model passed and will return the regressor object and the score\n    \"\"\"\n    regressor = model\n    regressor.fit(X_train_transformed, y_train)\n    score = regressor.score(X_test_transformed, y_test)\n    return regressor, score","065a2f01":"model_performance = pd.DataFrame(columns = [\"Features\", \"Model\", \"Score\"])\n\nmodels_to_evaluate = [LinearRegression(), Ridge(), Lasso(), SVR(), RandomForestRegressor(), MLPRegressor()]\n\nfor model in models_to_evaluate:\n    regressor, score = regression_model(model)\n    model_performance = model_performance.append({\"Features\": \"Linear\",\"Model\": model, \"Score\": round(score, 2)}, ignore_index=True)\n\nmodel_performance","c9dbc75a":"poly = PolynomialFeatures()\nX_train_transformed_poly = poly.fit_transform(X_train)\nX_test_transformed_poly = poly.transform(X_test)\n\nprint(X_train_transformed_poly.shape)\n\nno_of_features = []\nr_squared = []\n\n#look at shape\nfor k in range(1, 10):\n    selector = SelectKBest(f_regression, k = k)\n    X_train_transformed = selector.fit_transform(X_train_transformed_poly, y_train)\n    regressor = LinearRegression()\n    regressor.fit(X_train_transformed, y_train)\n    no_of_features.append(k)\n    r_squared.append(regressor.score(X_train_transformed, y_train))\n    \nsns.lineplot(x = no_of_features, y = r_squared)","87cc6288":"selector = SelectKBest(f_regression, k = 6)\nX_train_transformed = selector.fit_transform(X_train_transformed_poly, y_train)\nX_test_transformed = selector.transform(X_test_transformed_poly)","a7ae97f1":"models_to_evaluate = [LinearRegression(), Ridge(), Lasso(), SVR(), RandomForestRegressor(), MLPRegressor()]\n\nfor model in models_to_evaluate:\n    regressor, score = regression_model(model)\n    model_performance = model_performance.append({\"Features\": \"Polynomial\",\"Model\": model, \"Score\": round(score,2)}, ignore_index=True)\n\nmodel_performance\n","4c1a0aff":"# Data loading and overview","5d07642e":"# Thanks for watching!\n## If you liked notebook then upvoted it or write your opinion","f877d7c0":"We uses scalling","cfe805de":"# Import libs","11fb825c":"### Boxplot","0c5392dd":"### The function removes features with high p-value","8dc6d523":"### Train split test","20558f85":"Feature distribution is not normal","2427fdcc":"# Modeling ","cfe6e74b":"### Uses SelectKBest","d3de26be":"# Preprocessing","d0ac8878":"# EDA\n## Distplot\nWe look at the destribution"}}