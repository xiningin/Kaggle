{"cell_type":{"228af31b":"code","d8b2c1ec":"code","441d50a0":"code","590e8925":"code","68491498":"code","bb218281":"code","01a53744":"code","b03e9af1":"code","409b52d4":"code","0b56bd3c":"code","78b115d7":"code","a89005d2":"code","47a23261":"code","9225a222":"code","529729e9":"code","403e4186":"code","24ff4189":"code","691e1ed2":"code","37bf7fb9":"code","b69fbc02":"code","3a7499c7":"code","2bf9b9eb":"code","74bef81c":"code","196ff101":"code","db269ac2":"code","80d48174":"code","aae6d6c4":"code","34126358":"code","34cf8d9e":"code","e9554e98":"markdown","003872b1":"markdown","61b54912":"markdown","244e32a1":"markdown","4f752d18":"markdown","9653a73a":"markdown"},"source":{"228af31b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\n\nfrom tensorflow_addons.metrics import RSquare","d8b2c1ec":"data = pd.read_csv('..\/input\/videogamesales\/vgsales.csv', index_col='Rank')","441d50a0":"data","590e8925":"columns_to_drop = ['Name', 'NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales']\n\ndata.drop(columns_to_drop, axis=1, inplace=True)","68491498":"data","bb218281":"data.isnull().sum()","01a53744":"data['Year'] = data['Year'].fillna(data['Year'].mean())","b03e9af1":"data = data.dropna(axis=0)","409b52d4":"data.isnull().sum()","0b56bd3c":"data","78b115d7":"data['Platform'].unique()","a89005d2":"data['Genre'].unique()","47a23261":"counts = data['Publisher'].value_counts()\n\ndata['Publisher'] = data['Publisher'].apply(lambda x: 'Small Publisher' if counts[x] < 50 else x)","9225a222":"data","529729e9":"onehot_columns = ['Platform', 'Genre', 'Publisher']","403e4186":"def onehot_encode(data, columns):\n    for column in columns:\n        dummies = pd.get_dummies(data[column])\n        data = pd.concat([data, dummies], axis=1)\n        data.drop(column, axis=1, inplace=True)\n    return data","24ff4189":"data = onehot_encode(data, onehot_columns)","691e1ed2":"data","37bf7fb9":"y = data['Global_Sales']\nX = data.drop('Global_Sales', axis=1)","b69fbc02":"X","3a7499c7":"scaler = StandardScaler()\n\nX = scaler.fit_transform(X)","2bf9b9eb":"X.shape","74bef81c":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)","196ff101":"inputs = tf.keras.Input(shape=(91,))\nx = tf.keras.layers.Dense(128, activation='relu')(inputs)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\noutputs = tf.keras.layers.Dense(1)(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\n\noptimizer = tf.keras.optimizers.RMSprop(0.001)\n\nmodel.compile(\n    optimizer=optimizer,\n    loss='mse'\n)\n\n\nbatch_size = 64\nepochs = 18\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    validation_split=0.2,\n    batch_size=batch_size,\n    epochs=epochs,\n    verbose=0\n)","db269ac2":"plt.figure(figsize=(14, 10))\n\nepochs_range = range(1, epochs + 1)\ntrain_loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.plot(epochs_range, train_loss, label=\"Training Loss\")\nplt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\nplt.show()","80d48174":"np.argmin(val_loss)","aae6d6c4":"y_pred = np.squeeze(model.predict(X_test))\n\nresult = RSquare()\nresult.update_state(y_test, y_pred)\n\nprint(\"R^2 Score:\", result.result())","34126358":"model.evaluate(X_test, y_test)","34cf8d9e":"history.history['val_loss']","e9554e98":"## Scaling","003872b1":"# Preprocessing","61b54912":"## Encoding","244e32a1":"# Results","4f752d18":"# Training","9653a73a":"# Getting Started"}}