{"cell_type":{"5f53ae00":"code","9889c883":"code","65b35146":"code","d6681e62":"code","12867313":"code","d759e7be":"code","4578f03a":"code","078b2afb":"code","55ef7449":"code","e03d365d":"code","8b79752c":"code","3fb12421":"code","747dfb1b":"code","a793b94d":"code","6d2f306a":"code","152a51c8":"code","f1ef25cd":"code","ca1a2f50":"code","ba7adfff":"code","1f5979ce":"code","79951f7d":"code","90430214":"code","bc805b30":"code","802e76ca":"code","5b41303d":"code","cd639a5e":"code","ed0e5665":"code","1ea29a32":"code","b48e4af6":"code","21f7ee4d":"code","cd0a00e1":"code","c1b45cad":"code","c9256d32":"code","c8a37401":"code","feb1b4e2":"code","24861cb2":"code","e0161ddb":"code","62c2c443":"code","51d6aeb5":"code","66bafc04":"code","4e93a175":"code","e3204ebb":"code","10bc27b8":"code","ec3597a0":"code","5263a298":"code","c2a67afe":"code","c0053608":"code","f520859c":"code","2d2487ab":"code","682638cd":"code","f8d594ee":"code","27b863fb":"code","badf4171":"code","a658bcb2":"code","e1483484":"code","0d1df9fe":"code","bf1d8b34":"code","e10ef106":"code","4d99b5ad":"code","599e8a39":"code","b2e9f338":"code","825bfd5d":"code","d372ad85":"code","e49443f6":"code","32e1f93a":"code","0aef44f3":"code","f60743ec":"code","a862e737":"code","f658e41f":"code","42ea11e0":"code","171838ea":"code","b2cd9b7a":"code","999444f9":"code","c9e814a9":"code","c3142072":"code","f8fc6d41":"code","b5881bd6":"code","1cc9cdbe":"code","13a19af0":"code","f2604acb":"code","674586f5":"code","859ea951":"code","a57d606d":"code","59d23299":"code","b0f36cda":"code","fb6e5514":"code","79abc4db":"code","4e24c2f7":"code","b5852776":"code","3595794a":"code","35fdabd7":"code","516aa3e3":"code","ed3c21d6":"code","165e6b16":"code","6309a303":"code","7d39f3fb":"code","57465118":"code","ef40e082":"code","a7063f2f":"code","9ff6b3f1":"code","15d8c3f0":"code","2cf9c8c8":"code","2ee601bf":"code","4d601dad":"code","7ebe20cc":"code","3df364e3":"code","88a3054c":"code","bcbf03b4":"code","1a60a269":"code","c8d999e1":"code","332267f0":"code","4dc87497":"code","2e78367c":"code","aacc2496":"code","cf765f12":"code","ee622812":"code","d3d579c6":"code","0d015039":"code","4499f2ea":"code","098a8732":"code","8ba45856":"code","3a3022cf":"code","2269834d":"code","c7a4a42e":"code","90d251ee":"code","0de79237":"code","d78b112b":"code","db6e0d37":"code","b837c103":"code","ed6d3f04":"code","882a6e79":"code","b1f8352b":"code","98848df1":"code","92815bda":"code","8059dcfb":"code","f9aeaab5":"code","3efbe126":"code","f35856db":"code","3fc893ac":"code","6a67ae8b":"code","363ee6ac":"code","2a1385cb":"code","d9f2f403":"code","e530e3bf":"code","4f9c7cc1":"code","4dc74697":"code","8fe00e6d":"code","8c9ca44b":"code","d8ea6771":"code","fe617bc1":"code","de06ee40":"code","85a895e9":"code","c41530a3":"code","3692b464":"code","8888d953":"code","268d7b66":"code","15cca6aa":"code","21472ac3":"code","731b7273":"code","3271b506":"code","f79b4cf2":"code","008ffec4":"code","62e1a084":"code","280a8935":"code","eff0aee5":"code","8a8734c5":"code","2ef6ad0c":"code","f704ddb2":"code","b772f97d":"code","3073d038":"code","f46943c5":"code","141aeadd":"code","ddea8635":"code","ff011e38":"code","eddd84e3":"code","d7980dbf":"code","e3633577":"code","59d18c9f":"code","fef399c2":"code","afa9fdac":"code","7fb455c3":"code","a4e0cc08":"code","6c6088c1":"code","139ecae5":"code","d34430a3":"markdown","4b0af9d2":"markdown","836e891a":"markdown","92c409ab":"markdown","64c47e6d":"markdown","17948880":"markdown","5bb20250":"markdown","9f0a97a8":"markdown","e174bf0f":"markdown","0437dd22":"markdown","b79a4acd":"markdown","6755e59b":"markdown","2b678dfc":"markdown","a21a78ca":"markdown","ae461204":"markdown","b7ebc101":"markdown","54930395":"markdown","bbfbcdf0":"markdown","96c5aa52":"markdown","fe4b6da3":"markdown","c202240d":"markdown","a8122926":"markdown","b35aca28":"markdown","e7179875":"markdown","a25bbc58":"markdown","4f46c01b":"markdown","6544ae1f":"markdown","f4ddf6de":"markdown","fafe2356":"markdown","aed26130":"markdown"},"source":{"5f53ae00":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","9889c883":"data1=pd.read_csv('\/kaggle\/input\/health-insurance-cross-sell-prediction\/train.csv')","65b35146":"data1.head()","d6681e62":"data1.info()","12867313":"data1.isnull().sum()","d759e7be":"data1.isnull().mean()","4578f03a":"data1.describe()","078b2afb":"data1.describe(include='O')","55ef7449":"data1.shape","e03d365d":"data1['Response'].value_counts()","8b79752c":"sns.countplot('Gender',data=data1,hue='Response')\nplt.plot()","3fb12421":"data1.groupby(['Gender'])['Response'].value_counts(normalize=True)*100","747dfb1b":"sns.distplot(data1['Age'])\nplt.plot()","a793b94d":"data1['Age'].describe()","6d2f306a":"def brac(x):\n    if (x>=20) & (x<31):\n        return '20-30'\n    if(x>=31) & (x<41):\n        return '31-40'\n    if(x>=41) & (x<51):\n        return '41-50'\n    if(x>=51) & (x<61):\n        return '51-60'\n    if(x>=61) & (x<71):\n        return '61-70'\n    if(x>=71) & (x<81):\n        return '71-80'\n    if(x>=81) & (x<91):\n        return '81-90'\n        ","152a51c8":"data1['AgeBracket']=data1['Age'].apply(brac)","f1ef25cd":"data1[['Age','AgeBracket']]","ca1a2f50":"sns.countplot('AgeBracket',data=data1,hue='Response')\nplt.plot()","ba7adfff":"t1=pd.DataFrame(data1.groupby(['AgeBracket'])['Response'].value_counts(normalize=True)*100)","1f5979ce":"t1","79951f7d":"pd.DataFrame(data1.groupby(['Driving_License'])['Response'].value_counts(normalize=True))","90430214":"pd.DataFrame(data1.groupby(['Previously_Insured'])['Response'].value_counts(normalize=True))","bc805b30":"data1['Vehicle_Age'].unique()","802e76ca":"pd.DataFrame(data1.groupby(['Vehicle_Age'])['Response'].value_counts(normalize=True))","5b41303d":"data1['Vehicle_Damage'].unique()","cd639a5e":"pd.DataFrame(data1.groupby(['Vehicle_Damage'])['Response'].value_counts(normalize=True))","ed0e5665":"data1['Annual_Premium'].unique()","1ea29a32":"t3=pd.DataFrame(data1.groupby(['Annual_Premium'])['Response'].value_counts(normalize=True))","b48e4af6":"t3","21f7ee4d":"data1['Annual_Premium'].describe()","cd0a00e1":"data3=data1.copy()","c1b45cad":"sns.distplot(data1['Annual_Premium'])\nsns.relplot('Response','Annual_Premium',data=data1)","c9256d32":"data1['quantile_5']=pd.qcut(data1['Annual_Premium'], q=5)","c8a37401":"pd.DataFrame(data1.groupby(['quantile_5'])['Response'].value_counts(normalize=True)*100)","feb1b4e2":"pp=pd.DataFrame(data1.groupby(['Policy_Sales_Channel'])['Response'].value_counts(normalize=True)*100)","24861cb2":"pp","e0161ddb":"def find_non_rare_labels(df, variable, tolerance):\n    \n    temp = df.groupby([variable])[variable].count() \/ len(df)\n    \n    non_rare = [x for x in temp.loc[temp>tolerance].index.values]\n    \n    return non_rare","62c2c443":"def rare_encoding(new, variable, tolerance):\n    frequent_cat = find_non_rare_labels(data3, variable, tolerance)\n\n    # re-group rare labels\n    data3[variable] = np.where(data3[variable].isin(\n        frequent_cat), data3[variable], 'Rare')\n\n    return data3","51d6aeb5":"for variable in ['Policy_Sales_Channel']:\n    \n     data3= rare_encoding(data3, variable, 0.01)","66bafc04":"for col in ['Policy_Sales_Channel']:\n\n    temp_df = pd.Series(data3[col].value_counts() \/ len(data3) )\n\n    # make plot with the above percentages\n    fig = temp_df.sort_values(ascending=False).plot.bar()\n    fig.set_xlabel(col)\n\n    # add a line at 5 % to flag the threshold for rare categories\n    fig.axhline(y=0.01, color='red')\n    fig.set_ylabel('Percentage of houses')\n    plt.show()","4e93a175":"pd.DataFrame(data3.groupby(['Policy_Sales_Channel'])['Response'].value_counts(normalize=True)*100)","e3204ebb":"data1['Vintage'].plot(kind='hist')","10bc27b8":"data1['Vin_q']=pd.cut(data1['Vintage'], bins=10)","ec3597a0":"pd.DataFrame(data1.groupby(['Vin_q'])['Response'].value_counts(normalize=True)*100)","5263a298":"sns.distplot(data1['Vintage'])\nsns.relplot('Response','Vintage',data=data1)","c2a67afe":"for col in ['Region_Code']:\n\n    temp_df = pd.Series(data3[col].value_counts() \/ len(data3) )\n\n    # make plot with the above percentages\n    fig = temp_df.sort_values(ascending=False).plot.bar()\n    fig.set_xlabel(col)\n\n    # add a line at 5 % to flag the threshold for rare categories\n    fig.axhline(y=0.05, color='red')\n    fig.set_ylabel('Percentage of houses')\n    plt.show()","c0053608":"def find_non_rare_labels(df, variable, tolerance):\n    \n    temp = df.groupby([variable])[variable].count() \/ len(df)\n    \n    non_rare = [x for x in temp.loc[temp>tolerance].index.values]\n    \n    return non_rare","f520859c":"find_non_rare_labels(data3, 'Region_Code', 0.02)","2d2487ab":"def rare_encoding(new, variable, tolerance):\n    frequent_cat = find_non_rare_labels(data3, variable, tolerance)\n\n    # re-group rare labels\n    data3[variable] = np.where(data3[variable].isin(\n        frequent_cat), data3[variable], 'Rare')\n\n    return data3","682638cd":"for variable in ['Region_Code']:\n    \n     data3= rare_encoding(data3, variable, 0.01)","f8d594ee":"for col in ['Region_Code']:\n\n    temp_df = pd.Series(data3[col].value_counts() \/ len(data3) )\n\n    # make plot with the above percentages\n    fig = temp_df.sort_values(ascending=False).plot.bar()\n    fig.set_xlabel(col)\n\n    # add a line at 5 % to flag the threshold for rare categories\n    fig.axhline(y=0.01, color='red')\n    fig.set_ylabel('Percentage of houses')\n    plt.show()","27b863fb":"pd.DataFrame(data3.groupby(['Region_Code'])['Response'].value_counts(normalize=True)*100)","badf4171":"data_contact=data3[(data3['Driving_License']==1) & \n      (data3['Previously_Insured']==0) &\n     (data3['Vehicle_Age']=='> 2 Years') & (data3['Vehicle_Damage']=='Yes') & \n      ((data3['AgeBracket']=='31-40') | (data3['AgeBracket']=='41-50') | (data3['AgeBracket']=='51-60')) & \n                  ((data3['Region_Code']=='11.0') | (data3['Region_Code']=='18.0') |\n                  (data3['Region_Code']=='20.0') | (data3['Region_Code']=='29.0') |\n                  (data3['Region_Code']=='3.0') | (data3['Region_Code']=='25.0') |\n                  (data3['Region_Code']=='39.0') | (data3['Region_Code']=='41.0')) & \n                  ((data3['Policy_Sales_Channel']=='154.0') | (data3['Policy_Sales_Channel']=='156.0') |\n                  (data3['Policy_Sales_Channel']=='157.0'))]","a658bcb2":"data_contact.head()","e1483484":"data_contact.shape","0d1df9fe":"cor1=data1.corr()","bf1d8b34":"plt.figure(figsize = (16,10))\nsns.heatmap(cor1,linewidths=1,annot=True)\nplt.plot()","e10ef106":"data2=data1.copy()","4d99b5ad":"data2.drop(['AgeBracket','quantile_5','Vin_q'],axis=1,inplace=True)","599e8a39":"data2.shape","b2e9f338":"data_test=pd.read_csv('\/kaggle\/input\/health-insurance-cross-sell-prediction\/test.csv')","825bfd5d":"data_test.shape","d372ad85":"#data_test.drop(['Annual_Premium','Vintage'],axis=1,inplace=True)","e49443f6":"new=pd.concat([data2,data_test],axis=0)","32e1f93a":"new['Vintage']=new['Vintage']\/365","0aef44f3":"for col in ['Region_Code']:\n\n    temp_df = pd.Series(new[col].value_counts() \/ len(new) )\n\n    # make plot with the above percentages\n    fig = temp_df.sort_values(ascending=False).plot.bar()\n    fig.set_xlabel(col)\n\n    # add a line at 5 % to flag the threshold for rare categories\n    fig.axhline(y=0.05, color='red')\n    fig.set_ylabel('Percentage of houses')\n    plt.show()","f60743ec":"def find_non_rare_labels(df, variable, tolerance):\n    \n    temp = df.groupby([variable])[variable].count() \/ len(df)\n    \n    non_rare = [x for x in temp.loc[temp>tolerance].index.values]\n    \n    return non_rare","a862e737":"find_non_rare_labels(new, 'Region_Code', 0.02)","f658e41f":"[x for x in new['Region_Code'].unique(\n) if x not in find_non_rare_labels(new, 'Region_Code', 0.02)]","42ea11e0":"new1=new.copy()","171838ea":"def rare_encoding(new, variable, tolerance):\n    frequent_cat = find_non_rare_labels(new1, variable, tolerance)\n\n    # re-group rare labels\n    new1[variable] = np.where(new1[variable].isin(\n        frequent_cat), new1[variable], 'Rare')\n\n    return new1","b2cd9b7a":"for variable in ['Region_Code']:\n    \n     new1= rare_encoding(new1, variable, 0.01)","999444f9":"for col in ['Region_Code']:\n\n    temp_df = pd.Series(new1[col].value_counts() \/ len(new1) )\n\n    # make plot with the above percentages\n    fig = temp_df.sort_values(ascending=False).plot.bar()\n    fig.set_xlabel(col)\n\n    # add a line at 5 % to flag the threshold for rare categories\n    fig.axhline(y=0.01, color='red')\n    fig.set_ylabel('Percentage of houses')\n    plt.show()","c9e814a9":"g1=pd.DataFrame((new1.groupby(['Region_Code'])['Response'].value_counts(normalize=True)*100).sort_values(ascending=False))","c3142072":"for col in ['Policy_Sales_Channel']:\n\n    temp_df = pd.Series(new[col].value_counts() \/ len(new) )\n\n    # make plot with the above percentages\n    fig = temp_df.sort_values(ascending=False).plot.bar()\n    fig.set_xlabel(col)\n\n    # add a line at 5 % to flag the threshold for rare categories\n    fig.axhline(y=0.01, color='red')\n    fig.set_ylabel('Percentage of houses')\n    plt.show()","f8fc6d41":"def find_non_rare_labels(df, variable, tolerance):\n    \n    temp = df.groupby([variable])[variable].count() \/ len(df)\n    \n    non_rare = [x for x in temp.loc[temp>tolerance].index.values]\n    \n    return non_rare","b5881bd6":"find_non_rare_labels(new1, 'Policy_Sales_Channel', 0.01)","1cc9cdbe":"def rare_encoding(new, variable, tolerance):\n    frequent_cat = find_non_rare_labels(new1, variable, tolerance)\n\n    # re-group rare labels\n    new1[variable] = np.where(new1[variable].isin(\n        frequent_cat), new1[variable], 'Rare')\n\n    return new1","13a19af0":"for variable in ['Policy_Sales_Channel']:\n    \n     new1= rare_encoding(new1, variable, 0.01)","f2604acb":"for col in ['Policy_Sales_Channel']:\n\n    temp_df = pd.Series(new1[col].value_counts() \/ len(new1) )\n\n    # make plot with the above percentages\n    fig = temp_df.sort_values(ascending=False).plot.bar()\n    fig.set_xlabel(col)\n\n    # add a line at 5 % to flag the threshold for rare categories\n    fig.axhline(y=0.01, color='red')\n    fig.set_ylabel('Percentage of houses')\n    plt.show()","674586f5":"pc=pd.DataFrame((new1.groupby(['Policy_Sales_Channel'])['Response'].value_counts(normalize=True)*100).sort_values(ascending=False))","859ea951":"pc","a57d606d":"new1.dtypes","59d23299":"#from feature_engine.categorical_encoders import CountFrequencyCategoricalEncoder","b0f36cda":"#dl=dict(new['Driving_License'].value_counts())","fb6e5514":"#new['Driving_License']=new['Driving_License'].replace(dl)","79abc4db":"#a=dict(new['Region_Code'].value_counts())","4e24c2f7":"#new['Region_Code']=new['Region_Code'].replace(a)","b5852776":"new1['Vehicle_Age']=new1['Vehicle_Age'].replace({'< 1 Year':0,'1-2 Year':1,'> 2 Years':2})","3595794a":"new1['Vehicle_Damage']=new1['Vehicle_Damage'].replace({'Yes':1,'No':0})","35fdabd7":"new1['Gender']=new1['Gender'].replace({'Male':1,'Female':0})","516aa3e3":"new1.head()","ed3c21d6":"!pip install feature-engine\nfrom feature_engine.categorical_encoders import OneHotCategoricalEncoder","165e6b16":"#new.columns","6309a303":"new1.dtypes","7d39f3fb":"new1['Region_Code'].unique()","57465118":"#new1['Region_Code']=new1['Region_Code'].replace({'Rare':0})","ef40e082":"\n#new1=new1.astype({'Region_Code':float})","a7063f2f":"new1.describe()","9ff6b3f1":"import scipy.stats as stats","15d8c3f0":"# function to create histogram, Q-Q plot and\n# boxplot. We learned this in section 3 of the course\n\n\ndef diagnostic_plots(df, variable):\n    # function takes a dataframe (df) and\n    # the variable of interest as arguments\n\n    # define figure size\n    plt.figure(figsize=(16, 4))\n\n    # histogram\n    plt.subplot(1, 3, 1)\n    sns.distplot(df[variable], bins=30)\n    plt.title('Histogram')\n\n    # Q-Q plot\n    plt.subplot(1, 3, 2)\n    stats.probplot(df[variable], dist=\"norm\", plot=plt)\n    plt.ylabel('Variable quantiles')\n\n    # boxplot\n    plt.subplot(1, 3, 3)\n    sns.boxplot(y=df[variable])\n    plt.title('Boxplot')\n\n    plt.show()","2cf9c8c8":"diagnostic_plots(new, 'Age')","2ee601bf":"diagnostic_plots(new, 'Annual_Premium')","4d601dad":"diagnostic_plots(new, 'Vintage')","7ebe20cc":"def find_skewed_boundaries(df, variable, distance):\n\n    # Let's calculate the boundaries outside which sit the outliers\n    # for skewed distributions\n\n    # distance passed as an argument, gives us the option to\n    # estimate 1.5 times or 3 times the IQR to calculate\n    # the boundaries.\n\n    IQR = df[variable].quantile(0.75) - df[variable].quantile(0.25)\n\n    lower_boundary = df[variable].quantile(0.25) - (IQR * distance)\n    upper_boundary = df[variable].quantile(0.75) + (IQR * distance)\n\n    return upper_boundary, lower_boundary","3df364e3":"ap_upper_limit, ap_lower_limit = find_skewed_boundaries(new, 'Annual_Premium', 1.5)\nap_upper_limit, ap_lower_limit","88a3054c":"# Now let's replace the outliers by the maximum and minimum limit\n\nnew['Annual_Premium']= np.where(new['Annual_Premium'] > ap_upper_limit, ap_upper_limit,\n                       np.where(new['Annual_Premium'] < ap_lower_limit, ap_lower_limit, new['Annual_Premium']))","bcbf03b4":"diagnostic_plots(new, 'Annual_Premium')","1a60a269":"new['Annual_Premium'].describe()","c8d999e1":"ohe_enc = OneHotCategoricalEncoder(\n    top_categories=None, # we can select which variables to encode\n    drop_last=True) # to return k-1, false to return k\n\n\nohe_enc.fit(new1)","332267f0":"tmp = ohe_enc.transform(new1)\n\ntmp.head()","4dc87497":"#tmp.drop('Driving_License',axis=1,inplace=True)","2e78367c":"tmp.drop('id',axis=1,inplace=True)","aacc2496":"Train=tmp.iloc[0:381109]","cf765f12":"Test=tmp.iloc[381109:]","ee622812":"X=Train.drop('Response',axis=1)","d3d579c6":"Y=Train['Response']","0d015039":"from imblearn.over_sampling import RandomOverSampler","4499f2ea":"os =  RandomOverSampler(0.70)","098a8732":"X_train_res, y_train_res = os.fit_sample(X, Y)","8ba45856":"X_train_res.shape,y_train_res.shape","3a3022cf":"from collections import Counter\nprint('Original dataset shape {}'.format(Counter(Y)))\nprint('Resampled dataset shape {}'.format(Counter(y_train_res)))","2269834d":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2","c7a4a42e":"ordered_rank_features=SelectKBest(score_func=chi2,k=5)\nordered_feature=ordered_rank_features.fit(X_train_res,y_train_res)","90d251ee":"\ndfscores=pd.DataFrame(ordered_feature.scores_,columns=[\"Score\"])\ndfcolumns=pd.DataFrame(X.columns)\n\n","0de79237":"features_rank=pd.concat([dfcolumns,dfscores],axis=1)","d78b112b":"features_rank.columns=['Features','Score']\n","db6e0d37":"X_train_res.shape","b837c103":"features_rank.nlargest(15,'Score')","ed6d3f04":"from sklearn.model_selection import train_test_split","882a6e79":"X_train, X_test, Y_train, Y_test = train_test_split(X_train_res,\n                                                    y_train_res,\n                                                    test_size=0.3,\n                                                    random_state=0)\n\nX_train.shape, X_test.shape","b1f8352b":"Test.drop('Response',axis=1,inplace=True)","98848df1":"from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error, roc_auc_score","92815bda":"test1=pd.read_csv('\/kaggle\/input\/health-insurance-cross-sell-prediction\/test.csv')","8059dcfb":"id1=test1['id']","f9aeaab5":"from lightgbm import LGBMClassifier\nlgbcl = LGBMClassifier(boosting_type='gbdt',n_estimators=500,depth=10,learning_rate=0.04,objective='binary',metric='auc',\n                 colsample_bytree=0.5,reg_lambda=2,reg_alpha=2,random_state=294,n_jobs=-1)\nlgbcl= lgbcl.fit(X_train, Y_train,eval_metric='auc',verbose=2)\ny_lgb = lgbcl.predict(X_test)\nprobs_tr = lgbcl.predict_proba(X_train)[:, 1]\nprobs_te = lgbcl.predict_proba(X_test)[:, 1]\nprint(roc_auc_score(Y_train, probs_tr))\nprint(roc_auc_score(Y_test, probs_te))","3efbe126":"lgbcl1=lgbcl.fit(X_train_res,y_train_res)","f35856db":"lgbcl1","3fc893ac":"lgb_pred= lgbcl1.predict_proba(Test)[:, 1]","6a67ae8b":"lgb_pred","363ee6ac":"lgb=pd.concat([pd.DataFrame(id1),pd.DataFrame(lgb_pred)],axis=1)","2a1385cb":"lgb2=lgb.copy()","d9f2f403":"lgb2.rename(columns={0:'Response'},inplace=True)","e530e3bf":"lgb2.to_csv('lgb_onehot+label.csv',index=False)","4f9c7cc1":"te=lgbcl.predict(X_test)","4dc74697":"tr=lgbcl.predict(X_train)","8fe00e6d":"from sklearn.metrics import confusion_matrix\ntrc=confusion_matrix(Y_train,tr)","8c9ca44b":"\ntec=confusion_matrix(Y_test,te)","d8ea6771":"recall_train=((trc[0][0])\/(trc[0][0]+trc[1][0]))*100","fe617bc1":"recall_train","de06ee40":"recall_test=((tec[0][0])\/(tec[0][0]+tec[1][0]))*100","85a895e9":"recall_test","c41530a3":"precision_train=((trc[0][0])\/(trc[0][0]+trc[0][1]))*100","3692b464":"precision_train","8888d953":"precision_test=((tec[0][0])\/(tec[0][0]+trc[0][1]))*100","268d7b66":"precision_test","15cca6aa":"from sklearn.ensemble import RandomForestClassifier","21472ac3":"rf1=RandomForestClassifier()","731b7273":"cross_val_score(rf1,X_train_res,y_train_res,cv=5,scoring='accuracy')","3271b506":"rf1.fit(X_train,Y_train)","f79b4cf2":"probs_tr_rf = rf1.predict_proba(X_train)[:, 1]\nprobs_te_rf = rf1.predict_proba(X_test)[:, 1]\nprint(roc_auc_score(Y_train, probs_tr_rf))\nprint(roc_auc_score(Y_test, probs_te_rf))","008ffec4":"te=rf1.predict(X_test)","62e1a084":"tr=rf1.predict(X_train)\n","280a8935":"from sklearn.metrics import confusion_matrix\ntrc=confusion_matrix(Y_train,tr)","eff0aee5":"\ntec=confusion_matrix(Y_test,te)","8a8734c5":"recall_train=((trc[0][0])\/(trc[0][0]+trc[1][0]))*100","2ef6ad0c":"recall_train","f704ddb2":"recall_test=((tec[0][0])\/(tec[0][0]+tec[1][0]))*100","b772f97d":"recall_test","3073d038":"precision_train=((trc[0][0])\/(trc[0][0]+trc[0][1]))*100","f46943c5":"precision_train","141aeadd":"precision_test=((tec[0][0])\/(tec[0][0]+trc[0][1]))*100","ddea8635":"precision_test","ff011e38":"F1_train = 2 * (precision_train * recall_train) \/ (precision_train + recall_train)","eddd84e3":"F1_train","d7980dbf":"F1_test = 2 * (precision_test * recall_test) \/ (precision_test + recall_test)","e3633577":"F1_test","59d18c9f":"rf_t=rf1.predict_proba(Test)","fef399c2":"rf_t","afa9fdac":"rf123=pd.concat([pd.DataFrame(id1),pd.DataFrame(rf_t)],axis=1)","7fb455c3":"rf_done=rf123.drop(0,axis=1)","a4e0cc08":"rf_done.rename(columns={1:'Response'},inplace=True)","6c6088c1":"rf_done.to_csv('AR_check.csv',index=False)","139ecae5":"Kindly Like the notebook, as it motivates me :), Thank You!","d34430a3":"**AGE**","4b0af9d2":"**VINTAGE**","836e891a":"EDA:\n    1) VISUALIZE","92c409ab":"***people with drivig liscence should be contacted first to pitch the insurance***","64c47e6d":"**When sales team in bank hands over data to business intelligence department, the BI department digs deep into the data to get the customers list for whom they should pitch the product first\nIf a proper EDA is not followed, it is not possible to access the list of customers for whom sales team should contact first.\nAs from business part certain parameters are defined in order to set constraints to get the high priority list of customers for sales pitching\nIf not done in a systematic manner, with taking into account business parameters, the cost may increase as sales team may start contacting customers with less probability of buying the product.\nThe main focus of this notebook is to access the list of  those customers who have high probability of buying the product**","17948880":"***People who are not previously insured should be contacted first***","5bb20250":"***for region code we can use greater than 10% chance\nregion 11,18,20,29,3,25,39,41***","9f0a97a8":"**ANNUAL PREMIUM**","e174bf0f":"UNIVIRATE ANALYSIS","0437dd22":"**Customer list that has to be contatced first**","b79a4acd":"**PTRVIOUSLY INSURED**","6755e59b":"**CHI SQUARE FOR FEATURE SELECTION**","2b678dfc":"***>2 years and 1-2 years should be contacted first***","a21a78ca":"ENCODING RARE LABELS IN POLICY SALES CHANNEL","ae461204":"***In vintage also we can include all***","b7ebc101":"**VEHICLE AGE**","54930395":"**VEHICLE DAMAGE**","bbfbcdf0":"**OUTLIER Treatment**","96c5aa52":"**DRIVING LICENSE**","fe4b6da3":"***We can contact all customers in case of annual premium***","c202240d":"***Here we have to take care of Recall more than Precision\nBy taking care of Recall, We say that we want to increase Our True positives and reduce False neagtive\nWe dont want to miss out customers who have actually responed 1***\n*\n**We also want to take care of type 1 error\nthat is we dont want to classify who has response as 0 to response of 1\nit may increase our cost on business side, as calling may increase***\n\n***but recall has higher importance here***","a8122926":"**REGION CODE**","b35aca28":"***SO age bracket of 31-40 and 41-50 and even 51-60 are the ones of who should be contacted first\nfor vehicle insurance premium***","e7179875":"**GENDER**","a25bbc58":"***POLICY SALES CAHNNEL***","4f46c01b":"***CLEAR CASE OF IMBALANCE PROBLEM***","6544ae1f":"***For policy sales channel BY TAKING greater than 20% chance we should contact customers which are contacted through\n154,156,157 sales channel***","f4ddf6de":"***Annual premium is health premium taken by the customer\nlets find out in what range of annual premium does customer go for vehicle insurance***","fafe2356":"***People who have damaged the vehicle should be contacted first***","aed26130":"***SO from 381109 customers we have boiled down the list to 106,\nthe sales department can use this list and contact them first***"}}