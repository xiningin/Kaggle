{"cell_type":{"1771b8ce":"code","070f0d3c":"code","b309c4b2":"code","8bfbfa15":"code","605f8ded":"code","20a5f843":"code","70252a30":"code","3b5d9ef6":"code","d468c0ee":"code","381a3b60":"code","f52809b0":"code","e1b80056":"code","4f7eb35c":"code","b096cea6":"code","ce931c1b":"code","c2eed0fd":"code","aa0cf4bf":"code","33889524":"code","9bc2b572":"code","c2311126":"code","c0a59a2a":"code","7031699f":"code","49212709":"code","d86dfba0":"code","5c1491e1":"code","fa6f43d5":"code","6d232faa":"code","a1e17cad":"code","d04e0d56":"code","dfc2c600":"code","ccb833fa":"code","dfa42738":"code","f0a89c3d":"code","5e5048f1":"code","9e9f95ab":"code","05e015a2":"markdown","56380281":"markdown","40670b38":"markdown","dd4bd6a5":"markdown","11ae8c55":"markdown","aea76f55":"markdown"},"source":{"1771b8ce":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/black-friday'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","070f0d3c":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns","b309c4b2":"train = pd.read_csv('\/kaggle\/input\/black-friday\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/black-friday\/test.csv')","8bfbfa15":"train.head()","605f8ded":"train.info()","20a5f843":"train.describe()","70252a30":"train.isnull().sum()","3b5d9ef6":"import seaborn as sns\nsns.heatmap(train.isnull(), cbar=False)","d468c0ee":"sns.set(rc = {'figure.figsize':(16,10)})\nsns.heatmap(train.corr(),annot=True,cbar=False)","381a3b60":"plt.figure(figsize=(10,5))\nsns.countplot(train['Age'])\n","f52809b0":"plt.figure(figsize=(10,5))\nsns.countplot(train['Stay_In_Current_City_Years'])","e1b80056":"train.head()","4f7eb35c":"plt.figure(figsize=(10,5))\nsns.countplot(train['City_Category'])","b096cea6":"train[['Product_ID','Gender','Age','Occupation','City_Category','Stay_In_Current_City_Years','Marital_Status']].nunique()","ce931c1b":"sns.distplot(train['Product_Category_3'])","c2eed0fd":"sns.distplot(train['Product_Category_2'])","aa0cf4bf":"train['Product_Category_2'].fillna(train['Product_Category_2'].mean(),inplace=True)\ntrain['Product_Category_3'].fillna(train['Product_Category_3'].mean(),inplace=True)\ntest['Product_Category_2'].fillna(train['Product_Category_2'].mean(),inplace=True)\ntest['Product_Category_3'].fillna(train['Product_Category_3'].mean(),inplace=True)\n","33889524":"train.isnull().sum()","9bc2b572":"train['Stay_In_Current_City_Years'].replace({'4+':4},inplace=True)\ntest['Stay_In_Current_City_Years'].replace({'4+':4},inplace=True)","c2311126":"# Gender\ntrain['Gender'].replace({\"M\":1,\"F\":0},inplace=True)\ntest['Gender'].replace({\"M\":1,\"F\":0},inplace=True)","c0a59a2a":"# Age\ndef map_age(age):\n    if age == '0-17':\n        return 0\n    elif age == '18-25':\n        return 1\n    elif age == '26-35':\n        return 2\n    elif age == '36-45':\n        return 3\n    elif age == '46-50':\n        return 4\n    elif age == '51-55':\n        return 5\n    else:\n        return 6","7031699f":"train['Age'] = train['Age'].apply(map_age)\ntest['Age'] = test['Age'].apply(map_age)","49212709":"# Mapping the City_Category \n\ntrain['City_Category']=train['City_Category'].map({\"B\":1,\"A\":2,\"C\":3})\ntest['City_Category']=test['City_Category'].map({\"B\":1,\"A\":2,\"C\":3})","d86dfba0":"test['City_Category']= test['City_Category'].astype(int)\ntrain['City_Category']= train['City_Category'].astype(int)","5c1491e1":"train['Stay_In_Current_City_Years']= train['Stay_In_Current_City_Years'].astype(int)\ntest['Stay_In_Current_City_Years']= test['Stay_In_Current_City_Years'].astype(int)","fa6f43d5":"train = train.drop([\"User_ID\",\"Product_ID\"],axis=1)","6d232faa":"from sklearn.model_selection import train_test_split\nX = train.drop(\"Purchase\",axis=1)\ny = train['Purchase']\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n\n","a1e17cad":"import xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\n\nxg=xgb.XGBRegressor()\n","d04e0d56":"xg.fit(X_train, y_train)\nxg_predict= xg.predict(X_test)","dfc2c600":"print(\"RMSE score for XGB Regressor : \", np.sqrt(mean_squared_error(y_test,xg_predict)))","ccb833fa":"test.head()","dfa42738":"X_testing = test[['Gender','Age','Occupation','City_Category','Stay_In_Current_City_Years','Marital_Status','Product_Category_1'\n                 ,'Product_Category_2','Product_Category_3']]","f0a89c3d":"predict = xg.predict(X_testing)","5e5048f1":"Submit = pd.DataFrame({'Purchase':predict,'User_ID':test['User_ID'],'Product_ID':test['Product_ID']})","9e9f95ab":"Submit.to_csv('submission.csv',index=False)","05e015a2":"*Note* - If the data seems right or left handed skewed then we have to first convert it and then we can replace null values with mean or median.","56380281":"If we observe carefully we can see that the distribution os neither too scattered nor converged to one value, hence for the missing values we could use mean \/ median","40670b38":"Obviously we can see that there is missing values in both category_2 and category_3 in large amount","dd4bd6a5":"Data preprocessing","11ae8c55":"Training","aea76f55":"Hence for missing values we are going to use mean.\n"}}