{"cell_type":{"5f82a7fd":"code","da1a061d":"code","ec4a1482":"code","707a8857":"code","90315eb2":"code","d86b1188":"code","3d05e674":"code","d758d276":"code","32f51320":"markdown","5ba972d7":"markdown","ebe0657f":"markdown"},"source":{"5f82a7fd":"from kaggle_environments import make, evaluate\n\n# Create the game environment\n# Set debug=True to see the errors if your agent refuses to run\nenv = make(\"connectx\", debug=True)","da1a061d":"def agent_monte_carlo(obs, config):\n    import random\n    import time\n    import numpy as np\n    import math\n\n    #############\n    ## Helpers ##\n    #############\n    def board_to_grid(board, config):\n        return np.asarray(board).reshape(config.rows, config.columns)\n\n    def grid_to_board(grid):\n        return grid.reshape(-1)\n\n    def other_player(player):\n        return 1 if player == 2 else 2 \n\n    # Gets grid at next step if agent drops piece in selected column\n    def drop_piece(grid, col, piece, config):\n        next_grid = grid.copy()\n        for row in range(config.rows-1, -1, -1):\n            if next_grid[row][col] == 0:\n                break\n        next_grid[row][col] = piece\n        return next_grid, row\n\n    # The \"4\" at the end of the name idicates this function only works when dealing with \n    # games that terminate with 4 in-a-row.\n    # This version checks the full board; the one below checks only the spaces affected by the \n    # latest drop.\n    def player_has_won_fast_4_full(grid, config):\n        assert config.inarow == 4\n\n        for r in range(config.rows):\n            for c in range(config.columns-3):\n                if 0 != grid[r][c] == grid[r][c+1] == grid[r][c+2] == grid[r][c+3]:\n                    return grid[r][c]\n\n        for c in range(config.columns):\n            for r in range(config.rows-3):\n                if 0 != grid[r][c] == grid[r+1][c] == grid[r+2][c] == grid[r+3][c]:\n                    return grid[r][c]\n\n        for r in range(config.rows-3):\n            for c in range(config.columns-3):\n                if 0 != grid[r][c] == grid[r+1][c+1] == grid[r+2][c+2] == grid[r+3][c+3]:\n                    return grid[r][c]\n\n        for r in range(config.rows-3):\n            for c in range(config.columns-3):\n                if 0 != grid[r][c+3] == grid[r+1][c+2] == grid[r+2][c+1] == grid[r+3][c]:\n                    return grid[r][c+3]\n\n        return 0\n    \n    def player_has_won_fast_4(grid, row, col, config):\n        assert config.inarow == 4\n\n        # Check horizontal\n        for c in range(max(0, col-3), min(col, config.columns-3)):\n            if 0 != grid[row][c] == grid[row][c+1] == grid[row][c+2] == grid[row][c+3]:\n                return grid[row][col]\n\n        # Check vertical\n        for r in range(max(0, row-3), min(row, config.rows-3)):\n            if 0 != grid[r][col] == grid[r+1][col] == grid[r+2][col] == grid[r+3][col]:\n                return grid[row][col]\n\n        # Check diagonal down-right\n        for i in range(max(-3, -row, -col), min(0, -3+config.rows-1-row, -3+config.columns-1-col)):\n            if 0 != grid[row+i][col+i] == grid[row+i+1][col+i+1] == grid[row+i+2][col+i+2] == grid[row+i+3][col+i+3]:\n                return grid[row][col]\n\n        # Check diagonal down-left\n        for i in range(max(-3, -row, -config.columns+1+col), min(0, -3+config.rows-1-row, -3+col)):\n            if 0 != grid[row+i][col-i] == grid[row+i+1][col-i-1] == grid[row+i+2][col-i-2] == grid[row+i+3][col-i-3]:\n                return grid[row][col]\n\n        return 0\n\n    # This function defines a simple rule-based look-ahead agent. \n    # Returns (col, guaranteed_win)\n    def behavior_lookahead_2(grid, piece, config):\n        valid_moves = [col for col in range(config.columns) if grid[0][col] == 0]\n\n        if len(valid_moves) == 0:\n            return None, False\n\n        # If dropping a piece makes us win, then do that.\n        for move in valid_moves:   \n            next_grid, row = drop_piece(grid, move, piece, config)\n            if player_has_won_fast_4(next_grid, row, move, config) != 0:\n                return move, True\n\n        # If dropping a piece blocks our opponent from winning next turn, then do that.\n        for move in valid_moves:    \n            next_grid, row = drop_piece(grid, move, other_player(piece), config)\n            if player_has_won_fast_4(next_grid, row, move, config) != 0:\n                return move, False\n\n        # If dropping a piece gives us two ways to win next turn, then do that.\n#         for move_1 in valid_moves:\n#             paths_to_victory = 0\n#             next_grid, _ = drop_piece(grid, move_1, piece, config)\n#             next_valid_moves = [col for col in range(config.columns) if next_grid[0][col] == 0]\n#             for move_2 in next_valid_moves:\n#                 next_grid_2, row = drop_piece(next_grid, move_2, piece, config)\n#                 if player_has_won_fast_4(next_grid_2, row, move, config) != 0:\n#                     paths_to_victory += 1\n#                     if paths_to_victory >= 2:\n#                         return move_1, True\n        \n        # Otherwise, choose a random valid move\n        return random.choice(valid_moves), False\n    \n    discount_factor = 0.9\n    max_depth = 10\n\n    # Simulate two lookahead_2 players from the given grid position.\n    def simulate(move, grid, row, col):\n        us = obs.mark\n        them = other_player(obs.mark)\n\n        if player_has_won_fast_4(grid, row, col, config) == us:\n            return 1.0\n\n        next_grid = grid\n        k = 0\n\n        while time.time() < deadline:\n            their_move, guaranteed_win = behavior_lookahead_2(next_grid, them, config)\n            if their_move == None:\n                return 0\n            if guaranteed_win:\n                # They won\n                return -1.0 * discount_factor**k      \n            next_grid, _ = drop_piece(next_grid, their_move, them, config)\n            k+=1\n\n            our_move, guaranteed_win = behavior_lookahead_2(next_grid, us, config)\n            if our_move == None:\n                return 0\n            if guaranteed_win:\n                # We won\n                return 1.0 * discount_factor**k\n            next_grid, _ = drop_piece(next_grid, our_move, us, config)\n            k+=1\n            \n            if k >= max_depth:\n                return \"max_depth\"\n        \n        return \"timeup\"\n\n    def choose_next_move_uniform(valid_moves):\n        return random.choice(valid_moves)\n    \n    ###########\n    ## AGENT ##\n    ###########\n    \n    deadline = time.time() + config.actTimeout - 0.5\n    # Uncomment to limit time per turn during testing.\n    # deadline = time.time() + 1\n    \n    grid = board_to_grid(obs.board, config)\n    \n    valid_moves = [col for col in range(config.columns) if grid[0][col] == 0]\n    \n    # Initialize all values to -2. Invalid moves will never be updated, so they will always be\n    # worse than moves that guarantee defeat. This prevents us from erroring out.\n    values = np.repeat(-2.0, config.columns)\n    \n    num_observed = np.zeros_like(values)\n    \n    while time.time() < deadline:\n        move = choose_next_move_uniform(valid_moves)\n        \n        # Estimate return\n        next_grid, row = drop_piece(grid, move, obs.mark, config)\n        _return = simulate(move, next_grid, row, move)\n        if _return == \"timeup\":\n            # Ended early. Time is almost up!\n            break\n        if _return == \"max_depth\":\n            continue\n        \n        # Update estimated values\n        num_observed[move] += 1\n        values[move] = _return \/ num_observed[move] + \\\n                       (num_observed[move] - 1) \/ num_observed[move] * values[move] \n    \n    return int(np.argmax(values))","ec4a1482":"# Copy the helper methods from the agent_monte_carlo function to try this out.\n\n# g_board = None\n# g_config = None\n\n# def agent_lookahead_2(obs, config):\n#     global g_board, g_config\n#     grid = board_to_grid(obs.board, config)\n#     g_board = obs.board\n#     g_config = config\n#     move, _ behavior_lookahead_2(grid, obs.mark, config)\n#     return move","707a8857":"# # Two agents play one game round\n# env.run([agent_monte_carlo, \"random\"]);\n# # Show the game\n# env.render(mode=\"ipython\")","90315eb2":"# grid = board_to_grid(g_board, g_config)\n\n# %timeit drop_piece(grid, 4, 1, g_config)","d86b1188":"# Modified from tutorial\n\n# def get_win_percentages(agent1, agent2, n_rounds=50):\n#     import numpy as np\n#     config = {\"rows\": 6, \"columns\": 7, \"inarow\": 4}\n#     outcomes = []\n#     for i in range(n_rounds):\n#         outcomes += evaluate(\"connectx\", [agent1, agent2], config, [], 1)\n#         outcomes += [[b,a] for [a,b] in evaluate(\"connectx\", [agent2, agent1], config, [], 1)]\n#     print(\"Agent 1 Win Percentage:\", np.round(outcomes.count([1,-1])\/len(outcomes), 2))\n#     print(\"Agent 2 Win Percentage:\", np.round(outcomes.count([-1,1])\/len(outcomes), 2))\n#     return outcomes\n    \n# outcomes = get_win_percentages(agent_lookahead_2, agent_lookahead_3, 50)","3d05e674":"import inspect\nimport os\n\n# Create submission file\ndef write_agent_to_file(function, file):\n    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n        f.write(inspect.getsource(function))\n        print(function, \"written to\", file)\n        \nwrite_agent_to_file(agent_monte_carlo, \"submission.py\")","d758d276":"# Validate submission file\n\nimport sys\nfrom kaggle_environments import utils\n\nout = sys.stdout\nsubmission = utils.read_file(\"\/kaggle\/working\/submission.py\")\nagent = utils.get_last_callable(submission)\nsys.stdout = out\n\nenv = make(\"connectx\", debug=True)\nenv.run([agent, agent])\nprint(\"Success!\" if env.state[0].status == env.state[1].status == \"DONE\" else \"Failed...\")","32f51320":"To sumit to the competition, follow these steps:\n1. Begin by clicking on the blue **Save Version** button in the top right corner of this window.  This will generate a pop-up window.  \n2. Ensure that the **Save and Run All** option is selected, and then click on the blue **Save** button.\n3. This generates a window in the bottom left corner of the notebook.  After it has finished running, click on the number to the right of the **Save Version** button.  This pulls up a list of versions on the right of the screen.  Click on the ellipsis **(...)** to the right of the most recent version, and select **Open in Viewer**.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n4. Click on the **Output** tab on the right of the screen.  Then, click on the **Submit to Competition** button to submit your results to the leaderboard.\n\nYou have now successfully submitted to the competition!\n\nIf you want to keep working to improve your performance, select the blue **Edit** button in the top right of the screen. Then you can change your code and repeat the process. There's a lot of room to improve, and you will climb up the leaderboard as you work.\n\n\nGo to **\"My Submissions\"** to view your score and episodes being played.","5ba972d7":"Agents are functions that take two parameters:\n\n- `obs.board` : the game board (a Python list with one item for each grid location)\n- `obs.mark` : the piece assigned to the agent (either 1 or 2)\n\n- `config.columns` : number of columns in the game board (7 for Connect Four)\n- `config.rows` : number of rows in the game board (6 for Connect Four)\n- `config.inarow` : number of pieces a player needs to get in a row in order to win (4 for Connect Four)\n\nAgents return the column to drop their next piece into (0-6).\n\nRemember that the agent function must be completely stand-alone! It must contain *all* helper functions and imports.","ebe0657f":"# Summary\n\nThis Monte Carlo algorithm improves a simple lookahead by running as many simulated games from the current position as possible within our turn time limit. We choose the move that appears to have the greatest chance of victory based on the simulations. "}}