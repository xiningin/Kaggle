{"cell_type":{"e8dd36e7":"code","3c4ac572":"code","bb11bb63":"code","68a09037":"code","9593beb5":"code","aea8c859":"code","67959b52":"code","bf9e0830":"code","9abff0c1":"code","4e87a4fe":"code","272e7a82":"code","4f04eb43":"code","84c76c78":"code","1001e15b":"code","080bc80f":"code","6d2a55d8":"code","8f8091c6":"code","3ba2ce76":"code","9b17bc60":"code","e9fd3503":"code","7c457707":"code","dc7395c2":"code","fd603346":"code","1ab9fd29":"code","bbd798d2":"code","19558827":"code","48d4a036":"code","af4a8814":"code","895bceaf":"code","4a1f7616":"code","cf3950de":"code","7ee4d8b2":"code","916b11c4":"code","20e3400b":"code","bc8b933f":"code","a6fab53b":"code","d4c26d93":"code","415264c1":"markdown","f6c911ee":"markdown","d98c5534":"markdown"},"source":{"e8dd36e7":"#Importando Bibliotecas\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.utils import resample\nfrom sklearn.model_selection import train_test_split\nimport scikitplot as skplt\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","3c4ac572":"# Carregando os dados\ndf = pd.read_csv('\/kaggle\/input\/costa-rican-household-poverty-prediction\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/costa-rican-household-poverty-prediction\/test.csv')\n\ndf.shape, test.shape","bb11bb63":"# Juntando os dataframes\ndf_all = df.append(test)\n\ndf_all.shape","68a09037":"# Verificando tamanhos e tipos\ndf_all.info()","9593beb5":"# Quais colunas do dataframe s\u00e3o do tipo object\ndf_all.select_dtypes('object').head()","aea8c859":"# Olhando a coluna dependency\ndf_all['dependency'].value_counts()","67959b52":"# Analisando os dados da coluna edjefa\ndf_all['edjefa'].value_counts()","bf9e0830":"# Analisando os dados da coluna edjefe\ndf_all['edjefe'].value_counts()","9abff0c1":"# Vamos transformar 'yes' em 1 e 'no' em 0\n# nas colunas edjefa e edjefe\nmapeamento = {'yes': 1, 'no': 0}\n\ndf_all['edjefa'] = df_all['edjefa'].replace(mapeamento).astype(int)\ndf_all['edjefe'] = df_all['edjefe'].replace(mapeamento).astype(int)","4e87a4fe":"# Quais colunas do dataframe s\u00e3o do tipo object\ndf_all.select_dtypes('object').head()","272e7a82":"# Olhando a coluna dependency\ndf_all['dependency'].value_counts()","4f04eb43":"# Vamos transformar 'yes' em 1 e 'no' em 0\n# na coluna dependency\ndf_all['dependency'] = df_all['dependency'].replace(mapeamento).astype(float)","84c76c78":"# Quais colunas do dataframe s\u00e3o do tipo object\ndf_all.select_dtypes('object').head()","1001e15b":"# Visualizando do comando info\ndf_all.info()","080bc80f":"# Verificando os valores nulos\ndf_all.isnull().sum()","6d2a55d8":" # Verificando os valores de aluguel (v2a1) para os chefes\/as de familia (parentesco1 = 1)\ndf_all[df_all['parentesco1'] == 1]['v2a1'].isnull().sum()","8f8091c6":"# Qual a cara dos dados de v18q\ndf_all['v18q'].value_counts()","3ba2ce76":"# Prenchendo com -1 os valores nulos de v2a1\ndf_all['v2a1'].fillna(-1, inplace=True)","9b17bc60":"# Prenchendo com 0 os valores nulos de v18q1\ndf_all['v18q1'].fillna(0, inplace=True)","e9fd3503":"# Verificando os valores nulos\ndf_all.isnull().sum().sort_values()","7c457707":"# Prenchendo com -1 os valores nulos de SQBmeaned, meaneduc e rez_esc\ndf_all['SQBmeaned'].fillna(-1, inplace=True)\ndf_all['meaneduc'].fillna(-1, inplace=True)\ndf_all['rez_esc'].fillna(-1, inplace=True)","dc7395c2":"#Verificando as Classes\ndf_all.Target.value_counts()","fd603346":"#Plotando as Classes\nimport seaborn as sns\nax = sns.countplot(x='Target',  data=df_all)","1ab9fd29":"# Separando as colunas para treinamento\nfeats = [c for c in df_all.columns if c not in ['Id', 'idhogar', 'Target']]","bbd798d2":"# Separar os dataframes\ntrain, test = df_all[~df_all['Target'].isnull()], df_all[df_all['Target'].isnull()]\n\ntrain.shape, test.shape","19558827":"# Random Forest\nrf = RandomForestClassifier(max_depth=None, random_state=42, n_jobs=4, n_estimators=701, min_impurity_decrease=0.0007, min_samples_leaf=2, min_samples_split=5, verbose=0, class_weight='balanced')\n\nrf.fit(train[feats], train['Target'])\n\ntest['Target'] = rf.predict(test[feats]).astype(int)\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","48d4a036":"# Dividindo os dados por classes\ndf_a = df_all[df_all['Target'] == 1]\ndf_b = df_all[df_all['Target'] == 2]\ndf_c = df_all[df_all['Target'] == 3]\ndf_d = df_all[df_all['Target'] == 4]","af4a8814":"# Aplicando Over_Sampling\ndf_a_os = resample(df_a, replace=True, n_samples=len(df_d), random_state=42)\ndf_b_os = resample(df_b, replace=True, n_samples=len(df_d), random_state=42)\ndf_c_os = resample(df_c, replace=True, n_samples=len(df_d), random_state=42)\n\n# Concatenando\ndf_os = pd.concat([df_a_os, df_b_os, df_c_os, df_d])","895bceaf":"# Verificando as classes ap\u00f3s o balanceamento\ndf_os['Target'].value_counts()","4a1f7616":"#Plotando as Classes\nimport seaborn as sns\nax = sns.countplot(x='Target',  data=df_os)","cf3950de":"# Executando novo RandomForest ap\u00f3s Over_Sampling\n\n# Dividindo em treino e teste\ntrain, test = train_test_split(df_os, test_size=0.2, random_state=42)\n\n# Treinar o modelo\nrf.fit(train[feats], train['Target'])\n\n# Previs\u00f5es na base de teste\npreds_test = rf.predict(test[feats])\n\n# Medir a acur\u00e1cia\naccuracy_score(test['Target'], preds_test)","7ee4d8b2":"skplt.metrics.plot_confusion_matrix(test['Target'], preds_test)","916b11c4":"# Aplicando Under-Sampling\ndf_b_us = resample(df_b, replace=False, n_samples=len(df_a),random_state=42)\ndf_c_us = resample(df_c, replace=False, n_samples=len(df_a),random_state=42)\ndf_d_us = resample(df_d, replace=False, n_samples=len(df_a),random_state=42)\n\n# Concatenando os dados\ndf_us = pd.concat([df_a, df_b_us, df_c_us, df_d_us])","20e3400b":"# Verificando as Classes ap\u00f3s o Balanceamento\ndf_us['Target'].value_counts()","bc8b933f":"#Plotando as Classes\nimport seaborn as sns\nax = sns.countplot(x='Target',  data=df_us)","a6fab53b":"# Executando novo RandomForest ap\u00f3s Over_Sampling\n\n# Dividindo em treino e teste\ntrain, test = train_test_split(df_us, test_size=0.2, random_state=42)\n\n# Treinar o modelo\nrf.fit(train[feats], train['Target'])\n\n# Previs\u00f5es na base de teste\npreds_test = rf.predict(test[feats])\n\n# Medir a acur\u00e1cia\naccuracy_score(test['Target'], preds_test)","d4c26d93":"skplt.metrics.plot_confusion_matrix(test['Target'], preds_test)","415264c1":"# **Score Encontrado = **0.44049****","f6c911ee":"# Agora vamos balancear as classes!","d98c5534":"# IESB - Graduacao - CIA028 - Costa Rica"}}