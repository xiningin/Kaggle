{"cell_type":{"44ee4d23":"code","fd9000c9":"code","1528958f":"code","6bafbb12":"code","4c6aa656":"code","34c3abe5":"code","86eb9596":"code","d43da6e0":"code","6d20fb6c":"code","d6277c13":"code","13aa1fec":"code","9e0ff647":"code","5e63ff9d":"code","01a9d7f0":"code","b4da0d63":"code","86f05a93":"code","2499726c":"code","444c5f89":"code","df97083f":"code","b0ed63f3":"code","e786a42c":"code","5bd06823":"code","0534a682":"code","dd2ba65b":"code","50beb8d4":"code","1ce60498":"code","d766e082":"code","a6fb3042":"code","8c26d48d":"code","7d83701e":"code","387cec5c":"code","a0c5cc83":"code","6d5c906f":"code","79df9297":"code","4225342c":"code","6fb3187c":"code","dd2efd9c":"code","7a192d2c":"code","113dcb99":"code","82bb695a":"code","29eb9dcc":"code","5ecf3bab":"code","47355d26":"code","cc162aec":"code","381c2b18":"code","295be42c":"code","cadb8d1c":"code","b75205b9":"code","8c117d89":"code","f4613f5d":"code","ec94b251":"code","55c2cc9e":"code","b6059c6a":"code","b7e60332":"code","81f38d60":"code","458e1b5c":"code","92e90caf":"code","b0aef7b9":"code","dc40bb4e":"code","2a1c4b9a":"code","c945b0be":"code","ee41c816":"code","48444a67":"code","24e3e9e8":"code","521131a1":"code","d184cbd5":"code","80d27b8c":"code","c1063b9d":"code","18087895":"code","e40a34e6":"code","56a30ebe":"code","b7d22532":"code","1833ce28":"code","24aa0d60":"code","a4ba88ba":"code","0c694c77":"code","b678caed":"code","902a6e9d":"code","e69ff723":"code","06baa3e9":"code","d623d83d":"code","973df424":"code","1223242f":"markdown","413ab66a":"markdown","5f17e47c":"markdown","16d8c6c5":"markdown","94b1868a":"markdown","aa295f5c":"markdown","bb2394ea":"markdown","478138a3":"markdown","7915f386":"markdown","5ce9d097":"markdown","11902a5d":"markdown","48b70e66":"markdown","0079c1a2":"markdown","6137e9b9":"markdown","902ed027":"markdown","706d7a33":"markdown","930c2bcb":"markdown","97ad31f3":"markdown","a4ffd250":"markdown","a86da2ef":"markdown","6dea0344":"markdown","18a6e05a":"markdown","a781f8c1":"markdown","8339ec1a":"markdown","9ec01fef":"markdown","ca5ee6f3":"markdown","7d9b554c":"markdown","c85ec61b":"markdown","fe1ca84b":"markdown","9b89d512":"markdown","21eb2d10":"markdown","0a0102fb":"markdown","8e891939":"markdown","4cdf7ca4":"markdown","b58dd3e4":"markdown","e2b5080f":"markdown","ed54cac2":"markdown","4516f8bc":"markdown","3f79daf5":"markdown","d8d8fd50":"markdown","a79f09c9":"markdown","37715dcc":"markdown","bfc35b36":"markdown","311785e8":"markdown","69d333b2":"markdown","a1396fb6":"markdown","f17a678e":"markdown","6fc92e17":"markdown","68a30471":"markdown","a7daddb7":"markdown","dbd19dfb":"markdown","7cf5742d":"markdown","9c20f5f6":"markdown","1d2ad5c4":"markdown","58e77ca6":"markdown","68cfca30":"markdown","64c8623b":"markdown","4c3c1ec2":"markdown","632a880f":"markdown","8f3823dd":"markdown","a8db69a0":"markdown","4a160d11":"markdown"},"source":{"44ee4d23":"# \u0438\u043c\u043f\u043e\u0440\u0442 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0445 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\nimport pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pylab import rcParams\nimport math\nimport xgboost # conda install py-xgboost\nimport time\nfrom tqdm import tqdm","fd9000c9":"fd_001_train = pd.read_csv(\"\/kaggle\/input\/nasa-cmaps\/CMaps\/train_FD001.txt\",sep=\" \",header=None)","1528958f":"fd_001_test = pd.read_csv(\"\/kaggle\/input\/nasa-cmaps\/CMaps\/test_FD001.txt\",sep=\" \",header=None)","6bafbb12":"fd_001_train.describe()","4c6aa656":"fd_001_train.drop(columns=[26,27],inplace=True)","34c3abe5":"fd_001_test.drop(columns=[26,27],inplace=True)","86eb9596":"columns = ['unit_number','time_in_cycles','setting_1','setting_2','TRA','T2','T24','T30','T50','P2','P15','P30','Nf',\n           'Nc','epr','Ps30','phi','NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32' ]","d43da6e0":"fd_001_train.columns = columns","6d20fb6c":"fd_001_test.columns = columns","d6277c13":"# \u043f\u0435\u0440\u0432\u0438\u0447\u043d\u043e\u0435 \u0437\u043d\u0430\u043a\u043e\u043c\u0441\u0442\u0432\u043e \u0441 \u0434\u0430\u043d\u043d\u044b\u043c\u0438\n#initial acquaintance with data\nfd_001_train.describe()","13aa1fec":"# \u0443\u0434\u0430\u043b\u0438\u043c \u043a\u043e\u043b\u043e\u043d\u043a\u0438 \u0441 \u043a\u043e\u043d\u0441\u0442\u0430\u043d\u0442\u043d\u044b\u043c\u0438 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\u043c\u0438, \u043a\u0430\u043a \u043d\u0435 \u043d\u0435\u0441\u0443\u0449\u0438\u043c\u0438 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044e \u043e \u0441\u043e\u0441\u0442\u043e\u044f\u043d\u0438\u0438 \u0430\u0433\u0440\u0435\u0433\u0430\u0442\u0430\n#delete columns with constant values \u200b\u200bthat do not carry information about the state of the unit\nfd_001_train.drop(columns=['Nf_dmd','PCNfR_dmd','P2','T2','TRA','farB','epr'],inplace=True)\n","9e0ff647":"# \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u043f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0438 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438 \u0444\u043e\u0440\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u043a\u043e\u043b\u043e\u043d\u043a\u0438 RUL  \u0441 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0435\u0439 \u043e\u0431 \u043e\u0441\u0442\u0430\u0432\u0448\u0438\u0445\u0441\u044f\n#\u0434\u043e \u043f\u043e\u043b\u043e\u043c\u043a\u0438 \u0446\u0438\u043a\u043b\u0430\u0445\n#function for preparing training data and forming a RUL column with information about the remaining\n# before breaking cycles\ndef prepare_train_data(data, factor = 0):\n    df = data.copy()\n    fd_RUL = df.groupby('unit_number')['time_in_cycles'].max().reset_index()\n    fd_RUL = pd.DataFrame(fd_RUL)\n    fd_RUL.columns = ['unit_number','max']\n    df = df.merge(fd_RUL, on=['unit_number'], how='left')\n    df['RUL'] = df['max'] - df['time_in_cycles']\n    df.drop(columns=['max'],inplace = True)\n    \n    return df[df['time_in_cycles'] > factor]\n","5e63ff9d":"df = prepare_train_data(fd_001_train)","01a9d7f0":"sns.heatmap(df.corr(),annot=True,cmap='RdYlGn',linewidths=0.2)\nfig=plt.gcf()\nfig.set_size_inches(20,20)\nplt.show()","b4da0d63":"# \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u043e\u0448\u0438\u0431\u043a\u0438 \u0434\u043b\u044f \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\n#Error Function for Competitive Data\ndef score(y_true,y_pred,a1=10,a2=13):\n    score = 0\n    d = y_pred - y_true\n    for i in d:\n        if i >= 0 :\n            score += math.exp(i\/a2) - 1   \n        else:\n            score += math.exp(- i\/a1) - 1\n    return score\n    \n   ","86f05a93":"def score_func(y_true,y_pred):\n    print(f' \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0439 \u0441\u0447\u0435\u0442 {round(score(y_true,y_pred),2)}')\n    print(f' mean absolute error {round(mean_absolute_error(y_true,y_pred),2)}')\n    print(f' root mean squared error {round(mean_squared_error(y_true,y_pred),2) ** 0.5}')\n    print(f' R2 score {round(r2_score(y_true,y_pred),2)}')\n    return\n    ","2499726c":"train_df = df.drop(columns = ['unit_number','setting_1','setting_2','P15','NRc'])","444c5f89":"# \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u044f \u0438 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043a\u0438 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u043f\u043e \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430\u043c \"Random forest\" \u0438 \"XGBoost\"\n#function for creating and training models using the \"Random forest\" and \"XGBoost\" algorithms\ndef train_models(data,model = 'FOREST'):\n    X = data.iloc[:,:14].to_numpy() \n    Y = data.iloc[:,14:].to_numpy()\n    Y = np.ravel(Y)\n    if model == 'FOREST':\n         # \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0434\u043b\u044f \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u043f\u043e\u0434\u043e\u0431\u0440\u0430\u043d\u044b \u0432 \u043f\u043e\u0434\u043e\u0431\u043d\u043e\u043c \u0446\u0438\u043a\u043b\u0435, \u0441 \u0432\u0432\u0435\u0434\u0435\u043d\u0438\u0435\u043c \u0432 \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430 param:\n         #  parameters for models are selected in a similar cycle, with the introduction \n         # of an additional param parameter into the function:\n         #for i in range(1,11):\n         #     xgb = train_models(train_df,param=i,model=\"XGB\",)\n         #     y_xgb_i_pred = xgb.predict(X_001_test)\n         #     print(f'param = {i}')\n         #     score_func(y_true,y_xgb_i_pred)\n        model = RandomForestRegressor(n_estimators=70, max_features=7, max_depth=5, n_jobs=-1, random_state=1)\n        model.fit(X,Y)\n        return model\n    elif model == 'XGB':\n        model = xgboost.XGBRegressor(n_estimators=110, learning_rate=0.018, gamma=0, subsample=0.8,\n                           colsample_bytree=0.5, max_depth=3,silent=True)\n        model.fit(X,Y)\n        return model\n    return\n    ","df97083f":"# \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u0441\u043e\u0432\u043c\u0435\u0441\u0442\u043d\u043e\u0433\u043e \u043e\u0442\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0445 \u0438 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439\n#function for joint display of real and predicted values\n\ndef plot_result(y_true,y_pred):\n    rcParams['figure.figsize'] = 12,10\n    plt.plot(y_pred)\n    plt.plot(y_true)\n    plt.tick_params(axis='x', which='both', bottom=False, top=False,labelbottom=False)\n    plt.ylabel('RUL')\n    plt.xlabel('training samples')\n    plt.legend(('Predicted', 'True'), loc='upper right')\n    plt.title('\u0421\u0440\u0430\u0432\u043d\u0435\u043d\u0438\u0435 \u0440\u0435\u0430\u043b\u044c\u043d\u044b\u0445 \u0438 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 ')\n    plt.show()\n    return","b0ed63f3":"fd_001_test.drop(columns=['Nf_dmd','PCNfR_dmd','P2','T2','TRA','farB','epr'],inplace=True)","e786a42c":"test_max = fd_001_test.groupby('unit_number')['time_in_cycles'].max().reset_index()\ntest_max.columns = ['unit_number','max']","5bd06823":"fd_001_test = fd_001_test.merge(test_max, on=['unit_number'], how='left')","0534a682":"test = fd_001_test[fd_001_test['time_in_cycles'] == fd_001_test['max']].reset_index()","dd2ba65b":"test.drop(columns=['index','max','unit_number','setting_1','setting_2','P15','NRc'],inplace = True)","50beb8d4":"X_001_test = test.to_numpy()","1ce60498":"X_001_test.shape","d766e082":"model_1 = train_models(train_df)","a6fb3042":"y_pred = model_1.predict(X_001_test)","8c26d48d":"RUL = pd.read_csv(\"\/kaggle\/input\/nasa-cmaps\/CMaps\/RUL_FD001.txt\",sep=\" \",header=None)","7d83701e":"y_true = RUL[0].to_numpy()","387cec5c":"score_func(y_true, y_pred)","a0c5cc83":"plot_result(y_true,y_pred)","6d5c906f":"# \u0434\u043b\u044f \u043e\u0442\u0431\u0440\u0430\u0441\u044b\u0432\u0430\u043d\u0438\u044f \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u0432 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u043e\u043c \u043c\u0430\u0441\u0441\u0438\u0432\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0441\u044f \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 factor \u0432 \n# \u0444\u0443\u043d\u043a\u0446\u0438\u0438 prepare_train_data, \u0432 test_data \u043d\u0430\u0445\u043e\u0434\u044f\u0442\u0441\u044f \u043f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043b\u0435\u043d\u043d\u044b\u0435 \u043a \u0440\u0430\u0441\u043f\u043e\u0437\u043d\u0430\u0432\u0430\u043d\u0438\u044e \u0441\u044d\u043c\u043f\u043b\u044b, \u0432 \u043f\u0435\u0440\u0432\u043e\u043c \u0441\u0442\u043e\u043b\u0431\u0446\u0435 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \n#  - \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u0432 \u0446\u0438\u043a\u043b\u0430\u0445, \u0434\u043b\u044f \u043a\u043e\u0442\u043e\u0440\u043e\u0433\u043e \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u0442\u0441\u044f \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 RUL\n\n# to discard values in the training array, use the factor parameter in\n# prepare_train_data functions, in test_data are samples prepared for recognition, in the first column of which\n# - value of time in cycles for which RUL is predicted\ndef single_train(test_data,train_data,algorithm):\n    y_single_pred = []\n    for sample in tqdm(test_data):\n        time.sleep(0.01)\n        single_train_df = prepare_train_data(train_data, factor = sample[0])\n        single_train_df.drop(columns = ['unit_number','setting_1','setting_2','P15','NRc'],inplace = True)\n        model = train_models(single_train_df,algorithm)\n        y_p = model.predict(sample.reshape(1,-1))[0]\n        y_single_pred.append(y_p)\n    y_single_pred = np.array(y_single_pred)\n    return y_single_pred","79df9297":"y_single_pred = single_train(X_001_test,fd_001_train,'FOREST')","4225342c":"plot_result(y_true,y_single_pred)","6fb3187c":"score_func(y_true, y_single_pred)","dd2efd9c":"def prepare_test_data(fd_001_test,n=0):\n    test = fd_001_test[fd_001_test['time_in_cycles'] == fd_001_test['max'] - n].reset_index()\n    test.drop(columns=['index','max','unit_number','setting_1','setting_2','P15','NRc'],inplace = True)\n    X_return = test.to_numpy()\n    return X_return","7a192d2c":"N=5\ny_n_pred = y_single_pred\nfor i in range(1,N):\n    X_001_test = prepare_test_data(fd_001_test,i)\n    y_single_i_pred = single_train(X_001_test,fd_001_train,'FOREST')    \n    y_n_pred = np.vstack((y_n_pred,y_single_i_pred))  ","113dcb99":"y_multi_pred = np.mean(y_n_pred,axis = 0)","82bb695a":"score_func(y_true,y_multi_pred)","29eb9dcc":"plot_result(y_true,y_multi_pred)","5ecf3bab":"N=10\n#\u0427\u0442\u043e\u0431\u044b \u043f\u043e\u0432\u0442\u043e\u0440\u043d\u043e \u043d\u0435 \u0432\u044b\u0447\u0438\u0441\u043b\u044f\u0442\u044c \u0441\u0440\u0435\u0434\u043d\u0438\u0439 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0434\u043b\u044f 5 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439, \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 y_multi_pred \n# \u0437\u0430\u043d\u043e\u0441\u0438\u0442\u0441\u044f \u0432 y_n_pred, \u0434\u0430\u043b\u0435\u0435 \u0441\u0447\u0438\u0442\u0430\u044e\u0442\u0441\u044f \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0434\u043b\u044f 5,6.... \u0441\u0442\u0440\u043e\u043a\u0438 \u043e\u0442 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0439 \u0434\u043b\u044f \u0434\u0430\u043d\u043d\u043e\u0433\u043e \u0434\u0432\u0438\u0433\u0430\u0442\u0435\u043b\u044f\n\n# In order not to recalculate the average result for 5 predictions, the stored value y_multi_pred\n# is entered in y_n_pred, then the predictions for 5,6,7 .... lines from the last for the given engine\ny_n_pred = y_multi_pred\nfor i in range(5,N):\n    X_001_test = prepare_test_data(fd_001_test,i)\n    y_single_i_pred = single_train(X_001_test,fd_001_train,'FOREST')    \n    y_n_pred = np.vstack((y_n_pred,y_single_i_pred))  ","47355d26":"y_multi_pred_10 = np.mean(y_n_pred,axis = 0)","cc162aec":"score_func(y_true,y_multi_pred_10)","381c2b18":"plot_result(y_true,y_multi_pred_10)","295be42c":"xgb = train_models(train_df,model=\"XGB\")","cadb8d1c":"y_xgb_pred = xgb.predict(X_001_test)","b75205b9":"score_func(y_true,y_xgb_pred)","8c117d89":"plot_result(y_true,y_xgb_pred)","f4613f5d":"y_single_xgb_pred = single_train(X_001_test,fd_001_train,'XGB')","ec94b251":"score_func(y_true,y_single_xgb_pred)","55c2cc9e":"plot_result(y_true,y_single_xgb_pred)","b6059c6a":"N=5\ny_n_pred = y_single_xgb_pred\nfor i in range(1,N):\n    X_001_test = prepare_test_data(fd_001_test,i)\n    y_single_i_pred = single_train(X_001_test,fd_001_train,'XGB')    \n    y_n_pred = np.vstack((y_n_pred,y_single_i_pred)) ","b7e60332":"y_5_pred_xgb = np.mean(y_n_pred,axis = 0)","81f38d60":"score_func(y_true,y_5_pred_xgb)","458e1b5c":"plot_result(y_true,y_5_pred_xgb)","92e90caf":"compare = pd.DataFrame(list(zip(y_true, y_pred, y_single_pred,y_multi_pred,y_multi_pred_10,y_xgb_pred,y_single_xgb_pred)), \n               columns =['True','Forest_Predicted','Forest_Single_predicted','multi_5','multi_10'\n                         ,'XGBoost','XGBoost_single']) \ncompare['unit_number'] = compare.index + 1","b0aef7b9":"compare['Predicted_error'] = compare['True'] - compare['Forest_Predicted']\ncompare['Single_pred_error'] = compare['True'] - compare['Forest_Single_predicted']\ncompare['multi_5_error'] = compare['True'] - compare['multi_5']\ncompare['multi_10_error'] = compare['True'] - compare['multi_10']\ncompare['xgb_error'] = compare['True'] - compare['XGBoost']\ncompare['xgb_single_error'] = compare['True'] - compare['XGBoost_single']\nax1 = compare.plot(subplots=True, sharex=True, figsize=(20,20))","dc40bb4e":"# \u0444\u043e\u0440\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439 label, TTF - \u0432\u0440\u0435\u043c\u044f \u0434\u043e \u043f\u043e\u043b\u043e\u043c\u043a\u0438\nTTF = 10\ntrain_df['label'] = np.where(train_df['RUL'] <= TTF, 1, 0 )","2a1c4b9a":"train_df.head()","c945b0be":"sns.scatterplot(x=\"Nc\", y=\"T50\", hue=\"label\", data=train_df)\nplt.title('\u0414\u0438\u0430\u0433\u0440\u0430\u043c\u043c\u0430 \u0440\u0430\u0441\u0441\u0435\u0438\u0432\u0430\u043d\u0438\u044f T50 \u043e\u0442 Nc')","ee41c816":"#\u0438\u0441\u043a\u043b\u044e\u0447\u0430\u0435\u043c \u0441\u0432\u043e\u0439\u0441\u0442\u0432\u043e RUL \u0438 \u0444\u043e\u0440\u043c\u0438\u0440\u0443\u0435\u043c \u043c\u0430\u0441\u0441\u0438\u0432 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u0438 \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439\n# exclude the RUL property and form an array of attributes and the target variable\nX_class = train_df.iloc[:,:14].to_numpy() \nY_class = train_df.iloc[:,15:].to_numpy()\nY_class = np.ravel(Y_class)","48444a67":"# \u0411\u0430\u043b\u0430\u043d\u0441\u0438\u0440\u043e\u0432\u043a\u0430 \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0434\u043b\u044f \u0443\u043b\u0443\u0447\u0448\u0435\u043d\u0438\u044f \u0440\u0430\u0431\u043e\u0442\u044b \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440\u0430\n\n# Class balancing to improve classifier performance\nfrom imblearn.over_sampling import RandomOverSampler\n#from imblearn.under_sampling import RandomUnderSampler\nros = RandomOverSampler(random_state=0)\nros.fit(X_class, Y_class)\nX_resampled, y_resampled = ros.fit_sample(X_class, Y_class)\nprint('\u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u043e\u0432 \u0434\u043e \u043e\u043f\u0435\u0440\u0430\u0446\u0438\u0438:', len(X_class))\nprint('\u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u043e\u0432 \u043f\u043e\u0441\u043b\u0435 \u043e\u043f\u0435\u0440\u0430\u0446\u0438\u0438:', len(X_resampled))","24e3e9e8":"# \u0417\u0434\u0435\u0441\u044c \u0434\u0435\u043b\u0438\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u043d\u0430 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0443 \u0438 \u0442\u0435\u0441\u0442\u043e\u0432\u0443\u044e , test_size = 0.2 \u0437\u0430\u0434\u0430\u0435\u0442 \u0434\u043e\u043b\u044e \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438 = 20%\n\n#\n# Here we divide the data into the training sample and the test one, \n#test_size = 0.2 sets the proportion of the test sample = 20%\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X_resampled,y_resampled,test_size = 0.2,random_state = 3)","521131a1":"from sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier","d184cbd5":"forest = RandomForestClassifier(n_estimators=70 ,max_depth = 8, random_state=193)\nforest.fit(X_train,y_train)","80d27b8c":"model_xgb = XGBClassifier()\nmodel_xgb.fit(X_train, y_train)","c1063b9d":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score","18087895":"def classificator_score(y_,y_p):\n    print(f' accuracy score {round(accuracy_score(y_, y_p),2)}')\n    print(f' precision score {round(precision_score(y_, y_p),2)}')\n    print(f' recall score {round(recall_score(y_, y_p),2)}')\n    print(f' F1 score {round(f1_score(y_, y_p),2)}')\n    return","e40a34e6":"classificator_score(y_test,forest.predict(X_test))","56a30ebe":"y_xgb_pred = model_xgb.predict(X_001_test)\nclassificator_score(y_test,model_xgb.predict(X_test))","b7d22532":"test.head()","1833ce28":"X_001_test = test.to_numpy()","24aa0d60":"# \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u0434\u043b\u044f X_001_test, \u0432\u0440\u0435\u043c\u044f \u0434\u043e \u043f\u043e\u043b\u043e\u043c\u043a\u0438 = TTF =10\npredicted = pd.DataFrame()\npredicted ['forest'] =  forest.predict(X_001_test)\npredicted['XGB'] = y_xgb_pred\npredicted['RUL']=RUL[0]\npredicted['true_label'] = np.where(y_true <= TTF, 1, 0 )\npredicted['unit_number'] = predicted.index + 1","a4ba88ba":"predicted.head()","0c694c77":"# \u0438\u0441\u0442\u0438\u043d\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f TTF <= 10\npredicted[predicted['true_label'] == 1]","b678caed":"# \u0434\u0432\u0438\u0433\u0430\u0442\u0435\u043b\u0438, \u0434\u043b\u044f \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 RandomForest \u0434\u0430\u043b \u043d\u0435\u0432\u0435\u0440\u043d\u044b\u0435 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f\n# engines for which the RandomForest classification algorithm gave incorrect predictions\npredicted[predicted['true_label'] != predicted['forest']]","902a6e9d":"# \u0434\u0432\u0438\u0433\u0430\u0442\u0435\u043b\u0438, \u0434\u043b\u044f \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 XGBoost \u0434\u0430\u043b \u043d\u0435\u0432\u0435\u0440\u043d\u044b\u0435 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f\n# engines for which the XGBoost classification algorithm gave incorrect predictions\npredicted[predicted['true_label'] != predicted['XGB']]","e69ff723":"y_true_class = np.where(y_true <= TTF, 1, 0 )\ny_pred_class = predicted['forest'].tolist()","06baa3e9":"def expected_profit(y_true,y_pred):\n    TP=0\n    FP=0\n    TN=0\n    FN=0\n    for i in range(len(y_true)):\n        if (y_true[i] != y_pred[i]) & (y_pred[i] == 1):\n            FP += 1\n        elif (y_true[i] != y_pred[i]) & (y_pred[i] == 0):\n            FN += 1\n        elif (y_true[i] == y_pred[i]) & (y_pred[i] == 0):\n            TN += 1\n        else:\n            TP += 1\n    print(f'TP ={TP}, TN = {TN}, FP = {FP}, FN = {FN}')\n    print (f'\u043e\u0436\u0438\u0434\u0430\u0435\u043c\u0430\u044f \u043f\u0440\u0438\u0431\u044b\u043b\u044c {(300 * TP - 200 * FN - 100 * FP) * 1000}')\n    return \n        ","d623d83d":"expected_profit(y_true_class,y_pred_class)","973df424":"expected_profit(y_true_class,y_xgb_pred)","1223242f":"Errors in all algorithms are strongly correlated, to further improve the forecasts of the algorithm, pre-processing of training and possibly test data is necessary to eliminate outliers","413ab66a":"Prediction of the final result for all engines","5f17e47c":"Display the results.","16d8c6c5":"## \u041f\u043e\u0441\u0447\u0438\u0442\u0430\u0435\u043c \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u0434\u0432\u0438\u0433\u0430\u0442\u0435\u043b\u044f","94b1868a":"## \u0414\u043b\u044f \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u044f \u043f\u0440\u0430\u043a\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0439 \u0446\u0435\u043d\u043d\u043e\u0441\u0442\u0438 \u043e\u0442 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u044b \u0431\u0438\u043d\u0430\u0440\u043d\u043e\u0439 \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 \u0434\u043b\u044f \u043f\u043b\u0430\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f \u0442\u0435\u0445\u043d\u0438\u0447\u0435\u0441\u043a\u043e\u0433\u043e \u043e\u0431\u0441\u043b\u0443\u0436\u0438\u0432\u0430\u043d\u0438\u044f ,\u043f\u043e\u0441\u0447\u0438\u0442\u0430\u0435\u043c \u043a\u0430\u043a\u0443\u044e \u043f\u0440\u0438\u0431\u044b\u043b\u044c (\u0438\u043b\u0438 \u0443\u0431\u044b\u0442\u043e\u043a) \u043c\u043e\u0436\u0435\u0442 \u043f\u0440\u0438\u043d\u0435\u0441\u0442\u0438 \u0430\u043d\u0430\u043b\u0438\u0437 \u0438 \u043f\u043b\u0430\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0422\u041e \u0434\u043b\u044f \u0433\u0438\u043f\u043e\u0442\u0435\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0439 \u0430\u0432\u0438\u0430\u043a\u043e\u043c\u043f\u0430\u043d\u0438\u0438\nhttps:\/\/github.com\/Samimust\/predictive-maintenance\/blob\/master\/Model%20Selection%20-%20Binary%20Classifiaction.ipynb","aa295f5c":"## \u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0443\u043b\u0443\u0447\u0448\u0438\u0442\u044c \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432, \u0434\u043b\u044f \u044d\u0442\u043e\u0433\u043e \u0431\u0443\u0434\u0435\u043c \u043e\u0431\u0443\u0447\u0430\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c \u043a\u0430\u0436\u0434\u044b\u0439 \u0440\u0430\u0437 \u0437\u0430\u043d\u043e\u0432\u043e \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f, \u043e\u0442\u0431\u0440\u0430\u0441\u044b\u0432\u0430\u044f \u0432 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u043e\u043c \u043c\u0430\u0441\u0441\u0438\u0432\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043f\u043e \u0432\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439 \u0448\u043a\u0430\u043b\u0435 (\u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f time_in_cycles) \u043c\u0435\u043d\u044c\u0448\u0438\u0435, \u0447\u0435\u043c \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0432 \u043c\u0430\u0441\u0441\u0438\u0432\u0435 fd_001_test, \u0442\u043e \u0435\u0441\u0442\u044c \u043c\u0435\u043d\u044c\u0448\u0438\u0435 \u0442\u043e\u0433\u043e \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0434\u043b\u044f \u043a\u043e\u0442\u043e\u0440\u043e\u0433\u043e \u043d\u0443\u0436\u043d\u043e \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u0442\u044c RUL (remaining useful life)","bb2394ea":"## \u0423\u0434\u0430\u043b\u0438\u043c \u0441\u0432\u043e\u0439\u0441\u0442\u0432\u0430, \u0441\u043b\u0430\u0431\u043e \u043a\u043e\u0440\u0440\u0435\u043b\u0438\u0440\u0443\u044e\u0449\u0438\u0435 \u0441 \u0446\u0435\u043b\u0435\u0432\u044b\u043c \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0435\u043c RUL: setting_1, setting_2, P15, unit_number, \u0430 \u0442\u0430\u043a\u0436\u0435 \u043e\u0434\u0438\u043d \u0438\u0437 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432, \u0432 \u0441\u0438\u043b\u044c\u043d\u043e \u043a\u043e\u0440\u0440\u0435\u043b\u0438\u0440\u0443\u044e\u0449\u0438\u0445 \u043c\u0435\u0436\u0434\u0443 \u0441\u043e\u0431\u043e\u0439 (Nc \u0438 NRc \u0438\u043c\u0435\u044e\u0442 \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442 \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u0438 0.96, \u0443\u0434\u0430\u043b\u0438\u043c NRc)\n","478138a3":"##   \u041c\u043e\u0434\u0438\u0444\u0438\u0446\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u043c \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u043c \u0441 \u0438\u043d\u0434\u0438\u0432\u0438\u0434\u0443\u0430\u043b\u044c\u043d\u044b\u043c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\u043c \u0438 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435\u043c \u0443\u0434\u0430\u043b\u043e\u0441\u044c \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u043e \u0441\u043d\u0438\u0437\u0438\u0442\u044c MAE \u0438 \u043f\u043e\u0432\u044b\u0441\u0438\u0442\u044c R2 score","7915f386":"## \u041e\u0448\u0438\u0431\u043a\u0438 \u0432\u043e \u0432\u0441\u0435\u0445 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430\u0445 \u0441\u0438\u043b\u044c\u043d\u043e \u043a\u043e\u0440\u0440\u0435\u043b\u0438\u0440\u0443\u044e\u0442, \u0434\u043b\u044f \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0435\u0433\u043e \u0443\u043b\u0443\u0447\u0448\u0435\u043d\u0438\u044f \u043f\u0440\u043e\u0433\u043d\u043e\u0437\u043e\u0432 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430, \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e \u043d\u0443\u0436\u043d\u0430 \u043f\u0440\u0435\u0434\u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0445 \u0438,  \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u0438\u0441\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u044f \u0432\u044b\u0431\u0440\u043e\u0441\u043e\u0432","5ce9d097":"## \u041f\u043e \u043c\u0435\u0442\u0440\u0438\u043a\u0430\u043c \u043e\u0446\u0435\u043d\u043a\u0438 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u0432 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0445\u0443\u0436\u0435, \u0447\u0435\u043c \u0434\u043b\u044f \"\u0441\u043b\u0443\u0447\u0430\u0439\u043d\u043e\u0433\u043e \u043b\u0435\u0441\u0430\"\n\u041c\u0435\u0442\u0440\u0438\u043a\u0438 \u0434\u043b\u044f RandomForestRegressor\n\n\u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0439 \u0441\u0447\u0435\u0442 1057.2\n\n mean absolute error 19.25\n \n root mean squared error 24.45219826518671\n \n R2 score 0.65","11902a5d":"## \u041e\u0442\u043e\u0431\u0440\u0430\u0437\u0438\u043c \u0434\u0438\u0430\u0433\u0440\u0430\u043c\u043c\u0443 \u0440\u0430\u0441\u0441\u0435\u0438\u0432\u0430\u043d\u0438\u044f \u0434\u0432\u0443\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0441 \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u0435\u043c \u043f\u043e \u0446\u0435\u043b\u0435\u0432\u043e\u043c\u0443 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0443","48b70e66":"## \u0410\u043d\u0430\u043b\u043e\u0433\u0438\u0447\u043d\u043e, \u0432\u0441\u0435 \u043c\u0435\u0442\u0440\u0438\u043a\u0438, \u043a\u0440\u043e\u043c\u0435 \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0439 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u043e\u0448\u0438\u0431\u043a\u0438 (\u043f\u043e \u0441\u0440\u0430\u0432\u043d\u0435\u043d\u0438\u044e \u0441 \u0441\u043e\u0432\u043c\u0435\u0441\u0442\u043d\u044b\u043c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435\u043c)  \u0443\u043b\u0443\u0447\u0448\u0438\u043b\u0438 \u0441\u0432\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435","0079c1a2":"Competitive score, the average absolute error, the root mean square error and the coefficient of determination of the resulting model:","6137e9b9":"To obtain practical value from the data, we use binary classification algorithms for maintenance planning, calculate what profit (or loss) analysis and maintenance planning can bring for a hypothetical airline\n\nhttps:\/\/github.com\/Samimust\/predictive-maintenance\/blob\/master\/Model%20Selection%20-%20Binary%20Classifiaction.ipynb","902ed027":"we will form a generalized table for predicted and correct values","706d7a33":"\nLet's create a classifier that will answer the question: \"Current engine resource more or less than 10 cycles\"? It is assumed that this is sufficient time to prepare and start maintenance.","930c2bcb":"##  \u041e\u0431\u0443\u0447\u0438\u043c \u043c\u043e\u0434\u0435\u043b\u044c \u043d\u0430 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0431\u0435\u0437 \u0443\u0434\u0430\u043b\u0435\u043d\u043d\u044b\u0445 \u0441\u0432\u043e\u0439\u0441\u0442\u0432 'unit_number','setting_1','setting_2','P15','NRc'","97ad31f3":"According to regression algorithm estimation metrics, the result is worse than for a \"random forest\"\nMetrics for RandomForestRegressor\n\nCompetitive Score 1057.2\n\n mean absolute error 19.25\n \n root mean squared error 24.45219826518671\n \n R2 score 0.65","a4ffd250":"## Error Function for Competitive Data","a86da2ef":"## \u0441\u0444\u043e\u0440\u043c\u0438\u0440\u0443\u0435\u043c \u043e\u0431\u043e\u0431\u0449\u0435\u043d\u043d\u0443\u044e \u0442\u0430\u0431\u043b\u0438\u0446\u0443 \u0434\u043b\u044f \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u0445 \u0438 \u0432\u0435\u0440\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439","6dea0344":"## \u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u0438\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438","18a6e05a":"\nWe display the results for an average of 10 predictions","a781f8c1":"## Conclusion: the proposed classification algorithms show useful results on test data and can be used to obtain cost savings during preventive maintenance of aircraft engines, to estimate the approximate remaining engine life (if the corresponding error is permissible under specific conditions) it can be used in conjunction with the regression algorithms described above","8339ec1a":"\u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u044f \u043e\u0436\u0438\u0434\u0430\u0435\u043c\u043e\u0439 \u043f\u0440\u0438\u0431\u044b\u043b\u0438, \u043a\u0430\u043a \u043e\u043f\u0438\u0441\u0430\u043d\u043e \u0432\u044b\u0448\u0435","9ec01fef":"## \u041e\u0442\u043e\u0431\u0440\u0430\u0437\u0438\u043c \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0434\u043b\u044f \u0441\u0440\u0435\u0434\u043d\u0435\u0433\u043e \u0438\u0437 10 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439","ca5ee6f3":"## \u0421\u0440\u0430\u0432\u043d\u0438\u043c \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0441 \u0435\u0449\u0435 \u043e\u0434\u043d\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u044c\u044e - XGBoost","7d9b554c":"formation of the target variable label, TTF - time to failure","c85ec61b":"Similarly, all metrics, except for the competitive error function (compared to the joint prediction) have improved their value","fe1ca84b":"## We will display the mutual correlations of the signs on the \"heat map\", for this we will prepare an additional sign \"RUL\", showing the number of cycles to failure in the training data","9b89d512":"We calculate the average value of predictions for each engine","21eb2d10":"\nWe display the scattering diagram of two parameters with a separation according to the target attribute","0a0102fb":"## \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u0438\u0442\u043e\u0433\u043e\u0432\u043e\u0433\u043e \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0430 \u0434\u043b\u044f \u0432\u0441\u0435\u0445 \u0434\u0432\u0438\u0433\u0430\u0442\u0435\u043b\u0435\u0439","8e891939":"## \u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u0438\u043c \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438\n\u043d\u0443\u0436\u043d\u044b \u0442\u043e\u043b\u044c\u043a\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0432\u0448\u0438\u0435\u0441\u044f \u043f\u0440\u0438 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043a\u0435 features \u0438 \u0441\u0442\u0440\u043e\u043a\u0430 \u0441 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u043c \u0434\u043b\u044f \u044d\u0442\u043e\u0433\u043e \u0434\u0432\u0438\u0433\u0430\u0442\u0435\u043b\u044f \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435\u043c time_in_cycles (\u043f\u043e\u0441\u043b\u0435\u0434\u043d\u044f\u044f)","4cdf7ca4":"\nLet\u2019s try to improve the algorithm for predicting the results, for this we will train the model each time again for each individual prediction, discarding in the training array the values \u200b\u200bon the timeline (time_in_cycles) are smaller than the last value in the fd_001_test array, that is, lower than the value for which RUL should be predicted (remaining useful life)","b58dd3e4":"## \u0421\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0431\u0443\u0434\u0435\u0442 \u043e\u0442\u0432\u0435\u0447\u0430\u0442\u044c \u043d\u0430 \u0432\u043e\u043f\u0440\u043e\u0441: \"\u0422\u0435\u043a\u0443\u0449\u0438\u0439 \u0440\u0435\u0441\u0443\u0440\u0441 \u0434\u0432\u0438\u0433\u0430\u0442\u0435\u043b\u044f \u0431\u043e\u043b\u044c\u0448\u0435 \u0438\u043b\u0438 \u043c\u0435\u043d\u044c\u0448\u0435 10 \u0446\u0438\u043a\u043b\u043e\u0432\" ? \u041f\u0440\u0435\u0434\u043f\u043e\u043b\u0430\u0433\u0430\u0435\u0442\u0441\u044f, \u0447\u0442\u043e \u044d\u0442\u043e \u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e\u0435 \u0432\u0440\u0435\u043c\u044f \u0434\u043b\u044f \u043f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0438 \u0438 \u043d\u0430\u0447\u0430\u043b\u0430 \u0442\u0435\u0445\u043d\u0438\u0447\u0435\u0441\u043a\u043e\u0433\u043e \u043e\u0431\u0441\u043b\u0443\u0436\u0438\u0432\u0430\u043d\u0438\u044f.","e2b5080f":"Metrics for RandomForestClassifier","ed54cac2":"Since the sensor data is very noisy, we will try the following approach to improve the prediction: we will make predictions based on not one (last) \u201cslice\u201d of the sensor values, as was done above, but some optimized (for example, by determination coefficient or mean absolute error) number of previous breaking values. To display the final value of RUL, we use the average value of all predictions","4516f8bc":"## \u041e\u0436\u0438\u0434\u0430\u0435\u043c\u0430\u044f \u043f\u0440\u0438\u0431\u044b\u043b\u044c \u0434\u043b\u044f Random Forest \u043e\u043a\u0430\u0437\u0430\u043b\u0430\u0441\u044c \u0432\u044b\u0448\u0435\n","3f79daf5":"## \u041e\u0442\u043e\u0431\u0440\u0430\u0437\u0438\u043c \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b","d8d8fd50":"## We remove the properties that weakly correlate with the RUL target: setting_1, setting_2, P15, unit_number, as well as one of the features that are highly correlated with each other (Nc and NRc have a correlation coefficient of 0.96, remove NRc)","a79f09c9":"## \u0422\u0430\u043a \u043a\u0430\u043a \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u0430\u0442\u0447\u0438\u043a\u043e\u0432 \u0441\u0438\u043b\u044c\u043d\u043e \u0437\u0430\u0448\u0443\u043c\u043b\u0435\u043d\u044b, \u0434\u043b\u044f \u0443\u043b\u0443\u0447\u0448\u0435\u043d\u0438\u044f \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0439 \u043f\u043e\u0434\u0445\u043e\u0434: \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0431\u0443\u0434\u0435\u043c \u0434\u0435\u043b\u0430\u0442\u044c \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u043d\u0435 \u043e\u0434\u043d\u043e\u0433\u043e (\u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u0433\u043e) \"\u0441\u0440\u0435\u0437\u0430\" \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u0434\u0430\u0442\u0447\u0438\u043a\u043e\u0432, \u043a\u0430\u043a \u044d\u0442\u043e \u0434\u0435\u043b\u0430\u043b\u043e\u0441\u044c \u0432\u044b\u0448\u0435, \u0430 \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u043e\u0433\u043e \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u0443\u0435\u043c\u043e\u0433\u043e (\u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440 \u043f\u043e \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442\u0443 \u0434\u0435\u0442\u0435\u0440\u043c\u0438\u043d\u0430\u0446\u0438\u0438 \u0438\u043b\u0438 \u0441\u0440\u0435\u0434\u043d\u0435\u0439 \u0430\u0431\u0441\u043e\u043b\u044e\u0442\u043d\u043e\u0439 \u043e\u0448\u0438\u0431\u043a\u0438) \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u043f\u0440\u0435\u0434\u0448\u0435\u0441\u0442\u0432\u0443\u044e\u0449\u0438\u0445 \u043f\u043e\u043b\u043e\u043c\u043a\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439. \u0414\u043b\u044f \u0432\u044b\u0432\u043e\u0434\u0430 \u0438\u0442\u043e\u0433\u043e\u0432\u043e\u0433\u043e \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f RUL \u0432\u043e\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c\u0441\u044f \u0441\u0440\u0435\u0434\u043d\u0438\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435\u043c \u0432\u0441\u0435\u0445 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439","37715dcc":"Compare the results with another model - XGBoost","bfc35b36":"\n## Competitive score, average absolute error and coefficient of determination of the improved model","311785e8":"## \u0421\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0439 \u0441\u0447\u0435\u0442, \u0441\u0440\u0435\u0434\u043d\u044f\u044f \u0430\u0431\u0441\u043e\u043b\u044e\u0442\u043d\u0430\u044f \u043e\u0448\u0438\u0431\u043a\u0430 \u0438 \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442 \u0434\u0435\u0442\u0435\u0440\u043c\u0438\u043d\u0430\u0446\u0438\u0438 \u0443\u043b\u0443\u0447\u0448\u0435\u043d\u043d\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438","69d333b2":"## \u041e\u0447\u0435\u0432\u0438\u0434\u043d\u043e, \u0447\u0442\u043e \u0441 \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0438\u043c \u0440\u043e\u0441\u0442\u043e\u043c \u0447\u0438\u0441\u043b\u0430 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439 \u0434\u043b\u044f \u0432\u044b\u0432\u043e\u0434\u0430 \u0441\u0440\u0435\u0434\u043d\u0435\u0433\u043e \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u043e\u0442\u0432\u0435\u0442\u043e\u0432 \u043c\u043e\u0434\u0435\u043b\u0438 \u043d\u0435 \u0443\u043b\u0443\u0447\u0448\u0430\u0435\u0442\u0441\u044f, \u0432 \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0435\u043c \u0432 \u0440\u0430\u0431\u043e\u0442\u0435 \u0431\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c y_multi_pred (\u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u0438\u0437 5 \u0438\u043d\u0434\u0438\u0432\u0438\u0434\u0443\u0430\u043b\u044c\u043d\u044b\u0445 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439)","a1396fb6":"## \u0418\u043d\u0434\u0438\u0432\u0438\u0434\u0443\u0430\u043b\u044c\u043d\u044b\u0435 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u0434\u043b\u044f XGBoost:","f17a678e":"## \u041c\u0435\u0442\u0440\u0438\u043a\u0438 \u0434\u043b\u044f RandomForestClassifier","6fc92e17":"\nLet's train the model on training data without the deleted properties 'unit_number', 'setting_1', 'setting_2', 'P15', 'NRc'","68a30471":"## \u0412\u044b\u0432\u043e\u0434: \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d\u043d\u044b\u0435 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u044b \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u044e\u0442 \u043f\u043e\u043b\u0435\u0437\u043d\u044b\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438 \u043c\u043e\u0433\u0443\u0442 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c\u0441\u044f \u0434\u043b\u044f \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u044f \u044d\u043a\u043e\u043d\u043e\u043c\u0438\u0438 \u0441\u0440\u0435\u0434\u0441\u0442\u0432 \u043f\u0440\u0438 \u043f\u0440\u043e\u0432\u0435\u0434\u0435\u043d\u0438\u0438 \u043f\u0440\u0435\u0434\u0443\u043f\u0440\u0435\u0434\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u0440\u0435\u043c\u043e\u043d\u0442\u0430 \u0430\u0432\u0438\u0430\u0434\u0432\u0438\u0433\u0430\u0442\u0435\u043b\u0435\u0439, \u0434\u043b\u044f \u043e\u0446\u0435\u043d\u043a\u0438 \u043f\u0440\u0438\u043c\u0435\u0440\u043d\u043e\u0433\u043e \u043e\u0441\u0442\u0430\u0432\u0448\u0435\u0433\u043e\u0441\u044f \u0440\u0435\u0441\u0443\u0440\u0441\u0430 \u0434\u0432\u0438\u0433\u0430\u0442\u0435\u043b\u044f (\u0435\u0441\u043b\u0438 \u0432 \u043a\u043e\u043d\u043a\u0440\u0435\u0442\u043d\u044b\u0445 \u0443\u0441\u043b\u043e\u0432\u0438\u044f\u0445 \u0434\u043e\u043f\u0443\u0441\u0442\u0438\u043c\u0430 \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0430\u044f \u043f\u043e\u0433\u0440\u0435\u0448\u043d\u043e\u0441\u0442\u044c) \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e \u0435\u0433\u043e \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u0435 \u0441\u043e\u0432\u043c\u0435\u0441\u0442\u043d\u043e \u0441 \u043e\u043f\u0438\u0441\u0430\u043d\u043d\u044b\u043c\u0438 \u0432\u044b\u0448\u0435 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u0430\u043c\u0438 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438","a7daddb7":"Prepare test data for classification\nonly the features used in the training are needed and a line with the maximum value for this engine time_in_cycles (last)","dbd19dfb":"The expected profit for Random Forest is higher.","7cf5742d":"Individual predictions for XGBoost:","9c20f5f6":"## \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u043e\u0448\u0438\u0431\u043a\u0438 \u0434\u043b\u044f \u0441\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445","1d2ad5c4":"We display the results for the average of 5 predictions","58e77ca6":"Function for calculating expected profits as described above","68cfca30":"Obviously, with a further increase in the number of predictions for deriving the average, the quality of the model\u2019s answers does not improve, in the future we will use y_multi_pred (the average of 5 individual predictions)","64c8623b":"## \u041e\u0442\u043e\u0431\u0440\u0430\u0437\u0438\u043c \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0434\u043b\u044f \u0441\u0440\u0435\u0434\u043d\u0435\u0433\u043e \u0438\u0437 5 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439","4c3c1ec2":"## \u0421\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0439 \u0441\u0447\u0435\u0442, \u0441\u0440\u0435\u0434\u043d\u044f\u044f \u0430\u0431\u0441\u043e\u043b\u044e\u0442\u043d\u0430\u044f \u043e\u0448\u0438\u0431\u043a\u0430, \u043a\u043e\u0440\u0435\u043d\u044c \u0441\u0440\u0435\u0434\u043d\u0435\u043a\u0432\u0430\u0434\u0440\u0430\u0442\u0438\u0447\u043d\u043e\u0439 \u043e\u0448\u0438\u0431\u043a\u0438 \u0438 \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442 \u0434\u0435\u0442\u0435\u0440\u043c\u0438\u043d\u0430\u0446\u0438\u0438 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438:","632a880f":"Using a modified algorithm with individual training and prediction, it was possible to significantly reduce the MAE and increase the R2 score","8f3823dd":"## \u041c\u0435\u0442\u0440\u0438\u043a\u0438 \u0434\u043b\u044f XGBClassifier","a8db69a0":"## \u041e\u0442\u043e\u0431\u0440\u0430\u0437\u0438\u043c \u0432\u0437\u0430\u0438\u043c\u043d\u044b\u0435 \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u0438 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u043d\u0430 \"\u0442\u0435\u043f\u043b\u043e\u0432\u043e\u0439 \u043a\u0430\u0440\u0442\u0435\", \u0434\u043b\u044f \u044d\u0442\u043e\u0433\u043e \u043f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u0438\u043c \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0439 \u043f\u0440\u0438\u0437\u043d\u0430\u043a \"RUL\", \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u044e\u0449\u0438\u0439 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0446\u0438\u043a\u043b\u043e\u0432 \u0434\u043e \u043e\u0442\u043a\u0430\u0437\u0430 \u0432 \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445","4a160d11":"## Expected Value Calculation:\nBased on the book: Data Science for Business, https:\/\/www.amazon.com\/Data-Science-Business-Data-Analytic-Thinking\/dp\/1449361323 . Expected Value is a method to compare different classification models by constructing cost-benefit matrix in line with the confusion matrix, and then convert model performance to a single monetary value by multiplying confusion matrix into the cost-benefit matrix.\n\nCost-benefit matrix should be designed by domain expert. Let us assume the following:\n\nTrue Positive (TP) has benefit of USD 300K: engines that need maintenance and correctly selected by the model.\n\nTrue Negative (TN) has benefit of USD 0K: engines that are OK and not selected by the model.\n\nFalse Positive (FP) has cost of USD -100K: engines that are OK but selected by the model.\n\nFalse Negative (FN) has cost of USD -200K: engines that need maintenance but not selected by the model."}}