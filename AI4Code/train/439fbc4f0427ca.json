{"cell_type":{"64391fd7":"code","d73c070f":"code","7a4bd50e":"code","86c55271":"code","23ab7a51":"code","73f6672a":"code","46563377":"code","ad4a9474":"code","f38c02ad":"code","e49384f4":"code","1430c2bb":"code","e35dd184":"code","89599f4e":"code","680470a4":"code","7ed41a08":"code","bd2375ab":"code","9af3b58f":"code","03bd36c1":"code","70a2b3a9":"code","bf7035aa":"code","28caffc6":"code","1bb309da":"code","87eee38d":"code","2cafa190":"code","fd21a92f":"code","ba567bbc":"code","4dfee277":"code","e8d0df92":"code","53d07666":"code","ee848480":"code","a670a07b":"code","d6939dfb":"code","b5a972ee":"code","bbf4a626":"code","833cfdaf":"code","ea9f5693":"code","d4462692":"code","5b220f07":"code","935c613d":"code","c5e1d638":"code","472dfdc0":"code","46a39b2f":"code","7d02c39e":"code","a95712f2":"code","b348b637":"code","b8e8c4d7":"code","9777a83b":"code","4ac89c19":"code","25f7e1b8":"code","0b43160d":"code","5a3e40b3":"code","9f895a92":"code","afa08036":"code","9215574e":"code","5309dd92":"code","f3ceb76b":"code","ae1465f3":"code","37ae1e2d":"code","f213affd":"code","72a4ec3d":"markdown","0010f121":"markdown","7e8dc2e3":"markdown","49d98205":"markdown","e578873b":"markdown","bf66077c":"markdown","09d776fb":"markdown","f6f98980":"markdown","12f44c4e":"markdown"},"source":{"64391fd7":"from pyspark.sql import SparkSession\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql.functions import mean,col,split, col, regexp_extract, when, lit\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.feature import QuantileDiscretizer","d73c070f":"spark = SparkSession \\\n    .builder \\\n    .appName(\"Spark ML example on titanic data \") \\\n    .getOrCreate()","7a4bd50e":"titanic_df = spark.read.csv('..\/input\/train.csv',header = 'True',inferSchema='True')","86c55271":"display(titanic_df)","23ab7a51":"titanic_df.printSchema()","73f6672a":"passengers_count = titanic_df.count()","46563377":"print(passengers_count)","ad4a9474":"titanic_df.show(5)","f38c02ad":"titanic_df.describe().show()","e49384f4":"titanic_df.printSchema()","1430c2bb":"titanic_df.select(\"Survived\",\"Pclass\",\"Embarked\").show()","e35dd184":"titanic_df.groupBy(\"Survived\").count().show()","89599f4e":"gropuBy_output = titanic_df.groupBy(\"Survived\").count()","680470a4":"display(gropuBy_output)","7ed41a08":"titanic_df.groupBy(\"Sex\",\"Survived\").count().show()","bd2375ab":"titanic_df.groupBy(\"Pclass\",\"Survived\").count().show()","9af3b58f":"# This function use to print feature with null values and null count \ndef null_value_count(df):\n  null_columns_counts = []\n  numRows = df.count()\n  for k in df.columns:\n    nullRows = df.where(col(k).isNull()).count()\n    if(nullRows > 0):\n      temp = k,nullRows\n      null_columns_counts.append(temp)\n  return(null_columns_counts)","03bd36c1":"null_columns_count_list = null_value_count(titanic_df)","70a2b3a9":"spark.createDataFrame(null_columns_count_list, ['Column_With_Null_Value', 'Null_Values_Count']).show()","bf7035aa":"mean_age = titanic_df.select(mean('Age')).collect()[0][0]\nprint(mean_age)","28caffc6":"titanic_df.select(\"Name\").show()","1bb309da":"titanic_df = titanic_df.withColumn(\"Initial\",regexp_extract(col(\"Name\"),\"([A-Za-z]+)\\.\",1))","87eee38d":"titanic_df.show()","2cafa190":"titanic_df.select(\"Initial\").distinct().show()","fd21a92f":"# Replacing initials with Mr, Miss, Mrs, etc\ntitanic_df = titanic_df.replace(['Mlle','Mme', 'Ms', 'Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],\n               ['Miss','Miss','Miss','Mr','Mr',  'Mrs',  'Mrs',  'Other',  'Other','Other','Mr','Mr','Mr'])","ba567bbc":"titanic_df.select(\"Initial\").distinct().show()","4dfee277":"titanic_df.groupby('Initial').avg('Age').collect()","e8d0df92":"titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Miss\") & (titanic_df[\"Age\"].isNull()), 22).otherwise(titanic_df[\"Age\"]))\ntitanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Other\") & (titanic_df[\"Age\"].isNull()), 46).otherwise(titanic_df[\"Age\"]))\ntitanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Master\") & (titanic_df[\"Age\"].isNull()), 5).otherwise(titanic_df[\"Age\"]))\ntitanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Mr\") & (titanic_df[\"Age\"].isNull()), 33).otherwise(titanic_df[\"Age\"]))\ntitanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Mrs\") & (titanic_df[\"Age\"].isNull()), 36).otherwise(titanic_df[\"Age\"]))","53d07666":"titanic_df.filter(titanic_df.Age==46).select(\"Initial\").show()","ee848480":"titanic_df.select(\"Age\").show()","a670a07b":"titanic_df.groupBy(\"Embarked\").count().show()","d6939dfb":"titanic_df = titanic_df.na.fill({\"Embarked\" : 'S'})","b5a972ee":"titanic_df = titanic_df.drop(\"Cabin\")","bbf4a626":"titanic_df.printSchema()","833cfdaf":"titanic_df = titanic_df.withColumn(\"Family_Size\",col('SibSp')+col('Parch'))","ea9f5693":"titanic_df.groupBy(\"Family_Size\").count().show()","d4462692":"titanic_df = titanic_df.withColumn('Alone',lit(0))","5b220f07":"titanic_df = titanic_df.withColumn(\"Alone\",when(titanic_df[\"Family_Size\"] == 0, 1).otherwise(titanic_df[\"Alone\"]))","935c613d":"titanic_df.columns","c5e1d638":"indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(titanic_df) for column in [\"Sex\",\"Embarked\",\"Initial\"]]\npipeline = Pipeline(stages=indexers)\ntitanic_df = pipeline.fit(titanic_df).transform(titanic_df)","472dfdc0":"titanic_df.show()","46a39b2f":"titanic_df.printSchema()","7d02c39e":"titanic_df = titanic_df.drop(\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\",\"Embarked\",\"Sex\",\"Initial\")  # drop columns which are not required","a95712f2":"titanic_df.show()","b348b637":"feature = VectorAssembler(inputCols=titanic_df.columns[1:],outputCol=\"features\")   #vectorizing remaining features\nfeature_vector= feature.transform(titanic_df)","b8e8c4d7":"feature_vector.show()","9777a83b":"(trainingData, testData) = feature_vector.randomSplit([0.8, 0.2],seed = 11)   #train, test split","4ac89c19":"from pyspark.ml.classification import LogisticRegression\nlr = LogisticRegression(labelCol=\"Survived\", featuresCol=\"features\")\n#Training algo\nlrModel = lr.fit(trainingData)\nlr_prediction = lrModel.transform(testData)\nlr_prediction.select(\"prediction\", \"Survived\", \"features\").show()\nevaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")","25f7e1b8":"lr_accuracy = evaluator.evaluate(lr_prediction)\nprint(\"Accuracy of LogisticRegression is = %g\"% (lr_accuracy))\nprint(\"Test Error of LogisticRegression = %g \" % (1.0 - lr_accuracy))","0b43160d":"from pyspark.ml.classification import DecisionTreeClassifier\ndt = DecisionTreeClassifier(labelCol=\"Survived\", featuresCol=\"features\")\ndt_model = dt.fit(trainingData)\ndt_prediction = dt_model.transform(testData)\ndt_prediction.select(\"prediction\", \"Survived\", \"features\").show()","5a3e40b3":"dt_accuracy = evaluator.evaluate(dt_prediction)\nprint(\"Accuracy of DecisionTreeClassifier is = %g\"% (dt_accuracy))\nprint(\"Test Error of DecisionTreeClassifier = %g \" % (1.0 - dt_accuracy))","9f895a92":"from pyspark.ml.classification import RandomForestClassifier\nrf = DecisionTreeClassifier(labelCol=\"Survived\", featuresCol=\"features\")\nrf_model = rf.fit(trainingData)\nrf_prediction = rf_model.transform(testData)\nrf_prediction.select(\"prediction\", \"Survived\", \"features\").show()","afa08036":"rf_accuracy = evaluator.evaluate(rf_prediction)\nprint(\"Accuracy of RandomForestClassifier is = %g\"% (rf_accuracy))\nprint(\"Test Error of RandomForestClassifier  = %g \" % (1.0 - rf_accuracy))","9215574e":"from pyspark.ml.classification import GBTClassifier\ngbt = GBTClassifier(labelCol=\"Survived\", featuresCol=\"features\",maxIter=10)\ngbt_model = gbt.fit(trainingData)\ngbt_prediction = gbt_model.transform(testData)\ngbt_prediction.select(\"prediction\", \"Survived\", \"features\").show()","5309dd92":"gbt_accuracy = evaluator.evaluate(gbt_prediction)\nprint(\"Accuracy of Gradient-boosted tree classifie is = %g\"% (gbt_accuracy))\nprint(\"Test Error of Gradient-boosted tree classifie %g\"% (1.0 - gbt_accuracy))","f3ceb76b":"from pyspark.ml.classification import NaiveBayes\nnb = NaiveBayes(labelCol=\"Survived\", featuresCol=\"features\")\nnb_model = nb.fit(trainingData)\nnb_prediction = nb_model.transform(testData)\nnb_prediction.select(\"prediction\", \"Survived\", \"features\").show()","ae1465f3":"nb_accuracy = evaluator.evaluate(nb_prediction)\nprint(\"Accuracy of NaiveBayes is  = %g\"% (nb_accuracy))\nprint(\"Test Error of NaiveBayes  = %g \" % (1.0 - nb_accuracy))","37ae1e2d":"from pyspark.ml.classification import LinearSVC\nsvm = LinearSVC(labelCol=\"Survived\", featuresCol=\"features\")\nsvm_model = svm.fit(trainingData)\nsvm_prediction = svm_model.transform(testData)\nsvm_prediction.select(\"prediction\", \"Survived\", \"features\").show()","f213affd":"svm_accuracy = evaluator.evaluate(svm_prediction)\nprint(\"Accuracy of Support Vector Machine is = %g\"% (svm_accuracy))\nprint(\"Test Error of Support Vector Machine = %g \" % (1.0 - svm_accuracy))","72a4ec3d":"### Splitting Data in Train and Test","0010f121":"## Random Forest","7e8dc2e3":"### Spark Session","49d98205":"## Naive Bayes","e578873b":"## Logistic Regression","bf66077c":"## Gradient Boosted Classifier","09d776fb":"### Data and basic EDA","f6f98980":"## Linear SVC","12f44c4e":"## Decision Tree Classifier"}}