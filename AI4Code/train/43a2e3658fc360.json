{"cell_type":{"a82b3030":"code","793c78dc":"code","00d6a9eb":"code","c9b4c296":"code","6e684769":"code","2fe9726f":"code","907d9eec":"code","0f8c517f":"code","e74744a5":"code","541ac4e1":"code","f76054bd":"code","96c2f5d2":"code","794d09e7":"code","fbfe5447":"code","fa5f6d79":"code","41e65b88":"code","d231d173":"code","b3dff577":"code","6a71f4cf":"code","176c8315":"code","4e63618f":"code","82c0675e":"code","a9dcaa4c":"code","5bc42337":"code","bd4a6d67":"code","9d043a8a":"code","cb1ae0a6":"code","dad3bc48":"code","1b6a9327":"code","be34adb0":"code","7873965e":"code","46fe095e":"code","1fb02b36":"code","a172f628":"code","6b9cd43d":"code","f2dedab0":"code","9a242e53":"code","3dee14e5":"code","7c4dd19b":"code","9ee86e15":"code","82ac907e":"code","a0991a00":"code","198ae728":"code","7993e3ce":"code","92b79eab":"code","77e81751":"code","8fc290eb":"code","157a457b":"code","a29d0ecc":"code","471a3418":"code","f2b4f252":"code","6c7b4813":"code","f45adda5":"code","6fc26887":"code","750888f5":"code","e906eae1":"code","0cfd5d1a":"code","6106d316":"code","a0128699":"code","ee19be24":"code","d9e28057":"code","ed8e7bb1":"code","0e2a3806":"code","40beda28":"code","f21bfb86":"code","02e7879a":"code","33898481":"code","86877954":"code","4e25d058":"code","54a1e259":"code","c8069b84":"code","ea8cee8d":"code","5c08c782":"code","f4fcb7df":"code","7dfa134d":"code","6c520a6f":"code","8fc68920":"code","4e83dd32":"code","775b35fa":"code","7f8f4b91":"code","a1d4138f":"code","93d055b1":"code","6f1b782b":"code","0191877f":"code","40af173d":"code","451ad22e":"code","f087913e":"code","30c04a8b":"code","9dfe935b":"code","b57bc7f2":"code","16944ce5":"code","8191533a":"code","3cbdb803":"code","4ed27a7b":"code","e5125345":"markdown","d83ec2a9":"markdown","9bf8aa06":"markdown","37ddc83b":"markdown","3688c571":"markdown","14f2f7ba":"markdown","4712480c":"markdown","5162d723":"markdown","68f4e5ab":"markdown","f826b678":"markdown","e0d09959":"markdown","e29709ef":"markdown","42e2e709":"markdown","5a33f104":"markdown"},"source":{"a82b3030":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n# Any results you write to the current directory are saved as output.","793c78dc":"import os\nprint(os.listdir(\"..\/input\"))","00d6a9eb":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\ngender_submission = pd.read_csv('..\/input\/gender_submission.csv')","c9b4c296":"train.head()","6e684769":"print(train.shape)\nprint(test.shape)","2fe9726f":"pd.options.display.max_colwidth = 100","907d9eec":"train.isnull().mean()","0f8c517f":"test.isnull().mean()","e74744a5":"train = train.drop('Cabin',axis=1)\ntest = test.drop('Cabin',axis=1)","541ac4e1":"train['Embarked'].head()","f76054bd":"train['Embarked'].mode()","96c2f5d2":"train['Embarked'] = train['Embarked'].fillna('S')","794d09e7":"import seaborn as sns\nimport matplotlib.pyplot as plt","fbfe5447":"# Fare in test data :\nfare_test = test[test['Fare'].notnull()]\nsns.distplot(fare_test['Fare'],rug=True)\nplt.show()","fa5f6d79":"fare_test['Fare'].quantile(0.50) # Checking Median","41e65b88":"# Let's impute it with Median and see first:\ntest['Fare'] = test['Fare'].fillna(test['Fare'].median())","d231d173":"train.isnull().sum()","b3dff577":"test.isnull().sum()","6a71f4cf":"names = train['Name'].str.split('.')\nnames_1 = []\nfor i in names:\n    names_1.append(i[0].split(',')[1])","176c8315":"names","4e63618f":"names_1 = []\nfor i in names:\n    names_1.append(i[0].split(',')[1])","82c0675e":"names_1","a9dcaa4c":"train['Name_Referred'] = names_1","5bc42337":"train['Name_Referred'].value_counts()","bd4a6d67":"train.groupby('Name_Referred')['Survived'].value_counts()","9d043a8a":"train['Name_Referred'] = train['Name_Referred'].replace({' Mr':'Mr',' Mrs':'Mrs',' Ms':'Ms',' Rev':'Rev',' Capt':'Military Man',' Col':'Military Man',' Don':'Noble',' Jonkheer': 'Noble',' Lady':'Noble',' Major':'Military Man',' Mlle':'Miss',' Mme':'Ms',' Master':'Master',' Miss':'Miss',' Sir':'Noble',' the Countess':'Noble',' Dr':'Dr'})","cb1ae0a6":"train.groupby('Name_Referred')['Survived'].value_counts()","dad3bc48":"names = test['Name'].str.split('.')\nnames_1 = []\nfor i in names:\n    names_1.append(i[0].split(',')[1])","1b6a9327":"test['Name_Referred'] = names_1\ntest['Name_Referred'].value_counts()","be34adb0":"test['Name_Referred'] = test['Name_Referred'].replace({' Mr':'Mr',' Mrs':'Mrs',' Ms':'Ms',' Rev':'Rev',' Col':'Military Man',' Dona':'Noble',' Master':'Master',' Miss':'Miss',' Dr':'Dr'})","7873965e":"test['Name_Referred'].value_counts()","46fe095e":"train_Age_NotMissing = train[train['Age'].notnull()] # Training data\n# I should also avoid using the column 'Survived' as it's not present in the testing data provided by Kaggle.\nSurvived_AgeNotMissing = train_Age_NotMissing.pop('Survived')","1fb02b36":"print(train_Age_NotMissing.shape)","a172f628":"train_Age_NotMissing = train_Age_NotMissing.drop(['PassengerId','Name','Ticket','Fare'],axis=1)","6b9cd43d":"train_Age_NotMissing = pd.get_dummies(train_Age_NotMissing,columns=['Embarked','Sex','Name_Referred'],drop_first = True)","f2dedab0":"train_Age_NotMissing.head()","9a242e53":"train_Age_NotMissing_y = train_Age_NotMissing.pop('Age')\ntrain_Age_NotMissing_X = train_Age_NotMissing","3dee14e5":"from sklearn import svm\nml = svm.SVR(kernel='linear',gamma='scale')","7c4dd19b":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(ml,train_Age_NotMissing_X,train_Age_NotMissing_y,cv=4)","9ee86e15":"scores.mean()","82ac907e":"from sklearn.metrics import SCORERS\nSCORERS.keys()","a0991a00":"ml.fit(train_Age_NotMissing_X,train_Age_NotMissing_y)","198ae728":"test = test.drop(['PassengerId','Name','Ticket','Fare'],axis=1)\ntest = pd.get_dummies(test,columns=['Embarked','Sex','Name_Referred'],drop_first=True)","7993e3ce":"test_age = test['Age']\ntest_y = test.pop('Age')\ntest_X = test","92b79eab":"train_Age_NotMissing_X.head()","77e81751":"test_X.head()","8fc290eb":"test['New_Age'] = ml.predict(test_X)","157a457b":"test['Age'] = test_age","a29d0ecc":"test['Age'] = test['Age'].fillna(0)","471a3418":"test.Age.isnull().sum()","f2b4f252":"for i in range(0,len(test['Age'])):\n    if test['Age'][i] == 0:\n        test['Age'] = test['Age'].replace(test['Age'][i],test['New_Age'][i])","6c7b4813":"test[test['Age']==0]","f45adda5":"test = test.drop(['New_Age'],axis=1)","6fc26887":"train.head()","750888f5":"train_New = train.drop(['PassengerId','Name','Ticket','Fare','Survived'],axis=1)\ntrain_New = pd.get_dummies(train_New,columns=['Embarked','Sex','Name_Referred'],drop_first=True)","e906eae1":"train_New.head()","0cfd5d1a":"train_New_Age=train_New.pop('Age')\ntrain_New_X = train_New\ntrain_New['New_Age'] = ml.predict(train_New_X)","6106d316":"train_New['Age'] = train_New_Age\ntrain_New['Age'] = train_New['Age'].fillna(0)","a0128699":"for i in range(0,len(train_New['Age'])):\n    if train_New['Age'][i] == 0:\n        train_New['Age'] = train_New['Age'].replace(train_New['Age'][i],train_New['New_Age'][i])","ee19be24":"train_New[train_New['Age']==0]","d9e28057":"train_New = train_New.drop(['New_Age'],axis=1)","ed8e7bb1":"train_New.head()","0e2a3806":"test.head()","40beda28":"train_New['Survived'] = train['Survived']","f21bfb86":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.boxplot(train_New['Age'])\nplt.show()","02e7879a":"sns.boxplot(test['Age'])\nplt.show()","33898481":"print(train_New['Age'].quantile(0.99))\nprint(test['Age'].quantile(1.0))","86877954":"print(train_New['Age'].quantile(0.001))\nprint(test['Age'].quantile(0.001))","4e25d058":"train_New = train_New[train_New['Age'] <= 76]","54a1e259":"train_New.shape","c8069b84":"train_New.corr()","ea8cee8d":"print(train_New.isnull().sum())\nprint(test.isnull().sum())","5c08c782":"sns.pairplot(train_New)\nplt.show()","f4fcb7df":"plt.figure(figsize=(26,20),dpi=30)\nsns.set(font_scale=2)\nsns.heatmap(train_New.corr(),cmap='YlGnBu')","7dfa134d":"train_New['Family_members'] = train_New['SibSp'] + train_New['Parch']\ntest['Family_members'] = test['SibSp'] + test['Parch']","6c520a6f":"train_New = train_New.drop(['SibSp','Parch'],axis=1)\ntest = test.drop(['SibSp','Parch'],axis=1)","8fc68920":"train_New['Family_members'].value_counts()","4e83dd32":"test['Family_members'].value_counts()","775b35fa":"from sklearn.preprocessing import MinMaxScaler","7f8f4b91":"scaler = MinMaxScaler()\ntrain_New.loc[:,['Age','Family_members']] = scaler.fit_transform(train_New.loc[:,['Age','Family_members']])","a1d4138f":"test.loc[:,['Age','Family_members']] = scaler.transform(test.loc[:,['Age','Family_members']])","93d055b1":"y_train = train_New.pop('Survived')\nX_train = train_New\nX_test = test","6f1b782b":"from sklearn.model_selection import GridSearchCV\nfrom sklearn import svm\nparam_grid = {'kernel' : ['rbf','poly','linear']}\nml_1 = svm.SVC(gamma = 'scale')\ngrid_search = GridSearchCV(estimator = ml_1,param_grid=param_grid,cv = 4,scoring = 'accuracy', n_jobs=-1,verbose=1)\ngrid_search.fit(X_train,y_train)","0191877f":"print(grid_search.best_score_)\nprint(grid_search.best_params_)","40af173d":"ml_1 = svm.SVC(kernel='rbf',gamma='scale')","451ad22e":"ml_1.fit(X_train,y_train)","f087913e":"y_pred = ml_1.predict(X_test)","30c04a8b":"from sklearn.metrics import accuracy_score","9dfe935b":"accuracy_score(gender_submission['Survived'],y_pred)","b57bc7f2":"test_X['Survived'] = y_pred\ntest_X[test_X['Age']<1]","16944ce5":"submission_8 = pd.DataFrame()\nsubmission_8['PassengerId'] = gender_submission['PassengerId']\nsubmission_8['Survived'] = y_pred","8191533a":"gender_submission.head() # To check the required form of submission.","3cbdb803":"submission_8.head()","4ed27a7b":"submission_8.to_csv('titanic_submission_8.csv',index = False, encoding='utf-8')","e5125345":"## 3) Scaling :","d83ec2a9":"### Here is how I create my submission file,viz.'submission_8'.","9bf8aa06":"## 5) Modelling :","37ddc83b":"## 7) Submission :","3688c571":"#### Similarly for train data :","14f2f7ba":"### Now,comes 'Age' column :","4712480c":"### My target initially for imputing the missing values in 'Age' column is by using it as a dependent variable,and using all other columns,including the newly created 'Referred Name' as the predictors.\n\n### So,I split the 'train' data into 2 parts.One with the values present which I'll use to train,and the other with the values missing,which I'll use as the data for which I'll predict the values :","5162d723":"## 4) Train-Test Split :","68f4e5ab":"## 2) Outlier Treatment :","f826b678":"## 1) Missing Value Handling :","e0d09959":"### Firstly,we'll drop the columns with missing values of above 40% or more,and impute the columns with less than 2-5% of values missing :","e29709ef":"### Before doing outlier treatment,let's get the 'Survived' column here,as that'll allow me to carry out outlier operations on the dataset :","42e2e709":"### Let's also do the same for testing data now :","5a33f104":"### Let's first do the outlier treatment for 'Age',now :"}}