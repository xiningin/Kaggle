{"cell_type":{"aafc4fa8":"code","7d3b9eb4":"code","b1dfa6ff":"code","c55ef57c":"code","c2182beb":"code","a9451f3b":"code","6a1eb426":"code","bb96990c":"code","8a108d0f":"code","34e5db47":"code","755e6198":"code","b85f7b16":"code","218de873":"code","56a6bf03":"code","a02205a6":"code","66eb789b":"code","c0f2f6c5":"code","61043661":"code","6ca90fef":"code","5cf7208a":"code","58173e11":"code","ca0a4246":"code","b98405de":"code","ffe94d9c":"code","4c1686f3":"code","3939490d":"code","3a4f8b16":"code","e045fb01":"code","e1d742f4":"code","3e12558e":"code","5852669c":"code","45aec326":"code","cf34af33":"code","5ebc277d":"code","cf9897cd":"code","d678c229":"code","442b528d":"code","fb33845a":"code","1f852e7a":"code","8f0d4dc9":"code","4ac31c74":"code","fb9bc689":"code","95cf1835":"code","ecd6e6b9":"code","59fbbc4e":"code","a0fd023d":"code","418b615c":"code","ee742500":"code","7b143928":"markdown","0f224582":"markdown","18ed3bea":"markdown","130c2983":"markdown","3dcf5e58":"markdown","51feeb95":"markdown","931127c2":"markdown","c7a47627":"markdown","51b12088":"markdown","eff2ac36":"markdown","a9460d7f":"markdown","2890d040":"markdown","5345ec20":"markdown","a0eec545":"markdown","affbdbbe":"markdown","a51af556":"markdown"},"source":{"aafc4fa8":"# Reference notebooks:\n# https:\/\/www.kaggle.com\/sinamhd9\/mechanisms-of-action-moa-tutorial\n# https:\/\/www.kaggle.com\/fchmiel\/xgboost-baseline-multilabel-classification","7d3b9eb4":"# Upload libraries\nimport numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\n#% matplotlib inline\nimport seaborn as sns\n\nimport statistics as st \nimport scipy.stats as stats\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom keras.layers import Input,Dense\nfrom keras.models import Model\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","b1dfa6ff":"# Upload data set\ntrain = pd.read_csv('\/kaggle\/input\/lish-moa\/train_features.csv')\ntest = pd.read_csv('\/kaggle\/input\/lish-moa\/test_features.csv')\ntargets = pd.read_csv('\/kaggle\/input\/lish-moa\/train_targets_scored.csv')\ntargets_ns = pd.read_csv('\/kaggle\/input\/lish-moa\/train_targets_nonscored.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/lish-moa\/sample_submission.csv')","c55ef57c":"train.shape","c2182beb":"test.shape","a9451f3b":"df = train.append(test)","6a1eb426":"# Look at dimension of data set and types of each attribute\ndf.info()","bb96990c":"# train\n# ['sig_id', 'cp_type', 'cp_dose'] == object\n# ['cp_time'] == int","8a108d0f":"# Summarize attribute distributions of the data frame\ndf.describe(include = 'all').T","34e5db47":"# Take a peek at the first rows of the data\ndf.head(10)","755e6198":"# Look at dimension of data set and types of each attribute\ntargets.info()","b85f7b16":"# Summarize attribute distributions of the data frame\ntargets.describe(include = 'all').T","218de873":"# Take a peek at the first rows of the data\ntargets.head(10)","56a6bf03":"# Look at dimension of data set and types of each attribute\ntargets_ns.info()","a02205a6":"# Summarize attribute distributions of the data frame\ntargets_ns.describe(include = 'all').T","66eb789b":"# Take a peek at the first rows of the data\ntargets_ns.head(10)","c0f2f6c5":"# Check missing values both to numeric features and categorical features \nfeat_missing = []\n\nfor f in df.columns:\n    missings = df[f].isnull().sum()\n    if missings > 0:\n        feat_missing.append(f)\n        missings_perc = missings\/df.shape[0]\n        \n        # printing summary of missing values\n        print('Variable {} has {} records ({:.2%}) with missing values'.format(f, missings, missings_perc))\n\n# How many variables do present missing values?\nprint()\nprint('In total, there are {} variables with missing values'.format(len(feat_missing)))","61043661":"targets_df = targets.copy()\ntargets_df = targets_df.drop(['sig_id'], axis=1)","6ca90fef":"# Summarize the class distribution \ncol_name = targets_df.columns\nfor var in col_name:\n    count = pd.crosstab(index = targets_df[var], columns=\"count\")\n    percentage = pd.crosstab(index = targets_df[var], columns=\"frequency\")\/pd.crosstab(index = targets_df[var], columns=\"frequency\").sum()\n    print('\\n',pd.concat([count, percentage], axis=1))","5cf7208a":"# Plot the target variable\nfigures_per_time = 4\ncount = 0 \nfor var in targets_df.columns:\n    x = targets_df[var]\n    plt.figure(count\/\/figures_per_time,figsize=(25,5))\n    plt.subplot(1,figures_per_time,np.mod(count,4)+1)\n    sns.countplot(x, color='g',linewidth=2)\n    plt.xticks(rotation=45)\n    count+=1\nax = sns.countplot(x=targets[var], data=targets, palette='rocket')","58173e11":"# gene features\ngene_features = [cols for cols in df.columns if cols.startswith('g-')]","ca0a4246":"# Univariate analysis looking at Mean, Standard Deviation, Skewness and Kurtosis\nfor col in gene_features:\n    print(col,\n        '\\nMean :', np.mean(df[col]),  \n        '\\nVariance :', np.var(df[col]),\n        '\\nStandard Deviation :', st.stdev(df[col]), \n        '\\nSkewness :', stats.skew(df[col]), \n        '\\nKurtosis :', stats.kurtosis(df[col]))","b98405de":"# Univariate analysis with density plots \nfigures_per_time = 4\ncount = 0 \nfor var in gene_features:\n    x = df[var]\n    plt.figure(count\/\/figures_per_time,figsize=(25,5))\n    plt.subplot(1,figures_per_time,np.mod(count,4)+1)\n    sns.kdeplot(x, color='g',linewidth=2)\n    plt.xticks(rotation=45)\n    count+=1","ffe94d9c":"# Univariate analysis with histogram plots \nfigures_per_time = 4\ncount = 0 \nfor var in gene_features:\n    x = df[var]\n    plt.figure(count\/\/figures_per_time,figsize=(25,5))\n    plt.subplot(1,figures_per_time,np.mod(count,4)+1)\n    sns.distplot(x, bins=10, color='r')\n    plt.xticks(rotation=45)\n    count+=1","4c1686f3":"# Univariate analysis with box plots \nfigures_per_time = 4\ncount = 0 \nfor var in gene_features:\n    x = df[var]\n    plt.figure(count\/\/figures_per_time,figsize=(25,5))\n    plt.subplot(1,figures_per_time,np.mod(count,4)+1)\n    sns.boxplot(x, color='b')\n    plt.xticks(rotation=45)\n    count+=1","3939490d":"# cell features\ncell_features = [cols for cols in df.columns if cols.startswith('g-')]","3a4f8b16":"# Univariate analysis looking at Mean, Standard Deviation, Skewness and Kurtosis\nfor col in cell_features:\n    print(col,\n        '\\nMean :', np.mean(df[col]),  \n        '\\nVariance :', np.var(df[col]),\n        '\\nStandard Deviation :', st.stdev(df[col]), \n        '\\nSkewness :', stats.skew(df[col]), \n        '\\nKurtosis :', stats.kurtosis(df[col]))","e045fb01":"# Univariate analysis with density plots \nfigures_per_time = 4\ncount = 0 \nfor var in cell_features:\n    x = df[var]\n    plt.figure(count\/\/figures_per_time,figsize=(25,5))\n    plt.subplot(1,figures_per_time,np.mod(count,4)+1)\n    sns.kdeplot(x, color='g',linewidth=2)\n    plt.xticks(rotation=45)\n    count+=1","e1d742f4":"# Univariate analysis with histogram plots \nfigures_per_time = 4\ncount = 0 \nfor var in cell_features:\n    x = df[var]\n    plt.figure(count\/\/figures_per_time,figsize=(25,5))\n    plt.subplot(1,figures_per_time,np.mod(count,4)+1)\n    sns.distplot(x, bins=10, color='r')\n    plt.xticks(rotation=45)\n    count+=1","3e12558e":"# Univariate analysis with box plots \nfigures_per_time = 4\ncount = 0 \nfor var in cell_features:\n    x = df[var]\n    plt.figure(count\/\/figures_per_time,figsize=(25,5))\n    plt.subplot(1,figures_per_time,np.mod(count,4)+1)\n    sns.boxplot(x, color='b')\n    plt.xticks(rotation=45)\n    count+=1","5852669c":"fcat = ['cp_type', 'cp_dose']\nfor col in fcat:\n    count = pd.crosstab(index = df[col], columns=\"count\")\n    percentage = pd.crosstab(index = df[col], columns=\"frequency\")\/pd.crosstab(index = df[col], columns=\"frequency\").sum()\n    tab = pd.concat([count, percentage], axis=1)\n    plt.figure(figsize=(5,5))\n    sns.countplot(x=df[col], data=df, palette=\"Set1\")\n    plt.xticks(rotation=45)\n    print(tab)\n    plt.show()","45aec326":"# One-Hot Encoding into k-1 dummy Variables\ndummy_df = pd.concat([pd.get_dummies(df.cp_type, drop_first=True), \n                         pd.get_dummies(df.cp_dose, drop_first=True)], axis=1)\ndummy_df = dummy_df.astype(int)","cf34af33":"# Whole data set\ndf_new = pd.concat([df, dummy_df], axis=1)","5ebc277d":"X_all = df_new.copy()","cf9897cd":"# Drop features not helpful\nX_all = X_all.drop(['sig_id', 'cp_type', 'cp_dose'], axis=1)","d678c229":"# Normalization of data\nscaling = MinMaxScaler()\nX_all_sc = scaling.fit_transform(X_all)\n","442b528d":"# Take number of autoencoder features from number of components which explain 70% of variance with PCA \npca = PCA(0.70, random_state=0)\npca_X_all_sc = pca.fit_transform(X_all_sc)\npca.n_components_","fb33845a":"# single fully-connected neural layer as encoder and as decoder\n# This is the size of encoded representations\nencoding_dim = pca.n_components_  \n\n# This is input \ninput_data = Input(shape=(875,)) # number of features\/columns\n# \"encoded\" is the encoded representation of the input\nencoded = Dense(encoding_dim, activation='relu')(input_data)\n# \"decoded\" is the lossy reconstruction of the input\ndecoded = Dense(875, activation='relu')(encoded)\n\n# This model maps an input to its reconstruction\nautoencoder = Model(input_data, decoded)","1f852e7a":"# create a separate encoder model:\n# This model maps an input to its encoded representation\nencoder = Model(input_data, encoded)\n# create a separate decoder model:\n# This is encoded input\nencoded_input = Input(shape=(encoding_dim,))\n# Retrieve the last layer of the autoencoder model\ndecoder_layer = autoencoder.layers[-1]\n# Create the decoder model\ndecoder = Model(encoded_input, decoder_layer(encoded_input))","8f0d4dc9":"# Configure the model\nautoencoder.compile(optimizer='adam', loss='mean_squared_error')","4ac31c74":"# train the model\nnp.random.seed(0)\nautoencoder.fit(X_all_sc,\n                X_all_sc,\n                epochs=50,\n                shuffle=True)\n\nautoencoder.summary()","fb9bc689":"# predict after training\nencoded_input = encoder.predict(X_all_sc)","95cf1835":"# New data set\nautoencoder_df = pd.DataFrame(data = encoded_input, columns=['autoencoder'+str(i) for i in range(pca_X_all_sc.shape[1])])\nautoencoder_df","ecd6e6b9":"tsne_df = TSNE(n_components=2, random_state=0).fit_transform(autoencoder_df)","59fbbc4e":"tsne_data = pd.DataFrame(tsne_df, columns=['x', 'y'], index=autoencoder_df.index)","a0fd023d":"dff = pd.concat([targets_df['5-alpha_reductase_inhibitor'], tsne_data], axis=1)\n\n# Show the diagram\nfig, ax = plt.subplots(figsize=(10, 10))\n\nwith sns.plotting_context(\"notebook\", font_scale=1.0):\n     sns.scatterplot(x='x',\n                        y='y',\n                        hue='5-alpha_reductase_inhibitor',\n                        palette=sns.color_palette(\"husl\", 2),\n                        data=dff,\n                        ax=ax)\n\nax.set_xlabel(r'$x$')\nax.set_ylabel(r'$y$')\n\nplt.show()","418b615c":"dff = pd.concat([targets_df['antiprotozoal'], tsne_data], axis=1)\n\n# Show the diagram\nfig, ax = plt.subplots(figsize=(10, 10))\n\nwith sns.plotting_context(\"notebook\", font_scale=1.0):\n     sns.scatterplot(x='x',\n                        y='y',\n                        hue='antiprotozoal',\n                        palette=sns.color_palette(\"Set2\", 2),\n                        data=dff,\n                        ax=ax)\n\nax.set_xlabel(r'$x$')\nax.set_ylabel(r'$y$')\n\nplt.show()","ee742500":"dff = pd.concat([targets_df['adenylyl_cyclase_activator'], tsne_data], axis=1)\n\n# Show the diagram\nfig, ax = plt.subplots(figsize=(10, 10))\n\nwith sns.plotting_context(\"notebook\", font_scale=1.0):\n     sns.scatterplot(x='x',\n                        y='y',\n                        hue='adenylyl_cyclase_activator',\n                        palette=sns.color_palette(\"Set1\", 2),\n                        data=dff,\n                        ax=ax)\n\nax.set_xlabel(r'$x$')\nax.set_ylabel(r'$y$')\n\nplt.show()","7b143928":"# Scaling Data","0f224582":"# Handling Data Set","18ed3bea":"# Import Data","130c2983":"# t-SNE for Visualizing Dimensionality reduction Data","3dcf5e58":"# Prepare Workspace","51feeb95":"![](https:\/\/image.slidesharecdn.com\/mechanismofdrugaction-131104071748-phpapp01\/95\/mechanism-of-drug-action-3-638.jpg?cb=1383549622)","931127c2":"# Target Variable Analysis","c7a47627":"### Handling missing values","51b12088":"# Dimensionality Reduction","eff2ac36":"# Numerical Features Analysis","a9460d7f":"# Categorical Features Analysis","2890d040":"# Feature Engineering","5345ec20":"# Have a peek of Data","a0eec545":"# Notes","affbdbbe":"The goal of this competition is to advance drug development through improvements of MoA prediction algorithms.\nWith MoA, scientists seek to identify a protein target associated with a disease and develop a molecule that can modulate that protein target. Mechanism of action stands for the biochemical interactions through which a drug generates its pharmacological effect.\nThere is a data set that combines gene expression and cell viability data. \nHence, the task is to use the training data set to develop a model that automatically labels each case in the test set as one or more MoA classes, so the task is a multi-label classification problem.\nThe evaluation of the model is based on the log loss function and it measures the performance of a classification model whose output is a probability value between 0 and 1. Log loss increases as the predicted probability diverges from the actual label.\nIn this Project after an Exploratory Data Analysis and the One-Hot Encoding into k-1 dummy variables, the data set is reduced with Autoencoder, moving from 875 features to 28 features. I've applied t-SNE at some new features and some target labels to discover graphical patterns.\n\n","a51af556":"# Mechanisms of Action (MoA) Prediction"}}