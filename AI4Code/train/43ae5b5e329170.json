{"cell_type":{"5c792085":"code","b8741aac":"code","130d4181":"code","ba1f4d97":"code","5cbf4677":"code","7a1e0ad8":"code","b8d1bec5":"code","420f0583":"code","b160b455":"code","4b7219ab":"code","b2149402":"code","6bd61e8d":"code","29c522cc":"code","14bd2ef5":"code","2bc21bd3":"code","72adb556":"code","8f6f2d3c":"code","fa4ad4bc":"code","6294b6c4":"code","dbb7df93":"code","eadbc17d":"code","f47cbdfd":"code","2b2f9d09":"code","ba64c28c":"code","fd42e679":"code","1a4e70fd":"code","0fe91001":"code","30ac4f16":"code","2b4c5ffd":"code","2f95e83b":"code","2f9d3bdb":"code","71bff57a":"code","55433edc":"code","84ad598f":"code","de3e8415":"code","17114801":"code","6640c2d1":"code","ee7aa30f":"code","e090f9f6":"code","6e0dede3":"code","93432981":"markdown","c13dc27c":"markdown","e9bfcdb4":"markdown","6cc939e6":"markdown","f99edb44":"markdown","590dab90":"markdown","d00d394c":"markdown","2cf4e9e9":"markdown","17b6f032":"markdown","e2ffacd7":"markdown","3f00900a":"markdown","62256dd1":"markdown","f98b391e":"markdown","879f0951":"markdown","e9b77dd5":"markdown","789b41de":"markdown","0f9390e4":"markdown","461fe715":"markdown"},"source":{"5c792085":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom tqdm import tqdm\nimport os\nimport random\nimport functools\nimport matplotlib.pyplot as plt\nimport time\n\n# sklearn\nfrom sklearn.model_selection import train_test_split, KFold\n\n# tensorflow\nimport tensorflow as tf\ntf.enable_eager_execution()\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\n# keras\nimport keras.backend as K\n\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b8741aac":"SIZE = 156\nBATCH_SIZE = 64","130d4181":"# training dataframe\ntrain_val_df = pd.read_csv(\"..\/input\/imetmetadata\/weird_images_w_labels.csv\")\ntrain_val_df.head()","ba1f4d97":"labels_df = pd.read_csv(\"..\/input\/imet-2019-fgvc6\/labels.csv\")\nlabels_df.head()","5cbf4677":"N_CLASSES = len(labels_df)\nprint(\"Number of classes:\", N_CLASSES)","7a1e0ad8":"n_width_300 = len(train_val_df[train_val_df['width'] == 300])\nn_height_300 = len(train_val_df[train_val_df['height'] == 300])\nn_width_height_300 = len(train_val_df[(train_val_df['height'] == 300) & (train_val_df['width'] == 300)])\n\nn_all_images = len(train_val_df)\n\nprint(\"Total images: \", n_all_images)\nprint(\"Total images with width or height = 300: \", n_height_300 + n_width_300 - n_width_height_300)","b8d1bec5":"width_larger_equal_height = train_val_df[train_val_df['width'] >= train_val_df['height']]\nwidth_smaller_equal_height = train_val_df[train_val_df['width'] < train_val_df['height']]\n\nprint(\"Number of image with width >= height: \", len(width_larger_equal_height))\nprint(\"Number of image with height = 300: \", sum(width_larger_equal_height['height'] == 300))\n# print(n_width_smaller_height)\nprint(\"\\n\")\nprint(\"Number of image with width <= height: \", len(width_smaller_equal_height))\nprint(\"Number of image with width = 300: \", sum(width_smaller_equal_height['width'] == 300))","420f0583":"test_ids = pd.read_csv('..\/input\/imet-2019-fgvc6\/sample_submission.csv')['id']\nprint(\"Total number of images in test set: \", len(test_ids))\ntest_ids.head()","b160b455":"ok = True\ntest_datasets = tf.data.Dataset.from_tensor_slices(test_ids).map(lambda x: tf.image.decode_jpeg(\n                                                                        tf.read_file(\"..\/input\/imet-2019-fgvc6\/test\/\"+x+\".png\")))\nfor img in tqdm(test_datasets):\n    if((img.shape[0] != 300) & (img.shape[1] != 300)):\n        print(\"Assumption is not right\")\n        ok = False\n        break\n        \nif(ok == True):\n    print(\"All images in test set have width or height = 300\")\n        ","4b7219ab":"train_val_df['aspect_ratio'] = train_val_df['width'] \/ train_val_df['height']","b2149402":"ar_larger_2 = train_val_df[(train_val_df['aspect_ratio'] > 3) & (train_val_df['height'] == 300)]\nar_larger_2['id'].head()","6bd61e8d":"grids = (3, 3)\nplt.figure(figsize=(7, 7))\n\nn_plot = grids[0] * grids[1]\n\nplot_image_names = random.choices(list(ar_larger_2['id']), k=n_plot)\nplot_dataset = tf.data.Dataset.from_tensor_slices(plot_image_names).map(lambda x: tf.image.decode_jpeg(\n                                                                        tf.read_file(\"..\/input\/imet-2019-fgvc6\/train\/\"+x+\".png\")))\n\nfor i, img in enumerate(plot_dataset):\n    ax = plt.subplot(grids[0], grids[1], i+1)\n    ax = plt.imshow(img, cmap='brg')\n    ","29c522cc":"ar_smaller_1_2 = train_val_df[(train_val_df['aspect_ratio'] < 1\/3.0) & (train_val_df['width'] == 300)]\nar_smaller_1_2['id'].head()","14bd2ef5":"grids = (3, 3)\nplt.figure(figsize=(7, 7))\n\nn_plot = grids[0] * grids[1]\n\nplot_image_names = random.choices(list(ar_smaller_1_2['id']), k=n_plot)\nplot_dataset = tf.data.Dataset.from_tensor_slices(plot_image_names).map(lambda x: tf.image.decode_jpeg(\n                                                                        tf.read_file(\"..\/input\/imet-2019-fgvc6\/train\/\"+x+\".png\")))\n\nfor i, img in enumerate(plot_dataset):\n    ax = plt.subplot(grids[0], grids[1], i+1)\n    ax = plt.imshow(img, cmap='brg')\n    ","2bc21bd3":"categorical_labels = np.zeros(shape=(len(train_val_df['attribute_ids']), N_CLASSES))\nfor i, label in enumerate(train_val_df['attribute_ids']):\n    list_indices = [int(k) for k in label.split(\" \")]\n    categorical_labels[i, list_indices] = 1\n    \nprint(categorical_labels.shape)","72adb556":"def shift_img(img, width_shift_range, height_shift_range):\n    \"\"\"This fn will perform the horizontal or vertical shift\"\"\"\n    img_shape = img.get_shape()\n#     print(type(img_shape))\n    if width_shift_range or height_shift_range:\n        if width_shift_range:\n            width_shift_range = tf.random_uniform([], \n                                              -width_shift_range * img_shape[1].value,\n                                              width_shift_range * img_shape[1].value)\n        if height_shift_range:\n            height_shift_range = tf.random_uniform([],\n                                               -height_shift_range * img_shape[0].value,\n                                               height_shift_range * img_shape[0].value)\n        # Translate both \n        output_img = tf.contrib.image.translate(img,\n                                             [width_shift_range, height_shift_range])\n        return output_img\n    else:\n        return img\n\ndef rotate_img(img, angle_range):\n    rotate_angle = tf.random_uniform([], minval = angle_range[0]\/180.0*3.1415, maxval=angle_range[1]\/180.0*3.1415)\n    out_img = tf.contrib.image.rotate(img, angles=rotate_angle)\n    return out_img\n    \ndef flip_img(horizontal_flip, img):\n    if horizontal_flip:\n        flip_prob = tf.random_uniform([], 0.0, 1.0)\n        out_img = tf.cond(tf.less(flip_prob, 0.5),\n                                lambda: tf.image.flip_left_right(img),\n                                lambda: img)\n        return out_img\n    else:\n        return img","8f6f2d3c":"def load_img_label(image_name, label):\n    img_string = tf.read_file(\"..\/input\/imet-2019-fgvc6\/train\/\"+ image_name + \".png\")\n    img = tf.image.decode_png(img_string)\n    shape = tf.shape(img)  # Use dynamic shape, only known at runtime\n    tfwidth = tf.to_float(shape[1])\n    tfheight = tf.to_float(shape[0])\n\n    img = tf.cond(tf.math.logical_or(tfwidth\/tfheight > 3.0, tfwidth\/tfheight < 1\/3.0), \n            lambda: tf.image.random_crop(img, size=[300, 300, 3]), \n            lambda: img)\n\n    return img, label\n\ndef _augment(img,\n             label,\n             resize=None,  # Resize the image to some size e.g. [256, 256]\n             scale=1,  # Scale image e.g. 1 \/ 255.\n             hue_delta=0,  # Adjust the hue of an RGB image by random factor\n             horizontal_flip=False,  # Random left right flip,\n             width_shift_range=0,  # Randomly translate the image horizontally\n             height_shift_range=0,   # Randomly translate the image vertically \n             rotation_range = None):  \n    \n    if resize is not None:\n        img = tf.image.resize_images(img, resize)\n    if hue_delta:\n        img = tf.image.random_hue(img, hue_delta)\n    img = flip_img(horizontal_flip, img)\n    img = shift_img(img, width_shift_range, height_shift_range)\n    \n    if(rotation_range):\n        img = rotate_img(img, rotation_range)\n    \n    img = tf.to_float(img) * scale \n    return img, label\n\ndef create_dataset(filenames, \n                   labels,\n                    preproc_fn=functools.partial(_augment),\n                    threads=5, \n                    batch_size=BATCH_SIZE,\n                    shuffle=True):\n\n    num_x = len(filenames)\n    # Create a dataset from the filenames and labels\n    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n    # Map our preprocessing function to every element in our dataset, taking\n    # advantage of multithreading\n    \n    if shuffle:\n        dataset = dataset.apply(\n              tf.data.experimental.shuffle_and_repeat(buffer_size=num_x))\n    else:\n        dataset = dataset.repeat()\n        \n    # load image and label from file name\n    dataset = dataset.map(load_img_label)\n\n    if preproc_fn.keywords is not None and 'resize' not in preproc_fn.keywords:\n        assert batch_size == 1, \"Batching images must be of the same size\"\n\n    dataset = dataset.map(preproc_fn, num_parallel_calls=threads)\n        \n    # It's necessary to repeat our data for all epochs \n    dataset = dataset.batch(batch_size).prefetch(AUTOTUNE)\n    \n    return dataset","fa4ad4bc":"tr_cfg = {\n    'resize': [SIZE, SIZE],\n    'scale': 1 \/ 255.,\n    # 'hue_delta': 0.4,\n    'horizontal_flip': True,\n    'width_shift_range': 0.2,\n    'height_shift_range': 0.2,\n    'rotation_range': (-15,15)\n}\n\ntr_preprocessing_fn = functools.partial(_augment, **tr_cfg)\n# train_dataset = create_dataset(train_img_names, train_categorical_labels, preproc_fn=tr_preprocessing_fn, threads=2)","6294b6c4":"val_cfg = {\n    'resize': [SIZE, SIZE],\n    'scale': 1 \/ 255.,\n}\n\nval_preprocessing_fn = functools.partial(_augment, **val_cfg)\n# val_dataset = create_dataset(val_img_names, val_categorical_labels, preproc_fn=val_preprocessing_fn, threads=2)","dbb7df93":"plot_dataset =  create_dataset(train_val_df['id'], categorical_labels, preproc_fn=tr_preprocessing_fn, threads=2, shuffle=True)\ncounter = 0\nplt.figure(figsize=(10,10))\ns = time.time()\nX, y = next(plot_dataset.make_one_shot_iterator())\ne = time.time()\n\nprint(e-s)\n\nfor img, label in zip(X,y):\n    plt.subplot(3,3, counter+1)\n    plt.imshow(img, cmap='brg')\n    if(counter >= 8):\n        break\n    else:\n        counter += 1\n        ","eadbc17d":"# kfold\ndef generate_kfolds(n_folds=10, image_names=None, categorical_labels=None):\n    return KFold(n_splits=n_folds, random_state=333, shuffle=True)","f47cbdfd":"# Loss\n\ngamma = 2.0\nepsilon = tf.keras.backend.epsilon()\ndef focal_loss(y_true, y_pred):\n    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n    pt = tf.keras.backend.clip(pt, epsilon, 1-epsilon)\n    CE = -tf.log(pt)\n    FL = tf.pow(1-pt, gamma) * CE\n    loss = tf.keras.backend.sum(FL, axis=1)\n    return loss\n\n# Metric\ndef f2_score(y_true, y_pred):\n    beta = 2\n    true_positives = tf.keras.backend.sum(tf.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)), axis=1)\n    predicted_positives = tf.keras.backend.sum(tf.round(tf.keras.backend.clip(y_pred, 0, 1)), axis=1)\n    possible_positives = tf.keras.backend.sum(tf.round(tf.keras.backend.clip(y_true, 0, 1)), axis=1)\n    \n    precision = true_positives \/ (predicted_positives + tf.keras.backend.epsilon())\n    recall = true_positives \/ (possible_positives + tf.keras.backend.epsilon())\n    \n    return tf.keras.backend.mean(((1+beta**2)*precision*recall) \/ ((beta**2)*precision+recall+tf.keras.backend.epsilon()))","2b2f9d09":"custom_weight = True\ntraining = False","ba64c28c":"def create_model(input_shape, n_out):\n    input_tensor = tf.keras.layers.Input(shape=input_shape)\n    base_model = tf.keras.applications.Xception(include_top=False,\n                   weights=None,\n                   input_tensor=input_tensor)\n    if(not custom_weight):\n        base_model.load_weights('..\/input\/xception\/xception_weights_tf_dim_ordering_tf_kernels_notop.h5')\n#     x = Conv2D(32, kernel_size=(1,1), activation='relu')(base_model.output)\n#     x = Flatten()(x)\n    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n    # x = Dropout(0.5)(x)\n    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n    # x = Dropout(0.5)(x)\n    final_output = tf.keras.layers.Dense(n_out, activation='sigmoid', name='final_output')(x)\n    model = tf.keras.Model(input_tensor, final_output)\n    if(custom_weight):\n        model.load_weights('..\/input\/imetpretrained\/imet_xception_val_f2_0.686829-f2_0.611568.h5')\n        \n    return model","fd42e679":"model = create_model(input_shape=(SIZE, SIZE, 3), n_out=N_CLASSES)\nmodel.summary()","1a4e70fd":"# create callbacks list\ncheckpoint = tf.keras.callbacks.ModelCheckpoint('..\/working\/imet_xception_val_f2_{val_f2_score:3f}-f2_{f2_score:3f}.h5',\n                                                monitor='val_loss', verbose=1, save_best_only=True, mode='min', \n                                                save_weights_only = True)\nreduceLROnPlat = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, \n                                   verbose=1, mode='auto', epsilon=0.0001)\nearly = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=9)\n\ncsv_logger = tf.keras.callbacks.CSVLogger(filename='..\/working\/training_log.csv',\n                       separator=',',\n                       append=True)\n\ncallbacks_list = [checkpoint, csv_logger, reduceLROnPlat]","0fe91001":"# warm up model\nif(training and not custom_weight):\n    n_folds = 10\n\n    for layer in model.layers:\n        layer.trainable = False\n\n    for i in range(-5,0):\n        model.layers[i].trainable = True\n\n    model.compile(\n        loss=focal_loss,\n        optimizer=tf.keras.optimizers.Adam(1e-3),\n        metrics=[f2_score])\n\n    kfolder = generate_kfolds(n_folds, image_names=train_val_df['id'], categorical_labels=categorical_labels)\n    list_loss = []\n    list_f2 = []\n\n    for i, (train_indices, val_indices) in enumerate(kfolder.split(train_val_df['id'], categorical_labels)):\n        print(\"============== Fold\", (i+1), \"================\")\n        train_dataset = create_dataset(train_val_df.loc[train_indices, 'id'], categorical_labels[train_indices, :], preproc_fn=tr_preprocessing_fn, threads=2)\n        val_dataset = create_dataset(train_val_df.loc[val_indices, 'id'], categorical_labels[val_indices, :], preproc_fn=val_preprocessing_fn, threads=2)\n        history = model.fit_generator(\n            train_dataset,\n            steps_per_epoch=int(np.ceil(float(len(train_indices)) \/ float(BATCH_SIZE))),\n            validation_data=val_dataset,\n            validation_steps=int(np.ceil(float(len(val_indices)) \/ float(BATCH_SIZE))),\n            epochs=1,\n            verbose=1,\n            callbacks=callbacks_list)\n        list_loss.append(history.history['val_loss'][0])\n        list_f2.append(history.history['val_f2_score'][0])\n        print(\"Val loss of fold %d = %f\"%(i+1, history.history['val_loss'][0]))\n        print(\"F2 score of fold %d = %f\"%(i+1, history.history['val_f2_score'][0]))\n\n    print(\"\\nMean val loss over all: \", np.mean(np.array(list_loss)))\n    print(\"Mean f2_score over all: \", np.mean(np.array(list_f2)))","30ac4f16":"# train all layers - finetuning\nif(training):\n    n_folds = 15\n\n    for layer in model.layers:\n        layer.trainable = True\n\n    model.compile(loss=focal_loss,\n                optimizer=tf.keras.optimizers.Adam(lr=0.0003),\n                 metrics=[f2_score])\n\n    checkpoint = tf.keras.callbacks.ModelCheckpoint('..\/working\/imet_xception_val_f2_{val_f2_score:3f}-f2_{f2_score:3f}.h5',\n                                                    monitor='val_loss', verbose=1, save_best_only=True, \n                                                    mode='min', save_weights_only = True)\n    reduceLROnPlat = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, \n                                       verbose=1, mode='auto', epsilon=0.0001)\n    early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", \n                          mode=\"min\", \n                          patience=9)\n    callbacks_list = [checkpoint, csv_logger, reduceLROnPlat]\n\n    print(\"Start training ...\")\n\n    kfolder = generate_kfolds(n_folds, image_names=train_val_df['id'], categorical_labels=categorical_labels)\n    list_loss = []\n    list_f2 = []\n\n    for i, (train_indices, val_indices) in enumerate(kfolder.split(train_val_df['id'], categorical_labels)):\n        print(\"============== Fold\", (i+1), \"================\")\n        train_dataset = create_dataset(train_val_df.loc[train_indices, 'id'], categorical_labels[train_indices, :], preproc_fn=tr_preprocessing_fn, threads=2)\n        val_dataset = create_dataset(train_val_df.loc[val_indices, 'id'], categorical_labels[val_indices, :], preproc_fn=val_preprocessing_fn, threads=2)\n        history = model.fit_generator(\n            train_dataset,\n            steps_per_epoch=int(np.ceil(float(len(train_indices)) \/ float(BATCH_SIZE))),\n            validation_data=val_dataset,\n            validation_steps=int(np.ceil(float(len(val_indices)) \/ float(BATCH_SIZE))),\n            epochs=1,\n            verbose=1,\n            callbacks=callbacks_list)\n        list_loss.append(history.history['val_loss'][0])\n        list_f2.append(history.history['val_f2_score'][0])\n        print(\"Val loss of fold %d = %f\"%(i+1, history.history['val_loss'][0]))\n        print(\"F2 score of fold %d = %f\"%(i+1, history.history['val_f2_score'][0]))\n\n    print(\"\\nMean val loss over all: \", np.mean(np.array(list_loss)))\n    print(\"Mean f2_score over all: \", np.mean(np.array(list_f2)))","2b4c5ffd":"submit = pd.read_csv('..\/input\/imet-2019-fgvc6\/sample_submission.csv')\npredicted = []","2f95e83b":"# load the best score model\ndef file_filter(filename):\n    return filename.startswith('imet_xception')\n\nif(training):\n    model_files = list(filter(file_filter, os.listdir('..\/working\/')))\n    model_files = sorted(model_files)\n\n    weight_path = os.path.join(\"..\/working\/\", model_files[-1])\n    print(\"Current weight path for prediction: \", weight_path)\n    \n    model.load_weights(weight_path)","2f9d3bdb":"'''Search for the best threshold regarding the validation set'''\nBATCH = 512\ncheck_dataset = create_dataset(train_val_df['id'], categorical_labels, preproc_fn=val_preprocessing_fn, threads=2)\n\ncounter = 0\nn_val = round(len(train_val_df)*0.5\/\/BATCH)\nprint(n_val)\n\nlastFullValPred = np.empty((0, N_CLASSES))\nlastFullValLabels = np.empty((0, N_CLASSES))\n\nfor X, y in tqdm(check_dataset): \n    if(counter >= n_val):\n        break\n    else:\n        counter += 1\n    \n    y_pred = model.predict(X.numpy())\n    lastFullValPred = np.append(lastFullValPred, y_pred, axis=0)\n    lastFullValLabels = np.append(lastFullValLabels, y, axis=0)\n    \n\nprint(lastFullValPred.shape, lastFullValLabels.shape)","71bff57a":"beta_f2 = 2\ndef my_f2(y_true, y_pred):\n    assert y_true.shape[0] == y_pred.shape[0]\n\n    tp = np.sum((y_true == 1) & (y_pred == 1))\n    tn = np.sum((y_true == 0) & (y_pred == 0))\n    fp = np.sum((y_true == 0) & (y_pred == 1))\n    fn = np.sum((y_true == 1) & (y_pred == 0))\n    \n    p = tp \/ (tp + fp + K.epsilon())\n    r = tp \/ (tp + fn + K.epsilon())\n\n    f2 = (1+beta_f2**2)*p*r \/ (p*beta_f2**2 + r + 1e-15)\n\n    return f2\n\ndef find_best_fixed_threshold(preds, targs, do_plot=True):\n    score = []\n    thrs = np.arange(0, 0.5, 0.01)\n    for thr in tqdm(thrs):\n        score.append(my_f2(targs, (preds > thr).astype(int) ))\n    score = np.array(score)\n    pm = score.argmax()\n    best_thr, best_score = thrs[pm], score[pm].item()\n    print(f'thr={best_thr:.3f}', f'F2={best_score:.3f}')\n    if do_plot:\n        plt.plot(thrs, score)\n        plt.vlines(x=best_thr, ymin=score.min(), ymax=score.max())\n        plt.text(best_thr+0.03, best_score-0.01, f'$F_{2}=${best_score:.3f}', fontsize=14);\n        plt.show()\n    return best_thr, best_score","55433edc":"best_thr, best_score = find_best_fixed_threshold(lastFullValPred, lastFullValLabels, do_plot=True)","84ad598f":"def load_img(img_name):\n    path = '..\/input\/imet-2019-fgvc6\/test\/'+ img_name +\".png\"\n    img_string = tf.read_file(path)\n    img = tf.image.decode_png(img_string)\n    shape = tf.shape(img)  # Use dynamic shape, only known at runtime\n    tfwidth = tf.to_float(shape[1])\n    tfheight = tf.to_float(shape[0])\n\n    img = tf.cond(tf.math.logical_or(tfwidth\/tfheight > 3.0, tfwidth\/tfheight < 1\/3.0), \n            lambda: tf.image.random_crop(img, size=[300, 300, 3]), \n            lambda: img)\n    \n    img = tf.image.resize(img, (SIZE, SIZE))\n    img = tf.to_float(img) \/ 255.0\n    return img","de3e8415":"submit_ds = tf.data.Dataset.from_tensor_slices(submit['id'])\nsubmit_ds = submit_ds.apply(tf.data.experimental.map_and_batch(map_func=load_img, batch_size=BATCH_SIZE))","17114801":"predictions = model.predict_generator(submit_ds, steps = int(np.ceil(len(submit['id']) \/ BATCH_SIZE)), verbose=1)","6640c2d1":"label_indices = []\nfor raw_pred in predictions:\n    label_predict = np.arange(N_CLASSES)[raw_pred>=best_thr]\n    str_predict_label = ' '.join(str(l) for l in label_predict)\n    label_indices.append(str_predict_label)","ee7aa30f":"submit['attribute_ids'] = label_indices\nsubmit.to_csv('submission.csv', index=False)","e090f9f6":"submit['attribute_ids'].head()","6e0dede3":"submit['attribute_ids'].map(lambda row: len(row.split(\" \"))).value_counts()","93432981":"## 3.2. Call backs on training progress:","c13dc27c":"- An image with width >= height will have height = 300\n- An image with width <= height will have width = 300\n- Or we can say the min size of an image is always 300","e9bfcdb4":"## 2.3. Plot some images to see our augmentation","6cc939e6":"# 4. Prediction and submit","f99edb44":"## 1.1. Number of classes:\n- Number of classes = 1103, highly imbalanced between class labels","590dab90":"- This is a multi-label classification problem\n- The train_val_df below contain information about label of each classes, with key to map is the image id\n- Using a dataframe generated from: https:\/\/www.kaggle.com\/chewzy\/train-file-with-labels-and-meta-data\n- This contains more detailed information of an image","d00d394c":"# 3. Build the model:\n- We will use XCeption net with no top pretrain + some custom top layers\n- Loss: focal loss\n- Metrics: f2_score\n- We will warm up the training by freeze all the layers of Xception net and train only our custom ones\n- Finally, set all layers' trainability = True and fine tuning","2cf4e9e9":"## 3.3. Training:\n- We will first freeze convolution layer of exception nets and train only newly added ones. If we have custom weights that are already trained, the step is simply skipped.\n- Then the second steps is to set all the net layers to be trainable and fine tune with several epochs","17b6f032":"## 2.2. Some functions to create tf.data.Dataset","e2ffacd7":"### Image with aspect ratio (width \/ height) > 3 or < 1\/3:\n- They tends to have repetitive pattern","3f00900a":"- What about test set ? The same thing happen on test set, let see if our assumption is right","62256dd1":"# 2. Prepare tensorflow dataset:","f98b391e":"## Image processing strategy:\n- With image having size of aspect ratio > 3.0 or < 1\/3.0 will be crop to size 300x300 and then resized to target size 156x156\n- The others will be resized to 156x156 (no crop)","879f0951":"# 1. Explore data analysis:","e9b77dd5":"## 2.1. Encode label to categorical vector:\n- Each label of image will be represented as a vector of shape (1, N_CLASSES)","789b41de":"## 2.4. Function to generate Kfold cross validation data:","0f9390e4":"## 3.1. Model architecture:","461fe715":"## 1.2. Images' width and height:\n- All the images in the training set have width or height = 300. We're gonna prove it below"}}