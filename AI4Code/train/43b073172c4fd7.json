{"cell_type":{"d18137bf":"code","859c64c3":"code","e34af29f":"code","3e391846":"code","a4d435d0":"code","9422bd5f":"code","eeaa45d0":"code","829eedf8":"code","f83c0a02":"code","8530400c":"code","883bd7db":"code","3de1aba4":"code","03138cf1":"code","027b0bc7":"code","0aa22b20":"code","05f1f885":"markdown","4ec9c074":"markdown","36568fb3":"markdown","0b3d1276":"markdown"},"source":{"d18137bf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","859c64c3":"np.load('..\/input\/face_images.npz')['face_images'].shape","e34af29f":"# load the dataset\nPface = np.moveaxis(np.load('..\/input\/face_images.npz')['face_images'],-1,0)\nLMs = pd.read_csv('..\/input\/facial_keypoints.csv')\n\nLMpos=LMs.columns.tolist()\nprint(LMs.isnull().sum())","3e391846":"LMs.head()","a4d435d0":"LMs_mod = LMs.dropna()\nLMs_mod.info()\nprint()","9422bd5f":"idx = LMs_mod.index.tolist()\nlen(idx)","eeaa45d0":"Pface_mod = Pface[idx]\nPface_mod.shape","829eedf8":"import matplotlib.pyplot as plt\n\nplt.imshow(Pface_mod[0])\nplt.show()","f83c0a02":"# iselect=np.nonzero(LMs.left_eye_center_x.notna() & LMs.right_eye_center_x.notna() &\n#          LMs.nose_tip_x.notna() & LMs.mouth_center_bottom_lip_x.notna())[0]\n\nSpic=Pface_mod.shape[1]\n\nX = Pface_mod\/255.0\nY = LMs_mod.values\/Spic\n\nprint(Y.shape)","8530400c":"Y.min(), Y.max(), Spic","883bd7db":"import matplotlib.pyplot as plt\n\nn = 0\nnrows = 4\nncols = 4\nirand=np.random.choice(Y.shape[0],nrows*ncols)\nfig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True,figsize=[ncols*2,nrows*2])\nfor row in range(nrows):\n    for col in range(ncols):\n        ax[row,col].imshow(X[irand[n]], cmap='gray')\n        ax[row,col].scatter(Y[irand[n],0::2]*Spic,Y[irand[n],1::2]*Spic,marker='X',c='r',s=100)\n        ax[row,col].set_xticks(())\n        ax[row,col].set_yticks(())\n        ax[row,col].set_title('image index = %d' %(irand[n]),fontsize=10)\n        n += 1\n","3de1aba4":"# Split the dataset\nfrom sklearn.model_selection import train_test_split\n\nrandom_seed=21\nXtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=random_seed)","03138cf1":"Xtrain = np.expand_dims(Xtrain, -1)\nXtest = np.expand_dims(Xtest, -1)","027b0bc7":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, GlobalAveragePooling2D, SpatialDropout2D\nfrom keras.optimizers import SGD\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding = 'same', activation='relu', kernel_initializer=\"he_normal\", input_shape=(Spic, Spic, 1)))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(SpatialDropout2D(0.25))\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(256, activation='relu', kernel_initializer=\"he_normal\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(30, activation='sigmoid'))\n\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='mean_squared_error', optimizer=sgd)\n\nmodel.fit(Xtrain, Ytrain, batch_size=128, epochs=10, validation_data = (Xtest, Ytest), verbose = 1)","0aa22b20":"Ytrain_pred = model.predict(Xtrain)\nYtest_pred = model.predict(Xtest)\n\nn = 0\nnrows = 4\nncols = 4\nirand=np.random.choice(Ytest.shape[0],nrows*ncols)\nfig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True,figsize=[ncols*2,nrows*2])\nfor row in range(nrows):\n    for col in range(ncols):\n        ax[row,col].imshow(Xtest[irand[n]].squeeze(-1), cmap='gray')\n        ax[row,col].scatter(Ytest[irand[n],0::2]*Spic,Ytest[irand[n],1::2]*Spic,marker='X',c='r',s=100)\n        ax[row,col].scatter(Ytest_pred[irand[n],0::2]*Spic,Ytest_pred[irand[n],1::2]*Spic,marker='+',c='b',s=100)\n        ax[row,col].set_xticks(())\n        ax[row,col].set_yticks(())\n        ax[row,col].set_title('image index = %d' %(irand[n]),fontsize=10)\n        n += 1\nplt.suptitle('x: Manual; +: CNN', fontsize=16)","05f1f885":"Not bad for a first try. Lots of improvements possible.","4ec9c074":"I will only select the x and y of the eyes center, nose tip and mouth center, because these values are most avaiable. This gives 7000 images and X and Y are build to fit Keras format. Y is rescaled between 0 and 1.","36568fb3":"# Facial landmark detection with Keras CNN\n\nIn this kernel I used Keras to make a simple convolutional neural network (CNN) to detect the eyes, nose and mouth from this database.","0b3d1276":"The model I used is a very simple CNN just to try if it works. I used the sigmoid activation for the output layer because this produces an output between 0 and 1 and because it is not a classification problem. Softmax is not usefull."}}