{"cell_type":{"be8bcdb7":"code","05944a6f":"code","4adabe54":"code","8da288bb":"code","1d6483ee":"code","1c11c770":"code","cad22569":"code","66e98f7c":"code","8f5b9b33":"code","2aac39f7":"code","9170532f":"code","070f345c":"code","b50a3312":"code","cb88766e":"code","48d5c302":"code","4bf07679":"code","0accf5bc":"code","d6f3f4af":"code","c6293125":"code","f3be7e49":"code","11a69cb3":"markdown","6ef097a3":"markdown","a399172e":"markdown","cb3e1b4d":"markdown"},"source":{"be8bcdb7":"!pip install git+https:\/\/github.com\/darecophoenixx\/wordroid.sblo.jp","05944a6f":"from feature_eng import lowcols","4adabe54":"%matplotlib inline\nfrom IPython.display import SVG, Image\nfrom keras.utils.vis_utils import model_to_dot\n\nimport os.path\nimport sys\nimport re\nimport itertools\nimport csv\nimport datetime\nimport pickle\nimport random\nfrom collections import defaultdict, Counter\nimport gc\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import NullFormatter\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport scipy\nimport gensim\nfrom sklearn.metrics import f1_score, classification_report, confusion_matrix, log_loss\nfrom sklearn.model_selection import train_test_split\nimport gensim\nfrom keras.preprocessing.sequence import skipgrams\nimport tensorflow as tf","8da288bb":"def hexbin(x, y, color, **kwargs):\n    cmap = sns.light_palette(color, as_cmap=True)\n    plt.hexbin(x, y, cmap=cmap, **kwargs)\ndef scatter(x, y, color, **kwargs):\n    plt.scatter(x, y, marker='.')","1d6483ee":"X_df = pd.read_csv('..\/input\/sample-data-wordanddoc2vec\/sample009.csv', index_col=0)\nX_df_user_group = pd.read_csv('..\/input\/sample-data-wordanddoc2vec\/sample009_user_group.csv', index_col=0)\nX_df_brand_group = pd.read_csv('..\/input\/sample-data-wordanddoc2vec\/sample009_brand_group.csv', index_col=0)\nX_df","1c11c770":"plt.figure(figsize=(15, 15))\nplt.imshow(X_df.values.T)","cad22569":"wd2v = lowcols.WD2vec(X_df)\nwd2v","66e98f7c":"# num_features = 2\n\n# models = wd2v.make_model(num_features=num_features, seed=101, embeddings_val=0.2)\n\n# print('\\n\\n##################### model_gk1 >>>')\n# models['model_gk1'].summary()\n# print('\\n\\n##################### model_user >>>')\n# models['model_user'].summary()\n# print('\\n\\n##################### model >>>')\n# model = models['model']\n# model.summary()","8f5b9b33":"num_features = 2\n\nfrom sklearn import decomposition\npca = decomposition.PCA(n_components=num_features)\npca.fit(X_df)\nrscore = pca.transform(X_df) \/ 5\nprint(rscore.shape)\n\n#cscore = pca.components_.T \/ 3\ncscore = np.zeros((0,num_features))\nfor icol in X_df:\n    v = X_df[icol]\n    tmp = rscore[v==1].mean(axis=0, keepdims=True)\n    cscore = np.r_[cscore, tmp]\nprint(cscore.shape)\n\nmodels = wd2v.make_model(num_features=num_features, rscore=rscore, cscore=cscore)\n\nprint('\\n\\n##################### model_gk1 >>>')\nmodels['model_gk1'].summary()\nprint('\\n\\n##################### model_user >>>')\nmodels['model_user'].summary()\nprint('\\n\\n##################### model >>>')\nmodel = models['model']\nmodel.summary()","2aac39f7":"wgt_lm = wd2v.get_wgt_bycol()\nprint(wgt_lm.shape)\ndf = pd.DataFrame(wgt_lm[:,:5])\nsns.set_context('paper')\ng = sns.PairGrid(df, height=3.5)\ng.map_diag(plt.hist, edgecolor=\"w\")\ng.map_lower(scatter)\ng.map_upper(hexbin)","9170532f":"wgt_user = wd2v.get_wgt_byrow()\n# wgt_user = model.get_layer('user_embedding').get_weights()[0]\nprint(wgt_user.shape)\ndf = pd.DataFrame(wgt_user[:,:5])\nsns.set_context('paper')\ng = sns.PairGrid(df, height=3.5)\ng.map_diag(plt.hist, edgecolor=\"w\")\ng.map_lower(scatter)\ng.map_upper(hexbin)","070f345c":"%%time\nhst, hst2 = wd2v.train(epochs=500, batch_size=32, verbose=0, lr0=0.001)\nhst_history = hst.history","b50a3312":"fig, ax = plt.subplots(1, 3, figsize=(20,5))\nax[0].set_title('loss')\nax[0].plot(list(range(len(hst_history[\"loss\"]))), hst_history[\"loss\"], label=\"Train loss\")\nax[1].set_title('acc')\nax[1].plot(list(range(len(hst_history[\"loss\"]))), hst_history[\"binary_accuracy\"], label=\"accuracy\")\nax[2].set_title('learning rate')\nax[2].plot(list(range(len(hst_history[\"loss\"]))), hst_history[\"lr\"], label=\"learning rate\")\nax[0].legend()\nax[1].legend()\nax[2].legend()","cb88766e":"fig, ax = plt.subplots(1, 3, figsize=(20,5))\nax[0].set_title('loss')\nax[0].plot(list(range(len(hst2.history[\"loss\"]))), hst2.history[\"loss\"], label=\"Train loss\")\nax[1].set_title('acc')\nax[1].plot(list(range(len(hst2.history[\"loss\"]))), hst2.history[\"binary_accuracy\"], label=\"accuracy\")\nax[2].set_title('learning rate')\nax[2].plot(list(range(len(hst2.history[\"loss\"]))), hst2.history[\"lr\"], label=\"learning rate\")\nax[0].legend()\nax[1].legend()\nax[2].legend()","48d5c302":"# %%time\n# hst = wd2v.train2(epochs=150, batch_size=32, verbose=0, lr0=0.001, flag_early_stopping=False, shuffle=False)\n# hst_history = hst.history","4bf07679":"# fig, ax = plt.subplots(1, 3, figsize=(20,5))\n# ax[0].set_title('loss')\n# ax[0].plot(list(range(len(hst_history[\"loss\"]))), hst_history[\"loss\"], label=\"Train loss\")\n# ax[1].set_title('acc')\n# ax[1].plot(list(range(len(hst_history[\"loss\"]))), hst_history[\"binary_accuracy\"], label=\"accuracy\")\n# ax[2].set_title('learning rate')\n# ax[2].plot(list(range(len(hst_history[\"loss\"]))), hst_history[\"lr\"], label=\"learning rate\")\n# ax[0].legend()\n# ax[1].legend()\n# ax[2].legend()","0accf5bc":"wgt_prod = wd2v.get_wgt_bycol()\nprint(wgt_prod.shape)\ndf = pd.DataFrame(wgt_prod[:,:5])\ndf['brand_group'] = ['brand_group'+str(ii) for ii in X_df_brand_group['0'].values]\nsns.pairplot(df, markers='o', height=3.5, diag_kind='hist', hue='brand_group')","d6f3f4af":"wgt_user = wd2v.get_wgt_byrow()\nprint(wgt_user.shape)\ndf = pd.DataFrame(wgt_user[:,:5])\ndf['brand_user_group'] = ['group' + str(ee) for ee in X_df_user_group['0'].values]\nsns.pairplot(df, markers='o', hue='brand_user_group', height=3.5, diag_kind='hist',\n             hue_order=['group'+str(ii) for ii in np.unique(X_df_user_group['0'].values)])","c6293125":"df1 = pd.DataFrame(wgt_prod)\ndf1['brand_group'] = ['group' + str(ee) for ee in X_df_brand_group['0'].values]\ndf2 = pd.DataFrame(wgt_user)\ndf2['brand_group'] = ['user_group' + str(ee) for ee in X_df_user_group['0'].values]\ndf = pd.concat([df2, df1])\n\nplt.figure(figsize=(15,15))\nax = sns.kdeplot(data=df2, x=0, y=1,\n                 levels=5, thresh=.1, hue='brand_group',\n                 hue_order=['user_group'+str(ee) for ee in np.unique(X_df_user_group['0'].values)])\nfor ee in df1.iterrows():\n    ax.scatter(ee[1][0], ee[1][1], s=200, marker='X')\nax","f3be7e49":"plt.figure(figsize=(10,10))\nax = sns.kdeplot(data=df2, x=0, y=1,\n                 levels=5, thresh=.1, hue='brand_group',\n                 hue_order=['user_group'+str(ee) for ee in np.unique(X_df_user_group['0'].values)])\nfor ee in df1.iterrows():\n    ax.scatter(ee[1][0], ee[1][1], s=200, marker='X')\nax","11a69cb3":"# WordAndDoc2vec","6ef097a3":"[WordAndDoc2vec](https:\/\/github.com\/darecophoenixx\/wordroid.sblo.jp\/wiki\/WordAndDoc2vec)","a399172e":"# load sample data","cb3e1b4d":"### train"}}