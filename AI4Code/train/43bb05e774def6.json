{"cell_type":{"65c36366":"code","9a7136f4":"code","2cf00961":"code","adb3525d":"code","016ffda0":"code","44385f33":"code","5876c97d":"code","c4cd3d66":"code","38ab1c5d":"code","a0df5414":"code","06b94dc9":"code","df694d5a":"code","ea067409":"code","6854ae96":"code","89a943be":"code","c0438df0":"code","34c1f245":"code","889fabed":"markdown","828c4ee9":"markdown","9551bf97":"markdown","6c8aa08a":"markdown","8e714ddc":"markdown","64630627":"markdown","678a49cb":"markdown","9beea320":"markdown","ac061c98":"markdown","6a01a642":"markdown","386f9841":"markdown","5357926c":"markdown","7342a5b4":"markdown","5d97a4e3":"markdown","f9421aac":"markdown","49c4395a":"markdown","7400f455":"markdown","b9462591":"markdown"},"source":{"65c36366":"import pandas as pd\nimport nltk, re, string, collections\nfrom nltk.util import ngrams # function for making ngrams\nimport re\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nfrom nltk.tokenize import word_tokenize","9a7136f4":"df = pd.read_csv('\/kaggle\/input\/coronawhy\/dataset_v6.csv')","2cf00961":"df['text'] = df['text'].astype(str)\ndf['text'] = df['text'].str.lower()","adb3525d":"filter_keywords = ['age']\ndf = df[df['text'].str.contains('|'.join(filter_keywords))]","016ffda0":"text_to_search = ' '.join(df[\"text\"])","44385f33":"del df","5876c97d":"# get rid of punctuation\npunctuationNoPeriod = \"[\" + re.sub(\"\\.\",\"\",string.punctuation) + \"]\"\ntext_to_search = re.sub(punctuationNoPeriod, \"\", text_to_search)","c4cd3d66":"# let's remove stop words\n# we will use the stop words provided by the NLTK\n# we will also add in some customized stop words used in other places for COVID-19\n\ncustomized_stop_words = [\n    'doi', 'preprint', 'copyright', 'peer', 'reviewed', 'org', 'https', 'et', 'al', 'author', 'figure', \n    'rights', 'reserved', 'permission', 'used', 'using', 'biorxiv', 'fig', 'fig.', 'al.', 'q', 'license',\n    'di', 'la', 'il', 'del', 'le', 'della', 'dei', 'delle', 'una', 'da',  'dell',  'non', 'si', 'holder',\n    'p', 'h'\n]\n\nstop_words = list(stopwords.words('english')) + customized_stop_words\nprint(stop_words)","38ab1c5d":"# let's tokenize the words\ntext_tokens = word_tokenize(text_to_search)\ntext_to_search = [word for word in text_tokens if not word in stop_words]","a0df5414":"# and get a list of all the bigrams\nesBigrams = ngrams(text_to_search, 2)\n\n# get the frequency of each bigram in our corpus\nesBigramFreq = collections.Counter(esBigrams)\n\n# what are the ten most popular bigrams\nesBigramFreq.most_common(25)","06b94dc9":"# and get a list of all the trigrams\nesTrigrams = ngrams(text_to_search, 3)\n\n# get the frequency of each trigram in our corpus\nesTrigramFreq = collections.Counter(esTrigrams)\n\n# what are the ten most popular trigrams\nesTrigramFreq.most_common(25)","df694d5a":"del esBigrams\ndel esBigramFreq\ndel esTrigrams\ndel esTrigramFreq","ea067409":"search_for_word = 'age' # Text we want the Bi\/Trigrams to contain\n\n# reset the Bigrams\nesBigrams = ngrams(text_to_search, 2)\nesBigramFreq = collections.Counter(esBigrams)","6854ae96":"for gram, freq in esBigramFreq.most_common():\n    if gram[0] == search_for_word or gram[1] == search_for_word:\n        print(gram, freq)","89a943be":"del esBigrams\ndel esBigramFreq","c0438df0":"# reset the Trigrams\nesTrigrams = ngrams(text_to_search, 3)\nesTrigramFreq = collections.Counter(esTrigrams)","34c1f245":"for gram, freq in esTrigramFreq.most_common():\n    if gram[0] == search_for_word or gram[1] == search_for_word or gram[2] == search_for_word:\n        print(gram, freq)","889fabed":"### Setting this column as text column to make the data easier to process.","828c4ee9":"### Removing stop words.  We'll use the English stop words from NLTK plus some customized stop words we've been using for COVID-19","9551bf97":"### Filter the data by keywords.  This is recommended because there is a LOT of data to parse through.  In this section we will filter the data by anything that contains the word 'age'.","6c8aa08a":"### Clean up memory again","8e714ddc":"### Now we'll start with Bigrams.","64630627":"### Cleaning up some RAM here since we don't have unlimited memory with Kaggle","678a49cb":"### Let's tokenize the text and remove the stop words (this takes a while depending on the size of the data)","9beea320":"### Now let's show the Trigrams containing our search word","ac061c98":"### Combining the text to search so we can process it for later.","6a01a642":"### Now let's look at Trigrams.","386f9841":"### Let's import all the tools we will need","5357926c":"### Removing punctuation since we don't need that for N-grams.","7342a5b4":"# COVID-19 CoronaWhy NLP N-grams (Bigrams & Trigrams)","5d97a4e3":"### Now we will look for Bigrams and Trigrams with specific words.","f9421aac":"### Now we will load the data from one of our CoronaWhy datasets.","49c4395a":"### Now let's show the Bigrams containing our search word","7400f455":"### Now that we have our text loaded, let's delete the data frame to save some memory","b9462591":"Memory is a concern for this task so you'll see a few instances of some memory clean ups."}}