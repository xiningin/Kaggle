{"cell_type":{"e0d45a80":"code","0a1628c0":"code","bef0749e":"code","238cb78a":"code","9fe4fd11":"code","b6d8c3a2":"code","fe454445":"code","def2e62f":"code","fc242d46":"code","0c1540c2":"code","491ad726":"code","ae227769":"code","74ead3eb":"code","14cf2822":"code","f61463c5":"code","c7602ce7":"code","9cce3192":"code","81f33817":"code","1e43a574":"code","3b529c2f":"code","e751b071":"code","6abef0c0":"code","8bad4272":"code","d295d2fb":"code","bd018d1c":"code","f4c0bed0":"code","d3ba7bc9":"code","35e21774":"code","2e3d5a29":"code","818d776c":"code","605da41f":"code","c0b641b4":"code","253299ce":"code","50f51174":"code","93b25e2e":"code","005ae1cd":"code","24a28337":"code","be2dd213":"code","489e0a59":"code","11dbc054":"code","f5fdf877":"code","d1153696":"code","86858662":"code","94d6f58e":"code","0f773db8":"code","fbf48443":"code","9e855ac2":"code","6120a897":"code","15d1c0de":"code","5bbea1f1":"code","52563225":"code","c6a7160b":"code","1030196a":"code","59484714":"code","e23fc424":"code","65e8411a":"code","c18a8621":"code","1ebdbded":"code","c74b8f15":"code","884e6086":"code","80db6edc":"code","7d4e6d77":"code","68d84e35":"code","115bfeac":"code","182ae04c":"code","20596270":"code","d8f4d734":"markdown","936c4d01":"markdown","3ca55b8a":"markdown","85fb81de":"markdown","35f535c9":"markdown","b96cecaa":"markdown","fd9d2023":"markdown","fc9b739b":"markdown","04f8e940":"markdown","a6bbdfe5":"markdown","0309b885":"markdown","bb13379f":"markdown","aff65fe0":"markdown","8f5d570b":"markdown","c1e7e269":"markdown","470546bf":"markdown","878a9b96":"markdown","c87e361f":"markdown","a33d8b61":"markdown","7a103200":"markdown","5b97348b":"markdown","404e825e":"markdown","2a8721f0":"markdown","430e2a95":"markdown","67916b07":"markdown","0158c3a5":"markdown","018ec807":"markdown","a28427dd":"markdown","99509628":"markdown","1cbcd428":"markdown","af428503":"markdown","82a26b95":"markdown","914c43bf":"markdown","d6db8986":"markdown","a900b110":"markdown","a4e0efb9":"markdown","63db493d":"markdown","6f4ecfff":"markdown","9af7b472":"markdown","70345b00":"markdown","b38f4795":"markdown","85088b0a":"markdown","6628fa64":"markdown","06d0caa7":"markdown"},"source":{"e0d45a80":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0a1628c0":"#Returns Model Metrics Scores\n\ndef Scores(model,y_test,y_pred):\n    print(model)\n    print('---------------\\n')\n    print('Accuracy : ',accuracy_score(y_test,y_pred))\n    print('Precision : ',precision_score(y_test,y_pred))\n    print('Recall : ',recall_score(y_test,y_pred))\n    print('F1 : ',f1_score(y_test,y_pred))\n    print('Area Under ROC : ',roc_auc_score(y_test,y_pred))\n    print('Error : ',np.sqrt(mean_squared_error(y_test,y_pred)))\n    print(confusion_matrix(ytest,y_pred))","bef0749e":"#Plots Traning VS Validation Scores For a Model\n\nfrom sklearn.model_selection import learning_curve\ndef learningCurve(model,title,X,y,ax):\n    train_sizes,train_score,test_score=learning_curve(model,X,y)\n    train_scores_mean=np.mean(train_score,axis=1)\n    test_scores_mean=np.mean(test_score,axis=1)\n    train_scores_std=np.std(train_score,axis=1)\n    test_scores_std=np.std(test_score,axis=1)\n    \n    ax.grid()\n    ax.set_title(title,color='white')\n    ax.plot(train_sizes,train_scores_mean,'o-',color='r',label='Training Curve')\n    ax.plot(train_sizes,test_scores_mean,'o-',color='g',label='Cross Val Curve')\n    ax.fill_between(train_sizes, train_scores_mean - train_scores_std,train_scores_mean + train_scores_std, alpha=0.1,color=\"r\")\n    ax.fill_between(train_sizes, test_scores_mean - test_scores_std,test_scores_mean + test_scores_std, alpha=0.1,color=\"g\")\n    ax.tick_params(axis='x', colors='white')\n    ax.tick_params(axis='y', colors='white')\n    ax.set_xlabel(\"Training examples\",color=\"white\")\n    ax.set_ylabel(\"Score\",color=\"white\")\n    ax.legend(loc=\"best\")","238cb78a":"test=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","9fe4fd11":"train=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntrain.head()","b6d8c3a2":"train.isnull().sum()","fe454445":"train['title']=train.Name.map(lambda i : i.split(\".\")[0].split(' ')[1])\ntrain['title'].value_counts()","def2e62f":"train['title']=train['title'].map(lambda i: i if i in ['Mr','Master','Miss','Mrs'] else 'Rare')","fc242d46":"train['title'].value_counts()","0c1540c2":"sns.countplot(x='title',data=train,hue='Survived')","491ad726":"test['title']=test.Name.map(lambda i : i.split(\".\")[0].split(' ')[1])\ntest['title']=test['title'].map(lambda i: i if i in ['Mr','Master','Miss','Mrs'] else 'Rare')","ae227769":"train['family']=train['SibSp']+train['Parch']+1","74ead3eb":"sns.barplot(x=train['family'],y='Survived',data=train)","14cf2822":"train['SmallF']=train['family'].map(lambda i: 1 if i==1 else 0)\ntrain['MidF']=train['family'].map(lambda i: 1 if 2<=i<=4 else 0)\ntrain['LargeF']=train['family'].map(lambda i: 1 if i>=5 else 0)","f61463c5":"test['family']=test['SibSp']+test['Parch']+1\ntest['SmallF']=test['family'].map(lambda i: 1 if i==1 else 0)\ntest['MidF']=test['family'].map(lambda i: 1 if 2<=i<=4 else 0)\ntest['LargeF']=test['family'].map(lambda i: 1 if i>=5 else 0)","c7602ce7":"sns.distplot(train['Age'],label='Skew %.2f' % train['Age'].skew()).legend(loc='best')","9cce3192":"Age_cat=[]\ndef cat(x):\n    if x<=18:\n        Age_cat.append('Young')\n    if 18<x<=37:\n        Age_cat.append('Mid')\n    if 37<x<=60:\n        Age_cat.append('Ret')\n    else:\n        Age_cat.append('Old')\ntrain['Age'].map(cat)","81f33817":"Age_cat=pd.Series(Age_cat)","1e43a574":"sns.barplot(x=Age_cat,y=train['Survived'])","3b529c2f":"sns.distplot(train['Fare'],label=\"Skewness: %f\" % (train['Fare'].skew())).legend(loc='best')","e751b071":"fare_unskwed=train['Fare'].map(lambda i : np.log(i) if i>0 else 0)\ntrain['fare_unskewed']=fare_unskwed\nsns.distplot(fare_unskwed,label=\"Skewness: %f\" % (fare_unskwed.skew())).legend(loc='best')","6abef0c0":"fare_unskwed_test=test['Fare'].map(lambda i : np.log(i) if i>0 else 0)\ntest['fare_unskewed']=fare_unskwed_test","8bad4272":"train['Cabin'].fillna('X',inplace=True)\ncabin=train['Cabin'].map(lambda i: i[0])\ntrain['Cabin_pre']=cabin","d295d2fb":"sns.barplot(x='Cabin_pre',y='Survived',data=train)","bd018d1c":"train['Cabin_pre']=train['Cabin_pre'].map(lambda i: 'X' if i in ['X','G','T'] else i)","f4c0bed0":"test['Cabin'].fillna('X',inplace=True)\ncabin_test=test['Cabin'].map(lambda i: i[0])\ntest['Cabin_pre']=cabin_test\ntest['Cabin_pre']=test['Cabin_pre'].map(lambda i: 'X' if i in ['X','G','T'] else i)","d3ba7bc9":"train['Embarked'].mode()","35e21774":"train['Embarked'].fillna('S',inplace=True)","2e3d5a29":"sns.barplot(x=train['Embarked'],y='Survived',hue='Pclass',data=train)","818d776c":"test['Embarked'].fillna('S',inplace=True)","605da41f":"train['Ticket'].value_counts()","c0b641b4":"tickets_nums=train['Ticket'].map(lambda i: i.split(' ')[1] if len(i.split(' '))>1 else i)\ntic_cat=tickets_nums.map(lambda i: i[0])\ntic_cat.value_counts()","253299ce":"sns.barplot(x=tic_cat,y=train['Survived'])","50f51174":"tic_catF=tic_cat.map(lambda i : 'Class1&2' if i=='1' or i=='2' else 'ClassLow')","93b25e2e":"sns.barplot(x=tic_catF,y=train['Survived'])","005ae1cd":"train['ticketClass']=tic_catF.map(lambda i : 1 if i=='Class1&2' else 0)","24a28337":"test_tickets_nums=test['Ticket'].map(lambda i: i.split(' ')[1] if len(i.split(' '))>1 else i)\ntest_tic_cat=test_tickets_nums.map(lambda i: i[0])\ntest_tic_catF=test_tic_cat.map(lambda i : 'Class1&2' if i=='1' or i=='2' else 'ClassLow')\ntest['ticketClass']=test_tic_catF.map(lambda i : 1 if i=='Class1&2' else 0)","be2dd213":"train.head()","489e0a59":"corr=train.corr()\ncorr.Survived.sort_values(ascending=False)","11dbc054":"X_test=test.drop(['Fare','Name','Ticket','Cabin'],axis=1)","f5fdf877":"y_train=train.Survived\nX_train=train.drop(['Fare','Name','Ticket','Cabin','Survived'],axis=1)\nX_train.head()","d1153696":"sns.heatmap(X_train[['Age','Pclass','Parch','SibSp','fare_unskewed']].corr(),annot=True,fmt=\".2f\")","86858662":"X_train.info()","94d6f58e":"X_train.drop('PassengerId',axis=1,inplace=True)","0f773db8":"PassengerId_test=X_test.PassengerId\nX_test.drop('PassengerId',axis=1,inplace=True)","fbf48443":"from sklearn.preprocessing import StandardScaler,LabelEncoder,OrdinalEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer","9e855ac2":"ct=ColumnTransformer([\n    ('rel',SimpleImputer(strategy='mean'),list(X_train.drop(['Sex','Embarked','title','Cabin_pre'],axis=1))),\n    ('cat',OrdinalEncoder(),['Sex','Embarked','title','Cabin_pre'])\n])","6120a897":"X_train_prepared=ct.fit_transform(X_train)\nnum_cols=list(X_train.drop(['Sex','Embarked','title','Cabin_pre'],axis=1))\ncat_cols=['Sex','Embarked','title','Cabin_pre']\nnum_cols.extend(cat_cols)\nX_train_prepared=pd.DataFrame(X_train_prepared,columns=num_cols)\nX_train_prepared.head()","15d1c0de":"    X_test_prepared=ct.fit_transform(X_test)","5bbea1f1":"from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score,roc_auc_score,mean_squared_error,confusion_matrix,auc,roc_curve,make_scorer\nfrom sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score","52563225":"Xtrain,Xtest,ytrain,ytest=train_test_split(X_train_prepared,y_train,test_size=0.2,random_state=42)","c6a7160b":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier,ExtraTreesClassifier","1030196a":"def classifierScores(classifiers,scorer,scorer_label,Algo_names,X,y):\n    cv_results=[]\n\n    for classifier in classifiers:\n        cv_results.append(cross_val_score(classifier,X,y,scoring=scorer,n_jobs=-1))\n    \n    cv_means,cv_stds=[],[]\n    for cv_result in cv_results:\n        cv_means.append(cv_result.mean())\n        cv_stds.append(cv_result.std())\n        \n    cv_data=pd.DataFrame({'CVmeans':cv_means,\n                          'CVerrors':cv_stds,\n                          'Algo':Algo_names\n                         })\n    \n    g=sns.barplot('CVmeans','Algo',data=cv_data,orient='h',**{'xerr':cv_stds})\n    g.set_xlabel(scorer_label)\n    g=g.set_title('Cross Val Scores')","59484714":"classifiers=[LogisticRegression(),SVC(),\n             KNeighborsClassifier(),DecisionTreeClassifier(),\n             RandomForestClassifier(),BaggingClassifier(),\n             AdaBoostClassifier(),GradientBoostingClassifier(),\n             ExtraTreesClassifier()\n            ]\nscorer=make_scorer(roc_auc_score)","e23fc424":"classifierScores(classifiers,scorer,\n                 'Mean ROC_AUC',\n                 [\n                  \"LogisticRegression\",\"SVC\",\n                    \"KNeighborsClassifier\",\"DecisionTreeClassifier\",\n                    \"RandomForestClassifier\",\"BaggingClassifier\",\n                    \"AdaBoostClassifier\",\"GradientBoostingClassifier\",\n                    \"ExtraTreesClassifier\"\n                ],\n                X_train_prepared,\n                y_train\n                )","65e8411a":"def gridSearch(model,param):\n    gs=GridSearchCV(model,param_grid=param,n_jobs=-1)\n    gs.fit(Xtrain,ytrain)\n    print(gs.best_estimator_)","c18a8621":"gridSearch(LogisticRegression(max_iter=500),{'C':[6,6.6,7]})","1ebdbded":"gridSearch(RandomForestClassifier(n_jobs=-1,random_state=42),{'n_estimators':[390,400,410],\n                                                              'criterion':['gini','entropy'],\n                                                              'max_depth':[9,10,11],\n                                                              'min_samples_split':[9,10,11]\n                                                             })","c74b8f15":"gridSearch(BaggingClassifier(n_jobs=-1,random_state=42),{'base_estimator':[None,LogisticRegression()],\n                                                        'max_samples':[0.1,0.2,0.3,0.5,0.7]\n                                                        })","884e6086":"gridSearch(AdaBoostClassifier(random_state=42),{\n                                                    'n_estimators':[65,70,75],\n                                                    'learning_rate':[0.15,0.20,0.25]\n                                                })","80db6edc":"gridSearch(GradientBoostingClassifier(random_state=42),{'loss':['deviance', 'exponential'],\n                                                         'learning_rate':[0.1,0.2,0.3],\n                                                        'n_estimators':[110,120,130],\n                                                        'min_samples_split':[2,3,4],\n                                                        'max_depth':[2,3,4,5]\n                                                       })","7d4e6d77":"classifiers_final=[LogisticRegression(C=6.6, max_iter=400),\n                   RandomForestClassifier(criterion='entropy', max_depth=10, min_samples_split=10,\n                       n_estimators=400, n_jobs=-1, random_state=42),\n                   BaggingClassifier(base_estimator=LogisticRegression(), max_samples=0.2,\n                        n_jobs=-1, random_state=42),\n                   AdaBoostClassifier(learning_rate=0.2, n_estimators=70, random_state=42),\n                   GradientBoostingClassifier(loss='exponential', min_samples_split=3,\n                           n_estimators=120, random_state=42)\n                  ]\n\nclassifierScores(classifiers_final,scorer,\n                 'Mean ROC_AUC',\n                 [\n                  \"LogisticRegression\",\n                    \"RandomForestClassifier\",\n                    \"BaggingClassifier\",\n                    \"AdaBoostClassifier\",\n                    \"GradientBoostingClassifier\"\n                ],\n                 X_train_prepared,\n                y_train\n                )","68d84e35":"figure,((ax1,ax2),(ax3,ax4),(ax5,ax6))=plt.subplots(3,2,figsize=(15,7))\nlearningCurve(LogisticRegression(C=6.6, max_iter=500),'Logistic Regession',X_train_prepared,y_train,ax1)\nlearningCurve(RandomForestClassifier(criterion='entropy', max_depth=10, min_samples_split=10,\n                       n_estimators=400, n_jobs=-1, random_state=42),'Random Forest',X_train_prepared,y_train,ax2)\nlearningCurve(BaggingClassifier(base_estimator=LogisticRegression(), max_samples=0.2,\n                        n_jobs=-1, random_state=42),'Bagging Clf',X_train_prepared,y_train,ax3)\nlearningCurve(AdaBoostClassifier(learning_rate=0.2, n_estimators=70, random_state=42),'Ada Bosst',X_train_prepared,y_train,ax4)\nlearningCurve(GradientBoostingClassifier(loss='exponential', min_samples_split=3,\n                           n_estimators=120, random_state=42),'Gradient Boosting',X_train_prepared,y_train,ax5)","115bfeac":"from sklearn.ensemble import VotingClassifier\nesti=[('lr',LogisticRegression(C=6.6, max_iter=500)),\n       ('rndForest',RandomForestClassifier(criterion='entropy', max_depth=10, min_samples_split=10,\n                       n_estimators=400, n_jobs=-1, random_state=42)),\n        ('bgg_clf',BaggingClassifier(base_estimator=LogisticRegression(), max_samples=0.2,\n                        n_jobs=-1, random_state=42)),\n        ('Adb_clg',AdaBoostClassifier(learning_rate=0.2, n_estimators=70, random_state=42)),\n        ('Gb_clf',GradientBoostingClassifier(loss='exponential', min_samples_split=3,\n                           n_estimators=120, random_state=42))\n    ]\nvc=VotingClassifier(estimators=esti,n_jobs=-1,voting='soft')\nvc.fit(Xtrain,ytrain)\ny_pred_vc=vc.predict(Xtest)\nScores('Voting Classifier',ytest,y_pred_vc)","182ae04c":"from collections import Counter\ndf=X_train_prepared\noutlier_indices=[]\nfor col in ['Age','Parch','SibSp','fare_unskewed']:\n    Q1=np.percentile(df[col],25)\n    Q3=np.percentile(df[col],75)\n    IQR=Q3-Q1\n    outlier_step=1.5*IQR\n    outlier_list_col=df[(df[col]<Q1-outlier_step) | (df[col]>Q3+outlier_step)].index\n    outlier_indices.extend(outlier_list_col)\noutlier_indices=Counter(outlier_indices)\nmultipal_outliers=list(k for k,v in outlier_indices.items() if v>2)\nprint(multipal_outliers)","20596270":"X_train_prepared.loc[multipal_outliers]","d8f4d734":"*Here 'X' , 'G' ,'T' do not have much effect so we add them.*","936c4d01":"1. Logistic Regression","3ca55b8a":"* As a concluding step i used VotingClassifier to combine all the Individual Classifiers","85fb81de":"3. Age ","35f535c9":"# Modeling","b96cecaa":"* This is the most difficult col to extract relation from, after much brain storming, i tried to categorize Tickets via category classes like class that has '1' in its start i.e values which has Ticket number '1*****' and similarly for others.","fd9d2023":"*As we can see there are many Titles which appear rarely so we will categorize them as 'Rare'*","fc9b739b":"# Functions To Help In Model Selection","04f8e940":"# Feature Preparation","a6bbdfe5":"* Fare is skewed feature so we can apply 'log Transformation' to it as skewness can cause unwanted weight distribution","0309b885":"4. Fare","bb13379f":"* Finally, We Plot There Learning Curves To Check For OverFitting VS UnderFitting","aff65fe0":"*Here we can see that Title 'Mr' has much higher Death rate, so yes we have a new feature here*","8f5d570b":"*Here we can see that medium family has greater survival rate, so we can categorize them*","c1e7e269":"*Transformation Removes Col Names So we add them Back*","470546bf":"# Feature Generation","878a9b96":"* Here we Apply Simple Imputer for 'Age' and Ordinal Encoder for 'Sex','Embarked','title' and 'Cabin_pre'","c87e361f":"* Here i Choose Most Popular Classification Algos and Compared there performance based on ROC_AUC","a33d8b61":"*Here we will try to extract as many meaningfull features from the pre define features which are not of much use as provived.*","7a103200":"6. Embarked ","5b97348b":"* Age, Canbin and Embarked have missing values so we need to handel them as well","404e825e":"**I tried the outlier process but it was not much effective so i ended the NoteBook here 'cause i am LAZY AF, the Scores can be 'Improved' by investing some more time **","2a8721f0":"* The Models which performed best are chosen for Grid Search","430e2a95":"# Ensemble","67916b07":"*Here we check the Skewness of the distribution which seems to be fine, so we can't do much here*","0158c3a5":"1. **Title**","018ec807":"*More Class 1 People Borded From Harbour 'C', and Class 1 people have more Survival Rate, where as Class 3 the least *","a28427dd":"* Filling missing Cabin values by 'X' and Trying to extract the first letter of Cabin 'cause Cabins in Ships are categorized 'Alphabetically'","99509628":"*Looks Great, Lets checkout via Visualization*","1cbcd428":"7. Tickets ","af428503":"*The technique used classifies an instance if it has two or more outliers, a value is considered outlier if its is less tham Q1 - 1.5 x IQR or its greater than Q3 + 1.5 x IQR, more outlier detection methods are avaliable but this is simplest for begginers to understand if you know \"Percenticles\"* ","82a26b95":"*Skewness is reduced by log Transformation, other Transformations can provied better results.*","914c43bf":"* In the 'Name' col we can see that every name has a 'Title' to it eg. Mr., Mrs. etc. These can be helpfull lets try to extract them ","d6db8986":"# Hope you Liked It, comment for suggestion. BTW i am a biggner myself, xD","a900b110":"* The cols 'SibSp' and 'Parch' can be added to form a new feature 'Family'","a4e0efb9":"*We can see that class 1&2 has appreciable survival so lets categorize futher*","63db493d":"* Here we try to identify outliers for futher inprovement for models","6f4ecfff":"* Here i tried to find some relation via categorization buts its not too prominent so i didn't applied it.\nBut via further inspection improvement can be made on this feature","9af7b472":"5. Cabin","70345b00":"*Looks Good, but not much confident about it*","b38f4795":"*Lets Checkout Co-Realation*","85088b0a":"# Further Improvement","6628fa64":"* Filling the missing values in Embarked via its 'Mode'.","06d0caa7":"2. family"}}