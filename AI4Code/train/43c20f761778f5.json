{"cell_type":{"fe3e592d":"code","1ac6a324":"code","2b25ca9b":"code","a27f7d13":"code","f40e1635":"code","ae741e47":"code","b4ff9a09":"code","a4034385":"code","79ae6a2a":"code","d5bf2ba9":"code","66df7a21":"code","26f238c4":"code","c50f3c29":"code","fde4f120":"markdown","d5710653":"markdown"},"source":{"fe3e592d":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import InputLayer, Conv2D, MaxPool2D, Flatten, Dense\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport os","1ac6a324":"NO_CLASSES = len(os.listdir('..\/input\/100-bird-species\/train'))\nBATCH_SIZE = 32\nHEIGHT = 224\nWIDTH = 224\nCHANNELS = 3","2b25ca9b":"def preprocess_image(image):\n    image \/= 255.0\n    return image","a27f7d13":"def train_model(model, epochs, save_model_on_epoch = False, model_name = 'model'):\n    model.compile(loss=keras.losses.CategoricalCrossentropy())\n    if save_model_on_epoch:\n        model_checkpoint = keras.callbacks.ModelCheckpoint(\n            model_name + \"_{epoch}\", save_freq='epoch'\n        )\n        training_history = model.fit(x = train_ds, validation_data = valid_ds,\n                                     epochs = epochs, verbose = 1, callbacks = [model_checkpoint])\n    else:\n        training_history = model.fit(x = train_ds, validation_data = valid_ds, epochs = epochs, verbose = 1)\n    \n    return model, training_history","f40e1635":"def save_history(model_history, filepath, epochs):\n    history = model_history.history\n    history['epoch'] = np.array(range(1, epochs+1))\n    df = pd.DataFrame(data = history)\n    df = df.set_index('epoch')\n    df.to_csv(filepath + '.csv')","ae741e47":"bird_data_generator = keras.preprocessing.image.ImageDataGenerator(preprocessing_function = preprocess_image)\n\ntrain_ds = bird_data_generator.flow_from_directory('..\/input\/100-bird-species\/train', target_size=(HEIGHT, WIDTH),\n                                                  batch_size=BATCH_SIZE)\n\nvalid_ds = bird_data_generator.flow_from_directory('..\/input\/100-bird-species\/valid', target_size=(HEIGHT, WIDTH),\n                                                  batch_size=BATCH_SIZE)\n\ntest_ds = bird_data_generator.flow_from_directory('..\/input\/100-bird-species\/test', target_size=(HEIGHT, WIDTH),\n                                                 batch_size=BATCH_SIZE)","b4ff9a09":"vgg16_model = keras.applications.vgg16.VGG16(weights=None, classes=NO_CLASSES)\nvgg16_model.summary()","a4034385":"vgg16_epochs = 10\nsave_model = False\nmodel_name = 'vgg16'\nmodel_history_filepath = model_name + '_history'\nvgg16_model, vgg16_model_history = train_model(vgg16_model, vgg16_epochs, save_model, model_name)\nsave_history(vgg16_model_history, model_history_filepath, vgg16_epochs)","79ae6a2a":"model = Sequential([\n    InputLayer(input_shape=(HEIGHT, WIDTH, CHANNELS), name = 'Input'),\n    Conv2D(filters = 4, kernel_size = 3, padding='same', strides=1, activation='sigmoid'),\n    MaxPool2D(),\n    Conv2D(filters = 4, kernel_size = 3, padding='same', strides=1, activation='sigmoid'),\n    MaxPool2D(),\n    Conv2D(filters = 8, kernel_size = 3, padding='same', strides=1, activation='sigmoid'),\n    MaxPool2D(),\n    Conv2D(filters = 16, kernel_size = 3, padding='same', strides=1, activation='sigmoid'),\n    MaxPool2D(),\n    Flatten(data_format = 'channels_last'),\n    Dense(600, activation='sigmoid'),\n    Dense(300, activation='sigmoid')\n])\n\nmodel.summary()","d5bf2ba9":"custom_epochs = 40\nsave_model = True\nmodel_name = 'model'\nmodel_history_filepath = model_name + '_history'\ncustom_model, custom_model_history = train_model(model, custom_epochs, save_model, model_name)\nsave_history(custom_model_history, model_history_filepath, custom_epochs)","66df7a21":"badfit = {\n    'name': 'VGG16',\n    'epochs': np.array(range(1,vgg16_epochs + 1)),\n    'train_loss': vgg16_model_history.history['loss'],\n    'valid_loss': vgg16_model_history.history['val_loss']\n}\n\ngoodfit = {\n    'name': 'Custom Model',\n    'epochs': np.array(range(1,custom_epochs + 1)),\n    'train_loss': custom_model_history.history['loss'],\n    'valid_loss': custom_model_history.history['val_loss']\n}\n\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 6))\n\n# plot overfitting model\nax[0].plot('epochs', 'train_loss', data=badfit, label='Training Loss')\nax[0].plot('epochs', 'valid_loss', data=badfit, label='Validation Loss')\nax[0].legend()\nax[0].set(ylim=(0,10))\nax[0].set_xlabel('Epochs')\nax[0].set_ylabel('Loss')\nax[0].set_title('VGG16 Model')\n\n\n# plot goodfit model\nax[1].plot('epochs', 'train_loss', data=goodfit, label='Training Loss')\nax[1].plot('epochs', 'valid_loss', data=goodfit, label='Validation Loss')\nax[1].legend()\nax[1].set(ylim=(0,6))\nax[1].set_xlabel('Epochs')\nax[1].set_ylabel('Loss')\n_ = ax[1].set_title('Custom Model')","26f238c4":"custom_model = keras.models.load_model('.\/model_15')","c50f3c29":"test_ds = bird_data_generator.flow_from_directory('..\/input\/100-bird-species\/test', target_size=(HEIGHT, WIDTH),\n                                                  batch_size=BATCH_SIZE)\nperformance = custom_model.evaluate(x = test_ds)","fde4f120":"As we can see that our custom model starts overfitting after around 15 epochs. So we will load the model saved at after 15 epochs and use that to test!","d5710653":"The VGG16 starts overfitting and then does not learn much from dataset. One possible reason is that the model is too deep for the simple training set. So we will build our own shallow model."}}