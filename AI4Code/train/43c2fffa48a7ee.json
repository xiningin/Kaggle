{"cell_type":{"052f0059":"code","af277f6d":"code","2eae70ff":"code","b9679551":"code","1289f852":"code","3640f96f":"code","66108ebe":"code","a6564769":"code","ee017d5e":"code","572c6c27":"code","3e4d43b1":"code","f1a0647f":"markdown","6236aca2":"markdown"},"source":{"052f0059":"import cv2\nimport os\nfrom PIL import Image\nimport shutil  \n\n# \u7f29\u5c0f\u56fe\u50cf  \nsize = (int(128), int(120)) \n\npath = '..\/input\/ml-pro3\/faces\/'\nsave_path = '..\/working\/'\n\n\n# shutil.rmtree(save_path)  \n# os.mkdir(save_path)\n\nls = os.listdir(path)\nfor dir in ls:\n    os.makedirs(save_path + 'train\/' + dir)\n    os.makedirs(save_path + 'validation\/' + dir)\n    imgs = os.listdir(path + dir)\n    i = 0\n    for image in imgs:\n        i = i + 1\n#         img = cv2.imread(path + dir + '\/' + image, -1) \n        img = Image.open(path + dir + '\/' + image)\n        img = img.resize((128,120))\n#         shrink = cv2.resize(img, size, interpolation=cv2.INTER_AREA)\n        if i < 80:\n            img.save(os.path.join(save_path + 'train\/' + dir + '\/', image))\n        else:\n            img.save(os.path.join(save_path + 'validation\/' + dir + '\/', image))\n        \n        \nprint(ls)","af277f6d":"print(os.listdir('..\/working\/train'))","2eae70ff":"# \u5bfc\u5165\u57fa\u672c\u4f9d\u8d56\u5305\nimport cv2\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom keras.layers import Conv2D, Activation, MaxPooling2D, GlobalMaxPooling2D, Dense, Dropout\nfrom tensorflow import keras\nfrom keras import optimizers, Sequential\n# from keras_preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n\n\ndef plot_training(history):\n    acc = history.history['acc']\n    val_acc = history.history['val_acc']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs_x = range(len(acc))\n\n    plt.plot(epochs_x, acc, 'bo', label='Training acc')\n    plt.plot(epochs_x, val_acc, 'b', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n\n    plt.figure()\n\n    plt.plot(epochs_x, loss, 'bo', label='Training loss')\n    plt.plot(epochs_x, val_loss, 'b', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n\n    plt.show()\n\n\nif __name__ == '__main__':\n    batch_size = 16\n\n    width = 224\n    height = 224\n    epochs = 64\n    NUM_TRAIN = 21000\n    NUM_TEST = 5000\n    dropout_rate = 0.6\n    input_shape = (height, width, 3)\n    num_classes = 20\n\n    train_dir = '..\/working\/train'\n    validation_dir = '..\/working\/validation'\n\n    \n    \n    # \u56fe\u50cf\u6570\u636e\u589e\u5f3a\n    train_datagen = ImageDataGenerator(\n        rescale=1. \/ 255,  # \u5f52\u4e00\u5316\n        horizontal_flip=False,\n        fill_mode='nearest')\n\n    validation_datagen = ImageDataGenerator(rescale=1. \/ 255, )\n\n    train_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(height, width),\n        shuffle=False,\n        batch_size=batch_size,\n        class_mode='categorical')\n\n    validation_generator = validation_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(height, width),\n        shuffle=False,\n        batch_size=batch_size,\n        class_mode='categorical')\n\n    print(train_generator.class_indices)\n    print(validation_generator.class_indices)\n\n\n    def plotImages(images_arr):\n        fig, axes = plt.subplots(1, 5, figsize=(20, 20))  # \u8fd9\u91cc\u548c\u4e0b\u9762for\u5faa\u73afrange\u91cc\u7684\u503c\u8981\u5339\u914d\n        axes = axes.flatten()\n        for img, ax in zip(images_arr, axes):\n            ax.imshow(img)\n            ax.axis('off')\n        plt.tight_layout()\n        plt.show()\n\n\n    augemted_images = [train_generator[0][0][0] for i in range(5)]\n    plotImages(augemted_images)\n\n    model = Sequential()\n    \n    model.add(Conv2D(64, (3, 3), input_shape=(224, 224, 3), data_format='channels_last'))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(64, (3, 3)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(128, (3, 3)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(GlobalMaxPooling2D())  # this converts our 3D feature maps to 1D feature vectors\n    model.add(Dense(128))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(20))\n    model.add(Activation('softmax'))\n\n    model.summary()\n    \n    model.compile(loss='categorical_crossentropy',\n                  #optimizer='rmsprop',\n                  optimizer='adam',\n                  metrics=['acc'])\n\n    history_tl = model.fit_generator(\n        train_generator,\n        #steps_per_epoch=NUM_TRAIN,\n        epochs=epochs,\n        validation_data=validation_generator,\n        #validation_steps=NUM_TEST\n    )\n\n    from keras.models import load_model\n\n    plot_training(history_tl)\n\n    model.save('..\/working\/my_model.h5')\n\n#     \u7528\u4e8e\u8bad\u7ec3\u540e\u8f93\u51faTraining\u548cValidation\u7684accuracy\u53caloss\u56fe","b9679551":"from keras.models import load_model\nimport os\n\nmodel = load_model('.\/my_model.h5')\n\nls = os.listdir('.\/train\/megak\/')\nfor l in ls:\n    model.predict('.\/train\/megak\/' + l)\n","1289f852":"import torch\n\n# Model\nmodel = torch.hub.load('ultralytics\/yolov3', 'yolov3')  # or yolov3-spp, yolov3-tiny, custom\n\n# Images\nimg = 'https:\/\/ultralytics.com\/images\/zidane.jpg'  # or file, Path, PIL, OpenCV, numpy, list\n\n# Inference\nresults = model(img)\n\n# Results\nresults.print()  # or .show(), .save(), .crop(), .pandas(), etc.","3640f96f":"import shutil\nimport os\npath = '..\/input\/ml-pro3\/faces\/'\nsave_path = '..\/working\/'\n\nos.makedirs(save_path + 'task2\/')\nexpressions = ['angry', 'happy', 'neutral', 'sad']\nfor e in expressions:\n    os.makedirs(save_path + 'task2\/' + 'train\/' + e)\n    os.makedirs(save_path + 'task2\/' + 'validation\/' + e)\n\nls = os.listdir(path)\nfor l in ls:\n    # \u83b7\u53d6\u6bcf\u4e2a\u6587\u4ef6\u5939\u4e2d\u6587\u4ef6\u7684\u76ee\u5f55\u96c6\u5408\n    subls = os.listdir(path + l)\n    print(subls[0])\n    print(type(subls[0]))\n    for sl in subls:\n        # \u5bf9\u5e94\u5230\u6bcf\u4e2a\u6587\u4ef6\u7684\u8def\u5f84\u5c31\u662f\uff1apath + l + sl\n#         print(path + l + '\/' + sl)\n        for e in expressions:\n            # \u5982\u679c\u627e\u5230\u4e86\u8fd9\u4e2a\u8868\u60c5\uff0c\u5219\u5c06\u5f53\u524d\u56fe\u7247\u590d\u5236\u5230\u8bad\u7ec3\u96c6\u7684\u5bf9\u5e94\u8868\u60c5\u4e2d\n            if(sl.find(e) != -1):\n                shutil.copy(path + l + '\/' + sl, save_path + 'task2\/' + 'train\/' + e + '\/')\n            \n            \n        ","66108ebe":"import os\nimport shutil\nfrom PIL import Image\n\npath = '..\/input\/ml-pro3\/faces\/'\nsave_path = '..\/working\/task2\/'\n\nexpressions = [\"angry\", \"happy\", \"sad\", \"neutral\"]\ndata_set = [\"train\", \"validation\", \"test\"]\n\nfor ds in data_set:\n    for e in expressions:\n        if(os.path.exists(save_path + ds + '\/' + e) == False):\n            os.makedirs(save_path + ds + '\/' + e)\n\n    \nls = os.listdir(path)\n\nfor l in ls:\n    # l \u4ee3\u8868 an2i\u7b4920\u7c7b\u8868\u60c5\u6587\u4ef6\u5939\n    subls = os.listdir(path + l)\n    for sl in subls:\n        for e in expressions:\n            if(sl.find(e) != -1):\n                img = Image.open(path + l + '\/' + sl)\n                img = img.resize((128,120))\n                img.save(os.path.join(save_path + 'train\/' + e + '\/', sl))\n#                 shutil.copy(path + l + '\/' + sl, save_path + 'train\/' + e + '\/')","a6564769":"import os\nimport shutil\nfrom PIL import Image\n\npath = '..\/input\/ml-pro3\/faces\/'\nsave_path = '..\/working\/task2\/'\n\nexpressions = [\"angry\", \"happy\", \"sad\", \"neutral\"]\ndata_set = [\"train\", \"validation\", \"test\"]\n\nfor ds in data_set:\n    for e in expressions:\n        if(os.path.exists(save_path + ds + '\/' + e) == False):\n            os.makedirs(save_path + ds + '\/' + e)\n\n    \nls = os.listdir(path)\n\nfor l in ls:\n    # l \u4ee3\u8868 an2i\u7b4920\u7c7b\u8868\u60c5\u6587\u4ef6\u5939\n    subls = os.listdir(path + l)\n    for sl in subls:\n        for e in expressions:\n            if(sl.find(e) != -1):\n                img = Image.open(path + l + '\/' + sl)\n                img = img.resize((128,120))\n                img.save(os.path.join(save_path + 'train\/' + e + '\/', sl))\n#                 shutil.copy(path + l + '\/' + sl, save_path + 'train\/' + e + '\/')\n\n'''\n    \u5206\u5272\u7ebf\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n'''\n\nimport os\nimport random\nimport shutil\n\ndef moveFile(fileDir,tarDir,rate):\n    pathDir = os.listdir(fileDir)    #\u53d6\u56fe\u7247\u7684\u539f\u59cb\u8def\u5f84\n    filenumber=len(pathDir)\n    # \u81ea\u5b9a\u4e49\u62bd\u53d6\u56fe\u7247\u7684\u6bd4\u4f8b\uff0c\u6bd4\u65b9\u8bf4100\u5f20\u62bd10\u5f20\uff0c\u90a3\u5c31\u662f0.1\n    picknumber=int(filenumber*rate) #\u6309\u7167rate\u6bd4\u4f8b\u4ece\u6587\u4ef6\u5939\u4e2d\u53d6\u4e00\u5b9a\u6570\u91cf\u56fe\u7247\n    sample = random.sample(pathDir, picknumber)  #\u968f\u673a\u9009\u53d6picknumber\u6570\u91cf\u7684\u6837\u672c\u56fe\u7247\n\n    for name in sample:\n        shutil.move(fileDir+name, tarDir+name)\n\nfileDir = '..\/working\/task2\/train\/'    #\u6e90\u56fe\u7247\u6587\u4ef6\u5939\u8def\u5f84\ntarDir  = '..\/working\/task2\/validation\/'       #\u79fb\u52a8\u5230\u65b0\u7684\u6587\u4ef6\u5939\u8def\u5f84\ntarDir2  = '..\/working\/task2\/test\/'       #\u79fb\u52a8\u5230\u65b0\u7684\u6587\u4ef6\u5939\u8def\u5f84\n\nrate = 0.1\n\nfor oneDir in os.listdir(fileDir):\n    # oneDir: happy\u3001sad\n    onefileDir = fileDir+oneDir+\"\/\"  # A\u7684\u4e8c\u7ea7\u76ee\u5f55\n    onetarDir  = tarDir+oneDir+\"\/\"   # B\u7684\u4e8c\u7ea7\u76ee\u5f55\n    onetarDir2  = tarDir2+oneDir+\"\/\"   # B\u7684\u4e8c\u7ea7\u76ee\u5f55\n    # \u5224\u65ad\u6587\u4ef6\u5939\u662f\u5426\u5b58\u5728\uff0c\u4e0d\u5b58\u5728\u5219\u521b\u5efa\n    if not os.path.exists(onefileDir):\n        os.makedirs(onefileDir)\n    if not os.path.exists(onetarDir):\n        os.makedirs(onetarDir)\n        \n    moveFile(onefileDir, onetarDir, rate)\n    moveFile(onefileDir, onetarDir2, rate)\n    \n    \n'''\n    \u5206\u5272\u7ebf\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n'''\n\n\nimport os\nprint(len(os.listdir('.\/task2\/validation\/sad')))\n\n'''\n    \u5206\u5272\u7ebf\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\n'''\n\nimport os\nimport matplotlib.pyplot as plt # plt \u7528\u4e8e\u663e\u793a\u56fe\u7247\nimport matplotlib.image as mpimg # mpimg \u7528\u4e8e\u8bfb\u53d6\u56fe\u7247\n\ndef plot(p):\n    plt.imshow(mpimg.imread(p)) # \u663e\u793a\u56fe\u7247\n    plt.axis('off') # \u4e0d\u663e\u793a\u5750\u6807\u8f74\n    plt.show()\n\npath = '..\/working\/task2\/validation\/sad'\nls = os.listdir(path)\nfor l in ls:\n    print(l)\n#     plot(path + '\/' + l)","ee017d5e":"import os, shutil\n\ndef del_file(filepath):\n    \"\"\"\n    \u5220\u9664\u67d0\u4e00\u76ee\u5f55\u4e0b\u7684\u6240\u6709\u6587\u4ef6\u6216\u6587\u4ef6\u5939\n    :param filepath: \u8def\u5f84\n    :return:\n    \"\"\"\n    del_list = os.listdir(filepath)\n    for f in del_list:\n        file_path = os.path.join(filepath, f)\n        if os.path.isfile(file_path):\n            os.remove(file_path)\n        elif os.path.isdir(file_path):\n            shutil.rmtree(file_path)\n\ndel_file('..\/working\/')","572c6c27":"# \u5bfc\u5165\u57fa\u672c\u4f9d\u8d56\u5305\nimport cv2\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom keras.layers import Conv2D, Activation, MaxPooling2D, GlobalMaxPooling2D, Dense, Dropout\nfrom tensorflow import keras\nfrom keras import optimizers, Sequential\n# from keras_preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n\n\ndef plot_training(history):\n    acc = history.history['acc']\n    val_acc = history.history['val_acc']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs_x = range(len(acc))\n\n    plt.plot(epochs_x, acc, 'bo', label='Training acc')\n    plt.plot(epochs_x, val_acc, 'b', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n\n    plt.figure()\n\n    plt.plot(epochs_x, loss, 'bo', label='Training loss')\n    plt.plot(epochs_x, val_loss, 'b', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n\n    plt.show()\n\n\nif __name__ == '__main__':\n    batch_size = 16\n\n    width = 32\n    height = 32\n    epochs = 256\n    NUM_TRAIN = 21000\n    NUM_TEST = 5000\n    dropout_rate = 0.6\n    input_shape = (height, width, 3)\n    num_classes = 4\n\n    train_dir = '..\/working\/task2\/train'\n    validation_dir = '..\/working\/task2\/validation'\n\n    \n    \n    # \u56fe\u50cf\u6570\u636e\u589e\u5f3a\n    train_datagen = ImageDataGenerator(\n        rescale=1. \/ 255,  # \u5f52\u4e00\u5316\n        horizontal_flip=False,\n        fill_mode='nearest')\n\n    validation_datagen = ImageDataGenerator(rescale=1. \/ 255, )\n\n    train_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(height, width),\n        shuffle=True,\n        batch_size=batch_size,\n        class_mode='categorical')\n\n    validation_generator = validation_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(height, width),\n        shuffle=True,\n        batch_size=batch_size,\n        class_mode='categorical')\n\n    print(train_generator.class_indices)\n    print(validation_generator.class_indices)\n\n\n    def plotImages(images_arr):\n        fig, axes = plt.subplots(1, 5, figsize=(20, 20))  # \u8fd9\u91cc\u548c\u4e0b\u9762for\u5faa\u73afrange\u91cc\u7684\u503c\u8981\u5339\u914d\n        axes = axes.flatten()\n        for img, ax in zip(images_arr, axes):\n            ax.imshow(img)\n            ax.axis('off')\n        plt.tight_layout()\n        plt.show()\n\n\n    augemted_images = [train_generator[0][0][0] for i in range(5)]\n    plotImages(augemted_images)\n\n    model = Sequential()\n    \n    model.add(Conv2D(64, (3, 3), input_shape=(width, height, 3), data_format='channels_last'))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(64, (3, 3)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    model.add(Conv2D(64, (3, 3)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(GlobalMaxPooling2D())  # this converts our 3D feature maps to 1D feature vectors\n    model.add(Dense(128))\n    model.add(Activation('relu'))\n    model.add(Dropout(dropout_rate))\n    model.add(Dense(num_classes))\n    model.add(Activation('softmax'))\n\n    model.summary()\n    \n    Adam = tf.keras.optimizers.Adam(lr=1e-1)\n    model.compile(loss='categorical_crossentropy',\n#                   optimizer='rmsprop',\n                  optimizer='adam',\n                  metrics=['acc'])\n\n    history_tl = model.fit_generator(\n        train_generator,\n        #steps_per_epoch=NUM_TRAIN,\n        epochs=epochs,\n        validation_data=validation_generator,\n        #validation_steps=NUM_TEST\n    )\n\n    from keras.models import load_model\n\n    plot_training(history_tl)\n\n    model.save('..\/working\/my_model_exp.h5')\n\n#     \u7528\u4e8e\u8bad\u7ec3\u540e\u8f93\u51faTraining\u548cValidation\u7684accuracy\u53caloss\u56fe","3e4d43b1":"from keras.models import load_model\nimport os\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n \n# image=Image.open('cat.jpg')\n# plt.imshow(image)\n# plt.show()\n# image=np.copy(image) # \u8fd9\u4e00\u53e5\n# print(image.shape)\n# print(image)\n\n\nmodel = load_model('my_model_exp.h5')\n\n\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255, )\ntest_generator = test_datagen.flow_from_directory(\n        '..\/working\/task2\/test\/',\n        target_size=(height, width),\n        shuffle=True,\n        batch_size=batch_size,\n        class_mode='categorical')\n\nscore = model.evaluate_generator(test_generator, steps=1)\nprint(f'Test loss: {score[0]} \/ Test accuracy: {score[1]}')\n\n# https:\/\/stackoverflow.com\/questions\/63758447\/how-can-i-evaluate-a-model-loading-data-with-flow-from-directory","f1a0647f":"\u751f\u6210Train\u3001Validation\u3001Test\u6570\u636e\u96c6","6236aca2":"\u5220\u9664\u6587\u4ef6"}}