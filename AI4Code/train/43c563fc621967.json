{"cell_type":{"a6e91b32":"code","f1ee8889":"code","1eab5f2d":"code","6469baf8":"code","dd6c8be0":"code","da385b15":"code","e73d86c1":"code","250899f7":"code","00287465":"code","15940de6":"code","7da699ca":"code","acc89383":"code","53df4591":"code","86b92aaf":"code","91ebe304":"code","50fb3cbf":"code","066787aa":"code","e48e7959":"code","c6f6a769":"code","a4f81e6e":"markdown","eda31b0c":"markdown","8da41b15":"markdown","7b0caa40":"markdown","4753ba3d":"markdown","c6a61885":"markdown","6954f6dc":"markdown"},"source":{"a6e91b32":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f1ee8889":"import pandas as pd\nimport numpy as np\nimport json\nfrom os import listdir, path\nimport re\nimport keras\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Conv2D, UpSampling2D\nfrom keras.optimizers import Adam\nfrom tensorflow.keras.models import Model, load_model\nfrom keras.utils import CustomObjectScope\nfrom keras.layers import DepthwiseConv2D\n\n\nimport os\n\nimport cv2\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","1eab5f2d":"!ls \/kaggle\/input\/test-detection-rstd\/kaggle\/kaggle\/train\/","6469baf8":"data_path = '\/kaggle\/input\/test-detection-rstd\/kaggle\/kaggle\/'\n\nseed = 1\nbatch_size = 8\ntrain_dir = f'{data_path}\/train\/' # images for training","dd6c8be0":"# Train generator\n\nimage_datagen = ImageDataGenerator(\n    rotation_range=15.,\n    width_shift_range=0.1,\n    height_shift_range=0.2,\n    zoom_range=0.2,\n    validation_split=0.2,\n    preprocessing_function=preprocess_input\n)\nmask_datagen = ImageDataGenerator(\n    rotation_range=15.,\n    width_shift_range=0.1,\n    height_shift_range=0.2,\n    zoom_range=0.2,\n    validation_split=0.2,\n    preprocessing_function=lambda x: x \/ 255\n)\n\n# Provide the same seed and keyword arguments to the fit and flow methods\n\nimage_generator = image_datagen.flow_from_directory(\n    train_dir+'images',\n    class_mode=None,\n    seed=seed,\n    target_size=(512, 512),\n    batch_size=batch_size,\n    subset='training'\n)\n\nmask_generator = mask_datagen.flow_from_directory(\n    train_dir+'masks_one_channel',\n    class_mode=None,\n    seed=seed,\n    target_size=(512, 512),\n    batch_size=batch_size,\n    subset='training'\n)\n\n\nval_image_generator = image_datagen.flow_from_directory(\n    train_dir+'images',\n    class_mode=None,\n    seed=seed,\n    target_size=(512, 512),\n    batch_size=batch_size,\n    subset='validation'\n)\n\nval_mask_generator = mask_datagen.flow_from_directory(\n    train_dir+'masks_one_channel',\n    class_mode=None,\n    seed=seed,\n    target_size=(512, 512),\n    batch_size=batch_size,\n    subset='validation'\n)\n\n# combine generators into one which yields image and masks\ntrain_generator = zip(image_generator, mask_generator)\nval_generator = zip(val_image_generator, val_mask_generator)","da385b15":"def jaccard_distance(y_true, y_pred):\n    y_true = y_true[:,:,:,0]\n    y_pred = y_pred[:,:,:,0]\n    y_pred = K.round(y_pred)\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n    jac = (intersection + 1e-8) \/ (sum_ - intersection + 1e-8)\n    return jac","e73d86c1":"basemodel = ResNet50(input_shape=(512, 512, 3), include_top=False) # use the Resnet\nmodel_x8_output = Conv2D(128, (1, 1), activation='relu')(basemodel.layers[-95].output)\nmodel_x8_output = UpSampling2D(size=(8, 8))(model_x8_output)\nmodel_x8_output = Conv2D(3, (3, 3), padding='same', activation='sigmoid')(model_x8_output)\nMODEL_x8 = Model(inputs=basemodel.input, outputs=model_x8_output)","250899f7":"MODEL_x8.summary()","00287465":"MODEL_x8.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-3), \n              metrics=[jaccard_distance])","15940de6":"MODEL_x8.fit_generator(train_generator, steps_per_epoch=300,\n                    epochs=2, verbose=1, \n                    validation_data=val_generator, validation_steps=10)","7da699ca":"from skimage.io import imread, imshow\nfrom skimage import img_as_ubyte\nfrom skimage.transform import resize\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndef plot(src, cmap=None):\n    plt.rcParams['figure.figsize'] = (10, 10)\n    plt.imshow(src, cmap)","acc89383":"!ls ","53df4591":"path = f'{data_path}\/train\/'\ntest_imgs = os.listdir(f\"{path}\/images\/images\/\")\n\nimg_id = 2 # you may change this id, it may be from 0-10 in our case (to number of images in folder -1)\n\nimg = imread(f'{path}images\/images\/{test_imgs[img_id]}')\nmask = imread(f'{path}masks_one_channel\/masks\/{test_imgs[img_id]}')\n# plot image\nplot(img, cmap='gray')","86b92aaf":"pred = MODEL_x8.predict(preprocess_input(img_as_ubyte(resize(img, (512, 512)))).reshape((1, 512, 512, 3)))[0]\n\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3,figsize=(15,15))\nax1.imshow(img)\nax2.imshow(mask)\nax3.imshow((resize(pred, (img.shape[0], img.shape[1])) > 0.1).astype(np.uint8) * 255)","91ebe304":"from multiprocessing import Pool\n\nfrom tqdm import tqdm_notebook\n\ndef RLenc(img, order='F', format=True):\n    \"\"\"\n    img is binary mask image, shape (r,c)\n    order is down-then-right, i.e. Fortran\n    format determines if the order needs to be preformatted (according to submission rules) or not\n\n    returns run length as an array or string (if format is True)\n    \"\"\"\n    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n    runs = []  ## list of run lengths\n    r = 0  ## the current run length\n    pos = 1  ## count starts from 1 per WK\n    for c in bytes:\n        if (c == 0):\n            if r != 0:\n                runs.append((pos, r))\n                pos += r\n                r = 0\n            pos += 1\n        else:\n            r += 1\n\n    # if last run is unsaved (i.e. data ends with 1)\n    if r != 0:\n        runs.append((pos, r))\n        pos += r\n        r = 0\n\n    if format:\n        z = ''\n\n        for rr in runs:\n            z += '{} {} '.format(rr[0], rr[1])\n        return z[:-1]\n    else:\n        return runs\n    \n\ndef rle2mask(mask_rle, shape=(1600,256)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T","50fb3cbf":"image_dir = f'{data_path}\/test\/images\/images\/'\n\nimages_paths = [f\"{image_dir}{i}\" for i in os.listdir(image_dir) if i.endswith('.jpg')]\n\n\ndef pred_gen(images_paths: list):\n    for image_path in tqdm_notebook(images_paths):\n        filename = image_path.split('\/')[-1]\n\n        img = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n        pred = MODEL_x8.predict(preprocess_input(img_as_ubyte(resize(img, (512, 512)))).reshape((1, 512, 512, 3)))[0]\n        pred_r = (resize(pred, (img.shape[0], img.shape[1])) > 0.1).astype(np.uint8)\n        pred_mask = pred_r[:,:, 0]\n        yield (filename, pred_mask)\n        \npred_masks = pred_gen(images_paths)","066787aa":"# import random\n\ndef rlen_pool(name_mask: tuple):\n    name, pred_mask = name_mask\n    pred_mask = cv2.resize(pred_mask, (1280, 720))\n    mask_string = RLenc(np.round(pred_mask))\n    \n    return (name, mask_string)","e48e7959":"results = {filename.split('\/')[-1]: \"1 1\" for filename in images_paths}\n\nwith Pool(processes=2) as p:\n    max_ = len(images_paths)\n    with tqdm_notebook(total=max_) as pbar:\n        for i, res in enumerate(p.imap_unordered(rlen_pool, pred_masks)):\n            name, rle_string = res\n            results[name]= rle_string\n            pbar.update()","c6f6a769":"with open('fcn_submission.csv', 'w') as f:\n    f.write('Id,Expected\\n')\n\n    for key_value in tqdm_notebook(results.items()):\n        filename, rle_string_mask = key_value\n        f.write(f'{filename},{rle_string_mask}\\n')","a4f81e6e":"### Create FCN model","eda31b0c":"### Make Submission","8da41b15":"### Specify data folder","7b0caa40":"### Create generators for data","4753ba3d":"### Perform a metric","c6a61885":"### Train it","6954f6dc":"### Check what we predict"}}