{"cell_type":{"537fdea6":"code","f8bbaffc":"code","ad928bea":"code","73da19e5":"code","cad44204":"code","373f1539":"code","b6ff032f":"code","caa4efca":"code","56399491":"code","5fcdfd7c":"code","0910670a":"code","f952f184":"code","cf63e5be":"code","736d19af":"code","6e770627":"code","31de98a5":"code","08dc0f4a":"code","85ed96df":"code","906cf53e":"code","583e475c":"code","68c4f7e1":"code","53a320ae":"code","f7429295":"code","0523320d":"markdown","c06a7773":"markdown","fc9ce9c3":"markdown","01925176":"markdown"},"source":{"537fdea6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f8bbaffc":"#Utils\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import classification_report, roc_auc_score, make_scorer, accuracy_score, roc_curve\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC \nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cluster import KMeans\nfrom kmodes.kmodes import KModes\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.model_selection import StratifiedKFold\nimport lightgbm\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import uniform as sp_uniform\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\nfrom sklearn.metrics import pairwise_distances\nfrom sklearn.metrics.pairwise import pairwise_kernels\nfrom sklearn.metrics.pairwise  import cosine_similarity\nfrom sklearn.metrics.pairwise import chi2_kernel\nfrom catboost import CatBoostClassifier\nimport seaborn as sns\nimport plotly.io as pio\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode, iplot\nfrom sklearn.manifold import TSNE\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import KBinsDiscretizer\nimport category_encoders as ce\nfrom tpot import TPOTClassifier\nimport timeit\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom tpot.builtins import ZeroCount\nfrom sklearn.preprocessing import RobustScaler","ad928bea":"pd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)","73da19e5":"train= pd.read_csv('\/kaggle\/input\/tabular-playground-series-may-2021\/train.csv', sep=',')\ntest= pd.read_csv('\/kaggle\/input\/tabular-playground-series-may-2021\/test.csv', sep=',')","cad44204":"train = train.set_index('id')\ntest = test.set_index('id')","373f1539":"sub_sample = pd.read_csv('\/kaggle\/input\/tabular-playground-series-may-2021\/sample_submission.csv', sep=',')\nsub_sample = sub_sample.set_index('id')","b6ff032f":"fig = px.histogram(train, x=\"target\",\n                   width=600, \n                   height=400,\n                   histnorm='percent',\n                   template=\"simple_white\"\n                   )\nfig.update_layout(title=\"Target Description\", \n                  font_family=\"San Serif\",\n                  titlefont={'size': 20},\n                  showlegend=True,\n                  legend=dict(\n                      orientation=\"v\", \n                      y=1, \n                      yanchor=\"top\", \n                      x=1.0, \n                      xanchor=\"right\"\n                  )                \n                 ).update_xaxes(categoryorder='total descending')#\nfig.update_traces( \n                  marker_line_width=1.5, opacity=0.99)\nfig.show()","caa4efca":"def calc_loss(class_perc, num):\n    \n    lst=[]\n    \n    for i,z in enumerate(class_perc):\n        lst = lst+[i for x in range(int(z*(num+1)))]\n        \n    preds=[]\n    \n    for i in range(num):\n        preds+=[class_perc]\n    \n    return (log_loss(lst,preds))","56399491":"#example of how could be the distribution in classes according to the LB\ncalc_loss([0.60, 0.20, 0.10, 0.10], 200000)","5fcdfd7c":"#target Map\ndict1 = dict(zip(list(train.target.unique()),range(4)))\ndict1","0910670a":"train['target']= train['target'].replace(dict1)","f952f184":"cols = train.columns[:-1]\ntarget = train['target']\ntrain = train[cols]","cf63e5be":"train[train<0]=0\ntest[test<0]=0","736d19af":"# create train and test sets\nX_train, X_val, y_train, y_val = train_test_split(train, target, train_size=0.75, test_size=0.25, stratify=target, random_state=2)","6e770627":"tpot = TPOTClassifier(verbosity=3, \n                      scoring='neg_log_loss', \n                      random_state=2, \n                      periodic_checkpoint_folder='tpot_tpsmay.txt', \n                      n_jobs=-1,\n                      cv=5,\n                      generations=5, \n                      population_size=10)","31de98a5":"start_time = timeit.default_timer()\ntpot.fit(X_train, y_train)\nwinning = tpot.fitted_pipeline_\nscore = (tpot.score(X_val, y_val))\ntpot.export('tps_may_pipeline.py')  \nprint('Winning pipeline :', winning, 'Score:', score)","08dc0f4a":"print('Winning pipeline :', winning, 'Score:', score)","85ed96df":"preds = np.zeros((len(test), 4))\noof_preds = pd.DataFrame(index=train.index)\nk=10\nkf = StratifiedKFold(n_splits = k, random_state = 22 , shuffle = True)\nroc = []\n\nn = 0\nfor trn_idx , val_idx in kf.split(train , target):\n    train_x = train.iloc[trn_idx]\n    train_y = target.iloc[trn_idx]\n    val_x = train.iloc[val_idx]\n    val_y = target.iloc[val_idx]\n    \n    \n   \n    \n    \n    model = Pipeline(steps=[('zerocount', ZeroCount()), ('robustscaler', RobustScaler()),\n                ('mlpclassifier',\n                 MLPClassifier(alpha=0.1, learning_rate_init=0.01,\n                               random_state=2))])\n    \n    \n    if n!=0:\n        model.fit(train_x , train_y)\n        preds += model.predict_proba(test)\n        preds0 = preds\/(k)\n        roc.append(log_loss(val_y ,model.predict_proba(val_x)))\n        print(n+1 , roc[n])\n\n    if n==0:\n        roc.append(0)\n        print(n+1 , roc[n])\n        \n    \n    n+=1","906cf53e":"p = pd.DataFrame(preds0, index=test.index)","583e475c":"p.head()","68c4f7e1":"sub_sample['Class_1']=p[1]\nsub_sample['Class_2']=p[0]\nsub_sample['Class_3']=p[3]\nsub_sample['Class_4']=p[2]","53a320ae":"sub_sample = sub_sample.reset_index()\nsub_sample.head()","f7429295":"sub_sample.to_csv('submission.csv',index=False)","0523320d":"### Estimation model Log-loss vs Random Guessing","c06a7773":"### Load Data","fc9ce9c3":"### Train the Model","01925176":"### TPOT Classifier"}}