{"cell_type":{"050750b0":"code","383f98e8":"code","e0e126c2":"code","36877e84":"code","3cb7b55c":"code","9644e63d":"code","dcbbc2ae":"code","880102a4":"code","2bad95f2":"code","7650ac51":"code","202cd6fd":"code","05aec2ee":"code","0d125e0c":"code","7e3299c3":"code","6e5687ef":"code","266a5663":"code","a6ef41ac":"code","78d48953":"code","0471e0aa":"code","abb713d7":"code","afbcbd95":"code","7563a332":"code","a67fb8b8":"code","5560be7c":"code","d84a1b63":"code","38e9178a":"code","d72310fe":"code","119e4a12":"code","2df69201":"code","20868db9":"code","1126b08c":"code","8d09f231":"markdown","4f954798":"markdown","94528bd4":"markdown","6360eeb5":"markdown","1eb75926":"markdown","82e4dddf":"markdown","92cf54eb":"markdown","4410e8e5":"markdown","9c380727":"markdown","5d85fbee":"markdown","a3d91173":"markdown","ab412684":"markdown","b5bc3529":"markdown","df12b276":"markdown","5980b01f":"markdown","6cd4e2bd":"markdown","ffe721f3":"markdown","434e0d20":"markdown","3e6aa57b":"markdown","9b2b6977":"markdown","062d719e":"markdown","93beca93":"markdown","ccf0f74c":"markdown","67a308c0":"markdown","1f8fb721":"markdown","fb5cd14f":"markdown"},"source":{"050750b0":"# Remove warning messages\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport plotly\nimport plotly.graph_objects as go\n%matplotlib inline\n\nimport os\n\nimport math\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nimport tensorflow as tf\nfrom keras.utils.np_utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, Activation\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.metrics import top_k_categorical_accuracy, categorical_accuracy\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, LearningRateScheduler","383f98e8":"# Set seed\nnp.random.seed(42)","e0e126c2":"print(\"Tensorflow version \" + tf.__version__)\nAUTO = tf.data.experimental.AUTOTUNE","36877e84":"# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","3cb7b55c":"PATH_TO_DATA = '..\/input\/digit-recognizer\/' # This is where the data is stored on this notebook","9644e63d":"# Load train and test\ntrain = pd.read_csv(PATH_TO_DATA + 'train.csv')\ntest = pd.read_csv(PATH_TO_DATA + 'test.csv')","dcbbc2ae":"def preprocessing(train, test, split_train_size = 0.1):\n\n    X_submission = train.drop([\"label\"],axis = 1)\n    y_submission = train[\"label\"]\n\n    # Normalize the data\n    X_submission = X_submission \/ 255.0\n    test = test \/ 255.0\n\n    # Reshape into right format vectors\n    X_submission = X_submission.values.reshape(-1,28,28,1)\n    X_test = test.values.reshape(-1,28,28,1)\n\n    # Apply ohe on labels\n    y_submission = to_categorical(y_submission, num_classes = 10)\n    \n    # Split the train and the validation set for the fitting\n    X_train, X_val, y_train, y_val = train_test_split(X_submission, y_submission, test_size = split_train_size, random_state=42)\n    \n    return X_train, y_train, X_val, y_val, X_test, X_submission, y_submission\n\nX_train, y_train, X_val, y_val, X_test, X_submission, y_submission = preprocessing(train, test)","880102a4":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_val.shape)\nprint(y_val.shape)\nprint(X_test.shape)\nprint(X_submission.shape)\nprint(y_submission.shape) # We can see that the submission set contains all the data","2bad95f2":"batch_size = 32 * strategy.num_replicas_in_sync # this is 8 on TPU v3-8, it is 1 on CPU and GPU\n# As a result we will store batches of 256 images into the dataset","7650ac51":"def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n    # returns 3x3 transform matrix which transforms indicies\n        \n    # CONVERT DEGREES TO RADIANS\n    rotation = math.pi * rotation \/ 180.\n    \n    # ROTATION MATRIX\n    c1 = tf.math.cos(rotation)\n    s1 = tf.math.sin(rotation)\n    one = tf.constant([1],dtype='float32')\n    zero = tf.constant([1],dtype='float32')\n    rotation_matrix = tf.reshape(tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3])\n    \n    # SHEAR MATRIX\n    c2 = tf.math.cos(shear)\n    s2 = tf.math.sin(shear)\n    shear_matrix = tf.reshape(tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3])    \n    \n    # ZOOM MATRIX\n    zoom_matrix = tf.reshape(tf.concat([one\/height_zoom,zero,zero, zero,one\/width_zoom,zero, zero,zero,one],axis=0),[3,3])\n    \n    # SHIFT MATRIX\n    shift_matrix = tf.reshape(tf.concat([one,zero,height_shift, zero,one,width_shift, zero,zero,one],axis=0),[3,3])\n\n    return(rotation_matrix)","202cd6fd":"def transform(image,label):\n    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n    # output - image randomly rotated\n    DIM = image.shape[0]\n    XDIM = DIM%2 #fix for size 331\n    \n    rot = 12. * tf.random.normal([1],dtype='float32')\n    shr = 30. * tf.random.normal([1],dtype='float32') \n    h_zoom = 1.0 + tf.random.normal([1],dtype='float32')\/10.\n    w_zoom = 1.0 + tf.random.normal([1],dtype='float32')\/10.\n    h_shift = 10. * tf.random.normal([1],dtype='float32') \n    w_shift = 20. * tf.random.normal([1],dtype='float32') \n  \n    # GET TRANSFORMATION MATRIX\n    m = get_mat(rot, shr, h_zoom, w_zoom, h_shift, w_shift) \n\n    # LIST DESTINATION PIXEL INDICES\n    x = tf.repeat( tf.range(DIM\/\/2,-DIM\/\/2,-1), DIM )\n    y = tf.tile( tf.range(-DIM\/\/2,DIM\/\/2),[DIM] )\n    z = tf.ones([DIM*DIM],dtype='int32')\n    idx = tf.stack( [x,y,z] )\n    \n    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n    idx2 = tf.keras.backend.dot(m,tf.cast(idx,dtype='float32'))\n    idx2 = tf.keras.backend.cast(idx2,dtype='int32')\n    idx2 = tf.keras.backend.clip(idx2,-DIM\/\/2+XDIM+1,DIM\/\/2)\n    \n    # FIND ORIGIN PIXEL VALUES           \n    idx3 = tf.stack( [DIM\/\/2-idx2[0,], DIM\/\/2-1+idx2[1,]] )\n    d = tf.gather_nd(image,tf.transpose(idx3))\n        \n    return tf.reshape(d,[DIM,DIM,1]),label","05aec2ee":"# Put data in a tensor format for parallelization\ndef data_augment(image,label):\n    #image = tf.image.convert_image_dtype(image, tf.float32) # Cast and normalize the image to [0,1]\n    #image = tf.image.resize_with_crop_or_pad(image, 35, 35) # Add 6 pixels of padding\n    #image = tf.image.random_crop(image, size=[28, 28, 1]) # Random crop back to 28x28    \n    image = tf.image.random_brightness(image, max_delta=0.3) # Random brightness\n\n    return(image,label)","0d125e0c":"train_dataset_augment = (\n    tf.data.Dataset\n    .from_tensor_slices((X_train.astype(np.float32), y_train.astype(np.float32)))\n    .map(data_augment, num_parallel_calls=AUTO)\n    .map(transform, num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(2048)\n    .batch(batch_size)\n    .prefetch(AUTO)\n)\n\ntrain_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((X_train.astype(np.float32), y_train.astype(np.float32)))\n    .repeat()\n    .shuffle(2048)\n    .batch(batch_size)\n    .prefetch(AUTO)\n)\n\nval_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((X_val.astype(np.float32), y_val.astype(np.float32)))\n    .batch(batch_size)\n    .cache()\n    .prefetch(AUTO)\n)\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(X_test.astype(np.float32))\n    .batch(batch_size)\n)\n\nsubmission_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((X_submission.astype(np.float32), y_submission.astype(np.float32)))\n    #.map(data_augment, num_parallel_calls=AUTO)\n    .map(transform, num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(2048)\n    .batch(batch_size)\n    .prefetch(AUTO)\n)","7e3299c3":"row = 3; col = 4;\nall_elements = train_dataset.unbatch()\none_element = tf.data.Dataset.from_tensors(next(iter(all_elements)))\naugmented_element = one_element.repeat().batch(row*col)\n\nfor (img,label) in augmented_element:\n    plt.figure(figsize=(15,int(15*row\/col)))\n    for j in range(row*col):\n        plt.subplot(row,col,j+1)\n        image=img[j]\n        plt.imshow(image[:,:,0])\n    plt.show()\n    break","6e5687ef":"row = 1; col = 1;\nall_elements = train_dataset.unbatch()\none_element = tf.data.Dataset.from_tensors(next(iter(all_elements)))\naugmented_element = one_element.repeat().map(data_augment).batch(row*col)\n\nfor (img,label) in augmented_element:\n    plt.figure(figsize=(15,int(15*row\/col)))\n    for j in range(row*col):\n        plt.subplot(row,col,j+1)\n        image=img[j]\n        plt.imshow(image[:,:,0])\n    plt.show()\n    break","266a5663":"row = 3; col = 4;\nall_elements = train_dataset.unbatch()\none_element = tf.data.Dataset.from_tensors(next(iter(all_elements)))\naugmented_element = one_element.repeat().map(transform).batch(row*col)\n\nfor (img,label) in augmented_element:\n    plt.figure(figsize=(15,int(15*row\/col)))\n    for j in range(row*col):\n        plt.subplot(row,col,j+1)\n        image=img[j]\n        plt.imshow(image[:,:,0])\n    plt.show()\n    break","a6ef41ac":"row = 3; col = 4;\nall_elements = train_dataset.unbatch()\none_element = tf.data.Dataset.from_tensors(next(iter(all_elements)))\naugmented_element = one_element.repeat().map(transform).map(data_augment).batch(row*col)\n\nfor (img,label) in augmented_element:\n    plt.figure(figsize=(15,int(15*row\/col)))\n    for j in range(row*col):\n        plt.subplot(row,col,j+1)\n        image=img[j]\n        plt.imshow(image[:,:,0])\n    plt.show()\n    break","78d48953":"# Parameters\nepochs = 100\nn_steps = X_train.shape[0]\/\/batch_size","0471e0aa":"# Define a custom metric\ndef top_5_categorical_accuracy(y_true, y_pred):\n    return top_k_categorical_accuracy(y_true, y_pred, k=5)","abb713d7":"def CNN_model():\n    model = Sequential([\n        Conv2D(filters = 32, kernel_size = (3,3), activation ='relu', input_shape = (28 ,28 ,1)), # Important to specify the shape of the input data in the first layer.\n        Conv2D(filters = 32, kernel_size = (3,3), activation ='relu'), # The kernel_size is the grid that will stop at every possible location to extract a patch of surrounding features\n        BatchNormalization(),\n        Activation('relu'),\n        MaxPool2D(pool_size=(2,2)),\n        Dropout(0.10), # We are shunting down 25% of the nodes randomly\n\n        Conv2D(filters = 64, kernel_size = (3,3), activation ='relu'), # Same as block 1 but with 64 nodes\n        Conv2D(filters = 64, kernel_size = (3,3), activation ='relu'),\n        BatchNormalization(),\n        Activation('relu'),\n        MaxPool2D(pool_size=(2,2)),\n        Dropout(0.10),\n        Flatten(), # Important to start using the 1D fully connected part of the layer\n\n        Dense(256, activation='relu'), # Creating a layer with 256 nodes\n        BatchNormalization(),\n        Activation('relu'),\n\n        Dense(128, activation='relu'),\n        BatchNormalization(),\n        Activation('relu'),\n        \n        \n        Dense(64, activation='relu'),\n        BatchNormalization(),\n        Activation('relu'),\n        Dropout(0.20),\n\n        Dense(10, activation='softmax') # We need to end the model with a Dense layer composed of 10 nodes (because 10 numbers from 0 to 9) and with a softmax activation to get a probability\n    ])\n\n    return model\n","afbcbd95":"# TPU\nwith strategy.scope():\n    model = CNN_model()\n    \nmodel.summary()\n\n# Compile the model\nmodel.compile(optimizer = RMSprop(lr=1e-4), \n              loss = \"categorical_crossentropy\", \n              metrics=[\"accuracy\", top_5_categorical_accuracy])","7563a332":"# Save weights only for best model\ncheckpointer = ModelCheckpoint(filepath = 'weights_best_MNIST_20.hdf5', \n                               verbose = 2, \n                               save_best_only = True) # This callback will be used to save the model with the best weights\n\ndef scheduler(epoch, lr):\n    if epoch < 30: # For the first 30 epochs, the learning rate is not changed\n        return(lr)\n    else: # After 30 epochs the lrdecreases exponentially\n        return(lr*math.exp(-0.1))\n\nLRScheduler = LearningRateScheduler(scheduler)\n\nearlystopper = EarlyStopping(monitor='val_loss', min_delta =0, patience=20, verbose=2, mode='min',restore_best_weights=True) # This callback is used to stop the training session if the model does'nt learn anymore","a67fb8b8":"history = model.fit(train_dataset, \n                    steps_per_epoch = n_steps, \n                    epochs = 60, \n                    validation_data=(val_dataset),\n                    callbacks = [checkpointer, LRScheduler, earlystopper])","5560be7c":"def plot_history(model_history):\n\n    plt.figure(figsize = (20,15))\n    \n    plt.subplot(221)\n    # summarize history for accuracy\n    plt.plot(model_history.history['top_5_categorical_accuracy'][5:])\n    plt.plot(model_history.history['val_top_5_categorical_accuracy'][5:])\n    plt.title('top_3_categorical_accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.grid()\n    \n    plt.subplot(222)\n    # summarize history for accuracy\n    plt.plot(model_history.history['accuracy'][5:])\n    plt.plot(model_history.history['val_accuracy'][5:])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.grid()\n    \n    plt.subplot(223)\n    # summarize history for loss\n    plt.plot(model_history.history['loss'][5:])\n    plt.plot(model_history.history['val_loss'][5:])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.grid()\n    \n    plt.subplot(224)\n    # summarize history for lr\n    plt.plot(model_history.history['lr'][5:])\n    plt.title('learning rate')\n    plt.ylabel('lr')\n    plt.xlabel('epoch')\n    plt.grid()\n    \n    plt.show()","d84a1b63":"plot_history(history)","38e9178a":"# TPU\nwith strategy.scope():\n    # loading the model with the best validation accuracy\n    model.load_weights('weights_best_MNIST_20.hdf5')\n    \nmodel.evaluate(val_dataset)","d72310fe":"def plot_confusion_matrix(confusion_matrix, \n                          cmap=plt.cm.Reds):\n    \n    classes = range(10)\n    \n    plt.figure(figsize=(8,8))\n    plt.imshow(confusion_matrix, \n               interpolation='nearest', \n               cmap=cmap)\n    plt.title('Confusion matrix')\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = confusion_matrix.max() \/ 2.\n    for i, j in itertools.product(range(confusion_matrix.shape[0]), range(confusion_matrix.shape[1])):\n        plt.text(j, i, confusion_matrix[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if confusion_matrix[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","119e4a12":"# Predict the values from the validation dataset\ny_pred = model.predict(X_val.astype(np.float32))\n# Convert predictions classes to one hot vectors \ny_pred_classes = np.argmax(y_pred, axis = 1) \n# Convert validation observations to one hot vectors\ny_true = np.argmax(y_val, axis = 1) \n# compute the confusion matrix\ncm = confusion_matrix(y_true, y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(cm)","2df69201":"# We recreate a model from scartch and we use the full data available in X_submission and y_submission\nearlystopper = EarlyStopping(monitor='loss', min_delta =0, patience=10, verbose=2, mode='min',restore_best_weights=True)\n\ndef scheduler(epoch, lr):\n    if epoch < 30: # For the first 20 epochs, the learning rate is not changed\n        return(lr)\n    else: # After ten is decreases exponentially\n        return(lr*math.exp(-0.1))\n\nLRScheduler = LearningRateScheduler(scheduler)\n\n# TPU\nwith strategy.scope():\n    # loading the model with the best validation accuracy\n    model = CNN_model()\n\n# TPU\nwith strategy.scope():\n    model = CNN_model()\n\n# Compile the model\nmodel.compile(optimizer = RMSprop(lr=1e-4), \n              loss = \"categorical_crossentropy\", \n              metrics=[\"accuracy\"])\n\nhistory = model.fit(submission_dataset, \n                    steps_per_epoch = n_steps, \n                    epochs = 60, \n                    callbacks = [LRScheduler, earlystopper])","20868db9":"\nplt.plot(history.history['accuracy'][10:])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train'], loc='upper left')\nplt.grid()","1126b08c":"# predict results\ny_test_pred = model.predict(test_dataset)\n\n# Associate max probability obs with label class\ny_test_pred = np.argmax(y_test_pred, axis = 1)\ny_test_pred = pd.Series(y_test_pred, name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1,28001), name = \"ImageId\"), y_test_pred], axis = 1)\n\nsubmission.to_csv(\"CNN_model_TPU_submission.csv\", index = False)","8d09f231":"# <div id=\"chap2\">2.1 Data manipulation<\/div>\n## <div id=\"chap2.1\">2.1 Load data<\/div>","4f954798":"### <div id=\"chap3.1.2\">3.1.2 Zoom<\/font>","94528bd4":"### <div id=\"chap4.2\">4.2. Whith data augmentation<\/font>\nThis is the raw data without any transformation or augmentation","6360eeb5":"## <div id=\"summary\">Summary<\/div>\n\n**<font size=\"2\"><a href=\"#chap1\">1. Set up<\/a><\/font>**\n**<br><font size=\"2\"><a href=\"#chap2\">2. Data manipulation<\/a><\/font>**\n**<br><font size=\"2\"><a href=\"#chap3\">3. Tensorflow dataset<\/a><\/font>**\n**<br><font size=\"2\"><a href=\"#chap4\">4. Data visualisation<\/a><\/font>**\n**<br><font size=\"2\"><a href=\"#chap4\">5. Building the model<\/a><\/font>**\n**<br><font size=\"2\"><a href=\"#chap4\">6. Modelisation for TPU<\/a><\/font>**\n**<br><font size=\"2\"><a href=\"#chap4\">7. Evaluation<\/a><\/font>**\n**<br><font size=\"2\"><a href=\"#chap4\">8. Submission<\/a><\/font>**\n**<br><font size=\"2\"><a href=\"#chap4\">8. References<\/a><\/font>**","1eb75926":"### <div id=\"chap4.3\">4.3. Whith data transformation<\/font>","82e4dddf":"We'll build one dataset for each type of data we have: train, validation and submission. For the train-set, we'll make one with images transformation, one without.","92cf54eb":"## <div id=\"chap7.2\">7.2 Confusion Matrix<\/font>","4410e8e5":"# <div id=\"chap6\">6. Modelisation on TPU<\/font>\n## <div id=\"chap6.1\">6.1 Compiling on TPU<\/font>","9c380727":"# <div id=\"chap8\">8. Submission<\/div>\n## <div id=\"chap8.1\">8.1. Retraining the best model on the submission set<\/div>","5d85fbee":"## <div id=\"chap6.2\">6.2. Defining the callbacks<\/font>\nCallbacks are usefull to make our model more efficient. While using these, it is possible to modulate the learning rate, to automatically stop the training sesssion if the model doesn't learn anymore and it is possible to save the best weights obtained.","a3d91173":"# <div id=\"chap3\">3. Tensorflow dataset<\/font>\nIn order to make full advantage of the TPU, we will store the previously preprocessed data in a dataset shape. However, this dataset will be a bit different from the ones we can find on *pandas*. Here the dataset will contain batches of images. The purpose of this is to apply transformations\/augmentations to the images just when we feed it to the model. That way we don't use that much memory.","ab412684":"### <div id=\"chap4.4\">4.4 Whith data augmentation and transformation<\/font>","b5bc3529":"## <div id=\"chap3.1\">3.1 Data transformation<\/font>\n### <div id=\"chap3.1.1\">3.1.1 Rotation<\/font>\nHere we will build fonctions that we'll use to rotate randomly the images. It needs a bit of mathematical background if you want to fully understand what's happening here (check-out wikipedia \"rotation matrix\" for instance if needed).","df12b276":"## <font color='red'> Thank you for reading this, do not hesitate to leave a comment. Your feedbacks will help me to improve.<\/font>","5980b01f":"## <div id=\"chap6.4\">6.4. Model history<\/font>","6cd4e2bd":"## <div id=\"chap3.2\">3.2. Building the datasets<\/font>","ffe721f3":"## <div id=\"chap1\">1.2. Detect TPU or GPU<\/div>","434e0d20":"## <div id=\"chap2.1\">2.2 Preprocessing<\/div>\nHere we build 3 kinds of data:\n- train set: on which we will train our model\n- validation set: on which we will evaluate our model before any submission to make sure it is doing well on classifying the digits\n- submission set: that contains all the data available on which we will train our model one last time before the submission whith all its parameters well adjusted.","3e6aa57b":"# <div id=\"chap1\">1. Set up\n## <div id=\"chap1.1\">1.1. Load useful libraries<\/div>","9b2b6977":"## <div id=\"chap6.3\">6.3. Fitting the model<\/font>","062d719e":"# References\n* Thanks to  <a href=\"https:\/\/www.kaggle.com\/sanchitvj\/deep-learning-cnn\">sanchitvj<\/a> that taught me how to use TPUs on this kind of data and from which this notebook originally comes from. A lot of functions used here comes from his notebook. Check out the link for more details.\n* Tahnks to <a href=\"https:\/\/www.kaggle.com\/cdeotte\/rotation-augmentation-gpu-tpu-0-96\">cdeotte<\/a> that taught me how to make data augmentation while using TPUs, that was a big issue for me.\n\n* Thanks to <a href=\"https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6\">yassineghouzam<\/a> for his inspiring notebook\n\n* <a href=\"https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/\">TensorFlow documentation<\/a> that was so usefull.","93beca93":"# Data augmentation on TPU for the MNIST classification\nThe aim of this notebook is to show how to use data augmentation techniques while using a TPU to gain fast results.","ccf0f74c":"# <div id=\"chap7\">7. Evaluation<\/div>\n## <div id=\"chap7.1\">7.1. Load the best model<\/div>","67a308c0":"# <div id=\"chap4\">4. Data visualisation<\/font>\n## <div id=\"chap4.1\">4.1. Whithout data augmentation<\/font>","1f8fb721":"No need to fully understand what the next code does. Just keep in mind that this part will detect whether the model has to train on TPU or GPU.","fb5cd14f":"# <div id=\"chap5\">5. Building the model<\/div>"}}