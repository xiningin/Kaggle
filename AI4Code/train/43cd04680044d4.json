{"cell_type":{"6b8b3568":"code","3a079699":"code","6dcf852d":"code","7bf4afa1":"code","95c054a9":"code","91425002":"code","e8e449c5":"code","eac34158":"code","eb30a392":"code","05c7eef6":"code","9c6db9d0":"code","4c03def2":"code","18b1fcc5":"code","1e9dd92d":"code","df0a0c64":"code","4468695a":"code","a89e47bf":"markdown","d5e55d34":"markdown","f4d1a88c":"markdown","4a77738d":"markdown","4edefe37":"markdown","10620b84":"markdown","9c4d91e1":"markdown","f2f58584":"markdown","2601f783":"markdown","6b96923e":"markdown","506d89f9":"markdown","fc3dc8c9":"markdown","ee90cb1e":"markdown","f251b37a":"markdown","88d9b9d3":"markdown","a17719c2":"markdown","ad3dc316":"markdown","b6ac66ff":"markdown","31c4ddb5":"markdown"},"source":{"6b8b3568":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport xml.etree.ElementTree as ET\nimport os\nfrom PIL import Image\nfrom sklearn.preprocessing import LabelEncoder\nimport holoviews as hv\nimport functools \nfrom torch.utils.data import Dataset\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3a079699":"hv.extension('bokeh')","6dcf852d":"BASE_PATH  = \"\/kaggle\/input\/face-mask-detection\"\nXML_PATH = os.path.join(BASE_PATH, \"annotations\")\nIMG_PATH = os.path.join(BASE_PATH, \"images\")\nXML_FILES = [os.path.join(XML_PATH, f) for f in os.listdir(XML_PATH)]\ncolor = '#fcba03'","7bf4afa1":"class XmlParser(object):\n    \"\"\"Helper class to parse the xml files with annotations.\"\"\"\n    def __init__(self, xml_file):\n        # path to the xml file\n        self.xml_file = xml_file\n        self._root = ET.parse(self.xml_file).getroot()\n        self._objects = self._root.findall('object')\n        # path to the image file as described in the xml file\n        self.img_path = os.path.join(IMG_PATH, self._root.find('filename').text)\n        # names of the classes contained in the xml file\n        self.names = self._get_names()\n        # coordinates of the bounding boxes\n        self.boxes = self._get_bndbox()\n    \n    def parse_xml(self):\n        \"\"\"Parse the xml file returning the root.\"\"\"\n        tree = ET.parse(self.xml_file)\n        return tree.getroot()\n        \n    \n    def _get_names(self):\n        \"\"\"Return the labels from the objets in the xml file encoded as integers.\"\"\"\n        names = []\n        for obj in self._objects:\n            name = obj.find('name')\n            names.append(name.text)\n        return np.array(names)\n    \n    def _get_bndbox(self):\n        \"\"\"Return the labels from the objets in the xml file.\"\"\"\n        boxes = []\n        for obj in self._objects:\n            coordinates = [] # [xmin, ymin, xmax, ymax]\n            bndbox = obj.find('bndbox')\n            coordinates.append(np.int32(bndbox.find('xmin').text))\n            coordinates.append(np.int32(bndbox.find('ymin').text))\n            coordinates.append(np.int32(bndbox.find('xmax').text))\n            coordinates.append(np.int32(bndbox.find('ymax').text))\n            boxes.append(coordinates)\n        return np.array(boxes)\n    \n#     def get_target(self, root):\n#         \"\"\"Return the target as dict with keys: 'labels', 'boxes'.\"\"\"\n#         target = {}\n#         objects = root.findall('object')\n#         target['labels'] = torch.as_tensor(self.get_labels(objects), dtype=torch.int32)\n#         target['boxes'] = torch.as_tensor(self.get_bndbox(objects), dtype=torch.float32)","95c054a9":"xml = XmlParser(XML_FILES[1])\nprint(\nf\"\"\"xml file: {xml.xml_file}\nimage: {xml.img_path}\nclass names: {xml.names}\nbounding boxes (xmin, ymin, xmax, ymax): {xml.boxes}\"\"\"\n)","91425002":"def xml_files_to_df(xml_files):\n    \"\"\"Return pandas DataFrame from list of XML files.\"\"\"\n    names = []\n    boxes = []\n    xml_path = []\n    img_path = []\n    for file in xml_files:\n        xml = XmlParser(file)\n        names.extend(xml.names)\n        boxes.extend(xml.boxes)\n        # make sure the lenght of the files path is the same as that of the names\n        xml_path.extend([xml.xml_file]*len(xml.names))\n        img_path.extend([xml.img_path]*len(xml.names))\n    return pd.DataFrame({'xml_path': xml_path,\n                         'img_path': img_path,\n                         'names': names,\n                         'boxes': boxes})    ","e8e449c5":"df = xml_files_to_df(XML_FILES)\ndf.head()","eac34158":"df.describe()","eb30a392":"df['names'].value_counts()\/df['names'].count() * 100.","05c7eef6":"options = dict(width=600, height=400, color=color, tools=['hover'], xlabel='Classes', ylabel='Count', title=\"Classes Distribution\")\nhv.Bars(df['names'].value_counts()).opts(**options)","9c6db9d0":"def scale_dimensions(arr, dim):\n    \"\"\"Scales the dimension in order to fit them in the holoviews plot.\"\"\"\n    return (arr - dim \/ 2.) \/ dim","4c03def2":"def path_from_box(box, width=None, height=None):\n    \"\"\"Return the x and y coordinates to draw the box.\"\"\"\n    # [xmin, ymin, xmax, ymax]\n    xmin = 0\n    ymin = 1\n    xmax = 2\n    ymax = 3\n    x = np.array([box[xmin], box[xmax], box[xmax], box[xmin], box[xmin]])\n    y = np.array([box[ymin], box[ymin], box[ymax], box[ymax], box[ymin]])\n    if width and height:\n        x = scale_dimensions(x, width)\n        y = scale_dimensions(y, height)\n    # mirror the y coordinate over the y = 0 line\n    # to make transform it into coordinates staarting from y = 0 \n    return (x, y * -1)","18b1fcc5":"# first 12 images\nimages = [Image.open(im) for im in df['img_path'].unique()[:12]]\n# boxes in each of the 12 images\n# each element of the list contains all the\n# boxes contained in the image\nboxes = [df['boxes'][df['img_path'] == im].values for im in df['img_path'].unique()[:12]]\n# class names for each of the box\nnames = [df['names'][df['img_path'] == im].values for im in df['img_path'].unique()[:12]]","1e9dd92d":"# used to visualize the differnt classes\nmask_color = {'with_mask': 'green', 'mask_weared_incorrect': 'orange', 'without_mask': 'red'}\nimg_plots = []\nfor i, im in enumerate(images):\n    w, h = im.size\n    cc = [hv.Curve(path_from_box(x, w, h)).opts(color=mask_color[name]) for x, name in zip(boxes[i], names[i])]\n    img_plots.append(hv.RGB(np.array(im)).opts(width=w, height=h) * functools.reduce(lambda x,y: x*y, cc))\nhv.Layout(img_plots).cols(3)","df0a0c64":"options = dict(width=600, height=400, color=color, tools=['hover'], xlabel='Number of boxes per iamge', ylabel='Frequency', title=\"Boxes Distribution\")\nbox_count = df.groupby(['img_path']).count()['boxes']\nhist = np.histogram(box_count, np.arange(0, box_count.max() + 5, 5))\nhv.Histogram(hist).opts(**options).redim(x='Number of boxes per iamge')","4468695a":"class MaskDataset(Dataset):\n    def __init__(self, train=True, transform=None):\n        self.transforms = transforms\n        self.train = train\n        # get all the xml files into a list\n        self.xml_files = [os.path.join(XML_PATH, f) for f in os.listdir(XML_PATH)]\n        \n    def __len__(self):\n        return len(self.imgs)\n    \n    def __get_item(idx):\n        xml = XmlParser(xml_files[idx])\n        root = xml.parse_xml()\n        img = Image(xml.get_img_path(root)).convert(\"RGB\")\n        target = xml.get_target(root)\n        \n        if self.transform:\n            img = self.transform(img)         ","a89e47bf":"### Example of an xml object","d5e55d34":"Clearly most images only have less than 5 bounding boxes per image but there are images with over 100 boxes per image.","f4d1a88c":"We now define a function to create a pandas dataframe from all the xml files. We will use this dataframe to analyze the dataset. ","4a77738d":"## Parse the XML files","4edefe37":"## Content\n* [How to parse the XML files](#Parse-the-XML-files)\n* [How to get a DataFrame](#Dataframe-from-the-XML-files)\n* [Analysis](#Analysis)","10620b84":"As we can see there are images with many boxes and with different classes per image. Let's check the distribution of the mounding boxes per image.","9c4d91e1":"### Class distribution","f2f58584":"This notebook provides the tools to get started with this dataset as well as some preliminary analysis.\n\nYou can use the class `XmlParser`, which requires the path to an xml file as input, to return the basic information about the file as an object.<br>\nThis object will have the following attributes:\n* `xml_file`: path to the xml file\n* `img_path`: path to the image file\n* `names` containing an array of all the class names present in the image\n* `boxes` containg an array of all the bounding boxes present in the image\n\nYou can also use the function `xml_files_to_df()` to transform all the xml files into a pandas dataframe.\nThis function requires the list of the xml file paths as input and returns a dataframe. Each row of the dataframe represents one bounding box hence the same image and xml file are presenent multiple times in the dataframe.","2601f783":"## Dataframe from the XML files","6b96923e":"# Face Mask Starter with XML","506d89f9":"As reported by the Dataset author the dataset includes 3 different classes. The dataset is highly class unbalanced with almost 80% of the labels in the images belonging to the class with_mask.","fc3dc8c9":"Let's first define an helper class to process the xml files. This will lead to an object containing all the information needed to create the dataset.","ee90cb1e":"Each object contains the path to the xml file and the relative image, the names of the classes and the coordinates of the bounding boxes for each class.","f251b37a":"Now let's see how the first 12 images look like. In order to visualize the bounding boxes we need to create a curve out of the coordinates we have.\nWe have xmin, ymin, xmax, ymax, hence the curve should go through all the vertices. If we start from the xmin, ymin vertice and go around anticlockwise we would end up with the following pairs:<br>\n\n`((xmin,ymin), (xmax,ymin), (xmax,ymax), (xmin,ymax), (xmin,ymin))`<br>\n\nThe sorted coordinates are then:<br>```x: (xmin, xmax, xmax, xmin, xmin)\ny: (ymin, ymin, ymax, ymax, ymin)```\n","88d9b9d3":"## Analysis","a17719c2":"The author of the dataset wrote that there are 3 different classes: With Mask, Without Mask and Mask Weared Incorrectly. However it is always a good idea to check whether this is true and make sure no mistakes, such as spelling mistakes are present. This also gives us the chance to check the class distribution and check whether this is balanced.","ad3dc316":"## TODO","b6ac66ff":"### Boxes Distribution","31c4ddb5":"## Visualize the Images"}}