{"cell_type":{"64766932":"code","cf002601":"code","70e02dfb":"code","49601fd8":"code","6d4c7f91":"code","84d07143":"code","f02a91b7":"code","b083bf6b":"code","5fc56cd7":"code","31849302":"code","15851c77":"code","b87604bf":"code","b371f509":"code","9759ceb5":"code","4bd9193b":"code","59f60e5c":"code","8c7d5711":"code","493a60ad":"code","0b424cd9":"code","803a7b13":"code","edb38332":"code","d615c4af":"code","a1c183e4":"code","b7933925":"code","c1be79ee":"code","c960a0fd":"code","7bff733a":"code","5956217d":"code","bed425f6":"code","0af7e6d1":"code","4c614b91":"code","3ee3c24b":"code","acc27fb0":"code","abd93500":"code","d04d0277":"code","23667999":"code","8a69a409":"code","ac11bc44":"code","8d1f9b44":"code","8fe40778":"code","5a619c82":"code","54978416":"code","c5ae193d":"code","4eec2085":"code","552a2e51":"code","53aaae84":"code","422badc2":"markdown","1e0f2fd1":"markdown","8893f58e":"markdown","0a284950":"markdown","0c7fdc7d":"markdown","1264426c":"markdown","feae9c58":"markdown","8da8f371":"markdown","444d48fd":"markdown","59ddc4eb":"markdown","a13114fd":"markdown","25182c03":"markdown","954c0c67":"markdown","fbb3005c":"markdown","bd925fd5":"markdown","4b4baffa":"markdown","cb5b456f":"markdown","d4c94de0":"markdown","a529ee46":"markdown","c7bc5b03":"markdown"},"source":{"64766932":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cf002601":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport random\n\n# Sklearn\nfrom sklearn.model_selection import train_test_split\n\n# keras\nfrom keras_preprocessing.image import ImageDataGenerator, load_img\nfrom keras.utils import to_categorical\n\n","70e02dfb":"import zipfile\nzip_files = ['test1', 'train']\n\nfor zip_file in zip_files:\n    with zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/{}.zip\".format(zip_file), \"r\") as z:\n        z.extractall(\".\")\n        print(\"{} unzipped\".format(zip_file))","49601fd8":"print(os.listdir(\"..\/input\/dogs-vs-cats\"))","6d4c7f91":"train_folder_path = \"..\/working\/train\"\nfilenames = os.listdir(train_folder_path)","84d07143":"categories = []\nfor filename in filenames:\n  category = filename.split(\".\")[0]\n  if category == 'dog':\n    categories.append(1)\n  else:\n    categories.append(0)\n\ndf = pd.DataFrame({'filename': filenames, \n                   'category' : categories})","f02a91b7":"df.head()","b083bf6b":"df.tail()","5fc56cd7":"df['category'].value_counts()","31849302":"df.shape","15851c77":"df['category'].value_counts().plot(kind = 'bar')","b87604bf":"train_folder_path + \"\/\" +sample","b371f509":"sample= random.choice(filenames)\nimage = load_img(train_folder_path + \"\/\" +sample)\nplt.imshow(image)","9759ceb5":"img_wd, img_ht = 128, 128","4bd9193b":"# import layers from keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n","59f60e5c":"model = Sequential()\n\n# layer 1 (Convo)\nmodel.add(Conv2D(32,(3,3),activation='relu',\n                 input_shape=(img_wd,img_ht,3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\n# layer 2 ( Convo)\nmodel.add(Conv2D(64, (3,3), activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(0.25))\n\n# layer 3 (Convo)\nmodel.add(Conv2D(128, (3,3), activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(0.25))\n\n# layer 4 Dense \nmodel.add(Flatten()) # input layer\nmodel.add(Dense(512, activation = 'relu')) # hidden layer\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(2, activation = 'softmax')) # output layer\n\n# model compile\nmodel.compile(loss = 'categorical_crossentropy', \n              optimizer = 'rmsprop', metrics = ['accuracy'])\nmodel.summary()","8c7d5711":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau","493a60ad":"earlystop = EarlyStopping(patience=15)","0b424cd9":"lr_reduction = ReduceLROnPlateau(monitor = 'val_acc', patience = 2, verbose = 1, \n                                factor = 0.5, min_lr = 0.00001)","803a7b13":"callbacks = [earlystop, lr_reduction]","edb38332":"df['category'] = df['category'].map({0: 'cat', 1: 'dog'})","d615c4af":"train_df, validate_df = train_test_split(df, test_size= 0.2, random_state=42)\ntrain_df = train_df.reset_index(drop = True)\nvalidate_df = validate_df.reset_index(drop = True)","a1c183e4":"train_df['category'].value_counts().plot(kind = 'bar')","b7933925":"validate_df['category'].value_counts().plot(kind = 'bar')","c1be79ee":"train_size = train_df.shape[0]\nval_size = validate_df.shape[0]\nbatch_size = 200","c960a0fd":"train_datagen = ImageDataGenerator(rotation_range= 15, \n                                  rescale= 1\/255,\n                                  shear_range= 0.1,\n                                  zoom_range=0.2,\n                                  horizontal_flip=True,\n                                  width_shift_range = 0.1,\n                                  height_shift_range=0.1)\ntrain_generator = train_datagen.flow_from_dataframe(train_df, \n                                                   \"..\/working\/train\/\",\n                                                   x_col = 'filename', \n                                                   y_col = 'category', \n                                                   target_size = (img_wd,img_ht),\n                                                   class_mode = 'categorical')","7bff733a":"valid_datagen = ImageDataGenerator(rescale = 1\/255)\n\nvalid_generator = valid_datagen.flow_from_dataframe(validate_df, \n                                                   \"..\/working\/train\/\",\n                                                   x_col = 'filename', \n                                                   y_col = 'category', \n                                                   target_size = (img_wd,img_ht),\n                                                   class_mode = 'categorical', \n                                                   batch_size=batch_size)\n","5956217d":"example_df = train_df.sample(n = 1).reset_index(drop=True)\nexample_gen = train_datagen.flow_from_dataframe(example_df, \n                                                   \"..\/working\/train\/\",\n                                                   x_col = 'filename', \n                                                   y_col = 'category', \n                                                   target_size = (img_wd,img_ht),\n                                                   class_mode = 'categorical')","bed425f6":"plt.figure(figsize = (12, 12))\nfor i in range(0, 20):\n    plt.subplot(5, 4, i+1)\n    for x_batch, y_batch in example_gen:\n        img = x_batch[0]\n        plt.imshow(img)\n        break\nplt.tight_layout()","0af7e6d1":"Fast_run = False\nepochs = 3 if Fast_run else 50\nhistroy = model.fit(train_generator, \n                             epochs = epochs,\n                             validation_data=valid_generator,\n                             validation_steps=val_size\/\/batch_size, \n                             steps_per_epoch=train_size\/\/batch_size,\n                             callbacks = callbacks)","4c614b91":"model.save('model.h5')","3ee3c24b":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize =(12,12))\n\nax1.plot(histroy.history['loss'], color = 'b', label = 'Training loss')\nax1.plot(histroy.history['val_loss'], color = 'r', label = 'validation loss')\nax1.set_xticks(np.arange(1, epochs, 1))\nax1.set_yticks(np.arange(0,1,0.1))\n\nax2.plot(histroy.history['accuracy'], color = 'b', label = 'Training acc')\nax2.plot(histroy.history['val_accuracy'],color = 'r', label = 'validation acc')\nax2.set_xticks(np.arange(1,epochs, 1))\n\nlegend = plt.legend(loc = 'best', shadow = True)\nplt.tight_layout()","acc27fb0":"test_folder_path = \"..\/working\/test1\"\ntest_filenames = os.listdir(test_folder_path)\n\ntest_df = pd.DataFrame({'filename': test_filenames})\ntest_size = test_df.shape[0]","abd93500":"test_datagen = ImageDataGenerator(rescale = 1\/255)\ntest_generator = test_datagen.flow_from_dataframe(test_df,\n                                                 \"..\/working\/test1\/\",\n                                                 x_col = 'filename',\n                                                 y_col = None,\n                                                 class_mode = None,\n                                                 target_size = (img_wd, img_ht),\n                                                 batch_size = batch_size,\n                                                 shuffle = False\n                                                 )","d04d0277":"predict = model.predict(test_generator, steps = np.ceil(test_size\/batch_size))","23667999":"test_df['category'] = np.argmax(predict, axis = -1)","8a69a409":"predict","ac11bc44":"test_df.head()","8d1f9b44":"label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n\ntest_df['category'] = test_df['category'].map(label_map)","8fe40778":"test_df['category'] = test_df['category'].map({'cat':0, 'dog':1})","5a619c82":"test_df.head()","54978416":"test_df['category'].value_counts()","c5ae193d":"sample_test = test_df.head(15)\nsample_test.head()\nplt.figure(figsize = (12,24))\n\nfor index, row in sample_test.iterrows():\n    filename = row['filename']\n    category = row['category']\n    img = load_img(\"..\/working\/test1\/\" + filename, \n                   target_size = (img_wd, img_ht))\n    plt.subplot(5,3, index +1)\n    plt.imshow(img)\n    plt.xlabel(filename + '(' + \"{}\".format(category) + \")\")\n    \nplt.tight_layout()","4eec2085":"submission_df = test_df.copy()\nsubmission_df['id'] = submission_df['filename'].str.split(\".\").str[0]\nsubmission_df.rename(columns= {'category': 'label'}, inplace = True)","552a2e51":"submission_df.drop('filename', axis = 1, inplace = True)","53aaae84":"submission_df.to_csv('submission.csv', index = False)","422badc2":"# Model Fitting","1e0f2fd1":"**Learning Rate Reduction**    \nWe will reduce the learning rate when then accuracy not increase for 2 steps","8893f58e":"For categoral classication the prediction will come with probability of each category. So we will pick the category that have the highest probability with numpy average max","0a284950":"# Image Generator for data augmentation","0c7fdc7d":"## Preparing Test Data","1264426c":"# Predict","feae9c58":"Unzip the folders","8da8f371":"# Build Model Framework ","444d48fd":"## Visualize Training","59ddc4eb":"# Submission","a13114fd":"# Save Model","25182c03":"## Validation Data Generator","954c0c67":"## Data Preparation","fbb3005c":"Because we will use image genaretor with class_mode=\"categorical\". We need to convert column category into string. Then imagenerator will convert it one-hot encoding which is good for our classification.\n\nSo we will convert 1 to dog and 0 to cat","bd925fd5":"## See predicted results with images","4b4baffa":"## Train data generator","cb5b456f":"## Callbacks","d4c94de0":"## Creating Test Generators","a529ee46":"## See sample image","c7bc5b03":"## let's see the working of generator"}}