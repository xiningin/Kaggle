{"cell_type":{"39e7cd2a":"code","d623eb03":"code","2411c7e4":"code","ed47fefb":"code","66e081ec":"code","cc577140":"code","5dafd80a":"code","f19802fd":"code","24f70f1e":"code","0028e618":"code","cac04543":"code","78c6c82a":"code","78644eab":"code","7631f398":"code","2d28cd2c":"code","bf073e14":"code","93ce3ba0":"code","13b61ab7":"code","de67bce6":"code","34530892":"code","497a1a7c":"code","2967728a":"code","e76182e3":"code","bf18bc9e":"code","c74efaaa":"code","1906a648":"code","88596311":"code","d775ad13":"code","18458281":"code","ca1fd8b7":"code","7aec3058":"code","0da4bf7a":"code","756720ba":"code","31d4de03":"code","89b486f4":"code","e567245d":"code","7fcf7308":"code","bed6278e":"code","71394232":"code","2597cba4":"code","84c5fc27":"code","8ef3d12c":"code","e282bd04":"code","4c4419d5":"code","abf77f7d":"code","69da9c3c":"code","5f363dff":"code","c52cd7f9":"code","837a9857":"code","20d97e50":"code","26120616":"code","002392f8":"markdown","b049dedc":"markdown","2aaeacd9":"markdown","6e3047a0":"markdown","c2dc91c4":"markdown","db93c7a0":"markdown","cb348c0a":"markdown","656301ea":"markdown","be50d313":"markdown","6192da3e":"markdown","aac1e9fa":"markdown","e9d07c96":"markdown","e0de3069":"markdown","9756fa32":"markdown","acf46e6e":"markdown","123d0718":"markdown","5e1d4116":"markdown","a5450b94":"markdown"},"source":{"39e7cd2a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d623eb03":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","2411c7e4":"import plotly\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom plotly.offline import download_plotlyjs, plot, init_notebook_mode, iplot","ed47fefb":"# Load the data from the CSV file\ndata = pd.read_csv('\/kaggle\/input\/netflix-shows\/netflix_titles.csv')","66e081ec":"# Display the first 5 rows of data\ndata.head()","cc577140":"# Display the last 5 rows of data\ndata.tail()","5dafd80a":"# There are 7787 movies \/ TV shows in the dataset\nprint('Total Number of Rows:', data.shape[0])\nprint('Total Number of Columns:', data.shape[1])\nprint('-' * 10)\n# Check if there is any duplicated records\nprint('Duplicated Records:', data.duplicated().any())\nprint('-' * 10)\nprint('Missing Values:', data.isnull().values.sum())\nprint('\\n')\nprint('Unique Values: \\n\\n', data.nunique())\nprint('-' * 10)\n# Most of the missing values is in the director, cast and country column\nprint('Missing rows in each column: \\n')\nfor i in data.columns:\n    # Total number of null values in the column \n    nullNum = data[i].isnull().sum()\n    nullRate = nullNum \/ len(data) * 100 \n    if nullRate > 0:\n        print(f\"{i} {nullNum} ({nullRate:.2f}%)\")","f19802fd":"# We can observe 11 of the datatype are object and 1 is integer\ndata.info()","24f70f1e":"# Data frame of date_added column\ndata[\"date_added\"].value_counts().to_frame()","0028e618":"# Replace null values in data_added column with January 1, mode of {release_year} column\ndata[\"date_added\"] = data[\"date_added\"].fillna(data[\"date_added\"].mode()[0])","cac04543":"# Check if all the null values in date_added column are filled\ndata[\"date_added\"].isnull().sum()","78c6c82a":"import re\n\nmonths = {\n    'January': 1,\n    'February': 2,\n    'March': 3,\n    'April': 4,\n    'May': 5,\n    'June': 6,\n    'July': 7,\n    'August': 8,\n    'September': 9,\n    'October': 10,\n    'November': 11,\n    'December': 12\n}\ndateList = []\n\n# Convert the date_added column from object type to datetime\nfor i in data['date_added'].values:\n    str1 = re.findall('([a-zA-Z]+)\\s[0-9]+\\,\\s[0-9]+', i)\n    str2 = re.findall('[a-zA-Z]+\\s([0-9]+)\\,\\s[0-9]+', i)\n    str3 = re.findall('[a-zA-Z]+\\s[0-9]+\\,\\s([0-9]+)', i)\n    date = '{}-{}-{}'.format(str3[0], months[str1[0]], str2[0])\n    dateList.append(date)\n    \ndata['date_added_cleaned'] = dateList\ndata = data.drop('date_added', axis = 1)\ndata['date_added_cleaned'] = data['date_added_cleaned'].astype('datetime64[ns]')\n\ndata.head(3)","78644eab":"# Data frame of country column\ndata[\"country\"].value_counts().to_frame()","7631f398":"# Replace null values in country column by Japan for Anime\nfor i, j in zip(data['country'].values, data.index):\n    if i == np.nan:\n        if ('Anime' in data.loc[j, 'listed_in']) or ('anime' in data.loc[j, 'listed_in']):\n            data.loc[j, 'country'] = 'Japan'\n        else:\n            continue\n    else:\n        continue\n\n# Replace null values in country column with the word Unknown\ndata['country'] = data['country'].fillna('Unknown')","2d28cd2c":"# Check if all the null values in country column are filled\ndata['country'].isnull().sum()","bf073e14":"# Data frame of rating column\nrating_order = data[\"rating\"].value_counts().to_frame()\nrating_order","93ce3ba0":"# Replace null values in rating column with the mode: TV-MA\ndata['rating'] = data['rating'].fillna(data['rating'].mode()[0])","13b61ab7":"# Check if all the null values in rating column are filled\ndata['rating'].isnull().sum()","de67bce6":"# Data frame of director column\ndata[\"director\"].value_counts().to_frame()","34530892":"# Replace null values in director column with word Unknown\ndata['director'] = data['director'].fillna('Unknown')","497a1a7c":"# Check if all the null values in director column are filled\ndata[\"director\"].isnull().sum()","2967728a":"# Data frame of cast column\ndata[\"cast\"].value_counts().to_frame()","e76182e3":"# Replace null values in cast column with word Unknown\ndata['cast'] = data['cast'].fillna('Unknown')\n\n# Add a column for number of cast\ndef cast_counter(cast):\n    if cast == 'Unknown':\n        return 0\n    else:\n        castList = cast.split(', ')\n        castLength = len(castList)\n        return castLength\n\ndata['number_of_cast'] = data['cast'].apply(cast_counter)","bf18bc9e":"# Check if all the null values in cast column are filled\ndata[\"cast\"].isnull().sum()","c74efaaa":"# Plot the bar chart for the number of movies and TV shows\nplt.figure(figsize = (8,6))\nsns.countplot(x = \"type\", data = data)\n\n# Get current axis on current figure\nax = plt.gca()\n\n# The maximum scale of y axis\ny_max = data['type'].value_counts().max() \nax.set_ylim([0, y_max + 1000])\n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width() \/ 2., p.get_height(), '%d' % int(p.get_height()), \n            fontsize = 12, color = 'black', ha = 'center', va = 'bottom')\n\n# There are more movies than TV shows in Netflix\nplt.title('Comparison of Total TV Shows & Movies', size = '15')\nplt.show()","1906a648":"# Plot the pie chart for the distribution of movies and TV shows\nmovies_count = data[data.type == 'Movie']\ntvshows_count = data[data.type == 'TV Show']\n\ncolors = ['red', 'black']\ntrace = go.Pie(labels = ['Movie', 'TV Show'], \n               values = [movies_count.type.count(), tvshows_count.type.count()],\n               hoverinfo = 'label + percent', textinfo = 'label + percent', marker = dict(colors = colors,\n                line = dict(color = 'blue', width = 2)))\n\nfig = go.Figure(data = [trace])\niplot(fig)","88596311":"# Plot the bar chart for the TV rating distribution \nplt.figure(figsize = (12,8))\nsns.countplot(data.rating, order = rating_order.index)\nplt.title(\"Rating for Movies And TV Shows\")\nplt.xlabel(\"Rating\")\nplt.ylabel(\"Total Count\")\n\n# The content for mature adult is the most abundent\nplt.show()","d775ad13":"# Plot the bar chart for the TV rating distribution of movies and TV shows separately\nplt.figure(figsize = (12,8))\nsns.countplot(x = 'rating', data = data, hue = 'type')\nplt.xlabel('Rating')\nplt.ylabel('Total Count')\nplt.show()","18458281":"# List the years with most content released\nyear_wise_content = data.release_year.value_counts().index[0:20]\nyear_wise_content","ca1fd8b7":"# Plot the bar chart for the release year distribution of movies and TV shows\nplt.figure(figsize = (12,10))\n\n# Most content is released from 2016 to 2020\nsns.countplot(data = data, y = 'release_year', order = year_wise_content)","7aec3058":"# Plot the bar chart for the release year distribution of movies and TV shows separately\nplt.figure(figsize = (8,6))\n\nimport datetime\nstartYear = datetime.datetime.now().year - 5 + 1\nlastFiveYears =  data[data.release_year >= startYear]\n\nsns.catplot(data = lastFiveYears, kind = 'count',\n    x = 'release_year', hue = 'type', height = 6)\n\nax = plt.gca()\n\n# The maximum scale of y axis\nax.set_ylim([0, 1000])\n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/2., p.get_height(), '%d' % int(p.get_height()), \n            fontsize = 12, color = 'black', ha = 'center', va = 'bottom')\n\n# The movies produced are decreasing while the TV shows produced are increasing in the last 5 years\nplt.title('Last 5 years trends in Netflix', size = '15')\nplt.show()","0da4bf7a":"# Plot the bar and pie chart for the conuntry distribution of movies\nfrom collections import Counter\ncountry_data = data['country']\ncountry_counting = pd.Series(dict(Counter(','.join(country_data).replace(' ,',',').replace(', ',',').split(',')))).sort_values(ascending = False)\ntop20_country = country_counting[0:20]\n\nfrom matplotlib import gridspec\nfig = plt.figure(figsize = (20, 6))\ngs = gridspec.GridSpec(nrows = 1, ncols = 2,\n                       height_ratios = [6], \n                       width_ratios = [10, 5])\n\nax = plt.subplot(gs[0])\nsns.barplot(top20_country.index, top20_country, ax = ax)\nax.set_xticklabels(top20_country.index, rotation = '90')\nax.set_title('Top 20 producing countries', fontsize = 15, fontweight='bold')\n\nax2 = plt.subplot(gs[1])\nax2.pie(top20_country, labels = top20_country.index)\nax2.axis('equal') \n\n# United States produced the most content\nplt.show()","756720ba":"from sklearn.preprocessing import MultiLabelBinarizer # Similar to One-Hot Encoding\n\ndef relation_heatmap(df, title):\n    df['genre'] = df['listed_in'].apply(lambda x :  x.replace(' ,',',').replace(', ',',').split(',')) \n    Types = []\n    for i in df['genre']: Types += i\n    Types = set(Types)\n    print(f\"There are {len(Types)} types in the Netflix {title} Dataset\")    \n    test = df['genre']\n    mlb = MultiLabelBinarizer()\n    res = pd.DataFrame(mlb.fit_transform(test), columns = mlb.classes_, index = test.index)\n    corr = res.corr()\n    mask = np.zeros_like(corr, dtype = np.bool)\n    mask[np.triu_indices_from(mask)] = True\n    fig, ax = plt.subplots(figsize = (15, 14))\n    pl = sns.heatmap(corr, mask = mask, cmap = \"coolwarm\", vmax = .5, vmin = -.5, center = 0,\n                    square = True, linewidths = .7, cbar_kws = {\"shrink\": 0.6})\n    \n    plt.show()","31d4de03":"# Movie Genre Relatation\n# Dramas is not likely to be Documentaries\n# Dramas is very likely to be Independent and International Movies\nrelation_heatmap(movies_count, 'Movie')","89b486f4":"# TV Show Genre Relation\n# Kids' TV is not likely to be Internation TV Shows\n# Science and Nature TV is very likely to be Docuseries\nrelation_heatmap(tvshows_count, 'TV Show')","e567245d":"# Plot the histogram for the durtation of movies\n# Most movies last for 75 - 120 mins\nsns.set(style = \"darkgrid\")\nsns.kdeplot(data = movies_count['duration'].str.replace(' min','').astype(int), shade = True)","7fcf7308":"from collections import Counter\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom PIL import Image\n\ndef generateWordCloud(df):\n    # Get the unique values of content genres\n    genres = list(df['listed_in'])\n    gen = []\n\n    for i in genres:\n        i = list(i.split(','))\n        for j in i:\n            gen.append(j.replace(' ',\"\"))\n    g = Counter(gen)\n\n    # Generate the Word Cloud for content genres\n    text = list(set(gen))\n    plt.rcParams['figure.figsize'] = (13, 13)\n\n    wordcloud = WordCloud(background_color = \"white\").generate(str(text))\n\n    plt.imshow(wordcloud, interpolation = \"bilinear\")\n    plt.axis(\"off\")\n    plt.show()","bed6278e":"# Word Cloud for movies genres\ngenerateWordCloud(movies_count)","71394232":"# Word Cloud for TV shows genres\ngenerateWordCloud(tvshows_count)","2597cba4":"# import librairies\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport math as math\nimport time \nplt.style.use('seaborn')\nplt.rcParams['figure.figsize'] = [14,14]","84c5fc27":"# load the data\ndf = pd.read_csv('\/kaggle\/input\/netflix-shows\/netflix_titles.csv')\n# convert to datetime\ndf[\"date_added\"] = pd.to_datetime(df['date_added'])\ndf['year'] = df['date_added'].dt.year\ndf['month'] = df['date_added'].dt.month\ndf['day'] = df['date_added'].dt.day\n# convert columns \"director, listed_in, cast and country\" in columns that contain a real list\n# the strip function is applied on the elements\n# if the value is NaN, the new column contains a empty list []\ndf['directors'] = df['director'].apply(lambda l: [] if pd.isna(l) else [i.strip() for i in l.split(\",\")])\ndf['categories'] = df['listed_in'].apply(lambda l: [] if pd.isna(l) else [i.strip() for i in l.split(\",\")])\ndf['actors'] = df['cast'].apply(lambda l: [] if pd.isna(l) else [i.strip() for i in l.split(\",\")])\ndf['countries'] = df['country'].apply(lambda l: [] if pd.isna(l) else [i.strip() for i in l.split(\",\")])\n\ndf.head()","8ef3d12c":"print(df.shape)","e282bd04":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel\nfrom sklearn.cluster import MiniBatchKMeans\n\n# Build the tfidf matrix with the descriptions\nstart_time = time.time()\ntext_content = df['description']\nvector = TfidfVectorizer(max_df=0.4,         # drop words that occur in more than X percent of documents\n                             min_df=1,      # only use words that appear at least X times\n                             stop_words='english', # remove stop words\n                             lowercase=True, # Convert everything to lower case \n                             use_idf=True,   # Use idf\n                             norm=u'l2',     # Normalization\n                             smooth_idf=True # Prevents divide-by-zero errors\n                            )\ntfidf = vector.fit_transform(text_content)\n\n# Clustering  Kmeans\nk = 200\nkmeans = MiniBatchKMeans(n_clusters = k)\nkmeans.fit(tfidf)\ncenters = kmeans.cluster_centers_.argsort()[:,::-1]\nterms = vector.get_feature_names()\n\n# print the centers of the clusters\n# for i in range(0,k):\n#     word_list=[]\n#     print(\"cluster%d:\"% i)\n#     for j in centers[i,:10]:\n#         word_list.append(terms[j])\n#     print(word_list) \n    \nrequest_transform = vector.transform(df['description'])\n# new column cluster based on the description\ndf['cluster'] = kmeans.predict(request_transform) \n\ndf['cluster'].value_counts().head()","4c4419d5":"# Find similar : get the top_n movies with description similar to the target description \ndef find_similar(tfidf_matrix, index, top_n = 5):\n    cosine_similarities = linear_kernel(tfidf_matrix[index:index+1], tfidf_matrix).flatten()\n    related_docs_indices = [i for i in cosine_similarities.argsort()[::-1] if i != index]\n    return [index for index in related_docs_indices][0:top_n]  ","abf77f7d":"G = nx.Graph(label=\"MOVIE\")\nstart_time = time.time()\nfor i, rowi in df.iterrows():\n    if (i%1000==0):\n        print(\" iter {} -- {} seconds --\".format(i,time.time() - start_time))\n    G.add_node(rowi['title'],key=rowi['show_id'],label=\"MOVIE\",mtype=rowi['type'],rating=rowi['rating'])\n#    G.add_node(rowi['cluster'],label=\"CLUSTER\")\n#    G.add_edge(rowi['title'], rowi['cluster'], label=\"DESCRIPTION\")\n    for element in rowi['actors']:\n        G.add_node(element,label=\"PERSON\")\n        G.add_edge(rowi['title'], element, label=\"ACTED_IN\")\n    for element in rowi['categories']:\n        G.add_node(element,label=\"CAT\")\n        G.add_edge(rowi['title'], element, label=\"CAT_IN\")\n    for element in rowi['directors']:\n        G.add_node(element,label=\"PERSON\")\n        G.add_edge(rowi['title'], element, label=\"DIRECTED\")\n    for element in rowi['countries']:\n        G.add_node(element,label=\"COU\")\n        G.add_edge(rowi['title'], element, label=\"COU_IN\")\n    \n    indices = find_similar(tfidf, i, top_n = 5)\n    snode=\"Sim(\"+rowi['title'][:15].strip()+\")\"        \n    G.add_node(snode,label=\"SIMILAR\")\n    G.add_edge(rowi['title'], snode, label=\"SIMILARITY\")\n    for element in indices:\n        G.add_edge(snode, df['title'].loc[element], label=\"SIMILARITY\")\nprint(\" finish -- {} seconds --\".format(time.time() - start_time))   ","69da9c3c":"def get_all_adj_nodes(list_in):\n    sub_graph=set()\n    for m in list_in:\n        sub_graph.add(m)\n        for e in G.neighbors(m):        \n                sub_graph.add(e)\n    return list(sub_graph)\ndef draw_sub_graph(sub_graph):\n    subgraph = G.subgraph(sub_graph)\n    colors=[]\n    for e in subgraph.nodes():\n        if G.nodes[e]['label']==\"MOVIE\":\n            colors.append('blue')\n        elif G.nodes[e]['label']==\"PERSON\":\n            colors.append('red')\n        elif G.nodes[e]['label']==\"CAT\":\n            colors.append('green')\n        elif G.nodes[e]['label']==\"COU\":\n            colors.append('yellow')\n        elif G.nodes[e]['label']==\"SIMILAR\":\n            colors.append('orange')    \n        elif G.nodes[e]['label']==\"CLUSTER\":\n            colors.append('orange')\n\n    nx.draw(subgraph, with_labels=True, font_weight='bold',node_color=colors)\n    plt.show()","5f363dff":"list_in = ['Inception', 'Star Wars: Episode VIII: The Last Jedi']\nsub_graph = get_all_adj_nodes(list_in)\ndraw_sub_graph(sub_graph)","c52cd7f9":"def get_recommendation(root):\n    commons_dict = {}\n    for e in G.neighbors(root):\n        for e2 in G.neighbors(e):\n            if e2==root:\n                continue\n            if G.nodes[e2]['label']==\"MOVIE\":\n                commons = commons_dict.get(e2)\n                if commons==None:\n                    commons_dict.update({e2 : [e]})\n                else:\n                    commons.append(e)\n                    commons_dict.update({e2 : commons})\n    movies=[]\n    weight=[]\n    for key, values in commons_dict.items():\n        w=0.0\n        for e in values:\n            w=w+1\/math.log(G.degree(e))\n        movies.append(key) \n        weight.append(w)\n    \n    result = pd.Series(data=np.array(weight),index=movies)\n    result.sort_values(inplace=True,ascending=False)        \n    return result;","837a9857":"result = get_recommendation(\"Inception\")\nresult2 = get_recommendation(\"Star Wars: Episode VIII: The Last Jedi\")\nresult3 = get_recommendation(\"Avengers: Infinity War\")\nresult4 = get_recommendation(\"Spider-Man 3\")\nprint(\"*\"*40+\"\\n Recommendation for Inception\\n\"+\"*\"*40)\nprint(result.head())\nprint(\"*\"*40+\"\\n Recommendation for Star Wars: Episode VIII: The Last Jedi\\n\"+\"*\"*40)\nprint(result2.head())\nprint(\"*\"*40+\"\\n Recommendation for Avengers: Infinity War\\n\"+\"*\"*40)\nprint(result3.head())\nprint(\"*\"*40+\"\\n Recommendation for Spider-Man 3\\n\"+\"*\"*40)\nprint(result4.head())","20d97e50":"reco = list(result.index[0:2].values)\nreco.extend(['Spider-Man 3'])\nsub_graph = get_all_adj_nodes(reco)\ndraw_sub_graph(sub_graph)","26120616":"reco = list(result4.index[0:4].values)\nreco.extend(['Inception'])\nsub_graph = get_all_adj_nodes(reco)\ndraw_sub_graph(sub_graph)","002392f8":"<h1 style=color:blue align=\"left\"> Visualizations <\/h1>","b049dedc":"<h2 style=color:green align=\"left\"> Fill Missing Values <\/h2>","2aaeacd9":"|Variable             |Description                                        |\n|---------------------|---------------------------------------------------|\n|Show_id              |Unique ID for every Movie \/ Tv Show                |\n|Type                 |Identifier - A Movie or TV Show                    |\n|Title                |Title of the Movie \/ Tv Show                       |\n|Director             |Director of the Movie                              |\n|Cast                 |Actors involved in the movie \/ show                |\n|Country              |Country where the movie \/ show was produced        |\n|Date_added           |Date it was added on Netflix                       |\n|Release_year         |Actual Release year of the move \/ show             |\n|Rating               |TV Rating of the movie \/ show                      |\n|Duration             |Total Duration - in minutes or number of seasons   |\n|Listed_in            |Genre                                              |\n|Description          |The summary description                            |","6e3047a0":"--------------------------","c2dc91c4":"<h2 style=color:green align=\"left\"> Movies and TV Shows Content Comparison <\/h2>","db93c7a0":"<h2 style=color:green align=\"left\"> Load and Check Data <\/h2>","cb348c0a":"<h1 style=color:blue align=\"left\"> Load Required Libraries <\/h1>","656301ea":"<h2 style=color:green align=\"left\"> Comparison of Movies and TV Shows <\/h2>","be50d313":"<h3 style=color:blue align=\"left\"> director <\/h3>","6192da3e":"<h3 style=color:blue align=\"left\"> country <\/h3>","aac1e9fa":"|Rating Label   |Description                                                                          |\n|---------------|-------------------------------------------------------------------------------------|\n|TV-MA          |This program is intended to be viewed by mature, adult audiences and may be unsuitable for children under 17|\n|TV-14          |This program may be unsuitable for children under 14 years of age                    |\n|TV-PG          |This program contains material that parents may find unsuitable for younger children. Parental guidance is recommended|\n|R              |May be unsuitable for children under the age of 17 (Under 17 requires accompanying parent or adult guardian)|\n|TV-Y           |This program is aimed at a very young audience, including children from ages 2\u20136     |\n|TV-PG          |This program contains material that parents may find unsuitable for younger children. Parental guidance is recommended|\n|TV-Y7          |This program is most appropriate for children age 7 and up                           |\n|TV-G           |This program is suitable for all ages.                                               |","e9d07c96":"<h1 style=\"color:green; align:center\">Netflix Movies and TV Shows - Data Analysis and Visualization<\/h1> \n<hr style=\"width:100%; height:5px; border-width:0; color:gray; background-color:gray;\">\n<center><img style=\"height:450px;\" src=\"https:\/\/media.npr.org\/assets\/img\/2019\/07\/04\/ap_19165551810863-852cd5b90680e782e02303308afd219172d04aa1-s800-c85.jpg\"><\/center>","e0de3069":"# **Recommedation Engine**","9756fa32":"<h3 style=color:blue align=\"left\"> rating <\/h3>","acf46e6e":"<h3 style=color:blue align=\"left\"> cast <\/h3>","123d0718":"<h3 style=color:blue align=\"left\"> date_added <\/h3>","5e1d4116":"<h1 style=color:blue align=\"left\"> Exploratory Data Analysis <\/h1>","a5450b94":"<h2 style=color:green align=\"left\"> Find Missing Values <\/h2>"}}