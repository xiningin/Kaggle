{"cell_type":{"b8aa0c31":"code","ae386832":"code","9b8300f1":"code","7469443c":"code","a8117263":"code","219d68cb":"code","c9aa60af":"code","48b37d96":"code","cff49d50":"code","693625d4":"code","ce513cfc":"code","c07dc986":"code","56b0e213":"code","999c97d7":"code","1f37914a":"code","8da8e53f":"code","7d4971e0":"code","b92e4dd7":"code","a1266f5c":"code","d76cc9b9":"code","b6084fa8":"code","19781b55":"code","6f8e3d1c":"code","635eb574":"code","18a3508f":"code","4e84f86e":"code","b3735930":"code","f2fbdb12":"code","d0ede0c5":"code","dc42f415":"code","b06628b7":"code","6a5a43bc":"code","b95ec957":"code","2388b851":"code","fed570b6":"code","96e4fd9f":"code","b7575bf7":"code","6ab24a86":"code","ae4f7d98":"code","94fae202":"markdown","7f0659c0":"markdown","73c21a48":"markdown","7a5b2b78":"markdown","d3a832b8":"markdown","3e50f788":"markdown","27d72a1f":"markdown","537ec74e":"markdown"},"source":{"b8aa0c31":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport random\n","ae386832":"mnist = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")","9b8300f1":"mnist","7469443c":"y = mnist.iloc[:, 0].values\nx = mnist.iloc[:, 1:].values","a8117263":"x","219d68cb":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state = 42)","c9aa60af":"x_test = x_test \/ 255\nx_train = x_train \/ 255\nx_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\nx_test = x_test.reshape(x_test.shape[0], 28, 28, 1)","48b37d96":"y_train = tf.keras.utils.to_categorical(y_train, 10)\ny_test = tf.keras.utils.to_categorical(y_test, 10)","cff49d50":"# hyper parameters\nlearning_rate = 0.001","693625d4":"model = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Conv2D(filters=20, kernel_size=(3, 3), input_shape=(28,28,1),activation='relu',kernel_initializer='glorot_uniform',padding=\"same\"))\nfor a in range(3):\n    model.add(tf.keras.layers.Conv2D(filters=62, kernel_size=(3, 3), activation='relu',kernel_initializer='glorot_uniform',padding=\"same\"))\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(units=100, kernel_initializer='glorot_normal', activation='relu'))\nmodel.add(tf.keras.layers.Dense(units=10, kernel_initializer='glorot_normal', activation='softmax'))\nmodel.summary()","ce513cfc":"model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n","c07dc986":"from tensorflow.keras.callbacks import EarlyStopping\n\nEarlyStopping = EarlyStopping(monitor='val_loss', patience = 5, verbose=1)","56b0e213":"history = model.fit(x_train, y_train, batch_size=100, epochs=10,validation_data =(x_test,y_test),callbacks=EarlyStopping)","999c97d7":"history_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['accuracy', 'val_accuracy']].plot();","1f37914a":"y_predicted = model.predict(x_test)\nfor x in range(0, 10):\n    random_index = random.randint(0, x_test.shape[0]-1)\n    print(\"index: \", random_index,\n          \"actual y: \", np.argmax(y_test[random_index]),\n          \"predicted y: \", np.argmax(y_predicted[random_index]))\n\nevaluation = model.evaluate(x_test, y_test)\nprint('loss: ', evaluation[0])\nprint('accuracy', evaluation[1])","8da8e53f":"y_train = tf.keras.utils.to_categorical(y_train, 10)\ny_test = tf.keras.utils.to_categorical(y_test, 10)","7d4971e0":"test = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\").values\ntest = test.reshape(-1, 28, 28, 1).astype('float32') \/ 255.0\ny_pred = model.predict(test).argmax(axis=1)","b92e4dd7":"submission = pd.DataFrame({'ImageId': np.arange(1, 28001), 'Label': y_pred})\nsubmission.to_csv(\"submission3.csv\", index = False)","a1266f5c":"import tensorflow as tf\nfrom tensorflow.keras import layers\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","d76cc9b9":"from tensorflow.keras.applications import EfficientNetB0\nefficientnet = EfficientNetB0(weights='imagenet', include_top=False)\nefficientnet.trainable=False","b6084fa8":"IMG_SIZE = 224","19781b55":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")","6f8e3d1c":"X = train.drop(\"label\", axis=1)\ny = train[\"label\"]","635eb574":"X_broadcasted = np.broadcast_to(\n        X.to_numpy().reshape(-1, 28, 28, 1),\n        (len(X), 28, 28, 3)\n)","18a3508f":"X_broadcasted.shape","4e84f86e":"plt.imshow(X_broadcasted[0], cmap=plt.cm.binary)","b3735930":"X_train, X_val, y_train, y_val = train_test_split(X_broadcasted, y, test_size=0.2)","f2fbdb12":"model = tf.keras.Sequential([\n    layers.InputLayer((28, 28, 3)),\n    layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE),\n    efficientnet,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(10, activation='softmax')\n])","d0ede0c5":"lr = 1e-3\nepochs = 30\nbatch_size = 64\ncosine_decay = tf.keras.experimental.CosineDecay(initial_learning_rate=lr, decay_steps=int(round(len(X_train)\/batch_size)), alpha=0.3)\ncallbacks = [\n    tf.keras.callbacks.ModelCheckpoint(filepath='model.h5', monitor='val_loss', save_best_only=True), # Save weights to .\/model.h5 -> download and create dataset\n    tf.keras.callbacks.EarlyStopping(patience=5, verbose=1)        \n]\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=cosine_decay),\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=['accuracy']\n)\n\nmodel.summary()","dc42f415":"history = model.fit(\n    X_train, y_train,\n    epochs=epochs,\n    validation_data=(X_val, y_val),\n    callbacks=callbacks,\n    batch_size=batch_size\n)\n\nprint(\"\\nMax validation accuracy of {} achieved.\".format(max(history.history['val_accuracy'])))\n# 0.975595235824585","b06628b7":"min(history.history['val_loss'])\n\n# 0.0819","6a5a43bc":"history_df = pd.DataFrame(history.history)\nhistory_df.loc[0:, ['loss', 'val_loss']].plot()","b95ec957":"history_df.loc[10:, ['accuracy', 'val_accuracy']].plot()","2388b851":"model = tf.keras.models.load_model('..\/input\/mnistefficientnet\/model.h5') # load weights from pre-saved data","fed570b6":"test = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","96e4fd9f":"test_broadcasted = np.broadcast_to(\n        test.to_numpy().reshape(-1, 28, 28, 1),\n        (len(test), 28, 28, 3)\n)","b7575bf7":"submit = pd.DataFrame(np.argmax(model.predict(test_broadcasted), axis=1), columns=[\"Label\"], index=pd.RangeIndex(1, test.shape[0]+1, name=\"ImageId\"))","6ab24a86":"submit.head()","ae4f7d98":"submit.to_csv('TransferLearning.csv')","94fae202":"\ub2e4\uc591\ud55c \uc2dc\ub3c4\ub97c \ud1b5\ud574 \ub2e4\uc74c\uc758 \uacb0\ub860\uc744 \uc5bb\uc744 \uc218 \uc788\ub2e4.\n- valid\uc640 same\uc740 \uc774\ubbf8\uc9c0\uc758 \uc0ac\uc774\uc988\uac00 \ud074 \ub54c same\uc774 \ub354 \uc798\ub098\uc628\ub2e4\n- \uc774\ubbf8\uc9c0\uac00 \uc791\uae30 \ub54c\ubb38\uc5d0 conv2d layer\uac00 \uc545\uc601\ud5a5\uc744 \ub07c\uce5c\ub2e4\n- dense\uc758 \uac1c\uc218\ub294 \ud06c\uac8c \uc601\ud5a5\uc744 \ubbf8\uce58\uc9c0 \uc54a\uace0\n- dense\uac00 wide\ud560 \ub54c \uc131\ub2a5\uc774 \uc88b\ub2e4","7f0659c0":"## 1. Custom ConvNet\n\nAuthor: \uc1a1\uc6d0\ubbfc","73c21a48":"### 1. Transfer Learning\uc740 \uc5b4\ub5a8\uae4c?\n\n EfficientNetB0 \ub97c \uc774\uc6a9\ud574\uc11c Transfer Learning\uc744 \ud588\uc744 \ub54c \uc5bb\uc740 \uacb0\uacfc\ub294 \ub2e4\uc74c\uacfc \uac19\ub2e4.\n\n| Transfer Learning |                                 |                               |          |              |\n|-----------------|---------------------------------|-------------------------------|----------|--------------|\n|                 | Resize(224, 224, 3)             |                               |          |              |\n|                 | EfficientNetB0                  | on ImageNet, top excluded     |          |              |\n|                 | GlobalAveragePooling2D()        |                               |          |              |\n|                 | Dense(10, activation='softmax') |                               |          |              |\n\n| epochs | batch_size | lr                            | val_loss | val_accuracy |\n|--------|------------|-------------------------------|----------|--------------|\n|     30 |         64 | cosine_decay(1e-3, alpha=0.3) |   0.0819 |       0.9756 |","7a5b2b78":"## Introduction\n\nMNIST\ub294 28x28 \ud751\ubc31 \uc22b\uc790 \uc774\ubbf8\uc9c0\ub97c \ubd84\ub958\ud558\ub294 \ubb38\uc81c\uc774\ub2e4. \uc774 \ub178\ud2b8\ubd81\uc5d0\uc11c\ub294 Transfer Learning\uc744 \uc774\uc6a9\ud574 \ubd84\ub958\uae30\ub97c \ub9cc\ub4dc\ub294 \uac83\uacfc, CNN\uc744 \uc9c1\uc811 \ub9cc\ub4dc\ub294 \uac83\uc744 \uc124\uba85\ud55c\ub2e4.","d3a832b8":"## Transfer Learning\nwith EfficientNetB0\n\n* Author: \uc774\uc0c1\uaddc","3e50f788":"### 4. \uac00\uc7a5 \uc798 \uc218\ud589\ub418\ub294 \ubaa8\ub378\uc744 \uac1c\uc120\ud560 \uc218 \uc788\uc744\uae4c?\n- Dropout\uc744 \uc801\uc6a9\ud560\uae4c?\n- Optimizer\ub97c \ubc14\uafc0\uae4c?\n\n| optimizer | batch | earlyStopping_patience | learning_rate | dropout  |   | val_loss | val_accuracy |\n|-----------|-------|------------------------|---------------|----------|---|----------|--------------|\n| Adam      |   100 |                      5 |        0.001 |      0.4 |   |   0.0357 |         **0.9898*** |\n| RMSprop   |   100 |                      5 |         0.001 |      0.4 |   | 0.0516   |       0.9881 |","27d72a1f":"### 5. Test Accuracy\ub294 \uc5b4\ub5a0\ud55c\uac00?\n    \n|                   | Validation Accuracy | Test Accuracy |\n|:-----------------:|---------------------|---------------|\n| Custom CNN        |              0.9898 | 0.98564       |\n| Transfer Learning |              0.9756 | 0.9751        |","537ec74e":"### 2. Custom ConvNet\uc740 \uc5b4\ub5a8\uae4c?\n    \n- filter\uc758 \uac1c\uc218\ub97c \ubc14\uafb8\uba74?\n- Dense layer units\ub97c \ubc14\uafb8\uba74?\n- Conv2D layer\uc758 \uc218\ub97c \ubc14\uafb8\uba74?\n- Dense layer\uc758 \uc218\ub97c \ubc14\uafb8\uba74?\n    \n\n\n|      | layer\uc758 \uc885\ub958\uc640 \uc218                                                | \ud30c\ub77c\ubbf8\ud130 \uc218               | best loss, accuracy                                                       | EarlyStopping \uc5ec\ubd80 |              \ubc14\uafbc \uc810              |                        \ud55c\uc904\ud3c9                       |\n|------|------------------------------------------------------------------|---------------------------|---------------------------------------------------------------------------|:------------------:|:---------------------------------:|:---------------------------------------------------:|\n| 1\ucc28  | conv2D 1\uac1c filters 20       \/        Dense 1\uac1c \ucd5c\ub300 units=20     | Total params: 314,030     | loss: 0.0076 - accuracy: 0.9987 - val_loss: 0.0829 - val_accuracy: 0.9806 |          o         |           \uae30\ubcf8\uc801\uc778 \uc2dc\uc791           |                                                     |\n| 2\ucc28  | conv2D 1\uac1c filters 20       \/        Dense 1\uac1c \ucd5c\ub300 units=30     | Total params: 470,940     | loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0849 - val_accuracy: 0.9801 |          o         |     dense\ub97c \uc880 wide\ud558\uac8c \ud574\ubcf4\uc790    |                    \ubcc4 \ucc28\uc774\uac00 \uc5c6\ub2e4                   |\n| 3\ucc28  | conv2D 1\uac1c filters 20       \/        Dense 1\uac1c \ucd5c\ub300 units=100    | Total params: 1,569,310   | loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.0751 - val_accuracy: 0.9806 |          o         |     dense\ub97c \ub354 wide\ud558\uac8c \ud574\ubcf4\uc790    |                    loss\uac00 \uc904\uc5c8\ub2e4                    |\n| 4\ucc28  | conv2D 1\uac1c filters 20       \/        Dense 1\uac1c \ucd5c\ub300 units=300    | Total params: 4,707,510   | loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0619 - val_accuracy: 0.9843 |          o         |     dense\ub97c \ub354 wide\ud558\uac8c \ud574\ubcf4\uc790    |                   \ud6a8\uacfc\ub294 \uad49\uc7a5\ud588\ub2e4                   |\n| 5\ucc28  | conv2D 1\uac1c filters 20       \/        Dense 1\uac1c \ucd5c\ub300 units=1000   | Total params: 15,691,210  | loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0683 - val_accuracy: 0.9852 |          o         |     dense\ub97c \ub354 wide\ud558\uac8c \ud574\ubcf4\uc790    |                   \ud6a8\uacfc\ub294 \ubbf8\ubbf8\ud588\ub2e4                   |\n| 6\ucc28  | conv2D 1\uac1c filters 20       \/        Dense 1\uac1c \ucd5c\ub300 units=2000   | Total params: 31,382,210  | loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0669 - val_accuracy: 0.9833 |          o         |     dense\ub97c \ub354 wide\ud558\uac8c \ud574\ubcf4\uc790    |                   \ud6a8\uacfc\ub294 \ubbf8\ubbf8\ud588\ub2e4                   |\n| 7\ucc28  | conv2D 1\uac1c filters 100       \/        Dense 1\uac1c \ucd5c\ub300 units=1000  | Total params: 7,842,110   | loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0794 - val_accuracy: 0.9813 |          o         |       filter\uc758 \uc218\ub97c \ub298\ub824\ubcf4\uc790      |                   \ud6a8\uacfc\ub294 \ubbf8\ubbf8\ud588\ub2e4                   |\n| 8\ucc28  | conv2D 1\uac1c filters 1000       \/        Dense 1\uac1c \ucd5c\ub300 units=1000 | Total params: 784,021,010 | loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0818 - val_accuracy: 0.9818 |          o         |       filter\uc758 \uc218\ub97c \ub298\ub824\ubcf4\uc790      |         \ud6a8\uacfc\ub3c4 \ubcc4\ub85c\uace0 \ud55cepoch\uc5d0 1\ubd84\uc774 \uac78\ub9b0\ub2e4        |\n| 9\ucc28  | conv2D 1\uac1c filters 5       \/        Dense 1\uac1c \ucd5c\ub300 units=100     | Total params: 393,160     | loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0785 - val_accuracy: 0.9804 |          o         |       filter\uc758 \uc218\ub97c \uc904\uc5ec\ubcf4\uc790      |                    \ubcc4 \ucc28\uc774\uac00 \uc5c6\ub2e4                   |\n| 10\ucc28 | conv2D 1\uac1c filters 5 \/ Dense 1\uac1c \ucd5c\ub300 units=1000                 | Total params: 3,931,060   | loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0980 - val_accuracy: 0.9793 |          o         |     dense\ub97c \ub354 wide\ud558\uac8c \ud574\ubcf4\uc790    |                    \ubcc4 \ucc28\uc774\uac00 \uc5c6\ub2e4                   |\n| 11\ucc28 | conv2D 5\uac1c filters 62 \/ Dense 1\uac1c \ucd5c\ub300 units=100                 | Total params: 2,159,964   | loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.0553 - val_accuracy: 0.9869 |          o         |   conv2d layer\ub97c \ub298\ub824\ubcf4\uc790(valid)  |                \uc131\ub2a5\uc774 \ub9ce\uc774 \uac1c\uc120\ub418\uc5c8\ub2e4               |\n| 12\ucc28 | conv2D 5\uac1c filters 62 \/ Dense 1\uac1c \ucd5c\ub300 units=100(same)           | Total params: 5,011,964   | loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.0511 - val_accuracy: **0.9881*** |          o         |     padding\uc744 same\uc73c\ub85c \ud574\ubcf4\uc790     |                valid\ubcf4\ub2e4 \uc131\ub2a5\uc774 \uc88b\ub2e4                |\n| 13\ucc28 | conv2D 27\uac1c filters 62 ,(2,2)\/ Dense 1\uac1c \ucd5c\ub300 units=100          | Total params: 413,920     | loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1082 |          o         |   conv2d layer\ub97c \ub298\ub824\ubcf4\uc790(valid)  |             \uc774\ubbf8\uc9c0\uac00 \ub108\ubb34 \uc791\uc740 \uac83 \uac19\ub2e4.             |\n| 14\ucc28 | conv2D 27\uac1c filters 62 ,(2,2)\/ Dense 1\uac1c \ucd5c\ub300 units=100          | Total params: 5,268,520   | loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1082 |          o         |   conv2d layer\ub97c \ub298\ub824\ubcf4\uc790(same)   |             \uc774\ubbf8\uc9c0\uac00 \ub108\ubb34 \uc791\uc740 \uac83 \uac19\ub2e4.             |\n| 15\ucc28 | conv2D 10\uac1c filters 62 ,(2,2)\/ Dense 1\uac1c \ucd5c\ub300 units=100          | Total params: 5,006,074   | loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0896 - val_accuracy: 0.9857 |          o         |      conv2d layer\ub97c \uc904\uc5ec\ubcf4\uc790      | \uc774\ubbf8\uc9c0\uac00 \uc791\uae30 \ub54c\ubb38\uc5d0 conv2d layer\uac00 \uc545\uc601\ud5a5\uc744 \ub07c\uce5c\ub2e4 |\n| 16\ucc28 | conv2D 3\uac1c filters 62 ,(2,2)\/ Dense 5\uac1c \ucd5c\ub300 units=1000          | Total params: 398,822     | loss: 0.0294 - accuracy: 0.9908 - val_loss: 0.0794 - val_accuracy: 0.9788 |          o         | dense\uc758 \uac1c\uc218\ub97c \ub298\ub824\ubcf4\uc790(deep\ud558\uac8c) |             \uc131\ub2a5\uc740 \uc88b\uc73c\ub098 \ud070 \uc601\ud5a5\uc740 \uc5c6\ub2e4            |\n| 17\ucc28 | conv2D 3\uac1c filters 62 ,(2,2)\/ Dense 5\uac1c \ucd5c\ub300 units=1000          | Total params: 29,452,808  | loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.0773 - val_accuracy: 0.9860 |          o         | dense\uc758 \uac1c\uc218\ub97c \ub298\ub824\ubcf4\uc790(deep\ud558\uac8c) |             \uc131\ub2a5\uc740 \uc88b\uc73c\ub098 \ud070 \uc601\ud5a5\uc740 \uc5c6\ub2e4            |"}}