{"cell_type":{"1f9ae24c":"code","d25d4f6a":"code","88712bc8":"code","4724eb73":"code","6f69dbbc":"code","950256a1":"code","63e172fa":"code","cf541d28":"code","6cdcc56a":"code","72c7378b":"code","5b9cec72":"code","5f6eb924":"code","854c94e2":"code","f2e9b233":"code","db271602":"code","a660f7fa":"code","a4387dd0":"code","9ad7d379":"code","553a014c":"code","5f45a73a":"code","36ede115":"code","e8b0cb93":"code","a957d3c3":"code","af0ada22":"code","9e469b47":"code","b9ccd6a7":"code","43a3c108":"code","259387bd":"markdown","2232fd8f":"markdown","b4ce8501":"markdown","ba55d395":"markdown","766e6af2":"markdown","5225c224":"markdown","11bcbb20":"markdown","5e723e05":"markdown","a8bcadfe":"markdown","8d2fbe5f":"markdown","f8526d7b":"markdown","9fb4cf7a":"markdown","ee1fbfd0":"markdown"},"source":{"1f9ae24c":"# Import libraries and set desired options\nimport numpy as np\nimport pandas as pd\nfrom scipy.sparse import hstack\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import TimeSeriesSplit, cross_val_score, GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression","d25d4f6a":"# A helper function for writing predictions to a file\ndef write_to_submission_file(predicted_labels, out_file,\n                             target='target', index_label=\"session_id\"):\n    predicted_df = pd.DataFrame(predicted_labels,\n                                index = np.arange(1, predicted_labels.shape[0] + 1),\n                                columns=[target])\n    predicted_df.to_csv(out_file, index_label=index_label)","88712bc8":"train_df = pd.read_csv('..\/input\/train_sessions.csv',\n                       index_col='session_id', parse_dates=['time1'])\ntest_df = pd.read_csv('..\/input\/test_sessions.csv',\n                      index_col='session_id', parse_dates=['time1'])\n\n# Sort the data by time\ntrain_df = train_df.sort_values(by='time1')\n\n# Look at the first rows of the training set\ntrain_df.head()","4724eb73":"sites = ['site%s' % i for i in range(1, 11)]\ntrain_df[sites].fillna(0).astype('int').to_csv('train_sessions_text.txt', \n                                               sep=' ', \n                       index=None, header=None)\ntest_df[sites].fillna(0).astype('int').to_csv('test_sessions_text.txt', \n                                              sep=' ', \n                       index=None, header=None)","6f69dbbc":"!head -5 train_sessions_text.txt","950256a1":"%%time\ncv = CountVectorizer(ngram_range=(1, 3), max_features=50000)\nwith open('train_sessions_text.txt') as inp_train_file:\n    X_train = cv.fit_transform(inp_train_file)\nwith open('test_sessions_text.txt') as inp_test_file:\n    X_test = cv.transform(inp_test_file)\nX_train.shape, X_test.shape","63e172fa":"y_train = train_df['target'].astype('int').values","cf541d28":"time_split = TimeSeriesSplit(n_splits=10)","6cdcc56a":"[(el[0].shape, el[1].shape) for el in time_split.split(X_train)]","72c7378b":"logit = LogisticRegression(C=1, random_state=17, solver='liblinear')","5b9cec72":"%%time\n\ncv_scores = cross_val_score(logit, X_train, y_train, cv=time_split, \n                            scoring='roc_auc', n_jobs=1) # hangs with n_jobs > 1, and locally this runs much faster","5f6eb924":"cv_scores, cv_scores.mean()","854c94e2":"logit.fit(X_train, y_train)","f2e9b233":"logit_test_pred = logit.predict_proba(X_test)[:, 1]\nwrite_to_submission_file(logit_test_pred, 'subm1.csv') # 0.91288","db271602":"def add_time_features(df, X_sparse):\n    hour = df['time1'].apply(lambda ts: ts.hour)\n    morning = ((hour >= 7) & (hour <= 11)).astype('int')\n    day = ((hour >= 12) & (hour <= 18)).astype('int')\n    evening = ((hour >= 19) & (hour <= 23)).astype('int')\n    night = ((hour >= 0) & (hour <= 6)).astype('int')\n    X = hstack([X_sparse, morning.values.reshape(-1, 1), \n                day.values.reshape(-1, 1), evening.values.reshape(-1, 1), \n                night.values.reshape(-1, 1)])\n    return X","a660f7fa":"%%time\nX_train_new = add_time_features(train_df.fillna(0), X_train)\nX_test_new = add_time_features(test_df.fillna(0), X_test)","a4387dd0":"X_train_new.shape, X_test_new.shape","9ad7d379":"%%time\ncv_scores = cross_val_score(logit, X_train_new, y_train, cv=time_split, \n                            scoring='roc_auc', n_jobs=1) # hangs with n_jobs > 1, and locally this runs much faster","553a014c":"cv_scores, cv_scores.mean()","5f45a73a":"logit.fit(X_train_new, y_train)","36ede115":"logit_test_pred2 = logit.predict_proba(X_test_new)[:, 1]\nwrite_to_submission_file(logit_test_pred2, 'subm2.csv') # 0.93843","e8b0cb93":"import numpy as np","a957d3c3":"np.logspace(-2, 2, 10)","af0ada22":"c_values = np.logspace(-2, 2, 10)\n\nlogit_grid_searcher = GridSearchCV(estimator=logit, param_grid={'C': c_values},\n                                  scoring='roc_auc', n_jobs=1, cv=time_split, verbose=1)","9e469b47":"%%time\nlogit_grid_searcher.fit(X_train_new, y_train) # WTF? Locally, it's 3min 30s","b9ccd6a7":"logit_grid_searcher.best_score_, logit_grid_searcher.best_params_","43a3c108":"logit_test_pred3 = logit_grid_searcher.predict_proba(X_test_new)[:, 1]\nwrite_to_submission_file(logit_test_pred3, 'subm3.csv') # 0.94242","259387bd":"**Save train targets into a separate vector.**","2232fd8f":"**We'll be performing time series cross-validation, see `sklearn` [TimeSeriesSplit](http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.TimeSeriesSplit.html) and [this dicussion](https:\/\/stats.stackexchange.com\/questions\/14099\/using-k-fold-cross-validation-for-time-series-model-selection) on StackOverflow.**","b4ce8501":"**Now we'll add some time features: indicators of morning, day, evening and night.**","ba55d395":"**Now we tune regularization parameter `C`.**","766e6af2":"**Read training and test sets, sort train set by session start time.**","5225c224":"**Performing time series cross-validation, we see an improvement in ROC AUC.**","11bcbb20":"**Perform time series cross-validation with logistic regression.**","5e723e05":"**Again, we notice an improvement in both cross-validation score and LB score. Now that you've settled a correct cross-validation scheme, go on with feature engineering! Good luck!**","a8bcadfe":"<img src=\"https:\/\/habrastorage.org\/webt\/8i\/5k\/vx\/8i5kvxrehatyvf-l3glz_-ymhtw.png\" \/>","8d2fbe5f":"**Fit `CountVectorizer` and transfrom data with it.**","f8526d7b":"**Making a new submission, we notice a leaderboard score improvement as well (0.91288 ->  0.93843). Correlated CV and LB improvements is a good justifications for added features being useful and CV scheme being correct.**","9fb4cf7a":"**Transform data into format which can be fed into `CountVectorizer`**","ee1fbfd0":"**Train logistic regression with all training data, make predictions for test set and form a submission file.**"}}