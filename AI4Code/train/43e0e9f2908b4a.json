{"cell_type":{"a2b334fe":"code","81cf0082":"code","b2e22d6c":"code","7c9e7dd1":"code","9093b3b6":"code","6959b65f":"code","bcce0721":"code","fd52da65":"code","db2245c6":"code","1b74f0cc":"code","122f2307":"code","07a9affd":"code","2ebbe755":"code","a5203b1a":"code","55a33632":"code","2099de46":"code","c495806a":"code","3ea39b63":"code","fe5976a5":"code","461e91b2":"code","4440f0c9":"code","30999e6d":"code","67c3c8d6":"code","6673d960":"code","9aac237b":"code","509bd7af":"code","885278e6":"code","b6c798ff":"markdown","fad26f5a":"markdown","6b524fd5":"markdown","95e8e93a":"markdown","eab4dc01":"markdown","346db6b4":"markdown","1c065ba1":"markdown","885eee89":"markdown","73897de9":"markdown","bd73bfff":"markdown","907ae354":"markdown"},"source":{"a2b334fe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport numpy  as np\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","81cf0082":"import torch\nfrom torch import nn, optim\nfrom sklearn.model_selection import train_test_split\n# \u56fe\u50cf\u589e\u5e7f\nimport torchvision.transforms as transforms\nfrom PIL import Image","b2e22d6c":"train=pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest=pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\ntrain","7c9e7dd1":"label=train[\"label\"]\ntrain=train.drop(labels = [\"label\"],axis = 1) \nlabel","9093b3b6":"train.isnull().any().sum()","6959b65f":"test.isnull().any().sum()","bcce0721":"train=train\/255\ntest=test\/255","fd52da65":"# xmean=train.mean()\n# xstd=train.std()\n# train=(train-xmean)\/xstd\n# xmean=test.mean()\n# xstd=test.std()\n# test=(test-xmean)\/xstd","db2245c6":"train=train.values.reshape(-1,1,28,28) #1,28,28 \u5355\u901a\u9053\uff0c28\u884c 28\u5217 # \u7531\u4e8e\u4f7f\u7528\u56fe\u50cf\u589e\u5e7f\uff0c\u53bb\u6389\u4e00\u7ef4\ntest=test.values.reshape(-1,1,28,28) #1,28,28 \u5355\u901a\u9053\uff0c28\u884c 28\u5217","1b74f0cc":"from keras.preprocessing.image import ImageDataGenerator","122f2307":"#  randomly rotating, scaling, and shifting\n# CREATE MORE IMAGES VIA DATA AUGMENTATION\ndatagen = ImageDataGenerator(\n        rotation_range=10,  \n        #zoom_range = 0.10,  \n        width_shift_range=0.001, \n        height_shift_range=0.001\n        )","07a9affd":"# \u8bad\u7ec3\u65f6\u4e0d\u8dd1\n# b=np.array([datagen.flow(train[i:i+1]).next()[0] for i in range(30)])\n# import matplotlib.pyplot as plt\n# # PREVIEW IMAGES\n# plt.figure(figsize=(15,4.5))\n# for i in range(30):  \n#     plt.subplot(3, 10, i+1)\n#     plt.imshow(b[i].reshape((28,28)),cmap=plt.cm.binary)\n#     plt.axis('off')\n# plt.subplots_adjust(wspace=-0.1, hspace=-0.1)\n# plt.show()","2ebbe755":"# k=0\n# for i in range(1312):\n#     image=datagen.flow(train[k:k+32]).next()\n#     train=np.concatenate((train, image), axis = 0) \n#     label=pd.concat([label,label[k:k+32]],axis = 0)\n#     k=k+32","a5203b1a":"# transform = transforms.Compose([\n#      transforms.ToPILImage(),\n#      transforms.RandomRotation((10,80)),\n#  ])","55a33632":"# X_train, X_val, Y_train, Y_val = train_test_split(train, label, test_size = 0.1, random_state=2)\n# X_train=torch.tensor(X_train, dtype=torch.float)\n# Y_train=torch.tensor(Y_train.values, dtype=torch.float)\n","2099de46":"train=torch.tensor(train, dtype=torch.float)\nlabel=torch.tensor(label.values, dtype=torch.float)","c495806a":"batch_size = 32\ntrain_data = torch.utils.data.TensorDataset(train,label)\ntrain_iter = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True )","3ea39b63":"class cusmodule(nn.Module):\n    def __init__(self):\n        super(cusmodule,self).__init__()\n        self.conv=nn.Sequential(\n            nn.Conv2d(1, 16, 3), # in_channels, out_channels, kernel_size\n            nn.ReLU(),\n            nn.Conv2d(16, 16, 3),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # kernel_size, stride\n            #nn.Dropout(0.4),\n            #nn.BatchNorm2d(6),\n            nn.Conv2d(16, 32, 3),\n            nn.ReLU(),\n            nn.Conv2d(32, 32, 3),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            #nn.Dropout(0.4),\n            #nn.BatchNorm2d(16),\n        )\n        self.fc=nn.Sequential(\n            nn.Linear(32*4*4,256),\n            nn.ReLU(),\n            #nn.Dropout(0.4),\n            nn.Linear(256,84),\n            nn.ReLU(),\n            #nn.Dropout(0.4),\n            nn.Linear(84,10)\n        )\n    def forward(self,img):\n        feature=self.conv(img)\n        output=self.fc(feature.view(img.shape[0], -1))\n        return output","fe5976a5":"lr=0.0015\ndecay=0\nnum_epochs=40\nnet=cusmodule()\nloss=nn.CrossEntropyLoss()\noptimizer = optim.Adam(net.parameters(), lr=lr)","461e91b2":"def train_net(net, train_iter,loss, num_epochs, lr, optimizer):\n    for epochs in range(num_epochs):\n        for x,y in train_iter:\n            # \u6ce8\u610f\u6700\u540e\u4e00\u6b21\u7684\u6570\u636e\u4e0d\u4e00\u5b9a\u662f\u7b26\u5408batch_size\u7684 \u6240\u4ee5\u7528x.shape[0]\u4ee3\u66ff\n            if (epochs % 2)==0:\n                b=np.array([datagen.flow(x[i:i+1]).next()[0] for i in range(x.shape[0])])\n                x=torch.tensor(b, dtype=torch.float)\n            y_hat=net(x) #\u6a21\u578b\u8ba1\u7b97\n            l=loss(y_hat,y.long()) #\u635f\u5931\u8ba1\u7b97\n            optimizer.zero_grad() #\u68af\u5ea6\u6e050\n            l.backward() #\u53cd\u5411\u4f20\u64ad\n            optimizer.step()\n        print(\"epochs:\"+str(epochs)+\" loss:\"+str(l))","4440f0c9":"train_net(net,train_iter,loss, num_epochs, lr, optimizer)","30999e6d":"test=torch.tensor(test, dtype=torch.float)","67c3c8d6":"sub=net(test)","6673d960":"sub=sub.argmax(dim=1)\nsub=sub.numpy()","9aac237b":"sub.reshape(-1,1)","509bd7af":"submission=pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\nsubmission[\"Label\"]=sub","885278e6":"submission.to_csv('submission.csv', index=False)","b6c798ff":"\u9884\u6d4b","fad26f5a":"### \u5904\u7406\u56fe\u7247\u4e0d\u4f1a\u6539\u53d8\u6570\u636e\u5b9e\u9a8c","6b524fd5":"\u65cb\u8f6c\u65b9\u6cd5\uff0cpytorch\u6709\u9519\u8bef","95e8e93a":"- lenet 0.98500   rank1147\n- 1,\u6807\u51c6\u5316\uff0c\u6570\u636e\/255   0.98671  rank1057 --(\u7070\u5ea6\u6807\u51c6\u5316\uff0c\u51cf\u5c11\u7167\u660e\u5dee\u5f02\u7684\u5f71\u54cd\uff0c\u52a0\u5febcnn\u8fd0\u884c\u901f\u5ea6)\n- 2,\u6a21\u578b\u52a0\u4e86drpout(0.4) \u548c \u6807\u51c6\u5316  0.96428 \u4e0b\u964d\n- 3,\u53bb\u6389dropout\u6807\u51c6\u5316\uff0c\u589e\u52a0\u8bad\u7ec3\u6b21\u6570\u523040 0.98757 1032\n- 4,\u6539\u53d8\u6a21\u578b  0.98771  1017\n- 5,\u6539\u53d8\u6a21\u578b  0.99128  752\n- 2,\u56fe\u50cf\u589e\u5e7f","eab4dc01":"\u6570\u636e\u589e\u5e7f","346db6b4":"### \u6a21\u578b","1c065ba1":"\u6570\u636e\u8f6ctensor","885eee89":"\u6807\u51c6\u5316","73897de9":"\u68c0\u67e5\u7f3a\u5931\u503c","bd73bfff":"\u7528\u4e0b\u9762\u7684\u65b9\u6cd5\u6807\u51c6\u5316\uff0c\u6570\u636e\u88ab\u6bc1","907ae354":"1\uff0c\u6807\u51c6\u5316"}}