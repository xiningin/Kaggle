{"cell_type":{"f9f6617a":"code","3ea3d25a":"code","21761026":"code","3b26a2ea":"code","17221b76":"code","ccdcb8c7":"code","b2b43c01":"code","5d36821a":"code","53e93577":"code","b5c9fc04":"code","f28868a9":"code","70968c27":"code","f942fe9f":"code","4badff45":"code","cdb29a7d":"code","66ba5ce8":"code","3e57efee":"code","fb9349c3":"code","fc2d2366":"code","9a8df6ab":"code","fd68a51f":"code","9127af46":"code","16e362f2":"markdown","23e5f627":"markdown","96777b08":"markdown","4911b4d8":"markdown","3e98fb27":"markdown","5bc09e55":"markdown","f53e0cbb":"markdown","3a64de4e":"markdown","d4f5c87a":"markdown","0d451756":"markdown","55695402":"markdown","c532029a":"markdown","f5bf6ca7":"markdown","0da7f6c9":"markdown","163e75d6":"markdown"},"source":{"f9f6617a":"import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom glob import glob\nimport pandas as pd\nimport os\nimport re\nimport random \nfrom PIL import Image \nfrom sklearn.preprocessing import LabelEncoder\nimport os\nimport pandas as pd\nfrom skimage import io\nimport torch\nimport torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\nimport torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\nimport torchvision.transforms as transforms  # Transformations we can perform on our dataset\nimport torchvision\nfrom torch.utils.data import (Dataset, DataLoader)  # Gives easier dataset managment and creates mini batches\nfrom torchvision.datasets import ImageFolder\nimport torchvision.models as models","3ea3d25a":"animals_list = os.listdir(\"..\/input\/oregon-wildlife\/oregon_wildlife\/oregon_wildlife\")\nanimals_file_list = []\n\nfor i in range(len(animals_list)):\n\n  animals_file_list.append(os.listdir(str(\"..\/input\/oregon-wildlife\/oregon_wildlife\/oregon_wildlife\/\" + animals_list[i])))  \n  n = len(animals_file_list[i])\n  print('There are', n , animals_list[i] , 'images.')","21761026":"w=10\nh=10\nfig=plt.figure(figsize=(16, 16))\ncolumns = 4\nrows = 5\n\nfor i in range(1, len(animals_list)+1):\n    img = mpimg.imread(str(\"..\/input\/oregon-wildlife\/oregon_wildlife\/oregon_wildlife\/\"+ animals_list[i-1] + \"\/\"+ animals_file_list[i-1][10]))\n    compose = transforms.Compose([transforms.ToPILImage(),transforms.Resize((256,256))])\n    img = compose(img)\n    fig.add_subplot(rows, columns, i)\n    plt.axis('off')\n    plt.title(animals_list[i-1])\n    plt.imshow(img)\nplt.show()","3b26a2ea":"dir = '..\/input\/oregon-wildlife\/oregon_wildlife\/oregon_wildlife'\nfiles = [f for f in glob(dir + \"**\/**\", recursive=True)] # create a list will allabsolute path of all files","17221b76":"df_animals = pd.DataFrame({\"file_path\":files}) # transform in a dataframe\ndf_animals['animal'] = df_animals['file_path'].str.extract('\/oregon_wildlife\/(.+)\/') # extract the name of the animal\ndf_animals['file'] = df_animals['file_path'].str.extract('oregon_wildlife\/.+\/(.+)') # extrat the file name\ndf_animals = df_animals.dropna() # drop nas  ","ccdcb8c7":"animal_set = set(df_animals['animal'])\ntrain_val_test_list = [0,1,2]\ntrain_val_weights = [70,15,15]\ndf_animals['train_val_test'] = 'NA' \n\nfor an in animal_set:\n  n = sum(df_animals['animal'] == an) # count the number of animals\n  train_val_test = random.choices(train_val_test_list, weights= train_val_weights,  k=n)\n  df_animals.loc[df_animals['animal'] == an, 'train_val_test'] = train_val_test ","b2b43c01":"transform = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(10),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ]),\n    'valid': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ]),    \n}\n","5d36821a":"def check_train(path):\n    return (df_animals[df_animals['file_path'] == path].train_val_test == 0).bool\n\ndef check_valid(path):\n    return (df_animals[df_animals['file_path'] == path].train_val_test == 1).bool\n\ndef check_test(path):\n    return (df_animals[df_animals['file_path'] == path].train_val_test == 2).bool","53e93577":"# Reading Dataset\nimage_datasets = {\n    'train' : ImageFolder(root= dir, transform=transform['train'], is_valid_file=check_train),\n    'valid' : ImageFolder(root=dir, transform=transform['valid'], is_valid_file=check_valid),\n    'test' : ImageFolder(root=dir, transform=transform['test'], is_valid_file=check_test)\n}","b5c9fc04":"num_workers = 0\nbatch_size = 20\n\nloaders_scratch = {\n    'train' : DataLoader(image_datasets['train'], shuffle = True, batch_size = batch_size),\n    'valid' : DataLoader(image_datasets['valid'], shuffle = True, batch_size = batch_size),\n    'test' : DataLoader(image_datasets['test'], shuffle = True, batch_size = batch_size)    \n}","f28868a9":"# check if CUDA is available\nuse_cuda = torch.cuda.is_available()","70968c27":"import torch.nn as nn\nimport torch.nn.functional as F\n\n# define the CNN architecture\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        # convolutional layer (sees 224 x 224 x 3 image tensor)\n        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n        # convolutional layer (sees 122 x 122 x 16 tensor)\n        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n        # convolutional layer (sees 56 x 56 x 32 tensor)\n        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n        # convolutional layer (sees 28 x 28 x 64 tensor)\n        self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n        # convolutional layer (sees 14 x 14 x 128 tensor)\n        self.conv5 = nn.Conv2d(128, 256, 3, padding=1)\n        \n        # max pooling layer\n        self.pool = nn.MaxPool2d(2, 2)\n        # dropout layer (p=0.25)\n        self.dropout = nn.Dropout(0.25)\n\n        self.conv_bn1 = nn.BatchNorm2d(224,3)\n        self.conv_bn2 = nn.BatchNorm2d(16)\n        self.conv_bn3 = nn.BatchNorm2d(32)\n        self.conv_bn4 = nn.BatchNorm2d(64)\n        self.conv_bn5 = nn.BatchNorm2d(128)\n        self.conv_bn6 = nn.BatchNorm2d(256)\n\n        # linear layer (64 * 4 * 4 -> 133)\n        self.fc1 = nn.Linear(256 * 7 * 7, 512)\n        # linear layer (133 -> 133)\n        self.fc2 = nn.Linear(512, 20)\n        \n\n    def forward(self, x):\n        # add sequence of convolutional and max pooling layers\n        x = self.conv_bn2(self.pool(F.relu(self.conv1(x))))\n        x = self.conv_bn3(self.pool(F.relu(self.conv2(x))))\n        x = self.conv_bn4(self.pool(F.relu(self.conv3(x))))\n        x = self.conv_bn5(self.pool(F.relu(self.conv4(x))))\n        x = self.conv_bn6(self.pool(F.relu(self.conv5(x))))\n        # flatten image input\n        x = x.view(-1, 256 * 7 * 7)\n        # add dropout layer\n        x = self.dropout(x)\n        # add 1st hidden layer, with relu activation function\n        x = F.relu(self.fc1(x))\n        # add dropout layer\n        x = self.dropout(x)\n        # add 2nd hidden layer, with relu activation function\n        x = self.fc2(x)\n        return x\n\n#-#-# You so NOT have to modify the code below this line. #-#-#\n\n# instantiate the CNN\nmodel_scratch = Net()\nprint(model_scratch)\n\n# move tensors to GPU if CUDA is available\nif use_cuda:\n    model_scratch.cuda()","f942fe9f":"\n# specify loss function\ncriterion_scratch = nn.CrossEntropyLoss()\n\n# specify optimizer\noptimizer_scratch = optim.SGD(model_scratch.parameters(), lr=0.001, momentum=0.9)","4badff45":"def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n\n    \"\"\"returns trained model\"\"\"\n    # initialize tracker for minimum validation loss\n    valid_loss_min = np.Inf \n    \n    for epoch in range(1, n_epochs+1):\n        # initialize variables to monitor training and validation loss\n        train_loss = 0.0\n        valid_loss = 0.0\n        \n        ###################\n        # train the model #\n        ###################\n        model.train()\n        for batch_idx, (data, target) in enumerate(loaders['train']):\n            # move to GPU\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n            ## find the loss and update the model parameters accordingly\n            ## record the average training loss, using something like\n            ## train_loss = train_loss + ((1 \/ (batch_idx + 1)) * (loss.data - train_loss))\n            optimizer.zero_grad()\n            # forward pass: compute predicted outputs by passing inputs to the model\n            output = model(data)\n            # calculate the batch loss\n            loss = criterion(output, target)\n            # backward pass: compute gradient of the loss with respect to model parameters\n            loss.backward()\n            # perform a single optimization step (parameter update)\n            optimizer.step()\n            # update training loss\n            ## record the average training loss, using something like\n            train_loss = train_loss + (1 \/ (batch_idx + 1)) * (loss.data - train_loss)\n\n            \n        ######################    \n        # validate the model #\n        ######################\n        model.eval()\n        for batch_idx, (data, target) in enumerate(loaders['valid']):\n            # move to GPU\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n            ## update the average validation loss\n            # forward pass: compute predicted outputs by passing inputs to the model\n            output = model(data)\n            # calculate the batch loss\n            loss = criterion(output, target)\n            # update average validation loss \n            valid_loss = valid_loss + (1 \/ (batch_idx + 1)) * (loss.data - valid_loss)\n\n            \n        # print training\/validation statistics \n        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n            epoch, \n            train_loss,\n            valid_loss\n            ))\n        \n        ## TODO: save the model if validation loss has decreased\n        if valid_loss <= valid_loss_min:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n            valid_loss_min,\n            valid_loss))\n            torch.save(model.state_dict(), 'model_scratch.pt')\n            valid_loss_min = valid_loss\n            \n    # return trained model\n    return model\n\n# train the model\nmodel_scratch = train(10, loaders_scratch, model_scratch, optimizer_scratch, criterion_scratch, use_cuda, 'model_scratch.pt')\n\n# load the model that got the best validation accuracy\nmodel_scratch.load_state_dict(torch.load('model_scratch.pt'))","cdb29a7d":"def test(loaders, model, criterion, use_cuda):\n\n    # monitor test loss and accuracy\n    test_loss = 0.\n    correct = 0.\n    total = 0.\n\n    model.eval()\n    if torch.cuda.is_available():\n      model.cuda()\n    for batch_idx, (data, target) in enumerate(loaders['test']):\n        # move to GPU\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the loss\n        loss = criterion(output, target)\n        # update average test loss \n        test_loss = test_loss + ((1 \/ (batch_idx + 1)) * (loss.data - test_loss))\n        # convert output probabilities to predicted class\n        pred = output.data.max(1, keepdim=True)[1]\n        # compare predictions to true label\n        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n        total += data.size(0)\n            \n    print('Test Loss: {:.6f}\\n'.format(test_loss))\n\n    print('\\nTest Accuracy: %2d%% (%2d\/%2d)' % (\n        100. * correct \/ total, correct, total))\n\n# call test function    \ntest(loaders_scratch, model_scratch, criterion_scratch, use_cuda)","66ba5ce8":"## TODO: Specify data loaders\nloaders_transfer = loaders_scratch","3e57efee":"import torchvision.models as models\nimport torch.nn as nn\n\nmodel_transfer = models.vgg16(pretrained=True)\n\nfor param in model_transfer.features.parameters():\n    param.requires_grad = False\n\nn_inputs = model_transfer.classifier[6].in_features\nlast_layer = nn.Linear(n_inputs, 133)\nmodel_transfer.classifier[6] = last_layer\n\n\n# if GPU is available, move the model to GPU\nif use_cuda:\n    model_transfer.cuda()\nprint(model_transfer)","fb9349c3":"criterion_transfer = nn.CrossEntropyLoss()\noptimizer_transfer = optim.SGD(model_transfer.classifier.parameters(), lr=0.001)","fc2d2366":"# train the model\nmodel_transfer = train(10, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')","9a8df6ab":"model_transfer.load_state_dict(torch.load('model_scratch.pt'))","fd68a51f":"test(loaders_transfer, model_transfer, criterion_transfer, use_cuda)","9127af46":"### TODO: Write a function that takes a path to an image as input\n### and returns the animal that is predicted by the model.\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom torch.autograd import Variable\nimport random\nimport re\n\n# create a list with a class names\nclass_names = image_datasets['train'].classes\nclass_names = [re.sub(\"\\d{3}.\", \"\", item) for item in class_names]\nclass_names = [re.sub(\"_\", \" \", item) for item in class_names]\n\ndef predict_breed_transfer(img_path):\n  \n    # load the image and return the predicted breed    \n    img = Image.open(img_path) # Load the image from provided path\n    \n    normalize = transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n    \n    preprocess = transforms.Compose([\n        transforms.Resize(224),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        normalize]\n    )\n    \n    img_tensor = preprocess(img).float()\n    img_tensor.unsqueeze_(0)  # Insert the new axis at index 0 i.e. in front of the other axes\/dims.\n    img_tensor = Variable(img_tensor) #The input to the network needs to be an autograd Variable\n    \n    if use_cuda:\n        img_tensor = Variable(img_tensor.cuda())        \n    \n    model_transfer.eval()\n    output = model_transfer(img_tensor) # Returns a Tensor of shape (batch, num class labels)\n    output = output.cpu()\n    \n    # Our prediction will be the index of the class label with the largest value.\n    predict_index = output.data.numpy().argmax() \n    \n    predicted_breed = class_names[predict_index]\n    true_breed = image_datasets['train'].classes[predict_index]\n    \n    return (predicted_breed, true_breed)\n\n# Create list of test image paths\ntest_img_paths = list(df_animals[df_animals.train_val_test == 2].file_path)\nnp.random.shuffle(test_img_paths)\n\nfor img_path in test_img_paths[0:20]:\n    predicted_breed, true_breed = predict_breed_transfer(img_path)\n    print(\"Predicted Animal:\" , predicted_breed, \"\\n\", \"True Animal:\" , true_breed)\n    img=mpimg.imread(img_path)\n    imgplot = plt.imshow(img)\n    plt.show()\n","16e362f2":"#### USE GPU","23e5f627":"## Visualize the data\n\nFirst lets examine the files. \n- Which are the species?\n- How many pictures do we have from each animal? \n\n","96777b08":"<a id='step3'><\/a>\n## Step 3: Create a CNN to Classify Wild Animals (using Transfer Learning)\n\nWe will now use transfer learning to create a CNN that can identify the animals from the images. \n\nFrom [neurohive](https:\/\/neurohive.io\/en\/popular-networks\/vgg16\/):\n*VGG16 is a convolutional neural network model proposed by K. Simonyan and A. Zisserman from the University of Oxford in the paper \u201cVery Deep Convolutional Networks for Large-Scale Image Recognition\u201d. The model achieves 92.7% top-5 test accuracy in ImageNet, which is a dataset of over 14 million images belonging to 1000 classes. It was one of the famous model submitted to ILSVRC-2014. It makes the improvement over AlexNet by replacing large kernel-sized filters (11 and 5 in the first and second convolutional layer, respectively) with multiple 3\u00d73 kernel-sized filters one after another. VGG16 was trained for weeks and was using NVIDIA Titan Black GPU\u2019s.*\n\n\n\n\n\n\n\n\n","4911b4d8":"Apparently we have a balanced dataset,  which means we have a similar 9but not equal) proportion of images of animals from each species. \nTo have a more real notion let's visualize the animals.\n\n\n\n\n","3e98fb27":"We create an auxiliary function to make sure the data is correctly splited among train, test and validation.   ","5bc09e55":"<a id='step1'><\/a>\n## Step 1: Import Dataset and Libraries\n\nOur fist step is to import all the libraries used in this project.","f53e0cbb":"We define an optmizer and a loss function. \n\n- **loss function**: Cross-entropy loss, or log loss, measures the performance of a classification model whose output is a probability value between 0 and 1. Cross-entropy loss increases as the predicted probability diverges from the actual label. So predicting a probability of .012 when the actual observation label is 1 would be bad and result in a high loss value. A perfect model would have a log loss of 0. From the [ml-cheatsheet](https:\/\/ml-cheatsheet.readthedocs.io\/en\/latest\/loss_functions.html)\n\n- **optimizer**: Stochastic gradient descent (often abbreviated SGD) is an iterative method for optimizing an objective function with suitable smoothness properties (e.g. differentiable or subdifferentiable). It can be regarded as a stochastic approximation of gradient descent optimization, since it replaces the actual gradient (calculated from the entire data set) by an estimate thereof (calculated from a randomly selected subset of the data). Especially in high-dimensional optimization problems this reduces the computational burden, achieving faster iterations in trade for a lower convergence rate. From [wikipedia](https:\/\/en.wikipedia.org\/wiki\/Stochastic_gradient_descent)","3a64de4e":"### (IMPLEMENTATION) Test the Model\n\nTry out your model on the test dataset of dog images.  Use the code cell below to calculate and print the test loss and accuracy.  Ensure that your test accuracy is greater than 10%.","d4f5c87a":"## Load Data\n\nNow we will make use of Pytorch elements `transform`, `ImageFolder`, `DataLoader` to load the data. \n\nThe next steps will be the following. \n\n1. Create a dataframe with the name of each file, the animal and the absolute path. \n2. Select files that will further be in the train, test and validation sets. \n3. Perform transformation in the data such as reshaping, croping and rotation that will allow the images that are from different sizes to be analyzed together. \n4. Load the datasets using the DataLoader function, that will transform the images in tensors that will be analysed by the CNN.","0d451756":"#### Load the dataset","55695402":"# An Algorithm for Wildlife Animals Identification\n\nIn notebook we will be working with the Oregon Wildlife [dataset](https:\/\/www.kaggle.com\/virtualdvid\/oregon-wildlife\/kernels) created by [David Molina](https:\/\/www.kaggle.com\/virtualdvid) with a google scrapper.It constains about 14.000 pictures of 19 different wildlife species such as Deers, Cougars, Grey Wolfs and so on. \n\nWouldn't it be fun to have a app that tells you what animals are you observing in the nature when you are camping or hiking? This project may be a first step to create this app. \n\nWe aim to generate a model that scans an image and identify what is the animal species on the screen. To achieve this goal we will make use of **Convolutional Neural Networks.** <br><br>\n\n## How does a Convolutional Neural Network function ?  \n\n[deep.ai](https:\/\/deepai.org\/machine-learning-glossary-and-terms\/convolutional-neural-network): CNNs process images as volumes, receiving a color image as a rectangular box where the width and height are measure by the number of pixels associated with each dimension, and the depth is three layers deep for each color (RGB). These layers are called channels. Within each pixel of the image, the intensity of the R, G, or B is expressed by a number. That number is part of three, stacked two-dimensional matrices that make up the image volume and form the initial data that is fed to into the convolutional network. The network then begins to filter the image by grouping squares of pixels together and looking for patterns, performing what is known as a convolution. This process of pattern analysis is the foundation of CNN functions.<br><br>\n\n\n![CNN](https:\/\/miro.medium.com\/max\/2510\/1*vkQ0hXDaQv57sALXAJquxA.jpeg)\n\n\n### Libraries\n- numpy (Linear Algebra)\n- pandas (Data Manipulation and Analysis)\n- glob (File Manipulation)\n- os (File Manipulation)\n- regex (text patterns)\n- random (sampling data)\n- PIL (image processing) \n- Sklearn (Evaluation Metrics)\n- Pytorch (Deep Learning)\n\n\n### The Road Ahead\n\nWe break the notebook into separate steps.  Feel free to use the links below to navigate the notebook.\n\n* [Step 1](#step1): Import Libraries and Load the Dataset \n* [Step 2](#step2): Create a CNN to Classify Wild Animals (from Scratch)\n* [Step 3](#step3): Create a CNN to Classify Wild Animals (using Transfer Learning) \n* [Step 4](#step3): Test the model and create an Algorithm\n\nWe first mount the folder on the google drive with the dataset. ","c532029a":"Now we split the data in train, test and validation (inside the dataframe). ","f5bf6ca7":"Now we will create the dictonary `transform`. it will be used to transform the train, test and validation datasets. \nWe will apply different transformations on the train and test\/validation datasets. Data augmentation is used in the trainning dataset to avoid overfitting, that means to avoid the a very good performance on the trainning set but a bed performane on the validation and testing datasets (bed generalization). The methods used were:\n- Flipping the images horizontally \n- Random Cropping: Extract randomly a 224 \u00d7 224 pixels section from 256 \u00d7 256 pixels\n- RandomRotation: Randomly rotate the image by 10 degrees.\n","0da7f6c9":"Very beautiful animals right?","163e75d6":"<a id='step2'><\/a>\n## Step 2: Create a CNN to Classify Wild Animals (from Scratch)\n\nWe create a CNN that reveives tensors of `224 x 224 x 3` dimensions (that's how we prepared the dataset). \n\nSome of the elements of our network built from scratch. \n- Five convolutional layers. The last will return a tensor of `128 x 256, x 3` dimensions. Padding equals 1. \n- A relu function applied after every convolutional iteration.\n- A pooling function applied after every convolutional iteration.\n- Two dropout layers to avoid overffiting.\n- Two fully connected layers.  \n\n\n\n\n that will transform `128 x 256 x 3`\n- relu\n"}}