{"cell_type":{"7a76e694":"code","524fc1fe":"code","4e66e2b3":"code","dbd7dee4":"code","a94dd080":"code","37ec1984":"code","22ea31c9":"code","489edc4b":"code","272cc689":"code","706c0188":"code","3f3b1672":"code","6d8073e8":"code","da3f05a9":"code","0d8a150a":"code","6d915f51":"code","92b00da4":"markdown","d1bbef59":"markdown","aedb3d55":"markdown","913504fc":"markdown","2598037e":"markdown","b84fe472":"markdown","13920a73":"markdown","2427e6ac":"markdown","683fa70a":"markdown","db6bb6e0":"markdown","5bd05aa6":"markdown","a1d81e7b":"markdown","564cf004":"markdown","e0189301":"markdown","d79aa3eb":"markdown","4fbf2a50":"markdown","dbefb776":"markdown","3120ef03":"markdown","fc4023bf":"markdown","150b477e":"markdown","568d96c4":"markdown","45bb9f2a":"markdown","eee89f58":"markdown","efd8a633":"markdown","6618af53":"markdown","4d95e74c":"markdown","8e545447":"markdown"},"source":{"7a76e694":"#Loading the libraries\nimport numpy as np #Math library\nimport pandas as pd #Dataset library\nimport seaborn as sns #Graph library\nimport matplotlib.pyplot as plt #Help seaborn\n\n#Importing data and renaming columns for consistency\ndf = pd.read_csv('..\/input\/dota_games.txt', header=None)\ndf = df.rename(columns={0: 'ancient_1', 1: 'ancient_2', 2: 'ancient_3', 3: 'ancient_4', 4: 'ancient_5',\n                        5: 'dire_1', 6: 'dire_2', 7: 'dire_3', 8: 'dire_4', 9: 'dire_5', \n                    10: 'team_win'})","524fc1fe":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report","4e66e2b3":"print(df.info())","dbd7dee4":"#Looking unique values\nprint(df.nunique())","a94dd080":"#Knowing the data\nprint(df.head())","37ec1984":"import plotly.offline as py #library that implement interactive visuals\npy.init_notebook_mode(connected=True) #allow us to work with offline plotly\nimport plotly.graph_objs as go #like \"plt\" of matplotlib\nimport plotly.tools as tls #it will be useful soon\n\ntrace0 = go.Bar(\n    x = df[df['team_win'] == 1]['team_win'].value_counts().index.values,\n    y = df[df['team_win'] == 1]['team_win'].value_counts().values,\n    name = 'Ancient team'\n)\n\ntrace1 = go.Bar(\n    x = df[df['team_win'] == 2]['team_win'].value_counts().index.values,\n    y = df[df['team_win'] == 2]['team_win'].value_counts().values,\n    name = 'Dire team'\n)\n\ndata = [trace0, trace1]\n\nlayout = go.Layout(\n    yaxis=dict(title='Wins'),\n    xaxis=dict(title='Team'),\n    title='Target variable distribution'\n)\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig, filename='grouped-bar')","22ea31c9":"y = df['team_win']\nX = df.drop(['team_win'], axis=1)","489edc4b":"print('The number of wins are equal to each team? {}'.format(\n    round(len(df.loc[df.team_win == 1])\/len(df.loc[df.team_win == 2]), 1) == 1\n))\nprint('How much is this advantage ratio? {}%'.format(\n    round(len(df.loc[df.team_win == 1])\/len(df.loc[df.team_win == 2]) - 1, 3) * 100\n))","272cc689":"winners_team_1 = df.loc[df.team_win == 1][['ancient_1', 'ancient_2', 'ancient_3', 'ancient_4', 'ancient_5']]\nwinners_team_1.rename(index=str, inplace=True, columns={'ancient_1': 'player_1', \n                                                        'ancient_2': 'player_2', \n                                                        'ancient_3': 'player_3', \n                                                        'ancient_4': 'player_4', \n                                                        'ancient_5': 'player_5'})\n\nwinners_team_2 = df.loc[df.team_win == 2][['dire_1', 'dire_2', 'dire_3', 'dire_4', 'dire_5']]\nwinners_team_2.rename(index=str, inplace=True, columns={'dire_1': 'player_1',\n                                                        'dire_2': 'player_2',\n                                                        'dire_3': 'player_3',\n                                                        'dire_4': 'player_4',\n                                                        'dire_5': 'player_5'})\n\nwinners = winners_team_1.append(winners_team_2)\n\nhero_wins = winners.player_1.value_counts() + \\\n            winners.player_2.value_counts() + \\\n            winners.player_3.value_counts() + \\\n            winners.player_4.value_counts() + \\\n            winners.player_5.value_counts()\n\nhero_wins = hero_wins.sort_values(ascending=False)\n\n# TODO: get the wins for each hero\n","706c0188":"le = LabelEncoder()\n\nfor col in X.columns.values:\n    le.fit(X[col].values)\n    X[col] = le.transform(X[col])\n    \nprint(X.info())","3f3b1672":"steps = [('scaler', StandardScaler()), ('logistic', SGDClassifier())]\n\npipeline = Pipeline(steps)","6d8073e8":"alpha_space = np.logspace(-5, 8, 11)\nparam_grid = {'logistic__alpha': alpha_space}\n\ncv = GridSearchCV(pipeline, param_grid, cv=5)","da3f05a9":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\ncv.fit(X_train, y_train)","0d8a150a":"y_pred = cv.predict(X_test)","6d915f51":"print(\"Accuracy: {}\".format(cv.score(X_test, y_test)))\nprint(classification_report(y_test, y_pred))\nprint(\"Tuned Model Parameters: {}\".format(cv.best_params_))\nprint(\"Tuned Model Score: {}\".format(cv.best_score_))","92b00da4":"<a id='meeting'><\/a> <br>\n# **2. Meet & Greet**\n- Knowing the Type of Data\n- Missing Values\n- Unique Values\n- First Rows of the Dataset","d1bbef59":"<a href='#top'>back to top<\/a>","aedb3d55":"We initialized the `Pipeline` class with the following steps: \n* `StandardScaler` to normalize the data\n* `SGDClassifier` is our classifier model","913504fc":"#### Explanatory Data Analysis\n\nGet to know our dataset is a succint way to gain insights.","2598037e":"<a id='explanatory'><\/a> <br>\n# **3. Explanatory Data Analysis (EDA)**\n- Distribuition of Target Variable\n- Identifying Bias","b84fe472":"As we saw, there is a little advantage, but how we gonna balance it? Let's take a look of hero biggests win ratio.","13920a73":"<a href='#top'>back to top<\/a>","2427e6ac":"Test if there any missing values in DataFrame `df`. It turns out there are no aparent missing values.","683fa70a":"<a href='#top'>back to top<\/a>","db6bb6e0":"<a id='training'><\/a>\n##### 32. Training and predicting\n\nFinally, train our model with the best parameters, but first, split our dataset with `train_test_split`. Remember to train with the training dataset.","5bd05aa6":"Let's have some fun predicting some DOTA 2 games based on picks.","a1d81e7b":"<a href='#top'>back to top<\/a>","564cf004":"<a href='#top'>back to top<\/a>","e0189301":"<a id='top'><\/a>\n# Contents:\n**1. [Import](#import)** <br>\n    - Import Libraries\n    - Import Dataset\n**2. [Meet & Greet](#meeting)** <br>\n    - Knowing the Type of Data\n    - Missing Values\n    - Unique Values\n    - First Rows of the Dataset\n**3. [Explanatory Data Analysis (EDA)](#explanatory)** <br>\n    - Distribuition of Target Variable\n    - Identifying Bias","d79aa3eb":"<a id='pipeline'><\/a>\n#### 3. Putting into pipeline\n\nI'll use pipeline because it's easiler to piece everything together (I could have put section 2 here, but... well, I had already written that section). Here, the pipeline includes scaling and hyperparameter tuning to classify victory. If you aren't familiar with these concepts, check this [course](https:\/\/www.datacamp.com\/courses\/supervised-learning-with-scikit-learn) of Datacamp (sign in with a Microsoft account and have free trial for 2 months).\n\n","4fbf2a50":"Now, predict the labels of the test set.","dbefb776":"##### 22. Which are the heroes with the biggest win ratio?","3120ef03":"<a id='evaluating'><\/a>\n#### 4. Evaluating model performance\n\nLet's see the scores of the current model.","fc4023bf":"<a id='encoding'><\/a>\n#### 2. Encoding labels\n\nSince the hero names are present in the feature data, we need to encode these names into values so the `sklearn` could work properly. Lets initialize the encoder with `LabelEncoder` that already been imported in previous section.","150b477e":"## Let's start looking through target variable and their distribuition","568d96c4":"<a id='import'><\/a> <br>\n# **1. Import**\n- Import Libraries\n- Import Dataset","45bb9f2a":"<h1>I'M REWRITING THIS KERNEL. AFTER THIS LINE IT'S JUST PAST WORK<\/h1>","eee89f58":"<a href='#top'>back to top<\/a>","efd8a633":"<a id='tuning'><\/a>\n##### 31. Hyperparameter tuning\n\nThe hyperparameter we will tune is `alpha`. `alpha` controls the regularization strength. Check [scikit-learn documentation](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier) to learn more about it. \n\nTo tune, we need to specify a dictionary as the following pattern: `model__param`. Check out below.","6618af53":"Split the data into features `X` and target `y`.","4d95e74c":"<a href='#top'>back to top<\/a>","8e545447":"##### 21. There is a team side advantage? The map influences the victory?\n"}}