{"cell_type":{"734032a9":"code","dc665fb3":"code","f5ec6591":"code","c6fdd3d6":"code","fedbf14c":"code","ab1deacf":"code","ad75fc97":"code","3463679d":"code","b9868520":"code","8d19c57a":"code","f8626611":"code","11475abb":"code","f48f6be0":"code","0e5c8cc4":"code","5ef1f09a":"code","bd3ead61":"code","d2b47bf8":"code","0863d780":"code","fc0c0942":"code","4a853bab":"code","a8df167f":"code","c60d1990":"code","eb4916e4":"markdown"},"source":{"734032a9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import MinMaxScaler, PowerTransformer\nfrom catboost import CatBoostRegressor\nfrom sklearn.neural_network import MLPRegressor\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dc665fb3":"df = pd.read_csv('\/kaggle\/input\/tabular-playground-series-aug-2021\/train.csv', index_col=0)\ndf","f5ec6591":"X = df.iloc[:, :-1].values\ny = df.iloc[:, -1].values\nX.shape, y.shape","c6fdd3d6":"scaler = PowerTransformer()\nX = scaler.fit_transform(X)","fedbf14c":"Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=1\/3)\nXtrain.shape, Xtest.shape, ytrain.shape, ytest.shape","ab1deacf":"N_ESTIMATORS = 10000","ad75fc97":"catboost1_params={\n    'objective': 'Poisson',\n    'bootstrap_type': 'Poisson',\n    'loss_function': 'RMSE',\n    'eval_metric': 'RMSE',\n    'task_type': 'GPU',\n    'max_depth': 8,\n    'learning_rate': 5e-3,\n    'n_estimators': N_ESTIMATORS,\n    'max_bin': 280,\n    'min_data_in_leaf': 64,\n    'l2_leaf_reg': 0.01,\n    'subsample': 0.8,\n    'verbose': 0\n}\n# mlp_params=dict(\n#     hidden_layer_sizes=5000,\n#     max_iter=15000,\n#     early_stopping=True\n# )\nxgb_params={\n    'objective': 'count:poisson',\n    'learning_rate': 5e-3,\n    'subsample': 0.8,\n    'colsample_bytree': 0.6,\n    'n_estimators': N_ESTIMATORS,\n    'max_depth': 11,\n    'alpha': 20,\n    'lambda': 9,\n    'min_child_weight': 256,\n    'importance_type': 'total_gain',\n    'tree_method': 'gpu_hist'\n}\nmodels = [\n    CatBoostRegressor(**catboost1_params),\n#     MLPRegressor(**mlp_params),\n    XGBRegressor(**xgb_params)\n]","3463679d":"%%time\n\nfor model in models:\n    model.fit(X, y)","b9868520":"predicted = np.array([model.predict(X) for model in models])\npredicted","8d19c57a":"def cost(w, X, y):\n    return .5\/y.shape[0]*np.linalg.norm(X.T.dot(w) - y, 2)**2\n\ndef grad(w, X, y):\n    return 1\/y.shape[0]*X.dot(X.T.dot(w) - y)","f8626611":"def predicting(coef, predicted):\n    return predicted.T.dot(coef)","11475abb":"lr = 0.001\ngamma = 0.01\ncoef = np.array([1\/len(models)] * len(models))","f48f6be0":"w = [coef]\nv_old = np.zeros_like(coef)\nfor it in range(30000):\n    v_new = gamma*v_old + lr*grad(w[-1], predicted, y)\n    w_new = w[-1] - v_new\n    if np.linalg.norm(grad(w_new, predicted, y))\/w_new.shape[0] < 1e-3:\n        print('Converged at {} steps'.format(it))\n        break\n    w.append(w_new)\n    v_old = v_new\nw = np.array(w)\nw.shape","0e5c8cc4":"w[-1]","5ef1f09a":"pred = predicting(w[-1], predicted)\nmean_squared_error(y, pred, squared=False)","bd3ead61":"def predict_new(w, data):\n    predicted_value = np.array([model.predict(data) for model in models])\n    return predicting(w, predicted_value)","d2b47bf8":"plt.scatter(predict_new(coef, X), y)","0863d780":"test = pd.read_csv('\/kaggle\/input\/tabular-playground-series-aug-2021\/test.csv')","fc0c0942":"testX = test.iloc[:, 1:]\ntestX = scaler.transform(testX)","4a853bab":"outcome = predict_new(w[-1], testX)\noutcome.shape","a8df167f":"pd.DataFrame({'id': test['id'], 'loss': outcome}).to_csv('aug_submission.csv', index=False)","c60d1990":"pd.read_csv('aug_submission.csv')","eb4916e4":"## Predict for `test` file"}}