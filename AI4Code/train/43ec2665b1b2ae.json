{"cell_type":{"8d84e52b":"code","f69b1b5d":"code","efa60363":"code","20a29665":"code","ae779339":"code","54c60333":"code","9a44ab05":"code","ee89195b":"code","a569bfe2":"code","5abbb79d":"code","c571131d":"code","1c08d465":"code","322a41d7":"code","3d807c24":"code","8ac29618":"code","2768198c":"code","4f655134":"code","b2d3fc5d":"code","1ed5e1c8":"code","9223cc57":"code","33b926ae":"code","f2285b1c":"code","0e792f3c":"code","4c0432c3":"code","02a00500":"code","e17cac01":"code","eb5cf5f4":"code","473fbf03":"code","c1044c37":"code","1147c8d4":"code","75f49e38":"code","44ea46db":"code","d9738a0f":"code","db1d94d5":"code","b3aa1750":"code","e9130d27":"code","58196858":"code","fdf2a19d":"code","313303ba":"code","ec2e9765":"code","c93ce89c":"code","1dc199c3":"code","cfa7d5d3":"code","10831d1f":"code","d853ba0d":"code","85da43ef":"code","bbd9b82d":"code","0d18c864":"code","cc6f7181":"markdown","4001b7d9":"markdown","1c2f8111":"markdown","9035d67d":"markdown","fcf5e03e":"markdown","e8b4b559":"markdown","3c4e04bd":"markdown","049bf2b1":"markdown","fbfc2245":"markdown","55a696e9":"markdown","f6aaa6e7":"markdown","b5541163":"markdown","287e0521":"markdown","32db534f":"markdown","7ae376ee":"markdown","bf951462":"markdown","020320ca":"markdown","5ad702ad":"markdown","d67c53c1":"markdown","f76ed869":"markdown","38767529":"markdown","df6da6a4":"markdown","1ea04909":"markdown","002549ab":"markdown","80d5b8ab":"markdown","8b89393c":"markdown","090c4952":"markdown","97bceb5c":"markdown","5dad1c6a":"markdown","c72923e8":"markdown","bbe6e59c":"markdown","6e7ca0e6":"markdown","fbfebc72":"markdown","da8cbc3f":"markdown","9e5304b2":"markdown","e9fcc392":"markdown","bb727f6a":"markdown","bbf10365":"markdown","cb6799ef":"markdown","43546eb7":"markdown","5aa6b586":"markdown","f9a17686":"markdown","b6273356":"markdown","a22854b2":"markdown","b5a85b51":"markdown","5d9290aa":"markdown","17618b34":"markdown","08bc77a8":"markdown","fde40b8c":"markdown","508de01e":"markdown","2137460f":"markdown","7cc63bc9":"markdown","2498dfba":"markdown","3377b738":"markdown","bbc86b7f":"markdown"},"source":{"8d84e52b":"%matplotlib inline","f69b1b5d":"import os\nfrom shutil import copyfile\npython_files_path = \"..\/input\/parkinsons-detection-python-files-for-notebook\"\nfiles = os.listdir(python_files_path)\nfor file in files:\n    copyfile(src = os.path.join(python_files_path, file), \n             dst = os.path.join(\"..\/working\", file))\n    ","efa60363":"import pandas as pd\nimport numpy as np\nimport warnings\nfrom sklearn.svm import SVC, NuSVC, SVR\nfrom scipy import stats\nfrom constants import *\nfrom auxiliary_functions import *\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import cross_validate, cross_val_score, train_test_split, KFold, StratifiedKFold, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, GradientBoostingRegressor, VotingClassifier, AdaBoostClassifier, BaggingRegressor\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom collections import namedtuple\nfrom sklearn.decomposition import PCA\nfrom os import cpu_count\nfrom TwoGroupsWeightedModel import TwoGroupsWeightedModel\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom scipy.stats import iqr, kurtosis, skew\nfrom create_nqi_features_with_hand_direction_partition import create_nqi_features_from_raw_data_with_sides_partitions\nfrom method1_feature_extraction import *\nfrom plots import *\nimport random","20a29665":"# if set to False, data will be loaded from previously processed saved files.\n# Else, it will be created from the raw data inside DATA_FOLDER\/RawData.zip.\nPROCESS_DATA_FILES = True\n\n# if set to False, features will be loaded from previously saved files. Else they will be created from scratch.\nCALCULATE_FEATURES = True","ae779339":"# if PROCESS_DATA_FILES:\n#     from zipfile import ZipFile  \n#     with ZipFile(os.path.join(DATA_FOLDER, RAW_DATA_ZIP_FILENAME)) as myzip:\n#         myzip.extractall(DATA_FOLDER)","54c60333":"from constants import DATA_FOLDER\nprint(DATA_FOLDER)","9a44ab05":"from kaggle_data_loader import *\n\nif PROCESS_DATA_FILES:\n    # Create dataframe from files, perform basic cleaning\n    kaggle_users = create_merged_users_details_file()\n    kaggle_taps = create_merged_taps_dataframe()\n    kaggle_taps = clean_bad_values(kaggle_taps)\n    kaggle_taps = clean_incompatible_user_ids(kaggle_taps, kaggle_users)","ee89195b":"if PROCESS_DATA_FILES:\n    def filter_column_by_quantile(df, column, threshold):\n        len_before = len(df)\n        df = df[df[column] < np.percentile(df[column], threshold)]\n        len_after = len(df)\n        print(\"Filtered out {} rows with outliers in column '{}'\".format((len_before - len_after), column))\n        return df\n    \n    \n    def plot_percentiles_of_column(df, col, start, end, bins):\n        X = np.linspace(start, end, bins)\n        Y = [np.percentile(df[col], x) for x in X]\n        plt.plot(X, Y)\n        plt.title(col + \" Percentiles\")\n        plt.xlabel(\"Percent\")\n        plt.ylabel(\"Percentile Value\")\n        plt.show()\n    \n    \n    # Filter out outliers of HoldTime:\n    plot_percentiles_of_column(kaggle_taps, 'HoldTime', 99.96, 99.9999, 20)\n    print(\"After the percentile 99.993 we see significantly higher values, which are definitely outliers.\")\n    kaggle_taps = filter_column_by_quantile(kaggle_taps, 'HoldTime', 99.993)","a569bfe2":"if PROCESS_DATA_FILES:\n\n    # Add parsed date and time column + calculate cumulative time\n    kaggle_taps = add_cumulative_timestamps_column(kaggle_taps)\n    \n    # Group to bin indexes by the cumulative timestamps\n    def build_bins(df, bin_size_seconds):\n        df[\"PressTimeCumulative\"] = df[\"PressTimeCumulative\"] \/ 1000\n        max_press = (int(max((df[\"PressTimeCumulative\"])) \/ bin_size_seconds) + 1) * bin_size_seconds + 1\n        user_bins = [i for i in range(0, max_press, bin_size_seconds)]\n        df[\"binIndex\"] = pd.cut((df[\"PressTimeCumulative\"]), user_bins)\n        return df\n    \n    \n    kaggle_taps = build_bins(kaggle_taps, 90)\n    \n    # Keep only necessary columns and save to file\n    kaggle_taps = kaggle_taps[TAPS_FINAL_COLUMNS + ['binIndex']]    \n    kaggle_taps.to_csv(constants.KAGGLE_TAPS_INPUT, index=False)","5abbb79d":"kaggle_taps = pd.read_csv(KAGGLE_TAPS_INPUT)\nkaggle_users = pd.read_csv(KAGGLE_USERS_INPUT)\n\nprint(\"Kaggle taps final dataframe:\\n\")\nprint(kaggle_taps.head())\nprint(\"\\nKaggle users dataframe:\\n\")\nprint(kaggle_users.head())","c571131d":"warnings.simplefilter(action='ignore', category=FutureWarning) # Ignore pandas warning caused by an internal call to deprecated 'reshape'\n\nages = add_age_column(kaggle_users)\nmild_users = keep_only_mild_users(kaggle_users)\n\n# general statistics of the users\nfig = plt.figure(figsize=(15, 10))\nages_plot(fig, ages)\ngenders_plot(fig, mild_users)\ndiagnosis_plot(fig, mild_users)\nsickness_level_plot(fig, ages)\n\nwarnings.resetwarnings()","1c08d465":"holdTimeCounters = kaggle_taps.groupby(['HoldTime']).HoldTime.count().sort_values()\nprint(\"10 most common values in 'HoldTime' and their count:\\n\")\nprint(holdTimeCounters.tail(10))\nhist = holdTimeCounters.hist(bins=100).set(xlabel=\"Count of occurrences of a 'HoldTime' value\", ylabel=\"Count of unique values\")","322a41d7":"hist = kaggle_taps[(kaggle_taps.HoldTime < 80) & (kaggle_taps.HoldTime > 75)].HoldTime \\\n    .hist(bins=100).set(xlabel=\"'HoldTime' value\", ylabel=\"Count of occurrences\")","3d807c24":"from mit_data_loader import *\n    \nif PROCESS_DATA_FILES:\n    mit_users = pd.read_csv(USERS, delimiter=',', header=0, error_bad_lines=False,\n                            low_memory=False, usecols=[\"pID\", \"gt\", \"updrs108\", \"file_1\", \"file_2\"])\n    \n    mit_taps = create_merged_taps_dataframe()\n    mit_taps = clean_errors_and_bad_values(mit_taps)\n\n    print(\"\\nMIT taps initial dataframe:\\n\")\n    print(mit_taps.head())","8ac29618":"if PROCESS_DATA_FILES:\n\n    # Group to bin indexes by pressTime and add as a new column\n    bin_size_seconds = 90\n    max_press = (int(max(mit_taps[\"pressTime\"]) \/ bin_size_seconds) + 1) * bin_size_seconds + 1\n    user_bins = [i for i in range(0, max_press, bin_size_seconds)]\n    mit_taps[\"binIndex\"] = pd.cut(mit_taps[\"pressTime\"], user_bins)","2768198c":"if PROCESS_DATA_FILES:\n    \n    def plot_percentile(df, column, start, end, bins):\n        X = np.linspace(start, end, bins)\n        Y = [np.percentile(df[column], x) for x in X]\n        plt.plot(X, Y)\n        plt.title(column + \" Percentiles\")\n        plt.xlabel(\"Percent\")\n        plt.ylabel(\"Percentile Value\")\n        plt.show()\n    \n    \n    def filter_column_by_quantile(df, column, threshold):\n        len_before = len(df)\n        df = df[df[column] < np.percentile(df[column], threshold)]\n        len_after = len(df)\n        print(\"Filtered out {} rows with outliers in column '{}'\".format((len_before - len_after), column))\n        return df\n    \n    for col in list(set(FLOAT_COLUMNS) - {\"pressTime\"}):\n        plot_percentile(mit_taps, col, 98, 99.9999, 40)\n    \n    # Filter according to the results in the plots\n    mit_taps = filter_column_by_quantile(mit_taps, \"HoldTime\", 99.99)\n    mit_taps = filter_column_by_quantile(mit_taps, \"LatencyTime\", 99.4)\n    mit_taps = filter_column_by_quantile(mit_taps, \"FlightTime\", 99.95)","4f655134":"if PROCESS_DATA_FILES:\n\n    # Save to file - Taps file\n    mit_taps[[\"HoldTime\", \"LatencyTime\", \"FlightTime\"]] = \\\n        1000 * mit_taps[[\"HoldTime\", \"LatencyTime\", \"FlightTime\"]]  # to milliseconds\n    mit_taps.to_csv(MIT_TAPS_INPUT, index=False)\n    \n    # Save to file - Users file\n    mit_users.rename(columns={'pID': 'ID', 'gt': 'Parkinsons', 'updrs108': 'UPDRS'}, inplace=True)\n    mit_users = mit_users[['ID', 'Parkinsons', 'UPDRS']]\n    \n    mit_users.to_csv(MIT_USERS_INPUT, index=False)","b2d3fc5d":"mit_taps = pd.read_csv(MIT_TAPS_INPUT)\nmit_users = pd.read_csv(MIT_USERS_INPUT)\n\nprint(\"MIT users dataframe:\\n\")\nprint(mit_users.head())\nprint(\"\\nMIT taps final dataframe:\\n\")\nprint(mit_taps.head())","1ed5e1c8":"warnings.simplefilter(action='ignore', category=FutureWarning) # Ignore pandas warning caused by an internal call to deprecated 'reshape'\n\nfig = plt.figure(figsize=(15, 5))\nmit_updrs_distribution(fig, mit_users)\nmit_diagnosis(fig, mit_users)\n\nwarnings.resetwarnings()","9223cc57":"if CALCULATE_FEATURES:\n    method1_features = create_summary_statistics(kaggle_taps,\n                                                 columns_to_aggregate=[\"FlightTime\", \"HoldTime\", \"LatencyTime\"],\n                                                 aggregation_functions=[np.mean, np.std, stats.kurtosis, stats.skew,\n                                                            percnt10, percnt20, percnt40, percnt60, percnt70,\n                                                            percnt80, percnt90])\n    # Add a feature of the mean-diff between Left and Right HoldTimes, and Between LR and RL LatencyTimes:\n    method1_features[\"mean_diff_L_R_HoldTime\"] = method1_features.R_HoldTime_mean - method1_features.L_HoldTime_mean\n    method1_features[\"mean_diff_LR_RL_LatencyTime\"] = method1_features.RL_LatencyTime_mean - method1_features.LR_LatencyTime_mean\n    method1_features[\"mean_diff_LL_RR_LatencyTime\"] = method1_features.LL_LatencyTime_mean - method1_features.RR_LatencyTime_mean\n    \n    # Join with the Users data:\n    method1_features = method1_features.merge(kaggle_users, on=\"ID\", how=\"left\")\n    # Dump to csv:\n    method1_features.to_csv(KAGGLE_DATA_ARTICLE_METHOD1_FEATURES)\nelse:\n    method1_features = pd.read_csv(KAGGLE_DATA_ARTICLE_METHOD1_FEATURES)\n    \nprint(\"Summary statistics on the Kaggle data:\\n\\n\",method1_features.head())","33b926ae":"method1_features = method1_features[method1_features.total_count >= TAPS_THRESHOLD]  # take only users with more than THRESHOLD keystrokes\nmethod1_features = method1_features[method1_features.Levadopa.astype(str) == 'False']\nmethod1_features = method1_features[(method1_features.Parkinsons.astype(str) == 'False') | ( (method1_features.Parkinsons.astype(str) == 'True') & (method1_features.Impact == \"Mild\"))]","f2285b1c":"print(\"After all the above filtering, we are left with {} patients\".format(len(method1_features['ID'].unique())))","0e792f3c":"warnings.simplefilter(action='ignore', category=FutureWarning) # Ignore pandas warning caused by an internal call to deprecated 'reshape'\n\nsick = method1_features.loc[(method1_features['Parkinsons'] == True)]\nhealthy = method1_features.loc[(method1_features['Parkinsons'] == False)]\n\nfig = plt.figure(figsize=(15, 10))\nlFlight_mean(fig, sick, healthy)\nlFlight_std(fig, sick, healthy)\nlFlight_kurtosis(fig, sick, healthy)\nlFlight_skew(fig, sick, healthy)","4c0432c3":"fig = plt.figure(figsize=(18, 5))\n\nLR_Hold_Time(fig, healthy, sick)\nLR_RL_Latency_Time(fig, healthy, sick)\nLL_RR_Latency_Time(fig, healthy, sick)\n\nwarnings.resetwarnings()","02a00500":"# The summary statistics used in the original article:\nARTICLE_EXPLANATORY_VARIABLES =['L_HoldTime_mean', 'L_HoldTime_std', 'L_HoldTime_kurtosis', 'L_HoldTime_skew',\n 'R_HoldTime_mean', 'R_HoldTime_std', 'R_HoldTime_kurtosis', 'R_HoldTime_skew', 'LL_LatencyTime_mean', 'LL_LatencyTime_std',\n 'LL_LatencyTime_kurtosis', 'LL_LatencyTime_skew', 'LR_LatencyTime_mean', 'LR_LatencyTime_std', 'LR_LatencyTime_kurtosis',\n 'LR_LatencyTime_skew', 'RL_LatencyTime_mean', 'RL_LatencyTime_std', 'RL_LatencyTime_kurtosis', 'RL_LatencyTime_skew',\n 'RR_LatencyTime_mean', 'RR_LatencyTime_std', 'RR_LatencyTime_kurtosis', 'RR_LatencyTime_skew', 'mean_diff_LR_RL_LatencyTime',\n 'mean_diff_LL_RR_LatencyTime', 'mean_diff_L_R_HoldTime']","e17cac01":"X = method1_features[ARTICLE_EXPLANATORY_VARIABLES]\ny = method1_features[\"Parkinsons\"]\nclassifiers = [LogisticRegression(),\n               RandomForestClassifier(),\n               AdaBoostClassifier(),\n               KNeighborsClassifier(),\n               GradientBoostingClassifier(),\n               SVC(kernel='rbf', probability=True),\n               ]\nfor final_classifier in classifiers:\n    accuracy = evaluate_classifier_cv(final_classifier, X, y, cross_validation_folds=5)\n    print(str(final_classifier).split(\"(\")[0] + \":\")\n    print(\"\\t\"+accuracy.train)\n    print(\"\\t\" + accuracy.test)","eb5cf5f4":"scaler = StandardScaler()\nnormalized_X = scaler.fit_transform(X)","473fbf03":"# Visualizing the data in 3d, 2d and 1d after PCA:\n\npca = PCA(n_components=1)\nreduced_X = pca.fit_transform(normalized_X)\n_1d_res = get_labeled_data_1d(reduced_X, y)\n\npca = PCA(n_components=2)\nreduced_X = pca.fit_transform(normalized_X)\n_2d_res = get_labeled_data_2d(reduced_X, y)\n\npca = PCA(n_components=3)\nreduced_X = pca.fit_transform(normalized_X)\n_3d_res = get_labeled_data_3d(reduced_X, y)\n\nplot_dimensionality_reduction(_1d_res, _2d_res, _3d_res)","c1044c37":"original_dim = len(normalized_X[0])\ntested_dimensions = []\naccuracies = []\nfor dim in [i for i in range(1, original_dim+1)]:\n    if dim != original_dim:\n        pca = PCA(n_components=dim)\n        reduced_X = pca.fit_transform(normalized_X, y.values)\n    else:\n        reduced_X = normalized_X\n    best_accuracy = namedtuple(\"best_accuracy\", \"clf_name test_accuracy train_accuracy\")\n    best_accuracy.test_accuracy = -1  #init\n    for clf in classifiers:\n        accuracy = evaluate_classifier_cv(clf, reduced_X, y, cross_validation_folds=10)\n        if accuracy.test_score > best_accuracy.test_accuracy:\n            best_accuracy.test_accuracy = accuracy.test_score\n            best_accuracy.clf_name = str(clf).split(\"(\")[0]\n    tested_dimensions.append(dim)\n    accuracies.append(best_accuracy.test_accuracy)\nplt.title(\"Best test accuracy by dimension (reduction with PCA)\")\nplt.xlabel(\"Dimension\")\nplt.ylabel(\"Test accuracy rate\")\np = plt.plot(tested_dimensions, accuracies)\n","1147c8d4":"# LDA produces a \"Variables are collinear\" warning here. This is true, \n# as the Pearson Correlation factor of some of the features is very close to one. As we now attempt to reproduce the results of the article,\n# we will ignore this error.\nres = pd.DataFrame()\nfor i in range(100):\n    warnings.filterwarnings(\"ignore\", category=UserWarning)\n    train_X, train_y, test_X, test_y = split_to_train_test_and_apply_scaling_and_lda_dim_reduction(X, y, \n                                                                                                   train_percentage=0.7)\n    warnings.resetwarnings()\n    \n    # Fit several models, and find the best one by AUC measure:\n    best_auc, best_clf = get_best_roc(classifiers, train_X, train_y, test_X, test_y)\n    res = res.append([{'model': type(best_clf).__name__, 'score':best_auc}])\nmean_values = res.groupby(\"model\")[\"score\"].mean()\nprint(\"Best AUC and model:\\n\\n\", mean_values[mean_values == mean_values.max()])","75f49e38":"PERCENTILES = [c for c in method1_features.columns.values if \"perc\" in c and \"FlightTime\" not in c]\nX = method1_features[ARTICLE_EXPLANATORY_VARIABLES + PERCENTILES]\ny = method1_features[\"Parkinsons\"]\n\n# LDA produces a \"Variables are collinear\" warning here. This is true, \n# as the Pearson Correlation factor of some of the features are very close to one. As we now attempt to reproduce the results of the article,\n# we will ignore this error.\n\nres = pd.DataFrame()\nfor i in range(100):\n    warnings.filterwarnings(\"ignore\", category=UserWarning)\n    train_X, train_y, test_X, test_y = split_to_train_test_and_apply_scaling_and_lda_dim_reduction(X, y, \n                                                                                                   train_percentage=0.7)\n    warnings.resetwarnings()\n    \n    # Fit several models, and find the best one by AUC measure:\n    best_auc, best_clf = get_best_roc(classifiers, train_X, train_y, test_X, test_y)\n    res = res.append([{'model': type(best_clf).__name__, 'score':best_auc}])\nmean_values = res.groupby(\"model\")[\"score\"].mean()\nprint(\"Best AUC and model:\\n\\n\", mean_values[mean_values == mean_values.max()])","44ea46db":"from TwoGroupsWeightedModel import TwoGroupsWeightedModel\nimport warnings\n\nALL_VARIABLES = ARTICLE_EXPLANATORY_VARIABLES\nHOLD_VARIABLES = [v for v in ALL_VARIABLES if \"HoldTime\" in v]\nLATENCY_VARIABLES = [v for v in ALL_VARIABLES if \"LatencyTime\" in v]\n\nvoting_ensemble = VotingClassifier(estimators=[\n                                    ('1', RandomForestClassifier()),\n                                    ('2', SVC(probability=True)),\n                                    ('3', MLPClassifier()),\n                                    ('4', LogisticRegression()),\n                                    ('5', NuSVC(probability=True)),\n                                    ('6', KNeighborsClassifier()),\n                                    ('7', DecisionTreeClassifier()),\n                                    ('8', QuadraticDiscriminantAnalysis())\n                                  ],\n                        voting='soft')\n\n\ndef weighting_function(hold_probs, latency_probs):\n    \"\"\"\n    These are the weights described in the article. We note that this weighting can yield probs > 1, and therefore is not optimal. \n    We've tried other weightings as well, with no significant improvement.\n    \"\"\"\n    return (hold_probs + 0.5*(1-1.2) + 1.2*latency_probs)\/2.0\n\n\ngroups_model = TwoGroupsWeightedModel(underlying_estimator_module_and_class=\"sklearn.pipeline Pipeline\",\n                            group1_var_names=HOLD_VARIABLES,\n                            group2_var_names=LATENCY_VARIABLES,\n                             weighting_function=weighting_function,              \n                            classification_threshold=0.5,\n                            steps=[(\"normalization\", StandardScaler()),\n                                   (\"lda\", LinearDiscriminantAnalysis()),\n                                   (\"clf\", voting_ensemble)])\n\n# calculate accuracy and AUC for the groups-model, using K-fold CV:\nX = method1_features[ARTICLE_EXPLANATORY_VARIABLES]\ny = method1_features[\"Parkinsons\"]\n\n\"\"\"\nTraining the model on this data results in a \"Collinear Variables\" warnings. This is true, as some of the variables have very high Pearson-correlation.\nIn order to reporoduce the article findings we ignore these erros for now, and  filter warnings for the next few lines. \n\"\"\"\nwarnings.filterwarnings(\"ignore\")\ntest_auc = evaluate_classifier_cv(clf=groups_model, X=X, y=y, cross_validation_folds=5, scoring='roc_auc').test_score\ntest_accuracy = evaluate_classifier_cv(clf=groups_model, X=X, y=y, cross_validation_folds=5, scoring='accuracy').test_score\nwarnings.resetwarnings()\n\nprint(\"Test AUC: {}\\nTest Accuracy: {}\".format(test_auc, test_accuracy))","d9738a0f":"from nqi_feature_creation_functions import *\nMIN_PRESSES_PER_BUCKET_THRESHOLD = 1 # Filtering on a higher value did not prove usefull\n\n# Create the UPDRS regression features for both the MIT and the Kaggle Datasets:\n\nbin_identifier = [\"ID\", \"binIndex\"] # These two columns uniqely identify a user's time-window (90 secs of taps for specific user)\ni = 1\nif CALCULATE_FEATURES:\n    for taps_input_file_path, nqi_features_output_filepath in \\\n            zip([MIT_TAPS_INPUT, KAGGLE_TAPS_INPUT], [MIT_NQI_FEATURES, KAGGLE_NQI_FEATURES]):\n        print(\"Creating features for dataset #{}...\".format(i))\n        taps = pd.read_csv(taps_input_file_path)\n        len_before = len(taps)\n        taps = taps.groupby(bin_identifier).filter(lambda x: x['HoldTime'].count() > MIN_PRESSES_PER_BUCKET_THRESHOLD)\n        print(\"\\tRemoved {} rows from time-windows containing too few taps in file.\".format(len_before - len(taps)))\n        \n        # Filter out time-windows where the IQR feature cannot be calculated (this happens in the Kaggle data set,\n        # due to sparse time windows and HoltTime values that are very common. See project documentation for elaboration on this issue.)\n        len_before = len(taps)\n        taps = taps.groupby(bin_identifier).filter(lambda x: np.percentile(x.HoldTime, 25) != np.percentile(x.HoldTime, 75) )\n        print(\"\\tFiltered {} rows where the IQR feature cannot be calculated.\".format(len_before - len(taps)))\n        \n        # Create summary statistics for HoldTime columns, per time-window (='binIndex'):\n        grouped_taps = taps.groupby(bin_identifier)[\"HoldTime\"].\\\n            agg([agg_outliers, agg_iqr, agg_histogram_bin0, agg_histogram_bin1, \n                 agg_histogram_bin2, agg_histogram_bin3, np.count_nonzero])\n        # Rename columns for clarity:\n        grouped_taps.rename(columns={c:'hold_'+c for c in grouped_taps.columns if c not in bin_identifier}, inplace=True)\n        grouped_taps.rename(columns={'hold_count_nonzero':'count_nonzero'}, inplace=True)\n        \n        # Create summary statistics for FlightTime columns, per time-window (='binIndex'):\n        flight_grouped = taps.groupby(bin_identifier)[\"FlightTime\"].agg([np.mean, np.std]).reset_index()\n        # Rename columns for clarity:\n        flight_grouped.rename(columns={c: 'flight_' + c for c in flight_grouped.columns if c not in bin_identifier}, inplace=True)\n        \n        # Join all features together:\n        nqi_calculator_input = grouped_taps.reset_index()\n        nqi_calculator_input = nqi_calculator_input.merge(flight_grouped, on=bin_identifier)\n        \n        # Filter time-bins with insufficient taps:\n        nqi_calculator_input = nqi_calculator_input[nqi_calculator_input.count_nonzero > MIN_PRESSES_PER_BUCKET_THRESHOLD]\n        \n        # Write result ot file:\n        nqi_calculator_input.to_csv(nqi_features_output_filepath, index=False)\n        print(\"\\tDone.\")\n        i += 1","db1d94d5":"mit_nqi_features = pd.read_csv(MIT_NQI_FEATURES)\nmit_users = pd.read_csv(MIT_USERS_INPUT)\n\nmit_data = mit_nqi_features.merge(mit_users, on=\"ID\").dropna().reset_index().drop(\"index\", axis=1)\nPREDICTION_COLUMNS = list_diff(mit_data.columns, [\"UPDRS\", \"Parkinsons\", 'binIndex', 'ID', 'count_nonzero'])\n\nHOLD_FEATURES = [v for v in PREDICTION_COLUMNS if 'hold' in v]\nFLIGHT_FEATURES = [v for v in PREDICTION_COLUMNS if 'flight' in v]\n\nprint(\"All regression features on the MIT dataset:\\n\\n\", PREDICTION_COLUMNS)\nprint(\"\\n\\nMIT features sample:\\n\\n\", mit_data.head())\n\n# Split the unified MIT dataset to train and test according to ID's (IDs<=100 belong to train set, all others to test set):\ntrain_mit_data = mit_data[mit_data.ID <= 100].copy()\ntest_mit_data = mit_data[mit_data.ID >= 1000].copy()","b3aa1750":"warnings.simplefilter(action='ignore', category=FutureWarning) # Ignore pandas warning caused by an internal call to deprecated 'reshape'\n\nfig = plt.figure(figsize=(10,5))\niqr_histogram(fig, mit_data)\noutliers_histogram(fig, mit_data)\n\nwarnings.resetwarnings()","e9130d27":"# We first define a function that performs the UPDRS-regression\n# and subsequent classification using the regression's predictions:\n\n\ndef updrs_regression_and_pd_classification(train_data, test_data, regression_model, final_classifier, prediction_columns):\n    \"\"\"\n    :param train_data, test_data: a DataFrame with NQI-features and regression target ('UPDRS').\n    :param regression_model: the regression model that will be used for predicting the nqi score.\n    :param final_classifier: the classification model that will be used for predicting Parkinson's\/no-Parkinson's based on the predicted nqi score.\n    :return: the test AUC of the final model, that uses the predicted-nqi in order to predict Parkinson's.\n    \"\"\"\n    # Scale features and compress UPDRS to the [0,1] interval:\n    scaler = StandardScaler()\n    min_max_scaler = MinMaxScaler(feature_range=(0, 1))  # We use this to scale the UPDRS target to the [0,1] interval.\n    \n    train_X = train_data[prediction_columns]\n    train_y = train_data[\"UPDRS\"]\n    \n    train_X = pd.DataFrame(scaler.fit_transform(train_X))\n    train_y = min_max_scaler.fit_transform(train_y.values.reshape(-1,1))\n    \n    test_X = test_data[prediction_columns]\n    test_X = pd.DataFrame(scaler.transform(test_X))\n    \n    # Fit the regression model, and predict the test data:\n    regression_model.fit(X=train_X, y=np.ravel(train_y))\n    train_nqi_predictions = regression_model.predict(train_X)\n    train_data[\"predicted_nqi\"] = train_nqi_predictions\n    \n    # Calculate the average predicted-UPDRS (AKA 'NQI') per training patient:\n    train_final_df = train_data.groupby(\"ID\")[\"Parkinsons\", \"predicted_nqi\"].mean().reset_index()\n\n    # Predict nqi for every subject in the test-set (as mean of predicted UPDRS of all the subjects' time-windows):\n    test_nqi_predictions = regression_model.predict(test_X)\n    test_data[\"predicted_nqi\"] = test_nqi_predictions\n    test_final_df = test_data.groupby(\"ID\")[\"Parkinsons\", \"predicted_nqi\"].mean().reset_index()\n\n    # Use the result of the nqi-regression, to predict Parkinsons and calculate test score:    \n    final_classifier.fit(train_final_df[\"predicted_nqi\"].values.reshape(-1, 1), train_final_df[\"Parkinsons\"])\n    predicted_test_probs = final_classifier.predict_proba(test_final_df[\"predicted_nqi\"].values.reshape(-1, 1))[:, 1]\n    test_set_auc = roc_auc_score(y_true=test_final_df[\"Parkinsons\"], y_score=predicted_test_probs)\n    \n    # Store results in a results object:\n    result = namedtuple('result', 'test_auc y_true y_predicted test_df')\n    result.test_auc, result.y_true, result.y_predicted, result.test_df  = \\\n        test_set_auc, test_final_df[\"Parkinsons\"], predicted_test_probs, test_final_df.copy()\n    \n    return result ","58196858":"sv_regression_ensemble = BaggingRegressor(base_estimator=SVR(),\n                                n_estimators=200,\n                                bootstrap=True,\n                                n_jobs=1)\n\nupdrs_regression_on_mit_data_with_sv_regression_hold_features_results = \\\n    updrs_regression_and_pd_classification(train_mit_data, test_mit_data,\n                                         regression_model=sv_regression_ensemble,\n                                         final_classifier=LogisticRegression(), \n                                         prediction_columns=HOLD_FEATURES)\ntest_auc = updrs_regression_on_mit_data_with_sv_regression_hold_features_results.test_auc\nprint(\"Test AUC using support-vector regression and the HoldTime features (original article features): {}\".format(test_auc))","fdf2a19d":"sv_regression_ensemble = BaggingRegressor(base_estimator=SVR(),\n                                n_estimators=200,\n                                bootstrap=True,\n                                n_jobs=1)\n\nupdrs_regression_on_mit_data_with_sv_regression_all_features_results = \\\n    updrs_regression_and_pd_classification(train_mit_data, test_mit_data,\n                                           regression_model=sv_regression_ensemble,\n                                           final_classifier=LogisticRegression(),\n                                           prediction_columns=HOLD_FEATURES + FLIGHT_FEATURES)\n\ntest_auc = updrs_regression_on_mit_data_with_sv_regression_all_features_results.test_auc\nprint(\"Test AUC using support-vector regression and both HoldTime and FlightTime features (our added features): {}\".format(test_auc))","313303ba":"gbt_regression_ensemble = GradientBoostingRegressor(n_estimators=1000)\nupdrs_regression_on_mit_data_with_gbt_regression_hold_features_results = updrs_regression_and_pd_classification(\n                                                train_mit_data, test_mit_data,\n                                                regression_model=gbt_regression_ensemble,\n                                                final_classifier=LogisticRegression(), \n                                                prediction_columns=HOLD_FEATURES\n                                                )\nprint(\"Test AUC using gb-tree regression with only the HoldTime features: {}\".\n      format(updrs_regression_on_mit_data_with_gbt_regression_hold_features_results.test_auc))\n\nupdrs_regression_on_mit_data_with_gbt_regression_all_features_results = updrs_regression_and_pd_classification(\n                                                train_mit_data, test_mit_data,\n                                                regression_model=gbt_regression_ensemble,\n                                                final_classifier=LogisticRegression(), \n                                                prediction_columns=HOLD_FEATURES + FLIGHT_FEATURES\n                                                )\nprint(\"Test AUC using gb-tree regression using HoldTime+FlightTime features: {}\".\n      format(updrs_regression_on_mit_data_with_gbt_regression_all_features_results.test_auc))","ec2e9765":"warnings.simplefilter(action='ignore', category=FutureWarning) # Ignore pandas warning caused by an internal call to deprecated 'reshape'\n\nbasic_model_test_result = updrs_regression_on_mit_data_with_sv_regression_hold_features_results.test_df\nour_model_test_result = updrs_regression_on_mit_data_with_gbt_regression_all_features_results.test_df\n\nfig = plt.figure(figsize=(10,5))\nboxplot_nqi_score(fig, 1, basic_model_test_result, \"Basic Model Predicted-NQI\")\nboxplot_nqi_score(fig, 2, our_model_test_result, \"Our Improved Model Predicted-NQI\")\n\nwarnings.resetwarnings()","c93ce89c":"train_X = train_mit_data[HOLD_FEATURES + FLIGHT_FEATURES]\ntrain_y = train_mit_data[\"UPDRS\"]\n\nparam_space = {\n    'n_estimators': [100, 500, 1000],\n    'loss': ['ls', 'lad', 'huber', 'quantile'],\n    'learning_rate': [0.001, 0.01, 0.1],\n    'max_depth': [1, 2, 3, 5, 7, 8],\n    'max_leaf_nodes': [None, 3, 5, 10, 50, 100]\n}\n\ngrid_searcher = GridSearchCV(gbt_regression_ensemble, param_grid=param_space, n_jobs=-1, cv=3, verbose=2, scoring=\"r2\")\ngrid_searcher.fit(X=train_X, y=np.ravel(train_y))\nprint(\"Best params:\\n\", grid_searcher.best_params_)\n","1dc199c3":"gbt_regression_ensemble.set_params(**grid_searcher.best_params_)\n\nupdrs_regression_on_mit_data_with_optimized_gbt_regression_results = \\\n                      updrs_regression_and_pd_classification(train_mit_data, test_mit_data,\n                                                             regression_model=gbt_regression_ensemble,\n                                                             final_classifier=LogisticRegression(),\n                                                             prediction_columns=HOLD_FEATURES + FLIGHT_FEATURES)\nprint(\"Test AUC using gb-tree regression after hyper-parameter optimization: {}\".format(updrs_regression_on_mit_data_with_optimized_gbt_regression_results.test_auc))\n","cfa7d5d3":"kaggle_nqi_features = pd.read_csv(KAGGLE_NQI_FEATURES)\nkaggle_users_data = pd.read_csv(KAGGLE_USERS_INPUT)\nkaggle_data = kaggle_nqi_features.merge(kaggle_users_data, on=\"ID\").dropna().reset_index().drop([\"index\"], axis=1)\n\n# Remove patients taking Levadopa or patients with non-mild Parkinson's:\nkaggle_data = kaggle_data[kaggle_data.Levadopa==False]\nkaggle_data = kaggle_data[kaggle_data.Parkinsons==False | ((kaggle_data.Parkinsons==True) & (kaggle_data.Impact == \"Mild\"))]\n\n\n# Apply our model:\ngbt_regression_ensemble = GradientBoostingRegressor(n_estimators=1000)\nupdrs_regression_on_kaggle_and_mit_data_with_gbt_regression_results = \\\n    updrs_regression_and_pd_classification(train_data=mit_data, test_data=kaggle_data,\n                                           regression_model=gbt_regression_ensemble,\n                                           final_classifier=LogisticRegression(),\n                                           prediction_columns=HOLD_FEATURES + FLIGHT_FEATURES)\nprint(\"Test AUC on Kaggle data training on MIT data: {}\".\n      format(updrs_regression_on_kaggle_and_mit_data_with_gbt_regression_results.test_auc))","10831d1f":"# Preparing the MIT data with measures of asymmetry:\nnqi_features_with_side_partitions_data_path = create_nqi_features_from_raw_data_with_sides_partitions(MIT_TAPS_INPUT, MIT_NQI_FEATURES_SIDES_PARTITIONS)\n\nmit_nqi_features_with_sides_partition = pd.read_csv(nqi_features_with_side_partitions_data_path)\nmit_users = pd.read_csv(MIT_USERS_INPUT)\n\nprint(\"NQI features with keyboard side partitions:\\n\")\nprint(sorted(mit_nqi_features_with_sides_partition.columns))\n\nmit_data_with_sides_partition = mit_nqi_features_with_sides_partition.merge(mit_users, on=\"ID\").dropna().reset_index().drop(\"index\", axis=1)\nPREDICTION_COLUMNS_SIDE_PARTITION = list_diff(mit_data_with_sides_partition.columns, [\"UPDRS\", \"Parkinsons\", 'binIndex', 'ID', 'count_nonzero'])\n\n# Split the unified MIT dataset to train and test according to ID's:\ntrain_mit_data_with_sides_partitions = mit_data_with_sides_partition[mit_data_with_sides_partition.ID <= 100].copy()\ntest_mit_data_with_sides_partitions = mit_data_with_sides_partition[mit_data_with_sides_partition.ID >= 1000].copy()","d853ba0d":"updrs_regression_on_mit_data_with_assymetry_features = \\\n    updrs_regression_and_pd_classification(train_data=train_mit_data_with_sides_partitions,\n                                           test_data=test_mit_data_with_sides_partitions,\n                                           regression_model=gbt_regression_ensemble,\n                                           final_classifier=LogisticRegression(), \n                                           prediction_columns=PREDICTION_COLUMNS_SIDE_PARTITION)\nprint(\"Test AUC on MIT with assymetry measurement features (keyboard side partitions) : {}\".\n      format(updrs_regression_on_mit_data_with_assymetry_features.test_auc))","85da43ef":"# Plot ROC curves for all of the above variations on the model:\nplot_multiple_roc_curves([('model with asymmetry features', updrs_regression_on_mit_data_with_assymetry_features.y_true,\n                           updrs_regression_on_mit_data_with_assymetry_features.y_predicted),                          \n                          ('model with gbt regressor, all features', updrs_regression_on_mit_data_with_gbt_regression_all_features_results.y_true,\n                           updrs_regression_on_mit_data_with_gbt_regression_all_features_results.y_predicted),                          \n                          ('model with support-vector regressor, hold features', updrs_regression_on_mit_data_with_sv_regression_hold_features_results.y_true,\n                           updrs_regression_on_mit_data_with_sv_regression_hold_features_results.y_predicted),                          \n                          ('model trained on Kaggle data', updrs_regression_on_kaggle_and_mit_data_with_gbt_regression_results.y_true,\n                           updrs_regression_on_kaggle_and_mit_data_with_gbt_regression_results.y_predicted),                          \n                          ], \n                         title=\"ROC curves for parkinson's classification based on nqi-regression\")","bbd9b82d":"kaggle_ids = kaggle_data.ID.unique()\n\n\nNFOLDS = 10\ncv_gen = KFold(NFOLDS, shuffle=True)\n\nclf = GradientBoostingClassifier()\nfinal_probabilities_over_folds = pd.DataFrame()\n\ni = 1\nfor train_indices, test_indices in cv_gen.split(kaggle_ids):\n    print(\"Fitting & testing fold #{}\".format(i))\n    train_ids = kaggle_ids[train_indices]\n    test_ids = kaggle_ids[test_indices]\n    train_data = kaggle_data[kaggle_data.ID.isin(train_ids)].copy()\n    test_data = kaggle_data[kaggle_data.ID.isin(test_ids)].copy()\n    clf.fit(train_data[PREDICTION_COLUMNS], train_data[\"Parkinsons\"])\n    test_data[\"predicted_pd_prob\"] = clf.predict_proba(X=test_data[HOLD_FEATURES+FLIGHT_FEATURES])[:,1]\n    \n    # average probabilities over time-windows per-subject:\n    final_probabilities_over_folds = pd.concat([final_probabilities_over_folds, test_data.groupby(\"ID\")[\"predicted_pd_prob\", \"Parkinsons\"].mean()])\n    i += 1\nprint(\"\\nsample of final predictions:\\n\", final_probabilities_over_folds.head())","0d18c864":"test_auc = roc_auc_score(y_true=final_probabilities_over_folds['Parkinsons'], \n                    y_score=final_probabilities_over_folds['predicted_pd_prob'])\nprint(test_auc)","cc6f7181":"We now continue to follow the method descdribed in the article, by partitioning the data into two groups, Hold variables and Latency variables (depending on the orignal column they were created by). \nWe then assign a Parkinson's probability using each group seperately, and output a final probability as a weighted average of these two probabilities.","4001b7d9":"<b>Conclusion:<\/b> We see that this approach is not much better than random, although it could have potential given a home-environment data set of better quality and larger size.","1c2f8111":"We first construct the features for the UPDRS-regression:","9035d67d":"We can see that PCA dimensionality reduction does not improve performance.","fcf5e03e":"## Load full users and taps datasets from Kaggle","e8b4b559":"The plots above suggest a visual way to see the improvement in the model, in addition to the higher AUC score. On the right we see better separation between PD\/non-PD patients in their predicted NQI.","3c4e04bd":"## 1. Creating features from the Kaggle data set, according to the first approach:\n\nFor every patient, calculate summary statistics for all of their data, partitioned into Left\/Right, and LR\/RL\/LL\/RR transitions: \n","049bf2b1":"Divide keystrokes to time-intervals of 90 seconds:","fbfc2245":"### Summary plots of Kaggle data features","55a696e9":"In this work, we investigated algorithmic prediction of early Parkinson\u2019s Disease based on the patient\u2019s keyboard tapping characteristics. We apply several different methods, following recent academic papers on the subject. \n\nIn the first part, we tried to reproduce the results of the first article that initiated the Kaggle challenge. We reached a conclusion that the results given in this article are flawed, and elaborate more on this in the project document.\nWe successfully reproduced the results published in Nature magazine and introduced some significant improvements over it. We also leave leads for future research, by combining the use of asymmetry features in the UPDRS regression process. \n","f6aaa6e7":"We now apply the UPDRS-regression procedure defined above. We use a bagging-ensemble of 200 support-vector regressors, and apply it to the HoldTime features (in accordance with the original research). We then use logistic regression as the final classifier (Our tests show that most classification models yield very similar results, so this choice is not critical). ","b5541163":"We can see that the above method works well, providing similar results to those described in the article (our result are within the CI of the AUC achieved in the Nature article). The features selected above were designed to incorporate the FlightTime as well, which we assumed should be useful for detection of Parkinson. We've tried many other statistics for both HoldTime and LatencyTime, with limited success, and we omit these tests for brevity.\n\n\nAnother point for improvement would be to use a more powerful regression model. We found the following to be more effective - we use a large forest of boosted regression trees instead of the support-vector regression ensemble:","287e0521":"We try to provide a visual way to see the improvement in the model, in addition to the higher AUC score. \nThe plots below show the predicted NQI scores (mean UPDRS over time-windows per subject) for each target-class (PD\/non-PD), in the first model and in the last improved model. On the right we see slightly better seperation between PD\/non-PD patients in their predicted NQI.","32db534f":"Following are the plots describing the differences in means of different sides (Left, Right) HoldTime and side transitions (Left-to-Right, Right-to-Left, etc) LatencyTime:","7ae376ee":"# Load Data","bf951462":"<b>Conclusion:<\/b> The optimization did not provide additional value, most likely due to the small size of the dataset.\n\n\nWe will now try to evaluate the relevance of the above method to home-environment data, by training the model on all of the MIT data, and testing it on the Kaggle data (which is home-environment data):","020320ca":"An important finding that we had during the analysis of the Kaggle data, is that there is a significant number of specific 'HoldTime' values that occur hundreds of thousands of times in the data, sometimes even in a series of sequential keystrokes, in a pattern that is totally unlikely.","5ad702ad":"It is evident that neither technique of dimensionaliy reduction improves performance. \nWe now explore adding additional predictors, specifically calculating percentiles of the HoldTime and LatencyTime, trying to better describe the distribution of these measures for each patient. Results here have high variance due to the small size of the dataset, so we repeat the process 100 times and average the results:","d67c53c1":"<b>Conclusion:<\/b> in the above section we tried to reproduce and improve the classifying technique described in the article that inspired the Kaggle challenge.\nWe believe that the the results in the articles are not valid and non-reproducible, and we ellaborate further on this in the project document.","f76ed869":"### Copy uploaded code and copy to working dir so that it's available from import:","38767529":"<b>Conclusion:<\/b> Using gradient-boosting regression yields better results, and improves over the previous models. Together with our additional LatencyTime features we see significant improvement.","df6da6a4":"We can see that the value is '78.1' is extremely common (>600,000 occurrences) while other close values are rare.\nWe therefore conclude that the Kaggle data has built-in corrupted entries which are hard to distinguish from the correct ones. Trying to filter out such extremely common values leads to losing the vast majority of tha data. We therefore decided to continue working with the original data but keeping in mind the understanding that the signal could be corrupted.","1ea04909":"Calculate AUC with optimized parameters:","002549ab":"# Modeling Phase 1: Attempting to reproduce the results from the Kaggle challenge article","80d5b8ab":"# Feature Creation","8b89393c":"Filter outliers:","090c4952":"The main idea of this approach is to use a regression model to predict the UPDRS score of a patient, averaged over all of their keystrokes time windows, and subsequently apply a classification model to classify PD\/non-PD based on that score.","97bceb5c":"### Summary plots of MIT data features","5dad1c6a":"# Final Conclusions","c72923e8":"Divide keystrokes to time-intervals of 90 seconds:","bbe6e59c":"In the above plot, we can for the 'HoldTime' column the values after which the observations are clearly outliers, therefore we filter them out. In the other columns there are no such clear cut-off values.","6e7ca0e6":"We now attempt to use the features that were constructed for the UPDRS-regression to directly classify a patient as PD\/non-PD. This is desired because in the first dataset we do not have UPDRS scores so we cannot train the above model that performed well on the MIT dataset. ","fbfebc72":"### Second attempt: normalize the data and apply PCA dimensionality reduction","da8cbc3f":"Summary plots on MIT data:","9e5304b2":"### Summary plots on Kaggle data","e9fcc392":"As an example, let's focus on the extreme value '78.1'. If it were a valid normal value, we would expect to see that the density of it's appearance count should be similar to that of values around it. Let's plot the histogram around the value '78.1': ","bb727f6a":"We now apply LDA dimensionality reduction and scaling to the data, and randomly split to test and train sets. Results here have high variance due to the small size of the dataset, so we repeat the process 100 times and average the results:","bbf10365":"# Modeling Phase 2: A completely different approach, inspired by results published in Nature magazine by a team of MIT researchers","cb6799ef":"### Configuration Constants","43546eb7":"#### In-depth analysis of the values in 'HoldTime'","5aa6b586":"<b>Conclusion:<\/b> our attempt to apply measuring asymmetry to the process of predicting a patient's UPDRS score did not improve the model over what we have previously achieved. This could be a result of the small size of our datatset, which suffers from high dimensionality when we introduce asymmetry features. Our attempts at dimensionality reduction on this dataset did not prove useful.","f9a17686":"Filter outliers:","b6273356":"we can see that all models are highly overfitted, and do not perform well.","a22854b2":"Our next step is to apply the main idea from the first article, i.e splitting the keystrokes according to the side of the keyboard in which they occur, to the MIT data using all the features constructed above for UPDRS regression. We hope that those features will introduce measures of functional asymmetry to the model which may prove useful:","b5a85b51":"From the above plots, it is evident that the data is not well seperated in low dimensions. We now try all possible dimensionality reductions, and for every number of dimensions we reduce to, we apply several classification models and keep the test score of the best one:","5d9290aa":"We can see that most of the values appear less than 200 times, while there are some extreme values that appear hundreds of thousand of time.","17618b34":"Filter the data so that we only keep patients with plenty of tapping events, and only patients with mild Parkinsons:","08bc77a8":"We see above that the UPDRS-regression trained on the MIT data does not generalize well to the Kaggle data. We propose two possible explanations for this: it could be that the MIT data is fundamentally different, being collected in the lab and not at home. Another possible explanation is that the Kaggle data is corrupt (this could explain the inability to reproduce the first article).","fde40b8c":"Save final dataframe:","508de01e":"### First attempt: applying several models to the raw data with the variables used in the article, without further processing:\n","2137460f":"We can see that the above method provides reasonable results. Our test-AUC are very close to the CI provided in the article (0.72-0.87). We now add statistical features based on the LatencyTime columns that we calculated. This was not performed in the original article:","7cc63bc9":"### Construct a regression model to predict UPDRS score and then classify patients accordingly:","2498dfba":"In the above plots, we can see for each column the values after which the observations are clearly outliers, therefore we filter them out.","3377b738":"# Optimize regressor hyper-parameters:","bbc86b7f":"## Load full users and taps datasets from MIT dataset"}}