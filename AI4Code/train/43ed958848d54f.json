{"cell_type":{"69430a27":"code","99c3ff6d":"code","58cb6983":"code","2a87a21d":"code","2212bf63":"code","47f4ce64":"code","de6193ef":"code","4a8ba99a":"code","d50aa339":"code","25a4735c":"code","c699c181":"code","405bb3d1":"code","bc9674c2":"code","186781c0":"code","a35d398e":"code","39b8bdbb":"code","97965644":"code","f4c8e7eb":"code","7c7957f4":"code","729b1a39":"code","8c30ea1b":"code","9725f63e":"code","8ea6a3d7":"markdown","d5dc487a":"markdown","62090040":"markdown","7114a212":"markdown","45e2b59e":"markdown","f5e5c3e9":"markdown","9946d58d":"markdown","94c63f03":"markdown","e64c7fae":"markdown","3be0426a":"markdown","932e2349":"markdown"},"source":{"69430a27":"import numpy as np\nimport pandas as pd\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport os\nfrom os.path import isfile, join\nimport random\n\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import metrics","99c3ff6d":"DIR = \"..\/input\/lgg-mri-segmentation\/kaggle_3m\"\nINPUT_CHANNELS = 3\nTARGET_CHANNELS = 1\nSIZE = 256\nBATCH_SIZE = 32","58cb6983":"mri_images_with_tumer = []\nmri_images_without_tumer = []\nmask_images_with_tumer = []\nmask_images_without_tumer = []\n\npatients = os.listdir(DIR)\nfor patient in tqdm(patients):\n    if isfile(join(DIR, patient)) == False:\n        images = os.listdir(join(DIR, patient))\n        mask_images = list(filter(lambda x: x.find('mask') != -1, images))\n        mri_images = list(filter(lambda x: x.find('mask') == -1, images))\n        \n        for mask_image in mask_images:\n            mask = np.asarray(load_img(\n                join(DIR, patient, mask_image), \n                target_size=(SIZE, SIZE), \n                color_mode=\"grayscale\"))\n            if np.amax(mask) != 0:\n                mri_images_with_tumer.append(join(patient, mask_image.replace('_mask', '')))\n                mask_images_with_tumer.append(join(patient, mask_image))\n            else:\n                mri_images_without_tumer.append(join(patient, mask_image.replace('_mask', '')))\n                mask_images_without_tumer.append(join(patient, mask_image))","2a87a21d":"random.Random(1337).shuffle(mri_images_with_tumer)\nrandom.Random(1337).shuffle(mask_images_with_tumer)\nrandom.Random(1337).shuffle(mri_images_without_tumer)\nrandom.Random(1337).shuffle(mask_images_without_tumer)\n\n\nprint(\"Total MRI images: \", len(mri_images_with_tumer) + len(mri_images_without_tumer))\nprint(\"Total mask images: \", len(mask_images_with_tumer) + len(mask_images_without_tumer))\nprint(\"Total images with tumer: \", len(mri_images_with_tumer))\nprint(\"Total images without tumer: \", len(mri_images_without_tumer))\n\nlabels = ['With Tumer', 'Without Tumer']\ncount = [len(mri_images_with_tumer), len(mri_images_without_tumer)]\n\nfig, ax = plt.subplots()\nax.pie(count, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)\nax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\nplt.show()","2212bf63":"mri_images_with_tumer = np.array(mri_images_with_tumer)\nmri_images_without_tumer = np.array(mri_images_without_tumer)\nmask_images_with_tumer = np.array(mask_images_with_tumer)\nmask_images_without_tumer = np.array(mask_images_without_tumer)","47f4ce64":"with_tumer_val_images = 300\nwithout_tumer_val_images = 600\n\nwith_tumer_test_images = 10\nwithout_tumer_test_images = 5\n\ntrain_images = np.concatenate(\n    (mri_images_with_tumer[:-with_tumer_val_images-with_tumer_test_images], \n     mri_images_without_tumer[:-without_tumer_val_images-without_tumer_test_images]), \n    axis = 0)\n\nval_images = np.concatenate(\n    (mri_images_with_tumer[-with_tumer_val_images-with_tumer_test_images:-with_tumer_test_images], \n     mri_images_without_tumer[-without_tumer_val_images-without_tumer_test_images:-without_tumer_test_images]), \n    axis = 0)\n\ntest_images = np.concatenate(\n    (mri_images_with_tumer[-with_tumer_test_images:], \n     mri_images_without_tumer[-without_tumer_test_images:]), \n    axis = 0)\n\ntrain_targets = np.concatenate(\n    (mask_images_with_tumer[:-with_tumer_val_images-with_tumer_test_images], \n     mask_images_without_tumer[:-without_tumer_val_images-without_tumer_test_images]), \n    axis = 0)\n\nval_targets = np.concatenate(\n    (mask_images_with_tumer[-with_tumer_val_images-with_tumer_test_images:-with_tumer_test_images], \n     mask_images_without_tumer[-without_tumer_val_images-without_tumer_test_images:-without_tumer_test_images]), \n    axis = 0)\n\ntest_targets = np.concatenate(\n    (mask_images_with_tumer[-with_tumer_test_images:], \n     mask_images_without_tumer[-without_tumer_test_images:]), \n    axis = 0)\n\n\nprint(\"train_images: \", train_images.shape)\nprint(\"train_targets: \", train_targets.shape)\nprint(\"val_images: \", val_images.shape)\nprint(\"val_targets: \", val_targets.shape)\nprint(\"test_images: \", test_images.shape)\nprint(\"test_targets: \", test_targets.shape)","de6193ef":"random.Random(37).shuffle(train_images)\nrandom.Random(37).shuffle(train_targets)\nrandom.Random(37).shuffle(val_images)\nrandom.Random(37).shuffle(val_targets)","4a8ba99a":"train_df = pd.DataFrame(data={'mris': train_images, 'masks': train_targets})\nval_df = pd.DataFrame(data={'mris': val_images, 'masks': val_targets})\ntest_df = pd.DataFrame(data={'mris': test_images, 'masks': test_targets})","d50aa339":"plt.figure(figsize=(30,60))\n\nfor j in range(0, 10):\n    index = random.randrange(0, 1000, 3)\n    \n    mri = np.asarray(load_img(\n         join(DIR, train_df['mris'][index]), \n         target_size=(SIZE, SIZE)))\n    mask = np.asarray(load_img(\n        join(DIR, train_df['masks'][index]), \n        target_size=(SIZE, SIZE), \n        color_mode=\"grayscale\"))\n             \n    images = [mri, mri[:,:,0], mri[:,:,1], mri[:,:,2], mask]\n    titles = [\"RBG Image\", \"Pre Contrast\", \"FLAIR\", \"Post Contrast\", \"Mask\"]\n    \n    for i in range(0, 5):\n        ax = plt.subplot(10, 5, (j*5)+i+1)\n        ax.set_title(titles[i], fontsize = 16)\n        plt.imshow(X=images[i], cmap='gray')\n\nplt.show()","25a4735c":"plt.figure(figsize=(30,60))\n\nfor j in range(0, 10):\n    index = random.randrange(0, 200, 3)\n    \n    mri = np.asarray(load_img(\n         join(DIR, val_df['mris'][index]), \n         target_size=(SIZE, SIZE)))\n    mask = np.asarray(load_img(\n        join(DIR, val_df['masks'][index]), \n        target_size=(SIZE, SIZE), \n        color_mode=\"grayscale\"))\n             \n    images = [mri, mri[:,:,0], mri[:,:,1], mri[:,:,2], mask]\n    titles = [\"RBG Image\", \"Pre Contrast\", \"FLAIR\", \"Post Contrast\", \"Mask\"]\n    \n    for i in range(0, 5):\n        ax = plt.subplot(10, 5, (j*5)+i+1)\n        ax.set_title(titles[i], fontsize = 16)\n        plt.imshow(X=images[i], cmap='gray')\n\nplt.show()","c699c181":"def adjust_data(img,mask):\n    img = img \/ 255\n    mask = mask \/ 255\n    mask[mask > 0.5] = 1\n    mask[mask <= 0.5] = 0\n    \n    return (img, mask)\n\nclass BrainMRIs(keras.utils.Sequence):\n\n    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths, directory):\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.input_img_paths = input_img_paths\n        self.target_img_paths = target_img_paths\n        self.directory = directory\n\n    def __len__(self):\n        return len(self.target_img_paths) \/\/ self.batch_size\n\n    def __getitem__(self, idx):\n        i = idx * self.batch_size\n        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n\n        x = np.zeros((self.batch_size, self.img_size, self.img_size, 3), dtype=\"float32\")\n        for j, path in enumerate(batch_input_img_paths):\n            img = load_img(join(self.directory, path), target_size=(self.img_size, self.img_size))\n            x[j] = img\n            \n        y = np.zeros((self.batch_size, self.img_size, self.img_size, 1), dtype=\"float32\")\n        for j, path in enumerate(batch_target_img_paths):\n            img = load_img(join(self.directory, path), target_size=(self.img_size, self.img_size), color_mode=\"grayscale\")\n            y[j] = np.expand_dims(img, 2)\n        \n        return adjust_data(x, y)","405bb3d1":"train_gen = BrainMRIs(BATCH_SIZE, SIZE, train_images, train_targets, DIR)\nval_gen = BrainMRIs(BATCH_SIZE, SIZE, val_images, val_targets, DIR)\ntest_gen = BrainMRIs(BATCH_SIZE, SIZE, test_images, test_targets, DIR)","bc9674c2":"smooth=100\n\ndef dice_coef(y_true, y_pred):\n    y_truef = keras.backend.flatten(y_true)\n    y_predf = keras.backend.flatten(y_pred)\n    And = keras.backend.sum(y_truef*y_predf)\n    return((2* And + smooth) \/ (keras.backend.sum(y_truef) + keras.backend.sum(y_predf) + smooth))\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\ndef iou(y_true, y_pred):\n    intersection = keras.backend.sum(y_true * y_pred)\n    sum_ = keras.backend.sum(y_true + y_pred)\n    jac = (intersection + smooth) \/ (sum_ - intersection + smooth)\n    return jac\n\ndef jac_distance(y_true, y_pred):\n    y_truef = keras.backend.flatten(y_true)\n    y_predf = keras.backend.flatten(y_pred)\n\n    return - iou(y_true, y_pred)","186781c0":"keras.backend.clear_session()","a35d398e":"inputs = layers.Input((SIZE, SIZE, INPUT_CHANNELS))\n\nc1 = layers.Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', name='conv1_1')(inputs)\nc1 = layers.Dropout(0.2)(c1)\nc1 = layers.Conv2D(32, kernel_size=(3, 3), padding='same', name=\"conv1_2\")(c1)\nc1 = layers.BatchNormalization(axis=3)(c1)\nc1 = layers.Activation('relu')(c1)\ninput_1 = layers.MaxPooling2D((2, 2))(c1)\n\nc2 = layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', name='conv2_1')(input_1)\nc2 = layers.Dropout(0.2)(c2)\nc2 = layers.Conv2D(64, kernel_size=(3, 3), padding='same', name=\"conv2_2\")(c2)\nc2 = layers.BatchNormalization(axis=3)(c2)\nc2 = layers.Activation('relu')(c2)\ninput_2 = layers.MaxPooling2D((2, 2))(c2)\n\nc3 = layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', name='conv3_1')(input_2)\nc3 = layers.Dropout(0.2)(c3)\nc3 = layers.Conv2D(128, kernel_size=(3, 3), padding='same', name=\"conv3_2\")(c3)\nc3 = layers.BatchNormalization(axis=3)(c3)\nc3 = layers.Activation('relu')(c3)\ninput_3 = layers.MaxPooling2D((2, 2))(c3)\n\nc4 = layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', name='conv4_1')(input_3)\nc4 = layers.Dropout(0.2)(c4)\nc4 = layers.Conv2D(256, kernel_size=(3, 3), padding='same', name=\"conv4_2\")(c4)\nc4 = layers.BatchNormalization(axis=3)(c4)\nc4 = layers.Activation('relu')(c4)\ninput_4 = layers.MaxPooling2D((2, 2))(c4)\n\nc5 = layers.Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same', name='conv5_1')(input_4)\nc5 = layers.Dropout(0.2)(c5)\nc5 = layers.Conv2D(512, kernel_size=(3, 3), padding='same', name=\"conv5_2\")(c5)\nc5 = layers.BatchNormalization(axis=3)(c5)\nc5 = layers.Activation('relu')(c5)\n\nu6 = layers.Conv2DTranspose(256, kernel_size=(2, 2), strides=(2, 2), activation='relu', padding='same', name='conv6_1')(c5)\nu6 = layers.concatenate([u6, c4])\nc6 = layers.Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same', name='conv6_2')(u6)\nc6 = layers.Dropout(0.2)(c6)\nc6 = layers.Conv2D(256, kernel_size=(3, 3), padding='same', name=\"conv6_3\")(c6)\nc6 = layers.BatchNormalization(axis=3)(c6)\nc6 = layers.Activation('relu')(c6)\n\nu7 = layers.Conv2DTranspose(128, kernel_size=(2, 2), strides=(2, 2), activation='relu', padding='same', name='conv7_1')(c6)\nu7 = layers.concatenate([u7, c3])\nc7 = layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', name='conv7_2')(u7)\nc7 = layers.Dropout(0.2)(c7)\nc7 = layers.Conv2D(128, kernel_size=(3, 3), padding='same', name=\"conv7_3\")(c7)\nc7 = layers.BatchNormalization(axis=3)(c7)\nc7 = layers.Activation('relu')(c7)\n\nu8 = layers.Conv2DTranspose(64, kernel_size=(2, 2), strides=(2, 2), activation='relu', padding='same', name='conv8_1')(c7)\nu8 = layers.concatenate([u8, c2])\nc8 = layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', name='conv8_2')(u8)\nc8 = layers.Dropout(0.2)(c8)\nc8 = layers.Conv2D(64, kernel_size=(3, 3), padding='same', name=\"conv8_3\")(c8)\nc8 = layers.BatchNormalization(axis=3)(c8)\nc8 = layers.Activation('relu')(c8)\n\nu9 = layers.Conv2DTranspose(32, kernel_size=(2, 2), strides=(2, 2), activation='relu', padding='same', name='conv9_1')(c8)\nu9 = layers.concatenate([u9, c1])\nc9 = layers.Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', name='conv9_2')(u9)\nc9 = layers.Dropout(0.2)(c9)\nc9 = layers.Conv2D(32, kernel_size=(3, 3), padding='same', name=\"conv9_3\")(c9)\nc9 = layers.BatchNormalization(axis=3)(c9)\nc9 = layers.Activation('relu')(c9)\n\noutputs = layers.Conv2D(1, kernel_size=(1, 1), activation='sigmoid', padding='same', name=\"output\")(c9)\n\nmodel = keras.Model(inputs=[inputs], outputs=[outputs])\nmodel.summary()","39b8bdbb":"EPOCHS = 30\nlearning_rate = 1e-2\ndecay_rate = learning_rate \/ 10","97965644":"model.compile(\n    optimizer=keras.optimizers.Adam(\n        learning_rate=learning_rate, \n        beta_1=0.9, \n        beta_2=0.999, \n        epsilon=None, \n        decay=decay_rate, \n        amsgrad=False), \n    loss=dice_coef_loss,\n    metrics=[\"binary_accuracy\", iou, dice_coef])\n\nmodel_checkpoint = keras.callbacks.ModelCheckpoint('unet_brain_mri_seg.hdf5', verbose=1, save_best_only=True)\n#early_stopping  = keras.callbacks.EarlyStopping(min_delta=0.001, patience=5)\n\nhistory = model.fit(\n    train_gen, \n    validation_data=val_gen,\n    epochs=100,\n    callbacks=[model_checkpoint])","f4c8e7eb":"a = history.history\n\nlist_trainloss = a['loss']\nlist_testloss = a['val_loss']\nlist_traindice = a['dice_coef']\nlist_testdice = a['val_dice_coef']\n\nplt.figure(figsize=(20,5))\n\nax = plt.subplot(1, 2, 1)\nax.set_title('loss graph', fontsize = 16)\nplt.xlabel('iteration')\nplt.ylabel('loss')\nplt.plot(list_testloss, 'b-')\nplt.plot(list_trainloss,'r-')\n\nax = plt.subplot(1, 2, 2)\nax.set_title('accuracy graph', fontsize = 16)\nplt.xlabel('iteration')\nplt.ylabel('accuracy')\nplt.plot(list_traindice, 'r-')\nplt.plot(list_testdice, 'b-')\n\nplt.show()","7c7957f4":"x = np.zeros((15, SIZE, SIZE, 3), dtype=\"float32\")   \ndisp_x = np.zeros((15, SIZE, SIZE, 3), dtype=\"uint8\")\ny = np.zeros((15, SIZE, SIZE, 1), dtype=\"uint8\")\n\nfor j in range(0, 15):\n    x[j] = np.asarray(load_img(\n         join(DIR, test_df['mris'][j]), \n         target_size=(SIZE, SIZE)))\n    disp_x[j] = x[j]\n    img = np.asarray(load_img(\n        join(DIR, test_df['masks'][j]), \n        target_size=(SIZE, SIZE), \n        color_mode=\"grayscale\"))\n    y[j] = np.expand_dims(img, 2)","729b1a39":"model = keras.models.load_model('unet_brain_mri_seg.hdf5', custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef})\npreds = model.predict(x \/ 255)","8c30ea1b":"preds_t = (preds > 0.5).astype(np.uint8)\nprint(np.amax(preds))\nprint(np.amax(preds_t))\nprint(preds.shape)\n\nprint(np.unique(preds_t, return_counts=True))","9725f63e":"plt.figure(figsize=(10,50))\n\ntitles = [\"Image\", \"Original Mask\", \"Predicted Mask\"]\n\nfor j in range(15):\n    images = [disp_x[j], y[j], preds_t[j]**255]\n    for i in range(0, 3):\n        ax = plt.subplot(15, 3, (j*3)+i+1)\n        ax.set_title(titles[i], fontsize = 16)\n        plt.imshow(X=images[i], cmap='gray')\n        \nplt.tight_layout()\nplt.show()","8ea6a3d7":"# Visulization","d5dc487a":"# LOG\n1. Loss was not improving after 2nd epoch(it was remaining same). \n  1. Shuffle data - Done, No improvement\n  2. Add BatchNormalization layer - Done, Significant improvement\n2. Masks predicted were not accurate. It was covering majority area of image. Seems model is overfit\n  1. Decrease learning rate - Done(set lr to 1e-3), No improvement\n  2. Decrease no. of filters - Done(Halfed no. of filters at each layers), Some improvement\n  3. Decrease learning rate - Done(set lr to 1e-4), No improvement hence setting back to 1e-3\n  4. Add dropout layers, Updated patience from 3 to 5 - Done, but now model is underfit\n  5. Increase no. of filters - Done\n  6. Load model saved using checkpoint and use it for prediction\n  7. Found that I was not dividing input by 255. ","62090040":"# Resources referred\n* https:\/\/github.com\/keras-team\/keras\/issues\/2711\n* https:\/\/blog.slavv.com\/37-reasons-why-your-neural-network-is-not-working-4020854bd607\n* https:\/\/www.kaggle.com\/monkira\/brain-mri-segmentation-using-unet-keras\n* https:\/\/keras.io\/examples\/vision\/oxford_pets_image_segmentation\/","7114a212":"# Data Generator","45e2b59e":"# Testing","f5e5c3e9":"# Model","9946d58d":"## Train Validation Test split","94c63f03":"# Observation\n1. Loss was not improving after 2nd epoch(it was remaining same). However that issue was resolved aftre adding batch normalization layers\n2. Masks predicted were not accurate. It was covering majority area of image. This issue was resolved after tunning no. of filters and learning rate and prediction input normalization.","e64c7fae":"# Data Preperation","3be0426a":"# Loss function and Metrics","932e2349":"# Training"}}