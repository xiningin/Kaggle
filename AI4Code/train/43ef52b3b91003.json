{"cell_type":{"6164c0fc":"code","bf05899e":"code","23c718a2":"code","82936509":"code","a717fb5c":"code","61a47545":"code","e1a1aeb1":"code","07f69196":"code","50d031c2":"code","f9d87daf":"code","cce99901":"code","e07dd6ce":"code","15255d75":"code","2aa76710":"code","6907d9ef":"code","bae4eebd":"code","81db94fc":"code","8022202e":"code","81d91f16":"code","825dcd76":"code","710166b3":"code","7164b96d":"code","f16d7e26":"code","79faee37":"code","7040367e":"markdown","ff6e298a":"markdown","a4375533":"markdown","aaed2d73":"markdown","5b9e873e":"markdown","375ebef1":"markdown","d1648baf":"markdown","b14d7af5":"markdown"},"source":{"6164c0fc":"!pip install -q segmentation-models-pytorch\n\nfrom glob import glob\nimport os\nimport time\n\nimport albumentations as A\nimport cv2\nimport numpy as np\nimport matplotlib.patches as mpatches\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom scipy.ndimage.morphology import binary_dilation\nimport segmentation_models_pytorch as smp\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms as T\nfrom tqdm import tqdm","bf05899e":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","23c718a2":"def get_file_row(path):\n    \"\"\"Produces ID of a patient, image and mask filenames from a particular path\"\"\"\n    path_no_ext, ext = os.path.splitext(path)\n    filename = os.path.basename(path)\n    \n    patient_id = '_'.join(filename.split('_')[:3]) # Patient ID in the csv file consists of 3 first filename segments\n    \n    return [patient_id, path, f'{path_no_ext}_mask{ext}']","82936509":"get_file_row('\/kaggle\/input\/lgg-mri-segmentation\/lgg-mri-segmentation\/kaggle_3m\/TCGA_DU_7010_19860307\/TCGA_DU_7010_19860307_45.tif')","a717fb5c":"files_dir = '\/kaggle\/input\/lgg-mri-segmentation\/lgg-mri-segmentation\/kaggle_3m\/'\nfile_paths = glob(f'{files_dir}\/*\/*[0-9].tif')","61a47545":"csv_path = '\/kaggle\/input\/lgg-mri-segmentation\/lgg-mri-segmentation\/kaggle_3m\/data.csv'\ndf = pd.read_csv(csv_path)\n\ndf.info()","e1a1aeb1":"imputer = SimpleImputer(strategy=\"most_frequent\")\nprint(list(df.columns))\ndf = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\ndf","07f69196":"filenames_df = pd.DataFrame((get_file_row(filename) for filename in file_paths), columns=['Patient', 'image_filename', 'mask_filename'])\nfilenames_df","50d031c2":"class MriDataset(Dataset):\n    def __init__(self, df, transform=None, mean=0.5, std=0.25):\n        super(MriDataset, self).__init__()\n        self.df = df\n        self.transform = transform\n        self.mean = mean\n        self.std = std\n        \n        \n    def __len__(self):\n        return len(self.df)\n        \n    def __getitem__(self, idx, raw=False):\n        row = self.df.iloc[idx]\n        img = cv2.imread(row['image_filename'], cv2.IMREAD_UNCHANGED)\n        mask = cv2.imread(row['mask_filename'], cv2.IMREAD_GRAYSCALE)\n        if raw:\n            return img, mask\n        \n        if self.transform:\n            augmented = self.transform(image=img, mask=mask)\n            image, mask = augmented['image'], augmented['mask']\n        \n        img = T.functional.to_tensor(img)\n        mask = mask \/\/ 255\n        mask = torch.Tensor(mask)\n        return img, mask","f9d87daf":"df = pd.merge(df, filenames_df, on=\"Patient\")","cce99901":"train_df, test_df = train_test_split(df, test_size=0.3)\ntest_df, valid_df = train_test_split(test_df, test_size=0.5)","e07dd6ce":"transform = A.Compose([\n    A.ChannelDropout(p=0.3),\n    A.RandomBrightnessContrast(p=0.3),\n    A.ColorJitter(p=0.3),\n])\n\ntrain_dataset = MriDataset(train_df, transform)\nvalid_dataset = MriDataset(valid_df)\ntest_dataset = MriDataset(test_df)","15255d75":"batch_size = 16\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=1)","2aa76710":"%matplotlib inline\nn_examples = 4\n\nfig, axs = plt.subplots(n_examples, 3, figsize=(20, n_examples*7), constrained_layout=True)\ni = 0\nfor ax in axs:\n    while True:\n        image, mask = train_dataset.__getitem__(i, raw=True)\n        i += 1\n        if np.any(mask): \n            ax[0].set_title(\"MRI images\")\n            ax[0].imshow(image)\n            ax[1].set_title(\"Highlited abnormality\")\n            ax[1].imshow(image)\n            ax[1].imshow(mask, alpha=0.2)\n            ax[2].imshow(mask)\n            ax[2].set_title(\"Abnormality mask\")\n            break\n        \n    \n    ","6907d9ef":"class EarlyStopping():\n    \"\"\"\n    Stops training when loss stops decreasing in a PyTorch module.\n    \"\"\"\n    def __init__(self, patience:int = 6, min_delta: float = 0, weights_path: str = 'weights.pt'):\n        \"\"\"\n        :param patience: number of epochs of non-decreasing loss before stopping\n        :param min_delta: minimum difference between best and new loss that is considered\n            an improvement\n        :paran weights_path: Path to the file that should store the model's weights\n        \"\"\"\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = float('inf')\n        self.weights_path = weights_path\n\n    def __call__(self, val_loss: float, model: torch.nn.Module):\n        if self.best_loss - val_loss > self.min_delta:\n            self.best_loss = val_loss\n            torch.save(model.state_dict(), self.weights_path)\n            self.counter = 0\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                return True\n        return False\n\n    def load_weights(self, model: torch.nn.Module):\n        \"\"\"\n        Loads weights of the best model.\n        :param model: model to which the weigths should be loaded\n        \"\"\"\n        return model.load_state_dict(torch.load(self.weights_path))\n            ","bae4eebd":"def iou_pytorch(predictions: torch.Tensor, labels: torch.Tensor, e: float = 1e-7):\n    \"\"\"Calculates Intersection over Union for a tensor of predictions\"\"\"\n    predictions = torch.where(predictions > 0.5, 1, 0)\n    labels = labels.byte()\n    \n    intersection = (predictions & labels).float().sum((1, 2))\n    union = (predictions | labels).float().sum((1, 2))\n    \n    iou = (intersection + e) \/ (union + e)\n    return iou\n\ndef dice_pytorch(predictions: torch.Tensor, labels: torch.Tensor, e: float = 1e-7):\n    \"\"\"Calculates Dice coefficient for a tensor of predictions\"\"\"\n    predictions = torch.where(predictions > 0.5, 1, 0)\n    labels = labels.byte()\n    \n    intersection = (predictions & labels).float().sum((1, 2))\n    return ((2 * intersection) + e) \/ (predictions.float().sum((1, 2)) + labels.float().sum((1, 2)) + e)","81db94fc":"def BCE_dice(output, target, alpha=0.01):\n    bce = torch.nn.functional.binary_cross_entropy(output, target)\n    soft_dice = 1 - dice_pytorch(output, target).mean()\n    return bce + alpha * soft_dice","8022202e":"model = smp.FPN(\n    encoder_name=\"efficientnet-b7\",\n    encoder_weights=\"imagenet\",\n    in_channels=3,\n    classes=1,\n    activation='sigmoid',\n)\nmodel.to(device);","81d91f16":"def training_loop(epochs, model, train_loader, valid_loader, optimizer, loss_fn, lr_scheduler):\n    history = {'train_loss': [], 'val_loss': [], 'val_IoU': [], 'val_dice': []}\n    early_stopping = EarlyStopping(patience=7)\n    \n    for epoch in range(1, epochs + 1):\n        start_time = time.time()\n        \n        running_loss = 0\n        model.train()\n        for i, data in enumerate(tqdm(train_loader)):\n            img, mask = data\n            img, mask = img.to(device), mask.to(device)\n            predictions = model(img)\n            predictions = predictions.squeeze(1)\n            loss = loss_fn(predictions, mask)\n            running_loss += loss.item() * img.size(0)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        \n        model.eval()\n        with torch.no_grad():\n            running_IoU = 0\n            running_dice = 0\n            running_valid_loss = 0\n            for i, data in enumerate(valid_loader):\n                img, mask = data\n                img, mask = img.to(device), mask.to(device)\n                predictions = model(img)\n                predictions = predictions.squeeze(1)\n                running_dice += dice_pytorch(predictions, mask).sum().item()\n                running_IoU += iou_pytorch(predictions, mask).sum().item()\n                loss = loss_fn(predictions, mask)\n                running_valid_loss += loss.item() * img.size(0)\n        train_loss = running_loss \/ len(train_loader.dataset)\n        val_loss = running_valid_loss \/ len(valid_loader.dataset)\n        val_dice = running_dice \/ len(valid_loader.dataset)\n        val_IoU = running_IoU \/ len(valid_loader.dataset)\n        \n        history['train_loss'].append(train_loss)\n        history['val_loss'].append(val_loss)\n        history['val_IoU'].append(val_IoU)\n        history['val_dice'].append(val_dice)\n        print(f'Epoch: {epoch}\/{epochs} | Training loss: {train_loss} | Validation loss: {val_loss} | Validation Mean IoU: {val_IoU} '\n         f'| Validation Dice coefficient: {val_dice}')\n        \n        lr_scheduler.step(val_loss)\n        if early_stopping(val_loss, model):\n            early_stopping.load_weights(model)\n            break\n    model.eval()\n    return history","825dcd76":"loss_fn = BCE_dice\noptimizer = Adam(model.parameters(), lr=0.001)\nepochs = 60\nlr_scheduler = ReduceLROnPlateau(optimizer=optimizer, patience=2,factor=0.2)\n\nhistory = training_loop(epochs, model, train_loader, valid_loader, optimizer, loss_fn, lr_scheduler)","710166b3":"plt.figure(figsize=(7, 7))\nplt.plot(history['train_loss'], label='Training loss')\nplt.plot(history['val_loss'], label='Validation loss')\nplt.ylim(0, 0.01)\nplt.legend()\nplt.show()","7164b96d":"plt.figure(figsize=(7, 7))\nplt.plot(history['val_IoU'], label='Validation mean Jaccard index')\nplt.plot(history['val_dice'], label='Validation Dice coefficient')\nplt.legend()\nplt.show()","f16d7e26":"with torch.no_grad():\n    running_IoU = 0\n    running_dice = 0\n    running_loss = 0\n    for i, data in enumerate(test_loader):\n        img, mask = data\n        img, mask = img.to(device), mask.to(device)\n        predictions = model(img)\n        predictions = predictions.squeeze(1)\n        running_dice += dice_pytorch(predictions, mask).sum().item()\n        running_IoU += iou_pytorch(predictions, mask).sum().item()\n        loss = loss_fn(predictions, mask)\n        running_loss += loss.item() * img.size(0)\n    loss = running_loss \/ len(test_dataset)\n    dice = running_dice \/ len(test_dataset)\n    IoU = running_IoU \/ len(test_dataset)\n    \n    print(f'Tests: loss: {loss} | Mean IoU: {IoU} | Dice coefficient: {dice}')","79faee37":"%matplotlib inline\n\nwidth = 3\ncolumns = 10\nn_examples = columns * width\n\nfig, axs = plt.subplots(columns, width, figsize=(7*width , 7*columns), constrained_layout=True)\nred_patch = mpatches.Patch(color='red', label='The red data')\nfig.legend(loc='upper right',handles=[\n    mpatches.Patch(color='red', label='Ground truth'),\n    mpatches.Patch(color='green', label='Predicted abnormality')])\ni = 0\nwith torch.no_grad():\n    for data in test_loader:\n        image, mask = data\n        mask = mask[0]\n        if not mask.byte().any():\n            continue\n        image = image.to(device)\n        prediction = model(image).to('cpu')[0][0]\n        prediction = torch.where(prediction > 0.5, 1, 0)\n        prediction_edges = prediction - binary_dilation(prediction)\n        ground_truth = mask - binary_dilation(mask)\n        image[0, 0, ground_truth.bool()] = 1\n        image[0, 1, prediction_edges.bool()] = 1\n        \n        axs[i\/\/width][i%width].imshow(image[0].to('cpu').permute(1, 2, 0))\n        if n_examples == i + 1:\n            break\n        i += 1\n","7040367e":"Only applied channel dropout and random color changes, the model gave subpar results when confronted with rotations and flips.","ff6e298a":"# 1. Loading data","a4375533":"# 3. Visualization and analysis","aaed2d73":"# 5. Testing","5b9e873e":"Adding custom lose consisting of binary crossentropy and soft dice coefficient gives slightly better results.","375ebef1":"# 2. Preparing the datasets","d1648baf":"# 4. Preparing model and training","b14d7af5":"I am not sure if the csv data would be useful, but I'll put it together with the images anyway."}}