{"cell_type":{"0a511105":"code","6761db51":"code","b58e54e5":"code","44aef6e6":"code","31d9a23b":"code","fd81db34":"code","d7a74a35":"code","e0b4c733":"code","944bc12d":"code","20844d04":"code","3626fa93":"code","d89f3053":"code","ccfb96db":"code","f71abed9":"code","b5457e1d":"code","b51d554c":"code","376df5ab":"code","0bcd6037":"code","b14ddf02":"code","03c78005":"code","423947e2":"code","b5e612c2":"code","ae1fe3af":"code","5fa457c8":"code","0e82be64":"code","870a34ad":"code","9b1b35fd":"code","83b53912":"code","48f09688":"code","5d3fdf0f":"code","59b603e1":"code","7846efb7":"code","e05d29aa":"code","1dd8469d":"code","b655bbf2":"code","27f2adda":"code","7f693b37":"code","49c208c0":"code","04d522fa":"code","b670200b":"code","ce7b9db0":"code","a0ef3280":"code","a4b092a5":"code","5b9fbb33":"code","9bcb53e5":"code","211af665":"code","25deb26a":"code","ec9d0843":"code","89ac6f79":"markdown","c91ac46f":"markdown","63269add":"markdown","5f3dcddc":"markdown","5ff18222":"markdown","742122c0":"markdown","838a9b38":"markdown","96a93d60":"markdown","f85553ed":"markdown","6830cf98":"markdown","4473deeb":"markdown","a3f9e382":"markdown","e74319d4":"markdown","b08d36f8":"markdown","dd742401":"markdown","85aa2df9":"markdown","84b0c4a2":"markdown","150f59c4":"markdown","abd0f02e":"markdown","6529be44":"markdown","a09b9a6c":"markdown","759e146c":"markdown","efc47f4c":"markdown","56dc445d":"markdown","8cea017c":"markdown","8fc58433":"markdown","e4ef0b0f":"markdown","96a541fc":"markdown"},"source":{"0a511105":"# Importing all the necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import defaultdict\nimport string\nimport re\nimport nltk\nfrom nltk.corpus import stopwords as StopWords\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, log_loss\nfrom xgboost import XGBClassifier\nimport warnings\nwarnings.filterwarnings(\"ignore\")","6761db51":"# Loading the dataset\nreviews_dataset = pd.read_csv(\"..\/input\/hotel-reviews-from-tripadvisor\/mussorie_reviews.csv\")\nreviews_dataset.head()","b58e54e5":"# Checking information about the dataset\nreviews_dataset.info()","44aef6e6":"# Dropping all the rows with null values\nreviews_dataset.dropna(inplace=True)","31d9a23b":"# Dropping duplicate rows\nreviews_dataset.drop_duplicates(inplace=True)","fd81db34":"# Checking information for the dataset after removing null value rows and duplicate rows\nreviews_dataset.info()","d7a74a35":"reviews_dataset","e0b4c733":"# Extracting rating value from the unclean rating column\nreviews_dataset[\"Rating\"] = reviews_dataset[\"Rating\"].apply(lambda x: re.findall(\"\\d\", x)[0])\nreviews_dataset","944bc12d":"# Checking percentage of rows for each rating\nreviews_dataset[\"Rating\"].value_counts(normalize = True)","20844d04":"# Mapping positive, neutral and negative to rating values \nreviews_dataset[\"Sentiment\"] = reviews_dataset[\"Rating\"].map({\"5\":\"Positive\", \"4\":\"Positive\", \"3\":\"Neutral\", \"2\":\"Negative\", \"1\":\"Negative\"})","3626fa93":"# Creating a new column year of stay from our existing column date of stay\nreviews_dataset[\"Year of stay\"] = reviews_dataset[\"Date of stay\"].apply(lambda x: \"\".join(re.findall(\"\\d\\d\\d\\d\", x)))\nreviews_dataset","d89f3053":"# Creating a month of stay column from date of stay column\nreviews_dataset[\"Month of stay\"] = reviews_dataset[\"Date of stay\"].apply(lambda x: \"\".join(re.findall(r'(Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)', x)))\nreviews_dataset","ccfb96db":"# Dropping all rows for which year is less than 2018\nreviews_dataset.drop(reviews_dataset[reviews_dataset[\"Year of stay\"] < '2018'].index, axis=0, inplace=True)\n\n# Dropping all neutral sentiment rows\nreviews_dataset.drop(reviews_dataset[reviews_dataset[\"Sentiment\"] == \"Neutral\"].index, axis=0, inplace=True)","f71abed9":"# Checking information for the dataset after removing rows\nreviews_dataset.info()","b5457e1d":"# Checking percentage of each sentiment in our dataset\nreviews_dataset.Sentiment.value_counts(normalize=True)","b51d554c":"# Shuffling the dataset\nreviews_dataset = reviews_dataset.sample(frac = 1)\nreviews_dataset","376df5ab":"# Dropping date of stay and rating column from our dataset\nreviews_dataset.drop(['Date of stay', 'Rating'], axis=1, inplace=True)","0bcd6037":"# Creating a function to preprocess data\ndef preprocess_data(text):\n    \"\"\"\n    Returns text after removing numbers, punctuations, urls, emojis, html tags and lowercasing all the words in given text.\n    \"\"\"\n    text = re.sub(r'[0-9]+', '', str(text))   # removing numbers\n    text = re.sub(r'[^\\w\\s]', '', str(text))   # removing punctuations\n    text = \" \".join(x.lower() for x in text.split())  # lower casing the text\n    text = re.sub(r'https?:\/\/\\S+|www\\.\\S+', '', text)  # removing urls\n    text = re.sub(r'<.*?>', '', text) # removing html tags\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    text = \" \".join(x for x in text.split() if x not in StopWords.words('english'))\n    return text","b14ddf02":"# Applying preprocess_data function to review column\nreviews_dataset[\"Preprocessed_reviews\"] = reviews_dataset[\"Review\"].apply(lambda x: preprocess_data(x))\nreviews_dataset","03c78005":"# Word count\nreviews_dataset[\"Word_count\"] = reviews_dataset[\"Review\"].apply(lambda x: len(str(x).split()))\nreviews_dataset.head()","423947e2":"# Unique word count\nreviews_dataset[\"Unique_word_count\"] = reviews_dataset[\"Review\"].apply(lambda x: len(set(str(x).split())))\nreviews_dataset.head()","b5e612c2":"# Number of stop words in review\nstop_words = StopWords.words('english')\nreviews_dataset[\"Stopword_count\"] = reviews_dataset[\"Review\"].apply(lambda x: len([w for w in str(x).lower().split() if w not in stop_words]))\nreviews_dataset.head()","ae1fe3af":"# mean word length\nreviews_dataset[\"Mean_word_length\"] = reviews_dataset[\"Review\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\nreviews_dataset.head()","5fa457c8":"#char count\nreviews_dataset[\"Char_count\"] = reviews_dataset[\"Review\"].apply(lambda x: len(str(x)))\nreviews_dataset.head()","0e82be64":"# punctuation count\nreviews_dataset[\"Punctuation_count\"] = reviews_dataset[\"Review\"].apply(lambda x: len([p for p in str(x) if p in string.punctuation]))\nreviews_dataset.head()","870a34ad":"# Creating a pie chart showing target distribution in dataset\nplt.figure(figsize=(9, 9))\ns = reviews_dataset['Sentiment'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=90, fontsize=14, colors=['#72EEA4', '#F37D67']);\ns.set_ylabel('');\ns.set_title('Target Distribution in dataset', fontsize=20);","9b1b35fd":"# Funtion for generating ngrams\ndef generate_ngrams(text, n_gram=1):\n    \"\"\"\n    Returns ngrams for the given text.\n    \n    Parameters:\n    text : for which we want ngrams\n    n_gram : value for ngram\n    \"\"\"\n    token = [token for token in text.lower().split(' ') if token != '' if token not in STOPWORDS]\n    ngrams = zip(*[token[i:] for i in range(n_gram)])\n    return [' '.join(ngram) for ngram in ngrams]","83b53912":"# Creating a default dictionary for positive and negative unigrams\npositive_unigrams = defaultdict(int)\nnegative_unigrams = defaultdict(int)\n\n# Number of ngrams we want\nN = 25\n\n# Loop for updating value of positive_unigrams\nfor review in reviews_dataset['Preprocessed_reviews'][reviews_dataset['Sentiment']==\"Positive\"]:\n    for word in generate_ngrams(review):\n        positive_unigrams[word] += 1\n\nfor review in reviews_dataset['Preprocessed_reviews'][reviews_dataset['Sentiment']==\"Negative\"]:\n    for word in generate_ngrams(review):\n        negative_unigrams[word] += 1\n        \n# Creating dataframes using default dictionaries\ndf_positive_unigrams = pd.DataFrame(sorted(positive_unigrams.items(), key=lambda x: x[1])[::-1])\ndf_negative_unigrams = pd.DataFrame(sorted(negative_unigrams.items(), key=lambda x: x[1])[::-1])\n\n        \nfig, axes = plt.subplots(ncols=2, figsize=(24, 10))\nplt.tight_layout(pad=4.0)\n\n# Plotting positive and negative unigrams dataset\nsns.despine()\nsns.barplot(y = df_positive_unigrams[0].values[:N], x = df_positive_unigrams[1].values[:N], ax=axes[0], color='#72EEA4')\nsns.barplot(y = df_negative_unigrams[0].values[:N], x = df_negative_unigrams[1].values[:N], ax=axes[1], color='#F37D67')\n\naxes[0].set_title(f'Top {N} most common unigrams in Positive Reviews', fontsize=15)\naxes[1].set_title(f'Top {N} most common unigrams in Negative Reviews', fontsize=15)\n\nplt.show()","48f09688":"# Creating a default dictionary for positive and negative bigrams\npositive_bigrams = defaultdict(int)\nnegative_bigrams = defaultdict(int)\n\n# Number of ngrams we want\nN = 25\n\n# Loop for updating values of bigrams in default dictionary\nfor review in reviews_dataset['Preprocessed_reviews'][reviews_dataset['Sentiment']==\"Positive\"]:\n    for word in generate_ngrams(review, n_gram=2):\n        positive_bigrams[word] += 1\n\nfor review in reviews_dataset['Preprocessed_reviews'][reviews_dataset['Sentiment']==\"Negative\"]:\n    for word in generate_ngrams(review, n_gram=2):\n        negative_bigrams[word] += 1\n        \n# Creating a dataset using default dictionaries\ndf_positive_bigrams = pd.DataFrame(sorted(positive_bigrams.items(), key=lambda x: x[1])[::-1])\ndf_negative_bigrams = pd.DataFrame(sorted(negative_bigrams.items(), key=lambda x: x[1])[::-1])\n        \nfig, axes = plt.subplots(ncols=2, figsize=(24, 10))\nplt.tight_layout(pad=4.0)\n \n# Plotting both positive and negative bigrams\nsns.despine()\nsns.barplot(y = df_positive_bigrams[0].values[:N], x = df_positive_bigrams[1].values[:N], ax=axes[0], color='#72EEA4')\nsns.barplot(y = df_negative_bigrams[0].values[:N], x = df_negative_bigrams[1].values[:N], ax=axes[1], color='#F37D67')\n\naxes[0].set_title(f'Top {N} most common bigrams in Positive Reviews', fontsize=15)\naxes[1].set_title(f'Top {N} most common bigrams in Negative Reviews', fontsize=15)\n\nplt.show()","5d3fdf0f":"# Creating default dictionary for positive and negative trigrams\npositive_trigrams = defaultdict(int)\nnegative_trigrams = defaultdict(int)\n\n# Number of ngrams we want\nN = 25\n\n# Loop for updating default dictionaries \nfor review in reviews_dataset['Preprocessed_reviews'][reviews_dataset['Sentiment']==\"Positive\"]:\n    for word in generate_ngrams(review, n_gram=3):\n        positive_trigrams[word] += 1\n\nfor review in reviews_dataset['Preprocessed_reviews'][reviews_dataset['Sentiment']==\"Negative\"]:\n    for word in generate_ngrams(review, n_gram=3):\n        negative_trigrams[word] += 1\n        \n# Creating a dataframe using dictionaries\ndf_positive_trigrams = pd.DataFrame(sorted(positive_trigrams.items(), key=lambda x: x[1])[::-1])\ndf_negative_trigrams = pd.DataFrame(sorted(negative_trigrams.items(), key=lambda x: x[1])[::-1])\n        \nfig, axes = plt.subplots(ncols=2, figsize=(24, 10))\nplt.tight_layout(pad=4.0)\n     \n# Plotting positive and negative trigrams\nsns.despine()\nsns.barplot(y = df_positive_trigrams[0].values[:N], x = df_positive_trigrams[1].values[:N], ax=axes[0], color='#72EEA4')\nsns.barplot(y = df_negative_trigrams[0].values[:N], x = df_negative_trigrams[1].values[:N], ax=axes[1], color='#F37D67')\n\naxes[0].set_title(f'Top {N} most common trigrams in Positive Reviews', fontsize=15)\naxes[1].set_title(f'Top {N} most common trigrams in Negative Reviews', fontsize=15)\n\nplt.show()","59b603e1":"# Plotting number of reviews in each month\nplt.figure(figsize = (24, 5))\nmonth =['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\nsns.despine()\nsns.countplot(x=\"Month of stay\", data=reviews_dataset, order=month, color='#62DCEC');","7846efb7":"# Plotting number of reviews for each year\nplt.figure(figsize = (24, 5))\nyears = ['2018', '2019', '2020', '2021']\nsns.despine()\nsns.countplot(x=\"Year of stay\", data=reviews_dataset, order=years, color='#62DCEC');","e05d29aa":"# Plotting word count for reviews\nfig, axes = plt.subplots(ncols = 2, figsize=(24, 6))\n\nsns.despine()\nsns.histplot(ax=axes[0], x=\"Word_count\", data=reviews_dataset[reviews_dataset['Sentiment']=='Positive'], kde=True, color='#72EEA4');\nsns.histplot(ax=axes[1], x=\"Word_count\", data=reviews_dataset[reviews_dataset['Sentiment']=='Negative'], kde=True, color='#F37D67');\n\naxes[0].set_title(\"Positive reviews\", fontsize=16)\naxes[1].set_title(\"Negative reviews\", fontsize=16)\n\naxes[0].set_ylabel(\"Number of reviews\", fontsize=12)\naxes[1].set_ylabel(\"Number of reviews\", fontsize=12)\naxes[0].set_xlabel(\"Word count in review\", fontsize=12)\naxes[1].set_xlabel(\"Word count in review\", fontsize=12)\n\nfig.suptitle(\"Word count for reviews\", fontsize=20)\nplt.show()","1dd8469d":"# Plotting unique word count for reviews\nfig, axes = plt.subplots(ncols = 2, figsize=(24, 6))\n\nsns.despine()\nsns.histplot(ax=axes[0], x=\"Unique_word_count\", data=reviews_dataset[reviews_dataset['Sentiment']=='Positive'], kde=True, color='#72EEA4');\nsns.histplot(ax=axes[1], x=\"Unique_word_count\", data=reviews_dataset[reviews_dataset['Sentiment']=='Negative'], kde=True, color='#F37D67');\n\naxes[0].set_title(\"Positive reviews\", fontsize=16)\naxes[1].set_title(\"Negative reviews\", fontsize=16)\n\naxes[0].set_ylabel(\"Number of reviews\", fontsize=12)\naxes[1].set_ylabel(\"Number of reviews\", fontsize=12)\naxes[0].set_xlabel(\"Unique word count in review\", fontsize=12)\naxes[1].set_xlabel(\"Unique word count in review\", fontsize=12)\n\nfig.suptitle(\"Unique word count for reviews\", fontsize=20)\nplt.show()","b655bbf2":"# Plotting stopword count for reviews\nfig, axes = plt.subplots(ncols = 2, figsize=(24, 6))\n\nsns.despine()\nsns.histplot(ax=axes[0], x=\"Stopword_count\", data=reviews_dataset[reviews_dataset['Sentiment']=='Positive'], kde=True, color='#72EEA4');\nsns.histplot(ax=axes[1], x=\"Stopword_count\", data=reviews_dataset[reviews_dataset['Sentiment']=='Negative'], kde=True, color='#F37D67');\n\naxes[0].set_title(\"Positive reviews\", fontsize=16)\naxes[1].set_title(\"Negative reviews\", fontsize=16)\n\naxes[0].set_ylabel(\"Number of reviews\", fontsize=12)\naxes[1].set_ylabel(\"Number of reviews\", fontsize=12)\naxes[0].set_xlabel(\"Stopword count in review\", fontsize=12)\naxes[1].set_xlabel(\"Stopword count in review\", fontsize=12)\n\nfig.suptitle(\"Stopword count for reviews\", fontsize=20)\nplt.show()","27f2adda":"# Plotting character count for reviews\nfig, axes = plt.subplots(ncols = 2, figsize=(24, 6))\n\nsns.despine()\nsns.histplot(ax=axes[0], x=\"Char_count\", data=reviews_dataset[reviews_dataset['Sentiment']=='Positive'], kde=True, color='#72EEA4');\nsns.histplot(ax=axes[1], x=\"Char_count\", data=reviews_dataset[reviews_dataset['Sentiment']=='Negative'], kde=True, color='#F37D67');\n\naxes[0].set_title(\"Positive reviews\", fontsize=16)\naxes[1].set_title(\"Negative reviews\", fontsize=16)\n\naxes[0].set_ylabel(\"Number of reviews\", fontsize=12)\naxes[1].set_ylabel(\"Number of reviews\", fontsize=12)\naxes[0].set_xlabel(\"Character count in review\", fontsize=12)\naxes[1].set_xlabel(\"Character count in review\", fontsize=12)\n\nfig.suptitle(\"Character count for reviews\", fontsize=20)\nplt.show()","7f693b37":"# Plotting punctuation count for reviews\nfig, axes = plt.subplots(ncols = 2, figsize=(24, 6))\n\nsns.despine()\nsns.histplot(ax=axes[0], x=\"Punctuation_count\", data=reviews_dataset[reviews_dataset['Sentiment']=='Positive'], kde=True, color='#72EEA4');\nsns.histplot(ax=axes[1], x=\"Punctuation_count\", data=reviews_dataset[reviews_dataset['Sentiment']=='Negative'], kde=True, color='#F37D67');\n\naxes[0].set_title(\"Positive reviews\", fontsize=16)\naxes[1].set_title(\"Negative reviews\", fontsize=16)\naxes[0].set_xscale('log')\n\naxes[0].set_ylabel(\"Number of reviews\", fontsize=12)\naxes[1].set_ylabel(\"Number of reviews\", fontsize=12)\naxes[0].set_xlabel(\"Punctuation count in review\", fontsize=12)\naxes[1].set_xlabel(\"Punctuation count in review\", fontsize=12)\n\nfig.suptitle(\"Punctuation count for reviews\", fontsize=20)\nplt.show()","49c208c0":"# Plotting a wordcloud for positive reviews\npositive = \" \".join(review for review in reviews_dataset['Preprocessed_reviews'][reviews_dataset['Sentiment']==\"Positive\"])\nwordcloud = WordCloud(background_color='white', stopwords = STOPWORDS, max_words=500, max_font_size=40, random_state=42, colormap='Greens').generate(positive)\nplt.figure(figsize=(15, 10))\nplt.title(\"Most common words in positive reviews\")\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","04d522fa":"# Plotting wordcloud for negative reviews\nnegative = \" \".join(review for review in reviews_dataset['Preprocessed_reviews'][reviews_dataset['Sentiment']==\"Negative\"])\nwordcloud = WordCloud(background_color='white', stopwords = STOPWORDS, max_words=500, max_font_size=40, random_state=42, colormap = \"Reds\").generate(negative)\nplt.figure(figsize=(15, 10))\nplt.title(\"Most common words in negative reviews\")\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","b670200b":"# Create custom stop words\nall_text = \" \".join(list(reviews_dataset[\"Preprocessed_reviews\"]))\nwords = pd.Series(all_text.split(\" \"))\nfrequent_words = words.value_counts()[:20]","ce7b9db0":"# Deleting top 10 frequent words from preprocessed_reviews\nreviews_dataset[\"Preprocessed_reviews\"] = reviews_dataset[\"Preprocessed_reviews\"].apply(lambda x: \" \".join([word for word in str(x).split() if word not in frequent_words]))","a0ef3280":"# Using label encoder to encode sentiment column\nle = LabelEncoder()\nreviews_dataset['Sentiment'] = le.fit_transform(reviews_dataset['Sentiment'])","a4b092a5":"# Splitting the dataset into training and testing dataset\nxtrain, xtest, ytrain, ytest = train_test_split(reviews_dataset['Review'], reviews_dataset['Sentiment'], \n                                                  stratify=reviews_dataset['Sentiment'], \n                                                  random_state=42, \n                                                  test_size=0.2, shuffle=True)","5b9fbb33":"# Splitting training dataset into training and validation dataset\nxtrain, xval, ytrain, yval = train_test_split(xtrain, ytrain, \n                                                  stratify=ytrain, \n                                                  random_state=42, \n                                                  test_size=0.1, shuffle=True)","9bcb53e5":"# Initializing TfidfVectorizer\ntfv = TfidfVectorizer(min_df=3,  max_features=None, decode_error = \"replace\", preprocessor = preprocess_data,\n            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n            stop_words = 'english')\n\n# Fitting Tfidf vectorizer to training dataset\ntfv.fit(list(xtrain))\n\n# Transforming the training and validation dataset \nxtrain_tfv = tfv.transform(xtrain)\nxval_tfv = tfv.transform(xval)","211af665":"# Initializing XGBClassifier\nxgb = XGBClassifier(learning_rate=0.02, n_estimators=600, max_depth=4, subsample= 1.0, min_child_weight=1, gamma= 0.5, colsample_bytree= 0.8, random_state=42)\n\n# Fitting xgb on training dataset\nxgb.fit(xtrain_tfv, ytrain)\n\n# Making predictions on validation dataset\npredictions = xgb.predict_proba(xval_tfv)\nprint (\"logloss: %0.3f \" % log_loss(yval, predictions))\n\nypred_xg = xgb.predict(xval_tfv)\nprint(classification_report(yval, ypred_xg))","25deb26a":"# Transfroming test dataset using the same tfidf vectorizer we fit on training dataset\nxtest_tfv = tfv.transform(xtest)","ec9d0843":"# Making prediction on testing dataset \npredictions = xgb.predict_proba(xtest_tfv)\nprint (\"logloss: %0.3f \" % log_loss(ytest, predictions))\nypred_xg = xgb.predict(xtest_tfv)\nprint(classification_report(ytest, ypred_xg))","89ac6f79":"### Creating year of stay column","c91ac46f":"## <center><h1 style=\"border-radius: 25px; background: #49F7F8; width: 500px; height: 60px;\">Model evaluation<\/h1><\/center>","63269add":"**There are a total of 15196 entries in the dataset. Date of stay column have 16 missing values.**","5f3dcddc":"**XGBClassifier gives a log loss of 0.034 and F1-score for negative reviews is 0.69 and for positive reviews it is 0.99.**","5ff18222":"### Creating month of stay column","742122c0":"### Creating a column for average word length in a review","838a9b38":"### Creating a column for number of words in a review","96a93d60":"### Creating a column for number of stopwords in a review","f85553ed":"### Creating a column for number of unique words in a review","6830cf98":"### Creating a column for number of character in a review","4473deeb":"**For test dataset we get a log loss of 0.051 and F1 score for negative reviews is 0.68 and for positive reviews is 0.99.**","a3f9e382":"### Function to preprocess the review column","e74319d4":"**Looking at these ngram plots we can easily see what are most positive and most negative words used in the reviews.**","b08d36f8":"**After removing reviews before 2018 and neutral sentiment, remaining row number is 8293.**","dd742401":"## <center><h1 style=\"border-radius: 25px; background: #49F7F8; width: 500px; height: 60px;\">Load Dataset<\/h1><\/center>","85aa2df9":"### Cleaning Rating column","84b0c4a2":"**Month of January and October has the highest number of reviews so we can say that number of people staying in hotel in these month is more compared to other months. Month of April has the  lowest number of reviews.**","150f59c4":"## <center><h1 style=\"border-radius: 25px; background: #49F7F8; width: 600px; height: 60px;\">Data Preprocessing<\/h1><\/center>","abd0f02e":"**Percentage of each kind of reviews in the dataset.**","6529be44":"### Creating a column for number of punctuation in a review","a09b9a6c":"**Number of rows after removing all the duplicates and null value rows is 12796.**","759e146c":"**2019 has the highest number of reviews whereas 2020 has the lowest because of global pandemic.**","efc47f4c":" **There are three columns namely, review, date of stay and rating.**\n- Review column have the review given by the customer. We have to extract relevant words from the text.\n- Date of stay column contains the month and year of the stay in the hotel. We can extract both month and year from the column.\n- Rating column is the rating the customer gave to their stay at the hotel. We need to extract the numbers from the text.","56dc445d":"**This is an imbalanced dataset as positive sentiment has more than 97.4% rows and negative sentiment has only 2.58% rows.**","8cea017c":"## <center><h1 style=\"border-radius: 25px; background: #49F7F8; width: 500px; height: 60px;\">Model training<\/h1><\/center>","8fc58433":"## <center><h1 style=\"border-radius: 25px; background: #49F7F8; width: 800px; height: 60px;\">Exploratory data analysis<\/h1><\/center>","e4ef0b0f":"Once there was a businessman having a good hotel in the city of Mussoorie near Mall Road. Well, what stuck your mind first when your heard about Mussoorie? Let me guess, and i am certain that it was beautiful mountains, greenery, cold breeze, and scenic beauty. So to enjoy all this you mush have a great place to stay and for this comfortability we are talking about that businessmen who owns a hotel in this beautiful hill station.\n\n\nBut this business man was old and his hotel had a very gentle and nice vintage touch , a place where you can sense the glory of past time along with the essence of woods from which it was made. It had soft carpets , beautiful wooden crafted bed, velvet stitched cushions and a fire place in every room to make you feel comfortable and cozy in your stay. Overall I can say that it was such a place where you can get the British times architecture along with Indian hospitality.\n\n\nAs we have seen in all these years of rapid advancement in urban sector and tourism that sometimes in the race of this modern world the vintage and old crafts lag behind. its not because that the owners of such businesses does not want to go ahead its just they don't know the right course of action and also the right idea that in what field they are lagging and exactly what their customers are expecting from them. \n\nThe owner of one such business asked you to somehow figure out what are the positives and negatives about his hotel according to the customer. He gave you a csv file which contains reviews, date of stay and rating given by reviewer. He also asked you to somehow help in predicting the sentiment of some reviews.","96a541fc":"## <center><h1 style=\"border-radius: 25px; background: #49F7F8; width: 500px; height: 60px;\">Introduction<\/h1><\/center>"}}