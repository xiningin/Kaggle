{"cell_type":{"278a613d":"code","c106be51":"code","9a139321":"code","8c43f72d":"code","adbc6da1":"code","8b604b83":"code","c69f2743":"code","41c932a9":"code","5898a74f":"code","19792119":"code","3820cf17":"code","50e14cba":"code","bac46885":"code","99984e07":"code","c9779749":"code","db4a9217":"code","c65eeaad":"code","ccc54964":"code","94db1934":"code","1f10c9b3":"code","8664c77d":"code","eea3fd8d":"code","0a0c68f8":"code","f377d563":"code","6197904d":"code","32160b78":"code","2b74a70b":"code","65d02644":"code","1b90b53c":"code","a8db422e":"code","7f046ab9":"code","d380353b":"code","a4264370":"code","c2849ba1":"code","4cc511a1":"code","8ce88729":"code","efeeda99":"code","7be0925a":"code","9d812a54":"code","5f91b42e":"code","c63951a6":"code","fe560787":"code","af2f2808":"code","36f0ff3c":"code","59fff5ea":"code","83cdf114":"code","0bdff285":"code","0215f577":"code","e05d6404":"code","95d69116":"code","85e67792":"code","93d3f8eb":"code","9bcc401b":"code","21d7db68":"code","d597f61a":"code","f1d24574":"code","e5f9d583":"code","42b58074":"code","f1c31c3e":"code","f75d9f2b":"code","e70c7bfd":"code","245f2c63":"code","bb59c9fa":"code","a0da9ef5":"code","99b84df2":"markdown","52d853d1":"markdown","4d1e33f0":"markdown","776be156":"markdown","1f1bf18a":"markdown","22a3f029":"markdown","e42988ef":"markdown","6a980c75":"markdown","13680aa6":"markdown","2dc66d6c":"markdown","7bdae7fd":"markdown","95566fea":"markdown","0b15aa2e":"markdown","6aba6320":"markdown","980a0884":"markdown","91bd1942":"markdown","93c87b8b":"markdown","2fd39046":"markdown","bc7aaeca":"markdown","05abf145":"markdown","c874e14e":"markdown","32c0bf84":"markdown","226d03a2":"markdown","d88407d3":"markdown","ffd7a2f1":"markdown","84f8b88d":"markdown","628b3d06":"markdown","b87a2031":"markdown","1756571a":"markdown","7fb4075c":"markdown","489e0f10":"markdown","2342cee6":"markdown","60754fdd":"markdown","7ecef65e":"markdown","d0a75f7a":"markdown","34248f2c":"markdown","4c89d6bc":"markdown","0133e7ef":"markdown","0cde1adb":"markdown","95365d26":"markdown","e9d9dc63":"markdown","31dd4be8":"markdown","9500b43a":"markdown","4ca6cfb4":"markdown","f24c755d":"markdown","4603c1e9":"markdown"},"source":{"278a613d":"import numpy as np\nimport pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler, OneHotEncoder\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport plotly.express as px \nimport plotly.graph_objects as go\nimport seaborn as sns\nimport xgboost\nimport warnings\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import set_config\nfrom lightgbm import LGBMClassifier\nimport math\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neural_network import MLPClassifier\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","c106be51":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","9a139321":"sns.set_theme()\nsns.set(font_scale=1.4)\nsns.set_style({'font.family': 'serif',\n               'fontname': 'Times New Roman'})\npd.options.display.max_columns = None\nmpl.rcParams['figure.dpi'] = 100\nset_config(display='diagram')","8c43f72d":"df_train = pd.read_csv('\/kaggle\/input\/aml-t2-fw\/Dados_Treino.csv')","adbc6da1":"df_test = pd.read_csv('\/kaggle\/input\/aml-t2-fw\/Dados_Teste.csv')","8b604b83":"df_train.head()","c69f2743":"df_train.describe()","41c932a9":"df_train.shape","5898a74f":"corrMatrix = df_train.corr()\nfig, ax = plt.subplots(figsize=(20,20))\nsns.heatmap(corrMatrix, annot=False, linewidths=.5, ax=ax)\nplt.show()","19792119":"pd.DataFrame(corrMatrix['diabetes_mellitus'].sort_values(ascending=False)).transpose()","3820cf17":"sns.countplot(df_train['diabetes_mellitus'])\nplt.title('Quantidade de amostras para cada classe')\nplt.show()","50e14cba":"dbdf = pd.DataFrame(df_train['diabetes_mellitus'].value_counts()).rename(index={0: \"N\u00e3o diab\u00e9tico\", 1: \"Diab\u00e9tico\"})\ndbdf['percent_diabetic'] = round(100*dbdf[\"diabetes_mellitus\"]\/len(df_train),2)\nfig = go.Figure(data = [go.Bar(\n                            x = dbdf.index.tolist(), \n                            y = dbdf[\"percent_diabetic\"].tolist(), \n                            width = [0.4,0.4],\n                            marker_color = ['lightskyblue', 'pink']\n                            )])\n\nfig.update_layout(yaxis_range=[0,100], width = 550, height = 550,\n                  title_text='Porcentagem de Pacientes com diabetes no dataset de Treino',\n                  xaxis_title = \"Diagn\u00f3stico\",\n                  yaxis_title = \"Porcentagem (%)\")","bac46885":"plt.hist(df_train.age, bins=[10,20,30,40,50,60,70,80,90,100],color='lightskyblue')\nplt.show()","99984e07":"plt.hist(df_train.weight, bins=[40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200],color='lightskyblue')\nplt.show()","c9779749":"plt.hist(df_train.height, bins=[130,135,140,145,150,155,160,165,170,175,180,185,190,195,200],color='lightskyblue')\nplt.show()","db4a9217":"plt.hist(df_train.bmi, bins=[20,25,30,35,40,45,50,55,60,65,70],color='lightskyblue')\nplt.show()","c65eeaad":"fig = px.histogram(df_train, x='gender', y='diabetes_mellitus', width = 500, height = 400)\nfig.update_layout(title='G\u00eanero', yaxis_title='Ocorr\u00eancia de diabetes')\nfig.show()\n\nfig = px.histogram(df_train, x='ethnicity', y='diabetes_mellitus', width = 500, height = 400)\nfig.update_layout(title='Etinia', yaxis_title='Ocorr\u00eancia de diabetes')\nfig.show()\n\nfig = px.histogram(df_train, x='bmi', y='diabetes_mellitus', width = 500, height = 400)\nfig.update_layout(title='\u00cdndice de Massa Corp\u00f3rea', yaxis_title='Ocorr\u00eancia de diabetes')\nfig.show()","ccc54964":"def fill_na(df, numeric_data, categoric_data):\n    \n    for category in categoric_data:\n        if df[category].isna().any():\n            # most frequent\n            df[category] = df[category].fillna(df[category].mode().iloc[0])\n    \n    for numeric in numeric_data:\n        if df[numeric].isna().any():\n            df[numeric] = df[numeric].fillna(df[numeric].median())\n    \n    return df","94db1934":"def normalize(df, num_cols, cat_cols):\n    df = df.drop(['encounter_id', 'hospital_id'], axis=1)\n\n    df['height'] = df['height'].fillna(df['height'].median())\n    df['weight'] = df['weight'].fillna(df['weight'].median())\n\n    median_weight = df['weight'].median()\n    median_height = df['height'].median()\n\n    df['bmi'] = df['bmi'].fillna(median_weight \/ (median_height * median_height))\n\n    df['elective_surgery'] = df['elective_surgery'].astype('category')\n    df['apache_post_operative'] = df['apache_post_operative'].astype('category')\n    df['arf_apache'] = df['arf_apache'].astype('category')\n    df['aids'] = df['aids'].astype('category')\n    df['cirrhosis'] = df['cirrhosis'].astype('category')\n    df['hepatic_failure'] = df['hepatic_failure'].astype('category')\n    df['immunosuppression'] = df['immunosuppression'].astype('category')\n    df['leukemia'] = df['leukemia'].astype('category')\n    df['lymphoma'] = df['lymphoma'].astype('category')\n    df['solid_tumor_with_metastasis'] = df['solid_tumor_with_metastasis'].astype('category') \n    \n    df = fill_na(df, num_cols, cat_cols)\n    \n    return df","1f10c9b3":"def plot_confusion_matrix(y_test, y_pred):\n    fig, ax = plt.subplots(figsize=(5,5))\n    cm = confusion_matrix(y_test, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot(cmap=plt.cm.Blues, ax=ax)\n    plt.title('Matriz de Confus\u00e3o')\n    plt.show()","8664c77d":"numeric_data = df_train.loc[:,'age':'solid_tumor_with_metastasis'].select_dtypes(include=['int64', 'float64']).columns\ncategoric_data = df_train.loc[:,'age':'solid_tumor_with_metastasis'].select_dtypes(include=['object', 'category', 'bool']).columns","eea3fd8d":"df_train = normalize(df_train, numeric_data, categoric_data)","0a0c68f8":"x = df_train.drop(['diabetes_mellitus'], axis=1)\ny = df_train['diabetes_mellitus']\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.3, random_state=42)\n\nprint('Amostras de treino:')\nprint(f' * X_train: {x_train.shape}')\nprint(f' * y_train: {y_train.shape}')\n\nprint('Amostras de teste:')\nprint(f' * X_test: {x_test.shape}')\nprint(f' * y_test: {y_test.shape}')","f377d563":"transformers=[('cat_scale', OneHotEncoder(), categoric_data),\n             ('num_scale', MinMaxScaler(), numeric_data)]\n\npreprocessor = ColumnTransformer(transformers=transformers)","6197904d":"knn_steps = [('preprocessor', preprocessor),\n        ('knn_model', KNeighborsClassifier())]\n\nknn_model = Pipeline(steps=knn_steps, verbose=1)\nknn_model","32160b78":"knn_params = {\n    'knn_model__n_neighbors': np.arange(3,13,2),\n    'knn_model__weights': ['uniform', 'distance'],\n    'knn_model__metric': ['euclidean', 'manhattan']\n}\n\nknn_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)","2b74a70b":"knn_gs = GridSearchCV(knn_model, param_grid=knn_params, cv=knn_cv, scoring='roc_auc', return_train_score=False, n_jobs=4, verbose=3)","65d02644":"knn_steps = [('preprocessor', preprocessor),\n        ('knn_model', KNeighborsClassifier(metric='manhattan', n_neighbors=11, weights='distance'))]\n\nknn_model = Pipeline(steps=knn_steps, verbose=1)\nknn_model","1b90b53c":"# %%time\n# knn_model.fit(x_train, y_train)","a8db422e":"# como o KNN ficou ultimo e por ser o que mais demora, n\u00e3o iremos execut\u00e1-lo\n# %%time\n# knn_rocauc = roc_auc_score(y_test, knn_model.predict_proba(x_test)[:, 1])\n# print(f'KNN ROC-AUC Score: {knn_rocauc}\\n')\n# knn_y_predict = knn_model.predict(x_test)\n\n# print(\"Classification Report: \\n\")\n# print(classification_report(y_test, knn_y_predict))\n# plot_confusion_matrix(y_test, knn_y_predict)","7f046ab9":"from sklearn.impute import KNNImputer\n\nimputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n\n# x_train = imputer.fit_transform(x_train)","d380353b":"mlp_steps = [('preprocessor', preprocessor),\n        ('mlp_model', MLPClassifier(random_state=42))]\n\nmlp_model = Pipeline(steps=mlp_steps, verbose=1)\nmlp_model","a4264370":"mlp_params = {\n    'mlp_model__activation': ['identity', 'logistic','tanh','relu'],\n    'mlp_model__hidden_layer_sizes': [(10,),(50,),(100,),(10,10),(50,50),(100,100)],\n    'mlp_model__solver': ['adam'],\n    'mlp_model__early_stopping': [True]\n}\n\nmlp_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)","c2849ba1":"mlp_gs = GridSearchCV(mlp_model, param_grid=mlp_params, cv=mlp_cv, scoring='roc_auc', return_train_score=False, n_jobs=4, verbose=1)","4cc511a1":"mlp_steps = [('preprocessor', preprocessor),\n        ('mlp_model',  MLPClassifier(activation='tanh', early_stopping=True, hidden_layer_sizes=(100,100),\n                                     solver='adam', random_state=42))]\n\nmlp_model = Pipeline(steps=mlp_steps, verbose=1)\nmlp_model","8ce88729":"%%time\nmlp_model.fit(x_train, y_train)","efeeda99":"%%time\nmlp_rocauc = roc_auc_score(y_test, mlp_model.predict_proba(x_test)[:, 1])\nprint(f'Neural Network ROC-AUC Score: {mlp_rocauc}\\n')\nmlp_y_predict = mlp_model.predict(x_test)\n\nprint(\"Classification Report: \\n\")\nprint(classification_report(y_test, mlp_y_predict))\nplot_confusion_matrix(y_test, mlp_y_predict)","7be0925a":"rf_steps = [('preprocessor', preprocessor),\n        ('rf_model', RandomForestClassifier(random_state=42))]\n\nrf_model = Pipeline(steps=rf_steps, verbose=1)\nrf_model","9d812a54":"rf_params = {\n    'rf_model__n_estimators': [10, 50, 100],\n    'rf_model__criterion': ['gini', 'entropy'],\n    'rf_model__max_depth' : [4,5,6,7,8],\n    'rf_model__class_weight': [None, 'balanced', 'balanced_subsample']\n}\n\n\nrf_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)","5f91b42e":"rf_gs = GridSearchCV(rf_model, param_grid=rf_params, cv=rf_cv, scoring='roc_auc', return_train_score=False)","c63951a6":"rf_steps = [('preprocessor', preprocessor),\n        ('rf_model', RandomForestClassifier(criterion='entropy', random_state=42))]\n\nrf_model = Pipeline(steps=rf_steps, verbose=1)\nrf_model","fe560787":"%%time\nrf_model.fit(x_train, y_train)","af2f2808":"%%time\nrf_rocauc = roc_auc_score(y_test, rf_model.predict_proba(x_test)[:, 1])\nprint(f'Random Forest ROC-AUC Score: {rf_rocauc}\\n')\nrf_y_predict = rf_model.predict(x_test)\n\nprint(\"Classification Report: \\n\")\nprint(classification_report(y_test, rf_y_predict))\nplot_confusion_matrix(y_test, rf_y_predict)","36f0ff3c":"xgb_steps = [('preprocessor', preprocessor),\n        ('xgb_model', xgboost.XGBClassifier(learning_rate =0.01,\n        n_estimators=5000,\n        max_depth=4,\n        min_child_weight=6,\n        gamma=0,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        reg_alpha=0.005,\n        objective= 'binary:logistic',\n        nthread=4,\n        scale_pos_weight=1,\n        random_state=42))]\n\nxgb_model = Pipeline(steps=xgb_steps, verbose=1)\nxgb_model","59fff5ea":"xgb_model.fit(x_train, y_train)","83cdf114":"%%time\nxgb_rocauc = roc_auc_score(y_test, xgb_model.predict_proba(x_test)[:, 1])\nprint(f'XGBoost ROC-AUC Score: {xgb_rocauc}\\n')\nxgb_y_predict = xgb_model.predict(x_test)\n\nprint(\"Classification Report: \\n\")\nprint(classification_report(y_test, xgb_y_predict))\nplot_confusion_matrix(y_test, xgb_y_predict)","0bdff285":"lgb_steps = [('preprocessor', preprocessor),\n        ('lgb_model', LGBMClassifier(\n                        colsample_bytree=0.2,\n                        learning_rate=0.01,\n                        metric='auc',\n                        n_estimators=3000,\n                        objective='binary',\n                        random_state=42,\n                        reg_alpha=3,\n                        reg_lambda=1,\n                        scale_pos_weight=1,\n                        subsample=1))]\n\nlgb_model = Pipeline(steps=lgb_steps, verbose=1)\nlgb_model","0215f577":"%%time\nlgb_model.fit(x_train, y_train)","e05d6404":"%%time\nlgb_rocauc = roc_auc_score(y_test, lgb_model.predict_proba(x_test)[:, 1])\nprint(f'LightGBM ROC-AUC Score: {lgb_rocauc}\\n')\nlgb_y_predict = lgb_model.predict(x_test)\n\nprint(\"Classification Report: \\n\")\nprint(classification_report(y_test, lgb_y_predict))\nplot_confusion_matrix(y_test, lgb_y_predict)","95d69116":"xgb_steps_2 = [('preprocessor', preprocessor),\n        ('xgb_model',  xgboost.XGBClassifier(\n            learning_rate=0.05, max_depth=4,  n_estimators=1000, nthread=4, use_label_encoder=False, random_state=42))]\n\nxgb_model_2 = Pipeline(steps=xgb_steps_2, verbose=1)\nxgb_model_2","85e67792":"lgb_steps_2 = [('preprocessor', preprocessor),\n        ('lgbm_model_2', LGBMClassifier(is_unbalance=True, max_depth=6,\n                                n_estimators=291, num_leaves=16,\n                                objective='binary', random_state=42,\n                                subsample=0.2))]\n\nlgb_model_2 = Pipeline(steps=lgb_steps_2, verbose=1)\nlgb_model_2","93d3f8eb":"lgb_steps_3 = [('preprocessor', preprocessor),\n        ('lgb_model_3', LGBMClassifier(\n                        n_estimators=291,\n                        num_leaves=45,\n                        max_depth=6,\n                        subsample=0.2,\n                        objective='binary',\n                        learning_rate=0.1,\n                        boosting_type='gbdt',\n                        random_state=42,\n))]\n\nlgb_model_3 = Pipeline(steps=lgb_steps_3, verbose=1)\nlgb_model_3","9bcc401b":"soft_voting_model = VotingClassifier(estimators=[('xgb_model', xgb_model),\n                                                 ('xgb_model_2', xgb_model_2),\n                                                 ('lgb_model', lgb_model),\n                                                 ('lgb_model_2', lgb_model_2),\n                                                ('lgb_model_3', lgb_model_3)], \n                                     voting='soft')","21d7db68":"%%time\nsoft_voting_model.fit(x_train, y_train)","d597f61a":"%%time\nsoft_rocauc = roc_auc_score(y_test, soft_voting_model.predict_proba(x_test)[:, 1])\nprint(f'Voting Classifier ROC-AUC Score: {soft_rocauc}\\n')\nsoft_y_predict = soft_voting_model.predict(x_test)\n\nprint(\"Classification Report: \\n\")\nprint(classification_report(y_test, soft_y_predict))\nplot_confusion_matrix(y_test, soft_y_predict)","f1d24574":"knn_rocauc = 0.6888581323557232\nrf_rocauc = 0.8331758809669855\nxgb_rocauc = 0.8658914529816535\nlgb_rocauc = 0.8685743535944752\nmlp_rocauc = 0.8389027730801789\nsoft_rocauc = 0.8671604973658413","e5f9d583":"model_comparison = {\n    'modelos': ['KNN', 'Random Forest', 'XGBoost', 'LightGBM', 'Redes Neurais', 'SoftVoting'],\n    'roc_auc': [knn_rocauc, rf_rocauc, xgb_rocauc, lgb_rocauc, mlp_rocauc, soft_rocauc]\n}","42b58074":"pd.DataFrame(model_comparison).sort_values('roc_auc', ascending=False)","f1c31c3e":"df_test.head()","f75d9f2b":"df_test_final = normalize(df_test, numeric_data, categoric_data)","e70c7bfd":"y_pred_lgb = lgb_model.predict_proba(df_test_final)[:,1]\ndf_sub_lgb = pd.DataFrame({'encounter_id': df_test.encounter_id, 'diabetes_mellitus': y_pred_lgb})\ndf_sub_lgb.to_csv(\"lgbm_submit.csv\", sep=',', index=False)\n\ndf_sub_lgb.head()","245f2c63":"knn_score = 0.70371\nrf_score = 0.84109\nxgb_score = 0.87433\nlgb_score = 0.87687\nmlp_score = 0.85191\nsoft_score = 0.87584","bb59c9fa":"model_comparison = {\n    'modelos': ['KNN', 'Random Forest', 'XGBoost', 'LightGBM', 'Redes Neurais', 'SoftVoting'],\n    'roc_auc': [knn_score, rf_score, xgb_score, lgb_score, mlp_score, soft_score]\n}","a0da9ef5":"pd.DataFrame(model_comparison).sort_values('roc_auc', ascending=False)","99b84df2":"## Cria\u00e7\u00e3o e Treinamento dos Modelos","52d853d1":"#### Melhor Modelo","4d1e33f0":"### Distribui\u00e7\u00e3o por Altura","776be156":"Todos os melhores modelos foram treinados com `x` e ent\u00e3o submetidos para serem avaliados na competi\u00e7\u00e3o. Os seus resultados foram registrados abaixo","1f1bf18a":"### Distribui\u00e7\u00e3o por Idade","22a3f029":"Como podemos visualizar, o resultado final \u00e9 extremamente semelhante ao resultado obtido na avalia\u00e7\u00e3o dos modelos, isto mostra a import\u00e2ncia de avaliarmos os modelos antes de submet\u00ea-los. Novamente a LightGBM apresentou melhor desempenho, seguido do VotingClassifier e o XGBoost.\n\nConclu\u00edmos ent\u00e3o que o LighGBM \u00e9 o modelo mais apropriado para este desafio, devido ao seu alto `score` final.","e42988ef":"Preenchimento de dados faltantes utilizando KNNImputer","6a980c75":"Para o VotingClassifier, utilizamos 2 XGBoost e 3 LightGBM onde todos os cinco modelos alcan\u00e7aram mais de 0.87, e vota\u00e7\u00e3o ser\u00e1 por `soft`. Abaixo temos as inst\u00e2ncias adicionais dos modelos que ser\u00e3o utilizadas","13680aa6":"## Avalia\u00e7\u00e3o dos Modelos","2dc66d6c":"#### Melhor Modelo","7bdae7fd":"### Redes Neurais","95566fea":"Uma vez definida a abordagem, partimos para a implementa\u00e7\u00e3o. Dessa forma, para esta fase de pr\u00e9-processamento constru\u00edmos algumas fun\u00e7\u00f5es auxiliares visando organizar e reaproveitar c\u00f3digo, j\u00e1 que o tratamento \u00e9 necess\u00e1rio tanto no *dataset* de treinamento quanto no *dataset* de testes para os resultados finais.\n\nA fun\u00e7\u00e3o `fill_na` recebe como par\u00e2metro um *DataFrame* e duas listas com os nomes das *features* de tipo num\u00e9rico e categ\u00f3rico. Essa fun\u00e7\u00e3o tem como objetivo fazer o preenchimento dos dados faltantes de uma forma mais estruturada, atrav\u00e9s de chamadas ao m\u00e9todo `fillna` dabilbioteca Pandas. Para os dados categ\u00f3ricos \u00e9 usado o termo mais frequente e para os dados num\u00e9ricos utiliza-se a mediana (devido a distribui\u00e7\u00e3o dos dados).\n\nJ\u00e1 a fun\u00e7\u00e3o `normalize` tem o prop\u00f3sito de encapsular as etapas do pr\u00e9-processamento. Neste momento apenas duas colunas foram julgadas com dados n\u00e3o significativos e descartadas nesta fun\u00e7\u00e3o, e em seguida realizou-se um tratamento espec\u00edfico em algumas *features*, como preencher dados ausentes com base em outra *feature* ou alterar o tipo da vari\u00e1vel. Ao final de sua execu\u00e7\u00e3o, ela retorna um *DataFrame* com os dados pr\u00e9-processados que ser\u00e3o usados posteriormente no processo de aprendizagem com os diversos modelos analisados.\n\nFinalmente, a fun\u00e7\u00e3o `plot_confusion_matrix` \u00e9 utilizada basicamente para plotar uma matriz de confus\u00e3o com os resultados obtidos.","0b15aa2e":"### Diabetes por G\u00eanero, Etinia e BMI","6aba6320":"Para cada modelo escolhido, foi criado um novo notebook para trein\u00e1-lo individualmente e posteriormente integrado neste notebook. Cada modelo passou pelo mesmo processo de:\n* Instanci\u00e1-lo atrav\u00e9s do *pipeline*\n* Levantar um conjunto de hiperpar\u00e2metros\n* Trein\u00e1-lo com GridSearchCV (com StratifiedKFold e m\u00e9trica `roc_auc`)\n* Retreinar o melhor modelo com todo o conjunto de testes\n* Subemeter o `score` resultante\n\nVale ressaltar que come\u00e7amos retreinando com `x_train` e `y_train` mas com os testes observamos que retreinar com `x` e `y` alcan\u00e7ar\u00edamos melhores resultados.","980a0884":"## Predi\u00e7\u00e3o Final com o Dataset de Testes","91bd1942":"#### GridSearchCV","93c87b8b":"### KNN","2fd39046":"Inicialmente testamos com KNN, Random Forest e Naive Bayes onde retreinando com `x_train`, os melhores `scores` obtidos nas submiss\u00f5es desses algoritmos foram 76.90% com Naive Bayes, 76.01% e 50% com KNN. Observamos ent\u00e3o que com os modelos mais tradicionais n\u00e3o estava sendo poss\u00edvel alcan\u00e7ar resultados satisfat\u00f3rios, e em decorr\u00eancia disso resolvemos come\u00e7ar a testar modelos baseados em Gradient Boosting.\n\nRealizamos ent\u00e3o novos testes com XGBoost e LightGBM e conseguimos alcan\u00e7ar mais de 80%, e neste momento, temos o melhor modelo de LightGBM 87.687% e o melhor XGBoost com 87.433%.\n\nA medida que melhoramos o pr\u00e9-processamento de dados, outros modelos tamb\u00e9m conseguiram alcan\u00e7ar mais de 80%, e retreinando com `x` tivemos uma pequena melhora em todos os modelos.\n\nPor fim, treinamos um ensemble dos modelos acima de 0.87 com VotingClassifier para tentar alcan\u00e7ar resultados ainda maiores, obtendo-se um `score` final de 87.584%\n","bc7aaeca":"Neste notebook ser\u00e1 mostrado como geramos o `GridSearchCV` mas o treinamento e resultados ser\u00e1 somente do melhor modelo obtido.","05abf145":"### XGBoost","c874e14e":"Para o *dataset* de teste foi utilizado o mesmo pr\u00e9-processamento do *dataset* de treinamento","32c0bf84":"## Explora\u00e7\u00e3o dos Dados","226d03a2":"#### KNNImputer","d88407d3":"Abordagem\n\nAp\u00f3s analisar e realizar a explora\u00e7\u00e3o dos dados, percebemos que muitas colunas possuiam baixa correla\u00e7\u00e3o com a nossa vari\u00e1vel algo (`diabetes_mellitus`), ent\u00e3o a primeira abordagem foi remover essas colunas e diminuir a quantidade de features. Em seguida, devido ao fato do *dataset* conter muitas amostras, buscamos remover todos os registros com valores nulos para limpar os dados. Observamos que estas duas abordagens **n\u00e3o funcionaram**.\n\nDurante os testes observamos que estas abordagens estavam diminuindo o `score` final dos modelos, e por consequ\u00eancia optamos por manter todas as colunas com dados significativos, mesmo com baixa correla\u00e7\u00e3o e al\u00e9m disso, decidimos preencher todos os dados ausentes no *dataset* para n\u00e3o perder nenhuma informa\u00e7\u00e3o \u00fatil para o modelo.","ffd7a2f1":"Uma segunda fase de pre-processamento ocorre no momento de criar e treinar os modelos atrav\u00e9s do m\u00e9todo de `pipeline`. Nesta fase fazemos uso de dois m\u00e9todos pre-existentes no biblioteca `scikit-learn`. O primeiro \u00e9 `OneHotEncoder`, utilizado para transformar dados categ\u00f3ricos e features que possam ser compreendidas pelos algoritmos de aprendizagem. O segundo m\u00e9todo \u00e9 a normaliza\u00e7\u00e3o das features num\u00e9ricas atrav\u00e9s do `MinMaxScaler`, que transforma os dados num\u00e9ricos em um intervalo num\u00e9rico que vai de 0 a 1. A escolha destes dois m\u00e9todos foi fundamentada com base nos resultados dos testes obtidos com todos os modelos analisados.","84f8b88d":"### Ajustes na Configura\u00e7\u00e3o","628b3d06":"## Pr\u00e9-Processamento do Dataset de Testes","b87a2031":"#### Melhor Modelo","1756571a":"### Distribui\u00e7\u00e3o por \u00cdndice de Massa Corp\u00f3rea (IMC\/BMI)","7fb4075c":"### Prepara\u00e7\u00e3o para dados de treino e avalia\u00e7\u00e3o","489e0f10":"#### Melhor Modelo","2342cee6":"### Importa\u00e7\u00e3o do dataset","60754fdd":"## Importa\u00e7\u00e3o de Bibliotecas","7ecef65e":"### Distribui\u00e7\u00e3o por Peso","d0a75f7a":"### Voting Classifier","34248f2c":"## Melhor Modelo no Conjunto de Testes","4c89d6bc":"Observamos que os modelos que utilizam Gradient Boosting obtiveram resultados melhores na etapa de avalia\u00e7\u00e3o. Embora o SoftVoting contenha o LightGBM, sua performance foi um menor que o modelo sozinho, devido a presen\u00e7a de outros modelos.","0133e7ef":"### Random Forest","0cde1adb":"Embora o desafio j\u00e1 disponibilize um *dataset* de teste, \u00e9 importante tamb\u00e9m avaliarmos os nossos modelos antes de submet\u00ea-los ao Kaggle, para assim entendermos seu comportamento e alterar seus hiperpar\u00e2metros caso necess\u00e1rio. Assim, o *dataset* de treino foi dividido em dois, onde 30% ser\u00e1 utilizado para \"teste\", que \u00e9 justamente a avalia\u00e7\u00e3o. A divis\u00e3o foi estratificada para termos um conjunto significativo das duas classes.","95365d26":"## Pr\u00e9-Processamento dos Dados","e9d9dc63":"### LightGBM","31dd4be8":"# Machine Learning Aplicado I - Trabalho Final\n\n**Alunos**:\n\n* Andrea Monicque dos Santos Silva (amdss.cid20@uea.edu.br)\n* Francisco Marcelo Mendes Damasceno (fmmd.cid20@uea.edu.br)\n* Lucas Pereira Reis (lpr.cid20@uea.edu.br)\n* Marcos Wenneton Ara\u00fajo (mwvda.cid20@uea.edu.br)","9500b43a":"#### GridSearchCV","4ca6cfb4":"#### Melhor Modelo","f24c755d":"### Porcentagem de Pacientes com diabetes no dataset de Treino","4603c1e9":"Cada um dos melhores modelos foram treinados com `x_train` e `y_train` e avaliados com `x_test`, o conjunto de avalia\u00e7\u00e3o que corresponde \u00e0 30% do *dataset* de treinamento. Esta etapa foi necess\u00e1rio para termos uma estimativa do comportamento do modelo e ter uma ideia de como ser\u00e1 o `score` final no *dataset* de teste. Ap\u00f3s avaliar o modelo, este ser\u00e1 retreinado com `x` para ent\u00e3o ser submetido.\n\nOs valores foram calculados previamente para evitar a necessidade de executar todo o notebook e inseridos logo abaixo"}}