{"cell_type":{"eee88d51":"code","c0784784":"code","194d578e":"code","df336965":"code","3fb9ae4d":"code","03df610a":"code","cee2e4a1":"code","7896aab2":"code","9ae05e02":"code","86978656":"code","c59a2f80":"code","3b958a89":"code","01d22c68":"code","f61bb52a":"code","24d42067":"code","1be4a04a":"code","d9abfb92":"code","75e54b16":"code","61a757da":"code","a37e67ee":"code","8ed4d4e6":"code","61ee0521":"code","5b3a28cb":"code","2ca99957":"code","c000889d":"code","c2060feb":"code","64c79641":"code","34d53e76":"code","dadc5c81":"code","c9e3f6e6":"code","55dca0fe":"code","dbcf9231":"code","abc9a316":"code","17a6a444":"code","2fdca96f":"code","0d7e1acd":"code","af79538b":"code","42113ac1":"code","44b13e9e":"code","34b07dab":"code","94b6c5e7":"code","c1520f8e":"code","f977ea75":"code","34d4c43a":"code","71921543":"code","3e7980bf":"code","452578f7":"code","877d2f97":"code","55758bbb":"code","d5d3ed05":"code","69d8295a":"code","a378a4b0":"code","a909d17f":"code","c6c36a86":"markdown"},"source":{"eee88d51":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os","c0784784":"import json","194d578e":"f = open('\/kaggle\/input\/coleridgeinitiative-show-us-the-data\/train\/0007f880-0a9b-492d-9a58-76eb0b0e0bd7.json')","df336965":"loaded = json.load(f)","3fb9ae4d":"f.close()","03df610a":"loaded[0]","cee2e4a1":"import nltk","7896aab2":"tagged_corpus = []\nfor i in range(20):\n    sentences = loaded[i]['text']\n    words  = nltk.word_tokenize(sentences)\n    tagged_corpus.append(nltk.tag.pos_tag(words))","9ae05e02":"len(tagged_corpus)","86978656":"sentences = []\nfor section in tagged_corpus:\n    sentence = []\n    for key in section:\n        if key[0] != '.':\n            sentence.append(key)\n        else:\n            sentences.append(sentence)\n            sentence = []","c59a2f80":"for x in loaded:\n    print(x['section_title'])","3b958a89":"corp = nltk.corpus.brown.tagged_sents(categories='adventure')[:500]","01d22c68":"from nltk.util import unique_list","f61bb52a":"tag_list = unique_list(tag for sent in sentences for (word, tag) in sent)","24d42067":"syms = unique_list(word for sent in sentences for (word, tag) in sent)","1be4a04a":"print(len(syms))","d9abfb92":"print(len(tag_list))","75e54b16":"trainer = nltk.HiddenMarkovModelTrainer(tag_list, syms)","61a757da":"from sklearn.model_selection import train_test_split","a37e67ee":"len(sentences)","8ed4d4e6":"x_train, x_val, y_train, y_val = train_test_split(sentences, range(150), test_size=0.1, shuffle=True, random_state=42)","61ee0521":"def train_and_test(est):\n    hmm = trainer.train_supervised(x_train, estimator=est)\n    print(\"%.2f\"%(100 * hmm.evaluate(x_val)))","5b3a28cb":"trigrams = list(nltk.ngrams(words,n=3))","2ca99957":"tokenized =  nltk.tokenize.sent_tokenize(loaded[0]['text'])","c000889d":"from nltk.sentiment.vader import SentimentIntensityAnalyzer","c2060feb":"sid = SentimentIntensityAnalyzer()","64c79641":"docs = {}","34d53e76":"from glob import glob","dadc5c81":"all_docs = {}","c9e3f6e6":"i = 0","55dca0fe":"sums = 0","dbcf9231":"for i in all_docs:\n    sums+=(all_docs[i][0]['section_title'] == 'Abstract')","abc9a316":"len(all_docs)","17a6a444":"sums","2fdca96f":"for file in glob('\/kaggle\/input\/coleridgeinitiative-show-us-the-data\/train\/*.json'):\n#     print(file)\n    f = open(file)\n    all_docs[\"doc-\"+str(i)] = json.load(f)\n    f.close()\n    i+=1","0d7e1acd":"docs = {}\ni = 0","af79538b":"for doc in  all_docs:\n    sents = all_docs[doc][0]['text']\n    tokenized = nltk.tokenize.sent_tokenize(sents)\n    add = {\"compound\":0.0, \"neg\":0.0, \"neu\":0.0, \"pos\":0.0}\n    for sent in tokenized:\n        ss = sid.polarity_scores(sent)\n        for so in sorted(ss):\n            add[so]+=ss[so]\n    for s in add:\n        if len(tokenized):\n            add[s]\/=len(tokenized)\n    docs[i] = add\n    i+=1","42113ac1":"negs = []\nposis = []\nneus = []\ncompounds  = []\nfor key in docs:\n    compounds.append(docs[key]['compound'])\n    negs.append(docs[key]['neg'])\n    posis.append(docs[key]['pos'])\n    neus.append(docs[key]['neu'])","44b13e9e":"import matplotlib.pyplot as plt","34b07dab":"from scipy.interpolate import interp1d","94b6c5e7":"def interpolate(compounds):\n    # Define x, y, and xnew to resample at.\n    x = np.array(range(len(compounds)))\n    y = np.array(compounds)\n    xnew = np.linspace(0, len(compounds) - 1, 100)\n\n    # Define interpolators.\n    f_linear = interp1d(x, y)\n    f_cubic = interp1d(x, y, kind='cubic')\n\n    # Plot.\n    plt.plot(x, y, 'o', label='data')\n    # plt.plot(xnew, f_linear(xnew), '-', label='linear')\n    plt.plot(xnew, f_cubic(xnew), '-', label='cubic')\n    plt.legend(loc='best')\n    plt.show()","c1520f8e":"interpolate(compounds)","f977ea75":"interpolate(negs)","34d4c43a":"interpolate(neus)","71921543":"interpolate(posis)","3e7980bf":"def mad_based_outlier(points, thresh=3.5):\n    points = np.array(points)\n    if len(points.shape) == 1:\n        points = points[:,None]\n    median = np.median(points, axis=0)\n    diff = np.sum((points - median)**2, axis=-1)\n    diff = np.sqrt(diff)\n    med_abs_deviation = np.median(diff)\n\n    modified_z_score = 0.6745 * diff \/ med_abs_deviation\n\n    return modified_z_score > thresh","452578f7":"indexes = mad_based_outlier(compounds)","877d2f97":"compounds_outliers = []\nnegatives_outliers = []\npositives_outliers = []\nneutrals_outliers = []","55758bbb":"for i in range(len(indexes)):\n    if indexes[i]:\n        compounds_outliers.append(i)","d5d3ed05":"indexes_2 = mad_based_outlier(negs)\nfor j in range(len(indexes_2)):\n    if indexes_2[j]:\n        negatives_outliers.append(j)","69d8295a":"indexes = mad_based_outlier(posis)\nfor j in range(len(indexes)):\n    if indexes[j]:\n        positives_outliers.append(j)","a378a4b0":"indexes_2 = mad_based_outlier(neus)\nfor j in range(len(indexes_2)):\n    if indexes_2[j]:\n        neutrals_outliers.append(j)","a909d17f":"def intersection(first, *others):\n    return set(first).intersection(*others)","c6c36a86":"# Sentiments for Abstract\/Introduction\/etc\n* Generally compounds means they cannot be properly identified and are tricky\n* Negs--> negative, Posis-->Positives\n* Neus --> Neutrals"}}