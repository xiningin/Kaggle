{"cell_type":{"0677947d":"code","fdb5723c":"code","79fc4222":"code","6495afd8":"code","cbcc6cea":"code","0d021ea9":"code","53e42fcb":"code","3ab4f5c9":"code","2d6d8aab":"code","aeaa6ba2":"code","0aaf1424":"code","6e268814":"code","199ffcb5":"code","c01077e2":"code","59398590":"code","a44503fe":"markdown","4ae61d13":"markdown","c92581b2":"markdown","e8f57c3d":"markdown","6d0178f5":"markdown"},"source":{"0677947d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fdb5723c":"import tensorflow","79fc4222":"ozellik_cikaran_model = tensorflow.keras.applications.VGG16(\n    weights = \"imagenet\",\n    include_top = False,\n    input_shape = (224,224,3)\n)","6495afd8":"ozellik_cikaran_model.summary()","cbcc6cea":"set_trainable = False\nozellik_cikaran_model.trainable = True\n\nfor layer in ozellik_cikaran_model.layers:\n    if layer.name == \"block5_conv1\":\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = set_trainable\n    else:\n        layer.trainable = set_trainable","0d021ea9":"model = tensorflow.keras.Sequential()\n\n# modelimizin ilk a\u015famas\u0131na yukar\u0131da tan\u0131mlad\u0131\u011f\u0131m\u0131z k\u00fc\u00e7\u00fck modeli ekliyoruz.\nmodel.add(ozellik_cikaran_model)   # bo\u015f olan modelimize ilk \u00f6nce yukar\u0131da tan\u0131mlad\u0131\u011f\u0131m\u0131z VGG16 b\u00fct\u00fcnle\u015fmi\u015f modelini ekliyoruz.\n\n# modeli d\u00fcz bir vekt\u00f6r yap\u0131yoruz.\nmodel.add(tensorflow.keras.layers.Flatten())  # ekledi\u011fimiz modeli d\u00fcz bir vekt\u00f6r olacak \u015fekilde uzat\u0131yoruz.\n\nmodel.add(tensorflow.keras.layers.Dense(256, activation=\"relu\"))\n# en son 2 adet s\u0131n\u0131f ay\u0131rmas\u0131n\u0131 istiyoruz.\nmodel.add(tensorflow.keras.layers.Dense(38,activation= \"softmax\"))   # 38 s\u0131n\u0131f\u0131 ay\u0131rt etmek istedi\u011fimiz i\u00e7in \u00e7\u0131k\u0131\u015f katman\u0131n\u0131 38 n\u00f6ron olarak ayarl\u0131yoruz.\n\n# olu\u015fturdu\u011fumuz modeli derliyoruz ve en son i\u015flem olarak kap\u0131y\u0131 kapatmm\u0131\u015f oluyoruz.\nmodel.compile(loss = \"binary_crossentropy\",\n              optimizer = tensorflow.keras.optimizers.RMSprop(learning_rate= 1e-5),\n              metrics = [\"acc\"])\n","53e42fcb":"model.summary()","3ab4f5c9":"egitim_yolu = \"..\/input\/new-plant-diseases-dataset\/New Plant Diseases Dataset(Augmented)\/New Plant Diseases Dataset(Augmented)\/train\"\ngecerleme_yolu = \"..\/input\/new-plant-diseases-dataset\/New Plant Diseases Dataset(Augmented)\/New Plant Diseases Dataset(Augmented)\/valid\"\ntest_yolu = \"..\/input\/new-plant-diseases-dataset\/test\"\n","2d6d8aab":"# veri kayna\u011f\u0131 i\u00e7in ne i\u015flemler yapmas\u0131 gerekti\u011fini s\u00f6ylememiz gerekiyor.\n# sadece e\u011fitilen verilerde veri art\u0131m\u0131 yap\u0131lm\u0131\u015ft\u0131r.\ntrain_datagen = tensorflow.keras.preprocessing.image.ImageDataGenerator(\n    rescale = 1.\/255,   # piksel de\u011ferleini 0-255 aras\u0131ndan 0-1 aras\u0131na al\u0131yoruz.\n    rotation_range = 40,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    horizontal_flip = True,\n    fill_mode = \"nearest\"\n) \n\ntrain_generator = train_datagen.flow_from_directory(\n    egitim_yolu,\n    target_size = (224,224),\n    batch_size = 16\n)\n\nvalidation_datagen = tensorflow.keras.preprocessing.image.ImageDataGenerator(\n    rescale = 1.\/255\n)\n\nvalidation_generator = validation_datagen.flow_from_directory(\n    gecerleme_yolu,\n    target_size = (224,224),\n    batch_size = 16\n)\n\ntest_datagen = tensorflow.keras.preprocessing.image.ImageDataGenerator(\n    rescale = 1.\/255\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_yolu,\n    target_size = (224,224),\n    batch_size = 16\n)","aeaa6ba2":"egitim = model.fit_generator(\n    train_generator,\n    steps_per_epoch = 200,\n    epochs = 35,\n    validation_data = validation_generator,\n    validation_steps = 5\n)","0aaf1424":"test_loss,test_acc = model.evaluate_generator(validation_generator, steps = 50)\nprint(\"test acc: \",   test_acc)","6e268814":"import numpy as np\nfrom keras_preprocessing import image\ntest_image = image.load_img(\"..\/input\/new-plant-diseases-dataset\/test\/test\/AppleCedarRust2.JPG\",target_size = (224,224))\ntest_image = image.img_to_array(test_image)\ntest_image = np.expand_dims(test_image,axis = 0)","199ffcb5":"model.predict(test_image)","c01077e2":"np.argmax(model.predict_generator(test_image))","59398590":"model.save(\"crop_diseases_recommendation.h5\")","a44503fe":"Yukar\u0131daki model i\u00e7in block5_conv1 katman\u0131ndan sonra e\u011fitim i\u015flemine ba\u015flayaca\u011f\u0131m\u0131z\u0131 yani bu katmana gelene VGG16 n\u0131n kendi weights de\u011ferlerini kullanmas\u0131n\u0131 s\u00f6yl\u00fcyoruz.","4ae61d13":"Tensorflowun VGG16 modeli i\u00e7inde convol\u00fcsyonel katman ve maxpooling katman\u0131 bulunduran toplu bir \nmodeldir.","c92581b2":"# Testing","e8f57c3d":"Keras'ta fit() ve predict() kullanmak belle\u011fe y\u00fcklenebilen daha k\u00fc\u00e7\u00fck veri k\u00fcmeleri i\u00e7in uygundur. Ancak pratikte, \u00e7o\u011fu pratik kullan\u0131m \u00f6rne\u011finde, neredeyse t\u00fcm veri k\u00fcmeleri b\u00fcy\u00fckt\u00fcr ve ayn\u0131 anda belle\u011fe y\u00fcklenemez.\n\n\u00c7\u00f6z\u00fcm, fit_generator() ve predict_generator() e\u011fitim veya tahmin s\u0131ras\u0131nda g\u00f6r\u00fcnt\u00fcleri belle\u011fe y\u00fckleyebilen \u00f6zel veri olu\u015fturucu i\u015flevleriyle kullanmakt\u0131r. Bunlar\u0131 kendimiz yazabiliriz, ancak Keras'taki ImageDataGenerator() flow() veya flow_from_directory()kullanarak olu\u015fturabilece\u011fimiz b\u00f6yle bir jenerat\u00f6r sa\u011flar. \u00c7o\u011fu derin \u00f6\u011frenme modeli muhtemelen Zaten ImageDataGenerator() kullan\u0131l\u0131r ve ger\u00e7ekten harika bir \u00e7\u00f6z\u00fcmd\u00fcr.","6d0178f5":"# Saving"}}