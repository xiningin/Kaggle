{"cell_type":{"2d8fdb77":"code","4399df52":"code","d9878fe5":"code","4b010c9b":"code","6415b287":"code","3c3de6d0":"code","86d6e5a2":"code","39340e4d":"code","e7ead3f0":"code","96531808":"code","593ff1cf":"code","c25bf146":"code","dbba4d2f":"code","ae87fa25":"code","821c6142":"code","0d11ff85":"code","dc0ad250":"code","6c8c101a":"code","a430d4fa":"code","9926aefc":"code","20d92f6c":"code","b5eb23dc":"code","8a7f4c51":"code","125bced4":"code","2e7bfb55":"code","c7ef6679":"code","8c0c870c":"code","e35d953b":"code","766882dc":"code","e733f416":"code","058c6168":"code","d4fc6841":"markdown","372c2f8f":"markdown","e43e9b32":"markdown","47807745":"markdown","3eafb625":"markdown","e75a1a71":"markdown","28112176":"markdown","ad9279e2":"markdown","7a1cfb20":"markdown","96d6a79d":"markdown","8626cbfd":"markdown"},"source":{"2d8fdb77":"\n# importing libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\n\nimport random\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.metrics import roc_auc_score as rauc\n","4399df52":"train = pd.read_csv('..\/input\/cat-in-the-dat-ii\/train.csv') \ntest = pd.read_csv('..\/input\/cat-in-the-dat-ii\/test.csv')","d9878fe5":"# get test id for later in submit file\ntest_id = test.id\n","4b010c9b":"del train['id']\ndel test['id']","6415b287":"target = train['target']\ndel train['target']\n","3c3de6d0":"all_data = pd.concat([train, test], axis = 0).copy()","86d6e5a2":"plt.figure(figsize=(5,3))\nplt.hist(all_data.bin_0);","39340e4d":"plt.figure(figsize=(5,3))\nplt.hist(all_data.bin_1);","e7ead3f0":"plt.figure(figsize=(5,3))\nplt.hist(all_data.bin_2);","96531808":"# replacing the nans\nfill_bin_cols_nan = ['bin_0', 'bin_1', 'bin_2']\nall_data[fill_bin_cols_nan] = all_data[fill_bin_cols_nan].fillna(0)","593ff1cf":"# these string types\nfill_nom_cols1_nan = ['nom_0','nom_1', 'nom_2', 'nom_3', 'nom_4', 'bin_3', 'bin_4']\nall_data[fill_nom_cols1_nan] = all_data[fill_nom_cols1_nan].fillna('NAN')","c25bf146":"plt.figure(figsize=(5,2))\nplt.hist(all_data.ord_0);","dbba4d2f":"plt.figure(figsize=(5,2))\nplt.hist(all_data.day, bins=20);","ae87fa25":"plt.figure(figsize=(5,2))\nplt.hist(all_data.month, bins=40);","821c6142":"all_data['ord_0'] = all_data.ord_0.fillna(1)\nall_data['day'] = all_data.day.fillna(3)\nall_data['month'] = all_data.month.fillna(8)\n# fill all other nans with 'ffffffffff'\ncolumns_to_encode = [ 'ord_1', 'ord_2','ord_3' , 'ord_4', 'ord_5','bin_3', 'bin_4', \n                     'nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4',\n                    'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']\nall_data[columns_to_encode] = all_data[columns_to_encode].fillna('fffffffff')","0d11ff85":"all_data.bin_3.unique()","dc0ad250":"# label encoding\ncolumns_to_encode = [ 'ord_1', 'ord_2','ord_3' , 'ord_4', 'ord_5','bin_3', 'bin_4', \n                     'nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4']\n\nencoder = LabelEncoder()\nfor col in columns_to_encode:\n    print(col)\n    all_data[col][:len(train)] = encoder.fit_transform(all_data[col][:len(train)])\n    all_data[col][len(train):] = all_data[col][len(train):].map(lambda s: '<unknown>' if s not in encoder.classes_ else s)\n    encoder.classes_ = np.append(encoder.classes_, '<unknown>')\n    all_data[col][len(train):] = encoder.transform(all_data[col][len(train):])\n","6c8c101a":"nom_label_array = np.zeros([len(all_data), len(all_data.nom_5.values[0])])\n\nfor step in range(nom_label_array.shape[1]):\n    row=0\n    for item in all_data.nom_5.values :\n        #print(item)\n        #print(int(item[0]  ,16))\n        nom_label_array[row][step]= int(item[step]  ,16)\n        row +=1\n\nfor step in range(nom_label_array.shape[1]):        \n    col_name = 'nom_5_' + str(step)\n    all_data[col_name] = nom_label_array[:,step]","a430d4fa":"# nom_6\nfor step in range(nom_label_array.shape[1]):\n    row=0\n    for item in all_data.nom_6.values :\n        nom_label_array[row][step]= int(item[step]  ,16)\n        row +=1\n\nfor step in range(nom_label_array.shape[1]):        \n    col_name = 'nom_6_' + str(step)\n    all_data[col_name] = nom_label_array[:,step]\n\n# nom_7\nfor step in range(nom_label_array.shape[1]):\n    row=0\n    for item in all_data.nom_7.values :\n        nom_label_array[row][step]= int(item[step]  ,16)\n        row +=1\n\nfor step in range(nom_label_array.shape[1]):        \n    col_name = 'nom_7_' + str(step)\n    all_data[col_name] = nom_label_array[:,step]\n\n# nom_8\nfor step in range(nom_label_array.shape[1]):\n    row=0\n    for item in all_data.nom_8.values :\n        nom_label_array[row][step]= int(item[step]  ,16)\n        row +=1\n\nfor step in range(nom_label_array.shape[1]):        \n    col_name = 'nom_8_' + str(step)\n    all_data[col_name] = nom_label_array[:,step]\n\n# nom_9\nfor step in range(nom_label_array.shape[1]):\n    row=0\n    for item in all_data.nom_9.values :\n        nom_label_array[row][step]= int(item[step]  ,16)\n        row +=1\n\nfor step in range(nom_label_array.shape[1]):        \n    col_name = 'nom_9_' + str(step)\n    all_data[col_name] = nom_label_array[:,step]","9926aefc":"all_data.head(10).T","20d92f6c":"# drop the nominal features 5 to 9","b5eb23dc":"all_data = all_data.drop(['nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9'], axis='columns')","8a7f4c51":"all_data.columns","125bced4":"all_data.shape","2e7bfb55":"from numpy.random import seed\nseed(1) # for reproducability\nimport tensorflow\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.models import Sequential\nall_data_input = np.asarray(all_data)\nmodel_embed = Sequential()\nmodel_embed.add(Embedding(500, 14, ))\nmodel_embed.compile('rmsprop', 'mse')\noutput_data = model_embed.predict(all_data_input)\noutput_data.shape","c7ef6679":"embedded_all_data = output_data.reshape(output_data.shape[0], output_data.shape[1]*output_data.shape[2])\nprint(embedded_all_data.shape)\ntrain = embedded_all_data[:len(train)]\ntest = embedded_all_data[len(train):]\nX_train, X_valid, y_train, y_valid = train_test_split(train, target, test_size=0.2, random_state=1)","8c0c870c":"\neval_dataset = Pool(X_valid, y_valid)\nmodel2 = CatBoostClassifier(iterations=1000 ,random_state=2, verbose=0,eval_metric='Accuracy', \n                            learning_rate=0.1, task_type='GPU'  )\n                           \nhistory = model2.fit(X_train, y_train, eval_set=eval_dataset,\n                     use_best_model=True, verbose=False, plot=True)\n","e35d953b":"predictions_proba_for_valid = model2.predict_proba(X_valid)\n#print(predictions_proba.shape)\npred_proba = predictions_proba_for_valid[:,1]\n#print(pred_proba.shape)\nR_AUC_valid = rauc(y_valid, pred_proba)\nprint('Area under the ROC curve between target and predictions_proba %.5f' % R_AUC_valid)","766882dc":"plt.hist(y_valid, bins=4, density=True, label='y_valid', align='left')\nplt.hist(model2.predict(X_valid), bins=4, density=True, label='predicted', align='right')\nplt.legend()\nplt.show()","e733f416":"# training on all train data\n\nmodel2 = CatBoostClassifier(iterations=800 ,random_state=2, verbose=0,eval_metric='Accuracy', \n                            learning_rate=0.1, task_type='GPU')\n                           \nhistory = model2.fit(X_train, y_train, verbose=False, plot=False)","058c6168":"predictions_proba_test = model2.predict_proba(test)[:,1]\n\n\nfilename = 'submission.csv'\npd.DataFrame({'id': test_id, \n              'target': predictions_proba_test}).to_csv(filename , index=False)","d4fc6841":"The nominals 5 to 9 have some kind of hexadecimal code. We kan make extra features from each hex digit","372c2f8f":"1 has highes frequency","e43e9b32":"idemn for bin_1","47807745":"0 has highest incidence we will replace then nans with 0","3eafb625":"day 3 has highest frequency","e75a1a71":"also for bin_2","28112176":"Using Keras Embedding to do more label encoding and create more features","ad9279e2":"# Label encoding\n","7a1cfb20":"Month 8 has the majority","96d6a79d":"It shows that predicted values have not the best balance","8626cbfd":"This notebook uses Embedding to make more features.\nI am not a pro programmer as you can see but I am still learning. "}}