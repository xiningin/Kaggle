{"cell_type":{"9e353fc1":"code","28173120":"code","f4e9ecc0":"code","96e33b11":"code","8eccae02":"code","b5ca0ee0":"code","1e2e4699":"code","521bdef6":"code","fa246930":"code","7a2c6af9":"code","91aedfb3":"code","e7014994":"code","296f4f96":"code","a028b098":"code","9aeeea90":"code","b28d51f0":"code","fff2d616":"code","c8686690":"code","e16fd1d6":"code","0a3fd041":"code","c7c8eb65":"code","1e5abbf7":"code","e6c6a16f":"code","8f6d4c3c":"code","d0f10c7e":"code","5687f8b1":"code","2e4d357b":"code","329a4f82":"code","59d031e6":"code","16c03524":"code","c8934c89":"code","4ed6ade4":"code","a27d68ae":"code","73177a6c":"code","c4430690":"code","7ee7e55c":"code","450649da":"code","0a2caeff":"code","59dd5faf":"code","9fcec549":"code","16420010":"code","af232c22":"code","7e91e45d":"code","479e52b2":"code","b74e069d":"code","0e4b8ef2":"code","3b1bec18":"code","58879962":"code","e62ea626":"code","62d1c61b":"code","0a9aa71b":"code","5cd673da":"code","ca071c2d":"code","9a195bbf":"code","e5e984fa":"code","de565437":"code","ae17127d":"code","2ef3324a":"code","53af44ac":"code","132d1263":"code","2f401443":"code","7c34f8a0":"markdown","4bc8f344":"markdown","4871d073":"markdown","765ecd93":"markdown","289d1e25":"markdown","373e803b":"markdown","b569c0ae":"markdown"},"source":{"9e353fc1":"from datetime import datetime\nfrom time import time\n\nimport seaborn as sns\nimport numpy as np\nimport pandas as opd\nimport cv2\n\nfrom tqdm import tqdm\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.lines import Line2D\n\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly as py\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\n\ninit_notebook_mode(connected=True)\n\nimport warnings\nimport fastai\nfrom fastai.vision import *\nfrom fastai.callbacks import *\nfrom fastai.callbacks.hooks import *\nfrom fastai.utils.mem import *","28173120":"from fastai.utils.show_install import show_install; show_install()","f4e9ecc0":"!nvidia-smi","96e33b11":"def fmt_now():\n    return datetime.today().strftime('%Y%m%d-%H%M%S')","8eccae02":"sigmoid = lambda x: 1 \/ (1 + np.exp(-x))\n\n\ndef post_process(probability, threshold, min_size):\n    \"\"\"\n    Post processing of each predicted mask, components with lesser number of pixels\n    than `min_size` are ignored\n    \"\"\"\n    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n    predictions = np.zeros(final_size, np.float32)\n    num = 0\n    for c in range(1, num_component):\n        p = (component == c)\n        if p.sum() > min_size:\n            predictions[p] = 1\n            num += 1\n    return predictions, num\n\ndef dice(img1, img2):\n    img1 = np.asarray(img1).astype(np.bool)\n    img2 = np.asarray(img2).astype(np.bool)\n\n    intersection = np.logical_and(img1, img2)\n\n    return 2. * intersection.sum() \/ (img1.sum() + img2.sum())","b5ca0ee0":"class MultiLabelSegmentationLabelList(SegmentationLabelList):\n    \"\"\"Return a single image segment with all classes\"\"\"\n    # adapted from https:\/\/forums.fast.ai\/t\/how-to-load-multiple-classes-of-rle-strings-from-csv-severstal-steel-competition\/51445\/2\n    \n    def __init__(self, items:Iterator, src_img_size=None, classes:Collection=None, **kwargs):\n        super().__init__(items=items, classes=classes, **kwargs)\n        self.loss_func = bce_logits_floatify\n        self.src_img_size = src_img_size\n        # add attributes to copy by new() \n        self.copy_new += [\"src_img_size\"]\n    \n    def open(self, rles):        \n        # load mask at full resolution\n        masks = torch.zeros((len(self.classes), *self.src_img_size)) # shape CxHxW\n        for i, rle in enumerate(rles):\n            if isinstance(rle, str):  # filter out NaNs\n                masks[i] = rle_to_mask(rle, self.src_img_size)\n        return MultiLabelImageSegment(masks)\n    \n    def analyze_pred(self, pred, thresh:float=0.0):\n        # binarize masks\n        return (pred > thresh).float()\n    \n    \n    def reconstruct(self, t:Tensor): \n        return MultiLabelImageSegment(t)","1e2e4699":"            \ndef visualize_with_raw(image, mask, original_image=None, original_mask=None, raw_image=None, raw_mask=None):\n    \"\"\"\n    Plot image and masks.\n    If two pairs of images and masks are passes, show both.\n    \"\"\"\n    fontsize = 14\n    class_dict = {0: 'Fish', 1: 'Flower', 2: 'Gravel', 3: 'Sugar'}\n\n    f, ax = plt.subplots(3, 5, figsize=(24, 12))\n\n    ax[0, 0].imshow(original_image)\n    ax[0, 0].set_title('Original image', fontsize=fontsize)\n\n    for i in range(4):\n        ax[0, i + 1].imshow(original_mask[:, :, i])\n        ax[0, i + 1].set_title(f'Original mask {class_dict[i]}', fontsize=fontsize)\n\n\n    ax[1, 0].imshow(raw_image)\n    ax[1, 0].set_title('Original image', fontsize=fontsize)\n\n    for i in range(4):\n        ax[1, i + 1].imshow(raw_mask[:, :, i])\n        ax[1, i + 1].set_title(f'Raw predicted mask {class_dict[i]}', fontsize=fontsize)\n        \n    ax[2, 0].imshow(image)\n    ax[2, 0].set_title('Transformed image', fontsize=fontsize)\n\n\n    for i in range(4):\n        ax[2, i + 1].imshow(mask[:, :, i])\n        ax[2, i + 1].set_title(f'Predicted mask with processing {class_dict[i]}', fontsize=fontsize)\n            ","521bdef6":"path = Path('..\/input\/understanding_cloud_organization\/')\npath.ls()","fa246930":"path_img = path\/'train_images'\n\nfnames_train = get_image_files(path_img)\nfor f in fnames_train[:3]:\n    print(f)\nprint('\\nTotal number of training images: {}'.format(len(fnames_train)))","7a2c6af9":"path_test = path\/'test_images'\n\nfnames_test = get_image_files(path_test)\nfor f in fnames_test[:3]:\n    print(f)\nprint('\\nTotal number of test images: {}'.format(len(fnames_test)))","91aedfb3":"img_f = fnames_train[2]\nimg = open_image(img_f)\nimg.show(figsize=(10, 10))","e7014994":"def split_img_label(img_lbl):\n    \"\"\"Return image and label from filename \"\"\"\n    s = img_lbl.split(\"_\")\n    assert len(s) == 2\n    return s[0], s[1]","296f4f96":"train = pd.read_csv(f'{path}\/train.csv')\ntrain['Image'] = train['Image_Label'].apply(lambda img_lbl: split_img_label(img_lbl)[0])\ntrain['Label'] = train['Image_Label'].apply(lambda img_lbl: split_img_label(img_lbl)[1])\ndel train['Image_Label']\ntrain.head(5)","a028b098":"train_with_mask = train.dropna(subset=['EncodedPixels'])\n\n#colors = ['gold', 'mediumturquoise', 'darkorange', 'lightgreen']\n\nfig = go.Figure(data=[go.Pie(labels=train_with_mask['Label'].value_counts().index, \n                             values=train_with_mask['Label'].value_counts().values)])\n\nfig.update_traces(hoverinfo=\"label+percent+name\")\n\nfig.update_layout(height=600, width=900, title = 'Class distribution')\n\nfig.show()","9aeeea90":"class_counts = train.dropna(subset=['EncodedPixels']).groupby('Image')['Label'].nunique()\n\nfig = go.Figure()\n\nfig.add_trace(\n    go.Histogram(\n        x = class_counts,\n        xbins=dict(\n        start=0.5,\n        end=4.5,\n        size=1\n        ),\n    )\n)\n\nfig.update_layout(height=450, width=900, title = 'Distribution of no. labels per image')\n\nfig.update_layout(\n    xaxis_title_text='No. Image Class Labels', # xaxis label\n    yaxis_title_text='Count', # yaxis label\n    bargap=0.2, # gap between bars of adjacent location coordinates\n    bargroupgap=0.1 # gap between bars of the same location coordinates\n)\n\nfig.update_xaxes(tickvals=[1, 2, 3, 4])\n\nfig.show()","b28d51f0":"train = train.pivot(index='Image', columns='Label', values='EncodedPixels')\nassert len(train) == len(fnames_train)\ntrain.head()","fff2d616":"def show_img_fn(fname, figsize=(10, 10)):\n    img = open_image(fname)\n    img.show(figsize=figsize)","c8686690":"def show_img_info(fname):\n    show_img_fn(path_img\/fname)\n    display(train.loc[[fname]])","e16fd1d6":"unusual_imgs = [\"1588d4c.jpg\", \"c0306e5.jpg\", \"c26c635.jpg\", \"fa645da.jpg\", \"41f92e5.jpg\", \"e5f2f24.jpg\"]","0a3fd041":"for fname in unusual_imgs:\n    img = open_image(path_img\/fname)\n    img.show(figsize=(5, 5), title=fname)     ","c7c8eb65":"train_img_dims = (1400, 2100)","1e5abbf7":"def rle_to_mask(rle, shape):\n    mask_img = open_mask_rle(rle, shape)\n    mask = mask_img.px.permute(0, 2, 1)\n    return mask","e6c6a16f":"def mask_to_rle(mask):\n    \"\"\" Convert binary 'mask' to RLE string \"\"\"\n    return rle_encode(mask.numpy().T)","8f6d4c3c":"def test_mask_rle():\n    \"\"\" test case for mask RLE encode\/decode\"\"\"\n    mask_rle = train.iloc[0]['Fish']\n    mask = rle_to_mask(mask_rle, train_img_dims)\n    mask_rle_enc = mask_to_rle(mask)\n    \n    print(mask.shape)\n    Image(mask).show()\n    assert mask_rle_enc == mask_rle\n    \n    \ntest_mask_rle()","d0f10c7e":"item_list = (SegmentationItemList\n            .from_df(df=train.reset_index(), path=path_img, cols='Image')\n             #.use_partial_data(sample_pct=0.1)\n            .split_by_rand_pct(0.2)\n            )","5687f8b1":"class MultiLabelImageSegment(ImageSegment):\n    \"\"\"Store overlapping masks in separate image channels\"\"\"\n\n    def show(self, ax:plt.Axes=None, figsize:tuple=(3,3), title:Optional[str]=None, hide_axis:bool=True,\n        cmap:str='tab20', alpha:float=0.5, class_names=None, **kwargs):\n        \"Show the masks on `ax`.\"\n             \n        # put all masks into a single channel\n        flat_masks = self.px[0:1, :, :].clone()\n        for idx in range(1, self.shape[0]): # shape CxHxW\n            mask = self.px[idx:idx+1, :, :] # slice tensor to a single mask channel\n            # use powers of two for class codes to keep them distinguishable after sum \n            flat_masks += mask * 2**idx\n        \n        # use same color normalization in image and legend\n        norm = matplotlib.colors.Normalize(vmin=0, vmax=2**self.shape[0]-1)\n        ax = show_image(Image(flat_masks), ax=ax, hide_axis=hide_axis, cmap=cmap, norm=norm,\n                        figsize=figsize, interpolation='nearest', alpha=alpha, **kwargs)\n        \n        # custom legend, see https:\/\/matplotlib.org\/3.1.1\/gallery\/text_labels_and_annotations\/custom_legends.html\n        cm = matplotlib.cm.get_cmap(cmap)\n        legend_elements = []\n        for idx in range(self.shape[0]):\n            c = 2**idx\n            label = class_names[idx] if class_names is not None else f\"class {idx}\"\n            line = Line2D([0], [0], color=cm(norm(c)), label=label, lw=4)\n            legend_elements.append(line)\n        ax.legend(handles=legend_elements)\n        \n        # debug info\n        # ax.text(10, 10, f\"px={self.px.size()}\", {\"color\": \"white\"})\n        \n        if title: ax.set_title(title)\n\n    def reconstruct(self, t:Tensor): \n        return MultiClassImageSegment(t)\n        ","2e4d357b":"# source: https:\/\/forums.fast.ai\/t\/unet-how-to-get-4-channel-output\/54674\/4\ndef bce_logits_floatify(input, target, reduction='mean'):\n    return F.binary_cross_entropy_with_logits(input, target.float(), reduction=reduction)","329a4f82":"class_names = [\"Fish\", \"Flower\", \"Gravel\", \"Sugar\"]","59d031e6":"def get_masks_rle(img):\n    \"\"\"Get RLE-encoded masks for this image\"\"\"\n    img = img.split(\"\/\")[-1]  # get filename only\n    return train.loc[img, class_names].to_list()","16c03524":"img_size = (84, 132)  # use multiple of 4\nimg_size","c8934c89":"classes = [0, 1, 2, 3] # no need for a \"void\" class: if a pixel isn't in any mask, it is not labelled\nitem_list = item_list.label_from_func(func=get_masks_rle, label_cls=MultiLabelSegmentationLabelList, \n                                      classes=classes, src_img_size=train_img_dims)","4ed6ade4":"test_items = ItemList.from_folder(path_test)\nitem_list = item_list.add_test(test_items)","a27d68ae":"item_list","73177a6c":"!ls -lth \"..\/input\/understanding_cloud_organization\/test_images\/\"","c4430690":"batch_size = 8\n\n# TODO add data augmentation\ntfms = ([], [])\n# tfms = get_transforms()\n\nitem_list = item_list.transform(tfms, tfm_y=True, size=img_size)","7ee7e55c":"data = (item_list\n        .databunch(bs=batch_size)\n        .normalize(imagenet_stats) # use same stats as pretrained model\n       )  \nassert data.test_ds is not None","450649da":"path_test","0a2caeff":"data.show_batch(4, figsize=(15, 10), class_names=class_names)","59dd5faf":"def dice_metric(pred, targs, threshold=0):\n    pred = (pred > threshold).float()\n    targs = targs.float()  # make sure target is float too\n    return 2.0 * (pred*targs).sum() \/ ((pred+targs).sum() + 1.0)","9fcec549":"!cp ..\/input\/satellite-cloud-image-segmentation-with-fast-ai\/*.pth \/kaggle\/working\/","16420010":"data.test_ds","af232c22":"metrics = [dice_metric]\n\ncallback_fns = [\n    # update a graph of learner stats and metrics after each epoch\n    ShowGraph,\n\n    # save model at every metric improvement\n    partial(SaveModelCallback, every='improvement', monitor='dice_metric', name=f\"{fmt_now()}_unet_resnet18_stage1_best\"),\n    \n    # stop training if metric no longer improve\n    partial(EarlyStoppingCallback, monitor='dice_metric', min_delta=0.01, patience=2),\n]\n\nlearn = unet_learner(data, models.resnet18, metrics=metrics, wd=1e-2, callback_fns=callback_fns)\nlearn.model_dir = \"\/kaggle\/working\/\" # point to writable directory\nlearn.load(\"20190928-235953_unet_resnet18_stage2\")\n","7e91e45d":"learn.validate(learn.data.valid_dl)","479e52b2":"learn.loss_func","b74e069d":"#valid_preds = learn.get_preds(ds_type=DatasetType.Valid)","0e4b8ef2":"#valid_dataset = zip(learn.data.valid_ds.x, learn.data.valid_ds.y)","3b1bec18":"final_size = (350, 525)\nfinal_size_swap = (final_size[1], final_size[0])\n","58879962":"attempts = []\nnumber_images = len(learn.data.valid_ds)\n\nfor i, (image, mask) in enumerate(tqdm(learn.data.valid_ds)):\n    \n    valid_masks = []\n    predict_masks = []\n    output = learn.predict(image)[2] # 2 means logits\n    \n    for m in mask.px:\n        np_mask = m.numpy()\n        if np_mask.shape != final_size:\n            np_mask = cv2.resize(np_mask, dsize=final_size_swap, interpolation=cv2.INTER_LINEAR)\n        valid_masks.append(np_mask)\n\n        \n    for j, prob in enumerate(output):\n        probability = prob.numpy().astype('float32')\n        if probability.shape != final_size:\n            probability = cv2.resize(probability, dsize=final_size_swap, interpolation=cv2.INTER_LINEAR)\n        predict_masks.append(probability)\n        \n    d = 1\n    for class_id, (i, j) in enumerate(zip(valid_masks, predict_masks)):\n        i_condition = i.sum() == 0\n        for t in range(0, 100, 5):\n            t \/= 100\n            for ms in [10000]:\n                predict, _ = post_process(sigmoid(j), t, ms)\n                if i_condition & (predict.sum() == 0):\n                    d = 1\n                else:\n                    d = dice(i, predict)\n                attempts.append((class_id, t, ms, d))\n    \n    del valid_masks\n    del predict_masks\n    del output","e62ea626":"len(attempts)","62d1c61b":"attempts_df = pd.DataFrame(attempts, columns=['class_id', 'threshold', 'size', 'dice']).groupby(['class_id', 'threshold', 'size'], as_index=False).dice.mean()\nattempts_df.head()","0a9aa71b":"assert(attempts_df.shape[0] * number_images == len(attempts))","5cd673da":"class_params = {}\n\nfor class_id in attempts_df.class_id.unique():\n    class_df = attempts_df[attempts_df.class_id == class_id].sort_values('dice', ascending=False)\n    print(class_df.head())\n    best_threshold = class_df['threshold'].values[0]\n    best_size = class_df['size'].values[0]\n    class_params[class_id] = (best_threshold, best_size)\n    ","ca071c2d":"sns.lineplot(x='threshold', y='dice', data=attempts_df);\nplt.title('Threshold and min size vs dice for one of the classes');","9a195bbf":"for i, (image, mask) in enumerate(learn.data.valid_ds):\n    image_vis = image.px.numpy().transpose(1, 2, 0)\n    mask = mask.px.numpy().astype('uint8').transpose(1, 2, 0)\n    pr_mask = np.zeros((final_size[0], final_size[1], 4))\n    output = learn.predict(image)[2] # 2 means logits\n    output_tr = output.numpy().transpose(1, 2, 0).astype('float32')\n    for j in range(4):\n        probability = cv2.resize(output_tr[:, :, j], dsize=final_size_swap, interpolation=cv2.INTER_LINEAR)\n        pr_mask[:, :, j], _ = post_process(sigmoid(probability), class_params[j][0], class_params[j][1])\n    #pr_mask = (sigmoid(output.numpy()) > 0.5).astype('uint8').transpose(1, 2, 0) # TO BE REPLACED BY THE PREV LINE\n    \n        \n    visualize_with_raw(image=image_vis, mask=pr_mask, original_image=image_vis, original_mask=mask, raw_image=image_vis, raw_mask=output_tr)\n    \n    if i >= 4:\n        break","e5e984fa":"import gc\ntorch.cuda.empty_cache()\ngc.collect()","de565437":"#class_params = {0: (0.5, 10000), 1: (0.5, 10000), 2: (0.45, 10000), 3: (0.55, 10000)}\nclass_params","ae17127d":"def mask_to_rle_numpy(mask):\n    \"\"\" Convert binary 'mask' to RLE string \"\"\"\n    return rle_encode(mask.T)","2ef3324a":"encoded_pixels = []\nimage_labels = []\n\nimage_id = 0\n\nfor i, (p, (image, mask)) in enumerate(tqdm(zip(learn.data.test_dl.items, learn.data.test_ds))):\n    output = learn.predict(image)[2] # 2 means logits\n    for labelpred, prob in enumerate(output):\n        probability = prob.numpy().astype('float32')\n        if probability.shape != final_size:\n            probability = cv2.resize(probability, dsize=final_size_swap, interpolation=cv2.INTER_LINEAR)\n        predict, num_predict = post_process(sigmoid(probability), class_params[image_id % 4][0], class_params[image_id % 4][1])\n        if num_predict == 0:\n            encoded_pixels.append('')\n        else:\n            r = mask_to_rle_numpy(predict)\n            encoded_pixels.append(r)\n        image_labels.append(p.name + '_' + class_names[labelpred])\n        del predict\n        del probability\n        image_id += 1\n    del output","53af44ac":"submission = pd.DataFrame({'Image_Label': image_labels, 'EncodedPixels': encoded_pixels}).drop_duplicates()\nsubmission.head()","132d1263":"assert(submission.Image_Label.nunique() == submission.shape[0])","2f401443":"submission.to_csv('submission.csv', columns=['Image_Label', 'EncodedPixels'], index=False)","7c34f8a0":"## EDA","4bc8f344":"# Compute final predictions using selected thresholds","4871d073":"> ## Training (loading fine-tuned model from other competition's mates)","765ecd93":"### Convert masks from\/to RLE","289d1e25":"> # Get predictions","373e803b":"### Broken images","b569c0ae":"## Load images"}}