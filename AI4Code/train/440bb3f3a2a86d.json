{"cell_type":{"33bafcf4":"code","45d53168":"code","a592b27f":"code","7562378e":"code","6f532eb8":"code","1a9b4798":"code","6d05934b":"code","806821ff":"code","f41543aa":"code","793209d9":"code","d1ea86e1":"code","64c27ac6":"code","1790f11a":"markdown","5dce111e":"markdown","041215a4":"markdown","b8ecf7a7":"markdown","3103af9a":"markdown","430b4adc":"markdown"},"source":{"33bafcf4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","45d53168":"!pip install wikipedia","a592b27f":"import nltk\nimport random\nimport string\nimport re, string, unicodedata\nfrom nltk.corpus import wordnet as wn\nfrom nltk.stem.wordnet import WordNetLemmatizer\nimport wikipedia as wk\nfrom collections import defaultdict\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nnltk.download('punkt') \nnltk.download('wordnet')\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity, linear_kernel","7562378e":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","6f532eb8":"data = open('\/kaggle\/input\/bot-data\/alllines.txt','r',errors = 'ignore')\nraw = data.read()\nraw = raw.lower()","1a9b4798":"raw[:1000]","6d05934b":"import nltk\nnltk.download('averaged_perceptron_tagger')","806821ff":"sent_tokens = nltk.sent_tokenize(raw)","f41543aa":"def Normalize(text):\n    remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n    #word tokenization\n    word_token = nltk.word_tokenize(text.lower().translate(remove_punct_dict))\n    \n    #remove ascii\n    new_words = []\n    for word in word_token:\n        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n        new_words.append(new_word)\n    \n    #Remove tags\n    rmv = []\n    for w in new_words:\n        text=re.sub(\"&lt;\/?.*?&gt;\",\"&lt;&gt;\",w)\n        rmv.append(text)\n        \n    #pos tagging and lemmatization\n    tag_map = defaultdict(lambda : wn.NOUN)\n    tag_map['J'] = wn.ADJ\n    tag_map['V'] = wn.VERB\n    tag_map['R'] = wn.ADV\n    lmtzr = WordNetLemmatizer()\n    lemma_list = []\n    rmv = [i for i in rmv if i]\n    for token, tag in nltk.pos_tag(rmv):\n        lemma = lmtzr.lemmatize(token, tag_map[tag[0]])\n        lemma_list.append(lemma)\n    return lemma_list","793209d9":"welcome_input = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\nwelcome_response = [\"hi\", \"hey\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\ndef welcome(user_response):\n    for word in user_response.split():\n        if word.lower() in welcome_input:\n            return random.choice(welcome_response)","d1ea86e1":"def generateResponse(user_response):\n    robo_response=''\n    sent_tokens.append(user_response)\n    TfidfVec = TfidfVectorizer(tokenizer=Normalize, stop_words='english')\n    tfidf = TfidfVec.fit_transform(sent_tokens)\n    #vals = cosine_similarity(tfidf[-1], tfidf)\n    vals = linear_kernel(tfidf[-1], tfidf)\n    idx=vals.argsort()[0][-2]\n    flat = vals.flatten()\n    flat.sort()\n    req_tfidf = flat[-2]\n    if(req_tfidf==0) or \"tell me about\" in user_response:\n        print(\"Checking Wikipedia\")\n        if user_response:\n            robo_response = wikipedia_data(user_response)\n            return robo_response\n    else:\n        robo_response = robo_response+sent_tokens[idx]\n        return robo_response\n#wikipedia search\ndef wikipedia_data(input):\n    reg_ex = re.search('tell me about (.*)', input)\n    try:\n        if reg_ex:\n            topic = reg_ex.group(1)\n            wiki = wk.summary(topic, sentences = 3)\n            return wiki\n    except Exception as e:\n            print(\"No content has been found\")","64c27ac6":"flag=True\nprint(\"My name is Chatterbot and I'm a chatbot. If you want to exit, type Bye!\")\nwhile(flag==True):\n    user_response = input()\n    user_response=user_response.lower()\n    if(user_response not in ['bye','shutdown','exit', 'quit']):\n        if(user_response=='thanks' or user_response=='thank you' ):\n            flag=False\n            print(\"Chatterbot : You are welcome..\")\n        else:\n            if(welcome(user_response)!=None):\n                print(\"Chatterbot : \"+welcome(user_response))\n            else:\n                print(\"Chatterbot : \",end=\"\")\n                print(generateResponse(user_response))\n                sent_tokens.remove(user_response)\n    else:\n        flag=False\n        print(\"Chatterbot : Bye!!! \")","1790f11a":"# This wasn\u2019t too bad. Even though the chatbot couldn\u2019t give a satisfactory answer for some questions, it fared pretty well on others. If you like the kernel please upvote and if any query please feel free to ask in the comment box","5dce111e":"**Installing NLTK Packages**","041215a4":"# So what is a chatbot?\nA chatbot is an artificial intelligence-powered piece of software in a device (Siri, Alexa, Google Assistant etc), application, website or other networks that try to gauge consumer\u2019s needs and then assist them to perform a particular task like a commercial transaction, hotel booking, form submission etc . Today almost every company has a chatbot deployed to engage with the users. Some of the ways in which companies are using chatbots are:\n* To deliver flight information\n* to connect customers and their finances\n* As customer support\nThe possibilities are (almost) limitless.","b8ecf7a7":"**we will be using the Wikipedia page for chatbots as our corpus.**","3103af9a":"> **So that\u2019s pretty much it. We have coded our first chatbot in NLTK. Now, let us see how it interacts with humans:**","430b4adc":"**Text Pre- Processing with NLTK**"}}