{"cell_type":{"2f718cc0":"code","c6f4a0be":"code","4fa703d9":"code","3287e61b":"code","7a886f15":"code","2fa5a6e6":"code","a9c69ea2":"code","1ebbfa3a":"code","d809fcf4":"code","cb5ca608":"code","620fa5b0":"code","e71775bb":"code","31814673":"code","d9daa404":"code","312806ad":"code","6697fed0":"code","578e9d86":"code","cfcf18da":"code","10e65da5":"code","50a3cb80":"code","40ecf1d2":"code","b7acd35f":"code","14562327":"code","2e7fee83":"code","59ecfd28":"code","97010ff8":"code","633b7e02":"code","4c3494f0":"code","cef60898":"code","b700da5b":"code","404eed4d":"code","29dca83b":"code","b3a9af68":"code","9e749b50":"code","e35cdc2c":"code","e62de777":"code","c205402a":"code","bd237830":"code","695fab65":"code","90d2b71b":"code","1b2a9bd8":"code","8b1f58c0":"code","8fc36b27":"code","b309d93d":"code","50a75be9":"code","ba47eeb2":"code","55cf09df":"code","d215a9b7":"code","f0b2fea9":"code","2881ce61":"code","3d4af38c":"code","3d755f43":"code","0940db46":"code","becbaf7f":"code","704adbc6":"code","66eb8d30":"code","551f36a9":"code","0869887b":"code","c4d419bb":"code","0d42ef4a":"code","9befe147":"code","1f084427":"code","52d69778":"code","dfe5c4f3":"code","77555346":"code","114cb136":"code","c3cbc210":"code","8325b8f6":"code","f6863a34":"code","37ccd733":"code","41ce8ee3":"code","0284d4fb":"code","8e0b7cc4":"code","5f838624":"code","6cf90bd1":"code","162d91f0":"code","0012fdd4":"code","17f78792":"code","03dbd33d":"code","fbe0eb9b":"code","c713ad85":"markdown","ab407cf1":"markdown","bb3c062f":"markdown","6d567bd3":"markdown","58ee8b77":"markdown","f0ed9643":"markdown","2e07406e":"markdown","0d1af858":"markdown","c9699545":"markdown","f6851f60":"markdown","26cd6201":"markdown","3c5e3870":"markdown","0f222e1a":"markdown","fe8e6c0d":"markdown","0104a439":"markdown","b70f18f2":"markdown","9b5c83af":"markdown","045bbf6d":"markdown","560d4eff":"markdown","af6a4bd1":"markdown","798543d8":"markdown","8fa819b6":"markdown","d919cb63":"markdown","617f1990":"markdown","822dd779":"markdown","20da04d9":"markdown","be5d5982":"markdown","d5d56a6a":"markdown","904c2f7a":"markdown","319da7f8":"markdown","bd94e76c":"markdown","e8d19fb7":"markdown","7e306fd6":"markdown","81fc4306":"markdown","2a1c6a5d":"markdown","7b25ff01":"markdown","369916c0":"markdown","8a6fcde2":"markdown","d4108fa9":"markdown","256d912b":"markdown","28780e83":"markdown","e610d411":"markdown","946c7a49":"markdown","a76b6751":"markdown","6af2b8d8":"markdown","14104eb7":"markdown","1bc9e5b2":"markdown","210cd3fb":"markdown","969bd37a":"markdown","94e95981":"markdown","9e311601":"markdown","d742db80":"markdown"},"source":{"2f718cc0":"import pandas as pd # Import Pandas for data manipulation using dataframes\nimport numpy as np # Import Numpy for data statistical analysis \nimport matplotlib.pyplot as plt # Import matplotlib for data visualisation\nimport seaborn as sns # Statistical data visualization\nimport missingno as msno# # Import missingno for visualizing missing values in the dataset\n","c6f4a0be":"#import titanic dataset\ndf_train = pd.read_csv('..\/input\/titanic\/train.csv')\ndf_test  = pd.read_csv('..\/input\/titanic\/test.csv')","4fa703d9":"df_train.shape","3287e61b":"df_test.shape","7a886f15":"df_combined= pd.concat([df_train,df_test],ignore_index = True) # code to merge 2 dataframes","2fa5a6e6":"df_combined.shape","a9c69ea2":"df_combined.head()","1ebbfa3a":"df_combined.describe()","d809fcf4":"df_combined.info()","cb5ca608":"df_combined.isnull().sum()","620fa5b0":"msno.matrix(df_combined.drop('Survived', axis='columns'));","e71775bb":"# checking Male to female Ratio\nsns.factorplot('Sex',data = df_train,kind ='count');","31814673":"# checking no of passengers survived and not survived\nsns.factorplot('Survived',data = df_train,kind ='count');","d9daa404":"# Checking the no of male and female passengers survived\nsns.catplot(x =\"Sex\", hue =\"Survived\", kind =\"count\", data = df_train);","312806ad":"# plotting the Pclass column to know no of passengers in each class\nsns.factorplot('Pclass',data= df_train,kind='count');","6697fed0":"# checking the passengers survived by class\nsns.factorplot('Pclass',data = df_train,hue = 'Sex',kind = 'count');","578e9d86":"# Group the dataset by Pclass, Sex ,Survived and then unstack them \ngroup = df_train.groupby(['Pclass','Sex', 'Survived']) \npclass_survived_bySex = group.size().unstack() \n  \n# Heatmap showing the surived and unsurvived by Pclass\nsns.heatmap(pclass_survived_bySex, annot = True, fmt =\"d\");\n","cfcf18da":"# checking the no of passengers boarded Titanic at each port\nsns.factorplot('Embarked', data = df_train, kind='count');","10e65da5":"# Surivival data grouped by Embarked\nsns.factorplot('Embarked',data = df_train,hue='Survived',kind='count');","50a3cb80":"# Survival data grouped by Embarked and class\nsns.catplot(x ='Embarked', hue ='Survived',  \nkind ='count', col ='Pclass', data = df_train);","40ecf1d2":"#Extracting Title from name\ndf_combined['Title'] = df_combined['Name'].str.split(', ',expand = True)[1].str.split('.',expand = True)[0]\ndf_combined.head()","b7acd35f":"df_combined['Title'].unique()","14562327":"df_combined['Title'].value_counts()","2e7fee83":" Rear_titles = ['Don', 'Rev', 'Dr', 'Mme', 'Ms','Major', 'Lady', 'Sir', \n                'Mlle', 'Col', 'Capt', 'the Countess', 'Jonkheer', 'Dona']","59ecfd28":"for title in Rear_titles:\n    print('\\n',title)\n    print(df_combined[df_combined.Title == title][['Name','Sex','Age','Title','Survived','Pclass']])","97010ff8":"df_combined.iloc[710,12]","633b7e02":"#compressing the titles into 4 'Mr', 'Mrs', 'Miss', 'Master' using replace function\ndf_combined['Title'].replace(['Don','Rev','Dr','Mme','Ms','Major','Mlle','Lady','Sir','Col','Capt','the Countess','Jonkheer','Dona'],\n                             ['Mr','Mr','Mr','Miss','Miss','Mr','Miss','Mrs','Mr','Mr','Mr','Mrs','Mr','Mrs'],inplace=True)","4c3494f0":"df_combined['Title'].unique()","cef60898":"# Lets handle the title of a 'Dr' in which we have a female Dr where we assigned title as 'Mr'.\n# we use Sex and title to find out the observation\n#df_combined[(df_combined.Sex.str.contains('Female')) & (df_combined.Title.str.contains('Mr'))].Title\ndf_combined.iloc[796,12] = 'Mrs' # Observation who is Female Doctor\ndf_combined.iloc[710,12] = 'Mrs' # Observation who has Title Mrs in her Name","b700da5b":"df_combined['Title'].value_counts()","404eed4d":"# Creating Family size as a new feature using Parch and SibSp\ndf_combined['Fam_Size'] = df_combined['Parch'] + df_combined['SibSp'] + 1","29dca83b":"df_combined.Ticket.unique()","b3a9af68":"len(df_combined.Ticket.unique())","9e749b50":"# As same Ticket is shared by family members as well we can calculate the Fare per person using 'Fare' and 'Family_Size'\n# Calculating Fare_per_person\n#feature Engineering Fare per person\ndf_combined['Fare_per_person'] = df_combined['Fare']\/df_combined['Fam_Size']","e35cdc2c":"#Now we came to Cabin let's see what we have for Cabin\ndf_combined.Cabin.unique()","e62de777":"#Extracting Deck feature from Cabin\ndf_combined['Deck'] = df_combined[\"Cabin\"].str.slice(0,1)","c205402a":"df_combined['Deck'].unique()","bd237830":"df_combined.Deck.value_counts()","695fab65":"df_combined[df_combined.Deck == 'T']","90d2b71b":"#we will put all of them in Cabin 'G'\ndf_combined.loc[df_combined.Deck == 'T','Deck'] = 'G' ","1b2a9bd8":"df_combined.isnull().sum()","8b1f58c0":"#Let's clear the 'Nan' in Age \n#cleaning null values of age\nimport itertools\nfor Title,Pclass in itertools.product(df_combined['Title'].unique(),df_combined['Pclass'].unique()):\n    df_combined.loc[(df_combined.Age.isnull()) & (df_combined.Title == Title) & (df_combined.Pclass == Pclass),'Age'] = df_combined.Age[(df_combined.Title == Title) & (df_combined.Pclass == Pclass)].median()\n","8fc36b27":"#Let's check did we cleared the Nan's in Age\ndf_combined['Age'].isnull().sum()","b309d93d":"# Let's clear the Embarked column we have 2 embareked missing values in the data\n# we will replace the Nan with 'mode'(most repeated) of the category\n# Let's check the counts of embareked\ndf_combined['Embarked'].value_counts()","50a75be9":"#cleaning Embarked Feature\ndf_combined['Embarked'] = df_combined['Embarked'].fillna(df_combined['Embarked'].mode().iloc[0])","ba47eeb2":"df_combined[df_combined['Fare'].isnull()]","55cf09df":"# Let's clear the 'Fare' feature which has 1 missing value  \ndf_combined.loc[(df_combined.Fare.isnull()),'Fare'] = df_combined.Fare[df_combined.Pclass==3].mean()","d215a9b7":"df_combined['Fare'].isnull().sum()","f0b2fea9":"df_combined[df_combined['Fare_per_person'].isnull()]","2881ce61":"#Clearing the Fare_per_person using index from above\ndf_combined.loc[1043,'Fare_per_person'] = df_combined.loc[1043,'Fare'] \/ df_combined.loc[1043,'Fam_Size']  ","3d4af38c":"df_combined['Fare_per_person'].isnull().sum()","3d755f43":"# we will assign the 'Nans' in Deck to 'N'\ndf_combined['Deck'] = df_combined['Deck'].fillna('N')","0940db46":"# Let's check what more missing we have\ndf_combined.isnull().sum()","becbaf7f":"# we use get_dummies from pandas to create Dummy Variables for each category and drop the 1st column to avoid dummy variable Trap\ndf_combined = pd.get_dummies(df_combined, columns = ['Embarked','Title','Deck','Pclass'],drop_first = True)\ndf_combined.head()","704adbc6":"df_combined.columns","66eb8d30":"# Label encoding 'Sex' variable using LabelEncoder from Sklearn preprocessing module\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf_combined.Sex = le.fit_transform(df_combined.Sex)","551f36a9":"# string the unwanted columns in a list as Name \ndrop_columns = ['PassengerId','Name','Ticket','Cabin']","0869887b":"df_combined.drop( drop_columns, axis = 1 , inplace = True)","c4d419bb":"df_combined.head()","0d42ef4a":"# As test data does not contain the Survived column I am using that as my condition to separate the dataset you can use indexing also\ndf_cleaned_train = df_combined[~df_combined.Survived.isnull()]\ndf_cleaned_test = df_combined[df_combined.Survived.isnull()]","9befe147":"#we will drop the Survived column from the test data set as we have to predict the values \ndf_cleaned_test = df_cleaned_test.drop(['Survived'],axis =1)","1f084427":"# Let's confirm that we don't have Survived in test set\ndf_cleaned_test.columns","52d69778":"#Correlation Plot to check the relation of the newly created features with survival\nplt.figure(figsize=(20,10)) \nsns.heatmap(df_cleaned_train.corr(), annot=True);","dfe5c4f3":"#splitting target variable and features\n# Let's drop the target label coloumn and we will be left with variables storing them in X\nX = df_cleaned_train.drop(['Survived'],axis=1)\nX.head()","77555346":"# Target Variable storing in y\ny = df_cleaned_train['Survived']\ny.head()","114cb136":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=5)","c3cbc210":"# Standardizing the varibles in the dataset \nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train.loc[:,['Age','Fare','Fare_per_person','Fam_Size']] = sc.fit_transform(X_train.loc[:,['Age','Fare','Fare_per_person','Fam_Size']])\nX_test.loc[:,['Age','Fare','Fare_per_person','Fam_Size']] = sc.transform(X_test.loc[:,['Age','Fare','Fare_per_person','Fam_Size']])","8325b8f6":"X_train.head()","f6863a34":"y_train.head()","37ccd733":"#logistic Regression Model\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(random_state = 0)\nlr.fit(X_train, y_train)","41ce8ee3":"from sklearn.svm import SVC\nsvc = SVC(kernel = 'rbf', random_state = 0)\nsvc.fit(X_train, y_train)","0284d4fb":"# Random Forest Classifier\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nrf.fit(X_train, y_train)","8e0b7cc4":"# Models PREDICTIONS\nfrom sklearn.metrics import confusion_matrix, accuracy_score,recall_score,precision_score,f1_score\ny_pred_lr = lr.predict(X_test)\ny_pred_svc = svc.predict(X_test)\ny_pred_rf = rf.predict(X_test)\nprint(\"Logistic Regression\",accuracy_score(y_test, y_pred_lr))\nprint(recall_score(y_test, y_pred_lr))\nprint(precision_score(y_test, y_pred_lr))\nprint(f1_score(y_test, y_pred_lr))\nprint(\"Support Vector Classifier\",accuracy_score(y_test, y_pred_svc))\nprint(recall_score(y_test, y_pred_svc))\nprint(precision_score(y_test, y_pred_svc))\nprint(f1_score(y_test, y_pred_svc))\nprint(\"Random Forest\",accuracy_score(y_test, y_pred_rf))\nprint(recall_score(y_test, y_pred_rf))\nprint(precision_score(y_test, y_pred_rf))\nprint(f1_score(y_test, y_pred_rf))\n","5f838624":"from sklearn.metrics import roc_auc_score,roc_curve, auc\n#roc_curve(y_test, y_pred_svc) \n#auc(y_test, y_pred_svc)\nprint(roc_auc_score(y_test, y_pred_svc))","6cf90bd1":"# Confusion matrix \ncm = confusion_matrix(y_test, y_pred_svc)\nsns.heatmap(cm, annot = True, fmt = \"d\");","162d91f0":"# we finilize Support Vector Machine as our Classifier and Tune its hyperparamters\nfrom sklearn.model_selection import GridSearchCV\nparameters = [{'C': [0.25, 0.5, 0.75, 1], 'kernel': ['linear']},\n              {'C': [0.25, 0.5, 0.75, 1], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\ngrid_search = GridSearchCV(estimator = svc,\n                           param_grid = parameters,\n                           scoring = 'accuracy',\n                           cv = 10,\n                           n_jobs = -1)\ngrid_search.fit(X_train, y_train)\nbest_accuracy = grid_search.best_score_\nbest_parameters = grid_search.best_params_\nprint(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\nprint(\"Best Parameters:\", best_parameters)","0012fdd4":"from sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = svc, X = X_train, y = y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))","17f78792":"# Standardising df_cleaned_test varibales\ndf_cleaned_test.loc[:,['Age','Fare','Fare_per_person','Fam_Size']] = sc.transform(df_cleaned_test.loc[:,['Age','Fare','Fare_per_person','Fam_Size']])\ndf_cleaned_test.head()","03dbd33d":"# standardising the df_cleaned_test set results\ny_pred = svc.predict(df_cleaned_test)\nsubmission = pd.DataFrame(df_test['PassengerId'])\nsubmission['Survived'] = y_pred\nsubmission","fbe0eb9b":"#exporting submission file into csv \nsubmission.to_csv('Titanic_survival_prediction.csv',index = False)","c713ad85":"From the above basic statistics about the data we can draw some insights such as \n75% of the passengers are below Age of '39'. \nMaximum no of 'SibSp' & 'Parch' are '8' and '9'. \nBy the count of Age we can say that there are some missing values in the Age and Fare has one missing value.\ndescribe method can only give the statistics of numerical variables let's explore more to see our categorical variables like 'Sex' & 'Embarked'","ab407cf1":"Ok.. there are so many unique 'Tickets'. ","bb3c062f":"# Visualisations","6d567bd3":"** Feature Engineering**","58ee8b77":"Test data has above dimensions which has 418 rows or observations and 11 variables with survived missing column which have to predict","f0ed9643":"Above we saw in the Visulisation of missing values that we have '1014' missing values in Cabin. We will extract the letter which means the 'Deck' and the number is 'Room no'. It is possible that Deck can be correlated to the Survival as for Upper Deck passengers it will take less time to reach the top and escape through the life boats. \n\nLet's extract Deck from Cabin","2e07406e":"Let's check the Nan in Fare","0d1af858":"We can see from the above plot that more no of female survived and less no of female not Survived but when coming to Male it's quite opposite. ","c9699545":"Let's go by each column and check whether we can extract any new features from the dataset. If we see name it has Title, Surname and Name we will extract titles from the 'Name' using split and use them for imputing missing 'Age'.","f6851f60":"Now, we will separate the datasets into back again into Train_set and Test_set.","26cd6201":"Train data has above dimensions which has 891 rows or observations and 12 variables","3c5e3870":"# Hyperparamter tuning using GridSearch","0f222e1a":"merging the Train and Test data","fe8e6c0d":"By the count of the titles I see that we have maximum number titles of 'Mr', 'Miss', 'Mrs', 'Master'. We will combine the other title into this 4 titles by checking the other features like 'Sex' and 'Age'. We proceed by below assumptions\n\n1.  if 'Sex' = Female and Age Greater than 25 we assume them as married and combine them with Title 'Mrs'. If 'Age' Less than 25 we assume them as 'unmarried' and combine them with title 'Miss'.\n\n2. if 'Sex' = Male and 'Age' Greater than 16 we assume as 'Mr' Title .If Age less than 16 then we assume them as children and combine with 'Master' Title \n \n3. Passengers having title as 'Ms' can be combined with 'Miss'\n\nLet's check one by one using titles and use replace the old titles with new","0104a439":"We didn't clear the Cabin Values as we don't have data about which cabin is assigned to passengers. We will drop the Cabin coulmn going further.","b70f18f2":"From the above heat map we can see that large group of 1st class people survived where as large no of 3rd class people died","9b5c83af":"Yes, the dataset is combined. Let's proceed","045bbf6d":"# Let's check the dataset variables and perform EDA","560d4eff":"# Import necessary libraries \n","af6a4bd1":"So, we have 418 Survived(Target) missing data which we are going to Predict. More, we have 1014 missing values from Cabin Column, 263 missing values from 'Age',2 from 'Embarked' and 1 from 'Fare'. Let's plot the missing values and check.","798543d8":"we can see that we predicted '154' Correct predictions out of '179' test observations and 25 incorrect Predictions","8fa819b6":"# Import Datasets","d919cb63":"We have successfully replaced the Rear Titles with the usual ones Let's check how we did we perform.","617f1990":"We can see that most of the passengers embarked in S = Southampton. ","822dd779":"We combined the dataset using pandas concat function and assigned it to 'df_combined' Let's check the shape of it to verify that the dataset is combined.","20da04d9":"Finally, we are done combing the rear titles with usual Titles.\nNow, let's see other columns for more feature extraction","be5d5982":"# Data Preprocessing","d5d56a6a":"We dropped the Survived feature as we have lot of unpredicted values in the test set. We will handle the missing values going further","904c2f7a":"we got the best paramters of gamma = 0.1, 'C' = 1, kernal = 'rdf' which is radial basis function","319da7f8":"By Observing the Rare title passenger details we can see there is a Passenger Name which has Title 'Mrs' in braces and has 'Mlle' as Title passengerid 710. I will hilight that observation below.","bd94e76c":"# Splitting the dataset into Train and Test  ","e8d19fb7":"We got a new column called Title. Let's check what we have got in it.","7e306fd6":"# Applying k-Fold cross validation","81fc4306":"As we created the 'Fare_per_person' before clearing the 'Fare' using 'Fare' and 'Family_size'. We have i 1 missing value in 'Fare_per_person' we will clear this now.","2a1c6a5d":"We finished the data Cleaning part. Now we go to next step","7b25ff01":"We can see that there are more missing values in 'Cabin' and 'Embarked' also. Let's count the no of missing values in the dataset. ","369916c0":"I can see the letters and numbers in the Ticket Feature but not sure what to extract from it. But let's examine it once","8a6fcde2":"# Data Cleansing","d4108fa9":"Predicting the test set results","256d912b":"# Dummy Variable for the Categorical values ","28780e83":"we have 11 variables or predictors and 1 Target variable. Below is the small description about each variables\n1. PassengerId ( Unique ID for every Passenger )\n2. Survived    ( Our Target varibale which takes 2 values 1 = survived, 0 = not survived )  \n3. Pclass      ( Represent the class of the passenger which takes 1,2,3 values )\n4. Name        ( Name of each Passenger )\n5. Sex         ( Represents gender of passenger Male\/Female )\n6. Age         ( Age of passenger )\n7. Sibsp       ( No of Sib = Sibillings and Sp = Spouse shorlty termed as SibSp )\n8. Parch       ( No of Par = Parents and ch = Children shorlty termed as Parch )\n9. Ticket      ( Ticket Number )\n10. Fare       ( Fare of the ticket )\n11. Cabin      ( Cabin which passenger assigned to )\n12. Embarked   ( Place where the passenger boarded. It takes 3 categories C = Cherbourg,Q = Queenstown,S = Southampton )\n","e610d411":"# Training Model ","946c7a49":"We can see from the above correlation plot that 'Survived' is positively correlated with 'Fare_per_person', 'Title_Miss', 'Title_Mrs' and negativily correlated with 'Pclass_3', 'Deck_N', 'Title_Mr', 'Embarked_S'.","a76b6751":"Length of unique Tickets is 929 but we have 1309 Passengers. So, samiliar ticket is shared by other passengers also maybe be all the family members can have same ticket numbers.","6af2b8d8":"# Drop Unwanted columns","14104eb7":"We got accuracy more than 84% for both the logistic Regression and Random Forest model. Let's check the confusion matrix generated by Support Vector Machine Model.","1bc9e5b2":"we claer the age using 'Median Impuation' method. It will be unfair if we assign the median of the whole age column to the missing values. So, we use grouping by 'Title' & 'Pclass' column which we extracted from the name and take the median of age grouping by title and assign the value to respective Nan's. We are using not using mean as it will be effceted by outliers.","210cd3fb":"As we have only 1 'T' Deck and 5 'G' Deck we will combine these two into the one Deck which is 'G'. As the less cardinality can make out Model get confused. ","969bd37a":"As we have reached the end of the columns in feature engineering now let's enter into the Data Cleansing phase as we have large Nan to clear.","94e95981":"Ok.. we have a lot of title in it. Let's get a count using value.counts() ","9e311601":"we can see the observation which has missing Fare it is of Pclass 3. Fare is mostly related to the Pclass. So, we take the mean 'fare' of Pclass 3 and assign it to Nan.","d742db80":"By observing the above details of the passengers with Rare Titles we can decide which title to assign according to our assumptions. we replace the title as following                                                                     \nold Titles | new Titles                                                          \n  Don      :   'Mr'                                                 \n  Rev      :   'Mr'                                            \n  Dr       :   'Mr'                                       \n  Mme      :   'Miss'                                     \n  Ms       :   'Miss'                                          \n  Major    :   'Mr'                                      \n  Mlle     :   'Miss'                                    \n  Lady     :   'Mrs'                                           \n  Sir      :   'Mr'                                         \n  Col      :   'Mr'                                           \n  Capt     :   'Mr'                                           \n  the Countess : 'Mrs'                                               \n  Jonkheer :   'Mr'                                           \n  Dona     :   'Mrs'                                                     \n  We can see in the above list of Passengers in 'Dr' title that we have 1 female doctor we will deal with it manually later. Further 'Mlle' is French word used for 'Miss'.    "}}