{"cell_type":{"6efe3180":"code","f010dcc8":"code","3d98a0b5":"code","8fff6adc":"code","510e1540":"code","30684043":"code","9b7e3a7c":"code","b17543b8":"code","38fbbf64":"code","f6818470":"code","17006f02":"code","9ff718e6":"code","35cd6a4c":"code","de2d96fa":"code","8f9864c6":"code","141a889e":"code","9b4ed391":"code","986a0edd":"code","6b223abc":"code","8919e3c2":"code","19199fd2":"code","e31e2ffd":"code","8fcf8e51":"code","ebb911ac":"code","d52b8ef4":"code","ad4f3fc9":"code","da5e596c":"code","b86bec79":"code","524c4475":"code","e45dc19a":"code","319af099":"code","99008e05":"code","1d8be844":"code","233c18a9":"code","fd5741b5":"markdown","205ff836":"markdown","d5faab4e":"markdown"},"source":{"6efe3180":"import pandas as pd\nimport numpy as np\nimport scipy as sp\nimport scipy.stats as st\nimport statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom warnings import filterwarnings\n\nfilterwarnings(\"ignore\")\nsns.set_theme()\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\nfrom sklearn.impute import KNNImputer\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\n\nprint(\"imported\")","f010dcc8":"import json\nimport requests\nimport folium\nimport branca","3d98a0b5":"location = \"..\/input\/uber-and-lyft-dataset-boston-ma\/rideshare_kaggle.csv\"\ndata = pd.read_csv(location)\ndata.head()","8fff6adc":"data.T","510e1540":"data[\"cab_type\"].unique()","30684043":"uber = data[data[\"cab_type\"] == \"Uber\"].reset_index(drop=True)\nuber.head()","9b7e3a7c":"uniques = dict()\nfor i in uber.select_dtypes(\"object\"):\n    unique_count = uber[i].nunique()\n    #print(f\"{i} : {unique_count}\")\n    uniques.update({i:unique_count})\nuc_df = pd.DataFrame(uniques, index = [\"unique_count\"]).T\nuc_df[uc_df[\"unique_count\"] > 10]","b17543b8":"drop_cols = [\"cab_type\", \"timestamp\", \"product_id\", \"timezone\", \"latitude\", \"longitude\", \"surge_multiplier\"]\ndrop_cols.extend(list(uc_df[uc_df[\"unique_count\"] > 10].index))\nuber_df1 = uber.drop(drop_cols, axis = 1)\nuber_df1.head()","38fbbf64":"uber_df1.info()","f6818470":"nulls = pd.DataFrame(data.isnull().sum(), columns=[\"nulls\"])\nnulls[\"null percentage\"] = nulls[\"nulls\"]\/uber_df1.shape[0]*100\nnulls[nulls[\"nulls\"] > 0]","17006f02":"'''\nuber_num = uber_df1.select_dtypes(\"number\")\nfrom sklearn.impute import KNNImputer\nuber_num = KNNImputer().fit_transform(uber_num)\nuber_num.isnull().sum()\n'''\n\n# -- since the missing value is in a target column itself, it is dropped.\n\nuber_df1.dropna(inplace = True)","9ff718e6":"#uber_df1.duplicated().sum()\nuber_df1.drop_duplicates(inplace = True)","35cd6a4c":"uber_df1.corr().style.background_gradient()","de2d96fa":"uber_df1.describe()","8f9864c6":"uber_cat = uber_df1.select_dtypes(\"object\")\nuber_cat.head()","141a889e":"a,b,c = 1,3,1\nplt.figure(figsize = (20,5))\nfor i in uber_cat.columns:\n    plt.subplot(a,b,c)\n    plt.title(i.upper(), fontsize = 12)\n    sns.countplot(uber_cat[i], palette = \"ocean_d\", order= uber_cat[i].value_counts().index)\n    plt.xticks(rotation = 90)\n    c = c+1\nplt.show()","9b4ed391":"pd.crosstab(uber_cat[\"icon\"], uber_cat[\"name\"]).plot(kind = \"bar\", stacked = True, figsize = (20,5))\nplt.xticks(rotation = 360)\nplt.legend(loc = \"upper left\")\nplt.show()","986a0edd":"plt.figure(figsize = (30,5))\nsns.countplot(uber_df1[\"hour\"], palette = \"ocean_d\")\nplt.show()","6b223abc":"hour = uber_df1.groupby([\"hour\"]).mean().drop([\"day\",\"month\",\"distance\"], axis = 1)\nscaled = StandardScaler().fit_transform(hour)\nhour[hour.columns] = scaled\nhour.reset_index(inplace = True)\nx = hour[\"hour\"]\ny = hour.drop([\"hour\"], axis = 1)\nplt.figure(figsize = (30,10))\nplt.plot(x,y)\nplt.legend(y.columns, ncol = 2, bbox_to_anchor=(1, 1))\nplt.show()","8919e3c2":"price = uber_df1.groupby([\"name\"])[[\"price\"]].mean()\nplt.figure(figsize = (10,5))\nsns.barplot(price.index, price[\"price\"], palette = \"ocean_d\", order = price[\"price\"].sort_values().index)\nplt.show()","19199fd2":"lyft = data[data[\"cab_type\"] == \"Lyft\"].reset_index(drop=True)\nlyft.head()","e31e2ffd":"uniques = dict()\nfor i in lyft.select_dtypes(\"object\"):\n    unique_count = lyft[i].nunique()\n    #print(f\"{i} : {unique_count}\")\n    uniques.update({i:unique_count})\nuc_df = pd.DataFrame(uniques, index = [\"unique_count\"]).T\nuc_df[uc_df[\"unique_count\"] > 10]","8fcf8e51":"drop_cols = [\"cab_type\", \"timestamp\", \"product_id\", \"timezone\", \"latitude\", \"longitude\", \"surge_multiplier\"]\ndrop_cols.extend(list(uc_df[uc_df[\"unique_count\"] > 10].index))\nlyft_df1 = lyft.drop(drop_cols, axis = 1)\nlyft_df1.head()","ebb911ac":"lyft_df1.info()","d52b8ef4":"nulls = pd.DataFrame(lyft_df1.isnull().sum(), columns=[\"nulls\"])\nnulls[\"null percentage\"] = nulls[\"nulls\"]\/lyft_df1.shape[0]*100\nnulls[nulls[\"nulls\"] > 0]","ad4f3fc9":"#lyft_df1.duplicated().sum()\nlyft_df1.drop_duplicates(inplace = True)","da5e596c":"lyft_df1.corr().style.background_gradient()","b86bec79":"lyft_df1.describe()","524c4475":"lyft_cat = lyft_df1.select_dtypes(\"object\")\nlyft_cat.head()","e45dc19a":"a,b,c = 1,3,1\nplt.figure(figsize = (20,5))\nfor i in lyft_cat.columns:\n    plt.subplot(a,b,c)\n    plt.title(i.upper(), fontsize = 12)\n    sns.countplot(lyft_cat[i], palette = \"ocean_d\", order= lyft_cat[i].value_counts().index)\n    plt.xticks(rotation = 90)\n    c = c+1\nplt.show()","319af099":"pd.crosstab(lyft_cat[\"icon\"], lyft_cat[\"name\"]).plot(kind = \"bar\", stacked = True, figsize = (20,5))\nplt.xticks(rotation = 360)\nplt.legend(loc = \"upper left\")\nplt.show()","99008e05":"hour = lyft_df1.groupby([\"hour\"]).mean().drop([\"day\",\"month\",\"distance\"], axis = 1)\nscaled = StandardScaler().fit_transform(hour)\nhour[hour.columns] = scaled\nhour.reset_index(inplace = True)\nx = hour[\"hour\"]\ny = hour.drop([\"hour\"], axis = 1)\nplt.figure(figsize = (30,10))\nplt.plot(x,y)\nplt.legend(y.columns, ncol = 2, bbox_to_anchor=(1, 1))\nplt.show()","1d8be844":"from folium import plugins\nfrom folium.plugins import HeatMap\n# extracting longitude and latitude values to separate lists\nlongs = data.longitude.to_list()\nlats = data.latitude.to_list()\n# calculating mean longitude and latitude values\nimport statistics\nmeanLong = statistics.mean(longs)\nmeanLat = statistics.mean(lats)\n# create base map object using Map()\nmapObj = folium.Map(location=[meanLat, meanLong], tiles=\"openstreetmap\", zoom_start = 10)","233c18a9":"# create heatmap layer\ndata.dropna(inplace = True)\nheatmap = HeatMap( list(zip(lats, longs, data[\"price\"])),\n                   min_opacity=0.2,\n                   max_val=data[\"price\"].max(),\n                   radius=50, blur=50, \n                   max_zoom=1)\n# add heatmap layer to base map\nheatmap.add_to(mapObj)\nmapObj","fd5741b5":"# **LYFT**","205ff836":"# **GEO SPATIAL ANALYSIS ON PRICE**","d5faab4e":"# **UBER**"}}