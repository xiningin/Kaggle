{"cell_type":{"37b30a7e":"code","df506ee7":"code","51443a92":"code","92b8a058":"code","2e037a65":"code","28f32f3b":"code","66da2c5c":"code","7448dd90":"code","d3420a04":"code","d8089da3":"code","0bb31438":"code","f81b3f09":"code","25ec0ba3":"code","85e0ad0c":"code","7d7796b0":"code","cf3d617b":"code","0c8856c3":"code","e79cef64":"code","e6215a4f":"code","e227f4c6":"code","bedc9576":"code","1f1999ac":"code","ae077171":"code","d4690869":"code","7ac25f3e":"code","45769f36":"code","9d20362f":"code","037d07e7":"code","72123834":"code","04392330":"code","9ed33534":"code","c3ae9cf0":"code","5b2dc6ba":"code","3c223868":"code","d7be8882":"code","63e1f213":"code","24f7fab9":"code","86347b58":"code","43dc2c8c":"code","4eb99b91":"code","fb93e284":"code","9b609171":"markdown"},"source":{"37b30a7e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport sklearn as sk\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import confusion_matrix\n\nimport warnings","df506ee7":"!pip install eigpca\n!pip install kneed","51443a92":"df = pd.read_csv('..\/input\/combo17-galaxy-dataset\/COMBO17.csv')","92b8a058":"warnings.filterwarnings(\"ignore\")","2e037a65":"df.head()","28f32f3b":"df.shape","66da2c5c":"df = df.dropna()\ndf.shape","7448dd90":"df.info()","d3420a04":"useless_features=[]\nfor f in df.columns:\n    if f[0] == 'e':\n        useless_features.append(f)\n        ","d8089da3":"df.drop(useless_features, axis='columns', inplace=True)","0bb31438":"df.head(1)","f81b3f09":"plt.figure(figsize=(10,8))\nsns.scatterplot(df.Rmag, df.ApDRmag, label=\"ApDRmag=Galaxy Size\")\nsns.scatterplot(df.Rmag, df.mumax, label=\"mumax=Center of Galaxy\")\nplt.title(\"Magnitude vs (ApDRmag and Center of galaxy)\")\nplt.legend()","25ec0ba3":"plt.figure(figsize=(10,8))\nsns.scatterplot(df.chi2red,df.Rmag, label=\"Red Magnitude\")\nsns.scatterplot(df.chi2red,df.mumax, label=\"Center of Galaxy\")\n#sns.scatterplot(df.chi2red,df.ApDRmag, label=\"Difference btw R Band & Magnitude\")\nplt.axvline(x=5, label=\"Chi-Square Line 5\", c='r')\nplt.legend()\nplt.title(\"Main Features comparing by chi-square line\")\n\n","85e0ad0c":"sns.displot(df.ApDRmag)\nplt.axvline(x=0, c='r', label=\"Range Cut\")\nplt.legend()","7d7796b0":"fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(10,8))\nsns.boxplot(df.Rmag, ax=ax[0,0])\nsns.histplot(df.Rmag, ax=ax[0,1]);\nsns.boxplot(df.mumax, ax=ax[1,0])\nsns.histplot(df.mumax, ax=ax[1,1]);","cf3d617b":"df = df[df.chi2red<5]\ndf = df[df.ApDRmag>=0]\ndf = df[df.mumax>=20]\ndf.shape","0c8856c3":"cor = df.corr()\nfig, ax = plt.subplots(figsize=(20,10))\nmask = np.triu(np.ones_like(cor, dtype=np.bool))\nsns.heatmap(cor, annot=True, cmap=\"Reds\", mask=mask, linewidth=0.5)\nplt.title(\"Correletion matrix of Features\")","e79cef64":"#Scaling data for Below Graph Plotting and Clustring\nscaler = MinMaxScaler()\n# transform data\nscaled=pd.DataFrame(scaler.fit_transform(df),columns=df.columns, index=df.index) \nscaled.head(1)","e6215a4f":"from eigpca import PCA\n\n\neigpca = PCA()\neigpca.fit(scaled)\n\neigpca.explained_variance_ratio_","e227f4c6":"plt.figure(figsize=(15,5))\neigpca.plot(y='eig')\neigpca.plot(y='pov')\nplt.title(\"Eigen Values of PCA\")","bedc9576":"from sklearn.decomposition import PCA\n\ncolumn_list = scaled.columns.tolist()\nspca = PCA(4)\nout_pca = spca.fit_transform(scaled[column_list])\ndf_pca = pd.DataFrame(data = out_pca, columns = ['pca1', 'pca2', 'pca3', 'pca4'])\n","1f1999ac":"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\n\ndef kmeans_clustring(data, limit):\n    \n    sse=[]\n    silhouette_coefficient=[]\n    for k in range(1,limit):\n        kmeans = KMeans(n_clusters = k, init='k-means++', n_init=50, max_iter=500, random_state=42 )\n        kmeans.fit(data)\n        kmeans.y_kmn =  kmeans.fit_predict(out_pca)\n        kmeans.clusters = kmeans.cluster_centers_\n        sse.append(kmeans.inertia_)\n        \n    return kmeans, sse\n\nkmeans, sse = kmeans_clustring(data=df_pca, limit=13)","ae077171":"kmeans.cluster_centers_","d4690869":"sse","7ac25f3e":"\nplt.style.use('fivethirtyeight')\nplt.plot(range(1,13), sse)\nplt.xticks(range(1,13))\nplt.xlabel('Number of Clusters')\nplt.ylabel('Error')\nplt.title(\"SSE OF CLUSTERS\")\nplt.show()\n","45769f36":"from sklearn.metrics import silhouette_score\ndef s_score(data):\n    silhouette_coefficient = []\n    for k in range(2,13):\n        kmeans = KMeans(n_clusters = k, init='k-means++', n_init=30, max_iter=500, random_state=42 )\n        kmeans.fit(data)\n        score = silhouette_score(data, kmeans.labels_)\n        silhouette_coefficient.append(score)\n    return silhouette_coefficient\ns_score = s_score(data=df_pca)","9d20362f":"s_score","037d07e7":"plt.style.use('fivethirtyeight')\nplt.plot(range(2,13), s_score)\nplt.xticks(range(2,13))\nplt.xlabel('Number of Clusters')\nplt.ylabel('silhouette Error')\nplt.show()","72123834":"from kneed import KneeLocator\nknee = KneeLocator(range(1,13), sse, curve = 'convex', direction = 'decreasing')\nprint(f'Cluster points: {knee.elbow}')","04392330":"from sklearn.cluster import DBSCAN\n\ndef dbscan_cluster(dataset):\n    silhouette_coefficient=[]\n  #setting radius for core points\n    for radius in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n    #setting number of points inside the radius\n        for n_samples in [2,3,4,5,6,7,8,9,10]:\n            dbscan = DBSCAN(eps=radius,min_samples = n_samples)\n            dbscan.fit(dataset)\n            score = silhouette_score(dataset, dbscan.labels_)\n            silhouette_coefficient.append(score)\n    print(f'radius-0.1: {max(silhouette_coefficient[:9])}, {len(silhouette_coefficient[:9])}')\n    print(f'radius-0.2: {max(silhouette_coefficient[9:18])}, {len(silhouette_coefficient[9:18])}')\n    print(f'radius-0.3: {max(silhouette_coefficient[18:27])}, {len(silhouette_coefficient[18:27])}')\n    print(f'radius-0.4: {max(silhouette_coefficient[27:36])}, {len(silhouette_coefficient[27:36])}')\n    print(f'radius-0.5: {max(silhouette_coefficient[36:45])}, {len(silhouette_coefficient[36:45])}')\n    print(f'radius-0.6: {max(silhouette_coefficient[45:54])}, {len(silhouette_coefficient[45:54])}')\n    print(f'radius-0.7: {max(silhouette_coefficient[54:63])}, {len(silhouette_coefficient[54:63])}')\n    print(f'radius-0.8: {max(silhouette_coefficient[63:72])}, {len(silhouette_coefficient[63:72])}')\n    print(f'radius-0.9: {max(silhouette_coefficient[72:81])}, {len(silhouette_coefficient[72:81])}')","9ed33534":"dbscan_cluster(df_pca)","c3ae9cf0":"from sklearn.model_selection import train_test_split","5b2dc6ba":"kmns, sse = kmeans_clustring(data=df_pca, limit=4)","3c223868":"from sklearn.svm import SVC\nprint('Support vector score of Regularization')\ndef svc_model(data, y_pridict):\n    X_train, X_test, y_train, y_test = train_test_split(data, y_pridict, test_size=0.2, random_state=21)\n    for x in range(1,8):\n        svc = SVC(C=x)\n        svc.fit(X_train, y_train)\n        print('score of  Regularization ',x, ': ',svc.score(X_test,y_test))\n\nsvc_model(scaled, kmns.labels_)\n\n","d7be8882":"def svc_model_gamma(data, y_pridict):\n    X_train, X_test, y_train, y_test = train_test_split(data, y_pridict, test_size=0.2, random_state=21)\n    for x in range(1,10):\n        svc = SVC(gamma=x)\n        svc.fit(X_train, y_train)\n        print('score of  Gamma ',x, ': ',svc.score(X_test,y_test))\n\nsvc_model_gamma(scaled, kmns.labels_)","63e1f213":"\n\n\ndef svc_model_kernel(data, y_pridict):\n    X_train, X_test, y_train, y_test = train_test_split(data, y_pridict, test_size=0.2, random_state=21)\n    model_linear_kernal = SVC(kernel='linear')\n    model_linear_kernal.fit(X_train, y_train)\n    yhat =  model_linear_kernal.predict(X_test)\n    print('score of SVC Linear Kernel: ',model_linear_kernal.score(X_test, y_test))\n    print(\"SVC Linear Kernel Accuracy: \" + str(accuracy_score(y_test, yhat)))\n    print(classification_report(y_test,yhat))\n    print('Confussion Matrix ofSVC Linear Kernel')\n    print(confusion_matrix(y_test, yhat))\n    \n    sns.heatmap(confusion_matrix(y_test, yhat), annot=True, fmt='d')\n    plt.xlabel('Predicted Value')\n    plt.ylabel('Truth Value')\n    \n","24f7fab9":"svc_model_kernel(scaled, kmns.labels_)","86347b58":"from sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import SGDClassifier\n\ndef sdgp(data, y_pridict):\n    X_train, X_test, y_train, y_test = train_test_split(data, y_pridict, test_size=0.2, random_state=21)\n    clf = make_pipeline(StandardScaler(), SGDClassifier(max_iter=1000, tol=1e-3))\n    SDG_model = clf.fit(X_train, y_train)\n    yhat = SDG_model.predict(X_test)\n\n    print(\"SDG Pipelined Classifiers accuracy with TF-IDF: \" + str(accuracy_score(y_test, yhat)))\n    print(classification_report(y_test,yhat))\n    print('The Confusion matrix for SDG Pipelined Classifier is')\n    print(confusion_matrix(y_test, yhat))","43dc2c8c":"sdgp(scaled, kmns.labels_)","4eb99b91":"from sklearn.ensemble import RandomForestClassifier\ndef r_forest(dataframe, y_pridicted):\n    X_train, X_test, y_train, y_test = train_test_split(dataframe, y_pridicted, test_size=0.3, random_state=1, stratify=y_pridicted)\n    forest = RandomForestClassifier(criterion='gini',n_estimators=5,random_state=1, n_jobs=2)\n    #\n    # Fit the model\n    #\n    forest.fit(X_train, y_train)\n\n    #\n    # Measure model performance\n    #\n    y_pred = forest.predict(X_test)\n    print('score of Random Forest: ',forest.score(X_test, y_test))\n    print(\"Accuracy for Random Forest: \" + str(accuracy_score(y_test, y_pred)))\n    print(classification_report(y_test,y_pred))\n    print('The Confusion matrix for Random Forest')\n    print(confusion_matrix(y_test, y_pred))","fb93e284":"r_forest(scaled, kmns.labels_)","9b609171":"Detecting Outlaiers"}}