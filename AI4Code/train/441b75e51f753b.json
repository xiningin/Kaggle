{"cell_type":{"b48c1a75":"code","9a84b4d9":"code","fee72864":"code","ec670c22":"code","b8a9b329":"code","fc0a93bc":"code","b56c6e7e":"code","935150b8":"code","2df88f2b":"code","0398bcc0":"code","097b3aae":"code","3b7923d8":"code","620ca6d6":"code","15b5c01a":"code","180b4610":"code","0c1efed6":"code","20d666dc":"code","639f7f38":"code","b067e346":"code","1c122f39":"code","53e020b1":"code","a14a1d94":"code","5ffc52e8":"code","272a48b1":"code","c2104a14":"code","afbce8bb":"code","0ee4f46c":"code","5741aeab":"code","db9c93e3":"code","f71e1375":"code","9cb3b6bb":"code","198c0292":"markdown","e05ed2a1":"markdown","789ba890":"markdown","450085a2":"markdown","c50047f8":"markdown"},"source":{"b48c1a75":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9a84b4d9":"import pandas as pd\ntrain = pd.read_csv(\"\/kaggle\/input\/fake-news\/train.csv\")\ntest  = pd.read_csv (\"\/kaggle\/input\/fake-news\/test.csv\")","fee72864":"train.head()","ec670c22":"print(train.shape)\nprint(test.shape)","b8a9b329":"train.info()","fc0a93bc":"test.info()","b56c6e7e":"train.isnull().sum()","935150b8":"test.isnull().sum()","2df88f2b":"#Handeling missing values\ntest=test.fillna(' ')\ntrain=train.fillna(' ')","0398bcc0":"train.isnull().sum()","097b3aae":"test.isnull().sum()","3b7923d8":"# data to single column\ntrain_data=train[\"title\"]+\" \"+train[\"author\"]+\" \"+train[\"text\"]\ntrain_data.head()","620ca6d6":"test_data=test[\"title\"]+\" \"+test[\"author\"]+\" \"+test[\"text\"]\ntest_data","15b5c01a":"from sklearn.feature_extraction.text import CountVectorizer\n\n# implement BAG OF WORDS\ncv=CountVectorizer(ngram_range=(2,2))\ntraindataset=cv.fit_transform(train_data)","180b4610":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(traindataset, train.label, test_size=0.20, random_state=0)","0c1efed6":"# Modelling Algorithms\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn import metrics\nimport numpy as np","20d666dc":"# tune the hyperparameter alpha for the naive bayes classifier\nfrom sklearn.naive_bayes import MultinomialNB\nfor alpha in np.arange(0,1,.05):\n    mnb = MultinomialNB(alpha=alpha)\n    mnb.fit(X_train, y_train)\n    pred = mnb.predict(X_test)\n    score = metrics.accuracy_score(y_test, pred)\n    print(\"Alpha: {:.2f} Score: {:.5f}\".format(alpha, score))","639f7f38":"\nmnb = MultinomialNB(alpha = 0.15)\nmnb.fit(X_train, y_train)\npred_nb = mnb.predict(X_test)\nacc_nb = metrics.accuracy_score(y_test, pred_nb)\nprint(acc_nb)\ncm = metrics.confusion_matrix(y_test, pred_nb, labels=[0,1])","b067e346":"import matplotlib.pyplot as plt\nimport numpy as np\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"red\" if cm[i, j] > thresh else \"red\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","1c122f39":"plot_confusion_matrix(cm, classes=['TRUE','FAKE'], title ='Confusion matrix for a MultinomialNB with Count Vectorizer')","53e020b1":"#Passive Agressive Classifier With Count Vectorizer\nfrom sklearn.linear_model import PassiveAggressiveClassifier\npac = PassiveAggressiveClassifier(max_iter=10)\npac.fit(X_train, y_train)\npred = pac.predict(X_test)\nacc_linear = metrics.accuracy_score(y_test, pred)\nprint(acc_linear)\ncm6 = metrics.confusion_matrix(y_test, pred, labels=[0,1])\nplot_confusion_matrix(cm6, classes=['TRUE','FAKE'], title ='Confusion matrix for a PA Classifier with Count Vectorizer')","a14a1d94":"#Logistic Regression with CountVectorizer\nlogreg = LogisticRegression(C=1e5)\nlogreg.fit(X_train, y_train)\npred_logreg_count = logreg.predict(X_test)\nacc_logreg_count = metrics.accuracy_score(y_test,pred_logreg_count)\nprint(acc_logreg_count)\ncm3 = metrics.confusion_matrix(y_test, pred_logreg_count, labels=[0,1])\nplot_confusion_matrix(cm3, classes=['TRUE','FAKE'], title ='Confusion matrix for a Logistic Regression with Count Vectorizer')","5ffc52e8":"#Initialize the `tfidf_vectorizer` \nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer(ngram_range=(1, 2))\ntfidf_train = tfidf.fit_transform(train_data) \ntfidf_test = tfidf.transform(test_data)","272a48b1":"X_train, X_test, y_train, y_test = train_test_split(tfidf_train, train.label, test_size=0.20, random_state=0)","c2104a14":"# tune the hyperparameter alpha for the naive bayes classifier\nfor alpha in np.arange(0,0.1,.01):\n    nb_classifier_tune = MultinomialNB(alpha=alpha)\n    nb_classifier_tune.fit(X_train, y_train)\n    pred_tune = nb_classifier_tune.predict(X_test)\n    score = metrics.accuracy_score(y_test, pred_tune)\n    print(\"Alpha: {:.2f}  Score: {:.5f}\".format(alpha, score))","afbce8bb":"# Let's run the optimized model with best value of hyperparameter and check the confusion matrix\nmnb = MultinomialNB(alpha = 0.01)\nmnb.fit(X_train, y_train)\npred = mnb.predict(X_test)\ncm2 = metrics.confusion_matrix(y_test, pred, labels=[0,1])\nacc = metrics.accuracy_score(y_test, pred)\nprint(\"Acc :\",acc)\nplot_confusion_matrix(cm2, classes=['TRUE','FAKE'], title ='Confusion matrix for a MultinomialNB with Tf-IDF')","0ee4f46c":"pac = PassiveAggressiveClassifier(max_iter=10)\npac.fit(X_train, y_train)\npred = pac.predict(X_test)\nacc = metrics.accuracy_score(y_test, pred)\nprint(acc)\ncm5 = metrics.confusion_matrix(y_test, pred, labels=[0,1])\nplot_confusion_matrix(cm5, classes=['TRUE','FAKE'], title ='Confusion matrix for a PA Classifier with Tf-IDF')","5741aeab":"logreg = LogisticRegression(C=1e5)\nlogreg.fit(X_train, y_train)\npred_logreg_tfidf = logreg.predict(X_test)\npred_logreg_tfidf_proba = logreg.predict_proba(X_test)[:,1]\nacc_logreg_tfidf = metrics.accuracy_score(y_test,pred_logreg_tfidf)\nprint(acc_logreg_tfidf)\ncm4 = metrics.confusion_matrix(y_test, pred_logreg_tfidf, labels=[0,1])\nplot_confusion_matrix(cm4, classes=['TRUE','FAKE'], title ='Confusion matrix for a Logistic Regression with Tf-IDF')","db9c93e3":"pac = PassiveAggressiveClassifier(max_iter=10)\npac.fit(X_train, y_train)\npred = pac.predict(X_test)\nacc = metrics.accuracy_score(y_test, pred)\nprint(acc)\ncm5 = metrics.confusion_matrix(y_test, pred, labels=[0,1])\nplot_confusion_matrix(cm5, classes=['TRUE','FAKE'], title ='Confusion matrix for a PA Classifier with Tf-IDF')","f71e1375":"# Now Prediction on test data\npred_test = pac.predict(tfidf_test)","9cb3b6bb":"submission = pd.read_csv('\/kaggle\/input\/fake-news\/submit.csv')\nsubmission[\"label\"] = pred_test\nsubmission.to_csv('my_output.csv', index=False)\nsubmission.head()","198c0292":"# Best Model With High Acc. is Passive Aggressive Classifier by using TFIDF vectorization","e05ed2a1":"# Final Submission","789ba890":"# TfidfVectorizer","450085a2":"# CountVectorizer BAG OF WORDS","c50047f8":"# Data Preprocessing"}}