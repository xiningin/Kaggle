{"cell_type":{"2f5d4440":"code","79a778b2":"code","80ba2e4d":"code","5f634de4":"code","be9f02ac":"code","13e82450":"code","f7a46800":"code","c6f1405c":"code","9fd5af27":"code","5d8d73bc":"code","92caba72":"code","08e53b6a":"code","fe79e0b7":"code","fe8f5a2b":"code","230ddc07":"code","6f6baa4a":"code","827a317f":"code","68866f72":"code","c129af8f":"code","07c88d7e":"markdown","e939cca1":"markdown","20761275":"markdown","fb3a8ba3":"markdown","691dd8ad":"markdown","974b34de":"markdown","bf183e2d":"markdown","1e6fed56":"markdown","c4b18474":"markdown","144fe167":"markdown","d8de5f96":"markdown","81467a73":"markdown","bb3656ca":"markdown"},"source":{"2f5d4440":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport statistics as stat\nfrom scipy import stats","79a778b2":"df = pd.read_csv('..\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')\ndf.head()","80ba2e4d":"df.info()","5f634de4":"df = df.drop_duplicates()\ndf.shape","be9f02ac":"def z_score_method(df, variable_name):\n    #Takes two parameters: dataframe & variable of interest as string\n    columns = df.columns\n    z = np.abs(stats.zscore(df))\n    threshold = 3\n    outlier = []\n    index=0\n    for item in range(len(columns)):\n        if columns[item] == variable_name:\n            index = item\n    for i, v in enumerate(z[:, index]):\n        if v > threshold:\n            outlier.append(i)\n        else:\n            continue\n    return outlier","13e82450":"outlier = []\ncol = []\nfor i,k in enumerate(df.columns):\n    outlier.append(z_score_method(df,k))\n    if outlier[i] != []:\n        col.append(k)\n\n#handle outlier\nind = 0\nfor i in range(len(outlier)):\n    if (outlier[i] == []):\n        continue\n    else:\n        for j in (outlier[i]):\n            df[col[ind]].values[j] = stat.median(df[col[ind]])\n        ind += 1","f7a46800":"sns.countplot(x = \"output\",data = df)","c6f1405c":"plt.figure(figsize=(15,10))\nsns.heatmap(df.corr(),annot=True,cmap='coolwarm')","9fd5af27":"sns.catplot(x=\"sex\", data=df, kind=\"count\")\nsns.catplot(x=\"cp\", data=df, kind=\"count\")\nsns.catplot(x=\"fbs\", data=df, kind=\"count\")\nsns.catplot(x=\"restecg\", data=df, kind=\"count\")\nsns.catplot(x=\"exng\", data=df, kind=\"count\")\nsns.catplot(x=\"slp\", data=df, kind=\"count\")\nsns.catplot(x=\"caa\", data=df, kind=\"count\")\nsns.catplot(x=\"thall\", data=df, kind=\"count\")","5d8d73bc":"sns.catplot(x=\"output\", y=\"age\", data=df, kind=\"box\")\nsns.catplot(x=\"output\", y=\"trtbps\", data=df, kind=\"box\")\nsns.catplot(x=\"output\", y=\"chol\", data=df, kind=\"box\")\nsns.catplot(x=\"output\", y=\"thalachh\", data=df, kind=\"box\")\nsns.catplot(x=\"output\", y=\"oldpeak\", data=df, kind=\"box\")","92caba72":"plt.figure(figsize=(12,8))\nsns.histplot(data=df, x='age', hue='output')\nplt.title('Distribution Output Based on Ages')\nplt.show()","08e53b6a":"df1 = df.copy()","fe79e0b7":"x = df1.iloc[:, :-1].values\ny = df1.iloc[:, -1].values","fe8f5a2b":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nimport xgboost as xgb","230ddc07":"# Spliting the data\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 0)\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","6f6baa4a":"from imblearn.over_sampling import SMOTENC\nsmote_nc = SMOTENC(categorical_features=[df['output'].min(), df['output'].max()], random_state=0)\nx_train, y_train = smote_nc.fit_resample(x_train, y_train)","827a317f":"key = ['LogisticRegression','KNeighborsClassifier','SVC','DecisionTreeClassifier','RandomForestClassifier',\n       'GradientBoostingClassifier','AdaBoostClassifier','XGBClassifier']\nvalue = [LogisticRegression(),KNeighborsClassifier(),SVC(C=.5, gamma = 0.1,kernel = 'rbf', random_state = 0),\n         DecisionTreeClassifier(),RandomForestClassifier(),GradientBoostingClassifier(),AdaBoostClassifier(),xgb.XGBClassifier()]\nmodels = dict(zip(key,value))\nprint(models)","68866f72":"predicted =[]\nfor name,algo in models.items():\n    model=algo\n    model.fit(x_train,y_train)\n    predict = model.predict(x_test)\n    acc = accuracy_score(y_test, predict)\n    predicted.append(acc)\n    print(name,acc)","c129af8f":"plt.figure(figsize = (10,5))\nsns.barplot(x = predicted, y = key)","07c88d7e":"#### Train Model","e939cca1":"## Check Unbalance Data","20761275":"So, before we train the model we should balancing the data firstly","fb3a8ba3":"## Distribution Output Based on Ages","691dd8ad":"#### Splitting Data and Standarizing Data","974b34de":"## Visualize Categorical Data","bf183e2d":"## Classification Process","1e6fed56":"## Import Dataset","c4b18474":"The highest accuracy score is 93.4 % using SVM","144fe167":"#### Balancing Data\n\nHandle unbalanced data using SMOTE","d8de5f96":"## Visualize Numerical Data","81467a73":"## Check Correlation","bb3656ca":"## Outlier Check and Handling"}}