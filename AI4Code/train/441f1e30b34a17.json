{"cell_type":{"9e5c9645":"code","655ca4a1":"code","dca21c8a":"code","cd394045":"code","40384a7b":"code","79c7d073":"code","661e3812":"code","8cbafad7":"code","80d67037":"code","cc8f67ed":"code","768be8a4":"code","1935cdc6":"code","3107b733":"code","6cbc0a41":"code","1d0fb719":"code","e67f529c":"code","0d9255e2":"code","7ad5876d":"code","b79be594":"code","3a1b6290":"code","5619adb9":"code","5b603f49":"code","c33247f6":"code","106d87c5":"code","30090a47":"code","6fd4fbb3":"code","998d58a2":"code","00c1d9ec":"code","94f1862e":"code","075f616e":"code","73304e71":"markdown","ef2d444d":"markdown","41167188":"markdown","7ca0537f":"markdown","9b1b039e":"markdown","07631d01":"markdown","53b3f193":"markdown","bd617231":"markdown","c1dc01dc":"markdown","07d24be7":"markdown","f5e2dc0b":"markdown","066a7025":"markdown","56ae018b":"markdown","60ad5d43":"markdown","2527e9ed":"markdown","8d0bc5a5":"markdown","d88fe2fc":"markdown","ec235c7f":"markdown","bdd89e20":"markdown","b03598dd":"markdown","cad6b341":"markdown","c8b738b0":"markdown","87da712a":"markdown","83f9e11e":"markdown","01167cee":"markdown","0e13fa31":"markdown","689fb2bd":"markdown","76932395":"markdown","ff963bbd":"markdown","6e29ec44":"markdown","1150b952":"markdown","a6f094b5":"markdown","d50b4501":"markdown"},"source":{"9e5c9645":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\nimport warnings\n\nwarnings.simplefilter('ignore')","655ca4a1":"# load the datset into data \ndata = pd.read_csv('..\/input\/data.csv')\n\n# drop uncessary columns \ndata.drop(['id', 'Unnamed: 32'], axis = 1, inplace = True)\n\n#print the number of columns and rows\nprint(\"This dataset contains {} rows and {} columns\".format(data.shape[0], data.shape[1]))\n\n# change the target to numerical to help us in statistics\ndata['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n\ndata.head()","dca21c8a":"# Calculate Statistics for numerical features\ndata.describe()","cd394045":"data.info()","40384a7b":"# Split the dataset to target and features\nfeatures = data.drop('diagnosis', axis = 1)\ntarget = data['diagnosis']","79c7d073":"plt.figure(figsize = (15, 38))\nplt.suptitle('Histograms for Numeric Features in the dataset', fontsize = 20)\nL = list(data)\nfor i in range(data.shape[1]):\n    plt.subplot(11, 3, i + 1)\n    sns.distplot(data[L[i]])","661e3812":"from scipy.stats import skew\n\nfeatures_list = list(features)\nSkew_D = {}\n\n# Claculate the skewness of each feature and store them in Skew_D\nfor f in features_list:\n    Skew_D[f] = skew(features[f], bias = False)\n    \n# Store the features that have high skewned\nHigh_skewed_features = []\nfor i in Skew_D:\n    if (Skew_D[i] > 1) or (Skew_D[i] < -1):\n        High_skewed_features.append(i)\n","8cbafad7":"features[High_skewed_features].hist(figsize = (15, 15))\nplt.show()","80d67037":"data_corr = data.corr()\n\nplt.figure(figsize = (18, 18))\nsns.heatmap(data_corr, annot = True)\nplt.show()","cc8f67ed":"highest_corr = data_corr['diagnosis'].sort_values(ascending = False)[1: 20]\nhighest_corr","768be8a4":"plt.figure(figsize = (20, 35))\nplt.suptitle('Barplots for Diagnosis versus highest correlated features in the dataset, B: 0 , M: 1', fontsize = 25)\n\nL = highest_corr.index\nfor i in range(len(L)):\n    plt.subplot(8, 4, i + 1)\n    sns.barplot(data = data, x = 'diagnosis', y = L[i])\n","1935cdc6":"# hold all indices of outliers\noutliers_index = set()\n\n# factor for calculating the step\nfactor = 4.5 \n\n\nfor f in list(features): \n    Q1 = np.percentile(data[f], q = 25)\n    Q3 = np.percentile(data[f], q = 75)\n    step = (Q3 - Q1) * factor\n    \n    for i in range(len(data)):\n        if (data[f].loc[i] > (Q3 + step)) | (data[f].loc[i] < (Q1 - step)):\n            outliers_index.add(i)\n            \nprint(\"There {} detected outliers\".format(len(outliers_index)))","3107b733":"clean_data = data.drop(list(outliers_index), axis = 0)\n\n#Define features and Target again\nfeatures = clean_data.drop('diagnosis', axis = 1)\ntarget = clean_data['diagnosis']\n\nprint(\"The number of rows after deleting outliers is: {}\".format(len(clean_data)))","6cbc0a41":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\n# prepare the final data for the model\nfinal_features = scaler.fit_transform(features)","1d0fb719":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(final_features, target, test_size = 0.2, \n                                                    shuffle = True, random_state = 0)\n\nprint(\"training set size: {}, testing set size: {}\".format(len(X_train), len(X_test)))","e67f529c":"from sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier \n\n# Build these models\nsvc_model = SVC(random_state= 40) \nlogistic_model = LogisticRegression(random_state= 40)\nrandom_model = RandomForestClassifier(random_state= 40)\nmlp_model = MLPClassifier(random_state= 40)\n","0d9255e2":"from sklearn.metrics import f1_score, accuracy_score\nimport numpy as np \nimport matplotlib.pyplot as plt \nfrom sklearn.model_selection import learning_curve, cross_val_score, GridSearchCV\n\n\ndef plot_learning_curve(estimators, X, y, train_sizes, scorer, cv):\n    \n    #calculate required number of rows in the figure \n    n_rows = np.ceil(len(estimators) \/ 2)\n    \n    #calculate the width of the figure\n    y_length = n_rows * 5 + 5\n    \n    # Create the figure window\n    fig = plt.figure(figsize=(10, y_length))\n    \n    for i, est in enumerate(estimators):\n        sizes, train_scores, test_scores = learning_curve(est, X, y, \n                                                          cv = cv, train_sizes = train_sizes, scoring = scorer)\n        \n        #print the done precentage\n        print(\"Precentage of work done: {}%\".format((i + 1) * 100 \/ len(estimators)))\n        \n        #get estimator name for title setting\n        est_name = est.__class__.__name__\n        \n        # average train_scores and test_scores\n        train_mean = np.mean(train_scores, axis = 1)\n        test_mean = np.mean(test_scores, axis = 1)\n        \n        #Create subplots\n        ax = fig.add_subplot(n_rows, 2, i + 1)\n        ax.plot(sizes, train_mean, 'o-', color = 'r', label = 'Training Score')\n        ax.plot(sizes, test_mean, 'o-', color = 'g', label = 'Testing Score')\n        \n        #add texts \n        ax.set_title(est_name)\n        ax.set_xlabel('Number of Training Points')\n        ax.set_ylabel('Score')\n       \n    # Visual aesthetics\n    ax.legend(bbox_to_anchor=(1.05, 1.8), loc='lower left', borderaxespad = 0.)\n    fig.suptitle('Learning Performances for Multiple Models', fontsize = 16, y = 1.03)\n    fig.show()\n\ndef multi_cross_val(estimators, X, y, cv, scoring):\n    \n    scores = []\n    \n    for est in estimators:\n        S = cross_val_score(est, X, y, cv =cv, scoring = scoring)\n        scores.append(S)\n        \n    return scores\n\ndef cal_confusion_matrix(y_true, pred):\n    POS = 0\n    true_pos = 0\n    \n    NEG = 0\n    true_neg = 0\n    for i, element in enumerate(y_true):\n\n        if element == 1:\n            POS += 1\n            if pred[i] == 1:\n                true_pos += 1\n        else:\n            NEG += 1\n            if pred[i] == 0 :\n                true_neg += 1\n\n    false_neg = POS - true_pos\n    false_pos = NEG - true_neg\n    \n    return ['True Positive', 'False Positive', 'False Negative','True Negative'], [true_pos, false_pos, false_neg, true_neg]\n    \ndef multi_grid_search(estimators, X, y, params, cv, scoring):\n    \n    grids = []\n    \n    for i, est in enumerate(estimators):\n        \n        #Define the grid search object\n        grid_obj = GridSearchCV(est, param_grid = params[i], cv = cv, scoring = scoring)\n        grid_obj.fit(X, y)\n        grids.append(grid_obj)\n        #print the done precentage\n        print(\"Precentage of work done: {}%\".format((i + 1) * 100 \/ len(estimators)))\n   \n    #return grid_obj\n    return grids\n","7ad5876d":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import make_scorer, f1_score\n\n\ncv= KFold(n_splits = 10, shuffle = True, random_state = 0) \ntrain_sizes= [20, 40, 80, 180, 300, 390]\nscorer= make_scorer(f1_score)\n\nplot_learning_curve([svc_model, logistic_model, random_model, mlp_model], X_train, y_train, train_sizes, scorer, cv)","b79be594":"# apply cross_val_score for SVC and MLPClassifier\nscores = multi_cross_val([svc_model, logistic_model, random_model, mlp_model], X_train, y_train, cv, scorer)\n\n#get the average of the scores\nscores = np.mean(scores, axis = 1)\n\nprint(\"The average scores for SVC is: {} and for LogisticRegression is: {}\".format(scores[0], scores[1]))\nprint(\"The average score for RandomForest is: {} and for MLPClassifier is: {}\".format(scores[2], scores[3]))","3a1b6290":"#prepare svc's paramters\nsvc_params = {'C': [1, 2, 2.5, 3], 'kernel': ['linear', 'poly', 'rbf']}\n\n#prepare mlp's prarmeters\nlogistic_params = {'penalty': ['l1','l2'], 'C': [0.09, 0.1, 0.5, 1, 2], 'max_iter': [75, 100, 200, 500]}\n\n#apply GrideSearchCv for both models\ngrids = multi_grid_search([svc_model, logistic_model], X_train, y_train, [svc_params, logistic_params], cv, scorer)","5619adb9":"# get the best svc\nbest_svc = grids[0].best_estimator_\n\n# get the best logistic model \nbest_logistic = grids[1].best_estimator_","5b603f49":"# apply cross_val_score for SVC and MLPClassifier\nscores = multi_cross_val([best_svc, best_logistic], X_train, y_train, cv, scorer)\n\n#get the average of the scores\nscores = np.mean(scores, axis = 1)\n\nprint(\"The average score for SVC is: {} and for LogisticRegression is: {}\".format(scores[0], scores[1]))","c33247f6":"# predict on testset \nsvc_pred = best_svc.predict(X_test)\nlogistic_pred = best_logistic.predict(X_test)\n\n#calculate f1_score for both predictions to decide the winner\nsvc_score = f1_score(y_test, svc_pred)\nlogistic_score = f1_score(y_test, logistic_pred)\n\nprint(\"The test score for SVC is: {} and for LogisticRegression is: {}\".format(svc_score, logistic_score))","106d87c5":"import copy \n\nscaler = StandardScaler()\n\n# prepare the final data for the model\nfinal_features_reduced = scaler.fit_transform(features[highest_corr.index])\n\n\nX_train_reduced, X_test_reduced, y_train, y_test = train_test_split(final_features_reduced,\n                                                                                    target, test_size = 0.2, \n                                                                                    shuffle = True, random_state = 0)\n\nsvc = copy.copy(best_svc)\nlogistic = copy.copy(best_logistic)\nsvc.fit(X_train_reduced, y_train)\nlogistic.fit(X_train_reduced, y_train)","30090a47":"# apply cross_val_score for SVC and MLPClassifier\nscores = multi_cross_val([svc, logistic], X_train_reduced, y_train, cv, scorer)\n\n#get the average of the scores\nscores = np.mean(scores, axis = 1)\n\nprint(\"The average score for SVC is: {}, and for Logistic is: {} \".format(scores[0], scores[1]))","6fd4fbb3":"# predict on testset \nsvc_pred_reduced = svc.predict(X_test_reduced)\nlogistic_pred_reduced = logistic.predict(X_test_reduced)\n\n# Calculate f1_score for both predictions to decide the winner\nsvc_score = f1_score(y_test, svc_pred_reduced)\nlogistic_score = f1_score(y_test, logistic_pred_reduced)\n\nprint(\"The test score for SVC is: {} , and for Logistic is: {}\".format(svc_score, logistic_score))","998d58a2":"\n# apply first on trainset\nelements, train_confusion = cal_confusion_matrix(y_train, best_svc.predict(X_train))\n\n# apply first on trainset\nelements, test_confusion = cal_confusion_matrix(y_test, best_svc.predict(X_test))\n","00c1d9ec":"#Build dataframe for train_confusion\nconfusion_train = pd.DataFrame(index = ['Predict Positive', 'Predict Negative'], \n                          columns = ['Actual Positive', 'Actual Negative'])\n\n#Assign values for corresponding rows and columns\nconfusion_train['Actual Positive'] = train_confusion[0], train_confusion[2]\nconfusion_train['Actual Negative'] = train_confusion[1], train_confusion[3]\n\n#Build dataframe for test_confusion\nconfusion_test = pd.DataFrame(index = ['Predict Positive', 'Predict Negative'], \n                          columns = ['Actual Positive', 'Actual Negative'])\n\n#Assign values for corresponding rows and columns\nconfusion_test['Actual Positive'] = test_confusion[0], test_confusion[2]\nconfusion_test['Actual Negative'] = test_confusion[1], test_confusion[3]","94f1862e":"#plot confusion for trainset\nplt.figure(figsize = (15, 8))\nplt.suptitle(\"Confusion Matrix for Trainset\", fontsize = 30)\nsns.heatmap(confusion_train, annot = True, fmt = 'd')\nplt.show()","075f616e":"#plot confusion for trainset\nplt.figure(figsize = (15, 8))\nplt.suptitle(\"Confusion Matrix for Testset\", fontsize = 30)\nsns.heatmap(confusion_test, annot = True, fmt = 'd')\nplt.show()","73304e71":"### From the above evaluations on trainset and testset, `SVC` have won on trainset, but LogisticRegression beats it on testset. That's make it hard to decide which is better so we can use both algorithms.","ef2d444d":"### Delete the outliers\nBecause the number of outliers is not high we can drop them ","41167188":"# Model Evaluation\nIn this section of the project I'm going to measure the performance of the final model(s) to make sure the final one can go to the light.","7ca0537f":"### - Plot Histograms to Visualize Feature Distributions in the dataset and Detect Skewness ","9b1b039e":"From the above learning curves and Cross Validation I will pick `SVC` and `LogisticRegression` because they both gives high accuracy in learning curves and Cross Validation.\nSo I'm going to take these two models and filter them later in the project.","07631d01":"### Calculate coffecients of corelations between each pair of input features","53b3f193":"# Fine Tune the Model\nIn this sectoin of this project I'm going to fine tune the model's hyperparameters using `Grid Search` Technique in order to improve the performance of the model.\nFor this purpose I have built a method called `multi_grid_search` in functions file in order to apply GrideSearchCV for multiple models to apply it for the filtered models.","bd617231":"## Conclusion\n##### The total `False Postives` for trainset and testset is `7`  and got zero `False Negatives` so that's great result.\n---","c1dc01dc":"## Refine the model input features\nIn this section I will remove the least important features trying to speed-up the model perormance, this setp might seems not necessary in my case because I have a small dataset. But I'll do in the seek of figure out what would be the result.","07d24be7":"### Now I'm going to plot `learning curves` and apply `Cross Validation` to help me filter \nthese models and pick the most appropriate one.\nlearning curve give initial intution about which model will overfit and which will underfit and which one will do good job.","f5e2dc0b":"# Accuracy Visualization\n### Final Step\nIn this final step I'm going to calculate the `confusion matrix` in order to detect the two types of errors `False Positive` and `False Negative`. \nFor sure we care much about `False Negatives` because it's more risky as it sends the patient to home pretending he\/she is safe and don't suffer anything, and because of this this type of error more risky so we wish to cut it out.","066a7025":"##### CONCLUSION: the dataset contains only 1 categorical column and the rest are numericals, also the dataset is clean and have no null values and ready for the preprocessing stage","56ae018b":"In this section I'm going to implement the following:\n* Implement cross validation and test the models on the testset in order to pick the best one of them.\n* Plot confusion Matrix to detect `false positive` and `false_negative`","60ad5d43":"##### Calculate the `skewness` of each feature to make sure the features are normally or sub-normally distributed and fix them if not normally distributed","2527e9ed":"### Note:\nThe following cell contains some functions that have built personally to assest me when ploting `Learning Curves` and applying `GridSearchCV`, `Cross-Validation` or calculating `confusion matrix`.","8d0bc5a5":"# Correlation Testing\nIn this section of this project I'm going to find the correlations in the dataset. Because detecting these correlations can help us in `Feature Selection` process in order to minimize the number of features in the dataset.\n\n#### NOTE: I will calculate the correlation between each pair of attributes (correlation matrix). Then I'll plot the correlation matrix to get an idea of which variables have a high correlation with each other.","d88fe2fc":"##### From the difference between the `median` and `mean` it seems there are some features that have `skewness` that need to be transformed ","ec235c7f":"### That's Good! \nAs we see after removing the less important features the model's accuracy decreased a little on both trainset and testset.\nThis trade-off in this size of the dataset not important because we have small dataset, but if we increased the number of rows to be high (like 20,000 - 50,000) we may prefere to eliminate these less important features\n---","bdd89e20":"In this section I planned to list some of the best Machine Learning Classifiers and see which ones are appropriate for this problem, and after that I will filter these models to pick the best one that give me the best accuracy.\n##### These models are:\n1. Support Vector Machine (SVM)\n2. Logistic Regression\n3. Random Forest Classifier\n4. Multi-Layer Perceptron (MLP)","b03598dd":"### - Get information about the dataset and its dtypes to detect null values","cad6b341":"##### Plot the features that have high skewness to visualize the skewness using histograms ","c8b738b0":"# Model Selection\n#### In this Process I'm going to apply the following:\n* Pick up the most `appropriate models` that best-fit the problem I'm trying to solve.\n* Define the required metrics that need to evaluate the model performance.\n* Filter these models by testing them by ploting `learing curve` for each one.","87da712a":"#### Plot the confution Matrix for trainset and testset using seaborn","83f9e11e":"As you noticed the SVC beats the LogisticRegression model by 1%, but further I'm going to test both on testset to make sure that SVC still generalize well.","01167cee":"# Outlier Detection\nIn this section I'm going to apply some techniques to detect the outliers in the dataset. Outlier can be source of information in the dataset on the other hand it maybe lead to bad results or biased result. So we need to detect them and treat them in the `Preprocessing` stage. ","0e13fa31":"**(Optional)** Now I'm going to try eliminate the less important featreus and keep the highest coorelated ones, trying to simplify the model. This setp will lead to less acurate model but if we came to trade-off between accuracy and speed of the model we may choose to reduce the number of features. So i'll give it a try.","689fb2bd":"# Data Exploration\nIn this section of this project, I will make a cursory investigation about the dataset and provide some observations. Also I'm gooing to Familiarize myself with the data through an `explorative` process and it is a fundamental process to help us better understand the data and justify the final results. So we are going to walk through the following\n* Calculate `Statistics` for numerical features\n* Get information about the dataset and its dtypes to detect null values\n* Plot Histograms to `Visualize Feature Distributions` in the dataset(Detect Skewness)","76932395":"The presence of outliers can often skew results. There are many techniques for how to detect and deal with the outliers in a dataset. *outlier step* is calculated as `factor` multiplied the interquartile range (IQR). A data point with a feature that is beyond an outlier step outside of the IQR for that feature is considered abnormal.","ff963bbd":"#### Now I'm going to plot barplot (diagnosis VS highest_corr features) to visualize the correlation between the target and the most effective features. ","6e29ec44":"# **Inroduction**\nThe goal of this problem is to use the power of Machine Learning algorithms to take the dataset of past measurements of Breast Cancer and apply some analysis to understand which most features that can be asign of a Breast Cancer? Also, to predict the likelihood of future patients to be diagnosed as sick.\nSo given important measurements of a future patient we can train a ML algorithm to predict if he\/she carries a Breast Cancer easily and accurately.","1150b952":"# Getting Started \nImport the basic liberaries used in this project\n* Pandas\n* Numpy\n* seaborn\n* Matplotlib \n\nfor this project I have build a python file called `functions` and will use it in `Model Selection` section","a6f094b5":"# Data Preprocessing\n#### In this section of this project I'm going to apply:\n* Apply `Feature Scaling` (Transformation). This will fix the skewness of the data \n* Split the dataset into `Trainset` and `Testset`","d50b4501":"### - Calculate Statistics for numerical features"}}