{"cell_type":{"408545db":"code","0f0840a7":"code","d2368e5a":"code","ebed05c0":"code","c80fbb87":"code","e27730c1":"code","7a24e66a":"code","104fb7bd":"code","55dfecc5":"code","618fd689":"code","faf6a4d1":"code","61220ad0":"code","206fc648":"code","aedcd614":"code","4997c158":"markdown","99c65933":"markdown","d833887a":"markdown"},"source":{"408545db":"# To make sure all of the correct libraries are installed, import each module and print the version number\n\nimport sys\nimport numpy\nimport sklearn\nimport pandas\n\nprint('Python: {}'.format(sys.version))\nprint('Numpy: {}'.format(numpy.__version__))\nprint('Sklearn: {}'.format(sklearn.__version__))\nprint('Pandas: {}'.format(pandas.__version__))","0f0840a7":"# Import, change module names\nimport numpy as np\nimport pandas as pd\n\n# import the uci Molecular Biology (Promoter Gene Sequences) Data Set\nurl = 'https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/molecular-biology\/promoter-gene-sequences\/promoters.data'\nnames = ['Class', 'id', 'Sequence']\ndata = pd.read_csv(url, names = names)","d2368e5a":"print(data.iloc[0])","ebed05c0":"# Building our Dataset by creating a custom Pandas DataFrame\n# Each column in a DataFrame is called a Series. Lets start by making a series for each column.\n\nclasses = data.loc[:, 'Class']\nprint(classes[:5])","c80fbb87":"# generate list of DNA sequences\nsequences = list(data.loc[:, 'Sequence'])\ndataset = {}\n\n# loop through sequences and split into individual nucleotides\nfor i, seq in enumerate(sequences):\n    \n    # split into nucleotides, remove tab characters\n    nucleotides = list(seq)\n    nucleotides = [x for x in nucleotides if x != '\\t']\n    \n    # append class assignment\n    nucleotides.append(classes[i])\n    \n    # add to dataset\n    dataset[i] = nucleotides\n    \nprint(dataset[0])","e27730c1":"# turn dataset into pandas DataFrame\ndframe = pd.DataFrame(dataset)\nprint(dframe)","7a24e66a":"# transpose the DataFrame\ndf = dframe.transpose()\nprint(df.iloc[:5])","104fb7bd":"# for clarity, lets rename the last dataframe column to class\ndf.rename(columns = {57: 'Class'}, inplace = True) \nprint(df.iloc[:5])","55dfecc5":"# looks good! Let's start to familiarize ourselves with the dataset so we can pick the most suitable \n# algorithms for this data\n\ndf.describe()","618fd689":"# desribe does not tell us enough information since the attributes are text. Lets record value counts for each sequence\nseries = []\nfor name in df.columns:\n    series.append(df[name].value_counts())\n    \ninfo = pd.DataFrame(series)\ndetails = info.transpose()\nprint(details)","faf6a4d1":"# Unfortunately, we can't run machine learning algorithms on the data in 'String' formats. As a result, we need to switch\n# it to numerical data. This can easily be accomplished using the pd.get_dummies() function\nnumerical_df = pd.get_dummies(df)\nnumerical_df.iloc[:5]","61220ad0":"# We don't need both class columns.  Lets drop one then rename the other to simply 'Class'.\ndf = numerical_df.drop(columns=['Class_-'])\n\ndf.rename(columns = {'Class_+': 'Class'}, inplace = True)\nprint(df.iloc[:5])","206fc648":"# Use the model_selection module to separate training and testing datasets\nfrom sklearn import model_selection\n\n# Create X and Y datasets for training\nX = np.array(df.drop(['Class'], 1))\ny = np.array(df['Class'])\n\n# define seed for reproducibility\nseed = 1\n\n# split data into training and testing datasets\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=seed)\n","aedcd614":"# Now that we have our dataset, we can start building algorithms! We'll need to import each algorithm we plan on using\n# from sklearn.  We also need to import some performance metrics, such as accuracy_score and classification_report.\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, accuracy_score\n\n# define scoring method\nscoring = 'accuracy'\n\n# Define models to train\nnames = [\"Nearest Neighbors\", \"Gaussian Process\",\n         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n         \"Naive Bayes\", \"SVM Linear\", \"SVM RBF\", \"SVM Sigmoid\"]\n\nclassifiers = [\n    KNeighborsClassifier(n_neighbors = 3),\n    GaussianProcessClassifier(1.0 * RBF(1.0)),\n    DecisionTreeClassifier(max_depth=5),\n    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n    MLPClassifier(alpha=1),\n    AdaBoostClassifier(),\n    GaussianNB(),\n    SVC(kernel = 'linear'), \n    SVC(kernel = 'rbf'),\n    SVC(kernel = 'sigmoid')\n]\n\nmodels = zip(names, classifiers)\n\n# evaluate each model in turn\nresults = []\nnames = []\n\nfor name, model in models:\n    kfold = model_selection.KFold(n_splits=10, random_state = seed)\n    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)\n    model.fit(X_train, y_train)\n    predictions = model.predict(X_test)\n    print('Test-- ',name,': ',accuracy_score(y_test, predictions))\n    print()\n    print(classification_report(y_test, predictions))","4997c158":"# Classifying DNA Sequences\n### Presented by Eduonix\n\nDuring this tutorial, we will explore the world of bioinformatics by using Markov models, K-nearest neighbor (KNN) algorithms, support vector machines, and other common classifiers to classify short E. Coli DNA sequences. This project will use a dataset from the UCI Machine Learning Repository that has 106 DNA sequences, with 57 sequential nucleotides (\u201cbase-pairs\u201d) each.   \n\nYou will learn how to:\n* Import data from the UCI repository\n* Convert text inputs to numerical data\n* Build and train classification algorithms\n* Compare and contrast classification algorithms\n\n## Step 1: Importing the Dataset\n\nThe following code cells will import necessary libraries and import the dataset from the UCI repository as a Pandas DataFrame.","99c65933":"## Step 2: Preprocessing the Dataset\n\nThe data is not in a usable form; as a result, we will need to process it before using it to train our algorithms.","d833887a":"## Step 3: Training and Testing the Classification Algorithms\n\nNow that we have preprocessed the data and built our training and testing datasets, we can start to deploy different classification algorithms. It's relatively easy to test multiple models; as a result, we will compare and contrast the performance of ten different algorithms."}}