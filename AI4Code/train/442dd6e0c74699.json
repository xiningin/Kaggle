{"cell_type":{"70933cc7":"code","1e9e4a96":"code","20ad212f":"code","b68c260b":"code","0059dad2":"code","90f66ad1":"code","e85e13a7":"code","3d440964":"code","52fcf782":"code","0176ed8e":"code","ed6fd073":"code","58d5342c":"code","8b3a3dc9":"code","5bad05df":"code","a77c6caa":"code","096290f8":"code","2848c108":"code","2b63ade0":"code","378c1813":"code","85656bee":"code","c4fcb18c":"code","0c5df30d":"code","7fe7840f":"code","c39a5882":"code","a553f702":"code","ce4f8a8e":"code","439230b2":"code","2fe5b7fd":"code","64a04b6e":"code","4724d843":"code","dbb37e28":"code","f374495a":"code","a281db9b":"code","d4fc3a80":"code","d98a49c0":"code","a41def1d":"code","bcb4694c":"code","64a78834":"code","6137f3fc":"code","6420d75b":"code","7690b211":"code","eb221640":"code","d24fe2cc":"code","8cb7f0c2":"markdown","07225d24":"markdown"},"source":{"70933cc7":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom datetime import datetime\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action=\"ignore\", category=pd.core.common.SettingWithCopyWarning)\n\npd.set_option('display.max_rows', 160)\npd.set_option('display.max_columns', 160)","1e9e4a96":"train = pd.read_csv(\"..\/input\/hr-analytics-analytcis-vidhya\/train_LZdllcl.csv\")\ntest = pd.read_csv(\"..\/input\/hr-analytics-analytcis-vidhya\/test_2umaH9m.csv\")\n\ntrain_id = train.employee_id\ntest_id = test.employee_id\n\nprint(\"Train set: \", train.shape)\nprint(\"Test set: \", test.shape)\n\ntrain.sample(10)","20ad212f":"train.info()","b68c260b":"train.describe()","0059dad2":"train[train.duplicated()]","90f66ad1":"cat_cols = [\"department\", \"region\", \"gender\", \"recruitment_channel\", \"no_of_trainings\", \"KPIs_met >80%\", \"awards_won?\"]\n\nnum_cols = [\"age\", \"length_of_service\", \"avg_training_score\"]\n\nord_cols = [\"education\", \"previous_year_rating\"]","e85e13a7":"train.is_promoted.value_counts()","3d440964":"fig, ax = plt.subplots(figsize = (8, 8))\n\nax.pie(train.is_promoted.value_counts(), labels = [\"Not Promoted\", \"Promoted\"], \n       autopct = '%1.2f%%', startangle = 180, colors = [\"#0EB8F1\", \"#F1480F\"])\n\nax.set_title(\"Promotion\")\nplt.show()","52fcf782":"df = pd.concat([train, test])\ndf_raw = df.copy()","0176ed8e":"df.isnull().sum()","ed6fd073":"df.loc[df.previous_year_rating.isnull() & (df.length_of_service == 1), \"previous_year_rating\"] = 0","58d5342c":"df.education.value_counts(normalize = True)","8b3a3dc9":"freq_df = df.groupby([\"department\", \"gender\", \"recruitment_channel\"])[\"education\"].value_counts().unstack()\npct_df = freq_df.divide(freq_df.sum(axis=1), axis=0)\n\npct_df[\"new_val\"] = \"\"\nfor i in range(pct_df.shape[0]):\n    if (pct_df.values[i][2] >= 0.30) & (pct_df.values[i][0] < 0.69):\n        pct_df[\"new_val\"][i] = \"Master's & above\"\n    elif (pct_df.values[i][0] >= 0.70) & (pct_df.values[i][2] <= 0.28):\n        pct_df[\"new_val\"][i] = \"Bachelor's\"\n    elif (pct_df.values[i][0] >= 0.70):\n        pct_df[\"new_val\"][i] = \"Bachelor's\"\n    else:\n         pct_df[\"new_val\"][i] = \"Below Secondary\"\n\npct_df","5bad05df":"for i in range(pct_df.shape[0]):\n\n    df.loc[(df.education.isnull()) & (df.department == pct_df.index[i][0]) & (df.gender == pct_df.index[i][1]) & \\\n           (df.recruitment_channel == pct_df.index[i][2]), \"education\"] = pct_df.new_val.values[i]","a77c6caa":"df.isnull().sum()","096290f8":"def count_percentage(df, col, hue):\n\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 6))\n    order = sorted(df[col].unique())\n    palette = [\"#0EB8F1\", \"#F1480F\"]\n    \n    sns.countplot(col, data = df, hue = hue, ax = ax1, order = order, palette = palette)\n    ax1.set_title(\"Counts For Feature:\\n\" + col)\n\n    df_temp = df.groupby(col)[hue].value_counts(normalize = True).\\\n    rename(\"percentage\").\\\n    reset_index()\n    \n    fig = sns.barplot(x = col, y = \"percentage\", hue = hue, data = df_temp, ax = ax2, order = order, palette = palette)\n    fig.set_ylim(0,1)\n    \n    fontsize = 14 if len(order) <= 10 else 8\n    for p in fig.patches:\n        \n        txt = \"{:.1f}\".format(p.get_height() * 100) + \"%\"\n        txt_x = p.get_x() \n        txt_y = p.get_height()\n        fig.text(txt_x + 0.125, txt_y + 0.02,txt, fontsize = fontsize)\n\n    ax2.set_title(\"Percentages For Feature: \\n\" + col)\n    plt.setp(ax1.get_xticklabels(), rotation=70, horizontalalignment='right')\n    plt.setp(ax2.get_xticklabels(), rotation=70, horizontalalignment='right')\n    \n    for ax in [ax1, ax2]:\n        ax.set_facecolor(\"#C7D3D4FF\")\n        ax.grid(linewidth = 0.25)","2848c108":"for col in cat_cols + ord_cols:\n    count_percentage(df, col, \"is_promoted\")","2b63ade0":"def feature_dist_clas(df, col, hue):\n    \n    fig, axes = plt.subplots(1, 4, figsize = (25, 5))\n    order = sorted(df[hue].unique())\n    palette = [\"#0EB8F1\", \"#F1480F\"]\n    \n    sns.histplot(x = col, hue = hue, data = df, ax = axes[0], palette = palette, edgecolor=\"black\", linewidth=0.5)\n    sns.kdeplot(x = col, hue = hue, data = df, fill = True, ax = axes[1], palette = palette, linewidth = 2)\n    sns.boxplot(y = col, hue = hue, data = df, x = [\"\"] * len(df), ax = axes[2], \n                palette = palette, linewidth = 2, flierprops = dict(marker = \"x\", markersize = 3.5))\n    \n    sns.violinplot(y = col, hue = hue, data = df, x = [\"\"] * len(df), ax = axes[3], palette = palette)\n    \n    fig.suptitle(\"For Feature:  \" + col)\n    axes[0].set_title(\"Histogram For Feature \" + col)\n    axes[1].set_title(\"KDE Plot For Feature \" + col)   \n    axes[2].set_title(\"Boxplot For Feature \" + col)   \n    axes[3].set_title(\"Violinplot For Feature \" + col)   \n    \n    for ax in axes:\n        ax.set_facecolor(\"#C7D3D4FF\")\n        ax.grid(linewidth = 0.25)","378c1813":"for col in num_cols:\n    feature_dist_clas(df, col, \"is_promoted\")","85656bee":"df2 = df.copy()","c4fcb18c":"df2[\"is_firstyear\"] = df2[\"length_of_service\"].apply(lambda x: 1 if x==1 else 0)\ndf2[\"starting_age\"] = df2[\"age\"] - df2[\"length_of_service\"]\ndf2[\"total_success\"] = df2[\"avg_training_score\"] + df2[\"KPIs_met >80%\"]*100 + df2[\"awards_won?\"]* 100 + df2[\"previous_year_rating\"]*20","0c5df30d":"rd1 = df2.groupby([\"region\", \"department\"])[\"employee_id\"].count()\nrd2 = df2.groupby([\"region\", \"department\"])[\"age\"].mean()\nrd3 = df2.groupby([\"region\", \"department\"])[\"avg_training_score\"].mean()\nrd4 = df2.groupby([\"region\", \"department\"])[\"total_success\"].mean()\nrd5 = df2.groupby([\"region\", \"department\"])[\"previous_year_rating\"].mean()\nrd6 = df2.groupby([\"region\", \"department\"])[\"length_of_service\"].mean()\nrd7 = df2.groupby([\"region\", \"department\"])[\"is_firstyear\"].sum()\n\n\nfor i in range(rd1.shape[0]):\n    region = rd1.index[i][0]\n    department = rd1.index[i][1]\n\n    df2.loc[(df2.region == region) & (df2.department == department), \"employee_per_department&region\"] = rd1[i]\n    df2.loc[(df2.region == region) & (df2.department == department), \"avg_age_for_department&region\"] = rd2[i]\n    df2.loc[(df2.region == region) & (df2.department == department), \"avg_score_for_department&region\"] = rd3[i]\n    df2.loc[(df2.region == region) & (df2.department == department), \"avg_succes_department&region\"] = rd4[i]\n    df2.loc[(df2.region == region) & (df2.department == department), \"avg_prev_year_rating_department&region\"] = rd5[i]\n    df2.loc[(df2.region == region) & (df2.department == department), \"avg_len_of_service_department&region\"] = rd6[i]\n    df2.loc[(df2.region == region) & (df2.department == department), \"total_rookie_for_department&region\"] = rd7[i]    ","7fe7840f":"df2[\"is_young_in_dep_reg\"] = np.where((df2.age <= df2[\"avg_age_for_department&region\"]), 0, 1)\ndf2[\"better_score_in_dep_reg\"] = np.where((df2[\"avg_score_for_department&region\"] <= df2[\"avg_training_score\"]), 1, 0)\ndf2[\"better_success_in_dep_reg\"] = np.where((df2[\"avg_succes_department&region\"] <= df2[\"total_success\"]), 1, 0)\ndf2[\"better_prev_year_rating_in_dep_reg\"] = np.where((df2[\"avg_prev_year_rating_department&region\"] <= df2[\"previous_year_rating\"]), 1, 0)\ndf2[\"longer_len_of_service_rating_in_dep_reg\"] = np.where((df2[\"avg_len_of_service_department&region\"] <= df2[\"length_of_service\"]), 1, 0)","c39a5882":"d1 = df2.groupby(\"department\")[\"employee_id\"].count()\nd2 = df2.groupby(\"department\")[\"age\"].mean()\nd3 = df2.groupby(\"department\")[\"avg_training_score\"].mean()\nd4 = df2.groupby(\"department\")[\"total_success\"].mean()\nd5 = df2.groupby(\"department\")[\"previous_year_rating\"].mean()\nd6 = df2.groupby(\"department\")[\"length_of_service\"].mean()\nd7 = df2.groupby(\"department\")[\"is_firstyear\"].sum()\n\n\nfor i in range(d1.shape[0]):\n    department = d1.index[i]\n\n    df2.loc[(df2.department == department), \"employee_per_department\"] = d1[i]\n    df2.loc[(df2.department == department), \"avg_age_for_department\"] = d2[i]\n    df2.loc[(df2.department == department), \"avg_score_for_department\"] = d3[i]\n    df2.loc[(df2.department == department), \"avg_succes_department\"] = d4[i]\n    df2.loc[(df2.department == department), \"avg_prev_year_rating_department\"] = d5[i]\n    df2.loc[(df2.department == department), \"avg_len_of_service_department\"] = d6[i]\n    df2.loc[(df2.department == department), \"total_rookie_for_department\"] = d7[i]  ","a553f702":"df2[\"is_young_in_dep\"] = np.where((df2.age <= df2[\"avg_age_for_department\"]), 0, 1)\ndf2[\"better_score_in_dep\"] = np.where((df2[\"avg_score_for_department\"] <= df2[\"avg_training_score\"]), 1, 0)\ndf2[\"better_success_in_dep\"] = np.where((df2[\"avg_succes_department\"] <= df2[\"total_success\"]), 1, 0)\ndf2[\"better_prev_year_rating_in_dep\"] = np.where((df2[\"avg_prev_year_rating_department\"] <= df2[\"previous_year_rating\"]), 1, 0)\ndf2[\"longer_len_of_service_rating_in_dep\"] = np.where((df2[\"avg_len_of_service_department\"] <= df2[\"length_of_service\"]), 1, 0)","ce4f8a8e":"df2[\"education\"] = df2[\"education\"].map({\"Below Secondary\": 1, \"Bachelor's\": 2, \"Master's & above\":3})","439230b2":"df2[\"total_training_score\"] = df2[\"no_of_trainings\"] * df2[\"avg_training_score\"]","2fe5b7fd":"#https:\/\/maxhalford.github.io\/blog\/target-encoding\/\ndef calc_smooth_mean(df, by, on, m):\n    # Compute the global mean\n    mean = df[on].mean()\n\n    # Compute the number of values and the mean of each group\n    agg = df.groupby(by)[on].agg(['count', 'mean'])\n    counts = agg['count']\n    means = agg['mean']\n\n    # Compute the \"smoothed\" means\n    smooth = (counts * means + m * mean) \/ (counts + m)\n\n    # Replace each value by the according smoothed mean\n    return df[by].map(smooth)\n\ndf2[\"region\"] = calc_smooth_mean(df2, \"region\", \"is_promoted\", 300)\ndf2[\"department\"] = calc_smooth_mean(df2, \"department\", \"is_promoted\", 300)","64a04b6e":"from sklearn.metrics import f1_score, make_scorer\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\nimport lightgbm as lgb\n\nfrom hyperopt import hp, tpe\nfrom hyperopt.fmin import fmin","4724d843":"dummies = pd.get_dummies(df2[[\"gender\", \"recruitment_channel\"]], drop_first = True)\n\nfin = pd.concat([df2, dummies], axis = 1).drop([\"gender\", \"recruitment_channel\"], axis = 1)\nfin","dbb37e28":"train = fin[fin.is_promoted.notnull()]\ntest = fin[fin.is_promoted.isnull()]\n\ntarget = \"is_promoted\"\npredictors = [x for x in train.columns if x not in [\"employee_id\", \"is_promoted\"]]","f374495a":"f1_scorer = make_scorer(f1_score)\n\nskf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n\nX_train, X_test, y_train, y_test = train_test_split(train[predictors], train[target], \n                                                    test_size = 0.2, \n                                                    stratify = train[target], \n                                                    random_state = 42)","a281db9b":"def lgb_f1_score(y_true, y_pred):\n    y_pred = np.round(y_pred)\n    return ('F1', f1_score(y_true, y_pred), True)","d4fc3a80":"clf = lgb.LGBMClassifier(objective = \"binary\", n_jobs = -1, random_state = 42, metric=\"F1\", n_estimators = 500)","d98a49c0":"# def objective(params):\n#     params = {\n#         'max_depth': int(params['max_depth']),\n#         'num_leaves': int(params['num_leaves']),\n#         'min_child_samples': int(params['min_child_samples']),\n#         'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n#         'subsample': '{:.3f}'.format(params['subsample']),\n#         'min_split_gain': '{:.3f}'.format(params['min_split_gain']),\n#         'scale_pos_weight': '{:.3f}'.format(params['scale_pos_weight']),\n#         'reg_alpha': '{:.3f}'.format(params['reg_alpha']),\n#         'reg_lambda': '{:.3f}'.format(params['reg_lambda']),\n#     }\n    \n#     clf = lgb.LGBMClassifier(\n#         n_estimators = 500,\n#         learning_rate = 0.1,\n#         n_jobs = -1,\n#         random_state = 42,\n#         **params\n#     )\n    \n#     score = cross_val_score(clf, X_train.values, y_train.values, scoring = f1_scorer, cv = skf).mean()\n#     print(\"F1-score {:.3f} params {}\".format(score, params))\n#     return -score\n\n# space = {\n#     \"max_depth\": hp.quniform('max_depth', 3, 10, 1),\n#     'num_leaves': hp.quniform('num_leaves', 20, 100, 10),\n#     'min_child_samples': hp.quniform('min_child_samples', 50, 150, 10),\n#     'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n#     'subsample': hp.uniform('subsample', 0.3, 1.0),\n#     'min_split_gain': hp.uniform('min_split_gain', 0, 0.5),\n#     'scale_pos_weight': hp.uniform('scale_pos_weight', 2, 4),\n#     'reg_alpha': hp.uniform('reg_alpha', 0, 5),\n#     'reg_lambda': hp.uniform('reg_lambda', 0, 1),\n\n# }\n# rstate = np.random.RandomState(42)\n# best = fmin(fn = objective,\n#             space = space,\n#             algo = tpe.suggest,\n#             max_evals = 150,\n#             rstate = rstate)","a41def1d":"# best","bcb4694c":"{'colsample_bytree': 0.3994433425727357,\n 'max_depth': 5.0,\n 'min_child_samples': 100.0,\n 'min_split_gain': 0.42375288862944277,\n 'num_leaves': 70.0,\n 'reg_alpha': 4.231800280468554,\n 'reg_lambda': 0.276033039672689,\n 'scale_pos_weight': 2.743189307803528,\n 'subsample': 0.9730690656599836}","64a78834":"clf = lgb.LGBMClassifier(n_estimators=10000, learning_rate=0.005, n_jobs = -1, random_state = 42, \n                         colsample_bytree = 0.3994433425727357, max_depth = 5, min_child_samples = 100,\n                         num_leaves = 70, scale_pos_weight = 2.743189307803528, \n                         subsample = 0.9730690656599836, min_split_gain = 0.4990782438045411, \n                         reg_alpha = 4.231800280468554, reg_lambda = 0.276033039672689)","6137f3fc":"clf.fit(train[predictors], train[target],\n        eval_set = [(train[predictors], train[target])], \n        eval_metric = lgb_f1_score, \n        early_stopping_rounds = 200,\n        verbose=500)\n\ny_pred = clf.predict(test[predictors])\npreds = [int(round(x)) for x in y_pred]\n\nsub=pd.DataFrame({\"employee_id\": test_id, \"is_promoted\": preds})\n\nsub.to_csv(\"fin7005.csv\", index=False)","6420d75b":"sub.is_promoted.value_counts()","7690b211":" created_cols = ['is_firstyear', 'is_young_in_dep_reg', 'better_score_in_dep_reg', 'better_success_in_dep_reg', \n                 'better_prev_year_rating_in_dep_reg', 'longer_len_of_service_rating_in_dep_reg', 'employee_per_department',\n                 'is_young_in_dep', 'better_score_in_dep', 'better_success_in_dep',\n                 'better_prev_year_rating_in_dep', 'longer_len_of_service_rating_in_dep']","eb221640":"for col in created_cols:\n    count_percentage(train, col, \"is_promoted\")","d24fe2cc":"fig, ax = plt.subplots(figsize = (20, 10))\nax.set_facecolor(\"#C7D3D4FF\")\nax.grid(linewidth = 0.25)\n\nlgb.plot_importance(clf, ax = ax, title = 'Feature importance for Lightgbm Classifier', max_num_features = 30)\nplt.show()","8cb7f0c2":"**Results:**","07225d24":"https:\/\/www.kaggle.com\/eikedehling\/tune-and-compare-xgb-lightgbm-rf-with-hyperopt"}}