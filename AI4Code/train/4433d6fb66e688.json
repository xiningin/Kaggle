{"cell_type":{"6cd45a60":"code","86dc73d2":"code","a76446b4":"code","cb89a4c8":"code","84fd4ab4":"code","81fa197d":"code","6a870fc2":"code","698a881d":"code","0d3da33f":"code","d1255467":"code","6d48ce0a":"code","b99584bc":"code","5abb7ae4":"code","cc7bb04a":"code","14d01f69":"code","fbd5eced":"code","718e579b":"markdown","34bd8aca":"markdown","ed3b6f11":"markdown","7e6fcc36":"markdown","79a798c8":"markdown","0ffcc86b":"markdown","e62b4236":"markdown","a7b007e0":"markdown","68a7af40":"markdown","c6df2d43":"markdown"},"source":{"6cd45a60":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#Keras \nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n\nimport matplotlib.pyplot as plt #Visualization\nfrom glob import glob \n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","86dc73d2":"train_path = \"..\/input\/fruits\/fruits-360\/Training\/\"\ntest_path = \"..\/input\/fruits\/fruits-360\/Test\/\"","a76446b4":"img = load_img(train_path + \"Apple Braeburn\/0_100.jpg\")\nimg","cb89a4c8":"img = load_img(test_path + \"Apple Braeburn\/3_100.jpg\")\nimg","84fd4ab4":"plt.imshow(img);","81fa197d":"img_to_array(img)","6a870fc2":"img_to_array(img).shape","698a881d":"className = glob(train_path + \"\/*\")\nclassName[:10]","0d3da33f":"numberOfclass = len(className)\nprint(\"There are {} different fruit files...\".format(numberOfclass))","d1255467":"model = Sequential()\n\nmodel.add(Conv2D(32, (3,3), input_shape = (100,100,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D())\n\n\nmodel.add(Conv2D(32, (3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(64, (3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(64, (3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D())\n\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.50))\nmodel.add(Dense(numberOfclass))\nmodel.add(Activation(\"softmax\"))","6d48ce0a":"#Compiling\nmodel.compile(loss = \"categorical_crossentropy\",\n             optimizer = \"rmsprop\",\n             metrics = [\"accuracy\"])","b99584bc":"#Batch Size\nbatch_size = 32","5abb7ae4":"train_datagen = ImageDataGenerator(rescale= 1.\/255,\n                                   shear_range = 0.3,\n                                   horizontal_flip= True,\n                                   zoom_range= 0.3)\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)\n\n\ntrain_generator = train_datagen.flow_from_directory(train_path, \n                                                    target_size = (100,100),\n                                                    batch_size = batch_size,\n                                                    color_mode = \"rgb\",\n                                                    class_mode = \"categorical\")\n\n\ntest_generator = train_datagen.flow_from_directory(test_path, \n                                                    target_size = (100,100),\n                                                    batch_size = batch_size,\n                                                    color_mode = \"rgb\",\n                                                    class_mode = \"categorical\")\n\n\nhist = model.fit_generator(\n                    generator=train_generator,\n                    steps_per_epoch=1600 \/\/ batch_size,\n                    epochs = 50,\n                    validation_data=test_generator,\n                    validation_steps= 800 \/\/ batch_size,\n                    )\n","cc7bb04a":"hist.history.keys()","14d01f69":"plt.plot(hist.history[\"loss\"], label = \"Train Loss\")\nplt.plot(hist.history[\"val_loss\"], label = \"Validation Loss\")\nplt.legend()","fbd5eced":"plt.plot(hist.history[\"accuracy\"], label = \"Train acc\")\nplt.plot(hist.history[\"val_accuracy\"], label = \"Validation acc\")\nplt.legend()","718e579b":"If you want to dive deeper , you can look at [DATAI TEAM](https:\/\/www.kaggle.com\/kanncaa1\/notebooks)","34bd8aca":"## Converting Image to Array","ed3b6f11":"**Both the above apples are the same kind therefore noticing the differences between them can be a little hard. If you want to use matplotlib to show images, it is possible.**","7e6fcc36":"Looking at one image in the Traning file.","79a798c8":"Looking at one image in the Test file.","0ffcc86b":"### Creating CNN Model","e62b4236":"### Taking The Data Sets.","a7b007e0":"### Data Generation","68a7af40":"### Learning How Many Different Files Are In Training and Test Files.","c6df2d43":"### Model Evaluation"}}