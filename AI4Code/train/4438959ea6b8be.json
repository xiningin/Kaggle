{"cell_type":{"18abfd66":"code","6b41bf97":"code","4537fe96":"code","03e1cd4a":"code","13b778d4":"code","b72dec9e":"code","eb8e0d53":"code","41870e12":"code","a9e970fa":"code","d649e0f7":"code","fc2e2daa":"code","d300d39e":"code","42b1382f":"code","c42e4f27":"code","ab108262":"code","6b95323f":"code","a7996f6d":"code","a4dc3e46":"code","f89c8604":"code","b9244179":"code","7f2a6d21":"code","450b3d42":"code","ed862c86":"code","8ef38258":"code","b7cccfd4":"code","ed0854e2":"code","5bfc8152":"code","6a18d4a2":"code","f234861e":"code","330d5f55":"code","1d9511af":"code","1fe4deda":"code","dd08e340":"code","d118348b":"code","f15dd131":"code","1a59a3e1":"code","f1e89ded":"code","d933b8e5":"code","28262ce6":"code","3a0a8f62":"code","10e52e4d":"code","fc1d1d13":"code","902f275f":"code","72d1d151":"code","5affd9b9":"code","ee7fd6a4":"code","a46c4e01":"code","299ed4c7":"code","77188c18":"code","579793f7":"code","307ddeb2":"code","8c227ae9":"code","1245b144":"code","b97fa10b":"code","50c6f24a":"code","23257c2c":"code","60117db6":"code","c57fde36":"code","b7d7d050":"code","777dfdd9":"code","78ce87bd":"code","222c4e17":"code","0d29ebfd":"code","fe0e1540":"code","f87f1805":"code","ba75231d":"code","21517e22":"code","0e2ae329":"code","48cd595f":"code","d6fc6fdb":"code","dbdd9891":"code","1541126e":"markdown","fc51e384":"markdown","7568723e":"markdown","4db08580":"markdown","2e2d2154":"markdown","3bfee2ec":"markdown","3445903e":"markdown","2aa18005":"markdown","bbe6795a":"markdown","b442503d":"markdown","a661fad9":"markdown","27e7b903":"markdown","ce1d49f7":"markdown","e4285884":"markdown","700ace45":"markdown","a4ac1767":"markdown","ca57253d":"markdown","354f9a5d":"markdown","3a104b2b":"markdown","d2e25462":"markdown","e8df63e7":"markdown","64bf3445":"markdown","a7414ae4":"markdown","1d682cb3":"markdown","e5631f79":"markdown","0f0de9ae":"markdown"},"source":{"18abfd66":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom collections import Counter #counter\u5de5\u5177\u7528\u4e8e\u652f\u6301\u4fbf\u6377\u548c\u5feb\u901f\u5730\u8ba1\u6570\n#\u968f\u673a\u68ee\u6797\u3001\u96c6\u6210\u5206\u7c7b\u3001\u68af\u5ea6\u5206\u7c7b\u3001\u6781\u9650\u968f\u673a\u6811\u3001\u6295\u7968\u5206\u7c7b\u5668\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis #\u7ebf\u6027\u5224\u522b\u5206\u6790\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n\nsns.set(style='white', context='notebook', palette='deep')","6b41bf97":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\nIDtest = test[\"PassengerId\"]\nprint(train.head())","4537fe96":"#\u5f02\u5e38\u503c\u68c0\u6d4b\u51fd\u6570\ndef detect_outliers(df,n,features):\n    outlier_indices = []\n    for col in features:\n#         print(col)\n        Q1 = np.percentile(df[col],25)  #\u8ba1\u7b97\u5217\u767e\u5206\u4f4d\u6570\n        Q3 = np.percentile(df[col],75)\n        IQR=Q3-Q1\n        outlier_step = 1.5*IQR\n#         print(IQR,outlier_step)\n        outlier_list_col=df[(df[col]<Q1-outlier_step)|(df[col]>Q3+outlier_step)].index\n#         print(outlier_list_col)\n        outlier_indices.extend(outlier_list_col)\n#     print(outlier_indices)\n    outlier_indices=Counter(outlier_indices)\n#     print(outlier_indices)\n    multiple_outliers = list(k for k,v in outlier_indices.items() if v>n)\n#     print(multiple_outliers)\n    return multiple_outliers\n\nOutliers_to_drop = detect_outliers(train,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])\n# print(train.loc[Outliers_to_drop])\ntrain=train.drop(Outliers_to_drop,axis=0).reset_index(drop=True)\nprint(train.info())","03e1cd4a":"train_len = len(train)\nprint(train_len)\ndataset = pd.concat(objs=[train,test],axis=0).reset_index(drop=True)\nprint(dataset.info())","13b778d4":"dataset = dataset.fillna(np.nan)\nprint(dataset.isnull().sum())","b72dec9e":"print(train.info())\nprint(train.isnull().sum())","eb8e0d53":"print(train.dtypes)","41870e12":"print(train.describe())","a9e970fa":"g = sns.heatmap(train[[\"Survived\",\"SibSp\",\"Parch\",\"Age\",\"Fare\"]].corr(),annot=True,fmt=\".2f\",cmap=\"coolwarm\")","d649e0f7":"g = sns.factorplot(x=\"SibSp\",y=\"Survived\",data=train,kind=\"bar\", size = 6 , \npalette = \"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","fc2e2daa":"g = sns.FacetGrid(train,col='Survived')\ng = g.map(sns.distplot,\"Age\")","d300d39e":"g = sns.kdeplot(train[\"Age\"][(train[\"Survived\"] == 0) & (train[\"Age\"].notnull())], color=\"Red\", shade = True)\ng = sns.kdeplot(train[\"Age\"][(train[\"Survived\"] == 1) & (train[\"Age\"].notnull())], ax =g, color=\"Blue\", shade= True)\ng.set_xlabel(\"Age\")\ng.set_ylabel(\"Frequency\")\ng = g.legend([\"Not Survived\",\"Survived\"])","42b1382f":"dataset[\"Fare\"] = dataset[\"Fare\"].fillna(dataset[\"Fare\"].median())","c42e4f27":"g = sns.distplot(dataset[\"Fare\"], color=\"m\", label=\"Skewness : %.2f\"%(dataset[\"Fare\"].skew()))\ng = g.legend(loc=\"best\")","ab108262":"dataset[\"Fare\"] = dataset[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)\nprint(dataset.head())","6b95323f":"g = sns.distplot(dataset[\"Fare\"], color=\"b\", label=\"Skewness : %.2f\"%(dataset[\"Fare\"].skew()))\ng = g.legend(loc=\"best\")","a7996f6d":"g = sns.barplot(x=\"Sex\",y=\"Survived\",data=train)\ng = g.set_ylabel(\"Survival Probability\")","a4dc3e46":"train[[\"Sex\",\"Survived\"]].groupby('Sex').mean()","f89c8604":"g = sns.factorplot(x=\"Pclass\",y=\"Survived\",data=train,kind=\"bar\", size = 6 , \npalette = \"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","b9244179":"g = sns.factorplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=train,\n                   size=6, kind=\"bar\", palette=\"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","7f2a6d21":"dataset[\"Embarked\"].isnull().sum()","450b3d42":"dataset[\"Embarked\"] = dataset[\"Embarked\"].fillna(\"S\")","ed862c86":"g = sns.factorplot(x=\"Embarked\", y=\"Survived\",  data=train,\n                   size=6, kind=\"bar\", palette=\"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","8ef38258":"g = sns.factorplot(\"Pclass\", col=\"Embarked\",  data=train,\n                   size=6, kind=\"count\", palette=\"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"Count\")","b7cccfd4":"g = sns.factorplot(y=\"Age\",x=\"Sex\",data=dataset,kind=\"box\")\ng = sns.factorplot(y=\"Age\",x=\"Sex\",hue=\"Pclass\", data=dataset,kind=\"box\")\ng = sns.factorplot(y=\"Age\",x=\"Parch\", data=dataset,kind=\"box\")\ng = sns.factorplot(y=\"Age\",x=\"SibSp\", data=dataset,kind=\"box\")","ed0854e2":"dataset[\"Sex\"] = dataset[\"Sex\"].map({\"male\": 0, \"female\":1})","5bfc8152":"g = sns.heatmap(dataset[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\"]].corr(),cmap=\"BrBG\",annot=True)","6a18d4a2":"index_NaN_age = list(dataset[\"Age\"][dataset[\"Age\"].isnull()].index)\n\nfor i in index_NaN_age :\n    age_med = dataset[\"Age\"].median()\n    age_pred = dataset[\"Age\"][((dataset['SibSp'] == dataset.iloc[i][\"SibSp\"]) & (dataset['Parch'] == dataset.iloc[i][\"Parch\"]) & (dataset['Pclass'] == dataset.iloc[i][\"Pclass\"]))].median()\n    if not np.isnan(age_pred) :\n        dataset['Age'].iloc[i] = age_pred\n    else :\n        dataset['Age'].iloc[i] = age_med","f234861e":"g = sns.factorplot(x=\"Survived\", y = \"Age\",data = train, kind=\"box\")\ng = sns.factorplot(x=\"Survived\", y = \"Age\",data = train, kind=\"violin\")","330d5f55":"dataset[\"Name\"].head()","1d9511af":"dataset_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in dataset[\"Name\"]]\ndataset[\"Title\"] = pd.Series(dataset_title)\ndataset[\"Title\"].head()","1fe4deda":"g = sns.countplot(x=\"Title\",data=dataset)\ng = plt.setp(g.get_xticklabels(), rotation=45) ","dd08e340":"dataset[\"Title\"] = dataset[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ndataset[\"Title\"] = dataset[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\nprint(dataset[\"Title\"].drop_duplicates())","d118348b":"g = sns.countplot(dataset[\"Title\"])\ng = g.set_xticklabels([\"Master\",\"Miss\/Ms\/Mme\/Mlle\/Mrs\",\"Mr\",\"Rare\"])","f15dd131":"g = sns.factorplot(x=\"Title\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_xticklabels([\"Master\",\"Miss-Mrs\",\"Mr\",\"Rare\"])\ng = g.set_ylabels(\"survival probability\")","1a59a3e1":"dataset.drop(labels = [\"Name\"], axis = 1, inplace = True)","f1e89ded":"dataset[\"Fsize\"] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1","d933b8e5":"g = sns.factorplot(x=\"Fsize\",y=\"Survived\",data = dataset)\ng = g.set_ylabels(\"Survival Probability\")","28262ce6":"dataset['Single'] = dataset['Fsize'].map(lambda s: 1 if s == 1 else 0)\ndataset['SmallF'] = dataset['Fsize'].map(lambda s: 1 if  s == 2  else 0)\ndataset['MedF'] = dataset['Fsize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ndataset['LargeF'] = dataset['Fsize'].map(lambda s: 1 if s >= 5 else 0)","3a0a8f62":"g = sns.factorplot(x=\"Single\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_ylabels(\"Survival Probability\")\ng = sns.factorplot(x=\"SmallF\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_ylabels(\"Survival Probability\")\ng = sns.factorplot(x=\"MedF\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_ylabels(\"Survival Probability\")\ng = sns.factorplot(x=\"LargeF\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_ylabels(\"Survival Probability\")","10e52e4d":"dataset = pd.get_dummies(dataset, columns = [\"Title\"])\ndataset = pd.get_dummies(dataset, columns = [\"Embarked\"], prefix=\"Em\")","fc1d1d13":"dataset.head()","902f275f":"dataset[\"Cabin\"].head()","72d1d151":"dataset[\"Cabin\"].describe()","5affd9b9":"dataset[\"Cabin\"].isnull().sum()","ee7fd6a4":"dataset[\"Cabin\"][dataset[\"Cabin\"].notnull()].head()","a46c4e01":"dataset[\"Cabin\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in dataset['Cabin'] ])","299ed4c7":"g = sns.countplot(dataset[\"Cabin\"],order=['A','B','C','D','E','F','G','T','X'])","77188c18":"g = sns.factorplot(y=\"Survived\",x=\"Cabin\",data=dataset,kind=\"bar\",order=['A','B','C','D','E','F','G','T','X'])\ng = g.set_ylabels(\"Survival Probability\")","579793f7":"dataset = pd.get_dummies(dataset, columns = [\"Cabin\"],prefix=\"Cabin\")","307ddeb2":"dataset[\"Ticket\"].head()","8c227ae9":"Ticket = []\nfor i in list(dataset.Ticket):\n    if not i.isdigit() :\n        Ticket.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(' ')[0]) #Take prefix\n    else:\n        Ticket.append(\"X\")\n        \ndataset[\"Ticket\"] = Ticket\ndataset[\"Ticket\"].head()","1245b144":"dataset = pd.get_dummies(dataset, columns = [\"Ticket\"], prefix=\"T\")","b97fa10b":"dataset[\"Pclass\"] = dataset[\"Pclass\"].astype(\"category\")\ndataset = pd.get_dummies(dataset, columns = [\"Pclass\"],prefix=\"Pc\")","50c6f24a":"dataset.drop(labels = [\"PassengerId\"], axis = 1, inplace = True)","23257c2c":"dataset.head()","60117db6":"train = dataset[:train_len]\ntest = dataset[train_len:]\ntest.drop(labels=[\"Survived\"],axis = 1,inplace=True)","c57fde36":"train[\"Survived\"] = train[\"Survived\"].astype(int)\n\nY_train = train[\"Survived\"]\n\nX_train = train.drop(labels = [\"Survived\"],axis = 1)","b7d7d050":"#\u6837\u672c\u4ea4\u53c9\u9a8c\u8bc1\u65b9\u6cd5\nkfold = StratifiedKFold(n_splits=10)","777dfdd9":"random_state = 2\nclassifiers = []\nclassifiers.append(SVC(random_state=random_state))\nclassifiers.append(DecisionTreeClassifier(random_state=random_state))\nclassifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1))\nclassifiers.append(RandomForestClassifier(random_state=random_state))\nclassifiers.append(ExtraTreesClassifier(random_state=random_state))\nclassifiers.append(GradientBoostingClassifier(random_state=random_state))\nclassifiers.append(MLPClassifier(random_state=random_state))\nclassifiers.append(KNeighborsClassifier())\nclassifiers.append(LogisticRegression(random_state = random_state))\nclassifiers.append(LinearDiscriminantAnalysis())\n\ncv_results = []\nfor classifier in classifiers :\n    cv_results.append(cross_val_score(classifier, X_train, y = Y_train, scoring = \"accuracy\", cv = kfold, n_jobs=4))\n\ncv_means = []\ncv_std = []\nfor cv_result in cv_results:\n    cv_means.append(cv_result.mean())\n    cv_std.append(cv_result.std())\n\ncv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":[\"SVC\",\"DecisionTree\",\"AdaBoost\",\n\"RandomForest\",\"ExtraTrees\",\"GradientBoosting\",\"MultipleLayerPerceptron\",\"KNeighboors\",\"LogisticRegression\",\"LinearDiscriminantAnalysis\"]})\n\ng = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\ng.set_xlabel(\"Mean Accuracy\")\ng = g.set_title(\"Cross validation scores\")","78ce87bd":"# Adaboost\nDTC = DecisionTreeClassifier()\n\nadaDTC = AdaBoostClassifier(DTC, random_state=7)\n\nada_param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n              \"base_estimator__splitter\" :   [\"best\", \"random\"],\n              \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n              \"n_estimators\" :[1,2],\n              \"learning_rate\":  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5]}\n\ngsadaDTC = GridSearchCV(adaDTC,param_grid = ada_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsadaDTC.fit(X_train,Y_train)\n\nada_best = gsadaDTC.best_estimator_\nprint(ada_best)","222c4e17":"gsadaDTC.best_score_","0d29ebfd":"#ExtraTrees \nExtC = ExtraTreesClassifier()\n\n\n## Search grid for optimal parameters\nex_param_grid = {\"max_depth\": [None],\n              \"max_features\": [1, 3, 10],\n              \"min_samples_split\": [2, 3, 10],\n              \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [False],\n              \"n_estimators\" :[100,300],\n              \"criterion\": [\"gini\"]}\n\n\ngsExtC = GridSearchCV(ExtC,param_grid = ex_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsExtC.fit(X_train,Y_train)\n\nExtC_best = gsExtC.best_estimator_\n\n# Best score\ngsExtC.best_score_","fe0e1540":"# RFC Parameters tunning \nRFC = RandomForestClassifier()\n\n\n## Search grid for optimal parameters\nrf_param_grid = {\"max_depth\": [None],\n              \"max_features\": [1, 3, 10],\n              \"min_samples_split\": [2, 3, 10],\n              \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [False],\n              \"n_estimators\" :[100,300],\n              \"criterion\": [\"gini\"]}\n\n\ngsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsRFC.fit(X_train,Y_train)\n\nRFC_best = gsRFC.best_estimator_\n\n# Best score\ngsRFC.best_score_","f87f1805":"# Gradient boosting tunning\n\nGBC = GradientBoostingClassifier()\ngb_param_grid = {'loss' : [\"deviance\"],\n              'n_estimators' : [100,200,300],\n              'learning_rate': [0.1, 0.05, 0.01],\n              'max_depth': [4, 8],\n              'min_samples_leaf': [100,150],\n              'max_features': [0.3, 0.1] \n              }\n\ngsGBC = GridSearchCV(GBC,param_grid = gb_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsGBC.fit(X_train,Y_train)\n\nGBC_best = gsGBC.best_estimator_\n\n# Best score\ngsGBC.best_score_","ba75231d":"### SVC classifier\nSVMC = SVC(probability=True)\nsvc_param_grid = {'kernel': ['rbf'], \n                  'gamma': [ 0.001, 0.01, 0.1, 1],\n                  'C': [1, 10, 50, 100,200,300, 1000]}\n\ngsSVMC = GridSearchCV(SVMC,param_grid = svc_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsSVMC.fit(X_train,Y_train)\n\nSVMC_best = gsSVMC.best_estimator_\n\n# Best score\ngsSVMC.best_score_","21517e22":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"Generate a simple plot of the test and training learning curve\"\"\"\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt\n\ng = plot_learning_curve(gsRFC.best_estimator_,\"RF mearning curves\",X_train,Y_train,cv=kfold)\ng = plot_learning_curve(gsExtC.best_estimator_,\"ExtraTrees learning curves\",X_train,Y_train,cv=kfold)\ng = plot_learning_curve(gsSVMC.best_estimator_,\"SVC learning curves\",X_train,Y_train,cv=kfold)\ng = plot_learning_curve(gsadaDTC.best_estimator_,\"AdaBoost learning curves\",X_train,Y_train,cv=kfold)\ng = plot_learning_curve(gsGBC.best_estimator_,\"GradientBoosting learning curves\",X_train,Y_train,cv=kfold)","0e2ae329":"nrows = ncols = 2\nfig, axes = plt.subplots(nrows = nrows, ncols = ncols, sharex=\"all\", figsize=(15,15))\n\nnames_classifiers = [(\"AdaBoosting\", ada_best),(\"ExtraTrees\",ExtC_best),(\"RandomForest\",RFC_best),(\"GradientBoosting\",GBC_best)]\n\nnclassifier = 0\nfor row in range(nrows):\n    for col in range(ncols):\n        name = names_classifiers[nclassifier][0]\n        classifier = names_classifiers[nclassifier][1]\n        indices = np.argsort(classifier.feature_importances_)[::-1][:40]\n        g = sns.barplot(y=X_train.columns[indices][:40],x = classifier.feature_importances_[indices][:40] , orient='h',ax=axes[row][col])\n        g.set_xlabel(\"Relative importance\",fontsize=12)\n        g.set_ylabel(\"Features\",fontsize=12)\n        g.tick_params(labelsize=9)\n        g.set_title(name + \" feature importance\")\n        nclassifier += 1","48cd595f":"test_Survived_RFC = pd.Series(RFC_best.predict(test), name=\"RFC\")\ntest_Survived_ExtC = pd.Series(ExtC_best.predict(test), name=\"ExtC\")\ntest_Survived_SVMC = pd.Series(SVMC_best.predict(test), name=\"SVC\")\ntest_Survived_AdaC = pd.Series(ada_best.predict(test), name=\"Ada\")\ntest_Survived_GBC = pd.Series(GBC_best.predict(test), name=\"GBC\")\n\n\n# Concatenate all classifier results\nensemble_results = pd.concat([test_Survived_RFC,test_Survived_ExtC,test_Survived_AdaC,test_Survived_GBC, test_Survived_SVMC],axis=1)\n\n\ng= sns.heatmap(ensemble_results.corr(),annot=True)","d6fc6fdb":"votingC = VotingClassifier(estimators=[('rfc', RFC_best), ('extc', ExtC_best),\n('svc', SVMC_best), ('adac',ada_best),('gbc',GBC_best)], voting='soft', n_jobs=4)\n\nvotingC = votingC.fit(X_train, Y_train)","dbdd9891":"test_Survived = pd.Series(votingC.predict(test), name=\"Survived\")\n\nresults = pd.concat([IDtest,test_Survived],axis=1)\nprint(results)\n\nresults.to_csv(\"ensemble_python_voting.csv\",index=False)","1541126e":"2.2\u3001\u5f02\u5e38\u503c\u68c0\u6d4b","fc51e384":"3\u3001\u7279\u5f81\u5206\u6790\n    3.1\u3001\u6570\u503c","7568723e":"**5.3 Cabin**","4db08580":"**Fare**","2e2d2154":"\u6a21\u578b\u5efa\u7acb\u548c\u4f18\u5316\u5b8c\u6210\u3002","3bfee2ec":"**5\u3001\u7279\u5f81\u5de5\u7a0b**\n* **5.1 \u59d3\u540d\u548c\u6807\u9898**","3445903e":"3.2\u3001\u7c7b\u522b\u7279\u5f81\n*     Sex","2aa18005":"**6.1 \u7b80\u5355\u6a21\u578b**\n* 6.1.1\u4ea4\u53c9\u9a8c\u8bc1\u6a21\u578b\n     * SVC\n    * Decision Tree\n    * AdaBoost\n    * Random Forest\n    * Extra Trees\n    * Gradient Boosting\n    * Multiple layer perceprton (neural network)\n    * KNN\n    * Logistic regression\n    * Linear Discriminant Analysis","bbe6795a":"**6.2 \u5408\u5e76\u6a21\u578b**\n* **6.2.1 \u8fde\u63a5\u6a21\u578b**","b442503d":"2\u3001\u52a0\u8f7d\u6838\u67e5\u6570\u636e\n    2.1 \u52a0\u8f7d\u6570\u636e","a661fad9":"**5.2 \u5bb6\u5ead\u6210\u5458**","27e7b903":"**6.1.4 \u5206\u7c7b\u7279\u5f81\u7684\u91cd\u8981\u6027\u6392\u5e8f**","ce1d49f7":"**Embarked**","e4285884":"**6.1.2 \u53c2\u6570\u8c03\u4f18**","700ace45":"**Pclass**","a4ac1767":"**6\u3001\u6a21\u578b**","ca57253d":"2.3\u3001\u8fde\u63a5\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e","354f9a5d":"**6.3 \u9884\u6d4b\u6a21\u578b\uff1a\u9884\u6d4b\u5e76\u63d0\u4ea4**","3a104b2b":"**\u6cf0\u5854\u5c3c\u514b\u751f\u5b58\u9884\u6d4b**\n> Bear xiong\n14\/06\/2018\n\n* 1\u3001\u9879\u76ee\u4ecb\u7ecd\n* 2\u3001\u52a0\u8f7d\u6838\u67e5\u6570\u636e\n    *     2.1\u3001\u52a0\u8f7d\u6570\u636e\n    *     2.2\u3001\u79bb\u6563\u503c\u68c0\u6d4b\n    *     2.3\u3001\u8fde\u63a5\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\n    *     2.4\u3001\u68c0\u6d4b\u63a7\u5236\u548c\u7f3a\u5931\u503c\n* 3\u3001\u7279\u5f81\u5206\u6790\n    *     3.1\u3001\u6570\u503c\n    *     3.2\u3001\u5206\u7c7b\u503c\n* 4\u3001\u586b\u5145\u7f3a\u5931\u503c\n    *     4.1\u3001\u5e74\u9f84\n    *     4.2\u3001\u8239\u8231\n* 5\u3001\u7279\u5f81\u5de5\u7a0b\n    *     5.1\u3001\u540d\u5b57\/\u6807\u9898\n    *     5.2\u3001\u5bb6\u5ead\u4eba\u5458\n    *     5.3\u3001\u8239\u8231\n    *     5.4\u3001\u7968\u53f7\n* 6\u3001\u6a21\u578b\u5efa\u7acb\n    *     6.1\u3001\u5355\u4e00\u7b97\u6cd5\u5efa\u6a21\n        *         6.1.1\u3001\u4ea4\u53c9\u9a8c\u8bc1\u6a21\u578b\n        *         6.1.2\u3001\u53c2\u6570\u8c03\u4f18\u5230\u6700\u4f73\u6a21\u578b\n        *         6.1.3\u3001\u7ed8\u5236\u5b66\u4e60\u66f2\u7ebf\n        *         6.1.4\u3001\u57fa\u4e8e\u6811\u5206\u7c7b\u7684\u7279\u5f81\u91cd\u8981\u6027\n    * 6.2\u3001\u591a\u7b97\u6cd5\u96c6\u6210\u5efa\u6a21\n        *     6.2.1\u3001\u7ec4\u5408\u6a21\u578b\n    * 6.3\u3001\u6a21\u578b\u9884\u6d4b\u68c0\u9a8c\n        *     6.3.1\u3001\u9884\u6d4b\u5e76\u63d0\u4ea4\u7ed3\u679c","d2e25462":"**6.1.3 \u7ed8\u5236\u5b66\u4e60\u66f2\u7ebf**","e8df63e7":"**Age**","64bf3445":"**SibSp**","a7414ae4":"1\u3001\u9879\u76ee\u4ecb\u7ecd\n    \u57fa\u4e8e\u6837\u672c\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u8fc7\u7a0b\u4e2d\u9700\u8981\u7ecf\u5386\u6570\u636e\u63a2\u7d22\u3001\u6570\u636e\u5206\u6790\u3001\u6570\u636e\u9884\u5904\u7406\u3001\u6570\u636e\u5efa\u6a21\u3001\u6570\u636e\u53c2\u6570\u8c03\u4f18\u3001\u6a21\u578b\u7ed3\u679c\u6821\u9a8c\u3001\u9884\u6d4b\u7ed3\u679c\u51e0\u4e2a\u6b65\u9aa4\u3002\n* \uff081\uff09\u6570\u636e\u63a2\u7d22\n* \uff082\uff09\u6570\u636e\u5206\u6790\n* \uff083\uff09\u6570\u636e\u9884\u5904\u7406\n* \uff084\uff09\u6570\u636e\u5efa\u6a21\n* \uff085\uff09\u53c2\u6570\u8c03\u8282\n* \uff086\uff09\u7ed3\u679c\u9884\u6d4b","1d682cb3":"**4\u3001\u586b\u5145\u7f3a\u5931\u503c**\n* **4.1 Age**","e5631f79":"**5.4\u3001Ticket**","0f0de9ae":"2.4\u3001\u6838\u67e5\u7a7a\u503c\u548c\u7f3a\u5931\u503c"}}