{"cell_type":{"f37ea71e":"code","b5adefc2":"code","5bd9747f":"code","db9af640":"code","0de40daa":"code","d8ae52b2":"code","d773c0eb":"code","8194baa2":"code","5ad1a0bf":"code","59e8d1eb":"code","77d762fb":"code","5657fe99":"code","4e090261":"code","9be233ec":"code","00a626ec":"code","50d521ca":"code","0334a9bb":"code","b58c998e":"code","cba01aeb":"code","615e4e89":"code","8c3b2df4":"code","5cd53c6a":"code","5c166270":"code","857822bb":"code","7f7f82e6":"code","6dc71321":"code","1c753210":"code","0cd175a6":"code","c11e08b7":"code","316a5147":"code","5a3af703":"code","b2572130":"code","a5061951":"code","b65aa60c":"code","707dfa78":"code","65221d1e":"code","6e8f5178":"code","f920feaa":"code","327c5811":"code","5cd977b3":"code","02882528":"code","01206b3b":"code","f79b6806":"code","0036ed2f":"code","ba23511b":"code","1ac1af29":"code","ea7d0c2f":"code","8950e599":"code","73cc527d":"code","f53391f1":"code","55f63191":"code","cf79c039":"code","943453c9":"code","9146633b":"code","64522fa2":"code","667e621c":"code","2bc5373b":"code","d3da8f56":"code","beeaf825":"code","b92a9458":"code","a2fe8060":"code","14765fb4":"code","f40595b3":"code","adc64a73":"code","3a7e1249":"code","035b931d":"code","2124160a":"code","878f6759":"code","b6264a3d":"code","f22efe21":"code","cb384d8d":"code","ff7ed69e":"code","d8b0ebca":"code","020935f8":"code","30887dae":"markdown"},"source":{"f37ea71e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b5adefc2":"https:\/\/towardsdatascience.com\/pytorch-basics-sampling-samplers-2a0f29f0bf2a","5bd9747f":"import torch\nimport torchvision\nfrom torchvision.datasets import MNIST\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","db9af640":"dataset = MNIST(root='data\/', download=True)","0de40daa":"len(dataset)","d8ae52b2":"MNIST","d773c0eb":"dataset","8194baa2":"test_dataset = MNIST(root='data\/', train=False)\nlen(test_dataset)","5ad1a0bf":"test_dataset","59e8d1eb":"dataset[0]\n","77d762fb":"img,label=dataset[0]","5657fe99":"plt.imshow(img,cmap=\"gray\")","4e090261":"import torchvision.transforms as transforms","9be233ec":"dataset = MNIST(root='data\/', \n                train=True,\n                transform=transforms.ToTensor())","00a626ec":"dataset","50d521ca":"img_tensor, label = dataset[0]\nprint(img_tensor.shape, label)","0334a9bb":"plt.imshow(img_tensor[0][:][:])","b58c998e":"from torch.utils.data import random_split\n\ntrain_ds, val_ds = random_split(dataset, [50000, 10000])\nlen(train_ds), len(val_ds)","cba01aeb":"train_ds","615e4e89":"def split_indices(dataset,pct):\n    n=len(dataset)\n    n_val=int(pct*n)\n    idxs=np.random.permutation(n)\n    return idxs[:n_val],idxs[n_val:]","8c3b2df4":"val_indices,train_indices=split_indices(dataset,0.2)","5cd53c6a":"val_indices","5c166270":"from torch.utils.data.sampler import SubsetRandomSampler \nfrom torch.utils.data.dataloader import DataLoader ","857822bb":"train_sampler=SubsetRandomSampler(train_indices)\n","7f7f82e6":"train_sampler","6dc71321":"test_sampler=SubsetRandomSampler(val_indices)\n","1c753210":"?SubsetRandomSampler","0cd175a6":"iterator_obj = iter(train_sampler)\n  \nprint(next(iterator_obj))\nprint(next(iterator_obj))\nprint(next(iterator_obj))\n","c11e08b7":"iterator_obj = iter(train_sampler)\n  \nprint(next(iterator_obj))\nprint(next(iterator_obj))\nprint(next(iterator_obj))","316a5147":"train_ds[0]","5a3af703":"len(train_ds)","b2572130":"batch_size=100\ntrain_loader=DataLoader(dataset,batch_size,sampler=train_sampler)\nval_loader=DataLoader(dataset,batch_size,sampler=test_sampler)","a5061951":"batch_size=100\ntrain_loader = DataLoader(train_ds, batch_size, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size)","b65aa60c":"iterator_obj = train_loader.__iter__()\n  \nprint(len(next(iterator_obj)[0][0][0][0]))\nprint(next(iterator_obj))\nprint(next(iterator_obj))","707dfa78":"import torch.nn as nn","65221d1e":"input_size=784\nclasses=10","6e8f5178":"model=nn.Linear(784,10)","f920feaa":"print(model.parameters())","327c5811":"\nmodel.weight.shape,model.bias.shape\n","5cd977b3":"for images, labels in train_loader:\n    print(labels)\n    print(images.shape)\n    outputs = model(images)\n    print(outputs)\n    plt.imshow(images[0][0])\n    break","02882528":"for images, labels in train_loader:\n    print(labels)\n    print(images.shape)\n    outputs = model(images)\n    print(outputs)\n    break","01206b3b":"class MnistModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear=nn.Linear(input_size,classes)\n        \n    def forward(self,xb):\n        xb=xb.reshape(-1,784)\n        out=self.linear(xb)\n        return out","f79b6806":"model2=MnistModel()","0036ed2f":"model2.linear","ba23511b":"print(model2.linear.weight.shape, model2.linear.bias.shape)\nlist(model2.parameters())","1ac1af29":"import torch.nn.functional as F","ea7d0c2f":"for images, labels in train_loader:\n    print(images.shape)\n    outputs = model2(images)\n    break\n\nprint('outputs.shape : ', outputs.shape)\nprint('Sample outputs :\\n', outputs[:2].data)","8950e599":"probs = F.softmax(outputs[:2], dim=1)\nprobs2 = F.softmax(outputs[:2], dim=0)","73cc527d":"torch.sum(probs[0])","f53391f1":"torch.sum(probs2[0])","55f63191":"probs","cf79c039":"max_probs, preds = torch.max(probs, dim=1)\nprint(preds)\nprint(max_probs)","943453c9":"loss_fn = F.cross_entropy\n# Loss for current batch of data\nloss = loss_fn(outputs, labels)\nprint(loss)","9146633b":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))","64522fa2":"accuracy(outputs, labels)","667e621c":"def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    optimizer = opt_func(model.parameters(), lr)\n    history = [] # for recording epoch-wise results\n    \n    for epoch in range(epochs):\n        \n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        \n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result)\n        history.append(result)\n\n    return history","2bc5373b":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)","d3da8f56":"def accuracy(outputs, labels): \n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))","beeaf825":"torch.tensor(torch.sum(x[0]==y[0]).item() \/ 10)","b92a9458":"x = torch.tensor([[1, 4, 3], [4, 5, 6]])\ny = torch.tensor([[1, 2, 3], [4, 5, 6]])","a2fe8060":"input_size = 28*28\nnum_classes = 10","14765fb4":"class MnistModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(input_size, num_classes)\n        \n    def forward(self, xb):\n        xb = xb.reshape(-1, 784)\n        out = self.linear(xb)\n        return out\n    \n    def training_step(self,batch):\n        image,labels=batch\n        out=self(image)\n        loss=F.cross_entropy(out,labels)\n        return loss\n    \n    def validation_step(self,batch):\n        image,labels=batch\n        out=self(images)\n        loss=F.cross_entropy(out,labels)\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss, 'val_acc': acc}\n    \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n    \nmodel = MnistModel()","f40595b3":"fit(10, 0.01, model, train_loader, val_loader)","adc64a73":"fit(20, 0.001, model, train_loader, val_loader)","3a7e1249":"a=torch.randn(2,3)\nb=torch.randn(2,3)\nprint(a.size())  # 2, 3, 4\nprint(b.size()) # 2, 3, 4\n\nf=torch.stack([a, b], dim=2).mean()  # 2, 3, 2, 4\nf.item()","035b931d":"f","2124160a":"test_dataset = MNIST(root='data\/', \n                     train=False,\n                     transform=transforms.ToTensor())","878f6759":"img, label = test_dataset[0]\nplt.imshow(img[0], cmap='gray')\nprint('Shape:', img.shape)\nprint('Label:', label)","b6264a3d":"def predict_image(img, model):\n    xb = img.unsqueeze(0)\n    yb = model(xb)\n    _, preds = torch.max(yb, dim=1)\n    return preds[0].item()","f22efe21":"img, label = test_dataset[0]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', label, ', Predicted:', predict_image(img, model))","cb384d8d":"img, label = test_dataset[10]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', label, ', Predicted:', predict_image(img, model))","ff7ed69e":"img, label = test_dataset[193]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', label, ', Predicted:', predict_image(img, model))","d8b0ebca":"\nimg, label = test_dataset[1839]\nplt.imshow(img[0], cmap='gray')\nprint('Label:', label, ', Predicted:', predict_image(img, model))","020935f8":"test_loader = DataLoader(test_dataset, batch_size=100)\nresult = evaluate(model, test_loader)\nresult","30887dae":"Randomsubsetsampler is an iterable"}}