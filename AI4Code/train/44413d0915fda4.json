{"cell_type":{"e915ba58":"code","6cd5fdab":"code","4b317f1d":"code","b6396669":"code","4be7a04f":"code","5f46383d":"code","080992ea":"code","d0b14f3c":"code","7f942460":"code","c401bd55":"code","6b01fa17":"code","6c61a089":"code","b1e379b5":"markdown","8670f54b":"markdown","a7e035e0":"markdown","0ec6e418":"markdown","cd97866f":"markdown"},"source":{"e915ba58":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","6cd5fdab":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nd0 = pd.read_csv(\"\/kaggle\/input\/mnist-dataset\/train.csv\")\nprint(d0.head(5))","4b317f1d":"l = d0['label']\nd= d0.drop('label',axis=1)\nprint(d)","b6396669":"labels = l.head(1500)\ndata = d.head(1500)\nprint('the shape of sampledata=',data.shape)","4be7a04f":"from sklearn import decomposition\npca = decomposition.PCA()","5f46383d":"pca.n_components = 2\npca_data = pca.fit_transform(data)\nprint('shape  of  pca-reduced.shape ',pca_data.shape)","080992ea":"import seaborn as sn\npca_data = np.vstack((pca_data.T,labels)).T\npca_df = pd.DataFrame(data= pca_data,columns=('1st_principal','2nd_principal','label'))\nsn.FacetGrid(pca_df, hue= \"label\",height =6).map(plt.scatter,'1st_principal','2nd_principal').add_legend()\nplt.show()","d0b14f3c":"pca.n_components = 784\n\npca_data = pca.fit_transform(data)\n\npercentage_var_explained = pca.explained_variance_ \/ np.sum(pca.explained_variance_)\n\ncum_var_explaind = np.cumsum(percentage_var_explained)\n\n#plot the pca specturm\nplt.figure(1, figsize=(6,4))\nplt.clf()\nplt.plot(cum_var_explaind,linewidth = 2)\nplt.axis('tight')\nplt.grid()\nplt.show()","7f942460":"label_1500 = l.head(1500)\nprint(label_1500)","c401bd55":"from sklearn.manifold import TSNE\nfrom sklearn.preprocessing import StandardScaler\nimport seaborn as sn\nstandardized_data = StandardScaler().fit_transform(data)\ndata_1000 = standardized_data[0:1500,:]\nmodel = TSNE(n_components = 2)\ntane_data = model = model.fit_transform(data_1000)\n# creating a data fram which help us in ploting the result\ntane_data = np.vstack((tane_data.T,label_1500)).T\ntane_df = pd.DataFrame(data=tane_data, columns=('Dim_1','Dim_2','lable'))\n# ploting the result of tsne\nsn.FacetGrid(tane_df,hue='lable',height = 6).map(plt.scatter,'Dim_1','Dim_2').add_legend()\nplt.show()","6b01fa17":"model = TSNE(n_components = 2 , random_state = 0 ,perplexity = 50 , n_iter = 5000)\ntane_data = model = model.fit_transform(data_1000)\n# creating a data fram which help us in ploting the result\ntane_data = np.vstack((tane_data.T,label_1500)).T\ntane_df = pd.DataFrame(data=tane_data, columns=('Dim_1','Dim_2','lable'))\n# ploting the result of tsne\nsn.FacetGrid(tane_df,hue='lable',height = 6).map(plt.scatter,'Dim_1','Dim_2').add_legend()\nplt.show()","6c61a089":"model = TSNE(n_components = 2 , random_state = 0 ,perplexity = 100 , n_iter = 5000)\ntane_data = model = model.fit_transform(data_1000)\n# creating a data fram which help us in ploting the result\ntane_data = np.vstack((tane_data.T,label_1500)).T\ntane_df = pd.DataFrame(data=tane_data, columns=('Dim_1','Dim_2','lable'))\n# ploting the result of tsne\nsn.FacetGrid(tane_df,hue='lable',height = 6).map(plt.scatter,'Dim_1','Dim_2').add_legend()\nplt.show()","b1e379b5":"# t-distributed stochastic neighbor embedding (t-SNE)","8670f54b":"#  Principal component analysis (PCA)","a7e035e0":"This code is Principal component analysis (PCA) dimensionality reduction technique.","0ec6e418":"Dimensionality Reduction & Visualization Technique blog \n\nhttps:\/\/distill.pub\/2016\/misread-tsne\/","cd97866f":"This code is t-distributed stochastic neighbor embedding (t-SNE) dimensionality reduction technique.\nIn this chapter\/notebook we usig mnist data for both technique and visualizing the graph.We using a 1500 sample data plot the graph.\n\ndataset:-https:\/\/www.kaggle.com\/shivambaldha\/mnist-dataset"}}