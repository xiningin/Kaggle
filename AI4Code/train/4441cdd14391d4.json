{"cell_type":{"2d0f32df":"code","3edbac48":"code","edd9135e":"code","0e560e47":"code","04442828":"code","599250ca":"code","ad68ded1":"code","f34d3450":"code","ba854fb1":"code","0a66533d":"code","217cf038":"code","4763a987":"code","03378a55":"code","cb344302":"code","4656db34":"code","2f680f62":"code","c6d7a871":"code","e6c65eb6":"code","e7449a09":"code","f566c0de":"code","e902fcd6":"code","0656a595":"code","d5f89c21":"code","224db957":"code","b0f4d053":"code","b2aa07d0":"code","686e5ccb":"code","6bcf548c":"code","30d291ea":"code","30477503":"code","ffb4e6ed":"code","9ec766aa":"code","02a6b6e6":"code","fbafc3b0":"code","11b9bebc":"code","9688ea41":"code","39468d59":"code","fb19621f":"code","1e97f287":"code","e4a07543":"code","c80b2f0b":"code","8b1b2193":"code","8bb6d721":"code","c70bde97":"code","b14214c8":"code","cd052274":"code","02e2ad0d":"code","e93b8667":"code","2948b9c9":"code","604a519a":"code","87c5c952":"code","c40583d3":"code","2403aa40":"code","1188e612":"code","1a301be9":"code","23b3b8e5":"code","4e4b627d":"code","e4a29ccc":"markdown","4e729a0e":"markdown","f7ab51fb":"markdown"},"source":{"2d0f32df":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3edbac48":"from PIL import Image\nimport matplotlib.pyplot as plt","edd9135e":"import torch\nimport torch\nimport random\nimport torch.backends.cudnn as cudnn\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nimport numpy as np\nimport math\nimport h5py\nimport os","0e560e47":"im = Image.open('..\/input\/celeba-dataset\/img_align_celeba\/img_align_celeba\/000001.jpg')\nplt.imshow(im)","04442828":"from torchvision.transforms import ToTensor\nt = ToTensor()\nimt = t(im)\nimt.shape","599250ca":"df = pd.read_csv('..\/input\/celeba-dataset\/list_attr_celeba.csv')\nlen(df)","ad68ded1":"def load_img(filepath):\n    img = Image.open(filepath)\n    return img","f34d3450":"def is_image_file(filename):\n    return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg'])","ba854fb1":"import torch.utils.data as data\nimport torchvision\nfrom os import listdir\nclass DatasetFromFolder(data.Dataset):\n    def __init__(self, image_dir, LR_transform=None, HR_2_transform=None, \n                                 HR_4_transform=None):\n        super(DatasetFromFolder, self).__init__()\n        self.image_filenames = [join(image_dir, x) for x in listdir(image_dir) if is_image_file(x)]\n\n        self.LR_transform = LR_transform\n        self.HR_2_transform = HR_2_transform\n        self.HR_4_transform = HR_4_transform\n#         self.HR_8_transform = HR_8_transform\n\n\n    def __getitem__(self, index):\n        input = load_img(self.image_filenames[index])\n        #print type(input)\n#         HR_8 = self.HR_8_transform(input)\n        #print type(HR_8)\n        HR_4 = self.HR_4_transform(input)\n        HR_2 = self.HR_2_transform(HR_4)\n        LR = self.LR_transform(HR_4)\n        to_tensor = torchvision.transforms.ToTensor()\n        HR_4 = to_tensor(HR_4)\n        return LR, HR_2, HR_4\n\n    def __len__(self):\n        return len(self.image_filenames)","0a66533d":"def get_training_set():\n    root_dir = '..\/input\/celeba-dataset'\n    train_dir = join(root_dir, \"img_align_celeba\/img_align_celeba\")\n\n    return DatasetFromFolder(train_dir,\n                             LR_transform=LR_transform(crop_size),\n                             HR_2_transform=HR_2_transform(crop_size),\n                             HR_4_transform=HR_4_transform(crop_size))\n\n","217cf038":"def LR_transform(crop_size):\n    return Compose([\n        Scale(crop_size\/\/4),\n        ToTensor(),\n    ])\n\ndef HR_2_transform(crop_size):\n    return Compose([\n        Scale(crop_size\/\/2),\n        ToTensor(),\n    ])\n\ndef HR_4_transform(crop_size):\n    return Compose([\n        RandomCrop((crop_size, crop_size)),\n        RandomHorizontalFlip(),\n    ])","4763a987":"from os.path import exists, join, basename\nfrom os import makedirs, remove\nfrom six.moves import urllib\nimport tarfile\nfrom torchvision.transforms import Compose, CenterCrop, ToTensor, Scale, RandomCrop, RandomHorizontalFlip\ncrop_size =128","03378a55":"train_set = get_training_set()","cb344302":"len(train_set)","4656db34":"from torch.utils.data.dataset import random_split\ntrain_len = 200000\nvalid_len = 2599\nTrainData1, ValidationData1 = random_split(train_set,[train_len, valid_len])","2f680f62":"from torch.utils.data import DataLoader\ntraining_data_loader = DataLoader(dataset = TrainData1, num_workers = 1, batch_size = 64, shuffle = True)\ntesting_data_loader = DataLoader(dataset=ValidationData1, num_workers=1, batch_size=64, shuffle=False)","c6d7a871":"from PIL import Image\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\na = training_data_loader.dataset[0]","e6c65eb6":"import torchvision.transforms as transforms\nplt.imshow(transforms.ToPILImage()(a[0]), interpolation=\"bicubic\")","e7449a09":"class L1_Charbonnier_loss(nn.Module):\n    \"\"\"L1 Charbonnierloss.\"\"\"\n    def __init__(self):\n        super(L1_Charbonnier_loss, self).__init__()\n        self.eps = 1e-3\n\n    def forward(self, X, Y):\n        diff = torch.add(X, -Y)\n        error = torch.sqrt( diff * diff + self.eps * self.eps )\n        loss = torch.sum(error) \n        return loss","f566c0de":"def get_upsample_filter(size):\n    \"\"\"Make a 2D bilinear kernel suitable for upsampling\"\"\"\n    factor = (size + 1) \/\/ 2\n    if size % 2 == 1:\n        center = factor - 1\n    else:\n        center = factor - 0.5\n    og = np.ogrid[:size, :size]\n    filter = (1 - abs(og[0] - center) \/ factor) * \\\n             (1 - abs(og[1] - center) \/ factor)\n    return torch.from_numpy(filter).float()","e902fcd6":"class _Conv_Block(nn.Module):    \n    def __init__(self):\n        super(_Conv_Block, self).__init__()\n        \n        self.cov_block = nn.Sequential(\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n        \n    def forward(self, x):  \n        output = self.cov_block(x)\n        return output","0656a595":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        \n        self.conv_input = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.relu = nn.LeakyReLU(0.2, inplace=True)\n        \n        self.convt_I1 = nn.ConvTranspose2d(in_channels=3, out_channels=3, kernel_size=4, stride=2, padding=1, bias=False)\n        self.convt_R1 = nn.Conv2d(in_channels=64, out_channels=3, kernel_size=3, stride=1, padding=1, bias=False)\n        self.convt_F1 = self.make_layer(_Conv_Block)\n  \n        self.convt_I2 = nn.ConvTranspose2d(in_channels=3, out_channels=3, kernel_size=4, stride=2, padding=1, bias=False)\n        self.convt_R2 = nn.Conv2d(in_channels=64, out_channels=3, kernel_size=3, stride=1, padding=1, bias=False)\n        self.convt_F2 = self.make_layer(_Conv_Block)        \n        \n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. \/ n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            if isinstance(m, nn.ConvTranspose2d):\n                c1, c2, h, w = m.weight.data.size()\n                weight = get_upsample_filter(h)\n                m.weight.data = weight.view(1, 1, h, w).repeat(c1, c2, 1, 1)\n                if m.bias is not None:\n                    m.bias.data.zero_()\n                    \n    def make_layer(self, block):\n        layers = []\n        layers.append(block())\n        return nn.Sequential(*layers)\n\n    def forward(self, x):    \n#         x = x.cuda()\n#         print(type(x))\n        out = self.relu(self.conv_input(x))\n        \n        convt_F1 = self.convt_F1(out)\n        convt_I1 = self.convt_I1(x)\n        convt_R1 = self.convt_R1(convt_F1)\n        HR_2x = convt_I1 + convt_R1\n        HR_2x = HR_2x.cuda()\n        \n        convt_F2 = self.convt_F2(convt_F1)\n        convt_I2 = self.convt_I2(HR_2x)\n        convt_R2 = self.convt_R2(convt_F2)\n        HR_4x = convt_I2 + convt_R2\n        HR_4x = HR_4x.cuda()\n        return HR_2x, HR_4x","d5f89c21":"okay = iter(training_data_loader)\nfirst = next(okay)\nfirst[0].shape","224db957":"# plt.imshow(first[2][0][0].cpu(), cmap = 'gray')\nplt.imshow(transforms.ToPILImage()(first[2][0]), interpolation=\"bicubic\")","b0f4d053":"class lapinit():\n    def __init__(self, batchSize = 64, nEpochs = 100, lr = 1e-4, step = 100,\n            cuda = {'action' : True}, resume = '', start_epoch = 1, threads = 1,\n            momentum = 0.9, weight_decay = 1e-4, pretrained = ''):\n        self.batchSize = batchSize\n        self.nEpochs = nEpochs\n        self.lr = lr\n        self.step = step\n        self.cuda = cuda\n        self.resume = resume\n        self.start_epoch = start_epoch\n        self.threads = threads\n        self.momentum = momentum\n        self.weight_decay = weight_decay\n        self.pretrained = pretrained\n\nopt = lapinit()\n\n","b2aa07d0":"model = Net()\nmodel = model.cuda()\ncriterion = L1_Charbonnier_loss()","686e5ccb":"first[0] = first[0].cuda()\ntmp1, tmp2 = model(first[0])\ntmp1.shape, tmp2.shape","6bcf548c":"optimizer = optim.Adam(model.parameters(), lr=opt.lr)","30d291ea":"okay = iter(testing_data_loader)\ntest1 = next(okay)\ntest1[0].shape","30477503":"test1[0] = test1[0].cuda()","ffb4e6ed":"img_list1 = []\nimg_list2 = []","9ec766aa":"def train(training_data_loader, optimizer, model, criterion, epoch):\n\n#     lr = adjust_learning_rate(optimizer, epoch-1)\n#     lr = input()\n    global lr\n    lr = float(lr)\n\n    for param_group in optimizer.param_groups:\n        param_group[\"lr\"] = lr\n\n    print(\"Epoch={}, lr={}\".format(epoch, optimizer.param_groups[0][\"lr\"]))\n\n    model.train()\n\n    for iteration, batch in enumerate(training_data_loader, 1):\n\n        input, label_x2, label_x4 = Variable(batch[0]), Variable(batch[1], requires_grad=False), Variable(batch[2], requires_grad=False)\n\n        if opt.cuda['action']:\n#             input = input.cuda()\n#             label_x2 = label_x2.cuda()\n#             label_x4 = label_x4.cuda()\n            \n            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n            input, label_x2, label_x4 = input.to(device), label_x2.to(device), label_x4.to(device)\n#             print(type(input))\n\n        HR_2x, HR_4x = model(input)\n#         HR_2x = HR_2x.cuda()\n#         HR_4x = HR_4x.cuda()\n        # print(HR_4x.shape)\n        # print(label_x4.shape)\n        loss_x2 = criterion(HR_2x, label_x2)\n        loss_x4 = criterion(HR_4x, label_x4)\n        loss = loss_x2 + loss_x4\n\n        optimizer.zero_grad()\n\n        loss_x2.backward(retain_graph = True)\n\n        loss_x4.backward()\n\n        optimizer.step()\n\n        if iteration%100 == 0:\n            print(\"===> Epoch[{}]({}\/{}): Loss: {:.10f}\".format(epoch, iteration, len(training_data_loader), loss.data.item()))\n            tmp1, tmp2 = model(test1[0])\n#             tmp1 = tmp1.cpu()\n#             tmp2 = tmp2.cpu()\n#             plt.imshow(transforms.ToPILImage()(tmp1[0].cpu()), interpolation=\"bicubic\")\n#             plt.show()\n#             plt.imshow(transforms.ToPILImage()(tmp2[0].cpu()), interpolation=\"bicubic\")\n#             plt.show()\n            img_list1.append(tmp1[0].detach().cpu())\n            img_list2.append(tmp2[0].detach().cpu())\n            del tmp1\n            del tmp2\n            torch.cuda.empty_cache()\n#             tmp1.detach()\n#             tmp2.detach()","02a6b6e6":"def save_checkpoint(model, epoch):\n    model_folder = \"checkpoint\/\"\n    model_out_path = model_folder + \"lapsrn_model_epoch_{}.pth\".format(epoch)\n    state = {\"epoch\": epoch ,\"model\": model, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()}\n    if not os.path.exists(model_folder):\n        os.makedirs(model_folder)\n\n    torch.save(state, model_out_path)\n\n    print(\"Checkpoint saved to {}\".format(model_out_path))","fbafc3b0":"def adjust_learning_rate(optimizer, epoch):\n    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 10 epochs\"\"\"\n#     if epoch == 2:\n#         lr = 1e-3\n#         return lr\n    lr = opt.lr * (0.1 ** (epoch \/\/ (opt.step\/10)))\n    return lr","11b9bebc":"plt.imshow(transforms.ToPILImage()(test1[2][0].cpu()), interpolation=\"bicubic\")","9688ea41":"plt.imshow(transforms.ToPILImage()(test1[0][0].cpu()), interpolation=\"bicubic\")\nplt.show()","39468d59":"from datetime import datetime\nstart=datetime.now()\nfor epoch in range(opt.start_epoch, opt.nEpochs + 1):\n    lr = input()\n    train(training_data_loader, optimizer, model, criterion, epoch)\n    # save_checkpoint(model, epoch)\n    print('do you want to save the model before proceeding?[y\/n]')\n    ch = input()\n    if ch=='y':\n        save_checkpoint(model, epoch)\n    \n    print(datetime.now() - start)","fb19621f":"checkpoint = torch.load('..\/working\/checkpoint\/lapsrn_model_epoch_7.pth')\nmodel.load_state_dict(checkpoint['state_dict'])\nmodel.eval()","1e97f287":"test1[0][0].shape","e4a07543":"# plt.imshow(test1[0][0][0].cpu(), cmap = 'gray')\nplt.imshow(transforms.ToPILImage()(test1[0][0].cpu()), interpolation=\"bicubic\")","c80b2f0b":"tmp1, tmp2 = model(test1[0])\ntmp1 = tmp1.cpu()\ntmp2 = tmp2.cpu()\nplt.imshow(transforms.ToPILImage()(tmp1[0]), interpolation=\"bicubic\")\n","8b1b2193":"plt.imshow(transforms.ToPILImage()(tmp2[0]), interpolation=\"bicubic\")","8bb6d721":"# plt.imshow(tmp1[0][0].detach().cpu(), cmap = 'gray')\nplt.imshow(transforms.ToPILImage()(tmp1[0].cpu()), interpolation=\"bicubic\")","c70bde97":"# plt.imshow(tmp2[0][0].detach().cpu(), cmap = 'gray')\nplt.imshow(transforms.ToPILImage()(tmp2[0].cpu()), interpolation=\"bicubic\")","b14214c8":"# plt.imshow(test1[2][0][0].cpu(), cmap = 'gray')\nplt.imshow(transforms.ToPILImage()(test1[2][0].cpu()), interpolation=\"bicubic\")","cd052274":"import matplotlib.animation as animation\nfrom IPython.display import HTML\nimport torchvision.utils as vutils\nfig = plt.figure(figsize = (6,6))\nplt.axis('off')\n# ims2 = [plt.imshow(torchvision.transforms.ToPILImage()(i.detach()), animated = True) for i in img_list2]\nims2 = [[plt.imshow(np.transpose(i.detach(), (1,2,0)), animated=True)] for i in img_list2]\nani = animation.ArtistAnimation(fig, ims2, interval = 100, repeat_delay = 500, blit = True)\nHTML(ani.to_jshtml())\n","02e2ad0d":"fig = plt.figure(figsize = (6,6))\nplt.axis('off')\n# ims2 = [plt.imshow(torchvision.transforms.ToPILImage()(i.detach()), animated = True) for i in img_list2]\nims2 = [[plt.imshow(np.transpose(i.detach(), (1,2,0)), animated=True)] for i in img_list1]\nani = animation.ArtistAnimation(fig, ims2, interval = 100, repeat_delay = 500, blit = True)\nHTML(ani.to_jshtml())","e93b8667":"# save_checkpoint(model, 1)","2948b9c9":"test1[0].shape","604a519a":"plt.imshow(torchvision.transforms.ToPILImage()(test1[0][0].cpu()), interpolation='bicubic')","87c5c952":"pred1 = model.conv_input(test1[0])\nplt.imshow(torchvision.transforms.ToPILImage()(pred1[0].cpu()), interpolation='bicubic')","c40583d3":"import torch.nn.functional as F","2403aa40":"pred2 = F.relu(pred1)\n# type(pred2)\nplt.imshow(torchvision.transforms.ToPILImage()(pred2[0].cpu()), interpolation='bicubic')","1188e612":"pred3 = model.convt_F1(pred2)\nplt.imshow(torchvision.transforms.ToPILImage()(pred3[0].cpu()), interpolation='bicubic')","1a301be9":"pred4 = model.convt_I1(test1[0])\nplt.imshow(torchvision.transforms.ToPILImage()(pred4[0].cpu()), interpolation='bicubic')","23b3b8e5":"pred5 = model.convt_R1(pred3)\nplt.imshow(torchvision.transforms.ToPILImage()(pred5[0].cpu()), interpolation='bicubic')","4e4b627d":"pred6 = pred4 + pred5\nplt.imshow(torchvision.transforms.ToPILImage()(pred6[0].cpu()), interpolation='bicubic')","e4a29ccc":"## Animation of model(input)","4e729a0e":"real image - ","f7ab51fb":"LR image of this is"}}