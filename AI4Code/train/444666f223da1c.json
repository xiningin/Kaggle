{"cell_type":{"790c3311":"code","f0f349cc":"code","a13ddfec":"code","2c92c0d0":"code","028c4263":"code","04379adb":"code","b8bec1b6":"code","68e23821":"code","f3546303":"code","e0d0a044":"code","b91039c7":"code","b06c375e":"code","67710c48":"code","1bbb7cd8":"code","5539d3c3":"code","344bea92":"code","b204bef0":"code","66ed5755":"code","1fc788c3":"code","8f5c129b":"code","a1d39644":"code","fc7497e9":"code","3ec5d3e6":"code","b138060c":"code","8c07a97d":"code","aa935500":"code","3e0617eb":"code","e9404e2a":"code","b535aeb0":"code","cd98979b":"code","bab9b495":"code","2edc21f4":"code","3b1a977c":"code","9bb374a7":"code","f53694c8":"code","95f7f87c":"code","328fc109":"code","fab9b819":"code","c093591a":"code","0cf9ce08":"code","56919e56":"code","fbfc6cd1":"code","930d3c73":"code","7960660b":"markdown","084fd43a":"markdown","e0532ceb":"markdown","12a5419b":"markdown","18fbb06e":"markdown","e9c6bd91":"markdown","2a222116":"markdown","38ee1736":"markdown","730b67ae":"markdown","9ad58f02":"markdown","968c05fe":"markdown","e601c776":"markdown","2d3cfc22":"markdown","64b231f2":"markdown","afe300b5":"markdown","4823f51d":"markdown","8b0585a4":"markdown","05a68b1d":"markdown","da9f1e64":"markdown","f2d7ba76":"markdown","cf1ebed4":"markdown","d155efc3":"markdown","11b84237":"markdown","57c5b7f5":"markdown","7e4664e8":"markdown","32844060":"markdown","72212c64":"markdown","0633b28a":"markdown","b5b5fe90":"markdown","70246a28":"markdown","35921a57":"markdown"},"source":{"790c3311":"import numpy as np \nimport pandas as pd\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import Lasso, Ridge, ElasticNet\nfrom sklearn.model_selection import cross_val_score\nfrom scipy.stats import norm\nfrom scipy import stats \nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","f0f349cc":"train= pd.read_csv('..\/input\/train.csv')\ntest= pd.read_csv('..\/input\/test.csv')\n\nprint(\"shape of train dataset:\", train.shape)\nprint(\"shape of test dataset:\", test.shape)","a13ddfec":"train.head()","2c92c0d0":"plt.figure(figsize=[10,6])\nsns.distplot(train.SalePrice, fit=norm)","028c4263":"plt.figure(figsize=[10,6])\nsns.distplot(np.log(train.SalePrice), fit=norm)","04379adb":"correlation= train.corr()\nplt.figure(figsize=[12,8])\nplt.title('Correlation of Numeric Features with Sale Price')\nsns.heatmap(correlation,cmap=\"YlGnBu\")","b8bec1b6":"correlation= train.corr()\ncorrelation=correlation['SalePrice'].sort_values(ascending=False)\npos_correlation=correlation.head(25)\npos_correlation","68e23821":"plt.figure(figsize=[8,5])\nsns.regplot(train['OverallQual'], train['SalePrice'])","f3546303":"plt.figure(figsize=[8,5])\nsns.regplot(train['GrLivArea'], train['SalePrice'])","e0d0a044":"plt.figure(figsize=[8,5])\nsns.regplot(train['GarageArea'], train['SalePrice'])","b91039c7":"plt.figure(figsize=[8,5])\nsns.regplot(train['TotalBsmtSF'], train['SalePrice'])","b06c375e":"print(\"Before:\",train.shape)\n\ntrain.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index, inplace=True)\ntrain.drop(train[(train['GarageArea']>1200) & (train['SalePrice']<100000)].index, inplace=True)\ntrain.drop(train[(train['TotalBsmtSF']>6000) & (train['SalePrice']<200000)].index, inplace=True)\ntrain.reset_index(drop=True, inplace=True)\n\nprint(\"After:\",train.shape)","67710c48":"data= pd.concat([train.drop(['SalePrice'], axis=1), test])","1bbb7cd8":"xx= (data.isnull().sum())\/len(data)*100\nxx=xx.sort_values(ascending=False).head(30)\n\nplt.figure(figsize=(15, 6))\nplt.xticks(rotation=\"90\")\nsns.barplot(xx.keys(), xx)","5539d3c3":"total=data.isnull().sum().sort_values(ascending=False)\npercent=((data.isnull().sum()\/data.isnull().count())*100).sort_values(ascending=False)\nmissing= pd.concat([total,percent], axis=1, join='outer', keys=['Total missing count', 'Percentage '])\nmissing.head(30)","344bea92":"train['GarageQual'].fillna('None', inplace=True)\ntest['GarageQual'].fillna('None', inplace=True)\ntrain['GarageFinish'].fillna('None', inplace=True)\ntest['GarageFinish'].fillna('None', inplace=True)\ntrain['GarageYrBlt'].fillna('None', inplace=True)\ntest['GarageYrBlt'].fillna('None', inplace=True)\ntrain['GarageType'].fillna('None', inplace=True)\ntest['GarageType'].fillna('None', inplace=True)\ntrain['GarageCond'].fillna('None', inplace=True)\ntest['GarageCond'].fillna('None', inplace=True)\ntest.loc[test['Id']==2577, 'GarageType']='None'\n\ntest['GarageCars'].fillna(0, inplace=True)\ntest['GarageArea'].fillna(0, inplace=True)","b204bef0":"data[(data['TotalBsmtSF']!=0) & (data['BsmtCond'].isnull()==True)][['Id','TotalBsmtSF','BsmtCond','BsmtQual','BsmtExposure',\n                                                                    'BsmtFinType1','BsmtFinSF1','BsmtUnfSF']]","66ed5755":"test.loc[test['Id']==2041, 'BsmtCond']='Gd'\ntest.loc[test['Id']==2186, 'BsmtCond']='TA'\ntest.loc[test['Id']==2525, 'BsmtCond']='TA'\ntrain['BsmtCond'].fillna('None', inplace=True)\ntest['BsmtCond'].fillna('None', inplace=True)","1fc788c3":"data[(data['TotalBsmtSF']!=0) & (data['BsmtExposure'].isnull()==True)][['Id','TotalBsmtSF','BsmtCond','BsmtQual','BsmtExposure',\n                                                                    'BsmtFinType1','BsmtFinSF1','BsmtUnfSF']]","8f5c129b":"train.loc[train['Id']==949, 'BsmtExposure']='Gd'\ntest.loc[test['Id']==1488, 'BsmtExposure']='Gd'\ntest.loc[test['Id']==2349, 'BsmtExposure']='Gd'\ntrain['BsmtExposure'].fillna('None', inplace=True)\ntest['BsmtExposure'].fillna('None', inplace=True)","a1d39644":"data[(data['TotalBsmtSF']!=0) & (data['BsmtQual'].isnull()==True)][['Id','TotalBsmtSF','BsmtQual','BsmtCond','BsmtExposure',\n                                                                    'BsmtFinType1','BsmtFinSF1','BsmtUnfSF']]","fc7497e9":"test.loc[test['Id']==2218, 'BsmtQual']='Fa'\ntest.loc[test['Id']==2219, 'BsmtQual']='TA'\ntrain['BsmtQual'].fillna('None', inplace=True)\ntest['BsmtQual'].fillna('None', inplace=True)","3ec5d3e6":"data[(data['TotalBsmtSF']!=0) & (data['BsmtFinType1'].isnull()==True)][['Id','TotalBsmtSF','BsmtQual','BsmtCond','BsmtExposure',\n                                                                        'BsmtFinType1','BsmtFinSF1','BsmtUnfSF']]","b138060c":"data[(data['TotalBsmtSF']!=0) & (data['BsmtFullBath'].isnull()==True)][['Id','TotalBsmtSF','BsmtQual','BsmtCond',\n                                                                        'BsmtExposure','BsmtFullBath']]","8c07a97d":"train['BsmtFinType1'].fillna('None', inplace=True)\ntest['BsmtFinType1'].fillna('None', inplace=True)\ntest['BsmtFinSF1'].fillna(0, inplace=True)\ntrain['BsmtFinType2'].fillna('None', inplace=True)\ntest['BsmtFinType2'].fillna('None', inplace=True)\ntest['BsmtUnfSF'].fillna(0, inplace=True)\ntest['TotalBsmtSF'].fillna(0, inplace=True)\n\ntest['BsmtFullBath'].fillna(0, inplace=True)\ntest['BsmtHalfBath'].fillna(0, inplace=True)\n\ntest['BsmtFinSF1'].fillna(0, inplace=True)\ntest['BsmtFinSF2'].fillna(0, inplace=True)","aa935500":"train['FireplaceQu'].fillna('None', inplace=True)\ntest['FireplaceQu'].fillna('None', inplace=True)\n\ntrain.loc[train['LotFrontage'].isnull()==True, 'LotFrontage']= train['LotFrontage'].mean()\ntest.loc[test['LotFrontage'].isnull()==True, 'LotFrontage']= test['LotFrontage'].mean()\n\ntrain['MasVnrType'].fillna('None', inplace=True)\ntest['MasVnrType'].fillna('None', inplace=True)\n\ntrain['MasVnrArea'].fillna(0, inplace=True)\ntest['MasVnrArea'].fillna(0, inplace=True)\n\ntrain['PoolQC'].fillna('None', inplace=True)\ntest['PoolQC'].fillna('None', inplace=True)\n\ntrain['MiscFeature'].fillna('None', inplace=True)\ntest['MiscFeature'].fillna('None', inplace=True)\n\ntrain['Alley'].fillna('None', inplace=True)\ntest['Alley'].fillna('None', inplace=True)\n\ntrain['Fence'].fillna('None', inplace=True)\ntest['Fence'].fillna('None', inplace=True)\n\ntrain['MSZoning'].fillna('RL', inplace=True)\ntest['MSZoning'].fillna('RL', inplace=True)\n\ntrain['Electrical'].fillna('SBrkr', inplace=True)\ntest['Functional'].fillna('Typ', inplace=True)\ntest['SaleType'].fillna('WD', inplace=True)\ntest['Exterior1st'].fillna('VinylSd', inplace=True)\ntest['KitchenQual'].fillna('TA', inplace=True)\ntest['Exterior2nd'].fillna('VinylSd', inplace=True)","3e0617eb":"train.drop('Utilities', axis=1, inplace=True)\ntest.drop('Utilities', axis=1, inplace=True)","e9404e2a":"print(\"Train dataset:\\n\",train.isnull().sum().sort_values(ascending=False).head(5))\nprint(\"\\n\\nTest dataset:\\n\",test.isnull().sum().sort_values(ascending=False).head(5))","b535aeb0":"train['renovated']= 1\ntrain.loc[(train['YearBuilt']!=train['YearRemodAdd']),'renovated' ]=0\ntest['renovated']= 1\ntest.loc[(test['YearBuilt']!=test['YearRemodAdd']),'renovated' ]=0\n\ntrain['Total_porch']= (train['OpenPorchSF'])+train['ScreenPorch']+train['3SsnPorch']\ntrain['BsmtFinSF_total']= (train['BsmtFinSF1']**2)+train['BsmtFinSF2']\ntrain['Bath']= (train['FullBath']**2)+ train['HalfBath']\ntrain['BsmtBath']= (train['BsmtFullBath'])+train['BsmtHalfBath']\ntrain['TotalSF'] = train['TotalBsmtSF'] + train['1stFlrSF'] + train['2ndFlrSF']\ntrain['Total_garage']= (train['GarageCars']**5)+ train['GarageArea']\n\n\ntest['Total_porch']= (test['OpenPorchSF'])+test['ScreenPorch']+test['3SsnPorch']\ntest['BsmtFinSF_total']= (test['BsmtFinSF1']**2)+test['BsmtFinSF2']\ntest['Bath']= (test['FullBath']**2)+ test['HalfBath']\ntest['BsmtBath']= (test['BsmtFullBath'])+test['BsmtHalfBath']\ntest['TotalSF'] = test['TotalBsmtSF'] + test['1stFlrSF'] + test['2ndFlrSF']\ntest['Total_garage']= (test['GarageCars']**5)+ test['GarageArea']","cd98979b":"y=np.asarray(train['SalePrice'])\ny=np.log(y+1)\n\nX_train = pd.get_dummies(pd.concat((train.drop([\"SalePrice\", \"Id\"], axis=1),\n                                          test.drop([\"Id\"], axis=1)), axis=0)).iloc[: train.shape[0]]\nX_test = pd.get_dummies(pd.concat((train.drop([\"SalePrice\", \"Id\"], axis=1),\n                                         test.drop([\"Id\"], axis=1)), axis=0)).iloc[train.shape[0]:]\n\nX_train.shape, X_test.shape","bab9b495":"def return_rmse(model):\n    return np.sqrt(-cross_val_score(model, X_train, y, cv=5, scoring=\"neg_mean_squared_error\")).mean()","2edc21f4":"RR= Ridge(alpha=15)\nreturn_rmse(RR)","3b1a977c":"LSR = Lasso(alpha=0.0005)\nreturn_rmse(LSR)","9bb374a7":"EN = ElasticNet(alpha=0.01,l1_ratio=0.1)\nreturn_rmse(EN)","f53694c8":"RR.fit(X_train, y)\nLSR.fit(X_train, y)\nEN.fit(X_train, y)\n\ny_pred = RR.predict(X_train)\nresidual = y - y_pred\nz = np.abs(stats.zscore(residual))\noutliers1=np.where(abs(z) > abs(z).std() * 3)[0]\noutliers1","95f7f87c":"y_pred = LSR.predict(X_train)\nresidual = y - y_pred\nz = np.abs(stats.zscore(residual))\noutliers2=np.where(abs(z) > abs(z).std() * 3)[0]\noutliers2","328fc109":"y_pred = EN.predict(X_train)\nresidual = y - y_pred\nz = np.abs(stats.zscore(residual))\noutliers3=list(np.where(abs(z) > abs(z).std() * 3))[0]\noutliers3","fab9b819":"outliers = []\nfor i in outliers1:\n    if (i in outliers2) & (i in outliers3):\n        outliers.append(i)     \n\ntrain = train.drop(outliers)        ","c093591a":"y = train[\"SalePrice\"]\ny = np.log(y+1)\n\nX_train = pd.get_dummies(pd.concat((train.drop([\"SalePrice\", \"Id\"], axis=1),\n                                    test.drop([\"Id\"], axis=1)), axis=0)).iloc[: train.shape[0]]\nX_test = pd.get_dummies(pd.concat((train.drop([\"SalePrice\", \"Id\"], axis=1),\n                                   test.drop([\"Id\"], axis=1)), axis=0)).iloc[train.shape[0]:]","0cf9ce08":"RR= Ridge(alpha=15)\nreturn_rmse(RR)","56919e56":"LSR = Lasso(alpha=0.0004)\nreturn_rmse(LSR)","fbfc6cd1":"EN = ElasticNet(alpha=0.001,l1_ratio=0.5)\nreturn_rmse(EN)","930d3c73":"RR.fit(X_train, y)\nLSR.fit(X_train, y)\nEN.fit(X_train, y)\n\npredict = 0.4 * RR.predict(X_test) + 0.3 * EN.predict(X_test) + 0.3 * LSR.predict(X_test)\n\npredict= np.exp(predict)-1\nsample_submission= pd.DataFrame({'Id':np.asarray(test.Id), 'SalePrice':predict})\nsample_submission.to_csv(\"submit.csv\", index=False)","7960660b":"## Data Cleaning\n\n### Dealing with Outliers","084fd43a":"# Data Preprocessing\n\n#### Visualization of target variable SalePrice data distribution.","e0532ceb":"### Combine these models for final prediction on test set","12a5419b":"Fill these BsmtQual null values with values of BsmtCond and others with None.","18fbb06e":"The target variable is right skewed. So we need to transform this variable and make it more normally distributed.\n\nIn case of positive skewness, log transformation works well.","e9c6bd91":"#### Let's visualize relationship of features with SalePrice using Seaborn's Heatmap","2a222116":"#### Importing some important libraries to work with","38ee1736":"### 2. Lasso Regression\n\nLasso (Least Absolute Shrinkage and Selection Operator) uses L1 penalty which means it adds penalty of `absolute value of magnitude` of coefficients to it's `cost function`. Unlike L2, it can lead to zero coefficients. So in this case some features are completely neglected thus less prone to overfit. By assigning zero coefficients to less important features it helps in feature selection\n\n* **alpha** works same as `Ridge`\n\n* If it is zero, it works same as `LinearRegression`\n\n* Increase in alpha increases smoothness (reduces complexity by decreasing variance)\n\n* Decrease in alpha increases magnitude of coefficients (increases complexity by decreasing bias)","730b67ae":"### 1. Ridge Regression \n\nRidge regression uses L2 penalty which means it adds penalty of `squared magnitude` of coefficients to it's `cost function`.\n\n* **alpha** is used for regularization strength\n\n* If it is zero, it works same as `LinearRegression`\n\n* Increase in alpha increases smoothness (reduces complexity by decreasing variance)\n\n* Decrease in alpha increases magnitude of coefficients (increases complexity by decreasing bias)","9ad58f02":"#### Get percentage of these missing values in features","968c05fe":"#### Let's drop these outliers","e601c776":"**Load datasets.**","2d3cfc22":"# Model Building\n\nLet's build our model using:\n\n* Ridge\n* Lasso\n* Elastic Net","64b231f2":"## Feature Engineering and Transformation","afe300b5":"Fill all other Basement features missing values with None or Zero.","4823f51d":"#### Apply log tranformation to target variable and Transform categorical features values into dummies.","8b0585a4":"### Train models again","05a68b1d":"The data is now normally distributed as we corrected skew.","da9f1e64":"### Handling Outliers where our model predicted poor results using Z-Score","f2d7ba76":"#### Updating FireplaceQu, LotFrontage, MasVnrType and MasVnrArea, PoolQC, MiscFeature, Alley, Fence, Electrical, Functional, SaleType, Exterior1st, KitchenQual, Exterior2nd","cf1ebed4":"Fill these BsmtExposure null values with values of BsmtQual and other with None.","d155efc3":"# Regularized Linear Regression \n\n**This competition helps alot to understand the methodology of a Data Science project and is a good option as a starter in this field.**\n\nKernels that helps alot to learn:\n\n* https:\/\/www.kaggle.com\/pmarcelino\/comprehensive-data-exploration-with-python\n* https:\/\/www.kaggle.com\/apapiu\/regularized-linear-models\n* https:\/\/www.kaggle.com\/firstbloody\/an-uncomplicated-model-top-2-or-top-1\n\n\n\n### Content of this Kernel: \n\n#### Data Preprocessing\n\n* Exploratory Data Analysis\n* Data Cleaning\n* Dealing with Outliers\n* Feature Engineering and Transformation\n\n#### Model Building\n\n* Ridge Regression\n* Lasso Regression\n* ElasticNet Regression","11b84237":"#### Visualizing some highly correlated features to get better understanding.","57c5b7f5":"Our models performance got better!","7e4664e8":"Fill these BsmtCond null values with BsmtQual and others with None as they have no Basement at all.","32844060":"#### Check again if we have any feature left with missing vale.","72212c64":"#### Updating Garage features\n\n\nFill all missing values of Garage features with 'None' as they have no Garage.","0633b28a":"#### And its done!","b5b5fe90":"### Let's move to handle missing values","70246a28":"### 3. ElasticNet\n\nElastic Net uses `both L1 and L2` penalty like it's a `combination of LASSO and Ridge`. It works well on `large datasets`\n\n* **alpha** works same as in `Ridge and Lasso` \n\n* **l1_ratio** is to control penalty \n\n* if it is `0` , it is `L2`\n\n* if it is `1`, it is `L1`\n\n* if it is `0 < l1_ratio < 1`, it is combination of `L1 and L2`","35921a57":"#### Updating Basement features\n\nLet's first have a look at BsmtCond. There are some rows having Basement but no Basement condition. Let's dig out more."}}