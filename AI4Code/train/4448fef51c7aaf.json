{"cell_type":{"09c43a48":"code","d00abfa7":"code","34f783bb":"code","4ad94067":"code","b70183dd":"code","39ff5cc6":"code","a5b673df":"code","8623993e":"code","c1092228":"code","b7042d14":"code","68604634":"code","1bac3778":"code","cec99c78":"code","3d815568":"code","2f42562b":"code","160364ef":"code","c6046fbf":"code","7b622bc8":"code","aa1a484e":"code","1a4d8c56":"code","47e84411":"code","af3f7a35":"code","6d0ae72f":"code","eb68fd1c":"code","3d70b36f":"code","b5cbb998":"code","e4033485":"code","2889790a":"markdown"},"source":{"09c43a48":"import os\nos.environ['PYTHONHASHSEED']=str(199)\nos.environ['TF_DETERMINISTIC_OPS'] = '1'\n#rest of the code\n#TensorFlow version 2.3.1","d00abfa7":"KAGGLE_FLAG = True\nSEED = 945\nNUM_FOLDS = 5 #10\nNUM_REPEATS = 10 #5","34f783bb":"pip install feature_engine","4ad94067":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport os, gc\n# import cudf\nimport pandas as pd\nimport numpy as np\nimport random\n# import cupy as cp\nimport xgboost as xgb\nfrom hyperopt import hp, fmin, tpe, Trials\nfrom hyperopt.pyll.base import scope\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import GroupKFold\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nfrom joblib import dump, load\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as layers\nfrom tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.metrics import f1_score","b70183dd":"# function to process data\nfrom sklearn.metrics import confusion_matrix, make_scorer, f1_score\nfrom scipy.optimize import differential_evolution\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\nfrom sklearn.model_selection import KFold, StratifiedKFold, train_test_split\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn import metrics\nfrom feature_engine.encoding import MeanEncoder, RareLabelEncoder, CountFrequencyEncoder, OneHotEncoder\nfrom feature_engine.selection import DropFeatures\nfrom feature_engine.imputation import AddMissingIndicator\nfrom feature_engine.imputation import ArbitraryNumberImputer, MeanMedianImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.mixture import GaussianMixture","39ff5cc6":"def reset_random_seeds():\n    os.environ['PYTHONHASHSEED']=str(SEED)\n    tf.random.set_seed(SEED)\n    np.random.seed(SEED)\n    random.seed(SEED)\n\n#make some random data\nreset_random_seeds()","a5b673df":"train_input_path = ('..\/input\/porto-seguro-data-challenge\/train.csv' if KAGGLE_FLAG else '\/home\/rapela\/Downloads\/kaggle\/porto_seguro_data_challenge\/data\/train.csv')\ntest_input_path = ('..\/input\/porto-seguro-data-challenge\/test.csv' if KAGGLE_FLAG else '\/home\/rapela\/Downloads\/kaggle\/porto_seguro_data_challenge\/data\/test.csv')\nsubmission_input_path = ('\/kaggle\/input\/porto-seguro-data-challenge\/submission_sample.csv' if KAGGLE_FLAG else '\/home\/rapela\/Downloads\/kaggle\/porto_seguro_data_challenge\/data\/submission_sample.csv')\nmetadata_input_path = ('\/kaggle\/input\/porto-seguro-data-challenge\/metadata.csv' if KAGGLE_FLAG else '\/home\/rapela\/Downloads\/kaggle\/porto_seguro_data_challenge\/data\/metadata.csv')","8623993e":"train = pd.read_csv(train_input_path, na_values = -999).drop(['id'], axis=1)\ntest = pd.read_csv(test_input_path, na_values = -999).drop(['id'], axis=1)\nsubmission = pd.read_csv(submission_input_path)\nmetadata = pd.read_csv(metadata_input_path)","c1092228":"cat_nom = [x for x in metadata.iloc[1:-1, :].loc[(metadata.iloc[:,1]==\"Qualitativo nominal\")].iloc[:,0]]\ncat_ord = [x for x in metadata.iloc[1:-1, :].loc[(metadata.iloc[:,1]==\"Qualitativo ordinal\")].iloc[:,0]]\nnum_dis = [x for x in metadata.iloc[1:-1, :].loc[(metadata.iloc[:,1]==\"Quantitativo discreto\")].iloc[:,0]]\nnum_con = [x for x in metadata.iloc[1:-1, :].loc[(metadata.iloc[:,1]==\"Quantitativo continua\")].iloc[:,0]]\n\ncat_cols = cat_nom + cat_ord\nnum_cols = num_dis + num_con","b7042d14":"def preprocess(df):\n    \n    df = df.replace(-999, np.nan)\n    df = df.fillna(df.mean())\n    \n    return df\n\ndef preprocess_cat(df):\n    \n    df = df.replace(-999, np.nan)\n    df = df.fillna(df.mode().iloc[0])\n    \n    return df # df = df.fillna(df.mode().iloc[0])\n\ndef preprocess_num(df):\n    \n    df = df.replace(-999, np.nan)\n    df = df.fillna(0)\n    \n    return df\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nscaler = MinMaxScaler()\nscaler1 = MinMaxScaler()","68604634":"meta = pd.read_csv(metadata_input_path)\n\nfrom feature_engine.discretisation import EqualFrequencyDiscretiser\ncat_var = [ 'var1', 'var2', 'var7', 'var8', 'var9', 'var10', 'var14', 'var15',\n       'var16', 'var17', 'var18', 'var20', 'var22', 'var23', 'var28', 'var29',\n       'var30',  'var33', 'var34', 'var37', 'var39',\n       'var41', 'var5', 'var6', 'var11', 'var57']\ncat_ord = [x for x in meta.iloc[1:-1, :].loc[(meta.iloc[:,1]==\"Qualitativo ordinal\")].iloc[:,0]]\ncat_var.extend(cat_ord)\n\nnum_dis = [x for x in meta.iloc[1:-1, :].loc[(meta.iloc[:,1]==\"Quantitativo discreto\")].iloc[:,0]]\nnum_con = [x for x in meta.iloc[1:-1, :].loc[(meta.iloc[:,1]==\"Quantitativo continua\")].iloc[:,0]]\n\nnum_cols = num_dis + num_con\nto_drop = ['var65', 'var66', 'var19', 'var31', 'var36', 'var68', 'var38']\nto_treat = ['var3', 'var4', 'var12', 'var13', 'var21', 'var35']\ncat_var.extend(to_treat)\n\naddBinary_imputer = AddMissingIndicator()\nmedian_Imputer = MeanMedianImputer(imputation_method='median', variables = num_cols)\narbitrary_imputer = ArbitraryNumberImputer(arbitrary_number=-999)\nRefactorBins = EqualFrequencyDiscretiser(q=20, variables=to_treat)\nrare_encoder = RareLabelEncoder(tol=0.02, n_categories=2, variables=cat_var,\n                           replace_with=-999, ignore_format = True)\nmean_encoder = MeanEncoder(variables=cat_var, ignore_format = True)\narbitrary_imputer_zero = ArbitraryNumberImputer(arbitrary_number=0.22)\ndrop_Features = DropFeatures(features_to_drop = to_drop)\n\npipe1 = Pipeline([('indicator', addBinary_imputer),\n                  ('median_imputer', median_Imputer),\n                  ('ReplaceNa', arbitrary_imputer),\n                  ('RefactorBins', RefactorBins),\n                  ('RareLabelEncoder1', rare_encoder),\n                  ('MeanEncoder', mean_encoder),\n                  ('arbitrary_imputer_zero', arbitrary_imputer_zero),\n                 ('dropFeatures', drop_Features)])","1bac3778":"X = train[cat_nom+cat_ord+num_dis+num_con]\ny = train.y\nX_test = test[cat_nom+cat_ord+num_dis+num_con]","cec99c78":"X = pipe1.fit_transform(X, y)\nX_test = pipe1.transform(X_test)","3d815568":"# from scipy.special import erfinv as sp_erfinv\n# epsilon = 1e-6\n\n# def rankGauss(data):\n#     data = data.values.argsort().argsort()\n#     data = (data\/data.max()-0.5)*2 # scale to (-1,1)\n#     data = np.clip(data,-1+epsilon,1-epsilon)\n#     data = sp_erfinv(data) # map to gaussian\n#     return data\n\n# X = pd.DataFrame(rankGauss(X), columns=X.columns)\n# X_test = pd.DataFrame(rankGauss(X_test), columns=X_test.columns)","2f42562b":"num_cols = sorted(list(set(num_cols) - set(to_drop)))\ncat_cols = sorted(list(set(cat_cols) - set(to_drop)))","160364ef":"rkf = RepeatedStratifiedKFold(n_splits=NUM_FOLDS, n_repeats=NUM_REPEATS, random_state=SEED)\nkf = StratifiedKFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)","c6046fbf":"# fun\u00e7\u00f5es criadas para resolver o problema do neg\u00f3cio\n\ndef optimal_cutoff(y_target, y_predict_prob, only_fun = True, random_state = 1997):\n    \n    optimization = differential_evolution(lambda c: (-f1_score(y_target, (y_predict_prob > c[0]))),\n                                          [(0, 0.5)], tol = 0.00001, seed = random_state, popsize=3)\n    if only_fun == False:\n        return -optimization['fun'], optimization['x']\n    else:\n        return 'f1score', -optimization['fun'], True\n        ","7b622bc8":"def create_mlp(num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate):\n    \n    reset_random_seeds()\n    \n    inp = tf.keras.layers.Input(shape = (num_columns, ))\n    x = tf.keras.layers.BatchNormalization()(inp)\n    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n    for i in range(len(hidden_units)): \n        x = tf.keras.layers.Dense(hidden_units[i])(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n        x = tf.keras.layers.Dropout(dropout_rates[i+1])(x)    \n        \n    x = tf.keras.layers.Dense(num_labels)(x)\n    out = tf.keras.layers.Activation('sigmoid')(x)\n    \n    model = tf.keras.models.Model(inputs = inp, outputs = out)\n    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001),\n                  loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = label_smoothing), \n                  metrics = tf.keras.metrics.AUC(name = 'AUC'), \n                 )\n    \n    return model","aa1a484e":"batch_size = 1024\nhidden_units = [64, 128, 128, 64]\ndropout_rates = [0.10143786981358652, 0.19720339053599725, 0.2703017847244654, 0.23148340929571917, 0.2357768967777311]\nlabel_smoothing = 1e-2\nlearning_rate = 1e-3","1a4d8c56":"def cross_valid(model, train, target, test, num_folds=10, random_state=42):\n\n    train_oof = np.zeros((len(train)))\n    test_preds = 0\n\n    scores=[]\n    cut = []\n    \n    \n    for f, (train_ind, val_ind) in tqdm(enumerate(rkf.split(train, target))):\n\n        train_df, val_df = train.iloc[train_ind][columns], train.iloc[val_ind][columns]\n        \n        train_target, val_target = target[train_ind], target[val_ind]\n\n        ckp_path = f'my_model_{f}.hdf5'\n        \n        test_preds_avg = np.zeros(len(X_test))\n        \n        mrange = 10\n\n        for j in range(0, mrange):\n    \n            model = None\n\n            model = create_mlp(train_df.shape[1], 1, hidden_units, dropout_rates, label_smoothing, learning_rate)\n\n            rlr = ReduceLROnPlateau(monitor = 'val_AUC', factor = 0.1, patience = 3, verbose = 0, \n                                    min_delta = 1e-4, mode = 'max')\n\n\n            es = EarlyStopping(monitor = 'val_AUC', min_delta = 1e-4, patience = 7, mode = 'max', \n                               baseline = None, restore_best_weights = True, verbose = 0)\n\n\n            model.fit(train_df, train_target, validation_data = (val_df, val_target), epochs = 1000, \n                      batch_size = batch_size, callbacks = [rlr, es], verbose = 0)\n\n\n            temp_oof = model.predict(val_df, batch_size = batch_size * 4).ravel()\n\n            business_metric_opt, cutoff = optimal_cutoff(val_target, temp_oof, only_fun= False)\n            cut.append(cutoff[0])  \n\n            temp_oof  = (temp_oof > cutoff[0]).astype(int)\n            train_oof[val_ind] += (temp_oof \/ mrange)\n        \n            temp_test = model.predict(test[columns])\n            temp_test = (temp_test > cutoff[0])        \n        \n            test_preds_avg = test_preds_avg + (temp_test \/ mrange)\n        \n            K.clear_session()\n            del model\n            rubbish = gc.collect()\n\n            \n        test_preds += ((test_preds_avg)\/(NUM_FOLDS*NUM_REPEATS))\n        \n        scores.append(f1_score(val_target, temp_oof))\n\n        print(f'Fold {f}: {f1_score(val_target, (temp_oof >= 0.5).astype(int))}')\n        print(f'Best f1 score: {business_metric_opt} ----  cutoff: {cutoff[0]}')\n\n        \n    print(\"Mean F1 Score: \", np.mean(scores))\n    print(f'F1 Score OOF: {f1_score(y, (train_oof >= 0.5).astype(int))}')\n\n    return (train_oof >= 0.5).astype(int), (test_preds >= 0.5).astype(int), np.mean(scores)","47e84411":"columns = X_test.columns\n\nclf = None\n\ntrain_oof_1, test_preds_1, score_oof_1 = cross_valid(clf, X, y, X_test, num_folds=NUM_FOLDS, random_state=SEED)\n\nprint(f'CV: {f1_score(y, train_oof_1)}')","af3f7a35":"# Fold 0: 0.5567765567765568\n# Best f1 score: 0.5567765567765568 ----  cutoff: 0.27645615089621667\n# Fold 1: 0.6194398682042833\n# Best f1 score: 0.6194398682042833 ----  cutoff: 0.2623411028812064\n# Fold 2: 0.5888324873096447\n# Best f1 score: 0.5888324873096447 ----  cutoff: 0.1904531406501712\n# Fold 3: 0.634920634920635\n# Best f1 score: 0.634920634920635 ----  cutoff: 0.21441705772226313\n# Fold 4: 0.5870445344129555\n# Best f1 score: 0.5870445344129555 ----  cutoff: 0.3943412897919669\n# Fold 5: 0.6250000000000001\n# Best f1 score: 0.6250000000000001 ----  cutoff: 0.3578938890031358\n# Fold 6: 0.6097560975609756\n# Best f1 score: 0.6097560975609756 ----  cutoff: 0.24849551455529834\n# Fold 7: 0.6397188049209139\n# Best f1 score: 0.6397188049209139 ----  cutoff: 0.3343530106212663\n# Fold 8: 0.6042065009560229\n# Best f1 score: 0.6042065009560229 ----  cutoff: 0.3467769421648002\n# Fold 9: 0.5961002785515321\n# Best f1 score: 0.5961002785515321 ----  cutoff: 0.14393520390159936\n# Mean F1 Score:  0.6061795763613519\n# F1 Score OOF: 0.6065743944636678\n# CV: 0.6065743944636678","6d0ae72f":"# Fold 0: 0.5861027190332326\n# Best f1 score: 0.5861027190332326 ----  cutoff: 0.16791291037566652\n# Fold 1: 0.6113671274961597\n# Best f1 score: 0.6113671274961597 ----  cutoff: 0.197041552574232\n# Fold 2: 0.6163934426229507\n# Best f1 score: 0.6163934426229507 ----  cutoff: 0.2169035930173714\n# Fold 3: 0.6463414634146342\n# Best f1 score: 0.6463414634146342 ----  cutoff: 0.21645076584951045\n# Fold 4: 0.6292134831460674\n# Best f1 score: 0.6292134831460674 ----  cutoff: 0.352944365743085\n# Fold 5: 0.6365054602184087\n# Best f1 score: 0.6365054602184087 ----  cutoff: 0.19438142339321393\n# Fold 6: 0.6472602739726027\n# Best f1 score: 0.6472602739726027 ----  cutoff: 0.3149464927046893\n# Fold 7: 0.6699669966996699\n# Best f1 score: 0.6699669966996699 ----  cutoff: 0.2782603706923412\n# Fold 8: 0.6394779771615009\n# Best f1 score: 0.6394779771615009 ----  cutoff: 0.2528239028520541\n# Fold 9: 0.6586206896551723\n# Best f1 score: 0.6586206896551723 ----  cutoff: 0.28655595555316266\n# Mean F1 Score:  0.6341249633420399\n# F1 Score OOF: 0.6335343001466515\n# CV: 0.6335343001466515","eb68fd1c":"np.save('train_oof_nn_tf.npy', train_oof_1)\nnp.save('test_preds_nn_tf.npy', test_preds_1)","3d70b36f":"(test_preds_1 == 0).sum()","b5cbb998":"(test_preds_1 == 1).sum()","e4033485":"submission['predicted'] = test_preds_1.astype(int)\nsubmission.to_csv('submission_nn_tensorflow.csv', index=False)\nprint(submission)","2889790a":"# Submitting"}}