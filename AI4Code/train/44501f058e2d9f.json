{"cell_type":{"88ddba7b":"code","a0b48021":"code","8bb5b266":"code","663465fa":"code","16b71ddf":"code","a9f90b8b":"code","34e25bea":"code","2dbbb8d9":"code","980c5c66":"code","bca40db5":"code","f0bd0ecc":"code","bad3b169":"code","ff2a71e7":"code","f7358652":"code","cc2533cc":"code","dbc17756":"code","af4532c8":"code","ed193319":"markdown","d5aa0d55":"markdown","ce28df34":"markdown","44f9c84d":"markdown","d835a5fe":"markdown","4b288360":"markdown"},"source":{"88ddba7b":"!pip install surprise\n!wget http:\/\/www2.informatik.uni-freiburg.de\/~cziegler\/BX\/BX-CSV-Dump.zip\n    \nimport zipfile\n\nzip_ref = zipfile.ZipFile('BX-CSV-Dump.zip', 'r')\nzip_ref.extractall(\"BX_CSV_Dump\")\nzip_ref.close()","a0b48021":"import pandas as pd\nimport numpy as np\n\nfrom plotly.offline import init_notebook_mode, plot, iplot\nimport plotly.graph_objs as go\ninit_notebook_mode(connected=True)\n\nfrom surprise.reader import Reader\nfrom surprise.dataset import Dataset\nfrom surprise import SVD, SVDpp, SlopeOne, NMF, NormalPredictor\nfrom surprise import KNNBaseline, KNNBasic, KNNWithMeans, KNNWithZScore\nfrom surprise import BaselineOnly, CoClustering\nfrom surprise.model_selection import cross_validate, train_test_split\nfrom surprise import accuracy","8bb5b266":"# reading BX-Users and removing bad lines from the dataframe\n# we will just use the following 3 columns\nuser = pd.read_csv('BX_CSV_Dump\/BX-Users.csv', sep=';', \n                   error_bad_lines=False, encoding=\"latin-1\")\nuser.columns = ['userID', 'Location', 'Age']\n\n# reading BX-Book-Ratings and removing bad lines from the dataframe\n# we will just use the following 3 columns\nrating = pd.read_csv('BX_CSV_Dump\/BX-Book-Ratings.csv', sep=';', \n                     error_bad_lines=False, encoding=\"latin-1\")\nrating.columns = ['userID', 'ISBN', 'bookRating']\n\n# performing inner join on userID\n# dropping unnecessary columns\ndf = pd.merge(user, rating, on='userID', how='inner')\ndf.drop(['Location', 'Age'], axis=1, inplace=True)\n\ndf.head()","663465fa":"data = df['bookRating'].value_counts().sort_index(ascending=False)\ntrace = go.Bar(x = data.index,\n               text = ['{:.1f} %'.format(val) for val in (data.values \/ df.shape[0] * 100)],\n               textposition = 'auto',\n               textfont = dict(color = '#000000'),\n               y = data.values,\n               )\n# Create layout\nlayout = dict(title = 'Distribution Of {} book-ratings'.format(df.shape[0]),\n              xaxis = dict(title = 'Rating'),\n              yaxis = dict(title = 'Count'))\n# Create plot\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","16b71ddf":"# Number of ratings per book\ndata = df.groupby('ISBN')['bookRating'].count().clip(upper=50)\n\n# Create trace\ntrace = go.Histogram(x = data.values,\n                     name = 'Ratings',\n                     xbins = dict(start = 0,\n                                  end = 50,\n                                  size = 2))\n# Create layout\nlayout = go.Layout(title = 'Distribution Of Number of Ratings Per Book (Clipped at 100)',\n                   xaxis = dict(title = 'Number of Ratings Per Book'),\n                   yaxis = dict(title = 'Count'),\n                   bargap = 0.2)\n\n# Create plot\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","a9f90b8b":"df.groupby('ISBN')['bookRating'].count().reset_index().sort_values('bookRating', ascending=False)[:10]","34e25bea":"# Number of ratings per user\ndata = df.groupby('userID')['bookRating'].count().clip(upper=50)\n\n# Create trace\ntrace = go.Histogram(x = data.values,\n                     name = 'Ratings',\n                     xbins = dict(start = 0,\n                                  end = 50,\n                                  size = 2))\n# Create layout\nlayout = go.Layout(title = 'Distribution Of Number of Ratings Per User (Clipped at 50)',\n                   xaxis = dict(title = 'Ratings Per User'),\n                   yaxis = dict(title = 'Count'),\n                   bargap = 0.2)\n\n# Create plot\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","2dbbb8d9":"df.groupby('userID')['bookRating'].count().reset_index().sort_values('bookRating', ascending=False)[:10]","980c5c66":"min_book_ratings = 50\nfilter_books = df['ISBN'].value_counts() > min_book_ratings\nfilter_books = filter_books[filter_books].index.tolist()\n\nmin_user_ratings = 50\nfilter_users = df['userID'].value_counts() > min_user_ratings\nfilter_users = filter_users[filter_users].index.tolist()\n\ndf_new = df[(df['ISBN'].isin(filter_books)) & (df['userID'].isin(filter_users))]\nprint('The original data frame shape:\\t{}'.format(df.shape))\nprint('The new data frame shape:\\t{}'.format(df_new.shape))","bca40db5":"reader = Reader(rating_scale=(0, 9))\ndata = Dataset.load_from_df(df_new[['userID', 'ISBN', 'bookRating']], reader)","f0bd0ecc":"benchmark = []\n# Iterate over all algorithms\nfor algorithm in [SVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(), \n                  KNNBasic(), KNNWithMeans(), KNNWithZScore(), BaselineOnly(), CoClustering()]:\n    # Perform cross validation\n    results = cross_validate(algorithm, data, measures=['RMSE'], cv=3, verbose=False)\n    \n    # Get results & append algorithm name\n    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n    benchmark.append(tmp)\n    \npd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')    ","bad3b169":"print('Using ALS')\nbsl_options = {'method': 'als',\n               'n_epochs': 5,\n               'reg_u': 12,\n               'reg_i': 5\n               }\nalgo = KNNBaseline(bsl_options=bsl_options)\ncross_validate(algo, data, measures=['RMSE'], cv=3, verbose=False)","ff2a71e7":"trainset, testset = train_test_split(data, test_size=0.25)\nalgo = KNNBaseline(bsl_options=bsl_options)\npredictions = algo.fit(trainset).test(testset)\naccuracy.rmse(predictions)","f7358652":"def get_Iu(uid):\n    \"\"\" return the number of items rated by given user\n    args: \n      uid: the id of the user\n    returns: \n      the number of items rated by the user\n    \"\"\"\n    try:\n        return len(trainset.ur[trainset.to_inner_uid(uid)])\n    except ValueError: # user was not part of the trainset\n        return 0\n    \ndef get_Ui(iid):\n    \"\"\" return number of users that have rated given item\n    args:\n      iid: the raw id of the item\n    returns:\n      the number of users that have rated the item.\n    \"\"\"\n    try: \n        return len(trainset.ir[trainset.to_inner_iid(iid)])\n    except ValueError:\n        return 0\n    \ndf = pd.DataFrame(predictions, columns=['uid', 'iid', 'rui', 'est', 'details'])\ndf['Iu'] = df.uid.apply(get_Iu)\ndf['Ui'] = df.iid.apply(get_Ui)\ndf['err'] = abs(df.est - df.rui)\nbest_predictions = df.sort_values(by='err')[:10]\nworst_predictions = df.sort_values(by='err')[-10:]","cc2533cc":"best_predictions","dbc17756":"worst_predictions","af4532c8":"import matplotlib.pyplot as plt\n%matplotlib notebook\ndf_new.loc[df_new['ISBN'] == '055358264X']['bookRating'].hist()\nplt.xlabel('rating')\nplt.ylabel('Number of ratings')\nplt.title('Number of ratings book ISBN 055358264X has received')\nplt.show();","ed193319":"From the plot and returned ratings, we can infer that most of our books have received number of ratings less than 6","d5aa0d55":"## Ratings Distribution by Book","ce28df34":"## Ratings Distribution by User","44f9c84d":"### To reduce the dimensionality of the data set, and avoid running into \u201cmemory error\u201d, we will filter out rarely rated movies and rarely rating users.","d835a5fe":"* From the above plot we can see that most of our data has ratings = 0 \n* Ratings range from 1 - 10","4b288360":"## Performing EDA on our dataset (Book Ratings)"}}