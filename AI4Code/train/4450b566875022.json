{"cell_type":{"43581e64":"code","a4dbeee8":"code","3ad48394":"code","b6c01a71":"code","fac5497a":"code","fe652ed9":"code","6a303f09":"code","e72ae4d4":"code","e521406a":"code","27cd6637":"code","a818a51a":"code","33549676":"code","941aa797":"code","743df56b":"code","ac7aec5d":"code","406ad33a":"code","45b3f686":"code","3ee60b62":"code","bbb092b3":"code","d2c9eb62":"code","4e569314":"code","258ea5c8":"markdown","52d3fe55":"markdown","84b01205":"markdown","b3d19d45":"markdown","80ebcf6b":"markdown","616424da":"markdown","121f1856":"markdown","cec6d6dc":"markdown"},"source":{"43581e64":"\n# for visualization -------------------\n\nimport matplotlib.pyplot as plt\nimport seaborn as srn\n\n# for data pipeline --------------------\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import*\n\n# for prediction (machine learning models) ------------------------\n\nfrom sklearn.linear_model import*\nfrom sklearn.preprocessing import*\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import*\nfrom sklearn.neighbors import*\nfrom sklearn import svm\nfrom sklearn.naive_bayes import*","a4dbeee8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3ad48394":"df=pd.read_csv('\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv')\ndf","b6c01a71":"df.info()","fac5497a":"ar1=[]\nar2=[]\nar3=[]\nar4=[]\nar5=[]\nar6=[]\ncolm=[]\nfor col in df.columns:\n    if col != 'Outcome':\n        colm.append(col)\n        x1=df[df['Outcome']==0]\n        x2=df[df['Outcome']==1]\n        m1=max(df[col])\n        m2=min(df[col])\n        ar1.append((np.mean(x1[col])-m2)\/(m1-m2))\n        ar2.append((np.mean(x2[col])-m2)\/(m1-m2))\n        ar3.append((np.median(x1[col])-m2)\/(m1-m2))\n        ar4.append((np.median(x2[col])-m2)\/(m1-m2))\n        ar5.append((x1[col].mode()-m2)\/(m1-m2))\n        ar6.append((x2[col].mode()-m2)\/(m1-m2))","fe652ed9":"plt.plot(colm,ar1,label='mean output : 0')\nplt.legend()\nplt.plot(colm,ar2,label='mean output : 1')\nplt.legend()\nplt.xticks(rotation=300)\nplt.show()","6a303f09":"\nplt.plot(colm,ar3,label='median output : 0')\nplt.legend()\nplt.plot(colm,ar4,label='median output : 1')\nplt.legend()\nplt.xticks(rotation=300)\nplt.show()","e72ae4d4":"\nplt.plot(colm,ar5,label='mode output : 0')\nplt.legend()\nplt.plot(colm,ar6,label='mode output : 1')\nplt.legend()\n\nplt.xticks(rotation=300)\nplt.show()","e521406a":"df.duplicated().value_counts()","27cd6637":"model=RandomForestRegressor()","a818a51a":"X=df.drop('Outcome',1)\ny=df['Outcome']","33549676":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)","941aa797":"model.fit(X_train,y_train)\nmodel.score(X_train,y_train)\nmodel.score(X_test,y_test)","743df56b":"model=RandomForestClassifier()","ac7aec5d":"model.fit(X_train,y_train)\nmodel.score(X_train,y_train)\nmodel.score(X_test,y_test)","406ad33a":"model=KNeighborsClassifier(n_neighbors=2)","45b3f686":"model.fit(X_train,y_train)\nmodel.score(X_train,y_train)\nmodel.score(X_test,y_test)","3ee60b62":"model=svm.SVC()","bbb092b3":"model.fit(X_train,y_train)\nmodel.score(X_train,y_train)\nmodel.score(X_test,y_test)","d2c9eb62":"model=GaussianNB()","4e569314":"model.fit(X_train,y_train)\nmodel.score(X_train,y_train)\nmodel.score(X_test,y_test)","258ea5c8":"after checking through various classifiers the SVM gave us the best prediction.","52d3fe55":"Creating X and Y","84b01205":"The outcome 1 condition is always greater than the outcome 0 condition.\n\nstill the Glucose condition has a much higher value of outcome 1.","b3d19d45":"scaling and average representation","80ebcf6b":"train-test split","616424da":"Clearly visible that there are no leakages and no object type column. So we don't have to preprocess anything. Going to EDA","121f1856":"There are no duplicates in the data . So it is clear to go forward.","cec6d6dc":"### UPVOTE if you like the kernel :)"}}