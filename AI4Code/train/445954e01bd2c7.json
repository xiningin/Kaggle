{"cell_type":{"8e29378d":"code","9b04435d":"code","57239a4f":"code","a932a104":"code","34bf399b":"code","7b38e16b":"code","0f602ece":"code","9da4e098":"code","5f54afe5":"code","cd2de148":"code","1878088e":"code","c027ac58":"code","126b134e":"code","db52e2be":"code","4f958dd8":"code","46a2c3e3":"code","f4cf4e63":"code","25d2eff6":"code","e1dbf63e":"code","babd3ecc":"code","b5ffd9fc":"code","be8dba40":"code","b87064db":"code","fdf4015c":"code","64c55cd3":"code","cda573be":"code","4518c0ba":"code","dbf95f3b":"code","c78a7629":"markdown","508b2dca":"markdown","522a54c7":"markdown","a8bf3a67":"markdown","a9447f29":"markdown","3616ebce":"markdown","892bbe15":"markdown","2b79034b":"markdown","a30e727c":"markdown","435d2b95":"markdown","ed041cf1":"markdown","bd31fd72":"markdown","3e4d7a37":"markdown","3426a253":"markdown","19436829":"markdown","868081ca":"markdown"},"source":{"8e29378d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nsns.set()\nimport numpy as np # linear algebra\n # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import  *\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.keras.applications import DenseNet121, VGG19, ResNet50\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport PIL.Image\nimport matplotlib.pyplot as mpimg\nimport os\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\nfrom tensorflow.keras.preprocessing import image\n\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.utils import shuffle\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9b04435d":"train_df = pd.read_csv('..\/input\/coronahack-chest-xraydataset\/Chest_xray_Corona_Metadata.csv')\ntrain_df.shape","57239a4f":"train_df.head(5)","a932a104":"train_df.info()","34bf399b":"missing_vals = train_df.isnull().sum()\nmissing_vals.plot(kind = 'bar')","7b38e16b":"train_df.dropna(how = 'all')\ntrain_df.isnull().sum()","0f602ece":"#impute unknown to null data points, we don't wanna see those ugly null values\ntrain_df.fillna('unknown', inplace=True)\ntrain_df.isnull().sum()","9da4e098":"train_data = train_df[train_df['Dataset_type'] == 'TRAIN']\ntest_data = train_df[train_df['Dataset_type'] == 'TEST']\nassert train_data.shape[0] + test_data.shape[0] == train_df.shape[0]\nprint(f\"Shape of train data : {train_data.shape}\")\nprint(f\"Shape of test data : {test_data.shape}\")\ntest_data.sample(10)","5f54afe5":"print((train_df['Label_1_Virus_category']).value_counts())\nprint('--------------------------')\nprint((train_df['Label_2_Virus_category']).value_counts())","cd2de148":"plt.figure(figsize=(15,10))\nsns.countplot(train_data['Label_2_Virus_category']);","1878088e":"test_img_dir = '\/kaggle\/input\/coronahack-chest-xraydataset\/Coronahack-Chest-XRay-Dataset\/Coronahack-Chest-XRay-Dataset\/test'\ntrain_img_dir = '\/kaggle\/input\/coronahack-chest-xraydataset\/Coronahack-Chest-XRay-Dataset\/Coronahack-Chest-XRay-Dataset\/train'\n\nsample_train_images = list(os.walk(train_img_dir))[0][2][:8]\nsample_train_images = list(map(lambda x: os.path.join(train_img_dir, x), sample_train_images))\n\nsample_test_images = list(os.walk(test_img_dir))[0][2][:8]\nsample_test_images = list(map(lambda x: os.path.join(test_img_dir, x), sample_test_images))","c027ac58":"plt.figure(figsize = (10,10))\nfor iterator, filename in enumerate(sample_train_images):\n    image = PIL.Image.open(filename)\n    plt.subplot(4,2,iterator+1)\n    plt.imshow(image, cmap=plt.cm.bone)\n\nplt.tight_layout()","126b134e":"fig, ax = plt.subplots(4, 2, figsize=(15, 10))\n\n\ncovid_path = train_data[train_data['Label_2_Virus_category']=='COVID-19']['X_ray_image_name'].values\n\nsample_covid_path = covid_path[:4]\nsample_covid_path = list(map(lambda x: os.path.join(train_img_dir, x), sample_covid_path))\n\nfor row, file in enumerate(sample_covid_path):\n    image = plt.imread(file)\n    ax[row, 0].imshow(image, cmap=plt.cm.bone)\n    ax[row, 1].hist(image.ravel(), 256, [0,256])\n    ax[row, 0].axis('off')\n    if row == 0:\n        ax[row, 0].set_title('Images')\n        ax[row, 1].set_title('Histograms')\nfig.suptitle('Label 2 Virus Category = COVID-19', size=16)\nplt.show()","db52e2be":"fig, ax = plt.subplots(4, 2, figsize=(15, 10))\n\n\nnormal_path = train_data[train_data['Label']=='Normal']['X_ray_image_name'].values\n\nsample_normal_path = normal_path[:4]\nsample_normal_path = list(map(lambda x: os.path.join(train_img_dir, x), sample_normal_path))\n\nfor row, file in enumerate(sample_normal_path):\n    image = plt.imread(file)\n    ax[row, 0].imshow(image, cmap=plt.cm.bone)\n    ax[row, 1].hist(image.ravel(), 256, [0,256])\n    ax[row, 0].axis('off')\n    if row == 0:\n        ax[row, 0].set_title('Images')\n        ax[row, 1].set_title('Histograms')\nfig.suptitle('Label = NORMAL', size=16)\nplt.show()","4f958dd8":"#remove Pnuemonia with unknown value\nfinal_train_data = train_data[(train_data['Label'] == 'Normal') | \n                              ((train_data['Label'] == 'Pnemonia') &\n                               (train_data['Label_2_Virus_category'] == 'COVID-19'))]\n\n# add a target and class feature\nfinal_train_data['class'] = final_train_data.Label.apply(lambda x: 'negative' if x=='Normal' else 'positive')\ntest_data['class'] = test_data.Label.apply(lambda x: 'negative' if x=='Normal' else 'positive')\n\nfinal_train_data['target'] = final_train_data.Label.apply(lambda x: 0 if x=='Normal' else 1)\ntest_data['target'] = test_data.Label.apply(lambda x: 0 if x=='Normal' else 1)\n#get the important features\nfinal_train_data = final_train_data[['X_ray_image_name', 'class', 'target', 'Label_2_Virus_category']]\nfinal_test_data = test_data[['X_ray_image_name', 'class', 'target']]\n\ntest_data['Label'].value_counts()","46a2c3e3":"#create a imagegenerator for for augmentation\ndatagen =  ImageDataGenerator(\n  shear_range=0.2,\n  zoom_range=0.2,\n)\ndef read_img(filename, size, path):\n    img = image.load_img(os.path.join(path, filename), target_size=size)\n    #convert image to array\n    img = img_to_array(img) \/ 255\n    return img","f4cf4e63":"#augment the images labeled with covid-19 to balance the data\n\ncorona_df = final_train_data[final_train_data['Label_2_Virus_category'] == 'COVID-19']\nwith_corona_augmented = []\n\n#create a function for augmentation\ndef augment(name):\n    img = read_img(name, (255,255), train_img_dir)\n    i = 0\n    for batch in tqdm(datagen.flow(tf.expand_dims(img, 0), batch_size=32)):\n        with_corona_augmented.append(tf.squeeze(batch).numpy())\n        if i == 20:\n            break\n        i =i+1\n\n#apply the function\ncorona_df['X_ray_image_name'].apply(augment)","25d2eff6":"# extract the image from traing data and test data, then convert them as array\ntrain_arrays = [] \nfinal_train_data['X_ray_image_name'].apply(lambda x: train_arrays.append(read_img(x, (255,255), train_img_dir)))\ntest_arrays = []\nfinal_test_data['X_ray_image_name'].apply(lambda x: test_arrays.append(read_img(x, (255,255), test_img_dir)))","e1dbf63e":"#concatenate the training data labels and the labels for augmented images\ny_train = np.concatenate((np.int64(final_train_data['target'].values), np.ones(len(with_corona_augmented), dtype=np.int64)))","babd3ecc":"# Converting Data to tensors\ntrain_tensors = tf.convert_to_tensor(np.concatenate((np.array(train_arrays), np.array(with_corona_augmented))))\ntest_tensors  = tf.convert_to_tensor(np.array(test_arrays))\ny_train_tensor = tf.convert_to_tensor(y_train)\ny_test_tensor = tf.convert_to_tensor(final_test_data['target'].values)\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_tensors, y_train_tensor))\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_tensors, y_test_tensor))","b5ffd9fc":"BATCH_SIZE = 16\nBUFFER = 1000\n\ntrain_batches = train_dataset.shuffle(BUFFER).batch(BATCH_SIZE)\ntest_batches = test_dataset.batch(BATCH_SIZE)","be8dba40":"#define input shape\nINPUT_SHAPE = (255,255,3) \n\n#get the pretrained model\nbase_model = tf.keras.applications.ResNet50(input_shape= INPUT_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')\n\n#set the trainable method of covolution layer as false\n# why set to false?? because we don't want to mess up the pretrained weights of the model!!\nbase_model.trainable = False","b87064db":"#let's try to pass an image to the model to verify the output shape\nfor i,l in train_batches.take(1):\n    pass\nbase_model(i).shape","fdf4015c":"model = Sequential()\nmodel.add(base_model)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(128))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation = 'sigmoid'))","64c55cd3":"#add a earlystopping callback to stop the training if the model is not learning anymore\ncallbacks = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n\n#let's just choose adam as our optimizer, we all love adam anyway.\nmodel.compile(optimizer='adam',\n              loss = 'binary_crossentropy',\n              metrics=['accuracy'])\n","cda573be":"model.fit(train_batches, epochs=10, validation_data=test_batches, callbacks=[callbacks])","4518c0ba":"#predict the test data\npred = model.predict_classes(np.array(test_arrays))\n#let's print a classification report\nfrom sklearn.metrics import classification_report, confusion_matrix\nprint(classification_report(test_data['target'], pred.flatten()))","dbf95f3b":"con_mat = confusion_matrix(test_data['target'], pred.flatten())\nplt.figure(figsize = (10,10))\nplt.title('CONFUSION MATRIX')\nsns.heatmap(con_mat, cmap='coolwarm',\n            yticklabels=['Negative', 'Positive'],\n            xticklabels=['Negative', 'Positive'],\n            annot=True);","c78a7629":"Let's fill the missing values with 'unknown'","508b2dca":"# Load the libraries","522a54c7":"**Credits to [John Wendell](https:\/\/www.kaggle.com\/delllectron\/deep-learning-on-covid-19) for an awesome implementation**","a8bf3a67":"**WORK IN PROGRESS**","a9447f29":"# Let's Visualize Label_2 virus category","3616ebce":"**Label_2 virus category consists of COVID-19 cases!!**","892bbe15":"# Histogram analysis of Images","2b79034b":"# 2. Missing Values","a30e727c":"**Normal Histogram images**","435d2b95":"# ResNet 50","ed041cf1":"# 4. Display Images","bd31fd72":"# COVID-19 Pandemic\n\n![](https:\/\/www.statnews.com\/wp-content\/uploads\/2020\/02\/Coronavirus-CDC-645x645.jpg)\n\nSource = https:\/\/www.statnews.com\/wp-content\/uploads\/2020\/02\/Coronavirus-CDC-645x645.jpg\n","3e4d7a37":"# 5. Image Augmentation","3426a253":"**For COVID-19 cases**","19436829":"# 8. References\nThanks to some amazing notebooks I was able to learn how to display images in an orderly fashion and was able to apply transfer learning CNN in COVID related applications.\n1. https:\/\/www.kaggle.com\/adityam1311\/covid-19-x-ray-images-eda-models\/notebook\n2. https:\/\/www.kaggle.com\/eswarchandt\/covid-19-detection-from-lung-x-rays","868081ca":"# Understanding some cols"}}