{"cell_type":{"0c28a819":"code","236d19e0":"code","55fa947b":"code","cf2d58ff":"code","b9d35be3":"code","76df1f8a":"code","4f1a3764":"code","0825eb8e":"code","fb2d9d84":"code","2182b6aa":"code","d47ebab0":"code","76a9c35e":"code","48909ff3":"code","5c66f89e":"code","8c106fa1":"code","e2670fb6":"code","daba62e2":"code","46076026":"code","2ae2e9d8":"code","099caf07":"markdown"},"source":{"0c28a819":"!pip install --use-feature=2020-resolver https:\/\/s3-us-west-2.amazonaws.com\/xgboost-nightly-builds\/xgboost-1.3.0_SNAPSHOT%2Bdda9e1e4879118738d9f9d5094246692c0f6123c-py3-none-manylinux2010_x86_64.whl","236d19e0":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport random\nimport glob\nimport os\nfrom scipy.interpolate import interp1d\nfrom scipy import signal\nimport gc\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GroupKFold\nimport lightgbm as lgb\nfrom joblib import Parallel, delayed\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import train_test_split\nimport shap\n\nimport soundfile as sf\n# Librosa Libraries\nimport librosa\nimport librosa.display\nimport IPython.display as ipd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import roc_auc_score, accuracy_score\n\nimport xgboost","55fa947b":"train_files = glob.glob( '..\/input\/rfcx-species-audio-detection\/train\/*.flac' )\ntest_files = glob.glob( '..\/input\/rfcx-species-audio-detection\/test\/*.flac' )\nlen(train_files), len(test_files), train_files[0]","cf2d58ff":"def extract_features(fn):\n    data, samplerate = sf.read(fn)\n    data_fft = np.fft.fft(data)\n    data_fft = data_fft[:(len(data)\/\/2)]\n    varfft = np.abs(data_fft)\n    x = np.linspace(0, len(varfft), num=len(varfft), endpoint=True)\n    f1 = interp1d(x, varfft, kind='cubic')\n    x = np.linspace(0, len(varfft), num=1000, endpoint=True)\n    varfft = f1(x)\n    \n    return varfft","b9d35be3":"train_fft_features = Parallel(n_jobs=4)(delayed(extract_features)(fn) for fn in tqdm(train_files))\ntrain_fft_features = np.stack(train_fft_features)\ngc.collect()\n\ntrain_fft_features.shape","76df1f8a":"test_fft_features = Parallel(n_jobs=4)(delayed(extract_features)(fn) for fn in tqdm(test_files))\ntest_fft_features = np.stack(test_fft_features)\ngc.collect()\n\ntest_fft_features.shape","4f1a3764":"target = np.hstack([np.ones(train_fft_features.shape[0]), np.zeros(train_fft_features.shape[0])])","0825eb8e":"train_test = np.vstack([train_fft_features, test_fft_features])","fb2d9d84":"index = list(range(train_test.shape[0]))\nrandom.shuffle(index)","2182b6aa":"train_test = train_test[index, :]\ntarget = target[index]","d47ebab0":"train, test, y_train, y_test = train_test_split(train_test, target, test_size=0.33, random_state=42)","76a9c35e":"train = xgboost.DMatrix(train, label=y_train)\ntest = xgboost.DMatrix(test, label=y_test)","48909ff3":"%%time\nparam = {\n    'eta': 0.05,\n    'max_depth': 10,\n    'subsample': 0.8,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:logistic',\n    'eval_metric': 'auc',\n    'tree_method': 'gpu_hist', \n    'predictor': 'gpu_predictor'\n}\nclf = xgboost.train(param, train, 600)","5c66f89e":"preds = clf.predict(test)","8c106fa1":"roc_auc_score(y_test, preds)","e2670fb6":"%%time\nshap_preds = clf.predict(test, pred_contribs=True)","daba62e2":"shap.initjs()","46076026":"shap.summary_plot(shap_preds[:,:1000])","2ae2e9d8":"shap.summary_plot(shap_preds[:,:1000], plot_type=\"bar\")","099caf07":"This is a modified version of Bojan's Adverserial Rainforest notebook. https:\/\/www.kaggle.com\/tunguz\/adversarial-rainforest\n- fft features are extracted from both train and test at the file level instead of using tp and fp labels for train.\n- The classier trained on this data scores **0.6372492726994334** roc_auc vs **0.8668358325958252** when using tp and fp slices to extract fft features for train.\n- The lower score of ~0.6 suggests the train and test distributions do not differ greatly which seems to be more in line with CV vs LB scores. "}}