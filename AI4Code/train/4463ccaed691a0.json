{"cell_type":{"d84f2e0a":"code","9eae5c53":"code","ddea5a36":"code","0e433902":"code","aa7e167d":"code","aa425cfb":"code","1cd63b1a":"code","77bf4ad8":"code","377b1d43":"code","e1e459b1":"code","2c131c80":"code","5d221c06":"code","2c892f57":"code","40071b30":"code","0547338c":"code","027ffdb3":"code","5beb399f":"code","6fc100fa":"code","4fda2b75":"markdown","2cea4298":"markdown"},"source":{"d84f2e0a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9eae5c53":"import pandas as pd\ndata=pd.read_csv(\"..\/input\/fake-news\/train.csv\")","ddea5a36":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer","0e433902":"data=data.dropna()\n#since null value rows are dropped indexes needs to be reset\nmessages=data.copy()\nmessages.reset_index(inplace=True)","aa7e167d":"messages.head()","aa425cfb":"#stemmatize news titles\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nimport re\nps = PorterStemmer()\ncorpus = []\nfor i in range(0, len(messages)):\n    review = re.sub('[^a-zA-Z]', ' ', messages['text'][i])\n    review = review.lower()\n    review = review.split()\n    \n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)","1cd63b1a":"corpus[:10]","77bf4ad8":"#vectorize all preprocessed titles in corpus\n## Applying Countvectorizer\n# Creating the Bag of Words model\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntfidf =TfidfVectorizer(max_features=5000,ngram_range=(1,3))\nX = tfidf.fit_transform(corpus).toarray()","377b1d43":"y=messages.iloc[:,-1]","e1e459b1":"## Divide the dataset into Train and Test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)","2c131c80":"import matplotlib.pyplot as plt\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    See full source and example: \n    http:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_confusion_matrix.html\n    \n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","5d221c06":"#now implement a classification model Multinomial NB\nfrom sklearn.naive_bayes import MultinomialNB\nclassifier=MultinomialNB()","2c892f57":"from sklearn import metrics\nimport numpy as np\nimport itertools\n\nclassifier.fit(X_train, y_train)\npred = classifier.predict(X_test)\nscore = metrics.accuracy_score(y_test, pred)\nprint(\"accuracy:   %0.3f\" % score)\ncm = metrics.confusion_matrix(y_test, pred)\nplot_confusion_matrix(cm, classes=['FAKE', 'REAL'])","40071b30":"#lets implemet another classification algorithm- Passive Aggressive Classifier\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nlinear_clf = PassiveAggressiveClassifier(max_iter=50)\n\nlinear_clf.fit(X_train, y_train)\npred = linear_clf.predict(X_test)\nscore = metrics.accuracy_score(y_test, pred)\nprint(\"accuracy:   %0.3f\" % score)\ncm = metrics.confusion_matrix(y_test, pred)\nplot_confusion_matrix(cm, classes=['FAKE Data', 'REAL Data'])","0547338c":"import pandas as pd\ntest=pd.read_csv(\"..\/input\/fake-news\/test.csv\")","027ffdb3":"#stemmatize news titles\nimport numpy as np\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nimport re\nps = PorterStemmer()\ncorpus = []\nfor i in range(0, len(test)):\n    \n    if(pd.isnull(test[\"text\"][i])):\n        review=\"\"\n    else:\n        review = re.sub('[^a-zA-Z]', ' ',test['text'][i])\n        review = review.lower()\n        review = review.split()\n\n        review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)","5beb399f":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf=TfidfVectorizer(max_features=5000,ngram_range=(1,3))\nX_test = tfidf.fit_transform(corpus).toarray()\npred=linear_clf.predict(X_test)","6fc100fa":"import csv\nwith open(\".\/output.csv\", \"w\", newline=\"\") as file:\n    writer=csv.writer(file)\n    writer.writerow([\"id\", \"label\"])\n    for i in range(len(test)):\n        writer.writerow([test[\"id\"][i], pred[i]])\nfile.close()\n    ","4fda2b75":"# Multinomial NB\n","2cea4298":"# Passive Aggressive Classiifier\u00b6\n"}}