{"cell_type":{"02715ae8":"code","d8e38888":"code","108d84c2":"code","a4f5cf63":"code","41bf5e85":"code","cf56eab5":"code","ea988d3a":"code","ff52f3ca":"code","76a9af4d":"code","d95ab4e5":"code","2828c52a":"code","a3487573":"code","c246f778":"code","94bd74f3":"code","c7284e3d":"code","34b46855":"code","9987ce56":"code","eca0955d":"code","e40a1ef1":"code","eeb088f7":"code","7c2f46d2":"code","ad75c19f":"code","097bdef6":"code","e73b8527":"code","deab90c2":"code","e335a2ef":"code","171e8297":"code","29c89694":"code","67cb93ca":"code","f9008dde":"code","ad2f37c8":"code","6d2ab45e":"code","5b499014":"code","a09f606a":"code","a172914b":"code","a4adb6e7":"code","7894ed41":"code","3adfcfb1":"code","81d18cb1":"code","c69c13e5":"code","0d5e1242":"code","ac0b76d3":"code","6dd5d0e8":"code","c9065081":"code","bbdb7812":"code","bb16f3e5":"code","01873df1":"code","83d3c584":"code","3e5e8a40":"code","15062eb2":"code","36ab9f87":"code","7110078c":"code","64ac009a":"code","e9f50f0c":"code","2cb2fc83":"code","9f3692b8":"code","1880370f":"code","266c2067":"code","41af10fe":"code","9f14ceba":"code","c1509ed7":"code","dc325a70":"code","d9aea7e1":"code","72b16575":"code","d8e3d3ab":"code","55a39ed4":"code","5a660756":"code","7f9c0f46":"code","e981fa33":"code","ce1fa071":"code","56351745":"code","2c08d0d5":"code","41c43e39":"code","6563114e":"code","9cdbd021":"code","8ce2d51c":"code","26cee817":"code","9528392d":"code","847be683":"code","85ad7bee":"code","d5e40d3d":"code","657dd45e":"code","a3d370c8":"markdown","1aecb5d1":"markdown","39bf7105":"markdown","5ec9a4a4":"markdown","b9cdd74d":"markdown","140a50a0":"markdown","1566f5c2":"markdown","a1453c0a":"markdown","c51e6c13":"markdown","760105e9":"markdown","408993d1":"markdown","3972a19a":"markdown","ef870a5e":"markdown","a0de371f":"markdown","f378ab58":"markdown","e639c327":"markdown","427a6b12":"markdown","742c5879":"markdown","7236f360":"markdown"},"source":{"02715ae8":"# TensorFlow\/keras\u306e\u6700\u65b0version\u3067\u758e\u884c\u5217\u5468\u308a\u3067\u30a8\u30e9\u30fc\u304c\u51fa\u308b\u306e\u3067\u30d0\u30fc\u30b8\u30e7\u30f3\u6307\u5b9a\u3057\u3066\u3044\u307e\u3059\u3002\n# \u73fe\u72b6\u3067\u306f\u672a\u89e3\u6c7a\u306e\u3088\u3046\u3067\u3001PyTorch\u4f7f\u3063\u305f\u307b\u3046\u304c\u3044\u3044\u304b\u3082\u3002\n!pip uninstall tensorflow -y\n!pip install tensorflow==1.11.0\n\n!pip uninstall keras -y\n!pip install keras==2.2.4","d8e38888":"import gc\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport scipy as sp\nimport pandas as pd\nfrom pandas import DataFrame, Series\n\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.metrics import roc_auc_score, mean_squared_error, mean_squared_log_error, log_loss\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom tqdm import tqdm_notebook as tqdm\nfrom category_encoders import OrdinalEncoder\n\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\n\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier","108d84c2":"df_train = pd.read_csv('..\/input\/homework-for-students3\/train.csv', index_col=0, skiprows=lambda x: x%20!=0)\n\ny_train = df_train.tot_cur_bal\nX_train = df_train.drop(['tot_cur_bal'], axis=1)\n\nX_test = pd.read_csv('..\/input\/homework-for-students3\/test.csv', index_col=0, skiprows=lambda x: x%20!=0)","a4f5cf63":"X_train = X_train[y_train.isnull()==False]\ny_train = y_train[y_train.isnull()==False]","41bf5e85":"# \u30c6\u30ad\u30b9\u30c8\u306f\u9664\u3044\u3066\u304a\u304f\u3002\nX_train.drop(['issue_d', 'emp_title'], axis=1, inplace=True)\nX_test.drop(['issue_d', 'emp_title'], axis=1, inplace=True)","cf56eab5":"from category_encoders import OrdinalEncoder\n\ncats = []\n\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object':\n        cats.append(col)\n        \noe = OrdinalEncoder(cols=cats)\n\nX_train = oe.fit_transform(X_train)\nX_test = oe.transform(X_test)","ea988d3a":"X_train.fillna(-99999, inplace=True)\nX_test.fillna(-99999, inplace=True)","ff52f3ca":"X_train.head()","76a9af4d":"X_test.head()","d95ab4e5":"%%time\n# CV\u3057\u3066\u30b9\u30b3\u30a2\u3092\u898b\u3066\u307f\u308b\n# \u306a\u304a\u3001\u305d\u3082\u305d\u3082StratifiedKFold\u304c\u9069\u5207\u306a\u306e\u304b\u306f\u5225\u9014\u8003\u3048\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\n# \u6b21\u56deBuild Model\u306e\u5185\u5bb9\u3067\u3059\u304c\u3001\u662f\u975e\u5404\u81ea\u691c\u8a0e\u3057\u3066\u307f\u3066\u304f\u3060\u3055\u3044\nscores = []\n\nskf = KFold(n_splits=5, random_state=71, shuffle=True)\n\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n    X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n    X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n    \n    clf = GradientBoostingRegressor() \n    \n    clf.fit(X_train_, y_train_)\n    y_pred = clf.predict(X_val)\n    score = mean_squared_error(y_val, y_pred)**0.5\n    scores.append(score)\n    \n    print('CV Score of Fold_%d is %f' % (i, score))","2828c52a":"# Fold_4\u306eactual vs pred\u3092\u30d7\u30ed\u30c3\u30c8\u3057\u3066\u307f\u3088\u3046\nplt.figure(figsize=[7,7])\nplt.scatter(y_val, y_pred, s=5)\nplt.xlabel('actual')\nplt.ylabel('pred')\nplt.show()","a3487573":"%%time\n# \u91d1\u984d\u7cfb\u306a\u306e\u3067\u3001RMSLE\u3067\u6700\u9069\u5316\u3057\u3066\u307f\u308b\u3002\n# \u4f55\u3082\u6307\u5b9a\u3057\u306a\u3044\u3068\u5927\u62b5\u306fRMSE\u3067\u6700\u9069\u5316\u3055\u308c\u308b\u3002\u3053\u3053\u3067\u306f\u5bfe\u6570\u3092\u53d6\u3063\u3066\u304a\u304f\u3068\u3061\u3087\u3046\u3069RMSLE\u306e\u6700\u9069\u5316\u306b\u76f8\u5f53\u3059\u308b\u3002\nscores = []\n\nskf = KFold(n_splits=5, random_state=71, shuffle=True)\n\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n    X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n    X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n    \n    clf = GradientBoostingRegressor() \n    \n    clf.fit(X_train_, np.log1p(y_train_))\n    y_pred = np.expm1(clf.predict(X_val))\n    score = mean_squared_log_error(y_val, y_pred)**0.5\n    scores.append(score)\n    \n    print('CV Score of Fold_%d is %f' % (i, score))","c246f778":"# Fold_4\u306eactual vs pred\u3092\u30d7\u30ed\u30c3\u30c8\u3057\u3066\u307f\u3088\u3046\nplt.figure(figsize=[7,7])\nplt.scatter(y_val, y_pred, s=5)\nplt.xlabel('actual')\nplt.ylabel('pred')\nplt.show()","94bd74f3":"df_train = pd.read_csv('..\/input\/homework-for-students3\/train.csv', index_col=0, skiprows=lambda x: x%20!=0)\n\ny_train = df_train.purpose\nX_train = df_train.drop(['purpose'], axis=1)\n\nX_test = pd.read_csv('..\/input\/homework-for-students3\/test.csv', index_col=0, skiprows=lambda x: x%20!=0)","c7284e3d":"y_train ","34b46855":"le = LabelEncoder()\ny_train = le.fit_transform(y_train)","9987ce56":"# \u30c6\u30ad\u30b9\u30c8\u306f\u9664\u3044\u3066\u304a\u304f\u3002\nX_train.drop(['issue_d', 'emp_title'], axis=1, inplace=True)\nX_test.drop(['issue_d', 'emp_title'], axis=1, inplace=True)","eca0955d":"y_train","e40a1ef1":"cats = []\n\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object':\n        cats.append(col)\n        \noe = OrdinalEncoder(cols=cats)\n\nX_train = oe.fit_transform(X_train)\nX_test = oe.transform(X_test)","eeb088f7":"X_train.fillna(-99999, inplace=True)\nX_test.fillna(-99999, inplace=True)","7c2f46d2":"%%time\n# CV\u3057\u3066\u30b9\u30b3\u30a2\u3092\u898b\u3066\u307f\u308b\n# \u306a\u304a\u3001\u305d\u3082\u305d\u3082StratifiedKFold\u304c\u9069\u5207\u306a\u306e\u304b\u306f\u5225\u9014\u8003\u3048\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\nscores = []\n\nskf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n    X_train_, y_train_ = X_train.values[train_ix], y_train[train_ix]\n    X_val, y_val = X_train.values[test_ix], y_train[test_ix]\n    \n    clf = GradientBoostingClassifier() \n    \n    clf.fit(X_train_, y_train_)\n    y_pred = clf.predict_proba(X_val)\n    score = log_loss(y_val, y_pred)\n    scores.append(score)\n    \n    print('CV Score of Fold_%d is %f' % (i, score))","ad75c19f":"y_pred","097bdef6":"labels = np.argmax(y_pred, axis=1)\nlabels","e73b8527":"# \u4e88\u6e2c\u5024\u3092\u5143\u306e\u30e9\u30d9\u30eb\u306b\u623b\u3057\u3066\u307f\u308b\u3002\nle.inverse_transform(labels)","deab90c2":"le.inverse_transform(y_val)","e335a2ef":"df_train = pd.read_csv('..\/input\/homework-for-students3\/train.csv', index_col=0, skiprows=lambda x: x%20!=0)\n\ny_train = df_train.loan_condition\nX_train = df_train.drop(['loan_condition'], axis=1)\n\nX_test = pd.read_csv('..\/input\/homework-for-students3\/test.csv', index_col=0, skiprows=lambda x: x%20!=0)","171e8297":"# \u30c6\u30ad\u30b9\u30c8\u306f\u9664\u3044\u3066\u304a\u304f\u3002\nX_train.drop(['issue_d', 'emp_title'], axis=1, inplace=True)\nX_test.drop(['issue_d', 'emp_title'], axis=1, inplace=True)","29c89694":"cats = []\n\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object':\n        cats.append(col)\n        \noe = OrdinalEncoder(cols=cats)\n\nX_train = oe.fit_transform(X_train)\nX_test = oe.transform(X_test)","67cb93ca":"X_train.fillna(-99999, inplace=True)\nX_test.fillna(-99999, inplace=True)","f9008dde":"# \u3042\u3068\u3067\u307e\u305f\u4f7f\u3046\u306e\u3067\u4fdd\u5b58\u3057\u3066\u304a\u304f\nX_train.to_csv('X_train_tree.csv')\nX_test.to_csv('X_test_tree.csv')","ad2f37c8":"%%time\n# CV\u3057\u3066\u30b9\u30b3\u30a2\u3092\u898b\u3066\u307f\u308b\n# \u306a\u304a\u3001\u305d\u3082\u305d\u3082StratifiedKFold\u304c\u9069\u5207\u306a\u306e\u304b\u306f\u5225\u9014\u8003\u3048\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\nscores = []\n\nskf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n\nfor i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n    X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n    X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n    \n    clf = GradientBoostingClassifier() \n    \n    clf.fit(X_train_, y_train_)\n    y_pred = clf.predict_proba(X_val)[:,1]\n    score = roc_auc_score(y_val, y_pred)\n    scores.append(score)\n    \n    print('CV Score of Fold_%d is %f' % (i, score))","6d2ab45e":"scores = np.array(scores)","5b499014":"scores.mean(), scores.std()","a09f606a":"df_train = pd.read_csv('..\/input\/homework-for-students3\/train.csv', index_col=0, parse_dates=['issue_d'], skiprows=lambda x: x%20!=0)\ny_train = df_train.loan_condition\nX_train = df_train.drop(['loan_condition'], axis=1)\n\nX_test = pd.read_csv('..\/input\/homework-for-students3\/test.csv', index_col=0, parse_dates=['issue_d'], skiprows=lambda x: x%20!=0)\n\ndel df_train\ngc.collect()","a172914b":"X_train.issue_d.head()","a4adb6e7":"cats = []\n\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object':\n        if col != 'issue_d':\n            cats.append(col)\n        \noe = OrdinalEncoder(cols=cats)\n\nX_train = oe.fit_transform(X_train)\nX_test = oe.transform(X_test)","7894ed41":"year = X_train.issue_d.dt.year\n\nX_train.drop(['issue_d', 'emp_title'], axis=1, inplace=True)\nX_test.drop(['issue_d', 'emp_title'], axis=1, inplace=True)","3adfcfb1":"X_train.fillna(-99999, inplace=True)\nX_test.fillna(-99999, inplace=True)","81d18cb1":"X_train_, y_train_ = X_train[year < 2015], y_train[year < 2015]\nX_val, y_val = X_train[year >= 2015], y_train[year >= 2015]","c69c13e5":"clf = GradientBoostingClassifier() \n\nclf.fit(X_train_, y_train_)\ny_pred = clf.predict_proba(X_val)[:,1]\nscore = roc_auc_score(y_val, y_pred)\n\nprint('Time Split Score is %f' % (score))","0d5e1242":"df_train = pd.read_csv('..\/input\/homework-for-students3\/train.csv', index_col=0, skiprows=lambda x: x%20!=0)\n\ny_train = df_train.loan_condition\nX_train = df_train.drop(['loan_condition'], axis=1)\n\nX_test = pd.read_csv('..\/input\/homework-for-students3\/test.csv', index_col=0, skiprows=lambda x: x%20!=0)\n\ndel df_train\ngc.collect()","ac0b76d3":"# \u4f4f\u6240\uff08\u5dde\uff09\u3092\u30b0\u30eb\u30fc\u30d7\u8b58\u5225\u5b50\u3068\u3057\u3066\u5206\u96e2\u3057\u3066\u304a\u304f\u3002\u65e5\u4ed8\u3068\u30c6\u30ad\u30b9\u30c8\u3082\u9664\u3044\u3066\u304a\u304f\u3002\ngroups = X_train.addr_state.values\n\nX_train.drop(['issue_d', 'emp_title', 'addr_state'], axis=1, inplace=True)\nX_test.drop(['issue_d', 'emp_title', 'addr_state'], axis=1, inplace=True)","6dd5d0e8":"groups","c9065081":"cats = []\n\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object':\n        cats.append(col)\n        \noe = OrdinalEncoder(cols=cats)\n\nX_train = oe.fit_transform(X_train)\nX_test = oe.transform(X_test)","bbdb7812":"X_train.fillna(-99999, inplace=True)\nX_test.fillna(-99999, inplace=True)","bb16f3e5":"score","01873df1":"gkf = GroupKFold(n_splits=5)\nscores = []\n\nfor i, (train_ix, test_ix) in enumerate(tqdm(gkf.split(X_train, y_train, groups))):\n    \n    X_train_, y_train_, groups_train_ = X_train.iloc[train_ix], y_train.iloc[train_ix], groups[train_ix]\n    X_val, y_val, groups_val = X_train.iloc[test_ix], y_train.iloc[test_ix], groups[test_ix]\n    \n    print('Train Groups', np.unique(groups_train_))\n    print('Val Groups', np.unique(groups_val))\n    \n    clf = GradientBoostingClassifier(n_estimators=1) \n    \n    clf.fit(X_train_, y_train_)\n    y_pred = clf.predict_proba(X_val)[:,1]\n    score = roc_auc_score(y_val, y_pred)\n    scores.append(score)\n    \n    print('CV Score of Fold_%d is %f' % (i, score))\n    print('\\n')","83d3c584":"clf = LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.9,\n                                importance_type='split', learning_rate=0.05, max_depth=-1,\n                                min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n                                n_estimators=9999, n_jobs=-1, num_leaves=15, objective=None,\n                                random_state=71, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n                                subsample=1.0, subsample_for_bin=200000, subsample_freq=0)","3e5e8a40":"%%time\nclf.fit(X_train_, y_train_, early_stopping_rounds=20, eval_metric='auc', eval_set=[(X_val, y_val)])","15062eb2":"clf.booster_.feature_importance(importance_type='gain')","36ab9f87":"imp = DataFrame(clf.booster_.feature_importance(importance_type='gain'), index = X_train.columns, columns=['importance']).sort_values(['importance'], ascending=False)\nimp","7110078c":"imp.shape","64ac009a":"use_col = imp.index[:10]","e9f50f0c":"X_train_[use_col]","2cb2fc83":"fig, ax = plt.subplots(figsize=(5, 8))\nlgb.plot_importance(clf, max_num_features=50, ax=ax, importance_type='gain')","9f3692b8":"y_pred = clf.predict_proba(X_val)[:,1]\ny_pred","1880370f":"df_train = pd.read_csv('..\/input\/homework-for-students3\/train.csv', index_col=0, parse_dates=['issue_d'], skiprows=lambda x: x%20!=0)\n#df_train = pd.read_csv('..\/input\/train.csv', index_col=0)\ny_train = df_train.loan_condition\nX_train = df_train.drop(['loan_condition'], axis=1)\n\nX_test = pd.read_csv('..\/input\/homework-for-students3\/test.csv', index_col=0, parse_dates=['issue_d'], skiprows=lambda x: x%20!=0)\n\ndel df_train\ngc.collect()","266c2067":"cat = []\nnum = []\n\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object':\n        if col != 'emp_title':\n            cat.append(col)\n    else:\n        if col != 'issue_d':\n            num.append(col)","41af10fe":"# train\/test\n# \u7279\u5fb4\u91cf\u30bf\u30a4\u30d7\u3054\u3068\u306b\u5206\u5272\u3059\u308b\ncat_train = X_train[cat]\ntxt_train = X_train.emp_title\nX_train = X_train[num]\n\ncat_test = X_test[cat]\ntxt_test = X_test.emp_title\nX_test = X_test[num]","9f14ceba":"from sklearn.preprocessing import StandardScaler","c1509ed7":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train.fillna(X_train.median()))\nX_test = scaler.transform(X_test.fillna(X_test.median()))","dc325a70":"from sklearn.preprocessing import OneHotEncoder\nfrom category_encoders import OrdinalEncoder\nfrom tqdm import tqdm_notebook as tqdm","d9aea7e1":"for col in tqdm(cat):\n    ohe = OneHotEncoder(handle_unknown='ignore', sparse=True)\n    oe = OrdinalEncoder(return_df=False)\n    \n    cat_train[col] = oe.fit_transform(cat_train[[col]])\n    cat_test[col] = oe.transform(cat_test[[col]])    \n    \n    train = ohe.fit_transform(cat_train[[col]])\n    test = ohe.transform(cat_test[[col]])\n    \n    X_train = sp.sparse.hstack([X_train, train])\n    X_test = sp.sparse.hstack([X_test, test])","72b16575":"from sklearn.feature_extraction.text import TfidfVectorizer","d8e3d3ab":"tfidf = TfidfVectorizer(max_features=100000, analyzer='word', ngram_range=(1, 2))","55a39ed4":"train = tfidf.fit_transform(txt_train.fillna('#'))\ntest = tfidf.transform(txt_test.fillna('#'))\n\nX_train = sp.sparse.hstack([X_train, train])\nX_test = sp.sparse.hstack([X_test, test])\n\nX_train = X_train.tocsr()# \u884c\u65b9\u5411\u306e\u30b9\u30e9\u30a4\u30b9\u304c\u3067\u304d\u308b\u3088\u3046\u306b\u5909\u63db\u3059\u308b\nX_test = X_test.tocsr()","5a660756":"del cat_train, cat_test, txt_train, txt_test\ngc.collect()","7f9c0f46":"num_train = int(X_train.shape[0]*0.7)\n\nX_train_ = X_train[:num_train, :]\ny_train_ = y_train[:num_train]\n\nX_val = X_train[num_train:, :]\ny_val = y_train[num_train:]","e981fa33":"from keras.layers import Input, Dense ,Dropout, BatchNormalization\nfrom keras.optimizers import Adam, SGD\nfrom keras.models import Model\nfrom keras.callbacks import EarlyStopping","ce1fa071":"# \u30b7\u30f3\u30d7\u30eb\u306aMLP\n\ndef create_model(input_dim):\n    inp = Input(shape=(input_dim,), sparse=True) # \u758e\u884c\u5217\u3092\u5165\u308c\u308b\n    x = Dense(194, activation='relu')(inp)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(64, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(64, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    outp = Dense(1, activation='sigmoid')(x)\n    model = Model(inputs=inp, outputs=outp)\n    model.compile(loss='binary_crossentropy', optimizer='adam')\n    \n    return model","56351745":"X_train_.shape","2c08d0d5":"model = create_model(X_train_.shape[1])\n\nes = EarlyStopping(monitor='val_loss', patience=0)\n\nmodel.fit(X_train_, y_train_, batch_size=32, epochs=999, validation_data=(X_val, y_val), callbacks=[es])","41c43e39":"roc_auc_score(y_val, model.predict(X_val))","6563114e":"from sklearn.model_selection import GridSearchCV, StratifiedKFold\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nskf = StratifiedKFold(n_splits=3, random_state=71, shuffle=True)\ngkf = GroupKFold(n_splits=3, )\n\nparam_grid = {'learning_rate': [0.05],\n                    'max_depth':  np.linspace(5,12,4,dtype = int),\n                    'colsample_bytree': np.linspace(0.5, 1.0, 3),\n                    'random_state': [71]}\n\nfit_params = {\"early_stopping_rounds\": 20,\n                    \"eval_metric\": 'auc',\n                    \"eval_set\": [(X_val, y_val)]}\n\nclf  = LGBMClassifier(n_estimators=9999, n_jobs=1)\n\ngs = GridSearchCV(clf, param_grid, scoring='roc_auc',  \n                              n_jobs=-1, cv=skf, verbose=True)\n\ngs.fit(X_train_, y_train_, **fit_params,)","9cdbd021":"gs.best_score_","8ce2d51c":"X_train = pd.read_csv('X_train_tree.csv', index_col=0)\nX_test = pd.read_csv('X_test_tree.csv', index_col=0)","26cee817":"from hyperopt import fmin, tpe, hp, rand, Trials\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nfrom lightgbm import LGBMClassifier","9528392d":"def objective(space):\n    scores = []\n\n    skf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n\n    for i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n        X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n        X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n\n        clf = LGBMClassifier(n_estimators=9999, **space) \n\n        clf.fit(X_train_, y_train_, early_stopping_rounds=20, eval_metric='auc', eval_set=[(X_val, y_val)])\n        y_pred = clf.predict_proba(X_val)[:,1]\n        score = roc_auc_score(y_val, y_pred)\n        scores.append(score)\n        \n    scores = np.array(scores)\n    print(scores.mean())\n    \n    return -scores.mean()","847be683":"space ={\n        'max_depth': hp.choice('max_depth', np.arange(10, 30, dtype=int)),\n        'subsample': hp.uniform ('subsample', 0.8, 1),\n        'learning_rate' : hp.quniform('learning_rate', 0.025, 0.5, 0.025),\n        'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 0.05)\n    }","85ad7bee":"trials = Trials()\n\nbest = fmin(fn=objective,\n              space=space, \n              algo=tpe.suggest,\n              max_evals=20, \n              trials=trials, \n              rstate=np.random.RandomState(71) \n             )","d5e40d3d":"LGBMClassifier(**best)","657dd45e":"trials.best_trial['result']","a3d370c8":"## \u5909\u6570\u91cd\u8981\u5ea6\u3092\u898b\u3066\u307f\u3088\u3046","1aecb5d1":"## GroupKfold","39bf7105":"# \u5404\u4e88\u6e2c\u30bf\u30b9\u30af\u306e\u578b\u3092\u30cf\u30f3\u30ba\u30aa\u30f3\u3067\u3084\u3063\u3066\u307f\u3088\u3046","5ec9a4a4":"## \u307e\u305aNumeric\u3092StandardScaler","b9cdd74d":"## \u6b21\u306bcategorical\u3092One-hot","140a50a0":"# \u30cf\u30a4\u30d1\u30e9\u6700\u9069\u5316\u30fb\u30e2\u30c7\u30eb\u9078\u629e","1566f5c2":"## \u5206\u985e\u5668\u306b\u5165\u308c\u3089\u308c\u308b\u3088\u3046\u306b\u6700\u4f4e\u9650\u306e\u30a8\u30f3\u30b3\u30fc\u30c9\u3092\u3057\u3066\u304a\u304f\u3002  \n\u305f\u3060\u3057\u3001\u3053\u306e\u72b6\u614b\u3067\u306f\u30d9\u30b9\u30c8\u306a\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u304b\u3089\u306f\u7a0b\u9060\u3044\u306e\u306f\u3053\u306e\u4e00\u9031\u9593\u3067\u4f53\u9a13\u3057\u305f\u3068\u304a\u308a\u3067\u3059\u3002\n\u5f15\u304d\u7d9a\u304d\u7279\u5fb4\u91cf\u30a8\u30f3\u30b8\u30cb\u30a2\u30ea\u30f3\u30b0\u3082\u9811\u5f35\u308a\u307e\u3057\u3087\u3046","a1453c0a":"## Neural Network","c51e6c13":"## \u6700\u5f8c\u306b\u30c6\u30ad\u30b9\u30c8\u306e\u51e6\u7406","760105e9":"## \u6b21\u306f\u591a\u5024\u5206\u985e","408993d1":"## hyperopt\u3082\u3084\u3063\u3066\u307f\u308b","3972a19a":"## \u4e8c\u5024\u5206\u985e\u306f\u3084\u3063\u305f\u306e\u3067\u3001\u305d\u308c\u4ee5\u5916\u3092\u3084\u3063\u3066\u307f\u3088\u3046\u3002\u307e\u305a\u306f\u56de\u5e30\u304b\u3089\u3002\u53e3\u5ea7\u6b8b\u9ad8\u3092\u30bf\u30fc\u30b2\u30c3\u30c8\u306b\u8a66\u3057\u3066\u307f\u3088\u3046\u3002","ef870a5e":"# Validation Scheme\u306e\u69cb\u7bc9\u306b\u30c1\u30e3\u30ec\u30f3\u30b8","a0de371f":"## \u4eca\u5ea6\u306ftime split","f378ab58":"\u3053\u3053\u3067\u306f\u4f4f\u6240\uff08\u5dde\uff09\u3067\u30b0\u30eb\u30fc\u30d7\u30d1\u30fc\u30c6\u30a3\u30b7\u30e7\u30cb\u30f3\u30b0\u3092\u884c\u3046\u3002","e639c327":"# \u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\u3068\u78ba\u8a8d","427a6b12":"## \u5c64\u5316\u62bd\u51fa","742c5879":"## \u30b0\u30ea\u30c3\u30c9\u30b5\u30fc\u30c1\u3057\u3066\u307f\u3088\u3046","7236f360":"## LightGBM"}}