{"cell_type":{"c6a28bf6":"code","286aee5d":"code","b43b44e6":"code","d4d1beac":"code","545ca223":"code","4db02f4e":"code","163d739e":"code","032cd843":"code","2e623235":"code","f783bb5c":"code","c5123ebf":"code","883157b9":"code","b1b53555":"code","2a5282ff":"code","7003156d":"code","1b00c8f0":"code","29932183":"code","035a133f":"code","e50787b3":"code","4d947491":"code","82ac9301":"code","48416689":"code","5a650a45":"code","912f90a6":"markdown","689a0533":"markdown","86f7d943":"markdown","d1128d87":"markdown"},"source":{"c6a28bf6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","286aee5d":"import pathlib\nimport tensorflow as tf\ndata_dir = pathlib.Path('..\/input\/pcbexperiment\/dataset\/tobeaugmented')","b43b44e6":"#count total number of images in the directory\nimage_count = len(list(data_dir.glob('*\/*.jpg')))\nprint(image_count)","d4d1beac":"import os\n\ndefected_count = next(os.walk('..\/input\/pcbexperiment\/dataset\/tobeaugmented\/defected'))[2] \ndc=len(defected_count)\nprint(\"Images for defected PCB : \",dc)","545ca223":"import os\n\nlist = os.listdir('..\/input\/pcbexperiment\/dataset\/tobeaugmented\/non-defect') # dir is your directory path\nnc = len(list)\nprint(\"Image count for non-defect PCB :\",nc)","4db02f4e":"import matplotlib.pyplot as plt\nx = [\"Defected PCB\",\"non-defect PCB\"]\ny = [dc,nc]\nplt.barh(x, y)\nfor index, value in enumerate(y):\n    plt.text(value, index, str(value))","163d739e":"import os\nonlyfiles = next(os.walk('..\/input\/pcbexperiment\/dataset\/tobeaugmented\/non-defect'))[2] #dir is your directory path as string\nprint(len(onlyfiles))","032cd843":"import numpy as np\nimport os\nimport PIL\nimport PIL.Image\nimport tensorflow as tf\nimport tensorflow_datasets as tfds","2e623235":"from PIL import Image\n#...\ndefected_path='..\/input\/pcbexperiment\/dataset\/tobeaugmented\/defected\/20200707_085703.jpg'\nimg = Image.open(defected_path)\nPIL.Image.open(defected_path)","f783bb5c":"from PIL import Image\n#...\nnondefectpath='..\/input\/pcbexperiment\/dataset\/tobeaugmented\/non-defect\/20200630_114408(1).jpg'\nimg = Image.open(nondefectpath)\nPIL.Image.open(nondefectpath)","c5123ebf":"batch_size = 32\nimg_height = 180\nimg_width = 180","883157b9":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","b1b53555":"val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"validation\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","2a5282ff":"class_names = train_ds.class_names\nprint(class_names)","7003156d":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")","1b00c8f0":"for image_batch, labels_batch in train_ds:\n  print(image_batch.shape)\n  print(labels_batch.shape)\n  break","29932183":"from tensorflow.keras import layers\n\nnormalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1.\/255)","035a133f":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","e50787b3":"num_classes = 2\n\nmodel = tf.keras.Sequential([\n  layers.experimental.preprocessing.Rescaling(1.\/255),\n  layers.Conv2D(32, 3, activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n])","4d947491":"model.compile(\n  optimizer='Nadam',\n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])","82ac9301":"history=model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=3\n)","48416689":"loss, accuracy = model.evaluate(val_ds)","5a650a45":"print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","912f90a6":"# Is the dataset imbalanced?\nwe can check the imbalanceness of the dataset for differet classes by plotting the bar graph using matplotlib library using this code","689a0533":"Here,we see that the number of images for defected PCB\/1 is very less compared to the non-defect PCB\/0. Hence the dataset is imbalanced due to which the dominating class cause unfair results.","86f7d943":"# Load the dataset ","d1128d87":"# Standardize the data\nThe RGB channel values are in the [0, 255] range. This is not ideal for a neural network; in general you should seek to make your input values small. Here, we will standardize values to be in the [0, 1] by using a Rescaling layer."}}