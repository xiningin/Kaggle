{"cell_type":{"3a51ad01":"code","77b4d964":"code","dbf9836b":"code","05628dcb":"code","b5be8b5c":"code","a6d87142":"code","5f402dc4":"code","95474e86":"code","6f42379a":"code","9ca6b57f":"code","5f238531":"code","e611697d":"code","bf36d5fa":"code","82bd94c7":"code","b3d5d5cb":"code","5a49641b":"code","e2124549":"code","dcfda4f7":"code","b9aa4127":"code","6797de00":"code","3d64e227":"code","b420fa73":"code","04628ed8":"code","e131f386":"code","6af9ab34":"code","6e6dbc9a":"code","8ead31eb":"code","9b5f57c4":"code","9859beee":"code","d04ed1c4":"code","9e8b7a34":"markdown","39c29ced":"markdown","1798f9a9":"markdown","017d2d8f":"markdown","0bf734fd":"markdown","36a69616":"markdown","ffdc9fd6":"markdown","535aff71":"markdown","ebdd79dc":"markdown","2dc18189":"markdown","72ac76cb":"markdown","8dc8bef7":"markdown","530946c9":"markdown","2b7b6098":"markdown","c3f29c1f":"markdown","22f49cdc":"markdown","f40993a0":"markdown","d82f71a2":"markdown","fc9485c9":"markdown","3261d182":"markdown","adcb9660":"markdown","ed361fc4":"markdown","ecf4aa4e":"markdown","8eb867bb":"markdown","3dfd0ee8":"markdown"},"source":{"3a51ad01":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport tensorflow\nfrom tensorflow import keras\n\nfrom sklearn.metrics import accuracy_score,f1_score,confusion_matrix","77b4d964":"train=pd.read_csv('..\/input\/tool-wear-detection-in-cnc-mill\/train.csv')","dbf9836b":"train.shape","05628dcb":"train.columns","b5be8b5c":"train.info()","a6d87142":"train.head()","5f402dc4":"plt.style.use('seaborn-darkgrid')","95474e86":"fig, ((ax0,ax1,ax2),(ax3,ax4,ax5))=plt.subplots(nrows=2,\n                                       ncols=3,\n                                       figsize=(30, 20))\ndef label_function(val):\n    return f'{val \/ 100 * len(train):.0f}\\n{val:.0f}%'\n\n# feedrate\ntrain.groupby('material').size().plot(kind='pie',\n                                      autopct=label_function, \n                                      textprops={'fontsize': 15},\n                                      ax=ax0)                                         \nax0.set_xlabel('material',size=15)\n\n# Tool Condition\ntrain.groupby('tool_condition').size().plot(kind='pie', \n                                              autopct=label_function,\n                                              textprops={'fontsize': 15},\n                                              ax=ax1)\nax1.set_xlabel('Tool Condition',size=15)\n\n# Pressure\ntrain.groupby('clamp_pressure').size().plot(kind='pie', \n                                      autopct=label_function, \n                                      textprops={'fontsize': 15},\n                                      colors=['violet', 'lime','tomato'],\n                                      ax=ax2)\nax2.set_xlabel('Clamp Pressure',size=15)\n\n# Machining Finalized\ntrain.groupby('machining_finalized').size().plot(kind='pie',\n                                                 autopct=label_function, \n                                                 textprops={'fontsize': 15},\n                                                 colors=['tomato', 'gold','violet','lime'],\n                                                 ax=ax3)\nax3.set_xlabel('Machining_finalized',size=15)\n\n# passed_visual_inspection\ntrain.groupby('passed_visual_inspection').size().plot(kind='pie',\n                                                 autopct=label_function, \n                                                 textprops={'fontsize': 15},\n                                                 ax=ax4)                                         \nax4.set_xlabel('passed_visual_inspection',size=15)\n\n# feedrate\ntrain.groupby('feedrate').size().plot(kind='pie',\n                                      autopct=label_function, \n                                      textprops={'fontsize': 15},\n                                      ax=ax5)                                         \nax5.set_xlabel('feedrate',size=15)\n\n# showing the figure\nfig.show()","6f42379a":"frames=list()\nfor i in range(1,19):\n    exp = '0' + str(i) if i < 10 else str(i)\n    frame = pd.read_csv(\"..\/input\/tool-wear-detection-in-cnc-mill\/experiment_{}.csv\".format(exp))\n    row = train[train['No'] == i]\n    frame['target'] = 1 if row.iloc[0]['tool_condition'] == 'worn' else 0\n    frames.append(frame)\ndf = pd.concat(frames, ignore_index = True)","9ca6b57f":"df.head()","5f238531":"df.info()","e611697d":"# when training model,cant use string values so that is why i am creating dummy variables\ndef dummy_creation(dataset,dummy_categories):\n  for i in dummy_categories:\n    dataset_dummy=pd.get_dummies(dataset[i])\n    dataset=pd.concat([dataset,dataset_dummy],\n                      axis=1)\n    dataset=dataset.drop(i,axis=1)\n  return dataset","bf36d5fa":"df['Machining_Process'].unique()","82bd94c7":"df=dummy_creation(df, ['Machining_Process'])","b3d5d5cb":"df.info()","5a49641b":"# Seperating features and labels\nfeatures=df.drop('target',axis=\"columns\")\nlabels=df['target']\n\nfrom sklearn.model_selection import train_test_split\nx_Train, x_Test, y_Train, y_Test=train_test_split(features,labels,test_size=0.2)","e2124549":"np.random.seed(42)","dcfda4f7":"from sklearn.ensemble import RandomForestClassifier\nrandom_forest=RandomForestClassifier()\nrandom_forest.get_params()","b9aa4127":"random_forest.fit(x_Train,y_Train)","6797de00":"random_forest_acc=random_forest.score(x_Test,y_Test)","3d64e227":"y_pred=random_forest.predict(x_Test)\naccuracy_score(y_true=y_Test,\n               y_pred=y_pred)","b420fa73":"confusion_matrix(y_true=y_Test,y_pred=y_pred)","04628ed8":"for n_estimator in range(10,100,10):\n  clf=RandomForestClassifier(n_estimators=n_estimator)\n  clf.fit(x_Train,y_Train)\n  y_pred=clf.predict(x_Test)\n  if (accuracy_score(y_Test,y_pred) > random_forest_acc):\n    print(f\"{n_estimator} is the n_estimator\")\n    print(f\"Model Accuracy:{accuracy_score(y_Test,y_pred)}\")\n    print(\"------------------------------------\")  ","e131f386":"random_forest=RandomForestClassifier(n_estimators=30)\nrandom_forest.fit(x_Train,y_Train)\ny_pred=random_forest.predict(x_Test)\nnew_random_forest_acc=accuracy_score(y_true=y_Test,y_pred=y_pred)\nprint(new_random_forest_acc-random_forest_acc)","6af9ab34":"from sklearn.tree import DecisionTreeClassifier\ndecision_trees=DecisionTreeClassifier()\ndecision_trees.get_params()","6e6dbc9a":"decision_trees.fit(x_Train,y_Train)","8ead31eb":"decision_trees.score(x_Test,y_Test)","9b5f57c4":"import xgboost as xgb\nfrom xgboost import XGBClassifier\nxgboost_clf=XGBClassifier()","9859beee":"xgboost_clf.fit(x_Train,y_Train)","d04ed1c4":"xgboost_clf.score(x_Test,y_Test)","9e8b7a34":"### 6.1.3 Evaluate the model\n* Way 1 : Accuracy Score","39c29ced":"### 6.2.2 Train the Model","1798f9a9":"### 6.3.2 Train the model","017d2d8f":"# 6.Train & Evaluate Model\n","0bf734fd":"* Way 2 : Accuracy Score","36a69616":"## 6.1 Random Forest","ffdc9fd6":"### 6.1.4 Improve the Model\n* In this part, we are trying to find best accuracy using different n_estimator values","535aff71":"# 1.Import Libraries","ebdd79dc":"### 6.1.2 Train the model","2dc18189":"* Confusion Matrix","72ac76cb":"## 6.2 Decision Trees","8dc8bef7":"### 6.2.1 Create the Model","530946c9":"## 5.4 Split data as features&label , train&test dataset","2b7b6098":"## 5.3 Creating dummy variables","c3f29c1f":"# 2.Load Dataset","22f49cdc":"### 6.3.3 Evaluate the Model","f40993a0":"# 5.Preprocess Data","d82f71a2":"### 6.2.3 Evaluate the model","fc9485c9":"## 5.2 Join Experiments","3261d182":"## 5.1 Visualize Data Before Join Experiments","adcb9660":"### 6.1.1 Create the Model","ed361fc4":"### 6.3.1 Create the model","ecf4aa4e":"*  model with 30 n_estimators gave better results than model with 100 n_estimators so we can fit our model using 30 n_estimators","8eb867bb":"# 3.Analyze Data","3dfd0ee8":"## 6.3 Xgboost"}}