{"cell_type":{"ccedb528":"code","0406cf09":"code","a8eda774":"code","1b4f7903":"code","a490d4e1":"code","58732e15":"code","89813a12":"code","6b8cc0a8":"code","4bbe9c1e":"code","4d670740":"code","7381c4fd":"markdown","73f8eb44":"markdown","b18e1834":"markdown","75ea1004":"markdown","7be9c407":"markdown","36f41108":"markdown","184cb7f5":"markdown","6a001b54":"markdown","1e64c732":"markdown","f0040443":"markdown","8dccb4b2":"markdown","f8e52ce6":"markdown","65515de6":"markdown"},"source":{"ccedb528":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport shutil\nimport tensorflow as tf\nimport pathlib\nimport PIL\nimport time\nimport zipfile\nimport random\nfrom tensorflow.keras.layers import *","0406cf09":"MAIN_PATH = \"..\/input\/traffic-sign-cropped\/crop_dataset\/crop_dataset\"\nTEST_PATH = \"..\/input\/traffic-sign-cropped\/test_data\"\nCLASSES = os.listdir(MAIN_PATH)\nNUM_CLASSES = len(CLASSES)\nNUM_TEST_IMAGES = len(os.listdir(os.path.join(TEST_PATH,\"test_data\")))\nHEIGHT,WIDTH = 32,32\nBATCH_SIZE = 32\nSPLIT = 0.2","a8eda774":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=20,\n    horizontal_flip=True,\n    validation_split=SPLIT)\n'''\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    '''\ntrain_ds = train_datagen.flow_from_directory(\n    MAIN_PATH,\n    target_size = (HEIGHT,WIDTH),\n    batch_size = BATCH_SIZE,\n    subset = \"training\",\n    class_mode = \"categorical\",\n    shuffle = True\n)\n\nval_ds = train_datagen.flow_from_directory(\n    MAIN_PATH,\n    target_size = (HEIGHT,WIDTH),\n    batch_size = BATCH_SIZE,\n    subset = \"validation\",\n    class_mode = \"categorical\",\n    shuffle = True\n)\n\ntest_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255)\ntest_ds = test_datagen.flow_from_directory(\n    TEST_PATH,\n    target_size = (HEIGHT,WIDTH),\n    shuffle = False\n)","1b4f7903":"def create_model():\n    vgg16 = tf.keras.applications.VGG16(include_top=False, weights='imagenet',input_shape=[HEIGHT,WIDTH, 3])\n            \n    x = vgg16.output\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dropout(0.3) (x)\n    x = tf.keras.layers.Dense(128) (x)\n    x = tf.keras.layers.LeakyReLU(alpha=0.2) (x)\n    x = tf.keras.layers.GaussianDropout(0.4) (x)\n    outputs = tf.keras.layers.Dense(NUM_CLASSES,activation=\"softmax\", dtype='float32')(x)\n        \n    model = tf.keras.Model(vgg16.input, outputs)\n    return model\n\nmodel = create_model()\nmodel.summary()","a490d4e1":"def compile_model(model, lr=0.0001):\n    \n    optimizer = tf.keras.optimizers.Adam(lr=lr)\n    \n    loss = tf.keras.losses.CategoricalCrossentropy()\n        \n    metrics = [\n       tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy')\n    ]\n\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n    return model","58732e15":"def create_callbacks():\n    \n    cpk_path = '.\/best_model.h5'\n    \n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath=cpk_path,\n        monitor='val_categorical_accuracy',\n        mode='max',\n        save_best_only=True,\n        verbose=1,\n    )\n\n    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_categorical_accuracy',\n        mode='max',\n        factor=0.1,\n        patience=3,\n        verbose=0\n    )\n\n    earlystop = tf.keras.callbacks.EarlyStopping(\n        monitor='val_categorical_accuracy',\n        mode='max',\n        patience=10, \n        verbose=1\n    )\n    \n    callbacks = [checkpoint, reducelr, earlystop]         \n    \n    return callbacks","89813a12":"EPOCHS= 60\nVERBOSE =1\n\ntf.keras.backend.clear_session()\n\nwith tf.device('\/device:GPU:0'):\n    \n    model = create_model()\n    model = compile_model(model, lr=0.0001)\n   \n    callbacks = create_callbacks()\n    \n    history = model.fit(train_ds, \n                        epochs=EPOCHS,\n                        callbacks=callbacks,\n                        validation_data = val_ds,\n                        verbose=VERBOSE)","6b8cc0a8":"acc = history.history['categorical_accuracy']\nval_acc = history.history['val_categorical_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(len(history.history['val_loss']))\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Categorical Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Categorical Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Categorical Accuracy')\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","4bbe9c1e":"label_df = pd.read_csv(\"..\/input\/traffic-sign-cropped\/test_labels.csv\")\nlabels = np.array(label_df.label)\n\nmodel = tf.keras.models.load_model(\".\/best_model.h5\")\n\npred_arr = model.predict(test_ds)\n\npredictions = np.zeros((NUM_TEST_IMAGES,))\nfor i,pred in enumerate(pred_arr):\n    predictions[i] = np.argmax(pred)\n    \nconfusion_matrix = tf.math.confusion_matrix(labels,predictions,num_classes=NUM_CLASSES)\n\ncount = 0\nfor i in range(NUM_TEST_IMAGES):\n    if predictions[i]== labels[i]:\n        count+=1\n        \ntest_acc = count\/NUM_TEST_IMAGES\nprint(\"Test Accuracy: \",test_acc)","4d670740":"import seaborn as sns\n\nsns.set(rc={'figure.figsize':(13,10)})\n\nsns.heatmap(confusion_matrix,cmap='Blues')  ","7381c4fd":"# TESTING","73f8eb44":"# METRICS VISUALIZATION","b18e1834":"# Introduction","75ea1004":"* **This is notebook for absolute beginner who is learning TensorFlow framework.**\n* First go through the Traffic Sign Dataset which I used for this notebook. I will be highly obliged if you upvote the dataset also\ud83d\ude0a.\n* Basically this is a Multi class classification using Transfer Learning in Tensorflow.","7be9c407":"### Go through the [Tensorflow preprocessing](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/preprocessing\/image\/ImageDataGenerator) image data documentation for more details","36f41108":"## Function for compiling the model","184cb7f5":"### I am using transfer learning for this task. Based on the number of elements of 'ls', I will be varying the number of pretrained model I am using. If I use more than one pretrained model, I will take average of all the outputs.","6a001b54":"## Function for callbacks","1e64c732":"# Preprocessing Data","f0040443":"## Training","8dccb4b2":"### Hope you learnt something useful from this notebook. Feel free to contact me in case of doubts or any suggestions. \n## Happy coding\u2764","f8e52ce6":"# Loading Data","65515de6":"# Creating model"}}