{"cell_type":{"b9a40195":"code","64efb624":"code","b3020c9c":"code","1083ab4b":"code","bfa2d86e":"code","56e8f077":"code","f8a2faa8":"code","1fc3d57e":"code","883d3ae9":"code","80b25366":"code","cc492f54":"code","85e98d08":"code","7396abac":"code","c0fcda5d":"code","a27ba24b":"code","382ae4d6":"code","ad9a1aa5":"code","b899075c":"code","c63ae16d":"code","12a5a139":"code","ce94117d":"code","e370f84f":"code","651aaf34":"code","ecf91ff3":"code","c5b28351":"code","392a2d5a":"code","f51ed268":"markdown","e9ba8af8":"markdown","f6181de6":"markdown","8b35fa4c":"markdown","502678b8":"markdown","c88274b2":"markdown","2eea75c5":"markdown","8ce51350":"markdown","94992f0a":"markdown","1920206f":"markdown","b94cb187":"markdown"},"source":{"b9a40195":"import os\nimport re\n\nimport numpy as np\nimport tensorflow as tf\n\nnp.random.seed(1)\ntf.random.set_seed(2)\n\nimport pandas as pd\nimport keras\n\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import f1_score, classification_report, log_loss\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import to_categorical\n\nprint(os.listdir('..\/input'))","64efb624":"import warnings\nwarnings.filterwarnings('ignore')","b3020c9c":"MAX_SEQ_LEN = 25\nDEFAULT_BATCH_SIZE = 128","1083ab4b":"data = pd.read_csv('..\/input\/cyberbullying-classification\/cyberbullying_tweets.csv')\ntrain, test = train_test_split(data, random_state = 42, test_size=0.1)\nprint(train.shape)\nprint(test.shape)","bfa2d86e":"data.head()","56e8f077":"CONTRACTION_MAPPING = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\",\n                       \"It's\": 'It is', \"Can't\": 'Can not',\n                      }","f8a2faa8":"def clean_text(text, mapping):\n    replace_white_space = [\"\\n\"]\n    for s in replace_white_space:\n        text = text.replace(s, \" \")\n    replace_punctuation = [\"\u2019\", \"\u2018\", \"\u00b4\", \"`\", \"\\'\", r\"\\'\"]\n    for s in replace_punctuation:\n        text = text.replace(s, \"'\")\n    \n    mapped_string = []\n    for t in text.split(\" \"):\n        if t in mapping:\n            mapped_string.append(mapping[t])\n        elif t.lower() in mapping:\n            mapped_string.append(mapping[t.lower()])\n        else:\n            mapped_string.append(t)\n    return ' '.join(mapped_string)","1fc3d57e":"train_text_vec = [clean_text(text, CONTRACTION_MAPPING) for text in train['tweet_text'].values]\ntest_text_vec = [clean_text(text, CONTRACTION_MAPPING) for text in test['tweet_text'].values]\n\ntokenizer = Tokenizer(lower=False)\ntokenizer.fit_on_texts(train_text_vec)\ntrain_text_vec = tokenizer.texts_to_sequences(train_text_vec)\ntest_text_vec = tokenizer.texts_to_sequences(test_text_vec)\n\ntrain_text_vec = pad_sequences(train_text_vec, maxlen=MAX_SEQ_LEN)\ntest_text_vec = pad_sequences(test_text_vec, maxlen=MAX_SEQ_LEN)\n\nprint('Number of Tokens:', len(tokenizer.word_index))\nprint(\"Max Token Index:\", train_text_vec.max(), \"\\n\")\n\nprint('Sample Tweet Before Processing:', train[\"tweet_text\"].values[0])\nprint('Sample Tweet After Processing:', tokenizer.sequences_to_texts([train_text_vec[0]]), '\\n')\n\nprint('What the model will interpret:', train_text_vec[0].tolist())","883d3ae9":"encoder = LabelEncoder()\n\ny_train = encoder.fit_transform(train['cyberbullying_type'].values)\ny_train = to_categorical(y_train) \n\ny_test = encoder.fit_transform(test['cyberbullying_type'].values)\ny_test = to_categorical(y_test) ","80b25366":"from collections import Counter\nctr = Counter(train['cyberbullying_type'].values)\nprint('Distribution of Classes:', ctr)\n\ny_train_int = np.argmax(y_train,axis=1)\ncws = class_weight.compute_class_weight('balanced', np.unique(y_train_int), y_train_int)\nprint(cws)","cc492f54":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils.multiclass import unique_labels\n\nnp.set_printoptions(precision=4)\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n\n    # Compute confusion matrix\n    classes = classes[unique_labels(y_true, y_pred)]\n    _cm = confusion_matrix(y_true, y_pred)\n\n    print(classification_report(y_true, y_pred, target_names=classes))\n        \n    def _build_matrix(fig, ax, cm, normalize = False):\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n        \n        if normalize:\n            cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n        im = ax.imshow(cm, cmap=cmap)\n        \n        ax.set(xticks=np.arange(cm.shape[1]),\n               yticks=np.arange(cm.shape[0]),\n               # ... and label them with the respective list entries\n               xticklabels=classes, \n               yticklabels=classes,\n               title=title,\n               ylabel='True label',\n               xlabel='Predicted label')\n\n        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n\n        fmt = '.2f' if normalize else 'd'\n        thresh = cm.max() \/ 2.\n        for i in range(cm.shape[0]):\n            for j in range(cm.shape[1]):\n                ax.text(j, i, format(cm[i, j], fmt),\n                        ha=\"center\", va=\"center\",\n                        color=\"white\" if cm[i, j] > thresh else \"black\")\n        \n    fig, [ax1, ax2] = plt.subplots(nrows = 1, ncols = 2, figsize=(10, 5))\n    _build_matrix(fig, ax1, cm = _cm, normalize=False)\n    _build_matrix(fig, ax2, cm = _cm, normalize=True)\n    fig.tight_layout()","85e98d08":"# \nprint('Dominant Class: ', ctr.most_common(n = 1)[0][0])\nprint('Baseline Accuracy Dominant Class', (ctr.most_common(n = 1)[0][0] == test['cyberbullying_type'].values).mean())\n\npreds = np.zeros_like(y_test)\npreds[:, 0] = 1\npreds[0] = 1\nprint('F1 Score:', f1_score(y_test, preds, average='weighted'))","7396abac":"# Naive Bayse Baseline\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\n\ntext_clf = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf', MultinomialNB()),\n])\ntext_clf.fit(tokenizer.sequences_to_texts_generator(train_text_vec), y_train.argmax(axis=1))\npredictions = text_clf.predict(tokenizer.sequences_to_texts_generator(test_text_vec)) \nprint('Baseline Accuracy Using Naive Bayes: ', (predictions == y_test.argmax(axis = 1)).mean())\nprint('F1 Score:', f1_score(y_test.argmax(axis = 1), predictions, average='weighted'))\n\n_ = plot_confusion_matrix(y_test.argmax(axis = 1), predictions, classes=encoder.classes_, title='Confusion matrix, without normalization')","c0fcda5d":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import Pipeline\n\ntext_clf = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf', RandomForestClassifier(class_weight='balanced', n_estimators=100)),\n])\ntext_clf.fit(tokenizer.sequences_to_texts_generator(train_text_vec), y_train.argmax(axis=1))\npredictions = text_clf.predict(tokenizer.sequences_to_texts_generator(test_text_vec)) \nprint('Baseline Accuracy Using RFC: ', (predictions == y_test.argmax(axis = 1)).mean())\nprint('F1 Score:', f1_score(y_test.argmax(axis = 1), predictions, average='weighted'))\n\n_ = plot_confusion_matrix(y_test.argmax(axis = 1), predictions, classes=encoder.classes_)","a27ba24b":"def bullying_judge(ex):\n    if ex == 'not_cyberbullying':\n        return 'not_cyberbullying'\n    else:\n        return 'cyberbullying'","382ae4d6":"data2=data.copy()","ad9a1aa5":"data2.loc[:,'cyberbullying_type']=data2.loc[:,'cyberbullying_type'].apply(bullying_judge)\ndata2","b899075c":"train2, test2 = train_test_split(data2, random_state = 42, test_size=0.1)\nprint(train2.shape)\nprint(test2.shape)","c63ae16d":"CONTRACTION_MAPPING = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\",\n                       \"It's\": 'It is', \"Can't\": 'Can not',\n                      }","12a5a139":"train_text_vec2 = [clean_text(text, CONTRACTION_MAPPING) for text in train2['tweet_text'].values]\ntest_text_vec2 = [clean_text(text, CONTRACTION_MAPPING) for text in test2['tweet_text'].values]\n\ntokenizer = Tokenizer(lower=False)\ntokenizer.fit_on_texts(train_text_vec2)\ntrain_text_vec2 = tokenizer.texts_to_sequences(train_text_vec2)\ntest_text_vec2 = tokenizer.texts_to_sequences(test_text_vec2)\n\ntrain_text_vec2 = pad_sequences(train_text_vec2, maxlen=MAX_SEQ_LEN)\ntest_text_vec2 = pad_sequences(test_text_vec2, maxlen=MAX_SEQ_LEN)\n\nprint('Number of Tokens:', len(tokenizer.word_index))\nprint(\"Max Token Index:\", train_text_vec2.max(), \"\\n\")\n\nprint('Sample Tweet Before Processing:', train2[\"tweet_text\"].values[0])\nprint('Sample Tweet After Processing:', tokenizer.sequences_to_texts([train_text_vec2[0]]), '\\n')\n\nprint('What the model will interpret:', train_text_vec2[0].tolist())","ce94117d":"encoder = LabelEncoder()\n\ny_train2 = encoder.fit_transform(train2['cyberbullying_type'].values)\ny_train2 = to_categorical(y_train2) \n\ny_test2 = encoder.fit_transform(test2['cyberbullying_type'].values)\ny_test2 = to_categorical(y_test2) ","e370f84f":"from collections import Counter\nctr2 = Counter(train2['cyberbullying_type'].values)\nprint('Distribution of Classes:', ctr2)\n\ny_train_int2 = np.argmax(y_train2,axis=1)\ncws2 = class_weight.compute_class_weight('balanced', np.unique(y_train_int2), y_train_int2)\nprint(cws2)","651aaf34":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils.multiclass import unique_labels\n\nnp.set_printoptions(precision=4)\ndef plot_confusion_matrix(y_true2, y_pred2, classes,\n                          normalize=False,\n                          title=None,\n                          cmap=plt.cm.Reds):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n\n    classes = classes[unique_labels(y_true2, y_pred2)]\n    _cm = confusion_matrix(y_true2, y_pred2)\n\n    print(classification_report(y_true2, y_pred2, target_names=classes))\n        \n    def _build_matrix(fig, ax, cm, normalize = False):\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n        \n        if normalize:\n            cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n        im = ax.imshow(cm, cmap=cmap)\n        \n        ax.set(xticks=np.arange(cm.shape[1]),\n               yticks=np.arange(cm.shape[0]),\n               xticklabels=classes, \n               yticklabels=classes,\n               title=title,\n               ylabel='True label',\n               xlabel='Predicted label')\n\n        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n\n        fmt = '.2f' if normalize else 'd'\n        thresh = cm.max() \/ 2.\n        for i in range(cm.shape[0]):\n            for j in range(cm.shape[1]):\n                ax.text(j, i, format(cm[i, j], fmt),\n                        ha=\"center\", va=\"center\",\n                        color=\"white\" if cm[i, j] > thresh else \"black\")\n        \n    fig, [ax1, ax2] = plt.subplots(nrows = 1, ncols = 2, figsize=(10, 5))\n    _build_matrix(fig, ax1, cm = _cm, normalize=False)\n    _build_matrix(fig, ax2, cm = _cm, normalize=True)\n    fig.tight_layout()","ecf91ff3":"print('Dominant Class: ', ctr2.most_common(n = 1)[0][0])\nprint('Baseline Accuracy Dominant Class', (ctr2.most_common(n = 1)[0][0] == test2['cyberbullying_type'].values).mean())\n\npreds = np.zeros_like(y_test2)\npreds[:, 0] = 1\npreds[0] = 1\nprint('F1 Score:', f1_score(y_test2, preds, average='weighted'))","c5b28351":"text_clf = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf', MultinomialNB()),\n])\ntext_clf.fit(tokenizer.sequences_to_texts_generator(train_text_vec2), y_train2.argmax(axis=1))\npredictions = text_clf.predict(tokenizer.sequences_to_texts_generator(test_text_vec2)) \nprint('Baseline Accuracy Using Naive Bayes: ', (predictions == y_test2.argmax(axis = 1)).mean())\nprint('F1 Score:', f1_score(y_test2.argmax(axis = 1), predictions, average='weighted'))\n\n_ = plot_confusion_matrix(y_test2.argmax(axis = 1), predictions, classes=encoder.classes_, title='Confusion matrix, without normalization')","392a2d5a":"text_clf = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('clf', RandomForestClassifier(class_weight='balanced', n_estimators=100)),\n])\ntext_clf.fit(tokenizer.sequences_to_texts_generator(train_text_vec2), y_train2.argmax(axis=1))\npredictions = text_clf.predict(tokenizer.sequences_to_texts_generator(test_text_vec2)) \nprint('Baseline Accuracy Using RFC: ', (predictions == y_test2.argmax(axis = 1)).mean())\nprint('F1 Score:', f1_score(y_test2.argmax(axis = 1), predictions, average='weighted'))\n\n_ = plot_confusion_matrix(y_test2.argmax(axis = 1), predictions, classes=encoder.classes_)","f51ed268":"I refered to 'https:\/\/www.kaggle.com\/mkowoods\/deep-learning-lstm-for-tweet-classification' for modeling. Thank you very much for sharing 'https:\/\/www.kaggle.com\/mkowoods\/deep-learning-lstm-for-tweet-classification'\n\nIn this note book, I tried to identify 'cyberbullying tweet' and 'not cyberbullying tweet' by 'multi class classification' and 'binary calssification' with 'Naive Bayse Model' and 'RandomForestClassifier Model'.","e9ba8af8":"1)Data Preprocessing","f6181de6":"2)Naive Bayse Model","8b35fa4c":"2.Binary Classification Model","502678b8":"1)Data Preprocessing","c88274b2":"3)RandomForestClassifier Model","2eea75c5":"1.Multi Class Classification","8ce51350":"The important thing is that how we can identify 'Cyberbullying tweet' with high accuracy.\nIt seems that it is easy to find 'Cyberbullying', but it may be difficult to identify 'Not cyberbullying tweet' as they are with high accuracy....","94992f0a":"3)RandomForestClassifier Model","1920206f":"2)Naive Bayse Model","b94cb187":"![image.png](attachment:b957883f-a970-4cb3-befa-2f043d3fbb31.png)\n\nimage from https:\/\/aaci.org\/healthy-living-blog-preventing-cyberbullying-while-learning-online\/"}}