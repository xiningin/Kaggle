{"cell_type":{"bf55dd5f":"code","3be60a4e":"code","71390869":"code","b907bfb6":"code","948c9828":"code","3e84f42c":"code","ff2c9e9e":"code","33573fad":"code","1ea1e4ff":"code","a71fadd9":"code","9f0d0338":"code","a81019eb":"code","e7092e74":"code","6eb5ff30":"code","77a9e467":"code","e4480838":"code","9d0135be":"code","4f3c9952":"code","07db581f":"code","8050ea33":"code","25d06f8c":"code","7b1e1d76":"code","ef92fc38":"code","fb4fa165":"code","31547cc7":"code","805e6315":"code","c0f6b820":"code","7aee35c5":"code","3668dc2a":"code","0c4edab7":"code","ab1a7faa":"code","308d10ca":"code","4661d6a0":"code","2014a035":"code","d241a697":"code","e304d0d3":"code","dda87e35":"code","6502d83f":"code","92fe246e":"code","9d559023":"code","ba2b9cf9":"code","4caff99b":"code","d7cd6d4b":"code","b8be8a4e":"code","7690d16e":"code","0d8084c2":"code","678470bc":"code","3aa711bd":"code","59ffafe0":"code","e88a3fc2":"code","b05d0520":"code","c9127c8a":"code","ad76cc38":"code","2ad71ea3":"code","98b8de4a":"code","10be81e7":"code","37525ef1":"code","caeba364":"code","b872fda6":"code","d1792b67":"code","62375b49":"code","7b9ab03b":"code","e728e092":"code","e5c7b318":"code","2a794521":"code","6f3125bc":"code","1ec075f2":"code","a0496634":"code","82940bb5":"code","0b4e66b5":"code","ac74020a":"code","6448acf5":"code","744647ea":"code","c6cecccc":"code","2ed00e3c":"code","db517791":"code","2c36d262":"code","8cacb150":"code","ed24c806":"code","675cf08c":"code","6be1b1a8":"code","e436bd81":"code","1cb9140b":"code","e269a500":"code","b5134096":"code","5c1cfc2e":"code","8799f288":"code","95548253":"code","90643f7c":"code","2c690b2b":"code","bdd9de65":"code","8c493c46":"code","35fd58b7":"code","89ea677f":"code","e07bbf68":"code","0c108435":"code","1ae7b4bc":"code","7a0f22be":"code","9afb16c0":"code","6f020672":"code","86acdcd5":"code","ebd59bff":"markdown","c3b8cef6":"markdown"},"source":{"bf55dd5f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3be60a4e":"import matplotlib.pyplot as plt\n%matplotlib inline\nfrom itertools import product\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\nimport plotly.express as px\nimport time","71390869":"# !pip install googletrans\n# from googletrans import Translator\n# translator= Translator()\n# translations = {}\n# # unique elements of the column\n# unique_elements = df_items['item_name'].unique()\n# for element in unique_elements:\n#     # add translation to the dictionary\n#     translations[element] = translator.translate(element).text\n# df_items['item_name'].replace(result_translation, inplace = True)","b907bfb6":"df_train = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv')\ndf_shops = pd.read_csv('\/kaggle\/input\/predict\/shops_en.csv')\ndf_items = pd.read_csv('\/kaggle\/input\/predict\/items_en.csv')\ndf_catog = pd.read_csv('\/kaggle\/input\/predict\/item_categories_en.csv')\ndf_submission = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv')","948c9828":"# Find specific column lag with respect to date\ndef feature_lag(dataframe, lags, column):\n    temp = dataframe[['date_block_num','shop_id','item_id',column]]\n    for i in lags:\n        shifted = temp.copy()\n        shifted.columns = ['date_block_num','shop_id','item_id', column+'_lag_'+str(i)]\n        shifted['date_block_num'] += i\n        dataframe = pd.merge(dataframe, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n    return dataframe","3e84f42c":"# Show first 5 columns of \"df_train\" Dataframe\ndf_train.head()","ff2c9e9e":"# Show description of \"df_train\" Dataframe\ndf_train.describe().T","33573fad":"# Show unique values of each column of \"df_train\" Dataframe\ndf_train.nunique()","1ea1e4ff":"# Show first 5 columns of \"df_test\" Dataframe\ndf_test.head()","a71fadd9":"# Show unique values of each column of \"df_test\" Dataframe\ndf_test.nunique()","9f0d0338":"# Show first 5 columns of \"df_shops\" Dataframe\ndf_shops.head()","a81019eb":"# Show unique values of each column of \"df_shops\" Dataframe\ndf_shops.nunique()","e7092e74":"# Show first 5 columns of \"df_items\" Dataframe\ndf_items.head()","6eb5ff30":"# Show unique values of each column of \"df_items\" Dataframe\ndf_items.nunique()","77a9e467":"# Show first 5 columns of \"df_catog\" Dataframe\ndf_catog.head()","e4480838":"# Show unique values of each column of \"df_catog\" Dataframe\ndf_catog.nunique()","9d0135be":"# Show first 60 columns of \"df_shops\" Dataframe\ndf_shops.head(60)","4f3c9952":"# Removing Duplicates\n# 1) ! Yakutsk Ordzhonikidze, 56 Franc ---> Yakutsk Ordzhonikidze, 56\ndf_train.loc[df_train.shop_id == 0, \"shop_id\"] = 57\ndf_test.loc[df_test.shop_id == 0 , \"shop_id\"] = 57\n# 2) ! Yakutsk TC \"Central\" Franc  ---> Yakutsk TC \"Central\"\ndf_train.loc[df_train.shop_id == 1, \"shop_id\"] = 58\ndf_test.loc[df_test.shop_id == 1 , \"shop_id\"] = 58\n# 3) Zhukovsky Street. Chkalov 39m\u00b2  ---> Zhukovsky Street. Chkalov 39m?\ndf_train.loc[df_train.shop_id == 11, \"shop_id\"] = 10\ndf_test.loc[df_test.shop_id == 11, \"shop_id\"] = 10\n# 4) RostovNaDonu TRC \"Megacenter Horizon\" Island ---> RostovNaDonu TRC \"Megacenter Horizon\"\ndf_train.loc[df_train.shop_id == 40, \"shop_id\"] = 39\ndf_test.loc[df_test.shop_id == 40, \"shop_id\"] = 39","07db581f":"# Box plot of item_price Column in \"df_train\" Dataframe to check the outliers \ndf_train['item_price'].plot(kind=\"box\")","8050ea33":"# Box plot of item_cnt_day Column in \"df_train\" Dataframe to check the outliers\ndf_train['item_cnt_day'].plot(kind=\"box\")","25d06f8c":"# Removing Outliers from \"df_train\" Dataframe\ndf_train = df_train[df_train['item_price']<100000]\ndf_train = df_train[df_train['item_cnt_day']<1001]","7b1e1d76":"# Checking Negative values item_price column in \"df_train\" Dataframe\ndf_train_price_negative = df_train[df_train['item_price']<=0]","ef92fc38":"df_train_price_negative","fb4fa165":"# Removing Negative values item_price column in \"df_train\" Dataframe\ndf_train = df_train[df_train['item_price'] > 0].reset_index(drop = True)","31547cc7":"# Checking Negative values item_cnt_day column in \"df_train\" Dataframe\ndf_train_cnt_negative = df_train[df_train['item_cnt_day']<0]\ndf_train_cnt_negative.count()","805e6315":"# Changing negative values of item_cnt_day in \"df_train\" with zero\ndf_train.loc[df_train['item_cnt_day'] < 1, \"item_cnt_day\"] = 0","c0f6b820":"# Converting day by day data into per month data \ntemp = []\ncols = ['date_block_num','shop_id','item_id']\nfor i in df_train['date_block_num'].unique():\n    sales = df_train[df_train['date_block_num'] == i]\n    temp.append(np.array(list(product([i], sales['shop_id'].unique(), sales['item_id'].unique()))))\n    \nupdated_df_train = pd.DataFrame(np.vstack(temp), columns=cols)","7aee35c5":"# length of new dataframe\nlen(updated_df_train)","3668dc2a":"# Addind new column revenue in \"updated_df_train\" Dataframe\ndf_train['revenue'] = df_train['item_price'] *  df_train['item_cnt_day']","0c4edab7":"# Show first 5 columns of \"df_train\" Dataframe\ndf_train.head()","ab1a7faa":"# Group by 'date_block_num','shop_id','item_id' and count item_cnt_month\ngroupby_date_shop_item = df_train.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': ['sum']})\ngroupby_date_shop_item.columns = ['item_cnt_month']\ngroupby_date_shop_item.reset_index(inplace=True)\nupdated_df_train = pd.merge(updated_df_train, groupby_date_shop_item, on=cols, how='left').fillna(0)","308d10ca":"# Show first 5 columns of \"updated_df_train\" Dataframe\nupdated_df_train.head()","4661d6a0":"# Training Dataframe have 33 months so next is 34Th month and test dataframe have only one month data \ndf_test['date_block_num'] = 34","2014a035":"# merging df_test into updated_df_train \ntest_shop_ids = df_test['shop_id'].unique()\ntest_item_ids = df_test['item_id'].unique()\nupdated_df_train = updated_df_train[updated_df_train['shop_id'].isin(test_shop_ids)]\nupdated_df_train = updated_df_train[updated_df_train['item_id'].isin(test_item_ids)]\nupdated_df_train.reset_index(inplace=True, drop=True)","d241a697":"updated_df_train = pd.concat([updated_df_train, df_test], ignore_index=True, sort=False, keys=['date_block_num','shop_id','item_id'])\nupdated_df_train.fillna(0, inplace=True)","e304d0d3":"# merging df_shops, df_items, df_catog into updated_df_train \nupdated_df_train = pd.merge(updated_df_train, df_shops, on=['shop_id'], how='left')\nupdated_df_train = pd.merge(updated_df_train, df_items, on=['item_id'], how='left')\nupdated_df_train = pd.merge(updated_df_train, df_catog, on=['item_category_id'], how='left')","dda87e35":"# Show first 5 columns of \"updated_df_train\" Dataframe\nupdated_df_train.head()","6502d83f":"# show unique item_catogories name in \"Updated_df_train\" dataframe\nupdated_df_train['item_category_name'].unique()","92fe246e":"# splitting item_category_name column into category_type and category_subtype\nupdated_df_train['split'] = updated_df_train['item_category_name'].str.split('-')\nupdated_df_train['category_type'] = updated_df_train['split'].map(lambda x: x[0].strip())\nupdated_df_train['category_subtype'] = updated_df_train['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\nupdated_df_train.drop(columns=['item_category_name' , 'split'] , inplace=True , axis=1)","9d559023":"# correcting category_subtype name and category_type column values\nupdated_df_train['category_subtype'].replace('Blu','BluRay' , inplace=True)\nupdated_df_train['category_type'].replace('Movies','Movie' , inplace=True)\nupdated_df_train['category_type'].replace('\u0418\u0433\u0440\u044b','Games' , inplace=True)","ba2b9cf9":"# Show first 5 columns of \"updated_df_train\" Dataframe\nupdated_df_train.head()","4caff99b":"# Correcting shop_name column values\nupdated_df_train['shop_name'].replace('St. Petersburg TK \"Nevsky Center\"' , 'Petersburg TK \"Nevsky Center\"' , inplace=True) \nupdated_df_train['shop_name'].replace('Shop Online Emergencies' , 'online Shop Emergencies' , inplace=True) \nupdated_df_train['shop_name'].replace('Digital storage 1C-line' , 'online Digital storage 1C-line' , inplace=True)","d7cd6d4b":"# getting city name from shop_name column\nupdated_df_train['city'] = updated_df_train['shop_name'].str.split(' ').map(lambda x: x[0])","b8be8a4e":"# Adding new column avg_item_cnt_per_mnth column which tells us average of all items sales per month\ntemp = updated_df_train.groupby(['date_block_num']).agg({'item_cnt_month': ['mean']})\ntemp.columns = [ 'avg_item_cnt_per_mnth' ]\ntemp.reset_index(inplace=True)\nupdated_df_train = pd.merge(updated_df_train, temp, on=['date_block_num'], how='left')","7690d16e":"# Adding new column \"date_item_avg_item_cnt\"  which tells us average for each item sales per month\ntemp = updated_df_train.groupby(['date_block_num', 'item_id']).agg({'item_cnt_month': ['mean']})\ntemp.columns = [ 'date_item_avg_item_cnt' ]\ntemp.reset_index(inplace=True)\nupdated_df_train = pd.merge(updated_df_train, temp, on=['date_block_num','item_id'], how='left')","0d8084c2":"# Adding new column \"date_shop_avg_item_cnt\" which tells us average for each shop sales per month\ntemp = updated_df_train.groupby(['date_block_num', 'shop_id']).agg({'item_cnt_month': ['mean']})\ntemp.columns = [ 'date_shop_avg_item_cnt' ]\ntemp.reset_index(inplace=True)\nupdated_df_train = pd.merge(updated_df_train, temp, on=['date_block_num','shop_id'], how='left')","678470bc":"updated_df_train.columns","3aa711bd":"# Adding new column \"date_cat_avg_item_cnt\" ahich tells us average for each category sales per month\ntemp = updated_df_train.groupby(['date_block_num', 'item_category_id']).agg({'item_cnt_month': ['mean']})\ntemp.columns = [ 'date_cat_avg_item_cnt' ]\ntemp.reset_index(inplace=True)\nupdated_df_train = pd.merge(updated_df_train, temp, on=['date_block_num','item_category_id'], how='left')","59ffafe0":"# Adding new column \"date_shop_cat_avg_item_cnt\" which tells us average for each shop with category sales per month\ntemp = updated_df_train.groupby(['date_block_num', 'shop_id', 'item_category_id']).agg({'item_cnt_month': ['mean']})\ntemp.columns = ['date_shop_cat_avg_item_cnt']\ntemp.reset_index(inplace=True)\nupdated_df_train = pd.merge(updated_df_train, temp, on=['date_block_num', 'shop_id', 'item_category_id'], how='left')","e88a3fc2":"# Adding new column \"item_avg_item_price\" which tells us average price for each item\ntemp =df_train.groupby(['item_id']).agg({'item_price': ['mean']})\ntemp.columns = ['item_avg_item_price']\ntemp.reset_index(inplace=True)\nupdated_df_train = pd.merge(updated_df_train, temp, on=['item_id'], how='left')","b05d0520":"# Adding new column \"date_item_avg_item_price\" which tells us average price for each item per month\ntemp = df_train.groupby(['date_block_num','item_id']).agg({'item_price': ['mean']})\ntemp.columns = ['date_item_avg_item_price']\ntemp.reset_index(inplace=True)\nupdated_df_train = pd.merge(updated_df_train, temp, on=['date_block_num','item_id'], how='left')","c9127c8a":"# Adding new column \"date_shop_revenue\" which tells us sum of revenue for each shop per month\ntemp = df_train.groupby(['date_block_num','shop_id']).agg({'revenue': ['sum']})\ntemp.columns = ['date_shop_revenue']\ntemp.reset_index(inplace=True)\nupdated_df_train = pd.merge(updated_df_train, temp, on=['date_block_num','shop_id'], how='left')","ad76cc38":"# Adding  new column \"date_shop_revenue\" which tells us avreage of revenue for each shop\ntemp = updated_df_train.groupby(['shop_id']).agg({'date_shop_revenue': ['mean']})\ntemp.columns = ['shop_avg_revenue']\ntemp.reset_index(inplace=True)\nupdated_df_train = pd.merge(updated_df_train, temp, on=['shop_id'], how='left')","2ad71ea3":"# Adding  new lag columns which will contains the percent of the difference-\n# -between average shop revenue in lag months and sum of revenue for each shop per month\nupdated_df_train['delta_revenue'] = (updated_df_train['date_shop_revenue'] - updated_df_train['shop_avg_revenue']) \/ updated_df_train['shop_avg_revenue']","98b8de4a":"# Adding new column \"month\" wich will take month number from date_block_num\nupdated_df_train['month'] = updated_df_train['date_block_num'] % 12","10be81e7":"plot_fig = updated_df_train.groupby('month').agg({'item_cnt_month': sum}).sort_values(by='item_cnt_month',ascending=False).reset_index()","37525ef1":"\nplt.figure(figsize=(13,8))\nfig = sns.barplot(x=\"month\", y=\"item_cnt_month\", data=plot_fig)\n\nplt.xlabel(\"Item Count per Month\", fontsize=12)\nplt.ylabel(\"Months\", fontsize=12)\nplt.title(\"Monthly Sales\", fontsize=18)\nplt.show(fig)","caeba364":"# Adding Lag Columns\n\nupdated_df_train = feature_lag(updated_df_train, [1], 'avg_item_cnt_per_mnth')\n# updated_df_train.drop(['date_avg_item_cnt'], axis=1, inplace=True)\nupdated_df_train = feature_lag(updated_df_train, [1,2,3,6,12], 'date_item_avg_item_cnt')\n# updated_df_train.drop(['date_item_avg_item_cnt'], axis=1, inplace=True)\nupdated_df_train = feature_lag(updated_df_train, [1,2,3,6,12], 'date_shop_avg_item_cnt')\n# updated_df_train.drop(['date_shop_avg_item_cnt'], axis=1, inplace=True)\nupdated_df_train = feature_lag(updated_df_train, [1,2,3,6,12], 'date_item_avg_item_cnt')\n# updated_df_train.drop(['date_item_avg_item_cnt'], axis=1, inplace=True)\nupdated_df_train = feature_lag(updated_df_train, [1,2,3,6,12], 'date_shop_avg_item_cnt')\n# updated_df_train.drop(['date_shop_avg_item_cnt'], axis=1, inplace=True)\nupdated_df_train = feature_lag(updated_df_train, [1], 'date_cat_avg_item_cnt')\n# updated_df_train.drop(['date_cat_avg_item_cnt'], axis=1, inplace=True)\nupdated_df_train = feature_lag(updated_df_train, [1], 'date_shop_cat_avg_item_cnt')\n# updated_df_train.drop(['date_shop_cat_avg_item_cnt'], axis=1, inplace=True)\n\nupdated_df_train = feature_lag(updated_df_train, [1,2,3,4,5,6], 'date_item_avg_item_price')\nupdated_df_train = feature_lag(updated_df_train, [1], 'delta_revenue')\nlags = [1,2,3,4,5,6]\nfor i in lags:\n    updated_df_train['delta_price_lag_'+str(i)] = (updated_df_train['date_item_avg_item_price_lag_'+str(i)] - updated_df_train['item_avg_item_price']) \/ updated_df_train['item_avg_item_price']\n\ndef select_trend(row):\n    for i in lags:\n        if row['delta_price_lag_'+str(i)]:\n            return row['delta_price_lag_'+str(i)]\n    return 0\n    \nupdated_df_train['delta_price_lag'] = updated_df_train.apply(select_trend, axis=1)\nupdated_df_train['delta_price_lag'].fillna(0, inplace=True)\n\nfetures_to_drop = []\nfor i in lags:\n    fetures_to_drop += ['date_item_avg_item_price_lag_'+str(i)]\n    fetures_to_drop += ['delta_price_lag_'+str(i)]\n\nupdated_df_train.drop(fetures_to_drop, axis=1, inplace=True)\n","b872fda6":"updated_df_train.columns","d1792b67":"# Monthly Sales per category type\nplot_fig = updated_df_train.groupby('category_type').agg({'item_cnt_month': sum}).sort_values(by='item_cnt_month',ascending=False).reset_index()","62375b49":"plt.figure(figsize=(13,8))\nfig = sns.barplot(x=\"item_cnt_month\", y=\"category_type\", data=plot_fig)\n\nplt.xlabel(\"Item Count per Month\", fontsize=12)\nplt.ylabel(\"Category Type\", fontsize=12)\nplt.title(\"Monthly Sales per category type\", fontsize=18)\nplt.show(fig)","7b9ab03b":"# Sales Percentage Per Category\nplt.figure(figsize=(20,10))\nfig = px.pie(plot_fig, values='item_cnt_month', names='category_type', title='Sales Percentage Per Category')\nfig.show()","e728e092":"# Monthly Sales Per Sub Category Type\nplot_fig = updated_df_train.groupby('category_subtype').agg({'item_cnt_month': sum}).sort_values(by='item_cnt_month',ascending=False).reset_index()","e5c7b318":"plt.figure(figsize=(13,9))\nfig = sns.barplot(x=\"item_cnt_month\", y=\"category_subtype\", data=plot_fig)\n\nplt.xlabel(\"Item Count per Month\", fontsize=12)\nplt.ylabel(\"Sub Category Type\", fontsize=12)\nplt.title(\"Monthly Sales Per Sub Category Type\", fontsize=18)\nplt.show(fig)","2a794521":"# Sales Percentage Per Sub Category\nplt.figure(figsize=(20,10))\nfig = px.pie(plot_fig, values='item_cnt_month', names='category_subtype', title='Sales Percentage Per Sub Category')\nfig.show()","6f3125bc":"# Total Sales Per City\nplot_fig = updated_df_train.groupby('city').agg({'item_cnt_month': sum}).sort_values('item_cnt_month', ascending=False).reset_index()","1ec075f2":"plt.figure(figsize=(13,9))\nfig = sns.barplot(x=\"item_cnt_month\", y=\"city\", data=plot_fig)\nplt.xlabel(\"Item Count per Month\", fontsize=12)\nplt.ylabel(\"City\", fontsize=12)\nplt.title(\"Total Sales Per City\", fontsize=18)\nplt.show(fig)","a0496634":"# Sales Percentage Per City\nplt.figure(figsize=(20,10))\nfig = px.pie(plot_fig, values='item_cnt_month', names='city', title='Sales Percentage Per City')\nfig.show()","82940bb5":"# Total Sales Per Month\nplot_fig = updated_df_train.groupby('date_block_num').agg({'item_cnt_month': sum}).reset_index() \nplot_fig = plot_fig[plot_fig['date_block_num']<34]","0b4e66b5":"plt.figure(figsize=(13,8))\nfig = sns.lineplot(x=\"date_block_num\", y=\"item_cnt_month\", data=plot_fig)\nplt.xlabel(\"Item Count per Month\", fontsize=12)\nplt.ylabel(\"Months\", fontsize=12)\nplt.title(\"Total Sales Per Month\", fontsize=18)\nplt.xticks([i for i in range(0, 34)])\nplt.show(fig)\n","ac74020a":"# Avg Price Per Month\nplot_fig = updated_df_train.groupby('date_block_num').agg({'item_avg_item_price': sum}).reset_index()\nplot_fig = plot_fig[plot_fig['date_block_num']<34]","6448acf5":"plt.figure(figsize=(13,9))\nfig = sns.barplot(x=\"date_block_num\", y=\"item_avg_item_price\", data=plot_fig)\nplt.xlabel(\"Months\", fontsize=12)\nplt.ylabel(\"Avg Price\", fontsize=12)\nplt.title(\"Avg Price Per Month\", fontsize=18)\nplt.show(fig)","744647ea":"# Shop Sales\nplot_fig =  updated_df_train.groupby('shop_name').agg({'item_cnt_month': sum}).sort_values(by='item_cnt_month', ascending=False).reset_index()","c6cecccc":"plt.figure(figsize=(13,8))\nfig = sns.barplot(x=\"item_cnt_month\", y=\"shop_name\", data=plot_fig)\nplt.xlabel(\"Item Count per Month\", fontsize=12)\nplt.ylabel(\"Shop Name\", fontsize=12)\nplt.title(\"Shop Sales\", fontsize=18)\nplt.show(fig)","2ed00e3c":"# Description of updated_df_train\nupdated_df_train.describe().T","db517791":"# Label encoding Categorical Features\ncols=updated_df_train.select_dtypes(include=['object']).columns\nle=LabelEncoder()\nfor i in cols:\n    updated_df_train[i]=le.fit_transform(updated_df_train[i])","2c36d262":"updated_df_train.columns","8cacb150":"# Droping Unnecessary Features\nupdated_df_train.drop(['date_shop_cat_avg_item_cnt', 'avg_item_cnt_per_mnth' ,'date_item_avg_item_cnt',\n                        'date_shop_avg_item_cnt','date_cat_avg_item_cnt','shop_name','ID','item_avg_item_price',\n                        'date_item_avg_item_price','date_shop_revenue','shop_avg_revenue','delta_revenue',\n                        'delta_revenue_lag_1'], axis=1, inplace=True)","ed24c806":"# we will remove first 12 months because we are using 12 as lag\nupdated_df_train = updated_df_train[updated_df_train['date_block_num'] > 11]","675cf08c":"# Our data is too big so to save memory and modeling time we will change types for all columns\nfor col in updated_df_train.columns:\n    if col == 'date_shop_revenue':\n        updated_df_train[col] = updated_df_train[col].astype('float64')\n    elif col == 'item_cnt_month':\n        updated_df_train[col] = updated_df_train[col].astype('float32')\n    elif updated_df_train[col].dtype == 'float64':\n        updated_df_train[col] = updated_df_train[col].astype('float16')\n    elif col == 'item_id':\n        updated_df_train[col] = updated_df_train[col].astype('int16')\n    elif updated_df_train[col].dtype == 'int64':\n        updated_df_train[col] = updated_df_train[col].astype('int8')","6be1b1a8":"# AS mention in problem to clip the item_cnt_month to (0,20)\nupdated_df_train['item_cnt_month'] = updated_df_train['item_cnt_month'].clip(0,20)","e436bd81":"# Dividing the Features into X,y\nX = updated_df_train[updated_df_train['date_block_num'] < 34].drop(['item_cnt_month', 'item_name'], axis=1)\ny = updated_df_train[updated_df_train['date_block_num']< 34]['item_cnt_month']","1cb9140b":"# Spliting dataframe into train and test \nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=.1, random_state = 56)","e269a500":"# for testing\ntest = updated_df_train[updated_df_train['date_block_num'] == 34].drop(['item_cnt_month', 'item_name'], axis=1)","b5134096":"# for garbage collection\nimport gc\ngc.collect()","5c1cfc2e":"# applying Model Xgboost\nts = time.time()\n\nxgb_model = xgb.XGBRegressor(eta=0.01,\n                                 max_depth=10,n_estimators=2000,\n                                 colsample_bytree=0.5,\n                                 subsample=0.8,\n                                 gamma=2, reg_alpha=0, reg_lambda=2, min_child_weight=300,\n                                 max_bin=2048,\n                                 n_jobs=-1,\n                                 tree_method='hist'\n                                 )\n\nxgb_hist = xgb_model.fit(X_train,y_train,\n                         eval_set=[(X_train,y_train),(X_test,y_test)],\n                         eval_metric='rmse',\n                         early_stopping_rounds=10)\n\ntime.time() - ts","8799f288":"# prediction RMS value\ny_predV = xgb_model.predict(X_test)\nprint(np.sqrt(mean_squared_error(y_test, y_predV)))","95548253":"# prediction on test\ny_pred = xgb_model.predict(test)","90643f7c":"# Model Scores \nprint('Train Score:', xgb_model.score(X_train, y_train))\nprint('Test Score :', xgb_model.score(X_test, y_test))","2c690b2b":"results = xgb_model.evals_result()\nepochs = len(results['validation_0']['rmse'])\nx_axis = range(0, epochs)","bdd9de65":"# Decay in RMS value over n_estimators\nfig, ax = plt.subplots(figsize=(13,8))\nax.plot(x_axis, results['validation_0']['rmse'], label='Train')\nax.plot(x_axis, results['validation_1']['rmse'], label='Test')\nax.legend()\nplt.ylabel('rmse', fontsize=12)\nplt.xlabel('n_estimators', fontsize=12)\nplt.title('XGBoost', fontsize=18)\nplt.show()","8c493c46":"y_predV_Df = pd.DataFrame({'date_block_num' : X_test['date_block_num'] ,'item_cnt_month' : y_predV  })","35fd58b7":"y_test_Df = pd.DataFrame({'date_block_num' : X_test['date_block_num'] ,'item_cnt_month' : y_test  })","89ea677f":"# showing actual and predicted values\nfig , ax = plt.subplots(ncols=1 , figsize=(13,8))\nxl = y_test_Df.groupby('date_block_num').agg({'item_cnt_month': sum}).reset_index()\ny_predsum = y_predV_Df.groupby('date_block_num').agg({'item_cnt_month': sum}).reset_index()\nxl.plot(x='date_block_num',y='item_cnt_month' , kind='line' , ax=ax ,  linewidth=2 , c='b')\ny_predsum.plot(x='date_block_num',y='item_cnt_month' , kind='line' , ax=ax , linewidth=2 , c='orange' )\nplt.legend(['Actual' , 'Predicted'])\nplt.xlabel('Months' , fontsize=12)\nplt.ylabel('Item Count per Month' , fontsize=12)\nplt.title('Total Sales Per Month', fontsize=18)\nax.set_xticks([i for i in range(12, 35)])\nplt.show()","e07bbf68":"X_plot= updated_df_train[updated_df_train['date_block_num'] < 34]","0c108435":"y_predDf = pd.DataFrame({'date_block_num' : 34 ,'item_cnt_month' : y_pred  })\ny_predsum = y_predDf.groupby('date_block_num').agg({'item_cnt_month': sum}).reset_index()\nxl = X_plot.groupby('date_block_num').agg({'item_cnt_month': sum}).reset_index()\nmk = pd.concat([xl, y_predsum])","1ae7b4bc":"# ploting prediction sales\nfig , ax = plt.subplots(ncols=1 , figsize=(13,8))\nmk.plot(x='date_block_num',y='item_cnt_month' , kind='line' , ax=ax ,  linewidth=2 , c='orange')\nxl.plot(x='date_block_num',y='item_cnt_month' , kind='line' , ax=ax , linewidth=2 , c='b' )\nax.legend(['Test' , 'Train'])\nplt.xlabel('Months' , fontsize=12)\nplt.ylabel('Item Count per Month' , fontsize=12)\nplt.title('Total Sales Per Month', fontsize=18)\nax.set_xticks([i for i in range(12, 35)])\nplt.show()","7a0f22be":"# predicted Total Sales Per Month\nfig, ax = plt.subplots(ncols=1, sharey=True, figsize = (13,8))\nsns.barplot(data=mk, x='date_block_num', y='item_cnt_month', ax = ax)\nplt.title('Total Sales Per Month', fontsize=18)\nplt.xlabel('Months', fontsize=12)\nplt.ylabel('Sales', fontsize=12)","9afb16c0":"df_test.head()\n","6f020672":"df_test['item_cnt_month'] = y_pred\ndf_test.loc[:,['ID','item_cnt_month']].to_csv('Submission_boost.csv',index = False)","86acdcd5":"df_test.head()","ebd59bff":"|Feature|Dataset|Description|\n|-------|---|---|\n|ID|df_test|an Id that represents a (Shop, Item) tuple within the test set.| \n|Shop_id|df_train|unique identifier of a shop.| \n|item_id|df_train|unique identifier of a product.| \n|item_category_id |df_catog|unique identifier of item category.| \n|item_cnt_day|df_train|number of products sold. You are predicting a monthly amount of this measure.| \n|item_price|df_train|current price of an item.| \n|date|df_train|date in format dd\/mm\/yyyy.| \n|date_block_num|df_train|a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1,..., October 2015 is 33.| \n|item_name|df_items|name of item.|\n|shop_name|df_shops|name of shop.|\n|item_category_name|df_catog|name of item category.|","c3b8cef6":"### The data in time series structure, So here we are creating a function which will create a lag columns to see how the data changes from time to time"}}