{"cell_type":{"bffe9076":"code","1f3ade05":"code","4b95a492":"code","c74f06a6":"code","376a9550":"code","2a57cef3":"code","1f1bf07b":"code","0737e3f7":"code","cdbb334b":"code","7f649449":"code","c093ab25":"code","78258a64":"code","2550684c":"code","adc97121":"markdown","f22d58fb":"markdown","b3031a0a":"markdown","e4a93b1f":"markdown","9613ed2e":"markdown","2ace3e17":"markdown","d6ee8caf":"markdown","20bdacf4":"markdown","b492b408":"markdown","01b4c395":"markdown","8b3c9acd":"markdown"},"source":{"bffe9076":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import linear_model\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder","1f3ade05":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_full=test.copy(deep=True)\ntrain.head()","4b95a492":"train.info()","c74f06a6":"train.drop(columns=['Cabin','Name','Ticket','PassengerId'],inplace=True)\ntest.drop(columns=['Cabin','Name','Ticket','PassengerId'],inplace=True)\n\ntrain.info()","376a9550":"test.info()","2a57cef3":"train.Age.fillna(train.Age.median(),inplace=True)\ntest.Age.fillna(test.Age.median(),inplace=True)\n\ntest.Fare.fillna(test.Age.median(),inplace=True)\n\ntrain.Embarked.fillna(train.Embarked.mode()[0],inplace=True)\ntest.Embarked.fillna(test.Embarked.mode()[0],inplace=True)","1f1bf07b":"labeler = LabelEncoder()\n\ntrain['Sex']=labeler.fit_transform(train['Sex'])\ntrain['Embarked']=labeler.fit_transform(train['Embarked'])\n\ntest['Sex']=labeler.fit_transform(test['Sex'])\ntest['Embarked']=labeler.fit_transform(test['Embarked'])","0737e3f7":"y_train = train['Survived']\nX_train = train.drop(columns='Survived')","cdbb334b":"plt.figure(figsize=(10,6))\ncorr = train.corr()\nsns.heatmap(abs(corr),cmap='Blues',annot=True)","7f649449":"vif = pd.DataFrame()\nvif[\"VIF Factor\"] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif[\"features\"] = X_train.columns\nvif","c093ab25":"scale = StandardScaler()\nX_train = scale.fit_transform(X_train)","78258a64":"lr = linear_model.LogisticRegression()\nlr.fit(X_train,y_train)\nlr.score(X_train,y_train)","2550684c":"predictions = lr.predict(test)\noutput=pd.DataFrame({'PassengerId': test_full.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)","adc97121":"Separate the independent and dependent variables.","f22d58fb":"First we scale the data and run a quick and dirty model.","b3031a0a":"Let us fill the null values of Age with the median and the null values for Embarked with the mode. For Fare in test data, we fill using median also.","e4a93b1f":"### Takeaway: Since no feature has VIF Factor>10, we can be confident to retain all features.","9613ed2e":"# 1. Let us first load the data and check what it contains","2ace3e17":"# 3. Model","d6ee8caf":"Let us drop the column 'Cabin' since it contains a lot of missing data. Also Name and Ticket are unique values per passenger so we can drop these.","20bdacf4":"### Takeaway: Sex and Pclass has the strongest correlation to Survival.\n\nI am planning to use Logistic Regression for this problem. So let us check if multi-collinearity exists using VIF.","b492b408":"# 2. Visualizations","01b4c395":"Check for missing data","8b3c9acd":"Then, let us convert the categorical values into numbers. We use LabelEncoder on this.\nWe have two features to transform: Sex and Embarked"}}