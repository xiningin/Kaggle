{"cell_type":{"4da5ce56":"code","20bf889a":"code","e894a01a":"code","10d87da5":"code","fe96064c":"code","814ad38d":"code","ad7e5cc0":"code","5c48a73d":"code","cbe813c9":"code","b0e96902":"code","d1bfb556":"code","dc3e0d95":"code","f52408c0":"code","4b695ef9":"code","79216189":"code","e826e1a5":"code","c3e6dd33":"markdown","13c7c179":"markdown","8ba2e004":"markdown","7c64a006":"markdown","5b814f76":"markdown","bca6967b":"markdown","02486a4a":"markdown","5b98ce4a":"markdown","bdc3915d":"markdown","93268645":"markdown","b375b65b":"markdown"},"source":{"4da5ce56":"!pip install openpyxl\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport pandas as pd\nimport numpy as np","20bf889a":"l_data = pd.read_excel('..\/input\/air-quality-time-series-data-uci\/AirQualityUCI.xlsx')","e894a01a":"l_data['hour'] = 0\nfor i in range(l_data.shape[0]):\n  l_data['hour'][i] = l_data['Time'][i].hour\n\ntime_se = l_data['Date'].dt.date - l_data['Date'].dt.date.min()\n\nleak = pd.DataFrame({\n    'deg_C' : l_data['T'],\n    'relative_humidity' : l_data['RH'],\n    'absolute_humidity' : l_data['AH'],\n    'sensor_1' : l_data['PT08.S1(CO)'],\n    'sensor_2' : l_data['PT08.S2(NMHC)'],\n    'sensor_3' : l_data['PT08.S3(NOx)'],\n    'sensor_4' : l_data['PT08.S4(NO2)'],\n    'sensor_5' : l_data['PT08.S5(O3)'],\n    'target_carbon_monoxide' : l_data['CO(GT)'],\n    'target_benzene' : l_data['C6H6(GT)'],\n    'target_nitrogen_oxides' : l_data['NOx(GT)'],\n    'year' : l_data['Date'].dt.year,\n    'month' : l_data['Date'].dt.month,\n    'week' : l_data['Date'].dt.week,\n    'day' : l_data['Date'].dt.day,\n    'dayofweek' : l_data['Date'].dt.dayofweek,\n    'time' : time_se,\n    'hour' : l_data['hour'],\n})\nleak['time'] = leak['time'].apply(lambda x : x.days)\n\nleak_sub = leak[7110:].reset_index(drop = True)\ncarbon_out = leak_sub[leak_sub['target_carbon_monoxide'] == -200].index\nbenzene_out = leak_sub[leak_sub['target_benzene'] == -200].index\nnitrogen_out = leak_sub[leak_sub['target_nitrogen_oxides'] == -200].index\n\nleak","10d87da5":"tps_train = pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/train.csv')\ntps_test = pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/test.csv')\ntps_dataset = pd.concat([tps_train, tps_test]).reset_index(drop = True)\n\ntps_dataset['date_time'] = pd.to_datetime(tps_dataset['date_time'])\ntps_dataset['year'] = tps_dataset['date_time'].dt.year\ntps_dataset['month'] = tps_dataset['date_time'].dt.month\ntps_dataset['week'] = tps_dataset['date_time'].dt.week\ntps_dataset['day'] = tps_dataset['date_time'].dt.day\ntps_dataset['dayofweek'] = tps_dataset['date_time'].dt.dayofweek\ntps_dataset['time'] = tps_dataset['date_time'].dt.date - tps_dataset['date_time'].dt.date.min()\ntps_dataset['hour'] = tps_dataset['date_time'].dt.hour\ntps_dataset['time'] = tps_dataset['time'].apply(lambda x : x.days)\n\ntps_dataset.drop(columns = 'date_time', inplace = True)\ntps_dataset","fe96064c":"import matplotlib.pyplot as plt\nimport seaborn as sns","814ad38d":"def Comparison_Dist_Plot(targets):\n    NUM_COLS = len(targets)\n    n = 0\n    fig, ax = plt.subplots(NUM_COLS, 2, figsize = (10, NUM_COLS * 3))\n    if NUM_COLS == 1:\n        sns.distplot(tps_dataset[targets[0]], ax = ax[0]);\n        ax[0].set_title('TPS', fontsize = 15)\n        sns.distplot(leak[targets[0]], ax = ax[1]);\n        ax[1].set_title('UCI', fontsize = 15)\n    else:\n        for i in range(NUM_COLS):\n            sns.distplot(tps_dataset[targets[i]], ax = ax[n, 0], color='red');\n            ax[n, 0].set_title('TPS', fontsize = 15)\n            sns.distplot(leak[targets[i]], ax = ax[n, 1], color = 'violet');\n            ax[n, 1].set_title('UCI', fontsize = 15)\n            n += 1\n        plt.tight_layout()\n        plt.show()","ad7e5cc0":"Comparison_Dist_Plot(tps_dataset.columns[:11])","5c48a73d":"# Outliers Preprocessing\n\nfrom lightgbm import LGBMRegressor\n\ndef Outliers(targets):\n    NUM = len(targets)\n    for i in range(NUM):\n        # Data Preparing\n        leaked_data = leak.drop(columns = targets[i])\n        out = leak[leak[targets[i]] == -200].index\n        X = tps_dataset.drop(columns = targets[i])\n        X = X.drop(columns = 'year')\n        y = tps_dataset[targets[i]]\n        test = leaked_data.iloc[out]\n        test = test.drop(columns = 'year')\n        \n        # Modeling\n        lgbm = LGBMRegressor(learning_rate = 0.1, n_estimators=1000)\n        lgbm.fit(X, y, verbose = False)\n        pred = lgbm.predict(test)\n        \n        leak.loc[out, targets[i]] = pred\n    print('done!')","cbe813c9":"Outlier_Target = tps_dataset.columns[:11]\nOutliers(Outlier_Target)","b0e96902":"Comparison_Dist_Plot(tps_dataset.columns[:11])","d1bfb556":"fig, ax = plt.subplots(1, 2, figsize = (20, 10))\nsns.heatmap(tps_dataset.corr(), ax = ax[0])\nax[0].set_title('TPS', fontsize = 30)\nsns.heatmap(leak.corr(), ax = ax[1])\nax[1].set_title('UCI', fontsize = 30)\nplt.tight_layout()\nplt.show()","dc3e0d95":"best_sub = pd.read_csv('..\/input\/dasdas\/sub (44).csv')\nbest_sub","f52408c0":"leak_sub","4b695ef9":"leak_sub.loc[carbon_out, 'target_carbon_monoxide'] = best_sub.loc[carbon_out, 'target_carbon_monoxide']\nleak_sub.loc[benzene_out, 'target_benzene'] = best_sub.loc[benzene_out, 'target_benzene']\nleak_sub.loc[nitrogen_out, 'target_nitrogen_oxides'] = best_sub.loc[nitrogen_out, 'target_nitrogen_oxides']","79216189":"sub = pd.read_csv('..\/input\/tabular-playground-series-jul-2021\/sample_submission.csv')\nsub['target_carbon_monoxide'] = leak_sub['target_carbon_monoxide']\nsub['target_benzene'] = leak_sub['target_benzene']\nsub['target_nitrogen_oxides'] = leak_sub['target_nitrogen_oxides']\nsub","e826e1a5":"sub.to_csv('sub.csv', index = False)","c3e6dd33":"## **Let's make sub.csv !!**","13c7c179":"### **Making new dataframe which has same columns with TPS-dataset**\n\n**Preprocessed Datetime-column!**","8ba2e004":"## **Some sick kagglers found the data which is similar with our competition's data!!**","7c64a006":"## **NOW, we can clarify that those two datasets are similar each other!!**\n\n## More Visualization??","5b814f76":"[Click Here](https:\/\/archive.ics.uci.edu\/ml\/datasets\/Air+Quality) **to check the original data!**","bca6967b":"### **We can see that there are outliers in UCI Dataset (like missing values, value = -200)**\n\n  ### **Let's handle it!**\n  ###   **Change values which are -200 using LGBM to predict real value**","02486a4a":"### **With above datasets, it seems that kaggle just changed Year information in UCI dataset and used for this competition...**\n\n\n### **We can clarify this with comparision using visualization**","5b98ce4a":"# **EDA**","bdc3915d":"### With UCI-Air Quality Dataset, we can compare given data's informations!!!\n\n\n- **Sensor Columns**\n\n    * sensor_1 : Hourly Averaged Sensor Response (nominally CO targeted)\n    * sensor_2 : Hourly Averaged Sensor Response (nominally NMHC targeted, not in this competition)\n    * sensor_3 : Hourly Averaged Sensor Response (nominally NOx targeted)\n    * sensor_4 : Hourly Averaged Sensor Response (nominally NO2 targeted)\n    * sensor_5 : Hourly Averaged Sensor Response (nominally O3 targeted)\n\n\n- **Target Columns**\n\n    * target_carbon_monoxide : Hourly Averaged CO Concentration in mg\/m^3\n    * target_benzene : Hourly Averaged Benzene Concentration in microg\/m^3\n    * target_nitrogen_oxides : Hourly Averaged NOx Concentration in ppb","93268645":"# **Introduction**","b375b65b":"### **Changing -200 values to Best Sub's values**"}}