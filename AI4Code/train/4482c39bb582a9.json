{"cell_type":{"7a68bf2a":"code","6c165b92":"code","c8a453f8":"code","96b1fec7":"code","888f5c7c":"code","9b5a2b78":"code","afdacf2c":"code","27c3c964":"code","17420335":"code","a1e9d90a":"code","cc7c48dd":"code","86653e21":"code","6addb1fe":"code","f4486d3a":"code","d365a050":"code","66332a7e":"code","ff3e8534":"code","e272c557":"code","f21e2179":"code","ebc640f3":"code","4da66116":"code","b544da06":"code","8eb082d2":"code","f464b502":"code","1048642b":"code","3b0ff3f9":"code","840f09f4":"code","1e5d1748":"code","f3be4b69":"code","7e64ee80":"code","4aa61ca8":"code","81edfc43":"code","e7dbe6e7":"code","d4c482f4":"code","ac64cb1a":"code","6d72ca47":"code","73edbd82":"code","b9208688":"code","be95a8f7":"code","201f6915":"code","2ff6e80a":"code","d8d307c3":"code","eed221e3":"code","49b603ac":"code","af7f63af":"code","280c45bd":"code","26e092bf":"code","ef0893ec":"code","0907058c":"markdown","7e9cf749":"markdown","0492ea20":"markdown","36cf8eb9":"markdown","51e7b9e3":"markdown","b61dff01":"markdown","dcc8d7d9":"markdown","3ba42a6b":"markdown","de8568c5":"markdown","2cbd06df":"markdown","55b64976":"markdown","c54f9226":"markdown","caa576a4":"markdown","5656c0b6":"markdown","0782754a":"markdown","aa508553":"markdown","56a88f89":"markdown","cf30b7f2":"markdown","fd7b2b2f":"markdown","457c7f35":"markdown","0291219a":"markdown","f0189d64":"markdown","d950694c":"markdown","4fcff312":"markdown","a2fccd43":"markdown","a93289d4":"markdown","7a185beb":"markdown"},"source":{"7a68bf2a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.metrics import f1_score\nimport graphviz\nfrom sklearn import tree\nfrom sklearn.model_selection import KFold","6c165b92":"# prettify plots\nplt.rcParams['figure.figsize'] = [20.0, 5.0]","c8a453f8":"!ls ..\/input\/**","96b1fec7":"%%time\ntest = pd.read_csv('..\/input\/clean-datasets-drift-noise-removed\/test_clean_removed_drift_noise.csv')","888f5c7c":"%%time\ntrain = pd.read_csv('..\/input\/clean-datasets-drift-noise-removed\/train_clean_removed_drift_noise.csv')","9b5a2b78":"train.head()","afdacf2c":"test.head()","27c3c964":"res = 1000\nbatch_size=500000\nsub_sample_size = batch_size\/5\nmargin=200000\n\ndef plot_data(column, column_name):\n    plt.figure(figsize=(20,5))\n    plt.plot(range(0, column.shape[0], res), column[0::res])\n    for i in range(11): plt.plot([i*batch_size,i*batch_size],[-5,12.5],'r')\n    for j in range(10): plt.text(j*batch_size+margin,10,str(j+1),size=20)\n    plt.xlabel('Row',size=16); plt.ylabel(column_name,size=16); \n    plt.title(f'Training Data {column_name} - 10 batches',size=20)\n    plt.show()","17420335":"plot_data(train.signal, 'Signal')","a1e9d90a":"plot_data(train.open_channels, 'Open Channels')","cc7c48dd":"def chain_to_previous_range(indices: tuple, folds: int):\n    return indices[1] + folds, indices[1] + folds\n    \ndef generate_range_of_indices(indices: tuple, fold_size: int, max_allowed_value: int):\n    start = fold_size * indices[0]\n    end = fold_size * (indices[1] + 1)\n    if abs(max_allowed_value - end) <= 3:\n        end = max_allowed_value\n\n    return np.array(range(start, end))","86653e21":"def generate_nested_folds_batch_ranges(total_folds_size: int, num_of_training_folds: int = 3,\n                                       num_of_validation_folds: int = 1, num_of_test_folds: int = 0):\n    total_folds_size = int(total_folds_size)\n    total_folds = num_of_training_folds + num_of_validation_folds + num_of_test_folds\n    each_fold_size = int(round(total_folds_size \/ total_folds))\n\n    nested_folds_indices = []\n    min_training_index = 0\n    max_training_index = total_folds - num_of_validation_folds - num_of_test_folds\n    for max_training_index_this_fold in range(min_training_index, max_training_index):\n        training_indices = (min_training_index, max_training_index_this_fold)\n        validation_indices = chain_to_previous_range(training_indices, num_of_validation_folds)\n        test_indices = (0, 0)\n        if num_of_test_folds > 0:\n            test_indices = chain_to_previous_range(validation_indices, num_of_test_folds)\n        nested_folds_indices.append([training_indices, validation_indices, test_indices])\n\n    nested_batch_indices = []\n    for each_nested_fold_indices in nested_folds_indices:\n        training_indices = each_nested_fold_indices[0]\n        validation_indices = each_nested_fold_indices[1]\n        test_indices = each_nested_fold_indices[2]\n\n        indices = [\n            generate_range_of_indices(training_indices, each_fold_size, total_folds_size),\n            generate_range_of_indices(validation_indices, each_fold_size, total_folds_size),\n        ]\n        if num_of_test_folds > 0:\n            indices.append(\n                generate_range_of_indices(test_indices, each_fold_size, total_folds_size),\n            )\n        nested_batch_indices.append(indices)\n\n    return nested_batch_indices","6addb1fe":"print(\"training,      validation,        test\")\ngenerate_nested_folds_batch_ranges(train.shape[0], 5)","f4486d3a":"print(\"training,      validation,        test\")\ngenerate_nested_folds_batch_ranges(train.shape[0], 5, 1, 1)","d365a050":"training_folds = 5","66332a7e":"def get_kfold_enumerator(dataset: pd.DataFrame, folds: int = training_folds):\n    return enumerate(KFold(n_splits=folds).split(dataset))","ff3e8534":"def get_nestedcv_enumerator(dataset: pd.DataFrame, folds: int = training_folds):\n    return enumerate(generate_nested_folds_batch_ranges(dataset.shape[0], folds))","e272c557":"def train_with_cross_validation(params, model, X_train, y_train, cv_enumerator=get_nestedcv_enumerator):\n    total_f1_macro_score = 0.0\n    models = []\n    best_model = None\n    best_f1_macro_score = 0.0\n    for fold_index, (training_index, validation_index) in cv_enumerator(X_train):\n        X_training_set = X_train[training_index]\n        y_training_set = y_train[training_index]\n        X_validation = X_train[validation_index]\n        y_validation = y_train[validation_index]\n        model = model.fit(X_training_set, y_training_set)\n        models.append(model)\n        predictions = model.predict(X_validation)\n        f1_macro_score = f1_score(y_validation, predictions, average='macro')\n        if best_f1_macro_score < f1_macro_score:\n            best_f1_macro_score = f1_macro_score\n            best_model = model\n        print(f'fold {fold_index + 1}: macro f1 validation score: {f1_macro_score}, best macro f1 validation score: {best_f1_macro_score}')\n        total_f1_macro_score += f1_macro_score\n\n    return models, best_model, total_f1_macro_score\/training_folds\n\ndef train_model_by_batch(train_df, first_batch, second_batch, model_type, class_names=['0', '1'], params={'max_depth':1}, cv_enumerator=get_nestedcv_enumerator):\n    a = batch_size * (first_batch - 1); b = batch_size * first_batch\n    c = batch_size * (second_batch - 1); d = batch_size * second_batch\n    X_train = np.concatenate([train_df.signal.values[a:b], train_df.signal.values[c:d]]).reshape((-1,1))\n    y_train = np.concatenate([train_df.open_channels.values[a:b], train_df.open_channels.values[c:d]]).reshape((-1,1))\n\n    print(f'Training model {model_type} channel')\n    model = tree.DecisionTreeClassifier(**params)\n    models, best_model, f1_macro_score = train_with_cross_validation(params, model, X_train, y_train, cv_enumerator=cv_enumerator)\n    print(f'model {model_type}, average macro f1 validation score = {f1_macro_score}')\n\n    tree_graph = tree.export_graphviz(best_model, out_file=None, max_depth = 10,\n        impurity = False, feature_names = ['signal'], class_names = class_names,\n        rounded = True, filled= True )\n    return models, f1_macro_score, graphviz.Source(tree_graph) ","f21e2179":"import numpy as np\nfrom sklearn.metrics import f1_score\nfrom tensorflow.keras.callbacks import Callback\n\n\ndef macro_f1(y_true, y_pred):\n    \"\"\"\n    The Macro F1 metric used in this competition\n    :param y_true: The ground truth labels given in the dataset\n    :param y_pred: Our predictions\n    :return: The Macro F1 Score\n    \"\"\"\n    return f1_score(y_true, y_pred, average=\"macro\", labels=np.unique(y_true))","ebc640f3":"nestedcv_f1_macro_scores = []\nkfold_f1_macro_scores = []","4da66116":"%%time\nnestedcv_clf1s, f1_macro_score, graph = train_model_by_batch(train, 1, 2, '1s', cv_enumerator=get_nestedcv_enumerator)\nnestedcv_f1_macro_scores.append(f1_macro_score)\ngraph","b544da06":"%%time\nkfold_clf1s, f1_macro_score, graph = train_model_by_batch(train, 1, 2, '1s', cv_enumerator=get_kfold_enumerator)\nkfold_f1_macro_scores.append(f1_macro_score)\ngraph","8eb082d2":"%%time\nnestedcv_clf1f, f1_macro_score, graph = train_model_by_batch(train, 3, 7, '1f', cv_enumerator=get_nestedcv_enumerator)\nnestedcv_f1_macro_scores.append(f1_macro_score)\ngraph","f464b502":"%%time\nkfold_clf1f, f1_macro_score, graph = train_model_by_batch(train, 3, 7, '1f', cv_enumerator=get_kfold_enumerator)\nkfold_f1_macro_scores.append(f1_macro_score)\ngraph","1048642b":"%%time\nprint(\"Training using NestedCV cross-validation method\")\nnestedcv_clf3, f1_macro_score, graph = train_model_by_batch(train, 4, 8, '3', \n                                                            class_names=['0','1','2','3'], params={'max_leaf_nodes': 4}, \n                                                            cv_enumerator=get_nestedcv_enumerator)\nnestedcv_f1_macro_scores.append(f1_macro_score)\ngraph","3b0ff3f9":"%%time\nprint(\"Training using KFold cross-validation method\")\nkfold_clf3, f1_macro_score, graph = train_model_by_batch(train, 4, 8, '3', \n                                                         class_names=['0','1','2','3'], params={'max_leaf_nodes': 4}, \n                                                         cv_enumerator=get_kfold_enumerator)\nkfold_f1_macro_scores.append(f1_macro_score)\ngraph","840f09f4":"%%time\nprint(\"Training using NestedCV cross-validation method\")\nnestedcv_clf5, f1_macro_score, graph = train_model_by_batch(train, 6, 9, '5', \n                                                            class_names=['0','1','2','3','4','5'], params={'max_leaf_nodes': 6}, \n                                                            cv_enumerator=get_nestedcv_enumerator)\nnestedcv_f1_macro_scores.append(f1_macro_score)\ngraph","1e5d1748":"%%time\nprint(\"Training using KFold cross-validation method\")\nkfold_clf5, f1_macro_score, graph = train_model_by_batch(train, 6, 9, '5', \n                                                            class_names=['0','1','2','3','4','5'], params={'max_leaf_nodes': 6}, \n                                                           cv_enumerator=get_kfold_enumerator)\nkfold_f1_macro_scores.append(f1_macro_score)\ngraph","f3be4b69":"%%time\nprint(\"Training using NestedCV cross-validation method\")\nnestedcv_clf10, f1_macro_score, graph = train_model_by_batch(train, 5, 10, '10', \n                                                             class_names=[str(x) for x in range(11)], params={'max_leaf_nodes': 255}, \n                                                             cv_enumerator=get_nestedcv_enumerator)\nnestedcv_f1_macro_scores.append(f1_macro_score)\ngraph","7e64ee80":"%%time\nprint(\"Training using KFold cross-validation method\")\nkfold_clf10, f1_macro_score, graph = train_model_by_batch(train, 5, 10, '10', \n                                                             class_names=[str(x) for x in range(11)], params={'max_leaf_nodes': 255}, \n                                                             cv_enumerator=get_kfold_enumerator)\nkfold_f1_macro_scores.append(f1_macro_score)\ngraph","4aa61ca8":"%%time\nnestedcv_sub = pd.read_csv('..\/input\/liverpool-ion-switching\/sample_submission.csv')\nkfold_sub = nestedcv_sub.copy()","81edfc43":"\"\"\"\n1 Slow Open Channel (1)\n1 Fast Open Channel (2)\n3 Open Channels (3)\n5 Open Channels (4)\n10 Open Channels (5)\n\nTraining Batches\n1,  2 ==>  1 Slow Open Channel\n3,  7 ==>  1 Fast Open Channel\n4,  8 ==>  3 Open Channels\n6,  9 ==>  5 Open Channels\n5, 10 ==> 10 Open Channels\n\"\"\"\n\nf1_macro_scores = nestedcv_f1_macro_scores\nnestedcv_params = [\n    [ (0, 1), \"Subsample A\",     \"Model 1s (1 Slow Open Channel)\", nestedcv_clf1s, f1_macro_scores[0]],\n    [ (1, 2), \"Subsample B\",     \"Model 3  (3 Open Channels)\",     nestedcv_clf3,  f1_macro_scores[2]],\n    [ (2, 3), \"Subsample C\",     \"Model 5  (5 Open Channels)\",     nestedcv_clf5,  f1_macro_scores[3]],\n    [ (3, 4), \"Subsample D\",     \"Model 1s (1 Slow Open Channel)\", nestedcv_clf1s, f1_macro_scores[0]],\n    [ (4, 5), \"Subsample E\",     \"Model 1f (1 Fast Open Channel)\", nestedcv_clf1f, f1_macro_scores[1]],\n    [ (5, 6), \"Subsample F\",     \"Model 10 (10 Open Channels)\",    nestedcv_clf10, f1_macro_scores[4]],\n    [ (6, 7), \"Subsample G\",     \"Model 5  (5 Open Channels)\",     nestedcv_clf5,  f1_macro_scores[3]],\n    [ (7, 8), \"Subsample H\",     \"Model 10 (10 Open Channels)\",    nestedcv_clf10, f1_macro_scores[4]],\n    [ (8, 9), \"Subsample I\",     \"Model 1s (1 Slow Open Channel)\", nestedcv_clf1s, f1_macro_scores[0]],\n    [ (9,10), \"Subsample J\",     \"Model 3  (3 Open Channels)\",     nestedcv_clf3,  f1_macro_scores[2]],\n    [(10,20), \"Batches 3 and 4\", \"Model 1s (1 Slow Open Channel)\", nestedcv_clf1s, f1_macro_scores[0]]\n]\n\nf1_macro_scores = kfold_f1_macro_scores\nkfold_params = [\n    [ (0, 1), \"Subsample A\",     \"Model 1s (1 Slow Open Channel)\", kfold_clf1s, f1_macro_scores[0]],\n    [ (1, 2), \"Subsample B\",     \"Model 3  (3 Open Channels)\",     kfold_clf3,  f1_macro_scores[2]],\n    [ (2, 3), \"Subsample C\",     \"Model 5  (5 Open Channels)\",     kfold_clf5,  f1_macro_scores[3]],\n    [ (3, 4), \"Subsample D\",     \"Model 1s (1 Slow Open Channel)\", kfold_clf1s, f1_macro_scores[0]],\n    [ (4, 5), \"Subsample E\",     \"Model 1f (1 Fast Open Channel)\", kfold_clf1f, f1_macro_scores[1]],\n    [ (5, 6), \"Subsample F\",     \"Model 10 (10 Open Channels)\",    kfold_clf10, f1_macro_scores[4]],\n    [ (6, 7), \"Subsample G\",     \"Model 5  (5 Open Channels)\",     kfold_clf5,  f1_macro_scores[3]],\n    [ (7, 8), \"Subsample H\",     \"Model 10 (10 Open Channels)\",    kfold_clf10, f1_macro_scores[4]],\n    [ (8, 9), \"Subsample I\",     \"Model 1s (1 Slow Open Channel)\", kfold_clf1s, f1_macro_scores[0]],\n    [ (9,10), \"Subsample J\",     \"Model 3  (3 Open Channels)\",     kfold_clf3,  f1_macro_scores[2]],\n    [(10,20), \"Batches 3 and 4\", \"Model 1s (1 Slow Open Channel)\", kfold_clf1s, f1_macro_scores[0]]\n]","e7dbe6e7":"def ensemble_by_geometric_mean(sets_of_predictions,\n                               number_of_predictions_per_set: int,\n                               min_label_value: int,\n                               max_label_value: int) -> np.ndarray:\n    result = np.ones(number_of_predictions_per_set)\n    for index, each_set_of_predictions in enumerate(sets_of_predictions):\n        result *= each_set_of_predictions\n    result = result ** (1 \/ len(sets_of_predictions))\n    \n    return np.nan_to_num(result, nan=min_label_value, posinf=max_label_value, neginf=min_label_value)\n    \ndef predict_using(models, data):\n    predictions = []\n    if isinstance(models, list):\n        for each_model in models:\n            predictions.append(each_model.predict(data))\n        return ensemble_by_geometric_mean(predictions, len(data), 0, 10)\n    else:\n        return np.round(models.predict(data))\n    \ndef create_prediction(reference_dataframe, results_dataframe, params):\n    total_score = 0.0\n    for each_param in params:\n        begin_index, end_index = each_param[0]\n        start_batch = int(sub_sample_size * begin_index)\n        end_batch = int(sub_sample_size * end_index)\n        batch_or_sample_models = each_param[3]\n        f1_macro_score = each_param[4]\n        X_signal_batch = reference_dataframe.signal.values[start_batch:end_batch].reshape((-1,1))\n        results_dataframe.iloc[start_batch:end_batch, 1] = predict_using(batch_or_sample_models, X_signal_batch)\n        print(f\"Updated {each_param[1]} ({start_batch} to {end_batch}) of submission with predictions from {each_param[2]} with a F1 Macro score of {f1_macro_score}\")\n        total_score = total_score + f1_macro_score\n\n    print()\n    average_f1_macro_score = total_score\/len(params)\n    print(f\"Average F1 Macro across the {len(params)} subsamples\/batches: {average_f1_macro_score}\")\n    results_dataframe.open_channels = results_dataframe.open_channels.astype(int)\n    return results_dataframe, average_f1_macro_score","d4c482f4":"%%time\nnestedcv_sub, nestedcv_average_f1_macro_score = create_prediction(test, nestedcv_sub, nestedcv_params)","ac64cb1a":"%%time\nkfold_sub, kfold_average_f1_macro_score = create_prediction(test, kfold_sub, kfold_params)","6d72ca47":"res = 1000\nletters = ['A','B','C','D','E','F','G','H','I','J']\n\ndef plot_results(reference_dataframe, results_dataframe):\n    plt.figure(figsize=(20,5))\n    plt.plot(range(0,reference_dataframe.shape[0],res),results_dataframe.open_channels[0::res])\n    for i in range(5): plt.plot([i*batch_size,i*batch_size],[-5,12.5],'r')\n    for i in range(21): plt.plot([i*sub_sample_size, i*sub_sample_size],[-5,12.5],'r:')\n    for k in range(4): plt.text(k*batch_size + (batch_size\/2),10,str(k+1),size=20)\n    for k in range(10): plt.text(k*sub_sample_size + 40000,7.5,letters[k],size=16) # \n    plt.title('Test Data Predictions',size=16)\n    plt.show()","73edbd82":"plot_results(test, nestedcv_sub)","b9208688":"nestedcv_sub.describe()","be95a8f7":"print(nestedcv_sub.open_channels.describe())\nnestedcv_sub.open_channels.hist()","201f6915":"nestedcv_sub","2ff6e80a":"nestedcv_sub[100000:200000]","d8d307c3":"plot_results(test, kfold_sub)","eed221e3":"kfold_sub.describe()","49b603ac":"print(kfold_sub.open_channels.describe())\nkfold_sub.open_channels.hist()","af7f63af":"kfold_sub","280c45bd":"kfold_sub[100000:200000]","26e092bf":"%%time\n!rm sub*nestedcv*.csv || true\nsubmission_filename = f'submission-1-nestedcv-DecisionTree-f1-macro.csv'\nkfold_sub.to_csv(submission_filename, index=False, float_format='%0.4f')\nprint(f'Saved {submission_filename} with Macro F1 validation score of {kfold_average_f1_macro_score}')\n!ls sub*nestedcv*.csv","ef0893ec":"%%time\n!rm sub*kfold*.csv || true\nsubmission_filename = f'submission-2-kfold-DecisionTree-f1-macro.csv'\nkfold_sub.to_csv(submission_filename, index=False, float_format='%0.4f')\nprint(f'Saved {submission_filename} with Macro F1 validation score of {kfold_average_f1_macro_score}')\n!ls sub*kfold*.csv","0907058c":"## 1 Fast Open Channel","7e9cf749":"### Full credits to the author [Chris Deotte](https:\/\/www.kaggle.com\/cdeotte) of the [Original notebook](https:\/\/www.kaggle.com\/cdeotte\/one-feature-model-0-930)\n\n#### I have reorganised and refactored the code for my curiosity and learnings. Added console logs, and re-wrote datastructure to understand how the splits and batching is occuring. Also added two differentCV methods **KFold** and **NestedCV** methods, these are ideal for using with Timeseries-like problems. The focus of the changes in the notebook was to focus a bit more on the training aspects (CV methods), the original notebook covered a lot on analysis and cleaning, please refer to it for those goodies.\n\nYou can read more about **NestedCV** here:\n- https:\/\/www.elderresearch.com\/blog\/nested-cross-validation\n- https:\/\/towardsdatascience.com\/time-series-nested-cross-validation-76adba623eb9\n- https:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_nested_cross_validation_iris.html?highlight=nested%20cross%20validation\n\nEnsembling of sub-models at each fold was done using the Geometric Mean method.\n\n### Find other such refactored notebooks [here](https:\/\/www.kaggle.com\/c\/liverpool-ion-switching\/discussion\/153653).","0492ea20":"#### Saving submission results for NestedCV cross-validation","36cf8eb9":"## 3 Open Channels","51e7b9e3":"#### Ensembled models through KFold cross-validation","b61dff01":"**Note:** This channel produce low Macro F1 scores (in the ranges of`0.78nnnn`) using the configuration mentioned in the [original notebook](https:\/\/www.kaggle.com\/cdeotte\/one-feature-model-0-930). So a set of hyperparameters were tried and the one that worked best was passing in `params={'max_leaf_nodes': 255}` to the `DecisionTreeClassifier`.\n\nOther results from using different values for `max_leaf_nodes` are as below:\n```\nOriginal: max_leaf_nodes: 8 => scores: 0.78nnnnn (no folds)\nmax_leaf_nodes:     100 => oof score: 0.843581 (5 folds)\nmax_leaf_nodes:     250 => oof score: 0.871766 (5 folds)\nmax_leaf_nodes:     255 => oof score: 0.871819 (5 folds) -- best so far\nmax_leaf_nodes:     500 => oof score: 0.87133  (5 folds)\nmax_leaf_nodes:   1_000 => oof score: 0.870259 (5 folds)\nmax_leaf_nodes:   2_000 => oof score: 0.864435 (5 folds)\nmax_leaf_nodes:   4_000 => oof score: 0.861501 (5 folds)\nmax_leaf_nodes:   5_000 => oof score: 0.859787  (5 folds)\nmax_leaf_nodes:   5_000 => F1 Macro Score: 0.9025314007624331 (no folds)\nmax_leaf_nodes:  10_000 => oof score: 0.827114 (5 folds)\nmax_leaf_nodes:  10_000 => F1 Macro Score: 0.9177560091220058 (no folds)\nmax_leaf_nodes:  25_000 => oof score: 0.815225 (5 folds)\nmax_leaf_nodes:  25_000 => F1 Macro Score: 0.9435734746197743 (bit away from overfit zone) (no folds)\nmax_leaf_nodes:  50_000 => oof score: 0.78893 (5 folds)\nmax_leaf_nodes:  50_000 => F1 Macro Score: 0.9687715940722476 (nearing overfit zone) (no folds)\nmax_leaf_nodes: 100_000 => F1 Macro Score: 1.0 (fully in overfit zone) (no folds)\n```\n\nFeel free to play with this parameter to improve the scores further, although the scores seem to slowly plateau and go down past the 255-300 mark.","dcc8d7d9":"#### Example usage of the NestCV generator function","3ba42a6b":"### Ensembling sub-models using Geometric mean","de8568c5":"### Define the CV to be used for training: KFold and NestedCV","2cbd06df":"# Load Libraries and Data","55b64976":"#### _Removed cells about **Reflection**, **Correlation Between Signal and Open Channels**, Test Data, and Remove Training Data Drift, see [original notebook](https:\/\/www.kaggle.com\/cdeotte\/one-feature-model-0-930) by [Chris Deotte](https:\/\/www.kaggle.com\/cdeotte\/)._","c54f9226":"# One Feature Model Scores LB 0.930!\nIn this notebook, we will explore the Kaggle Ion Comp data and explore a one feature model. The LB result of 0.930 is enlightening.\n\nHere we manually remove signal drift. Note that it is better to use machine learning to remove drift, but doing it by hand once allows us to understand its nature and build better models later.","caa576a4":"# Description of Data\nThe training data is recordings in time. At each 10,000th of a second, the strength of the signal was recorded and the number of ion channels open was recorded. It is our task to build a model that predicts the number of open channels from signal at each time step. Furthermore we are told that the data was recorded in batches of 50 seconds. Therefore each 500,000 rows is one batch. The training data contains 10 batches and the test data contains 4 batches. Let's display the number of open channels and signal strength together for each training batch.","5656c0b6":"# Make Five Simple Models\nWe will make one model for each different type of signal we observed above.","0782754a":"### Define the Macro F1 function to be used during training","aa508553":"#### Ensembled models through KFold cross-validation","56a88f89":"Below code cells show the smaller building blocks that make up the NestedCV generator (the data structure of the output created by `generate_nested_folds_batch_ranges()` can be wrapped with `enumerate()` and used as an iterator and swapped with other CV methods i.e. `KFold`, etc...","cf30b7f2":"#### Saving submission results for KFold cross-validation","fd7b2b2f":"#### Plot results for NestedCV cross-validation","457c7f35":"## 5 Open Channels","0291219a":"#### _Removed cells about **Reflection**, **Test Data**, and **Remove Test Data Drift**, see [original notebook](https:\/\/www.kaggle.com\/cdeotte\/one-feature-model-0-930) by [Chris Deotte](https:\/\/www.kaggle.com\/cdeotte\/)._","f0189d64":"## 1 Slow Open Channel","d950694c":"#### Ensembled models through NestedCV cross-validation","4fcff312":"# Predict Test\n","a2fccd43":"## 10 Open Channels","a93289d4":"### NestedCV implementation","7a185beb":"# Display Test Predictions"}}