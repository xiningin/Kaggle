{"cell_type":{"44d57459":"code","912126b0":"code","9314f5e7":"code","02c3cbeb":"code","49509dc5":"code","db6de031":"code","5557793e":"code","c17e9bcf":"code","00930da1":"code","7829b9c1":"code","53fb2558":"code","1c9ef4ff":"code","26f299c7":"code","df6789c6":"code","782ac09d":"code","c6b42e3c":"code","a68943b0":"code","204f57fd":"code","d3b2d985":"code","8b97229e":"code","a4ac9a74":"code","f50a6a0f":"code","7a3ac71d":"code","67fb907a":"code","38ab772a":"code","636c1272":"code","68c66455":"code","a79dffda":"code","b8f92829":"code","2e58457b":"code","3718527a":"code","73d07cc7":"code","592f16c7":"code","62be1cec":"code","b467229c":"code","5e319397":"code","ffbb320f":"code","d9cb2e16":"code","5f4613c8":"markdown","8f7c07d9":"markdown","15cbe9e7":"markdown","df615ba5":"markdown","5dff0739":"markdown"},"source":{"44d57459":"print('Loading packages')\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint('These are the files to use: ',os.listdir(\"..\/input\"))\nfrom sklearn import preprocessing\nfrom statistics import mean\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport random\nfrom matplotlib import rcParams\n%matplotlib inline\nle = preprocessing.LabelEncoder()\nimport re","912126b0":"print('reading input files..')\ndata = pd.read_csv('..\/input\/train.csv')\nsampl = pd.read_csv('..\/input\/gender_submission.csv')","9314f5e7":"test  = pd.read_csv('..\/input\/test.csv')","02c3cbeb":"# Appending test data with train data, since both dataset can have related values like family name and ticket\ndf = data.append(test, sort = False)","49509dc5":"# Creating a TicketId feature, it will tell which person was part of that Family or group\nticketNum = pd.DataFrame(df.Ticket.value_counts())\nticketNum.rename(columns = {'Ticket' : 'TicketNum'}, inplace = True)\nticketNum['TicketId'] = pd.Categorical(ticketNum.index).codes\nticketNum.loc[ticketNum.TicketNum < 3, 'TicketId'] = -1\ndf = pd.merge(left = df, right = ticketNum, left_on = 'Ticket', \n              right_index = True, how = 'left', sort = False)\ndf = df.drop(['TicketNum'],axis=1)\ndf.head()","db6de031":"# Separating FamilyName\ndf['FamilyName'] = df.Name.apply(lambda x : str.split(x, ',')[0])","5557793e":"# Lets create one more feature FamilySurvival\ndf['FamilySurv'] = 0.5\nfor _, grup in df.groupby(['FamilyName','Fare']):\n    if len(grup) != 1:\n        for index, row in grup.iterrows():\n            smax = grup.drop(index).Survived.max()\n            smin = grup.drop(index).Survived.min()\n            pid = row.PassengerId\n            \n            if smax == 1:\n                df.loc[df.PassengerId == pid, 'FamilySurv'] = 1.0\n            elif smin == 0:\n                df.loc[df.PassengerId == pid, 'FamilySurv'] = 0.0\nfor _, grup in df.groupby(['Ticket']):\n    if len(grup) != 1:\n        for index, row in grup.iterrows():\n            if (row.FamilySurv == 0.0 or row.FamilySurv == 0.5):\n                smax = grup.drop(index).Survived.max()\n                smin = grup.drop(index).Survived.min()\n                pid  = row.PassengerId\n\n                if smax == 1:\n                    df.loc[df.PassengerId == pid, 'FamilySurv'] = 1.0\n                elif smin == 0:\n                    df.loc[df.PassengerId == pid, 'FamilySurv'] = 0.0\ndf.FamilySurv.value_counts()","c17e9bcf":"# CabinNum (Finding, how many cabin a person has)\ndef CabinNum(data):\n    data.Cabin = data.Cabin.fillna('0')\n    regex = re.compile('\\s*(\\w+)\\s*')\n    data['CabinNum'] = data.Cabin.apply(lambda x : len(regex.findall(x)))\nCabinNum(df)","00930da1":"df.CabinNum.value_counts()","7829b9c1":"# Creating Feature Title, since Higher Rank people has more survival chances, should give hit and trail\ndef TitleFunc(data):\n    sub = {'Col.','Rev.', 'Mr.','Sir.','Jonkheer.', 'Don.','Dona.','Capt.',\n           'General.','Major.'}\n    sub1 = {'Miss.','Mme.','Mlle.','Ms.'}\n    sub2 = {'Mrs.','Countess.','Lady.'}\n    sub3 = {'Master.'}\n    sub4 = {'Dr.'}\n    pattern, pattern1, pattern2, pattern3 = '|'.join(sub), '|'.join(sub1), '|'.join(sub2), '|'.join(sub3)\n    pattern4 = '|'.join(sub4)\n    data['Title'] = ''\n    data.loc[data['Name'].str.contains(pattern),'Title'] = 'Mr.'\n    data.loc[data['Name'].str.contains(pattern1),'Title'] = 'Miss.'\n    data.loc[data['Name'].str.contains(pattern2),'Title'] = 'Mrs.'\n    data.loc[data['Name'].str.contains(pattern3),'Title'] = 'Master.'\n    data.loc[(data['Name'].str.contains(pattern)) & (data['Age'] <=13),'Title'] = 'Master.'\n    data.loc[(data['Name'].str.contains(pattern4)) & (data['Sex'] == 'female'),'Title'] = 'Dr.f'\n    data.loc[(data['Name'].str.contains(pattern4)) & (data['Sex'] == 'male'),'Title'] = 'Dr.m'\nTitleFunc(df)","53fb2558":"#Lets see Who Survived most\ntrain1 = df[0:891].copy()\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(10,3))\nax = sns.barplot(x=\"Title\", y=\"Survived\", data=train1)\n#ax = sns.barplot(x=\"Title\", y=\"Survived\",hue='Title', data=train1)","1c9ef4ff":"# Lets first check missing fare\ndf.loc[df['Fare'].isnull()]","26f299c7":"#Let's find simlar data, and fill that for missing fare\ndf.loc[(df['Age'] >= 60) & (df['Pclass'] ==3) & (df['Sex'] == 'male') & (df['Embarked'] =='S')]","df6789c6":"# Creating FareCat Title, since High Fare people has more survival chances\ndef FareFunc(data):\n    data.loc[data['Fare'].isnull(), 'Fare'] = 7            #First fill missing fare by least value\n    data['FareCat'] = 0\n    data.loc[data['Fare'] < 8, 'FareCat'] = 0\n    data.loc[(data['Fare'] >= 8 ) & (data['Fare'] < 16),'FareCat' ] = 1\n    data.loc[(data['Fare'] >= 16) & (data['Fare'] < 30),'FareCat' ] = 2\n    data.loc[(data['Fare'] >= 30) & (data['Fare'] < 45),'FareCat' ] = 3\n    data.loc[(data['Fare'] >= 45) & (data['Fare'] < 80),'FareCat' ] = 4\n    data.loc[(data['Fare'] >= 80) & (data['Fare'] < 160),'FareCat' ] = 5\n    data.loc[(data['Fare'] >= 160) & (data['Fare'] < 270),'FareCat' ] = 6\n    data.loc[(data['Fare'] >= 270), 'FareCat'] = 7\nFareFunc(df)","782ac09d":"#Lets check which Fare class Survived along with their title\ntrain1 = df[0:891].copy()\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(14,3.5))\nax = sns.barplot(x=\"FareCat\", y=\"Survived\",hue='Title', data=train1)","c6b42e3c":"# Creating FamlSize Feature, since Very big family dint survive as per data\ndef FamlSize(data):\n    data['FamlSize'] = 0\n    data['FamlSize'] = data['SibSp'] + data['Parch'] + 1\ndef IsAlone(data):\n    data['IsAlone'] = 0\n    data.loc[(data['FamlSize'] == 1), 'IsAlone'] = 0\n    data.loc[(data['FamlSize'] > 1), 'IsAlone'] = 1\nFamlSize(df)\nIsAlone(df)","a68943b0":"df.head(3)","204f57fd":"def LablFunc(data):\n    lsr = {'Title','Cabin'}\n    for i in lsr:\n        le.fit(data[i].astype(str))\n        data[i] = le.transform(data[i].astype(str))\nLablFunc(df)","d3b2d985":"# Fill missing Age\n## Lets predict the age of a person and fill the missing Age\nfeatures = ['Pclass','SibSp','Parch','TicketId','Fare','CabinNum','Title']\nfrom sklearn.ensemble import ExtraTreesRegressor as ETRg\ndef AgeFunc(df):\n    Etr = ETRg(n_estimators = 200, random_state = 2)\n    AgeX_Train = df[features][df.Age.notnull()]\n    AgeY_Train = df['Age'][df.Age.notnull()]\n    AgeX_Test = df[features][df.Age.isnull()]\n    \n    Etr.fit(AgeX_Train,np.ravel(AgeY_Train))\n    AgePred = Etr.predict(AgeX_Test)\n    df.loc[df.Age.isnull(), 'Age'] = AgePred\n    \nAgeFunc(df)","8b97229e":"# Lets derive AgeGroup feature from age\ndef AgeCat(data):\n    data['AgeCat'] = 0\n    data.loc[(data['Age'] <= 5), 'AgeCat'] = 0\n    data.loc[(data['Age'] <= 12) & (data['Age'] > 5), 'AgeCat'] = 1\n    data.loc[(data['Age'] <= 18) & (data['Age'] > 12), 'AgeCat'] = 2\n    data.loc[(data['Age'] <= 22) & (data['Age'] > 18), 'AgeCat'] = 3\n    data.loc[(data['Age'] <= 32) & (data['Age'] > 22), 'AgeCat'] = 4\n    data.loc[(data['Age'] <= 45) & (data['Age'] > 32), 'AgeCat'] = 5\n    data.loc[(data['Age'] <= 60) & (data['Age'] > 45), 'AgeCat'] = 6\n    data.loc[(data['Age'] <= 70) & (data['Age'] > 60), 'AgeCat'] = 7\n    data.loc[(data['Age'] > 70), 'AgeCat'] = 8\nAgeCat(df)","a4ac9a74":"#Lets check which Fare class Survived along with their title\ntrain1 = df[0:891].copy()\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(14,3.5))\nax = sns.barplot(x=\"AgeCat\", y=\"Survived\",hue='Sex', data=train1)","f50a6a0f":"def AgeCatTitle(data):\n    data['AgeCatTitle'] = data['Title'].map(str) + data['AgeCat'].map(str)\n#AgeCatTitle(df)","7a3ac71d":"df.loc[df['Embarked'].isnull()]","67fb907a":"#Lets Check first from where 1st Class passesnger Came\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(12,2))\nax = sns.barplot(x=\"Embarked\", y=\"Survived\",hue='Pclass', data=df)","38ab772a":"# from 'C' high number of 1st Pclass people Survived, lets fill 'C' in missing value\ndef FillEmbk(data):\n    var = 'Embarked'\n    data.loc[(data.Embarked.isnull()),'Embarked']= 'C'\nFillEmbk(df)","636c1272":"# Label Encode Embarked\ndef LablFunc(data):\n    lst = {'Embarked','Sex'}\n    for i in lst:\n        le.fit(data[i].astype(str))\n        data[i] = le.transform(data[i].astype(str))\nLablFunc(df)","68c66455":"df.columns","a79dffda":"# Lets Scale the data now\nfrom sklearn.preprocessing import StandardScaler\ntarget = data['Survived'].values\nselect_features = ['Pclass', 'Age','AgeCat','SibSp', 'Parch', 'Fare', \n                   'Embarked', 'TicketId', 'CabinNum', 'Title','Cabin',\n                   'FareCat', 'FamlSize','FamilySurv','Sex']\nscaler = StandardScaler()\ndfScaled = scaler.fit_transform(df[select_features])\ntrain = dfScaled[0:891].copy()\ntest = dfScaled[891:].copy()","b8f92829":"# Checking best features\nfrom sklearn.feature_selection import SelectKBest, f_classif\nselector = SelectKBest(f_classif, len(select_features))\nselector.fit(train, target)\nscores = -np.log10(selector.pvalues_)\nindices = np.argsort(scores)[::-1]\n\nprint('Features importance:')\nfor i in range(len(scores)):\n    print('%.2f %s' % (scores[indices[i]], select_features[indices[i]]))","2e58457b":"#cormat = df[select_features].copy()\n#f, ax = plt.subplots(figsize=(10,8))\n#sns.heatmap(cormat, vmax=0.8, square=True)","3718527a":"#reslt = data.filter(['Survived'],axis=1)\n#train = data\n#train = train.drop(['Survived'],axis=1)","73d07cc7":"# Define Feture importance function\ndef FeatFunc(t_data,model):\n    names = t_data.columns.values\n    print(\"Features sorted by their score:\")\n    print(sorted(zip(map(lambda x: round(x, 4), model.feature_importances_), names), \n                 reverse=True))","592f16c7":"train.shape","62be1cec":"from keras import models, regularizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, BatchNormalization\nimport numpy\nnumpy.random.seed(7)\nmodel = models.Sequential()\nmodel.add(Dense(30,input_dim=15,activation='relu'))  # Adding input layer of 30 Neurons and 15 inputs\nmodel.add(Dropout(0.5))                              # Adding droupout layer to overcome overfitting\nmodel.add(Dense(15,activation='relu'))               # Adding 1 hidden layer of 15 Neurons\nmodel.add(Dropout(0.5))                              # Adding droupout layer to overcome overfitting\nmodel.add(Dense(5,activation='relu'))                # Adding 1 hidden layer of 3 Neurons\nmodel.add(Dropout(0.5))                              # Adding droupout layer to overcome overfitting\nmodel.add(Dense(1,activation='sigmoid'))             # Output layer of 1 neuron of sigmoid type\n#Compile mode\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n# Fit the model\nmodel.fit(train,target,epochs=150, batch_size=20, verbose=1)","b467229c":"prc = model.predict(train)\n# round predictions\nprc = [round(x[0]) for x in prc]\naccuracy_score(target,prc)","5e319397":"#FeatFunc(train,SrchRFC)","ffbb320f":"snum = 0\nenum = len(test)\nprdt2 = model.predict(test)      # Predicting values\nprdt2 = [round(x[0]) for x in prdt2]   # round predictions\nprdt2 = list(map(int,prdt2))\nprint('Predicted result: ', prdt2)","d9cb2e16":"sampl['Survived'] = pd.DataFrame(prdt2)\nsampl.to_csv('submission.csv', index=False)","5f4613c8":"\n****Please upvote this Kernel, if you find it useful.****\n","8f7c07d9":"If you are a begginer, you can leave this portion of creating 'FamilySurv, and come back later when start unserstanding.","15cbe9e7":"In this kernel we will be learning **simple Neural Network** model to use and **learn the Visualizations** using **matplotlib**.","df615ba5":"Oh Wow... Doctor of female category survived most and after that Mrs and after that Miss and then Master and then Male Doctors","5dff0739":"Bravo!! Mrs. Misss. and female Dr. survived even in zero fare category. However Male Survived in higher Fare category only.."}}