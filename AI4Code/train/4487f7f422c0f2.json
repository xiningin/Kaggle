{"cell_type":{"ac52b0a0":"code","f4b0e351":"code","775554fd":"code","9f5de9fb":"code","d24b3bee":"code","ba9067b1":"code","79b6ebb7":"code","243c0630":"code","691dcfff":"code","4bc73c41":"code","92a946b5":"code","bb332278":"code","5558bf71":"code","c2f1fec1":"code","777383be":"code","bd9aa214":"markdown","f2178ff6":"markdown","7d700fb3":"markdown","14091159":"markdown","6642c08b":"markdown","1945e7b1":"markdown","8291ae7f":"markdown","7591c293":"markdown","6b57cab3":"markdown","a8378c27":"markdown","989331b4":"markdown"},"source":{"ac52b0a0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","f4b0e351":"from sklearn.datasets import load_breast_cancer\ncancerdata = load_breast_cancer()\ncancerdata.keys()","775554fd":"# Lets see the description of the dataset \nprint(cancerdata['DESCR'])","9f5de9fb":"cancerdata['data'].shape # Tells number of example and features","d24b3bee":"# Creating dataframe from our data \ndf = pd.DataFrame(np.c_[cancerdata['data'],cancerdata['target']], columns = np.append(cancerdata['feature_names'],['target']))\ndf.head()","ba9067b1":"import seaborn as sns\ndistinctfeature = cancerdata['feature_names'][:10] # We know first 10 features are mean features\n#sns.pairplot(df,hue='target',vars=['mean radius','mean texture','mean perimeter','mean area','mean smoothness','mean compactness'])\nsns.pairplot(df,hue='target',vars=distinctfeature)","79b6ebb7":"plt.figure(figsize=(15,6))\nsns.heatmap(df.corr()) # Checking the correlation in the data ","243c0630":"X = df.drop(['target'],axis=1)\ny = df['target']","691dcfff":"from sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3)\nclf_svc = SVC()\nclf_svc.fit(X_train,y_train)","4bc73c41":"baseline_ypred = clf_svc.predict(X_test)\ncm = confusion_matrix(y_test,baseline_ypred)\nprint(cm)","92a946b5":"print(classification_report(y_test,baseline_ypred))","bb332278":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_trainScaled = sc.fit_transform(X_train)\nX_testScaled = sc.transform(X_test)\n\n# standard scaler X = (X - mean ) \/ StandardDeviation","5558bf71":"clf_svc.fit(X_trainScaled,y_train)\nscaled_ypred = clf_svc.predict(X_testScaled)\nprint(classification_report(y_test,scaled_ypred))\nprint(confusion_matrix(y_test,scaled_ypred))","c2f1fec1":"# Lets just change the split and rerun the test. \nXScaled = sc.transform(X)\n# using the same Xtrain y train nomenclature \nX_train,X_test,y_train,y_test = train_test_split(XScaled,y,test_size=0.4)\nclf_svc.fit(X_train,y_train)\nscaled_ypred = clf_svc.predict(X_test)\nprint(classification_report(y_test,scaled_ypred))\nprint(confusion_matrix(y_test,scaled_ypred))","777383be":"sns.heatmap(confusion_matrix(y_test,scaled_ypred), annot=True)","bd9aa214":"**Requirement translated to machine learning question **\n\nWe receive the data and based on its features we need to be able to come up with a model which could classify each example as either a cancerous or benign (harmless). We are going to use SVC for the job (Support vector classification) ","f2178ff6":"**Business Case :** \n\nOur objective is to identify whether the blood sample tumor cell, taken for test is cancerous or benign (harmless). The normal procedure starts from a path lab where doctor takes a sample of blood see it through microscope and based on the features of the cells, take a call on whether the cell is cancerous or not. ","7d700fb3":"**Proceeding to model building stage **","14091159":"We can see except few features pretty much all features are clearly separable ","6642c08b":"We can see thre are few features which are highly correlated except others, we can choose to discard them, treat them or proceed, Lets proceed without modifying the data and check how it goes.","1945e7b1":"Checkout the parameters that are passed to support vector classifier. two of the most important parameters are C, gamma, kernel and degree\n\n* C : regularization parameter (just like lambda in regression)\n* gamma : gamma controls the variation (variance) of the gaussian distribution\n* degree : for non linear classification (polynomial function)","8291ae7f":"So the Baseline model appears to be poor with accuracy of 60%, we try and improove the accuracy of the model.\n","7591c293":"<img src=\"https:\/\/image.shutterstock.com\/image-photo\/breast-cancer-core-biopsy-ductal-600w-551260165.jpg\" width=\"600px\">","6b57cab3":"Our data has total 10 distinct features, their mean standard error and worst or larfest of thest value thus total 30 features. We have 569 such image example data. We also have results whether it is cancerous or not. These are the features.\n\n       - radius (mean of distances from center to points on the perimeter)\n        - texture (standard deviation of gray-scale values)\n        - perimeter\n        - area\n        - smoothness (local variation in radius lengths)\n        - compactness (perimeter^2 \/ area - 1.0)\n        - concavity (severity of concave portions of the contour)\n        - concave points (number of concave portions of the contour)\n        - symmetry \n        - fractal dimension (\"coastline approximation\" - 1)\n        ","a8378c27":"#### Result :  \nBy just feature scaling we can obtain a model with great accuracy in classifying the breast cancer cells data in to cancerous of harmless.","989331b4":"### BAM !!! \nwhat just happend !! We signinifactly see improovement in the accuracy of the model. "}}