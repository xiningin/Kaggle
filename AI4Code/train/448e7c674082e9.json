{"cell_type":{"a8af4058":"code","c194fdff":"code","36041b8c":"code","e6d112b5":"code","a6398901":"code","0fdd9609":"code","52ad87c6":"code","4576cdb9":"code","20265763":"code","f8c6c757":"code","c3e0f210":"code","2ad28caa":"code","5b48b897":"code","a39746dd":"code","060c30a5":"code","842856e9":"code","2e47ca95":"code","c6f7d621":"code","cac0738d":"code","16250b86":"code","4dfee8e7":"code","e9058dd6":"code","c1475864":"code","1a0363ae":"code","36840356":"code","bf6868ff":"code","82337091":"code","882707a3":"markdown","4de2a065":"markdown","764a3af2":"markdown","9ebae45e":"markdown","094b9313":"markdown","ae6e791d":"markdown","472894ef":"markdown"},"source":{"a8af4058":"import warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')","c194fdff":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style='darkgrid')","36041b8c":"from sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_iris\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics","e6d112b5":"iris=load_iris()\ndata=pd.DataFrame(iris.data,columns=iris.feature_names)\ndata['species']=iris.target\ndata.head()","a6398901":"#getting to know missing values\nimport missingno as mn\nmn.matrix(data)","0fdd9609":"data.columns","52ad87c6":"plt.figure()\nfig,ax=plt.subplots(2,2,figsize=(15,6))\n\n\nsns.distplot(data['sepal length (cm)'],ax=ax[0][0],hist=True,kde=True,\n            bins='auto',color='darkblue',\n            hist_kws={'edgecolor':'black'},\n            kde_kws={'linewidth':4})\nsns.distplot(data['sepal width (cm)'],ax=ax[0][1],hist=True,kde=True,\n            bins='auto',color='darkblue',\n            hist_kws={'edgecolor':'black'},\n            kde_kws={'linewidth':4})\nsns.distplot(data['petal length (cm)'],ax=ax[1][0],hist=True,kde=True,\n            bins='auto',color='darkblue',\n            hist_kws={'edgecolor':'black'},\n            kde_kws={'linewidth':4})\nsns.distplot(data['petal width (cm)'],ax=ax[1][1],hist=True,kde=True,\n            bins='auto',color='darkblue',\n            hist_kws={'edgecolor':'black'},\n            kde_kws={'linewidth':4})","4576cdb9":"formatter=plt.FuncFormatter(lambda i,*args: iris.target_names[int(i)])\nplt.figure(figsize=(15,8))\nplt.scatter(np.array(data.iloc[:,0]),np.array(data.iloc[:,1]),c=data.species)\nplt.colorbar(ticks=[0,1,2],format=formatter)\nplt.xlabel('Sepal Length (cm)')\nplt.ylabel('Sepal Width (cm)')\nplt.show()","20265763":"X=data.iloc[:,0:4].values\ny=data.iloc[:,4].values","f8c6c757":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=4)\nX_train.shape,X_test.shape,y_train.shape,y_test.shape","c3e0f210":"from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\npipeline=make_pipeline(StandardScaler(),DecisionTreeClassifier(criterion='entropy',max_depth=4))","2ad28caa":"pipeline.fit(X_train,y_train)","5b48b897":"pipeline.score(X_train,y_train),pipeline.score(X_test,y_test)","a39746dd":"pipeline=make_pipeline(StandardScaler(),DecisionTreeClassifier(criterion='entropy',max_depth=4))","060c30a5":"from sklearn.ensemble import BaggingClassifier\nbgclf=BaggingClassifier(base_estimator=pipeline,n_estimators=100,max_samples=10,random_state=1,n_jobs=5)","842856e9":"bgclf.fit(X_train,y_train)","2e47ca95":"bgclf.score(X_train,y_train),bgclf.score(X_test,y_test)","c6f7d621":"y_train_pred=bgclf.predict(X_train)\ny_test_pred=bgclf.predict(X_test)\ny_test_pred","cac0738d":"cm_train=metrics.confusion_matrix(y_train_pred,y_train)\nprint(cm_train)\nsns.heatmap(cm_train,annot=True)","16250b86":"cm_test=metrics.confusion_matrix(y_test_pred,y_test)\nprint(cm_test)\nsns.heatmap(cm_test,annot=True,cmap='Blues')","4dfee8e7":"metrics.accuracy_score(y_test_pred,y_test)","e9058dd6":"import graphviz","c1475864":"!pip install pydotplus","1a0363ae":"import pydotplus\nfrom IPython.display import Image","36840356":"clf=DecisionTreeClassifier(min_samples_leaf=20,max_depth=5)\nclf.fit(X_train,y_train)\nfrom sklearn import tree\ndot_data=tree.export_graphviz(clf,out_file=None,feature_names=iris.feature_names,filled=True)","bf6868ff":"graph=pydotplus.graph_from_dot_data(dot_data)\nImage(graph.create_png())","82337091":"clftree2=DecisionTreeClassifier(min_samples_leaf=20,max_depth=5)\nclftree2.fit(X_train,y_train)\ndot_data=tree.export_graphviz(clftree2,out_file=None,feature_names=iris.feature_names,filled=True)\ngraph=pydotplus.graph_from_dot_data(dot_data)\nImage(graph.create_png())","882707a3":"### Now, we can intro our Bagging Classifier","4de2a065":"## Controlling Tree Growth","764a3af2":"Here you see,\nWe can't speak like our model is trained with high accuracy, indeed it is an overfitting which cannot do well with test_data.","9ebae45e":"## Facing off, Decision Tree Algorithm","094b9313":"### Evaluation","ae6e791d":"## Cheers!!!\n## Then, Plotting our Pretty Decision Tree","472894ef":"# Bagging Classifier\n\nBagging Classifier is an ensemble method, that helps in reducing the variance of individual estimators by introducing randomisation into the training stage of each of the estimators and making an ensemble out of all the estimators.<br>\n***\nIt simply, takes all the predictions from different estimators and gives final predictions<br>\nFor training mulitple estimators, it uses different sampling techniques like **Pasting,Bagging\/Bootstrap aggregation,Random subspaces and Random patches**<br>\n\nMostly, this Classifier is used on high variance classifiers like **Decision Tree**."}}