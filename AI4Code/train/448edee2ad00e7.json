{"cell_type":{"d2f9d4f8":"code","7d91705f":"code","8987a6d4":"code","b33c9dce":"code","6def94b7":"code","ab898bad":"code","23c8d2a1":"code","01cf9755":"code","89cf5708":"code","4b106810":"code","7475edee":"code","6c767e24":"code","996eb737":"code","47fb3cec":"code","833efc06":"code","9650fd5b":"code","21354460":"code","b0144dd3":"markdown","a867fdef":"markdown","5e61a1e4":"markdown","d1bb2c27":"markdown","fb34db40":"markdown","5be4bd2a":"markdown","2f106bcd":"markdown"},"source":{"d2f9d4f8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","7d91705f":"train_dir = '..\/input\/10-monkey-species\/training\/training\/'\nval_dir = '..\/input\/10-monkey-species\/validation\/validation\/'","8987a6d4":"\n\nlabels = pd.read_csv(\"..\/input\/10-monkey-species\/monkey_labels.txt\")\nnum_classes = labels['Label'].size\nlabels","b33c9dce":"# for display images in notebook\nfrom IPython.display import Image, display\n\nfrom os import listdir\n%matplotlib inline","6def94b7":"IMAGE_WIDTH = 150\nIMAGE_HEIGHT = 150\nBATCH_SIZE = 24","ab898bad":"from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras.applications.inception_v3 import preprocess_input\n\n\n## use inception's own preprocess function\ntrain_data_gen_aug=ImageDataGenerator(\n                              preprocessing_function=preprocess_input,\n                              rotation_range=20,\n                              width_shift_range=0.2,\n                              height_shift_range=0.2,\n#                               shear_range=0.2,\n#                               horizontal_flip=True,\n#                               fill_mode='nearest' # default is nearest\n                             )\n\nvalidation_data_gen=ImageDataGenerator(\n                                       preprocessing_function=preprocess_input\n                                      )\n","23c8d2a1":"train_gen=train_data_gen_aug.flow_from_directory(train_dir,\n                                            target_size=(IMAGE_WIDTH,\n                                                       IMAGE_HEIGHT),\n                                            batch_size=BATCH_SIZE,\n                                            shuffle=True,\n                                            class_mode=\"categorical\")\nval_gen = validation_data_gen.flow_from_directory(val_dir, \n                                                    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT), \n                                                    batch_size = BATCH_SIZE, \n                                                    class_mode=\"categorical\")","01cf9755":"train_count=1097\nval_count=272\nsteps_per_epoch=train_count\/\/BATCH_SIZE\nsteps_per_epoch","89cf5708":"from keras.applications import InceptionV3\nfrom keras.models import Sequential\nfrom keras.layers import Dense, GlobalAveragePooling2D, Dropout\n\n# set  up the model\nmodel=Sequential()\n# add inception pretrained model, the wieghts 80Mb\nmodel.add(InceptionV3(include_top=False, \n                      pooling='avg', \n                      weights='..\/input\/inceptionv3\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n                     ))\n# use relu as activation function \"vanishing gradiends\" :)\n# model.add(Dense(2048, activation=\"relu\"))  \n# # add drop out to avoid overfitting\n# model.add(Dropout(0.25))\nmodel.add(Dense(num_classes, activation=\"softmax\"))","4b106810":"# we should keep trainable layers as less than possible to speed up\n# for layer in model.layers[0].layers:\n#     layer.trainable= False\n       \n    \nmodel.layers[0].trainable=False","7475edee":"# for layer in model.layers[0].layers:\n#     print(layer, layer.trainable)","6c767e24":"model.summary()","996eb737":"\nfrom keras import optimizers\nadam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.00001)\n# use adam to avoid overfitting\n\nmodel.compile(loss=\"categorical_crossentropy\",\n              optimizer=adam,\n              metrics=[\"accuracy\"])\n","47fb3cec":"model_history = model.fit_generator(train_gen,\n                                    steps_per_epoch=steps_per_epoch,\n                                    epochs=48,\n                                    validation_data=val_gen,\n                                    validation_steps=val_count \/\/ BATCH_SIZE\n                                   )\n","833efc06":"model.save('incept_adv.h5') ","9650fd5b":"import pandas as pd\nhistory = pd.DataFrame()\nhistory[\"acc\"] = model_history.history[\"acc\"]\nhistory[\"val_acc\"] = model_history.history[\"val_acc\"]\nhistory.plot(figsize=(12, 6))","21354460":"acc = model_history.history['acc']\nval_acc = model_history.history['val_acc']\nloss = model_history.history['loss']\nval_loss = model_history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n\nimport matplotlib.pyplot as plt\n\nplt.title('Training and validation accuracy')\nplt.plot(epochs, acc, 'red', label='Training acc')\nplt.plot(epochs, val_acc, 'blue', label='Validation acc')\nplt.legend()\n\nplt.figure()\nplt.title('Training and validation loss')\nplt.plot(epochs, loss, 'red', label='Training loss')\nplt.plot(epochs, val_loss, 'blue', label='Validation loss')\n\nplt.legend()\n\nplt.show()","b0144dd3":"# Show the results","a867fdef":"# Compile then Fit the model","5e61a1e4":"## Set up Model","d1bb2c27":"**Credits:**\n1. Dan Becker https:\/\/www.kaggle.com\/learn\n2. Juan https:\/\/www.kaggle.com\/moriano\/monkey-species-transfer-learning-95-6-accuracy\n3. Dan Rusei https:\/\/www.kaggle.com\/danrusei\/10-monkey-keras-transfer-learning-resnet50","fb34db40":"# Data Augmetation","5be4bd2a":"# About\nThis is a deep learning kernel to use Inception v3 pretrained model to train the classificators for monkeys. \n- keras\n- tensorflow\n- inception v3\n\nIt is also my assignment for machine learning paper at uni.\n\n\n","2f106bcd":"# Preparation\n"}}