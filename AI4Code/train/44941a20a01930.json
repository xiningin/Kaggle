{"cell_type":{"87f7965d":"code","aa2a616a":"code","b354137d":"code","5e6726de":"code","b8d4e236":"code","3e8f7921":"code","e18e66ba":"code","ccf1fa51":"code","204061d1":"code","0f21dc3e":"code","315c26fc":"code","ab90e86d":"code","7ca52f1b":"code","7308b44b":"code","36c2c5d9":"code","f152835f":"code","9c8784fd":"markdown","df62cd06":"markdown","2e91ed69":"markdown","d3f1d162":"markdown","907e51af":"markdown","b3f4905f":"markdown"},"source":{"87f7965d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aa2a616a":"# Importing important modules for predicting\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","b354137d":"#loading datasets\ndf1=pd.read_csv(\"..\/input\/heart-attack-analysis-prediction-dataset\/heart.csv\")\ndf2=pd.read_csv(\"..\/input\/heart-attack-analysis-prediction-dataset\/o2Saturation.csv\")","5e6726de":"# Viewing dataset\ndf1.head(5)","b8d4e236":"#Here since second document had only one column we took mean of it so as to get the average o2 levels for aa normal human.\ndf2.mean()","3e8f7921":"# checking whether the data has any missing values.\ndf1.isnull().sum()","e18e66ba":"# oh god , luckily there are none  ","ccf1fa51":"# Now we check whether the dataset is balanced or not\noutput_with_1=round(len(df1[df1['output']==1]['output'])\/len(df1['output']),3)\noutput_with_0=round(len(df1[df1['output']==0]['output'])\/len(df1['output']),3)\nprint(output_with_1,output_with_0)","204061d1":"# Plotting a histogram of people who had heart attack.\nplt.figure(figsize=(7,7))\ndf1[df1['output']==1]['age'].hist(bins=30,color='red',label='output=1',alpha=0.6)\nplt.legend()","0f21dc3e":"plt.figure(figsize=(7,7))\nsns.countplot(x='output',data=df1,hue='sex')","315c26fc":"plt.figure(figsize=(7,7))\nplt.scatter(df1['age'],df1['chol'],c=df1['sex'],cmap='coolwarm')","ab90e86d":"# splitting output from other features\nx=df1.drop('output',axis=1)\ny=df1['output']","7ca52f1b":"# train test split\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)","7308b44b":"# to have classification report and confusion matrix\nfrom sklearn.metrics import confusion_matrix,classification_report","36c2c5d9":"from sklearn.linear_model import LogisticRegression as LR\nlr=LR()\nlr.fit(x_train,y_train)","f152835f":"predictions_lr=lr.predict(x_test)\nprint(classification_report(y_test,predictions_lr))","9c8784fd":" From this we interpret that people mostly btw age of 50-65 are more prone to having one than others","df62cd06":"Now we start modelling , since we have binary outputs so a logistic regression is suitable for this dataset","2e91ed69":"Here we interpret that people have higher tendencies of getting heart attack if they have high cholestrol lvl and are leaning towards the age of 60.","d3f1d162":"Here we interpret that assuing for a normal heart this model will predict with an accuracy of 89 percent.","907e51af":"Here from the countplot we get that gender 0 is more prone to having a heart attack than 1 ","b3f4905f":"Here we see that the dataset is balanced hence accuracy is a good measure to calculate the predictability of the model"}}