{"cell_type":{"2550a5d1":"code","a23c65ee":"code","3701d964":"code","cac482be":"code","f6d36828":"code","b96b9615":"code","bcc19a1f":"code","5ad982e1":"code","253ac41a":"code","5b65c6b0":"code","3649eb8f":"code","158b9e76":"code","ec0da651":"code","b144c5af":"code","d0ddebe7":"code","c8082943":"code","370a798f":"code","3521a9b5":"code","70d21871":"code","91a5bf01":"code","12d29288":"markdown","1c7efb24":"markdown"},"source":{"2550a5d1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a23c65ee":"import numpy as np \nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.linear_model import LinearRegression","3701d964":"data = pd.read_csv('..\/input\/climate-change\/climate_change.csv')","cac482be":"data","f6d36828":"data.info()","b96b9615":"data.isna().sum()","bcc19a1f":"plt.scatter(data['CO2'], data['Temp'])","5ad982e1":"plt.bar(data['Year'], data['Temp'])","253ac41a":"plt.bar(data['Year'],data['Aerosols'])","5b65c6b0":"plt.bar(data['Year'],data['CO2'])","3649eb8f":"data.describe()","158b9e76":"data.corr()","ec0da651":"data.drop('Month', axis=1,inplace=True)","b144c5af":"def model(m):\n    np.random.seed(0)\n    x = data.drop('CO2', axis=1)\n    y = data['CO2']\n    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n    clf = m\n    clf.fit(x_train, y_train)\n    s = clf.score(x_test,y_test)\n    return s","d0ddebe7":"model(RandomForestRegressor())","c8082943":"model(LinearRegression())","370a798f":"np.random.seed(45)\nx = data.drop('CO2', axis=1)\ny = data['CO2']\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\nclf = LinearRegression()\nclf.fit(x_train, y_train)\nclf.score(x_test,y_test)","3521a9b5":"y_preds = clf.predict(x_test)\nmean_absolute_error(y_test, y_preds)","70d21871":"grid={'n_estimators': [10,100,200,500,1000,1200], \n      'max_depth':[None, 5, 10, 20, 30], \n      'max_features':[0.5, 0.2, 'auto', 'sqrt'],\n      'min_samples_split':[2,4,6],\n      'min_samples_leaf':[1,2,4]}\nnp.random.seed(45)\nx = data.drop('CO2', axis=1)\ny = data['CO2']\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\nclf = RandomForestRegressor()\nrs_clf = RandomizedSearchCV(estimator=clf,\n                            param_distributions=grid,\n                            n_iter=50, \n                            cv=5,\n                            verbose=2)\nrs_clf.fit(x_train, y_train)\nrs_clf.score(x_test,y_test)","91a5bf01":"y_preds2 = rs_clf.predict(x_test)\nmean_absolute_error(y_test, y_preds2)","12d29288":"# linear regression is better","1c7efb24":"# Predicting CO2 level"}}