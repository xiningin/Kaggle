{"cell_type":{"5c2cece7":"code","d18cf02d":"code","0f0d34a9":"code","0480038b":"code","52a40b73":"code","4e6c3f9a":"code","48aeb15a":"code","378ae7cb":"code","07e50354":"code","ec8d931c":"code","3e16f476":"code","da5d5cfb":"code","98531c28":"code","11aab31b":"code","89864a97":"markdown"},"source":{"5c2cece7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom skimage.io import imshow\nfrom pathlib import Path\nimport pandas as pd\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","d18cf02d":"dataset_root = Path('..\/input\/mura\/MURA-v1.1')","0f0d34a9":"list(dataset_root.iterdir())","0480038b":"df = pd.read_csv(dataset_root\/'train_image_paths.csv', header=None, names=['filename'])\ndf.head()","52a40b73":"df['class'] = (df.filename\n               .str.extract('study.*_(positive|negative)'))\ndf.head()","4e6c3f9a":"def generate_df(dataset_root, csv_name):\n    df = pd.read_csv(dataset_root\/csv_name, header=None, names=['filename'])\n    df['class'] = (df.filename\n               .str.extract('study.*_(positive|negative)'))\n    return df","48aeb15a":"list(dataset_root.parent.iterdir())","378ae7cb":"datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1. \/ 255)\n\ntrain_gen = datagen.flow_from_dataframe(generate_df(dataset_root, 'train_image_paths.csv'),\n                                        directory=dataset_root.parent,\n                                        target_size=(512, 512),\n                                        class_mode='binary')\nvalid_gen = datagen.flow_from_dataframe(generate_df(dataset_root, 'valid_image_paths.csv'),\n                                        directory=dataset_root.parent,\n                                        target_size=(512, 512),\n                                        class_mode='binary')","07e50354":"densenet = tf.keras.applications.DenseNet169(weights='imagenet', include_top = False, input_shape=(512, 512, 3))","ec8d931c":"densenet.trainable = False","3e16f476":"model = tf.keras.models.Sequential([\n    densenet,\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])","da5d5cfb":"lr_scheduler = ReduceLROnPlateau(monitor='accuracy', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)","98531c28":"model.compile(loss=tf.keras.losses.binary_crossentropy,\n              optimizer=tf.keras.optimizers.Adam(),\n              metrics=['accuracy'])","11aab31b":"model.fit_generator(train_gen, \n                    epochs=100, \n                    validation_data=valid_gen, \n                    use_multiprocessing=True, \n                    callbacks=[lr_scheduler])","89864a97":"Since the dataset images are all very rectangular and not even close to being a square, we really need to be careful about how the images are resized. What could happen \n\nHowever, for the first draft of the training pipeline, I will just be lazy and use the default resizing method provided by Keras."}}