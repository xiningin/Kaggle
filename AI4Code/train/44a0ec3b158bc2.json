{"cell_type":{"72b6dfda":"code","b0ab1a41":"code","b638be15":"code","3309e926":"code","02265368":"code","2ca98501":"code","3f46b122":"code","2bb40a03":"code","b5e5029f":"code","9cb97a79":"code","849e78f4":"code","c962ccff":"code","39f31df6":"code","bb1d08a3":"code","512c7c5b":"code","13172bca":"code","b34e3530":"code","fe085add":"code","41d27c72":"code","59b667f9":"code","c421a9fa":"code","3af95732":"code","4ba2c162":"code","c8c02ea1":"code","50b55535":"code","e64bed01":"code","e8f61ed6":"code","35118330":"code","14cab902":"code","9a1017bd":"code","5fff57f9":"code","0d4fcd4b":"code","39f019cf":"code","7c89239a":"code","452ca047":"code","5e4e6db2":"code","43997e58":"code","3b99d445":"code","5bc2f481":"code","d948b9ac":"code","7ea06f54":"code","0a59dd8b":"code","fb75e136":"code","f732d894":"code","1ffbc261":"code","3a34db98":"code","d30f6a5d":"code","e6b4f2e5":"code","c9980adf":"code","68185c7e":"code","61f3020e":"code","6e49c5ce":"code","6d427ea3":"code","5fd3f67b":"code","c6dcf041":"code","88cae16f":"code","85d156ab":"code","570cb275":"code","be100ec0":"code","b547f7e1":"code","2cc8041e":"code","159be209":"code","dc1e01ae":"code","990e60dd":"markdown","a6085351":"markdown","e21e38d7":"markdown","fa5a50c0":"markdown","ac310e2b":"markdown","4cf2c864":"markdown","9287249f":"markdown","8893a19d":"markdown","50046b20":"markdown","dd769a78":"markdown","ac45f85b":"markdown","2e10654a":"markdown","6c9a5b3c":"markdown","2e0dd0b7":"markdown","e35be5e7":"markdown","69249ff0":"markdown","8c8dbc2c":"markdown","b501482d":"markdown","c6639ca0":"markdown","ae1b9cca":"markdown","a5aade5d":"markdown","1483f463":"markdown","77fd2307":"markdown","f65dfaa1":"markdown","b609d9f0":"markdown","c1ab71b4":"markdown","604dd702":"markdown","81a25600":"markdown","f7398675":"markdown","2915629c":"markdown","f94795ed":"markdown","bd4b48e9":"markdown","bcd08edb":"markdown","9f5ad40d":"markdown","7b4b171b":"markdown","565363a7":"markdown","8e38fa3f":"markdown","f0518946":"markdown","9ce2b7fa":"markdown","dcea7f9f":"markdown","40dd7c4f":"markdown","3702c0a1":"markdown","bbb528bf":"markdown"},"source":{"72b6dfda":"import pandas as pd\npd.set_option('display.max_colwidth',None)\nimport numpy as np\nnp.random.seed(27)\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\ncolours = plt.rcParams['axes.prop_cycle'].by_key()['color']\n%matplotlib inline\nimport seaborn as sns\nsns.color_palette('muted')\nsns_colours = sns.color_palette()\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom scipy.stats import kstest,boxcox,skew\nfrom collections import defaultdict\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression, Lasso\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\nimport xgboost as xgb\n\n\nfrom mlxtend.plotting import heatmap, plot_learning_curves\nfrom mlxtend.regressor import StackingRegressor","b0ab1a41":"# Import data. We know there is a date column so we will set it to be converted to datetime format\ndata = pd.read_csv('..\/input\/new-york-city-airbnb-open-data\/AB_NYC_2019.csv', parse_dates = ['last_review'])","b638be15":"data.info()","3309e926":"data.describe().T","02265368":"# Explicitly show the number of NaNs in each column, if any\ndef nan_count(df):\n    for col in df:\n        nans = df[col].isna().sum()\n        if nans>0:\n            print(f'{col} contains {nans} NaNs')\n\nnan_count(data)","2ca98501":"# Inspect missing name and host name entries for concurrence\nmissing_names = set(data[data['name'].isna()]['id'])\nmissing_hosts = set(data[data['host_name'].isna()]['id'])\nmissing_names.intersection(missing_hosts)","3f46b122":"# Inspect missing review entries for concurrence\nmissing_last_rev = set(data[data['last_review'].isna()]['id'])\nmissing_rpm = set(data[data['reviews_per_month'].isna()]['id'])\nlen(missing_last_rev.intersection(missing_rpm))","2bb40a03":"# Fill missing values and drop ID column\ndata['name'].fillna('Information Missing',inplace=True)\ndata['host_name'].fillna('None',inplace=True)\ndata['reviews_per_month'].fillna(0,inplace=True)\ncleaned_data = data.drop(['id','host_name'],axis=1)","b5e5029f":"# Reinspect dataframe information\ncleaned_data.info()","9cb97a79":"X_train, X_test, y_train, y_test = train_test_split(cleaned_data.drop(['price'],axis=1),cleaned_data['price'],\\\n                                                    test_size=0.1, random_state = 27)\n\n# Recombine training data\ntrain_df = pd.concat([X_train,y_train],axis=1)\nprint(f'Training data dimensions: {train_df.shape}')\ndisplay(train_df.sample())","849e78f4":"_ = train_df['price'].hist(bins=500)\n_ = plt.title('New York Airbnb Room Prices')\n_ = plt.xlabel('Room Price $')\n\nprint(f'The skewness of the room price is {np.round(train_df[\"price\"].skew(),2)}')","c962ccff":"print(f'There are {len(train_df[train_df[\"price\"]==0])} listings with a price of $0\\n')\ndisplay(train_df[train_df[\"price\"]==0])","39f31df6":"# Drop listings with a price of 0\ntrain_df.drop(train_df[train_df['price']==0].index,inplace=True)\nX_test.drop(y_test[y_test==0].index,inplace=True)\ny_test.drop(y_test[y_test==0].index,inplace=True)","bb1d08a3":"# Create rugplot to see spread of listings\nfig = plt.figure(figsize=(12,2))\n_ = sns.rugplot(train_df['price'])\n_ = plt.title('Rugplot of New York Airbnb Room Prices')\n_ = plt.xlabel('Room Price $')","512c7c5b":"high_prices = train_df.nlargest(10,'price')\ndisplay(high_prices)\n\nprices = [500,1000,2000,3000,4000,5000]\nfor price in prices:\n    perc = round(sum((train_df['price']>price)\/len(train_df)),4)*100\n    print(f'{perc:.2f}% of listings cost more than ${price}')","13172bca":"# Split out properties over $1000\nhigh_price_lists = train_df.drop(train_df[train_df['price']<1000].index)\n\n# Remove high price properties from other datasets\ntrain_df.drop(train_df[train_df['price']>=1000].index,inplace=True)\nX_test.drop(y_test[y_test>=1000].index,inplace=True)\ny_test.drop(y_test[y_test>=1000].index,inplace=True)","b34e3530":"# Graphical analysis of listing prices >$1000\npic = plt.imread('..\/input\/new-york-city-airbnb-open-data\/New_York_City_.png',0)\nfig = plt.figure(figsize=(20,16))\nfig.suptitle('New York Airbnb Listings >$1000',fontsize=16,y=0.9)\nax1 = plt.subplot2grid((2,3),(0,0),rowspan=2,colspan=2)\n_ = plt.imshow(pic,extent = [min(data['longitude']),max(data['longitude'])\\\n                             ,min(data['latitude']),max(data['latitude'])])\n\n# Add subplot for scatterplot with same axis extents as underlying image\n_ = ax1.axis([min(data['longitude']),max(data['longitude']),min(data['latitude']),max(data['latitude'])])\n_ = sns.scatterplot(x='longitude',y='latitude',data=high_price_lists,hue='price',palette='coolwarm')\n_ = ax1.legend().texts[0].set_text('Price $')\n\nax2 = plt.subplot2grid((2,3),(0,2))\n_ = sns.barplot(y=high_price_lists['neighbourhood_group'].value_counts().index,\\\n                x = high_price_lists['neighbourhood_group'].value_counts(),ax=ax2,orient='h')\n_ = ax2.set_title('Neighbourhood')\n_ = ax2.set_xlabel('Number of Listings')\n_ = ax2.tick_params(axis='y',rotation=45)\n\nax3 = plt.subplot2grid((2,3),(1,2))\n_ = sns.barplot(y = high_price_lists['room_type'].value_counts().index,\n               x = high_price_lists['room_type'].value_counts(),ax=ax3,orient='h')\n_ = ax3.set_title('Room Type')\n_ = ax3.set_xlabel('Number of Listings')\n_ = ax3.tick_params(axis='y',rotation=45)","fe085add":"fig,ax = plt.subplots(1,3,figsize=(18,8))\n_ = train_df.hist(column = 'calculated_host_listings_count',bins=327,color = colours[1],alpha=0.8,ax=ax[0])\n_ = ax[0].set_title('Histogram of Listings Per Host')\n_ = ax[0].set_xlabel('Listings Per Host')\n_ = ax[0].set_ylabel('Count of Listings')\n\n_ = train_df.hist(column='calculated_host_listings_count',bins = 323,color = colours[0],alpha = 0.8,ax=ax[1],cumulative=True)\n_ = ax[1].set_title('Cumulative Sum of Listings')\n_ = ax[1].set_xlabel('Listings Per Host')\n_ = ax[1].set_ylabel('Cumulative Listings')\n\n_ = train_df[train_df['calculated_host_listings_count']>10].hist(\n            column='calculated_host_listings_count',bins = 94,color = colours[2],alpha=0.8,ax=ax[2])\n_ = ax[2].set_title('Listings > 10')\n_ = ax[2].set_xlabel('Listings Per Host')\n_ = ax[2].set_ylabel('Count of Listings')","41d27c72":"print(f'The mean number of listings per host is {np.floor(train_df[\"calculated_host_listings_count\"].mean())}')\nprint(f'The median number of listings per host is {np.floor(train_df[\"calculated_host_listings_count\"].median())}')\nprint(f'The modal number of listings per host is {np.floor(train_df[\"calculated_host_listings_count\"].mode()[0])}')\nprint(f'''\\nThe modal number of listings accounts for \\\n{round(len(train_df[train_df['calculated_host_listings_count']==1])\/len(train_df),2)*100}% of all listings''')","59b667f9":"# Look at the average price by the number of listings per host\nprice_by_number_of_listings = train_df.groupby('calculated_host_listings_count').agg({'price':['mean','median']})\nprice_by_number_of_listings.rename_axis('Listings Per Host',inplace=True)\nprice_by_number_of_listings.rename(columns={'mean':'Mean Price','median':'Median Price'},inplace=True)\nprice_by_number_of_listings.columns = price_by_number_of_listings.columns.droplevel() # Drop top level column index \"price\"\n\n\nfig, ax = plt.subplots(2,1,figsize=(16,8))\n_ = plt.suptitle('Mean and Median Room Price by Number of Host Listings',fontsize='14',y=0.93)\n_ = sns.barplot(x=price_by_number_of_listings.index,y=price_by_number_of_listings['Mean Price'],ax=ax[0])\n_ = ax[0].set_ylabel('Mean Room Price ($)')\n_ = sns.barplot(x=price_by_number_of_listings.index, y=price_by_number_of_listings['Median Price'],ax=ax[1])\n_ = ax[1].set_ylabel('Median Room Price ($)')","c421a9fa":"listing_numbers = [11,12,49]\nfig, ax = plt.subplots(1,3,figsize=(12,8),sharex=True,sharey=True)\n_ = plt.suptitle('Boxplot of Room Prices for Hosts with 11, 12 and 49 Listings Each',y=0.93,fontsize='14')\nfor ind,listing in enumerate(listing_numbers):\n    print(f'''There are {len(train_df[train_df[\"calculated_host_listings_count\"]==listing].groupby(\"host_id\"))}\\\n different hosts with {listing} listings each''')\n    _ = sns.boxplot(train_df[train_df[\"calculated_host_listings_count\"]==listing]['price'],labels=[''],ax=ax[ind],orient='v',\\\n                   color=sns_colours[ind])\n    _ = ax[ind].set_xlabel(f'{listing} listings per host')\n    _ = ax[ind].set_ylabel(\"\")\n_ = ax[0].set_ylabel('Room Price ($)')","3af95732":"print(f'There are {len(set(train_df[\"neighbourhood\"]))} unique neighbourhoods in the data set')\nprint(f'There are {len(set(train_df[\"neighbourhood_group\"]))} unique neighbourhood groups in the data set')","4ba2c162":"# Create dataframe of number of listings per neighbourhood\n\nneighbourhoods = train_df.groupby('neighbourhood').agg({'neighbourhood':'count'})\nneighbourhoods.rename(columns={'neighbourhood':'Count'},inplace=True)\nneighbourhoods = neighbourhoods.sort_values(by='Count',ascending=False)","c8c02ea1":"# Plot cumulative distribution of listings across neighbourhoods and number of listings in top 5 neighbourhoods\nfig,ax = plt.subplots(1,2,figsize=(16,6))\n\ny = np.arange(len(neighbourhoods['Count']))\/len(neighbourhoods['Count'])\nx = np.sort(neighbourhoods['Count'])\n_ = ax[0].plot(x,y,marker='.',color = sns_colours[1],linestyle='none',alpha = 0.8)\n_ = ax[0].set_title(\"Empirical CDF of Listings per Neighbourhood\")\n_ = ax[0].set_xlabel(\"Number of Listings per Neighbourhood\")\n_ = ax[0].set_ylabel(\"ECDF\")\n\n_ = sns.barplot(x = neighbourhoods.index[:5],y = neighbourhoods['Count'][:5],ax=ax[1]).set_title('Number of Listings in Top 5 Neighbourhoods')\n_ = ax[1].set_ylabel('Number of Listings')\n_ = ax[1].set_xlabel('')\n_ = ax[1].tick_params(axis='x',labelrotation=-15)\n\nprint(f'The mean number of listings per neighbourhood is {np.floor(neighbourhoods[\"Count\"].mean())}')\nprint(f'The median number of listings per neighbourhood is {neighbourhoods[\"Count\"].median()}\\n')","50b55535":"# Create underlying image using map of new york\npic = plt.imread('..\/input\/new-york-city-airbnb-open-data\/New_York_City_.png',0)\nfig,ax = plt.subplots(1,figsize=(14,14))\n\n# Set extends to correspond to coordinate system\n_ = plt.imshow(pic,extent = [min(data['longitude']),max(data['longitude']),min(data['latitude']),max(data['latitude'])])\n\n# Add subplot for scatterplot with same axis extents as underlying image\n_ = ax.axis([min(data['longitude']),max(data['longitude']),min(data['latitude']),max(data['latitude'])])\n\n# Create colourmap that doesn't have grey in it\ncolrs = ['lightcoral','goldenrod','yellowgreen','steelblue','mediumpurple']\n\n_ = sns.scatterplot(x = 'longitude',y = 'latitude',hue = 'neighbourhood_group',data = train_df,\\\n                   alpha = 0.7, palette = colrs)\n_ = ax.legend().texts[0].set_text('Neighbourhood Area')","e64bed01":"# Create dataframe of rooms in each neighbourhood group\nrooms_in_ngroup = train_df.groupby('neighbourhood_group').agg({'name':'count'})\n\n# Create data frame without highest price rooms for plotting\nprice_less_500 = train_df[train_df['price']<500].sort_values(by='neighbourhood_group')\n\nfig, ax = plt.subplots(1,2,figsize=(12,6))\n_ = sns.barplot(x=rooms_in_ngroup.index,y=rooms_in_ngroup['name'],ax=ax[0],orient='v')\n_ = plt.suptitle('Analysis of Room Information in Different Neighbourhood Groups',y=0.94)\n_ = ax[0].set_xlabel(\"\")\n_ = ax[0].set_ylabel('Number of Rooms')\n\n_ = sns.violinplot(x = 'neighbourhood_group',y='price',data = price_less_500,ax=ax[1])\n_ = ax[1].set_xlabel(\"\")\n_ = ax[1].set_ylabel('Room Price (\\$) for rooms <$500')\n","e8f61ed6":"log_data = train_df[['host_id','longitude','latitude']]\nlog_data['Log Price'] = np.log(train_df['price'])#+abs(min(np.log(train_df['price'])))\nlog_data['Log Reviews per Month'] = np.sqrt(train_df['reviews_per_month'])","35118330":"# Plot listing locations with room price as a colourmap\nfig, ax = plt.subplots(1,1,figsize=(9,9))\n# Set extends to correspond to coordinate system\n_ = plt.imshow(pic,extent = [min(data['longitude']),max(data['longitude']),\\\n                             min(data['latitude']),max(data['latitude'])])\n\n# Add subplot for polygons with same axis extents as underlying image\n_ = ax.axis([min(data['longitude']),max(data['longitude']),min(data['latitude']),\\\n             max(data['latitude'])])\n\n_ = sns.scatterplot(x='longitude',y='latitude',data=log_data,hue='Log Price',\\\n                    palette = 'coolwarm',alpha=0.5).set_title('Location of New York listings under $500')","14cab902":"# Plot breakdown of room types and how they vary per neighbourhood\nroom_types_by_neighbourhood = pd.crosstab(train_df['neighbourhood_group'],train_df['room_type'],\\\n                                          normalize='index')\n\nfig, ax = plt.subplots(1,2,figsize=(14,4))\n\n_ = room_types_by_neighbourhood.plot.bar(stacked=True,ax=ax[1])\n_ = ax[1].legend(title='Room Type').texts[0]\n_ = ax[1].set_title('Room Type Proportions by Neighbourhood')\n_ = ax[1].set_xlabel(\"\")\n_ = ax[1].tick_params(axis='x',rotation=360)\n\n_ = sns.barplot(x=train_df['room_type'].value_counts().index,y = train_df['room_type'].value_counts(),ax=ax[0])\n_ = ax[0].set_title('Breakdown of Room Types')\n_ = ax[0].set_ylabel(\"Number of Rooms\")","9a1017bd":"# Check median price of each room type\nroom_types = train_df['room_type'].unique()\nfor room in room_types:\n    med_price = round(np.median(train_df['price'][train_df['room_type']==room]),0)\n    print(f'The median price of a {room} is ${med_price}')","5fff57f9":"# Look at spread of minimum nights\nfig = plt.figure(figsize=(12,2))\n_ = sns.rugplot(train_df['minimum_nights']).set_title('Minimum Nights for Booking')","0d4fcd4b":"train_df[train_df['minimum_nights']>365]","39f019cf":"# Look at scatter of prices against minimum nights\nfig, ax = plt.subplots(1,2,figsize=(14,6),sharey=True)\nplt.suptitle('Room Price vs Minimum Nights')\n\n# Set up dataframe excluding bookings longer than one year\ntrain_df2 = train_df[train_df['minimum_nights']<367]\n\n# Add plot axes\n_ = sns.scatterplot(x='minimum_nights',y='price',data=train_df,ax=ax[0]).set_title('All Listings')\n_ = ax[0].set_ylabel('Room Price $')\n_ = ax[0].set_xlabel('Minimum Nights')\n\n_ = _ = sns.scatterplot(x='minimum_nights',y='price',data=train_df2,ax=ax[1],\\\n                       color = sns_colours[1]).set_title('Listings of One Year or Less')\n_ = ax[1].set_xlabel('Minimum Nights')","7c89239a":"# Look at last review date by year\ntrain_df['review_year'] = train_df['last_review'].dt.year\n\nfig = plt.figure(figsize=(10,5))\n_ = sns.distplot(train_df['review_year'],kde=False,bins=[2011.5,2012.5,2013.5,2014.5\\\n                                                         ,2015.5,2016.5,2017.5,2018.5,2019.5])\\\n.set_title('Last Review Date by Year')\n_ = plt.xlabel('Year')\n_ = plt.ylabel('Number of Reviews')","452ca047":"# Look at number of reviews in each neighbourhood group\nreviews_in_neighbourhood = train_df.groupby('neighbourhood_group')\\\n.agg({'name':'count','number_of_reviews':'sum'})\nreviews_in_neighbourhood['ratio'] = reviews_in_neighbourhood['number_of_reviews']\/reviews_in_neighbourhood['name']\nplt.figure(figsize=(8,6))\n_ = sns.barplot(x = reviews_in_neighbourhood.index,y = reviews_in_neighbourhood['ratio'],orient='v')\n_ = plt.title('Review Ratio by Neighbourhood')\n_ = plt.xlabel(\"\")\n_ = plt.ylabel('Mean Reviews per Listing')\n_ = plt.tick_params(axis='x',rotation = 360)","5e4e6db2":"# Look at reviews per room type\nroom_type_reviews = train_df.groupby('room_type').agg({'name':'count','number_of_reviews':'sum'})\nroom_type_reviews['ratio'] = room_type_reviews['number_of_reviews']\/ room_type_reviews['name']\nfig = plt.figure(figsize=(6,6))\n_ = sns.barplot(x = room_type_reviews.index,y=room_type_reviews['ratio'],orient='v')\n_ = plt.title('Review Ratio by Room Type')\n_ = plt.xlabel(\"\")\n_ = plt.ylabel(\"Mean Reviews per Listing\")","43997e58":"train_df['has_review'] = train_df['number_of_reviews']>0\nprint('Mean listing price split by whether the listing has been reviewed \\n')\nhas_review = train_df.groupby('has_review').agg({'price':'mean'})\ndisplay(has_review)\nprint('\\nProportion of room types split by whether a listing has been reviewed \\n')\ndisplay(pd.crosstab(train_df['has_review'],train_df['room_type'],normalize='index'))","3b99d445":"# Set up bootstrap test for mean price difference\ndifference = has_review.loc[False] - has_review.loc[True]\n\n# Find size of samples to draw\nno_reviews_size = sum(train_df['has_review']==False)\nreviews_size = sum(train_df['has_review']==True)\n\n# Initialize bootstrap variables\nreps = 1000\ndifferences = []\n\nfor i in range(reps):\n    sample1 = train_df.sample(no_reviews_size,replace=True)\n    sample2 = train_df.drop(sample1.index)\n    \n    sample1_price = np.mean(sample1['price'])\n    sample2_price = np.mean(sample2['price'])\n    differences.append(sample1_price-sample2_price)","5bc2f481":"# Review results of bootstrapping\nfig = plt.figure(figsize=(8,6))\n_ = plt.hist(differences, bins=50,color=colours[2])\n_ = plt.title('Difference in Mean Price Between Bootstrap Samples')\n_ = plt.xlabel('Price Difference $')\n_ = plt.ylabel('Count')\n\nprint(f'''The price difference between listings with and without reviews is ${round(difference[0],1)}.\nThe maximum price difference in {reps} boostrap samples was ${round(max(map(abs,differences)),1)}''')","d948b9ac":"# Extract time on site from total reviews and reviews per month - this will not work for listings with no reviews\ntrain_df['months_on_site'] = train_df['number_of_reviews']\/train_df['reviews_per_month']\ntrain_df['months_on_site'].fillna(0,inplace=True)\nfig = plt.subplots(figsize=(12,8))\nx = train_df[train_df['months_on_site']>0]['months_on_site']\nscatter = sns.scatterplot(x=x,y='number_of_reviews',data=train_df,hue='room_type',)\n\nx2 = np.arange(0,max(train_df['months_on_site']))\ny = x2\n\nline, = plt.plot(x2,y,color=colours[5],linewidth=3,label='One Review per Month')\n\n_ = plt.title('Listings With at Least One Review')\n_ = plt.xlabel('Months Listing on Airbnb')\n_ = plt.ylabel('Total Number of Reviews')\n_ = plt.legend().texts[1].set_text('Room Type')\n\nperc = sum(train_df['reviews_per_month']>1)\nat_least_1 = sum(train_df['number_of_reviews']>0)\nprint(f'{perc\/at_least_1*100:.1f}% of listings with at least one review average more than one review per month\\n')\nprint(f'{perc\/train_df.shape[0]*100:.1f}% of all listings average more than one review per month\\n')","7ea06f54":"top_availabilities = train_df['availability_365'].value_counts().to_frame().head(10)\ntop_availabilities.rename({'availability_365':'Count'},axis='columns',inplace=True)\ntop_availabilities.rename_axis('Availability (days per year)',inplace=True)\n\ndisplay(top_availabilities)","0a59dd8b":"# Look at how mean availability varies with room type\nroom_avail = train_df.groupby('room_type').agg({'availability_365':'mean'})\ndisplay(room_avail)","fb75e136":"# Reimport Data\ndata = pd.read_csv('..\/input\/new-york-city-airbnb-open-data\/AB_NYC_2019.csv', parse_dates = ['last_review'])\ndata.columns","f732d894":"# Clean and split data using methods identified during EDA\ndef clean_and_split(df):\n    '''Returns cleaned and split data: training, testing'''\n    temp = df.copy()\n    temp = temp.drop(['id','host_name'],axis=1)\n    temp['name'] = temp['name'].fillna('Information Missing')\n    temp['reviews_per_month'] = temp['reviews_per_month'].fillna(0)\n    temp = temp.drop(temp[temp['price']==0].index)\n    temp = temp.drop(temp[temp['price']>1000].index)\n    \n    X_tr,X_te,y_tr,y_te = train_test_split(temp.drop(['price'],axis=1),temp['price'],\\\n                                           test_size=0.1,random_state=27)\n    \n    training = pd.concat([X_tr,y_tr],axis=1)\n    testing = pd.concat([X_te,y_te],axis=1)\n    \n    return training, testing\n    ","1ffbc261":"# Apply cleaning function to get training and test data set\ntrain_df,test_df = clean_and_split(data)","3a34db98":"print(f'The skewness of the listing price is {train_df[\"price\"].skew():.2f}')\nlog_price = np.log(train_df['price'])\nprint(f'\\nThe skewness of the logarithm of the price is {log_price.skew():.2f}')","d30f6a5d":"# Select only numeric features\nnumeric_df = train_df.select_dtypes(include=['int64','float64'])\nnumeric_df.drop(['host_id','longitude','latitude'],axis=1,inplace=True)\n\n# Create correlation matrix\ncorrelation = numeric_df.corr()\n\nhm = heatmap(correlation.values,column_names=correlation.columns,row_names=correlation.columns,\\\n            figsize=(6,6),column_name_rotation=90)","e6b4f2e5":"print(f'''The skewness of the host listings count is\\\n {train_df[\"calculated_host_listings_count\"].skew():.2f}''')\n\nlog_listings = np.log(train_df['calculated_host_listings_count'])\nbox_listings = boxcox(train_df['calculated_host_listings_count'])\n\nprint(f'''The skewness of the log of the host listings count is\\\n {skew(log_listings):.2f}''')\n\nprint(f'''The skewness of the boxcox transform of the host listings count is\\\n {skew(box_listings[0]):.2f} using a lambda of {box_listings[1]:.3f}''')\n\nprint(f'\\nThe skewness of the availability is {train_df[\"availability_365\"].skew():.2f}')","c9980adf":"def create_model_df(df):\n    temp = df.copy()\n    temp['log_price'] = np.log(temp['price'])\n    temp = pd.get_dummies(temp,columns=['room_type','neighbourhood_group'])\n    temp['has_review'] = temp['number_of_reviews']>0\n    temp['calculated_host_listings_count'] = boxcox(temp['calculated_host_listings_count'],lmbda=-1.298)\n    temp = temp.drop(['name','host_id','neighbourhood','latitude','longitude','number_of_reviews',\\\n                     'last_review','reviews_per_month','price'],axis=1)\n    \n    return temp","68185c7e":"visible_df = create_model_df(train_df)\ntesting_df = create_model_df(test_df)\n\nvisible_df.head()","61f3020e":"# Split the visible data into training and validation sets\nX_train,X_valid,y_train,y_valid = train_test_split(visible_df.drop('log_price',axis=1),\\\n                                                  visible_df['log_price'],test_size=0.2,random_state=27)\n\ntraining_df = pd.concat([X_train,y_train],axis=1)\nvalidation_df = pd.concat([X_valid,y_valid],axis=1)","6e49c5ce":"# Create correlation matrix\ncorrelation = training_df.corr()\n\nhm = heatmap(correlation.values,column_names=correlation.columns,row_names=correlation.columns,\\\n            figsize=(12,12),column_name_rotation=90)","6d427ea3":"# Select model features to use as estimators\nestimators = training_df.columns.to_list()\nestimators.remove('log_price')","5fd3f67b":"# Construct and evaluate naive model\nmean_price = training_df['log_price'].mean()\nnaive_preds = training_df['log_price']-mean_price\n\n# Find rmse and convert from log price to price in $\nnaive_rmse = (mean_squared_error(np.exp(training_df['log_price']),np.exp(naive_preds))**0.5)\nprint(f'The RMSE of the naive model is ${naive_rmse:.2f}')","c6dcf041":"# Instantiate Base Models\nlin_reg = LinearRegression()\nsvr = SVR()\nlasso = Lasso()\nxgbr = xgb.XGBRegressor()\ndt = DecisionTreeRegressor()\nrf = RandomForestRegressor()\n\nmodels = [('Linear Regression',lin_reg),('Support Vector',svr),('Lasso',lasso),\\\n         ('XGBoost',xgbr),('Decision Tree',dt),('Random Forest',rf)]","88cae16f":"# Use CV socring with neg mean squared error to assess base models. For speed use only 10000 training examples\nscores = defaultdict(list)\nfor name, model in models:\n    cv = cross_val_score(model,X=training_df.loc[:10000,estimators],y = training_df.loc[:10000,'log_price'],\\\n                        scoring='neg_mean_squared_error',verbose=1,cv=5)\n    scores[name] = cv.mean()\n\ndisplay(pd.DataFrame(pd.Series(scores),columns=['MSE']))","85d156ab":"# Obtain RMSE score for model\nlin_reg.fit(training_df[estimators],training_df['log_price'])\nlin_reg_preds = lin_reg.predict(testing_df[estimators])\nlin_reg_rmse = (mean_squared_error(np.exp(testing_df['log_price']),np.exp(lin_reg_preds))**0.5)\n\nprint(f'The RMSE of the Linear Regression model is ${lin_reg_rmse:.3f}')","570cb275":"# Plot learning curves\nfig = plt.figure(figsize=(12,12))\n_ = plot_learning_curves(training_df[estimators], training_df['log_price'], testing_df[estimators],\\\n                     testing_df['log_price'], lin_reg,scoring='mean_squared_error')\n_ = plt.ylim(0.21,0.23)","be100ec0":"# XGBoost\nxgbr_params = {'objective':['reg:squarederror'],\n              'learning_rate': [.03, 0.05, .07], #so called `eta` value\n              'max_depth': [5, 6, 7],\n              'min_child_weight': [3,4,5],\n              'subsample': [0.5,0.7,0.8],\n              'colsample_bytree': [0.6,0.7,0.8],\n              'n_estimators': [100,200]}\n\nxgbr_gs = RandomizedSearchCV(xgbr,param_distributions= xgbr_params,n_iter = 100,scoring='neg_mean_squared_error',\\\n                             cv=3,verbose=0)\nxgbr_gs.fit(validation_df[estimators],validation_df['log_price'])\nprint(f'The lowest MSE achieved is: {xgbr_gs.best_score_:.3f} with parameters:{xgbr_gs.best_params_}')\n","b547f7e1":"xgbr_final = xgb.XGBRegressor(**xgbr_gs.best_params_)\nxgbr_final.fit(training_df[estimators],training_df['log_price'])\nxgbr_preds = xgbr_final.predict(testing_df[estimators])\nxgbr_rmse = (mean_squared_error(np.exp(testing_df['log_price']),np.exp(xgbr_preds))**0.5)\n\nprint(f'The RMSE of the XGBoost model is ${xgbr_rmse:.3f}')","2cc8041e":"# Plot learning curves\nfig = plt.figure(figsize=(12,12))\n_ = plot_learning_curves(training_df[estimators], training_df['log_price'], testing_df[estimators],\\\n                     testing_df['log_price'], xgbr_final,scoring='mean_squared_error')","159be209":"# Add columns for actual price, predicted price and absolute error to dataframe.\ntesting_df['price'] = np.exp(testing_df['log_price'])\ntesting_df['predicted_price'] = np.exp(xgbr_preds)\ntesting_df['error'] = abs(testing_df['price']-testing_df['predicted_price'])","dc1e01ae":"# Look at scatterplot and histogram of errors.\nfig,ax = plt.subplots(1,figsize=(12,6))\n_ = testing_df.hist('error',bins=100,ax=ax)\n_ = ax.set_title('Absolute Prediction Errors of XGB Regressor')\n_ = ax.set_xlabel('Abs Error ($)')\n_ = ax.set_ylabel('Count')\n\nfig,ax1 = plt.subplots(1,figsize=(12,6))\n_ = sns.scatterplot(x='price',y='error',data=testing_df,ax=ax1,color=sns_colours[1])\n_ = ax1.set_title('Absolute Errors of XGB Regressor')\n_ = ax1.set_xlabel('Room Price ($)')\n_ = ax1.set_ylabel('Abs Error ($)')","990e60dd":"As would be expected by the clear modal year for last review is 2019, the year of the dataset. There are though a number of listings without a review in over three years. The presumption is that any listing still on the site is active so to not have been reviewed for so long in curious. It shoulde be noted that there are a number of listings which have never been reviewed. It would have been useful to have records for how often and on what dates listings have been booked as without this information it is not possible to do a full analysis of the review years.\n\nThere are differences between the regularity with which different neighbourhood groups receive reviews. This may be linked to room type.","a6085351":"### Minimum Nights","e21e38d7":"We know from previous examination that the target variable, price, is highly skewed. Removing the highest price rooms will have helped but further processing will likely be needed.","fa5a50c0":"The dataset is dominated by hosts with a small number of properties, particularly single property hosts, though there are a handful of hosts with over 50 listings. As expected from the mean vs median bar charts, the box plots above show that there are some outlying room prices. The price feature will be examined in more detail later.","ac310e2b":"The price distribution of listings is very heavily skewed and it also seems as though there are some rooms listed at zero price. It is worth investigating the two ends of the distribution.","4cf2c864":"### Room Type","9287249f":"Shared rooms are by far the smallest proportion in the data set and also have the lowest median price. Private rooms and entire homes\/ apartments are fairly evenly split but entire homes\/ apartments have a much higher median price. Manhattan has the highest proportion of entire homes of the five neighbourhood groups which helps to explain why it has the highest median listing prices as discovered earlier in the analysis.","8893a19d":"### Longitude and Latitude\nThese features will be most useful for visualizing the locations of individual listings. The ranges of room prices that I want to vizualise are too skewed for using a colour map so I will first create log features of these.","50046b20":"There is no commonality between the entries with missing names and missing host names. To be able to retain these entries I will replace the name missing entries with \"Information Missing\".\n\nTo deal with the missing host_name information I am actually going to drop the feature from the data set. Partly this kind of feature brings privacy concerns but the main reason is that while studies have shown that the name gender and racial of the host could have an affect on price that is not something I want to investigate as part of this analysis. \n\nThe overlap between the missing reviews per month data and missing last review date data is 100% which liekly means that these facilities have not received any reviews. I will therefore replace the NaNs in the reviews per month field with 0.\n\nI will leave the NaNs in the date column at present. I am unliekly to use the lastreview field directly but may use it to create additional features and I will deal with any NaNs at that point.\n\nI will also drop the id column as it is not needed. The default pandas index can serve the same purpose and has the advantage of being sequential.","dd769a78":"Listings without reviews actually have a lower mean price, even despite listings without reviews containing a higher proportion of the lower priced shared rooms. I will perform a bootstrap test to check wether this difference is significant.","ac45f85b":"# New York City Airbnb\n\nThis Notebook uses the New York Airbnb open data set [available from Kaggle.com](https:\/\/www.kaggle.com\/dgomonov\/new-york-city-airbnb-open-data). At the time of writing in June 2020 there is not an open competition on this data set. I will be using this as an exercise to practice EDA and vizualization, though I will also develop a machine learning model to try and predict rental prices, using RMSE as the assesment metric.","2e10654a":"### Availability","6c9a5b3c":"The Linear Regression, XGBoost and Random Forest models have the best performance. Random Forest is the costliest to tune and train so for this task I will take forward Linear Regression and XGBoost. The linear regression model does not have any hyperparameters to tune.","2e0dd0b7":"XGBoost performs the best but a RMSE of $92 is very high given the typical room price in the data set. I will analyse the errors of the XGB model to see if there is any pattern.","e35be5e7":"As with other analytics shared rooms are an outlier. It seems like there is a clear difference in the market for people listing a room in a shared residence compared to those listing an entire residence or a private room. While the latter two are similar on most measures the higher price of whole homes\/ apartments would make sense as they are liekly to have a larger footprint.","69249ff0":"#### High Price Properties","8c8dbc2c":"From bootstrap testing it is clear that the price difference between listings with and without a review is significant so should be factored in to modelling.\n\nI will now look into whether it is possible to tell something about how busy a host has been since registering on the site. I will need to try and account for different lengths of stay as a high number of short stays could result in the same occupancy rate as a smaller number of long stays","b501482d":"The majority of the highest price listings are whole home\/ apartments located in Manhatten.","c6639ca0":"The plot above gives a good sense of the different neighbourhood groups and the deliniation between listings seems consistent. The southern grouping of Queens listings is distinct so it is possible that coding this into a separate group might benefit modelling.\n\nNext I will look at the breakdown of rooms across the neighbourhoods in a bit more detail. On some plots I will miss off the highest price rooms as the distribution has a long tail which will compromise some visualizations.","ae1b9cca":"#### Splitting Data\n\nAfter completing basic data cleaning I will now split off a portion of the data to be held back to use for testing the price prediction models I intend to develope. With nearly 50,000 observations I will only hold back 10% for the test set as this still gives a good test size.","a5aade5d":"Brooklyn and Manhattan dominate the rooms listings and are also the groups with the highest median prices. These two features should show up well when plotting using the longitude and latitude coordinates in the next section.\n\nThe prices in Manhattan have a narrower and longer distrubuation compoared to the other groups.","1483f463":"There are a small number of listings with a very high minimum number of nights. I will look more closely at those listings with a minimum requirement of longer than one year.","77fd2307":"Even with feature engineering there does not look to be a great deal of predictive power in the available information.\n\nI will first construct a naive model to use as a baseline before testing a the most likely model candidates. I will select the most promising subset of these to tune on the validation set before using the test data for the final evaluation.","f65dfaa1":"There are differences in the average review rate across neighbourhoods which is likely to be driven by the different review rates by room type combined with the differences in room type distribution between the neighbourhoods.\n\nA next question to look at is whether there is a difference in price between those listings which have been reviewed and those which haven't.","b609d9f0":"Having set up three models I will now train them on the full set of training data then evaluate their performance. As a reminder the RMSE of the naive model was $181.\n\n#### Linear Regression","c1ab71b4":"The listings of over a year still seem odd on closer inspection and do not seem to fit a pattern. These will be excluded from the learning algorithm.\n\nLooking at the listings with a mimimum requirement of less than a years stay the majority of these require less than a week mimimum stay. There are clusters at intervals which make sense in terms of our calendar, e.g. one month, 3 months, 6 months and 1 year.\n\nThe highest prices listings are all short duration but there is not a clear linear relationship between price and minimum night requirements beyond this.","604dd702":"There is not a high degree of correlation between any of the numerical variables and the price which is not ideal for a model with good predictive power. The only high degree of cross-correlation is between the number of reviews and the reviews per month, which is unsurprising.\n\n#### calculated_host_listings_count and availability_365","81a25600":"Taking a boxcox transform of the host listings count brings it to an acceptable level of skewness while the availability does not need transforming to achieve this.\n\nI will now write a function to process the training and test sets into the form I will use for modelling. The steps will be:\n- Create a column of log transformer price to use as the target variable\n- Binary encode the Room Type and Neighbourhood Group features\n- Create a feature for whether or not a listing has been reviewed\n- Perform a boxcox transformation with a lambda of -1.298 on the host listings count feature\n- Only retain the features I will use for modelling","f7398675":"The dataset contains a small proportion of very high priced rooms. Having done some research two reasons are suggested for this:\n\n1. Airbnb have recently started a premium\/ luxury service aimed at wealthy people. It seems likely that some of these listings feature in the dataset.\n\n2. There is some suggestion that for listings where the minimum nights are 30 or 31  then the price given is for a month. I cannot find a conclusive verdict on this so will treat all prices as being nightly.\n\nGiven the above while the presence of high end properties is an interesting feature of the data it seems reasonable ot conclude that that actually belong to a distinct customer segment, so from a modelling perspectvie should be treated differently. I will therefore split out all listings over $1000, which represents 0.5\\% of the data. I will analyse this a bit more but drop it from the main dataset for modelling purposes.","2915629c":"Over a third of the reduced dataset have an availability of 0 set. Reading up on how listing works it seems that this is how owners indicate that their listing is not currently available. There is no way to tell from the available data how long a zero availbility has been set for and therefore whether this listing is long- or short-term inactive.\n\nThe next most common availabilities are for full years which are probably hotels using the Airbnb website as another way to sell rooms. After that are a collection of short term availabilites and entries around three and six months in duration.","f94795ed":"## EDA and Vizualizations\n\nEDA is broken down into sections primarily looking at specific features, or groups of features, though in each section other information from the data set may be used during the analysis.\n\n### Price\n\nAs I am treating room price as the target variable I will inspect it first.","bd4b48e9":"### Neighbourhood and Neighbourhood Group","bcd08edb":"With such a high number of neighbourhoods it will be impractical to visualize them all at once on most plots so they will need to be partitioned. First though I will plot a cumulative distribution of the number of listings across neighbourhoods to see how even the distribution is.","9f5ad40d":"There are three groupings with unusually large mean prices for listings of 11, 12 and 49 listings per host. For hosts with 11 and 12 listing the median price is much more in line with surrounding groupings impliying that there may be a small number of high price rooms in those groups. Box plots will help shed some more light on this.","7b4b171b":"### EDA Conclusions\nFollowing the exploration of the data above a number of observations can be drawn:\n- The price distribution is highly right skewed. Even when the 0.5% of listings with prices over $1000 are removed there is still a heavy skew to the data. The majority of the highest priced listings are in Manhattan.\n- Around 66\\% of hosts only have a single listing on the site but a small number have in excess of 50 listings and the highest single host has 327 listings. Some of the hosts with higher numbers of listings seem to be hotls.\n- How listings are spread across the 200+ neighbourhoods of New York is very uneven. The median number of listings per neighbourhood is 30 but the mean in 197. This is skewed by a handful of neighbourhood which have over 1000 listings. Moving up a level to look at Neighbourhood Groups Manhattan and Brooklyn have more listings by a factor of 4+ than the other three groups. The price distribution of listings in these groups is also distinct, tending - towards higher prices.\n- The majority of listings are for whole ccomodations of private rooms. The mean price varies considerably by listing type and the variation of price across neighbourhoods looks to be in large part driven by the different room mixes.\n- Most listings on Airbnb are likely rented out fewer than once per month. There are some very popular listings but also a significant proportion which have likely never been rented.\n- There are high occurrence modalities in the minimum night requirements and annual availability which correspond to typical calendar intervals, e.g. 7 nights, 30 nights, then 90, 180 and 365 nights. There are also a significant number of listings showing a zero availability but it is not possible to tell how long this has been the case.\n- Shared rooms are the least likely to be reviewed but it seems that not having a review is correlated with a higher room price.","565363a7":"A small number of listings do record a price of $0 which seems likely to be an error. Two possible options are to either impute a room price based on the room characteristics or two drop those listings. Given the very small proportion of listings covered I will choose the option to drop them.","8e38fa3f":"### Number of Reviews, Reviews per Month and Last Review","f0518946":"Taking the log of the price brings it into an acceptable range. Next I will look at the correlation between numerical variables.","9ce2b7fa":"The listings are dominated by neighbourhoods with relatively small numbers of listings but there is a long tail with a handful of neighbourhoods having in excess of 1000 lisings.\n\nMoving on to neighbourhood groups, as a non New Yorker it would be useful to get a feel for the geography of the neighbourhoods.","dcea7f9f":"Above a room price of ~$250 the absolute prediction error begins to increase linearly with room price. This is another indication that the model does not have sufficient predictive power to account for the variation in the dataset. Givent the relatively close values of the training and test error and how little they change with the size of the training set the logical conclusion is that the available features are not sufficient to construct a good model.","40dd7c4f":"Most listings average fewer than one review per month. Airbnb estimate that around 70% of guests leave reviews so even adjusting for this it seems that most listings are rented out less than once per month. This would also suggest that 70% of listings without any reviews have never been rented out.\n\nThere are a number of site which are clearly averaging significantly above one review per month even without adjusting the figures.\n\nIt should be noted that one factor not considered here is the average length of listing.","3702c0a1":"## Predicting Prices\nHaving examined the available data to understand it I will now attempt to build a model to predict the price of listings in the dataset. This is a regression problem so I will use mean squared error at the metric.\n\nI will reimport that data from scratch, apply the cleaning methods developed above and split into training and test sets using a random seed of 27 so that I am not inadvertantly seeing previously hidden data.\n\nI will then perform feature engineering before moving on to test and develop models.","bbb528bf":"### host_id and calculated_host_listings_count\n\nThere is likely to be a limited amount to be learned from the host_id but from the listings_count featur we know that some hosts have more than one property available on Airbnb so it would be interesting to look at this in more detail."}}