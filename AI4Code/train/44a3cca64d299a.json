{"cell_type":{"ef00a428":"code","b9dc1a54":"code","b79bfe18":"code","b41aa5eb":"code","26bca5f3":"code","cfc25409":"code","248eb9fd":"code","597f6b8f":"code","72661b43":"code","2295dd19":"code","47dd356b":"code","69146ef5":"code","51de752b":"code","100544b3":"code","a5682717":"code","aad7fe40":"code","1ac61f98":"code","2b2a265c":"code","9ecff029":"code","e8fbdccf":"code","633890df":"code","c96eca63":"code","162cd1c9":"code","342cbeba":"code","f760ace2":"code","5797122c":"code","fbf7ce81":"code","ca2e6cf1":"markdown","c75e1f64":"markdown","4dd608a3":"markdown","1dd299a2":"markdown","5b7b2a0d":"markdown","979f4793":"markdown","a7e1ec04":"markdown","aa2ebbc3":"markdown","52f2519b":"markdown","5aead1ab":"markdown","99e7e252":"markdown","0a47de5f":"markdown","e20c0911":"markdown","7858b128":"markdown","11d3c9c5":"markdown","b65e89d5":"markdown"},"source":{"ef00a428":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport optuna\n\n\n# Pandas setting to display more dataset rows and columns\npd.set_option('display.max_rows', 150)\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', None)\npd.set_option('display.float_format', lambda x: '%.5f' % x)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b9dc1a54":"train = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-sep-2021\/train.csv\", low_memory=False)#, nrows=10000)\ntest = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-sep-2021\/test.csv\", low_memory=False)#, nrows=10000)\ntrain.info(memory_usage=\"deep\")","b79bfe18":"test.info(memory_usage=\"deep\")","b41aa5eb":"# Colors to be used for plots\ncolors = [\"lightcoral\", \"sandybrown\", \"darkorange\", \"mediumseagreen\",\n          \"lightseagreen\", \"cornflowerblue\", \"mediumpurple\", \"palevioletred\",\n          \"lightskyblue\", \"sandybrown\", \"yellowgreen\", \"indianred\",\n          \"lightsteelblue\", \"mediumorchid\", \"deepskyblue\"]","26bca5f3":"train.head()","cfc25409":"train.columns.values","248eb9fd":"fig, ax = plt.subplots(figsize=(5, 5))\npie = ax.pie([len(train), len(test)],\n             labels=[\"Train dataset\", \"Test dataset\"],\n             colors=[\"salmon\", \"teal\"],\n             textprops={\"fontsize\": 15},\n             autopct='%1.1f%%')\nax.axis(\"equal\")\nax.set_title(\"Dataset length comparison\", fontsize=18)\nfig.set_facecolor('white')\nplt.show();","597f6b8f":"train.describe().T","72661b43":"fig, ax = plt.subplots(figsize=(6, 6))\n\nbars = ax.bar(train[\"claim\"].value_counts().index,\n              train[\"claim\"].value_counts().values,\n              color=colors,\n              edgecolor=\"black\",\n              width=0.4)\nax.set_title(\"Claim (target) values distribution\", fontsize=20, pad=15)\nax.set_ylabel(\"Amount of values\", fontsize=14, labelpad=15)\nax.set_xlabel(\"Claim (target) value\", fontsize=14, labelpad=10)\nax.set_xticks(train[\"claim\"].value_counts().index)\nax.tick_params(axis=\"both\", labelsize=14)\nax.bar_label(bars, [f\"{x:2.2f}%\" for x in train[\"claim\"].value_counts().values\/(len(train)\/100)],\n                 padding=5, fontsize=15)\nax.bar_label(bars, [f\"{x:2d}\" for x in train[\"claim\"].value_counts().values],\n                 padding=-30, fontsize=15)\nax.margins(0.2, 0.12)\nax.grid(axis=\"y\")\n\nplt.show();","2295dd19":"fig, ax = plt.subplots(figsize=(16, 6))\n\nbars = ax.bar(train.isna().sum().index,\n              train.isna().sum().values,\n              color=\"lightskyblue\",\n              edgecolor=\"black\",\n              width=0.7)\nax.set_title(\"Missing feature values distribution in the train dataset\", fontsize=20, pad=15)\nax.set_ylabel(\"Missing values\", fontsize=14, labelpad=15)\nax.set_xlabel(\"Feature\", fontsize=14, labelpad=10)\nax.set_xticks([x if i%2==0 else \"\" for i, x in enumerate(train.columns.values)])\nax.tick_params(axis=\"x\", rotation=90, labelsize=8)\nax.margins(0.005, 0.12)\nax.grid(axis=\"y\")\n\nplt.show();","47dd356b":"fig, ax = plt.subplots(figsize=(16, 6))\n\nbars = ax.bar(test.isna().sum().index,\n              test.isna().sum().values,\n              color=\"lightsteelblue\",\n              edgecolor=\"black\",\n              width=0.7)\nax.set_title(\"Missing feature values distributionin in the test dataset\", fontsize=20, pad=15)\nax.set_ylabel(\"Missing values\", fontsize=14, labelpad=15)\nax.set_xlabel(\"Feature\", fontsize=14, labelpad=10)\nax.set_xticks([x if i%2==0 else \"\" for i, x in enumerate(test.columns.values)])\nax.tick_params(axis=\"x\", rotation=90, labelsize=8)\nax.margins(0.005, 0.12)\nax.grid(axis=\"y\")\n\nplt.show();","69146ef5":"df = pd.concat([train.drop([\"id\", \"claim\"], axis=1), test.drop(\"id\", axis=1)], axis=0)\ncolumns = df.columns.values\n\ncols = 4\nrows = len(columns) \/\/ cols + 1\n\nfig, axs = plt.subplots(ncols=cols, nrows=rows, figsize=(16,130), sharex=False)\n\nplt.subplots_adjust(hspace = 0.3)\ni=0\n\nfor r in np.arange(0, rows, 1):\n    for c in np.arange(0, cols, 1):\n        if i >= len(columns):\n            axs[r, c].set_visible(False)\n        else:\n            hist1 = axs[r, c].hist(train[columns[i]].values,\n                                   range=(df[columns[i]].min(),\n                                          df[columns[i]].max()),\n                                   bins=40,\n                                   color=\"deepskyblue\",\n                                   edgecolor=\"black\",\n                                   alpha=0.7,\n                                   label=\"Train Dataset\")\n            hist2 = axs[r, c].hist(test[columns[i]].values,\n                                   range=(df[columns[i]].min(),\n                                          df[columns[i]].max()),\n                                   bins=40,\n                                   color=\"palevioletred\",\n                                   edgecolor=\"black\",\n                                   alpha=0.7,\n                                   label=\"Test Dataset\")\n            axs[r, c].set_title(columns[i], fontsize=12, pad=5)\n            axs[r, c].set_yticks(axs[r, c].get_yticks())\n            axs[r, c].set_yticklabels([str(int(i\/1000))+\"k\" for i in axs[r, c].get_yticks()])\n            axs[r, c].tick_params(axis=\"y\", labelsize=10)\n            axs[r, c].tick_params(axis=\"x\", labelsize=10)\n            axs[r, c].grid(axis=\"y\")\n            axs[r, c].legend(fontsize=13)\n                                  \n        i+=1\n#plt.suptitle(\"Feature values distribution in both datasets\", y=0.99)\nplt.show();","51de752b":"print(\"Features with the leas amount of unique values:\")\ntrain.drop([\"id\", \"claim\"], axis=1).nunique().sort_values().head(5)","100544b3":"# Plot dataframe\ndf = train.drop(\"id\", axis=1).corr().round(5)\n\n# Mask to hide upper-right part of plot as it is a duplicate\nmask = np.zeros_like(df)\nmask[np.triu_indices_from(mask)] = True\n\n# Making a plot\nplt.figure(figsize=(16,16))\nax = sns.heatmap(df, annot=False, mask=mask, cmap=\"RdBu\", annot_kws={\"weight\": \"bold\", \"fontsize\":13})\nax.set_title(\"Feature correlation heatmap\", fontsize=17)\nplt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\",\n         rotation_mode=\"anchor\", weight=\"normal\")\nplt.setp(ax.get_yticklabels(), weight=\"normal\",\n         rotation_mode=\"anchor\", rotation=0, ha=\"right\")\nplt.show();","a5682717":"df[(df[\"claim\"]>-0.001) & (df[\"claim\"]<0.001)][\"claim\"]","aad7fe40":"features = [x for x in train.columns.values if x[0]==\"f\"]","1ac61f98":"# Counting amount of missing values in each row and adding it as a new feature\ntrain['n_missing'] = train[features].isna().sum(axis=1)\ntest['n_missing'] = test[features].isna().sum(axis=1)","2b2a265c":"# Filling missing values with mean of each column\nimputer = SimpleImputer(strategy=\"median\")\nfor col in features:\n    train[col] = imputer.fit_transform(np.array(train[col]).reshape(-1,1))\n    test[col] = imputer.transform(np.array(test[col]).reshape(-1,1))","9ecff029":"# Scaling all values to [0,1] range\ns_scaler = StandardScaler()\nm_scaler = MinMaxScaler()\nfor col in features:\n    train[col] = s_scaler.fit_transform(np.array(train[col]).reshape(-1,1))\n    test[col] = s_scaler.transform(np.array(test[col]).reshape(-1,1))\n    train[col] = m_scaler.fit_transform(np.array(train[col]).reshape(-1,1))\n    test[col] = m_scaler.transform(np.array(test[col]).reshape(-1,1))","e8fbdccf":"X = train.drop([\"id\", \"claim\"], axis=1)\nX_test = test.drop(\"id\", axis=1)\ny = train[\"claim\"]","633890df":"# def train_model_optuna(trial, X_train, X_valid, y_train, y_valid):\n#     \"\"\"\n#     A function to train a model using different hyperparamerters combinations provided by Optuna. \n#     Loss of validation data predictions is returned to estimate hyperparameters effectiveness.\n#     \"\"\"\n#     preds = 0\n    \n        \n#     #A set of hyperparameters to optimize by optuna\n#     xgb_params = {\n#                  \"objective\": trial.suggest_categorical('objective', [\"binary:logistic\"]),\n#                  \"use_label_encoder\": trial.suggest_categorical('use_label_encoder', [False]),\n#                  \"n_estimators\": trial.suggest_categorical('n_estimators', [40000]),\n#                  \"learning_rate\": trial.suggest_loguniform('learning_rate', 0.1, 1.0),\n#                  \"subsample\": trial.suggest_float('subsample', 0.1, 1, step=0.01),\n#                  \"colsample_bytree\": trial.suggest_float('colsample_bytree', 0.05, 1, step=0.01),\n#                  \"max_depth\": trial.suggest_int(\"max_depth\", 1, 8),\n#                  \"booster\": trial.suggest_categorical('booster', [\"gbtree\"]),\n#                  \"gamma\": trial.suggest_float('gamma', 0, 100, step=0.1),\n# #                  \"tree_method\": trial.suggest_categorical('tree_method', [\"gpu_hist\"]),\n#                  \"reg_lambda\": trial.suggest_loguniform('reg_lambda', 0.1, 100),\n#                  \"reg_alpha\": trial.suggest_loguniform('reg_alpha', 0.1, 100),\n#                  \"random_state\": trial.suggest_categorical('random_state', [42]),\n#                  \"n_jobs\": trial.suggest_categorical('n_jobs', [4]),\n#                  \"min_child_weight\": trial.suggest_categorical(\"min_child_weight\", [256]),\n#                     }\n\n\n\n#     # Model loading and training\n#     model = XGBClassifier(**xgb_params)\n#     model.fit(X_train, y_train,\n#               eval_set=[(X_train, y_train), (X_valid, y_valid)],\n#               eval_metric=\"auc\",\n#               early_stopping_rounds=100,\n#               verbose=False)\n    \n#     print(f\"Number of boosting rounds: {model.best_iteration}\")\n#     oof = model.predict_proba(X_valid)[:, 1]\n    \n#     return roc_auc_score(y_valid, oof)","c96eca63":"# %%time\n# # Splitting data into train and valid folds using target bins for stratification\n# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# # Setting optuna verbosity to show only warning messages\n# # If the line is uncommeted each iteration results will be shown\n# # optuna.logging.set_verbosity(optuna.logging.WARNING)\n\n# time_limit = 3600 * 4\n\n# study = optuna.create_study(direction='maximize')\n# study.optimize(lambda trial: train_model_optuna(trial, X_train, X_valid,\n#                                                     y_train, y_valid),\n# #                n_trials = 2\n#                timeout=time_limit\n#               )\n\n# # Showing optimization results\n# print('Number of finished trials:', len(study.trials))\n# print('Best trial parameters:', study.best_trial.params)\n# print('Best score:', study.best_value)","162cd1c9":"# Model hyperparameters\nxgb_params = {'objective': 'binary:logistic',\n              'use_label_encoder': False,\n              'n_estimators': 40000,\n              'learning_rate': 0.35,\n              'subsample': 0.88,\n              'colsample_bytree': 0.51,\n              'max_depth': 1,\n              'booster': 'gbtree',\n              'gamma': 0.2,\n#               'tree_method': 'gpu_hist',\n              'reg_lambda': 0.7497270276048157,\n              'reg_alpha': 52.11267615877387, \n              'random_state': 42,\n              'n_jobs': 4,\n              'min_child_weight': 256}","342cbeba":"%%time\n# Setting up fold parameters\nsplits = 5\nskf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=42)\n\n# Creating an array of zeros for storing \"out of fold\" predictions\noof_preds = np.zeros((X.shape[0],))\npreds = 0\nmodel_fi = 0\ntotal_mean_auc = 0\n\n# Generating folds and making training and prediction for each of 10 folds\nfor num, (train_idx, valid_idx) in enumerate(skf.split(X, y)):\n    X_train, X_valid = X.loc[train_idx], X.loc[valid_idx]\n    y_train, y_valid = y.loc[train_idx], y.loc[valid_idx]\n    \n    model = XGBClassifier(**xgb_params)\n    model.fit(X_train, y_train,\n              verbose=False,\n              # These three parameters will stop training before a model starts overfitting \n              eval_set=[(X_train, y_train), (X_valid, y_valid)],\n              eval_metric=\"auc\",\n              early_stopping_rounds=300,\n              )\n    \n    # Getting mean test data predictions (i.e. devided by number of splits)\n    preds += model.predict_proba(X_test)[:, 1] \/ splits\n    \n    # Getting mean feature importances (i.e. devided by number of splits)\n    model_fi += model.feature_importances_ \/ splits\n    \n    # Getting validation data predictions. Each fold model makes predictions on an unseen data.\n    # So in the end it will be completely filled with unseen data predictions.\n    # It will be used to evaluate hyperparameters performance only.\n    oof_preds[valid_idx] = model.predict_proba(X_valid)[:, 1]\n    \n    # Getting score for a fold model\n    fold_auc = roc_auc_score(y_valid, oof_preds[valid_idx])\n    print(f\"Fold {num} ROC AUC: {fold_auc}\")\n\n    # Getting mean score of all fold models (i.e. devided by number of splits)\n    total_mean_auc += fold_auc \/ splits\n    \nprint(f\"\\nOverall ROC AUC: {total_mean_auc}\")","f760ace2":"# Creating a dataframe to be used for plotting\ndf = pd.DataFrame()\ndf[\"Feature\"] = X.columns\n# Extracting feature importances from the trained model\ndf[\"Importance\"] = model_fi \/ model_fi.sum()\n# Sorting the dataframe by feature importance\ndf.sort_values(\"Importance\", axis=0, ascending=False, inplace=True)","5797122c":"fig, ax = plt.subplots(figsize=(13, 35))\nbars = ax.barh(df[\"Feature\"], df[\"Importance\"], height=0.4,\n               color=\"mediumorchid\", edgecolor=\"black\")\nax.set_title(\"Feature importances\", fontsize=30, pad=15)\nax.set_ylabel(\"Feature name\", fontsize=20, labelpad=15)\nax.set_xlabel(\"Feature importance\", fontsize=20, labelpad=15)\nax.set_yticks(df[\"Feature\"])\nax.set_yticklabels(df[\"Feature\"], fontsize=15)\nax.tick_params(axis=\"x\", labelsize=15)\nax.grid(axis=\"x\")\n# Adding labels on top\nax2 = ax.secondary_xaxis('top')\nax2.set_xlabel(\"Feature importance\", fontsize=20, labelpad=15)\nax2.tick_params(axis=\"x\", labelsize=15)\n\n# Inverting y axis direction so the values are decreasing\nplt.gca().invert_yaxis()","fbf7ce81":"predictions = pd.DataFrame()\npredictions[\"id\"] = test[\"id\"]\npredictions[\"claim\"] = preds\n\npredictions.to_csv('submission.csv', index=False, header=predictions.columns)\npredictions.head()","ca2e6cf1":"Let's check feature values distribution in the both datasets.","c75e1f64":"# **Data import**","4dd608a3":"As you can see, both train and test datasets have missing values in every feature excepth for \"id\" and \"claim\". We should take care with them.","1dd299a2":"# **Hyperparameters optimization**","5b7b2a0d":"# **Predictions submission**","979f4793":"# **EDA**","a7e1ec04":"As you can see, the datasets are well balanced. So target distribution should probably be the same for test predictions.","aa2ebbc3":"# **Model training**","52f2519b":"There are no categorical features in the dataset.\n\nLet's look at feature correlation.","5aead1ab":"# **Feature importances**","99e7e252":"Hyperparameters used in this notebook were optimized using Optuna. The code used or that is shown below. They are commented in order to save runtime as optimization has been already done.","0a47de5f":"Probably worth a try to drop them and check if it improves the result.","e20c0911":"# **Data preprocessing**","7858b128":"The target value classes are balanced which is good.","11d3c9c5":"The idea of adding a new feature below is taken from [this notebook](https:\/\/www.kaggle.com\/hiro5299834\/tps-sep-2021-single-lgbm) by [BIZEN](https:\/\/www.kaggle.com\/hiro5299834).","b65e89d5":"There is very weak linear correlation between the features. There are some features with relatively low correlation with target value even comparing with other features:"}}