{"cell_type":{"170bc564":"code","29194331":"code","9d6552cc":"code","59368182":"code","2e2fa571":"code","30f53764":"code","ccc4ee96":"code","d3f6ce58":"code","e931d5d1":"code","f0e20716":"code","8728cb61":"code","e8b5a158":"code","5b415550":"code","9c8e220e":"code","211ef540":"code","12b46fd9":"code","dfc621e4":"code","63eed21c":"code","77ce4b64":"code","acc82697":"code","480466a3":"code","cfdf2b2f":"code","1db8d516":"code","90700dba":"code","5f71ee4f":"code","ea336928":"code","a18dcc1b":"code","3e9cd211":"code","b8655f84":"code","e02838b6":"markdown","5dd6ced7":"markdown","9c31f471":"markdown","03b19b37":"markdown","f36dd688":"markdown","90d54f3b":"markdown","1984799b":"markdown","4567de05":"markdown","48a0035f":"markdown","754678ed":"markdown","d17fa428":"markdown","e3776f32":"markdown","2865a20b":"markdown","b2dbed7a":"markdown","0ef0a0de":"markdown","5afa8ec1":"markdown","27bc60a3":"markdown","947a7fa6":"markdown","3bbbcc57":"markdown","df0dfb83":"markdown","6d367699":"markdown","86af19a5":"markdown","b04124c1":"markdown","539e5197":"markdown","05b14cee":"markdown","9fc05527":"markdown","54f771b9":"markdown","010fc287":"markdown","f7f59997":"markdown","6e6e0f20":"markdown","89d1dc66":"markdown"},"source":{"170bc564":"# A hashtag means comment in python\n# Import the pandas library \n# And alias it as pd\n\n##Type your code below this ( 1 line of code)\n","29194331":"# Now we will see what all data files are present in the Docker Container\n# os library help us go through the file system and will be used to list all the files present\nimport os\nprint(os.listdir(\"..\/input\"))","9d6552cc":"print(os.listdir(\"..\/input\/heart-disease-uci\/\"))","59368182":"#This code now reads the files heart.csv and we have the data stored in the pandas variable heart_data\nheart_data = pd.read_csv(\"..\/input\/heart-disease-uci\/heart.csv\")","2e2fa571":"# Pandas Challenge ( Get first 5 rows of heart_data ) 1 line of code\n","30f53764":"# Pandas Challenge 1 line of code\n","ccc4ee96":"# Pandas Challenge 1 line of code\n","d3f6ce58":"# Pandas Challenge 1 line of code\n","e931d5d1":"# Pandas Challenge 1 line of code\n","f0e20716":"# Pandas Challenge : Use pandas loc to print first column ('age') loc['age']\n\n# Pandas Challenge : Use pandas iloc to print first column ('age') iloc[0]\n\n# Pandas Challenge : Use pandas iloc\/loc to print 3rd element of 'age' column\n","8728cb61":"# Pandas Challenge 1 line of code\n","e8b5a158":"# Numpy challenge ( 1 line of code) Import the numpy library\n","5b415550":"# Numpy challenge ( 1 line of code) Create a numpy array with few elements (np.array([1,2,3])\n# Also assign it to a variable say, a\n","9c8e220e":"a = np.array([1,2,3,4,5,6])\nb = np.array([1])\n# Numpy Challenge 1 line of code add a and b\n","211ef540":"a = np.array([1,2,3,4,5,6])\n# Numpy Challenge 1 line of code find the square of a\n","12b46fd9":"import numpy as np \nimport pandas as pd \n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","dfc621e4":"# import input_data # standard python class for downloading datasets\n# read MNIST data\n# https:\/\/stackoverflow.com\/a\/37540230\/5411712\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"MNIST_Data\", one_hot=True)\nprint(mnist)","63eed21c":"import tensorflow as tf","77ce4b64":"learning_rate = 0.01 # how fast to update weights; 0.01 is standard and pretty good\n        # too big >> miss optimal soln; too small >> takes too long to find optimal soln\ntraining_iteration = 30 # number of times to run the gradient descent (optimizer) step\nbatch_size = 100\ndisplay_step = 2","acc82697":"# TF graph input\nx = tf.placeholder(\"float\", [None, 784]) # mnist data image of shape; 28*28=784\n     # notice images are 28px by 28px arrays & get \"flattened\" into 1D array of 784 pixels\ny = tf.placeholder(\"float\", [None, 10]) # 0-9 digits recognition >> 10 classes to be \"classified\"\n\n# create a model\n\n# set model parameters\nW = tf.Variable(tf.zeros([784, 10])) # weights (probabilities that affect how data flows in graph)\nb = tf.Variable(tf.zeros([10]))      # biases (lets us shift the regression line to fit data)","480466a3":"# \"scopes help us organize nodes in the graph visualizer called, Tensorboard\"\nwith tf.name_scope(\"Wx_b\") as scope:\n    # First scope constructs a linear model (Logistic Regression)\n    # `tf.nn` --- https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/nn\n    model = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax???? what about ReLU? Sigmoid? \n                                               # tf.nn.relu(biases=,features=,name=,weights=,x=)\n                                               # tf.nn.softmax(_sentinel=,axis=,dim=,labels=,logits=,name=)","cfdf2b2f":"# Add summary operations to collect data\n# helps us later visualize the distribution of the Weights and biases\n# https:\/\/github.com\/tensorflow\/serving\/issues\/270\nw_h = tf.summary.histogram(\"weights\", W)\nb_h = tf.summary.histogram(\"biases\", b)","1db8d516":"# More name scopes will clean up graph representation\nwith tf.name_scope(\"cost_function\") as scope:\n    # Second scope minimizes error using \"cross entropy function\" as the \"cost function\"\n    # cross entropy function\n    cost_function = -tf.reduce_sum(y*tf.log(model))\n    # create a summary to monitor the cost function; for later visualization\n    tf.summary.scalar(\"cost_function\", cost_function)","90700dba":"with tf.name_scope(\"train\") as scope:\n    # Last scope Gradient Descent; the training algorithm\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)","5f71ee4f":"# initialize the variables\ninit = tf.initialize_all_variables()","ea336928":"# merge summaries into 1 operation\n# https:\/\/github.com\/tensorflow\/tensorflow\/issues\/7737\nmerged_summary_op = tf.summary.merge_all()","a18dcc1b":"print(\"learning_rate\\t\\t=\\t\" + str(learning_rate))\nprint(\"training_iteration\\t=\\t\" + str(training_iteration))\nprint(\"batch_size\\t\\t=\\t\" + str(batch_size))\nprint(\"display_step\\t\\t=\\t\" + str(display_step))","3e9cd211":"# Start training by launching a session that executes the data flow graph\nwith tf.Session() as sess:\n    sess.run(init)\n\n    # Set the logs writer to the folder \/tmp\/tensorflow_logs\n    # This is for all the visualizations later\n    # https:\/\/stackoverflow.com\/a\/41483033\/5411712\n    summary_writer = tf.summary.FileWriter('.\/logs', graph_def=sess.graph_def)\n    \n    # Training cycle\n    for i in range(training_iteration):\n        avg_cost = 0.0 # prints out periodically to make sure model is \"improving\" ... goal is to minimize cost\n        total_batch = int(mnist.train.num_examples \/ batch_size)\n        # loop over all batches\n        for b in range(total_batch): # for each example in training data\n            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n            # fit training using batch data\n            # `optimizer` is Gradient Descent; used for 'backpropagation'\n            sess.run(optimizer, feed_dict={x:batch_xs, y:batch_ys})\n            # compute the average loss\n            avg_cost += sess.run(cost_function, feed_dict={x:batch_xs, y:batch_ys})\/total_batch\n            # write logs for each iteration\n            summary_str = sess.run(merged_summary_op, feed_dict={x:batch_xs, y:batch_ys})\n            summary_writer.add_summary(summary_str, i * total_batch + b)\n                                            # why `i * total_batch + b` ??? idk.\n        # Display logs per iteration step\n        if (i % display_step == 0):\n            print(\"iteration:\", '%04d' % (i+1), \"avg_cost=\", \"{:9f}\".format(avg_cost))\n\n    print(\"\\nTraining completed!\\n\")\n\n    # Test the model\n    # remember 'y' is the prediction variable\n    predictions = tf.equal(tf.argmax(model, 1), tf.argmax(y, 1))\n    # Calculate accuracy\n    accuracy = tf.reduce_mean(tf.cast(predictions, \"float\"))\n    print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))","b8655f84":"# optionally run the command in the notebook itself by uncommenting the line below\n!tensorboard --logdir=.\/logs","e02838b6":"# [MNIST Dataset Source](http:\/\/yann.lecun.com\/exdb\/mnist\/)\n# [I am following this YouTube tutorial](https:\/\/www.youtube.com\/watch?v=2FmcHiLCwTU&vl=en)\n\n### Goal \n* Build a classifier that can look at a 28x28 image of a handwritten digit and classify the digit (0-9).\n  * the \"Hello World\" of Deep Learning\n* Personal goals: \n  * understand Tensorflow's python wrapper & Tensorflow a little bit better\n  * understand neural networks a little bit better\n  * understand some basics of machine learning a little bit better","5dd6ced7":"# Logistic Regression:\n![Imgur](https:\/\/i.imgur.com\/rrkOONc.png)","9c31f471":"# Gradient Descent:\n![Imgur](https:\/\/i.imgur.com\/i6WW4gH.png)","03b19b37":"**Pandas Challenge**\n* Read the last  5 Rows of the heart_data dataframe This can be acheived using variable_name.tail(no_of_rows)","f36dd688":"# This is what the data looks like:\n![mnist_data](https:\/\/i.imgur.com\/mKstG9R.png)","90d54f3b":"# set \"hyperparameters\" (knobs & dials)","1984799b":"# Viewing all the summaries in ***Tensorboard***\n##### this should be done locally so make sure to **download** the ```kernal.ipynb``` file and run ```tensorboard --logdir=.\/logs``` in the command line \n* ***Note:*** ```pip install tensorflow``` may be required to import tensorflow","4567de05":"**Pandas Challenge**\n* Read the first 5 rows of the heart_data dataframe This can be acheived using variable_name.head(no_of_rows)","48a0035f":"## Notice that the ```avg_cost``` values decrease with each logged iteration. This means that the gradient descent algorithm is minimizing the cost function. \n### I suppose if we ran the code with ```training_iteration``` set to a larger number then we would expect to see little to no improvement on the accuracy since the ```avg_cost``` seems to level off at around 18.","754678ed":"# An image is represented as a matrix of pixel values:\n![Imgur](https:\/\/i.imgur.com\/XYyI1ha.png)\n\n# It gets flattened into a 1D array to be used as the feature vector:\n![Imgur](https:\/\/i.imgur.com\/d9ZvYPV.png)","d17fa428":"**Numpy Challenge**\n* In numpy you can compute power using power(np_array,power_value) ","e3776f32":"## notes\n#### tensorflow\n* Tensorflow \"model\" = \"data flow graph\"\n* Graph has nodes called \"operations\"\n  * basic units of math (e.g: addition, multiplication, fancy-schmancy-multivar-calculus, etc)\n  * input: tensor\n  * output: tensor\n* tensor = multidimensional arrays (matrices)\n\n#### conventions\n* x = feature vector \/ the thing(s) that help us do the prediction\n* y = \"output classes\" \/ the thing we want to predict\n* \"**placeholder**\" = a variable that will have data assigned to it later","2865a20b":"## Learning Rate:\n![learning_rate](https:\/\/i.imgur.com\/3L1qbdT.png)","b2dbed7a":"#### Now that you have imported the library, its time to see what we can do with this library\n#### Now, we will be importing the Heart Disease UCI data\n#### And do some tasks with pandas for which it is well know","0ef0a0de":"**Why do we need pandas?**\nPandas is well suited for many different kinds of data:\n* Tabular data with heterogeneously-typed columns, as in an SQL table or Excel spreadsheet\n* Ordered and unordered (not necessarily fixed-frequency) time series data.\n* Arbitrary matrix data (homogeneously typed or heterogeneous) with row and column labels\n* Any other form of observational \/ statistical data sets. The data actually need not be labeled at all to be placed into a pandas data structure","5afa8ec1":"**Pandas Challenge**\n* Get the statisctical description of the data heart_data\n* Use heart_data.describe()","27bc60a3":"#### main graph\n<img src=\"https:\/\/i.imgur.com\/f8LgApJ.png\" width=\"400\">\n#### tensorboard_auxilary_nodes\n![tensorboard_auxilary_nodes](https:\/\/i.imgur.com\/ZABjzeR.png)\n#### tensorboard_cost_function\n![tensorboard_cost_function](https:\/\/i.imgur.com\/yTCklib.png)\n#### tensorboard_biases_distribution\n![tensorboard_biases_distribution](https:\/\/i.imgur.com\/iyZupnI.png)\n#### tensorboard_weights_distribution\n![tensorboard_weights_distribution](https:\/\/i.imgur.com\/DxgMGZt.png)\n#### tensorboard_biases_histogram\n![tensorboard_biases_histogram](https:\/\/i.imgur.com\/Af06kgc.png)\n#### tensorboard_weights_histogram\n![tensorboard_weights_histogram](https:\/\/i.imgur.com\/wcbcIdy.png)","947a7fa6":"* Now with the two folders we have I want you to focus on heart-disease-uci within which we have heart.csv\n#### This is the file we will use and understand how pandas is used and we have a better understanding of the library\n* [To open a csv file we use pd.read_csv](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.read_csv.html)","3bbbcc57":"**Pandas Challenge**\n* [Find NA values](https:\/\/stackoverflow.com\/questions\/29530232\/how-to-check-if-any-value-is-nan-in-a-pandas-dataframe)\n* Play with the solution and understand how each function works","df0dfb83":"**Numpy Challenge**\n* Create an numpy array with few elements in it","6d367699":"**Pandas Challenge**\n* Find the list of columns from the heart_data\n* Data_Variable.columns does it","86af19a5":"**Numpy Challenge**\n* In numpy broadcasting can be demonstrated by a simple example by adding the two arrays arrays below of different sizes ","b04124c1":"**NUMPY**\n* That was a basic cover on Pandas library and now we will talk about numpy\n#### Start with importing the library and aliase it as np","539e5197":"**Pandas Challenge**\n* Print only the age column\n* For a Datavariable -> df\n* To get only a particular column type df[\"column_name\"]\n* Since it is case sensitive, note that any deviation from the original name will cause it to throw error","05b14cee":"### Topics Covered\n* What Kaggle is (A Basic run-through the online platform)\n* [Business model of Kaggle](https:\/\/www.kaggle.com\/competitions)\n* [Competetions in Kaggle and top Kagglers](https:\/\/www.kaggle.com\/rankings)\n* [Ipython shortcut Keys](http:\/\/johnlaudun.org\/20131228-ipython-notebook-keyboard-shortcuts\/) \n* Important Libraries - Pandas, Numpy, Tensorflow","9fc05527":"# Future Learning\n* What is PyTorch and how does it compare to Tensorflow?\n   * https:\/\/www.youtube.com\/watch?v=nbJ-2G2GXL0\n     * Would PyTorch reduce the need to define \"placeholders\" because that was, frankly, weird to see in a language like python?\n* [But what *is* a Neural Network?](https:\/\/youtu.be\/aircAruvnKk)\n  * [and how do they learn?](https:\/\/youtu.be\/IHZwWFHWa-w) \n  * [and what is backprop really doing?](https:\/\/youtu.be\/Ilg3gGewQ5U)\n  * [and how does backprop use calculus?](https:\/\/youtu.be\/tIeHLnjs5U8)\n* How can the accuracy found above ```0.9254``` be improved to closer to ```0.95``` or ```0.99```?\n   * To what extend does changing the ```learning_rate``` or ```training_iteration``` or ```batch_size``` affect the accuracy? \n     * I dont think batch_size should have any affect. \n     * with ```training_iteration=30``` and ```learning_rate=0.01``` the algorithm ran in less than a few minutes and achieved ```0.9254```. Perhaps allowing it to train for several hours would boost the accuracy?\n       * [relevant quora question](http:\/\/qr.ae\/TUGJid)\n* How long would it take a human toddler to \"classify\" digits (0-9)? An hour or two? maybe less? Of course you would need to hold their attention to the task, haha! \n* What would happen to the accuracy if I modified the test data or the training data to include **random noise** or even attempt the [**one pixel attack**](https:\/\/arxiv.org\/abs\/1710.08864)\n  * [video about one pixel attack](https:\/\/youtu.be\/SA4YEAWVpbk)\n>   \"Now, note that this also means that we have to be able to look into the neural network and have access to the confidence values.\" - [K\u00e1roly Zsolnai-Feh\u00e9r](https:\/\/youtu.be\/SA4YEAWVpbk?t=155)\n  *  Would a method for reducing NerualNet accuracy that only sees output classes, *without accuracy values*, be analogous to humans discovering optical illusions? haha! \ud83d\ude02\n  * [it seems some researchers have tried to trick AI that learned on MNIST data](https:\/\/arxiv.org\/pdf\/1801.02612.pdf)\n  * [another one](https:\/\/arxiv.org\/pdf\/1608.04644.pdf)\n  * [and another one](https:\/\/arxiv.org\/pdf\/1807.10335.pdf)\n  * [and more](https:\/\/www.google.com\/search?safe=off&q=one+pixel+attack+\"mnist\")\n* What would happen to the accuracy if I changed **```tf.nn.softmax```** to **```relu```** or even **```sigmoid```** or **```tanh```**?\n  * [learn more about activation functions](https:\/\/youtu.be\/-7scQpJT7uo)","54f771b9":"**Concept of Broadcasting**\n* In numpy, you can do broadcasting, which in theory means extending a smaller arrays numerics to a larger array","010fc287":"# Training","f7f59997":"**Basic Pandas Codes**\n\n#### To start with we need to import pandas library\n#### To import any library we need to use the import command\n* Example to import os library we type **import os** and run\n#### Aliasing in libraries is done with the keyword **as**\n* To import tensorflow as call it tf during the coding we type **import tensorflow as tf**","6e6e0f20":"**Tutorial on TensorFlow**\n* From here on we will attempt to do a basic ML related tasks using tensorflow\n\n**Basic points, on TENSORFLOW** ","89d1dc66":"**Pandas Challenge**\n* User loc and iloc\n* loc is used for locating using variable name\n* iloc is used for locating using index number"}}