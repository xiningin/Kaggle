{"cell_type":{"1b808414":"code","df7f39a1":"code","99b0969f":"code","35f72804":"code","c39144b7":"code","17233b5d":"code","a5aa2b06":"code","b39093f8":"code","8702c3c2":"code","3bf644ce":"code","8ec35f89":"code","8df8c6cd":"code","74f2850b":"code","ac5568f5":"code","cdea3292":"code","9ab5b5cd":"code","04ed1fd3":"code","2bbd5baf":"code","ac924766":"code","c1ec9cf4":"code","6526f799":"code","7591244f":"markdown","0501a3ad":"markdown","b33f1ed4":"markdown","7eda8523":"markdown","c66236df":"markdown","d032ce18":"markdown"},"source":{"1b808414":"import os\nimport pathlib\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.applications.xception import Xception, preprocess_input\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers.experimental.preprocessing import Normalization, RandomFlip, RandomRotation, RandomCrop\nfrom tensorflow.keras.layers.experimental.preprocessing import CenterCrop, RandomZoom, RandomContrast\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import utils\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nimport matplotlib.pyplot as plt","df7f39a1":"image_path = list(pathlib.Path('..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset').glob(r'**\/*.png'))\nimage_label = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], image_path))","99b0969f":"df = pd.DataFrame({\"path\":image_path,\n                  \"label\":image_label})\ndf","35f72804":"df[\"path\"] = df[\"path\"].astype(str)\ndf.label.value_counts()","c39144b7":"# Let's get rid of GT folders\ndf = df[~df[\"label\"].str.contains(\"GT\")].reset_index(drop=True)\ndf","17233b5d":"# all this fishes are awesome, aren't they?\n\nimport matplotlib.image as mpimg\n\nplt.figure(figsize=(15,10))\nfor i in range(9):\n    random_num = np.random.randint(len(df))\n    path = df[\"path\"][random_num]\n    label = df[\"label\"][random_num]\n    img = mpimg.imread(path)\n    plt.subplot(3,3,i+1)\n    plt.imshow(img)\n    plt.title(label)\n    plt.axis(\"off\")","a5aa2b06":"from sklearn.model_selection import train_test_split\ndf_train, df_test = train_test_split(df, test_size=0.1)","b39093f8":"# Data Augmentation should be applied only to training data\ntrain_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input, \n                                    validation_split=0.2,                                    \n                                    rotation_range=20,\n                                    width_shift_range=0.2,\n                                    height_shift_range=0.2,\n                                    shear_range=0.2, \n                                    zoom_range=0.2,\n                                    channel_shift_range=0.2,\n                                    horizontal_flip=True)\ntest_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input)","8702c3c2":"train_data = train_data_gen.flow_from_dataframe(dataframe=df_train,\n                                               x_col=\"path\",\n                                               y_col=\"label\",\n                                               color_mode=\"rgb\",\n                                               class_mode=\"categorical\",\n                                               target_size=(224, 224),\n                                               batch_size=32,\n                                               shuffle=True,\n                                               seed=42,\n                                               subset=\"training\")","3bf644ce":"val_data = train_data_gen.flow_from_dataframe(dataframe=df_train,\n                                             x_col=\"path\",\n                                             y_col=\"label\",\n                                             color_mode=\"rgb\",\n                                             class_mode=\"categorical\",\n                                             target_size=(224, 224),\n                                             batch_size=32,\n                                             shuffle=True,\n                                             seed=42,\n                                             subset=\"validation\")","8ec35f89":"# when we create test data it is better to switch off the shuffle parameter\ntest_data = test_data_gen.flow_from_dataframe(dataframe=df_test,\n                                             x_col=\"path\",\n                                             y_col=\"label\",\n                                             color_mode = \"rgb\",\n                                             class_mode = \"categorical\",\n                                             target_size=(224, 224),\n                                             batch_size=32,\n                                             shuffle=False)","8df8c6cd":"base_model = Xception(\n    weights='imagenet',  \n    input_shape=(224, 224, 3),\n    pooling=\"max\",\n    include_top=False)","74f2850b":"base_model.trainable = False","ac5568f5":"# Build model\ninputs = tf.keras.layers.Input(shape=(224, 224, 3))\n\nx = base_model(inputs)\nx = tf.keras.layers.Dense(256, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\noutputs = tf.keras.layers.Dense(9, activation=\"softmax\")(x)\n\nmodel = tf.keras.Model(inputs, outputs, name=\"xception_model\")","cdea3292":"model.compile(loss='categorical_crossentropy',\n              optimizer=tf.keras.optimizers.Adam(),\n              metrics=['accuracy'])","9ab5b5cd":"history = model.fit(train_data, \n                    validation_data=val_data,\n                    epochs=15)","04ed1fd3":"scores = model.evaluate(test_data, verbose=1)\nprint(\"The percent of correct answers:\", round(scores[1] * 100, 4))","2bbd5baf":"plt.plot(history.history['accuracy'], \n         label='Test correct answers percent')\nplt.plot(history.history['val_accuracy'], \n         label='Validation correct answers percent')\nplt.xlabel('Epoch')\nplt.ylabel('Correct answers percent')\nplt.legend()\nplt.show()","ac924766":"plt.plot(history.history['loss'], \n         label='Train loss')\nplt.plot(history.history['val_loss'], \n         label='Validation loss')\nplt.xlabel('Epoch')\nplt.ylabel('loss')\nplt.legend()\nplt.show()","c1ec9cf4":"base_model.trainable = True\nmodel.summary()\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-5),  # Low learning rate\n    loss=tf.keras.losses.CategoricalCrossentropy(),\n    metrics=[tf.keras.metrics.CategoricalAccuracy()],\n)\n\nepochs = 10\nmodel.fit(train_data, epochs=epochs, validation_data=val_data)","6526f799":"scores = model.evaluate(test_data, verbose=1)\nprint(\"The percent of correct answers:\", round(scores[1] * 100, 4))","7591244f":"The result is very impressive. Let's try **Fine-tuning**\n\nUnfreeze the base_model. Note that it keeps running in inference mode since we passed `training=False` when calling it. This means thatthe batchnorm layers will not update their batch statistics. This prevents the batchnorm layers from undoing all the training we've done so far.","0501a3ad":"While creating datasgenerators let's implement **Data Augmentation**. Keras has the following Data Augmentation techniques:\n\n* [RandomFlip](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/RandomFlip) - horizontal or vertical flip\n* [RandomRotation](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/RandomRotation) - rotation clockwise and counter-clockwise\n* [RandomCrop](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/RandomCrop) - crop the images to target height and width\n* [CenterCrop](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/CenterCrop) - crop the images center to target height and width\n* [RandomZoom](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/RandomZoom) - changing image scale\n* [RandomContrast](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/RandomContrast) - contrast level adjustment\nAll this mthods are applied during the training process only","b33f1ed4":"Now we can create our datasets. Tensorfolw has a very convinient tool for this purpose - **flow_from_dataframe** ","7eda8523":"Since our dataset is not split let's do this manualy","c66236df":"Do you know what time it is? \n\nIt's time for **transfer learning**. Transfer learinig consists of taking features learned on one problem, and leveraging them on a new, similar problem. For instance, features from a model that has learned to identify racoons may be useful to kick-start a model meant to identify tanukis.\nTransfer learning is usually done for tasks where your dataset has too little data to train a full-scale model from scratch.\n\nThe most common incarnation of transfer learning in the context of deep learning is the following workflow:\n\n* Take layers from a previously trained model.\n* Freeze them, so as to avoid destroying any of the information they contain during future training rounds.\n* Add some new, trainable layers on top of the frozen layers. They will learn to turn the old features into predictions on a new dataset.\n* Train the new layers on your dataset.\n* (optional) fine-tuning, which consists of unfreezing the entire model you obtained above (or part of it), and re-training it on the new data with a very low learning rate.\n\nTransfer learning is usually done for tasks where your dataset has too little data to train a full-scale model from scratch. The list of the most popular models is [here](http:\/\/https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/applications). \n\nLet's try the **Xception** model","d032ce18":"The accuracy result is high enough. It was my first Xception experinece. I find this model very useful and effective."}}