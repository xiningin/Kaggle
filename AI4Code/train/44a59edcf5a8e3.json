{"cell_type":{"3170eb5f":"code","922d96fd":"code","7f36e473":"code","eb61743b":"code","56442ada":"code","7109180b":"code","b41d7be3":"code","fa86afed":"code","8cdc4d82":"code","f5000779":"code","ae9136b4":"code","19663cc5":"code","ca4cf9db":"code","27d3da9a":"code","91606fcd":"code","eaace1a6":"code","2c048e25":"code","4a9678b9":"code","0aad0f3e":"code","8f15ca91":"code","6893a1bc":"code","f4fd1876":"code","f51d592b":"code","46e193b1":"code","72b11863":"code","effd2634":"code","9f8d815c":"code","3e4220e5":"code","9aac56d5":"code","54086881":"code","22939ef0":"code","ffe69526":"code","45d1b430":"code","eb2b5bfe":"code","67e5db14":"code","d06e08cc":"code","e20e76d6":"code","cf295049":"markdown","afbd0c1a":"markdown","084f904b":"markdown","131440d8":"markdown","8881653b":"markdown","94f7c35a":"markdown","94a1d0e2":"markdown","5fb3b463":"markdown","0c25f41f":"markdown","8a46528f":"markdown","e9888d97":"markdown","b437f586":"markdown","f8c5ff57":"markdown","6d28f64d":"markdown","250b87e5":"markdown","6f6061d9":"markdown","0540161d":"markdown","45168bea":"markdown","e7dadbf6":"markdown","fe9c105f":"markdown","63d9ad75":"markdown","e502f706":"markdown","e4f85f66":"markdown","4fd9536b":"markdown"},"source":{"3170eb5f":"import os\nimport glob\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport json\nfrom tqdm.notebook import tqdm\nfrom pathlib import Path\nfrom dataclasses import dataclass","922d96fd":"dataset_path = Path('..\/input\/indoor-location-navigation')\nos.listdir(dataset_path)","7f36e473":"train_sites = os.listdir(dataset_path\/\"train\")\nprint(f'There are {len(train_sites)} sites in the training set')","eb61743b":"example_site = os.listdir(dataset_path\/\"train\")[10]\nexample_site_path = dataset_path\/\"train\"\/example_site\nprint('Floors for example site:')\nprint(os.listdir(example_site_path))","56442ada":"floors_per_site = []\nfor i in os.listdir(dataset_path\/\"train\"): floors_per_site.append(len(os.listdir(dataset_path\/\"train\"\/i)))\nprint(f'There are a total of {sum(floors_per_site)} floors. On average, each site has {np.mean(floors_per_site)} floors')","7109180b":"print('Path text files for example floor:')\nprint(os.listdir(example_site_path\/'B1'))","b41d7be3":"print(f\"There are {len(list((dataset_path\/'train').rglob('*.txt')))} path text files in the training set\")","fa86afed":"print(f\"There are {len(os.listdir(dataset_path\/'test'))} path text files in the test set\")","8cdc4d82":"print(f'There are {len(os.listdir(dataset_path\/\"metadata\"))} sites in the metadata, just like the training set')","f5000779":"metadata_example_site = os.listdir(dataset_path\/\"metadata\")[10]\nmetadata_example_site_path = dataset_path\/\"metadata\"\/metadata_example_site\nmetadata_example_floor_path = dataset_path\/\"metadata\"\/metadata_example_site\/os.listdir(metadata_example_site_path)[0]\nprint(os.listdir(metadata_example_floor_path))","ae9136b4":"Image.open(metadata_example_floor_path\/'floor_image.png')","19663cc5":"with open(metadata_example_floor_path\/'geojson_map.json') as geojson_map:\n    data = json.load(geojson_map)\n    geojson_map.close()\nprint(data)","ca4cf9db":"with open(metadata_example_floor_path\/'floor_info.json') as floor_info:\n    data = json.load(floor_info)\n    floor_info.close()\nprint(data)","27d3da9a":"example_floor_path = example_site_path\/'B1'\nexample_txt_path = example_floor_path\/os.listdir(example_floor_path)[0]","91606fcd":"with open(example_txt_path) as example_txt:\n    data = example_txt.read()\n    example_txt.close()","eaace1a6":"print(data)","2c048e25":"@dataclass\nclass ReadData:\n    acce: np.ndarray\n    acce_uncali: np.ndarray\n    gyro: np.ndarray\n    gyro_uncali: np.ndarray\n    magn: np.ndarray\n    magn_uncali: np.ndarray\n    ahrs: np.ndarray\n    wifi: np.ndarray\n    ibeacon: np.ndarray\n    waypoint: np.ndarray\n\n\ndef read_data_file(data_filename):\n    acce = []\n    acce_uncali = []\n    gyro = []\n    gyro_uncali = []\n    magn = []\n    magn_uncali = []\n    ahrs = []\n    wifi = []\n    ibeacon = []\n    waypoint = []\n\n    with open(data_filename, 'r', encoding='utf-8') as file:\n        lines = file.readlines()\n\n    for line_data in lines:\n        line_data = line_data.strip()\n        if not line_data or line_data[0] == '#':\n            continue\n\n        line_data = line_data.split('\\t')\n\n        if line_data[1] == 'TYPE_ACCELEROMETER':\n            acce.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n            continue\n\n        if line_data[1] == 'TYPE_ACCELEROMETER_UNCALIBRATED':\n            acce_uncali.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n            continue\n\n        if line_data[1] == 'TYPE_GYROSCOPE':\n            gyro.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n            continue\n\n        if line_data[1] == 'TYPE_GYROSCOPE_UNCALIBRATED':\n            gyro_uncali.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n            continue\n\n        if line_data[1] == 'TYPE_MAGNETIC_FIELD':\n            magn.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n            continue\n\n        if line_data[1] == 'TYPE_MAGNETIC_FIELD_UNCALIBRATED':\n            magn_uncali.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n            continue\n\n        if line_data[1] == 'TYPE_ROTATION_VECTOR':\n            ahrs.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])\n            continue\n\n        if line_data[1] == 'TYPE_WIFI':\n            sys_ts = line_data[0]\n            ssid = line_data[2]\n            bssid = line_data[3]\n            rssi = line_data[4]\n            lastseen_ts = line_data[6]\n            wifi_data = [sys_ts, ssid, bssid, rssi, lastseen_ts]\n            wifi.append(wifi_data)\n            continue\n\n        if line_data[1] == 'TYPE_BEACON':\n            ts = line_data[0]\n            uuid = line_data[2]\n            major = line_data[3]\n            minor = line_data[4]\n            rssi = line_data[6]\n            ibeacon_data = [ts, '_'.join([uuid, major, minor]), rssi]\n            ibeacon.append(ibeacon_data)\n            continue\n\n        if line_data[1] == 'TYPE_WAYPOINT':\n            waypoint.append([int(line_data[0]), float(line_data[2]), float(line_data[3])])\n\n    acce = np.array(acce)\n    acce_uncali = np.array(acce_uncali)\n    gyro = np.array(gyro)\n    gyro_uncali = np.array(gyro_uncali)\n    magn = np.array(magn)\n    magn_uncali = np.array(magn_uncali)\n    ahrs = np.array(ahrs)\n    wifi = np.array(wifi)\n    ibeacon = np.array(ibeacon)\n    waypoint = np.array(waypoint)\n\n    return ReadData(acce, acce_uncali, gyro, gyro_uncali, magn, magn_uncali, ahrs, wifi, ibeacon, waypoint)","4a9678b9":"example_data = read_data_file(example_txt_path)","0aad0f3e":"print(example_data.acce.shape)\nprint(example_data.acce_uncali.shape)\nprint(example_data.gyro.shape)\nprint(example_data.gyro_uncali.shape)\nprint(example_data.magn.shape)\nprint(example_data.magn_uncali.shape)\nprint(example_data.ahrs.shape)\nprint(example_data.wifi.shape)\nprint(example_data.ibeacon.shape)\nprint(example_data.waypoint.shape)","8f15ca91":"acce_shape = []\nacce_uncali_shape = []\ngyro_shape = []\ngyro_uncali_shape = []\nmagn_shape = []\nmagn_uncali_shape = []\nahrs_shape = []\nwifi_shape = []\nibeacon_shape = []\ntrain_files = list((dataset_path\/'train').rglob('*.txt'))[:1000] #take a subset for now\nfor i in tqdm(train_files):\n    train_data = read_data_file(i)\n    acce_shape.append(train_data.acce.shape)\n    acce_uncali_shape.append(train_data.acce_uncali.shape)\n    gyro_shape.append(train_data.gyro.shape)\n    gyro_uncali_shape.append(train_data.gyro_uncali.shape)\n    magn_shape.append(train_data.magn.shape)\n    magn_uncali_shape.append(train_data.magn_uncali.shape)\n    ahrs_shape.append(train_data.ahrs.shape)\n    wifi_shape.append(train_data.wifi.shape)\n    ibeacon_shape.append(train_data.ibeacon.shape)\n","6893a1bc":"_ = plt.hist([i[0] for i in acce_shape])\n_ = plt.title('accelerometer # data points training set histogram')","f4fd1876":"_ = plt.hist([i[0] for i in ahrs_shape])\n_ = plt.title('rotation vector # data points training set histogram')","f51d592b":"_ = plt.hist([i[0] for i in wifi_shape])\n_ = plt.title('WiFi # data points training set histogram')","46e193b1":"_ = plt.hist([i[0] for i in ibeacon_shape])\n_ = plt.title('iBeacon # data points training set histogram')","72b11863":"print(f'{sum([i == (0,) for i in ibeacon_shape])} of the training samples are missing iBeacon data')","effd2634":"example_test_data = read_data_file(dataset_path\/'test'\/os.listdir(dataset_path\/'test')[0])","9f8d815c":"print(example_test_data.acce.shape)\nprint(example_test_data.acce_uncali.shape)\nprint(example_test_data.gyro.shape)\nprint(example_test_data.gyro_uncali.shape)\nprint(example_test_data.magn.shape)\nprint(example_test_data.magn_uncali.shape)\nprint(example_test_data.ahrs.shape)\nprint(example_test_data.wifi.shape)\nprint(example_test_data.ibeacon.shape)\nprint(example_test_data.waypoint.shape) # will be zero because this is target","3e4220e5":"acce_shape = []\nacce_uncali_shape = []\ngyro_shape = []\ngyro_uncali_shape = []\nmagn_shape = []\nmagn_uncali_shape = []\nahrs_shape = []\nwifi_shape = []\nibeacon_shape = []\ntest_files = os.listdir(dataset_path\/'test')\nfor i in tqdm(range(len(test_files))):\n    test_data = read_data_file(dataset_path\/'test'\/test_files[i])\n    acce_shape.append(test_data.acce.shape)\n    acce_uncali_shape.append(test_data.acce_uncali.shape)\n    gyro_shape.append(test_data.gyro.shape)\n    gyro_uncali_shape.append(test_data.gyro_uncali.shape)\n    magn_shape.append(test_data.magn.shape)\n    magn_uncali_shape.append(test_data.magn_uncali.shape)\n    ahrs_shape.append(test_data.ahrs.shape)\n    wifi_shape.append(test_data.wifi.shape)\n    ibeacon_shape.append(test_data.ibeacon.shape)\n","9aac56d5":"_ = plt.hist([i[0] for i in acce_shape])\n_ = plt.title('accelerometer # data points test set histogram')","54086881":"_ = plt.hist([i[0] for i in ahrs_shape])\n_ = plt.title('rotation vector # data points test set histogram')","22939ef0":"_ = plt.hist([i[0] for i in wifi_shape])\n_ = plt.title('WiFi # data points test set histogram')","ffe69526":"_ = plt.hist([i[0] for i in ibeacon_shape])\n_ = plt.title('iBeacon # data points test set histogram')","45d1b430":"print(f'{sum([i == (0,) for i in ibeacon_shape])} of the test samples are missing iBeacon data')","eb2b5bfe":"sample_df = pd.read_csv(dataset_path\/'sample_submission.csv')","67e5db14":"sample_df.head(10)","d06e08cc":"unique_test_sites = list(set([j[0] for j in [i.split('_') for i in list(sample_df.site_path_timestamp)]]))\nlen(list(set(unique_test_sites) & set(train_sites))) == len(unique_test_sites)","e20e76d6":"sample_df.to_csv('submission.csv',index=False)","cf295049":"Let's see the shape of the data:","afbd0c1a":"To summarize, this is how the training data is structured:\n\n```\n\u2514\u2500\u2500\u2500train                                                        \/\/raw data from two sites\n      \u2514\u2500\u2500\u2500site1\n      |     \u2514\u2500\u2500\u2500B1                                               \/\/traces from one floor\n      |     |   \u2514\u2500\u2500\u25005dda14a2c5b77e0006b17533.txt                 \/\/trace file                             \n      |     |   | ...\n      |     |\n      |     |\n      |     \u2514\u2500\u2500\u2500F1\n      |     | ...\n      |\n      \u2514\u2500\u2500\u2500site2\n```","084f904b":"We are provided with our train and test data, as well as metadata with additional information about the buildings (including maps) where the data collection took place.\n\nNote that the data is organized by the sites and floors. How many sites do we have in this dataset?\n","131440d8":"Like we did for the training data, let's look at the shape of the test data (code is hidden):","8881653b":"![header.png](attachment:header.png)\n\n# **Indoor Location Navigation EDA**\n\nIn this competition (hosted by [Microsoft Research](https:\/\/www.microsoft.com\/en-us\/research\/)), we aim to predict the position of a smartphone in an indoor location based on smartphone-provided data like accelerometer, gyroscope, magnometer readings, as well as WiFi and Bluetooth scans. The data is taken from hundreds of buildings in China. More details on the data collection is provided [here](https:\/\/github.com\/location-competition\/indoor-location-competition-20) and [here](https:\/\/www.youtube.com\/watch?v=xt3OzMC-XMU).\n\n\nIn this notebook, I will provide an in-depth exploration of the data available for this competition. Please upvote if you find this notebook useful!\n\n# Table of Contents\n\n* [Dataset organization](#1) - Here, I briefly go over how the training and test dataset is organized.\n* [Metadata organization](#2) - Here, I briefly go over what extra information is provided in the metadata.\n* [Path text files](#3) - Here, I briefly analyze the path text files, how to open them, what features are available, etc.\n* [Submission CSV and evaluation](#4) - Here, I show what needs to be predicted and how the results are evaluated.","94f7c35a":"Here is an example text file (unhide the output, it's very long):","94a1d0e2":"<a id=\"4\"><\/a>\n## Submission CSV and evaluation\n\nLastly, let's look at the submission CSV and figure out what we need to predict and how our results are evaluated.","5fb3b463":"Here we have 9 features and the target:\n\n`acce` - accelerometer data \n\n`acce_uncali` - uncalibrated accelerometer data\n\n`gyro` - gyroscope data\n\n`gyro_uncali` - uncalibrated gyroscope data\n\n`magn` - magnetometer data\n\n`magn_uncali` - uncalibrated magnetometer data\n\n`ahrs` - rotation vector data\n\n`wifi` - WiFi data\n\n`ibeacon` - iBeacon data (sometimes can be missing)\n\n`waypoint` - position, target\n\n\nLet's look at the distribution of the number of datapoint for the features in the training data (code is hidden):","0c25f41f":"So every site has about 5 floors.\n\nIn each floor are the path trace text files with the data:","8a46528f":"Also, let's look for missing iBeacon data:","e9888d97":"Each site folder is organized by the floor (a variable to predict!):","b437f586":"<a id=\"2\"><\/a>\n## Metadata organization\n\nNow let's check the metadata. It's organized in the same way the training set is organized. ","f8c5ff57":"<a id=\"1\"><\/a>\n## Dataset organization\n\nLet's see what folders we have:","6d28f64d":"We can see that the shape of the arrays for the accelerometer, gyroscope, and magnetometer measuements are the same, likely because they are coming from the smartphone and sampled simultaneously. Interestingly, this sample is missing iBeacon data, so it looks like sometimes the iBeacon data is not present.\n\nThis function also works with the test files. The test files provide all the same information, except the waypoint, which is the target.","250b87e5":"<a id=\"3\"><\/a>\n## Path text files\n\nLet's look more closely at the path text files and how to process them.\n\nThe [GitHub README](https:\/\/github.com\/location-competition\/indoor-location-competition-20) provides more information about the text file format:\n\n> The first column is Unix Time in millisecond. In specific, we use SensorEvent.timestamp for sensor data and system time for WiFi and Bluetooth scans.\n> \n>The second column is the data type (ten in total).\n>\n>TYPE_ACCELEROMETER\n>\n>TYPE_MAGNETIC_FIELD\n>\n>TYPE_GYROSCOPE\n>\n>TYPE_ROTATION_VECTOR\n>\n>TYPE_MAGNETIC_FIELD_UNCALIBRATED\n>TYPE_GYROSCOPE_UNCALIBRATED\n>\n>TYPE_ACCELEROMETER_UNCALIBRATED\n>\n>TYPE_WIFI\n>\n>TYPE_BEACON\n>\n>TYPE_WAYPOINT: ground truth location labeled by the surveyor\n>\n>Data values start from the third column.\n>\n>Column 3-5 of TYPE_ACCELEROMETER\u3001TYPE_ACCELEROMETER\u3001TYPE_GYROSCOPE\u3001TYPE_ROTATION_VECTOR are SensorEvent.values[0-2] from the callback function onSensorChanged(). Column 6 is SensorEvent.accuracy.\n>\n>Column 3-8 of TYPE_ACCELEROMETER_UNCALIBRATED\u3001TYPE_GYROSCOPE_UNCALIBRATED\u3001TYPE_MAGNETIC_FIELD_UNCALIBRATED are SensorEvent.values[0-5] from the callback function onSensorChanged(). Column 9 is SensorEvent.accuracy.","6f6061d9":"Each floor has metadata with a floor map, floor information, and geographic information.","0540161d":"**THE END**\n\nPlease upvote if you found this notebook useful!","45168bea":"Also, let's look for missing iBeacon data:","e7dadbf6":"The organizers have thankfully provided some code for processing the text files over [here](https:\/\/github.com\/location-competition\/indoor-location-competition-20\/blob\/master\/io_f.py). We will use that code to process our data (code is hidden):","fe9c105f":"We see that we are given the name of the path trace files and we are supposed to predict the floor number, as well as the position (x,y). The name of the path trace file provides the ID for the site as well as the path ID and UNIX timestamp. We can see that the sites in the test site are also present in the training set.","63d9ad75":"Let's now move on to the test set. The test set simply is a collection of path text files:","e502f706":"How many total training path files are there?","e4f85f66":"Let's look at how our submission is evaluated:\n\n> ![image.png](attachment:image.png)\n\nNote that the floor numbers are mapped to integers for the submission file. The above-ground floors are mapped as the floor number minue one. For example F1 would be mapped to 0, F2 to 1, F3 to 2, etc. The below-ground floors are mapped to negative floor numbers. For example B1 is -1, B2 is -2, B3 is -3, etc. There are non-traditional floor numbers in the training set (ex: LG2, LM, etc.) but those are not in the test set.","4fd9536b":"Let's look at a single floor of a single site:"}}