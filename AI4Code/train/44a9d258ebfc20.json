{"cell_type":{"d545426c":"code","2f7dc025":"code","e9552ada":"code","1a52bff0":"code","9fa769a5":"code","765226d7":"code","28c4c97e":"code","72d0c1ac":"code","4037c1cc":"code","0da5ffd4":"code","e80c6006":"code","7e167fc3":"code","e4025d9a":"code","ac97c4f0":"code","2c0988a1":"code","d7667093":"code","e7a51cce":"code","468508bb":"code","ec12bf93":"code","9cb85dbb":"markdown","01a40577":"markdown","25cf9054":"markdown","a738cba5":"markdown","ea014956":"markdown","839d48eb":"markdown","f2c170a6":"markdown","65966e39":"markdown","25cc5963":"markdown","5946c33b":"markdown","c53fe7a4":"markdown","9d54e8b6":"markdown","4f6a4d4e":"markdown","7de2240f":"markdown","775b60ea":"markdown","a5630f6c":"markdown"},"source":{"d545426c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport json\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport random\n\nkaggle_data_path=os.path.join(os.sep, \"kaggle\", \"input\", \"CORD-19-research-challenge\")","2f7dc025":"df = pd.read_csv(kaggle_data_path+\"\/metadata.csv\")","e9552ada":"datafiles = []\nfor dirname, _, filenames in os.walk(kaggle_data_path):\n    for filename in filenames:\n        ifile = os.path.join(dirname, filename)\n        if ifile.split(\".\")[-1] == \"json\":\n            datafiles.append(ifile)","1a52bff0":"citations = []\nfilter_words = ['proc.', 'magazine'] # Words to filter \nremove_names=[\"publisher's note\", \"world health organization\", \"fields virology\", \"united states census\", \"geneva: world health organization\"] # full name to remove\nfor file in datafiles:\n    with open(file,'r')as f:\n        doc = json.load(f)\n    reftitle = doc['metadata']['title'].lower()\n    \n    '''Get citations'''\n    for key,value in doc['bib_entries'].items():\n        value['title'] = value['title'].lower().split('proc.')[0]\n        # ignore remove_names\n        if value['title'] in remove_names: \n            continue\n        # add citation if not containing filter_words\n        if (len(set(value['title'].lower().split(' ')).intersection(set(filter_words))) == 0) and len(value['title'].lower()) > 0:\n            citations.append({\"title\": reftitle, \"citation\": value['title'].lower()})","9fa769a5":"dfc = pd.DataFrame(citations)","765226d7":"G = nx.from_pandas_edgelist(dfc,source='title',target='citation',create_using=nx.DiGraph)","28c4c97e":"print(f\"Reduced citation graph loaded is having {len(list(G.nodes))} nodes and {len(list(G.edges))} edges.\")","72d0c1ac":"# get number of time a paper was cite by others and number of its own citations\ntitle = \"interferon-stimulated gene 15 conjugation stimulates hepatitis b virus production independent of type i interferon signaling pathway in vitro\"\nprint(f\"The paper '{title}' \\n is cited {G.in_degree[title]} times. Its annexe contain {G.out_degree[title]} references.\")","4037c1cc":"nx.write_gpickle(G, \"citation_network.gpickle\")","0da5ffd4":"H= nx.ego_graph(G, title, radius=1)\nsize = 15\nplt.figure(figsize = [size,size]) \npos = nx.spring_layout(H) \nnx.draw(H, with_labels=True, node_size = 20 , node_color = 'lightblue')\nplt.title(f'Paper <<{title}>> ego graph')\nplt.savefig('cite.png')","e80c6006":"graph_size = 20000\nGsub = G.subgraph(list(G.nodes)[0:graph_size])\nprint(f\"Graph loaded is having {len(list(Gsub.nodes))} nodes and {len(list(Gsub.edges))} edges\")","7e167fc3":"max_nodes=2000\nH= Gsub.subgraph(random.sample(list(Gsub.nodes), max_nodes))\nplt.figure(figsize = [15,15]) \npos = nx.spring_layout(H) \nnx.draw(H, with_labels=False, node_size = 10 , node_color = 'lightblue')\nplt.title(f'Random Subgraph of citation network of a subset {max_nodes} papers')\nplt.savefig('cite.png')","e4025d9a":"def get_paper_cited_K_times_graph(G , M = 500) -> nx.DiGraph:\n    \"\"\"\n    Return a network of paper cited at least M times\n    \"\"\"\n    Gs = nx.DiGraph()\n    for node in G.nodes():\n        if G.in_degree[node] > M:\n            # We look for adjacent nodes\n            for adj_node in G.in_edges(\n                    node):  # create link for each paper point to current paper\n                Gs.add_node(adj_node)\n                Gs.add_node(node)\n                Gs.add_edge(adj_node,node)\n    return Gs","ac97c4f0":"N = 40\nG_most_cited = get_paper_cited_K_times_graph(Gsub, N)","2c0988a1":"# This illustrate some article are gathering a lot of attention by the community.\nsize = 15\nplt.figure(figsize = [size,size]) \npos = nx.spring_layout(H) \nnx.draw(G_most_cited, with_labels=False, node_size = 20 , node_color = 'lightblue')\nplt.title(f'Most cited papers')\nplt.savefig('most_cited.png')","d7667093":"%time pr = nx.pagerank(G)","e7a51cce":"pagerank = pd.DataFrame(pr.items(), columns=[\"title\", \"pagerank\"]).sort_values(by=\"pagerank\", ascending=False)","468508bb":"title = pagerank.iloc[0][\"title\"]\nprint(f\"The paper <<{title}>> \\n is cited {G.in_degree[title]} times. Its annexe contain {G.out_degree[title]} references.\")","ec12bf93":"pagerank.to_csv('pagerank.csv')","9cb85dbb":"# Subgraph display","01a40577":"# Display citation graph of a single paper","25cf9054":"simple example usage","a738cba5":"We iterate over the coprus and build up a list of link: article -> citation","ea014956":"We use a subset of the full graph for display , too avoid unreadable spaghettis plots\n\n","839d48eb":"# Intro\n\nWe are a group of engineers at Atos\/Bull.\n\n### Goals\n\n* Generate quickly and simply a citation network of the dataset corpus to provide a insight of the relation between papers\n* Generate a score for each paper depending on their importance in the corpus.  \n* Provide a kaggle dataset so people can reuse this citation graph and the pagerank score of the papers\n\n### What's cool\n* easy & fast\n* reusable since provided as a dataset\n* it is pertinent for any task (to know if a paper is meaningful in the corpus)\n\n### What's less cool\n* to keep thing fast and easy, the matching is made on title lowercase. If a paper is cited with a typo in reference, the match won't be made\n\n### Improvement to come\n* using some fuzzy matching on title strinsg to avoid fails in matches\n","f2c170a6":"# Quickly and simply create a citation network using networkx","65966e39":"# Pagerank to score our papers in corpus","25cc5963":"Thanks to this dataframe contaninig all the edges(links) of the corpus, it is now extremly easy to build up a graph from it","5946c33b":"Create the article->citation dataframe","c53fe7a4":"Hope that might be useful to someone. All the best and stay safe","9d54e8b6":"**Now to reuse this dataset you may simply run : G = nx.read_gpickle(\"test.gpickle\")**","4f6a4d4e":"NetworkX also a us quickly build a pagerank score for each paper. The score provide an insight of how important\/relevant is a paper in the network. See [pagerank](https:\/\/en.wikipedia.org\/wiki\/PageRank) for more details.","7de2240f":"We will show here some papers seems much more central than some others. Therefore might be more relevant to return to researchers when they want to answer a specific task. That something our team is using is this [notebook](http:\/\/https:\/\/www.kaggle.com\/mrmimic\/opinions-extraction-tool-chloroquine-case-study) where we find the closest papers to a question, clustering them by opinion and then give the most relevant papers for each opinion. ","775b60ea":"# Most cited papers graph","a5630f6c":"We output it so someone can reused it if needed"}}