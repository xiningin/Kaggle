{"cell_type":{"3f813060":"code","5cc74851":"code","58aead29":"code","862b77cf":"code","500edef7":"code","06b8d3dc":"code","1efacc32":"code","2195138b":"code","83b8c32e":"code","c9d602b7":"code","7a17d048":"code","3ea34192":"code","21c0447e":"code","835ed6ff":"code","a05107d5":"code","e2dffa81":"code","7242b12e":"code","6c579b7c":"code","9aa8b0d1":"code","a09a4a8f":"code","37fc075a":"code","b2232fda":"code","ab488cce":"code","47ea086a":"code","5ad9aefc":"code","862ef3b2":"code","b7d0854a":"code","c84badc9":"code","6ef5726c":"code","1b69ff16":"code","c2e82774":"code","cd5ccf66":"code","25f6fe25":"code","698ba29c":"code","b2ddbae2":"code","f47e8850":"code","d282f1d2":"code","da684720":"code","bf1dabd0":"code","f53e5640":"code","db9bd875":"code","c1aa1872":"code","5dfd9b1e":"code","4aba91ed":"code","d975af3e":"code","38b52095":"code","b5c40149":"code","ed3a2ace":"code","f1e26007":"code","ee651273":"code","4e6eb69d":"markdown","40020842":"markdown","987b1772":"markdown","8ed71ff4":"markdown","44916dce":"markdown","9af74809":"markdown","f42c7a37":"markdown","e76e169c":"markdown","2b5fa619":"markdown","8bc52752":"markdown","e558ce37":"markdown","0620b751":"markdown","1df0d078":"markdown","87d7d192":"markdown","d49b03c5":"markdown","a42bb553":"markdown","fa38e51d":"markdown"},"source":{"3f813060":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\npd.pandas.set_option('display.max_columns',None)","5cc74851":"dataset=pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/train.csv')\ndataset","58aead29":"feature_with_na=[features for features in dataset.columns if dataset[features].isnull().sum()>1]\n\nfor feature in feature_with_na:\n    print(feature,np.round(dataset[feature].isnull().mean(),4), \"% missing values\")","862b77cf":"for feature in feature_with_na:\n    data=dataset.copy()\n    data[feature]=np.where(data[feature].isnull(),1,0)\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.title(feature)\n    plt.show()","500edef7":"print(f\"Id of houses {len(dataset.Id)}\")","06b8d3dc":"numerical_features=[feature for feature in dataset.columns if dataset[feature].dtypes!='O']\nprint(\"Number of numerical variables: \",len(numerical_features))\ndataset[numerical_features].head()","1efacc32":"# list of variable that contain year variables\nyear_feature=[feature for feature in dataset if 'Yr' in feature or \"Year\" in feature]\nyear_feature","2195138b":"# let's explore the ontent of feature\nfor feature in year_feature:\n    print(feature,dataset[feature].unique())","83b8c32e":"## let's analyze the datatime variable\n\ndataset.groupby('YrSold')['SalePrice'].median().plot()\nplt.xlabel('Year sold')\nplt.ylabel('Median House Price')\nplt.title('House Price vs YearSold')","c9d602b7":"# here we will compare the difference between all years feature with SalePrice\n\nfor feature in year_feature:\n    if feature!='YrSold':\n        data=dataset.copy()\n        data[feature]=data['YrSold']-data[feature]\n        plt.scatter(data[feature],data['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('SalePrice')\n        plt.show()\n        ","7a17d048":"## Numerical variables are usually of 2 type\n## 1. Continous variable and Discrete Variables\n\ndiscrete_features=[feature for feature in numerical_features if len(dataset[feature].unique())<25 and feature not in year_feature+['Id']]\nprint(f\"Discrete Variables Count: {len(discrete_features)}\")","3ea34192":"dataset[discrete_features].head()","21c0447e":"## lets find the relationship between then and salePrice\n\nfor feature in discrete_features:\n    data=dataset.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature)\n    plt.show()","835ed6ff":"continuous_feature=[feature for feature in numerical_features if feature not in discrete_features + year_feature+['Id']]\nprint(f\"Continuous Variables Count: {len(continuous_feature)}\")","a05107d5":"dataset[continuous_feature].head()","e2dffa81":"## lets find the relationship between then and salePrice by creating histograms\n\nfor feature in continuous_feature:\n    data=dataset.copy()\n    data[feature].hist(bins=25)\n    plt.xlabel(feature)\n    plt.ylabel('Count')\n    plt.title(feature)\n    plt.show()","7242b12e":"# we will be using logarithmic transformation\n\nfor feature in continuous_feature:\n    data=dataset.copy()\n    if 0 in data[feature].unique() or feature=='SalePrice':\n        pass\n    else:\n        data[feature]=np.log(data[feature])\n        data['SalePrice']=np.log(data['SalePrice'])\n        plt.scatter(data[feature],data['SalePrice'])\n        plt.xlabel('Feature')\n        plt.ylabel('SalesPrice')\n        plt.title(feature)\n        plt.show()","6c579b7c":"for feature in continuous_feature:\n    data=dataset.copy()\n    if 0 in data[feature].unique() or feature=='SalePrice':\n        pass\n    else:\n        data[feature]=np.log(data[feature])\n        data.boxplot(column=feature)\n        plt.title(feature)\n        plt.show()","9aa8b0d1":"categorical_features=[feature for feature in dataset.columns if data[feature].dtypes=='O']\ncategorical_features","a09a4a8f":"dataset[categorical_features].head()","37fc075a":"for feature in categorical_features:\n    print(f\"The feature is {feature} and number of categories are {len(dataset[feature].unique())}\")","b2232fda":"## find out the relationship between categorical variable and dependent feature\nfor feature in categorical_features:\n    data=dataset.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature)\n    plt.show()","ab488cce":"dataset.head()","47ea086a":"features_nan=[feature for feature in dataset.columns if dataset[feature].isnull().sum()>1 and dataset[feature].dtypes=='O']\nfor feature in features_nan:\n    print(feature,np.round(dataset[feature].isnull().mean(),4), \"% missing values\")","5ad9aefc":"## Replace missing value with a new label\ndef replace_cat_feature(dataset,features_nan):\n    data=dataset.copy()\n    data[features_nan]=data[features_nan].fillna('Missing')\n    return data\ndataset=replace_cat_feature(dataset,features_nan)\ndataset[features_nan].isnull().sum()","862ef3b2":"dataset.head()","b7d0854a":"## now lets check for numerical variables that containes missing values\nnumerical_with_nan=[features for features in dataset.columns if dataset[features].isnull().sum()>1 and dataset[features].dtypes!='O']\nfor feature in numerical_with_nan:\n    print(feature,np.round(dataset[feature].isnull().mean(),4), \"% missing values\")","c84badc9":"# replacing the numerical missing values\n\nfor feature in numerical_with_nan:\n    ## we will replace by using median since there are outliers\n    median_value=dataset[feature].median()\n    \n    ## create a new feature to capture nan values\n    dataset[feature+'nan']=np.where(dataset[feature].isnull(),1,0)\n    dataset[feature].fillna(median_value,inplace=True)\ndataset[numerical_with_nan].isnull().sum()","6ef5726c":"dataset.head()","1b69ff16":"\n## Temporal Variables (Date Time Variables)\n\nfor feature in ['YearBuilt','YearRemodAdd','GarageYrBlt']:\n       \n    dataset[feature]=dataset['YrSold']-dataset[feature]","c2e82774":"dataset[['YearBuilt','YearRemodAdd','GarageYrBlt']].head()","cd5ccf66":"dataset.head()","25f6fe25":"num_features=['LotFrontage','LotArea','1stFlrSF','GrLivArea','SalePrice']\n\nfor feature in num_features:\n    dataset[feature]=np.log(dataset[feature])","698ba29c":"dataset.head()","b2ddbae2":"for feature in categorical_features:\n    temp=dataset.groupby(feature)['SalePrice'].count()\/len(dataset)\n    temp_df=temp[temp>0.01].index\n    dataset[feature]=np.where(dataset[feature].isin(temp_df),dataset[feature],'Rare_var')","f47e8850":"dataset.head(20)","d282f1d2":"for feature in categorical_features:\n    labels_ordered=dataset.groupby([feature])['SalePrice'].mean().sort_values().index\n    labels_ordered={k:i for i,k in enumerate(labels_ordered,0)}\n    dataset[feature]=dataset[feature].map(labels_ordered)","da684720":"dataset.head()","bf1dabd0":"feature_scale=[feature for feature in dataset.columns if feature not in ['Id','SalePrice']]\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\nscaler.fit(dataset[feature_scale])","f53e5640":"scaler.transform(dataset[feature_scale])","db9bd875":"# transform the train and test set, and add on the Id and SalePrice variables\ndata = pd.concat([dataset[['Id', 'SalePrice']].reset_index(drop=True),\n                    pd.DataFrame(scaler.transform(dataset[feature_scale]), columns=feature_scale)],\n                    axis=1)","c1aa1872":"data.head()","5dfd9b1e":"data.to_csv('X_train.csv',index=False)","4aba91ed":"from sklearn.linear_model import Lasso\nfrom sklearn.feature_selection import SelectFromModel","d975af3e":"dataset=pd.read_csv('X_train.csv')\ndataset.head()","38b52095":"## capture dependent feature\ny=dataset['SalePrice']\ny=y[:1459]","b5c40149":"## drop dependent feature from dataset\nX=dataset.drop(['Id','SalePrice'],axis=1)\nX=X[:1459]","ed3a2ace":"### Apply Feature selection\n# first, I specify the lasso regression model, and I\n# select suitable alpha (equivalent of penalty)\n# the bigger the alpha the less feature that will be selected\n\n# Then I use the selectFromModel object from sklearn, which\n# will select the features which coefficients are non-zero\n\nfeature_sel_model=SelectFromModel(Lasso(alpha=0.005,random_state=0))\nfeature_sel_model.fit(X,y)","f1e26007":"feature_sel_model.get_support()","ee651273":"selected_feat=X.columns[(feature_sel_model.get_support())]\n\n# let's print some stats\nprint('total features: {}'.format((X.shape[1])))\nprint('selected features: {}'.format(len(selected_feat)))\nX.shape","4e6eb69d":"## Handaling Rare Categorical Feature\n\nwe will remove categorical variables that are present less than 1% of the observations","40020842":"## outliers","987b1772":"## Continuous Variable","8ed71ff4":"Here with the relation between the missing values and the depenedent variables is clearly visible. So we need to replace these nan values with something meaningful which we will do in feature engineering section.\n\nFrom the above dataset some of the features like id is not required","44916dce":"## Since they are many missing values, we nedd to find the realtionship between missing values and sales price\nLet's plt some diagram for the relationship","9af74809":"## All the Lifecycle In A Data Science Projects\n\n1. Data Analysis\n2. Feature Engineering\n3. Feature Selection\n4. Model Building\n5. Model Deployment","f42c7a37":"## Missing values","e76e169c":"## Feature Engineering\n\nwe will be performing all the below steps in feature engineering\n\n1. Missing Values\n2. Temporal variables\n3. Categorical variables: remove rare labels\n4. Standarise values of the variables to the same range","2b5fa619":"## Feature selection","8bc52752":"## House Prices Prediction ","e558ce37":"## categorical variables","0620b751":"## EDA Part 2","1df0d078":"## Missing Value","87d7d192":"## Feature Scalling ","d49b03c5":"## In data analysis we will Analyze to find out the below stuff\n\n1. Missing values\n2. all the numerical variables\n3. Distribution of the numerical variables\n4. categorical variables\n5. Cardinality of Categorical Variables\n6. Outliers\n7. Relationship between independent feature(SalePrice)","a42bb553":"## Numarical variable","fa38e51d":"## Numerical Variables"}}