{"cell_type":{"4ac96b61":"code","e020c933":"code","97bfc602":"code","dd0eaef5":"code","174c4d82":"code","bf28d513":"code","3c6b47f6":"code","2e16bc5c":"code","f1ef5313":"code","20c64b69":"code","b1cadf7d":"code","3f3f02ba":"code","67083dbc":"code","5339cfa2":"code","3737934e":"code","a521cde7":"code","ee2089eb":"code","0878b1e8":"code","7635e0bc":"code","bc31e032":"code","ea8f7ab4":"code","9d5e4178":"code","fba57ecc":"code","6cfaa113":"code","7afd8403":"code","799db55f":"code","ac2e68a4":"code","80c5577d":"code","264acc28":"code","f6f70a6a":"code","cb2ca36f":"code","0b9e687e":"code","10d8c788":"code","758d205a":"code","f78154ef":"code","388aa55e":"code","5629efc6":"code","750c09aa":"code","3c9af394":"code","dc251d55":"code","4120b26c":"code","3b5639b4":"markdown","0ec1ba5c":"markdown","801ea429":"markdown","cbf21c5f":"markdown","8bc49faf":"markdown","d5b1289e":"markdown","5dd6c9a7":"markdown","e81f6493":"markdown","e4c5a1a3":"markdown","43e27568":"markdown","d15cc3e6":"markdown"},"source":{"4ac96b61":"# import necessary libraries\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nfrom tensorflow.keras import layers, models\nfrom keras.layers import UpSampling2D,Input,LeakyReLU,Lambda,add,Activation,Concatenate\nfrom keras.utils import plot_model\nfrom keras.models import Model\nfrom keras.layers.convolutional import Conv2D\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\nimport tensorflow as tf\nfrom keras.applications import VGG16\nimport math\nfrom keras import backend as K","e020c933":"def PSNR(y_true, y_pred):\n    max_pixel = 1.0\n    return (10.0 * K.log((max_pixel ** 2) \/ (K.mean(K.square(y_pred - y_true), axis=-1))))","97bfc602":"#using generator to load images\ndef train_gen():\n    img_directory = '..\/input\/pascal-voc-2007\/voctrainval_06-nov-2007\/VOCdevkit\/VOC2007\/JPEGImages\/'\n    arr = os.listdir(img_directory)[1000:]\n    for p in arr:\n        img = cv2.imread(img_directory+p)\n        img = np.asarray(img)\/255  \n        img72 = (cv2.resize(img, (72,72), interpolation = cv2.INTER_AREA))\n        img144 = (cv2.resize(img, (144,144), interpolation = cv2.INTER_AREA))\n        img72 = np.expand_dims(img72, axis=0)\n        img144 = np.expand_dims(img144, axis=0)\n        yield [img72,img144]\ndef val_gen_144():\n    img_directory = '..\/input\/pascal-voc-2007\/voctrainval_06-nov-2007\/VOCdevkit\/VOC2007\/JPEGImages\/'\n    arr = os.listdir(img_directory)[:100]\n    for p in arr:\n        img = cv2.imread(img_directory+p)\n        img = np.asarray(img)\/255 \n        img72 = (cv2.resize(img, (72,72), interpolation = cv2.INTER_AREA))\n        img144 = (cv2.resize(img, (144,144), interpolation = cv2.INTER_AREA))\n        img72 = np.expand_dims(img72, axis=0)\n        img144 = np.expand_dims(img144, axis=0)\n        yield [img72,img144]\ndef val_gen_144_288():\n    img_directory = '..\/input\/pascal-voc-2007\/voctrainval_06-nov-2007\/VOCdevkit\/VOC2007\/JPEGImages\/'\n    arr = os.listdir(img_directory)[:100]\n    for p in arr:\n        img = cv2.imread(img_directory+p)\n        img = np.asarray(img)\/255 \n        img72 = (cv2.resize(img, (72,72), interpolation = cv2.INTER_AREA))\n        img144 = (cv2.resize(img, (144,144), interpolation = cv2.INTER_AREA))\n        img72 = np.expand_dims(img72, axis=0)\n        img144 = np.expand_dims(img144, axis=0)\n        img288 = (cv2.resize(img, (288,288), interpolation = cv2.INTER_AREA))\n        img288 = np.expand_dims(img288, axis=0)\n        yield [img72,img144,img288]\ndef data_generator_train(arr_len ,batch = 32):\n    while True:\n        a = train_gen()\n        batchsize = batch\n        for i,j in enumerate(a):\n            if i == 0:\n                r = np.asarray(j[0])\n                t = np.asarray(j[1])\n            else:\n                r = np.concatenate((r,np.asarray(j[0])))\n                t = np.concatenate((t,np.asarray(j[1])))\n            if i % (batchsize-1) == 0 and i != 0 or (i == arr_len-1):\n                yield r[i-(batchsize-1):i],t[i-(batchsize-1):i]\ndef data_generator_val_144(arr_len ,batch = 32):\n    while True:\n        a = val_gen_144()\n        batchsize = batch\n        for i,j in enumerate(a):\n            if i == 0:\n                r = np.asarray(j[0])\n                t = np.asarray(j[1])\n            else:\n                r = np.concatenate((r,np.asarray(j[0])))\n                t = np.concatenate((t,np.asarray(j[1])))\n            if i % (batchsize-1) == 0 and i != 0 or (i == arr_len-1):\n                yield r[i-(batchsize-1):i],t[i-(batchsize-1):i]\ndef data_generator_val_144_288(arr_len ,batch = 32):\n    while True:\n        a = val_gen_144_288()\n        batchsize = batch\n        for i,j in enumerate(a):\n            if i == 0:\n                r = np.asarray(j[0])\n                t = np.asarray(j[1])\n                y = np.asarray(j[2])\n            else:\n                r = np.concatenate((r,np.asarray(j[0])))\n                t = np.concatenate((t,np.asarray(j[1])))\n                y = np.concatenate((y,np.asarray(j[2])))\n                \n            if i % (batchsize-1) == 0 and i != 0 or (i == arr_len-1):\n                yield r[i-(batchsize-1):i],[t[i-(batchsize-1):i],y[i-(batchsize-1):i]]","dd0eaef5":"def load_images(height=72,width=72):\n    img_directory = '..\/input\/pascal-voc-2007\/voctrainval_06-nov-2007\/VOCdevkit\/VOC2007\/JPEGImages\/'\n    arr = os.listdir(img_directory)[0:100]\n    img_array = []\n    for p in arr:\n        img = cv2.imread(img_directory+p)\n        img = np.asarray(img)\/255\n        img_array.append(cv2.resize(img, (height,width), interpolation = cv2.INTER_AREA))\n    return img_array\nimg72 = load_images(72,72)\nimg144 = load_images(144,144)\nimg288 = load_images(288,288)\nimg72 = np.asarray(img72)  \nimg144 = np.asarray(img144)  \nimg288 = np.asarray(img288) ","174c4d82":"# plot func with more then 1 row or col, expect images to be a list\ndef plot_images(images,titles = ['original','original','pred144'],figsize=(15,15)):\n    nrows = len(images[0])\n    ncols = len(images)\n    fig, ax = plt.subplots(nrows = nrows,ncols = ncols,figsize=figsize)\n    fig.tight_layout()\n\n#     fig.subplots_adjust(hspace=0.3, wspace=0.1)\n    for i in range(nrows):\n        for j in range(ncols):\n            ax[i][j].imshow(images[j][i])\n            if i == 0:\n                ax[i][j].set_title(titles[j] + ' size = ' + str(images[j][i].shape))\nplot_images([img72[0:4],img144[0:4],img288[0:4]],['original,','original,','original,'])","bf28d513":"def build_model_step2():\n    inp = Input(shape=(72, 72, 3))\n    x = Conv2D(64, (3, 3), padding='same')(inp)\n    x = LeakyReLU(alpha=0.2)(x)\n    x = Conv2D(64, (3, 3), padding='same')(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    x = UpSampling2D((2,2))(x)\n    x = Conv2D(3, 1,activation = 'sigmoid',padding='same',name = 'output')(x)\n    return Model(inputs=inp, outputs=x)","3c6b47f6":"model1 = build_model_step2()\nmodel1.compile(optimizer='adam', loss='mse',metrics=[PSNR])\nmodel1.summary()\nplot_model(model1, to_file='multiple_outputs.png')","2e16bc5c":"def set_callbacks( name = 'best_model_weights',patience=8,tb_base_logdir='.\/logs\/'):\n#     from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n    cp = ModelCheckpoint(name +'.h5',save_best_only=True)\n    es = EarlyStopping(patience=patience,monitor='val_loss')\n    rlop = ReduceLROnPlateau(patience=patience)\n    return [rlop, es, cp]","f1ef5313":"# work on sample of the data\n# hist1 = model1.fit(img72[0:80], img144[0:80], validation_data=(img72[80:100], img144[80:100]), shuffle=True, epochs=100,batch_size = 64,callbacks = set_callbacks(name = 'model1_weights'))\nbatch = 64\nhist1 = model1.fit_generator(data_generator_val_144(4011,batch),validation_data=data_generator_val_144(1000,batch),\n                             validation_steps = 1000\/\/batch, steps_per_epoch= 4011\/\/batch,epochs=10,callbacks = set_callbacks(name = 'best_model1_weights'))","20c64b69":"def print_loss_psnr(hist,title_name):\n    if len(hist.history.keys()) <= 5:\n        plt.plot(hist.history['loss'], 'r', hist.history['val_loss'], 'b')\n        plt.xlabel('Epochs')\n        plt.ylabel('loss')\n        plt.title(title_name + ' loss')\n        plt.legend(['loss','val_loss'])\n        plt.figure()\n        plt.plot(hist.history['PSNR'], 'r', hist.history['val_PSNR'], 'b')\n        plt.xlabel('Epochs')\n        plt.ylabel('PSNR')\n        plt.title(title_name + ' PSNR')\n        plt.legend(['PSNR','val_PSNR'])\n    else:\n        plt.plot(hist.history['output1_loss'], 'r', hist.history['output2_loss'], 'b',\n                hist.history['val_output1_loss'], 'g', hist.history['val_output2_loss'], 'y')\n        plt.xlabel('Epochs')\n        plt.ylabel('loss')\n        plt.title(title_name + ' loss')\n        plt.legend(['output1_loss','output2_loss','val_output1_loss','val_output2_loss'])\n        plt.figure()\n        plt.plot(hist.history['output1_PSNR'], 'r', hist.history['output2_PSNR'], 'b',\n                hist.history['val_output1_PSNR'], 'g', hist.history['val_output2_PSNR'], 'y')\n        plt.xlabel('Epochs')\n        plt.ylabel('PSNR')\n        plt.title(title_name + ' PSNR')\n        plt.legend(['output1_PSNR','output2_PSNR','val_output1_PSNR','val_output2_PSNR'])","b1cadf7d":"print_loss_psnr(hist = hist1,title_name = 'step 2 - model1')","3f3f02ba":"pred144 = model1.predict(img72[80:100])\nplot_images([img72[80:85],img144[80:85],pred144[0:5]],titles = ['original,','original,','pred,'])","67083dbc":"def build_model_step3():\n    inp = Input(shape=(72, 72, 3))\n    x = Conv2D(64, (3, 3), padding='same')(inp)\n    x = LeakyReLU(alpha=0.2)(x)\n    x = Conv2D(64, (3, 3), padding='same')(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    x = UpSampling2D((2,2))(x)\n    out2 = UpSampling2D((2,2))(x)\n    out2 = Conv2D(3, 1,activation = 'sigmoid', padding='same',name = 'output2')(out2)\n    out1 = Conv2D(3, 1, activation='sigmoid', padding='same',name = 'output1')(x)\n    model = Model(inputs=inp, outputs=[out1, out2])\n#     model.compile(optimizer='adam', loss='mse',loss_weights = [0.1,0.9])\n    return model","5339cfa2":"model2 = build_model_step3()\nmodel2.compile(optimizer='adam', loss='mse',metrics=[PSNR])\nmodel2.summary()\nplot_model(model2, to_file='multiple_outputs.png')","3737934e":"# hist2 = model2.fit(img72[0:80], [img144[0:80],img288[0:80]] ,validation_data=(img72[80:100],[img144[80:100],img288[80:100]]), shuffle=True, epochs=100,batch_size = 64,callbacks = set_callbacks())\nbatch = 64\nhist2 = model2.fit_generator(data_generator_val_144_288(4011,batch),validation_data=data_generator_val_144_288(1000,batch),\n                             validation_steps = 1000\/\/batch, steps_per_epoch= 4011\/\/batch,epochs=10,callbacks = set_callbacks(name = 'best_model2_weights'))\n","a521cde7":"print_loss_psnr(hist = hist2,title_name = 'step 3 model')","ee2089eb":"pred2 = model2.predict(img72[80:100])\nplot_images([img72[80:85],img144[80:85],img288[80:85],pred2[0][0:5],pred2[1][0:5]],titles = ['original,','original,','original,','pred1,','pred2,'])","0878b1e8":"def res(Channels_num = 32):\n    inp = Input(shape=(None,None, Channels_num ))\n    x = (Conv2D(Channels_num, (3, 3), padding='same'))(inp)\n    x = LeakyReLU(alpha=0.2)(x)\n    x = (Conv2D(Channels_num, (3, 3), padding='same'))(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    x = add([x, inp])\n    x = LeakyReLU(alpha=0.2)(x)\n    return Model(inputs=inp, outputs=x)","7635e0bc":"model_res = res()\nmodel_res.summary()\nplot_model(model_res, to_file='multiple_outputs.png')","bc31e032":"def build_model_step4():\n    inp = Input(shape=(72, 72, 3))\n    x = Conv2D(32, (3, 3), padding='same')(inp)\n    x = LeakyReLU(alpha=0.2)(x)\n    x = res(32)(x)\n    x = res(32)(x)\n    x = UpSampling2D((2,2))(x)\n    out1 = Conv2D(3, 1,activation = 'sigmoid', padding='same',name = 'output1')(x)\n    x = res()(x)\n    x = (UpSampling2D((2,2)))(x)\n    out2 = (Conv2D(3, 1, activation = 'sigmoid',padding='same',name = 'output2'))(x)\n    model = Model(inputs=inp, outputs=[out1, out2])\n    return model","ea8f7ab4":"model3 = build_model_step4()\nmodel3.compile(optimizer='adam', loss='mse',metrics=[PSNR])\nmodel3.summary()\nplot_model(model3, to_file='multiple_outputs.png')","9d5e4178":"# hist3 = model3.fit(img72[0:80], [img144[0:80],img288[0:80]] ,validation_data=(img72[80:100],[img144[80:100],img288[80:100]]), shuffle=True, epochs=100,batch_size = 64,callbacks = set_callbacks())\nbatch = 64\nhist3 = model3.fit_generator(data_generator_val_144_288(4011,batch),validation_data=data_generator_val_144_288(1000,batch),\n                             validation_steps = 1000\/\/batch, steps_per_epoch= 4011\/\/batch,epochs=10,callbacks = set_callbacks(name = 'best_model3_weights'))\n","fba57ecc":"print_loss_psnr(hist = hist3,title_name = 'step 4 model')","6cfaa113":"pred3 = model3.predict(img72[80:100])\nplot_images([img72[80:85],img144[80:85],img288[80:85],pred3[0][0:5],pred3[1][0:5]],titles = ['original,','original,','original,','pred1,','pred2,'])","7afd8403":"def dil(Channels_num = 32):\n    inp = Input(shape=(None,None, Channels_num))\n    dil1 = (Conv2D(Channels_num, (3, 3),dilation_rate=1, padding='same'))(inp)\n    dil1 = LeakyReLU(alpha=0.2)(dil1)\n    dil2 = (Conv2D(Channels_num, (3, 3),dilation_rate=2, padding='same'))(inp)\n    dil2 = LeakyReLU(alpha=0.2)(dil2)\n    dil4 = (Conv2D(Channels_num, (3, 3),dilation_rate=4, padding='same'))(inp)\n    dil4 = LeakyReLU(alpha=0.2)(dil4)\n    \n    x = Concatenate()([dil1, dil2,dil4])\n    x = LeakyReLU(alpha=0.2)(x)\n#     x = Activation('relu')(x)\n    out = Conv2D(Channels_num, 3, padding='same')(x)\n    out = LeakyReLU(alpha=0.2)(out)\n    model = Model(inputs=inp, outputs=out)\n    return model","799db55f":"model_dil = dil()\nmodel_dil.summary()\nplot_model(model_dil, to_file='multiple_outputs.png')","ac2e68a4":"def step5_model():\n    inp = Input(shape=(72, 72, 3))\n    x = Conv2D(32, (3, 3), padding='same')(inp)\n    x = LeakyReLU(alpha=0.2)(x)\n    x = dil()(x)\n    x = dil()(x)\n    x = UpSampling2D((2,2))(x)\n    out1 = (Conv2D(3, 1, activation='sigmoid', padding='same',name = 'output1'))(x)\n    x = dil()(x)\n    x = UpSampling2D((2,2))(x)\n    out2 = (Conv2D(3, 1, activation='sigmoid', padding='same',name = 'output2'))(x)\n    model = Model(inputs=inp, outputs=[out1, out2])\n    return model\n# m2 = step5_model()\n","80c5577d":"model4 = step5_model()\nmodel4.compile(optimizer='adam', loss='mse',metrics=[PSNR])\nmodel4.summary()\nplot_model(model4, to_file='multiple_outputs.png')","264acc28":"# hist4 = model4.fit(img72[0:80], [img144[0:80],img288[0:80]] ,validation_data=(img72[80:100],[img144[80:100],img288[80:100]]), shuffle=True, epochs=100,batch_size = 64,callbacks = set_callbacks(patience = 10))\nbatch = 64\nhist4 = model4.fit_generator(data_generator_val_144_288(4011,batch),validation_data=data_generator_val_144_288(1000,batch),\n                             validation_steps = 1000\/\/batch, steps_per_epoch= 4011\/\/batch,epochs=10,callbacks = set_callbacks(name = 'best_model4_weights'))","f6f70a6a":"print_loss_psnr(hist = hist4,title_name = 'step 5 model')","cb2ca36f":"pred4 = model4.predict(img72[80:100])\nplot_images([img72[80:85],img144[80:85],img288[80:85],pred4[0][0:5],pred4[1][0:5]],titles = ['original,','original,','original,','pred1,','pred2,'])","0b9e687e":"def step6_model():\n    vgg_model = VGG16(weights='imagenet',include_top=False,input_shape=(72, 72, 3))\n    block1_conv2 = Model(inputs=vgg_model.input, outputs=vgg_model.get_layer('block1_conv2').output)\n\n    inp = Input(shape=(72, 72, 3))\n    x = Conv2D(64, (3, 3), padding='same')(inp)\n    x = LeakyReLU(alpha=0.2)(x)\n    x = Conv2D(64, (3, 3), padding='same')(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    \n    FeatureEx = block1_conv2(inp)\n        \n\n    x = Concatenate()([x, FeatureEx])\n\n    x = UpSampling2D((2,2))(x)\n    out1 = (Conv2D(3, 1, activation='sigmoid', padding='same',name = 'output1'))(x)\n    \n    x = UpSampling2D((2,2))(x)\n    out2 = (Conv2D(3, 1, activation='sigmoid', padding='same',name = 'output2'))(x)\n    model = Model(inputs=inp, outputs=[out1, out2])\n    return model","10d8c788":"model5 = step6_model()\nmodel5.compile(optimizer='adam', loss='mse',metrics=[PSNR])\nmodel5.summary()\nplot_model(model5, to_file='multiple_outputs.png')","758d205a":"# hist5 = model5.fit(img72[0:80], [img144[0:80],img288[0:80]] ,validation_data=(img72[80:100],[img144[80:100],img288[80:100]]), shuffle=True, epochs=100,batch_size = 64,callbacks = set_callbacks())\nhist5 = model5.fit_generator(data_generator_val_144_288(4011,batch),validation_data=data_generator_val_144_288(1000,batch),\n                             validation_steps = 1000\/\/batch, steps_per_epoch= 4011\/\/batch,epochs=10,callbacks = set_callbacks(name = 'best_model5_weights'))","f78154ef":"print_loss_psnr(hist = hist5,title_name = 'step 6 model')","388aa55e":"pred5 = model5.predict(img72[80:100])\nplot_images([img72[80:85],img144[80:85],img288[80:85],pred5[0][0:5],pred5[1][0:5]],titles = ['original,','original,','original,','pred1,','pred2,'])","5629efc6":"def step7_model():\n    vgg_model = VGG16(weights='imagenet',include_top=False,input_shape=(72, 72, 3))\n    block1_conv2 = Model(inputs=vgg_model.input, outputs=vgg_model.get_layer('block1_conv2').output)\n\n    inp = Input(shape=(72, 72, 3))\n    x = Conv2D(64, (3, 3), padding='same')(inp)\n    x = LeakyReLU(alpha=0.2)(x)\n    x = Conv2D(64, (3, 3), padding='same')(x)\n    x = LeakyReLU(alpha=0.2)(x)\n    \n    FeatureEx = block1_conv2(inp)\n        \n\n    x = Concatenate()([x, FeatureEx])\n\n    sub_layer = Lambda(lambda x:tf.nn.depth_to_space(x,2))\n    x = sub_layer(inputs=x)\n    out1 = (Conv2D(3, 1, activation='sigmoid', padding='same',name = 'output1'))(x)\n    \n#     x = Conv2D(64, (3, 3), padding='same')(x)\n#     x = LeakyReLU(alpha=0.2)(x)\n    \n    x = sub_layer(inputs=x)\n    out2 = (Conv2D(3, 1, activation='sigmoid', padding='same',name = 'output2'))(x)\n    model = Model(inputs=inp, outputs=[out1, out2])\n    return model\n","750c09aa":"model6 = step7_model()\nmodel6.compile(optimizer='adam', loss='mse',metrics=[PSNR])\nmodel6.summary()\nplot_model(model6, to_file='multiple_outputs.png')","3c9af394":"# hist6 = model6.fit(img72[0:80], [img144[0:80],img288[0:80]] ,validation_data=(img72[80:100],[img144[80:100],img288[80:100]]), shuffle=True, epochs=100,batch_size = 64,callbacks = set_callbacks())\nhist6 = model6.fit_generator(data_generator_val_144_288(4011,batch),validation_data=data_generator_val_144_288(1000,batch),\n                             validation_steps = 1000\/\/batch, steps_per_epoch= 4011\/\/batch,epochs=10,callbacks = set_callbacks(name = 'best_model1_weights'))","dc251d55":"print_loss_psnr(hist = hist6,title_name = 'step 7 model')","4120b26c":"pred6 = model6.predict(img72[80:100])\nplot_images([img72[80:85],img144[80:85],img288[80:85],pred6[0][0:5],pred6[1][0:5]],titles = ['original,','original,','original,','pred1,','pred2,'])","3b5639b4":"# model 3 (step 4)","0ec1ba5c":"# Model 4 (step 5)","801ea429":"# Define evaluation metric PSNR","cbf21c5f":"# Plot some Examples","8bc49faf":"# Model 5 (step 6)","d5b1289e":"# Model 6 (step 7)","5dd6c9a7":"Written by: Yaniv Rotaru <br>\nDeep Learning workshop - Class Assignment (assignment 3 - Image super-resolution)\n\n","e81f6493":"# Second model (step 3)","e4c5a1a3":"# Using Generators to save RAM and load all the data\nfirst 1000 images for validation <br>\nThe rest for training (4011)","43e27568":"# First model (step 2)","d15cc3e6":"# Conclusion:\n* We can see that there are variety of methods in the field of super-resolution (and i assume that there are much more) <br>\n* our evaluation metric was PSNR which computes the signal - to - noise ratio, ideally we want infinite value - the higher the better. <br>\n* All of our models PSNR values was more or less around 73 for the 144 resolution prediction and 70 for the 288 resolution prediction. <br>\n* models 3 and 5 achieved the highest scores, model 3 uses residual blocks (inspired by ResNet), and model 5 uses feature extraction from the pretrained vgg model. <br>\n* If we look carefully, we can notice that the 144 resolution prediction benefits better picture comparing to the 72 resolution, but still not as good as the original 144 resolution. <br> \n"}}