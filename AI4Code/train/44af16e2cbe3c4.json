{"cell_type":{"3bcc0d28":"code","764f9da5":"code","d94b75e1":"code","e4ece5a8":"code","20b2b27f":"code","8dd50331":"code","e35c2346":"code","96770f42":"code","b4fd227c":"code","b2b0d0f4":"code","d6c7db89":"code","5ab44c4c":"code","211404f1":"code","0df81aaa":"code","35d2cc34":"code","d174cfc1":"code","b2cd6265":"code","9c5540ed":"code","e87124ca":"code","07edecc0":"markdown","2228e162":"markdown","e7be4aaf":"markdown","60b3b475":"markdown","0a12c19e":"markdown","13d67897":"markdown","60924ce9":"markdown","383a3f00":"markdown","82de151d":"markdown"},"source":{"3bcc0d28":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport numpy as np\nimport torch\nfrom torchvision import datasets, transforms\nimport matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F","764f9da5":"# Define a transform to normalize the data\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\n# Download and load the training data\ntrainset = datasets.FashionMNIST('~\/.pytorch\/F_MNIST_data\/', download=True, train=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n\n# Download and load the testing data\ntestset = datasets.FashionMNIST('~\/.pytorch\/F_MNIST_data\/', download=True, train=False, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)","d94b75e1":"# helper functions\ndef imshow(image, ax=None, title=None, normalize=True):\n    \"\"\"Imshow for Tensor.\"\"\"\n    if ax is None:\n        fig, ax = plt.subplots()\n    image = image.numpy().transpose((1, 2, 0))\n\n    if normalize:\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n        image = std * image + mean\n        image = np.clip(image, 0, 1)\n\n    ax.imshow(image)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.tick_params(axis='both', length=0)\n    ax.set_xticklabels('')\n    ax.set_yticklabels('')\n\n    return ax\n\ndef view_classify(img, ps, version=\"MNIST\"):\n    ''' Function for viewing an image and it's predicted classes.\n    '''\n    ps = ps.data.numpy().squeeze()\n\n    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n    ax1.axis('off')\n    ax2.barh(np.arange(10), ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(np.arange(10))\n    if version == \"MNIST\":\n        ax2.set_yticklabels(np.arange(10))\n    elif version == \"Fashion\":\n        ax2.set_yticklabels(['T-shirt\/top',\n                            'Trouser',\n                            'Pullover',\n                            'Dress',\n                            'Coat',\n                            'Sandal',\n                            'Shirt',\n                            'Sneaker',\n                            'Bag',\n                            'Ankle Boot'], size='small');\n    ax2.set_title('Class Probability')\n    ax2.set_xlim(0, 1.1)\n\n    plt.tight_layout()","e4ece5a8":"image, label = next(iter(trainloader))\nimshow(image[0,:]);","20b2b27f":"model = nn.Sequential(nn.Linear(784, 256),\n                      nn.ReLU(),\n                      nn.Linear(256, 128),\n                      nn.ReLU(),\n                      nn.Linear(128, 64),\n                      nn.ReLU(),\n                      nn.Linear(64, 10),\n                      nn.LogSoftmax(dim=1))\n","8dd50331":"criterion = nn.NLLLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.03)\n\nepochs = 30\ntrain_losses, test_losses = [], []\n\nfor e in range(epochs):\n    running_loss = 0\n    for images, labels in trainloader:\n        images = images.view(images.shape[0], -1)\n        optimizer.zero_grad()\n        logps = model(images)\n        loss = criterion(logps, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    else:\n        test_loss = 0\n        accuracy = 0\n        # Turn off gradients for validation, saves memory and computations\n        with torch.no_grad():\n            for test_images, test_labels in testloader:\n                test_images = test_images.view(test_images.shape[0], -1)\n                logps = model(test_images)\n                test_loss += criterion(logps, test_labels)\n                ps = torch.exp(logps)\n                top_p, top_class = ps.topk(1, dim=1)\n                equals = top_class == test_labels.view(*top_class.shape)\n                accuracy += torch.mean(equals.type(torch.FloatTensor))\n        \n        train_losses.append(running_loss\/len(trainloader))\n        test_losses.append(test_loss\/len(testloader))\n        \n        print(\"Epoch {}\/{}..\".format(e+1, epochs),\n              \"Training loss: {:.3f}..\".format(train_losses[-1]),\n              \"Test loss: {:.3f}..\".format(test_losses[-1]),\n              \"Test Accuracy: {:.3f}%\".format(accuracy\/len(testloader)))\n        ","e35c2346":"plt.plot(train_losses, label='Training loss')\nplt.plot(test_losses, label='Validation loss')\nplt.legend(frameon=False)","96770f42":"# Test out your network!\n\ndataiter = iter(testloader)\nimages, labels = dataiter.next()\nimg = images[0]\n# Convert 2D image to 1D vector\nimg = img.resize_(1, 784)\n\n# Calculate the class probabilities (softmax) for img\n# Turn off gradients to speed up this part\nwith torch.no_grad():\n    logps = model(img)\n\nps = torch.exp(logps)\n\n# Plot the image and probabilities\nview_classify(img.resize_(1, 28, 28), ps, version='Fashion');","b4fd227c":"class Classifier(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(784, 256)\n        self.fc2 = nn.Linear(256, 128)\n        self.fc3 = nn.Linear(128, 64)\n        self.fc4 = nn.Linear(64, 10)\n        \n        # Dropout module with 0.2 drop probability\n        self.dropout = nn.Dropout(p=0.2)\n        \n    def forward(self, x):\n        x = self.dropout(F.relu(self.fc1(x)))\n        x = self.dropout(F.relu(self.fc2(x)))\n        x = self.dropout(F.relu(self.fc3(x)))\n        return F.log_softmax(self.fc4(x), dim=1)\n        ","b2b0d0f4":"model = Classifier()\n\ncriterion = nn.NLLLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.003)\n\nepochs = 30\n\ntrain_losses, test_losses = [], []\n\nfor e in range(epochs):\n    running_loss = 0\n    for images, labels in trainloader:\n        images = images.view(images.shape[0], -1)\n        optimizer.zero_grad()\n        logps = model(images)\n        loss = criterion(logps, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    else:\n        test_loss = 0\n        accuracy = 0\n        # Turn off gradients for validation, saves memory and computations\n        with torch.no_grad():\n            # set model to evaluation mode\n            model.eval()\n            \n            # validation pass\n            for test_images, test_labels in testloader:\n                test_images = test_images.view(test_images.shape[0], -1)\n                logps = model(test_images)\n                test_loss += criterion(logps, test_labels)\n                ps = torch.exp(logps)\n                top_p, top_class = ps.topk(1, dim=1)\n                equals = top_class == test_labels.view(*top_class.shape)\n                accuracy += torch.mean(equals.type(torch.FloatTensor))\n        \n        # set model back to train mode\n        model.train()\n        \n        train_losses.append(running_loss\/len(trainloader))\n        test_losses.append(test_loss\/len(testloader))\n                \n        print(\"Epoch {}\/{}..\".format(e+1, epochs),\n              \"Training loss: {:.3f}..\".format(train_losses[-1]),\n              \"Test loss: {:.3f}..\".format(test_losses[-1]),\n              \"Test Accuracy: {:.3f}%\".format(accuracy\/len(testloader)))\n","d6c7db89":"plt.plot(train_losses, label='Training loss')\nplt.plot(test_losses, label='Validation loss')\nplt.legend(frameon=False)","5ab44c4c":"# Test out your network!\n\nmodel.eval()\n\ndataiter = iter(testloader)\nimages, labels = dataiter.next()\nimg = images[0]\n# Convert 2D image to 1D vector\nimg = img.view(1, 784)\n\n# Calculate the class probabilities (softmax) for img\nwith torch.no_grad():\n    output = model.forward(img)\n\nps = torch.exp(output)\n\n# Plot the image and probabilities\nview_classify(img.view(1, 28, 28), ps, version='Fashion')","211404f1":"checkpoint = {'input_size': 784,\n              'output_size': 10,\n              'hidden_layers': [each.out_features for each in model.hidden_layers],\n              'state_dict': model.state_dict()}\n\ntorch.save(checkpoint, 'checkpoint.pth')","0df81aaa":"torch.save(model.state_dict(), 'checkpoint.pth')","35d2cc34":"model2 = Classifier()\nmodel2.load_state_dict(torch.load('checkpoint.pth'))\nmodel2.eval()","d174cfc1":"# Test out your loaded model!\n\nmodel2.eval()\n\ndataiter = iter(testloader)\nimages, labels = dataiter.next()\nimg = images[0]\n# Convert 2D image to 1D vector\nimg = img.view(1, 784)\n\n# Calculate the class probabilities (softmax) for img\nwith torch.no_grad():\n    output = model2.forward(img)\n\nps = torch.exp(output)\n\n# Plot the image and probabilities\nview_classify(img.view(1, 28, 28), ps, version='Fashion')","b2cd6265":"torch.save(model, 'checkpoint2.pth')","9c5540ed":"# Model class must be defined somewhere\nmodel3 = torch.load('checkpoint2.pth')\nmodel3.eval()\n","e87124ca":"model3.eval()\n\ndataiter = iter(testloader)\nimages, labels = dataiter.next()\nimg = images[0]\n# Convert 2D image to 1D vector\nimg = img.view(1, 784)\n\n# Calculate the class probabilities (softmax) for img\nwith torch.no_grad():\n    output = model2.forward(img)\n\nps = torch.exp(output)\n\n# Plot the image and probabilities\nview_classify(img.view(1, 28, 28), ps, version='Fashion')","07edecc0":"### Train the network\nFirst I'll define the criterion ( something like nn.CrossEntropyLoss) and the optimizer (typically optim.SGD or optim.Adam).\n\nThen write the training code. Remember the training pass is a fairly straightforward process:\n\nMake a forward pass through the network to get the logits\nUse the logits to calculate the loss\nPerform a backward pass through the network with loss.backward() to calculate the gradients\nTake a step with the optimizer to update the weights\nBy adjusting the hyperparameters (hidden units, learning rate, etc), I should be able to get the training loss below 0.4.","2228e162":"### Classifying Fashion-MNIST\nLet's build and train a neural network. I'll be using the Fashion-MNIST dataset, a drop-in replacement for the MNIST dataset. MNIST is actually quite trivial with neural networks where you can easily achieve better than 97% accuracy. Fashion-MNIST is a set of 28x28 greyscale images of clothes. It's more complex than MNIST, so it's a better representation of the actual performance of your network, and a better representation of datasets you'll use in the real world.\n\nFirst off, let's import required libraries and load the dataset through torchvision.","e7be4aaf":"**Save\/Load Entire Model**\nThis save\/load process uses the most intuitive syntax and involves the least amount of code. Saving a model in this way will save the entire module using Python\u2019s pickle module. The disadvantage of this approach is that the serialized data is bound to the specific classes and the exact directory structure used when the model is saved. The reason for this is because pickle does not save the model class itself. Rather, it saves a path to the file containing the class, which is used during load time. Because of this, your code can break in various ways when used in other projects or after refactors.","60b3b475":"### Inference","0a12c19e":"### Building the network\nHere I'll define network. As with MNIST, each image is 28x28 which is a total of 784 pixels, and there are 10 classes. I will use ReLU activations for the hidden layers and nn.LogSoftmax to return the logits or log-softmax from the forward pass. It's up to you how many layers you add and the size of those layers.","13d67897":"As we can see that test loss is not decreasing and it is in fact increasing over more epochs, this proves that our model is over fitting.\n\nThe network learns the training set better and better, resulting in lower training losses. However, it starts having problems generalizing to data outside the training set leading to the validation loss increasing. The ultimate goal of any deep learning model is to make predictions on new data, so we should strive to get the lowest validation loss possible. One option is to use the version of the model with the lowest validation loss, here the one around 8-10 training epochs. This strategy is called early-stopping. In practice, you'd save the model frequently as you're training then later choose the model with the lowest validation loss.\n\nThe most common method to reduce overfitting (outside of early-stopping) is dropout, where we randomly drop input units. This forces the network to share information between weights, increasing it's ability to generalize to new data. Adding dropout in PyTorch is straightforward using the nn.Dropout module. \nLet's build a new model with droput.","60924ce9":"When saving a model for inference, it is only necessary to save the trained model\u2019s learned parameters. Saving the model\u2019s state_dict with the torch.save() function will give you the most flexibility for restoring the model later, which is why it is the recommended method for saving models.\n\nA common PyTorch convention is to save models using either a .pt or .pth file extension.\n\nRemember that you must call model.eval() to set dropout and batch normalization layers to evaluation mode before running inference. Failing to do this will yield inconsistent inference results.","383a3f00":"### Saving and Loading Models\nIn this section, I'll show you how to save and load models with PyTorch. This is important because you'll often want to load previously trained models to use in making predictions or to continue training on new data.\n\nAs you can imagine, it's impractical to train a network every time you need to use it. Instead, we can save trained networks then load them later to train more or use them for predictions.\n\nThe parameters for PyTorch networks are stored in a model's state_dict. We can see the state dict contains the weight and bias matrices for each of our layers. The simplest thing to do is simply save the state dict with torch.save. For example, we can save it to a file 'checkpoint.pth'. Then we can load the state dict with torch.load. And to load the state dict in to the network, you do model.load_state_dict(state_dict).\nSeems pretty straightforward, but as usual it's a bit more complicated. Loading the state dict works only if the model architecture is exactly the same as the checkpoint architecture. If I create a model with a different architecture, this fails.\nThis means we need to rebuild the model exactly as it was when trained. Information about the model architecture needs to be saved in the checkpoint, along with the state dict. To do this, you build a dictionary with all the information you need to compeletely rebuild the model.","82de151d":"Here we can see one of the images."}}