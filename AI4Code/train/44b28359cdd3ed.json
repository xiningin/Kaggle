{"cell_type":{"4130f1d0":"code","c736ee9b":"code","1315b3ca":"code","d4b51c4a":"code","03675ef9":"code","c123ee9d":"code","763d8373":"code","fceb52fa":"code","b1755eb4":"code","5a08461b":"code","318e7be2":"code","cb046614":"code","e14d5120":"code","9ee3562a":"code","a1bf16f0":"markdown","c7afb36a":"markdown","c5c27d9d":"markdown","c68d0d67":"markdown","bb6736d2":"markdown","0405a100":"markdown","e2e72fbf":"markdown"},"source":{"4130f1d0":"import pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical # convert to one-hot-encoding\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import CategoricalCrossentropy\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n# Set the random seed\nrandom_seed = 2\n%matplotlib inline\n\nnp.random.seed(2)\n\nsns.set(style='white', context='notebook', palette='deep')","c736ee9b":"# Load the data\nX = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\n\nY = X[\"label\"]\nX.drop(\"label\",axis = 1, inplace = True) \n","1315b3ca":"tmp = X.iloc[3].values\ntmp = tmp.reshape(28, 28)\nplt.imshow(tmp)","d4b51c4a":"X.shape","03675ef9":"# Check the data\nnp.sum(X.isnull().any())","c123ee9d":"sum(test.isnull().any())","763d8373":"test.isnull().any().describe()","fceb52fa":"# Set the CNN model \n# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n\ndef get_model(optim, loss):\n    model = Sequential()\n\n    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\n    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(0.25))\n\n\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\n    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n    model.add(Dropout(0.25))\n\n\n    model.add(Flatten())\n    model.add(Dense(256, activation = \"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(10, activation = \"softmax\"))\n    model.compile(optimizer= optim, loss=loss, metrics=['accuracy'])\n    return model\n\n\ndef normalize(X, Y = None):\n    X = X \/ 255.0\n    X = X.values.reshape(-1,28,28,1)\n    # Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n    if Y is not None:\n        Y = Y.values.reshape(-1,1)\n    return X,Y\n  \n\n# data augmentation and train validation split\ndef get_samples(X, Y, encoder, val_size = 0.9):\n    X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size = val_size, random_state=42,  stratify= Y)\n    X_train = np.vstack([X_train,X_train,X_train])\n    y_train = np.concatenate([y_train, y_train, y_train])\n    # random shuffle\n    idx = np.arange(0, X_train.shape[0])\n    np.random.shuffle(idx)\n    X_train = X_train[idx,:]\n    y_train = y_train[idx]\n    X_train = X_train.reshape(-1,28,28,1)\n    X_val = X_val.reshape(-1,28,28,1)\n    y_train = encoder.transform(y_train).todense()\n    y_val = encoder.transform(y_val).todense()\n    return X_train,X_val,y_train,y_val","b1755eb4":"X_train,Y_train = normalize(X,Y)\nX_test,_ = normalize(test)\n\nencoder = OneHotEncoder()\nencoder.fit(Y_train)","5a08461b":"\n# Data augmentation\n #- Randomly rotate some training images by 10 degrees\n #- Randomly  Zoom by 10% some training images\n #- Randomly shift images horizontally by 10% of the width\n #- Randomly shift images vertically by 10% of the height\n\ndata_generator = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n# compute quantities required for featurewise normalization\n# (std, mean, and principal components if ZCA whitening is applied)","318e7be2":"EPOCHS = 50\nBATCH_SIZE = 20\nENSEMBLES = 7 # number of models to ensemble\nresults = np.zeros((test.shape[0],10))\nhistories = []\nmodels = []\n\n\ncallback_list = [\n    ReduceLROnPlateau(monitor='val_loss', factor=0.25, min_lr=0.00001, patience=2, verbose=1),\n    EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=3, verbose=1)\n]\n\noptimizer = Adam(learning_rate=0.001)\nloss_fn = CategoricalCrossentropy()","cb046614":"for i in range(ENSEMBLES):\n    # split training and validation sets\n    X_train_tmp, X_val, y_train_tmp, y_val = get_samples(X_train, Y_train, encoder)\n    data_generator.fit(X_train_tmp)\n    # create model\n    models.append(get_model(optimizer, loss_fn))\n    # fit the model\n    history = models[i].fit_generator(data_generator.flow(X_train_tmp, y_train_tmp, batch_size=BATCH_SIZE),\n                   epochs=EPOCHS,\n                   callbacks=[callback_list],\n                   validation_data=(X_val, y_val),\n                   steps_per_epoch=X_train_tmp.shape[0] \/\/ BATCH_SIZE,\n                   use_multiprocessing=True,\n                   verbose = 2)\n    # save results\n    histories.append(history)","e14d5120":"#Result\nresults = np.zeros((X_test.shape[0],10)) \nfor i in range(ENSEMBLES):\n    results = results + models[i].predict(X_test)\n \nresults = np.argmax(results, axis = 1)","9ee3562a":"submission = pd.DataFrame({\"ImageID\": range(1,len(results)+1), \"Label\": results})\nsubmission.to_csv('submission.csv', index=False)","a1bf16f0":"# 1. Data preparation\n## Load data. Normalize","c7afb36a":"# 2 CNN\n## Define the model","c5c27d9d":"# CNN Keras MNIST - using ensembles + data augmentation","c68d0d67":"# 3. Generate submission","bb6736d2":"## Control number of training data per class","0405a100":"## Check for null and missing values","e2e72fbf":"## Train the ensemble of models"}}