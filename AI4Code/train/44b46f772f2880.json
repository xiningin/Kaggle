{"cell_type":{"10f676ad":"code","45395321":"code","89c31d40":"code","db5a2e24":"code","bb50a2a0":"code","2a4fb59c":"code","9d9664e1":"code","014c282c":"code","08956bc4":"code","175664c8":"code","fd5c1c32":"code","f977fbf8":"code","02a68f6b":"code","71d7d8ae":"code","c4105210":"code","fd212c57":"code","7bcac218":"code","60639ce0":"code","4b0672d9":"code","22a71ea9":"code","4f68500b":"code","7fcaf159":"code","d7ac5c8d":"code","c0e21113":"code","c90fa65e":"code","a8ebfbe2":"code","28079809":"code","b1cf0fdc":"code","7dcf7170":"code","3cd7dd97":"code","605b0d3e":"code","206b245c":"code","2090b842":"code","03fe012b":"code","290f2372":"code","1a6e1fd3":"markdown","035f254f":"markdown","0f3d55f8":"markdown","803eb99b":"markdown","83d96a21":"markdown","bcab6433":"markdown","d8db6439":"markdown","9913e260":"markdown","a7db02cf":"markdown","3952cae6":"markdown","c9c878dd":"markdown","22bfa6f0":"markdown","e5af07c8":"markdown","80261b18":"markdown","8b594f51":"markdown","6a7565f1":"markdown","1c0efb36":"markdown","4c5812a0":"markdown","885ea17a":"markdown","f9db5e2d":"markdown","52f56cf1":"markdown","6b212e34":"markdown","633b396c":"markdown","c2ee473a":"markdown","fee7278b":"markdown","72cfa786":"markdown","6b5f4944":"markdown","42175272":"markdown","59595868":"markdown","000e84a7":"markdown","87e49100":"markdown","f5589d96":"markdown","d360379a":"markdown","62040550":"markdown","adb12dd5":"markdown","e56a3edb":"markdown","f16a9950":"markdown","bfa7cc8c":"markdown","787a4f76":"markdown","b537d418":"markdown","a04541d8":"markdown","d151d488":"markdown","f2da0e8f":"markdown","de36a06d":"markdown","306bbb89":"markdown","7fb13c33":"markdown","98dfe023":"markdown","bdb2e2be":"markdown","4a88729b":"markdown","b6d1f9ef":"markdown","047cec51":"markdown"},"source":{"10f676ad":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt","45395321":"dataset = pd.read_csv('..\/input\/xAPI-Edu-Data.csv')\ndataset.head(5)","89c31d40":"df = dataset[['gender','PlaceofBirth','StageID','Topic','raisedhands','VisITedResources','AnnouncementsView','Discussion', 'ParentAnsweringSurvey','ParentschoolSatisfaction','StudentAbsenceDays', 'Class']]\ndf.head()","db5a2e24":"df.groupby(['ParentschoolSatisfaction'])['Class'].value_counts(normalize=True)\n","bb50a2a0":"df.groupby(['ParentAnsweringSurvey'])['ParentschoolSatisfaction'].value_counts(normalize=True)","2a4fb59c":"df.groupby(['ParentAnsweringSurvey'])['Class'].value_counts(normalize=True)","9d9664e1":"df2 = dataset[['gender','raisedhands','VisITedResources','AnnouncementsView','Discussion','StudentAbsenceDays', 'Class']]\ndf2.head()","014c282c":"df2['raisedhands'] = pd.cut(df2.raisedhands, bins=3, labels=np.arange(3), right=False)\ndf2.groupby(['raisedhands'])['Class'].value_counts(normalize=True)","08956bc4":"df2['VisITedResources'] = pd.cut(df2.VisITedResources, bins=3, labels=np.arange(3), right=False)\ndf2.groupby(['VisITedResources'])['Class'].value_counts(normalize=True)","175664c8":"df2['AnnouncementsView'] = pd.cut(df2.AnnouncementsView, bins=3, labels=np.arange(3), right=False)\ndf2.groupby(['AnnouncementsView'])['Class'].value_counts(normalize=True)","fd5c1c32":"df2['Discussion'] = pd.cut(df2.Discussion, bins=3, labels=np.arange(3), right=False)\ndf2.groupby(['Discussion'])['Class'].value_counts(normalize=True)","f977fbf8":"df2.groupby(['StudentAbsenceDays'])['Class'].value_counts(normalize=True)","02a68f6b":"df2 = dataset[['gender','raisedhands','VisITedResources','AnnouncementsView','Discussion','StudentAbsenceDays', 'Class']]\ndf2.tail()\n","71d7d8ae":"correlation = df2[['raisedhands','VisITedResources','AnnouncementsView','Discussion']].corr(method='pearson')\ncorrelation","c4105210":"df2 = pd.concat([df2,pd.get_dummies(df2['gender'], prefix='gender_')], axis=1)\ndf2 = pd.concat([df2,pd.get_dummies(df2['StudentAbsenceDays'], prefix='absence_')], axis=1)\ndf2 = pd.concat([df2,pd.get_dummies(df2['Class'], prefix='class_')], axis=1)\n\ndf2.drop(['gender'], axis = 1,inplace=True)\ndf2.drop(['StudentAbsenceDays'], axis = 1,inplace=True)\ndf2.drop(['Class'], axis = 1,inplace=True)\n\ndf2.head()","fd212c57":"from sklearn.cluster import KMeans\nfrom sklearn import preprocessing","7bcac218":"X = df2[['raisedhands', 'VisITedResources']].values\n#NORMALIZE OUR ARRAY\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(X)\n#GET X AXIS\nX = pd.DataFrame(x_scaled).values\nX[:5]","60639ce0":"wcss = []\n \nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++')\n    kmeans.fit(X)\n    #print (i,kmeans.inertia_)\n    wcss.append(kmeans.inertia_)  \nplt.plot(range(1, 11), wcss)\nplt.title('Elbow Method')\nplt.xlabel('N of Clusters')\nplt.ylabel('WSS') #within cluster sum of squares\nplt.show()","4b0672d9":"kmeans = KMeans(n_clusters = 3, init = 'k-means++')\nkmeans.fit(X)","22a71ea9":"k_means_labels = kmeans.labels_\nk_means_cluster_centers = kmeans.cluster_centers_","4f68500b":"import matplotlib.pyplot as plt\n\nplt.scatter(X[:, 0], X[:,1], s = 10, c = kmeans.labels_)\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 30, c = 'red',label = 'Centroids')\nplt.title('Students Clustering')\nplt.xlabel('RaisedHands')\nplt.ylabel('VisITedResources')\nplt.legend()\n\nplt.show()","7fcaf159":"df3 = dataset[['raisedhands','VisITedResources','AnnouncementsView','Discussion','Class']]\ndf3.head()","d7ac5c8d":"y = df3['Class'].values\ny[0:5]","c0e21113":"X = df3[['raisedhands', 'VisITedResources', 'AnnouncementsView', 'Discussion']].values\nX= preprocessing.StandardScaler().fit(X).transform(X)\nX[:5]","c90fa65e":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)","a8ebfbe2":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\n\nKs = 10\nmean_acc = np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\nConfustionMx = [];\nfor n in range(1,Ks):\n    \n    #Train Model and Predict  \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n    yhat=neigh.predict(X_test)\n    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n\n    \n    std_acc[n-1]=np.std(yhat==y_test)\/np.sqrt(yhat.shape[0])\n\nprint( \"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1) ","28079809":"#REBUILDING THE MODEL WITH BEST K\nk = 4\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\nneigh","b1cf0fdc":"from sklearn.tree import DecisionTreeClassifier\nDtree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\nDtree.fit(X_train,y_train)\nDtree","7dcf7170":"from sklearn import svm\nsupMac = svm.SVC(kernel='rbf', gamma='auto')\nsupMac.fit(X_train, y_train) ","3cd7dd97":"from sklearn.linear_model import LogisticRegression\nLR = LogisticRegression(C=0.01, solver='liblinear', multi_class='auto').fit(X_train,y_train)\nLR","605b0d3e":"from sklearn.metrics import jaccard_similarity_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss","206b245c":"knn_yhat = neigh.predict(X_test)\nprint(\"KNN Jaccard index: %.2f\" % jaccard_similarity_score(y_test, knn_yhat))\nprint(\"KNN F1-score: %.2f\" % f1_score(y_test, knn_yhat, average='weighted') )","2090b842":"dtree_yhat = Dtree.predict(X_test)\nprint(\"Decision Tree Jaccard index: %.2f\" % jaccard_similarity_score(y_test, dtree_yhat))\nprint(\"Decision Tree F1-score: %.2f\" % f1_score(y_test, dtree_yhat, average='weighted') )","03fe012b":"svm_yhat = supMac.predict(X_test)\nprint(\"SVM Jaccard index: %.2f\" % jaccard_similarity_score(y_test, svm_yhat))\nprint(\"SVM F1-score: %.2f\" % f1_score(y_test, svm_yhat, average='weighted') )","290f2372":"LR_yhat = LR.predict(X_test)\nLR_yhat_prob = LR.predict_proba(X_test)\nprint(\"LR Jaccard index: %.2f\" % jaccard_similarity_score(y_test, LR_yhat))\nprint(\"LR F1-score: %.2f\" % f1_score(y_test, LR_yhat, average='weighted') )\nprint(\"LR LogLoss: %.2f\" % log_loss(y_test, LR_yhat_prob))","1a6e1fd3":"The presented research focused in data analytics and building a machine learning model to understand the student's behavior and classification under online learning courses.\nThe results concluded some points:\n* Parents active participation and tracking are important. Absent parents are linked to absent students and more unsatisfaction with the school.\n* Students who read announcements and visit the course resources are most likely to have higher classification.\n* Actions related to discussions are less likely to improve student's classification.\n","035f254f":"### 4.1.1 Clustering DataSet","0f3d55f8":"Data analytics and Data Science are vital fields for improving Online Courses experience. Set the right content for the right student is a complex but essential task to keep the students enrolled, motivated and getting high classification. This will, with no doubt, improve education levels of their countries and help to improve their economy. Despite that, online learning has a potential value for increasing society levels.","803eb99b":"Concluding this step on analysis, we're going to understand the absence rate with the grade level","83d96a21":"Now it's time to build a model to predict the student's classification based on his actions on the Online Learning enviroment.","bcab6433":"So, the ideal K is 3. Now we are going to build the Kmeans with k=3","d8db6439":"Next, it is important to know what characteristics are linked to students sucess. So, we're going to test the features related.","9913e260":"### Question: What's the relation between raising hands and classification?","a7db02cf":"As mentioned, this section will understand the data in order to compose the clustering dataset.","3952cae6":"The act of visualizing the announcements makes the students more prepared for the tasks and they are most likely to plan the assessments of the week. High visualization frequency is lined, indeed, to better classifications.","c9c878dd":"In the context to understand the student and his results, setting up a dataframe with certain columns","22bfa6f0":"It seems that parents which aren't envolved in answering the scholar's surveys are likely to become unsatisfied with the School. This can mean that well informed parents can better understand the student's enrollment and reality and are better satisfied.","e5af07c8":"# 2. Data\nA description of the data and how it will be used to solve the problem\n\nTo guide my investigation, I was looking for a Set to help to understand the student's behavior, motivation and correlated characteristics in order to better understand why or how is the result of an enrollment. So, it is important to find a dataset with some key features like grade, gender, enrollment levels, and so on. Location data is also important to understand cultural marks, which will be explored by locations APIs.\nGuided by the analysis exploration, I'll be able to build a model to predict student's behavior or results.\nAfter querying correlated datasets in order to find those with better columns, I found a nice DataSet from Kaggle called \"Students' Academic Performance Dataset\". You can check it here https:\/\/www.kaggle.com\/aljarah\/xAPI-Edu-Data.\n<p> The data compounds 16 columns with aggregated informations about over 480 students of a Learning Platform called Kalboard360. The datails will be shown next section.\n","80261b18":"### 4.1 Exploratory Analysis","8b594f51":"Create the train | test sets","6a7565f1":"Try to understand the results from countries","1c0efb36":"So, definitively parent's active behavior has an important role on student's growth.","4c5812a0":"Low levels of resource exploring means lower levels of classification. High levels of visiting resources are linked to higher classification.","885ea17a":"As a final result, a predictive model is offered in order to help the online platforms to understand the student's acts and take decisions. The best model was the K-Nearest neighbors with k=4 and accuracy of 0.65 Jaccard Index.\nFinally, it is important to mention that location data was not possible to be used. That's because it refers to Born location of the student and this is not a important feature. So, it could be a more important data the place where the student was conected, because the high absence levels could be related to poor Internet connection areas, like conflicted-areas and under development countries. So, this research can be used as a starting point for further works and model adaptation.","f9db5e2d":"As previously mentioned, this dataset includes 16 columns:\n\n1. Gender - student's gender (nominal: 'Male' or 'Female\u2019)\n\n2. Nationality- student's nationality (nominal:\u2019 Kuwait\u2019,\u2019 Lebanon\u2019,\u2019 Egypt\u2019,\u2019 SaudiArabia\u2019,\u2019 USA\u2019,\u2019 Jordan\u2019,\u2019 Venezuela\u2019,\u2019 Iran\u2019,\u2019 Tunis\u2019,\u2019 Morocco\u2019,\u2019 Syria\u2019,\u2019 Palestine\u2019,\u2019 Iraq\u2019,\u2019 Lybia\u2019)\n\n3. Place of birth- student's Place of birth (nominal:\u2019 Kuwait\u2019,\u2019 Lebanon\u2019,\u2019 Egypt\u2019,\u2019 SaudiArabia\u2019,\u2019 USA\u2019,\u2019 Jordan\u2019,\u2019 Venezuela\u2019,\u2019 Iran\u2019,\u2019 Tunis\u2019,\u2019 Morocco\u2019,\u2019 Syria\u2019,\u2019 Palestine\u2019,\u2019 Iraq\u2019,\u2019 Lybia\u2019)\n\n4. Educational Stages- educational level student belongs (nominal: \u2018lowerlevel\u2019,\u2019MiddleSchool\u2019,\u2019HighSchool\u2019)\n\n5. Grade Levels- grade student belongs (nominal: \u2018G-01\u2019, \u2018G-02\u2019, \u2018G-03\u2019, \u2018G-04\u2019, \u2018G-05\u2019, \u2018G-06\u2019, \u2018G-07\u2019, \u2018G-08\u2019, \u2018G-09\u2019, \u2018G-10\u2019, \u2018G-11\u2019, \u2018G-12 \u2018)\n\n6. Section ID- classroom student belongs (nominal:\u2019A\u2019,\u2019B\u2019,\u2019C\u2019)\n\n7. Topic- course topic (nominal:\u2019 English\u2019,\u2019 Spanish\u2019, \u2018French\u2019,\u2019 Arabic\u2019,\u2019 IT\u2019,\u2019 Math\u2019,\u2019 Chemistry\u2019, \u2018Biology\u2019, \u2018Science\u2019,\u2019 History\u2019,\u2019 Quran\u2019,\u2019 Geology\u2019)\n\n8. Semester- school year semester (nominal:\u2019 First\u2019,\u2019 Second\u2019)\n\n9. Parent responsible for student (nominal:\u2019mom\u2019,\u2019father\u2019)\n\n10. Raised hand- how many times the student raises his\/her hand on classroom (numeric:0-100)\n\n11. Visited resources- how many times the student visits a course content(numeric:0-100)\n\n12. Viewing announcements-how many times the student checks the new announcements(numeric:0-100)\n\n13. Discussion groups- how many times the student participate on discussion groups (numeric:0-100)\n\n14. Parent Answering Survey- parent answered the surveys which are provided from school or not (nominal:\u2019Yes\u2019,\u2019No\u2019)\n\n15. Parent School Satisfaction- the Degree of parent satisfaction from school(nominal:\u2019Yes\u2019,\u2019No\u2019)\n\n16. Student Absence Days-the number of absence days for each student (nominal: above-7, under-7)\n\nThe most important characteristic of this dataset is that it has included the parent's data, which is a nice approach to understand the student.","52f56cf1":"#### Suport Vector Machine - SVM","6b212e34":"Using the Elbow Method to find the best K for Kmeans based on our data","633b396c":"So, now we can see 3 clusters: \n* High applied Students\n* Mid Applied Students\n* Low Applied Students","c2ee473a":"As expected, the lower the absence of the student, the higher tends to become their classification. Let's keep this feature.","fee7278b":"#### KNN","72cfa786":"So, we need an <b>one hot encoding<\/b> on columns gender,absence and class","6b5f4944":"# 4. Analysis","42175272":"Let's identify the correlations between the student's actions","59595868":"# 3. Methodology\n\nThe first steps are the data exploration and insight-taking approach in order to better understand the data and the columns. The purpose of this exploratory analysis is to identify hidden features and understand the relations between the features.\nNext, I'll do a descritive analysis by building a dataset for a clustering algorithm. This way, the data understanding will become a more powerfull decision making, focused on student's behaviors.\nFinally, I'll create a my predictive analysis by building a dataset with the best features for a supervised learning algorithm to predict the student's beahvior under certain conditions, which will achieve my final objective.","000e84a7":"Extract our dependent variable Y","87e49100":"#### Decision Tree","f5589d96":"### Question: What is the relation between active parents and student's classification?","d360379a":"Suprisingly, discussion frequency is weakly linked to higher results, at least, directly. Of course, there are higher interactions levels ocrring with Higher graded students but the data shows that discussion is a secondary act.","62040550":"# Results and Discussion","adb12dd5":"### Model Performance","e56a3edb":"## 2.1 Data Structure","f16a9950":"# Analyzing Student's Behavior and Model suggestion for classification levels\n### Marlon Ferrari\n> #### This Data Science project was made under Capstone Data Science IBM Certification Program.","bfa7cc8c":"### 4.1.2 Building a supervised algorithm","787a4f76":"## Table of contents\n* [Introduction: Business Problem](#introduction)\n* [Data](#data)\n* [Methodology](#methodology)\n* [Analysis](#analysis)\n* [Results and Discussion](#results)\n* [Conclusion](#conclusion)","b537d418":"Gets X independent variables and normalize them","a04541d8":"Now that we know what are the important features to understand the student's behavior and classification, we're going to build a dataset for a K-Means algorithm, which will show the student's cluster.","d151d488":"## Understanding student's behavior ","f2da0e8f":"# 1. Introduction <a name=\"introduction\"><\/a>\nA description of the problem and a discussion of the background\n\nThe Internet revolution brought more than social medias and faster information exchanges. It brought also a generation of people who studies through the digital environments. Under this context, the online education evolved quickly and the transformation of the societies really started. Nowadays, people in distant places, poor countries can benefit from technology to achieve information and in this case, the Massive Open Online Courses, MOOCs had a major role.\nMOOCs can join people all around the world to achieve understand in a wide range of areas, delivering science and culture.\n\nIt is known, also, that online learning suffers massive unenrollment. The logical border and the lack of motivation can make the students leave. Under this context, what are the related features which causes it? How understand the student scenario and predict his churn or low grades?\nI think that is a relevant point. If MOOCs platforms achieve student understanding and predicting, I think it's possible to menage the student's churn and find a way to give them the needed motivation.\n\nWith this set in mind, I started a search for MOOCs generated Students Data to investigate and prepare some conclusions about the theme.\n","de36a06d":"To make the construction process easiest to understand, we're going to reimplement the dataset building phases.","306bbb89":"# Conclusion","7fb13c33":"So, it seems that students which has low levels of raising hands are most likely to have Low classification. In the otherside, high frequency of raising hands are linked to higher classification.","98dfe023":"#### Logistic Regression","bdb2e2be":"Next, we're going to check the act of visiting the course resources.","4a88729b":"This made clear that our best correlated features are raisedHands and visitedResources, which will compose our model dataset further.","b6d1f9ef":"So, based on previous exploratory analysis, was possible to identify that raised hands and announcements visualization brings most results respect high classification. So, both features will compound our X axis","047cec51":"Now, we're going to check the accuracy and performance of the following models:\n\n* K Nearest Neighbor(KNN)\n* Decision Tree\n* Support Vector Machine\n* Logistic Regression"}}