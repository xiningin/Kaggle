{"cell_type":{"ca0cb9b4":"code","558bdc54":"code","3c07595f":"code","1e10f12e":"code","83bec983":"code","867a973f":"code","87a061e9":"code","5811297a":"code","0299fbe5":"code","2805b827":"code","ad84508d":"code","719a52ef":"code","90d4134f":"code","9f19b7b2":"code","6aaa65a2":"code","e60855f9":"code","1c2b7a15":"code","07553619":"code","188b8b24":"code","230a6c11":"code","2f43184a":"code","e76f41a6":"code","292c7e13":"code","54b9ada3":"code","ebce1567":"code","3f4196c7":"code","4694fa1a":"code","fa656e5a":"code","a538d8e4":"code","b554ad33":"code","08a0db3f":"code","57af78ea":"code","e1727a9a":"code","fff7e5e6":"code","dd78743e":"code","9213e914":"code","df0fc63a":"code","c5612482":"code","52303697":"code","6ee8a2c6":"code","d4875d71":"code","1b49d036":"code","ab984c34":"code","54d8f023":"code","3cf709ba":"code","a61943b0":"code","77cae66f":"code","00640c75":"code","6510b08b":"code","f998211b":"code","46841932":"code","48a3388a":"code","022abc67":"markdown","ff34a138":"markdown","117fb5fc":"markdown","f599eddf":"markdown","74992cc6":"markdown","e1f3c75e":"markdown","23f4500c":"markdown","1f5c5c21":"markdown","2de4258c":"markdown","974d3253":"markdown","cdafa4fb":"markdown","f339ce2a":"markdown","33509e98":"markdown","5f9f8777":"markdown","b1924f21":"markdown"},"source":{"ca0cb9b4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfullpath = os.path.join(dirname,filename)\ndata = pd.read_csv(fullpath)\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current sessio","558bdc54":"#%%timeit\n%matplotlib inline\nimport sklearn \nimport pickle\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\n\nfrom sklearn.pipeline import Pipeline\nfrom collections import Counter\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit,cross_val_score,KFold,cross_val_predict,RepeatedStratifiedKFold,StratifiedShuffleSplit\n\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import svm\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score ,f1_score,confusion_matrix,precision_recall_curve,plot_precision_recall_curve,average_precision_score,balanced_accuracy_score,classification_report,plot_confusion_matrix,roc_auc_score,plot_roc_curve,average_precision_score\n\n\n\nimport numpy as np \nimport matplotlib.pyplot as plt \nimport yellowbrick as yb # For the styles\n\nfrom sklearn.base import clone \nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics.classification import _check_targets\nfrom sklearn.utils.multiclass import unique_labels\nfrom sklearn.utils.validation import check_consistent_length\nfrom sklearn.externals.joblib import Parallel, delayed","3c07595f":"data.head(3)","1e10f12e":"#data['AppointmentDay'] = pd.to_datetime(data['AppointmentDay'],errors='coerce')\n#data['ScheduledDay'] = pd.to_datetime(data['ScheduledDay'],errors='coerce')\ndata.ScheduledDay =  data.ScheduledDay.apply(np.datetime64)\ndata.AppointmentDay =  data.AppointmentDay.apply(np.datetime64)\n\ndata['appointment_day'] = data['AppointmentDay'].dt.day_name()\ndata['scaduled_day'] = data['ScheduledDay'].dt.day_name()\ndata[\"waiting_days\"] = abs(data.AppointmentDay - data.ScheduledDay).dt.days\ndata.waiting_days.head(20)","83bec983":"data=data.rename(columns={\n                         \"Handcap\":\"Handicap\",\n                         \"No-show\": \"Show\"\n                         })","867a973f":"data.head(3)","87a061e9":"df=data.copy()","5811297a":"days={'Saturday':0,'Sunday':1,'Monday':2,'Tuesday':3,'Wednesday':4,'Thursday':5,'Friday':6}\ngender={'F':0 , 'M':1 }\ndata['scaduled_day'] = data.scaduled_day.map(days)\ndata['appointment_day'] = data.appointment_day.map(days)\ndata['Gender']=data.Gender.map(gender)","0299fbe5":"y = data['Show']\ny.replace('No',1,inplace=True)\ny.replace('Yes',0,inplace=True)","2805b827":"print('Age:',sorted(data.Age.unique()))\nprint('Gender:',data.Gender.unique())\nprint('scaduled_day:',data.scaduled_day.unique())\nprint('appointment_day:',data.appointment_day.unique())\nprint('waiting_days',sorted(data.waiting_days.unique()))\n","ad84508d":"%matplotlib inline\nsns.stripplot(data = data, y = 'waiting_days', jitter = True)","719a52ef":"data = data[data.waiting_days < 350]","90d4134f":"df.head(2)","9f19b7b2":"\ndef probStatus(dataset, group_by):\n    # count no-show \/showup with respct to age\n    df = pd.crosstab(index=dataset[group_by], columns=dataset.Show).reset_index()\n    df['probShowUp'] = df['No'] \/ (df['No'] + df['Yes'])\n    return df[[group_by, 'probShowUp']]","6aaa65a2":"dfprop.head(1)","e60855f9":"dfprop = probStatus(df,'Age')\nageplot = sns.lmplot(data = dfprop, x='Age', y='probShowUp', fit_reg=True)\nageplot.set(xlim=(0, 100), title='Probability of showing up with respect to Age')","1c2b7a15":"def calculateHour(timestamp):\n    timestamp = str(timestamp)\n    hour = int(timestamp[11:13])\n    minute = int(timestamp[14:16])\n    second = int(timestamp[17:])\n    return round(hour + minute\/60 + second\/3600)\n\ndf['HourOfTheDay'] = df.ScheduledDay.apply(calculateHour)","07553619":"data.head(1)","188b8b24":"df.head(1)","230a6c11":"#dfhour=probStatus(data, 'HourOfTheDay')\n\nH = sns.lmplot(data = probStatus(df, 'HourOfTheDay'), x = 'HourOfTheDay', \n           y = 'probShowUp', fit_reg = True)\nH.set(title=('Probability of showing up with respect to HourOfTheDay'))\n\n\nT = sns.lmplot(data = probStatus(df, 'waiting_days'), x = 'waiting_days', \n           y = 'probShowUp', fit_reg = True)\n\nT.set(title=('Probability of showing up with respect to AwaitingTime'),\n     ylim=(0, 1))\n","2f43184a":"sns.countplot(x='Show', data=df)\nplt.show()","e76f41a6":"sns.countplot(x='Gender', data=df, palette = 'plasma')\nplt.show()\n","292c7e13":"plt.figure(figsize=(20,50))\nct = pd.crosstab(data.Age, data['Show'])\nct.plot.bar(stacked=True)\nplt.show()","54b9ada3":"ct = pd.crosstab(df.Gender, df['Show'])\nct.plot.bar(stacked=True)\nplt.show()\nx=data['Gender']\nprint(Counter(x))\n\nScholarship = sns.countplot(x = 'Gender', hue = 'Show', data = df)\nScholarship.set_title('Gender Attendence')\nplt.xlabel('Gender')\nplt.ylabel('No of Visits')\nplt.show()","ebce1567":"ct = pd.crosstab(df.Scholarship, df['Show'])\nct.plot.bar(stacked=True)\nplt.show()\nx=data['Scholarship']\nprint(Counter(x))","3f4196c7":"Scholarship = sns.countplot(x = 'Scholarship', hue = 'Show', data = data)\nScholarship.set_title('Scholarship status for patients')\nplt.xlabel('Scholarship received Status')\nplt.ylabel('No of Visits')\nplt.show()","4694fa1a":"cat_list = ['Scholarship','Gender',  'Hipertension', 'Diabetes', 'Alcoholism']\nfor col in cat_list:\n    col1 =pd.crosstab(df[col],df['Show'])\n    x=df[col]\n    print(Counter(x))\n    #ct.plot.bar(stacked=True)\n   # plt.show()\n    col1.div(col1.sum(1).astype(float), axis=0).plot(kind=\"bar\",  stacked=True, figsize=(4,4));\n","fa656e5a":"categories = pd.Series(['same day: 0', 'week: 1-7', 'month: 8-30', 'quarter: 31-90', 'semester: 91-180', 'a lot of time: >180'])\ndf['waiting_days_categories'] = pd.cut(df.waiting_days, bins = [-1, 0, 7, 30, 90, 180, 500], labels=categories)\nplt.figure(figsize=(1,6))\nct = pd.crosstab(df.waiting_days_categories, df['Show'])\nct.plot.bar(stacked=True)\nplt.show()\nx=df['waiting_days_categories']\nprint(Counter(x))","a538d8e4":"plt.figure(figsize=(1,6))\nct = pd.crosstab(df.SMS_received, df['Show'])\nct.plot.bar(stacked=True)\nplt.show()","b554ad33":"plt.figure(figsize=(1,6))\nct = pd.crosstab(df.appointment_day, df['Show'])\nct.plot.bar(stacked=True)\nplt.show()\nfrom collections import Counter\nx=df['appointment_day']\nprint(Counter(x))","08a0db3f":"plt.figure(figsize=(1,6))\nct = pd.crosstab(df.scaduled_day , df['Show'])\nct.plot.bar(stacked=True)\nplt.show()\nfrom collections import Counter\nx=df['scaduled_day']\nprint(Counter(x))","57af78ea":"data=data.drop(['AppointmentID','ScheduledDay','AppointmentDay','Neighbourhood'],axis=1)\ndata.head(3)","e1727a9a":"\ndata.drop(data[(data.Age < 0) | (data.Age > 100)].index, inplace = True)","fff7e5e6":"scaler=StandardScaler()\ndata['Age'] = scaler.fit_transform(data[['Age']])\ndata['PatientId'] = scaler.fit_transform(data[['PatientId']])","dd78743e":"print(\"Columns with Missing Values::\",data.columns[data.isnull().any()].tolist())\nprint(\"Number of rows with Missing Values::\",len(pd.isnull(data).any(1).to_numpy().nonzero()[0].tolist()))\nprint(\"Sample Indices with missing data::\",pd.isnull(data).any(1).to_numpy().nonzero()[0].tolist()[0:5] )","9213e914":"print(df['Show'].value_counts())\nprint('No show', round(df['Show'].value_counts()[0]\/len(df) * 100,2), '% of the dataset')\nprint('show', round(df['Show'].value_counts()[1]\/len(df) * 100,2), '% of the dataset')","df0fc63a":"osa=data.copy()\nosa.head(2)","c5612482":"from sklearn.utils import resample\n\n# Separate input features and target\ny = osa.Show\nX = osa.drop('Show', axis=1)\n\n# setting up testing and training sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27)\n\n# concatenate our training data back together\nX = pd.concat([X_train, y_train], axis=1)\n\n# separate minority and majority classes\nno_show = X[X.Show==0]\nshow = X[X.Show==1]\n\n# upsample minority\nnoshow_upsampled = resample(show,\n                          replace=True, # sample with replacement\n                          n_samples=len(no_show), # match number in majority class\n                          random_state=27) # reproducible results\n\n# combine majority and upsampled minority\nupsampled = pd.concat([no_show, noshow_upsampled])\n\n# check new class counts\nprint(upsampled.Show.value_counts())\nprint(upsampled.Show.shape)\n   ","52303697":"upsampled.head(2)","6ee8a2c6":"y = upsampled.Show\nX = upsampled.drop('Show', axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27)\n#clf=LogisticRegression(solver='liblinear')\n#clf=SVC(kernel='linear')\n#clf=DecisionTreeClassifier(max_depth=5,min_samples_leaf=12)\nclf= RandomForestClassifier(n_estimators=1000, random_state=42)\n#clf=LinearSVC()\n#upsampled = LogisticRegression(solver='liblinear').fit(X_train, y_train)\nclf.fit(X_train, y_train)\nupsampled_pred = clf.predict(X_test)\n\n# Checking accuracy\naccuracy_score(y_test, upsampled_pred)\n#    0.9807\n    \n# f1 score\nf1_score(y_test, upsampled_pred)\n #   0.1437\n    \nrecall_score(y_test, upsampled_pred)\n#    0.8712\n# Checking unique values\npredictions = pd.DataFrame(upsampled_pred)\ncl=classification_report(y_test,upsampled_pred)\nprint(cl)\ncm=confusion_matrix(y_test, upsampled_pred)\nprint(cm)","d4875d71":"CV = StratifiedShuffleSplit(n_splits=7, test_size=0.2, random_state=100)\nscore=['accuracy','f1']\nscores=cross_validate(clf, X, y, cv=CV, scoring=score)\nprint(sorted(scores.keys()))\nprint(scores['test_accuracy'])\nprint(scores[ 'test_f1'])","1b49d036":"#plot ROC curve\nclf_disp = plot_roc_curve(clf, X_test, y_test)\nplt.show()","ab984c34":"y_pred = clf.predict(X_test)\naverage_precision = average_precision_score(y_test, y_pred)\n\nprint('Average precision-recall score: {0:0.2f}'.format(\n      average_precision))","54d8f023":"#Plot precision and recall curve\ndisp = plot_precision_recall_curve(clf, X_test, y_test)\ndisp.ax_.set_title('2-class Precision-Recall curve: '\n                   'AP={0:0.2f}'.format(average_precision))\n","3cf709ba":"rfc = clf\npred=rfc.fit(X_train, y_train)\nax = plt.gca()\nrfc_disp = plot_roc_curve(rfc, X_test, y_test, ax=ax, alpha=0.8)\nclf_disp.plot(ax=ax, alpha=0.8)\nplt.show()","a61943b0":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)\n\nax= plt.subplot()\nsns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n# labels, title and ticks\nax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(['no-show', 'Show']); ax.yaxis.set_ticklabels(['no-show', 'Show']);","77cae66f":"plot_confusion_matrix(clf, X_test, y_test,)  \nplt.show()  ","00640c75":"#make a function to plot result and compare predicted and actual \ndef plot_target(y_true, y_pred, labels=None, ax=None, width=0.35, **kwargs):\n    # Validate the input \n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n    \n    if y_type not in (\"binary\", \"multiclass\"):\n        raise ValueError(\"%s is not supported\" % y_type)\n    \n\n    # This is probably not necessary \n    check_consistent_length(y_true, y_pred)\n    \n    # Manage the labels passed in (yb might use classes for this arg)\n    if labels is None:\n        labels = unique_labels(y_true, y_pred)\n    else:\n        labels = np.asarray(labels)\n        if np.all([l not in y_true for l in labels]):\n            raise ValueError(\"At least one label specified must be in y_true\")\n\n\n    # Count the values of y_true and y_pred for each class\n    indices = np.arange(0, labels.shape[0]) \n\n    # This expects labels to be numerically encoded, not strings \n    # YB needs to handle either case better, though _check_targets \n    # may deal with this, I'm not sure - need to review the code. \n    # Needless to say this is a HACK that needs to be addressed. \n    t_counts = np.array([(y_true==label).sum() for label in indices])\n    p_counts = np.array([(y_pred==label).sum() for label in indices])\n    \n    # Begin the figure \n    if ax is None:\n        _, ax = plt.subplots()\n\n    b1 = ax.bar(indices, t_counts, width, color='b', label=\"actual\")\n    b2 = ax.bar(indices+width, p_counts, width, color='g', label=\"predicted\")\n\n    ax.set_xticks(indices + width\/2)\n    ax.set_xticklabels(labels)\n    ax.set_xlabel(\"class\")\n    ax.set_ylabel(\"number of instances\")\n    ax.legend(loc='best', frameon=True)\n    ax.grid(False, axis='x')\n\n    return ax\n\n\n\n","6510b08b":"#Plot result on test data \nplot_target(y_test, y_pred) \nplt.show()","f998211b":"\nX_list=list(X_test)\ny_list=list(y_test)\nprint(pred)\n#print(X_test)\n#print(X_list)\n#print(y_list)\n\n","46841932":"listt1=list(y_test)\nlistt2=list(y_pred)\n#print(listt1)\nprint(listt2)","48a3388a":"print(listt1.count(1))\nprint(listt1.count(0))\nprint(listt2.count(1))\nprint(listt2.count(0))","022abc67":"Removing the outliers from the Age feature","ff34a138":"Scaling some numerical features","117fb5fc":"PS: The feature which related to show-up in the original data it name was No-show so the value No is meaning Show up that is the reason I decode NO as 1 and Yes as 0","f599eddf":"We have a problem here we will deal with imbalance data","74992cc6":"Choosing the important feature which have an effect on prediction and drop out the rest","e1f3c75e":"- check for any erroneous values and NaNs in data.","23f4500c":"#  2. EXPLORING THE DATA","1f5c5c21":" Rename some features","2de4258c":"plot confusion matrix for test data ","974d3253":" Encoding the categorical data","cdafa4fb":"* converting the AppointmentRegistration and Appointment columns into datetime64 format and the    AwaitingTime column into absolute values.\n* Return the day names of the DateTimeIndex\n* Fetch a new features of number of waiting days","f339ce2a":"Clearly, the data starts to thin out after 150 days AwaitingTime. There is one observation at 398 days, which is likely an outlier. There are almost no observations beyond 350 days, so let us remove anything beyond 350 days which will include that 398 day observation too.","33509e98":"We see that the data is imbalncing so for modeling we implement some techniques like over sampling the minority class \n# Modeling","5f9f8777":"Analyzing the probability of showing up with respect to different features","b1924f21":"Check if there is any missing values after cleaning and pre processing the data"}}