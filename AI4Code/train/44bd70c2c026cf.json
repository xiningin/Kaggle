{"cell_type":{"adf1f574":"code","0d40f0cf":"code","e9214e0f":"code","c989da6f":"code","b3dc62a7":"code","625b8076":"code","976a2113":"code","9cb48dd4":"code","3c985c5c":"code","9957a34e":"code","cef5c970":"code","cba5b8c9":"code","e3b1592b":"code","00250ddd":"code","0c5339ab":"code","1479649a":"code","44c7e57a":"code","c619c130":"code","0d8df91a":"code","46b10efd":"code","8de57152":"code","702fb43e":"code","e172bad3":"code","a6e15a1a":"code","bb373a35":"code","b7bef015":"code","3f9e5160":"markdown","8fc637b9":"markdown","032ae60e":"markdown","ee822cca":"markdown","4a48d20f":"markdown","01558275":"markdown","9f93e849":"markdown","d4811b9e":"markdown","d5bee701":"markdown"},"source":{"adf1f574":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0d40f0cf":"import nltk\nfrom nltk.book import*","e9214e0f":"text7","c989da6f":"len(text7)","b3dc62a7":"sents()","625b8076":"len(set(text7))","976a2113":"list(set(text7))[:10]","9cb48dd4":"freq = FreqDist(text7)\nfreq","3c985c5c":"freq[',']","9957a34e":"key = freq.keys()\nlist(key)[:10]","cef5c970":"freqWords = [words for words in key if len(words)>5 and freq[words]>100]\nfreqWords","cba5b8c9":"input1 = 'Go go Going Goings Goes'\nword1 = input1.lower().split(' ')\nword1","e3b1592b":"porter = nltk.PorterStemmer()\n[porter.stem(i) for i in word1]","00250ddd":"corpus = nltk.corpus.udhr.words('English-Latin1')\ncorpus","0c5339ab":"# still lematization\n[porter.stem(t) for t in corpus][:20]","1479649a":"WNlemma = nltk.WordNetLemmatizer()\n[WNlemma.lemmatize(t) for t in corpus[:20]]","44c7e57a":"## Tokenization\ntext = 'hey whats going on.'\ntext.split(' ')","c619c130":"nltk.word_tokenize(text)","0d8df91a":"text12 = \"This is the first sentence. A gallon of milk in the Nepal costs Rs.300. Is this the third sentence? Yes, it is!\"\nsentences = nltk.sent_tokenize(text12)\nsentences","46b10efd":"len(sentences)","8de57152":"nltk.help.upenn_tagset('MD')","702fb43e":"text13 = nltk.word_tokenize(text)\nnltk.pos_tag(text13)","e172bad3":"text14 = nltk.word_tokenize(\"Chilling with friends is a fantastic feeling.\")\nnltk.pos_tag(text14)","a6e15a1a":"# Parsing sentence structure\ntext15 = nltk.word_tokenize(\"Alice loves Bob\")\ngrammar = nltk.CFG.fromstring(\"\"\"\nS -> NP VP\nVP -> V NP\nNP -> 'Alice' | 'Bob'\nV -> 'loves'\n\"\"\")\n\nparser = nltk.ChartParser(grammar)\ntrees = parser.parse_all(text15)\nfor tree in trees:\n    print(tree)","bb373a35":"text18 = nltk.word_tokenize(\"The old man the boat\")\nnltk.pos_tag(text18)","b7bef015":"text19 = nltk.word_tokenize(\"Colorless green ideas sleep furiously\")\nnltk.pos_tag(text19)","3f9e5160":"## Counting vocabulary of words.","8fc637b9":"## Lemmatization\n * Word that come out to be actually meaningful.","032ae60e":"## POS tagging and Ambiguity.","ee822cca":"# Advanced Natural Language Processing","4a48d20f":"# Basic Natural Language Processing with NLTK","01558275":"## Frequency of words","9f93e849":"## POS(Parts-Of-Speech) tagging","d4811b9e":"# What is Natural Language Processing?\nNatural Language Processing, usually shortened as NLP, is a branch of artificial intelligence that deals with the interaction between computers and humans using the natural language.\nThe ultimate objective of NLP is to read, decipher, understand, and make sense of the human languages in a manner that is valuable.\nMost NLP techniques rely on machine learning to derive meaning from human languages.\nIn fact, a typical interaction between humans and machines using Natural Language Processing could go as follows:\n1. A human talks to the machine\n2. The machine captures the audio\n3. Audio to text conversion takes place\n4. Processing of the text\u2019s data\n5. Data to audio conversion takes place\n6. The machine responds to the human by playing the audio file\n\n# What is NLP used for?\nNatural Language Processing is the driving force behind the following common applications:\n1. Language translation applications such as Google Translate\n2. Word Processors such as Microsoft Word and Grammarly that employ NLP to check grammatical accuracy of texts.\n3. Interactive Voice Response (IVR) applications used in call centers to respond to certain users\u2019 requests.\n4. Personal assistant applications such as OK Google, Siri, Cortana, and Alexa.\n\n\n# Why is NLP difficult?\nNatural Language processing is considered a difficult problem in computer science. It\u2019s the nature of the human language that makes NLP difficult.\nThe rules that dictate the passing of information using natural languages are not easy for computers to understand.\nSome of these rules can be high-leveled and abstract; for example, when someone uses a sarcastic remark to pass information.\nOn the other hand, some of these rules can be low-levelled; for example, using the character \u201cs\u201d to signify the plurality of items.\nComprehensively understanding the human language requires understanding both the words and how the concepts are connected to deliver the intended message.\nWhile humans can easily master a language, the ambiguity and imprecise characteristics of the natural languages are what make NLP difficult for machines to implement.\n\n# How does Natural Language Processing Works?\nNLP entails applying algorithms to identify and extract the natural language rules such that the unstructured language data is converted into a form that computers can understand.\nWhen the text has been provided, the computer will utilize algorithms to extract meaning associated with every sentence and collect the essential data from them.\nSometimes, the computer may fail to understand the meaning of a sentence well, leading to obscure results.\nFor example, a humorous incident occurred in the 1950s during the translation of some words between the English and the Russian languages.\nHere is the biblical sentence that required translation:\n\n\u201cThe spirit is willing, but the flesh is weak.\u201d \n\nHere is the result when the sentence was translated to Russian and back to English:\n\n\u201cThe vodka is good, but the meat is rotten.\u201d \n\n# What are the techniques used in NLP?\nSyntactic analysis and semantic analysis are the main techniques used to complete Natural Language Processing tasks.\nHere is a description on how they can be used.\n### Syntax\nSyntax refers to the arrangement of words in a sentence such that they make grammatical sense.\nIn NLP, syntactic analysis is used to assess how the natural language aligns with the grammatical rules.\nComputer algorithms are used to apply grammatical rules to a group of words and derive meaning from them.\nHere are some syntax techniques that can be used:\n* Lemmatization *: It entails reducing the various inflected forms of a word into a single form for easy analysis.\n* Morphological segmentation: It involves dividing words into individual units called morphemes.\n* Word segmentation: It involves dividing a large piece of continuous text into distinct units.\n* Part-of-speech tagging: It involves identifying the part of speech for every word.\n* Parsing: It involves undertaking grammatical analysis for the provided sentence.\n* Sentence breaking: It involves placing sentence boundaries on a large piece of text.\n* Stemming: It involves cutting the inflected words to their root form.\n\n\n### Semantics\nSemantics refers to the meaning that is conveyed by a text. Semantic analysis is one of the difficult aspects of Natural Language Processing that has not been fully resolved yet.\nIt involves applying computer algorithms to understand the meaning and interpretation of words and how sentences are structured.\nHere are some techniques in semantic analysis:\n* Named entity recognition (NER): It involves determining the parts of a text that can be identified and categorized       into preset groups. Examples of such groups include names of people and names of places.\n* Word sense disambiguation: It involves giving meaning to a word based on the context.\n* Natural language generation: It involves using databases to derive semantic intentions and convert them into human       language.\n\n\nhttps:\/\/becominghuman.ai\/a-simple-introduction-to-natural-language-processing-ea66a1747b32","d5bee701":"## Normalization and stemming\n\n* Different forms of same 'words'"}}