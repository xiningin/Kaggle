{"cell_type":{"2bbc14d5":"code","01fb4a03":"code","16578586":"code","8ca00427":"code","93e3e086":"code","350d59a0":"code","979e4b0e":"code","74a1bc36":"code","0cfd2911":"code","f8625d55":"markdown","54b11081":"markdown","9d9a79be":"markdown","48434941":"markdown","de2658ad":"markdown","fd194b3a":"markdown","964629cf":"markdown","4e5b86b5":"markdown"},"source":{"2bbc14d5":"import pandas as pd\nimport numpy as np","01fb4a03":"train_targets_scored = pd.read_csv('..\/input\/lish-moa\/train_targets_scored.csv')\ntest_features = pd.read_csv('..\/input\/lish-moa\/test_features.csv')\nsubmission = pd.read_csv('..\/input\/lish-moa\/sample_submission.csv')\ntrain_targets_positive = train_targets_scored.sum()[1:]\ntrain_targets_positive.sort_values(ascending=True)","16578586":"remainder = train_targets_positive % 6\nnumber_to_be_added = 6 - remainder\nnumber_to_be_added = number_to_be_added % 6\ntrain_targets_positive_corrected = train_targets_positive + number_to_be_added","8ca00427":"dumb_pred_for_each_class = train_targets_positive_corrected\/(23814 + number_to_be_added.sum())","93e3e086":"sample_submission = pd.read_csv('..\/input\/lish-moa\/sample_submission.csv')","350d59a0":"submission.iloc[:, 1:] = dumb_pred_for_each_class.values","979e4b0e":"# https:\/\/www.kaggle.com\/c\/lish-moa\/discussion\/180165 \nvehicle_indices = test_features[test_features[\"cp_type\"]==\"ctl_vehicle\"].index.tolist()\nsubmission.iloc[vehicle_indices, 1:] = np.zeros((1, 206))","74a1bc36":"submission","0cfd2911":"submission.to_csv(\"submission.csv\", index=False)","f8625d55":"### Dumb model\nIt is important to understand what is the random loss value, so that we can understand how good is our current best losses (around 0.0185) in leaderboard. \n","54b11081":"For each class, divide the corrected prevalence with total number of records. Here the correction is applied to total number of records as well.","9d9a79be":"### Post Processing","48434941":"### 0.5 for each class?\nBut providing 0.5 as the prediction for each class is not the dumb loss (it is dumber). This would make sense only if half of the test records would have each of the class as positive. But we have a highly unbalanced case here. We need to take the class prevalence into consideration. Let us try doing that.","de2658ad":"As you see above, some of the classes are just having prevalences of 1, but this cannot happen as it was [made clear](https:\/\/www.kaggle.com\/c\/lish-moa\/discussion\/184005) that every class should have atleast 6 truth values. So let us look into each class and ensure that we have prevalences as multiples of 6.","fd194b3a":"### Class prevalence?\n\nConsider the training set which has 23814 records. For each class find out how many times it has ones. Let us say N. We are going to set the probability as N\/23814 for each test record for that class.","964629cf":"So with this dumb model, (in fact no model at all) I am able to get a score of **0.02359**. This is better that nearly 1\/3 rd submissions in the leaderboard. \n\nSo questions to ask\n0.0185 does not seem to be very high compared to the dumb score of 0.02359. Why are we unable to get a really good score? Less data?\nWhat is a good score in this compitition?","4e5b86b5":"### Score"}}