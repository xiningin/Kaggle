{"cell_type":{"e7dbbc6f":"code","bed6e2f3":"code","8fddebef":"code","5935eae8":"code","1e326791":"code","37ff9157":"code","4f231d57":"code","c9eb1a45":"code","8202478f":"code","9df95f5a":"code","d6cb6627":"code","1f982677":"code","ba3c5085":"code","ff745602":"markdown","328162f8":"markdown","a02ed564":"markdown","89cfcda1":"markdown","d1af0749":"markdown","bc7b5256":"markdown","fcc4ad16":"markdown","ff06cec0":"markdown","c21951b7":"markdown","768caa84":"markdown","b38b8454":"markdown","5c5d8dfd":"markdown","8f6f3d18":"markdown","3727ba8d":"markdown","9d6acd42":"markdown","89bb29c0":"markdown","a74fa744":"markdown","bc14de57":"markdown","08fa2cce":"markdown","8d3f39c8":"markdown","f2e75c61":"markdown","63ecec97":"markdown"},"source":{"e7dbbc6f":"import numpy as np\nimport pandas as pd\npd.set_option('display.float_format', '{:.10f}'.format)\n\ntrain = pd.read_csv('..\/input\/train.csv')\nhistorical_transactions = pd.read_csv('..\/input\/historical_transactions.csv')\nnew_merchant_transactions = pd.read_csv('..\/input\/new_merchant_transactions.csv')","bed6e2f3":"new_merchant_transactions['purchase_amount_new'] = np.round(new_merchant_transactions['purchase_amount'] \/ 0.00150265118 + 497.06,2)\nhistorical_transactions['purchase_amount_new'] = np.round(historical_transactions['purchase_amount'] \/ 0.00150265118 + 497.06,2)\ntrain['target_raw'] = 2**train['target']","8fddebef":"merchant_counts = historical_transactions.groupby(['card_id'])['merchant_id'].nunique().reset_index(name = 'merchant_n')\none_merchant = merchant_counts[merchant_counts['merchant_n']==1].reset_index(drop=True)\ndat = historical_transactions.loc[historical_transactions['card_id'].isin(one_merchant['card_id'])]\ndat = dat.loc[~dat['card_id'].isin(new_merchant_transactions['card_id'])]\ndat = dat.loc[dat.merchant_id=='M_ID_fc7d7969c3'].reset_index(drop=True)","5935eae8":"historical_transactions[historical_transactions.card_id=='C_ID_b3c7ff9e19'].sort_values('purchase_date')","1e326791":"new_merchant_transactions[new_merchant_transactions.card_id=='C_ID_b3c7ff9e19'].sort_values('purchase_date')","37ff9157":"historical_transactions.loc[historical_transactions.merchant_id=='M_ID_fc7d7969c3'].groupby('purchase_amount_new')['card_id'].count()","4f231d57":"dat = dat.merge(train, on = 'card_id')","c9eb1a45":"dat.head()","8202478f":"dat.groupby('target_raw')['card_id'].count().reset_index(name='n')","9df95f5a":"dat.loc[dat['target_raw']==1,['card_id','purchase_date','purchase_amount_new','target_raw']].sort_values(['card_id','purchase_date'])","d6cb6627":"prices = [19.90, 22.90, 27.90, 29.90, 37.90]\nsorted({ i\/j for j in prices for i in prices})","1f982677":"dat.groupby('target_raw')['card_id'].count().reset_index(name='n')","ba3c5085":"dat[dat.card_id=='C_ID_2c8d99614f'].sort_values('purchase_date')","ff745602":"# What's next?\n\nSo what you can do with this kind of information. Firstly, the rate of `purchase_amount` monthly change for (`card_id, merchant_id`) tuple should be the key features in your models, i.e. average change ratio of (5->4, 4->3, 3->2, 2->1, 1->0); Or features such as `sum(future_purchase_amount)\/sum(purchase_amount_lag_-1)`, etc.\n\nThis also allows building new intermediate models, like predicting the historic merchant performance in `month_lag=1` and `month_lag=2` and stacking its predictions to your main model.\n\nThese are the most impactful things I can think of right now, but there could always be more!","328162f8":"# Things that are still not clear...","a02ed564":"If we excluded the subscribtion activation fees (1.00), you would expect the `target_raw` to be 1 (as `purchase_amount` is constant...)\n\nHowever the `target_raw` is 1.2183406082, which in fact is equivalent to `27.90\/22.90`.\n\nAmazing! Now we definetly know that the `purchase_amount` for this `card_id` has changed, and it is very likely happened in the future (`month_lag = 1` or `month_lag = 2`). This information we do not observe in `new_merchant_transactions` table, because organizers have excluded that on purpose in data preparation stage - if we would have this information, we could easily track down how target has been calculated, and 0.000 RMSE score would be possible.\n\nWhat does this all mean for `target` calculation?\n\nThe answer is simple:\n## target is equal to the ratio of money spent in the future divided by money spent in the past!\n\nI guess this transfers to all merchants and to all cards in the dataset, but the calculations are a bit harder, as more merchants are involved.","89cfcda1":"# Bonus\n\nNow as we know that we are working with future\/history ratios, the outlier value (-33.xxxxx) is actually the meaning of a user not spending a single cent in the future on the historical merchants - mystery solved!\n\nIf i was an organizer, I would have made it to be ~ -10 or so, as RMSE is so sensitive regarding this outler'ish value...\n\nSadly, this also means that these outliers cannot be predicted with the given historical information...\n\n\n\nKnowing all this I can say for sure that the data we have is in fact **real data** and not **simulated one**! In case I am wrong on this one - well done Elo - you did a marvelous job in simulation part (would be hard to make a clean generator like that!)","d1af0749":"You will find the values like 0.713261, 1.21834, 1.35842 appearing in both objects!","bc7b5256":"However, the most interesting part lies not in `target_raw=1`, but actually in other float numbers!\n\nLet's take a step back first and revisit the `purchase_amount` values we extracted earlier, and let's calculate possible ratios based on these values:","fcc4ad16":"So why the `merchant_id=M_ID_fc7d7969c3` is so special? It turns out it is subscribtion based merchant - most likely internet payments???The `purchase_amount` is distributed in a few very distinct categories:","ff06cec0":"Now in order to prove that target is a meaningful ratio, I was looking for some easy cases, such as `card_id` with only one `merchant_id`, with no transactions in`new_merchant_transaction_table`. This helps to isolate the problem and analyze it more thoroughly. \n\nWith some manual exploration, I found that `merchant_id=M_ID_fc7d7969c3` is a perfect candidate to work with.","c21951b7":"Following my previous kernel (https:\/\/www.kaggle.com\/raddar\/towards-de-anonymizing-the-data-some-insights) I was able to reveal that `target` is transformed using log function, and the raw target can be reversed with `2**target` transformation. Moreover, I speculated that the true target is a ratio of `product_sum`. \n\nThis kernel is all about explaining, what kind of ratio we are working with, and why the problem is so hard!\n\nAnd this is going to blow your mind!","768caa84":"So there is some fluctuation in `purchase_amount`, therefore it is still unclear why the `target_raw==1`.","b38b8454":"Now as we definetly know that target is a ratio of future and past transaction amounts, there are still some unaswered questions, mainly:\n\n- which months are taken into calculation? `month_lag=1` \/ `month_lag=0`, `month_lag=2` \/ `month_lag=0`, `month_lag=1` \/ `min(month_lag=0, month_lag=-1)`, etc. All these are all valid options...\n- does `new_merchant_transactions` have any influence for the `target`?","5c5d8dfd":"This is pretty amazing find and at this point I am 100% sure that the target is a ratio of change in `purchase_amount`.\n\nHowever, there is still a question to ask - how exactly this ratio is calculated?\n\nLet's take this `card_id` for example:","8f6f3d18":"# This is going to be epic... sit back, relax and enjoy!","3727ba8d":"Let's apply transformations as in previous kernel:","9d6acd42":"# Thank you!\n\nif you liked the content don't forget to upvote!","89bb29c0":"The payments are happeninig roughly on the same day of month (maybe recurring credit card payments). We also observe a `purchase_amount` increase from 29.9 to 37.9.","a74fa744":"Let's take a look at a random `card_id` to inspect the transactional history:","bc14de57":"These numbers are not telling anything at the moment.\n\nBut there is the catch - let's revisit the previous table, were we calculated unique `target_raw` values (compare the list above with the table below).\n\nHint: if you looked closely you may find that some of the list values overlap!","08fa2cce":"This is a very useful information - remember - the hypothesis was that target is based on some kind of ratios, and the `purchase_amount` ratio seems like a very reasonable candidate.","8d3f39c8":"Now let's try to make some correlations with train `target`:","f2e75c61":"At this point let's summarise what we know:\n\n- merchant is selling subscribtion based products\n- card_id is automatically charged monthly\n- the price for the subscribtion can change (most likely due to upselling)\n- there are 5 products with prices of 19.90, 22.90, 27.90, 29.90 and 37.90; the 1.00 is probably subscribtion activation fee","63ecec97":"It seems most of the target values for this specific `card_id` group is concentrated in `target_raw=1`. This is great news, because we were able to somehow cluster this specific group of cards just by some ad hoc rules (single merchant, specific merchant, no new merchant transactions).\n\nLet's take a look at `card_id``s, which `target_raw` is equal to 1:"}}