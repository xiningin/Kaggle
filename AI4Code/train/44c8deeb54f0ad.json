{"cell_type":{"0010584e":"code","2de2a096":"code","391f36cb":"code","8237cefd":"code","eaa52541":"code","9a92e36f":"code","c5ff49bd":"code","0c724690":"code","3e4e7403":"code","34ab863e":"code","638317fc":"code","4e3f7519":"code","e9823592":"code","bb8e83d9":"code","1133dedd":"code","2c8efdd9":"code","afbeb248":"code","af887764":"markdown","be8045fb":"markdown","ba032cb6":"markdown","382f3c78":"markdown","e2d1d76c":"markdown","f222d66b":"markdown"},"source":{"0010584e":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\nimport seaborn as sns\nimport matplotlib.pyplot as plt","2de2a096":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","391f36cb":"df = pd.read_csv('\/kaggle\/input\/engineering-graduate-salary-prediction\/Engineering_graduate_salary.csv')","8237cefd":"def print_evaluate(predicted,true):  \n    mse = metrics.mean_squared_error(true, predicted)\n    print('MSE:', mse)","eaa52541":"def draw_missing_data_table(df):\n    total = df.isnull().sum().sort_values(ascending=False)\n    percent = (df.isnull().sum()\/df.isnull().count()).sort_values(ascending=False)\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    return missing_data","9a92e36f":"df","c5ff49bd":"draw_missing_data_table(df)","0c724690":"df.corr()[\"Salary\"].sort_values(ascending=False)","3e4e7403":"X = df[['ID','Quant']].values\nY = df['Salary'].values","34ab863e":"from sklearn.model_selection import train_test_split\nXtrain, Xtest, Ytrain, Ytest = train_test_split(X,Y,test_size=0.3,random_state=20000)","638317fc":"from sklearn.ensemble import GradientBoostingRegressor\ngb = GradientBoostingRegressor()\ngb.fit(Xtrain,Ytrain)\npgb = gb.predict(Xtest)\nprint_evaluate(pgb,Ytest)","4e3f7519":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(Xtrain,Ytrain)\nplr = lr.predict(Xtest)\nprint_evaluate(plr,Ytest)","e9823592":"from sklearn.ensemble import RandomForestRegressor\nparams = {\n    'bootstrap': [True],\n    'max_depth': [1,10,30,50, 75],\n    'max_features': ['auto'],\n    'min_samples_leaf': [1],\n    'min_samples_split': [3],\n    'n_estimators': [1,10,100,200]}\nrfr = RandomForestRegressor()\nrf_grid=GridSearchCV(rfr, params, n_jobs=1, cv=3,scoring='neg_mean_squared_error')\nrf_grid.fit(Xtrain,Ytrain)\nprf = rf_grid.predict(Xtest)\nprint_evaluate(prf,Ytest)","bb8e83d9":"from sklearn.linear_model import Lasso\nparams = {\n    'alpha' : [.01, .1, .5, .7, .9, .95, .99, 1, 5, 10, 20],\n    'fit_intercept' : [True, False],\n    'normalize' : [True,False],\n    'tol' : [0.0001, 0.001, 0.01, 0.1,0.5,1],\n    \"random_state\" : [50] }\n\nlasso = Lasso()\nlasso_grid = GridSearchCV(lasso, params, scoring='neg_mean_squared_error', cv=5, n_jobs=1)\nlasso_grid.fit(Xtrain, Ytrain)\npla = lasso_grid.predict(Xtest)\nprint_evaluate(pla,Ytest)","1133dedd":"from sklearn.linear_model import Ridge\nparams = {\n    \"alpha\" : [.01, .1, .95, .99, 1, 5],\n    \"fit_intercept\" : [True, False],\n    \"normalize\" : [True,False],\n    \"solver\" : ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n    \"tol\" : [0.001, 0.01, 0.1],\n    \"random_state\" : [50]}\n\nridge = Ridge()\nridge_grid = GridSearchCV(ridge, params, scoring='neg_mean_squared_error', cv=5, n_jobs=1)\nridge_grid.fit(Xtrain, Ytrain)\npr = ridge_grid.predict(Xtest)\nprint_evaluate(pr,Ytest)","2c8efdd9":"from sklearn.neighbors import KNeighborsRegressor\nparams = {'n_neighbors' : [2,3,4,5,49,100] ,    \n              'weights' : ['uniform','distance'] ,\n              'algorithm' : ['ball_tree', 'kd_tree', 'brute']}\n\nknn = KNeighborsRegressor()\nknn_grid = GridSearchCV(knn, params, scoring='neg_mean_squared_error', cv=3, n_jobs=1)\nknn_grid.fit(Xtrain, Ytrain)\npknn = knn_grid.predict(Xtest)\nprint_evaluate(pknn,Ytest)","afbeb248":"from sklearn.ensemble import VotingRegressor\nvoting = VotingRegressor([('Ridge',ridge_grid),('Lasso',lasso_grid)])\nvoting.fit(Xtrain, Ytrain)\nvote = voting.predict(Xtest)\nprint_evaluate(vote,Ytest)","af887764":"# **Importing Libraries**","be8045fb":"Choose Feature which Correlation Coefficient > 0.2 and Correlation Coefficient < -0.2","ba032cb6":"# **Data Preprocess**","382f3c78":"# **Model**","e2d1d76c":"# **Importing Dataset**","f222d66b":"# **Ensemble Learning (Voting)**"}}