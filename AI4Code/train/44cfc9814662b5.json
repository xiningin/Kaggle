{"cell_type":{"1b2e2fa6":"code","98d19409":"code","a5b21b5f":"code","9fa077a0":"code","fb31787c":"code","f98f813a":"code","cb1cfd1e":"code","10a002b2":"code","f153a8af":"code","8376d716":"code","cd0116f6":"code","748be90a":"code","73c55920":"code","595b22b4":"code","c105fb4a":"code","28f65f8f":"code","375bcdaf":"code","61fd6730":"code","76efc6ce":"code","995b5216":"code","65436d33":"code","c502d28e":"code","e0b2a61c":"code","fd10783f":"markdown","27d95ea4":"markdown"},"source":{"1b2e2fa6":"from tqdm import tqdm\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nfrom datetime import datetime as dt","98d19409":"# \u0441\u0447\u0438\u0442\u044b\u0432\u0430\u0435\u043c \u0444\u0430\u0439\u043b\u044b\nsubmission=pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/sample_submission.csv')\ntrain=pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/test.csv')","a5b21b5f":"train.head()","9fa077a0":"# \u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0431\u0430\u043b\u0430\u043d\u0441 \u043a\u043b\u0430\u0441\u0441\u043e\u0432\ntrain.loc[:,'healthy':'scab'].sum(axis=0)\/(train.shape[0]\/100)","fb31787c":"test.head()","f98f813a":"submission.head()","cb1cfd1e":"# \u0437\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0438 \u043c\u0435\u043d\u044f\u0435\u043c \u0438\u0445 \u0440\u0430\u0437\u043c\u0435\u0440\n# \u0435\u0441\u043b\u0438 \u043f\u043e\u043c\u0435\u043d\u044f\u0435\u0442\u0435 \u0440\u0430\u0437\u043c\u0435\u0440 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0442\u0443\u0442, \u0442\u043e \u043d\u0435 \u0437\u0430\u0431\u0443\u0434\u044c\u0442\u0435 \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u044d\u0442\u043e \u043d\u0430 \u0432\u0445\u043e\u0434\u0435 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438\ntrain_img=[]\ntrain_label=[]\npath='\/kaggle\/input\/plant-pathology-2020-fgvc7\/images'\nfor im in tqdm(train['image_id']):\n    im=im+\".jpg\"\n    final_path=os.path.join(path,im)\n    img=cv2.imread(final_path)\n    img=cv2.resize(img,(224,224))\n    img=img.astype('float32')\n    train_img.append(img)","10a002b2":"test_img=[]\npath='\/kaggle\/input\/plant-pathology-2020-fgvc7\/images'\nfor im in tqdm(test['image_id']):\n    im=im+\".jpg\"\n    final_path=os.path.join(path,im)\n    img=cv2.imread(final_path)\n    img=cv2.resize(img,(224,224))\n    img=img.astype(('float32'))\n    test_img.append(img)","f153a8af":"# \u0432\u044b\u0434\u0435\u043b\u044f\u0435\u043c \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0435 \u043c\u0435\u0442\u043a\u0438\ntrain_label=train.loc[:,'healthy':'scab']","8376d716":"# \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u044b\u0432\u0430\u0435\u043c \u0432\u0441\u0435 \u043c\u0430\u0441\u0441\u0438\u0432\u044b \u0432 numpy\ntrain_img=np.array(train_img)\/255.0\ntest_img=np.array(test_img)\/255.0\ntrain_label=np.array(train_label)","cd0116f6":"print(train_img.shape)\nprint(test_img.shape)\nprint(train_label.shape)","748be90a":"# \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u0434\u0430\u0442\u0430 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440 \u0434\u043b\u044f \u0443\u0432\u0435\u043b\u0438\u0447\u0435\u043d\u0438\u044f \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.3, # Randomly zoom image \n        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True)  # randomly flip images\n\n\ndatagen.fit(train_img)","73c55920":"!pip install efficientnet","595b22b4":"## ______________ \u0411\u041b\u041e\u041a \u0421 \u0418\u041c\u041f\u041e\u0420\u0422\u0410\u041c\u0418 \u0410\u0420\u0425\u0418\u0422\u0415\u041a\u0422\u0423\u0420 ____________________\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom tensorflow.keras.applications.densenet import DenseNet121, DenseNet169, DenseNet201 \nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.resnet_v2 import ResNet50V2, ResNet101V2, ResNet152V2\nfrom tensorflow.keras.applications.nasnet import NASNetLarge\nfrom efficientnet.tfkeras import EfficientNetB7, EfficientNetL2\n## ______________ \u041a\u041e\u041d\u0415\u0426 \u0411\u041b\u041e\u041a\u0410 \u0421 \u0418\u041c\u041f\u041e\u0420\u0422\u0410\u041c\u0418 \u0410\u0420\u0425\u0418\u0422\u0415\u041a\u0422\u0423\u0420 ____________________\n\n# \u0438\u043c\u043f\u043e\u0440\u0442 \u0434\u0440\u0443\u0433\u0438\u0445 \u043f\u043e\u043b\u0435\u0437\u043d\u044b\u0445 \u0438\u043d\u0441\u0442\u0440\u0443\u043c\u0435\u043d\u0442\u043e\u0432: \u0441\u043b\u043e\u0435\u0432, \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440\u043e\u0432, \u0444\u0443\u043d\u043a\u0446\u0438\u0439 \u043e\u0431\u0440\u0430\u0442\u043d\u043e\u0439 \u0441\u0432\u044f\u0437\u0438\nfrom tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint","c105fb4a":"# \u0442\u0443\u0442 \u043c\u043e\u0436\u0435\u0442\u0435 \u0432\u043c\u0435\u0441\u0442\u043e ResNet50 \u043f\u043e\u0434\u0441\u0442\u0430\u0432\u043b\u044f\u0442\u044c \u043f\u043e \u043e\u0447\u0435\u0440\u0435\u0434\u0438 \u0432\u044b\u0448\u0435\u043f\u0435\u0440\u0435\u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044b\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 VGG19, InceptionV3, InceptionResNetV2, DenseNet201 \u0438 \u0434\u0440\nbase_model=EfficientNetB7(include_top=False, weights='imagenet',input_shape=(224,224,3), pooling='avg')\n\nmodel=Sequential()\nmodel.add(base_model)\n\n#  \u0432 \u044d\u0442\u043e\u043c \u0431\u043b\u043e\u043a\u0435 \u043c\u043e\u0436\u0435\u0442\u0435 \u043f\u043e\u0432\u0430\u0440\u044c\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0431\u043b\u043e\u043a\u043e\u0432 Dense, \u0438\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b (128, 256, 1024, \u0434\u0440) \u0438\u043b\u0438 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0430\u043a\u0442\u0438\u0432\u0430\u0446\u0438\u0438,\n# \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0431\u043b\u043e\u043a\u0430 Dropout, \u0443\u0431\u0440\u0430\u0442\u044c\/\u0434\u043e\u0431\u0432\u0430\u0438\u0442\u044c BatchNormalization\nmodel.add(Dense(1024,activation='relu'))\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dropout(0.8))\nmodel.add(Dense(4,activation='softmax'))\n\n# \u0435\u0441\u043b\u0438 \u0445\u043e\u0442\u0438\u0442\u0435 \u043f\u043e\u043b\u043d\u043e\u0441\u0442\u044c\u044e \u0437\u0430\u043c\u043e\u0440\u043e\u0437\u0438\u0442\u044c \u0441\u0435\u0442\u044c, \u0442\u043e \u043f\u0440\u0438\u0440\u0430\u0432\u043d\u044f\u0439\u0442\u0435 \u043a True, \u0438\u043d\u0430\u0447\u0435 \u043d\u0430\u043f\u0438\u0448\u0438\u0442\u0435 \u043a\u0430\u043a\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0441\u043b\u043e\u0435\u0432 \u0432\u044b \u0445\u043e\u0442\u0438\u0442\u0435 \u0440\u0430\u0437\u043c\u043e\u0440\u043e\u0437\u0438\u0442\u044c\nfroze = True # 13\nif froze is True:\n    base_model.trainable=False\nelse:\n    for layer in base_model.layers[:-int(froze)]:\n        layer.trainable = False\n\n# \u0442\u0443\u0442 \u043c\u043e\u0436\u043d\u043e \u0440\u0435\u0433\u0443\u043b\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0447\u0435\u0440\u0435\u0437 \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u044d\u043f\u043e\u0445 (patience) \u0448\u0430\u0433 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f (lr) \u0431\u0443\u0434\u0435\u0442 \u043c\u0435\u043d\u044f\u0442\u044c\u0441\u044f \u0438 \u043d\u0430 \u0441\u043a\u043e\u043b\u044c\u043a\u043e (factor).\n# \u043f\u0440\u0438 \u0434\u043e\u0441\u0442\u0438\u0436\u0435\u043d\u0438\u0438 min_lr \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043f\u0440\u0435\u0440\u0432\u0435\u0442\u0441\u044f \u0434\u0430\u0436\u0435 \u0435\u0441\u043b\u0438 \u043d\u0435 \u0437\u0430\u043a\u043e\u043d\u0447\u0438\u043b\u0438\u0441\u044c \u044d\u043f\u043e\u0445\u0438, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0432\u044b \u0437\u0430\u0434\u0430\u043b\u0438 \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f\nreduce_learning_rate = ReduceLROnPlateau(monitor='categorical_accuracy',\n                                         factor=0.5,\n                                         patience=5,\n                                         cooldown=2,\n                                         min_lr=0.0000001,\n                                         verbose=1)\n# \u0442\u0443\u0442 \u043c\u043e\u0436\u043d\u043e \u043c\u043e\u043d\u0438\u0442\u043e\u0440\u0438\u0442\u044c \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u0443\u0435\u043c\u0443\u044e \u043c\u0435\u0442\u0440\u0438\u043a\u0443 \u0438 \u0435\u0441\u043b\u0438 \u043e\u043d\u0430 \u043d\u0435 \u0443\u043b\u0443\u0447\u0448\u0430\u043b\u0430\u0441\u044c \"patience\" \u044d\u043f\u043e\u0445, \u0442\u043e \u043e\u0441\u0442\u0430\u043d\u043e\u0432\u0438\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\nearly_stopping = EarlyStopping(monitor='categorical_accuracy', patience=10)\n\n# \u0442\u0443\u0442 \u043c\u044b \u043c\u043e\u043d\u0438\u0442\u043e\u0440\u0438\u043c \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u0443\u0435\u043c\u0443\u044e \u043c\u0435\u0442\u0440\u0438\u043a\u0443 \u0438 \u0434\u0435\u043b\u0430\u0435\u043c \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u0442\u043e\u043b\u044c\u043a\u043e \u043a\u043e\u0433\u0434\u0430 \u043e\u043d\u0430 \u0441\u0442\u0430\u043d\u043e\u0432\u0438\u0442\u0441\u044f \u043b\u0443\u0447\u0448\u0435, \u0445\u0443\u0434\u0448\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u043e\u0442\u0431\u0440\u0430\u0441\u044b\u0432\u0430\u0435\u043c\ncheck_point = ModelCheckpoint(filepath='resnet_50.h5', monitor='categorical_accuracy', save_best_only=True)\n\n# \u0442\u0443\u0442 \u043f\u0440\u043e\u0441\u0442\u043e \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u0441\u043f\u0438\u0441\u043e\u043a \u043d\u0430\u0448\u0438\u0445 \u043e\u0431\u0440\u0430\u0442\u043d\u044b\u0445 \u0441\u0432\u044f\u0437\u0435\u0439, \u0435\u0441\u043b\u0438 \u043f\u043e\u0441\u0447\u0438\u0442\u0430\u0435\u0442\u0435 \u043a\u0430\u043a\u0438\u0435-\u043b\u0438\u0431\u043e \u043b\u0438\u0448\u043d\u0438\u043c\u0438, \u0442\u043e \u043f\u0440\u043e\u0441\u0442\u043e \u043d\u0435 \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0439\u0442\u0435 \u0432 \u0441\u043f\u0438\u0441\u043e\u043a\ncallbacks = [reduce_learning_rate, early_stopping, check_point]\n    \n# \u0442\u0443\u0442 \u043c\u043e\u0436\u0435\u0442\u0435 \u043f\u043e\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c \u043c\u0435\u043d\u044f\u0442\u044c \"optimizer\" \u0438 \"metrics\". \u041d\u043e \u0435\u0441\u043b\u0438 \u043f\u043e\u043c\u0435\u043d\u044f\u0435\u0442\u0435 \"metrics\", \u0442\u043e \u043d\u0435 \u0437\u0430\u0431\u0443\u0434\u044c\u0442\u0435 \u043f\u043e\u043c\u0435\u043d\u044f\u0442\u044c \u0435\u0435 \u0438 \u0432\u044b\u0448\u0435 \u0432\u043e \u0432\u0441\u0435\u0445 \"monitor\"\nmodel.compile( optimizer='adam',loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n","28f65f8f":"# \u043e\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438\nmodel.summary()","375bcdaf":"# \u0437\u0430\u043f\u0443\u0441\u043a\u0430\u0435\u043c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\nstart = dt.now()\nhistory = model.fit_generator(datagen.flow(train_img, train_label, batch_size=32),\n                    epochs=200,callbacks=callbacks)\nprint(\"\u0412\u0440\u0435\u043c\u044f \u0440\u0430\u0431\u043e\u0442\u044b \u043c\u043e\u0434\u0435\u043b\u0438: {}. \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u044d\u043f\u043e\u0445: {}.\".format(dt.now() - start, len(history.epoch)))","61fd6730":"# \u0447\u0438\u0441\u0442\u0438\u043c \u043f\u0430\u043c\u044f\u0442\u044c\nimport gc\ndel train_img, train_label","76efc6ce":"# \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u043f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u0433\u0440\u0430\u0444\u0438\u043a\u043e\u0432 \u043f\u043e\u0442\u0435\u0440\u044c \u0438 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438\n%matplotlib inline\ndef plot_loss(his, title):\n    epoch = len(his.epoch)\n    plt.style.use('ggplot')\n    plt.figure()\n    plt.plot(np.arange(0, epoch), his.history['loss'], label='train_loss')\n#     plt.plot(np.arange(0, epoch), his.history['val_loss'], label='valid_loss')\n\n    plt.title(title)\n    plt.xlabel('Epoch #')\n    plt.ylabel('Loss')\n    plt.legend(loc='upper right')\n    plt.show()\n\ndef plot_acc(his, title):\n    epoch = len(his.epoch)\n    plt.style.use('ggplot')\n    plt.figure()\n    plt.plot(np.arange(0, epoch), his.history['categorical_accuracy'], label='categorical_accuracy')\n#     plt.plot(np.arange(0, epoch), his.history['val_accuracy'], label='valid_accuracy')\n\n    plt.title(title)\n    plt.xlabel('Epoch #')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='upper right')\n    plt.show()","995b5216":"# \u0441\u0442\u0440\u043e\u0438\u043c \u0433\u0440\u0430\u0444\u0438\u043a\u0438\nplot_loss(history,'Training Dataset')\nplot_acc(history, 'Training Dataset')","65436d33":"# \u0434\u0435\u043b\u0430\u0435\u043c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f\ny_pred=model.predict(test_img)\nprint(y_pred)","c502d28e":"# \u043c\u0435\u043d\u044f\u0435\u043c \u0444\u0430\u0439\u043b submission\nsubmission.loc[:,'healthy':'scab'] = y_pred","e0b2a61c":"# \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0435\u043c \u0444\u0430\u0439\u043b submission\nsubmission.to_csv('submission.csv',index=False)","fd10783f":"**\u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435**","27d95ea4":"**\u042d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u0438\u0440\u0443\u0435\u043c \u0441 \u0440\u0430\u0437\u043b\u0438\u0447\u043d\u044b\u043c\u0438 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u0430\u043c\u0438**"}}