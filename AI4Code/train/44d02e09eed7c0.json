{"cell_type":{"16e37e66":"code","f2ef9805":"code","41cf36bd":"code","746d64e5":"code","4a749fea":"code","b93cc7af":"code","afac4ff3":"code","527c286a":"code","9d7a3388":"code","5e8cbe82":"code","0073b9f8":"code","2a694215":"code","8865ea01":"code","aed960b1":"code","7cff35e2":"code","a3897429":"code","2fa4000c":"code","4df9802d":"code","0ae78b13":"code","7aa897ac":"code","b5943219":"code","e6d7b1d8":"code","ecadde92":"code","da1a76bd":"code","6aa4f1fc":"code","bc2097b3":"markdown","c5d578b7":"markdown","6afb2ef9":"markdown","641257d3":"markdown","b31295c1":"markdown","32e309a4":"markdown","33a5ab42":"markdown","1a85706d":"markdown","51dc1aa9":"markdown","9757d082":"markdown","a05ee94a":"markdown","b5dfa88b":"markdown","bfa5b29f":"markdown","69529258":"markdown","4cbca21e":"markdown","a1724dda":"markdown","dfc98cba":"markdown","ba5fd71a":"markdown","5b85026a":"markdown"},"source":{"16e37e66":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nfrom sklearn.preprocessing import minmax_scale, scale\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","f2ef9805":"survey_schema = pd.read_csv('..\/input\/SurveySchema.csv')\nfree_form = pd.read_csv('..\/input\/freeFormResponses.csv')\nmultiple_choice = pd.read_csv('..\/input\/multipleChoiceResponses.csv')","41cf36bd":"all_na_values = (multiple_choice.loc[1:, :].isna().sum() == (len(multiple_choice) - 1))\nprint('Dropped columns ', multiple_choice.columns[all_na_values].tolist(),\n      ' from multipleChoiceResponses.csv because are all na')\nmultiple_choice = multiple_choice.loc[:, ~all_na_values]","746d64e5":"# Many support functions\ndef cols_part_questionary(q):\n    return multiple_choice.columns[multiple_choice.columns.str.startswith(q) & multiple_choice.columns.str.contains('_Part_')]\n\ndef get_cols_values(values):\n    return values.iloc[1:, :].apply(lambda col: col[col.first_valid_index()])\n\ndef plot_correlation_question(*qs):\n    q_multiple_answers = []\n    for q in qs:\n        q_multiple_answers += cols_part_questionary(q).tolist()\n    q_choices = multiple_choice.loc[1:, q_multiple_answers]\n    map_index = q_choices.apply(lambda col: col[col.first_valid_index()], axis=0).reset_index(drop=True)\n    if not map_index.str.match('[0-9]+').any():\n        q_choices = ~q_choices.isna()\n#       plt.subplots(figsize=(15, 11))\n#         plt.title(survey_schema.loc[0, q])\n        sns.heatmap(cramerv(q_choices, q_choices.columns.tolist()),\n                    xticklabels=map_index.values,\n                    yticklabels=map_index.values)\n        plt.show()\n    return map_index, q_choices\n\ndef plot_countbar(responses, values):\n    counts = values.sum()\n    counts.index = responses.values\n    plt.subplots(figsize=(10, 7))\n    ax = sns.barplot(counts.index, counts.values)\n    ax.set_xticklabels(counts.index.values, rotation=90)\n    return ax\n\ndef plot_cross_correlation(q1, q2):\n    q1 = cols_part_questionary(q1).tolist()\n    q2 = cols_part_questionary(q2).tolist()\n    q_choices = multiple_choice.loc[1:, q1 + q2]\n    map_index = q_choices.apply(lambda col: col[col.first_valid_index()], axis=0).reset_index(drop=True)\n    q_choices = ~q_choices.isna()\n    corr_matrix = cramerv(q_choices, q1 + q2)\n    ax = sns.heatmap(corr_matrix[:len(q1), len(q1):], yticklabels=map_index[:len(q1)], xticklabels=map_index[len(q1):])\n    return ax\n\nfrom scipy.stats import chi2_contingency\ndef _cramerv(col1: np.array, col2: np.array):\n    confusion_matrix = pd.crosstab(col1, col2)\n    chi2, p_value = chi2_contingency(confusion_matrix)[0:2]\n    n = confusion_matrix.sum().sum()\n    phi2 = chi2 \/ n\n    r, k = confusion_matrix.shape\n    phi2corr = max(0, phi2 - ((k - 1) * (r - 1)) \/ (n - 1))\n    rcorr = r - ((r - 1) ** 2) \/ (n - 1)\n    kcorr = k - ((k - 1) ** 2) \/ (n - 1)\n    return np.sqrt(phi2corr \/ min((kcorr - 1), (rcorr - 1))) if not phi2corr == 0 else 0\n\n\ndef cramerv(dataset: pd.DataFrame, cols) -> np.matrix:\n    \"\"\"\n    Apply the cramerv test on each pair of columns. The cramerv test is used to\n    measure in [0,1] the correlation between categorical variables\n    :param dataset: Dataframe where the correlation is measured\n    :param cols: the columns of dataset where measure the correlation\n    :return: the correlation matrix of cramerv on the specified columns of dataset\n    \"\"\"\n    matr = np.matrix([[0] * len(cols)] * len(cols), dtype='float')\n    for i in range(len(cols)):\n        for j in range(i, len(cols)):\n            if i == j:\n                matr[i, j] = 1\n            else:\n                corr = _cramerv(dataset[cols[i]], dataset[cols[j]])\n                matr[i, j] = corr\n                matr[j, i] = corr\n    return matr\n\ndef normalized_crosstab(q1, q2):\n    \"\"\"Get the crosstab normalized by q1\"\"\"\n    crosstab = pd.crosstab(multiple_choice.loc[1:, q1], multiple_choice.loc[1:, q2])\n    norm_crosstab = crosstab.divide(crosstab.sum(axis=1), axis='rows')\n    return norm_crosstab.T","4a749fea":"multiple_choice.Q2[1:].value_counts().plot.barh(title='Age of kagglers survey respondants')\nplt.show()","b93cc7af":"multiple_choice.Q8[1:].value_counts().plot.barh(title=multiple_choice.Q8[0])\nplt.show()","afac4ff3":"multiple_choice.Q10[1:].value_counts().plot.barh(title=multiple_choice.Q10[0])\nplt.show()","527c286a":"q49_cols = multiple_choice.loc[:, cols_part_questionary('Q49')]\nq49_values = get_cols_values(q49_cols)\ncounts_q49 = (~q49_cols.isna()).sum()\ncounts_q49.index = q49_values.values\ncounts_q49.plot.barh(title=survey_schema.Q49[0])\nplt.show()","9d7a3388":"multiple_choice.loc[1:, 'Q5'].value_counts().plot.barh(title=multiple_choice.Q5[0])\nplt.show()","5e8cbe82":"q16_cols = multiple_choice.loc[1:, cols_part_questionary('Q16')]\nq16_values = get_cols_values(q16_cols)\ncounts_q16 = (~q16_cols.isna()).sum()\ncounts_q16.index = q16_values.values\ncounts_q16.plot.barh(title=survey_schema.Q16[0])\nplt.show()","0073b9f8":"multiple_choice.Q18[1:].value_counts().plot.barh(title=multiple_choice.Q18[0])\nplt.show()","2a694215":"ax = plot_cross_correlation('Q11', 'Q16')\nplt.show()","8865ea01":"crosstab = pd.crosstab(multiple_choice.Q17[1:], multiple_choice.Q5[1:])\nnorm_crosstab = crosstab.divide(crosstab.sum(axis=1), axis='rows')\nax = sns.heatmap(norm_crosstab.T)\nax.set_xlabel('')\nax.set_ylabel('')\n\nplt.show()","aed960b1":"ax = sns.heatmap(normalized_crosstab('Q17', 'Q10'))\n# sns.heatmap(pd.crosstab(multiple_choice.Q17[1:], multiple_choice.Q10[1:]).T)\nplt.show()","7cff35e2":"counts = multiple_choice.Q17[1:].value_counts()\nq9_true_order = [0, 1, 5,8, 10, 12, 14, 15, 16, 17, 2, 3, 4 ,6 , 7, 9, 11, 13, 18]\ncrosstab = (pd.crosstab(multiple_choice.Q17[1:], multiple_choice.Q9[1:]))\ncrosstab = crosstab.iloc[:, q9_true_order]\ncrosstab = crosstab.rename({crosstab.columns[-1]:\"I don't want to disclose\"}, axis='columns')\nnorm_crosstab = crosstab.divide(crosstab.sum(axis=1), axis='rows')\nfig, ax = plt.subplots(figsize=(7, 5))\nsns.heatmap(norm_crosstab, ax=ax)\nplt.tight_layout()\nax.set_xlabel('')\nax.set_ylabel('')\nplt.show()","a3897429":"ax = plot_cross_correlation('Q13', 'Q16')\nplt.show()","2fa4000c":"mlf_col = 'Q19'","4df9802d":"mlf_cols = cols_part_questionary(mlf_col)\nmlf_counts = (~multiple_choice.loc[1:, mlf_cols].isna()).sum()\ncols_values = get_cols_values(multiple_choice.loc[:, mlf_cols])\nmlf_counts.index = cols_values.values\nmlf_counts.plot.barh()\nplt.show()","0ae78b13":"ax = plot_cross_correlation('Q11', mlf_col)\nax.set_title(survey_schema.Q11[0])\nplt.show()","7aa897ac":"ax = sns.heatmap(normalized_crosstab('Q20', 'Q10'))\nplt.show()","b5943219":"_ = plot_correlation_question('Q27')\ndel _","e6d7b1d8":"plt.subplots(figsize=(8, 5))\n_ = plot_correlation_question('Q29')\ndel _","ecadde92":"plt.subplots(figsize=(10, 7))\n_ = plot_correlation_question('Q28')\ndel _","da1a76bd":"legend_cols = multiple_choice.loc[0, cols_part_questionary('Q35')].str.split(' - ').tolist()[:-1]\nlegend_cols = list(map(lambda el: el[1], legend_cols))\ntime_use = multiple_choice.loc[1:, cols_part_questionary('Q35')[:-1]].fillna(0).astype('float')\ntime_use.columns = legend_cols\ntime_use.plot.hist(bins=15, title=survey_schema.Q35[0])\nplt.xlim((1, 100))\nplt.show()","6aa4f1fc":"multiple_choice.Q40[1:].value_counts().plot.barh(title=multiple_choice.Q40[0])\nplt.show()","bc2097b3":"### Use of programming language\nNow let's explore the principal use of programming languages:\n- We can note that SQL has a strong correlation with  \"Analyze and understand data to influence product or business decisions\". In my opinion this is caused by the fact that sql is used a lot in business context and, for example, not so much in reseach\n- Also R has a significative correlation with the latter, because R is mainly used by statistician and they care a lot understand data, causal relations and so on\n- The latter hypothesis is corfirmed also by the correlation with SAS\/STATA\n- It is also interesting note that research use a lot Python because popularity and the presence of Deep Learning libraries because DL is the main research area today in ML\n- Also  C\/C++ and MATLAB are used for research purpuose. The choice of C\/C++ implies more difficult to code compared to Python (e.g. manual memory management) but allow more speed of execution and also a more control of what happend under the hood.\n- Scala has a significative correlation with \"Building a data pipeline\" thanks to Spark library\n\n##### Technical notes:\nThis heatmap is extracted from the correlation matrix calculated with [CramerV](https:\/\/en.wikipedia.org\/wiki\/Cram%C3%A9r%27s_V) correlation coefficient beween the multiple choice responses between question 11 and 16.  If you have seen the csv the matrix involve the columns of type \"Q11_Part_&#65121;\" and \"Q16_Part_&#65121;, then from the square correlation matrix i've extracted the rectangular part that involve only the correlation between the possible responses in Q11 and Q16","c5d578b7":"We can observe that Python is the most used language but it also the most recomended -  in the latter case is also vastly suggested in proportion to the others ","6afb2ef9":"### Earning by programming language\n\n##### Tecnical notes:\nSince Python is the preponderant programming langauge an heatmap of \"Earning by programming language\" give light colours only to Python programming language so i thought that is more logical plot a normalized version of earning, in math terms every row is divided by the frequency of the language","641257d3":"because the major part of the people are from Computer Science (me too!). <br> It is also surprisingly low the amount of statistician that use Kaggle taking into account\n that data science is a mix of computer science and statistic. \n","b31295c1":"### IDE used by language","32e309a4":"#### DBMS\nIs interesting to note that there is a correlation \"square\" between the most popular DBMS","33a5ab42":"#### Machine learning products\nMachine learning products are different from the last cited Machine learning frameworks because have some kind of web-interface or it is a software program to run locally.<br>\nPersonally i don't like too much for the lack of flexibility but i admit they are good for anyone who don't want going too technical and deep inside machine learning field","1a85706d":"## Stationarity in the same company\nWhile i was exploring the data i noted a pattern in many CramerV correlation matrix: in different topics there is the same tendency to have an high correlation between products from the same company","51dc1aa9":"### Machine learning frameworks used in production:\nInteresting note: A 33% of the people who use CNTK and Mxnet (Deep learning libraries) have in production a ML model for more than two year","9757d082":"# Data science is a young field\nFrom the next three plots we can see that the age of kagglers is mostly between 18-30 and they have mostly low experience in the current role (i'm also in) while the companies are still exploring machine learning or not using at all. <br>\nI can also confirm this from my personal experience: in Italy, in my university, there are few people that are doing the master degree in Data Science (in my year we are 4) and there aren't so much professors that are doing research or teaching data science\/machine learning. <br>\nThere are few people also because there is a high entry barrier: in order to understand and practice it require at least a basic knowledge of statistic, math and computer science.<br>\nA young field has advantages and disadvantages:<br>\nif you are in this field there you have surely few competitors but also less collaborators: this means less progression on research, less people to chat and from a student perspective learn by yourself many things that aren't explained in any course <br>\nLuckly this trend is changing, there are many incentives to invest into data science field nowdays and i think in 10 years (but maybe also less) things changes dramatically","a05ee94a":"## The university effectiveness\nThere are a modest group of people that dedicate all  or the most of time to the university but if we see the results of question 40, a better expertize is demonstrated more likely from indipendent projects rather than academic achievements.<br>\nI don't say that university is a waste of time, i also do actually a master degree, but it is important in my opinion differentiate the kind of things we do in university: for example instead of dedicate three hours to the study for an exam you can study two hours and the last remaining you can watch a youtube video about autoencoders, or partecipate into a kaggle competition ","b5dfa88b":"# Coding stuff during ml projects\n","bfa5b29f":"## Machine learning frameworks\nNowdays exists many machine learning frameworks to do all kinds of machine learning algorithms. Most of them are for Python or R, so this cause a strong preference to this two languages in the field of Data Science.<br>\nSome are generic collection of machine learning algorithms while some others implements very well a single powerful algorithm. In the first set we have, for example, mlr and Scikit-learn for R and python respectively while in the second set we have for example randomForest, lightgbm ","69529258":"Since i have greatly appretiate the book Clean Code (read it if you hadn't!) i'm very glad that the most importants things cared by data scientist are make the code human-readable and well documented!","4cbca21e":"## Programming languages and data scientist\n### Most used programming languages\nWe know without plots that Python and R are the most widely used programming languages in the field of data scientist. <br>\nIn this survey we observe a different story but this is caused by the sample we are observing:  the major part are computer scientist so they mostly like use Python instead of R","a1724dda":"Hi! My name is Michele De Vita, i'm Italian and i have a bachelor degree in computer science and now i'm doing a master degree in data science (under the computer science department) at the University of Florence. With this kernel i want to give my impressions about this survey by a person with a computer science background! I hope you enjoy!","dfc98cba":"#### Cloud computing","ba5fd71a":"### Most popular frameworks","5b85026a":"### What is the background of the kagglers\nThe latter result is not surprising if we see the background of the kaggle survey partecipants:"}}