{"cell_type":{"a43b30ac":"code","4384363e":"code","30c1fe21":"code","309c46e9":"code","df61b6bc":"code","b3411685":"code","76f38ba6":"code","06f2da1c":"code","91fd3d50":"code","2ed61505":"code","22d642f3":"code","407c6e35":"code","e1a10b69":"code","56ba4416":"code","fda581a8":"code","72eabbc2":"code","11c12abe":"code","3d046fe4":"code","57cd69ea":"code","5cee63f0":"code","2c250141":"code","6bbbd60c":"markdown","43154d9f":"markdown","feff6aff":"markdown","2f2b57b8":"markdown","d115d86e":"markdown","0dc57cf0":"markdown","a2cec74c":"markdown","77ad11b5":"markdown","560bfb7e":"markdown","12a133aa":"markdown","5ab29969":"markdown","7fbb38fa":"markdown","8e5213ad":"markdown","a6606821":"markdown","d244f7ee":"markdown","e0fde6e5":"markdown","099cbfd2":"markdown","89497581":"markdown","1c7dedb1":"markdown"},"source":{"a43b30ac":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder\nimport os\nprint(os.listdir(\"..\/input\"))\n# Any results you write to the current directory are saved as output.","4384363e":"dataframe_companies = pd.read_csv(\"..\/input\/companies_sorted.csv\")\ndataframe_companies.head()","30c1fe21":"dataframe_companies = dataframe_companies[['name','year founded','industry','size range','country','current employee estimate']]\ndataframe_companies.head()","309c46e9":"print(dataframe_companies.info())","df61b6bc":"dataframe_companies.boxplot('year founded','size range',figsize = (10,10))","b3411685":"print('Total null values in the dataset: ',dataframe_companies.isnull().values.sum())\nprint('Column wise distribution of null values in the dataset')\nprint(dataframe_companies.isnull().sum())","76f38ba6":"#Removing the row where company name is null. Since it's completely useless. There are 3 rows where company name is null.\n#axis = 0 defines that we need to delete the row. If axis is 1 then the column would be deleted.\n#subset defines which column to consider for null values.\ndataframe_companies = dataframe_companies.dropna(axis = 0,subset = ['name'])\n\n#Cross checking if the null values were deleted properly.\nprint('Total null values in the dataset: ',dataframe_companies.isnull().values.sum())\nprint('Column wise distribution of null values in the dataset')\nprint(dataframe_companies.isnull().sum())","06f2da1c":"#fill the null values in the country by inserting \"missing\" in the column where it's null or empty.\ndataframe_companies['country'].fillna('missing',inplace = True)\ndataframe_companies['industry'].fillna('missing',inplace = True)\n\n#Keep only those rows where we have atleast 3 non null column values. Drop rest of them.\ndataframe_companies.dropna(thresh = 3, inplace = True)\n\n#Cross checking \nprint('Total null values in the dataset: ',dataframe_companies.isnull().values.sum())\nprint('Column wise distribution of null values in the dataset')\nprint(dataframe_companies.isnull().sum())","91fd3d50":"#Drawing a histogram for the year.\ndataframe_companies.hist('year founded',bins = 10)","2ed61505":"print(dataframe_companies['year founded'].median())","22d642f3":"dataframe_companies.fillna(dataframe_companies['year founded'].median(), inplace = True)\n\n#Cross checking \nprint('Total null values in the dataset: ',dataframe_companies.isnull().values.sum())\nprint('Column wise distribution of null values in the dataset')\nprint(dataframe_companies.isnull().sum())","407c6e35":"dataframe_companies.industry.value_counts()\n","e1a10b69":"labelEncoder = LabelEncoder()\nindustry_labels = labelEncoder.fit_transform(dataframe_companies['industry'])\nindustry_mappings = {index: label for index, label in enumerate(labelEncoder.classes_)}\nprint(industry_mappings)","56ba4416":"dataframe_companies['industry_mapping'] = LabelEncoder().fit_transform(dataframe_companies['industry'])\ndataframe_companies.head()","fda581a8":"dataframe_companies.country.value_counts()\n","72eabbc2":"dataframe_companies['country_mapping'] = LabelEncoder().fit_transform(dataframe_companies['country'])\ndataframe_companies.head()","11c12abe":"dataframe_companies.rename(index=str, columns={\"size range\": \"size_range\",\"year founded\": \"year_founded\",\"current employee estimate\":\"current_employee_estimate\"},inplace = True)\ndataframe_companies.head()\n","3d046fe4":"dataframe_companies.size_range.value_counts()","57cd69ea":"dataframe_companies['size_range_mapping'] = LabelEncoder().fit_transform(dataframe_companies['size_range'])\ndataframe_companies.head()","5cee63f0":"dataframe_companies['year_founded'] = dataframe_companies['year_founded'].astype(np.int64)\nprint(dataframe_companies.info())\ndataframe_companies.head()","2c250141":"dataframe_companies.to_csv('Companies_Cleaned_Dataset.csv', sep=',', encoding='utf-8')\n","6bbbd60c":"Converting the categorical data into numerical data. \nPrinting all the unique values for a categorical data to check,\n* Nominal : no order associated\n* ordinal : some order associated\n* continious : infine values between two values","43154d9f":"Converting this categorical variable into labels by label encoder","feff6aff":"Renaming certain column headers since there is space between the column names.","2f2b57b8":"Printing total null values in the dataset. Then printing the column wise distribution of null values across dataset.","d115d86e":"Importing pandas and numpy library for doing data exploration.","0dc57cf0":"Handling the missing or null values.","a2cec74c":"Loading the csv file into the memory into a pandas dataframe.\nPrinting the first 5 rows to check the data.","77ad11b5":"We have now successfully converted all the fields to numerical data. \nFor countries and industry we can further create one-hot encoding since there is no order associated with them in future. \nAlso just drop the categorical textual fields and save the table.","560bfb7e":"Convert the year field from float to int.","12a133aa":"Let's perform the subset selection. Select the columns that we care about and ignore the rest of the data.","5ab29969":"Performing the same steps for country field for converting categorical data to numerical data.","7fbb38fa":"Saving the dataset as CSV before more modification. So that we have a CSV backup. Check out the output tab on the left navigation bar to see the result. Click on the download dataset to download it.","8e5213ad":"Drawing a box plot for checking retlationship of categorical feature and continious feature.","a6606821":"Printing the median of the year. Since from the figure it's pretty much clear the year founded field has a median somewhere in mid 2000s","d244f7ee":"Printing the info of the dataframe to check what type of data is held within each column. \nEach column that has datatype set to object is potentially a categorical data.","e0fde6e5":"Checking how many unique values the size range contains","099cbfd2":"Filling in the missing value with median","89497581":"Adding these labels to our dataset as a new column.","1c7dedb1":"Industry is a nominal data type since there is no order associated with the industry. \nLet's use Scikit learn label encoder for converting the nominal data into numeric data by assigning a unique number from 0 to N - 1 = 0 to 148 for each industry."}}