{"cell_type":{"8dedbe04":"code","98db4f89":"code","cc882523":"code","34e0e768":"code","0ae157a3":"code","567acba6":"code","cbcc0fe0":"code","f3664539":"code","9f0c086f":"code","17d0d25e":"code","7a96f5b7":"code","7bab3e17":"code","1ac36b45":"code","1cee6fef":"code","09fb6f79":"code","61358eaa":"code","e57f1cc3":"code","a0e7ccee":"code","74c47d9b":"code","42853e9a":"code","b1c25a22":"code","905fc9e0":"code","4dc14485":"markdown","da3fb105":"markdown","606b0558":"markdown","205b8efd":"markdown","98c19acf":"markdown","92ea1a4e":"markdown","b8b58ee9":"markdown","64346bd1":"markdown","6fb12287":"markdown","a6b3b67a":"markdown","ab7c8e2a":"markdown","b4c771e2":"markdown","e808c8dc":"markdown","8242bb4d":"markdown","c15e4f27":"markdown","b61980df":"markdown","ed54bb26":"markdown","c230386f":"markdown","8a3b14c0":"markdown","b0dc463a":"markdown","5b270723":"markdown","993f348a":"markdown","02af9938":"markdown","ca4ea331":"markdown"},"source":{"8dedbe04":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn import svm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nimport seaborn as sns\nimport sklearn.metrics as me\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nimport plotly.figure_factory as ff\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","98db4f89":"#Reading Dataset\niris_data = pd.read_csv(\"..\/input\/Iris.csv\")\n\n\n#Dropping id column \niris_data=iris_data.drop('Id',axis=1)\n\n\n\n#print(iris_data)","cc882523":"#Common Methods\n\ndef createdf():\n    data = {'Species Type':['Iris-setosa','Iris-versicolor','Iris-virginica']}  \n    df = pd.DataFrame(data)\n    return df\n\ndef createdf_avg():\n    data = {'ML Metric':['Precision','Recall','F1 - Score']}  \n    df = pd.DataFrame(data)\n    return df\n\ndef adddata(mlmodel,report,metric,df):\n    df.loc [0,mlmodel] = round(report[\"Iris-setosa\"][metric],2)\n    df.loc [1,mlmodel] = round(report[\"Iris-versicolor\"][metric],2)\n    df.loc [2,mlmodel] = round(report[\"Iris-virginica\"][metric],2)\n    return df\n\ndef adddata_avg(mlmodel,report,avg_type,df):\n    df.loc [0,mlmodel] = round(report[avg_type][\"precision\"],4)*100\n    df.loc [1,mlmodel] = round(report[avg_type][\"recall\"],4)*100\n    df.loc [2,mlmodel] = round(report[avg_type][\"f1-score\"],4)*100\n    return df\n\n\ndef plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=True):\n    \"\"\"\n    given a sklearn confusion matrix (cm), make a nice plot\n\n    Arguments\n    ---------\n    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n\n    target_names: given classification classes such as [0, 1, 2]\n                  the class names, for example: ['high', 'medium', 'low']\n\n    title:        the text to display at the top of the matrix\n\n    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n                  see http:\/\/matplotlib.org\/examples\/color\/colormaps_reference.html\n                  plt.get_cmap('jet') or plt.cm.Blues\n\n    normalize:    If False, plot the raw numbers\n                  If True, plot the proportions\n\n    Usage\n    -----\n    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n                                                              # sklearn.metrics.confusion_matrix\n                          normalize    = True,                # show proportions\n                          target_names = y_labels_vals,       # list of names of the classes\n                          title        = best_estimator_name) # title of graph\n\n    Citiation\n    ---------\n    http:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_confusion_matrix.html\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import itertools\n\n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n\n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()\n\n\n#DFs\ndata = {'Metric':['Accuracy']}  \ndf_accuracy = pd.DataFrame(data)\ndf_precision = createdf()\ndf_recall = createdf()\ndf_f1 = createdf()\ndf_support = createdf()\ndf_macro = createdf_avg()\ndf_weighted = createdf_avg()\n","34e0e768":"#Pair plot among all features given in data set\nsns.pairplot(iris_data, hue=\"Species\", height=3, diag_kind=\"kde\")","0ae157a3":"#Assigning Varibles for Model\ny=iris_data.Species\nX =iris_data.drop('Species',1)\n\n#Splitting Data for train and test\nx_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.5,random_state=42)","567acba6":"#logistical Regression\nmodel = LogisticRegression(solver='liblinear',multi_class='auto')\nmodel.fit(x_train,y_train)\npred_test_log=model.predict(x_test)\nlog_report = classification_report(y_test,pred_test_log,output_dict=True)\ncnf_matrix = confusion_matrix(y_test,pred_test_log)\nplot_confusion_matrix(cnf_matrix,normalize = False, target_names =['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'],\n                      title='Confusion matrix, without normalization')\nplt.figure()","cbcc0fe0":"df_accuracy.loc[0,'Logistic'] = round(log_report['accuracy'],4)*100\ndf_precision = adddata('Logistic',log_report,'precision',df_precision)\ndf_recall = adddata('Logistic',log_report,'recall',df_recall)\ndf_f1 = adddata('Logistic',log_report,'f1-score',df_f1)\ndf_macro = adddata_avg('Logistic',log_report,'macro avg',df_macro)\ndf_weighted = adddata_avg('Logistic',log_report,'weighted avg',df_weighted)","f3664539":"#Decision Tree Classifier\nmodel = DecisionTreeClassifier()\nmodel.fit(x_train,y_train)\npred_test_Dec=model.predict(x_test)\nDec_report = classification_report(y_test,pred_test_Dec,output_dict=True)\ncnf_matrix = confusion_matrix(y_test,pred_test_Dec)\nplot_confusion_matrix(cnf_matrix,normalize = False, target_names =['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'],\n                      title='Confusion matrix, without normalization')\nplt.figure()","9f0c086f":"df_accuracy.loc[0,'Decision Tree'] = round(Dec_report['accuracy'],4)*100\ndf_precision = adddata('DecisionTree',Dec_report,'precision',df_precision)\ndf_recall = adddata('DecisionTree',Dec_report,'recall',df_recall)\ndf_f1 = adddata('DecisionTree',Dec_report,'f1-score',df_f1)\ndf_macro = adddata_avg('DecisionTree',Dec_report,'macro avg',df_macro)\ndf_weighted = adddata_avg('DecisionTree',Dec_report,'weighted avg',df_weighted)","17d0d25e":"#SVM\nmodel = svm.SVC(kernel='linear') \nmodel.fit(x_train,y_train)\npred_test_svm=model.predict(x_test)\nsvm_report = classification_report(y_test,pred_test_svm,output_dict=True)\ncnf_matrix = confusion_matrix(y_test,pred_test_svm)\nplot_confusion_matrix(cnf_matrix,normalize = False, target_names =['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'],\n                      title='Confusion matrix, without normalization')\nplt.figure()","7a96f5b7":"df_accuracy.loc[0,'SVM'] = round(svm_report['accuracy'],4)*100\ndf_precision = adddata('SVM',svm_report,'precision',df_precision)\ndf_recall = adddata('SVM',svm_report,'recall',df_recall)\ndf_f1 = adddata('SVM',svm_report,'f1-score',df_f1)\ndf_macro = adddata_avg('SVM',svm_report,'macro avg',df_macro)\ndf_weighted = adddata_avg('SVM',svm_report,'weighted avg',df_weighted)","7bab3e17":"#Random Forest\nmodel =  RandomForestClassifier(n_estimators=10, criterion = 'entropy')\nmodel.fit(x_train,y_train)\npred_test_rf=model.predict(x_test)\nrf_report = classification_report(y_test,pred_test_rf,output_dict=True)\ncnf_matrix = confusion_matrix(y_test,pred_test_rf)\nplot_confusion_matrix(cnf_matrix,normalize = False, target_names =['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'],\n                      title='Confusion matrix, without normalization')\nplt.figure()","1ac36b45":"df_accuracy.loc[0,'Random Forest'] = round(rf_report['accuracy'],4)*100\ndf_precision = adddata('RandomForest',rf_report,'precision',df_precision)\ndf_recall = adddata('RandomForest',rf_report,'recall',df_recall)\ndf_f1 = adddata('RandomForest',rf_report,'f1-score',df_f1)\ndf_macro = adddata_avg('RandomForest',rf_report,'macro avg',df_macro)\ndf_weighted = adddata_avg('RandomForest',rf_report,'weighted avg',df_weighted)","1cee6fef":"#KNN\nmodel = KNeighborsClassifier(n_neighbors=1, metric='minkowski')\nmodel.fit(x_train,y_train)\npred_test_knn=model.predict(x_test)\nknn_report = classification_report(y_test,pred_test_knn,output_dict=True)\ncnf_matrix = confusion_matrix(y_test,pred_test_knn)\nplot_confusion_matrix(cnf_matrix,normalize = False, target_names =['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'],\n                      title='Confusion matrix, without normalization')\nplt.figure()","09fb6f79":"df_accuracy.loc[0,'KNN'] = round(knn_report['accuracy'],4)*100\ndf_precision = adddata('KNN',knn_report,'precision',df_precision)\ndf_recall = adddata('KNN',knn_report,'recall',df_recall)\ndf_f1 = adddata('KNN',knn_report,'f1-score',df_f1)\ndf_macro = adddata_avg('KNN',knn_report,'macro avg',df_macro)\ndf_weighted = adddata_avg('KNN',knn_report,'weighted avg',df_weighted)","61358eaa":"#Naive Bayes\nmodel = GaussianNB()\nmodel.fit(x_train, y_train)\npred_test_nb=model.predict(x_test)\nnb_report = classification_report(y_test,pred_test_nb,output_dict=True)\ncnf_matrix = confusion_matrix(y_test,pred_test_nb)\nplot_confusion_matrix(cnf_matrix,normalize = False, target_names =['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'],\n                      title='Confusion matrix, without normalization')\nplt.figure()","e57f1cc3":"df_accuracy.loc[0,'Naive Bayes'] = round(nb_report['accuracy'],4)*100\ndf_precision = adddata('NB',nb_report,'precision',df_precision)\ndf_recall = adddata('NB',nb_report,'recall',df_recall)\ndf_f1 = adddata('NB',nb_report,'f1-score',df_f1)\ndf_macro = adddata_avg('NB',nb_report,'macro avg',df_macro)\ndf_weighted = adddata_avg('NB',nb_report,'weighted avg',df_weighted)","a0e7ccee":"df_accuracy","74c47d9b":"df_precision","42853e9a":"df_recall","b1c25a22":"df_f1","905fc9e0":"df_weighted","4dc14485":"# **Description**","da3fb105":"# **Data Distribution Visualization**","606b0558":"  # **Impression :** \n1. <n> Predicted all 29 species of Iris-Setosa\n2. <n> Predicted all 23 species of Iris-Versicolor \n3. <n> Predicted all 23 species of Iris-Verginica","205b8efd":"# **SVM**","98c19acf":"# Recall Comparision ","92ea1a4e":"# Precision Comparision ","b8b58ee9":" **Ranking:**\n1. <n> SVM\n2. <n> Naive bayes\n3. <n> Logistic, Random Forest , KNN \n3. <n> Decision Tree","64346bd1":" **Conclusion:**\n\n<n> 1. SVM performs the best while Decision Tree is the least among the 6 Models\n<n> 2. Iris-setosa class has perfect score for all models.This is because of the     <n>    seprate set of points which is not interfering with other classes\n<n> 3. Precision of all models are above 96 %\n<n> 4. The models which has less precision is because of mispredicting Iris-       <n>    versicolor and Iris-virginica\n","6fb12287":"# F1 Score Comparision ","a6b3b67a":"# Naive Bayes Classifier ","ab7c8e2a":"  # **Impression :** \n1. <n> Predicted all 29 species of Iris-Setosa\n2. <n> Missed 3 out of 23 species of Iris-Versicolor \n3. <n> Missed 2 out of 23 species of Iris-Verginica","b4c771e2":"# **Classification**","e808c8dc":"The aim of this kernel is to compare the performance of 6 machine learning classification models on a single dataset with less training","8242bb4d":"# **Decision Tree Classifier**","c15e4f27":"  # **Impression :** \n1. <n> Predicted all 29 species of Iris-Setosa\n2. <n> Missed 2 out of 23 species of Iris-Versicolor \n3. <n> Predicted all 23 species of Iris-Verginica","b61980df":"  # **Impression :** \n1. <n> Predicted all 29 species of Iris-Setosa\n2. <n> Predicted all 23 species of Iris-Versicolor \n3. <n> Missed 1 out of 23 species of Iris-Verginica","ed54bb26":"# **Precision , Recall and F1 Score (Overall)**","c230386f":"  # **Impression :** \n1. <n> Predicted all 29 species of Iris-Setosa\n2. <n> Predicted all 23 species of Iris-Versicolor \n3. <n> Missed 2 out of 23 species of Iris-Verginica","8a3b14c0":"  # **Impression :** \n1. <n> Predicted all 29 species of Iris-Setosa\n2. <n> Predicted all 23 species of Iris-Versicolor \n3. <n> Missed 2 out of 23 species of Iris-Verginica","b0dc463a":"# **Logistic Regression**","5b270723":"<n>The X and Y variables are same for all models. The models will be tested for multi class classification problem (IRIS Specicies).\n<n>\n<n>\nThe following 6 models will be used for comparison\n\n<n>1.Logistical Regression\n<n>2.Decision Tree Classifier \n<n>3.SVM\n<n>4.Random Forest\n<n>5.KNN\n<n>6.Naive Bayes Classifier\n","993f348a":"# **KNN**","02af9938":"# **Random Forest**","ca4ea331":"# Accuracy Comparision "}}