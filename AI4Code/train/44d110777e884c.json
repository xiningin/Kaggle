{"cell_type":{"7bb3852a":"code","e8b2bf87":"code","83d1c8ca":"code","e3ae36ed":"code","4c8b6e9c":"code","0b876dc6":"code","caf266ce":"code","fc9f45b3":"code","f57efa0e":"code","17a50f51":"code","52d2296f":"code","5facb969":"code","a10448b3":"code","ff6230fc":"code","2710c543":"code","7e38addc":"code","1dcc127b":"code","c7890442":"code","6aedd0ae":"markdown","d84640ff":"markdown","2984bca1":"markdown","4053cb82":"markdown","5ffb7509":"markdown","84f36c7d":"markdown","80cd881a":"markdown","20b8578a":"markdown","72dd062c":"markdown","bded17b4":"markdown","b9f5043a":"markdown","935a5930":"markdown"},"source":{"7bb3852a":"!pip install ..\/input\/kerasapplications\/keras-team-keras-applications-3b180cb -f .\/ --no-index\n!pip install ..\/input\/efficientnet\/efficientnet-1.1.0\/ -f .\/ --no-index\n\nimport efficientnet.tfkeras as efn","e8b2bf87":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom mlxtend.plotting import plot_confusion_matrix\n\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\nimport tensorflow as tf\nfrom keras.utils.vis_utils import plot_model\nimport tensorflow_addons as tfa\n\ndef seed_everything(seed=2020):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\nSEED = 42\nseed_everything(SEED)\n\nsns.set_style(\"whitegrid\")\nmpl.rc(\"axes\", labelsize=14)\nmpl.rc(\"xtick\", labelsize=12)\nmpl.rc(\"ytick\", labelsize=12)\npalette_ro = [\"#ee2f35\", \"#fa7211\", \"#fbd600\", \"#75c731\", \"#1fb86e\", \"#0488cf\", \"#7b44ab\"]\n\nROOT = \"..\/input\/chest-xray-pneumonia\/chest_xray\/\"\nprint(os.listdir(ROOT))","83d1c8ca":"train_dir = ROOT + \"train\/\"\nval_dir = ROOT + \"val\/\"\ntest_dir = ROOT + \"test\/\"\n\nIMG_SIZE = 224\n# b0: 224, b1: 240, b2: 260, b3: 300, b4: 380, b5: 456, b6: 528, b7: 600\nBATCH_SIZE = 64\n\nd1 = 64\nd2 = 32\nEPOCHS_1 = 7\n\nfine_tune_at = 45\nEPOCHS_2 = 10","e3ae36ed":"print(\"Train dataset:\")\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    train_dir,\n    # validation_split=0.2,\n    # subset=\"training\",\n    seed=SEED,\n    image_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE)\n\nprint(\"Validation dataset:\")\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    val_dir,\n    seed=SEED,\n    image_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE)","4c8b6e9c":"class_count = pd.DataFrame(index=[\"label\", \"count\"])\n\nfor _class in train_ds.class_names:\n    print(\"{:<14}{} images\".format(_class, len(os.listdir(train_dir + _class))))\n    class_count[_class] = [_class, len(os.listdir(train_dir + _class))]\n\n# NUM_CLASSES = len(train_ds.class_names)\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 5))\nsns.barplot(x=\"label\", y=\"count\", data=class_count.T, ax=ax, palette=palette_ro[1::5])\nfig.suptitle(\"Train dataset distribution\", fontsize=18);","0b876dc6":"plt.figure(figsize=(12, 12))\nfor images, labels in train_ds.take(1):\n    for i in range(16):\n        ax = plt.subplot(4, 4, i+1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(train_ds.class_names[labels[i]])\n        plt.axis(\"off\")","caf266ce":"sample = next(iter(train_ds))[0][0].numpy().astype(\"uint8\")\nplt.imshow(sample)\nplt.axis(\"off\");","fc9f45b3":"data_augmentation = tf.keras.Sequential([\n    tf.keras.layers.experimental.preprocessing.RandomRotation(0.02, seed=SEED),\n    tf.keras.layers.experimental.preprocessing.RandomTranslation(0.1, 0.1, seed=SEED),\n    tf.keras.layers.experimental.preprocessing.RandomZoom(0.33, seed=SEED),\n    tf.keras.layers.experimental.preprocessing.RandomFlip(mode=\"horizontal\", seed=SEED),\n    # tf.keras.layers.experimental.preprocessing.RandomHeight(0.1, interpolation=\"nearest\", seed=SEED),\n    # tf.keras.layers.experimental.preprocessing.RandomWidth(0.1, interpolation=\"nearest\", seed=SEED),\n    # tf.keras.layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE, interpolation=\"nearest\"),\n    # tf.keras.layers.experimental.preprocessing.RandomContrast(0.1, 1.9)\n])\n\nsample_b = tf.expand_dims(sample, 0)\n\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n    result = data_augmentation(sample_b)\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(result[0])\n    plt.axis(\"off\")","f57efa0e":"def build_model():\n    inp = tf.keras.layers.Input((IMG_SIZE, IMG_SIZE, 3))\n    x =  tf.keras.layers.experimental.preprocessing.Rescaling(1.\/127.5, offset=-1)(inp)\n    x = data_augmentation(x)\n    \n    ef = efn.EfficientNetB0(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights=\"imagenet\", input_tensor=x)\n    ef.trainable = False\n    \n    x = tf.keras.layers.GlobalAveragePooling2D()(ef.output)\n    #x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dropout(0.32)(x)\n    x = tf.keras.layers.Dense(d1, activation=\"elu\")(x)\n    # x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dropout(0.25)(x)\n    x = tf.keras.layers.Dense(d2, activation=\"elu\")(x)\n    # x = tf.keras.layers.BatchNormalization()(x)\n    # x = tf.keras.layers.Dropout(0.2)(x)\n    \n    y = tf.keras.layers.Dense(1, activation=\"sigmoid\", kernel_initializer=\"he_normal\")(x)\n    \n    model = tf.keras.Model(inputs=inp, outputs=y)\n    \n    return model\n\nmodel = build_model()\n\nprint(\"Number of layers in the model: \", len(model.layers))\nmodel.summary()","17a50f51":"AUTOTUNE = tf.data.experimental.AUTOTUNE\ntrain_ds = train_ds.cache().shuffle(1000, seed=SEED).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","52d2296f":"model.compile(optimizer=tfa.optimizers.RectifiedAdam(),\n              loss=\"binary_crossentropy\",\n              metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=EPOCHS_1\n)","5facb969":"acc = history.history[\"accuracy\"]\nval_acc = history.history[\"val_accuracy\"]\n\nloss = history.history[\"loss\"]\nval_loss = history.history[\"val_loss\"]\n\nprec = history.history[\"precision\"]\nval_prec = history.history[\"val_precision\"]\n\nrec = history.history[\"recall\"]\nval_rec = history.history[\"val_recall\"]\n\nepochs_range = range(EPOCHS_1)\n\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n\nax1.plot(epochs_range, acc, label=\"Training Accuracy\")\nax1.plot(epochs_range, val_acc, label=\"Validation Accuracy\")\nax1.legend(loc=\"lower right\")\nax1.set_title(\"Training and Validation Accuracy\", fontsize=16)\n\nax2.plot(epochs_range, loss, label=\"Training Loss\")\nax2.plot(epochs_range, val_loss, label=\"Validation Loss\")\nax2.legend(loc=\"upper right\")\nax2.set_title(\"Training and Validation Loss\", fontsize=16)\n\nax3.plot(epochs_range, prec, label=\"Training Precision\")\nax3.plot(epochs_range, val_prec, label=\"Validation Precision\")\nax3.legend(loc=\"lower right\")\nax3.set_title(\"Training and Validation Precision\", fontsize=16)\n\nax4.plot(epochs_range, rec, label=\"Training Recall\")\nax4.plot(epochs_range, val_rec, label=\"Validation Recall\")\nax4.legend(loc=\"lower right\")\nax4.set_title(\"Training and Validation Recall\", fontsize=16)\n\nplt.tight_layout()\nplt.show()","a10448b3":"def unfreeze_model(model):\n    for layer in model.layers[-fine_tune_at:]:\n        if not isinstance(layer, tf.keras.layers.BatchNormalization):\n            layer.trainable = True\n\n    model.compile(optimizer=tfa.optimizers.RectifiedAdam(),\n                  loss=\"binary_crossentropy\",\n                  metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n\nunfreeze_model(model)","ff6230fc":"history = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=EPOCHS_2\n)","2710c543":"acc = history.history[\"accuracy\"]\nval_acc = history.history[\"val_accuracy\"]\n\nloss = history.history[\"loss\"]\nval_loss = history.history[\"val_loss\"]\n\nprec = history.history[\"precision_1\"]\nval_prec = history.history[\"val_precision_1\"]\n\nrec = history.history[\"recall_1\"]\nval_rec = history.history[\"val_recall_1\"]\n\nepochs_range = range(EPOCHS_2)\n\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n\nax1.plot(epochs_range, acc, label=\"Training Accuracy\")\nax1.plot(epochs_range, val_acc, label=\"Validation Accuracy\")\nax1.legend(loc=\"lower right\")\nax1.set_title(\"Training and Validation Accuracy\", fontsize=16)\n\nax2.plot(epochs_range, loss, label=\"Training Loss\")\nax2.plot(epochs_range, val_loss, label=\"Validation Loss\")\nax2.legend(loc=\"upper right\")\nax2.set_title(\"Training and Validation Loss\", fontsize=16)\n\nax3.plot(epochs_range, prec, label=\"Training Precision\")\nax3.plot(epochs_range, val_prec, label=\"Validation Precision\")\nax3.legend(loc=\"lower right\")\nax3.set_title(\"Training and Validation Precision\", fontsize=16)\n\nax4.plot(epochs_range, rec, label=\"Training Recall\")\nax4.plot(epochs_range, val_rec, label=\"Validation Recall\")\nax4.legend(loc=\"lower right\")\nax4.set_title(\"Training and Validation Recall\", fontsize=16)\n\nplt.tight_layout()\nplt.show()","7e38addc":"print(\"Test dataset:\")\ntest_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    test_dir,\n    seed=SEED,\n    image_size=(IMG_SIZE, IMG_SIZE),\n)\n\ntest_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)","1dcc127b":"y_test = []\n\nfor i in range(len(list(test_ds))):\n    y_test += list(list(test_ds)[i][1].numpy())","c7890442":"preds = model.predict(test_ds)\ny_pred = preds > 0.5\n\nfig, ax = plot_confusion_matrix(confusion_matrix(y_test, y_pred), figsize=(12,8), hide_ticks=True, colorbar=True, class_names=[\"NORMAL\", \"PNEUMONIA\"])\n\nplt.title(\"Confusion Matrix\", fontsize=18)\nplt.ylabel(\"True label\", fontsize=14)\nplt.xlabel(\"Predicted label\\naccuracy={:0.4f}, F1-score={:0.4f}\".format(accuracy_score(y_test, y_pred), f1_score(y_test, y_pred)), fontsize=14)\nplt.xticks(np.arange(2), [\"NORMAL\", \"PNEUMONIA\"], fontsize=16)\nplt.yticks(np.arange(2), [\"NORMAL\", \"PNEUMONIA\"], fontsize=16);\n\nprint(\"Classification report on test data\")\nprint(classification_report(y_test, y_pred))","6aedd0ae":"We were able to get good accuracy. Thanks so much for reading!<br>\n<font color=\"RoyalBlue\">\u826f\u3044\u7cbe\u5ea6\u3092\u51fa\u3059\u3053\u3068\u304c\u3067\u304d\u307e\u3057\u305f\u3002\u3053\u3053\u307e\u3067\u8aad\u3093\u3067\u304f\u3060\u3055\u308a\u3069\u3046\u3082\u3042\u308a\u304c\u3068\u3046\u3054\u3056\u3044\u307e\u3057\u305f\uff01<\/font>","d84640ff":"<a id=\"load\"><\/a>\n# Load the data \ud83d\udcc3","2984bca1":"<a id=\"overview\"><\/a>\n# Overview \ud83e\uddd0\n<img src=\"https:\/\/i.imgur.com\/KdaJ6z7.jpg\" width=\"600\"><br>\nIn this notebook, we predict from the chest x-ray images whether the patient's lungs are normal or pneumonia. This prediction will help the hospital in diagnosing patients.<br>\n<font color=\"RoyalBlue\">\u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3067\u306f\u3001\u80f8\u90e8X\u7dda\u753b\u50cf\u304b\u3089\u3001\u60a3\u8005\u306e\u80ba\u304c\u6b63\u5e38\u304b\u80ba\u708e\u304b\u3092\u4e88\u6e2c\u3057\u307e\u3059\u3002\u3053\u306e\u4e88\u6e2c\u306f\u75c5\u9662\u3067\u60a3\u8005\u3092\u8a3a\u65ad\u3059\u308b\u969b\u306b\u5f79\u7acb\u3066\u3089\u308c\u308b\u3067\u3057\u3087\u3046\u3002<\/font><br>\n\nWe will first load the image data set using `tf.data`. We then visualize the images and also check how the image data is augmented. Then we use a pre-trained model (EfficientNet) to build the model and perform the transfer training. We then fine-tune the model and then train it, and finally check the performance measures and confusion matrix.<br>\n<font color=\"RoyalBlue\">\u307e\u305a\u306f tf.data \u3092\u4f7f\u3063\u3066\u753b\u50cf\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002\u305d\u308c\u304b\u3089\u753b\u50cf\u3092\u53ef\u8996\u5316\u3057\u3001\u753b\u50cf\u30c7\u30fc\u30bf\u306e\u62e1\u5f35\u65b9\u6cd5\u3082\u30c1\u30a7\u30c3\u30af\u3057\u3066\u3044\u304d\u307e\u3059\u3002\u305d\u3057\u3066\u3001\u4e8b\u524d\u8a13\u7df4\u3055\u308c\u305f\u30e2\u30c7\u30eb\uff08EfficientNet\uff09\u3092\u4f7f\u3063\u3066\u30e2\u30c7\u30eb\u3092\u69cb\u7bc9\u3057\u3001\u8ee2\u79fb\u5b66\u7fd2\u3092\u884c\u3044\u307e\u3059\u3002\u305d\u306e\u3042\u3068\u30e2\u30c7\u30eb\u306e\u30d5\u30a1\u30a4\u30f3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3092\u884c\u3063\u3066\u304b\u3089\u8a13\u7df4\u3057\u3001\u6700\u5f8c\u306b\u6027\u80fd\u6307\u6a19\u3084\u6df7\u540c\u884c\u5217\u3092\u78ba\u8a8d\u3057\u307e\u3059\u3002<\/font>\n\n# Table of contents \ud83d\udcd6\n* [Overview \ud83e\uddd0](#overview)\n* [Setup \ud83d\udcbb](#setup)\n* [Load the data \ud83d\udcc3](#load)\n* [Visualise the data \ud83d\uddbc](#visualise)\n* [Data augmentation \ud83d\udc50](#augmentation)\n* [Create and train the model \ud83e\udde0](#model)\n    * [Transfer learning \ud83e\uddca](#transfer)\n    * [Fine tuning \ud83d\udd25](#tuning)\n* [Evaluate the model \ud83d\udcaf](#evaluate)\n\n<a id=\"setup\"><\/a>\n# Setup \ud83d\udcbb\nAll seed values are fixed at 42.<br>\n<font color=\"RoyalBlue\">\u30b7\u30fc\u30c9\u5024\u306f\u5168\u306642\u3067\u56fa\u5b9a\u3057\u3066\u3044\u307e\u3059\u3002<\/font><br>","4053cb82":"Before training, we will compile the model. In this case, we will use Rectified Adam (RAdam) for the optimization algorithm. It is an algorithm that warms up (starts with a smaller-than-normal learning rate and gradually increases to the normal learning rate as the training progresses) in the early stages of training.<br>\n<font color=\"RoyalBlue\">\u8a13\u7df4\u306e\u524d\u306b\u3001\u30e2\u30c7\u30eb\u306e\u30b3\u30f3\u30d1\u30a4\u30eb\u3092\u884c\u3044\u307e\u3059\u3002\u4eca\u56de\u306f\u3001\u6700\u9069\u5316\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306b\u306f Rectified Adam (RAdam) \u3092\u4f7f\u3044\u307e\u3059\u3002\u5b66\u7fd2\u306e\u521d\u671f\u6bb5\u968e\u306b\u304a\u3044\u3066 Warmup\uff08\u901a\u5e38\u3088\u308a\u3082\u5c0f\u3055\u306a\u5b66\u7fd2\u7387\u3067\u59cb\u3081\u3001\u5b66\u7fd2\u304c\u9032\u3080\u306b\u3064\u308c\u3066\u5f90\u3005\u306b\u901a\u5e38\u306e\u5b66\u7fd2\u7387\u307e\u3067\u4e0a\u3052\u3066\u3044\u304f\uff09\u3059\u308b\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3067\u3059\u3002<\/font><br>\n\nThe loss function is `binary_crossentropy`. Cross entropy loss is a measure defined between the two probability distributions, and the goal of the training is to reduce this value.<br>\n<font color=\"RoyalBlue\">\u640d\u5931\u95a2\u6570\u306f binary_crossentropy \u3067\u3059\u3002\u4ea4\u5dee\u30a8\u30f3\u30c8\u30ed\u30d4\u30fc\u640d\u5931\u306f2\u3064\u306e\u78ba\u7387\u5206\u5e03\u306e\u9593\u306b\u5b9a\u7fa9\u3055\u308c\u308b\u5c3a\u5ea6\u3067\u3001\u3053\u306e\u5024\u3092\u5c0f\u3055\u304f\u3059\u308b\u306e\u304c\u5b66\u7fd2\u306e\u76ee\u7684\u306b\u306a\u308a\u307e\u3059\u3002<\/font><br>\n\nThe metric functions we use are accuracy, precision and recall.<br>\nThe performance measures for classifiers are as follows.<br>\n<font color=\"RoyalBlue\">\u8a55\u4fa1\u95a2\u6570\u306b\u306f\u6b63\u89e3\u7387\u3001\u9069\u5408\u7387\u3001\u518d\u73fe\u7387\u3092\u4f7f\u3044\u307e\u3059\u3002<br>\n\u5206\u985e\u5668\u306e\u6027\u80fd\u6307\u6a19\u306b\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u3082\u306e\u304c\u3042\u308a\u307e\u3059\u3002<\/font>\n\n> Referenced from Hands-On Machine Learning with Scikit-Learn and TensorFlow (Aurelien Geron, 2017).\n* accuracy - the ratio of correct predictions\n<br>\u3000<font color=\"RoyalBlue\">\u6b63\u89e3\u7387\uff08\u7cbe\u5ea6\uff09 - \u6b63\u3057\u3044\u4e88\u6e2c\u306e\u5272\u5408<\/font>\n* confusion matrix - counting the number of times instances of class A are classified as class B\n<br>\u3000<font color=\"RoyalBlue\">\u6df7\u540c\u884c\u5217 - \u30af\u30e9\u30b9\uff21\u306e\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u304c\u30af\u30e9\u30b9\uff22\u306b\u5206\u985e\u3055\u308c\u305f\u56de\u6570\u3092\u6570\u3048\u308b<\/font>\n* precision - the accuracy of the positive predictions\n<br>\u3000<font color=\"RoyalBlue\">\u9069\u5408\u7387 - \u967d\u6027\u306e\u4e88\u6e2c\u306e\u6b63\u89e3\u7387\uff08\u967d\u6027\u3067\u3042\u308b\u3068\u4e88\u6e2c\u3057\u305f\u3046\u3061\u3001\u5f53\u305f\u3063\u3066\u3044\u305f\u7387\uff09<\/font>\n* recall (sensitivity, true positive rate: TPR) - the ratio of positive instances that are correctly detected by the classifier\n<br>\u3000<font color=\"RoyalBlue\">\u518d\u73fe\u7387\uff08\u611f\u5ea6\u3001\u771f\u967d\u6027\u7387\uff09- \u5206\u985e\u5668\u304c\u6b63\u3057\u304f\u5206\u985e\u3057\u305f\u967d\u6027\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u306e\u5272\u5408\uff08\u672c\u5f53\u306b\u967d\u6027\u3067\u3042\u308b\u30b1\u30fc\u30b9\u306e\u3046\u3061\u3001\u967d\u6027\u3060\u3068\u5224\u5b9a\u3067\u304d\u305f\u7387\uff09<\/font>\n* F1 score - the harmonic mean of precision and recall\n<br>\u3000<font color=\"RoyalBlue\">F1 \u30b9\u30b3\u30a2\uff08F \u5024\uff09 - \u9069\u5408\u7387\u3068\u518d\u73fe\u7387\u306e\u8abf\u548c\u5e73\u5747\uff08\u7b97\u8853\u5e73\u5747\u306b\u6bd4\u3079\u3001\u8abf\u548c\u5e73\u5747\u306f\u4f4e\u3044\u5024\u306b\u305d\u3046\u3067\u306a\u3044\u5024\u3088\u308a\u3082\u305a\u3063\u3068\u5927\u304d\u306a\u91cd\u307f\u3092\u7f6e\u304f\uff09<\/font>\n* AUC - the area under the ROC curve (plotting the true positive rate (another name for recall) against the false positive rate)\n<br>\u3000<font color=\"RoyalBlue\">AUC - ROC \u66f2\u7dda\uff08\u507d\u967d\u6027\u7387\u306b\u5bfe\u3059\u308b\u771f\u967d\u6027\u7387\uff08\u518d\u73fe\u7387\uff09\u3092\u30d7\u30ed\u30c3\u30c8\u3057\u305f\u66f2\u7dda\uff09\u306e\u4e0b\u306e\u9762\u7a4d<\/font><br>\n\nWhen evaluating the model, the confusion matrix and F1 score will be checked, as well as accuracy and other measures in the test data.<br>\n<font color=\"RoyalBlue\">\u6700\u5f8c\u306b\u30e2\u30c7\u30eb\u306e\u8a55\u4fa1\u3092\u884c\u3046\u3068\u304d\u306b\u306f\u3001\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3067\u306e\u7cbe\u5ea6\u306a\u3069\u3068\u3068\u3082\u306b\u6df7\u540c\u884c\u5217\u3084 F1 \u30b9\u30b3\u30a2\u3082\u78ba\u8a8d\u3057\u307e\u3059\u3002<\/font>","5ffb7509":"Dataset from: [Labeled Optical Coherence Tomography (OCT) and Chest X-Ray Images for Classification](https:\/\/data.mendeley.com\/datasets\/rscbjbr9sj\/2)\n\n* `NORMAL`<font color=\"RoyalBlue\"> - \u6b63\u5e38<\/font>\n* `PNEUMONIA`<font color=\"RoyalBlue\"> - \u80ba\u708e<\/font>\n\n<a id=\"visualise\"><\/a>\n# Visualise the data \ud83d\uddbc","84f36c7d":"<a id=\"augmentation\"><\/a>\n# Data augmentation \ud83d\udc50\nWe will use keras preprocessing layers for data augmentation. Let's try it out on the sample image.<br>\n<font color=\"RoyalBlue\">Keras \u306e\u524d\u51e6\u7406\u5c64\u3092\u4f7f\u3063\u3066\u753b\u50cf\u30c7\u30fc\u30bf\u3092\u62e1\u5f35\u3057\u3066\u3044\u304d\u307e\u3059\u3002\u8a66\u3057\u306b\u30b5\u30f3\u30d7\u30eb\u753b\u50cf\u306b\u9069\u7528\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002<\/font>","80cd881a":"<a id=\"evaluate\"><\/a>\n# Evaluate the model \ud83d\udcaf\nLoad the test dataset and evaluate the model by looking at the performance measures and confusion matrix in the test data.<br>\n<font color=\"RoyalBlue\">\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u30ed\u30fc\u30c9\u3057\u3001\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3067\u306e\u6027\u80fd\u6307\u6a19\u3084\u6df7\u540c\u884c\u5217\u3092\u898b\u3066\u30e2\u30c7\u30eb\u3092\u8a55\u4fa1\u3057\u307e\u3059\u3002<\/font>","20b8578a":"As you can see, the sample image is randomly rotated, translated, zoomed and flipped.<br>\n<font color=\"RoyalBlue\">\u3053\u306e\u3088\u3046\u306b\u3001\u30b5\u30f3\u30d7\u30eb\u753b\u50cf\u304c\u30e9\u30f3\u30c0\u30e0\u306b\u56de\u8ee2\u30fb\u79fb\u52d5\u30fb\u62e1\u5927\u30fb\u30d5\u30ea\u30c3\u30d7\u3057\u3066\u3044\u308b\u306e\u3092\u78ba\u8a8d\u3067\u304d\u307e\u3059\u3002<\/font>\n\n<a id=\"model\"><\/a>\n# Create and train the model \ud83e\udde0\n<a id=\"transfer\"><\/a>\n## Transfer learning \ud83e\uddca\nFirst, we use EfficientNet, a pre-trained model, to perform transition learning. We remove the top layer and add a new `Dense` layer and so on. To avoid training the EfficientNet part of the model during training, we set `trainable = False`.<br>\n<font color=\"RoyalBlue\">\u307e\u305a\u306f\u3001\u4e8b\u524d\u5b66\u7fd2\u6e08\u307f\u306e\u30e2\u30c7\u30eb\u3067\u3042\u308b EfficientNet \u3092\u4f7f\u3063\u3066\u8ee2\u79fb\u5b66\u7fd2\u3092\u884c\u3044\u307e\u3059\u3002\u6700\u4e0a\u4f4d\u5c64\u306f\u7121\u304f\u3057\u3066\u3001\u65b0\u305f\u306b Dense \u5c64\u306a\u3069\u3092\u8ffd\u52a0\u3057\u307e\u3059\u3002\u8a13\u7df4\u4e2d\u306b EfficientNet \u90e8\u5206\u306f\u5b66\u7fd2\u3057\u306a\u3044\u3088\u3046\u306b\u3059\u308b\u305f\u3081\u3001trainable = False \u3068\u8a2d\u5b9a\u3057\u3066\u304a\u304d\u307e\u3057\u3087\u3046\u3002<\/font>","72dd062c":"Now, let's continue with the training.<br>\n<font color=\"RoyalBlue\">\u3067\u306f\u3001\u8a13\u7df4\u306e\u7d9a\u304d\u3092\u884c\u3063\u3066\u3044\u304d\u307e\u3057\u3087\u3046\u3002<\/font>","bded17b4":"Let's get a sample image from the train dataset.<br>\n<font color=\"RoyalBlue\">\u8a13\u7df4\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u304b\u3089\uff11\u3064\u30b5\u30f3\u30d7\u30eb\u753b\u50cf\u3092\u53d6\u5f97\u3057\u3066\u307f\u307e\u3059\u3002<\/font><br>","b9f5043a":"To optimize performance, the dataset should be cached and prefetched. The training dataset will also be shuffled.<br>\n<font color=\"RoyalBlue\">\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u6700\u9069\u5316\u3059\u308b\u305f\u3081\u306b\u3001\u4f7f\u7528\u3059\u308b\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u30ad\u30e3\u30c3\u30b7\u30f3\u30b0\u3001\u30d7\u30ea\u30d5\u30a7\u30c3\u30c1\uff08\u4e8b\u524d\u8aad\u8fbc\u307f\uff09\u3092\u884c\u3063\u3066\u304a\u304d\u307e\u3059\u3002\u8a13\u7df4\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306f\u30b7\u30e3\u30c3\u30d5\u30eb\u3082\u884c\u3044\u307e\u3059\u3002<\/font>","935a5930":"<a id=\"tuning\"><\/a>\n## Fine tuning \ud83d\udd25\nNext, we unfreeze some of the upper layers of EfficientNet and fine-tune it. You will need to recompile the model for this to take effect.<br>\n<font color=\"RoyalBlue\">\u6b21\u306b\u3001EfficientNet \u306e\u4e0a\u4f4d\u5c64\u3092\u3044\u304f\u3064\u304b\u89e3\u51cd\u3057\u3001\u30d5\u30a1\u30a4\u30f3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\uff08\u5fae\u8abf\u6574\uff09\u3092\u884c\u3044\u307e\u3059\u3002\u30e2\u30c7\u30eb\u3092\u518d\u30b3\u30f3\u30d1\u30a4\u30eb\u3059\u308c\u3070\u3053\u306e\u8a2d\u5b9a\u304c\u6709\u52b9\u306b\u306a\u308a\u307e\u3059\u3002<\/font>"}}