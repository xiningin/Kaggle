{"cell_type":{"26961c24":"code","bd8f9cc2":"code","77543095":"code","28a2f7dd":"code","721e59ac":"code","21af75cb":"code","43a72da7":"code","f0e9107a":"code","d7d81d3e":"code","0ee91865":"code","b4d21eff":"code","38b4ff01":"code","832544a8":"code","9243f16b":"code","f7baf0d5":"code","a61d17b9":"code","0ad310d8":"code","849d243b":"code","bbf4d8b5":"code","0fa89e92":"code","ec9667e2":"code","56fb72ad":"code","a761002e":"code","32156eb8":"code","e83e1fda":"code","496b3530":"code","3b4a24db":"code","f46da057":"markdown","1174627f":"markdown","40ade212":"markdown","3d57af32":"markdown","fbda78d6":"markdown","077d6dd9":"markdown","80e6eab0":"markdown","40d6443e":"markdown","70a7ac90":"markdown","3d4f9d8f":"markdown","cbcab9bf":"markdown","d8bd8a66":"markdown","36615875":"markdown","a5a3fbe0":"markdown","84cbde5e":"markdown"},"source":{"26961c24":"%matplotlib inline\n\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport cv2\nimport os\nimport glob","bd8f9cc2":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","77543095":"IMAGE_SIZE = 224","28a2f7dd":"img_dir = \"..\/input\/car-plate-detection\/images\" # Enter Directory of all images \ndata_path = os.path.join(img_dir,'*g')\nfiles = glob.glob(data_path)\nfiles.sort() #We sort the images in alphabetical order to match them to the xml files containing the annotations of the bounding boxes\nX=[]\nfor f1 in files:\n    img = cv2.imread(f1)\n    img = cv2.resize(img, (IMAGE_SIZE,IMAGE_SIZE))\n    X.append(np.array(img))\n    ","721e59ac":"from lxml import etree\ndef resizeannotation(f):\n    tree = etree.parse(f)\n    for dim in tree.xpath(\"size\"):\n        width = int(dim.xpath(\"width\")[0].text)\n        height = int(dim.xpath(\"height\")[0].text)\n    for dim in tree.xpath(\"object\/bndbox\"):\n        xmin = int(dim.xpath(\"xmin\")[0].text)\/(width\/IMAGE_SIZE)\n        ymin = int(dim.xpath(\"ymin\")[0].text)\/(height\/IMAGE_SIZE)\n        xmax = int(dim.xpath(\"xmax\")[0].text)\/(width\/IMAGE_SIZE)\n        ymax = int(dim.xpath(\"ymax\")[0].text)\/(height\/IMAGE_SIZE)\n    return [int(xmax), int(ymax), int(xmin), int(ymin)]\n        ","21af75cb":"path = '..\/input\/car-plate-detection\/annotations'\ntext_files = ['..\/input\/car-plate-detection\/annotations\/'+f for f in sorted(os.listdir(path))]\ny=[]\nfor i in text_files:\n    y.append(resizeannotation(i))","43a72da7":"resizeannotation(\"\/kaggle\/input\/car-plate-detection\/annotations\/Cars147.xml\")","f0e9107a":"y[0]","d7d81d3e":"np.array(X).shape","0ee91865":"np.array(y).shape","b4d21eff":"plt.figure(figsize=(10,20))\nfor i in range(0,17) :\n    plt.subplot(10,5,i+1)\n    plt.axis('off')\n    plt.imshow(X[i])","38b4ff01":"#Example with the first image of the dataset\nimage = cv2.rectangle(X[0],(y[0][0],y[0][1]),(y[0][2],y[0][3]),(0, 0, 255))\nplt.imshow(image)\nplt.show()\n","832544a8":"#Example with the second image of the dataset\nimage = cv2.rectangle(X[1],(y[1][0],y[1][1]),(y[1][2],y[1][3]),(0, 0, 255))\nplt.imshow(image)\nplt.show()\n","9243f16b":"#Transforming in array\nX=np.array(X)\ny=np.array(y)","f7baf0d5":"#Renormalisation\nX = X \/ 255\ny = y \/ 255","a61d17b9":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1)","0ad310d8":"from keras.models import Sequential\n\nfrom keras.layers import Dense, Flatten\n\nfrom keras.applications.vgg19 import VGG19","849d243b":"# Create the model\nmodel = Sequential()\nmodel.add(VGG19(weights=\"imagenet\", include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dense(64, activation=\"relu\"))\nmodel.add(Dense(4, activation=\"sigmoid\"))\n\nmodel.layers[-6].trainable = False\n\nmodel.summary()","bbf4d8b5":"model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])","0fa89e92":"train = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=500, batch_size=32, verbose=1)","ec9667e2":"model.save('djarot-Hindarto-2020101006-model.h5', overwrite=True) ","56fb72ad":"# Test\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","a761002e":"def plot_scores(train) :\n    accuracy = train.history['accuracy']\n    val_accuracy = train.history['val_accuracy']\n    epochs = range(len(accuracy))\n    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n    plt.title('Scores')\n    plt.legend()\n    plt.show()","32156eb8":"plot_scores(train)","e83e1fda":"test_loss, test_accuracy = model.evaluate(X_test, y_test,steps=int(100))\n\nprint(\"Test results \\n Loss:\",test_loss,'\\n Accuracy',test_accuracy)\n","496b3530":" y_cnn = model.predict(X_test)","3b4a24db":"plt.figure(figsize=(20,40))\nfor i in range(0,43) :\n    plt.subplot(10,5,i+1)\n    plt.axis('off')\n    ny = y_cnn[i]*255\n    image = cv2.rectangle(X_test[i],(int(ny[0]),int(ny[1])),(int(ny[2]),int(ny[3])),(0, 255, 0))\n    plt.imshow(image)\n\n","f46da057":"We can see how our model localize license plates on our testing set :","1174627f":"## using the OpenCV library","40ade212":"### Prepare the data for the CNN","3d57af32":"### Resizing image","fbda78d6":"# List of dataset","077d6dd9":"We check X et y shape","80e6eab0":"Thanks\nDjarot Hindarto\n2020101006\nPradita University","40d6443e":"Display 17 image dataset","70a7ac90":"## DETECTION ","3d4f9d8f":"# Data Preparation","cbcab9bf":" new size of the images (200*200). ","d8bd8a66":"We split our dataset in two : training set\/testing set","36615875":"# Try train a convolutional neural network VGG 19, with dataset contains 433 images.","a5a3fbe0":"# Convolutionnal Neural Network VGG-19","84cbde5e":"Dataset is the same as Vehicle License Plate Detection | VGG16, but I'm using model VGG19 model"}}