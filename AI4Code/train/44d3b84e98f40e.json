{"cell_type":{"605c1d3e":"code","f949c54a":"code","bf4f3ab6":"code","dfcf3bec":"code","638e6060":"code","790f0d11":"code","ee355c42":"code","46657b68":"code","f5233c8b":"markdown","d08a24c1":"markdown","97acd8f9":"markdown","e28f27bc":"markdown","bef81853":"markdown","801727a9":"markdown","3307e677":"markdown","4f04b7fb":"markdown","697b3a8a":"markdown","f3a5864a":"markdown","ce2929dc":"markdown"},"source":{"605c1d3e":"# import the Azure ML libs.\n!pip install azureml\n!pip install azureml.core\n!pip install azureml.widgets\n!pip install azureml.train\n\nimport azureml.core\nimport azureml.widgets \nprint(\"Ready to use Azure ML\", azureml.core.VERSION)\nfrom azureml.core import Workspace","f949c54a":"## in this segment you should replace the 3-parameters values according to the workspace available in the subscription\n## ths experiment will not work beyond this point if these values are not appropriatly inserted.\n## HENCE, THE Notebook Execution will terminate\n\n## Example - \n    ## ws = Workspace.get(name=\"<<MLSERVICENAME>>\", subscription_id='<<GUID - ML Service ID>>', resource_group='<<Hosting Azure Resource Group>>')\n\n# Pulling values from Kaggle Secrets\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nMLServiceName = user_secrets.get_secret(\"MLServiceName\")\naz_resource_grp = user_secrets.get_secret(\"az_resource_grp\")\nsub_id = user_secrets.get_secret(\"sub_id\")\n\n## Instanciating the Workspace object.\nws = Workspace.get(name=MLServiceName, subscription_id=sub_id, resource_group=az_resource_grp)\nprint(ws.name, \"loaded\")","bf4f3ab6":"import os, shutil\n\n# Create a folder for the experiment files\nfolder_name = 'experiment-files'\nexperiment_folder = '.\/' + folder_name\nos.makedirs(experiment_folder, exist_ok=True)\n\n#Copy the datast in the experiment folder so that it is made locally available to the model when it runs frm the script\nshutil.copy('..\/input\/iris-flower-dataset\/IRIS.csv', os.path.join(folder_name, \"IRIS.csv\"))","dfcf3bec":"%%writefile $folder_name\/iris_simple_experiment.py\nfrom azureml.core import Run\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nimport joblib\nimport os\n\n#\"argparse\" to define the input parameters for the script.\nimport argparse\n\n# Get the experiment run context -  we are going to pass this configuration later\nrun = Run.get_context()\n\n#define the regularization parameter for the logistic regression. I will pass this value from Estimator API of the Experiment later.\nparser = argparse.ArgumentParser()\nparser.add_argument('--reg_rate', type=float, dest='reg', default=0.01)\nargs=parser.parse_args()\nr = args.reg\n\n# load the data from a local file\ndata = pd.read_csv('IRIS.csv')\nX = data[['sepal_length', 'sepal_width','petal_length','petal_width']].values\nX=StandardScaler().fit_transform(X)\nY= (data['species']).map(lambda x: 0 if x=='Iris-setosa' else (1 if x=='Iris-versicolor' else 2))\n\n#Split data into train and test set\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.25, random_state=1234)\n# fit the model\nrun.log(\"model regularization\", np.float(r))\nmodel = LogisticRegression(C=1\/r, solver='lbfgs', multi_class='multinomial').fit(X_train,Y_train)\n\nY_pred = model.predict(X_test)\naccuracy = np.average(Y_test == Y_pred)\nprint(\"accuracy: \" + str(accuracy))\nrun.log(\"Accuracy\", np.float(accuracy))\n\n# Save the trained model in the \"outputs\" folder. The \"outputs\" folder is standard output folder for AML.\nos.makedirs(\"outputs\", exist_ok=True)\njoblib.dump(value=model, filename='outputs\/iris_simple_model.pkl')\n# Complete the run\nrun.complete()","638e6060":"from azureml.train.estimator import Estimator\nfrom azureml.core import Experiment\nfrom azureml.widgets import RunDetails\n\n# Create an estimator\nestimator = Estimator(source_directory=experiment_folder,\n                      entry_script='iris_simple_experiment.py',\n                      compute_target='local',\n                      use_docker=False,\n                      script_params = {'--reg_rate': 0.07},\n                      conda_packages=['scikit-learn']\n                      )\n\n# COMMENTED - SKLearn as an estimator\n#estimator = SKLearn(source_directory=experiment_folder, entry_script='iris_simple_experiment.py', compute_target='local', use_docker=False)\n\n# Create an experiment\nexperiment_name = 'iris-estimator-experiment'\nexperiment = Experiment(workspace = ws, name = experiment_name)\n\n# Run the experiment based on the estimator\nrun = experiment.submit(config=estimator)\n\n# Get Run Details\nRunDetails(run).show()\n\n# Wait to complete the experiment. In the Azure Portal we will find the experiment state as preparing --> finished.\nrun.wait_for_completion(show_output=True)","790f0d11":"# get logged Metrics.\nmetrics = run.get_metrics()\nprint(\"Metrics\")\nfor key in metrics.keys():\n    print(key, metrics.get(key))\nprint(\"\\nFile Names\")\nfor file in run.get_file_names():\n    print(file)","ee355c42":"from azureml.core import Model\n\nrun.register_model(model_path='outputs\/iris_simple_model.pkl', model_name='iris_estimator_model', tags={\"Training Context\":\"Estimator\", \"Script Context\":\"Parameters\"},\n                  properties={\"Accuracy\":run.get_metrics()[\"Accuracy\"]})","46657b68":"for model in Model.list(ws):\n    print(model.name, \":\", model.version)\n    print(\"\\nTag List\")\n    for tag_name in model.tags:\n        tag = model.tags[tag_name]\n        print(tag_name, tag)\n    print(\"\\nProperties List\")\n    for prop_name in model.properties:\n        prop = model.properties[prop_name]\n        print(prop_name,prop)","f5233c8b":"## What Next?\nIn the next notebook I will discuss about:\n- How to enable different data sources to enable cloud machine learning. Example - blob storage and tables.\n- Pass the data_set using the Estimator object. This will help to avoid passing static data_set files with the experiment (e.g. Iris csv) and enable online learning wile constantly looking into the remote data sources defined within the experiment.\n\nPhew - if you are feeling too much overwhelmed with these concepts.. wait for my next notebook to uncover these. :) ","d08a24c1":"<u>**IMPORTANT NOTE**<\/u>\n\n>Please proceed with this example **iff** you are familier with foundation of Microsoft Azure public cloud. In this notebook, the basics of Microsoft Azure and its development methodology is not covered. As it will be beyond the scope of this notebook.\n\n* [PART 1: Azure Machine Learning service - Introduction](https:\/\/www.kaggle.com\/pankaj1234\/azure-machine-learning-introduction): in the first notebook I have already discussed about the nitty-gritty of Azure ML service.\n    * Creating an instance of Azure ML service\n    * Downloading libraries\/dependencies (in Kaggle environment)\n    * Various methods to connect to Azure ML service workspace: using config file and using get() method.\n    * Simple ML experiment - for data exploration. Capture the details from the experiment, logging and preserving the run details from the experiment.\n    * Overview of Azure ML Service Dashboard. Experiment Dashboard.\n    \n* [PART 2: Azure Machine Learning service - Introduction II](https:\/\/www.kaggle.com\/pankaj1234\/azure-machine-learning-introduction-ii): I did deep-dive into the introduction and covered some more topics:\n    * Create and run the experiment using <u>Custom Script<\/u> file. Implementing simple Logistic Regression model on IRIS dataset.\n    * RunConfiguration and ScriptRunConfiguration, these classes were used to define the runtime environment for the custom script.\n    * Output the model and run details to the external folder for future referencing.\n    \n# Azure Machine Learning Service - III\nIn this third part from the same Azure Machine Learning Service (**AML**) series I will do a experiment to show:\n* How to pass parameters to the <u>Custom Script<\/u> so that it can run experiment dynamically.\n* Advantage of using Estimator API over RunConfiguration and ScriptRunConfiguration\n* Register and Consuming the Machine Learning Model in AML service.\n","97acd8f9":"![image.png](attachment:image.png)","e28f27bc":"Models with version numbers as registered in Azure Portal in AML workspace.\n![image.png](attachment:image.png)","bef81853":"## Register Model\nOnce the model is trained and captured as \\*.pkl with the experiment run it can be registered with Name and Version number. Also, there are few meta-data proprties and tags can also be updated with the registered model.","801727a9":"**See the --reg_rate (Model Regularization) parameter with its assigned value.**\n\n![image.png](attachment:image.png)","3307e677":"> Get Experiment details, logs, files and captured metrics.","4f04b7fb":"> Code segment below will create the experiment folder and also copy the data for the experimnt to run from.","697b3a8a":"## Passing Script Parameters\nBefore I discuss about the Estimator API of AML. I will be defining the script wich will accept the input parameters while it is called from the Estimator API for training and implementing the model. Passing a parameter value uning **argparse** allow us to run this experiment using different settings.The parameter which is defined here is regularization rate for the Logistic Regression model","f3a5864a":"## Estimator API\nOnce I was able to define the experment script with all the required parameter details, the next code segment below is for Estimator implementation. The Estimator is used to encapsulate both previously learnt RunConfiguration and ScriptRunConfiguration in 1 step. Hence it is an abstraction on these 2 combined.<br\/>\nThe code segment below uses the generic **Estimator** object to run the training Experiment. It has a power to provision any compute resource for experiment execution, e.g. Container, VM, or local compute, using **compute_target** parameter. <br\/>\nThe generic Estimator does not include the scikit-learn packages therefore I have to pass the value for **conda_packages** parameter. One can also use estimator objects as **framework_specific** SKLearn or Tensorflow or PyTorch to avoid using explicit Conda_packages as parameter.\n\n- See the comment section for SKLearn as an Estimator.\n- See the parameters passed which are already defined in above script. '--reg_rate'\n","ce2929dc":"**Expriment Output  - Model (.pkl) & logs**\n\n![image.png](attachment:image.png)"}}