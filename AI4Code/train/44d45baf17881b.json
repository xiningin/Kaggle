{"cell_type":{"15a5785d":"code","7e2b7232":"code","9dcbec8b":"code","a4e194ba":"code","9ab469bf":"code","c11f24d7":"code","7fd512f0":"code","8dbdbb2f":"code","e59a830c":"code","f1246d03":"code","a3d1be3c":"code","311d8636":"code","b314e8a6":"code","99c17b0c":"code","9e24ff59":"code","c39c85ac":"markdown","74a3aada":"markdown","55253179":"markdown","5fcf0b70":"markdown","da353eb7":"markdown","8534a414":"markdown","0fcd9f85":"markdown","2d6663c3":"markdown","2169bb22":"markdown"},"source":{"15a5785d":"import tensorflow.keras as keras\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold, learning_curve, cross_val_score\nfrom sklearn.metrics import confusion_matrix, log_loss, make_scorer, accuracy_score\n\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","7e2b7232":"train = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/test.csv')\nsample_submission = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/sample_submission.csv')\n\ntrain = train.drop('id', axis=1)\ntest = test.drop('id', axis=1)","9dcbec8b":"train.info()","a4e194ba":"# # for i in range(50):\n# #     mean, std = train[f'feature_{i}'].mean(), train[f'feature_{i}'].std()\n# #     train[f'feature_{i}'] = train[f'feature_{i}'].apply(lambda x : (x-mean)\/std)\n# #     test[f'feature_{i}'] = test[f'feature_{i}'].apply(lambda x : (x-mean)\/std)\n\nfeatures = [col for col in test.columns if col != \"id\" and col != \"target\"]\n\n# from sklearn.preprocessing import StandardScaler\n# scaler = StandardScaler().fit(train[features])\n# train[features] = scaler.transform(train[features])\n# test[features] = scaler.transform(test[features])\n\n# # from sklearn import preprocessing\n# # min_max_scaler = preprocessing.MinMaxScaler()\n# # train[features] = min_max_scaler.fit_transform(train[features])\n# # test[features] = min_max_scaler.fit_transform(test[features])","9ab469bf":"label_dict = {val:idx for idx, val in enumerate(sorted(train['target'].unique()))}\ntrain['target'] = train['target'].map(label_dict)\n\ntarget = train['target']\ntrain.drop(['target'], inplace=True, axis=1)\n\n# train = train.values\n# target = target.values\n# target =  to_categorical(target)","c11f24d7":"drop_features = ['feature_3']\ntrain_new = train.drop(drop_features,axis=1)\ntest_new =test.drop(drop_features,axis=1)","7fd512f0":"def gen_features(df, features):\n    for i in range (len(features)):\n        for j in range(i+1, len(features)):\n            df[str(features[i])+'+'+str(features[j])] = df[str(features[i])]+df[str(features[j])]\n    \n    return df","8dbdbb2f":"features = ['feature_2','feature_13']\ntrain_new = gen_features(train_new, features)\ntest_new = gen_features(test_new, features)","e59a830c":"new_features = train_new.columns\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler().fit(train_new[new_features])\ntrain_new[new_features] = scaler.transform(train_new[new_features])\ntest_new[new_features] = scaler.transform(test_new[new_features])","f1246d03":"num_features = len(new_features)\nnum_classes = 4","a3d1be3c":"def CreateModel():\n    hidden_units = [150, 150, 150]\n    dropout_rates = [0.2, 0.2, 0.2, 0.2]\n    \n    inp = tf.keras.layers.Input(shape=(num_features,))\n    x = tf.keras.layers.BatchNormalization()(inp)\n    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n    for i in range(len(hidden_units)):\n        x = tf.keras.layers.Dense(hidden_units[i])(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Activation(\"relu\")(x)\n#         x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n\n    x = tf.keras.layers.Dense(num_classes)(x)\n    out = tf.keras.layers.Activation(\"softmax\")(x)\n\n    model = tf.keras.models.Model(inputs=inp, outputs=out)\n    \n#     model = Sequential([\n#         Dense(512, input_dim=num_features, activation='relu'),\n#         BatchNormalization(),\n#         Dropout(0.3),\n#         Dense(256, activation='relu'),\n#         BatchNormalization(),\n#         Dropout(0.2),\n#         Dense(128, activation='relu'),\n#         BatchNormalization(),\n#         Dropout(0.2),\n#         Dense(num_classes, activation='softmax')\n#     ])\n    model.compile(loss='mean_squared_logarithmic_error', optimizer=\"adam\", metrics='accuracy')\n    return model","311d8636":"N_FOLDS = 5\nskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)","b314e8a6":"oof = np.zeros((train_new.shape[0],4))\npred = np.zeros((test_new.shape[0],4))\n\nfor fold, (tr_idx, ts_idx) in enumerate(skf.split(train_new, target)):\n    print(f\"===== FOLD {fold} =====\")       \n    X_train = train_new.iloc[tr_idx] # X_train\n    y_train = target.iloc[tr_idx] # y_train\n    X_val = train_new.iloc[ts_idx] # X_valid \n    y_val = target.iloc[ts_idx] # y_valid\n    \n    X_train = X_train.values\n    X_val = X_val.values\n    y_train = y_train.values\n    y_val = y_val.values\n    y_train =  to_categorical(y_train)\n    y_val =  to_categorical(y_val)\n\n    model = CreateModel()\n    model.fit(X_train, y_train,\n          batch_size = 100, epochs = 20, verbose = 2,\n          validation_data=(X_val, y_val));\n    \n    oof[ts_idx] = model.predict(X_val)\n    pred += model.predict(test) \/ N_FOLDS\n    \n    score = log_loss(y_val, oof[ts_idx])\n    print(f\"FOLD {fold} Score {score}\\n\")\n\nscore = log_loss(target, oof)\nprint(f\"Score total {score}\\n\")","99c17b0c":"sample_submission[['Class_1','Class_2', 'Class_3', 'Class_4']] = pred","9e24ff59":"sample_submission.to_csv(f'submission.csv',index=False)","c39c85ac":"https:\/\/www.kaggle.com\/nishantdhingra\/cb-lgbm-xgb-feature-importance-and-interactions","74a3aada":"## Output","55253179":"### Fit\n\nI didn't do a lot of Epochs for fast execution, and the batch size and epoch can be adjusted.\n\nWith the GPU, you can run the model much faster.","5fcf0b70":"The structure of the model can be changed freely, and the model is an MLP model using only Dense, Batchnormalization, Dropout.","da353eb7":"## Simple Keras Pipeline\n\n- EDA : https:\/\/www.kaggle.com\/subinium\/tps-may-categorical-eda","8534a414":"## Normalization\n\nThe data needs to be normalized to fit into the DNN.","0fcd9f85":"## Model (Keras)","2d6663c3":"### Initialization","2169bb22":"## Feature Selection"}}