{"cell_type":{"92e31895":"code","ddecbc98":"code","80542b53":"code","5138964c":"code","77ac06d9":"code","a3c31aa8":"code","619ea9e7":"code","8e0ec5e3":"code","d53151bf":"code","572c4bb2":"code","7d036f22":"code","19e22e61":"code","1afc9732":"code","098a6da1":"code","b7aa1fe5":"code","98eeafba":"code","b051978d":"code","34d092c7":"code","79e9f9f5":"code","0933dcbf":"code","de325c96":"code","9e666f43":"code","efdf6074":"code","1ff3137a":"code","dd0943dc":"code","4fc0d3ba":"code","733de0e4":"code","1d5606ca":"code","d7b26c49":"code","530d1c1b":"code","3edca69f":"code","3a146b3f":"code","70e6c8a7":"code","9d8780c0":"code","44029574":"code","3178bb94":"code","e5c84703":"code","5b76280f":"code","59d97a14":"code","ebc66cef":"code","6a447632":"code","4e86610e":"code","149910de":"code","5fb12a1a":"code","1ecded07":"code","70e9b537":"markdown","3bfd54da":"markdown","aaddbfad":"markdown","fafe36d9":"markdown","77d7f223":"markdown","64948e37":"markdown","9f3f2966":"markdown","079a49ff":"markdown","247dd88c":"markdown","8d3f7361":"markdown","437ef23a":"markdown","4f0c21ff":"markdown","3bac9856":"markdown","d93ed561":"markdown"},"source":{"92e31895":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nwarnings.filterwarnings('ignore')","ddecbc98":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","80542b53":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","5138964c":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\nsns.factorplot(x='Pclass', y='Survived', hue='Sex', col='Embarked', data=train_data)","77ac06d9":"def concat_df(train_data, test_data):\n    # Returns a concatenated df of training and test set\n    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)","a3c31aa8":"train_test_data = concat_df(train_data, test_data)","619ea9e7":"# Extract titles from names\ntrain_test_data['Title'] = train_test_data.Name.str.extract('([A-Za-z]+)\\.')","8e0ec5e3":"pd.crosstab(train_test_data['Title'], train_test_data['Sex'])","d53151bf":"train_test_data['Title'] = train_test_data['Title'].replace('Mlle', 'Miss')\ntrain_test_data['Title'] = train_test_data['Title'].replace('Ms', 'Miss')\ntrain_test_data['Title'] = train_test_data['Title'].replace('Mme', 'Mrs')\ntrain_test_data['Title'] = train_test_data['Title'].replace('Dona', 'Mrs')\ntrain_test_data['Title'] = train_test_data['Title'].replace('Countess', 'Mrs')\ntrain_test_data['Title'] = train_test_data['Title'].replace('Lady', 'Mrs')\ntrain_test_data['Title'] = train_test_data['Title'].replace('Don', 'Mr')\ntrain_test_data['Title'] = train_test_data['Title'].replace('Capt', 'Mr')\ntrain_test_data['Title'] = train_test_data['Title'].replace('Col', 'Mr')\ntrain_test_data['Title'] = train_test_data['Title'].replace('Don', 'Mr')\ntrain_test_data['Title'] = train_test_data['Title'].replace('Dr', 'Mr')\ntrain_test_data['Title'] = train_test_data['Title'].replace('Jonkheer', 'Mr')\ntrain_test_data['Title'] = train_test_data['Title'].replace('Major', 'Mr')\ntrain_test_data['Title'] = train_test_data['Title'].replace('Rev', 'Mr')\ntrain_test_data['Title'] = train_test_data['Title'].replace('Sir', 'Mr')","572c4bb2":"train_test_data['Title'] = train_test_data['Title'].map({'Mrs': 1, 'Miss': 2, 'Master': 3, 'Mr': 4}).astype(int)","7d036f22":"survived_by_title_pclass = round(train_test_data.groupby(['Title', 'Pclass']).mean()['Survived'], 2)\n\nsurvived_by_title_pclass","19e22e61":"train_test_data['Title'] = train_test_data['Title'].map({1: 1, 2: 1, 3: 2, 4: 3}).astype(int)","1afc9732":"survived_by_title_pclass = round(train_test_data.groupby(['Title', 'Pclass']).mean()['Survived'], 2)\n\nsurvived_by_title_pclass","098a6da1":"train_test_data['Age'].isna().sum()","b7aa1fe5":"age_by_pclass_title = round(train_test_data.groupby(['Title', 'Pclass']).median()['Age'])\n\nage_by_pclass_title","98eeafba":"train_test_data['Age'] = train_test_data.groupby(['Title', 'Pclass'])['Age'].apply(lambda x: x.fillna(round(x.median())))\ntrain_test_data['Age'] = train_test_data['Age'].astype(int)","b051978d":"train_test_data.isna().sum()","34d092c7":"# Filling the missing value in Fare with the median Fare of 3rd class alone passenger\nmed_fare = train_test_data.groupby(['Pclass', 'Parch', 'SibSp']).Fare.median()[3][0][0]\ntrain_test_data['Fare'] = train_test_data['Fare'].fillna(med_fare)","79e9f9f5":"train_test_data['AgeBand'] = pd.qcut(train_test_data['Age'], 5)","0933dcbf":"count_by_title_age = train_test_data.groupby(['Title', 'AgeBand']).count()['PassengerId']\n\ncount_by_title_age","de325c96":"survived_by_title_age = round(train_test_data.groupby(['Title', 'AgeBand']).mean()['Survived'], 2)\n\nsurvived_by_title_age","9e666f43":"train_test_data.loc[train_test_data['Age'] > 26, 'Fortunate_Age'] = 1\ntrain_test_data.loc[train_test_data['Age'] <= 26, 'Fortunate_Age'] = 2\ntrain_test_data['Fortunate_Age'] = train_test_data['Fortunate_Age'].astype(int)","efdf6074":"count_by_title_fortunate = train_test_data.groupby(['Title', 'Fortunate_Age']).count()['PassengerId']\n\ncount_by_title_fortunate","1ff3137a":"survived_by_title_fortunate = round(train_test_data.groupby(['Title', 'Fortunate_Age']).mean()['Survived'], 2)\n\nsurvived_by_title_fortunate","dd0943dc":"# Fill two empty values in the 'Embarked' column with S as most passengers embarked in this port\ntrain_test_data['Embarked'] = train_test_data['Embarked'].fillna('S')\ntrain_test_data['Embarked'] = train_test_data['Embarked'].map({'C': 1, 'Q': 2, 'S': 3})","4fc0d3ba":"count_by_title_embarked = train_test_data.groupby(['Title', 'Embarked']).count()['PassengerId']\n\ncount_by_title_embarked","733de0e4":"survived_by_title_embarked = round(train_test_data.groupby(['Title', 'Embarked']).mean()['Survived'], 2)\n\nsurvived_by_title_embarked","1d5606ca":"# Drop features (columns) we don't need anymore\ndrop_cols = ['Age', 'Cabin', 'Fare', 'Name', 'Parch', 'Sex', 'SibSp', 'Ticket', 'AgeBand']\n\ntrain_test_data.drop(columns=drop_cols, inplace=True)","d7b26c49":"train_data = train_test_data[train_test_data['Survived'].notna()]","530d1c1b":"train_data['Survived'] = train_data['Survived'].astype(int)","3edca69f":"train_data.head()","3a146b3f":"train_data.describe()","70e6c8a7":"test_data = train_test_data.drop(train_test_data[train_test_data.Survived >= 0].index)","9d8780c0":"test_data.head()","44029574":"test_data.describe()","3178bb94":"# Importing Classifier Module\nfrom sklearn.tree import DecisionTreeClassifier","e5c84703":"y = train_data[\"Survived\"]\n\nfeatures = [\"Title\", \"Pclass\", \"Embarked\",\"Fortunate_Age\"]\nX = train_data[features]\nX_test = test_data[features]\n\nmodel_default = DecisionTreeClassifier(random_state=10)\nmodel_default.fit(X, y)\npredictions = model_default.predict(X_test)","5b76280f":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('model_default.csv', index=False)\nprint(\"Your submission was successfully saved!\")","59d97a14":"from sklearn import tree\nimport graphviz\n\ntree_graph = tree.export_graphviz(model_default, out_file=None, feature_names=features)\ngraphviz.Source(tree_graph)","ebc66cef":"dot = graphviz.Source(tree_graph)\ndot.render('tree_graph_default.gv', view=True)","6a447632":"importances = pd.DataFrame({'feature':X.columns,'importance':np.round(model_default.feature_importances_,2)})\nimportances = importances.sort_values('importance',ascending=False).set_index('feature')\nprint(importances)","4e86610e":"# Calculate permutation importance\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(model_default, random_state=0).fit(X, y)\neli5.show_weights(perm, feature_names = X.columns.tolist())","149910de":"from pdpbox import pdp, get_dataset, info_plots\n\nfor feat_name in features:\n    pdp_dist = pdp.pdp_isolate(model=model_default, dataset=train_data, model_features=features, feature=feat_name)\n    pdp.pdp_plot(pdp_dist, feat_name)\n    plt.show()","5fb12a1a":"features_to_plot = ['Title', 'Pclass']\ninter  =  pdp.pdp_interact(model=model_default, dataset=train_data, model_features=features, features=features_to_plot)\n\npdp.pdp_interact_plot(pdp_interact_out=inter, feature_names=features_to_plot, plot_type='contour')\nplt.show()","1ecded07":"import shap  # package used to calculate Shap values\n\n# Create object that can calculate shap values\nexplainer = shap.TreeExplainer(model_default)\n\n# calculate shap values\nshap_values = explainer.shap_values(X)\n\n# Make plot\nshap.summary_plot(shap_values[1], X)","70e9b537":"This DecisionTreeClassifier model scores almost 79% and it's several points better than a DecisionTreeClassifier which I run with more features before. This DecisionTreeClassifier scores exactly as many points as RandomForestClassifier with the same features, although RandomForestClassifier performs better in the Titanic competition and is usually the first choice. But from the very beginning I decided to fit my features for the DecisionTreeClassifier and this strategy worked well.","3bfd54da":"# 4. Getting model insights and saving results","aaddbfad":"# 2. Data preparation and categorization of values","fafe36d9":"We have two datasets: one to **train** the machine learning algorithm and another one to **test** it.","77d7f223":"Our aim is to categorize **titles** into 3 bigger groups.","64948e37":"We can ignore the **Master** title which includes almost exclusively **boys** and if we look at titles 1 and 3 we can see that **people over 26 have better chances to survive**. ","9f3f2966":"# 3. Prepare tables for machine learning algorithms","079a49ff":"Now as we have titles we don't need to divide passengers into gender groups anymore. The **Master title is very important** and for the most passengers it referred to a boy. In contrast to other males, **boys had good chances to survive**. There were also a couple of crew members who had the title Master, but it's not easy to identify them since age values are missing.","247dd88c":"On the graphs below we see that a **gender** and a **travel class** have a huge influence on whether a passenger survived. ","8d3f7361":"As in most cases Master meant a boy, we want to fill **missing age values** in this group with the **median value** and we apply the same rule to all title groups.","437ef23a":"We see that there is almost no difference in **survival rate** between **Mrs** and **Miss** and we can **merge** these two groups.","4f0c21ff":"# 1. Foreword\n\n![](https:\/\/i.imgur.com\/OcSiuGJ.jpeg)\n\n[Link to larger view where zoom is also available](https:\/\/i.imgur.com\/OcSiuGJ.jpeg)\n\nIt was important for me to understand how the machine algorithm works and the DecisionTreeClassifier reveals part of its internal work as a simple **decision tree**. So when I selected features for it I always kept this graph in mind. I wanted to have very few features and soon I realized that **titles of Titanic passengers should be the key feature**! Why? It is known that most females survived and most males died, the only males who had good chances to survive on Titanic were boys and to sort them out we can use the **title Master which boys had in those days**.\n\nWhen I had title as the key feature, I started to check if other features have correlations with it. I found out that the columns **Parch** (means number of parents \/ children aboard the Titanic) or **SibSp** (siblings \/ spouses) didn't influence survival chances of men and women. True that on average passengers travelling alone had worse chances to survive, but it's only because children and most women travelled with a family and children and women did survive. But **in separate groups of females, boys and men it didn't matter if you had a family or not**.\n\nLooking for useful features, I also tried the **Fare** (ticket prices), but it turned out that **travel class correlates with chances to survie better than the price of a ticket** even if we categorize ticket prices into several groups.\n\nOne valuable feauture was already in the table and it was Embarked. **Passengers who embarked in Cherbourg** (these were mostly rich people) had better chances to survive and it also correlated with the chances to survive inside three title groups.\n\nThe last feature was the age. If we have boys in a separate group of Masters, then in two other groups the young age meant worse chances to survive and **people over 26 had better chances**.\n\nAt the end of this notebook we'll create the **decision tree**. If you want to explore this tree now, you can download it as **'tree_graph_default.gv.pdf'** from the **Output** of this notebook.\n\nAs **guidance** to read the tree:\n\n*     Leaves with children show their splitting criterion on the top\n*     The pair of values at the bottom show the count of False values and True values for the target respectively, of data points in that node of the tree.\n\n**Example 1:**\n1. At the top we have **Title** as the **splitting criterion** and we still have all passengers in the training set, **549** of them died, **342 survived**.\n1. All passengers with titles 1 or 2 (aka females and boys) go to the left, here only 98 will die and 255 will survive. As the splitting criterion we have **Pclass (travel class)**.\n1. Those who travelled in the third class go down and get **Embarked** as the splitting criterion.\n1. Those who embarked in **Southampton** go to the right and get **Title** as the splitting criterion again.\n1. **Masters** go to the right and we see that **13 of them died and 7 survived**, but the gini impurity is high and equals **0.455**, so we cannot predict precisely the outcome in the test model for this group of passengers (**Boys in the third class who embarked in Southampton**).\n\n**Example 2:**\n1. At the top we have **Title** as the **splitting criterion** and we still have all passengers in the training set, **549** of them died, **342 survived**.\n1. All passengers with the title 3 (aka males) go to the right, here **451** will die and **87** survive. As the splitting criterion we have **Pclass**.\n1. Those in the **second and third class** go further to the right and have **Age** as the splitting criterion.\n1. Men who are **26 or younger** (age group 2) go to the right and have **Embarked** as the splitting criterion.\n1. Those who embarked in Southampton or Queenstown go to the right and have **Pclass** as the splitting criterion again.\n1. Those who travelled in **the second class** go down and we see that 25 of them died and only 1 survived. The gini impurity is low and equals **0.074**, so we can predict **precisely** the outcome in the test model for this group of passengers (**Young men in the second class who embarked in Southampton or Queenstown**).","3bac9856":"On the Shap graph we see that \"title 3 - males\" (red dots) made a big impact on the output. The impact of the 3rd class is also visible (all red dots are on the left side). Passengers embarked in Southampton (red dots) are all on the left side too. The age had less distinct effect.","d93ed561":"Our next aim is to categorize **age values** into several big groups."}}