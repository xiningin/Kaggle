{"cell_type":{"6f3bfc6a":"code","068c53bf":"code","5c818cec":"code","e334aa66":"code","b563414b":"code","b29bc1fd":"code","583a8a6c":"code","b2680400":"code","17b75477":"code","bf540a0d":"code","01f0832d":"code","22131aef":"code","a337aacd":"code","e17ac88a":"code","bfd83b61":"code","d1b62202":"code","6d6ed933":"code","0432f337":"code","d10516d6":"code","8a1eba95":"code","a69b38cd":"code","860e453b":"code","18aeda84":"code","1f90b13c":"code","bbf3dda4":"code","8c8fe282":"code","424e0a01":"code","b290fb0f":"code","3f5f60c0":"code","5415667f":"code","1dbcfcfc":"code","5af09451":"code","d7f3f5fc":"code","981bb31f":"code","217f58ac":"code","0d0aa0a7":"code","16b95c94":"code","ad15fdc1":"code","7396c86b":"code","82641080":"code","6282a22f":"code","4b17ccb3":"code","a567f27a":"code","5a9ab50e":"code","bf0ac63c":"code","5f819b36":"code","75e05dc5":"code","8f42df21":"code","961d6d22":"code","ef0cd98a":"markdown","a3f6cef5":"markdown","9e92c950":"markdown","7d91bee6":"markdown","7d7a549f":"markdown","5c57da15":"markdown","1663a81d":"markdown","2d7025ec":"markdown","ff413e1d":"markdown","23b2c208":"markdown","0b39a867":"markdown","fa7d2d6c":"markdown","633c2de1":"markdown","7346a8d2":"markdown","57e58add":"markdown","6387dcfe":"markdown","80f86c4f":"markdown"},"source":{"6f3bfc6a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()","068c53bf":"pd.set_option('display.max_columns', 111)","5c818cec":"HP=pd.read_csv('..\/input\/brooklyn_sales_map.csv')","e334aa66":"HP.shape","b563414b":"HP.head()","b29bc1fd":"HP.describe().append(HP.isnull().sum().rename('isnull'))","583a8a6c":"HP.columns.values","b2680400":"columns = ['Unnamed: 0', 'borough', 'Borough','apartment_number', 'Ext', 'Landmark','AreaSource', 'UnitsRes', 'UnitsTotal', 'LotArea', 'BldgArea','BldgClass','Easements', 'easement', 'OwnerType', 'building_class_category','sale_date', 'CT2010', 'CB2010', 'ZipCode', 'ZoneDist1', 'ZoneDist2', 'ZoneDist3', 'ZoneDist4', 'Overlay1', 'Overlay2', 'SPDist1', 'SPDist2', 'SPDist3', 'LtdHeight', 'YearBuilt', 'BoroCode', 'BBL', 'Tract2010', 'ZoneMap', 'ZMCode', 'Sanborn', 'TaxMap', 'EDesigNum', 'PLUTOMapID', 'FIRM07_FLA', 'PFIRM15_FL', 'Version', 'MAPPLUTO_F', 'APPBBL', 'APPDate', 'SHAPE_Leng', 'SHAPE_Area','CD', 'SchoolDist', 'Council', 'PolicePrct', 'HealthCent', 'SanitBoro', 'SanitDistr','FireComp','SanitSub', 'CondoNo','Address']\nHP.drop(columns, inplace=True, axis=1)","17b75477":"HP.columns.values","bf540a0d":"HP=HP[HP['sale_price']!=0]\nHP['gross_sqft']=HP['gross_sqft'].replace(0.0,HP['gross_sqft'].median())\nHP['land_sqft']=HP['land_sqft'].replace(0.0,HP['land_sqft'].median())\nHP['NumBldgs']= HP['NumBldgs'].fillna(HP['NumBldgs'].median())\nHP['NumFloors']= HP['NumFloors'].fillna(HP['NumFloors'].median())\nHP['ProxCode']= HP['ProxCode'].fillna(HP['ProxCode'].mode()[0])\nHP['LotType']= HP['LotType'].fillna(HP['LotType'].mode()[0])\nHP['BsmtCode']= HP['BsmtCode'].fillna(HP['BsmtCode'].mode()[0])\nHP['LandUse']= HP['LandUse'].fillna(HP['LandUse'].mode()[0])\nHP['AssessLand']= HP['AssessLand'].fillna(HP['AssessLand'].median())\nHP['AssessTot']= HP['AssessTot'].fillna(HP['AssessTot'].median())\nHP['ExemptLand']= HP['ExemptLand'].fillna(HP['ExemptLand'].median())\nHP['ExemptTot']= HP['ExemptTot'].fillna(HP['ExemptTot'].median())\nHP['BuiltFAR']= HP['BuiltFAR'].fillna(HP['BuiltFAR'].median())\nHP['ResidFAR']= HP['ResidFAR'].fillna(HP['ResidFAR'].median())\nHP['CommFAR']= HP['CommFAR'].fillna(HP['CommFAR'].median())\nHP['FacilFAR']= HP['FacilFAR'].fillna(HP['FacilFAR'].mean())\nHP['OwnerName']= HP['OwnerName'].fillna(value=0)\nHP['IrrLotCode']= HP['IrrLotCode'].fillna(value=0)\nHP['SplitZone']= HP['SplitZone'].fillna(value=0)\n\nHP['XCoord']= HP['XCoord'].fillna(HP['XCoord'].mode()[0])\nHP['YCoord']= HP['YCoord'].fillna(HP['YCoord'].mode()[0])\nHP['XCoord']= HP['XCoord'].replace(0.0,HP['XCoord'].mode()[0] )\nHP['YCoord']= HP['YCoord'].replace(0.0,HP['YCoord'].mode()[0] )\n\nHP['ComArea']= HP['ComArea'].fillna(HP['ComArea'].median())\nHP['ResArea']= HP['ResArea'].fillna(HP['ResArea'].median())\nHP['OfficeArea']= HP['OfficeArea'].fillna(HP['OfficeArea'].median())\nHP['RetailArea']= HP['RetailArea'].fillna(HP['RetailArea'].median())\nHP['GarageArea']= HP['GarageArea'].fillna(HP['GarageArea'].median())\nHP['OtherArea']= HP['OtherArea'].fillna(HP['OtherArea'].median())\nHP['StrgeArea']= HP['StrgeArea'].fillna(HP['StrgeArea'].median())\nHP['FactryArea']= HP['FactryArea'].fillna(HP['FactryArea'].median())\nHP['LotFront']= HP['LotFront'].fillna(HP['LotFront'].median())\nHP['LotDepth']= HP['LotDepth'].fillna(HP['LotDepth'].median())\nHP['BldgFront']= HP['BldgFront'].fillna(HP['BldgFront'].median())\nHP['BldgDepth']= HP['BldgDepth'].fillna(HP['BldgDepth'].median())\nHP['HealthArea']= HP['HealthArea'].fillna(HP['HealthArea'].median())\nHP['YearAlter1']= HP['YearAlter1'].fillna(HP['YearAlter1'].mode()[0])\nHP['YearAlter2']= HP['YearAlter2'].fillna(HP['YearAlter2'].mode()[0])","01f0832d":"HP['HistDist'].fillna(0.0, inplace=True)\nHP['HistDist']=HP['HistDist'].astype('category')\nHP['HistDist']=HP['HistDist'].cat.codes\nHP['HistDist'].unique()","22131aef":"HP['neighborhood']=HP['neighborhood'].astype('category')\nHP['neighborhood']=HP['neighborhood'].cat.codes","a337aacd":"HP[['number','street name']] = HP['address'].str.split(n=1, expand=True)\ndel HP['address']\ndel HP['number']\nHP['street name']=HP['street name'].astype('category')\nHP['street name']=HP['street name'].cat.codes","e17ac88a":"print(HP['tax_class'].unique())\nprint(HP['tax_class'].isnull().sum())\nprint(HP['tax_class_at_sale'].unique())\nprint(HP['tax_class_at_sale'].isnull().sum())\nHP['tax_class'] = HP['tax_class'].map({'1B': 5, '2A': 6, '2B':7, '1A':8, '2C':9, '3':3,'4':4,'2':2,'1':1})\nHP['tax_class'].fillna(HP['tax_class_at_sale'], inplace=True)","bfd83b61":"HP['building_class'].fillna(HP['building_class_at_sale'], inplace=True)\nHP['building_class']=HP['building_class'].astype('category')\nHP['building_class_at_sale']=HP['building_class_at_sale'].astype('category')\n\ncat_columns = HP.select_dtypes(['category']).columns\ncat_columns\nHP[cat_columns] = HP[cat_columns].apply(lambda x: x.cat.codes)","d1b62202":"print(HP['OwnerName'].unique())\nHP['OwnerName']= HP['OwnerName'].fillna(value=0)\nprint(HP['OwnerName'].isnull().sum())\n\nHP['OwnerName']=HP['OwnerName'].astype('category')\nHP['OwnerName']=HP['OwnerName'].cat.codes","6d6ed933":"HP['IrrLotCode'].unique()\nHP['IrrLotCode']= HP['IrrLotCode'].fillna(value=0)\nHP['IrrLotCode']= HP['IrrLotCode'].astype('category')\nHP['IrrLotCode']= HP['IrrLotCode'].cat.codes","0432f337":"HP['SplitZone'].unique()\nHP['SplitZone']= HP['SplitZone'].fillna(value=0)\nHP['SplitZone']= HP['SplitZone'].astype('category')\nHP['SplitZone']= HP['SplitZone'].cat.codes","d10516d6":"HP.describe().append(HP.isnull().sum().rename('isnull'))","8a1eba95":"HP.isnull().sum().sum()","a69b38cd":"HP.shape","860e453b":"HP.boxplot(column='gross_sqft')","18aeda84":"from scipy import stats\nHP=HP[(np.abs(stats.zscore(HP)) < 3).all(axis=1)]","1f90b13c":"HP.boxplot(column='gross_sqft')","bbf3dda4":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import RFE\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.linear_model import LinearRegression","8c8fe282":"X = HP.drop('sale_price',axis=1)\ny = HP['sale_price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","424e0a01":"vif = pd.DataFrame()\nvif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif[\"features\"] = X.columns\nvif.round(1)","b290fb0f":"del HP['zip_code']","3f5f60c0":"X = HP.drop('sale_price',axis=1)\ny = HP['sale_price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","5415667f":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif[\"features\"] = X.columns\nvif.round(1)","1dbcfcfc":"del HP['total_units']","5af09451":"columns = ['YearAlter2', 'XCoord', 'year_of_sale',  'YCoord', 'ComArea','LotDepth', 'LotType', 'NumFloors', 'LotFront', 'tax_class_at_sale', 'building_class', 'ResArea', 'SplitZone', 'BldgDepth', 'ResidFAR', 'LandUse', 'HealthArea', 'gross_sqft', 'BldgFront', 'year_built', 'IrrLotCode', 'AssessTot', 'land_sqft', 'FacilFAR', 'building_class_at_sale', 'NumBldgs']\nHP.drop(columns, inplace=True, axis=1)","d7f3f5fc":"HP.columns.values","981bb31f":"HP.head()","217f58ac":"HP.shape","0d0aa0a7":"import seaborn as sns\nsns.pairplot(HP,y_vars=['sale_price'], x_vars=['AssessLand', 'HistDist', 'OtherArea', 'StrgeArea', 'YearAlter1', 'BuiltFAR'],palette='Dark2')","16b95c94":"sns.pairplot(HP,y_vars=['sale_price'], x_vars=['commercial_units', 'lot', 'neighborhood', 'residential_units', 'tax_class', 'BsmtCode'],palette='Dark2')","ad15fdc1":"sns.pairplot(HP,y_vars=['sale_price'], x_vars=['GarageArea', 'OwnerName', 'ExemptTot', 'FactryArea', 'block'],palette='Dark2')","7396c86b":"sns.pairplot(HP,y_vars=['sale_price'], x_vars=['RetailArea', 'CommFAR', 'OfficeArea', 'ProxCode', 'ExemptLand', 'street name'],palette='Dark2')","82641080":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn import ensemble\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn import svm\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import r2_score\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import linear_model\nfrom sklearn.linear_model import Ridge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn import ensemble\nfrom sklearn.ensemble import GradientBoostingRegressor\n\nfrom sklearn.feature_selection import RFE","6282a22f":"X = HP.drop('sale_price',axis=1)\ny = HP['sale_price']\n\nXtrn, Xtest, Ytrn, Ytest = train_test_split(X,y,test_size=0.3, random_state=42)\nmodels = [LinearRegression(), linear_model.Lasso(alpha=0.1), Ridge(alpha=100.0), RandomForestRegressor(n_estimators=100, max_features='sqrt'), KNeighborsRegressor(n_neighbors=6),DecisionTreeRegressor(max_depth=4), ensemble.GradientBoostingRegressor()]\n\nTestModels = pd.DataFrame()\ntmp = {}\n \nfor model in models:\n    print(model)\n    m = str(model)\n    tmp['Model'] = m[:m.index('(')]\n    model.fit(Xtrn, Ytrn)\n    tmp['R2_Price'] = r2_score(Ytest, model.predict(Xtest))\n    print('score on training',model.score(Xtrn, Ytrn))\n    print('r2 score',r2_score(Ytest, model.predict(Xtest)))\n    TestModels = TestModels.append([tmp])\nTestModels.set_index('Model', inplace=True)\n \nfig, axes = plt.subplots(ncols=1, figsize=(10, 4))\nTestModels.R2_Price.plot(ax=axes, kind='bar', title='R2_Price')\nplt.show()","4b17ccb3":"HP.columns.values","a567f27a":"HP_list=list(HP.columns.values)\nHP_list1=list(HP.columns.values)\n\nnames=HP_list1\nfeature_cols =['neighborhood', 'tax_class', 'block', 'lot', 'residential_units', 'commercial_units', 'OwnerName', 'OfficeArea',\n       'RetailArea', 'GarageArea', 'StrgeArea', 'FactryArea', 'OtherArea', 'ProxCode', 'BsmtCode', 'AssessLand', 'ExemptLand', 'ExemptTot',\n       'YearAlter1', 'HistDist', 'BuiltFAR', 'CommFAR', 'street name']\ntarget=['sale_price']\nX=HP[feature_cols].dropna()\ny=np.array(HP[target].dropna()).ravel()\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n#use linear regression as the model\nmodel = ensemble.GradientBoostingRegressor()\nmodel.fit(X_train, y_train)\n#rank all features, i.e continue the elimination until the last one\nrfe = RFE(model, n_features_to_select=10, step=1)\nrfe.fit(X,y)\nprint('Features sorted by their rank:')\nprint(sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), names)))\n\n# Plot feature importance\nfeature_importance = model.feature_importances_\n# make importances relative to max importance\nfeature_importance = 100.0 * (feature_importance \/ feature_importance.max())\nsorted_idx = np.argsort(feature_importance)\npos = np.arange(sorted_idx.shape[0]) + .5\nplt.subplot(1, 2, 2)\nplt.barh(pos, feature_importance[sorted_idx], align='center')\nplt.yticks(pos, X.columns[sorted_idx])\nplt.xlabel('Relative Importance')\nplt.title('Variable Importance')\nplt.show()","5a9ab50e":"columns = ['OfficeArea', 'GarageArea', 'StrgeArea', 'FactryArea', 'OtherArea', 'BsmtCode', 'CommFAR']\nHP.drop(columns, inplace=True, axis=1)","bf0ac63c":"HP.head()","5f819b36":"X = HP.drop('sale_price',axis=1)\ny = HP['sale_price']\nXtrn, Xtest, Ytrn, Ytest = train_test_split(X,y,test_size=0.3, random_state=42)\n\nmodel = ensemble.GradientBoostingRegressor()\nparameters = {'learning_rate':[0.1,0.2,0.3],'n_estimators':[50,100,150]}\ngrid_obj = GridSearchCV(model, parameters,refit=True,cv=3,verbose=10)\ngrid_obj = grid_obj.fit(Xtrn, Ytrn)\nprint(grid_obj.fit(Xtrn, Ytrn))","75e05dc5":"grid_obj.best_params_","8f42df21":"params = grid_obj.best_params_\nmodel = ensemble.GradientBoostingRegressor(**params)\nmodel.fit(Xtrn, Ytrn.values.ravel())\ntest_score = np.zeros((params['n_estimators']),dtype=np.float64)\n\n# Predict\nYpred = model.predict(Xtest)\nmodel_mse = mean_squared_error(Ypred, Ytest)\nmodel_rmse = np.sqrt(model_mse)\nprint('Gradient Boosting RMSE: %.4f' % model_rmse)\nprint('score on training',model.score(Xtrn, Ytrn))\nprint('r2 score',r2_score(Ytest, model.predict(Xtest)))\ndf = pd.DataFrame({'Actual': Ytest, 'Predicted': Ypred, 'Difference': Ypred-Ytest})\nprint(df.head())\n\nfor i,Ypred in enumerate(model.staged_predict(Xtest)):\n    test_score[i]=model.loss_(Ytest.values.ravel(),Ypred)\n\n# Plot training deviance\nplt.figure(figsize=(10, 6))\nplt.subplot(1, 2, 1)\nplt.title('Deviance')\nplt.plot(np.arange(params['n_estimators']) + 1, model.train_score_, 'b-',label='Training Set Deviance')\nplt.plot(np.arange(params['n_estimators']) + 1, test_score, 'r-', label='Test Set Deviance')\nplt.legend(loc='upper right')\nplt.xlabel('Boosting Iterations')\nplt.ylabel('Deviance')","961d6d22":"colors=('red','blue')\nplt.scatter(Ypred,Ytest,c=colors)\nplt.xlabel('sale_price_pred')\nplt.ylabel('sale_price_test')\nplt.show","ef0cd98a":"We only consider rows for which the sale price is non zero. As zero sale price is associated with a transfer of property so we safely delete those. We have replaced zeros\/NaNs in many variables with median\/mode. Some other categorical variables were filled by 0 like 'OwnerName', 'IrrLotCode', 'SplitZone'. For 'XCoord' and 'YCoord' we have replaced the NaN and 0s by Mode(0). Same is for variables 'YearAlter1' and 'YearAlter2'. Mostly for continuous variables we have replaced the missing values by median\/mean.","a3f6cef5":"We split the 'address' into number and 'street name'. Convert the 'street name' to categorical variable and delete the number column along with 'address'.","9e92c950":"We describe the data and append in it the number of NaN's in each column in the last row. We see that there are many columns with NaNs. Our next step will be to clean this data as much as possible.","7d91bee6":"We categorize several other variables 'OwnerName', 'IrrLotCode', 'SplitZone'","7d7a549f":"We delete few more variables which shows weak dependence on the sale_price","5c57da15":"The dataset was found in the following Kaggle page.\nhttps:\/\/www.kaggle.com\/tianhwu\/brooklynhomes2003to2017\/kernels?sortBy=dateRun&group=profile&pageSize=20&datasetId=13270\nIt consists of two concatenated datasets from two sourses which were left joined to form the finl dataset as is available. One of the original data is from the NYC department of Finance (Housing Sales Data ) and the other one from NYC Department of City Planning (PLUTO and MapPLUTO).The left join was performed based on \"Block\" & \"Lot\" but 25% of the data was missing from the second set. As a result there are lots of NA's in the dataframe. ","1663a81d":"**We make arrangement so that wecan see the entire dataframe.**","2d7025ec":"The categorical variables are categorized.","ff413e1d":"We drop few more columns based on the above analysis","23b2c208":"Next we remove variables those are highly correlated by evaluating their Variable Inflation Factor. We remove one variable each step and again calculate the VIF and then remove the next. We remove all variables with VIF>5 by this way to minimize correlation among the variables. We show a few and the rest are done in a similar way.","0b39a867":"A big simplification can be done by removing duplicate columns. Also there are some coumns refering various map ID or file numbers which supposedly have no impact on any of the predictions made. We can easily remove 59 columns on various grounds.\n(0) 'Unnamed: 0' It's the ID number associated with each sale.\n\n(1) We remove both 'borough' & 'Borough' since we are working on Brooklyn borough only.\n\n(2) 'Unnamed: 0 no description\n\n(3) 'apartment_number' more than 90% missing data\n\n(4) 'Ext' EXTENSION CODE\n\n(5) 'Landmark' we delete this because we also have address and neighbourhood to specify the importance of the location\n\n(6) 'AreaSource' A code indicating the source file that was used to determine the tax lot's TOTAL BUILDING FLOOR AREA (BldgArea)\n\n(7) 'UnitsRes' The sum of residential units in all buildings on the tax lot. Same as 'residential_units'\n\n(8) 'UnitsTotal' The sum of residential and non-residential (offices, retail stores, etc.) units in all buildings on the tax lot. Same as 'total_units'.\n\n(9) 'LotArea' Total area of the tax lot, expressed in square feet rounded to the nearest integer. This is same as 'lot'\n\n(10) 'BldgArea' The total gross area in square feet. Same as 'gross_sqft'\n\n(11) 'BldgClass' Same as 'building_class'\n\n(12) 'Easements', 'easement' we delete both. The number of easements on the tax lot. As this is not important for most of the sales.\n\n(13)'OwnerType' A code indicating type of ownership for the tax lot\n\n(14) 'building_class_category' same as 'building_class'\n\n(15) 'sale_date' date of sale but we keep only the year in 'year_of_sale'\n\n(16) 'CT2010' The 2010 census tract that the tax lot is located in. Not considered to be important.\n\n(17)'CB2010' The 2010 census block that the tax lot is located in. Not considered to be important.\n\n(18) 'ZipCode' same as 'zip_code'\n\n(19) 'ZoneDist1' The zoning district classification of the tax lot, ZONING DISTRICT 1 represents the zoning district classification occupying the greatest percentage of the tax lot\u2019s area.\n\n     'ZoneDist2' If the tax lot is divided by zoning boundary lines,Zoning, ZONING DISTRICT 2 represents the zoning classification occupying the second greatest percentage of the tax lot's area.\n     \n     'ZoneDist3'If the tax lot is divided by zoning boundary lines, ZONING, ZONING DISTRICT 3 represents the zoning classification occupying the third greatest percentage of the tax lot's area. \n     \n     'ZoneDist4' If the tax lot is divided by zoning boundary lines, Zoning, ZONING DISTRICT 4 represents the zoning classification occupying the fourth greatest percentage of the tax lot's area.\n     \n(20) 'Overlay1' The commercial overlay assigned to the tax lot. \n     'Overlay2' A commercial overlay associated with the tax lot.\n     \n(21) 'SPDist1' The special purpose district assigned to the tax lot.SPECIAL PURPOSE DISTRICT 1 represents the special purpose district occupying the greatest percentage of the lot area.\n\n     'SPDist2' SPECIAL PURPOSE DISTRICT 2 represents the special purpose district occupying the second greatest percentage of the lot area.\n     \n     'SPDist3' SPECIAL PURPOSE DISTRICT 3 represents the special purpose district occupying the smallest percentage of the lot area.\n     \n(22) 'LtdHeight' Limited height districts are coded using the three to five character district symbols\n\n(23) 'YearBuilt' same as 'year_built' \n\n(24) 'BoroCode' same as 'Borough'\n\n(25)  'BBL' A concatenation of the borough code, tax block and tax lot. \n\n(26) 'Tract2010' The 2010 census tract that the tax lot is located in.\n\n(27) 'ZoneMap' The Department of City Planning Zoning Map Number associated with the tax lot\u2019s X and Y Coordinates.\n\n(28) 'ZMCode' A code (Y) identifies a border Tax Lot, i.e., a Tax Lot on the border of two or more Zoning Maps.\n\n(29) 'Sanborn' The Sanborn Map Company map number associated with the tax block and lot.\n\n(30) 'TaxMap' The Department of Finance paper tax map Volume Number associated with the tax block and lot.\n\n(31) 'EDesigNum' The E-Designation number assigned to the tax lot.\n\n(32) 'PLUTOMapID' A code indicating whether the tax lot is in the PLUTO file and\/or the modified DTM and\/or the modified DTM Clipped to the Shoreline File.\n\n(33) 'FIRM07_FLA' A one character field. Code of 1 means that some portion of the tax lot falls within the 1% annual chance floodplain as determined by FEMA\u2019s 2007 Flood Insurance Rate Map.\n\n(34) 'PFIRM15_FL' A one character field. Code of 1 means that some portion of the tax lot falls within the 1% annual chance floodplain as determined by FEMA\u2019s 2015 Preliminary Flood Insurance Rate Map.\n\n(35) 'Version' The Version Number related to the release of PLUTO.\n\n(36) 'MAPPLUTO_F' No description found.\n\n(37) 'APPBBL' The originating Borough, Tax Block and Tax Lot from the apportionment prior to the merge, split or property\u2019s conversion to a condominium. The Apportionment BBL is only available for mergers, splits and conversions since 1984. \n\n(38) 'APPDate' The date of the Apportionment.\n\n(39) 'SHAPE_Leng', 'SHAPE_Area no description of both so we drop\n\n(40) 'CD' The community district (CD) or joint interest area (JIA) that the tax lot is located in, or partially located in.\n\n(41) 'SchoolDist' The community school district that the tax lot is located in. \n\n(42) 'Council'  The city council district that the tax lot is located in.\n\n(43) 'PolicePrct' The police precinct the tax lot is located in. This field contains a three digit police precinct number.\n\n(44) 'HealthCent' The health center district that the tax lot is located in.\n\n(45) 'SanitBoro' The Boro of the Sanitation District that services the tax lot. \n\n(46) 'SanitDistr' The Sanitation District that services the tax lot.\n\n(47) 'FireComp' The fire company that services the tax lot.\n\n(48) 'SanitSub' The Subsection of the Sanitation District that services the tax lot.\n\n(49) 'CondoNo' The condominium number assigned to the complex.\n\n(50) 'Address' same as 'address'","fa7d2d6c":"It should continue this way resulting in the deletion of the following variables.","633c2de1":"We see that GradientBoostingRegressor is the best model for us as scores on both training and testing sets are close, indicating no overfitting. So we choose it and apply grid search CV to find out best set of parameters. We dont run this step as it is really time consuming.  We state the final result and use it in prediction.","7346a8d2":"We see the missing values in 'tax_class' and replace them by the corresponding values from 'tax_class_at_sale'. The convert 'tax_class' to categorical. Same is done for the missing values in 'building_class' by replacing the missing values from 'building_class_at_sale'.","57e58add":"We have thus removed all the null values from the dataframe ","6387dcfe":"We do grid search to find out the best parameters for Gradient Boosting Regressor. Since there is a trade off between the parameters 'learning_rate' and 'n_estimators' we try to find out the best values for them. Other parameters are accepted at their default values.","80f86c4f":"We locate and remove all the outliers in each column. Which makes the data more streamlined."}}