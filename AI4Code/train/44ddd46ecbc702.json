{"cell_type":{"aa52afb6":"code","474a5baa":"code","477ee447":"code","538cc25f":"code","9c184691":"code","1e4cfd7e":"code","9bb14b95":"markdown","9bc4243c":"markdown","b26844a5":"markdown","16d0e9e4":"markdown","72139d3e":"markdown","3a75451b":"markdown","b481d2c4":"markdown"},"source":{"aa52afb6":"import numpy as np\nfrom pprint import pprint","474a5baa":"def gradE(w1,w2):\n    g1 = -0.8182 + 1\/2*(2*w1+2*0.8182*w2)\n    g2 = -0.354 + 1\/2*(2*0.8182*w1+2*w2)\n    return [g1,g2]","477ee447":"def desc(rate,w1,w2):\n    vector = gradE(w1,w2)\n    return [component * -rate for component in vector]","538cc25f":"w0 = [0,0]\nw = [0,0]\n\nrate = 0.3\n\nw0_rate03_vect = [0]\nw1_rate03_vect = [0]\n\nfor i in range(200):\n    descent = desc(rate, w[0], w[1])\n    w[0] = w[0] + descent[0]\n    w[1] = w[1] + descent[1]\n    w0_rate03_vect.append(w[0])\n    w1_rate03_vect.append(w[1])    \n    \npprint(w)","9c184691":"w0 = [0,0]\nw = [0,0]\n\nrate = 1\n\nw0_rate1_vect = [0]\nw1_rate1_vect = [0]\n\nfor i in range(80):\n    descent = desc(rate, w[0], w[1])\n    w[0] = w[0] + descent[0]\n    w[1] = w[1] + descent[1]\n    w0_rate1_vect.append(w[0])\n    w1_rate1_vect.append(w[1])\n    \npprint(w)","1e4cfd7e":"from matplotlib import pyplot as plt\n\nplt.plot(w0_rate03_vect, list(range(201)), label='\u03b7=0.3', color='blue')\nplt.plot(w1_rate03_vect, list(range(201)), color='blue')\nplt.plot(w0_rate1_vect, list(range(81)), label='\u03b7=1.0', color='green')\nplt.plot(w1_rate1_vect, list(range(81)), color='green')\n\nplt.xlabel(\"Peso\")\nplt.ylabel(\"Num. Iteraciones\")\nplt.legend(loc='best')\n\nplt.show()","9bb14b95":"Con 200 iteraciones y tasa 0.3 hallamos el m\u00ednimo.\n\n\nAhora probaremos con tasa 1.0","9bc4243c":"Y podemos plantear la f\u00f3rmula de descenso de gradiente como:","b26844a5":"Con una tasa de 1 fueron suficientes tan solo 80 iteraciones.\n\nProcedemos a graficar en el plano.","16d0e9e4":"Hab\u00edamos visto que la gradiente de E(w) es","72139d3e":"## Use el m\u00e9todo del descenso de gradiente para calcular el valor \u00f3ptimo, usando los valores de la tasa de aprendizaje y en cada caso grafique la trayectoria de la evoluci\u00f3n de los pesos w(n) en el plano.\n\n1. \u03b7 = 0.3\n2. \u03b7 = 1.0","3a75451b":"Comenzamos con peso W0 = [0,0].\n\n\nQueremos obtener el m\u00ednimo hallado en la pregunta 4.a usando el descenso de gradiente\nEste ser\u00eda:[1.599 ; -0.9543]","b481d2c4":"Podemos ver c\u00f3mo con \u03b7=1 encontramos los valores \u00f3ptimos de w m\u00e1s r\u00e1pido."}}