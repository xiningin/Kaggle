{"cell_type":{"7fc3bac7":"code","855533ef":"code","55997e70":"code","5a34d3c6":"code","2c580981":"code","09c47f11":"code","8589f0c9":"code","b121f759":"code","27560a18":"code","094bdefc":"code","8443ed5b":"code","7b37689b":"code","56774ebe":"code","0751f109":"code","c129e91e":"code","690727ab":"code","ac06bb3a":"code","2656b094":"code","e9861355":"code","508214fd":"code","f21e69c9":"code","36b57ebd":"code","6f80a7fd":"code","cd62a596":"code","cea97cb9":"code","7ea4e4e7":"code","e47423c9":"code","ec17431e":"code","8d5b2db8":"code","76cabf70":"code","9fe9e11e":"code","6de96d86":"code","680262d8":"code","9bad2159":"code","9420d3b7":"code","55a93001":"code","83362bc6":"code","73733aa8":"code","68938f4f":"code","b372dd4d":"code","f02e32cf":"code","e40ee8df":"code","44bc8469":"code","548e5327":"code","db564b53":"markdown","dab4bd64":"markdown","318212a0":"markdown","db7fa829":"markdown","6cdc887d":"markdown","dbaee648":"markdown","e8295ca1":"markdown","1d3c67de":"markdown","8ff72223":"markdown","7762e8a1":"markdown"},"source":{"7fc3bac7":"import pandas as pd\nsample=pd.read_csv(\"..\/input\/samplereviews.csv\")","855533ef":"print(sample.shape)","55997e70":"#look of the dataset\nsample.head()","5a34d3c6":"def partition(x):\n    if x < 3:\n        return 'negative'\n    return 'positive'\n\n#changing reviews with score less than 3 to be positive\nactualScore = sample['Score']\npositiveNegative = actualScore.map(partition) \nsample['Score'] = positiveNegative","2c580981":"sample.head()","09c47f11":"# no of positive and negative reviews\nsample[\"Score\"].value_counts()","8589f0c9":"#dropping  the duplicates column if any\nsorted_data=sample.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\nfinal=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\nfinal.shape","b121f759":"# no duplicate columns found\n(final['Id'].size*1.0)\/(sample['Id'].size*1.0)*100","27560a18":"final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]\n# Help..Num is always less than Denom.. as Denom is people who upvote and donwvote\n#Before starting the next phase of preprocessing lets see the number of entries left\nprint(final.shape)\n\n#How many positive and negative reviews are present in our dataset?\nfinal['Score'].value_counts()","094bdefc":"# find sentences containing HTML tags\nimport re\ni=0;\nfor sent in final['Text'].values:\n    if (len(re.findall('<.*?>', sent))):\n        print(i)\n        print(sent)\n        break;\n    i += 1;","8443ed5b":"import nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nsno = nltk.stem.SnowballStemmer('english') #initialising the snowball stemmer\nstop=set(stopwords.words('english'))\n\n\ndef cleanhtml(sentence): #function to clean the word of any html-tags\n    cleanr = re.compile('<.*?>')\n    cleantext = re.sub(cleanr, ' ', sentence)\n    return cleantext\ndef cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n    cleaned = re.sub(r'[.|,|)|(|\\|\/]',r' ',cleaned)\n    return  cleaned\nprint(stop)\nprint('************************************')\nprint(sno.stem('tasty'))","7b37689b":"i=0\nstr1=' '\nfinal_string=[]\nall_positive_words=[] # store words from +ve reviews here\nall_negative_words=[] # store words from -ve reviews here.\ns=''\nfor sent in final['Text'].values:\n    filtered_sentence=[]\n    #print(sent);\n    sent=cleanhtml(sent) # remove HTMl tags\n    for w in sent.split():\n        for cleaned_words in cleanpunc(w).split():\n            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n                if(cleaned_words.lower() not in stop):\n                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n                    filtered_sentence.append(s)\n                    if (final['Score'].values)[i] == 'positive': \n                        all_positive_words.append(s) #list of all words used to describe positive reviews\n                    if(final['Score'].values)[i] == 'negative':\n                        all_negative_words.append(s) #list of all words used to describe negative reviews reviews\n                else:\n                    continue\n            else:\n                continue \n    #print(filtered_sentence)\n    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n    #print(\"***********************************************************************\")\n    \n    final_string.append(str1)\n    i+=1","56774ebe":"final['CleanedText']=final_string #adding a column of CleanedText which displays the data after pre-processing of the review \nfinal['CleanedText']=final['CleanedText'].str.decode(\"utf-8\")","0751f109":"final.shape","c129e91e":"final.head(3) #below the processed review can be seen in the CleanedText Column ","690727ab":"data_pos = final[final[\"Score\"] == \"positive\"]\ndata_neg = final[final[\"Score\"] == \"negative\"]\nfinal = pd.concat([data_pos, data_neg])\nscore =final[\"Score\"]\nfinal.head()\n","ac06bb3a":"final[\"Time\"] = pd.to_datetime(final[\"Time\"], unit = \"s\")\nfinal= final.sort_values(by = \"Time\")\nfinal.head()","2656b094":"# entire reviews are stored in X\nX = final[\"CleanedText\"]\nprint(\"shape of X:\", X.shape)\nX.shape","e9861355":"# Corresponding class labels positive and negative are stores in y\ny = final[\"Score\"]\nprint(\"shape of y:\", y.shape)","508214fd":"# split data into train and test where 70% data used to train model and 30% for test\n# final[:int(len(final) * 0.75)], final[int(len(final) * 0.75):]\nfrom sklearn.model_selection import train_test_split\nX_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\nprint(X_train.shape, y_train.shape, x_test.shape)","f21e69c9":"# Train Vectorizor using BOW\nfrom sklearn.feature_extraction.text import CountVectorizer \n\nbow = CountVectorizer()\nX_train = bow.fit_transform(X_train)\nX_train","36b57ebd":"X_train.shape","6f80a7fd":"# Test Vectorizor using BOW\nx_test = bow.transform(x_test)\nx_test","cd62a596":"x_test.shape","cea97cb9":"# Fuction to compute k value\ndef k_classifier_brute(X_train, y_train):\n    # creating odd list of K for KNN and note even is not selected as we face problems in majority vote\n    myList = list(range(0,50))\n    neighbors = list(filter(lambda x: x % 2 != 0, myList))\n\n    # empty list that will hold cv scores\n    cv_scores = []\n\n    # perform 10-fold cross validation\n    for k in neighbors:\n        knn = KNeighborsClassifier(n_neighbors=k, algorithm = \"brute\")\n        scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n        cv_scores.append(scores.mean())\n\n    # changing to misclassification error\n    MSE = [1 - x for x in cv_scores]\n    \n     # determining best k\n    optimal_k = neighbors[MSE.index(min(MSE))]\n    print('\\nThe optimal number of neighbors is %d.' % optimal_k)\n    \n    plt.figure(figsize=(10,6))\n    plt.plot(list(filter(lambda x: x % 2 != 0, myList)),MSE,color='red', linestyle='dashed', marker='o',\n             markerfacecolor='black', markersize=10)\n\n   \n    plt.title(\"Misclassification Error vs K\")\n    plt.xlabel('Number of Neighbors K')\n    plt.ylabel('Misclassification Error')\n    plt.show()\n\n    print(\"the misclassification error for each k value is : \", np.round(MSE,3))\n    return optimal_k","7ea4e4e7":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n#from sklearn.model_selection import cross_val_score\nfrom sklearn.cross_validation import cross_val_score\nfrom collections import Counter\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import model_selection\nfrom sklearn import cross_validation\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\noptimal_k_bow = k_classifier_brute(X_train, y_train)\noptimal_k_bow","e47423c9":"# instantiate learning model k = optimal_k\nknn_optimal = KNeighborsClassifier(n_neighbors=optimal_k_bow)\n\n# fitting the model\nknn_optimal.fit(X_train, y_train)\n#knn_optimal.fit(bow_data, y_train)\n\n# predict the response\npred = knn_optimal.predict(x_test)","ec17431e":"# Accuracy of train data\ntrain_acc_bow = knn_optimal.score(X_train, y_train)\nprint(\"Train accuracy is \", train_acc_bow)","8d5b2db8":"# Error on train data\ntrain_err_bow = 1-train_acc_bow\nprint(\"Train Error %f%%\" % (train_err_bow))","76cabf70":"# evaluate accuracy on test data\nacc_bow = accuracy_score(y_test, pred) * 100\nprint('\\nThe accuracy of the knn classifier for k = %d is %f%%' % (optimal_k_bow, acc_bow))","9fe9e11e":"# Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, pred)\ncm","6de96d86":"# plot confusion matrix to describe the performance of classifier.\nimport seaborn as sns\nclass_label = [\"negative\", \"positive\"]\ndf_cm = pd.DataFrame(cm, index = class_label, columns = class_label)\nsns.heatmap(df_cm, annot = True, fmt = \"d\")\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"Actual Label\")\nplt.show()","680262d8":"# To show main classification report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, pred))","9bad2159":"# Split data\nX_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\nprint(X_train.shape, x_test.shape, y_train.shape, y_test.shape)","9420d3b7":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_curve, auc\n#tfidf = TfidfVectorizer()\n#tfidf_data = tfidf.fit_transform(final[\"CleanedText\"])\n#tfidf_data\ntf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\nX_train = tf_idf_vect.fit_transform(X_train)\nX_train","55a93001":"# Convert test text data to its vectorizor\nx_test = tf_idf_vect.transform(x_test)\nx_test.shape","83362bc6":"# To choosing optimal_k\n\noptimal_k_tfidf = k_classifier_brute(X_train, y_train)\noptimal_k_tfidf","73733aa8":"# instantiate learning model k = optimal_k\nknn_optimal = KNeighborsClassifier(n_neighbors=optimal_k_tfidf)\n\n# fitting the model\nknn_optimal.fit(X_train, y_train)\n#knn_optimal.fit(bow_data, y_train)\n    \n# predict the response\npred = knn_optimal.predict(x_test)","68938f4f":"# Accuracy on train data\ntrain_acc_tfidf = knn_optimal.score(X_train, y_train)\nprint(\"Train accuracy\", train_acc_tfidf)","b372dd4d":"# Error on train data\ntrain_err_tfidf = 1-train_acc_tfidf\nprint(\"Train Error %f%%\" % (train_err_tfidf))","f02e32cf":" #evaluate accuracy\nacc_tfidf = accuracy_score(y_test, pred) * 100\nprint('\\nThe accuracy of the knn classifier for k = %d is %f%%' % (optimal_k_tfidf, acc_tfidf))","e40ee8df":"#from sklearn.matrics import confusion_matrix\ncm = confusion_matrix(y_test, pred)\ncm","44bc8469":"class_label = [\"negative\", \"positive\"]\ndf_cm = pd.DataFrame(cm, index = class_label, columns = class_label)\nsns.heatmap(df_cm, annot = True, fmt = \"d\")\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","548e5327":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, pred))","db564b53":"### TFIDF","dab4bd64":"The Amazon text reviews given by the users are considered word by word and text reviews are cleaned by using Stop words and removed unwanted HTML tags. Once time stamp is assigned, then our objective is to determine whether the review is positive or negative.We will classify the reviews by using Bag of Words and TFIDF(Term frequency and inverse document frequency), and classification algorithm called K Nearest Neighbors where the review would be chosen on the nearest distances based on the majority voting. The results are explained with the help of a confusion matrix and classification report for both the cases.\n","318212a0":"# Introduction","db7fa829":"# Feature Engineering and Classification","6cdc887d":"### Bag Of words","dbaee648":"Accuracy on the training data is 85.4%, and Accuracy on the test data based on the nine neighbors is 86%.  We should not conclude the performance only based on the accuracy as it does not tell us how much accurately it is predicting individual class labels. In this case, we have used confusion matrix to interpret the performance of the classifier.\nTrue Positive: 2525 predicted as positive reviews, and they are positive\nTrue Negative: 7 predicted as negative reviews and they are negative\nFalse Positive: 402 predicted as positive reviews and they are negative\nFalse Negative: 7 predicted as negative reviews and they are positive\nTrue Positive rate: 2525\/2532=99.7%\nTrue Negative rate:7\/409=1.7%\nFalse Positive rate: 402\/409=98.3%\nFalse Negative rate: 7\/2532=0.3%\n","e8295ca1":"We have to convert the positive and negative which is in numerical to categorical variables which we will use for classifying based on the text. For a set of 10,000 rows, we have 8514 reviews are positive, and 1486 are negative reviews.\nAfter dropping the duplicates from the 10,000 rows, we have 9803 rows left with a percentage of data retrieval of 98.03 %. The final positive and negative reviews are present in our dataset are 8346 and 1457 respectively.\nThe data also contains HTML tags in few reviews and remove all the stop words in reviews which we have clean before working on the model. After cleaning all the text review data is processed and placed in the cleaned text column. \n","1d3c67de":"the optimal number of k, i.e. 13 neighbors with classification error 0.144 . Accuracy on the training data is 86.1%, and Accuracy on the test data based on the 13 neighbors is 86.9%. We have used confusion matrix (Exhibit 4.5.2) to interpret the performance of the classifier.\nTrue Positive: 2525 predicted as positive reviews, and actually they are positive\nTrue Negative: 32 predicted as negative reviews, and actually they are negative\nFalse Positive: 377 predicted as positive reviews and actually they are negative\nFalse Negative: 7 predicted as negative reviews and actually they are positive\nTrue Positive rate: 2525\/2532=99.7%\nTrue Negative rate:32\/409=1.7%\nFalse Positive rate: 377\/409=98.3%\nFalse Negative rate: 7\/2532=0.3%\n","8ff72223":"# Text Processing","7762e8a1":" # Data Cleaning"}}