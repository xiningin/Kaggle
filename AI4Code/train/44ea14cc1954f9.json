{"cell_type":{"438c2ae6":"code","962e4853":"code","41a12878":"code","8c79f25e":"code","3925f5ad":"code","06cc043c":"code","0483e757":"code","32f14cad":"code","f71914de":"code","19ef9f54":"code","f4c162bb":"code","0b7a3fdb":"code","676d4fd2":"code","7434e65f":"code","44dfb34f":"code","944151c2":"code","5e9a4d81":"code","18238607":"code","0eeaa972":"code","ade21b7c":"code","704ff970":"code","90f73345":"code","8111e6bf":"code","fe7a2a73":"code","ab8efe27":"code","6c6574fb":"code","3c84305b":"code","aad04974":"code","f8ee6e7d":"code","7f7bc089":"code","8b89f827":"code","922e37aa":"markdown","94a1e1dd":"markdown","c2c6f628":"markdown","f0af16b1":"markdown","2a664c88":"markdown","6285d4ce":"markdown","1181ab5a":"markdown","df16c359":"markdown","d40641bb":"markdown","abdbc9ab":"markdown","a9d57905":"markdown","5893e58e":"markdown","b6f87e96":"markdown","5b4986d5":"markdown","d125401a":"markdown","02c6330b":"markdown","8482c5e6":"markdown"},"source":{"438c2ae6":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport time","962e4853":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom xgboost import XGBRegressor","41a12878":"import multiprocessing as mp","8c79f25e":"import warnings\nwarnings.filterwarnings(\"ignore\")","3925f5ad":"path_in = '\/kaggle\/input\/m5-forecasting-accuracy\/'\nos.listdir(path_in)","06cc043c":"sales = pd.read_csv(path_in+'sales_train_validation.csv')\ncal = pd.read_csv(path_in+'calendar.csv')\nprices = pd.read_csv(path_in+'sell_prices.csv')\nsamp_subm = pd.read_csv(path_in+'sample_submission.csv')","0483e757":"print('sales shape (rows, cols): ', sales.shape)\nprint('cal shape (rows, cols): ', cal.shape)\nprint('prices shape (rows, cols): ', prices.shape)\nprint('subm shape (rows, cols): ', samp_subm.shape)","32f14cad":"sales.head()","f71914de":"features_cat = ['cat_id', 'state_id']\ncal.fillna('empty', inplace=True)\nle = LabelEncoder()\nfor col in features_cat:\n    le.fit(sales[col])\n    sales[col] = le.transform(sales[col])","19ef9f54":"cal.head()","f4c162bb":"features_cat = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\ncal.fillna('empty', inplace=True)\nle = LabelEncoder()\nfor col in features_cat:\n    le.fit(cal[col])\n    cal[col] = le.transform(cal[col])","0b7a3fdb":"group_wday = cal.groupby('wday').count()\ngroup_wday","676d4fd2":"prices.head()","7434e65f":"samp_subm.head()","44dfb34f":"sales[sales.columns[6:]].iloc[0].values","944151c2":"def plot_timeseries(data, index):\n    fig = plt.figure(figsize=(16,9))\n    ax = fig.add_subplot(111)\n    x = range(1, 1913+1)\n    y = data[data.columns[6:]].iloc[index].values\n    ax.plot(x, y, linewidth=2.8, label=index)\n    plt.legend(loc='upper center')\n    plt.xlabel('days')\n    plt.ylabel('number of sales')\n    plt.grid()","5e9a4d81":"def plot_sales_and_preds(sales, preds, index, skip_days=0):\n    fig = plt.figure(figsize=(16,9))\n    ax = fig.add_subplot(111)\n    # plot sales\n    x_sales = range(1+skip_days, 1913+1)\n    y_sales = sales[sales.columns[6+skip_days:]].iloc[index].values\n    ax.plot(x_sales, y_sales, linewidth=2.8, color='blue', label='sale')\n    \n    # plot vals\n    x_val = range(1913+1, 1941+1)\n    y_val = preds[preds.columns[1:]].iloc[index].values\n    ax.plot(x_val, y_val, linewidth=2.8, color='orange', label='val')\n    \n    x_eval = range(1941+1, 1969+1)\n    y_eval = preds[preds.columns[1:]].iloc[index+30490].values\n    ax.plot(x_eval, y_eval, linewidth=2.8, color='green', label='eval')\n    \n    \n    plt.legend(loc='upper center')\n    plt.xlabel('days')\n    plt.ylabel('number of sales')\n    plt.grid()","18238607":"plot_timeseries(sales, 200)","0eeaa972":"def predict_article(articles_list):\n    skip_days = 0\n    results = []\n    for article in articles_list:\n        #print(article)\n        merge_on = ['wm_yr_wk', 'store_id']\n        X_train_org['store_id'] = sales.loc[article, 'store_id']\n        X_train_org['cat_id'] = sales.loc[article, 'cat_id']\n        X_train_org['state_id'] = sales.loc[article, 'state_id']\n        item = sales.loc[article, 'item_id']\n   \n        X_train = pd.merge(X_train_org, prices[prices['item_id']==item], on=merge_on, how='left')\n    \n        #features = ['wday', 'month', 'year', 'sell_price']\n        features = ['wday', 'month', 'year', 'sell_price', 'snap_CA', 'snap_TX', 'snap_WI']\n                    #'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2',\n                    #'cat_id', 'state_id']\n    \n        X_train = X_train[features]\n        X_train.fillna(X_train.mean(), inplace=True)\n        y_train = sales[sales.columns[6+skip_days:]].iloc[article].values\n        y_train = np.log1p(y_train)\n    \n        # scale data\n        scaler.fit(X_train)\n        X_train_scale = scaler.transform(X_train)\n    \n        # train model\n        model.fit(X_train_scale[1+skip_days:1913+1], y_train)\n        preds_val = model.predict(X_train_scale[1913+1:1941+1])\n        #y_val = np.append(y_train, preds_val)\n        #model.fit(X_train_scale[1:1941+1], y_val)\n        #preds_eval = model.predict(X_train_scale[1941:1969+1])\n        preds_eval = np.array([0 for i in range(28)]) \n        \n        preds_val = np.expm1(preds_val)\n        #preds_eval = np.expm1(preds_eval)\n        results.append(preds_val)\n        results.append(preds_eval)\n\n    return results \n    ","ade21b7c":"article_list = [i for i in range(0, 1)]\narticle_list\n\nsales_article = pd.DataFrame()\nsales_article['d'] = ['d_'+str(i) for i in range(1, 1969+1)]\n\n# merge with cal data\nX_train_org = pd.merge(sales_article, cal, on='d')\n\n# create new features for merge\nX_train_org['store_id'] = None\n\n# define scaler\nscaler = MinMaxScaler(feature_range=(0, 1))\n\n#define model\nmodel = XGBRegressor(objective='reg:squarederror', learning_rate=0.1,\n                     max_depth=3, n_estimators=200, random_state=2020)\n\nresults = predict_article(article_list)","704ff970":"results","90f73345":"def predict_by_mean(articles_list):\n    num_vals = 5\n    shift = 7\n    results = []\n    \n    for article in articles_list:\n        y_train = sales[sales.columns[6:]].iloc[article].values.tolist()\n        \n        # predict first 28 days - val\n        preds_val = []\n        for day in range(28):\n            value = 0\n            for days_back in range(1, num_vals+1):\n                idx = 1913+day-days_back*shift\n                value += y_train[idx]\n            value = value\/num_vals\n            preds_val.append(value)\n            y_train.append(value)\n            \n        # predict second 28 days - eval\n        preds_eval = []\n        value = 0\n        for day in range(28):\n            for days_back in range(1, num_vals+1):\n                idx = 1941+day-days_back*shift\n                value += y_train[idx]\n            value = 0 #value\/num_vals\n            preds_eval.append(value)\n            y_train.append(value)\n        \n        results.append(preds_val)\n        results.append(preds_eval)\n        \n    return results","8111e6bf":"article_list = [7623]#[i for i in range(0, 1)]\nresults = predict_by_mean(article_list)","fe7a2a73":"# sales_article = pd.DataFrame()\n# sales_article['d'] = ['d_'+str(i) for i in range(1, 1969+1)]\n\n# # merge with cal data\n# X_train_org = pd.merge(sales_article, cal, on='d')\n\n# # create new features for merge\n# X_train_org['store_id'] = None\n\n# # define scaler\n# scaler = MinMaxScaler(feature_range=(0, 1))\n\n# # define model\n# #objective: reg:squarederror\n# model = XGBRegressor(objective='reg:squarederror', learning_rate=0.1,\n#                          max_depth=3, n_estimators=100, random_state=2020)\n\n# cores = 4\n# article_lists = np.array_split(range(len(sales.index)), cores, axis=0)\n# start = time.time()\n# pool = mp.Pool(cores)\n# results = np.vstack(pool.map(predict_article, article_lists))\n# pool.close()\n# pool.join()\n# end = time.time()\n# print(end-start)\n","ab8efe27":"cores = 4\narticle_lists = np.array_split(range(len(sales.index)), cores, axis=0)\nstart = time.time()\npool = mp.Pool(cores)\nresults = np.vstack(pool.map(predict_by_mean, article_lists))\npool.close()\npool.join()\nend = time.time()\nprint(end-start)","6c6574fb":"(end-start)*36490\/10\/3600","3c84305b":"# samp_subm.loc[0:10-1, samp_subm.columns[1:]] = results[0:len(results):2]\n# samp_subm.loc[30490:30490+10-1, samp_subm.columns[1:]] = results[1:len(results):2]","aad04974":"samp_subm.head()","f8ee6e7d":"samp_subm.loc[0:30490-1, samp_subm.columns[1:]] = results[0:len(results):2]\nsamp_subm.loc[30490:30490+30490-1, samp_subm.columns[1:]] = results[1:len(results):2]","7f7bc089":"samp_subm.to_csv('submission.csv', index=False)","8b89f827":"plot_sales_and_preds(sales, samp_subm, 5400, skip_days=1400)","922e37aa":"# Simple Prediction\nUse the columns: wday, month, year and sell_price.","94a1e1dd":"# Functions","c2c6f628":"For testing of 10 articles:","f0af16b1":"Prod","2a664c88":"For all articles:","6285d4ce":"## Sales Data","1181ab5a":"# EDA","df16c359":"# Libraries","d40641bb":"## Price Data","abdbc9ab":"Test","a9d57905":"# Export Submission","5893e58e":"# Intro\nWelcome to the [M5 Forecasting - Accuracy](https:\/\/www.kaggle.com\/c\/m5-forecasting-accuracy) competition.\n![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/18599\/logos\/header.png)","b6f87e96":"## Calendar Data","5b4986d5":"Count the number of the feature wday:","d125401a":"# Path","02c6330b":"# Plot Results","8482c5e6":"# Load Data"}}