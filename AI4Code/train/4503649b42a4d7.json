{"cell_type":{"a1cea6f9":"code","1789c4bb":"code","98a8b5e4":"code","6bb4b523":"code","5ae09a13":"code","23c1fa17":"code","ec6d59f7":"code","1b3b064f":"markdown","0d9b57bb":"markdown","1fb5a0ce":"markdown"},"source":{"a1cea6f9":"import csv\nimport numpy as np\nimport pandas as pd\n\ndf = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\n\ndf.info()\n\nx=df.iloc[:,range(0,30)]\ny=df.iloc[:,30]\nprint(\"features.shape:\", x.shape)\nprint(\"targets.shape:\", y.shape)\n#x.columns\n#print(x.iloc[0,:])\n#print(y.iloc[0])\n","1789c4bb":"num_val_samples = int(len(x) * 0.2)\ntrain_x = x[:-num_val_samples]\ntrain_y = y[:-num_val_samples]\nval_x = x[-num_val_samples:]\nval_y = y[-num_val_samples:]\n\nprint(\"# training samples:\", len(train_x))\nprint(\"# validation samples:\", len(val_x))","98a8b5e4":"#len(train_y[train_y[:]==1])\n\ncounts = np.bincount(train_y[:])\nprint(\n    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n        counts[1], 100 * float(counts[1]) \/ len(train_y)\n    )\n)\nweight_for_0 = 1.0 \/ counts[0]\nweight_for_1 = 1.0 \/ counts[1]\n","6bb4b523":"mean = np.mean(train_x, axis=0)\ntrain_x -= mean\nval_x -= mean\nstd = np.std(train_x, axis=0)\ntrain_x \/= std\nval_x \/= std","5ae09a13":"from tensorflow import keras\n\nmodel = keras.Sequential(\n    [\n        keras.layers.Dense(\n            512, activation=\"relu\", input_shape=(train_x.shape[-1],)\n        ),\n        keras.layers.Dense(256, activation=\"relu\"),\n        keras.layers.Dropout(0.3),\n        keras.layers.Dense(256, activation=\"relu\"),\n        keras.layers.Dropout(0.3),\n        keras.layers.Dense(1, activation=\"sigmoid\"),\n    ]\n)\nmodel.summary()","23c1fa17":"metrics = [\n    keras.metrics.Accuracy(name=\"ACC\"),\n    keras.metrics.FalseNegatives(name=\"fn\"),\n    keras.metrics.FalsePositives(name=\"fp\"),\n    keras.metrics.TrueNegatives(name=\"tn\"),\n    keras.metrics.TruePositives(name=\"tp\"),\n    keras.metrics.Precision(name=\"precision\"),\n    keras.metrics.Recall(name=\"recall\"),\n]\n\nmodel.compile(\n    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n)\n\ncallbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.h5\")]\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nhistory=model.fit(\n    train_x,\n    train_y,\n    batch_size=2048,\n    epochs=30,\n    verbose=2,\n    callbacks=callbacks,\n    validation_data=(val_x, val_y),\n    class_weight=class_weight,\n)","ec6d59f7":"import matplotlib.pyplot as plt\n\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['ACC'])\nplt.plot(history.history['val_ACC'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","1b3b064f":"Conclusions\nAt the end of training, out of 56,961 validation transactions, we are:\n\n- Correctly identifying 66 of them as fraudulent\n- Missing 9 fraudulent transactions\n- At the cost of incorrectly flagging 441 legitimate transactions","0d9b57bb":"Reference: https:\/\/keras.io\/examples\/structured_data\/imbalanced_classification\/","1fb5a0ce":"# Make sure to upvote if this was useful (and motivate me to make more!)\n"}}