{"cell_type":{"9955432b":"code","cb2e39bb":"code","a8e7a28d":"code","5cf0840d":"code","d19b8b6f":"code","60ede664":"code","34aa3481":"code","47dc4b0d":"code","1e675c91":"code","cc8ed2d7":"code","59dc8864":"code","d2ceab9d":"code","b596a098":"code","c138ca3d":"code","46d452d4":"code","53680061":"code","6af011a4":"code","1f624c31":"code","61e3e4c6":"code","4b9b8dad":"code","69a024d0":"code","50297c04":"code","31276643":"code","add891e4":"code","121f7443":"code","da2473cb":"code","b3ec86d2":"code","92414bbc":"code","0a256386":"code","344fc063":"code","b7cd0d8e":"markdown","36fb160f":"markdown","1ae79793":"markdown","bec4cbc0":"markdown","9f07cee1":"markdown","1676912b":"markdown","d76674f3":"markdown","48c53c73":"markdown","e395efde":"markdown"},"source":{"9955432b":"! pip install librosa","cb2e39bb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n%matplotlib inline\nfrom matplotlib import pyplot as plt\n\nimport IPython.display as ipd\n\nimport os\nimport os.path\nfrom os import path\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\nimport time\n\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm\n\n\nimport librosa \nimport librosa.display\n#Librosa is a python package for music and audio analysis.\n\nimport tensorflow as tf","a8e7a28d":"traindf=pd.read_csv(r\"\/kaggle\/input\/rfcx-species-audio-detection\/train_tp.csv\")","5cf0840d":"traindf.shape","d19b8b6f":"traindf.head(10)","60ede664":"print(f\"total Species in Dataset : {len(traindf.recording_id)}\")\nprint(f\"total Recordings in Dataset : {len(traindf.recording_id.unique())}\")","34aa3481":"traindf['idx'] = range(1, len(traindf) + 1)\ntraindf.head(5)","47dc4b0d":"sns.countplot(traindf['species_id'])","1e675c91":"sns.countplot(traindf['songtype_id'])","cc8ed2d7":"temp=traindf.loc[(traindf['songtype_id'] ==4)]\ntemp.head(10)","59dc8864":"path.exists(\"\/kaggle\/input\/rfcx-species-audio-detection\/train\/0099c367b.flac\")","d2ceab9d":"## playing audio for songtype_id=4\nstart = time.perf_counter()\ndata1, sr1 = librosa.load('\/kaggle\/input\/rfcx-species-audio-detection\/train\/0099c367b.flac')\nprint(\"Time taken - \" + str(time.perf_counter()-start))","b596a098":"ipd.Audio('\/kaggle\/input\/rfcx-species-audio-detection\/train\/003bec244.flac')","c138ca3d":"path='\/kaggle\/input\/rfcx-species-audio-detection\/train\/003bec244.flac'\ny, sr = librosa.load(path)\nplt.figure(figsize=(20,5))\nlibrosa.display.waveplot(y, sr=sr)","46d452d4":"#display Spectrogram\npath='\/kaggle\/input\/rfcx-species-audio-detection\/train\/003bec244.flac'\nx, sr = librosa.load(path)\nX = librosa.stft(x)\nXdb = librosa.amplitude_to_db(abs(X))\nplt.figure(figsize=(20, 5))\nlibrosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz') \n#If to pring log of frequencies  \n#librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log')\nplt.colorbar()","53680061":"# Getting list of all filenames and shuffling them\nIDX=np.random.permutation(traindf['idx'])\nnum_samples = len(IDX)\nprint('Number of total examples:', num_samples)","6af011a4":"train_idx = IDX[:850]\nval_idx = IDX[850: 1216]\nprint('Training set size', len(train_idx))\nprint('Validation set size', len(val_idx))","1f624c31":"def trim_audio(IDX):\n    recording_id=traindf.loc[traindf['idx'] == IDX,'recording_id'].iloc[0]\n    t_min=traindf.loc[traindf['idx'] == IDX,'t_min'].iloc[0]\n    t_max=traindf.loc[traindf['idx'] == IDX,'t_max'].iloc[0]\n    label=traindf.loc[traindf['idx'] == IDX,'species_id'].iloc[0]\n    #print(f\"recording_id == {recording_id} & t_min = {t_min} & t_max = {t_max}\")\n    path='\/kaggle\/input\/rfcx-species-audio-detection\/train\/'+recording_id+'.flac'\n    #print(f\"Path == {path}\")\n    y, sr = librosa.load(path)\n    time_start = t_min*sr\n    time_end = t_max*sr\n    # Positioning sound slice\n    # taking 5 seconds around center of the start and end time and cropping it accordingly\n    effective_length=10*sr\n    center = np.round((time_start + time_end) \/ 2)\n    beginning = center - effective_length \/ 2\n    if beginning < 0:\n        beginning = 0\n    beginning = np.random.randint(beginning , center)\n    ending = beginning + effective_length\n    if ending > len(y):\n        ending = len(y)\n    beginning = ending - effective_length\n    y = y[beginning:ending].astype(np.float32)\n    \n    beginning_time = beginning \/ sr\n    ending_time = ending \/ sr\n    \n    #query_string = f\"recording_id == {recording_id} & \"\n    #query_string += f\"t_min = {beginning_time} & t_max = {ending_time}\"\n    #print(query_string)\n    #y=tf.squeeze(y, axis=-1)\n    return y,label","61e3e4c6":"traindf_new = pd.DataFrame(columns = ['audio', 'label'])\nvaldf_new=pd.DataFrame(columns = ['audio', 'label'])","4b9b8dad":"for index in tqdm(train_idx):\n    d,l=trim_audio(index)\n    traindf_new = traindf_new.append({'audio' : d, 'label' : l},ignore_index = True)","69a024d0":"traindf_new.head(10)","50297c04":"def convert_tolist(x):\n    return x.tolist()","31276643":"traindf_new1=traindf_new\nconvert_tolist(traindf_new.iloc[5].audio)","add891e4":"traindf_new1.audio=traindf_new1.audio.apply(convert_tolist)","121f7443":"traindf_new1.to_csv('TrainWaveForm.csv', index = False)","da2473cb":"traindf_new.iloc[5].audio","b3ec86d2":"ipd.Audio(traindf_new.iloc[5].audio, rate=16000)","92414bbc":"for index in tqdm(val_idx):\n    d,l=trim_audio(index)\n    valdf_new = valdf_new.append({'audio' : d, 'label' : l},ignore_index = True) ","0a256386":"valdf_new1=valdf_new\nvaldf_new1.audio=valdf_new1.audio.apply(convert_tolist)","344fc063":"valdf_new1.to_csv('ValWaveForm.csv', index = False)","b7cd0d8e":"Creating an Index column as there is redundancy in Recording Id Column, May need a unique identifier","36fb160f":"<h2> 1. Importing required libraries and dataset <\/h2>","1ae79793":"Creating train and validation datasets","bec4cbc0":"<h2>3. Data Preparation <\/h2>\n\n* Creating Train and Validation split\n* Triming the audio\n* Reading the audio files with labels","9f07cee1":"<center><h3>IN PROGRESS<\/h3><\/center>","1676912b":"#### Let's analyse the number of Species ID we have and their frequencies using count plot ","d76674f3":"<h2>2. Data Analysis <\/h2>","48c53c73":"#### Species_id is balanced, all the categories have sufficient number of entries\nLet's look into other features","e395efde":"### Helpful Resources\n<hr\/>\n\n* https:\/\/www.youtube.com\/watch?v=iCwMQJnKk2c&list=PL-wATfeyAMNqIee7cH3q1bh4QJFAaeNv0\n* https:\/\/www.kaggle.com\/c\/rfcx-species-audio-detection\/discussion\/200922\n* https:\/\/medium.com\/@patrickbfuller\/librosa-a-python-audio-libary-60014eeaccfb \n* https:\/\/towardsdatascience.com\/extract-features-of-music-75a3f9bc265d\n* https:\/\/www.kdnuggets.com\/2020\/02\/audio-data-analysis-deep-learning-python-part-1.html"}}