{"cell_type":{"f3d668cc":"code","629097a2":"code","6a311b95":"code","b59ee9f8":"code","4125a660":"code","39fbc10b":"code","2312d4b8":"code","1a911438":"code","df8d8e12":"code","0cb8ee33":"code","cc784dad":"code","178a122f":"code","a8dc51ce":"code","4fe6385b":"code","a07cd229":"code","aa2d0dbf":"code","7da135d6":"code","9f516ea1":"code","e46e3609":"code","12fe2a67":"code","bb735e83":"code","aeadb542":"code","a58441c5":"code","9bd81c3c":"code","ad034f4f":"code","82163c7c":"code","f5b08576":"code","75340d6d":"code","2ad7d8c5":"code","bc7058fc":"code","454ecca8":"code","ab642a71":"code","01befa9d":"code","447c088f":"code","5314f3d7":"code","78fbe835":"code","83efdc90":"code","70d199d6":"code","29af7e61":"code","ea92e34b":"code","23fee66e":"code","7f4eec67":"code","cb07476b":"code","eae98dc6":"code","682812f4":"code","a8b4f14b":"code","7aeb66ca":"code","02ce4909":"code","475238bf":"code","c2ab6db9":"code","9a631051":"code","32f033dc":"code","5bab957b":"code","f1ec13e3":"code","c7c9b867":"code","23baef75":"code","08b48f92":"code","5bca1775":"code","e20b784c":"code","71cb284d":"code","6e356972":"code","4e4c0fe5":"code","e642ce17":"code","6662b118":"code","9f8d5d5d":"code","89a5e0ce":"code","4300328f":"code","13e6a184":"code","72448c63":"code","d255cdbb":"code","e1200d2e":"code","05aac7af":"code","96e465b6":"code","bd0041f7":"code","283442a7":"code","c9c87f2a":"code","49b4046f":"code","525f4dde":"code","e56067ac":"code","316d941a":"code","2e50c03b":"code","08e6778e":"code","e5532a3a":"code","37546659":"code","61bab141":"code","e31e8f0a":"code","f5a2ad66":"code","c679211b":"code","cd283d57":"code","9efb5d7f":"code","1b5f778a":"code","6ad53172":"code","8774c20c":"code","af20d503":"code","50bb0dee":"code","82c672f6":"code","da9b8904":"code","c37a8162":"code","aad2e624":"code","be8392fd":"code","e199f306":"markdown","1174b3a9":"markdown","201f528e":"markdown"},"source":{"f3d668cc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","629097a2":"# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nimport time\nfrom sklearn.model_selection import train_test_split","6a311b95":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n","b59ee9f8":"combine = [train_df, test_df]","4125a660":"train_df.shape","39fbc10b":"train_df.head()","2312d4b8":"test_df.shape","1a911438":"test_df.head()","df8d8e12":"print(train_df.columns.values)","0cb8ee33":"train_df.tail()","cc784dad":"train_df.info()\nprint('_*'*20)\ntest_df.info()","178a122f":"train_df.describe()","a8dc51ce":"train_df.describe(include=['O'])","4fe6385b":"train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","a07cd229":"train_df.columns.values","aa2d0dbf":"train_df[['Sex', 'Survived']].groupby(['Sex'], as_index = False).mean().sort_values(by='Survived', ascending=False)","7da135d6":"train_df[['SibSp', 'Survived']].groupby(['SibSp'], as_index = False).mean().sort_values(by='Survived', ascending=False)","9f516ea1":"train_df[['Parch', 'Survived']].groupby(['Parch'], as_index = False).mean().sort_values(by='Survived', ascending=False)","e46e3609":"g = sns.FacetGrid(train_df, col = 'Survived')\ng.map(plt.hist, 'Age', bins=10)","12fe2a67":"grid = sns.FacetGrid(train_df, col = 'Survived', row = 'Pclass')\ngrid.map(plt.hist, 'Age',alpha=.5, bins=20)\ngrid.add_legend()","bb735e83":"grid = sns.FacetGrid(train_df, row='Embarked', size=2.2, aspect=1.6)\ngrid.map(sns.pointplot,'Pclass', 'Survived', 'Sex',palette='deep')\ngrid.add_legend()","aeadb542":"grid = sns.FacetGrid(train_df, row='Embarked', col='Survived', size=2.2, aspect=1.6)\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\ngrid.add_legend()","a58441c5":"print(\"Before\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)\ntrain_df = train_df.drop(['Ticket','Cabin'], axis=1)\ntest_df = test_df.drop(['Ticket','Cabin'], axis=1)\nprint(\"After\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)","9bd81c3c":" train_df.head()","ad034f4f":"train_df['Title'] = train_df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest_df['Title'] = test_df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\n","82163c7c":"pd.crosstab(train_df['Title'], train_df['Sex'])","f5b08576":"train_df['Title'] = train_df['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n    'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\ntrain_df['Title'] = train_df['Title'].replace('Mlle', 'Miss')\ntrain_df['Title'] = train_df['Title'].replace('Ms', 'Miss')\ntrain_df['Title'] = train_df['Title'].replace('Mme', 'Mrs')\n    \n","75340d6d":"train_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","2ad7d8c5":"test_df['Title'] = test_df['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n    'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\ntest_df['Title'] = test_df['Title'].replace('Mlle', 'Miss')\ntest_df['Title'] = test_df['Title'].replace('Ms', 'Miss')\ntest_df['Title'] = test_df['Title'].replace('Mme', 'Mrs')\n    \n","bc7058fc":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n\ntrain_df['Title'] = train_df['Title'].map(title_mapping)\ntrain_df['Title'] = train_df['Title'].fillna(0)\n\ntrain_df.head()","454ecca8":"train_df['Title'].value_counts()","ab642a71":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n\ntest_df['Title'] = test_df['Title'].map(title_mapping)\ntest_df['Title'] = test_df['Title'].fillna(0)\n\ntest_df.head()","01befa9d":"train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\ntest_df = test_df.drop(['Name'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.shape, test_df.shape","447c088f":"train_df.head()","5314f3d7":"test_df['Sex'] = test_df['Sex'].map({'female':1, 'male':0}).astype(int)","78fbe835":"train_df['Sex'] = train_df['Sex'].map({'female':1, 'male':0}).astype(int)","83efdc90":"train_df.head()","70d199d6":"test_df.head()","29af7e61":"grid = sns.FacetGrid(train_df, row='Pclass', col= 'Sex',\n                    size=2.2, aspect=1.6)\ngrid.map(plt.hist,'Age', alpha=.5, bins=20)\ngrid.add_legend()","ea92e34b":"guess_ages = np.zeros((2,3))\nguess_ages","23fee66e":"\nfor i in range(0,2):\n    for j in range(0,3):\n        guess_df = train_df[(train_df['Sex'] == i) &(train_df['Pclass'] == j + 1)]['Age'].dropna()\n       \n        age_guess = guess_df.median()\n        guess_ages[i,j] = int( age_guess\/0.5 + 0.5 ) * 0.5\n\nfor i in range(0,2):\n    for j in range(0,3):\n        train_df.loc[(train_df.Age.isnull())&\\\n                    (train_df.Sex == i)&\\\n                    (train_df.Pclass == j+1),\\\n                    'Age'] = guess_ages[i,j]\n        \ntrain_df['Age'] = train_df['Age'].astype(int)\n\ntrain_df.head()","7f4eec67":"for i in range(0,2):\n    for j in range(0,3):\n        guess_df = test_df[(test_df['Sex'] == i) &\\\n                           (test_df['Pclass'] == j + 1)]['Age'].dropna()\n        age_guess = guess_df.median()\n        guess_ages[i,j] = int(age_guess\/0.5 + 0.5)*0.5\n\nfor i in range(0,2):\n    for j in range(0,3):\n        test_df.loc[(test_df.Age.isnull())&\\\n                    (test_df.Sex == i)&\\\n                    (test_df.Pclass == j+1),\\\n                    'Age'] = guess_ages[i,j]\n        \ntest_df['Age'] = test_df['Age'].astype(int)\n\ntest_df.head()","cb07476b":"train_df['Age']","eae98dc6":"pd.cut(train_df['Age'],5)","682812f4":"train_df['AgeBand'] = pd.cut(train_df['Age'],5)\ntrain_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)","a8b4f14b":"type(train_df.loc[train_df['Age'] <= 16, 'Age'])","7aeb66ca":"def AgeBand(df):\n    df.loc[df['Age'] <= 16, 'Age'] = 0\n    df.loc[(df['Age'] > 16) &(df['Age'] <= 32), 'Age'] = 1\n    df.loc[(df['Age'] > 32) &(df['Age'] <= 48), 'Age'] = 2\n    df.loc[(df['Age'] > 48) &(df['Age'] <= 64), 'Age'] = 3\n    df.loc[(df['Age'] > 164) , 'Age'] = 4\n    return df","02ce4909":"train_df = AgeBand(train_df)\ntrain_df.head()","475238bf":"test_df = AgeBand(test_df)\ntest_df.head()","c2ab6db9":"train_df = train_df.drop(['AgeBand'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()","9a631051":"for dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\ntrain_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)","32f033dc":"for dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1,'IsAlone'] = 1\n    \ntrain_df[['IsAlone', 'Survived']].groupby(['IsAlone'],as_index=False).mean().sort_values(by='Survived', ascending=False)","5bab957b":"train_df = train_df.drop(['Parch','SibSp', 'FamilySize'], axis=1)\ntest_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ncombine = [train_df, test_df]\n\ntrain_df.head()","f1ec13e3":"for dataset in combine:\n    dataset['Age*Class'] = dataset.Age * dataset.Pclass\ntrain_df.loc[:,['Age*Class', 'Age', 'Pclass']].head(10)","c7c9b867":"freq_port = train_df.Embarked.dropna().mode()[0]\nfreq_port","23baef75":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n    \ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index = False).mean().sort_values(by='Survived', ascending=False)","08b48f92":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map({'S':0,\n                                                  'C':1,\n                                                  'Q':2}).astype(int)\n\ntrain_df.head()","5bca1775":"test_df['Fare']= test_df['Fare'].fillna(test_df['Fare'].dropna().median())","e20b784c":"test_df.head()","71cb284d":"train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\ntrain_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)","6e356972":"train_df.head(10)","4e4c0fe5":"train_df.head()","e642ce17":"combine = [train_df, test_df]","6662b118":"for dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain_df = train_df.drop(['FareBand'], axis=1)\ncombine = [train_df, test_df]\n    \ntrain_df.head(10)","9f8d5d5d":"test_df.head()","89a5e0ce":"test_df.head()","4300328f":"X_train = train_df.drop(\"Survived\", axis=1)\nY_train = train_df[\"Survived\"]\nX_test = test_df.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","13e6a184":"X_train_train, X_train_val, Y_train_train, Y_train_val = train_test_split(\n                                                        X_train, Y_train, test_size = 0.2, random_state=42)","72448c63":"logreg = LogisticRegression()\nstart_time = time.time()\nlogreg.fit(X_train, Y_train)\nelapsed_time = time.time() - start_time\n\nprint(\"Time consumed to fit model: \",time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\nstart_time = time.time()\nY_pred = logreg.predict(X_test)\nelapsed_time = time.time() - start_time\nprint(\"Time consumed to pred model: \",time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\nacc_log = round(logreg.score(X_train, Y_train)*100,2)\nacc_log","d255cdbb":"pd.DataFrame(train_df.columns)","e1200d2e":"pd.DataFrame(train_df.columns.delete(0))","05aac7af":"coeff_df = pd.DataFrame(train_df.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\ncoeff_df.sort_values(by='Correlation', ascending=False)","96e465b6":"logreg.coef_[0]","bd0041f7":"logreg = LogisticRegression()\nstart_time = time.time()\nlogreg.fit(X_train_train, Y_train_train)\nelapsed_time = time.time() - start_time\n\nprint(\"Time consumed to fit model: \",time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\nstart_time = time.time()\nY_pred = logreg.predict(X_train_val)\nelapsed_time = time.time() - start_time\nprint(\"Time consumed to pred model: \",time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\nacc_log = round(logreg.score(X_train_val, Y_train_val)*100,2)\nacc_log","283442a7":"svc = SVC()\nstart_time = time.time()\nsvc.fit(X_train, Y_train)\nelapsed_time = time.time() - start_time\nprint(\"Time consumed to fit model: \",time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\nstart_time = time.time()\nY_pred = svc.predict(X_test)\nelapsed_time = time.time() - start_time\nprint(\"Time consumed to pred model: \",time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nacc_svc","c9c87f2a":"svc = SVC()\nstart_time = time.time()\nsvc.fit(X_train_train, Y_train_train)\nelapsed_time = time.time() - start_time\nprint(\"Time consumed to fit model: \",time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\nstart_time = time.time()\nY_pred = svc.predict(X_train_val)\nelapsed_time = time.time() - start_time\nprint(\"Time consumed to pred model: \",time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n\nacc_svc = round(svc.score(X_train_val, Y_train_val) * 100, 2)\nacc_svc","49b4046f":"svc.support_vectors_.shape","525f4dde":"svc.support_.shape","e56067ac":"svc.n_support_","316d941a":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","2e50c03b":"knn = KNeighborsClassifier(n_neighbors=5)\nstart_time = time.time()\nknn.fit(X_train_train, Y_train_train)\nelapsed_time = time.time() - start_time\nprint(\"Time consumed to fit model: \",time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\nstart_time = time.time()\nY_pred = knn.predict(X_train_val)\nelapsed_time = time.time() - start_time\nprint(\"Time consumed to pred model: \",time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n\nacc_knn = round(knn.score(X_train_val, Y_train_val) * 100, 2)\nacc_knn","08e6778e":"gaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nY_pred = gaussian.predict(X_train)\nacc_gaussian = round(gaussian.score(X_train, Y_train) * 100,2)\nacc_gaussian","e5532a3a":"gaussian = GaussianNB()\nstart_time = time.time()\ngaussian.fit(X_train_train, Y_train_train)\nelapsed_time = time.time() - start_time\nprint(\"Time consumed to fit model: \",time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\nstart_time = time.time()\nY_pred = gaussian.predict(X_train_val)\nelapsed_time = time.time() - start_time\nprint(\"Time consumed to pred model: \",time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n\nacc_gaussian = round(gaussian.score(X_train_val, Y_train_val) * 100, 2)\nacc_gaussian","37546659":"perceptron = Perceptron()\nperceptron.fit(X_train, Y_train)\nY_pred = perceptron.predict(X_test)\nacc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\nacc_perceptron","61bab141":"perceptron = Perceptron()\nstart_time = time.time()\nperceptron.fit(X_train_train, Y_train_train)\nelapsed_time = time.time() - start_time\nprint(\"Time consumed to fit model: \",time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\nstart_time = time.time()\nY_pred = perceptron.predict(X_train_val)\nelapsed_time = time.time() - start_time\nprint(\"Time consumed to pred model: \",time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n\nacc_perceptron = round(gaussian.score(X_train_val, Y_train_val) * 100, 2)\nacc_perceptron","e31e8f0a":"linear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nY_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\nacc_linear_svc","f5a2ad66":"linear_svc = LinearSVC()\nlinear_svc.fit(X_train_train, Y_train_train)\nY_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train_val, Y_train_val) * 100, 2)\nacc_linear_svc","c679211b":"sgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\nacc_sgd","cd283d57":"sgd = SGDClassifier()\nsgd.fit(X_train_train, Y_train_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train_val, Y_train_val) * 100, 2)\nacc_sgd","9efb5d7f":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","1b5f778a":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train_train, Y_train_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train_val, Y_train_val) * 100, 2)\nacc_decision_tree","6ad53172":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nacc_random_forest = round(random_forest.score(X_train, Y_train)*100, 2)\nacc_random_forest","8774c20c":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree'],\n    'Score': [acc_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree]})    \nmodels.sort_values(by='Score', ascending=False)","af20d503":"test_df.head()","50bb0dee":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","82c672f6":"from xgboost.sklearn import XGBClassifier\nxgb = XGBClassifier(learning_rate=0.001,n_estimators=2500,\n                                max_depth=4, min_child_weight=0,\n                                gamma=0, subsample=0.7,\n                                colsample_bytree=0.7,\n                                scale_pos_weight=1, seed=27,\n                                reg_alpha=0.00006)\nxgb.fit(X_train_train, Y_train_train)\nY_pred = xgb.predict(X_test)\nacc_xgb = round(xgb.score(X_train_val, Y_train_val) * 100, 2)\nacc_xgb","da9b8904":"from xgboost.sklearn import XGBClassifier\nxgb = XGBClassifier(learning_rate=0.001,n_estimators=2500,\n                                max_depth=4, min_child_weight=0,\n                                gamma=0, subsample=0.7,\n                                colsample_bytree=0.7,\n                                scale_pos_weight=1, seed=27,\n                                reg_alpha=0.00006)\nxgb.fit(X_train, Y_train)\nY_pred = xgb.predict(X_test)\nacc_xgb = round(xgb.score(X_train, Y_train) * 100, 2)\nacc_xgb","c37a8162":"submission = pd.DataFrame({\n    \"PassengerId\": test_df[\"PassengerId\"],\n    \"Survived\":Y_pred\n})","aad2e624":"submission","be8392fd":"submission.to_csv('submision.csv', index=False)\nsub_read = pd.read_csv('submision.csv')\nsub_read","e199f306":"# 2. SVM","1174b3a9":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train_train, Y_train_train)\nY_pred = random_forest.predict(X_test)\nacc_random_forest = round(random_forest.score(X_train_val, Y_train_val)*100, 2)\nacc_random_forest","201f528e":"># 1. LogisticRegression"}}