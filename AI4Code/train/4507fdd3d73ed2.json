{"cell_type":{"36340af7":"code","d3e3a6bf":"code","64708674":"code","a41b23ae":"code","d6aa782d":"code","5a14636f":"code","8d296579":"code","d05e4ed6":"code","d37f43b1":"code","1ef213e2":"code","12d48c8b":"code","9c55ada0":"code","b8d8160f":"code","848b9e5c":"code","b5fce4ac":"code","c70cbc32":"code","a4137f09":"code","c7f6c1a3":"code","300a0643":"code","8f090b11":"markdown","ab84f479":"markdown","966c1b8b":"markdown","14e87ac7":"markdown","9b3e3457":"markdown","898a0baa":"markdown"},"source":{"36340af7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d3e3a6bf":"df_test = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-5\/test.csv\")\ndf_train = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-5\/train.csv\")\ndf_sub = pd.read_csv(\"..\/input\/covid19-global-forecasting-week-5\/submission.csv\")","64708674":"valid_date = df_test.Date.min()\ndf_train = df_train[df_train.Date < valid_date]\ndf = pd.concat([df_train, df_test])\ndf.Date = pd.to_datetime(df.Date)","a41b23ae":"from sklearn.preprocessing import LabelEncoder\nfrom datetime import datetime\n\ndf[\"geography\"] = df.Country_Region + \"_\" + df.Province_State + \"_\" + df.County\ndf.loc[df.County.isna(), \"geography\"] = df[df.County.isna()].Country_Region + \"_\" + df[df.County.isna()].Province_State\ndf.loc[df.Province_State.isna(), \"geography\"] = df[df.Province_State.isna()].Country_Region\n\nle = LabelEncoder()\ndf.Country_Region = le.fit_transform(df.Country_Region.astype(str))\ndf.Province_State = le.fit_transform(df.Province_State.astype(str))\ndf.County = le.fit_transform(df.County.astype(str))\ndf.Target = le.fit_transform(df.Target.astype(str))","d6aa782d":"lags = [1, 2, 3, 4, 5, 6, 7, 8, 9]\nlag_cols = [f\"lag_{lag}\" for lag in lags]\nwins = [3,7]\nlag_wins = [1,2,3]\n\nwin_cols = []\nfor win in wins:\n    for lag_win in lag_wins:\n        win_col = f\"rmean_{lag_win}_{win}\"  \n        win_cols = win_cols + [win_col]\n\ndef createfeature(df):   \n    df.sort_values([\"geography\", \"Date\", \"Target\"], inplace = True)\n    for lag, lag_col in zip(lags, lag_cols):\n        df[lag_col] = df.groupby([\"geography\", \"Target\"])[\"TargetValue\"].shift(lag)\n\n    for win in wins:\n        for lag_win in lag_wins:\n            win_col = f\"rmean_{lag_win}_{win}\"          \n            df[win_col] = df[[f\"lag_{lag}\" for lag in range(lag_win, lag_win+win)]].mean(axis = 1)\n\n    return df\n    ","5a14636f":"df = createfeature(df)","8d296579":"features = [\"Country_Region\", \"Province_State\", \"County\", \"Population\",\"Target\"] + lag_cols + win_cols   \n\ncategorical_features = [\"Country_Region\", \"Province_State\", \"County\", \"Target\"]\n\ndf_train = df[~(df.TargetValue.isna()) & ~ (df.lag_9.isna())]\nX_train = df_train[df_train.Date < datetime(2020, 4, 20)][features]\ny_train = df_train[df_train.Date < datetime(2020, 4, 20)].TargetValue.values\nX_test = df_train[df_train.Date >= datetime(2020, 4, 20)][features]\ny_test = df_train[df_train.Date >= datetime(2020, 4, 20)].TargetValue.values\n\nprint(f\"Train shape: {(X_train.shape, y_train.shape)}\")\nprint(f\"Test shape: {(X_test.shape, y_test.shape)}\")\n","d05e4ed6":"QUANTILE = [0.05, 0.5, 0.95]\n\ndef Weighted_Pinball_Loss(q, X_test, y_test, y_pred):\n    df_weight = X_test[['Population','Target']].copy()\n    df_weight['Weight'] = df_weight['Population']\n    #Facilities\n    df_weight.loc[df_weight.Target == 1, 'Weight'] = 10 *  df_weight.loc[df_weight.Target == 1, 'Weight']\n    #W = X_test.apply(lambda x: x.Population if x.Target == 0 else 10 * x.Population, axis=1).values\n    W = df_weight['Weight'].values\n    W = np.log(W+1) ** -1\n    e = y_test - y_pred\n    L = np.maximum(q * e, (q - 1) * e)\n    score = np.average(L, weights = W)\n    return score","d37f43b1":"def quantile_loss(q,y_true,y_pred):\n    e = y_true - y_pred\n    return np.maximum(q * e, (q - 1) * e).mean()","1ef213e2":"%%time\n\nfrom sklearn.ensemble import GradientBoostingRegressor\n\nLEARNING_RATE = 0.01\nN_ESTIMATORS = 2000\nN_ESTIMATORS = 1000\n\nmodel_bst_save = {}\nscore_bst_save = {}\n\nfor alpha in QUANTILE:\n    print(f'Train quantile: {alpha}')\n    model = GradientBoostingRegressor(loss='quantile', alpha=alpha, n_estimators=N_ESTIMATORS, learning_rate=LEARNING_RATE, n_iter_no_change = 10, validation_fraction = 0.2)\n    model = model.fit(X_train,y_train)\n    y_pred = model.predict(X_test)\n    print(f' Number estimator: {model.n_estimators_}')\n    n_est_build = model.n_estimators_\n    model = GradientBoostingRegressor(loss='quantile', alpha=alpha, n_estimators=n_est_build, learning_rate=LEARNING_RATE)\n    score = Weighted_Pinball_Loss(alpha,X_test,y_test,y_pred)\n    score_bst_save.update({alpha: score})\n    print(f' Weighted Pinball Loss {score}')\n    model = model.fit(df_train[features], df_train.TargetValue.values)\n    model_bst_save.update({alpha: model})\n\nprint(f'Average Pinball Loss: {np.mean(list(score_bst_save.values()))}')\n\nmodel_bst_reg = GradientBoostingRegressor(loss='ls',n_estimators=N_ESTIMATORS, learning_rate=LEARNING_RATE, n_iter_no_change = 10, validation_fraction = 0.2)\nmodel_bst_save.update({'reg': model_bst_reg})","12d48c8b":"'''\n%%time\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nLEARNING_RATE = 0.01\nN_ESTIMATORS = 500\n\nmodel_rf_save = {}\nscore_rf_save = {}\n\nmodel = RandomForestRegressor(n_estimators=N_ESTIMATORS,n_jobs=-1)\nmodel = model.fit(X_train,y_train)\n\nrf_preds = []\nfor estimator in model.estimators_:\n    rf_preds.append(estimator.predict(X_test))\nrf_preds = np.array(rf_preds).transpose()\n\nfor alpha in QUANTILE:\n    y_pred = np.percentile(rf_preds, alpha * 100, axis=1)\n    score = Weighted_Pinball_Loss(alpha,X_test,y_test,y_pred)\n    score_rf_save.update({alpha: score})\n    print(f'{alpha}: Weighted Pinball Loss {score}')\nprint(f'Average Pinball Loss: {np.mean(list(score_rf_save.values()))}')    \n\nmodel = RandomForestRegressor(n_estimators=N_ESTIMATORS,n_jobs=-1)\nmodel = model.fit(df_train[features], df_train.TargetValue.values)\nmodel_rf_save = model\n'''","9c55ada0":"%%time\n\nimport lightgbm as lgb\n\nLEARNING_RATE = 0.1\nN_ESTIMATORS = 2000\n#N_ESTIMATORS = 1000\n\ndtrain = lgb.Dataset(X_train, label = y_train, free_raw_data=False, categorical_feature = categorical_features)\ndbuild = lgb.Dataset(df_train[features], label = df_train.TargetValue.values, free_raw_data=False, categorical_feature = categorical_features)\ndval = lgb.Dataset(X_test, label = y_test, free_raw_data=False, categorical_feature = categorical_features)\n\nmodel_lgb_save = {}\nscore_lgb_save = {}\n\nfor alpha in QUANTILE:\n    params = {\n        \"objective\": \"quantile\",\n        #\"objective\": \"regression\",       \n        \"alpha\": alpha,\n        \"learning_rate\": LEARNING_RATE,\n        \"metric\": \"mae\",\n        \"reg_sqrt\": True\n    }\n       \n    print(f'Train quantile: {alpha}')\n    model_lgb_val = lgb.train(params, train_set = dtrain, valid_sets = [dval], num_boost_round = N_ESTIMATORS, early_stopping_rounds = 100, verbose_eval = 50)\n    y_pred = model_lgb_val.predict(X_test)\n    score = Weighted_Pinball_Loss(alpha,X_test,y_test,y_pred)\n    score_lgb_save.update({alpha: score})\n    print(f' Weighted Pinball Loss {score}')   \n    model_lgb_build = lgb.train(params, train_set = dbuild, num_boost_round = model_lgb_val.best_iteration)\n    model_lgb_save.update({alpha: model_lgb_build})\n\nprint(f'Average Pinball Loss: {np.mean(list(score_lgb_save.values()))}')\n\n# Create model to regresion forecast\n\nparams = {\n    \"objective\": \"regression\",       \n    \"alpha\": alpha,\n    \"learning_rate\": LEARNING_RATE,\n    \"metric\": \"mse\",\n}\n\nmodel_lgb_reg = lgb.train(params, train_set = dtrain, valid_sets = [dval], num_boost_round = N_ESTIMATORS, early_stopping_rounds = 100, verbose_eval = 50)\nmodel_lgb_save.update({'reg': model_lgb_reg})","b8d8160f":"'''Memory error\nimport tensorflow as tf\n\ndef tilted_loss(q, y, f):\n    e = (y - f)\n    return tf.keras.backend.mean(tf.keras.backend.maximum(q * e, (q - 1) * e), axis=-1)\nBATCH_SIZE = 512\nEPOCHS = 500\nUNITS = 50\n\nearly_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\noptimizer = tf.keras.optimizers.Adam(0.01)\n\nmodel = tf.keras.Sequential([\n      tf.keras.layers.Dense(UNITS, activation='relu', input_dim=X_train.shape[1]),\n      tf.keras.layers.Dense(UNITS, activation='relu'),\n      tf.keras.layers.Dense(1)\n    ])\n\nmodel_save = {}\n\nfor ALPHA in QUANTILE:\n    print(f'Train quantile: {ALPHA}')\n    model.compile(loss=lambda y, f: tilted_loss(ALPHA, y, f), optimizer=optimizer)\n    model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0, validation_data=(X_test, y_test), callbacks=[early_stop])    \n    y_pred = model.predict(X_test)\n    model_save.update({ALPHA: model})\n    print(f' Weighted Pinball Loss {Weighted_Pinball_Loss(ALPHA,X_test,y_test,y_pred)}')\n\n'''","848b9e5c":"%%time\nmodel_save = model_lgb_save\n#model_save = model_bst_save\n# Predict by day\ndf_sub = pd.DataFrame()\nfor pred_date in df_test.Date.unique():\n    print(f'Predict day {pred_date}')\n    X_pred = df[df.Date == pred_date][features]\n    if isinstance(model_save,dict):\n        for alpha in QUANTILE:\n            Y_pred = model_save[alpha].predict(X_pred)\n            df_sub = df_sub.append(pd.DataFrame({\n                'ForecastId': (df_test[df_test.Date == pred_date]['ForecastId']).values,\n                'Quantile': alpha,\n                'ForecastId_Quantile': (df_test[df_test.Date == pred_date]['ForecastId'].astype(str) + '_' + str(alpha)).values, \n                'TargetValue': Y_pred }),ignore_index=True)\n            # Save target with accuracy forecast\n            #if alpha == 0.5:\n            #    df.loc[df.Date == pred_date, 'TargetValue'] = Y_pred\n            #    df = createfeature(df)\n        # Predict new target\n        Y_pred = model_save['reg'].predict(X_pred)\n        df.loc[df.Date == pred_date, 'TargetValue'] = Y_pred\n        df = createfeature(df)\n    else: #Random Forest\n        rf_preds = []\n        for estimator in model_save.estimators_:\n            rf_preds.append(estimator.predict(X_pred))\n        rf_preds = np.array(rf_preds).transpose()\n\n        for alpha in QUANTILE:\n            y_pred = np.percentile(rf_preds, alpha * 100, axis=1)\n            df_sub = df_sub.append(pd.DataFrame({\n                'ForecastId': (df_test[df_test.Date == pred_date]['ForecastId']).values,\n                'Quantile': alpha,\n                'ForecastId_Quantile': (df_test[df_test.Date == pred_date]['ForecastId'].astype(str) + '_' + str(alpha)).values, \n                'TargetValue': Y_pred }),ignore_index=True)\n        y_pred = model_save.predict(X_pred)\n        df.loc[df.Date == pred_date, 'TargetValue'] = y_pred\n        df = createfeature(df)           \n        \n    # Create submission\ndf_sub = df_sub.sort_values(['ForecastId','Quantile']).reset_index(drop = True)","b5fce4ac":"df_sub[['ForecastId_Quantile','TargetValue']].to_csv(\"submission.csv\", index = False)","c70cbc32":"from bokeh.plotting import figure, show, output_notebook\nfrom bokeh.models import NumeralTickFormatter\nfrom bokeh.palettes import Spectral11\noutput_notebook()","a4137f09":"def plotCountry(country):\n    df_country = pd.merge(left=df_test[df_test['Country_Region'] == country], right=df_sub, left_on='ForecastId', right_on='ForecastId')\n    df_country = df_country.groupby(['Date','Target','Quantile']).sum().reset_index()\n    df_country.Date = pd.to_datetime(df_country.Date)\n    mypalette=Spectral11[0:3]\n    p = figure(title=country + \" Confirmed Cases Forecast\", x_axis_label='Date', x_axis_type='datetime', y_axis_label='Confirmed Cases')\n    i = 0\n    for alpha in QUANTILE:\n        df_quantile = df_country[(df_country['Target'] == 'ConfirmedCases') & (df_country['Quantile'] == alpha)]   \n        p.line(df_quantile['Date'], df_quantile['TargetValue'], legend_label=f\"Confirmed Cases - Quantile {alpha}\", line_width=2, line_color=mypalette[i])\n        i += 1\n    p.legend.location = \"top_left\"\n    p.yaxis.formatter=NumeralTickFormatter(format=\"\u20180.0a\")    \n    show(p)\n\n    mypalette=Spectral11[0:3]\n    p = figure(title=country + \" Fatalities Forecast\", x_axis_label='Date', x_axis_type='datetime', y_axis_label='Fatalities')\n    i = 0\n    for alpha in QUANTILE:\n        df_quantile = df_country[(df_country['Target'] == 'Fatalities') & (df_country['Quantile'] == alpha)]   \n        p.line(df_quantile['Date'], df_quantile['TargetValue'], legend_label=f\"Fatalities - Quantile {alpha}\", line_width=2, line_color=mypalette[i])\n        i += 1\n    p.legend.location = \"top_left\"\n    p.yaxis.formatter=NumeralTickFormatter(format=\"\u20180.0a\")    \n    show(p)","c7f6c1a3":"plotCountry('US')","300a0643":"plotCountry('Vietnam')","8f090b11":"Reference:\n\nQuantile regression:\n- https:\/\/colab.research.google.com\/drive\/1nXOlrmVHqCHiixqiMF6H8LSciz583_W2#scrollTo=3QoChH3zXVnl\n\nTensorflow probability\n- https:\/\/towardsdatascience.com\/deep-quantile-regression-in-tensorflow-1dbc792fe597\n- http:\/\/hyperion.usc.edu\/UQ-SummerSchool\/pres\/Dillon.pdf\n","ab84f479":"# Light GBM","966c1b8b":"# Predict plot","14e87ac7":"# Tensorflow\n\nNeed to improve memory issues","9b3e3457":"# Gradient Boosting Regressor","898a0baa":"# Random Forest\n\nMoved to other kernel:\n\nhttps:\/\/www.kaggle.com\/binhlc\/sar-cov-2-week-5-random-forest-quantile"}}