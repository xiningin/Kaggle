{"cell_type":{"f308f29a":"code","13b15294":"code","5cedb8c4":"code","4a452527":"code","14828982":"code","49c7c0d6":"code","d890a57b":"code","232e977d":"code","5eecbce5":"code","a690076a":"code","87c3d0d0":"code","dc97293e":"code","40d81a82":"code","8886dedc":"code","5d59e222":"code","1bc1243c":"code","71a42c9b":"code","2eed569c":"code","57539707":"code","d7c3f4e0":"code","4a862a6f":"code","91879d74":"code","c8133df5":"code","77764f4f":"code","69c3abe8":"code","d62edc9a":"code","05375c66":"code","5001700c":"code","59285a10":"code","15b4fb3b":"code","049a59ec":"code","34da7986":"code","ccc71ae9":"code","7e73d30d":"code","048efd35":"code","83279584":"code","ed11068c":"code","52134a98":"code","f182ba13":"code","17122c3e":"code","c21813e1":"code","92b69dcf":"code","317a1c76":"code","28548f68":"code","814fee1a":"code","6bc86b5c":"code","a2a6528d":"code","b1b20bc3":"code","9fb14d39":"code","5fcaa550":"code","d4d5ce34":"code","84d4c1c7":"code","1c85f1ed":"code","6883bf5d":"code","912e5509":"code","d9b7f759":"code","ae553fd0":"code","2a1dfa2f":"code","eb201227":"code","83daaa84":"code","f4a2d7dc":"code","8285305c":"code","ed1bf328":"code","ba09698e":"code","01a90912":"code","64b35b56":"code","e2067acd":"code","65406c36":"code","f42617d0":"code","7ebeaea7":"code","e67f7360":"code","6bfe2949":"code","119de288":"code","e60727b7":"code","24a8caa9":"code","e7bb3d1f":"code","402a5ccb":"code","8dde5c32":"code","b3795d1b":"code","f42b932a":"code","fe133ade":"code","670ecfff":"code","f5ba03b5":"code","6ff7fe4e":"code","324ee5e5":"code","7d33064a":"code","1c277d92":"code","9c9fe838":"code","800d45f8":"code","f78e6eb5":"code","adc93c2a":"code","7eae98a9":"code","307e7ec0":"code","ddb7daaa":"code","d594d65f":"code","fe6554bb":"code","e7c56892":"code","1f597c67":"code","4b993bc3":"code","4f248cd9":"markdown","7cb3f0c2":"markdown","288e39bd":"markdown","f34aeab0":"markdown","ebb51e00":"markdown","71b87eb4":"markdown","d4cf74e3":"markdown","92aac8c7":"markdown","ccb76950":"markdown","18bcb8a4":"markdown","590ead41":"markdown","265709e7":"markdown","5477cb9f":"markdown","0047a645":"markdown","f0f04791":"markdown","50fbf867":"markdown","5805d295":"markdown","2c68f398":"markdown","05821711":"markdown","ec59c4f3":"markdown","06a319a6":"markdown","2f3188d9":"markdown","81bd28f9":"markdown","f19df971":"markdown","0b3afb9e":"markdown","debca532":"markdown","7cfeb404":"markdown","091e44f6":"markdown","bd15bb58":"markdown"},"source":{"f308f29a":"!pip install 'openpyxl'","13b15294":"import numpy as np\nimport pandas as pd\nimport missingno\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tabulate import tabulate\n\n\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_validate\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import average_precision_score, classification_report, roc_auc_score, roc_curve, auc, plot_confusion_matrix, precision_recall_fscore_support\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.preprocessing import OneHotEncoder\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\nfrom xgboost  import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\nimport time\n\nnotebook_start = time.time()","5cedb8c4":"# features used by Sirio Libanes' Hospital\n\ndef makebio_df(df:pd.DataFrame):\n\n    df[\"BLOODPRESSURE_ARTERIAL_MEAN\"] = (df['BLOODPRESSURE_SISTOLIC_MEAN'] + 2*df['BLOODPRESSURE_DIASTOLIC_MEAN'])\/3\n \n    df[\"NEUTROPHILES\/LINFOCITOS\"] = df['NEUTROPHILES_MEAN']\/df['LINFOCITOS_MEAN']\n\n    df[\"GASO\"] = df.groupby(\"PATIENT_VISIT_IDENTIFIER\").P02_ARTERIAL_MEAN.apply(lambda x: x.fillna(method='ffill'))\n    df[\"GASO\"] = (~df[\"GASO\"].isna()).astype(int)\n\n    return df[[\"ICU\",\"WINDOW\",\n               \"PATIENT_VISIT_IDENTIFIER\",\n               \"AGE_ABOVE65\", \n               \"GENDER\", \n               \"BLOODPRESSURE_ARTERIAL_MEAN\", \n               \"RESPIRATORY_RATE_MAX\", \n               \"HTN\", \n               'DISEASE GROUPING 1',\n               'DISEASE GROUPING 2',\n               'DISEASE GROUPING 3',\n               'DISEASE GROUPING 4',\n               'DISEASE GROUPING 5',\n               'DISEASE GROUPING 6',\n               \"GASO\",\n               \"OXYGEN_SATURATION_MIN\",\n               \"HEART_RATE_MAX\",\n               \"PCR_MEAN\",\n               \"CREATININ_MEAN\"]]","4a452527":"# creates a new df based on selected window,next one i.e.(0-2,2-4) for ICU prediction and previous one for feature temporal differences\n\ndef window_df_creation(df_base):\n# first, we create our 0-2 WINDOW dataframe\n\n    starting_window = '0-2' \n    ending_window = '2-4'\n#     slicing df to match selected Windows\n    df = df_base.copy()\n    df = df[(df['WINDOW']==starting_window)|(df['WINDOW']==ending_window)]\n    \n#     creating feature identifying if patient went to the ICU on the ending_window    \n    next_period_icu = df.groupby(['PATIENT_VISIT_IDENTIFIER'])['WINDOW','ICU'].sum()\n    next_period_icu = next_period_icu.rename(columns={'ICU':'next_period_ICU'})\n    \n#     adding new columns to starting_window rows\n    df1 = df.merge(next_period_icu,left_on='PATIENT_VISIT_IDENTIFIER',right_index=True)\n    df1 = df1[(df1['WINDOW']==starting_window)]\n    df1 = df1.drop(columns=['WINDOW','AGE_ABOVE65','ICU'])\n    \n#     transforming categorical data to dummies and setting index as unique ID (Patient ID)\n    df1 = pd.get_dummies(df1)\n    df1.index = df1['PATIENT_VISIT_IDENTIFIER']\n\n\n    \n    \n# creating 2-4 WINDOW df\n    \n    starting_window = '2-4' \n    ending_window = '4-6'\n    dif_window = '0-2'\n    \n    #     slicing df to match selected Windows\n    df = df_best_features.copy()\n    df = df[(df['WINDOW']==starting_window)|(df['WINDOW']==ending_window)]\n    \n#     remove starting_window ICU patients\n    remove_patients = df[(df['WINDOW']==starting_window) & (df['ICU']==1)]['PATIENT_VISIT_IDENTIFIER'].to_list()\n\n    df = df.query(\"PATIENT_VISIT_IDENTIFIER not in @remove_patients\")\n    df = df.reset_index(drop=True)\n    \n#     creating feature identifying if patient went to the ICU on the ending_window    \n    next_period_icu = df.groupby(['PATIENT_VISIT_IDENTIFIER'])['WINDOW','ICU'].sum()\n    next_period_icu = next_period_icu.rename(columns={'ICU':'next_period_ICU'})\n    \n#     adding new columns to starting_window rows\n    df = df.merge(next_period_icu,left_on='PATIENT_VISIT_IDENTIFIER',right_index=True)\n    df = df[(df['WINDOW']==starting_window)]\n    df = df.drop(columns=['WINDOW','AGE_ABOVE65','ICU'])\n    \n#     transforming categorical data to dummies and setting index as unique ID (Patient ID)\n    df = pd.get_dummies(df)\n    df['WINDOW'] = starting_window\n    df.index = df['PATIENT_VISIT_IDENTIFIER']\n        \n    df_dif_list = []\n    for x in df[(df['WINDOW']==starting_window)].index:\n        df_end = df_best_features[(df_best_features['WINDOW']==starting_window) & (df_best_features['PATIENT_VISIT_IDENTIFIER']==x)]\n        df_end = df_end.drop(columns=['WINDOW'])\n\n        df_init = df_best_features[(df_best_features['WINDOW']==dif_window) & (df_best_features['PATIENT_VISIT_IDENTIFIER']==x)]\n        df_init = df_init.drop(columns=['WINDOW'])\n        df_init = df_init.values.tolist()[0]\n\n        df_dif2 = df_end.sub(df_init, axis='columns')\n\n        df_dif2['PATIENT_VISIT_IDENTIFIER'] = x\n        df_dif2['WINDOW'] = starting_window\n        dif_vector = df_dif2.values.tolist()[0] \n        df_dif_list.append(dif_vector)\n\n    df_dif2 = pd.DataFrame(df_dif_list)\n\n    # new headers for dif columns\n    dif_headers = [f\"{x}_windif_2\" for x in df_best_features.columns.to_list()]\n    new_col = ['WINDOW']\n    dif_headers_new = dif_headers + new_col\n    dif_headers_new[0] = 'PATIENT_VISIT_IDENTIFIER'\n    dif_headers_new.remove('WINDOW_windif_2')\n    dif_headers_new\n\n    df_dif2.columns = dif_headers_new\n    df_dif2.drop(columns=['WINDOW','AGE_ABOVE65_windif_2','DISEASE GROUPING 2_windif_2','DISEASE GROUPING 3_windif_2','DISEASE GROUPING 4_windif_2','DISEASE GROUPING 5_windif_2','ICU_windif_2','AGE_PERCENTIL_10th_windif_2','AGE_PERCENTIL_20th_windif_2','AGE_PERCENTIL_80th_windif_2','AGE_PERCENTIL_90th_windif_2','AGE_PERCENTIL_Above 90th_windif_2'],inplace=True)\n\n#     merging dfs to create final df\n    df2 = df.merge(df_dif2,left_index = True,right_on='PATIENT_VISIT_IDENTIFIER')\n    df2.index = df2['PATIENT_VISIT_IDENTIFIER']\n    df2.drop(columns=['PATIENT_VISIT_IDENTIFIER','WINDOW'],inplace=True)\n    \n\n    \n    \n    \n    \n# creating 4-6 WINDOW df\n    \n    starting_window = '4-6' \n    ending_window = '6-12'\n    dif_window = '2-4'\n    \n    #     slicing df to match selected Windows\n    df = df_best_features.copy()\n    df = df[(df['WINDOW']==starting_window)|(df['WINDOW']==ending_window)]\n    \n    #     remove starting_window ICU patients\n    remove_patients = df[(df['WINDOW']==starting_window) & (df['ICU']==1)]['PATIENT_VISIT_IDENTIFIER'].to_list()\n\n    df = df.query(\"PATIENT_VISIT_IDENTIFIER not in @remove_patients\")\n    df = df.reset_index(drop=True)\n    \n#     creating feature identifying if patient went to the ICU on the ending_window    \n    next_period_icu = df.groupby(['PATIENT_VISIT_IDENTIFIER'])['WINDOW','ICU'].sum()\n    next_period_icu = next_period_icu.rename(columns={'ICU':'next_period_ICU'})\n    \n#     adding new columns to starting_window rows\n    df = df.merge(next_period_icu,left_on='PATIENT_VISIT_IDENTIFIER',right_index=True)\n    df = df[(df['WINDOW']==starting_window)]\n    df = df.drop(columns=['WINDOW','AGE_ABOVE65','ICU'])\n    \n#     transforming categorical data to dummies and setting index as unique ID (Patient ID)\n    df = pd.get_dummies(df)\n    df['WINDOW'] = starting_window\n    df.index = df['PATIENT_VISIT_IDENTIFIER']\n        \n    df_dif_list = []\n    for x in df[(df['WINDOW']==starting_window)].index:\n        df_end = df_best_features[(df_best_features['WINDOW']==starting_window) & (df_best_features['PATIENT_VISIT_IDENTIFIER']==x)]\n        df_end = df_end.drop(columns=['WINDOW'])\n\n        df_init = df_best_features[(df_best_features['WINDOW']==dif_window) & (df_best_features['PATIENT_VISIT_IDENTIFIER']==x)]\n        df_init = df_init.drop(columns=['WINDOW'])\n        df_init = df_init.values.tolist()[0]\n\n        df_dif3 = df_end.sub(df_init, axis='columns')\n\n        df_dif3['PATIENT_VISIT_IDENTIFIER'] = x\n        df_dif3['WINDOW'] = starting_window\n        dif_vector = df_dif3.values.tolist()[0] \n        df_dif_list.append(dif_vector)\n\n    df_dif3 = pd.DataFrame(df_dif_list)\n\n    # new headers for dif columns\n    dif_headers = [f\"{x}_windif_4\" for x in df_best_features.columns.to_list()]\n    new_col = ['WINDOW']\n    dif_headers_new = dif_headers + new_col\n    dif_headers_new[0] = 'PATIENT_VISIT_IDENTIFIER'\n    dif_headers_new.remove('WINDOW_windif_4')\n    dif_headers_new\n\n    df_dif3.columns = dif_headers_new\n    df_dif3.drop(columns=['WINDOW','AGE_ABOVE65_windif_4','DISEASE GROUPING 2_windif_4','DISEASE GROUPING 3_windif_4','DISEASE GROUPING 4_windif_4','DISEASE GROUPING 5_windif_4','ICU_windif_4','AGE_PERCENTIL_10th_windif_4','AGE_PERCENTIL_20th_windif_4','AGE_PERCENTIL_80th_windif_4','AGE_PERCENTIL_90th_windif_4','AGE_PERCENTIL_Above 90th_windif_4'],inplace=True)\n\n    \n    #     merging dfs to create final df\n    df3 = df.merge(df_dif3,left_index = True,right_on='PATIENT_VISIT_IDENTIFIER')\n    df3 = df3.merge(df_dif2,left_on = 'PATIENT_VISIT_IDENTIFIER',right_on='PATIENT_VISIT_IDENTIFIER')\n    df3.index = df3['PATIENT_VISIT_IDENTIFIER_x']\n    df3.drop(columns=['PATIENT_VISIT_IDENTIFIER','PATIENT_VISIT_IDENTIFIER_x','WINDOW'],inplace=True)\n    \n\n    \n    \n# creating 6-12 WINDOW df\n    \n    starting_window = '6-12' \n    ending_window = 'ABOVE_12'\n    dif_window = '4-6'\n    \n    #     slicing df to match selected Windows\n    df = df_best_features.copy()\n    df = df[(df['WINDOW']==starting_window)|(df['WINDOW']==ending_window)]\n    \n    #     remove starting_window ICU patients\n    remove_patients = df[(df['WINDOW']==starting_window) & (df['ICU']==1)]['PATIENT_VISIT_IDENTIFIER'].to_list()\n\n    df = df.query(\"PATIENT_VISIT_IDENTIFIER not in @remove_patients\")\n    df = df.reset_index(drop=True)\n    \n#     creating feature identifying if patient went to the ICU on the ending_window    \n    next_period_icu = df.groupby(['PATIENT_VISIT_IDENTIFIER'])['WINDOW','ICU'].sum()\n    next_period_icu = next_period_icu.rename(columns={'ICU':'next_period_ICU'})\n    \n#     adding new columns to starting_window rows\n    df = df.merge(next_period_icu,left_on='PATIENT_VISIT_IDENTIFIER',right_index=True)\n    df = df[(df['WINDOW']==starting_window)]\n    df = df.drop(columns=['WINDOW','AGE_ABOVE65','ICU'])\n    \n#     transforming categorical data to dummies and setting index as unique ID (Patient ID)\n    df = pd.get_dummies(df)\n    df['WINDOW'] = starting_window\n    df.index = df['PATIENT_VISIT_IDENTIFIER']\n        \n    df_dif_list = []\n    for x in df[(df['WINDOW']==starting_window)].index:\n        df_end = df_best_features[(df_best_features['WINDOW']==starting_window) & (df_best_features['PATIENT_VISIT_IDENTIFIER']==x)]\n        df_end = df_end.drop(columns=['WINDOW'])\n\n        df_init = df_best_features[(df_best_features['WINDOW']==dif_window) & (df_best_features['PATIENT_VISIT_IDENTIFIER']==x)]\n        df_init = df_init.drop(columns=['WINDOW'])\n        df_init = df_init.values.tolist()[0]\n\n        df_dif4 = df_end.sub(df_init, axis='columns')\n\n        df_dif4['PATIENT_VISIT_IDENTIFIER'] = x\n        df_dif4['WINDOW'] = starting_window\n        dif_vector = df_dif4.values.tolist()[0] \n        df_dif_list.append(dif_vector)\n\n    df_dif4 = pd.DataFrame(df_dif_list)\n\n    # new headers for dif columns\n    dif_headers = [f\"{x}_windif_6\" for x in df_best_features.columns.to_list()]\n    new_col = ['WINDOW']\n    dif_headers_new = dif_headers + new_col\n    dif_headers_new[0] = 'PATIENT_VISIT_IDENTIFIER'\n    dif_headers_new.remove('WINDOW_windif_6')\n    dif_headers_new\n\n    df_dif4.columns = dif_headers_new\n    df_dif4.drop(columns=['WINDOW','AGE_ABOVE65_windif_6','DISEASE GROUPING 2_windif_6','DISEASE GROUPING 3_windif_6','DISEASE GROUPING 4_windif_6','DISEASE GROUPING 5_windif_6','ICU_windif_6','AGE_PERCENTIL_10th_windif_6','AGE_PERCENTIL_20th_windif_6','AGE_PERCENTIL_80th_windif_6','AGE_PERCENTIL_90th_windif_6','AGE_PERCENTIL_Above 90th_windif_6'],inplace=True)\n\n    \n    #     merging dfs to create final df\n    df4 = df.merge(df_dif4,left_index = True,right_on='PATIENT_VISIT_IDENTIFIER')\n    df4 = df4.merge(df_dif2,left_on = 'PATIENT_VISIT_IDENTIFIER',right_on='PATIENT_VISIT_IDENTIFIER')\n    df4 = df4.merge(df_dif3,left_on = 'PATIENT_VISIT_IDENTIFIER',right_on='PATIENT_VISIT_IDENTIFIER')\n    df4.index = df4['PATIENT_VISIT_IDENTIFIER_x']\n    df4.drop(columns=['PATIENT_VISIT_IDENTIFIER','PATIENT_VISIT_IDENTIFIER_x','PATIENT_VISIT_IDENTIFIER_y','WINDOW'],inplace=True)\n    \n    return df1,df2,df3,df4","14828982":"# creates new dfs to be used with proba combination\n\ndef df_proba_create(df_base):\n\n    # first, we create our 0-2 WINDOW dataframe\n\n    starting_window = '0-2' \n    ending_window = '2-4'\n#     slicing df to match selected Windows\n    df = df_base.copy()\n    df = df[(df['WINDOW']==starting_window)|(df['WINDOW']==ending_window)]\n    \n#     creating feature identifying if patient went to the ICU on the ending_window    \n    next_period_icu = df.groupby(['PATIENT_VISIT_IDENTIFIER'])['WINDOW','ICU'].sum()\n    next_period_icu = next_period_icu.rename(columns={'ICU':'next_period_ICU'})\n    \n#     adding new columns to starting_window rows\n    df1 = df.merge(next_period_icu,left_on='PATIENT_VISIT_IDENTIFIER',right_index=True)\n    df1 = df1[(df1['WINDOW']==starting_window)]\n    df1 = df1.drop(columns=['WINDOW','AGE_ABOVE65','ICU'])\n    \n#     transforming categorical data to dummies and setting index as unique ID (Patient ID)\n    df1 = pd.get_dummies(df1)\n    df1.index = df1['PATIENT_VISIT_IDENTIFIER']\n    df1.drop(columns=['PATIENT_VISIT_IDENTIFIER'], inplace = True)\n    \n\n    \n    \n    # 2-4 WINDOW dataframe\n\n    starting_window = '0-2' \n    ending_window = '4-6'\n#     slicing df to match selected Windows\n    df = df_base.copy()\n    df = df[(df['WINDOW']==starting_window)|(df['WINDOW']==ending_window)]\n    \n    #     remove starting_window ICU patients\n    remove_patients = df[(df['WINDOW']==starting_window) & (df['ICU']==1)]['PATIENT_VISIT_IDENTIFIER'].to_list()\n\n    df = df.query(\"PATIENT_VISIT_IDENTIFIER not in @remove_patients\")\n    df = df.reset_index(drop=True)\n    \n#     creating feature identifying if patient went to the ICU on the ending_window    \n    next_period_icu = df.groupby(['PATIENT_VISIT_IDENTIFIER'])['WINDOW','ICU'].sum()\n    next_period_icu = next_period_icu.rename(columns={'ICU':'next_period_ICU'})\n    \n#     adding new columns to starting_window rows\n    df2 = df.merge(next_period_icu,left_on='PATIENT_VISIT_IDENTIFIER',right_index=True)\n    df2 = df2[(df2['WINDOW']==starting_window)]\n    df2 = df2.drop(columns=['WINDOW','AGE_ABOVE65','ICU'])\n    \n#     transforming categorical data to dummies and setting index as unique ID (Patient ID)\n    df2 = pd.get_dummies(df2)\n    df2.index = df2['PATIENT_VISIT_IDENTIFIER']\n    df2.drop(columns=['PATIENT_VISIT_IDENTIFIER'], inplace = True)\n    \n\n    # 4-6 WINDOW dataframe\n\n    starting_window = '0-2' \n    ending_window = '6-12'\n#     slicing df to match selected Windows\n    df = df_base.copy()\n    df = df[(df['WINDOW']==starting_window)|(df['WINDOW']==ending_window)]\n    \n    #     remove starting_window ICU patients\n    remove_patients = df[(df['WINDOW']==starting_window) & (df['ICU']==1)]['PATIENT_VISIT_IDENTIFIER'].to_list()\n\n    df = df.query(\"PATIENT_VISIT_IDENTIFIER not in @remove_patients\")\n    df = df.reset_index(drop=True)\n    \n#     creating feature identifying if patient went to the ICU on the ending_window    \n    next_period_icu = df.groupby(['PATIENT_VISIT_IDENTIFIER'])['WINDOW','ICU'].sum()\n    next_period_icu = next_period_icu.rename(columns={'ICU':'next_period_ICU'})\n    \n#     adding new columns to starting_window rows\n    df3 = df.merge(next_period_icu,left_on='PATIENT_VISIT_IDENTIFIER',right_index=True)\n    df3 = df3[(df3['WINDOW']==starting_window)]\n    df3 = df3.drop(columns=['WINDOW','AGE_ABOVE65','ICU'])\n    \n#     transforming categorical data to dummies and setting index as unique ID (Patient ID)\n    df3 = pd.get_dummies(df3)\n    df3.index = df3['PATIENT_VISIT_IDENTIFIER']\n    df3.drop(columns=['PATIENT_VISIT_IDENTIFIER'], inplace = True)\n    \n\n    # 6-12 WINDOW dataframe\n\n    starting_window = '0-2' \n    ending_window = 'ABOVE_12'\n#     slicing df to match selected Windows\n    df = df_base.copy()\n    df = df[(df['WINDOW']==starting_window)|(df['WINDOW']==ending_window)]\n    \n    #     remove starting_window ICU patients\n    remove_patients = df[(df['WINDOW']==starting_window) & (df['ICU']==1)]['PATIENT_VISIT_IDENTIFIER'].to_list()\n\n    df = df.query(\"PATIENT_VISIT_IDENTIFIER not in @remove_patients\")\n    df = df.reset_index(drop=True)\n    \n#     creating feature identifying if patient went to the ICU on the ending_window    \n    next_period_icu = df.groupby(['PATIENT_VISIT_IDENTIFIER'])['WINDOW','ICU'].sum()\n    next_period_icu = next_period_icu.rename(columns={'ICU':'next_period_ICU'})\n    \n#     adding new columns to starting_window rows\n    df4 = df.merge(next_period_icu,left_on='PATIENT_VISIT_IDENTIFIER',right_index=True)\n    df4 = df4[(df4['WINDOW']==starting_window)]\n    df4 = df4.drop(columns=['WINDOW','AGE_ABOVE65','ICU'])\n    \n#     transforming categorical data to dummies and setting index as unique ID (Patient ID)\n    df4 = pd.get_dummies(df4)\n    df4.index = df4['PATIENT_VISIT_IDENTIFIER']\n    df4.drop(columns=['PATIENT_VISIT_IDENTIFIER'], inplace = True)\n    \n    return df1,df2,df3,df4","49c7c0d6":"def train_test(df):\n    features = df.columns.to_list()\n    features.remove('next_period_ICU')\n    \n    x=df[features]\n    y=df['next_period_ICU']\n    \n    X_train, X_test, y_train, y_test = train_test_split(x,y,stratify = y,random_state = 42, test_size=0.20)\n    return X_train, X_test, y_train, y_test, x, y","d890a57b":"def model_comparison(df):\n    \n#     train test split\n    X_train, X_test, y_train, y_test, x_full, y_full = train_test(df)  \n    \n    \n    \n    ###############     Logistic Regression     ###############\n    \n    init_time = time.time()\n    \n        ###### Hyperoptimization ######\n    lr_params = {\n        'C': np.random.uniform(low=0.0, high=1.0, size=1000),\n        'penalty': ['l1', 'l2'],\n        'max_iter': np.random.uniform(low=2000, high=10000, size=1000),\n    }\n\n    lr_random_search_model = RandomizedSearchCV(\n        estimator=LogisticRegression(\n            fit_intercept=True,\n            class_weight='balanced',\n            random_state=42\n        ), \n        param_distributions=lr_params,\n        scoring='f1',\n        cv=4,\n        n_iter=2000,\n        n_jobs=-1,\n        random_state=42\n    )\n\n    lr_random_search_model.fit(x_full, y_full)\n    lr_best_model = lr_random_search_model.best_estimator_\n\n    \n    ###### Evaluating hyperopt ######\n    y_pred_test = lr_best_model.predict(x_full)\n    y_prob_test = lr_best_model.predict_proba(x_full)[:, 1]\n\n    lr_auc_score_test = round(roc_auc_score(y_full,y_prob_test),4)\n\n    _,recall_test,f1_score_test,_ = precision_recall_fscore_support(y_full,y_pred_test)\n    lr_f1_score_test = round(f1_score_test[1],4)\n    lr_recall_test = round(recall_test[1],4)\n\n    lr_avg_prec_test = round(average_precision_score(y_full,y_pred_test),4)\n\n    end_time = time.time()\n    lr_fit_time = round((end_time - init_time)\/60,2)\n    \n    print(f\"Logistic Regression done in {lr_fit_time} minutes\")\n    \n    \n    ###############     Extra Trees     ############### \n    \n    init_time = time.time()\n\n\n    # Hyperparameter grid\n    param_grid = {\n        'n_estimators': np.linspace(1500, 3000).astype(int),\n        'max_depth': list(np.linspace(2, 4).astype(int)),\n        'max_features': ['auto', 'sqrt'],\n        'max_samples': list(np.arange(0.5, 1, 0.1)),\n        'min_samples_split': [5, 10, 20],\n        'bootstrap': [True, False]\n    }\n\n    # Estimator for use in random search\n    estimator = ExtraTreesClassifier(class_weight='balanced',random_state=42)\n\n    # Create the random search model\n    xtrees_model = RandomizedSearchCV(estimator, param_grid, n_jobs = -1, \n                            scoring = 'f1', cv = 3, \n                            n_iter = 100, verbose = 0,\n                            random_state=42)\n\n    # Fit \n    xtrees_model.fit(x_full, y_full)\n    xt_best_model = xtrees_model.best_estimator_\n\n\n    ###### Evaluating hyperopt - test ######\n    y_pred_test = xt_best_model.predict(x_full)\n    y_prob_test = xt_best_model.predict_proba(x_full)[:, 1]\n\n    xt_auc_score_test = round(roc_auc_score(y_full,y_prob_test),4)\n\n    _,recall_test,f1_score_test,_ = precision_recall_fscore_support(y_full,y_pred_test)\n    xt_f1_score_test = round(f1_score_test[1],4)\n    xt_recall_test = round(recall_test[1],4)\n\n    xt_avg_prec_test = round(average_precision_score(y_full,y_pred_test),4)\n\n    end_time = time.time()\n    xt_fit_time = round((end_time - init_time)\/60,2)\n    print(f\"Extra Trees done in {xt_fit_time} minutes\")\n    \n    \n    \n    ###############     LGBM     ###############\n\n    init_time = time.time()\n\n\n    # Hyperparameter grid\n    param_grid = {\"n_estimators\": np.linspace(2, 5).astype(int),\n                  \"boosting_type\": [\"gbdt\",\"dart\",\"goss\"],\n                  \"subsample\": list(np.arange(0.5, 1, 0.2)),\n                  \"colsample_bytree\": list(np.arange(0.5, 0.8, 0.1)),\n                  \"objective\": [\"binary\",\"multiclass\"],\n                  \"alpha\": list(np.arange(0, 0.6, 0.2)),\n                  \"max_depth\": [2,3,4,5,6],\n                  \"num_leaves\": np.linspace(20, 40).astype(int),\n                 }\n\n    # Estimator for use in random search\n    estimator = LGBMClassifier(class_weight='balanced',random_state=42)\n\n    # Create the random search model\n    lgbm = RandomizedSearchCV(estimator, param_grid, n_jobs = -1, \n                            scoring = 'f1', cv = 5, \n                            n_iter = 100, verbose = 0,\n                            random_state=42)\n\n    # Fit \n    lgbm.fit(x_full, y_full)\n    lgbm_best_model = lgbm.best_estimator_\n\n    ###### Evaluating hyperopt - test ######\n    y_pred_test = lgbm_best_model.predict(x_full)\n    y_prob_test = lgbm_best_model.predict_proba(x_full)[:, 1]\n\n    lgbm_auc_score_test = round(roc_auc_score(y_full,y_prob_test),4)\n\n    _,recall_test,f1_score_test,_ = precision_recall_fscore_support(y_full,y_pred_test)\n    lgbm_f1_score_test = round(f1_score_test[1],4)\n    lgbm_recall_test = round(recall_test[1],4)\n\n    lgbm_avg_prec_test = round(average_precision_score(y_full,y_pred_test),4)\n\n    end_time = time.time()\n    lgbm_fit_time = round((end_time - init_time)\/60,2)\n    print(f\"LGBM done in {lgbm_fit_time} minutes\")\n    \n    \n    ###############     Model comparison table     ###############\n    \n    \n    print(\n    tabulate(\n        [\n            [\"Model\", \"F1-score\", \"Recall\", \"AUC\", \"Avg Precision\"],\n            [\n                \"Logistic Regression\",\n                lr_f1_score_test,\n                lr_recall_test,\n                lr_auc_score_test,\n                lr_avg_prec_test,          \n            ],\n            [\n                \"Extra Trees\",\n                xt_f1_score_test,\n                xt_recall_test,\n                xt_auc_score_test,\n                xt_avg_prec_test,\n            ],\n            [\n                \"LGBM\",\n                lgbm_f1_score_test,\n                lgbm_recall_test,\n                lgbm_auc_score_test,\n                lgbm_avg_prec_test\n            ],\n        ]\n    )\n)\n    \n    return lr_best_model, xt_best_model, lgbm_best_model","232e977d":"# plots ROC AUC curve\ndef roc_auc_plot(y_test, y_prob):\n  \n  # get roc\/auc info\n  fpr = dict()\n  tpr = dict()\n  fpr, tpr, _ = roc_curve(y_test, y_prob)\n  roc_auc = dict()\n  roc_auc = round(auc(fpr, tpr),3)\n\n  # make the plot\n  fig = plt.figure(figsize=(10,10))\n  plt.plot([0, 1], [0, 1], 'k--')\n  plt.xlim([-0.05, 1.0])\n  plt.ylim([0.0, 1.05])\n  plt.xlabel('False Positive Rate')\n  plt.ylabel('True Positive Rate')\n  plt.grid(True)\n  plt.plot(fpr, tpr, label='AUC = {0}'.format(roc_auc))        \n  plt.legend(loc=\"lower right\", shadow=True, fancybox =True)","5eecbce5":"# function to transform predict_proba values for Tree based models, by using Logistic Regression (based on https:\/\/gdmarmerola.github.io\/probability-calibration\/)\n\ndef lr_proba(model,df):\n    \n    features = df.columns.to_list()\n    features.remove('next_period_ICU')\n\n    X=df[features]\n    y=df['next_period_ICU']\n    x_id=df.index.values\n\n    if str(model)[:3] == 'LGB':\n        leaves = model.predict(X,pred_leaf = True)\n    else:\n        # then, we apply the model to the data in order to get the leave indexes\n        leaves = model.apply(X)\n        \n    encoder = OneHotEncoder()\n    leaves_encoded = encoder.fit_transform(leaves)\n\n    # parameters obtained via random search\n    lr_params = {'solver':'sag',\n                 'C': 0.001756\t,\n                 'fit_intercept': False}\n\n    lr = LogisticRegression(**lr_params)\n    lr.fit(leaves_encoded, y)\n\n    if str(model)[:3] == 'LGB':\n        leaves = model.predict(X,pred_leaf = True)\n    else:\n        # then, we apply the model to the data in order to get the leave indexes\n        leaves = model.apply(X)\n\n    # then, we one-hot encode the leave indexes so we can use them in the logistic regression\n    leaves_encoded = encoder.transform(leaves)\n\n    # and fit it to the encoded leaves\n    y_hat = lr.predict_proba(leaves_encoded)\n\n    # retuning probabilities\n    df_yhat = pd.DataFrame(y_hat)\n    df_xid = pd.DataFrame(x_id)\n    df_xid.columns = ['id']\n    \n    df_mix = df_xid.merge(df_yhat,left_index = True, right_index = True)\n    df_mix.index = df_mix['id']\n    df_mix.drop(columns=['id'],inplace=True)\n    \n    return df_mix","a690076a":"pd.set_option('display.max_columns', None)\ndf = pd.read_excel(\"\/kaggle\/input\/covid19\/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx\")\ndf.head()","87c3d0d0":"df_raw = df.copy()","dc97293e":"# Adding new features based on features used by hospital\n\ndf_raw[\"BLOODPRESSURE_ARTERIAL_MEAN\"] = (df_raw['BLOODPRESSURE_SISTOLIC_MEAN'] + 2*df_raw['BLOODPRESSURE_DIASTOLIC_MEAN'])\/3\n \ndf_raw[\"NEUTROPHILES\/LINFOCITOS\"] = df_raw['NEUTROPHILES_MEAN']\/df_raw['LINFOCITOS_MEAN']\n\ndf_raw[\"GASO\"] = df_raw.groupby(\"PATIENT_VISIT_IDENTIFIER\").P02_ARTERIAL_MEAN.apply(lambda x: x.fillna(method='ffill'))\ndf_raw[\"GASO\"] = (~df_raw[\"GASO\"].isna()).astype(int)","40d81a82":"df_raw.shape","8886dedc":"missingno.matrix(df_raw)\nplt.show()","5d59e222":"#####  removing when patient was sent to the ICU in the first window\n\nremove_patients = df_raw.query(\"WINDOW == '0-2' and ICU == 1\")['PATIENT_VISIT_IDENTIFIER'].to_list()\n\ndf_raw = df_raw.query(\"PATIENT_VISIT_IDENTIFIER not in @remove_patients\")\ndf_raw = df_raw.reset_index(drop=True)\n\n# making sure there are no spaces in column names\ndf_raw.columns = df_raw.columns.map(lambda x: x.strip())","1bc1243c":"# removed 32 patients that were sent to the ICU on during the first window (0-2 hours)\n\ndf_raw.shape","71a42c9b":"# creating list with float features\n\nnew_floats = ['BLOODPRESSURE_ARTERIAL_MEAN','NEUTROPHILES\/LINFOCITOS']\nfloat_features_columns = df.iloc[:,13:-2].columns.to_list()\nfloat_features_columns = float_features_columns + new_floats\n\n# creating list with cat features\n\nnew_cat = ['GASO']\ncat_features_columns = df.iloc[:,:13].columns.to_list()\ncat_features_columns = cat_features_columns + new_cat\n\n# creating list with outputs\noutputs_columns = df.iloc[:,-2:].columns.to_list()","2eed569c":"# in order not to use ICU rows to do a backfill, created a df with no ICU rows in order to do the backfill\ndf_no_icu = df_raw.query(\"ICU != 1.0\")\n\nfloat_features_no_icu = df_no_icu.groupby('PATIENT_VISIT_IDENTIFIER',as_index=False)[float_features_columns].fillna(method='bfill').fillna(method='ffill')\ncat_features_no_icu = df_no_icu.groupby('PATIENT_VISIT_IDENTIFIER',as_index=False)[cat_features_columns].fillna(method='bfill').fillna(method='ffill')\noutput_no_icu = df_no_icu[outputs_columns]\n\ndf_no_icu_concat = pd.concat([cat_features_no_icu,float_features_no_icu,output_no_icu], ignore_index=True, axis=1)\nnew_headers = cat_features_columns + float_features_columns + outputs_columns\ndf_no_icu_concat.columns = new_headers\ndf_no_icu_concat.shape","57539707":"# creating df with first row when Patient was sent to the ICU\ndf_icu = df_raw.query(\"ICU == 1.0\").reset_index()\ndf_icu = df_icu.groupby('PATIENT_VISIT_IDENTIFIER').first().reset_index()\n\nfloat_features_icu = df_icu.groupby('PATIENT_VISIT_IDENTIFIER',as_index=False)[float_features_columns].fillna(method='bfill').fillna(method='ffill')\nfloat_features_icu.index = df_icu['index']\ncat_features_icu = df_icu.groupby('PATIENT_VISIT_IDENTIFIER',as_index=False)[cat_features_columns].fillna(method='bfill').fillna(method='ffill')\ncat_features_icu.index = df_icu['index']\noutput_icu = df_icu[outputs_columns]\noutput_icu.index = df_icu['index']\n\ndf_icu.drop(columns=['index'],inplace=True)\ndf_icu_concat = pd.concat([cat_features_icu,float_features_icu,output_icu], ignore_index=True, axis=1)\ndf_icu_concat.columns = new_headers\ndf_icu_concat.shape","d7c3f4e0":"# concatenating ICU and no ICU dataframes\ndf_concat = pd.concat([df_no_icu_concat,df_icu_concat], ignore_index=False, axis=0)\ndf_concat = df_concat.sort_index()\ndf_concat.shape","4a862a6f":"# transforming categorical data to dummies\ndf_dummies = df_concat[['PATIENT_VISIT_IDENTIFIER','AGE_PERCENTIL']].copy()\ndf_dummies = pd.get_dummies(df_dummies)\ndf_dummies = df_dummies.drop_duplicates()\n\n# joining new dummy features\ndf_concat = df_concat.drop(columns=['AGE_PERCENTIL'])\ndf_concat = df_concat.merge(df_dummies,left_on = 'PATIENT_VISIT_IDENTIFIER',right_on = 'PATIENT_VISIT_IDENTIFIER')","91879d74":"# checking again visually for gaps in data\nmissingno.matrix(df_concat)\nplt.show()","c8133df5":"# There are no NULL values in df\ndf_concat.columns[df_concat.isna().any()].tolist()","77764f4f":"# in order to remove columns with no variance, the second position of a value_counts will be searched. When no number returns, it means the feature has only one value\ndrop_columns_no_variance = []\nfor x in df_concat.columns:\n    try :\n        has_variance = df_concat[x].value_counts().to_list()[1]\n    except Exception:\n        drop_columns_no_variance.append(x)\n        continue","69c3abe8":"len(drop_columns_no_variance)","d62edc9a":"# there are 36 values that have no variance and will be removed\ndf_concat.drop(columns=drop_columns_no_variance,inplace=True)\ndf_concat.shape","05375c66":"df_concat.info()","5001700c":"# highly or perfectly correlated features should be removed. In order to do that, I checked tbe number of times a feature had a correlation of 1 with another one. Then I removed N-1 oif those features.\n\ncorrelation_mat = df_concat.corr()\ncorrelation_mat","59285a10":"# checking which features have a perfect correlation more than once, which implies it is perfectly correlated with other features\ndrop_columns_repeated = []\nfor x in correlation_mat.columns:\n    sum_perfect_correlation = correlation_mat[x].value_counts()[1]\n    if sum_perfect_correlation>1:\n        drop_columns_repeated.append(x)\n    else:\n        pass\n\n# since there are 144 features that fall into that category, a list will be created in order to pick only one of those for features in order for it to remain\nfeature_reduction = np.arange(0, 143, 4)\nfeature_reduction = feature_reduction.tolist()\n\nkeep_features_list = []\nfor x in feature_reduction:\n    keep_feature_index = drop_columns_repeated[x]\n    keep_features_list.append(keep_feature_index)\n    \nrepeated_columns_drop = [x for x in drop_columns_repeated if x not in keep_features_list]","15b4fb3b":"df_concat_clean = df_concat.copy()\ndf_concat_clean = df_concat_clean.drop(columns=repeated_columns_drop)\ndf_concat_clean.shape","049a59ec":"# checking if there are still perfectly correlated features\ncorrelation_mat_clean = df_concat_clean.corr()\n\ndrop_columns_repeated_clean = []\nfor x in correlation_mat_clean.columns:\n    sum_perfect_correlation = correlation_mat_clean[x].value_counts()[1]\n    if sum_perfect_correlation>1:\n        drop_columns_repeated_clean.append(x)\n    else:\n        pass\n\nlen(drop_columns_repeated_clean)","34da7986":"min_threshold = 0.05\nmax_threshold = 0.90\n\nkeep_features = correlation_mat_clean[((correlation_mat_clean['ICU']>=min_threshold) & (correlation_mat_clean['ICU']<=max_threshold)) | ((correlation_mat_clean['ICU']<=-min_threshold)) & (correlation_mat_clean['ICU']>=-max_threshold)]['ICU'].index.to_list()\nadd_icu_window = ['WINDOW','ICU']\nadd_patient_id = ['PATIENT_VISIT_IDENTIFIER']\nkeep_features = add_patient_id + keep_features + add_icu_window","ccc71ae9":"df_best_features = df_concat_clean.copy()\ndf_best_features = df_best_features[keep_features]\ndf_best_features.shape","7e73d30d":"# with a clean database, we can plot the correlation heatmap\nplt.figure(figsize=(20,14))\ncorrelation_mat = df_best_features.corr()\n\nsns.heatmap(correlation_mat)\n\nplt.show()","048efd35":"# creating dataframes for each window, with a feature indicating whether the Patient was sent to the ICU on the next window\ndf_first_window,df_second_window,df_third_window,df_fourth_window = window_df_creation(df_best_features)","83279584":"print(df_first_window['next_period_ICU'].value_counts())\nprint(f\"\\nShape {df_first_window.shape}\")","ed11068c":"print(df_second_window['next_period_ICU'].value_counts())\nprint(f\"\\nShape {df_second_window.shape}\")","52134a98":"print(df_third_window['next_period_ICU'].value_counts())\nprint(f\"\\nShape {df_third_window.shape}\")","f182ba13":"print(df_fourth_window['next_period_ICU'].value_counts())\nprint(f\"\\nShape {df_fourth_window.shape}\")","17122c3e":"#     train test split\n_, _, _, _, x_full, y_full = train_test(df_first_window)  \n\n\n\n###############     Logistic Regression     ###############\n\n# init_time = time.time()\n\n# ###### Hyperoptimization ###### --> after discovering the best hyperparameters, we do not need to keep executing that part of the code\n# lr_params = {\n#     'C': np.random.uniform(low=0.0, high=1.0, size=1000),\n#     'penalty': ['l1', 'l2'],\n#     'max_iter': np.random.uniform(low=2000, high=10000, size=1000),\n# }\n\n# lr_random_search_model = RandomizedSearchCV(\n#     estimator=LogisticRegression(\n#         fit_intercept=True,\n#         class_weight='balanced',\n#         random_state=42\n#     ), \n#     param_distributions=lr_params,\n#     scoring='f1',\n#     cv=4,\n#     n_iter=2000,\n#     n_jobs=-1,\n#     random_state=42\n# )\n\n# lr_random_search_model.fit(x_full, y_full)\n# lr_best_model = lr_random_search_model.best_estimator_\n\n\n# cv_scores = cross_validate(\n#                             lr_best_model, # best_estimator da RandomSearchCV\n#                             x_full,\n#                             y_full,\n#                             cv=4,\n#                             scoring=('f1', 'average_precision', 'roc_auc','recall'),\n#                             return_train_score=True\n#                             )\n\n# f1_score_train_cv =  round(np.mean(cv_scores['train_f1']),3)\n# recall_train_cv =  round(np.mean(cv_scores['train_recall']),3)\n# auc_score_train_cv =  round(np.mean(cv_scores['train_roc_auc']),3)\n# avg_prec_train_cv =  round(np.mean(cv_scores['train_average_precision']),3)\n\n# lr_f1_score_test_cv = round(np.mean(cv_scores['test_f1']),3)\n# lr_recall_test_cv = round(np.mean(cv_scores['test_recall']),3)\n# lr_auc_score_test_cv = round(np.mean(cv_scores['test_roc_auc']),3)\n# lr_avg_prec_test_cv = round(np.mean(cv_scores['test_average_precision']),3)\n\n\n# ###### Tabela comparativa ######\n# print(\n#     tabulate(\n#         [\n#             [\"Logistic Regression\",\"F1 Score\", \"Recall\", \"AUC\", \"Avg Precision\"],\n#             [\n#                 \"Hyperopt Train\",\n#                 f1_score_train_cv,\n#                 recall_train_cv,\n#                 auc_score_train_cv,\n#                 avg_prec_train_cv,\n#             ],\n#             [\n#                 \"Hyperopt Test\",\n#                 lr_f1_score_test,\n#                 lr_recall_test,\n#                 lr_auc_score_test,\n#                 lr_avg_prec_test,\n#             ],\n#         ]\n#     )\n# )\n\n# end_time = time.time()\n# lr_fit_time = round((end_time - init_time),2)\n\n# print(f\"Logistic Regression done in {lr_fit_time} seconds\")","c21813e1":"# crossval results\n\n# -------------------  --------  ------  -----  -------------\n# Logistic Regression  F1 Score  Recall  AUC    Avg Precision\n# Hyperopt Train       0.433     0.814   0.897  0.469\n# Hyperopt Test        0.309     0.619   0.675  0.245\n# -------------------  --------  ------  -----  -------------\n# Logistic Regression done in 271.84 seconds","92b69dcf":"###############     Logistic Regression     ###############\n\nlr_best_model = LogisticRegression(C=0.2133298308566437, class_weight='balanced',\n                   max_iter=8461.978386670755, random_state=42)\n\nlr_best_model.fit(x_full, y_full)\n\n###### Avaliando hyperopt - test ######\ny_pred_test = lr_best_model.predict(x_full)\ny_prob_test = lr_best_model.predict_proba(x_full)[:, 1]\n\nlr_auc_score_test = round(roc_auc_score(y_full,y_prob_test),4)\n\n_,recall_test,f1_score_test,_ = precision_recall_fscore_support(y_full,y_pred_test)\nlr_f1_score_test = round(f1_score_test[1],4)\nlr_recall_test = round(recall_test[1],4)\n\nlr_avg_prec_test = round(average_precision_score(y_full,y_pred_test),4)","317a1c76":"# ###############     Extra Trees     ############### \n    \n# init_time = time.time()\n\n\n# # Hyperparameter grid\n# param_grid = {\n#     'n_estimators': np.linspace(1500, 3000).astype(int),\n#     'max_depth': list(np.linspace(2, 4).astype(int)),\n#     'max_features': ['auto', 'sqrt'],\n#     'max_samples': list(np.arange(0.5, 1, 0.1)),\n#     'min_samples_split': [5, 10, 20],\n#     'bootstrap': [True, False]\n# }\n\n# # Estimator for use in random search\n# estimator = ExtraTreesClassifier(class_weight='balanced',random_state=42)\n\n# # Create the random search model\n# xtrees_model = RandomizedSearchCV(estimator, param_grid, n_jobs = -1, \n#                         scoring = 'f1', cv = 3, \n#                         n_iter = 100, verbose = 0,\n#                         random_state=42)\n\n# # Fit \n# xtrees_model.fit(x_full, y_full)\n# xt_best_model = xtrees_model.best_estimator_\n\n\n# cv_scores = cross_validate(\n#                             xt_best_model, # best_estimator da RandomSearchCV\n#                             x_full,\n#                             y_full,\n#                             cv=4,\n#                             scoring=('f1', 'average_precision', 'roc_auc','recall'),\n#                             return_train_score=True\n#                             )\n\n# f1_score_train_cv =  round(np.mean(cv_scores['train_f1']),3)\n# recall_train_cv =  round(np.mean(cv_scores['train_recall']),3)\n# auc_score_train_cv =  round(np.mean(cv_scores['train_roc_auc']),3)\n# avg_prec_train_cv =  round(np.mean(cv_scores['train_average_precision']),3)\n\n# xt_f1_score_test_cv = round(np.mean(cv_scores['test_f1']),3)\n# xt_recall_test_cv = round(np.mean(cv_scores['test_recall']),3)\n# xt_auc_score_test_cv = round(np.mean(cv_scores['test_roc_auc']),3)\n# xt_avg_prec_test_cv = round(np.mean(cv_scores['test_average_precision']),3)\n\n\n# ###### Tabela comparativa ######\n# print(\n#     tabulate(\n#         [\n#             [\"Extra Trees\",\"F1 Score\", \"Recall\", \"AUC\", \"Avg Precision\"],\n#             [\n#                 \"Hyperopt Train\",\n#                 f1_score_train,\n#                 recall_train,\n#                 auc_score_train,\n#                 avg_prec_train,\n#             ],\n#             [\n#                 \"Hyperopt Test\",\n#                 xt_f1_score_test_cv,\n#                 xt_recall_test_cv,\n#                 xt_auc_score_test_cv,\n#                 xt_avg_prec_test_cv,\n#             ],\n#         ]\n#     )\n# )\n\n# end_time = time.time()\n# xt_fit_time = round((end_time - init_time),2)\n# print(f\"Extra Trees done in {xt_fit_time} seconds\")","28548f68":"# crossval results\n\n# --------------  --------  ------  -----  -------------\n# Extra Trees     F1 Score  Recall  AUC    Avg Precision\n# Hyperopt Train  0.8734    0.8961  0.969  0.7984\n# Hyperopt Test   0.273     0.292   0.7    0.263\n# --------------  --------  ------  -----  -------------\n# Extra Trees done in 475.69 seconds","814fee1a":"###############     Extra Trees     ###############\n\nxt_best_model = ExtraTreesClassifier(class_weight='balanced', max_depth=4, max_features='sqrt',\n                     max_samples=0.6, min_samples_split=20, n_estimators=1591,\n                     random_state=42)\n\nxt_best_model.fit(x_full, y_full)\n\n###### Avaliando hyperopt - test ######\ny_pred_test = xt_best_model.predict(x_full)\ny_prob_test = xt_best_model.predict_proba(x_full)[:, 1]\n\nxt_auc_score_test_1 = round(roc_auc_score(y_full,y_prob_test),4)\n\n_,recall_test,f1_score_test,_ = precision_recall_fscore_support(y_full,y_pred_test)\nxt_f1_score_test_1 = round(f1_score_test[1],4)\nxt_recall_test_1 = round(recall_test[1],4)\n\nxt_avg_prec_test_1 = round(average_precision_score(y_full,y_pred_test),4)","6bc86b5c":"# init_time = time.time()\n\n\n# # Hyperparameter grid\n# param_grid = {\"n_estimators\": np.linspace(2, 5).astype(int),\n#               \"boosting_type\": [\"gbdt\",\"dart\",\"goss\"],\n#               \"subsample\": list(np.arange(0.5, 1, 0.2)),\n#               \"colsample_bytree\": list(np.arange(0.5, 0.8, 0.1)),\n#               \"objective\": [\"binary\",\"multiclass\"],\n#               \"alpha\": list(np.arange(0, 0.6, 0.2)),\n#               \"max_depth\": [2,3,4,5,6]\n#              }\n\n# # Estimator for use in random search\n# estimator = LGBMClassifier(class_weight='balanced',random_state=42)\n\n# # Create the random search model\n# lgbm = RandomizedSearchCV(estimator, param_grid, n_jobs = -1, \n#                         scoring = 'f1', cv = 5, \n#                         n_iter = 100, verbose = 0,\n#                         random_state=42)\n\n# # Fit \n# lgbm.fit(x_full, y_full)\n# lgbm_best_model = lgbm.best_estimator_\n\n# cv_scores = cross_validate(\n#                             lr_best_model, # best_estimator da RandomSearchCV\n#                             x_full,\n#                             y_full,\n#                             cv=5,\n#                             scoring=('f1', 'average_precision', 'roc_auc','recall'),\n#                             return_train_score=True\n#                             )\n\n# f1_score_train_cv =  round(np.mean(cv_scores['train_f1']),3)\n# recall_train_cv =  round(np.mean(cv_scores['train_recall']),3)\n# auc_score_train_cv =  round(np.mean(cv_scores['train_roc_auc']),3)\n# avg_prec_train_cv =  round(np.mean(cv_scores['train_average_precision']),3)\n\n# lgbm_f1_score_test_cv = round(np.mean(cv_scores['test_f1']),3)\n# lgbm_recall_test_cv = round(np.mean(cv_scores['test_recall']),3)\n# lgbm_auc_score_test_cv = round(np.mean(cv_scores['test_roc_auc']),3)\n# lgbm_avg_prec_test_cv = round(np.mean(cv_scores['test_average_precision']),3)\n\n\n# ###### Tabela comparativa ######\n# print(\n#     tabulate(\n#         [\n#             [\"\",\"F1 Score\", \"Recall\", \"AUC\", \"Avg Precision\"],\n#             [\n#                 \"Hyperopt Train\",\n#                 f1_score_train,\n#                 recall_train,\n#                 auc_score_train,\n#                 avg_prec_train,\n#             ],\n#             [\n#                 \"Hyperopt Test\",\n#                 lgbm_f1_score_test_cv,\n#                 lgbm_recall_test_cv,\n#                 lgbm_auc_score_test_cv,\n#                 lgbm_avg_prec_test_cv,\n#             ],\n#         ]\n#     )\n# )\n\n# end_time = time.time()\n# lgbm_fit_time = round(end_time - init_time,3)\n# print(f\"LGBM done in {lgbm_fit_time} seconds\")\n# print(lgbm_best_model)","a2a6528d":"# crossval results\n\n# --------------  --------  ------  -----  -------------\n#                 F1 Score  Recall  AUC    Avg Precision\n# Hyperopt Train  0.8734    0.8961  0.969  0.7984\n# Hyperopt Test   0.313     0.593   0.729  0.33\n# --------------  --------  ------  -----  -------------","b1b20bc3":"lgbm_best_model = LGBMClassifier(alpha=0.4, class_weight='balanced',\n               colsample_bytree=0.7999999999999999, max_depth=5, n_estimators=4,\n               objective='binary', random_state=42,\n               subsample=0.8999999999999999)\n\nlgbm_best_model.fit(x_full, y_full)\n\n###### Avaliando hyperopt - test ######\ny_pred_test = lgbm_best_model.predict(x_full)\ny_prob_test = lgbm_best_model.predict_proba(x_full)[:, 1]\n\nlgbm_auc_score_test = round(roc_auc_score(y_full,y_prob_test),4)\n\n_,recall_test,f1_score_test,_ = precision_recall_fscore_support(y_full,y_pred_test)\nlgbm_f1_score_test = round(f1_score_test[1],4)\nlgbm_recall_test = round(recall_test[1],4)\n\nlgbm_avg_prec_test = round(average_precision_score(y_full,y_pred_test),4)","9fb14d39":"###############     Model comparison table     ###############\n\n\nprint(\n    tabulate(\n        [\n            [\"Model\", \"F1-score\", \"Recall\", \"AUC\", \"Avg Precision\"],\n            [\n                \"Logistic Regression\",\n                lr_f1_score_test,\n                lr_recall_test,\n                lr_auc_score_test,\n                lr_avg_prec_test,          \n            ],\n            [\n                \"Extra Trees\",\n                xt_f1_score_test_1,\n                xt_recall_test_1,\n                xt_auc_score_test_1,\n                xt_avg_prec_test_1,\n            ],\n            [\n                \"LGBM\",\n                lgbm_f1_score_test,\n                lgbm_recall_test,\n                lgbm_auc_score_test,\n                lgbm_avg_prec_test\n            ],\n        ]\n    )\n)\n\nbest_model_1 = xt_best_model\nbest_model_1","5fcaa550":"#     train test split\n_, _, _, _, x_full, y_full = train_test(df_second_window)  \n\n\n\n# ###############     Logistic Regression     ###############\n\n# init_time = time.time()\n\n# ###### Hyperoptimization ###### --> after discovering the best hyperparameters, we do not need to keep executing that part of the code\n# lr_params = {\n#     'C': np.random.uniform(low=0.0, high=1.0, size=1000),\n#     'penalty': ['l1', 'l2'],\n#     'max_iter': np.random.uniform(low=2000, high=10000, size=1000),\n# }\n\n# lr_random_search_model = RandomizedSearchCV(\n#     estimator=LogisticRegression(\n#         fit_intercept=True,\n#         class_weight='balanced',\n#         random_state=42\n#     ), \n#     param_distributions=lr_params,\n#     scoring='f1',\n#     cv=4,\n#     n_iter=2000,\n#     n_jobs=-1,\n#     random_state=42\n# )\n\n# lr_random_search_model.fit(x_full, y_full)\n# lr_best_model = lr_random_search_model.best_estimator_\n\n\n# cv_scores = cross_validate(\n#                             lr_best_model, # best_estimator da RandomSearchCV\n#                             x_full,\n#                             y_full,\n#                             cv=4,\n#                             scoring=('f1', 'average_precision', 'roc_auc','recall'),\n#                             return_train_score=True\n#                             )\n\n# f1_score_train_cv =  round(np.mean(cv_scores['train_f1']),3)\n# recall_train_cv =  round(np.mean(cv_scores['train_recall']),3)\n# auc_score_train_cv =  round(np.mean(cv_scores['train_roc_auc']),3)\n# avg_prec_train_cv =  round(np.mean(cv_scores['train_average_precision']),3)\n\n# lr_f1_score_test_cv = round(np.mean(cv_scores['test_f1']),3)\n# lr_recall_test_cv = round(np.mean(cv_scores['test_recall']),3)\n# lr_auc_score_test_cv = round(np.mean(cv_scores['test_roc_auc']),3)\n# lr_avg_prec_test_cv = round(np.mean(cv_scores['test_average_precision']),3)\n\n\n# ###### Tabela comparativa ######\n# print(\n#     tabulate(\n#         [\n#             [\"Logistic Regression\",\"F1 Score\", \"Recall\", \"AUC\", \"Avg Precision\"],\n#             [\n#                 \"Hyperopt Train\",\n#                 f1_score_train_cv,\n#                 recall_train_cv,\n#                 auc_score_train_cv,\n#                 avg_prec_train_cv,\n#             ],\n#             [\n#                 \"Hyperopt Test\",\n#                 lr_f1_score_test_cv,\n#                 lr_recall_test_cv,\n#                 lr_auc_score_test_cv,\n#                 lr_avg_prec_test_cv,\n#             ],\n#         ]\n#     )\n# )\n\n# end_time = time.time()\n# lr_fit_time = round((end_time - init_time),2)\n\n# print(f\"Logistic Regression done in {lr_fit_time} seconds\")\n# print(lr_best_model)","d4d5ce34":"# crossval results\n\n# -------------------  --------  ------  -----  -------------\n# Logistic Regression  F1 Score  Recall  AUC    Avg Precision\n# Hyperopt Train       0.592     0.883   0.93   0.716\n# Hyperopt Test        0.393     0.6     0.792  0.452\n# -------------------  --------  ------  -----  -------------\n# Logistic Regression done in 187.67 seconds","84d4c1c7":"lr_best_model = LogisticRegression(C=0.8343348698861569, class_weight='balanced',\n                   max_iter=4431.907052952959, random_state=42)\n\nlr_best_model.fit(x_full, y_full)\n\n###### Avaliando hyperopt - test ######\ny_pred_test = lr_best_model.predict(x_full)\ny_prob_test = lr_best_model.predict_proba(x_full)[:, 1]\n\nlr_auc_score_test = round(roc_auc_score(y_full,y_prob_test),4)\n\n_,recall_test,f1_score_test,_ = precision_recall_fscore_support(y_full,y_pred_test)\nlr_f1_score_test = round(f1_score_test[1],4)\nlr_recall_test = round(recall_test[1],4)\n\nlr_avg_prec_test = round(average_precision_score(y_full,y_pred_test),4)","1c85f1ed":"# ###############     Extra Trees     ############### \n    \n# init_time = time.time()\n\n\n# # Hyperparameter grid\n# param_grid = {\n#     'n_estimators': np.linspace(1500, 3000).astype(int),\n#     'max_depth': list(np.linspace(2, 4).astype(int)),\n#     'max_features': ['auto', 'sqrt'],\n#     'max_samples': list(np.arange(0.5, 1, 0.1)),\n#     'min_samples_split': [5, 10, 20],\n#     'bootstrap': [True, False]\n# }\n\n# # Estimator for use in random search\n# estimator = ExtraTreesClassifier(class_weight='balanced',random_state=42)\n\n# # Create the random search model\n# xtrees_model = RandomizedSearchCV(estimator, param_grid, n_jobs = -1, \n#                         scoring = 'f1', cv = 3, \n#                         n_iter = 100, verbose = 0,\n#                         random_state=42)\n\n# # Fit \n# xtrees_model.fit(x_full, y_full)\n# xt_best_model = xtrees_model.best_estimator_\n\n\n# cv_scores = cross_validate(\n#                             xt_best_model, # best_estimator da RandomSearchCV\n#                             x_full,\n#                             y_full,\n#                             cv=4,\n#                             scoring=('f1', 'average_precision', 'roc_auc','recall'),\n#                             return_train_score=True\n#                             )\n\n# f1_score_train_cv =  round(np.mean(cv_scores['train_f1']),3)\n# recall_train_cv =  round(np.mean(cv_scores['train_recall']),3)\n# auc_score_train_cv =  round(np.mean(cv_scores['train_roc_auc']),3)\n# avg_prec_train_cv =  round(np.mean(cv_scores['train_average_precision']),3)\n\n# xt_f1_score_test_cv = round(np.mean(cv_scores['test_f1']),3)\n# xt_recall_test_cv = round(np.mean(cv_scores['test_recall']),3)\n# xt_auc_score_test_cv = round(np.mean(cv_scores['test_roc_auc']),3)\n# xt_avg_prec_test_cv = round(np.mean(cv_scores['test_average_precision']),3)\n\n\n# ###### Tabela comparativa ######\n# print(\n#     tabulate(\n#         [\n#             [\"Extra Trees\",\"F1 Score\", \"Recall\", \"AUC\", \"Avg Precision\"],\n#             [\n#                 \"Hyperopt Train\",\n#                 f1_score_train,\n#                 recall_train,\n#                 auc_score_train,\n#                 avg_prec_train,\n#             ],\n#             [\n#                 \"Hyperopt Test\",\n#                 xt_f1_score_test_cv,\n#                 xt_recall_test_cv,\n#                 xt_auc_score_test_cv,\n#                 xt_avg_prec_test_cv,\n#             ],\n#         ]\n#     )\n# )\n\n# end_time = time.time()\n# xt_fit_time = round((end_time - init_time),2)\n# print(f\"Extra Trees done in {xt_fit_time} seconds\")\n# print(xt_best_model)","6883bf5d":"# crossval results \n\n# --------------  --------  ------  ------  -------------\n# Extra Trees     F1 Score  Recall  AUC     Avg Precision\n# Hyperopt Train  0.6154    0.7407  0.9655  0.4097\n# Hyperopt Test   0.288     0.2     0.804   0.461\n# --------------  --------  ------  ------  -------------","912e5509":"###############     Extra Trees     ###############\n\nxt_best_model = ExtraTreesClassifier(bootstrap=True, class_weight='balanced', max_depth=3,\n                     max_samples=0.5, min_samples_split=5, n_estimators=1653,\n                     random_state=42)\n\nxt_best_model.fit(x_full, y_full)\n\n###### Avaliando hyperopt - test ######\ny_pred_test = xt_best_model.predict(x_full)\ny_prob_test = xt_best_model.predict_proba(x_full)[:, 1]\n\nxt_auc_score_test = round(roc_auc_score(y_full,y_prob_test),4)\n\n_,recall_test,f1_score_test,_ = precision_recall_fscore_support(y_full,y_pred_test)\nxt_f1_score_test = round(f1_score_test[1],4)\nxt_recall_test = round(recall_test[1],4)\n\nxt_avg_prec_test = round(average_precision_score(y_full,y_pred_test),4)","d9b7f759":"# ##############     LGBM     ###############\n\n# init_time = time.time()\n\n\n# # Hyperparameter grid\n# param_grid = {\"n_estimators\": np.linspace(2, 5).astype(int),\n#               \"boosting_type\": [\"gbdt\",\"dart\",\"goss\"],\n#               \"subsample\": list(np.arange(0.5, 1, 0.2)),\n#               \"colsample_bytree\": list(np.arange(0.5, 0.8, 0.1)),\n#               \"objective\": [\"binary\",\"multiclass\"],\n#               \"alpha\": list(np.arange(0, 0.6, 0.2)),\n#               \"max_depth\": [2,3,4,5,6],\n#               \"num_leaves\": np.linspace(20, 40).astype(int),\n#              }\n\n# # Estimator for use in random search\n# estimator = LGBMClassifier(class_weight='balanced',random_state=42)\n\n# # Create the random search model\n# lgbm = RandomizedSearchCV(estimator, param_grid, n_jobs = -1, \n#                         scoring = 'f1', cv = 5, \n#                         n_iter = 100, verbose = 0,\n#                         random_state=42)\n\n# # Fit \n# lgbm.fit(x_full, y_full)\n# lgbm_best_model = lgbm.best_estimator_\n\n# cv_scores = cross_validate(\n#                             lr_best_model, # best_estimator da RandomSearchCV\n#                             x_full,\n#                             y_full,\n#                             cv=5,\n#                             scoring=('f1', 'average_precision', 'roc_auc','recall'),\n#                             return_train_score=True\n#                             )\n\n# f1_score_train_cv =  round(np.mean(cv_scores['train_f1']),3)\n# recall_train_cv =  round(np.mean(cv_scores['train_recall']),3)\n# auc_score_train_cv =  round(np.mean(cv_scores['train_roc_auc']),3)\n# avg_prec_train_cv =  round(np.mean(cv_scores['train_average_precision']),3)\n\n# lgbm_f1_score_test_cv = round(np.mean(cv_scores['test_f1']),3)\n# lgbm_recall_test_cv = round(np.mean(cv_scores['test_recall']),3)\n# lgbm_auc_score_test_cv = round(np.mean(cv_scores['test_roc_auc']),3)\n# lgbm_avg_prec_test_cv = round(np.mean(cv_scores['test_average_precision']),3)\n\n\n# ###### Tabela comparativa ######\n# print(\n#     tabulate(\n#         [\n#             [\"\",\"F1 Score\", \"Recall\", \"AUC\", \"Avg Precision\"],\n#             [\n#                 \"Hyperopt Train\",\n#                 f1_score_train,\n#                 recall_train,\n#                 auc_score_train,\n#                 avg_prec_train,\n#             ],\n#             [\n#                 \"Hyperopt Test\",\n#                 lgbm_f1_score_test_cv,\n#                 lgbm_recall_test_cv,\n#                 lgbm_auc_score_test_cv,\n#                 lgbm_avg_prec_test_cv,\n#             ],\n#         ]\n#     )\n# )\n\n# end_time = time.time()\n# lgbm_fit_time = round(end_time - init_time,3)\n# print(f\"LGBM done in {lgbm_fit_time} seconds\")\n# print(lgbm_best_model)","ae553fd0":"# crossval results\n\n# --------------  --------  ------  ------  -------------\n#                 F1 Score  Recall  AUC     Avg Precision\n# Hyperopt Train  0.6154    0.7407  0.9655  0.4097\n# Hyperopt Test   0.339     0.525   0.758   0.447\n# --------------  --------  ------  ------  -------------","2a1dfa2f":"###############     LGBM     ###############\n\nlgbm_best_model = LGBMClassifier(alpha=0.4, class_weight='balanced', colsample_bytree=0.5,\n               max_depth=6, n_estimators=4, num_leaves=28, objective='binary',\n               random_state=42, subsample=0.8999999999999999)\n\nlgbm_best_model.fit(x_full, y_full)\n\n###### Avaliando hyperopt - test ######\ny_pred_test = lgbm_best_model.predict(x_full)\ny_prob_test = lgbm_best_model.predict_proba(x_full)[:, 1]\n\nlgbm_auc_score_test_2 = round(roc_auc_score(y_full,y_prob_test),4)\n\n_,recall_test,f1_score_test,_ = precision_recall_fscore_support(y_full,y_pred_test)\nlgbm_f1_score_test_2 = round(f1_score_test[1],4)\nlgbm_recall_test_2 = round(recall_test[1],4)\n\nlgbm_avg_prec_test_2 = round(average_precision_score(y_full,y_pred_test),4)","eb201227":"###############     Model comparison table     ###############\n\n\nprint(\n    tabulate(\n        [\n            [\"Model\", \"F1-score\", \"Recall\", \"AUC\", \"Avg Precision\"],\n            [\n                \"Logistic Regression\",\n                lr_f1_score_test,\n                lr_recall_test,\n                lr_auc_score_test,\n                lr_avg_prec_test,          \n            ],\n            [\n                \"Extra Trees\",\n                xt_f1_score_test,\n                xt_recall_test,\n                xt_auc_score_test,\n                xt_avg_prec_test,\n            ],\n            [\n                \"LGBM\",\n                lgbm_f1_score_test_2,\n                lgbm_recall_test_2,\n                lgbm_auc_score_test_2,\n                lgbm_avg_prec_test_2\n            ],\n        ]\n    )\n)\n\n\nbest_model_2 = lgbm_best_model\nbest_model_2","83daaa84":"#     train test split\n_, _, _, _, x_full, y_full = train_test(df_third_window)  \n\n\n\n# ###############     Logistic Regression     ###############\n\n# init_time = time.time()\n\n# ###### Hyperoptimization ###### --> after discovering the best hyperparameters, we do not need to keep executing that part of the code\n# lr_params = {\n#     'C': np.random.uniform(low=0.0, high=1.0, size=1000),\n#     'penalty': ['l1', 'l2'],\n#     'max_iter': np.random.uniform(low=2000, high=10000, size=1000),\n# }\n\n# lr_random_search_model = RandomizedSearchCV(\n#     estimator=LogisticRegression(\n#         fit_intercept=True,\n#         class_weight='balanced',\n#         random_state=42\n#     ), \n#     param_distributions=lr_params,\n#     scoring='f1',\n#     cv=4,\n#     n_iter=2000,\n#     n_jobs=-1,\n#     random_state=42\n# )\n\n# lr_random_search_model.fit(x_full, y_full)\n# lr_best_model = lr_random_search_model.best_estimator_\n\n\n# cv_scores = cross_validate(\n#                             lr_best_model, # best_estimator da RandomSearchCV\n#                             x_full,\n#                             y_full,\n#                             cv=4,\n#                             scoring=('f1', 'average_precision', 'roc_auc','recall'),\n#                             return_train_score=True\n#                             )\n\n# f1_score_train_cv =  round(np.mean(cv_scores['train_f1']),3)\n# recall_train_cv =  round(np.mean(cv_scores['train_recall']),3)\n# auc_score_train_cv =  round(np.mean(cv_scores['train_roc_auc']),3)\n# avg_prec_train_cv =  round(np.mean(cv_scores['train_average_precision']),3)\n\n# lr_f1_score_test_cv = round(np.mean(cv_scores['test_f1']),3)\n# lr_recall_test_cv = round(np.mean(cv_scores['test_recall']),3)\n# lr_auc_score_test_cv = round(np.mean(cv_scores['test_roc_auc']),3)\n# lr_avg_prec_test_cv = round(np.mean(cv_scores['test_average_precision']),3)\n\n\n# ###### Tabela comparativa ######\n# print(\n#     tabulate(\n#         [\n#             [\"Logistic Regression\",\"F1 Score\", \"Recall\", \"AUC\", \"Avg Precision\"],\n#             [\n#                 \"Hyperopt Train\",\n#                 f1_score_train_cv,\n#                 recall_train_cv,\n#                 auc_score_train_cv,\n#                 avg_prec_train_cv,\n#             ],\n#             [\n#                 \"Hyperopt Test\",\n#                 lr_f1_score_test_cv,\n#                 lr_recall_test_cv,\n#                 lr_auc_score_test_cv,\n#                 lr_avg_prec_test_cv,\n#             ],\n#         ]\n#     )\n# )\n\n# end_time = time.time()\n# lr_fit_time = round((end_time - init_time),2)\n\n# print(f\"Logistic Regression done in {lr_fit_time} seconds\")\n# print(lr_best_model)","f4a2d7dc":"#  crossval results\n\n# -------------------  --------  ------  -----  -------------\n# Logistic Regression  F1 Score  Recall  AUC    Avg Precision\n# Hyperopt Train       0.285     0.666   0.711  0.25\n# Hyperopt Test        0.282     0.647   0.734  0.427\n# -------------------  --------  ------  -----  -------------","8285305c":"lr_best_model = LogisticRegression(C=0.009174855205852595, class_weight='balanced',\n                   max_iter=7681.345742769994, random_state=42)\n\nlr_best_model.fit(x_full, y_full)\n\n###### Avaliando hyperopt ######\ny_pred_test = lr_best_model.predict(x_full)\ny_prob_test = lr_best_model.predict_proba(x_full)[:, 1]\n\nlr_auc_score_test = round(roc_auc_score(y_full,y_prob_test),4)\n\n_,recall_test,f1_score_test,_ = precision_recall_fscore_support(y_full,y_pred_test)\nlr_f1_score_test = round(f1_score_test[1],4)\nlr_recall_test = round(recall_test[1],4)\n\nlr_avg_prec_test = round(average_precision_score(y_full,y_pred_test),4)","ed1bf328":"# ###############     Extra Trees     ############### \n    \n# init_time = time.time()\n\n\n# # Hyperparameter grid\n# param_grid = {\n#     'n_estimators': np.linspace(1500, 3000).astype(int),\n#     'max_depth': list(np.linspace(2, 4).astype(int)),\n#     'max_features': ['auto', 'sqrt'],\n#     'max_samples': list(np.arange(0.5, 1, 0.1)),\n#     'min_samples_split': [5, 10, 20],\n#     'bootstrap': [True, False]\n# }\n\n# # Estimator for use in random search\n# estimator = ExtraTreesClassifier(class_weight='balanced',random_state=42)\n\n# # Create the random search model\n# xtrees_model = RandomizedSearchCV(estimator, param_grid, n_jobs = -1, \n#                         scoring = 'f1', cv = 3, \n#                         n_iter = 100, verbose = 0,\n#                         random_state=42)\n\n# # Fit \n# xtrees_model.fit(x_full, y_full)\n# xt_best_model = xtrees_model.best_estimator_\n\n\n# cv_scores = cross_validate(\n#                             xt_best_model, # best_estimator da RandomSearchCV\n#                             x_full,\n#                             y_full,\n#                             cv=4,\n#                             scoring=('f1', 'average_precision', 'roc_auc','recall'),\n#                             return_train_score=True\n#                             )\n\n# f1_score_train_cv =  round(np.mean(cv_scores['train_f1']),3)\n# recall_train_cv =  round(np.mean(cv_scores['train_recall']),3)\n# auc_score_train_cv =  round(np.mean(cv_scores['train_roc_auc']),3)\n# avg_prec_train_cv =  round(np.mean(cv_scores['train_average_precision']),3)\n\n# xt_f1_score_test_cv = round(np.mean(cv_scores['test_f1']),3)\n# xt_recall_test_cv = round(np.mean(cv_scores['test_recall']),3)\n# xt_auc_score_test_cv = round(np.mean(cv_scores['test_roc_auc']),3)\n# xt_avg_prec_test_cv = round(np.mean(cv_scores['test_average_precision']),3)\n\n\n# ###### Tabela comparativa ######\n# print(\n#     tabulate(\n#         [\n#             [\"Extra Trees\",\"F1 Score\", \"Recall\", \"AUC\", \"Avg Precision\"],\n#             [\n#                 \"Hyperopt Train\",\n#                 f1_score_train,\n#                 recall_train,\n#                 auc_score_train,\n#                 avg_prec_train,\n#             ],\n#             [\n#                 \"Hyperopt Test\",\n#                 xt_f1_score_test_cv,\n#                 xt_recall_test_cv,\n#                 xt_auc_score_test_cv,\n#                 xt_avg_prec_test_cv,\n#             ],\n#         ]\n#     )\n# )\n\n# end_time = time.time()\n# xt_fit_time = round((end_time - init_time),2)\n# print(f\"Extra Trees done in {xt_fit_time} seconds\")\n# print(xt_best_model)","ba09698e":"# crossval results\n\n# --------------  --------  ------  ------  -------------\n# Extra Trees     F1 Score  Recall  AUC     Avg Precision\n# Hyperopt Train  0.6154    0.7407  0.9655  0.4097\n# Hyperopt Test   0.466     0.643   0.811   0.375\n# --------------  --------  ------  ------  -------------","01a90912":"###############     Extra Trees     ###############\n\nxt_best_model = ExtraTreesClassifier(class_weight='balanced', max_depth=3, max_features='sqrt',\n                     max_samples=0.5, min_samples_split=10, n_estimators=2632,\n                     random_state=42)\n\nxt_best_model.fit(x_full, y_full)\n\n###### Avaliando hyperopt - test ######\ny_pred_test = xt_best_model.predict(x_full)\ny_prob_test = xt_best_model.predict_proba(x_full)[:, 1]\n\nxt_auc_score_test_3 = round(roc_auc_score(y_full,y_prob_test),4)\n\n_,recall_test,f1_score_test,_ = precision_recall_fscore_support(y_full,y_pred_test)\nxt_f1_score_test_3 = round(f1_score_test[1],4)\nxt_recall_test_3 = round(recall_test[1],4)\n\nxt_avg_prec_test_3 = round(average_precision_score(y_full,y_pred_test),4)","64b35b56":"# ##############     LGBM     ###############\n\n# init_time = time.time()\n\n\n# # Hyperparameter grid\n# param_grid = {\"n_estimators\": np.linspace(2, 5).astype(int),\n#               \"boosting_type\": [\"gbdt\",\"dart\",\"goss\"],\n#               \"subsample\": list(np.arange(0.5, 1, 0.2)),\n#               \"colsample_bytree\": list(np.arange(0.5, 0.8, 0.1)),\n#               \"objective\": [\"binary\",\"multiclass\"],\n#               \"alpha\": list(np.arange(0, 0.6, 0.2)),\n#               \"max_depth\": [2,3,4,5,6],\n#               \"num_leaves\": np.linspace(20, 40).astype(int),\n#              }\n\n# # Estimator for use in random search\n# estimator = LGBMClassifier(class_weight='balanced',random_state=42)\n\n# # Create the random search model\n# lgbm = RandomizedSearchCV(estimator, param_grid, n_jobs = -1, \n#                         scoring = 'f1', cv = 5, \n#                         n_iter = 100, verbose = 0,\n#                         random_state=42)\n\n# # Fit \n# lgbm.fit(x_full, y_full)\n# lgbm_best_model = lgbm.best_estimator_\n\n# cv_scores = cross_validate(\n#                             lr_best_model, # best_estimator da RandomSearchCV\n#                             x_full,\n#                             y_full,\n#                             cv=5,\n#                             scoring=('f1', 'average_precision', 'roc_auc','recall'),\n#                             return_train_score=True\n#                             )\n\n# f1_score_train_cv =  round(np.mean(cv_scores['train_f1']),3)\n# recall_train_cv =  round(np.mean(cv_scores['train_recall']),3)\n# auc_score_train_cv =  round(np.mean(cv_scores['train_roc_auc']),3)\n# avg_prec_train_cv =  round(np.mean(cv_scores['train_average_precision']),3)\n\n# lgbm_f1_score_test_cv = round(np.mean(cv_scores['test_f1']),3)\n# lgbm_recall_test_cv = round(np.mean(cv_scores['test_recall']),3)\n# lgbm_auc_score_test_cv = round(np.mean(cv_scores['test_roc_auc']),3)\n# lgbm_avg_prec_test_cv = round(np.mean(cv_scores['test_average_precision']),3)\n\n\n# ###### Tabela comparativa ######\n# print(\n#     tabulate(\n#         [\n#             [\"\",\"F1 Score\", \"Recall\", \"AUC\", \"Avg Precision\"],\n#             [\n#                 \"Hyperopt Train\",\n#                 f1_score_train,\n#                 recall_train,\n#                 auc_score_train,\n#                 avg_prec_train,\n#             ],\n#             [\n#                 \"Hyperopt Test\",\n#                 lgbm_f1_score_test_cv,\n#                 lgbm_recall_test_cv,\n#                 lgbm_auc_score_test_cv,\n#                 lgbm_avg_prec_test_cv,\n#             ],\n#         ]\n#     )\n# )\n\n# end_time = time.time()\n# lgbm_fit_time = round(end_time - init_time,3)\n# print(f\"LGBM done in {lgbm_fit_time} seconds\")\n# print(lgbm_best_model)","e2067acd":"# crossval results\n\n# --------------  --------  ------  ------  -------------\n#                 F1 Score  Recall  AUC     Avg Precision\n# Hyperopt Train  0.6154    0.7407  0.9655  0.4097\n# Hyperopt Test   0.24      0.533   0.712   0.319\n# --------------  --------  ------  ------  -------------","65406c36":"###############     LGBM     ###############\n\nlgbm_best_model = LGBMClassifier(alpha=0.4, boosting_type='dart', class_weight='balanced',\n               colsample_bytree=0.7, max_depth=2, n_estimators=2, num_leaves=39,\n               objective='binary', random_state=42, subsample=0.5)\n\nlgbm_best_model.fit(x_full, y_full)\n\n###### Avaliando hyperopt - test ######\ny_pred_test = lgbm_best_model.predict(x_full)\ny_prob_test = lgbm_best_model.predict_proba(x_full)[:, 1]\n\nlgbm_auc_score_test = round(roc_auc_score(y_full,y_prob_test),4)\n\n_,recall_test,f1_score_test,_ = precision_recall_fscore_support(y_full,y_pred_test)\nlgbm_f1_score_test = round(f1_score_test[1],4)\nlgbm_recall_test = round(recall_test[1],4)\n\nlgbm_avg_prec_test = round(average_precision_score(y_full,y_pred_test),4)","f42617d0":"###############     Model comparison table     ###############\n\n\nprint(\n    tabulate(\n        [\n            [\"Model\", \"F1-score\", \"Recall\", \"AUC\", \"Avg Precision\"],\n            [\n                \"Logistic Regression\",\n                lr_f1_score_test,\n                lr_recall_test,\n                lr_auc_score_test,\n                lr_avg_prec_test,          \n            ],\n            [\n                \"Extra Trees\",\n                xt_f1_score_test_3,\n                xt_recall_test_3,\n                xt_auc_score_test_3,\n                xt_avg_prec_test_3,\n            ],\n            [\n                \"LGBM\",\n                lgbm_f1_score_test,\n                lgbm_recall_test,\n                lgbm_auc_score_test,\n                lgbm_avg_prec_test\n            ],\n        ]\n    )\n)\n\n\nbest_model_3 = xt_best_model\nbest_model_3","7ebeaea7":"#     train test split\n_, _, _, _, x_full, y_full = train_test(df_fourth_window)  \n\n\n# ###############     Logistic Regression     ###############\n\n# init_time = time.time()\n\n# ###### Hyperoptimization ###### --> after discovering the best hyperparameters, we do not need to keep executing that part of the code\n# lr_params = {\n#     'C': np.random.uniform(low=0.0, high=1.0, size=1000),\n#     'penalty': ['l1', 'l2'],\n#     'max_iter': np.random.uniform(low=2000, high=10000, size=1000),\n# }\n\n# lr_random_search_model = RandomizedSearchCV(\n#     estimator=LogisticRegression(\n#         fit_intercept=True,\n#         class_weight='balanced',\n#         random_state=42\n#     ), \n#     param_distributions=lr_params,\n#     scoring='f1',\n#     cv=4,\n#     n_iter=2000,\n#     n_jobs=-1,\n#     random_state=42\n# )\n\n# lr_random_search_model.fit(x_full, y_full)\n# lr_best_model = lr_random_search_model.best_estimator_\n\n\n# cv_scores = cross_validate(\n#                             lr_best_model, # best_estimator da RandomSearchCV\n#                             x_full,\n#                             y_full,\n#                             cv=4,\n#                             scoring=('f1', 'average_precision', 'roc_auc','recall'),\n#                             return_train_score=True\n#                             )\n\n# f1_score_train_cv =  round(np.mean(cv_scores['train_f1']),3)\n# recall_train_cv =  round(np.mean(cv_scores['train_recall']),3)\n# auc_score_train_cv =  round(np.mean(cv_scores['train_roc_auc']),3)\n# avg_prec_train_cv =  round(np.mean(cv_scores['train_average_precision']),3)\n\n# lr_f1_score_test_cv = round(np.mean(cv_scores['test_f1']),3)\n# lr_recall_test_cv = round(np.mean(cv_scores['test_recall']),3)\n# lr_auc_score_test_cv = round(np.mean(cv_scores['test_roc_auc']),3)\n# lr_avg_prec_test_cv = round(np.mean(cv_scores['test_average_precision']),3)\n\n\n\n# ###### Tabela comparativa ######\n# print(\n#     tabulate(\n#         [\n#             [\"Logistic Regression\",\"F1 Score\", \"Recall\", \"AUC\", \"Avg Precision\"],\n#             [\n#                 \"Hyperopt Train\",\n#                 f1_score_train_cv,\n#                 recall_train_cv,\n#                 auc_score_train_cv,\n#                 avg_prec_train_cv,\n#             ],\n#             [\n#                 \"Hyperopt Test\",\n#                 lr_f1_score_test_cv,\n#                 lr_recall_test_cv,\n#                 lr_auc_score_test_cv,\n#                 lr_avg_prec_test_cv,\n#             ],\n#         ]\n#     )\n# )\n\n# end_time = time.time()\n# lr_fit_time = round((end_time - init_time),2)\n\n# print(f\"Logistic Regression done in {lr_fit_time} seconds\")\n# lr_best_model","e67f7360":"# crossval results\n\n# -------------------  --------  ------  -----  -------------\n# Logistic Regression  F1 Score  Recall  AUC    Avg Precision\n# Hyperopt Train       0.816     0.944   0.969  0.912\n# Hyperopt Test        0.599     0.722   0.817  0.615\n# -------------------  --------  ------  -----  -------------","6bfe2949":"lr_best_model = LogisticRegression(C=0.8289805678387626, class_weight='balanced',\n                   max_iter=9335.5416957698, random_state=42)\n\nlr_best_model.fit(x_full, y_full)\n\n###### Avaliando hyperopt - test ######\ny_pred_test = lr_best_model.predict(x_full)\ny_prob_test = lr_best_model.predict_proba(x_full)[:, 1]\n\nlr_auc_score_test = round(roc_auc_score(y_full,y_prob_test),4)\n\n_,recall_test,f1_score_test,_ = precision_recall_fscore_support(y_full,y_pred_test)\nlr_f1_score_test = round(f1_score_test[1],4)\nlr_recall_test = round(recall_test[1],4)\n\nlr_avg_prec_test = round(average_precision_score(y_full,y_pred_test),4)","119de288":"# ###############     Extra Trees     ############### \n    \n# init_time = time.time()\n\n\n# # Hyperparameter grid\n# param_grid = {\n#     'n_estimators': np.linspace(1500, 3000).astype(int),\n#     'max_depth': list(np.linspace(2, 4).astype(int)),\n#     'max_features': ['auto', 'sqrt'],\n#     'max_samples': list(np.arange(0.5, 1, 0.1)),\n#     'min_samples_split': [5, 10, 20],\n#     'bootstrap': [True, False]\n# }\n\n# # Estimator for use in random search\n# estimator = ExtraTreesClassifier(class_weight='balanced',random_state=42)\n\n# # Create the random search model\n# xtrees_model = RandomizedSearchCV(estimator, param_grid, n_jobs = -1, \n#                         scoring = 'f1', cv = 3, \n#                         n_iter = 100, verbose = 0,\n#                         random_state=42)\n\n# # Fit \n# xtrees_model.fit(x_full, y_full)\n# xt_best_model = xtrees_model.best_estimator_\n\n\n# cv_scores = cross_validate(\n#                             xt_best_model, # best_estimator da RandomSearchCV\n#                             x_full,\n#                             y_full,\n#                             cv=4,\n#                             scoring=('f1', 'average_precision', 'roc_auc','recall'),\n#                             return_train_score=True\n#                             )\n\n# f1_score_train_cv =  round(np.mean(cv_scores['train_f1']),3)\n# recall_train_cv =  round(np.mean(cv_scores['train_recall']),3)\n# auc_score_train_cv =  round(np.mean(cv_scores['train_roc_auc']),3)\n# avg_prec_train_cv =  round(np.mean(cv_scores['train_average_precision']),3)\n\n# xt_f1_score_test_cv = round(np.mean(cv_scores['test_f1']),3)\n# xt_recall_test_cv = round(np.mean(cv_scores['test_recall']),3)\n# xt_auc_score_test_cv = round(np.mean(cv_scores['test_roc_auc']),3)\n# xt_avg_prec_test_cv = round(np.mean(cv_scores['test_average_precision']),3)\n\n\n# ###### Tabela comparativa ######\n# print(\n#     tabulate(\n#         [\n#             [\"Extra Trees\",\"F1 Score\", \"Recall\", \"AUC\", \"Avg Precision\"],\n#             [\n#                 \"Hyperopt Train\",\n#                 f1_score_train,\n#                 recall_train,\n#                 auc_score_train,\n#                 avg_prec_train,\n#             ],\n#             [\n#                 \"Hyperopt Test\",\n#                 xt_f1_score_test_cv,\n#                 xt_recall_test_cv,\n#                 xt_auc_score_test_cv,\n#                 xt_avg_prec_test_cv,\n#             ],\n#         ]\n#     )\n# )\n\n# end_time = time.time()\n# xt_fit_time = round((end_time - init_time),2)\n# print(f\"Extra Trees done in {xt_fit_time} seconds\")\n# print(xt_best_model)","e60727b7":"# crossval results\n\n# --------------  --------  ------  ------  -------------\n# Extra Trees     F1 Score  Recall  AUC     Avg Precision\n# Hyperopt Train  0.6154    0.7407  0.9655  0.4097\n# Hyperopt Test   0.746     0.877   0.939   0.876\n# --------------  --------  ------  ------  -------------","24a8caa9":"###############     Extra Trees     ###############\n\nxt_best_model = ExtraTreesClassifier(class_weight='balanced', max_depth=3, max_samples=0.5,\n                     min_samples_split=20, n_estimators=2816, random_state=42)\n\nxt_best_model.fit(x_full, y_full)\n\n###### Avaliando hyperopt - test ######\ny_pred_test = xt_best_model.predict(x_full)\ny_prob_test = xt_best_model.predict_proba(x_full)[:, 1]\n\nxt_auc_score_test_4 = round(roc_auc_score(y_full,y_prob_test),4)\n\n_,recall_test,f1_score_test,_ = precision_recall_fscore_support(y_full,y_pred_test)\nxt_f1_score_test_4 = round(f1_score_test[1],4)\nxt_recall_test_4 = round(recall_test[1],4)\n\nxt_avg_prec_test_4 = round(average_precision_score(y_full,y_pred_test),4)","e7bb3d1f":"# ##############     LGBM     ###############\n\n# init_time = time.time()\n\n\n# # Hyperparameter grid\n# param_grid = {\"n_estimators\": np.linspace(2, 5).astype(int),\n#               \"boosting_type\": [\"gbdt\",\"dart\",\"goss\"],\n#               \"subsample\": list(np.arange(0.5, 1, 0.2)),\n#               \"colsample_bytree\": list(np.arange(0.5, 0.8, 0.1)),\n#               \"objective\": [\"binary\",\"multiclass\"],\n#               \"alpha\": list(np.arange(0, 0.6, 0.2)),\n#               \"max_depth\": [2,3,4,5,6],\n#               \"num_leaves\": np.linspace(20, 40).astype(int),\n#              }\n\n# # Estimator for use in random search\n# estimator = LGBMClassifier(class_weight='balanced',random_state=42)\n\n# # Create the random search model\n# lgbm = RandomizedSearchCV(estimator, param_grid, n_jobs = -1, \n#                         scoring = 'f1', cv = 5, \n#                         n_iter = 100, verbose = 0,\n#                         random_state=42)\n\n# # Fit \n# lgbm.fit(x_full, y_full)\n# lgbm_best_model = lgbm.best_estimator_\n\n# cv_scores = cross_validate(\n#                             lr_best_model, # best_estimator da RandomSearchCV\n#                             x_full,\n#                             y_full,\n#                             cv=5,\n#                             scoring=('f1', 'average_precision', 'roc_auc','recall'),\n#                             return_train_score=True\n#                             )\n\n# f1_score_train_cv =  round(np.mean(cv_scores['train_f1']),3)\n# recall_train_cv =  round(np.mean(cv_scores['train_recall']),3)\n# auc_score_train_cv =  round(np.mean(cv_scores['train_roc_auc']),3)\n# avg_prec_train_cv =  round(np.mean(cv_scores['train_average_precision']),3)\n\n# lgbm_f1_score_test_cv = round(np.mean(cv_scores['test_f1']),3)\n# lgbm_recall_test_cv = round(np.mean(cv_scores['test_recall']),3)\n# lgbm_auc_score_test_cv = round(np.mean(cv_scores['test_roc_auc']),3)\n# lgbm_avg_prec_test_cv = round(np.mean(cv_scores['test_average_precision']),3)\n\n\n# ###### Tabela comparativa ######\n# print(\n#     tabulate(\n#         [\n#             [\"\",\"F1 Score\", \"Recall\", \"AUC\", \"Avg Precision\"],\n#             [\n#                 \"Hyperopt Train\",\n#                 f1_score_train,\n#                 recall_train,\n#                 auc_score_train,\n#                 avg_prec_train,\n#             ],\n#             [\n#                 \"Hyperopt Test\",\n#                 lgbm_f1_score_test_cv,\n#                 lgbm_recall_test_cv,\n#                 lgbm_auc_score_test_cv,\n#                 lgbm_avg_prec_test_cv,\n#             ],\n#         ]\n#     )\n# )\n\n# end_time = time.time()\n# lgbm_fit_time = round(end_time - init_time,3)\n# print(f\"LGBM done in {lgbm_fit_time} seconds\")\n# print(lgbm_best_model)","402a5ccb":"# crossval results\n\n# --------------  --------  ------  ------  -------------\n#                 F1 Score  Recall  AUC     Avg Precision\n# Hyperopt Train  0.6154    0.7407  0.9655  0.4097\n# Hyperopt Test   0.632     0.723   0.842   0.676\n# --------------  --------  ------  ------  -------------","8dde5c32":"###############     LGBM     ###############\n\nlgbm_best_model = LGBMClassifier(alpha=0.4, boosting_type='dart', class_weight='balanced',\n               colsample_bytree=0.7, max_depth=2, n_estimators=2, num_leaves=39,\n               objective='binary', random_state=42, subsample=0.5)\n\nlgbm_best_model.fit(x_full, y_full)\n\n###### Avaliando hyperopt - test ######\ny_pred_test = lgbm_best_model.predict(x_full)\ny_prob_test = lgbm_best_model.predict_proba(x_full)[:, 1]\n\nlgbm_auc_score_test = round(roc_auc_score(y_full,y_prob_test),4)\n\n_,recall_test,f1_score_test,_ = precision_recall_fscore_support(y_full,y_pred_test)\nlgbm_f1_score_test = round(f1_score_test[1],4)\nlgbm_recall_test = round(recall_test[1],4)\n\nlgbm_avg_prec_test = round(average_precision_score(y_full,y_pred_test),4)","b3795d1b":"###############     Model comparison table     ###############\n\n\nprint(\n    tabulate(\n        [\n            [\"Model\", \"F1-score\", \"Recall\", \"AUC\", \"Avg Precision\"],\n            [\n                \"Logistic Regression\",\n                lr_f1_score_test,\n                lr_recall_test,\n                lr_auc_score_test,\n                lr_avg_prec_test,          \n            ],\n            [\n                \"Extra Trees\",\n                xt_f1_score_test_4,\n                xt_recall_test_4,\n                xt_auc_score_test_4,\n                xt_avg_prec_test_4,\n            ],\n            [\n                \"LGBM\",\n                lgbm_f1_score_test,\n                lgbm_recall_test,\n                lgbm_auc_score_test,\n                lgbm_avg_prec_test,\n            ],\n        ]\n    )\n)\n\n\nbest_model_4 = xt_best_model\nbest_model_4","f42b932a":"print(\n    tabulate(\n        [\n            [\"Model\", \"F1-score\", \"Recall\", \"AUC\", \"Avg Precision\"],\n            [\n                \"W1 - Extra Trees\",\n                xt_f1_score_test_1,\n                xt_recall_test_1,\n                xt_auc_score_test_1,\n                xt_avg_prec_test_1,          \n            ],\n            [\n                \"W2 - Extra Trees\",\n                lgbm_f1_score_test_2,\n                lgbm_recall_test_2,\n                lgbm_auc_score_test_2,\n                lgbm_avg_prec_test_2, \n            ],\n            [\n                \"W3 - Extra Trees\",\n                xt_f1_score_test_3,\n                xt_recall_test_3,\n                xt_auc_score_test_3,\n                xt_avg_prec_test_3 \n            ],\n            [\n                \"W4 - LGBM\",\n                xt_f1_score_test_4,\n                xt_recall_test_4,\n                xt_auc_score_test_4,\n                xt_avg_prec_test_4,\n            ],\n        ]\n    )\n)","fe133ade":"df_first_proba,df_second_proba,df_third_proba,df_fourth_proba = df_proba_create(df_best_features)","670ecfff":"df_first_proba.shape","f5ba03b5":"df_second_proba.shape","6ff7fe4e":"df_third_proba.shape","324ee5e5":"df_fourth_proba.shape","7d33064a":"# lr_best_model_1, xt_best_model_1, lgbm_best_model_1 = model_comparison(df_first_proba)\n# best_model_proba_1 = xt_best_model_1\n# best_model_proba_1","1c277d92":"_, _, _, _, x_full, y_full = train_test(df_first_proba)\n\n###############     Extra Trees     ###############\n\nxt_best_model = ExtraTreesClassifier(bootstrap=True, class_weight='balanced', max_depth=3,\n                     max_samples=0.7999999999999999, min_samples_split=20,\n                     n_estimators=2724, random_state=42)\n\nxt_best_model.fit(x_full, y_full)\nxt1_y_prob_test = xt_best_model.predict_proba(x_full)[:, 1]\n\ndf_proba_1 = lr_proba(xt_best_model,df_first_proba)\ndf_proba_1.drop(columns=[0],inplace=True)\ndf_proba_1.columns = ['ICU_1']\ndf_proba_1","9c9fe838":"# lr_best_model_2, xt_best_model_2, lgbm_best_model_2 = model_comparison(df_second_proba)\n# best_model_proba_2 = xt_best_model_2\n# best_model_proba_2","800d45f8":"_, _, _, _, x_full, y_full = train_test(df_first_proba)\n\n###############     Extra Trees     ###############\n\nxt_best_model = ExtraTreesClassifier(bootstrap=True, class_weight='balanced', max_depth=2,\n                     max_features='sqrt', max_samples=0.8999999999999999, min_samples_split=20,\n                     n_estimators=1714, random_state=42)\n\nxt_best_model.fit(x_full, y_full)\n\nxt2_y_prob_test = xt_best_model.predict_proba(x_full)[:, 1]\n\ndf_proba_2 = lr_proba(xt_best_model,df_first_proba)\ndf_proba_2.drop(columns=[0],inplace=True)\ndf_proba_2.columns = ['ICU_2']\ndf_proba_2","f78e6eb5":"# lr_best_model_3, xt_best_model_3, lgbm_best_model_3 = model_comparison(df_third_proba)\n# best_model_proba_3 = xt_best_model_3\n# best_model_proba_3","adc93c2a":"_, _, _, _, x_full, y_full = train_test(df_first_proba)\n\n###############     Extra Trees     ###############\n\nxt_best_model = ExtraTreesClassifier(class_weight='balanced', max_depth=3, max_features='sqrt',\n                     max_samples=0.8999999999999999, min_samples_split=10,\n                     n_estimators=2479, random_state=42)\n\nxt_best_model.fit(x_full, y_full)\n\nxt3_y_prob_test = xt_best_model.predict_proba(x_full)[:, 1]\n\ndf_proba_3 = lr_proba(xt_best_model,df_first_proba)\ndf_proba_3.drop(columns=[0],inplace=True)\ndf_proba_3.columns = ['ICU_3']\ndf_proba_3","7eae98a9":"# lr_best_model_4, xt_best_model_4, lgbm_best_model_4 = model_comparison(df_fourth_proba)\n# best_model_proba_4 = xt_best_model_4\n# best_model_proba_4","307e7ec0":"_, _, _, _, x_full, y_full = train_test(df_first_proba)\n\n###############     LGBM     ###############\n\nlgbm_best_model = LGBMClassifier(alpha=0.4, class_weight='balanced', colsample_bytree=0.5,\n               max_depth=3, n_estimators=4, num_leaves=24, objective='binary',\n               random_state=42, subsample=0.7)\n\nlgbm_best_model.fit(x_full, y_full)\n\nlgbm4_y_prob_test = lgbm_best_model.predict_proba(x_full)[:, 1]\n\ndf_proba_4 = lr_proba(lgbm_best_model,df_first_proba)\ndf_proba_4.drop(columns=[0],inplace=True)\ndf_proba_4.columns = ['ICU_4']\ndf_proba_4","ddb7daaa":"# _, _, _, _, x_full, y_full = train_test(df_first_proba)\n\n# ###############     Extra Trees     ###############\n\n# xt_best_model = ExtraTreesClassifier(bootstrap=True, class_weight='balanced', max_depth=2,\n#                      max_features='sqrt', max_samples=0.5, min_samples_split=10,\n#                      n_estimators=1836, random_state=42)\n\n# xt_best_model.fit(x_full, y_full)\n\n# xt4_y_prob_test = xt_best_model.predict_proba(x_full)[:, 1]\n\n# df_proba_4 = lr_proba(xt_best_model,df_first_proba)\n# df_proba_4.drop(columns=[0],inplace=True)\n# df_proba_4.columns = ['ICU_4']\n# df_proba_4","d594d65f":"df_combined_proba = df_proba_1.merge(df_proba_2,left_index = True,right_index = True)\ndf_combined_proba = df_combined_proba.merge(df_proba_3,left_index = True,right_index = True)\ndf_combined_proba = df_combined_proba.merge(df_proba_4,left_index = True,right_index = True)\ndf_combined_proba['combined_ICU_proba'] = round(df_combined_proba['ICU_1'] + df_combined_proba['ICU_2'] + df_combined_proba['ICU_3'] + df_combined_proba['ICU_4'],2)\ndf_combined_proba","fe6554bb":"plt.figure(figsize=[8, 8])\n\nax = sns.distplot(df_combined_proba['combined_ICU_proba'])\nplt.title('Distribution of patient probabilities of needing the ICU')\nax.set(xlim=(0, 1.1));","e7c56892":"# Patients below the 50% threshold\nlen(df_combined_proba[df_combined_proba['combined_ICU_proba']<0.5]['combined_ICU_proba'])","1f597c67":"# Patients above the 50% threshold\nlen(df_combined_proba[df_combined_proba['combined_ICU_proba']>=0.5]['combined_ICU_proba'])","4b993bc3":"# total Notebook run  time\n\nnotebook_stop = time.time()\ntotal_run_time = round(notebook_stop - notebook_start,3)\ntotal_run_time_minutes = round(total_run_time\/60,2)\ntotal_run_time_minutes","4f248cd9":"# Importing and handling data","7cb3f0c2":"# Chosen approach","288e39bd":"This notebook was based on the Kaggle competition below, and executed as a final project for a Data Science Bootcamp, ministered by [Alura](https:\/\/www.alura.com.br\/).\n\nIt was written by Brian Lear.\n\n* LinkedIn: https:\/\/www.linkedin.com\/in\/brian-lear-155bb745\/\n* GitHub: https:\/\/github.com\/brian-lear","f34aeab0":"All metrics were used to determine the best Model, but a model with balanced metrics would have preference before one that excelled in a  specific metric, such as AUC.","ebb51e00":"# Examples of created features","71b87eb4":"After running the Hyperoptimization once, and finding the best hyperparameters, that section of the code was commented, due to it taking long to run, and the model being already stable.","d4cf74e3":"# Next Window ICU Models","92aac8c7":"Now we need to create new dataframes without the feature difference features, in order to be able to use the new df's features across all windows. In these dataframes, we wil have the info of how many patients went to the ICU on other windows, and features related to the first window.","ccb76950":"In order to have the best features in the model, features with low correlation to the target or with a correlation too high will be removed","18bcb8a4":"Another relevant instruction is that we should not use patient information related to the row when it is already in the ICU, as we do not know whether the information was measured prior or after the patient being sent to the ICU.\n\n![image.png](attachment:image.png)\n\n![image.png](attachment:image.png)","590ead41":"# Target variable","265709e7":"# Combined Probability usage \n\nAs we want the probability of a combined event, we sum the probabilities of each individual event happening. With this approach, we are checking whether the patient will be sent to the ICU in any given window.  That information can be of great use to the hospital in checking, with the first exam results, if a patient is more likely to need an ICU spot. And when combined allied with the previous models, the patients wigh a higher risk can be monitored and analysed if in the following window the transfer to the ICU will be required.","5477cb9f":"# Libs and defs","0047a645":"The target 'next_period_ICU' was created in order to capture the information if, for each patient, they were sent to the ICU on the next window. In that way, with initial data from a window, it could be predicted whether the patient would need an ICU spot on the following window, which would greatly improve the hospital's logistics and efficiency.","f0f04791":"# **COVID-19 - Clinical Data to assess diagnosis** -> [Kaggle submission](https:\/\/www.kaggle.com\/S%C3%ADrio-Libanes\/covid19)","50fbf867":"# **Best model for each window**\n\n* First Window: Extra Trees \n* Second Window: LGBM\n* Third Window: Extra Trees \n* Fourth Window: Extra Trees ","5805d295":"**Window Concept**\n\nThe original data contains information about specific Patients and their stay at the hospital, comprised of 5 rows per patient,being each row referent to a time window, as per below.\n\n![image.png](attachment:image.png)","2c68f398":"The primary goal is to have a good model predicting whether a pacient that was not sent to the ICU on the first window (0-2 hours) will be sent on the following window (2-4 hours). After pondering about the task at hand, I decided to tackle the other windows as well. Hence, there are 4 models, each for a w0 (window0) and a prediction for the w1, focused on predicting who will be sent to the ICU.\n\nIn order to determine which model to choose, I created 4 dataframes, for each combination of w0 and w1, while including new features, which were the lagging memory of how the other features changed (non categorical ones). For instance, how much did the blood tests improved or worsened between windows, and that information was carried to following dataframes, leaving the dataframde for the last window (6-12 hours predicting ICU in Above 12h), with lagged difference features between windows [0-2 and 4-6], [4-6 and 6-12], etc. \n\nI then ran those 4 dataframes throught a Logistic Regression, a Extra Trees and a LGBM, all with hyperopt. After analysing the final results using cross validation, with F1 score, Recall, Average Precision and AUC, I chose the best model for each window.\n\nAfter creating those 4 final models, I decided to analyse the combined probability of a patient ever going to the ICU. In order to do so, I created 4 new dataframes, but this time all had the same features, since using features dereived from past data would not make sense in this case. With those 4 dataframes in hand, I ran them through the same models, and underwent the same model selection. \n\nThe idea was to use the predict_proba for each model, but for Tree models, the predict proba is not calibrated, which means it can't be used as we would use predict proba from a Logistic Regression. Therefore, before I could use the predict probas, I needed to calibrate the ones that were generated using a tree model. That was achieved by fitting the leaves of the Tree Models with a Logistic Regression, and using the predict proba from the Logistic Regression. With the calibrated probas in hand, I then sumed all probas, which gave me the combined probability that a pacient would be sent to the ICU at any given time.","05821711":"The feature creating technique below was used with all non categorical information, in order to try to capture if results changing overtime had a positive or negative impact on the prediction.\n\n* RESPIRATORY_RATE_DIFF: original variable, related to the original dataset\n* RESPIRATORY_RATE_DIFF_windif_2: feature created by checking if there was a difference between RESPIRATORY_RATE_DIFF(window 2-4) to RESPIRATORY_RATE_DIFF(window 0-2)\n* RESPIRATORY_RATE_DIFF_windif_3: feature created by checking if there was a difference between RESPIRATORY_RATE_DIFF(window 4-6) to RESPIRATORY_RATE_DIFF(window 2-4)\n* RESPIRATORY_RATE_DIFF_windif_4: feature created by checking if there was a difference between RESPIRATORY_RATE_DIFF(window 6-12) to RESPIRATORY_RATE_DIFF(window 4-6)","ec59c4f3":"**Analysing wich model to use for the first window ICU analysis**","06a319a6":"**Finding the best models for the predict proba dataframes. For that, we train the models with the dataframes related to their windows, but after we find the best model, we fit the first widnow dataframe in order to have all patients in our final dataframe.**\n\n**After that, we have to calibrate the predict probas from the Tree Models in order to use them in a combined fashion, based on the following [article](https:\/\/gdmarmerola.github.io\/probability-calibration\/)**","2f3188d9":"* # Window (4-6 hours)","81bd28f9":"* # Window (0-2 hours)","f19df971":"Context\n\nCOVID-19 pandemic impacted the whole world, overwhelming healthcare systems - unprepared for such intense and lengthy request for ICU beds, professionals, personal protection equipment and healthcare resources.\nBrazil recorded first COVID-19 case on February 26 and reached community transmission on March 20.\n\nCall to action\n\nThere is urgency in obtaining accurate that to better predict and prepare healthcare systems and avoid collapse, defined by above capacity need of ICU beds (assuming human resources, PPE and professionals are available), using individual clinical data - in lieu of epidemiological and populational data.**","0b3afb9e":"With a clean dataset, Window focused dataframes can be created, in order to study each window separately.","debca532":"Based on the metrics above, there will be a high success rate in predicting, for each window, which patients are going to be sent to the ICU on the next window. But further dedicaton should be spent in improving the hyperparameters, in order to check for eventual overfitting, even if the hyperoptimization was done using cross validation techniques.","7cfeb404":"# Combined Proba","091e44f6":"* # Window (6-12 hours)","bd15bb58":"* # Window (2-4 hours)"}}