{"cell_type":{"48f4d148":"code","ea536a49":"code","ac320caf":"code","a471b226":"code","e4d6cf63":"code","dd4b0328":"code","1d79b472":"code","786cdf25":"code","05b0ae17":"code","42c105f1":"code","b62318c9":"code","3fd8f0a0":"code","e17543da":"code","6db45df2":"code","ff6f4403":"code","5bebb830":"code","1dce0160":"code","efeb44a4":"code","0ae4e357":"code","376e7c33":"code","4d4fbf28":"code","86e404f0":"code","c150396f":"code","34a32473":"code","7de73f0d":"code","7d017fa7":"code","ff51f6c7":"code","0825b627":"code","3757756e":"code","4f426904":"code","e0e2d253":"code","3493969f":"code","23871fa7":"code","37165a79":"code","377a013b":"code","a79ce5f8":"code","2f42be06":"code","4a09d1ab":"code","01d21f80":"code","7943d904":"code","5a183bdf":"code","7e94d721":"code","adba1820":"code","b3aa7cdc":"code","b1251fa4":"code","34dd9d07":"code","3cac924f":"code","c9b135ad":"code","751736a5":"code","8c128d1e":"code","ca2f350a":"code","bd611229":"code","f197cbe9":"code","7bf22b08":"code","abb48959":"code","22cd9864":"code","5c9a70bc":"code","a6373b7a":"code","80dca1ae":"code","e92c506d":"code","09a5aacd":"code","fc74d29d":"code","ad15a097":"code","87211193":"code","6d1aabe3":"code","91cfa90f":"code","5da66aeb":"code","a1490a78":"markdown","d5564e15":"markdown","d76113d1":"markdown"},"source":{"48f4d148":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ea536a49":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split","ac320caf":"data=pd.read_csv('\/kaggle\/input\/fish-market\/Fish.csv')\ndata.head()","a471b226":"data.info()","e4d6cf63":"data.nunique()","dd4b0328":"data['Weight'].plot()","1d79b472":"from scipy.stats import skew\ndata['Weight'].skew()","786cdf25":"cor_mat=data.corr().round(2)","05b0ae17":"plt.figure(figsize=(10,7))\nsns.heatmap(data=cor_mat,annot=True)","42c105f1":"X=data.drop(columns=['Length2','Length3','Weight','Species','Width'])\nY=data['Weight']","b62318c9":"import seaborn as sns\nsns.boxplot(Y)","3fd8f0a0":"X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.1,random_state=7)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(Y_train.shape)\nprint(Y_test.shape)","e17543da":"from sklearn.preprocessing import PowerTransformer\nfrom sklearn.preprocessing import MinMaxScaler\n\npw=PowerTransformer()\nms=MinMaxScaler()\n\nX_train=ms.fit_transform(X_train)\nX_test=ms.transform(X_test)\n\nY_train=Y_train.values.reshape(-1,1)\nY_test=Y_test.values.reshape(-1,1)\n\nY_train=pw.fit_transform(Y_train)\nY_test=pw.transform(Y_test)","6db45df2":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error,r2_score\n\nmodel_lin=LinearRegression()\nmodel_lin.fit(X_train,Y_train)","ff6f4403":"y_test_predictv=model_lin.predict(X_test)\n\nrmse=np.sqrt(mean_squared_error(Y_test,y_test_predictv))\n\nr2=r2_score(y_test_predictv,Y_test)\n\nprint('the values predicted has')\nprint('RMSE = {}'.format(rmse))\nprint('r2 Score= {}'.format(r2))\n","5bebb830":"from sklearn.linear_model import ElasticNet\n\ne_model=ElasticNet(alpha=0.01)\n\ne_model.fit(X_train,Y_train)\n\ny_test_predict=e_model.predict(X_test)\n\nrmse=np.sqrt(mean_squared_error(Y_test,y_test_predict))\n\nr2=r2_score(Y_test,y_test_predict)\n\nprint('RMSE={}'.format(rmse))\n\nprint('r2 score={}'.format(r2))","1dce0160":"from sklearn.model_selection import GridSearchCV\n\ne_estimator=ElasticNet()\n\nparameters={'alpha':[0.001,0.1,0.3,0.5,0.8,10,11,12],\n          'l1_ratio':[0.01,0.1,0.3,0.4,0.8,1]}\ngrid=GridSearchCV(estimator=e_estimator,param_grid=parameters,cv=2,n_jobs=-1)\ngrid.fit(X_train,Y_train)","efeb44a4":"grid.best_params_","0ae4e357":"from sklearn.linear_model import ElasticNet\n\ne_model=ElasticNet(alpha=0.001,l1_ratio=0.1)\n\ne_model.fit(X_train,Y_train)\n\ny_test_predict=e_model.predict(X_test)\n\nrmse=np.sqrt(mean_squared_error(Y_test,y_test_predict))\n\nr2=r2_score(Y_test,y_test_predict)\n\nprint('RMSE={}'.format(rmse))\n\nprint('r2 score={}'.format(r2))","376e7c33":"y_test_predict=y_test_predict.reshape(-1,1)","4d4fbf28":"Y_test = pw.inverse_transform(Y_test)\ny_test_predict = pw.inverse_transform(y_test_predict)\nfrom matplotlib.pyplot import plot\nplot(y_test_predict, label='Pred')\nplot(Y_test, label='Actual')\nplt.legend(loc='best')","86e404f0":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls","c150396f":"#Species\nplt.figure(figsize=(20,5))\n\nax=sns.countplot(data['Species'])\nfor p in ax.patches:\n    h=p.get_height()\n    w=p.get_width()\/2\n    ax.text(p.get_x()+w,h+1,\n    '{:1}'.format(h),\n    ha='center')\nplt.show    ","34a32473":"#height\nplt.figure(figsize=(30,7))\n\nax=sns.countplot(data['Height'])\nfor p in ax.patches:\n    h=p.get_height()\n    w=p.get_width()\/2\n    ax.text(p.get_x()+w,h,\n    '{:1}'.format(h),\n    ha='center')\nplt.xticks(rotation=90)    \nplt.show    ","7de73f0d":"#length\nplt.figure(figsize=(30,7))\n\nax=sns.countplot(data['Length1'])\nfor p in ax.patches:\n    h=p.get_height()\n    w=p.get_width()\/2\n    ax.text(p.get_x()+w,h,\n    '{:1}'.format(h),\n    ha='center')\nplt.xticks(rotation=90)    \nplt.show    ","7d017fa7":"#a = data.groupby(['Species'],as_index=False)[['Height']].count() #indexing\n#a","ff51f6c7":"a=data.groupby(['Species'])[['Weight']].count()\na","0825b627":"#using plotly\ncolors = ['cyan']*9\ntrace1 = go.Bar(\ny=a.Weight,\nx=a.index,\nmarker_color=colors\n)\n\ndf=[trace1]\nlayout=go.Layout(\n    title='species count',\n                font=dict(size=16),\n                legend=dict(font=dict(size=6)))\nfigure=go.Figure(data=df,layout=layout)\npy.iplot(figure,filename='barchart')\n","3757756e":"#mean weight\nc=data.groupby(['Species'])[['Weight']].mean()\nc","4f426904":"plt.figure(figsize=(10,5))\nax = sns.barplot(x=c.index, y='Weight', data=c)\nfor p in ax.patches:\n    h = p.get_height()\n    w = p.get_width()\/2\n    ax.text(p.get_x()+w, h+3,\n            '{:.2f}'.format(h),\n           ha=\"center\")\nplt.show()","e0e2d253":"#using plotly\ncolors = ['lightpink','lightblue','orange','cyan','violet','red','lightgreen']\ntrace1 = go.Bar(\ny=c.Weight,\nx=c.index,\nmarker_color=colors,\n    marker=dict(color='darkblue')\n)\n\ndf=[trace1]\nlayout=go.Layout(\n    title='average weight of species',\n                font=dict(size=16),\n                legend=dict(font=dict(size=6)))\nfigure=go.Figure(data=df,layout=layout)\npy.iplot(figure,filename='barchart')\n","3493969f":"data['Length']=(data['Length1']+data['Length2']+data['Length3'])\/3","23871fa7":"plt.plot(data['Length1'], label='1')\nplt.plot(data['Length2'], label='2')\nplt.plot(data['Length3'], label='3')\nplt.plot(data['Length'], label='mean')\nplt.legend()","37165a79":"#Min length\ndata.drop(columns=['Length1','Length2','Length3'],inplace=True)","377a013b":"a = data.groupby(['Species'],as_index=False)[['Length']].min()\na = a.rename(columns={'Length':'Min_length'})\na","a79ce5f8":"data = pd.merge(data, a , on='Species')","2f42be06":"#Max weight\na = data.groupby(['Species'],as_index=False)[['Width']].max()\na = a.rename(columns={'Width':'Max_width'})\na\n","4a09d1ab":"data = pd.merge(data, a , on='Species')","01d21f80":"import seaborn as sns\nplt.figure(figsize=(10,7))\ncor_mat= data.corr()\nsns.heatmap(data=cor_mat,annot=True)","7943d904":"# mean height\na = data.groupby(['Species'],as_index=False)[['Height']].max()\na = a.rename(columns={'Height':'Mean_Height'})\na\n","5a183bdf":"data = pd.merge(data, a , on='Species')","7e94d721":"data['Volume'] =  data['Height'] * data['Width'] * data['Length']","adba1820":"data.drop(columns=['Height','Width','Length'], inplace=True)","b3aa7cdc":"import seaborn as sns\nplt.figure(figsize=(10,7))\ncor_mat= data.corr()\nsns.heatmap(data=cor_mat,annot=True)","b1251fa4":"dumm=pd.get_dummies(data['Species'])\ndumm","34dd9d07":"#adding the above data back to data\ndata=pd.concat([dumm,data],axis=1)\ndata","3cac924f":"#now creating a spearman model for the data above\nimport seaborn as sns\nplt.figure(figsize=(10,7))\ncor_mat= data.corr(method='spearman')\nsns.heatmap(cor_mat ,annot=True)","c9b135ad":"#now here we can see that this is too much of data of seeing every correlation is a tedious work\nimport seaborn as sns\nplt.figure(figsize=(10,7))\ncor_mat= data.corr(method='spearman')\nsns.heatmap(cor_mat>0.7 ,annot=True)","751736a5":"#here we can see we have bream and perch are correlated to other parameters other than weight\n#dropping species as it is categorical data\ndata.drop(columns=['Species','Perch','Bream'], inplace =True)\ndata","8c128d1e":"X=data.drop(columns=['Weight'])\nY=data['Weight']","ca2f350a":"from sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=7)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(Y_train.shape)\nprint(Y_test.shape)","bd611229":"from sklearn.preprocessing import PowerTransformer\nfrom sklearn.preprocessing import MinMaxScaler\n\npw=PowerTransformer()\nms=MinMaxScaler()\n\nX_train=ms.fit_transform(X_train)\nX_test=ms.transform(X_test)\n\nY_train=Y_train.values.reshape(-1,1)\nY_test=Y_test.values.reshape(-1,1)\n\nY_train=pw.fit_transform(Y_train)\nY_test=pw.transform(Y_test)","f197cbe9":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error,r2_score\n\nmodel_lin=LinearRegression()\nmodel_lin.fit(X_train,Y_train)","7bf22b08":"y_test_predictv=model_lin.predict(X_test)\n\nrmse=np.sqrt(mean_squared_error(Y_test,y_test_predictv))\n\nr2=r2_score(y_test_predictv,Y_test)\n\nprint('the values predicted has')\nprint('RMSE = {}'.format(rmse))\nprint('r2 Score= {}'.format(r2))","abb48959":"from sklearn.linear_model import Ridge\n\nR_model=Ridge(alpha=0.1)\nR_model.fit(X_train,Y_train)\n\ny_test_predict=R_model.predict(X_test)\n\nrmse=np.sqrt(mean_squared_error(Y_test,y_test_predict))\nr2=r2_score(Y_test,y_test_predict)\n\nprint('RMSE={}'.format(rmse))\nprint('r2 score={}'.format(r2))","22cd9864":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import ElasticNet\nr_estimator=ElasticNet()\n\nparameters={'alpha':[0.001,0.01,0.05,0.1,0.3,0.5,0.8,10,11,12],\n           'l1_ratio' : [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]}\ngrid=GridSearchCV(estimator=r_estimator,param_grid=parameters,cv=7,n_jobs=11)\ngrid.fit(X_train,Y_train)","5c9a70bc":"grid.best_params_","a6373b7a":"e_model=ElasticNet(alpha=0.001,l1_ratio=0.9)\ne_model.fit(X_train,Y_train)\ny_test_predictv=e_model.predict(X_test)\n\nrmse=np.sqrt(mean_squared_error(Y_test,y_test_predictv))\n\nr2=r2_score(Y_test,y_test_predictv)\n\nprint('RMSE={}'.format(rmse))\n\nprint('r2 score={}'.format(r2))","80dca1ae":"plt.plot(Y_test)\nplt.plot(y_test_predictv)","e92c506d":"X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=7)","09a5aacd":"from sklearn.model_selection import KFold\nerr=[]\ny_pred=[]\n\nX_test = ms.transform(X_test)\nfold=KFold(n_splits=7)\nfor train_index, test_index in fold.split(X_train,Y_train):\n    x_train, x_test = X_train.iloc[train_index], X_train.iloc[test_index]\n    y_train, y_test = Y_train.iloc[train_index], Y_train.iloc[test_index]\n    \n    \n    x_train = ms.fit_transform(x_train)\n    x_test = ms.transform(x_test)\n    # Y_train = pd.DataFrame(Y_train)  \n    y_train = y_train.values.reshape(-1,1)\n    y_test = y_test.values.reshape(-1,1)\n    y_train = pw.fit_transform(y_train)\n    y_test = pw.transform(y_test)\n\n    \n    \n    \n    m1 = ElasticNet(alpha=0.001,\n                           l1_ratio=0.9)\n    m1.fit(x_train,y_train)\n    preds = m1.predict(x_test)\n\n    print(\"err: \",np.sqrt(mean_squared_error(y_test,preds)))\n    print(\"r2square: \",r2_score(y_test,preds))\n    err.append(np.sqrt(mean_squared_error(y_test,preds)))\n    test_pred = m1.predict(X_test)\n    test_pred = test_pred.reshape(-1,1)\n    test_pred = pw.inverse_transform(test_pred)\n    y_pred.append(test_pred)\nnp.mean(err)","fc74d29d":"Y_test = Y_test.reset_index(drop=True)","ad15a097":"\nplt.plot(Y_test)\nplt.plot(y_pred[1])","87211193":"len(y_pred)","6d1aabe3":"for i in  range(0,len(y_pred)):\n# y_pred = np.mean(y_pred, 0)\n    rmse=np.sqrt(mean_squared_error(Y_test,y_pred[i]))\n\n    r2=r2_score(Y_test,y_pred[i])\n\n    print('RMSE= {}'.format(rmse))\n\n    print('r2 score= {}'.format(r2))","91cfa90f":"plt.plot(Y_test)\nplt.plot(y_pred[6])","5da66aeb":"y_predm = np.mean(y_pred, 0)\nrmse=np.sqrt(mean_squared_error(Y_test,y_predm))\n\nr2=r2_score(Y_test,y_predm)\n\nprint('RMSE= {}'.format(rmse))\n\nprint('r2 score= {}'.format(r2))","a1490a78":"# elastic net","d5564e15":"# visualisation","d76113d1":"# prediction model"}}