{"cell_type":{"5cf9465c":"code","cdfb6929":"code","0af09e47":"code","3a1f0b3e":"code","1511890a":"code","be05acfb":"code","f383132f":"code","6dd7904d":"code","f75addc2":"code","08cb2ebe":"code","fbf578dc":"code","b5775409":"code","f30980e3":"code","7d676e3e":"code","8c804993":"code","a1da0fe5":"code","74f6239d":"code","fc28626d":"code","3dc7812a":"code","d24e4f6c":"code","c9c399f6":"code","294c3eb4":"code","4e0df495":"code","9e4118bd":"code","e1440ecf":"code","8ac22ea2":"code","264738d8":"code","5873525a":"code","af3b0334":"code","389768ab":"code","9e88cc06":"code","fd7c7be2":"code","9327889f":"code","5e075912":"code","349db7f1":"code","47bcc42e":"code","230a91c3":"code","8258971d":"code","433c6998":"code","ced6a1b1":"code","28f6732f":"code","1b470090":"code","fa9ec369":"code","f00d5e4b":"code","88dce609":"code","40970a7b":"code","a13b55b7":"code","eb9b513d":"code","3d6e4032":"code","e2379571":"code","5000945a":"code","7a86ab8a":"code","1792849d":"code","3711584b":"code","5312d4d7":"code","563f6c3c":"code","aadb473c":"code","1412ecf5":"markdown","e85d98e0":"markdown","f13f5430":"markdown","109336d8":"markdown","378964e4":"markdown","3fbca694":"markdown","635f5690":"markdown","477be09c":"markdown","49183599":"markdown","143f7d48":"markdown","6b1521bd":"markdown","34f96525":"markdown","30383c33":"markdown","e473bb11":"markdown","6e50e6b4":"markdown","2d75326c":"markdown","1b31de86":"markdown","ada422f2":"markdown","2a5e6510":"markdown","d0a14e54":"markdown","61ca70b3":"markdown","eaaf302e":"markdown","914e7a4d":"markdown"},"source":{"5cf9465c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers.recurrent import LSTM, GRU,SimpleRNN\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.utils import np_utils\nfrom sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\nfrom keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\nfrom keras.preprocessing import sequence, text\nfrom keras.callbacks import EarlyStopping,ReduceLROnPlateau\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as ex\nimport plotly.graph_objs as go","cdfb6929":"train=pd.read_csv(\"..\/input\/commonlitreadabilityprize\/train.csv\")\ntest=pd.read_csv(\"..\/input\/commonlitreadabilityprize\/test.csv\")\nsubmission=pd.read_csv(\"..\/input\/commonlitreadabilityprize\/sample_submission.csv\")","0af09e47":"print(train.head)\nprint(test.head)\nprint(submission.head)","3a1f0b3e":"display(train.info())\nprint(\"\\n\\n\")\ndisplay(test.info())\nprint(\"\\n\\n\")\ndisplay(submission.info())","1511890a":"train_stats = (pd.concat([train.apply(lambda x: x.nunique(), axis = 0)\n                          .rename(\"distinct_values\").to_frame(),\n                          train.apply(lambda x: x.notna().sum(), axis = 0)\n                          .rename(\"not_nan_values\").to_frame()], 1)\n              .reset_index().rename({'index': 'variable'}, axis = 1))","be05acfb":"train_stats","f383132f":"fig=go.Figure()\nfig.add_trace(go.Bar(x=train_stats['variable'],\n                     y=train_stats['distinct_values'],\n                     name=\"distinct val\",\n                     text=train_stats['distinct_values'],\n                     textposition=\"outside\"\n))\nfig.add_trace(go.Bar(x=train_stats['variable'],\n                     y=train_stats['not_nan_values'],\n                     name=\"not na\",\n                     text=train_stats['distinct_values'],\n                     textposition=\"outside\"\n))\nfig.update_layout(title={'text':\"Train set Data Comparison Unique vs Not NA's\",\n                         'xanchor': 'center',\n                         'yanchor': 'top',\n                         'x':0.5,'y':0.97},\n                  font=dict(size=10,family='Verdana'),\n                  template='plotly_dark',\n                  legend=dict(\n                        orientation='h',\n                        yanchor=\"bottom\",\n                        y=1.01,\n                        xanchor=\"center\",\n                        x=0.5,\n                        bgcolor=\"black\",\n                        bordercolor=\"white\",\n                        borderwidth=2,\n                        font=dict(\n                                family=\"Courier\",\n                                size=10,\n                                color=\"white\"\n                            )))\nfig.show()","6dd7904d":"fig, ax = plt.subplots(2, 1, figsize = (20, 12))\n\nfig.suptitle(\"Distribution of Target and Std. Dev.\", fontsize = 20)\n\nsns.histplot(data = train, x = 'target', \n             ax = ax[0], kde=True, bins = 50,\n             stat = 'density', color = 'maroon',\n             alpha = 0.3, label = 'Target',\n             linewidth = 3, line_kws= {'linewidth': 3})\n\nax[0].legend(fontsize=18)\nax[0].set_xlabel('target', fontsize = 18)\nax[0].set_title('target distribution', fontsize = 15)\nax[0].tick_params(axis='both', which='major', labelsize=14)\nax[0].tick_params(axis='both', which='minor', labelsize=14)\n\nsns.histplot(data = train, x = 'standard_error', \n             ax = ax[1], kde=True, bins = 50,\n             stat = 'density', color = 'blue',\n             alpha = 0.3, label = 'Standard Error',\n             linewidth = 3, line_kws= {'linewidth': 3})\n\nax[1].legend(fontsize=18)\nax[1].set_xlabel('standard_error', fontsize = 18)\nax[1].set_xlim(0.4, 0.7)\nax[1].set_title('standard_error distribution', fontsize = 15)\nax[1].tick_params(axis='both', which='major', labelsize=14)\nax[1].tick_params(axis='both', which='minor', labelsize=14)\n\nplt.subplots_adjust(hspace = 0.3)","f75addc2":"fig = go.Figure()\nfig.add_trace(go.Violin(y=train['target'],\n                            name='KDE with Boxplot',\n                            box_visible=True,\n                            meanline_visible=True,\n                            text=train['target'],\n                            fillcolor=\"lightgrey\",\n                            line=dict(color='darkred')))\nfig.update_traces(points='all',jitter=0.05)\nfig.update_layout(template='plotly_dark',\n                  title={'text':\"Distribution of Target\",\n                         'xanchor': 'center',\n                         'yanchor': 'top',\n                         'x':0.5,'y':0.9},\n                  width=1000,\n                  height=800,\n                  yaxis_title=\"Target\",\n                  legend=dict(\n                        orientation='h',\n                        yanchor=\"bottom\",\n                        y=0.5,\n                        xanchor=\"center\",\n                        x=0.5,\n                        bgcolor=\"black\",\n                        bordercolor=\"white\",\n                        borderwidth=2,\n                        font=dict(\n                                family=\"Courier\",\n                                size=10,\n                                color=\"white\"\n                            )))\nfig.show()","08cb2ebe":"fig = go.Figure()\nfig.add_trace(go.Violin(y=train['standard_error'],\n                            name='KDE with Boxplot',\n                            box_visible=True,\n                            meanline_visible=True,\n                            text=train['target'],\n                            fillcolor=\"lightgrey\",\n                            line=dict(color='darkred')))\nfig.update_traces(points='all',jitter=0.05)\nfig.update_layout(template='plotly_dark',\n                  title={'text':\"Distribution of standard error\",\n                         'xanchor': 'center',\n                         'yanchor': 'top',\n                         'x':0.5,'y':0.9},\n                  width=1000,\n                  height=800,\n                  yaxis_title=\"standard error\",\n                  font=dict(\n                            size=10,\n                            color=\"white\"),\n                  legend=dict(\n                            yanchor=\"bottom\",\n                            y=-0.3,\n                            xanchor=\"center\",\n                            x=0.5))\nfig.show()","fbf578dc":"import re,string\n\ndef strip_links(text):\n    link_regex    = re.compile('((https?):((\/\/)|(\\\\\\\\))+([\\w\\d:#@%\/;$()~_?\\+-=\\\\\\.&](#!)?)*)', re.DOTALL)\n    links         = re.findall(link_regex, text)\n    for link in links:\n        text = text.replace(link[0], ', ')    \n    return text","b5775409":"train['excerpt']=train['excerpt'].apply(lambda x:strip_links(x))\ntest['excerpt']=test['excerpt'].apply(lambda x:strip_links(x))","f30980e3":"### replace :\\n \ntrain['excerpt']=train['excerpt'].str.replace(\"\\n\",' ')\ntest['excerpt']=test['excerpt'].str.replace(\"\\n\",' ')","7d676e3e":"# Define the function to remove the punctuation\ndef remove_punctuations(text):\n    for punctuation in string.punctuation:\n        text = text.replace(punctuation, '')\n    return text\n# Apply to the DF series\ntrain['excerpt'] = train['excerpt'].apply(remove_punctuations) \ntest['excerpt'] = test['excerpt'].apply(remove_punctuations) ","8c804993":"### lower case \ntrain['excerpt']=train['excerpt'].apply(lambda x:x.lower())\ntest['excerpt']=test['excerpt'].apply(lambda x:x.lower())","a1da0fe5":"# Define a function to plot word cloud\ndef plot_cloud(wordcloud):\n    # Set figure size\n    plt.figure(figsize=(40, 30))\n    # Display image\n    plt.imshow(wordcloud) \n    # No axis details\n    plt.axis(\"off\");","74f6239d":"# Import package\nfrom wordcloud import WordCloud, STOPWORDS\n# Generate word cloud\nwordcloud = WordCloud(width = 3000, \n                      height = 2000, \n                      random_state=1, \n                      background_color='salmon', \n                      colormap='Pastel1', \n                      collocations=False, \n                      stopwords = STOPWORDS).generate(train['excerpt'].values[0])\n# Plot\nplot_cloud(wordcloud)","fc28626d":"# Generate wordcloud\nwordcloud = WordCloud(width = 3000, \n                      height = 2000, \n                      random_state=1, \n                      background_color='black', \n                      colormap='Set2', \n                      collocations=False, \n                      stopwords = STOPWORDS).generate(train['excerpt'].values[1])\n# Plot\nplot_cloud(wordcloud)","3dc7812a":"from PIL import Image\n# Import image to np.array\nmask = np.array(Image.open('..\/input\/maskcloud\/upvote.png'))\n# Generate wordcloud\nwordcloud = WordCloud(width = 3000, \n                      height = 2000, \n                      random_state=1, \n                      background_color='white', \n                      colormap='rainbow', \n                      collocations=False, \n                      stopwords = STOPWORDS, mask=mask).generate(train['excerpt'].values[2])\n# Plot\nplot_cloud(wordcloud)","d24e4f6c":"from PIL import Image\n# Import image to np.array\nmask = np.array(Image.open('..\/input\/maskcloud1\/comment.png'))\n# Generate wordcloud\nwordcloud = WordCloud(width = 3000, \n                      height = 2000, \n                      random_state=1, \n                      background_color='white', \n                      colormap='rainbow', \n                      collocations=False, \n                      stopwords = STOPWORDS, mask=mask).generate(test['excerpt'].values[0])\n# Plot\nplot_cloud(wordcloud)","c9c399f6":"train.head()\nX=train[['id','excerpt','target']]","294c3eb4":"## Check lenght of text in the data\ntrain['excerpt'].apply(lambda x:len(str(x).split())).max()","4e0df495":"X_train, X_test, y_train, y_test = train_test_split(X.excerpt, X.target, \n                                                    random_state=42, \n                                                    test_size=0.2)","9e4118bd":"max_features = 5000\nmaxlen = 200","e1440ecf":"# using keras tokenizer here\ntoken = tf.keras.preprocessing.text.Tokenizer(num_words=max_features)\n\ntoken.fit_on_texts(list(X_train) + list(X_test))\nX_train_seq = token.texts_to_sequences(X_train)\nX_test_seq = token.texts_to_sequences(X_test)\n\n#zero pad the sequences\nX_train_pad = sequence.pad_sequences(X_train_seq, maxlen=maxlen,padding='post',truncating='post')\nX_test_pad = sequence.pad_sequences(X_test_seq, maxlen=maxlen,padding='post',truncating='post')\n\nword_index = token.word_index","8ac22ea2":"X_train[0]","264738d8":"X_train_pad[0]","5873525a":"len(token.word_index)##30112","af3b0334":"# !wget http:\/\/nlp.stanford.edu\/data\/glove.6B.zip","389768ab":"#unzip the file, we get multiple embedding files. We can use either one of them\n# !unzip glove.6B.zip\n\nfrom gensim.scripts.glove2word2vec import glove2word2vec\n\n#Glove file - we are using model with 50 embedding size\nglove_input_file = \"..\/input\/gloveembeddings\/glove.6B.50d.txt\"\n\n#Name for word2vec file\nword2vec_output_file = 'glove.6B.50d.txt.word2vec'\n\n#Convert Glove embeddings to Word2Vec embeddings\nglove2word2vec(glove_input_file, word2vec_output_file)","9e88cc06":"### We will extract word embedding for which we are interested in; the pre trained has 400k words each with 50 embedding vector size.\nfrom gensim.models import Word2Vec, KeyedVectors\n\n# Load pretrained embedding model (in word2vec form)\nemd_model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n\n#Embedding length based on selected model - we are using 300d here.\nembedding_vector_length = 50","fd7c7be2":"#Initialize embedding matrix\nembedding_matrix = np.zeros((max_features + 1, embedding_vector_length))\nprint(embedding_matrix.shape)","9327889f":"for word, i in sorted(token.word_index.items(),key=lambda x:x[1]):\n    if i > (max_features+1):\n        break\n    try:\n        embedding_vector = emd_model[word] #Reading word's embedding from Glove model for a given word\n        embedding_matrix[i] = embedding_vector\n    except:\n        pass","5e075912":"embedding_matrix.shape","349db7f1":"### callbacks\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_root_mean_squared_error', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\nearly_stopping = EarlyStopping(min_delta=0.001,patience=5,restore_best_weights=True,verbose=1)","47bcc42e":"# A simple bidirectional LSTM with glove embeddings and one dense layer\nmodel = Sequential()\nmodel.add(Embedding(max_features+1,\n                    embedding_vector_length,\n                    weights=[embedding_matrix],\n                    input_length=maxlen, \n                    trainable=False))\nmodel.add(Bidirectional(LSTM(100, dropout=0.3, recurrent_dropout=0.3)))\nmodel.add(Dense(1,activation='linear'))\nmodel.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer='adam',metrics=tf.keras.metrics.RootMeanSquaredError())\nmodel.summary()","230a91c3":"history=model.fit(X_train_pad,y_train,\n          epochs=50,\n          batch_size=32,          \n          validation_data=(X_test_pad, y_test),\n          callbacks=[early_stopping,learning_rate_reduction])","8258971d":"get_acc = history.history['root_mean_squared_error']\nvalue_acc = history.history['val_root_mean_squared_error']\nget_loss = history.history['loss']\nvalidation_loss = history.history['val_loss']","433c6998":"# summarize history for metric\nfig=go.Figure()\nfig.add_trace(go.Scatter(x=[n for n in range(1,51)],\n                         y=get_acc,\n                         name=\"Training RMSE\",\n                         mode=\"markers+lines\",\n                         marker=dict(color='green',size=4)))\nfig.add_trace(go.Scatter(x=[n for n in range(1,50)],\n                         y=value_acc,\n                         name=\"Validation RMSE\",\n                         mode=\"markers+lines\",\n                         marker=dict(color='red',size=4)))\nfig.update_layout(title=\"Model Metric - Training and Validation\",\n                  xaxis_title=\"Epochs\",\n                  yaxis_title=\"RMSE value\",\n                  template=\"plotly_dark\"\n                 )\nfig.show()","ced6a1b1":"\n# summarize history for metric\nfig=go.Figure()\nfig.add_trace(go.Scatter(x=[n for n in range(1,51)],\n                         y=get_loss,\n                         name=\"Training Loss\",\n                         mode=\"markers+lines\",\n                         marker=dict(color='green',size=4)))\nfig.add_trace(go.Scatter(x=[n for n in range(1,51)],\n                         y=validation_loss,\n                         name=\"Validation Loss\",\n                         mode=\"markers+lines\",\n                         marker=dict(color='red',size=4)))\nfig.update_layout(title=\"Model Metric - Training and Validation\",\n                  xaxis_title=\"Epochs\",\n                  yaxis_title=\"Loss\",\n                  template=\"plotly_dark\"\n                 )\nfig.show()","28f6732f":"test.head()","1b470090":"test.shape","fa9ec369":"test_seq = token.texts_to_sequences(test['excerpt'])\ntest_pad = sequence.pad_sequences(test_seq, maxlen=maxlen,padding='post',truncating='post')","f00d5e4b":"prediction = model.predict(test_pad)","88dce609":"prediction","40970a7b":"submission.head()","a13b55b7":"submission[\"target\"] = prediction\nsubmission.to_csv(\"submission_v1.csv\", index=False)","eb9b513d":"submission.head()","3d6e4032":"### callbacks\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_root_mean_squared_error', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\nearly_stopping = EarlyStopping(min_delta=0.001,patience=5,restore_best_weights=True,verbose=1)","e2379571":"model1 = Sequential()\nmodel1.add(Embedding(max_features+1,\n                    embedding_vector_length, ### 50 here\n                    weights=[embedding_matrix],\n                    input_length=maxlen, ### 1400 here\n                    trainable=False))\nmodel1.add(SpatialDropout1D(0.3))\nmodel1.add(GRU(300))\nmodel1.add(Dense(1, activation='linear'))\nmodel1.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer='adam',metrics=tf.keras.metrics.RootMeanSquaredError())   \n\nmodel1.summary()","5000945a":"history1=model1.fit(X_train_pad,y_train,\n          epochs=50,\n          batch_size=32,          \n          validation_data=(X_test_pad, y_test),\n          callbacks=[early_stopping,learning_rate_reduction])","7a86ab8a":"get_acc1 = history1.history['root_mean_squared_error']\nvalue_acc1 = history1.history['val_root_mean_squared_error']\nget_loss1 = history1.history['loss']\nvalidation_loss1 = history1.history['val_loss']","1792849d":"# summarize history for metric\nfig=go.Figure()\nfig.add_trace(go.Scatter(x=[n for n in range(1,51)],\n                         y=get_acc1,\n                         name=\"Training RMSE\",\n                         mode=\"markers+lines\",\n                         marker=dict(color='green',size=4)))\nfig.add_trace(go.Scatter(x=[n for n in range(1,50)],\n                         y=value_acc1,\n                         name=\"Validation RMSE\",\n                         mode=\"markers+lines\",\n                         marker=dict(color='red',size=4)))\nfig.update_layout(title=\"Model Metric - Training and Validation\",\n                  xaxis_title=\"Epochs\",\n                  yaxis_title=\"RMSE value\",\n                  template=\"plotly_dark\"\n                 )\nfig.show()","3711584b":"# summarize history for metric\nfig=go.Figure()\nfig.add_trace(go.Scatter(x=[n for n in range(1,51)],\n                         y=get_loss1,\n                         name=\"Training Loss\",\n                         mode=\"markers+lines\",\n                         marker=dict(color='green',size=4)))\nfig.add_trace(go.Scatter(x=[n for n in range(1,51)],\n                         y=validation_loss1,\n                         name=\"Validation Loss\",\n                         mode=\"markers+lines\",\n                         marker=dict(color='red',size=4)))\nfig.update_layout(title=\"Model Metric - Training and Validation\",\n                  xaxis_title=\"Epochs\",\n                  yaxis_title=\"Loss\",\n                  template=\"plotly_dark\"\n                 )\nfig.show()","5312d4d7":"prediction1 = model1.predict(test_pad)","563f6c3c":"prediction1","aadb473c":"submission1=pd.read_csv(\"..\/input\/commonlitreadabilityprize\/sample_submission.csv\")\nsubmission1[\"target\"] = prediction1\nsubmission1.to_csv(\"submission.csv\", index=False)","1412ecf5":"### Tokenization and Indexing","e85d98e0":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Plots for Accuracy and Loss&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","f13f5430":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Import Libraries&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","109336d8":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Word Clouds&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","378964e4":"<br>\n<h1 style = \"font-size:40px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">CommonLit Readability<\/h1>\n<br>\n<img src=\"https:\/\/i.imgur.com\/mi9U6o5.png\">\n\n### <h3 style=\"color:#fe346e\">About the Problem<\/h3>\n\nCommonLit, Inc., is a nonprofit education technology organization serving over 20 million teachers and students with free digital reading and writing lessons for grades 3-12. Together with Georgia State University, an R1 public research university in Atlanta, they are challenging Kagglers to improve readability rating methods.\nIn this competition, you\u2019ll build algorithms to rate the complexity of reading passages for grade 3-12 classroom use. To accomplish this, you'll pair your machine learning skills with a dataset that includes readers from a wide variety of age groups and a large collection of texts taken from various domains. Winning models will be sure to incorporate text cohesion and semantics.\n\n### <h3 style=\"color:#fe346e\">Evaluation<\/h3>\n\nSubmissions are scored on the root mean squared error. RMSE is defined as:\n\n<img src=\"https:\/\/miro.medium.com\/max\/966\/1*lqDsPkfXPGen32Uem1PTNg.png\">","3fbca694":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Plot distribution of target values and Std.dev&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","635f5690":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Drop columns not required&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","477be09c":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Prediction on test&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","49183599":"### Load embedding file","143f7d48":"### Define max features and max len","6b1521bd":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Check for Outliers in Standard Error&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","34f96525":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Plots for Accuracy and Loss&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","30383c33":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Model Building : LSTM&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","e473bb11":"<div class=\"alert alert-success\">The above boxplot cum violin distribution plot for <b>Target<\/b> seems to show mean very close to median value","6e50e6b4":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Read dataset&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","2d75326c":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Model Building : GRU&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","1b31de86":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Check for Outliers in Target&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","ada422f2":"### Split the data into Train and Test","2a5e6510":"<div class=\"alert alert-success\">The above distribution plot for <b>Target<\/b> seems to have slight normal distribution whereas Standard error plot seems to show some right skewness","d0a14e54":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Cleaning the text data&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","61ca70b3":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Plot distribution of values&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","eaaf302e":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Prediction on test&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>","914e7a4d":"<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: navy;\">Check nulls and unique values&nbsp;&nbsp;&nbsp;&nbsp;<\/h1>"}}