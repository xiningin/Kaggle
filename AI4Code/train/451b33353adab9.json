{"cell_type":{"c988e7b2":"code","7bebe690":"code","ed166ac1":"code","df354244":"code","9b66718f":"code","876966b4":"code","43b9df0a":"code","33effa69":"code","b473481f":"code","3e05b8b9":"code","d5212b01":"code","45895882":"code","98d5e8cb":"code","d2377a78":"code","df7b2041":"code","1ac65c78":"code","8b7a1ad0":"code","20b8250a":"code","ff7116ae":"code","b25b0353":"code","d2423321":"code","4f47b908":"code","e089125c":"code","e1b08af3":"code","ad644186":"code","00efcab4":"code","5e853457":"code","839252c1":"code","3480c145":"code","9e4be058":"code","d6f4dc2f":"markdown","58638f75":"markdown","e309a886":"markdown","eee8c18f":"markdown","8a6da75f":"markdown","ac785228":"markdown","06e7b2a5":"markdown","e1cc1814":"markdown","7b597270":"markdown","8acb3415":"markdown","a5456569":"markdown","e417a2da":"markdown","3f13e240":"markdown","3e079854":"markdown","30e8cc97":"markdown","4cce9892":"markdown","30d2d1ef":"markdown","2201af76":"markdown","adb758ca":"markdown","7feff019":"markdown","8f024992":"markdown","b25ae1e5":"markdown","f701f51a":"markdown","b8a1e496":"markdown","925507f0":"markdown","98e8acdc":"markdown","e3791dbd":"markdown","c82cc944":"markdown","e78c067c":"markdown","990bf5f9":"markdown","fad00163":"markdown","61768e1a":"markdown","41d3cc65":"markdown","9938452c":"markdown"},"source":{"c988e7b2":"import numpy as np\nimport imageio\nimport os\nimport cv2 \nimport matplotlib.pyplot as plt\n\ndef load_img(name):\n    img = imageio.imread(name)\n    return img\n\ndef load_images():\n    img_directory = '..\/input\/pascal-voc-2007\/voctrainval_06-nov-2007\/VOCdevkit\/VOC2007\/JPEGImages\/'\n    arr = os.listdir(img_directory)\n    imgs = list()\n    for i,p in enumerate(arr):\n        img = load_img(img_directory+p)\n        imgs.append(np.array(img))\n    return np.array(imgs)\n\ndef resize_imgs(imgs, nrow=244,ncol=244):\n    output = []\n    for i, img in enumerate(imgs):\n        tmp = cv2.resize(img,dsize=(nrow,ncol))\n        output.append(tmp)\n    return np.array(output)\n\ndef plot(img_a , img_b, img_c):\n    fig = plt.figure(figsize=(20,20))\n    a = fig.add_subplot(1, 3, 1)\n    imgplot = plt.imshow(img_a)\n    a.set_title('72*72')\n    a = fig.add_subplot(1, 3, 2)\n    imgplot = plt.imshow(img_b)\n    a.set_title('144*144')\n    a = fig.add_subplot(1, 3, 3)\n    imgplot = plt.imshow(img_c)\n    a.set_title('288*288')\n\ndef better_plot(cols, imgs, titles, figsize=(20,20)):\n    fig = plt.figure(figsize=figsize)\n    for j in range(cols):\n        ax = fig.add_subplot(1, cols, j+1)\n        ax.set_title(titles[j])\n        plt.imshow(imgs[j])\n            \n\nimgs = load_images()\nprint(len(imgs),',',len(imgs[0]),',',len(imgs[0][0]) ,',',len(imgs[0][0][0]))\nresize_a = resize_imgs(imgs, 72, 72)\nresize_b = resize_imgs(imgs, 144, 144)\nresize_c = resize_imgs(imgs, 288, 288)\n\ntitles = ['72*72','144*144','288*288']\nlst = [resize_a[50],resize_b[50], resize_c[50]]\nbetter_plot(len(lst), lst, titles)","7bebe690":"def next_X(s,e):\n    while True:\n        for i, img in enumerate(resize_a[s:e]):\n            img = img \/ 255\n            yield img\n\ndef next_y_mid(s,e):\n    while True:\n        for i, img in enumerate(resize_b[s:e]):\n            img = img \/ 255\n            yield img\n\n        \ndef next_y_large(s,e):\n    while True:\n        for i, img in enumerate(resize_c[s:e]):\n            img = img \/ 255\n            yield img\n\ndef next_X_y_mid(s,e):\n    while True:\n        for i, (img_x, img_y) in enumerate(zip(resize_a[s:e],resize_b[s:e])):\n            img_x = img_x \/ 255\n            img_y = img_y \/ 255\n            yield np.expand_dims(img_x, axis=0), np.expand_dims(img_y, axis=0) \n        \ndef next_X_y_mid_large(s,e):\n    while True:\n        for i, (img_x, img_y_mid, img_y_large) in enumerate(zip(resize_a[s:e],resize_b[s:e],resize_c[s:e])):\n            img_x = img_x \/ 255\n            img_y_mid = img_y_mid \/ 255\n            img_y_large = img_y_large \/ 255\n            yield np.expand_dims(img_x, axis=0) , [np.expand_dims(img_y_mid, axis=0), np.expand_dims(img_y_large, axis=0)]\n\ndef next_y(s,e):\n    img_directory = '..\/input\/pascal-voc-2007\/voctrainval_06-nov-2007\/VOCdevkit\/VOC2007\/JPEGImages\/'\n    arr = os.listdir(img_directory)\n    while True:\n        for i, p in enumerate(arr[s:e]):\n            img = load_img(img_directory+p)\n            img = np.array(img)\n            yield img\n\ndef get_i_gen(gen, i):\n    while i > 0:\n        res = next(gen)\n        i -= 1\n    return res        \n\ndef new_gens(num_train=3600, num_val=900, num_max=5011):\n    X_train_2 = next_X_y_mid(0, num_train + num_val)\n    X_val_2 = next_X_y_mid(num_train, num_max)\n    X_test_2 = next_X_y_mid(num_train + num_val, num_max) #511 test sampels\n    X_train_3 = next_X_y_mid_large(0, num_train + num_val)\n    X_val_3 = next_X_y_mid_large(num_train, num_max)\n    X_test_3 = next_X_y_mid_large(num_train + num_val, num_max)\n    return X_train_2, X_val_2, X_test_2, X_train_3, X_val_3, X_test_3\n\nnum_train = 3600\nnum_val = 900\nnum_max = 5011  \nX_train_2, X_val_2, X_test_2, X_train_3, X_val_3, X_test_3 = new_gens()","ed166ac1":"import imageio\nfrom PIL import Image\nimport keras\nimport matplotlib.animation as animation\n\ndef plot_gif(cols, imgs, titles, figsize=(20,20), rows=2):\n    fig = plt.figure(figsize=figsize)\n    for j in range(cols):\n        ax = fig.add_subplot(rows, cols, j+1)\n        ax.set_title(titles[j])\n        plt.imshow(imgs[j])\n    plt.show()\n\n\nclass Gif(keras.callbacks.Callback):\n    \n    def __init__(self, img, model, name,  mode='double'):\n        super().__init__()\n        self.img = np.expand_dims(img, axis=0)\n        self.preds = []\n        self.model = model\n        self.name = name\n        self.mode = mode \n    \n    def on_epoch_end(self, batch, logs={}):\n        pred = model.predict(self.img)\n        self.preds.append(pred)\n        \n    def on_train_end(self, logs=None):\n        times = 12\n        size = (288, 288)\n        plot_imgs = []\n        imgs = []\n        imgs2 = []\n        for p in self.preds:\n            if self.mode == 'solo':\n                p = (p[0] * 255).astype(int)\n                plot_imgs.append(p)\n                for i in range(0,times):\n                    imgs.append(p)\n            elif self.mode =='double':\n                p0 = (p[0][0] * 255).astype(int)\n                p1 = (p[1][0] * 255).astype(int)\n                plot_imgs.append(p1)\n                for i in range(0,times):\n                    imgs.append(p0)\n                    imgs2.append(p1)\n        if self.mode == 'solo':       \n            imageio.mimsave('.\/'+self.name+'.gif', imgs)\n        elif self.mode =='double':\n            imageio.mimsave('.\/'+self.name+'_1.gif', imgs)\n            imageio.mimsave('.\/'+self.name+'_2.gif', imgs2)\n        self.show_plot(plot_imgs)\n            \n    def show_plot(self, imgs):\n        titles = []\n        for i in range(0, len(imgs)):\n            titles.append('epoc '+ str(i))\n        print(titles)\n        plot_gif(len(imgs), imgs, titles, figsize=(40,40))\n        ","df354244":"from keras.models import Sequential, Model\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import Input,Add, Activation, LeakyReLU, Concatenate, Dense, Conv2D, UpSampling2D, Lambda\nimport keras.backend as K ","9b66718f":"def PSNR(real, pred):\n    max_val = 1.0\n    alpha = 10.0\n    div = 2.303\n    p = 2\n    inner = (max_val ** p) \/ K.mean(K.square(pred - real), axis=-1)\n    return (alpha * K.log(inner)) \/ div\n                                    \ndef get_metrics():\n    return [PSNR]\n                                    \ndef get_callbacks(model, name, mode='double'):\n    img = resize_a[50] \/ 255\n    early_stopping_monitor = EarlyStopping(patience=2) \n    gifer = Gif(img, model, name, mode=mode)\n    return [early_stopping_monitor, gifer]","876966b4":"X_train_2, X_val_2, X_test_2, X_train_3, X_val_3, X_test_3 = new_gens()\n\ndef create_model():\n    model = Sequential()\n    model.add( Conv2D(64, kernel_size=(3,3), padding='same', activation='relu',input_shape =(72,72,3)))\n    model.add( Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'))\n    model.add( UpSampling2D(size=(2,2)))\n    model.add( Conv2D(3, kernel_size=(1,1), activation='relu'))\n    model.compile(loss='mse', optimizer='adam', metrics=get_metrics())\n    model.summary()\n    return model\n\nmodel = create_model()\n\ncallbacks = get_callbacks(model ,'model1', 'solo')\nhistory = model.fit_generator(X_train_2, steps_per_epoch=64, epochs=10, validation_data=X_val_2, validation_steps = 64,  callbacks=callbacks)","43b9df0a":"def quick_plot_history(history):\n    # Plot training & validation loss values\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n    plt.show()\n    \nquick_plot_history(history)\n    ","33effa69":"def quick_plot_PSNR(history):\n    # Plot training & validation loss values\n    plt.plot(history.history['PSNR'])\n    plt.plot(history.history['val_PSNR'])\n    plt.title('Model loss')\n    plt.title('Model PSNR')\n    plt.ylabel('PSNR')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n    plt.show()\n    \nquick_plot_PSNR(history)  ","b473481f":"X_train_2, X_val_2, X_test_2, X_train_3, X_val_3, X_test_3 = new_gens()\nX_print = next_X(num_train + num_val, num_max)\n# preds = model.predict(X_train[80:])\npreds = model.predict_generator(X_test_2, 511)\nlst = [(next(X_print) * 255).astype(int), (preds[0]* 255) .astype(int)]\ntitles = ['72*72','144*144']\nbetter_plot(len(lst), lst, titles)","3e05b8b9":"X_train_2, X_val_2, X_test_2, X_train_3, X_val_3, X_test_3 = new_gens()\n\ndef create_model_2():\n    inp = Input(shape=(None,None,3), name='input')\n    x = Conv2D(64, kernel_size=(3,3), padding='same', activation='relu')(inp)\n    x = Conv2D(64, kernel_size=(3,3), padding='same', activation='relu')(x)\n    x = UpSampling2D(size=(2,2))(x)\n    y = UpSampling2D(size=(2,2))(x)\n    y = Conv2D(3, kernel_size=(1,1), activation='relu', name='output1')(y)\n    x = Conv2D(3, kernel_size=(1,1), activation='relu', name='output2')(x)\n    \n    model = Model(inputs=inp,outputs=[x,y])\n    model.compile(loss='mse', optimizer='adam', metrics=get_metrics())\n    model.summary()\n    return model\n\nmodel = create_model_2()\ncallbacks = get_callbacks(model, 'model2')\n\nhistory = model.fit_generator(X_train_3, steps_per_epoch=64, epochs=10, validation_data=X_val_3, validation_steps = 64,  callbacks=callbacks)","d5212b01":"def quick_plot_history_3(history, name_conv1, name_conv2):\n    plt.plot(history.history['loss'])\n    plt.plot(history.history[name_conv1])\n    plt.plot(history.history[name_conv2])\n    plt.plot(history.history['val_loss'])\n    plt.plot(history.history['val_'+name_conv1])\n    plt.plot(history.history['val_'+name_conv2])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Train_144x144','Train_288x288', 'Val','Val_144x144', 'Val_288x288'], loc='upper left')\n    plt.show()\n    \nquick_plot_history_3(history,'output1_loss', 'output2_loss')","45895882":"def quick_plot_PSNR_3(history):\n    # Plot training & validation loss values\n    plt.plot(history.history['output2_PSNR'])\n    plt.plot(history.history['output1_PSNR'])\n    plt.plot(history.history['val_output2_PSNR'])\n    plt.plot(history.history['val_output1_PSNR'])\n    plt.title('Model PSNR')\n    plt.ylabel('PSNR')\n    plt.xlabel('Epoch')\n    plt.legend(['Train 2 PSNR','Train 1 PSNR' ,'Val 2 PSNR','Val 1 PSNR'], loc='upper left')\n    plt.show()\n\nquick_plot_PSNR_3(history)","98d5e8cb":"def visual_model(model, index = 5):\n    X_train_2, X_val_2, X_test_2, X_train_3, X_val_3, X_test_3 = new_gens()\n    X_print = next_X(num_train + num_val, num_max)\n    y_mid = next_y_mid(num_train + num_val, num_max)\n    y_large = next_y_large(num_train + num_val, num_max)\n    preds = model.predict_generator(X_test_3, 511)\n    titles = ['input 72*72','original 144*144','pred 144*144','original 288*288','pred 288*288']\n    lst = [(get_i_gen(X_print, index) * 255).astype(int), (get_i_gen(y_mid, index) * 255).astype(int) , (preds[0][index-1] * 255).astype(int) ,\n            (get_i_gen(y_large, index) * 255).astype(int), (preds[1][index-1] * 255).astype(int)]\n    better_plot(len(lst), lst, titles)\n\nvisual_model(model)","d2377a78":"X_train_2, X_val_2, X_test_2, X_train_3, X_val_3, X_test_3 = new_gens()\n\ndef create_residual(h,w,z=32):\n    inp = Input(shape=(h,w,z), name='input')\n    x = Conv2D(32, kernel_size=(3,3), padding='same', activation='relu')(inp)\n    x = Conv2D(32, kernel_size=(3,3), padding='same', activation='relu')(x)\n    x = Add()([inp,x])\n    x = Activation('relu')(x)\n    return Model(inputs=inp,outputs=[x])\n\ndef create_model_3(h=None,w=None):\n    inp = Input(shape=(h,w,3), name='input')\n    x = Conv2D(32, kernel_size=(3,3),padding='same', activation='relu')(inp)\n    x = create_residual(h,w)(x)\n    x = create_residual(h,w)(x)\n    x = UpSampling2D(size=(2,2))(x)\n    y = create_residual(h,w)(x)\n    y = UpSampling2D(size=(2,2))(y)\n    y = Conv2D(3, kernel_size=(1,1), activation='relu', name='output1')(y)\n    x = Conv2D(3, kernel_size=(1,1), activation='relu', name='output2')(x)\n    model = Model(inputs=inp,outputs=[x,y])\n    model.compile(loss='mse', optimizer='adam',metrics=get_metrics())\n    model.summary()\n    return model\n\nmodel = create_model_3()\n\ncallbacks = get_callbacks(model, 'model3')\n\nhistory = model.fit_generator(X_train_3, steps_per_epoch=64, epochs=10, validation_data=X_val_3, validation_steps = 64,  callbacks=callbacks)","df7b2041":"quick_plot_history_3(history,'output1_loss', 'output2_loss')","1ac65c78":"quick_plot_PSNR_3(history)","8b7a1ad0":"visual_model(model)","20b8250a":"X_train_2, X_val_2, X_test_2, X_train_3, X_val_3, X_test_3 = new_gens()\n\ndef create_delayed(h,w,z=32):\n    inp = Input(shape=(h,w,z), name='input')\n    x1 = Conv2D(32, kernel_size=(3,3), padding='same', dilation_rate = (1,1), activation=LeakyReLU(0.2))(inp)\n    x2 = Conv2D(32, kernel_size=(3,3), padding='same', dilation_rate = (2,2), activation=LeakyReLU(0.2))(inp)\n    x3 = Conv2D(32, kernel_size=(3,3), padding='same', dilation_rate = (4,4), activation=LeakyReLU(0.2))(inp)\n    x = Concatenate()([x1,x2,x3])\n    x = Activation('relu')(x)\n    x = Conv2D(32, kernel_size=(3,3), padding='same', activation='relu')(x)\n    return Model(inputs=inp,outputs=[x])\n\ndef create_model_4(h=None,w=None):\n    inp = Input(shape=(h,w,3), name='input')\n    x = Conv2D(32, kernel_size=(3,3),padding='same', activation=LeakyReLU(0.2))(inp)\n    x = create_delayed(h,w)(x)\n    x = create_delayed(h,w)(x)\n    x = UpSampling2D(size=(2,2))(x)\n    y = create_delayed(h,w)(x)\n    y = UpSampling2D(size=(2,2))(y)\n    y = Conv2D(3, kernel_size=(1,1), activation='relu', name='output1')(y)\n    x = Conv2D(3, kernel_size=(1,1), activation='relu', name='output2')(x)\n    model = Model(inputs=inp,outputs=[x,y])\n    model.compile(loss='mse', optimizer='adam',metrics=get_metrics())\n    model.summary()\n    return model\n\nmodel = create_model_4()\n\ncallbacks = get_callbacks(model, 'model4')\nhistory = model.fit_generator(X_train_3, steps_per_epoch=64, epochs=10, validation_data=X_val_3, validation_steps = 64,  callbacks=callbacks)","ff7116ae":"quick_plot_history_3(history,'output1_loss', 'output2_loss')","b25b0353":"quick_plot_PSNR_3(history)","d2423321":"visual_model(model)","4f47b908":"from tensorflow import keras\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.layers import Input,Add, Activation, LeakyReLU, Concatenate\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Input, Conv2D, UpSampling2D, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nvgg = VGG16(weights='imagenet', include_top=False, input_shape = (None,None, 3))\nvgg = Model(inputs=vgg.input,outputs=vgg.get_layer(\"block1_conv2\").output)","e089125c":"X_train_2, X_val_2, X_test_2, X_train_3, X_val_3, X_test_3 = new_gens()\nearly_stopping_monitor = EarlyStopping(patience=2) \n\ndef create_model_5(h=None,w=None):\n    inp = Input(shape=(h,w,3), name='input')\n    x1 = Conv2D(64, kernel_size=(3,3),padding='same', activation=LeakyReLU(0.8))(inp)\n    x1 = Conv2D(64, kernel_size=(3,3),padding='same', activation=LeakyReLU(0.8))(x1)\n    x2 = vgg(inp)\n    x = Concatenate()([x1, x2])\n    x = UpSampling2D(size=(2,2))(x)\n    x = Conv2D(3, kernel_size=(1,1), activation=LeakyReLU(0.2),name='output1')(x)\n    y = UpSampling2D(size=(2,2))(x)\n    y = Conv2D(3, kernel_size=(1,1), activation=LeakyReLU(0.2), name='output2')(y)\n    model = Model(inputs=inp,outputs=[x,y])\n    model.compile(loss='mse', optimizer='adam',metrics=get_metrics())\n    model.summary()\n    return model\n\nmodel = create_model_5()\n\ncallbacks = get_callbacks(model, 'model5')\n\nhistory = model.fit_generator(X_train_3, steps_per_epoch=64, epochs=10, validation_data=X_val_3, validation_steps = 64,  callbacks=callbacks)","e1b08af3":"quick_plot_history_3(history,'output1_loss', 'output2_loss')","ad644186":"quick_plot_PSNR_3(history)","00efcab4":"visual_model(model)","5e853457":"import tensorflow as tf\n\nX_train_2, X_val_2, X_test_2, X_train_3, X_val_3, X_test_3 = new_gens()\n\ndef create_model_6(h=None,w=None):\n    inp = Input(shape=(h,w,3), name='input')\n    x1 = Conv2D(64, kernel_size=(3,3),padding='same',  activation=LeakyReLU(0.3))(inp)\n    x1 = Conv2D(64, kernel_size=(3,3),padding='same',  activation=LeakyReLU(0.3))(x1)\n    x2 = vgg(inp)\n    x = Concatenate()([x1, x2])\n    x = tf.keras.layers.Lambda(lambda x: tf.nn.depth_to_space(x, 2))(x)\n    x = Conv2D(3, kernel_size=(1,1), activation=LeakyReLU(0.2), name='output1')(x)\n    y = Conv2D(12, kernel_size=(1,1), activation=LeakyReLU(0.2))(x)\n    y = tf.keras.layers.Lambda(lambda x: tf.nn.depth_to_space(x, 2))(y)\n    y = Conv2D(3, kernel_size=(1,1), activation=LeakyReLU(0.05), name='output2')(y) # \n    model = Model(inputs=inp,outputs=[x,y])\n    model.compile(loss='mse', optimizer='adam', metrics=get_metrics())\n    model.summary()\n    return model\n\nmodel = create_model_6()\n\nmetrics=get_metrics()\ncallbacks = get_callbacks(model, 'model6')\n\nhistory = model.fit_generator(X_train_3, steps_per_epoch=64, epochs=10, validation_data=X_val_3, validation_steps = 64,  callbacks=callbacks)","839252c1":"quick_plot_history_3(history,'output1_loss', 'output2_loss')","3480c145":"quick_plot_PSNR_3(history)","9e4be058":"visual_model(model)","d6f4dc2f":"# **Step 1: creating the data**\n### We will use the data of pascal voc 2007 images\n### We will create 3 sup sets of images sizes: 288x288, 144x144, 72x72","58638f75":"## anaylze model2","e309a886":"## note that the arrays we resized isn't holding a normolaized data. only the value between 0 - 255 of rgb","eee8c18f":"# Image super-resolution Task - Fully convolutional networks ","8a6da75f":"## we will first need to scale down the images for getting better results. However there are to many images, so we will use genrators.","ac785228":"## analyze model6","06e7b2a5":"## define metricses and callbacks","e1cc1814":"## view results model1","7b597270":"## defining the model2","8acb3415":"## PSNR table: \n### model3 the best of train, model2 the best of the val\n![image.png](attachment:image.png)\n## gifs in the folder","a5456569":"# model 1:","e417a2da":"# Step 2 - create an initial fully convolutional model","3f13e240":"## creating model6","3e079854":"## analyze model 1:","30e8cc97":"## Extra callback: Creating a gif callback analyzer\n","4cce9892":"## anaylze model4:","30d2d1ef":"# Step 4: adding a residual blocks ","2201af76":"## view model6 results","adb758ca":"## view results model2","7feff019":"# Step 6 - Adding pretrained network","8f024992":"## creating model5","b25ae1e5":"# Step 5 - replacing residual blocks with conv blocks","f701f51a":"## using vgg16 as our pretranied model ","b8a1e496":"# imports for the model","925507f0":"## analyze model5","98e8acdc":"## creating model4","e3791dbd":"# The validation stratgy is to split to train, & val","c82cc944":"<table>\n    <tr> \n        <th><\/th>\n    <\/tr>","e78c067c":"# Step 3: create an initial fully convolutional model with 2 output chanels","990bf5f9":"## view model4 results","fad00163":"# creating the model3","61768e1a":"## anaylze model3","41d3cc65":"# Step 7 - replacing Upsampling with depth_to_space","9938452c":"## view results model3"}}