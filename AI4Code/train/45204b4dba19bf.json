{"cell_type":{"b209ba94":"code","b019f490":"code","14342bb3":"code","228f79fd":"code","e4d16c72":"code","33b1b05b":"code","1183cb85":"code","2bf9fcd8":"code","8dfa75b2":"code","4fc7f866":"code","e878ccf4":"code","11b08a79":"code","6411bfbf":"code","5973b76e":"code","35835222":"code","57b711cb":"code","22db4596":"code","e8786903":"code","5a38f262":"code","2bf5ddea":"code","3e230b8c":"code","afaa944b":"code","a003bb8f":"code","cd4242d6":"code","d1ab33a4":"code","7835c294":"code","ad9b64d3":"code","bb60261d":"code","23aef87a":"code","77692d7f":"code","4d896042":"code","82d5b270":"code","906704ae":"code","191e78d5":"code","23eaf05f":"code","8bce64fd":"code","e50f72b1":"code","57e570fd":"code","a3348869":"code","513da36d":"code","e749d73d":"code","3d5eedfe":"code","962941e0":"code","ece822d2":"code","eece5491":"code","e480d9bc":"code","17125b80":"code","5f3e3433":"code","6dff9e9e":"code","8b53d425":"code","ebeadce1":"code","965e46b9":"code","1b4600c8":"code","dcabd16a":"markdown","ceb3f44c":"markdown","26fa28a1":"markdown","93bd5d54":"markdown","3a88f08f":"markdown","30dde8a0":"markdown","c87d7bc4":"markdown","07b8a795":"markdown","e5c3af6d":"markdown","6b97691f":"markdown"},"source":{"b209ba94":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b019f490":"import sys\nassert sys.version_info >= (3, 5)\n\n# \uc0ac\uc774\ud0b7\ub7f0 \u22650.20 \ud544\uc218\nimport sklearn\nassert sklearn.__version__ >= \"0.20\"\n\n# \ud150\uc11c\ud50c\ub85c \u22652.0 \ud544\uc218\nimport tensorflow as tf\nassert tf.__version__ >= \"2.0\"","14342bb3":"tf.__version__","228f79fd":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n","e4d16c72":"from sklearn.datasets import load_iris\nfrom sklearn.linear_model import Perceptron","33b1b05b":"iris = load_iris()\nX = iris.data[:, (2, 3)] # petal length, petal width\ny = (iris.target == 0).astype(np.int) # iris Setosa?\n\nper_clf = Perceptron(max_iter = 1000, tol = 1e-3, random_state=42)\nper_clf.fit(X, y)\n\ny_pred = per_clf.predict([[2, 0.5]])","1183cb85":"y_pred","2bf9fcd8":"def sigmoid(z):\n    return 1 \/ (1 + np.exp(-z))\n\ndef relu(z):\n    return np.maximum(0, z)\n\ndef derivative(f, z, eps=0.000001):\n    return (f(z + eps) - f(z - eps)) \/ (2 * eps)","8dfa75b2":"z = np.linspace(-5, 5, 200)\n\nplt.figure(figsize=(11, 4))\n\nplt.subplot(121)\nplt.plot(z, np.sign(z), \"r-\", linewidth=1, label=\"Step\")\nplt.plot(z, sigmoid(z), \"g--\", linewidth=2, label=\"Sigmoid\")\nplt.plot(z, np.tanh(z), \"b-\", linewidth=2, label=\"Tanh\")\nplt.plot(z, relu(z), \"m-.\", linewidth=2, label=\"ReLU\")\nplt.grid(True)\nplt.legend(loc=\"center right\", fontsize=14)\nplt.title(\"Activation functions\", fontsize=14)\nplt.axis([-5, 5, -1.2, 1.2])\n\nplt.subplot(122)\nplt.plot(z, derivative(np.sign, z), \"r-\", linewidth=1, label=\"Step\")\nplt.plot(0, 0, \"ro\", markersize=5)\nplt.plot(0, 0, \"rx\", markersize=10)\nplt.plot(z, derivative(sigmoid, z), \"g--\", linewidth=2, label=\"Sigmoid\")\nplt.plot(z, derivative(np.tanh, z), \"b-\", linewidth=2, label=\"Tanh\")\nplt.plot(z, derivative(relu, z), \"m-.\", linewidth=2, label=\"ReLU\")\nplt.grid(True)\n#plt.legend(loc=\"center right\", fontsize=14)\nplt.title(\"Derivatives\", fontsize=14)\nplt.axis([-5, 5, -0.2, 1.2])\n\nplt.show()","4fc7f866":"from tensorflow import keras","e878ccf4":"keras.__version__","11b08a79":"fasion_mnist = keras.datasets.fashion_mnist\n(X_train_full, y_train_full), (X_test, y_test) = fasion_mnist.load_data()","6411bfbf":"X_train_full.shape","5973b76e":"X_valid, X_train = X_train_full[:5000] \/ 255., X_train_full[5000:] \/ 255.\ny_valid, y_train = y_train_full[:5000], y_train_full[5000:]\nX_test = X_test \/ 255.","35835222":"plt.imshow(X_train[0], cmap='binary')\nplt.axis('off')\nplt.show()","57b711cb":"y_train","22db4596":"class_names = [\"T-shirt\/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]","e8786903":"n_rows = 4\nn_cols = 10\nplt.figure(figsize=(n_cols * 1.2, n_cols * 1.2))\nfor row in range(n_rows):\n    for col in range(n_cols):\n        index = n_cols * row + col\n        plt.subplot(n_rows, n_cols, index + 1)\n        plt.imshow(X_train[index], cmap='binary', interpolation='nearest')\n        plt.axis('off')\n        plt.title(class_names[y_train[index]], fontsize=12)\n\nplt.subplots_adjust(wspace=0.2, hspace=0.5)\nplt.show()","5a38f262":"model = keras.models.Sequential()\nmodel.add(keras.layers.Flatten(input_shape=[28, 28]))\nmodel.add(keras.layers.Dense(300, activation='relu'))\nmodel.add(keras.layers.Dense(100, activation='relu'))\nmodel.add(keras.layers.Dense(10, activation='softmax'))","2bf5ddea":"keras.backend.clear_session()\nnp.random.seed(42)\ntf.random.set_seed(42)","3e230b8c":"model = keras.models.Sequential([\n    keras.layers.Flatten(input_shape=[28, 28]),\n    keras.layers.Dense(300, activation=\"relu\"),\n    keras.layers.Dense(100, activation=\"relu\"),\n    keras.layers.Dense(10, activation=\"softmax\")\n])","afaa944b":"model.summary()","a003bb8f":"keras.utils.plot_model(model, show_shapes=True)","cd4242d6":"hidden1 = model.layers[1]\nhidden1.name","d1ab33a4":"weights, biases = hidden1.get_weights()","7835c294":"weights","ad9b64d3":"biases","bb60261d":"model.compile(loss = keras.losses.sparse_categorical_crossentropy,\n             optimizer = keras.optimizers.SGD(),\n             metrics = [keras.metrics.sparse_categorical_accuracy])","23aef87a":"history = model.fit(X_train, y_train, epochs = 30, \n                   validation_data=(X_valid, y_valid))","77692d7f":"pd.DataFrame(history.history).plot(figsize = (15, 5))\nplt.grid(True)\nplt.gca().set_ylim(0, 1)\n\nplt.show()","4d896042":"model.evaluate(X_test, y_test)","82d5b270":"X_new = X_test[:3]\ny_proba = model.predict(X_new)\ny_proba.round(2)","906704ae":"y_pred = np.argmax(model.predict(X_new), axis=-1)\ny_pred","191e78d5":"from sklearn.datasets import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","23eaf05f":"housing = fetch_california_housing()\n\nX_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\nX_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_valid = scaler.fit_transform(X_valid)\nX_test = scaler.fit_transform(X_test)","8bce64fd":"model = keras.models.Sequential([\n    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n    keras.layers.Dense(1)\n])\nmodel.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\nhistory = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\nmse_test = model.evaluate(X_test, y_test)\nX_new = X_test[:3]\ny_pred = model.predict(X_new)","e50f72b1":"plt.plot(pd.DataFrame(history.history))\nplt.grid(True)\nplt.gca().set_ylim(0, 1)\nplt.show()","57e570fd":"model = keras.models.Sequential([\n    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n    keras.layers.Dense(30, activation=\"relu\"),\n    keras.layers.Dense(1)\n])    ","a3348869":"model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\nhistory = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\nmse_test = model.evaluate(X_test, y_test)","513da36d":"model.save('my_keras_model.h5')","e749d73d":"model = keras.models.load_model('my_keras_model.h5')","3d5eedfe":"model.predict(X_new)","962941e0":"model.save_weights(\"my_keras_weights.ckpt\")","ece822d2":"model.load_weights(\"my_keras_weights.ckpt\")","eece5491":"keras.backend.clear_session()","e480d9bc":"model = keras.models.Sequential([\n    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n    keras.layers.Dense(30, activation=\"relu\"),\n    keras.layers.Dense(1)\n])    ","17125b80":"model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\ncheckpoint_cb = keras.callbacks.ModelCheckpoint('my_keras_model.h5', save_best_only=True)\nhistory = model.fit(X_train, y_train, epochs = 10,\n                   validation_data=(X_valid, y_valid),\n                   callbacks=[checkpoint_cb])\n\nmodel = keras.models.load_model('my_keras_model.h5')\nmse_test = model.evaluate(X_test, y_test)","5f3e3433":"import os","6dff9e9e":"root_logdir = os.path.join(os.curdir, 'my_logs')","8b53d425":"def get_run_logdir():\n    import time\n    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n    return os.path.join(root_logdir, run_id)\n\nrun_logdir = get_run_logdir()\nrun_logdir","ebeadce1":"keras.backend.clear_session()\nmodel = keras.models.Sequential([\n    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n    keras.layers.Dense(30, activation=\"relu\"),\n    keras.layers.Dense(1)\n])    \nmodel.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))","965e46b9":"tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\nhistory = model.fit(X_train, y_train, epochs=30,\n                    validation_data=(X_valid, y_valid),\n                    callbacks=[checkpoint_cb, tensorboard_cb])","1b4600c8":"%reload_ext tensorboard\n%tensorboard --logdir=.\/my_logs --port=6006\n!kill 440","dcabd16a":"# Tensorboard","ceb3f44c":"# Callback","26fa28a1":"* Unlike logistic regression classifiers, perceptrons do not provide class probabilities and make predictions based on fixed threshold values.","93bd5d54":"## Data Load","3a88f08f":"# Image Classification with Keras","30dde8a0":"# Perceptron","c87d7bc4":"# Save and Load","07b8a795":"# Regression MLP","e5c3af6d":"or","6b97691f":"# Activation Function"}}