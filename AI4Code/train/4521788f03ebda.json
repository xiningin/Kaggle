{"cell_type":{"790b479d":"code","aab2e48d":"code","f956339e":"code","a4f3b398":"code","705d1f75":"code","97676060":"code","cf1d8255":"code","f4d00514":"code","c6d2f109":"code","c402fda9":"code","f5ec0cc6":"code","79312c1c":"code","c42495fd":"code","ee8f7c38":"code","0065b34e":"code","dcfdf560":"code","bda2d9fe":"code","ef95955b":"code","a8971003":"code","56d0da0f":"code","15f82d05":"code","5d7ea9cd":"code","1fbad526":"code","072ad8bf":"code","26968900":"code","87110bb6":"code","ffb92e24":"code","f752916f":"code","58a477cd":"code","d57eeaf4":"code","c392d985":"code","62ee0713":"code","137757f7":"code","7d13ff47":"code","31d808a2":"code","944d8aef":"code","31b78405":"markdown","7ac30ad1":"markdown","73903c98":"markdown","4d050799":"markdown","1573eedd":"markdown","b52c07b9":"markdown","9586a1a9":"markdown","a59948aa":"markdown","f7c74929":"markdown","11637ad9":"markdown","421ffeb3":"markdown"},"source":{"790b479d":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix,accuracy_score\nfrom sklearn.metrics import classification_report\n\nsampleEntry = pd.read_csv('..\/input\/sampleEntry.csv')\ndf = pd.read_csv('..\/input\/cs-training.csv')\ntest = pd.read_csv('..\/input\/cs-test.csv')\ntest.head()","aab2e48d":"# descriptive statistics\ndf.describe()","f956339e":"# renaming model columns\ndf.rename(columns={'Unnamed: 0':'Id',\n                          'SeriousDlqin2yrs':'Default'}, \n                 inplace=True)","a4f3b398":"# count of null values across variables\ndf.isnull().sum()","705d1f75":"test.isnull().sum()","97676060":"# fill na values appropriately\ndf['MonthlyIncome'].fillna(df['MonthlyIncome'].mean(),inplace=True)\ndf['NumberOfDependents'].fillna(test['NumberOfDependents'].mode()[0], inplace=True)\n\n# check\ndf.isnull().sum()","cf1d8255":"# maybe change color scheme\ncor=df.corr()\nfig, ax = plt.subplots(figsize=(12,12))\nsns.heatmap(cor,xticklabels=cor.columns,yticklabels=cor.columns,annot=True,ax=ax)","f4d00514":"sns.countplot(x='Default',data=df,palette='RdBu_r')\nplt.title('Default Outcomes')\nprint(\"Percentage of People Who Defaulted: {}%\".format(df[\"Default\"].sum()*100 \/ len(df)))\n","c6d2f109":"sns.kdeplot(df.loc[df[\"Default\"] == 0][\"age\"], label=\"Not in Default\")\nsns.kdeplot(df.loc[df[\"Default\"] == 1][\"age\"], label=\"In Default\")\nplt.xlabel('Age')\nplt.title('Distribuition of Default Rate by Age')","c402fda9":"sns.distplot(df.MonthlyIncome)","f5ec0cc6":"import statsmodels.formula.api as sm\n\ndef vif_cal(input_data, dependent_col):\n    x_vars=input_data.drop([dependent_col], axis=1)\n    xvar_names=x_vars.columns\n    for i in range(0,xvar_names.shape[0]):\n        y=x_vars[xvar_names[i]] \n        x=x_vars[xvar_names.drop(xvar_names[i])]\n        rsq=sm.ols(formula=\"y~x\", data=x_vars).fit().rsquared  \n        vif=round(1\/(1-rsq),2)\n        print (xvar_names[i], \" VIF = \" , vif)\n        \n#Calculating VIF values using that function\nvif_cal(input_data=df, dependent_col=\"Default\")","79312c1c":"# splitting data into train and test set\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.preprocessing import StandardScaler\n\nfeatures=['RevolvingUtilizationOfUnsecuredLines','age','NumberOfTime30-59DaysPastDueNotWorse','DebtRatio','MonthlyIncome','DebtRatio','MonthlyIncome','NumberOfOpenCreditLinesAndLoans','NumberRealEstateLoansOrLines','NumberOfDependents']\ndep=['Default']\nx=df[features]\ny=df[dep]\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n\n\n#\nscaler = StandardScaler()\nscaler.fit(x_train.fillna(0))\nsel_ = SelectFromModel(LogisticRegression(C=1, penalty='l1'))\nsel_.fit(scaler.transform(x_train.fillna(0)), y_train)\nsel_.get_support()","c42495fd":"# splitting data into train and test set\nfrom sklearn.feature_selection import SelectFromModel\n\nfeatures=['RevolvingUtilizationOfUnsecuredLines','age','NumberOfTime30-59DaysPastDueNotWorse','MonthlyIncome','DebtRatio','MonthlyIncome','NumberOfOpenCreditLinesAndLoans','NumberRealEstateLoansOrLines','NumberOfDependents']\ndep=['Default']\nx=df[features]\ny=df[dep]\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n\nlogmodel = LogisticRegression()\nlogmodel.fit(x_train, y_train)\nimport sklearn.metrics as metrics\n\n# implementing model and scoring\npredictions = logmodel.predict(x_test)\nprint(classification_report(y_test, predictions))\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, predictions))\n","ee8f7c38":"import scikitplot as skplt\nskplt.metrics.plot_confusion_matrix(y_test,predictions,figsize=(6,6))","0065b34e":"# roc curve and auc\nfrom sklearn.datasets import make_classification\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom matplotlib import pyplot\n# generate 2 class dataset\nfeatures=['RevolvingUtilizationOfUnsecuredLines','age','NumberOfTime30-59DaysPastDueNotWorse','DebtRatio','MonthlyIncome']\ndep=['Default']\nx=df[features]\ny=df[dep]\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n# fit a model\nlogmodel = LogisticRegression()\nlogmodel.fit(x_train, y_train)\n# generate a no skill prediction (majority class)\nns_probs = [0 for _ in range(len(y_test))]\n# predict probabilities\nlr_probs = logmodel.predict_proba(x_test)\n# keep probabilities for the positive outcome only\nlr_probs = lr_probs[:, 1]\n# calculate scores\nns_auc = roc_auc_score(y_test, ns_probs)\nlr_auc = roc_auc_score(y_test, lr_probs)\n# summarize scores\nprint('Random Classifier: ROC AUC=%.3f' % (ns_auc))\nprint('Logistic: ROC AUC=%.3f' % (lr_auc))\n# calculate roc curves\nns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\nlr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n# plot the roc curve for the model\npyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='Random Classifier')\npyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n# axis labels\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\n# show the legend\npyplot.legend()\n# show the plot\npyplot.show()","dcfdf560":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(x_train,y_train)","bda2d9fe":"y_pred2 = knn.predict_proba(x_train)\ny_pred2 = y_pred2[:,1]\n","ef95955b":"from sklearn.metrics import auc,roc_curve\nfpr,tpr,_ = roc_curve(y_train, y_pred2)\nroc_auc = auc(fpr, tpr)\nplt.figure(figsize=(10,8))\nplt.title('Receiver Operating Characteristic')\nsns.lineplot(fpr, tpr, label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","a8971003":"test=pd.read_csv('..\/input\/cs-test.csv')","56d0da0f":"print(test.isnull().sum())","15f82d05":"test['MonthlyIncome'].fillna(test['MonthlyIncome'].mean(),inplace=True)","5d7ea9cd":"xtest=test[features]","1fbad526":"xtest.head()","072ad8bf":"ytest=logmodel.predict_proba(xtest)","26968900":"print(ytest)","87110bb6":"testing=pd.DataFrame(ytest,columns=['Id','Probability'])","ffb92e24":"testing.head()","f752916f":"dataf=pd.DataFrame(ytest,columns=['Id','Probability'])\n\ndataf.head()","58a477cd":"export_csv = df.to_csv('export_dataframe.csv',index = None,header=True)","d57eeaf4":"from sklearn.preprocessing import StandardScaler\nfrom imblearn.over_sampling import SMOTE\n# Data\nX = df[['RevolvingUtilizationOfUnsecuredLines','age','NumberOfTime30-59DaysPastDueNotWorse','DebtRatio','MonthlyIncome','NumberOfOpenCreditLinesAndLoans','NumberOfTimes90DaysLate','NumberRealEstateLoansOrLines','NumberOfTime60-89DaysPastDueNotWorse']]\ny = df['Default']\n\n# Data standarlization\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n\n# Create StandardScaler instance and fit_trainsform\nsc = StandardScaler()\nX_train_std = sc.fit_transform(X_train)\nX_test_std = sc.fit_transform(X_test)\n\n# Create SMOTE instance\nsmote = SMOTE(sampling_strategy=\"auto\", random_state=10)\n\n# data split\nX_train_resampled, y_train_resampled = smote.fit_sample(X_train_std, y_train)","c392d985":"# Create logistic regression instance\nlr = LogisticRegression()\n\nfrom sklearn.model_selection import GridSearchCV\n# Grid search\nparam_range = [0.001, 0.01, 0.1, 1.0, 10, 100]\npenalty = ['l1', 'l2']\nparam_grid = [{\"C\":param_range, \"penalty\":penalty}]\n\ngs = GridSearchCV(estimator=lr, param_grid=param_grid, scoring=\"recall\", cv=10, n_jobs=-1)\ngs = gs.fit(X_train_resampled, y_train_resampled)\n\nprint(gs.best_score_.round(3))\nprint(gs.best_params_)","62ee0713":"clf_lr = gs.best_estimator_\nprint('Test accuracy: %.3f' % clf_lr.score(X_test_std, y_test))","137757f7":"from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\ny_pred = clf_lr.predict(X_test_std)\ny_pred_train = clf_lr.predict(X_train_std)\n\n# Validation of model\nprint(\"confusion_matrix = \\n\", confusion_matrix(y_true=y_test, y_pred=y_pred))\n\nprint(\"*accuracy_train = %.3f\" % accuracy_score(y_true=y_train, y_pred=y_pred_train))\nprint(\"accuracy = %.3f\" % accuracy_score(y_true=y_test, y_pred=y_pred))\n\nprint(\"*precision_train = %.3f\" % precision_score(y_true=y_train, y_pred=y_pred_train))\nprint(\"precision = %.3f\" % precision_score(y_true=y_test, y_pred=y_pred))\n\nprint(\"*recall_train = %.3f\" % recall_score(y_true=y_train, y_pred=y_pred_train))\nprint(\"recall = %.3f\" % recall_score(y_true=y_test, y_pred=y_pred))\n\nprint(\"*f1_score_train = %.3f\" % f1_score(y_true=y_train, y_pred=y_pred_train))\nprint(\"f1_score = %.3f\" % f1_score(y_true=y_test, y_pred=y_pred))","7d13ff47":"# ROC curve and AUC\ny_score = clf_lr.predict_proba(X_test_std)[:, 1]\n\nfpr, tpr, thresholds = roc_curve(y_true=y_test, y_score=y_score)\n# Visualization\nplt.figure(figsize=(10,6))\nplt.plot(fpr, tpr, label=\"roc curve (area = %.3f)\" % auc(fpr, tpr))\nplt.plot([0,1], [0,1], linestyle='--', label='random')\nplt.plot([0,0,1], [0,1,1], linestyle='--', label=\"ideal\")\nplt.legend()\nplt.xlabel(\"false positive rate\")\nplt.ylabel(\"true positive rate\")","31d808a2":"import scikitplot as skplt\nskplt.metrics.plot_confusion_matrix(y_test,y_pred,figsize=(6,6))","944d8aef":"print(classification_report(y_test, y_pred))\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","31b78405":" # Import Data and Packages","7ac30ad1":"# Apply and test our Logistic Regression model","73903c98":"# Logistic Regression Model","4d050799":"grid search technique prooved to be inferior in this case","1573eedd":"# Variable explanation\n\n**SeriousDlqin2yrs**:\n\n**RevolvingUtilizationOfUnsecuredLines**:\n\n**age**:\n\n**NumberOfTime30-59DaysPastDueNotWorse**:\t\n\n**DebtRatio**:\n\n**MonthlyIncome**:\n\n**NumberOfOpenCreditLinesAndLoans**:\n\n**NumberOfTimes90DaysLate**:\n\n**NumberRealEstateLoansOrLines**:\n\n**NumberOfTime60-89DaysPastDueNotWorse**:\t\n\n**NumberOfTime60-89DaysPastDueNotWorse:**\n\n","b52c07b9":"# Data Cleaning","9586a1a9":"We should consider selecting only one of the Days Past Due features as there is significant multicollinearity between the variables.","a59948aa":"# Feature Selection","f7c74929":"# Trying different model","11637ad9":"# Different feature selection techniques wit Logistic Regression","421ffeb3":"# Data Exploration\n"}}