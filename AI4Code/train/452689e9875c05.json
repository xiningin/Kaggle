{"cell_type":{"39eab68f":"code","563773a0":"code","44c6cb1f":"code","fa15fe12":"code","040b7665":"code","110f525a":"code","a6a19a33":"code","b2d5fc7d":"code","5069d653":"code","f033bed5":"code","4386c670":"code","4159e20f":"code","384f6c45":"code","710099c2":"code","eea6de12":"code","eb30393e":"code","32fb554b":"code","37524076":"code","1d47bad6":"code","67d4eb80":"code","cc4d2f81":"code","f2772bfc":"code","dc2089f7":"code","97ddc9a4":"code","f8a456de":"code","00cae9d5":"code","a907fd84":"code","55d122bb":"code","c85e6074":"code","f52e0017":"code","4fa09149":"code","b330cc8b":"code","2c75a095":"code","cdfa6a92":"code","b647bcdd":"code","fad2709d":"code","4b25ecc6":"code","d8752d37":"code","76d4cf2d":"code","a02815ee":"code","f5866f2a":"code","dffd9c29":"code","701056e7":"code","1078047e":"code","641ebb5e":"code","4694f159":"code","dca57aba":"code","47763d38":"markdown","a669baa4":"markdown","c5ec9252":"markdown","ad56a1cd":"markdown","6e937015":"markdown","21f418b0":"markdown","5b321803":"markdown","5f3da827":"markdown","76a8ae50":"markdown","4bfd2b81":"markdown","2a592a5c":"markdown","b054133f":"markdown","e2acdc09":"markdown","e7988c08":"markdown","9f765384":"markdown","07dad6da":"markdown","2d42b810":"markdown","2e452d00":"markdown","188ae96c":"markdown","e09fae0a":"markdown","d1d3de4e":"markdown","88ef5cb8":"markdown","f9b9897b":"markdown","175fea62":"markdown","2c592825":"markdown","b7d174aa":"markdown","f6346e8a":"markdown","dbf0942c":"markdown","a04a2ae2":"markdown","a373d829":"markdown","52c57b06":"markdown","08250c9f":"markdown","a6f3a766":"markdown","d38eede3":"markdown","a59ecee4":"markdown","61f0a588":"markdown","4c2728db":"markdown","9b84aa33":"markdown","ffb0bb52":"markdown","116f7e52":"markdown","d1a103e4":"markdown","ca895dfc":"markdown","3798d3ec":"markdown","ae659713":"markdown","060dc410":"markdown","1d5d39cb":"markdown","abc71635":"markdown","f8da645e":"markdown","18d8f6c3":"markdown","6daae4b1":"markdown","8e5934a7":"markdown","e8542657":"markdown","b682ad40":"markdown","0f45264f":"markdown","bcfd5cd3":"markdown","d36f2fc0":"markdown","35ead54c":"markdown","073bd63e":"markdown","4303130f":"markdown","cf9420d8":"markdown","c9eea2bf":"markdown","a9dbaece":"markdown","9576d307":"markdown","0102d398":"markdown","1723da51":"markdown","6db9205f":"markdown","7b08dec4":"markdown","f8a149d0":"markdown","9c6ea9bd":"markdown","a2049f62":"markdown","fd279fca":"markdown","cb7baf44":"markdown","1c2e468f":"markdown","ffc46a5e":"markdown","1fc0aef5":"markdown","8d5b78be":"markdown","bed9e679":"markdown","fdcec2d0":"markdown","229ea25a":"markdown","5ce62140":"markdown","e048b7ba":"markdown","f37a1a8d":"markdown","d84397cb":"markdown","d95e435f":"markdown","bd9fcbb3":"markdown","da1c4d0e":"markdown","2808a97f":"markdown","7400c2d3":"markdown","feb0a0c5":"markdown","bdd69b76":"markdown","1fa7d764":"markdown","1e6c5e2f":"markdown","6dfeb0a7":"markdown","d355947e":"markdown","f504bb4e":"markdown","5a1e5362":"markdown","273a1323":"markdown","7f7f5ae9":"markdown","ae6753fa":"markdown","b5241790":"markdown","7343d068":"markdown","b4291977":"markdown","9bce3135":"markdown","bb7790a5":"markdown","6a649ff5":"markdown","196ba201":"markdown","5a3b1d1a":"markdown","231c393f":"markdown","51e1c15e":"markdown","2696e4e0":"markdown","fe1c69ba":"markdown","ca2ffecc":"markdown","e2cc71db":"markdown","52f2a9ea":"markdown","52e649d8":"markdown","25df057a":"markdown","004408ba":"markdown","d8d1d569":"markdown","b21b3f4c":"markdown","cb7eac8d":"markdown","2cef1a49":"markdown","99791288":"markdown","31f02855":"markdown","6c060c27":"markdown","19455cae":"markdown","5d8a0d7c":"markdown","19cb1425":"markdown","abeae2f4":"markdown","7c4840f5":"markdown"},"source":{"39eab68f":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport matplotlib.lines as mlines\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, learning_curve\nfrom sklearn.metrics import average_precision_score\nfrom xgboost.sklearn import XGBClassifier\nfrom xgboost import plot_importance, to_graphviz\nfrom sklearn.model_selection import StratifiedKFold\nimport warnings\nimport time\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'","563773a0":"Data_Fraud = pd.read_csv(\"..\/input\/paysim-part\/PS_20174392719_1491204439457_log.csv\")\n","44c6cb1f":"Data_Fraud.isnull().sum().sum()          # Checking for null\nData_Fraud = Data_Fraud.dropna()\nData_Fraud.isnull().values.any()\nprint(Data_Fraud.isnull().values.any())\nprint(Data_Fraud.isnull().sum().sum())\n\n# Let look over 50th rows for example.    \ndisplay(Data_Fraud.head(50))\nprint('-'*30)\nprint('\\n')","fa15fe12":"Data_Fraud.describe(percentiles=[0.25, 0.5, 0.75, 0.9, 0.95, 0.99])","040b7665":"# Let look which kind of types objects columns we have?\n# We heve 3 types columns as an objects: 'type ', 'nameOrig', 'nameDest'\nprint(Data_Fraud.dtypes)\nprint('-'*80)\nprint('\\n')\n\n# The 'type' Column is ordinal category with some texts meaning, let inquiry it.\n# We see which type of text we have on \"typ\"=x and how much from each type text\n# Sub query\nx1 = Data_Fraud.sort_values(by = [\"type\"])[[\"type\"]]\nword1,count1 = np.unique(x1.values,return_counts = True)\nprint(word1)\nprint(count1)\nprint('-'*80)\nprint('\\n')\nprint('Mini conclusion: we see those types of transaction above are not symmetric.')\n","110f525a":"CASH_IN_Per_Total_Client = (count1[0]) \/ count1.sum()*100\nCASH_OUT__Per_Total_Client = (count1[1]) \/ count1.sum()*100\nDEBIT_Per_Total_Client = (count1[2]) \/ count1.sum()*100\nPAYMENT_Per_Total_Client = (count1[3]) \/ count1.sum()*100\nTRANSFER_Per_Total_Client = (count1[4]) \/ count1.sum()*100","a6a19a33":"plt.figure(figsize=(8, 8))\nTotal_client_per_plot1 = plt.pie(x = [CASH_IN_Per_Total_Client, \n    CASH_OUT__Per_Total_Client, DEBIT_Per_Total_Client, PAYMENT_Per_Total_Client, \n    TRANSFER_Per_Total_Client], labels=['CASH_IN','CASH_OUT','DEBIT','PAYMENT', 'TRANSFER'], \n    autopct = '%1.2f%%',shadow = True, startangle=90,colors = ['yellow','green','purple','blue','orange'])\nplt.title('All Types Clients Transactions Ratio');","b2d5fc7d":"plt.figure(figsize=[15, 15])\nplt.bar(word1, count1, width=0.7, edgecolor='blueviolet',\n        color=['yellow','green','purple','blue','orange'], linewidth=2)\nplt.title('All Types Clients Transactions', fontsize=15)\nplt.xlabel('word1', fontsize=15)\nplt.ylabel('count1', fontsize=15)\nplt.show()","5069d653":"Total_Not_Risk = (count1[0]) \/ count1.sum()*100\nTotal_Risk = ((count1[1]) + (count1[2]) + (count1[3]) + (count1[4])) \/ count1.sum()*100\n","f033bed5":"plt.figure(figsize=(8, 8))\nTotal_client_per_plot2 = plt.pie(x = [Total_Not_Risk, Total_Risk], \n    labels=['CASH_IN = NOT RISKY','TOTAL_CASH_OUT = RISKY'],autopct = '%1.2f%%', \n    shadow = True, startangle=90,colors = ['green','red'])\nplt.title('Dichotomy Risk Transactions Ratio Via column type');","4386c670":"Count_Not_Risk = ((count1[0]))\nCount_Risk = ((count1[1]) + (count1[2]) + (count1[3]) + (count1[4]))\nWord_2D = np.array(['Risky', 'Not in Risk'])\n# Word_2D = Word_2D.reshape((2,1))  \nCount_2D = np.vstack((Count_Risk, Count_Not_Risk)).reshape(2,)\nplt.figure(figsize=[15, 15])\nplt.bar(Word_2D, Count_2D, width=0.7, edgecolor='blueviolet',\n        color=['red','green'], linewidth=2)\nplt.title('Dichotomy Types Clients Transactions', fontsize=15)\nplt.xlabel('Type of transactions', fontsize=15)\nplt.ylabel('amount', fontsize=15)\nplt.show()\n","4159e20f":"Data_Fraud.describe()\nData_Fraud.type.unique()\nData_Fraud_list = ['PAYMENT', 'DEBIT', 'CASH_IN']\nData_Fraud1 = Data_Fraud[~Data_Fraud.isin(Data_Fraud_list)]\nData_Fraud1.type.unique()\nData_Fraud1['isFlaggedFraud'] = Data_Fraud1['amount'] >= 300000       \nprint(Data_Fraud1.dtypes)\nData_Fraud1['isFlaggedFraud'] = Data_Fraud1['isFlaggedFraud'].astype(float)\nprint(Data_Fraud1.dtypes)\n\nprint('\\n The number of Suspect Frauds =')\nprint(Data_Fraud1['isFlaggedFraud'].sum())\n\nPercentage_Suspects_Cases = Data_Fraud1['isFlaggedFraud'].sum() \/ len(Data_Fraud1['type']) *100\nprint('\\n The Percentage of Suspect Frauds =')\nprint(Percentage_Suspects_Cases)\n\n# let check which type of suspects fraud we have over 'isFlaggedFraud' column?\nprint('\\n The types of suspects fraudulent transactions are {}'.format(\\\nlist(Data_Fraud1.loc[Data_Fraud1.isFlaggedFraud == 1].type.drop_duplicates().values)))\n","384f6c45":"A = len(Data_Fraud1)\nB = Data_Fraud1['isFlaggedFraud'].sum() # New Risk\nC = A - B                               # New not in Risk\nprint('-'*80)\nprint('\\n')\nNew_Total_Not_Risk = C \/ A * 100\nNew_Total_Risk = B \/ C * 100","710099c2":"plt.figure(figsize=(8, 8))\nTotal_client_per_plot3 = plt.pie(x = [New_Total_Not_Risk, New_Total_Risk], \n    labels=['ALL_OTHERS = NOT RISKY', 'CASH_OUT & TRANSFER > 300,000 = RISKY'],\n    autopct = '%1.2f%%',shadow = True, startangle=90,colors = ['green','red'])\nplt.title('SUSPECTS FRAUD OVER 300K');\n","eea6de12":"Count_Not_Risk = C\nCount_Risk = B\nWord_2D = np.array(['Risky', 'Not in Risk'])\n# Word_2D = Word_2D.reshape((2,1))  \nCount_2D = np.vstack((Count_Risk, Count_Not_Risk)).reshape(2,)\nplt.figure(figsize=[15, 15])\nplt.bar(Word_2D, Count_2D, width=0.7, edgecolor='blueviolet',\n        color=['red','green'], linewidth=2)\nplt.title('Dichotomy Types Clients Transactions over 300,000', fontsize=15)\nplt.xlabel('Type of transactions', fontsize=15)\nplt.ylabel('amount', fontsize=15)\nplt.show()\n    \n","eb30393e":"print('\\n The types of fraudulent transactions are {}'.format(\\\nlist(Data_Fraud.loc[Data_Fraud.isFraud == 1].type.drop_duplicates().values)))\n#only 'CASH_OUT' & 'TRANSFER'\n\"\"\" \nLet inquiry by simulator column: 'isFraud' ?\n\"\"\"\n# Checking the first high risk\nDF_Fraud_Transfer = Data_Fraud.loc[(Data_Fraud.isFraud == 1) & (Data_Fraud.type == 'TRANSFER')] # For TRANSFER \nDF_Fraud_Cash_out = Data_Fraud.loc[(Data_Fraud.isFraud == 1) & (Data_Fraud.type == 'CASH_OUT')] # For Cash_out\n\n# Print the results of the suspects of each columns high risk.\nprint ('\\n The number of fraudulent TRANSFER = {}'.\\\n       format(len(DF_Fraud_Transfer)))\nprint ('\\n The number of fraudulent CASH_OUT = {}'.\\\n       format(len(DF_Fraud_Cash_out)))\n# On both of the columns above we have Frauds.\n\nPercentage_TRANSFER_Fraud = len(DF_Fraud_Transfer) \/ len(Data_Fraud['type']) *100\nPercentage_CASH_OUT_Fraud = len(DF_Fraud_Cash_out) \/ len(Data_Fraud['type']) *100\nPercentage_Total = Percentage_TRANSFER_Fraud + Percentage_CASH_OUT_Fraud\nprint('\\n The Total Percentage Frauds = {}'.\\\n       format(Percentage_Total))\n ","32fb554b":"plt.figure(figsize=(8, 8))\nTotal_client_per_plot4 = plt.pie(x = [1-Percentage_Total, Percentage_Total], \n    labels=['ALL_OTHERS = NOT RISKY', 'Found guilty = RISKY'],\n    autopct = '%1.2f%%',shadow = True, startangle=90,colors = ['green','red'])\nplt.title('GUILTY FRAUD BY ,Is_Fraud');\n\n","37524076":"B = len(DF_Fraud_Transfer) + len(DF_Fraud_Cash_out) # New Risk\nC = A - B                                           # New not in Risk\n\nCount_Not_Risk = C\nCount_Risk = B\nWord_2D = np.array(['Risky', 'Not in Risk'])\n# Word_2D = Word_2D.reshape((2,1))  \nCount_2D = np.vstack((Count_Risk, Count_Not_Risk)).reshape(2,)\nplt.figure(figsize=[15, 15])\nplt.bar(Word_2D, Count_2D, width=0.7, edgecolor='blueviolet',\n        color=['red','green'], linewidth=2)\nplt.title('Dichotomy Types Clients Transactions Via Is_Fraud', fontsize=15)\nplt.xlabel('Type of transactions', fontsize=15)\nplt.ylabel('amount', fontsize=15)\nplt.show()\n\n","1d47bad6":"X = Data_Fraud.loc[(Data_Fraud.type == 'TRANSFER') | (Data_Fraud.type == 'CASH_OUT')]\nY = X['isFraud'].values\nX = X.drop(['nameOrig', 'nameDest', 'isFraud'], axis = 1)\n\n\n\n# Encoding of feautures data for binaries 'type'\nX.loc[X.type == 'TRANSFER', 'type'] = 0\nX.loc[X.type == 'CASH_OUT', 'type'] = 1\nX.type = X.type.astype(int) # convert dtype('O') to dtype(int)\n","67d4eb80":"print(len(Y))","cc4d2f81":"(Y == 0).sum()","f2772bfc":"(Y == 1).sum()","dc2089f7":"Xfraud = X.loc[Y == 1,:]\nXnonFraud = X.loc[Y == 0]","97ddc9a4":"print('\\nThe fraction of fraudulent transactions with \\'oldBalanceDest\\' = \\\n\\'newBalanceDest\\' = 0 although the transacted \\'amount\\' is non-zero is: {}'.\\\nformat(len(Xfraud.loc[(Xfraud.oldbalanceDest == 0) & \\\n(Xfraud.newbalanceDest == 0) & (Xfraud.amount)]) \/ (len(Xfraud))))\n\nprint('\\nThe fraction of genuine transactions with \\'oldBalanceDest\\' = \\\nnewBalanceDest\\' = 0 although the transacted \\'amount\\' is non-zero is: {}'.\\\nformat(len(XnonFraud.loc[(XnonFraud.oldbalanceDest == 0) & \\\n(XnonFraud.newbalanceDest == 0) & (XnonFraud.amount)]) \/ (len(XnonFraud))))\n\n     \nR = len(Data_Fraud) * len(Xfraud.loc[(Xfraud.oldbalanceDest == 0) & \\\n(Xfraud.newbalanceDest == 0) & (Xfraud.amount)]) \/ (1.0 * len(Xfraud))    \n    # % Fraction of fraudulent transactions\n  \nS = len(Data_Fraud) * len(XnonFraud.loc[(XnonFraud.oldbalanceDest == 0) & \\\n(XnonFraud.newbalanceDest == 0) & (XnonFraud.amount)]) \/ (1.0 * len(XnonFraud))     \n    # % Fraction of genuine transactions\n","f8a456de":"C = R                           # Fraction of fraudulent transactions\nB = S                           # Fraction of genuine transactions\n\n\nCount_Not_Risk = C\nCount_Risk = B\nWord_2D = np.array(['Problems of Purified transacs = Faulse Negative', 'Problems of fraudulent transacs = True Positive '])\n  \nCount_2D = np.vstack((Count_Risk, Count_Not_Risk)).reshape(2,)\nplt.figure(figsize=[15, 15])\nplt.bar(Word_2D, Count_2D, width=0.7, edgecolor='blueviolet',\n        color=['azure','blue'], linewidth=2)\n\nplt.title('Dest Predicting Fraud in Financial Payment Services (Tp + Fn)', fontsize=20)\nplt.xlabel('Type of transactions Problems', fontsize=20)\nplt.ylabel('Amplitude transactions Problems', fontsize=20)\nplt.show()\n","00cae9d5":"print('\\nThe fraction of fraudulent transactions with \\'oldBalanceOrg\\' = \\\n\\'newBalanceOrg\\' = 0 although the transacted \\'amount\\' is non-zero is: {}'.\\\nformat(len(Xfraud.loc[(Xfraud.oldbalanceOrg == 0) & \\\n(Xfraud.newbalanceOrig == 0) & (Xfraud.amount != 0)]) \/ (len(Xfraud))))\n    \n\n\nprint('\\nThe fraction of fraudulent transactions with \\'oldBalanceOrg\\' = \\\n\\'newBalanceOrg\\' = 0 although the transacted \\'amount\\' is non-zero is: {}'.\\\nformat(len(XnonFraud.loc[(XnonFraud.oldbalanceOrg == 0) & \\\n(XnonFraud.newbalanceOrig == 0) & (XnonFraud.amount != 0)]) \/ (len(XnonFraud))))\n\n\n    \nT = len(Xfraud.loc[(Xfraud.oldbalanceOrg == 0) & \\\n(Xfraud.newbalanceOrig == 0) & (Xfraud.amount != 0)]) \/ (len(Xfraud))    \n    # % Fraction of fraudulent transactions\n  \nW = len(XnonFraud.loc[(XnonFraud.oldbalanceOrg == 0) & \\\n(XnonFraud.newbalanceOrig == 0) & (XnonFraud.amount != 0)]) \/ (len(XnonFraud))     \n    # % Fraction of genuine transactions    \n    ","a907fd84":"C = T                           # Fraction of fraudulent transactions\nB = W                           # Fraction of genuine transactions\n\n\nCount_Not_Risk = C\nCount_Risk = B\nWord_2D = np.array(['Problems of Purified transacs = Faulse Negative', 'Problems of fraudulent transacs = True Positive '])\n  \nCount_2D = np.vstack((Count_Risk, Count_Not_Risk)).reshape(2,)\nplt.figure(figsize=[15, 15])\nplt.bar(Word_2D, Count_2D, width=0.7, edgecolor='blueviolet',\n        color=['azure','blue'], linewidth=2)\n\nplt.title('Org Predicting Fraud in Financial Payment Services (Tp + Fn)', fontsize=20)\nplt.xlabel('Type of transactions Problems', fontsize=20)\nplt.ylabel('Amplitude transactions Problems', fontsize=20)\nplt.show() ","55d122bb":"X.loc[(X.oldbalanceDest == 0) & (X.newbalanceDest == 0) & (X.amount != 0), \\\n      ['oldBalanceDest', 'newBalanceDest']] = - 1    \n\n    \nprint('\\nFlags to be checked via oldBalanceDest = {}'.format(X.oldBalanceDest.sum() * - 1))\nprint('\\nFlags to be checked via newBalanceDest = {}'.format(X.newBalanceDest.sum() * - 1))\n   \nX.loc[(X.oldbalanceOrg == 0) & (X.newbalanceOrig == 0) & (X.amount != 0), \\\n      ['oldBalanceOrig', 'newBalanceOrig']] = 1\n\n","c85e6074":"print(\"Skewness: %f\" % Data_Fraud['amount'].skew())\nprint(\"Kurtosis: %f\" % Data_Fraud['amount'].kurt())\n\ndisplay(Data_Fraud['amount'].skew())","f52e0017":"warnings.filterwarnings(\"ignore\")","4fa09149":"plt.figure()\ng = sns.distplot(Data_Fraud[\"amount\"], color=\"m\", label=\"Skewness : %.2f\"%(Data_Fraud[\"amount\"].skew()))\nplt.show()","b330cc8b":"warnings.filterwarnings(\"ignore\")","2c75a095":"\nData_Fraud[\"amount\"] = Data_Fraud[\"amount\"].map(lambda i: np.log(i) if i > 0 else 0)\nplt.figure()\ng = sns.distplot(Data_Fraud[\"amount\"], color=\"g\", label=\"Skewness : %.2f\"%(Data_Fraud[\"amount\"].skew()))\ng = g.legend(loc=\"best\")\nplt.show()\n# Skewness is clearly reduced after the log transformation\n","cdfa6a92":"# let see how'amount' feature are via atd ?\n# we see that we have alots of small transaction.\n#fig = plt.figure(figsize=(8,6))\n\nplt.figure()\nsns.displot(data = Data_Fraud, x = 'amount', kde=True)\nplt.title('Distribution graph');\nplt.show()\n","b647bcdd":"plt.figure(figsize=(10, 8))\nsns.boxplot(x=\"amount\", y=\"type\", data=Data_Fraud)\nplt.xlabel(\"Quat transactions\", size=14)\nplt.ylabel(\"Type transactions\", size=14)\nplt.title(\"Fraud detection - Outlayers of transactions\", size=18)\nplt.savefig(\"simple_boxplot_with_Seaborn_boxplot_Python.png\")\nplt.show()\n# Here we see that 'CHSH_OUT, & 'TRANSFER' are kinds of outlayers.\n\n","fad2709d":"g = sns.heatmap(Data_Fraud[['step', 'type', 'amount', 'oldbalanceOrg', \\\n    'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'isFraud']].corr(),annot=True, fmt = \".2f\", cmap = \"coolwarm\")\nplt.show()","4b25ecc6":"X = Data_Fraud.loc[(Data_Fraud.type == 'TRANSFER') | (Data_Fraud.type == 'CASH_OUT')]\n# Y = X['isFraud'].values\nX = X.drop(['nameOrig', 'nameDest', 'isFlaggedFraud', 'isFraud'], axis = 1)\n","d8752d37":"X['ErrorBalanceOrig'] = X.newbalanceOrig + X.amount - X.oldbalanceOrg\nX['ErrorBalanceDest'] = X.oldbalanceDest + X.amount - X.newbalanceDest\n","76d4cf2d":"sns.set()\ncols = ['step', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'ErrorBalanceOrig', 'ErrorBalanceDest']\n\nsns_plot = sns.pairplot(X[cols].sample(100), height = 2.5, kind=\"kde\") \nplt.show()","a02815ee":"g = sns.heatmap(X[['step', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest', 'ErrorBalanceOrig', 'ErrorBalanceDest']].corr(),annot=True, fmt = \".2f\", cmap = \"coolwarm\")\nplt.show()","f5866f2a":"def Type_Rank2num(x):\n    if x == 'NONE':\n        return 0\n    if x == 'CASH_IN':\n        return 1\n    if x == 'DEBIT':\n        return 2\n    if x == 'PAYMENT':\n        return 2\n    if x == 'CASH_OUT':\n        return 2\n    if x == 'TRANSFER':\n        return 2\nX['type'] = X['type'].apply(Type_Rank2num)\n   \n\n\nprint('-'*80)\nprint('\\n')\n    \n# Finally after ranking we have only 8 columns and we will try to reduce them    \n    \n","dffd9c29":"print(X.dtypes)\nprint(X.shape)\nprint(Y.shape)","701056e7":"# x_train, x_test, y_train, y_test = train_test_split(x_scaled, Y, train_size=0.80, random_state=42)\nrandomState = 42\nnp.random.seed(3)\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, \\\n                                                random_state = randomState)\n  ","1078047e":"weights = (Y == 0).sum() \/ (1.0 * (Y == 1).sum())\ntime.sleep(2)\nclf = XGBClassifier(use_label_encoder=False, max_depth = 3, scale_pos_weight = weights, \\\n                n_jobs = 4, eval_metric='mlogloss')\nprobabilities = clf.fit(x_train, y_train).predict_proba(x_test)\nprint('Probability Score AUPRC = {}'.format(average_precision_score(y_test, \\\n                                              probabilities[:, 1])))","641ebb5e":"fig = plt.figure(figsize = (14, 9))\nax = fig.add_subplot(111)\n\ncolours = plt.cm.Set1(np.linspace(0, 1, 9))\n\nax = plot_importance(clf, height = 1, color = colours, grid = False, \\\n                     show_values = False, importance_type = 'cover', ax = ax);\nfor axis in ['top','bottom','left','right']:\n            ax.spines[axis].set_linewidth(2)\n        \nax.set_xlabel('importance score', size = 16);\nax.set_ylabel('features', size = 16);\nax.set_yticklabels(ax.get_yticklabels(), size = 12);\nax.set_title('Ordering of features by importance to the model learnt', size = 20);    \n  ","4694f159":"to_graphviz(clf)","dca57aba":"stkf = StratifiedKFold(5)\ntrainSizes, trainScores, crossValScores = learning_curve( \\\nXGBClassifier(use_label_encoder=False, eval_metric='mlogloss', max_depth = 3, scale_pos_weight = weights, n_jobs = 4), x_train,\\\n                                         y_train, scoring = 'average_precision', cv = stkf)\n\n\n\n\n\ntrainScoresMean = np.mean(trainScores, axis=1)\ntrainScoresStd = np.std(trainScores, axis=1)\ncrossValScoresMean = np.mean(crossValScores, axis=1)\ncrossValScoresStd = np.std(crossValScores, axis=1)\n\ncolours = plt.cm.tab10(np.linspace(0, 1, 9))\n\nfig = plt.figure(figsize = (14, 9))\nplt.fill_between(trainSizes, trainScoresMean - trainScoresStd,\n    trainScoresMean + trainScoresStd, alpha=0.01, color=colours[0])\nplt.fill_between(trainSizes, crossValScoresMean - crossValScoresStd,\n    crossValScoresMean + crossValScoresStd, alpha=0.01, color=colours[1])\nplt.plot(trainSizes, trainScores.mean(axis = 1), 'o-', label = 'train', \\\n         color = colours[0])\nplt.plot(trainSizes, crossValScores.mean(axis = 1), 'o-', label = 'cross-val', \\\n         color = colours[1])\n\nax = plt.gca()\nfor axis in ['top','bottom','left','right']:\n    ax.spines[axis].set_linewidth(2)\n\nhandles, labels = ax.get_legend_handles_labels()\nplt.legend(handles, ['train', 'cross-val'], bbox_to_anchor=(0.8, 0.15), \\\n               loc=2, borderaxespad=0, fontsize = 16);\nplt.xlabel('training set size', size = 16); \nplt.ylabel('AUPRC', size = 16)\nplt.title(\"Learning curves indicate slightly underfit model - It's a kind of Loss\", size = 20);\n","47763d38":"**Going forward we need to mark those transactions above weed flags to be inquiry\nlater, so since the destination account balances being zero is a strong indicator of \nfraud, we do not impute the account balance (before the transaction is made) \nwith a statistic or from a distribution with a subsequent adjustment for the \namount transacted. Doing so would mask this indicator of fraud and make \nfraudulent transactions appear genuine. Instead, below we replace the value \nof 0 with -1 which will be more useful to a suitable machine-learning (ML) \nalgorithm detecting fraud.**","a669baa4":"**For Inquiries I need to inspect only 2 transaction: 'TRANSFER', & 'CASH_OUT'.\nEmphasize 'isFlaggedFraud' was inquired in the first part and therefore has no reference here.**","c5ec9252":"**1)'step'           is it use to be time simulator. But with no use.**","ad56a1cd":"**3)'amount'         refer to the Quantity and size  of transaction was done - need it.**","6e937015":"# **10.Conclusion**","21f418b0":"**4.3.3 Bar plotting**","5b321803":"**I would like to thanks the owner of the dataset M. Edgar Alonso Lopez-Rojas.**","5f3da827":"# **8. Modeling (XGBoost)**","76a8ae50":"**5)'newbalanceDest' refer to balance was done - need it.** ","4bfd2b81":"**cases for 1000 transactions.**","2a592a5c":"**So, I decide after a look with some calculations to put every order Above 300,000**","b054133f":"**1.3 Definition: What is a transaction? A transaction is a set of commands that \nall of them need to be executed together. If one of them would not made the \nmoney transfer records or the payments are not made with no Fraud (but we need \nevery mistransactions need to be inspect).**","e2acdc09":"**3.4.2 Bar plotting**","e7988c08":"**This column show which transaction is suspect to be Fraud  ?**","9f765384":"**6.3.1 In the above Matrix we see how much the features are confusing?**","07dad6da":"**It is a kind of control over all \nthe integrity of the process. we will inspect this aspect with classification methods.\nEach transaction process have double checking: one is on the transmitter side, \nand the second is on the receiver. Both of the checking need to be given same result.**","2d42b810":"**8.3 Classification XGBoost**","2e452d00":"**Finally we assuming via 'isFraud' column that the fraud is coming from 'CASH_OUT' & 'TRANSFER' columns**","188ae96c":"# **2. Libraries to import.**","e09fae0a":"**There are still some types of frauds that this model does not discuss, \nbut it is certainly applicable.\nThis inquiry seem to be applicable for the majority frauds.  \nThis vision and methods work used in this kernel should therefore be useful for\nlarge range of such problems likes these types of frauds.**","d1d3de4e":"**4.2.1 Inquiries: With 'Xfraud' & 'XnonFraud' then:'oldbalanceDest'==0 & 'newbalanceDest'==0 &'amount'!=0**","88ef5cb8":"Let display the relationship between two numerical variables\nFor any combination features.\n\n1) By this plot we could see Significantly that 'ErrorBalanceOrig' & 'ErrorBalanceDest'\n   are suspects as frauds.\n2) We can see here that the scatter and the distribution are around the mean of \n   each and every figure.","f9b9897b":"# **5. inquiry by: Skewness**","175fea62":"**What we see ?**","2c592825":"**lambda: L2 regularization on leaf weights and is smoother than L1 \n    regularization.**","b7d174aa":"**7.4 Rank from scratch what is risky ?**","f6346e8a":"**5.1.1 Apply log to 'amount to reduce skewness distribution.**","dbf0942c":"**So Finally we have 2 type of transactions: in and out direction.**","a04a2ae2":"# **4. Inquiries by accounting individuals cash flow**","a373d829":"**I inquiry Those frauds data from several aspects. I inspect a transaction level \nand show every inquiry by plot. The plots provided visual confirmation \nthat the data could indeed be inquiry and present by the new features.\nAs we saw we have a large skew then ML algorithm based on an ensemble of decision \ntrees XGBoost which works best with strongly imbalanced classes.\nI chose to introduce two very basic types of scams:**","52c57b06":"    **In addition, we have two Columns texts that need to be keep in attention:\n        1) The first is the origin address of the data:'nameOrig'.\n        2) The second is the target address of the data:'nameDest'.\n        3) Usually it's Ip address or domain name  \n    We have to keep those address data in case that it's a Fraud detection and we need\n    to follow them. Any system data or Sys admin will help us commands like: \n        Tracert, Ping etc..\n    in else Some information from: Dhcp, Index, Firewall servers \n    (Unix, AS-400, Main-fraim) could help us for fraud detection owner and\n    we should look for it\n    Else - We must inspect columns: 'oldbalanceDest', 'newbalanceDest'.\n    Since the transaction is not close, we need to keep the 'oldbalancDest' and \n    to pay attention that no traffic was done. Just if the transaction was close\n    then the traffic was done, and Fraud could be done. But even the transactions\n    was no close and seem to be problematics = we need to inspect them.\n    In this case we need to inquiry correlation between this 'newbalanceDest' to\n    any suspect fraud?**","08250c9f":"**3.5.2.1 Plot risky via Is_Fraud'**","a6f3a766":"**5.2 Mini ratio:**","d38eede3":"**4.3.1 Inquiries: With 'Xfraud' & 'XnonFraud' then:'oldbalanceOrg'==0 & 'newbalanceOrg'==0 &'amount'!=0**","a59ecee4":"**done then we keep the old balance, and to inspects all**","61f0a588":"**(will be fix for transactions over 300,000 = suspect)**","4c2728db":"**Flag to be suspect = '1' to enlarge safety control in this cases.**","9b84aa33":"**4.1 Let's inspect every 'CASH_OUT' & 'TRANSFER' that could be masking.**","ffb0bb52":"**5.1 Plotting Skewness**","116f7e52":"**7.2 Scatterplot - Data Visualization**","d1a103e4":"**The root node in the decision tree visualized below is emphasizes  the feature \n'ErrorBalanceOrig', as would be expected to be high significance to our model**","ca895dfc":"**gamma: controls whether a given node will split based on the expected \n    reduction in loss after the split. A higher value leads to fewer \n    splits. Supported only for tree-based learners.**","3798d3ec":"**3.5 In addition - We will inquiry two columns that use to be indicator for Fraud.**","ae659713":"**6.3.2 Mini Ratio**","060dc410":"**3.4 On one side - The high risk fraud are coming from outside Transactions**","1d5d39cb":"**6)'oldbalanceOrg'  refer to transaction balance org. If the transaction was not**","abc71635":"**3.2 Inquiry data**","f8da645e":"**8)'isFraud'        refer to real transaction fraud - need it.**","18d8f6c3":"**3.5.1 Let inquiry by simulator column: 'isFlaggedFraud' ?**","6daae4b1":"# **9. Bias-variance trade of**f","8e5934a7":"**As we can see, 'amount'' distribution is very skewed. This can lead to overweight \nvery high values in the model. The anomaly distribution is not uniform \nIn this case, it is better to transform it with the log function to reduce this skew.**","e8542657":"**4.2.2 Calculations for bar plotting**","b682ad40":"**alpha: L1 regularization on leaf weights. A large value leads to more \n    regularization.**","0f45264f":"**was not done we need inspects all the process  for fraud - need it.**","bcfd5cd3":"**2)'type'           refer to type of transaction was done.Finally 2 types are needed for our predict**","d36f2fc0":"**8.5 Plotting XGBoost Model**","35ead54c":"**Maybe we have some correlative Fraud?\n('oldbalanceOrg' & 'newbalanceOrig') and ('oldbalanceDest' & 'newbalanceDest')\nsince the last process in the transaction is not finished, we need to remember \nthe last Account Balance. The features above need to be correlative since it's \nreplicas and we need to remember them.\"\nSo only here we could view correlation between those columns.\nJust those need to be remembered.\nOther correlations are low & it's good.**","073bd63e":"# **What we need to keep as a prameter but not for our predict ?**","4303130f":"**3.4.1 Pie plotting**","cf9420d8":"**6.2 Inquiry of outlier by plt.figure() type(transaction) \/amount(transaction))**","c9eea2bf":"**we will inspect it for errors calculations along the process.**","a9dbaece":"**Refer to 'type' column!.\nMy classification refer to the degree of risk\nWe could see that \"CASH_OUT\" and \"TRANSFER\", as my vision are in the same risk**","9576d307":"**This column reject out the fraud transaction that was declare as Fraud and in Risk.**","0102d398":"**9.1 Plotting Mean - STD**","1723da51":"**3.1 Load data**","6db9205f":"**we see that when each feature is stand alone, we have 0.0608 (or 1) mean frauds**","7b08dec4":"**8.2 SMOTE for Imbalanced Classification**","f8a149d0":"**The challenge of working with imbalanced datasets is that most machine learning \ntechniques will ignore, and in turn have poor performance on, the minority class, \nalthough typically it is performance on the minority class that is most important.\nOne approach to addressing imbalanced datasets is to over sample the minority class. \nThe simplest approach involves duplicating examples in the minority class, although \nthese examples don\u2019t add any new information to the model. Instead, new examples \ncan be synthesized from the existing examples. This is a type of data augmentation \nfor the minority class and is referred to as the Synthetic Minority Oversampling \nTechnique, or SMOTE for short.\nAfter some inquiries those below parameters were best chosen.**","9c6ea9bd":"**Hope you like my vision and enjoyed reading this code. \nPls. feel free to upvote I will be thankful.** ","a2049f62":"# **Which features we need ?,**","fd279fca":"**7.1 The next calculation need to be appointed for detecting Fraud.**","cb7baf44":"**2) Concerns inaccuracies and calculations in the transfer of money.**","1c2e468f":"Created on Sun Oct 17 09:54:32 2021\n\n@author: Rony Keller - Algorithm Engineer (Data Science), \nFintech technologies Manager @ Economic investigation (Electronic engineer &\nGraduate of Business Administration) ML and Deep Learning.\n\"\"\"","ffc46a5e":"# **1. Instruction**","1fc0aef5":"**3.5.1.2 Pie plotting**","8d5b78be":"**3.5.2 By the simulator column: 'isFraud' which transaction are in high risk?**","bed9e679":"# **6 Inquiry by Plotting**","fdcec2d0":"**8.0 XGBoost is a greedy algorithm, sovwe expect to get the best one.**","229ea25a":" **THE DELTA new balance origin or dest. could be Fraud - need it.**","5ce62140":"**3.3 Exploring all types data by plotting**","e048b7ba":"# **The data was provided here is a type of simulator of Fraud detection.**","f37a1a8d":"**3.3.2 Bar plotting**","d84397cb":"The results could be normalized with Random-Seed and results could be regal. Actually, after various attempts the actual accuracy is 93% while the data is unordered, and the last output of plot shows the fact that the data is in disorder. In else on my Spider PC, I got 81% accuracy with good plot above So what is wrong? nothing. The work environment has changed along with the weights that are a function by Random-Seed and the last parameters could be changed in every environment. What we are seeing here is the real-life problem as anomalies data and the accuracy is more like 81% as on my Spider enviroment Pc with good output last plot then 93% here.  ","d95e435f":"**4.2 Mini ratio (Dest)**","bd9fcbb3":"**2)'nameDest'       refer to the new origin address I.P.**","da1c4d0e":" **like : CASH_OUT, DEBIT,**","2808a97f":"\n    0)  A long all the code we have mini ratio = Feature analysis.\n    1)  Instruction.\n    2)  Libraries to import.\n    3)  Load dataset with some inquiries by some plots.\n    4)  Inquiries individuals cash flow by Calculations & some plots.\n    5)  Inquiry by Skewness.\n    6)  Inquiry by Plotting.\n    7)  Pre modeling - Ordering importance\n    8)  Modeling (XGBoost)\n    9)  Bias-variance trade off\n    10) Conclusion\n","7400c2d3":"**3.3.1 Pie plotting**","feb0a0c5":"**7)'oldbalanceDest' refer to old balance dest. Since it is old the transaction**","bdd69b76":"**PAYMENT & TRANSFER, just CASH_IN are not in high risk.**","1fa7d764":"**1}'nameOrig'       refer to the origin address I.P or Dns.**","1e6c5e2f":"**1.2 The variety and issue of fraud is very large. Here is a simulation in which \nthe Flags of fraud is given, and we do not have to investigate whole range of \ntypes fraud.Even this flag I will inspect the dataset for miscalculations and \ntransactions over 300,000$.**","6dfeb0a7":"# **0. Table of Contents:**","d355947e":"**6.3 Plotting Confusion Correlation matrix between numerical values**","f504bb4e":"**8.4 Plotting the relevant importance of the features**","5a1e5362":"# **7.0  Pre modeling - Ordering importance**","273a1323":"**3.5.2.2 Bar plotting**","7f7f5ae9":"**the process  for fraud - need it.**","ae6753fa":"**Explore Fare distribution\nHere The Skewness is very high, meaning that the Data_Fraud is in inbalance.\nWe will discuss this problem later as synthetic minority oversampling technique (SMOTE)**","b5241790":"**WE see some data has several transactions with zero balances in the destination \naccount both before and after transactions with a non-zero amount is transacted. \nThe fraction of such transactions, where zero likely denotes a missing value = \nmean a potential fraud and is much larger in fraudulent (49.55%) compared to \nreal or genuine transactions (0.061%).\nThe fraudulent transactions (49.55%) are True Positive = fraud could be detected, and \nThe real or genuine transactions (0.061%) are False Negative that equivalents\nto fraud that can't be detected. It is very important to find those 0.061% Frauds.\nI said at the beginning that transactions like those would be stopped at the middle\njust if the process was not finish.**","7343d068":"**Except correlation features showing in 6.3.1 and others low correlation features. \nThe vision was taken till here is good.\nSo, I will try to predict some frauds via:\n    1) 'IsFraud' column via all features\n    2) 'amount' via 'isFlaggedFraud'\n    3) Risky above via 'Is Fraud'**","b4291977":"**1.1 We suppose that this dataset is simulated money transfers with\nfraudulent actives.**","9bce3135":"**9.1.2 Hipper parameters of XGBoost:**","bb7790a5":"# **3. Load and check data**","6a649ff5":"**For inquiring 'ErrorBalanceOrig' & 'ErrorBalanceDest' relation ?:\nWe could see again more prominently the ratio of errors accessibility to \nother variables.**","196ba201":"**9)'isFlaggedFraud' refer to transaction fraud over 300,000$ = suspect - need it**","5a3b1d1a":"**8.1 splitting the Datas to train @ test : 80%-20%** ","231c393f":"**7.3 Plotting Confusion Correlation matrix between numerical values**","51e1c15e":"**A. Let describe all numeric features in case to see out layers = Fraud.**","2696e4e0":"**4.3.2 Calculations for bar plotting**","fe1c69ba":"**Since it is a simulator I do not find any suspects Fraud,**","ca2ffecc":"# **What we need for our predict and calculation ?**","e2cc71db":"**4.3 Mini ratio (Org   -   on the other side of transaction)**","52f2a9ea":"**The data also has several transactions with zero balances in the originating \naccount both before and after a non-zero amount is transacted. In this case, \nthe fraction of such transactions is much smaller in fraudulent (0.3%) compared \nto genuine transactions (47.37%).\nThe fraudulent transactions (0.3%) are True Positive = fraud could be detected, and \nThe real or genuine transactions (47.37%) are False Negative that equivalents\nto fraud that can't be detected. It is very important to find those 47.37% Frauds.\nI said it at the beginning that transactions like those would be stopped at the middle,\nand need to be inquiry. As it was shown (and my)\nUsually most of the fraud's cases are coming from inside business by workers.**","52e649d8":"**4.4 Mini ratio (results of problematics transactions need to be flagged)**","25df057a":"**6.1 histogram plot**","004408ba":"**Our model have learnt a degree of bias, even this degree of bias is slightly \nunder fit. \nThis is indicated by the levelling in AUPRC as the size of the training set \nis increased in the cross-validation curve below. The easiest way to improve \nmore and best performance of the model still further is to increase the max_depth \nparameter of the XGBClassifier at the expense of the longer time spent learning \nthe model and time running memory. Other parameters of the classifier that can be \nadjusted for correcting the effect of the modest under fitting refer to decreasing \nmin_child_weight and decreasing reg_lambda**","d8d1d569":"**4)'newbalanceOrig' refer to the new balance after the transaction - need it.**","b21b3f4c":"**9.1.1. Mini Ratio**","cb7eac8d":"**Finally I will check just both of them.** ","2cef1a49":"**As we saw above by Skewness, we have an imbalance Data Fraud as 'X'\nI will try to correct it with synthetic minority oversampling technique (SMOTE)**","99791288":"**We could change this suspect limit every time to be more \/ less safety.**","31f02855":"**8.2.1 Mini Ratio:**","6c060c27":"**3.5.1.1 Plot risky Fraud over 300K via 'CASH_out' & 'TRANSFER'**","19455cae":"**What could we see?**","5d8a0d7c":"**3.5.1.3 Bar plotting**","19cb1425":"**1) Relates to a transfer higher than 300,000$.**","abeae2f4":"**it's very Dichotomy - Let plot it.**","7c4840f5":"**4.2.3 Bar plotting**"}}