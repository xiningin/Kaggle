{"cell_type":{"ff527153":"code","f0c863ab":"code","1585edb3":"code","8eed2970":"code","79cf71b5":"code","be713ba5":"markdown","ce57b56c":"markdown","3820ef7d":"markdown"},"source":{"ff527153":"#!pip install selenium\nimport pandas as pd\nfrom selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium.webdriver.chrome.options import Options","f0c863ab":"DRIVER_PATH = \"Put your webdriver path here\"\ndriver = webdriver.Chrome(executable_path=DRIVER_PATH)\n# Got absolute link address that you want scrape for by doing job search.\ndriver.get(\"Put your link here\")","1585edb3":"# After running above code a new browser with link will open. Inspect the element you wnat capture.\nelem = driver.find_elements_by_id(\"gbqfq\")\n# If Search by ID doesnt work use find_elements_by_class_name or xpath\n#elem is a list of captured elems, use each elem to capture text\nelem[0].text","8eed2970":"lst = []\nfor i in range(len(elem)):\n    print(elem[i].text.replace(\"\\n\",\",\"))\n    line = elem[i].text.replace(\"\\n\",\",\")\n    lst.append(line)\n\ndf = pd.DataFrame(columns=['Data'])\ndf[\"Data\"] = lst\n    ","79cf71b5":"### Save dataframe to csv\ndf.to_csv(\"Enter your Filename .csv\")","be713ba5":"# Extract with Selenium","ce57b56c":"## Use below link to download drivers and save it to default python directory or anywhere and copy the path.\n- https:\/\/chromedriver.storage.googleapis.com\/index.html?path=94.0.4606.61\/","3820ef7d":"### Note:\nThis code is not supposed ot be used on Kaggle but Jupyter Notebook, it can only be used when there is webdriver accessable by IDE with respect to your browser."}}