{"cell_type":{"4c4ba700":"code","aafcbac1":"code","f2e3f331":"code","066eecc1":"code","e242ca7d":"code","b92ad258":"code","a012f005":"code","7b0adff1":"code","39747314":"code","cf1e9312":"code","4376b037":"code","e69e7ca0":"code","0a2e3a93":"code","90503a7e":"code","d0dae09f":"code","2ca7e8cf":"code","b8140493":"code","aa2fef60":"code","30e85530":"code","f0ff42a4":"code","aa5283c7":"markdown","74ee6516":"markdown"},"source":{"4c4ba700":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aafcbac1":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport PIL\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential","f2e3f331":"import pathlib\ndata_dir = \"..\/input\/covid19-image-dataset\/Covid19-dataset\/train\"\ndata_dir = pathlib.Path(data_dir)\n","066eecc1":"image_count = len(list(data_dir.glob('*\/*.*')))\nprint(image_count)","e242ca7d":"covid = list(data_dir.glob('Covid\/*'))\nPIL.Image.open(str(covid[1]))","b92ad258":"normal = list(data_dir.glob('Normal\/*'))\nPIL.Image.open(str(normal[0]))","a012f005":"vir_pne = list(data_dir.glob('Viral Pneumonia\/*'))\nPIL.Image.open(str(vir_pne[0]))","7b0adff1":"batch_size = 32\nimg_height = 180\nimg_width = 180","39747314":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","cf1e9312":"val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"validation\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","4376b037":"class_names = train_ds.class_names\nprint(class_names)","e69e7ca0":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n  for i in range(6):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")","0a2e3a93":"data_augmentation = keras.Sequential(\n  [\n    layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n                                                 input_shape=(img_height, \n                                                              img_width,\n                                                              3)),\n    layers.experimental.preprocessing.RandomRotation(0.1),\n    layers.experimental.preprocessing.RandomZoom(0.1),\n  ]\n)","90503a7e":"plt.figure(figsize=(10, 10))\nfor images, _ in train_ds.take(1):\n  for i in range(9):\n    augmented_images = data_augmentation(images)\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n    plt.axis(\"off\")","d0dae09f":"num_classes = 5\nmodel = Sequential([\n  data_augmentation,\n  layers.experimental.preprocessing.Rescaling(1.\/255),\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Dropout(0.2),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n])","2ca7e8cf":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","b8140493":"model.summary()","aa2fef60":"epochs = 12\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs\n)","30e85530":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","f0ff42a4":"test_dir = \"..\/input\/covid19-image-dataset\/Covid19-dataset\/test\/Viral Pneumonia\/0101.jpeg\"\ntest_dir = pathlib.Path(test_dir)\n\n\nimg = keras.preprocessing.image.load_img(\n    test_dir, target_size=(img_height, img_width)\n)\nimg_array = keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0) # Create a batch\n\npredictions = model.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\n\nprint(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(class_names[np.argmax(score)], 100 * np.max(score))\n)","aa5283c7":"### creating dataset","74ee6516":"## Data Augmentation"}}