{"cell_type":{"8f001ff2":"code","87e96746":"code","9ebe3e85":"code","023bb318":"code","f51af469":"code","cc81f15f":"code","9d4aaccf":"code","80fd5a3d":"code","5a6810c2":"code","118d7b46":"code","ad2b7a7d":"code","84f67274":"code","501789c8":"code","067dbfa3":"code","7ef419ad":"code","7d399ca8":"code","7df94343":"code","7fb4da65":"code","b04bc6ef":"code","ccb8d38e":"code","ffafa226":"code","c7dcc4f2":"code","567771ae":"code","ed55f64a":"code","4b19078c":"code","6cef4d36":"code","bb834c5c":"code","53fe60b7":"code","1cdf8d45":"markdown","9add368b":"markdown","b4d415e6":"markdown","0e272b73":"markdown","277991af":"markdown","38e3ed51":"markdown","7ec81680":"markdown","4de75f89":"markdown","d12e4fe0":"markdown","82079ceb":"markdown","85e1ccf8":"markdown","0d7c4749":"markdown","8c03d386":"markdown","78a98944":"markdown","23c30f1e":"markdown","e22df418":"markdown","e356ee2f":"markdown","d1e78f5a":"markdown","f00e6734":"markdown","594ac478":"markdown","f950211c":"markdown","0d19badc":"markdown","227374a4":"markdown"},"source":{"8f001ff2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom datetime import datetime # Convert date and time into a timestep\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","87e96746":"data_file = \"..\/input\/g-research-crypto-forecasting\/\"\n!ls $data_file","9ebe3e85":"cf_df = pd.read_csv(data_file + 'train.csv')","023bb318":"cf_df.head(8)","f51af469":"asset_details = pd.read_csv(data_file + 'asset_details.csv')\nasset_details","cc81f15f":"btcoin = cf_df[cf_df[\"Asset_ID\"]==1].set_index(\"timestamp\") # Asset_ID = 1 for Bitcoin\nbtcoin_min = btcoin.iloc[-200:] # Select recent data rows","9d4aaccf":"import plotly.graph_objects as go\n\nfig = go.Figure(data=[go.Candlestick(x=btcoin_min.index, open=btcoin_min['Open'], high=btcoin_min['High'], low=btcoin_min['Low'], close=btcoin_min['Close'])])\nfig.show()","80fd5a3d":"miss = cf_df[cf_df[\"Asset_ID\"]==6].set_index(\"timestamp\") # Asset_ID = 6 for Ethereum\nmiss.info(show_counts =True)","5a6810c2":"miss.isna().sum()","118d7b46":"btcoin.head()","ad2b7a7d":"leg_btcoin = btcoin.index[0].astype('datetime64[s]')\nend_btcoin = btcoin.index[-1].astype('datetime64[s]')\nleg_miss = miss.index[0].astype('datetime64[s]')\nend_miss = miss.index[-1].astype('datetime64[s]')\n\nprint('BTCOIN data goes from ', leg_btcoin, 'to ', end_btcoin)\nprint('Ethereum data goes from ', leg_miss, 'to ', end_miss)","84f67274":"(miss.index[1:]-miss.index[:-1]).value_counts().head()","501789c8":"miss = miss.reindex(range(miss.index[0],miss.index[-1]+60,60),method='pad')","067dbfa3":"(miss.index[1:]-miss.index[:-1]).value_counts().head()","7ef419ad":"import matplotlib.pyplot as plt\n\n# plot vwap time series for both chosen assets\nf = plt.figure(figsize=(15,4))\n\n# fill missing values for BTCOIN\nbtcoin = btcoin.reindex(range(btcoin.index[0],btcoin.index[-1]+60,60),method='pad')\n\nax = f.add_subplot(121)\nplt.plot(btcoin['Close'], label='BTCOIN')\nplt.legend()\nplt.xlabel('Time')\nplt.ylabel('Bitcoin')\n\nax2 = f.add_subplot(122)\nax2.plot(miss['Close'], color='red', label='ETH')\nplt.legend()\nplt.xlabel('Time')\nplt.ylabel('Ethereum') # Ethereum is a blockchain computer program similar to Bitcoin. It can be used to create automated contracts or circulate a digital currency called Ether.\n\nplt.tight_layout()\nplt.show()","7d399ca8":"import time\n\n# auxiliary function, from datetime to timestamp\ntotimestamp = lambda s: np.int32(time.mktime(datetime.strptime(s, \"%d\/%m\/%Y\").timetuple()))\n\n# create intervals\nbtcoin_min_2021 = btcoin.loc[totimestamp('01\/06\/2021'):totimestamp('01\/07\/2021')]\nmiss_min_2021 = miss.loc[totimestamp('01\/06\/2021'):totimestamp('01\/07\/2021')]","7df94343":"# plot time series for both chosen assets\nf = plt.figure(figsize=(7,8))\n\nax = f.add_subplot(211)\nplt.plot(btcoin_min_2021['Close'], label='btc')\nplt.legend()\nplt.xlabel('Time')\nplt.ylabel('Bitcoin Close')\n\nax2 = f.add_subplot(212)\nax2.plot(miss_min_2021['Close'], color='red', label='eth')\nplt.legend()\nplt.xlabel('Time')\nplt.ylabel('Ethereum Close') \n\nplt.tight_layout()\nplt.show()","7fb4da65":"# define function to compute log returns\ndef log_return(series, periods=1):\n    return np.log(series).diff(periods=periods)","b04bc6ef":"import scipy.stats as stats\n\nlret_btc = log_return(btcoin_min_2021.Close)[1:]\nlret_eth = log_return(miss_min_2021.Close)[1:]\nlret_btc.rename('lret_btc', inplace=True)\nlret_eth.rename('lret_eth', inplace=True)\n\nplt.figure(figsize=(8,4))\nplt.plot(lret_btc);\nplt.plot(lret_eth);\nplt.show()","ccb8d38e":"# join two asset in single DataFrame\n\nlret_btc_long = log_return(btcoin.Close)[1:]\nlret_eth_long = log_return(miss.Close)[1:]\nlret_btc_long.rename('lret_btc', inplace=True)\nlret_eth_long.rename('lret_eth', inplace=True)\ntwo_assets = pd.concat([lret_btc_long, lret_eth_long], axis=1)\n\n# group consecutive rows and use .corr() for correlation between columns\ncorr_time = two_assets.groupby(two_assets.index\/\/(10000*60)).corr().loc[:,\"lret_btc\"].loc[:,\"lret_eth\"]\n\ncorr_time.plot();\nplt.xticks([])\nplt.ylabel(\"Correlation\")\nplt.title(\"Correlation between BTC and ETH over time\");","ffafa226":"# create dataframe with returns for all assets\nall_assets_2021 = pd.DataFrame([])\nfor asset_id, asset_name in zip(asset_details.Asset_ID, asset_details.Asset_Name):\n  asset = cf_df[cf_df[\"Asset_ID\"]==asset_id].set_index(\"timestamp\")\n  asset = asset.loc[totimestamp('01\/01\/2021'):totimestamp('01\/05\/2021')]\n  asset = asset.reindex(range(asset.index[0],asset.index[-1]+60,60),method='pad')\n  lret = log_return(asset.Close.fillna(0))[1:]\n  all_assets_2021 = all_assets_2021.join(lret, rsuffix=asset_name, how=\"outer\")","c7dcc4f2":"plt.imshow(all_assets_2021.corr());\nplt.yticks(asset_details.Asset_ID.values, asset_details.Asset_Name.values);\nplt.xticks(asset_details.Asset_ID.values, asset_details.Asset_Name.values, rotation='vertical');\nplt.colorbar();","567771ae":"# Select some input features from the trading data: \n# 5 min log return, abs(5 min log return), upper shadow, and lower shadow.\nupper_shadow = lambda asset: asset.High - np.maximum(asset.Close,asset.Open)\nlower_shadow = lambda asset: np.minimum(asset.Close,asset.Open)- asset.Low\n\nX_btc = pd.concat([log_return(btcoin.VWAP,periods=5), log_return(btcoin.VWAP,periods=1).abs(), \n               upper_shadow(btcoin), lower_shadow(btcoin)], axis=1)\ny_btc = btcoin.Target\n\nX_eth = pd.concat([log_return(miss.VWAP,periods=5), log_return(miss.VWAP,periods=1).abs(), \n               upper_shadow(miss), lower_shadow(miss)], axis=1)\ny_eth = miss.Target","ed55f64a":"# select training and test periods\ntrain_window = [totimestamp(\"01\/05\/2021\"), totimestamp(\"30\/05\/2021\")]\ntest_window = [totimestamp(\"01\/06\/2021\"), totimestamp(\"30\/06\/2021\")]\n\n# divide data into train and test, compute X and y\n# we aim to build simple regression models using a window_size of 1\nX_btc_train = X_btc.loc[train_window[0]:train_window[1]].fillna(0).to_numpy()  # filling NaN's with zeros\ny_btc_train = y_btc.loc[train_window[0]:train_window[1]].fillna(0).to_numpy()  \n\nX_btc_test = X_btc.loc[test_window[0]:test_window[1]].fillna(0).to_numpy() \ny_btc_test = y_btc.loc[test_window[0]:test_window[1]].fillna(0).to_numpy() \n\nX_eth_train = X_eth.loc[train_window[0]:train_window[1]].fillna(0).to_numpy()  \ny_eth_train = y_eth.loc[train_window[0]:train_window[1]].fillna(0).to_numpy()  \n\nX_eth_test = X_eth.loc[test_window[0]:test_window[1]].fillna(0).to_numpy() \ny_eth_test = y_eth.loc[test_window[0]:test_window[1]].fillna(0).to_numpy() ","4b19078c":"from sklearn.preprocessing import StandardScaler\n# simple preprocessing of the data \nscaler = StandardScaler()\n\nX_btc_train_scaled = scaler.fit_transform(X_btc_train)\nX_btc_test_scaled = scaler.transform(X_btc_test)\n\nX_eth_train_scaled = scaler.fit_transform(X_eth_train)\nX_eth_test_scaled = scaler.transform(X_eth_test)","6cef4d36":"from sklearn.linear_model import LinearRegression\n\n# implement basic ML baseline (one per asset)\nlr = LinearRegression()\nlr.fit(X_btc_train_scaled,y_btc_train)\ny_pred_lr_btc = lr.predict(X_btc_test_scaled)\n\nlr.fit(X_eth_train_scaled,y_eth_train)\ny_pred_lr_eth = lr.predict(X_eth_test_scaled)","bb834c5c":"# implement more complex baseline (multiple output regression model)\nfrom sklearn.multioutput import MultiOutputRegressor\n\n# we concatenate X and y for both assets\nX_both_train = np.concatenate((X_btc_train_scaled, X_eth_train_scaled), axis=1)\nX_both_test = np.concatenate((X_btc_test_scaled, X_eth_test_scaled), axis=1)\ny_both_train = np.column_stack((y_btc_train, y_eth_train))\ny_both_test = np.column_stack((y_btc_test, y_eth_test))\n\n# define the direct multioutput model and fit it\nmlr = MultiOutputRegressor(LinearRegression())\nlr.fit(X_both_train,y_both_train)\ny_pred_lr_both = lr.predict(X_both_test)","53fe60b7":"print('Test score for LR baseline: BITCOIN', f\"{np.corrcoef(y_pred_lr_btc, y_btc_test)[0,1]:.2f}\", \n                                ', ETHEREUM', f\"{np.corrcoef(y_pred_lr_eth, y_eth_test)[0,1]:.2f}\")\nprint('Test score for multiple output LR baseline: BITCOIN', f\"{np.corrcoef(y_pred_lr_both[:,0], y_btc_test)[0,1]:.2f}\", \n                                                ', ETHEREUM', f\"{np.corrcoef(y_pred_lr_both[:,1], y_eth_test)[0,1]:.2f}\")","1cdf8d45":"## Loading Data","9add368b":"## Baseline model: Linear Regression\n- We will try a simple Linear Regression model on the features we designed. Note that Linear Regression is not commonly used in time series analysis, specially with only one time step! \n\n- We compare two Linear Regression baselines, one that considers each asset independently and one multiple inputs that models all assets together.\n","b4d415e6":"## In order to analyze price changes for an asset we can deal with the price difference. However, different assets exhibit different price scales, so that the their returns are not readily comparable. We can solve this problem by computing the percentage change in price instead, also known as the return. This return coincides with the percentage change in our invested capital.\n\n## Returns are widely used in finance, however log returns are preferred for mathematical modelling of time series, as they are additive across time. Also, while regular returns cannot go below -100%, log returns are not bounded.\n\n## To compute the log return, we can simply take the logarithm of the ratio between two consecutive prices. The first row will have an empty return as the previous value is unknown, therefore the empty return data point will be dropped.","0e272b73":"- On shorter intervals we can visually see some potential correlation between both assets, with some simultaneous ups and downs. A better format for analyzing such movements is by calculating asset returns. \n","277991af":"## Stored In Variable","38e3ed51":"## Data features\n-  **timestamp**: All timestamps are returned as second Unix timestamps (the number of seconds elapsed since 1970-01-01 00:00:00.000 UTC). Timestamps in this dataset are multiple of 60, indicating minute-by-minute data.","7ec81680":"## Data visualisation\n- We  will start by visualising the Close prices for the two assets we have selected.","4de75f89":"# Preprocessing \n- ","d12e4fe0":"## We can also check the correlation between all assets visualizing the correlation matrix. Note how some assets have much higher pairwise correlation than others.","82079ceb":"## Submission \n\nNote that this is a Code Competition, in which you must submit your notebook to be run against the hidden private data. Your notebook should use the provided python time-series API, which ensures that models do not peek forward in time. To use the API, follow the instructions and template in [Code Competition Detailed API instructions](https:\/\/www.kaggle.com\/eranuragsingh\/anurag-detailed-api-introduction\/edit) and [Basic Submission Template](https:\/\/www.kaggle.com\/eranuragsingh\/anurag-basic-submission-template\/edit).","85e1ccf8":"## Correlation between assets\n\n- We hypothesized before that crypto asset returns may exhibit some correlation. Let's check this in more detail now.\n- We can check how the correlation between Bitcoin and Ethereum change over time for the 2021 period we selected. \n\n\n\n","0d7c4749":"- We encourage participants to perform additional statistical analyses to have a stronger grasp on the dataset, including autocorrelation, time-series decomposition and stationarity tests.\n","8c03d386":"# Building your prediction model","78a98944":"## Evaluate baselines\n- The competition performance metric is weighted correlation. However, for now we will use simple correlation to evaluate the two baseline models built.","23c30f1e":"## A stationary behaviour of a system or a process is characterized by non-changing statistical properties over time such as the mean, variance and autocorrelation. On the other hand, a non-stationary behaviour is characterized by a continuous change of statistical properties over time. Stationarity is important because many useful analytical tools and statistical tests and models rely on it.\n","e22df418":"## Log returns","e356ee2f":"## Note the high but variable correlation between the assets. Here we can see that there is some changing dynamics over time, and this would be critical for this time series challenge, that is, how to perform forecasts in a highly non-stationary environment.\n","d1e78f5a":"- Missing asset data, for a given minute, is not represented by NaN's, but instead by the absence of those rows. We can check the timestamp difference between consecutive rows to see if there is missing data.","f00e6734":"## We can visualize the log return for our two assets. See how the signal now looks more like white noise, with less drift than the time series for prices.\n","594ac478":"## We can see that, for the training and test periods selected, the multiple asset LR model performs better than simply modelling each asset separately. Note that because the data is highly non-stationary, these results might vary a lot for different periods.\n","f950211c":"- Notice that there are many gaps in the data. To work with most time series models, we should preprocess our data into a format without time gaps. To fill the gaps, we can use the `.reindex()` method for forward filling, filling gaps with the previous valid value. \n","0d19badc":"## Dealing with missing data ","227374a4":"## We now standardize the input data. Standardization is the process of putting different variables on the same scale. In regression analysis, it is often crucial to standardize your independent variables or you may risk obtaining misleading results.\n"}}