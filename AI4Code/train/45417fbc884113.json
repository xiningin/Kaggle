{"cell_type":{"1c7c4556":"code","e8851d96":"code","84959a9e":"code","b1dd94da":"code","f84a607f":"code","07cee1a2":"markdown","ae4db6ad":"markdown","2926a0c4":"markdown"},"source":{"1c7c4556":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom keras.datasets import mnist\nfrom keras.layers import Input, Dense, Reshape, Flatten, Dropout\nfrom keras.layers import BatchNormalization, Activation, ZeroPadding2D\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers.convolutional import UpSampling2D, Conv2D\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\nimport cv2\nfrom PIL import Image","e8851d96":"X_train=np.load('..\/input\/train-imgs.npz')['arr_0']\nY_train=np.load('..\/input\/train-labels.npz')['arr_0']","84959a9e":"img_rows = 28\nimg_cols = 28\nchannels = 1\nimg_shape = (img_rows, img_cols, channels)\nlatent_dim = 100","b1dd94da":"def generate_model_for_class(class_generator):\n    _indices = np.where(Y_train==class_generator)\n    x_train = X_train[_indices]\n    \n    def build_generator():\n        model = Sequential()\n        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=latent_dim))\n        model.add(Reshape((7, 7, 128)))\n        model.add(UpSampling2D())\n        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Activation(\"relu\"))\n        model.add(UpSampling2D())\n        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Activation(\"relu\"))\n        model.add(Conv2D(channels, kernel_size=3, padding=\"same\"))\n        model.add(Activation(\"tanh\"))\n        model.summary()\n        noise = Input(shape=(latent_dim,))\n        img = model(noise)\n        return Model(noise, img)\n    \n    def build_discriminator():\n        model = Sequential()\n        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.25))\n        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.25))\n        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.25))\n        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.25))\n        model.add(Flatten())\n        model.add(Dense(1, activation='sigmoid'))\n        model.summary()\n        img = Input(shape=img_shape)\n        validity = model(img)\n        return Model(img, validity)\n    \n    optimizer = Adam(0.0002, 0.5)\n    \n    discriminator = build_discriminator()\n    discriminator.compile(loss='binary_crossentropy',\n                          optimizer=optimizer,\n                          metrics=['accuracy'])\n\n    # build generator\n    generator = build_generator()\n    z = Input(shape=(100,))\n    img = generator(z)\n\n    # The discriminator takes generated images as input and determines validity\n    valid = discriminator(img)\n\n    # The combined model  (stacked generator and discriminator)\n    # Trains the generator to fool the discriminator\n    combined = Model(z, valid)\n    combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n    \n    \n    def train(epochs, batch_size, save_interval, x_train):\n        os.makedirs('images', exist_ok=True)        \n\n        # Rescale -1 to 1\n        x_train = x_train \/ 127.5 - 1.\n        x_train = np.expand_dims(x_train, axis=3)\n\n        # Adversarial ground truths\n        valid = np.ones((batch_size, 1))\n        fake = np.zeros((batch_size, 1))\n\n        for epoch in range(epochs):\n            # Select a random real images\n            idx = np.random.randint(0, x_train.shape[0], batch_size)\n            real_imgs = x_train[idx]\n\n            # Sample noise and generate a batch of fake images\n            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n            fake_imgs = generator.predict(noise)\n\n            # Train the discriminator\n            D_loss_real = discriminator.train_on_batch(real_imgs, valid)\n            D_loss_fake = discriminator.train_on_batch(fake_imgs, fake)\n            D_loss = 0.5 * np.add(D_loss_real, D_loss_fake)\n\n            # Train the generator\n            g_loss = combined.train_on_batch(noise, valid)\n\n            # If at save interval\n            if epoch % save_interval == 0:\n                # Print the progress\n                print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, D_loss[0], 100 * D_loss[1], g_loss))\n\n    start = time.time()\n\n    train(epochs=70000, batch_size=32, save_interval=1000, x_train=x_train)\n\n    end = time.time()\n    elapsed_train_time = 'elapsed training time: {} min, {} sec '.format(int((end - start) \/ 60),\n                                                                         int((end - start) % 60))\n    print(elapsed_train_time)\n    generator.save('generator_'+str(class_generator)+'.h5')","f84a607f":"for i in range(0,10):\n    generate_model_for_class(i)","07cee1a2":"# Build GAN model","ae4db6ad":"# Load training data","2926a0c4":"# Create a generative model for each class"}}