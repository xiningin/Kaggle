{"cell_type":{"0b0e4fc4":"code","4bb22268":"code","31e5ecfe":"code","8900b667":"code","37b5f750":"code","96b62c49":"code","1bee8e17":"code","1797eb10":"code","d88d7e1f":"code","11a4bb96":"code","5a623177":"code","f9a9071c":"code","2dc296c9":"code","c6ff4877":"code","7ad75fee":"code","ef550070":"code","bfc3198a":"code","8353cb6f":"code","92ca43bd":"code","64c7d8e0":"code","429500d8":"code","d81a09f3":"code","455429a0":"code","6d166c98":"markdown","4f974a64":"markdown","a9948448":"markdown","88d33838":"markdown","e22bfb2d":"markdown","4cf2759d":"markdown","26aac590":"markdown","9b2593de":"markdown","db3b0407":"markdown","e73b0fc9":"markdown","26cc7a97":"markdown","3de5996e":"markdown","ad5711ec":"markdown"},"source":{"0b0e4fc4":"import numpy as np\nimport pandas as pd","4bb22268":"train=pd.read_csv(\"..\/input\/train.csv\")\ntest=pd.read_csv(\"..\/input\/test.csv\")\nsub=pd.read_csv(\"..\/input\/sample_submission.csv\")","31e5ecfe":"train.head()","8900b667":"test.head()","37b5f750":"Y=train[\"label\"]\nX=train.drop(columns=['label'])","96b62c49":"print(X.shape)\nprint(Y.shape)","1bee8e17":"X = X \/ 255.0\ntest = test \/ 255.0","1797eb10":"X = X.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","d88d7e1f":"from keras.utils.np_utils import to_categorical\nY = to_categorical(Y, num_classes = 10)","11a4bb96":"from sklearn.model_selection import train_test_split","5a623177":" X_train, X_test, y_train, y_test = train_test_split(\n...     X, Y, test_size=0.33, random_state=42)","f9a9071c":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D","2dc296c9":"#Model 1\nmodel = Sequential()\n#Layer 1\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n#Layer2\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n#Layer3\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))\nmodel.summary()","c6ff4877":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","7ad75fee":"history=model.fit(X,Y,validation_split=0.2,epochs=40)","ef550070":"import matplotlib.pyplot as plt\nplt.figure(1)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Complexity Graph:  Training vs. Validation Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validate'], loc='upper right')\n\nplt.figure(2)\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('Model Accuracy Graph:  Training vs. Validation accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validate'], loc='upper right')\nplt.show()\n\n","bfc3198a":"from keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(featurewise_center=False, \n                             samplewise_center=False, \n                             featurewise_std_normalization=False, \n                             samplewise_std_normalization=False, \n                             zca_whitening=False, \n                             zca_epsilon=1e-06, \n                             rotation_range=10, \n                             width_shift_range=0.1, \n                             height_shift_range=0.1, \n                             brightness_range=None, \n                             shear_range=0.1, \n                             zoom_range=0.15, \n                             channel_shift_range=0.0, \n                             fill_mode='nearest', \n                             cval=0.0, \n                             horizontal_flip=False, \n                             vertical_flip=False, \n                             rescale=None, \n                             preprocessing_function=None, \n                             data_format=None, validation_split=0.0, dtype=None)","8353cb6f":"datagen.fit(X)","92ca43bd":"#model.compile(optimizer = \"Nadam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])","64c7d8e0":"#history=model.fit(X,Y,validation_split=0.2,epochs=40)","429500d8":"#plt.figure(1)\n#plt.plot(history.history['loss'])\n#plt.plot(history.history['val_loss'])\n#plt.title('Model Complexity Graph:  Training vs. Validation Loss')\n#plt.ylabel('loss')\n#plt.xlabel('epoch')\n#plt.legend(['train', 'validate'], loc='upper right')\n\n#plt.figure(2)\n#plt.plot(history.history['acc'])\n#plt.plot(history.history['val_acc'])\n#plt.title('Model Accuracy Graph:  Training vs. Validation accuracy')\n#plt.ylabel('accuracy')\n#plt.xlabel('epoch')\n#plt.legend(['train', 'validate'], loc='upper right')\n#plt.show()\n\n","d81a09f3":"pred = model.predict(test)\npred = np.argmax(pred,axis = 1)\npred = pd.Series(pred,name=\"Label\")","455429a0":"out = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),pred],axis = 1)\nout.to_csv(\"output.csv\",index=False)","6d166c98":"### After train visualizations","4f974a64":"reading files","a9948448":"Splitting data","88d33838":"### Help me increase the accuracy :)","e22bfb2d":"### Predicting","4cf2759d":"Separating the data","26aac590":"Normalizing","9b2593de":"### Modelling\nusing CNN","db3b0407":"### With Augmentation","e73b0fc9":"Reshaping","26cc7a97":"### Imports","3de5996e":"Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0]) \n\nReference from : https:\/\/medium.com\/@contactsunny\/label-encoder-vs-one-hot-encoder-in-machine-learning-3fc273365621\n","ad5711ec":"### After train visualizations"}}