{"cell_type":{"dadfde39":"code","65be4138":"code","c5b7cad6":"code","797f74bb":"code","e00ee8b0":"code","7eeaa26a":"code","af497aa2":"markdown","70b46d14":"markdown","6418f333":"markdown","94a06542":"markdown"},"source":{"dadfde39":"# import library (pustaka) yang dibutuhkan\nimport cv2 #pustaka pengolah image dan video\nimport numpy as np #pustaka pengolah array\nimport matplotlib.pyplot as plt #pustaka untuk visualisasi\n\n# install library tambahan (download)\n!pip install imutils\nimport imutils\n\nimport time","65be4138":"\n# from scipy.spatial import distance as dist #pustaka u\/ menghitung jarak\n# from collections import OrderedDict #pustaka u\/ sorting","c5b7cad6":"# kelas utills atau utilitas\nclass utills:\n\n    # Fungsi u\/ menentukan bottom center dari semua bounding boxes object--\n    # --dan kemudian akan digunakan u\/ melakukan transformasi dari prespective-view ke bird-view\n    def get_transformed_points(boxes, prespective_transform):\n        \n        # initialize rects dan bottom_points yg berguna untuk menyimpan array bottom center--\n        # --dari bounding box object\n        rects = []\n        bottom_points = []\n        \n        for box in boxes:\n            pnts = np.array([[[int(box[0]+(box[2]*0.5)),int(box[1]+box[3])]]] , dtype=\"float32\")\n            bd_pnt = cv2.perspectiveTransform(pnts, prespective_transform)[0][0]\n            pnt = [int(bd_pnt[0]), int(bd_pnt[1])]\n            pnt_bird = [int(bd_pnt[0]), int(bd_pnt[1]), 0, 0]\n            \n            bottom_points.append(pnt)\n            rects.append(np.array(pnt_bird))\n\n        return bottom_points, rects\n    \n    \n    \n    # Fungsi u\/ menghitung jarak antar dua point object (orang).\n    # distance_w, distance_h mempresentasikan pixel-to-metric ratio atau--\n    # --besar nilai pixel untuk jarak 180 cm dalam frame video.\n    def cal_dis(p1, p2, distance_w, distance_h):\n\n        h = abs(p2[1]-p1[1])\n        w = abs(p2[0]-p1[0])\n\n        dis_w = float((w\/distance_w)*180)\n        dis_h = float((h\/distance_h)*180)\n\n        return int(np.sqrt(((dis_h)**2) + ((dis_w)**2)))\n\n    \n    \n    \n    # Fungsi u\/ menghitung jarak antar semua titik object dan--\n    # --menghiutng closeness ratio (rasio kedekatan).\n    def get_distances(boxes1, bottom_points, distance_w, distance_h):\n\n        distance_mat = []\n        bxs = []\n\n        for i in range(len(bottom_points)):\n            for j in range(len(bottom_points)):\n                if i != j:\n                    dist = utills.cal_dis(bottom_points[i], bottom_points[j], distance_w, distance_h)\n                    if dist <= 180:\n                        closeness = 0\n                        distance_mat.append([bottom_points[i], bottom_points[j], closeness])\n                        bxs.append([boxes1[i], boxes1[j], closeness])      \n                    else:\n                        closeness = 2\n                        distance_mat.append([bottom_points[i], bottom_points[j], closeness])\n                        bxs.append([boxes1[i], boxes1[j], closeness])\n\n        return distance_mat, bxs\n\n    \n    \n    # Function gives scale for birds eye view  \n    # Fungsi memberikan skala untuk transformasi bird-view\n    # Skala yg digunakan w:480, h:1180 (video=1080 + pad=100) \n    def get_scale(W, H):\n        dis_w = 387\n        dis_h = 580\n        return float(dis_w\/W),float(dis_h\/H)\n\n    \n    \n    \n    # Fungsi u\/ menghitung jumlah objek (orang) yg melakukan pelanggaran\n    def get_count(distances_mat):\n        r = []\n        g = []\n        for i in range(len(distances_mat)):\n            if distances_mat[i][2] == 0:\n                if (distances_mat[i][0] not in r) and (distances_mat[i][0] not in g):\n                    r.append(distances_mat[i][0])\n                if (distances_mat[i][1] not in r) and (distances_mat[i][1] not in g):\n                    r.append(distances_mat[i][1])\n        for i in range(len(distances_mat)):\n            if distances_mat[i][2] == 2:\n                if (distances_mat[i][0] not in r) and (distances_mat[i][0] not in g):\n                    g.append(distances_mat[i][0])\n                if (distances_mat[i][1] not in r) and (distances_mat[i][1] not in g):\n                    g.append(distances_mat[i][1])\n        return (len(r), len(g))","797f74bb":"class plot:\n\n    # Fungsi u\/ melakukan transformasi bird-view\n    def bird_eye_view(frame, distances_mat, bottom_points, scale_w, scale_h, risk_count):\n        h = frame.shape[0]\n        w = frame.shape[1]\n\n        red = (0, 0, 255, 255)\n        green = (0, 255, 0, 255)\n        white = (200, 200, 200, 255)\n        map_bg = (0,0,0,0)\n        black = (0,0,0, 255)\n        \n        blank_image = np.zeros((int(h * scale_h), int(w * scale_w), 4), np.uint8)\n        blank_image[:] = white\n        red_image = np.zeros((int(h * scale_h), int(w * scale_w), 4), np.uint8)\n        red_image[:] = map_bg\n        \n        warped_pts = []\n        r = []\n        g = []\n\n        for i in range(len(distances_mat)):\n            if distances_mat[i][2] == 0:\n                if (distances_mat[i][0] not in r) and (distances_mat[i][0] not in g):\n                    r.append(distances_mat[i][0])\n                if (distances_mat[i][1] not in r) and (distances_mat[i][1] not in g):\n                    r.append(distances_mat[i][1])\n                    \n                # menggambar garis untuk pelanggaran    \n                blank_image = cv2.line(blank_image, (int(distances_mat[i][0][0] * scale_w), \n                                                     int(distances_mat[i][0][1] * scale_h)), \n                                       (int(distances_mat[i][1][0] * scale_w), \n                                        int(distances_mat[i][1][1]* scale_h)), red, 2)\n\n        for i in range(len(distances_mat)):\n            if distances_mat[i][2] == 2:\n                if (distances_mat[i][0] not in r) and (distances_mat[i][0] not in g):\n                    g.append(distances_mat[i][0])\n                if (distances_mat[i][1] not in r) and (distances_mat[i][1] not in g):\n                    g.append(distances_mat[i][1])\n        \n        # menggambar circle pada setiap objek yg terdeteksi\n        for i in bottom_points:\n            blank_image = cv2.circle(blank_image, (int(i[0]  * scale_w), int(i[1] * scale_h)), 5, green, 10)\n        for i in r:\n            blank_image = cv2.circle(blank_image, (int(i[0]  * scale_w), int(i[1] * scale_h)), 5, red, 10)\n            red_image = cv2.circle(red_image, (int(i[0]  * scale_w), int(i[1] * scale_h)), 10, red, 10)\n        return blank_image, red_image\n    \n    \n    \n    # Fungsi u\/ drawing bounding boxes pada frame perspective view--\n    # --dan drawing lines antar objek yg melakukan pelanggaran\n    def social_distancing_view(frame, distances_mat, boxes, risk_count, bird_view):\n\n        red = (0, 0, 255)\n        green = (0, 255, 0)\n        \n        # gambar bounding box u\/ yg tidak melanggar\n        for i in range(len(boxes)):\n            x,y,w,h = boxes[i][:]\n            frame = cv2.rectangle(frame,(x,y),(x+w,y+h),green,2)\n\n        for i in range(len(distances_mat)):\n            per1 = distances_mat[i][0]\n            per2 = distances_mat[i][1]\n            closeness = distances_mat[i][2]\n\n            if closeness == 0:\n                x,y,w,h = per1[:]\n                frame = cv2.rectangle(frame,(x,y),(x+w,y+h),red,2)\n\n                x1,y1,w1,h1 = per2[:]\n                frame = cv2.rectangle(frame,(x1,y1),(x1+w1,y1+h1),red,2)\n\n                frame = cv2.line(frame, (int(x+w\/2), int(y+h\/2)), (int(x1+w1\/2), int(y1+h1\/2)),red, 2)\n                \n            # buat pad (padding) pada sisi bawah frame prespective-view\n            # dengan h=100, dan w=frame.shape[1]\n            pad = np.full((100,frame.shape[1],4), [250, 250, 250, 255], dtype=np.uint8)\n\n            # draw text pada padding\n            cv2.putText(pad, \"Jumlah Orang Terdeteksi : \" + str(risk_count[0] + risk_count[1]) + \" Orang\", (100, 40),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (100, 100, 0), 2)\n            cv2.putText(pad, \"Jumlah Pelanggaran Social Distancing : \" + str(risk_count[0]) + \" Orang\", (100, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n    \n        # gabungkan pad dengan frame prespective-view\n        # dan kemudian gabungkan dengan bird-view\n        frame = np.vstack((frame,pad))\n        frame = np.hstack((frame, bird_view))\n    \n        return frame","e00ee8b0":"# Fungsi u\/ melakukan processing social distancing detector\ndef calculate_social_distancing(vid_path, net, ln1, points):\n    \n    # initialize count dan video capture\n    count = 0\n    vs = cv2.VideoCapture(vid_path)    \n\n    # Ambil video height, width dan fps\n    height = int(vs.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    width = int(vs.get(cv2.CAP_PROP_FRAME_WIDTH))\n    fps = int(vs.get(cv2.CAP_PROP_FPS))\n    \n    # Tentukan skala untuk bird-view\n    scale_w, scale_h = utills.get_scale(width, height)\n    \n    # initialize penyimpanan video output hasil processing\n    fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n    output_movie = cv2.VideoWriter(\"Social Distancing Detection.avi\", fourcc, fps, (1540, 720), True)\n    \n    # variable berisi nilai red \/ map pelanggaran\n    RED_IMAGE = []\n    \n    global image\n    \n    # mulai processing dengan loop pada video capture\n    while True:\n        \n        # ambil grab dan frame\n        (grabbed, frame) = vs.read()\n\n        # berhenti saat nilai grab = false\n        if not grabbed:\n            print(\"[INFO] Processing done...\")\n            break\n        \n        # ambil H dan W dari frame vs\n        (H, W) = frame.shape[:2]\n          \n        # initialize src yg berisi 4 titik tranformasi, dan--\n        # --dst yang berisi 4 titik ukuran vs sebenarnya\n        # prespective_transform berisi matriks u\/ transformasi prespective ke bird-view\n        src = np.float32(np.array(points[:4]))\n        dst = np.float32([[0, H], [W, H], [W, 0], [0, 0]])\n        prespective_transform = cv2.getPerspectiveTransform(src, dst)\n        \n        # invers matriks u\/ transformasi bird ke prespective-view\n        inv_trans = np.linalg.pinv(prespective_transform)\n        \n        # gunakan 3 titik setelahnya u\/ pixel-to-metric ratio dalam variable pts\n        # warped_pt berisi transformasi 3 titik pada bird-view\n        pts = np.float32(np.array([points[4:7]]))\n        warped_pt = cv2.perspectiveTransform(pts, prespective_transform)[0]\n        \n        # initialize distance_w, dan distance_h yg masing2 berisi jarak 180 cm dalam satuan pixel\n        distance_w = np.sqrt((warped_pt[0][0] - warped_pt[1][0]) ** 2 + (warped_pt[0][1] - warped_pt[1][1]) ** 2)\n        distance_h = np.sqrt((warped_pt[0][0] - warped_pt[2][0]) ** 2 + (warped_pt[0][1] - warped_pt[2][1]) ** 2)\n        \n        # draw 4 titik transformasi pada frame video prespective-view\n        pnts = np.array(points[:4], np.int32)\n        cv2.polylines(frame, [pnts], True, (70, 70, 70), thickness=2)\n    \n        # Memproses deteksi dengan pre-trained model YOLO-v3\n        blob = cv2.dnn.blobFromImage(frame, 1 \/ 255.0, (416, 416), swapRB=True, crop=False)\n        net.setInput(blob)\n        start = time.time()\n        layerOutputs = net.forward(ln1)\n        end = time.time()\n        \n        boxes = []\n        confidences = []\n        classIDs = []   \n        rects = []\n    \n        for output in layerOutputs:\n            for detection in output:\n                scores = detection[5:]\n                classID = np.argmax(scores)\n                confidence = scores[classID]\n                \n                # deteksi (hanya) orang pada frame\n                # YOLO menggunakan dataset COCO dimana index human dalam--\n                # --dataset berada pada index 0\n                if classID == 0:\n\n                    if confidence > confid:\n\n                        box = detection[0:4] * np.array([W, H, W, H])\n                        (centerX, centerY, width, height) = box.astype(\"int\")\n                                    \n                        x = int(centerX - (width \/ 2))\n                        y = int(centerY - (height \/ 2))\n                        \n                        boxes.append([x, y, int(width), int(height)])\n                        confidences.append(float(confidence))\n                        classIDs.append(classID)\n            \n        idxs = cv2.dnn.NMSBoxes(boxes, confidences, confid, thresh)\n        font = cv2.FONT_HERSHEY_PLAIN\n        boxes1 = []\n        \n        for i in range(len(boxes)):\n            if i in idxs:\n                boxes1.append(boxes[i])\n                x,y,w,h = boxes[i]\n                \n        if len(boxes1) == 0:\n            count = count + 1\n            continue\n            \n        # initialize bottom-center dari setiap bounding-box yg terdeteksi, dan--\n        # initialize rects yg berisi bottom-center untuk digunakan pada generating ID's\n        person_points, rects = utills.get_transformed_points(boxes1, prespective_transform)\n\n        \n        frame1 = np.copy(frame)\n        # convert frame1 (rgb) to frame1 (rbga)\n        r, g, b = cv2.split(frame1)\n        alpha_frame1 = np.ones(r.shape, np.uint8)*255\n        frame1 = cv2.merge((r,g,b,alpha_frame1))\n        \n        # Hitung dan pelanggaran jarak antar objek (manusia) pada transformasi bird-view\n        distances_mat, bxs_mat = utills.get_distances(boxes1, person_points, distance_w, distance_h)\n        risk_count = utills.get_count(distances_mat)\n    \n        # Draw bird eye view and frame with bouding boxes around humans according to risk factor \n        # Hasilkan video output transformasi bird-view, dan--\n        # gunakan hasil u\/ digabungkan dgn video output prespective-view \n        bird_image, red_image = plot.bird_eye_view(frame, distances_mat, person_points, scale_w, scale_h, \n                                        risk_count)\n        RED_IMAGE.append(red_image)\n        \n        # buat map pelanggaran\n        for red_image in RED_IMAGE:\n            red_point = red_image[:, :, 3] > 0\n            bird_image[red_point] = red_image[red_point]\n            \n        img = plot.social_distancing_view(frame1, bxs_mat, boxes1, risk_count, bird_image)\n        \n        # resizing video output\n        img = imutils.resize(img, height=720)\n        img_r, img_g, img_b, img_a = cv2.split(img)\n        img = cv2.merge((img_r,img_g,img_b))\n        \n        # write video\n        if count != 0:\n            output_movie.write(img)    \n        count = count + 1","7eeaa26a":"# initialize confidence dan threshold\nconfid = 0.5\nthresh = 0.5\n\n# initialize 7 titik transformasi prespective-view ke bird-view\n# 4 titik pertama (bottom-left, bottom-right, top-right, top-left) digunakan u\/--\n# --melakukan transformasi prespective ke bird-view\n# 3 titik setelahnya digunakan untuk menghitung pixel-to-metric ratio\npts = [(0, 236.2), (615.86, 346.92), (853.5, 7), (500.25, 7), \n       (382.11, 271.98), (445.91, 285.82), (427, 236.2)]\n\n# Load Yolov3 weights\nweightsPath = \"..\/input\/yolo-coco-data\/yolov3.weights\"\nconfigPath = \"..\/input\/yolo-coco-data\/yolov3.cfg\"\n\nnet_yl = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\nln = net_yl.getLayerNames()\nln1 = [ln[i[0] - 1] for i in net_yl.getUnconnectedOutLayers()]\n\nnet_yl.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\nnet_yl.setPreferableTarget(cv2.dnn.DNN_TARGET_OPENCL_FP16)\n\n# initialize video path\nvideo_path = \"..\/input\/social-distancing\/Pedestrian 480p.mp4\"\n\n# hitung waktu running; MULAI\nt1 = cv2.getTickCount()\n\n# processing social distancing detector\ncalculate_social_distancing(video_path, net_yl, ln1=ln1, points=pts)\n\n# hitung waktu running; SELESAI\nt2 = cv2.getTickCount()\n\n# hitung waktu running\nt3 = (t2 - t1)\/ cv2.getTickFrequency()\nprint(\"Waktu yang dibutuhkan :\", t3)","af497aa2":"# Utills Class\nUtills Class atau kelas utilitas berisi fungsi yang berguna dalam membantu\npenerapan sistem seperti :\n1. Transformasi dari prespective-view ke bird-view\n2. Menghitung pelanggaran social distancing ","70b46d14":"# Processing Social Distancing Detector","6418f333":"# Social Distancing Detektor Berbasis Computer Vision","94a06542":"# Plot Class\nPlot Class atau Kelas Ploting digunakan u\/ melakukan fungsi plotting atau drawing pada frame video"}}