{"cell_type":{"108227aa":"code","63d4314e":"code","79e04ef7":"code","5404390f":"code","66d08cad":"code","0443cd88":"code","fecd9ede":"code","28d19e6f":"code","b8b1f31a":"code","a35b6175":"code","98c460de":"code","2f03fc49":"code","f1225e07":"code","39c35c5b":"code","4cdd7cfa":"code","c66b04d1":"code","a9126f76":"code","3d03639c":"code","6a2a79d0":"code","313e583f":"code","c108609f":"markdown","6ef65b3a":"markdown","1d87b84d":"markdown","856fd860":"markdown","b4f4f916":"markdown","ef04067e":"markdown","31dd9f9b":"markdown","001e3210":"markdown","5f8fc56b":"markdown","5a54c786":"markdown","498ffc64":"markdown","b8d384a4":"markdown","c452e336":"markdown","caed0439":"markdown","06b95bc0":"markdown"},"source":{"108227aa":"import tensorflow as tf\n\nphysical_devices = tf.config.experimental.list_physical_devices('GPU')\n\ntf.config.experimental.set_memory_growth(physical_devices[0], True)","63d4314e":"! git clone https:\/\/github.com\/Nelson-Gon\/cytounet.git","79e04ef7":"%cd cytounet","5404390f":"from cytounet.model import *\nfrom cytounet.data import *\nfrom cytounet.augmentation import *","66d08cad":"!  ls examples\/BBBC003_v1\/","0443cd88":"data_generator_args =  dict(rotation_range=0.1,\n                      rescale = 1.\/255,\n                    width_shift_range=0.1,\n                    height_shift_range=0.1,\n                    shear_range=0.1,\n                    zoom_range=0.1,\n                    horizontal_flip=True,\n                    fill_mode='nearest')","fecd9ede":"! if [ ! -d \"aug\" ]; then mkdir aug;fi","28d19e6f":"train_gen = generate_train_data(5, \"examples\/BBBC003_v1\",\"images\", \"truth\",aug_dict = data_generator_args,\n                                 seed = 2, target_size = (512, 512), save_to_dir=\"aug\")","b8b1f31a":"for i, batch in enumerate(train_gen):\n    if i>= 5:\n        break","a35b6175":"! ls aug | wc -l","98c460de":"! if [ ! -d  \"aug\/images\" ]; then mkdir aug\/images aug\/masks;fi","2f03fc49":"! mv aug\/image_* aug\/images && mv aug\/mask_* aug\/masks && ls aug\/masks | wc -l","f1225e07":"def load_augmentations(image_path, mask_path, image_prefix=\"image\", mask_prefix=\"mask\"):\n    image_name_arr = glob.glob(os.path.join(image_path, \"{}*.png\".format(image_prefix)))\n    image_arr = []\n    mask_arr = []\n    for index, item in enumerate(image_name_arr):\n        img = image.load_img(item, color_mode=\"grayscale\", target_size = (512, 512))\n        img = image.img_to_array(img)\n       \n        mask = image.load_img(item.replace(image_path, mask_path).replace(image_prefix, mask_prefix),\n                              color_mode=\"grayscale\", target_size = (512, 512))\n        mask = image.img_to_array(mask)\n       \n        image_arr.append(img)\n        mask_arr.append(mask)\n    image_arr = np.array(image_arr)\n    mask_arr = np.array(mask_arr)\n    return image_arr, mask_arr","39c35c5b":"images, masks = load_augmentations(\"aug\/images\",\"aug\/masks\")","4cdd7cfa":"show_images(images, number=10)","c66b04d1":"show_images(masks, number = 10)","a9126f76":"model = unet(input_size = (512, 512, 1), learning_rate = 1e-4, metrics=[\"accuracy\"],\n            loss=[\"binary_crossentropy\"])","3d03639c":"\nhistory = train(model, train_gen, epochs = 5, steps_per_epoch=150, save_as=\"unet_embryo.hdf5\")","6a2a79d0":"results =  predict(model_object=unet(),test_path=\"aug\/images\", model_weights=\"unet_embryo.hdf5\",\n                  image_length=15, image_suffix=\"png\")","313e583f":"show_images(results, number = 10)","c108609f":"# Model building and training\n\nNext we build our model by calling `unet`. Here, we use binary cross entropy and accuracy as our loss function and metric respectively. You can alternatively use dice coeffiecient, jaccard similarity, mean IOU and so on as you may wish or as theory may allow. \n\nI have found `dice_coef` not to work very well so far. We also use `Adam` as our default optimizer. One could use `SGD` instead. Please try it out and let me know what your results are. ","6ef65b3a":"**Importing relevant modules**\n\nWithin cytounet are a few functions that will be useful for our pipeline. For convenience, we import everything from these modules.","1d87b84d":" \n\nThis section moves our images to target directories, it should be run to generate our test data.","856fd860":"## Cloning the repository\n\nIn this notebook as stated above, we use `cytounet` an implementation of the Unet[algorithm](https:\/\/lmb.informatik.uni-freiburg.de\/people\/ronneber\/u-net\/). The name `cytounet` reflects the fact that this is an implementation of the Unet algorithm for biological data(`cyto`). \n\nThis does not mean that it is limited to biological data. You can play around with different non biological datasets and judge for yourself how well it works. \n\n","b4f4f916":"# Predict on our generated data\n\nFinally, we predict on our generated \"fake\" data and see how well our model does. ","ef04067e":"**Generate training data**\n\nUsing the above arguments,we generate our train data. We also generate \"fake\" data which we save to `aug` to use this as our test data. You can also use this as your validation dataset and feed it to `generate_validation_data`. ","31dd9f9b":"In training our model, most of these hyperparameters are randomly chosen. This is one of the limitations of deep and machine learning in my opinion. One could perform a hyperparameter grid search but at the time of writing, this is not yet implemented in this package. ","001e3210":"**What does our data look like?**\n\nIt is often important to understand what our data looks like. For our purposes, it is especially important to know the file format of our images. It is also a useful idea to `l`ist files in our directory to simply confirm that it in fact is not empty. ","5f8fc56b":"The above tells us that we have generated 60 fake images. ","5a54c786":"**Image Transformations**\n\n First, we need to define a dictionary to define what kind of transformations will be used in our processing functions(`generate_*_data`) which generate augmented images that are then fed to our model on each epoch. This can also be useful if you need to synthesize data to escape the \"curse\" of small datasets which apparently do not work well for deep learning methods. \n \n Of particular interest here is the `rescale` argument which will allow us to transform our images to a form that is recognizable by our model","498ffc64":"# Results\n\n\nFrom these results, it is clear that our model is overfitting on our dataset. We could overcome this by using regularizers such as `L1` and `L2` which use the absolute weights and sum square of the weights for the penalty respectively. \n\nAnother solution is to use a simpler model and build on this to see how model complexity affects the model's output. ","b8d384a4":"For convenience, we shall `c`hange `d`irectory into our newly cloned repository.","c452e336":"# Introduction\n\n\n**Date**: 13th August 2020\n    \n**Author**: Nelson Gonzabato\n    \n\nHello and welcome to another notebook. After a very long break from Kaggle, I have returned and decided to share what I am currently working on. \n\n**What's new in this version of the notebook?**\n\nI have added text to the notebook. More importantly, I have fixed issues with `load_augmentations` that flipped images. It is defined in this notebook and will be committed to `cytounet` later. Thank you for reading and hope you like it.\n\nAs always, please let me know what could be improved. \n\n**Notebook Aims**\n\n\nImage data is an integral part of the biomedical research indsutry especially in experiments that aim to image different stages of the cell or organisms. From imaging embryonic events to histopathological imaging, microscopy is extremely important.\n\nDespite its importance, microscopy tasks are often time consuming and require years of expert experience to not only obtain datasets but also perform such tasks as classifying normal vs diseased samples or simply counting the number of cells in an image.\n\n**Introducing cytounet**\n\n\nTo simplify image segmentation, I have written up a small deep learning based Keras\/Tensorflow python package [cytounet](https:\/\/github.com\/Nelson-Gon\/cytounet\/tree\/master\/cytounet). It should be noted that depsite its relative implementation simplicity, deep learning still has some flaws and limitations that we discusss at the end of this notebook.\n\nWith that short intro, let us dive right into the code. For this task, we are going to generate image labels(masks) for embryonic images from the [Broad Institute](https:\/\/data.broadinstitute.org\/bbbc\/BBBC009\/) ","caed0439":"# Conclusion\n\nThis has been a very brief example of what the unet algorithm could do and how this could be harnessed for biological datasets. Let me know what you think could be improved, better explained or what you think is a better approach.  \n\nFor future steps, as described previously, one could try to:\n\n* test this model on non biological data\n\n* determine the effect of kernel regularization on predicted values\n\n* determine if dropout is a better approach than batch normalization that this model uses.\n\n* define a novel algorithm that does the same with similar or better results.\n\n\nThank you very much for reading. If you would like to contribute to this work, please do so at [cytounet](https:\/\/github.com\/Nelson-Gon\/cytounet). ","06b95bc0":"**View newly generated data**"}}