{"cell_type":{"b9e1a3ff":"code","d317fc26":"code","0828b6d3":"code","6ffdc527":"code","616b9e9e":"code","c3b659ea":"code","fde1ace2":"code","f66db3c3":"code","ca8e613a":"code","9c82c649":"code","3982571c":"code","19985697":"code","256db5d6":"code","18c84207":"code","373c6093":"code","2ef604b9":"code","8d403002":"code","a6007383":"code","5c2f99db":"code","4ad580df":"code","213dd0d9":"code","8be6ab40":"code","48b5219c":"code","68bc0ff0":"code","6e74e1c4":"code","b28e6940":"code","a4642468":"code","ed9c8c86":"code","3971c49b":"code","75808bff":"code","6fa6ece6":"code","f3c13db7":"code","4082a941":"code","555e6b36":"code","bcf3d9cb":"code","65ed622d":"code","fd7b8be1":"code","ebd7d876":"code","aa51aa20":"code","82a02c0f":"code","424d9a7c":"code","bbdb867d":"code","f7add627":"code","fe563e49":"code","edd7ea92":"code","e63f9ef1":"code","60980037":"code","3e4568e7":"code","64239609":"code","ec397ba7":"code","32389489":"code","c1f19807":"code","0eb9b0df":"code","f5756f4a":"code","3ed32448":"code","87c0477e":"code","b7ef6ef4":"code","60f2e92a":"code","6169ed03":"code","e6310743":"code","8a8bee07":"code","fd25abef":"code","f2f52cbe":"code","8aff3350":"code","8b5fa884":"code","0df9d115":"code","29510896":"code","446347d1":"code","a93ee989":"code","4e0360e5":"code","deb7d28a":"code","bea1734b":"code","f8c59df0":"code","9b0968af":"code","9a53ee32":"code","a6c8cc8b":"code","0a299dbf":"markdown","0aea2aa4":"markdown","79424c8e":"markdown","cccbd106":"markdown","a6f9f858":"markdown","a75c0f8f":"markdown","3b4ad70c":"markdown","da603116":"markdown","74df56fe":"markdown","8975a22b":"markdown","dc683b66":"markdown","138592a6":"markdown","e7e89dad":"markdown","0f397d06":"markdown","9ec8e77b":"markdown","b8b51d93":"markdown","d43e0080":"markdown","a66f4bb2":"markdown","79b30e04":"markdown","4e5ab63c":"markdown","56448c96":"markdown","97a98040":"markdown","8e388d1f":"markdown","1811823c":"markdown","b189208e":"markdown","1860c492":"markdown","86c52280":"markdown","5c29a37d":"markdown","263470b7":"markdown","c44d0246":"markdown","0457b3ee":"markdown","50b207ed":"markdown","c57b08ff":"markdown","c4802d24":"markdown","0981804c":"markdown","33c63da3":"markdown","fcaa4d61":"markdown","195ba41b":"markdown","69d87c13":"markdown","e8180af6":"markdown","7cc647b8":"markdown","fa4ca6ba":"markdown","00862709":"markdown","84e7af16":"markdown","84721811":"markdown","7dda723d":"markdown","65bf3736":"markdown"},"source":{"b9e1a3ff":"import torch\n\nprint(torch.__version__)","d317fc26":"torch.get_default_dtype()","0828b6d3":"#This will generate an exception when executed\ntorch.set_default_dtype(torch.int)","6ffdc527":"torch.set_default_dtype(torch.float64)","616b9e9e":"torch.get_default_dtype()","c3b659ea":"#When we use torch.tensor, it's an alias for the default tensor type, \n#torch.FloatTensor, and remember we had set the default data type to be torch.float64\n\ntensor_arr = torch.Tensor([[1,2,3], [4,5,6]])\ntensor_arr","fde1ace2":"torch.is_tensor(tensor_arr)","f66db3c3":"torch.numel(tensor_arr)","ca8e613a":"# uninitialized tensor means that behind the scenes PyTorch will \n# allocate the memory for this tensor, but it won't set up any \n# initial values because you haven't specified any. \n\ntensor_uninitialized = torch.Tensor(2, 2) ","9c82c649":"# You can see that there are some random values within this tensor here\n\ntensor_uninitialized","3982571c":"tensor_initialized = torch.rand(2, 2)","19985697":"tensor_initialized","256db5d6":"# Creates an integer32 tensor on the CPU\n\ntensor_int = torch.tensor([5, 3]).type(torch.IntTensor) \ntensor_int","18c84207":"# Creates an integer of 16 bits tensor on the CPU\n\ntensor_short = torch.ShortTensor([1.0, 2.0, 3.0])   \ntensor_short","373c6093":"tensor_float = torch.tensor([1.0, 2.0, 3.0]).type(torch.half)\ntensor_float","2ef604b9":"tensor_fill = torch.full((2, 6), fill_value=10)\ntensor_fill","8d403002":"tensor_of_ones = torch.ones([2, 4], dtype=torch.int32)\ntensor_of_ones","a6007383":"tensor_of_zeroes = torch.zeros_like(tensor_of_ones)\ntensor_of_zeroes","5c2f99db":"tensor_eye = torch.eye(5)\ntensor_eye","4ad580df":"non_zero = torch.nonzero(tensor_eye)\nnon_zero","213dd0d9":"i = torch.tensor([[0, 1, 1],\n                  [2, 2, 0]])","8be6ab40":"v = torch.tensor([3, 4, 5], dtype=torch.float32)","48b5219c":"# i = indices\n# v = values\n# coo = coordinates\n\nsparse_tensor = torch.sparse_coo_tensor(i, v, [2, 5])","68bc0ff0":"# Every PyTorch tensor has the .data member variable, \n# which you can use to access the underlying matrix. \n\nsparse_tensor.data","6e74e1c4":"initial_tensor = torch.rand(2, 3) \n\ninitial_tensor","b28e6940":"initial_tensor.fill_(10) ","a4642468":"# There is no corresponding out-place func for fill \n#This will generate an exception when executed\n\ninitial_tensor.fill(10) ","ed9c8c86":"# addition broadcast to all values using out of place operation\nnew_tensor = initial_tensor.add(5)\nnew_tensor","3971c49b":"initial_tensor","75808bff":"initial_tensor.add_(8)\ninitial_tensor","6fa6ece6":"new_tensor","f3c13db7":"new_tensor.sqrt_()\nnew_tensor","4082a941":"# generate evenly spaced nums btw 2 given nums (lower and upper bound) with steps given\n\nx = torch.linspace(start=0.1, end=10.0, steps=15)\nx","555e6b36":"# dividing the elements into chunks \n# 3-- num of chunks\n# 0-- dimension along which the seperation occurs\n\ntensor_chunk = torch.chunk(x, 3, 0)\ntensor_chunk ##contain tuple with three different tensors, each with 5 elements","bcf3d9cb":"tensor1 = tensor_chunk[0]\ntensor2 = tensor_chunk[1]\ntensor3 = torch.tensor([3.0, 4.0, 5.0])\n\ntorch.cat((tensor1, tensor2, tensor3), 0)","65ed622d":"random_tensor = torch.Tensor([[10, 8, 30], [40, 5, 6], [12, 2, 21]])\nrandom_tensor","fd7b8be1":"random_tensor[0, 1]","ebd7d876":"random_tensor[1:, 1:]","aa51aa20":"random_tensor_split = torch.split(random_tensor, 2)\nrandom_tensor_split","82a02c0f":"random_tensor","424d9a7c":"random_tensor.size()","bbdb867d":"resized_tensor = random_tensor.view(9)  \nresized_tensor","f7add627":"#resized_tensor = random_tensor.view(-1, 6)  \n#resized_tensor","fe563e49":"resized_tensor.size()","edd7ea92":"random_tensor[2, 2] = 100.0\nresized_tensor","e63f9ef1":"random_tensor","60980037":"random_tensor.shape","3e4568e7":"tensor_unsqueeze = torch.unsqueeze(random_tensor, 2)\ntensor_unsqueeze","64239609":"tensor_unsqueeze.shape","ec397ba7":"initial_tensor","32389489":"tensor_transpose = torch.transpose(initial_tensor, 0, 1)\ntensor_transpose","c1f19807":"random_tensor","0eb9b0df":"sorted_tensor, sorted_indices = torch.sort(random_tensor)","f5756f4a":"sorted_tensor","3ed32448":"sorted_indices","87c0477e":"tensor_float = torch.FloatTensor([-1.1, -2.2, 3.3])\ntensor_float","b7ef6ef4":"tensor_abs = torch.abs(tensor_float)      \ntensor_abs","60f2e92a":"initial_tensor","6169ed03":"new_tensor = torch.add(initial_tensor, 2)\nnew_tensor","e6310743":"torch.add(initial_tensor, 10, new_tensor)","8a8bee07":"rand1 = torch.abs(torch.randn(2, 3))\nrand2 = torch.abs(torch.randn(2, 3))","fd25abef":"add1 = rand1 + rand2\nadd1","f2f52cbe":"add2 = torch.add(rand1, rand2)\nadd2","8aff3350":"tensor = torch.Tensor([[-1, -2, -3],\n                       [ 1,  2,  3]])","8b5fa884":"tensor_div = torch.div(tensor, tensor + 0.3)\ntensor_div","0df9d115":"tensor_mul = torch.mul(tensor, tensor)\ntensor_mul","29510896":"tensor_clamp = torch.clamp(tensor, min= -0.2, max=2)\ntensor_clamp","446347d1":"t1 = torch.Tensor([1, 2])\nt2 = torch.Tensor([10, 20])","a93ee989":"dot_product = torch.dot(t1, t2) \ndot_product","4e0360e5":"matrix = torch.Tensor([[1, 2, 3],\n                       [4, 5, 6]])\n\nvector = torch.Tensor([0, 1, 2])","deb7d28a":"matrix_vector = torch.mv(matrix, vector)\nmatrix_vector","bea1734b":"another_matrix = torch.Tensor([[10, 30],\n                               [20, 0],\n                               [0 , 50]])","f8c59df0":"matrix_mul = torch.mm(matrix, another_matrix)\nmatrix_mul","9b0968af":"torch.argmax(matrix_mul, dim=1)","9a53ee32":"torch.argmin(matrix_mul, dim=1)","a6c8cc8b":"#End of Code","0a299dbf":"#### Matrix Vector product\nIf mat is a (n\u00d7m) tensor, vec is a 1-D tensor of size m, out will be 1-D of size n.","0aea2aa4":"It's not necessary that all in-place operations have a corresponding function for an out of place operation where a new tensor is created. For example, the tensor object has no fill function without the underscore","79424c8e":"#### A Tensor of type short","cccbd106":"#### The original tensor is unchanged","a6f9f858":"#### A Tensor of type float half (float16)","a75c0f8f":"### Indexing, Slicing, Joining, Mutating Ops","3b4ad70c":"#### The new_tensor was a separate copy and is unaffected","da603116":"#### The default floating point dtype is initially torch.float32\n#### Set the default floating point to torch.float64","74df56fe":"#### A Tensor initialized with a specific array, the torch tensor always creates a copy of the data","8975a22b":"#### Dot product","dc683b66":"# Math Operations\nPytorch supports a number of mathematical operations which can be performed on tensors. We take a look at a few of them here","138592a6":"#### A tensor of size (2,4) like tensor_of_ones containing all zeroes","e7e89dad":"#### A tensor of size (2,4) containing all ones","0f397d06":"#### Create an identity 5X5 tensor","9ec8e77b":"#### The add() method does an out-of-place add operation and returns a new tensor\nThis is assigned to the new_tensor variable","b8b51d93":"#### An un-initialized Tensor of shape 2X2 allocated space in memory","d43e0080":"#### numel() returns the number of elements in a particular tensor no matter what its size and shape. This particular tensor has a total of 6 elements, it's a 2-D tensor","a66f4bb2":"#### A tensor filled with a specific values\n","79b30e04":"#### Returns the indices of the maximum values of a tensor across a dimension.","4e5ab63c":"## Vector Multiplication ","56448c96":"#### Slicing","97a98040":"#### Splits a tensor into a specific number of chunks.\n- tensor (Tensor) \u2013 the tensor to split\n- chunks (int) \u2013 number of chunks to return\n- dim (int) \u2013 dimension along which to split the tensor\n","8e388d1f":"#### Element-wise division\nThe div() and mul() functions can be used to divide and multiply the values in a tensor. Here, we do an element-wise division between two tensors","1811823c":"#### Sorting tensors\nTensors can be sorted along a specified dimension. If no dimension is specified, the last dimension is picked by default","b189208e":"#### default dtype for a tensor can only be a float type\n\nWhen you're working to build neural networks, and on machine learning models you'll typically work with floating points, which is why only floating point types are supported as the default type in PyTorch","1860c492":"The size of the sparse tensor above is (2, 5), but you can see that we've only specified values at index positions for 2 rows and 3 columns here. This is in the indices tensor. \n\nThe remaining two columns in the sparse tensor do not have any values. So we know which index positions have values in the sparse tensor. \n\nWhat are these values? They are given by the values tensor here, which means when you see the number 0 within the indices tensor, that corresponds to the value at position 0 from the values tensor.","86c52280":"#### A tensor of size 2x2 initialized with random values","5c29a37d":"#### Get the current default floating point torch.dtype","263470b7":"#### Splits the tensor into chunks","c44d0246":"## Inplace \/ Out-of-place\nThe first difference is that ALL operations on the tensor that operate in-place on it will have an \"\\_\" postfix. For example, add is the out-of-place version, and add\\_ is the in-place version.","0457b3ee":"#### view() does not create a deep copy - just a view as the name suggests\nModifying the original tensor affects the resized_tensor as they both point to the same space in memory","50b207ed":"#### In-place version of sqrt()","c57b08ff":"#### Transpose\n\n#### Returns a tensor that is a transposed version of input. The given dimensions dim0 and dim1 are swapped.","c4802d24":"#### Creating Tensors\n\nPyTorch supports a total of eight CPU tensor types and eight GPU tensor types. CPU and GPU tensor types are a little different","0981804c":"#### Absolute values","33c63da3":"#### Unsqueeze\nReturns a new tensor with a dimension of size one inserted at the specified position.","fcaa4d61":"#### .fill_ is in-place operation and it doesnt have any out-place equivalent","195ba41b":"#### Create a sparse tensor using coordinates specified by indices and values\n\nPytorch has support for sparse tensors as your data may not be always dense, it would be sparse data.","69d87c13":"#### The add() method does an out-of-place add operation and returns a new tensor\nThis is assigned to the new_tensor variable","e8180af6":"#### Matrix multiplication","7cc647b8":"#### Tensors can be set to have specific data types","fa4ca6ba":"#### Element-wise multiplicaton","00862709":"#### Clamp the value of a Tensor\nThere will be occasions where you would like to set upper and lower limits for the values in a tensor. This is where the clamp function is used. The value of an element is set to:\n* min if if x<sub>i<\/sub> < min\n* x<sub>i<\/sub> if min < x<sub>i<\/sub> < max\n* max if x<sub>i<\/sub> > max","84e7af16":"#### Get the list of indices of non-zero elements in a tensor\n[ i, j ] index for non-zero elements","84721811":"#### Concatenates the  sequence of tensors along the given dimension\n\nAll tensors must either have the same shape (except in the concatenating dimension) or be empty.","7dda723d":"#### The add\\_ method does an in-place add, changing the calling tensor","65bf3736":"#### View"}}