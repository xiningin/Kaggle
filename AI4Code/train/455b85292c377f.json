{"cell_type":{"b7c4ff51":"code","76238047":"code","3d664c15":"code","036554ac":"code","e9648827":"code","374f4a41":"code","687e62fa":"code","68ef84e9":"code","7e37ed51":"code","b393bfef":"code","36e9114c":"code","b8c638ee":"code","65a2204f":"code","290893c3":"code","1847288e":"code","539a6b9d":"code","252379aa":"code","1e57a3ea":"code","dbc920c3":"code","ead05cde":"code","f34b92aa":"code","a02ef381":"code","4c07a4e9":"code","5c390bbf":"code","5d1e0293":"code","f1cb12a5":"code","73144a05":"code","10cc612e":"markdown","7f0f6452":"markdown","9dd5dcbf":"markdown","b914cf14":"markdown","f4c63104":"markdown","e8fe3bcc":"markdown","b1aa8cf5":"markdown","a3478df6":"markdown","064ce6eb":"markdown","fb7f6f0d":"markdown","1399ce15":"markdown","52f63555":"markdown"},"source":{"b7c4ff51":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport tensorflow as tf\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.utils import to_categorical\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import classification_report, confusion_matrix","76238047":"(X_train, y_train), (X_test, y_test) = cifar10.load_data()","3d664c15":"print(f\"X_train shape: {X_train.shape}\")\nprint(f\"y_train shape: {y_train.shape}\")\nprint(f\"X_test shape: {X_test.shape}\")\nprint(f\"y_test shape: {y_test.shape}\")","036554ac":"# Define the labels of the dataset\nlabels = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n          'dog', 'frog', 'horse', 'ship', 'truck']\n\n# Let's view more images in a grid format\n# Define the dimensions of the plot grid \nW_grid = 10\nL_grid = 10\n\n# fig, axes = plt.subplots(L_grid, W_grid)\n# subplot return the figure object and axes object\n# we can use the axes object to plot specific figures at various locations\n\nfig, axes = plt.subplots(L_grid, W_grid, figsize = (17,17))\n\naxes = axes.ravel() # flaten the 15 x 15 matrix into 225 array\n\nn_train = len(X_train) # get the length of the train dataset\n\n# Select a random number from 0 to n_train\nfor i in np.arange(0, W_grid * L_grid): # create evenly spaces variables \n\n    # Select a random number\n    index = np.random.randint(0, n_train)\n    # read and display an image with the selected index    \n    axes[i].imshow(X_train[index,1:])\n    label_index = int(y_train[index])\n    axes[i].set_title(labels[label_index], fontsize = 8)\n    axes[i].axis('off')\n\nplt.subplots_adjust(hspace=0.4)","e9648827":"classes_name = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n\nclasses, counts = np.unique(y_train, return_counts=True)\nplt.barh(classes_name, counts)\nplt.title('Class distribution in training set')","374f4a41":"classes, counts = np.unique(y_test, return_counts=True)\nplt.barh(classes_name, counts)\nplt.title('Class distribution in testing set')","687e62fa":"# Scale the data\nX_train = X_train \/ 255.0\nX_test = X_test \/ 255.0\n\n# Transform target variable into one-hotencoding\ny_cat_train = to_categorical(y_train, 10)\ny_cat_test = to_categorical(y_test, 10)","68ef84e9":"y_cat_train","7e37ed51":"model = Sequential()\n\n# Convolutional Layer\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\n# Pooling layer\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n# Dropout layers\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=128, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=128, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n# model.add(Dropout(0.2))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(10, activation='softmax'))\n\nMETRICS = [\n    'accuracy',\n    tf.keras.metrics.Precision(name='precision'),\n    tf.keras.metrics.Recall(name='recall')\n]\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=METRICS)","b393bfef":"model.summary()","36e9114c":"early_stop = EarlyStopping(monitor='val_loss', patience=2)","b8c638ee":"batch_size = 32\ndata_generator = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\ntrain_generator = data_generator.flow(X_train, y_cat_train, batch_size)\nsteps_per_epoch = X_train.shape[0] \/\/ batch_size","65a2204f":"r = model.fit(train_generator, \n              epochs=50,\n              steps_per_epoch=steps_per_epoch,\n              validation_data=(X_test, y_cat_test), \n#               callbacks=[early_stop],\n#               batch_size=batch_size,\n             )","290893c3":"plt.figure(figsize=(12, 16))\n\nplt.subplot(4, 2, 1)\nplt.plot(r.history['loss'], label='Loss')\nplt.plot(r.history['val_loss'], label='val_Loss')\nplt.title('Loss Function Evolution')\nplt.legend()\n\nplt.subplot(4, 2, 2)\nplt.plot(r.history['accuracy'], label='accuracy')\nplt.plot(r.history['val_accuracy'], label='val_accuracy')\nplt.title('Accuracy Function Evolution')\nplt.legend()\n\nplt.subplot(4, 2, 3)\nplt.plot(r.history['precision'], label='precision')\nplt.plot(r.history['val_precision'], label='val_precision')\nplt.title('Precision Function Evolution')\nplt.legend()\n\nplt.subplot(4, 2, 4)\nplt.plot(r.history['recall'], label='recall')\nplt.plot(r.history['val_recall'], label='val_recall')\nplt.title('Recall Function Evolution')\nplt.legend()","1847288e":"evaluation = model.evaluate(X_test, y_cat_test)\nprint(f'Test Accuracy : {evaluation[1] * 100:.2f}%')","539a6b9d":"y_pred = model.predict(X_test)\ny_pred = np.argmax(y_pred, axis=1)\ncm = confusion_matrix(y_test, y_pred)","252379aa":"disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=labels)\n\n\n# NOTE: Fill all variables here with default values of the plot_confusion_matrix\nfig, ax = plt.subplots(figsize=(10, 10))\ndisp = disp.plot(xticks_rotation='vertical', ax=ax,cmap='summer')\n\nplt.show()","1e57a3ea":"print(classification_report(y_test, y_pred))","dbc920c3":"my_image = X_test[100]\nplt.imshow(my_image)","ead05cde":"# that's a Deer\ny_test[100]","f34b92aa":"# correctly predicted as a Deer\nnp.argmax(model.predict(my_image.reshape(1, 32, 32, 3)))","a02ef381":"# Define the labels of the dataset\nlabels = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n          'dog', 'frog', 'horse', 'ship', 'truck']\n\n# Let's view more images in a grid format\n# Define the dimensions of the plot grid \nW_grid = 5\nL_grid = 5\n\n# fig, axes = plt.subplots(L_grid, W_grid)\n# subplot return the figure object and axes object\n# we can use the axes object to plot specific figures at various locations\n\nfig, axes = plt.subplots(L_grid, W_grid, figsize = (17,17))\n\naxes = axes.ravel() # flaten the 15 x 15 matrix into 225 array\n\nn_test = len(X_test) # get the length of the train dataset\n\n# Select a random number from 0 to n_train\nfor i in np.arange(0, W_grid * L_grid): # create evenly spaces variables \n\n    # Select a random number\n    index = np.random.randint(0, n_test)\n    # read and display an image with the selected index    \n    axes[i].imshow(X_test[index,1:])\n    label_index = int(y_pred[index])\n    axes[i].set_title(labels[label_index], fontsize = 8)\n    axes[i].axis('off')\n\nplt.subplots_adjust(hspace=0.4)","4c07a4e9":"predictions = model.predict(X_test)","5c390bbf":"def plot_image(i, predictions_array, true_label, img):\n    predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n\n    plt.imshow(img, cmap=plt.cm.binary)\n\n    predicted_label = np.argmax(predictions_array)\n    if predicted_label == true_label:\n        color = 'blue'\n    else:\n        color = 'red'\n\n    plt.xlabel(f\"{labels[int(predicted_label)]} {100*np.max(predictions_array):2.0f}% ({labels[int(true_label)]})\", \n               color=color)\n\ndef plot_value_array(i, predictions_array, true_label):\n    predictions_array, true_label = predictions_array, int(true_label[i])\n    plt.grid(False)\n    plt.xticks(range(10))\n    plt.yticks([])\n    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n    plt.ylim([0, 1])\n    predicted_label = np.argmax(predictions_array)\n\n    thisplot[predicted_label].set_color('red')\n    thisplot[true_label].set_color('blue')","5d1e0293":"# Plot the first X test images, their predicted labels, and the true labels.\n# Color correct predictions in blue and incorrect predictions in red.\nnum_rows = 8\nnum_cols = 5\nnum_images = num_rows * num_cols\nplt.figure(figsize=(2 * 2 * num_cols, 2 * num_rows))\nfor i in range(num_images):\n    plt.subplot(num_rows, 2 * num_cols, 2 * i + 1)\n    plot_image(i, predictions[i], y_test, X_test)\n    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n    plot_value_array(i, predictions[i], y_test)\nplt.tight_layout()\nplt.show()","f1cb12a5":"from keras.applications.densenet import DenseNet121\nfrom keras.layers import Dense\nfrom keras.models import Sequential\n\nmodel = Sequential()\nbase_model = DenseNet121(input_shape=(32, 32, 3), include_top=False, weights='imagenet', pooling='avg')\nmodel.add(base_model)\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nr = model.fit(train_generator, \n              epochs=100,\n              steps_per_epoch=steps_per_epoch,\n              validation_data=(X_test, y_cat_test), \n#               callbacks=[early_stop],\n             )","73144a05":"from tensorflow.keras.models import load_model\n\nmodel.save('cnn_20_epochs.h5')","10cc612e":"# \ud83d\udce5 Load the data","7f0f6452":"## Test on one image","9dd5dcbf":"# \ud83d\udd04 Data Preprocessing","b914cf14":"# 7. Save the models","f4c63104":"# \ud83e\udd16 Model Building","e8fe3bcc":"# \ud83d\udcf7 Cifar-10 Image Classifiction\n\nThe `CIFAR-10` dataset consists of `60000` `32x32` color images in `10` classes, with `6000` images per class. There are `50000` training images and `10000` test images.\n\n# \ud83d\udd2c Problem Definition:\n\nGiven an image, can we predict the correct class of this image?\n\nThe images are very small (`32x32`) and by visualizing them you will notice how difficult it is to distinguish them even for a human. \n\nIn this notebook we are going to build a CNN model that can classify images of various objects. We have `10` class of images:\n1. Airplane\n2. Automobile\n3. Bird\n4. Cat\n5. Deer\n6. Dog\n7. Frog\n8. Horse\n9. Ship\n10. Truck\n\n# \ud83c\udfaf Evaluation:\n\nWe have `10` classes, so if we pick a image and we randomly gues it class, we have `1\/10` probability to be true.","b1aa8cf5":"## Data Augmentations","a3478df6":"# \ud83d\udcca Model Evaluation","064ce6eb":"# \ud83d\uddbc Data Visualization","fb7f6f0d":"# 6. DenseNet model for image classification","1399ce15":"## Early Stopping","52f63555":"The class are equally distributed"}}