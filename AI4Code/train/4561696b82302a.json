{"cell_type":{"a5aa3d8e":"code","3870bf72":"code","be1f6f7e":"code","0719450c":"code","64d88510":"code","bbd4818c":"code","35823532":"code","813aa796":"code","7c26050a":"code","aa569081":"code","537cb6cb":"code","9a9b8d51":"code","6aa1cdeb":"code","a798f4b3":"code","ccdc5c5a":"markdown","29989800":"markdown","35ee1d5c":"markdown","4aece296":"markdown","a4429cee":"markdown","95657b3b":"markdown","74221011":"markdown","5fe22f7b":"markdown","286b65c8":"markdown","a5552b8b":"markdown"},"source":{"a5aa3d8e":"from shutil import copyfile\ncopyfile(src = \"..\/input\/modules\/dataset_det.py\", dst = \"..\/working\/dataset_det.py\")\ncopyfile(src = \"..\/input\/vis-module\/vis.py\", dst = \"..\/working\/vis.py\")","3870bf72":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\nfrom collections import OrderedDict\nimport matplotlib.pyplot as plt\n\nimport dataset_det as d_loader\n!pip install ipdb\nimport vis\nimport torch.utils.data as torch_d\nfrom torch.nn import functional as F\n!pip install torchsummary\nfrom torchsummary import summary","be1f6f7e":"BATCHSIZE=50\n\ndataset = d_loader.Balls_CF_Detection (\"..\/input\/balls-images\/train\", 21000)\ntrain_dataset, test_dataset = torch_d.random_split(dataset, [int(21000*0.9), int(21000*0.1)])\n\ndataloaders = {}\ndataloaders['train'] = torch.utils.data.DataLoader(train_dataset,batch_size=BATCHSIZE, shuffle=True)\ndataloaders['val'] = torch.utils.data.DataLoader(test_dataset,batch_size=BATCHSIZE, shuffle=True)\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","0719450c":"COLORS = ['red', 'green', 'blue', 'yellow', 'lime', 'purple', 'orange', 'cyan', 'magenta']\nfirst_batch = next(iter(dataloaders[\"train\"]))\nimages, labels, bb = first_batch\nimages = images.to(device)\n\nfor i in range(5):\n    plt.imshow(np.asarray(vis.show_bboxes(images[i].cpu(), bb[i].cpu(), COLORS)))\n    plt.show()","64d88510":"class myCNN(torch.nn.Module):\n    def __init__(self):\n        super(myCNN, self).__init__()\n        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels = 15, kernel_size=5, groups=1)\n        self.conv2 = torch.nn.Conv2d(15, 25, 5, 1)\n        self.pool = torch.nn.MaxPool2d(2,2)\n        self.fc1 = torch.nn.Linear(25*22*22, 100)\n        self.fc2 = torch.nn.Linear(100, 36)\n        #self.drp = torch.nn.Dropout(0.05)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1,25*22*22)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x","bbd4818c":"def intersect(box_a, box_b):\n    \"\"\" We resize both tensors to [A,B,2] without new malloc:\n    [A,2] -> [A,1,2] -> [A,B,2]\n    [B,2] -> [1,B,2] -> [A,B,2]\n    Then we compute the area of intersect between box_a and box_b.\n    Args:\n      box_a: (tensor) bounding boxes, Shape: [A,4].\n      box_b: (tensor) bounding boxes, Shape: [B,4].\n    Return:\n      (tensor) intersection area, Shape: [A,B].\n    \"\"\"\n    A = box_a.size(0)\n    B = box_b.size(0)\n    max_xy = torch.min(box_a[:, 2:].unsqueeze(1).expand(A, B, 2),\n                       box_b[:, 2:].unsqueeze(0).expand(A, B, 2))\n    min_xy = torch.max(box_a[:, :2].unsqueeze(1).expand(A, B, 2),\n                       box_b[:, :2].unsqueeze(0).expand(A, B, 2))\n    inter = torch.clamp((max_xy - min_xy), min=0)\n    return inter[:, :, 0] * inter[:, :, 1]","35823532":"def IOU(box_a, box_b):\n    \"\"\"Compute the jaccard overlap of two sets of boxes.  The jaccard overlap\n    is simply the intersection over union of two boxes.  Here we operate on\n    ground truth boxes and default boxes.\n    E.g.:\n        A \u2229 B \/ A \u222a B = A \u2229 B \/ (area(A) + area(B) - A \u2229 B)\n    Args:\n        box_a: (tensor) Ground truth bounding boxes, Shape: [num_objects,4]\n        box_b: (tensor) Prior boxes from priorbox layers, Shape: [num_priors,4]\n    Return:\n        jaccard overlap: (tensor) Shape: [box_a.size(0), box_b.size(0)]\n    \"\"\"\n    inter = intersect(box_a, box_b)\n    area_a = ((box_a[:, 2]-box_a[:, 0]) *\n              (box_a[:, 3]-box_a[:, 1])).unsqueeze(1).expand_as(inter)  # [A,B]\n    area_b = ((box_b[:, 2]-box_b[:, 0]) *\n              (box_b[:, 3]-box_b[:, 1])).unsqueeze(0).expand_as(inter)  # [A,B]\n    union = area_a + area_b - inter\n    return inter \/ union  # [A,B]","813aa796":"def calcLoss (model, dataloader, customLoss, mse):\n    correct = 0\n    with torch.no_grad():\n        for data in dataloader:\n            images, labels, bb= data\n            images = images.to(device)\n            bb = bb.to(device)\n            outputs = model(images)\n            correct += (customLoss(outputs, bb) + mse(outputs, bb.view(-1, 36))) * outputs.size(0)\n    return (correct \/ len(dataloader.dataset))","7c26050a":"def iouLoss(outputs, groundtruth_bb):\n    bb = groundtruth_bb.view(-1, 36)\n    iou = 0\n    bb = bb.view(-1, 9, 4)\n    outputs = outputs.view(-1, 9, 4)\n    for i in range(outputs.size(0)):\n        iou += IOU(outputs[i], bb[i])\n    iou = iou \/ outputs.size(0)\n    return (1 - iou.mean())","aa569081":"def train_model(dataloaders, model, criterion, optimizer, scheduler, num_epochs=25):\n    train_accuracies = []\n    valid_accuracies = []\n    \n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_loss = calcLoss(model, dataloaders[\"val\"], customLoss, criterion)\n    print('Initial val loss: {:.4f}'.format(best_loss))\n\n    for epoch in range(1, num_epochs+1):\n        print('Epoch {}\/{}'.format(epoch, num_epochs))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels, bb in dataloaders[phase]:\n                inputs = inputs.to(device)\n                bb = bb.view(-1, 36).to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    \n                    loss = customLoss(outputs, bb) + criterion(outputs, bb)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n            if phase == 'train' and scheduler != None:\n                scheduler.step()\n\n            epoch_loss = running_loss \/ (len(dataloaders[phase].dataset))\n            \n            if phase == 'train':\n                train_accuracies.append(epoch_loss)\n            else:\n                valid_accuracies.append(epoch_loss)\n\n            print('{} Loss: {:.4f} '.format(\n                phase, epoch_loss))\n\n            # deep copy the model\n            if phase == 'val' and epoch_loss < best_loss:\n                best_loss = epoch_loss\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val loss: {:4f}'.format(best_loss))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, train_accuracies, valid_accuracies","537cb6cb":"model = myCNN().to(device)\n\ncriterion = torch.nn.MSELoss()\ncustomLoss = iouLoss\n\noptimizer = optim.Adam(model.parameters(), 0.00001)","9a9b8d51":"EPOCH_NUMBER = 70\n\nmodel, train_accs, val_accs = train_model(dataloaders, model, criterion, optimizer, None,\n                       num_epochs=EPOCH_NUMBER)\n\ntorch.save(model.state_dict(), \".\/model\")","6aa1cdeb":"f = plt.figure(figsize=(10, 8))\nplt.plot(train_accs, label='training loss')\nplt.plot(val_accs, label='validation loss')\nplt.legend()\nplt.show()","a798f4b3":"COLORS = ['red', 'green', 'blue', 'yellow', 'lime', 'purple', 'orange', 'cyan', 'magenta']\nfirst_batch = next(iter(dataloaders[\"val\"]))\nimages, labels, bb = first_batch\nimages = images.to(device)\npreds_bb = model(images).view(-1, 9, 4)\n\nfor i in range(5):\n    plt.imshow(np.asarray(vis.show_bboxes(images[i].cpu(), preds_bb[i].cpu(), COLORS)))\n    plt.show()","ccdc5c5a":"## Define loss and optimizer","29989800":"## Training monitoring plots","35ee1d5c":"## Custom accuracy metrics definition","4aece296":"## Split the dataset and define the dataloaders","a4429cee":"## Train !","95657b3b":"## Training schedule definition","74221011":"## Double check the model performance","5fe22f7b":"## Let's have a glance at the data","286b65c8":"## Model definition","a5552b8b":"# Multi-dimension regression on the three balls' bounding boxes problem"}}