{"cell_type":{"05befdbe":"code","e001ba28":"code","d53ea166":"code","bee33243":"code","aadfcf4c":"code","79cf781e":"code","b27764bd":"code","141d6021":"code","9d4a81a0":"code","cf1e68e0":"code","b6bedba8":"code","5ad69470":"code","b754e1cd":"code","132644c3":"code","647c43c8":"code","6aa465c5":"markdown","68237e8b":"markdown","847cb3e2":"markdown","9e6e7bb7":"markdown","e328b7a0":"markdown","3b33e18b":"markdown","d8212ae3":"markdown","02553a54":"markdown","59d80ac3":"markdown","5117ed60":"markdown","bca2a903":"markdown","97401eb9":"markdown","5e42ad00":"markdown","732abdca":"markdown","dc6707e0":"markdown"},"source":{"05befdbe":"from IPython.display import Image\nImage(filename=\"..\/input\/sign-language-mnist\/amer_sign2.png\")","e001ba28":"import pandas as pd\ntrain_df = pd.read_csv(\"..\/input\/sign-language-mnist\/sign_mnist_train\/sign_mnist_train.csv\")\ntest_df = pd.read_csv(\"..\/input\/sign-language-mnist\/sign_mnist_test\/sign_mnist_test.csv\")\n\ntrain_df.head()","d53ea166":"train_labels = train_df[\"label\"].values\ntest_labels = test_df[\"label\"].values\n\ntrain_pixels = train_df.drop(\"label\", axis=1).values.astype(\"float32\")\ntest_pixels = test_df.drop(\"label\", axis=1).values.astype(\"float32\")","bee33243":"print(\"training images shape\", train_pixels.shape)\nprint(\"training targets shape \",train_labels.shape)\nprint(\"test images shape\", test_pixels.shape)\nprint(\"test targets shape\", test_labels.shape)","aadfcf4c":"train_images = train_pixels.reshape(train_pixels.shape[0], 1, 28, 28)\ntest_images = test_pixels.reshape(test_pixels.shape[0], 1, 28, 28)\n\nprint(\"training images shape\", train_images.shape)\nprint(\"test images shape\", test_images.shape)","79cf781e":"import matplotlib.pyplot as plt\n\ntrain_images = train_images\ntest_images = test_images\n\nimage = train_images[0].squeeze()\nlabel = train_labels[0]\n\nplt.title(f\"label {label}\")\nplt.imshow(image, cmap=\"gray\")\nplt.show()","b27764bd":"import torch\n\ntrain_image_tensor = torch.tensor(train_images) \/ 255.0\ntest_image_tensor  = torch.tensor(test_images) \/ 255.0\ntrain_label_tensor = torch.tensor(train_labels)\ntest_label_tensor  = torch.tensor(test_labels)","141d6021":"from torch.utils.data import TensorDataset\ntrain_set = TensorDataset(train_image_tensor, train_label_tensor)\ntest_set = TensorDataset(test_image_tensor, test_label_tensor)","9d4a81a0":"from torch.utils.data import DataLoader\n\nbatch_size = 16\nnum_workers = 2\n\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\ntest_loader  = DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)","cf1e68e0":"from torchvision.utils import make_grid\nimport numpy as np\n\ndef show(img):\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n    \nimages, labels = next(iter(train_loader))\ngrid = make_grid(images, nrow=4)\nshow(grid)","b6bedba8":"import torch.nn as nn\n\nmodal = nn.Sequential(\n    nn.Conv2d(1, 32, 5),\n    nn.ReLU(),\n    nn.Dropout2d(0.4),\n\n    nn.MaxPool2d(2, 2),\n    nn.BatchNorm2d(32),\n\n    nn.Conv2d(32, 64, 5),\n    nn.ReLU(),\n    nn.Dropout2d(0.4),\n\n    nn.MaxPool2d(2, 2),\n    nn.BatchNorm2d(64),\n\n    nn.Flatten(start_dim=1),\n    \n    nn.Linear(1024, 128),\n    nn.ReLU(),\n    nn.Dropout(0.4),\n    \n    nn.BatchNorm1d(128),\n\n    nn.Linear(128, 26)\n)\n\nmodal","5ad69470":"import torch.optim as optim\n\nlearning_rate = 0.001\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(modal.parameters(), lr = learning_rate)","b754e1cd":"%%time\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodal.to(device)\n\ntotal_train_loss = []\ntotal_val_loss = []\n\nepochs = 10\nprint(f\"training on {device}\")\nfor epoch in range(epochs):\n    train_loss = 0\n    val_loss = 0\n    \n    modal.train()\n    for images, labels in train_loader:\n        images, labels = images.to(device=device), labels.to(device=device)\n        optimizer.zero_grad()\n        preds = modal(images)\n        loss = criterion(preds, labels)\n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item() * train_loader.batch_size\n        \n    modal.eval()\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device=device), labels.to(device=device)\n            preds = modal(images)\n            loss = criterion(preds, labels)\n            \n            val_loss += loss.item() * test_loader.batch_size\n    \n    total_train_loss.append(train_loss \/ len(train_loader))\n    total_val_loss.append(val_loss \/ len(test_loader))\n    \n    print(\n        f\"epoch: {epoch+1}\/{epochs} train_loss: {total_train_loss[-1]} val_loss: {total_val_loss[-1]}\"\n    )","132644c3":"plt.plot(total_train_loss, label=\"train loss\")\nplt.plot(total_val_loss, label=\"val loss\")\nplt.xlabel(\"epoch\")\nplt.ylabel(\"loss\")\nplt.legend()\nplt.show()","647c43c8":"def no_of_correct(preds, targets):\n    return targets.eq(preds.argmax(dim=1)).sum().item()\n\ntotal_correct = 0\nmodal.eval()\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device=device), labels.to(device=device)\n        preds = modal(images)\n        total_correct += no_of_correct(preds, labels)\n\nprint(f\"{total_correct}\/{len(test_set)} correct Accuracy: {(total_correct\/len(test_set))*100:.3f}\")","6aa465c5":"declare loss function and optimizer for modal","68237e8b":"get the required colums(pixels and labels) in numpy ndarray objects","847cb3e2":"preprocess the data and visualise any one of them","9e6e7bb7":"visualise a batch of images","e328b7a0":"create a validation set from training set by keeping aside 20 percent of training data","3b33e18b":"get the dataset which in csv format as pandas dataframe object","d8212ae3":"join the train_images and labels to prepare a training set similary a test set","02553a54":"shape of all the numpy ndarrays","59d80ac3":"get the accuracy on test set","5117ed60":"plot training loss and validation loss","bca2a903":"create a dataloader for training and test data sets","97401eb9":"change the shape in appropriate form (batch, channels, width, height)","5e42ad00":"create a training loop","732abdca":"change the numpy ndarray into pytorch tensor for gradient calculations and gpu computation","dc6707e0":"create a modal to classify the training set"}}