{"cell_type":{"b2f50c4b":"code","79e6688b":"code","5cffff76":"code","1b83cdca":"code","9bf95a79":"code","69907645":"code","910ea1b3":"code","c03d03ee":"code","2fb794b2":"code","42cca983":"code","46d9e8af":"code","cce9b818":"code","b58b8907":"code","e95ba6f0":"code","b94f3662":"code","2d81a94c":"code","29fd935b":"code","1d9e175f":"code","b121cdf2":"markdown","27ae0a16":"markdown","65802d89":"markdown","bf88c761":"markdown","c5170521":"markdown","ca8aa0d7":"markdown","df6c3d57":"markdown","db35e87c":"markdown"},"source":{"b2f50c4b":"!pip install torch-scatter -f https:\/\/pytorch-geometric.com\/whl\/torch-1.7.0+cu102.html --quiet\n!pip install torch-sparse -f https:\/\/pytorch-geometric.com\/whl\/torch-1.7.0+cu102.html --quiet\n!pip install torch-cluster -f https:\/\/pytorch-geometric.com\/whl\/torch-1.7.0+cu102.html --quiet\n!pip install torch-spline-conv -f https:\/\/pytorch-geometric.com\/whl\/torch-1.7.0+cu102.html --quiet\n!pip install torch-geometric==1.6.3 --quiet\n!pip install openTSNE --quiet\n!pip install \"gif[plotly]\" --quiet","79e6688b":"from torch_geometric.data import Data, GraphSAINTRandomWalkSampler, NeighborSampler, GraphSAINTEdgeSampler\nfrom torch_geometric.nn import RGCNConv, Node2Vec, FastRGCNConv\nfrom torch_geometric.utils import contains_isolated_nodes\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score, precision_recall_curve, f1_score, average_precision_score\nimport matplotlib.pyplot as plt\n\nfrom tqdm.notebook import tqdm\n\nimport plotly.graph_objects as go\nimport gif\n\nfrom openTSNE import TSNE","5cffff76":"!mkdir data\n!cp -r \/kaggle\/input\/rgcndatabioproject\/* .\/data\/","1b83cdca":"edge_index = torch.load('data\/edge_index.pt')\nrow, col = edge_index # row: first row, col: second row\nedge_attr = torch.load('data\/edge_attr.pt')\nedge_meta_type = torch.load('data\/edge_meta_type.pt')\nedge_type = torch.load('data\/edge_type.pt')\nx = torch.load('data\/x.pt')\ny = torch.load('data\/y.pt')\nnum_nodes = len(y) # total number of nodes in the graph\n\ntrain_mask = torch.load('data\/train_mask.pt') # training mask of edges, split randomly 80%\nval_mask = torch.load('data\/val_mask.pt') # validation mask of edges, split randomly 10%\ntest_mask = torch.load('data\/test_mask.pt') # test_mask of edges, split randomly 10%\n\nnum_relations = edge_type.unique().size(0) # total number of edge types in the graph\n\ndata = Data(edge_attr=edge_attr, edge_index=edge_index, edge_type=edge_type, edge_meta_type=edge_meta_type, \n            x=x, y=y, train_mask=train_mask, val_mask=val_mask, test_mask=test_mask)","9bf95a79":"len(torch.where(y==1)[0]), len(torch.where(y==0)[0]), len(y)","69907645":"edge_type_mapping = {\n    0: 'target', \n    1: 'enzyme', \n    2: 'carrier', \n    3: 'transporter', \n    4: 'ppi', \n    5: 'target_rev',\n    6: 'enzyme_rev',\n    7: 'carrier_rev',\n    8: 'transporter_rev'\n}","910ea1b3":"data_loader = GraphSAINTRandomWalkSampler(data, batch_size=128, walk_length=16, num_steps=32)","c03d03ee":"class RGCN(torch.nn.Module):\n    def __init__(self, in_dim, h_dim, out_dim, num_rels):\n        super(RGCN, self).__init__()\n        self.num_rels = num_rels\n        self.conv1 = FastRGCNConv(in_dim, h_dim, num_rels)\n        self.conv2 = FastRGCNConv(h_dim, out_dim, num_rels)\n        self.relu = nn.ReLU()\n        self.w_rels = nn.Parameter(torch.Tensor(num_rels, out_dim))\n        nn.init.kaiming_uniform_(self.w_rels, nonlinearity='relu')\n\n    def forward(self, x, edge_index, edge_type):\n        x1 = self.conv1(x, edge_index, edge_type)\n        x1 = self.relu(x1)\n        x2 = self.conv2(x1, edge_index, edge_type)\n        out = F.log_softmax(x2, dim=1)\n\n        return out\n\n\ndef get_metrics(model, embed, edge_index, edge_type, labels):\n    probs = DistMult(embed, edge_index, edge_type, model)\n    loss = F.binary_cross_entropy(probs, labels)\n\n    probs = probs.cpu().detach().numpy()\n    labels = labels.cpu().detach().numpy()\n\n    return loss, probs, labels\n\n\ndef DistMult(embed, edge_index, edge_type, model):\n    s = embed[edge_index[0, :]]\n    o = embed[edge_index[1, :]]\n    r = model.w_rels[edge_type]\n    scores = torch.sum(s * r * o, dim=1)\n\n    return torch.sigmoid(scores)\n\n\ndef get_link_labels(edge_index_pos_len, edge_index_neg_len):\n    link_labels = (torch.zeros(edge_index_pos_len + edge_index_neg_len).float().to(device))\n    link_labels[: int(edge_index_pos_len)] = 1.0\n    return link_labels\n\n\ndef get_embeddings(data):\n    data = data.to(device)\n    x = data.x\n    edge_index_pos = data.edge_index\n    edge_type = torch.squeeze(data.edge_type)\n    embed = model(x, edge_index_pos, edge_type)\n\n    return embed\n\n\ndef negative_sample(edge_index, edge_meta_type):\n    \"\"\"\n    generate negative samples but keep the node type the same\n    \"\"\"\n    edge_index_copy = edge_index.clone()\n\n    # resample ppi, the meta edge type for ppi is 2\n    ppi = edge_index_copy[0, torch.squeeze(edge_meta_type == 2)]\n    new_index = torch.randperm(ppi.shape[0])\n    new_ppi = ppi[new_index]\n    edge_index_copy[0, torch.squeeze(edge_meta_type == 2)] = new_ppi\n\n    # resample dpi, the meta edge type for ppi is 1\n    dpi = edge_index_copy[0, torch.squeeze(edge_meta_type == 1)]\n    new_index = torch.randperm(dpi.shape[0])\n    new_dpi = dpi[new_index]\n    edge_index_copy[0, torch.squeeze(edge_meta_type == 1)] = new_dpi\n\n    # resample dpi_rev, the meta edge type for ppi is 3\n    dpi_rev = edge_index_copy[0, torch.squeeze(edge_meta_type == 3)]\n    new_index = torch.randperm(dpi_rev.shape[0])\n    new_dpi_rev = dpi_rev[new_index]\n    edge_index_copy[0, torch.squeeze(edge_meta_type == 3)] = new_dpi_rev\n\n    return edge_index_copy","2fb794b2":"params = {\n    \"in_dim\": 128,\n    \"h_dim\": 64,\n    \"out_dim\": 64,\n    \"num_rels\": num_relations,\n    \"epochs\": 60,\n}","42cca983":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = RGCN(params['in_dim'], params['h_dim'], params['out_dim'], params['num_rels']).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4)","46d9e8af":"def train(data, embed):\n    data = data.to(device)\n    x = data.x\n    \n    edge_index_train_pos = data.edge_index[:, data.train_mask]\n    edge_type_train = torch.squeeze(data.edge_type[data.train_mask])\n    \n    edge_meta_type = data.edge_meta_type[data.train_mask]\n    edge_index_train_neg = negative_sample(edge_index_train_pos, edge_meta_type)\n\n    edge_index_train_total = torch.cat([edge_index_train_pos, edge_index_train_neg], dim=-1)\n    edge_type_train_total = torch.cat([edge_type_train, edge_type_train[:edge_index_train_neg.size(1)]], dim=-1)\n\n\n    link_labels = get_link_labels(edge_index_train_pos.size(1), edge_index_train_neg.size(1))\n    loss, probs, labels = get_metrics(model, embed, edge_index_train_total, edge_type_train_total, \n                                            link_labels)\n    \n    auroc = roc_auc_score(labels, probs)\n    auprc = average_precision_score(labels, probs)\n    \n    loss_epoch_train.append(loss.item())\n    auroc_epoch_train.append(auroc)\n    \n    loss.backward()\n    optimizer.step()\n\n@torch.no_grad()\ndef validation(data, embed, evaluate_rel=False):\n    data = data.to(device)\n    x = data.x\n    \n    edge_index_val_pos = data.edge_index[:, data.val_mask]\n    edge_type_val = torch.squeeze(data.edge_type[data.val_mask])\n    \n    edge_meta_type = data.edge_meta_type[data.val_mask]\n    edge_index_val_neg = negative_sample(edge_index_val_pos, edge_meta_type)\n    \n    edge_index_val_total = torch.cat([edge_index_val_pos, edge_index_val_neg], dim=-1)\n    edge_type_val_total = torch.cat([edge_type_val, edge_type_val[:edge_index_val_neg.size(1)]], dim=-1)\n    \n    link_labels = get_link_labels(edge_index_val_pos.size(1), edge_index_val_neg.size(1))\n    loss, probs, labels = get_metrics(model, embed, edge_index_val_total, edge_type_val_total, \n                                                                link_labels)\n    auroc = roc_auc_score(labels, probs)\n    auprc = average_precision_score(labels, probs)\n    \n    edge_type_val_total = edge_type_val_total.detach().cpu()\n    \n    loss_epoch_val.append(loss.item())\n    auroc_epoch_val.append(auroc)\n    \n    if not evaluate_rel:\n        return\n    \n    for i in range(num_relations):\n        mask = (edge_type_val_total == i)\n        if mask.sum() == 0:\n            continue\n        probs_per_rel = probs[mask]\n        labels_per_rel = labels[mask]\n        auroc_per_rel = roc_auc_score(labels_per_rel, probs_per_rel)\n        auroc_edge_type[i].append(auroc_per_rel)","cce9b818":"loss_train_total, loss_val_total = [], []\nauroc_train_total, auroc_val_total = [], []\n\nfor epoch in range(0, params[\"epochs\"]):\n    loss_epoch_train, loss_epoch_val = [], []\n    auroc_epoch_train, auroc_epoch_val = [], []\n\n    for batch in data_loader:\n\n        optimizer.zero_grad()\n        model.train()\n        embed = get_embeddings(batch)\n        train(batch, embed)\n        model.eval()\n        validation(batch, embed)\n\n    loss_train_total.append(np.mean(loss_epoch_train))\n    auroc_train_total.append(np.mean(auroc_epoch_train))\n    loss_val_total.append(np.mean(loss_epoch_val))\n    auroc_val_total.append(np.mean(auroc_epoch_val))\n\n    print(\n        \"Epoch: {} | train loss: {} | train auroc: {} |\".format(\n            epoch + 1,\n            \"%.3f\" % np.mean(loss_epoch_train),\n            \"%.3f\" % np.mean(auroc_epoch_train),\n        )\n    )\n    print(\n        \"Epoch: {} | val loss: {} | val auroc: {} |\".format(\n            epoch + 1,\n            \"%.3f\" % np.mean(loss_epoch_val),\n            \"%.3f\" % np.mean(auroc_epoch_val),\n        )\n    )\n\n    print(\"----------------------------------------------------------------------------------------------\")","b58b8907":"auroc_edge_type = {rel:[] for rel in range(num_relations)}\n\nfor batch in data_loader:\n    embed = get_embeddings(batch)\n    validation(batch, embed, evaluate_rel=True)\n\nfor rel, values in auroc_edge_type.items():\n     print('auroc for relation type {}: {}'.format(edge_type_mapping[rel], \"%.3f\" % np.mean(values)))","e95ba6f0":"fig = go.Figure()\nfig.add_trace(\n    go.Scatter(\n        x=list(range(1, params[\"epochs\"] + 1)),\n        y=loss_train_total,\n        mode=\"lines\",\n        name=\"Training Loss\",\n    )\n)\nfig.add_trace(\n    go.Scatter(\n        x=list(range(1, params[\"epochs\"] + 1)),\n        y=loss_val_total,\n        mode=\"lines\",\n        name=\"Validation Loss\",\n    )\n)\nfig.update_layout(\n    autosize=False,\n    width=700,\n    height=500,\n    xaxis=dict(title=\"Epochs\"),\n    yaxis=dict(title=\"Loss\")\n)\nfig.show()","b94f3662":"fig = go.Figure()\nfig.add_trace(\n    go.Scatter(\n        x=list(range(1, params[\"epochs\"] + 1)),\n        y=auroc_train_total,\n        mode=\"lines\",\n        name=\"Training AUROC\",\n    )\n)\nfig.add_trace(\n    go.Scatter(\n        x=list(range(1, params[\"epochs\"] + 1)),\n        y=auroc_val_total,\n        mode=\"lines\",\n        name=\"Validation AUROC\",\n    )\n)\nfig.update_layout(\n    autosize=False,\n    width=700,\n    height=500,\n    xaxis=dict(title=\"Epochs\"),\n    yaxis=dict(title=\"AUROC\")\n)\nfig.show()","2d81a94c":"from plotly.subplots import make_subplots\n\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\nfig.add_trace(\n    go.Scatter(\n        x=list(range(1, params[\"epochs\"] + 1)),\n        y=loss_train_total,\n        mode=\"lines\",\n        name=\"Training Loss\",\n    ),\n    secondary_y=False,\n)\n\nfig.add_trace(\n    go.Scatter(\n        x=list(range(1, params[\"epochs\"] + 1)),\n        y=loss_val_total,\n        mode=\"lines\",\n        name=\"Validation Loss\",\n    ),\n    secondary_y=False,\n)\n\nfig.add_trace(\n    go.Scatter(\n        x=list(range(1, params[\"epochs\"] + 1)),\n        y=auroc_train_total,\n        mode=\"lines\",\n        name=\"Training AUROC\",\n    ),\n    secondary_y=True,\n)\n\nfig.add_trace(\n    go.Scatter(\n        x=list(range(1, params[\"epochs\"] + 1)),\n        y=auroc_val_total,\n        mode=\"lines\",\n        name=\"Validation AUROC\",\n    ),\n    secondary_y=True,\n)\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"<b>Epochs<\/b>\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"<b>Loss<\/b>\", secondary_y=False)\nfig.update_yaxes(title_text=\"<b>AUROC<\/b>\", secondary_y=True)\n\n\nfig.update_layout(\n    title=\"Loss\/AUROC plot\",\n    autosize=False,\n    width=700,\n    height=500,\n)\nfig.show()","29fd935b":"tsne_embeddings = []\ndrug_inds = []\nprotien_inds = []\nfor batch in tqdm(data_loader):\n    embed = get_embeddings(batch)\n    ys = batch.y.cpu().detach().numpy()\n    \n    drug_index = np.where(ys == 0)\n    drug_inds.append(drug_index)\n    \n    protien_index = np.where(ys == 1)\n    protien_inds.append(protien_index)\n    \n    tsne_embedding = TSNE(exaggeration=1, n_jobs=4).fit(embed.cpu().detach().numpy())\n    tsne_embeddings.append(tsne_embedding)","1d9e175f":"@gif.frame\ndef plot(embedding, drug_index, protien_index):\n    fig = go.Figure()\n    fig.add_trace(\n        go.Scatter(\n            x=embedding[drug_index, 0][0],\n            y=embedding[drug_index, 1][0],\n            mode=\"markers\",\n            name=\"drug\",\n        )\n    )\n    fig.add_trace(\n        go.Scatter(\n            x=embedding[protien_index, 0][0],\n            y=embedding[protien_index, 1][0],\n            mode=\"markers\",\n            name=\"protien\",\n        )\n    )\n\n    fig.update_layout(\n        autosize=False,\n        width=700,\n        height=700,\n        xaxis=dict(visible=False),\n        yaxis=dict(visible=False)\n    )\n    return fig\n\nframes = []\nfor tsne_embed, drug_indx, protien_indx in zip(tsne_embeddings, drug_inds, protien_inds):\n    frame = plot(tsne_embed, drug_indx, protien_indx)\n    frames.append(frame)\n\ngif.save(frames, 'output_embeddings_plot.gif', duration=300)","b121cdf2":"### Constructing a GNN Model","27ae0a16":"- `edge_index` stores all the edges in the dataset in the form of a 2-D tensor. Each column represents an edge formed by two nodes and the number of columns indicate the total number of edges in the dataset. For example, the first column in `edge_index` is [0, 9052], which represents an edge between node 0 and node 9052.\n- `edge_attr` contains edge attributes calulated using `1.0 \/ torch_geometric.utils.degree(col, num_nodes)[col]`. This attribute is used for GraphSAINT sampler. Please see [this](https:\/\/github.com\/rusty1s\/pytorch_geometric\/blob\/master\/examples\/graph_saint.py) and [this](https:\/\/pytorch-geometric.readthedocs.io\/en\/latest\/modules\/utils.html) for reference. \n- `edge_meta_type` helps to identify the meta edge type of each edge in `edge_index`. Because drug and protein edges are directional, we use edge meta types here to do negative sampling more easily.  There are 3 meta edges. `1` represents edges between a drug and a protein, where drug is the starting node and protein is the ending node. `2` represents edges between proteins and proteins. `3` represents edges between a protein and a drug where protein is the starting node and drug is the ending node.\n- `edge_type` stores the edge type for each edge in `edge_index`. The meaning of each number is shown in the next cell. See `edge_type_mapping`.\n- `x` stores the input embeddings\/attributes of each node, with dimension of 128. It was learnt separately using [node2vec](https:\/\/arxiv.org\/pdf\/1607.00653.pdf). The main reason to use these embeddings is to decrease the input dimension for each node from 25455 to 128. Naively, one-hot-encoded embeddings are used to represent each node. Alternatively, one can use random Gaussian vectors as input embeddings\/attributes. In applications where side feature information about nodes is available, x can be used to integrate that information into the model.\n- `y` stores the node type, where `0` represents a drug and `1` represents a protein.","65802d89":"We utilize [GraphSAINT Random Walk Sampler](https:\/\/arxiv.org\/pdf\/1907.04931.pdf) as it allows us to sample fully-connected sub-graphs for training.","bf88c761":"Here we have 9 different edge types. The last 4 edge types are the opposites of the first 4 edge types as we want our graph to be un-directional.\ne.g. Drug A **targets** Protein A is equivalent to Protein A is **targeted** by Drug A","c5170521":"### Preparing Data","ca8aa0d7":"Here we construct a 2-layer RGCN with hidden dimension of 64 for both node and edge embeddings. We model it as a binary classification task that tries to minimize the loss between real edge labels and fake edge labels geneated from negative sampling. We use RGCN as the encoder for node embeddings and DistMult as the decoder.","df6c3d57":"# Multi-relational Link Prediction on Knowledge Graphs\n\nIn the biological world, different types of relation could exist between two entities. For example, a drug\/chemical compound can act as a *target, enzyme, carrier* or *transporter* on proteins, forming 4 types of edges. Thus, it would not be ideal to represent these relations using the same edge embeddings. In this demo, we explore [Relational Graph Convolutional Neural Network](https:\/\/arxiv.org\/pdf\/1703.06103.pdf) (RGCN) and apply this achitecture on real world biological dataset, including protein-protein interactions, and drug-protein interactions.","db35e87c":"### Model Training\nNote: the data for training is sampled from GraphSaint, whereas the data for validation is the whole graph. Parameters initialization may affect model convergence."}}