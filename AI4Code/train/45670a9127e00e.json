{"cell_type":{"b6731f55":"code","2edfa151":"code","51313020":"code","d0448cc2":"code","544a818a":"code","19944ef6":"code","d279ce4f":"code","a9360b1f":"code","26de1b55":"code","fdfed565":"code","f1453ea6":"code","261f5fc8":"code","30f41aa2":"code","eff10894":"code","2b026fcf":"code","225bd0ec":"markdown","77b7cd9d":"markdown","56f4d8f0":"markdown","7cacd24d":"markdown","eef995d0":"markdown"},"source":{"b6731f55":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom scipy.stats import beta\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport copy","2edfa151":"# needed for deterministic output\nSEED = 2\nnp.random.seed(SEED)","51313020":"dataset = pd.read_csv(\"..\/input\/santander-customer-transaction-prediction\/train.csv\")\ndataset","d0448cc2":"dataset.info()","544a818a":"dataset.groupby(\"target\")[\"ID_code\"].count() \/ len(dataset)","19944ef6":"# dataset stratified split: train 60% - valid 20% - test 20%\n\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\nsplit = skf.split(dataset, dataset.target)\n_,valid_index = next(split)\n_,test_index = next(split)\n\ntrain_dset = dataset.drop(valid_index).drop(test_index).reset_index(drop=True)\nvalid_dset = dataset.loc[valid_index].reset_index(drop=True)\ntest_dset = dataset.loc[test_index].reset_index(drop=True)","d279ce4f":"display(train_dset.groupby(\"target\")[\"ID_code\"].count() \/ len(train_dset))\ndisplay(valid_dset.groupby(\"target\")[\"ID_code\"].count() \/ len(valid_dset))\ndisplay(test_dset.groupby(\"target\")[\"ID_code\"].count() \/ len(test_dset))","a9360b1f":"input_features = dataset.columns[2:].tolist()\ntarget = \"target\"","26de1b55":"train_dataset = lgb.Dataset(\n    train_dset[input_features].values,\n    train_dset[target].values,\n    free_raw_data=False\n)\n\nvalid_dataset = lgb.Dataset(\n    valid_dset[input_features].values,\n    valid_dset[target].values,\n    free_raw_data=False\n)","fdfed565":"model_params = dict(\n    objective = \"cross_entropy\",\n    learning_rate = 0.05,\n    num_leaves = 32,\n    feature_fraction = 0.8,\n    bagging_fraction = 0.8,\n    seed = 2,\n    deterministic = True,\n    metric = \"auc\"\n)","f1453ea6":"model = lgb.train(\n    model_params, \n    train_dataset, \n    valid_sets=[valid_dataset,],\n    num_boost_round=2000,\n    early_stopping_rounds=50,\n    verbose_eval=50,\n)","261f5fc8":"# AUC on validation dataset\nmodel.best_score[\"valid_0\"][\"auc\"]","30f41aa2":"# AUC on test dataset\npreds = model.predict(test_dset[input_features].values)\nroc_auc_score(test_dset[target].values, preds)","eff10894":"num_boosting_rounds = 2000\nearly_stopping_rounds = 50\nverbose_eval = 50\nalpha = 0.25\n\nX_valid = valid_dset[input_features].values\ny_valid = valid_dset[target].values\n\nbest_metric = 0.\nbest_iteration = 0\nbest_model = None\nno_improvement = 0\n\nmodel_params[\"verbosity\"] = -1\n\nfor iteration in range(num_boosting_rounds):\n    \n    X = train_dset[input_features].values\n    y = train_dset[target].values\n    \n    index = np.arange(len(X))\n    np.random.shuffle(index)\n    X = X[index,:].copy()\n    y = y[index].copy()\n    \n    n = len(X)\/\/2\n    lam = np.random.beta(alpha,alpha,size=n)\n    X_mixed = lam.reshape(-1,1)*X[:n,:] + (1-lam.reshape(-1,1))*X[n:,:]\n    y_mixed = lam*y[:n] + (1-lam)*y[n:]\n    \n    train_dataset = lgb.Dataset(\n        X_mixed, y_mixed,\n        free_raw_data=False\n    )\n    \n    if iteration == 0:\n        model = lgb.train(\n            model_params, \n            train_dataset, \n            num_boost_round=1,\n        )\n    else:\n        model = lgb.train(\n            model_params, \n            train_dataset, \n            num_boost_round=1,\n            init_model=model\n        )\n    \n    y_hat = model.predict(X_valid)\n    metric = roc_auc_score(y_valid, y_hat)\n    \n    if metric > best_metric:\n        best_metric = metric\n        best_iteration = iteration\n        best_model = copy.deepcopy(model)\n        no_improvement = 0\n    else:\n        no_improvement += 1\n    \n    if no_improvement == early_stopping_rounds:\n        print(f\"Eearly stopping. Best score: {best_metric} and reached at: {best_iteration}\")\n        break\n    \n    if iteration%verbose_eval == 0:\n        print(f\"Iteration: {iteration} - AUC: {metric}\")\n        ","2b026fcf":"# AUC on test dataset\npreds = best_model.predict(test_dset[input_features].values)\nroc_auc_score(test_dset[target].values, preds)","225bd0ec":"****","77b7cd9d":"***\n## LightGBM with mixup","56f4d8f0":"***\n## LightGBM without mixup","7cacd24d":"***\n## data preparation","eef995d0":"# Assessment of a plain LightGBM+mixup on SCTP\n"}}