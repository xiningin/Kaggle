{"cell_type":{"4ea6175e":"code","1d4f1435":"code","1edc910e":"code","1355110d":"code","46ab88d1":"code","0d9aac48":"code","f0ef0feb":"code","327dd432":"code","64ad92c6":"code","11ef236c":"code","badfbb8c":"code","7d1a6e6d":"code","bcbc07fd":"code","cacb33d8":"code","22193e34":"code","d582daae":"code","3c64ac07":"code","6c5f1844":"code","e8f19f35":"code","5ea5e3a2":"code","7f3c3be7":"code","3036a75c":"code","7774fc58":"code","06dc87f0":"code","8ca20fb3":"code","af6d7b42":"code","4516ebc6":"code","1da53884":"code","6e3ec312":"code","990b2a8b":"code","97530479":"code","5ec82955":"code","704929d9":"code","f6e5afb6":"code","eaffde93":"code","f17d3932":"code","d4b56c9b":"code","ee1643ed":"code","21209d72":"code","ff6b4b39":"code","aad1bd11":"code","ca1421b5":"code","9280b97f":"code","f8d11882":"markdown","d6066ff7":"markdown","b228eb64":"markdown","23b4d67b":"markdown","0d47cdfa":"markdown","28dce6b9":"markdown","7c99cac3":"markdown","6fab4c40":"markdown","83e9ddd0":"markdown","4684e893":"markdown","1cc67d63":"markdown","48d17f92":"markdown","ce7841eb":"markdown"},"source":{"4ea6175e":"#import required libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing,\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, auc, confusion_matrix, precision_score, recall_score, roc_curve,classification_report\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split,GridSearchCV \nfrom sklearn.preprocessing import StandardScaler\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","1d4f1435":"#importing data\ntrain=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","1edc910e":"train.shape, test.shape","1355110d":"train.head()","46ab88d1":"train.isna().sum() # check for null values","0d9aac48":"train.info()","f0ef0feb":"train.describe() # statistical summary","327dd432":"test.head()","64ad92c6":"test.isna().sum()","11ef236c":"test.info()","badfbb8c":"test.describe()","7d1a6e6d":"plt.figure(figsize=(10,10))\nsns.heatmap(train.corr(),annot=True,cmap='afmhot_r')\nplt.show()","bcbc07fd":"plt.figure(figsize=(5,5))\nsns.countplot(x='Survived',data=train)\nplt.show()","cacb33d8":"plt.figure(figsize=(5,5))\nsns.countplot(x='Survived',hue='Sex',data=train)\nplt.show()","22193e34":"plt.figure(figsize=(5,5))\nsns.countplot(x='Survived',hue='Pclass',data=train)\nplt.show()","d582daae":"plt.figure(figsize=(5,5))\nsns.distplot(train['Age'].dropna(),kde=False,bins=30)\nplt.show()","3c64ac07":"plt.figure(figsize=(10,7))\nsns.boxplot(x='Pclass',y='Age',data=train)\nplt.show()","6c5f1844":"#dropping unwanted columns\ntrain.drop(['PassengerId','Name','Ticket','Cabin'],axis=1,inplace=True)\ntest.drop(['Name','Ticket','Cabin'],axis=1,inplace=True)","e8f19f35":"#adding two columns and putting them into new column\ntrain['Total_mem']=train['SibSp']+train['Parch']\ntest['Total_mem']=test['SibSp']+test['Parch']","5ea5e3a2":"#dropping of those two extra columns\ntrain.drop(['SibSp','Parch'],axis=1,inplace=True)\ntest.drop(['SibSp','Parch'],axis=1,inplace=True)","7f3c3be7":"#filling null values by mode and mean for embarked and age column respectively\ntrain[['Embarked']]=train[['Embarked']].fillna(train.mode()['Embarked'][0])\ntrain[['Age']]=train[['Age']].fillna(train['Age'].mean())","3036a75c":"#filling null values by mode and mean for fare and age respectively\ntest[['Fare']]=test[['Fare']].fillna(test.mode()['Fare'][0])\ntest[['Age']]=test[['Age']].fillna(test['Age'].mean())","7774fc58":"#converting to numeric variables and adding them into train data\nsex=pd.get_dummies(train['Sex'])\nembarked=pd.get_dummies(train['Embarked'])\npclass=pd.get_dummies(train['Pclass'])\ntrain=pd.concat([train,sex,embarked,pclass],axis=1)","06dc87f0":"#converting to numeric variables and adding them into test data\nsex=pd.get_dummies(test['Sex'])\nembarked=pd.get_dummies(test['Embarked'])\npclass=pd.get_dummies(test['Pclass'])\ntest=pd.concat([test,sex,embarked,pclass],axis=1)","8ca20fb3":"#dropping extra columns\ntrain.drop(['Sex','Embarked','Pclass'],axis=1,inplace=True)\ntest.drop(['Sex','Embarked','Pclass'],axis=1,inplace=True)","af6d7b42":"#changing column type\ntrain.columns = train.columns.astype(str)\ntest.columns = test.columns.astype(str)\ntrain.drop(['male','C','1'],axis=1,inplace=True)\ntest.drop(['male','C','1'],axis=1,inplace=True)","4516ebc6":"train.head()","1da53884":"test.head()","6e3ec312":"#splitting the data \nX=np.array(train.drop(['Survived'],axis=1))\ny=np.array(train['Survived'])\nX=StandardScaler().fit_transform(X)\n","990b2a8b":"df=test['PassengerId']\ntest.drop(['PassengerId'],axis=1,inplace=True)\npred=np.array(test)\npred=StandardScaler().fit_transform(pred)","97530479":"model_lr = LogisticRegression()  # create an instance of logistic regression\nmodel_lr.fit(X,y) \nmodel_lr.score(X,y) ","5ec82955":"y_pred_train = model_lr.predict(X)\ny_pred_train[:10]","704929d9":"confusion_matrix(y, y_pred_train)    # create a confusion matrix ","f6e5afb6":"summary =classification_report(y, y_pred_train)\nprint(summary);","eaffde93":"pred_train_prob = model_lr.predict_proba(X)\npred_train_prob[:10]","f17d3932":"fpr,tpr,t = roc_curve(y, pred_train_prob[:,1],pos_label=1)","d4b56c9b":"# plotting the ROC curve \nfrom matplotlib.collections import LineCollection\nimport matplotlib as mpl\nl1 = []\nfor i in range(len(fpr)-1):\n    l1.append([(fpr[i],tpr[i]),(fpr[i+1],tpr[i+1])])\n#print(l1)\n\nlc = LineCollection(l1, cmap='hsv')\nplt.figure(figsize=(10,5))\nfig, ax = plt.subplots()\nline=ax.add_collection(lc)\nlc.set_array(t[1:])\n\nplt.colorbar(line, ticks=np.arange(0,1,0.1))\n\nplt.title(\"ROC Curve\")\nplt.xlabel(\"False Positive Rate (FPR)\")\nplt.ylabel(\"True Positive Rate (TPR)\")","ee1643ed":"# Applying Random forest with hyperparameter tuning \nmodel_rf=RandomForestClassifier()\n\nparam={'n_estimators':[100,200,300], 'max_depth':[1,3,5,7], 'criterion':[\"gini\"], 'max_features': [1,3,5], \"min_samples_split\": [2,3,5] }\n\ntune_model=GridSearchCV(estimator=model_rf, param_grid=param, scoring=\"accuracy\", verbose=1, n_jobs=-1, cv=5)\n\ntune_model.fit(X,y)\nprint(tune_model.best_estimator_)\nprint(tune_model.best_score_)\nprint('Score =',tune_model.score(X,y))","21209d72":"prediction=tune_model.predict(X)   # Making predictions on our train data\nprediction[:20]","ff6b4b39":"confusion_matrix(y, prediction)    # create a confusion matrix ","aad1bd11":"summary =classification_report(y, prediction)\nprint(summary);","ca1421b5":"pred_test = tune_model.predict(pred)\n","9280b97f":"final={'PassengerId':df,\n        'Survived':pred_test}\n\nsubmission=pd.DataFrame(data=final)\nsubmission.to_csv('final_prediction.csv',index=False)","f8d11882":"Precision = 0.77... means TP\/(TP + FP)\n\nRecall    = 0.70...  true positive rate TP\/(TP + FN)\n","d6066ff7":"As accuracy score of Random Forest model gives more accuracy that logistic regression model, So I'll use the same for predictions ","b228eb64":"More number of female passenger survived as compare to male\n\n\n","23b4d67b":"Above heat map shows correlation between each variable in train data. 1 is highest correlation and as it approches towards negative correlation decreases","0d47cdfa":"# **EDA (Exploratory Data Analysis)**","28dce6b9":"Approximate passenger age range","7c99cac3":"# Data Pre-processing ","6fab4c40":"# Logestic regression model","83e9ddd0":"PClass 3 passenger died more than other 2 pclasses","4684e893":"# Random forest model using hyperparameter tuning ","1cc67d63":"According to the ROC curve we will take the default threshold of 0.5 \nBecause by taking 0.5 as threshold , model is able to predict right amount of TPR and FPR ","48d17f92":"count of ceased passenger is more (0 is false-passenger didnt survived, 1 is true- passenger did survived)","ce7841eb":"TN   FP\n\nFN   TP     \n\nIn our problem statement.. \n\nTN = 476... means actually the passenger has died and our model has also predicted it as dead. (Good)  \nFP = 73...  means actually died but predicted survived. (Not good, but the count is less so its ok)\n\nFN = 102... means actually survived but predicted dead. (this is ok, as we are predicted the passenger is dead but in reality has survived).\n\nTP = 240... means actually survived and predicted survived. (Good)"}}