{"cell_type":{"b6bde5db":"code","319d5464":"code","3338befa":"code","1bf5b325":"code","51c94496":"code","85c6177a":"code","8e4b7992":"code","12e2e677":"code","3abed546":"code","b997f275":"code","38da1951":"code","0ac17709":"code","960b064f":"code","d7ff4a26":"code","2927df40":"code","f96d0360":"code","7d248a98":"code","6e8ea817":"code","d3afef78":"code","4b66abcd":"code","d916260d":"code","36ae1de2":"code","53c69896":"code","34aaf9ee":"code","aa3f11a3":"code","9720c4a8":"code","1d62de8c":"code","6352e81c":"code","45603dfd":"code","18d65c81":"code","e9ed3804":"code","be135861":"code","943c2320":"code","3f73a418":"code","8dcdb2dc":"code","6046bac5":"code","5a2e5838":"code","3883d065":"code","3db54283":"code","2c88d7d0":"code","69ba0b84":"code","b14359b1":"code","e657a27e":"code","ae8f3486":"code","4feefcf5":"code","e91cdcd9":"code","31312bfd":"code","f3d8cc00":"code","d1d3431d":"code","6d992af8":"code","1f934d66":"code","f4c37b97":"code","acd3b0ec":"code","cd84e9ed":"code","1ed6903e":"code","5a21e783":"code","e618f668":"code","7255a194":"code","e634165e":"code","4e0ad264":"code","609367f4":"code","eec74d9c":"code","ffe21cd7":"code","75aa282f":"code","f7939e7f":"code","9c0d6d4c":"code","6e1c5ad4":"code","75ade505":"code","242738c2":"code","22ce5b2b":"code","08aa3337":"code","7c190603":"code","a92bb12d":"markdown","6c63b83f":"markdown","26683287":"markdown","9337496c":"markdown","a454c6e2":"markdown","ce40d54c":"markdown","e06a934d":"markdown","8b96aceb":"markdown","1fdf7510":"markdown","5ee21b21":"markdown","8be58a8e":"markdown","3c32f9b2":"markdown","a22b1416":"markdown","f24d9086":"markdown","a3653f27":"markdown","e5daf009":"markdown","249c55cb":"markdown","dcbaa582":"markdown","bfd1ccc3":"markdown","9b5c1e2b":"markdown","8f6047ac":"markdown","585d10de":"markdown","3b7625c8":"markdown","5723f4ce":"markdown","febaba8d":"markdown","0bf541dc":"markdown","3dc3272e":"markdown","f88932dd":"markdown","f43067fb":"markdown","290e0061":"markdown"},"source":{"b6bde5db":"# supress warnings\nimport warnings\nwarnings.filterwarnings('ignore')","319d5464":"# import the required libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport calendar\nimport statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score","3338befa":"# Display all columns\npd.set_option('display.max_columns',200)","1bf5b325":"# Read the csv file using 'read_csv'.\nday= pd.read_csv(\"..\/input\/boombikes-bike-sharing\/day.csv\")","51c94496":"# Check the head of the dataset\nday.head()","85c6177a":"# Check the number of rows and columns in the dataframe\nday.shape","8e4b7992":"# Types of all columns\nday.info(verbose=True)","12e2e677":"# Check the summary for the numeric columns \nday.describe()","3abed546":"# Count the number of null values in each column\nday.isnull().sum()","b997f275":"# Function to convert number to month\ndef month_mapping(month_number):\n    return calendar.month_abbr[month_number]","38da1951":"# Function to convert number to weekday\ndef weekday_mapping(weekday_number):\n    return calendar.day_abbr[weekday_number]","0ac17709":"# Convert numeric values into categorical string values\n\nday['season'] = day['season'].map({1: 'spring', 2: 'summer', 3: 'fall', 4: 'winter'})\nday['weathersit'] = day['weathersit'].map({1: 'Clear', 2: 'Cloudy', 3: 'Light Rain', 4: 'Heavy Rain'})\nday['holiday'] = day['holiday'].map({1: 'Yes', 0: 'No'})\nday['workingday'] = day['workingday'].map({1: 'Yes', 0: 'No'})\nday['yr'] = day['yr'].map({0: '2018', 1:'2019'})\nday['mnth'] = day['mnth'].apply(month_mapping)\nday['weekday'] = day['weekday'].apply(weekday_mapping)\n\n# Drop unnecessary columns\nday.drop(['instant'], axis = 1, inplace = True)\nday.drop(['dteday'], axis = 1, inplace = True)","960b064f":"# Check the head of the dataset\nday.head()","d7ff4a26":"# Types of all columns\nday.info(verbose=True)","2927df40":"# describe gives all numerical cols summary\nday.describe()","f96d0360":"# Show all numerical columns\nday.describe().columns","7d248a98":"day[['temp', 'atemp', 'hum', 'windspeed', 'casual', 'registered', 'cnt']].info()","6e8ea817":"# Let's make a pairplot of all the numeric variables\nsns.pairplot(day)\nplt.show()","d3afef78":"# Correlation between numeric variables\ncor = day[['temp', 'atemp', 'hum', 'windspeed', 'casual', 'registered', 'cnt']].corr()\ncor","4b66abcd":"# Heatmap\nmask = np.array(cor)\nmask[np.tril_indices_from(mask)] = False\nsns.heatmap(cor, mask=mask, vmax=.8, square=True, annot=True);","d916260d":"# distplot for temp, atemp, hum, windspeed, casual, registered, cnt -> Provide insights\nplt.figure(figsize=(20, 12))\nplt.subplot(2,3,1)\nsns.distplot(day['temp'])\nplt.subplot(2,3,2)\nsns.distplot(day['atemp'])\nplt.subplot(2,3,3)\nsns.distplot(day['hum'])\nplt.subplot(2,3,4)\nsns.distplot(day['windspeed'])\nplt.subplot(2,3,5)\nsns.distplot(day['casual'])\nplt.subplot(2,3,6)\nsns.distplot(day['registered'])\nplt.show()","36ae1de2":"sns.distplot(day['cnt'])\nplt.show()","53c69896":"# Types of all columns\nday.info()","34aaf9ee":"# Find all the categorical variables in the dataset\ndf_categorical = day.select_dtypes(exclude=['float64','int64'])\ndf_categorical.columns","aa3f11a3":"# make a boxplot for categorical variables.\nplt.figure(figsize=(20, 20))\nplt.subplot(3,3,1)\nsns.boxplot(x = 'season', y = 'cnt', data = day)\nplt.subplot(3,3,2)\nsns.boxplot(x = 'weathersit', y = 'cnt', data = day)\nplt.subplot(3,3,3)\nsns.boxplot(x = 'mnth', y = 'cnt', data = day)\nplt.subplot(3,3,4)\nsns.boxplot(x = 'workingday', y = 'cnt', data = day)\nplt.subplot(3,3,5)\nsns.boxplot(x = 'holiday', y = 'cnt', data = day)\nplt.subplot(3,3,6)\nsns.boxplot(x = 'weekday', y = 'cnt', data = day)\nplt.subplot(3,3,7)\nsns.boxplot(x = 'yr', y = 'cnt', data = day)\nplt.show()","9720c4a8":"# visualise categorical features parallely\nplt.figure(figsize=(20, 20))\nplt.subplot(3,3,1)\nsns.boxplot(x = 'season', y = 'cnt', hue = 'weathersit', data = day)\nplt.subplot(3,3,2)\nsns.boxplot(x = 'season', y = 'cnt', hue = 'yr', data = day)\nplt.subplot(3,3,3)\nsns.boxplot(x = 'season', y = 'cnt', hue = 'workingday', data = day)\nplt.subplot(3,3,4)\nsns.boxplot(x = 'season', y = 'cnt', hue = 'holiday', data = day)\nplt.subplot(3,3,5)\nsns.boxplot(x = 'weathersit', y = 'cnt', hue = 'yr', data = day)\nplt.subplot(3,3,6)\nsns.boxplot(x = 'weekday', y = 'cnt', hue = 'season', data = day)\nplt.subplot(3,3,7)\nsns.boxplot(x = 'weekday', y = 'cnt', hue = 'weathersit', data = day)\nplt.subplot(3,3,8)\nsns.boxplot(x = 'weekday', y = 'cnt', hue = 'yr', data = day)\nplt.show()","1d62de8c":"# Check the head of the dataset\nday.head()","6352e81c":"# Types of all columns\nday.info(verbose=True)","45603dfd":"# Convert yes\/no into numeric values\nday['holiday'] = day['holiday'].map({'Yes': 1, 'No': 0})\nday['workingday'] = day['workingday'].map({'Yes': 1, 'No': 0})\nday['yr'] = day['yr'].map({'2018': 0, '2019': 1})","18d65c81":"# Function to create dummy variables\ndef dummy_variables(df, feature):\n    \n    # Get the dummy variables for the feature and store it in a new variable - 'dummy', drop the first column from status df using 'drop_first = True'\n    dummy = pd.get_dummies(df[feature], drop_first = True)\n    \n    # Add prefix to column names\n    prefix = feature + '_'\n    dummy = dummy.add_prefix(prefix)\n    \n    # Add the results to the original season dataframe\n    df = pd.concat([df, dummy], axis = 1)\n    \n    # Drop feature as we have created the dummies for it\n    df.drop([feature], axis = 1, inplace = True)\n    \n    return df","e9ed3804":"# Get the dummy variables\nday = dummy_variables(day, 'season')\n\n# Now let's see the head of our dataframe.\nday.head()","be135861":"# Get the dummy variables\nday = dummy_variables(day, 'weathersit')\n\n# Now let's see the head of our dataframe.\nday.head()","943c2320":"# Get the dummy variables\nday = dummy_variables(day, 'weekday')\n\n# Now let's see the head of our dataframe.\nday.head()","3f73a418":"# Get the dummy variables\nday = dummy_variables(day, 'mnth')\n\n# Now let's see the head of our dataframe.\nday.head()","8dcdb2dc":"day.shape","6046bac5":"# Drop casual & registered\nday.drop(['casual'], axis = 1, inplace = True)\nday.drop(['registered'], axis = 1, inplace = True)\n\n# Drop atemp as it is highly multicollinear with temp\nday.drop(['atemp'], axis = 1, inplace = True)","5a2e5838":"# Dividing into X and Y sets for the model building\nX = day.drop('cnt', axis=1)\ny = day.cnt","3883d065":"# Check top values of X\nX.head()","3db54283":"# Check top values of y\ny.head()","2c88d7d0":"# Split Train & Test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)","69ba0b84":"# See all features of X\nnum_feat = list(X_train.describe().columns)\nnum_feat","b14359b1":"X_train.info()","e657a27e":"# scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train[num_feat] = sc.fit_transform(X_train[num_feat])\nX_test[num_feat] = sc.transform(X_test[num_feat])","ae8f3486":"# Check X_train\nX_train.info()","4feefcf5":"# Check top values of X_train\nX_train.head()","e91cdcd9":"# RFE -> Recursive Feature Elimination\nfrom sklearn.svm import LinearSVC\nfrom sklearn.feature_selection import RFE\nlm = LinearRegression()\nlm.fit(X_train, y_train)\nrfe = RFE(lm, 20)\nrfe = rfe.fit(X_train, y_train)","31312bfd":"# See all of the columns & their ranking\nlist(zip(X_train.columns, rfe.support_, rfe.ranking_))","f3d8cc00":"# Columns with high rank\nX_train.columns[rfe.support_]","d1d3431d":"# Get X_train with those columns\nX_train_rfe = X_train[X_train.columns[rfe.support_]]","6d992af8":"# See top values of X_train_rfe\nX_train_rfe.head()","1f934d66":"def build_model(X,y):\n    X = sm.add_constant(X) #Adding the constant\n    lm = sm.OLS(y,X).fit() # fitting the model\n    print(lm.summary()) # model summary\n    return X, lm\n    \ndef checkVIF(X):\n    vif = pd.DataFrame()\n    vif['Features'] = X.columns\n    vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n    vif['VIF'] = round(vif['VIF'], 2)\n    vif = vif.sort_values(by = \"VIF\", ascending = False)\n    return(vif)","f4c37b97":"X_train_new,lm = build_model(X_train_rfe, y_train)","acd3b0ec":"checkVIF(X_train_new)","cd84e9ed":"def feature_reduction(X_train, y_train, variables):\n    \n    # Dropping highly correlated variables and insignificant variables\n    X_train = X_train.drop(variables, 1,)\n    \n    # Build model\n    X_train_lm,lm = build_model(X_train, y_train)\n\n    \n    # Calculate the VIFs again for the new model\n    print(checkVIF(X_train_lm))\n\n    return X_train, lm, X_train_lm","1ed6903e":"# Dropping highly correlated variables and insignificant variables, build model and calculate VIF again\nX_train, lm, X_train_lm = feature_reduction(X_train_rfe, y_train, [\"workingday\",\"weekday_Mon\",\"weekday_Sun\", \"mnth_Sep\"])","5a21e783":"X_train.head()","e618f668":"X_train.columns","7255a194":"regressor = LinearRegression()\nregressor.fit(X_train, y_train)","e634165e":"coeff = pd.DataFrame(regressor.coef_, X_train.columns, columns=['Coefficients'])\ncoeff","4e0ad264":"regressor.intercept_","609367f4":"y_pred = regressor.predict(X_train)","eec74d9c":"df = pd.DataFrame({\n    'Actual':y_train,\n    'Predicted': y_pred\n})\ndf","ffe21cd7":"r2_score(y_train, y_pred)","75aa282f":"y_train_count = lm.predict(X_train_lm)","f7939e7f":"# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((y_train - y_train_count), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \nplt.xlabel('Errors', fontsize = 18)                         # X-label","9c0d6d4c":"num_vars = X_train.columns\nX_train[num_vars] = sc.fit_transform(X_train[num_vars])\nX_test[num_vars] = sc.transform(X_test[num_vars])","6e1c5ad4":"X_test = X_test[num_vars]","75ade505":"X_test.head()","242738c2":"# Adding constant variable to test dataframe\nX_test_m = sm.add_constant(X_test)","22ce5b2b":"# Making predictions using the model\ny_pred_m = lm.predict(X_test_m)","08aa3337":"# Plotting y_test and y_pred to understand the spread\n\nfig = plt.figure()\nplt.scatter(y_test, y_pred_m)\nfig.suptitle('y_test vs y_pred', fontsize = 20)              # Plot heading \nplt.xlabel('y_test', fontsize = 18)                          # X-label\nplt.ylabel('y_pred', fontsize = 16)      ","7c190603":"from sklearn.metrics import r2_score\nr2_score(y_test, y_pred_m)","a92bb12d":"## Reading and Understanding the Data","6c63b83f":"## Building a linear model\n\n<!-- Fit a regression line through the training data using `statsmodels`. Remember that in `statsmodels`, you need to explicitly fit a constant using `sm.add_constant(X)` because if we don't perform this step, `statsmodels` fits a regression line passing through the origin, by default. -->","26683287":"## Model Evaluation\n\nLet's now plot the graph for actual versus predicted values.","9337496c":"Insights:\n- Fall and clear weather had more rental bikes\n- 2019 had more rental bikes than 2018\n- The number of rental bikes looked similar on working days and non-working days","a454c6e2":"## Residual Analysis of the train data\n\nSo, now to check if the error terms are also normally distributed (which is infact, one of the major assumptions of linear regression), let us plot the histogram of the error terms and see what it looks like.","ce40d54c":"Inspect the various aspects of the dataframe","e06a934d":"### Weather","8b96aceb":"## RFE","1fdf7510":"Insights:\n- atemp and temp have multicollinear relationship\n- registered and count have multicollinear relationship","5ee21b21":"### Visualising Numeric Variables","8be58a8e":"### Applying the scaling on the test sets","3c32f9b2":"Insights:\n- Most of the days had temperature between 10 and 30 Celsius degree, feeling temperature between 10 and 35 Celsius degree. Very few days had temperature and feeling temperature less than 2 degree Celsius and more than 40 degree Celsius.\n- Most of the days had humidity between 50 and 80 Celsius degree. Very few days had humidity less than 20 and greater than 100.\n- Most of the days had winspeed between 8 and 17. Very few days had windspeed greater than 30.\n- Most of the days had the number of rental bikes by casual customers around 1,000 or less. Very few days had more than 3,000 rental bikes by casual customers.\n- Most of the rental bikes were from registered users. Most of the days had the number of rental bikes by this type of customers around 2,000 to 5,000.\n- When taking into accounts both registered and casual customers, most of the days had around 2,000 to 7,000 rental bikes.","a22b1416":"### Dividing into X and Y sets for the model building","f24d9086":"## Visualising the Data","a3653f27":"## Dummy Variables","e5daf009":"# Bike Sharing","249c55cb":"## Splitting the Data into Training and Testing Sets","dcbaa582":"### Visualising Categorical Variables","bfd1ccc3":"### Train Test Split","9b5c1e2b":"## Making Predictions Using the Final Model\n\nNow that we have fitted the model and checked the normality of error terms, it's time to go ahead and make predictions using the final, i.e. fourth model.","8f6047ac":"### Weekday","585d10de":"### Make prediction","3b7625c8":"### Build model with features selected from FRE","5723f4ce":"-> No null columns","febaba8d":"## Data Preparation","0bf541dc":"### Season","3dc3272e":"### Rescaling the Features ","f88932dd":"<h1>Table of Contents<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Reading-and-Understanding-the-Data\" data-toc-modified-id=\"Reading-and-Understanding-the-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;<\/span>Reading and Understanding the Data<\/a><\/span><\/li><li><span><a href=\"#Data-Preparation\" data-toc-modified-id=\"Data-Preparation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;<\/span>Data Preparation<\/a><\/span><\/li><li><span><a href=\"#Visualising-the-Data\" data-toc-modified-id=\"Visualising-the-Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;<\/span>Visualising the Data<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Visualising-Numeric-Variables\" data-toc-modified-id=\"Visualising-Numeric-Variables-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;<\/span>Visualising Numeric Variables<\/a><\/span><\/li><li><span><a href=\"#Visualising-Categorical-Variables\" data-toc-modified-id=\"Visualising-Categorical-Variables-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;<\/span>Visualising Categorical Variables<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Dummy-Variables\" data-toc-modified-id=\"Dummy-Variables-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;<\/span>Dummy Variables<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Season\" data-toc-modified-id=\"Season-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;<\/span>Season<\/a><\/span><\/li><li><span><a href=\"#Weather\" data-toc-modified-id=\"Weather-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;<\/span>Weather<\/a><\/span><\/li><li><span><a href=\"#Weekday\" data-toc-modified-id=\"Weekday-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;<\/span>Weekday<\/a><\/span><\/li><li><span><a href=\"#Month\" data-toc-modified-id=\"Month-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;<\/span>Month<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Splitting-the-Data-into-Training-and-Testing-Sets\" data-toc-modified-id=\"Splitting-the-Data-into-Training-and-Testing-Sets-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;<\/span>Splitting the Data into Training and Testing Sets<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Dividing-into-X-and-Y-sets-for-the-model-building\" data-toc-modified-id=\"Dividing-into-X-and-Y-sets-for-the-model-building-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;<\/span>Dividing into X and Y sets for the model building<\/a><\/span><\/li><li><span><a href=\"#Train-Test-Split\" data-toc-modified-id=\"Train-Test-Split-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;<\/span>Train Test Split<\/a><\/span><\/li><li><span><a href=\"#Rescaling-the-Features\" data-toc-modified-id=\"Rescaling-the-Features-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;<\/span>Rescaling the Features<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#RFE\" data-toc-modified-id=\"RFE-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;<\/span>RFE<\/a><\/span><\/li><li><span><a href=\"#Building-a-linear-model\" data-toc-modified-id=\"Building-a-linear-model-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;<\/span>Building a linear model<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Build-model-with-features-selected-from-FRE\" data-toc-modified-id=\"Build-model-with-features-selected-from-FRE-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;<\/span>Build model with features selected from FRE<\/a><\/span><\/li><li><span><a href=\"#Dropping-the-variable-and-Updating-the-model\" data-toc-modified-id=\"Dropping-the-variable-and-Updating-the-model-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;<\/span>Dropping the variable and Updating the model<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Residual-Analysis-of-the-train-data\" data-toc-modified-id=\"Residual-Analysis-of-the-train-data-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;<\/span>Residual Analysis of the train data<\/a><\/span><\/li><li><span><a href=\"#Making-Predictions-Using-the-Final-Model\" data-toc-modified-id=\"Making-Predictions-Using-the-Final-Model-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;<\/span>Making Predictions Using the Final Model<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Applying-the-scaling-on-the-test-sets\" data-toc-modified-id=\"Applying-the-scaling-on-the-test-sets-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;<\/span>Applying the scaling on the test sets<\/a><\/span><\/li><li><span><a href=\"#Make-prediction\" data-toc-modified-id=\"Make-prediction-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;<\/span>Make prediction<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Model-Evaluation\" data-toc-modified-id=\"Model-Evaluation-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;<\/span>Model Evaluation<\/a><\/span><\/li><\/ul><\/div>","f43067fb":"### Dropping the variable and Updating the model","290e0061":"### Month"}}