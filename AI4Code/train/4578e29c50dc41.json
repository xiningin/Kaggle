{"cell_type":{"668257cd":"code","1627516d":"code","ad1aa1ea":"code","931a13b7":"code","6247b98d":"code","9ab19cd1":"code","40f8ac7e":"code","3fa66ac2":"code","41c39805":"code","cd8ff792":"code","6ae3f269":"code","67a99545":"code","164ca3e0":"code","706f75af":"code","8069ec09":"code","af0b8a70":"code","bff2ed23":"code","acd31b80":"code","f79c4a5c":"code","e3c6ab68":"code","7b45dfbb":"code","6178ffcd":"code","55decc88":"code","9597a94c":"code","a8a292b0":"code","e670f8ad":"code","f5f6efa7":"code","21b0a35c":"code","56838468":"code","a6ad39b1":"code","fea7dd37":"code","8c72dadb":"code","3a6485ba":"code","f662915e":"code","7ddf5bcb":"code","e7f25c00":"code","447d1de2":"code","0a153dbb":"code","60efd6d7":"code","38e03264":"code","2ef0be11":"code","d496259f":"code","b073dd12":"code","6dfce150":"code","55118678":"code","5cfe03f9":"code","1a542805":"code","770ee48f":"code","1878ffba":"code","efe2a48a":"code","a9480398":"code","d97a7056":"code","07610f20":"code","38744866":"code","62888d5e":"code","e8970c03":"code","571dc4fb":"code","5b333d85":"code","46c4c994":"code","7f3f34c5":"code","c486f150":"code","37db0b0a":"code","154303ce":"code","cc304a70":"code","6ee0cfb4":"code","4baadc52":"code","1fb55476":"code","ef567569":"code","5e80ad13":"code","ce9e2629":"code","258b3292":"code","40af5f04":"code","d24cdbcd":"code","b3042116":"code","51850f48":"code","47d54745":"code","193ca05b":"code","e884e34b":"code","20638801":"code","7a5b0483":"code","1a38ef81":"code","bf93d6d8":"code","59c793d5":"code","51d7a2e9":"code","08e5262b":"code","9b8c4281":"code","c812bd36":"code","ac5245af":"code","a26dd59e":"code","cb56b533":"code","451cb1bd":"markdown","8217d07a":"markdown","5f7b650d":"markdown","17b08625":"markdown","32940e3e":"markdown","f0fa97e5":"markdown","0958fec3":"markdown","82187248":"markdown","fab8897c":"markdown","d3d43975":"markdown","2496a28f":"markdown","bf7c66ad":"markdown","336f39f4":"markdown","c72efa5e":"markdown","fbaf2fb0":"markdown","aa2ca2e8":"markdown","c8f6f93a":"markdown","450fe9da":"markdown","650aa6aa":"markdown","49873f44":"markdown","d1c6b766":"markdown","7eb87f06":"markdown","ecd1dba1":"markdown","ab750fda":"markdown","b01b8218":"markdown","463d86e2":"markdown","21460bdf":"markdown","48772a6c":"markdown","4a691904":"markdown","9903c955":"markdown","85cb3744":"markdown"},"source":{"668257cd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1627516d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as py\nimport plotly.express as go","ad1aa1ea":"train = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/test.csv')","931a13b7":"train.head()","6247b98d":"train.info()","9ab19cd1":"is_na = pd.DataFrame(train.isna().sum(),columns=['Number'])\nis_na['Percent'] = is_na['Number']\/100000\nis_na = is_na.sort_values('Percent',ascending=False)\nis_na","40f8ac7e":"print(\"The number of unique values in the column Cabin are:\", train['Cabin'].nunique())","3fa66ac2":"train['Cabin']","41c39805":"train['Cabin_alpha'] = train['Cabin'].str.replace('[^a-zA-Z]', '')\ntest['Cabin_alpha'] = test['Cabin'].str.replace('[^a-zA-Z]', '')","cd8ff792":"train['Cabin_alpha'].value_counts()","6ae3f269":"train['Cabin_alpha'].isna().sum()","67a99545":"train['Cabin_alpha'].fillna('NA',inplace=True)\ntest['Cabin_alpha'].fillna('NA',inplace=True)","164ca3e0":"train.groupby('Cabin_alpha')['Pclass'].value_counts()","706f75af":"train.groupby('Cabin_alpha')['Survived'].mean().sort_values()","8069ec09":"go.bar(train.groupby('Cabin_alpha')['Survived'].mean().sort_values())","af0b8a70":"print(\"The number of unique values in the column Ticket are:\", train['Ticket'].nunique())","bff2ed23":"train['Ticket_alpha'] = train['Ticket'].str.replace('[^a-zA-Z]', '')\ntest['Ticket_alpha'] = test['Ticket'].str.replace('[^a-zA-Z]', '')","acd31b80":"train['Ticket_num'] = train['Ticket'].str.replace('[^0-9]', '')\ntest['Ticket_num'] = test['Ticket'].str.replace('[^0-9]', '')","f79c4a5c":"train['Ticket_alpha'].fillna('NA',inplace=True)\ntrain['Ticket_alpha'].replace({'':'NA'},inplace=True)\ntest['Ticket_alpha'].fillna('NA',inplace=True)\ntest['Ticket_alpha'].replace({'':'NA'},inplace=True)","e3c6ab68":"train['Ticket_num'].fillna('0',inplace=True)\ntrain['Ticket_num'].replace({'':'0'},inplace=True)\ntest['Ticket_num'].fillna('0',inplace=True)\ntest['Ticket_num'].replace({'':'0'},inplace=True)","7b45dfbb":"train.head()","6178ffcd":"train['Ticket_num'] = train['Ticket_num'].astype(int)\ntest['Ticket_num'] = test['Ticket_num'].astype(int)","55decc88":"train[['Ticket_alpha','Ticket_num']].dtypes","9597a94c":"train.drop(columns=['Cabin','Ticket'],inplace=True)\ntest.drop(columns=['Cabin','Ticket'],inplace=True)","a8a292b0":"x = pd.DataFrame(train.groupby('Pclass')['Cabin_alpha'].value_counts())\nx.columns = ['Counts']\nx = x.reset_index()","e670f8ad":"x['Percentage']=train.groupby('Pclass')['Cabin_alpha'].value_counts().groupby(level=0).apply(lambda \n        x:100 * x\/float(x.sum())).values","f5f6efa7":"go.bar(x,x='Pclass',y='Percentage',color='Cabin_alpha')","21b0a35c":"fig = go.bar(train['Pclass'].value_counts())\nfig.update_layout(title='Number of passengers in each Class',xaxis_title='Pclass',yaxis_title='Number of passengers')\nfig.show()","56838468":"y = pd.DataFrame(train.groupby('Pclass')['Sex'].value_counts())\ny.columns = ['Counts']\ny = y.reset_index()\ny['Percentage']=train.groupby('Pclass')['Sex'].value_counts().groupby(level=0).apply(lambda \n        x:100 * x\/float(x.sum())).values\ny['Pclass'] = y['Pclass'].astype('category')","a6ad39b1":"go.bar(y,x='Pclass',y='Percentage',color='Sex')","fea7dd37":"z = pd.DataFrame(train.groupby(['Pclass','Sex'])['Survived'].mean()).reset_index()","8c72dadb":"go.bar(z,x='Pclass',y='Survived',color='Sex',barmode='group')","3a6485ba":"sns.boxplot(x=train['Survived'],y=train['Age'])","f662915e":"age = train[['Age','Survived','Sex']].dropna()\nbins = [0,15, 50, 200]\nlabels = ['Child', 'Adult', 'Old']\nage['age_band'] = pd.cut(age.Age, bins, labels = labels,include_lowest = True)\ngo.bar(age.groupby(['age_band'])['Survived'].mean())\n","7ddf5bcb":"for i in ['Embarked','Sex','Pclass']:\n    print('Value counts for column',i,'are:')\n    print(train[i].value_counts())\n    print('-'*50)","e7f25c00":"train['Name'].head(10)","447d1de2":"train.drop(columns = 'Name',inplace=True)","0a153dbb":"train.head()","60efd6d7":"is_na = pd.DataFrame(train.isna().sum(),columns=['Number'])\nis_na['Percent'] = is_na['Number']\/100000\nis_na = is_na.sort_values('Percent',ascending=False)\nis_na","38e03264":"train['Age'].hist()","2ef0be11":"print('Age mean;',train['Age'].mean())\nprint('Age median:',train['Age'].median())\nprint('Age skew:',train['Age'].skew())","d496259f":"print(train.groupby('Survived')['Age'].mean())\nprint('-'*50)\nprint(train.groupby('Survived')['Age'].median())","b073dd12":"print(train.groupby('Pclass')['Age'].mean())\nprint('-'*50)\nprint(train.groupby('Pclass')['Age'].median())","6dfce150":"for df in [train,test]:\n    for i in [1,2,3]:\n        a = df[df['Age'].isna()][['Pclass','Age']]\n        ind = list(a[a['Pclass']==i].index)\n        df.loc[ind,'Age'] = df[df['Pclass']==i]['Age'].mean()","55118678":"train['Age'].skew()","5cfe03f9":"for df in [train,test]:\n    df['Embarked'].fillna(df['Embarked'].mode()[0],inplace=True)","1a542805":"train['Fare'].hist()\nprint('Mean:',train['Fare'].mean())\nprint('Median:',train['Fare'].median())","770ee48f":"train.groupby('Pclass')['Fare'].mean()","1878ffba":"train.groupby('Pclass')['Fare'].median()","efe2a48a":"for df in [train,test]:\n    for i in [1,2,3]:\n        a = df[df['Fare'].isna()][['Pclass','Fare']]\n        ind = list(a[a['Pclass']==i].index)\n        df.loc[ind,'Fare'] = df[df['Pclass']==i]['Fare'].median()","a9480398":"is_na = pd.DataFrame(train.isna().sum(),columns=['Number'])\nis_na['Percent'] = is_na['Number']\/100000\nis_na = is_na.sort_values('Percent',ascending=False)\nis_na","d97a7056":"train.head()","07610f20":"train.head()","38744866":"train.groupby('Cabin_alpha')['Fare'].describe()","62888d5e":"sns.heatmap(train.corr(),annot=True,cmap='crest')","e8970c03":"train['Family_members'] = train['SibSp'] + train['Parch']\ntest['Family_members'] = test['SibSp'] + test['Parch']","571dc4fb":"train['Alone'] = 0\ntest['Alone'] = 0\ntrain.loc[train['Family_members']==0,'Alone'] = 1\ntest.loc[test['Family_members']==0,'Alone'] = 1\n    ","5b333d85":"sns.heatmap(train.corr(),annot=True,cmap='crest')","46c4c994":"train.columns","7f3f34c5":"fig = go.bar(train.drop(columns=['PassengerId']).corr().loc['Survived','Pclass':'Alone'])\nfig.update_layout(title='Correlation of features with Surival',xaxis_title='Features',yaxis_title='Correlation value')\nfig.show()","c486f150":"train.skew()","37db0b0a":"train['Fare'] = np.log(train['Fare'])\ntest['Fare'] = np.log(test['Fare'])","154303ce":"train['Fare'].skew()","cc304a70":"print(set(train.columns) - set(test.columns))\nprint(set(test.columns) - set(train.columns))","6ee0cfb4":"test.drop(columns='Name',inplace=True)","4baadc52":"train.groupby('Cabin_alpha')['Fare'].describe().T","1fb55476":"from sklearn.preprocessing import LabelEncoder\nlb = LabelEncoder()","ef567569":"train[train.dtypes[train.dtypes == object].index].nunique()","5e80ad13":"for i in ['Cabin_alpha','Ticket_alpha']:\n    train[i] = lb.fit_transform(train[i])\n    test[i] = lb.transform(test[i])","ce9e2629":"train.head()","258b3292":"train = pd.get_dummies(train)\ntest = pd.get_dummies(test)","40af5f04":"train.drop(columns=['Sex_male'],inplace=True)\ntest.drop(columns=['Sex_male'],inplace=True)","d24cdbcd":"import statsmodels.api as sm","b3042116":"def forward_selection(data, target, significance_level=0.05):\n    initial_features = data.columns.tolist()\n    best_features = []\n    while (len(initial_features)>0):\n        remaining_features = list(set(initial_features)-set(best_features))\n        new_pval = pd.Series(index=remaining_features)\n        for new_column in remaining_features:\n            model = sm.OLS(target, sm.add_constant(data[best_features+[new_column]])).fit()\n            new_pval[new_column] = model.pvalues[new_column]\n        min_p_value = new_pval.min()\n        if(min_p_value<significance_level):\n            best_features.append(new_pval.idxmin())\n        else:\n            break\n    return best_features","51850f48":"features = forward_selection(train.drop(columns=['PassengerId','Survived']),train['Survived']) ","47d54745":"features","193ca05b":"train.head()","e884e34b":"id_col = test['PassengerId']","20638801":"for df in [train,test]:\n    df.drop(columns='PassengerId',inplace=True)","7a5b0483":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score","1a38ef81":"from sklearn.linear_model import LogisticRegression","bf93d6d8":"lr = LogisticRegression(max_iter=1000)","59c793d5":"rfc = RandomForestClassifier(max_depth=10, min_samples_leaf=10, min_samples_split=100)","51d7a2e9":"X = train.drop(columns='Survived')\ny = train['Survived']","08e5262b":"X.head()","9b8c4281":" lr.fit(X.drop(columns=['Ticket_alpha','Ticket_num','Family_members']),y)","c812bd36":"cv_means = cross_val_score(lr,X.drop(columns=['Ticket_alpha','Ticket_num','Family_members']),y)","ac5245af":"np.mean(cv_means)","a26dd59e":"submission = pd.DataFrame({'PassengerID':id_col,'Survived':lr.predict(test.drop(columns=['Ticket_alpha','Ticket_num','Family_members']))})\nsubmission = submission.set_index('PassengerID')","cb56b533":"submission.to_csv('submission.csv')","451cb1bd":"# Feature Engineering","8217d07a":"* This piece of code tells us that in the train df, Survived is a column that isn't there in the test df.\n* Similarly, test df has the Name column which is not in the train df","5f7b650d":"Except this time there are a 100k rows that have been generated. Hopefully this means that people can't cheat their way into getting an accuracy of 1 on the test set.\n\nRight off the bat we can see that Age, Ticket, Fare, Cabin, and Embarked have missing values. Seems like this dataset follows the patterns of the original pretty closely. ","17b08625":"The Fare column is highly skewed to the right","32940e3e":"* In all the classes, it is very clear that a significant amount of women survived, as opposed to men. On average, over 70% of the females survived, whereas only 20% of the males survived.\n* Class also plays an important role as more men from Class 1 survive as opposed to Classes 2 and 3.","f0fa97e5":"The NA class dominates the 2nd and 3rd Passenger Class. This could mean that people in those classes did not get a Cabin and there's no available record for them.","0958fec3":"# Data exploration","82187248":"The columns with the highest missing values is Cabin (67.86% data points missing). In the original dataset this was a good column for analysis because there were only a 1000 data points, we will see later on if it's the same here.","fab8897c":"From the correlation table above:- \n* Survived has a negative relationship with Pclass, which we saw earlier in the bar plots\n* Survived has a positive relationship with Fare, which also makes sense since people in higher classes pay more\n* Sibling\/Parent columns by themselves have very little correlation with survival so maybe this can be looked into further","d3d43975":"The above code finds the indices all the rows which have a class of 1\/2\/3 and have missing values and inputs the averages of the dataset into them.","2496a28f":"I will impute the missing values the same way I did with age. With the median of the classes","bf7c66ad":"Seems like the updated Cabin column would be a good feature since the different cabin values seem to have variable survival rates.","336f39f4":"There isn't too much disparity within the counts of the classes, which is good because there will not be an imbalance in the data.","c72efa5e":"Since we are inputting the means, the skew remains about the same","fbaf2fb0":"The categorical columns have a good number of values for each unique item, which will be good when a model is being made","aa2ca2e8":"This scored 0.79 on the leaderboards, which is good for a simple model!","c8f6f93a":"The continous feature age does not differ too much in the plot above. The median age of people who surived is higher, which indicates that older people probably had a higher survival rate.\n\nTo try to dive into this further, I will create age bands with 3 labels: Child, Adult, and Old. Children will be within the age of 0-15, Adults will be from 15-50, and Old will be any age above that.","450fe9da":"Classes 1 and 2 have the same male-female ratio but Class 3 has significantly more males.","650aa6aa":"There are only 2 continous columns, Age and Fare. Fare is highly skewed while Age is quite already. Thus, I will take the log of the Fare column to make it more symmetrical. ","49873f44":"Oh look it's the Titanic Dataset!","d1c6b766":"Filling Embarked column with the mode, which is port S","7eb87f06":"# EDA","ecd1dba1":"The original Titanic dataset had titles (Mr,Mrs,Officer etc) attached with the names. Since this dataset doesn't, there isn't any insight to be gained other than gender, so this column is useless.","ab750fda":"The ticket column is similar to the Cabin column, it has letters followed by numbers, or just numbers. Let's try to break this down.","b01b8218":"It seems like the Cabin column has an alphabet followed by numbers. While the numbers seem useless, the alphabet could be important. We could try isolating them and seeing what we find.","463d86e2":"# Loading the Dataset","21460bdf":"Now our Ticket and Cabin columns are sorted. We can drop the original columns.","48772a6c":"Problem sort of solved!","4a691904":"Children and Old people have a higher chance of survival as compared to adults, which makes sense.","9903c955":"# Missing Values","85cb3744":"While I feel like this would be an interesting way to approach this problem, it doesn't make sense because we cannot fill in the test values based on survival. So I will look at other methods."}}