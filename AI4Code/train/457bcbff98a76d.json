{"cell_type":{"61b53274":"code","14c093a9":"code","61bcba4f":"code","9d4aa3d1":"code","4c8ed275":"code","f66e7624":"code","0742493c":"code","db0031e9":"code","ff591b7d":"code","eaef291d":"code","1308f8fe":"code","dd8e5696":"code","22981aef":"code","bfb546fe":"code","3491be5e":"code","f979fa22":"code","ffbc995b":"code","37bc47f5":"code","7c6a94e5":"code","4559f4a0":"markdown","beb64125":"markdown","caeaf52f":"markdown","134d103e":"markdown","ae7a2d34":"markdown","d03adf61":"markdown","ac43c31f":"markdown","ca71e3e6":"markdown","514bce5a":"markdown","939b6606":"markdown"},"source":{"61b53274":"import numpy as np\nimport pandas as pd\n# pd.plotting.register_matplotlib_converters()\n# import matplotlib.pyplot as plt\n# %matplotlib inline\n# import matplotlib.patches as mpatches\n# import seaborn as sns","14c093a9":"test_data = pd.read_csv('..\/input\/adult-test\/adult_test.txt', names=[\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education.num\", \"marital.status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital.gain\", \"capital.loss\", \"hours.per.week\", \"native.country\", \"income\"], engine='python', na_values=\"?\").dropna()\nadult = pd.read_csv('..\/input\/train-data\/train_data.csv', index_col='Id')","61bcba4f":"adult.head()","9d4aa3d1":"filtro = adult['workclass'] != '?'\nadult = adult[filtro]","4c8ed275":"adult = adult.drop(columns=['education'])\n# adult.head()","f66e7624":"# features = adult.columns[:-1]\n# X, Y = adult[features], adult['income']","0742493c":"adult_encoded = adult.copy()\nfrom sklearn.preprocessing import OrdinalEncoder\nencoder = OrdinalEncoder()\nencoder.fit(adult[['sex', 'native.country', 'income']])\nadult_encoded[['sex', 'native.country', 'income']] = encoder.transform(adult_encoded[['sex', 'native.country', 'income']])\n# adult_encoded.head()","db0031e9":"adult_dummies = pd.get_dummies(adult_encoded, columns=['workclass', 'marital.status', 'occupation', 'relationship', 'race'])\nadult_dummies.head()","ff591b7d":"features_encoded = adult_dummies.columns.delete(8)\n# features_encoded\nX_encoded, Y_encoded = adult_dummies[features_encoded], adult_dummies['income']","eaef291d":"from sklearn.linear_model import LogisticRegression \n# obs: regulariza\u00e7\u00e3o \u00e9 aplicada automaticamente por essa fun\u00e7\u00e3o\nfrom sklearn.model_selection import cross_val_score, StratifiedShuffleSplit\n\nlogreg = LogisticRegression(max_iter=500)\nlogreg.fit(X_encoded, Y_encoded)\nfolds = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=121)\nlogreg_scores = cross_val_score(logreg, X_encoded, Y_encoded, cv=folds)\nprint(f'Acur\u00e1cia m\u00e9dia da regress\u00e3o log\u00edstica: {round(logreg_scores.mean()*100, 2)}%')","1308f8fe":"from sklearn.svm import SVC\n\nsvmachine = SVC()\nsvmachine.fit(X_encoded, Y_encoded)\nsvmachine_scores = cross_val_score(svmachine, X_encoded, Y_encoded, cv=folds)\nprint(f'Acur\u00e1cia m\u00e9dia da support vector machine: {round(svmachine_scores.mean()*100, 2)}%')","dd8e5696":"from sklearn.tree import DecisionTreeClassifier\n\ntree = DecisionTreeClassifier(random_state=0)\ntree.fit(X_encoded, Y_encoded)\ntree_scores = cross_val_score(tree, X_encoded, Y_encoded, cv=folds)\nprint(f'Acur\u00e1cia m\u00e9dia da \u00e1rvore de classifica\u00e7\u00e3o: {round(tree_scores.mean()*100, 2)}%')","22981aef":"from sklearn.naive_bayes import MultinomialNB\n\nnb = MultinomialNB()\nnb.fit(X_encoded, Y_encoded)\nnb_scores = cross_val_score(nb, X_encoded, Y_encoded, cv=folds)\nprint(f'Acur\u00e1cia m\u00e9dia do modelo naive bayes: {round(nb_scores.mean()*100, 2)}%')","bfb546fe":"test_data.head()","3491be5e":"test_data = test_data.drop(columns=['education'])\n# test_data.head()","f979fa22":"test_data_encoded = test_data.copy()\nencoder = OrdinalEncoder()\nencoder.fit(test_data[['sex', 'native.country', 'income']])\ntest_data_encoded[['sex', 'native.country', 'income']] = encoder.transform(test_data_encoded[['sex', 'native.country', 'income']])\n# test_data_encoded.head()","ffbc995b":"test_data_dummies = pd.get_dummies(test_data_encoded, columns=['workclass', 'marital.status', 'occupation', 'relationship', 'race'])\ntest_data_dummies.head()","37bc47f5":"features_encoded = test_data_dummies.columns.delete(8)\ntest_data_X, test_data_Y = test_data_dummies[features_encoded], test_data_dummies['income']","7c6a94e5":"tree.predict(test_data_X)","4559f4a0":"## \u00c1rvore de classifica\u00e7\u00e3o","beb64125":"Ent\u00e3o, fazemos a previs\u00e3o usando a melhor t\u00e9cnica obtida, isto \u00e9, a \u00e1rvore de classifica\u00e7\u00e3o.","caeaf52f":"## Regress\u00e3o Log\u00edstica\n\nAqui rodamos uma regress\u00e3o log\u00edstica no dataset e a avaliamos por meio de um processo de valida\u00e7\u00e3o cruzada estratificada. Nesse processo, o dataset \u00e9 embaralhado e dividido em 10 *folds* com a propor\u00e7\u00e3o de labels do dataset sendo mantida em cada um deles. Ao final, \u00e9 tirada a m\u00e9dia das acur\u00e1cias dos 10 classificadores gerados. A mesma forma de valida\u00e7\u00e3o cruzada estratificada foi utilizada nos demais modelos.","134d103e":"## Previs\u00e3o para competi\u00e7\u00e3o\n\nPrimeiro, fazemos a mesma limpeza e formata\u00e7\u00e3o que fizemos no dataset principal.","ae7a2d34":"## Support vector machine","d03adf61":"## Naive Bayes","ac43c31f":"Ent\u00e3o, transformamos as vari\u00e1veis categ\u00f3ricas em vari\u00e1veis num\u00e9ricas por meio do processo de *encoding*. Para vari\u00e1veis categ\u00f3ricas sem rela\u00e7\u00e3o de ordem entre seus poss\u00edveis valores, o ideal \u00e9 usar *one hot encoding*, como foi feito para a maioria delas. Para a coluna 'native.country', entretanto, *one hot encoding* resultaria em em 42 novas colunas, o que aumentaria excessivamente o tempo de processamento dos modelos. Por esse motivo, nessa coluna foi usado *ordinal encoding*. <br>\nPara as colunas bin\u00e1rias 'sex' e 'income' tamb\u00e9m foi usado *ordinal encoding*.","ca71e3e6":"Agora, fazemos uma breve limpeza do dataset. As linhas com 'workclass' = '?' foram removidas e a coluna 'education' tamb\u00e9m. Mant\u00e9m-se a coluna 'educational.num', a qual \u00e9 equivalente \u00e0 coluna 'education', por\u00e9m \u00e9 mais simples de ser interpretada, por ser num\u00e9rica.","514bce5a":"Separamos o dataset em features (X_encoded) e labels (Y_encoded).","939b6606":"# Classification with the Adult dataset\n\nPrimeiro, importamos as bibliotecas e carregamos os datasets. 'adult' \u00e9 o dataset completo, enquanto 'test_data' \u00e9 o dataset para a competi\u00e7\u00e3o do Kaggle."}}