{"cell_type":{"fd79c4b2":"code","f951c537":"code","ac8df664":"code","f927651a":"code","c18fdba7":"code","fa933c18":"code","448062ee":"code","46101b4b":"code","f182b549":"code","66a06165":"code","a602863c":"code","c54d88a7":"code","8147e381":"code","e1a225a9":"code","7158e0c0":"code","0066fc50":"code","38f36579":"code","e31549f7":"code","753da43a":"code","224dad2f":"code","0469d729":"code","14ad2b46":"code","c606e688":"markdown","cbaa9196":"markdown","c4e193f8":"markdown"},"source":{"fd79c4b2":"%matplotlib inline","f951c537":"import matplotlib.pyplot as plt\nimport cv2","ac8df664":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, decode_predictions, preprocess_input\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Conv2D, Conv2DTranspose, Reshape\nimport tensorflow as tf\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","f927651a":"modelv2 = InceptionResNetV2( input_shape = (224, 224, 3), weights = \"..\/input\/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5\")","c18fdba7":"images_gray = np.load('..\/input\/l\/gray_scale.npy')\nimages_lab = np.load('..\/input\/ab\/ab\/ab1.npy')","fa933c18":"def get_rbg_from_lab(gray_imgs, ab_imgs, n = 10):\n    imgs = np.zeros((n, 224, 224, 3))\n    imgs[:, :, :, 0] = gray_imgs[0:n:]\n    imgs[:, :, :, 1:] = ab_imgs[0:n:]\n    \n    imgs = imgs.astype(\"uint8\")\n    \n    imgs_ = []\n    for i in range(0, n):\n        imgs_.append(cv2.cvtColor(imgs[i], cv2.COLOR_LAB2RGB))\n\n    imgs_ = np.array(imgs_)\n\n    print(imgs_.shape)\n    \n    return imgs_\n    ","448062ee":"def pipe_line_img(gray_scale_imgs, batch_size = 100, preprocess_f = preprocess_input):\n    imgs = np.zeros((batch_size, 224, 224, 3))\n    for i in range(0, 3):\n        imgs[:batch_size, :, :,i] = gray_scale_imgs[:batch_size]\n    return preprocess_f(imgs)","46101b4b":"tbCallBack = tf.keras.callbacks.TensorBoard(log_dir='.\/folder_to_save_graph_3', histogram_freq=0, write_graph=True, write_images=True)","f182b549":"imgs_for_input = pipe_line_img(images_gray, batch_size = 300)","66a06165":"imgs_for_output = preprocess_input(get_rbg_from_lab(gray_imgs = images_gray, ab_imgs = images_lab, n = 300))","a602863c":"plt.imshow(imgs_for_output[17])","c54d88a7":"model_simple = Sequential()\nmodel_simple.add(Conv2D(strides = 1, kernel_size = 3, filters = 12, use_bias = True, bias_initializer = tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05) , padding = \"valid\", activation = tf.nn.relu))\nmodel_simple.add(Conv2D(strides = 1, kernel_size = 3, filters = 12, use_bias = True, bias_initializer = tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05) , padding = \"valid\", activation = tf.nn.relu))\nmodel_simple.add(Conv2DTranspose(strides = 1, kernel_size = 3, filters = 12, use_bias = True, bias_initializer = tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05) , padding = \"valid\", activation = tf.nn.relu))\nmodel_simple.add(Conv2DTranspose(strides = 1, kernel_size = 3, filters = 3, use_bias = True, bias_initializer = tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05) , padding = \"valid\", activation = tf.nn.relu))","8147e381":"model_simple.compile(optimizer = tf.keras.optimizers.Adam(epsilon = 1e-8), loss = tf.losses.mean_pairwise_squared_error)\n","e1a225a9":"imgs_for_s = np.zeros((300, 224, 224, 1))\nimgs_for_s[:, :, :, 0] = images_gray[:300] ","7158e0c0":"prediction = model_simple.predict(imgs_for_input)","0066fc50":"prediction.shape","38f36579":"model_simple.fit(imgs_for_input, imgs_for_output, epochs = 15)","e31549f7":"model_simple.fit(imgs_for_input, imgs_for_output, epochs = 1100, batch_size = 16)","753da43a":"out = model_simple.predict(imgs_for_input)","224dad2f":"plt.imshow(np.squeeze(imgs_for_input[3,:])) # Input","0469d729":"plt.imshow(out[3,:]) # Ouput","14ad2b46":"plt.imshow(np.squeeze(imgs_for_output[3,:])) # Expected","c606e688":"## Expected Output","cbaa9196":"## Output Image","c4e193f8":"## Input Image\n"}}