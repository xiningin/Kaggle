{"cell_type":{"a33f9001":"code","e827acf4":"code","23dfa47f":"code","d39c7763":"code","fa6a57c9":"code","31bfd73b":"code","9920654a":"code","b81dab80":"code","b9dca1d7":"code","ed724a76":"code","3c5fc9ad":"code","58335c73":"code","89e9fc6d":"code","8030a073":"code","b2b48fff":"code","7373abc1":"code","b4271e94":"code","652ea7b4":"code","33993d6e":"code","81846d10":"code","7b9ef973":"code","e77f2086":"code","cc4c09a9":"code","b29fcb68":"code","cd49cd7e":"code","f1739b2a":"code","01179669":"code","17170df9":"markdown","11ae6d27":"markdown","e1dec652":"markdown","ff91aa35":"markdown","da77d6de":"markdown","95182908":"markdown","292cda76":"markdown","3d6ad50c":"markdown","35518192":"markdown","d9d71756":"markdown","ecf01de3":"markdown","b3742c05":"markdown","9df356f6":"markdown","c714a45c":"markdown","a2a4da50":"markdown","8fbbaa1d":"markdown","3c346fc0":"markdown","838fe71f":"markdown","4d18d24e":"markdown","d3f91d4b":"markdown","b0cd51e0":"markdown"},"source":{"a33f9001":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 12,6\n\n# to avoid warnings\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.warn(\"this will not show\")\n\nsns.set(style='darkgrid')\n%matplotlib inline\n\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nfrom scipy.stats import chi2_contingency\nfrom numpy.random import seed\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler","e827acf4":"data = pd.read_csv('..\/input\/diabetic-data-cleaned\/diabetic_data_cleaned.csv', index_col=0) # import data\ndf = data.copy() # save a copy of data as diabetes","23dfa47f":"features = pd.read_csv('..\/input\/diabeticdatacleaned\/features.csv',index_col='Unnamed: 0')\ninfo = lambda attribute:print(f\"{attribute.upper()} : {features[features['Feature']==attribute]['Description'].values[0]}\\n\")","d39c7763":"def summary(df, pred=None):\n    obs = df.shape[0]\n    Types = df.dtypes\n    Counts = df.apply(lambda x: x.count())\n    Min = df.min()\n    Max = df.max()\n    Uniques = df.apply(lambda x: x.unique().shape[0])\n    Nulls = df.apply(lambda x: x.isnull().sum())\n    print('Data shape:', df.shape)\n\n    if pred is None:\n        cols = ['Types', 'Counts', 'Uniques', 'Nulls', 'Min', 'Max']\n        str = pd.concat([Types, Counts, Uniques, Nulls, Min, Max], axis = 1, sort=True)\n\n    str.columns = cols\n    print('___________________________\\nData Types:')\n    print(str.Types.value_counts())\n    print('___________________________')\n    return str\n\nsummary(df)","fa6a57c9":"df.describe().round(2).T","31bfd73b":"plt.figure(figsize=(6,6))\n\nexplode = [0,0.1]\nplt.pie(df['readmitted'].value_counts(),explode=explode,autopct='%1.1f%%',shadow=True,startangle=60)\nplt.legend(labels=df.readmitted.value_counts().index)\nplt.title('Readmitted Patients')\nplt.axis('off')\nplt.show()","9920654a":"print('Unique Values of Each Features:\\n')\nfor i in df:\n    print(f'{i}:\\n{sorted(df[i].unique())}\\n')","b81dab80":"categorical=df.select_dtypes(include='object').columns.tolist()\nprint(categorical)","b9dca1d7":"# define a function that returns a table, a chi-square value, and a p value\ndef chisquare_test(df, var_list, target, null_list=[]):\n    for var in var_list:\n        print(var.upper())\n        chi_test = pd.crosstab(df[var], df[target])\n        display(chi_test)\n    \n        chisq_value, pvalue, dataframe, expected = chi2_contingency(chi_test)\n    \n        print(f\"\"\"Chi-square value: {chisq_value:.2f}\np-value\\t\\t: {pvalue:.3f}\\n\"\"\")\n        \n        if pvalue > 0.01: # adds variables that fail to reject the null hypothesis\n            null_list.append(var)\n            \n    print(f'Fail to reject null hypothesis: {null_list}')","ed724a76":"cols_cat = ['race','gender', 'age', 'diag_1', 'max_glu_serum', 'A1Cresult', 'change', 'diabetesMed']\nnull_list=[]\nchisquare_test(df, cols_cat,'readmitted',null_list)","3c5fc9ad":"medications = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', \n            'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', \n               'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide', \n               'insulin', 'glyburide-metformin', 'glipizide-metformin', 'metformin-pioglitazone']\nchisquare_test(df, medications,'readmitted', null_list)","58335c73":"print(null_list)","89e9fc6d":"# drop columns that do not pass the p-value test\ndf = df.drop(columns=null_list)","8030a073":"# The numerical variables \nnumerical=df.select_dtypes(include=['int64','float']).columns.tolist()\nprint(numerical)","b2b48fff":"df.describe().T.round(2)","7373abc1":"# define a function that performs the ANOVA test and returns a table\ndef anova_table(var_list, null_list=[]):\n    for var in var_list:\n        print(var.upper())\n        \n        anova = ols('time_in_hospital ~ {}'.format(var), data=df).fit()\n        table = sm.stats.anova_lm(anova, typ=2)\n        pvalue=table['PR(>F)'][0]\n        if pvalue > 0.01: # adds variables that fail to reject the null hypothesis\n            null_list.append(var)\n        display(table)\n    print(f'Fail to reject null hypothesis: {null_list}')","b4271e94":"anova_vars = ['readmitted']+numerical\nanova_table(anova_vars)","652ea7b4":"# drop number_emergency column\ndf = df.drop(columns=['number_emergency'])","33993d6e":"# Unique Values of Each Features\nfor i in df:\n    print(f'{i}:\\n{sorted(df[i].unique())}\\n')","81846d10":"df_dummy = pd.get_dummies(df,drop_first=True)\ndf_dummy.head()","7b9ef973":"plt.figure(figsize=(20,5))\ndf_dummy.corr()[\"readmitted_YES\"].sort_values()[:-1].plot.bar();","e77f2086":"plt.figure(figsize=(20,20))\nsns.heatmap(df_dummy.corr(), cmap=\"coolwarm\");","cc4c09a9":"def corrank(X, threshold=0):\n    import itertools\n    df = pd.DataFrame([[i,j,X.corr().abs().loc[i,j]] for i,j in list(itertools.combinations(X.corr().abs(), 2))],columns=['Feature1','Feature2','corr'])    \n    df = df.sort_values(by='corr',ascending=False).reset_index(drop=True)\n    return df[df['corr']>threshold]\n\n# prints a descending list of correlation pair (Max on top)\ncorrank(df_dummy, 0.7)","b29fcb68":"# Remove the highly collinear features from data\ndef remove_collinear_features(x, threshold):\n    # Calculate the correlation matrix\n    corr_matrix = x.corr()\n    iters = range(len(corr_matrix.columns) - 1)\n    drop_cols = []\n\n    # Iterate through the correlation matrix and compare correlations\n    for i in iters:\n        for j in range(i+1):\n            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n            col = item.columns\n            row = item.index\n            val = abs(item.values)\n\n            # If correlation exceeds the threshold\n            if val >= threshold:\n                # Print the correlated features and the correlation value\n                print(col.values[0], \"|\", row.values[0], \"|\", round(val[0][0], 2))\n                drop_cols.append(col.values[0])\n\n    # Drop one of each pair of correlated columns\n    drops = set(drop_cols)\n    x = x.drop(columns=drops)\n\n    return x","cd49cd7e":"#Remove columns having more than 70% correlation\n#Both positive and negative correlations are considered here\ndf_dummy = remove_collinear_features(df_dummy,0.70)","f1739b2a":"df_dummy.shape","01179669":"# save dataset to new file for machine learning\ndf_dummy.to_csv('.\/diabetic_data_cleaned_dummy.csv')","17170df9":"## statistical testing - analysis of variance (ANOVA)","11ae6d27":"## chi-square test for association","e1dec652":"# One Hot Encoding","ff91aa35":"### categorical variables","da77d6de":"![one-way-ANOVA-formulas.png](attachment:one-way-ANOVA-formulas.png)","95182908":"# Are the features that affect readmissions correlated with each other?","292cda76":"* The categorical variables are: \n<br>`['race', 'gender', 'age', 'diag_1', 'max_glu_serum', 'A1Cresult', 'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide', 'insulin', 'glyburide-metformin', 'glipizide-metformin', 'metformin-pioglitazone', 'change', 'diabetesMed', 'readmitted']`\n\n\n* We are using the chi-square test for association with a p-value of 0.01 to reject the null hypothesis.","3d6ad50c":"* Using the analysis of variance (ANOVA) test, we want to determine if there is a statistically significant relationship between a numerical variable and the categorical target variable. Our p-value threshold is 0.01.","35518192":"# General Overview - Statistical Analysis","d9d71756":"> Based on the chi-square value and p-value, we can safely say that there is no relation between the independent variables and the target variable.","ecf01de3":"- We got cleaned dataset in the [first notebook](https:\/\/www.kaggle.com\/kirshoff\/01-exploratory-data-analysis-with-diabetes-dataset)\n- We use diabetic_data_cleaned.csv here.","b3742c05":"* We want to analyze the variables in this dataset to understand any relationships between them and their overall effects.\n* To do this,\n        * `Chi-square test` for categorical variables relationship\n        * We have to analyze numerical variables using `analysis of variance` or `ANOVA test`.\n* The purpose of these tests is to determine whether there is a statistically significant relationship between the target variable, readmissions and independent variable. Our p-value is 0.01, if anything above that, we cannot reject the null hypothesis.\n* A machine learning model can interpret integers as well as process strings, so we must transform all categorical variables using dummy variables as numeric variables. This takes the string values \u200b\u200bin a variable and converts them to columns labeled 0 or 1 relative to the string. We will also standardize the original numerical variables with a mean of 0 and a standard deviation of 1.\n* Finally, we look at the correlation coefficients between the independent variables to make sure they do not have a strong influence on each other. The threshold we used is -0.7 <x <0.7.\n\n","9df356f6":"### medications","c714a45c":"## Feature Selection\n![How-to-Choose-Feature-Selection-Methods-For-Machine-Learning.png](attachment:How-to-Choose-Feature-Selection-Methods-For-Machine-Learning.png)","a2a4da50":"### Import Libraries","8fbbaa1d":"> Based on the ANOVA test, we can drop the number of emergency visits since we cannot reject the null hypothesis that the averages for each class are similar, the p-value is greater than our threshold of 0.01.","3c346fc0":"* The medications: nateglinide, chlorpropamide, glimepiride, acetohexamide, glyburide, tolbutamide, miglitol, troglitazone, tolazamide, glyburide-metformin, glipizide-metformin, and metformin-pioglitazone all failed to pass the test since they have p-values greater than 0.01.\n\n* Since these variables are not independent of the target variable, we are removing them from the dataset.","838fe71f":"Binary columns will be replaced with 0 for No and 1 for Yes. In the gender column, Male and Female will be replaced with 0 and 1 respectively.","4d18d24e":"# saving machine learning dataset","d3f91d4b":"If the correlation value is greater than 0.7 or less than -0.7, we have to drop one of the two columns.\n\nThe correlation map is quite large for this notebook. Instead, we are going to find each correlation coefficient individually and mark the ones that have a coefficient greater than 0.7 or less than -0.7.","b0cd51e0":"# numerical variables"}}