{"cell_type":{"c77664cf":"code","c2a68701":"code","37567044":"code","bf7549e7":"code","c7e7789a":"code","2bbb44a5":"code","be0e8c67":"code","4477ff20":"code","5a3c0731":"code","717dbbda":"code","3bf10f94":"code","81ba694d":"code","d1b2da0b":"code","e6381175":"code","4389e437":"code","67aff663":"code","c738fb23":"code","5c9f9dea":"code","823fccfe":"code","c954f316":"code","0d100032":"code","c8189b04":"code","5492f27b":"code","7f3d3d8e":"code","01322874":"code","8294023f":"code","77bed0ed":"code","95e64ac6":"code","36052814":"code","1f8ba47c":"code","6fcccb94":"code","4fb03b1e":"code","f1bfc611":"code","edeae50a":"code","eebbfab0":"code","cd2b6e67":"code","21e09917":"code","5f10aefa":"code","c770b5eb":"code","e6d03b26":"code","b51651b3":"code","9d0f133f":"code","b66a2e13":"code","bbc88e00":"code","7e170ba2":"code","2620939e":"code","30047507":"code","abb026f1":"code","faa232af":"code","e3bed92b":"code","fe008d57":"code","95bfbcfa":"code","54283dbe":"code","0c8e549c":"code","c5621b97":"code","19defe59":"code","6111972f":"code","3054a5d7":"code","0de3cd65":"code","e151ba6b":"code","b14ce4df":"code","787f44db":"code","c6a5456f":"code","6fca61e9":"code","1c6bc403":"code","78573b44":"code","a68f27e1":"code","69c776c3":"code","c027e7aa":"code","9f434d7e":"code","2d8bc2ee":"code","11c2d0be":"code","f2040878":"code","96b55236":"code","03b0d6c1":"code","c3142681":"code","e782a5e8":"code","5b68c3af":"code","39706455":"code","d3269f9e":"code","e92c3ba9":"code","1168b217":"code","52322afd":"code","be244c4d":"code","cc83faaa":"code","81182a0a":"code","ded6f292":"code","595ab194":"code","a1eb67e4":"code","4efd402e":"code","dbbf2275":"code","f815ecaf":"code","fde18830":"code","a742ade2":"code","d0041f67":"code","c3b7b480":"code","158486b3":"code","25b29959":"code","d8e25975":"code","6c62fb04":"code","780a85b5":"code","a87dbfb0":"code","ff094bfe":"code","f8b196e0":"code","b094736d":"code","55bd080b":"code","ffebeb9a":"code","ccf5f8d9":"code","062afa71":"code","2749ae52":"code","47483ae8":"code","b95e6eee":"code","de7d2851":"code","6e51c0d2":"code","23fdf8f2":"code","2be38045":"code","7e4d0f1c":"markdown","fc24ccc6":"markdown","1ee8a8d7":"markdown","91dc6f98":"markdown","6274faa1":"markdown","b0ddc89d":"markdown","26a22902":"markdown","2bc5af9b":"markdown","68895684":"markdown","229c8fe8":"markdown","543f3393":"markdown","f6e5b613":"markdown","a26a326e":"markdown","b4e4759a":"markdown","4263812b":"markdown","2ffb590f":"markdown","dc6291d6":"markdown"},"source":{"c77664cf":"import pandas as pd\nimport numpy as np\nimport sklearn\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.pipeline import Pipeline\n%config InlineBackend.figure_format = 'svg'\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nimport warnings\nwarnings.filterwarnings('ignore')\nimport random\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, RidgeCV\nfrom yellowbrick.regressor import prediction_error","c2a68701":"df1= pd.read_csv('..\/input\/tlc-green-taxi-for-jan-and-fab\/green_tripdata-one-.csv')\ndf1","37567044":"df2= pd.read_csv('..\/input\/tlc-green-taxi-for-jan-and-fab\/green_tripdata_two-.csv')\ndf2","bf7549e7":"con_data= pd.concat([df1,df2])   # concat two dataset\ncon_data.head(10)","c7e7789a":"con_data= con_data.reset_index(drop= True)","2bbb44a5":"con_data.shape","be0e8c67":"con_data.info()","4477ff20":"duplicate = con_data.duplicated()\nprint(duplicate.sum())\ncon_data[duplicate]","5a3c0731":"duplicate = con_data.index.duplicated()\nprint(duplicate.sum())","717dbbda":"# split the data for train and test\ncon_data_train , con_data_test = train_test_split(con_data, test_size=0.2, random_state=199)","3bf10f94":"# split the train for train and val\ncon_data_train2, con_data_val =  train_test_split(con_data_train, test_size=0.2, random_state=199)","81ba694d":"# convert type pickup datetime for train\ncon_data_train2['lpep_pickup_datetime']= pd.to_datetime(con_data_train2['lpep_pickup_datetime'],format=\"%Y-%m-%d %H:%M:%S\")\n\n# convert type pickup datetime for val\ncon_data_val['lpep_pickup_datetime']= pd.to_datetime(con_data_val['lpep_pickup_datetime'],format=\"%Y-%m-%d %H:%M:%S\")\n\n# convert type pickup datetime for test\ncon_data_test['lpep_pickup_datetime']= pd.to_datetime(con_data_test['lpep_pickup_datetime'],format=\"%Y-%m-%d %H:%M:%S\")\n\n############################\n\n# convert type dropoff datetime for train\ncon_data_train2['lpep_dropoff_datetime']= pd.to_datetime(con_data_train2['lpep_dropoff_datetime'],format=\"%Y-%m-%d %H:%M:%S\")\n\n# convert type dropoff datetime for val\ncon_data_val['lpep_dropoff_datetime']= pd.to_datetime(con_data_val['lpep_dropoff_datetime'],format=\"%Y-%m-%d %H:%M:%S\")\n\n# convert type dropoff datetime for test\ncon_data_test['lpep_dropoff_datetime']= pd.to_datetime(con_data_test['lpep_dropoff_datetime'],format=\"%Y-%m-%d %H:%M:%S\") ","d1b2da0b":"con_data_train2.dtypes","e6381175":"con_data_val.dtypes","4389e437":"con_data_test.dtypes","67aff663":"#### Pickup datetime convert ####\n\n# for train\n\n#extract month\ncon_data_train2[\"month_pickup\"] = pd.DatetimeIndex(con_data_train2[\"lpep_pickup_datetime\"]).month\n\n#extract week day \ncon_data_train2[\"week_day_pickup\"]= con_data_train2[\"lpep_pickup_datetime\"].dt.weekday\n\n#extract day \ncon_data_train2[\"day_pickup\"]= con_data_train2[\"lpep_pickup_datetime\"].dt.day\n\n#extract hour\ncon_data_train2[\"hour_pickup\"]= con_data_train2[\"lpep_pickup_datetime\"].dt.hour \n\ncon_data_train2 =con_data_train2.sort_values(by = \"lpep_pickup_datetime\",ascending = True)\n\n#####################\n\n# for val\n\n#extract month\ncon_data_val[\"month_pickup\"] = pd.DatetimeIndex(con_data_val[\"lpep_pickup_datetime\"]).month\n\n#extract week day \ncon_data_val[\"week_day_pickup\"]= con_data_val[\"lpep_pickup_datetime\"].dt.weekday\n\n#extract day \ncon_data_val[\"day_pickup\"]= con_data_val[\"lpep_pickup_datetime\"].dt.day\n\n#extract hour\ncon_data_val[\"hour_pickup\"]= con_data_val[\"lpep_pickup_datetime\"].dt.hour \n\ncon_data_val =con_data_val.sort_values(by = \"lpep_pickup_datetime\",ascending = True)\n\n#####################\n\n# for test\n\n#extract month\ncon_data_test[\"month_pickup\"] = pd.DatetimeIndex(con_data_test[\"lpep_pickup_datetime\"]).month\n\n#extract week day \ncon_data_test[\"week_day_pickup\"]= con_data_test[\"lpep_pickup_datetime\"].dt.weekday\n\n#extract day \ncon_data_test[\"day_pickup\"]= con_data_test[\"lpep_pickup_datetime\"].dt.day\n\n#extract hour\ncon_data_test[\"hour_pickup\"]= con_data_test[\"lpep_pickup_datetime\"].dt.hour \n\ncon_data_test =con_data_test.sort_values(by = \"lpep_pickup_datetime\",ascending = True)","c738fb23":"#### Dropoff datetime convert ####\n\n# for train\n\n#extract month\ncon_data_train2[\"month_dropoff\"] = pd.DatetimeIndex(con_data_train2[\"lpep_dropoff_datetime\"]).month\n\n#extract week day \ncon_data_train2[\"week_day_dropoff\"]= con_data_train2[\"lpep_dropoff_datetime\"].dt.weekday\n\n#extract day \ncon_data_train2[\"day_dropoff\"]= con_data_train2[\"lpep_dropoff_datetime\"].dt.day\n\n#extract hour\ncon_data_train2[\"hour_dropoff\"]= con_data_train2[\"lpep_dropoff_datetime\"].dt.hour \n\ncon_data_train2 =con_data_train2.sort_values(by = \"lpep_dropoff_datetime\",ascending = True)\n\n#####################\n\n# for val\n\n#extract month\ncon_data_val[\"month_dropoff\"] = pd.DatetimeIndex(con_data_val[\"lpep_dropoff_datetime\"]).month\n\n#extract week day \ncon_data_val[\"week_day_dropoff\"]= con_data_val[\"lpep_dropoff_datetime\"].dt.weekday\n\n#extract day \ncon_data_val[\"day_dropoff\"]= con_data_val[\"lpep_dropoff_datetime\"].dt.day\n\n#extract hour\ncon_data_val[\"hour_dropoff\"]= con_data_val[\"lpep_dropoff_datetime\"].dt.hour \n\ncon_data_val =con_data_val.sort_values(by = \"lpep_dropoff_datetime\",ascending = True)\n\n#####################\n\n# for test\n\n#extract month\ncon_data_test[\"month_dropoff\"] = pd.DatetimeIndex(con_data_test[\"lpep_dropoff_datetime\"]).month\n\n#extract week day \ncon_data_test[\"week_day_dropoff\"]= con_data_test[\"lpep_dropoff_datetime\"].dt.weekday\n\n#extract day \ncon_data_test[\"day_dropoff\"]= con_data_test[\"lpep_dropoff_datetime\"].dt.day\n\n#extract hour\ncon_data_test[\"hour_dropoff\"]= con_data_test[\"lpep_dropoff_datetime\"].dt.hour \n\ncon_data_test =con_data_test.sort_values(by = \"lpep_dropoff_datetime\",ascending = True)","5c9f9dea":"con_data_train2.hour_pickup.unique()","823fccfe":"con_data_train2.week_day_pickup.unique()","c954f316":"# adding rush hours\ndef rushhour(hour):\n    if hour in [5,6,7,8,17,18,19]:\n        return 1\n    else: return 0\n \n# apply method\ncon_data_train2['rush_hour'] = con_data_train2.hour_pickup.apply(rushhour)\ncon_data_val['rush_hour'] = con_data_val.hour_pickup.apply(rushhour)\ncon_data_test['rush_hour'] = con_data_test.hour_pickup.apply(rushhour)\n\n#adding work days\ndef workday(day):\n    if day in [0,1,2,3,4]:\n        return 1\n    else: return 0\n\n  # apply method\ncon_data_train2['work_day'] = con_data_train2.week_day_pickup.apply(workday)\ncon_data_val['work_day'] = con_data_val.week_day_pickup.apply(workday)\ncon_data_test['work_day'] = con_data_test.week_day_pickup.apply(workday)\n\n# #adding work hours\n# def workhours(hour):\n#     if hour in [7,8,9,16,17,18,19]:\n#         return 1\n#     else: return 0\n\n#   # apply method\n# con_data_train2['work_hours'] = con_data_train2.hour_pickup.apply(workhours)\n# con_data_val['work_hours'] = con_data_val.hour_pickup.apply(workhours)\n# con_data_test['work_hours'] = con_data_test.hour_pickup.apply(workhours)\n","0d100032":"con_data_train2.sample(10)","c8189b04":"con_data_val.head()","5492f27b":"con_data_test.head()","7f3d3d8e":"con_data_train2.columns","01322874":"con_data_val.columns","8294023f":"con_data_test.columns","77bed0ed":"#### Clean outliers for time ####\n\n\n#### for train ####\n\ndate = pd.Timestamp(2021,1,1)\ncon_data_train2 = con_data_train2[con_data_train2['lpep_pickup_datetime'] >= date ]\n\ndate = pd.Timestamp(2021,2,28)\ncon_data_train2 = con_data_train2[con_data_train2['lpep_pickup_datetime'] <= date ]\n\n\n#### for val ####\n\ndate = pd.Timestamp(2021,1,1)\ncon_data_val = con_data_val[con_data_val['lpep_pickup_datetime'] >= date ]\n\ndate = pd.Timestamp(2021,2,28)\ncon_data_val = con_data_val[con_data_val['lpep_pickup_datetime'] <= date ]\n\n\n#### for test ####\n\ndate = pd.Timestamp(2021,1,1)\ncon_data_test = con_data_test[con_data_test['lpep_pickup_datetime'] >= date ]\n\ndate = pd.Timestamp(2021,2,28)\ncon_data_test = con_data_test[con_data_test['lpep_pickup_datetime'] <= date ]","95e64ac6":"# drop datetime columns for train \ncon_data_train2= con_data_train2.drop(['lpep_pickup_datetime','lpep_dropoff_datetime'],axis =1)\n# drop datetime columns for val \ncon_data_val= con_data_val.drop(['lpep_pickup_datetime','lpep_dropoff_datetime'],axis =1)\n# drop datetime columns for test \ncon_data_test= con_data_test.drop(['lpep_pickup_datetime','lpep_dropoff_datetime'],axis =1)","36052814":"con_data_train2.isna().sum()","1f8ba47c":"con_data_val.isna().sum()","6fcccb94":"con_data_test.isna().sum()","4fb03b1e":"# drop columns for Train\ncon_data_train2.drop(columns=['ehail_fee'], inplace=True)\n\n# drop columns for Val\ncon_data_val.drop(columns=['ehail_fee'], inplace=True)\n\n# drop columns for test\ncon_data_test.drop(columns=['ehail_fee'], inplace=True)","f1bfc611":"con_data_val.isna().sum()","edeae50a":"#### for train ####\n\nduplicate = con_data_train2.duplicated()\nprint(duplicate.sum())\ncon_data_train2[duplicate]","eebbfab0":"#### for train ####\n\n# drop duplicates rows\ncon_data_train2.drop_duplicates(inplace=True)","cd2b6e67":"#### for val ####\n\nduplicate = con_data_val.duplicated()\nprint(duplicate.sum())\ncon_data_val[duplicate]","21e09917":"#### for val ####\n\n# drop duplicates rows\ncon_data_val.drop_duplicates(inplace=True)","5f10aefa":"#### for test ####\n\nduplicate = con_data_test.duplicated()\nprint(duplicate.sum())\ncon_data_test[duplicate]","c770b5eb":"#### for test ####\n\n# drop duplicates rows\ncon_data_test.drop_duplicates(inplace=True)","e6d03b26":"#### fill nulls ####\n\n# drop null in rows for Train\ncon_data_train2 = con_data_train2.dropna()\n\n# drop null in rows for Val\ncon_data_val = con_data_val.dropna()\n\n# drop null in rows for test\ncon_data_test = con_data_test.dropna()","b51651b3":"con_data_train2.describe().transpose()","9d0f133f":"con_data_train2['passenger_count'].value_counts()","b66a2e13":"con_data_train2['trip_distance'].value_counts()","bbc88e00":"con_data_train2['trip_distance'].nlargest(10)","7e170ba2":"con_data_train2['fare_amount'].value_counts()","2620939e":"con_data_train2['payment_type'].value_counts()","30047507":"con_data_train2['total_amount'].value_counts()","abb026f1":"#### passenger_count outliers ####\n\n# Remove passenger_count outliers for Train\ncon_data_train2 = con_data_train2[con_data_train2['passenger_count']>0]\ncon_data_train2 = con_data_train2[con_data_train2['passenger_count']<7]\n\n# Remove passenger_count outliers for val\ncon_data_val = con_data_val[con_data_val['passenger_count']>0]\ncon_data_val = con_data_val[con_data_val['passenger_count']<7]\n\n# Remove passenger_count outliers for test\ncon_data_test = con_data_test[con_data_test['passenger_count']>0]\ncon_data_test = con_data_test[con_data_test['passenger_count']<7]\n\n\n\n#### zero distance trips ####\n\n# removing zero distance trips for Train\ncon_data_train2 = con_data_train2[con_data_train2['trip_distance'] > 0]\ncon_data_train2 = con_data_train2[con_data_train2['trip_distance'] <= 200]\n\n# removing zero distance trips for val\ncon_data_val = con_data_val[con_data_val['trip_distance'] > 0]\ncon_data_val = con_data_val[con_data_val['trip_distance'] <= 200]\n\n# removing zero distance trips for test\ncon_data_test = con_data_test[con_data_test['trip_distance'] > 0]\ncon_data_test = con_data_test[con_data_test['trip_distance'] <= 200]\n\n\n\n#### zero\/negative fares ####\n\n# removing trips with zero\/negative fares for Train\ncon_data_train2= con_data_train2[con_data_train2['fare_amount'] > 2.5]\ncon_data_train2= con_data_train2[con_data_train2['total_amount'] > 0]\n\n# removing trips with zero\/negative fares for val\ncon_data_val= con_data_val[con_data_val['fare_amount'] > 2.5]\ncon_data_val= con_data_val[con_data_val['total_amount'] > 0]\n\n# removing trips with zero\/negative fares for test\ncon_data_test= con_data_test[con_data_test['fare_amount'] > 2.5]\ncon_data_test= con_data_test[con_data_test['total_amount'] > 0]\n\n\n\n#### payment type ####\n\n# removing payment type more than 4 for Train\ncon_data_train2= con_data_train2[con_data_train2['payment_type'] <= 4]\n\n# removing payment type more than 4 for val\ncon_data_val= con_data_val[con_data_val['payment_type'] <= 4]\n\n# removing payment type more than 4 for test\ncon_data_test= con_data_test[con_data_test['payment_type'] <= 4]","faa232af":"con_data_train2.info()","e3bed92b":"con_data_val.info()","fe008d57":"con_data_test.info()","95bfbcfa":"con_data_train2.shape","54283dbe":"con_data_val.shape","0c8e549c":"con_data_test.shape","c5621b97":"con_data_train2['store_and_fwd_flag'].dtypes","19defe59":"con_data_train2['RatecodeID'].value_counts()","6111972f":"con_data_val['RatecodeID'].value_counts()","3054a5d7":"con_data_test['RatecodeID'].value_counts()","0de3cd65":"# RatecodeID type conversion to get dummies\ncon_data_train2['RatecodeID'] = con_data_train2.RatecodeID.astype('category')\ncon_data_val['RatecodeID'] = con_data_val.RatecodeID.astype('category')\ncon_data_test['RatecodeID'] = con_data_test.RatecodeID.astype('category')","e151ba6b":"con_data_train2['payment_type'].value_counts()","b14ce4df":"con_data_val['payment_type'].value_counts()","787f44db":"con_data_test['payment_type'].value_counts()","c6a5456f":"# payment_type type conversion to get dummies\ncon_data_train2['payment_type'] = con_data_train2.payment_type.astype('category')\ncon_data_val['payment_type'] = con_data_val.payment_type.astype('category')\ncon_data_test['payment_type'] = con_data_test.payment_type.astype('category')","6fca61e9":"# get dummies for train \ncon_data_train2 = pd.get_dummies(con_data_train2)\n\n# get dummies for val \ncon_data_val = pd.get_dummies(con_data_val)\n\n# get dummies for test \ncon_data_test = pd.get_dummies(con_data_test)","1c6bc403":"con_data_train2.shape","78573b44":"con_data_val.shape","a68f27e1":"con_data_test.shape","69c776c3":"con_data_train2.columns","c027e7aa":"con_data_val.columns","9f434d7e":"con_data_test.columns","2d8bc2ee":"# rename the columns for train\ncon_data_train2.rename(columns={'store_and_fwd_flag_N': 'not_a_store_and_forward_trip',\n                         'store_and_fwd_flag_Y': 'store_and_forward_trip',\n                         'RatecodeID_1.0': 'standard_rate',\n                         'RatecodeID_2.0': 'JFK',\n                         'RatecodeID_3.0': 'newark',\n                         'RatecodeID_4.0': 'nassau_or_westchester',\n                         'RatecodeID_5.0': 'negotiated_fare',\n                         'payment_type_1.0': 'credit_card',\n                         'payment_type_2.0': 'cash',\n                         'payment_type_3.0': 'no_charge',\n                         'payment_type_4.0': 'dispute'\n                         }, inplace= True)\n\n\n\n# rename the columns for val\ncon_data_val.rename(columns={'store_and_fwd_flag_N': 'not_a_store_and_forward_trip',\n                         'store_and_fwd_flag_Y': 'store_and_forward_trip',\n                         'RatecodeID_1.0': 'standard_rate',\n                         'RatecodeID_2.0': 'JFK',\n                         'RatecodeID_3.0': 'newark',\n                         'RatecodeID_4.0': 'nassau_or_westchester',\n                         'RatecodeID_5.0': 'negotiated_fare',\n                         'payment_type_1.0': 'credit_card',\n                         'payment_type_2.0': 'cash',\n                         'payment_type_3.0': 'no_charge',\n                         'payment_type_4.0': 'dispute'\n                         }, inplace= True)\n\n\n# rename the columns for test\ncon_data_test.rename(columns={'store_and_fwd_flag_N': 'not_a_store_and_forward_trip',\n                         'store_and_fwd_flag_Y': 'store_and_forward_trip',\n                         'RatecodeID_1.0': 'standard_rate',\n                         'RatecodeID_2.0': 'JFK',\n                         'RatecodeID_3.0': 'newark',\n                         'RatecodeID_4.0': 'nassau_or_westchester',\n                         'RatecodeID_5.0': 'negotiated_fare',\n                         'payment_type_1.0': 'credit_card',\n                         'payment_type_2.0': 'cash',\n                         'payment_type_3.0': 'no_charge',\n                         'payment_type_4.0': 'dispute'\n                         }, inplace= True)","11c2d0be":"con_data_train2.sample(7)","f2040878":"con_data_val.sample(7)","96b55236":"con_data_test.sample(7)","03b0d6c1":"train_sample = con_data_train2[[ 'passenger_count'\t,'improvement_surcharge','congestion_surcharge',\n                   'week_day_pickup','hour_pickup','work_day','trip_distance',\n                   'store_and_forward_trip', \n                   'standard_rate','JFK','newark','nassau_or_westchester','negotiated_fare',\n                   'credit_card', 'cash', 'no_charge', 'dispute'\n                   ]]\nval_sample = con_data_val[['passenger_count'\t,'improvement_surcharge', 'congestion_surcharge',\n                   'week_day_pickup','hour_pickup','work_day','trip_distance',\n                   'store_and_forward_trip', \n                   'standard_rate','JFK','newark','nassau_or_westchester','negotiated_fare',\n                   'credit_card', 'cash', 'no_charge', 'dispute'\n                   ]]\ntest_sample = con_data_test[[ 'passenger_count'\t,'improvement_surcharge','congestion_surcharge',\n                   'week_day_pickup','hour_pickup','work_day','trip_distance',\n                   'store_and_forward_trip',\n                   'standard_rate','JFK','newark','nassau_or_westchester','negotiated_fare',\n                   'credit_card', 'cash', 'no_charge', 'dispute'\n                   ]]","c3142681":"# frequency of fare_amount\nplt.figure(figsize=(8, 6))\nsns.histplot(con_data_train2['fare_amount'], bins = 75, color ='#533e98' , stat='density', kde=True)\nplt.title('Fare Distribution');\nplt.xlabel('Fare Amount');\nplt.grid(axis='y', lw = 0.25);\n# plt.savefig('plot1.png', dpi = 300, bbox_inches = 'tight');","e782a5e8":"#create new variable log of fare amount\ncon_data_train2[\"log_fare_amount\"] = np.log(con_data_train2[\"fare_amount\"])","5b68c3af":"plt.figure(figsize = (8,5))\nsns.distplot(con_data_train2[\"log_fare_amount\"],color ='#533e98')\nplt.axvline(con_data_train2[\"log_fare_amount\"].mean(),color = \"k\",\n            linestyle = \"dashed\",label = \"Avg fare amount\")\nplt.title(\"Distribution in log of fare amount\")\nplt.legend(loc = \"best\",prop = {\"size\" : 12});\n# plt.savefig('plot2.png', dpi = 300, bbox_inches = 'tight');","39706455":"fig1=plt.figure(figsize=(8, 6))\nax1=fig1.add_subplot(1,1,1)\nax1.scatter(con_data_train2.trip_distance, con_data_train2.fare_amount, color='#533e98',alpha=0.1)\nax1.set_title('The graph of payment depending on the trip distance')\nax1.set_xlabel('Distance')\nax1.set_ylabel('Payment');\n\nfig2= plt.figure(figsize=(8, 6))\nax2= fig2.add_subplot(1,1,1)\nax2.scatter(con_data_train2.passenger_count, con_data_train2.fare_amount, color='#c15a3a',alpha=0.1)\nax2.set_title('The graph of payment depending on the number of passengers');\nax2.set_xlabel('Number of passengers')\nax2.set_ylabel('Payment');\n# plt.savefig('plot3.png', dpi = 300, bbox_inches = 'tight');","d3269f9e":"con_data_train2['passenger_count'].value_counts()","e92c3ba9":"# passenger count in trips distribution\nplt.figure(figsize=(9, 19))\npass_count = con_data_train2['passenger_count'].value_counts()\nc = ['#6f5e8f', '#c15a3a', '#ade5e1', '#11415f', '#dfb08b', '#92576e']\nplt.pie(pass_count,labels=None\n        , autopct=\"%0.1f%%\", pctdistance=1.15, colors=c);\nplt.legend(title = 'Passenger count:',\n           labels=['One person', 'Two persons','Five persons', 'Three persons', 'Six persons','Four persons']);\n# plt.savefig('plot4.png', dpi = 300, bbox_inches = 'tight');","1168b217":"# taxi trip repartition by hour of the day\nplt.figure(figsize=(8,6));\nsns.catplot(x='hour_pickup', kind='count', palette='icefire', data=con_data_train2, height=3, aspect=3);\nplt.title('Hour of Day');\n# plt.savefig('plot5.png', dpi = 300, bbox_inches = 'tight');","52322afd":"plt.figure(figsize=(8,6));\nsns.lineplot(data = con_data_train2, x='hour_pickup',y='fare_amount',palette=['#6f5e8f', '#c15a3a'], hue='month_pickup')\nplt.xticks(np.arange(0, 24, 1))\nplt.legend(title = 'Pickup Months:',\n           labels=['January', 'February']);\nplt.xlabel('Pick Up Hours')\nplt.ylabel('Total Amount')\nplt.title('Rush Hour of Day Efficting on Payment in January and February');\nplt.grid(axis='both', lw = 0.25);\n# plt.savefig('plot6.png', dpi = 300, bbox_inches = 'tight');","be244c4d":"plt.figure(figsize=(8,6))\nplt.hist(con_data_train2['passenger_count'], bins=100, color='#533e98' )\nplt.xlabel('No. of Passengers')\nplt.ylabel('Frequency');\n# plt.savefig('plot7.png', dpi = 300, bbox_inches = 'tight');","cc83faaa":"plt.figure(figsize=(8,6))\nplt.scatter(x=con_data_train2['passenger_count'], y=con_data_train2['fare_amount'], s=10, color='#c15a3a',alpha=0.2)\nplt.xlabel('No. of Passengers')\nplt.ylabel('Fare');\n# plt.savefig('plot8.png', dpi = 300, bbox_inches = 'tight');","81182a0a":"plt.figure(figsize=(8,6))\nplt.hist(con_data_train2['hour_pickup'], bins=100, color='#533e98')\nplt.xlabel('Pickup Hour')\nplt.ylabel('Frequency');\n# plt.savefig('plot9.png', dpi = 300, bbox_inches = 'tight');","ded6f292":"plt.figure(figsize=(8,6))\nplt.scatter(x=con_data_train2['hour_pickup'], y=con_data_train2['fare_amount'], s=10, color='#c15a3a',alpha=0.2)\nplt.xlabel('Pickup Hour')\nplt.ylabel('Fare');\n# plt.savefig('plot10.png', dpi = 300, bbox_inches = 'tight');","595ab194":"plt.figure(figsize=(8,6))\npositions = (0, 1, 2, 3, 4, 5, 6)\nlabels = ('Mon','Tue','Wed','Thu','Fri','Sat','Sun')\nplt.xticks(positions,labels); \nplt.hist(con_data_train2['week_day_pickup'], bins=100, color='#533e98')\nplt.xlabel('Day pickup of Week')\nplt.ylabel('Frequency');\n# plt.savefig('plot11.png', dpi = 300, bbox_inches = 'tight');","a1eb67e4":"plt.figure(figsize=(8,6))\npositions = (0, 1, 2, 3, 4, 5, 6)\nlabels = ('Mon','Tue','Wed','Thu','Fri','Sat','Sun')\nplt.xticks(positions,labels); \nplt.scatter(x=con_data_train2['week_day_pickup'], y=con_data_train2['fare_amount'], s=10, color='#c15a3a',alpha=0.2)\nplt.xlabel('Day pickup of Week')\nplt.ylabel('Fare');\n# plt.savefig('plot12.png', dpi = 300, bbox_inches = 'tight');","4efd402e":"plt.rcParams[\"figure.figsize\"] = (20,18);\n\n# corr\ncon_data_corr = con_data_train2.corr()\n\n# mask\nmask = np.triu(np.ones_like(con_data_corr, dtype=np.bool))\n\n# adjust mask and df\nmask = mask[1:, :-1]\ncorr = con_data_corr.iloc[1:,:-1].copy()\n\nsns.heatmap(corr, cmap = 'icefire', annot = True, vmin= -1, vmax= 1, linewidths=1.5, fmt='.2f', mask=mask);\nplt.title('CORRELATION BETWEEN FEATURES\\n', loc='left', fontsize=18);\n# plt.savefig('plot13.png', dpi = 300, bbox_inches = 'tight');","dbbf2275":"con_data_corr = con_data_train2.corr()['fare_amount'][:-1] \ncorr_features = con_data_corr[abs(con_data_corr) > 0.5].sort_values(ascending=False)\nprint('Strongly correlated features with fare amount:\\n{}'.format(corr_features))","f815ecaf":"con_data_val.shape","fde18830":"con_data_train2.shape","a742ade2":"con_data_test.shape","d0041f67":"scaler = StandardScaler()\n\ntrain_sample[train_sample.columns]=scaler.fit_transform(train_sample[train_sample.columns])\nval_sample[val_sample.columns]=scaler.transform(val_sample[val_sample.columns])\ntest_sample[test_sample.columns]=scaler.transform(test_sample[test_sample.columns])\n\n","c3b7b480":"X_train=train_sample\ny_train=con_data_train2['fare_amount']\nX_val=val_sample\ny_val=con_data_val['fare_amount']\nX_test=test_sample\ny_test=con_data_test['fare_amount']","158486b3":"print(\"Length of the X_train = \",len(X_train))\nprint(\"Length of the y_train = \",len(y_train))\nprint(\"Length of the X_test = \",len(X_test))\nprint(\"Length of the y_test = \",len(y_test))\nprint(\"Length of the y_val = \",len(X_val))\nprint(\"Length of the y_val = \",len(y_val))","25b29959":"seed = 199\nlm = LinearRegression()\nlm1 = lm.fit(X_train,y_train)\ny_pred_val = lm1.predict(X_val)\ny_pred_train = lm1.predict(X_train)\ny_pred_test = lm1.predict(X_test)\nprint(\"R-sq of training set = \",lm1.score(X_train,y_train))\nprint(\"R-sq of validation set = \",lm1.score(X_val,y_val))\nprint(\"R-sq of Test set = \",lm1.score(X_test,y_test))","d8e25975":"# plot\npred = lm1.predict(X_train) \nsns.jointplot(x= pred, y= y_train, kind='reg', color='#533e98');\n# plt.savefig('plot14.png', dpi = 300, bbox_inches = 'tight');","6c62fb04":"from sklearn import metrics\nprint('\\nLinear Regression Performance Metrics')\nprint('R^2=',metrics.explained_variance_score(y_test,y_pred_test))\nprint('MAE:',metrics.mean_absolute_error(y_test,y_pred_test))\nprint('MSE:',metrics.mean_squared_error(y_test,y_pred_test))\nprint('RMSE:',np.sqrt(metrics.mean_squared_error(y_test,y_pred_test)))","780a85b5":"visualizer = prediction_error(lm, X_train, y_train, X_test, y_test, size=(700, 400),color='y')\n# plt.savefig('plot15.png', dpi = 300, bbox_inches = 'tight');","a87dbfb0":"#  train data\nlm_model_ridge = Ridge(alpha = .01)\nlm_model_ridge.fit(X_train, y_train)\nlm_model_ridge.score(X_train, y_train)","ff094bfe":"#  val data \nlm_model_ridge = Ridge(alpha = 0.01)\nlm_model_ridge.fit(X_train, y_train)\nlm_model_ridge.score(X_val, y_val)","f8b196e0":"#  Test data \nlm_model_ridge = Ridge(alpha = 0.01)\nlm_model_ridge.fit(X_train, y_train)\nlm_model_ridge.score(X_test, y_test)","b094736d":"#Mean Absolute Error (MAE)\ndef mae(y_true, y_pred):\n    return np.mean(np.abs(y_pred - y_true)) ","55bd080b":"alphalist = 10**(np.linspace(-2,2,200))\nerr_vec_val = np.zeros(len(alphalist))\nerr_vec_train = np.zeros(len(alphalist))\n\nfor i,curr_alpha in enumerate(alphalist):\n\n    \n    steps = [('standardize', StandardScaler()), \n             ('Ridge', Ridge(alpha = curr_alpha))]\n\n    pipe = Pipeline(steps)\n    pipe.fit(X_train.loc[:,:].values, y_train)\n    \n    val_set_pred = pipe.predict(X_val.loc[:,:].values)\n    err_vec_val[i] = mae(y_val, val_set_pred)","ffebeb9a":"plt.figure(figsize=(8,6))\nplt.plot(np.log10(alphalist), err_vec_val, color='#c15a3a');\n# plt.savefig('plot16.png', dpi = 300, bbox_inches = 'tight');","ccf5f8d9":"np.min(err_vec_val)","062afa71":"alphalist[np.argmin(err_vec_val)]","2749ae52":"# train  \nlm_model_lasso = Lasso(alpha = 0.01)\nlm_model_lasso.fit(X_train, y_train)\nlm_model_lasso.score(X_train, y_train)","47483ae8":"# val  \nlm_model_lasso = Lasso(alpha = 0.01)\nlm_model_lasso.fit(X_train, y_train)\nlm_model_lasso.score(X_val, y_val)","b95e6eee":"#  Test data \nlm_model_ridge = Ridge(alpha = 0.01)\nlm_model_ridge.fit(X_train, y_train)\nlm_model_ridge.score(X_test, y_test)","de7d2851":"alphalist = 10**(np.linspace(-2,2,200))\ner_vec_val = np.zeros(len(alphalist))\ner_vec_train = np.zeros(len(alphalist))\n\nfor i,curr_alpha in enumerate(alphalist):\n\n    \n    steps = [('standardize', StandardScaler()), \n             ('Lasso', Lasso(alpha = curr_alpha))]\n\n    pipe = Pipeline(steps)\n    pipe.fit(X_train.loc[:,:].values, y_train)\n    \n    val_set_pred = pipe.predict(X_val.loc[:,:].values)\n    er_vec_val[i] = mae(y_val, val_set_pred)","6e51c0d2":"plt.figure(figsize=(8,6))\nplt.plot(np.log10(alphalist), er_vec_val, color='#c15a3a');\n# plt.savefig('plot17.png', dpi = 300, bbox_inches = 'tight');","23fdf8f2":"np.min(er_vec_val)","2be38045":"alphalist[np.argmin(err_vec_val)]","7e4d0f1c":"---\n## Model Building","fc24ccc6":"---\n## Relation Between Features","1ee8a8d7":"---\n## Scaling\nscaling the features makes interpretation of regression coefficients easier","91dc6f98":"---\n## Visualize data","6274faa1":"---\n## Lasso Model","b0ddc89d":"3. Does the day of the week affect the fare?","26a22902":"---\n## Ridge Regularization","2bc5af9b":"This Code about Green trip dataset in New York City for 2 months: January and February at 2021. To do EDA and predict Fare amount using Linear Regrassion Model.\n\nThe dataset provided by nyc.gov website:\n([https:\/\/www1.nyc.gov\/site\/tlc\/about\/tlc-trip-record-data.page](https:\/\/www1.nyc.gov\/site\/tlc\/about\/tlc-trip-record-data.page))\n\n### Content:\n- Split data to: Train ,Validation, Test\n- Data Cleaning (drop columns ,drop nulls,drop dublicates, Outliers )\n- One Hot Encoding\n- Seaborn Plot\n- Matplotlib Plot\n- Machine learning (Regression Model)\n- Ridge Model\n- Lasso Model","68895684":"---\n## Feature Engineering on Time","229c8fe8":"# TLC Trip Record Data Prediction\n---","543f3393":"1. Does the number of passengers affect the fare?","f6e5b613":" day of the week doesn't seem to have that much of an influence on the number of cab rides.","a26a326e":"---\n## Data Pre-Processing","b4e4759a":"---\n## Import packages ","4263812b":"---\n## Get Dummies ","2ffb590f":"---\n## Sample data for modling","dc6291d6":"2. Does the time of pickup affect the fare?"}}