{"cell_type":{"21c841ab":"code","5e140ff5":"code","8d7d0de8":"code","205a3604":"code","211e7f33":"code","f50dca25":"code","c28b32e7":"code","1621ab3a":"code","4b6ea61b":"code","284ca7cc":"code","e898c45b":"code","44b46be2":"code","5ab1d09b":"code","44244288":"code","07b0e962":"code","c1d8585d":"code","3f73dc8b":"code","0d93534d":"markdown","8780f977":"markdown","a2383bd3":"markdown","962a77cd":"markdown","78ee08ad":"markdown","74d5805a":"markdown","eae1f721":"markdown","349177ea":"markdown","de261ea7":"markdown","8fcbb5a0":"markdown","cf433de9":"markdown"},"source":{"21c841ab":"IMG_ROWS = 480\nIMG_COLS = 320","5e140ff5":"import cv2\nimport numpy as np\nimport imageio\nfrom scipy import ndimage\nfrom glob import glob\nimport zipfile\nimport tensorflow as tf\nfrom skimage.morphology import label","8d7d0de8":"from subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\/test-segm-comp\/train\"]).decode(\"utf8\"))","205a3604":"train_img_paths = sorted(glob('..\/input\/test-segm-comp\/train\/images\/*.png'))\ntrain_mask_paths = sorted(glob('..\/input\/test-segm-comp\/train\/masks\/*.png'))","211e7f33":"train_imgs = np.array([cv2.resize(imageio.imread(path), (IMG_ROWS, IMG_COLS))\n                        for path in train_img_paths])\n\ntrain_masks = np.array([cv2.resize(imageio.imread(path), (IMG_ROWS, IMG_COLS))\n                        for path in train_mask_paths])\n\ntrain_masks = train_masks.astype(np.float32)\ntrain_masks[train_masks<=127] = 0.\ntrain_masks[train_masks>127] = 1.\ntrain_masks = np.reshape(train_masks, (*train_masks.shape, 1))\ntrain_masks = train_masks.astype(np.bool)\ntrain_imgs = train_imgs.astype(np.uint8)","f50dca25":"%matplotlib inline\nfrom matplotlib import pyplot as plt\nfig = plt.figure(0, figsize=(20, 20))\nfig.add_subplot(1, 2, 1)\nplt.imshow(train_imgs[0])\nfig.add_subplot(1, 2, 2)\nplt.imshow(np.squeeze(train_masks[0]), cmap='gray')","c28b32e7":"from keras.layers import Input\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Conv2DTranspose\nfrom keras.layers import BatchNormalization\nfrom keras.layers import concatenate\nfrom keras.models import Model","1621ab3a":"inputs = Input((IMG_COLS, IMG_ROWS, 3))\nbnorm1 = BatchNormalization()(inputs)\nconv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(bnorm1)\nconv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\npool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\nconv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\nconv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\npool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\nconv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\nconv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\npool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\nconv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\nconv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\npool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\nconv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\nconv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n\nup6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\nconv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\nconv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n\nup7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\nconv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\nconv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n\nup8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\nconv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\nconv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n\nup9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\nconv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\nconv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n\nconv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n\nmodel = Model(inputs=[inputs], outputs=[conv10])","4b6ea61b":"model.summary()","284ca7cc":"from keras import backend as K\nfrom keras.losses import binary_crossentropy\n\ndef IoUMetric(y_true, y_pred, smooth=1e-6):\n    \n    #tf.cast(y_true, tf.int32)\n    #tf.cast(y_pred, tf.int32)\n    #flatten label and prediction tensors\n    y_pred_f = K.flatten(y_pred)\n    y_true_f = K.flatten(y_true)\n    \n    intersection = K.sum(y_true_f * y_pred_f)\n    total = K.sum(y_true_f) + K.sum(y_pred_f)\n    union = total - intersection\n    \n    IoU = (intersection + smooth) \/ (union + smooth)\n    \n    return IoU\n\ndef IoULoss(y_true, y_pred, smooth=1e-6):\n    \n    #tf.cast(y_true, tf.int32)\n    #tf.cast(y_pred, tf.int32)\n    \n    #flatten label and prediction tensors\n    \n    y_pred_f = K.flatten(y_pred)\n    y_true_f = K.flatten(y_true)\n    \n    intersection = K.sum(y_true_f * y_pred_f)\n    total = K.sum(y_true_f) + K.sum(y_pred_f)\n    union = total - intersection\n    \n    IoU = (intersection + smooth) \/ (union + smooth)\n    \n    return 1 - IoU\n\ndef IoU_numpy(outputs: np.array, labels: np.array, smooth=1e-6):\n    outputs = outputs.squeeze(1)\n    \n    intersection = (outputs & labels).sum((1, 2))\n    union = (outputs | labels).sum((1, 2))\n    \n    IoU = (intersection + smooth) \/ (union + smooth)\n    \n    thresholded = np.ceil(np.clip(20 * (IoU - 0.5), 0, 10)) \/ 10\n    \n    return thresholded  # Or thresholded.mean()","e898c45b":"def iou_metric(y_true_in, y_pred_in, print_table=False):\n    labels = label(y_true_in > 0.5)\n    y_pred = label(y_pred_in > 0.5)\n    \n    true_objects = len(np.unique(labels))\n    pred_objects = len(np.unique(y_pred))\n\n    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n\n    # Compute areas (needed for finding the union between all objects)\n    area_true = np.histogram(labels, bins = true_objects)[0]\n    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n    area_true = np.expand_dims(area_true, -1)\n    area_pred = np.expand_dims(area_pred, 0)\n\n    # Compute union\n    union = area_true + area_pred - intersection\n\n    # Exclude background from the analysis\n    intersection = intersection[1:,1:]\n    union = union[1:,1:]\n    union[union == 0] = 1e-9\n\n    # Compute the intersection over union\n    iou = intersection \/ union\n\n    # Precision helper function\n    def precision_at(threshold, iou):\n        matches = iou > threshold\n        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n        return tp, fp, fn\n\n    # Loop over IoU thresholds\n    prec = []\n    if print_table:\n        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, iou)\n        if (tp + fp + fn) > 0:\n            p = tp \/ (tp + fp + fn)\n        else:\n            p = 0\n        if print_table:\n            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n        prec.append(p)\n    \n    if print_table:\n        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n    return np.mean(prec)\n\ndef iou_metric_batch(y_true_in, y_pred_in):\n    batch_size = y_true_in.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n        metric.append(value)\n    return np.array(np.mean(metric), dtype=np.float32)\n\ndef my_iou_metric(label, pred):\n    metric_value = tf.py_function(iou_metric_batch, [label, pred], tf.float32)\n    return metric_value\n\ndef my_iou_loss(label, pred):\n    metric_value = tf.py_function(iou_metric_batch, [label, pred], tf.float32)\n    iou_loss = 1- metric_value\n    return iou_loss","44b46be2":"from tensorflow.keras.optimizers import Adam\nmodel.compile(Adam(lr=1e-4),\n              binary_crossentropy,\n              metrics=[binary_crossentropy,my_iou_metric])","5ab1d09b":"model.fit(train_imgs[50:], train_masks[50:],\n          batch_size=12, epochs=20, \n          validation_data=(train_imgs[:50], train_masks[:50]))","44244288":"test_paths = sorted(glob('..\/input\/test-segm-comp\/test\/*.png'))","07b0e962":"def rle_encode(mask):\n    pixels = mask.flatten()\n    pixels[0] = 0\n    pixels[-1] = 0\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    runs[1::2] = runs[1::2] - runs[:-1:2]\n    return runs","c1d8585d":"with open('submit.txt', 'w') as dst:\n    dst.write('ImageId,EncodedPixels\\n')\n    for path in test_paths:\n        img = np.array([cv2.resize(imageio.imread(path), (IMG_ROWS, IMG_COLS))])\n        img = img.astype(np.uint8)\n        pred_mask = model.predict(img)[0]\n        bin_mask = 255. * cv2.resize(pred_mask, (imageio.imread(path).shape[0], imageio.imread(path).shape[1]))\n        bin_mask[bin_mask<=127] = 0\n        bin_mask[bin_mask>127] = 1\n        rle = rle_encode(bin_mask.astype(np.uint8))\n        rle = ' '.join(str(x) for x in rle)\n        dst.write('%s,%s\\n' % (path.split('\/')[-1].split('.')[0], rle))","3f73dc8b":"import csv\n\nwith open('..\/working\/submit.txt', 'r') as in_file:\n    stripped = (line.strip() for line in in_file)\n    lines = (line.split(\",\") for line in stripped if line)\n    with open('submission.csv', 'w') as out_file:\n        writer = csv.writer(out_file)\n        writer.writerows(lines)","0d93534d":"## \u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442","8780f977":"## \u041f\u043e\u0434\u0433\u043e\u0442\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u043e\u0442\u043f\u0440\u0430\u0432\u043a\u0438","a2383bd3":"## \u0417\u0430\u043f\u0443\u0441\u043a\u0430\u0435\u043c \u043f\u0440\u043e\u0446\u0435\u0441\u0441 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f","962a77cd":"imageio.imread(path).shape[0]","78ee08ad":"## \u0417\u0430\u0434\u0430\u0435\u043c \u0444\u0443\u043d\u043a\u0446\u0438\u044e \u043f\u043e\u0442\u0435\u0440\u044c","74d5805a":"fig = plt.figure(0, figsize=(20, 10))\nk = 5\nfig.add_subplot(2, 2, 1)\nplt.imshow(imageio.imread(test_paths[k]))\nfig.add_subplot(2, 2, 2)\nplt.imshow(np.squeeze(cv2.resize(pred[k], (TEST_IMG_ROWS, TEST_IMG_COLS))), cmap='gray')\nfig.add_subplot(2, 2, 3)\nplt.imshow(imageio.imread(test_paths[k+1]))\nfig.add_subplot(2, 2, 4)\nplt.imshow(np.squeeze(cv2.resize(pred[k+1], (TEST_IMG_ROWS, TEST_IMG_COLS))), cmap='gray')","eae1f721":"## \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438","349177ea":"from tensorflow.keras.optimizers import Adam\nimport tensorflow.keras.metrics\nmodel.compile(Adam(lr=1e-4),\n              tensorflow.keras.metrics.MeanIoU(num_classes=2),\n              metrics=[tensorflow.keras.metrics.MeanIoU(num_classes=2)])","de261ea7":"def test_img_generator(test_paths):\n    while True:\n        for path in test_paths:\n            yield np.array([cv2.resize(imageio.imread(path), (IMG_ROWS, IMG_COLS))])","8fcbb5a0":"## Flower Segmentation\n#### Image Segmentation Competition","cf433de9":"pred = model.predict_generator(test_img_generator(test_paths[:10]), len(test_paths[:10]))"}}