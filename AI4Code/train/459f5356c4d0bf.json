{"cell_type":{"83b4ebb7":"code","7ef85d34":"code","0dda5cb3":"code","6288eed8":"code","1b87f387":"code","7c3843f0":"code","a4ef7e46":"code","01e282ce":"code","15bb35c8":"code","fe58a0d5":"code","5d41fe19":"markdown","547150c7":"markdown","992645b4":"markdown","59f580f5":"markdown","343c3e05":"markdown","5117d702":"markdown","46f5871c":"markdown"},"source":{"83b4ebb7":"!python -c \"import torch; print(torch.__version__)\"\n!python -c \"import torch; print(torch.version.cuda)\"\n!pip -q install torch-spline-conv==latest+cu102 torch-scatter==latest+cu102 torch-cluster==latest+cu102 torch-sparse==latest+cu102 torch-geometric  -f https:\/\/pytorch-geometric.com\/whl\/torch-1.6.0.html\n!pip -q install torch-geometric-temporal","7ef85d34":"import math\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import ChebConv\nfrom torch_geometric.utils import to_dense_adj, dense_to_sparse\nfrom torch_geometric.nn.conv import MessagePassing\n\nfrom torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\nfrom torch_geometric_temporal.signal import temporal_signal_split\n","0dda5cb3":"loader = ChickenpoxDatasetLoader()\ndataset = loader.get_dataset()\ntrain_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)","6288eed8":"class GConvGRU(torch.nn.Module):\n    \n#------------------------------------------------------------------------init\n    def __init__( self, in_channels: int, out_channels: int, K: int,normalization: str = \"sym\",bias: bool = True ):\n        super(GConvGRU, self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.K = K\n        self.normalization = normalization\n        self.bias = bias\n        self._create_parameters_and_layers()\n\n    def _create_update_gate_parameters_and_layers(self):\n        self.conv_x_z = ChebConv(in_channels=self.in_channels,out_channels=self.out_channels, K=self.K, normalization=self.normalization, bias=self.bias)\n        self.conv_h_z = ChebConv(in_channels=self.out_channels,out_channels=self.out_channels, K=self.K, normalization=self.normalization, bias=self.bias)\n\n    def _create_reset_gate_parameters_and_layers(self):\n        self.conv_x_r = ChebConv( in_channels=self.in_channels,out_channels=self.out_channels, K=self.K,  normalization=self.normalization, bias=self.bias )\n        self.conv_h_r = ChebConv( in_channels=self.out_channels,out_channels=self.out_channels, K=self.K,  normalization=self.normalization, bias=self.bias )\n\n    def _create_candidate_state_parameters_and_layers(self):\n        self.conv_x_h = ChebConv(  in_channels=self.in_channels, out_channels=self.out_channels, K=self.K,normalization=self.normalization,bias=self.bias)\n        self.conv_h_h = ChebConv(  in_channels=self.out_channels, out_channels=self.out_channels, K=self.K,normalization=self.normalization,bias=self.bias)\n\n    def _create_parameters_and_layers(self):\n        self._create_update_gate_parameters_and_layers()\n        self._create_reset_gate_parameters_and_layers()\n        self._create_candidate_state_parameters_and_layers()\n        \n#-------------------------------------------------------------------------------------------\n    def _set_hidden_state(self, X): # step 1\n        H = torch.zeros(X.shape[0], self.out_channels).to(X.device)\n        return H\n#---------------------------------------------------\n    def _calculate_update_gate(self, X, edge_index, edge_weight, H): # step 2\n        Z = self.conv_x_z(X, edge_index, edge_weight)\n        Z = Z + self.conv_h_z(H, edge_index, edge_weight)\n        Z = torch.sigmoid(Z)\n        return Z\n#------------------------------------------------------\n    def _calculate_reset_gate(self, X, edge_index, edge_weight, H):\n        R = self.conv_x_r(X, edge_index, edge_weight)\n        R = R + self.conv_h_r(H, edge_index, edge_weight)\n        R = torch.sigmoid(R)\n        return R\n#------------------------- # Step 4\n    def _calculate_candidate_state(self, X, edge_index, edge_weight, H, R):\n        H_tilde = self.conv_x_h(X, edge_index, edge_weight)\n        H_tilde = H_tilde + self.conv_h_h(H * R, edge_index, edge_weight)\n        H_tilde = torch.tanh(H_tilde)\n        return H_tilde\n\n#-------------------------------\n    def _calculate_hidden_state(self, Z, H, H_tilde):\n        H = Z * H + (1 - Z) * H_tilde\n        return H\n\n    def forward( self, X: torch.FloatTensor, edge_index: torch.LongTensor, edge_weight: torch.FloatTensor = None) -> torch.FloatTensor:\n        H = self._set_hidden_state(X) # step 1 # X (20,4) H (20,32)\n        Z = self._calculate_update_gate(X, edge_index, edge_weight, H) # step 2 Z (20, 32)\n        R = self._calculate_reset_gate(X, edge_index, edge_weight, H) # step 3  R (20, 32)\n        H_tilde = self._calculate_candidate_state(X, edge_index, edge_weight, H, R) # step 4 H_tilde (20, 32)\n        \n        H = self._calculate_hidden_state(Z, H, H_tilde) # step 5  H (20, 32)\n        return H","1b87f387":"class DConv(MessagePassing):\n    \n#----------------------------------------- init\n    def __init__(self, in_channels, out_channels, K, bias=True):\n        super(DConv, self).__init__(aggr=\"add\", flow=\"source_to_target\")\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.weight = torch.nn.Parameter(torch.Tensor(2, K, in_channels, out_channels))  # 2, 32, 20,1 ?\n\n        if bias:\n            self.bias = torch.nn.Parameter(torch.Tensor(out_channels))\n        else:\n            self.register_parameter(\"bias\", None)\n\n        self.__reset_parameters()\n\n    def __reset_parameters(self):\n        torch.nn.init.xavier_uniform_(self.weight)\n        torch.nn.init.zeros_(self.bias)\n\n#---------------------------------------------------\n    def message(self, x_j, norm):\n        return norm.view(-1, 1) * x_j\n\n    def forward(self, X: torch.FloatTensor, edge_index: torch.LongTensor, edge_weight: torch.FloatTensor) -> torch.FloatTensor:\n        \n        adj_mat = to_dense_adj(edge_index, edge_attr=edge_weight) # create  adjacency matrix shape (1,20,20)\n        adj_mat = adj_mat.reshape(adj_mat.size(1), adj_mat.size(2)) # (20, 20)\n        deg_out = torch.matmul(\n            adj_mat, torch.ones(size=(adj_mat.size(0), 1)).to(X.device)\n        ) #  (20, 1)\n        deg_out = deg_out.flatten() # (20)\n        deg_in = torch.matmul(\n            torch.ones(size=(1, adj_mat.size(0))).to(X.device), adj_mat\n        ) # (1, 20)\n        deg_in = deg_in.flatten() # 20 \n\n        deg_out_inv = torch.reciprocal(deg_out) # receprocal of each item 2 will be 1\/2 (20)\n        deg_in_inv = torch.reciprocal(deg_in) # (20)\n        row, col = edge_index\n        \n        norm_out = deg_out_inv[row] # (102)\n        norm_in = deg_in_inv[row] # (102)\n\n        reverse_edge_index = adj_mat.transpose(0, 1) # (20,20)\n        reverse_edge_index, vv = dense_to_sparse(reverse_edge_index) #  creates sparse adjacency matrix defined by edge indices and edge attributes. # (2, 102), (102)\n\n        Tx_0 = X  # (20, 36)\n        Tx_1 = X  # (20, 36)\n        # weight is (2, 2, 36, 32) so weight[0][0] is (36, 32) \n        H = torch.matmul(Tx_0, (self.weight[0])[0]) +  torch.matmul(Tx_0, (self.weight[1])[0]) # (20, 32) # calculate the embedding of each node -> step1\n\n        # Step 2 message passing\n        if self.weight.size(1) > 1:\n            Tx_1_o = self.propagate(edge_index, x=X, norm=norm_out, size=None) # (20, 36)\n            Tx_1_i = self.propagate(reverse_edge_index, x=X, norm=norm_in, size=None) # (20, 36)\n            H = ( H  + torch.matmul(Tx_1_o, (self.weight[0])[1]) + torch.matmul(Tx_1_i, (self.weight[1])[1]) ) #(20, 32)\n            \n        #for k in range(2, self.weight.size(1)): # not true\n        #    Tx_2_o = self.propagate(edge_index, x=Tx_1_o, norm=norm_out, size=None)\n        #    Tx_2_o = 2.0 * Tx_2_o - Tx_0  # (20, 36)\n        #    Tx_2_i = self.propagate(reverse_edge_index, x=Tx_1_i, norm=norm_in, size=None)\n        #    Tx_2_i = 2.0 * Tx_2_i - Tx_0\n        #    H = (H + torch.matmul(Tx_2_o, (self.weight[0])[k]) + torch.matmul(Tx_2_i, (self.weight[1])[k]))\n        #    Tx_0, Tx_1_o, Tx_1_i = Tx_1, Tx_2_o, Tx_2_i\n\n        if self.bias is not None:\n            H += self.bias\n\n        return H","7c3843f0":"class DCRNN(torch.nn.Module):\n#----------------------------------------------------init\n    def __init__(self, in_channels: int, out_channels: int, K: int, bias: bool = True):\n        super(DCRNN, self).__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.K = K\n        self.bias = bias\n        self._create_parameters_and_layers()\n\n    def _create_update_gate_parameters_and_layers(self):\n        self.conv_x_z = DConv(in_channels=self.in_channels + self.out_channels, out_channels=self.out_channels, K=self.K, bias=self.bias)\n\n    def _create_reset_gate_parameters_and_layers(self):\n        self.conv_x_r = DConv( in_channels=self.in_channels + self.out_channels,out_channels=self.out_channels, K=self.K, bias=self.bias)\n\n    def _create_candidate_state_parameters_and_layers(self):\n        self.conv_x_h = DConv( in_channels=self.in_channels + self.out_channels, out_channels=self.out_channels, K=self.K, bias=self.bias)\n\n    def _create_parameters_and_layers(self):\n        self._create_update_gate_parameters_and_layers()\n        self._create_reset_gate_parameters_and_layers()\n        self._create_candidate_state_parameters_and_layers()\n#--------------------------------------------------------------------------\n\n    def _set_hidden_state(self, X, H): # step 1\n        if H is None:\n            H = torch.zeros(X.shape[0], self.out_channels).to(X.device)\n        return H\n\n    def _calculate_update_gate(self, X, edge_index, edge_weight, H): # step 2\n        Z = torch.cat([X, H], dim=1) # (20, 36)\n        Z = self.conv_x_z(Z, edge_index, edge_weight) # (20, 32)\n        Z = torch.sigmoid(Z)\n\n        return Z\n\n    def _calculate_reset_gate(self, X, edge_index, edge_weight, H): # step 3\n        R = torch.cat([X, H], dim=1)\n        R = self.conv_x_r(R, edge_index, edge_weight)\n        R = torch.sigmoid(R)\n        return R\n\n    def _calculate_candidate_state(self, X, edge_index, edge_weight, H, R): # step 4\n        H_tilde = torch.cat([X, H * R], dim=1)\n        H_tilde = self.conv_x_h(H_tilde, edge_index, edge_weight)\n        H_tilde = torch.tanh(H_tilde)\n        return H_tilde\n\n    def _calculate_hidden_state(self, Z, H, H_tilde): # step 5\n        H = Z * H + (1 - Z) * H_tilde\n        return H\n\n    def forward( self, X: torch.FloatTensor, edge_index: torch.LongTensor, edge_weight: torch.FloatTensor = None, H: torch.FloatTensor = None) -> torch.FloatTensor:\n        H = self._set_hidden_state(X, H)  # X(20,4) H(20, 32)\n        Z = self._calculate_update_gate(X, edge_index, edge_weight, H) # Z (20,32)\n        R = self._calculate_reset_gate(X, edge_index, edge_weight, H) # R (20,32)\n        H_tilde = self._calculate_candidate_state(X, edge_index, edge_weight, H, R) # H_tilde (20, 32)\n        H = self._calculate_hidden_state(Z, H, H_tilde) # H (20, 32)\n        return H","a4ef7e46":"class RecurrentGCN(torch.nn.Module):\n    def __init__(self, node_features, filters):\n        super(RecurrentGCN, self).__init__()\n        self.recurrent = DCRNN(node_features, filters, 2) # or use  GConvGRU(node_features, filters, 2) both will lead to similar results\n        self.linear = torch.nn.Linear(filters, 1)\n\n    def forward(self, x, edge_index, edge_weight):\n        h = self.recurrent(x, edge_index, edge_weight) # h (20, 32)\n        h = F.relu(h) # h (20, 32)\n\n        h = self.linear(h) # h (20, 1)\n        return h\n","01e282ce":"from tqdm import tqdm\n\nmodel = RecurrentGCN(node_features=4, filters=32)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","15bb35c8":"model.train()\n\nfor epoch in range(100):\n    cost = 0\n    for time, snapshot in enumerate(train_dataset):\n        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n        cost = torch.mean((y_hat-snapshot.y)**2)\n        cost.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        \n    print(\"epoch {}--cost is {}\".format(epoch, round(cost.item(),6)))\n","fe58a0d5":"model.eval()\ncost = 0\nfor time, snapshot in enumerate(test_dataset):\n    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n    cost = cost + torch.mean((y_hat-snapshot.y)**2)\ncost = cost \/ (time+1)\ncost = cost.item()\nprint(\"MSE: {:.4f}\".format(cost))","5d41fe19":"# Training","547150c7":"## DCRNN  (Diffusion Convolution RNN) \n## Another implementation of Recurrent GCN which is similar to the previous implementation; however it uses diffusion convolution\n\n\n![bbcp.jpg](attachment:a16e94cd-5d29-4469-821f-bc04c371b68b.jpg)","992645b4":"# Testing","59f580f5":"# Create the Model","343c3e05":"### Diffusion convolution message passing mechanism","5117d702":"# Loading the dataset \n\nThe dataset is described here https:\/\/paperswithcode.com\/dataset\/chickenpox-cases-in-hungary","46f5871c":"## GConvGRU ( Chebyshev Graph Convolutional Gated Recurrent Unit Cell.)\n## First implementation of a Recurrent GCN\n\n![aacp.jpg](attachment:627c921e-6370-4987-91a4-eb8f2bc10419.jpg)"}}