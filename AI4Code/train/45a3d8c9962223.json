{"cell_type":{"be1fe2f0":"code","9a204b73":"code","7dd4ec5d":"code","0335b629":"code","4fb5e511":"code","8b3a0951":"code","98089fc2":"code","42a8f984":"code","5d8ce3d3":"code","2cf4ea5b":"code","5410eb61":"code","3eab0733":"code","a693833f":"code","3f3389e5":"code","5cbfc8e7":"code","92c6b17f":"code","4b26612e":"code","b4558367":"code","98ce98fc":"code","e9eb6f51":"code","ecab4439":"code","72b6c03c":"code","a8c97dd0":"markdown","89ce79b8":"markdown","76c1b2bc":"markdown","e1419f40":"markdown","2f47714b":"markdown","b714bd41":"markdown","21e8eb7f":"markdown","a4b91570":"markdown","063e00d8":"markdown","a67da923":"markdown","8c2fe83e":"markdown","ba5cf728":"markdown","8a052723":"markdown"},"source":{"be1fe2f0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","9a204b73":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn.datasets import load_files\nimport torch.optim as optim\nimport os\nimport numpy as np\nimport time\nfrom PIL import Image\nfrom torchvision.utils import make_grid\nfrom torchvision import datasets,transforms\nfrom torch.utils.data import Dataset\nfrom torchvision.datasets import ImageFolder\nfrom torch.autograd import Variable\nimport matplotlib.pyplot as plt\nimport copy\nfrom glob import glob","7dd4ec5d":"path = '..\/input\/fruits-360_dataset\/fruits-360'","0335b629":"files_training = glob(os.path.join(path,'Training', '*\/*.jpg'))\nnum_images = len(files_training)\nprint('Number of images in Training file:', num_images)","4fb5e511":"min_images = 1000\nim_cnt = []\nclass_names = []\nprint('{:18s}'.format('class'), end='')\nprint('Count:')\nprint('-' * 24)\nfor folder in os.listdir(os.path.join(path, 'Training')):\n    folder_num = len(os.listdir(os.path.join(path,'Training',folder)))\n    im_cnt.append(folder_num)\n    class_names.append(folder)\n    print('{:20s}'.format(folder), end=' ')\n    print(folder_num)\n    if (folder_num < min_images):\n        min_images = folder_num\n        folder_name = folder\n        \nnum_classes = len(class_names)\nprint(\"\\nMinumum imgages per category:\", min_images, 'Category:', folder)    \nprint('Average number of Images per Category: {:.0f}'.format(np.array(im_cnt).mean()))\nprint('Total number of classes: {}'.format(num_classes))","8b3a0951":"tensor_transform = transforms.Compose([\n    transforms.ToTensor()\n])\n\nall_data = ImageFolder(os.path.join(path, 'Training'), tensor_transform)","98089fc2":"data_loader = torch.utils.data.DataLoader(all_data, batch_size=512, shuffle=True)","42a8f984":"pop_mean = []\npop_std = []\n\nfor i, data in enumerate(data_loader, 0):\n    numpy_image = data[0].numpy()\n    \n    batch_mean = np.mean(numpy_image, axis=(0,2,3))\n    batch_std = np.std(numpy_image, axis=(0,2,3))\n    \n    pop_mean.append(batch_mean)\n    pop_std.append(batch_std)\n\npop_mean = np.array(pop_mean).mean(axis=0)\npop_std = np.array(pop_std).mean(axis=0)","5d8ce3d3":"print(pop_mean)\nprint(pop_std)","2cf4ea5b":"np.random.seed(123)\nshuffle = np.random.permutation(num_images)","5410eb61":"split_val = int(num_images * 0.2)\nprint('Total number of images:', num_images)\nprint('Number of valid images after split:',len(shuffle[:split_val]))\nprint('Number of train images after split:',len(shuffle[split_val:]))","3eab0733":"class FruitTrainDataset(Dataset):\n    def __init__(self, files, shuffle, split_val, class_names, transform=transforms.ToTensor()):\n        self.shuffle = shuffle\n        self.class_names = class_names\n        self.split_val = split_val\n        self.data = np.array([files[i] for i in shuffle[split_val:]])\n        self.transform=transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        img = Image.open(self.data[idx])\n        name = self.data[idx].split('\/')[-2]\n        y = self.class_names.index(name)\n        img = self.transform(img)\n            \n        return img, y\n\nclass FruitValidDataset(Dataset):\n    def __init__(self, files, shuffle, split_val, class_names, transform=transforms.ToTensor()):\n        self.shuffle = shuffle\n        self.class_names = class_names\n        self.split_val = split_val\n        self.data = np.array([files[i] for i in shuffle[:split_val]])\n        self.transform=transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        img = Image.open(self.data[idx])\n        name = self.data[idx].split('\/')[-2]\n        y = self.class_names.index(name)\n        img = self.transform(img)\n            \n        return img, y\n    \nclass FruitTestDataset(Dataset):\n    def __init__(self, path, class_names, transform=transforms.ToTensor()):\n        self.class_names = class_names\n        self.data = np.array(glob(os.path.join(path, '*\/*.jpg')))\n        self.transform=transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        img = Image.open(self.data[idx])\n        name = self.data[idx].split('\/')[-2]\n        y = self.class_names.index(name)\n        img = self.transform(img)\n            \n        return img, y\n    ","a693833f":"data_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(pop_mean, pop_std) # These were the mean and standard deviations that we calculated earlier.\n    ]),\n    'Test': transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize(pop_mean, pop_std) # These were the mean and standard deviations that we calculated earlier.\n    ]),\n    'valid': transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize(pop_mean, pop_std) # These were the mean and standard deviations that we calculated earlier.\n    ])\n}\n\ntrain_dataset = FruitTrainDataset(files_training, shuffle, split_val, class_names, data_transforms['train'])\nvalid_dataset = FruitValidDataset(files_training, shuffle, split_val, class_names, data_transforms['valid'])\ntest_dataset = FruitTestDataset('..\/input\/fruits-360_dataset\/fruits-360\/Test', class_names, transform=data_transforms['Test'])\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=64, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)","3f3389e5":"### These are just used for convinience purposes\n\ndataloaders = {'train': train_loader,\n              'valid': valid_loader,\n              'Test': test_loader}\ndataset_sizes = {\n    'train': len(train_dataset),\n    'valid': len(valid_dataset),\n    'Test': len(test_dataset)\n}","5cbfc8e7":"# This allows us to see some of the fruits in each of the datasets \ndef imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    inp = pop_std * inp + pop_mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated","92c6b17f":"# Here we are just checking out the next batch of images from the train_loader, and below I print the class names. \ninputs, classes = next(iter(train_loader))\nout = make_grid(inputs)\n\ncats = ['' for x in range(len(classes))]\nfor i in range(len(classes)):\n    cats[i] = class_names[classes[i].item()]\n    \nimshow(out)\nprint(cats)","4b26612e":"class Net(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=5)\n        self.conv1_bn = nn.BatchNorm2d(16)\n        self.pool = nn.MaxPool2d(2, 2)\n        \n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3)\n        self.conv2_bn = nn.BatchNorm2d(32)\n        \n        self.conv3 = nn.Conv2d(32, 64, kernel_size=3)\n        self.conv3_bn = nn.BatchNorm2d(64)\n        \n        self.fc1 = nn.Linear(64 * 10 * 10, 250)\n        self.fc2 = nn.Linear(250, num_classes)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1_bn(self.conv1(x))))\n        x = self.pool(F.relu(self.conv2_bn(self.conv2(x))))\n        x = self.pool(F.relu(self.conv3_bn(self.conv3(x))))\n        x = x.view(-1, 64 * 10 * 10)\n        x = F.dropout(F.relu(self.fc1(x)), training=self.training, p=0.4)\n        x = self.fc2(x)\n\n        return F.log_softmax(x, dim=1) ","b4558367":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","98ce98fc":"model = Net(num_classes)\nmodel.to(device)\n\noptimizer = optim.SGD(model.parameters(), lr=0.01)\ncriterion = nn.CrossEntropyLoss()\nexp_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","e9eb6f51":"def fit(model, criterion, optimizer, scheduler, num_epochs=30):\n    since = time.time() # allows us to keep track of how long it took\n    \n    best_acc = 0.0 # allows us to store the best_acc rate (for validation stage)\n    \n    # Loop through the data-set num_epochs times.\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 15)\n        \n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                scheduler.step()\n                model.train() # This sets the model to training mode\n            else:\n                model.eval() # this sets the model to evaluation mode \n                \n            running_loss = 0.0\n            running_corrects = 0\n            \n            # using the dataloaders to load data in batches\n            for inputs, labels in dataloaders[phase]:\n                # putting the inputs and labels on cuda (gpu)\n                inputs = inputs.to(device) \n                labels = labels.to(device)\n                \n                # zero the gradient\n                optimizer.zero_grad()\n                \n                # if training phase, allow calculating the gradient, but don't allow otherwise\n                with torch.set_grad_enabled(phase == 'train'):\n                    # get outputs and predictions\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    \n                    loss = criterion(outputs, labels) # get value of loss function with the current weights \n                    \n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                        \n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n                \n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n            \n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n            \n            # keep track of the best weights for the validation dataset \n            if phase == 'valid' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n                \n        print()\n        \n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best validation Acc: {:4f}'.format(best_acc))\n    \n    model.load_state_dict(best_model_wts)\n    return model","ecab4439":"model = fit(model, criterion, optimizer, exp_scheduler, num_epochs=30)","72b6c03c":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for images, labels in dataloaders['Test']:\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the {} test images: {:.3f}%'.format(dataset_sizes['Test'], \n                                                                      100 * correct \/ dataset_sizes['Test']))","a8c97dd0":"This is my first attempt at a Kaggle Kernel. I am currently learning how to use pytorch as well. In this notebook, we will take a look at the Fruit-360 data and try to fit a neural network to classify the fruit images. I noticed that this data-set gets additional images and categories periodically, so I designed the network so that it will be able to make a proper fit regardless if the data-set has been expanded. Here we go! ","89ce79b8":"# Results:","76c1b2bc":"Okay, now on to the fun part. Below I create a class Net from scratch. The architecture of course wasn't my first attempt, but it follows the basic pattern that we typically be most successful with CNN, namely several convolutional-pooled layers followed by one or two (two in this case) fully connected layers. ","e1419f40":"So there are 95 different classes of fruit, and there are on average 515 images for each category. It looks like most categories have about the same number of fruit, so I will not worry too much about not having enough pictures in any given category. Now I will create a shuffle that will be used to split the 'Training' data into a 'train' and 'valid' set:","2f47714b":"We now need to be able to train our model, which can be done with the function bellow:","b714bd41":"We will now apply the function to train our model ","21e8eb7f":"This is a pretty decent number of images, so I think that we have enough to split these images into a 'train' and 'valid' dataset. First, lets also take a look at how many different classes of fruit there are, and how many images there are of each different type of fruit.","a4b91570":"Now real quick I will try to get an estimate of the mean of each channel from the images and an estimate of the standard deviation of the channels so I can normalize the imputs:","063e00d8":"## Defining the Network","a67da923":"Now I'm going to create some sub-classes that extends the Dataset class so I can read the data in batches. I realize now that there was probably a more efficient way of doing this, but this will get the job done. I created a subclass for loading in the train_data, valid_data, and test_data:","8c2fe83e":"Now I will define some data transformations and create the three different datasets. ","ba5cf728":"First, I want to check how many images there are in the subfolder 'Training':","8a052723":"We now create an instance of the network and run it on GPU. We also define an optimizer, loss criterion, and a scheduler. "}}