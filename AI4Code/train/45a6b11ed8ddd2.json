{"cell_type":{"b89eeefe":"code","19d04f5c":"code","13813924":"code","4b2b8462":"code","8e6e3316":"code","58c5556a":"code","b55e1ca0":"code","2f80910a":"code","58d55c1f":"code","e747b695":"code","7a67242e":"code","d71fee95":"code","4d006690":"code","aa902159":"code","dd749557":"code","bc2bf6b1":"code","12fce595":"code","6c927cd7":"code","e2ee6f32":"code","6f04015d":"code","ad33df1b":"code","1ad5f0f8":"code","06d25e08":"code","aae3a04f":"code","76222b7c":"code","8a882478":"code","9c312470":"code","0b46683e":"code","5bb90fc3":"code","abd99a6a":"code","25f9daeb":"code","a50058a4":"code","29c8155d":"code","74cbfc72":"code","588ae047":"code","5e488fea":"markdown","8a5f97df":"markdown","4aa5475a":"markdown","15698c19":"markdown","505c46eb":"markdown","8d9c8348":"markdown","5829cea7":"markdown","7b250adf":"markdown","f14814a1":"markdown","4b8381d7":"markdown","99696b14":"markdown","4b1cc378":"markdown","5c8009c7":"markdown","b6112e24":"markdown","819b7328":"markdown","18086a15":"markdown","76b6fdcc":"markdown","fcf9227f":"markdown","83473f10":"markdown","79be2d91":"markdown","ec584424":"markdown","e7d52d06":"markdown","a96d027a":"markdown","8a65bf68":"markdown","6adca67e":"markdown","abd99d05":"markdown","f0f3fa40":"markdown","c8216c14":"markdown","99e9e28f":"markdown","c849e964":"markdown","498aea0d":"markdown","7d5321d1":"markdown","918db6d5":"markdown"},"source":{"b89eeefe":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport os\nfrom subprocess import check_output\nfrom wordcloud import WordCloud, STOPWORDS","19d04f5c":"df_yout = pd.read_csv(\"..\/input\/usvideosyoutube\/USvideos.csv\")","13813924":"#Looking some information of the data\nprint(df_yout.shape)\nprint(df_yout.nunique())","4b2b8462":"#Looking for Nulls and type of our data\ndf_yout.info()","8e6e3316":"df_yout.head(n=2)","58c5556a":"df_yout['likes_log'] = np.log(df_yout['likes'] + 1)\ndf_yout['views_log'] = np.log(df_yout['views'] + 1)\ndf_yout['dislikes_log'] = np.log(df_yout['dislikes'] + 1)\ndf_yout['comment_log'] = np.log(df_yout['comment_count'] + 1)\n\nplt.figure(figsize = (12,6))\n\nplt.subplot(221)\ng1 = sns.distplot(df_yout['views_log'])\ng1.set_title(\"VIEWS LOG DISTRIBUITION\", fontsize=16)\n\nplt.subplot(224)\ng2 = sns.distplot(df_yout['likes_log'],color='green')\ng2.set_title('LIKES LOG DISTRIBUITION', fontsize=16)\n\nplt.subplot(223)\ng3 = sns.distplot(df_yout['dislikes_log'], color='r')\ng3.set_title(\"DISLIKES LOG DISTRIBUITION\", fontsize=16)\n\nplt.subplot(222)\ng4 = sns.distplot(df_yout['comment_log'])\ng4.set_title(\"COMMENTS LOG DISTRIBUITION\", fontsize=16)\n\nplt.subplots_adjust(wspace = 0.2, hspace = 0.4,top = 0.9)\n\nplt.show()","b55e1ca0":"print(\"Views quantiles\")\nprint(df_yout['views'].quantile([.01,.25,.5,.75,.99]))\nprint(\"\")\nprint(\"Likes quantiles\")\nprint(df_yout['likes'].quantile([.01,.25,.5,.75,.99]))\nprint(\"\")\nprint(\"Dislikes quantiles\")\nprint(df_yout['dislikes'].quantile([.01,.25,.5,.75,.99]))\nprint(\"\")\nprint(\"Comment quantiles\")\nprint(df_yout['comment_count'].quantile([.01,.25,.5,.75,.99]))","2f80910a":"df_yout['category_name'] = np.nan\n\ndf_yout.loc[(df_yout[\"category_id\"] == 1),\"category_name\"] = 'Film and Animation'\ndf_yout.loc[(df_yout[\"category_id\"] == 2),\"category_name\"] = 'Cars and Vehicles'\ndf_yout.loc[(df_yout[\"category_id\"] == 10),\"category_name\"] = 'Music'\ndf_yout.loc[(df_yout[\"category_id\"] == 15),\"category_name\"] = 'Pets and Animals'\ndf_yout.loc[(df_yout[\"category_id\"] == 17),\"category_name\"] = 'Sport'\ndf_yout.loc[(df_yout[\"category_id\"] == 19),\"category_name\"] = 'Travel and Events'\ndf_yout.loc[(df_yout[\"category_id\"] == 20),\"category_name\"] = 'Gaming'\ndf_yout.loc[(df_yout[\"category_id\"] == 22),\"category_name\"] = 'People and Blogs'\ndf_yout.loc[(df_yout[\"category_id\"] == 23),\"category_name\"] = 'Comedy'\ndf_yout.loc[(df_yout[\"category_id\"] == 24),\"category_name\"] = 'Entertainment'\ndf_yout.loc[(df_yout[\"category_id\"] == 25),\"category_name\"] = 'News and Politics'\ndf_yout.loc[(df_yout[\"category_id\"] == 26),\"category_name\"] = 'How to and Style'\ndf_yout.loc[(df_yout[\"category_id\"] == 27),\"category_name\"] = 'Education'\ndf_yout.loc[(df_yout[\"category_id\"] == 28),\"category_name\"] = 'Science and Technology'\ndf_yout.loc[(df_yout[\"category_id\"] == 29),\"category_name\"] = 'Non Profits and Activism'\ndf_yout.loc[(df_yout[\"category_id\"] == 25),\"category_name\"] = 'News & Politics'","58d55c1f":"print(\"Category Name count\")\nprint(df_yout.category_name.value_counts()[:5])\n\nplt.figure(figsize = (14,9))\n\nplt.subplot(211)\ng = sns.countplot('category_name', data=df_yout, palette=\"Set1\")\ng.set_xticklabels(g.get_xticklabels(),rotation=45)\ng.set_title(\"Counting the Video Category's \", fontsize=15)\ng.set_xlabel(\"\", fontsize=12)\ng.set_ylabel(\"Count\", fontsize=12)\n\nplt.subplot(212)\ng1 = sns.boxplot(x='category_name', y='views_log', data=df_yout, palette=\"Set1\")\ng1.set_xticklabels(g.get_xticklabels(),rotation=45)\ng1.set_title(\"Views Distribuition by Category Names\", fontsize=20)\ng1.set_xlabel(\"\", fontsize=15)\ng1.set_ylabel(\"Views(log)\", fontsize=15)\n\nplt.subplots_adjust(hspace = 0.9, top = 0.9)\n\nplt.show()","e747b695":"plt.figure(figsize = (14,6))\n\ng = sns.boxplot(x='category_name', y='likes_log', data=df_yout, palette=\"Set1\")\ng.set_xticklabels(g.get_xticklabels(),rotation=45)\ng.set_title(\"Likes Distribuition by Category Names \", fontsize=15)\ng.set_xlabel(\"\", fontsize=12)\ng.set_ylabel(\"Likes(log)\", fontsize=12)\nplt.show()","7a67242e":"plt.figure(figsize = (14,6))\n\ng = sns.boxplot(x='category_name', y='dislikes_log', data=df_yout, palette=\"Set1\")\ng.set_xticklabels(g.get_xticklabels(),rotation=45)\ng.set_title(\"Dislikes distribuition by Category's\", fontsize=15)\ng.set_xlabel(\"\", fontsize=12)\ng.set_ylabel(\"Dislikes(log)\", fontsize=12)\nplt.show()","d71fee95":"plt.figure(figsize = (14,6))\n\ng = sns.boxplot(x='category_name', y='comment_log', data=df_yout, palette=\"Set1\")\ng.set_xticklabels(g.get_xticklabels(),rotation=45)\ng.set_title(\"Comments Distribuition by Category Names\", fontsize=15)\ng.set_xlabel(\"\", fontsize=12)\ng.set_ylabel(\"Comments Count(log)\", fontsize=12)\n\nplt.show()","4d006690":"df_yout['like_rate'] =  df_yout ['likes'] \/ df_yout['views'] * 100\ndf_yout['dislike_rate'] =  df_yout ['dislikes'] \/ df_yout['views'] * 100\ndf_yout['comment_rate'] =  df_yout ['comment_count'] \/ df_yout['views'] * 100","aa902159":"plt.figure(figsize = (9,6))\n\ng1 = sns.distplot(df_yout['dislike_rate'], color='red',hist=False, label=\"Dislike\")\ng1 = sns.distplot(df_yout['like_rate'], color='green',hist=False, label=\"Like\")\ng1 = sns.distplot(df_yout['comment_rate'],hist=False,label=\"Comment\")\ng1.set_title('CONVERT RATE DISTRIBUITION', fontsize=16)\nplt.legend()\nplt.show()","dd749557":"plt.figure(figsize = (12,18))\n\nplt.subplot(311)\ng= sns.boxplot(x='category_name',y='like_rate',  data=df_yout)\ng.set_xticklabels(g.get_xticklabels(),rotation=45)\ng.set_title(\"LIKE RATE DISTRIBUITIONS\", fontsize=15)\ng.set_xlabel(\"\", fontsize=12)\ng.set_ylabel(\"Like rate\", fontsize=12)\n\nplt.subplot(312)\ng1= sns.boxplot(y='dislike_rate', x='category_name', data=df_yout)\ng1.set_xticklabels(g.get_xticklabels(),rotation=45)\ng1.set_title(\"DISLIKE RATE DISTRIBUITIONS\", fontsize=15)\ng1.set_xlabel(\"\", fontsize=12)\ng1.set_ylabel(\"Dislike rate\", fontsize=12)\n\nplt.subplot(313)\ng2= sns.boxplot(y='comment_rate', x='category_name', data=df_yout)\ng2.set_xticklabels(g.get_xticklabels(),rotation=45)\ng2.set_title(\"COMMENT RATE BY CATEGORY NAME\", fontsize=15)\ng2.set_xlabel(\"Category Names\", fontsize=12)\ng2.set_ylabel(\"Comment Rate\", fontsize=12)\n\nplt.subplots_adjust(wspace = 0.2, hspace = 0.5,top = 0.9)\n\nplt.show()","bc2bf6b1":"plt.figure(figsize = (14,8))\nplt.subplots_adjust(wspace = 0.2, hspace = 0.4,top = 0.9)\n\nplt.subplot(2,2,1)\ng = sns.countplot(x='comments_disabled', data=df_yout)\ng.set_title(\"Comments Disabled\", fontsize=16)\n\nplt.subplot(2,2,2)\ng1 = sns.countplot(x='ratings_disabled', data=df_yout)\ng1.set_title(\"Rating Disabled\", fontsize=16)\n\nplt.subplot(2,2,3)\ng2 = sns.countplot(x='video_error_or_removed', data=df_yout)\ng2.set_title(\"Video Error or Removed\", fontsize=16)\nplt.show()","12fce595":"plt.figure(figsize = (12,10))\n\nplt.subplot(221)\ng1 = sns.distplot(df_yout[df_yout['comments_disabled'] == True]['views_log'], \n                  hist=False, label='Comm_dis')\ng1 = sns.distplot(df_yout[df_yout['ratings_disabled'] == True]['views_log'], \n                  hist=False, label='Rati_dis')\ng1 = sns.distplot(df_yout[df_yout['video_error_or_removed'] == True]['views_log'], \n                  hist=False, label='vide_rmv_err')\ng1.set_title(\"VIEWS LOG DISTRIBUITION\", fontsize=16)\n\nplt.subplot(222)\ng4 = sns.distplot(df_yout[df_yout['comments_disabled'] == True]['comment_log'],\n                  hist=False, label='Comm_dis')\ng4 = sns.distplot(df_yout[df_yout['ratings_disabled'] == True]['comment_log'], \n                  hist=False, label='Rati_dis')\ng4 = sns.distplot(df_yout[df_yout['video_error_or_removed'] == True]['comment_log'], \n                  hist=False, label='vide_rmv_err')\ng4.set_title(\"COMMENTS LOG DISTRIBUITION\", fontsize=16)\n\nplt.subplot(223)\ng3 = sns.distplot(df_yout[df_yout['comments_disabled'] == True]['dislikes_log'], \n                  hist=False, label='Comm_dis')\ng3 = sns.distplot(df_yout[df_yout['ratings_disabled'] == True]['dislikes_log'], \n                  hist=False, label='Rati_dis')\ng3 = sns.distplot(df_yout[df_yout['video_error_or_removed'] == True]['dislikes_log'], \n                  hist=False, label='vide_rmv_err')\ng3.set_title(\"DISLIKES LOG DISTRIBUITION\", fontsize=16)\n\nplt.subplot(224)\ng2 = sns.distplot(df_yout[df_yout['comments_disabled'] == True]['likes_log'], \n                  hist=False, label='Comm_dis')\ng2 = sns.distplot(df_yout[df_yout['ratings_disabled'] == True]['likes_log'], \n                  hist=False, label='Rati_dis')\ng2 = sns.distplot(df_yout[df_yout['video_error_or_removed'] == True]['likes_log'], \n                  hist=False, label='vide_rmv_err')\ng2.set_title('LIKES LOG DISTRIBUITION', fontsize=16)\n\nplt.subplots_adjust(wspace = 0.2, hspace = 0.3,top = 0.9)\nplt.legend()\nplt.show()","6c927cd7":"plt.figure(figsize = (10,8))\n\n#Let's verify the correlation of each value\nsns.heatmap(df_yout[['like_rate', 'dislike_rate', 'comment_rate', 'comment_log',\n         'views_log','likes_log','dislikes_log', \"category_name\"]].corr(), annot=True)\nplt.show()","e2ee6f32":"#nlp\nimport string\nimport re    #for regex\nimport nltk\nfrom nltk.corpus import stopwords\nimport spacy\nfrom nltk import pos_tag\nfrom nltk.stem.wordnet import WordNetLemmatizer \nfrom nltk.tokenize import word_tokenize\n# Tweet tokenizer does not split at apostophes which is what we want\nfrom nltk.tokenize import TweetTokenizer   ","6f04015d":"#Setting the stopwords\neng_stopwords = set(stopwords.words(\"english\"))\n","ad33df1b":"#Word count in each comment:\ndf_yout['count_word']=df_yout[\"title\"].apply(lambda x: len(str(x).split()))\ndf_yout['count_word_tags']=df_yout[\"tags\"].apply(lambda x: len(str(x).split()))\n\n#Unique word count\ndf_yout['count_unique_word']=df_yout[\"title\"].apply(lambda x: len(set(str(x).split())))\ndf_yout['count_unique_word_tags']=df_yout[\"tags\"].apply(lambda x: len(set(str(x).split())))\n\n#Letter count\ndf_yout['count_letters']=df_yout[\"title\"].apply(lambda x: len(str(x)))\ndf_yout['count_letters_tags']=df_yout[\"tags\"].apply(lambda x: len(str(x)))\n\n#punctuation count\ndf_yout[\"count_punctuations\"] =df_yout[\"title\"].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\ndf_yout[\"count_punctuations_tags\"] =df_yout[\"tags\"].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n\n#upper case words count\ndf_yout[\"count_words_upper\"] = df_yout[\"title\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\ndf_yout[\"count_words_upper_tags\"] = df_yout[\"tags\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n\n#title case words count\ndf_yout[\"count_words_title\"] = df_yout[\"title\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\ndf_yout[\"count_words_title_tags\"] = df_yout[\"tags\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n\n#Number of stopwords\ndf_yout[\"count_stopwords\"] = df_yout[\"title\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\ndf_yout[\"count_stopwords_tags\"] = df_yout[\"tags\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n\n#Average length of the words\ndf_yout[\"mean_word_len\"] = df_yout[\"title\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\ndf_yout[\"mean_word_len_tags\"] = df_yout[\"tags\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))","1ad5f0f8":"#derived features\n#Word count percent in each comment:\ndf_yout['word_unique_percent']=df_yout['count_unique_word']*100\/df_yout['count_word']\ndf_yout['word_unique_percent_tags']=df_yout['count_unique_word_tags']*100\/df_yout['count_word_tags']\n\n#Punct percent in each comment:\ndf_yout['punct_percent']=df_yout['count_punctuations']*100\/df_yout['count_word']\ndf_yout['punct_percent_tags']=df_yout['count_punctuations_tags']*100\/df_yout['count_word_tags']","06d25e08":"plt.figure(figsize = (12,18))\n\nplt.subplot(421)\ng1 = sns.distplot(df_yout['count_word'], \n                  hist=False, label='Text')\ng1 = sns.distplot(df_yout['count_word_tags'], \n                  hist=False, label='Tags')\ng1.set_title(\"COUNT WORDS DISTRIBUITION\", fontsize=16)\n\nplt.subplot(422)\ng2 = sns.distplot(df_yout['count_unique_word'],\n                  hist=False, label='Text')\ng2 = sns.distplot(df_yout['count_unique_word_tags'], \n                  hist=False, label='Tags')\ng2.set_title(\"COUNT UNIQUE DISTRIBUITION\", fontsize=16)\n\nplt.subplot(423)\ng3 = sns.distplot(df_yout['count_letters'], \n                  hist=False, label='Text')\ng3 = sns.distplot(df_yout['count_letters_tags'], \n                  hist=False, label='Tags')\ng3.set_title(\"COUNT LETTERS DISTRIBUITION\", fontsize=16)\n\nplt.subplot(424)\ng4 = sns.distplot(df_yout[\"count_punctuations\"], \n                  hist=False, label='Text')\ng4 = sns.distplot(df_yout[\"count_punctuations_tags\"], \n                  hist=False, label='Tags')\ng4.set_xlim([-2,50])\ng4.set_title('COUNT PONCTUATIONS DISTRIBUITION', fontsize=16)\n\nplt.subplot(425)\ng5 = sns.distplot(df_yout[\"count_words_upper\"] , \n                  hist=False, label='Text')\ng5 = sns.distplot(df_yout[\"count_words_upper_tags\"] , \n                  hist=False, label='Tags')\ng5.set_title('COUNT WORDS UPPER DISTRIBUITION', fontsize=16)\n\nplt.subplot(426)\ng6 = sns.distplot(df_yout[\"count_words_title\"], \n                  hist=False, label='Text')\ng6 = sns.distplot(df_yout[\"count_words_title_tags\"], \n                  hist=False, label='Tags')\ng6.set_title('WORDS DISTRIBUITION', fontsize=16)\n\nplt.subplot(427)\ng7 = sns.distplot(df_yout[\"count_stopwords\"], \n                  hist=False, label='Title')\ng7 = sns.distplot(df_yout[\"count_stopwords_tags\"], \n                  hist=False, label='Tags')\ng7.set_title('STOPWORDS DISTRIBUITION', fontsize=16)\n\nplt.subplot(428)\ng8 = sns.distplot(df_yout[\"mean_word_len\"], \n                  hist=False, label='Text')\ng8 = sns.distplot(df_yout[\"mean_word_len_tags\"], \n                  hist=False, label='Tags')\ng8.set_xlim([-2,100])\ng8.set_title('MEAN WORD LEN DISTRIBUITION', fontsize=16)\n\nplt.subplots_adjust(wspace = 0.2, hspace = 0.4,top = 0.9)\nplt.legend()\nplt.show()","aae3a04f":"plt.figure(figsize = (12,8))\n\nplt.subplot(221)\ng=sns.boxplot(x='count_punctuations', y='views_log',data=df_yout)\ng.set_title(\"Vews by Ponctuations\")\ng.set_xlabel(\"Numer of Punctuations\")\ng.set_ylabel(\"Vews log\")\n\nplt.subplot(222)\ng1 = sns.boxplot(x='count_punctuations', y='likes_log',data=df_yout)\ng1.set_title(\"Likes by Ponctuations\")\ng1.set_xlabel(\"Numer of Punctuations\")\ng1.set_ylabel(\"Likes log\")\n\nplt.subplot(223)\ng2 = sns.boxplot(x='count_punctuations', y='dislikes_log',data=df_yout)\ng2.set_title(\"Dislikes by Ponctuations\")\ng2.set_xlabel(\"Numer of Punctuations\")\ng2.set_ylabel(\"Dislikes log\")\n\nplt.subplot(224)\ng3 = sns.boxplot(x='count_punctuations', y='comment_log',data=df_yout)\ng3.set_title(\"Comments by Ponctuations\")\ng3.set_xlabel(\"Numer of Punctuations\")\ng3.set_ylabel(\"Comments log\")\n\nplt.subplots_adjust(wspace = 0.2, hspace = 0.4,top = 0.9)\n\nplt.show()","76222b7c":"plt.figure(figsize = (12,8))\n\nplt.subplot(221)\ng=sns.boxplot(x='count_punctuations_tags', y='views_log',data=df_yout[df_yout['count_punctuations_tags'] < 20])\ng.set_title(\"Vews by Ponctuations tags\")\ng.set_xlabel(\"Numer of Tag Punctuations\")\ng.set_ylabel(\"Vews log\")\n\nplt.subplot(222)\ng1 = sns.boxplot(x='count_punctuations_tags', y='likes_log',data=df_yout[df_yout['count_punctuations_tags'] < 20])\ng1.set_title(\"Likes by Ponctuations tags\")\ng1.set_xlabel(\"Numer of Tag Punctuations\")\ng1.set_ylabel(\"Likes log\")\n\nplt.subplot(223)\ng2 = sns.boxplot(x='count_punctuations_tags', y='dislikes_log',data=df_yout[df_yout['count_punctuations_tags'] < 20])\ng2.set_title(\"Dislikes by Ponctuations tagsss\")\ng2.set_xlabel(\"Numer of Tag Punctuations\")\ng2.set_ylabel(\"Dislikes log\")\n\nplt.subplot(224)\ng3 = sns.boxplot(x='count_punctuations_tags', y='comment_log',data=df_yout[df_yout['count_punctuations_tags'] < 20])\ng3.set_title(\"Comments by Ponctuations tags\")\ng3.set_xlabel(\"Numer of Tag Punctuations\")\ng3.set_ylabel(\"Comments log\")\n\nplt.subplots_adjust(wspace = 0.2, hspace = 0.4,top = 0.9)\n\nplt.show()","8a882478":"plt.figure(figsize = (12,8))\n\nsns.heatmap(df_yout[['count_word', 'count_unique_word','count_letters',\n                     \"count_punctuations\",\"count_words_upper\", \"count_words_title\", \n                     \"count_stopwords\",\"mean_word_len\", \n                     'views_log', 'likes_log','dislikes_log','comment_log',\n                     'ratings_disabled', 'comments_disabled', 'video_error_or_removed']].corr(), annot=True)\nplt.show()","9c312470":"mpl.rcParams['font.size']= 15              \nmpl.rcParams['savefig.dpi']= 100         \nmpl.rcParams['figure.subplot.bottom']= .1 ","0b46683e":"plt.figure(figsize = (15,15))\n\nstopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(\n                          background_color='black',\n                          stopwords=stopwords,\n                          max_words=1000,\n                          max_font_size=120, \n                          random_state=42\n                         ).generate(str(df_yout['title']))\n\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.title(\"WORD CLOUD - TITLES\")\nplt.axis('off')\nplt.show()","5bb90fc3":"plt.figure(figsize = (15,15))\n\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(\n                          background_color='black',\n                          stopwords=stopwords,\n                          max_words=150,\n                          max_font_size=40, \n                          random_state=42\n                         ).generate(str(df_yout['title']))\n\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.title(\"WORD CLOUD - DESCRIPTION\")\nplt.axis('off')\nplt.show()","abd99a6a":"plt.figure(figsize = (15,15))\n\nstopwords = set(STOPWORDS)\n\nnewStopWords= ['https', 'youtube', 'VIDEO','youtu','CHANNEL', 'WATCH']\n\nstopwords.update(newStopWords)\n\nwordcloud = WordCloud(\n                          background_color='black',\n                          stopwords=stopwords,\n                          max_words=1200,\n                          max_font_size=80, \n                          random_state=42\n                         ).generate(str(df_yout['description']))\n\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.title(\"WORD CLOUD - DESCRIPTION\")\nplt.axis('off')\nplt.show()\n","25f9daeb":"plt.figure(figsize = (15,15))\n\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(\n                          background_color='black',\n                          stopwords=stopwords,\n                          max_words=1200,\n                          max_font_size=120, \n                          random_state=42\n                         ).generate(str(df_yout['tags']))\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.title(\"WORD CLOUD - TAGS\")\nplt.axis('off')\nplt.show()","a50058a4":"df_yout['publish_time'] = pd.to_datetime(df_yout['publish_time'], format='%Y-%m-%dT%H:%M:%S.%fZ')","29c8155d":"df_yout['month'] = df_yout['publish_time'].dt.month\n\nprint(\"Category Name count\")\nprint(df_yout['month'].value_counts()[:5])\n\nplt.figure(figsize = (14,9))\n\nplt.subplot(211)\ng = sns.countplot('month', data=df_yout, palette=\"Set1\")\ng.set_xticklabels(g.get_xticklabels(),rotation=45)\ng.set_title(\"Counting Months \", fontsize=20)\ng.set_xlabel(\"Months\", fontsize=15)\ng.set_ylabel(\"Count\", fontsize=15)\n\nplt.subplot(212)\ng1 = sns.lvplot(x='month', y='like_rate', data=df_yout, palette=\"Set1\")\ng1.set_xticklabels(g.get_xticklabels(),rotation=45)\ng1.set_title(\"Like Rate by Month\", fontsize=20)\ng1.set_xlabel(\"Months\", fontsize=15)\ng1.set_ylabel(\"Like Rate(log)\", fontsize=15)\n\nplt.subplots_adjust(hspace = 0.5, top = 0.9)\n\nplt.show()","74cbfc72":"# separates date and time into two columns from 'publish_time' column\ndf_yout.insert(4, 'publish_date', df_yout['publish_time'].dt.date)\ndf_yout['publish_time'] = df_yout['publish_time'].dt.time\ndf_yout[['hour','min','sec']] = df_yout['publish_time'].astype(str).str.split(':', expand=True).astype(int)","588ae047":"print(\"TOP 5 Hour values\")\nprint(df_yout['hour'].value_counts()[:5])\n\nplt.figure(figsize = (14,9))\n\nplt.subplot(211)\ng = sns.countplot('hour', data=df_yout, palette=\"Set1\")\ng.set_xticklabels(g.get_xticklabels(),rotation=45)\ng.set_title(\"Counting Hour \", fontsize=20)\ng.set_xlabel(\"Hours\", fontsize=15)\ng.set_ylabel(\"Count\", fontsize=15)\n\nplt.subplot(212)\ng1 = sns.lvplot(x='hour', y='like_rate', data=df_yout, palette=\"Set1\")\ng1.set_xticklabels(g.get_xticklabels(),rotation=45)\ng1.set_title(\"Like Rate by Hour\", fontsize=20)\ng1.set_xlabel(\"Hours\", fontsize=15)\ng1.set_ylabel(\"Like Rate(log)\", fontsize=15)\n\nplt.subplots_adjust(hspace = 0.5, top = 0.9)\n\nplt.show()","5e488fea":"<h3>Rating Disabled<\/h3>","8a5f97df":"<h1>Hi, welcome to my Kernel. <\/h1>\n","4aa5475a":"<h2>Looking through the anothers categoricals variables <\/h2>\nWe have the variables:\n- Comments Disable\n- Rating disable\n- Video error\n","15698c19":"<h2>Have the Punctuations title and tags any relation with views, likes, dislikes comments? <\/h2>","505c46eb":"<h1>Engagement Features <\/h1>","8d9c8348":"<h2>Analysing the Correlation Matrix of the numerical variables<\/h2>","5829cea7":"<h2>The same view using Tags punctuations values<\/h2>","7b250adf":"Very meaningful distribuition! Like x Dislikes rate have interesting differences","f14814a1":"<h2>Looking the Views, likes, dislikes distribuition by category_name's<\/h2>","4b8381d7":"# Votesup and stay Tuned because I will continue this analysis","99696b14":"Significant number of politics and news videos.\n\nThe unique difference is in Non Profits and Activism videos that have less views than the \"normal\" videos\n","4b1cc378":"## Let's extract the hour value of datetime'","5c8009c7":"<h2>Looking the Views, likes, dislikes distribuition by category_name's<\/h2>","b6112e24":"<h1>Visualizing  the Word Cloud of Tagged videos <\/h1>\n- Ratings Disable \n- Comments Disable\n- Video Error or Removed","819b7328":"<i>English is not my first language, so sorry about any error.<\/i>","18086a15":"<h1>Visualizing the WordCloud of Description<\/h1>","76b6fdcc":"## Knowning the Hour feature","fcf9227f":"<h2>Importing librarys and data<\/h2>","83473f10":"<h3>Comments Disabled<\/h3>","79be2d91":"I will create some new variables to us analyse the percent of likes, dislikes, comment by each category to discover what category have the highest engagement","ec584424":"Very interesting distribuition by hour","e7d52d06":"<h2>General Title Word Cloud<\/h2>","a96d027a":"I will analyse the youtube data to undersand the US videos patterns.\n\nWe will find for some informations like:\n\n- Whats the most frequent type of video?\n- The distribuition of views, likes, comments and engamet is equal for all category's?\n- We have normal distribuition to the values?\n- Whats the most frequent names in title, description, tags? \n","8a65bf68":"<h2>Let's verify the correlation of title and tags values with views<\/h2>\n- exploring the Correlation matrix to see if have any interesting relation","6adca67e":"<h2>Let's look the kde of this variables separated to deep understand them<\/h2>","abd99d05":"<h1>Analysing the Wordcloud of Tags<\/h1>","f0f3fa40":"We can see that the Dislike rate is very low in almost all categories but some outliers in 'People and Blogs' and News & Politics that we can might can consider \"Normal\"\n\nThe mean of ike distribuition is less than 5% but in music we have a very interesting pattern of like rate... The music category have the highest engagement rate.\n\nAnd at the Comment rate we can see the how-to category with the highest rates of commments. Interesting because isn't politics LOL","c8216c14":"Give me your feedback and if you like my kernel <b>votes up<\/b>","99e9e28f":"News and Politics have a the same of Non Profits of engagement likes","c849e964":"<h2>I will start creating some features from texts using Title and Tags columns<\/h2>","498aea0d":"Removed videos no have some views until be moreved... <br>Rating disable and Comments disable have the same distribuition ","7d5321d1":"<h2>Let's start looking if Views, likes, dislikes and comment counts have a normal distribuition<\/h2>","918db6d5":"I will continue implementing this analysis because I want learn about text data! <br>\n\nThank you very much for your view and <b> votes up<\/b> my kernel "}}