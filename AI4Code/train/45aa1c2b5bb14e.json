{"cell_type":{"532649e7":"code","a9a7b53b":"code","92aa90b4":"code","0755c752":"code","3faf2685":"code","2bae6255":"code","838e7a28":"code","7808d5b5":"code","a8832ee9":"code","393fb885":"code","3fcd8151":"code","cced232f":"code","4e2e66f0":"code","cada252e":"code","8b014d4b":"markdown","4279951a":"markdown","adc3412d":"markdown","d79e1b23":"markdown","818357e3":"markdown","601b58fb":"markdown","2660488a":"markdown","399ec0ab":"markdown","61fe5915":"markdown","4d346109":"markdown","d4b4b153":"markdown","9ffd305e":"markdown","106b1b78":"markdown","b8c3f576":"markdown","dc06344b":"markdown","d4ee1bbf":"markdown","d68d488e":"markdown","b6a43eff":"markdown","253afea3":"markdown","d458913a":"markdown","8a260f54":"markdown","f85fa82d":"markdown","b35e4390":"markdown","fb6199db":"markdown","e06848a7":"markdown","d800a62c":"markdown","99729f8b":"markdown","641b4032":"markdown","82d60dca":"markdown"},"source":{"532649e7":"import pandas as pd\nimport numpy as np\nimport datetime as dt\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix\nimport sklearn.metrics as mt\nfrom plotly import tools\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n \ndf1 = pd.read_csv('..\/input\/Womens Clothing E-Commerce Reviews.csv')\ndf = df1[['Review Text','Rating','Class Name','Age']]\n#df1.info()\n#df1.describe()\ndf1.head()","a9a7b53b":"# fill NA values by space\ndf['Review Text'] = df['Review Text'].fillna('')\n\n# CountVectorizer() converts a collection \n# of text documents to a matrix of token counts\nvectorizer = CountVectorizer()\n# assign a shorter name for the analyze\n# which tokenizes the string\nanalyzer = vectorizer.build_analyzer()\n\ndef wordcounts(s):\n    c = {}\n    # tokenize the string and continue, if it is not empty\n    if analyzer(s):\n        d = {}\n        # find counts of the vocabularies and transform to array \n        w = vectorizer.fit_transform([s]).toarray()\n        # vocabulary and index (index of w)\n        vc = vectorizer.vocabulary_\n        # items() transforms the dictionary's (word, index) tuple pairs\n        for k,v in vc.items():\n            d[v]=k # d -> index:word \n        for index,i in enumerate(w[0]):\n            c[d[index]] = i # c -> word:count\n    return  c\n\n# add new column to the dataframe\ndf['Word Counts'] = df['Review Text'].apply(wordcounts)\ndf.head()","92aa90b4":"# selecting some words to examine detailed \nselectedwords = ['awesome','great','fantastic','extraordinary','amazing','super',\n                 'magnificent','stunning','impressive','wonderful','breathtaking',\n                 'love','content','pleased','happy','glad','satisfied','lucky',\n                 'shocking','cheerful','wow','sad','unhappy','horrible','regret',\n                 'bad','terrible','annoyed','disappointed','upset','awful','hate']\n\ndef selectedcount(dic,word):\n    if word in dic:\n        return dic[word]\n    else:\n        return 0\n    \ndfwc = df.copy()  \nfor word in selectedwords:\n    dfwc[word] = dfwc['Word Counts'].apply(selectedcount,args=(word,))\n    \nword_sum = dfwc[selectedwords].sum()\nprint('Selected Words')\nprint(word_sum.sort_values(ascending=False).iloc[:5])\n\nprint('\\nClass Names')\nprint(df['Class Name'].fillna(\"Empty\").value_counts().iloc[:5])\n\nfig, ax = plt.subplots(1,2,figsize=(20,10))\nwc0 = WordCloud(background_color='white',\n                      width=450,\n                      height=400 ).generate_from_frequencies(word_sum)\n\ncn = df['Class Name'].fillna(\" \").value_counts()\nwc1 = WordCloud(background_color='white',\n                      width=450,\n                      height=400 \n                     ).generate_from_frequencies(cn)\n\nax[0].imshow(wc0)\nax[0].set_title('Selected Words\\n',size=25)\nax[0].axis('off')\n\nax[1].imshow(wc1)\nax[1].set_title('Class Names\\n',size=25)\nax[1].axis('off')\n\nrt = df['Review Text']\nplt.subplots(figsize=(18,6))\nwordcloud = WordCloud(background_color='white',\n                      width=900,\n                      height=300\n                     ).generate(\" \".join(rt))\nplt.imshow(wordcloud)\nplt.title('All Words in the Reviews\\n',size=25)\nplt.axis('off')\nplt.show()","0755c752":"df1=df['Rating'].value_counts().to_frame()\navgdf1 = df.groupby('Class Name').agg({'Rating': np.average})\navgdf2 = df.groupby('Class Name').agg({'Age': np.average})\navgdf3 = df.groupby('Rating').agg({'Age': np.average})\n\ntrace1 = go.Bar(\n    x=avgdf1.index,\n    y=round(avgdf1['Rating'],2),\n    marker=dict(\n        color=avgdf1['Rating'],\n        colorscale = 'RdBu')\n)\n\ntrace2 = go.Bar(\n    x=df1.index,\n    y=df1.Rating,\n    marker=dict(\n        color=df1['Rating'],\n        colorscale = 'RdBu')\n)\n\ntrace3 = go.Bar(\n    x=avgdf2.index,\n    y=round(avgdf2['Age'],2),\n    marker=dict(\n        color=avgdf2['Age'],\n        colorscale = 'RdBu')\n)\n\ntrace4 = go.Bar(\n    x=avgdf3.index,\n    y=round(avgdf3['Age'],2),\n    marker=dict(\n        color=avgdf3['Age'],\n        colorscale = 'Reds')\n)\n\nfig = tools.make_subplots(rows=2, cols=2, print_grid=False)\n\nfig.append_trace(trace1, 1, 1)\nfig.append_trace(trace2, 1, 2)\nfig.append_trace(trace3, 2, 1)\nfig.append_trace(trace4, 2, 2)\n\nfig['layout']['xaxis1'].update(title='Class')\nfig['layout']['yaxis1'].update(title='Average Rating')\nfig['layout']['xaxis2'].update(title='Rating')\nfig['layout']['yaxis2'].update(title='Count')\nfig['layout']['xaxis3'].update(title='Class')\nfig['layout']['yaxis3'].update(title='Average Age of the Reviewers')\nfig['layout']['xaxis4'].update(title='Rating')\nfig['layout']['yaxis4'].update(title='Average Age of the Reviewers')\n\nfig['layout'].update(height=800, width=900,showlegend=False)\nfig.update_layout({'plot_bgcolor':'rgba(0,0,0,0)',\n                   'paper_bgcolor':'rgba(0,0,0,0)'})\n#fig['layout'].update(plot_bgcolor='rgba(0,0,0,0)')\n#fig['layout'].update(paper_bgcolor='rgba(0,0,0,0)')\npy.iplot(fig)","3faf2685":"cv = df['Class Name'].value_counts()\n\ntrace = go.Scatter3d( x = avgdf1.index,\n                      y = avgdf1['Rating'],\n                      z = cv[avgdf1.index],\n                      mode = 'markers',\n                      marker = dict(size=10,color=avgdf1['Rating']),\n                      hoverinfo =\"text\",\n                      text=\"Class: \"+avgdf1.index+\" \\ Average Rating: \"+avgdf1['Rating'].map(' {:,.2f}'.format).apply(str)+\" \\ Number of Reviewers: \"+cv[avgdf1.index].apply(str)\n                      )\n\ndata = [trace]\nlayout = go.Layout(title=\"Average Rating & Class & Number of Reviewers\",\n                   scene = dict(\n                    xaxis = dict(title='Class'),\n                    yaxis = dict(title='Average Rating'),\n                    zaxis = dict(title='Number of Sales'),),\n                   margin = dict(l=30, r=30, b=30, t=30))\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)\nplt.savefig('3D_Scatter.png')","2bae6255":"# Rating of 4 or higher -> positive, while the ones with \n# Rating of 2 or lower -> negative \n# Rating of 3 -> neutral\ndf = df[df['Rating'] != 3]\ndf['Sentiment'] = df['Rating'] >=4\ndf.head()\n\n# split data\ntrain_data,test_data = train_test_split(df,train_size=0.8,random_state=0)\n# select the columns and \n# prepare data for the models \nX_train = vectorizer.fit_transform(train_data['Review Text'])\ny_train = train_data['Sentiment']\nX_test = vectorizer.transform(test_data['Review Text'])\ny_test = test_data['Sentiment']","838e7a28":"start=dt.datetime.now()\nlr = LogisticRegression()\nlr.fit(X_train,y_train)\nprint('Elapsed time: ',str(dt.datetime.now()-start))","7808d5b5":"start=dt.datetime.now()\nnb = MultinomialNB()\nnb.fit(X_train,y_train)\nprint('Elapsed time: ',str(dt.datetime.now()-start))","a8832ee9":"start=dt.datetime.now()\nsvm = SVC()\nsvm.fit(X_train,y_train)\nprint('Elapsed time: ',str(dt.datetime.now()-start))","393fb885":"start=dt.datetime.now()\nnn = MLPClassifier()\nnn.fit(X_train,y_train)\nprint('Elapsed time: ',str(dt.datetime.now()-start))","3fcd8151":"# define a dataframe for the prediction probablities of the models\n#df1 = train_data.copy()\n#df1['Logistic Regression'] = lr.predict_proba(X_train)[:,1]\n#df1['Naive Bayes'] = nb.predict_proba(X_train)[:,1]\n#df1['SVM'] = svm.decision_function(X_train)\n#df1['Neural Network'] = nn.predict_proba(X_train)[:,1]\n#df1=df1.round(2)\n#df1.head()\n\n# define a dataframe for the predictions\ndf2 = train_data.copy()\ndf2['Logistic Regression'] = lr.predict(X_train)\ndf2['Naive Bayes'] = nb.predict(X_train)\ndf2['SVM'] = svm.predict(X_train)\ndf2['Neural Network'] = nn.predict(X_train)\ndf2.head()","cced232f":"pred_lr = lr.predict_proba(X_test)[:,1]\nfpr_lr,tpr_lr,_ = roc_curve(y_test,pred_lr)\nroc_auc_lr = auc(fpr_lr,tpr_lr)\n\npred_nb = nb.predict_proba(X_test)[:,1]\nfpr_nb,tpr_nb,_ = roc_curve(y_test.values,pred_nb)\nroc_auc_nb = auc(fpr_nb,tpr_nb)\n\npred_svm = svm.decision_function(X_test)\nfpr_svm,tpr_svm,_ = roc_curve(y_test.values,pred_svm)\nroc_auc_svm = auc(fpr_svm,tpr_svm)\n\npred_nn = nn.predict_proba(X_test)[:,1]\nfpr_nn,tpr_nn,_ = roc_curve(y_test.values,pred_nn)\nroc_auc_nn = auc(fpr_nn,tpr_nn)\n\nf, axes = plt.subplots(2, 2,figsize=(15,10))\naxes[0,0].plot(fpr_lr, tpr_lr, color='darkred', lw=2, label='ROC curve (area = {:0.2f})'.format(roc_auc_lr))\naxes[0,0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\naxes[0,0].set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05])\naxes[0,0].set(xlabel ='False Positive Rate', ylabel = 'True Positive Rate', title = 'Logistic Regression')\naxes[0,0].legend(loc='lower right', fontsize=13)\n\naxes[0,1].plot(fpr_nb, tpr_nb, color='darkred', lw=2, label='ROC curve (area = {:0.2f})'.format(roc_auc_nb))\naxes[0,1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\naxes[0,1].set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05])\naxes[0,1].set(xlabel ='False Positive Rate', ylabel = 'True Positive Rate', title = 'Naive Bayes')\naxes[0,1].legend(loc='lower right', fontsize=13)\n\naxes[1,0].plot(fpr_svm, tpr_svm, color='darkred', lw=2, label='ROC curve (area = {:0.2f})'.format(roc_auc_svm))\naxes[1,0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\naxes[1,0].set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05])\naxes[1,0].set(xlabel ='False Positive Rate', ylabel = 'True Positive Rate', title = 'Support Vector Machine')\naxes[1,0].legend(loc='lower right', fontsize=13)\n\naxes[1,1].plot(fpr_nn, tpr_nn, color='darkred', lw=2, label='ROC curve (area = {:0.2f})'.format(roc_auc_nn))\naxes[1,1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\naxes[1,1].set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05])\naxes[1,1].set(xlabel ='False Positive Rate', ylabel = 'True Positive Rate', title = 'Neural Network')\naxes[1,1].legend(loc='lower right', fontsize=13);","4e2e66f0":"# preparation for the confusion matrix\nlr_cm=confusion_matrix(y_test.values, lr.predict(X_test))\nnb_cm=confusion_matrix(y_test.values, nb.predict(X_test))\nsvm_cm=confusion_matrix(y_test.values, svm.predict(X_test))\nnn_cm=confusion_matrix(y_test.values, nn.predict(X_test))\n\nplt.figure(figsize=(15,12))\nplt.suptitle(\"Confusion Matrices\",fontsize=24)\n\nplt.subplot(2,2,1)\nplt.title(\"Logistic Regression\")\nsns.heatmap(lr_cm, annot = True, cmap=\"Greens\",cbar=False);\n\nplt.subplot(2,2,2)\nplt.title(\"Naive Bayes\")\nsns.heatmap(nb_cm, annot = True, cmap=\"Greens\",cbar=False);\n\nplt.subplot(2,2,3)\nplt.title(\"Support Vector Machine (SVM)\")\nsns.heatmap(svm_cm, annot = True, cmap=\"Greens\",cbar=False);\n\nplt.subplot(2,2,4)\nplt.title(\"Neural Network\")\nsns.heatmap(nn_cm, annot = True, cmap=\"Greens\",cbar=False);","cada252e":"print(\"Logistic Regression\")\nprint(mt.classification_report(y_test, lr.predict(X_test)))\nprint(\"\\n Naive Bayes\")\nprint(mt.classification_report(y_test, nb.predict(X_test)))\nprint(\"\\n Support Vector Machine (SVM)\")\nprint(mt.classification_report(y_test, svm.predict(X_test)))\nprint(\"\\n Neural Network\")\nprint(mt.classification_report(y_test, nn.predict(X_test)))","8b014d4b":"In order to make some analysis, we need to set our environment up. To do this, I firstly imported some modules and read the data. The below output is the head of the data but if you want to see more details, you might try removing ***#*** signs in front of the ***df.describe()*** and ***df.info()***.  \n\nFurther, I decided that I do not need some columns and defined a new dataset which just has the columns I used. ","4279951a":"# <span id=\"1\"><\/span> Overview\n<hr\/>\nWelcome to my Kernel! In this kernel, I use various methods and try to predict the customer sentiment from reviews. As you can guess, there are various methods to suceed this and each method has pros and cons. I think **Naive Bayes is one of the most important methods in text mining because it is the fastest**. However, if we do not have a very large dataset or have high CPU power, the others might be useful too. \n\nHere, I started with examining the data and use some charts to reach more insights. Afterwards, I applied different models and compared them from various aspects.\n\nIf you have a question or feedback, do not hesitate to write and if you like this kernel, please <b><font color=\"red\">do not forget to <\/font><font color=\"green\">UPVOTE <\/font><\/b> \ud83d\ude42 \n<br\/>\n<img src=\"https:\/\/i.imgur.com\/1tHbhZ4.jpg\" title=\"source: imgur.com\"\/>","adc3412d":"# <span id=\"11\"><\/span> Evaluating Models\n#### [Return Contents](#0)\n<hr\/>","d79e1b23":"# <span id=\"4\"><\/span>  Demonstrating the Densities of Class Names, Some Selected Words and All Words in the Reviews By Using WordCloud \n#### [Return Contents](#0)\n<hr\/>","818357e3":"Adding the word counts to a dataframe is a very good practice because we might use these counts to reach some useful information. To do this, I defined the function ***wordcounts***.","601b58fb":"It seems that most of the ratings are positive and the average rating between the classes looks close. On the other hand, when we look at ages, average age does not change significantly according to the rating. Also, average age changes slightly between class names except casual bottoms. We can disregard casual bottoms because the below chart shows that there are just two reviews and making an inference will not be right.","2660488a":"## <span id=\"14\"><\/span> Confusion Matrices","399ec0ab":"In this section, I demonstrated the word densities which can be very informative. First, I selected some words which show the customer sentiments like love, hate, fantastic or regret. Second, since we do not know the product names, I decided to check the product class names. By doing this, we may at least learn the most prefered classes. Further, I thought that looking at the densities of all words in the reviews might be interesting. Lastly, I used the *WordCloud* module and printed the first five lines of the tables which shows the word counts for the selected words and the class names. \n\nIt can be observed from the below figures and tables that positive words as love, great, super were used more. When we look at the classes, customers mostly prefered dress, knits and blouses. We may also see that dress and love are in the freequently used words within all reviews. ","61fe5915":"## <span id=\"12\"><\/span> Adding Results to the Dataframe","4d346109":"I started my evaluation with ROC curve and AUC. As you may observe below, results look pretty good but it does not give much insight. To decide which model is the best we must also examine other evaluation metrics.","d4b4b153":"# <span id=\"16\"><\/span> Conclusion\n#### [Return Contents](#0)\n<hr\/>","9ffd305e":"# <span id=\"2\"><\/span> Importing Modules and Reading the Dataset\n#### [Return Contents](#0)\n<hr\/>","106b1b78":"## <span id=\"9\"><\/span> Support Vector Machine (SVM)","b8c3f576":"Since we do not have a column which shows the sentiment as positive or negative in the dataset, I defined a new sentiment column. To do this, I assumed the reviews which has **4 or higher ** rating as **positive (True in the new dataframe)** and **2 or lower** rating as **negative (False in the new dataframe)**. Also, I did not include the lines that has **neutral** ratings which are equal to **3**. Following that, I splitted the data as training and test sets.","dc06344b":"Last but not least, I examined *Precision*, *Recall* and *F1-score*. They are defined as\n\n$$\\textbf{Precision} = \\dfrac{TP}{TP + FP} \\;\\;\\;\\;\\;\\;\\;\\;\\;\\; \\textbf{Recall} = \\dfrac{TP}{TP + FN}$$\n\n\n$$\\textbf{}$$\n\n\n$$\\textbf{F}_{1} = 2 \\; \\dfrac{Precision \\; \\times \\;Recall}{Precision + Recall} = \\dfrac{2 \\; TP}{2 \\; TP + FN + FP}$$ \n\nWe have already examined ROC curves and confusion matrices but this is not enough for a final decision. In our case precision might be the best choice to evaluate our models beacause we want to determine negative comments with less mistakes (To compare precisions, we must look at the precision values for *True*.). However, if we predict positive comments false, it will not have a negative impact. Of course for some other purposes other evaluation metrics may be useful too.","d4ee1bbf":"Then, I fitted the models one by one. Since, some of them take too much time, running each of them in different cells is a better choice.   ","d68d488e":"## <span id=\"8\"><\/span> Naive Bayes","b6a43eff":"I thought that examining the relation between the rating, class names and age might be good because some age groups may always give low ratings or make negative reviews or prefer the products in the same class. To examine this relationship, I used the below dynamic charts. ","253afea3":"## <span id=\"7\"><\/span> Logistic Regression","d458913a":" # <span id=\"6\"><\/span> Building a Sentiment Classifier\n#### [Return Contents](#0)\n<hr\/>","8a260f54":"# <span id=\"3\"><\/span> Adding the Word Counts to the Dataframe and Finding out How Many Times Some Words Were Used \n#### [Return Contents](#0)\n<hr\/>","f85fa82d":"## <span id=\"13\"><\/span> ROC Curves and AUC","b35e4390":"<hr\/>\n# **Predicting Sentiment from Clothing Reviews**\n\n[**Burhan Y. Kiyakoglu**](https:\/\/www.kaggle.com\/burhanykiyakoglu)\n<hr\/>\n<span id=\"0\"><\/span>\n<font color=green>\n1. [Overview](#1)\n1. [Importing Modules and Reading the Dataset](#2)\n1. [Adding the Word Counts to the Dataframe and Finding out How Many Times Some Words Were Used ](#3)\n1. [Demonstrating the Densities of Class Names, Some Selected Words and All Words in the Reviews By Using WordCloud](#4)\n1. [Viewing the Relation Between Ratings, Class Names and Age](#5)\n1. [Building a Sentiment Classifier](#6)\n   * [Logistic Regression ](#7)\n   * [Naive Bayes](#8)\n   * [Support Vector Machine (SVM)](#9)\n   * [Neural Network](#10)\n1. [Evaluating Models](#11) \n   * [Adding Results to the Dataframe](#12)\n   * [ROC Curves and AUC](#13)\n   * [Confusion Matrices](#14)\n   * [Precision - Recall - F1-Score](#15)\n1. [Conclusion](#16) ","fb6199db":"At first, I added the prediction results to my training data. However, if you want to observe the prediction probabilies, you might use the commented out code.","e06848a7":"## <span id=\"10\"><\/span> Neural Network","d800a62c":"## <span id=\"15\"><\/span> Precision - Recall - F1-Score","99729f8b":" # <span id=\"5\"><\/span> Viewing the Relation Between Rating, Class Name and Age  \n#### [Return Contents](#0)\n<hr\/>","641b4032":"To reach more information, I also used confusion matrices. It can be seen that SVM does not give healthy results although it has high ROC values.","82d60dca":"When we look at the results of the all evaluation metrics in the *evaluating models section*, **Naive Bayes** and **Logistic Regression** gives the best results for our analysis. Thus, both of them are very effective at predicting sentiment. On the other hand, it seems that **Naive Bayes** takes less time and when we have a bigger dataset, this difference might increase and be an important advantage .\n\n<b><font color=\"green\">Thank you for reading my kernel <\/font><\/b> **and If you liked this kernel, please** <b><font color=\"red\">do not forget to <b><\/font><font color=\"green\">UPVOTE <\/font><\/b> \ud83d\ude42"}}