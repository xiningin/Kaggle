{"cell_type":{"582a0159":"code","155e0118":"code","6973cbf2":"code","d3ce4d70":"code","c04ed6f0":"code","0b923b49":"code","1f87cd95":"code","e1492a0d":"code","2e94d386":"code","c6d16331":"code","703227df":"code","c73ee0d3":"code","382b0c1f":"code","8ccd5167":"code","8e22ac41":"code","7c7ce0cc":"code","0f1c5ba9":"code","514092f9":"code","868c37db":"code","142754de":"code","b31f9489":"code","57c0d450":"code","4633a244":"code","d72b826e":"code","7d1576b4":"code","130f9827":"code","d3e6c2af":"code","a98713b4":"code","f983996a":"code","a777399a":"code","dd38b5bf":"code","8d07a6d9":"markdown","8ea93e1e":"markdown","5c163f60":"markdown","e9f77634":"markdown","5c1ffcd6":"markdown","76266343":"markdown","5a0a2783":"markdown","6f286e4f":"markdown","1527f9e2":"markdown","c5bc17b4":"markdown","5865cf00":"markdown","51c93d16":"markdown","8551837c":"markdown","5edacdd8":"markdown","5afa6d86":"markdown","05858b8f":"markdown","1f1ef311":"markdown","8fd0b942":"markdown","cc46ac74":"markdown","06863281":"markdown","77d0328e":"markdown","90284f08":"markdown","15beadd7":"markdown","9f832950":"markdown","c69dfd42":"markdown"},"source":{"582a0159":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport ipywidgets as widgets\nfrom scipy.stats import binom\nfrom scipy.stats import norm","155e0118":"import os\nos.getcwd()","6973cbf2":"df= pd.read_csv(\"..\/input\/1yearsaledataanalysis\/Sales_April_2019.csv\")\ndf.head()","d3ce4d70":"df.dtypes","c04ed6f0":"df.shape\n","0b923b49":"df = pd.read_csv(\"..\/input\/1yearsaledataanalysis\/Sales_April_2019.csv\")\n\nfiles = [file for file in os.listdir(\"..\/input\/1yearsaledataanalysis\")]\nfor file in files:\n    print(file)","1f87cd95":"# import os\n# import pandas as pd","e1492a0d":"path = \"..\/input\/1yearsaledataanalysis\"\nfiles = [file for file in os.listdir(path) if not file.startswith('.')] # Ignore hidden files\n\nall_data = pd.DataFrame()\n\nfor file in files:\n    current_data = pd.read_csv(path+\"\/\"+file)\n    all_data = pd.concat([all_data, current_data])\n    \nall_data.to_csv(\"all_data_copy.csv\", index=False)","2e94d386":"all_data = pd.read_csv(\"all_data_copy.csv\")\nall_data.head()","c6d16331":"#firstly let's find NaN Values in our DataFrame, ifany!!!\n\n\nnan_df = all_data[all_data.isna().any(axis=1)]\ndisplay(nan_df.head())\n\nall_data = all_data.dropna(how='all')\nall_data.head()\n","703227df":"all_data.head()","c73ee0d3":"# Find NaN\nnan_df = all_data[all_data.isna().any(axis=1)]\ndisplay(nan_df.head())\n\nall_data = all_data.dropna(how='all')\nall_data.head()","382b0c1f":"all_data = all_data[all_data['Order Date'].str[0:2]!='Or']\nall_data.head()","8ccd5167":"all_data['Quantity Ordered'] = pd.to_numeric(all_data['Quantity Ordered'])\nall_data['Price Each'] = pd.to_numeric(all_data['Price Each'])","8e22ac41":"all_data['Month'] = all_data['Order Date'].str[0:2]\nall_data['Month'] = all_data['Month'].astype('int32')\nall_data.head()","7c7ce0cc":"# this is more efficient way to convert becuase it do not throw any gibberish on you. :)\nall_data['Month 2'] = pd.to_datetime(all_data['Order Date']).dt.month\nall_data.head()","0f1c5ba9":"#Add a city column (address)\ndef get_city(address):\n    return address.split(\",\")[1].strip(\" \")                    #Thanks to KG\n\ndef get_state(address):\n    return address.split(\",\")[2].split(\" \")[1]\n\nall_data['City'] = all_data['Purchase Address'].apply(lambda x: f\"{get_city(x)}  ({get_state(x)})\")\nall_data.head()","514092f9":"all_data['Sales'] = all_data['Quantity Ordered'].astype('int') * all_data['Price Each'].astype('float')\nall_data.groupby(['Month']).sum()","868c37db":"import matplotlib.pyplot as plt\nimport numpy as np\nplt.style.use('fivethirtyeight')\n\nmonths = range(1,13)\n# print(months)\n\nplt.bar(months,all_data.groupby(['Month']).sum()['Sales'],edgecolor='black', color='seagreen', alpha= 0.6)\nplt.title('Monthly Sales')\nplt.xticks(months)\nplt.ylabel('Sales in USD ($)')\nplt.xlabel('Month number', color='darkblue')\nplt.show()","142754de":"all_data.groupby(['City']).sum()","b31f9489":"import matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n\nkeys = [city for city, df in all_data.groupby(['City'])]\n\nplt.bar(keys,all_data.groupby(['City']).sum()['Sales'],edgecolor='b', color='limegreen', alpha= 0.6)\nplt.title(\"City wise Sales\")\nplt.ylabel('Sales in USD ($)')\nplt.xlabel('Month number')\nplt.xticks(keys, rotation='45', size=8, color='black')\nplt.show()","57c0d450":"# Add hour column\nall_data['Hour'] = pd.to_datetime(all_data['Order Date']).dt.hour\nall_data['Minute'] = pd.to_datetime(all_data['Order Date']).dt.minute\nall_data['Count'] = 1\nall_data.head()","4633a244":"keys = [pair for pair, df in all_data.groupby(['Hour'])]\nplt.style.use('fivethirtyeight') #538\n\nplt.plot(keys, all_data.groupby(['Hour']).count()['Count'], color='limegreen')\nplt.title(\"Peak time of placing orders\")\nplt.xticks(keys)\nplt.grid()\nplt.show()\n\nprint(\"Advertisement recommended time should be slightly before 11am or 7pm\")","d72b826e":"df = all_data[all_data['Order ID'].duplicated(keep=False)]\n\n\ndf['Grouped'] = df.groupby('Order ID')['Product'].transform(lambda x: ','.join(x))\ndf2 = df[['Order ID', 'Grouped']].drop_duplicates()","7d1576b4":"from itertools import combinations\nfrom collections import Counter\n\ncount = Counter()\n\nfor row in df2['Grouped']:\n    row_list = row.split(',')\n    count.update(Counter(combinations(row_list, 2)))\n\nfor key,value in count.most_common(10):\n    print(key, value)","130f9827":"product_group = all_data.groupby('Product')\nquantity_ordered = product_group.sum()['Quantity Ordered']\nplt.style.use('fivethirtyeight') #538\n\nkeys = [pair for pair, df in product_group]\nplt.bar(keys, quantity_ordered, color='navy')\nplt.title(\"The mix sold item\")\nplt.xticks(keys, rotation='vertical', size=8)\nplt.show()","d3e6c2af":"prices = all_data.groupby('Product').mean()['Price Each']\nplt.style.use('fivethirtyeight') #538\n\nfig, ax1 = plt.subplots()\n\nax2 = ax1.twinx()\nax1.bar(keys, quantity_ordered, color='limegreen', edgecolor='black')\nax2.plot(keys, prices, color='navy')\n\nax1.set_xlabel('Product Names')\nax1.set_ylabel('Quantity Ordered', color='g')\nax2.set_ylabel('Price ($)', color='b')\nax1.set_xticklabels(keys, rotation='vertical', size=8)\n\nfig.show()","a98713b4":"all_data.groupby(['City']).sum()","f983996a":"all_data.describe()","a777399a":"df.shape","dd38b5bf":"import matplotlib.pyplot as plt\nimport numpy as np\n\n\nplt.style.use('fivethirtyeight')\n\nx = np.linspace(0, 10)\n\n# Fixing random state for reproducibility\nnp.random.seed(19680801)\n\nfig, ax = plt.subplots()\n\nax.plot(x, np.sin(x) + x + np.random.randn(50))\nax.plot(x, np.sin(x) + 0.5 * x + np.random.randn(50))\nax.plot(x, np.sin(x) + 2 * x + np.random.randn(50))\nax.plot(x, np.sin(x) - 0.5 * x + np.random.randn(50))\nax.plot(x, np.sin(x) - 2 * x + np.random.randn(50))\nax.plot(x, np.sin(x) + np.random.randn(50))\nax.set_title(\"'fivethirtyeight' style sheet\")\n\nplt.show()","8d07a6d9":"### Merging 12 months different files into 1 single csv file ","8ea93e1e":"* finding soution for find and removing NaN values in dataframe","5c163f60":"### Data Cleaning Step 1\nDropping Rows containing 'NaN' values","e9f77634":"- **Note: a different chart can be produce which can represent time for orders.** ","5c1ffcd6":"###  Add city column\n**Apply Method usage and creating fuction:**\n","76266343":"### Plot style used: 'fivethirtyeight' ","5a0a2783":"### Merging 12 months of data into 1 file","6f286e4f":"### Question 2: What city sold the most product?","1527f9e2":"#### Add month column (method 2)","c5bc17b4":"#### Augment data with additional columns\n\n\n###  Add month column","5865cf00":"### Question 4: What products are most often sold together?","51c93d16":"**SAN FRANCISCO (CA) was the top city in terms of Sales.**","8551837c":"**Drop the Rows containing NaN**","5edacdd8":"## Data Exploration!\n#### Question 1: What was the best month for sales? How much was earned that month?","5afa6d86":"## Cleaning up data - NaN in dataset","05858b8f":"STAGE 1: Data Cleaning\n    - Once we start processing our data we usually find errors, missing values in our dataframe, so it is always best to start cleaning your data as per process go on, and you figuering out what should be dropped off and what should be added.","1f1ef311":"### Question 3: What time should we display advertisements to maximize likelihood of customer's buying product?","8fd0b942":"### importing relevant libraries into jupyter notebook","cc46ac74":"- **Month of December had the highest sales volume**","06863281":"# Sales Analysis- \n### one (1) Years Sales data Analysis\n\n* By: $Ertiza Abbas$\n* September 2021\n","77d0328e":"### Plot to visualize which month was best is sales\n","90284f08":"## Merging all 12 months data into 1 file\n\n\n$ Important Notes:$\n- Always try to write your code with same location you dataset existing.\n- while merging dataset try to be simple as much as you can.\n- always check the values in different dataframes and confirm data integrity while performing analysis. ","15beadd7":"## Thank you","9f832950":"### Removing text in order date column","c69dfd42":"### What product sold the most? Why do you think it sold the most?"}}