{"cell_type":{"8dc5a124":"code","e99689d5":"code","831f58fd":"code","cea82f7c":"code","c13d299b":"code","360117b4":"code","402cd3f6":"code","b62675e7":"code","cbd0b8f3":"code","edf51092":"code","6cbf7d2a":"code","39b42ef0":"code","e0533591":"code","5c42d15d":"code","0a67226e":"code","c2b9f2b4":"code","fa1c77c3":"code","c06fd14e":"code","655685ac":"code","8650c987":"code","87e75b56":"code","a1bdffa5":"code","44876b37":"code","c0577626":"code","2646fefa":"code","3849fe01":"code","da8fe419":"code","a3bc6d9a":"markdown","5bc2c3ec":"markdown","ba0bca11":"markdown","090a780f":"markdown","8e53c725":"markdown","c5f1c2f6":"markdown","5ae329d3":"markdown","73fb78f8":"markdown","84225ba3":"markdown","5d136151":"markdown"},"source":{"8dc5a124":"import numpy as np \nimport pandas as pd \nimport os\nimport random\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom PIL import Image\nimport matplotlib.patches as patches\nfrom torchvision import torch,datasets,transforms,models\nfrom torch.utils.data import Dataset,DataLoader","e99689d5":"path_images=os.path.join(\"\/kaggle\/input\/face-mask-detection-dataset\/Medical mask\/Medical mask\/Medical Mask\/images\")\ntrain=pd.read_csv(os.path.join(\"\/kaggle\/input\/face-mask-detection-dataset\/train.csv\"))","831f58fd":"train #quick look into dataset","cea82f7c":"train=train[train.classname.str.contains(\"face_with_mask$|face_no_mask\")] # filtering the data to mask and no mask bales\ntrain.classname.value_counts()","c13d299b":"#lets lookinto the data after filtering\ntrain.head()","360117b4":"# creating the function to visualize images\ndef draw_box(image_name):\n    img=plt.imread(os.path.join(path_images,image_name))\n    temp=train[train.name==image_name]\n    fig,ax=plt.subplots(1)\n    fig.set_size_inches(10,5)\n    ax.imshow(img)\n    ax.axis('off')\n    edgecolor={\"face_no_mask\":\"r\",\"face_with_mask\":\"b\"}\n    for i in range(len(temp)):\n        a,b,c,d=temp.values[i][1:5]\n        patch=patches.Rectangle((a,b),c-a,d-b,linewidth=2, \n                                edgecolor=edgecolor[temp.values[i][5:6][0]],facecolor=\"none\",)\n        ax.text(a, b, temp.values[i][5:6][0], style='italic',bbox={'facecolor': 'yellow', 'alpha': 0.5, 'pad': 10})\n        ax.add_patch(patch)","402cd3f6":"draw_box(random.choice(train.name.values))","b62675e7":"#defining sizes for testing and training the images\ntrain_size=int(len(train)*0.8)\ntest_size=int(len(train))-train_size","cbd0b8f3":"from sklearn.preprocessing import LabelEncoder\nlbl=LabelEncoder()\ntrain[\"labels\"]=lbl.fit_transform(train.classname)\ntrain.to_csv(\"new.csv\", header=False)\ntrain_new=pd.read_csv(\".\/new.csv\",header=None)","edf51092":"class MaskAndNoMask(Dataset): \n    def __init__(self,dataframe,root_dir,transform=None):\n        self.annotation=dataframe\n        self.root_dir=root_dir\n        self.transform=transform\n        \n    def __len__(self):\n        return len(self.annotation)\n    \n    def __getitem__(self,index):\n        img_path=os.path.join(self.root_dir,self.annotation.iloc[index,1])\n        new_img=Image.open(img_path).crop((self.annotation.iloc[index,2:6]))\n        label=torch.tensor(int(self.annotation.iloc[index,7:8]))\n    \n        if self.transform:\n            image=self.transform(new_img)\n            return(image,label)","6cbf7d2a":"my_transform=transforms.Compose([transforms.Resize((224,224)),\n                                 transforms.RandomCrop((224,224)),\n                                 transforms.ToTensor()])\n\ndataset=MaskAndNoMask(dataframe=train_new,root_dir=path_images,transform=my_transform)\n\nbatch_size=32\n\ntrainset,testset=torch.utils.data.random_split(dataset,[train_size,test_size])\ntrain_loader=DataLoader(dataset=trainset,batch_size=batch_size,shuffle=True)\ntest_loader=DataLoader(dataset=testset,batch_size=batch_size,shuffle=True)","39b42ef0":"dataiter=iter(train_loader)\nimages,labels=dataiter.next()\nimages=images.numpy()\n\nfig=plt.figure(figsize=(25,4))\nfor idx in np.arange(20):\n    ax=fig.add_subplot(2,20\/2,idx+1,xticks=[],yticks=[])\n    plt.imshow(np.transpose(images[idx],(1,2,0)))","e0533591":"torch.cuda.empty_cache() ","5c42d15d":"resnet=models.resnet34(pretrained=True)","0a67226e":"for param in resnet.parameters():\n    param.requires_grad=False","c2b9f2b4":"if torch.cuda.is_available():\n    device=torch.device(\"cuda\")\n    print(\"gpu available {}\".format(torch.cuda.device_count()))\n    print(\"device name {}\".format(torch.cuda.get_device_name(0)))\nelse:\n    device=torch.device(\"cpu\")\n    print(\"No gpu avalable,traing on cpu\")","fa1c77c3":"import torch.nn as nn\nn_inputs=resnet.fc.in_features\nlast_layer=nn.Linear(n_inputs,2)\nresnet.fc.out_features=last_layer\n\nif torch.cuda.is_available():\n    resnet.cuda()\n\nprint(resnet.fc.out_features)","c06fd14e":"for param in resnet.parameters():\n    param.requires_grad=True","655685ac":"import torch.optim as optim\n\ncriterion=nn.CrossEntropyLoss()\noptimizer=optim.SGD(resnet.parameters(),lr=0.001)","8650c987":"n_epochs=3\nepochs=[]\ntraining_loss=[]\n\nfor epoch in range(1,n_epochs+1):\n    train_loss=0\n    epochs.append(epoch)\n    \n    \n    for batch,(data,target) in enumerate(train_loader):\n        if torch.cuda.is_available():\n            data,target=data.cuda(),target.cuda()\n\n        optimizer.zero_grad()\n        output=resnet(data)\n        loss=criterion(output,target)\n        loss.backward()\n        optimizer.step()\n        train_loss+=loss.item()\n     \n        if batch%20==19:\n            print(\"Epoch {}, batch {}, training loss {}\".format(epoch,batch+1,train_loss\/20))\n            training_loss.append(train_loss) \n            train_loss=0.0","87e75b56":"test_loss=0\nacc=0\nresnet.eval()\n\nfor data,target in test_loader:\n    if torch.cuda.is_available():\n        data,target=data.cuda(),target.cuda()\n    output=resnet(data)\n    loss=criterion(output,target)\n    test_loss+=loss.item()\n    _,pred=torch.max(output,1)\n    predicted=pred.numpy()[:,np.newaxis] if not torch.cuda.is_available() else pred.cpu().numpy()[:,np.newaxis]\n    actual=target.numpy()[:,np.newaxis] if not torch.cuda.is_available() else target.cpu().numpy()[:,np.newaxis]    \n    acc+=np.sum(predicted==actual)\/len(test_loader)\n    \navg_loss=test_loss\/len(test_loader)\navg_acc=acc\/len(test_loader)\n\nprint(\"Average total loss is {:.6f}\".format(avg_loss))\nprint(\"Average total accuracy is {:.6f}\".format(avg_acc))","a1bdffa5":"torch.save(resnet,open(\"resnet_face_mask_detect\",\"wb\"))\nmodel=torch.load(open(\".\/resnet_face_mask_detect\",\"rb\"))","44876b37":"!pip install facenet-pytorch","c0577626":"from facenet_pytorch import MTCNN\nmtcnn = MTCNN()","2646fefa":"model=model.eval()","3849fe01":"class TagImages():\n    def __init__(self):\n        \n        self.filepath=filepath\n        img=Image.open(self.filepath)\n        boxes, _ = mtcnn.detect(img)\n        predictions=[]\n        for i in boxes:\n            im_pr=img.crop(i)\n            predict_im=my_transform(im_pr).unsqueeze(0)\n            output=model(predict_im.cuda())\n            _,pred=torch.max(output,1)\n            predicted=pred.numpy() if not torch.cuda.is_available() else pred.cpu().numpy()\n            predictions.append(predicted[0])\n        self.boxes=boxes\n        self.predictions=predictions\n        \n    def draw_box_predicted(self,filepath):\n        img=plt.imread(self.filepath)\n        fig,ax=plt.subplots(1)\n        fig.set_size_inches(10,5)\n        ax.imshow(img)\n        ax.axis('off')\n        configuration=[\"face_no_mask\", \"face_with_mask\"]\n        color={\"face_no_mask\":\"r\",\"face_with_mask\":\"b\"}\n        for i,j in zip(self.boxes,self.predictions):\n            a,b,c,d=i\n            patch=patches.Rectangle((a,b),c-a,d-b,linewidth=2, \n                                    edgecolor=color[configuration[j]],facecolor=\"none\",)\n            ax.text(a, b, configuration[j],\n                    style='italic',bbox={'facecolor': color[configuration[j]], 'alpha': 0.4, 'pad': 10})\n            ax.add_patch(patch)","da8fe419":"filepath=os.path.join(path_images,random.choice(train.name.values))\nTagImages().draw_box_predicted(filepath)","a3bc6d9a":"Defining Loss function and optimizer","5bc2c3ec":"## Saving and Loading the saved model","ba0bca11":"## downloading facenet model for predicting faces,which would be the input for our current model.\nthis is neccessary for predicting the images other than this dataset,since image file will not have facial information.","090a780f":"## Creating the dataset for training...","8e53c725":"## Testing the Model","c5f1c2f6":"## Loading the Data","5ae329d3":"## Importing neccessary Libraries","73fb78f8":"## downloading the Pretrained model","84225ba3":"### I am a Beginner here, please feel free to comment.that will help me to move forward\n\n### Thanks in Advance","5d136151":"## Training the Model"}}