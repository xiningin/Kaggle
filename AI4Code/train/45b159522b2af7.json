{"cell_type":{"5e8b2a98":"code","ad1b9411":"code","d3aa552f":"code","726aface":"code","ef1bdd2d":"code","59283930":"code","5eaaa3cf":"code","b822e216":"code","24533c41":"code","716fa018":"code","79ae56db":"code","4919f8fc":"code","f83a70b8":"code","96d0a935":"code","630dd98e":"code","0dddf1aa":"code","fed9764c":"code","d814440a":"code","2e552947":"code","8b44931f":"code","4be7c5e1":"code","99a480b4":"code","b20c56ba":"code","69282663":"code","aa097b51":"code","66ec7450":"code","c55da29a":"code","61953146":"code","9c6e8ba7":"code","013cc691":"code","8a331a63":"code","dd61c5ae":"code","cbeef5e2":"code","1d6b6576":"code","36bd8e99":"code","cc2e689c":"code","5bd6c4f0":"code","0905650e":"code","edcd95fd":"code","dea17121":"code","2efe220c":"code","9acb71ac":"code","45b62901":"code","807cc468":"code","a238cadc":"code","2c90544c":"code","50f22dfe":"code","c11118f1":"code","bea8a33b":"code","a9c25683":"code","5bedc432":"code","dd6201ba":"code","515b9453":"code","62cd2082":"code","5f4442b8":"code","4e623080":"code","f83cb387":"code","590e6c5d":"code","e2cb7761":"code","277440f3":"code","b8b40d61":"code","17f52fda":"code","8f9ab79e":"markdown","69b2bdc3":"markdown","c0afe40c":"markdown","6276a07e":"markdown","9984c6d0":"markdown","78576a42":"markdown","9e38d137":"markdown","6dc9bdcd":"markdown","2b2f92e5":"markdown","6feb81fa":"markdown","da9a5fca":"markdown","235e5a8d":"markdown","c15f4511":"markdown","9cf768d3":"markdown","53f69435":"markdown","a7d075a5":"markdown","eaf31905":"markdown","866e6db6":"markdown","98e5a658":"markdown","690ec985":"markdown","1fa29eaf":"markdown","4bf9b643":"markdown","a0c1aec4":"markdown","75650c02":"markdown","026c2981":"markdown","09724009":"markdown","c479003d":"markdown","8945e230":"markdown","1550b3b5":"markdown","a5a0fa8e":"markdown","f3b8b25a":"markdown","0b9c59db":"markdown","60538215":"markdown","1327d8ec":"markdown","35f836a2":"markdown","83478915":"markdown","0761542a":"markdown","ded1ad87":"markdown","fcedf75d":"markdown"},"source":{"5e8b2a98":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n\n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ad1b9411":"# import the data (chunksize returns jsonReader for iteration)\nbusinesses = pd.read_json(\"\/kaggle\/input\/yelp-dataset\/yelp_academic_dataset_business.json\", lines=True, orient='columns', chunksize=1000000)\nreviews = pd.read_json(\"\/kaggle\/input\/yelp-dataset\/yelp_academic_dataset_review.json\", lines=True, orient='columns', chunksize=1000000)","d3aa552f":"# read the data \nfor business in businesses:\n    subset_business = business\n    break\n    \nfor review in reviews:\n    subset_review = review\n    break","726aface":"# peak the tables\ndisplay(subset_business.head(2))\ndisplay(subset_review.head(2))","ef1bdd2d":"# Businesses in Toronto and currently open business\ncity = subset_business[(subset_business['city'] == 'Toronto') & (subset_business['is_open'] == 1)]\ntoronto = city[['business_id','name','address', 'categories', 'attributes','stars']]\ntoronto","59283930":"# getting just restaurants from Toronto business\nrest = toronto[toronto['categories'].str.contains('Restaurant.*')==True].reset_index()\nrest   ","5eaaa3cf":"# Function that extract keys from the nested dictionary\ndef extract_keys(attr, key):\n    if attr == None:\n        return \"{}\"\n    if key in attr:\n        return attr.pop(key)\n\n# convert string to dictionary\nimport ast\ndef str_to_dict(attr):\n    if attr != None:\n        return ast.literal_eval(attr)\n    else:\n        return ast.literal_eval(\"{}\")    ","b822e216":"# get dummies from nested attributes\nrest['BusinessParking'] = rest.apply(lambda x: str_to_dict(extract_keys(x['attributes'], 'BusinessParking')), axis=1)\nrest['Ambience'] = rest.apply(lambda x: str_to_dict(extract_keys(x['attributes'], 'Ambience')), axis=1)\nrest['GoodForMeal'] = rest.apply(lambda x: str_to_dict(extract_keys(x['attributes'], 'GoodForMeal')), axis=1)\nrest['Dietary'] = rest.apply(lambda x: str_to_dict(extract_keys(x['attributes'], 'Dietary')), axis=1)\nrest['Music'] = rest.apply(lambda x: str_to_dict(extract_keys(x['attributes'], 'Music')), axis=1)","24533c41":"rest","716fa018":"# create table with attribute dummies\ndf_attr = pd.concat([ rest['attributes'].apply(pd.Series), rest['BusinessParking'].apply(pd.Series),\n                    rest['Ambience'].apply(pd.Series), rest['GoodForMeal'].apply(pd.Series), \n                    rest['Dietary'].apply(pd.Series) ], axis=1)\ndf_attr_dummies = pd.get_dummies(df_attr)\ndf_attr_dummies","79ae56db":"# get dummies from categories\ndf_categories_dummies = pd.Series(rest['categories']).str.get_dummies(',')\ndf_categories_dummies","4919f8fc":"# pull out names and stars from rest table \nresult = rest[['name','stars']]\nresult","f83a70b8":"# Concat all tables and drop Restaurant column\ndf_final = pd.concat([df_attr_dummies, df_categories_dummies, result], axis=1)\ndf_final.drop('Restaurants',inplace=True,axis=1)","96d0a935":"# map floating point stars to an integer\nmapper = {1.0:1,1.5:2, 2.0:2, 2.5:3, 3.0:3, 3.5:4, 4.0:4, 4.5:5, 5.0:5}\ndf_final['stars'] = df_final['stars'].map(mapper)","630dd98e":"# Final table for the models \ndf_final","0dddf1aa":"# Create X (all the features) and y (target)\nX = df_final.iloc[:,:-2]\ny = df_final['stars']","fed9764c":"# Split the data into train and test sets\nfrom sklearn.model_selection import train_test_split\nX_train_knn, X_test_knn, y_train_knn, y_test_knn = train_test_split(X, y, test_size=0.2, random_state=1)","d814440a":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\nknn = KNeighborsClassifier(n_neighbors=20)\nknn.fit(X_train_knn, y_train_knn)\n\n#y_pred = knn.predict(X_test)\n\naccuracy_train = knn.score(X_train_knn, y_train_knn)\naccuracy_test = knn.score(X_test_knn, y_test_knn)\n\nprint(f\"Score on training set: {accuracy_train}\")\nprint(f\"Score on test set: {accuracy_test}\")","2e552947":"# look at the last row for the test\ndisplay(df_final.iloc[-1:])\n\n# look at the restaurant name from the last row.\nprint(\"Validation set (Restaurant name): \", df_final['name'].values[-1])","8b44931f":"# test set from the df_final table (only last row): Restaurant name: \"Steak & Cheese & Quick Pita Restaurant\"\ntest_set = df_final.iloc[-1:,:-2]\n\n# validation set from the df_final table (exclude the last row)\nX_val =  df_final.iloc[:-1,:-2]\ny_val = df_final['stars'].iloc[:-1]","4be7c5e1":"# fit model with validation set\nn_knn = knn.fit(X_val, y_val)","99a480b4":"# distances and indeces from validation set (Steak & Cheese & Quick Pita Restaurant)\ndistances, indeces =  n_knn.kneighbors(test_set)\n#n_knn.kneighbors(test_set)[1][0]\n\n# create table distances and indeces from \"Steak & Cheese & Quick Pita Restaurant\"\nfinal_table = pd.DataFrame(n_knn.kneighbors(test_set)[0][0], columns = ['distance'])\nfinal_table['index'] = n_knn.kneighbors(test_set)[1][0]\nfinal_table.set_index('index')","b20c56ba":"# get names of the restaurant that similar to the \"Steak & Cheese & Quick Pita Restaurant\"\nresult = final_table.join(df_final,on='index')\nresult[['distance','index','name','stars']].head(5)","69282663":"# looking at the columns of subset_review table\nsubset_review.columns","aa097b51":"# pull out needed columns from subset_review table\ndf_review = subset_review[['user_id','business_id','stars', 'date']]\ndf_review","66ec7450":"# pull out names and addresses of the restaurants from rest table\nrestaurant = rest[['business_id', 'name', 'address']]\nrestaurant","c55da29a":"# combine df_review and restaurant table\ncombined_business_data = pd.merge(df_review, restaurant, on='business_id')\ncombined_business_data","61953146":"# the most POPULAR restaurants by stars.\ncombined_business_data.groupby('business_id')['stars'].count().sort_values(ascending=False).head()","9c6e8ba7":"# see the NAME of the most popular restaurant\nFilter = combined_business_data['business_id'] == 'h_4dPV9M9aYaBliH1Eoeeg'\nprint(\"Name: \", combined_business_data[Filter]['name'].unique())\nprint(\"Address:\", combined_business_data[Filter]['address'].unique())","013cc691":"# create a user-item matrix\nrating_crosstab = combined_business_data.pivot_table(values='stars', index='user_id', columns='name', fill_value=0)\nrating_crosstab.head()","8a331a63":"# shape of the Utility matrix (original matrix) \nrating_crosstab.shape","dd61c5ae":"# Transpose the Utility matrix\nX = rating_crosstab.values.T\nX.shape","cbeef5e2":"import sklearn\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.metrics import accuracy_score\n\n\nSVD = TruncatedSVD(n_components=12, random_state=17)\nresult_matrix = SVD.fit_transform(X)\nresult_matrix.shape","1d6b6576":"# PearsonR coef \ncorr_matrix = np.corrcoef(result_matrix)\ncorr_matrix.shape","36bd8e99":"# get the index of the popular restaurant\nrestaurant_names = rating_crosstab.columns\nrestaurants_list = list(restaurant_names)\n\npopular_rest = restaurants_list.index('Wvrst')\nprint(\"index of the popular restaurant: \", popular_rest) ","cc2e689c":"# restaurant of interest \ncorr_popular_rest = corr_matrix[popular_rest]\ncorr_popular_rest.shape  ","5bd6c4f0":"list(restaurant_names[(corr_popular_rest < 1.0) & (corr_popular_rest > 0.9)])","0905650e":"display(rest[rest['name'] == 'Wvrst'])","edcd95fd":"# create the copy of combined_business_data table\ncombined_business_data_keras = combined_business_data.copy()\ncombined_business_data_keras.head(1)","dea17121":"from sklearn.preprocessing import LabelEncoder\n\nuser_encode = LabelEncoder()\n\ncombined_business_data_keras['user'] = user_encode.fit_transform(combined_business_data_keras['user_id'].values)\nn_users = combined_business_data_keras['user'].nunique()\n\nitem_encode = LabelEncoder()\n\ncombined_business_data_keras['business'] = item_encode.fit_transform(combined_business_data_keras['business_id'].values)\nn_rests = combined_business_data_keras['business'].nunique()\n\ncombined_business_data_keras['stars'] = combined_business_data_keras['stars'].values#.astype(np.float32)\n\nmin_rating = min(combined_business_data_keras['stars'])\nmax_rating = max(combined_business_data_keras['stars'])\n\nprint(n_users, n_rests, min_rating, max_rating)\n\ncombined_business_data_keras","2efe220c":"from sklearn.model_selection import train_test_split\n\nX = combined_business_data_keras[['user', 'business']].values\ny = combined_business_data_keras['stars'].values\n\nX_train_keras, X_test_keras, y_train_keras, y_test_keras = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train_keras.shape, X_test_keras.shape, y_train_keras.shape, y_test_keras.shape","9acb71ac":"X_train_keras[:, 0]","45b62901":"n_factors = 50\n\nX_train_array = [X_train_keras[:, 0], X_train_keras[:, 1]]\nX_test_array = [X_test_keras[:, 0], X_test_keras[:, 1]]","807cc468":"X_train_array, X_test_array","a238cadc":"from keras.layers import Add, Activation, Lambda\nfrom keras.models import Model\nfrom keras.layers import Input, Reshape, Dot\nfrom keras.layers.embeddings import Embedding\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l2\n\nclass EmbeddingLayer:\n    def __init__(self, n_items, n_factors):\n        self.n_items = n_items\n        self.n_factors = n_factors\n    \n    def __call__(self, x):\n        x = Embedding(self.n_items, self.n_factors, embeddings_initializer='he_normal', embeddings_regularizer=l2(1e-6))(x)\n        x = Reshape((self.n_factors,))(x)\n        \n        return x\n    \ndef Recommender(n_users, n_rests, n_factors, min_rating, max_rating):\n    user = Input(shape=(1,))\n    u = EmbeddingLayer(n_users, n_factors)(user)\n    ub = EmbeddingLayer(n_users, 1)(user)\n    \n    restaurant = Input(shape=(1,))\n    m = EmbeddingLayer(n_rests, n_factors)(restaurant)\n    mb = EmbeddingLayer(n_rests, 1)(restaurant)   \n    \n    x = Dot(axes=1)([u, m])\n    x = Add()([x, ub, mb])\n    x = Activation('sigmoid')(x)\n    x = Lambda(lambda x: x * (max_rating - min_rating) + min_rating)(x)  \n    \n    model = Model(inputs=[user, restaurant], outputs=x)\n    opt = Adam(lr=0.001)\n    model.compile(loss='mean_squared_error', optimizer=opt)  \n    \n    return model","2c90544c":"keras_model = Recommender(n_users, n_rests, n_factors, min_rating, max_rating)\nkeras_model.summary()","50f22dfe":"keras_model.fit(x=X_train_array, y=y_train_keras, batch_size=64,\\\n                          epochs=5, verbose=1, validation_data=(X_test_array, y_test_keras))","c11118f1":"# prediction\npredictions = keras_model.predict(X_test_array)","bea8a33b":"# create the df_test table with prediction results\ndf_test = pd.DataFrame(X_test_keras[:,0])\ndf_test.rename(columns={0: \"user\"}, inplace=True)\ndf_test['business'] = X_test_keras[:,1]\ndf_test['stars'] = y_test_keras\ndf_test[\"predictions\"] = predictions\ndf_test.head()","a9c25683":"# Plotting the distribution of actual and predicted stars\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nvalues, counts = np.unique(df_test['stars'], return_counts=True)\n\nplt.figure(figsize=(8,6))\nplt.bar(values, counts, tick_label=['1','2','3','4','5'], label='true value')\nplt.hist(predictions, color='orange', label='predicted value')\nplt.xlabel(\"Ratings\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Ratings Histogram\")\nplt.legend()\nplt.show()","5bedc432":"# # plot \n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n# plt.figure(figsize=(15,6))\n\n# ax1 = sns.distplot(df_test['stars'], hist=False, color=\"r\", label=\"Actual Value\")\n# sns.distplot(predictions, hist=False, color=\"g\", label=\"model2 Fitted Values\" , ax=ax1)\n\n# plt.title('Actual vs Fitted Values for Restaurant Ratings')\n# plt.xlabel('Stars')\n# plt.ylabel('Proportion of Ratings')\n\n# plt.show()\n# plt.close()","dd6201ba":"# Extract embeddings\nemb = keras_model.get_layer('embedding_3')\nemb_weights = emb.get_weights()[0]\n\nprint(\"The shape of embedded weights: \", emb_weights.shape)\nprint(\"The length of embedded weights: \", len(emb_weights))","515b9453":"# normalize and reshape embedded weights\nemb_weights = emb_weights \/ np.linalg.norm(emb_weights, axis = 1).reshape((-1, 1))\nlen(emb_weights)","62cd2082":"# get all unique business_ids (restaurants)\nrest_id_emb = combined_business_data_keras[\"business_id\"].unique()\nlen(rest_id_emb)","5f4442b8":"rest_pd = pd.DataFrame(emb_weights)\nrest_pd[\"business_id\"] = rest_id_emb\nrest_pd = rest_pd.set_index(\"business_id\")\nrest_pd","4e623080":"# merging rest_pd and temp tables to get the name of the restaurants.\ntemp = combined_business_data_keras[['business_id', 'name']].drop_duplicates()\ndf_recommend = pd.merge(rest_pd, temp, on='business_id')\ndf_recommend","f83cb387":"# exrtract the target restaurant from the df_recommend table\ntarget = df_recommend[df_recommend['name'] == 'Wvrst']\ntarget.iloc[:,1:51]","590e6c5d":"def find_similarity_total(rest_name):\n    \"\"\"Recommends restaurant based on the cosine similarity between restaurants\"\"\"\n    cosine_list_total = []\n    result = []\n\n    for i in range(0, df_recommend.shape[0]):\n        sample_name = df_recommend[df_recommend[\"name\"] == rest_name].iloc[:,1:51]\n        row = df_recommend.iloc[i,1:51]\n        cosine_total = np.dot(sample_name, row)\n        \n        recommended_name = df_recommend.iloc[i,51]\n        cosine_list_total.append(cosine_total)\n        result.append(recommended_name)\n        \n    cosine_df_total = pd.DataFrame({\"similar_rest\" : result, \"cosine\" : cosine_list_total})\n\n    return cosine_df_total","e2cb7761":"# call the function with input of \"Wvrst\" and store it in result variable.\nresult = find_similarity_total('Wvrst')","277440f3":"# head of result table\nresult.head()","b8b40d61":"'''\n- function that replace '[]' to empty str \n- convert string to float\n'''\ndef convert(input):\n    return float(str(input).replace('[','').replace(']',''))","17f52fda":"# create new column called \"cos\" in result table\nresult['cos'] = result.apply(lambda x: convert(x['cosine']), axis=1)\n\n# drop original 'cosine' column (which had values with np.array)\nresult.drop('cosine', axis=1, inplace=True)\n\n# sort values with cos\nresult.sort_values('cos', ascending=False).head(10)","8f9ab79e":"* **Split the data into train and test set (80:20)**","69b2bdc3":"<a id=\"decompose-matrix\"><\/a>\n* **Decomposing the Matrix**\n\nNow we use TruncatedSVD from sklearn to compress the transposed matrix into down to a number of rows by 12 matrices. All of the restaurants are in the rows. But the users will be compressed down to 12 components arbitrarily that represent a generalized view of users' tastes.  ","c0afe40c":"<a id=\"prediction\"><\/a>\n* **Prediction**\n\nAfter creating the model now it's time to predict the test dataset. ","6276a07e":"We are going to create a table that contains all the unique restaurants in 50 dimensions with their embedded weights.","9984c6d0":"<a id=\"recommendation\"><\/a>\n* **Recommendation**\n\nNow we going to use this model to recommend restaurants to a popular restaurant which was \"Wvrst\".","78576a42":"<a id=\"transpose-matrix\"><\/a>\n* **Transposing the Matrix**\n\nAfter transpose the matrix, users are represented by columns, and restaurants are represented by rows.","9e38d137":"# Restaurant Recommendation (Yelp dataset)","6dc9bdcd":"Each restaurant is now represented as a 50-dimensional vector. We need to normalize the embeddings so that the dot product between two embeddings becomes the cosine similarity.\n\nSource:  https:\/\/towardsdatascience.com\/building-a-recommendation-system-using-neural-network-embeddings-1ef92e5c80c9","2b2f92e5":"<a id=\"NN-keras\"><\/a>\n## 2. Neural Network Model - Keras\n\nFinally, we\u2019ll build a neural network and see how it compares to the other collaborative filtering approach. ","6feb81fa":"We are creating the following ***result*** table which displays similar restaurants to \"Steak & Cheese & Quick Pita Restaurant\" by their distances. Based on this recommendation system, the short distance means having more similarity to \"Steak & Cheese & Quick Pita Restaurant\". ","da9a5fca":"* **Test the model:** \n\n> We used the last row as a validation set (we didn't include this last row for modeling). ","235e5a8d":"Here, we\u2019re going to use embeddings to represent each user and each restaurant in the data. To get these embeddings we need to do the dot product between the user vector and restaurant vector. As a result, we will have vectors of size n factors to capture the weights related to each user per restaurant. \n\nIn order to increase the model performance, we add the \"bias\" to each embedding. We run the output of the dot product through a sigmoid layer and then scaling the result using the min and max ratings in the data. ","c15f4511":"<a id=\"content-based\"><\/a>\n# Content Based Filtering- Model\n\nIn this section, we are going to build a system that recognizes the similarity between restaurants based on specific features and recommends restaurants that are most similar to a particular restaurant. __df_final__ (features) table used to build this system.","9cf768d3":"<a id=\"svd\"><\/a>\n## 1. Singular Value Decomposition model (SVD)","53f69435":"![](http:\/\/blog.yelp.com\/wp-content\/uploads\/2020\/02\/Full-Article-Feature-Image-900x354-1.png)\n\n* [Introduction](#introduction)\n* [Data](#data)\n* [Preprocessing Data](#preprocessing-data) \n    * [Get Dummies from attributes](#get-dummies) \n* [Content Based Filtering Model](#content-based)\n    * [K-nearest neighbours](#knn)       \n* [Collaboritive Filtering - Model](#collaboritive)\n    * [SVD - Singular Value Decomposition](#svd)  \n        - [Building a Utility Matrix](#u-matrix)\n        - [Transposing the Matrix](#transpose-matrix)\n        - [Decomposing the Matrix](#decompose-matrix)\n        - [Generating a correlation Matrix](#gen-corr-matrix)  \n        - [Isolating the most popular restaurant from the Correlation Matrix](#isolate)\n        - [Recommend highly correlated Restaurants](#recommend)                   \n    * [Neural Network - keras](#NN-keras)    \n        - [Prediction](#prediction)\n        - [Cosine similarity](#cos-similarity)\n        - [Recommendation](#recommendation)","a7d075a5":"<a id=\"cos-similarity\"><\/a>\n* **Cosine similarity**\n\nWe will be using the Cosine Similarity to calculate a numeric quantity that denotes the similarity between two restaurants. Therefore, we need to extract embedding layers from the Keras model to compute the cosine similarity by doing a dot product.","eaf31905":"We created the following function to get rid of the \"[ ]\" in \"cosine\" column.","866e6db6":"<a id=\"knn\"><\/a>\n## 1. K-Nearest Neighbours model (KNN)\n> \n>    - Split the data into train and test set  (80:20)\n>    - Instantiate and fit the model\n>    - Test the model: we used the last row as a validation set (we didn't include this last row to train the model)\n>    - Recommend restaurants for the validation set (the last restaurant in the df_final table)","98e5a658":"The \"Steak & Cheese & Quick Pita Restaurant\" is an authentic Lebanese cuisine (sandwiches). **Hooray!!!** We got our first recommendations from our model. All of those restaurants are have a common main menu which is making sandwiches.\n\n------------------------\n\nThe problem of the Content-Based Filtering Method is that it doesn't capture any information about users' preferences since it only cares about restaurant features. Next, we will implement the Collaborative Filtering Methods.","690ec985":"<a id=\"isolate\"><\/a>\n* **Isolating the most popular restaurant from the Correlation Matrix**\n\nIn our case, the most popular restaurant is \"Wvrst\". So we will extract the correlation values between \"Wvrst\" with all other restaurants from corr_matrix.","1fa29eaf":"The restaurant name of the validation set is \"Steak & Cheese & Quick Pita Restaurant\".","4bf9b643":"<a id=\"data\"><\/a>\n# Data\n\nWe are using subsets of each table since we have a large dataset to work with. For this notebook, we used _business_ and _review_ tables.","a0c1aec4":"We are using LabelEncoder from sklearn to encode business and user id's. We will create variables that store unique users, restaurants, min_rating, and max_rating.","75650c02":"<a id=\"recommend\"><\/a>\n* **Recommend Highly Correlated Restaurants**\n\nNow we will filter out the most correlated restaurant to \"Wvrst\" by applying the following conditions as shown below. **Yey!!!** There you go we have another recommender system.","026c2981":"Tada!!!! We have our restaurant recommendations. \n# Hopefully you have enjoyed and learned something new \ud83e\udd13\ud83e\udd29\ud83d\ude09!!!","09724009":"<a id=\"preprocessing-data\"><\/a>\n# Preprocessing the Data\n\nWe chose Toronto since it has the highest number of reviews in Canada. The restaurant is the most popular category among businesses. ","c479003d":"<a id=\"collaboritive\"><\/a>\n# Collaboritive Filtering - Model\n\nIn this section, we use the Collaborative Filtering technique to make a recommendation to restaurant users. This technique is based on the idea that similar users can have a similar restaurant preference. \n\nWe are implementing the following machine learning techniques to build a recommender system:\n1. Singular Value Decomposition model (SVD)\n2. Neural Network (Keras)","8945e230":"We will need another variable that stores the number of factors per user\/restaurant for the model. This number can be arbitrary. But for the Collaborative filtering model it needs to be the same size for both users and restaurants. \n\nFinally, we will store users and restaurants into separate arrays for the train and test set. It is because in Keras they\u2019ll each be defined as distinct inputs.","1550b3b5":"<a id=\"gen-corr-matrix\"><\/a>\n* **Generating a Correlation Matrix**\n\nWe calculated PearsonR coefficient for every restaurant pair in the result_matrix. The correlation-based on similarities between users' tastes. ","a5a0fa8e":"Let\u2019s go ahead and train this for a few epochs and see what we get.","f3b8b25a":"<a id=\"u-matrix\"><\/a>\n* **Building a Utility Matrix (User-Restaurant Matrix)**\n\nThis matrix contains each user, each restaurant, and the rating each user gave to each restaurant. Notice this matrix will be sparse because every user doesn't review every restaurant.","0b9c59db":"By creating the following table, we are able to see the model performance by comparing the actual stars and predictions.","60538215":"<a id=\"introduction\"><\/a>\n# Introduction\n\nIn this notebook, we are building a recommender system using Yelp Dataset. In order to build this system, we had two main approaches which are Content-Based Filtering and Collaborative Filtering. \n\n> * **Content-Based Filtering:** It is based on the features of the restaurants rather than the user features. The idea is if the user likes a restaurant then he\/she will like the other similar restaurants.\n> \u00a0\n> * **Collaborative Filtering:** It is based on the assumption that people like restaurants similar to other restaurants they like, and restaurants that are liked by other people with similar tastes.","1327d8ec":"* **Instantiate and fit the model**","35f836a2":"We are creating a function that calculates the cosine similarity between the target and the rest of the other restaurants and returns the table with the result.","83478915":"<a id=\"get-dummies\"><\/a>\n* ** Get Dummies from attributes and categories columns**\n\n> In \"attributes\" column has nested attributes. In order to create a feature table, we need to separate those nested attributes into their own columns. Therefore, the following functions will be used to achieve this goal.","0761542a":"The popular restaurant by ratings is **\"Wvrst\"**. It is a beer bar and they have few locations in Toronto. But the popular one is located at \"609 King Street W\". \n\nTheir webpage: https:\/\/wvrst.com\/ ","ded1ad87":"Split the data into train and test sets.","fcedf75d":"After fitting the KNN model to the validation set, we are going to find the distances between the validation set and the other restaurants based on their similar features. "}}