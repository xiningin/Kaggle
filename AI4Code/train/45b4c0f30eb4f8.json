{"cell_type":{"89158e4d":"code","1fd5e394":"code","da1109c5":"code","8febef23":"code","a8e90bc6":"code","e9b579fe":"code","f9e1d9a6":"code","fa1fff92":"code","d081c1d0":"code","561e6909":"code","eb160bb6":"code","618d0e25":"code","e879250d":"code","e0ec359e":"code","225b7833":"code","039e1d8e":"code","00b30318":"code","c52609bb":"code","447bf0dd":"code","9f2e318c":"code","3d62ac12":"code","a13502df":"code","3d937fde":"code","6f69474e":"code","7365840a":"code","0f3cfb67":"code","501e2809":"code","431d20d4":"code","95fefaad":"code","d9d95670":"code","bae1d448":"code","dcd32325":"code","ee5361da":"code","38235fcc":"code","b8e8ba79":"code","209a7e2f":"code","cdf5964e":"code","89f093c0":"code","34b1f722":"code","85166a84":"code","f68b811f":"code","aa4d91ea":"code","165dbfba":"code","e6e24100":"code","f4fa192e":"code","852e3b95":"code","cddaaf11":"code","cd809697":"code","6c453943":"code","b6808573":"code","dae8d26b":"markdown","97cf2556":"markdown","1c43c7b2":"markdown","8d196ce5":"markdown","256292fc":"markdown","859e0c6a":"markdown","b802271f":"markdown","47862fbe":"markdown","87af180a":"markdown","1a273c3e":"markdown","fd821403":"markdown","b1c440a0":"markdown","5a32e8c2":"markdown","0ed48b54":"markdown","a695ab8a":"markdown","2a356179":"markdown","9cfe37e6":"markdown","05b2f6a6":"markdown","73dacadd":"markdown","70933beb":"markdown","728b1388":"markdown","7622125d":"markdown","016d0764":"markdown","1f188ef4":"markdown","720d719f":"markdown","7ffe18ea":"markdown","180ee269":"markdown","4a4e33d4":"markdown","9295744b":"markdown","b748193f":"markdown","83ed6bd5":"markdown","7553c758":"markdown","74ef4001":"markdown","3ca453c3":"markdown","bf8e1b17":"markdown","9c5edadc":"markdown","446836a6":"markdown","a92eb219":"markdown","a1f9c943":"markdown","f244ab57":"markdown","bcb56d87":"markdown","3eca4880":"markdown","d796b76e":"markdown","4a24873e":"markdown"},"source":{"89158e4d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # this is used for the plot the graph \nimport seaborn as sns # used for plot interactive graph.\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.svm import SVC\n%matplotlib inline","1fd5e394":"## Read file\n\n\ndata = pd.read_csv('..\/input\/googleplaystore.csv')\nx=data\ndata.head(3)","da1109c5":"data.info()","8febef23":"data.shape","a8e90bc6":"import pandas_profiling\npandas_profiling.ProfileReport(data)","e9b579fe":"data.isnull().sum()","f9e1d9a6":"data[data['Rating'] == 19]","fa1fff92":"data.iloc[10472,1:] = data.iloc[10472,1:].shift(1)\ndata[10471:10473]","d081c1d0":"data[\"Last Updated\"] = pd.to_datetime(data['Last Updated'])\ndata['year_added']=data['Last Updated'].dt.year\ndata['month_added']=data['Last Updated'].dt.month","561e6909":"data.head(2)","eb160bb6":"data.columns","618d0e25":"import plotly\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\ncol = \"Type\"\ngrouped = data[col].value_counts().reset_index()\ngrouped = grouped.rename(columns = {col : \"count\", \"index\" : col})\n\n## plot\ntrace = go.Pie(labels=grouped[col], values=grouped['count'], pull=[0.05, 0])\nlayout = {'title': 'Target(0 = No, 1 = Yes)'}\nfig = go.Figure(data = [trace], layout = layout)\niplot(fig)","e879250d":"d1=x[x['Type']=='Free']\nd2=x[x['Type']=='Paid']","e0ec359e":"col='year_added'\nv1=d1[col].value_counts().reset_index()\nv1=v1.rename(columns={col:'count','index':col})\nv1['percent']=v1['count'].apply(lambda x : 100*x\/sum(v1['count']))\nv1=v1.sort_values(col)\nv2=d2[col].value_counts().reset_index()\nv2=v2.rename(columns={col:'count','index':col})\nv2['percent']=v2['count'].apply(lambda x : 100*x\/sum(v2['count']))\nv2=v2.sort_values(col)\ntrace1 = go.Scatter(x=v1[col], y=v1[\"count\"], name=\"Free\", marker=dict(color=\"#a678de\"))\ntrace2 = go.Scatter(x=v2[col], y=v2[\"count\"], name=\"Paid\", marker=dict(color=\"#6ad49b\"))\ny = [trace1, trace2]\nlayout={'title':\"app udated or added over the years\",'xaxis':{'title':\"years\"}}\nfig = go.Figure(data=y, layout=layout)\niplot(fig)","225b7833":"col='month_added'\nv1=d1[col].value_counts().reset_index()\nv1=v1.rename(columns={col:'count','index':col})\nv1['percent']=v1['count'].apply(lambda x : 100*x\/sum(v1['count']))\nv1=v1.sort_values(col)\ntrace1 = go.Bar(x=v1[col], y=v1[\"count\"], name=\"Free\", marker=dict())\nlayout={'title':\"Free App added over the month\",'xaxis':{'title':\"months\"}}\nfig = go.Figure(data=[trace1], layout=layout)\niplot(fig)","039e1d8e":"col='month_added'\nv2=d2[col].value_counts().reset_index()\nv2=v2.rename(columns={col:'count','index':col})\nv2['percent']=v2['count'].apply(lambda x : 100*x\/sum(v2['count']))\nv2=v2.sort_values(col)\ntrace1 = go.Bar(x=v2[col], y=v2[\"count\"], name=\"aid\", marker=dict())\nlayout={'title':\"Paid App added over the month\",'xaxis':{'title':\"months\"}}\nfig = go.Figure(data=[trace1], layout=layout)\niplot(fig)","00b30318":"\ncol='Content Rating'\nv1=d1[col].value_counts().reset_index()\nv1=v1.rename(columns={col:'count','index':col})\nv1['percent']=v1['count'].apply(lambda x : 100*x\/sum(v1['count']))\nv1=v1.astype(str).sort_values(col)\nv2=d2[col].value_counts().reset_index()\nv2=v2.rename(columns={col:'count','index':col})\nv2['percent']=v2['count'].apply(lambda x : 100*x\/sum(v2['count']))\nv2=v2.sort_values(col)\ntrace1 = go.Scatter(x=v1[col], y=v1[\"count\"], name=\"Free\", marker=dict(color=\"#a678de\"))\ntrace2 = go.Scatter(x=v2[col], y=v2[\"count\"], name=\"Paid\", marker=dict(color=\"#6ad49b\"))\ny = [trace1, trace2]\nlayout={'title':\"Ratings of the free vs paid app\",'xaxis':{'title':\"Ratings\"}}\nfig = go.Figure(data=y, layout=layout)\niplot(fig)","c52609bb":"col='Content Rating'\nv1=d1[col].value_counts().reset_index()\nv1=v1.rename(columns={col:'count','index':col})\nv1['percent']=v1['count'].apply(lambda x : 100*x\/sum(v1['count']))\nv1=v1.sort_values(col)\ntrace1 = go.Bar(x=v1[col], y=v1[\"count\"], name=\"Free\", marker=dict())\nlayout={'title':\"Free App Content Rating \",'xaxis':{'title':\"Contents\"}}\nfig = go.Figure(data=[trace1], layout=layout)\niplot(fig)","447bf0dd":"col='Content Rating'\nv2=d2[col].value_counts().reset_index()\nv2=v2.rename(columns={col:'count','index':col})\nv2['percent']=v2['count'].apply(lambda x : 100*x\/sum(v2['count']))\nv2=v2.sort_values(col)\ntrace1 = go.Bar(x=v2[col], y=v2[\"count\"], name=\"aid\",  marker=dict(color=\"#6ad49b\"))\nlayout={'title':\"Paid App Content Rating\",'xaxis':{'title':\"contents\"}}\nfig = go.Figure(data=[trace1], layout=layout)\niplot(fig)","9f2e318c":"\ncol='Rating'\nv1=d1[col].value_counts().reset_index()\nv1=v1.rename(columns={col:'count','index':col})\nv1['percent']=v1['count'].apply(lambda x : 100*x\/sum(v1['count']))\nv1=v1.astype(str).sort_values(col)\nv2=d2[col].value_counts().reset_index()\nv2=v2.rename(columns={col:'count','index':col})\nv2['percent']=v2['count'].apply(lambda x : 100*x\/sum(v2['count']))\nv2=v2.sort_values(col)\ntrace1 = go.Scatter(x=v1[col], y=v1[\"count\"], name=\"Free\", marker=dict(color=\"#a678de\"))\ntrace2 = go.Scatter(x=v2[col], y=v2[\"count\"], name=\"Paid\", marker=dict(color=\"#6ad49b\"))\ny = [trace1, trace2]\nlayout={'title':\"Ratings of the free vs paid app\",'xaxis':{'title':\"Ratings\"}}\nfig = go.Figure(data=y, layout=layout)\niplot(fig)","3d62ac12":"col='Rating'\nv1=d1[col].value_counts().reset_index()\nv1=v1.rename(columns={col:'count','index':col})\nv1['percent']=v1['count'].apply(lambda x : 100*x\/sum(v1['count']))\ntrace1 = go.Bar(x=v1[col], y=v1[\"count\"], name=\"Free\", marker=dict())\nlayout={'title':\"Free App Rating\",'xaxis':{'title':\"Ratings\"}}\nfig = go.Figure(data=[trace1], layout=layout)\niplot(fig)","a13502df":"col='Rating'\nv2=d2[col].value_counts().reset_index()\nv2=v2.rename(columns={col:'count','index':col})\nv2['percent']=v2['count'].apply(lambda x : 100*x\/sum(v2['count']))\nv2=v2.sort_values(col)\ntrace1 = go.Bar(x=v2[col], y=v2[\"count\"], name=\"Paid\",  marker=dict(color=\"#6ad49b\"))\nlayout={'title':\"Paid App Rating\",'xaxis':{'title':\"Ratingss\"}}\nfig = go.Figure(data=[trace1], layout=layout)\niplot(fig)","3d937fde":"\ncol='Category'\nv1=d1[col].value_counts().reset_index()\nv1=v1.rename(columns={col:'count','index':col})\nv1['percent']=v1['count'].apply(lambda x : 100*x\/sum(v1['count']))\nv1=v1.sort_values(col)\nv2=d2[col].value_counts().reset_index()\nv2=v2.rename(columns={col:'count','index':col})\nv2['percent']=v2['count'].apply(lambda x : 100*x\/sum(v2['count']))\nv2=v2.sort_values(col)\ntrace1 = go.Scatter(x=v1[col], y=v1[\"count\"], name=\"Free\", marker=dict(color=\"#a678de\"))\ntrace2 = go.Scatter(x=v2[col], y=v2[\"count\"], name=\"Paid\", marker=dict(color=\"#6ad49b\"))\ny = [trace1, trace2]\nlayout={'title':\"App Category\"}\nfig = go.Figure(data=y, layout=layout)\niplot(fig)","6f69474e":"col='Android Ver'\nv1=d1[col].value_counts().reset_index()\nv1=v1.rename(columns={col:'count','index':col})\nv1['percent']=v1['count'].apply(lambda x : 100*x\/sum(v1['count']))\nv1=v1.sort_values(col)\nv2=d2[col].value_counts().reset_index()\nv2=v2.rename(columns={col:'count','index':col})\nv2['percent']=v2['count'].apply(lambda x : 100*x\/sum(v2['count']))\nv2=v2.sort_values(col)\ntrace1 = go.Scatter(x=v1[col], y=v1[\"count\"], name=\"Free\", marker=dict(color=\"#a678de\"))\ntrace2 = go.Scatter(x=v2[col], y=v2[\"count\"], name=\"Paid\", marker=dict(color=\"#6ad49b\"))\ny = [trace1, trace2]\nlayout={'title':\"Android Versions\"}\nfig = go.Figure(data=y, layout=layout)\niplot(fig)","7365840a":"col='Installs'\nv1=d1[col].value_counts().reset_index()\nv1=v1.rename(columns={col:'count','index':col})\nv1['percent']=v1['count'].apply(lambda x : 100*x\/sum(v1['count']))\nv1=v1.sort_values(col)\nv2=d2[col].value_counts().reset_index()\nv2=v2.rename(columns={col:'count','index':col})\nv2['percent']=v2['count'].apply(lambda x : 100*x\/sum(v2['count']))\nv2=v2.sort_values(col)\ntrace1 = go.Scatter(x=v1[col], y=v1[\"count\"], name=\"Free\", marker=dict(color=\"#a678de\"))\ntrace2 = go.Scatter(x=v2[col], y=v2[\"count\"], name=\"Paid\", marker=dict(color=\"#6ad49b\"))\ny = [trace1, trace2]\nlayout={'title':\"Installed App \",'xaxis':{'title':\"Installs\"}}\nfig = go.Figure(data=y, layout=layout)\niplot(fig)","0f3cfb67":"d3=x[x['Rating']==4.5]\nd4=x[x['Rating']==4]","501e2809":"col='Content Rating'\nv1=d3[col].value_counts().reset_index()\nv1=v1.rename(columns={col:'count','index':col})\nv1['percent']=v1['count'].apply(lambda x : 100*x\/sum(v1['count']))\nv1=v1.sort_values(col)\nv2=d4[col].value_counts().reset_index()\nv2=v2.rename(columns={col:'count','index':col})\nv2['percent']=v2['count'].apply(lambda x : 100*x\/sum(v2['count']))\nv2=v2.sort_values(col)\ntrace1 = go.Bar(x=v1[col], y=v1[\"count\"], name=\"rating = 4.5\", marker=dict(color=\"#6ad49b\"))\ntrace2 = go.Bar(x=v2[col], y=v2[\"count\"], name=\"rating = 4\", marker=dict())\ny = [trace1, trace2]\nlayout={'title':\"Rating over the contents\",'xaxis':{'title':\"Content Rating\"}}\nfig = go.Figure(data=y, layout=layout)\niplot(fig)","431d20d4":"col='Android Ver'\nv1=d3[col].value_counts().reset_index()\nv1=v1.rename(columns={col:'count','index':col})\nv1['percent']=v1['count'].apply(lambda x : 100*x\/sum(v1['count']))\nv1=v1.sort_values(col)\nv2=d4[col].value_counts().reset_index()\nv2=v2.rename(columns={col:'count','index':col})\nv2['percent']=v2['count'].apply(lambda x : 100*x\/sum(v2['count']))\nv2=v2.sort_values(col)\ntrace1 = go.Scatter(x=v1[col], y=v1[\"count\"], name=\"rating = 4.5\", marker=dict(color=\"#a678de\"))\ntrace2 = go.Scatter(x=v2[col], y=v2[\"count\"], name=\"rating = 4\", marker=dict(color=\"#6ad49b\"))\ny = [trace1, trace2]\nlayout={'title':\"Rating over the Android Version \"}\nfig = go.Figure(data=y, layout=layout)\niplot(fig)","95fefaad":"col='Category'\nv1=d3[col].value_counts().reset_index()\nv1=v1.rename(columns={col:'count','index':col})\nv1['percent']=v1['count'].apply(lambda x : 100*x\/sum(v1['count']))\nv1=v1.sort_values(col)\nv2=d4[col].value_counts().reset_index()\nv2=v2.rename(columns={col:'count','index':col})\nv2['percent']=v2['count'].apply(lambda x : 100*x\/sum(v2['count']))\nv2=v2.sort_values(col)\ntrace1 = go.Bar(x=v1[col], y=v1[\"count\"], name=\"rating = 4.5\", marker=dict(color=\"#a678de\"))\ntrace2 = go.Bar(x=v2[col], y=v2[\"count\"], name=\"rating = 4\", marker=dict())\ny = [trace1, trace2]\nlayout={'title':\"Category wise Rating\"}\nfig = go.Figure(data=y, layout=layout)\niplot(fig)","d9d95670":"col='Installs'\nv1=d3[col].value_counts().reset_index()\nv1=v1.rename(columns={col:'count','index':col})\nv1['percent']=v1['count'].apply(lambda x : 100*x\/sum(v1['count']))\nv1=v1.sort_values(col)\nv2=d4[col].value_counts().reset_index()\nv2=v2.rename(columns={col:'count','index':col})\nv2['percent']=v2['count'].apply(lambda x : 100*x\/sum(v2['count']))\nv2=v2.sort_values(col)\ntrace1 = go.Scatter(x=v1[col], y=v1[\"count\"], name=\"rating = 4.5\", marker=dict(color=\"#a678de\"))\ntrace2 = go.Scatter(x=v2[col], y=v2[\"count\"], name=\"rating = 4\", marker=dict(color=\"#6ad49b\"))\ny = [trace1, trace2]\nlayout={'title':\"Rating over total Installs \",'xaxis':{'title':\"Installs\"}}\nfig = go.Figure(data=y, layout=layout)\niplot(fig)","bae1d448":"data.isnull().sum().sum()","dcd32325":"total=data.isnull().sum()\npercent = (data.isnull().sum()\/data.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(13)","ee5361da":"data.dropna(inplace=True)","38235fcc":"data.shape","b8e8ba79":"data.head(3)","209a7e2f":"catgry=pd.get_dummies(data['Category'],prefix='catg',drop_first=True)\ntyp=pd.get_dummies(data['Type'],prefix='typ',drop_first=True)\ncr=pd.get_dummies(data['Content Rating'],prefix='cr',drop_first=True)\nframes=[data,catgry,typ,cr]\ndata=pd.concat(frames,axis=1)\ndata.drop(['Category','Installs','Type','Content Rating'],axis=1,inplace=True)","cdf5964e":"data.drop(['App','Size','Price','Genres','Last Updated','Current Ver','Android Ver'],axis=1,inplace=True)","89f093c0":"data.head(3)","34b1f722":"X=data.drop('Rating',axis=1)\ny=data['Rating'].values\ny=y.astype('int')","85166a84":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)","f68b811f":"from sklearn.preprocessing import StandardScaler\nsc_X=StandardScaler()\nX_train=sc_X.fit_transform(X_train)\nX_test=sc_X.transform(X_test)","aa4d91ea":"#LogisticRegression\nlr_c=LogisticRegression(random_state=0)\nlr_c.fit(X_train,y_train)\nlr_pred=lr_c.predict(X_test)\nlr_cm=confusion_matrix(y_test,lr_pred)\nlr_ac=accuracy_score(y_test, lr_pred)\nprint('LogisticRegression_accuracy:',lr_ac)","165dbfba":"plt.figure(figsize=(10,5))\nplt.title(\"lr_cm\")\nsns.heatmap(lr_cm,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False)\nplt.show()","e6e24100":"# DecisionTree Classifier\ndtree_c=DecisionTreeClassifier(criterion='entropy',random_state=0)\ndtree_c.fit(X_train,y_train)\ndtree_pred=dtree_c.predict(X_test)\ndtree_cm=confusion_matrix(y_test,dtree_pred)\ndtree_ac=accuracy_score(dtree_pred,y_test)","f4fa192e":"plt.figure(figsize=(10,5))\nplt.title(\"dtree_cm\")\nsns.heatmap(dtree_cm,annot=True,fmt=\"d\",cbar=False)\nprint('DecisionTree_Classifier_accuracy:',dtree_ac)","852e3b95":"#SVM regressor\nsvc_r=SVC(kernel='rbf')\nsvc_r.fit(X_train,y_train)\nsvr_pred=svc_r.predict(X_test)\nsvr_cm=confusion_matrix(y_test,svr_pred)\nsvr_ac=accuracy_score(y_test, svr_pred)","cddaaf11":"plt.figure(figsize=(10,5))\nplt.title(\"svm_cm\")\nsns.heatmap(svr_cm,annot=True,cmap=\"Oranges\",fmt=\"d\",cbar=False)\nprint('SVM_regressor_accuracy:',svr_ac)","cd809697":"#RandomForest\nrdf_c=RandomForestClassifier(n_estimators=10,criterion='entropy',random_state=0)\nrdf_c.fit(X_train,y_train)\nrdf_pred=rdf_c.predict(X_test)\nrdf_cm=confusion_matrix(y_test,rdf_pred)\nrdf_ac=accuracy_score(rdf_pred,y_test)","6c453943":"plt.figure(figsize=(10,5))\nplt.title(\"rdf_cm\")\nsns.heatmap(rdf_cm,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False)\nprint('RandomForest_accuracy:',rdf_ac)","b6808573":"%matplotlib inline\nmodel_accuracy = pd.Series(data=[lr_ac,dtree_ac,svr_ac,rdf_ac], \n        index=['Logistic_Regression','DecisionTree_Classifier','SVM_regressor_accuracy','RandomForest'])\nfig= plt.figure(figsize=(8,8))\nmodel_accuracy.sort_values().plot.barh()\nplt.title('Model Accracy')","dae8d26b":"**SEE!!** told you already that people like free service more than paid service.","97cf2556":"We already discuss about the category of the apps that most of the apps are belongs to the category of Family Game and Tools. --> 2nd most category of apps are **Games** kids now these days!!!","1c43c7b2":"In this google playstore data Almost 50% apps are available on the playstore are added or updated on the month of July, 25% of apps are updated or added on the month of August and rest of 25% remaing months. (please don't ask me the reason i don't know !!) .","8d196ce5":"By viewing this we say that in this row all data are placed wrong by one position so we shift the data to the right hand size and make correct position.","256292fc":"By ovserving the above plot highest installs of the apps are crossing the 1M than 10M than 100k, very less app are crossing the 500M and dream install **1B** .\nsome apps like Instagram, Youtoube, Facebook Whtsapp etc are crossing the dream installs 1B.","859e0c6a":"### Type","b802271f":"Here we added 2 more columns in the data set by spliting the last updated attribute, by doing this we find that in which year apps are added or updated on playstore.","47862fbe":"## Data Visualization","87af180a":"## Training & Testing of Model","1a273c3e":"##### >>By shifting the row right by 1 we get actual value of rating\n###### >>We see that the app 'Life Made WI-Fi Touchscreen Photo Frame' does not have any category,when we search this app on play store we found that it belong to lifestyle category.","fd821403":"# Import libraries","b1c440a0":"## Summary","5a32e8c2":"## Data Cleaning","0ed48b54":"Most important things about apps are there rating we even didn't see the app's whose ratings are less than 3.5 . Before downloading the app first we see the rating of app if the app rating is more then 4 than we say that yeah this is a good category of app then after we see other attribute of apps. Very less people see the review's of app. My personal observation is that some of the good people who are pationate about the technology and have enough time give the review of app. (**we are data scientist and our maximum time goes in the cleaning of data**).","a695ab8a":"Here we use pandas profilling to analyse whole set of data.\nPandas profiling provides analysis like type, unique values, missing values, quantile statistics, mean, mode, median, standard deviation, sum, skewness, frequent values, histograms, correlation between variables, count, heatmap visualization, etc.","2a356179":"## Rating","9cfe37e6":"###  Models comparision\n> The key to a fair comparison of machine learning algorithms is ensuring that each algorithm is evaluated in the same way on the same data. You can achieve this by forcing each algorithm to be evaluated on a consistent test harness. In this notebbok 4 different algorithms are compared","05b2f6a6":"SVM regressor\n>  As the name suggest the SVR is an regression algorithm , so we can use SVR for working with continuous Values instead of Classification which is SVM","73dacadd":"### Why google like month of **July** most !?","70933beb":"##### >> Spliting the 80% of the dataset into train_data and 20% of the dataset into test_data","728b1388":"##### >> StandardScaler will transform your data such that its distribution will have a mean value 0 and standard deviation of 1. Given the distribution of the data, each value in the dataset will have the sample mean value subtracted, and then divided by the standard deviation of the whole dataset.","7622125d":"<img src=\"https:\/\/www.picclickimg.com\/d\/l400\/pict\/323278941996_\/Life-Made-Wi-Fi-Digital-Touch-Screen-7-Picture-Frame.jpg\" style=\"width: 550px;\"\/>\n","016d0764":"## Creating Dummy Variables","1f188ef4":"From google playstore dataset, I decide to make some simple notebook for Exploratory Data Analysis\nand do some wrangling data for put it on my prediction model in future ","720d719f":"## Type","7ffe18ea":"#### while preprocessing and viewing the data we observe that in this Datasets the maximum rating of an app is 19 which is not posible yet,we know that the maximum rating of an app in the google play store is 5. >>so we confenditly says that something wrong.","180ee269":"Here we see that 92.6% apps are freee and 7.38% apps are paid on google playstore. so we say that Most of the people love free services including me :)","4a4e33d4":"###### >>here we comparing with other and see the difference","9295744b":"### Work IN Progress","b748193f":"# Introduction","83ed6bd5":"<img src=\"https:\/\/cdn-images-1.medium.com\/max\/1600\/1*OIIv4FEjJQMqh-zEPhtlYA.png\" style=\"width: 750px;\"\/>","7553c758":"DecisionTree Classifier\n> A decision tree classifier is a tree in which internal nodes are labeled by features. ... The classifier categorizes an object xi by recursively testing for the weights that the features labeling the internal nodes have in vector xi, until a leaf node is reached. The label of this node is then assigned to xi","74ef4001":"###### >>initialy our data contain 10841 records and 13 fields here we see after removing missing data our data contain 9360 records with 13 fields.","3ca453c3":"Data collection is the process of gathering and measuring data, information or any variables of interest in a standardized and established manner that enables the collector to answer or test hypothesis and evaluate outcomes of the particular collection.[techopedia]","bf8e1b17":"* App: Application name\n* Category: Category the app belongs to\n* Rating: Overall user rating of the app (as when scraped)\n* Reviews: Number of user reviews for the app (as when scraped)\n* Size: Size of the app (as when scraped)\n* Installs: Number of user downloads\/installs for the app (as when scraped)\n* Type: Paid or Free\n* Price: Price of the app (as when scraped)\n* Content Rating: Age group the app is targeted at - Children \/ Mature 21+ \/ Adult\n* Genres: An app can belong to multiple genres (apart from its main category). For eg, a musical family game will belong to Music, Game, Family genres.\n* Last Updated: Date when the app was last updated on Play Store (as when scraped)\n* Current Ver: Current version of the app available on Play Store (as when scraped)\n* Android Ver: Min required Android version (as when scraped)","9c5edadc":"No google is not bias beacuse they consider all of us proof!! --> see the above plot most of the app content rating rating are for everyone and most of them are Free.","446836a6":"# Data Collection","a92eb219":"Logestic Regression\n> Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model (a form of binary regression).\n","a1f9c943":"## Is Google Bias ??","f244ab57":"In the above plot we plot the app updated or added over the year Free vs Paid. By observing this plot we conclude that before 2011 there were no paid apps (after that google thinks that people have lots of money so why not take some charge for some apps >> just for fun ).\nBut with the year free apps are added in huge ammount in comparision to paid apps --> people does not like paid services.\n> By compairing the app updated or added in the year 2011 and 2018 free apps are increases from 80% to 96% and paid apps are goes from 20% to 4%.\n","bcb56d87":"## Feature selection\n\n### >> Xstant=X-mean(X)\/st.dev(X)\n\n### >> Xnorm=X-min(X)\/max(X)-min(X)","3eca4880":"In this notebook we use pandas, numpy, pandas profiling for data preprocessiong and for visualization we use matplotlib, seaborn and mostly plotly. By working on the google playstore data we conclude that most of the apps are free and their category are related to family, gaming and certains tools. Most of the content of these apps are for everyone. Most of the people pay for the category of family and medical apps. Here we use different machine learning model to predict the app ratings and also compare the model performence.","d796b76e":"## I hope this kernel is helpfull for you -->> upvote will appreciate me for further work.","4a24873e":"RandomForest\n> The random forest is a classification algorithm consisting of many decisions trees. It uses bagging and feature randomness when building each individual tree to try to create an uncorrelated forest of trees whose prediction by committee is more accurate than that of any individual tree"}}