{"cell_type":{"b52082a4":"code","513e3f8c":"code","8b49ec08":"code","bca3300c":"code","a886abef":"code","6bacb659":"code","65a0e658":"code","896ad852":"code","3e799170":"code","f63db8c5":"code","a6beb358":"code","ec605b39":"code","47f1661a":"code","4154781c":"markdown","702439fb":"markdown","e86d718f":"markdown"},"source":{"b52082a4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","513e3f8c":"df = pd.read_csv(\"\/kaggle\/input\/poezii-in-limba-romana\/train.csv\")\nprint(df.shape)\ndf.head()","8b49ec08":"import nltk \nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nimport re\nimport string\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import normalize\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import GaussianNB","bca3300c":"##Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'pink',\n                      height =2000,\n                      width = 2000\n                     ).generate(str(df[\"Versuri\"]))\nplt.rcParams['figure.figsize'] = (12,12)\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.title(\"Versuri - Poezii Rom\u00e2n\u0103\")\nplt.show()","a886abef":"def removePunctuation(x):\n    x = x.lower()\n    x = re.sub(r'[^\\x00-\\x7f]',r' ',x)\n    x = x.replace('\\r','')\n    x = x.replace('\\n','')\n    x = x.replace('  ','')\n    x = x.replace('\\'','')\n    return re.sub(\"[\"+string.punctuation+\"]\", \" \", x)","6bacb659":"#https:\/\/stackoverflow.com\/questions\/51534586\/add-and-remove-words-from-the-nltk-stopwords-list\n\nfrom nltk.corpus import stopwords\n\nstop_words = set(stopwords.words('romanian'))\n\n#add words that aren't in the NLTK stopwords list\nnew_stopwords = ['ne', 'ar', 'toti', 'acea']\nnew_stopwords_list = stop_words.union(new_stopwords)\n\n#remove words that are in NLTK stopwords list\nnot_stopwords = {'frunzare', 'eterna', 'care'} \nfinal_stop_words = set([word for word in new_stopwords_list if word not in not_stopwords])\n\nprint(final_stop_words)","65a0e658":"def processText(x):\n    x= removePunctuation(x)\n    #x= removeStopwords(x)\n    return x","896ad852":"from nltk.tokenize import sent_tokenize, word_tokenize\ntin = pd.Series([word_tokenize(processText(x)) for x in df['Versuri']])\ntin.head(10)","3e799170":"from gensim.models import word2vec\nnum_features = 300    # Word vector dimensionality                      \nmin_word_count = 40   # Minimum word count                        \nnum_workers = 4       # Number of threads to run in parallel\ncontext = 10          # Context window size                                                                                    \ndownsampling = 1e-3   # Downsample setting for frequent words\nmodel = word2vec.Word2Vec(tin, workers=num_workers, \n                          min_count = min_word_count,\n                          window = context, sample = downsampling)","f63db8c5":"from gensim import utils\nimport logging\nfrom timeit import default_timer\nimport threading\nfrom six.moves import range\nfrom six import itervalues, string_types\nfrom gensim import matutils\nfrom numpy import float32 as REAL, ones, random, dtype\nfrom types import GeneratorType\nfrom gensim.utils import deprecated\nimport os\nimport copy","a6beb358":"def most_similar(self, positive=None, negative=None, topn=10, restrict_vocab=None, indexer=None):\n        \"\"\"Deprecated, use self.wv.most_similar() instead.\n        Refer to the documentation for :meth:`~gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.most_similar`.\n        \"\"\"\n        return self.wv.most_similar(positive, negative, topn, restrict_vocab, indexer)","ec605b39":"#model.most_similar('urm\u0103')#most_similar() is now a part of KeyedVectors\nmodel.wv.most_similar('fata') ","47f1661a":"#Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'purple',\n                      height =2000,\n                      width = 2000\n                     ).generate(str(df[\"Autor\"]))\nplt.rcParams['figure.figsize'] = (12,12)\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.title(\"Autors Poezii Rom\u00e2n\u0103\")\nplt.show()","4154781c":"size=num_features \nWas removed from model= word2vec.Word2Vec(tin, workers=num_workers, size=num_features.........","702439fb":"#Poezii \u00een limba rom\u00e2n\u0103\n\nClasificarea versurilor \u00een limba rom\u00e2n\u0103 dup\u0103 autor\n\n![](https:\/\/i.postimg.cc\/9Q6dvqnv\/boboceii.jpg)latimp.net\nhttps:\/\/latimp.net\/forum\/thread\/25478\/poezii-in-imagini-pentru-clasa-pregatitoare-comunicare-in-limba-romana\/","e86d718f":"#Code by Andrea Sindico  https:\/\/www.kaggle.com\/asindico\/love-for-poems\/notebook"}}