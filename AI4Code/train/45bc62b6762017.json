{"cell_type":{"0c52ca2e":"code","97c43c8d":"code","bd02d8f2":"code","0d50c33b":"code","89d24fd5":"code","074106e3":"code","c4e5711c":"code","1c7dca67":"code","75e9daba":"code","f4c15443":"code","d6137480":"code","c8e70295":"code","e1abe54f":"code","4839992a":"code","614634fc":"code","ee6b913f":"code","70ec9c16":"code","56858d3f":"code","b7c4fca1":"code","91e110b3":"code","62c0f874":"code","97d9068b":"code","3f624021":"code","83fcd85c":"code","6400f933":"code","f9aeb9f5":"code","af7f6445":"code","032180e4":"code","59b0e50e":"code","e466e079":"code","dc31482e":"code","9432131c":"code","78692598":"code","0495f3bd":"code","3fc72d46":"code","1dc08331":"code","53b0f55e":"code","5e3b0cd7":"code","33cfc66b":"code","6b8126fd":"code","28815380":"code","aafa89fb":"code","8d683dd1":"code","30ed6bca":"code","a51a7f7a":"code","86840a37":"code","d0c76898":"code","afb22f80":"code","f0283311":"code","941e3d87":"code","a2d00588":"code","b95c6bcb":"code","642883a5":"code","751b0b96":"code","d2cadf5c":"code","ca61a5df":"code","0bff846e":"code","b9db975c":"code","a7034564":"code","c6f86826":"code","dfc52b99":"code","44026867":"code","172e4150":"code","f241b28b":"code","293c6f6d":"code","d035ed4b":"code","d5b5f2c0":"markdown","930ea752":"markdown","1c4037ec":"markdown","271378be":"markdown","fd9dd218":"markdown","3e84fb61":"markdown","b258b929":"markdown","d4dd149c":"markdown","722f69aa":"markdown","5ca1a1fd":"markdown","4839ed7c":"markdown","1a4b38e7":"markdown","97f72d48":"markdown","864574ff":"markdown","38a7beb2":"markdown","a573cdfb":"markdown","e0d2b8a0":"markdown","5c631737":"markdown","b7b7f324":"markdown","2ea00f4c":"markdown","d1bd57db":"markdown","4bd371c0":"markdown","ecdc0a0f":"markdown","92c931d6":"markdown","95507ad5":"markdown","9b44958b":"markdown","84665c55":"markdown","46c75df8":"markdown","9053fec3":"markdown","cdb04ad1":"markdown","54847aab":"markdown","48d33311":"markdown","751ff4ab":"markdown","40850845":"markdown","c1ae79ac":"markdown","23c93849":"markdown","80e0f29c":"markdown"},"source":{"0c52ca2e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings('ignore')\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","97c43c8d":"#importing libraries required \npd.options.display.max_columns = 100\npd.options.display.max_rows = 900\npd.set_option('float_format' , '{:f}'.format)\n\nimport matplotlib \nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n","bd02d8f2":"#reading the two data sets and merging them into a single data frame\ndf1_1 = pd.read_csv(\"..\/input\/fraud-detection\/fraudTrain.csv\")\ndf1_1 = df1_1.drop(df1_1.columns[0], axis=1)\n\ndf1_2 = pd.read_csv(\"..\/input\/fraud-detection\/fraudTest.csv\")\ndf1_2 = df1_2.drop(df1_2.columns[0], axis=1)\n\ndf = pd.concat([df1_1,df1_2])\ndf.head(6)\n\n#we have 22 different features look at the table below","0d50c33b":"#inspecting data\ndf.info()","89d24fd5":"#checking if any of the data in the dataset downloaded had any missing values so that we can skip that row, \ndf.isnull().sum()","074106e3":"#to check the shape(rows and colums ) in the data frame\ndf.shape","c4e5711c":"df_fraud=df[['is_fraud','trans_date_trans_time']].groupby('is_fraud').count().reset_index()\ndf_fraud.columns=['is_fraud','count']\ndf_fraud['percentage']=(df_fraud['count']\/df_fraud['count'].sum())*100\ndf_fraud","1c7dca67":"#Finiding unique values in each column\ndf.nunique()","75e9daba":"df[\"trans_date_trans_time\"] = pd.to_datetime(df['trans_date_trans_time'])","f4c15443":"df.dtypes['trans_date_trans_time']","d6137480":"df['trans_hour'] = df['trans_date_trans_time'].dt.hour\ndf['trans_hour']","c8e70295":"df['day_of_week'] = df['trans_date_trans_time'].dt.day_name()\ndf['day_of_week']","e1abe54f":"df.head()","4839992a":"df['year_month'] = df['trans_date_trans_time'].dt.to_period('M')\ndf['year_month']","614634fc":"df.head()\n","ee6b913f":"plt.figure(figsize=(20,8))\nplt.subplot(1,2,1)\ndf['category'].value_counts().plot.bar();\nplt.subplot(1,2,2)\ndf['day_of_week'].value_counts().plot.bar();","70ec9c16":"plt.figure(figsize=(20,8))\nplt.subplot(1,2,1)\ndf['gender'].value_counts().plot.bar();\nplt.subplot(1,2,2)\ndf['year_month'].value_counts().plot.bar();","56858d3f":"df.state.value_counts(normalize=True)","b7c4fca1":"df.job.value_counts(normalize = True , ascending= False)","91e110b3":"df['dob'] = pd.to_datetime(df['dob'])\ndf['age'] = np.round((df['trans_date_trans_time']- df['dob'])\/np.timedelta64(1,'Y'))\ndf['age']","62c0f874":"df.age.describe()","97d9068b":"pd.concat(\n[df['amt'].describe(percentiles = [0.5,0.95,0.999])\\\n.reset_index().rename(columns={'index': 'Row Type', 'amt':'Overall Amt Distribution'}),\ndf.loc[df['is_fraud']==0,['amt']].describe(percentiles = [0.5,0.95,0.999])\\\n.reset_index(drop = 1).rename(columns={'amt':'Non-Fraud Amt Distribution'}),\ndf.loc[df['is_fraud']==1,['amt']].describe(percentiles = [0.5,0.95,0.999])\\\n.reset_index(drop = 1).rename(columns={'amt':'Fraud Amt Distribution'})],\naxis=1\n)","3f624021":"fig, ax = plt.subplots(1,3,figsize=(20,5))\nax[0].hist(df[df.amt<=1500].amt, bins=50)\nax[1].hist(df[(df.is_fraud==0) & (df.amt<=1500)].amt, bins=50)\nax[2].hist(df[(df.is_fraud==1) & (df.amt<=1500)].amt, bins=50)\n\nax[0].set_title('Overall Amt Distribution')\nax[1].set_title('Non Fraud Amt Distribution')\nax[2].set_title('Fraud Amt Distribution')\n\nax[0].set_xlabel('Transaction Amount')\nax[0].set_ylabel('#.of Transactions')\n\nax[1].set_xlabel('Transaction Amount')\nax[2].set_xlabel('Transaction Amount')\nplt.show()","83fcd85c":"num_cols=['amt']\nplt.figure(figsize=[10,10])\nfor ind, col in enumerate(num_cols):\n    plt.subplot(1,2,ind+1)\n    df[col].plot.box()\n    plt.title(col)\nplt.show()","6400f933":"df_timeline01 = df.groupby(df['year_month'])[['trans_num','cc_num']].nunique().reset_index()\ndf_timeline01.columns = ['year_month','num_of_transactions','customers']\ndf_timeline01","f9aeb9f5":"x = np.arange(0,len(df_timeline01),1)\n\nfig, ax = plt.subplots(1,1,figsize=(20,5))\nax.plot(x,df_timeline01['num_of_transactions'])\nax.set_xticks(x)\nax.set_xticklabels(df_timeline01['year_month'])\n\nax.set_xlabel('Year Month')\nax.set_ylabel('Num of Transactions')\nplt.show()\n","af7f6445":"df_fraud_transactions = df[df['is_fraud']==1]\n\ndf_timeline02 = df_fraud_transactions.groupby(df_fraud_transactions['year_month'])[['trans_num','cc_num']].nunique().reset_index()\ndf_timeline02.columns = ['year_month','num_of_fraud_transactions','fraud_customers']\ndf_timeline02","032180e4":"print(df_timeline02['num_of_fraud_transactions'].mean())","59b0e50e":"df_gender = df[['gender','trans_num']].groupby(['gender']).count().reset_index()\ndf_gender.columns = ['Gender','gender_count']\n\ndf_gender['percent'] = (df_gender['gender_count']\/df_gender['gender_count'].sum())*100\n\ndf_gender","e466e079":"plt.bar(df_gender['Gender'], df_gender['gender_count'], color=(0.2,0.4,1,1),  \n        width = 0.4)\n\nplt.show()","dc31482e":"df_fraud_gender = df[['gender','is_fraud','trans_num']].groupby(['gender','is_fraud']).count().reset_index()\ndf_fraud_gender.columns = ['Gender','is_fraud','count']\n\ndf_fraud_gender = df_fraud_gender.merge(df_gender[['Gender','gender_count']],how='inner',\\\n                                  left_on='Gender',right_on='Gender')\n\n\ndf_fraud_gender['percent_grp'] = (df_fraud_gender['count']\/df_fraud_gender['gender_count'])*100\n\n\ndf_fraud_gender","9432131c":"df_category = df[['category','trans_num']].groupby(['category']).count().reset_index()\ndf_category.columns = ['Category','category_count']\n\ndf_category['percent'] = (df_category['category_count']\/df_category['category_count'].sum())*100\n\ndf_category.sort_values(by = ['percent'], ascending=False).reset_index()\ndf_category","78692598":"df_fraud_category = df[['category','is_fraud','trans_num']].groupby(['category','is_fraud']).count().reset_index()\ndf_fraud_category.columns = ['Category','is_fraud','count']\n\ndf_fraud_category = df_fraud_category.merge(df_category[['Category','category_count','percent']],how='inner',\\\n                                  left_on='Category',right_on='Category')\n\n\ndf_fraud_category['percent_grp'] = (df_fraud_category['count']\/df_fraud_category['category_count'])*100\n\ndf_fraud_category.sort_values(by = ['category_count'], ascending=False)","0495f3bd":"df_fraud=df_fraud_category[df_fraud_category['is_fraud'] == 1].sort_values(by = ['percent_grp'])\ndf_fraud","3fc72d46":"df.merchant.value_counts(normalize=True, ascending=False)","1dc08331":"df_merchant = df[['merchant','trans_num']].groupby(['merchant']).count().reset_index()\ndf_merchant.columns = ['Merchant','merchant_count']\n\ndf_merchant['percent'] = (df_merchant['merchant_count']\/df_merchant['merchant_count'].sum())*100\n\ndf_merchant.sort_values(by = ['percent'], ascending=False)","53b0f55e":"df_fraud_merchant = df[['merchant','is_fraud','trans_num']].groupby(['merchant','is_fraud']).count().reset_index()\ndf_fraud_merchant.columns = ['Merchant','is_fraud','count']\n\ndf_fraud_merchant = df_fraud_merchant.merge(df_merchant[['Merchant','merchant_count','percent']],how='inner',\\\n                                  left_on='Merchant',right_on='Merchant')\n\n\ndf_fraud_merchant['percent_grp'] = (df_fraud_merchant['count']\/df_fraud_merchant['merchant_count'])*100","5e3b0cd7":"df_fraud_merchant[df_fraud_merchant['is_fraud'] == 1].sort_values(by = ['percent_grp'],ascending=False)","33cfc66b":"category_onehot = pd.get_dummies(df.category, prefix='category', drop_first=True)\ngender_onehot = pd.get_dummies(df.gender, prefix='gender', drop_first=True)\nday_of_week_onehot = pd.get_dummies(df.day_of_week, prefix='week',drop_first=True)","6b8126fd":"df1 = pd.concat([df, category_onehot,gender_onehot,day_of_week_onehot], axis=1)\n\ndf1.head()","28815380":"df1.dtypes","aafa89fb":"df1.columns","8d683dd1":"df1.index = pd.to_datetime(df1['trans_date_trans_time'])\ndf1 = df1.rename_axis(index={'trans_date_trans_time': 'time_index'})\ndf1 = df1.sort_index()\ndf1.head()","30ed6bca":"df1['val_for_agg'] = 1","a51a7f7a":"df_hist_trans_60d = \\\n    df1 \\\n    .groupby(['cc_num'])['val_for_agg']\\\n    .rolling('60D')\\\n    .count()\\\n    .shift()\\\n    .reset_index()\\\n    .fillna(0)\n\ndf_hist_trans_60d.columns = ['cc_num','trans_date','hist_trans_60d']","86840a37":"df_hist_trans_60d['trans_date'] = df_hist_trans_60d['trans_date'].dt.date","d0c76898":"df_hist_trans_60d = df_hist_trans_60d.groupby(['cc_num','trans_date'])['hist_trans_60d'].min().reset_index()\ndf_hist_trans_60d.head()","afb22f80":"df_hist_orders_24h = \\\n    df1 \\\n    .groupby(['cc_num'])['val_for_agg']\\\n    .rolling('24H')\\\n    .count()\\\n    .shift()\\\n    .reset_index()\\\n    .fillna(0)\n\ndf_hist_orders_24h.columns = ['cc_num','trans_date_trans_time','hist_trans_24h']\ndf_hist_orders_24h.head()","f0283311":"df1['trans_date'] = df1['trans_date_trans_time'].dt.date\ndf2 = df1.merge(df_hist_trans_60d,left_on = ['cc_num','trans_date'], \\\n          right_on = ['cc_num','trans_date'],how = 'left')\n","941e3d87":"df2.head()","a2d00588":"df_job = df[['job','trans_num']].groupby(['job']).count().reset_index()\ndf_job.columns = ['Job','tran_count_by_job']\n\ndf_job['percent'] = (df_job['tran_count_by_job']\/df_job['tran_count_by_job'].sum())*100\n\ndf_job.sort_values(by = ['percent'], ascending=False)","b95c6bcb":"#transactiob by fraud\ndf_fraud_job = df[['job','is_fraud','trans_num']].groupby(['job','is_fraud']).count().reset_index()\ndf_fraud_job.columns = ['Job','is_fraud','count']\n\ndf_fraud_job =  df_fraud_job.merge(df_job[['Job','tran_count_by_job','percent']],how='inner',\\\n                                  left_on='Job',right_on='Job')\n\n\ndf_fraud_job['percent_grp'] = (df_fraud_job['count']\/df_fraud_job['tran_count_by_job'])*100","642883a5":"job_plt_data = df_fraud_job.sort_values(by = [\"tran_count_by_job\"], ascending = False).head(10)\njob_plt_data","751b0b96":"job_plt_data['label'] = 'Not Fraud'\njob_plt_data.loc[job_plt_data['is_fraud']==1,['label']]= 'Fraud'\njob_plt_data","d2cadf5c":"#Importing Library\nfrom sklearn.model_selection import train_test_split","ca61a5df":"#As this dataset is highly imbalance we have to balance this by over sampling\ncnt_non_fraud = df2[df2['is_fraud'] == 0]['amt'].count()\ndf2_class_fraud = df2[df2['is_fraud'] == 1]\ndf2_class_nonfraud = df2[df2['is_fraud'] == 0]\ndf2_class_fraud_oversample = df2_class_fraud.sample(cnt_non_fraud, replace=True)\ndf2_oversampled = pd.concat([df2_class_nonfraud, df2_class_fraud_oversample], axis=0)\ndf2_oversampled.head()","0bff846e":"X_cols = ['amt','city_pop', 'trans_hour',\n       'age', 'category_food_dining', 'category_gas_transport',\n       'category_grocery_net', 'category_grocery_pos',\n       'category_health_fitness', 'category_home', 'category_kids_pets',\n       'category_misc_net', 'category_misc_pos', 'category_personal_care',\n       'category_shopping_net', 'category_shopping_pos', 'category_travel',\n       'gender_M','week_Monday','week_Tuesday', 'week_Wednesday','week_Thursday',\n        'week_Saturday', 'week_Sunday','hist_trans_60d'] #,X_train, X_test, y_train, y_test = train_test_split(df2_oversampled[X_cols],df2_oversampled[Y_cols] , train_size=0.7, test_size=0.3, random_state=42)\nY_cols = ['is_fraud']","b9db975c":"X_train, X_test, y_train, y_test = train_test_split(df2_oversampled[X_cols],df2_oversampled[Y_cols] , train_size=0.7, test_size=0.3, random_state=42)\nX_train.shape","a7034564":"X_test.shape","c6f86826":"#Importing Library\nfrom sklearn.linear_model import LogisticRegression","dfc52b99":"#Building Logistic Regression  Model\nlogreg = LogisticRegression(random_state=42)\n","44026867":"logreg.fit(X_train , y_train)\n","172e4150":"y_train_pred = logreg.predict(X_train)\ny_test_pred = logreg.predict(X_test)","f241b28b":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report","293c6f6d":"print(confusion_matrix(y_train, y_train_pred))\nprint(classification_report(y_train, y_train_pred))","d035ed4b":"print(confusion_matrix(y_test, y_test_pred))\nprint(classification_report(y_test, y_test_pred))","d5b5f2c0":"**Highest number of Transactions are in month of December\n\nLowest number of Transactions happens in February**","930ea752":"we can see that the data set df has features n = 22 and m=1,852,394. n is small and m is very large, using logistic regression or svm without a kernel would help.","1c4037ec":"Derive 'Day of Week' Feature from 'Transaction Time' Feature****","271378be":"Normalizing the count of users by state","fd9dd218":"**Sunday and Monday of the week have highest credit card transactions**","3e84fb61":"Derive 'Transaction Hour' Feature from 'Transaction Time' Feature\u00b6****","b258b929":"This is imbalanced class data and we need to balance the dependent variable\n\n\n","d4dd149c":"Distributing the dependent variables\n","722f69aa":"grouping the fraud or not by gender","5ca1a1fd":"normalizing the different merchant counts ","4839ed7c":"splitting the data into training and test set","1a4b38e7":"oversampling","97f72d48":"grocery and shopping has more number of fraud transactios compared to other categories ","864574ff":"**one hot encoding**","38a7beb2":"24 hrs transactions by customer","a573cdfb":"Looking at the distribution of age","e0d2b8a0":"Logistoic Regression model results:\n\n# Training data:\n\nAccuracy - 84%\n\nrecall - 76%\n\n# Testing data:\n\nAccuracy - 84%\n\nrecall - 76%","5c631737":"**female users are higher than male**","b7b7f324":"transaction count by percentage to different mechants ","2ea00f4c":"distribution of Trasactions by gender","d1bd57db":"**ploting the bar graphs by distributing the category of transaction and looking at distribution of transactions over different days of a week with 1 row 2 coulums{ subplot(1,2,x) } **","4bd371c0":"******converting the data type trans_date_trans_time into datetime****","ecdc0a0f":"****logistic regression***","92c931d6":"year_month vs fraud trasactions and fraud customers ","95507ad5":"**plotting the distribution of no. of transactions over each month and by gender **","9b44958b":"distribution of value of trasaction ","84665c55":"fraud trasaction mean ( 67.65) is very high compared to non-fraud transaction mean (530.66)","46c75df8":"percentage of frauds distributed over all mearchants ","9053fec3":"**finding the age of the customer  and adding it to the dataframe**","cdb04ad1":"**normalizing the count of users by profession **","54847aab":"50 percentile people are 33-57 year old and youngest person is 14 years old while the oldest is 96 years old","48d33311":"distribution of transaction amount in categories of fraud amount and nonfraud amoung","751ff4ab":"merge historic variables with trasactions by cc_num , trans_date_trans_time","40850845":"60 days transactions by customer","c1ae79ac":"deriving year month feature from 'transaction time' feature","23c93849":"looking the data frame of first 5 data sets by default****","80e0f29c":"year month vs number of transactions "}}