{"cell_type":{"c67f328b":"code","7e2fd99b":"code","02424c33":"code","6393da2f":"code","a3ddc4a9":"code","42846bd4":"code","2b47b94d":"code","be77843c":"code","f02dfb17":"code","90a7088c":"code","2f6894cc":"code","d01b1ef2":"code","8378454a":"code","8af2e578":"code","c1558152":"code","802c54c9":"code","4f9eadb2":"code","04dcb50f":"code","3529ac3c":"code","0901c982":"code","a992f44f":"code","4f9a7f58":"code","189264ea":"code","c4481e6b":"markdown","311f8075":"markdown"},"source":{"c67f328b":"#!kaggle competitions download -c 2020-ai-term-project-18011759","7e2fd99b":"#!unzip 2020-ai-term-project-18011759.zip","02424c33":"import torch\nimport torchvision.datasets as data\nimport torchvision.transforms as transforms\nimport random\n\nimport pandas as pd\nimport numpy as np\n","6393da2f":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nrandom.seed(777)\ntorch.manual_seed(777)\nif device == 'cuda':\n  torch.cuda.manual_seed_all(777)","a3ddc4a9":"learning_rate = 0.001\ntraining_epochs = 200\nbatch_size = 100","42846bd4":"train_data = pd.read_csv('..\/input\/2020-ai-term-project-18011759\/train.CSV', encoding = \"euc-kr\",header = None, skiprows=1, usecols=range(0,8))\ntest_data = pd.read_csv('..\/input\/2020-ai-term-project-18011759\/test.CSV', encoding = \"euc-kr\", header = None, skiprows=1, usecols=range(0,7))","2b47b94d":"test_data","be77843c":"train_data","f02dfb17":"x_train_data = train_data.loc[:, 2:6]\ny_train_data = train_data.loc[:, [7]]","90a7088c":"  \nx_train_data = np.array(x_train_data)\ny_train_data = np.array(y_train_data)\nx_train_data = torch.FloatTensor(x_train_data)\ny_train_data = torch.FloatTensor(y_train_data)","2f6894cc":"train_dataset =  torch.utils.data.TensorDataset(x_train_data, y_train_data)","d01b1ef2":"data_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n                                          batch_size=batch_size, \n                                          shuffle = True, \n                                          drop_last = True)","8378454a":"linear1 = torch.nn.Linear(5,530, bias = True)\nlinear2 = torch.nn.Linear(530,530, bias = True)\nlinear3 = torch.nn.Linear(530,530, bias = True)\nlinear4 = torch.nn.Linear(530,530, bias = True)\nlinear5 = torch.nn.Linear(530,530, bias = True)\nlinear6 = torch.nn.Linear(530,530, bias = True)\nlinear7 = torch.nn.Linear(530,1, bias = True)\nReLU = torch.nn.SELU()\ndropout = torch.nn.Dropout(p=0.3)","8af2e578":"torch.nn.init.xavier_uniform_(linear1.weight)\ntorch.nn.init.xavier_uniform_(linear2.weight)\ntorch.nn.init.xavier_uniform_(linear3.weight)\ntorch.nn.init.xavier_uniform_(linear4.weight)\ntorch.nn.init.xavier_uniform_(linear5.weight)\ntorch.nn.init.xavier_uniform_(linear6.weight)\ntorch.nn.init.xavier_uniform_(linear7.weight)","c1558152":"model = torch.nn.Sequential(linear1, ReLU,dropout,\n                            linear2, ReLU,dropout,\n                            linear3, ReLU,dropout,\n                            linear4, ReLU,dropout,\n                            linear5, ReLU,dropout,\n                            linear6, ReLU,dropout,\n                            linear7).to(device)","802c54c9":"loss = torch.nn.MSELoss().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr = learning_rate,eps=1e-20)\nsch = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)","4f9eadb2":"total_batch = len(data_loader)\nfor epoch in range(training_epochs):\n  avg_cost = 0\n\n  for X, Y in data_loader:\n    X = X.to(device)\n    Y = Y.to(device)\n\n    optimizer.zero_grad()\n    hypothesis = model(X)\n    cost = loss(hypothesis, Y)\n    cost.backward()\n    optimizer.step()\n\n    avg_cost += cost\/total_batch\n  print(epoch+1)\n  print(avg_cost)\n  if avg_cost < 0.59 :\n    break\nprint(\"f\")","04dcb50f":"with torch.no_grad():\n  x_test = test_data.loc[:,2:6]\n  x_test = np.array(x_test)\n  x_test = torch.from_numpy(x_test).float().to(device)\n  prediction = model(x_test)","3529ac3c":"correct = prediction.cpu().numpy().reshape(-1, 1)","0901c982":"submit = pd.read_csv('..\/input\/2020-ai-term-project-18011759\/submit_sample.CSV')\nsubmit","a992f44f":"for i in range(len(correct)):\n  submit['total'][i] = correct[i].item()\nsubmit","4f9a7f58":"submit.to_csv('submit.csv', index = False, header = True)","189264ea":"#!kaggle competitions submit -c 2020-ai-term-project-18011759 -f submit.csv -m \"result\"","c4481e6b":"!pip uninstall kaggle<br>\n!pip install --upgrade pip<br>\n!pip install kaggle==1.5.6<br>\n!mkdir -p ~\/.kaggle<br>\n!cp kaggle.json ~\/.kaggle<br>\n!ls -lha kaggle.json<br>\n!chmood 600 ~\/.kaggle\/kaggle.json<br>","311f8075":"###\ucf54\ub4dc \uc124\uba85\n\n- 7layer\n(5->530->530->530->530->530->530->1)\n- xavier_uniform_ init\n- lr = 0.001\n- dropout 0.3\n- training_epochs \ubcc0\uacbd : \uae30\ubcf8 200, if\ubb38\uc73c\ub85c \uc6d0\ud558\ub294 cost\uac12 \ub098\uc62c\ub54c break\n```\nif avg_cost < 0.59:\n  break\n```\n\uc774\uc720 : \uadf8 \uc774\ud6c4\ub85c \ud559\uc2b5\uc744 \ub354 \uc2dc\ucf30\ub354\ub2c8 overfitting\uc774 \uc77c\uc5b4\ub098\uc11c \uc815\ud655\ub3c4\uac00 \ub354 \ub0ae\uc544\uc9d0\n- Adam\n- optimizer \uc548\uc5d0 \ud30c\ub77c\ubbf8\ud130 \ucd94\uac00 : eps = 1e-20<br>\n`optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate,eps=1e-20)`\n- \ucd08\uae30\ud654 \ubc29\uc2dd SELU\ub85c \ubcc0\uacbd<br>\n`relu = torch.nn.SELU()`\n- scheduler \ucd94\uac00 <br>\n`sch = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)`\n\n"}}