{"cell_type":{"eaaf8fda":"code","21f4b381":"code","f65cebd2":"code","3392d953":"code","bf887951":"code","3960225a":"code","821e96da":"code","8b4c49b2":"code","c425d3bb":"code","714e4d18":"code","0888e08c":"code","a9464841":"code","cf5151d3":"code","369a9c09":"code","067ce1ad":"code","faa5dd4c":"code","09b8fac7":"code","ee9a331e":"code","24a72ac0":"code","4f6da2b8":"code","36525ee3":"code","4790545c":"code","91376d4f":"code","a2b90058":"code","19b71a45":"code","794a1762":"code","53f48e5b":"code","1cdc4af3":"code","cb8763ef":"markdown","6cfc891a":"markdown","7faab390":"markdown","782ff1dc":"markdown","8c278b36":"markdown","6db9d0b7":"markdown","39b8645a":"markdown","080836c6":"markdown","557671b1":"markdown","586277ec":"markdown","2d9b865a":"markdown","f1aac9d2":"markdown","9cb494e3":"markdown"},"source":{"eaaf8fda":"import gc\nimport os\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import KFold\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\n\nimport warnings\nwarnings.filterwarnings('ignore')","21f4b381":"PATH = '..\/input\/russia-real-estate-20182021\/all_v2.csv'\n\nREGION_ID = 2661  # City of Saint Petersburg\n\nMIN_AREA = 20  # Outlier range for floor area\nMAX_AREA = 200\n\nMIN_KITCHEN = 6  # Outlier range for kitchen area\nMAX_KITCHEN = 30\n\nMIN_PRICE = 1_500_000  # Outlier range for price\nMAX_PRICE = 50_000_000\n\nSEED = 15\nN_FOLDS = 5","f65cebd2":"def set_display():\n    \"\"\"Function sets display options for charts and pd.DataFrames.\n    \"\"\"\n    # Plots display settings\n    plt.style.use('fivethirtyeight')\n    plt.rcParams['figure.figsize'] = 12, 8\n    plt.rcParams.update({'font.size': 14})\n    # DataFrame display settings\n    pd.set_option('display.max_columns', None)\n    pd.set_option('display.max_rows', None)\n    pd.options.display.float_format = '{:.4f}'.format\n\n\ndef clean_data(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Function removes excess columns and enforces\n    correct data types.\n    :param df: Original DataFrame\n    :return: Updated DataFrame\n    \"\"\"\n    df.drop('time', axis=1, inplace=True)\n    df['date'] = pd.to_datetime(df['date'])\n    # Column actually contains -1 and -2 values presumably for studio apartments.\n    df['rooms'] = df['rooms'].apply(lambda x: 0 if x < 0 else x)\n    df['price'] = df['price'].abs()  # Fix negative values\n    # Drop price and area outliers.\n    df = df[(df['area'] <= MAX_AREA) & (df['area'] >= MIN_AREA)]\n    df = df[(df['price'] <= MAX_PRICE) & (df['price'] >= MIN_PRICE)]\n    # Fix kitchen area outliers.\n    # At first, replace all outliers with 0.\n    df.loc[(df['kitchen_area'] >= MAX_KITCHEN) | (df['area'] <= MIN_AREA), 'kitchen_area'] = 0\n    # Then calculate kitchen area based on the floor area, except for studios.\n    erea_mean, kitchen_mean = df[['area', 'kitchen_area']].quantile(0.5)\n    kitchen_share = kitchen_mean \/ erea_mean\n    df.loc[(df['kitchen_area'] == 0) & (df['rooms'] != 0), 'kitchen_area'] = \\\n        df.loc[(df['kitchen_area'] == 0) & (df['rooms'] != 0), 'area'] * kitchen_share\n\n    return df\n\n\ndef select_region(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Function selects the listings belonging to a specified region.\n    :param df: Original DataFrame with all listings\n    :return: Filtered DataFrame\n    \"\"\"\n    df = df[df['region'] == REGION_ID]\n    df.drop('region', axis=1, inplace=True)\n    print(f'Selected {len(df)} samples in region {REGION_ID}.')\n    return df\n\n\ndef add_features(df: pd.DataFrame) -> pd.DataFrame:\n    # Replace \"date\" with numeric features for year and month.\n    df['year'] = df['date'].dt.year\n    df['month'] = df['date'].dt.month\n    df.drop('date', axis=1, inplace=True)\n    # Apartment floor in relation to total number of floors.\n    df['level_to_levels'] = df['level'] \/ df['levels']\n    # Average size of room in the apartment.\n    df['area_to_rooms'] = (df['area'] \/ df['rooms']).abs()\n    # Fix division by zero.\n    df.loc[df['area_to_rooms'] == np.inf, 'area_to_rooms'] = \\\n        df.loc[df['area_to_rooms'] == np.inf, 'area']\n    return df\n\n\ndef set_seed(seed=42):\n    \"\"\"Utility function to use for reproducibility.\n    :param seed: Random seed\n    :return: None\n    \"\"\"\n    np.random.seed(seed)\n    random.seed(seed)\n    # tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'","3392d953":"set_display()","bf887951":"data = pd.read_csv(PATH)\nprint(f'Data shape: {data.shape}')\ndata.head()","3960225a":"data.info()","821e96da":"data.describe()","8b4c49b2":"data = data.pipe(clean_data)\ndata.head()","c425d3bb":"building_types = data['building_type'].value_counts()\nplt.pie(building_types.values, labels=building_types.index, autopct='%1.1f%%')\nplt.title('Building Types')\nplt.show()","714e4d18":"apartment_types = data['object_type'].value_counts()\nplt.pie(apartment_types.values, labels=apartment_types.index, autopct='%1.1f%%')\nplt.title('Apartment Types')\nplt.show()","0888e08c":"rooms = data['rooms'].value_counts()\nplt.pie(rooms.values, labels=rooms.index, autopct='%1.1f%%')\nplt.title('Number of Rooms')\nplt.show()","a9464841":"pos = 0\nfor pos, feature in enumerate(['area', 'kitchen_area']):\n    sp = plt.subplot(1, 2, pos + 1)\n    plt.hist(data[feature], bins=20)\n    plt.title(f'Distribution: {feature}')\nplt.show()","cf5151d3":"pos = 0\nfor pos, feature in enumerate(['level', 'levels']):\n    levels = data[feature].value_counts()\n    sp = plt.subplot(1, 2, pos + 1)\n    plt.bar(levels.index, levels.values)\n    plt.title(feature)\nplt.show()","369a9c09":"# Regions are encoded with numeric IDs.\nregions = data['region'].value_counts()\nprint(regions.head(10))\n\nplt.hist(regions.values, bins=5)\nplt.title('Listings by Region')\nplt.show()","067ce1ad":"# Find out what regions are represented in the data set.\nfor region in data['region'].unique():\n    subset = data[data['region'] == region]\n    lat, lon = np.round(subset[['geo_lat', 'geo_lon']].mean(), 2)\n    print(f'Region {region}: latitude = {lat}, longitude = {lon}')","faa5dd4c":"avg_prices = data.groupby(by='region')['price'].mean()\nplt.hist(avg_prices.values, bins=10)\nplt.xlabel('Rubles')\nplt.ylabel('Frequency')\nplt.title('Average Price by Region')\nplt.show()","09b8fac7":"data = data.pipe(select_region)\ndata = data.pipe(add_features)\ndata.head()","ee9a331e":"gc.collect()","24a72ac0":"data.describe()","4f6da2b8":"correlation = data.corr()\nax = sns.heatmap(correlation, center=0, cmap='RdBu_r')\nl, r = ax.get_ylim()\nax.set_ylim(l + 0.5, r - 0.5)\nplt.yticks(rotation=0)\nplt.title('Correlation Matrix')\nplt.show()","36525ee3":"y = data.pop('price')","4790545c":"set_seed(SEED)\n\nkf = KFold(N_FOLDS, shuffle=True, random_state=SEED)","91376d4f":"scores = []\n\nfor train_index, test_index in kf.split(data, y):\n\n    x_train, x_test = data.iloc[train_index, :], data.iloc[test_index, :]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n\n    model_xgb = XGBRegressor(objective='reg:squarederror')\n\n    model_xgb.fit(x_train, y_train, eval_set=[(x_test, y_test)],\n                  eval_metric='rmse', early_stopping_rounds=50,\n                  verbose=0)\n\n    scores.append(model_xgb.best_score)\n    model_xgb.save_model(f'xgboost{len(scores)}.bin')\n\nprint('XGBoost average RMSE:', np.mean(scores))\nfor i, score in enumerate(scores):\n    print(f'Model {i} RMSE: {score}')","a2b90058":"# Display feature importance.\nimportance = pd.DataFrame({\n    'features': data.columns,\n    'importance': model_xgb.feature_importances_\n})\nimportance.sort_values(by='importance', inplace=True)\n\nplt.figure(figsize=(12, 16))\nplt.barh(importance['features'], importance['importance'])\nplt.title('XGBoost Feature Importance')\nplt.show()","19b71a45":"scores = []\n\nfor train_index, test_index in kf.split(data, y):\n\n    x_train, x_test = data.iloc[train_index, :], data.iloc[test_index, :]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n\n    model_lgb = LGBMRegressor(objective='regression', metrics='rmse')\n\n    model_lgb.fit(x_train, y_train, eval_set=(x_test, y_test),\n                  eval_metric='rmse', early_stopping_rounds=50,\n                  categorical_feature=['building_type', 'object_type', 'month'],\n                  verbose=0)\n\n    scores.append(model_lgb.best_score_['valid_0']['rmse'])\n    model_lgb.booster_.save_model(f'lgbm{len(scores)}.txt',\n                                  num_iteration=model_lgb.best_iteration_)\n\nprint('LGBM average RMSE:', np.mean(scores))\nfor i, score in enumerate(scores):\n    print(f'Model {i} RMSE: {score}')","794a1762":"importance = pd.DataFrame({\n    'features': data.columns,\n    'importance': model_lgb.feature_importances_\n})\nimportance.sort_values(by='importance', inplace=True)\n\nplt.figure(figsize=(12, 16))\nplt.barh(importance['features'], importance['importance'])\nplt.title('LGBM Feature Importance')\nplt.show()","53f48e5b":"scores = []\n\nfor train_index, test_index in kf.split(data, y):\n\n    x_train, x_test = data.iloc[train_index, :], data.iloc[test_index, :]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n\n    model_cb = CatBoostRegressor(eval_metric='RMSE',\n                                 cat_features=['building_type', 'object_type', 'month'])\n    model_cb.fit(x_train, y_train, eval_set=[(x_test, y_test)],\n                 early_stopping_rounds=20, use_best_model=True,\n                 verbose=0)\n\n    scores.append(model_cb.best_score_['validation']['RMSE'])\n    model_cb.save_model(f'catboost{len(scores)}.cbm')\n\nprint('Average RMSE:', np.mean(scores))\nfor i, score in enumerate(scores):\n    print(f'Model {i} RMSE: {score}')","1cdc4af3":"# Display feature importance.\nimportance = pd.DataFrame({\n    'features': data.columns,\n    'importance': model_cb.feature_importances_\n})\nimportance.sort_values(by='importance', inplace=True)\n\nplt.figure(figsize=(12, 16))\nplt.barh(importance['features'], importance['importance'])\nplt.title('CatBoost Feature Importance')\nplt.show()","cb8763ef":"## Data Analysis","6cfc891a":"### XGBoost Model","7faab390":"## Functions","782ff1dc":"# Apartment Pricing Model\nBased on the [data set](https:\/\/www.kaggle.com\/mrdaniilak\/russia-real-estate-20182021) containing **listings of apartments** offered for sale in various regions of Russia I develop a pricing models that could be used to evaluate apartments located in the **city of Saint Petersburg**. Similar approach could be used to create regression models for other regions.\n\n**Models used:** XGBoost, LGBM, CatBoost\n\n**Techniques applied:** data cleaning, filtering outliers, feature engineering","8c278b36":"### Features and data types\n- Categorical features:\n  - Region (numerically encoded geographical area, identifies either a large city like Moscow or Saint Petersburg or a federal region \/ district)\n  - Building type (numerically encoded type of the building where the apartment is located)\n  - Object type (apartment type, where 1 stands for secondary real estate market, 11 - new building)\n- Numerical features:\n  - Area (total floor area of the apartment in sq. meters)\n  - Kitchen area (kitchen area in sq. meters)\n  - Rooms (number of rooms in the apartment, -1 stands for studios with open-space layout)\n  - Level (floor the apartment is located on, could be treated as a categorical feature as well)\n  - Levels (total number of storeys in the building)\n- Geospatial features:\n  - Latitude - geographical coordinate of the preperty\n  - Longitude - geographical coordinate of the preperty\n- Temporal features:\n  - Date (date the listing was published)\n  - Time (exact time the listing was published)","6db9d0b7":"### CatBoost Model","39b8645a":"Knowing the basics of real estate pricing, it's unreasonable to develop a single model for all the regions. Pricing factors could have different impact on the actual price depending on the region, local market conditions, prevailing types of buildings in the area, etc.\n\nA number of important features are missing in this data set, which would lead to larger errors regardless of applied regression algorithms and quality of the model:\n- Condition: similar apartments would be priced differently, if one of them is being sold fully furnished in excellent condition and the other is being sold without finishing.\n- Ceiling height affects the price.\n- Balconies and terraces increase the price compared to similar apartments without such menities.\n- Additional unique properties usually mentioned in the description of the apartment, like chimneys or underground parking spaces, affect the price.\n\nTaking that in mind we will try to develop a pricing model for apartments located in Saint Petersburg.","080836c6":"### LGMB Model","557671b1":"## Conclusions\nStandard deviation of price in the selected subset of data representing Saint Petersburg housing market is about 5.6 mln rubles. Gradient boosting models RMSE is in the range between 1.7 and 1.9 mln rubles. There is still room for improvement taking into account that median price in the city is about 6 mln rubles. However without additional features describing condition, presence or absence of furniture and other improvements making these models significantly more accurate would be difficult.","586277ec":"Data set contains samples with typos and errors including negative prices, too large or unrealistically small floor area, etc. Let's clean the data before proceeding with the analysis. We limit the floor area to a range betwee 20 sq.m and 200 sq.m and price to a range between 1.5 mln to 50 mln rubles, which covers most of the housing market.","2d9b865a":"## Feature Engineering","f1aac9d2":"## Models Cross-Validation","9cb494e3":"Listings are unequally distributed between the regions with most of the offerings concentrated in the largest and most developed cities and their surrounding areas."}}