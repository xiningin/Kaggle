{"cell_type":{"6130e2e7":"code","1e150d40":"code","2c655e29":"code","f93f2e4d":"code","c3f3fb11":"code","fcbf29cc":"code","afd02d73":"code","daae8fd5":"code","4e346a5b":"code","babdaba7":"code","cd9a5c26":"markdown","007876cf":"markdown","76a05a4a":"markdown"},"source":{"6130e2e7":"#importing Libs\nimport pandas as pd\nimport pylab as pl\nimport numpy as np\nimport scipy.optimize as opt\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline \nimport matplotlib.pyplot as plt","1e150d40":"#importing Dataset\ndf=pd.read_csv('..\/input\/cell-samplescsv\/cell_samples.csv')\ndf.head(5)","2c655e29":"#Data types \ndf.dtypes","f93f2e4d":"#Data_preprocessing \n#It looks like the BareNuc column includes some values that are not numerical. We can drop those rows:\ndf = df[pd.to_numeric(df['BareNuc'], errors='coerce').notnull()]\ndf['BareNuc'] = df['BareNuc'].astype('int')\ndf.dtypes","c3f3fb11":"#the independent variables \nfeatures = df[['Clump', 'UnifSize', 'UnifShape', 'MargAdh', 'SingEpiSize', 'BareNuc', 'BlandChrom', 'NormNucl', 'Mit']]\nX = np.asarray(features)\nX[0:5]","fcbf29cc":"#the target or the dependent variable \ny=np.asarray(df[['Class']])\ny[0:5]","afd02d73":"#train and test dataset\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)","daae8fd5":"from sklearn import svm\nclf = svm.SVC(kernel='rbf')\nclf.fit(X_train, y_train) ","4e346a5b":"yhat = clf.predict(X_test)\nyhat [0:5]","babdaba7":"#Model evaluation using confusion matrix and reprt \nfrom sklearn.metrics import classification_report, confusion_matrix\nprint( confusion_matrix(y_test,yhat))\nprint( classification_report(y_test,yhat))","cd9a5c26":"<h2 id=\"load_dataset\">Load the Cancer data<\/h2>\nThe example is based on a dataset that is publicly available from the UCI Machine Learning Repository (Asuncion and Newman, 2007)[http:\/\/mlearn.ics.uci.edu\/MLRepository.html]. The dataset consists of several hundred human cell sample records, each of which contains the values of a set of cell characteristics. The fields in each record are:\n\n| Field name  | Description                 |\n| ----------- | --------------------------- |\n| ID          | Clump thickness             |\n| Clump       | Clump thickness             |\n| UnifSize    | Uniformity of cell size     |\n| UnifShape   | Uniformity of cell shape    |\n| MargAdh     | Marginal adhesion           |\n| SingEpiSize | Single epithelial cell size |\n| BareNuc     | Bare nuclei                 |\n| BlandChrom  | Bland chromatin             |\n| NormNucl    | Normal nucleoli             |\n| Mit         | Mitoses                     |\n| Class       | Benign or malignant         |\n\n<br>\n<br>\n\nFor the purposes of this example, we're using a dataset that has a relatively small number of predictors in each record. To download the data, we will use `!wget` to download it from IBM Object Storage.  \n\n**Did you know?** When it comes to Machine Learning, you will likely be working with large datasets. As a business, where can you host your data? IBM is offering a unique opportunity for businesses, with 10 Tb of IBM Cloud Object Storage: [Sign up now for free](http:\/\/cocl.us\/ML0101EN-IBM-Offer-CC)\n","007876cf":"**Support Vector Machines SVM Notebook**","76a05a4a":"This notebook was created with the help of IBM data science  professional certificate. "}}