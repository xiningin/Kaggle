{"cell_type":{"777961c1":"code","de162a27":"code","51ca1abc":"code","7b893c1f":"code","1ceaffbf":"code","24cf400f":"code","604fa2a6":"code","4b17a122":"code","db3fb3e6":"code","1dd89414":"code","daf56ac4":"code","8d910361":"code","e05285e4":"code","d9bdf1a8":"code","0c172c2c":"code","63074fcc":"code","ab96b736":"code","3d1a0ca1":"code","67b31eb6":"code","935baa7d":"code","f38924c0":"code","04203b28":"code","c872065b":"code","8e447c8b":"code","6bdd7695":"code","7edaf549":"code","1202099b":"code","b0745519":"code","1a461de9":"code","917c2394":"code","320c2744":"code","592e122c":"code","fb871cee":"code","4b3d3ffb":"code","1b4e8165":"code","742619e6":"code","3172bf77":"markdown"},"source":{"777961c1":"##Importing all necessary libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","de162a27":"train=pd.read_csv('..\/input\/malignant-comment-classification\/train.csv')\ntrain.head()","51ca1abc":"test=pd.read_csv('..\/input\/malignant-comment-classification\/test.csv')\ntest.head()","7b893c1f":"print('train shape is ',train.shape)\nprint('test shape is ',test.shape)\nprint('test info',test.info)\n\n\nprint('train info',train.info)\n","1ceaffbf":"print('train data Set descriptin',train.describe())\nprint('test data Set descriptin',test.describe())","24cf400f":"\n# checking null values\nprint(train.isnull().sum())\nprint(sns.heatmap(train.isnull()))","604fa2a6":"\n## checking correlation in dataset\nprint(train.corr())\nprint(sns.heatmap(train.corr()))","4b17a122":"# checking the skewness for the features:\ntrain.skew()","db3fb3e6":"col=['malignant','highly_malignant','loathe','rude','abuse','threat']\nfor i in col:\n    print(i)\n    print(\"\\n\")\n    print(train[i].value_counts())\n    sns.countplot(train[i])\n    plt.show()","1dd89414":"from nltk.stem import WordNetLemmatizer\nimport nltk\nfrom nltk.corpus import  stopwords\nimport string","daf56ac4":"train['length'] = train['comment_text'].str.len()\ntrain.head(2)","8d910361":"# Convert all messages to lower case\ntrain['comment_text'] = train['comment_text'].str.lower()\n\n# Replace email addresses with 'email'\ntrain['comment_text'] = train['comment_text'].str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$',\n                                 'emailaddress')\n\n# Replace URLs with 'webaddress'\ntrain['comment_text'] = train['comment_text'].str.replace(r'^http\\:\/\/[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(\/\\S*)?$',\n                                  'webaddress')\n\n# Replace money symbols with 'moneysymb' (\u00a3 can by typed with ALT key + 156)\ntrain['comment_text'] = train['comment_text'].str.replace(r'\u00a3|\\$', 'dollers')\n    \n# Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\ntrain['comment_text'] = train['comment_text'].str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n                                  'phonenumber')\n\n    \n# Replace numbers with 'numbr'\ntrain['comment_text'] = train['comment_text'].str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n\n\ntrain['comment_text'] = train['comment_text'].apply(lambda x: ' '.join(\n    term for term in x.split() if term not in string.punctuation))\n\nstop_words = set(stopwords.words('english') + ['u', '\u00fc', 'ur', '4', '2', 'im', 'dont', 'doin', 'ure'])\ntrain['comment_text'] = train['comment_text'].apply(lambda x: ' '.join(\n    term for term in x.split() if term not in stop_words))\n\nlem=WordNetLemmatizer()\ntrain['comment_text'] = train['comment_text'].apply(lambda x: ' '.join(\n lem.lemmatize(t) for t in x.split()))","e05285e4":"train['clean_length'] = train.comment_text.str.len()\ntrain.head()","d9bdf1a8":"\n# Total length removal\nprint ('Origian Length', train.length.sum())\nprint ('Clean Length', train.clean_length.sum())","0c172c2c":"\n#Getting sense of loud words which are offensive\nfrom wordcloud import WordCloud\nhams = train['comment_text'][train['malignant']==1]\nspam_cloud = WordCloud(width=600,height=400,background_color='black',max_words=50).generate(' '.join(hams))\nplt.figure(figsize=(10,8),facecolor='k')\nplt.imshow(spam_cloud)\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","63074fcc":"\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report,roc_curve,roc_auc_score,auc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,classification_report,confusion_matrix,f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score,GridSearchCV\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier","ab96b736":"cols_target = ['malignant','highly_malignant','rude','threat','abuse','loathe']\ndf_distribution = train[cols_target].sum()\\\n                            .to_frame()\\\n                            .rename(columns={0: 'count'})\\\n                            .sort_values('count')\n\ndf_distribution.plot.pie(y='count',\n                                      title='Label distribution over comments',\n                                      figsize=(5, 5))\\\n                            .legend(loc='center left', bbox_to_anchor=(1.3, 0.5))","3d1a0ca1":"\ntarget_data = train[cols_target]\n\ntrain['bad'] =train[cols_target].sum(axis =1)\nprint(train['bad'].value_counts())\ntrain['bad'] = train['bad'] > 0 \ntrain['bad'] = train['bad'].astype(int)\nprint(train['bad'].value_counts())","67b31eb6":"sns.set()\nsns.countplot(x=\"bad\" , data = train)\nplt.show()","935baa7d":"#  Convert text into vectors using TF-IDF\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntf_vec = TfidfVectorizer(max_features = 10000, stop_words='english')\nfeatures = tf_vec.fit_transform(train['comment_text'])\nx = features","f38924c0":"train.shape","04203b28":"test.shape","c872065b":"y=train['bad']\nx_train,x_test,y_train,y_test=train_test_split(x,y,random_state=56,test_size=.30)","8e447c8b":"\ny_train.shape,y_test.shape","6bdd7695":"# LogisticRegression\nLG = LogisticRegression(C=1, max_iter = 3000)\n\nLG.fit(x_train, y_train)\n\ny_pred_train = LG.predict(x_train)\nprint('Training accuracy is {}'.format(accuracy_score(y_train, y_pred_train)))\ny_pred_test = LG.predict(x_test)\nprint('Test accuracy is {}'.format(accuracy_score(y_test,y_pred_test)))\nprint(confusion_matrix(y_test,y_pred_test))\nprint(classification_report(y_test,y_pred_test))","7edaf549":"\n# DecisionTreeClassifier\nDT = DecisionTreeClassifier()\n\nDT.fit(x_train, y_train)\ny_pred_train = DT.predict(x_train)\nprint('Training accuracy is {}'.format(accuracy_score(y_train, y_pred_train)))\ny_pred_test = DT.predict(x_test)\nprint('Test accuracy is {}'.format(accuracy_score(y_test,y_pred_test)))\nprint(confusion_matrix(y_test,y_pred_test))\nprint(classification_report(y_test,y_pred_test))","1202099b":"#RandomForestClassifier\nRF = RandomForestClassifier()\n\nRF.fit(x_train, y_train)\ny_pred_train = RF.predict(x_train)\nprint('Training accuracy is {}'.format(accuracy_score(y_train, y_pred_train)))\ny_pred_test = RF.predict(x_test)\nprint('Test accuracy is {}'.format(accuracy_score(y_test,y_pred_test)))\nprint(confusion_matrix(y_test,y_pred_test))\nprint(classification_report(y_test,y_pred_test))","b0745519":"# xgboost\nimport xgboost\nxgb = xgboost.XGBClassifier()\nxgb.fit(x_train, y_train)\ny_pred_train = xgb.predict(x_train)\nprint('Training accuracy is {}'.format(accuracy_score(y_train, y_pred_train)))\ny_pred_test = xgb.predict(x_test)\nprint('Test accuracy is {}'.format(accuracy_score(y_test,y_pred_test)))\nprint(confusion_matrix(y_test,y_pred_test))\nprint(classification_report(y_test,y_pred_test))","1a461de9":"#AdaBoostClassifier\nada=AdaBoostClassifier(n_estimators=100)\nada.fit(x_train, y_train)\ny_pred_train = ada.predict(x_train)\nprint('Training accuracy is {}'.format(accuracy_score(y_train, y_pred_train)))\ny_pred_test = ada.predict(x_test)\nprint('Test accuracy is {}'.format(accuracy_score(y_test,y_pred_test)))\nprint(confusion_matrix(y_test,y_pred_test))\nprint(classification_report(y_test,y_pred_test))","917c2394":"#KNeighborsClassifier\nknn=KNeighborsClassifier(n_neighbors=9)\nknn.fit(x_train, y_train)\ny_pred_train = knn.predict(x_train)\nprint('Training accuracy is {}'.format(accuracy_score(y_train, y_pred_train)))\ny_pred_test = knn.predict(x_test)\nprint('Test accuracy is {}'.format(accuracy_score(y_test,y_pred_test)))\nprint(confusion_matrix(y_test,y_pred_test))\nprint(classification_report(y_test,y_pred_test))","320c2744":"# RandomForestClassifier\nRF = RandomForestClassifier()\nRF.fit(x_train, y_train)\ny_pred_train = RF.predict(x_train)\nprint('Training accuracy is {}'.format(accuracy_score(y_train, y_pred_train)))\ny_pred_test = RF.predict(x_test)\nprint('Test accuracy is {}'.format(accuracy_score(y_test,y_pred_test)))\ncvs=cross_val_score(RF, x, y, cv=10, scoring='accuracy').mean()\nprint('cross validation score :',cvs*100)\nprint(confusion_matrix(y_test,y_pred_test))\nprint(classification_report(y_test,y_pred_test))","592e122c":"#Plotting the graph which tells us about the area under curve , more the area under curve more will be the better prediction\n# model is performing good :\nfpr,tpr,thresholds=roc_curve(y_test,y_pred_test)\nroc_auc=auc(fpr,tpr)\nplt.plot([0,1],[1,0],'k--')\nplt.plot(fpr,tpr,label = 'RF Classifier')\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('RF CLASSIFIER')\nplt.show()","fb871cee":"import eli5\neli5.show_weights(RF,vec = tf_vec, top = 15)  #random forest\n# will give you top 15 features or words  which makes a comment toxic","4b3d3ffb":"test_data =tf_vec.fit_transform(test['comment_text'])\ntest_data","1b4e8165":"prediction=RF.predict(test_data)\nprediction","742619e6":"import joblib\njoblib.dump(RF,\"malig.pkl\")","3172bf77":"# <center>Malignant Comment Classification<\/center>\n"}}