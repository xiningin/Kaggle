{"cell_type":{"20630614":"code","306928fe":"code","5966bcb9":"code","056f9cc8":"code","31cf4bfe":"code","0e36193a":"code","9e991706":"code","d40ad0d0":"code","2fbae658":"code","595037a9":"code","eeaa64bc":"code","50f0bd60":"code","285b219b":"code","e0447d3c":"markdown","aee5ec89":"markdown","10f8da0c":"markdown","21352f23":"markdown","102350f4":"markdown","a6d2eae1":"markdown","107e0fbf":"markdown","4bab6b43":"markdown","4f2cb925":"markdown"},"source":{"20630614":"# importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport os\nfrom tensorflow.keras.preprocessing import image\nfrom zipfile import ZipFile ","306928fe":"# importing libraries for Deep Learning\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation,BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img","5966bcb9":"test=\"..\/input\/dogs-cats-images\/dog vs cat\/dataset\/test_set\"\ntrain=\"..\/input\/dogs-cats-images\/dog vs cat\/dataset\/training_set\"\n\n\ntrain_dog=(train+\"\/dogs\")\ntrain_cat=(train+\"\/cats\")\ntest_dog=(test+\"\/dogs\")\ntest_cat=(test+\"\/cats\")","056f9cc8":"print('number of cats training images - ',len(os.listdir(train_cat)))\nprint('number of dogs training images - ',len(os.listdir(train_dog)))\nprint('number of cats testing images - ',len(os.listdir(test_cat)))\nprint('number of dogs testing images - ',len(os.listdir(test_dog)))","31cf4bfe":"img = load_img(train_dog + \"\/dog.1004.jpg\")\nplt.axis(\"off\")\nplt.imshow(img)","0e36193a":"train_datagen=ImageDataGenerator(rescale = 1.0\/255.0,           #resimleri ayr\u0131ca scale edelim\n                             featurewise_center=True,\n                             width_shift_range=0.2,\n                             height_shift_range=0.2,\n                             rotation_range=40,\n                             shear_range=0.2,\n                             zoom_range=0.2,\n                             horizontal_flip=True,\n                             vertical_flip=True,\n                             fill_mode='nearest')\n\n\ntest_datagen = ImageDataGenerator(rescale= 1.\/255)","9e991706":"\n\nbatch_size = 32\n\ntrain_generator = train_datagen.flow_from_directory(directory = train,        #resmin \u00fcretilip depolanaca\u011f\u0131 yer\n                                              target_size = (64,64),        #resimlerimizle ayn\u0131 shape de olmal\u0131\n                                              class_mode = 'binary',          #sadece 2 s\u0131n\u0131f\u0131m\u0131z oldu\u011fu i\u00e7in binary\n                                              batch_size=batch_size,\n                                              shuffle=True)                   #shuffle (kar\u0131\u015ft\u0131rmak) datam\u0131z\u0131 kar\u0131\u015ft\u0131ral\u0131m.\n                               \n\ntest_generator = test_datagen.flow_from_directory(directory = test,\n                                             target_size = (64,64),\n                                             batch_size=batch_size,\n                                             class_mode = 'binary',\n                                             shuffle=True)","d40ad0d0":"model = Sequential()\nmodel.add(Conv2D(filters = 32, kernel_size = (3, 3),input_shape =(64,64,3),padding=\"same\"))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3, 3),padding=\"same\"))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\n\n\nmodel.add(Conv2D(filters = 128, kernel_size = (3, 3),padding=\"same\"))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(units = 128))\nmodel.add(Activation('relu'))\n\nmodel.add(Dense(units = 256))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(rate = 0.5))\n          \nmodel.add(Dense(units = 2))\nmodel.add(Activation('softmax'))","2fbae658":"model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])","595037a9":"model.summary()","eeaa64bc":"hist = model.fit_generator(\n                        generator=train_generator,\n                        steps_per_epoch = 500,\n                        epochs = 50,\n                        validation_data = test_generator,\n                        validation_steps = 400)","50f0bd60":"print(hist.history.keys())","285b219b":"plt.plot(hist.history[\"loss\"],label=\"Train loss\")\nplt.plot(hist.history[\"val_loss\"], label=\"Validation loss\")\nplt.legend()\nplt.show()\n\nplt.plot(hist.history[\"acc\"], label=\"Train accuracy\")\nplt.plot(hist.history[\"val_acc\"],label=\"Validation accuracy\")\nplt.legend()\nplt.show()","e0447d3c":"Matplotlib k\u00fct\u00fcphanesini kullarak g\u00f6rselle\u015ftirmemizi yapal\u0131m.","aee5ec89":"bu k\u0131s\u0131mda ise nas\u0131l \u00fcretilece\u011finiz belirledi\u011fimiz teknikleri flow_from_directory metodunu kullanarak ilgili dosyaya uygulad\u0131k.\nYine bu i\u015flemi bu i\u015flemi data_generator isimli bir objeye atad\u0131k","10f8da0c":"Ba\u015far\u0131 oran\u0131m\u0131z\u0131 epoch say\u0131s\u0131n\u0131 artt\u0131rarak biraz daha artt\u0131rabiliriz gibi.","21352f23":"steps_per_epoch = 400 ad\u0131m olsun dedik.\u00d6ncelikle her bir epoch i\u00e7in 400*batch_size(32)=12800 resim gerek .Bizim ise 8000 resmimiz var. Aradaki fark ise bizim ImageDataGeneratorle \u00fcretice\u011fimiz resimlerin say\u0131d\u0131r.\n\n","102350f4":"Datam\u0131z 8000 train ve 2000 adet test k\u00fcmesi resim i\u00e7eren kedi ve k\u00f6pek resimlerinden olu\u015fmakta.ImageDataGenerator yakla\u015f\u0131m\u0131 ve temel bir keras modeli uygulayarak s\u0131n\u0131fland\u0131rma i\u015flemini yapt\u0131k.","a6d2eae1":"#modelimizi compile edelim sadece iki s\u0131n\u0131f oldu\u011fu loss function i\u00e7in \"binary_crossentropy\" kullan\u0131caz.E\u011fer 2 den fazla s\u0131n\u0131f\u0131m\u0131z olsayd\u0131 \"categorical_crossentropy\" yi kullanmam\u0131z gerekti","107e0fbf":"ImageDataGenerator ile \u00fcretice\u011fimiz resimlerde hangi teknikleri kullan\u0131ca\u011f\u0131m\u0131z\u0131 belirleyelim ve scale etmeyi unutmayal\u0131m .Son olarak bu i\u015flemleri train_datagen ve test_datagen objesine atayal\u0131m.","4bab6b43":"modelimizi \u00e7al\u0131\u015ft\u0131rd\u0131ktan sonra modelimizle ilgili yorum yapabilmek \u00e7\u0131kar\u0131mlar elde etmek i\u00e7in g\u00f6rselle\u015ftirmeye ihtiyac duyar\u0131z. Bunun i\u00e7in Hist objesinin (kendimizin atad\u0131\u011f\u0131) baz\u0131 \u00f6zelliklerini keys metodunu \u00e7a\u011f\u0131rarak g\u00f6relim ve kullanal\u0131m. Bunlar\u0131 g\u00f6rmek i\u00e7in k\u0131saca ----\"modelin tan\u0131mlad\u0131\u011f\u0131m\u0131z obje ismi\".history.keys()----","4f2cb925":"modelimizi kural\u0131m. 3 katmanl\u0131 basit bir sequential model. Baz\u0131 incelemelere ve makalelere g\u00f6re Dropout i\u015flemini modelimiz i\u00e7inde kullanmak iyi sonu\u00e7lar vermemekte hatta sonucumuza negatif etki etmekte. Biz bu modelde Dropout i\u015flemini sadece tam ba\u011flant\u0131l\u0131 katmanlarda A\u011f\u0131rl\u0131klar\u0131n daha iyi kullan\u0131lmas\u0131 ve a\u015f\u0131r\u0131 ezberlemeyi(Overfitting) \u00f6nlemeye \u00e7al\u0131\u015ft\u0131k.Ayr\u0131ca resim boyutlar\u0131m\u0131z\u0131n\nConvolutinal katmanlar\u0131nda kaybolmamas\u0131 i\u00e7in padding uygulad\u0131k."}}