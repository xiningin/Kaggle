{"cell_type":{"ba855775":"code","fc49018a":"code","d004d13e":"code","40c6da68":"code","f584c989":"code","5e59dfb7":"code","94a3bc79":"code","0d953275":"code","1a90f160":"code","fecd9ca2":"code","643457d8":"code","f8a24383":"code","f448e95c":"markdown","aa69467a":"markdown","70eeee84":"markdown","13304578":"markdown","16345cf3":"markdown","bd7d697a":"markdown","47b14cda":"markdown","adb3a5b2":"markdown","30dc05f8":"markdown"},"source":{"ba855775":"import cv2\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nimport random\nfrom skimage import io\nfrom shutil import copyfile\nimport sys\nimport time\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array","fc49018a":"train = pd.read_csv(\"\/kaggle\/input\/global-wheat-detection\/train.csv\")\n#test = pd.read_csv(\"\/kaggle\/input\/global-wheat-detection\/test.csv\")","d004d13e":"train.head()","40c6da68":"#convert bbox into XMin XMax YMin YMax\n#train[\"bbox\"][0][1:-1].split(', ')\nbox_dict = {'XMin':[], 'XMax':[], 'YMin':[], 'YMax':[]}\ndef bbox(x):\n    #x = X[1:-1].split(', ')\n    #min value\n    #print(x)\n    box_dict['XMin'].append(int(x[0]))\n    box_dict['YMin'].append(int(x[1]))\n    \n    #Max value\n    box_dict['XMax'].append(int(x[0])+int(x[2]))\n    box_dict['YMax'].append(int(x[1])+int(x[3]))\n    \n\nb = train[\"bbox\"].apply(lambda X: bbox(list(map(float,X[1:-1].split(', ')))))\nbox = pd.DataFrame(box_dict)","f584c989":"train = pd.concat([train,box],axis=1)\ntrain.drop(\"bbox\",axis=1,inplace=True)","5e59dfb7":"dir_train = os.listdir(\"\/kaggle\/input\/global-wheat-detection\/train\/\")\ndir_test = os.listdir(\"\/kaggle\/input\/global-wheat-detection\/test\/\")","94a3bc79":"len(dir_test)","0d953275":"#Creating full path for each image ID\ndef creatingPath(x):\n    return (\"\/kaggle\/input\/global-wheat-detection\/train\/\"+x+\".jpg\")\n\ntrain[\"path\"] = train[\"image_id\"].apply(creatingPath)","1a90f160":"\n#Plot some of the images\ndef plot_bbox(img_id):\n  img_url = train.loc[train[\"image_id\"]==img_id]['path'].values[0]\n  img = io.imread(img_url)\n  height, width, channel = img.shape\n  print(f\"Image: {img.shape}\")\n  bboxs = train[train['image_id']==img_id]\n  for index, row in bboxs.iterrows():\n      xmin = row['XMin']\n      xmax = row['XMax']\n      ymin = row['YMin']\n      ymax = row['YMax']\n      #xmin = int(xmin*width)\n      #xmax = int(xmax*width)\n      #ymin = int(ymin*height)\n      #ymax = int(ymax*height)\n      label_name = row['source']\n      class_series = train[train[\"source\"]==label_name]\n      class_name = class_series[\"source\"].values[0]\n      print(f\"Coordinates: {xmin,ymin}, {xmax,ymax}\")\n      cv2.rectangle(img, (xmin,ymin), (xmax,ymax), (255,0,0), 5)\n      font = cv2.FONT_HERSHEY_SIMPLEX\n      cv2.putText(img, class_name, (xmin,ymin-10), font, 1, (0,255,0), 5)\n  plt.figure(figsize=(15,10))\n  plt.title('Image with Bounding Box')\n  plt.imshow(img)\n  plt.axis(\"off\")\n  plt.show()","fecd9ca2":"least_objects_img_ids = train[\"image_id\"].value_counts().tail(50).index.values\nfor img_id in random.sample(list(least_objects_img_ids), 5):\n  plot_bbox(img_id)","643457d8":"train[\"source\"].value_counts()","f8a24383":"test_df = train[int(train.shape[0]*0.9):]\n\n# for test\nwith open(\"test_annotation.txt\", \"w+\") as f:\n  for idx, row in test_df.iterrows():\n      sys.stdout.write(str(idx) + '\\r')\n      sys.stdout.flush()\n      img = cv2.imread(row['path'])\n      height, width = img.shape[:2]\n      x1 = int(row['XMin'])\n      x2 = int(row['XMax'])\n      y1 = int(row['YMin'])\n      y2 = int(row['YMax'])\n      \n      #google_colab_file_path = 'drive\/My Drive\/AI\/Dataset\/Open Images Dataset v4 (Bounding Boxes)\/test'\n      fileName = row['path']\n      className = row['source']\n      f.write(fileName + ',' + str(x1) + ',' + str(y1) + ',' + str(x2) + ',' + str(y2) + ',' + className + '\\n')","f448e95c":"#Combine two dataframe image_id with annotation","aa69467a":"#Testing Dataset annotation","70eeee84":"train_df = train[:int(train.shape[0]*0.9)]\n\n# for training\nwith open(\"annotation.txt\", \"w+\") as f:\n  for idx, row in train_df.iterrows():\n      img = cv2.imread(row['path'])\n      height, width = img.shape[:2]\n      x1 = int(row['XMin'])\n      x2 = int(row['XMax'])\n      y1 = int(row['YMin'])\n      y2 = int(row['YMax'])\n      \n      #google_colab_file_path = 'drive\/My Drive\/AI\/Dataset\/Open Images Dataset v4 (Bounding Boxes)\/train'\n      fileName = row['path']\n      className = row['source']\n      f.write(fileName + ',' + str(x1) + ',' + str(y1) + ',' + str(x2) + ',' + str(y2) + ',' + className + '\\n')","13304578":"#Load the datasets","16345cf3":"#Load the Required libraries","bd7d697a":"This Kernal Will explain all the EDA and data preprocessing for Faster Rcnn.\n\n","47b14cda":"#Training dATASET annotation","adb3a5b2":"There are total 7 classes , out of 7 classes 3 are in minority and 4 are in majority classes.","30dc05f8":"#Lets Check the class distribution"}}