{"cell_type":{"861f3598":"code","63692ca0":"code","ddfe3339":"code","6557a625":"code","6698c9f1":"code","9f030ec7":"code","763fb382":"code","6422328f":"code","7efddd20":"code","de884c6d":"code","0da00864":"code","1bac777b":"code","127c013e":"code","e86d49b9":"code","31e6a9f2":"code","8401471f":"code","71043d39":"code","7d1fbaf2":"code","3c5bbcdb":"code","2dcc66aa":"code","f985cc1b":"code","3a7ad8c1":"code","f3684e05":"code","88c06231":"code","d965d77c":"code","7c02b4f0":"code","e93ef65f":"code","c8b10d53":"code","d0037ace":"code","bfb7bd8f":"code","7c0ba1f9":"code","c0fd6e67":"code","2bcbd362":"code","63181d13":"code","3544f87e":"code","7df60aaf":"code","e5eba02c":"code","03fdceb4":"code","3aa13b25":"markdown","2dbbd376":"markdown","a560b56d":"markdown","3484c8c2":"markdown","d1f1e67b":"markdown","062300c8":"markdown","3002dd92":"markdown","074615af":"markdown","f4473647":"markdown","8aae6832":"markdown","da4e392d":"markdown","28bf36f5":"markdown","c6c33041":"markdown","6496c1eb":"markdown","c6df9877":"markdown","edc6eb8a":"markdown","b9ba1bdc":"markdown","5f553e8e":"markdown","e72009ec":"markdown","6a09271b":"markdown","1265e775":"markdown","70e0f150":"markdown","4f9d3f3c":"markdown","f8789e46":"markdown","7692b66b":"markdown","bde2f54e":"markdown","6c20f3f4":"markdown","54b8e54d":"markdown","697e7af8":"markdown","ed60e7ff":"markdown","0de3e070":"markdown","7c85eeaa":"markdown"},"source":{"861f3598":"# Core\nimport pandas as pd\nimport numpy as np\nimport datetime\nimport warnings\n\n# Machine learning\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn import metrics\nfrom sklearn.cluster import AgglomerativeClustering\nfrom yellowbrick.cluster import KElbowVisualizer\n\n# Data Visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","63692ca0":"# Path of file to read Start from US\nfile_path = '..\/input\/customer-personality-analysis\/marketing_campaign.csv'\n\n#Load data into panda Dataframe.\ndata = pd.read_csv(file_path, sep=\"\\t\")","ddfe3339":"data.head()","6557a625":"print(data.shape)\nprint(data.nunique().sort_values(ascending=False))","6698c9f1":"# Look for info\ndata.info()","9f030ec7":"# List of numerical attributes\nprint(data.select_dtypes(exclude=['object']).columns)\nprint(len(data.select_dtypes(exclude=['object']).columns))","763fb382":"data.select_dtypes(exclude=['object']).describe().round(decimals=2)","6422328f":"print(data.select_dtypes(include=['object']).columns)\nprint(len(data.select_dtypes(include=['object']).columns))","7efddd20":"data.select_dtypes(include=['object']).describe()","de884c6d":"# Convert Dt_Customer\ndata[\"Dt_Customer\"] = pd.to_datetime(data[\"Dt_Customer\"])","0da00864":"# Remove NA\ndata = data.dropna()\nprint(\"Data after dropping NA:\", len(data))","1bac777b":"# Create Age\ndata[\"Age\"] = 2022-data[\"Year_Birth\"]\n\n# Create Total_Spent\ndata[\"Total_Spent\"] = data[\"MntWines\"]+ data[\"MntFruits\"]+ data[\"MntMeatProducts\"]+ data[\"MntFishProducts\"]+ data[\"MntSweetProducts\"]+ data[\"MntGoldProds\"]\n\n# Repalce Marital_Status to numerical for easy to manipulate by create Relation\ndata[\"Relation\"] = data[\"Marital_Status\"].replace({\"Married\": 2, \"Together\": 2, \"Absurd\": 1, \"Widow\": 1, \"YOLO\": 1, \"Divorced\": 1, \"Single\": 1, \"Alone\": 1})\n\n# Create Children for total minor living in family\ndata[\"Children\"] = data[\"Kidhome\"]+ data[\"Teenhome\"]\n\n# Create Family_Size\ndata[\"Family_Size\"] = data[\"Relation\"]+ data[\"Children\"]","127c013e":"data.describe()","e86d49b9":"data.nunique()","31e6a9f2":"# Grouping Education into 3 main group\ndata[\"Education\"] = data[\"Education\"].replace({\"Basic\": \"Undergraduate\", \"2n Cycle\": \"Undergraduate\", \"Graduation\": \"Graduate\", \"Master\": \"College\", \"PhD\": \"College\"})\n\n# Clarify all Mnt Columns\ndata = data.rename(columns = {\"MntWines\": \"Wines\",\"MntFruits\":\"Fruits\",\"MntMeatProducts\":\"Meat\",\"MntFishProducts\":\"Fish\",\"MntSweetProducts\":\"Sweets\",\"MntGoldProds\":\"Gold\"})\n\n# Dropping data\ndrop = [\"Marital_Status\", \"Z_CostContact\", \"Z_Revenue\", \"Year_Birth\", \"ID\", \"Dt_Customer\"]\ndata = data.drop(drop, axis=1)","8401471f":"data.describe()","71043d39":"data['Education'].value_counts()","7d1fbaf2":"# Visualize Education group\ndata['Education'].value_counts().plot(kind='bar', linewidth = 3)\nplt.title(\"Frequency Of Each Category in the Education Variable \\n\", fontsize=24)\nplt.figure(figsize=(8,8))","3c5bbcdb":"# Visualize Relation group\ndata['Relation'].value_counts().plot(kind='bar', linewidth = 3)\nplt.title(\"Frequency Of Each Category in the Education Variable \\n\", fontsize=24)\nplt.figure(figsize=(8,8))","2dcc66aa":"# Visualize Education and Total_Spent\nsns.set_theme(style=\"white\")\nplt.figure(figsize=(8,8))\nplt.title(\"Education compare to Total_Spent\",fontsize=24)\nax = sns.barplot(x=\"Education\", y=\"Total_Spent\", data=data, palette=\"rainbow\")","f985cc1b":"# Visualize Relation and Total_Spent\nsns.set_theme(style=\"white\")\nplt.figure(figsize=(8,8))\nplt.title(\"Relation compare to Total_Spent\",fontsize=24)\nax = sns.barplot(x=\"Relation\", y=\"Total_Spent\", data=data, palette=\"rainbow\")","3a7ad8c1":"# Visualize Family_Size and Total_Spent\nsns.set_theme(style=\"white\")\nplt.figure(figsize=(8,8))\nplt.title(\"Family_Size compare to Total_Spent\",fontsize=24)\nax = sns.barplot(x=\"Family_Size\", y=\"Total_Spent\", data=data, palette=\"rainbow\")","f3684e05":"## Note to self: learn about seaborn more as they are very useful.\n# using seaborn  to set color\nsns.set(rc={\"axes.facecolor\":\"#FFF7E6\",\"figure.facecolor\":\"#FFF7E6\"})\n# Plotting\nTo_Plot = [ \"Income\", \"Recency\", \"Age\", \"Total_Spent\", \"Relation\"]\nplt.figure()\nsns.pairplot(data[To_Plot], hue= \"Relation\", palette= ([\"#FFCC66\",\"#B30000\"]))    \nplt.show()","88c06231":"#Dropping the outliers by setting a cap on Age and income. \ndata = data[(data[\"Age\"]<90)]\ndata = data[(data[\"Income\"]<600000)]\nprint(\"The total number of data-points after removing the outliers are:\", len(data))","d965d77c":"#correlation matrix\nfrom matplotlib import colors\ncmap = colors.ListedColormap([\"#FFCC66\", \"#FF9933\", \"#CC6600\", \"#FF6600\", \"#B30000\"])\ncorrelation = data.corr()\nf, ax = plt.subplots(figsize=(20,20))\nplt.title('Correlation of numerical attributes', size=16)\nsns.heatmap(correlation,annot=True, cmap=cmap, center=0)\nplt.show()","7c02b4f0":"# Get a list of object\/categorical data\nobj = data.dtypes == 'object'\ncategorical_col = obj[obj].index\n\nprint(\"List of object= \", categorical_col)","e93ef65f":"# Label encoding and transform\nfor i in categorical_col:\n    data[i] = data[[i]].apply(LabelEncoder().fit_transform)","c8b10d53":"data1 = data.copy()\nto_drop = [\"AcceptedCmp3\", \"AcceptedCmp4\", \"AcceptedCmp5\", \"AcceptedCmp1\",\"AcceptedCmp2\", \"Complain\", \"Response\", ]\ndata1 = data1.drop(to_drop, axis=1)","d0037ace":"# Scaling data\nscaler = StandardScaler()\nscaled_feature = scaler.fit_transform(data1.values)\nscaled_df = pd.DataFrame(scaled_feature, index=data1.index, columns=data1.columns)","bfb7bd8f":"# Using the elbow method to find the optimal number of clusters\nElbow_M = KElbowVisualizer(KMeans(), k=10)\nElbow_M.fit(scaled_df)\nElbow_M.show()","7c0ba1f9":"#Initiating the Agglomerative Clustering model \nAC = AgglomerativeClustering(n_clusters=4)\n# fit model and predict clusters\nyhat_AC = AC.fit_predict(scaled_df)\nscaled_df[\"Clusters\"] = yhat_AC\n#Adding the Clusters feature to the orignal dataframe.\ndata[\"Clusters\"]= yhat_AC","c0fd6e67":"data['Education'].value_counts()","2bcbd362":"# Look at group distribution\n# Plotting countplot of clusters\npal = [\"#682F2F\",\"#B9C0C9\", \"#9F8A78\",\"#F3AB60\"]\npl = sns.countplot(x=data[\"Clusters\"], palette=\"rainbow\")\npl.set_title(\"Distribution Of The Clusters\")\nplt.show()","63181d13":"pl = sns.scatterplot(data = data,x=data[\"Total_Spent\"], y=data[\"Income\"],hue=data[\"Clusters\"], palette=\"rainbow\")\npl.set_title(\"Cluster's Profile Based On Income And Total Spending\")\nplt.legend()\nplt.show()","3544f87e":"plt.figure()\npl=sns.swarmplot(x=data[\"Clusters\"], y=data[\"Total_Spent\"], color= \"#CBEDDD\", alpha=0.5 )\npl=sns.boxenplot(x=data[\"Clusters\"], y=data[\"Total_Spent\"], palette=\"rainbow\")\nplt.show()","7df60aaf":"#Creating a feature to get a sum of accepted promotions \ndata[\"Total_Promo\"] = data[\"AcceptedCmp1\"]+ data[\"AcceptedCmp2\"]+ data[\"AcceptedCmp3\"]+ data[\"AcceptedCmp4\"]+ data[\"AcceptedCmp5\"]\n#Plotting count of total campaign accepted.\nplt.figure()\npl = sns.countplot(x=data[\"Total_Promo\"],hue=data[\"Clusters\"], palette= \"rainbow\")\npl.set_title(\"Count Of Promotion Accepted\")\npl.set_xlabel(\"Number Of Total Accepted Promotions\")\nplt.show()","e5eba02c":"# Plotting the number of deals purchased\nplt.figure()\npl=sns.boxenplot(y=data[\"NumDealsPurchases\"],x=data[\"Clusters\"], palette= \"rainbow\")\npl.set_title(\"Number of Deals Purchased\")\nplt.show()","03fdceb4":"Personal = [ \"Kidhome\",\"Teenhome\", \"Age\", \"Children\", \"Family_Size\", \"Relation\", \"Education\"]\n\nfor i in Personal:\n    plt.figure()\n    sns.jointplot(x=data[i], y=data[\"Total_Spent\"], hue =data[\"Clusters\"],kind=\"kde\", palette=\"rainbow\")\n    plt.show()","3aa13b25":"### Explore the data\nWe first explore data to:\n1. Understanding of available data\n2. Check for missing or null\n3. Find potential outliers\n4. Find correlations\n5. Check for data skew","2dbbd376":"We will start to see what is characteristic of each group.","a560b56d":"The deal appear to be well recieved especially in grop 0 and 1. However our main focus group 3 is not greatly affect.","3484c8c2":"First of all I will deal with NA data by dropping it.","d1f1e67b":"## Clustering","062300c8":"It's appear Z_CostContact and Z_Revenue have only 1 value so we drop them as they are not contribute in model.","3002dd92":"It's appear the campaign is not very successful. There appear to have very low particition rate so it's best to find a way to improve.","074615af":"From the above we can observe that:\n* Group 0 : Low spending & Average income\n* Group 1 : High spending & Average Income\n* Group 2 : Low spending  & Low income\n* Group 3 : High spending & High income","f4473647":"### Categorical columns within the dataset","8aae6832":"## Evaluating model","da4e392d":"## Exploring data","28bf36f5":"It's appear that 4 will be the best number for this data. We will use Agglomerative Clustering to fit data next.","c6c33041":"## Assess correlations","6496c1eb":"That's it for my attemp analysis for this dataset do let's me know what should be improve or what I miss.\n\nThank you very much!","c6df9877":"In this case there are only 2 categorical data as Dt_Customer will convert to DateTime which is:\n* Education\n* Marital_Status","edc6eb8a":"# Attemping to exploring customer information to build model.","b9ba1bdc":"So from above we can see that:\n#### Group 0\n* Parents\n* At least 2 with maximum of 5 members in family\n* Also include single parent\n* Majority have teenager at home\n* Relatively older\n* Average income\n\n#### Group 1\n* Parents\n* At least 2 with maximum of 3 members in family\n* Relatively older\n* Average income but high spending\n\n#### Group 2\n* Majority are parents\n* Maximum 4 members in family\n* Majorly have 1 young kid.\n* Younger compare to others.\n* Low income\n* Have the highest undergraduate education\n\n#### Group 3\n* Not a parent\n* Only 2 member in family\n* Mostly couples\n* All ages\n* High Income","5f553e8e":"## Prelim observations","e72009ec":"## Data Cleaning & Featuaring","6a09271b":"* It's appear there are missing data in Income consider dropping in this case.\n* Dt_Customer is not in DateTime so we need to convert.","1265e775":"## Profiling","70e0f150":"### Import modules","4f9d3f3c":"There is still a lot of rebendant feature and we can also clean data better:\n* In the Education consider grouping them\n* Clarify all Mnt columns\n* Dropping rebundant \/ irreverent data","f8789e46":"Welcome to my second kennel. In this kennel I apply what I learn to build prediction model for this data set.","7692b66b":"Next we will see how our campaign did.","bde2f54e":"We are looking for the pattern that occure for this unsupervised clustering.","6c20f3f4":"Next I will create some features:\n* Create **Age** from **Year_Birth**\n* Create **Total_Spent** from total amount spent\n* Create **Family_Size** from total faimily member","54b8e54d":"Reminder that for Education \n* 1 = Graduate\n* 0 = College\n* 2 = Undergraduate","697e7af8":"## Data prepocessing","ed60e7ff":"### Numerical columns within dataset","0de3e070":"There are some outliers in the Income and Age features. ","7c85eeaa":"### Reading input file"}}