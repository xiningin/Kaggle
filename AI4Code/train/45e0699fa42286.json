{"cell_type":{"d9f5becd":"code","fbc70421":"code","0ff193fd":"code","380fcc29":"code","72d5e588":"code","c858a417":"code","95085c02":"code","e5880212":"code","e8a70724":"code","81515ead":"code","9b27a379":"code","32fbe3e6":"code","cbaea138":"code","ed9aff9c":"code","ca8fbe97":"markdown"},"source":{"d9f5becd":"%%bash\npip install pytorch-pfn-extras\npip install timm","fbc70421":"import os\nimport gc\nimport copy\nimport yaml\nimport random\nimport shutil\nimport typing as tp\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nimport torch\nfrom torch import nn\nfrom torch import optim\nfrom torch.optim import lr_scheduler\nfrom torch.cuda import amp\n\nimport timm\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport pytorch_pfn_extras as ppe\nfrom pytorch_pfn_extras.config import Config\nfrom pytorch_pfn_extras.training import extensions as ppe_exts, triggers as ppe_triggers","0ff193fd":"ROOT = Path.cwd().parent\nINPUT = ROOT \/ \"input\"\nOUTPUT = ROOT \/ \"output\"\nDATA = INPUT \/ \"seti-breakthrough-listen\"\nTRAIN = DATA \/ \"train\"\nTEST = DATA \/ \"test\"\n\nTMP = ROOT \/ \"tmp\"\nTMP.mkdir(exist_ok=True)\n\nRANDAM_SEED = 1086\nCLASSES = [\"target\",]\nN_CLASSES = len(CLASSES)\nFOLDS = [0, 1, 2, 3]\nN_FOLDS = len(FOLDS)","380fcc29":"train = pd.read_csv(DATA \/ \"train_labels.csv\")\nsmpl_sub = pd.read_csv(DATA \/ \"sample_submission.csv\")\nskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDAM_SEED)\ntrain[\"fold\"] = -1\nfor fold_id, (_, val_idx) in enumerate(skf.split(train[\"id\"], train[\"target\"])):\n    train.loc[val_idx, \"fold\"] = fold_id\ntrain.groupby(\"fold\").agg(total=(\"id\", len), pos=(\"target\", sum))","72d5e588":"class BasicImageModel(nn.Module):\n\n    def __init__(\n            self, base_name: str, dims_head: tp.List[int],\n            pretrained=False, in_channels: int = 3\n    ):\n        \"\"\"Initialize\"\"\"\n        self.base_name = base_name\n        super(BasicImageModel, self).__init__()\n\n        # # prepare backbone\n        if hasattr(timm.models, base_name):\n            base_model = timm.create_model(\n                base_name, num_classes=0, pretrained=pretrained, in_chans=in_channels)\n            in_features = base_model.num_features\n            print(\"load imagenet pretrained:\", pretrained)\n        else:\n            raise NotImplementedError\n\n        self.backbone = base_model\n        print(f\"{base_name}: {in_features}\")\n\n        # # prepare head clasifier\n        if dims_head[0] is None:\n            dims_head[0] = in_features\n\n        layers_list = []\n        for i in range(len(dims_head) - 2):\n            in_dim, out_dim = dims_head[i: i + 2]\n            layers_list.extend([\n                nn.Linear(in_dim, out_dim),\n                nn.ReLU(), nn.Dropout(0.5), ])\n        layers_list.append(\n            nn.Linear(dims_head[-2], dims_head[-1]))\n        self.head_cls = nn.Sequential(*layers_list)\n\n    def forward(self, x):\n        \"\"\"Forward\"\"\"\n        h = self.backbone(x)\n        h = self.head_cls(h)\n        return h","c858a417":"FilePath = tp.Union[str, Path]\nLabel = tp.Union[int, float, np.ndarray]\n\n\nclass SetiSimpleDataset(torch.utils.data.Dataset):\n    \"\"\"\n    Dataset using 6 channels by stacking them along time-axis\n\n    Attributes\n    ----------\n    paths : tp.Sequence[FilePath]\n        Sequence of path to cadence snippet file\n    labels : tp.Sequence[Label]\n        Sequence of label for cadence snippet file\n    transform: albumentations.Compose\n        composed data augmentations for data\n    \"\"\"\n\n    def __init__(\n            self,\n            paths: tp.Sequence[FilePath],\n            labels: tp.Sequence[Label],\n            transform: A.Compose,\n    ):\n        \"\"\"Initialize\"\"\"\n        self.paths = paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        \"\"\"Return num of cadence snippets\"\"\"\n        return len(self.paths)\n\n    def __getitem__(self, index: int):\n        \"\"\"Return transformed image and label for given index.\"\"\"\n        path, label = self.paths[index], self.labels[index]\n        img = self._read_cadence_array(path)\n        img = self.transform(image=img)[\"image\"]\n        return {\"image\": img, \"target\": label}\n\n    def _read_cadence_array(self, path: Path):\n        \"\"\"Read cadence file and reshape\"\"\"\n        img = np.load(path)  # shape: (6, 273, 256)\n        img = np.vstack(img)  # shape: (1638, 256)\n        img = img.transpose(1, 0)  # shape: (256, 1638)\n        img = img.astype(\"f\")[..., np.newaxis]  # shape: (256, 1638, 1)\n        return img\n\n    def lazy_init(self, paths=None, labels=None, transform=None):\n        \"\"\"Reset Members\"\"\"\n        if paths is not None:\n            self.paths = paths\n        if labels is not None:\n            self.labels = labels\n        if transform is not None:\n            self.transform = transform\n\n\nclass SetiAObsDataset(SetiSimpleDataset):\n    \"\"\"Use only on-target observation\"\"\"\n\n    def _read_cadence_array(self, path: Path):\n        \"\"\"Read cadence file and reshape\"\"\"\n        img = np.load(path)[[0, 2, 4]]  # shape: (3, 273, 256)\n        img = np.vstack(img)  # shape: (819, 256)\n        img = img.transpose(1, 0)  # shape: (256, 819)\n        img = img.astype(\"f\")[..., np.newaxis]  # shape: (256, 819, 1)\n        return img\n\n\nBatch = tp.Union[tp.Tuple[torch.Tensor], tp.Dict[str, torch.Tensor]]\nModelOut = tp.Union[tp.Tuple[torch.Tensor], tp.Dict[str, torch.Tensor], torch.Tensor]\n\n\nclass ROCAUC(nn.Module):\n    \"\"\"ROC AUC score\"\"\"\n\n    def __init__(self, average=\"macro\") -> None:\n        \"\"\"Initialize.\"\"\"\n        self.average = average\n        super(ROCAUC, self).__init__()\n\n    def forward(self, y, t) -> float:\n        \"\"\"Forward.\"\"\"\n        if isinstance(y, torch.Tensor):\n            y = y.detach().cpu().numpy()\n        if isinstance(t, torch.Tensor):\n            t = t.detach().cpu().numpy()\n\n        return roc_auc_score(t, y, average=self.average)\n\n\ndef micro_average(\n        metric_func: nn.Module,\n        report_name: str, prefix=\"val\",\n        pred_index: int = -1, label_index: int = -1,\n        pred_key: str = \"logit\", label_key: str = \"target\",\n) -> tp.Callable:\n    \"\"\"Return Metric Wrapper for Simple Mean Metric\"\"\"\n    metric_sum = [0.]\n    n_examples = [0]\n\n    def wrapper(batch: Batch, model_output: ModelOut, is_last_batch: bool):\n        \"\"\"Wrapping metric function for evaluation\"\"\"\n        if isinstance(batch, tuple):\n            t = batch[label_index]\n        elif isinstance(batch, dict):\n            t = batch[label_key]\n        else:\n            raise NotImplementedError\n\n        if isinstance(model_output, tuple):\n            y = model_output[pred_index]\n        elif isinstance(model_output, dict):\n            y = model_output[pred_key]\n        else:\n            y = model_output\n\n        metric = metric_func(y, t).item()\n        metric_sum[0] += metric * y.shape[0]\n        n_examples[0] += y.shape[0]\n\n        if is_last_batch:\n            final_metric = metric_sum[0] \/ n_examples[0]\n            ppe.reporting.report({f\"{prefix}\/{report_name}\": final_metric})\n            # # reset state\n            metric_sum[0] = 0.\n            n_examples[0] = 0\n\n    return wrapper\n\n\ndef calc_across_all_batchs(\n        metric_func: nn.Module,\n        report_name: str, prefix=\"val\",\n        pred_index: int = -1, label_index: int = -1,\n        pred_key: str = \"logit\", label_key: str = \"target\",\n) -> tp.Callable:\n    \"\"\"\n    Return Metric Wrapper for Metrics caluculated on all data\n\n    storing predictions and labels of evry batch, finally calculating metric on them.\n    \"\"\"\n    pred_list = []\n    label_list = []\n\n    def wrapper(batch: Batch, model_output: ModelOut, is_last_batch: bool):\n        \"\"\"Wrapping metric function for evaluation\"\"\"\n        if isinstance(batch, tuple):\n            t = batch[label_index]\n        elif isinstance(batch, dict):\n            t = batch[label_key]\n        else:\n            raise NotImplementedError\n\n        if isinstance(model_output, tuple):\n            y = model_output[pred_index]\n        elif isinstance(model_output, dict):\n            y = model_output[pred_key]\n        else:\n            y = model_output\n\n        pred_list.append(y.numpy())\n        label_list.append(t.numpy())\n\n        if is_last_batch:\n            pred = np.concatenate(pred_list, axis=0)\n            label = np.concatenate(label_list, axis=0)\n            final_metric = metric_func(pred, label)\n            ppe.reporting.report({f\"{prefix}\/{report_name}\": final_metric})\n            # # reset state\n            pred_list[:] = []\n            label_list[:] = []\n\n    return wrapper","95085c02":"CONFIG_TYPES = {\n    # # utils\n    \"__len__\": lambda obj: len(obj),\n    \"method_call\": lambda obj, method: getattr(obj, method)(),\n\n    # # Dataset, DataLoader\n    \"SetiSimpleDataset\": SetiSimpleDataset,\n    \"SetiAObsDataset\": SetiAObsDataset,\n    \"DataLoader\": torch.utils.data.DataLoader,\n\n    # # Data Augmentation\n    \"Compose\": A.Compose, \"OneOf\": A.OneOf,\n    \"Resize\": A.Resize,\n    \"HorizontalFlip\": A.HorizontalFlip, \"VerticalFlip\": A.VerticalFlip,\n    \"ShiftScaleRotate\": A.ShiftScaleRotate,\n    \"RandomResizedCrop\": A.RandomResizedCrop,\n    \"Cutout\": A.Cutout,\n    \"ToTensorV2\": ToTensorV2,\n\n    # # Model\n    \"BasicImageModel\": BasicImageModel,\n\n    # # Optimizer\n    \"AdamW\": optim.AdamW,\n\n    # # Scheduler\n    \"OneCycleLR\": lr_scheduler.OneCycleLR,\n\n    # # Loss,Metric\n    \"BCEWithLogitsLoss\": nn.BCEWithLogitsLoss,\n    \"ROCAUC\": ROCAUC,\n\n    # # Metric Wrapper\n    \"micro_average\": micro_average,\n    \"calc_across_all_batchs\": calc_across_all_batchs,\n\n    # # PPE Extensions\n    \"ExtensionsManager\": ppe.training.ExtensionsManager,\n\n    \"observe_lr\": ppe_exts.observe_lr,\n    \"LogReport\": ppe_exts.LogReport,\n    \"PlotReport\": ppe_exts.PlotReport,\n    \"PrintReport\": ppe_exts.PrintReport,\n    \"PrintReportNotebook\": ppe_exts.PrintReportNotebook,\n    \"ProgressBar\": ppe_exts.ProgressBar,\n    \"ProgressBarNotebook\": ppe_exts.ProgressBarNotebook,\n    \"snapshot\": ppe_exts.snapshot,\n    \"LRScheduler\": ppe_exts.LRScheduler,\n\n    \"MinValueTrigger\": ppe_triggers.MinValueTrigger,\n    \"MaxValueTrigger\": ppe_triggers.MaxValueTrigger,\n    \"EarlyStoppingTrigger\": ppe_triggers.EarlyStoppingTrigger,\n}\n\npre_eval_cfg = yaml.safe_load(\n    \"\"\"\n    globals:\n      seed: 1086\n      val_fold: null  # indicate when training\n      output_path: null # indicate when training\n      device: cuda\n      enable_amp: False\n      max_epoch: 80\n    \n    model:\n      type: BasicImageModel\n      dims_head: [null, 1]\n      base_name: efficientnet_b0\n      pretrained: True\n      in_channels: 1\n    \n    dataset:\n      height: 512\n      width: 512\n      mixup: {enabled: True, alpha: 0.2}\n      train:\n        type: SetiAObsDataset\n        paths: null  # set by lazy_init\n        labels: null  # set by lazy_init\n        transform:\n          type: Compose\n          transforms:\n            - {type: Resize, p: 1.0, height: \"@\/dataset\/height\", width: \"@\/dataset\/width\"}\n            - {type: HorizontalFlip, p: 0.5}\n            - {type: VerticalFlip, p: 0.5}\n            - {type: ShiftScaleRotate, p: 0.5, shift_limit: 0.2, scale_limit: 0.2,\n                rotate_limit: 20, border_mode: 0, value: 0, mask_value: 0}\n            - {type: RandomResizedCrop, p: 1.0,\n                scale: [0.9, 1.0], height: \"@\/dataset\/height\", width: \"@\/dataset\/width\"}\n            - {type: ToTensorV2, always_apply: True}\n      val:\n        type: SetiAObsDataset\n        paths: null  # set by lazy_init\n        labels: null  # set by lazy_init\n        transform:\n          type: Compose\n          transforms:\n            - {type: Resize, p: 1.0, height: \"@\/dataset\/height\", width: \"@\/dataset\/width\"}\n            - {type: ToTensorV2, always_apply: True}  \n      test:\n        type: SetiAObsDataset\n        paths: null  # set by lazy_init\n        labels: null  # set by lazy_init\n        transform: \"@\/dataset\/val\/transform\"\n    \n    loader:\n      train: {type: DataLoader, dataset: \"@\/dataset\/train\",\n        batch_size: 32, num_workers: 4, shuffle: True, pin_memory: True, drop_last: True}\n      val: {type: DataLoader, dataset: \"@\/dataset\/val\",\n        batch_size: 64, num_workers: 4, shuffle: False, pin_memory: True, drop_last: False}\n      test: {type: DataLoader, dataset: \"@\/dataset\/test\",\n        batch_size: 64, num_workers: 4, shuffle: False, pin_memory: True, drop_last: False}\n    \n    optimizer:\n      type: AdamW\n      params: {type: method_call, obj: \"@\/model\", method: parameters}\n      lr: 1.0e-06\n      weight_decay: 1.0e-02\n    \n    scheduler:\n      type: OneCycleLR\n      optimizer: \"@\/optimizer\"\n      epochs: \"@\/globals\/max_epoch\"\n      steps_per_epoch: {type: __len__, obj: \"@\/loader\/train\"}\n      max_lr: 1.0e-3\n      pct_start: 0.1\n      anneal_strategy: cos\n      div_factor: 1.0e+3\n      final_div_factor: 1.0e+3\n    \n    loss: {type: BCEWithLogitsLoss}\n    \n    eval:\n      - type: micro_average\n        metric_func: {type: BCEWithLogitsLoss}\n        report_name: loss\n      - type: calc_across_all_batchs\n        metric_func: {type: ROCAUC}\n        report_name: metric\n    \n    manager:\n      type: ExtensionsManager\n      models: \"@\/model\"\n      optimizers: \"@\/optimizer\"\n      max_epochs: \"@\/globals\/max_epoch\"\n      iters_per_epoch: {type: __len__, obj: \"@\/loader\/train\"}\n      out_dir: \"@\/globals\/output_path\"\n      # stop_trgiger: {type: EarlyStoppingTrigger,\n      #   monitor: val\/metric, mode: max, patience: 5, verbose: True,\n      #   check_trigger: [1, epoch], max_trigger: [\"@\/globals\/max_epoch\", epoch]}\n    \n    extensions:\n      # # log\n      - {type: observe_lr, optimizer: \"@\/optimizer\"}\n      - {type: LogReport}\n      - {type: PlotReport, y_keys: lr, x_key: epoch, filename: lr.png}\n      - {type: PlotReport, y_keys: [train\/loss, val\/loss], x_key: epoch, filename: loss.png}\n      - {type: PlotReport, y_keys: val\/metric, x_key: epoch, filename: metric.png}\n      - {type: PrintReport, entries: [\n          epoch, iteration, lr, train\/loss, val\/loss, val\/metric, elapsed_time]}\n      - {type: ProgressBarNotebook, update_interval: 20}\n      # snapshot\n      - extension: {type: snapshot, target: \"@\/model\", filename: \"snapshot_by_metric_epoch_{.epoch}.pth\"}\n        trigger: {type: MaxValueTrigger, key: \"val\/metric\", trigger: [1, epoch]}\n      # # lr scheduler\n      - {type: LRScheduler, scheduler: \"@\/scheduler\", trigger: [1,  iteration]}\n    \"\"\"\n)","e5880212":"def set_random_seed(seed: int = 42, deterministic: bool = False):\n    \"\"\"Set seeds\"\"\"\n    random.seed(seed)\n    random_state = np.random.RandomState(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\n\ndef to_device(\n        tensors: tp.Union[tp.Tuple[torch.Tensor], tp.Dict[str, torch.Tensor]],\n        device: torch.device, *args, **kwargs\n):\n    if isinstance(tensors, tuple):\n        return (t.to(device, *args, **kwargs) for t in tensors)\n    elif isinstance(tensors, dict):\n        return {\n            k: t.to(device, *args, **kwargs) for k, t in tensors.items()}\n    else:\n        return tensors.to(device, *args, **kwargs)\n\n\ndef get_path_label(cfg: Config, train_all: pd.DataFrame):\n    \"\"\"Get file path and target info.\"\"\"\n    use_fold = cfg[\"\/globals\/val_fold\"]\n\n    train_df = train_all[train_all[\"fold\"] != use_fold]\n    val_df = train_all[train_all[\"fold\"] == use_fold]\n    \n    train_path_label = {\n        \"paths\": [TRAIN \/ f\"{img_id[0]}\/{img_id}.npy\" for img_id in train_df[\"id\"].values],\n        \"labels\": train_df[CLASSES].values.astype(\"f\")}\n    val_path_label = {\n        \"paths\": [TRAIN \/ f\"{img_id[0]}\/{img_id}.npy\" for img_id in val_df[\"id\"].values],\n        \"labels\": val_df[CLASSES].values.astype(\"f\")\n    }\n    return train_path_label, val_path_label\n\n\ndef get_eval_func(cfg, model, device):\n    \n    def eval_func(**batch):\n        \"\"\"Run evaliation for val or test. This function is applied to each batch.\"\"\"\n        batch = to_device(batch, device)\n        x = batch[\"image\"]\n        with amp.autocast(cfg[\"\/globals\/enable_amp\"]): \n            y = model(x)\n        return y.detach().cpu().to(torch.float32)  # input of metrics\n\n    return eval_func\n\n","e8a70724":"def run_inference_loop(cfg, model, loader, device):\n    model.to(device)\n    model.eval()\n    pred_list = []\n    with torch.no_grad():\n        for batch in tqdm(loader):\n            x = to_device(batch[\"image\"], device)\n            y = model(x)\n            pred_list.append(y.sigmoid().detach().cpu().numpy())\n        \n    pred_arr = np.concatenate(pred_list)\n    del pred_list\n    return pred_arr","81515ead":"label_arr = train[CLASSES].values\noof_pred_arr = np.zeros((len(train), N_CLASSES))\nscore_list = []\ntest_pred_arr = np.zeros((N_FOLDS, len(smpl_sub), N_CLASSES))\ntest_path_label = {\n    \"paths\": [DATA \/ f\"test\/{img_id[0]}\/{img_id}.npy\" for img_id in smpl_sub[\"id\"].values],\n    \"labels\": smpl_sub[CLASSES].values.astype(\"f\")\n}\n\nfor fold_id in range(N_FOLDS):\n    print(f\"[fold {fold_id}]\")\n    tmp_dir = Path(f\"..\/input\/fold-{fold_id}\")\n    with open(tmp_dir \/ \"config.yml\", \"r\") as fr:\n        cfg = Config(yaml.safe_load(fr), types=CONFIG_TYPES)\n    torch.backends.cudnn.benchmark = True\n    set_random_seed(cfg[\"\/globals\/seed\"], True)\n    device = torch.device(cfg[\"\/globals\/device\"])\n    val_idx = train.query(\"fold == @fold_id\").index.values\n\n    # # get_dataloader\n    _, val_path_label = get_path_label(cfg, train)\n    cfg[\"\/dataset\/val\"].lazy_init(**val_path_label)\n    cfg[\"\/dataset\/test\"].lazy_init(**test_path_label)\n    val_loader = cfg[\"\/loader\/val\"]\n    test_loader = cfg[\"\/loader\/test\"]\n    \n    # # get model\n    model_path = f\"..\/input\/eff-b0-model\/best_metric_model_fold{fold_id}.pth\"\n    model = cfg[\"\/model\"]\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    \n    # # inference\n    val_pred = run_inference_loop(cfg, model, val_loader, device)\n    val_score = roc_auc_score(label_arr[val_idx], val_pred)\n    oof_pred_arr[val_idx] = val_pred\n    score_list.append([fold_id, val_score])\n    \n    test_pred_arr[fold_id] = run_inference_loop(cfg, model, test_loader, device)\n    \n    del cfg, val_idx, val_path_label\n    del model, val_loader, test_loader\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    print(f\"val score: {val_score:.4f}\")","9b27a379":"oof_score = roc_auc_score(label_arr, oof_pred_arr)\nscore_list.append([\"oof\", oof_score])\npd.DataFrame(score_list, columns=[\"fold\", \"metric\"])","32fbe3e6":"oof_df = train.copy()\noof_df[CLASSES] = oof_pred_arr\noof_df.to_csv(\".\/oof_prediction.csv\", index=False)","cbaea138":"sub_df = smpl_sub.copy()\nsub_df[CLASSES] = test_pred_arr.mean(axis=0)\nsub_df.to_csv(\".\/submission.csv\", index=False)","ed9aff9c":"sub_df.head()","ca8fbe97":"* thanks for https:\/\/www.kaggle.com\/ttahara\/seti-e-t-resnet18d-baseline  https:\/\/www.kaggle.com\/c\/seti-breakthrough-listen\/discussion\/245608\n* This is just a reference and not my best model at the moment\ud83d\ude1c\n* If you think it's good, you can vote to encourage it\ud83d\udc95"}}