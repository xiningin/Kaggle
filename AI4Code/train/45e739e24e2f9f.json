{"cell_type":{"1e8c051d":"code","1e1c093f":"code","35bbad4f":"code","995a7337":"code","bf36ef9e":"code","2205ca9b":"code","8a67a025":"code","2223eae7":"code","a007a927":"code","b7f80f07":"code","5cc44186":"code","37a90523":"code","91f4d15a":"code","5f9e2fde":"code","ccbedc47":"code","3baca675":"code","5010db18":"code","98f9118b":"code","1441114b":"code","4e9fe656":"code","1531763c":"code","7e083528":"code","0da965aa":"code","09711302":"code","7ae72526":"code","4d908bb1":"code","9be50397":"code","b94bc3c2":"markdown","2c80aa07":"markdown","332017f4":"markdown","cf1df263":"markdown","e19cfb88":"markdown","1a6c478b":"markdown","a0ca7e10":"markdown","5747c55a":"markdown","147b1306":"markdown","ec9926e0":"markdown","ff6e3ac0":"markdown"},"source":{"1e8c051d":"# Clone YOLOv5 code\n!git clone https:\/\/github.com\/rkuo2000\/yolov5\n%cd yolov5","1e1c093f":"!echo \"train: Dataset\/train\/images\" > data\/alpr.yaml\n!echo \"val:   Dataset\/train\/images\" >> data\/alpr.yaml\n\n!echo \"nc : 1\" >> data\/alpr.yaml\n!echo \"names: ['license']\" >> data\/alpr.yaml\n\n!cat data\/alpr.yaml","35bbad4f":"import os\nimport numpy as np\nfrom pathlib import Path\nfrom xml.dom.minidom import parse\nfrom shutil import copyfile","995a7337":"FILE_ROOT = \"\/kaggle\/input\/car-plate-detection\/\"\nIMAGE_PATH = FILE_ROOT + \"images\"  \nANNOTATIONS_PATH = FILE_ROOT + \"annotations\"\n\nDATA_ROOT = \"Dataset\/\"\nDEST_IMAGES_PATH = \"train\/images\"\nDEST_LABELS_PATH = \"train\/labels\"","bf36ef9e":"!mkdir -p Dataset\/train\/labels","2205ca9b":"# copy images\n!mkdir -p Dataset\/train\n!cp -rf \/kaggle\/input\/car-plate-detection\/images Dataset\/train","8a67a025":"!mkdir -p Dataset\/val\n!cp -rf \/kaggle\/input\/car-plate-detection\/images\/Cars1*.png Dataset\/val","2223eae7":"def cord_converter(size, box):\n    \"\"\"\n    convert xml annotation to darknet format coordinates\n    :param size\uff1a [w,h]\n    :param box: anchor box coordinates [upper-left x,uppler-left y,lower-right x, lower-right y]\n    :return: converted [x,y,w,h]\n    \"\"\"\n    x1 = int(box[0])\n    y1 = int(box[1])\n    x2 = int(box[2])\n    y2 = int(box[3])\n\n    dw = np.float32(1. \/ int(size[0]))\n    dh = np.float32(1. \/ int(size[1]))\n\n    w = x2 - x1\n    h = y2 - y1\n    x = x1 + (w \/ 2)\n    y = y1 + (h \/ 2)\n\n    x = x * dw\n    w = w * dw\n    y = y * dh\n    h = h * dh\n    return [x, y, w, h]\n    \ndef save_file(img_jpg_file_name, size, img_box):\n    classes = ['license']\n    save_file_name = DATA_ROOT + DEST_LABELS_PATH + '\/' + img_jpg_file_name + '.txt'\n    print(save_file_name)\n    file_path = open(save_file_name, \"a+\")\n    for box in img_box:                  \n        #cls_num = classes.index(box[0]) # find class_id\n        cls_num = 0\n        new_box = cord_converter(size, box[1:]) # convert box coord into YOLO x,y,w,h\n\n        file_path.write(f\"{cls_num} {new_box[0]} {new_box[1]} {new_box[2]} {new_box[3]}\\n\")\n\n    file_path.flush()\n    file_path.close()\n    \ndef get_xml_data(file_path, img_xml_file):\n    img_path = file_path + '\/' + img_xml_file + '.xml'\n    print(img_path)\n\n    dom = parse(img_path)\n    root = dom.documentElement\n    img_name = root.getElementsByTagName(\"filename\")[0].childNodes[0].data\n    img_size = root.getElementsByTagName(\"size\")[0]\n    objects = root.getElementsByTagName(\"object\")\n    img_w = img_size.getElementsByTagName(\"width\")[0].childNodes[0].data\n    img_h = img_size.getElementsByTagName(\"height\")[0].childNodes[0].data\n    img_c = img_size.getElementsByTagName(\"depth\")[0].childNodes[0].data\n    # print(\"img_name:\", img_name)\n    # print(\"image_info:(w,h,c)\", img_w, img_h, img_c)\n    img_box = []\n    for box in objects:\n        cls_name = box.getElementsByTagName(\"name\")[0].childNodes[0].data\n        x1 = int(box.getElementsByTagName(\"xmin\")[0].childNodes[0].data)\n        y1 = int(box.getElementsByTagName(\"ymin\")[0].childNodes[0].data)\n        x2 = int(box.getElementsByTagName(\"xmax\")[0].childNodes[0].data)\n        y2 = int(box.getElementsByTagName(\"ymax\")[0].childNodes[0].data)\n        print(\"box:(c,xmin,ymin,xmax,ymax)\", cls_name, x1, y1, x2, y2)\n        img_jpg_file_name = img_xml_file + '.jpg'\n        img_box.append([cls_name, x1, y1, x2, y2])\n    # print(img_box)\n    # test_dataset_box_feature(img_jpg_file_name, img_box)\n    save_file(img_xml_file, [img_w, img_h], img_box)","a007a927":"files = os.listdir(ANNOTATIONS_PATH)\nfor file in files:\n    print(\"file name: \", file)\n    file_xml = file.split(\".\")\n    get_xml_data(ANNOTATIONS_PATH, file_xml[0])","b7f80f07":"!mkdir -p Dataset\/val\/labels\n!cp -rf Dataset\/train\/labels\/Cars1*.txt Dataset\/val\/labels","5cc44186":"!ls Dataset\/train\/labels","37a90523":"!python train.py --img 416 --batch 16 --epochs 300 --data data\/alpr.yaml --cfg models\/yolov5s.yaml","91f4d15a":"# Download OpenALPR Benchmarks\n%cd ..\n!git clone https:\/\/github.com\/openalpr\/benchmarks","5f9e2fde":"%cd yolov5","ccbedc47":"!python detect.py --source ..\/benchmarks\/endtoend\/us --conf 0.4 --weights runs\/train\/exp\/weights\/best.pt --save-txt","3baca675":"!python detect.py --source ..\/benchmarks\/endtoend\/eu --conf 0.4 --weights runs\/train\/exp\/weights\/best.pt --save-txt","5010db18":"!python detect.py --source ..\/benchmarks\/endtoend\/br --conf 0.4 --weights runs\/train\/exp\/weights\/best.pt --save-txt","98f9118b":"from IPython.display import Image","1441114b":"Image('runs\/detect\/exp\/0b86cecf-67d1-4fc0-87c9-b36b0ee228bb.jpg')","4e9fe656":"Image('runs\/detect\/exp2\/test_001.jpg')","1531763c":"Image('runs\/detect\/exp3\/PWF3266.jpg')","7e083528":"# list saved .txt\n!ls runs\/detect\/exp\/labels","0da965aa":"# read .txt to get x,y,w,h of ALPR\ndef read_txt(filepath):\n    f = open(filepath, 'r')\n    lines = f.readlines()\n         \n    # read objects from each line of .txt\n    objects = []\n    for line in lines:\n        line=line.rstrip()\n        obj = [int(float(i)) for i in line.split(' ')]\n        objects.append(obj)\n    #print(objects)\n    return objects","09711302":"!pip install pytesseract","7ae72526":"DETECT_PATH = '\/kaggle\/working\/yolov5\/runs\/detect\/exp\/'\nIMG_NAME    = 'us10'","4d908bb1":"Image(DETECT_PATH+IMG_NAME+'.jpg')","9be50397":"import pytesseract\nimport cv2\nimport matplotlib.pyplot as plt\nimg = cv2.imread(DETECT_PATH+IMG_NAME+'.jpg')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nlics = read_txt(DETECT_PATH +'labels\/'+IMG_NAME+'.txt')\n\nfor lic in lics:\n    c, x, y, w, h = lic\n    print(x,y,w,h) # center of the bounding box\n    img_alpr = img[y-int(h\/2):y+int(h\/2),x-int(w\/2):x+int(w\/2)]\n    plt.imshow(img_alpr)\n    txt = pytesseract.image_to_string(img_alpr)\n    print(txt)\n    \n#    img = cv2.putText(img, txt, (x-int(w\/2),y-int(h\/2)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2)   \n#cv2.imwrite('alpr_us1.jpg', img)","b94bc3c2":"### Convert COCO Annotations to YOLOv5 Labels","2c80aa07":"## Repro [YOLOv5](https:\/\/github.com\/ultralytics\/yolov5)","332017f4":"## YOLOv5 Training","cf1df263":"## OCR ","e19cfb88":"### OCR using PyTesseract","1a6c478b":"# YOLOv5 for Automatic License Plate Recognition","a0ca7e10":"### get detected ALPR bounding box","5747c55a":"## Dataset: [Car License Plate Detection](https:\/\/www.kaggle.com\/andrewmvd\/car-plate-detection)\n![](https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-user-content\/o\/inbox%2F793761%2Fc15e812b3ab9aad2c0694a2e1f7548e9%2FUntitled.png?generation=1590981584876269&alt=media)","147b1306":"## Prepare Dataset","ec9926e0":"## YOLOv5 Detect","ff6e3ac0":"### Display Detected Images"}}