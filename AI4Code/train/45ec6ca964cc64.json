{"cell_type":{"7db4bc66":"code","078f401f":"code","d7170301":"code","d3844710":"code","be305a14":"code","48662488":"code","8ef751c6":"code","1b42e5df":"code","7e2eac1d":"code","12f45b64":"code","04027266":"code","b0f778e9":"code","831f77be":"code","9bcc8d36":"code","49a0797f":"code","0743c78a":"code","47a31c84":"code","89df3826":"code","72dc7aab":"code","29cf2f12":"code","59f30d03":"code","a63c93a6":"code","5be216b6":"code","2e01d4ae":"code","93719fa3":"code","3aa208b3":"code","1361ce0f":"code","c1a6cbd0":"code","8572fea5":"code","ae58f80a":"code","771b21e7":"code","12ab2c15":"code","eb455b5d":"code","16330366":"code","3646f8ca":"code","f946d5e0":"code","815ab890":"code","2a6025b5":"code","d547e0e5":"code","62883764":"code","0ce92d3d":"code","a84fa59f":"code","162682a9":"code","5798a5f9":"code","f88f6076":"code","386c400d":"code","f0958363":"code","314b8c60":"code","ac7884e6":"code","9e38a214":"code","247d0ae2":"code","f1dd0c74":"code","4e675788":"code","2815164e":"code","f5f50322":"code","3add5103":"code","6a1423ca":"code","8b609feb":"code","1e195a10":"code","a1e55ceb":"code","af0b37e4":"code","d75d5675":"code","50d3758e":"code","b9afd86c":"code","9233e879":"code","2493e183":"code","2a3220bd":"code","22453e48":"code","cf284bbd":"code","01e9760c":"code","c3b8c4a5":"code","51ab7c97":"code","0ce07bd8":"code","4b642c8d":"code","94fffd7a":"code","9a312e42":"code","ba59c50d":"code","2dd34aa5":"code","e44cc988":"code","60be272c":"code","143a945c":"code","57698103":"code","710e6fc9":"code","40b03336":"markdown","5c7e4d4b":"markdown","eb10182b":"markdown","95d07e6a":"markdown","20e3d09b":"markdown","881979f9":"markdown","2025eadf":"markdown","49d69f86":"markdown","f87b0f4c":"markdown","b482b4c5":"markdown","297b4f9f":"markdown","c3e63f1a":"markdown","384a3e3b":"markdown","99785d73":"markdown","73b483a3":"markdown","58c365c1":"markdown","2cf8120a":"markdown","db7587a5":"markdown","973517b2":"markdown","70afbfc0":"markdown","1eaf5be3":"markdown","a8443b43":"markdown","b95668c8":"markdown","bf5bf188":"markdown","7f998709":"markdown","90ab115e":"markdown","d12c768c":"markdown","31aba5df":"markdown","65441346":"markdown","ab460c7e":"markdown","b4fcd5d1":"markdown","68b0fdd2":"markdown","53e2560b":"markdown","8832ef56":"markdown","3543d944":"markdown","ea3b8fbf":"markdown","bc8fdf90":"markdown","35136f1c":"markdown","e607388c":"markdown","1ae0b762":"markdown","972f7148":"markdown","1910db3c":"markdown","8a58c7fe":"markdown","3adca955":"markdown","9344e64b":"markdown","f0ab865b":"markdown","a42e8297":"markdown","eab7afc8":"markdown","cc56d378":"markdown","5f55c2e4":"markdown","f5ee5563":"markdown","7622de5f":"markdown","1e04fa07":"markdown","8bc117fe":"markdown","5e5d0db5":"markdown","25aa5e62":"markdown","18e8ce73":"markdown","1e0755ac":"markdown","9c0b54b5":"markdown","251127cd":"markdown","2cdcecf5":"markdown","6a4cbde0":"markdown","ee0e34d6":"markdown","c89ef627":"markdown","878ba6d7":"markdown","4ef4edb1":"markdown","567cb54d":"markdown","65a1b87a":"markdown","d17529dd":"markdown","079f92e0":"markdown","ebfc94bf":"markdown","10594386":"markdown","c439ac80":"markdown","92c47c6c":"markdown","6999f9e2":"markdown"},"source":{"7db4bc66":"'''Ignorer l'obsolescence et les avertissements futurs.'''\ndef suppress_warnings():\n    import warnings\n    warnings.filterwarnings('ignore', category = DeprecationWarning) \n    warnings.filterwarnings('ignore', category = FutureWarning) \n\n'''Import des modules.'''\nimport numpy as np               # Pour l'alg\u00e8bre lin\u00e9aire\nimport pandas as pd              # Pour la maipulation des data\nimport matplotlib.pyplot as plt  # Visualisation 2D\nimport seaborn as sns            \nimport missingno as mn           # Pour voir les valeurs manquantes\nfrom scipy import stats          # Pour certaines stats\nfrom sklearn.model_selection import train_test_split\nimport category_encoders as ce\n\n\nfrom scipy.stats import norm, skew, kurtosis \n\nfrom IPython.core.display import HTML\n\n''' G\u00e9n\u00e9ratin de graphiques'''\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\n\nfrom IPython.display import display\n%matplotlib inline\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import preprocessing\n\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\npy.init_notebook_mode(connected=True)\n","078f401f":"'''Personnalisation de la visualisation'''\nplt.style.use('bmh')                    # Utilisation du style  bmh's pour les graphs\nsns.set_style({'axes.grid':False})      # Supprime les lignes\n\n'''On peut utiliser le gras , soulign\u00e9 etc avec markedown'''\nfrom IPython.display import Markdown\ndef bold(string):\n    display(Markdown(string))\n    \npd.options.display.max_rows = 150","d7170301":"'''Chargement du fichier csv\nCe reporter au notebook pr\u00e9c\u00e9dent concernant le type des variables\n\n'''\n\ncolumn_types = {\n    \"place\" : \"int64\",\n\"placeoptin\" : \"int64\",\n\"rapport\" : \"float32\",\n\"cr-reunion\" : \"int64\",\n\"cr-num\" : \"int64\",\n\"cr-nb_partants\" : \"int64\",\n\"cr-Hippodrome\" : \"object\",\n\"cr-Evt\" : \"int64\",\n\"cr-autostart\" : \"int64\",\n\"cr-corde\" : \"object\",\n\"cr-etat du terrain\" : \"object\",\n\"cr-distance\" : \"object\",\n\"Numcheval\" : \"int64\",\n\"CoteProbable\" : \"int64\",\n\"Sexe\" : \"object\",\n\"NbRencontre\" : \"float32\",\n\"NbBattus\" : \"float32\",\n\"SommeNbRencontre\" : \"float32\",\n\"SommeNbBattus\" : \"float32\",\n\"NumCourseJockey\" : \"float32\",\n\"QteCourseJockeyJour\" : \"float32\",\n\"SumCote5Race\" : \"float32\",\n\"MoyenneCote5Race\" : \"float32\",\n\"qteCoteCheval\" : \"float32\",\n\"ETCote5Race\" : \"float32\",\n\"SumPoids\" : \"int64\",\n\"SumIdJockey\" : \"float32\",\n\"SumidHippodrome\" : \"float32\",\n\"SumIdDeferre\" : \"float32\",\n\"SumDistance\" : \"float32\",\n\"SumAllocation\" : \"float32\",\n\"PositionIdJockey\" : \"float32\",\n\"PositionidHippodrome\" : \"float32\",\n\"PositionIdDeferre\" : \"float32\",\n\"PositionDistance\" : \"float32\",\n\"PositionAllocation\" : \"float32\",\n\"pourcentIdJockey\" : \"float32\",\n\"pourcentidHippodrome\" : \"float32\",\n\"pourcentIdDeferre\" : \"float32\",\n\"pourcentDistance\" : \"float32\",\n\"pourcentAllocation\" : \"float32\",\n\"SommeCourse\" : \"float32\",\n\"nbjourdercourse\" : \"float32\",\n\"numeroagespec\" : \"float32\",\n\"numerodistancespec\" : \"float32\",\n\"numerodeferrespec\" : \"float32\",\n\"numerosexespec\" : \"float32\",\n\"numeroagesexedistancespec\" : \"float32\",\n\"idjockeynumcoursenbrcoursespec\" : \"float32\",\n\"jockeyReussite\" : \"float32\",\n\"jockeyReussitePlusPlace\" : \"float32\",\n\"jockeyReussiteSpecialite\" : \"float32\",\n\"jockeynReussiteDistance\" : \"float32\",\n\"jockeyReussiteIdcheval\" : \"float32\",\n\"jockeyReussiteDeferre\" : \"float32\",\n\"jockeynReussiteSpecialiteDeferre\" : \"float32\",\n\"jockeyReussiteDistanceDeferre\" : \"float32\",\n\"entraineurReussite\" : \"float32\",\n\"entraineurReussitePlusPlace\" : \"float32\",\n\"entraineurReussiteSpecialite\" : \"float32\",\n\"entraineurnReussiteDistance\" : \"float32\",\n\"entraineurReussiteIdcheval\" : \"float32\",\n\"chevalReussite\" : \"float32\",\n\"chevalReussitePlusPlace\" : \"float32\",\n\"chevalReussiteSpecialite\" : \"float32\",\n\"chevalnReussiteDistance\" : \"float32\",\n\"coteprobable\" : \"float32\",\n\"gains\" : \"float32\"\n}\n\ncourses = pd.read_csv('..\/input\/export-1-pt-utf.csv',dtype=column_types,parse_dates=['cr-Date'],infer_datetime_format=True,sep=\",\")\n\n\n#courses= pd.read_csv('..\/input\/export-1-pt-utf.csv')\ncourses = courses.drop(columns=['placeoptin','rapport'])\n\n''' On divise notre jeu de donn\u00e9es en deux parties'''\ntrain, test = train_test_split(courses, test_size=0.33, random_state=42)\n\n\nbold('**Visualisation des Data d\\'entrainement:**')\ndisplay(train.head(2))\n\ntest = courses.drop(columns=['place'])\nbold('**Visualisation des Data de test:**')\ndisplay(test.head(2))","d3844710":"'''Configuration du DataFrame'''\nbold('**Configuration du DataFrame:**')\ndisplay(courses.shape)\n\n'''Nom de variables (nom des colonnes)'''\nbold('**Noms des variables:**')\ndisplay(courses.columns)","be305a14":"'''Type des donn\u00e9es de nos variables.'''\nbold('**Type des donn\u00e9es de nos variables:**')\n# On parcours les diff\u00e9rentes colonnes\nlisteInt=\"\"\nlisteFloat=\"\"\nlisteObj=\"\"\nfor col in courses.columns:\n    if courses[col].dtype in ['float32', 'float64']:\n        listeFloat+=col+','\n    if courses[col].dtype in [ 'int32','int64']:\n        listeInt +=col+\",\"\n    if courses[col].dtype in ['object']:\n        listeObj+=col+','\n\ndisplay(\"Type flottant : \"+listeFloat)\ndisplay(\"Type Int : \"+listeInt)\ndisplay(\"Type Objet : \"+listeObj)\ndisplay(\"Type Date : cr-Date\")","48662488":"'''Pour analyser les variables cat\u00e9gorielles, nous allons cr\u00e9er trois fonctions personnalis\u00e9es.\nLes deux premi\u00e8res fonctions affichent les \u00e9tiquettes des barres en \u00e9chelle absolue et relative respectivement.\nEt la 3\u00e8me cr\u00e9\u00e9e un dataframe de donn\u00e9es absolues et relatives et g\u00e9n\u00e8re \u00e9galement des courbes de fr\u00e9quence abs et relative pour chaque variable.'''\n\n''' #1.Fonction d'affichage de barres en \u00e9chelle absolue.'''\ndef abs_bar_labels():\n    font_size = 15\n    plt.ylabel('Fr\u00e9quence absolue', fontsize = font_size)\n    plt.xticks(rotation = 0, fontsize = font_size)\n    plt.yticks([])\n    \n    # Set individual bar lebels in absolute number\n    for x in ax.patches:\n        ax.annotate(x.get_height(), \n        (x.get_x() + x.get_width()\/2., x.get_height()), ha = 'center', va = 'center', xytext = (0, 7), \n        textcoords = 'offset points', fontsize = font_size, color = 'black')\n    \n'''#2.Fonction d'affichage de barres \u00e0 l'\u00e9chelle relative.'''\ndef pct_bar_labels():\n    font_size = 15\n    plt.ylabel('Fr\u00e9quence relative (%)', fontsize = font_size)\n    plt.xticks(rotation = 0, fontsize = font_size)\n    plt.yticks([]) \n    \n    # Etiquette personnalis\u00e9e\n    for x in ax1.patches:\n        ax1.annotate(str(x.get_height()) + '%', \n        (x.get_x() + x.get_width()\/2., x.get_height()), ha = 'center', va = 'center', xytext = (0, 7), \n        textcoords = 'offset points', fontsize = font_size, color = 'black')\n         \n'''#3.Fonction pour cr\u00e9er un DataFrame avec les valeurs absolue et relative. Affiche le graph correspondant.'''\ndef freq_absolue_et_relative(variable, horizontal=False):\n    global  ax, ax1 \n    # Cr\u00e9ation du DataFrame\n    absolute_frequency = variable.value_counts()\n    relative_frequency = round(variable.value_counts(normalize = True)*100, 2)\n    # On multiplie par 100 et on arronde \u00e0 2 d\u00e9cimales\n    df = pd.DataFrame({'Fr\u00e9quence absolue':absolute_frequency, 'Fr\u00e9quence relative(%)':relative_frequency})\n    print('Fr\u00e9quence absolue et relative de ',variable.name,':')\n    display(df)\n    \n    # G\u00e9n\u00e9ration du graph.\n    fig_size = (18,5)\n    font_size = 15\n    title_size = 18\n    if horizontal:\n        ax =  absolute_frequency.plot.barh(title = 'Fr\u00e9quence absolue de %s' %variable.name, figsize = fig_size)\n    else:\n        ax =  absolute_frequency.plot.bar(title = 'Fr\u00e9quence absolue de %s' %variable.name, figsize = fig_size)\n    ax.title.set_size(title_size)\n    abs_bar_labels()  # Displays bar labels in abs scale.\n    plt.show()\n    \n    if horizontal:\n        ax1 = relative_frequency.plot.barh(title = 'Fr\u00e9quence relative de %s' %variable.name, figsize = fig_size)\n    else:\n        ax1 = relative_frequency.plot.bar(title = 'Fr\u00e9quence relative de %s' %variable.name, figsize = fig_size)\n\n    ax1.title.set_size(title_size)\n    pct_bar_labels() # Affiche les \u00e9tiquettes.\n    plt.show()","8ef751c6":"'''Tracez et comptez le nombre de gagnants \u00e0 l'\u00e9chelle absolue et relative.'''\nfreq_absolue_et_relative(courses[\"place\"])","1b42e5df":"'''Tracez et comptez le nombre de plac\u00e9 \u00e0 l'\u00e9chelle absolue et relative.'''\nfreq_absolue_et_relative(courses[\"Sexe\"])","7e2eac1d":"'''Tracez et comptez \u00e0 l'\u00e9chelle absolue et relative la variable cr-corde.'''\nfreq_absolue_et_relative(courses[\"cr-corde\"])","12f45b64":"'''Tracez et comptez \u00e0 l'\u00e9chelle absolue et relative la variable cr-autostart.'''\n  \nfreq_absolue_et_relative(courses[\"cr-autostart\"])","04027266":"'''Tracez et comptez \u00e0 l'\u00e9chelle absolue et relative la variable cr-Evt.'''\n  \nfreq_absolue_et_relative(courses[\"cr-Evt\"])","b0f778e9":"'''Tracez et comptez \u00e0 l'\u00e9chelle absolue et relative la variable cr-etat du terrain.'''\n  \nfreq_absolue_et_relative(courses[\"cr-etat du terrain\"])","831f77be":"'''Tracez et comptez \u00e0 l'\u00e9chelle absolue et relative la variable cr-reunion.'''\n  \nfreq_absolue_et_relative(courses[\"cr-reunion\"])","9bcc8d36":"'''Tracez et comptez \u00e0 l'\u00e9chelle absolue et relative la variable cr-num.'''\n  \nfreq_absolue_et_relative(courses[\"cr-num\"])","49a0797f":"'''Tracez et comptez \u00e0 l'\u00e9chelle absolue et relative la variable cr-Hippodrome.'''\n  \nfreq_absolue_et_relative(courses[\"cr-Hippodrome\"])","0743c78a":"# On va cr\u00e9er unDatafRame pour stocker les valeurs de chaque hippodrome\nar=courses['cr-Hippodrome'].value_counts(dropna=False)\ndfhip = pd.DataFrame(ar)\n'''On calcul la moyenne des hippodromes'''\nprint(\"Moyenne : \"+str(round(dfhip['cr-Hippodrome'].mean(),2)) +\" Mediane : \"+str(dfhip['cr-Hippodrome'].median()))","47a31c84":"# Fonction de convertion\ndef convert_hip(val):\n    if dfhip.loc[val][0]>127:\n        return val\n    else:\n        return \"Autre\"\n\ncourses['cr-HippodromeCat']=courses['cr-Hippodrome'].apply(convert_hip)\n\n'''Nombre d'hippodromes diff\u00e9rents '''\nprint(\"Nombre d'hippodromes diff\u00e9rents : \"+str(courses['cr-Hippodrome'].value_counts(dropna=False).count()))\n\n'''Tracez et comptez \u00e0 l'\u00e9chelle absolue et relative la variable cr-HippodromeCat.'''\n  \nfreq_absolue_et_relative(courses[\"cr-HippodromeCat\"])","89df3826":"'''Tracez et comptez \u00e0 l'\u00e9chelle absolue et relative la variable cr-distance.'''\n  \nfreq_absolue_et_relative(courses[\"cr-distance\"])","72dc7aab":"def convert_distance(val):\n    val=val.replace('m\u00e8tres','')\n    val=val.replace('.','')\n    val=val.strip()\n    return val\n\n\ncourses['cr-distanceNum']=courses['cr-distance'].apply(convert_distance)  \ncourses['cr-distanceNum']=pd.to_numeric(courses['cr-distanceNum'], downcast='integer')","29cf2f12":"courses['cr-corde'] = pd.Categorical(courses['cr-corde'])\ncourses['cr-etat du terrain'] = pd.Categorical(courses['cr-etat du terrain'])\ncourses['Sexe'] = pd.Categorical(courses['Sexe'])\ncourses['cr-reunion'] = pd.Categorical(courses['cr-reunion'])\ncourses['cr-num'] = pd.Categorical(courses['cr-num'])\ncourses[\"cr-Evt\"] = pd.Categorical(courses[\"cr-Evt\"])\ncourses[\"cr-autostart\"] = pd.Categorical(courses[\"cr-autostart\"])\ncourses['cr-HippodromeCat'] = pd.Categorical(courses['cr-HippodromeCat'])\ncourses['place'] = pd.Categorical(courses['place'])","59f30d03":"courses.describe().transpose()","a63c93a6":"courses=courses.drop(\"SumPoids\", axis=1)","5be216b6":"def graph_unitaire(df,nom_colonne,proba):\n    f, (ax1, ax2) = plt.subplots(1,2,figsize=(20,8))\n    sns.kdeplot(df[nom_colonne],ax = ax1,color ='blue',shade=True,\n                label=(\"Skewness : %.2f\"%(df[nom_colonne].skew()),\n                       \"Kurtosis: %.2f\"%(df[nom_colonne].kurtosis())))\n    ax1.set_xlabel(nom_colonne,color='black',fontsize=12)\n    ax1.set_title(nom_colonne + ' Kdeplot',fontsize=14)\n    ax1.axvline(df[nom_colonne].mean() , color ='g',linestyle = '--')\n    ax1.legend(loc ='upper right',fontsize=12,ncol=2)\n    \n    sns.distplot(df[nom_colonne] , fit=norm,ax = ax2);\n    ax2.set_xlabel(nom_colonne,color='black',fontsize=12)\n    ax2.set_title(nom_colonne + ' distribution',fontsize=14)\n    ax2.axvline(df[nom_colonne].mean() , color ='g',linestyle = '--')  \n    (mu, sigma) = norm.fit(df[nom_colonne])\n    ax2.legend(['Normal dist. ($\\mu=$ {:.2f} et $\\sigma=$ {:.2f} )'.format(mu, sigma)],loc ='upper right',fontsize=12,ncol=2)\n    \n    sns.despine()\n    plt.show()\n    \n    if proba==True:\n        graph_duo(df,nom_colonne)\n        \n    return(df[nom_colonne].skew(),df[nom_colonne].kurtosis())\n\ndef graph_duo(df,nom_colonne):\n    \n    #Get also the QQ-plot\n    fig = plt.figure()\n    res = stats.probplot(courses[nom_colonne], plot=plt)\n    plt.show()\n\n\n            \n       ","2e01d4ae":"''' On parcours les diff\u00e9rentes colonnes '''\nfor col in courses.columns:\n    ''' Uniquement les colonnes num\u00e9riques '''\n    if courses[col].dtype in ['float32', 'int32','int64', 'float64']:            \n            display(HTML('<strong>Analyse de la variable '+col+'<\/strong>'))\n            (skew1,kurto1)=graph_unitaire(courses,col, True)\n            ","93719fa3":"columns = ['nom' ,'avant','apres']\nma_liste = []\n\n''' On parcours les diff\u00e9rentes colonnes '''\nfor col in courses.columns:\n    ''' Uniquement les colonnes num\u00e9riques '''\n    if courses[col].dtype in ['float32', 'int32','int64', 'float64']:    \n        ''' Si Skewness > Skewness alors on transforme la colonne en LOG '''\n        if abs(courses[col].skew())>=0.75:              \n            #courses[\"LOG\"+col] = np.log1p(courses[col])\n            my_dict = {'nom':col,'avant':courses[col].skew(),'apres':np.log1p(courses[col]).skew()}\n            ma_liste.append(dict(my_dict))\n            ''' On supprime la colonne initiale pour ne conserver que celle transformer '''\n            #courses=courses.drop(col, axis=1)\n                \ncompare = pd.DataFrame(ma_liste, columns=columns)\nprint(compare)","3aa208b3":"for col in ['qteCoteCheval', 'numeroagespec','jockeyReussiteDeferre']:\n    courses[\"LOG\"+col] = np.log1p(courses[col])\n    ''' On supprime la colonne initiale pour ne conserver que celle transformer '''\n    courses=courses.drop(col, axis=1)","1361ce0f":"courses['CoteProbable'].value_counts()","c1a6cbd0":"''' Fonction de convertion '''\ndef Vers_Nan(val):\n    if val>0:\n        return val\n    else:\n        return np.NaN\n\ncourses['CoteProbable']=courses['CoteProbable'].apply(Vers_Nan)\ncourses['CoteProbable'].value_counts()","8572fea5":"import missingno as mn\n\nmn.matrix(courses)","ae58f80a":"courses['jour_semaine']=courses['cr-Date'].dt.dayofweek\n\ncourses['jour_semaine'].describe()","771b21e7":"courses['mois_annee']=courses['cr-Date'].dt.month\ncourses['mois_annee'].describe()\n","12ab2c15":"courses['semaine_annee']=courses['cr-Date'].dt.weekofyear\ncourses['semaine_annee'].describe()","eb455b5d":"courses['jour_mois']=courses['cr-Date'].dt.day\ncourses['jour_mois'].describe()\n","16330366":"for col in ['jour_semaine','jour_mois','semaine_annee','mois_annee']:\n    ''' Uniquement les nouvelles colonnes  '''              \n    display(HTML('<strong>Analyse de la variable '+col+'<\/strong>'))\n    (skew1,kurto1)=graph_unitaire(courses,col, True)","3646f8ca":"def plotBarCat(df,feature,target):\n    \n    x0 = df[df[target]==0][feature]\n    x1 = df[df[target]==1][feature]\n    \n\n    trace1 = go.Histogram(\n        x=x0,\n        opacity=0.95,\n          name = \"Perdu\",\n        marker=dict(color='#FF7F0E')\n    )\n    trace2 = go.Histogram(\n        x=x1,\n        opacity=0.35,  \n        name = \"Gagn\u00e9\",\n        marker=dict(color='#35FF23')\n    )\n\n    data = [trace1,trace2]\n    layout = go.Layout(barmode='overlay',\n                      title=feature,\n                       yaxis=dict(title='Count'\n        ))\n    fig = go.Figure(data=data, layout=layout)\n\n    py.iplot(fig, filename='overlaid histogram')\n    \n","f946d5e0":"plotBarCat(courses,\"jour_semaine\",'place')","815ab890":"plotBarCat(courses,\"mois_annee\",'place')","2a6025b5":"plotBarCat(courses,\"jour_mois\",'place')","d547e0e5":"plotBarCat(courses,\"semaine_annee\",'place')","62883764":"'''Cr\u00e9ez une fonction pour compter le total des valeurs aberrantes. Et tracer des variables avec et sans valeurs aberrantes.'''\ndef outliers(variable):\n    global filtered\n    # calculer 1\u00b0, 3\u00b0 quartiles .\n    q1, q3 = variable.quantile(0.25), variable.quantile(0.75)\n    iqr = q3 - q1\n    \n    # Calculer le seuil inf\u00e9rieur et le seuil sup\u00e9rieur pour les valeurs aberrantes\n    l_fence, u_fence = q1 - 1.5*iqr , q3 + 1.5*iqr   # Toute valeur inf\u00e9rieure \u00e0 l_fence et sup\u00e9rieure \u00e0 u_fence est une valeur aberrante.\n    \n    # Observations that are outliers\n    outliers = variable[(variable<l_fence) | (variable>u_fence)]\n    print('Total des valeurs abarrantes', variable.name,':', outliers.count())\n    \n    # Supprime les valeurs aberrantes\n    filtered = variable.drop(outliers.index, axis = 0)\n\n    # Create subplots\n    out_variables = [variable, filtered]\n    out_titles = [' Distribution avec VA', ' Distribution sans VA']\n    title_size = 25\n    font_size = 18\n    plt.figure(figsize = (25, 15))\n    for ax, outlier, title in zip(range(1,3), out_variables, out_titles):\n        plt.subplot(2, 1, ax)\n        sns.boxplot(outlier).set_title('%s' %outlier.name + title, fontsize = title_size)\n        plt.xticks(fontsize = font_size)\n        plt.xlabel('%s' %outlier.name, fontsize = font_size)","0ce92d3d":"outliers(courses['CoteProbable'])","a84fa59f":"''' calculer 1\u00b0, 3\u00b0 quartiles '''\nq1, q3 = courses[\"CoteProbable\"].quantile(0.25), courses[\"CoteProbable\"].quantile(0.75)\niqr = q3 - q1\n    \n''' Calculer le seuil inf\u00e9rieur et le seuil sup\u00e9rieur pour les valeurs aberrantes '''\nl_fence, u_fence = q1 - 1.5*iqr , q3 + 1.5*iqr   # Toute valeur inf\u00e9rieure \u00e0 l_fence et sup\u00e9rieure \u00e0 u_fence est une valeur aberrante.\n    \n''' Observations that are outliers '''\noutliers = courses[\"CoteProbable\"][(courses[\"CoteProbable\"]<l_fence) | (courses[\"CoteProbable\"]>u_fence)]\n#print(outliers)\n\n''' Supprime les valeurs aberrantes '''\nfiltered = courses[\"CoteProbable\"].drop(outliers.index, axis = 0)\nmoyenne=filtered.mean()\nprint(\"Moyenne : \"+str(moyenne))\n\n\n\n''' Fonction de convertion '''\ndef Vers_moyenne(val,l_fence2,u_fence2,moy):\n    ''' On remplace les valeurs ab\u00e9rrantes par la moyenne'''\n    if (val<l_fence2) | (val>u_fence2):\n        return moy\n    else:\n        return val\n    \nprint(\"Stats avant la modif\")    \nprint(courses['CoteProbable'].describe().transpose())\ncourses['CoteProbable']=courses['CoteProbable'].apply(Vers_moyenne,l_fence2=l_fence, u_fence2=u_fence, moy=moyenne)\n\nprint(\"Stats apr\u00e8s la modif\") \nprint(courses['CoteProbable'].describe().transpose())","162682a9":"\"\"\"Pour chaque variable comptons les valeurs manquantes\"\"\"\nbold('**Valeurs manquantes pour chaque variables:**')\ndisplay(courses.isnull().sum())","5798a5f9":"\"\"\"Cr\u00e9ez un boxplot pour visualiser les variables corr\u00e9l\u00e9es avec l'cote probable. Extrayez d'abord les variables qui nous int\u00e9ressent.\"\"\"\n\ndef correlationCote(df,liste):\n    \n    if len(liste) % 2 == 0:\n        nbrow = int(len(liste)\/2)\n    else:\n        nbrow = int(len(liste)\/2)+1\n    \n    correlation = df.loc[:, liste]\n    fig, axes = plt.subplots(nrows = nbrow, ncols = 2, figsize = (50,150))\n    for ax, column in zip(axes.flatten(), correlation.columns):\n        sns.boxplot(x = correlation[column], y =  df['CoteProbable'], ax = ax)\n        ax.set_title(column, fontsize = 23)\n        ax.tick_params(axis = 'both', which = 'major', labelsize = 20)\n        ax.tick_params(axis = 'both', which = 'minor', labelsize = 20)\n        ax.set_ylabel('Cote Probable', fontsize = 20)\n        ax.set_xlabel('')\n    fig.suptitle('Variables associ\u00e9es', fontsize = 30)\n    fig.tight_layout(rect = [0, 0.03, 1, 0.95])\n    return correlation\n\n","f88f6076":"#correlation= correlationCote(courses,[\"cr-reunion\",\"cr-num\",\"cr-nb_partants\",\"cr-HippodromeCat\",\"cr-Evt\",\"cr-autostart\",\"cr-corde\",\"jour_mois\",\"jour_semaine\",\"Numcheval\"])","386c400d":"\"\"\" Tra\u00e7ons une carte de corr\u00e9lation pour voir quelle variable est fortement corr\u00e9l\u00e9e avec la coteprobable. \nNous devons convertir la variable cat\u00e9gorielle en une carte thermique de corr\u00e9lation num\u00e9rique pour tracer la corr\u00e9lation.\nConvertissez donc les variables cat\u00e9gorielles en variables num\u00e9riques.\"\"\"\nfrom sklearn.preprocessing import LabelEncoder\n\ndef graph_co(correlation, df, col):\n    correlation = correlation.agg(LabelEncoder().fit_transform)\n    correlation[col] = df[col] # Inserting CoteProbable in variable correlation.\n    correlation = correlation.set_index(col).reset_index() # Move CoteProbable at index 0.\n\n    '''Cr\u00e9ation du graphique'''\n    plt.figure(figsize = (60,60))\n    sns.set(font_scale=1.4)\n    sns.heatmap(correlation.corr(), cmap ='BrBG', annot = True,linewidths=.5)\n    plt.title('Variables correl\u00e9es avec la cote probable', fontsize = 18)\n    plt.show()","f0958363":"#graph_co(correlation, courses, 'CoteProbable')","314b8c60":"liste = []\nfor col in courses.columns:\n    if col.startswith('ARRONDI'):\n        courses = courses.drop(columns=[col])\n        \n# On va arrondir apr\u00e8s une d\u00e9cimale\nfor col in courses.columns:\n    if courses[col].dtype in ['float32', 'float64']:\n        #courses = courses.drop(columns=[col])\n        if col not in ['CoteProbable','qteCoteCheval','numeroagespec','jockeyReussiteDeferre','coteprobable']:\n            courses[\"ARRONDI\"+col]=courses[col].apply(lambda x:round(x,1))\n            liste.append(\"ARRONDI\"+col)\n\n    \n#correlation=correlationCote(courses,liste)","ac7884e6":"#graph_co(correlation, courses, 'CoteProbable')","9e38a214":"''' On va cr\u00e9er un nouveau df avec niquement les colonnes de liste'''\ndf = courses.loc[:, liste]\ndf['CoteProbable'] = courses['CoteProbable'] \n\n''' on cr\u00e9\u00e9 un df de corr\u00e9lation'''\ndfcor=df.corr().transpose()\n\n\nlistecor = []\n\n''' On parcours'''\nfor x in liste:   \n    ''' Notre liste avec uniquement des corr\u00e9lations sup\u00e9rieures \u00e0 0.15'''\n    if abs(dfcor.loc[x, \"CoteProbable\"])>0.15:\n        listecor.append(x)\n\nlistecor.append('cr-nb_partants')\n\nprint(listecor)\n            ","247d0ae2":"''' On impute la cote probable avec la m\u00e9diane des colonnes'''\ncourses['CoteProbable']=courses['CoteProbable'].fillna(courses.groupby(listecor)['CoteProbable'].transform('median'))\n\n''' On regarde si cela a bien fonctionn\u00e9 en comptant le nombre de Nan'''\ncourses['CoteProbable'].isnull().sum()\n#def blurp:\n#df1=courses.groupby('cr-nb_partants')['CoteProbable'].transform()\n\n#courses[\"CoteProbable\"] = courses.groupby('cr-nb_partants')['CoteProbable'].transform(lambda x: x.fillna(x.median()))\n\n\n#bold('**Valeurs manquantes apr\u00e8s imputation:**')\n#display(courses.isnull().sum())\n\n","f1dd0c74":"def combinliste(seq, k):\n    p = []\n    i, imax = 0, 2**len(seq)-1\n    while i<=imax:\n        s = []\n        j, jmax = 0, len(seq)-1\n        while j<=jmax:\n            if (i>>j)&1==1:\n                s.append(seq[j])\n            j += 1\n        if len(s)==k:\n            courses['CoteProbable']=courses['CoteProbable'].fillna(courses.groupby(s)['CoteProbable'].transform('median'))\n            #scomb = \" \".join(s)\n            print(s)\n            print(\"  Reste Nan : \"+str(courses['CoteProbable'].isnull().sum()))\n            if courses['CoteProbable'].isnull().sum()==0:\n                return True\n        i += 1 \n    return False","4e675788":"res=combinliste(listecor,11)","2815164e":"res=combinliste(listecor,10)\nres=combinliste(listecor,9)\nres=combinliste(listecor,8)\nres=combinliste(listecor,7)\nres=combinliste(listecor,6)","f5f50322":"print(courses['CoteProbable'].describe().transpose())","3add5103":"\"\"\"\nS\u00e9parons en deux notre jeu de donn\u00e9es pour l'entrainement et le test.\nNous avons besoin de notre variable cible sans valeurs manquantes pour effectuer le test d'association avec les variables pr\u00e9dicteurs.\n\"\"\"\ndf_train = courses.iloc[:9000, :]\ndf_test = courses.iloc[9000:, :]\ndf_test = df_test.drop(columns = ['place'], axis = 1)\n\n'''#1.Cr\u00e9er une fonction qui cr\u00e9e un boxplot entre les variables cat\u00e9gorielles et num\u00e9riques et calcule la corr\u00e9lation bis\u00e9riale.'''\ndef boxplot_and_correlation(cat,num):\n    '''cat =  variable categorielle, and num = variable num\u00e9rique.'''\n    plt.figure(figsize = (18,7))\n    title_size = 18\n    font_size = 15\n    ax = sns.boxplot(x = cat, y = num)\n    \n    # Changement de couleur\n    box = ax.artists[0]\n    box1 = ax.artists[1]\n    \n    # Change l'apparence\n    box.set_facecolor('red')\n    box1.set_facecolor('green')\n    plt.title('Association entre Place & %s' %num.name, fontsize = title_size)\n    plt.xlabel('%s' %cat.name, fontsize = font_size)\n    plt.ylabel('%s' %num.name, fontsize = font_size)\n    plt.xticks(fontsize = font_size)\n    plt.yticks(fontsize = font_size)\n    plt.show()\n    print('Corr\u00e9lation entre', num.name, ' et ', cat.name,':', stats.pointbiserialr(num, cat))\n\n'''#2.Cr\u00e9er une autre fonction pour calculer la moyenne lorsqu'elle est group\u00e9e par variable cat\u00e9gorielle. Et aussi tracer la moyenne group\u00e9e.'''\ndef nume_grouped_by_cat(num, cat):\n    global ax\n    font_size = 15\n    title_size = 18\n    grouped_by_cat = num.groupby(cat).mean().sort_values( ascending = False)\n    grouped_by_cat.rename ({1:'Plac\u00e9', 0:'Perdu'}, axis = 'rows', inplace = True) # Renaming index\n    grouped_by_cat = round(grouped_by_cat, 2)\n    ax = grouped_by_cat.plot.bar(figsize = (18,5)) \n    abs_bar_labels()\n    plt.title('Moyenne %s ' %num.name + ' de Plac\u00e9s vs perdus', fontsize = title_size)\n    plt.ylabel('Moyenne ' + '%s' %num.name, fontsize = font_size)\n    plt.xlabel('%s' %cat.name, fontsize = font_size)\n    plt.xticks(fontsize = font_size)\n    plt.yticks(fontsize = font_size)\n    plt.show()\n\n'''#3.Cette fonction trace l'histogramme de la variable num\u00e9rique pour chaque classe de variable cat\u00e9gorielle..'''\ndef num_hist_by_cat(num,cat):\n    font_size = 15\n    title_size = 18\n    plt.figure(figsize = (18,7))\n    num[cat == 1].hist(color = ['g'], label = 'Plac\u00e9', grid = False)\n    num[cat == 0].hist(color = ['r'], label = 'Perdu', grid = False)\n    plt.yticks([])\n    plt.xticks(fontsize = font_size)\n    plt.xlabel('%s' %num.name, fontsize = font_size)\n    plt.title('%s ' %num.name + ' Distribution des Plac\u00e9s vs Perdus', fontsize = title_size)\n    plt.legend()\n    plt.show()\n   \n'''#4.Cr\u00e9er une fonction pour calculer l'anova entre variable num\u00e9rique et variable cat\u00e9gorielle'''\ndef anova(num, cat):\n    from scipy import stats\n    grp_num_by_cat_1 = num[cat == 1] # Groupe notre variable num\u00e9rique par variable cat\u00e9gorielle.\n    grp_num_by_cat_0 = num[cat == 0] # Groupe notre variable num\u00e9rique par variable cat\u00e9gorielle\n    f_val, p_val = stats.f_oneway(grp_num_by_cat_1, grp_num_by_cat_0) # Calculate f statistics and p value\n    print('R\u00e9sultat Anova entre ' + num.name, ' & '+ cat.name, ':' , f_val, p_val)  \n    \n'''#5.Cr\u00e9er une autre fonction qui calcule le test de Tukey entre notre variable num\u00e9rique et cat\u00e9gorielle.'''\ndef tukey_test(num, cat):\n    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n    tukey = pairwise_tukeyhsd(endog = num,   # Data num\u00e9rique\n                             groups = cat,   # Data cat\u00e9gorielle\n                             alpha = 0.05)   # Niveau significatif\n    \n    summary = tukey.summary()   # See test summary\n    print(\"R\u00e9sultat test Tukey entre \" + num.name, ' & '+ cat.name, ':' )  \n    display(summary)        ","6a1423ca":"df_train[\"place\"]=df_train[\"place\"].astype(\"int32\")\ndf_train[\"cr-num\"]=df_train[\"cr-num\"].astype(\"int32\")\n\n#'''Cr\u00e9ez un boxplot pour visualiser la force d'association de Plac\u00e9 avec cr-num. Calcule \u00e9galement la corr\u00e9lation bis\u00e9riale.'''\nboxplot_and_correlation(df_train[\"place\"], df_train[\"cr-num\"])","8b609feb":"#'''Cr\u00e9ez un boxplot pour visualiser la force d'association de Plac\u00e9 avec jour_mois. Calcule \u00e9galement la corr\u00e9lation bis\u00e9riale.'''\nboxplot_and_correlation(df_train[\"place\"], df_train[\"jour_mois\"])","1e195a10":"#'''Cr\u00e9ez un boxplot pour visualiser la force d'association de Plac\u00e9 avec jour_mois. Calcule \u00e9galement la corr\u00e9lation bis\u00e9riale.'''\nboxplot_and_correlation(df_train[\"place\"], df_train[\"cr-distanceNum\"])\n","a1e55ceb":"'''#1. Cr\u00e9er une fonction qui calcule la fr\u00e9quence absolue et relative de la variable Plac\u00e9 par une variable cat\u00e9gorielle. Et trace ensuite la fr\u00e9quence absolue et relative de Plac\u00e9 par une variable cat\u00e9gorielle.\"\n'''\ndef crosstab(cat, cat_target):\n    '''cat = categorical variable, cat_target = our target categorical variable.'''\n    global ax, ax1\n    fig_size = (18, 5)\n    title_size = 18\n    font_size = 15\n    cat_grouped_by_cat_target = pd.crosstab(index = cat, columns = cat_target)\n    cat_grouped_by_cat_target.rename({0:'Perdu', 1:'Plac\u00e9'}, axis = 'columns', inplace = True)  # Renomme les colonnes\n    pct_cat_grouped_by_cat_target = round(pd.crosstab(index = cat, columns = cat_target, normalize = 'index')*100, 2)\n    pct_cat_grouped_by_cat_target.rename({0:'Perdu(%)', 1:'Plac\u00e9(%)'}, axis = 'columns', inplace = True)\n    \n    # Plot absolute frequency of Survived by a categorical variable\n    ax =  cat_grouped_by_cat_target.plot.bar(color = ['r', 'g'], title = 'Nombre absolu de Plac\u00e9 et de perdu par %s' %cat.name, figsize = fig_size)\n    ax.title.set_size(fontsize = title_size)\n    abs_bar_labels()\n    plt.xlabel(cat.name, fontsize = font_size)\n    plt.show()\n    \n    # Plot relative frequrncy of Survived by a categorical variable\n    ax1 = pct_cat_grouped_by_cat_target.plot.bar(color = ['r', 'g'], title = 'Pourcentage de Plac\u00e9 et de perdu par %s' %cat.name, figsize = fig_size)\n    ax1.title.set_size(fontsize = title_size)\n    pct_bar_labels()\n    plt.xlabel(cat.name, fontsize = font_size)\n    plt.show()\n    \n'''#2.Cr\u00e9ez une fonction pour calculer le chi_square  entre une variable cat\u00e9gorielle et une variable cat\u00e9gorielle cible.'''\ndef chi_square(cat, cat_target):\n    cat_grouped_by_cat_target = pd.crosstab(index = cat, columns = cat_target)\n    test_result = stats.chi2_contingency (cat_grouped_by_cat_target)\n    print('R\u00e9sultat du test Chi Square entre plac\u00e9 & %s' %cat.name + ':')\n    display(test_result)\n\n'''#3.Calcul de Bonferroni-adjust\u00e9'''\ndef bonferroni_adjusted(cat, cat_target):\n    dummies = pd.get_dummies(cat)\n    for columns in dummies:\n        crosstab = pd.crosstab(dummies[columns], cat_target)\n        print(stats.chi2_contingency(crosstab))\n    print('\\nColonnes:', dummies.columns)","af0b37e4":"crosstab(df_train[\"Sexe\"], df_train[\"place\"])","d75d5675":"chi_square(df_train[\"Sexe\"], df_train[\"place\"])","50d3758e":"'''Calcule pour sexe (H,F,M) Plac\u00e9.'''\nbonferroni_adjusted(df_train[\"Sexe\"], df_train[\"place\"])","b9afd86c":"crosstab(df_train[\"cr-corde\"], df_train[\"place\"])","9233e879":"chi_square(df_train[\"cr-corde\"], df_train[\"place\"])","2493e183":"crosstab(df_train[\"cr-autostart\"], df_train[\"place\"])\nchi_square(df_train[\"cr-autostart\"], df_train[\"place\"])","2a3220bd":"crosstab(df_train[\"cr-Evt\"], df_train[\"place\"])\nchi_square(df_train[\"cr-Evt\"], df_train[\"place\"])","22453e48":"crosstab(df_train[\"cr-etat du terrain\"], df_train[\"place\"])\nchi_square(df_train[\"cr-etat du terrain\"], df_train[\"place\"])","cf284bbd":"crosstab(df_train[\"cr-HippodromeCat\"], df_train[\"place\"])\nchi_square(df_train[\"cr-HippodromeCat\"], df_train[\"place\"])","01e9760c":"'''Calcule pour HippodromeCat Plac\u00e9.'''\nbonferroni_adjusted(df_train[\"cr-HippodromeCat\"], df_train[\"place\"])","c3b8c4a5":"'''Cr\u00e9ez une fonction qui trace l'impact de 3 variables pr\u00e9dicteurs \u00e0 la fois sur une variable cible.'''\ndef multivariate_analysis(cat1, cat2, cat3, cat_target,Type=1):\n    if type==1:\n        font_size = 15\n    else:\n        font_size = 45\n    grouped = round(pd.crosstab(index = [cat1, cat2, cat3], columns = cat_target, normalize = 'index')*100, 2)\n    grouped.rename({0:'Perdu%', 1:'Plac\u00e9%'}, axis = 1, inplace = True)\n    \n    if type==1:\n        grouped.plot.barh(color = ['r', 'g'], figsize = (18,5))\n    else:\n        grouped.plot.barh(color = ['r', 'g'], figsize = (100,500))\n    \n    \n    plt.xlabel(cat1.name + ',' + cat2.name + ',' + cat3.name, fontsize = font_size)\n    plt.ylabel('Fr\u00e9quence relative (%)', fontsize = font_size)\n    plt.xticks(fontsize = font_size)\n    plt.yticks(fontsize = font_size)\n    plt.legend(loc = 'best')\n    plt.show()\n\n","51ab7c97":"multivariate_analysis(df_train[\"cr-corde\"], df_train[\"cr-autostart\"], df_train[\"cr-Evt\"], df_train[\"place\"])","0ce07bd8":"multivariate_analysis(df_train[\"cr-corde\"], df_train[\"Sexe\"], df_train[\"Numcheval\"], df_train[\"place\"],2)","4b642c8d":"multivariate_analysis(df_train[\"cr-etat du terrain\"], df_train[\"cr-num\"], df_train[\"Sexe\"], df_train[\"place\"],2)","94fffd7a":"courses.shape","9a312e42":"courses.dtypes","ba59c50d":"courses.drop([\"cr-Hippodrome\", \"cr-distance\",\"cr-Date\"], axis=1, inplace=True)\n\nfor col in courses.columns:\n    if col.startswith('ARRONDI'):\n        courses.drop(columns=[col], axis=1, inplace=True)","2dd34aa5":"courses.shape\n","e44cc988":"courses.select_dtypes(include=['category'])","60be272c":"''\nlisteCat=courses.select_dtypes(include=['category']).columns.tolist() \nlisteCat","143a945c":"''' On supprime le libell\u00e9 place'''\nlisteCat.pop(0)\n\n''' On force en type object les category'''\n\nfor col in listeCat:\n    courses[col]=courses[col].astype(\"object\")","57698103":"''' Cr\u00e9ation d'un nouveau dataframe dans lequel les colonnes de listeCat ont \u00e9t\u00e9 supprim\u00e9es '''\ncoursesBinary = courses.drop(listeCat, axis = 1)\n\n'''Cr\u00e9ation de l'encodeur binaire '''\nce_binary = ce.BinaryEncoder(cols = listeCat)\n\n''' Transformation des datas'''\nce_binary.fit_transform(courses, coursesBinary)","710e6fc9":"coursesBinary.head()","40b03336":"### Que peut-on voir??\n**Nous avons 67 variables. et chaque variable poss\u00e8de 19867 enregistrements.**\n### Voici une description des variables:\n\nVoici une petite base de donn\u00e9es sur les courses hippiques.\n\nCela concerne le trot mont\u00e9.\n\nL'ensemble des colonnes apr\u00e8s sexe ont \u00e9t\u00e9 normalis\u00e9es en fonction des autres chevaux de la course.\nOn se retrouve ainsi avec des valeurs comprises entre 0 et 1.\n\nCi dessous vous trouverez le d\u00e9tail des diff\u00e9rents champs utilis\u00e9s.\n\n**Place**\n1 si le cheval est dans les trois premiers sinon 0\n\n**cr-reunion**\nN\u00b0 de la r\u00e9union\n\n**cr-num**\nN\u00b0 de la course\n\n**cr-nb_partants**\nNombre de partants\n\n**cr-Hippodrome**\nNom de l'hippodrome\n\n**cr-Evt**\nCourse \u00e9v\u00e9nement ou pas\n\n**cr-Date**\n\n**cr-autostart** \n1 ou 0\n\n**cr-corde**\nEmplacement de la corde \u00e0 droite ou \u00e0 gauche\n\n**cr-etat du terrain**\nEtat du terrain\n\n**cr-distance**\nDistance de la course\n\n**Numcheval**\t\nNum\u00e9ro du cheval\n\n**CoteProbable**\t\nCote probable du cheval\n\n**Sexe** \nH, F ou M\n\n**NbRencontre** \nNombre de fois o\u00f9 le cheval a rencontr\u00e9 un des concurents dans une course pr\u00e9c\u00e9dente\n\n**NbBattus** \nNombre de fois o\u00f9 le cheval courant a eu une meilleure place\n\n**SommeNbRencontre**\nToute les fois o\u00f9 notre cheval a rencontr\u00e9 un concurrent\n\n**SommeNbBattus** \nToute les fois o\u00f9 notre cheval a eu une meilleure place qu'un concurrent\n\n**NumCourseJockey**\nN\u00b0 de la cours edu jockey\n\n**QteCourseJockeyJour**\nNombre de course du jockey pour cette journ\u00e9e\n\n**SumCote5Race**\nSomme des cotes connues des 5 derni\u00e8res courses\n\n**MoyenneCote5Race**\nMoyenne des cotes des 5 denri\u00e8res courses\n\n**qteCoteCheval**\nNombre de fois o\u00f9 l'on a eu une cote sur les 5 derni\u00e8res courses\n\n**ETCote5Race**\nEcart type des cotes des 5 derni\u00e8res courses\n\n**SumPoids**\nNombre de fois o\u00f9 le cheval avait le m\u00eame poids sur les courses pr\u00e9c\u00e9dentes\n\n**SumIdJockey**\nNombre de fois o\u00f9 le cheval avait le m\u00eame jockey sur les courses pr\u00e9c\u00e9dentes\n\n**SumidHippodrome**\nNombre de fois o\u00f9 le cheval avait le m\u00eame hippodrome sur les courses pr\u00e9c\u00e9dentes\n\n**SumIdDeferre**\nNombre de fois o\u00f9 le cheval avait la m\u00eame ferrure sur les courses pr\u00e9c\u00e9dentes\n\n**SumDistance**\nNombre de fois o\u00f9 le cheval courrait sur la m\u00eame distance sur les courses pr\u00e9c\u00e9dentes\n\n**SumAllocation**\nNombre de fois o\u00f9 le cheval avait la m\u00eame allocation sur les courses pr\u00e9c\u00e9dentes\n\n**PositionPoids**\nNombre de fois o\u00f9 le cheval a \u00e9t\u00e9 dans les 3 premiers avec le m\u00eame poids sur les courses pr\u00e9c\u00e9dentes\n\n**PositionIdJockey**\nNombre de fois o\u00f9 le cheval a \u00e9t\u00e9 dans les 3 premiers avec le m\u00eame jockey sur les courses pr\u00e9c\u00e9dentes\n\n**PositionidHippodrome**\nNombre de fois o\u00f9 le cheval a \u00e9t\u00e9 dans les 3 premiers avec le m\u00eame hippodrome sur les courses pr\u00e9c\u00e9dentes\n\n**PositionIdDeferre**\nNombre de fois o\u00f9 le cheval a \u00e9t\u00e9 dans les 3 premiers avec la m\u00eame ferrure sur les courses pr\u00e9c\u00e9dentes\n\n**PositionDistance**\nNombre de fois o\u00f9 le cheval a \u00e9t\u00e9 dans les 3 premiers avec la m\u00eame distance sur les courses pr\u00e9c\u00e9dentes\n\n**PositionAllocation**\nNombre de fois o\u00f9 le cheval a \u00e9t\u00e9 dans les 3 premiers avec la m\u00eame allocation sur les courses pr\u00e9c\u00e9dentes\n\n**pourcentPoids**\n% o\u00f9 le cheval a \u00e9t\u00e9 plac\u00e9 pour le m\u00eame poids\n\n**pourcentIdJockey**\n% o\u00f9 le cheval a \u00e9t\u00e9 plac\u00e9 pour le m\u00eame jockey\n\n**pourcentidHippodrome**\n% o\u00f9 le cheval a \u00e9t\u00e9 plac\u00e9 pour le m\u00eame hippodrome\n\n**pourcentIdDeferre**\n% o\u00f9 le cheval a \u00e9t\u00e9 plac\u00e9 pour la m\u00eame ferrure\n\n**pourcentDistance**\n% o\u00f9 le cheval a \u00e9t\u00e9 plac\u00e9 pour la m\u00eame distance\n\n**pourcentAllocation**\n% o\u00f9 le cheval a \u00e9t\u00e9 plac\u00e9 pour la m\u00eame allocation\n\n**SommeCourse**\nNombre fois o\u00f9 un cheval a courru\n\n**numeroagespec**\n% de r\u00e9ussite  num\u00e9ro age specialit\u00e9\n\n**numerodistancespec**\n% de r\u00e9ussite    num\u00e9ro distance specialit\u00e9\n\n**numerodeferrespec**\n% de r\u00e9ussite   num\u00e9ro  ferrure specialit\u00e9 \n\n**numerosexespec**\n% de r\u00e9ussite  num\u00e9ro  sexe sp\u00e9cialit\u00e9  \n\n**numeroagesexedistancespec**\n% de r\u00e9ussite  num\u00e9ro age sexe distance specialit\u00e9  \n\n**idjockeynumcoursenbrcoursespec**\n% de r\u00e9ussite  \n\n**jockeyReussite**\n% de r\u00e9ussite  du joskey\n\n**jockeyReussiteSpecialite**\n% de r\u00e9ussite  du joskey dans la sp\u00e9cialit\u00e9\n\n**jockeynReussiteDistance**\n% de r\u00e9ussite  du jockey sur la distance\n\n**jockeyReussiteIdcheval**\n% de r\u00e9ussite  du jockey avec ce cheval\n\n**jockeyReussiteDeferre**\n% de r\u00e9ussite  du jockey fonction de la ferrure\n\n**jockeynReussiteSpecialiteDeferre**\n% de r\u00e9ussite  du jockey fonction d ela ferrure et de la spcialit\u00e9\n\n**jockeyReussiteDistanceDeferre**\n% de r\u00e9ussite  du jockey distance deferre\n\n**entraineurReussite**\n% de r\u00e9ussite  entraineur\n\n**entraineurReussiteSpecialite**\n% de r\u00e9ussite  entraineur sp\u00e9cialit\u00e9\n\n**entraineurnReussiteDistance**\n% de r\u00e9ussite  entraineur distance\n\n**entraineurReussiteIdcheval**\n% de r\u00e9ussite  entraineur avec cheval\n\n**chevalReussite**\n% de r\u00e9ussite  du cheval\n\n**chevalReussiteSpecialite**\n% de r\u00e9ussite  du cheval sp\u00e9cialit\u00e9\n\n**chevalnReussiteDistance**\n% de r\u00e9ussite  du cheval sur cette distance\n\n**coteprobable**\nValeur de la cote\n\n**gains**\nGains du cheval sur sa carri\u00e8re\n\nSi vous avez des questions n'h\u00e9sitez pas \u00e0 me contacter directement\n\n\n\n\n### Ici, place est la variable cible et le reste des variables sont des variables pr\u00e9dictives.\n.\n\n## 3.2 Variables Num\u00e9rique, de Cat\u00e9gorie et de Date <a id=\"3.2\"><\/a>\n**Variable de cat\u00e9gorie:**  cr-reunion, cr-num, cr-Hippodrome, cr-Evt, cr-autostart, cr-corde, cr-etat du terrain, cr-distance,  Sexe\n\n**Variable num\u00e9rique:**  cr-nb_partants, Numcheval, CoteProbable, NbRencontre,\n       NbBattus, SommeNbRencontre, SommeNbBattus, NumCourseJockey, QteCourseJockeyJour, SumCote5Race, MoyenneCote5Race,\n       qteCoteCheval, ETCote5Race, SumPoids, SumIdJockey,\n       SumidHippodrome, SumIdDeferre, SumDistance, SumAllocation,\n       PositionIdJockey, PositionidHippodrome, PositionIdDeferre,\n       PositionDistance, PositionAllocation, pourcentIdJockey,\n       pourcentidHippodrome, pourcentIdDeferre, pourcentDistance,\n       pourcentAllocation, SommeCourse, nbjourdercourse, numeroagespec,\n       numerodistancespec, numerodeferrespec, numerosexespec,\n       numeroagesexedistancespec, idjockeynumcoursenbrcoursespec,\n       jockeyReussite, jockeyReussitePlusPlace, jockeyReussiteSpecialite,\n       jockeynReussiteDistance, jockeyReussiteIdcheval,\n       jockeyReussiteDeferre, jockeynReussiteSpecialiteDeferre,\n       jockeyReussiteDistanceDeferre, entraineurReussite,\n       entraineurReussitePlusPlace, entraineurReussiteSpecialite,\n       entraineurnReussiteDistance, entraineurReussiteIdcheval,\n       chevalReussite, chevalReussitePlusPlace, chevalReussiteSpecialite, chevalnReussiteDistance, coteprobable, gains\n\n**Variable date:** cr-Date\n## 3.3 Types des  donn\u00e9es<a id=\"3.3\"><\/a>","5c7e4d4b":"**Dommage !**\n\nIl nous reste encore 8824 lignes avec des valeurs Nan. Cela provient du fait que pour cr\u00e9er la median d'un groupement, encore faut il que l'on ai assez de donn\u00e9es \u00e0 analyser.\n\nOn va donc faire une boucle et cr\u00e9er des combinaisons de colonnes afin de faire d\u00e9croitre le nombre de Nan","eb10182b":"Au final on ne va garder que les colonnes avec une corr\u00e9altion >=0.15","95d07e6a":"# 1. Description du probl\u00e8me et objectif <a id=\"1\"><\/a>\n\nDans ce probl\u00e8me, on nous demande de compl\u00e9ter l'analyse des types de cheveaux susceptibles de gagner en utilisant l'apprentissage automatique. C'est donc \u00e0 nous de pr\u00e9dire si un cheval sera ou non \u00e0 l'arriv\u00e9e. C'est donc un probl\u00e8me de classification binaire.\n\n# 2.Importation des modules et des donn\u00e9es <a id=\"2\"><\/a>\n","20e3d09b":"On remaque que le nombre de partants a une corr\u00e9lation de 0.21 avec la cote probable. Cela veut dire qu'au plus il y a de partants au plus la cote est \u00e9lev\u00e9e.\n\nOn va tenter une exp\u00e9rience \u00e0 savoir arrondir toutes les colonnes de type float au dixi\u00e8me. On aura ainsi 11 valeurs diff\u00e9rents.\nDe ce fait on referra ensuite l'analyse.","881979f9":"**Constations** :  On voit que p=0.98 qui est largement sup\u00e9rieur \u00e0 0.05\n\n### 8.2.3 Autostart et Plac\u00e9  <a id=\"8.2.3\"><\/a>","2025eadf":"**Conclusions** : On remarque que la corde \u00e0 gauche avec un autostart et un course evt augmente le % de r\u00e9ussite\n\n## 9.2 Corde, Sexe, num\u00e9ro  <a id=\"9.2\"><\/a>","49d69f86":"**Constations** :  On voit que p=0.98 qui est largement sup\u00e9rieur \u00e0 0.05\n\n### 8.2.4 Course \u00e9v\u00e9nement et Plac\u00e9  <a id=\"8.2.4\"><\/a>","f87b0f4c":"La fonction describe nous permet de v\u00e9rifier la nouvelle colonne. Le min est 1 et le max 31. Tout est ok.\n\nIl peut \u00eatre int\u00e9r\u00e9ssant de jeter un petit coup d'oeil \u00e0 ces nouvelles variables.","b482b4c5":"### 4.2.1 Skewness <a id=\"4.2.1\"><\/a>\n\nOn distingue trois types de distributions selon qu'elles sont dissym\u00e9triques (asym\u00e9triques) \u00e0 gauche (graphique de gauche), sym\u00e9triques (graphique du milieu) ou dissym\u00e9triques (asym\u00e9triques) \u00e0 droite (graphique de droite).\n\n![](http:\/\/www.logiciels-professionnels.com\/Skewness.jpg)\n\nQue sugg\u00e8re donc la valeur de l'asym\u00e9trie Skewness ?\n\n    Si l'asym\u00e9trie est inf\u00e9rieure \u00e0 -1 ou sup\u00e9rieure \u00e0 +1, la distribution peut \u00eatre consid\u00e9r\u00e9e comme fortement asym\u00e9trique.\n    Si l'asym\u00e9trie est comprise entre -1 et -0,5 ou entre 0,5 et +1, la distribution peut \u00eatre consid\u00e9r\u00e9e comme mod\u00e9r\u00e9ment asym\u00e9trique.\n    Enfin, si l'asym\u00e9trie est comprise entre -\u00bd et +\u00bd, la distribution peut \u00eatre consid\u00e9r\u00e9e comme approximativement sym\u00e9trique.\n\n\n\nEn r\u00e8gle g\u00e9n\u00e9rale, on cherche \u00e0 avoir des donn\u00e9es qui ne sont pas dissym\u00e9triques. Cela aide en g\u00e9n\u00e9ral, les processus pour les algo de regression, machine learning etc.\nUne mani\u00e8re rapide de traiter ce probl\u00e8me est d'appliquer une transformation log sur les datas.  Il y a d'autres mani\u00e8res de faire avec Box Cox par exemple.\n\nDans notre processus de tranformaion on va dire que si la valeur absolue de Skewness est sup\u00e9rieur \u00e0 0,75 alors on applique une transformation\n","297b4f9f":"A la vue des diff\u00e9rents graphiques, il semble qu'il n'y a que le nombre de partant qui g\u00e9n\u00e8re une influence sur la cote. On peut remarquer que plus le nombre de partants est important plus la cote monte.\n\nOn va cr\u00e9er un graphique de corr\u00e9lation pour v\u00e9rifier notre lecture des graphiques.","c3e63f1a":"En moyenne un hippodrome a \u00e9t\u00e9 pr\u00e9sent dans 127 courses et la m\u00e9diane est \u00e0 10 courses. Cela nous indique qu'il y a beaucoup d'hippodrome o\u00f9 l'on a couru peu de fois.\nOn va cr\u00e9er une nouvelle variable o\u00f9 l'on va regrouper les hippodromes. Cette nouvelle colonne se nommera **cr-HippodromeCat** . Si un hippodrome a eu moins de 127 courses alors on le regroupera dans une nouvelle categorie nomm\u00e9e \"Autre\".","384a3e3b":"**Constatations:** De nouveau on remarque un d\u00e9s\u00e9quilibre important avec les d\u00e9part \u00e0 l'auto start. \n\n### 4.1.5 cr-Evt <a id=\"4.1.5\"><\/a>","99785d73":"On visualise bien notre colonne cote probable avec des blancs \u00e0 la place des valeurs Nan. Pour l'instant nous allons laisse tel quel cette colonne. Dans un autre chapitre, nous verrons comment remplcaer les valeurs manquantes.\n\n\n## 5.2 cr-date <a id=\"5.2\"><\/a>\n\nA partir de cette variable, nous allons cr\u00e9er 4 nouvelles variables :\n* Le n\u00b0 du jour de la semaine\n* Le mois\n* Le n\u00b0 de la semaine dans l'ann\u00e9e\n* Le jour du mois\n\n### 5.2.1 Le n\u00b0 du jour de la semaine <a id=\"5.2.1\"><\/a>\nLe jour de la semaine en partant de Lundi=0 \u00e0 Dimanche = 6","73b483a3":"**Fin de la 1\u00b0 partie**","58c365c1":"**Note:** Nous n'avons pas de variable Place pour le jeu de test. Ce sera notre t\u00e2che d'inf\u00e9rer Place pour l'ensemble d'essai en apprenant de l'ensemble de train.","2cf8120a":"Comme nous l'avions vu pr\u00e9c\u00e9demment, il n'y a que la variable coteprobable qui poss\u00e9de des valeurs manquantes.\n\n## 7.1 Imputation de la cote probable <a id=\"7.1\"><\/a>\n\nPour imputer la cote probable \u00e0 la m\u00e9diane group\u00e9e, nous devons savoir quelles caract\u00e9ristiques sont fortement corr\u00e9l\u00e9es \u00e0 cette variable. Trouvons les variables corr\u00e9l\u00e9es avec la cote probable.\n","db7587a5":"### 4.2.2 Coefficient d'aplatissement (\u00ab Kurtosis \u00bb) <a id=\"4.2.2\"><\/a>\n\nL'aplatissement d'une distribution est estim\u00e9 par le coefficient d'aplatissement \u00df2 (ou \u00ab Kurtosis \u00bb). Comme le \u00ab Skewness \u00bb, le \u00ab Kurtosis \u00bb est une quantit\u00e9 sans dimension. Il mesure l'aplatissement (ou la plan\u00e9it\u00e9) d'une distribution . Plus la valeur de ce coefficient est grand, plus la distribution est pointue.\n\n![](http:\/\/www.logiciels-professionnels.com\/kurtosis.gif)\n\nTrois cas sont \u00e0 envisager :\n\n1. K > 3 : La distribution est dite pointue et donc leptokurtotique.\n1. K = 3 : La distribution est qualifi\u00e9e de normale.\n1. K< 3 : La distribution est dite \u00e9cras\u00e9e et donc playkurtotique.\n\nIl n'y a aucune traitement \u00e0 faire vis-\u00e0-vis de cet indicateur.\n\n","973517b2":"## 9.1 Corde, autostrat, \u00e9v\u00e9nement  <a id=\"9.1\"><\/a>","70afbfc0":"**Constatations** : La distribution est tr\u00e8s semblable chevauchement), ce qui en fait un pr\u00e9dicteurinutile.\nLa valeur de corr\u00e9lation de 0.0085 et la valeur p 0.416  qui sugg\u00e8re que nous ne sommes pas en mesure de d\u00e9finir la fiabilit\u00e9 du test. \n\n### 8.1.2 Jour du mois et Plac\u00e9 <a id=\"8.1.2\"><\/a>\n\n","1eaf5be3":"**Constatations** : Il semble \u00e0 la vue des graphiques qu'il y a pas de diff\u00e9rence entre une corde \u00e0 droite ou \u00e0 gauche.","a8443b43":"**Constatations**: La variable Place est l\u00e9g\u00e8rement d\u00e9s\u00e9quilibr\u00e9e puisque la proportion de plac\u00e9 et non plac\u00e9  n'est pas \u00e9galement repr\u00e9sent\u00e9e dans sa r\u00e9partition. Sur les 19869 courses seuls 8864 chevaux n'ont pas \u00e9t\u00e9 plac\u00e9s. Autrement dit, 55,39 % des chevaux se sont plac\u00e9s \u00e0 l'arriv\u00e9e dans les 3 premiers.**","b95668c8":"Le mois d'aout semble est un mois o\u00f9 la r\u00e9ussite est plus elev\u00e9e.","bf5bf188":"### 4.1.10 Distance <a id=\"4.1.10\"><\/a>","7f998709":"# 5 Pr\u00e9paration des variables <a id=\"5\"><\/a>\n\n\nDans cette section, nous allons modifier et cr\u00e9er de nouvelles caract\u00e9ristiques \u00e0 partir des caract\u00e9ristiques existantes qui sont autrement difficiles \u00e0 analyser dans leurs formes brutes que nous avons vues dans la section Analyse univari\u00e9e. Nous allons travailler sur les deux variables coteprobable et cr-date.\n\n## 5.1 Cote probable <a id=\"5.1\"><\/a>\n\nDans le paragraphe sur les Variables num\u00e9riques, quand on regarde le graphique concernant les cotes probables, on remarque qu'il y a beaucoup de valeurs \u00e9gales \u00e0 0. Cela indique que l'on ne connaissait pas la cote du cheval. Confirmons cela avec la commande ci-dessous.","90ab115e":"# 3.Variable Description et Identification <a id=\"3\"><\/a>\nD\u00e9crire ce que chacune des variables indique et identifier notre r\u00e9ponse et nos variables pr\u00e9dicteurs. S\u00e9parez ensuite les variables cat\u00e9gorielles des variables num\u00e9riques et identifiez enfin les types de donn\u00e9es pandas (c.-\u00e0-d. objet, float64 ou int64) pour chaque variable.\n\n## 3.1 Description des variables<a id=\"3.1\"><\/a>","d12c768c":"**Constations** :  On voit que p=0.27 qui est largement sup\u00e9rieur \u00e0 0.05\n\n### 8.2.6 Hippodrome et Plac\u00e9  <a id=\"8.2.5\"><\/a>","31aba5df":"La valeur 0 a bien \u00e9t\u00e9 supprim\u00e9e.\n\nNous allons charger le package missingno afin de visualiser dans nos colonnes les diff\u00e9rents valeurs manquantes.","65441346":"Ce graphique nous montre en vert clair les courses gagn\u00e9es et en couleur kaki les courses perdues.  On peut remarquer que le lundi est le jour o\u00f9 le taux de courses gagnantes est le plus bas.","ab460c7e":"La fonction describe nous permet de v\u00e9rifier la nouvelle colonne. Le min est 1 et le max 12. Tout est ok.\n\n### 5.2.3 Le n\u00b0 de la semaine de l'ann\u00e9e <a id=\"5.2.3\"><\/a>\n","b4fcd5d1":"**Constatations** : La distribution est tr\u00e8s semblable , ce qui en fait un pr\u00e9dicteu inutile.\nLa valeur de corr\u00e9lation de 0.006 et la valeur p 0.54  qui sugg\u00e8re que nous ne sommes pas en mesure de d\u00e9finir la fiabilit\u00e9 du test. \n\n\n## 8.2 Variables cat\u00e9goriques et cat\u00e9goriques  <a id=\"8.2\"><\/a>\n\nNous calculerons et tracerons la fr\u00e9quence absolue et relative de la variable cat\u00e9gorielle de sortie par variables nominales pr\u00e9dicteurs. ","68b0fdd2":"1\u00b0 ligne on a 0.8390186951454712\n2\u00b0 ligne on a 0.32058\n3\u00b0ligne on 0.174258 etc, etc\n\nOn voit de suite que les valeurs de p sont sup\u00e9rieures \u00e0 0.0013.\n\n# 9 Analyse multivariables  <a id=\"9\"><\/a>\n\nDans l'analyse multivari\u00e9e, nous essayons de trouver la relation entre plus de deux variables. Le nombre de variables pr\u00e9dicteurs dans l'analyse bivari\u00e9e \u00e9tait de un. Au contraire, le nombre de variables pr\u00e9dicteurs pour l'analyse multivari\u00e9e est sup\u00e9rieur \u00e0 un. Plus pr\u00e9cis\u00e9ment, nous tenterons d'associer plus d'une variable pr\u00e9dictive \u00e0 la variable r\u00e9ponse. Nous allons simplement visualiser l'impact de diff\u00e9rentes variables pr\u00e9dicteurs (3 variables) \u00e0 la fois sur la variable Place.","53e2560b":"**Interpr\u00e9tation des r\u00e9sultats du test de la valeur p ajust\u00e9e de Bonferroni** : En utilisant la valeur p ajust\u00e9e de Bonferroni de 0,017, 2 des 3 comparaisons par paires pr\u00e9vues sont significatives.  On voit que F M a un p de 0.1474\n\n### 8.2.2 Corde et Plac\u00e9  <a id=\"8.2.2\"><\/a>","8832ef56":"On remarque juste que les  semaines 38, 39 et 40ne semble pas \u00eatre id\u00e9ales pour jouer.\n\n# 6. D\u00e9tection des valeurs aberrantes <a id=\"6\"><\/a>\n\nComment les valeurs aberrantes affectent la distribution : Si une valeur d'une variable est nettement sup\u00e9rieure \u00e0 la fourchette pr\u00e9vue, elle fera glisser la distribution vers la droite, rendant le graphique oblique vers la droite ou oblique vers le positif . Alternativement, si une valeur est significativement en dessous de la plage attendue, elle fera glisser la distribution vers la gauche, rendant le graphique oblique vers la gauche ou oblique vers le n\u00e9gatif.\n\nUn autre trac\u00e9 utile pour visualiser une variable continue est le trac\u00e9 en bo\u00eetes. Le diagramme en encadr\u00e9 est particuli\u00e8rement utile pour comprendre la dispersion des donn\u00e9es et pour savoir s'il existe des observations inhabituelles potentielles (valeurs aberrantes) dans cette variable. Il pr\u00e9sente les informations de min, 1er quartile, 2\u00e8me quartile (m\u00e9diane), 3\u00e8me quartile, et max d'une variable. Nous utiliserons la m\u00e9thode IQR pour d\u00e9tecter les valeurs aberrantes pour la variable CoteProbable, mais nous ne les supprimerons pas.\n\n","3543d944":"### 8.1.1 N\u00b0 de la course et Plac\u00e9 <a id=\"8.1.1\"><\/a>\n","ea3b8fbf":"On se rappelle que nous avions transform\u00e9 la colonne hippodrome en cr-HippodromeCat et celle de la distance en cr-distanceNum.\nNous avions cr\u00e9\u00e9 aussi des colonnes ARRONDIxx. Nous allons \u00e9galement supprimer ces colonnes.\nOn peut supprimer aussi cr-Date","bc8fdf90":"**Constatations:** L\u00e0 on se rend compte que l'on va aoir un l\u00e9ger probl\u00e8me avec la variable hippodrome...\n\n\n","35136f1c":"# A propos de ce kernel\n\nCe noyau peut (ou non) \u00eatre utile dans votre long et souvent fastidieux apprentissage machine. Lors de la cr\u00e9ation de ce noyau, j'ai presque toujours utilis\u00e9 des commentaires \u00e0 lignes multiples ('''' '''') au lieu de commentaires \u00e0 ligne unique (#) car certains commentaires \u00e0 ligne unique n'\u00e9taient pas visibles apr\u00e8s avoir livr\u00e9 le noyau. \n\nParfois, vous trouverez ce carnet trop verbeux. Cette verbosit\u00e9 tente d'expliquer tout ce que je pourrais savoir. J'ai \u00e9galement essay\u00e9 d'\u00e9crire des codes r\u00e9utilisables autant que possible en utilisant des fonctions personnalis\u00e9es afin que nous puissions \u00e9viter d'\u00e9crire le m\u00eame code encore et encore.\n\n[https:\/\/turf-ia.com](https:\/\/turf-ia.com)\n\nLa premi\u00e8re partie de ce notebook traitera de l'analyse des donn\u00e9es.\nLa partie deux traitera de la construction et de l'\u00e9valuation des mod\u00e8les\n\nVous pouvez commenter si vous avez des questions sur ce carnet. \n","e607388c":"Il nous reste encore 7809 Nan","1ae0b762":"Au final on ne va garder que les colonnes avec une corr\u00e9altion >=0.15","972f7148":"**Constatations:** On peut constater l\u00e0 encore un d\u00e9s\u00e9quilibre entre les diff\u00e9rentes classes\n\n\n\n### 4.1.3 cr-corde  <a id=\"4.1.3\"><\/a>","1910db3c":"**Constatations:** A une \u00e9crasante majorit\u00e9 terrain bon et sur repr\u00e9sent\u00e9 dans cet \u00e9chantillon  cr-reunion, cr-num, cr-Hippodrome   cr-etat du terrain, cr-distance,**\n\n### 4.1.7 R\u00e9union <a id=\"4.1.7\"><\/a>","8a58c7fe":"# Sommaire\n\n* [1.Description du probl\u00e8me et objectif ](#1)\n* [2.Importation des modules et des donn\u00e9es](#2)\n* [3.Variable Description et Identification](#3)\n   * [3.1 Description des variables](#3.1) \n   * [3.2 Variables Num\u00e9rique, de Cat\u00e9gorie et de Date](#3.2) \n   * [3.3 Types des variables](#3.3)\n* [4.Analyse univari\u00e9e](#4)\n   * [4.1 Variables cat\u00e9gorielles](#4.1)\n      * [4.1.1 Place](#4.1.1) \n      * [4.1.2 Sexe](#4.1.2) \n      * [4.1.3 Corde](#4.1.3) \n      * [4.1.4 Autostart](#4.1.4) \n      * [4.1.5 Evt](#4.1.5) \n      * [4.1.6 Etat du terrain](#4.1.6) \n      * [4.1.7 R\u00e9union](#4.1.7) \n      * [4.1.8 Num\u00e9ro course](#4.1.8) \n      * [4.1.9 Hippodrome](#4.1.9)\n      * [4.1.10 Distance](#4.1.10)\n   * [4.2 Variables Num\u00e9riques ](#4.2)    \n      * [4.2.1 Skewness](#4.2.1)  \n      * [4.2.2 Coefficient d'aplatissement (\u00ab Kurtosis \u00bb) ](#4.2.2) \n* [5. Pr\u00e9paration des variables](#5)\n   * [5.1 Cote probable](#5.1) \n   * [5.2 Date de la course](#5.2)\n    * [5.2.1 Le n\u00b0 du jour de la semaine](#5.2.1)\n    * [5.2.2 Le mois](#5.2.2)\n    * [5.2.3 Le n\u00b0 de la semaine de l'ann\u00e9e](#5.2.3)\n    * [5.2.4 Le jour du mois](#5.2.4)\n    * [5.2.5 Analyse des nouvelles variables](#5.2.5)\n   \n* [6. D\u00e9tection des valeurs aberrantes](#6)\n   * [6.1 Valeurs aberrantes cote probables](#6.1) \n* [7.Imputation des variables manquantes](#7)\n   * [7.1 Imputation cote probables](#7.1) \n* [8.Analyse bivari\u00e9e](#8)\n   * [8.1 Variables numeriques et categorielle](#8.1)\n      * [8.1.1 Num\u00e9ro course & Plac\u00e9](#8.1.1)   \n      * [8.1.2 Jour du mois & Plac\u00e9](#8.1.2)\n   * [8.2 Variables de cat\u00e9gorie et de cat\u00e9gorie](#8.2)\n      * [8.2.1 Sexe & Plac\u00e9](#8.2.1)\n      * [8.2.2 Corde & Place](#8.2.2) \n      * [8.2.3 Autostart & Plac\u00e9](#8.2.3) \n      * [8.2.4 Evt & Plac\u00e9](#8.2.4) \n      * [8.2.5 Etat du terrain & Plac\u00e9](#8.2.5)\n      * [8.2.6 Hippodrome & Plac\u00e9](#8.2.6) \n      \n* [9.Analyse Multivariables](#9)  \n   * [9.1 (Corde, autostrat, \u00e9v\u00e9nement) vs Place](#9.1) \n   * [9.2 (Corde, Sexe, num\u00e9ro) vs Place](#9.2) \n   * [9.3 (Etat du terrain, num\u00e9ro course, Sexe) vs Place](#9.3) \n* [10. Transformation des donn\u00e9es](#10) \n   * [10.1 Suppression de variables](#10.1)\n   * [10.2 Encodage des variables cat\u00e9gorielles](#10.2) \n","3adca955":"La fonction describe nous permet de v\u00e9rifier la nouvelle colonne. Le min est 1 et le max 53. Tout est ok.\n\n### 5.2.4 Le jour du mois <a id=\"5.2.4\"><\/a>","9344e64b":"**Constations** :  On voit que p=0.98 qui est largement sup\u00e9rieur \u00e0 0.05\n\n### 8.2.5 Etat du terrain et Plac\u00e9  <a id=\"8.2.5\"><\/a>","f0ab865b":"On peut se rendre compte que ce n'est pas un baguette magique et que certaines colonnes ont un Skewness d\u00e9grad\u00e9 apr\u00e8s l'application de la transformation log.\n\nOn ne va transformer que certaines colonnes.\n\nJe ne vais pas transformer pour l'instant la colonne CoteProbable car nous verrons plus loin qu'il y a un traitement\u00e0 effectuer sur cette colonne.\n","a42e8297":"**Constations** :  On voit que p=0.004 qui est l\u00e9g\u00e8rement inf\u00e9rieur \u00e0 0.05  et que toutes les valeurs sont su\u00e9prieures \u00e0 5. Donc l'hippodrome a une influence sur la place.\n\nComme nous avons 37 cat\u00e9gories diff\u00e9rentes on doit diviser 0.05\/37 = 0.0013","eab7afc8":"**Nous comptons 739 valeurs aberrantes.\n\nDans le cas d'un diagramme en bo\u00eetes, si la partie la plus longue de la bo\u00eete est droite (ou sup\u00e9rieure) \u00e0 la m\u00e9diane, on dit que les donn\u00e9es sont biais\u00e9es \u00e0 droite. Si la partie la plus longue est laiss\u00e9e \u00e0 la m\u00e9diane (ou en dessous), les donn\u00e9es sont biais\u00e9es vers la gauche. Dans notre cas, la plus grande partie de la bo\u00eete est droite \u00e0 la m\u00e9diane.\n\nPour la suite de notre \u00e9tude nous allons remplacer ces valeurs ab\u00e9rrantes par la moyenne. Il y a de nombreuses mani\u00e8res de prendre en compte ce type de valeurs. Pour cet exemple, mon choix est de vous montrer le remplacement par la moyenne.\n\n","cc56d378":"1. **type int :** place,cr-reunion,cr-num,cr-nb_partants,cr-Evt,cr-autostart,Numcheval,CoteProbable,SumPoids\n2. **type float :** NbRencontre,NbBattus,SommeNbRencontre,SommeNbBattus,NumCourseJockey,QteCourseJockeyJour,SumCote5Race,MoyenneCote5Race,qteCoteCheval,ETCote5Race,SumIdJockey,SumidHippodrome,SumIdDeferre,SumDistance,SumAllocation,PositionIdJockey,PositionidHippodrome,PositionIdDeferre,PositionDistance,PositionAllocation,pourcentIdJockey,pourcentidHippodrome,pourcentIdDeferre,pourcentDistance,pourcentAllocation,SommeCourse,nbjourdercourse,numeroagespec,numerodistancespec,numerodeferrespec,numerosexespec,numeroagesexedistancespec,idjockeynumcoursenbrcoursespec,jockeyReussite,jockeyReussitePlusPlace,jockeyReussiteSpecialite,jockeynReussiteDistance,jockeyReussiteIdcheval,jockeyReussiteDeferre,jockeynReussiteSpecialiteDeferre,jockeyReussiteDistanceDeferre,entraineurReussite,entraineurReussitePlusPlace,entraineurReussiteSpecialite,entraineurnReussiteDistance,entraineurReussiteIdcheval,chevalReussite,chevalReussitePlusPlace,chevalReussiteSpecialite,chevalnReussiteDistance,coteprobable,gains\n3. **type object (numbers + strings):** cr-Hippodrome,cr-corde,cr-etat du terrain,cr-distance,Sexe\n4. **type date:** cr-date\n\n","5f55c2e4":"De mani\u00e8re assez \u00e9tonnante, le 10 de chaque mois est le pire jour pour jouer. Ensuite le 20 du mois n'est pas tr\u00e8s bon non plus. Il faudrait creuser un peu plus pour en chercher la raison.","f5ee5563":"**Constatations** : Il semble \u00e0 la vue des graphiques qu'un cheval Male \u00e0 plus de chance d'\u00eatre \u00e0 l'arriv\u00e9e\n\n**Test du Khi-deuxi\u00e8me degr\u00e9** : Les donn\u00e9es sont habituellement pr\u00e9sent\u00e9es sous forme de tableaux crois\u00e9s, chaque ligne repr\u00e9sentant une cat\u00e9gorie pour une variable et chaque colonne repr\u00e9sentant une cat\u00e9gorie pour une autre variable. Le test du Khi-deuxi\u00e8me crit\u00e8re d'ind\u00e9pendance est un test omnibus, c'est-\u00e0-dire qu'il teste les donn\u00e9es dans leur ensemble. Cela signifie que l'on ne pourra pas dire quels niveaux (cat\u00e9gories) des variables sont responsables de la relation si le tableau du Khi-deux est sup\u00e9rieur \u00e0 2\u00d72. Si l'essai est sup\u00e9rieur \u00e0 2\u00d72, il n\u00e9cessite des essais post hoc.\n\nLe H0 (hypoth\u00e8se nulle) : Il n'y a pas de relation entre la variable 1 et la variable 2.\n\nLe H1 (hypoth\u00e8se alternative) : Il existe une relation entre la variable 1 et la variable 2.\n\nSi la valeur p est significative (moins de 0,05), vous pouvez rejeter l'hypoth\u00e8se nulle et pr\u00e9tendre que les r\u00e9sultats appuient l'autre hypoth\u00e8se. Pendant que nous v\u00e9rifions les r\u00e9sultats du test chi2, nous devons \u00e9galement v\u00e9rifier que les fr\u00e9quences attendues des cellules sont sup\u00e9rieures ou \u00e9gales \u00e0 5. si une cellule a une fr\u00e9quence attendue inf\u00e9rieure \u00e0 5, alors le test de Fisher Exact devrait \u00eatre utilis\u00e9 pour surmonter ce probl\u00e8me.\n\nLa m\u00e9thode chi2_contingency() effectue le test du Khi-deux sur une table de contingence (tableau crois\u00e9).","7622de5f":"###  4.1.1 Place <a id=\"4.1.1\"><\/a>","1e04fa07":"\n\n# 10. Transformation des variables <a id=\"10\"><\/a>\n\nDans cette section, les variables redondantes et inutiles seront supprim\u00e9es. Enfin, les variables cat\u00e9gorielles seront cod\u00e9es en num\u00e9rique pour alimenter nos mod\u00e8les d'apprentissage .\n\n## 10.1 Suppression de variables  <a id=\"10.1\"><\/a>\n\nRappel de nos  diff\u00e9rentes colonnes\n","8bc117fe":"\n\n# 7 Imputation valeurs manquantes <a id=\"7\"><\/a>\n\nLa fa\u00e7on la plus simple d'imputer les valeurs manquantes d'une variable est d'imputer ses valeurs manquantes avec sa moyenne, sa m\u00e9diane ou en fonction de sa distribution et du type de variable (cat\u00e9gorique ou num\u00e9rique). Maintenant, nous devrions avoir une bonne id\u00e9e de la distribution des variables et de la pr\u00e9sence de valeurs aberrantes dans ces variables. \n\nPour une variable dont la distribution est asym\u00e9trique et les valeurs aberrantes (comme CoteProbable), l'imputation par la m\u00e9diane est recommand\u00e9e car la m\u00e9diane est plus immunis\u00e9e contre les valeurs aberrantes que la moyenne.\n\nToutefois, un inconv\u00e9nient \u00e9vident de l'utilisation de la moyenne, de la m\u00e9diane ou du mode pour imputer les valeurs manquantes est l'ajout d'un biais si le nombre de valeurs manquantes est important (comme pour la CoteProbable). Le simple fait de les remplacer par la moyenne ou la m\u00e9diane n'est donc peut-\u00eatre pas la meilleure solution, car la cote peut varier selon les types de course.\n\nPour r\u00e9soudre ce probl\u00e8me, nous pouvons regrouper nos donn\u00e9es en fonction de certaines variables qui ne comportent aucune valeur manquante et, pour chaque sous-ensemble, calculer la cote m\u00e9diane pour imputer les valeurs manquantes. Ou nous pouvons construire un mod\u00e8le de r\u00e9gression lin\u00e9aire qui pr\u00e9dira les valeurs manquantes de la cote  en utilisant les caract\u00e9ristiques qui ne comportent aucune valeur manquante. Ces deux m\u00e9thodes peuvent permettre d'obtenir une meilleure pr\u00e9cision sans biais \u00e9lev\u00e9, \u00e0 moins que l'on ne s'attende \u00e0 ce qu'une valeur manquante pr\u00e9sente une variance tr\u00e8s \u00e9lev\u00e9e. Nous allons montrer l'ancienne m\u00e9thode d'imputation.\n\nCherchons d'abord les variables avec les valeurs manquantes.\n\n\n\n","5e5d0db5":"## 6.1 Valeur Aberrante coteprobable <a id=\"6.1\"><\/a>","25aa5e62":"**Constatations:** Nous avons la m\u00eame probl\u00e8matique qu'avec les hippodromes avec \u00e9norm\u00e9mnt de cat\u00e9gories.\n\nPeut-\u00eatre serait il pr\u00e9f\u00e9rable de transformer cette colonne en valeur num\u00e9riques","18e8ce73":"La fonction describe nous permet de v\u00e9rifier la nouvelle colonne. Le min est 0 et le max 6. Tout est ok.\n\n### 5.2.2 Le mois <a id=\"5.2.2\"><\/a>\nLe jour de la semaine en partant de Janvier=1 \u00e0 D\u00e9cembre = 12","1e0755ac":"**Constatations:** L\u00e0 aussi on voit qu'il n'y a pas une r\u00e9partition constante. C'est normal dans la mesure, o\u00f9 il n'y a pas un nombre courses constant entre les diff\u00e9rentes R\u00e9union\n\n### 4.1.9 Hippodrome <a id=\"4.1.9\"><\/a>","9c0b54b5":"**Conclusion **: \nLe graphique n'est pas des plus lisible mais on peut voir quand m\u00eame qu'avec une corde \u00e0 dorite, sexe Hongre ou femelle et avec un gros num\u00e9ro augmente le pourcentage de r\u00e9ussite.\n\n## 9.3 Etat du terrain, num\u00e9ro course, Sexe  <a id=\"9.3\"><\/a>","251127cd":"**Interpr\u00e9tation des r\u00e9sultats du test du chi carr\u00e9 : **\n\nLa premi\u00e8re valeur (33.02) est la valeur du Khi-deux, suivie de la valeur p (6.75e-08), puis viennent les degr\u00e9s de libert\u00e9 (2), et enfin les fr\u00e9quences attendues sous forme de tableau. Puisque toutes les fr\u00e9quences attendues sont sup\u00e9rieures \u00e0 5, les r\u00e9sultats du test chi2 sont fiables. Nous pouvons rejeter l'hypoth\u00e8se nulle car la valeur p est inf\u00e9rieure \u00e0 0,05 (en fait, la valeur p est presque nulle). Ainsi, les r\u00e9sultats indiquent qu'il existe une relation statistiquement significative entre le sexe et la Place.\n\nBien que notre test du Khi-deux ait \u00e9t\u00e9 significatif,  nous ne savons pas quels niveaux de Sexe(F, H ou M) ont la plus forte association avec la variable Place. Nous devons donc effectuer un test post hoc pour v\u00e9rifier si et quelles combinaisons sont r\u00e9ellement associ\u00e9es de mani\u00e8re significative \u00e0 Plac\u00e9. Pour ce faire, nous devons effectuer de multiples tests du Khi-carr\u00e9  \u00e0 l'aide de la valeur p ajust\u00e9e de Bonferroni.\n\nPour effectuer plusieurs tests du Khi-carr\u00e9, il faut regrouper les variables de chaque test dans une cat\u00e9gorie et les comparer aux autres. Pour nous, \u00e7a le sera :\n\n    F contre H\n    F vs M\n    Et enfin H contre M\n\nComme il y a trois comparaisons, la valeur P ajust\u00e9e de Bonferroni n\u00e9cessaire pour la signification est de 0,05\/3, ou 0,017. Ainsi, pour que nos comparaisons par paires soient significatives, la valeur p doit \u00eatre inf\u00e9rieure \u00e0 0,017.","2cdcecf5":"### 8.2.1 Sexe et Plac\u00e9  <a id=\"8.2.1\"><\/a>","6a4cbde0":"## 10.2 Transformation des variables cat\u00e9gorielles  <a id=\"10.2\"><\/a>\n\nRappel de nos  diff\u00e9rentes colonnes de type category","ee0e34d6":"## 4.2 Variables num\u00e9riques<a id=\"4.2\"><\/a>\nNous aimerions analyser des variables num\u00e9riques \u00e0 l'aide d'histogrammes, de courbes de densit\u00e9 et de statistiques sommaires.\nNous allons tout d'abord afficher quelques stats g\u00e9n\u00e9rales sur nos valeurs num\u00e9riques.\n\nPour chaque variable nous allons analyser, le nombre de valeur, la moyenne, la variance, le min, le max et les quartiles","c89ef627":"Il y a 9018 courses ou l'on ne connait pas la cote. Comme cela fait preque 50% de notre dataframe, le mieux serait de supprimer totalement cette colonne. Mais nous allons quand m\u00eame essayer de nous en servir. Pour cela nous allons remplacer les 0 par Nan.","878ba6d7":"**Constatations:** L\u00e0 aussi on voit qu'il n'y a pas une r\u00e9partition constante. C'est int\u00e9ressant car on sait que notre cheval concerne uniquement les courses de trot mont\u00e9. L\u00e0 on se rend compte que la r\u00e9union 3 est plus port\u00e9e sur les courses de trot mont\u00e9.\n\n### 4.1.8 Num\u00e9ro de la course <a id=\"4.1.8\"><\/a>","4ef4edb1":"# 4.Analyse univari\u00e9e <a id=\"4\"><\/a>\nL'analyse univari\u00e9e explore s\u00e9par\u00e9ment la distribution de chaque variable dans un ensemble de donn\u00e9es. Il examine l'\u00e9ventail des valeurs, ainsi que la tendance centrale des valeurs. L'analyse des donn\u00e9es univari\u00e9es n'examine pas les relations entre les diverses variables (comme l'analyse bivari\u00e9e et l'analyse multivari\u00e9e), mais elle r\u00e9sume chaque variable s\u00e9par\u00e9ment. \n\nLes m\u00e9thodes d'analyse univari\u00e9e d\u00e9pendent du caract\u00e8re cat\u00e9gorique ou num\u00e9rique de la variable. Pour la variable num\u00e9rique, nous explorerions sa forme de distribution (la distribution peut \u00eatre sym\u00e9trique ou asym\u00e9trique) \u00e0 l'aide d'histogrammes et de diagrammes de densit\u00e9. Pour les variables cat\u00e9gorielles, nous utiliserions des diagrammes \u00e0 barres pour visualiser la distribution de fr\u00e9quence absolue et proportionnelle. Conna\u00eetre la distribution des valeurs des caract\u00e9ristiques devient important lorsque vous utilisez des m\u00e9thodes d'apprentissage machine qui supposent un type particulier, le plus souvent gaussien. **Commen\u00e7ons par les variables cat\u00e9gorielles:**.\n\n\n\n## 4.1 Variables  Cat\u00e9gorielles<a id=\"4.1\"><\/a>\nPour l'analyse univari\u00e9e cat\u00e9gorielle, nous allons cr\u00e9er des diagrammes \u00e0 barres et des bases de donn\u00e9es de fr\u00e9quence absolue et relative pour chaque variable cat\u00e9gorielle.","567cb54d":"**Super ! **Nous n'avons plus aucune valeur Nan.\n\n**Stats Initiales avant remplacement**\ncount    10851.000000\nmean         3.919106\nstd          1.501822\nmin          1.000000\n25%          3.000000\n50%          4.000000\n75%          5.000000\nmax          8.000000","65a1b87a":"On peut remarquer que la variable SumPoids a toujours la valeur 0. On peut donc supprimer cette variable num\u00e9rique.","d17529dd":"### 4.1.2 Sexe <a id=\"4.1.2\"><\/a>","079f92e0":"Le vendredi est le jour o\u00f9 il y a eu le plus de courses.\n\nOn  remarque que le d\u00e9but de l'ann\u00e9e est la p\u00e9riode o\u00f9 il y a le plus de course et cela d\u00e9croit lentement au fil des mois. Ce qui est normal pour les courses de trot.\n\nNous allons cr\u00e9er un nouveau graphique. Cela","ebfc94bf":"**Constatations** : La distribution est tr\u00e8s semblable , ce qui en fait un pr\u00e9dicteu rinutile.\nLa valeur de corr\u00e9lation de 0.01 et la valeur p 0.27  qui sugg\u00e8re que nous ne sommes pas en mesure de d\u00e9finir la fiabilit\u00e9 du test. \n\n### 8.1.2 Distance course et Plac\u00e9  <a id=\"8.1.3\"><\/a>","10594386":"**Constatations:** On peut constater l\u00e0 encore un d\u00e9s\u00e9quilibre entre les diff\u00e9rentes classes\n\n### 4.1.4 cr-autostart  <a id=\"4.1.4\"><\/a>","c439ac80":"**Constatations:** Surement le d\u00e9s\u00e9quilibre le plus important que nous ayons eu jusqu'alors.\n\n### 4.1.6 cr-etat du terrain <a id=\"4.1.6\"><\/a>","92c47c6c":"**Constatations**:  Comme nous venons de transformer cette variable en une variable num\u00e9rique, il nous faudra l'analyser dans le module suivant.\n\nAvant de commencer l'analyse des variables num\u00e9riques, nous allons transfomer certains colonnes en type category\n\n","6999f9e2":"**Stats Initiales avant remplacement**\n\ncount    10851.000000\n\nmean         3.919106\n\nstd          1.501822\n\nmin          1.000000\n\n25%          3.000000\n\n50%          4.000000\n\n75%          5.000000\n\nmax          8.000000\n\n# 8. Analyse bivari\u00e9e <a id=\"8\"><\/a>\n\nL'analyse bivari\u00e9e tente de trouver la relation entre deux variables. Nous rechercherons une corr\u00e9lation ou une association entre notre variable pr\u00e9dictive et notre variable cible. L'analyse bivari\u00e9e est effectu\u00e9e pour toute combinaison de variables cat\u00e9gorielles et num\u00e9riques. La combinaison peut l'\u00eatre : Num\u00e9rique & Num\u00e9rique, Num\u00e9rique & Cat\u00e9gorique et Cat\u00e9gorique & Cat\u00e9gorique. Diff\u00e9rentes m\u00e9thodes sont utilis\u00e9es pour aborder ces combinaisons au cours du processus d'analyse. Les m\u00e9thodes sont :\n\n    Num\u00e9rique & Num\u00e9rique : Corr\u00e9lation de Pearson, ou corr\u00e9lation de Spearman (ne n\u00e9cessite pas une distribution normale).\n    Num\u00e9rique & Cat\u00e9gorie : Corr\u00e9lation bis\u00e9riale ponctuelle (seulement si la variable cat\u00e9gorielle est de type binaire), ou test ANOVA. Pour ce probl\u00e8me, vous pouvez utiliser la corr\u00e9lation bis\u00e9riale ou ANOVA. Mais je vais faire les deux tests juste pour vous apprendre parce que ANOVA sera utile si la variable cat\u00e9gorielle a plus de deux groupes.\n    Cat\u00e9gorie & Cat\u00e9gorie : Nous utiliserions le test du Khi-deux pour l'analyse bivari\u00e9e entre variables cat\u00e9gorielles.\n\n\n## 8.1 Variables num\u00e9riques et cat\u00e9gorielles <a id=\"8.1\"><\/a>\n\nTout d'abord, nous cr\u00e9ons un boxplot entre nos variables num\u00e9riques et cat\u00e9gorielles pour v\u00e9rifier si la distribution des variables num\u00e9riques est distincte dans diff\u00e9rentes classes de variables nominales. Ensuite, nous trouvons la moyenne des variables num\u00e9riques pour chaque classe de variables cat\u00e9gorielles. Encore une fois, nous tra\u00e7ons un histogramme de variable num\u00e9rique pour chaque classe de variable cat\u00e9gorielle. Enfin, on calcule une corr\u00e9lation anova ou biserial (dans le cas de deux variables cat\u00e9gorielles de classe) pour trouver une association entre les variables nominales et num\u00e9riques.\n\n"}}