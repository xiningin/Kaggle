{"cell_type":{"752e8df7":"code","c1e50cbc":"code","774d522c":"code","4e0aed70":"code","15822c40":"code","c199ec65":"code","b72f811a":"code","f8cab5ad":"code","36300c43":"code","9ee398cd":"code","be8429b5":"code","5d74dd6d":"code","fe3e7388":"code","e0072a7a":"code","0028a3bc":"code","80213b4f":"code","df8d9e80":"code","c1d649c8":"code","412d1dfd":"code","b0b4ebf4":"code","c20d82d5":"code","6c905291":"code","8e7c8266":"code","af50619d":"code","b24ac818":"code","987e66fa":"code","d6343ae9":"code","f1e4d874":"code","910c9a12":"code","6ec34b6d":"code","41a12120":"code","8be27f94":"code","cae0f56b":"code","0574a8d7":"code","1ee78312":"code","48c5d6f3":"code","829bb452":"code","0dd3e2aa":"code","b14269af":"code","da610909":"code","4e0a698b":"code","e7548194":"code","516ddbae":"code","96a321c9":"code","b5dfe5f7":"code","98148271":"code","6930df7a":"code","192fb1af":"code","736dfb77":"code","709770a0":"markdown","8481edc4":"markdown","91bb6faa":"markdown","3681e0f2":"markdown","5c672fdc":"markdown","5871d977":"markdown","542e3064":"markdown","f560dce0":"markdown","28690fb5":"markdown","f426cbda":"markdown","bff5564b":"markdown","ecface7e":"markdown","c921ff66":"markdown","12ef5684":"markdown","f9d10756":"markdown","1b298a00":"markdown","ca077fa1":"markdown","ff612e94":"markdown","caf4274c":"markdown","a3a7a856":"markdown","928f74be":"markdown","40068149":"markdown","659a4b16":"markdown","969a3b72":"markdown","30d2debe":"markdown","2ef496b4":"markdown","07fc8122":"markdown","f74aa0c4":"markdown","e484984a":"markdown","ceae9d0a":"markdown","449d3b1c":"markdown","aab3558c":"markdown","07dce7cf":"markdown","f9b81461":"markdown","3f6abc10":"markdown","de058bbc":"markdown","81e0aad8":"markdown","57fc687f":"markdown","7f8e21bb":"markdown","da03ea09":"markdown","50591dc2":"markdown","e1473f4a":"markdown","450ae6b5":"markdown"},"source":{"752e8df7":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# it's a library that we work with plotly\nimport plotly.offline as py \npy.init_notebook_mode(connected=True)                  # this code, allow us to work with offline plotly version\nimport plotly.graph_objs as go                         # it's like \"plt\" of matplot\nimport plotly.tools as tls                             # It's useful to we get some tools of plotly\nfrom collections import Counter                        # To do counter of some features\nimport plotly.figure_factory as ff\n\n\n\n\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV                                         # to split the data\nfrom sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix, classification_report, fbeta_score     # to evaluate our model\n\n# Algorithmns models to be compared\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\n\nimport warnings\n\nfrom sklearn.exceptions import ConvergenceWarning\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n\npd.pandas.set_option('display.max_columns', None)\npd.set_option('display.float_format', lambda x: '%.3f' % x)\n\nprint(14 * \" >\", \"\\t n.B.a. \\t\", \"< \" * 14, \"\\n\\n\\n\")","c1e50cbc":"df = pd.read_csv(\"..\/input\/german-credit-data-with-risk\/german_credit_data.csv\", index_col=0)\ndf.head()","774d522c":"df.isnull().sum()","4e0aed70":"df.info()","15822c40":"cat_cols = [col for col in df.columns if df[col].dtypes == 'O']\n\nfor col in cat_cols:\n    print(df[col].value_counts(), \"\\n\\n\")","c199ec65":"trace0 = go.Bar(\n            x = df[df[\"Risk\"]== 'good'][\"Risk\"].value_counts().index.values,\n            y = df[df[\"Risk\"]== 'good'][\"Risk\"].value_counts().values,\n            name='Good credit')\n\ntrace1 = go.Bar(\n            x = df[df[\"Risk\"]== 'bad'][\"Risk\"].value_counts().index.values,\n            y = df[df[\"Risk\"]== 'bad'][\"Risk\"].value_counts().values,\n            name='Bad credit')\n\n\ndata = [trace0, trace1]\nlayout = go.Layout(\n    yaxis=dict(\n        title='Count'\n    ),\n    xaxis=dict(\n        title='Risk Variable'\n    ),\n    title='Target variable distribution'\n)\n\nfig = go.Figure(data=data, layout=layout)\nfig.data[0].marker.line.width = 4\nfig.data[0].marker.line.color = \"black\"\nfig.data[1].marker.line.width = 4\nfig.data[1].marker.line.color = \"black\"\npy.iplot(fig, filename='grouped-bar')","b72f811a":"num_cols = [col for col in df.columns if df[col].dtypes != 'O' and col not in \"Id\"]\nprint('Number of Numerical Variable: ', len(num_cols))\n\n\ndef hist_for_nums(data, numeric_cols):\n    col_counter = 0\n    data = data.copy()\n    for col in numeric_cols:\n        data[col].plot.hist(alpha=0.5, color='y')\n        plt.xlabel(col)\n        plt.title(col)\n        plt.show()\n        col_counter += 1\n    print(col_counter, \"variables have been plotted\")\n\n\nhist_for_nums(df, num_cols)","f8cab5ad":"df_good = df.loc[df[\"Risk\"] == 'good']['Age'].values.tolist()\ndf_bad = df.loc[df[\"Risk\"] == 'bad']['Age'].values.tolist()\ndf_age = df['Age'].values.tolist()\n\n#First plot\ntrace0 = go.Histogram(\n    x=df_good,\n    histnorm='probability',\n    name=\"Good Credit\"\n)\n#Second plot\ntrace1 = go.Histogram(\n    x=df_bad,\n    histnorm='probability',\n    name=\"Bad Credit\"\n)\n#Third plot\ntrace2 = go.Histogram(\n    x=df_age,\n    histnorm='probability',\n    name=\"Overall Age\"\n)\n\n#Creating the grid\nfig = tls.make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n                          subplot_titles=('Good','Bad', 'General Distribuition'))\n\n#setting the figs\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 1, 2)\nfig.append_trace(trace2, 2, 1)\n\nfig['layout'].update(showlegend=True, title='Age Distribuition', bargap=0.05)\npy.iplot(fig, filename='custom-sized-subplot-with-subplot-titles')","36300c43":"df_good = df[df[\"Risk\"] == 'good']\ndf_bad = df[df[\"Risk\"] == 'bad']\n\nfig, ax = plt.subplots(nrows=2, figsize=(12,8))\nplt.subplots_adjust(hspace = 0.4, top = 0.8)\n\ng1 = sns.distplot(df_good[\"Age\"], ax=ax[0], \n             color=\"g\")\ng1 = sns.distplot(df_bad[\"Age\"], ax=ax[0], \n             color='r')\ng1.set_title(\"Age Distribuition\", fontsize=15)\ng1.set_xlabel(\"Age\")\ng1.set_xlabel(\"Frequency\")\n\ng2 = sns.countplot(x=\"Age\",data=df, \n              palette=\"hls\", ax=ax[1], \n              hue = \"Risk\")\ng2.set_title(\"Age Counting by Risk\", fontsize=15)\ng2.set_xlabel(\"Age\")\ng2.set_xlabel(\"Count\")\nplt.show()","9ee398cd":"#Let's look the Credit Amount column\ninterval = (18, 25, 35, 60, 120)\n\ncats = ['Student', 'Young', 'Adult', 'Senior']\ndf[\"Age_cat\"] = pd.cut(df.Age, interval, labels=cats)\n\n# And let's re-create \"df_bad\" dataframes with \"df_good\" we created.\ndf_good = df[df[\"Risk\"] == 'good']\ndf_bad = df[df[\"Risk\"] == 'bad']","be8429b5":"trace0 = go.Box(\n    y=df_good[\"Credit amount\"],\n    x=df_good[\"Age_cat\"],\n    name='Good credit',\n    marker=dict(\n        color='LightSkyBlue'\n    )\n)\n\ntrace1 = go.Box(\n    y=df_bad['Credit amount'],\n    x=df_bad['Age_cat'],\n    name='Bad credit',\n    marker=dict(\n        color='DarkSlateGrey'\n    )\n)\n    \ndata = [trace0, trace1]\n\nlayout = go.Layout(\n    yaxis=dict(\n        title='Credit Amount (US Dollar)',\n        zeroline=False\n    ),\n    xaxis=dict(\n        title='Age Categorical'\n    ),\n    boxmode='group'\n)\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig, filename='box-age-cat')\n\n","5d74dd6d":"#First plot\ntrace0 = go.Bar(\n    x = df[df[\"Risk\"]== 'good'][\"Housing\"].value_counts().index.values,\n    y = df[df[\"Risk\"]== 'good'][\"Housing\"].value_counts().values,\n    name='Good credit'\n)\n\n#Second plot\ntrace1 = go.Bar(\n    x = df[df[\"Risk\"]== 'bad'][\"Housing\"].value_counts().index.values,\n    y = df[df[\"Risk\"]== 'bad'][\"Housing\"].value_counts().values,\n    name=\"Bad Credit\"\n)\n\ndata = [trace0, trace1]\n\nlayout = go.Layout(\n    title='Housing Distribuition'\n)\n\n\nfig = go.Figure(data=data, layout=layout)\nfig.data[0].marker.line.width = 4\nfig.data[0].marker.line.color = \"black\"\nfig.data[1].marker.line.width = 4\nfig.data[1].marker.line.color = \"black\"\n\npy.iplot(fig, filename='Housing-Grouped')","fe3e7388":"fig = {\n    \"data\": [\n        {\n            \"type\": 'violin',\n            \"x\": df_good['Housing'],\n            \"y\": df_good['Credit amount'],\n            \"legendgroup\": 'Good Credit',\n            \"scalegroup\": 'No',\n            \"name\": 'Good Credit',\n            \"side\": 'negative',\n            \"box\": {\n                \"visible\": True\n            },\n            \"meanline\": {\n                \"visible\": True\n            },\n            \"line\": {\n                \"color\": '#673D43'\n            }\n        },\n        {\n            \"type\": 'violin',\n            \"x\": df_bad['Housing'],\n            \"y\": df_bad['Credit amount'],\n            \"legendgroup\": 'Bad Credit',\n            \"scalegroup\": 'No',\n            \"name\": 'Bad Credit',\n            \"side\": 'positive',\n            \"box\": {\n                \"visible\": True\n            },\n            \"meanline\": {\n                \"visible\": True\n            },\n            \"line\": {\n                \"color\": '#AB9C2B'\n            }\n        }\n    ],\n    \"layout\" : {\n        \"yaxis\": {\n            \"zeroline\": False,\n        },\n        \"violingap\": 0,\n        \"violinmode\": \"overlay\"\n    }\n}\n\n\npy.iplot(fig, filename = 'violin\/split', validate = False)\n\n","e0072a7a":"#First plot\ntrace0 = go.Bar(\n    x = df[df[\"Risk\"]== 'good'][\"Sex\"].value_counts().index.values,\n    y = df[df[\"Risk\"]== 'good'][\"Sex\"].value_counts().values,\n    name='Good credit'\n)\n\n#First plot 2\ntrace1 = go.Bar(\n    x = df[df[\"Risk\"]== 'bad'][\"Sex\"].value_counts().index.values,\n    y = df[df[\"Risk\"]== 'bad'][\"Sex\"].value_counts().values,\n    name=\"Bad Credit\"\n)\n\n#Second plot\ntrace2 = go.Box(\n    x = df[df[\"Risk\"]== 'good'][\"Sex\"],\n    y = df[df[\"Risk\"]== 'good'][\"Credit amount\"],\n    name=trace0.name\n)\n\n#Second plot 2\ntrace3 = go.Box(\n    x = df[df[\"Risk\"]== 'bad'][\"Sex\"],\n    y = df[df[\"Risk\"]== 'bad'][\"Credit amount\"],\n    name=trace1.name\n)\n\ndata = [trace0, trace1, trace2,trace3]\n\nfig = tls.make_subplots(rows=1, cols=2, \n                        subplot_titles=('Sex Count', 'Credit Amount by Sex'))\n\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 1, 1)\nfig.append_trace(trace2, 1, 2)\nfig.append_trace(trace3, 1, 2)\n\nfig['layout'].update(height=400, width=800, title='Sex Distribuition', boxmode='group')\npy.iplot(fig, filename='sex-subplot')","0028a3bc":"#First plot\ntrace0 = go.Bar(\n    x = df[df[\"Risk\"]== 'good'][\"Job\"].value_counts().index.values,\n    y = df[df[\"Risk\"]== 'good'][\"Job\"].value_counts().values,\n    name='Good credit Distribuition'\n)\n\n#Second plot\ntrace1 = go.Bar(\n    x = df[df[\"Risk\"]== 'bad'][\"Job\"].value_counts().index.values,\n    y = df[df[\"Risk\"]== 'bad'][\"Job\"].value_counts().values,\n    name=\"Bad Credit Distribuition\"\n)\n\ndata = [trace0, trace1]\n\nlayout = go.Layout(\n    title='Job Distribuition'\n)\n\nfig = go.Figure(data=data, layout=layout)\nfig.data[0].marker.line.width = 4\nfig.data[0].marker.line.color = \"black\"\nfig.data[1].marker.line.width = 4\nfig.data[1].marker.line.color = \"black\"\npy.iplot(fig, filename='grouped-bar')","80213b4f":"trace0 = go.Box(\n    x=df_good[\"Job\"],\n    y=df_good[\"Credit amount\"],\n    name='Good credit',\n    marker=dict(\n        color='LightSkyBlue')\n)\n\ntrace1 = go.Box(\n    x=df_bad['Job'],\n    y=df_bad['Credit amount'],\n    name='Bad credit',\n    marker=dict(\n        color='DarkSlateGrey')\n)\n    \ndata = [trace0, trace1]\n\nlayout = go.Layout(\n    yaxis=dict(\n        title='Credit Amount distribuition by Job',\n        zeroline=False\n    ),\n    xaxis=dict(\n        title='Age Categorical'\n    ),\n    boxmode='group'\n)\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig, filename='box-age-cat')\n\n\n","df8d9e80":"fig = {\n    \"data\": [\n        {\n            \"type\": 'violin',\n            \"x\": df_good['Job'],\n            \"y\": df_good['Age'],\n            \"legendgroup\": 'Good Credit',\n            \"scalegroup\": 'No',\n            \"name\": 'Good Credit',\n            \"side\": 'negative',\n            \"box\": {\n                \"visible\": True\n            },\n            \"meanline\": {\n                \"visible\": True\n            },\n            \"line\": {\n                \"color\": '#673D43'\n            }\n        },\n        {\n            \"type\": 'violin',\n            \"x\": df_bad['Job'],\n            \"y\": df_bad['Age'],\n            \"legendgroup\": 'Bad Credit',\n            \"scalegroup\": 'No',\n            \"name\": 'Bad Credit',\n            \"side\": 'positive',\n            \"box\": {\n                \"visible\": True\n            },\n            \"meanline\": {\n                \"visible\": True\n            },\n            \"line\": {\n                \"color\": 'green'\n            }\n        }\n    ],\n    \"layout\" : {\n        \"yaxis\": {\n            \"zeroline\": False,\n        },\n        \"violingap\": 0,\n        \"violinmode\": \"overlay\"\n    }\n}\n\n\npy.iplot(fig, filename = 'Age-Housing', validate = False)","c1d649c8":"fig, ax = plt.subplots(figsize=(12,12), nrows=2)\n\ng1 = sns.boxplot(x=\"Job\", y=\"Credit amount\", data=df, \n            palette=\"husl\", ax=ax[0], hue=\"Risk\")\ng1.set_title(\"Credit Amount by Job\", fontsize=15)\ng1.set_xlabel(\"Job Reference\", fontsize=12)\ng1.set_ylabel(\"Credit Amount\", fontsize=12)\n\ng2 = sns.violinplot(x=\"Job\", y=\"Age\", data=df, ax=ax[1],  \n               hue=\"Risk\", split=True, palette=\"Blues\")\ng2.set_title(\"Job Type reference x Age\", fontsize=15)\ng2.set_xlabel(\"Job Reference\", fontsize=12)\ng2.set_ylabel(\"Age\", fontsize=12)\n\nplt.subplots_adjust(hspace = 0.4,top = 0.9)\n\nplt.show()\n\n","412d1dfd":"# Add histogram data\nx1 = np.log(df_good['Credit amount']) \nx2 = np.log(df_bad[\"Credit amount\"])\n\n# Group data together\nhist_data = [x1, x2]\n\ngroup_labels = ['Good Credit', 'Bad Credit']\ncolors = ['rgb(0, 0, 100)', 'rgb(0, 200, 200)']\n\n# Create distplot with custom bin_size\nfig = ff.create_distplot(hist_data, group_labels, bin_size=.1, colors=colors)\n\n# Plot!\npy.iplot(fig, filename='Distplot with Multiple Datasets')","b0b4ebf4":"#Ploting the good and bad dataframes in distplot\nplt.figure(figsize = (8,5))\n\ng= sns.distplot(df_good['Credit amount'], color='y')\ng = sns.distplot(df_bad[\"Credit amount\"], color='g')\ng.set_title(\"Credit Amount Frequency distribuition\", fontsize=18)\nplt.show()","c20d82d5":"count_good = go.Bar(\n    x = df_good[\"Saving accounts\"].value_counts().index.values,\n    y = df_good[\"Saving accounts\"].value_counts().values,\n    name='Good credit'\n)\ncount_bad = go.Bar(\n    x = df_bad[\"Saving accounts\"].value_counts().index.values,\n    y = df_bad[\"Saving accounts\"].value_counts().values,\n    name='Bad credit'\n)\n\n\nbox_1 = go.Box(\n    x=df_good[\"Saving accounts\"],\n    y=df_good[\"Credit amount\"],\n    name='Good credit'\n)\nbox_2 = go.Box(\n    x=df_bad[\"Saving accounts\"],\n    y=df_bad[\"Credit amount\"],\n    name='Bad credit'\n)\n\nscat_1 = go.Box(\n    x=df_good[\"Saving accounts\"],\n    y=df_good[\"Age\"],\n    name='Good credit'\n)\nscat_2 = go.Box(\n    x=df_bad[\"Saving accounts\"],\n    y=df_bad[\"Age\"],\n    name='Bad credit'\n)\n\ndata = [scat_1, scat_2, box_1, box_2, count_good, count_bad]\n\nfig = tls.make_subplots(rows=2, cols=2, specs=[[{}, {}], [{'colspan': 2}, None]],\n                          subplot_titles=('Count Saving Accounts','Credit Amount by Savings Acc', \n                                          'Age by Saving accounts'))\n\nfig.append_trace(count_good, 1, 1)\nfig.append_trace(count_bad, 1, 1)\n\nfig.append_trace(box_2, 1, 2)\nfig.append_trace(box_1, 1, 2)\n\nfig.append_trace(scat_1, 2, 1)\nfig.append_trace(scat_2, 2, 1)\n\n\n\nfig['layout'].update(height=700, width=800, title='Saving Accounts Exploration', boxmode='group')\n\npy.iplot(fig, filename='combined-savings')","6c905291":"print(\"Description of Distribuition Saving accounts by Risk:  \")\nprint(pd.crosstab(df[\"Saving accounts\"],df.Risk))\n\nfig, ax = plt.subplots(3,1, figsize=(12,12))\ng = sns.countplot(x=\"Saving accounts\", data=df, palette=\"husl\", \n              ax=ax[0],hue=\"Risk\")\ng.set_title(\"Saving Accounts Count\", fontsize=15)\ng.set_xlabel(\"Saving Accounts type\", fontsize=12)\ng.set_ylabel(\"Count\", fontsize=12)\n\ng1 = sns.violinplot(x=\"Saving accounts\", y=\"Job\", data=df, palette=\"Blues\", \n               hue = \"Risk\", ax=ax[1],split=True)\ng1.set_title(\"Saving Accounts by Job\", fontsize=15)\ng1.set_xlabel(\"Savings Accounts type\", fontsize=12)\ng1.set_ylabel(\"Job\", fontsize=12)\n\ng = sns.boxplot(x=\"Saving accounts\", y=\"Credit amount\", data=df, ax=ax[2],\n            hue = \"Risk\",palette=\"pastel\")\ng2.set_title(\"Saving Accounts by Credit Amount\", fontsize=15)\ng2.set_xlabel(\"Savings Accounts type\", fontsize=12)\ng2.set_ylabel(\"Credit Amount(US)\", fontsize=12)\n\nplt.subplots_adjust(hspace = 0.4,top = 0.9)\n\nplt.show()","8e7c8266":"print(\"Values describe: \")\nprint(pd.crosstab(df.Purpose, df.Risk))\n\nplt.figure(figsize = (14,12))\n\nplt.subplot(221)\ng = sns.countplot(x=\"Purpose\", data=df, \n              palette=\"husl\", hue = \"Risk\")\ng.set_xticklabels(g.get_xticklabels(),rotation=45)\ng.set_xlabel(\"\", fontsize=12)\ng.set_ylabel(\"Count\", fontsize=12)\ng.set_title(\"Purposes Count\", fontsize=20)\n\nplt.subplot(222)\ng1 = sns.violinplot(x=\"Purpose\", y=\"Age\", data=df, \n                    palette=\"Blues\", hue = \"Risk\",split=True)\ng1.set_xticklabels(g1.get_xticklabels(),rotation=45)\ng1.set_xlabel(\"\", fontsize=12)\ng1.set_ylabel(\"Count\", fontsize=12)\ng1.set_title(\"Purposes by Age\", fontsize=20)\n\nplt.subplot(212)\ng2 = sns.boxplot(x=\"Purpose\", y=\"Credit amount\", data=df, \n               palette=\"Set2\", hue = \"Risk\")\ng2.set_xlabel(\"Purposes\", fontsize=12)\ng2.set_ylabel(\"Credit Amount\", fontsize=12)\ng2.set_title(\"Credit Amount distribuition by Purposes\", fontsize=20)\n\nplt.subplots_adjust(hspace = 0.6, top = 0.8)\n\nplt.show()","af50619d":"\n\nplt.figure(figsize = (12,14))\n\ng= plt.subplot(311)\ng = sns.countplot(x=\"Duration\", data=df, \n              palette=\"husl\",  hue = \"Risk\")\ng.set_xlabel(\"Duration Distribuition\", fontsize=12)\ng.set_ylabel(\"Count\", fontsize=12)\ng.set_title(\"Duration Count\", fontsize=20)\n\ng1 = plt.subplot(312)\ng1 = sns.pointplot(x=\"Duration\", y =\"Credit amount\",data=df,\n                   hue=\"Risk\", palette=\"Set2\")\ng1.set_xlabel(\"Duration\", fontsize=12)\ng1.set_ylabel(\"Credit Amount(US)\", fontsize=12)\ng1.set_title(\"Credit Amount distribuition by Duration\", fontsize=20)\n\ng2 = plt.subplot(313)\ng2 = sns.distplot(df_good[\"Duration\"], color='y')\ng2 = sns.distplot(df_bad[\"Duration\"], color='b')\ng2.set_xlabel(\"Duration\", fontsize=12)\ng2.set_ylabel(\"Frequency\", fontsize=12)\ng2.set_title(\"Duration Frequency x good and bad Credit\", fontsize=20)\n\nplt.subplots_adjust(wspace = 0.4, hspace = 0.4,top = 0.9)\n\nplt.show()\n\n","b24ac818":"#First plot\ntrace0 = go.Bar(\n    x = df[df[\"Risk\"]== 'good'][\"Checking account\"].value_counts().index.values,\n    y = df[df[\"Risk\"]== 'good'][\"Checking account\"].value_counts().values,\n    name='Good credit Distribuition' \n    \n)\n\n#Second plot\ntrace1 = go.Bar(\n    x = df[df[\"Risk\"]== 'bad'][\"Checking account\"].value_counts().index.values,\n    y = df[df[\"Risk\"]== 'bad'][\"Checking account\"].value_counts().values,\n    name=\"Bad Credit Distribuition\"\n)\n\ndata = [trace0, trace1]\n\nlayout = go.Layout(\n    title='Checking accounts Distribuition',\n    xaxis=dict(title='Checking accounts name'),\n    yaxis=dict(title='Count'),\n    barmode='group'\n)\n\n\nfig = go.Figure(data=data, layout=layout)\nfig.data[0].marker.line.width = 4\nfig.data[0].marker.line.color = \"black\"\nfig.data[1].marker.line.width = 4\nfig.data[1].marker.line.color = \"black\"\npy.iplot(fig, filename = 'Age-ba', validate = False)","987e66fa":"df_good = df[df[\"Risk\"] == 'good']\ndf_bad = df[df[\"Risk\"] == 'bad']\n\ntrace0 = go.Box(\n    y=df_good[\"Credit amount\"],\n    x=df_good[\"Checking account\"],\n    name='Good credit'\n)\n\ntrace1 = go.Box(\n    y=df_bad['Credit amount'],\n    x=df_bad['Checking account'],\n    name='Bad credit'\n    \n)\n    \ndata = [trace0, trace1]\n\nlayout = go.Layout(\n    yaxis=dict(\n        title='Cheking distribuition'\n    ),\n    boxmode='group'\n)\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig, filename='box-age-cat')","d6343ae9":"print(\"Total values of the most missing variable: \")\nprint(df.groupby(\"Checking account\")[\"Checking account\"].count())\n\nplt.figure(figsize = (12,10))\n\ng = plt.subplot(221)\ng = sns.countplot(x=\"Checking account\", data=df, \n              palette=\"husl\", hue=\"Risk\")\ng.set_xlabel(\"Checking Account\", fontsize=12)\ng.set_ylabel(\"Count\", fontsize=12)\ng.set_title(\"Checking Account Counting by Risk\", fontsize=20)\n\ng1 = plt.subplot(222)\ng1 = sns.violinplot(x=\"Checking account\", y=\"Age\", data=df, palette=\"Set2\", hue = \"Risk\",split=True)\ng1.set_xlabel(\"Checking Account\", fontsize=12)\ng1.set_ylabel(\"Age\", fontsize=12)\ng1.set_title(\"Age by Checking Account\", fontsize=20)\n\ng2 = plt.subplot(212)\ng2 = sns.boxplot(x=\"Checking account\",y=\"Credit amount\", data=df,hue='Risk',palette=\"pastel\")\ng2.set_xlabel(\"Checking Account\", fontsize=12)\ng2.set_ylabel(\"Credit Amount(US)\", fontsize=12)\ng2.set_title(\"Credit Amount by Cheking Account\", fontsize=20)\n\nplt.subplots_adjust(wspace = 0.2, hspace = 0.3, top = 0.9)\n\nplt.show()\nplt.show()","f1e4d874":"plt.figure(figsize = (10,6))\n\ng = sns.violinplot(x=\"Housing\",y=\"Job\",data=df,\n                   hue=\"Risk\", palette=\"deep\", as_cmap=True, split=True)\ng.set_xlabel(\"Housing\", fontsize=12)\ng.set_ylabel(\"Job\", fontsize=12)\ng.set_title(\"Housing x Job - Dist\", fontsize=20)\n\nplt.show()","910c9a12":"\nprint(\"Job status by gender\", pd.crosstab(df.Sex, df.Job), sep=\"\\n\\n\")\n\n\nprint(\"\\n\\n\\nAccount status by gender\\n\\n\", pd.crosstab(df[\"Checking account\"],df.Sex))","6ec34b6d":"date_int = [\"Purpose\", 'Sex']\n#cm = sns.light_palette(\"green\", as_cmap=True)\npd.crosstab(df[date_int[0]], df[date_int[1]]).style.background_gradient(cmap = \"viridis\")","41a12120":"def missing_values_table(dataframe):\n    variables_with_na = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n    n_miss = dataframe[variables_with_na].isnull().sum().sort_values(ascending=False)\n    ratio = (dataframe[variables_with_na].isnull().sum() \/ dataframe.shape[0] * 100).sort_values(ascending=False)\n    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])\n    print(missing_df)\n    return variables_with_na\n\n\nmissing_values_table(df)","8be27f94":"#Filling missing values with mode\ndf[\"Saving accounts\"].fillna(df['Saving accounts'].mode()[0], inplace=True)\ndf[\"Checking account\"].fillna(df['Checking account'].mode()[0], inplace=True)","cae0f56b":"def outlier_thresholds(dataframe, variable):\n    quartile1 = dataframe[variable].quantile(0.25)\n    quartile3 = dataframe[variable].quantile(0.75)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n\n\ndef has_outliers(dataframe, num_col_names, plot=False):\n    variable_names = []\n    for col in num_col_names:\n        low_limit, up_limit = outlier_thresholds(dataframe, col)\n        if dataframe[(dataframe[col] > up_limit) | (dataframe[col] < low_limit)].any(axis=None):\n            number_of_outliers = dataframe[(dataframe[col] > up_limit) | (dataframe[col] < low_limit)].shape[0]\n            print(col, \":\", number_of_outliers)\n            variable_names.append(col)\n            if plot:\n                sns.boxplot(x=dataframe[col])\n                plt.show()\n    return variable_names\n\n\nhas_outliers(df, num_cols)","0574a8d7":"def replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n\n\nfor col in num_cols:\n    replace_with_thresholds(df, col)\n\nhas_outliers(df, num_cols)","1ee78312":"df.head()","48c5d6f3":"df[\"Risk\"].value_counts()","829bb452":"# cat_cols = [col for col in df.columns if df[col].dtypes == 'O']\n\n\n# def one_hot_encoder(dataframe, categorical_cols, nan_as_category=True):\n#     original_columns = list(dataframe.columns)\n#     dataframe = pd.get_dummies(dataframe, columns=categorical_cols, dummy_na=nan_as_category, drop_first=True)\n#     new_columns = [c for c in dataframe.columns if c not in original_columns]\n#     return dataframe, new_columns\n\n\n# df, new_cols_ohe = one_hot_encoder(df, cat_cols)","0dd3e2aa":"#Purpose to Dummies Variable\ndf = df.merge(pd.get_dummies(df.Purpose, drop_first=True, prefix='Purpose'), left_index=True, right_index=True)\n#Sex feature in dummies\ndf = df.merge(pd.get_dummies(df.Sex, drop_first=True, prefix='Sex'), left_index=True, right_index=True)\n# Housing get dummies\ndf = df.merge(pd.get_dummies(df.Housing, drop_first=True, prefix='Housing'), left_index=True, right_index=True)\n# Housing get Saving Accounts\ndf = df.merge(pd.get_dummies(df[\"Saving accounts\"], drop_first=True, prefix='Savings'), left_index=True, right_index=True)\n# Housing get Risk\ndf = df.merge(pd.get_dummies(df.Risk, prefix='Risk'), left_index=True, right_index=True)\n# Housing get Checking Account\ndf = df.merge(pd.get_dummies(df[\"Checking account\"], drop_first=True, prefix='Check'), left_index=True, right_index=True)\n# Housing get Age categorical\ndf = df.merge(pd.get_dummies(df[\"Age_cat\"], drop_first=True, prefix='Age_cat'), left_index=True, right_index=True)","b14269af":"droplist=[\"Sex\",\"Housing\",\"Saving accounts\",\"Checking account\",\"Purpose\",\"Risk\",\"Risk_good\",\"Age_cat\"]\n\ndf.drop(droplist, axis= 1, inplace = True)","da610909":"like_num = [col for col in df.columns if df[col].dtypes != 'O' and len(df[col].value_counts()) < 20]\n\n\ncols_need_scale = [col for col in df.columns if col not in \"Id\"\n                   and col not in \"Risk\"\n                   and col not in like_num]\n\ndf[cols_need_scale].head()\ndf[cols_need_scale].describe([0.05, 0.10, 0.25, 0.50, 0.75, 0.80, 0.90, 0.95, 0.99]).T\nhist_for_nums(df, cols_need_scale)\n\n\ndef robust_scaler(variable):\n    var_median = variable.median()\n    quartile1 = variable.quantile(0.25)\n    quartile3 = variable.quantile(0.75)\n    interquantile_range = quartile3 - quartile1\n    if int(interquantile_range) == 0:\n        quartile1 = variable.quantile(0.05)\n        quartile3 = variable.quantile(0.95)\n        interquantile_range = quartile3 - quartile1\n        z = (variable - var_median) \/ interquantile_range\n        return round(z, 3)\n    else:\n        z = (variable - var_median) \/ interquantile_range\n    return round(z, 3)\n\n\nfor col in cols_need_scale:\n    df[col] = robust_scaler(df[col])\n\n\ndf[cols_need_scale].head()\ndf[cols_need_scale].describe().T\nhist_for_nums(df, cols_need_scale)\n\n","4e0a698b":"plt.figure(figsize=(20,13))\nsns.heatmap(df.corr(),\n            cmap='coolwarm',\n            annot=True,\n            fmt=\".2f\",\n            annot_kws={'size':16},\n            cbar=False)\n","e7548194":"#Creating the X and y variables\nX = df.drop('Risk_bad', 1).values\ny = df[\"Risk_bad\"].values\n\n# Spliting X and y into train and test version\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=42)","516ddbae":"# to feed the random state\nseed = 7\n\n# prepare models\nmodels = []\n# models.append(('LR', LinearRegression()))\n# models.append(('RDR', Ridge()))\n# models.append(('LSSR', Lasso()))\n# models.append(('ER', ElasticNet()))\nmodels.append(('LGR', LogisticRegression()))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('RF', RandomForestClassifier()))\nmodels.append(('SVM', SVC(gamma='auto')))\nmodels.append(('XGBM', XGBClassifier()))\nmodels.append(('LGBM', LGBMClassifier()))\n\n\n# evaluate each model in turn\nresults = []\nnames = []\nscoring = 'recall'\n\nfor name, model in models:\n        kfold = KFold(n_splits=10, random_state=seed)\n        cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n        results.append(cv_results)\n        names.append(name)\n        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n        print(msg)\n        \n# boxplot algorithm comparison\nfig = plt.figure(figsize=(11,6))\nfig.suptitle('Algorithms Compare')\nax = fig.add_subplot(111)\ngreen_diamond = dict(markerfacecolor='g', marker='D')\nplt.boxplot(results, flierprops=green_diamond, patch_artist=True)\nax.set_xticklabels(names)\nplt.show()","96a321c9":"from sklearn.utils import resample\nfrom sklearn.metrics import roc_curve\n\nGNB = GaussianNB()\n\n# Fitting with train data\nmodel = GNB.fit(X_train, y_train)\n\nprint(\"Primitive error evaluation accuracy score: \", model.score(X_train, y_train))\n\ny_pred = model.predict(X_test)\n\nprint(\"Test predict accuracy score: \", accuracy_score(y_test,y_pred),\"\\n\")\n\nprint(\"Confussion Matrix: \\n\", confusion_matrix(y_test, y_pred),\"\\n\")\n\nprint(\"Classification report according to Test prediction: \\n\", classification_report(y_test, y_pred))\n","b5dfe5f7":"#Predicting proba\ny_pred_prob = model.predict_proba(X_test)[:,1]\n\n# Generate ROC curve values: fpr, tpr, thresholds\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n\n# Plot ROC curve\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr)\nplt.xlabel('False Positive Rate', color=\"r\")\nplt.ylabel('True Positive Rate', color=\"g\")\nplt.title('ROC Curve')\nplt.show()","98148271":"xgb = XGBClassifier(random_state = 12345)\n\nxgb_params = {\n    \"learning_rate\": [0.01, 0.1, 0.2, 1],\n    \"min_samples_split\": np.linspace(0.1, 0.5, 10),\n    \"max_depth\":[3,5,8],\n    \"subsample\":[0.5, 0.9, 1.0],\n    \"n_estimators\": [100,1000]}\n\nxgb_cv_model  = GridSearchCV(xgb,xgb_params, cv = 5, n_jobs = -1, verbose = 2).fit(X, y)    # i did cv=5 this is not enough and this is for faster estimate\n\nxgb_tuned = XGBClassifier(**xgb_cv_model.best_params_).fit(X,y)\ncross_val_score(xgb_tuned, X, y, cv = 10).mean()","6930df7a":"# model tuning\n\nlgbm = LGBMClassifier()\nlgbm_params = {\"learning_rate\": [0.01, 0.03, 0.05, 0.1, 0.5],\n               \"n_estimators\": [500, 1000, 1500],\n               \"max_depth\": [3,5,8]}\n\n#GridSearchCV method\ngs_cv = GridSearchCV(lgbm,\n                     lgbm_params,\n                     cv=5,                                  # i did cv=5 this is not enough and this is for faster estimate\n                     n_jobs=-1,\n                     verbose=2).fit(X_train, y_train)\n\n#En iyi parametrelerle model kurma\nlgbm_tuned = LGBMClassifier(**gs_cv.best_params_).fit(X, y)\ncross_val_score(lgbm_tuned, X_test, y_test, cv=10).mean()\n\n#cv islemleri(caprazlama)\nkfold = KFold(n_splits=10, random_state=123456)\ncv_results = cross_val_score(LGBMClassifier(), X_train, y_train, cv=kfold, scoring=\"accuracy\")\ncv_results.mean()","192fb1af":"from sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import SelectKBest\n\n\nfeatures = []\nfeatures.append(('PCA', PCA(n_components=2)))\nfeatures.append(('Select_best', SelectKBest(k=6)))\nfeature_union = FeatureUnion(features)\n\n# create pipeline\nestimators = []\nestimators.append(('Feature_union', feature_union))\nestimators.append(('Logistic_regression', LogisticRegression()))\nmodel = Pipeline(estimators)\n\n# evaluate pipeline\nseed = 7\nkfold = KFold(n_splits=10, random_state=seed)\nresults = cross_val_score(model, X_train, y_train, cv=kfold)\nprint(results.mean())","736dfb77":"model.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\nprint(\"Test predict accuracy score: {:.2f}\".format(accuracy_score(y_test,y_pred)),\"\\n\")\n\nprint(\"Confussion Matrix: \\n\", confusion_matrix(y_test, y_pred),\"\\n\")\n\nprint(\"Weighted harmonic mean of precision according to Test prediction: \", fbeta_score(y_test, y_pred, beta=2))","709770a0":"Let's drop categorical and at the same time old variables.","8481edc4":"The Naive Bayes, Decision Tree, LightGBM and XGBoost models are seen as the best methods. Let's subject them to hyperparameter optimization using the verification method one by one.\n\n### 4.1. Gaussian Naive Bayes Model","91bb6faa":"See relation between:\n- Credit Amount by Job, \n- Job Reference, \n- Credit Amount,\n- Job Type reference by Age,\n- Job Reference","3681e0f2":"### 4.3. LightGBM Model","5c672fdc":"# 2. EDA (Exploratory of Data Analysis)\n## 2.1. Data Preperation","5871d977":"### The distribution of having a job with hosting:","542e3064":"### Distribuition of Credit Amount by Housing visualization:\n\nFocus on the highest values \u200b\u200bcome from the category of \"free\" and we have a different distribution by Risk.","f560dce0":"Let me explain what is the \"fbeta_score\":\n\n> The F-beta score is the weighted harmonic mean of precision and recall, reaching its optimal value at 1 and its worst value at 0.\n\n> The beta parameter determines the weight of recall in the combined score. beta < 1 lends more weight to precision, while beta > 1 favors recall (beta -> 0 considers only precision, beta -> +inf only recall).\n\n\n\n## 5. Conclusion\n\nWe got different accuracy scores in the all of model estimation evaluation. A very successful modeling has been realized.\nNote:\n\n   - I took advantage of the https:\/\/www.kaggle.com\/kabure\/predicting-credit-risk-model-pipeline\/comments kernel, especially the visuals, but I tried to create a smoother notebook by fixing the problems a lot. But of course I would like to thank him :)\n   - This is also reference notebook https:\/\/www.kaggle.com\/mathchi\/predict-sales-prices-and-practice-feature-engineer\n   \n   - Recommend: If you want to see high accuracy score then try to CV=10.\n   - After this notebook, my aim is to prepare 'kernel' which is 'not clear' data set.\n\n   - If you have any suggestions, please could you write for me? I wil be happy for comment and critics!\n\n   - Thank you for your comment, suggestion and votes ;)\n","28690fb5":"Let's try to see which products they want to buy according to their ages and their quantities.","f426cbda":"## 3.3. Label Encoding & One-Hot Encoding\n\nFirst, observe the Label Encoding & One-Hot Encoding.\n","bff5564b":"Let's check NaN values:","ecface7e":"### Checking Account variable\n\nFirst, let's look the distribuition:","c921ff66":"\n# Data Description\n\n![0.jpg](attachment:0.jpg)\n\n## Context\nThe original dataset contains 1000 entries with 20 categorial\/symbolic attributes prepared by Prof. Hofmann. In this dataset, each entry represents a person who takes a credit by a bank. Each person is classified as good or bad credit risks according to the set of attributes. The link to the original dataset can be found below.\n\n## Content\nIt is almost impossible to understand the original dataset due to its complicated system of categories and symbols. Thus, I wrote a small Python script to convert it into a readable CSV file. Several columns are simply ignored, because in my opinion either they are not important or their descriptions are obscure. The selected attributes are:\n\n- Age (numeric)\n- Sex (text: male, female)\n- Job (numeric: 0 - unskilled and non-resident, 1 - unskilled and resident, 2 - skilled, 3 - highly skilled)\n- Housing (text: own, rent, or free)\n- Saving accounts (text - little, moderate, quite rich, rich)\n- Checking account (numeric, in DM - Deutsch Mark)\n- Credit amount (numeric, in DM)\n- Duration (numeric, in month)\n- Purpose(text: car, furniture\/equipment, radio\/TV, domestic appliances, repairs, education, business, vacation\/others\n- Risk (Value target - Good or Bad Risk)\n\n\n# 1. Installing","12ef5684":"## 4. Modelling","f9d10756":"Let's create age categories and look at the distribution of Loan Amount by Riskand try to do some research on Credit Amount by Age Crossed Work, and Distribution.\n\n### Distribuition","1b298a00":"See 'Target' variable distribution with visual:","ca077fa1":"It can be seen that the \"Age\" variable is very important. Because of the need, I create categorical variables according to the Age variable. And let's re-create df_bad dataframes with df_good we created.","ff612e94":"Lets see together another version:","caf4274c":"Let's visualize it again according to the last created.","a3a7a856":"\n# 3. Data Prepcoressing & Feature Engineering\n## 3.1. Missing Values Analysis","928f74be":"Now, we will verify the values through Checking Accounts","40068149":"### 4.4. Pipeline Method\nSelect features according to the k highest scores and Principal Component Analysis(PCA) then we will apply Logistic Regression with feature union.","659a4b16":"## 3.2. Outliers Analysis","969a3b72":"See together in graphs accordings to Frequency and Count:","30d2debe":"Now, set thresholds(low and up limits) for outliers then use for outliers","2ef496b4":"## 3.5. Correlation and Heatmap Analysis\n\nThen look at the correlations between target and independent variables.","07fc8122":"### 4.2. XGBOOST Model","f74aa0c4":"## 2.2. Numerical Variable Analysis","e484984a":"### Crossed by Credit amount and Age","ceae9d0a":"### Looking the diference by Sex visualization:\n","449d3b1c":"### Distruibution of Saving accounts by Risk:","aab3558c":"Now let's look at the breakdown of Leaseholder and Rent by Risk:","07dce7cf":"### The distribuition of Credit Amont:","f9b81461":"Filling missing values with mode","3f6abc10":"You can use the above method as a secondary method, but let's try to examine it one by one.","de058bbc":"Let's see general version:","81e0aad8":"and check what we have for instance missing value and numeric\/object fature observing:","57fc687f":"Let's illustrate with numbers and crosstab:","7f8e21bb":"## 3.4. Standardization","da03ea09":"Now let's try to perform a merge between variables according to the above.","50591dc2":"### Duration of the credits distribuition and density:\nAs seen, the 12th, 18th and 20th months are the time periods with the highest distribution.","e1473f4a":"### Credit Amount Frequency distribuition:","450ae6b5":"The Naive Bayes model seems to be the best method. Let's see ROC curve for predict probability:"}}