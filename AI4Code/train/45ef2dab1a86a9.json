{"cell_type":{"38281e13":"code","84fc6b0d":"code","3824b95c":"code","d74ec846":"code","e2680233":"code","63b9e9ba":"code","1b822f46":"code","21ef7d92":"code","ec4b02f4":"code","d468eb55":"code","b1c89243":"code","d1bc0db5":"code","414efd70":"code","ebac2c7d":"code","90201e28":"code","c032bf46":"code","ad7bb3fe":"code","66fabf2c":"code","eaf673de":"code","92b3fba8":"code","fc792840":"code","c49c4a81":"code","e19433ac":"code","5b257767":"code","d2f9d230":"code","75b449e9":"code","53ad989c":"code","0e6b895b":"code","20ac4a92":"code","6ca25e22":"code","919b5b59":"code","9e495c9f":"code","d7b33c14":"code","9aa49825":"code","642c04c6":"code","521a8a41":"code","12bbf0c5":"code","0ab6644e":"code","36b7218d":"code","7f07ef97":"code","bef99463":"code","4cf5c560":"code","4d6aad55":"code","f0e18c16":"code","9acb8341":"code","53efcecf":"markdown","c07ea9cd":"markdown","484eb580":"markdown","70465003":"markdown","f1385cb9":"markdown","8a2a8a1e":"markdown","e034f8b0":"markdown","4ad848b7":"markdown","0d927504":"markdown","8ff6de9a":"markdown","a915acd8":"markdown","07311f25":"markdown","51b50a4a":"markdown","2711a28e":"markdown","97036ecd":"markdown","2da744e2":"markdown","dababe09":"markdown","b6b95434":"markdown","22f2fb4e":"markdown","b7cd6a1f":"markdown","e22ecf56":"markdown","b048d4bb":"markdown","13d3e7a4":"markdown","56acf6cb":"markdown","35a0abe5":"markdown"},"source":{"38281e13":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","84fc6b0d":"customers = pd.read_csv(\"..\/input\/customer-clustering\/segmentation data.csv\")","3824b95c":"customers.head()","d74ec846":"customers.info()","e2680233":"customers.describe()","63b9e9ba":"customers = customers.drop(['ID'], axis = 1)","1b822f46":"customers.head()","21ef7d92":"corrs = customers.corr()\nsns.heatmap(corrs, annot=True)","ec4b02f4":"sns.histplot(data=customers,x=customers.Income)","d468eb55":"sns.histplot(data=customers,x=customers.Age)","b1c89243":"plt.figure(figsize=(18,8),num=1)\nm=1\nfor i in customers.drop(['Age','Income'],axis=1).columns:\n    plt.subplot(2,3,m)\n    sns.countplot(x=i,data=customers)\n    m+=1","d1bc0db5":"sns.scatterplot(x=customers.Income,y=customers.Age)","414efd70":"sns.stripplot(x=customers.Education, y=customers.Income)","ebac2c7d":"sns.stripplot(x=customers.Occupation, y=customers.Income)","90201e28":"sns.violinplot(x=customers[\"Settlement size\"], y=customers.Income)","c032bf46":"sns.barplot(x=customers.Occupation, y=customers.Age)","ad7bb3fe":"sns.boxplot(x=customers.Income)","66fabf2c":"sns.kdeplot(\n    data=customers,\n    x=\"Age\",\n    y=\"Income\",\n    hue=\"Sex\",\n    thresh=.1,\n)","eaf673de":"sns.scatterplot(\n     data=customers,\n    x=\"Age\",\n    y=\"Income\",\n    hue=\"Sex\",\n)","92b3fba8":"married = customers.groupby(['Sex','Marital status']).Age.count()\nmarried\n#0 is Male\n#1 is Female","fc792840":"percentage_of_men = 257 \/ (customers[customers.Sex == 0].Sex.count()) * 100\nprint(\"Percentage of men married: \" + str(percentage_of_men.round(1)) + \"%\")\n\npercentage_of_women = 736 \/ (customers[customers.Sex == 1].Sex.count()) * 100\nprint(\"Percentage of women married: \" + str(percentage_of_women.round(1)) + \"%\")\n","c49c4a81":"data=customers[['Age','Income']]\ndata.head()","e19433ac":"#lets tranaform these variables by standardizing them.\n\n#before standardizing\nfig, (ax1,ax2) = plt.subplots(ncols=2,figsize=(6, 5))\n\nax1.set_title('Before Scaling')\nsns.kdeplot(data['Age'], ax=ax1)\nsns.kdeplot(data['Income'], ax=ax2)","5b257767":"#transforming\ncol_names = data.columns\nfeatures = data[col_names]\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler().fit(features.values)\nfeatures = scaler.transform(features.values)\nscaled = pd.DataFrame(features, columns = col_names)\nscaled.head()\n","d2f9d230":"#after transforming\nfig, (ax1,ax2) = plt.subplots(ncols=2,figsize=(6, 5))\nax1.set_title('Before Scaling')\nsns.kdeplot(scaled['Age'], ax=ax1)\nsns.kdeplot(scaled['Income'], ax=ax2)","75b449e9":"from sklearn.cluster import KMeans","53ad989c":"clusters_range=[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]\ninertias=[]\n\nfor c in clusters_range:\n    kmeans=KMeans(n_clusters=c, random_state=0).fit(scaled)\n    inertias.append(kmeans.inertia_)\n\nplt.figure(figsize=(7,7))\nplt.plot(clusters_range,inertias, marker='o')","0e6b895b":"#Using 5 clusters\nkmeans=KMeans(n_clusters=5,random_state=0) \nkmeans.fit(scaled)","20ac4a92":"prediction=kmeans.fit_predict(scaled)\nprediction","6ca25e22":"clustered_data = data.copy()\nclustered_data[\"cluster_index\"] = prediction","919b5b59":"#lets visualise the clusters\nsns.scatterplot(x=clustered_data.Age,\n                y=clustered_data.Income,\n                hue=clustered_data.cluster_index,\n                palette=\"deep\")","9e495c9f":"for i in range(5):\n    average_age = clustered_data[clustered_data.cluster_index == i].Age.mean()\n    average_income = clustered_data[clustered_data.cluster_index == i].Income.mean()\n    average_age = round(average_age,0)\n    average_income = round(average_income,0)\n    print(\"The average age for cluster {} is {}. The average income is {}.\".format(i, average_age, average_income))","d7b33c14":"clustered_data.cluster_index.value_counts()","9aa49825":"customers.head()\ncustomers[['Age', 'Income']] = StandardScaler().fit_transform(customers[['Age', 'Income']])","642c04c6":"customers.head()","521a8a41":"from sklearn.decomposition import PCA\n\n#define PCA model to use\n#7 Variables\npca = PCA(n_components=7)\n\n#fit PCA model to data\npca_fit = pca.fit(customers)","12bbf0c5":"#creating scree plot - taken from statology.com\n\nPC_values = np.arange(pca.n_components_) + 1\nplt.plot(PC_values, pca.explained_variance_ratio_, 'o-', linewidth=2, color='blue')\nplt.title('Scree Plot')\nplt.xlabel('Principal Component')\nplt.ylabel('Variance Explained')\nplt.show()","0ab6644e":"print(pca.explained_variance_ratio_)","36b7218d":"pc = pca.fit_transform(customers)\npca_customers = pd.DataFrame(data = pc, columns = ['PC 1', 'PC 2', 'PC 3', 'PC 4', 'PC 5', 'PC 6','PC 7'])\npca_customers","7f07ef97":"#Choosing the first 4 Principal Components\npca_customers = pca_customers[['PC 1', 'PC 2','PC 3','PC 4']]","bef99463":"clusters_range=[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]\ninertias=[]\n\nfor c in clusters_range:\n    kmeans=KMeans(n_clusters=c, random_state=0).fit(pca_customers)\n    inertias.append(kmeans.inertia_)\n\nplt.figure(figsize=(7,7))\nplt.plot(clusters_range,inertias, marker='o')","4cf5c560":"kmeans=KMeans(n_clusters=5,random_state=0)\nkmeans.fit(pca_customers)","4d6aad55":"prediction_pca = kmeans.fit_predict(pca_customers)\nprediction_pca","f0e18c16":"clustered_data_pca = pca_customers.copy()\nclustered_data_pca[\"cluster_index\"] = prediction_pca\nclustered_data_pca","9acb8341":"sns.scatterplot(x=clustered_data_pca['PC 1'],\n                y=clustered_data_pca['PC 2'],\n                hue=clustered_data.cluster_index,\n                palette=\"deep\")","53efcecf":"**We do not need ID**","c07ea9cd":"**Lets look at clustering now - For the purpose of this cluster I would like to easiy visualise the clustering groups so I will only be clustering on two variables; age and income.**","484eb580":"**Now looking at our categorical variables!**","70465003":"**Going to use 5 clusters again.**","f1385cb9":"# 1. PCA with K-Means","8a2a8a1e":"**Are there any outliers in the income variable?**","e034f8b0":"**Yet again we are going to look at how many clusters we should have using the elbow method**","4ad848b7":"# 1. Reading and understanding the data","0d927504":"# 1. INTERPRETATION","8ff6de9a":"**We are going to use 4 pricipal components - with a a variance threshold of 80% , chosing 4 allows us to have 82%**","a915acd8":"# 1. EDA","07311f25":"**looks like around 5\/6 clusters will be the best**","51b50a4a":"**This data cannot be visualised as it is four dimensions - however for the purpose of just viusalising something we will plot with the frist two dimensions.**","2711a28e":"Going to have some fun with plots","97036ecd":"**We will still standardize our numeric variables**","2da744e2":"# 1. CLUSTERING WITH K-Means","dababe09":"# Customer Clustering - K means & PCA","b6b95434":"**We are going to go go back to using our original customers dataset amnd keep all the variables, we will use Principal Component Analysis to reduce the number of dimensions**","22f2fb4e":"**We are going to standardize these two numeric variables since standardization prevents variables with larger scales from dominating how clusters are defined.**","b7cd6a1f":"**Creating a scree plot to see how many components we should be using, scree plots allow us to see how much each principal components represents of the original data set.**","e22ecf56":"**Note: Both of these look like they could be log transformed**","b048d4bb":"**Visualizing the gender pay-gap with a bivariate kde plot and a scatter plot**","13d3e7a4":"**What percentage of women are married compared to men?**","56acf6cb":"**Using elbow method to test for best clusters**","35a0abe5":"**Lets look at the distributions of our numeric variables**"}}