{"cell_type":{"ae2bbb9d":"code","cde7639d":"code","221b8489":"code","0a38c930":"code","4c918eab":"code","601d367c":"code","67f5b527":"code","6264bb6e":"code","b76bbef2":"code","cdc57961":"code","8404f2c6":"code","2ba2ef38":"code","4352442a":"code","e41ae414":"code","b9d40354":"code","307d1866":"code","321ae23e":"code","20c82ad4":"code","b10fb434":"code","4b35eb28":"code","151260ae":"code","1df6af69":"code","63351c0e":"code","17bce958":"code","5c3c8012":"code","0fffe1bc":"code","683013c5":"code","dd080b9f":"code","0464f12c":"code","8005ef87":"markdown","599196f0":"markdown","b776e653":"markdown","427f8235":"markdown","f1bf09d3":"markdown","c1c79d72":"markdown","332347d8":"markdown","7fee7c09":"markdown"},"source":{"ae2bbb9d":"import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nkeras = tf.keras","cde7639d":"def plot_series(time, series, format=\"-\", start=0, end=None, label=None):\n    plt.plot(time[start:end], series[start:end], format, label=label)\n    plt.xlabel(\"Time\")\n    plt.ylabel(\"Value\")\n    if label:\n        plt.legend(fontsize=14)\n    plt.grid(True)\n    \ndef trend(time, slope=0):\n    return slope * time\n  \n  \ndef seasonal_pattern(season_time):\n    \"\"\"Just an arbitrary pattern, you can change it if you wish\"\"\"\n    return np.where(season_time < 0.4,\n                    np.cos(season_time * 2 * np.pi),\n                    1 \/ np.exp(3 * season_time))\n\n  \ndef seasonality(time, period, amplitude=1, phase=0):\n    \"\"\"Repeats the same pattern at each period\"\"\"\n    season_time = ((time + phase) % period) \/ period\n    return amplitude * seasonal_pattern(season_time)\n  \n  \ndef white_noise(time, noise_level=1, seed=None):\n    rnd = np.random.RandomState(seed)\n    return rnd.randn(len(time)) * noise_level","221b8489":"time = np.arange(4 * 365 + 1)\n\nslope = 0.05\nbaseline = 10\namplitude = 40\nseries = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)\n\nnoise_level = 5\nnoise = white_noise(time, noise_level, seed=42)\n\nseries += noise\n\nplt.figure(figsize=(10, 6))\nplot_series(time, series)\nplt.show()","0a38c930":"def window_dataset(series, window_size, batch_size=32,\n                   shuffle_buffer=1000):\n    dataset = tf.data.Dataset.from_tensor_slices(series)\n    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n    dataset = dataset.shuffle(shuffle_buffer)\n    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n    dataset = dataset.batch(batch_size).prefetch(1)\n    return dataset","4c918eab":"split_time = 1000\ntime_train = time[:split_time]\nx_train = series[:split_time]\ntime_valid = time[split_time:]\nx_valid = series[split_time:]","601d367c":"keras.backend.clear_session()\ntf.random.set_seed(42)\nnp.random.seed(42)\n\nwindow_size = 30\ntrain_set = window_dataset(x_train, window_size)\nvalid_set = window_dataset(x_valid, window_size)\nmodel = keras.models.Sequential([\n  keras.layers.Dense(1, input_shape=[window_size])\n])\noptimizer = keras.optimizers.SGD(lr=1e-5, momentum=0.9)\nmodel.compile(loss=keras.losses.Huber(),\n              optimizer=optimizer,\n              metrics=[\"mae\"])\nmodel.fit(train_set, epochs=100, validation_data=valid_set)","67f5b527":"keras.backend.clear_session()\ntf.random.set_seed(42)\nnp.random.seed(42)\n\nwindow_size = 30\ntrain_set = window_dataset(x_train, window_size)\n\nmodel = keras.models.Sequential([\n  keras.layers.Dense(1, input_shape=[window_size])\n])\n\nlr_schedule = keras.callbacks.LearningRateScheduler(\n    lambda epoch: 1e-6 * 10**(epoch \/ 30))\noptimizer = keras.optimizers.SGD(lr=1e-6, momentum=0.9)\nmodel.compile(loss=keras.losses.Huber(),\n              optimizer=optimizer,\n              metrics=[\"mae\"])\nhistory = model.fit(train_set, epochs=100, callbacks=[lr_schedule])","6264bb6e":"plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\nplt.axis([1e-6, 1e-3, 0, 20])","b76bbef2":"keras.backend.clear_session()\ntf.random.set_seed(42)\nnp.random.seed(42)\n\nwindow_size = 30\ntrain_set = window_dataset(x_train, window_size)\nvalid_set = window_dataset(x_valid, window_size)\n\nmodel = keras.models.Sequential([\n  keras.layers.Dense(1, input_shape=[window_size])\n])\noptimizer = keras.optimizers.SGD(lr=1e-5, momentum=0.9)\nmodel.compile(loss=keras.losses.Huber(),\n              optimizer=optimizer,\n              metrics=[\"mae\"])\nearly_stopping = keras.callbacks.EarlyStopping(patience=10)\nmodel.fit(train_set, epochs=500,\n          validation_data=valid_set,\n          callbacks=[early_stopping])","cdc57961":"def model_forecast(model, series, window_size):\n    ds = tf.data.Dataset.from_tensor_slices(series)\n    ds = ds.window(window_size, shift=1, drop_remainder=True)\n    ds = ds.flat_map(lambda w: w.batch(window_size))\n    ds = ds.batch(32).prefetch(1)\n    forecast = model.predict(ds)\n    return forecast","8404f2c6":"lin_forecast = model_forecast(model, series[split_time - window_size:-1], window_size)[:, 0]","2ba2ef38":"plt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplot_series(time_valid, lin_forecast)","4352442a":"keras.metrics.mean_absolute_error(x_valid, lin_forecast).numpy()","e41ae414":"keras.backend.clear_session()\ntf.random.set_seed(42)\nnp.random.seed(42)\n\nwindow_size = 30\ntrain_set = window_dataset(x_train, window_size)\n\nmodel = keras.models.Sequential([\n  keras.layers.Dense(10, activation=\"relu\", input_shape=[window_size]),\n  keras.layers.Dense(10, activation=\"relu\"),\n  keras.layers.Dense(1)\n])\n\nlr_schedule = keras.callbacks.LearningRateScheduler(\n    lambda epoch: 1e-7 * 10**(epoch \/ 20))\noptimizer = keras.optimizers.SGD(lr=1e-7, momentum=0.9)\nmodel.compile(loss=keras.losses.Huber(),\n              optimizer=optimizer,\n              metrics=[\"mae\"])\nhistory = model.fit(train_set, epochs=100, callbacks=[lr_schedule])","b9d40354":"plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\nplt.axis([1e-7, 5e-3, 0, 30])","307d1866":"keras.backend.clear_session()\ntf.random.set_seed(42)\nnp.random.seed(42)\n\nwindow_size = 30\ntrain_set = window_dataset(x_train, window_size)\nvalid_set = window_dataset(x_valid, window_size)\n\nmodel = keras.models.Sequential([\n  keras.layers.Dense(10, activation=\"relu\", input_shape=[window_size]),\n  keras.layers.Dense(10, activation=\"relu\"),\n  keras.layers.Dense(1)\n])\n\noptimizer = keras.optimizers.SGD(lr=1e-5, momentum=0.9)\nmodel.compile(loss=keras.losses.Huber(),\n              optimizer=optimizer,\n              metrics=[\"mae\"])\nearly_stopping = keras.callbacks.EarlyStopping(patience=10)\nmodel.fit(train_set, epochs=500,\n          validation_data=valid_set,\n          callbacks=[early_stopping])","321ae23e":"dense_forecast = model_forecast(\n    model,\n    series[split_time - window_size:-1],\n    window_size)[:, 0]","20c82ad4":"len(dense_forecast)","b10fb434":"plt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplot_series(time_valid, dense_forecast)","4b35eb28":"keras.metrics.mean_absolute_error(x_valid, dense_forecast).numpy()","151260ae":"diff_series = (series[365:] - series[:-365])\ndiff_time = time[365:]","1df6af69":"split_time = 1000\ntime_train_diff = diff_time[:split_time-365]\nx_train_diff = diff_series[:split_time-365]\ntime_valid_diff = diff_time[split_time-365:]\nx_valid_diff = diff_series[split_time-365:]","63351c0e":"keras.backend.clear_session()\ntf.random.set_seed(42)\nnp.random.seed(42)\n\nwindow_size = 30\ntrain_set = window_dataset(x_train_diff, window_size)\n\nmodel = keras.models.Sequential([\n  keras.layers.Dense(10, activation=\"relu\", input_shape=[window_size]),\n  keras.layers.Dense(10, activation=\"relu\"),\n  keras.layers.Dense(1)\n])\n\nlr_schedule = keras.callbacks.LearningRateScheduler(\n    lambda epoch: 1e-7 * 10**(epoch \/ 20))\noptimizer = keras.optimizers.SGD(lr=1e-7, momentum=0.9)\nmodel.compile(loss=keras.losses.Huber(),\n              optimizer=optimizer,\n              metrics=[\"mae\"])\nhistory = model.fit(train_set, epochs=100, callbacks=[lr_schedule])\nplt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\nplt.axis([1e-7, 5e-3, 0, 30])","17bce958":"keras.backend.clear_session()\ntf.random.set_seed(42)\nnp.random.seed(42)\n\nwindow_size = 30\ntrain_set = window_dataset(x_train_diff, window_size)\nvalid_set = window_dataset(x_valid_diff, window_size)\n\nmodel = keras.models.Sequential([\n  keras.layers.Dense(10, activation=\"relu\", input_shape=[window_size]),\n  keras.layers.Dense(10, activation=\"relu\"),\n  keras.layers.Dense(1)\n])\n\noptimizer = keras.optimizers.SGD(lr=1e-4, momentum=0.9)\nmodel.compile(loss=keras.losses.Huber(),\n              optimizer=optimizer,\n              metrics=[\"mae\"])\nearly_stopping = keras.callbacks.EarlyStopping(patience=10)\nmodel.fit(train_set, epochs=1000,\n          validation_data=valid_set,\n          callbacks=[early_stopping])","5c3c8012":"dense_forecast = model_forecast(\n    model,\n    diff_series[split_time - 365 - window_size:-1],\n    window_size)[:, 0]","0fffe1bc":"def moving_average_forecast(series, window_size):\n  mov = np.cumsum(series)\n  mov[window_size:] = mov[window_size:] - mov[:-window_size]\n  return mov[window_size - 1:-1] \/ window_size","683013c5":"diff_dense_forecast_smooth_past = moving_average_forecast(series[split_time - 370:-359], 11) + dense_forecast","dd080b9f":"plt.figure(figsize=(10, 6))\nplot_series(time_valid_diff, x_valid)\nplot_series(time_valid_diff, diff_dense_forecast_smooth_past)","0464f12c":"keras.metrics.mean_absolute_error(x_valid, diff_dense_forecast_smooth_past).numpy()","8005ef87":"We see a significant jump in performance.","599196f0":"## Forecasting with Machine Learning\n\nFirst, we will train a model to forecast the next step given the previous 30 steps, therefore, we need to create a dataset of 30-step windows for training.","b776e653":"### Linear Model","427f8235":"We try to find the best learning rate:","f1bf09d3":"## We try to forecast a Time Series using Neural Networks.","c1c79d72":"# Both these models didn't take into account the factor of seasonality and trend, We now remove trend seasonality and then implement the dense neural network again.","332347d8":"## We define a time-series:","7fee7c09":"### Dense Model Forecasting"}}