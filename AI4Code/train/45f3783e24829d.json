{"cell_type":{"31dfe535":"code","0959f0f3":"code","5259b2b5":"code","2bf58a41":"code","19aa98de":"code","e3fe2cea":"code","dbf2bbea":"code","4e715596":"code","717bef5f":"code","f7dec380":"code","90dcd859":"code","6315e5f7":"code","f7d6c207":"code","803a19a7":"code","9933a15e":"code","17fc9a44":"code","1847f9c7":"markdown","c6a9909f":"markdown","08574e3f":"markdown","5f3e6e7e":"markdown","11a82b34":"markdown","3b05ba59":"markdown","4ff13b69":"markdown"},"source":{"31dfe535":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n #   for filename in filenames:\n       # print(os.path.join(dirname, filename))\n    print (dirname)\n# Any results you write to the current directory are saved as output.","0959f0f3":"import numpy as np # linear algebra\nimport xml.etree.ElementTree as ET\n#lab=np.array([])\nlab=[]\n#tree = ET.ElementTree(file='..\/input\/ba3adads\/PetitCorpus_Racine0_tab3oudou.xml');\n#tree = ET.ElementTree(file='..\/input\/teb3odouds\/CorpusApprentissage_Racine0.xml');\ntree = ET.ElementTree(file='..\/input\/CorpusApprentissage_Racine0.xml');\nroot=tree.getroot();\n#print(root)\nchildren = root.getchildren();\nprint(children)\nsubchld = children[0].getchildren();\nfor sbs in subchld:\n    #print(sbs.get('Dist0'))\n    lab.append(sbs.get('Dist0'))\n #   np.append(lab,sbs.get('Dist0'))\n #   ET.dump(chld)\n##############################\nprint(np.shape(lab))\n#print(np.shape(Y_train))\nprint(lab[:])","5259b2b5":"#Determination de x_train et y_train\nimport numpy as np # linear algebra\nimport os\nimport glob as gb\nimport cv2\ns1=64\ns2=64\nx_train = []\ny_train = []\n#trainpath='..\/input\/ba3adads\/BA3ADA\/'\n#trainpath='..\/input\/teb3odouds\/teb3odou\/teb3odou\/'\n#trainpath='..\/input\/ba3adads2\/BA3ADA\/'\ntrainpath='..\/input\/BA3ADA-20200530T145551Z-001\/BA3ADA\/'\n#for folder in  os.listdir('..\/input\/ba3adads\/BA3ADA') : \n#for folder in  os.listdir('..\/input\/teb3odouds\/teb3odou\/teb3odou\/') : \n#for folder in  os.listdir('..\/input\/ba3adads2\/BA3ADA') : \nfor folder in  os.listdir('..\/input\/BA3ADA-20200530T145551Z-001\/BA3ADA\/') : \n    files = gb.glob(pathname= str( trainpath + folder +'\/*.png'))\n    for file in files: \n        image = cv2.imread(file)\/ 255.0\n        image_array = cv2.resize(image , (s1,s2))\n        x_train.append(list(image_array))\n        y_train.append(int(lab[int(folder)]))\n        #y_train.append(int(folder))\n##################################################\nprint(np.shape(x_train))\nprint(np.shape(y_train))","2bf58a41":"#print(np.shape(y_train))\n#print(type(x_train))\n#x_train = np.array(x_train) \n#print(np.shape(x_train))\n#print(type(x_train))\nimport numpy as np # linear algebra\ny_train = np.array(y_train) \n#print(type(y_train))\n#print(np.shape(y_train))\ny_train","19aa98de":"y_train = y_train.astype('int32')\nprint(np.unique(y_train))","e3fe2cea":"print(np.shape(x_train))\n#print(type(x_train))\nx_train = np.array(x_train) \nprint(np.shape(y_train))\nprint(type(x_train))\nprint(type(y_train))\n#######################\nprint(type(y_train[7]))\nprint(y_train[0:20])\nc=y_train","dbf2bbea":"import matplotlib.pyplot as plt\n# Some examples\ng = plt.imshow(x_train[5][:,:,:])","4e715596":"print(y_train[0])\nprint(x_train[0])","717bef5f":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nbatch_size = 64\nnum_classes = 6\nepochs = 20\ninput_shape = (64, 64, 3)","f7dec380":"y_train","90dcd859":"# convert class vectors to binary class matrices One Hot Encoding\n#y_train = y_train -2\ny_train = y_train -1\ny_train = keras.utils.to_categorical(y_train, num_classes)\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state=42)","6315e5f7":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal',input_shape=input_shape))\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Dropout(0.20))\nmodel.add(Conv2D(64, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\nmodel.add(Conv2D(64, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(128, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(Dense(num_classes, activation='softmax'))\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.RMSprop(),\n              metrics=['accuracy'])\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.0001)\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=15, # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images","f7d6c207":"model.summary()","803a19a7":"datagen.fit(x_train)","9933a15e":"epochs = 50","17fc9a44":"# Fit the model\nhistory = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n                              epochs = epochs,\n                              verbose = 2, steps_per_epoch=x_train.shape[0] \/\/ batch_size)","1847f9c7":"# Importation des donn\u00e9es et Determination de x_train et y_train\n\n","c6a9909f":"# Phase d'importation de distance de fichier xml**** ","08574e3f":"# Model fitting","5f3e6e7e":"# Cr\u00e9ation de mod\u00e8le","11a82b34":"# Importation des bibs et initialisation des parames","3b05ba59":"# Preparation des donn\u00e9es","4ff13b69":"# Pr\u00e9cision "}}