{"cell_type":{"bc8ced7a":"code","3df79e08":"code","4e297764":"code","8c779860":"code","fbcbfa74":"code","59bae8e6":"code","4901db74":"code","e7978dd1":"code","8c4f7a29":"code","aa826625":"code","13ba9fc5":"code","d791e91e":"code","0778a9c0":"code","ad8d9d15":"code","9b120c17":"code","453ec4d0":"code","6fdc1d85":"code","26e6ae20":"code","40cb305a":"code","9187e1b2":"code","e1a15486":"code","a7116127":"code","75f2b0a1":"code","c61d76e1":"code","e2ef489e":"code","b3cb899d":"code","5b5d6e9b":"code","40bb2266":"code","247386ab":"markdown","65b313fa":"markdown","4ccb859a":"markdown","ba8b161a":"markdown"},"source":{"bc8ced7a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import IsolationForest\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.impute import KNNImputer\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Lasso, Ridge, ElasticNet\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.ensemble import VotingClassifier\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler\nfrom sklearn.feature_selection import SelectKBest, chi2\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import RFE\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import roc_auc_score\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3df79e08":"train = pd.read_csv('..\/input\/iba-ml1-mid-project\/train.csv')\ntest = pd.read_csv('..\/input\/iba-ml1-mid-project\/test.csv')","4e297764":"df = train.replace(',','.', regex=True).astype(float) #changed the type to float as data type one of the columns was object","8c779860":"iso=IsolationForest(contamination=0.10)\nimp=SimpleImputer(strategy='mean')","fbcbfa74":"X=df[['age','number_dependent_family_members', 'monthly_income', 'number_of_credit_lines', 'real_estate_loans', 'ratio_debt_payment_to_income','credit_line_utilization','number_of_previous_late_payments_up_to_59_days','number_of_previous_late_payments_up_to_89_days','number_of_previous_late_payments_90_days_or_more']]\ny=df[['defaulted_on_loan']]\n","59bae8e6":"rus=RandomUnderSampler(random_state=42)\nros=RandomOverSampler(random_state=42)","4901db74":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8) \n","e7978dd1":"X_rus_train, y_rus_train = rus.fit_resample(X_train, y_train)\n","8c4f7a29":"sns.scatterplot(data=X_rus_train, x='age', y='monthly_income') #taking on pair plot to compair it to after outlier removal \n","aa826625":"outlier_predXtr = iso.fit_predict(imp.fit_transform(X_rus_train)) #checking outliers in X_train\nmask=outlier_predXtr != -1\nX_train2, y_train2 = X_rus_train.iloc[mask, :], y_rus_train.iloc[mask] #updating training dataset","13ba9fc5":"sns.scatterplot(data=X_train2, x='age', y='monthly_income') \n","d791e91e":"estimator=SVR(kernel='linear')","0778a9c0":"numerics = ['age','number_dependent_family_members', 'monthly_income', 'number_of_credit_lines', 'real_estate_loans', 'ratio_debt_payment_to_income','credit_line_utilization','number_of_previous_late_payments_up_to_59_days','number_of_previous_late_payments_up_to_89_days','number_of_previous_late_payments_90_days_or_more']","ad8d9d15":"numeric_transformer = Pipeline(steps=[\n    ('impute', KNNImputer()),\n    ('scaler', MinMaxScaler())\n    ])\n\ncolumn_preprocessing = ColumnTransformer(transformers=[\n    ('numeric', numeric_transformer, numerics)\n    \n    ])\n\nmodel = Pipeline(steps=[\n    ('preprocessing', column_preprocessing),\n    ('feat_select', RFE(estimator)),\n    ('classification', VotingClassifier(estimators=[\n        ('dt', DecisionTreeClassifier()),\n        ('knn', KNeighborsClassifier()),\n        ('randomforest', RandomForestClassifier())\n    ], voting='soft'))\n    ])\n\n  \nparam_space = {\n    'preprocessing__numeric__impute__n_neighbors':[3,9],\n    'classification__knn__n_neighbors':[3,9],\n    'classification__dt__max_depth':[5,7],\n    'feat_select__n_features_to_select':[4,7]\n    }","9b120c17":"gs= GridSearchCV(model, param_space, cv= 15, scoring='roc_auc', refit='precision_score')\n","453ec4d0":"gs.fit(X_train2, y_train2.values.ravel() )\n","6fdc1d85":"y_predict=gs.predict(X_test) #find target values on test dataset\ny_predict","26e6ae20":"y_predict_probs = gs.predict_proba(X_test) #find probabilities of target values on test dataset\ny_predict_probs","40cb305a":"plot_confusion_matrix(gs, X_test, y_test) ","9187e1b2":"positive_probs = y_predict_probs[:, 1]\n","e1a15486":"roc_auc_score(y_test, positive_probs)\n","a7116127":"newtest=test.drop(['Id'], axis=1).replace(',','.', regex=True).astype(float) #preparing test data","75f2b0a1":"resultsprob=gs.predict_proba(newtest) # .replace(',','.', regex=True).astype(float))\nresultsprob.shape #checking the size ","c61d76e1":"resultsdfprob=pd.DataFrame(resultsprob[:,1], columns = ['Predicted'])\nresultsdfprob.index.name = 'Id'\nresultsdfprob.index += 1 ","e2ef489e":"resultsdfprob.to_csv('submission proba Aghamir Aghazada.csv')\n","b3cb899d":"from sklearn import metrics\nfrom sklearn.metrics import roc_curve\nfrom matplotlib import pyplot","5b5d6e9b":"fpr, tpr, thresholds = roc_curve(y_test, positive_probs)\n","40bb2266":"pyplot.plot(fpr, tpr, marker='.', label='model')\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\npyplot.plot([0, 1], [0, 1], linestyle='--', label='No Skill')\npyplot.legend()\npyplot.show()","247386ab":"We can see that number of outliers decreased previous operation","65b313fa":"Decided to undersample the data since oversampling would take much more time to calculate.","4ccb859a":"Any train_size ratio yielded same results.","ba8b161a":"Initially I was calculating roc_auc_score by using gs.predict which would show 75% score. Later I realized that the task is to find probabilities of positive and negative cases, so I used gs.predict_proba which showed better results of ~82%"}}