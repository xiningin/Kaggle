{"cell_type":{"076275e5":"code","1840a6d2":"code","bc235a69":"code","8340cd13":"code","1ac46dbc":"code","ad037782":"code","bdf17cce":"code","f0103b4f":"code","8ce77403":"code","56e29dd2":"code","a6a779f0":"code","9152e871":"code","35012118":"code","ae46ded0":"code","1c6803c5":"code","04b63f2a":"code","439a0c44":"code","67998d29":"code","9a857f3b":"code","34bffa33":"markdown"},"source":{"076275e5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","1840a6d2":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom scipy.io import loadmat\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import np_utils\nfrom keras import backend as K","bc235a69":"mnist = loadmat(\"..\/input\/mnist-original.mat\")","8340cd13":"mnist","1ac46dbc":"x = mnist['data'].T  # T is for transpose the matrix\ny = mnist['label'][0]","ad037782":"x\n","bdf17cce":"y","f0103b4f":"print(x.shape)\nprint(y.shape)","8ce77403":"from sklearn.model_selection import train_test_split  # also imported in upper section\n\nx_test, x_train, y_test, y_train = train_test_split(x, y, test_size=0.25, random_state=0)\nprint(x_test)\nprint(x_train)\n\n","56e29dd2":"img_rows = 28\nimg_cols = 28","a6a779f0":"# Preprocess data for training model\n#reshaping\n#this assumes our data format\n#For 3D data, \"channels_last\" assumes (conv_dim1, conv_dim2, conv_dim3, channels) while \n#\"channels_first\" assumes (channels, conv_dim1, conv_dim2, conv_dim3).\nif K.image_data_format() == 'channels_first':\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n  \n","9152e871":"#more reshaping\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nprint('x_train shape: ', x_train.shape)","35012118":"# transform labels to vectors\nnum_category = 10\ny_train = np_utils.to_categorical(y_train, num_category)\ny_test = np_utils.to_categorical(y_test, num_category)\nprint(y_train.shape)\ny_train[0]","ae46ded0":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\ng = plt.imshow(x_train[3][:,:,0],\"gray\")  #showing digit","1c6803c5":"model = Sequential()\nmodel.add(Conv2D(30, kernel_size=3, activation='relu', input_shape=input_shape))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(15, kernel_size=3, activation='relu'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dense(7, activation='relu')) # <7 stops working, but higher values do nothing\nmodel.add(Flatten())\nmodel.add(Dense(units = num_category, activation='softmax')) # 'sigmoid'))","04b63f2a":"model.summary()","439a0c44":"\n\n#Adaptive learning rate (adaDelta) is a popular form of gradient descent rivaled only by adam and adagrad\n#categorical ce since we have multiple classes (10)\nmodel.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n\n","67998d29":"model_log = model.fit(x_train, y_train,\n          batch_size=128, \n          epochs=5, # 10,\n         verbose=1,\n         validation_data=(x_test, y_test))","9a857f3b":"score = model.evaluate(x_test, y_test, verbose=0)\nprint('Test loss: ', score[0])\nprint('Test accuracy: ', score[1])","34bffa33":"**Spiliting Data into Train set and Test set**"}}