{"cell_type":{"3955b149":"code","71c95fd2":"code","fb459659":"code","6e36eaae":"code","7ebb2792":"code","b60461a4":"code","df3bdfd6":"code","01b31ed0":"code","1670d35e":"code","838e328d":"code","9cb4ec79":"code","82343261":"code","b286bc49":"code","abd3c338":"code","3cdb0f94":"code","eb6af3b6":"code","b0170815":"code","16a71433":"code","dfe365e3":"code","07f60b9c":"markdown","a56346f9":"markdown","2222a95e":"markdown","15d29c9b":"markdown","40268b8b":"markdown","be3f1899":"markdown","882f19be":"markdown","4257899a":"markdown","36293792":"markdown","da0d9919":"markdown","057e2ec7":"markdown","0b590049":"markdown"},"source":{"3955b149":"!pip install efficientunet-pytorch","71c95fd2":"import numpy as np\nfrom PIL import Image\nimport cv2\nimport pandas as pd\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nimport random\nimport math\nimport time\nimport os\nimport re\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.model_selection import KFold\n\nfrom efficientunet import *\n\nimport torch\nimport torch.nn as nn\nfrom torch.cuda.amp import autocast, GradScaler\nimport torch.optim as optim\n\nimport torch.utils.data as data\nimport torchvision\nfrom torchvision import models, transforms\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu' ","fb459659":"PATH = '..\/input\/lung-segmentation'\nTRAIN_PATH = '..\/input\/lung-segmentation\/train\/train'\nTEST_PATH = '..\/input\/lung-segmentation\/test'","6e36eaae":"p = re.compile(r'\\d+')","7ebb2792":"train_img_list = os.listdir(TRAIN_PATH+'\/org')\ntrain_img_list = sorted(train_img_list, key=lambda s: int(p.search(s).group()))\ntrain_anno_list = os.listdir(TRAIN_PATH+'\/label')\ntrain_anno_list = sorted(train_anno_list, key=lambda s: int(p.search(s).group()))\ntrain_img_list = [TRAIN_PATH+'\/org\/'+t for t in train_img_list]\ntrain_anno_list = [TRAIN_PATH+'\/label\/'+t for t in train_anno_list]","b60461a4":"test_img_list = os.listdir(TEST_PATH+'\/org')\ntest_img_list = sorted(test_img_list, key=lambda s: int(p.search(s).group()))\ntest_img_list = [TEST_PATH+'\/org\/'+t for t in test_img_list]","df3bdfd6":"df_sub = pd.read_csv('..\/input\/lung-segmentation\/sample_submission.csv')","01b31ed0":"class Config():\n    def __init__(self):\n        self.seed = 42\n        self.folds = 5\n        self.num_classes = 2\n        self.img_width = 224\n        self.img_height = 224\n        self.epochs = 50\n        self.lr = 0.01\n        self.weight_decay = 0.01\n        self.T_max = 100\n        self.eta_min = 0.001\n        self.save_model_name = 'lung_model.pth'\n        self.batch_size = 3\n        \n\n        \n        \nconfig = Config()","1670d35e":"def fix_seed(seed):\n    # random\n    random.seed(seed)\n    # Numpy\n    np.random.seed(seed)\n    # Pytorch\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\nSEED = config.seed\nfix_seed(SEED)","838e328d":"class UNETdataset(data.Dataset):\n\n    def __init__(self, img_list, transform, anno_list=None, phase='test',target_transform=None):\n        self.img_list = img_list\n        self.anno_list = anno_list\n        self.phase = phase\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __len__(self):\n        '''\u753b\u50cf\u306e\u679a\u6570\u3092\u8fd4\u3059'''\n        return len(self.img_list)\n\n\n    def __getitem__(self, index):\n        '''\u753b\u50cf\u306eTensor\u5f62\u5f0f\u306e\u30c7\u30fc\u30bf\u3001\u30a2\u30ce\u30c6\u30fc\u30b7\u30e7\u30f3\u3092\u53d6\u5f97\u3059\u308b'''\n\n        # 1. \u753b\u50cf\u8aad\u307f\u8fbc\u307f\n        img = Image.open(self.img_list[index]).convert('RGB')\n        img = self.transform(img)\n      \n        if self.phase == 'train':\n            \n            # 2. \u30a2\u30ce\u30c6\u30fc\u30b7\u30e7\u30f3\u753b\u50cf\u8aad\u307f\u8fbc\u307f\n            anno_img = Image.open(self.anno_list[index])\n            anno_img = self.target_transform(anno_img)\n            \n            return img, anno_img\n            \n        else:\n            \n            return img","9cb4ec79":"num_classes = config.num_classes\n\n# \u30a2\u30ce\u30c6\u30fc\u30b7\u30e7\u30f3\u30c7\u30fc\u30bf\u524d\u51e6\u7406\u306e\u5b9a\u7fa9\n\ndef TargetToTensor(target):\n    target = np.array(target)\n    target[target > 0] = 1 # label\u30920-1\u306e\u5408\u8a082\u30af\u30e9\u30b9\u306b\u9650\u5b9a\n    target = torch.from_numpy(target).type(torch.long) \n    target = F.one_hot(target, num_classes=num_classes).permute(2,0,1).type(torch.float)\n    return target\n\nimage_transform = transforms.Compose([\n    transforms.Resize((config.img_width, config.img_height)),\n    transforms.ToTensor()\n])\ntarget_transform = transforms.Compose([\n    transforms.Resize((config.img_width, config.img_height)),\n    transforms.Lambda(lambda target: TargetToTensor(target))\n])","82343261":"# \u4e0b\u8a18\u30ea\u30f3\u30af\u5148\u306emIoU\u5b9f\u88c5\u3092\u5229\u7528\n# https:\/\/github.com\/wkentaro\/pytorch-fcn\/blob\/master\/torchfcn\/utils.py\nclass mIoUScore(object):\n    def __init__(self, n_classes):\n        self.n_classes = n_classes\n        self.confusion_matrix = np.zeros((n_classes, n_classes))\n\n    def _fast_hist(self, label_true, label_pred, n_class):\n        mask = (label_true >= 0) & (label_true < n_class)\n        hist = np.bincount(\n            n_class * label_true[mask].astype(int) + label_pred[mask], minlength=n_class ** 2\n        ).reshape(n_class, n_class)\n        return hist\n\n    def update(self, label_trues, label_preds):\n        for lt, lp in zip(label_trues, label_preds):\n            self.confusion_matrix += self._fast_hist(lt.flatten(), lp.flatten(), self.n_classes)\n\n    def get_scores(self):\n        hist = self.confusion_matrix\n        with np.errstate(divide='ignore', invalid='ignore'):\n            iou = np.diag(hist) \/ (hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist))\n        mean_iou = np.nanmean(iou)\n        return mean_iou\n\n    def reset(self):\n        self.confusion_matrix = np.zeros((self.n_classes, self.n_classes))","b286bc49":"model  = get_efficientunet_b7(out_channels=config.num_classes, concat_input=True, pretrained=True)\nepochs = config.epochs\nloss_fn = nn.BCEWithLogitsLoss()\nmetrics = mIoUScore(config.num_classes)\noptimizer = optim.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.T_max, eta_min=config.eta_min)\nmodel_path = '.\/'+config.save_model_name","abd3c338":"def train(model,\n          train_dataloader,\n          valid_dataloader,\n          n_epochs=epochs,\n          loss_fn = loss_fn,\n          metrics=metrics,\n          optimizer=optimizer,\n          scheduler=scheduler,\n          model_path=model_path):\n  # model\u306e\u5b66\u7fd2\n    model.to(device)\n    miou = 0\n    for epoch in range(n_epochs):\n        train_losses = []\n        valid_losses = []\n        metrics.reset()\n        \n        model.train()\n        with tqdm(total=len(train_dataloader), unit=\"batch\") as pbar:\n            pbar.set_description(f\"[train] Epoch {epoch+1}\/{n_epochs}\")\n            for image, target in train_dataloader:\n                scheduler.step()\n                optimizer.zero_grad()\n                image, target = image.to(device), target.to(device)\n                output = model(image)\n                loss = loss_fn(output, target)\n                loss.backward()\n                optimizer.step()\n                train_losses.append(loss.item())\n                pbar.set_postfix(loss=np.array(train_losses).mean())\n                pbar.update(1)\n        \n        if epoch % 5 == 0:\n            model.eval()\n            with tqdm(total=len(valid_dataloader), unit=\"batch\") as pbar:\n                pbar.set_description(f\"[valid] Epoch {epoch+1}\/{n_epochs}\")\n                for image, target in valid_dataloader:\n                    image, target = image.to(device), target.to(device)\n                    output = model(image)\n                    loss = loss_fn(output, target)\n                    valid_losses.append(loss.item())\n                    metrics.update(target.argmax(1).cpu().numpy(), output.argmax(1).cpu().numpy())\n                    pbar.set_postfix(loss=np.array(valid_losses).mean(), mIoU=metrics.get_scores())\n                    pbar.update(1)\n\n    torch.save(model.to('cpu').state_dict(), model_path)","3cdb0f94":"kf = KFold(n_splits=config.folds, shuffle=True, random_state=config.seed)\nfor i,(train_index, valid_index) in enumerate(kf.split(train_img_list)):\n    if i == 0:\n        x_train, x_valid = ([train_img_list[index] for index in train_index], [train_img_list[index] for index in valid_index])\n        y_train, y_valid = ([train_anno_list[index] for index in train_index] , [train_anno_list[index] for index in valid_index])\n\n        train_dataset = UNETdataset(x_train, transform = image_transform, anno_list = y_train, phase=\"train\", \n                                target_transform=target_transform)\n\n        val_dataset = UNETdataset(x_valid, transform = image_transform, anno_list = y_valid, phase=\"train\",  \n                                    target_transform = target_transform)\n\n        batch_size = config.batch_size\n\n        train_dataloader = data.DataLoader(\n            train_dataset, batch_size=batch_size, shuffle=True)\n\n        val_dataloader = data.DataLoader(\n            val_dataset, batch_size=batch_size, shuffle=False)\n\n        train(model,train_dataloader,val_dataloader)\n    else:\n        break","eb6af3b6":"def RLE_for(sequence):\n\n    element_dict = {'0':[],'1':[]}\n    \n    temp = sequence[0]\n\n    if temp == 0:\n        element_dict['0'].append(1)\n    else:\n        element_dict['1'].append(1)\n\n    length = 1\n\n    # 2\u756a\u76ee\u304b\u3089\u6700\u5f8c\u307e\u3067\n    for i in range(1, len(sequence)):\n        if sequence[i] != temp:  # \u65b0\u3057\u3044\u30c7\u30fc\u30bf\u304c\u6765\u305f\u3089\u3001\u30c7\u30fc\u30bf\u306e\u5909\u5316\u70b9\u3068\u3053\u308c\u307e\u3067\u306e\u9577\u3055\u3092\u8a18\u9332\n            \n            if temp == 0:\n                element_dict['0'].append(length)\n                element_dict['1'].append(i+1)\n            else:\n                element_dict['1'].append(length)\n                element_dict['0'].append(i+1)\n            \n            temp = sequence[i]\n            length = 1\n        \n        else: # \u524d\u3068\u540c\u3058\u30c7\u30fc\u30bf\u304c\u6765\u305f\u3089\u3001length\u3092\u30a4\u30f3\u30af\u30ea\u30e1\u30f3\u30c8\n            length += 1\n\n    # \u6700\u5f8c\u306blength\u3092\u8ffd\u52a0\n    if temp == 0:\n        element_dict['0'].append(length)\n    else:\n        element_dict['1'].append(length)\n\n    return element_dict","b0170815":"test_dataset = UNETdataset(img_list = test_img_list, phase=\"test\", \n                            transform=image_transform)\n\nmodel.load_state_dict(torch.load(model_path))\nmodel.to(device)\nmodel.eval()\n\nanswer_list = []\n\nfor i in range(len(test_dataset)):\n    image = test_dataset[i]\n    pred = model(image.to(device).unsqueeze(0))\n    pred_img = pred.argmax(1).cpu().numpy()[0]\n    seg_img = pred_img.astype('u1')\n    \n    plt.imshow(seg_img)\n    plt.show()\n    \n    seg_img = cv2.resize(seg_img, dsize=(256, 256))\n    seg_img = np.ravel(seg_img)\n    element_dict = RLE_for(seg_img)\n    answer = element_dict['1']\n    answer = [str(i) for i in answer]\n    W = ' '.join(answer)\n    answer_list.append(W)","16a71433":"df_sub['EncodedPixel'] = answer_list\ndf_sub.to_csv('submission.csv',index=False,encoding='utf-8')","dfe365e3":"df_sub.head()","07f60b9c":"## \u30e9\u30f3\u30ec\u30f3\u30b0\u30b9\u5727\u7e2e\u95a2\u6570\u5b9a\u7fa9","a56346f9":"## \u63a8\u8ad6","2222a95e":"## Train\u5b9a\u7fa9","15d29c9b":"## \u8a2d\u5b9a","40268b8b":"## \u30e9\u30a4\u30d6\u30e9\u30ea\u30a4\u30f3\u30dd\u30fc\u30c8","be3f1899":"## IoU\u8a55\u4fa1\u30af\u30e9\u30b9\u5b9a\u7fa9","882f19be":"## \u5b66\u7fd2","4257899a":"## Data\u8aad\u307f\u8fbc\u307f","36293792":"## Seed\u5024\u56fa\u5b9a","da0d9919":"##  submit","057e2ec7":"## \u30e2\u30c7\u30eb\u8a2d\u5b9a\u5b9a\u7fa9","0b590049":"# \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u5b9a\u7fa9"}}