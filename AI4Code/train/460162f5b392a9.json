{"cell_type":{"5f824d3a":"code","afa81ad5":"code","14050295":"code","3eb789b2":"code","e0a1bd9c":"code","d2bbcb64":"code","fe33d5fa":"code","d752be9f":"code","26065909":"code","8879db3d":"code","8d467ab5":"code","3d5affaf":"code","cd90e0fd":"code","0c88c2f1":"code","d5b2f063":"markdown","6e27b3e9":"markdown","e97e3bb6":"markdown","5d4c9305":"markdown","820c1b5e":"markdown","4916ba92":"markdown","95107c99":"markdown"},"source":{"5f824d3a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","afa81ad5":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom IPython.display import display\nimport pkg_resources \n\npkg_resources.get_distribution('pandas').version","14050295":"PSA = pd.read_csv('..\/input\/nyse\/prices-split-adjusted.csv')  \nPSA.head()","3eb789b2":"# use volume weighted averaged OHLC.mean to represent market average\n# comparison with SPY500 shows that market_average calculated this way is representative of overall market\ntickers_with_all_dates = (PSA\n                          .groupby('symbol')\n                          .size()\n                          .loc[lambda s: s.values==s.values.max()]\n                          .index\n                          .to_list())\ntickers_with_invalid_values = (PSA\n                               .loc[PSA[['open','close','high','low','volume']]\n                               .le(0.)\n                               .any(axis=1), 'symbol']\n                               .unique()\n                               .tolist())\ntickers_with_all_dates = list(set(tickers_with_all_dates).difference(set(tickers_with_invalid_values)))\nprint(f\"there are {len(tickers_with_all_dates)} tickers with all dates\")","e0a1bd9c":"market = (PSA\n          .loc[PSA['symbol'].isin(tickers_with_all_dates)]\n          .assign(**{'average': lambda df: df.loc[:,['open','high','low','close']].mean(axis=1), \n                     'price x volume': lambda df: df['average']*df['volume']})\n          .groupby('date')\n          .agg(**{'price x volume sum': pd.NamedAgg(column='price x volume', aggfunc=np.sum), \n                  'volume sum': pd.NamedAgg(column='volume', aggfunc=np.sum)})\n          .assign(**{'market_average': lambda df: df['price x volume sum']\/df['volume sum']})\n          .sort_index(ascending=True))\n# plt.plot(market['market_average'])","d2bbcb64":"lookback = 120\nlookahead = 5\ntest_size = 0.2\nX_train = []\nX_test = []\ny_train = []\ny_test = []\nfeatures = ['open', 'close', 'low', 'high', 'volume', 'dist_EMA20', 'dist_EMA5', 'market']\nfor k, ticker in enumerate(tickers_with_all_dates):\n    # data of a ticker\n    ticker_df = (PSA\n                 .loc[PSA['symbol']==ticker]\n                 .drop(columns='symbol')\n                 .sort_values(by='date',ascending=True)\n                 .reset_index(drop=True)\n                 .assign(**{'average': lambda df: df.loc[:,['open','high','low','close']].mean(axis=1), \n                            'EMA20': lambda df: df['average'].ewm(span=20, adjust=False).mean(), \n                            'EMA5': lambda df: df['average'].ewm(span=5, adjust=False).mean(), \n                            'dist_EMA20': lambda df: (df['average'] - df['EMA20'])\/df['EMA20'], \n                            'dist_EMA5': lambda df: (df['average'] - df['EMA5'])\/df['EMA5'], \n                            'market': market['market_average'].values}))\n\n    # Create sequence samples\n    # note: normalization is done with information within a sequence\n    data_array = ticker_df[features].values\n    sample_num = len(data_array)-lookback-lookahead\n    idx_C = lookback-1\n    idx_F = lookback+lookahead-1\n    \n    X = np.array([data_array[i:i+lookback] for i in range(sample_num)])\n    X[:, :, 0:4] = X[:, :, 0:4] \/ X[:, 0:1, 0:1]\n    X[:, :, 4:5] = X[:, :, 4:5] \/ X[:, 0:1, 4:5]\n    X[:, :, -1] = X[:,:,-1] \/ X[:, 0:1, -1]\n    y = np.array([(data_array[i+idx_F,1] - data_array[i+idx_C,1]) \/ data_array[i+idx_C,1] for i in range(sample_num)])\n    \n    if k==0:\n        n = np.round(len(X)*(1-test_size)).astype(int)\n        print(f\"for each ticker, {n} train samples, {len(X)-n} test samples\")    \n\n    X_train.append(X[:n,:,:])\n    X_test.append(X[n:,:,:])\n    y_train.append(y[:n])\n    y_test.append(y[n:])\n        \n    # show progress\n    if (k>0) & (k%50 == 0):\n        print(f\"ticker {k}\/{len(tickers_with_all_dates)}\")","fe33d5fa":"X_train = np.concatenate(X_train, axis=0)\nX_test = np.concatenate(X_test, axis=0)\ny_train = np.concatenate(y_train)\ny_test = np.concatenate(y_test)\nprint(f\"for all tickers, {X_train.shape[0]} train samples, {X_test.shape[0]} test samples\")","d752be9f":"__ = plt.hist(y_train, range=(-0.2, 0.2), bins=40)","26065909":"import keras\nimport tensorflow as tf\nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout, LSTM, Input, Activation, concatenate\nfrom keras import optimizers\nfrom keras import backend as K\nfrom keras.utils import plot_model\n\ndef r2_keras(y_true, y_pred):\n    SS_res =  K.sum(K.square(y_true - y_pred)) \n    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n    return ( 1 - SS_res\/(SS_tot + K.epsilon()) )\n\n\n# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n# instantiating the model in the strategy scope creates the model on the TPU\nwith tpu_strategy.scope():\n    lstm_input = Input(shape=(lookback, len(features)), name='lstm_input')\n    x = LSTM(units=64, return_sequences=False, return_state=False)(lstm_input)  # ??????????? return_sequence, return_state\n    x = Dropout(0.2)(x)\n    x = Dense(units=32, activation='relu')(x)\n    output = Dense(1, activation='linear')(x)\n    model = Model(inputs=lstm_input, outputs=output)\n\n    adam = optimizers.Adam(lr=0.0005)\n    model.compile(optimizer=adam, loss='mse', metrics=[r2_keras])\n    \n    \nmodel.summary()\nplot_model(model) ","8879db3d":"History = model.fit(X_train, y_train, \n                    epochs=10, \n                    shuffle=True,\n                    batch_size=128*8,\n                    validation_data=(X_test, y_test))","8d467ab5":"# Plot training & validation accuracy values\nplt.plot(History.history['r2_keras'], label='Train')\nplt.plot(History.history['val_r2_keras'], label='validation')\nplt.title('R2 score')\nplt.ylabel('R2 score')\nplt.xlabel('Epoch')\nplt.legend(loc='best')\nplt.show()","3d5affaf":"# y_pred = model.predict(X_test, batch_size=128*8, verbose=1)\n\n# fig, ax = plt.subplots(figsize=(10, 5))\n# ax.plot(y_test, label='y_test')  \n# ax.plot(y_pred, label='y_pred')  \n# ax.legend(loc='best')","cd90e0fd":"# r2_keras(y_test, y_pred)","0c88c2f1":"# num_right = (np.sign(y_test) == np.sign(y_pred).squeeze()).sum()\n# num_right\/len(y_test)","d5b2f063":"## Import and look at data\n* PSA and prices have the same content. Use PSA hereafter\n* Not all symbols have the same time lenght of data, but most have data from 2010 to 2016. \n* The fundamentals has at most 4 data points for any company and do not seem useful. Ignore.\n* data in securities are not useful for us. ","6e27b3e9":"## Train model","e97e3bb6":"R2 score is lower than but very close to zero --> the model is no better than a average guess which is close to zero. ","5d4c9305":"# 20200218: Use stock data from many stocks to train RNN model - Regression\nUsing data of many stocks, The hope is to extract common patterns of stock movement","820c1b5e":"## Test model","4916ba92":"## RNN model","95107c99":"## Feature engineering\n* How long is the look back? for intraday data, use 6 month (120 trading days) \n* All features should be normalized so they are nondimensional and the fitted model can be applied to any stock, but not necessarily normalized by min and max\n* Normalize each sequence with information within this sequence\n    - OHLC devided by some value from each sequence (no more minus and then normalize with prior days value)\n    - distance between OHLC.mean and EMA20 (or EMA5) normalzied by EMA20 (or EMA5)\n    - volume normalized by some value from each sequence\n    - other technical indicators "}}