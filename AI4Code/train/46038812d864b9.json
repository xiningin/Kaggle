{"cell_type":{"621f8966":"code","5e6c72c3":"code","59a99cd8":"code","5e990bb5":"code","2fd903c3":"code","dda7f878":"code","348f2f89":"code","0af117bd":"code","0cda7e4d":"code","62d09e0b":"code","1de8db31":"code","cac5d5c9":"code","69f4c097":"code","e68f60a5":"code","e5a3b7ff":"code","44307ae4":"code","466c75ec":"code","050c60ee":"code","775748fa":"code","f92f33bd":"code","de57b28d":"code","9ece50b3":"code","422ddaff":"code","8d94e53c":"code","0a22e47c":"code","cc5cdf29":"code","2992e031":"code","bd41b1f0":"code","43e2bdb9":"code","242ce7bc":"code","ef86aa53":"code","7314bdf4":"code","b835c781":"markdown","f90fbe01":"markdown","1a6bfd76":"markdown","0676ce10":"markdown","9bb136bf":"markdown","518c2b24":"markdown","0aecc2e5":"markdown","7c6545c7":"markdown","93996c69":"markdown","ffb0e78b":"markdown","b8ad9800":"markdown","0b0b2443":"markdown","7ba6a7c8":"markdown","a7faea35":"markdown","87cce1f8":"markdown","4f722910":"markdown","c031fc87":"markdown","a29660c5":"markdown","f6e000a5":"markdown","0f663ed1":"markdown","f1f844d9":"markdown","809b007b":"markdown","c8416464":"markdown","8911cad6":"markdown","7defe963":"markdown","de49ed7d":"markdown","9273ec30":"markdown","2b8dc9fe":"markdown","3bc80b2d":"markdown","23836d89":"markdown","586ff1ea":"markdown","ec4f0310":"markdown","03364fdb":"markdown"},"source":{"621f8966":"from __future__ import print_function, division","5e6c72c3":"import numpy as np\n# make a 3,3 array with ones in every position\nnp.ones((3,3))","59a99cd8":"a = np.arange(0, 25) # create a vector from 0 to 24\nprint('a',a)","5e990bb5":"b = a.reshape((5,5)) # shape the array into a 5x5 matrix instead of a vector\nprint('b_shape', b.shape) # each numpy array has a property called shape which gives you the dimensions\nprint('b',b)","2fd903c3":"import matplotlib.pyplot as plt\n# we can now show all the functions in plt by using the dir command. \n# The ones relevant for us are subplot and imshow\nprint(','.join(dir(plt)))","dda7f878":"%matplotlib inline\nplt.plot(a)","348f2f89":"plt.hist(a, bins = 5)","0af117bd":"# since that was a really boring histogram, we can make a normal distribution with 1000 points\nnorm_dist = np.random.normal(0, 25, size=(1000))\nplt.hist(norm_dist, bins = 10)","0cda7e4d":"plt.imshow(b)","62d09e0b":"plt.imshow(b, interpolation = 'none')","1de8db31":"from skimage import data\nimage = data.camera() # get the camera image from the scikit-image data\nplt.imshow(image, \n           cmap=plt.cm.gray) # we use a grayscale ma","cac5d5c9":"fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10, 5)) # make a new subplot figure with 2 axes\nax1.imshow(image, cmap=plt.cm.jet) # we can use a different color mapping scheme like jet (matlab's default)\nax1.set_title('Jet Colored Image')\nax1.axis('off') # turn off the axes lines\n\nimg1_ax = ax2.imshow(image, cmap = 'RdBu') # you can also specifiy color maps by name\nax2.set_title('Red Blue Image')\nax2.set_aspect(2) # change the aspect ratio to 2:1\nplt.colorbar(img1_ax) # show a color bar for the second image only","69f4c097":"from skimage.filters import threshold_otsu\n\n\nimage = data.camera()\nthresh = threshold_otsu(image)\nbinary = image > thresh\n\nfig, axes = plt.subplots(ncols=3, figsize=(8, 2.5))\nax = axes.ravel()\nax[0] = plt.subplot(1, 3, 1, adjustable='box-forced')\nax[1] = plt.subplot(1, 3, 2)\nax[2] = plt.subplot(1, 3, 3, sharex=ax[0], sharey=ax[0], adjustable='box-forced')\n\nax[0].imshow(image, cmap=plt.cm.gray)\nax[0].set_title('Original')\nax[0].axis('off')\n\nax[1].hist(image.ravel(), bins=256)\nax[1].set_title('Histogram')\nax[1].axvline(thresh, color='r')\n\nax[2].imshow(binary, cmap=plt.cm.gray)\nax[2].set_title('Thresholded')\nax[2].axis('off')\n\nplt.show()","e68f60a5":"try:\n    from skimage.filters import try_all_threshold\n\n    img = data.page()\n\n    # Here, we specify a radius for local thresholding algorithms.\n    # If it is not specified, only global algorithms are called.\n    fig, ax = try_all_threshold(img, figsize=(10, 8), verbose=False)\n    plt.show()\nexcept ImportError:\n    from warnings import warn\n    warn('The current version of skimage does not support this feature, sorry', RuntimeWarning)","e5a3b7ff":"import os\nfrom skimage.data import data_dir\nfrom skimage.util import img_as_ubyte\nfrom skimage import io\n\norig_phantom = img_as_ubyte(io.imread(os.path.join(data_dir, \"phantom.png\"),\n                                      as_grey=True))\nfig, ax = plt.subplots()\nax.imshow(orig_phantom, cmap=plt.cm.gray)","44307ae4":"def plot_comparison(original, filtered, filter_name):\n\n    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(8, 4), sharex=True,\n                                   sharey=True)\n    ax1.imshow(original, cmap=plt.cm.gray)\n    ax1.set_title('original')\n    ax1.axis('off')\n    ax1.set_adjustable('box-forced')\n    ax2.imshow(filtered, cmap=plt.cm.gray)\n    ax2.set_title(filter_name)\n    ax2.axis('off')\n    ax2.set_adjustable('box-forced')","466c75ec":"from skimage.morphology import erosion, dilation, opening, closing, white_tophat\nfrom skimage.morphology import black_tophat \nfrom skimage.morphology import disk\n\nselem = disk(6)\neroded = erosion(orig_phantom, selem)\nplot_comparison(orig_phantom, eroded, 'erosion')","050c60ee":"dilated = dilation(orig_phantom, selem)\nplot_comparison(orig_phantom, dilated, 'dilation')","775748fa":"opened = opening(orig_phantom, selem)\nplot_comparison(orig_phantom, opened, 'opening')","f92f33bd":"phantom = orig_phantom.copy()\nphantom[10:30, 200:210] = 0\n\nclosed = closing(phantom, selem)\nplot_comparison(phantom, closed, 'closing')","de57b28d":"phantom = orig_phantom.copy()\nphantom[340:350, 200:210] = 255\nphantom[100:110, 200:210] = 0\n\nw_tophat = white_tophat(phantom, selem)\nplot_comparison(phantom, w_tophat, 'white tophat')","9ece50b3":"b_tophat = black_tophat(phantom, selem)\nplot_comparison(phantom, b_tophat, 'black tophat')","422ddaff":"from scipy import ndimage as ndi\nfrom skimage import feature\n\n\n# Generate noisy image of a square\nim = np.zeros((128, 128))\nim[32:-32, 32:-32] = 1\n\nim = ndi.rotate(im, 15, mode='constant')\nim = ndi.gaussian_filter(im, 4)\nim += 0.2 * np.random.random(im.shape)\n\n# Compute the Canny filter for two values of sigma\nedges1 = feature.canny(im)\nedges2 = feature.canny(im, sigma=3)\n\n# display results\nfig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(8, 3),\n                                    sharex=True, sharey=True)\n\nax1.imshow(im, cmap=plt.cm.gray)\nax1.axis('off')\nax1.set_title('noisy image', fontsize=20)\n\nax2.imshow(edges1, cmap=plt.cm.gray)\nax2.axis('off')\nax2.set_title('Canny filter, $\\sigma=1$', fontsize=20)\n\nax3.imshow(edges2, cmap=plt.cm.gray)\nax3.axis('off')\nax3.set_title('Canny filter, $\\sigma=3$', fontsize=20)\n\nfig.tight_layout()\n\nplt.show()","8d94e53c":"from scipy.ndimage import gaussian_filter\nfrom skimage import img_as_float\nfrom skimage.morphology import reconstruction\n\n# Convert to float: Important for subtraction later which won't work with uint8\nimage = img_as_float(data.coins())\nimage = gaussian_filter(image, 1)\n\nseed = np.copy(image)\nseed[1:-1, 1:-1] = image.min()\nmask = image\n\ndilated = reconstruction(seed, mask, method='dilation')","0a22e47c":"fig, (ax0, ax1, ax2) = plt.subplots(nrows=1,\n                                    ncols=3,\n                                    figsize=(8, 2.5),\n                                    sharex=True,\n                                    sharey=True)\n\nax0.imshow(image, cmap='gray')\nax0.set_title('original image')\nax0.axis('off')\nax0.set_adjustable('box-forced')\n\nax1.imshow(dilated, vmin=image.min(), vmax=image.max(), cmap='gray')\nax1.set_title('dilated')\nax1.axis('off')\nax1.set_adjustable('box-forced')\n\nax2.imshow(image - dilated, cmap='gray')\nax2.set_title('image - dilated')\nax2.axis('off')\nax2.set_adjustable('box-forced')\n\nfig.tight_layout()","cc5cdf29":"h = 0.4\nseed = image - h\ndilated = reconstruction(seed, mask, method='dilation')\nhdome = image - dilated","2992e031":"fig, (ax0, ax1, ax2) = plt.subplots(nrows=1, ncols=3, figsize=(8, 2.5))\nyslice = 197\n\nax0.plot(mask[yslice], '0.5', label='mask')\nax0.plot(seed[yslice], 'k', label='seed')\nax0.plot(dilated[yslice], 'r', label='dilated')\nax0.set_ylim(-0.2, 2)\nax0.set_title('image slice')\nax0.set_xticks([])\nax0.legend()\n\nax1.imshow(dilated, vmin=image.min(), vmax=image.max(), cmap='gray')\nax1.axhline(yslice, color='r', alpha=0.4)\nax1.set_title('dilated')\nax1.axis('off')\n\nax2.imshow(hdome, cmap='gray')\nax2.axhline(yslice, color='r', alpha=0.4)\nax2.set_title('image - dilated')\nax2.axis('off')\n\nfig.tight_layout()\nplt.show()","bd41b1f0":"from skimage import measure\n\n\n# Construct some test data\nx, y = np.ogrid[-np.pi:np.pi:100j, -np.pi:np.pi:100j]\nr = np.sin(np.exp((np.sin(x)**3 + np.cos(y)**2)))\n\n# Find contours at a constant value of 0.8\ncontours = measure.find_contours(r, 0.8)\n\n# Display the image and plot all contours found\nfig, ax = plt.subplots()\nax.imshow(r, interpolation='nearest', cmap=plt.cm.gray)\n\nfor n, contour in enumerate(contours):\n    ax.plot(contour[:, 1], contour[:, 0], linewidth=2)\n\nax.axis('image')\nax.set_xticks([])\nax.set_yticks([])\nplt.show()","43e2bdb9":"from skimage.morphology import watershed\nfrom skimage.feature import peak_local_max\n\n\n# Generate an initial image with two overlapping circles\nx, y = np.indices((80, 80))\nx1, y1, x2, y2 = 28, 28, 44, 52\nr1, r2 = 16, 20\nmask_circle1 = (x - x1)**2 + (y - y1)**2 < r1**2\nmask_circle2 = (x - x2)**2 + (y - y2)**2 < r2**2\nimage = np.logical_or(mask_circle1, mask_circle2)\n\n# Now we want to separate the two objects in image\n# Generate the markers as local maxima of the distance to the background\ndistance = ndi.distance_transform_edt(image)\nlocal_maxi = peak_local_max(distance, indices=False, footprint=np.ones((3, 3)),\n                            labels=image)\nmarkers = ndi.label(local_maxi)[0]\nlabels = watershed(-distance, markers, mask=image)\n\nfig, axes = plt.subplots(ncols=3, figsize=(9, 3), sharex=True, sharey=True,\n                         subplot_kw={'adjustable': 'box-forced'})\nax = axes.ravel()\n\nax[0].imshow(image, cmap=plt.cm.gray, interpolation='nearest')\nax[0].set_title('Overlapping objects')\nax[1].imshow(-distance, cmap=plt.cm.gray, interpolation='nearest')\nax[1].set_title('Distances')\nax[2].imshow(labels, cmap=plt.cm.spectral, interpolation='nearest')\nax[2].set_title('Separated objects')\n\nfor a in ax:\n    a.set_axis_off()\n\nfig.tight_layout()\nplt.show()","242ce7bc":"from skimage.filters import rank\n\nimage = img_as_ubyte(data.camera())\n\n# denoise image\ndenoised = rank.median(image, disk(2))\n\n# find continuous region (low gradient -\n# where less than 10 for this image) --> markers\n# disk(5) is used here to get a more smooth image\nmarkers = rank.gradient(denoised, disk(5)) < 10\nmarkers = ndi.label(markers)[0]\n\n# local gradient (disk(2) is used to keep edges thin)\ngradient = rank.gradient(denoised, disk(2))\n\n# process the watershed\nlabels = watershed(gradient, markers)\n\n# display results\nfig, axes = plt.subplots(nrows=2, ncols=2, figsize=(8, 8), sharex=True, sharey=True, subplot_kw={'adjustable':'box-forced'})\nax = axes.ravel()\n\nax[0].imshow(image, cmap=plt.cm.gray, interpolation='nearest')\nax[0].set_title(\"Original\")\n\nax[1].imshow(gradient, cmap=plt.cm.spectral, interpolation='nearest')\nax[1].set_title(\"Local Gradient\")\n\nax[2].imshow(markers, cmap=plt.cm.spectral, interpolation='nearest')\nax[2].set_title(\"Markers\")\n\nax[3].imshow(image, cmap=plt.cm.gray, interpolation='nearest')\nax[3].imshow(labels, cmap=plt.cm.spectral, interpolation='nearest', alpha=.7)\nax[3].set_title(\"Segmented\")\n\nfor a in ax:\n    a.axis('off')\n\nfig.tight_layout()\nplt.show()","ef86aa53":"from skimage.transform import radon, rescale\n\nimage = io.imread(data_dir + \"\/phantom.png\", as_grey=True)\nimage = rescale(image, scale=0.4, mode='reflect')\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4.5))\n\nax1.set_title(\"Original\")\nax1.imshow(image, cmap=plt.cm.Greys_r)\n\ntheta = np.linspace(0., 180., max(image.shape), endpoint=False)\nsinogram = radon(image, theta=theta, circle=True)\nax2.set_title(\"Radon transform\\n(Sinogram)\")\nax2.set_xlabel(\"Projection angle (deg)\")\nax2.set_ylabel(\"Projection position (pixels)\")\nax2.imshow(sinogram, cmap=plt.cm.Greys_r,\n           extent=(0, 180, 0, sinogram.shape[0]), aspect='auto')\n\nfig.tight_layout()\nplt.show()","7314bdf4":"from skimage.transform import iradon\n\nreconstruction_fbp = iradon(sinogram, theta=theta, circle=True)\nerror = reconstruction_fbp - image\nprint('FBP rms reconstruction error: %.3g' % np.sqrt(np.mean(error**2)))\n\nimkwargs = dict(vmin=-0.2, vmax=0.2)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4.5),\n                               sharex=True, sharey=True,\n                               subplot_kw={'adjustable': 'box-forced'})\nax1.set_title(\"Reconstruction\\nFiltered back projection\")\nax1.imshow(reconstruction_fbp, cmap=plt.cm.Greys_r)\nax2.set_title(\"Reconstruction error\\nFiltered back projection\")\nax2.imshow(reconstruction_fbp - image, cmap=plt.cm.Greys_r, **imkwargs)\nplt.show()","b835c781":"Let's also define a convenience function for plotting comparisons:","f90fbe01":"Since ``closing`` an image starts with an dilation operation, dark regions\nthat are *smaller* than the structuring element are removed. The dilation\noperation that follows ensures that dark regions that are *larger* than the\nstructuring element retain their original size. Notice how the white\nellipses at the bottom get connected because of dilation, but other dark\nregion retain their original sizes. Also notice how the crack we added is\nmostly removed.\n\nWhite tophat\n============\n\nThe ``white_tophat`` of an image is defined as the *image minus its\nmorphological opening*. This operation returns the bright spots of the\nimage that are smaller than the structuring element.\n\nTo make things interesting, we'll add bright and dark spots to the image:","1a6bfd76":"As you can see in the image slice, each coin is given a different baseline\nintensity in the reconstructed image; this is because we used the local\nintensity (shifted by ``h``) as a seed value. As a result, the coins in the\nsubtracted image have similar pixel intensities. The final result is known\nas the h-dome of an image since this tends to isolate regional maxima of\nheight ``h``. This operation is particularly useful when your images are\nunevenly illuminated.","0676ce10":"# Numpy\nNumpy is a package for efficiently dealing with vector and matrix data. It has a high degree of similiarity to Matlab. We typically import the package as ```np``` since this is shorter to type ","9bb136bf":"As you can see, the 10-pixel wide white square is highlighted since it is\nsmaller than the structuring element. Also, the thin, white edges around\nmost of the ellipse are retained because they're smaller than the\nstructuring element, but the thicker region at the top disappears.\n\nBlack tophat\n============\n\nThe ``black_tophat`` of an image is defined as its morphological **closing\nminus the original image**. This operation returns the *dark spots of the\nimage that are smaller than the structuring element*.","518c2b24":"## Notes and Magic\nThe ```%matplotlib inline``` command is for use inside of Jupyter notebooks to show the figures in the notebook instead of opening a new figure window (the default when using python from the command line). Commands that start with a % are not normal python and are so-called _magic_ commands. They are just for use inside of jupyter notebooks. Another very useful magic command is ```%%time``` to show how long a time took to execute","0aecc2e5":"\n# Watershed segmentation\n\n\nThe watershed is a classical algorithm used for **segmentation**, that\nis, for separating different objects in an image.\n\nStarting from user-defined markers, the watershed algorithm treats\npixels values as a local topography (elevation). The algorithm floods\nbasins from the markers, until basins attributed to different markers\nmeet on watershed lines.  In many cases, markers are chosen as local\nminima of the image, from which basins are flooded.\n\nIn the example below, two overlapping circles are to be separated. To\ndo so, one computes an image that is the distance to the\nbackground. The maxima of this distance (i.e., the minima of the\nopposite of the distance) are chosen as markers, and the flooding of\nbasins from such markers separates the two circles along a watershed\nline.\n\nSee Wikipedia_ for more details on the algorithm.","7c6545c7":"# Showing Images\nImages can be shown using the ```imshow``` or ```matshow``` commands in ```plt```, for the most part we will focus on using the ```imshow``` command","93996c69":"# Morphological Filtering\n\n\nMorphological image processing is a collection of non-linear operations related\nto the shape or morphology of features in an image, such as boundaries,\nskeletons, etc. In any given technique, we probe an image with a small shape or\ntemplate called a structuring element, which defines the region of interest or\nneighborhood around a pixel.\n\nIn this document we outline the following basic morphological operations:\n\n1. Erosion\n2. Dilation\n3. Opening\n4. Closing\n5. White Tophat\n6. Black Tophat\n7. Skeletonize\n8. Convex Hull\n\n\nTo get started, let's load an image using ``io.imread``. Note that morphology\nfunctions only work on gray-scale or binary images, so we set ``as_grey=True``.","ffb0e78b":"\n# Thresholding\n\n\nThresholding is used to create a binary image from a grayscale image [1]_.\n\n.. [1] https:\/\/en.wikipedia.org\/wiki\/Thresholding_%28image_processing%29\n\n.. seealso::\n    A more comprehensive presentation on\n    `sphx_glr_auto_examples_xx_applications_plot_thresholding.py`\n\n","b8ad9800":"Notice how the white boundary of the image disappears or gets eroded as we\n increase the size of the disk. Also notice the increase in size of the two\n black ellipses in the center and the disappearance of the 3 light grey\n patches in the lower part of the image.\n\nDilation\n========\n\nMorphological ``dilation`` sets a pixel at (i, j) to the *maximum over all\npixels in the neighborhood centered at (i, j)*. Dilation enlarges bright\nregions and shrinks dark regions.","0b0b2443":"Subtracting the dilated image leaves an image with just the coins and a\nflat, black background, as shown below.","7ba6a7c8":"Notice how the white boundary of the image thickens, or gets dilated, as we\nincrease the size of the disk. Also notice the decrease in size of the two\nblack ellipses in the centre, and the thickening of the light grey circle\nin the center and the 3 patches in the lower part of the image.\n\nOpening\n=======\n\nMorphological ``opening`` on an image is defined as an *erosion followed by\na dilation*. Opening can remove small bright spots (i.e. \"salt\") and\nconnect small dark cracks.","a7faea35":"# Plots and figures with Matplotlib\nMatplotlib is a very helpful library for plotting graphs and displaying images. It is built to resemble to plotting tools in Matlab (hence the name). Typically we will load the ```pyplot``` sub-package and abbreviate it as ```plt``` this is done by a modified import command","87cce1f8":"If you are not familiar with the details of the different algorithms and the\nunderlying assumptions, it is often difficult to know which algorithm will give\nthe best results. Therefore, Scikit-image includes a function to evaluate\nthresholding algorithms provided by the library. At a glance, you can select\nthe best algorithm for you data without a deep understanding of their\nmechanisms.\n\n","4f722910":"# Python\nThere are two major versions of Python (3). While most projects and new developers are using 3, a number of tooboxes still have not been converted and even a few major players like Google and Kitware (Slicer, Paraview) are still using version 2. My recommendation would be to start using Python 3 but to write in a backwards compatible manner. ","c031fc87":"\n# Markers for watershed transform\n\n\nThe watershed is a classical algorithm used for **segmentation**, that\nis, for separating different objects in an image.\n\nHere a marker image is built from the region of low gradient inside the image.\nIn a gradient image, the areas of high values provide barriers that help to\nsegment the image.\nUsing markers on the lower values will ensure that the segmented objects are\nfound.\n\nSee Wikipedia_ for more details on the algorithm.","a29660c5":"Erosion\n=======\n\nMorphological ``erosion`` sets a pixel at (i, j) to the *minimum over all\npixels in the neighborhood centered at (i, j)*. The structuring element,\n``selem``, passed to ``erosion`` is a boolean array that describes this\nneighborhood. Below, we use ``disk`` to create a circular structuring\nelement, which we use for most of the following examples.","f6e000a5":"Although the features (i.e. the coins) are clearly isolated, the coins\nsurrounded by a bright background in the original image are dimmer in the\nsubtracted image. We can attempt to correct this using a different seed\nimage.\n\nInstead of creating a seed image with maxima along the image border, we can\nuse the features of the image itself to seed the reconstruction process.\nHere, the seed image is the original image minus a fixed value, ``h``.","0f663ed1":"# Controlling Figures\nWe see the figure looks fine, but if we want to give it a title and turn off the axes, we need to learn a bit more about the plot settings","f1f844d9":"\n# Radon transform\n\n\nIn computed tomography, the tomography reconstruction problem is to obtain\na tomographic slice image from a set of projections [1]_. A projection is\nformed by drawing a set of parallel rays through the 2D object of interest,\nassigning the integral of the object's contrast along each ray to a single\npixel in the projection. A single projection of a 2D object is one dimensional.\nTo enable computed tomography reconstruction of the object, several projections\nmust be acquired, each of them corresponding to a different angle between the\nrays with respect to the object. A collection of projections at several angles\nis called a sinogram, which is a linear transform of the original image.\n\nThe inverse Radon transform is used in computed tomography to reconstruct\na 2D image from the measured projections (the sinogram). A practical, exact\nimplementation of the inverse Radon transform does not exist, but there are\nseveral good approximate algorithms available.\n\nAs the inverse Radon transform reconstructs the object from a set of\nprojections, the (forward) Radon transform can be used to simulate a\ntomography experiment.\n\nThis script performs the Radon transform to simulate a tomography experiment\nand reconstructs the input image based on the resulting sinogram formed by\nthe simulation. Two methods for performing the inverse Radon transform\nand reconstructing the original image are compared: The Filtered Back\nProjection (FBP) and the Simultaneous Algebraic Reconstruction\nTechnique (SART).\n\nFor further information on tomographic reconstruction, see\n\n.. [1] AC Kak, M Slaney, \"Principles of Computerized Tomographic Imaging\",\n       IEEE Press 1988. http:\/\/www.slaney.org\/pct\/pct-toc.html\n\n.. [2] Wikipedia, Radon transform,\n       http:\/\/en.wikipedia.org\/wiki\/Radon_transform#Relationship_with_the_Fourier_transform\n\n.. [3] S Kaczmarz, \"Angenaeherte Aufloesung von Systemen linearer\n       Gleichungen\", Bulletin International de l'Academie Polonaise\n       des Sciences et des Lettres, 35 pp 355--357 (1937)\n\n.. [4] AH Andersen, AC Kak, \"Simultaneous algebraic reconstruction\n       technique (SART): a superior implementation of the ART algorithm\",\n       Ultrasonic Imaging 6 pp 81--94 (1984)\n\nThe forward transform\n=====================\n\nAs our original image, we will use the Shepp-Logan phantom. When calculating\nthe Radon transform, we need to decide how many projection angles we wish\nto use. As a rule of thumb, the number of projections should be about the\nsame as the number of pixels there are across the object (to see why this\nis so, consider how many unknown pixel values must be determined in the\nreconstruction process and compare this to the number of measurements\nprovided by the projections), and we follow that rule here. Below is the\noriginal image and its Radon transform, often known as its *sinogram*:\n\n","809b007b":"Reconstruction with the Filtered Back Projection (FBP)\n======================================================\n\nThe mathematical foundation of the filtered back projection is the Fourier\nslice theorem [2]_. It uses Fourier transform of the projection and\ninterpolation in Fourier space to obtain the 2D Fourier transform of the\nimage, which is then inverted to form the reconstructed image. The filtered\nback projection is among the fastest methods of performing the inverse\nRadon transform. The only tunable parameter for the FBP is the filter,\nwhich is applied to the Fourier transformed projections. It may be used to\nsuppress high frequency noise in the reconstruction. ``skimage`` provides a\nfew different options for the filter.\n\n","c8416464":"We illustrate how to apply one of these thresholding algorithms.\nOtsu's method [2]_ calculates an \"optimal\" threshold (marked by a red line in the\nhistogram below) by maximizing the variance between two classes of pixels,\nwhich are separated by the threshold. Equivalently, this threshold minimizes\nthe intra-class variance.\n\n.. [2] http:\/\/en.wikipedia.org\/wiki\/Otsu's_method\n\n","8911cad6":"\n# Contour finding\n\n\nWe use a marching squares method to find constant valued contours in an image.\nIn ``skimage.measure.find_contours``, array values are linearly interpolated\nto provide better precision of the output contours. Contours which intersect\nthe image edge are open; all others are closed.\n\nThe `marching squares algorithm\n<http:\/\/www.essi.fr\/~lingrand\/MarchingCubes\/algo.html>`__ is a special case of\nthe marching cubes algorithm (Lorensen, William and Harvey E. Cline. Marching\nCubes: A High Resolution 3D Surface Construction Algorithm. Computer Graphics\n(SIGGRAPH 87 Proceedings) 21(4) July 1987, p. 163-170).","7defe963":"# Show an image\nHere we start to use the scikit-image (_skimage_) package. The package includes some test images to make getting started a bit easier","de49ed7d":"### Histogram\nWe can also make a histogram using matplotlib using the ```hist``` function.","9273ec30":"\n# Canny edge detector\n\n\nThe Canny filter is a multi-stage edge detector. It uses a filter based on the\nderivative of a Gaussian in order to compute the intensity of the gradients.The\nGaussian reduces the effect of noise present in the image. Then, potential\nedges are thinned down to 1-pixel curves by removing non-maximum pixels of the\ngradient magnitude. Finally, edge pixels are kept or removed using hysteresis\nthresholding on the gradient magnitude.\n\nThe Canny has three adjustable parameters: the width of the Gaussian (the\nnoisier the image, the greater the width), and the low and high threshold for\nthe hysteresis thresholding.\n\n\n","2b8dc9fe":"Since ``opening`` an image starts with an erosion operation, light regions\nthat are *smaller* than the structuring element are removed. The dilation\noperation that follows ensures that light regions that are *larger* than\nthe structuring element retain their original size. Notice how the light\nand dark shapes in the center their original thickness but the 3 lighter\npatches in the bottom get completely eroded. The size dependence is\nhighlighted by the outer white ring: The parts of the ring thinner than the\nstructuring element were completely erased, while the thicker region at the\ntop retains its original thickness.\n\nClosing\n=======\n\nMorphological ``closing`` on an image is defined as a *dilation followed by\nan erosion*. Closing can remove small dark spots (i.e. \"pepper\") and\nconnect small bright cracks.\n\nTo illustrate this more clearly, let's add a small crack to the white\nborder:","3bc80b2d":"\n# Filtering regional maxima\n\n\nHere, we use morphological reconstruction to create a background image, which\nwe can subtract from the original image to isolate bright features (regional\nmaxima).\n\nFirst we try reconstruction by dilation starting at the edges of the image. We\ninitialize a seed image to the minimum intensity of the image, and set its\nborder to be the pixel values in the original image. These maximal pixels will\nget dilated in order to reconstruct the background image.","23836d89":"To get a feel for the reconstruction process, we plot the intensity of the\nmask, seed, and dilated images along a slice of the image (indicated by red\nline).","586ff1ea":"Here we start with a python notebook. The very first lines of a python script or notebook need to be the ```___future___``` commands since they change they way the rest of the lines are interpreted. The future commands are very important because they cause python 2 to behave more like python 3. The lines will be ignored in python 3. These two commands you should include in every file or notebook. \n### print_function\nThe print_function forces you to type ```print('hello')``` instead of ```print 'hello'``` the former works in both 2 and 3 while the later only works in 2.\n### division\nThis is very important and causes division of two round (integer) numbers to return a decimal (float) instead of a round number. If it is turned off\n```\n>>> 3\/4\n0\n```\nif it is turned on \n```\n>>> from __future__ import division\n>>> 3\/4\n0.75\n```","ec4f0310":"# Reconstruction Algorithms\nHere is a brief introduction to reconstruction algorithms. The following examples are from X-ray tomography but can be applied in other areas.","03364fdb":"The we know the image should be 25 pixels ranging between 0 and 25 but it shows up as a nice smooth graphic, did we do something wrong?\n\n- Yes, the default settings of matplotlib sometimes have the interpolation parameter set to something that makes the images appear higher resolution or smoother than the really are. We want to make sure that we show the image with this set to 'none'"}}