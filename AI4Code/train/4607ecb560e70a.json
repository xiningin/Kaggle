{"cell_type":{"13c2fe58":"code","db447353":"code","38601b6e":"code","4ad4b5c5":"code","1a52110a":"code","626bda23":"code","718ab0bc":"code","bec924d0":"code","3872d35a":"code","3ef7e8c3":"code","dd41ba3d":"code","71ec2d5f":"code","69adb0a9":"code","5e5c1152":"code","0aba1d83":"code","0a6fe3a7":"code","b0aac50b":"markdown"},"source":{"13c2fe58":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","db447353":"import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image","38601b6e":"plt.style.use(\"ggplot\")\n%matplotlib inline","4ad4b5c5":"main_train_dir = os.path.join(\"\/kaggle\/input\/indian-currency-notes-classifier\/Train\/\")\nmain_test_dir = os.path.join(\"\/kaggle\/input\/indian-currency-notes-classifier\/Test\/\")\n\nprint(main_train_dir)\nprint(main_test_dir)","1a52110a":"two_thousand_dir = os.path.join(\"\/kaggle\/input\/indian-currency-notes-classifier\/Train\/2Thousandnote\/\")\nfive_hundered_dir = os.path.join(\"\/kaggle\/input\/indian-currency-notes-classifier\/Train\/5Hundrednote\/\")\ntwo_hundered_dir = os.path.join(\"\/kaggle\/input\/indian-currency-notes-classifier\/Train\/2Hundrednote\/\")\none_hundered_dir = os.path.join(\"\/kaggle\/input\/indian-currency-notes-classifier\/Train\/1Hundrednote\/\")\nfifty_dir = os.path.join(\"\/kaggle\/input\/indian-currency-notes-classifier\/Train\/Fiftynote\/\")\ntwenty_dir = os.path.join(\"\/kaggle\/input\/indian-currency-notes-classifier\/Train\/Twentynote\/\")\nten_dir = os.path.join(\"\/kaggle\/input\/indian-currency-notes-classifier\/Train\/Tennote\/\")","626bda23":"two_thousand_names = os.listdir(two_thousand_dir)\nfive_hundered_names = os.listdir(five_hundered_dir)\ntwo_hundered_names = os.listdir(two_hundered_dir)\none_hundered_names = os.listdir(one_hundered_dir)\nfifty_names = os.listdir(fifty_dir)\ntwenty_names = os.listdir(twenty_dir)\nten_names = os.listdir(ten_dir)\n\n\nprint(two_thousand_names[:10])\nprint(five_hundered_names[:10])\nprint(two_hundered_names[:10])\nprint(one_hundered_names[:10])\nprint(fifty_names[:10])\nprint(twenty_names[:10])\nprint(ten_names[:10])","718ab0bc":"print(f\"total training of 2Thousand Notes : {len(two_thousand_names)}\")\nprint(f\"total training of 5Hundered Notes : {len(five_hundered_names)}\")\nprint(f\"total training of 2Hundered Notes : {len(two_hundered_names)}\")\nprint(f\"total training of 1Hundered Notes: {len(one_hundered_names)}\")\nprint(f\"total training of 50Notes : {len(fifty_names)}\")\nprint(f\"total training of 20Notes : {len(twenty_names)}\")\nprint(f\"total training of 10Notes : {len(ten_names)}\")","bec924d0":"# parameters for graph we'll output images in a 4x4\nnrows = 4\nncols = 4\n\n# Index for iterating over images\npic_index = 0","3872d35a":"# set up matplotlib fig, and size it to fit 4x4 pics\nfig = plt.gcf()\nfig.set_size_inches(ncols * 2, nrows * 2)\n\npic_index += 8\n\ntwo_thousand_pix = [os.path.join(two_thousand_dir, fname) \n                for fname in two_thousand_names[pic_index-8:pic_index]]\n\nfive_hundered_pix = [os.path.join(five_hundered_dir, fname) \n                for fname in five_hundered_names[pic_index-8:pic_index]]\n\n\nfor i, img in enumerate(two_thousand_pix + five_hundered_pix):\n    sub_plot = plt.subplot(nrows, ncols, i + 1)\n    sub_plot.axis(\"Off\")\n    img_read = mpimg.imread(img)\n    plt.imshow(img_read)\n    \nplt.show()","3ef7e8c3":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", input_shape=(150,150,3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\"),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\"),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\"),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=\"relu\"),\n    tf.keras.layers.Dense(7, activation=\"softmax\")\n])","dd41ba3d":"model.summary()","71ec2d5f":"model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","69adb0a9":"train_datagen = ImageDataGenerator(rescale=1\/255)\nvalidation_datagen = ImageDataGenerator(rescale=1\/255)\n\n# Flow training images in batches of 128 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(main_train_dir,\n                                                   batch_size=64,\n                                                   target_size=(150,150),\n                                                   class_mode=\"categorical\")\n\nvalidation_generator = validation_datagen.flow_from_directory(main_test_dir,\n                                                             batch_size=16,\n                                                              target_size=(150,150),\n                                                             class_mode=\"categorical\")","5e5c1152":"history = model.fit(train_generator,   \n                    epochs=100,\n                    steps_per_epoch=len(train_generator),\n                    verbose=1,\n                    validation_data=validation_generator,\n                    validation_steps=len(validation_generator))","0aba1d83":"acc = history.history[\"accuracy\"]\nval_acc = history.history[\"val_accuracy\"]\n\nloss = history.history[\"loss\"]\nval_loss = history.history[\"val_loss\"]\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, \"r\", label=\"Training Accuracy\")\nplt.plot(epochs, val_acc, \"b\", label=\"Validation Accuracy\")\n\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, \"r\", label=\"Training Loss\")\nplt.plot(epochs, val_loss, \"b\", label=\"Validation Loss\")\n\nplt.legend()\nplt.show()","0a6fe3a7":"path = \"\/kaggle\/input\/rupees\/2.jpg\"\nimg = image.load_img(path, target_size=(150, 150))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\n\nimages = np.vstack([x])\nclasses = model.predict_classes(images, batch_size=10)\n\n\n\nif classes[0] == 1:\n    print(path + \" is Two Thousand Rupees\")\nelif classes[0] == 2:\n    print(path + \" is Five Hundered Rupees\")\nelif classes[0] == 3:\n    print(path + \" is Two Hundered Rupees\")\nelif classes[0] == 4:\n    print(path, + \" is One Hundered Rupees\")\nelif classes[0] == 5:\n    print(path + \"is Fifty Rupees\")\nelif classes[0] == 6:\n    print(path + \" is Twenty Rupees\")\nelse:\n    print(path + \" is Ten Rupees\")\n    \nimg = mpimg.imread(path)\nplt.imshow(img)\nplt.show()","b0aac50b":"## If You Find Helpful Please Upvote"}}