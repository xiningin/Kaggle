{"cell_type":{"dec277b6":"code","d28bbe49":"code","9438c3a6":"code","a7848a38":"code","36538824":"code","bac1f792":"code","ddfd885f":"code","64589bc8":"code","ce98c4d9":"code","f80f386f":"code","367b6709":"code","c14dfb29":"code","6ecae4a6":"code","97a63786":"code","89f1d906":"code","70a8438f":"code","e1e847c3":"markdown","b01ef492":"markdown","cc701d0b":"markdown","407f800c":"markdown","72fc5339":"markdown","d106343b":"markdown","9a1c2dda":"markdown","1d52e48c":"markdown","726ab676":"markdown","e33bfeaa":"markdown","d74cadd1":"markdown","0bfe7270":"markdown","97ef3047":"markdown","63a4329a":"markdown","c3e05f8c":"markdown","2115094a":"markdown","18cde193":"markdown","819b518a":"markdown","bddbcc00":"markdown","9b6ea511":"markdown","b75655b5":"markdown","a7fdebcf":"markdown","7306075a":"markdown"},"source":{"dec277b6":"print(\"\\n... IMPORTS STARTING ...\\n\")\nprint(\"\\n\\tVERSION INFORMATION\")\n# Machine Learning and Data Science Imports\nimport tensorflow as tf; print(f\"\\t\\t\u2013 TENSORFLOW VERSION: {tf.__version__}\");\nimport tensorflow_addons as tfa; print(f\"\\t\\t\u2013 TENSORFLOW ADDONS VERSION: {tfa.__version__}\");\nimport pandas as pd; pd.options.mode.chained_assignment = None;\nimport numpy as np; print(f\"\\t\\t\u2013 NUMPY VERSION: {np.__version__}\");\nimport sklearn; print(f\"\\t\\t\u2013 SKLEARN VERSION: {sklearn.__version__}\");\nfrom sklearn.preprocessing import RobustScaler, PolynomialFeatures\nfrom sklearn.model_selection import GroupKFold;\n\n# Built In Imports\nfrom kaggle_datasets import KaggleDatasets\nfrom collections import Counter\nfrom datetime import datetime\nfrom glob import glob\nimport warnings\nimport requests\nimport imageio\nimport IPython\nimport sklearn\nimport urllib\nimport zipfile\nimport pickle\nimport random\nimport shutil\nimport string\nimport math\nimport time\nimport gzip\nimport ast\nimport sys\nimport io\nimport os\nimport gc\nimport re\n\n# Visualization Imports\nfrom matplotlib.colors import ListedColormap\nimport matplotlib.patches as patches\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm; tqdm.pandas();\nimport plotly.express as px\nimport seaborn as sns\nfrom PIL import Image\nimport matplotlib; print(f\"\\t\\t\u2013 MATPLOTLIB VERSION: {matplotlib.__version__}\");\nimport plotly\nimport PIL\nimport cv2\n\n\ndef seed_it_all(seed=7):\n    \"\"\" Attempt to be Reproducible \"\"\"\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\n    \nprint(\"\\n\\n... IMPORTS COMPLETE ...\\n\")\n    \nprint(\"\\n... SEEDING FOR DETERMINISTIC BEHAVIOUR ...\\n\")\nseed_it_all()","d28bbe49":"print(f\"\\n... ACCELERATOR SETUP STARTING ...\\n\")\n\n# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  \nexcept ValueError:\n    TPU = None\n\nif TPU:\n    print(f\"\\n... RUNNING ON TPU - {TPU.master()}...\")\n    tf.config.experimental_connect_to_cluster(TPU)\n    tf.tpu.experimental.initialize_tpu_system(TPU)\n    strategy = tf.distribute.experimental.TPUStrategy(TPU)\nelse:\n    print(f\"\\n... RUNNING ON CPU\/GPU ...\")\n    # Yield the default distribution strategy in Tensorflow\n    #   --> Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy() \n\n# What Is a Replica?\n#    --> A single Cloud TPU device consists of FOUR chips, each of which has TWO TPU cores. \n#    --> Therefore, for efficient utilization of Cloud TPU, a program should make use of each of the EIGHT (4x2) cores. \n#    --> Each replica is essentially a copy of the training graph that is run on each core and \n#        trains a mini-batch containing 1\/8th of the overall batch size\nN_REPLICAS = strategy.num_replicas_in_sync\n    \nprint(f\"... # OF REPLICAS: {N_REPLICAS} ...\\n\")\n\nprint(f\"\\n... ACCELERATOR SETUP COMPLTED ...\\n\")","9438c3a6":"print(\"\\n... DATA ACCESS SETUP STARTED ...\\n\")\n\nif TPU:\n    # Google Cloud Dataset path to training and validation images\n    DATA_DIR = KaggleDatasets().get_gcs_path('ventilator-pressure-prediction')\n    save_locally = tf.saved_model.SaveOptions(experimental_io_device='\/job:localhost')\nelse:\n    # Local path to training and validation images\n    DATA_DIR = \"\/kaggle\/input\/ventilator-pressure-prediction\"\n    save_locally = None\n    \nprint(f\"\\n... DATA DIRECTORY PATH IS:\\n\\t--> {DATA_DIR}\")\n\nprint(f\"\\n... IMMEDIATE CONTENTS OF DATA DIRECTORY IS:\")\nfor file in tf.io.gfile.glob(os.path.join(DATA_DIR, \"*\")): print(f\"\\t--> {file}\")\n\n    \nprint(\"\\n\\n... DATA ACCESS SETUP COMPLETED ...\\n\")","a7848a38":"MODEL_DIR = \"\/kaggle\/input\/vpp-synthetic-adventure-lstm-w-sofia-features\"\nN_FOLDS = 6\n\nprint(\"\\n... BASIC DATA SETUP STARTING ...\\n\\n\")\n\nprint(\"\\n... TRAIN DATAFRAME ...\\n\")\nTRAIN_CSV = os.path.join(DATA_DIR, \"train.csv\")\ntrain_df = pd.read_csv(TRAIN_CSV)\ndisplay(train_df)\n\nprint(\"\\n... VAL DATAFRAMES ...\\n\")\nfold_val_df_map = {\n    f\"fold_{i}\":pd.read_csv(os.path.join(MODEL_DIR, f\"fold_{i}_val.csv\")) \\\n    for i in range(N_FOLDS)\n}\ndisplay(fold_val_df_map[\"fold_0\"])\n\nprint(\"\\n... TEST DATAFRAME ..\\n\")\nTEST_CSV = os.path.join(DATA_DIR, \"test.csv\")\ntest_df = pd.read_csv(TEST_CSV)\ndisplay(test_df)\n\n# Get some basic breath information\nN_TRAIN_BREATHS = len(train_df.groupby(\"breath_id\").count())\nN_TEST_BREATHS = len(test_df.breath_id.value_counts())\nROWS_PER_BREATH = 80\n\nprint(\"\\n... SAMPLE SUBMISSION DATAFRAME ..\\n\")\nSS_CSV = os.path.join(DATA_DIR, \"sample_submission.csv\")\nss_df = pd.read_csv(SS_CSV)\ndisplay(ss_df)\n\n# Set Other Variables\nprint(\"\\n... SETTING OTHER VARIABLES ..\\n\")\n\nPOSSIBLE_PRESSURES = sorted(np.array(train_df.pressure.value_counts().keys()))\nAPPROX_PRESSURE_DELTA_STEP = 0.0703021454512\n\nREPLICA_BATCH_SIZE=64\nOVERALL_BATCH_SIZE=N_REPLICAS*REPLICA_BATCH_SIZE\n\nprint(\"\\n\\n... BASIC DATA SETUP FINISHING ...\\n\")","36538824":"print(f\"\\n... XLA OPTIMIZATIONS STARTING ...\\n\")\n\nprint(f\"\\n... CONFIGURE JIT (JUST IN TIME) COMPILATION ...\\n\")\n# enable XLA optmizations (10% speedup when using @tf.function calls)\ntf.config.optimizer.set_jit(True)\n\nprint(f\"\\n... XLA OPTIMIZATIONS COMPLETED ...\\n\")","bac1f792":"def flatten_l_o_l(nested_list):\n    \"\"\" Flatten a list of lists \"\"\"\n    return [item for sublist in nested_list for item in sublist]\n\ndef add_features(df, \n                 U_IN_N_FORWARD=7, \n                 U_IN_N_BACKWARD=7, \n                 U_OUT_N_FORWARD=2, \n                 U_OUT_N_BACKWARD=2, \n                 V_0=1, p_0=1, r_0=1, use_rc=True):\n    \"\"\" TBD \"\"\"\n    \n    # From Paper\n    df['measured_volume'] = (V_0+df[\"u_in\"]*df[\"time_step\"].diff()).fillna(0) + V_0\n\n    # From Paper\n    r_t = (3*df[\"measured_volume\"]\/4\/np.pi)**(1\/3)\n    df[\"measured_pressure\"] = (p_0 + (1-(r_t\/r_0)**6)*1\/(r_t*r_0**2)).fillna(0) + p_0\n    \n    # Features\n    print(\"\\n... Add general features ...\\n\")\n    df['uin_auc'] = df['time_step'] * df['u_in']\n    df['uin_auc'] = df.groupby('breath_id')['uin_auc'].cumsum()\n    df['uin_csum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    df['cross3']= df['time_step']*df['u_in']\n    df['cross3_sqd_1']= df['time_step']*df['u_in']**2\n    df['cross3_sqd_2']= df['time_step']**2*df['u_in']\n    df['cross3_cubed_1']= df['time_step']*df['u_in']**3\n    df['cross3_cubed_2']= df['time_step']**3*df['u_in']\n\n    \n    # Uin Lag\n    print(\"\\t... Add lag and advance UIN features ...\")\n    for i in range(1, U_IN_N_BACKWARD+1):\n        df[f'u_in_{i}_back'] = df.groupby(\"breath_id\")['u_in'].shift(i).fillna(0)\n    for i in range(1, U_IN_N_FORWARD+1):\n        df[f'u_in_{i}_forw'] = df.groupby(\"breath_id\")['u_in'].shift(-i).fillna(0)\n    \n    print(\"\\t... Add lag and advance UOUT features ...\")\n    for i in range(1, U_OUT_N_BACKWARD+1):\n        df[f'u_out_{i}_back'] = df.groupby(\"breath_id\")['u_out'].shift(i).fillna(0)\n    for i in range(1, U_OUT_N_FORWARD+1):\n        df[f'u_out_{i}_forw'] = df.groupby(\"breath_id\")['u_out'].shift(-i).fillna(0)\n    \n    print(\"\\t... Add UIN and UOUT `diff` features ...\")\n    for i in range(1, U_IN_N_BACKWARD+1):\n        df[f'u_in_diff_{i}_back'] = df['u_in'] - df[f'u_in_{i}_back']\n    for i in range(1, U_OUT_N_BACKWARD+1):\n        df[f'u_out_diff_{i}_back'] = df['u_out'] - df[f'u_out_{i}_back']\n    for i in range(1, U_IN_N_FORWARD+1):\n        df[f'u_in_diff_{i}_back'] = df['u_in'] - df[f'u_in_{i}_forw']\n    for i in range(1, U_OUT_N_FORWARD+1):\n        df[f'u_out_diff_{i}_forw'] = df['u_out'] - df[f'u_out_{i}_forw']\n    \n    print(\"\\t... Add categorical features ...\")\n    if use_rc:\n        df['R_C'] = df['R'].astype(str)+\"_\"+df['C'].astype(str)\n        df['R'] = df['R']\/50\n        df['C'] = df['C']\/50\n        df = pd.get_dummies(df,)\n    \n    print(\"\\t... Reset dtypes for lower memory usage ...\")\n    for c in df.columns:\n        if c==\"u_out\":\n            df[c] = df[c].astype(\"uint8\")\n        elif df[c].dtype==\"float64\":\n            df[c] = df[c].astype(\"float32\")\n    \n    # Final cleanup\n    gc.collect(); gc.collect();\n    \n    return df\n\nload_locally = tf.saved_model.LoadOptions(experimental_io_device='\/job:localhost')\ndef load_model(model_path):\n    tf.keras.backend.clear_session()\n    gc.collect(); gc.collect();\n\n    with strategy.scope():\n        _model = tf.keras.models.load_model(model_path, options=load_locally)\n        _model.compile(\"adam\", loss=\"mae\", weighted_metrics=[\"mae\",])\n    \n    return _model","ddfd885f":"print(\"\\n... ADDING FEATURES TO TRAIN DATAFRAME ...\\n\")\ntrain_df = add_features(train_df, use_rc=True)\n\nprint(\"\\n... ADDING FEATURES TO TEST DATAFRAME ...\\n\")\ntest_df = add_features(test_df, use_rc=True)\n\nLABEL_NAMES = [\"pressure\",]\nGROUPBY_NAMES = [\"breath_id\"]\nIGNORE_NAMES = [\"id\"]\nFEATURE_NAMES = [x for x in train_df.columns if x not in LABEL_NAMES+GROUPBY_NAMES+IGNORE_NAMES]\nN_FEATURES = len(FEATURE_NAMES)\n\nRS = RobustScaler()\nRS.fit(train_df[FEATURE_NAMES].to_numpy())\n\ndisplay(train_df.head(3))\ndisplay(test_df.head(3))","64589bc8":"# Get testing data\nN_TEST = len(test_df)\nTEST_PADDING = (OVERALL_BATCH_SIZE*80)-(N_TEST%(OVERALL_BATCH_SIZE*80))\ntest_df = pd.concat([test_df, test_df[:TEST_PADDING].reset_index(drop=True)])\nsub_test_x_np = RS.transform(test_df[FEATURE_NAMES].to_numpy())\ntest_ds = tf.data.Dataset.from_tensor_slices(sub_test_x_np)\ntest_ds = test_ds.batch(ROWS_PER_BREATH, drop_remainder=True).cache().batch(OVERALL_BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)","ce98c4d9":"fold_pred_map = {\n    f\"fold_{i}\":dict(val=None, test=None) \\\n    for i in range(N_FOLDS)\n}\n\nfor i in tqdm(range(N_FOLDS), total=N_FOLDS):\n    print(f\"\\n\\n\\n... STARTING FOLD {i} ...\\n\")\n    \n    print(f\"\\t--> LOADING MODEL FROM FOLD {i} ...\")\n    model = load_model(os.path.join(MODEL_DIR, f\"best_model_fold_{i}\"))\n    \n    # Preprocess the validation subset\n    _tmp_val_df = fold_val_df_map[f\"fold_{i}\"]\n    _tmp_n_val = len(_tmp_val_df)\n    _val_test_padding = (OVERALL_BATCH_SIZE*80)-(_tmp_n_val%(OVERALL_BATCH_SIZE*80))\n    _tmp_val_df = pd.concat([_tmp_val_df, _tmp_val_df[:_val_test_padding].reset_index(drop=True)])\n    _sub_val_x_np = RS.transform(_tmp_val_df[FEATURE_NAMES].to_numpy())\n    _tmp_val_ds = tf.data.Dataset.from_tensor_slices(_sub_val_x_np)\n    _tmp_val_ds = _tmp_val_ds.batch(ROWS_PER_BREATH, drop_remainder=True).cache().batch(OVERALL_BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n    \n    print(f\"\\t--> FOLD {i} MODEL INFER ON FOLD VAL DATASET AND SAVE PREDS ...\")\n    fold_pred_map[f\"fold_{i}\"][\"val\"]=model.predict(_tmp_val_ds).reshape(-1)[:_tmp_n_val]\n    \n    print(f\"\\t--> FOLD {i} MODEL INFER ON TEST DATASET AND SAVE PREDS ...\")\n    fold_pred_map[f\"fold_{i}\"][\"test\"]=model.predict(test_ds).reshape(-1)[:N_TEST]\n    \n    print(f\"\\t--> FOLD {i} MODEL PREDS BEING ADDED TO FOLD VAL DATAFRAMES ...\")\n    fold_val_df_map[f\"fold_{i}\"][f\"fold_{i}_pressure\"] = fold_pred_map[f\"fold_{i}\"][\"val\"]\n    \n    print(f\"\\t--> FOLD {i} MODEL PREDS BEING ADDED TO SAMPLE SUBMISSION DATAFRAME ...\")\n    ss_df[f\"fold_{i}_pressure\"] = fold_pred_map[f\"fold_{i}\"][\"test\"]\n    \n# Clean memory\ndel _tmp_val_df; del _tmp_n_val; del _val_test_padding; del _sub_val_x_np; del _tmp_val_ds;\ntf.keras.backend.clear_session(); gc.collect(); gc.collect();","f80f386f":"ss_df[\"pressure\"] = ss_df[[x for x in ss_df.columns if \"fold\" in x]].median(axis=1)\nss_df[[\"id\", \"pressure\"]].to_csv(\"submission.csv\", index=False)\ndisplay(ss_df.head(10))","367b6709":"for i in range(N_FOLDS):\n    tmp_df = fold_val_df_map[f\"fold_{i}\"]\n    tmp_df[\"int_step\"] = ((tmp_df.id-1)%80)\n    tmp_df[\"inhale_length\"] = 80-tmp_df.groupby([\"breath_id\",])[\"u_out\"].transform(\"sum\")\n    tmp_df[\"mae\"] = (tmp_df[f\"fold_{i}_pressure\"]-tmp_df[\"pressure\"]).abs()\n    tmp_df[\"full_breath_mae\"] = tmp_df.groupby([\"breath_id\",])[\"mae\"].transform(\"mean\")\n    tmp_df[\"inhale_breath_mae\"] = tmp_df[tmp_df.u_out==0].groupby([\"breath_id\",])[\"mae\"].transform(\"mean\")\n    tmp_df[\"inhale_breath_mae\"] = tmp_df[\"inhale_breath_mae\"].fillna(method=\"ffill\")\n    fold_val_df_map[f\"fold_{i}\"] = tmp_df\n    print(f\"\\n\\n\\n\\nFOLD {i} WHOLE-BREATH MAE: {fold_val_df_map[f'fold_{i}'].mae.mean()}\")\n    print(f\"FOLD {i} INHALE_ONLY  MAE: {fold_val_df_map[f'fold_{i}'][fold_val_df_map[f'fold_{i}'].u_out==0].mae.mean()}\\n\\n\")\n    display(tmp_df.head())","c14dfb29":"plt.figure(figsize=(20, 6))\nfor i in range(N_FOLDS):\n    tmp_df = fold_val_df_map[f\"fold_{i}\"][[\"id\", \"int_step\", \"breath_id\", \"R\", \"C\", \"u_in\", \"u_out\", \"pressure\", f\"fold_{i}_pressure\", \"mae\"]]\n    plt.plot(tmp_df.groupby(\"int_step\")[\"mae\"].mean(), label=f'FOLD {i}')\nplt.legend(loc=\"upper right\")\nplt.axvline(x=int(80-tmp_df.groupby(\"breath_id\")[\"u_out\"].sum().mean()),color='k')\nplt.title(\"Mean Error By Time Step For Each Fold\", fontweight=\"bold\")\nplt.grid(which=\"both\")\nplt.tight_layout()\nplt.show()\n\nplt.figure(figsize=(20, 6))\nfor i in range(N_FOLDS):\n    tmp_df = fold_val_df_map[f\"fold_{i}\"][[\"id\", \"int_step\", \"breath_id\", \"R\", \"C\", \"u_in\", \"u_out\", \"pressure\", f\"fold_{i}_pressure\", \"mae\"]]\n    plt.plot(tmp_df.groupby(\"int_step\")[\"mae\"].max(), label=f'FOLD {i}')\nplt.legend(loc=\"upper right\")\nplt.axvline(x=int(80-tmp_df.groupby(\"breath_id\")[\"u_out\"].sum().mean()),color='k')\nplt.title(\"Max Error By Time Step For Each Fold\", fontweight=\"bold\")\nplt.grid(which=\"both\")\nplt.tight_layout()\nplt.show()\n\nplt.figure(figsize=(20, 6))\nfor i in range(N_FOLDS):\n    tmp_df = fold_val_df_map[f\"fold_{i}\"][[\"id\", \"int_step\", \"breath_id\", \"R\", \"C\", \"u_in\", \"u_out\", \"pressure\", f\"fold_{i}_pressure\", \"mae\"]]\n    plt.plot(tmp_df.groupby(\"int_step\")[\"mae\"].std(), label=f'FOLD {i}')\nplt.legend(loc=\"upper right\")\nplt.axvline(x=int(80-tmp_df.groupby(\"breath_id\")[\"u_out\"].sum().mean()),color='k')\nplt.title(\"Standard Deviation of Error By Time Step For Each Fold\", fontweight=\"bold\")\nplt.grid(which=\"both\")\nplt.tight_layout()\nplt.show()","6ecae4a6":"for i in range(N_FOLDS):\n    plt.figure(figsize=(20, 6))\n    tmp_df = fold_val_df_map[f\"fold_{i}\"][[\"id\", \"int_step\", \"breath_id\", \"R\", \"C\", \"u_in\", \"u_out\", \"pressure\", f\"fold_{i}_pressure\", \"mae\", \"inhale_length\", \"full_breath_mae\", \"inhale_breath_mae\"]]\n    demo_breath_id = tmp_df[\"breath_id\"].sample(1).values[0]\n    tmp_df = tmp_df[tmp_df.breath_id==demo_breath_id]\n    print(\"\\n\\nINHALE-ONLY MAE:\", tmp_df.inhale_breath_mae.values[0])\n    plt.plot(tmp_df[\"pressure\"].values, label=f'FOLD {i} GT')\n    plt.plot(tmp_df[f\"fold_{i}_pressure\"].values, label=f'FOLD {i} PRED')\n    plt.fill_between(x=np.arange(80), y1=tmp_df[\"pressure\"].values, y2=tmp_df[f\"fold_{i}_pressure\"].values, color=\"r\", alpha=0.2)\n    plt.legend(loc=\"upper right\")\n    plt.axvline(x=int(80-tmp_df[\"u_out\"].sum()), color='k')\n    plt.title(f\"Random Example Breath - R={tmp_df.R.values[0]}, C={tmp_df.C.values[0]}\", fontweight=\"bold\")\n    plt.grid(which=\"both\")\n    plt.tight_layout()\n    plt.show()","97a63786":"BAD_BREATH_THRESH = 2.0\nfor i in range(N_FOLDS):\n    plt.figure(figsize=(20, 6))\n    tmp_df = fold_val_df_map[f\"fold_{i}\"][[\"id\", \"int_step\", \"breath_id\", \"R\", \"C\", \"u_in\", \"u_out\", \"pressure\", f\"fold_{i}_pressure\", \"mae\", \"inhale_length\", \"full_breath_mae\", \"inhale_breath_mae\"]]\n    demo_breath_id = tmp_df[tmp_df.inhale_breath_mae>BAD_BREATH_THRESH][\"breath_id\"].sample(1).values[0]\n    tmp_df = tmp_df[tmp_df.breath_id==demo_breath_id]\n    print(\"\\n\\nINHALE-ONLY MAE:\", tmp_df.inhale_breath_mae.values[0])\n    plt.plot(tmp_df[\"pressure\"].values, label=f'FOLD {i} GT')\n    plt.plot(tmp_df[f\"fold_{i}_pressure\"].values, label=f'FOLD {i} PRED')\n    plt.fill_between(x=np.arange(80), y1=tmp_df[\"pressure\"].values, y2=tmp_df[f\"fold_{i}_pressure\"].values, color=\"r\", alpha=0.2)\n    plt.legend(loc=\"upper right\")\n    plt.axvline(x=int(80-tmp_df[\"u_out\"].sum()), color='k')\n    plt.title(f\"Random BAD Example Breath - R={tmp_df.R.values[0]}, C={tmp_df.C.values[0]}\", fontweight=\"bold\")\n    plt.grid(which=\"both\")\n    plt.tight_layout()\n    plt.show()","89f1d906":"GOOD_BREATH_THRESH = 2.0\nfor i in range(N_FOLDS):\n    plt.figure(figsize=(20, 6))\n    tmp_df = fold_val_df_map[f\"fold_{i}\"][[\"id\", \"int_step\", \"breath_id\", \"R\", \"C\", \"u_in\", \"u_out\", \"pressure\", f\"fold_{i}_pressure\", \"mae\", \"inhale_length\", \"full_breath_mae\", \"inhale_breath_mae\"]]\n    demo_breath_id = tmp_df[tmp_df.inhale_breath_mae<GOOD_BREATH_THRESH][\"breath_id\"].sample(1).values[0]\n    tmp_df = tmp_df[tmp_df.breath_id==demo_breath_id]\n    print(\"\\n\\nINHALE-ONLY MAE:\", tmp_df.inhale_breath_mae.values[0])\n    plt.plot(tmp_df[\"pressure\"].values, label=f'FOLD {i} GT')\n    plt.plot(tmp_df[f\"fold_{i}_pressure\"].values, label=f'FOLD {i} PRED')\n    plt.fill_between(x=np.arange(80), y1=tmp_df[\"pressure\"].values, y2=tmp_df[f\"fold_{i}_pressure\"].values, color=\"r\", alpha=0.2)\n    plt.legend(loc=\"upper right\")\n    plt.axvline(x=int(80-tmp_df[\"u_out\"].sum()), color='k')\n    plt.title(f\"Random GOOD Example Breath - R={tmp_df.R.values[0]}, C={tmp_df.C.values[0]}\", fontweight=\"bold\")\n    plt.grid(which=\"both\")\n    plt.tight_layout()\n    plt.show()","70a8438f":"for _R in fold_val_df_map[\"fold_0\"].R.unique():\n    for _C in fold_val_df_map[\"fold_0\"].C.unique():\n        plt.figure(figsize=(20, 6))\n        print(f\"\\n\\n\\nCONFIG R={_R}, C={_C}\")\n        rc_mae_ave, overall_mae_ave = 0, 0\n        for i in range(N_FOLDS):\n            tmp_df = fold_val_df_map[f\"fold_{i}\"][[\"id\", \"int_step\", \"breath_id\", \"R\", \"C\", \"u_in\", \"u_out\", \"pressure\", f\"fold_{i}_pressure\", \"mae\", \"inhale_breath_mae\"]]\n            overall_mae_ave += tmp_df.inhale_breath_mae.mean()\n            tmp_df = tmp_df[(tmp_df.R==_R)&(tmp_df.C==_C)]\n            plt.plot(tmp_df.groupby(\"int_step\")[\"mae\"].mean(), label=f'FOLD {i}')\n            rc_mae_ave += tmp_df.inhale_breath_mae.mean()\n        print(f\"\\t--> ALL FOLD RC-SPECIFIC OOF MAE  =  {rc_mae_ave\/N_FOLDS:.5f}\\n\\t--> ALL FOLD OVERALL OOF MAE      =  {overall_mae_ave\/N_FOLDS:.5f}\\n\\n\")\n        plt.legend(loc=\"upper right\")\n        plt.axvline(x=int(80-tmp_df.groupby(\"breath_id\")[\"u_out\"].sum().mean()),color='k')\n        plt.title(\"Mean Error By Time Step For Each Fold By R and C\", fontweight=\"bold\")\n        plt.grid(which=\"both\")\n        plt.tight_layout()\n        plt.show()\n","e1e847c3":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkorange; background-color: #ffffff;\">6.1 UPDATE DATAFRAMES<\/h3>\n\n---\n","b01ef492":"<br>\n\n\n<a id=\"create_dataset\"><\/a>\n\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: darkorange; background-color: #ffffff;\" id=\"create_dataset\">\n    4&nbsp;&nbsp;CREATE DATASET&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#toc\">&#10514;<\/a>\n<\/h1>","cc701d0b":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkorange; background-color: #ffffff;\">2.1 ACCELERATOR DETECTION<\/h3>\n\n---\n\nIn order to use **`TPU`**, we use **`TPUClusterResolver`** for the initialization which is necessary to connect to the remote cluster and initialize cloud TPUs. Let's go over two important points\n\n1. When using TPU on Kaggle, you don't need to specify arguments for **`TPUClusterResolver`**\n2. However, on **G**oogle **C**ompute **E**ngine (**GCE**), you will need to do the following:\n\n<br>\n\n```python\n# The name you gave to the TPU to use\nTPU_WORKER = 'my-tpu-name'\n\n# or you can also specify the grpc path directly\n# TPU_WORKER = 'grpc:\/\/xxx.xxx.xxx.xxx:8470'\n\n# The zone you chose when you created the TPU to use on GCP.\nZONE = 'us-east1-b'\n\n# The name of the GCP project where you created the TPU to use on GCP.\nPROJECT = 'my-tpu-project'\n\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=TPU_WORKER, zone=ZONE, project=PROJECT)\n```\n\n<div class=\"alert alert-block alert-danger\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n    <b style=\"font-size: 16px;\">\ud83d\uded1 &nbsp; WARNING:<\/b><br><br>- Although the Tensorflow documentation says it is the <b>project name<\/b> that should be provided for the argument <b><code>`project`<\/code><\/b>, it is actually the <b>Project ID<\/b>, that you should provide. This can be found on the GCP project dashboard page.<br>\n<\/div>\n\n<div class=\"alert alert-block alert-info\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n    <b style=\"font-size: 16px;\">\ud83d\udcd6 &nbsp; REFERENCES:<\/b><br><br>\n    - <a href=\"https:\/\/www.tensorflow.org\/guide\/tpu#tpu_initialization\"><b>Guide - Use TPUs<\/b><\/a><br>\n    - <a href=\"https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/distribute\/cluster_resolver\/TPUClusterResolver\"><b>Doc - TPUClusterResolver<\/b><\/a><br>\n\n<\/div>","407f800c":"<br>\n\n\n<a id=\"helper_functions\"><\/a>\n\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: darkorange; background-color: #ffffff;\" id=\"helper_functions\">\n    3&nbsp;&nbsp;HELPER FUNCTION & CLASSES&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#toc\">&#10514;<\/a>\n<\/h1>","72fc5339":"WIP","d106343b":"## Dataframe Correction Steps","9a1c2dda":"<p id=\"toc\"><\/p>\n\n<br><br>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: darkorange; background-color: #ffffff;\">TABLE OF CONTENTS<\/h1>\n\n---\n\n<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: navy; background-color: #ffffff;\"><a href=\"#imports\">0&nbsp;&nbsp;&nbsp;&nbsp;IMPORTS<\/a><\/h3>\n\n---\n\n<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: navy; background-color: #ffffff;\"><a href=\"#background_information\">1&nbsp;&nbsp;&nbsp;&nbsp;BACKGROUND INFORMATION<\/a><\/h3>\n\n---\n\n<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: navy; background-color: #ffffff;\"><a href=\"#setup\">2&nbsp;&nbsp;&nbsp;&nbsp;SETUP<\/a><\/h3>\n\n---\n\n<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: navy; background-color: #ffffff;\"><a href=\"#helper_functions\">3&nbsp;&nbsp;&nbsp;&nbsp;HELPER FUNCTIONS<\/a><\/h3>\n\n---\n\n<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: navy; background-color: #ffffff;\"><a href=\"#create_dataset\">4&nbsp;&nbsp;&nbsp;&nbsp;DATASET CREATION<\/a><\/h3>\n\n---\n\n<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: navy; background-color: #ffffff;\"><a href=\"#inference\">5&nbsp;&nbsp;&nbsp;&nbsp;INFERENCE<\/a><\/h3>\n\n---\n\n<h3 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: navy; background-color: #ffffff;\"><a href=\"#error_analysis\">5&nbsp;&nbsp;&nbsp;&nbsp;ERROR ANALYSIS<\/a><\/h3>\n\n---","1d52e48c":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkorange; background-color: #ffffff;\">6.5 PLOT A RANDOM GOOD BREATH FOR EACH FOLD (GT v. PRED)<\/h3>\n\n---\n\n**GOOD --> MAE<0.5**","726ab676":"<br>\n\n\n<a id=\"setup\"><\/a>\n\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: darkorange; background-color: #ffffff;\"  id=\"setup\">2&nbsp;&nbsp;SETUP&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#toc\">&#10514;<\/a>\n<\/h1>","e33bfeaa":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkorange; background-color: #ffffff;\">6.3 PLOT A RANDOM BREATH FOR EACH FOLD (GT v. PRED)<\/h3>\n\n---\n","d74cadd1":"<h1 style=\"text-align: center; font-family: Verdana; font-size: 32px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; font-variant: small-caps; letter-spacing: 3px; color: orange; background-color: #ffffff;\">Ventilator Pressure Prediction<\/h1>\n<h2 style=\"text-align: center; font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: underline; text-transform: none; letter-spacing: 2px; color: black; background-color: #ffffff;\">ERROR ANALYSIS     <font color=\"red\">     WIP    <\/font><\/h2>\n<h5 style=\"text-align: center; font-family: Verdana; font-size: 12px; font-style: normal; font-weight: bold; text-decoration: None; text-transform: none; letter-spacing: 1px; color: black; background-color: #ffffff;\">CREATED BY: DARIEN SCHETTLER<\/h5>\n\n<br>\n\n---\n\n<br>\n\n<center><font color=\"red\"><b><mark>NOTE:<\/mark><br>THIS NOTEBOOK USES AN 6-FOLDS OF AN 8 FOLD TRAIN... BECAUSE I RAN OUT OF TPU... THIS SHOULD STILL BE REPRESENTATIVE<\/b><\/font><\/center>\n\n<br>\n\n---\n\n<br>\n","0bfe7270":"<br>\n\n\n<a id=\"inference\"><\/a>\n\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: darkorange; background-color: #ffffff;\" id=\"inference\">\n    5&nbsp;&nbsp;INFERENCE&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#toc\">&#10514;<\/a>\n<\/h1>\n\nWe will use a blend of our 5 folds (median and mean blend predictions)","97ef3047":"<br>\n\n<a id=\"imports\"><\/a>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: darkorange;\" id=\"imports\">0&nbsp;&nbsp;IMPORTS&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#toc\">&#10514;<\/a><\/h1>","63a4329a":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkorange; background-color: #ffffff;\">6.2 PLOT MAE FOR EACH FOLD BY TIMESTEP (80 STEPS)<\/h3>\n\n---\n","c3e05f8c":"<br>\n\n\n<a id=\"error_analysis\"><\/a>\n\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: darkorange; background-color: #ffffff;\" id=\"error_analysis\">\n    6&nbsp;&nbsp;ERROR ANALYSIS&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#toc\">&#10514;<\/a>\n<\/h1>","2115094a":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkorange; background-color: #ffffff;\">6.6 PLOT MAE FOR EACH RC CONFIGURATION ACROSS FOLDS<\/h3>\n\n---","18cde193":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkorange; background-color: #ffffff;\">6.4 PLOT A RANDOM BAD BREATH FOR EACH FOLD (GT v. PRED)<\/h3>\n\n---\n\n**BAD --> MAE>2.0**","819b518a":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkorange; background-color: #ffffff;\">2.2 COMPETITION DATA ACCESS<\/h3>\n\n---\n\nTPUs read data must be read directly from **G**oogle **C**loud **S**torage **(GCS)**. Kaggle provides a utility library \u2013\u00a0**`KaggleDatasets`** \u2013 which has a utility function **`.get_gcs_path`** that will allow us to access the location of our input datasets within **GCS**.<br><br>\n\n<div class=\"alert alert-block alert-info\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n    <b style=\"font-size: 16px;\">\ud83d\udccc &nbsp; TIPS:<\/b><br><br>- If you have multiple datasets attached to the notebook, you should pass the name of a specific dataset to the <b><code>`get_gcs_path()`<\/code><\/b> function. <i>In our case, the name of the dataset is the name of the directory the dataset is mounted within.<\/i><br><br>\n<\/div>","bddbcc00":"<br>\n\n<a id=\"background_information\"><\/a>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: darkorange; background-color: #ffffff;\" id=\"background_information\">1&nbsp;&nbsp;BACKGROUND INFORMATION&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"#toc\">&#10514;<\/a><\/h1>\n\n<br><b style=\"text-decoration: underline; font-family: Verdana; text-transform: uppercase;\">PRIMARY TASK DESCRIPTION<\/b>\n\n\n**TBD**\n\n---\n\n<br>","9b6ea511":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkorange; background-color: #ffffff;\">2.4 LEVERAGING XLA OPTIMIZATIONS<\/h3>\n\n---\n\n\n**XLA** (Accelerated Linear Algebra) is a domain-specific compiler for linear algebra that can accelerate TensorFlow models with potentially no source code changes. **The results are improvements in speed and memory usage**.\n\n<br>\n\nWhen a TensorFlow program is run, all of the operations are executed individually by the TensorFlow executor. Each TensorFlow operation has a precompiled GPU\/TPU kernel implementation that the executor dispatches to.\n\nXLA provides us with an alternative mode of running models: it compiles the TensorFlow graph into a sequence of computation kernels generated specifically for the given model. Because these kernels are unique to the model, they can exploit model-specific information for optimization.<br><br>\n\n<div class=\"alert alert-block alert-danger\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n    <b style=\"font-size: 16px;\">\ud83d\uded1 &nbsp; WARNING:<\/b><br><br>- XLA can not currently compile functions where dimensions are not inferrable: that is, if it's not possible to infer the dimensions of all tensors without running the entire computation<br>\n<\/div>\n\n<div class=\"alert alert-block alert-info\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n    <b style=\"font-size: 16px;\">\ud83d\udccc &nbsp; NOTE:<\/b><br><br>- XLA compilation is only applied to code that is compiled into a graph (in <b>TF2<\/b> that's only a code inside <b><code>tf.function<\/code><\/b>).<br>- The <b><code>jit_compile<\/code><\/b> API has must-compile semantics, i.e. either the entire function is compiled with XLA, or an <b><code>errors.InvalidArgumentError<\/code><\/b> exception is thrown)\n<\/div>\n\n<div class=\"alert alert-block alert-info\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n    <b style=\"font-size: 16px;\">\ud83d\udcd6 &nbsp; REFERENCE:<\/b><br><br>    - <a href=\"https:\/\/www.tensorflow.org\/xla\"><b>XLA: Optimizing Compiler for Machine Learning<\/b><\/a><br>\n<\/div>","b75655b5":"preprocessing and add features","a7fdebcf":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkorange; background-color: #ffffff;\">3.1 GENERAL HELPER FUNCTIONS<\/h3>\n\n---","7306075a":"<h3 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkorange; background-color: #ffffff;\">2.3 BASIC DATA DEFINITIONS & INITIALIZATIONS<\/h3>\n\n---\n"}}