{"cell_type":{"fe49677b":"code","4c55bc4c":"code","cd79d735":"code","c205a334":"code","565f94ed":"code","2939ecef":"code","e6e2da7b":"code","7496991c":"code","6b1d27ac":"code","ffa64428":"code","d6ab834d":"code","cbc9fdd1":"code","e9f42e71":"code","9d402fa5":"code","b3ac3b4e":"code","356444f4":"code","3fc07482":"code","604276b6":"code","67c1288e":"code","962afd35":"code","7e5732c0":"code","b89b6d8a":"markdown","a35ac586":"markdown","4aaddbb5":"markdown","53292837":"markdown","54156e96":"markdown","2b6e30b0":"markdown","6413f4d5":"markdown","452d2bc3":"markdown","ff697030":"markdown"},"source":{"fe49677b":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom sklearn.model_selection import train_test_split\nimport pickle\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","4c55bc4c":"#load the data\ntrain = pd.read_csv('..\/input\/cifar10-mu\/train.csv', dtype = str)\ntrain.shape","cd79d735":"#review training data\ntrain.info()","c205a334":"#display the head of the DataFrame. \ntrain.head()","565f94ed":"# Display the proportion of observations with each possible of the target variable\ny_train = train.label\n\n(train.label.value_counts() \/ len(train)).to_frame()","2939ecef":"train_path = \"..\/input\/cifar10-mu\/train_images\"\nprint('Training Images:', len(os.listdir(train_path)))","e6e2da7b":"# Sample 16 images, display with their labels in a 4x4 grid, set the figure size to (6,6)\n\nsample = train.sample(n = 16).reset_index()\n\nplt.figure(figsize = (6, 6))\n\nfor i, row in sample.iterrows():\n    img = mpimg.imread(f'..\/input\/cifar10-mu\/train_images\/{row.filename}')    \n    lab = row.label\n\n    plt.subplot(4, 4, i+1)\n    plt.imshow(img)\n    plt.text(0, -5, f'Class {lab}')\n        \n    plt.axis('off')\n    \nplt.tight_layout()    \nplt.show()","7496991c":"#split the training data\ntrain_df, valid_df = train_test_split(train, test_size = 0.2, random_state = 3, stratify = train.label)\n\nprint(train_df.shape)\nprint(valid_df.shape)","6b1d27ac":"# Create image data generators\ntrain_datagen = ImageDataGenerator(rescale = 1\/255)\nvalid_datagen = ImageDataGenerator(rescale = 1\/255)","ffa64428":"BATCH_SIZE = 64\n\ntrain_loader = train_datagen.flow_from_dataframe(\n    dataframe = train_df,\n    directory = train_path,\n    x_col = 'filename',\n    y_col = 'label',\n    batch_size = BATCH_SIZE,\n    seed = 1,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (32, 32)\n)\n\nvalid_loader = valid_datagen.flow_from_dataframe(\n    dataframe = valid_df,\n    directory = train_path,\n    x_col = 'filename',\n    y_col = 'label',\n    batch_size = BATCH_SIZE,\n    seed = 1,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (32, 32)\n)","d6ab834d":"# Determine the number of training and validation batches. \n \nTR_STEPS = len(train_loader)\nVA_STEPS = len(valid_loader)\n\nprint(TR_STEPS)\nprint(VA_STEPS)","cbc9fdd1":"np.random.seed(1)\ntf.random.set_seed(1)\n\ncnn = Sequential([\n    Conv2D(32, (3, 3), activation = 'relu', padding = 'same', input_shape=(32, 32, 3)),\n    Conv2D(32, (3, 3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2, 2),\n    Dropout(0.5),\n    BatchNormalization(),\n\n    Conv2D(64, (3, 3), activation = 'relu', padding = 'same'),\n    Conv2D(64, (3, 3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2, 2),\n    Dropout(0.25),\n    BatchNormalization(),\n\n    Conv2D(128, (3, 3), activation = 'relu', padding = 'same'),\n    Conv2D(128, (3, 3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2, 2),\n    Dropout(0.5),\n    BatchNormalization(),\n\n    Flatten(),\n    \n    Dense(128, activation='relu'),\n    Dropout(0.25),\n    Dense(64, activation='relu'),\n    Dropout(0.5),\n    Dense(32, activation='relu'),\n    Dropout(0.25),\n    BatchNormalization(),\n    Dense(10, activation='softmax')\n])\n\ncnn.summary()","e9f42e71":"opt = tf.keras.optimizers.Adam(0.001)\n\ncnn.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy', tf.keras.metrics.AUC()])","9d402fa5":"%%time \n\nh1 = cnn.fit(x = train_loader,\n             steps_per_epoch = TR_STEPS, \n             epochs = 20, \n             validation_data = valid_loader, \n             validation_steps = VA_STEPS, \n             verbose = 1\n)","b3ac3b4e":"history = h1.history","356444f4":"epoch_range = range(1, len(history['loss']) + 1)\n\nplt.figure(figsize=[12,6])\nplt.subplot(1, 3, 1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\n\nplt.subplot(1, 3, 2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\n\nplt.subplot(1, 3, 3)\nplt.plot(epoch_range, history['auc'], label='Training')\nplt.plot(epoch_range, history['val_auc'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('AUC'); plt.title('AUC')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","3fc07482":"#decrease the learning rate \ntf.keras.backend.set_value(cnn.optimizer.learning_rate, 0.0001)","604276b6":"%%time \n\nh2 = cnn.fit(x = train_loader,\n             steps_per_epoch = TR_STEPS, \n             epochs = 15, \n             validation_data = valid_loader, \n             validation_steps = VA_STEPS, \n             verbose = 1\n)","67c1288e":"for h in history.keys():\n    history[h] += h2.history[h]","962afd35":"epoch_range = range(1, len(history['loss']) + 1)\n\nplt.figure(figsize=[12,6])\nplt.subplot(1, 3, 1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\n\nplt.subplot(1, 3, 2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\n\nplt.subplot(1, 3, 3)\nplt.plot(epoch_range, history['auc'], label='Training')\nplt.plot(epoch_range, history['val_auc'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('AUC'); plt.title('AUC')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","7e5732c0":"cnn.save('cifar10_model_v01.h5')\npickle.dump(history, open(f'cifar10_model_v01.pk1', 'wb'))","b89b6d8a":"# Import Packages","a35ac586":"# CIFAR 10 Image Classification\n\n\u26a0 **NOTE:** You should make use of GPU acceleration in this notebook. \n\n","4aaddbb5":"# Data Generators","53292837":"# Label Distribution","54156e96":"# Save Model and History","2b6e30b0":"# Load Training DataFrame","6413f4d5":"# Build Network","452d2bc3":"# Train Network","ff697030":"# View Sample of Images"}}