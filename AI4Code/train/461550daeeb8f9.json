{"cell_type":{"d885c998":"code","2ffd690c":"code","aa619e47":"code","c68bf921":"code","50dde1f5":"code","06f50f8b":"code","951d19b6":"code","b578faf2":"code","5774993a":"code","7ebb0cc2":"code","f76c5c0e":"code","63814e03":"code","a6203960":"code","c6b287e1":"code","0c04b7a8":"code","a5ed10bf":"code","64699689":"code","add29306":"code","5ebb0201":"code","db5eccce":"code","28dbea53":"code","f327d564":"code","f4694995":"code","91a56237":"code","35c6a7d8":"code","2bad6db4":"code","07dff4a5":"code","3731e11c":"code","61eece6f":"code","64ce70a8":"code","e871906c":"code","6bdf3f6e":"code","45afb05b":"code","a4f545e6":"code","59465958":"code","b530dc44":"code","e201b5f5":"code","e4cbb9bc":"code","ea2402a1":"code","fbfdc50e":"code","a0a0c62e":"code","1671d6b3":"code","a2ad5861":"code","e0c0ccb9":"code","c084ccd5":"code","cf322686":"code","acf80645":"code","8f5e9dff":"code","54f34cd4":"code","3fc4f81a":"code","a7576a6a":"code","74f41f8a":"code","ee1c1d8c":"code","d28ca31e":"code","16845e3f":"code","6f86143f":"code","d3221954":"code","15709b67":"code","a885c31d":"code","3e432d03":"code","b0a9d01b":"code","6ecad925":"code","4120c532":"code","c067d44f":"code","a8c96fb6":"code","4867e6dd":"code","2b74b9e5":"code","4ad5afe1":"markdown","c838522a":"markdown","1cba300f":"markdown","f3a06ced":"markdown","1d425675":"markdown","ca028d67":"markdown","b7914265":"markdown","464a1019":"markdown","3b1e06ab":"markdown","afd6d2f6":"markdown","0f7860c0":"markdown","f870990d":"markdown","8b69c5e2":"markdown"},"source":{"d885c998":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","2ffd690c":"from os import walk\nfrom os.path import join \n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\nimport nltk as nltk  \n\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import SnowballStemmer\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\n%matplotlib inline","aa619e47":"# constant\nEXAMPLE_FILE = '\/kaggle\/input\/spamdata\/SpamData\/01_Processing\/practice_email.txt'\n\nSPAM_1_PATH = '\/kaggle\/input\/spamdata\/SpamData\/01_Processing\/spam_assassin_corpus\/spam_1\/'\nSPAM_2_PATH = '\/kaggle\/input\/spamdata\/SpamData\/01_Processing\/spam_assassin_corpus\/spam_2\/'\nEASY_NONSPAM_1_PATH = '\/kaggle\/input\/spamdata\/SpamData\/01_Processing\/spam_assassin_corpus\/easy_ham_1\/'\nEASY_NONSPAM_2_PATH = '\/kaggle\/input\/spamdata\/SpamData\/01_Processing\/spam_assassin_corpus\/easy_ham_2\/'\n\nSPAM_CAT = 1\nHAM_CAT = 0\n\nDATA_JSON_FILE = '\/kaggle\/input\/spamdata\/SpamData\/01_Processing\/email-text-data.json'","c68bf921":"# Reading files\nstream = open(EXAMPLE_FILE, encoding='latin-1')\nmessage = stream.read()\nstream.close()\nprint(message)","50dde1f5":"import sys\nsys.getfilesystemencoding()","06f50f8b":"print(type(message))","951d19b6":"stream = open(EXAMPLE_FILE, encoding='latin-1')\nis_body = False\nlines = []\n\nfor line in stream:\n    if is_body:\n        lines.append(line)\n    elif line == '\\n':\n        is_body = True\nstream.close()\n\nemail_body = '\\n'.join(lines)\nprint(email_body)","b578faf2":"def email_body_generator(path):\n    \n    for root, dirnames, filenames in walk(path):\n        for file_name in filenames:\n            \n            filepath = join(root, file_name)\n            \n            stream = open(filepath, encoding='latin-1')\n            \n            is_body = False\n            lines = []\n\n            for line in stream:\n                if is_body:\n                    lines.append(line)\n                elif line == '\\n':\n                    is_body = True\n            stream.close()\n\n            email_body = '\\n'.join(lines)\n            #print(email_body)\n            yield file_name , email_body\n","5774993a":"def df_from_directory(path, classification):\n    rows = []\n    row_names = []\n    \n    for file_name, email_body in email_body_generator(path):\n        rows.append({'MESSAGE' : email_body, 'CATEGORY': classification})\n        row_names.append(file_name)\n    return pd.DataFrame(rows, index=row_names)\n    ","7ebb0cc2":"spam_emails = df_from_directory(SPAM_1_PATH, 1)\nspam_emails = spam_emails.append(df_from_directory(SPAM_2_PATH, 1))","f76c5c0e":"spam_emails.head()","63814e03":"spam_emails.shape","a6203960":"ham_emails = df_from_directory(EASY_NONSPAM_1_PATH, 0)\nham_emails = ham_emails.append(df_from_directory(EASY_NONSPAM_2_PATH, 0))\nham_emails.head()","c6b287e1":"ham_emails.shape","0c04b7a8":"data = pd.concat([spam_emails, ham_emails])\nprint('Shape of entire dataframe is ', data.shape)\ndata.head()","a5ed10bf":"data.tail()","64699689":"data.sample(5)","add29306":"data['MESSAGE'].isnull().sum()","5ebb0201":"data['MESSAGE'].isnull().value_counts()","db5eccce":"data['MESSAGE'].isna().sum()","28dbea53":"data['MESSAGE'].isna().value_counts()","f327d564":"data['MESSAGE'].isna().any()","f4694995":"# Check if there sre empy emails (string lenth zero)\n(data.MESSAGE.str.len() == 0).any()","91a56237":"\n(data.MESSAGE.str.len() == 0).sum()","35c6a7d8":"data[(data.MESSAGE.str.len() == 0)]","2bad6db4":"data.MESSAGE.isnull().sum()","07dff4a5":"data[(data.MESSAGE.str.len() == 0)].index","3731e11c":"data.index.get_loc('cmds')","61eece6f":"data.drop(['cmds'], inplace=True)","64ce70a8":"data[(data.MESSAGE.str.len() == 0)].index","e871906c":"data.shape","6bdf3f6e":"document_ids = range(0, len(data.index))\ndocument_ids","45afb05b":"data['Doc_id'] = document_ids","a4f545e6":"data.head()","59465958":"data['FILE_NAME'] = data.index","b530dc44":"data.head()","e201b5f5":"data = data.set_index('Doc_id')","e4cbb9bc":"data.head()","ea2402a1":"data.sample(5)","fbfdc50e":"data.sample(5)","a0a0c62e":"#saving datafile\ndata.to_json('\/kaggle\/working\/DATA_JSON_FILE')","1671d6b3":"# NUmber of spam message\ndata['CATEGORY'].value_counts()","a2ad5861":"amount_of_spam = data.CATEGORY.value_counts()[1]\namount_of_ham = data.CATEGORY.value_counts()[0]","e0c0ccb9":"category_name = ['Spam', 'Legit Mail']\nsizes = [amount_of_spam, amount_of_ham]\n\nplt.figure(figsize=(6, 6), dpi=107)\nplt.pie(sizes, labels=category_name, textprops={'fontsize': 16}, autopct='%1.1f%%', explode=[0, 0.1])\nplt.show()","c084ccd5":"category_name = ['Spam', 'Legit Mail']\nsizes = [amount_of_spam, amount_of_ham]\n\nplt.figure(figsize=(6, 6), dpi=107)\nplt.pie(sizes, labels=category_name, textprops={'fontsize': 12}, autopct='%1.0f%%',startangle=90, )\n\n\n# draw circle\n\ncentre_circle = plt.Circle((0,0), radius=0.6, fc='white')\nplt.gca().add_artist(centre_circle)\nplt.show()","cf322686":"category_names = ['Spam', 'Legit Mail', 'Updates', 'Promotions']\nsizes = [25, 43, 19, 22]\ncustom_colours = ['#ff7675', '#74b9ff', '#55efc4', '#ffeaa7']\noffset = [0.05, 0.05, 0.05, 0.05]\n\nplt.figure(figsize=(2, 2), dpi=227)\nplt.pie(sizes, labels=category_names, textprops={'fontsize': 6}, startangle=90, \n       autopct='%1.0f%%', colors=custom_colours, pctdistance=0.8, explode=offset)\n\n# draw circle\ncentre_circle = plt.Circle((0, 0), radius=0.6, fc='white')\nplt.gca().add_artist(centre_circle)\n\nplt.show()","acf80645":"# Convert to llower case\nmsg = \"All the person In this World are good by Heart.\"\nmsg.lower()","8f5e9dff":"nltk.download('punkt')","54f34cd4":"nltk.download('stopwords')","3fc4f81a":"nltk.download('gutenberg')","a7576a6a":"nltk.download('shakespeare')","74f41f8a":"msg = 'All work and no play makes Jack a dull boy.'\nword_tokenize(msg.lower())","ee1c1d8c":"stop_words = set(stopwords.words('english'))","d28ca31e":"type(stop_words)","16845e3f":"if 'this'  in stop_words: print('Found it ')","6f86143f":"# Challenge: print out 'Nope. Not in here' if the word \"hello\" is not contained in stop_words\nif 'hello' not in stop_words: print('Nope!!, Its not there')","d3221954":"msg = 'All work and no play makes Jack a dull boy. To be or not to be.'\nwords = word_tokenize(msg.lower())\n\nfiltered_words = []\nfor word in words:\n    if word not in stop_words:\n        filtered_words.append(word)\n        \nprint(filtered_words)","15709b67":"msg = 'All work and no play makes Jack a dull boy. To be or not to be. \\ Nobody expects the Spanish Inquisition!'\nwords = word_tokenize(msg.lower())\n\nstemmer = PorterStemmer()\n\nfiltered_words = []\nfor word in words:\n    if word not in stop_words:\n        stemmed_word = stemmer.stem(word)\n        filtered_words.append(stemmed_word)\n        \nprint(filtered_words)","a885c31d":"msg = 'All work and no play makes Jack a dull boy. To be or not to be. \\ Nobody expects the Spanish Inquisition!'\nwords = word_tokenize(msg.lower())\n\nstemmer = SnowballStemmer('english')\n\nfiltered_words = []\nfor word in words:\n    if word not in stop_words:\n        stemmed_word = stemmer.stem(word)\n        filtered_words.append(stemmed_word)\n        \nprint(filtered_words)","3e432d03":"msg = 'All work and no play makes Jack a dull boy. To be or not to be. \\ Nobody expects the Spanish Inquisition!'\n\nwords = word_tokenize(msg.lower())\nstemmer = SnowballStemmer('english')\nfiltered_words = []\n\nfor word in words:\n    if word not in stop_words:\n        if word.isalpha():\n            stemmed_word = stemmer.stem(word)\n            filtered_words.append(stemmed_word)\n        \nprint(filtered_words)","b0a9d01b":"msg = 'All work and no play makes Jack a dull boy. To be or not to be. \\ Nobody expects the Spanish Inquisition!'\n\nwords = word_tokenize(msg.lower())\nstemmer = SnowballStemmer('english')\nfiltered_words = []\n\nfor word in words:\n    if word not in stop_words and word.isalpha():\n        stemmed_word = stemmer.stem(word)\n        filtered_words.append(stemmed_word)\n        \nprint(filtered_words)","6ecad925":"data.at[2, 'MESSAGE']","4120c532":"data.head()","c067d44f":"from bs4 import BeautifulSoup","a8c96fb6":"soup = BeautifulSoup(data.at[0, 'MESSAGE'], 'html.parser')","4867e6dd":"print(soup.prettify())","2b74b9e5":"soup.get_text()","4ad5afe1":"## Text Preprocessing","c838522a":"## remove system file entries","1cba300f":"## **Locate empty emails**","f3a06ced":"## Data Visualisation","1d425675":"# Natural Language Processing","ca028d67":"## Email body extraction","b7914265":"**Removing Panctuations**","464a1019":"## Add document IDs to track Emails in Dataset","3b1e06ab":"## Remmoving stop word","afd6d2f6":"## Data cleaning : Checking for missing value","0f7860c0":"## Tokenising","f870990d":" **Word stems**","8b69c5e2":"## Function for email processing"}}