{"cell_type":{"c4f5eb7c":"code","d4fa6920":"code","74147309":"code","fd6fcd0d":"code","2fe7e1c4":"code","79c53008":"code","30d00fe9":"code","974dd059":"code","c8a15ccd":"code","06a6a768":"code","a12c09aa":"code","6370ad81":"code","b14b02e2":"code","52bcc24b":"code","716b1b2f":"code","b4770521":"code","f5491d24":"code","ca0df690":"code","b6e9bdc6":"code","22005e93":"code","7672358e":"code","d4936d8d":"code","67f8affd":"code","91c95543":"code","d2ac33fc":"code","03729004":"code","e8191d73":"code","a8147ddf":"code","0c0630bb":"code","7280cf8d":"code","c4682cf9":"code","3f939698":"code","18e0258f":"code","785fd8d7":"code","90cac5da":"code","257a7a08":"code","e7fcc2c8":"code","3d06dbc7":"code","6e9e8046":"code","ded67885":"code","44933947":"code","bfe3ea6e":"code","a0e3845c":"code","1b56562e":"code","5b907b56":"code","6faa3768":"code","30279fd1":"code","2dd31fec":"code","26a65c9b":"markdown","1599da7e":"markdown","40043dd7":"markdown","5d7f98d8":"markdown","ff4eb865":"markdown","d4e149b9":"markdown","3d8b0938":"markdown","86cf7d82":"markdown","3e51f1d9":"markdown","a7b7e120":"markdown","f9f26048":"markdown","7c424271":"markdown","a601a850":"markdown","b833e85f":"markdown","479756b0":"markdown","a04d2a16":"markdown","a87d8adc":"markdown","eff1fe02":"markdown","03af959e":"markdown","cd398db5":"markdown","5aff75df":"markdown","1517e37d":"markdown","7d2e1e9f":"markdown","865e993c":"markdown","97a05be0":"markdown","cc05f905":"markdown","024554db":"markdown","2acff629":"markdown","72191212":"markdown","1f4e67b0":"markdown","4b20faf7":"markdown","27cb0346":"markdown","16795972":"markdown","9ce37185":"markdown","6ba967c6":"markdown","3d791b11":"markdown","695c3768":"markdown","e012f31e":"markdown","a745110d":"markdown","727ec26d":"markdown"},"source":{"c4f5eb7c":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn')\nimport seaborn as sns\nimport folium\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","d4fa6920":"df_raw = pd.read_csv('..\/input\/reviews_summary.csv')\ndf_raw.head(2)","74147309":"# drop unnecessary columns\ndf_raw.drop(['reviewer_id', 'reviewer_name', 'comments'], axis=1, inplace=True)\n\n# rename id column and replace current value simply with 1 to later count the # of reviews per accommodation\ndf_raw.rename({'id':'review_count'}, axis=1, inplace=True)\ndf_raw.review_count = 1\n\n# checking shape and duplicates\nprint(\"The first dataset has {} rows and {} columns.\".format(*df_raw.shape))\nprint(\"It contains {} duplicates.\".format(df_raw.duplicated().sum()))\n\ndf_raw.head(2)","fd6fcd0d":"df_raw.info()","2fe7e1c4":"# cast date-column from current object datatype to datetime datatype\ndf_raw.date = pd.to_datetime(df_raw.date, format=\"%Y-%m-%d\")","79c53008":"count_2017_18 = df_raw[df_raw[\"date\"].isin(pd.date_range('2017-11-01', '2018-10-31'))]\nprint(\"The dataset 2017\/2018 has {} reviews and {} columns.\".format(*count_2017_18.shape))","30d00fe9":"# set the date as index and sort by index\ncount_2017_18 = count_2017_18.set_index('date').sort_index()","974dd059":"# group by month and listing_id, i.e. specific apartment \n# agg argument: #work on this col:  {#name the new col : #perform count operation}                        \ncount_2017_18_monthly = count_2017_18.groupby([pd.TimeGrouper(freq='M'), 'listing_id'])['review_count']\\\n                                         .agg({'review_count':{'reviews_per_month':'count'}})\\\n                                         .reset_index()","c8a15ccd":"# initial check\ncount_2017_18_monthly.head(2)","06a6a768":"# to flatten the multi-index, we a) reset the index in the groupby statement above ...\n# ... and b) now define column names\ncount_2017_18_monthly.columns = ['date', 'listing_id', 'reviews_per_month']\n\n# set date as index again\ncount_2017_18_monthly.set_index('date', inplace=True)\n\n# check again\ncount_2017_18_monthly.head(2)","a12c09aa":"#count_2017_18_monthly[count_2017_18_monthly.listing_id==2015]","6370ad81":"# get rid of date index\ncount_2017_18_monthly = count_2017_18_monthly.reset_index()\n\n# group by listing_id and count reviews, turn it into a dataframe without groupby index\ncount_2017_18_monthly = pd.DataFrame(count_2017_18_monthly.groupby('listing_id')['reviews_per_month'].mean()\\\n                                                          .reset_index())\n\ncount_2017_18_monthly.head()","b14b02e2":"df_2 = pd.read_csv('..\/input\/listings_summary.csv')\ndf_2.head(1)","52bcc24b":"# merge full 2017\/2018 dataframe + add specific columns from df_2\ndf = pd.merge(count_2017_18_monthly, df_2[['id', 'price', 'cleaning_fee', 'neighbourhood_group_cleansed', \n                          'latitude', 'longitude', 'property_type', 'accommodates', \n                          'bathrooms', 'bedrooms', 'bed_type', 'host_is_superhost']], \n              left_on='listing_id', right_on='id')\n\n# drop 'id' from right dataframe as it's the same as 'listing_id' on the left dataframe\ndf.drop(['id'], axis=1, inplace=True)\n\n# shorten the name of one column\ndf.rename({'neighbourhood_group_cleansed':'neighbourhood'}, axis=1, inplace=True)\n\n# check the dataframe\nprint(\"The dataset has {} rows and {} columns - after combining it.\".format(*df.shape))\nprint(\"It contains {} duplicates.\".format(df.duplicated().sum()))\ndf.head(2)","716b1b2f":"df.info()","b4770521":"# convert price column into numeric value\ndf.price = df.price.str.replace('$', '').str.replace(',', '').astype(float).astype(int)\ndf.price.isna().sum()","f5491d24":"# replace missing values with zero and convert cleaning_fee column into numeric value\ndf.cleaning_fee.fillna('$0.00', inplace=True)\ndf.cleaning_fee = df.cleaning_fee.str.replace('$', '').str.replace(',', '').astype(float).astype(int)\ndf.cleaning_fee.isna().sum()","ca0df690":"# investigate price column\ndf['price'].describe()","b6e9bdc6":"# boxplot of price column\nred_square = dict(markerfacecolor='r', markeredgecolor='r', marker='.')\ndf['price'].plot(kind='box', xlim=(0, 1000), vert=False, flierprops=red_square, figsize=(16,2));","22005e93":"df.drop(df[df['price'] > 300].index, axis=0, inplace=True)\ndf['price'].describe()","7672358e":"avg_length_of_stay_berlin = 4.2\nreview_rate_modest = 0.5\n\n# calculate the occupancy and round the result\ndf['modest_occupancy'] = round(avg_length_of_stay_berlin * (df['reviews_per_month']\/review_rate_modest), 2)\n\n# occupancy cannot be greater than 100% - are there any mistakes?\nlen(df[df['modest_occupancy'] > 100])","d4936d8d":"# let's drop occupancy rates > 100\ndf.drop(df[(df['modest_occupancy'] > 100)].index, axis=0, inplace=True)\n\n# check the distribution\ndf['modest_occupancy'].describe()","67f8affd":"review_rate_optimistic = 0.4\n\n# calculate the occupancy and round the result\ndf['optimistic_occupancy'] = round(avg_length_of_stay_berlin * (df['reviews_per_month']\/review_rate_optimistic), 2)\n\n# occupancy cannot be greater than 100% - are there any mistakes?\nlen(df[df['optimistic_occupancy'] > 100])","91c95543":"# let's drop the occupancy rates > 100\ndf.drop(df[(df['optimistic_occupancy'] > 100)].index, axis=0, inplace=True)\n\n# check the distribution\ndf['optimistic_occupancy'].describe()","d2ac33fc":"sns.set_style(\"whitegrid\")\nplt.figure(figsize=(8,5))\n\nsns.distplot(df['modest_occupancy'], kde=False, bins=20, color='dimgrey')\nsns.distplot(df['optimistic_occupancy'], kde=False, bins=20, color='gold')\n\nplt.title('\\nAverage Occupancy Rate\\n', fontweight='bold')\nplt.legend(['Modest Estimate', 'Optimistic Estimate'])\nplt.xlabel('\\nMonthly Occupancy in %')\nplt.ylabel('Proportion of Accommodations\\n')\n\n# draw and label a line with median value of modest estimate\nplt.axvline(x=14, ymin=0, ymax=1, linewidth=1, linestyle=':', color='black')\nplt.text(14.5, 5350, 'Median (Modest Estimate)')\n\n# draw and label a line with median value of optimistic estimate\nplt.axvline(x=17.5, ymin=0, ymax=0.9, linewidth=1, linestyle='-', color='gold')\nplt.text(18, 4500, 'Median (Optimistic Estimate)', color='goldenrod');","03729004":"df['modest_income'] = df['modest_occupancy'] * df['price'] * 12\ndf.modest_income.describe()","e8191d73":"df['optimistic_income'] = df['optimistic_occupancy'] * df['price'] * 12\ndf.optimistic_income.describe()","a8147ddf":"sns.set_style(\"whitegrid\")\nplt.figure(figsize=(8,5))\n\nsns.distplot(df['modest_income'], kde=False, bins=100, color='dimgrey')\nsns.distplot(df['optimistic_income'], kde=False, bins=100, color='crimson')\n\nplt.title('\\nAverage Yearly Income\\n', fontweight='bold')\nplt.legend(['Modest Estimate', 'Optimistic Estimate'])\nplt.xlabel('\\nYearly Income in \u20ac')\nplt.xlim((0,100000))\nplt.ylabel('Proportion of Accommodations\\n')\n\n# draw and label a line with median value of modest estimate\nplt.axvline(x=8709, ymin=0, ymax=1, linewidth=1, linestyle=':', color='black')\nplt.text(9350, 2650, 'Median (Modest Estimate)')\n\n# draw and label a line with median value of optimistic estimate\nplt.axvline(x=10886, ymin=0, ymax=0.9, linewidth=1, linestyle='-', color='firebrick')\nplt.text(12000, 2350, 'Median (Optimistic Estimate)', color='firebrick');","0c0630bb":"sns.set(style=\"white\")\ncorr = df.corr()\n\n# generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# set up the matplotlib figure\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\":.5});","7280cf8d":"# split the data by date\ncount_2018 = df_raw[df_raw[\"date\"].isin(pd.date_range('2018-01-01', '2018-10-31'))]\ncount_2017 = df_raw[df_raw[\"date\"].isin(pd.date_range('2017-01-01', '2017-12-31'))]\ncount_2016 = df_raw[df_raw[\"date\"].isin(pd.date_range('2016-01-01', '2016-12-31'))]\ncount_2015 = df_raw[df_raw[\"date\"].isin(pd.date_range('2015-01-01', '2015-12-31'))]\n\n# set the date as index and sort by index\ncount_2018 = count_2018.set_index('date').sort_index()\ncount_2017 = count_2017.set_index('date').sort_index()\ncount_2016 = count_2016.set_index('date').sort_index()\ncount_2015 = count_2015.set_index('date').sort_index()\n\n# calculate reviews per month                       \ncount_2018_monthly = count_2018.groupby([pd.TimeGrouper(freq='M'), 'listing_id'])['review_count']\\\n                                         .agg({'review_count':{'reviews_per_month_18':'count'}})\\\n                                         .reset_index()\ncount_2017_monthly = count_2017.groupby([pd.TimeGrouper(freq='M'), 'listing_id'])['review_count']\\\n                                         .agg({'review_count':{'reviews_per_month_17':'count'}})\\\n                                         .reset_index()\ncount_2016_monthly = count_2016.groupby([pd.TimeGrouper(freq='M'), 'listing_id'])['review_count']\\\n                                         .agg({'review_count':{'reviews_per_month_16':'count'}})\\\n                                         .reset_index()\ncount_2015_monthly = count_2015.groupby([pd.TimeGrouper(freq='M'), 'listing_id'])['review_count']\\\n                                         .agg({'review_count':{'reviews_per_month_15':'count'}})\\\n                                         .reset_index()\n\n# flatten the multi-index\ncount_2018_monthly.columns = ['date', 'listing_id', 'reviews_per_month_18']\ncount_2017_monthly.columns = ['date', 'listing_id', 'reviews_per_month_17']\ncount_2016_monthly.columns = ['date', 'listing_id', 'reviews_per_month_16']\ncount_2015_monthly.columns = ['date', 'listing_id', 'reviews_per_month_15']\n\n# set date as index\ncount_2018_monthly.set_index('date', inplace=True)\ncount_2017_monthly.set_index('date', inplace=True)\ncount_2016_monthly.set_index('date', inplace=True)\ncount_2015_monthly.set_index('date', inplace=True)","c4682cf9":"sns.set(style=\"dark\")\nfig, axes = plt.subplots(4, 1, figsize=(12,10))\n\nsub_1 = count_2018_monthly.groupby('date')['reviews_per_month_18'].mean()\nsub_1.plot(ax=axes[0], color='midnightblue', style=':')\naxes[0].set_title('2018', fontweight='bold')\naxes[0].set_xlabel('') \n\nsub_2 = count_2017_monthly.groupby('date')['reviews_per_month_17'].mean()\nsub_2.plot(ax=axes[1], color='grey', style=':')\naxes[1].set_title('2017', fontweight='bold')\naxes[1].set_xlabel('') \n\nsub_3 = count_2016_monthly.groupby('date')['reviews_per_month_16'].mean()\nsub_3.plot(ax=axes[2], color='coral', style=':')\naxes[2].set_title('2016', fontweight='bold')\naxes[2].set_xlabel('') \n\nsub_4 = count_2015_monthly.groupby('date')['reviews_per_month_15'].mean()\nsub_4.plot(ax=axes[3], color='forestgreen', style=':')\naxes[3].set_title('2015', fontweight='bold')\naxes[3].set_xlabel('') \n\n# adjust space between subplots and set a title\nplt.subplots_adjust(hspace = 0.6)\nplt.suptitle('\\nAverage Reviews per Month for Berlin\\n', fontweight='bold')\n\n# plot common y-label\nfig.text(0.04, 0.5, 'Average Reviews per Month', fontweight='bold', va='center', rotation='vertical');","3f939698":"# check super host column for NaN's\ndf.host_is_superhost.isna().sum()","18e0258f":"# replace NaN's with value 'false' for not being a superhost\ndf.host_is_superhost.fillna(value='f', inplace=True)\ndf.host_is_superhost.isna().sum()","785fd8d7":"# assign the data\nsuper_host    = df.host_is_superhost.value_counts()['t']\nno_super_host = df.host_is_superhost.value_counts()['f']\nnames = ['Super Hosts','Standard Hosts']\nsize  = [super_host, no_super_host]\n\n# create a pie chart\nplt.pie(size, labels=names, colors=['darkorange','silver'], \n        autopct='%.2f%%', pctdistance=1.28,\n        wedgeprops={'linewidth':7, 'edgecolor':'white'})\n\n# create circle for the center of the plot to make the pie look like a donut\nmy_circle = plt.Circle((0,0), 0.6, color='white')\n\n# plot the donut chart\nfig = plt.gcf()\nfig.set_size_inches(7,7)\nfig.gca().add_artist(my_circle)\nplt.show()","90cac5da":"# the overall median differences between superhosts and standard hosts\ndf.groupby('host_is_superhost')['modest_occupancy'].agg(np.median)","257a7a08":"# group by neighbourhood and by status, then take the median occupancy\ndf_grouped = pd.DataFrame(df.groupby(['neighbourhood', 'host_is_superhost'])['modest_occupancy'].agg(np.median))\ndf_grouped.sort_values(by='modest_occupancy', ascending=False, inplace=True)\ndf_grouped.reset_index(inplace=True)\n\n# plot grouped dataframe with seaborn\nsns.set_style('darkgrid')\nfig, ax = plt.subplots(figsize=(10, 9))\nsns.barplot(x='modest_occupancy', y='neighbourhood', hue='host_is_superhost', hue_order=['t', 'f'], \n            data=df_grouped, palette=\"Blues_r\")\n\n# add title and axis label\nax.set_title('\\nOccupancy by Area and Host Status\\n', fontsize=14, fontweight='bold')\nax.set(xlabel='Average Occupancy in % (Modest Estimate)')\n\n# rename legend labels & put legend outside plot\nhandles, labels = ax.get_legend_handles_labels()\nax.legend((handles), ('Super Host', 'Normal Host'), bbox_to_anchor=(1.05, 1), borderaxespad=0.);","e7fcc2c8":"# the overall median differences between superhosts and standard hosts\ndf.groupby('host_is_superhost')['modest_income'].agg(np.median)","3d06dbc7":"# group by neighbourhood and by status, then take the median income\ndf_grouped = pd.DataFrame(df.groupby(['neighbourhood', 'host_is_superhost'])['modest_income'].agg(np.median))\ndf_grouped.sort_values(by='modest_income', ascending=False, inplace=True)\ndf_grouped.reset_index(inplace=True)\n\n# plot grouped dataframe with seaborn\nsns.set_style('dark')\nfig, ax = plt.subplots(figsize=(10, 9))\nsns.barplot(x='modest_income', y='neighbourhood', hue='host_is_superhost', hue_order=['t', 'f'], \n            data=df_grouped, palette=\"Purples_r\")\n\n# add title and axis label\nax.set_title('\\nIncome by Area and Host Status\\n', fontsize=14, fontweight='bold')\nax.set(xlabel='\\nAverage Income in \u20ac (Modest Estimate)')\n\n# rename legend labels & put legend outside plot\nhandles, labels = ax.get_legend_handles_labels()\nax.legend((handles), ('Super Host', 'Normal Host'), bbox_to_anchor=(1.25, 1), borderaxespad=0.);","6e9e8046":"def lollipop_with_2(dataframe, about, y_col, x1_col, x2_col):\n    ''' Function that creates a lollipop chart with \n    two observations (x-values) per group (y-value). '''\n       \n    # set style\n    sns.set_style(\"dark\")\n    \n    # prepare data\n    df_plot = dataframe[[y_col, x1_col, x2_col]].groupby(y_col).apply(lambda x: x.mean())\n    df_plot.sort_values(x1_col, inplace=True)\n    df_plot.reset_index(inplace=True)\n        \n    # draw plot\n    fig, ax = plt.subplots(figsize=(10,8))\n    ax.hlines (y=df_plot.index, xmin=df_plot[x1_col], xmax=df_plot[x2_col], color='grey', alpha=0.7, linewidth=2)\n    ax.scatter(y=df_plot.index, x=df_plot[x1_col], s=75, color='skyblue', alpha=0.7, label=x1_col)\n    ax.scatter(y=df_plot.index, x=df_plot[x2_col], s=75, color='darkblue', alpha=0.7, label=x2_col)\n    ax.legend()\n    \n    # title, label, ticks and xlim\n    ax.set_title('\\nAverage ' + about + ' by District\\n', fontdict={'size':12, 'weight':'bold'})\n    ax.set_xlabel('\\n' + about)\n    ax.set_yticks(df_plot.index)\n    ax.set_yticklabels(df_plot[y_col], rotation=0, \n                       fontdict={'horizontalalignment': 'right', 'size':12})\n    \n    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n    plt.show()","ded67885":"lollipop_with_2(df, 'Occupancy Estimate in %', 'neighbourhood', 'modest_occupancy', 'optimistic_occupancy')","44933947":"lollipop_with_2(df, 'Income Estimate in \u20ac', 'neighbourhood', 'modest_income', 'optimistic_income')","bfe3ea6e":"lollipop_with_2(df, 'Fees in \u20ac', 'neighbourhood', 'cleaning_fee', 'price')","a0e3845c":"def lollipop_with_highlight(dataframe, about, y_col, y_highlight, x_col):\n    ''' Function that creates a lollipop chart with only one observation (x-value) \n    per group (y-value) and the option to highlight one of the grouped values. '''\n    \n    # set style\n    sns.set_style(\"dark\")\n    \n    # prepare data\n    df_plot = dataframe[[y_col, x_col]].groupby(y_col).apply(lambda x: x.mean())\n    df_plot.sort_values(x_col, inplace=True)\n    df_plot.reset_index(inplace=True)\n\n    # highlight district specified as y_highlight\n    my_color = np.where(df_plot[y_col] == y_highlight, 'crimson', 'skyblue')\n    my_size  = np.where(df_plot[y_col] == y_highlight, 70, 30)\n\n    # draw plot\n    fig, ax = plt.subplots(figsize=(8,8))\n    ax.hlines (y=df_plot.index, xmin=0, xmax=df_plot[x_col], color=my_color, alpha=0.5, linewidth=2)\n    ax.scatter(y=df_plot.index, x=df_plot[x_col], s=my_size, color=my_color, alpha=1, label=x_col)\n    ax.legend()\n\n    # title, label, ticks and xlim\n    ax.set_title('\\nAverage ' + about + ' by District\\n', fontdict={'size':12, 'weight':'bold'})\n    ax.set_xlabel('\\n' + about)\n    ax.set_yticks(df_plot.index)\n    ax.set_yticklabels(df_plot[y_col], rotation=0, \n                       fontdict={'horizontalalignment': 'right', 'size':12})\n    \n    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n    plt.show()","1b56562e":"lollipop_with_highlight(df, 'Occupancy Estimate', 'neighbourhood', 'Mitte', 'optimistic_occupancy')","5b907b56":"lollipop_with_highlight(df, 'Income Estimate', 'neighbourhood', 'Mitte', 'optimistic_income')","6faa3768":"sns.set_style(\"darkgrid\")\nfig, ax = plt.subplots(figsize=(9,6))\n\nsns.scatterplot(x=\"accommodates\", y=\"modest_occupancy\", color='rosybrown',  data=df)\n\nplt.title('\\nAverage Occupancy by Capacity\\n', fontsize=12, fontweight='bold')\nplt.xlabel('\\nNumber of Max. People per Accommodation')\nplt.ylabel('Occupancy (Modest Estimate)\\n');","30279fd1":"# group by accomodates and plot median occupancy\ndf.groupby('accommodates')['modest_occupancy']\\\n                          .median()\\\n                          .plot(kind='bar', figsize=(10,6), color='rosybrown')\n\n# beautify the plot\nplt.xlabel('\\nNumber of Max. People per Accommodation', fontsize=12)\nplt.xticks(rotation='horizontal')\nplt.ylabel('Average Occupancy in %\\n', fontsize=12)\nplt.title('\\nAverage Occupancy by Capacity\\n', fontsize=12, fontweight='bold')\n\n# draw and label the median value\nplt.axhline(y=14.7, xmin=0, xmax=1, linewidth=1, linestyle=':', color='black')\nplt.text(x=15.6, y=14.2, s='Overall Median (Modest Estimate)');","2dd31fec":"# prepare plot\nsns.set_style(\"white\")\ncmap = sns.cubehelix_palette(rot=-.2, as_cmap=True)\nfig, ax = plt.subplots(figsize=(11,7))\n\n# draw scatter plot\nax = sns.scatterplot(x=\"longitude\", y=\"latitude\", size='modest_occupancy', sizes=(5, 200),\n                     hue='accommodates', palette=cmap,  data=df)\nax.legend(bbox_to_anchor=(1.3, 1), borderaxespad=0.)\nplt.title('\\nAccommodations in Berlin by Capacity & Occupancy\\n', fontsize=12, fontweight='bold')\n\n# remove spines\nsns.despine(ax=ax, top=True, right=True, left=True, bottom=True);","26a65c9b":"**> Seasonality**\n\nThe high season for lodgings in Berlin is during late spring and early summer (specifically from May to July) and during the autumn months September and October. You could use your apartment yourself during the rest of year and offer it in these periods to get the most out of it.\n\n**> Super Host**\n\nTo be a superhost is to be a cash machine. The occupancy rate in superhost lodgings is almost twice as high as in standard host lodgings, and the income is 60% higher.\n\n**> Location, Location, Location**\n\nIf you don't want to live in the vibrant, loud center of Berlin yourselves - well, that's bad luck for you! That's precisely where tourists are looking to to rent Airbnb accommodations, particularly in *Mitte* or *Charlottenburg*, \nand are willing to pay more for them than for lodgings in outlying districts.\n\n**> Capacity**\n\nTravelers in (bigger) groups benefit much more from how much they save by using Airbnb than couples or small groups do. That implies that lodgings accommodating 6+ people tend to be more in-demand than smaller ones.","1599da7e":"So far we only have a simple count of reviews per lodging. Let's use a second dataset to enrich our data:","40043dd7":"*Back to: <a href='#Table of contents'> Table of contents<\/a>*\n#### 2.2. Combining Datasets\n<a id='2.2. Combining Datasets'><\/a>","5d7f98d8":"*Back to: <a href='#Table of contents'> Table of contents<\/a>*\n#### 3.4. Demand by Neighbourhood\n<a id='3.4. Demand by Neighbourhood'><\/a>","ff4eb865":"*Comparing Occupancy Estimates*","d4e149b9":"*Lollipop Charts with two observations*","3d8b0938":"*Back to: <a href='#Table of contents'> Table of contents<\/a>*\n#### 3.2. Seasonal Demand\n<a id='3.2. Seasonal Demand'><\/a>","86cf7d82":"Generally, bigger homes seem to be sold more often than smaller ones. Perhaps this is due to the fact that a group might be able to save more money than 1-2 persons would by using Airbnb. It follows that accommodations with a bigger capacity enjoy greater popularity.","3e51f1d9":"Using our modest and optimistic estimates for the occupancy rate, we'll now do the same for income:","a7b7e120":"#### 2.1. Engineer Reviews per Month\n<a id='2.1. Engineer Reviews per Month'><\/a>","f9f26048":"*Back to: <a href='#Table of contents'> Table of contents<\/a>*\n#### 2.4. Occupancy Estimate\n<a id='2.4. Occupancy Estimate'><\/a>","7c424271":"*Back to: <a href='#Table of contents'> Table of contents<\/a>*\n#### 2.5. Income Estimate\n<a id='2.5. Income Estimate'><\/a>","a601a850":"#### 3.1. Getting Started with a Heat Map\n<a id='3.1. Getting Started with a Heat Map'><\/a>","b833e85f":"*2. Calculate reviews per month*","479756b0":"To examine if there's an underlying seasonality, let's split the dataset we loaded at the very beginning by year. We'll repeat the exact same steps we used earlier to pull out the full calendar year.","a04d2a16":"*Back to: <a href='#Table of contents'> Table of contents<\/a>*\n### 3. Exploratory Data Analysis (EDA)\n<a id='3. Exploratory Data Analysis (EDA)'><\/a>","a87d8adc":"All resources used in this notebook are listed below.\n\nData\n- Inside Airbnb: http:\/\/insideairbnb.com\/get-the-data.html\n\nOccupancy Model\n- http:\/\/insideairbnb.com\/about.html\n- https:\/\/www.airbnbcitizen.com\/hosts-on-airbnb-have-welcomed-700000-guests-to-berlin-in-2017\/\n- https:\/\/www.airbnbcitizen.com\/wp-content\/uploads\/2016\/04\/airbnb-community-berlin-en.pdf\n\nLollipop Plots\n- https:\/\/python-graph-gallery.com\/184-lollipop-plot-with-2-groups\/\n- https:\/\/python-graph-gallery.com\/183-highlight-a-group-in-lollipop\/\n- https:\/\/www.machinelearningplus.com\/plots\/top-50-matplotlib-visualizations-the-master-plots-python\/#16.-Lollipop-Chart\n\nBubble Plots\n- https:\/\/glowingpython.blogspot.com\/2011\/11\/how-to-make-bubble-charts-with.html\n- https:\/\/seaborn.pydata.org\/examples\/scatterplot_sizes.html\n\nInspiration\n- https:\/\/towardsdatascience.com\/airbnb-rental-listings-dataset-mining-f972ed08ddec\n- https:\/\/towardsdatascience.com\/improving-airbnb-yield-prediction-with-text-mining-9472c0181731\n- https:\/\/www.kaggle.com\/yogi045\/how-to-become-top-earner-in-airbnb?utm_medium=email&utm_source=intercom&utm_campaign=datanotes-2019","eff1fe02":"### 1. Obtaining and Viewing the Data \n<a id='1. Obtaining and Viewing the Data'><\/a>","03af959e":"Unsurprisingly, *Mitte* is the most in-demand area; it's a hotspot, right in the center, and close to most places of interest. But why the heck is *Reinickendorf* at the top?","cd398db5":"*Back to: <a href='#Table of contents'> Table of contents<\/a>*\n### 5. Appendix \n<a id='5. Appendix'><\/a>","5aff75df":"*Back to: <a href='#Table of contents'> Table of contents<\/a>*\n### 4. Interpreting the Data\n<a id='4. Interpreting the Data'><\/a>","1517e37d":"The boxplot above shows quite a skewed distribution with a long tail of high-priced outliers. However, 75% of all rentals only cost up to 70 Euro. For this project, let's remove the extremely high priced rentals above \u20ac 300\/night to maintain comparability.","7d2e1e9f":"As we can see above, `price` and `cleaning_fee` are both string columns, with the latter containing substantial null values that most likely mean that these hoste do not charge cleaning fees. Let's quickly tidy up here:","865e993c":"Let's take the most consecutive 12 months we can get a hold of. As the scraping took place on November 07th 2018, we can have a full year starting November 1st, 2017 and ending October 31st, 2018:","97a05be0":"## Table of Contents\n<a id='Table of contents'><\/a>\n\n### <a href='#1. Obtaining and Viewing the Data'> 1. Obtaining and Viewing the Data <\/a>\n\n### <a href='#2. Preprocessing the Data'> 2. Preprocessing the Data <\/a>\n* <a href='#2.1. Engineer Reviews per Month'> 2.1. Engineer Reviews per Month <\/a>\n* <a href='#2.2. Combining Datasets'> 2.2. Combining Datasets <\/a>\n* <a href='#2.3. Cleaning the Price Columns'> 2.3. Cleaning the Price Columns <\/a>\n* <a href='#2.4. Occupancy Estimate'> 2.4. Occupancy Estimate <\/a>\n* <a href='#2.5. Income Estimate'> 2.5. Income Estimate <\/a>\n\n### <a href='#3. Exploratory Data Analysis (EDA)'> 3. Exploratory Data Analysis (EDA) <\/a>\n* <a href='#3.1. Getting Started with a Heat Map'> 3.1. Getting Started with a Heat Map <\/a>\n* <a href='#3.2. Seasonal Demand'> 3.2. Seasonal Demand <\/a>\n* <a href='#3.3. Demand by Status SUPERHOST'> 3.3. Demand by Status SUPERHOST <\/a>\n* <a href='#3.4. Demand by Neighbourhood'> 3.4. Demand by Neighbourhood <\/a>\n* <a href='#3.5. Demand by Capacity'> 3.5. Demand by Capacity <\/a>\n\n* <a href='#3.6. Demand by Price'> 3.6. Demand by Price <\/a>\n\n### <a href='#4. Interpreting the Data'> 4. Interpreting the Data <\/a>\n\n### <a href='#5. Appendix'> 5. Appendix <\/a>","cc05f905":"*What do the differences between super hosts and standard hosts look like?*","024554db":"It's definitely worth aspring to become a super host! The differences in occupancy and income are striking!","2acff629":"*Back to: <a href='#Table of contents'> Table of contents<\/a>*\n#### 3.3. Demand by Status SUPERHOST\n<a id='3.3. Demand by Status SUPERHOST'><\/a>","72191212":"*Back to: <a href='#Table of contents'> Table of contents<\/a>*\n### 2. Preprocessing the Data \n<a id='2. Preprocessing the Data'><\/a>","1f4e67b0":"*Optimistic Estimate*\n\nNow let's try for a more optimistic estimate of occupancy using a review rate of 0.4, which assumes that only 40% of all guests left a review. This way, the number of reviews points to a higher occupancy than in the modest estimate we had before:","4b20faf7":"*Modest Estimate*\n\nWith a very modest review rate of 0.5, we are assuming that only every second guest left a review. While I could see many more than just half the visitors actually writing feedback, let's calculate this conservative estimate first:","27cb0346":"It appears to be that *Reinickendorf* benefits from rather low room rates, which lead to a high occupancy - as seen above. When it comes to earnings, Mitte is in the lead.","16795972":"*Back to: <a href='#Table of contents'> Table of contents<\/a>*\n#### 2.3. Cleaning the Price Columns\n<a id='2.3. Cleaning the Price Columns'><\/a>","9ce37185":"*Back to: <a href='#Table of contents'> Table of contents<\/a>*\n#### 3.5. Demand by Capacity\n<a id='3.5. Demand by Capacity'><\/a>","6ba967c6":"*1. Process the date column and create a new dataframe*","3d791b11":"## Explaining the Demand & Expected Earnings\n\nAirbnb has successfully disrupted the traditional hospitality industry as more and more travelers decide to use Airbnb as their primary accommodation provider. Since its inception in 2008, Airbnb has seen an enormous growth, with the number of rentals listed on its website growing exponentially each year.\n\nIn Germany, no city is more popular than Berlin. That implies that Berlin is one of the hottest markets for Airbnb in Europe, with over 22,552 listings as of November 2018. With a size of 891 km\u00b2, this means there are roughly 25 homes being rented out per km\u00b2 in Berlin on Airbnb!\n\nConsidering the possibility that I might have to relocate for a new data science job, but want to keep my current flat in Berlin (which is quite cheap!), I might wonder if it could be worth it to offer my jewel on Airbnb. Could this perhaps be a profitable option? However, it is difficult for potential hosts to know what the true value of their home is, and how in-demand their home might be. And since location and furniture are obviously fixed for the most part, is there anything else a host can influence - such as description, communication patterns, and\/or additional services to boost their earnings?\n\nThe following question will drive this project:\n\n> **How big is the demand likely to be? What can a host expect with respect to occupancy and earnings here in Berlin? What factors influence how in-demand it is?**\n\n### The datasets\n\nIn this notebook, I will combine the summary listings and the detailed Berlin listings data, sourced from the Inside Airbnb website. The goal is to visualize the rental landscape and to try to understand the aspects influencing the demand. Both datasets were scraped on November 07th, 2018.","695c3768":"Be aware that - unlike the other plots - the one for 2018 only ranges from January to October! \n\nHaving said that, we can see the same pattern each and every year: the visitors peak from May to July, and then again in September and October. It drops significantly during August and the winter months. The pattern in August is interesting: tourists seem to avoid city trips in the, liekely preferring to go on beach holidays.","e012f31e":"There is reason to believe that \n- a) the number of people that can be `accommodated` as an indicator for **size or capacity** and \n- b) the `latitude` as a proxy for **location** may help explaining the demand. \n\n(The feature `reviews_per_month` is what we used to estimate the occupancy, so no wonder the correlation is a vivid red.)\n\nI assume there might be also some **seasonality** that strongly influences the demand. Furthermore, I believe that the so-called **super host status** does benefit these hosts, who probably get far more guests than standard hosts. As the heat map only uses numeric columns, it can't show any such relationship \u2014 so let's walk through all of these factors to visually investigate their effect on demand:","a745110d":"One of the biggest issues with Airbnb is getting the occupancy rate for each host or for a market. *Inside Airbnb*, the website I sourced the data from, uses an occupancy model which they call the \"San Francisco Model\" with the following methodology:\n\n1. A **Review Rate** of 50% is used to convert reviews to estimated bookings. Other administrative authorities are said to use a review rate of 72% (however this may be attributed to an unreliable source: Airbnb's CEO and co-founder Brian Chesky) - or one of 30.5% (based on comparing public data of reviews to the The New York Attorney General\u2019s report on Airbnb released in October 2014.) *Inside Airbnb* chose 50% as it sits almost exactly between 72% and 30.5%. It basically means that only 50% of all visitors write a review. With that said, the number of reviews per month divided by the review rate equals an estimate of actual visitors.\n2. An **average length of stay** for each city is usually published by Airbnb. This number multiplied by the estimated bookings for each listing over a period of time gives **the occupancy rate**.\n3. Finally, the **income** can be calculated by multiplying the occupancy rate by the price and the time period of interest - here, 12 months:\n\n>**Monthly Occupancy Rate = Average Length of Stay * (No. of reviews per Month \/ Review Rate)**<br>\n*According to the latest Airbnb update, guests who booked stays in Berlin in 2017 via Airbnb spent 4.2 nights here on average.*\n\n>**Yearly Income = Monthly Occupancy Rate * Price * 12 Months**","727ec26d":"*Lollipop Charts with one observation and one group highlighted*"}}