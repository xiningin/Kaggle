{"cell_type":{"2619317d":"code","468464ab":"code","8fd47dcf":"code","ff919415":"code","f8475b3a":"code","1b4561d1":"code","69f4434e":"code","ec954fe4":"code","2f14040c":"code","e4098679":"code","a51c7ce6":"code","9fbcb7e2":"code","1d94c932":"code","5bc815db":"code","1069182d":"code","32879b5f":"code","ef8189f7":"code","85c60a55":"code","f3721b68":"code","9017f709":"code","735874f0":"code","d8415812":"code","237a5fcd":"code","39522ca7":"code","e5dae5e4":"code","3dafaa2e":"code","0d53e198":"code","9441701c":"code","fd5f06ff":"code","2fee13e7":"code","b6086fdf":"code","a0b12208":"code","167d1b6b":"code","b6849cf0":"code","0fb350f7":"code","898d8645":"code","845fd399":"code","17ff9570":"code","1592c24b":"code","0f99445f":"code","711ea23b":"code","350f1f1d":"code","bb007532":"code","d3e297c9":"code","7bd8bfcb":"code","7015b37b":"code","be2e1171":"code","a1e85a65":"code","0b8f828d":"code","4dae5861":"markdown","c87a7c92":"markdown","cd9ceb3b":"markdown","f208e74f":"markdown","1d3d788a":"markdown","6e514f67":"markdown","19b9e773":"markdown"},"source":{"2619317d":"#Import libraries\nimport numpy as np \nimport pandas as pd \nimport nltk\nfrom nltk.corpus import stopwords\nimport string","468464ab":"import os\nfor dirname, _, filenames in os.walk('..\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","8fd47dcf":"#read csv file & assign to a dataframe from https:\/\/www.kaggle.com\/karthickveerakumar\/spam-filter\/version\/1#emails.csv\ndf = pd.read_csv(\"..\/input\/spam-filter\/emails.csv\")","ff919415":"#show the first 5 elements of the csv\ndf.head(10)","f8475b3a":"#print number of rows and columns\ndf.shape","1b4561d1":"df.info()","69f4434e":"#show element n\nprint(df.iloc[100][0])\n","ec954fe4":"df.isnull().sum() #shows how many rows are null, this is good practice if we want to take care of null value in data prep","2f14040c":"#In Python3, string.punctuation is a pre-initialized string used as string constant, this contain all the punctuation\npunct= string.punctuation","e4098679":"punct","a51c7ce6":"#nltk.download('stopwords')\n#this package from natural language toolkit contains all the stopword in the major languages","9fbcb7e2":"stop_words = set(stopwords.words(\"italian\"))","1d94c932":"stop_words","5bc815db":"#now we remove all punctuations and stop words\ndf","1069182d":"def remove_punct(text):\n    nopunct = [char for char in text if char not in punct]\n    nopunct = ''.join(nopunct)\n    return(nopunct)\n\n#this function remove the punctuation\n    ","32879b5f":"df1 = df['text'].apply(remove_punct)","ef8189f7":"df1","85c60a55":"#now we remove all stop words\ndef remove_stop(text):\n    nostop = [word for word in text.split() if word.lower() not in stop_words]\n    return(nostop)","f3721b68":"df2 = df1.apply(remove_stop)","9017f709":"df2 #at this point we have a list of tokens to analyze","735874f0":"def remove_everything(text):\n    return remove_stop(remove_punct(text))\n\n#this is definetely not the best coding - but is just to show the progression","d8415812":"df['text'].apply(remove_everything)","237a5fcd":"from sklearn.feature_extraction.text import CountVectorizer\n#https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_extraction.text.CountVectorizer.html","39522ca7":"message = 'KEA is a university, \/\/\/\/\/located in N\u00f8rrebro I love burger burger'\nmessage2 = \"are great or burger, burger\"\nmessage3 = 'hey i love berries and burger love burger a lot burger'\nprint(message)","e5dae5e4":"vectorizer = CountVectorizer(analyzer=remove_everything)\n#initialize a vector object\n","3dafaa2e":"vect_fit_trans = vectorizer.fit_transform([message,message2,message3]) \n#run the function fit_transform over the array of messages","0d53e198":"vectorizer.get_feature_names()\n#shows all the features extracted - they are simply put in alphabetical order","9441701c":"print(vect_fit_trans)\n#each word is transformed into a vector (x,y) n\n#bag of words","fd5f06ff":"transformvc = CountVectorizer(analyzer=remove_everything)","2fee13e7":"FiTrannsformvc = transformvc.fit_transform(df['text'])","b6086fdf":"transformvc.get_feature_names()\n","a0b12208":"#now we split the dataset 80% for training and 20% for test\nfrom sklearn.model_selection import train_test_split\n","167d1b6b":"X_train, X_test, y_train, y_test = train_test_split(FiTrannsformvc, df['spam'], test_size=0.20, random_state=75)","b6849cf0":"from sklearn.naive_bayes import MultinomialNB\nclassifier = MultinomialNB()\nclassifier.fit(X_train, y_train)\n\n# I used Naive Bayes, being one of the most popular algoryth for spam detection\n# https:\/\/www.quora.com\/What-are-the-popular-ML-algorithms-for-email-spam-detection","0fb350f7":"X_train.shape #verify that train & test have the same shape, we fit_transform before the split, therefore it shouldn't be a problem","898d8645":"X_test.shape","845fd399":"print(classifier.predict(X_train))\nprint(y_train.values)","17ff9570":"from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\npred = classifier.predict(X_train)\nprint(classification_report(y_train ,pred ))\nprint('Confusion Matrix: \\n',confusion_matrix(y_train,pred))\nprint()\nprint('Accuracy: ', accuracy_score(y_train,pred))","1592c24b":"import seaborn as sn\nimport matplotlib.pyplot as plt","0f99445f":"#Print the predictions\nprint('Predicted value: ',classifier.predict(X_test))\n\n#Print Actual Label\nprint('Actual value: ',y_test.values)","711ea23b":"#here we evaluate the model on the test data set\nfrom sklearn.metrics import classification_report,confusion_matrix, accuracy_score\npred = classifier.predict(X_test)\nprint(classification_report(y_test ,pred ))\n\n\nprint('Confusion Matrix: \\n', confusion_matrix(y_test,pred))\nprint()\nprint('Accuracy: ', accuracy_score(y_test,pred))","350f1f1d":"type(X_test)\nX_test.shape\n","bb007532":"realmsg = '''\nINSERT A MESSAGE HERE\n'''\nprint(realmsg)","d3e297c9":"realvector = transformvc.transform([realmsg])","7bd8bfcb":"type(realvector)\nrealvector.shape\n","7015b37b":"confidence = classifier.predict_proba(realvector)\nprediction = classifier.predict(realvector)\n","be2e1171":"print(confidence[0,1])","a1e85a65":"if confidence[0,1] > 0.8:\n    print(\"This e-mail is Spam\")\nelif (confidence[0,1] > 0.5) and (confidence[0,1] < 0.8):\n    print(\"This e-mail seems to be Spam, check it\")\nelse:\n    print(\"This e-mail is legit\")","0b8f828d":"print(prediction)","4dae5861":"### Import Libraries","c87a7c92":"### Transform the entire df","cd9ceb3b":"### Example of transforming a string into a countvector","f208e74f":"### Train the model","1d3d788a":"### try on a personal email","6e514f67":"### Split the Dataset","19b9e773":"### Clean the DataFrame"}}