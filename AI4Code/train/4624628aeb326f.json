{"cell_type":{"83fe230e":"code","1202bedd":"code","61886876":"code","7bdad929":"code","e5a79098":"code","ba5dea54":"code","6a67a01b":"code","0a1b78c5":"code","9ad18008":"code","a451b017":"code","df4368ea":"code","b2447b97":"code","281c3d35":"code","d9313b48":"code","0d0db699":"code","9b60c84a":"code","089f1f81":"markdown","2761823f":"markdown","fcf96b5e":"markdown","f60ffe2e":"markdown","fc00f1b9":"markdown","ae374109":"markdown","768bf74a":"markdown","4d7b8581":"markdown","93fe4d5b":"markdown","9be86af8":"markdown"},"source":{"83fe230e":"import pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\npd.reset_option('^display.', silent=True)\n\n# Load data\nX_train = pd.read_csv(\"\/kaggle\/input\/donorsprediction\/Raw_Data_for_train_test.csv\")\nX_test = pd.read_csv(\"\/kaggle\/input\/donorsprediction\/Predict_donor.csv\")\n\n# Split target and predictors\ny_train = X_train['TARGET_B']\nnum_train = len(X_train)\nX_train.drop(['TARGET_B'], axis=1, inplace=True)\ndf = pd.concat([X_train, X_test], ignore_index=True)","1202bedd":"df.head()","61886876":"# Show the columns types\ndf.dtypes.value_counts()\ncategorical_columns = df.select_dtypes('object').columns\nprint(len(df.columns)-len(df.select_dtypes('object').columns),'numerical columns:')\nprint([i for i in list(df.columns) if i not in list(df.select_dtypes('object').columns)], '\\n')\nprint(len(df.select_dtypes('object').columns),'categorical columns:')\nprint(list(df.select_dtypes('object').columns))","7bdad929":"df.info()","e5a79098":"df.describe()","ba5dea54":"pd.set_option('mode.chained_assignment', None)\n\n# Delete unused variables CONTROL_NUMBER and TARGET_D\ndf = df.drop(['CONTROL_NUMBER', 'TARGET_D'], axis=1)\n\n# Fill missing values for age with median\nages = df.groupby(['DONOR_GENDER']).DONOR_AGE\nf = lambda x: x.fillna(x.median())\ndf.DONOR_AGE = ages.transform(f)\n\n# Fill missing values for income group with median\nincome = df.groupby(['DONOR_AGE', 'DONOR_GENDER']).INCOME_GROUP\nf = lambda x: x.fillna(x.median())\ndf.INCOME_GROUP = income.transform(f)\ndf.INCOME_GROUP = df.INCOME_GROUP.fillna(4)\n\n# Use zero for missing SES values\ndf.SES[df.SES == '?'] = 0\n\n# Use zero missing cluster\ndf.CLUSTER_CODE[df.CLUSTER_CODE == '.'] = 0\n\n# Use mean value S for missing URBANICITY\ndf.URBANICITY[df.URBANICITY == '?'] = 'S'\n\n# Fill missing values for wealth rating with median\nwealth = df.groupby(['DONOR_AGE', 'INCOME_GROUP']).WEALTH_RATING\nf = lambda x: x.fillna(x.median())\ndf.WEALTH_RATING = wealth.transform(f)\ndf.WEALTH_RATING = df.WEALTH_RATING.fillna(5)\n\n# Use mean value for missing MONTHS_SINCE_LAST_PROM_RESP\ndf.MONTHS_SINCE_LAST_PROM_RESP[df.MONTHS_SINCE_LAST_PROM_RESP.isnull()] = 19\n\n# Save indices of categorial features\ncategorical_features_indices = np.where(df.dtypes == 'object')[0]","6a67a01b":"# Split the df into train and test set\nX_train = df.iloc[:num_train,:]\nX_test = df.iloc[num_train:,:]\n\n# Make a training and validation set\nfrom sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, train_size=0.75, stratify=y_train, random_state=0)\n\n# Calculate pos weight\npos_weight = sum(y_train.values == 0)\/sum(y_train.values == 1)","0a1b78c5":"import catboost\nparams = {\"iterations\": 10000,\n          \"learning_rate\": 0.1,\n          \"scale_pos_weight\": pos_weight,\n          \"eval_metric\": 'AUC',\n          \"custom_loss\": 'Accuracy',\n          \"loss_function\": \"Logloss\",\n          \"boosting_type\": 'Ordered',\n          'od_type': 'Iter',\n          'od_wait': 30,\n          \"use_best_model\": True,\n          \"logging_level\": 'Verbose',\n          \"random_seed\": 0\n}\n\ntrain_pool = catboost.Pool(X_train, y_train, cat_features=categorical_features_indices)\nvalid_pool = catboost.Pool(X_valid, y_valid, cat_features=categorical_features_indices)\n\nmodel = catboost.CatBoostClassifier(**params)\nmodel.fit(train_pool, eval_set=valid_pool, plot=False)","9ad18008":"from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\nfrom sklearn.metrics import precision_score, recall_score\nfrom catboost.utils import get_roc_curve, select_threshold\n\ndef plot_roc_curve(fpr, tpr, label=None):\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'k--')\n\ny_pred = model.predict(X_valid)\nprint(f\"Confusion Matrix:\\n {confusion_matrix(y_valid, y_pred)}\\n\")\nprint(f\"Classification Report:\\n {classification_report(y_valid, y_pred)}\\n\")\n\ny_pred = model.predict(X_valid)\nprint(f\"Accuracy on validation set: {accuracy_score(y_valid, y_pred)}\")\nprint(f\"Precision on validation set: {precision_score(y_valid, y_pred)}\")\nprint(f\"Recall on validation set: {recall_score(y_valid, y_pred)}\")\n\nfpr_train, tpr_train, _ = get_roc_curve(model, train_pool)\nfpr_valid, tpr_valid, _ = get_roc_curve(model, valid_pool)\n\nplt.figure(figsize=(8,6))\nplot_roc_curve(fpr_train, tpr_train, \"Training ROC\")\nplot_roc_curve(fpr_valid, tpr_valid, \"Validation ROC\")\nplt.legend(loc=\"lower right\")\nplt.title(\"ROC plot\")\nplt.ylabel(\"TPR\")\nplt.xlabel(\"FPR\")\nplt.show()","a451b017":"model.get_feature_importance(train_pool, fstr_type=catboost.EFstrType.FeatureImportance, prettified=True)","df4368ea":"importances = model.get_feature_importance(train_pool, fstr_type=catboost.EFstrType.FeatureImportance)\nindices = np.argsort(importances)[::-1]\nplt.figure(figsize=(12,12))\nplt.title('Feature importance for CatBoost classifier')\nplt.barh(X_train.columns[indices][::-1], importances[indices][::-1])","b2447b97":"interactions = model.get_feature_importance(train_pool, fstr_type=catboost.EFstrType.Interaction)\nfeature_interaction = [[X_train.columns[interaction[0]], X_train.columns[interaction[1]], interaction[2]] for interaction in interactions]\nfeature_interaction_df = pd.DataFrame(feature_interaction, columns=['feature1', 'feature2', 'interaction_strength'])\nfeature_interaction_df.head(10)","281c3d35":"pd.Series(index=zip(feature_interaction_df['feature1'], feature_interaction_df['feature2']), data=feature_interaction_df['interaction_strength'].values, name='interaction_strength').head(10)[::-1].plot(kind='barh', figsize=(12,12))","d9313b48":"import shap\nshap_values = model.get_feature_importance(train_pool, fstr_type=catboost.EFstrType.ShapValues)\nshap.initjs()\nshap.summary_plot(shap_values[:, :-1], X_train, feature_names=X_train.columns.tolist())","0d0db699":"shap.summary_plot(shap_values[:, :-1], X_train, feature_names=X_train.columns.tolist(), plot_type=\"bar\")","9b60c84a":"y_test_preds = model.predict(X_test)\ny_test_probas = model.predict_proba(X_test)\n\nprint(f\"20 first predictions on test set: {y_test_preds[:20]}\")\nprint(f\"20 first probability dists: {y_test_probas[:20]}\")\nprint(f\"Number of predicated donors: {np.sum(y_test_preds == 1)}\")\nprint(f\"Number of predicated non-donors: {np.sum(y_test_preds == 0)}\")","089f1f81":"# Feature interactions","2761823f":"# Model analysis","fcf96b5e":"# Data loading","f60ffe2e":"# Feature importance","fc00f1b9":"# Feature encoding","ae374109":"# Train\/test split","768bf74a":"# Short EDA","4d7b8581":"# SHAP Values","93fe4d5b":"# Modelling","9be86af8":"# Model predictions"}}