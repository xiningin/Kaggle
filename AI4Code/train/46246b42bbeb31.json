{"cell_type":{"3cb4e97b":"code","2ca95d21":"code","e42e9259":"code","b4796a96":"code","1527821c":"code","7d7542f1":"code","4ebb81ee":"code","c1e6acba":"code","ce14a0b3":"code","e32e5264":"code","0b8dbfa9":"code","8348ef2f":"markdown","59a6934a":"markdown","0fb4d229":"markdown","ecfa9198":"markdown","51c8c0fa":"markdown","be5a95b2":"markdown","4c703406":"markdown","a880c0f1":"markdown","a3cad8b8":"markdown","8cd0d393":"markdown","361df91d":"markdown","31b27c23":"markdown","f0576326":"markdown"},"source":{"3cb4e97b":"# All imports\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport skimage.io\nfrom skimage import morphology\nimport time\nimport os\nfrom multiprocessing import Pool\nfrom tqdm.notebook import tqdm\nfrom operator import itemgetter \nfrom itertools import chain\nimport gc\n\nclass PandaProcess():\n    def __init__(self, pipeline=1, image_location=\"\", sensitivity=3500, lw_lvl=-1, hi_lvl=-2, size=None):\n        self.img_loc = image_location\n        self.sensitivity = sensitivity\n        self.lw_lvl = lw_lvl\n        self.lw_slide = None\n        self.lw_w_crop = None\n        self.lw_tiss_cnts = None\n        self.lw_tiss_slide = None\n        self.lw_tiss_only = None\n        self.prod = None\n\n        self.hi_lvl = hi_lvl\n        self.hi_slide = None\n\n        self.size = size\n\n        options = {\n            1:self.pipe1\n            }\n        \n        if pipeline in options.keys(): options[pipeline]()\n        \n    def read_slide(self, location, level):\n        return skimage.io.MultiImage(location)[level]\n\n    def bkgrnd_cut(self, in_slide, bkgrnd=255):\n        # Remove all rows of color\n        row_not_blank = [row.all() for row in ~np.all(in_slide == [bkgrnd]*3, axis=1)]\n        slide = in_slide[row_not_blank, :]\n        # Remove all columns of color\n        col_not_blank = [col.all() for col in ~np.all(slide == [bkgrnd]*3, axis=0)]\n        out_slide = slide[:, col_not_blank]\n        return out_slide\n\n    def otsu_filter(self, channel, gaussian_blur=True):\n        \"\"\"Otsu filter.\"\"\"\n        if gaussian_blur:\n            channel = cv2.GaussianBlur(channel, (5, 5), 0)\n        channel = channel.reshape((channel.shape[0], channel.shape[1]))\n\n        return cv2.threshold(channel, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n\n    def get_tissue_contours(self, in_slide, sensitivity):\n        # For timing\n        self.times_tiss_detc = {}\n        self.times_tiss_detc[\"start\"] = time.time()\n\n        # Convert from RGB to HSV color space\n        slide_hsv = cv2.cvtColor(in_slide, cv2.COLOR_BGR2HSV)\n        self.times_tiss_detc[\"Color Convert\"] = time.time()\n\n        # Compute optimal threshold values in each channel using Otsu algorithm\n        _, saturation, _ = np.split(slide_hsv, 3, axis=2)\n        mask = self.otsu_filter(saturation, gaussian_blur=True)\n        self.times_tiss_detc[\"Otsu\"] = time.time()\n\n        # Make mask boolean\n        mask = mask != 0\n\n        # Perform Morphology\n        mask = morphology.remove_small_holes(mask, area_threshold=sensitivity)\n        self.times_tiss_detc[\"Morph 1\"] = time.time()\n        mask = morphology.remove_small_objects(mask, min_size=sensitivity)\n        self.times_tiss_detc[\"Morph 2\"] = time.time()\n\n        # Get Contours\n        mask = mask.astype(np.uint8)\n        tissue_contours, _ = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n        self.times_tiss_detc[\"Contours\"] = time.time()\n        return tissue_contours\n\n    def draw_tissue(self, in_slide, tissue_contours, polygon_type, line_thickness=None):\n        for poly in tissue_contours:\n            if polygon_type == \"line\":\n                src_img = cv2.polylines(in_slide, [poly], True, [0, 255, 0], line_thickness)\n            elif polygon_type == \"area\":\n                if line_thickness is not None:\n                    warnings.warn(\n                        '\"line_thickness\" is only used if ' + '\"polygon_type\" is \"line\".'\n                    )\n\n                src_img = cv2.fillPoly(mask, [poly], tissue_color)\n            else:\n                raise ValueError('Accepted \"polygon_type\" values are \"line\" or \"area\".')\n\n        return src_img\n\n    def tissue_cutout(self, in_slide, tissue_contours):\n        # https:\/\/stackoverflow.com\/a\/28759496\n        # Get intermediate slide\n        base_slide_mask = np.zeros(in_slide.shape[:2])\n        crop_mask = np.zeros_like(\n            base_slide_mask\n        )  # Create mask where white is what we want, black otherwise\n        cv2.drawContours(\n            crop_mask, tissue_contours, -1, 255, -1\n        )  # Draw filled contour in mask\n        tissue_only = np.zeros_like(\n            in_slide\n        )  # Extract out the object and place into output image\n        tissue_only[crop_mask == 255] = in_slide[crop_mask == 255]\n        return tissue_only\n\n    def getSubImage(self, src_img, rect, scale):\n        rect = (\n            (rect[0][0] * scale, rect[0][1] * scale),\n            (rect[1][0] * scale, rect[1][1] * scale),\n            rect[2],\n        )\n        width = int(rect[1][0])\n        height = int(rect[1][1])\n        box = cv2.boxPoints(rect)\n\n        src_pts = box.astype(\"float32\")\n        dst_pts = np.array(\n            [[0, height - 1], [0, 0], [width - 1, 0], [width - 1, height - 1]],\n            dtype=\"float32\",\n        )\n        M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n        warped = cv2.warpPerspective(src_img, M, (width, height))\n        return warped\n\n    def min_rect_crop(self, in_slide, tissue_cnts, scale):\n        all_bounding_rect = cv2.minAreaRect(np.concatenate(tissue_cnts))\n        return self.getSubImage(in_slide, all_bounding_rect, scale)\n\n    def pipe1(self):\n        # For timing\n        self.times_pipe = {}\n        self.times_pipe[\"Start\"] = time.time()\n        self.lw_slide = self.read_slide(self.img_loc, self.lw_lvl)\n        self.times_pipe[\"Read\"] = time.time()\n        self.lw_tiss_cnts = self.get_tissue_contours(self.lw_slide, self.sensitivity)\n        if len(self.lw_tiss_cnts) == 0: return\n        self.times_pipe[\"Get Countours\"] = time.time()\n        self.lw_tiss_cut = self.tissue_cutout(self.lw_slide, self.lw_tiss_cnts)\n        self.times_pipe[\"Cut Tissue\"] = time.time()\n        self.lw_rect_crop = self.min_rect_crop(self.lw_tiss_cut, self.lw_tiss_cnts, 1)\n        self.times_pipe[\"Contour Rect\"] = time.time()\n        self.lw_w_crop = self.bkgrnd_cut(self.lw_rect_crop, bkgrnd=0)\n        if self.lw_w_crop.size==0: return\n        self.times_pipe[\"Final: Cut Background\"] = time.time()\n        self.prod = self.lw_w_crop\n        return\n\n\nclass PandaDataStore(PandaProcess):\n    def __init__(self, pct_store=.001, size=[512, 512], run=False):\n        self.save_dir = \"\/kaggle\/train_images\/\"\n        os.makedirs(self.save_dir, exist_ok=True)\n        self.slide_dir = \"..\/input\/prostate-cancer-grade-assessment\/train_images\/\"\n        self.mask_dir = \"..\/input\/prostate-cancer-grade-assessment\/train_label_masks\/\"\n        self.size = size\n        self.train_data_df = pd.read_csv(\"..\/input\/prostate-cancer-grade-assessment\/train.csv\")\n        N_to_process = int(len(self.train_data_df) * pct_store)\n        sample_df = self.categorical_sample(self.train_data_df, \"isup_grade\", N_to_process)\n        self.image_ids = list(sample_df.image_id)\n        if run: self.run_store()\n\n    def run_store(self):\n        with Pool(processes=4) as pool:\n            prod_bool = list(\n                pool.imap(self.img_prod_save, self.image_ids), total=len(self.image_ids)\n            )\n        return prod_bool\n\n    def categorical_sample(self, df, cat_col, N):\n        group = df.groupby(cat_col, group_keys=False)\n        sample_df = group.apply(lambda g: g.sample(int(N * len(g) \/ len(df))))\n        return sample_df\n\n    def img_prod_save(self, image_id):\n        load_path = self.slide_dir + image_id + '.tiff'\n        save_path = self.save_dir + image_id + '.png'\n        pprocess = PandaProcess(start_type=\"pipe1\", image_location=load_path, size=self.size)\n        if pprocess.prod is None: return 0\n        cv2.imwrite(save_path, pprocess.prod)\n        return 1\n    \nclass PandaMetadata(PandaDataStore):\n    def __init__(self, pct_review=.001, mode=\"load\", meta_slide_df=\"\", meta_cnts_df=\"\"):\n        PandaDataStore.__init__(self, pct_store=pct_review,size=None, run=False)\n        if mode==\"run\" or mode==\"save\":\n            results = self.run_meta()\n            meta_slide, meta_cnts = zip(*results)\n            self.meta_slide_df = pd.DataFrame(meta_slide)\n            self.meta_cnts_df = pd.DataFrame(list(chain.from_iterable(meta_cnts)))\n            self.meta_slide_df = pd.merge(self.train_data_df,self.meta_slide_df, on=\"image_id\", how=\"right\")\n            self.meta_cnts_df = pd.merge(self.train_data_df,self.meta_cnts_df, on=\"image_id\", how=\"right\")\n            \n            if mode == \"save\":\n                self.meta_slide_df.to_csv(\"PANDA_Tissue_Metadata_Slides.csv\", index=False)\n                self.meta_cnts_df.to_csv(\"PANDA_Tissue_Metadata_Contours.csv\", index=False)\n                \n        elif mode==\"load\": \n            self.df = pd.read_csv(df_loc)\n            self.meta_slide_df = pd.read_csv(meta_slide_df)\n            self.meta_cnts_df = pd.read_csv(meta_cnts_df)\n            \n        else:\n            print(\"Invalid Option\")\n            self.df = None\n        \n    def get_meta(self, image_id):\n        \n        load_path = self.slide_dir + image_id + '.tiff'\n        pprocess = PandaProcess(pipeline=1, image_location=load_path, size=self.size, sensitivity=3000)\n        \n        if pprocess.prod is None: return {}, []\n        \n        #Base\/Production image metadata\n        meta_image = {\n                \"image_id\": image_id,\n                \"base_shape\": pprocess.lw_slide.shape,\n                \"base_area\": np.prod(pprocess.lw_slide.shape[:-1]),\n                \"base_horz\": pprocess.lw_slide.shape[1] > pprocess.lw_slide.shape[0],\n                \"base_ratio\": pprocess.lw_slide.shape[1] \/ pprocess.lw_slide.shape[0],\n                \"prod_shape\": pprocess.prod.shape,\n                \"prod_area\": np.prod(pprocess.prod.shape[:-1]),\n                \"prod_horz\": pprocess.prod.shape[1] > pprocess.prod.shape[0],\n                \"prod_ratio\": pprocess.prod.shape[1] \/ pprocess.prod.shape[0],\n                \"prod_rect\" : cv2.minAreaRect(np.concatenate(pprocess.lw_tiss_cnts)),\n                \"cnt_count\":len(pprocess.lw_tiss_cnts)\n               }\n        \n        #Timing Metadata\n        meta_timimg = {\n                \"pipeline_times\": pprocess.times_pipe,\n                \"tissue_detect_times\": pprocess.times_tiss_detc\n                }\n        \n        #Contours Metadata (one row for each contour)\n        meta_cnts_list = []\n        for i,cnt in enumerate(pprocess.lw_tiss_cnts):\n            rect = cv2.minAreaRect(cnt)\n            cnt_area = cv2.contourArea(cnt)\n            cnt_rect_area = np.prod(rect[1])\n            meta_cnts = {\n                    \"image_id\":image_id,\n                    \"cnt_id\": i,\n                    \"cnt_area\":cnt_area,\n                    \"cnt_rects\":rect,\n                    \"cnt_react_shape\":rect[1],\n                    \"cnt_rect_area\":np.prod(rect[1]),\n                    \"cnt_horz\":rect[1][1] > rect[1][0],\n                    \"cnt_ratio\":rect[1][1] \/ rect[1][0],\n                    \"cnt_tissue_pct\": cnt_area \/ cnt_rect_area\n                    }\n            meta_cnts_list.append(meta_cnts)\n            \n        cnt_areas = list(map(itemgetter('cnt_area'), meta_cnts_list))\n        meta_image[\"cnt_area_total\"] = sum(cnt_areas)\n        \n        cnt_rect_areas = list(map(itemgetter('cnt_rect_area'), meta_cnts_list))\n        meta_image[\"cnt_rect_area_total\"] = sum(cnt_rect_areas)\n        \n        meta_image[\"pct_prod_base\"] = meta_image[\"prod_area\"] \/ meta_image[\"base_area\"]\n        meta_image[\"pct_tissue_base\"] = meta_image[\"cnt_area_total\"] \/ meta_image[\"base_area\"]\n        meta_image[\"pct_tissue_prod\"] = meta_image[\"cnt_area_total\"] \/ meta_image[\"prod_area\"]\n        meta_image[\"pct_tissue_rect\"] = meta_image[\"cnt_area_total\"] \/ meta_image[\"cnt_rect_area_total\"]\n        meta_image[\"pct_tissue_base_prod\"] = meta_image[\"pct_tissue_base\"] \/ meta_image[\"pct_tissue_prod\"]\n        meta_image[\"pct_tissue_prod_rect\"] = meta_image[\"pct_tissue_prod\"] \/ meta_image[\"pct_tissue_rect\"]\n        \n        #Clean up\n        del pprocess\n        gc.collect()\n        \n        return [meta_image, meta_cnts_list]\n    \n    def run_meta(self):\n        with Pool(processes=4) as pool:\n            results = list(pool.imap(self.get_meta, self.image_ids))\n        return results \n    \n","2ca95d21":"data_store = PandaMetadata(.001, mode=\"save\")","e42e9259":"import pandas as pd\nimport plotly.express as px\nimport ast\n\ndef categorical_sample(df, cat_col, pct):\n    N = int(len(df) * pct)\n    group = df.groupby(cat_col, group_keys=False)\n    sample_df = group.apply(lambda g: g.sample(int(N * len(g) \/ len(df))))\n    return sample_df\n\n#Read in dataset from saved data\ndataset_loc = \"\/kaggle\/input\/panda-tissue-metadata\/PANDA_Tissue_Metadata_Slides.csv\"\ntd_meta_df = pd.read_csv(dataset_loc)\n\n#Can also get directly from the saved run above\n#test_loc = \"\/kaggle\/working\/PANDA_Tissue_Metadata_Slides.csv\"\n#td_meta_df = pd.read_csv(test_loc)\n\n#Drop any columns without base shapes\ntd_meta_df = td_meta_df.dropna(subset=[\"base_shape\"])\n\n#Set ISUP to int\ntd_meta_df[\"isup_grade\"] = td_meta_df[\"isup_grade\"].astype(int)\n\n#Sample based on isup for memory saving reasons\ntd_meta_df = categorical_sample(td_meta_df, \"isup_grade\", .50)\n\n#Take all columns that are suppose to be lists and transform\ntouple_cols = [\"base_shape\", \"prod_shape\"]\n\ndef str_to_list(col):\n    return col.str.strip(\"[]\").str.split(\",\")\n\ndef tpl_to_list(col):\n    return col.str.strip(\"()\").str.split(\",\")\n\n#Convert touple cols to touple types\ntd_meta_df[touple_cols] = td_meta_df[touple_cols].apply(tpl_to_list, axis=1)\ntd_meta_df[\"prod_rect\"] = td_meta_df[\"prod_rect\"].apply(ast.literal_eval)\n\npd.set_option('display.max_columns', len(td_meta_df.columns))\ntd_meta_df.head(1)","b4796a96":"#Read in dataset\ndataset_loc_cnts = \"\/kaggle\/input\/panda-tissue-metadata\/PANDA_Tissue_Metadata_Contours.csv\"\ncnts_meta_df = pd.read_csv(dataset_loc_cnts)\n\n#Can also get directly from the saved run above\n#test_loc_cnts = \"\/kaggle\/working\/PANDA_Tissue_Metadata_Contours.csv\"\n#cnts_meta_df = pd.read_csv(test_loc_cnts)\n\n#Sample for data sake\ncnts_meta_df = categorical_sample(cnts_meta_df, \"isup_grade\", .50)\n\n#Take all columns that are suppose to be lists and transform\ntouple_cols_cnts = [\"cnt_react_shape\"]\n\n#Convert touple cols to touple types\ncnts_meta_df[touple_cols_cnts] = cnts_meta_df[touple_cols_cnts].apply(tpl_to_list, axis=1)\ncnts_meta_df[\"cnt_rects\"] = cnts_meta_df[\"cnt_rects\"].apply(ast.literal_eval)\ncnts_meta_df.head()","1527821c":"slide_dir = \"..\/input\/prostate-cancer-grade-assessment\/train_images\/\"\ndef show_cnts(ids):\n    for image_id in ids:\n        #Get CMBRs\n        tissue_CMBRs = cnts_meta_df[cnts_meta_df[\"image_id\"] == image_id].cnt_rects\n        slide_CMBR = list(td_meta_df[td_meta_df[\"image_id\"] == image_id].prod_rect)\n        #Get base slide\n        slide_loc = f\"{slide_dir}{image_id}.tiff\"\n        base_slide = skimage.io.MultiImage(slide_loc)[-1]\n\n        if len(slide_CMBR) > 0:\n            box = cv2.boxPoints(slide_CMBR[0])\n            box = np.int0(box)\n            cv2.drawContours(base_slide,[box],0,(255,255,0),10)\n\n        for rect in tissue_CMBRs:\n            box = cv2.boxPoints(rect)\n            box = np.int0(box)\n            cv2.drawContours(base_slide,[box],0,(0,255,255),5)\n\n        print(f\"Slide: {image_id} | Tissue Contours: {len(tissue_CMBRs)}\")\n        plt.imshow(base_slide)\n        plt.show()\n    return \n\n#train_data_df = pd.read_csv(\"..\/input\/prostate-cancer-grade-assessment\/train.csv\")\nsample_ids = list(td_meta_df.sample(5).image_id)\nshow_cnts(sample_ids)","7d7542f1":"td_meta_df[\"base_height\"] = td_meta_df.base_shape.map(lambda x: int(x[0]))\ntd_meta_df[\"base_width\"] = td_meta_df.base_shape.map(lambda x: int(x[1]))\n\n\nfig = px.scatter(td_meta_df, x=\"base_width\", y=\"base_height\", color=\"isup_grade\",\n                 hover_data=[\"image_id\", 'gleason_score'], trendline=\"ols\")\n\nfig.add_shape(\n        # Line Diagonal\n            type=\"line\",\n            x0=0,\n            y0=0,\n            x1=td_meta_df[\"base_width\"].max(),\n            y1=td_meta_df[\"base_height\"].max(),\n            line=dict(\n                color=\"MediumPurple\",\n                width=4,\n                dash=\"dot\",\n            )\n)\n\nfig.show()","4ebb81ee":"td_meta_df[\"prod_height\"] = td_meta_df.prod_shape.map(lambda x: int(x[0]))\ntd_meta_df[\"prod_width\"] = td_meta_df.prod_shape.map(lambda x: int(x[1]))\n\nfig = px.scatter(td_meta_df, x=\"prod_width\", y=\"prod_height\", color=\"isup_grade\",\n                 hover_data=[\"image_id\", 'gleason_score'], trendline=\"ols\")\n\nfig.add_shape(\n        # Line Diagonal\n            type=\"line\",\n            x0=0,\n            y0=0,\n            x1=td_meta_df[\"prod_width\"].max(),\n            y1=td_meta_df[\"prod_height\"].max(),\n            line=dict(\n                color=\"MediumPurple\",\n                width=4,\n                dash=\"dot\",\n            )\n)\n\nfig.show()","c1e6acba":"cnts_meta_df[\"cnt_height\"] = cnts_meta_df.cnt_react_shape.map(lambda x: float(x[0]))\ncnts_meta_df[\"cnt_width\"] = cnts_meta_df.cnt_react_shape.map(lambda x: float(x[1]))\n\nfig = px.scatter(cnts_meta_df, x=\"cnt_width\", y=\"cnt_height\", color=\"isup_grade\",\n                 hover_data=[\"image_id\", 'gleason_score'], trendline=\"ols\")\n\nfig.add_shape(\n        # Line Diagonal\n            type=\"line\",\n            x0=0,\n            y0=0,\n            x1=cnts_meta_df[\"cnt_width\"].max(),\n            y1=cnts_meta_df[\"cnt_height\"].max(),\n            line=dict(\n                color=\"MediumPurple\",\n                width=4,\n                dash=\"dot\",\n            )\n)\n\nfig.show()","ce14a0b3":"import plotly.express as px\nimport plotly.graph_objects as go\n\ndef get_px_to_sq(shape):\n    #Ensure that values are in float\n    shape = [float(x) for x in shape]\n    #Only keep the top two values (third would be channel values)\n    shape = shape if len(shape) < 2 else shape[:2]\n    #Sort values for arithmatic\n    shape.sort()\n    #Get base area\n    base_area = np.prod(shape)\n    #Find required area to amke sqaure\n    px_req = (shape[1] - shape[0]) * shape[1]\n    #Get percentage or original\n    px_to_sq = px_req \/ base_area\n    return px_to_sq\n\ncnts_meta_df[\"cnts_px_to_sq\"] = cnts_meta_df.cnt_react_shape.apply(get_px_to_sq)\ntd_meta_df[\"base_px_to_sq\"] = td_meta_df.base_shape.apply(get_px_to_sq)\ntd_meta_df[\"prod_px_to_sq\"] = td_meta_df.prod_shape.apply(get_px_to_sq)\ncnt_px_to_sq = cnts_meta_df[[\"image_id\", \"cnts_px_to_sq\"]]\nslide_px_to_sq = td_meta_df[[\"image_id\", \"base_px_to_sq\", \"prod_px_to_sq\"]]\nto_graph = slide_px_to_sq.merge(cnt_px_to_sq, on=\"image_id\", how=\"outer\").melt(\"image_id\")\n\n# create the bins\ngraph_top = 2000\n\nfig = px.histogram(to_graph, x=\"value\", color=\"variable\", marginal=\"rug\", # can be `box`, `violin`\n                         hover_data=[\"image_id\"])\n\n\n\nfig.add_trace(go.Scatter(\n    x=[td_meta_df[\"base_px_to_sq\"].mean()]*20,\n    y=np.linspace(0,graph_top,20),\n    mode=\"lines\",\n    name=\"base_px_to_sq mean\",\n    hoverinfo = \"x\",\n    textposition=\"bottom center\",\n    line=dict(\n                color=px.colors.qualitative.Plotly[0],\n                width=4,\n                dash=\"dot\",\n            )\n))\n\nfig.add_trace(go.Scatter(\n    x=[td_meta_df[\"prod_px_to_sq\"].mean()]*20,\n    y=np.linspace(0,graph_top,20),\n    mode=\"lines\",\n    name=\"prod_px_to_sq mean\",\n    hoverinfo = \"x\",\n    textposition=\"bottom center\",\n    line=dict(\n                color=px.colors.qualitative.Plotly[1],\n                width=4,\n                dash=\"dot\",\n            )\n))\n\n   \nfig.add_trace(go.Scatter(\n    x=[cnts_meta_df[\"cnts_px_to_sq\"].mean()]*20,\n    y=np.linspace(0,graph_top,20),\n    mode=\"lines\",\n    name=\"cnts_px_to_sq mean\",\n    hoverinfo = \"x\",\n    textposition=\"bottom center\",\n    line=dict(\n                color=px.colors.qualitative.Plotly[2],\n                width=4,\n                dash=\"dot\",\n            )\n))\n    \n\nfig.show()","e32e5264":"cnt_tiss_pct = cnts_meta_df[[\"image_id\", \"cnt_tissue_pct\"]]\nslide_tiss_pct = td_meta_df[[\"image_id\", \"pct_tissue_base\", \"pct_tissue_prod\"]]\nto_graph = slide_tiss_pct.merge(cnt_tiss_pct, on=\"image_id\", how=\"outer\").melt(\"image_id\")\n\ngraph_top = 1500\n\nfig = px.histogram(to_graph, x=\"value\", color=\"variable\", marginal=\"rug\", # can be `box`, `violin`\n                         hover_data=[\"image_id\"])\n\n\n\nfig.add_trace(go.Scatter(\n    x=[td_meta_df[\"pct_tissue_base\"].mean()]*20,\n    y=np.linspace(0,graph_top,20),\n    mode=\"lines\",\n    name=\"pct_tissue_base mean\",\n    hoverinfo = \"x\",\n    textposition=\"bottom center\",\n    line=dict(\n                color=px.colors.qualitative.Plotly[0],\n                width=4,\n                dash=\"dot\",\n            )\n))\n\nfig.add_trace(go.Scatter(\n    x=[td_meta_df[\"pct_tissue_prod\"].mean()]*20,\n    y=np.linspace(0,graph_top,20),\n    mode=\"lines\",\n    name=\"pct_tissue_prod mean\",\n    hoverinfo = \"x\",\n    textposition=\"bottom center\",\n    line=dict(\n                color=px.colors.qualitative.Plotly[1],\n                width=4,\n                dash=\"dot\",\n            )\n))\n\n   \nfig.add_trace(go.Scatter(\n    x=[cnts_meta_df[\"cnt_tissue_pct\"].mean()]*20,\n    y=np.linspace(0,graph_top,20),\n    mode=\"lines\",\n    name=\"cnt_tissue_pct mean\",\n    hoverinfo = \"x\",\n    textposition=\"bottom center\",\n    line=dict(\n                color=px.colors.qualitative.Plotly[2],\n                width=4,\n                dash=\"dot\",\n            )\n))\n    \n\nfig.show()","0b8dbfa9":"to_graph = td_meta_df.cnt_count.value_counts().reset_index()\nto_graph.columns = [\"Number of Countors\", \"Count\"]\nfig = px.pie(to_graph, values='Count', names=\"Number of Countors\")\nfig.show()","8348ef2f":"# Dataset: PANDA Tissue Detection -  Contours Metadata\n\n## Contours\n\n`cnt_cnt` : Number of unqiue tissue contours detected on the slide\n\n`cnt_array` : List of OpenCV contours found in the slide\n\n`cnt_areas` : List of the areas for the various contours detected\n\n`cnt_rects` : OpenCV Minimum Rectangle bounding box object for each of the tissue contours\n\n`cnt_rect_shapes` : Shapes (H,W) of the OpenCV Contour Min Bounding Rect (CMBR) from above\n\n`cnt_rect_areas` : Areas of each of the detected OpenCV CMRs\n\n`cnt_horz` : True if CMBR is horizontal and False if vertical\n\n`cnt_ratios`: Ratio of width \/ height for each of the CMR\n\n`cnt_tissue_pct` : Percetnage of CMBR that is tissue","59a6934a":"## Production Slide Deminsions\nThis trend is further exacerbated in the production images. Since the pipeline, further detailed discussed in my [scaling notebook](https:\/\/www.kaggle.com\/dannellyz\/tissue-detect-scaling-bounding-boxes-4xfaster), cuts all empty space from the image this is not surprising, but does then lead to a larger potential distortion problem. ","0fb4d229":"### Running on the full corpus takes ~45 min so I have run it and saved it to a dataset here:\n\n[PANDA Tissue Metadata](https:\/\/www.kaggle.com\/dannellyz\/panda-tissue-metadata\/)","ecfa9198":"# Contour Minimum Bounding Rectangles(CMBRs) Aspect Ratios\nLooking at the CMBRs the issue of aspect ratio becomes most clear. At this lowest level a massive trend towards highly rectangular objects can be seen. ","51c8c0fa":"![tissue_logo.001.jpeg](attachment:tissue_logo.001.jpeg)\n\nTissue Detection is a key aspect to research in the domain of computer vision applied to cancer classification. My main focus in this competition so far has been exploring previous work done in this domain and furthering its application towards this dataset. Notebooks in this collection include the following.\n* [Base Notebook](https:\/\/www.kaggle.com\/dannellyz\/panda-tissue-detection-size-optimization-70) : Tissue Detection Intro and First Application\n* [Base Dataset Generation](https:\/\/www.kaggle.com\/dannellyz\/tissue-detect-td-conv-png-512x512): Notebook to export images to zip file\n* [Scaling Bounding Boxes](https:\/\/www.kaggle.com\/dannellyz\/tissue-detect-scaling-bounding-boxes-4xfaster): 4x speed increase to base notebook\n* [Tissue Dection Metadata Analysis **(Currently Here)**](https:\/\/www.kaggle.com\/dannellyz\/tissue-detection-bounding-box-metadata-eda-viz\/): Exploring features from bounding boxes discovery on the slides","be5a95b2":"# Potential Fixes to This Problem\nSince making the images square will require some sort of manipulation, the rectangularity of smaller images is not as large of a problem as larger images. I have come up with a metric, Pixels to Square, that measures minimum required padding for a given rectangle to make it square. I have made this into a percent of the starting image in order to account for size scaling.\n\n## Pure Square Padding\nThis would simply be taking the shorted side of any given image and padding it with blank space. As seen by the below, that would be massive damaging to the slides.\n\n### Pixels to Sqaure (px_to_sq) Ratio Calculation for Simple Padding\n\n```python\ndef get_px_to_sq(shape):\n    #Ensure that values are in float\n    shape = [float(x) for x in shape]\n    #Only keep the top two values (third would be channel values)\n    shape = shape if len(shape) < 2 else shape[:2]\n    #Sort values for arithmatic\n    shape.sort()\n    #Get base area\n    base_area = np.prod(shape)\n    #Find required area to amke sqaure\n    px_req = (shape[1] - shape[0]) * shape[1]\n    #Get percentage or original\n    px_to_sq = px_req \/ base_area\n    return px_to_sq\n```\n\n\n### Results:\n* In order to take the production images and make them square with padding it will, on average, 4x the size of the images. This increse of course will be entirely filled with blank space\n* The individual CMBRs have a lower ratio than the production images indicating that looking into leveraging them could be useful\n* Tiling could be a great resource to help solve this issue as well","4c703406":"### I plan to do more invesigations as I continue my work and will add it here!","a880c0f1":"# Investigating Tissue Contours\n\n## Number Present\n\n#### - On about 60% of the slides there is more than one tissue sample present\n","a3cad8b8":"# Contour Visualizations\n\nThis section offers a sample of the vizualizations that the contours provide for each slide.\n\n### Bounding Rectangle for All Contours: <span style=\"color:yellow\">\u2500\u2500<\/span>\n### Individual CMBRs: <span style=\"color:blue\">\u2500\u2500<\/span>\n","8cd0d393":"# Tissue Detection (TD): Bounding Box Metadata Analysis\n\nAs I have been moving ahead with tissue detection, I wanted to take a short pause and complete a deep dive into the metadata generated by the process. I [have made a dataset](https:\/\/www.kaggle.com\/dannellyz\/panda-tissue-metadata\/) that contains all features that result in the creation of bounding boxes and cutting the images. It can be found here: \n\n# Key Findings\nSince this notebook is most exploratory I wanted to one highlight my key findings up front:\n\n#### \u25b3 Tissue samples \/ Production Slides have a very high rectangularity -> Some sort of sampling is a must\n#### \u25b3 Even in the minimum bounding rectagles there is a lot of white space -> Sampling from these is most efficient\n#### \u25b3 Orientation and size of the tissues varies widley from slide to slide -> Standardizing a sampling is required for consistency \n\nThis notebook simply documents my research into these findings. A forth coming notebook details how this fits into my revised pipeline.\n\n# \u2193 Metadata Generator \u2193\n\nBelow is a hidden class that sets up the pipeline I used to generate the contours and metadata. ","361df91d":"# Dataset: PANDA Tissue Detection -  Slide Metadata\nThe metadata set takes the `train.csv` document provided in the competition data and augments it with many other features that describe the features on the slide in terms of tissue deteciton. Usage of various features is shown below. It also has summary information on the Open CV Contour Minimum Bounding Rectangles on a given slide with more in depth information provided for each contour in the further metadata slide.\n\n## Train CSV\nThese features are merged from the [provided data](https:\/\/www.kaggle.com\/c\/prostate-cancer-grade-assessment\/data).\n\n`image_id` | `data_provider` | `isup_grade` | `gleason_score`\n\n## Base Image\n\n`base_shape` : Shape (H,W) of the base slide image\n\n`base_area` : Total area of the base slide\n\n`base_horz` : True if base slides is horizontal and False if vertical\n\n`base_ratio` : Ratio of width \/ height for each of the base slides\n\n## Processed (Prod) Image\n\n`prod_shape` : Shape (H,W) of the processed slide image\n\n`prod_area` : total area of the processed slide area\n\n`prod_horz` : True if prod image is horizontal and False if vertical\n\n`prod_ratio` : Ratio of width \/ height for each of the prod images\n\n## Timings\n\n`pipeline_times` : Timestamps in the pipeline process\n\n`tissue_detect_times` : Timstamps in the tissue detection process\n\n## Percentages\n\n`pct_prod_base` : Percentage of the prod image vs base image (based on area)\n\n`pct_tissue_base` : Percentage of the tissue contours on base slide (based on area)\n\n`pct_tissue_prod` : Percentage of the tissue contours on prod slide (based on area)\n\n`pct_tissue_rect` : Percentage of tissue contours compared to CMBRs\t\n\n`pct_tissue_base_prod` : Percentage of tissue on base slide vs prod image\t\n\n`pct_tissue_prod_rect` : Percentage of tissue on base slide vs CMBRs\t \n\n## Contours\n\n`cnt_area_total` : Total sum of contour areas\n\n`cnt_rect_area_total` : Total sum of CMBRs","31b27c23":"# Aspect Ratio\n\nIn conducting my previous analysis I noticed that the tissue slides had a high aspect ratios. As I performed my tissue detection and dropping this feature was only increased. Since many RNN models require same sized, square images this required reshaping and in doing so deforming morphologic features ([@Nanashi](https:\/\/www.kaggle.com\/jesucristo) thanks for the notes on this!). Therefore, the fist analysis I wanted to conduct was investigating this property of the data and the lightest touch to fix it.\n\n## Considerations\n* Least amount of cutting\/distortion is possible. Therefore, fewer manipulations will be investigated first\n* Speed must be a foremost consideration in order to fit into the pre-processing pipeline\n* If manipulations can be learned on smaller images then sclaed to larger ones it will enable large processing boosts.\n\n## Base Slide Deminsions\nThe <span style=\"color:purple\">\u25a0\u25a0\u25a0\u25a0\u25a0<\/span> line on the plot bvelow shoes a 1:1 aspect ratio. This would be the goal for any images that are ready to head into a training model. The <span style=\"color:red\">\u2500\u2500<\/span> shows the trend line for the given data. As seen it is quite a bit skewed. ","f0576326":"# Investigating Tissue Percentages\n\nAnother feature included with the metadata is the Tissue Percentages for each of the given slides as well as the CMBRs. \n\n## Results\n\n* Only 9% of base slides contain tissue informaiton\n* The production slides have 3x the tissue of the base slides\n* This is still only about 60-70% as efficient as the CMBRs\n"}}