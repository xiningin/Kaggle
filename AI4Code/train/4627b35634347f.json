{"cell_type":{"012d67a9":"code","6232ef2f":"code","71746d66":"code","43092916":"code","bfc1fe1b":"code","209fd198":"code","378f175b":"code","dfe72a72":"code","49c93419":"code","45d05191":"code","14eda1df":"code","be147be5":"code","3eb9a821":"markdown","8669170a":"markdown","b3f47895":"markdown","99fed415":"markdown","5482ce58":"markdown","01e6eaaa":"markdown","120ca5f1":"markdown","3befb41e":"markdown","4fa388ef":"markdown","e84218c9":"markdown","379bdcc2":"markdown"},"source":{"012d67a9":"import numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms, datasets","6232ef2f":"if torch.cuda.is_available():\n    DEVICE = torch.device('cuda')\nelse:\n    DEVICE = torch.device('cpu')\nprint('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)","71746d66":"BATCH_SIZE = 32\nEPOCHS = 10","43092916":"train_dataset = datasets.CIFAR10(root = \"..\/data\/CIFAR_10\",\n                                  train = True,\n                                  download = True,\n                                  transform = transforms.Compose([\n                                      transforms.RandomHorizontalFlip(),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]))\n                                  \n\ntest_dataset = datasets.CIFAR10(root = \"..\/data\/CIFAR_10\",\n                                train = False,\n                                transform = transforms.Compose([\n                                      transforms.RandomHorizontalFlip(),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]))\n\ntrain_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n                                            batch_size = BATCH_SIZE,\n                                            shuffle = True)\n\ntest_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n                                          batch_size = BATCH_SIZE,\n                                          shuffle = False)","bfc1fe1b":"for (X_train, y_train) in train_loader:\n    print('X_train:', X_train.size(), 'type:', X_train.type())\n    print('y_train:', y_train.size(), 'type:', y_train.type())\n    break","209fd198":"pltsize = 1\nplt.figure(figsize=(10 * pltsize, pltsize))\n\nfor i in range(10):\n    plt.subplot(1, 10, i + 1)\n    plt.axis('off')\n    plt.imshow(np.transpose(X_train[i], (1, 2, 0)))\n    plt.title('Class: ' + str(y_train[i].item()))","378f175b":"import torchvision.models as models\nmodel=models.resnet34(pretrained=False)\nnum_ftrs=model.fc.in_features\nmodel.fc=nn.Linear(num_ftrs,10)\nmodel=model.to(DEVICE)\n\n\n\n\n\n# class BasicBlock(nn.Module):\n#     def __init__(self, in_planes, planes, stride = 1):\n#         super(BasicBlock, self).__init__()\n#         self.conv1 = nn.Conv2d(in_planes, planes, kernel_size = 3, stride = stride, padding = 1, bias = False)\n#         self.bn1 = nn.BatchNorm2d(planes)\n#         self.conv2 = nn.Conv2d(planes, planes, kernel_size = 3, stride = 1, padding = 1, bias = False)\n#         self.bn2 = nn.BatchNorm2d(planes)\n        \n#         self.shortcut = nn.Sequential()\n#         if stride != 1 or in_planes != planes:\n#             self.shortcut = nn.Sequential(\n#                 nn.Conv2d(in_planes, planes, kernel_size = 1, stride = stride, bias = False),\n#                 nn.BatchNorm2d(planes))\n    \n#     def forward(self, x):\n#         out = F.relu(self.bn1(self.conv1(x)))\n#         out = self.bn2(self.conv2(out))\n#         out += self.shortcut(x)\n#         out = F.relu(out)\n#         return out\n    \n# class ResNet(nn.Module):\n#     def __init__(self, num_classes = 10):\n#         super(ResNet, self).__init__()\n#         self.in_planes = 16\n        \n#         self.conv1 = nn.Conv2d(3, 16, kernel_size = 3, stride = 1, padding = 1, bias = False)\n#         self.bn1 = nn.BatchNorm2d(16)\n#         self.layer1 = self._make_layer(16, 2, stride = 1)\n#         self.layer2 = self._make_layer(32, 2, stride = 2)\n#         self.layer3 = self._make_layer(64, 2, stride = 2)\n#         self.linear = nn.Linear(64, num_classes)\n        \n#     def _make_layer(self, planes, num_blocks, stride):\n#         strides = [stride] + [1] * (num_blocks  - 1)\n#         layers = []\n#         for stride in strides:\n#             layers.append(BasicBlock(self.in_planes, planes, stride))\n#             self.in_planes = planes\n#         return nn.Sequential(*layers)\n    \n#     def forward(self, x):\n#         out = F.relu(self.bn1(self.conv1(x)))\n#         out = self.layer1(out)\n#         out = self.layer2(out)\n#         out = self.layer3(out)\n#         out = F.avg_pool2d(out, 8)\n#         out = out.view(out.size(0), -1)\n#         out = self.linear(out)\n#         return out","dfe72a72":"#model = ResNet().to(DEVICE)\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\ncriterion = nn.CrossEntropyLoss()\n\nprint(model)","49c93419":"def train(model, train_loader, optimizer, log_interval):\n    model.train()\n    for batch_idx, (image, label) in enumerate(train_loader):\n        image = image.to(DEVICE)\n        label = label.to(DEVICE)\n        optimizer.zero_grad()\n        output = model(image)\n        loss = criterion(output, label)\n        loss.backward()\n        optimizer.step()\n\n        if batch_idx % log_interval == 0:\n            print(\"Train Epoch: {} [{}\/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n                epoch, batch_idx * len(image), \n                len(train_loader.dataset), 100. * batch_idx \/ len(train_loader), \n                loss.item()))","45d05191":"def evaluate(model, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n\n    with torch.no_grad():\n        for image, label in test_loader:\n            image = image.to(DEVICE)\n            label = label.to(DEVICE)\n            output = model(image)\n            test_loss += criterion(output, label).item()\n            prediction = output.max(1, keepdim = True)[1]\n            correct += prediction.eq(label.view_as(prediction)).sum().item()\n    \n    test_loss \/= (len(test_loader.dataset) \/ BATCH_SIZE)\n    test_accuracy = 100. * correct \/ len(test_loader.dataset)\n    return test_loss, test_accuracy","14eda1df":"for epoch in range(1, EPOCHS + 1):\n    train(model, train_loader, optimizer, log_interval = 200)\n    test_loss, test_accuracy = evaluate(model, test_loader)\n    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n        epoch, test_loss, test_accuracy))","be147be5":"model = models.resnet34(pretrained = True)\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 10)\nmodel = model.cuda()\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n\nfor epoch in range(1, EPOCHS + 1):\n    train(model, train_loader, optimizer, log_interval = 200)\n    test_loss, test_accuracy = evaluate(model, test_loader)\n    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n        epoch, test_loss, test_accuracy))","3eb9a821":"### 8. \ud559\uc2b5\ub370\uc774\ud130 \ubaa8\ub378 \uc131\ub2a5 \ud3c9\uac00","8669170a":"### 2. \ub525\ub7ec\ub2dd \ubaa8\ub378\uc744 \uc124\uacc4\ud560 \ub54c \ud65c\uc6a9\ud558\ub294 \uc7a5\ube44 \ud655\uc778","b3f47895":"### 4. \ub370\uc774\ud130 \ud655\uc778\ud558\uae30(1)","99fed415":"### 9. \uac80\uc99d\ub370\uc774\ud130 \ubaa8\ub378 \uc131\ub2a5 \ud3c9\uac00","5482ce58":"### 5. \ub370\uc774\ud130 \ud655\uc778\ud558\uae30(2)","01e6eaaa":"### 10. Loss, Accuracy \ud655\uc778","120ca5f1":"### 6. ResNet \ubaa8\ub378 \uc124\uacc4\ud558\uae30","3befb41e":"### 7. Optimizer, Objective Function \uc124\uc815\ud558\uae30","4fa388ef":"### 3. Data Augmentation \uc774 \uc801\uc6a9\ub41c CIFAR10 \ub370\uc774\ud130 \ub2e4\uc6b4\ub85c\ub4dc(Train set, Test set \ubd84\ub9ac\ud558\uae30)","e84218c9":"### 11. Fine tuning ResNet34 pretrained on ImageNet data ","379bdcc2":"### 1. Module Import"}}