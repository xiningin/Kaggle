{"cell_type":{"1a79731d":"code","126c92cf":"code","ecda4ad4":"code","9e470935":"code","55e01110":"code","362229eb":"code","19124a07":"code","c0ee14c0":"code","97bca75d":"code","0d3ace5b":"code","835cebc2":"code","ed9fd097":"code","d73d05dd":"code","7d498eec":"code","e488fcc4":"code","3a235ac0":"code","233a18da":"code","b20972f9":"code","1f96bcc1":"code","15a99336":"code","415bcf8f":"code","332cd9e3":"code","079d5d1a":"code","05e77ee5":"code","c935ce04":"code","e592665b":"code","783f7288":"code","4dd3fa9a":"code","f1d0a290":"code","03576a91":"code","bb1098c0":"code","867a779a":"code","c0ec40ab":"code","207cf3e7":"code","9c2b48b4":"code","d19ac7a5":"code","96cb65c1":"code","b0d1dba3":"code","170977d9":"code","520d5295":"code","b455d859":"code","8e113802":"code","d9ae770b":"code","5683187a":"code","143cb88e":"code","f3f000e9":"code","81984303":"code","61dfa1ad":"code","325f6296":"code","c7e01bfd":"code","cbcfd37d":"code","e0cfe480":"code","7b65a950":"code","e8bd58bd":"code","d979cb23":"code","5fed7465":"code","aef1b536":"code","277df79f":"code","b01cad76":"code","3444c149":"code","e2bd5af1":"markdown","7b28ae64":"markdown","e66e0e65":"markdown","96d7dc6a":"markdown","5811cb2b":"markdown","2d1a37e6":"markdown","6fe4f8fc":"markdown","eab41a79":"markdown","919577c5":"markdown","d7a46671":"markdown","3117c748":"markdown","3abe91d0":"markdown","300e5348":"markdown","12c92dbf":"markdown","359de4c2":"markdown","3ba05f1c":"markdown","d9c9cf6d":"markdown","54844495":"markdown","db822dc8":"markdown","3075233f":"markdown","e60419f6":"markdown","4bded788":"markdown","816e3df2":"markdown","e605212e":"markdown","bb483457":"markdown","32276cbf":"markdown","ee04a44d":"markdown","e52c62d9":"markdown","be814fd4":"markdown","27811f25":"markdown","1143fa41":"markdown","7b1055a1":"markdown","667fd6b7":"markdown","f8442eae":"markdown","e962733c":"markdown","dfd2dc0b":"markdown","4bd677f5":"markdown","eefb2e36":"markdown","fe4fa241":"markdown","c6738af2":"markdown","122d1d2a":"markdown","e803c529":"markdown","e7d1a350":"markdown","8dba58a5":"markdown","9799d1a5":"markdown","b7d31706":"markdown","c0522704":"markdown","92ae6f5a":"markdown","4de731a6":"markdown","1e3dc66c":"markdown","64d355f7":"markdown","218964ea":"markdown","dbd64a60":"markdown","3b0b88b1":"markdown","dcc7321e":"markdown","a9c6084a":"markdown","c2854104":"markdown","d1d5df84":"markdown","7d1dce1b":"markdown","0e17b6c6":"markdown","612d42b6":"markdown","e6b666ba":"markdown","728e1a18":"markdown"},"source":{"1a79731d":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","126c92cf":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB \nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import auc\nimport warnings\nwarnings.filterwarnings('ignore')","ecda4ad4":"plt.rc('axes', titlesize=18)\nplt.rc('axes', labelsize=15)\nplt.rc('xtick', labelsize=13)\nplt.rc('ytick', labelsize=13)\nplt.rc('figure', titlesize=35)\nplt.rc('legend', fontsize=12)","9e470935":"df=pd.read_csv('..\/input\/pima-indians-diabetes-dataset\/diabetes.csv')","55e01110":"df.head()","362229eb":"X = df.drop('Outcome',axis=1)\ny = df.Outcome","19124a07":"avg_accuracies={}\naccuracies={}\nroc_auc={}\npr_auc={}","c0ee14c0":"def cal_score(name,model,folds):\n    scores = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n    avg_result=[]\n    for sc in scores:\n        scores = cross_val_score(model, X, y, cv = folds, scoring = sc)\n        avg_result.append(np.average(scores))\n    df_avg_score=pd.DataFrame(avg_result)\n    df_avg_score= df_avg_score.rename(index={0: 'Accuracy', 1:'Precision', 2:'Recall',3:'F1 score',4:'Roc auc'},columns={0:'Average'})\n    avg_accuracies[name]=np.round(df_avg_score.loc['Accuracy']*100,3)\n    values=[np.round(df_avg_score.loc['Accuracy']*100,3),np.round(df_avg_score.loc['Precision']*100,3),np.round(df_avg_score.loc['Recall']*100,3),np.round(df_avg_score.loc['F1 score']*100,3),np.round(df_avg_score.loc['Roc auc']*100,3)]\n    plt.figure(figsize=(15,8))\n    sns.set_palette('mako')\n    ax=sns.barplot(x=['Accuracy','Precision','Recall','F1 score','Roc auc'],y=values)\n    plt.yticks(np.arange(0,100,10))\n    plt.ylabel('Percentage %',labelpad=10)\n    plt.xlabel('Scoring Parameters',labelpad=10)\n    plt.title('Cross Validation '+str(folds)+'-Folds Average Scores',pad=20)\n    for p in ax.patches:\n        ax.annotate(str(p.get_height()), (p.get_x(), p.get_height()),xytext=(p.get_x()+0.3,p.get_height()+1.02))\n    plt.show()","97bca75d":"def conf_matrix(ytest,pred):\n    plt.figure(figsize=(9,6))\n    global cm1\n    cm1 = confusion_matrix(ytest, pred)\n    ax=sns.heatmap(cm1, annot= True, cmap='Blues')\n    plt.title('Confusion Matrix',pad=20)","0d3ace5b":"def metrics_score(cm):\n    total=sum(sum(cm))\n    accuracy=(cm[0,0]+cm[1,1])\/total\n    precision = cm[1,1]\/(cm[0,1]+cm[1,1])\n    sensitivity = cm[1,1]\/(cm[1,0]+cm[1,1])\n    f1 = 2 * (precision * sensitivity) \/ (precision + sensitivity)\n    specificity = cm[0,0]\/(cm[0,1]+cm[0,0])\n    values=[np.round(accuracy*100,3),np.round(precision*100,3),np.round(sensitivity*100,3),np.round(f1*100,3),np.round(specificity*100,3)]\n    plt.figure(figsize=(15,8))\n    sns.set_palette('magma')\n    ax=sns.barplot(x=['Accuracy','Precision','Recall','F1 score','Specificity'],y=values)\n    plt.yticks(np.arange(0,100,10))\n    plt.ylabel('Percentage %',labelpad=10)\n    plt.xlabel('Scoring Parameter',labelpad=10)\n    plt.title('Metrics Scores',pad=20)\n    for p in ax.patches:\n        ax.annotate(str(p.get_height()), (p.get_x(), p.get_height()),xytext=(p.get_x()+0.3,p.get_height()+1.02))\n    plt.show()","835cebc2":"def plot_roc_curve(fpr, tpr):\n    plt.figure(figsize=(8,6))\n    plt.plot(fpr, tpr, color='Orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n    plt.ylabel('True Positive Rate',labelpad=10)\n    plt.xlabel('False Positive Rate',labelpad=10)\n    plt.title('Receiver Operating Characteristic (ROC) Curve',pad=20)\n    plt.legend()\n    plt.show()","ed9fd097":"def plot_precision_recall_curve(recall, precision):\n    plt.figure(figsize=(8,6))\n    plt.plot(recall, precision, color='orange', label='PRC')\n    plt.ylabel('Precision',labelpad=10)\n    plt.xlabel('Recall',labelpad=10)\n    plt.title('Precision Recall Curve',pad=20)\n    plt.legend()\n    plt.show()","d73d05dd":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 5)\nrf = RandomForestClassifier(n_estimators = 108, random_state = 5)\nrf.fit(X_train, y_train)\nprediction1 = rf.predict(X_test)\naccuracy1 = rf.score(X_test, y_test) \nprint ('Model Accuracy:',accuracy1 * 100)","7d498eec":"accuracies['Random Forest'] = np.round(accuracy1 * 100,3)","e488fcc4":"conf_matrix(y_test,prediction1)","3a235ac0":"metrics_score(cm1)","233a18da":"cal_score('Random Forest',rf,5)","b20972f9":"probs = rf.predict_proba(X_test)\nprobs = probs[:, 1]\nauc1 = roc_auc_score(y_test, probs)\nroc_auc['Random Forest']=np.round(auc1,3)\nprint('Area under the ROC Curve (AUC): %.2f' % auc1)\nfpr1, tpr1, _ = roc_curve(y_test, probs)\nplot_roc_curve(fpr1, tpr1)","1f96bcc1":"precision1, recall1, _ = precision_recall_curve(y_test, probs)\nauc_score1 = auc(recall1, precision1)\npr_auc['Random Forest']=np.round(auc_score1,3)\nprint('Area under the PR Curve (AUCPR): %.2f' % auc_score1)\nplot_precision_recall_curve(recall1, precision1)","15a99336":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 4)\ndtc = DecisionTreeClassifier(random_state = 5)\ndtc.fit(X_train, y_train)\nprediction2 = dtc.predict(X_test)\naccuracy2 = dtc.score(X_test, y_test)\nprint ('Model Accuracy:',accuracy2 * 100)","415bcf8f":"accuracies['Decision Tree'] = np.round(accuracy2 * 100,3)","332cd9e3":"conf_matrix(y_test,prediction2)","079d5d1a":"metrics_score(cm1)","05e77ee5":"cal_score('Decision Tree',dtc,7)","c935ce04":"probs = dtc.predict_proba(X_test)\nprobs = probs[:, 1]\nauc2 = roc_auc_score(y_test, probs)\nroc_auc['Decision Tree']=np.round(auc2,3)\nprint('Area under the ROC Curve (AUC): %.2f' % auc2)\nfpr2, tpr2, _ = roc_curve(y_test, probs)\nplot_roc_curve(fpr2, tpr2)","e592665b":"precision2, recall2, _ = precision_recall_curve(y_test, probs)\nauc_score2 = auc(recall2, precision2)\npr_auc['Decision Tree']=np.round(auc_score2,3)\nprint('Area under the PR Curve (AUCPR): %.2f' % auc_score2)\nplot_precision_recall_curve(recall2, precision2)","783f7288":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 5)\ngb=GradientBoostingClassifier(n_estimators=134,learning_rate=0.2)\ngb.fit(X_train, y_train)\nprediction3 = gb.predict(X_test)\naccuracy3 = gb.score(X_test, y_test)\nprint ('Model Accuracy:',accuracy3 * 100)","4dd3fa9a":"accuracies['Gradient Boosting'] = np.round(accuracy3 * 100,3)","f1d0a290":"conf_matrix(y_test,prediction3)","03576a91":"metrics_score(cm1)","bb1098c0":"cal_score('Gradient Boosting',gb,5)","867a779a":"probs = gb.predict_proba(X_test)\nprobs = probs[:, 1]\nauc3 = roc_auc_score(y_test, probs)\nroc_auc['Gradient Boosting']=np.round(auc3,3)\nprint('Area under the ROC Curve (AUC): %.2f' % auc3)\nfpr3, tpr3, _ = roc_curve(y_test, probs)\nplot_roc_curve(fpr3, tpr3)","c0ec40ab":"precision3, recall3, _ = precision_recall_curve(y_test, probs)\nauc_score3 = auc(recall3, precision3)\npr_auc['Gradient Boosting']=np.round(auc_score3,3)\nprint('Area under the PR Curve (AUCPR): %.2f' % auc_score3)\nplot_precision_recall_curve(recall3, precision3)","207cf3e7":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 5)\nknn = KNeighborsClassifier(n_neighbors =7 )\nknn.fit(X_train, y_train)\nprediction4 = knn.predict(X_test)\naccuracy4 = knn.score(X_test, y_test) \nprint ('Model Accuracy:',accuracy4 * 100)","9c2b48b4":"accuracies['KNN'] = np.round(accuracy4 * 100,3)","d19ac7a5":"conf_matrix(y_test,prediction4)","96cb65c1":"metrics_score(cm1)","b0d1dba3":"cal_score('KNN',knn,5)","170977d9":"probs = knn.predict_proba(X_test)\nprobs = probs[:, 1]\nauc4 = roc_auc_score(y_test, probs)\nroc_auc['KNN']=np.round(auc4,3)\nprint('Area under the ROC Curve (AUC): %.2f' % auc4)\nfpr4, tpr4, _ = roc_curve(y_test, probs)\nplot_roc_curve(fpr4, tpr4)","520d5295":"precision4, recall4, _ = precision_recall_curve(y_test, probs)\nauc_score4 = auc(recall4, precision4)\npr_auc['KNN']=np.round(auc_score4,3)\nprint('Area under the PR Curve (AUCPR): %.2f' % auc_score4)\nplot_precision_recall_curve(recall4, precision4)","b455d859":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 2)\nsvm = SVC(probability=True)\nsvm.fit(X_train, y_train)\nprediction5 = svm.predict(X_test)\naccuracy5 = svm.score(X_test, y_test) \nprint ('Model Accuracy:',accuracy5 * 100)","8e113802":"accuracies['SVM'] = np.round(accuracy5 * 100,3)","d9ae770b":"conf_matrix(y_test,prediction5)","5683187a":"metrics_score(cm1)","143cb88e":"cal_score('SVM',svm,5)","f3f000e9":"probs = svm.predict_proba(X_test)\nprobs = probs[:, 1]\nauc5 = roc_auc_score(y_test, probs)\nroc_auc['SVM']=np.round(auc5,3)\nprint('Area under the ROC Curve (AUC): %.2f' % auc5)\nfpr5, tpr5, _ = roc_curve(y_test, probs)\nplot_roc_curve(fpr5, tpr5)","81984303":"precision5, recall5, _ = precision_recall_curve(y_test, probs)\nauc_score5 = auc(recall5, precision5)\npr_auc['SVM']=np.round(auc_score5,3)\nprint('Area under the PR Curve (AUCPR): %.2f' % auc_score5)\nplot_precision_recall_curve(recall5, precision5)","61dfa1ad":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 5)\ngnb = GaussianNB()\ngnb.fit(X_train, y_train) \nprediction6 = gnb.predict(X_test) \naccuracy6 = gnb.score(X_test, y_test) \nprint ('Model Accuracy:',accuracy6 * 100)","325f6296":"accuracies['Naive Bayes'] = np.round(accuracy6 * 100,3)","c7e01bfd":"conf_matrix(y_test,prediction6)","cbcfd37d":"metrics_score(cm1)","e0cfe480":"cal_score('Naive Bayes',gnb,5)","7b65a950":"probs = gnb.predict_proba(X_test)\nprobs = probs[:, 1]\nauc6 = roc_auc_score(y_test, probs)\nroc_auc['Naive Bayes']=np.round(auc6,3)\nprint('Area under the ROC Curve (AUC): %.2f' % auc6)\nfpr6, tpr6, _ = roc_curve(y_test, probs)\nplot_roc_curve(fpr6, tpr6)","e8bd58bd":"precision6, recall6, _ = precision_recall_curve(y_test, probs)\nauc_score6 = auc(recall6, precision6)\npr_auc['Naive Bayes']=np.round(auc_score6,3)\nprint('Area under the PR Curve (AUCPR): %.2f' % auc_score6)\nplot_precision_recall_curve(recall6, precision6)","d979cb23":"plt.figure(figsize=(15,8))\nsns.set_palette('cividis')\nax=sns.barplot(x=list(accuracies.keys()),y=list(accuracies.values()))\nplt.yticks(np.arange(0,100,10))\nplt.ylabel('Percentage %',labelpad=10)\nplt.xlabel('Algorithms',labelpad=10)\nplt.title('Accuracy Scores Comparison',pad=20)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x(), p.get_height()),xytext=(p.get_x()+0.3,p.get_height()+1.02))\nplt.show()","5fed7465":"plt.figure(figsize=(15,8))\nsns.set_palette('viridis')\nax=sns.barplot(x=list(avg_accuracies.keys()),y=list(avg_accuracies.values()))\nplt.yticks(np.arange(0,100,10))\nplt.ylabel('Percentage %',labelpad=10)\nplt.xlabel('Algorithms',labelpad=10)\nplt.title('Average Accuracy Scores Comparison',pad=20)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x(), p.get_height()),xytext=(p.get_x()+0.3,p.get_height()+1.02))\nplt.show()","aef1b536":"plt.figure(figsize=(8,6))\nsns.set_palette('Set1')\nplt.plot(fpr1, tpr1, label='Random Forest ROC')\nplt.plot(fpr2, tpr2, label='Decision Tree ROC')\nplt.plot(fpr3, tpr3, label='Gradient Boosting ROC')\nplt.plot(fpr4, tpr4, label='KNN ROC')\nplt.plot(fpr5, tpr5, label='SVM ROC')\nplt.plot(fpr6, tpr6, label='Naive Bayes ROC')\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.ylabel('True Positive Rate',labelpad=10)\nplt.xlabel('False Positive Rate',labelpad=10)\nplt.title('Receiver Operating Characteristic (ROC) Curves',pad=20)\nplt.legend()\nplt.show()","277df79f":"plt.figure(figsize=(15,8))\nsns.set_palette('magma')\nax=sns.barplot(x=list(roc_auc.keys()),y=list(roc_auc.values()))\n#plt.yticks(np.arange(0,100,10))\nplt.ylabel('Score',labelpad=10)\nplt.xlabel('Algorithms',labelpad=10)\nplt.title('Area under the ROC Curves (AUC)',pad=20)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x(), p.get_height()),xytext=(p.get_x()+0.3,p.get_height()+0.01))\nplt.show()","b01cad76":"plt.figure(figsize=(8,6))\nsns.set_palette('Set1')\nplt.plot(recall1, precision1, label='Random Forest PRC')\nplt.plot(recall2, precision2, label='Decision Tree PRC')\nplt.plot(recall3, precision3, label='Gradient Boosting PRC')\nplt.plot(recall4, precision4, label='KNN PRC')\nplt.plot(recall5, precision5, label='SVM PRC')\nplt.plot(recall6, precision6, label='Naive Bayes PRC')\nplt.ylabel('Precision',labelpad=10)\nplt.xlabel('Recall',labelpad=10)\nplt.title('Precision Recall Curves',pad=20)\nplt.legend()\nplt.show()","3444c149":"plt.figure(figsize=(15,8))\nsns.set_palette('mako')\nax=sns.barplot(x=list(pr_auc.keys()),y=list(pr_auc.values()))\nplt.ylabel('Score',labelpad=10)\nplt.xlabel('Algorithms',labelpad=10)\nplt.title('Area under the PR Curves (AUCPR)',pad=20)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x(), p.get_height()),xytext=(p.get_x()+0.3,p.get_height()+0.01))\nplt.show()","e2bd5af1":"### 3.5. Support Vector Machine\n\nA Support Vector Machine (SVM) is a supervised machine learning algorithm that can be employed for both classification and regression purposes. SVMs are based on the idea of finding a hyperplane that best divides a dataset into two classes.","7b28ae64":"## 2. Overview","e66e0e65":"Plotting Receiver Operating Characteristic (ROC) Curve, to illustrate the diagnostic ability of Naive Bayes Classifier as its discrimination threshold is varied and showing the Area under the ROC Curve (AUC) value which will tell us how much our model is capable of distinguishing between healthy and diabetic patients.","96d7dc6a":"Plotting Confusion Matrix to describe the performance of Gradient Boosting Classifier on a set of test data.","5811cb2b":"Defining function to create Confusion Matrix.","2d1a37e6":"Defining function to calculate the Metrics Scores.","6fe4f8fc":"Plotting different metrics scores for the Gradient Boosting Classifier for evaluation.","eab41a79":"Plotting Precision-Recall Curve for different thresholds of precision and recall much like the ROC Curve and showing the Area under the Precision-Recall Curve (AUCPR), it gives the number summary of the information in the Precision-Recall Curve.","919577c5":"### 3.3. Gradient Boosting\n\nGradient Boosting builds an additive model in a forward stage-wise fashion. it allows for the optimization of arbitrary differentiable loss functions. In each stage n_classes_ regression trees are fit on the negative gradient of the binomial or multinomial deviance loss function. Binary classification is a special case where only a single regression tree is induced.","d7a46671":"Defining function to plot Precision-Recall Curve.","3117c748":"We can see that Gradient Boosting Classifier shows the highest average accuracy score of 88.938 followed by Random Forest Classifier with an average accuracy score of 88.549\n\nPlotting the ROC Curve of the machine learning models for comparison.","3abe91d0":"Plotting Confusion Matrix to describe the performance of K-Nearest Neighbours Classifier on a set of test data.","300e5348":"### 2.1. Head\n\nChecking data head","12c92dbf":"Plotting Confusion Matrix to describe the performance of Decision Tree Classifier on a set of test data.","359de4c2":"### 3.4. K-Nearest Neighbors\n\nKNN is a non-parametric, lazy learning algorithm. Its purpose is to use a database in which the data points are separated into several classes to predict the classification of a new sample point.","3ba05f1c":"Plotting different metrics scores for the K-Nearest Neighbours Classifier for evaluation.","d9c9cf6d":"Defining variables to store the outputs.","54844495":"### 1.1. Load libraries\n\nLoading the libraries","db822dc8":"## 3. Machine Learning\n\nWe will train out data on different machine learning models and use different techniques on each model and then compare our finding at the end to determine which model is working best for out data.","3075233f":"Plotting the average scores of different metrics scores for further evaluation.","e60419f6":"Plotting the average scores of different metrics scores for further evaluation.","4bded788":"Storing model accuracy to plot for comparison with other Machine Learning models.","816e3df2":"Plotting the average scores of different metrics scores for further evaluation.","e605212e":"## 4. Performance Comparison\n\nPlotting the accuracy metric score of the machine learning models for comparison.","bb483457":"We can see that Gradient Boosting Classifier shows the highest AUC score of 0.979 followed by Random Forest Classifier with an AUC score of 0.975\n\nPlotting the PR Curve of the machine learning models for comparison.","32276cbf":"### 3.1. Random Forest\n\nA Random Forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.","ee04a44d":"Setting the default values for plots","e52c62d9":"Plotting the average scores of different metrics scores for further evaluation.","be814fd4":"# Model Performance and Comparison\n\nTo measure the performance of a model, we need several elements\n\n**Confusion matrix** : also known as the error matrix, allows visualization of the performance of an algorithm\n\n    True Positive (TP) : Diabetic correctly identified as diabetic\n    True Negative (TN) : Healthy correctly identified as healthy\n    False Positive (FP) : Healthy incorrectly identified as diabetic\n    False Negative (FN) : Diabetic incorrectly identified as healthy\n\n**Metrics**\n\n    Accuracy : (TP + TN) \/ (TP + TN + FP +FN)\n    Precision : TP \/ (TP + FP)\n    Recall : TP \/ (TP + FN)\n    F1 score : 2 x ((Precision x Recall) \/ (Precision + Recall))\n\n**Roc Curve** : The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.\n\n**Precision Recall Curve** :  Shows the tradeoff between precision and recall for different threshold","27811f25":"### 3.2. Decision Tree\n\nDecision Trees are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.","1143fa41":"We can see that Random Forest Classifier shows the highest accuracy score of 92.857 followed by Decision Tree Classifier with an accuracy score of 92.208\n\nPlotting the average accuracy metric score of the machine learning models for comparison.","7b1055a1":"Plotting the AUC values of PR Curve of the machine learning models for comparison.","667fd6b7":"Plotting Precision-Recall Curve for different thresholds of precision and recall much like the ROC Curve and showing the Area under the Precision-Recall Curve (AUCPR), it gives the number summary of the information in the Precision-Recall Curve.","f8442eae":"Plotting Precision-Recall Curve for different thresholds of precision and recall much like the ROC Curve and showing the Area under the Precision-Recall Curve (AUCPR), it gives the number summary of the information in the Precision-Recall Curve.","e962733c":"Storing model accuracy to plot for comparison with other Machine Learning models.","dfd2dc0b":"Plotting Precision-Recall Curve for different thresholds of precision and recall much like the ROC Curve and showing the Area under the Precision-Recall Curve (AUCPR), it gives the number summary of the information in the Precision-Recall Curve.","4bd677f5":"Plotting Receiver Operating Characteristic (ROC) Curve, to illustrate the diagnostic ability of Random Forest Classifier as its discrimination threshold is varied and showing the Area under the ROC Curve (AUC) value which will tell us how much our model is capable of distinguishing between healthy and diabetic patients.","eefb2e36":"Plotting the average scores of different metrics scores for further evaluation.","fe4fa241":"Plotting different metrics scores for the Random Forest Classifier for evaluation.","c6738af2":"Storing model accuracy to plot for comparison with other Machine Learning models.","122d1d2a":"### 3.6. Na\u00efve Bayes\n\nA Naive Bayes Classifier is an algorithm that uses Bayes' theorem to classify objects. Naive Bayes classifiers assume strong, or naive, independence between attributes of data points.","e803c529":"Plotting different metrics scores for the Decision Tree Classifier for evaluation.","e7d1a350":"Plotting different metrics scores for the Naive Bayes Classifier for evaluation.","8dba58a5":"Storing model accuracy to plot for comparison with other Machine Learning models.","9799d1a5":"### 1.2. Read data\n\nReading the data with pandas","b7d31706":"Storing model accuracy to plot for comparison with other Machine Learning models.","c0522704":"Plotting Precision-Recall Curve for different thresholds of precision and recall much like the ROC Curve and showing the Area under the Precision-Recall Curve (AUCPR), it gives the number summary of the information in the Precision-Recall Curve.","92ae6f5a":"Plotting Precision-Recall Curve for different thresholds of precision and recall much like the ROC Curve and showing the Area under the Precision-Recall Curve (AUCPR), it gives the number summary of the information in the Precision-Recall Curve.","4de731a6":"Defining function to plot ROC Curve.","1e3dc66c":"Plotting Receiver Operating Characteristic (ROC) Curve, to illustrate the diagnostic ability of Decision Tree Classifier as its discrimination threshold is varied and showing the Area under the ROC Curve (AUC) value which will tell us how much our model is capable of distinguishing between healthy and diabetic patients.","64d355f7":"Plotting Receiver Operating Characteristic (ROC) Curve, to illustrate the diagnostic ability of K-Nearest Neighbours Classifier as its discrimination threshold is varied and showing the Area under the ROC Curve (AUC) value which will tell us how much our model is capable of distinguishing between healthy and diabetic patients.","218964ea":"Plotting Receiver Operating Characteristic (ROC) Curve, to illustrate the diagnostic ability of Support Vector Machine Classifier as its discrimination threshold is varied and showing the Area under the ROC Curve (AUC) value which will tell us how much our model is capable of distinguishing between healthy and diabetic patients.","dbd64a60":"Plotting Confusion Matrix to describe the performance of Support Vector Machine Classifier on a set of test data.","3b0b88b1":"Plotting different metrics scores for the Support Vector Machine Classifier for evaluation.","dcc7321e":"Plotting the average of different metrics scores for further evaluation.","a9c6084a":"Plotting Confusion Matrix to describe the performance of Random Forest Classifier on a set of test data.","c2854104":"Defining function to calculate the Cross-Validation score.","d1d5df84":"### 2.2. Splitting Dataset\n\nSplitting the target variable in y and all the other features in X","7d1dce1b":"We can see that Gradient Boosting Classifier shows the highest AUCPR score of 0.966 followed by Random Forest Classifier with an AUC score of 0.956\n\nBy analyzing the above results we can see that Random Forest and Gradient Boosting Classifer are both giving some what similar performance to each other and show better results than other machine learning algorithms.","0e17b6c6":"Plotting Receiver Operating Characteristic (ROC) Curve, to illustrate the diagnostic ability of Gradient Boosting Classifier as its discrimination threshold is varied and showing the Area under the ROC Curve (AUC) value which will tell us how much our model is capable of distinguishing between healthy and diabetic patients.","612d42b6":"Storing model accuracy to plot for comparison with other Machine Learning models.","e6b666ba":"Plotting Confusion Matrix to describe the performance of Naive Bayes Classifier on a set of test data.","728e1a18":"Plotting the AUC values of ROC Curve of the machine learning models for comparison."}}