{"cell_type":{"22cb658e":"code","a248c9df":"code","2a37caff":"code","091087e9":"code","76651253":"code","cd22d636":"code","81c9a9b1":"code","2272aabd":"code","fc613b82":"code","c298c078":"code","1b9b5929":"markdown","3de299e7":"markdown","f1799068":"markdown","69cfff1a":"markdown","31e00967":"markdown","c09271d8":"markdown","f53d9eca":"markdown","a665868e":"markdown","c383255a":"markdown"},"source":{"22cb658e":"from sklearn.neighbors import KNeighborsClassifier","a248c9df":"clf = KNeighborsClassifier()","2a37caff":"import mglearn\nX, y = mglearn.datasets.make_forge()","091087e9":"X.shape","76651253":"import matplotlib.pyplot as plt\n# plot dataset\nmglearn.discrete_scatter(X[:, 0], X[:, 1], y)\nplt.legend([\"Class 0\", \"Class 1\"], loc=4)\nplt.xlabel(\"First feature\")\nplt.ylabel(\"Second feature\")\nprint(\"X.shape: {}\".format(X.shape))","cd22d636":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)","81c9a9b1":"#train the model\nclf.fit(X_train, y_train)\n#use the model to predict values of test data \nprint(\"Test set predictions: {}\".format(clf.predict(X_test)))\n# model accuracy using test data\nprint(\"Test set accuracy: {:.2f}\".format(clf.score(X_test, y_test)))","2272aabd":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nimport mglearn","fc613b82":"clf = KNeighborsClassifier()\nX, y = mglearn.datasets.make_forge()\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n#train the model\nclf.fit(X_train, y_train)\n#use the model to predict values of test data \nprint(\"Test set predictions: {}\".format(clf.predict(X_test)))\n# model accuracy using test data\nprint(\"Test set accuracy: {:.2f}\".format(clf.score(X_test, y_test)))","c298c078":"import matplotlib.pyplot as plt\nX, y = mglearn.datasets.make_wave(n_samples=40)\nplt.plot(X, y, 'o')\nplt.ylim(-3, 3)\nplt.xlabel(\"Feature\")\nplt.ylabel(\"Target\")","1b9b5929":"load the classifier from sklean python package contain most of machine learning algorithms","3de299e7":"train the model","f1799068":"split the data set as training and set set load the train_test_split function from sklearn package parameter to the function","69cfff1a":"the classifier take a parameter \"n_neighbors\" by default=1 for one neighbor","31e00967":"import matplot package to visualize the dataset","c09271d8":"# The k-NN algorithm :\n* The k-NN algorithm is the simplest machine learning algorithm.\n* Is a non-parametric method proposed by Thomas Cover used for classification and regression.\n* The output depends on whether k-NN is used for classification or regression:\n* >  In k-NN classification, the output is a class membership. An object is classified by a majority vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). If k = 1, then the object is simply assigned to the class of that single nearest neighbor.\n* > In k-NN regression, the output is the property value for the object. This value is the average of the values of k nearest neighbors.\n* Building the model:\n>  1. storing the training dataset. \n>  2. To make a prediction for a new data point, the algorithm finds the closest data points in the training dataset\u2014its \"nearest neighbors.\"","f53d9eca":"# 2. Wave DataSet","a665868e":"# building the k-nn on simple data sets","c383255a":"# 1. on Forge Dataset\nload the data sets\n* to add mglearn \n    * open cosole on the bottom of kernal page then write a command\n    * pip install mglearn\n    * restart the kernal"}}