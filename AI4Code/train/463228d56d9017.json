{"cell_type":{"dae304c9":"code","30666457":"code","c23ec888":"code","82882d75":"code","143398ae":"code","cad17a8a":"code","220a53e2":"code","4604df9c":"code","3e0ce5d6":"code","d149c346":"code","85e2799f":"code","de058fc4":"code","e12704e5":"code","2883444f":"code","ba2772b4":"code","99074d6f":"code","b4d8d782":"code","463df696":"code","fd2e9094":"code","b80e3c4b":"code","a7269228":"code","da562417":"code","40b29637":"code","c9c4e053":"code","927f3ab2":"code","13aa825f":"code","12d8d8b0":"code","f438dfbe":"code","3db327cb":"code","9c1513b7":"markdown","d55f1537":"markdown","4e098378":"markdown","4e17e15a":"markdown","dd15bcf1":"markdown","d44b32a5":"markdown","090243f2":"markdown","3a938152":"markdown","30228d0f":"markdown","fbcbce5f":"markdown","3a8dc033":"markdown","72b9d8a4":"markdown","b056202a":"markdown","2e60f626":"markdown"},"source":{"dae304c9":"%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n#iris = pd.read_csv(\"C:\\\\Users\\\\user\\\\Downloads\\\\Iris.csv\")\n\n","30666457":"from sklearn.datasets import load_iris\niris = load_iris()","c23ec888":"print(iris.DESCR)","82882d75":"x = iris.data\ny = iris.target\nfeatures = iris.feature_names\ntarget = iris.target_names\n\nprint(\"Feature Names:\",features)\nprint(\"-\"*100)\nprint(\"Target Names:\", target)\nprint(\"-\"*100)\nprint(\"data:\", x[:10])\nprint(\"-\"*100)","143398ae":"df = pd.DataFrame(x, columns=iris.feature_names)\ndf['target'] = iris.target","cad17a8a":"df","220a53e2":"df_norm = df[iris.feature_names].apply(lambda x: (x - x.min()) \/ (x.max() - x.min()))\ndf_norm.sample(n=5)","4604df9c":"df_norm.describe()","3e0ce5d6":"df.sample(n=5)","d149c346":"df = pd.concat([df_norm, df['target']], axis=1)\ndf.sample(n=5)","85e2799f":"from sklearn.neural_network import MLPClassifier # neural network\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\ntrain, test = train_test_split(df, test_size = 0.3)\ntrainX = train[features]# taking the training data features\ntrainY=train.target# output of our training data\ntestX= test[features] # taking test data features\ntestY =test.target   #output value of test data\ntrainX.head(5)","de058fc4":"trainY.head(5)","e12704e5":"testX.head(5)","2883444f":"testY.head(5)","ba2772b4":"clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(3, 3), random_state=1)\nclf.fit(trainX, trainY)","99074d6f":"prediction = clf.predict(testX)\nprint(prediction)","b4d8d782":"print(testY.values)","463df696":"print('The accuracy of the Multi-layer Perceptron is:',metrics.accuracy_score(prediction,testY))","fd2e9094":"X_train, X_test, y_train, y_test = train_test_split(df[iris.feature_names], df['target'], test_size=0.4, random_state=17)","b80e3c4b":"from sklearn import tree\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport graphviz\n\nclf = tree.DecisionTreeClassifier(random_state=17)\nclf = clf.fit(X_train, y_train)\nclf = tree.DecisionTreeClassifier(random_state=17)\nclf = clf.fit(X_train, y_train)\n \ny_pred = clf.predict(X_test)\n","a7269228":"data = df.drop(columns=\"target\")","da562417":"print('\\nAccuracy: {0:.4f}'.format(accuracy_score(y_test, y_pred)))","40b29637":"from sklearn import tree\nfrom graphviz import Source\nimport pandas as pd\n\nimport graphviz\nfeat = data.columns \nSource(tree.export_graphviz(clf, out_file = None, feature_names = feat,max_depth=4))","c9c4e053":"X_train, X_test, y_train, y_test = train_test_split( df[iris.feature_names], df['target'],  test_size=0.2, random_state=20)","927f3ab2":"from sklearn.svm import LinearSVC\n\nclf = LinearSVC(penalty='l2', loss='squared_hinge',\n                dual=True, tol=0.0001, C=100, multi_class='ovr',\n                fit_intercept=True, intercept_scaling=1, class_weight=None,verbose=0\n                , random_state=0, max_iter=1000)\nclf.fit(X_train,y_train)\n\nprint('Accuracy of linear SVC on training set: {:.2f}'.format(clf.score(X_train, y_train) * 100))\n\nprint('Accuracy of linear SVC on test set: {:.2f}'.format(clf.score(X_test, y_test) *100))\n","13aa825f":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nimport numpy as np\n    \nc = np.logspace(start = -15, stop = 1000, base = 1.02)\nparam_grid = {'C': c}\n\n\ngrid = GridSearchCV(clf, param_grid =param_grid, cv=3, n_jobs=-1, scoring='accuracy')\ngrid.fit(X_train, y_train)\n  \nprint(\"The best parameters are %s with a score of %0.0f\" % (grid.best_params_, grid.best_score_ * 100 ))\nprint( \"Best estimator accuracy on test set {:.2f} \".format(grid.best_estimator_.score(X_test, y_test) * 100 ) )","12d8d8b0":"from sklearn.svm import SVC\n\nclf_SVC = SVC(C=100.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, \n          probability=False, tol=0.001, cache_size=200, class_weight=None, \n          verbose=0, max_iter=-1, decision_function_shape=\"ovr\", random_state = 0)\nclf_SVC.fit(X_train,y_train)\n\nprint('Accuracy of SVC on training set: {:.2f}'.format(clf_SVC.score(X_train, y_train) * 100))\n\nprint('Accuracy of SVC on test set: {:.2f}'.format(clf_SVC.score(X_test, y_test) * 100))\n","f438dfbe":"from sklearn.metrics import classification_report\nimport numpy as np\n    \nc_SVC = np.logspace(start = 0, stop = 10, num = 100, base = 2 , dtype = 'float64')\nprint( 'the generated array of c values')\nprint ( c_SVC )\nparam_grid_S = {'C': c_SVC}\n\n\n\nprint(\"\\n Array of means \\n\")\nclf = GridSearchCV(clf_SVC, param_grid =param_grid_S, cv=20 , scoring='accuracy')\nclf.fit(X_train, y_train)\nmeans = clf.cv_results_['mean_test_score']\nstds = clf.cv_results_['std_test_score']\nprint(means)\n\ny_true, y_pred = y_test, clf.predict(X_test)\nprint( '\\nClassification report\\n' )\nprint(classification_report(y_true, y_pred))","3db327cb":"\nfrom prettytable import PrettyTable\nx = PrettyTable()\nx.field_names = [\"SVM\",\"Train Score\",\"Test Score\"]\nx.add_row([\"LinearSVC\",97.5,90.00])\nx.add_row([\"SVC\",97.50,96.67])\n\nfrom IPython.display import Markdown, display\ndef printmd(string):\n    display(Markdown(string))\nprintmd('****Final Conclusion:****')\nprint(x)","9c1513b7":"### Visualizing Decision Tree ","d55f1537":"## SVC","4e098378":"### Creating Instance and prdicting labels","4e17e15a":"## Linear SVC","dd15bcf1":"### Measuring Model Performance","d44b32a5":"### Accuracy with MLP ","090243f2":"# Read and Load dataset","3a938152":"# Decision Tree","30228d0f":"### Splitting Data into Training and Test Sets","fbcbce5f":"### Conclusion","3a8dc033":"# MLP classifier","72b9d8a4":"### Splitting Data into Training and Test Sets","b056202a":"# SVM","2e60f626":"# IRIS Dataset"}}