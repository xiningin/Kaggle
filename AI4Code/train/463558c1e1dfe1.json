{"cell_type":{"ea577702":"code","d2304c72":"code","a2ea97f7":"code","dbf6f1c6":"code","34027678":"code","8f8ba579":"code","6ea8748d":"code","5da4b6c0":"code","cd8ecfdf":"code","bb3cf9a0":"code","bbd98d64":"code","c2a14ec3":"code","5c797d54":"code","1ec81c48":"code","e4751296":"code","c4a6dacb":"code","67a54868":"code","1d0e7a58":"code","fe28a43e":"code","c1ae185e":"code","9d5d6cb2":"code","d066ba9e":"code","cfa6b9b9":"code","b171100c":"code","53a1c62c":"code","206d1acb":"code","03348080":"code","ce83d359":"markdown","5bbc5b81":"markdown","791030bd":"markdown","dfff3eaf":"markdown","b3d2e392":"markdown","579e0a6a":"markdown","3f715daf":"markdown","eb7013cc":"markdown","9129f2d9":"markdown","6a254e0a":"markdown"},"source":{"ea577702":"import numpy as np \nimport pandas as pd \nimport random as rn\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\nimport seaborn as sns\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' ","d2304c72":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tokenizers import BertWordPieceTokenizer\n\nimport transformers\nfrom transformers import BertTokenizer, TFBertForSequenceClassification\nfrom transformers import InputExample, InputFeatures\n\nimport logging\ntransformers.logging.set_verbosity_error()\n# logging.getLogger(\"tensorflow\").setLevel(logging.WARNING)","a2ea97f7":"p = 0.002  # to randomly select n% of the rows","dbf6f1c6":"df_reviews = pd.read_csv('\/kaggle\/input\/steam-reviews\/dataset.csv', skiprows=lambda i: i>0 and rn.random() > p)\ndf_reviews.head()","34027678":"# remove Early Access Reviews\ndf_reviews = df_reviews[df_reviews.review_text.str.strip() != 'Early Access Review']","8f8ba579":"# size of dataframe\ndf_reviews.shape","6ea8748d":"# convert review text to string\ndf_reviews[\"review_text\"] = df_reviews[\"review_text\"].astype(str)","5da4b6c0":"# drop the reviews with null score\ndf_reviews_2 = df_reviews[df_reviews[\"review_score\"].notnull()]\ndf_reviews_2[\"review_score\"] = np.where(df_reviews_2[\"review_score\"]==-1, 0, df_reviews_2[\"review_score\"])","cd8ecfdf":"# distribution of negative and positive reviews\ndf_reviews_2[\"review_score\"].value_counts()","bb3cf9a0":"reviews = df_reviews_2[\"review_text\"].values.tolist()\nlabels = df_reviews_2[\"review_score\"].tolist()","bbd98d64":"# split the dataset into train, validation and holdout sets (60-20-20)\ntraining_sentences, test_sentences, training_labels, test_labels = train_test_split(reviews, labels, test_size=.4)\n\nvalidation_sentences, holdout_sentences, validation_labels, holdout_labels = train_test_split(test_sentences, test_labels, test_size=.5)","c2a14ec3":"# instantiate BERT tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-cased')","5c797d54":"# example of the output of the tokenizer: \ntokenizer([training_sentences[0]], truncation=True,\n                            padding=True, max_length=512)","1ec81c48":"# tokenize training, validation and hold-out sentences\ntrain_encodings = tokenizer(training_sentences,\n                            truncation=True,\n                            padding=True)\n\nvalidation_encodings = tokenizer(validation_sentences,\n                            truncation=True,\n                            padding=True)\n\nholdout_encodings = tokenizer(holdout_sentences,\n                            truncation=True,\n                            padding=True)","e4751296":"# convert the input encodings and labels into a TensorFlow Dataset object\ntrain_dataset = tf.data.Dataset.from_tensor_slices((\n                            dict(train_encodings),\n                            training_labels\n                            ));\n\nvalidation_dataset = tf.data.Dataset.from_tensor_slices((\n                            dict(validation_encodings),\n                            validation_labels\n                            ));\n\nholdout_dataset = tf.data.Dataset.from_tensor_slices((\n                            dict(holdout_encodings),\n                            holdout_labels\n                            ));","c4a6dacb":"# initialize a pre-trained model\nmodel = TFBertForSequenceClassification.from_pretrained('bert-base-cased',num_labels=2)","67a54868":"# create an optimizer and compile the model\noptimizer = tf.keras.optimizers.Adam(learning_rate=2e-5, epsilon=1e-08)\nmodel.compile(optimizer=optimizer, loss=model.compute_loss, metrics=['accuracy'])","1d0e7a58":"# train and fine-tune the model\nhistory = model.fit(train_dataset.shuffle(100).batch(8),\n          epochs=2,\n          batch_size=8,\n          validation_data=validation_dataset.shuffle(100).batch(8), verbose=1)","fe28a43e":"# plot train and validation accuracy\nax = plt.figure().gca()\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nax.xaxis.set_major_locator(MaxNLocator(integer=True))\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","c1ae185e":"# save the model\nmodel.save_pretrained(\".\/sent_model\")","9d5d6cb2":"# load the model and evaluate the model on holdout set\nloaded_model = TFBertForSequenceClassification.from_pretrained(\".\/sent_model\")\nresult = model.evaluate(holdout_dataset.batch(8))\ndict(zip(model.metrics_names, result))","d066ba9e":"# predict the sentiment for holdout set\ntf_output = loaded_model.predict(holdout_dataset.batch(8))\npred_label = tf.argmax(tf.nn.softmax(tf_output[\"logits\"], axis=1).numpy(), 1).numpy()","cfa6b9b9":"# generate the confusion matrix\ncm = tf.math.confusion_matrix(\n    holdout_labels, pred_label, num_classes=2, weights=None, dtype=tf.dtypes.int32,\n    name=None\n).numpy()\n\nprint(\"confusion matrix\\n\",cm)","b171100c":"# visualize the confusion matrix\ncm_norm = np.around(cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis], decimals=2)\n\ncm_df = pd.DataFrame(cm_norm,\n                 index = [0,1], \n                 columns =[0,1])\n\nfigure = plt.figure(figsize=(4, 4))\nsns.heatmap(cm_df, annot=True, cmap=plt.cm.Blues)\nplt.tight_layout()\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","53a1c62c":"# calculate recall and precision\n\ntp = cm[0][0]\nfn = cm[0][1]\n\ntn = cm[1][1]\nfp = cm[1][0]\n\nrecall = round(tp \/ (tp+fn), 2)\nprecision = round(tp \/ (tp+fp), 2)\n\nprint(\"recall score:\", recall)\nprint(\"precision score:\", precision)","206d1acb":"# altenatively you can use sklearn.classification_report:\nprint(classification_report(holdout_labels, pred_label))","03348080":"# example of a prediction\nindex = 91\nprint(\"example sentence:\\n\", holdout_sentences[index])\nprint(\"\\nsentiment:\", holdout_labels[index])\nprint(\"prediction:\", pred_label[index])","ce83d359":"<a id=\"section-1\"><\/a>\n## Import Libraries","5bbc5b81":"<a id=\"subsection-1\"><\/a>\n### Input Tokenization","791030bd":"I use BERT to predict the sentiment of a review.\n\nhttps:\/\/huggingface.co\/docs\/transformers\/model_doc\/bert","dfff3eaf":"You can see experiment with additional fine-tuning and\/or more training data to improve the recall\/precision score","b3d2e392":"<a id=\"section-3\"><\/a>\n## Sentiment Classification with BERT","579e0a6a":"<a id=\"section-2\"><\/a>\n## Read and Prep Data","3f715daf":"<a id=\"subsection-2\"><\/a>\n### Training the Model","eb7013cc":"#### The original dataset is quite large. I only read a subset of rows for faster run.","9129f2d9":"## Sentiment Classification\n\n* [Import Libraries ](#section-1)\n* [Read and Prep Data](#section-2)\n* [Sentiment Classification with BERT](#section-4)\n    - [Input Tokenization](#subsection-1)\n    - [Training the Model](#subsection-2)\n    - [Performance Metrics](#subsection-3)","6a254e0a":"<a id=\"subsection-3\"><\/a>\n### Performance Metrics"}}