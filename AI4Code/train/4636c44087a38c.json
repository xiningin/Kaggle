{"cell_type":{"eb7506b0":"code","92f32001":"code","8b32a596":"code","879911d9":"code","0deaac39":"code","a473a058":"code","f1793b41":"code","d9248869":"code","142ef89e":"code","92536ee6":"code","9efdcf1d":"code","2dac8ea5":"code","657ae99e":"code","2618d4da":"code","dfc42a4d":"code","a4794319":"code","21944620":"code","ac4e66f8":"code","b0968188":"code","d9b008b6":"code","838d1792":"markdown"},"source":{"eb7506b0":"# Import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n%matplotlib inline","92f32001":"import pandas as pd\nloans = pd.read_csv(\"..\/input\/loan_data.csv\")\nloans.head()\n\n# Data contains information on potential clients of LendingClub.com from 2007-2010.\n# Goal is to classify and predict if a borrower will pay his or her loan back in full based on these given features.","8b32a596":"loans.info()","879911d9":"# Check for missing values\nloans.isnull().sum()","0deaac39":"loans.describe()","a473a058":"sns.distplot(loans['fico'])\nplt.show()","f1793b41":"plt.figure(figsize=(10,6))\nloans[loans['credit.policy'] == 1]['fico'].hist(bins=30, alpha=0.6, label='Credit.Policy=1')\nloans[loans['credit.policy'] == 0]['fico'].hist(bins=30, alpha=0.6, label='Credit.Policy=0')\nplt.xlabel('FICO')\nplt.legend()\nplt.show()","d9248869":"plt.figure(figsize=(10,6))\nloans[loans['not.fully.paid'] == 1]['fico'].hist(bins=30, alpha=0.6, label='not.fully.paid=1')\nloans[loans['not.fully.paid'] == 0]['fico'].hist(bins=30, alpha=0.6, label='not.fully.paid=0')\nplt.xlabel('FICO')\nplt.legend()\nplt.show()","142ef89e":"plt.figure(figsize=(12,6))\nsns.countplot(x='purpose', hue='not.fully.paid', data=loans)\nplt.tight_layout\nplt.show()","92536ee6":"sns.jointplot(x='fico', y='int.rate', data=loans, space=0.2)\nplt.show()","9efdcf1d":"sns.lmplot(x='fico', y='int.rate', hue='credit.policy', data=loans, col='not.fully.paid')\nplt.show()","2dac8ea5":"loans['purpose'].nunique()","657ae99e":"# Converting categorical variables to dummy variables\ncat_feats = ['purpose']\nfinal_data = pd.get_dummies(loans, columns=cat_feats, drop_first=True)\nfinal_data.head()","2618d4da":"# Spltting data into training and test data sets\n\nfrom sklearn.model_selection import train_test_split\nX = final_data.drop('not.fully.paid', axis=1)\ny = final_data['not.fully.paid']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","dfc42a4d":"# We will use a single decision tree first before using a random forest model\nfrom sklearn.tree import DecisionTreeClassifier\ndtree = DecisionTreeClassifier()\ndtree.fit(X_train, y_train)\ny_pred_tree = dtree.predict(X_test)","a4794319":"# Decision Tree Model Evaluation\nfrom sklearn.metrics import confusion_matrix, classification_report\nprint(classification_report(y_test, y_pred_tree))\nprint(confusion_matrix(y_test, y_pred_tree))","21944620":"# Training a Random Forest Model\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=300)\nrf.fit(X_train, y_train)\ny_pred_rf = rf.predict(X_test)","ac4e66f8":"# Random Forest Model Evaluation\nprint(classification_report(y_test, y_pred_rf))\nprint(confusion_matrix(y_test, y_pred_rf))","b0968188":"loans.shape","d9b008b6":"# Random forest was slightly more accurate overall, which is expected with an ensemble of decision trees vs. one decision tree.\n# If more data were to be collected and used to retreain each model, the ensemble model will most likey start to outperform the single decision tree more significantly.","838d1792":"## Exploratory Data Analysis"}}