{"cell_type":{"cd83afd3":"code","ea2285af":"code","78b0b763":"code","1fc45e0e":"code","229dc687":"code","9ab316c4":"code","de4513f5":"code","b45c2ec6":"code","b8c1556f":"code","64f674db":"code","59cbc289":"code","831e4b57":"code","c32fc4d3":"code","c2cefc20":"code","fa4f5942":"code","079789cb":"code","fc791f95":"code","668fc19a":"code","41731bf3":"code","bcfa6d87":"code","c9351397":"code","6019a75d":"code","67d5bd0d":"code","28779dc0":"code","2c7425ea":"code","d1d2cee1":"code","7c467fa3":"code","2864d2f6":"code","0e8dd91c":"code","37c02ae1":"code","1935b181":"code","5e0c42e4":"code","3b75a031":"code","9fee2c73":"code","a77088da":"code","196b6ecf":"code","2e478ec3":"code","565b8195":"code","54e92483":"code","49106d2f":"code","c9835717":"code","00844ab0":"code","795f638c":"code","d91024f8":"code","36e4c011":"code","ec3aa0c4":"code","9f884639":"code","d38d32e6":"code","ab8139df":"code","fadd1e6a":"markdown","945de4b1":"markdown","f9a66a60":"markdown","de709b20":"markdown","4bc3f16e":"markdown","2af10f4c":"markdown","ab2b4034":"markdown","aaab3726":"markdown","c3285116":"markdown","de71d30a":"markdown","21523575":"markdown","17055ca6":"markdown"},"source":{"cd83afd3":"# This block is from https:\/\/www.kaggle.com\/ldfreeman3\/a-data-science-framework-to-achieve-99-accuracy\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n\n#load packages\nimport sys #access to system parameters https:\/\/docs.python.org\/3\/library\/sys.html\nprint(\"Python version: {}\". format(sys.version))\n\nimport pandas as pd #collection of functions for data processing and analysis modeled after R dataframes with SQL like features\nprint(\"pandas version: {}\". format(pd.__version__))\n\nimport matplotlib #collection of functions for scientific and publication-ready visualization\nprint(\"matplotlib version: {}\". format(matplotlib.__version__))\n\nimport numpy as np #foundational package for scientific computing\nprint(\"NumPy version: {}\". format(np.__version__))\n\nimport scipy as sp #collection of functions for scientific computing and advance mathematics\nprint(\"SciPy version: {}\". format(sp.__version__)) \n\nimport IPython\nfrom IPython import display #pretty printing of dataframes in Jupyter notebook\nprint(\"IPython version: {}\". format(IPython.__version__)) \n\nimport sklearn #collection of machine learning algorithms\nprint(\"scikit-learn version: {}\". format(sklearn.__version__))\n\nimport seaborn as sns #collection of functions for data visualization\nprint(\"seaborn version: {}\". format(sns.__version__))\n\nfrom sklearn.preprocessing import OneHotEncoder #OneHot Encoder\nfrom sklearn.impute import SimpleImputer\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n#misc libraries\nimport random\nimport time\nfrom pandas import datetime\n\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\nprint('-'*25)\n\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))","ea2285af":"item_categories = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\nitems = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/items.csv')\nsales_train_raw = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\nsample_submission = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv')\nshops_raw = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/shops.csv')\ntest_raw = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/test.csv')","78b0b763":"sales_train_raw.info()","1fc45e0e":"def parser(x):\n    return datetime.strptime(x,'%d.%m.%Y')\n\nsales_train_di = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv', index_col= 0, parse_dates=[0] ,date_parser=parser)","229dc687":"sales_train_raw.head()","9ab316c4":"sales_train_di.head()","de4513f5":"fig = plt.figure(figsize=(5,5))\nplt.subplot(1,2,1)\nsns.boxplot(y='item_price', data=sales_train_di)\nplt.subplot(1,2,2)\nsns.boxplot(y='item_cnt_day', data=sales_train_di)\nfig.tight_layout(pad=1.0)","b45c2ec6":"sales_train_di.item_price = sales_train_di.item_price.apply(lambda x: 6000 if x > 10000 else x)\nsales_train_di.item_cnt_day = sales_train_di.item_cnt_day.apply(lambda x: 700 if x > 700 else x)","b8c1556f":"fig = plt.figure(figsize=(5,5))\nplt.subplot(1,2,1)\nsns.boxplot(y='item_price', data=sales_train_di)\nplt.subplot(1,2,2)\nsns.boxplot(y='item_cnt_day', data=sales_train_di)\nfig.tight_layout(pad=1.0)","64f674db":"#since we want to predict the sales through time, we are creating the feature we want to target\nsales_train_di['sales'] = sales_train_di['item_price']*sales_train_di['item_cnt_day']","59cbc289":"sales_train_di.index.value_counts()","831e4b57":"sales = sales_train_di.drop(['date_block_num', 'shop_id', 'item_id', 'item_price', 'item_cnt_day'], axis=1)","c32fc4d3":"sales.head()","c2cefc20":"sns.boxplot(sales)","fa4f5942":"sales.sales = sales.sales.apply(lambda x: 800000 if x > 800000 else x)","079789cb":"sns.boxplot(sales)","fc791f95":"#grouping the data by month\nsales_gm = sales.resample(\"m\").sum()","668fc19a":"sales_gm","41731bf3":"sales_gm.size","bcfa6d87":"plt.figure(figsize=(14,6))\nsns.lineplot(data=sales_gm.sales)","c9351397":"from statsmodels.graphics.tsaplots import plot_acf\nplot_acf(sales_gm.sales)","6019a75d":"#split the data for trainning and validation purposes\ntrain_index_m = int(np.rint(sales_gm.size*0.8))","67d5bd0d":"sales_gm.size","28779dc0":"train_index_m","2c7425ea":"X_train_m = sales_gm[:train_index_m]\nX_train_m.size\n","d1d2cee1":"X_train_m","7c467fa3":"X_test_m = sales_gm[train_index_m:]\nX_test_m.size","2864d2f6":"X_test_m","0e8dd91c":"#hyperparameter tuning for the ARIMA model\nimport itertools\nfrom statsmodels.tsa.arima_model import ARIMA\n\ndef hyper_p (train):\n    best_aic = np.inf \n    best_param = None\n    best_model = None\n    \n    p=d=q=range(0,12)\n    pdq = list(itertools.product(p,d,q))\n\n    for param in pdq:\n        try:\n            arima = ARIMA(train,order=param)\n            arima_fit = arima.fit()\n            if arima_fit.aic < best_aic:\n                best_aic = arima_fit.aic\n                best_param = param\n                best_model = arima_fit\n        except:\n            continue\n\n    print('aic: {:6.5f} | pdq set: {}'.format(best_aic, best_param))\n    return best_model","37c02ae1":"best_arima = hyper_p (X_train_m)","1935b181":"predictions_m= best_arima.forecast(steps=X_test_m.size)[0]\npredictions_m","5e0c42e4":"from sklearn.metrics import mean_squared_error\nscore = mean_squared_error(X_test_m, predictions_m)","3b75a031":"score","9fee2c73":"p_df = pd.DataFrame({'sale': predictions_m}, index = X_test_m.index)","a77088da":"p_df","196b6ecf":"plt.plot(X_test_m)\nplt.plot(p_df,color='red')","2e478ec3":"train_rindex = X_train_m.copy()","565b8195":"train_rindex.reset_index(level=0, inplace=True)","54e92483":"train_rindex.columns = ['ds', 'y']","49106d2f":"train_rindex","c9835717":"#borrowed from https:\/\/www.kaggle.com\/jagangupta\/time-series-basics-exploring-traditional-ts\nfrom fbprophet import Prophet\n#prophet reqiures a pandas df at the below config \n# ( date column named as DS and the value column as Y)\nmodel = Prophet( yearly_seasonality=True) #instantiate Prophet with only yearly seasonality as our data is monthly \nmodel.fit(train_rindex) #fit the model with your dataframe","00844ab0":"future = model.make_future_dataframe(periods = 7, freq = 'MS')  \n# now lets make the forecasts\nforecast = model.predict(future)\n","795f638c":"forecast","d91024f8":"model.plot(forecast)","36e4c011":"sales_gm.plot()","ec3aa0c4":"y_pred = forecast[['ds', 'yhat_lower']].tail(7)","9f884639":"y_pred.columns = ['date', 'sales']","d38d32e6":"y_pred=y_pred.set_index('date')","ab8139df":"plt.plot(X_test_m)\nplt.plot(y_pred,color='red')","fadd1e6a":"## Let's see if we have outliers in the newly created sales feature","945de4b1":"## From the info() above, we can see that date is interpreted as objects, let's do a proper read in","f9a66a60":"## Next, we want to see if we could get a better result from the Facebook Prophet model","de709b20":"## Conclusion\nAfter several attempts, using both ARIMA and Prophet, we concluded this data is not ideal for time-serie predictions. We attempted removing outliers to make sure the data represents a general trend of the sales behavior, but still could not make the models to make accurate prediction. \n\nWe can conclude that there are not enough trends presented in the data, this could be due to the company was constantly making random changes to their maketing strategies, making the sales data preseting random behaviors. Or the company replies purely on organic grow and there isn't enought data presented in the provided dataset for accurate time-series predictions.\n\nIn conclusion, time-series is not a good approach for this data, should use other means, regression or CNN.","4bc3f16e":"# Future price prediction\nGot this data from Kaggle, this is not meant for time-series predictions, but want to experiment to see if we could get a relative good prediction out of time-series models.","2af10f4c":"## Check for outliers","ab2b4034":"### Observation\n\nLooks like the data is seperated by date and item_id, meaning that each observation is a sale for an item on a specific date, thus date data are not unique, we could group the data by month","aaab3726":"## Conclusion\nAfter several attempts, using both ARIMA and Prophet, we concluded this data is not ideal for time-serie predictions. We attempted removing outliers to make sure the data represents a general trend of the sales behavior, but still could not make the models to make accurate prediction. \n\nWe can conclude that there are not enough trends presented in the data, this could be due to the company was constantly making random changes to their maketing strategies, making the sales data preseting random behaviors. Or the company replies purely on organic grow and there isn't enought data presented in the provided dataset for accurate time-series predictions.\n\nIn conclusion, time-series is not a good approach for this data, should use other means, regression or CNN.","c3285116":"## There are a lot we can do with the data, but in this kernel we will focus on forcasting","de71d30a":"## Next we work with this data to shape it into formats that we can work with before modeling","21523575":"## Remove outliers by observation obtained from the boxplots above","17055ca6":"### Observation\n\nNot a good prediction, stationality should not be the reason, and the d parameter in the ARIMA should be able to remove it. We can conclude that the data is not exhibiting enough pattern for the model to pick up. "}}