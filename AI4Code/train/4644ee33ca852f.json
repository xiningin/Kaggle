{"cell_type":{"d2d5b8bc":"code","360315a1":"code","fffdf8ca":"code","f7c6d5a8":"code","258359e4":"code","1cab8a81":"code","b08b11ac":"code","9c27980f":"code","6e6a017f":"code","c5800b88":"code","62a0cec2":"code","8b3ab12f":"code","18db9019":"code","1602760b":"code","08a7d1e1":"code","27e4b424":"code","7afce498":"code","26c7a40a":"code","a5255994":"code","c82855eb":"code","f78001d4":"code","c65f8b60":"code","7e7cc510":"code","1144d4dc":"code","a08d5900":"code","5b2a0050":"code","14b15267":"code","1563b0bb":"markdown","a96f1a27":"markdown","db7d9e4e":"markdown","793fc878":"markdown","b0b87835":"markdown","e488e042":"markdown","d90f798c":"markdown","d4ff626f":"markdown","afd0e194":"markdown","86d623f9":"markdown","df92a778":"markdown","46af85d7":"markdown","21322573":"markdown","301fb954":"markdown","96014cb1":"markdown","a8fa3e2c":"markdown","a2ae4fc7":"markdown","7dc3bf42":"markdown","9491b72b":"markdown","d9b125e5":"markdown","9e6fae99":"markdown"},"source":{"d2d5b8bc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","360315a1":"import tensorflow as tf\nfrom tensorflow import keras \nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation , Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\nfrom tensorflow.keras.layers.experimental.preprocessing import Rescaling\nfrom tensorflow.keras.optimizers import Adam \nfrom tensorflow.keras.metrics import categorical_crossentropy \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix, plot_roc_curve,accuracy_score, roc_curve,roc_auc_score\nimport itertools \nimport shutil\nimport random\nimport glob\nimport matplotlib.pyplot as plt\nimport seaborn as sns","fffdf8ca":"graphics=tf.config.experimental.list_physical_devices('GPU')\nprint(\"GPU's Available: \", len(graphics))","f7c6d5a8":"training_path = '\/kaggle\/input\/fer2013\/train'\ntest_path = '\/kaggle\/input\/fer2013\/test'\ncategories = ('angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise')\ncount = 0\nprint('Count of Image Files for Each Training Category')\nprint('-----------------------------------------------')\nfor e in categories:\n    files = os.listdir(training_path + '\/' + e)\n    for f in files:\n        count+=1\n    print(e + ' : ' , count)\n    count=0\n","258359e4":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  training_path,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  image_size=(48,48),\n  batch_size=30)\n","1cab8a81":"validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  training_path,\n  validation_split=0.2,\n  subset=\"validation\",\n  seed=123,\n  image_size=(48,48),\n  batch_size=30)","b08b11ac":"plt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(categories[labels[i]])\n    plt.axis(\"off\")\n","9c27980f":"model = Sequential()\nmodel.add(Rescaling(1.\/255)),\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(7))\n\n","6e6a017f":"model_2 = Sequential()\nmodel_2.add(Rescaling(1.\/255)),\nmodel_2.add(Conv2D(32, (3, 3), activation='softmax', input_shape=(48, 48, 1)))\nmodel_2.add(MaxPool2D((2, 2)))\nmodel_2.add(Conv2D(64, (3, 3), activation='softmax'))\nmodel_2.add(MaxPool2D((2, 2)))\nmodel_2.add(Conv2D(64, (3, 3), activation='softmax'))\nmodel_2.add(Flatten())\nmodel_2.add(Dense(64, activation='softmax'))\nmodel_2.add(Dense(64, activation='softmax'))\nmodel_2.add(Dense(64, activation='softmax'))\nmodel_2.add(Dense(7))","c5800b88":"model.compile(\n  optimizer='adam',\n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])\n","62a0cec2":"model_2.compile(\n  optimizer='adam',\n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])","8b3ab12f":"\nhistory_log = model.fit(train_ds, validation_data=validation_ds,epochs=50)\n","18db9019":"history_log_2 = model_2.fit(train_ds, validation_data=validation_ds,epochs=10)","1602760b":"test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  test_path,\n  image_size=(48,48),\n  batch_size=30)\n  \n","08a7d1e1":"pred=model.predict(test_ds)","27e4b424":"pred","7afce498":"print(len(pred))","26c7a40a":"print(pred.shape)\n\npred_max=[]\nfor p in pred:\n    \n    position=list(p).index(max(p))\n    pred_max.append(position)\nprint(pred_max)\n","a5255994":"print(len(pred_max))","c82855eb":"test_labels=[]\nfor e in categories:\n    files = os.listdir(test_path + '\/' + e)\n    for f in files:\n        if e ==\"angry\":\n            test_labels.append(0)\n        elif e==\"disgust\":\n            test_labels.append(1)\n        elif e==\"fear\":\n            test_labels.append(2)\n        elif e==\"happy\":\n            test_labels.append(3)\n        elif e==\"neutral\":\n            test_labels.append(4)\n        elif e==\"sad\":\n            test_labels.append(5)\n        elif e==\"surprise\":\n            test_labels.append(6)\n                            \n            \n        #test_labels.append(e)\nprint(test_labels)","f78001d4":"test_results=pd.DataFrame(columns=[\"Prediction\",\"Labels\"])\ntest_results[\"Prediction\"]=pred_max\ntest_results[\"Labels\"]=test_labels\n","c65f8b60":"test_results\ntest_results.to_csv(\"results.csv\")","7e7cc510":" print(history_log.history.keys())","1144d4dc":"plt.plot(history_log.history['accuracy'])\nplt.plot(history_log.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","a08d5900":"plt.plot(history_log_2.history['accuracy'])\nplt.plot(history_log_2.history['val_accuracy'])\nplt.title('Model 2 Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","5b2a0050":"plt.plot(history_log.history['loss'])\nplt.plot(history_log.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","14b15267":"plt.plot(history_log_2.history['loss'])\nplt.plot(history_log_2.history['val_loss'])\nplt.title('Model 2 Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","1563b0bb":"This code section converts all of the prediction weights for each emotion into one choice represented by the highest weighted emotion. The max of the 7 weighted scores is found and the index returned. The index will correspond to the dictionary correlating a number to emotion string value. ","a96f1a27":"Compiling the model. This is telling the model how to gauge improvement for epoch run in order to have a metric to base results against. ","db7d9e4e":"Running the predict function on the test data set which has not been seen by the model. The model was trained on a different dataset. Running the prediction on an unseen dataset ensure the integrity of the model by measuring against unseen data. There is potential for overfitting during the model training which would not be caught otherwise. ","793fc878":"Second model to see how changes to the architecture affect the accuracy. ","b0b87835":"print(test_labels)","e488e042":"Showing the predictions as they are returned by **Model.Predict**. There is a row for each prediction result with 7 items in each row. These 7 items indicate the confidence score weight for each emotion category. The emotion category with the highest weight represent the ML algorithm prediction. (IE, most likely emotion representing that image) ","d90f798c":"Next two sections create the training and validation dataset batches which will be used to train the model. The validation split is used so that the model is not validated against the same data it is being trained with. Without creating this split and validating against unseen images the model could become overfit. Overfitting would produce high accuracy for the training but would perform poorly on unseen data for production. ","d4ff626f":"Creating test dataset batch","afd0e194":"Saving the dataframe to file","86d623f9":"training the model using the training dataset created and the validation dataset created. This will run for 50 epochs which essentially runs data through 50 times with each epoch building on the prior ones weights so that continous improvement of accuracy is achieved. There will be a tradeoff between the time it takes to run a certain number of epochs and the performance gained. There will also be a point where improvement is not made.  ","df92a778":"To determine if gains are being made the scores prefixed with \"Val\" should be used. This is how well the model is predicting against unseen data residing in the validation set. If val_loss is increasing or Val_accuracy is not increasing then the model is not learning despite any performance gains that might be gained in the training accuracy metric. Based on this the epochs run will need modified. Or, if performance is not desirable, the architecture will of the model will need modified. It's also possible the data will need additional prepping. \n\nUsing a variable to hold the history dictionary that is returned by the fit function epochs is useful for plotting metrics, comparing different models, and evalauating performance over epochs. ","46af85d7":"Saving the results of the predictions and corresponding labels into a pandas dataframe for easier use. ","21322573":"Building out a model with standard CNN architecture. Some important features are:\n* Scaling - this is to normalize the values between 0 and 1. 255 is used because the dataset is grayscale. \n* Flatten- this takes a 3d image and converts to 1 d\n* The last layer must have the same number of nodes as the categories being predicted. In this case it is 7. ","301fb954":"Showing a random selection of images from the dataset to showcase what the images look like ","96014cb1":"Iterating through the training directories to count the number of images in each emotion category. ","a8fa3e2c":"Ensuring that number of rows match after this data conversion","a2ae4fc7":"Code is used to list out GPU's available. This is useful if targeting GPU on personal machine and wanting to validate the proper TensorFlow setup is in place to utilize GPU. ","7dc3bf42":"only 10 epochs for this model because the peformance was terrible. Cancled the first run and ran again with this limited set of epochs to show the peformance and lack of learning. ","9491b72b":"Verifying the number of rows in the prediction set to ensure it matches the number of images feed to the network. this number will also be used after converting these arrays to a prediction to ensure the conversion yielded the same number of rows. ","d9b125e5":"Viewing accuracy for both models over the course of Epoch runs. This plots training scores vs validation scores. ROC (Receiver Operator Curve) would have been a nice added metric. However,with this being a multiclass problem, pairwise operations would need performed. This involves modeling one class as the positive and the rest as the negative. While this would have given some insight into the model, the work to accomplish this task would not be beneficial given the extreme difference in accuracy between these two models making selection of the best performing easy. ","9e6fae99":"Creating a Label List by iterating through all the images in the Test directories. This will be used to verify results of test predictions. \nAfter creating the label list the results are printed out to verify correctness. "}}