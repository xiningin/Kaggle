{"cell_type":{"b803db9a":"code","4611bb74":"code","8bfbbedf":"code","a98ee4a2":"code","5b533ef2":"code","898532db":"code","6e6ae8bc":"code","ebbad1ad":"code","feb35876":"code","461beb6e":"code","2959a56c":"code","5da99e55":"code","e50a1dc9":"code","47148e65":"code","102d1a9f":"code","79e1cef4":"code","aab6d0bb":"code","5f04ad34":"code","5fb3ae6b":"code","18cb77ae":"code","c30871d8":"code","165d5f9b":"code","f4e6a0a1":"code","710d550f":"code","e405dc74":"code","f02637ca":"code","64be12ce":"code","b930c8ab":"code","dfcd147d":"code","d9924f4c":"code","73cdc888":"code","7a5e96ab":"code","40c8c5c6":"code","3a6b8f0d":"code","1d552e1b":"code","20b72c06":"code","ab2f6e9b":"code","719f884c":"code","8d5f6ba1":"code","b920ed89":"markdown","ab0b87af":"markdown","766681b4":"markdown","73d8be33":"markdown","9247532c":"markdown","a6612e1a":"markdown","f525b23f":"markdown","a40a6ae9":"markdown","6d6044f9":"markdown","7d35b10e":"markdown","13007897":"markdown"},"source":{"b803db9a":"!pip install fastai==0.7.0","4611bb74":"%load_ext autoreload\n%autoreload 2\n%matplotlib inline","8bfbbedf":"from fastai.imports import *\nfrom fastai.structured import *\nfrom pandas_summary import DataFrameSummary\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn import metrics\nfrom IPython.display import display","a98ee4a2":"PATH = '..\/input\/'","5b533ef2":"df_raw = pd.read_csv(PATH + 'train.csv',low_memory=False)","898532db":"df_test = pd.read_csv(PATH + 'test.csv',low_memory=False)","6e6ae8bc":"df_raw.head(5)","ebbad1ad":"df_raw.describe()","feb35876":"#check the missing value\ndf_raw.isnull().values.any()","461beb6e":"df_trn, y_trn, nas = proc_df(df_raw, 'target')","2959a56c":"def split_vals(a,n): return a[:n], a[n:]\nn_valid = 30\nn_trn = len(df_trn)-n_valid\nX_train, X_valid = split_vals(df_trn, n_trn)\ny_train, y_valid = split_vals(y_trn, n_trn)\nraw_train, raw_valid = split_vals(df_raw, n_trn)","5da99e55":"from sklearn.metrics import roc_auc_score\n\ndef auc(x,y): return roc_auc_score(x, y)#x - y_true, y = y_score\n\ndef print_score(m):\n    res = [auc(y_train, m.predict(X_train)), auc(y_valid, m.predict(X_valid)),\n                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n    print(res)","e50a1dc9":"#This is definately overfitting\nm = RandomForestRegressor(n_estimators=1000, min_samples_leaf=5, max_features=0.5, n_jobs=-1, oob_score=True)\nm.fit(X_train, y_train)\nprint_score(m)","47148e65":"#a better fit\nm = RandomForestRegressor(n_estimators=1000, min_samples_leaf=25, max_features=0.6, n_jobs=-1, oob_score=True)\nm.fit(X_train, y_train)\nprint_score(m)","102d1a9f":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(m, df_trn, y_trn, cv=5, scoring='roc_auc')\nscores","79e1cef4":"fi = rf_feat_importance(m, df_trn);","aab6d0bb":"#top 30 features are\nfi[:30]","5f04ad34":"fi.plot('cols', 'imp', figsize=(10,6), legend=False);","5fb3ae6b":"def plot_fi(fi): return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)","18cb77ae":"plot_fi(fi[:30]);","c30871d8":"to_keep = fi[fi.imp>0.005].cols; \nlen_tokeep = len(to_keep)","165d5f9b":"df_keep = df_trn[to_keep].copy()\nX_train, X_valid = split_vals(df_keep, 250)","f4e6a0a1":"X_train.shape","710d550f":"m = RandomForestRegressor(n_estimators=100, min_samples_leaf=25, max_features=0.5, n_jobs=-1, oob_score=True)\nscores = cross_val_score(m, X_train, y_trn, cv=5, scoring='roc_auc')\nscores","e405dc74":"m.fit(X_train, y_trn)","f02637ca":"df_keep = df_test[to_keep].copy()","64be12ce":"df_keep.shape","b930c8ab":"y_preds = m.predict(df_keep)","dfcd147d":"y_preds","d9924f4c":"submission_rf = pd.read_csv(PATH + 'sample_submission.csv')","73cdc888":"submission_rf['target'] = y_preds","7a5e96ab":"submission_rf.to_csv('submission_0.005.csv', index=False)","40c8c5c6":"to_keep = fi[fi.imp>0.001].cols; \nlen(to_keep)","3a6b8f0d":"df_keep = df_trn[to_keep].copy()\nX_train, X_valid = split_vals(df_keep, 250)","1d552e1b":"m = RandomForestRegressor(n_estimators=100, min_samples_leaf=25, max_features=0.5, n_jobs=-1, oob_score=True)\nscores = cross_val_score(m, X_train, y_trn, cv=5, scoring='roc_auc')\nscores","20b72c06":"m.fit(X_train, y_trn)\ndf_keep = df_test[to_keep].copy()\ny_preds = m.predict(df_keep)\nsubmission_rf['target'] = y_preds\nsubmission_rf.to_csv('submission_0.001.csv', index=False)","ab2f6e9b":"to_keep = fi[fi.imp>0.005].cols; \ndf_keep = df_trn[to_keep].copy()\nlen_tokeep = len(to_keep)","719f884c":"from scipy.cluster import hierarchy as hc","8d5f6ba1":"corr = np.round(scipy.stats.spearmanr(df_keep).correlation, 4)\ncorr_condensed = hc.distance.squareform(1-corr)\nz = hc.linkage(corr_condensed, method='average')\nfig = plt.figure(figsize=(16,10))\ndendrogram = hc.dendrogram(z, labels=df_keep.columns, orientation='left', leaf_font_size=16)\nplt.show()","b920ed89":"\n### Now let's try with feature importance > 0.001","ab0b87af":"Here we can see that we are getting 87.5 AUC on whole set using crossval\n### Now let's try out prediction on this","766681b4":"Let's try cross validation","73d8be33":"So we are getting 80% AUC on crossval, let's try feature importance and then check cross val again\n## Feature importance\n","9247532c":"There are no missing values and also we have checked the mean and Standard Deviation of Target Column\n\nNow let's use proc_df function which will handle categorical data and convert into numeric data\n\nNote - There are no categorical data and no missing values so even if we dont do proc_df then it won't matter at all. Here proc df will just split the data into into X and Y(Predictor and Target)","a6612e1a":"We can clearly see that there are no features which are highly correlated with other, so don;t remove anything","f525b23f":"## Let's try removing redundant features","a40a6ae9":"## FastAi Approach \nThis notebook will guide you through FastAI approach.\n\nWe'll use RandomForest to  find out feature important and find Partial dependence. Also we'll plot the correlation between variables.\n\n### Imports","6d6044f9":"We'll keep all those varialbes which are above \n* 0.001\n* 0.005","7d35b10e":"## Thank you\n\nPlease upvote the kernel if you liked it\n\nConnect with me on - https:\/\/www.linkedin.com\/in\/savannahar\/\n\nShare important tips \/ links \/ resouces in comment section because sharing is caring.","13007897":"### We can see that  features between 0.001-0.005 are not giving great accuracy"}}