{"cell_type":{"c749ab9e":"code","049b7af8":"code","1a30435e":"code","aeef8b78":"code","28ad46df":"code","2225488c":"code","0037e18b":"code","2c43e85b":"code","c6e75d40":"code","3c93f013":"code","a2f121ce":"code","a2c4a892":"code","0d9f883d":"code","fd93cf88":"code","bd8cc856":"code","fb422848":"markdown","4ad80c53":"markdown","0e6a5044":"markdown","2f73dfb8":"markdown","e909852a":"markdown","f7151eec":"markdown","a0014b1a":"markdown","2c670dc9":"markdown","6c919dfe":"markdown","ba6eb0c7":"markdown","c7786d11":"markdown","6513c0d6":"markdown","05e3576b":"markdown","91535378":"markdown","c3d232eb":"markdown","f4bfc0bd":"markdown"},"source":{"c749ab9e":"%matplotlib inline\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom random import randrange\nfrom shutil import copytree, move, rmtree","049b7af8":"INPUT_DATA_DIR = '..\/input\/cell_images\/cell_images'\nROOT_DATA_DIR = '..\/cell_images'\ncopytree(INPUT_DATA_DIR, ROOT_DATA_DIR)","1a30435e":"INF_DIR = os.path.join(ROOT_DATA_DIR, 'Parasitized')\nUNINF_DIR = os.path.join(ROOT_DATA_DIR, 'Uninfected')\n\ninf_fnames = os.listdir(INF_DIR)\nuninf_fnames = os.listdir(UNINF_DIR)\n\nprint(f'Amount of parasitized images: {len(inf_fnames)}')\nprint(f'Amount of uninfected images: {len(uninf_fnames)}')\nprint(f'Total Images: {len(inf_fnames) + len(uninf_fnames)}')","aeef8b78":"nrows, ncols = 4, 4\nfig_size = 3 \n\nfig = plt.gcf()\nfig.set_size_inches(ncols * fig_size, nrows * fig_size)\n\ninf_pic_paths = [os.path.join(INF_DIR, inf_fnames[randrange(len(inf_fnames))]) \n                for _ in range(4) \n                ]\n\nuninf_pic_paths = [os.path.join(UNINF_DIR, uninf_fnames[randrange(len(uninf_fnames))]) \n                for _ in range(4) \n                ]\n\nfor i, img_path in enumerate(inf_pic_paths + uninf_pic_paths):  \n    sp = plt.subplot(nrows, ncols, i + 1)\n    sp.axis('Off') # Don't show axes (or gridlines)\n\n    img = mpimg.imread(img_path)\n    plt.imshow(img)\n\nplt.show()","28ad46df":"def split_data(sourse, split_size):\n    #Create root folder for valid&test data\n    root_folder_name = ROOT_DATA_DIR.strip('\/').split('\/')[-1]\n    valid_test_folder = ROOT_DATA_DIR.replace(root_folder_name,\n                                            'valid_test_' + root_folder_name)\n    try:\n        os.mkdir(valid_test_folder)\n    except:\n        pass\n    \n    folders = os.listdir(sourse)\n    for folder in folders:\n        try:\n            os.mkdir(os.path.join(valid_test_folder, folder))\n        except:\n            pass\n        fnames = os.listdir(os.path.join(sourse, folder))\n        start_split = len(fnames) - int(len(fnames) * split_size)\n        splited_fnames = fnames[start_split:]\n        for fname in splited_fnames:\n            s_dir = os.path.join(sourse, folder, fname)\n            d_dir = os.path.join(valid_test_folder, folder, fname)\n            move(s_dir, d_dir)\n        print(f'Moved {len(splited_fnames)} files')\n","2225488c":"split_data(ROOT_DATA_DIR, 0.2)","0037e18b":"img_size = 64\ndim = img_size, img_size\n\nimg_path = os.path.join(INF_DIR, inf_fnames[0])\nimg = cv2.imread(img_path)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nimg = cv2.resize(img, dim)\n\nplt.imshow(img)\nplt.show()","2c43e85b":"train_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        rotation_range=45,\n        shear_range=0.2,\n        vertical_flip=True,\n        horizontal_flip=True,\n        )\n\ntrain_generator = train_datagen.flow_from_directory(\n        '..\/cell_images',  \n        target_size=dim, \n        batch_size=32,\n        class_mode='binary',\n        )","c6e75d40":"valid_test_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        validation_split=0.5\n        )\n\nvalid_generator = valid_test_datagen.flow_from_directory(\n        '..\/valid_test_cell_images',  \n        target_size=dim, \n        batch_size=32,\n        class_mode='binary',\n        subset='training',\n        )\n\ntest_generator = valid_test_datagen.flow_from_directory(\n        '..\/valid_test_cell_images',  \n        target_size=dim, \n        batch_size=32,\n        class_mode='binary',\n        subset='validation',\n        )","3c93f013":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', padding='same', input_shape=(64, 64, 3)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    \n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    \n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    \n    tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(2, 2), \n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.5),\n    \n    tf.keras.layers.Dense(1024, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.5),\n    \n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.5),\n    \n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['acc'])","a2f121ce":"model.summary()","a2c4a892":"history = model.fit_generator(\n        train_generator,\n        epochs=20,\n        validation_data=valid_generator,\n        )","0d9f883d":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","fd93cf88":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","bd8cc856":"model.evaluate_generator(test_generator, verbose=1)","fb422848":"Define the matplotlib figure and plot 4 Parasitized and 4 Uninfected images.\n\nHere I use randrange for selecting a random image index. Rerun the cell for ploting different image.","4ad80c53":"Plot our accuracy and loss for understanding problems: \"high bias\" and \"high variance\".","0e6a5044":"### **What we need to solve the problem:**\n* Initial step\n    * git init\n    * import libraries\n    * etc\n* Data processing\n    * Plotting random images\n    * Split data\n    * Define resizing if it needed\n* Build the model\n    * Build a network\n    * Run it\n    * Plot acc and loss\n    * Repeat\n* Evaluate on test data","2f73dfb8":"### **Initial step**\nBasic initial step, import required libraries, etc\n\n*   os - for handling paths\n*   cv2 - best lib for image processing\n*   matplotlib - plot images and results\n*   zipfile - obviously work with zip archives\n*   tensorflow - self-explanatory\n*   randrange - we will use for selecting random images\n*   shutil - for copying\/moving images to a different folder\n","e909852a":"Let's define the paths of data and explore how many images we have.","f7151eec":"Call the function.\n\n*hint. If you want plot images after splitting you will need to redefine file names. Just rerun the cell above the plot.*","a0014b1a":"Define the function that will split the data.\n\nIt's pretty simple. \n\nDefining names \/ create folder \/ moving images.","2c670dc9":"After ~50 epochs acc will be > 97%","6c919dfe":"Our data set contain images with 150 by 150 pixels.\n\nI found that for this problem we don't need such resolution so I decide to resize the image.\n\nTo find out how it will look I use cv2 for resizing and plot the image.","ba6eb0c7":"### Build the model\nDefine the model.\n\nThis is our playground. Add and delete layers, try to find a perfect solution.","c7786d11":"Explore our model.","6513c0d6":"Finally lets train the model.\n\nI don't define steps_per_epoch since according to official documentation when we use the sequential model we don't need to do this.\n\nLts's try 50 epoch.","05e3576b":"### Data processing\nSince the \"input\" folder is read-only we need to copy files for future manipulation.\nThis workbook allows just copy from zipping without unzipping operation.","91535378":"Now I define validation and test generator.\n\nI use build in functionality for splitting one folder into two sets.\n\nSinge validation and test set should be from one distribution. This is a perfect solution.","c3d232eb":"### Evaluate on test data\nAfter finishing playing with model and we are happy with achieved accuracy.\n\nEvaluate your model on the test set.","f4bfc0bd":"After splitting we have 2 folders. One contains a training set and another for validation and test sets.\n\nLet's define training generator and add some image augmentation."}}