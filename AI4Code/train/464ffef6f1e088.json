{"cell_type":{"f0ae9a01":"code","71762c53":"code","b1c3c6eb":"code","3cf2d9d2":"code","c0b26e27":"code","726ed875":"code","5300663e":"code","9f0bb1f5":"code","ca540404":"code","b6687f24":"code","4ec28655":"code","7ee3da06":"code","e32c0966":"code","46aab077":"code","2b598c1d":"code","80388591":"markdown","15fa3e0e":"markdown","9d27c0d4":"markdown","9c23604f":"markdown","30e7266a":"markdown","54f42a7b":"markdown","c898233f":"markdown","dcdd3fdb":"markdown","c2ba56b5":"markdown","eed7866b":"markdown","a37e854c":"markdown","9bbc9553":"markdown"},"source":{"f0ae9a01":"import numpy as np \nimport pandas as pd \nimport os\n\nprint(os.listdir(\"\/kaggle\/input\/repository\/savannahar68-DataAugmentation-dce458d\/\"))\nPATH = \"\/kaggle\/input\/repository\/savannahar68-DataAugmentation-dce458d\/\"\n","71762c53":"df = pd.read_csv(PATH + 'dataAug.csv')\ndf.head(5)","b1c3c6eb":"df = df.drop(df.columns[0], axis=1)","3cf2d9d2":"df.shape","c0b26e27":"import numpy as np, os, cv2\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\nfrom PIL import Image\n%matplotlib inline","726ed875":"df.values","5300663e":"images = df.values\nimg_name = images[0][0]\nx1 = images[0][1]\nx2 = images[0][2]\ny1 = images[0][3]\ny2 = images[0][4]","9f0bb1f5":"plt.imshow(Image.open(PATH + 'images\/' + img_name))\nplt.gca().add_patch(Rectangle((x1,y1),x2-x1,y2-y1,linewidth=1,edgecolor='r',facecolor='none'))","ca540404":"x11 = 640 - x1\nx22 = 640 - x2\ny11 = y1\ny22 = y2\nplt.imshow(cv2.flip(cv2.imread(PATH + \"images\/\"+ img_name),1))\nplt.gca().add_patch(Rectangle((x11,y11),x22-x11,y22-y11,linewidth=1,edgecolor='r',facecolor='none'))","b6687f24":"x11 = x1\nx22 = x2\ny11 = 480 - y1\ny22 = 480 - y2\nplt.imshow(cv2.flip(cv2.imread(PATH + \"images\/\"+ img_name),0))\nplt.gca().add_patch(Rectangle((x11,y11),x22-x11,y22-y11,linewidth=1,edgecolor='r',facecolor='none'))","4ec28655":"x11 = 640 - x1\nx22 = 640 - x2\ny11 = 480 - y1\ny22 = 480 - y2\nplt.imshow(cv2.flip(cv2.imread(PATH + \"images\/\"+ img_name),-1))\nplt.gca().add_patch(Rectangle((x11,y11),x22-x11,y22-y11,linewidth=1,edgecolor='r',facecolor='none'))","7ee3da06":"for i,img in enumerate(df.values):\n    x1 = img[1]\n    x2 = img[2]\n    y1 = img[3]\n    y2 = img[4]\n    \n    df = df.append({'image_name':img[0].split('.')[0]+'H_FLIP.png', 'x1':640-x1, 'x2':640-x2, 'y1':y1, 'y2':y2}, ignore_index=True)\n    cv2.imwrite(PATH + \"images\/\" + img[0].split('.')[0]+'H_FLIP.png', cv2.flip(cv2.imread(PATH+\"images\/\"+img[0]),1))\n    \n    df = df.append({'image_name':img[0].split('.')[0]+'V_FLIP.png', 'x1':x1, 'x2':x2, 'y1':480-y1, 'y2':480-y2}, ignore_index=True)\n    cv2.imwrite(PATH + \"images\/\"+img[0].split('.')[0]+'V_FLIP.png', cv2.flip(cv2.imread(PATH+\"images\/\"+img[0]),0)) \n    \n    df = df.append({'image_name':img[0].split('.')[0]+'H_FLIPV_FLIP.png', 'x1':640-x1, 'x2':640-x2, 'y1':480-y1, 'y2':480-y2}, ignore_index=True)\n    cv2.imwrite(PATH + \"images\/\"+img[0].split('.')[0]+'H_FLIPV_FLIP.png', cv2.flip(cv2.imread(PATH+\"images\/\"+img[0].split('.')[0]+'H_FLIP.png'),0))\n   ","e32c0966":"df.shape","46aab077":"df.head(20) #This we have successfully augmented the data for bouding box prediction","2b598c1d":"for i,img in enumerate(df.values):\n    bx = img[1]\n    by = img[2]\n    bh = img[3]\n    bw = img[4]\n    \n    df = df.append({'image_name':img[0].split('.')[0]+'H_FLIP.png', 'bx':640 - bx, 'by':by, 'bh':bh, 'bw':bw}, ignore_index=True)\n    cv2.imwrite(PATH + \"images\/\" + img[0].split('.')[0]+'H_FLIP.png', cv2.flip(cv2.imread(PATH+\"images\/\"+img[0]),1))\n    \n    df = df.append({'image_name':img[0].split('.')[0]+'V_FLIP.png', 'bx':bx, 'by':480 - by, 'bh':bh, 'bw':bw}, ignore_index=True)\n    cv2.imwrite(PATH + \"images\/\"+img[0].split('.')[0]+'V_FLIP.png', cv2.flip(cv2.imread(PATH+\"images\/\"+img[0]),0)) \n    \n    df = df.append({'image_name':img[0].split('.')[0]+'H_FLIPV_FLIP.png', 'bx':640 - bx, 'by':640-by, 'bh':bh, 'bw':bw}, ignore_index=True)\n    cv2.imwrite(PATH + \"images\/\"+img[0].split('.')[0]+'H_FLIPV_FLIP.png', cv2.flip(cv2.imread(PATH+\"images\/\"+img[0].split('.')[0]+'H_FLIP.png'),0))\n   ","80388591":"## Displaying orignal image\n","15fa3e0e":"## If the dataset has bx,by,bh,bw as coordinates then\n\n### For H_flip change bx to \n   bx = image_width - bx\n   \n   rest all the coordinated remain same\n   \n### For V_flip change by to \n   by = image_height - by\n   \n   rest all the coordinated remain same\n\n### For H_flip_V_flip change bx,by to \n   bx = image_width - bx\n   \n   by = image_height - by\n   \n   rest all the coordinated remain same(bw,bh)\n  \n  The below code satisfies the purpose","9d27c0d4":"## Reading the Input","9c23604f":"## Vertical Flip\nIf you are given x1,y1,x2,y2 as coordinates and you have to v_flip the image then the coordinates of the new image changes to \n\nChange the **y1** and **y2** to following \n- y1 = image_height - y1\n- y2 = image_height - y2\n\nKeep **x1**,**x2** same\n\nTo **v_flip** the image pass argument **0** to cv2.flip function of Opencv\n\nHere we have image shape as (640,480,3) so image_height = 480","30e7266a":"## Horizontal Flip\nIf you are given x1,y1,x2,y2 as coordinates and you have to h_flip the image then the coordinates of the new image changes to \n\nChange the **x1** and **x2** to following \n- x1 = image_width - x1\n- x2 = image_width - x2\n\nKeep **y1**,**y2** same\n\nTo **h_flip** the image pass argument **1** to cv2.flip function of Opencv\n\nHere we have image shape as (640,480,3) so image_width = 640","54f42a7b":"**Now let's combine the above techniques and cerate the images and also append the generated images to the dataframe.","c898233f":"## Data Augmentation for Object Localization \nIn this kernel i'm going to augment data for the task of object localization that is Bouding Box prediction(Only).\nInput is in the following form\n\n> Image_name, x1, y1, x2, y2\n\n**Note** ; Same augmentation techniques can be used if the data is in the form of bx,by,bh,bw\n\nWhere x1, y1 are the top left cornor coordinates of bouding box and x2,y2 are bottom right cornor coordinate of bounding box.\n\n### Data Augmentation Techniques\n1. Horizontal Flip\n2. Vertical Flip\n3. Horizontal and Vertical Flip (Combined)\n\nAs we are specifically doing object localization so other Data Augmentation techniques like Random Crop, transforms, Angle change cannot be applied here.","dcdd3fdb":"Earlier we had 5 images in our dataset, now we have 5 + 5*3 types of augmentation images in out dataset\n\n","c2ba56b5":"Here the Rectangle function expect input in the form of x1,y1,width,height\n\nSo width can be removed using x2-x1 \n\nand Height by y2-y1","eed7866b":"## Horizontal Vertical Flip\nIf you are given x1,y1,x2,y2 as coordinates and you have to h_flip_v_flip the image then the coordinates of the new image changes to \n\nChange the **x1** ,**x2** , **y1** , **y2** to following \n- x1 = image_width - x1\n- x2 = image_width - x2\n- y1 = image_height - y1\n- y2 = image_height - y2\n\nTo **h_flip_v_flip** the image pass argument **-1** to cv2.flip function of Opencv\n\nHere we have image shape as (640,480,3) so image_width = 640 and  image_height = 480","a37e854c":"## Importing libraries for visualizing images","9bbc9553":"### Thank you\nConnect with me on linkedin - https:\/\/www.linkedin.com\/in\/savannahar\/"}}