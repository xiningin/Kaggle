{"cell_type":{"f3cd0fdb":"code","d58e1f06":"code","3c1103b3":"code","7aec3f5d":"code","9b793b30":"code","e28f4885":"code","1b4716f4":"code","8112dfd3":"code","b74c3f52":"code","17c8e1d2":"code","1cff0598":"code","8cf2da28":"code","54930cd0":"code","b4e12e95":"code","68cdc004":"code","096b5f42":"code","de2119b3":"code","e8b4164d":"code","eaef3600":"code","0e7bd689":"code","6605f1ed":"code","5824da45":"code","45f725e3":"code","015ee0fe":"code","12ce9126":"code","9d7c6d41":"code","62dad3bf":"code","5a046c92":"code","01990c01":"code","259e676a":"code","4bc52768":"code","1baf37f2":"code","0c7cc5db":"code","06e0d6ea":"code","156adfa9":"code","55509b6c":"code","8c2c8fc4":"code","5f0a8594":"code","59ad2b5e":"code","9cba2360":"code","5766b764":"code","3bb1a9d8":"code","49552214":"code","3186af19":"code","02a86099":"code","3fbfd6e7":"code","0540b843":"code","ca8b6b2d":"code","2a996a31":"code","22d7545d":"code","b14a622b":"code","8a7fe172":"code","d0377e35":"code","5c3e3083":"code","7494df3a":"code","b93d1199":"code","f795cf26":"code","e4c2bc38":"code","efad0bb9":"code","c9503c5e":"code","03b79ab9":"code","4a829add":"code","f4b69cff":"code","c053c389":"code","078d8f57":"code","804e8f11":"code","0d125fa8":"code","4e61c48e":"code","cdf35bb7":"code","adbdf965":"code","f01aa8e5":"code","74cf77b3":"code","0c23992e":"code","a4f8429c":"code","cec913e9":"code","5b6ac166":"code","4e19e948":"code","a8d353f8":"code","ad4dabbd":"code","500a1900":"code","fa53e718":"code","0298baa9":"code","41348023":"code","2d5eff67":"code","24009ef6":"code","30ed5cd4":"code","b17877e7":"code","0ece2b8a":"code","44eeedf4":"code","ac007783":"code","0676a748":"code","05de5fe0":"code","a1b4b10e":"code","e96c4d97":"code","81c85238":"code","ccd5876c":"code","7d94fdbd":"code","e6f118fb":"code","0e598e89":"code","25503842":"code","e0d992ec":"code","b22729d9":"code","b398092a":"markdown","aaf98a95":"markdown","e425b84c":"markdown","eeb0c398":"markdown","e17501ae":"markdown","6c1d0e79":"markdown","07cdc798":"markdown","a64e7775":"markdown","74f07033":"markdown","c4a96b4b":"markdown","8c458243":"markdown","b2753743":"markdown","e8297649":"markdown","0465f4d2":"markdown","fb94eca5":"markdown","b95f667c":"markdown","5257d05d":"markdown","0d4d43ea":"markdown","edee3422":"markdown","cc7bbe51":"markdown","dda64c98":"markdown","f2ff92ce":"markdown","7029249b":"markdown","17d9da0f":"markdown","4d6aba23":"markdown","bde4f4db":"markdown","aa5b18aa":"markdown","d465aca0":"markdown","f59eb3d4":"markdown","02618fed":"markdown","8f576724":"markdown","52cda959":"markdown","edf9c6fb":"markdown","306062ad":"markdown","7dd24018":"markdown","8fe47904":"markdown","69c02b75":"markdown","e3432a58":"markdown","e4e14fab":"markdown","f998b026":"markdown","8a854546":"markdown","cabdb236":"markdown","97d15a86":"markdown","a7e155ac":"markdown","9c8f5ab3":"markdown","db064952":"markdown","e6e29925":"markdown","cb78fb9e":"markdown","d832e2d9":"markdown","fce9d300":"markdown","5b32e183":"markdown","e64959dd":"markdown","e4d8e1d8":"markdown","799b2e9d":"markdown","abfac055":"markdown","dd564587":"markdown","770884b8":"markdown","8271c233":"markdown","2c4da707":"markdown","5c03573c":"markdown","acb0b3b6":"markdown","1c8167f6":"markdown","fbbe8603":"markdown","05b61505":"markdown","fa0918d2":"markdown","1d356b88":"markdown","1aeb8b78":"markdown","d3134d85":"markdown"},"source":{"f3cd0fdb":"!pip install comet_ml","d58e1f06":"from comet_ml import Experiment","3c1103b3":"experiment = Experiment(api_key = 'VWmaCXXdpmeXoNUPZya4tPsmi',\n                       project_name = 'Classification Predict',\n                       workspace = 'menzi-mchunu')","7aec3f5d":"!pip install emoji ","9b793b30":"!pip install demoji","e28f4885":"import time\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport nltk\nimport emoji as emoj\nimport demoji\n\nfrom nltk.stem.porter import *\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import confusion_matrix, recall_score, precision_score, classification_report,accuracy_score, log_loss, make_scorer, f1_score\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\nfrom sklearn.svm import LinearSVC\nfrom nltk.stem import WordNetLemmatizer\nfrom wordcloud import WordCloud\nfrom emoji import UNICODE_EMOJI\nfrom gensim import models\nfrom gensim.models import word2vec\nfrom sklearn.manifold import TSNE\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.utils import resample\nfrom sklearn import metrics\n\ndemoji.download_codes()\nsns.set_style('white')\n%matplotlib inline","1b4716f4":"df_train = pd.read_csv('..\/input\/climate-change-belief-analysis\/train.csv')\ndf_test = pd.read_csv('..\/input\/climate-change-belief-analysis\/test.csv')","8112dfd3":"df_train.head()","b74c3f52":"df_test.head()","17c8e1d2":"print(df_train.shape)\nprint(df_test.shape)","1cff0598":"df_train.info()","8cf2da28":"df_test.info()","54930cd0":"df_train[['message']].describe()","b4e12e95":"df_test[['message']].describe()","68cdc004":"def text_has_emoji(text):\n    \"\"\"This function checks all the rows of data to see if we have any emojis in the tweet \"\"\"\n    for character in text:\n        if character in emoj.UNICODE_EMOJI:\n            return True\n    return False\n\"\"\"We apply the above function to check for emojis\"\"\"\ndf_train['emoji'] = df_train['message'].apply(text_has_emoji)\ndf_test['emoji'] = df_test['message'].apply(text_has_emoji)","096b5f42":"df_train[df_train['emoji'] == True]","de2119b3":"df_test[df_test['emoji'] == True]","e8b4164d":"def extra_all_the_emoji(strings):\n    \"\"\"This function extracts the emojis for every row in the dataframe\"\"\"\n    return ''.join(character for character in strings if character in emoj.UNICODE_EMOJI)","eaef3600":"#We apply the extra_all_the_emoji function to the message column\n\"\"\"We see all the emojis in the train dataframe \"\"\"\ndf_train['emojis'] = df_train['message'].apply(extra_all_the_emoji)\ndf_train[df_train['emojis'] != '']['emojis']","0e7bd689":"\"\"\"We see all the emojis in the train dataframe \"\"\"\ndf_test['emojis'] = df_test['message'].apply(extra_all_the_emoji)\ndf_test[df_test['emojis'] != '']['emojis']","6605f1ed":"#The list of all emojis in the train data\nlist_of_emojis_train = df_train[df_train['emojis'] != '']['emojis'].tolist()","5824da45":"#The list of all emojis in the test data\nlist_of_emojis_test = df_test[df_test['emojis'] != '']['emojis'].tolist()","45f725e3":"#We loop through the whole list to change every emoji to text in the train data\nchanged_emoji_to_text_train = []\nfor emojis in list_of_emojis_train:\n    changed_emoji_to_text_train.append(emoj.demojize(emojis, delimiters=(\"\", \"\")))\nchanged_emoji_to_text_train   ","015ee0fe":"#We loop through the whole list to change every emoji to text in the train data\nchanged_emoji_to_text_test = []\nfor emojis in list_of_emojis_test:\n    changed_emoji_to_text_test.append(emoj.demojize(emojis, delimiters=(\"\", \"\")))\nchanged_emoji_to_text_test","12ce9126":"def emojis_to_text(text):\n    \"\"\"This function changes all the emojis in the message column into words\"\"\"\n    return emoj.demojize(text, delimiters=(\"\", \"\"))\ndf_train['message'] = df_train['message'].apply(emojis_to_text)\ndf_test['message'] = df_test['message'].apply(emojis_to_text)","9d7c6d41":"def remove_twitter_handles(tweet, pattern):\n    \"\"\"This function removes all the twitter handles on the dataframe\"\"\"\n    r = re.findall(pattern, tweet)\n    for text in r:\n        tweet = re.sub(text, '', tweet)\n    return tweet\n\ndf_train['clean_tweet'] = np.vectorize(remove_twitter_handles)(df_train['message'], \"@[\\w]*\") \ndf_test['clean_tweet'] = np.vectorize(remove_twitter_handles)(df_test['message'], \"@[\\w]*\") ","62dad3bf":"df_train.head()","5a046c92":"df_test.head()","01990c01":"# Lower Casing clean_tweet\ndf_train['clean_tweet']  = df_train['clean_tweet'].str.lower()\ndf_train.head()","259e676a":"# Lower Casing clean_tweet\ndf_test['clean_tweet']  = df_test['clean_tweet'].str.lower()\ndf_test.head()","4bc52768":"#Links for train data\ntweets = []\nnew = list(df_train['clean_tweet'])\nfor tweet in new:\n    tweet = re.sub(r\"http\\S+\", '', tweet, flags=re.MULTILINE)\n    tweets.append(tweet)\n    \ndf_train['clean_tweet'] = tweets\n\n#Links for test data\ntest_tweets = []\nnew1 = list(df_test['clean_tweet'])\nfor tweet in new1:\n    tweet = re.sub(r\"http\\S+\", '', tweet, flags=re.MULTILINE)\n    test_tweets.append(tweet)\n    \ndf_test['clean_tweet'] = test_tweets\n\n\n#Retweets for train data\ntweets = []\nnew = list(df_train['clean_tweet'])\nfor tweet in new:\n    tweet = re.sub(\"rt :\", '', tweet, flags=re.MULTILINE)\n    tweets.append(tweet)\n    \ndf_train['clean_tweet'] = tweets\n\n\n#Retweets test data\ntest_tweets = []\nnew1 = list(df_test['clean_tweet'])\nfor tweet in new1:\n    tweet = re.sub(\"rt :\", '', tweet, flags=re.MULTILINE)\n    test_tweets.append(tweet)\n    \ndf_test['clean_tweet'] = test_tweets","1baf37f2":"stop_words = nltk.corpus.stopwords.words('english')","0c7cc5db":"df_train['tidy_tweet'] = df_train['clean_tweet'].apply(lambda x: ' '.join([w for w in x.split() if w not in stop_words]))\ndf_test['tidy_tweet'] = df_test['clean_tweet'].apply(lambda x: ' '.join([w for w in x.split() if w not in stop_words]))","06e0d6ea":"df_train.head()","156adfa9":"df_test.head()","55509b6c":"#Tokenization\ndef tokenizing(text):\n    \"\"\"This Function breaks up text into tokens\"\"\"\n    text = re.split('\\W+', text)\n    return text\n\ndf_train['tokenized_tweet'] = df_train['tidy_tweet'].apply(lambda x: tokenizing(x))\ndf_test['tokenized_tweet'] = df_test['tidy_tweet'].apply(lambda x: tokenizing(x))","8c2c8fc4":"df_train.head()","5f0a8594":"df_test.head()","59ad2b5e":"#Lemmatization\ntokens = df_train['tokenized_tweet']\ntokens_test = df_test['tokenized_tweet']\n\nlemmatizer = WordNetLemmatizer()\n\ntokens = tokens.apply(lambda x: [lemmatizer.lemmatize(i) for i in x])\ntokens_test = tokens_test.apply(lambda x: [lemmatizer.lemmatize(i) for i in x])\n\ndf_train['lemmatized_tweet'] = tokens\ndf_test['lemmatized_tweet'] = tokens_test","9cba2360":"df_train.head()","5766b764":"df_test.head()","3bb1a9d8":"df_train = df_train.drop(['tidy_tweet'],axis=1)\ndf_train = df_train.drop(['tokenized_tweet'], axis=1)\ndf_train = df_train.drop(['emoji'],axis=1)\ndf_train = df_train.drop(['emojis'], axis=1)\n\ndf_test = df_test.drop(['tidy_tweet'],axis=1)\ndf_test = df_test.drop(['tokenized_tweet'], axis=1)\ndf_test = df_test.drop(['emoji'],axis=1)\ndf_test = df_test.drop(['emojis'], axis=1)","49552214":"df_train.head()","3186af19":"df_test.head()","02a86099":"plt.figure(figsize=(10,5))\nsns.countplot(x='sentiment',data=df_train, palette='CMRmap')\nplt.title('Number of Tweets per Class', fontsize=20)\nplt.xlabel('Number of Tweets', fontsize=14)\nplt.ylabel('Class', fontsize=14)\nplt.show()","3fbfd6e7":"#ADD Y LABEL \ndf_train['text length'] = df_train['message'].apply(len)\ng = sns.FacetGrid(df_train,col='sentiment')\ng.map(plt.hist,'text length')\nplt.show()","0540b843":"fig,axis = plt.subplots(figsize=(12,5))\nsns.boxplot(x='sentiment',y='text length',data=df_train, palette='rainbow')\nplt.title('Distribution of Text Length for Different Sentiments', fontsize = 12)\nplt.xlabel('Sentiment', fontsize = 12)\nplt.ylabel('Text Length', fontsize = 12)\nplt.show()","ca8b6b2d":"rate = df_train.groupby('sentiment').mean()\nrate","2a996a31":"rate.corr()","22d7545d":"#ADD TITLE\nplt.figure(figsize=(7,5))\nsns.heatmap(rate.corr(),cmap='coolwarm',annot=True)\nplt.title('Correlation between Tweetid and Text Length', fontsize = 15 )\nplt.show()","b14a622b":"df_pro = df_train[df_train.sentiment==1]\nwords = ' '.join([text for text in df_train['clean_tweet']])\nwordcloud = WordCloud(width = 1000, height = 500).generate(words)\nplt.figure(figsize=(15,5))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.title('Support Belief of Man-Made Climate Change', fontsize = 20)\nplt.show()","8a7fe172":"df_anti = df_train[df_train.sentiment==-1]\ntext= (' '.join(df_anti['clean_tweet']))\nwordcloud = WordCloud(width = 1000, height = 500).generate(text)\nplt.figure(figsize=(15,5))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.title('Against Belief of Man-Made Climate Change', fontsize = 20)\nplt.show()","d0377e35":"df_neutral = df_train[df_train.sentiment==0]\ntext= (' '.join(df_neutral['clean_tweet']))\nwordcloud = WordCloud(width = 1000, height = 500).generate(text)\nplt.figure(figsize=(15,5))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.title('Neutral About Climate Change', fontsize = 30)\nplt.show()","5c3e3083":"df_factual = df_train[df_train.sentiment==2]\ntext= (' '.join(df_factual['clean_tweet']))\nwordcloud = WordCloud(width = 1000, height = 500).generate(text)\nplt.figure(figsize=(15,5))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.title('News About Climate Change', fontsize = 30)\nplt.show()","7494df3a":"pro_hashtags = []\nfor message in df_pro['message']:\n    hashtag = re.findall(r\"#(\\w+)\", message)\n    pro_hashtags.append(hashtag)\n\npro_hashtags = sum(pro_hashtags,[])\na = nltk.FreqDist(pro_hashtags)\nd = pd.DataFrame({'Hashtag': list(a.keys()),\n                  'Count': list(a.values())})\n\n# selecting top 10 most frequent hashtags     \nd = d.nlargest(columns=\"Count\", n = 10) \nplt.figure(figsize=(10,5))\nax = sns.barplot(data=d, x= \"Hashtag\", y = \"Count\")\nplt.setp(ax.get_xticklabels(),rotation='vertical', fontsize=10)\nplt.title('Top 10 Hashtags in \"Pro\" Tweets', fontsize=14)\nplt.show()","b93d1199":"anti_hashtags = []\nfor message in df_anti['message']:\n    hashtag = re.findall(r\"#(\\w+)\", message)\n    anti_hashtags.append(hashtag)\n\nanti_hashtags = sum(anti_hashtags,[])\n\n\na = nltk.FreqDist(anti_hashtags)\nd = pd.DataFrame({'Hashtag': list(a.keys()),\n                  'Count': list(a.values())})\n\n# selecting top 20 most frequent hashtags     \nd = d.nlargest(columns=\"Count\", n = 10) \nplt.figure(figsize=(10,5))\nax = sns.barplot(data=d, x= \"Hashtag\", y = \"Count\")\nplt.setp(ax.get_xticklabels(),rotation='vertical', fontsize=10)\nplt.title('Top 10 Hashtags in \"Anti\" Tweets', fontsize=14)\nplt.show()","f795cf26":"neutral_hashtags = []\nfor message in df_neutral['message']:\n    hashtag = re.findall(r\"#(\\w+)\", message)\n    neutral_hashtags.append(hashtag)\n\nneutral_hashtags = sum(neutral_hashtags,[])\n\n\na = nltk.FreqDist(neutral_hashtags)\nd = pd.DataFrame({'Hashtag': list(a.keys()),\n                  'Count': list(a.values())})\n\n# selecting top 20 most frequent hashtags     \nd = d.nlargest(columns=\"Count\", n = 10) \nplt.figure(figsize=(10,5))\nax = sns.barplot(data=d, x= \"Hashtag\", y = \"Count\")\nplt.setp(ax.get_xticklabels(),rotation='vertical', fontsize=10)\nplt.title('Top 10 Hashtags in Neutral Tweets', fontsize=14)\nplt.show()","e4c2bc38":"factual_hashtags = []\nfor message in df_factual['message']:\n    hashtag = re.findall(r\"#(\\w+)\", message)\n    factual_hashtags.append(hashtag)\n\nfactual_hashtags = sum(factual_hashtags,[])\n\n\na = nltk.FreqDist(factual_hashtags)\nd = pd.DataFrame({'Hashtag': list(a.keys()),\n                  'Count': list(a.values())})\n\n# selecting top 20 most frequent hashtags     \nd = d.nlargest(columns=\"Count\", n = 10) \nplt.figure(figsize=(10,5))\nax = sns.barplot(data=d, x= \"Hashtag\", y = \"Count\")\nplt.setp(ax.get_xticklabels(),rotation='vertical', fontsize=10)\nplt.title('Top 10 Hashtags in Factual Tweets', fontsize=14)\nplt.show()","efad0bb9":"data = df_train.copy()","c9503c5e":"STOP_WORDS = nltk.corpus.stopwords.words()\n\ndef clean_sentence(val):\n    \"remove chars that are not letters or numbers, downcase, then remove stop words\"\n    regex = re.compile('([^\\s\\w]|_)+')\n    sentence = regex.sub('', val).lower()\n    sentence = sentence.split(\" \")\n    \n    for word in list(sentence):\n        if word in STOP_WORDS:\n            sentence.remove(word)  \n            \n    sentence = \" \".join(sentence)\n    return sentence\n\ndef clean_dataframe(data):\n    \"drop nans, then apply 'clean_sentence' function to question1 and 2\"\n    data = data.dropna(how=\"any\")\n    \n    for col in ['message']:\n        data[col] = data[col].apply(clean_sentence)\n    \n    return data\ndata = clean_dataframe(data)\ndata.head(5)","03b79ab9":"def build_corpus(data):\n    \"Creates a list of lists containing words from each sentence\"\n    corpus = []\n    for col in ['message']:\n        for sentence in data[col].iteritems():\n            word_list = sentence[1].split(\" \")\n            corpus.append(word_list)\n            \n    return corpus\n\ncorpus = build_corpus(data)        \ncorpus[0:2]","4a829add":"model = word2vec.Word2Vec(corpus, size=100, window=20, min_count=200, workers=4)\nmodel.wv['warming']","f4b69cff":"def tsne_plot(model):\n    \"Creates and TSNE model and plots it\"\n    labels = []\n    tokens = []\n\n    for word in model.wv.vocab:\n        tokens.append(model[word])\n        labels.append(word)\n    \n    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n    new_values = tsne_model.fit_transform(tokens)\n\n    x = []\n    y = []\n    for value in new_values:\n        x.append(value[0])\n        y.append(value[1])\n        \n    plt.figure(figsize=(13, 7)) \n    for i in range(len(x)):\n        plt.scatter(x[i],y[i])\n        plt.annotate(labels[i],\n                     xy=(x[i], y[i]),\n                     xytext=(5, 2),\n                     textcoords='offset points',\n                     ha='right',\n                     va='bottom')\n    plt.show()","c053c389":"tsne_plot(model)\nplt.show()","078d8f57":"# A more selective model\nmodel = word2vec.Word2Vec(corpus, size=100, window=20, min_count=500, workers=4)\ntsne_plot(model)","804e8f11":"df_train = df_train.drop(['text length'],axis=1)","0d125fa8":"combi = df_train.append(df_test, ignore_index=True)\n\ntfidf_vectorizer = TfidfVectorizer()\ntfidf = tfidf_vectorizer.fit_transform(combi['message'])\n\ntrain = tfidf[:15819,:]\ntest = tfidf[15819:,:]\n\nX_tfidf = train\ny_tfidf = df_train['sentiment']\n\nX_train, X_test, y_train, y_test = train_test_split(X_tfidf, y_tfidf,  random_state=42, test_size=0.1)","4e61c48e":"df = df_train.copy()\n\n# Separate majority and minority classes\ndf_majority = df[df.sentiment==1]\ndf_minority = df[(df.sentiment==-1) | (df.sentiment==0) | (df.sentiment==2)]\n \n# Downsample majority class\ndf_majority_downsampled = resample(df_majority, \n                                 replace=True,    # sample without replacement\n                                 n_samples=7000,     # to match minority class\n                                 random_state=42) # reproducible results\n \n# Combine minority class with downsampled majority class\ndf_downsampled = pd.concat([df_majority_downsampled, df_minority])\n \n# Display new class counts\ndf_downsampled.sentiment.value_counts()","cdf35bb7":"# Separate majority and minority classes\ndf_majority = df_downsampled[(df_downsampled.sentiment==1) | (df_downsampled.sentiment==0) | (df_downsampled.sentiment==2)]\ndf_minority = df_downsampled[df_downsampled.sentiment==-1]\n \n# Upsample minority class\ndf_minority_upsampled = resample(df_minority, \n                                 replace=True,     # sample with replacement\n                                 n_samples=4000,    # to match majority class\n                                 random_state=42) # reproducible results\n \n# Combine majority class with upsampled minority class\ndf_upsampled = pd.concat([df_majority, df_minority_upsampled])\n \n# Display new class counts\ndf_upsampled.sentiment.value_counts()","adbdf965":"# Separate majority and minority classes\ndf_majority = df_upsampled[(df_upsampled.sentiment==1) | (df_upsampled.sentiment==-1) | (df_upsampled.sentiment==2)]\ndf_minority = df_upsampled[df_upsampled.sentiment==0]\n \n# Upsample minority class\ndf_minority_upsampled = resample(df_minority, \n                                 replace=True,     # sample with replacement\n                                 n_samples=4000,    # to match majority class\n                                 random_state=42) # reproducible results\n \n# Combine majority class with upsampled minority class\nup_sampled = pd.concat([df_majority, df_minority_upsampled])\n \n# Display new class counts\nup_sampled.sentiment.value_counts()","f01aa8e5":"# Separate majority and minority classes\ndf_majority = up_sampled[(up_sampled.sentiment==1) | (up_sampled.sentiment==-1) | (up_sampled.sentiment==0)]\ndf_minority = up_sampled[up_sampled.sentiment==2]\n \n# Upsample minority class\ndf_minority_upsampled = resample(df_minority, \n                                 replace=True,     # sample with replacement\n                                 n_samples=4000,    # to match majority class\n                                 random_state=42) # reproducible results\n \n# Combine majority class with upsampled minority class\nresampled_data = pd.concat([df_majority, df_minority_upsampled])\n \n# Display new class counts\nresampled_data.sentiment.value_counts()","74cf77b3":"#Create training test and testing set for the resampled data\nresampled_data = resampled_data.append(df_test, ignore_index=True)\ntfidf_vectorizer1 = TfidfVectorizer()\ntfidf_resam = tfidf_vectorizer1.fit_transform(resampled_data['message'])\ntrain_resam = tfidf_resam[:19000,:]\ntest_resam = tfidf_resam[19000:,:]\n\nX_resampled = train_resam\ny_resampled = resampled_data.iloc[:19000,:]['sentiment']\nX_train_resam, X_test_resam, y_train_resam, y_test_resam = train_test_split(X_resampled, y_resampled, test_size=0.1)","0c23992e":"modelstart= time.time()\n\nclassifier1 = LinearSVC()\nclassifier2 = LinearSVC()\n\n#Fitting to Unbalanced data\nlvc1 = classifier1.fit(X_train,y_train)\nypred_lvc1 = lvc1.predict(X_test)\nlvc_score1 = f1_score(y_test, ypred_lvc1, average='macro')\nprecision_lvc1 = precision_score(y_test, ypred_lvc1, average='macro')\nrecall_lvc1 = recall_score(y_test, ypred_lvc1, average='macro')\n\n#Fitting to Balanced data\nlvc2 = classifier2.fit(X_train_resam,y_train_resam)\nypred2 = lvc2.predict(X_test_resam)\nlvc_score2 = f1_score(y_test_resam, ypred2, average='macro')\nprecision_lvc2 = precision_score(y_test_resam, ypred2,average='macro')\nrecall_lvc2 = recall_score(y_test_resam, ypred2, average='macro')\n\nprint(\"Testing: Linear Support Vector\")\nprint('F1 Score on unbalanced data', lvc_score1)\nprint('F1 Score on balanced data', lvc_score2)\nprint('Recall Score on unbalanced data', recall_lvc1)\nprint('Recall Score on balanced data', recall_lvc2)\nprint('PrecisionScore on unbalanced data', precision_lvc1)\nprint('Precision Score on balanced data', precision_lvc2)\nprint(\"Model Runtime: %0.2f seconds\"%((time.time() - modelstart)))","a4f8429c":"#Create Scorer\nf1 = make_scorer(f1_score , average='macro')\n\n#Unbalanced \n# create the grid\nmax_iter = [100,500,1000,2000,5000]\nC = [1,10,50,100,200]\nparam_grid = dict(C =C ,max_iter=max_iter)\n\n\n# search the grid\ngrid = GridSearchCV(estimator=lvc1, \n                    param_grid=param_grid,\n                    scoring = f1,\n                    cv= 2,\n                    verbose=0,\n                    n_jobs=-1)\n\n\nlvc_best = grid.fit(X_train, y_train)\nlvc_estimator = grid.best_estimator_\nlvc_parameters = grid.best_params_\nlvc_score = grid.best_score_\n\nprint('Linear Support Vector on Unbalanced Data')\nprint('Best Estimator: ', lvc_estimator)\nprint('Best Parameter: ', lvc_parameters)\nprint('Best Score: ', lvc_score)","cec913e9":"#Create Scorer\nf1 = make_scorer(f1_score , average='macro')\n\n#Balanced \n# create the grid\nmax_iter = [100,500,1000,2000,5000]\nC = [1,10,50,100,200]\nparam_grid = dict(C =C ,max_iter=max_iter)\n\n\n# search the grid\ngrid = GridSearchCV(estimator=lvc2, \n                    param_grid=param_grid,\n                    scoring = f1,\n                    cv= 2,\n                    verbose=0,\n                    n_jobs=-1)\n\n\nlvc_best = grid.fit(X_train_resam, y_train_resam)\nlvc_estimator = grid.best_estimator_\nlvc_parameters = grid.best_params_\nlvc_score = grid.best_score_\n\nprint('Linear Support Vector on Balanced Data')\nprint('Best Estimator: ', lvc_estimator)\nprint('Best Parameter: ', lvc_parameters)\nprint('Best Score: ', lvc_score)","5b6ac166":"nltk.download('vader_lexicon')\nsid = SentimentIntensityAnalyzer()\n\ndf_train['scores'] = df_train['message'].apply(lambda message: sid.polarity_scores(message))\ndf_train['compound']  = df_train['scores'].apply(lambda score_dict: score_dict['compound'])","4e19e948":"modelstart= time.time()\nlr_classifier1 = LogisticRegression(solver='lbfgs')\nlr_classifier2 = LogisticRegression(solver='lbfgs')\n\n#Fitting on Unbalanced data\nlr_model1 = lr_classifier1.fit(X_train, y_train)\npredictions_lr1 = lr_classifier1.predict(X_test)\nlr_score1 = f1_score(y_test, predictions_lr1, average='macro')\nprecision_lr1 = precision_score(y_test, predictions_lr1, average='macro')\nrecall_lr1 = recall_score(y_test, predictions_lr1, average='macro')\n\n#Fitting on Balanced data\nlr_model2 = lr_classifier2.fit(X_train_resam,y_train_resam)\npredictions_lr2 = lr_classifier2.predict(X_test_resam)\nlr_score2 = f1_score(y_test_resam, predictions_lr2, average='macro')\nprecision_lr2 = precision_score(y_test_resam, predictions_lr2, average='macro')\nrecall_lr2 = recall_score(y_test_resam, predictions_lr2, average='macro')\n\n\nprint(\"Testing: Logistic Regression\")\nprint('F1 Score on unbalanced data: ',lr_score1)\nprint('F1 Score on balanced data: ', lr_score2)\nprint('Recall Score on unbalanced data: ',recall_lr1)\nprint('Recall Score on balanced data: ', recall_lr2)\nprint('Precision Score on unbalanced data: ',precision_lr1)\nprint('Precision Score on balanced data: ', precision_lr2)\nprint(\"Model Runtime: %0.2f seconds\"%((time.time() - modelstart)))","a8d353f8":"#Create Scorer\nf1 = make_scorer(f1_score , average='macro')\n\n#Unbalanced \n# create the grid\nC = np.logspace(-3,3,7)\npenalty = [\"l1\",\"l2\"]\nparam_grid = dict(C =C ,penalty = penalty)\n\n\n# search the grid\ngrid = GridSearchCV(estimator=lr_model1, \n                    param_grid=param_grid,\n                    scoring = f1,\n                    cv= 2,\n                    verbose=0,\n                    n_jobs=-1)\n\n\nlr_best = grid.fit(X_train, y_train)\nlr_estimator = grid.best_estimator_\nlr_parameters = grid.best_params_\nlr_score = grid.best_score_\n\nprint('Logistic Regression on Unbalanced Data')\nprint('Best Estimator: ', lr_estimator)\nprint('Best Parameter: ', lr_parameters)\nprint('Best Score: ', lr_score)","ad4dabbd":"#Create Scorer\nf1 = make_scorer(f1_score , average='macro')\n\n#Balanced \n# create the grid\nC = np.logspace(-3,3,7)\npenalty = [\"l1\",\"l2\"]\nparam_grid = dict(C =C ,penalty = penalty)\n\n\n# search the grid\ngrid = GridSearchCV(estimator=lr_model2, \n                    param_grid=param_grid,\n                    scoring = f1,\n                    cv= 2,\n                    verbose=0,\n                    n_jobs=-1)\n\n\nlr_best = grid.fit(X_train_resam, y_train_resam)\nlr_estimator = grid.best_estimator_\nlr_parameters = grid.best_params_\nlr_score = grid.best_score_\n\nprint('Logistic Regression on Balanced Data')\nprint('Best Estimator: ', lr_estimator)\nprint('Best Parameter: ', lr_parameters)\nprint('Best Score: ', lr_score)","500a1900":"modelstart= time.time()\n\nKNN_classifier1 = KNeighborsClassifier()\nKNN_classifier2 = KNeighborsClassifier()\n\nknn_model1 = KNN_classifier1.fit(X_train, y_train)\npredictions_knn1 = KNN_classifier1.predict(X_test)\nknn_score1 = f1_score(y_test, predictions_knn1, average='macro')\nrecall_knn1 = recall_score(y_test, predictions_knn1, average='macro')\nprecision_knn1 = precision_score(y_test, predictions_knn1, average='macro')\n\nknn_model2 = KNN_classifier2.fit(X_train_resam,y_train_resam)\npredictions_knn2 = KNN_classifier2.predict(X_test_resam)\nknn_score2 = f1_score(y_test_resam, predictions_knn2, average='macro')\nrecall_knn2 = recall_score(y_test_resam, predictions_knn2, average='macro')\nprecision_knn2 = precision_score(y_test_resam, predictions_knn2, average='macro')\n\n\nprint(\"Testing: K-Nearest Neighbors\")\nprint('F1 Score on unbalanced data: ', knn_score1)\nprint('F1 Score on balanced data: ', knn_score2)\nprint('Recall Score on unbalanced data: ', recall_knn1)\nprint('Recall Score on balanced data: ', recall_knn2)\nprint('Precision Score on unbalanced data: ', precision_knn1)\nprint('Precision Score on balanced data: ', precision_knn2)\nprint(\"Model Runtime: %0.2f seconds\"%((time.time() - modelstart)))","fa53e718":"#Create Scorer\nf1 = make_scorer(f1_score , average='macro')\n\n#Unbalanced \n# create the grid\nn_neighbors = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 50, 100]\nparam_grid = dict(n_neighbors = n_neighbors)\n\n# search the grid\ngrid = GridSearchCV(estimator=knn_model1, \n                    param_grid=param_grid,\n                    scoring = f1,\n                    cv= 2,\n                    verbose=0,\n                    n_jobs=-1)\n\nknn_best = grid.fit(X_train, y_train)\nknn_estimator = grid.best_estimator_\nknn_parameters = grid.best_params_\nknn_score = grid.best_score_\n\nprint('K-Nearest Neighbours on Unbalanced Data')\nprint('Best Estimator: ', lr_estimator)\nprint('Best Parameter: ', lr_parameters)\nprint('Best Score: ', lr_score)","0298baa9":"#Create Scorer\nf1 = make_scorer(f1_score , average='macro')\n\n#Unbalanced \n# create the grid\nn_neighbors = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 50, 100]\nparam_grid = dict(n_neighbors = n_neighbors)\n\n# search the grid\ngrid = GridSearchCV(estimator=knn_model2, \n                    param_grid=param_grid,\n                    scoring = f1,\n                    cv= 5,\n                    verbose=0,\n                    n_jobs=-1)\n\nknn_best = grid.fit(X_train_resam, y_train_resam)\nknn_estimator = grid.best_estimator_\nknn_parameters = grid.best_params_\nknn_score = grid.best_score_\n\nprint('K-Nearest Neighbours on Balanced Data')\nprint('Best Estimator: ', knn_estimator)\nprint('Best Parameter: ', knn_parameters)\nprint('Best Score: ', knn_score)","41348023":"modelstart= time.time()\nrf1 = RandomForestClassifier(n_estimators=200, random_state=11)\nrf2 = RandomForestClassifier(n_estimators=200, random_state=11)\n \n#Training on Unbalanced data    \nrf_model1 = rf1.fit(X_train, y_train)\npredictions_rf1 = rf1.predict(X_test)\nrf_score1 = f1_score(y_test, predictions_rf1, average='macro')\nrecall_rf1 = recall_score(y_test, predictions_rf1, average='macro')\nprecision_rf1 = precision_score(y_test, predictions_rf1, average='macro')\n\n#Training on Balanced data\nrf_model2 = rf2.fit(X_train_resam,y_train_resam)\npredictions_rf2 = rf2.predict(X_test_resam)\nrf_score2 = f1_score(y_test_resam, predictions_rf2, average='macro')\nrecall_rf2 = recall_score(y_test_resam, predictions_rf2, average='macro')\nprecision_rf2 = precision_score(y_test_resam, predictions_rf2, average='macro')\n\nprint(\"Testing: Random Forest\")\nprint('F1 Score on unbalanced data: ', rf_score1)\nprint('F1 Score on balanced data: ', rf_score2)\nprint('Recall Score on unbalanced data: ', recall_rf1)\nprint('Recall Score on balanced data: ', recall_rf2)\nprint('Precision Score on unbalanced data: ', precision_rf1)\nprint('Precision Score on balanced data: ', precision_rf2)\nprint(\"Model Runtime: %0.2f seconds\"%((time.time() - modelstart)))","2d5eff67":"#Create Scorer\nf1 = make_scorer(f1_score , average='macro')\n\n#Unbalanced \n# create the grid\nn_estimators = [100, 1000, 2000]\nmax_features = [1, 3, 5]\nmax_depth = [5, 10, 20]\nparam_grid = dict(n_estimators=n_estimators, max_depth=max_depth)\n\n\n# search the grid\ngrid = GridSearchCV(estimator=rf_model1, \n                    param_grid=param_grid,\n                    scoring = f1,\n                    cv= 2,\n                    verbose=2,\n                    n_jobs=-1)\n\n\nrf_best = grid.fit(X_train_resam, y_train_resam)\nrf_estimator = grid.best_estimator_\nrf_parameters = grid.best_params_\nrf_score = grid.best_score_\n\nprint('Random Forest on Unbalanced Data')\nprint('Best Estimator: ', rf_estimator)\nprint('Best Parameter: ', rf_parameters)\nprint('Best Score: ', rf_score)","24009ef6":"#Create Scorer\nf1 = make_scorer(f1_score , average='macro')\n\n#Balanced \n# create the grid\nn_estimators = [100, 1000, 2000]\nmax_features = [1, 3, 5]\nmax_depth = [5, 10, 20]\nparam_grid = dict(n_estimators=n_estimators, max_depth=max_depth)\n\n\n# search the grid\ngrid = GridSearchCV(estimator=rf_model2, \n                    param_grid=param_grid,\n                    scoring = f1,\n                    cv= 2,\n                    verbose=2,\n                    n_jobs=-1)\n\n\nrf_best = grid.fit(X_train, y_train)\nrf_estimator = grid.best_estimator_\nrf_parameters = grid.best_params_\nrf_score = grid.best_score_\n\nprint('Random Forest on Balanced Data')\nprint('Best Estimator: ', rf_estimator)\nprint('Best Parameter: ', rf_parameters)\nprint('Best Score: ', rf_score)","30ed5cd4":"modelstart= time.time()\ndt_classifier1 = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\ndt_classifier2 = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n\ndt_model1 = dt_classifier1.fit(X_train, y_train)\npredictions_dt1 = dt_classifier1.predict(X_test)\ndt_score1 = f1_score(y_test, predictions_dt1, average='macro')\nrecall_dt1 = recall_score(y_test, predictions_dt1, average='macro')\nprecision_dt1 = precision_score(y_test, predictions_dt1, average='macro')\n\ndt_model2 = dt_classifier2.fit(X_train_resam,y_train_resam)\npredictions_dt2 = dt_classifier2.predict(X_test_resam)\ndt_score2 = f1_score(y_test_resam, predictions_dt2, average='macro')\nrecall_dt2 = recall_score(y_test_resam, predictions_dt2, average='macro')\nprecision_dt2 = precision_score(y_test_resam, predictions_dt2, average='macro')\n\nprint(\"Testing: Decision Tree\")\nprint('F1 Score on unbalanced data: ', dt_score1)\nprint('F1 Score on balanced data: ', dt_score2)\nprint('Recall Score on unbalanced data: ', recall_dt1)\nprint('Recall Score on balanced data: ', recall_dt2)\nprint('Precision Score on unbalanced data: ', precision_dt1)\nprint('Precision Score on balanced data: ', precision_dt2)\nprint(\"Model Runtime: %0.2f seconds\"%((time.time() - modelstart)))","b17877e7":"#Create Scorer\nf1 = make_scorer(f1_score , average='macro')\n\n#Unbalanced \n# create the grid\nmax_depth = [5, 10, 20,100,200]\nparam_grid = dict(max_depth=max_depth)\n\n# search the grid\ngrid = GridSearchCV(estimator=dt_model1, \n                    param_grid=param_grid,\n                    scoring = f1,\n                    cv=2,\n                    verbose=2,\n                    n_jobs=-1)\n\ndt_best = grid.fit(X_train, y_train)\ndt_estimator = grid.best_estimator_\ndt_parameters = grid.best_params_\ndt_score = grid.best_score_\n\nprint('Decision Tree on Unbalanced Data')\nprint('Best Estimator: ', dt_estimator)\nprint('Best Parameter: ', dt_parameters)\nprint('Best Score: ', dt_score)","0ece2b8a":"#Create Scorer\nf1 = make_scorer(f1_score , average='macro')\n\n#Balanced \n# create the grid\nmax_depth = [5, 10, 20,100,200]\nparam_grid = dict(max_depth=max_depth)\n\n# search the grid\ngrid = GridSearchCV(estimator=dt_model2, \n                    param_grid=param_grid,\n                    scoring = f1,\n                    cv= 2,\n                    verbose=2,\n                    n_jobs=-1)\n\ndt_best = grid.fit(X_train_resam, y_train_resam)\ndt_estimator = grid.best_estimator_\ndt_parameters = grid.best_params_\ndt_score = grid.best_score_\n\nprint('Decision Tree on Balanced Data')\nprint('Best Estimator: ', dt_estimator)\nprint('Best Parameter: ', dt_parameters)\nprint('Best Score: ', dt_score)","44eeedf4":"# Compare F1_score values between models\nfig,axis = plt.subplots(figsize=(12, 6))\nf1_x = ['Linear Support Vector','Logistic Regression','K-Nearest Neighbors','Random Forest','Decsion Tree']\nf1_y = [lvc_score2,lr_score2,knn_score2,rf_score2,dt_score2]\nax = sns.barplot(x=f1_x, y=f1_y,palette='plasma')\nplt.title('Classification Model F1 Score Values',fontsize=14)\nplt.ylabel('F1 Score')\nplt.xticks(rotation=90)\n\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/2, p.get_y() + p.get_height(), round(p.get_height(),2), fontsize=12, ha=\"center\", va='bottom')\nplt.show()","ac007783":"# Compare Precision score values between models\nfig,axis = plt.subplots(figsize=(12, 6))\nf1_x = ['Linear Support Vector','Logistic Regression','K-Nearest Neighbors','Random Forest','Decsion Tree']\nf1_y = [precision_lvc2,precision_lr2,precision_knn2,precision_rf2,precision_dt2]\nax = sns.barplot(x=f1_x, y=f1_y,palette='plasma')\nplt.title('Classification Model Precision Score Values',fontsize=14)\nplt.ylabel('F1 Score')\nplt.xticks(rotation=90)\n\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/2, p.get_y() + p.get_height(), round(p.get_height(),2), fontsize=12, ha=\"center\", va='bottom')\nplt.show()","0676a748":"# Compare Precision score values between models\nfig,axis = plt.subplots(figsize=(12, 6))\nf1_x = ['Linear Support Vector','Logistic Regression','K-Nearest Neighbors','Random Forest','Decsion Tree']\nf1_y = [recall_lvc2,recall_lr2,recall_knn2,recall_rf2,recall_dt2]\nax = sns.barplot(x=f1_x, y=f1_y,palette='plasma')\nplt.title('Classification Model Precision Score Values',fontsize=14)\nplt.ylabel('F1 Score')\nplt.xticks(rotation=90)\n\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/2, p.get_y() + p.get_height(), round(p.get_height(),2), fontsize=12, ha=\"center\", va='bottom')\nplt.show()","05de5fe0":"f1 = make_scorer(f1_score , average='macro')\nclassifier = [RandomForestClassifier(n_estimators = 2000, max_depth = 20),LinearSVC(C = 1, max_iter = 500)]\ncross_val = []\nfor c in classifier:\n    cross_val.append(np.sqrt(abs(cross_val_score(c, X_train, y=y_train, scoring= f1, cv=KFold(n_splits=5, random_state=0, shuffle=True)))))\ncross_val_mean = [i.mean() for i in cross_val] \ncross_val_df = pd.DataFrame({\"Model\": [\"RandomForest\", \"LinearSVC\"],\"F1 Score\": cross_val_mean})\npd.DataFrame(cross_val_df.sort_values(\"F1 Score\", ascending=True))","a1b4b10e":"#RUN MODEL AGAIN\nmodelstart= time.time()\nfinal_model = LinearSVC(C = 1, max_iter = 500, penalty = 'l2')\nfinal_model.fit(X_train, y_train)\ny_pred_final = final_model.predict(X_test)\nfinal_score = f1_score(y_test, y_pred_final, average = 'macro')\nprint(\"Testing: Linear Support Vector\")\nprint('Final F1 Score: ', final_score)\nprint(\"Model Runtime: %0.2f seconds\"%((time.time() - modelstart)))","e96c4d97":"print(metrics.classification_report(y_test,y_pred_final))","81c85238":"print(metrics.confusion_matrix(y_test,y_pred_final))","ccd5876c":"print(metrics.accuracy_score(y_test,y_pred_final))","7d94fdbd":"#Log Parameters of all models\nparams ={'LVC_model type': 'LVC',\n          'scaler': 'standard scaler',\n         'params': str(lvc_parameters),\n         \n         'LR_model type': 'logisticregression',\n         'LR_Params': str(lr_parameters),\n         \n         'KNN_model type': 'knn',\n         'KNN_Params': str(knn_parameters),\n         \n         'RF_model type': 'randomforest',\n         'RF_Params': str(rf_parameters),\n         \n         'DT_model type': 'decisiontree',\n         'DT_Params': str(dt_parameters),\n         \n         'stratify':True\n}","e6f118fb":"#Log metrics of all models \nmetrics = {'LVC_F1': lvc_score2,\n          'LR_F1':lr_score2,\n          'KNN_F1':knn_score2,\n          'RF_F1':rf_score2,\n          'DT_F1':dt_score2,\n           \n           'LVC_Recall':recall_lvc2,\n           'LR_Recall':recall_lr2,\n           'KNN_Recall':recall_knn2,\n           'RF_Recall':recall_rf2,\n           'DT_Recall':recall_dt2,\n           \n           'LVC_Precision':precision_lvc2,\n           'LR_Precision':precision_lr2,\n           'KNN_Precision':precision_knn2,\n           'RF_Precision':precision_rf2,\n           'DT_Precision':precision_dt2,\n           \n          }","0e598e89":"experiment.log_parameters(params)\nexperiment.log_metrics(metrics)","25503842":"experiment.end()","e0d992ec":"experiment.display()","b22729d9":"#SUBMISSION TO KAGGLE\nsubmission = final_model.predict(test)\ndf_test['sentiment'] = submission\ndf_test.sentiment = df_test.sentiment.astype(int)\nfinal_submission = df_test[['tweetid','sentiment']]\nfinal_submission.to_csv('submission.csv', index=False)","b398092a":"For the tweets that are pro the belief of man-made climate change, the words that seem the to be the most important or most frequent are *CLIMATE CHANGE, GLOBAL WARMING.*","aaf98a95":"## K-Nearest Neighbours","e425b84c":"We see that tweets in class -1 (the tweet does not believe in man-made climate change) tend to be longer.","eeb0c398":"Before we begin, we will first install comet for our experiment that will record the parameters and metrics of our models. ","e17501ae":"First we go through a process called vectorizarition or feature extraction. We will be using TF-IDF vectorizer to convert text to word frequency vectors.\nTerm Frequency \u2013 Inverse Document (TF-IDF) are word frequency scores that try to highlight words that are more interesting, eg. more frequent. This is important to prepare text data for predictive modelling. The words need to be encoded as numbers (integers or floating point values) to use as input to a machine learning algorithm. \n\nThen we split data into a training set, testing data and validation data:\n* Training set (X_train and y_train): Data that contains a known output and the model learns on this data.\n* Validation data (y_test): This data is used to assess how well the algorithm was trained with the training data.\n* Test data (X_test) Data used to provide an unbiased evaluation of a final model fit on the training dataset.","6c1d0e79":"K-Nearest Neighbours works by:\n\n1. Choosing K (number of neighbours)\n2. Choosing distance metric \n3. For each data point  $X_{test}$  in the testing data and for each data point  $X_{train}$    in the training data calculate the distance between the test point and training point. Then find the labels of the K closest poins to  $X_{test}$  and assign the mode label to  $X_{test}$.","07cdc798":"Because of the f1 score and runtime of the models, we choose the Linear Support Vector as our final model on the unbalanced data set ","a64e7775":"## Lower Casing the Text","74f07033":"We see above that the train data has 182 row that contain emojis while the test data has 120 rows.","c4a96b4b":"## Checking for Imbalance in Sentiment Data","8c458243":"<a id=\"modelling\"><\/a>\n# 6. Modelling","b2753743":"## Tokenization and Lemmatization","e8297649":"We can see from the above histogram that there is an imbalance of classes. The number of observations across the different class labels are unevenly distributed. When we're training our models, it is preferable for all classes to have a relatively even split of observations.","0465f4d2":"Random Forest is ensemble method built on decision trees. It aggregates the results of an ensemble of decision trees.","fb94eca5":"Here we see that majority of the tweets for all classes are longer in length.","b95f667c":"# Random Forest","5257d05d":"## Checking Relationship between Text Length and Sentiment ","0d4d43ea":"## Decision Tree","edee3422":"## Dealing with Unbalanced data","cc7bbe51":"For the tweets that are anti climate change, the words that seem the to be the most important or most frequent are *CLIMATE CHANGE*, *GLOBAL WARMING*, *SCIENCE*. It is also interesting to note that word such as *SCAM* and *HOAX* are highlighted as well.","dda64c98":"<a id=\"intro\"><\/a>\n# 1. Introduction\n## Project Description\nMany companies are built around lessening one\u2019s environmental impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product\/service may be received.\n\nWith this context, EDSA has challenged us during the Classification Sprint with the task of creating a Machine Learning model that is able to classify whether or not a person believes in climate change, based on their novel tweet data.\n\nProviding an accurate and robust solution to this task gives companies access to a broad base of consumer sentiment, spanning multiple demographic and geographic categories - thus increasing their insights and informing future marketing strategies.\n\n## Problem Statement\nBuild a machine learning model that will classify if people believe in climate change based on their tweets in other to improve and make castomer base products.\n\n##  Data Description (Datasets and Variables)\nThe data provided was funded by a Canada Foundation for Innovation JELF Grant to Chris Bauch, University of Waterloo. The dataset aggregates tweets pertaining to climate change collected between Apr 27, 2015 and Feb 21, 2018. In total, 43943 tweets were collected.\n\nEach tweet is labelled as one of the following classes:\n   *  **2**: News(the tweet links to factual news about climate change)\n   *  **1**: Pro(the tweet supports the belief of man-made climate change)\n   *  **0**: Neutral(the tweet neither supports nor refutes the belief of man-made climate change)\n   * **-1**: Anti(the tweet does not believe in man-made climate change)\n   \nDatasets provided:\n* **train.csv**: The dataset that will be used to train our model.\n* **test.csv**: The dataset to which we will apply our model.\n\nVariable Definition:\n* **sentiment**: Sentiment of tweet\n* **message**: Tweet body\n* **tweetid**: Twitter unique id","f2ff92ce":"For the tweets that are neutral, the word and phrases *CLIMATE, GLOBAL WARMING, CLIMATE CHANGE* seem to have more importance.","7029249b":"## Visualizing Tweets with Word2Vec and t-SNE\nWord2vec is a two-layer neural network that is designed to processes text, in this case, Twitter Tweets. It's input is a text corpus (ie. Tweet) and its output is a set of vectors: feature vectors for words in that corpus. Word2Vec converts text into a numerical form that can be understood by a machine.\n\nIn this step, we take the Tweets and perform tokenization - transforming the word into a numerical representation - prior to visualizing. We pass each tweet (tw.tweet) to be tokenised, with the output being appended to an array. reference : https:\/\/leightley.com\/visualizing-tweets-with-word2vec-and-t-sne-in-python\/","17d9da0f":"## Logistic Regression","4d6aba23":"For our modelling process, we will be modelling on unbalanced data and balanced and see which model performed better. Therefore, we will have two training and testing sets, one for the unbalanced data and one for the resampled data.","bde4f4db":"# Climate Change Challenge by EXPLORE Data Science Academy\n**Team_RM_3**\n* Menzi Mchunu, Lucas Sithole, Nthabeleng Vilakazi, Sizwe Bhembe, Mbuso Biyela and Sibusiso Luthuli","aa5b18aa":"### Grid Search","d465aca0":"Emojis have become part of everyday language and we suspect that the use of an emoji affects the sentiment of the tweet. Here, we explore the emojis found in both datasets and change them to text with functions below. We will then use this information to build our models.","f59eb3d4":"### GridSearch","02618fed":"<a id=\"analysis\"><\/a>\n# 8. Model Analysis","8f576724":"### Grid Search","52cda959":"## Understanding Common Words in Tweets\n\nWord Cloud is a data visualization technique used for representing text data whereby the size of each word indicates its frequency or importance. We will be using Word Cloud to anaylze the tweets. \nSince many companies would like to determine how people perceive climate change and whether or not they believe it is a real threat (see Project Description), word clouds can identify patterns that would otherwise be difficult to see in a tabular format.","edf9c6fb":"## Removing Twitter Handles","306062ad":"Both the test data and train data have no missing values. The training set and testing set have 14229 and 9575 unique tweets respectively. The most common tweet found in both dataset is 'RT @StephenSchlegel: she's thinking about how ... ' , this makes sense because it's a retweet.","7dd24018":"## Evaluate Models By Cross Validation\n\nCross validation is used to test the accuracy of a model's prediction on unseen data (validation sets). This is important because it can assist in picking up issues such as over\/underfititng and selection bias. We used the K-fold technique to perform cross validation.","8fe47904":"Decision Trees can be explained by two entities, decision nodes and leaves. The leaves are the decisions or the final outcomes. And the decision nodes are where the data is split. A decsion tree predictive model goes from an observation of a point to (represented in the branches) to conclusions about the target value.","69c02b75":"<a id=\"eda\"><\/a>\n# 4. Exploratory Data Analysis","e3432a58":"<a id=\"comet\"><\/a>\n# 9. Comet","e4e14fab":"Above we mentioned that the classes are imbalanced, the number of observations for the classes are unevenly distributed. An imbalanced dataset will lead a model to get good results by returning the majority. We will therefore resample the data by downsampling the majority classes and upsampling the minority classes. Downsampling is the process of taking a random subset of the majority class and matching it to the minority class. Upsampling is the process of taking random samples from the minority class until we have as many observations as the majority class.","f998b026":"We were successful in building a model that is able to predict the sentiment of a tweet. We tested five different models for this task and chose the the one with an F1 Score that is above 0.7.\nLinear Support Vector delivered the best F1 score based on our test sets.\n\n","8a854546":"[[](http:\/\/)](http:\/\/) Table of Contents\n\n1. [Introduction](#intro) \n * Project Description\n * Problem Statement\n * Datasets and Variables\n \n2. [Import Libraries and Data](#imports)\n\n3. [Data Evaluation and Data Cleaning](#data)\n * Checking Summary Statistics of all Data\n * Exploring Emojis\n * Removing Twitter Handles\n * Lower Casing the Text\n * Removing Links and Retweet Symbol (RT)\n * Removing Stopwords\n * Tokenization and Lemmatization\n\n4. [Exploratory Data Analysis](#eda)\n * Checking for Imbalance in Sentiment Data\n * Checking Relationship between Text Length and Sentiment\n * Understanding Common Words in Tweets\n * Understanding Relationship of Hashtags and Sentiment of Tweet\n * Visualizing Tweets with Word2Vec and t-SNE\n * Understanding Relationship Between Hashtags and Sentiment Of Tweet\n \n5. [Data Preprocessing](#preprocessing)\n \n6. [Modelling](#modelling)\n  * Linear Support Vector\n  * Logistic Regression\n  * K-Nearest Neighbours\n  * Random Forest\n  * Decision Tree\n  \n7. [Performance Evaluation](#evaluation)\n  * Compare Models on Performance Metrics\n  * Evaluate Models By Cross Validation\n  \n8. [Model Analysis](#analysis)\n\n9. [Comet](#comet)\n\n10. [Conclusion](#conclusion)\n\n11. [Save Model and Output](#save)\n\n \n","cabdb236":"Stop words are commonly used words in text such as \"a\", \"an\", \"the\". Since we are attempting to classify text into different classes, we'll remove stop words from the text in order to give more focus to the words that give the text meaning. ","97d15a86":"## Understanding Relationship of Hashtags and Sentiment of Tweet","a7e155ac":"## Exploring Emojis","9c8f5ab3":"## Removing Stopwords","db064952":"* ###  Extract All The Emojis In The Dataframe","e6e29925":"## Load Data","cb78fb9e":"## Removing Links and Retweet Symbol (RT)","d832e2d9":"## Linear Support Vector","fce9d300":"<a id=\"imports\"><\/a>\n# 2. Import Libraries and Data\nList of libralies and dataset that are going to be needed for the project, some will be imported as we move along","5b32e183":"Here, we can see that *CLIMATE CHANGE*, *CLIMATE, GLOBAL WARMING* are the most frequently occurring words for the different types of tweets.","e64959dd":"<a id=\"data\"><\/a>\n# 3. Data Evaluation and Data Cleaning\n## Checking Summary Statistics of all the Data\n","e4d8e1d8":"Tokenization is the process of splitting up a text into pieces such as words, symbols and other elements called tokens. These tokens are important as they are the base step for stemming and lemmatization (in our case, lemmatization).\n\nLemmatization returns the base or dictionary form of a word, by considering a language's full vocabulary.","799b2e9d":"## Compare Models on Performance Metrics","abfac055":"**Now that we've changed the emojis to text in a list we change them in the dataframe using the function below.**","dd564587":"### Grid Search","770884b8":"A linear SVC (Support Vector Classifier) fits to the data and returns a best fit hyperplane that categorizes the data. Thereafter, we can feed some features to the model to see what the predicted class is. \n\n\n","8271c233":"Logistic regression is a supervised learning classification algorithm used to predict the probability of a target variable. Normally, logistic regression is used to do binary classification, however,we'll do multiclass classification. In terms of logistic regression, multiclass classification can be done through the one-vs-rest scheme in which for each class a binary classification problem of data belonging or not to that class is done, or changing the loss function to cross- entropy loss.\n\nThe formula for logistic regression:\n\\begin{align}\n1 - P(X) &= \\displaystyle \\frac{1}{1+e^{\\beta_0 + \\beta_1 X}} \\\\\n\\therefore \\log \\left( \\frac{P(X)}{1-P(X)} \\right) &= {\\beta_0 + \\beta_1 X}\n\\end{align} where $P(X)$ is the probability of X belonging to class 1, $\\beta_0$ is the intercept and $\\beta_1$ is the regression coefficient. ","2c4da707":"<a id=\"preprocessing\"><\/a>\n# 5. Data Preprocessing","5c03573c":"We will compare the performance of the models using the precision, recall, precision.\n\n#### Precision:\nPrecision can be defined as the sum of true positives across all classes divided by the sum of true positives and false positives across all classes. Precision answers the question: what proportion of the predicted positves is indeed postive.\n\n$$ Precision = \\frac{TP}{TP \\space + FP} = \\frac{TP}{Total \\space Predicted \\space Positive} $$\n\n\n#### Recall:\nRecall can be defined as he sum of true positives across all classes divided by the sum of true positives and false negatives across all classes. Recall answers the question: what proportion of actual positives is correctly classified?\n\n$$ Recall = \\frac{TP}{TP \\space + FN} = \\frac{TP}{Total \\space Actual \\space Positive}$$\n\n#### F1 Score:\n$$F_1 = 2 \\times \\frac {Precision \\space \\times \\space Recall }{Precision \\space + \\space Recall }$$\nThe higher the f1 score is, the better the fit of the model","acb0b3b6":"<a id=\"save\"><\/a>\n# 11. Save Model and Output","1c8167f6":"<a id=\"conclusion\"><\/a>\n# 10. Conclusion","fbbe8603":"Please note that you'll have to install\/download the following before running this notebook:\n* pip install emoji\n* pip install demoji\n* genism\n* nltk \n* pip install wordcloud","05b61505":"<a id=\"evaluation\"><\/a>\n# 7. Performance Evaluation","fa0918d2":"* ###  Finding Rows with emojis for both train and test dataset","1d356b88":"**For each model in this section, we will:**\n\n* Train model on unbalanced data\n* Train model on balanced data\n* Perform GridSearch to find best parameters for each model","1aeb8b78":"### Grid Search","d3134d85":"***Drop columns that will not be used***"}}