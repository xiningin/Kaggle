{"cell_type":{"9d17e7de":"code","456092aa":"code","9f313ef2":"code","4436f9f6":"code","caeced6d":"code","97f5ef8b":"code","1da42e2e":"code","faecca7f":"code","0306bad4":"code","dcb22bff":"code","480ede1f":"code","742a041e":"code","8cd3708f":"code","2174f07f":"code","fec54399":"code","4540dccd":"code","f20562fa":"markdown","47377702":"markdown","9afa55de":"markdown","0df3b30c":"markdown","b316e997":"markdown","a58ca22f":"markdown","80147a40":"markdown","e3fbb4ea":"markdown","a281d624":"markdown","98f62d50":"markdown","1f90fbd6":"markdown","9a20f33b":"markdown"},"source":{"9d17e7de":"!pip install efficientnet_pytorch","456092aa":"import os\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\n# Libraries\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nimport sys\nimport glob\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport cv2\nfrom tqdm import tqdm\nfrom colorama import Fore, Back, Style\nr_ = Fore.WHITE\nfrom plotly.offline import iplot\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\nfrom skimage.io import imshow, imread, imsave\nfrom skimage.transform import rotate, AffineTransform, warp,rescale, resize, downscale_local_mean\nfrom skimage import color,data\nfrom skimage.exposure import adjust_gamma\nfrom skimage.util import random_noise\n\nfrom sklearn import metrics\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nfrom efficientnet_pytorch import model as enet\nimport random\nfrom sklearn.model_selection import StratifiedKFold","9f313ef2":"print(os.listdir(\"..\/input\/seti-breakthrough-listen\/\"))","4436f9f6":"def get_train_filename_by_id(_id: str) -> str:\n    return f\"..\/input\/seti-breakthrough-listen\/train\/{_id[0]}\/{_id}.npy\"\n\n\ndef show_cadence(filename: str, label: int) -> None:\n    plt.figure(figsize=(8, 8))\n    arr = np.load(filename)\n    for i in range(6):\n        plt.subplot(6, 1, i + 1)\n        if i == 0:\n            plt.title(f\"ID: {os.path.basename(filename)} TARGET: {label}\", fontsize=18)\n        plt.imshow(arr[i].astype(float), interpolation='nearest', aspect='auto')\n        plt.text(5, 100, [\"ON\", \"OFF\"][i % 2], bbox={'facecolor': 'white'})\n        plt.xticks([])\n    plt.show()\n    \n    \ndef show_channels(filename: str, label: int) -> None:\n    plt.figure(figsize=(10, 8))\n    plt.suptitle(f\"ID: {os.path.basename(filename)} TARGET: {label}\", fontsize=18)\n    arr = np.load(filename)\n    for i in range(6):\n        plt.subplot(2, 3, i + 1)\n        plt.imshow(arr[i].astype(float))\n    plt.show()","caeced6d":"train_labels = pd.read_csv(\"..\/input\/seti-breakthrough-listen\/train_labels.csv\")\nprint(train_labels.head())\nprint(\"-\" * 20)\nprint(train_labels.shape)\nprint(\"-\" * 20)\nprint(train_labels.target.value_counts())","97f5ef8b":"# \u5305\u542b\u4fe1\u53f7\u7684\u6837\u672c\ndf_tmp = train_labels[train_labels[\"target\"] == 1].sample(3)\nfor ind, row in df_tmp.iterrows():\n    show_cadence(get_train_filename_by_id(row[\"id\"]), row[\"target\"])","1da42e2e":"# \u4e0d\u5305\u542b\u4fe1\u53f7\u7684\u6837\u672c\ndf_tmp = train_labels[train_labels[\"target\"] == 0].sample(3)\nfor ind, row in df_tmp.iterrows():\n    show_cadence(get_train_filename_by_id(row[\"id\"]), row[\"target\"])","faecca7f":"from sklearn.metrics import roc_auc_score, roc_curve, auc\nimport numpy as np\n\nlist_y_true = [\n    [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n    [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n    [1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.], #  IMBALANCE\n    [1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.], #  IMBALANCE\n]\nlist_y_pred = [\n    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \n    [0.9, 0.9, 0.9, 0.9, 0.1, 0.9, 0.9, 0.1, 0.9, 0.1, 0.1, 0.5],\n    [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],#  IMBALANCE\n    [1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.], #  IMBALANCE\n]\n\nfor y_true, y_pred in zip(list_y_true, list_y_pred):\n    fpr, tpr, _ = roc_curve(y_true, y_pred)\n    roc_auc = auc(fpr, tpr)\n\n    plt.figure(figsize=(5, 5))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([-0.01, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC curve example')\n    plt.legend(loc=\"lower right\")\n    plt.show()","0306bad4":"# \u5c06\u8f93\u5165\u4fe1\u53f7\u89c6\u4e3a\u4e8c\u7ef4\u56fe\u50cf\uff0c\u91c7\u7528\u89c6\u89c9\u6a21\u578bEfficientNet\u505a\u8fc1\u79fb\u8bad\u7ec3\uff1b\n\nclass enetv2(nn.Module):\n    def __init__(self, backbone, out_dim):\n        super(enetv2, self).__init__()\n        self.enet = enet.EfficientNet.from_name(backbone)\n        self.enet.load_state_dict(torch.load(pretrained_model[backbone]))\n        self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)\n        self.enet._fc = nn.Identity()\n        self.conv1 = nn.Conv2d(6, 3, kernel_size=3, stride=1, padding=3, bias=False)\n\n    def extract(self, x):\n        return self.enet(x)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.extract(x)\n        x = self.myfc(x)\n        return x","dcb22bff":"# \u914d\u7f6e\n\ndef set_seed(seed = 0):\n    '''\u8bbe\u7f6e\u968f\u673a\u6570\u79cd\u5b50\uff0c\u4fdd\u8bc1\u6a21\u578b\u53ef\u590d\u73b0\u6027'''\n    np.random.seed(seed)\n    random_state = np.random.RandomState(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    return random_state\n\nrandom_state = set_seed(76)\n\n\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available, CPU used\")","480ede1f":"# ET-search\u5206\u7c7b\u6570\u636e\u96c6\n\nclass ClassificationDataset:\n    \n    def __init__(self, image_paths, targets): \n        self.image_paths = image_paths\n        self.targets = targets\n\n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):      \n        image = np.load(self.image_paths[item]).astype(float)\n\n        targets = self.targets[item]\n                \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.long),\n        }\n    \ndf_train=pd.read_csv('..\/input\/seti-breakthrough-listen\/train_labels.csv')\ndf_train['img_path']=df_train['id'].apply(lambda x:f'..\/input\/seti-breakthrough-listen\/train\/{x[0]}\/{x}.npy')","742a041e":"baseline_name = 'efficientnet-b1'\npretrained_model = {\n    baseline_name: '..\/input\/efficientnet-pytorch\/efficientnet-b1-dbc7070a.pth'\n}\n\nmodel = enetv2(baseline_name, out_dim=1)","8cd3708f":"# \u8bad\u7ec3\u8f85\u52a9\u51fd\u6570\n\ndef train(data_loader, model, optimizer, device):\n    \n    model.train()\n    \n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        inputs = data[\"image\"]\n        targets = data['targets']\n        \n        inputs = inputs.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n        loss.backward()\n        optimizer.step()\n\n\ndef evaluate(data_loader, model, device):\n    model.eval()\n    \n    final_targets = []\n    final_outputs = []\n    \n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            inputs = data[\"image\"]\n            targets = data[\"targets\"]\n            inputs = inputs.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float)\n            \n            output = model(inputs)\n            \n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            \n            final_targets.extend(targets)\n            final_outputs.extend(output)\n            \n    return final_outputs, final_targets","2174f07f":"baseline_name = 'efficientnet-b1'\npretrained_model = {\n    baseline_name: '..\/input\/efficientnet-pytorch\/efficientnet-b1-dbc7070a.pth'\n}\nmodels = []\ndevice = \"cuda\"\nepochs = 3\nBatch_Size = 32\nX = df_train.img_path.values\nY = df_train.target.values\nskf = StratifiedKFold(n_splits=5)\nfold = 0\n\nfor train_index, test_index in skf.split(X, Y):\n    \n    model = enetv2(baseline_name, out_dim=1)\n    model.to(device)\n\n    train_images, valid_images = X[train_index], X[test_index]\n    train_targets, valid_targets = Y[train_index], Y[test_index]\n\n    train_dataset = ClassificationDataset(image_paths=train_images, targets=train_targets)\n    valid_dataset = ClassificationDataset(image_paths=valid_images, targets=valid_targets)\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=Batch_Size,shuffle=True, num_workers=4)\n    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=Batch_Size,shuffle=False, num_workers=4)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n\n    for epoch in range(epochs):\n        train(train_loader, model, optimizer, device=device)\n        predictions, valid_targets = evaluate(valid_loader, model, device=device)\n        roc_auc = metrics.roc_auc_score(valid_targets, predictions)\n        print(f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\")\n        \n    torch.save(model.state_dict(),baseline_name + '-' + str(fold) + '.pt')\n    models.append(model)\n    fold += 1","fec54399":"submission=pd.read_csv('..\/input\/seti-breakthrough-listen\/sample_submission.csv')\nsubmission['img_path']=submission['id'].apply(lambda x:f'..\/input\/seti-breakthrough-listen\/test\/{x[0]}\/{x}.npy')\ntest_dataset=ClassificationDataset(image_paths=submission.img_path.values, targets=submission.target.values)\ntest_loader=torch.utils.data.DataLoader(test_dataset, batch_size=16,shuffle=False,num_workers=4)\n\nsig=torch.nn.Sigmoid()\nouts=[]\nfor model in models:\n    predictions,valid_targets=evaluate(test_loader, model, device=device)\n    predictions=np.array(predictions)[:,0]\n    out=sig(torch.from_numpy(predictions))\n    out=out.detach().numpy()\n    outs.append(out)\n    \npred=np.mean(np.array(outs),axis=0)\nsubmission.target=pred\nsubmission.drop(['img_path'],axis=1,inplace=True)\nsubmission.to_csv('submission.csv', index=False)","4540dccd":"submission.head()","f20562fa":"## Refs\n\n- https:\/\/www.kaggle.com\/ihelon\/signal-search-exploratory-data-analysis\n- https:\/\/www.kaggle.com\/c\/seti-breakthrough-listen\/overview\/data-information\n- https:\/\/www.kaggle.com\/c\/seti-breakthrough-listen\/discussion\/238298\n- https:\/\/www.cnblogs.com\/wuliytTaotao\/p\/9285227.html\n- https:\/\/www.kaggle.com\/robert76\/efficientnet-pretrained\/data","47377702":"### \u9884\u6d4b\u6807\u7b7e\n\n\u5171\u8ba150165\u4e2a\u6837\u672c\uff0c\u4e8c\u5206\u7c7b\u95ee\u9898\uff0c\u6837\u672c\u6bd4\u5217\u7ea6\u4e3a 10:1","9afa55de":"## \u8d5b\u9898\u80cc\u666f\n\n[\u6bd4\u8d5b\u5730\u5740\uff1aSETI Breakthrough Listen - E.T. Signal Search](https:\/\/www.kaggle.com\/c\/seti-breakthrough-listen\/) \n\n\u4e3a\u4e86\u641c\u5bfb\u5916\u661f\u4fe1\u53f7\uff0c\u6211\u4eec\u5c06\u6570\u5b57\u5149\u8c31\u4eeaBreakthrough Listen \u5b89\u88c5\u5728\u5927\u578b\u671b\u8fdc\u955cGreen Bank Telescope (GBT)\uff0c\u5b83\u4ece\u671b\u8fdc\u955c\u63a5\u6536\u539f\u59cb\u6570\u636e\uff08\u6bcf\u5929\u6570\u767e TB\uff09\u5e76\u6267\u884c\u5085\u7acb\u53f6\u53d8\u6362\u4ee5\u751f\u6210\u5149\u8c31\u56fe\u3002\u9891\u8c31\u7684\u6570\u636e\u975e\u5e38\u5bbd\uff0c\u901a\u5e38\u4f1a\u8de8\u8d8a\u51e0\u4e2a GHz \u7684\u65e0\u7ebf\u7535\u9891\u8c31\uff0c\u6570\u636e\u6587\u4ef6\u975e\u5e38\u5de8\u5927\uff0c\u4e3a\u4e86\u7b80\u5316\u6570\u636e\uff0c\u6bd4\u8d5b\u6570\u636e\u53ea\u62bd\u53d6\u5176\u4e2d\u5f88\u5c0f\u7684\u9891\u8c31\u533a\u57df\u7528\u4e8e\u9884\u6d4b\uff08\u88ab\u79f0\u4f5csnippets\uff0c\u9488\uff09\u3002\n\n\u4e3a\u4e86\u9632\u6b62\u6765\u81ea\u4e8e\u4eba\u7c7b\u4e16\u754c\u7684\u65e0\u7ebf\u7535\u53f0\uff0c\u8fd8\u6709 wifi \u8def\u7531\u5668\u7b49\u65e0\u7ebf\u7535\u4fe1\u53f7\u5e72\u6270\uff0cBreakthrough Listen \u901a\u8fc7\u4ea4\u66ff\u89c2\u6d4b\u6211\u4eec\u7684\u4e3b\u8981\u76ee\u6807\u661f\u548c\u9644\u8fd1\u4e09\u9897\u6052\u661f\u6765\u5bf9\u6297\u8fd9\u79cd\u5e72\u6270\uff0c\u5177\u4f53\u65b9\u5f0f\u4e3a\uff1a\u5728\u6052\u661f\u201cA\u201d\u4e0a\u89c2\u5bdf 5 \u5206\u949f\uff0c\u7136\u540e\u5728\u6052\u661f\u201cB\u201d\u4e0a\u89c2\u5bdf 5 \u5206\u949f\uff0c\u7136\u540e\u56de\u5230\u6052\u661f\u201cA\u201d\u4e0a 5 \u5206\u949f\uff0c\u7136\u540e\u662f\u201cC\u201d \u201d\uff0c\u7136\u540e\u56de\u5230\u201cA\u201d\uff0c\u7136\u540e\u5728\u201cD\u201d\u661f\u4e0a\u7528 5 \u5206\u949f\u7ed3\u675f\u3002\u4e00\u7ec4\u516d\u4e2a\u89c2\u5bdf\u503c (ABACAD) \u88ab\u79f0\u4e3acadence\uff08\u201c\u8282\u594f\u201d\uff09\u3002\u7531\u4e8e\u6211\u4eec\u53ea\u662f\u4e3a\u6bcf\u4e2a\u8282\u594f\u63d0\u4f9b\u5c0f\u8303\u56f4\u7684\u9891\u7387\uff0c\u56e0\u6b64\u6211\u4eec\u5c06\u60a8\u5c06\u8981\u5206\u6790\u7684\u6570\u636e\u96c6\u79f0\u4e3acadence snippets\uff08\u201c\u8282\u594f\u7247\u6bb5\u201d\uff09\u3002\n\n<div align=center>\n    <img src=\"https:\/\/storage.googleapis.com\/kaggle-media\/competitions\/SETI-Berkeley\/Screen%20Shot%202021-05-03%20at%2011.39.42.png\" width = \"500\", height = \"600\">\n<\/div>\n\n\n\u4e0a\u56fe\u662f\u8ddd\u79bb\u5730\u7403 200 \u4ebf\u516c\u91cc\u7684\u822a\u6d77\u8005\u4e00\u53f7\u98de\u8239\u7684cadence snippets\u3002\u7b2c\u4e00\u4e2a\u3001\u7b2c\u4e09\u4e2a\u548c\u7b2c\u4e94\u4e2a\u9762\u677f\u662f\u201cA\u201d\u76ee\u6807\uff08\u822a\u6d77\u8005\u4e00\u53f7\u98de\u8239\uff09\u3002\u9ec4\u8272\u5bf9\u89d2\u7ebf\u662f\u6765\u81ea\u822a\u6d77\u8005\u53f7\u7684\u65e0\u7ebf\u7535\u4fe1\u53f7\u3002\u5f53\u6211\u4eec\u6307\u5411\u822a\u5929\u5668\u65f6\u5b83\u4f1a\u88ab\u68c0\u6d4b\u5230\uff0c\u5f53\u6211\u4eec\u6307\u5411\u8fdc\u5904\u65f6\u5b83\u5c31\u4f1a\u6d88\u5931\u3002\u8fd9\u662f\u56fe\u4e2d\u7684\u4e00\u6761\u5bf9\u89d2\u7ebf\uff0c\u56e0\u4e3a\u5730\u7403\u548c\u822a\u5929\u5668\u7684\u76f8\u5bf9\u8fd0\u52a8\u4f1a\u4ea7\u751f\u591a\u666e\u52d2\u6f02\u79fb\uff0c\u5bfc\u81f4\u9891\u7387\u968f\u65f6\u95f4\u53d8\u5316\u3002\u800c\u5176\u4ed6\u5730\u7403\u7684\u4eba\u5de5\u4fe1\u53f7\u66f4\u503e\u5411\u4e8e\u4fdd\u6301\u5728\u56fa\u5b9a\u9891\u7387\uff0c\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u89c2\u6d4b\u662f\u5426\u53d1\u751f\u591a\u666e\u52d2\u6f02\u79fb\u73b0\u8c61\u6765\u8fdb\u884c\u4fe1\u53f7\u7504\u522b\u3002\u867d\u7136\u5b8c\u5168\u6839\u636e\u5df2\u7ecf\u53d1\u5c04\u7684\u98de\u8239\u7684\u89c2\u6d4b\u6765\u8bad\u7ec3\u6211\u4eec\u7684\u7b97\u6cd5\u4f1a\u5f88\u597d\uff0c\u4f46\u5b83\u4eec\u7684\u4f8b\u5b50\u5e76\u4e0d\u591a\uff0c\u800c\u4e14\u6211\u4eec\u8fd8\u5e0c\u671b\u80fd\u591f\u627e\u5230\u66f4\u5e7f\u6cdb\u7684\u4fe1\u53f7\u7c7b\u578b\u3002\u6240\u4ee5\u6211\u4eec\u8fdb\u884c\u4e86\u6570\u636e\u6a21\u62df\uff0c\u5728\u62cd\u6444\u4e86\u6570\u4ee5\u4e07\u8ba1\u7684\u8282\u594f\u7247\u6bb5\u4e0a\u6dfb\u52a0\u4e00\u4e9b\u7c7b\u4f3c\u4e8e\u822a\u6d77\u8005\u4e00\u53f7\u98de\u8239\u7684\u4fe1\u53f7\uff0c\u8fd9\u6784\u6210\u4e86\u6211\u4eec\u7684\u8bad\u7ec3\u6570\u636e\u3002","0df3b30c":"## \u8bc4\u4ef7\u6307\u6807\n\n\u8fd9\u662f\u4e00\u4e2a\u4e8c\u5206\u7c7b\u95ee\u9898\uff0c\u4e14\u5b58\u5728\u6837\u672c\u4e0d\u5747\u8861\u60c5\u51b5\uff0c\u56e0\u6b64\u4e3b\u529e\u65b9\u91c7\u7528\u4e86AUC\uff08Area Under the ROC Curve\uff0cROC\u66f2\u7ebf\u4e0b\u9762\u79ef\uff09\u4f5c\u4e3a\u8bc4\u4ef7\u6307\u6807\u3002\u4e0b\u9762\u7b80\u5355\u4ecb\u7ecd\u4e0bAUC\u7684\u8ba1\u7b97\u4e0e\u7279\u6027\u3002\n\n\u5bf9\u4e8e\u4e00\u4e2a\u4e8c\u5206\u7c7b\u95ee\u9898\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u5230\u5982\u4e0b\u56fe\u6240\u793a\u7684\u7684\u6df7\u6dc6\u77e9\u9635\uff08confusion matrix\uff09\n\n<div align=center>\n    <img src=\"https:\/\/i.loli.net\/2021\/06\/06\/82nuZpo1fQxHjNK.png\" width = \"500\", height = \"600\">\n<\/div>\n\n\n\n- TP(true positive)\uff1a\u771f\u5b9e\u7c7b\u522b\u4e3apositive\uff0c\u6a21\u578b\u9884\u6d4b\u7684\u7c7b\u522b\u4e5f\u4e3apositive\n- FP(false positive): \u9884\u6d4b\u4e3apositive\uff0c\u4f46\u771f\u5b9e\u7c7b\u522b\u4e3anegative\uff0c\u771f\u5b9e\u7c7b\u522b\u548c\u9884\u6d4b\u7c7b\u522b\u4e0d\u4e00\u81f4\n- FN(false negative): \u9884\u6d4b\u4e3anegative\uff0c\u4f46\u771f\u5b9e\u7c7b\u522b\u4e3apositive\uff0c\u771f\u5b9e\u7c7b\u522b\u548c\u9884\u6d4b\u7c7b\u522b\u4e0d\u4e00\u81f4\n- TN(true negtive): \u771f\u5b9e\u7c7b\u522b\u4e3anegative\uff0c\u6a21\u578b\u9884\u6d4b\u7684\u7c7b\u522b\u4e5f\u4e3anegative\n\n### ROC curve\n\nROC\u66f2\u7ebf\u7684\u7eb5\u5750\u6807True Positive Rate\uff08TPR\uff09\u5728\u6570\u503c\u4e0a\u5c31\u7b49\u4e8epositive\u7c7b\u522b\u7684\u53ec\u56de\u7387\uff0c\u6a2a\u5750\u6807False Positive Rate\uff08FPR\uff09\u5728\u6570\u503c\u4e0a\u7b49\u4e8e(1 - negative class\u7684recall)\u3002\u66f2\u7ebf\u901a\u8fc7\u5bf9\u5206\u7c7b\u9608\u503c\u03b8\uff08\u9ed8\u8ba40.5\uff09\u4ece\u5927\u5230\u5c0f\u6216\u8005\u4ece\u5c0f\u5230\u5927\u4f9d\u6b21\u53d6\u503c\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u5230\u5f88\u591a\u7ec4TPR\u548cFPR\u7684\u503c\uff0c\u5c06\u5176\u5728\u56fe\u50cf\u4e2d\u4f9d\u6b21\u753b\u51fa\u5c31\u53ef\u4ee5\u5f97\u5230\u4e00\u6761ROC\u66f2\u7ebf\uff0c\u9608\u503c\u03b8\u53d6\u503c\u8303\u56f4\u4e3a[0,1]\u3002ROC\u66f2\u7ebf\u5728\u56fe\u50cf\u4e0a\u8d8a\u63a5\u8fd1\u5de6\u4e0a\u89d2(0,1)\u6a21\u578b\u8d8a\u597d\uff0c\u5373ROC\u66f2\u7ebf\u4e0b\u9762\u4e0e\u6a2a\u8f74\u548c\u76f4\u7ebfFPR = 1\u56f4\u6210\u7684\u9762\u79ef\uff08AUC\u503c\uff09\u8d8a\u5927\u8d8a\u597d\u3002\u76f4\u89c2\u4e0a\u7406\u89e3\uff0c\u7eb5\u5750\u6807TPR\u5c31\u662frecallpositive\u503c\uff0c\u6a2a\u5750\u6807FPR\u5c31\u662f(1 - recallnegative)\uff0c\u524d\u8005\u8d8a\u5927\u8d8a\u597d\uff0c\u540e\u8005\u6574\u4f53\u8d8a\u5c0f\u8d8a\u597d\uff0c\u5728\u56fe\u50cf\u4e0a\u8868\u793a\u5c31\u662f\u66f2\u7ebf\u8d8a\u63a5\u8fd1\u5de6\u4e0a\u89d2(0,1)\u5750\u6807\u8d8a\u597d\u3002\n\n\u8981\u77e5\u9053\u54ea\u4e2a\u6a21\u578b\u66f4\u597d\uff0c\u5219\u9700\u8981\u8ba1\u7b97\u6bcf\u6761\u66f2\u7ebf\u7684AUC\u503c\uff0c\u4e00\u822c\u8ba4\u4e3aAUC\u503c\u8d8a\u5927\u8d8a\u597d\u3002AUC\u503c\u7531\u5b9a\u4e49\u901a\u8fc7\u8ba1\u7b97ROC\u66f2\u7ebf\u3001\u6a2a\u8f74\u548c\u76f4\u7ebfFPR = 1\u4e09\u8005\u56f4\u6210\u7684\u9762\u79ef\u5373\u53ef\u5f97\u5230\uff0c\u901a\u5e38\u53d6\u503c\u57280.5-1.0\u95f4\uff0c\u8d8a\u5927\u8d8a\u597d\u3002\n\n<div align=center>\n    <img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/3\/36\/Roc-draft-xkcd-style.svg\/1920px-Roc-draft-xkcd-style.svg.png\" width = \"500\", height = \"600\">\n<\/div>\n\n\n### AUC\nAUC\u80fd\u6709\u6548\u5904\u7406\u4e0d\u5747\u8861\u6837\u672c\uff0c\u4e0b\u9762\u6a21\u62df\u51e0\u7ec4\u6570\u636e\u3002\n\n- \u7b2c1\uff0c\u7b2c2\u7ec4\u6570\u636e\u4e3a\u5747\u8861\u6837\u672c\uff1b\n- \u7b2c3\uff0c\u7b2c4\u7ec4\u6570\u636e\u4e3a\u4e0d\u5747\u8861\u6837\u672c\uff1b\n\n\u53ef\u4ee5\u53d1\u73b0\uff0c\u7b2c\u4e09\u7ec4\u6837\u672c\u54ea\u6015\u5168\u90e8\u9884\u6d4b\u4e3a\u6b63\u6837\u672c\uff0cAUC\u4f9d\u7136\u53ea\u67090.5\u3002","b316e997":"## \u6570\u636e\u63a2\u7d22","a58ca22f":"# \ud83d\udef8 \u5916\u661f\u4fe1\u53f7\u641c\u7d22 \ud83d\udc7d \u6570\u636e\u5206\u6790 & \u57fa\u7ebf\u6a21\u578b [\u5e03\u5c14\u827a\u6570 BoolArt]\n\n<div align=center>\n<img src=\"https:\/\/storage.googleapis.com\/kaggle-media\/competitions\/SETI-Berkeley\/DSC_4014-Edit_2.jpg\" width = \"600\" height = \"100\" alt=\"\u56fe\u7247\u540d\u79f0\">\n<\/div>\n   \n\n**\u201c\u6211\u4eec\u5728\u5b87\u5b99\u4e2d\u662f\u5b64\u72ec\u7684\u5417?\u201d**\u8fd9\u662f\u4eba\u7c7b\u6700\u6df1\u523b\u548c\u6c38\u6052\u7684\u95ee\u9898\u4e4b\u4e00\u3002","80147a40":"#### \u5f88\u5bb9\u6613\u53d1\u73b0\u7684\u4fe1\u53f7\n\n<div align=center>\n    <img src=\"https:\/\/i.imgur.com\/5ohQpvE.png\" width = \"500\", height = \"600\">\n<\/div>\n\n#### \u4e2d\u7b49\u96be\u5ea6\u4fe1\u53f7\n\n<div align=center>\n    <img src=\"https:\/\/i.imgur.com\/Pz6YdoV.png\" width = \"500\", height = \"600\">\n<\/div>\n\n<div align=center>\n    <img src=\"https:\/\/i.imgur.com\/81jL2N7.png\" width = \"500\", height = \"600\">\n<\/div>\n\n\n#### \u9ad8\u96be\u5ea6\u4fe1\u53f7\n\n<div align=center>\n    <img src=\"https:\/\/i.imgur.com\/Sgu0k7n.png\" width = \"500\", height = \"600\">\n<\/div>","e3fbb4ea":"### \u6570\u636e\u6587\u4ef6\n\n**train\/** - \u8bad\u7ec3\u96c6\uff0c\u7531numpy float16\u683c\u5f0f\u5b58\u50a8\u7684\uff086,273,256\uff09\u7ef4\u5ea6\u7684\u6570\u7ec4\uff0c\u7b2c1\u4e2a\u7ef4\u5ea6\u8868\u793a6\u4e2a\u8282\u594f\uff0c\u7b2c2\u548c3\u4e2a\u7ef4\u5ea6\u8868\u793a\u9891\u8c31\u4fe1\u53f7\uff0c\u6bcf\u4e2a\u6587\u4ef6\u5bf9\u5e94\u7684\u6807\u7b7e\u53ef\u4ee5\u5728train_labels.csv\u4e2d\u627e\u5230\u3002  \n**test\/** - \u6d4b\u8bd5\u96c6\uff0c\u6570\u636e\u7ed3\u6784\u4e0e\u8bad\u7ec3\u96c6\u4e00\u81f4\u3002  \n**sample_submission.csv\/** - \u63d0\u4ea4\u683c\u5f0f\u8303\u4f8b\u3002  \n**train_labels\/** - \u8bad\u7ec3\u96c6\u6570\u636e\u6807\u7b7e\u3002","a281d624":"### \u53ef\u89c6\u5316","98f62d50":"## \u57fa\u7ebf\u6a21\u578b\n\n\u9891\u8c31\u6570\u636e\u53ef\u4ee5\u770b\u62106\u901a\u9053\u56fe\u50cf\uff0c\u56e0\u6b64\u6211\u4eec\u7684\u57fa\u7ebf\u6a21\u578b\u91c7\u7528\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u8fc1\u79fb\u5b66\u4e60\u7f51\u7edc\uff1aEfficientNet-B1\uff0c\u7531\u4e8e\u6a21\u578b\u539f\u672c\u662f\u57fa\u4e8e\u666e\u901a3\u901a\u9053\u56fe\u50cf\u8bbe\u8ba1\u7684\uff0c\u56e0\u6b64\u6211\u4eec\u5728EfficientNet\u524d\u6dfb\u52a01x1\u5377\u79ef\u5c42\uff0c\u4f7f\u5f97\u901a\u9053\u6570\u91cf 6 -> 3\uff0c\u4fee\u6539\u6700\u540e\u4e00\u5c42\u5168\u8fde\u63a5\u7f51\u7edc\uff0c\u8f93\u51fa\u7ef4\u5ea6\u8c03\u6574\u4e3a1\u3002","1f90fbd6":"<a id=\"top\"><\/a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='color:white; background:Blue; border:0' role=\"tab\" aria-controls=\"home\"><center>\u76ee\u5f55\u5bfc\u822a<\/center><\/h3>\n    \n# \u76ee\u5f55\n\n* \u8d5b\u9898\u80cc\u666f\n* \u6570\u636e\u63a2\u7d22\n* \u8bc4\u4ef7\u6307\u6807\n* \u57fa\u7ebf\u6a21\u578b\n* \u540e\u7eed\u601d\u8def\n* \u5f15\u7528","9a20f33b":"## \u6539\u8fdb\u65b9\u5411\n\n- \u5c1d\u8bd5\u591a\u79cd\u9884\u8bad\u7ec3\u6a21\u578b\uff1aResNext, SENet\uff0cVit\u7b49\uff1b\n- \u5c1d\u8bd5\u53ea\u4f7f\u75286\u4e2a\u8282\u594f\u4e2d\u7684\uff0c1,3,5\u8282\u594f\uff1b\n- \u5c1d\u8bd5\u53cc\u5854\u67b6\u6784\uff0cA\u6a21\u578b\u4f7f\u75281,3,5\u8282\u594f\uff0cB\u6a21\u578b\u4f7f\u75282,4,6\u8282\u594f\uff0c\u5e76\u5728\u4e0d\u540c\u5c3a\u5bf8\u7279\u5f81\u56fe\u8fdb\u884c\u878d\u5408\uff0c\u8fdb\u884c\u9884\u6d4b\uff1b\n- \u62b5\u6297\u6837\u672c\u4e0d\u5747\u8861\u7684\u7b56\u7565\uff08\u635f\u5931\u51fd\u6570\u3001\u6837\u672c\u62bd\u6837\u7b49\uff09\uff1b\n- \u8fc7\u62df\u5408\uff1b\n- \u6a21\u578b\u878d\u5408\uff1b\n- \u65f6\u95f4\u5e8f\u5217\u6a21\u578b\uff1b\n\n\n**\u6b22\u8fceFollow\uff0c\u540e\u7eed\u4f1a\u6301\u7eed\u66f4\u65b0\u8fd9\u4e2a\u6bd4\u8d5b\u7684\u5f00\u6e90\u5185\u5bb9**"}}