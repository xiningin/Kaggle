{"cell_type":{"6874b908":"code","f660a62b":"code","92b25386":"code","8a3a5b64":"code","2cd677dc":"code","93fbcaac":"code","53df070c":"code","a3c7b137":"code","a1f5166a":"code","996906da":"code","b1e2999b":"code","217af7e2":"code","7902e095":"code","23cf53a5":"code","5e9715c6":"code","e8ec7ecf":"code","a7c1d0b8":"code","f3a72cae":"code","8136fe21":"markdown","94f93675":"markdown","8ac4d996":"markdown","0cb10e36":"markdown","27128258":"markdown","a26a89ae":"markdown","63fd096d":"markdown","a94346b9":"markdown","1d55735c":"markdown","9c2c9217":"markdown","e4584162":"markdown","2d481b52":"markdown","18214e4e":"markdown","1d1acb57":"markdown","d4f9dcca":"markdown","222a2915":"markdown","82a47ba4":"markdown","35af1c14":"markdown","4d1d25a6":"markdown","dbfbc7c1":"markdown","e018500a":"markdown","72a4582e":"markdown","608d5767":"markdown","0d7e0892":"markdown","978491e5":"markdown"},"source":{"6874b908":"# 1. First install packages:\ninstall.packages(\"tidyverse\")\ninstall.packages(\"lubridate\")\n\n# 2. Load Libraries:\nlibrary(tidyverse)\nlibrary(lubridate)\n\n#3. Load csv:\nhourly_steps <- read_csv(\"hourlySteps_merged.csv\")\n\n#4. Create a Data Frame:\nhourly_steps_df <- data.frame(hourly_steps)\n\n#5. Create a new date format in the current date column:\nhourly_steps_df$ActivityHour <-mdy_hms(hourly_steps_df$ActivityHour)\n\n#6. Write the new CSV File:\nwrite.csv(hourly_steps_df,\"hourly_steps_bqc.csv\",row.names=FALSE)\n\n#7. Now your csv file is compatible and ready for upload and use in Big Query.\n","f660a62b":"#Install packages:\ninstall.packages(\"dplyr\")\ninstall.packages(\"tidyr\")\ninstall.packages(\"skimr\")\ninstall.packages(\"janitor\")\ninstall.packages(\"ggplot2\")\n\n#Load Libraries:\nlibrary(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"skimr\")\nlibrary(\"janitor\")\nlibrary(\"ggplot2\")","92b25386":"#Load the following csv files:\ndaily_activity <- read_csv(\"dailyActivity_merged.csv\")\ndaily_sleep <- read_csv(\"sleepDay_merged.csv\")\nhourly_intensities <- read_csv(\"hourlyIntensities_merged.csv\")\nhourly_steps <- read_csv(\"hourlySteps_merged.csv\")\nhourly_calories <- read_csv(\"hourlyCalories_merged.csv\")\nheartrate_seconds <- read_csv(\"heartrate_seconds_merged.csv\")","8a3a5b64":"#Create the following Data frames:\ndaily_activity_df <-data.frame(daily_activity)\ndaily_sleep_df <-data.frame(daily_sleep)\nhourly_intensities_df <-data.frame(hourly_intensities)\nhourly_steps_df <-data.frame(hourly_steps)\nhourly_calories_df <-data.frame(hourly_calories)\nheartrate_seconds_df <-data.frame(heartrate_seconds_merged)","2cd677dc":"#Daily Data\nhead(daily_activity_df)\nhead(daily_sleep_df)","93fbcaac":"#Lets identify the columns in the daily_activity_df data.\ncolnames(daily_activity_df)\ncolnames(daily_sleep_df)","53df070c":"#Before we merge the data sets lets see how many unique participants are in each dataframe? \nn_distinct(daily_activity_df$Id)\nn_distinct(daily_sleep_df$Id)","a3c7b137":"#Now lets take a look at our hourly data sets.\nhead(hourly_intensities_df)\nhead(hourly_steps_df )\nhead(hourly_calories_df )","a1f5166a":"#Identify the columns in each of the datasets.\ncolnames(hourly_intensities_df)\ncolnames(hourly_steps_df)\ncolnames(hourly_calories_df)","996906da":"#Before we merge the data sets lets see how many unique participants are in each dataframe? \nn_distinct(hourly_intensities_df$Id)\nn_distinct(hourly_steps_df$Id)\nn_distinct(hourly_calories_df$Id)","b1e2999b":"How many observations are there in each dataframe?\nnrow(hourly_intensities_df)\nnrow(hourly_steps_df)\nnrow(hourly_calories_df)","217af7e2":"#Overview of our Heartrate data.\nHead(heartrate_seconds_df)","7902e095":"#Identify the columns in the heartrate data.\ncolnames(heartrate_seconds_df)","23cf53a5":"#Lets see how many unique participants are in each dataframe? \nn_distinct(heartrate_seconds_df$Id)","5e9715c6":"#How many observations are there in each dataframe?\nnrow(heartrate_seconds_df)\n","e8ec7ecf":"#Before we merge our data sets lets clean the date columns to remove the timestamp portion from the daily data sets.\n\ndaily_activity_df <- daily_activity_df %>% \nrename(Date = ActivityDate) %>% \nmutate(Date = as.Date(Date, format = \"%m\/%d\/%y\"))*\n\ndaily_sleep_df <- daily_sleep_df %>% \nrename(Date = SleepDay) %>% \nmutate(Date = as.Date(Date, format = \"%m\/%d\/%y\"))","a7c1d0b8":"#Let's clean up the format for later use:\nhourly_steps_df$ActivityHour=as.POSIXct(hourly_steps_df$ActivityHour, format=\"%m\/%d\/%Y %I:%M:%S %p\", tz=Sys.timezone())\nhourly_steps_df$time <- format(hourly_steps_df$ActivityHour, format = \"%H\")\nhourly_steps_df$date <- format(hourly_steps_df$ActivityHour, format = \"%m\/%d\/%y\")\nhourly_steps_df$Day <-  weekdays(hourly_steps_df$ActivityHour)\n\n## Cleaning the format:\nSteps_Day_group$Day <- factor(Steps_Day_group$Day, levels = c(\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\",\"Sunday\"))\n\n### Group the Steps hourly data frame by day and hour to create a new data frame:\nhourly_steps_df_g <- hourly_steps_df %>%\n  group_by(Day, time) %>%\n  drop_na() %>%\n  summarise(mean_StepTotal = mean(StepTotal))\n\n## Cleaning the format:\nhourly_steps_df_g$Day <- factor(hourly_steps_df_g$Day, levels = c(\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\",\"Sunday\"))\n\nRelationships between days of the week and average steps:\n\n## Get the start date and end date of intensity hourly data frame for later use\nmindate <- min(hourly_steps_df$date)\nmaxdate <- max(hourly_steps_df$date)\nTotalID <- n_distinct(hourly_steps_df$Id)\n","f3a72cae":"## Let's clean up the format for later use:\nheartrate_seconds_df$Time <- mdy_hms(heartrate_seconds_df$Time)\nheartrate_seconds_df$time <- format(heartrate_seconds_df$Time, format = \"%H\")\nheartrate_seconds_df$Day <-  weekdays(heartrate_seconds_df$Time)\nheartrate_seconds_df$week <-  week(heartrate_seconds_df$Time)\nheartrate_seconds_df$sec <- format(heartrate_seconds_df$Time, format = \"%S\")\n\n#Group by time and day\nHeartrate_day <- heartrate_seconds_df %>%\n  group_by(Day,time) %>%\n  drop_na() %>%\n  summarise(mean_Value = mean(Value)) \n\n#Group by seconds, hour\nHeartrate_day_3 <- heartrate_seconds_df %>%\n  group_by(Id,Day,time,) %>%\n  drop_na() %>%\n  summarise(mean_Value = mean(Value)) \n\n#group by time\nHeartrate_day_2 <- heartrate_seconds_df %>%\n  group_by(time) %>%\n  drop_na() %>%\n  summarise(mean_Value = mean(Value)) \n\n#group by week and time\nHeartrate_day_2 <- heartrate_seconds_df %>%\n  group_by(week, time) %>%\n  drop_na() %>%\n  summarise(mean_Value = mean(Value))","8136fe21":"## 3.3 Cleaning our data:","94f93675":"### Loading CSV files:\nNow lets load our our data files.","8ac4d996":"### Hourly Data Cleaning:","0cb10e36":"### Seconds Data: (Optional)\nLets take a look at the heartrate data. \n\nNote this is a big file and the standard **R Studio Cloud will crash** if you attempt to follow all the following steps below. \n\nThere are **two solutions** though:\n\n1. **Option one:** upgrade to 8gb \/ 4 cpu account. Then set the ram to \"8\" and cpu to \"4', then proceed to the steps below.\n\n2. **Option two:** upload the processed data set and proceed to step 3. The heavy conversations have already been done and the rest of the steps should run without crashing r studio.\n","27128258":"**Observation:** There are 2,483,658 values in each data set.","a26a89ae":"# Case Study: Bellabeat\n\nThis analysis is the final project of the Google Data Analytics Certificate.\n\n**This walk through is formatted to run in RStudio Cloud.**\n\n# 1. Ask\n\n## Business Challenge:\nBella beats is high-tech manufacturer of health-focused products for women. They are small company that wants to find new opportunities to grow its business. If they can leverage new opportunities they have the potential to become a big company.\n\n## Business Task:\n* Data collected from Bella beats smart watch users will reveal key insights into its consumers.\n* The current data collected needs to be analyzed to identify trends.\n* Any trends identified will be used to create recommendations for the company.\n\n## 1.2 Key Stakeholders:\n\n### Primary Stakeholders:\n* Ur\u0161ka Sr\u0161en: Bellabeat\u2019s co-founder and Chief Creative Officer.\n* Sando Mur: Mathematician and Bellabeat\u2019s co-founder.\n \n### Secondary Stakeholders:\n* Bellabeat marketing analytics team.","63fd096d":"**Observation:** There are three variables. It appears the time-stamp is in incremental 5 second sets. This means we will have a lot of rows. We will confirm how many in a later step.","a94346b9":"**Observation:** It looks like there are 33 user ID:s in each Dataset.","1d55735c":"# 2. Prepare\n\n## Data sources used:\n\n* The data collected for this case study is provided by Fibit and publicly made available by [Mobious](https:\/\/www.kaggle.com\/arashnic)\n\n* The data is available here if you want to download it. [Fitbit Data](https:\/\/www.kaggle.com\/arashnic\/fitbit) \n\n## Data Integrity: \nThe data used in this case study is public. We will take it at face valuable that it is credible because it is provided by FitBit fitness Tracker.\n\n## Data information and organization:\n1. The Fitbit users have consented to the submission of their tracking data.\n2. Other then the unique user ID there is no identifying personal information in the data sets.\n3. The data in these sets include: minute level output for physical activity, heart rate and sleep monitoring as well as daily activity and steps.\n4. The Kaggle data set contains **18 files** in csv format. \n5. There are a total of **38 unique user IDs**.\n6. File naming convention: **Snake format**.\n\n## New naming conventions:\n* Files are in snake name format, but  Author prefers the lower case\/underscore format for file management purposes.\n\n* We could convert the naming of file formats outside R before loading them into R studio.\n\n### Example:\n\nOld file name format looks like this: **\"dailyActivity_merged\"**\n\nNew file name format would look like this: **\"daily_activity_merged\"**\n\nFor the sake of time and continuity for other users we leave files as they are so other users can reproduce the same results. We will end up renaming the data set within R in the next step. The example above could be considerd practice though.\n\n## Data Limitations: \n* The format of the **time stamp** in many of the csv files is **not compatible with Google big query**. It will need to be converted if Big Query SQL is utilized.\n\n### How to convert a time stamp for compatibility in SQL (Optional).\n### Example:","9c2c9217":"### Daily Data Cleaning:","e4584162":"**Observation:** all three datasets have the 'Id' field - this can be used to merge the datasets.","2d481b52":"# 3. Process\n### Process medium: [R Studio Cloud](https:\/\/www.rstudio.cloud\/)\n\nWe will be using R Studio Cloud to process our datasets.","18214e4e":"## 3.2 Lets take a look at our data:\nWe will start first by getting a general overview of each data set.\n\n### Daily Data:","1d1acb57":"### 3.1 Creating Data frames:\nWe will create Data frames for the csv files we loaded to insure we preserve our original data.\n","d4f9dcca":"**Observation:** It looks like there are 14 user IDs in each Dataset.","222a2915":"**Observation:** It looks like there are 33 user ID:s in activity data, but only 24 Ids in the sleep data. \n\n**Hypothesis:** Not everyone tracks their sleep patterns.\n\n**Question:** Are the watches comfortable enough? ","82a47ba4":"## Prepare Data\n### Prepare medium: [R Studio Cloud](https:\/\/www.rstudio.cloud\/)\n\nWe will be using R Studio Cloud to prepare our datasets.\n\n### Installing and loading common packages and libraries:\nTo start, let\u2019s set up the environment by downloading and opening the necessary libraries for the analysis.","35af1c14":"### Seconds Data Cleaning:","4d1d25a6":"### Hourly Data:","dbfbc7c1":"* [Introduction](#section-one)\n* [Body](#section-two)\n    - [Subsection 1](#da)\n    - [Subsection 2](#anything-you-like)\n* [Conclusion](#section-three)","e018500a":"**Observation:** both datasets have the 'Id' field - this can be used to merge the datasets.","72a4582e":"<a id=\"section-one\"><\/a>\n# da","608d5767":"**Observation:** There are 22099 values in each data set.","0d7e0892":"**Observation:** This dataset has an 'Id' field - this can be used to merge the datasets.","978491e5":"* [Introduction](#section-one)\n* [Body](#section-two)\n    - [Subsection 1](#subsection-one)\n    - [Subsection 2](#anything-you-like)\n* [Conclusion](#section-three)"}}