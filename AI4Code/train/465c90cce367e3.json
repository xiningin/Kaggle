{"cell_type":{"e3cf7ce0":"code","2e52258f":"code","279d772a":"code","e5053767":"code","5fc8cbb6":"code","aa1fde8e":"code","baef9410":"code","ea682595":"code","7574900f":"code","6842498f":"code","fd8ba2d5":"markdown","79bb6e86":"markdown","009ab958":"markdown","0080b8c2":"markdown","d30199da":"markdown","d7c25073":"markdown","7560b98e":"markdown","566bbfa8":"markdown"},"source":{"e3cf7ce0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","2e52258f":"import bz2\ndef get_labels_and_texts(file):\n    labels = []\n    texts = []\n    for line in bz2.BZ2File(file):\n        x = line.decode(\"utf-8\")\n        labels.append(1 if int(x[9]) == 2 else 0)\n        texts.append(x[10:].strip())\n    return np.array(labels), texts\ntrain_labels, train_texts = get_labels_and_texts('\/kaggle\/input\/amazonreviews\/train.ft.txt.bz2')\ntest_labels, test_texts = get_labels_and_texts('\/kaggle\/input\/amazonreviews\/test.ft.txt.bz2')","279d772a":"import re\ndef text_normalization(texts):\n    normalized_text = []\n    for text in texts:\n        lower = text.lower()\n        no_punctuation = re.sub('[\\W]',r' ', lower)\n        no_non_ascii = re.sub('[^a-z0-1\\s]',r'', no_punctuation)\n        normalized_text.append(no_non_ascii)\n    return normalized_text\n\ntrain_texts = text_normalization(train_texts)\ntest_texts = text_normalization(test_texts)","e5053767":"train_texts[3]","5fc8cbb6":"train_labels[:7]","aa1fde8e":"from sklearn.feature_extraction.text import CountVectorizer\n\ncv = CountVectorizer(binary=True)\ncv.fit(train_texts)\nX = cv.transform(train_texts)\nX_test = cv.transform(test_texts)","baef9410":"X.head()","ea682595":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, train_labels, train_size = 0.75\n)\n\nfor c in [0.01, 0.05, 0.25, 0.5, 1]:\n    \n    lr = LogisticRegression(C=c)\n    lr.fit(X_train, y_train)\n    print (\"Accuracy for C=%s: %s\" \n           % (c, accuracy_score(y_val, lr.predict(X_val))))","7574900f":"lr.predict(X_test[29])","6842498f":"test_labels[29]","fd8ba2d5":"Text normalization: Text is made lowercase, punctuations replaced with space and non ascii characters are removed ","79bb6e86":"Block of Output after vectorization","009ab958":"Output labels","0080b8c2":"Vectorization of all text to convert each word into column with value '0' or '1' for word hit or not . \n","d30199da":"Logistic Regression to predict sentiment with a set of C values to identify perfect fit","d7c25073":"Looks like c=0.5 works best.\n","7560b98e":"BZ2 format file is read using bz2 file decoder as well as creating columns (labels,text)","566bbfa8":"Output text"}}