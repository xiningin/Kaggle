{"cell_type":{"d3a8f238":"code","ae06b1c3":"code","cecc90ee":"code","1ee544bb":"code","fc01502a":"code","b64633c8":"code","9eec2e64":"code","45b68dd3":"code","12abecdb":"code","8b389531":"code","8df3207c":"code","2e9dfce2":"code","3bdf31e3":"code","69dda5da":"code","c92cd1b8":"code","ff338218":"code","bad6edb5":"code","d59e0afd":"code","2ad17604":"code","5d7a13ac":"code","edd2d7f6":"code","e404044f":"code","f6606e1d":"code","11021df6":"code","78ca8b90":"code","fdad1b77":"code","13ed190f":"code","f4038032":"code","ffa2fa54":"code","03ef8e53":"code","0eb9c3b3":"code","f8e254a0":"code","463390aa":"code","d39997cd":"code","b7e3250f":"code","b99303c3":"code","4a2ce2a4":"code","410c1391":"code","77dee2e9":"code","0e57d86f":"code","2dd282ca":"code","49529fea":"code","91999960":"code","0600a816":"code","59260888":"code","b8447cbb":"code","42a4b52b":"code","99ab64f7":"markdown","770d3e28":"markdown","19d5a5f0":"markdown","ac837686":"markdown","113c4c05":"markdown","c300271f":"markdown","4d66669b":"markdown","817178f6":"markdown","d1466bde":"markdown","1e99ab83":"markdown","8402e0ca":"markdown","420d05d2":"markdown","ee7a8c7f":"markdown","a5052934":"markdown","c34d550f":"markdown","a1d46471":"markdown","53f97824":"markdown","d2a511fd":"markdown","413fc418":"markdown","55107bb7":"markdown","6a962125":"markdown","ab521a86":"markdown","1449d8da":"markdown","2346254d":"markdown","cad90f5e":"markdown","df46536f":"markdown","f48c63f4":"markdown","ac63f71b":"markdown","ba4ab958":"markdown","63dc4804":"markdown","387fa1fb":"markdown"},"source":{"d3a8f238":"import numpy as np\nimport pandas as pd\n\n# Any results you write to the current directory are saved as output.\nimport os\nimport gc\nimport matplotlib.pyplot as plt\nimport json\n\nfrom collections import Counter","ae06b1c3":"# Input data files are available in the \"..\/input\/\" directory.\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","cecc90ee":"path = '\/kaggle\/input\/tensorflow2-question-answering\/'\ntrain_path = 'simplified-nq-train.jsonl'\ntest_path = 'simplified-nq-test.jsonl'\nsample_submission_path = 'sample_submission.csv'","1ee544bb":"train_line_count = 0\nwith open(path+train_path) as f:\n    for line in f:\n        line = json.loads(line)\n        train_line_count += 1\ntrain_line_count","fc01502a":"def read_data(path, sample = True, chunksize = 30000):\n    if sample == True:\n        df = []\n        with open(path, 'rt') as reader:\n            for i in range(chunksize):\n                df.append(json.loads(reader.readline()))\n        df = pd.DataFrame(df)\n    else:\n        df = pd.read_json(path, orient = 'records', lines = True)\n        gc.collect()\n    return df","b64633c8":"train = read_data(path+train_path, sample = True, chunksize=100000)\nprint(\"train shape\", train.shape)\ntrain[:10]","9eec2e64":"test = read_data(path+test_path, sample = False)\nprint(\"test shape\", test.shape)\ntest[:10]","45b68dd3":"sample_submission = pd.read_csv(path + sample_submission_path)\nprint(\"Sample submission shape\", sample_submission.shape)","12abecdb":"sample_submission[:10]","8b389531":"def missing_values(df):\n    df = pd.DataFrame(df.isnull().sum()).reset_index()\n    df.columns = ['features', 'n_missing_values']\n    return df","8df3207c":"missing_values(train)","2e9dfce2":"missing_values(test)","3bdf31e3":"train.columns","69dda5da":"# Question text\ntrain.loc[0, 'question_text']","c92cd1b8":"train.loc[0, 'document_text']","ff338218":"train.loc[0, 'document_text'].split()[:100]","bad6edb5":"train.loc[0, 'long_answer_candidates'][:10]","d59e0afd":"train['annotations'][:10]","2ad17604":"# Make a dataframe to accumulate answer types\nanswer_num_annotations = train.annotations.apply(lambda x: len(x))\nCounter(answer_num_annotations)","5d7a13ac":"train['annotations'][0]","edd2d7f6":"set().union(*(d[0].keys() for d in train['annotations']))","e404044f":"answer_summary = train['example_id'].to_frame()","f6606e1d":"answer_summary['annotation_id'] = train.annotations.apply(lambda x: x[0]['annotation_id'])","11021df6":"answer_summary[:10]","78ca8b90":"answer_yes_no = train.annotations.apply(lambda x: x[0]['yes_no_answer'])\nyes_no_answer_counts = Counter(answer_yes_no)\nyes_no_answer_counts","fdad1b77":"ks = [k for k in yes_no_answer_counts.keys()]\nvs = [yes_no_answer_counts[k] for k in ks]\n\nplt.bar(ks, vs)","13ed190f":"percent_yes_no = 1 - yes_no_answer_counts['NONE'] \/ sum(yes_no_answer_counts.values())\nprint(percent_yes_no, \"of the questions have yes\/no answers given\")","f4038032":"answer_yes_no_cleaned = answer_yes_no.apply(lambda x: None if x == 'NONE' else x)\nanswer_summary['has_yes_no'] = answer_yes_no_cleaned.apply(lambda x: x is not None)\nanswer_summary['yes_no'] = answer_yes_no_cleaned","ffa2fa54":"train.annotations.apply(lambda x: x[0]['short_answers'])[:10]","03ef8e53":"answer_short = train.annotations.apply(lambda x: [(y['start_token'], y['end_token']) for y in x[0]['short_answers']])\nnum_short_answers = answer_short.apply(lambda x: len(x))\nshort_answer_counts = Counter(num_short_answers)\nshort_answer_counts","0eb9c3b3":"ks = [k for k in short_answer_counts.keys()]\nks.sort()\nvs = [short_answer_counts[k] for k in ks]\n\nplt.bar(ks, vs)","f8e254a0":"percent_short = 1 - short_answer_counts[0] \/ sum(short_answer_counts.values())\nprint(percent_short, \"of the questions have at least one short answer\")","463390aa":"answer_summary['has_short_answers'] = num_short_answers.apply(lambda x: x>0)\nanswer_summary['num_short_answers'] = num_short_answers\nanswer_summary['answer_short'] = answer_short.apply(lambda x: x if len(x) > 0 else None)","d39997cd":"train.annotations.apply(lambda x: x[0]['long_answer'])[:20]","b7e3250f":"train.loc[0, 'annotations'][0]['long_answer']","b99303c3":"answer_long = train.annotations.apply(lambda x: (x[0]['long_answer']['start_token'], x[0]['long_answer']['end_token']))\nanswer_long_cleaned = answer_long.apply(lambda x: x if x != (-1, -1) else None)\nnum_long_answers = answer_long_cleaned.apply(lambda x: 1 if x else 0)\nlong_answer_counts = Counter(num_long_answers)\nlong_answer_counts","4a2ce2a4":"ks = [k for k in long_answer_counts.keys()]\nks.sort()\nvs = [long_answer_counts[k] for k in ks]\n\nplt.bar(ks, vs)","410c1391":"percent_long = 1 - long_answer_counts[0] \/ sum(long_answer_counts.values())\nprint (percent_long, \"of the questions have at least one long answer\")","77dee2e9":"answer_summary['has_long_answer'] = num_long_answers.apply(lambda x: x>0)\nanswer_summary['num_long_answers'] = num_long_answers\nanswer_summary['answer_long'] = answer_long_cleaned","0e57d86f":"candidate_indices = train.annotations.apply(lambda x: (x[0]['long_answer']['candidate_index']))","2dd282ca":"answer_summary['long_candidate_index'] = candidate_indices","49529fea":"answer_summary[:10]","91999960":"summary = answer_summary.apply(lambda row: \n                               True if (row['has_yes_no'] or row['has_short_answers'] or row['has_long_answer'])\n                               else False, axis=1)\nsummary[:10]","0600a816":"Counter(summary)","59260888":"answer_summary[\"summary\"] = summary","b8447cbb":"answer_summary.groupby(['has_yes_no', 'has_short_answers', 'has_long_answer']).size().reset_index()","42a4b52b":"answer_summary[:10]","99ab64f7":"Clean column and save in summary","770d3e28":"Also look at the candidate indices.","19d5a5f0":"### Long answer candidates\n'A JSON array containing all of the plausible long answers'.\nThere seem to be a lot of these. Each one has a start_token and an end_token in the text, to delimit where the long answer is.\nThere is also a 'top_level' field.","ac837686":"So we have a start token and an end token, similar to the short answers.\nThe candidate index is the index into the list of candidate answers.","113c4c05":"### Yes-No","c300271f":"## Annotations Analysis\nAnnotations is a JSON array containing all of the correct long + short answers. Only provided for train.\nWe will build a reformulated data frame around the annotations.","4d66669b":"# File Description\n\n* simplified-nq-train.jsonl - the training data, in newline-delimited JSON format.\n* simplified-nq-kaggle-test.jsonl - the test data, in newline-delimited JSON format.\n* sample_submission.csv - a sample submission file in the correct format","817178f6":"Clean columns and save in summary","d1466bde":"# Data fields\n* document_text - the text of the article in question (with some HTML tags to provide document structure). The text can be tokenized by splitting on whitespace.\n* question_text - the question to be answered\n* long_answer_candidates - a JSON array containing all of the plausible long answers.\n* annotations - a JSON array containing all of the correct long + short answers. Only provided for train.\n* document_url - the URL for the full article. Provided for informational purposes only. This is NOT the simplified version of the article so indices from this cannot be used directly. The content may also no longer match the html used to generate document_text. Only provided for train.\n* example_id - unique ID for the sample.","1e99ab83":"So we know about all our keys.","8402e0ca":"# Missing Values\nWhat columns we have and whether or not we have missing values","420d05d2":"Count how many have both a yes-no and at least one short answer; also how many have both short and long answers.","ee7a8c7f":"### Question text\nThe question as a text string. Note that it is not tokenized.","a5052934":"### Long Answers","c34d550f":"### Summary","a1d46471":"### Document text\n'The text of the article in question (with some HTML tags to provide document structure). The text can be tokenized by splitting on whitespace.'\nThis is a huge wikipedia text, where we need to find the answer for the previous question\nNote that they give the tokenization method they expect us to use.","53f97824":"# Load Data","d2a511fd":"Update the summary.","413fc418":"### Short Answers","55107bb7":"So there is only ever one annotation in the train data.\nLet us explore how well the annotations are structured. First we will find out what things are in the annotations.","6a962125":"### Annotations\n'A JSON array containing all of the correct long + short answers. Only provided for train.'\nThis defines the target we are training on.","ab521a86":"So in the training data there is either a yes-no answer or short answers, but not both.","1449d8da":"* This is our target variable. In this case this is telling us that our long answer starts in indices 1952 and end at indices 2019.\n* Also, we have a short answer that starts a indices 1960 and end at indices 1969.\n* In this example we dont have a yes or no answer","2346254d":"# What the train data looks like","cad90f5e":"Here is the final summary dataframe","df46536f":"So a large majority of the questions do not have any short answers. Of the remaining, most have only one short answer. The longest list is one question that has 21 answers.","f48c63f4":"Great we don't have missing values.","ac63f71b":"Looks like about half our training set consists of questions for which the document does not contain an answer.","ba4ab958":"The dataset is huge, for exploration purpose we are going perform the exploratory analysis over a sample of the dataset. Let's read the training data and extract a sample (hopefully the dataset is shuffled so that the first records are random)","63dc4804":"The submission file has 692 rows, this means that for each row in the test set (there are 346) we have to predict both the short and long answer.\nThe short answer may also be a Yes or No answer.","387fa1fb":"How many of the questions have some answer?"}}