{"cell_type":{"e4fa0974":"code","7f078629":"code","d1f45ba5":"code","025d2c9d":"code","1bdb529d":"code","fd126cfa":"code","44cc4280":"code","6e7098e8":"code","60330cdb":"code","ac5c0636":"code","94b28006":"code","cba6e162":"code","8c0e15c8":"code","d0cdc219":"markdown","a8ea581d":"markdown","6cc3dbd8":"markdown","c2df7b86":"markdown","66fe643e":"markdown","b9208064":"markdown","b530333b":"markdown"},"source":{"e4fa0974":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score\nfrom sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n%matplotlib inline","7f078629":"test_csv = \"\/kaggle\/input\/test-set.csv\"\ntrain_csv = \"\/kaggle\/input\/train-set.csv\"","d1f45ba5":"train_df = pd.read_csv(train_csv)\ntest_df = pd.read_csv(test_csv)\ntrain_df.head()","025d2c9d":"features = train_df.drop([\"Id\", \"Cover_Type\"], axis=1).columns\nX_train, X_val, y_train, y_val = train_test_split(train_df[features], train_df[\"Cover_Type\"], test_size=0.2, random_state=42)","1bdb529d":"rf_clf = RandomForestClassifier(n_jobs=-1)\nrf_clf.fit(X_train, y_train)\ny_pred = rf_clf.predict(X_val)\nprint(\"Total precision: \" + str(1 - np.count_nonzero(y_val - y_pred) \/ len(y_val - y_pred)))\nscores = np.round(precision_score(y_val, y_pred, average=None), 3)\nfor i in range(0, 7):\n    print(\"    Class {0}: {1}\".format(i+1, scores[i]))\n\n#Total precision: 0.9209600544711757\n#    Class 1: 0.914\n#    Class 2: 0.928\n#    Class 3: 0.893\n#    Class 4: 0.911\n#    Class 5: 0.915\n#    Class 6: 0.891\n#    Class 7: 0.965","fd126cfa":"feat_importances = pd.Series(rf_clf.feature_importances_, index=features)\nfeat_importances.nlargest(30).iloc[::-1].plot(kind='barh', figsize=[10, 15], title=\"Top 30 important features\")","44cc4280":"def feature_engineering(in_df):\n    \n    rs_df = in_df\n    \n    rs_df['Dist_to_Hydrolody'] = (rs_df['Horizontal_Distance_To_Hydrology']**2 + rs_df['Vertical_Distance_To_Hydrology']**2 ) **0.5\n\n    rs_df['Elev_m_VDH'] = rs_df['Elevation'] - rs_df['Vertical_Distance_To_Hydrology']\n         \n    rs_df['Elev_p_VDH'] = rs_df['Elevation'] + rs_df['Vertical_Distance_To_Hydrology']\n         \n    rs_df['Elev_m_HDH'] = rs_df['Elevation'] - rs_df['Horizontal_Distance_To_Hydrology']\n         \n    rs_df['Elev_p_HDH'] = rs_df['Elevation'] + rs_df['Horizontal_Distance_To_Hydrology']\n     \n    rs_df['Elev_m_DH'] = rs_df['Elevation'] - rs_df['Dist_to_Hydrolody']\n         \n    rs_df['Elev_p_DH'] = rs_df['Elevation'] + rs_df['Dist_to_Hydrolody']\n\n    rs_df['Hydro_p_Fire'] = rs_df['Horizontal_Distance_To_Hydrology'] + rs_df['Horizontal_Distance_To_Fire_Points']\n     \n    rs_df['Hydro_m_Fire'] = rs_df['Horizontal_Distance_To_Hydrology'] - rs_df['Horizontal_Distance_To_Fire_Points']\n     \n    rs_df['Hydro_p_Road'] = rs_df['Horizontal_Distance_To_Hydrology'] + rs_df['Horizontal_Distance_To_Roadways']\n     \n    rs_df['Hydro_p_Road'] = rs_df['Horizontal_Distance_To_Hydrology'] - rs_df['Horizontal_Distance_To_Roadways']\n     \n    rs_df['Fire_p_Road'] = rs_df['Horizontal_Distance_To_Fire_Points'] + rs_df['Horizontal_Distance_To_Roadways']\n     \n    rs_df['Fire_m_Road'] = rs_df['Horizontal_Distance_To_Fire_Points'] - rs_df['Horizontal_Distance_To_Roadways']\n        \n    rs_df['Soil'] = 0\n    for i in range(1,41):\n        rs_df['Soil']= rs_df['Soil'] + i * rs_df['Soil_Type'+str(i)]\n        \n    rs_df['Wilderness_Area'] = 0\n    for i in range(1,5):\n        rs_df['Wilderness_Area'] = rs_df['Wilderness_Area'] + i * rs_df['Wilderness_Area'+str(i)]\n        \n    return rs_df\n\nnew_features = ['Elevation','Aspect','Slope','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology',\n    'Horizontal_Distance_To_Roadways','Hillshade_9am','Hillshade_Noon','Hillshade_3pm','Horizontal_Distance_To_Fire_Points',\n    'Elev_m_VDH', 'Elev_p_VDH', 'Dist_to_Hydrolody', 'Hydro_p_Fire', 'Hydro_m_Fire', 'Hydro_p_Road', 'Hydro_p_Road',\n    'Fire_p_Road', 'Fire_m_Road', 'Soil', 'Wilderness_Area', \n    'Elev_m_HDH', 'Elev_p_HDH', 'Elev_m_VDH', 'Elev_p_VDH', 'Elev_m_DH', 'Elev_p_DH']\nnew_features_df = feature_engineering(train_df)\nX_train, X_val, y_train, y_val = train_test_split(new_features_df[new_features], new_features_df[\"Cover_Type\"], test_size=0.2, random_state=42)","6e7098e8":"rf_clf = RandomForestClassifier(n_jobs=-1)\nrf_clf.fit(X_train, y_train)\ny_pred = rf_clf.predict(X_val)\nprint(\"Total precision: \" + str(1 - np.count_nonzero(y_val - y_pred) \/ len(y_val - y_pred)))\nscores = np.round(precision_score(y_val, y_pred, average=None), 3)\nfor i in range(0, 7):\n    print(\"    Class {0}: {1}\".format(i+1, scores[i]))\n    \n#Total precision: 0.939107656226358\n#    Class 1: 0.93\n#    Class 2: 0.948\n#    Class 3: 0.921\n#    Class 4: 0.902\n#    Class 5: 0.92\n#    Class 6: 0.914\n#    Class 7: 0.969","60330cdb":"feat_importances = pd.Series(rf_clf.feature_importances_, index=new_features)\nfeat_importances.nlargest(50).iloc[::-1].plot(kind='barh', figsize=[10, 15], title=\"Most important features\")","ac5c0636":"et_clf = ExtraTreesClassifier(n_jobs=-1)\net_clf.fit(X_train, y_train)\ny_pred = et_clf.predict(X_val)\nprint(\"Total precision: \" + str(1 - np.count_nonzero(y_val - y_pred) \/ len(y_val - y_pred)))\nscores = np.round(precision_score(y_val, y_pred, average=None), 3)\nfor i in range(0, 7):\n    print(\"    Class {0}: {1}\".format(i+1, scores[i]))\n    \n#Total precision: 0.9431078831895899\n#    Class 1: 0.934\n#    Class 2: 0.952\n#    Class 3: 0.931\n#    Class 4: 0.903\n#    Class 5: 0.916\n#    Class 6: 0.92\n#    Class 7: 0.969","94b28006":"param_grid = {\n    'n_estimators': [10, 50, 100, 250, 500, 700, 1000],\n    'max_depth': [None, 3, 10],\n    'criterion': ['gini', 'entropy'],\n    'min_samples_leaf': [1, 2, 10],\n    'max_features': [0.3, 0.5, 0.7, 0.9],\n    'bootstrap': [False, True],\n    'class_weight': [None, 'balanced', 'balanced_subsample']\n}\n\nbest_model = GridSearchCV(ExtraTreesClassifier(n_jobs=-1, verbose=1), param_grid, cv=5, verbose=10)\n#best_model.fit(X_train, y_train)","cba6e162":"et_clf = ExtraTreesClassifier(n_jobs=-1, max_features=0.5, n_estimators=900, verbose=1)\net_clf.fit(X_train, y_train)\ny_pred = et_clf.predict(X_val)\nprint(\"Total precision: \" + str(1 - np.count_nonzero(y_val - y_pred) \/ len(y_val - y_pred)))\nscores = np.round(precision_score(y_val, y_pred, average=None), 3)\nfor i in range(0, 7):\n    print(\"    Class {0}: {1}\".format(i+1, scores[i]))\n\n#Total precision: 0.952006733242548\n#    Class 1: 0.958\n#    Class 2: 0.951\n#    Class 3: 0.942\n#    Class 4: 0.929\n#    Class 5: 0.924\n#    Class 6: 0.917\n#    Class 7: 0.967","8c0e15c8":"best_model = ExtraTreesClassifier(max_features=0.5, n_estimators=900, n_jobs=-1, verbose=1)\nbest_model.fit(new_features_df[new_features], new_features_df[\"Cover_Type\"])\n\nsubmisson_data = best_model.predict(feature_engineering(test_df)[new_features])\nsubmission_df = pd.DataFrame(np.column_stack([test_df.Id.values, submisson_data]), columns=[\"Id\", \"Cover_type\"])\nsubmission_df.to_csv(\"\/kaggle\/working\/submission_txx.csv\", index=False)\nsubmission_df.head()","d0cdc219":"* We notice that **Elevation, Horizontal_Distance_To_Roadways, Horizontal_Distance_To_Fire_Points, Horizontal_Distance_To_Hydrology and Vertical_Distance_To_Hydrology** are the most important features so let's generate new features from the mix of these features.\n* Also **Horizontal_Distance_To_Hydrology and Vertical_Distance_To_Hydrology** are the same mesure from different axes so a better feature may be the hypotenuse of both.\n* Finally since we want to use ensemble learning algorithms (such as RandomForest), we need to have consistant features, so we to group all **Soil_TypeXX** columns in one column. Same for **Wilderness_AreaX**. In fact random forest train many small trees based on a subset of the feature, it's no approriate to take some of the **Soil_TypeXX** columnw without the others.","a8ea581d":"# Cover Type Prediction of Forests\n## Introduction\nThis kaggle competition is a multiclass classification problem. We have 7 classes to predict, with continuous and categorical features.","6cc3dbd8":"## Features engineering","c2df7b86":"## Initial import","66fe643e":"### Use ExtraTrees\nExtraTree is Extra Randomized Trees algorithms. It's similar to Random Forest with usually better performance. Here are more details:\nhttps:\/\/stats.stackexchange.com\/questions\/175523\/difference-between-random-forest-and-extremely-randomized-trees","b9208064":"### Final model\nThe final model is ExtraTreesClassifier with these parameters:\n* 900 estimators\n* 0.3 features per tree\n* Default for other parameters (bootstrap=False, class_weight=None, min_samples_leaf=1, criterion='gini', max_depth=None)","b530333b":"### Tune Hyperparameters\nLet's make a grid search with 5-folds. We want the best hyperparameter out of this list:\n* n_estimators [10, 50, 100, 250, 500, 700, 1000]\n* criterion ['gini', 'entropy']\n* max_depth [None, 3, 10]\n* min_samples_leaf [1, 2, 10]\n* max_features [0.3, 0.5, 0.7, 0.9]\n* bootstrap [False, True]\n* class_weight [None, 'balanced', 'balanced_subsample']\n\nHowever this my take many time and a lot of memory..."}}