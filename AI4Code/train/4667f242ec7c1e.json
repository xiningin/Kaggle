{"cell_type":{"d8ccf29c":"code","4b33e479":"code","3a00ed88":"code","509fbe96":"code","73b39e7e":"code","b2425b6a":"code","58875039":"code","24d4d818":"code","2b8c3663":"code","673c6c3e":"code","2546e138":"code","dfa95980":"code","c724cf23":"code","7030e14f":"code","4683e785":"code","e3d448ae":"markdown","cf8497a6":"markdown","778930fe":"markdown","4355042e":"markdown","9fe317a2":"markdown","0b0ed576":"markdown","cf685277":"markdown","e2b87390":"markdown","0db518df":"markdown","66811457":"markdown","6ed3755f":"markdown","5ca02057":"markdown","4959001d":"markdown","ce8bcd08":"markdown","96abcbd2":"markdown","ba603316":"markdown","8ff28efb":"markdown","4eeb595e":"markdown","f14b04b4":"markdown","013b8645":"markdown"},"source":{"d8ccf29c":"import pandas as pd\nimport numpy as np\nimport math\nfrom sklearn import linear_model # Needed for Linear Regression\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold # K-fold Cross-Validation\nfrom sklearn.model_selection import cross_val_score # Cross-Validation Score\nfrom sklearn.metrics import r2_score # R-Squared\nfrom scipy.stats import pearsonr","4b33e479":"Salary_Data = pd.read_csv(\"..\/input\/random-salary-data-of-employes-age-wise\/Salary_Data.csv\")\nSalary_Data.head()","3a00ed88":"x1 = Salary_Data.drop('Salary', axis=1).values # Maintain the dataframe by dropping the Salary column\ny1 = Salary_Data['Salary'].values              # Create a Pandas Series as the target variable.\n\nkfold = KFold(n_splits=5, shuffle=True, random_state=1)\n\nslr = linear_model.LinearRegression()\n\nresults_kfold = cross_val_score(slr, x1, y1, cv=kfold) # Stores the accuracy of each split in a Numpy array.\n\nprint(\"R\\N{SUPERSCRIPT TWO}: %.2f%%\" % (results_kfold.mean()*100.0))","509fbe96":"X = Salary_Data[['YearsExperience']]  # Note the double square brackets.  This must be a DataFrame.\ny = Salary_Data.Salary\n\nslr = linear_model.LinearRegression() # Create the linear regression model\n\nkf = KFold(n_splits=5, shuffle=True, random_state=1) # Set the k-fold parameters\nkf.split(X)","73b39e7e":"accuracy_model = []  # The average of this list is the overall R-Squared\nslope = []\nintercept = []\nresiduals = []       # These will be used to validate model assumptions\n\nfor train_index, test_index in kf.split(X):\n    print('Train: %s\\nTest: %s\\n' % (train_index, test_index))\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    model = slr.fit(X_train, y_train)\n    r2 = r2_score(y_test, model.predict(X_test))\n    accuracy_model.append(r2)\n    slope.append(slr.coef_)\n    intercept.append(slr.intercept_)\n    residuals.append(y_test-model.predict(X_test))","b2425b6a":"# This is the cross-validation score (aka the overall accuracy of the model)\n# round((sum(accuracy_model)\/len(accuracy_model))*100,2)\nprint(\"Average R\\N{SUPERSCRIPT TWO}: %.2f%%\" % ((sum(accuracy_model)\/len(accuracy_model))*100))","58875039":"plt.bar(range(1,6),accuracy_model)\nplt.title(\"R\\N{SUPERSCRIPT TWO} Values by Split\")\nplt.xlabel(\"Split\")\nplt.ylabel(\"R\\N{SUPERSCRIPT TWO} as a Decimal\")\ncaption=\"Random sampling led to Split 1 having a very low R\\N{SUPERSCRIPT TWO} value\"\nplt.figtext(0.5, -0.05, caption, wrap=True, horizontalalignment='center', fontsize=12, color=\"gray\")","24d4d818":"print('\\u03B2\\N{SUBSCRIPT ONE}: %.2f' % ((sum(slope)\/len(slope))))\nprint('\\u03B2\\N{SUBSCRIPT ZERO}: %.2f' % ((sum(intercept)\/len(intercept))))","2b8c3663":"corr_coeff = pearsonr(Salary_Data.YearsExperience, Salary_Data.Salary)\nprint('Pearson r= %.3f' % corr_coeff[0])\nprint('p-value= ' + str(corr_coeff[1]))","673c6c3e":"print(\"The mean of the residuals is %.2f\" % np.mean(residuals))","2546e138":"for train_index, test_index in kf.split(X):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    fold_residuals = y_test-model.predict(X_test)\n    plt.scatter(y_test.index, fold_residuals, color='#1f77b4')\n#     plt.scatter(y_test.index, fold_residuals)\n    plt.xlabel('Index')\n    plt.ylabel('Residuals')\n    plt.title(\"Residuals Plot\")\n    plt.axhline(0, color=\"#d62728\")","dfa95980":"for train_index, test_index in kf.split(X):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    fold_residuals = y_test-model.predict(X_test)\n#     plt.scatter(y_test.index, fold_residuals, color='#1f77b4') # This line makes all the dots blue\n    plt.scatter(y_test.index, fold_residuals) # This line colors the dots according to their assigned test fold\n    plt.xlabel('Index')\n    plt.ylabel('Residuals')\n    plt.title(\"Residuals Plot\")\n    plt.axhline(0, color=\"#d62728\")","c724cf23":"for train_index, test_index in kf.split(X):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    plt.scatter(y_test, slr.predict(X_test), color='#1f77b4')\n#     plt.scatter(y_test, slr.predict(X_test))\nplt.xlabel('Actual Salary')\nplt.ylabel('Predicted Salary')\nplt.title(\"Actual vs. Predicted Salaries\")\ny_lim = plt.ylim()\nx_lim = plt.xlim()\nplt.plot(x_lim, y_lim, 'k-', color =\"#d62728\")\nplt.ylim(y_lim)\nplt.xlim(x_lim)","7030e14f":"combined_residuals = pd.concat([residuals[0], residuals[1], residuals[2], residuals[3], residuals[4]], ignore_index=True)\nplt.hist(combined_residuals, bins=7)\nplt.title(\"Residuals Distribution\")\nplt.ylabel(\"Frequency\")\nplt.xlabel(\"Residual Amount\")","4683e785":"from scipy.stats import shapiro\n\nresid_sum = []\n\nfor train_index, test_index in kf.split(X):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    fold_residuals = y_test-model.predict(X_test)\n    resid_sum.append(fold_residuals)\n\nall_residuals = pd.concat([resid_sum[0],resid_sum[1],resid_sum[2],resid_sum[3],resid_sum[4]])\n\n# Thanks to Machine Learning Mastery for the Shapiro-Wilk code and tutorial!\n# https:\/\/machinelearningmastery.com\/a-gentle-introduction-to-normality-tests-in-python\/\n\nstat, p = shapiro(all_residuals)\nprint('Test Statistic=%.3f, p-value=%.3f' % (stat, p))\n# interpret\nalpha = 0.05\nif p > alpha:\n    print('Distribution of residuals looks Normal (fail to reject H0)')\nelse:\n    print('Distribution of residuals does not look Normal (reject H0)')","e3d448ae":"Lastly, we need to make sure the relationship between the predictor and response variables is significant with Pearson's r:","cf8497a6":"## Step 4. Check Assumptions","778930fe":"# Small Sample Regression with K-Fold Cross-Validation\n\nThis simple linear regression predicts salary as a function of years of experience.  It uses the \"salary\\_data of Employees with years of Experience\" dataset by <a href=\"https:\/\/www.kaggle.com\/harsh45\" target=\"blank_\">Harsh singh<\/a> and can be found <a href=\"https:\/\/www.kaggle.com\/harsh45\/random-salary-data-of-employes-age-wise\" target=\"blank_\">here<\/a>.\n\nThis small dataset only has 30 samples, so setting aside even a single random sample could have an impact on the line of best fit.  In searching for resampling methods, I came across k-fold cross-validation and decided it would be a good method to try.\n\n## Intro to k-fold Cross-Validation\n\nK-fold cross-validation divides the dataset into <i>k<\/i> equal segments called folds.  When the cross-validation function is run, <i>k-1<\/i> folds are used as training data, and the remaining fold is used as test data.  This process is repeated until each fold has been used as test data.  The cross-validation scores are averaged to obtain an overall model accuracy percentage, or $R^2$.\n\n*Note: Technically a few data points should be removed from the initial set to act as a final validation set that has never been seen by the model.  I didn't realize that until I was pretty much done, so I just decided to do that next time. :)*","4355042e":"I'd say this fit looks okay, but certainly not excellent.  There are a few more points above the line at lower salary levels and a few more points below the line at higher salary levels, meaning \\\\( \\beta_{0} \\\\) is a bit low and \\\\( \\beta_{1} \\\\) is a little too steep.","9fe317a2":"## Step 1. Hypothesize the Model\nThis is pretty straightforward.  There are only two variables, so this will be a simple linear regression with the response variable being **Salary** and the predictor variable being **Years of Experience**.\n\nHere is the hypothesized model: \\\\( y=\\beta_{0}+\\beta_{1}x+\\epsilon \\\\)","0b0ed576":"### Assumption 4: Errors are independent of one another\n\nLast, but not least, there is no indiciation that the salaries and years of experience in this data set are related to one another.  Absent any further information, they are assumed to be independent of one another.","cf685277":"**Side Note:** I discovered that by default, residuals are plotted by color according to fold (see below!).  It reminds me of Skittles, and I was sorely tempted to keep it, but I decided too many colors might be distracting, so I stuck with the conservative default blue. :)","e2b87390":"![Screen%20Shot%202020-05-26%20at%209.43.26%20PM.png](attachment:Screen%20Shot%202020-05-26%20at%209.43.26%20PM.png)","0db518df":"#### Predicted vs. Actual Plot","66811457":"### Assumptions 1 & 2: Mean of Error = 0, Variance of Error is constant\nAs you can see below, the mean of the residuals is 125.54.  That is definitely not zero, but where we are looking at numbers in the 50,000 - 100,000 range, I'm not too bothered by it.\n\nYou can see in the residuals plot below that there is a pretty good spread across all X values.  It's worth noting that there seem to be more negative values than positive values, but the largest residuals are positive.","6ed3755f":"## Step 3. Estimate Parameters\nLet's take a look at the estimated parameters.  The thing that surprised me most was the $R^2$ value.  I expected it to be much higher.  The bar chart below explains why: one of the splits happened to generate a validation fold that was not very accurate.","5ca02057":"Looks like they are highly correlated, with a correlation coefficient of 0.978 and a p-value of 1.143e-20.  In this test, the null hypothesis ($H_0$) is that there is no correlation between the two variables.  This significantly small p-value shows that there is no reasonable chance that we would see this strong of a correlation if the null hypothesis were true.  Reject that $H_0$!  Woohoo!","4959001d":"Let's see what the values are for \\\\( \\beta_{1} \\\\) and \\\\( \\beta_{0} \\\\):","ce8bcd08":"## Step 2. Collect the Data\n\nHere are the various packages installed for this exercise, as well as the first 5 rows of the `Salary_Data` dataframe:","96abcbd2":"## Two Ways to Calculate Model Accuracy with k-fold\n\nI hunted around for a while before finding any useful k-fold tutorials.  Most of them are very simple, just splitting a single array of `range(0,9)` to show how the function works, but it isn't very helpful without any real context around it.  Eventually I found two sites that were very helpful.  They showed a couple different ways to set up the k-fold.  Both work for determining the $R^2$ value, but, as you'll see below, I was able to use the second method for calculating much more than overall model accuracy.\n\nThese are the two sites I found most helpful:\n\n- <a href=\"https:\/\/financetrain.com\/k-fold-cross-validation-example-python-scikit-learn\/\" target=\"_blank\">FinanceTrain.com: K-Fold Cross Validation Example Using Python scikit-learn<\/a>\n- <a href=\"https:\/\/www.pluralsight.com\/guides\/validating-machine-learning-models-scikit-learn\" target=\"_blank\">Pluralsight.com: Validating Machine Learning Models with scikit-learn<\/a>\n\nIn both methods, the independent variable is created as a Pandas DataFrame, and the dependent variable is a Series.  I thought that was confusing.  It seemed like they should both work as Series.  I was mistaken!  As you'll see in the second method below, the independent variable is iterated over using `iloc`, which requires a DataFrame instead of a Series.  Thank you to my colleague <a href=\"https:\/\/www.linkedin.com\/in\/morgan-gladden-12ba41144\/\" target=\"_blank\">Morgan Gladden<\/a> for clearing that up for me!\n\nYou'll also notice the same k-fold parameters in both methods.  There are 5 splits, meaning the 30 data points will be split into 5 folds of 6 items each.  The `shuffle` parameter is set to `True` because the original dataset is arranged in ascending order, and the `random_state` is set to 1 for repeatability.\n\n*Note: The `random_state` of 1 actually returned the lowest $R^2$ value of state values 0-3.  I decided to keep it because it was the first number I chose, and I didn't want my pride to get in the way of the reality that sometimes random choice is a bummer \u00af\\\\\\_(\u30c4)\\_\/\u00af*","ba603316":"### Method 2: Using a For loop to store lots of cool things!\nThe first steps here are pretty much the same as Method 1.","8ff28efb":"You can see here that in Method 2 I used a For loop to store several different values from the split iterations.  The most important for the rest of this analysis is the `residuals` list, which you will see used a few more times in validating assumptions about the model.\n\nThe output below looks a little cluttered, but I wanted to print out the different splits so you can see how each fold uses different indexes (indices?) for the validation set.","4eeb595e":"## Reflection\nI learned a lot more from this project than I was expecting!  I actually created the first draft several weeks ago as a very quick practice of simple linear regression and left it alone for a while.  I came back to it because I wanted to update it to use a random seed to create repeatable results while still being able to shuffle the dataset.  I tried to import `random`, but that only works on Lists.\n\nOn top of that, I was only pulling out a single data point for validation, so I started searching for other techniques.  That's when I came across resampling and cross-validation techniques, and suddenly  there was a new world of possibilities! :)\n\nAs I noted at the top, if I were to go back and do this again, I would probably pull out three data points from the initial dataset and use them as a final validation set.  Next time!\n\nI'm also getting much more comfortable with different Python data types, Matplotlib, Markdown, and LaTeX.","f14b04b4":"### Assumption 3: Error is Normally distributed\nThe residuals histogram for this regression doesn't look totally normal to me, but the Shapiro-Wilk test below returned a p-value of 0.186, so I failed to reject the null hypothesis.  Thanks to Machine Learning Mastery for the <a href=\"https:\/\/machinelearningmastery.com\/a-gentle-introduction-to-normality-tests-in-python\/\" target=\"_blank\">Shapiro-Wilk code and tutorial!<\/a>","013b8645":"### Method 1: $R^2$ Only\n\nThe first method has 5 main steps:\n1. Create the independent and dependent variables.\n1. Set the k-fold parameters mentioned above.\n1. Create the linear regression model\n1. Create the variable `results_kfold` to store the cross-validation scores for each split, incorporating the `kfold` variable into the `cv` parameter.\n1. Obtain the $R^2$ by taking the mean of the cross-validation scores from the regression."}}