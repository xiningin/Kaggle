{"cell_type":{"c4508d29":"code","5d52a1da":"code","e842edd8":"code","3959bc36":"code","2434fc29":"code","6c705bda":"code","c4901373":"code","6506cb99":"code","ecb812d6":"code","68fa19e6":"code","b0313c03":"code","98fee638":"code","99d339eb":"code","a203539e":"code","af603233":"code","b85ca2ae":"code","5cd91c03":"code","046d1673":"code","44d70953":"code","ed60c9f4":"code","2c5f9b3b":"code","7701bfef":"code","8f6b4ee4":"code","620f5f64":"code","59616d6c":"code","dada396e":"code","dd14281b":"code","461a2374":"code","c4e50f88":"code","ac983bc3":"code","024d5ee3":"code","4ec1113e":"code","187ba8a3":"code","4fcee6ba":"code","3439c64d":"code","b30c0b5f":"code","c7803db7":"code","f0514c4b":"code","a22d45fc":"code","119509a4":"code","3d07652a":"code","6e1e7d89":"code","951247ed":"code","0bc1806c":"code","f679425f":"code","b6f0a3bb":"code","d4762018":"code","bfbb1f64":"code","21a3c139":"code","b486331c":"code","7fb5705a":"code","144dc874":"markdown","bd2b6dc7":"markdown","24ff42ed":"markdown","3a7ac862":"markdown","fd574191":"markdown","5219610e":"markdown"},"source":{"c4508d29":"#importing all important package..\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","5d52a1da":"#load data into pandas dataframe..\ndf = pd.read_csv('..\/input\/data.csv', encoding=\"ISO-8859-1\")","e842edd8":"df.head()","3959bc36":"#information of dataset..\ndf.info()","2434fc29":"#Country with high count must be taken for testing purpose... can we divide based on demographic or similar taste\n\ndf.Country.value_counts().head(5)\n\ndf = df[df.Country == 'United Kingdom']","6c705bda":"#checking distribution of quantity..\n\nsns.violinplot(df.Quantity)","c4901373":"df.Quantity.describe()","6506cb99":"#Quantity can not be negative so remove negative values..\ndf = df[df['Quantity']>0]\ndf.Quantity.describe()","ecb812d6":"#checking distribution of unit price..\nsns.violinplot(df.UnitPrice)","68fa19e6":"df = df[df['UnitPrice']>0]\ndf.UnitPrice.describe()","b0313c03":"#checking null values in all columns in dataset\nnull_values = pd.DataFrame(df.isnull().sum(),columns=['count_value'])\nax = sns.barplot(null_values.count_value,null_values.index)","98fee638":"df.dropna(subset=['CustomerID'],how='all',inplace=True)","99d339eb":"df.isnull().sum()","a203539e":"#last date available in our dataset\ndf['InvoiceDate'].max()","af603233":"#use latest date in our data as current date..\n\nimport datetime as dt\nnow = dt.date(2011,12,9)","b85ca2ae":"df['date'] = pd.DatetimeIndex(df.InvoiceDate).date","5cd91c03":"df.head()","046d1673":"#group by customer by last date they purchased...\n\nrecency_df = df.groupby(['CustomerID'],as_index=False)['date'].max()\nrecency_df.columns = ['CustomerID','LastPurchaseDate']\nrecency_df.head()","44d70953":"#calculate how often he is purchasing with reference to latest date in days..\n\nrecency_df['Recency'] = recency_df.LastPurchaseDate.apply(lambda x : (now - x).days)","ed60c9f4":"recency_df.head()","2c5f9b3b":"recency_df.drop(columns=['LastPurchaseDate'],inplace=True)","7701bfef":"#check frequency of customer means how many transaction has been done..\n\nfrequency_df = df.copy()\nfrequency_df.drop_duplicates(subset=['CustomerID','InvoiceNo'], keep=\"first\", inplace=True) \nfrequency_df = frequency_df.groupby('CustomerID',as_index=False)['InvoiceNo'].count()\nfrequency_df.columns = ['CustomerID','Frequency']\nfrequency_df.head()","8f6b4ee4":"#calculate how much a customer spend in the each transaction...\n\ndf['Total_cost'] = df['UnitPrice'] * df['Quantity']","620f5f64":"#check summed up spend of a customer with respect to latest date..\n\nmonetary_df=df.groupby('CustomerID',as_index=False)['Total_cost'].sum()\nmonetary_df.columns = ['CustomerID','Monetary']","59616d6c":"monetary_df.head()","dada396e":"#Combine all together all dataframe in so we have recency, frequency and monetary values together..\n\n#combine first recency and frequency..\nrf = recency_df.merge(frequency_df,left_on='CustomerID',right_on='CustomerID')\n\n#combibe rf frame with monetary values..\n\nrfm = rf.merge(monetary_df,left_on='CustomerID',right_on='CustomerID')\n\nrfm.set_index('CustomerID',inplace=True)","dd14281b":"rfm.head()","461a2374":"#checking correctness of output..\n\ndf[df.CustomerID == 12346.0]","c4e50f88":"(now - dt.date(2011,1,18)).days == 325","ac983bc3":"#bring all the quartile value in a single dataframe\n\nrfm_segmentation = rfm.copy()","024d5ee3":"from sklearn.cluster import KMeans\n# get right number of cluster for K-means so we neeed to loop from 1 to 20 number of cluster and check score.\n#Elbow method is used to represnt that. \nNc = range(1, 20)\nkmeans = [KMeans(n_clusters=i) for i in Nc]\nscore = [kmeans[i].fit(rfm_segmentation).score(rfm_segmentation) for i in range(len(kmeans))]\nplt.plot(Nc,score)\nplt.xlabel('Number of Clusters')\nplt.ylabel('Score')\nplt.title('Elbow Curve')\nplt.show()","4ec1113e":"#fitting data in Kmeans theorem.\nkmeans = KMeans(n_clusters=3, random_state=0).fit(rfm_segmentation)","187ba8a3":"# this creates a new column called cluster which has cluster number for each row respectively.\nrfm_segmentation['cluster'] = kmeans.labels_","4fcee6ba":"#check our hypothesis\n\nrfm_segmentation[rfm_segmentation.cluster == 0].head(10)","3439c64d":"'''\ncluster 0 have high recency rate which is bad. cluster 1 and cluster 2 having low so they are in race of platinum\nand gold customer.\n'''\nsns.boxplot(rfm_segmentation.cluster,rfm_segmentation.Recency)","b30c0b5f":"'''\ncluster 0 have low frequency rate which is bad. cluster 1 and cluster 2 having high so they are in \nrace of platinum and gold customer.\n'''\nsns.boxplot(rfm_segmentation.cluster,rfm_segmentation.Frequency)","c7803db7":"'''\ncluster 0 have low Monetary rate which is bad. cluster 1 have highest Montary (money spend) platinum where as \ncluster 2 have medium level(Gold) and cluster 0 is silver customer.\n'''\n\nsns.boxplot(rfm_segmentation.cluster,rfm_segmentation.Monetary)","f0514c4b":"# Arguments (x = value, p = recency, monetary_value, frequency, d = quartiles dict)\n\n#lower the recency, good for store..\ndef RScore(x,p,d):\n    if x <= d[p][0.25]:\n        return 1\n    elif x <= d[p][0.50]:\n        return 2\n    elif x <= d[p][0.75]: \n        return 3\n    else:\n        return 4\n    \n    \n# Arguments (x = value, p = recency, monetary_value, frequency, k = quartiles dict)\n\n#higher value of frequency and monetary lead to a good consumer. here higher value = 1 in reverse way.\n\ndef FMScore(x,p,d):\n    if x <= d[p][0.25]:\n        return 4\n    elif x <= d[p][0.50]:\n        return 3\n    elif x <= d[p][0.75]: \n        return 2\n    else:\n        return 1","a22d45fc":"'''\nquantile is like 25% , 50% and 75% level of values. example if we have 100 values first 25 in 1st quartile 25% \nthen second contain next 25% which is 50% and there after next 25% which is 75% and 4th quartile is more than 75% \nvalues.\n'''\nquantile = rfm.quantile(q=[0.25,0.5,0.75])\nquantile","119509a4":"rfm_segmentation['R_Quartile'] = rfm_segmentation['Recency'].apply(RScore,args=('Recency',quantile))\nrfm_segmentation['F_Quartile'] = rfm_segmentation['Frequency'].apply(FMScore, args=('Frequency',quantile))\nrfm_segmentation['M_Quartile'] = rfm_segmentation['Monetary'].apply(FMScore, args=('Monetary',quantile))","3d07652a":"quantile.to_dict()\n","6e1e7d89":"#calculate RFM score..\n\nrfm_segmentation['RFMScore'] = rfm_segmentation.R_Quartile.map(str) \\\n                            + rfm_segmentation.F_Quartile.map(str) \\\n                            + rfm_segmentation.M_Quartile.map(str)\nrfm_segmentation.head()","951247ed":"'''\nAnother possibility is to combine the scores to create one score (eg. 4+1+1). This will create a score \nbetween 3 and 12. Here the sdvantage is that each of the scores got same importance. However some scores \nwill have many sgements as constituents (eg - 413 ad 431)\n'''\n\nrfm_segmentation['Total_score'] = rfm_segmentation['R_Quartile'] + rfm_segmentation['F_Quartile'] + \\\nrfm_segmentation['M_Quartile']","0bc1806c":"rfm_segmentation.head()","f679425f":"print(\"Best Customers: \",len(rfm_segmentation[rfm_segmentation['RFMScore']=='111']))\nprint('Loyal Customers: ',len(rfm_segmentation[rfm_segmentation['F_Quartile']==1]))\nprint(\"Big Spenders: \",len(rfm_segmentation[rfm_segmentation['M_Quartile']==1]))\nprint('Almost Lost: ', len(rfm_segmentation[rfm_segmentation['RFMScore']=='134']))\nprint('Lost Customers: ',len(rfm_segmentation[rfm_segmentation['RFMScore']=='344']))\nprint('Lost Cheap Customers: ',len(rfm_segmentation[rfm_segmentation['RFMScore']=='444']))","b6f0a3bb":"rfm_segmentation.sort_values(by=['RFMScore', 'Monetary'], ascending=[True, False])","d4762018":"rfm_segmentation.groupby('RFMScore')['Monetary'].mean()","bfbb1f64":"rfm_segmentation.groupby('Total_score')['Monetary'].mean()","21a3c139":"'''\nBased on Monetary we see Total_score 3,4,5 have highest value which is good for model. because it could have\ncombination of values such as 111, 121, 122 etc.\n'''\nrfm_segmentation.groupby('Total_score')['Monetary'].mean().plot(kind='bar', colormap='Blues_r')","b486331c":"'''\nBased on Frequncy we see Total_score 3,4,5 have highest value which is good for model. because it could have\ncombination of values such as 111, 121, 122 etc.\n'''\nrfm_segmentation.groupby('Total_score')['Frequency'].mean().plot(kind='bar', colormap='Blues_r')","7fb5705a":"'''\nBased on Recency we see Total_score 10,11,12 have highest value which is good for model. because it could have\ncombination of values such as 444, 434, 334 etc.\n'''\n\nrfm_segmentation.groupby('Total_score')['Recency'].mean().plot(kind='bar', colormap='Blues_r')","144dc874":"Before starting RFM analysis we need to set objective and outcome of analysis, for this example goal is to define class of customer example - Platinum, Gold and Silver.\n1. Platinum customer - frequent and more revenue generator.\n2. Gold customer - frequent but less revenue generator.\n3. silver customer - less frequent and less revenue generator.","bd2b6dc7":"**RFM** is a method used for analyzing customer value. It is commonly used in database marketing and direct marketing and has received particular attention in retail and professional services industries\n\nRFM stands for the three dimensions:\n\n1. Recency \u2013 How recently did the customer purchase?\n2. Frequency \u2013 How often do they purchase?\n3. Monetary Value \u2013 How much do they spend?\n\n","24ff42ed":"# RFM (Recency Frequency Monetary) Analysis","3a7ac862":"# Optional steps if want to perform for more granularity.","fd574191":"**Always open for feedback and suggestions.If it helps Thumbs Up !!!**","5219610e":"Based on customer Segmentation we found out\ncluster 1 is Platinum customers\nCluster 2 is Gold Customers\nCluster 3 is Silver Customers"}}