{"cell_type":{"07492e7b":"code","5219cdc2":"code","a94615e9":"code","e0390ba4":"code","a5853ea6":"code","e0635044":"code","c9c29aa1":"code","fecd4a0e":"code","6599a42b":"code","fc21b828":"code","1c4b588f":"code","052a360a":"code","c9e7683a":"code","be330dbc":"code","c9675b86":"code","41ebc9de":"code","131a7e63":"code","7ed8e022":"code","1f730490":"code","7bfc45b5":"code","f213a72b":"code","8379675c":"code","cf824719":"code","0df42273":"code","2abedaf8":"code","a5d38fe1":"code","2d947352":"code","6b0256aa":"code","e0c9ccd3":"code","5c0d6a62":"code","1838cf09":"code","5d968885":"code","77895dbc":"code","1bc1de4d":"code","e9f44206":"code","d9b1f988":"code","4198d90c":"code","05c9c5d1":"code","78c70d9f":"code","e38516fe":"code","3df9e08c":"code","2ba19929":"code","442d22a9":"code","ab7ee86c":"code","1e2cba5e":"code","ab020ab7":"code","60c70135":"code","c6d7a39c":"code","fc98a67c":"code","a42c78a4":"code","70a08e2d":"code","65536b27":"code","a434b574":"code","0d7e745d":"code","5f151a2d":"code","55aaa366":"code","a6d77530":"code","82529d40":"code","7bb62cac":"code","7cff54fc":"code","426316fb":"code","bde7c5f3":"code","7d33fe0e":"code","f9ce3d1b":"code","c34b09f3":"code","bc674b66":"code","5e94a72c":"code","ad9baac0":"code","ff566a62":"markdown","f6ea6393":"markdown","b3efe043":"markdown","13aec7f9":"markdown","09519774":"markdown","fc905654":"markdown","2a59061e":"markdown","b030ebc1":"markdown","c966ef4a":"markdown","d1e1ed3f":"markdown","7102c7ea":"markdown","128a45ae":"markdown","64e7941e":"markdown","45b29446":"markdown","25eee663":"markdown","0744cf85":"markdown"},"source":{"07492e7b":"#let's import the libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","5219cdc2":"#get the data\nbig_data=pd.read_csv('..\/input\/bigmart-sales-data\/Train.csv')\nbig_data.head()","a94615e9":"#lets try to get some information from the data","e0390ba4":"big_data.shape","a5853ea6":"big_data.columns","e0635044":"big_data.info()","c9c29aa1":"big_data.describe()","fecd4a0e":"#let's find out the missing values\nbig_data.isnull().sum()","6599a42b":"sns.heatmap(big_data.isnull(),yticklabels=False)","fc21b828":"#let's plot the relationship b\/w nan value and dependent value\nsns.scatterplot(x=big_data['Item_Weight'],y=big_data['Item_Outlet_Sales'])","1c4b588f":"sns.barplot(x=big_data['Outlet_Size'],y=big_data['Item_Outlet_Sales'])","052a360a":"#let's get the numerical features\nnum_data=[feature for feature in big_data.columns if big_data[feature].dtype!='O']\nprint('Total no.of numerical values are: ',len(num_data))\nbig_data[num_data].head()","c9e7683a":"# list of variables that contain year information\nyear_feature = [feature for feature in num_data if 'Yr' in feature or 'Year' in feature]\n\nyear_feature","be330dbc":"big_data['Outlet_Establishment_Year'].unique()\n","c9675b86":"big_data.groupby('Outlet_Establishment_Year')['Item_Outlet_Sales'].median().plot()","41ebc9de":"## Numerical variables are usually of 2 types\n## 1. Continous variable and Discrete Variables\n\ndiscrete_data=[feature for feature in num_data if len(big_data[feature].unique())<25 and feature not in year_feature]\nprint(\"Discrete Variables Count: {}\".format(len(discrete_data)))","131a7e63":"continuous_data=[feature for feature in num_data if feature not in discrete_data and feature not in year_feature]\nprint(\"Continuous Variable Count : \",len(continuous_data))","7ed8e022":"big_data[continuous_data].head()","1f730490":"#let's visualize the continuous feature\nfor feature in continuous_data:\n    data=big_data.copy()\n    data[feature].hist(bins=25)\n    plt.xlabel(feature)\n    plt.ylabel(\"Count\")\n    plt.title(feature)\n    plt.show()\n","7bfc45b5":"cat_data=[feature for feature in big_data.columns if big_data[feature].dtype=='O']\nprint(\"Total no of Categorical data are : \",len(cat_data))\nbig_data[cat_data].head()","f213a72b":"for feature in cat_data:\n  print('Feature: {} , No.of categories: {}'.format(feature,len(big_data[feature].unique())))","8379675c":"#let's plot the relationship b\/w cat_data and dependent feature\nfor feature in cat_data:\n  data1=big_data.copy()\n  data1.groupby(feature)['Item_Outlet_Sales'].median().plot.bar()\n  plt.xlabel(feature)\n  plt.ylabel('Item_Outlet_Sales')\n  plt.title(feature)\n  plt.show()","cf824719":"big_data['Item_Fat_Content'].value_counts()","0df42273":"big_data.replace({'Item_Fat_Content': {'low fat':'Low Fat','LF':'Low Fat', 'reg':'Regular'}}, inplace=True)","2abedaf8":"big_data['Item_Fat_Content'].value_counts()","a5d38fe1":"#let us find the correlation b\/w each feature\nsns.heatmap(big_data.corr(),annot=True)","2d947352":"# let us visualize using pairplot\nsns.pairplot(big_data)","6b0256aa":"#Handling missing values\n## Now lets check for numerical variables the contains missing values\nnumerical_with_nan=[feature for feature in big_data.columns if big_data[feature].isnull().sum()>1 and big_data[feature].dtypes!='O']\n\n## We will print the numerical nan variables and percentage of missing values\n\nfor feature in numerical_with_nan:\n    print(\"{}: {}% missing value\".format(feature,np.around(big_data[feature].isnull().mean(),4)))","e0c9ccd3":"#let's replace them with its mean\nbig_data['Item_Weight']=big_data['Item_Weight'].fillna(big_data['Item_Weight'].mean())","5c0d6a62":"big_data['Item_Weight'].isnull().sum()","1838cf09":"#replace the nan value with mode\nmode_of_Outlet_size = big_data.pivot_table(values='Outlet_Size', columns='Outlet_Type', aggfunc=(lambda x: x.mode()[0]))","5d968885":"miss_values = big_data['Outlet_Size'].isnull()   ","77895dbc":"big_data.loc[miss_values, 'Outlet_Size'] = big_data.loc[miss_values,'Outlet_Type'].apply(lambda x: mode_of_Outlet_size[x])","1bc1de4d":"sns.heatmap(big_data.isnull())","e9f44206":"from sklearn.preprocessing import MinMaxScaler","d9b1f988":"scaler=MinMaxScaler()","4198d90c":"scaled_features=scaler.fit_transform(big_data[continuous_data])","05c9c5d1":"scaled_data=pd.DataFrame(scaled_features,columns=big_data[continuous_data].columns)","78c70d9f":"scaled_data.head()","e38516fe":"from sklearn.preprocessing import LabelEncoder","3df9e08c":"encoder = LabelEncoder()","2ba19929":"big_data['Item_Identifier'] = encoder.fit_transform(big_data['Item_Identifier'])\n\nbig_data['Item_Fat_Content'] = encoder.fit_transform(big_data['Item_Fat_Content'])\n\nbig_data['Item_Type'] = encoder.fit_transform(big_data['Item_Type'])\n\nbig_data['Outlet_Identifier'] = encoder.fit_transform(big_data['Outlet_Identifier'])\n\nbig_data['Outlet_Size'] = encoder.fit_transform(big_data['Outlet_Size'])\n\nbig_data['Outlet_Location_Type'] = encoder.fit_transform(big_data['Outlet_Location_Type'])\n\nbig_data['Outlet_Type'] = encoder.fit_transform(big_data['Outlet_Type'])","442d22a9":"big_data.head()","ab7ee86c":"big_data[continuous_data].columns","1e2cba5e":"big_data.drop(columns=['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Item_Outlet_Sales'],axis=1,inplace=True)","ab020ab7":"final_data=pd.concat([big_data,scaled_data],axis=1)","60c70135":"final_data.head()","c6d7a39c":"from sklearn.model_selection import train_test_split","fc98a67c":"X=final_data.drop('Item_Outlet_Sales',axis=1)\ny=final_data['Item_Outlet_Sales']","a42c78a4":"from sklearn.linear_model import SGDRegressor","70a08e2d":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.03,random_state=102)","65536b27":"sgd=SGDRegressor(max_iter=1000,penalty=None,eta0=0.001)","a434b574":"model=sgd.fit(X_train,y_train)","0d7e745d":"y_pred=model.predict(X_test)","5f151a2d":"from sklearn.metrics import mean_absolute_error,mean_squared_error","55aaa366":"print('MSE: ',mean_squared_error(y_test,y_pred))\nprint('MAE: ',mean_absolute_error(y_test,y_pred))\nprint('RMSe: ',np.sqrt(mean_squared_error(y_test,y_pred)))","a6d77530":"from sklearn.tree import DecisionTreeRegressor\nd_tree=DecisionTreeRegressor()\nmodel=d_tree.fit(X_train,y_train)\n","82529d40":"predict=d_tree.predict(X_test)","7bb62cac":"from sklearn import metrics\nprint('MAE: ',metrics.mean_absolute_error(y_test,predict))\nprint('MSE: ',mean_squared_error(y_test,predict))\nprint('RMSE: ',np.sqrt(mean_squared_error(y_test,predict)))","7cff54fc":"from sklearn.ensemble import RandomForestRegressor","426316fb":"rf=RandomForestRegressor()\n\nmodel = rf.fit(X_train,y_train)","bde7c5f3":"y_pred=model.predict(X_test)","7d33fe0e":"print('MSE: ',mean_squared_error(y_pred,y_test))\nprint('MAE: ',mean_absolute_error(y_pred,y_test))\nprint('RMSE: ',np.sqrt(mean_squared_error(y_pred,y_test)))","f9ce3d1b":"import xgboost as xgb\n","c34b09f3":"xg_boost=xgb.XGBRegressor()","bc674b66":"model_1=xg_boost.fit(X_train,y_train)","5e94a72c":"predict_1=model_1.predict(X_test)","ad9baac0":"print(metrics.mean_absolute_error(y_test,predict_1))\nprint(mean_squared_error(y_test,predict_1))\nprint(np.sqrt(mean_squared_error(y_test,predict_1)))","ff566a62":"From this we can see that almost all the values are not corelated to each other.","f6ea6393":"**Let's standardize the numerical values using MinMaxScaler**\n\n","b3efe043":"**Using Descision Tree Regressor**\n\n","13aec7f9":"**Using Stochastic Gradient Descent**","09519774":"**Handling Categorical values using LabelEncoder**","fc905654":"**Exploratory Data Analysis**","2a59061e":"**Using XGboost**","b030ebc1":"<a href=\"https:\/\/colab.research.google.com\/github\/Suchitra-V31\/Machine-learning-projects\/blob\/main\/BigMart_Data.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","c966ef4a":"Now we have replaced all the missing values and there is no nan values present in the data","d1e1ed3f":"**Categorical Features**","7102c7ea":"From this we can see in the Item_Fat_Content it has similar features repeated..so let's replace them.\n","128a45ae":"**BigMart Sales Data**\n","64e7941e":"**Using Random Forest Regressor**","45b29446":"Our data is ready...let us train our data","25eee663":"We have handled all our features and now we can conactenate all the standardized features in a new dataframe.","0744cf85":"**Feature Engineering**"}}