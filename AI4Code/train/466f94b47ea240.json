{"cell_type":{"0f0b9fcc":"code","ac647654":"code","fb49ac4a":"code","0c7d963e":"code","f7bc5670":"code","0484aadc":"code","a4394dc8":"code","c1c261dd":"code","9ce4d9cf":"code","27e688f2":"code","e97fddff":"markdown","5680e651":"markdown","a53a0ceb":"markdown","e7662f29":"markdown","4f191a83":"markdown"},"source":{"0f0b9fcc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ac647654":"file = '..\/input\/loan-default-prediction\/Default_Fin.csv'\nimport pandas as pd \ndf = pd.read_csv(file)","fb49ac4a":"# lets view the file\ndf","0c7d963e":"# first we check for null values \ndf.isnull().sum()","f7bc5670":"# lets check the statistical summary of the dataset\ndf.describe()","0484aadc":"# lets view with more detail using a pairplot\nimport seaborn as sns \nsns.pairplot(df)","a4394dc8":"# lets set the index with employment as its relatively close linked with default rates\ndf.set_index('Employed')","c1c261dd":"# lets further visualize as we can see errors in the analysis comments easrlies based on the view now\ndf.plot.scatter('Employed', 'Defaulted?', s=3, title='Employee per default')","9ce4d9cf":"import matplotlib.pyplot as plt \nplt.hist(df['Annual Salary'])","27e688f2":"# show valye layers for better data driven insights\ndefault = df['Defaulted?']\nSalary = df['Annual Salary']\ndf.loc[default, Salary] = np.nan\n\n# compare the levels of corrupted values in refrence to the original value\nplt.hist(Salary, label='Salary level', histtype='step')\nplt.hist(default, label='Defaulted', histtype='step')\nplt.legend(), plt.xlabel('Default')","e97fddff":"# We are noticing an unsual trend as the default rate is the same for an unemployed and employed person thus we need to look into other factors","5680e651":"**We can say by looking at this data that we have attributes if financial metrics and employment reliability and have to determine how to measure the prediction of who will default next based on this**","a53a0ceb":"# Based on the Summary we can here analyse that in the Minimum row that defaulting on alona does seem to have a relationship with employment as where there is Employment there is also the ability to apply for a loan and thus the probability of defaulting on its as well","e7662f29":"# We can see here that that employment has a coniditional relationship with Defaulting, While it varies in Annual Salaries and bank balance","4f191a83":"**Since we have no null values we shall directly proceed to Exploratory Data Analysis in measuring in generating insightful information about the dataset**"}}