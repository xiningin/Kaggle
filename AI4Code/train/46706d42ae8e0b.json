{"cell_type":{"63c06d4a":"code","e1d1ba81":"code","141ac7c5":"code","5854016d":"code","ccafd2aa":"code","c5962684":"code","50b600fc":"code","0b1b022f":"code","8eeab6a1":"code","552e372f":"code","868471f6":"code","bbd62799":"code","5ca07a2f":"code","c648c4a1":"code","4824fe7d":"code","30a88c96":"code","7c70342e":"code","408ba2db":"code","66b4cb99":"code","6782bbe5":"code","c2ad5e0b":"code","02d48a53":"code","1c2cd1f3":"code","4221de40":"code","3c7dff59":"code","c7504746":"code","8913a9f7":"code","d3cb2749":"code","bc7ac509":"code","f639219d":"code","1d189068":"code","68bcb1d4":"code","74d7f4f5":"code","e4e98e29":"code","96b0ab50":"code","0a6d605f":"code","153eca03":"code","e997f3e6":"code","125b0099":"code","2c9f0b7f":"code","19830761":"code","1996d3d9":"markdown","d206b878":"markdown","37803cfa":"markdown","b7d3a645":"markdown","3544d059":"markdown","3ca02c74":"markdown","10198d83":"markdown","dadec5ac":"markdown","70013f88":"markdown","8322b0a8":"markdown","caef90a2":"markdown","f5351d89":"markdown","a72d130c":"markdown","1d74428b":"markdown","aa164bda":"markdown","ac0458b1":"markdown","536facee":"markdown","2ead3662":"markdown","3f4cef77":"markdown","f8672ffd":"markdown","b3f5b2ad":"markdown","a2ca16a7":"markdown","5e5eee82":"markdown","00962210":"markdown","6a235088":"markdown","a8d76f67":"markdown","293fa661":"markdown","a8c4e71f":"markdown","896dc5a2":"markdown","9443211d":"markdown","54c06d4e":"markdown","18b85055":"markdown","4959d9c0":"markdown","aa7887c3":"markdown","a1251d94":"markdown","fa943c4c":"markdown","0406d812":"markdown"},"source":{"63c06d4a":"import pandas as pd\ndf = pd.read_csv('\/kaggle\/input\/riga-real-estate-dataset\/riga_re.csv')\n# Printing top 5 rows\ndf.head(5)","e1d1ba81":"# Checking total amount of rows in given dataset\nlen(df)","141ac7c5":"# Printing out unique values of a column\ndf.op_type.unique()","5854016d":"# Grouping by operation type and getting statistics within groups\ndf_by_op_type = df.groupby('op_type')\ndf_by_op_type.describe()\n","ccafd2aa":"df_filt = df[~df['op_type'].isin(['Change', 'Other', 'Buying', 'Renting'])]\nlen(df_filt)","c5962684":"df_filt.district.unique()","50b600fc":"for col in ['floor', 'total_floors']:\n    print(col, \":\", sorted(df_filt[col].unique()))","0b1b022f":" for col in ['house_seria', 'house_type', 'condition']:\n    print(col, \":\", df_filt[col].unique())\n    ","8eeab6a1":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nviz=df_filt.plot(kind='scatter', x='lon', y='lat', alpha=0.4, figsize=(10,10))\nviz.legend()","552e372f":"wrong = df_filt[(df_filt['lat'] < 55)|(df_filt['lat'] > 58)|(df_filt['lon'] < 24)|(df_filt['lon'] > 25)]\nlen(wrong)","868471f6":"df_filt = df_filt[~((df_filt['lat'] < 55)|(df_filt['lat'] > 58)|(df_filt['lon'] < 24)|(df_filt['lon']>25))]\nviz=df_filt.plot(kind='scatter', x='lon', y='lat', alpha=0.4, figsize=(10,10))\nviz.legend()","bbd62799":"import folium\n# Define helper function to plot over Riga map\ndef plot_on_riga_map(data_frame): \n    riga_map = folium.Map(\n        location=[56.946285, 24.105078],\n        tiles='cartodbpositron',\n        zoom_start=12,\n    )\n    data_frame.apply(lambda row:folium.Marker(location=[row[\"lat\"], row[\"lon\"]]).add_to(riga_map), axis=1)\n    return riga_map","5ca07a2f":"plot_on_riga_map(df_filt[~df_filt['lon'].isna()].head(500))","c648c4a1":"def missing(df):\n    df_missing = pd.DataFrame(df.isna().sum().sort_values(ascending = False), columns = ['missing_count'])\n    df_missing['missing_share'] = df_missing.missing_count \/ len(df)\n    return df_missing","4824fe7d":"missing(df_filt)","30a88c96":"# Let's take a look at some samples with missing coordinates\ndf_filt.loc[df_filt['lon'].isna()].head(10)","7c70342e":"from geopandas.tools import geocode\ndef geocode_safely(address):\n    try: \n        return geocode(address, provider=\"nominatim\").geometry.iloc[0]\n    except: \n        return 'Not found'\n   \n\nprint(\"1.\", geocode_safely('Viestura pr. 47'))\nprint(\"2.\", geocode_safely('Viestura prospekts 47'))","408ba2db":"# Inspect all street names of samples without geo coordinates to find abbreviation patterns\ndf_filt.loc[df_filt['lon'].isna(), 'street'].tolist()","66b4cb99":"# Constructing dictionary mappings from abbreviations to full values\nabbrs = {\n  \"Asteres\": \"Aisteres iela\",\n  \"M. Kuld\u012bgas\": \"Maz\u0101 Kuld\u012bgas iela\",\n  \"M. Nomet\u0146u\": \"Maz\u0101 Nomet\u0146u iela\",\n  \"Pulkv. Brie\u017ea\": \"Pulkve\u017ea brie\u017ea iela\",\n  \"J. V\u0101cie\u0161a\": \"Jukuma V\u0101cie\u0161a iela\",\n  \"J. Dali\u0146a\": \"J\u0101\u0146a Dali\u0146a iela\",\n  \"pr.\": \"prospekts\",\n  \"l.\": \"l\u012bnija\",\n  \"\u0161.\" : \"\u0161oseja\",\n  \"d.\": \"dambis\",\n  \"g.\": \"gatve\",\n  \"lauk.\": \"laukums\",\n  \"bulv.\": \"bulv\u0101ris\",\n  \"krastm.\": \"krastmala\",\n  \"\u0161\u0137 l\u012bnija\": \"\u0161\u0137\u0113rsl\u012bnija\",\n  \"\u0161\u0137. l\u012bnija\": \"\u0161\u0137\u0113rsl\u012bnija\",\n  \"M.\": \"mazais\",  \n  \"432k1\": \"432-k-1\",\n  \"252k5\": \"252-k-5\"\n}\n# Defining helper method to unabbreviate address\ndef unabbreviate(address):\n    # 1. Replace abbreviations\n    for abbr, full in abbrs.items():\n        address = address.replace(abbr, full)\n     \n    streetTypes = list(abbrs.values())\n    # 2. If address does not contain word \"street\" (\"iela\" in Latvian) and none of manually abbreviated values\n    # -> add \"iela\" as a second word in address\n    if (\"iela\" not in address) & (not any(s in address for s in streetTypes)):\n        words = address.split(\" \")\n        words.insert(1,\"iela\")\n        address = \" \".join(words)\n    # 3. Finally, append \"R\u012bga\" at the end of address if not present\n    if \"R\u012bga\" not in address:\n        address += \", R\u012bga\"\n    return address\n    \ndf_filt.loc[df_filt['lon'].isna(), 'street'] = df_filt.loc[df_filt['lon'].isna()].street.apply(unabbreviate)\ndf_filt.loc[df_filt['lon'].isna(), 'street'].tolist()","6782bbe5":"from geopandas.tools import geocode\nfrom geopy.extra.rate_limiter import RateLimiter\n\n# Delay between geocode calls to prevent it from failures\ngeocode = RateLimiter(geocode, min_delay_seconds=1)\n\ndef get_lat_lon(address):\n    try:\n        point = geocode(address, provider='nominatim').geometry.iloc[0]\n        return pd.Series({'lat': point.y, 'lon': point.x})\n    except:\n        return pd.Series({'lat': None, 'lon': None})\n\n# Running this will take roughly 3 minutes due to artificial delay between geocode calls\ndf_filt.loc[df_filt['lon'].isna(), ['lat','lon']] = df_filt.loc[df_filt['lon'].isna()].street.apply(get_lat_lon)\nlen(df_filt.loc[df_filt['lon'].isna()])","c2ad5e0b":"df_filt.loc[df_filt['lon'].isna()]","02d48a53":"df_filt = df_filt[df_filt.street != 'Lauvu iela 22, R\u012bga']","1c2cd1f3":"missing(df_filt)","4221de40":"df_filt.loc[df_filt['district'].isna()]","3c7dff59":"df_filt.loc[df_filt.street.str.startswith('Og\u013cu')]","c7504746":"df_filt.loc[df_filt.street == 'Og\u013cu 32', 'district'] = '\u0136\u012bpsala'","8913a9f7":"df_filt.loc[df_filt.street.str.startswith('Pupuku')]","d3cb2749":"df_filt.loc[df_filt.street == 'Pupuku iela 9', 'district'] = 'Valdlau\u010di'","bc7ac509":"missing(df_filt)","f639219d":"df_filt.rooms.unique()","1d189068":"df_filt.loc[df_filt['rooms'] == 'Citi', 'rooms'] = None\ndf_filt.loc[df_filt['rooms'].isna()]","68bcb1d4":"# Filter out only valid rows with rooms\ndf_with_rooms = df_filt.loc[~df_filt['rooms'].isna()]\n# Calculate average dataset room area\naverage_room_area = (df_with_rooms['area']\/df_with_rooms['rooms'].astype('int64')).mean()\naverage_room_area","74d7f4f5":"import numpy as np\n# Very rough room count estimation using average dataset room area\ndef estimate_room_count_rough(area):\n    return np.ceil(area \/ average_room_area)","e4e98e29":"# Delicate estimation: finding out room count that occurs most among dataset samples of similar area\n# If no samples found of a similar area, fallback to rough estimation\ndef estimate_room_count(area, delta = 10):\n    # Defining lower and upper bounds to find similar area\n    area_lo = area - delta\n    area_up = area + delta\n    try:\n        df_similar_by_area = df_with_rooms[(df_with_rooms['area'] > area_lo) & (df_with_rooms['area'] < area_up)]\n        room_values = df_similar_by_area[\"rooms\"].values.flatten()\n        return pd.value_counts(room_values).idxmax()\n    except:\n        return estimate_room_count_rough(area)","96b0ab50":"# Inputing helper, that sets most probable rooms value\ndef impute_most_probable_room_value(index):\n    df_filt.loc[index, 'rooms'] = estimate_room_count(df_filt.loc[index].area)","0a6d605f":"# Fix missing rooms by imputing most probable room values\ndf_filt.loc[df_filt['rooms'].isna()].apply(lambda row: impute_most_probable_room_value(row.name), axis=1)","153eca03":"df_filt.loc[df_filt['rooms'].isna()]","e997f3e6":"# Change column type\ndf_filt.rooms= df_filt.rooms.astype('int64')\n\n# Verify\ndf_filt.rooms.unique()","125b0099":"missing(df_filt)","2c9f0b7f":"df_filt.dtypes","19830761":"df_filt.to_csv('riga.csv',index=False)","1996d3d9":"Final check:","d206b878":"Let's check this address on the [Google Maps](https:\/\/www.google.com\/maps\/place\/Lauvu+iela+22,+Ber%C4%A3i,+Garkalnes+novads,+LV-1024\/@56.9855,24.3108859,14z\/data=!4m5!3m4!1s0x46eecc767c49e4f1:0x2ac3e039274560b6!8m2!3d56.995796!4d24.3074993). It turns out it is located in Ber\u0123i, out of Riga borders, so our \"R\u012bga\" postfix in fact made geolocation fail for this particular item. Taking into account the property is located out of Riga, we will drop it.","37803cfa":"Once again, let's review what else is missing:","b7d3a645":"## Missing districts\nLet's take a look at the entries with missing district value:","3544d059":"All right. We have fixed most geo coordinates - just 1 address hasn't been geolocated. Let's review it manually:","3ca02c74":" It turns out this column is categorical due to the presence of value \"Citi\". This is bad, as room count by nature is numerical and might be important input for correct price prediction in our model. So what does this \"Citi\" really mean for **rooms**? \"Citi\" translates from Latvian as \"Other\". In our context this word might describe some special architectural solutions, where room count can't be clearly defined. ","10198d83":"Not so many to worry about, let's just drop them and see how plot looks without broken values:","dadec5ac":"For the sake of data integrity let's treat \"Citi\" the same way as missing value:","70013f88":"Let's verify all geo coordinates are corrected and review remaining missing values:","8322b0a8":"![Riga](https:\/\/cdn.getyourguide.com\/img\/tour_img-1814782-148.jpg)\n# Introduction\n[Riga](https:\/\/en.wikipedia.org\/wiki\/Riga) is a lovely city near the Baltic Sea, the capital of Latvia. \n\n\nThis kernel is written by Riga Data Science Club - an international community of data scientists based in Riga and Slack \ud83d\ude03\nWe will be happy to accept people from all over the world to join our friendly chat. It is totally free. Please sign up here: [http:\/\/rigadsclub.com\/join-us\/](http:\/\/rigadsclub.com\/join-us\/)\n\nYours,\nRiga DS Club","caef90a2":"## Missing geo coordinates\nWe see most missing values come from geo coordinate columns - **lon** and **lat**. Let's fix them using geocoding utility.","f5351d89":"One not coming from the eastern europe might be confused by the **house_seria** values, but believe us - they are fine. Despite Riga being the city with the highest concentration of [Art Nouveau architecture](https:\/\/en.wikipedia.org\/wiki\/Art_Nouveau_architecture_in_Riga) anywhere in the world, there are also many standardized apartment blocks constructed in the [Soviet period](https:\/\/en.wikipedia.org\/wiki\/Urban_planning_in_communist_countries), so **602**, **119**, **103.**, **467.**, **104.** are just weird names of construction projects. We will treat them as ordinary categorical values.\n","a72d130c":"Let's inspect unique values of other columns as well","1d74428b":"We are ready!","aa164bda":"# Handling missing values\n","ac0458b1":"Next, we could pay attention to **district** column. Let's explore unique districts first:","536facee":"Much better! All items are now concentrated within a single location matching Riga coordinates. Let's see them overlaying actual Riga map:","2ead3662":"The latitude of R\u012bga, Latvia is 56.946285, and the longitude is 24.105078. While some of the values seem to be within a correct range, there are broken values, that make plot look terribly zoomed out. Let's check how many samples have wrong coordinates. Previous plot allows us to assume all broken values deviate too much from real Riga coordinates, so we can use rough comparison to filter them out.","3f4cef77":"Let's check if there are any other operation types in this column:","f8672ffd":"Let's define a helper function to get missing values for a dataframe","b3f5b2ad":"# Data exploration\nFirst, let's load our dataset and get familiar with it by printing out several rows:","a2ca16a7":"One can find out missing district names by looking at rows with the same street:","5e5eee82":"No luck this time - this is the only property on the **Pupuku** street in our dataset. We might use alternative approach to seach nearest points within some range using **lat** **lon** column values, but it would be overkill for a single row. Let's impute district manually by finding **Pupuku iela 9** on [Google Maps](https:\/\/www.google.com\/maps\/place\/Pupu%C4%B7u+iela+9,+Zemgales+priek%C5%A1pils%C4%93ta,+R%C4%ABga,+LV-1076\/@56.9051591,24.1411307,17z\/data=!3m1!4b1!4m5!3m4!1s0x46eed191e0607163:0xb7e8552585e17c39!8m2!3d56.9051591!4d24.1433194):","00962210":"Let's try doing the same for **Pupuku iela 9**:","6a235088":"Great! There are multiple properties listed at the same address - Og\u013cu 32. Let's impute missing value:","a8d76f67":"## Invalid or missing Rooms\nJust **one** row without **rooms** value. This might be easy! ..not so fast, before doing this, let's check unique room values:","293fa661":"Fixing all different kinds of street name abbreviations seems to be a feature engineering task. Let us know if you wish to write a separate LSTM model to handle this \ud83d\ude03","a8c4e71f":"Now let's check how our items look on the map:","896dc5a2":"Floor values look fine.","9443211d":"To find missing geo coordinates we could potentially use **street** column which in fact is address of the building, however it seems to contain some abbreviations that might not be understood by geocoding utility. Let's check.","54c06d4e":"Great! Room column now is numeric and contains no missing values. ","18b85055":"As you see, there are also other values like \"Buying\", \"Renting\", \"Change\" and \"Other\". Before continuing, let's do the following:\n1. Drop entries with operations \"Change\", \"Other\" as irrelevant to our goal - price prediction\n2. Drop entries with operations \"Buying\" and \"Renting\" as they are presented with very few samples","4959d9c0":"Looks good. Let's move to geocoding.","aa7887c3":"We are done! Now it's time to save corrected dataset. ","a1251d94":"So we have 15 rows to fix instead of 1. In order to do this correctly, we could take advantage of other samples with the similar area. Let's build a helper functions to approximate room count. ","fa943c4c":"The assumption was correct. Abbreviation of the street is not found by geocoder, while full value is processed correctly. We might need to find a way to deal with this.","0406d812":"Let's take a look at the **op_type** column. This abbreviation stands for \"operation type\". Values of this column might have huge impact on our further work, since sale price is much different from the rent price for any object."}}