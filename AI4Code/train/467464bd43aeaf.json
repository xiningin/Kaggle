{"cell_type":{"ea375a86":"code","d4c16998":"code","55086763":"code","90e81dfa":"code","35cc1b02":"code","1988a568":"code","a6ac3e12":"code","48301c4f":"code","43611a7f":"code","b1811cf1":"code","20268eb5":"code","a687a504":"code","00cb0f54":"code","b99d690d":"code","3858b215":"code","8997bfd8":"code","5687040c":"code","e498af6a":"code","dd3ff738":"code","0c0e7224":"code","e826c12f":"code","8fc37abf":"code","090f1bbb":"code","74d73ae4":"code","755c2b91":"code","0f7f5022":"code","00c2d2eb":"code","aaa17f97":"markdown","3b395f77":"markdown","9808ad91":"markdown","4c410fba":"markdown","133df022":"markdown","ae2dc174":"markdown","9f3ee781":"markdown","120e2471":"markdown","8b1d4a33":"markdown","d49d29b7":"markdown","aec96ae1":"markdown","cdfa09a8":"markdown","98dd27b6":"markdown","b074c86f":"markdown"},"source":{"ea375a86":"# Other Imports\nimport json\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nimport plotly.graph_objs as go\nimport plotly.offline as py\nimport seaborn as sns\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torchvision\nfrom torchvision import transforms\nimport torchvision.models as models\n\nprint(os.listdir('..\/input'))\n%matplotlib inline\npy.init_notebook_mode(connected=False)\nsns.set(rc={'figure.figsize':(20,10)})\n\n%env JOBLIB_TEMP_FOLDER=\/tmp","d4c16998":"CAT_TO_NAME_PATH = '..\/input\/hackathon-blossom-flower-classification\/cat_to_name.json'\nTRAIN_DATA_PATH = \"..\/input\/hackathon-blossom-flower-classification\/flower_data\/flower_data\/train\"\nVAL_DATA_PATH = \"..\/input\/hackathon-blossom-flower-classification\/flower_data\/flower_data\/valid\"\nTEST_DATA_PATH = '..\/input\/hackathon-blossom-flower-classification\/test set\/'\nCHECKPOINT_PATH = '..\/input\/model-checkpoints\/'\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","55086763":"def get_cat_to_name_data(file_path):\n    \"\"\" Imports the cat_to_name.json file and returns a Pandas DataFrame \"\"\"\n    with open(file_path, 'r') as f:\n        cat_to_names = json.load(f)\n    return cat_to_names","90e81dfa":"cat_to_names = get_cat_to_name_data(CAT_TO_NAME_PATH)","35cc1b02":"cat_to_names","1988a568":"for i in cat_to_names:\n    if i == '11':\n        print(cat_to_names['11'])","a6ac3e12":"def get_data_loaders(train_data_path, val_data_path):\n    transform = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(256),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n        ])\n\n    train_data = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n    train_loader = data.DataLoader(train_data, batch_size=32, shuffle=True,  num_workers=4)\n    val_data = torchvision.datasets.ImageFolder(root=val_data_path, transform=transform)\n    val_loader  = data.DataLoader(val_data, batch_size=32, shuffle=True, num_workers=4) \n    \n    train_class_names = train_data.classes\n    val_class_names = val_data.classes\n    \n    return train_loader, val_loader, train_class_names, val_class_names","48301c4f":"train_loader, val_loader, train_class_names, val_class_names = get_data_loaders(TRAIN_DATA_PATH, VAL_DATA_PATH)","43611a7f":"def imshow(img):\n    img = img \/ 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n    \n\ndef visualize_images():\n\n    dataiter = iter(train_loader)\n    images, labels = dataiter.next()\n\n\n    imshow(torchvision.utils.make_grid(images[:4]))\n    for j in range(4):\n        print(\"label: {}, class: {}, name: {}\".format(labels[j].item(),\n                                               train_class_names[labels[j].item()],\n                                               cat_to_names[train_class_names[labels[j].item()]]))\n\n    \nvisualize_images()","b1811cf1":"def create_model():\n    model = models.densenet161(pretrained=True)\n\n    for param in model.parameters():\n        param.requires_grad = False\n\n    num_filters = model.classifier.in_features\n    model.classifier = nn.Sequential(nn.Linear(num_filters, 2048),\n                               nn.ReLU(),\n                               nn.Linear(2048, 512),\n                               nn.ReLU(),\n                               nn.Linear(512, 102),\n                               nn.LogSoftmax(dim=1))\n\n    # Move model to the device specified above\n    model.to(device)\n    return model","20268eb5":"model = create_model()","a687a504":"criterion = nn.NLLLoss()\n# Set the optimizer function using torch.optim as optim library\noptimizer = optim.Adam(model.parameters())","00cb0f54":"def train(epochs):\n    train_losses = []\n    valid_losses = []\n    \n    for epoch in range(epochs):\n        train_loss = 0\n        val_loss = 0\n        accuracy = 0\n\n        # Training the model\n        model.train()\n        counter = 0\n        for inputs, labels in train_loader:\n            # Move to device\n            inputs, labels = inputs.to(device), labels.to(device)\n            # Clear optimizers\n            optimizer.zero_grad()\n            # Forward pass\n            output = model.forward(inputs)\n            # Loss\n            loss = criterion(output, labels)\n            # Calculate gradients (backpropogation)\n            loss.backward()\n            # Adjust parameters based on gradients\n            optimizer.step()\n            # Add the loss to the training set's rnning loss\n            train_loss += loss.item()\n\n            # Print the progress of our training\n            counter += 1\n            #print(counter, \"\/\", len(train_loader))\n\n            # Evaluating the model\n        model.eval()\n        counter = 0\n        # Tell torch not to calculate gradients\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                # Move to device\n                inputs, labels = inputs.to(device), labels.to(device)\n                # Forward pass\n                output = model.forward(inputs)\n                # Calculate Loss\n                valloss = criterion(output, labels)\n                # Add loss to the validation set's running loss\n                val_loss += valloss.item()\n\n                # Since our model outputs a LogSoftmax, find the real \n                # percentages by reversing the log function\n                output = torch.exp(output)\n                # Get the top class of the output\n                top_p, top_class = output.topk(1, dim=1)\n                # See how many of the classes were correct?\n                equals = top_class == labels.view(*top_class.shape)\n                # Calculate the mean (get the accuracy for this batch)\n                # and add it to the running accuracy for this epoch\n                accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n\n                # Print the progress of our evaluation\n                counter += 1\n                #print(counter, \"\/\", len(val_loader))\n\n        # Get the average loss for the entire epoch\n        train_loss = train_loss\/len(train_loader)\n        valid_loss = val_loss\/len(val_loader)\n\n        train_losses.append(train_loss)\n        valid_losses.append(valid_loss)\n        # Print out the information\n        print('Accuracy: ', accuracy\/len(val_loader))\n        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))\n\n    return train_losses, valid_losses\n","b99d690d":"def save_checkpoint():\n    checkpoint = {'model': model,\n                  'state_dict': model.state_dict(),\n                  'optimizer' : optimizer.state_dict()}\n\n    torch.save(checkpoint, 'checkpoint1.pth')","3858b215":"def load_checkpoint(filepath, inference=False):\n    checkpoint = torch.load(filepath + 'checkpoint1.pth')\n    model = checkpoint['model']\n    model.load_state_dict(checkpoint['state_dict'])\n    \n    if inference:\n      for parameter in model.parameters():\n          parameter.requires_grad = False\n\n      model.eval()\n    \n    model.to(device)\n    return model\n\nmodel = load_checkpoint(filepath=CHECKPOINT_PATH)","8997bfd8":"def get_test_dataloaders(test_path):\n    transform = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(256),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n        ])\n\n    test_data = torchvision.datasets.ImageFolder(root=test_path, transform=transform)\n    test_loader  = data.DataLoader(test_data, batch_size=32, shuffle=False) \n    \n    return test_loader","5687040c":"test_loader = get_test_dataloaders(TEST_DATA_PATH)","e498af6a":"def predict(test_loader):\n    model.eval()\n    \n    predictions = []\n    with torch.no_grad():\n        for images, _ in test_loader:\n            images = images.to(device)\n            output = model(images)\n            ps = torch.exp(output)\n            top_p, top_class = ps.topk(1, dim=1)\n            predictions += [int(i) for i in list(top_class.data.cpu().numpy())]\n        \n    return predictions","dd3ff738":"predictions = predict(test_loader)","0c0e7224":"predictions","e826c12f":"image_names = [image_name for image_name in os.listdir(TEST_DATA_PATH + 'test set')]","8fc37abf":"def create_pred_dataframe(image_names, predictions):\n    predicted_labels = [cat_to_names[train_class_names[i]] for i in predictions]\n    pred_df_with_species_name = pd.DataFrame({'image-names': image_names, 'species': predicted_labels})\n    \n    print('cat: {} for : train_class_name{} for pred: {}'.format([cat_to_names[train_class_names[i]] for i in predictions[:2]],\n                                                [train_class_names[i] for i in predictions[:2]],\n                                                                predictions[:2]))\n    pred_df_with_cat_number = pd.DataFrame({'image-names': image_names, 'category': [train_class_names[i] for i in predictions]})\n    return pred_df_with_species_name, pred_df_with_cat_number","090f1bbb":"pred_df_with_species_name, pred_df_with_cat_number = create_pred_dataframe(image_names, predictions)","74d73ae4":"pred_df_with_species_name = pred_df_with_species_name.sort_values(by=['image-names'])\npred_df_with_cat_number = pred_df_with_cat_number.sort_values(by=['image-names'])","755c2b91":"with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n    print(pred_df_with_cat_number)","0f7f5022":"with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n    print(pred_df_with_species_name)","00c2d2eb":"pred_df_with_species_name.to_csv('my_predictions.csv', sep='\\t', encoding='utf-8')","aaa17f97":"## Step 9: Creating a Prediction Dataframe","3b395f77":"# For simplicity's sake, I have modularized the code in this notebook into functions. Simply call the corresponding function to train\/load\/predict the model.","9808ad91":"## Step 2: Importing the Category-to-Name file\n\nThe file assigns a unique categorical number to each type of flower. We import this file and convert it into a pandas dataframe.","4c410fba":"**I have sorted the predictions by the image-name in ascending order** \n\nThis way it will be easier for the judges to verify my predictions","133df022":"## Step 3: Import the Image data and create the Training and Validation DataLoaders","ae2dc174":"## Step 6: Defining the Save and Load functions","9f3ee781":"Printing all the predictions","120e2471":"## Step 7: Creating the Test DataLoader","8b1d4a33":"## Step 5: Training the Model by defining the _train_ function\n\nIn this kernel instead of training the model (which will take a lot of time), I will directly import the model's checkpoint file using the load function defined in Step 6","d49d29b7":"## Step 1: Importing the necessary packages","aec96ae1":"### Here we define a simple function to visualize the images along with their true values.","cdfa09a8":"### Defining Constants","98dd27b6":"## Step 8: Defining the Predict Function and predicting the labels for the test set","b074c86f":"## Step 4: Defining the Model "}}