{"cell_type":{"964978de":"code","5172bee5":"code","6b8022ed":"code","a99e6951":"code","9d2e7e63":"code","3d3891ac":"code","78e98e8e":"code","2b4042ae":"code","3ce29b83":"code","5d5b4809":"code","47f87751":"code","72238292":"code","4808efbc":"code","6b915265":"code","57274b05":"code","8c1a1c98":"code","0cee8b2d":"code","347a868b":"code","40934772":"code","1116b090":"code","55f251d5":"code","d300724a":"code","ae8adcb6":"code","9d2429ac":"code","557338de":"code","a3e6833f":"code","20dfedc5":"code","4a47164a":"code","0209b2ce":"code","0c2299fd":"code","5d6e6717":"code","01cb1608":"markdown","634f3d5f":"markdown","eb851614":"markdown","fd5a51a0":"markdown","666e2463":"markdown","4e9b93e8":"markdown"},"source":{"964978de":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_log_error","5172bee5":"train=pd.read_csv('..\/input\/bike-sharing-demand\/train.csv')\ntest=pd.read_csv('..\/input\/bike-sharing-demand\/test.csv')","6b8022ed":"train.head()","a99e6951":"train.dtypes","9d2e7e63":"train.info()","3d3891ac":"test.info()","78e98e8e":"# columns:'casual','registered' must be dropped because they don't exist in test data\ntrain.drop(['casual','registered'],axis=1,inplace=True)","2b4042ae":"#Count null values in each column\ntrain.isnull().sum()","3ce29b83":"#Count values of season column\ntrain.season.value_counts()","5d5b4809":"sns.factorplot(x='season',data=train,kind='count')","47f87751":"#Count values of holiday column\ntrain.holiday.value_counts()","72238292":"sns.factorplot(x='holiday',data=train,kind='count')","4808efbc":"#Count values of workingday column\ntrain.workingday.value_counts()","6b915265":"sns.factorplot(x='workingday',data=train,kind='count')","57274b05":"#Count values of weather column\ntrain.weather.value_counts()","8c1a1c98":"sns.factorplot(x='weather',data=train,kind='count')","0cee8b2d":"train.describe()","347a868b":"fig,axes=plt.subplots(2,2)\naxes[0,0].hist(x=\"temp\",data=train)\naxes[0,0].set_title(\"Temperature\")\naxes[0,1].hist(x=\"atemp\",data=train)\naxes[0,1].set_title(\"atemp\")\naxes[1,0].hist(x=\"windspeed\",data=train)\naxes[1,0].set_title(\"Windspeed\")\naxes[1,1].hist(x=\"humidity\",data=train)\naxes[1,1].set_title(\"Humidity\")\nfig.set_size_inches(10,10)","40934772":"cor_mat= train[:].corr()\nfig=plt.gcf()\nfig.set_size_inches(9,9)\nsns.heatmap(data=cor_mat,annot=True)","1116b090":"#make dummies of season column in both of train and test data\nseason=pd.get_dummies(train['season'],prefix='season')\ntrain=pd.concat([train,season],axis=1)\n\nseason=pd.get_dummies(test['season'],prefix='season')\ntest=pd.concat([test,season],axis=1)\n","55f251d5":"#make dummies of weather column in both of train and test data\nweather=pd.get_dummies(train['weather'],prefix='weather')\ntrain=pd.concat([train,weather],axis=1)\n\nweather=pd.get_dummies(test['weather'],prefix='weather')\ntest=pd.concat([test,weather],axis=1)","d300724a":"#Drop season and weather columns from train and test data\ntrain.drop(['season','weather'],inplace=True,axis=1)\n\ntest.drop(['season','weather'],inplace=True,axis=1)\n","ae8adcb6":"#Make columns of hour, day, month, and year out of train datetime column\ntrain[\"hour\"] = [t.hour for t in pd.DatetimeIndex(train.datetime)]\ntrain[\"day\"] = [t.dayofweek for t in pd.DatetimeIndex(train.datetime)]\ntrain[\"month\"] = [t.month for t in pd.DatetimeIndex(train.datetime)]\ntrain['year'] = [t.year for t in pd.DatetimeIndex(train.datetime)]\ntrain['year'] = train['year'].map({2011:0, 2012:1})","9d2429ac":"#Make columns of hour, day, month, and year out of test datetime column\ntest[\"hour\"] = [t.hour for t in pd.DatetimeIndex(test.datetime)]\ntest[\"day\"] = [t.dayofweek for t in pd.DatetimeIndex(test.datetime)]\ntest[\"month\"] = [t.month for t in pd.DatetimeIndex(test.datetime)]\ntest['year'] = [t.year for t in pd.DatetimeIndex(test.datetime)]\ntest['year'] = test['year'].map({2011:0, 2012:1})","557338de":"train.drop('datetime',axis=1,inplace=True)\ntest.drop('datetime',axis=1,inplace=True)","a3e6833f":"sns.factorplot(x=\"hour\",y=\"count\",data=train,kind='bar', size=8)","20dfedc5":"X_train,X_test,y_train,y_test=train_test_split(train.drop('count',axis=1),train['count'],test_size=0.25,random_state=42)","4a47164a":"model = RandomForestRegressor()\nmodel.fit(X_train,y_train)\npred = model.predict(X_test)","0209b2ce":"print('Validation rmsle = ', np.sqrt(mean_squared_log_error(pred,y_test)))","0c2299fd":"model.fit(train.drop('count',axis=1),train['count'])\npredictions = model.predict(test)","5d6e6717":"test = pd.read_csv('..\/input\/bike-sharing-demand\/test.csv')\nd = {'datetime':test['datetime'],'count':predictions}\nsubmission = pd.DataFrame(d)\nsubmission.to_csv('submission.csv',index=False)","01cb1608":"**We conclude that:**\nthere is a higher counts in intervals: 7-10 and 15-19","634f3d5f":"# Submission","eb851614":"# Model","fd5a51a0":"**we conclude that:**\n1. there is a high correlation between temp and atemp so they have the same value of correlation with counts \n1. there is a negative correlation between humidity and counts","666e2463":"# Data Exploration","4e9b93e8":"# Feature Engineering"}}