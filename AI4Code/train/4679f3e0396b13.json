{"cell_type":{"bd998dee":"code","ca5816ef":"code","32f98a69":"code","ba0f8c48":"code","1167139e":"code","f75daa2f":"code","449484a1":"code","084176c4":"code","5bb50a3a":"code","1648cf55":"code","b9dea91d":"code","4d9d0c25":"code","0b9d885c":"code","baf28213":"code","f144808e":"code","8617aca8":"code","2fd65b4d":"code","85550dc9":"code","7d5986f0":"code","f4660fa4":"code","4f054490":"code","e8bc8d7a":"code","fd799dec":"code","d4da7efa":"code","29a6ef02":"code","2daaa9e4":"code","ffc1b2bb":"code","e6dd3d79":"markdown","23eaaaac":"markdown","1813e6fa":"markdown","ef50ed15":"markdown","654e0929":"markdown","380b6b72":"markdown","acc1e464":"markdown","02459c17":"markdown","0a553918":"markdown","2f2ecf88":"markdown"},"source":{"bd998dee":"!wget https:\/\/raw.githubusercontent.com\/python-engineer\/pytorch-chatbot\/master\/intents.json","ca5816ef":"!dir","32f98a69":"import nltk\nnltk.download('punkt')\n\nfrom nltk.stem.porter import PorterStemmer\nstemmer = PorterStemmer()","ba0f8c48":"def tokenize(sentence):\n    return nltk.word_tokenize(sentence)","1167139e":"def stem(word):\n    return stemmer.stem(word.lower())","f75daa2f":"import numpy as np \n\ndef bag_of_words(tokenized_sentence, all_words):\n    tokenized_sentence = [stem(w) for w in tokenized_sentence]\n    \n    bag = np.zeros(len(all_words), dtype=np.float32)\n    for idx, w in enumerate(all_words):\n        if w in tokenized_sentence:\n            bag[idx] = 1.0\n    \n    return bag","449484a1":"# testing \n\na = \"How long does shipping take?\"\nprint(a)\nw = tokenize(a)\nprint(w)\nfor b in w:\n    print(stem(b))\n\ns = ['How', 'long']\n\nbag = bag_of_words(s,w)\nprint(bag)\n","084176c4":"import json","5bb50a3a":"with open('intents.json', 'r') as f:\n    intents = json.load(f)","1648cf55":"print(intents)","b9dea91d":"all_words = []\ntags = []\nxy = []\nfor intent in intents['intents']:\n    tag = intent['tag']\n    tags.append(tag)\n    for pattern in intent['patterns']:\n        w = tokenize(pattern)\n        all_words.extend(w)\n        xy.append((w, tag))\n\nignore_words = ['?', '!', '.', ',']\nprint(all_words)","4d9d0c25":"all_words = [stem(w) for w in all_words if w not in ignore_words]\nprint(all_words)","0b9d885c":"all_words = sorted(set(all_words))\ntags = sorted(set(tags))\nprint(tags)","baf28213":"X_train = []\ny_train = []\nfor(pattern_sentence, tag) in xy:\n    bag = bag_of_words(pattern_sentence, all_words)\n    X_train.append(bag)\n    \n    label = tags.index(tag)\n    y_train.append(label)","f144808e":"\nX_train = np.array(X_train)\ny_train = np.array(y_train)\n","8617aca8":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader","2fd65b4d":"class ChatDataset(Dataset):\n    def __init__(self):\n        self.n_samples = len(X_train)\n        self.x_data = X_train\n        self.y_data = y_train\n    \n    def __getitem__(self, index ):\n        return self.x_data[index], self.y_data[index]\n    \n    def __len__(self):\n        return self.n_samples\n    \n ","85550dc9":"batch_size = 8\n\ndataset = ChatDataset()\ntrain_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n","7d5986f0":"import torch\nimport torch.nn as nn\n\nclass NeuralNet(nn.Module):\n    \n    def __init__(self, input_size, hidden_size, num_classes):\n        super(NeuralNet, self).__init__()\n        self.l1 = nn.Linear(input_size, hidden_size)\n        self.l2 = nn.Linear(hidden_size, hidden_size)\n        self.l3 = nn.Linear(hidden_size, num_classes)\n        self.relu = nn.ReLU()\n    \n    def forward(self, x):\n        out = self.l1(x)\n        out = self.relu(out)\n        out = self.l2(out)\n        out = self.relu(out)\n        out = self.l3(out)\n        # no activation no softmax\n        return out","f4660fa4":"hidden_size = 8\noutput_size = len(tags)\n\ninput_size = len(X_train[0])\n\n","4f054490":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","e8bc8d7a":"model = NeuralNet(input_size, hidden_size, output_size )","fd799dec":"learning_rate = 0.001\nnum_epochs = 1000\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)","d4da7efa":"for epoch in range(num_epochs):\n    for (words, labels) in train_loader:\n        words = words\n        labels = labels\n        \n        #forward\n        outputs = model(words)\n        loss = criterion(outputs, labels)\n        \n        # backward and optimizer step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n    if ((epoch +1)% 100 == 0):\n        print('epoch: ', epoch + 1 , '\/', num_epochs, ' loss: ', loss.item())\n\nprint(\"final loss: \", loss.item())","29a6ef02":"data = {\n    \"model_state\": model.state_dict(),\n    \"input_size\": input_size,\n    \"output_size\": output_size,\n    \"hidden_size\" : hidden_size,\n    \"all_words\": all_words,\n    \"tags\": tags\n}\n\nFILE = \"data.pth\"\ntorch.save(data, FILE)\n\nprint(\"Training complete and file save to\", FILE)","2daaa9e4":"import random\n\nwith open('intents.json', 'r' ) as f:\n    intents = json.load(f)\n\nFILE = \"data.pth\"\n\ndata_loaded = torch.load(FILE)\n\ninput_size_l = data_loaded[\"input_size\"]\nhidden_size_l = data_loaded[\"hidden_size\"]\noutput_size_l = data_loaded[\"output_size\"]\n\nall_words = data_loaded[\"all_words\"]\ntags = data_loaded[\"tags\"]\nmodel_state = data_loaded[\"model_state\"]\n\nmodel_l = NeuralNet(input_size_l, hidden_size_l, output_size_l)\nmodel_l.load_state_dict(model_state)\n\nmodel.eval()\n","ffc1b2bb":"bot_name = \"Samus\"\nprint(\"let chat! type quit to exit\")\n\nwhile True:\n    sentence = input('You : ' )\n    if sentence == \"quit\":\n        break\n    \n    sentence = tokenize(sentence)\n    X = bag_of_words(sentence, all_words)\n    X = X.reshape(1, X.shape[0])\n    X = torch.from_numpy(X)\n    \n    output = model_l(X)\n    _, predicted = torch.max(output, dim=1)\n    tag = tags[predicted.item()]\n    \n    probs = torch.softmax(output, dim=1)\n    prob = probs[0][predicted.item()]\n    \n    if prob.item() > 0.75:\n        for intent in intents[\"intents\"]:\n            if tag == intent[\"tag\"]:\n                print(bot_name, \":\",random.choice(intent[\"responses\"]))\n    else:\n        print(bot_name, \":\", \"Well, I do not understand.\")","e6dd3d79":"lets save the model","23eaaaac":"### chat.py","1813e6fa":"### Getting the intents.json file","ef50ed15":"### model.py","654e0929":"We would be building a chatbot utilising nltk toolkit and pytorch.\n\nimplemented from this video tutorial given here : https:\/\/www.youtube.com\/watch?v=RpWeNzfSUHw\n\nThe implementation is given in the last cell. Run cells after `chat.py` to access it.","380b6b72":"creating a bag of words","acc1e464":"converting to numpy array","02459c17":"### nltk_utils.py","0a553918":"implementing the training loop","2f2ecf88":"### train.py"}}