{"cell_type":{"592cfed5":"code","10167f36":"code","07361ae7":"code","104d8664":"code","f6929979":"code","1bf43c9e":"code","ecfbd084":"code","ae30da1b":"code","15e430d5":"code","e4a2fb9f":"code","820035ba":"code","4fe8d8c9":"code","ccbff05d":"code","6c003c93":"code","292431b7":"code","4140c939":"code","89376278":"code","ed7a30e6":"code","8efcf163":"code","48118a54":"code","9d25ec89":"code","9d805d99":"markdown","ee2ca7be":"markdown","7b8eb07a":"markdown","51e9d4ee":"markdown","fffe5a98":"markdown","0f0bbf30":"markdown"},"source":{"592cfed5":"#importing libaries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","10167f36":"#importing dataset\nds = pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')","07361ae7":"#reviewing dataset\npd.set_option('display.max_columns',None)\nds.head()","104d8664":"#dropping unnecessary features\nds.drop(['id', 'Unnamed: 32'], axis = 1, inplace = True)","f6929979":"#checking type of feaures\nds.info()","1bf43c9e":"#dataset has 569 rows and 31 columns\nds.shape","ecfbd084":"#checking for null values\nds.isnull().sum()","ae30da1b":"#taking care of categorical values\nfrom sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\nds['diagnosis']=le.fit_transform(ds['diagnosis'])","15e430d5":"ds.head()","e4a2fb9f":"plt.figure(figsize=(16,14))\nsns.heatmap(ds.corr(), cmap='Blues', annot = True)\nplt.title(\"Correlation Map\", fontweight = \"bold\", fontsize=16)","820035ba":"#defining dependent and independent variables\nx = ds.drop('diagnosis', axis=1)\ny = ds['diagnosis']","4fe8d8c9":"#splitting data into training and testing set\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)","ccbff05d":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.fit_transform(x_test)","6c003c93":"#training model\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(max_iter = 10000)\nlr.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix\ny_pred = lr.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\nlra = accuracy_score(y_test,y_pred)\nprint('accuracy score = ',lra)","292431b7":"#training model\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski',p = 2)\nknn.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix\ny_pred = knn.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\nknna = accuracy_score(y_test,y_pred)\nprint('accuracy score = ',accuracy_score(y_test,y_pred))","4140c939":"#training model\nfrom sklearn.svm import SVC\nsvc = SVC(kernel = 'linear')\nsvc.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix\ny_pred = svc.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\nsva =accuracy_score(y_test,y_pred)\nprint('accuracy score = ',accuracy_score(y_test,y_pred))","89376278":"#training model\nfrom sklearn.svm import SVC\nsvc = SVC(kernel = 'rbf')\nsvc.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix\ny_pred = svc.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\nsva2 = accuracy_score(y_test,y_pred)\nprint('accuracy score = ',accuracy_score(y_test,y_pred))","ed7a30e6":"#training model\nfrom sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix\ny_pred = nb.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\nnba = accuracy_score(y_test,y_pred)\nprint('accuracy score = ',accuracy_score(y_test,y_pred))","8efcf163":"#training model\nfrom sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier(criterion = 'entropy')\ndt.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix\ny_pred = dt.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\ndta = accuracy_score(y_test,y_pred)\nprint('accuracy score = ',accuracy_score(y_test,y_pred))","48118a54":"#training model\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators = 60, criterion = 'entropy',random_state = 0)\nrf.fit(x_train,y_train)\n\n#getting confusion matrix\nfrom sklearn.metrics import confusion_matrix\ny_pred = rf.predict(x_test)\ncm = confusion_matrix(y_test,y_pred)\nprint('confusion matrix:\\n',cm)\n\n#checking accuracy\nfrom sklearn.metrics import accuracy_score\nrfa = accuracy_score(y_test,y_pred)\nprint('accuracy score = ',accuracy_score(y_test,y_pred))","9d25ec89":"#comparing accuracies\nplt.figure(figsize= (8,7))\nac = [lra,knna,sva,sva2,nba,dta,rfa]\nname = ['Logistic Regression','knn','svm','Kernel Svm','Naive Bayes','Decision Tree', 'Random Forest']\nsns.barplot(x = ac,y = name,palette='pastel')\nplt.title(\"Plotting the Model Accuracies\", fontsize=16, fontweight=\"bold\")","9d805d99":"**APPLYING FEATURE SCALING MAY IMPROVE ACCURACY**","ee2ca7be":"**NO MISSING DATA**","7b8eb07a":"**THERE WAS A TIE BETWEEN RANDOM FOREST AND KERNEL SVM WITH AN ACCURACY OF 98.2 %**","51e9d4ee":"**APPLYING MODELS**","fffe5a98":"**WE CAN EITHER REMOVE THE HIGH CORRELATED FEATURES OR WE CAN USE ALL THE FEATURES, I AM USING ALL FEATURES.**\n* **REMOVING CORRELATED FEATURES MAY INCREASE ACCURACY**","0f0bbf30":"**PREDICTING BREAST CANCER USING VARIOUS CLASSIFICATION MODELS.**\n* The features that have been computed from digitized images of the cell nuclei, which can be used to build a model to predict whether a tumor is benign or malignant.\n* 1 = Malignant (Cancerous) - Present (M)\n* 0  = Benign (Not Cancerous) -Absent (B)"}}