{"cell_type":{"982e8c60":"code","7761a62c":"code","d259162e":"code","3286166c":"code","06002fcf":"code","d895b587":"code","4b525629":"code","ab0af597":"code","2baf139f":"code","f5e9b5de":"code","7d7c167a":"code","53b8bd2c":"code","7c5833ea":"code","f3635985":"code","1dcaa771":"markdown","d74b066c":"markdown","89c9f6b1":"markdown","5b3b007f":"markdown","ec092151":"markdown","80a2123a":"markdown","41f3575b":"markdown","23944861":"markdown","05ddc4d2":"markdown","60a9aae5":"markdown","92ab28e3":"markdown","cf7c93bf":"markdown","3092a456":"markdown"},"source":{"982e8c60":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport cv2\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","7761a62c":"image = cv2.imread('\/kaggle\/input\/medical-masks-dataset\/images\/000_1ov3n5_0.jpeg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(20, 20))\nplt.subplot(1, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Create our shapening kernel, we don't normalize since the \n# the values in the matrix sum to 1\nkernel_sharpening = np.array([[-1,-1,-1], \n                              [-1,9,-1], \n                              [-1,-1,-1]])\n\n# applying different kernels to the input image\nsharpened = cv2.filter2D(image, -1, kernel_sharpening)\n\n\nplt.subplot(1, 2, 2)\nplt.title(\"Image Sharpening\")\nplt.imshow(sharpened)\n\nplt.show()","d259162e":"# Load our new image\nimage = cv2.imread('\/kaggle\/input\/\/medical-masks-dataset\/images\/003_1024.jpeg', 0)\n\nplt.figure(figsize=(30, 30))\nplt.subplot(3, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Values below 127 goes to 0 (black, everything above goes to 255 (white)\nret,thresh1 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n\nplt.subplot(3, 2, 2)\nplt.title(\"Threshold Binary\")\nplt.imshow(thresh1)\n\n# It's good practice to blur images as it removes noise\nimage = cv2.GaussianBlur(image, (3, 3), 0)\n\n# Using adaptiveThreshold\nthresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 3, 5) \n\nplt.subplot(3, 2, 3)\nplt.title(\"Adaptive Mean Thresholding\")\nplt.imshow(thresh)\n\n\n_, th2 = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n\nplt.subplot(3, 2, 4)\nplt.title(\"Otsu's Thresholding\")\nplt.imshow(th2)\n\n\nplt.subplot(3, 2, 5)\n# Otsu's thresholding after Gaussian filtering\nblur = cv2.GaussianBlur(image, (5,5), 0)\n_, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\nplt.title(\"Guassian Otsu's Thresholding\")\nplt.imshow(th3)\nplt.show()","3286166c":"image = cv2.imread('\/kaggle\/input\/medical-masks-dataset\/images\/002_1024.jpeg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(20, 20))\nplt.subplot(3, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Let's define our kernel size\nkernel = np.ones((5,5), np.uint8)\n\n# Now we erode\nerosion = cv2.erode(image, kernel, iterations = 1)\n\nplt.subplot(3, 2, 2)\nplt.title(\"Erosion\")\nplt.imshow(erosion)\n\n# \ndilation = cv2.dilate(image, kernel, iterations = 1)\nplt.subplot(3, 2, 3)\nplt.title(\"Dilation\")\nplt.imshow(dilation)\n\n\n# Opening - Good for removing noise\nopening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\nplt.subplot(3, 2, 4)\nplt.title(\"Opening\")\nplt.imshow(opening)\n\n# Closing - Good for removing noise\nclosing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\nplt.subplot(3, 2, 5)\nplt.title(\"Closing\")\nplt.imshow(closing)","06002fcf":"image = cv2.imread('\/kaggle\/input\/medical-masks-dataset\/images\/coronavirus-en-chine.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nheight, width,_ = image.shape\n\n# Extract Sobel Edges\nsobel_x = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\nsobel_y = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)\n\nplt.figure(figsize=(20, 20))\n\nplt.subplot(3, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\nplt.subplot(3, 2, 2)\nplt.title(\"Sobel X\")\nplt.imshow(sobel_x)\n\nplt.subplot(3, 2, 3)\nplt.title(\"Sobel Y\")\nplt.imshow(sobel_y)\n\nsobel_OR = cv2.bitwise_or(sobel_x, sobel_y)\n\nplt.subplot(3, 2, 4)\nplt.title(\"sobel_OR\")\nplt.imshow(sobel_OR)\n\nlaplacian = cv2.Laplacian(image, cv2.CV_64F)\n\nplt.subplot(3, 2, 5)\nplt.title(\"Laplacian\")\nplt.imshow(laplacian)\n\n# Canny Edge Detection uses gradient values as thresholds\n# The first threshold gradient\ncanny = cv2.Canny(image, 50, 120)\n\nplt.subplot(3, 2, 6)\nplt.title(\"Canny\")\nplt.imshow(canny)","d895b587":"image = cv2.imread('\/kaggle\/input\/medical-masks-dataset\/images\/0109-00176-096b1.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(20, 20))\n\nplt.subplot(1, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Cordinates of the 4 corners of the original image\npoints_A = np.float32([[320,15], [700,215], [85,610], [530,780]])\n\n# Cordinates of the 4 corners of the desired output\n# We use a ratio of an A4 Paper 1 : 1.41\npoints_B = np.float32([[0,0], [420,0], [0,594], [420,594]])\n \n# Use the two sets of four points to compute \n# the Perspective Transformation matrix, M    \nM = cv2.getPerspectiveTransform(points_A, points_B)\n\n\nwarped = cv2.warpPerspective(image, M, (420,594))\n\nplt.subplot(1, 2, 2)\nplt.title(\"warpPerspective\")\nplt.imshow(warped)","4b525629":"image = cv2.imread('\/kaggle\/input\/medical-masks-dataset\/images\/CHINA-HEALTH-VIRUS-134752 (1).jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(20, 20))\n\nplt.subplot(2, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Let's make our image 3\/4 of it's original size\nimage_scaled = cv2.resize(image, None, fx=0.75, fy=0.75)\n\nplt.subplot(2, 2, 2)\nplt.title(\"Scaling - Linear Interpolation\")\nplt.imshow(image_scaled)\n\n# Let's double the size of our image\nimg_scaled = cv2.resize(image, None, fx=2, fy=2, interpolation = cv2.INTER_CUBIC)\n\nplt.subplot(2, 2, 3)\nplt.title(\"Scaling - Cubic Interpolation\")\nplt.imshow(img_scaled)\n\n# Let's skew the re-sizing by setting exact dimensions\nimg_scaled = cv2.resize(image, (900, 400), interpolation = cv2.INTER_AREA)\n\nplt.subplot(2, 2, 4)\nplt.title(\"Scaling - Skewed Size\")\nplt.imshow(img_scaled)","ab0af597":"image = cv2.imread('\/kaggle\/input\/medical-masks-dataset\/images\/nouveau-virus-en-chine-la-ville-de-wuhan-mise-en-quarantaine-1.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(20, 20))\n\nplt.subplot(2, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\nheight, width = image.shape[:2]\n\n# Let's get the starting pixel coordiantes (top  left of cropping rectangle)\nstart_row, start_col = int(height * .25), int(width * .25)\n\n# Let's get the ending pixel coordinates (bottom right)\nend_row, end_col = int(height * .75), int(width * .75)\n\n# Simply use indexing to crop out the rectangle we desire\ncropped = image[start_row:end_row , start_col:end_col]\n\n\nplt.subplot(2, 2, 2)\nplt.title(\"Cropped\")\nplt.imshow(cropped)","2baf139f":"image = cv2.imread('\/kaggle\/input\/medical-masks-dataset\/images\/\/organizacion-preocupacion-potencial-virus-propague.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(20, 20))\n\nplt.subplot(2, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Creating our 3 x 3 kernel\nkernel_3x3 = np.ones((3, 3), np.float32) \/ 9\n\n# We use the cv2.fitler2D to conovlve the kernal with an image \nblurred = cv2.filter2D(image, -1, kernel_3x3)\n\nplt.subplot(2, 2, 2)\nplt.title(\"3x3 Kernel Blurring\")\nplt.imshow(blurred)\n\n# Creating our 7 x 7 kernel\nkernel_7x7 = np.ones((7, 7), np.float32) \/ 49\n\nblurred2 = cv2.filter2D(image, -1, kernel_7x7)\n\nplt.subplot(2, 2, 3)\nplt.title(\"7x7 Kernel Blurring\")\nplt.imshow(blurred2)","f5e9b5de":"# Let's load a simple image with 3 black squares\nimage = cv2.imread('\/kaggle\/input\/medical-masks-dataset\/images\/so(19).jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n\nplt.figure(figsize=(20, 20))\n\nplt.subplot(2, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n\n# Grayscale\ngray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n\n# Find Canny edges\nedged = cv2.Canny(gray, 30, 200)\n\nplt.subplot(2, 2, 2)\nplt.title(\"Canny Edges\")\nplt.imshow(edged)\n\n# Finding Contours\n# Use a copy of your image e.g. edged.copy(), since findContours alters the image\ncontours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n\nplt.subplot(2, 2, 3)\nplt.title(\"Canny Edges After Contouring\")\nplt.imshow(edged)\n\nprint(\"Number of Contours found = \" + str(len(contours)))\n\n# Draw all contours\n# Use '-1' as the 3rd parameter to draw all\ncv2.drawContours(image, contours, -1, (0,255,0), 3)\n\nplt.subplot(2, 2, 4)\nplt.title(\"Contours\")\nplt.imshow(image)","7d7c167a":"import numpy as np\nimport pandas as pd \nimport cv2\nfrom fastai.vision import *\nfrom wordcloud import WordCloud, STOPWORDS\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport shutil\nfrom glob import glob\n%matplotlib inline\n!pip freeze > '..\/working\/dockerimage_snapshot.txt'","53b8bd2c":"def makeWordCloud(df,column,numWords):\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    word_string=str(popular_words_nonstop)\n    wordcloud = WordCloud(stopwords=STOPWORDS,\n                          background_color='white',\n                          max_words=numWords,\n                          width=1000,height=1000,\n                         ).generate(word_string)\n    plt.clf()\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()\n\ndef plotImages(artist,directory):\n    print(artist)\n    multipleImages = glob(directory)\n    plt.rcParams['figure.figsize'] = (15, 15)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    i_ = 0\n    for l in multipleImages[:25]:\n        im = cv2.imread(l)\n        im = cv2.resize(im, (128, 128)) \n        plt.subplot(5, 5, i_+1) #.set_title(l)\n        plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n        i_ += 1\n\nnp.random.seed(7)","7c5833ea":"print(os.listdir(\"..\/input\/medical-masks-dataset\/images\/\"))","f3635985":"img_dir='..\/input\/medical-masks-dataset\/images'\npath=Path(img_dir)\ndata = ImageDataBunch.from_folder(path, train=\".\", \n                                  valid_pct=0.2,\n                                  ds_tfms=get_transforms(do_flip=False,flip_vert=False, max_rotate=0,max_lighting=0.3),\n                                  size=299,bs=64, \n                                  num_workers=0).normalize(imagenet_stats)\nprint(f'Classes: \\n {data.classes}')\ndata.show_batch(rows=8, figsize=(40,40))","1dcaa771":"Cropping","d74b066c":"Perpsective Transform","89c9f6b1":"Kaggle Notebook Runner: Mar\u00edlia Prata  @mpwolke","5b3b007f":"Scaling, re-sizing and interpolations","ec092151":"Thresholding, Binarization & Adaptive Thresholding","80a2123a":"#Codes from Paul Mooney https:\/\/www.kaggle.com\/paultimothymooney\/collections-of-paintings-from-50-artists\/data","41f3575b":"#Codes from Bulent Siyah https:\/\/www.kaggle.com\/bulentsiyah\/learn-opencv-by-examples-with-python\u00b6","23944861":"Edge Detection & Image Gradients","05ddc4d2":"Blurring","60a9aae5":"Sharpening","92ab28e3":"Dilation, Erosion, Opening and Closing","cf7c93bf":"Contours","3092a456":"#Health for all and all for health\n\nHealth promotion is the process of enabling people to increase control over, and to improve their health.\u201d\n \nThe first International Conference on Health Promotion was held in Ottawa in 1986, and was primarily a response to growing expectations for a new public health movement around the world. It launched a series of actions among international organizations, national governments and local communities to achieve the goal of \"Health For All\" by the year 2000 and beyond. The basic strategies for health promotion identified in the Ottawa Charter were: advocate (to boost the factors which encourage health), enable (allowing all people to achieve health equity) and mediate (through collaboration across all sectors). \n\nSince then, the WHO Global Health Promotion Conferences have established and developed the global principles and action areas for health promotion. Most recently, the 9th global conference (Shanghai 2016), titled \u2018Promoting health in the Sustainable Development Goals: Health for all and all for health\u2019, highlighted the critical links between promoting health and the 2030 Agenda for Sustainable Development. Whilst calling for bold political interventions to accelerate country action on the SDGs, the Shanghai Declaration provides a framework through which governments can utilize the transformational potential of health promotion. https:\/\/www.who.int\/health-topics\/health-promotion#tab=tab_1"}}