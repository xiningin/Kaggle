{"cell_type":{"7d696a5b":"code","b33a44bf":"code","1345329b":"code","47a079df":"code","490f304b":"code","75ed763d":"code","18908bf2":"code","69745a72":"code","390d88d3":"code","1c47ce5d":"code","c7d97e72":"code","0c8f776a":"code","f3c4e76f":"code","0e661c6f":"code","c71b0196":"code","87b853be":"code","765fb766":"code","9097765a":"code","168d4e27":"code","787a61d3":"code","25d837c7":"code","c3da4de5":"code","d9691d60":"code","62fa143d":"code","afdf402b":"code","04c26ef1":"code","81997227":"code","2180c5f0":"code","822b4540":"code","373347c1":"code","aa15460f":"code","ceb98b92":"code","dbe1ab5f":"code","c7a42985":"code","0d13bc25":"code","65b703c5":"code","8c464c3f":"code","1585c427":"code","48648c27":"code","ddc2ad6b":"code","b98778c3":"code","3e26c0c3":"code","10cab478":"code","df0a12e7":"code","00de15d0":"code","87e84f4d":"code","49b50664":"code","bd48c252":"code","076bbc2e":"code","9f970a98":"code","2edd3cd7":"code","ecba7519":"code","6aed3128":"code","8ed43145":"code","7dc61b59":"code","34ca04f7":"code","a507f97d":"code","b3274af6":"markdown","c5e128e4":"markdown","744edea2":"markdown","0155b039":"markdown","0cf6ed44":"markdown","6b90554b":"markdown","aabd1412":"markdown","ed178328":"markdown","ed14a32f":"markdown","3b16e9ab":"markdown","20239b1a":"markdown","2e81d22a":"markdown","a2fd3a3d":"markdown","a423cc21":"markdown","ea54b822":"markdown","445e5ea5":"markdown","894d946a":"markdown","992c592f":"markdown","d0c84b9b":"markdown","ba6152f8":"markdown","7d45e5cc":"markdown","6fc7fcee":"markdown","94bc4c27":"markdown","1ad9996c":"markdown"},"source":{"7d696a5b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n%config InlineBackend.figure_format = 'retina'","b33a44bf":"data = pd.read_csv(\"..\/input\/spam.csv\",encoding='latin-1')","1345329b":"data.head()","47a079df":"#Drop column and name change\ndata = data.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\ndata = data.rename(columns={\"v1\":\"label\", \"v2\":\"text\"})","490f304b":"data.tail()","75ed763d":"#Count observations in each label\ndata.label.value_counts()","18908bf2":"# convert label to a numerical variable\ndata['label_num'] = data.label.map({'ham':0, 'spam':1})","69745a72":"data.head()","390d88d3":"from sklearn.model_selection import train_test_split","1c47ce5d":"X_train,X_test,y_train,y_test = train_test_split(data[\"text\"],data[\"label\"], test_size = 0.2, random_state = 10)","c7d97e72":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","0c8f776a":"from sklearn.feature_extraction.text import CountVectorizer","f3c4e76f":"vect = CountVectorizer()","0e661c6f":"vect.fit(X_train)","c71b0196":"print(vect.get_feature_names()[0:20])\nprint(vect.get_feature_names()[-20:])","87b853be":"X_train_df = vect.transform(X_train)","765fb766":"X_test_df = vect.transform(X_test)","9097765a":"type(X_test_df)","168d4e27":"ham_words = ''\nspam_words = ''\nspam = data[data.label_num == 1]\nham = data[data.label_num ==0]","787a61d3":"import nltk\nfrom nltk.corpus import stopwords","25d837c7":"for val in spam.text:\n    text = val.lower()\n    tokens = nltk.word_tokenize(text)\n    #tokens = [word for word in tokens if word not in stopwords.words('english')]\n    for words in tokens:\n        spam_words = spam_words + words + ' '\n        \nfor val in ham.text:\n    text = val.lower()\n    tokens = nltk.word_tokenize(text)\n    for words in tokens:\n        ham_words = ham_words + words + ' '","c3da4de5":"from wordcloud import WordCloud","d9691d60":"# Generate a word cloud image\nspam_wordcloud = WordCloud(width=600, height=400).generate(spam_words)\nham_wordcloud = WordCloud(width=600, height=400).generate(ham_words)","62fa143d":"#Spam Word cloud\nplt.figure( figsize=(10,8), facecolor='k')\nplt.imshow(spam_wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()","afdf402b":"#Ham word cloud\nplt.figure( figsize=(10,8), facecolor='k')\nplt.imshow(ham_wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()","04c26ef1":"prediction = dict()\nfrom sklearn.naive_bayes import MultinomialNB\nmodel = MultinomialNB()\nmodel.fit(X_train_df,y_train)","81997227":"prediction[\"Multinomial\"] = model.predict(X_test_df)","2180c5f0":"from sklearn.metrics import accuracy_score,confusion_matrix,classification_report","822b4540":"accuracy_score(y_test,prediction[\"Multinomial\"])","373347c1":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(X_train_df,y_train)","aa15460f":"prediction[\"Logistic\"] = model.predict(X_test_df)","ceb98b92":"accuracy_score(y_test,prediction[\"Logistic\"])","dbe1ab5f":"from sklearn.neighbors import KNeighborsClassifier\nmodel = KNeighborsClassifier(n_neighbors=5)\nmodel.fit(X_train_df,y_train)","c7a42985":"prediction[\"knn\"] = model.predict(X_test_df)","0d13bc25":"accuracy_score(y_test,prediction[\"knn\"])","65b703c5":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier()\nmodel.fit(X_train_df,y_train)","8c464c3f":"prediction[\"random_forest\"] = model.predict(X_test_df)","1585c427":"accuracy_score(y_test,prediction[\"random_forest\"])","48648c27":"from sklearn.ensemble import AdaBoostClassifier\nmodel = AdaBoostClassifier()\nmodel.fit(X_train_df,y_train)","ddc2ad6b":"prediction[\"adaboost\"] = model.predict(X_test_df)","b98778c3":"accuracy_score(y_test,prediction[\"adaboost\"])","3e26c0c3":"from sklearn.model_selection import GridSearchCV","10cab478":"k_range = np.arange(1,30)","df0a12e7":"k_range","00de15d0":"param_grid = dict(n_neighbors=k_range)\nprint(param_grid)","87e84f4d":"model = KNeighborsClassifier()\ngrid = GridSearchCV(model,param_grid)\ngrid.fit(X_train_df,y_train)","49b50664":"grid.best_estimator_","bd48c252":"grid.best_params_","076bbc2e":"grid.best_score_","9f970a98":"grid.cv_results_","2edd3cd7":"print(classification_report(y_test, prediction['Multinomial'], target_names = [\"Ham\", \"Spam\"]))","ecba7519":"conf_mat = confusion_matrix(y_test, prediction['Multinomial'])\nconf_mat_normalized = conf_mat.astype('float') \/ conf_mat.sum(axis=1)[:, np.newaxis]","6aed3128":"sns.heatmap(conf_mat_normalized)\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","8ed43145":"print(conf_mat)","7dc61b59":"pd.set_option('display.max_colwidth', -1)","34ca04f7":"X_test[y_test < prediction[\"Multinomial\"] ]","a507f97d":"X_test[y_test > prediction[\"Multinomial\"] ]","b3274af6":"### 9.1 Misclassified as Spam","c5e128e4":"vect.fit function learns the vocabulary. We can get all the feature names from vect.get_feature_names( ). <br> <br> Let us print first and last twenty features","744edea2":"Now, let's transform the Test data.","0155b039":"# 6. Machine Learning models:","0cf6ed44":"### 9.2 Misclassfied as Ham","6b90554b":"# 8. Model Evaluation","aabd1412":"By seeing the above confusion matrix, it is clear that 5 Ham are mis classified as Spam, and 8 Spam are misclassified as Ham. Let'see what are those misclassified text messages. Looking those messages may help us to come up with more advanced feature engineering.","ed178328":"# 2. Import data","ed14a32f":"# 7. Parameter Tuning using GridSearchCV","3b16e9ab":"Based, on the above four ML models, Naive Bayes has given the best accuracy. However, Let's try to tune the parameters of $k$-NN using GridSearchCV","20239b1a":"### 6.3 $k$-NN classifier","2e81d22a":"### 6.4 Ensemble classifier","a2fd3a3d":"# 4.Text Transformation\nVarious text transformation techniques such as stop word removal, lowering the texts, tfidf transformations, prunning, stemming can be performed using sklearn.feature_extraction libraries. Then, the data can be convereted into bag-of-words. <br> <br>\nFor this problem, Let us see how our model performs without removing stop words.","a423cc21":"It seems length of the spam text is much higher than the ham. Maybe we can include length as a feature.  In addition to unigram, we can also try bigram features. ","ea54b822":"* *Forked from : https:\/\/www.kaggle.com\/futurist\/text-preprocessing-and-machine-learning-modeling*\n* **Grid Search CV grid.cv_results_ included which has been replace with grid_scores_ **\n* https:\/\/github.com\/scikit-learn\/scikit-learn\/issues\/11198\n","445e5ea5":"Let's drop the unwanted columns, and rename the column name appropriately.","894d946a":"# 9. Future works","992c592f":"* # 1. Import libraries","d0c84b9b":"# 3. Train Test Split\nBefore performing text transformation, let us do train test split. Infact, we can perform k-Fold cross validation. However, due to simplicity, I am doing train test split.","ba6152f8":"# 5. Visualisations ","7d45e5cc":"Note : We can also perform tfidf transformation.","6fc7fcee":"### 6.2 Logistic Regression","94bc4c27":"### 6.1 Multinomial Naive Bayes\nGenerally, Naive Bayes works well on text data. Multinomail Naive bayes is best suited for classification with discrete features. ","1ad9996c":"I increased the pandas dataframe width to display the misclassified texts in full width. "}}