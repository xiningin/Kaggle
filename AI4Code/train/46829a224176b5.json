{"cell_type":{"605aeb44":"code","0f01481e":"code","aa272936":"code","1a04723e":"code","be7bfc89":"code","2f89d64c":"code","48c9f6d1":"code","09533131":"code","156d69b2":"code","e665d312":"code","24e7acc5":"code","ffb82d54":"code","97aa64a2":"code","d6677cb8":"code","ee96ca58":"code","d1bc8503":"code","5da88e4e":"code","a55c0e37":"code","8065a4b5":"code","54dbe1f9":"code","1f9abacd":"code","131622e5":"code","1954fcea":"code","795c86e8":"code","db43aa95":"markdown","08bcbc8d":"markdown","9670462d":"markdown","60fe82f0":"markdown","bd950413":"markdown","9e6bdf0a":"markdown","3431f08b":"markdown","8b356488":"markdown","d944ff06":"markdown","4e2977bb":"markdown","d4159037":"markdown","cea34156":"markdown","7ef23b34":"markdown","68e31371":"markdown","10cb7835":"markdown","2b249185":"markdown","ec63c6c1":"markdown","34108770":"markdown","3c61d7f2":"markdown","ccb6147d":"markdown","0f149db4":"markdown","0bbc1056":"markdown","865adb05":"markdown"},"source":{"605aeb44":"import pandas as pd\nimport numpy as np\nimport os\nimport requests\nimport json\nimport datetime\nimport time\nimport glob\nimport collections\nimport time\n\nimport torch as th\nfrom torch import nn","0f01481e":"## You should configure these to your needs. Choose one of ...\n# 'hungry-geese', 'rock-paper-scissors', santa-2020', 'halite', 'google-football'\nCOMP = 'lux-ai-2021'","aa272936":"ROOT =\".\"\nMETA = \"..\/input\/meta-kaggle\/\"\nCOMPETITIONS = {\n    'lux-ai-2021': 30067,\n    'hungry-geese': 25401,\n    'rock-paper-scissors': 22838,\n    'santa-2020': 24539,\n    'halite': 18011,\n    'google-football': 21723\n}","1a04723e":"# Load Episodes\nst = time.time()\nepisodes_df = pd.read_csv(META + \"Episodes.csv\", usecols=['CompetitionId','Id'])\nprint(time.time()-st)\nprint(f'Episodes.csv: {len(episodes_df)} rows before filtering.')\nepisodes_df = episodes_df[episodes_df.CompetitionId == COMPETITIONS[COMP]] \nprint(f'Episodes.csv: {len(episodes_df)} rows after filtering for {COMP}.')","be7bfc89":"# Load EpisodeAgents\nst = time.time()\nepagents_df = pd.read_csv(META + \"EpisodeAgents.csv\", usecols=['EpisodeId','Reward','SubmissionId','UpdatedScore'])\nprint(time.time()-st)\nprint(f'EpisodeAgents.csv: {len(epagents_df)} rows before filtering.')\nepagents_df = epagents_df[epagents_df.EpisodeId.isin(episodes_df.Id)]\nprint(f'EpisodeAgents.csv: {len(epagents_df)} rows after filtering for {COMP}.')","2f89d64c":"epagents_df = epagents_df.sort_values('EpisodeId')","48c9f6d1":"assert np.all(epagents_df.EpisodeId.values[range(0,len(epagents_df),2)] == epagents_df.EpisodeId.values[range(1,len(epagents_df),2)])","09533131":"st = time.time()\ndf = pd.DataFrame(\n    np.concatenate(\n    [epagents_df.Reward.values.reshape((int(len(epagents_df)\/2),2)), \n     epagents_df.SubmissionId.values.reshape((int(len(epagents_df)\/2),2)),\n    ], axis=1), columns = ['Reward0','Reward1','SubmissionId0','SubmissionId1'])\nprint(time.time() - st)","156d69b2":"df['winner'] = np.where(df.Reward0 > df.Reward1, df.SubmissionId0, df.SubmissionId1)\ndf['loser'] = np.where(df.Reward0 > df.Reward1, df.SubmissionId1, df.SubmissionId0)","e665d312":"df = df.loc[df.Reward0 != df.Reward1]","24e7acc5":"sz = len(df) + 1\nwhile sz > len(df):\n    sz = len(df)\n    st = time.time()\n    df = df.loc[df.SubmissionId0.isin(df.winner) & df.SubmissionId0.isin(df.loser)]\n    df = df.loc[df.SubmissionId1.isin(df.winner) & df.SubmissionId1.isin(df.loser)]\n    print(len(df), sz-len(df), time.time() - st)","ffb82d54":"items = df.winner.astype(int).unique()\nn_items = len(items)","97aa64a2":"n_items","d6677cb8":"len(df)","ee96ca58":"mapping = {s:i for i,s in zip(range(n_items), items)}","d1bc8503":"cnts = pd.value_counts(df[['SubmissionId0','SubmissionId1']].astype(int).values.reshape(-1))\nLB_scores = epagents_df.groupby('SubmissionId').apply(lambda x: x.UpdatedScore.values[-1])","5da88e4e":"games = np.stack([[mapping[int(s)] for s in df.winner.values],\n                  [mapping[int(s)] for s in df.loser.values]], axis=1)","a55c0e37":"games.shape","8065a4b5":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        R = 1000*th.ones((n_items,))\n        self.R = nn.Parameter(R.cuda())\n        self.idx_i = th.Tensor(games[:,0]).to(int).cuda()\n        self.idx_j = th.Tensor(games[:,1]).to(int).cuda()\n        \n        self.base = th.log(th.Tensor([10]).cuda())\n        \n    def forward(self):\n        \n        with th.no_grad():\n            self.R -= (self.R.mean() - 1000)\n        \n        Ri = self.R[self.idx_i]\n        Rj = self.R[self.idx_j]\n        Qi = th.pow(10, Ri \/ 400)\n        Qj = th.pow(10, Rj \/ 400)\n        \n        loss = th.log(Qi + Qj) \/ self.base - Ri \/ 400\n        \n        return loss.mean()","54dbe1f9":"model = Model()\n\nlearning_rate = 1e2\noptimizer = th.optim.Adam(model.parameters(), lr=learning_rate)","1f9abacd":"for i in range(2000):\n    loss = model()\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    loss_cpu = loss.item()\n    \n    if i % 100 == 0:\n        print(i, learning_rate, loss_cpu, model.R.min().item(), model.R.grad.abs().max().item())","131622e5":"BT_scores = model.R.cpu().detach().numpy()\n\ninfo = pd.DataFrame({'BT_score':BT_scores, 'submission':items})\ninfo = info.join(cnts.rename('episodes'), on='submission')\ninfo = info.join(LB_scores.rename('LB_score'), on='submission')\ninfo = info.loc[~info.LB_score.isnull()]\n\nnames = pd.read_csv(\"..\/input\/luxai2021-submission-team-name-score-over-1500\/submission_team_names.csv\")\n\ninfo = info.join(names[['SubmissionId','TeamName']].set_index('SubmissionId'), on='submission')\ninfo = info.loc[~info.TeamName.isnull()]\ninfo_best = info.groupby('TeamName').apply(lambda x: x.iloc[np.argmax(x.BT_score.values)])\\\n    .sort_values('BT_score', ascending=False).reset_index(drop=True)","1954fcea":"info_best.head(20)","795c86e8":"info.to_csv('BT_scores_all')\ninfo_best.to_csv('BT_scores_best')","db43aa95":"For simulation competitions Kaggle implements a rating system which calculates deltas based on submissions scores at the moment of play. This, I think, is the main problem of the system. The influence of an episode only takes the history into account and not the future. Additionally, the calculation of deltas and sigmas seems to be unscientific. The Bradley\u2013Terry rating system (BT) solves these drawbacks, a solid maximum-likelihood based method, based on ELO-like probability function and solved with global optimisation.\n\nSee info on [Bradley-Terry model](https:\/\/en.wikipedia.org\/wiki\/Bradley%E2%80%93Terry_model), and [ELO rating system](https:\/\/en.wikipedia.org\/wiki\/Elo_rating_system#Theory).\n\n\nUsing the data from meta-kaggle dataset, this notebook implements BT scoring, with ELO probability function, and gradient descent optimisation by torch. The output is BT scores for all submissions, and also separately a list of best submissions per team. The association of submission Ids to team names is thanks to the [auxilliary dataset](https:\/\/www.kaggle.com\/skyramp\/luxai2021-submission-team-name-score-over-1500). The notebook can be adopted for other simulation competitions in a straightforward way.","08bcbc8d":"Validate that the even and odd entries are from the same episode","9670462d":"Counts and LB scores will be useful later to add to the output dataframes","60fe82f0":"![Lux game screenshot](https:\/\/i.imgur.com\/OLUObS2.png)","bd950413":"# Processing the result","9e6bdf0a":"Mappins from submission Id to index","3431f08b":"Calculate who won and who lost","8b356488":"This is the model implementation, it follows formulas from [Bradley-Terry model](https:\/\/en.wikipedia.org\/wiki\/Bradley%E2%80%93Terry_model), and [ELO rating system](https:\/\/en.wikipedia.org\/wiki\/Elo_rating_system#Theory).","d944ff06":"number of submissions","4e2977bb":"number of episodes","d4159037":"Get the model's output and enrich it with auxilliary columns. Calculate the best submission per team by BT score.|","cea34156":"This is the input to the model, which is basically a list of winners and losers for each episode.","7ef23b34":"Solving with torch","68e31371":"This is what we need from the original dataframe, only submission ids and rewards (to know who won\/lost)","10cb7835":"Model and optimizer","2b249185":"Load and filter only our competition.","ec63c6c1":"The END.","34108770":"![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/30067\/logos\/thumb76_76.png?t=2021-07-20-15-37-27)","3c61d7f2":"Filter submissions which do not have at least one win and one lose. The model is not able to handle all-wins or all-loses.","ccb6147d":"The best 20 teams, ordered by their best BT-scoring subs.","0f149db4":"Filter draws. This can be replaced with 0.5 weight for win and 0.5 for lose, but it will require addition of weights.","0bbc1056":"# Model and solving","865adb05":"Save all submissions and best submissions separately."}}