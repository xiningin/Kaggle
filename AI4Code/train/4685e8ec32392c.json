{"cell_type":{"c7d5a1b0":"code","d200fd35":"code","679076d7":"code","d2d64700":"code","549082c9":"code","9ec856c9":"code","85c81450":"code","55b48169":"code","2261a3b8":"code","0cada521":"code","8a654b20":"code","75d99740":"code","04e5e274":"code","29f7ac29":"code","4a357d9c":"code","ece2c6af":"code","15ab7cea":"code","9e149b15":"code","798d9f12":"code","33252471":"code","75a4c487":"code","48a277ad":"code","131cd8e8":"code","0df102b0":"code","303be941":"code","9e5d561c":"code","5a4f4cc6":"code","796c348a":"code","b3af7f1c":"code","f228ddb2":"code","8fdfa3df":"code","a54700a2":"code","0047233e":"code","eff12cd6":"markdown","866b26b1":"markdown","6a134da4":"markdown","a5787393":"markdown","53d2e366":"markdown","e1422cca":"markdown","24bf4fb6":"markdown","890fc503":"markdown","fe8b9012":"markdown","acf850c8":"markdown","8da7a7b7":"markdown"},"source":{"c7d5a1b0":"import glob,tqdm\nimport pandas as pd,numpy as np,os,ast,seaborn as sns,matplotlib.pyplot as plt,matplotlib as mpl,cv2\n# !pip install plotly\nimport plotly_express as px\nfrom colorama import Fore, Back, Style\nimport pydicom as dicom\nsample_sub_loc = '..\/input\/siim-covid19-detection\/sample_submission.csv'\nimage_level_loc = '..\/input\/siim-covid19-detection\/train_image_level.csv'\nstudy_level_loc  = '..\/input\/siim-covid19-detection\/train_study_level.csv'\ntrain_images_loc = '..\/input\/siim-covid19-detection\/train'\ntest_images_loc = '..\/input\/siim-covid19-detection\/test'","d200fd35":"print('Number of Train Images',len(glob.glob(os.path.join(train_images_loc,'*','*','*.dcm'))),'Test Images',len(glob.glob(os.path.join(test_images_loc,'*','*','*'))))\nprint(len(glob.glob(os.path.join(train_images_loc,'*'))),len(glob.glob(os.path.join(train_images_loc,'*','*'))))","679076d7":"study_level = pd.read_csv(study_level_loc)\nstudy_level['id'] = study_level['id'].str.split('_',expand=True)[0]\nprint('Shape of study' ,study_level.shape,'Check for Nulls ',study_level.isnull().sum(),sep='\\n')\nprint('Unique IDS are ',study_level['id'].nunique())\n\n# glob.glob(os.path.join(train_images_loc,'00086460a852','*','*.dcm'))\n\nviz = study_level[['Negative for Pneumonia', 'Typical Appearance','Indeterminate Appearance', 'Atypical Appearance']].idxmax(axis=1)\nstudy_level['type'] = study_level[['Negative for Pneumonia', 'Typical Appearance','Indeterminate Appearance', 'Atypical Appearance']].idxmax(axis=1)\nstudy_level['Images_in_study_file']=study_level['id'].apply(lambda x:len(glob.glob(os.path.join(train_images_loc,x,'*','*.dcm'))))\ndisplay(study_level.head())\nplt.pie(viz.value_counts(),labels=viz.value_counts().index,autopct=lambda x:f\"{x:.2f}% \")","d2d64700":"px.histogram(study_level['Images_in_study_file'],histnorm='percent')","549082c9":"for i in study_level['id'].iteritems():\n    if len(glob.glob(os.path.join(train_images_loc,'00086460a852','*','*.dcm')))>1:\n        print(i[1]) \n# Hence study id 1:1 image","9ec856c9":"image_level = pd.read_csv(image_level_loc)\nimage_level[['id','t']]= image_level['id'].str.split('_',expand=True)\nprint('Shape of Image level',image_level.shape,'Checking Unique IDS and also (Study Instance ID)',image_level['id'].nunique(),\n     image_level['StudyInstanceUID'].nunique())\ndisplay(image_level)\n#glob.glob(os.path.join(train_images_loc,'5776db0cec75','*','*.dcm')) Work only on SUID\n#glob.glob(os.path.join(train_images_loc,'*','*','000a312787f2.dcm')) Use id like this","85c81450":"display(image_level[image_level.StudyInstanceUID=='0fd2db233deb'])\nprint(glob.glob(os.path.join(train_images_loc,'0fd2db233deb','*','*.dcm')))","55b48169":"sns.set_style('darkgrid')\nfig, axs = plt.subplots(figsize=(20,10),ncols=3)\nimage_level['boxes'].fillna(0,inplace=True)\nimage_level['count_boxes'] = image_level['boxes'].apply(lambda x:len(ast.literal_eval(x)) if x else 0)\nsns.countplot(image_level.count_boxes,ax=axs[0])\n\nimage_level['label_type'] = image_level.label.str.split(expand=True)[0]\nsns.countplot(image_level['label_type'],ax=axs[1])\n#px.histogram(image_level.StudyInstanceUID.value_counts())\n\n\n# fig = px.pie(image_level,values='label_type',names='count_boxes')\n# fig.show()","2261a3b8":"gg = image_level[image_level['StudyInstanceUID'].isin (image_level['StudyInstanceUID'].value_counts()[image_level['StudyInstanceUID'].value_counts()>1].index)]\ndisplay(gg[gg.label_type=='opacity'].groupby('StudyInstanceUID')['label_type'].describe())\ndisplay(gg[gg.label_type!='opacity'].groupby('StudyInstanceUID')['label_type'].describe())\nprint('Maximum Frequency of opacity instances for any StudyUID is ',gg[gg.label_type=='opacity'].groupby('StudyInstanceUID')['label_type'].describe()['freq'].max(),\n     'and Maximum Frequency of None instances for any StudyUID is ',gg[gg.label_type!='opacity'].groupby('StudyInstanceUID')['label_type'].describe()['freq'].max())","0cada521":"print(image_level.columns,study_level.columns)\nmerged_levels = pd.merge(image_level, study_level, left_on='StudyInstanceUID',right_on='id')\nmerged_levels['boxes'] = merged_levels['boxes'].apply(lambda x :ast.literal_eval(x) if x else x)\n# merged_levels.drop(columns=['id_x','id_y'],inplace=True)\nmerged_levels.head()","8a654b20":"display(merged_levels[merged_levels['StudyInstanceUID']=='0fd2db233deb'])","75d99740":"print(image_level.columns)\nprint(study_level.columns)","04e5e274":"sample_sub = pd.read_csv(sample_sub_loc)\nprint('Shape of Sample submission',sample_sub.shape)\nsample_sub[['id','type']] = sample_sub['id'].str.split('_',expand=True)\ndisplay(sample_sub)\npx.bar(sample_sub['type'].value_counts())\n\n#glob.glob(os.path.join(test_images_loc,'00188a671292','*','*')) Works for study ids only\n#glob.glob(os.path.join(test_images_loc,'*','*','46719b856de1.dcm')) For Image ids","29f7ac29":"for i in merged_levels.StudyInstanceUID.unique():\n    if len(glob.glob(os.path.join(train_images_loc,i,'*','*.dcm')))>8:\n        print(i,len(glob.glob(os.path.join(train_images_loc,i,'*','*.dcm'))))","4a357d9c":"def make_cord(boxes):\n    boxes = ast.literal_eval(boxes)\n    b = list()\n    for b in boxes:\n        x,y,w,h = j['x'],j['y'],j['width'],j['height']\n        b.append(x,y,w,h)\n    return b\ndef metadata(study_id):\n    bbox,label =[],[]\n    df = merged_levels[merged_levels.id_y==study_id][['boxes','type']]\n    for i in df.iterrows():\n        a,b = i[1][0],i[1][1]\n        if a :\n            bboxes = [[x['x'],x['y'],x['x']+x['width'],x['y']+x['height']] for x in a]\n            bbox.append(bboxes)\n        else:\n            bbox.append([[-1,-1,-1,-1]])\n        label.append(b)\n        bbox\n    return bbox,label\n\ndef show_img(studyid,figsize=20):\n    if not isinstance(studyid, str):\n        for i in studyid:\n            show_img(i,figsize\/\/len(studyid))\n        return\n    dcms = glob.glob(os.path.join(train_images_loc,studyid,'*','*.dcm'))\n    row = ((len(dcms)-1)\/\/3)+1\n    ncols = 3 if len(dcms)>3 else len(dcms)\n    fig,axes = plt.subplots(figsize=(figsize,figsize),ncols=ncols,nrows =row)\n    meta_data = metadata(studyid)\n    for cnt,path in enumerate(dcms):\n        data = dicom.dcmread(path)\n        msg = meta_data[1][cnt].split()[0]+' Body Part '+data['BodyPartExamined'].value +' SEX  '+ data[\"PatientSex\"].value\n        img = data.pixel_array\n#         print(meta_data[0][cnt],meta_data[1][cnt])\n#         Loc '\/'.join(path.split('\/')[-2:])\n        if meta_data[0][cnt]:       \n            for x1, y1, x2, y2 in meta_data[0][cnt]:\n                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n                img = cv2.rectangle(img,(x1, y1), (x2, y2), color = [0,0,255], thickness = 10)\n        if len(dcms) == 1:\n            axes.imshow(img,cmap=\"gray\")\n            axes.axis('off')\n            axes.title.set_text(msg)\n        else:\n            axes[cnt\/\/3,cnt%3].imshow(img,cmap=\"gray\")\n            axes[cnt\/\/3,cnt%3].axis('off')\n            axes[cnt\/\/3,cnt%3].title.set_text(msg)","ece2c6af":"show_img('0fd2db233deb')","15ab7cea":"for i in merged_levels[(merged_levels['type']=='Negative for Pneumonia')]['StudyInstanceUID'].unique()[:3]:\n    show_img(i,20)","9e149b15":"for i in merged_levels[(merged_levels['count_boxes']>3)& (merged_levels['type']=='Typical Appearance')]['StudyInstanceUID'].unique()[:3]:\n    show_img(i,4)","798d9f12":"for i in merged_levels[(merged_levels['count_boxes']>3)& (merged_levels['type']=='Typical Appearance')]['StudyInstanceUID'].unique()[:3]:\n    show_img(i,4)","33252471":"show_img('53b92c44a02e',10)\nshow_img('341a8f794069',10)","75a4c487":"display(image_level[image_level['StudyInstanceUID'].isin(image_level.groupby('StudyInstanceUID').count()[image_level.groupby('StudyInstanceUID').count()['id']>1].index)])","48a277ad":"# dicom.dcmread(glob.glob(os.path.join(train_images_loc,image_level.StudyInstanceUID[0],'*','*.dcm'))[0])\nelem = dicom.dcmread(glob.glob(os.path.join(train_images_loc,image_level.StudyInstanceUID[2],'*','*.dcm'))[0])\nfor i in ['BodyPartExamined','ImageType',\"PatientSex\"]:\n    print(elem[i])\nelem","131cd8e8":"display(elem)\nprint(elem.dir())","0df102b0":"attrs =['AccessionNumber', 'BitsAllocated', 'BitsStored', 'BodyPartExamined','Columns', 'DeidentificationMethod', 'HighBit', 'ImageType', 'ImagerPixelSpacing', 'InstanceNumber', 'Modality', 'PatientID', 'PatientName', 'PatientSex', 'PhotometricInterpretation', 'PixelRepresentation','Rows', 'SOPClassUID', 'SOPInstanceUID', 'SamplesPerPixel', 'SeriesInstanceUID', 'SeriesNumber', 'SpecificCharacterSet', 'StudyDate', 'StudyID', 'StudyInstanceUID', 'StudyTime']\ndef get_metadata(path):\n    elem = dicom.dcmread(path)\n#     img = elem.get('PixelData')\n    attrs =['AccessionNumber', 'BitsAllocated', 'BitsStored', 'BodyPartExamined','Columns', 'DeidentificationMethod', 'HighBit', 'ImageType', 'ImagerPixelSpacing', 'InstanceNumber', 'Modality', 'PatientID', 'PatientName', 'PatientSex', 'PhotometricInterpretation', 'PixelRepresentation','Rows', 'SOPClassUID', 'SOPInstanceUID', 'SamplesPerPixel', 'SeriesInstanceUID', 'SeriesNumber', 'SpecificCharacterSet', 'StudyDate', 'StudyID', 'StudyInstanceUID', 'StudyTime']\n    df = [path]\n    for i in attrs:\n        df.append(elem.get(i))\n    return df","303be941":"# Datasets Saved\nmeta_data_loc = '..\/input\/all-metadata\/AllMeta.csv'\nif os.path.isfile(meta_data_loc):\n    full_meta = pd.read_csv(meta_data_loc,usecols=['path']+attrs)\nelse:\n    full_meta = []\n    for i in tqdm.tqdm(glob.glob(os.path.join(train_images_loc,'*','*','*.dcm'))):\n        full_meta.append(get_metadata(i))\n    full_meta = pd.DataFrame(full_meta,columns=['path']+attrs)\n    full_meta.to_csv('AllMeta.csv')\n    \n    \nfull_meta_test = []\nfor i in tqdm.tqdm(glob.glob(os.path.join(test_images_loc,'*','*','*.dcm'))):\n    full_meta_test.append(get_metadata(i))\nfull_meta_test = pd.DataFrame(full_meta_test,columns=['path']+attrs)\nfull_meta_test.to_csv('AllMeta_test.csv')","9e5d561c":"test_images_loc","5a4f4cc6":"print(attrs)","796c348a":"#full_meta.groupby(['PatientSex','BodyPartExamined']).size().reset_index().pivot(columns='PatientSex',index='BodyPartExamined',values=0).plot(kind='bar', stacked=True)\nprint(full_meta.PatientSex.value_counts()\/len(full_meta))\nprint(full_meta.BodyPartExamined.value_counts()\/len(full_meta))\nviz = full_meta.groupby(['PatientSex','BodyPartExamined']).size().reset_index().pivot(columns='PatientSex',index='BodyPartExamined',values=0)\npx.bar(viz,y=['F','M'])","b3af7f1c":"for i in full_meta.columns:\n    print(i,full_meta[i].nunique())","f228ddb2":"merged_meta = pd.merge(merged_levels,full_meta,left_on='id_x',right_on='SOPInstanceUID')\ndisplay(merged_meta)","8fdfa3df":"viz = merged_meta.groupby(['type','BodyPartExamined']).size().reset_index().pivot(columns='BodyPartExamined',index='type',values=0)\npx.bar(viz,orientation='h')","a54700a2":"px.histogram(merged_meta['PatientName'].value_counts(),histnorm='percent')","0047233e":"from pandas_profiling import ProfileReport\nprofile_study = ProfileReport(merged_levels, title=\"Pandas Profiling Report - Train Study df\")\nprofile_study.to_widgets()","eff12cd6":"Images ","866b26b1":"So mutliple Rows with same SIUID seems to have maximum of only one row instance to be of type opacity and rest are None","6a134da4":"REFRENCES \n\nhttps:\/\/www.kaggle.com\/piantic\/siim-fisabio-rsna-covid-19-detection-basic-eda\/notebook#7.-Etc.---Pandas-Profiling-%F0%9F%8C%A4%EF%B8%8F by @Heroseo\n\nhttps:\/\/www.kaggle.com\/andradaolteanu\/siim-covid-19-3d-analysis-augmentations by @andradaolteanu\n\nhttps:\/\/www.kaggle.com\/piantic\/siim-fisabio-rsna-covid-19-detection-basic-eda by @piantic\n\nhttps:\/\/www.kaggle.com\/tanlikesmath\/siim-covid-19-detection-a-simple-eda by @tanlikesmath\n\n","a5787393":"So around 56% percent entries aare of Men \n\nAnd most have examined their chest about 80%.","53d2e366":"Image level \n\nSame length as the number of images we have.All ids are unique.\n\nSome Images have no boxes or NAN with label none 1 0 0 1 1 .\n\nTo access a picture we have to use study instance uid which are on many:1 relation with id.","e1422cca":"Multiple Patients have same Name , so Even though their identity are anonymous the names have been encoded in a particular way.\n\nAbout 60% percent of patients have only one entry and as 96% of the total patients have exactly 1 image of them , we can say for sure that a good size of sample around (40-4 = 36%) of entries are made by a person who had a test before .\n\nLet me explain this in simple step:\n1. 96-4 is the ratio of patient having multiple images of them ,(as multiple images are a product of artifacts{small problems while taking the image } .\n2. 60-40 is the ratio of patiens having single entries ,but already 4% of entries have more than 1 image so that information is of not much use.\n3. So the main calculation here is that the 4% out of that 40% are the ones have multiple images due to error so we have 36% of actual double entries .","24bf4fb6":"Study level\n\n\n6054 IDs(Points to a unique dcm)\n\nSingle class multiple options\n","890fc503":"Submission Files\n\nGiven a study id , find the image and make the prediction(class Confidence bbox)\n","fe8b9012":"Some Images on ALL TYPES ","acf850c8":"DATA FROM IMAGE\n\nos.path.join(train_images_loc,image_level.StudyInstanceUID[2],'*','*.dcm')","8da7a7b7":"MERGE THE DATAFRAME\n\nStudy level has 6054 rows and Image level has 6334 .\n\nAs in Image level we have multiple rows with same StudyInstanceUID.(0fd2db233deb)"}}