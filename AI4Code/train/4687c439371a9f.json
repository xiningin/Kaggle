{"cell_type":{"6bf92e19":"code","3a0f9c39":"code","a6d0f0e9":"code","40320f22":"code","28474e99":"code","9f5b655c":"code","97690a7f":"code","4e0bfff7":"code","6ae0d4ee":"code","cf6bde2e":"code","03996d54":"code","249ea016":"code","9e8870bf":"code","251fa0ab":"code","459f27c5":"code","8830c5a8":"code","3ed434fb":"code","7766a1d5":"code","2a9d04c0":"code","f520c832":"code","1c286d5e":"markdown","7b691dd3":"markdown","682789b1":"markdown","dc18c7fb":"markdown","db0dac68":"markdown","2b4f2c7c":"markdown","8a22e14f":"markdown","f63d44bc":"markdown","4dbe485e":"markdown","c286deb7":"markdown","661dc4c0":"markdown","27d519dc":"markdown","efc96120":"markdown"},"source":{"6bf92e19":"import os\nimport pandas as pd\nimport pickle\nimport numpy as np\nimport statistics\nimport matplotlib.pyplot as plt\n\nfrom keras import regularizers\nfrom keras.models import Sequential\nfrom keras.optimizers import SGD, RMSprop, Adam\nfrom keras.layers import Dense, Dropout, SpatialDropout2D, Flatten, Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.callbacks import LearningRateScheduler, History, EarlyStopping, ReduceLROnPlateau\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom skimage import exposure, img_as_float\nfrom skimage.feature import hog\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_curve, auc, accuracy_score\nfrom sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\nfrom tensorflow.python.client import device_lib\nfrom tqdm import tqdm\n\nimport logging\nimport urllib3\nurllib3.disable_warnings()\nlogging.captureWarnings(False)","3a0f9c39":"# data folder\ndigits_dir = \"\/kaggle\/input\/digit-recognizer\"","a6d0f0e9":"# check the local device the notebook is running\ndevice_lib.list_local_devices()","40320f22":"def get_data():\n    \"\"\" Read the training and test dataset \"\"\"\n    x_train = pd.read_csv(os.path.join(digits_dir, \"train.csv\"))  \n    x_test = pd.read_csv(os.path.join(digits_dir, \"test.csv\")) \n    # set labels\n    df_labels = pd.DataFrame(data=x_train, columns=[\"label\"])\n    y_train = pd.get_dummies(df_labels, columns=['label']).to_numpy() \n    # drop labels from train\n    x_train.drop('label', axis=1, inplace=True)\n    return x_train, x_test, y_train","28474e99":"def ideal_cnn_model(init_mode=\"glorot_uniform\", dropout=0.25, learning_rate=0.1, momentum=0.9, epochs=100, decay=False):\n    \"\"\" Ideal Conv NN architecture based on the experiments \"\"\"\n    # add convolution layers with batch normalization and maxpooling\n    model = Sequential()\n    model.add(BatchNormalization())\n    model.add(Conv2D(16, kernel_initializer=init_mode, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), padding='same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32, kernel_initializer=init_mode, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), padding='same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64, kernel_initializer=init_mode, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), padding='same'))\n    model.add(SpatialDropout2D(dropout))\n    model.add(MaxPooling2D(2))\n    model.add(BatchNormalization())\n    model.add(Conv2D(128, kernel_initializer=init_mode, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), padding='same'))\n    model.add(SpatialDropout2D(dropout))\n    model.add(MaxPooling2D(2))\n    model.add(BatchNormalization())\n    model.add(Conv2D(256, kernel_initializer=init_mode, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), padding='same'))\n    model.add(SpatialDropout2D(dropout))\n    model.add(MaxPooling2D(2))\n    model.add(BatchNormalization())\n    # flatten plus dense layer\n    model.add(Flatten())\n    model.add(Dense(256, kernel_initializer=init_mode, kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4), activation='relu')) # kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)\n    model.add(Dropout(dropout*2))\n    # prediction layer\n    model.add(Dense(10, kernel_initializer=init_mode, activation='softmax', name='preds'))\n    # compile model\n    if decay:\n        model.compile(\n            loss=\"binary_crossentropy\",\n            optimizer=SGD(learning_rate=learning_rate, decay=learning_rate\/epochs, momentum=momentum),\n            metrics=['accuracy']\n        )\n        return model\n    model.compile(\n        loss=\"binary_crossentropy\",\n        optimizer=SGD(learning_rate=learning_rate, momentum=momentum),\n        metrics=['accuracy']\n    )\n    return model","9f5b655c":"def optimal_epoch(model_histories):\n    ''' Function to return the average epoch number of cross validation models where the validation loss is at its minimum '''\n    min_epochs = []\n    for model_i in model_histories:\n        min_epochs.append(np.argmin(model_i.history['val_loss']) + 1)\n    print(\"Minimum validation loss reached in epoch {}\".format(sum(min_epochs) \/ len(min_epochs)))","97690a7f":"def plot_acc_and_loss(model_histories):\n    \"\"\" Plot the average accuracy and loss of cross validation models with respect to epochs \"\"\"\n    losses = [model_i.history['loss'] for model_i in model_histories]\n    val_losses = [model_i.history['val_loss'] for model_i in model_histories]\n    accs = [model_i.history['accuracy'] for model_i in model_histories]\n    val_accs = [model_i.history['val_accuracy'] for model_i in model_histories]\n    # get average of lists\n    losses = [statistics.mean(k) for k in zip(*losses)]\n    val_losses = [statistics.mean(k) for k in zip(*val_losses)]\n    accs = [statistics.mean(k) for k in zip(*accs)]\n    val_accs = [statistics.mean(k) for k in zip(*val_accs)]\n    # plot the loss function\n    fig, ax = plt.subplots(1, 1, figsize=(6,4))\n    ax.plot(losses, 'r', label='train')\n    ax.plot(val_losses, 'b' ,label='val')\n    ax.set_xlabel(r'Epoch', fontsize=12)\n    ax.set_ylabel(r'Loss', fontsize=12)\n    ax.legend()\n    ax.tick_params(labelsize=12)\n    # plot the accuracy\n    fig, ax = plt.subplots(1, 1, figsize=(6,4))\n    ax.plot(accs, 'r', label='train')\n    ax.plot(val_accs, 'b' ,label='val')\n    ax.set_xlabel(r'Epoch', fontsize=12)\n    ax.set_ylabel(r'Accuracy', fontsize=12)\n    ax.legend()\n    ax.tick_params(labelsize=12)","4e0bfff7":"# read the training and test dataset\nx_train, x_test, y_train = get_data()","6ae0d4ee":"# apply standard scaler's fit_transform method\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","cf6bde2e":"# convert 1d arrays to image matrixes (28x28x1) for train\nx_train_matrix = np.apply_along_axis(lambda x: x.reshape(28, 28, 1), 1, x_train)\nx_train_matrix.shape","03996d54":"# convert 1d arrays to image matrixes (28x28x1) for test\nx_test_matrix = np.apply_along_axis(lambda x: x.reshape(28, 28, 1), 1, x_test)\nx_test_matrix.shape","249ea016":"# creating data augmentaion objects with required arguments \ntrain_datagen = ImageDataGenerator(\n    rotation_range=20,\n    rescale=1.0\/255,\n    shear_range=10,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.1,\n)\ntest_datagen = ImageDataGenerator(rescale=1.0\/255)","9e8870bf":"# show the fifth picture from training dataset\nplt.figure(figsize=(10,5))\nplt.imshow(x_train_matrix[4].reshape(28, 28), cmap='gray')\nplt.show()          ","251fa0ab":"# show 16 random augmented pictures for the fifth picture\ni = 0\nfor batch in train_datagen.flow(x_train_matrix[4].reshape((1,) + x_train_matrix[1].shape), batch_size=1):\n    plt.imshow(batch.reshape(28, 28), cmap='gray') \n    plt.show()    \n    i += 1\n    if i > 16:\n        break   ","459f27c5":"epoch = 100\nbatch = 256\nlr = 0.1\nmoment = 0.9\ndropout = 0.25\ninit_mode=\"glorot_uniform\"\nmodels = []\nmodel_histories = []\ncvscores = []\nkfold = KFold(n_splits=5, shuffle=True, random_state = 42)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\nfor train_index, val_index in kfold.split(x_train_matrix):\n    # call the best awesome model of mine\n    model = ideal_cnn_model()\n    # data augmentation    \n    train_batch = train_datagen.flow(x_train_matrix[train_index], y_train[train_index], batch_size=batch)\n    test_batch = test_datagen.flow(x_train_matrix[val_index], y_train[val_index], batch_size=batch)    \n    # fit the model\n    history = model.fit(train_batch, \n                        validation_data = test_batch, \n                        epochs = epoch,\n                        callbacks = [reduce_lr],\n                        steps_per_epoch = len(x_train_matrix[train_index]) \/\/ batch,\n                        validation_steps = len(x_train_matrix[val_index]) \/\/ batch,\n                        verbose=0)\n    model_histories.append(history)\n    models.append(model)\n    # evaluate the model\n    scores = model.evaluate(test_batch, verbose=0) \n    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n    cvscores.append(scores[1] * 100)\n# overall score\nprint(\"Overall: %.2f%% (+\/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))","8830c5a8":"plot_acc_and_loss(model_histories)","3ed434fb":"optimal_epoch(model_histories)","7766a1d5":"# define the parameter set you would like to try in grid search\ndropout = [0.2, 0.225, 0.25] \nlearning_rate = [0.075, 0.1, 0.125]\nbatches = [64, 96, 128]\ninit_mode = ['uniform', 'glorot_uniform', 'lecun_uniform', 'he_uniform', 'normal', 'glorot_normal', 'he_normal']\n\ndef run_grid():\n    # define keras classifier by giving our model as parameter\n    model_CV = KerasClassifier(build_fn=ideal_cnn_model, verbose=0)\n    # grid search\n    param_grid = dict(batch_size=batches, dropout=dropout, learning_rate=learning_rate, init_mode=init_mode)\n    grid = RandomizedSearchCV(model_CV, \n                              param_grid,\n                              cv=3, \n                              n_iter=25,  \n                              verbose=10)\n    grid_result = grid.fit(x_train_matrix, y_train, epochs=25)\n# run_grid()","2a9d04c0":"def most_frequent(lst):\n    return max(set(lst), key = lst.count)\n\npred_list = [model_i.predict_classes(test_datagen.flow(x_test_matrix, shuffle=False)) for model_i in models]\npreds = [most_frequent(tple) for tple in list(zip(*pred_list))]","f520c832":"# Save test predictions to file\ntest_df = pd.read_csv(os.path.join(digits_dir, \"test.csv\")) \noutput = pd.DataFrame({'ImageId': test_df.index + 1,\n                       'Label': preds})\noutput.to_csv(\"\/kaggle\/working\/\" + 'submission.csv', index=False)","1c286d5e":"### 2. Image Data Augmentation","7b691dd3":"### 3. Try a couple of different CNN architecture and compare\nPlay around with the architecture of CNN to find an ideal one for the problem. A short report about the classification results using a bunch of architectures is shared at the end.\n","682789b1":"### Analyze Model","dc18c7fb":"# Discussion \/ Last Notes\n\nA couple of suggestions\/rules of thumbs for the CNN architecture and some other stuff:\n* Do not use Dropout layer after a convolutional filter, use SpatialDropout instead. Check the official documentation here for better understanding: \nhttps:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/SpatialDropout2D\n* I won't suggest using H.O.G. (Histogram of Oriented Gradients), instead it is better to use a number of convolutional layers one after another.\n* The Adaptive Histogram Equalization didn't help me to increase classification score. If one somehow increase the performance using any of the equalization technique please let me know in the comments :)\n* If you do an image data augmentation but somehow see a negative impact then probably you are doing it wrong: which means you are creating unrepresentative set of images by rotating\/cropping\/shadowing\/zooming\/brightening and etc.\n* I would really suggest using batch normalization between convolutional layers which helps for smoother optimization and helps generalization. You can go through this awesome artichle to have better understanding on BN layers:\nhttps:\/\/towardsdatascience.com\/batch-normalization-in-3-levels-of-understanding-14c2da90a338\n","db0dac68":"### 1. Load Datasets\n\n","2b4f2c7c":"### Get Data","8a22e14f":"### Define CNN Architecture\nHere we have a function that define the CNN model architecture, compiles it and return the model. Throughout the journey I have done a set of experiments using different model architectures, later on you will see a report having overall validation accuracy of different architectures which were tested in cross validation.","f63d44bc":"# Grid Search\nTo have best set of parameters you can do a grid search on the ideal CNN architecture. Since we define the model in a parametrized function it would be much more easier to do a Grid Search (or Randomized Search) and try a set of parameters.\nI am not doing that here since it will take too much time, but one can easily modify the code and do this.","4dbe485e":"# Train a CNN Model","c286deb7":"# About the Notebook\nIn this notebook we will solve the digit classification problem using CNN approach.\nThroughout the notebook you will see and learn a couple of things about how this problem can be solved in an optimal way. You will learn about:\n* CNN architectures, how complicated the CNN architecture should be: you will see the accuracy results of different architectures\n* Dropout and regularization within the CNN\n* How spatial dropouts, max poolings and batch normalization should be placed between convolutional layers\n* Image data augmentation\n* Grid Search\n* Ensembling CNN models that are trained in CV (manually)\n\nLet's get started!","661dc4c0":"# Utils\nVariables and functions defined to make life easier","27d519dc":"#### Results:\n\n1. 32-64, 256 \nepochs=25, batch_size=128, lr=0.1, momentum=0.9, dropout = 0.25-0.5\n  >> Overall validation accuracy on CV=3: 98.71% (+\/- 0.06%)\n\n2. 64-64-64, 256 \nepochs=25, batch_size=100, lr=0.1, momentum=0.9, dropout = 0.25-0.5\n  >> Overall validation accuracy on CV=3: 98.91% (+\/- 0.02%)\n\n3. 16-32-64-128-256, 256 \nepochs=25, batch_size=100, lr=0.1, momentum=0.9, dropout = 0.25-0.5\n  >> Overall validation accuracy on CV=3: 98.97% (+\/- 0.06%)\n\n4.  16-32-64 MaxPool(2)-128 MaxPool(2)-256 MaxPool(2), 256, \nepochs=25, batch_size=100, lr=0.1, momentum=0.9, dropout = 0.25-0.5\n  >> Overall validation accuracy on CV=3: 99.26% (+\/- 0.01%)\n\n5. 32-32-64-64 MaxPool(2), 128-128 MaxPool(2), 256-256 MaxPool(2), 256 \nepochs=25, batch_size=100, lr=0.1, momentum=0.9, dropout = 0.25-0.5\n  >> Overall validation accuracy on CV=3: 99.26% (+\/- 0.06%)","efc96120":"# Final prediction: Ensemble models from CV \n\nFor the final prediction I manually use the ensemble of models that are already trained during CV. This means for a given picture from test dataset, all 5 trained CV models will make a prediction and most frequent answer will be placed in the final submission.csv file. The reasons to do that:\n1. For the learning rate decay, a callback function is used in the model which monitors the validation scores to tune decay of the learning rate. Without a validation set, the tune of learning rate decay would be purely based on training accuracy and that would be much more poorer.\n2. Ensemble models are more robust to bias and noise in data."}}