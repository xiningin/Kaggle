{"cell_type":{"fcfc2918":"code","5b123327":"code","5a3ddec7":"code","d242bb94":"code","2df42ecd":"code","3cc511ae":"code","7d5b8bb4":"code","701149c2":"code","cec8dfb7":"code","10395a3c":"code","f5f13e22":"code","e44d41d5":"code","f49fc0fa":"code","3bc01231":"code","3b5567a6":"code","37bb1a4c":"code","15dda80b":"code","3e8ddaf8":"code","fb107208":"code","9210cabc":"code","1e58d276":"code","b856be73":"code","307860a4":"code","50816b2e":"code","4f77a62e":"code","725d21cb":"code","5c5bd60c":"code","4101bb10":"code","d246e85d":"code","d927103d":"code","6bc2dc0b":"code","af44ad66":"code","cf5df6f0":"code","1da0c15d":"code","570ed483":"code","358240f7":"code","6afc93af":"code","882d2666":"markdown","12cf6e86":"markdown","c5f5f27b":"markdown","4b6341c3":"markdown","e0e6e667":"markdown","9c7e7a38":"markdown","d269bea6":"markdown","8ac69238":"markdown","2413a5d2":"markdown","a6134774":"markdown","cbed98cc":"markdown","9ffc482b":"markdown","cac64362":"markdown","3655b287":"markdown","5ac1c05f":"markdown","33129a14":"markdown","45e1dd97":"markdown","73c373a5":"markdown","eb4bd53e":"markdown","4162d706":"markdown","4521db95":"markdown","ddcb5bcc":"markdown","ea828b45":"markdown","f0033080":"markdown"},"source":{"fcfc2918":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5b123327":"pip install Lifetimes","5a3ddec7":"from sqlalchemy import create_engine\nimport datetime as dt\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport lifetimes\nfrom lifetimes import BetaGeoFitter #BG\/BND = Conditional Expected Number of Transaction\nfrom lifetimes import GammaGammaFitter# GAMMA GAMMA SUBMODEL = Conditional Expected AVG PROFIT\nfrom lifetimes.plotting import plot_period_transactions\nfrom sklearn.preprocessing import MinMaxScaler\nimport warnings # Warnings\nimport plotly.express as px # Visualization Operations\n\nwarnings.filterwarnings(\"ignore\") # We ignored the warnings.\npd.set_option('display.expand_frame_repr', False)\npd.set_option('display.float_format', lambda x: '%.4f' % x) # 4 digits after the comma","d242bb94":"def load_retail_data(pathname):\n    \"\"\"\n    Function created to retrieve Online Retail II datasets.\n    \n     Parameters\n     -----------\n     pathname str, optional\n         The index of the dataset.\n    \n     Returns\n     -----------\n     pd.DataFrame\n         Returned dataset by index.\n    \"\"\"\n    return pd.read_csv(pathname, sep=\";\")","2df42ecd":"def outlier_thresholds(dataframe, variable:str):\n    \"\"\"\n    This function is used to set the up and low limits in the outlier.\n    \n     Parameters\n     ------------\n     dataframe pd.DataFrame\n         Dataset for outlier thresholds\n         \n     variable: str\n         The variable column to deal with depending on the problem\n    \n     Returns\n     ------------\n     low_limit: int, float\n         low limit for outlier\n     up_limit: int, float\n         up limit for outlier\n    \n    \"\"\"\n    quartile1 = dataframe[variable].quantile(0.01)\n    quartile3 = dataframe[variable].quantile(0.99)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n","3cc511ae":"def replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit","7d5b8bb4":"df_ = load_retail_data('..\/input\/online-retail-ii-uci-two-peroid\/online_retail_II_2009_2010.csv')\ndf = df_.copy()","701149c2":"df.info()","cec8dfb7":"df.head()","10395a3c":"df.isnull().sum()","f5f13e22":"df.dropna(inplace=True)\ndf = df[df['Quantity'] > 0]\ndf = df[df['Price'] > 0]\ndf = df[df['Country'] == 'United Kingdom']","e44d41d5":"df = df[~df['Invoice'].str.contains('C', na=False)]","f49fc0fa":"df.describe().T","3bc01231":"replace_with_thresholds(df, \"Quantity\")\nreplace_with_thresholds(df, \"Price\")","3b5567a6":"df[\"TotalPrice\"] = df[\"Quantity\"] * df[\"Price\"]","37bb1a4c":"df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\ntoday = df['InvoiceDate'].max() + pd.DateOffset(days=2)","15dda80b":"cltv_df = df.groupby('Customer ID').agg({\n    'InvoiceDate': [\n        lambda recency: (recency.max() - recency.min()).days,\n        lambda customer_age: (today - customer_age.min()).days\n    ],\n    'Invoice': lambda frequency: frequency.nunique(),\n    'TotalPrice': lambda total_price: total_price.sum()\n})","3e8ddaf8":"cltv_df.head()","fb107208":"cltv_df.columns = cltv_df.columns.droplevel(0)\ncltv_df.columns = ['recency', 'T', 'frequency', 'monetary']\ncltv_df.head()","9210cabc":"cltv_df[\"monetary\"] = cltv_df[\"monetary\"] \/ cltv_df[\"frequency\"]","1e58d276":"cltv_df = cltv_df[(cltv_df['frequency'] > 1)]","b856be73":"cltv_df[\"recency\"] = cltv_df[\"recency\"] \/ 7\n\ncltv_df[\"T\"] = cltv_df[\"T\"] \/ 7","307860a4":"bgf = BetaGeoFitter(penalizer_coef=0.001)\n\nbgf.fit(\n    cltv_df['frequency'],\n    cltv_df['recency'],\n    cltv_df['T']\n)\n","50816b2e":"# 1 Month\n\ncltv_df[\"expected_purc_1_month\"] = bgf.predict(4,\n                                               cltv_df['frequency'],\n                                               cltv_df['recency'],\n                                               cltv_df['T'])","4f77a62e":"cltv_df.sort_values(\"expected_purc_1_month\", ascending=False).head(20)","725d21cb":"# 1 Week\ncltv_df[\"expected_purc_1_week\"] = bgf.predict(1,\n                                               cltv_df['frequency'],\n                                               cltv_df['recency'],\n                                               cltv_df['T'])","5c5bd60c":"cltv_df.sort_values(\"expected_purc_1_week\", ascending=False).head(20)","4101bb10":"ggf = GammaGammaFitter(penalizer_coef=0.01)\n\nggf.fit(\n    cltv_df['frequency'],\n    cltv_df['monetary']\n)","d246e85d":"cltv_df[\"expected_average_profit\"] = ggf.conditional_expected_average_profit(cltv_df['frequency'],\n                                                                             cltv_df['monetary'])","d927103d":"cltv_df.head()","6bc2dc0b":"cltv = ggf.customer_lifetime_value(\n    bgf,\n    cltv_df['frequency'],\n    cltv_df['recency'],\n    cltv_df['T'],\n    cltv_df['monetary'],\n    time=12,\n    discount_rate=0.01,\n    freq=\"W\"\n).sort_values(ascending=False)\n","af44ad66":"cltv.head()","cf5df6f0":"cltv = cltv.reset_index()\ncltv_final = cltv_df.merge(cltv, on='Customer ID', how=\"left\")\ncltv_final.head()","1da0c15d":"scaler = MinMaxScaler(feature_range=(0, 1))\nscaler.fit(cltv_final[[\"clv\"]])\ncltv_final[\"scaled_clv\"] = scaler.transform(cltv_final[[\"clv\"]])\n\ncltv_final.sort_values(by=\"scaled_clv\", ascending=False).head(10)","570ed483":"cltv_final[\"segment\"] = pd.qcut(cltv_final[\"scaled_clv\"], 4, labels=[\"D\", \"C\", \"B\", \"A\"])\n\ncltv_final.sort_values(by=\"scaled_clv\", ascending=False).head(10)","358240f7":"cltv_final.describe().T","6afc93af":"# # credentials.\ncreds = {'user': 'ismail',\n         'passwd': 'ismail123',\n         'host': '12.12.123.123',\n         'port': 1234,\n         'db': 'ismail'}\n\n# MySQL conection string.\nconnstr = 'mysql+mysqlconnector:\/\/{user}:{passwd}@{host}:{port}\/{db}'\n\n# # sqlalchemy engine for MySQL connection.\n# conn = create_engine(connstr.format(**creds))\n\n# # conn.close()\n\n# pd.read_sql_query(\"show databases;\", conn)\n# pd.read_sql_query(\"show tables\", conn)\n\n# ## In this step, we send our database data that we connect remotely.\n# cltv_final.to_sql(name='ismailhakki_ozcelik', con=conn,\n#                   if_exists='replace', index=False)\n\n# pd.read_sql(\"show tables\", conn)\n# pd.read_sql_query(\"select * from ismailhakki_ozcelik limit 10\", conn)","882d2666":"#### Let's look at the 20 people most likely to make purchases in a month","12cf6e86":"### BG\/NBD model asks us for recency and T expression weekly, let's adjust our data\n---","c5f5f27b":"##############################################################\n# Calculation of CLTV with BG-NBD and GG model.\n##############################################################","4b6341c3":"### Here, we see that the variables have doubled as levels. This is because we calculate both the recency and the age of the customer via InvoiceDate. Let's fix this and rename the variables\n---","e0e6e667":"### Let's check the number of values that are NA\n---","9c7e7a38":"!!! Now, our conditional expected number of transaction prediction model has been created.\n\n####  adding expected_purc_1_week  and expected_purc_1_month #####","d269bea6":"### When Quantity and Price are examined, we can see that there are outliers in the last 25% quarter. Let's suppress them too\n---","8ac69238":"* The remote server sending code is as above. You can edit and use the necessary settings according to yourself. \n* creds = {'user': 'ismail',\n         'passwd': 'ismail123',\n         'host': '12.12.123.123',\n         'port': 1234,\n         'db': 'ismail'}\n* **Just change this part\n\n#### let data be your best friend :D","2413a5d2":" ### Comment:\n When we look at the estimation results, it is seen that avg monetary and expected avg profit are close to values.\n so we can see that it makes a consistent estimation\n When we look at the scaled_clv value, we see that the average is 111\/1000 (About 11%)\n This is because the majority of customers make small-scale purchases\n and accordingly it causes low clv\n This can also be explained by Pareto analysis; So the company's top 20% customers\n It accounts for 80% of sales. Since there is no homogeneous structure between customers, clv is quite low.","a6134774":"### Let's calculate recency, T, frequency and monetary in customer breakdown\n---","cbed98cc":"#### !!! We observe that those with high frequency and monetary values are shown at the top of the list.","9ffc482b":"### Let's set our analysis date to be two days after the last day in the dataset. We will use this when calculating the age of the customer\n---","cac64362":"### We will cover the data preprocessing step in depth in another dataset later. For now all NA will be deleted and we will only work with United Kingdom\n---","3655b287":"### To build our forecasting model, we need to select customers who make us multiple purchases.\n---","5ac1c05f":"Let's calculate the average profit","33129a14":"### Ayk\u0131r\u0131 g\u00f6zlemleri bask\u0131lamak i\u00e7in kullan\u0131yoruz","45e1dd97":"## CLTV PREDICTION WITH BGNBD & GG AND SENDING RESULTS TO REMOTE SERVER ##\n----\n##### BUSINESS PROBLEM\n An e-commerce site wants a forward projection for customer actions according to the CLTV values of its customers.\n With the dataset in your hand, is it possible to identify the customers who can generate the most revenue within\n 1-month or 6-month time periods?\n\n##### DATASET STORY\n The dataset named Online Retail II includes the sales of a UK-based online store between 01\/12\/2009 - 09\/12\/2011.\n The product catalog of this company includes souvenirs. They can also be considered as promotional items.\n There is also information that most of its customers are wholesalers.\n\n##### VARIABLES\n* InvoiceNo \u2013 If the Invoice Number starts with C, it represents the canceled invoice\n* StockCode \u2013 Product code, unique code\n* Description \u2013 Product name\n* InvoiceDate \u2013 Invoice date\n* Price \u2013 Invoice price (Sterling)\n* Customer ID \u2013 Unique customer number\n* Country \u2013 Country name\n","73c373a5":"##############################################################\n#  Establishment of BG-NBD Model\n##############################################################","eb4bd53e":"### Let's also remove all canceled invoices\n---","4162d706":"#### Let's merge our dataset with the model we created","4521db95":"#### Let's scale the clv value between zero and one to better analyze and observe","ddcb5bcc":"### Let's calculate the total fee based on observation\n---","ea828b45":"#### !!! With the Gamma submodel model, we made the estimation of the conditional expected average profit.","f0033080":"##############################################################\n#  GAMMA-GAMMA SubModel\n##############################################################"}}