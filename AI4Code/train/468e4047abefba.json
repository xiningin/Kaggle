{"cell_type":{"fbfffecb":"code","69c04900":"code","83a45a35":"code","2a26c744":"code","b533debb":"code","e2823f6c":"code","807b03df":"code","a1c6eeb2":"code","548285da":"code","ead005e4":"code","4e83d956":"code","7174a6b1":"code","8c8220b2":"code","3b05b2ad":"code","4a268a52":"code","5d3ba168":"code","d4ae900a":"code","8f2f6296":"code","bb1369aa":"code","a366c652":"code","e127e1e1":"code","e8f93c7a":"code","e8bcf778":"code","ac555227":"code","3694a380":"markdown"},"source":{"fbfffecb":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.api import VAR\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tools.eval_measures import rmse, aic\nfrom statsmodels.tsa.stattools import grangercausalitytests\nfrom statsmodels.tsa.vector_ar.vecm import coint_johansen\nfrom datetime import date\nimport math","69c04900":"# Read data\ndata_test = pd.read_csv('test.csv')\ndata_test_spain = data_test.loc[data_test.Country_Region == 'Spain']\n#data_test_spain","83a45a35":"# Read data\ndata = pd.read_csv('train.csv')\ndata_grouped = data.groupby(['Country_Region', 'Date'], as_index=False).sum()","2a26c744":"data_china_dia = data_grouped\ndata_china_dia['GrowRateConf'] = (data_china_dia.ConfirmedCases.pct_change()) +1\ndata_china_dia['GrowRateFat'] = (data_china_dia.Fatalities.pct_change()) +1\ndata_china_dia = data_china_dia.loc[data_china_dia.Country_Region == 'China']\ndata_china_dia = data_china_dia.sort_values(['Date'])\ndata_china_dia['dia_contagio'] = range(53, len(data_china_dia)+53)\ndata_china_dia = data_china_dia.drop(2592)\ndata_china_dia.head(10)","b533debb":"data_spain_dia = data_grouped\ndata_spain_dia['GrowRateConf'] = (data_spain_dia.ConfirmedCases.pct_change()) +1\ndata_spain_dia['GrowRateFat'] = (data_spain_dia.Fatalities.pct_change()) +1\ndata_spain_dia = data_spain_dia.loc[data_spain_dia.Country_Region == 'Spain']\ndata_spain_dia = data_spain_dia.sort_values(['Date'])\ndata_spain_dia = data_spain_dia.loc[data_spain_dia.Date>='2020-02-01']\ndata_spain_dia['dia_contagio'] = range(0, len(data_spain_dia))\ndata_spain_dia","e2823f6c":"data_spain_54 = data_spain_dia.loc[data_spain_dia.dia_contagio>= 54]\ndata_concatenado = pd.merge(data_spain_54, data_china_dia[['GrowRateConf', 'GrowRateFat', \n                                                           'dia_contagio', 'Country_Region']], \n                            on='dia_contagio', how='right')\ndata_concatenado.head(20)","807b03df":"for i in range(8, len(data_concatenado)):\n    data_concatenado.loc[i,'ConfirmedCases'] = data_concatenado.loc[i-1,'ConfirmedCases'] \\\n                                                * data_concatenado.loc[i,'GrowRateConf_y']\n    data_concatenado.loc[i,'Fatalities'] = data_concatenado.loc[i-1,'Fatalities'] \\\n                                                * data_concatenado.loc[i,'GrowRateFat_y']\ndata_concatenado      \n        ","a1c6eeb2":"data_merge = pd.merge(data_concatenado[['Date', 'ConfirmedCases', 'Fatalities', 'dia_contagio', 'GrowRateConf_y']], \n                      data_test_spain[['Date']], on='Date', how='right')\n\ndata_merge['ConfirmedCases'] = data_concatenado.iloc[range(0, len(data_merge)), 3]\ndata_merge['Fatalities'] = data_concatenado.iloc[range(0, len(data_merge)), 4]\ndata_merge['GrowRateConf_y'] = data_concatenado.iloc[range(0, len(data_merge)), 8]\ndata_merge['dia_contagio'] = data_concatenado.iloc[range(0, len(data_merge)), 7]\ndata_merge.columns = ['Date', 'ConfirmedCases', 'Fatalities', 'Dia_contagio', 'Factor']\ndata_merge","548285da":"data_concatenado.ConfirmedCases.plot()","ead005e4":"data_concatenado.Fatalities.plot()","4e83d956":"data_escogida = data_merge[['ConfirmedCases','Fatalities']]","7174a6b1":"data_escogida.plot(figsize=(20,5))","8c8220b2":"# Get dimensions\ndata_escogida.shape","3b05b2ad":"# Plot\nfig, axes = plt.subplots(nrows=1, ncols=2, dpi=120, figsize=(7,3))\nfor i, ax in enumerate(axes.flatten()):\n    data = data_escogida[data_escogida.columns[i]]\n    ax.plot(data, color='red', linewidth=1)\n    # Decorations\n    ax.set_title(data_escogida.columns[i])\n    ax.xaxis.set_ticks_position('none')\n    #plt.setp(ax.xaxis.get_majorticklabels(), rotation=90)\n    ax.set_xticks(data.index[::4])\n    ax.set_xticklabels(data.index[::4], rotation=67)\n    ax.yaxis.set_ticks_position('none')\n    ax.spines[\"top\"].set_alpha(0)\n    ax.tick_params(labelsize=5)\n\nplt.tight_layout();","4a268a52":"maxlag=12\ntest = 'ssr_chi2test'\ndef grangers_causation_matrix(data, variables, test='ssr_chi2test', verbose=False):    \n    \"\"\"Check Granger Causality of all possible combinations of the Time series.\n    The rows are the response variable, columns are predictors. The values in the table \n    are the P-Values. P-Values lesser than the significance level (0.05), implies \n    the Null Hypothesis that the coefficients of the corresponding past values is \n    zero, that is, the X does not cause Y can be rejected.\n\n    data      : pandas dataframe containing the time series variables\n    variables : list containing names of the time series variables.\n    \"\"\"\n    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n    for c in df.columns:\n        for r in df.index:\n            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n            p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]\n            if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')\n            min_p_value = np.min(p_values)\n            df.loc[r, c] = min_p_value\n    df.columns = [var + '_x' for var in variables]\n    df.index = [var + '_y' for var in variables]\n    return df\n\ngrangers_causation_matrix(data_escogida, variables = data_escogida.columns)","5d3ba168":"plt.matshow(data_escogida.corr())","d4ae900a":"lq = 12*(71\/100)**(1\/4)\ndef cointegration_test(df, alpha=0.05): \n    \"\"\"Perform Johanson's Cointegration Test and Report Summary\"\"\"\n    out = coint_johansen(df,-1,round(lq))\n    d = {'0.9':0, '0.95':1, '0.99':2}\n    traces = out.lr1\n    cvts = out.cvt[:, d[str(1-alpha)]]\n    def adjust(val, length= 6): return str(val).ljust(length)\n\n    # Summary\n    print('Name   ::  Test Stat > C(95%)    =>   Signif  \\n', '--'*20)\n    for col, trace, cvt in zip(df.columns, traces, cvts):\n        print(adjust(col), ':: ', adjust(round(trace,2), 9), \">\", adjust(cvt, 8), ' =>  ' , trace > cvt)\n\ncointegration_test(data_escogida)","8f2f6296":"nobs = 10\ndata_escogida_train, data_escogida_test = data_escogida[0:-nobs], data_escogida[-nobs:]\n\n# Check size\nprint(data_escogida_train.shape)\nprint(data_escogida_test.shape)","bb1369aa":"def adfuller_test(series, signif=0.05, name='', verbose=False):\n    \"\"\"Perform ADFuller to test for Stationarity of given series and print report\"\"\"\n    r = adfuller(series, autolag='AIC')\n    output = {'test_statistic':round(r[0], 4), 'pvalue':round(r[1], 4), 'n_lags':round(r[2], 4), 'n_obs':r[3]}\n    p_value = output['pvalue'] \n    def adjust(val, length= 6): return str(val).ljust(length)\n\n    # Print Summary\n    print(f'    Augmented Dickey-Fuller Test on \"{name}\"', \"\\n   \", '-'*47)\n    print(f' Null Hypothesis: Data has unit root. Non-Stationary.')\n    print(f' Significance Level    = {signif}')\n    print(f' Test Statistic        = {output[\"test_statistic\"]}')\n    print(f' No. Lags Chosen       = {output[\"n_lags\"]}')\n\n    for key,val in r[4].items():\n        print(f' Critical value {adjust(key)} = {round(val, 3)}')\n\n    if p_value <= signif:\n        print(f\" => P-Value = {p_value}. Rejecting Null Hypothesis.\")\n        print(f\" => Series is Stationary.\")\n    else:\n        print(f\" => P-Value = {p_value}. Weak evidence to reject the Null Hypothesis.\")\n        print(f\" => Series is Non-Stationary.\")","a366c652":"for name, column in data_escogida_train.iteritems():\n    adfuller_test(column, name=column.name)\n    print('\\n')","e127e1e1":"def weird_log(d):\n    return math.log(d) if d else 0\n\ncolumn_names = [\"ConfirmedCases\", \"Fatalities\"]\ndata_spain_train_log = pd.DataFrame(columns = column_names)\n\nfor i in data_spain_train.index:\n    log_confirmedcases_aux = weird_log(data_spain_train.loc[i,'ConfirmedCases'])\n    log_fatalities_aux = weird_log(data_spain_train.loc[i,'Fatalities'])\n    data_spain_train_log = data_spain_train_log.append({'ConfirmedCases':log_confirmedcases_aux, 'Fatalities':log_fatalities_aux}, ignore_index = True)\n\ndata_spain_train_log.index = data_spain_train.index\n\n#data_spain_train_log = data_spain_train_log.loc[data_spain_train_log.index>'2020-02-08', :]\n\ndata_spain_train_log.tail(50)","e8f93c7a":"data_spain_train_log_differenced = data_spain_train_log.diff().dropna()\ndata_spain_train_log_differenced2 = data_spain_train_log_differenced.diff().dropna()\ndata_spain_train_log_differenced3 = data_spain_train_log_differenced2.diff().dropna()\n\ndata_spain_train_log_differenced3 = data_spain_train_log_differenced3.loc[data_spain_train_log_differenced3.index>'2020-02-24', :]\n\ndata_spain_train_log_differenced3.tail(50)","e8bcf778":"for name, column in data_spain_train_log_differenced3.iteritems():\n    adfuller_test(column.loc[column>0], name=column.name)\n    print('\\n')","ac555227":"data_spain_train_log_differenced3.plot(figsize = (20, 5))","3694a380":"#### Tomar diferencias"}}