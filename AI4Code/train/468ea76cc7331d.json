{"cell_type":{"adf33ca8":"code","e3542f5a":"code","a1ba2b97":"code","0f59f269":"code","0ee3c2f6":"code","d26149ff":"code","ba07b12f":"code","8c466dec":"code","bb1913d9":"code","efadce70":"code","6791eb24":"code","310640d5":"code","1143c106":"code","2dc172c6":"code","fe09fd5e":"code","a3404e27":"code","159a8553":"code","73333749":"code","73253748":"code","bb0c31c6":"code","ad762da0":"code","bf5fe87c":"code","3b7622fe":"markdown","77ff2d15":"markdown","9157fece":"markdown","86b6c66a":"markdown"},"source":{"adf33ca8":"# Import the Library\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\nsns.set_style(\"whitegrid\")\nplt.style.use(\"fivethirtyeight\")","e3542f5a":"#feature_columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age','Target']","a1ba2b97":"df = pd.read_csv(\"..\/input\/pima-indians-diabetes-database\/diabetes.csv\")#,header=None, names=feature_columns\ndf.head()","0f59f269":"df.info()","0ee3c2f6":"df.isnull().sum()","d26149ff":"pd.set_option('display.float_format', '{:.2f}'.format)\ndf.describe()","ba07b12f":"categorical_val = []\ncontinous_val = []\nfor column in df.columns:\n    print('==============================')\n    print(f\"{column} : {df[column].unique()}\")\n    if len(df[column].unique()) <= 10:\n        categorical_val.append(column)\n    else:\n        continous_val.append(column)","8c466dec":"# Visulazing the distibution of the data for every feature\nplt.figure(figsize=(20, 20))\n\nfor i, column in enumerate(df.columns, 1):\n    plt.subplot(3, 3, i)\n    df[df[\"Outcome\"] == 0][column].hist(bins=35, color='blue', label='Have Diabetes = NO', alpha=0.6)\n    df[df[\"Outcome\"]== 1][column].hist(bins=35, color='red', label='Have Diabetes = YES', alpha=0.6)\n    plt.legend()\n    plt.xlabel(column)","bb1913d9":"plt.figure(figsize=(30, 30))\nsns.pairplot(df, hue='Outcome', height=3, diag_kind='hist')","efadce70":"# Let's first check gender(male=0,female=1)\nsns.catplot('Outcome', data=df, kind='count')","6791eb24":"# Another way to visualize the data is to use FacetGrid to plot multiple kedplots on one plot\n\nfig = sns.FacetGrid(df, hue=\"Outcome\", aspect=4)\nfig.map(sns.kdeplot, 'Age', shade=True)\noldest = df['Age'].max()\nfig.set(xlim=(0, oldest))\nfig.add_legend()","310640d5":"# How many missing zeros are mising in each feature\nfeature_columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\nfor column in feature_columns:\n    print(\"============================================\")\n    print(f\"{column} ==> Missing zeros : {len(df.loc[df[column] == 0])}\")","1143c106":"from sklearn.impute import SimpleImputer\n\nfill_values = SimpleImputer(missing_values=0, strategy=\"mean\", copy=False)\n\ndf[feature_columns] = fill_values.fit_transform(df[feature_columns])","2dc172c6":"for column in feature_columns:\n    print(\"============================================\")\n    print(f\"{column} ==> Missing zeros : {len(df.loc[df[column] == 0])}\")","fe09fd5e":"# Visulazing the distibution of the data for every feature\nplt.figure(figsize=(20, 20))\n\nfor i, column in enumerate(df.columns, 1):\n    plt.subplot(3, 3, i)\n    df[df[\"Outcome\"] == 0][column].hist(bins=35, color='blue', label='Have Diabetes = NO', alpha=0.6)\n    df[df[\"Outcome\"] == 1][column].hist(bins=35, color='red', label='Have Diabetes = YES', alpha=0.6)\n    plt.legend()\n    plt.xlabel(column)","a3404e27":"from sklearn.model_selection import train_test_split\n\n\nX = df[feature_columns]\ny = df.Outcome\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.317, random_state=1)","159a8553":"from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n\n\ndef evaluate(model, X_train, X_test, y_train, y_test):\n    y_test_pred = model.predict(X_test)\n    y_train_pred = model.predict(X_train)\n\n    print(\"TRAINIG RESULTS: \\n===============================\")\n    clf_report = pd.DataFrame(classification_report(y_train, y_train_pred, output_dict=True))\n    print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_train, y_train_pred)}\")\n    print(f\"ACCURACY SCORE:\\n{accuracy_score(y_train, y_train_pred):.4f}\")\n    print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n\n    print(\"TESTING RESULTS: \\n===============================\")\n    clf_report = pd.DataFrame(classification_report(y_test, y_test_pred, output_dict=True))\n    print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_test, y_test_pred)}\")\n    print(f\"ACCURACY SCORE:\\n{accuracy_score(y_test, y_test_pred):.4f}\")\n    print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")","73333749":"from sklearn.ensemble import AdaBoostClassifier\n\nada_boost_clf = AdaBoostClassifier(n_estimators=30)\nada_boost_clf.fit(X_train, y_train)\nevaluate(ada_boost_clf, X_train, X_test, y_train, y_test)","73253748":"\nscores = {\n        'Train': accuracy_score(y_train, ada_boost_clf.predict(X_train)),\n        'Test': accuracy_score(y_test, ada_boost_clf.predict(X_test)),\n    }\nprint(\"Scores AdaBoost:\",scores)","bb0c31c6":"from sklearn.ensemble import GradientBoostingClassifier\n\ngrad_boost_clf = GradientBoostingClassifier(n_estimators=100, random_state=42)\ngrad_boost_clf.fit(X_train, y_train)\nevaluate(grad_boost_clf, X_train, X_test, y_train, y_test)","ad762da0":"scores['Gradient Boosting'] = {\n        'Train': accuracy_score(y_train, grad_boost_clf.predict(X_train)),\n        'Test': accuracy_score(y_test, grad_boost_clf.predict(X_test)),\n    }\nprint( \"Gradient Boosting:\",scores['Gradient Boosting'])","bf5fe87c":"df.corrwith(df.Outcome).plot(kind='bar', grid=True, figsize=(12, 8), title=\"Correlation with target\")","3b7622fe":"2. Data Pre-Processing","77ff2d15":"3. Use pima-indian-diabetes dataset. Apply Adaboosting Ensemble method and construct the \nclassification model for the dataset. Analyze the accuracy of your model","9157fece":"\nImplement GradientBoosting Ensemble Classifier on the dataset. Analyze the \nperformance of your model and compare your results with the previously created model ","86b6c66a":"1. Data visualization`"}}