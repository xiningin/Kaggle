{"cell_type":{"4be72d56":"code","d4bc829a":"code","287a8c8e":"code","9108d7c0":"code","2f8b321e":"code","a457c224":"code","d80d9194":"code","4cfe51dc":"code","39b63094":"markdown","eaf62ef9":"markdown","77fdc991":"markdown","e7b550cb":"markdown","8df33e7a":"markdown","a9f77be1":"markdown"},"source":{"4be72d56":"import os\nfile_path = \"..\/input\/nips-papers\/papers.csv\"","d4bc829a":"import pandas as pd\ndata = pd.read_csv(file_path)\ndata.head(4)","287a8c8e":"data = data.drop(['id','event_type','pdf_name'],axis=1)\ndata.head(4)","9108d7c0":"import matplotlib.pyplot as plt\n%matplotlib inline\ncounts = data.groupby('year').size()\ncounts.plot(kind='bar')","2f8b321e":"import re\nprint(data['title'].head())\n\ndata['title_cleaned'] = data['title'].map(lambda x: re.sub('[,.\\!?]','',x))\n\ndata['title_cleaned'] = data['title_cleaned'].str.lower()\n\nprint(data['title_cleaned'].head())","a457c224":"from wordcloud import WordCloud\nlong_string = ' '.join(data['title_cleaned'])\n\nwordcloud = WordCloud().generate(long_string)\nwordcloud.to_image()","d80d9194":"from sklearn.feature_extraction.text import CountVectorizer\nimport numpy as np\ndef plot_10_most_common_words(count_data, count_vectorizer):\n    import matplotlib.pyplot as plt\n    words = count_vectorizer.get_feature_names()\n    total_counts = np.zeros(len(words))\n    for t in count_data:\n        total_counts+=t.toarray()[0]\n    \n    count_dict = (zip(words, total_counts))\n    count_dict = sorted(count_dict, key=lambda x:x[1], reverse=True)[0:10]\n    words = [w[0] for w in count_dict]\n    counts = [w[1] for w in count_dict]\n    x_pos = np.arange(len(words)) \n\n    plt.bar(x_pos, counts,align='center')\n    plt.xticks(x_pos, words, rotation=90) \n    plt.xlabel('words')\n    plt.ylabel('counts')\n    plt.title('10 most common words')\n    plt.show()\n\ncount_vectorizer = CountVectorizer(stop_words='english')\ncount_data = count_vectorizer.fit_transform(data['title_cleaned'])\nplot_10_most_common_words(count_data,count_vectorizer)","4cfe51dc":"import warnings\nwarnings.simplefilter(\"ignore\", DeprecationWarning)\n\n# Load the LDA model from sk-learn\nfrom sklearn.decomposition import LatentDirichletAllocation as LDA\n \n# Helper function\ndef print_topics(model, count_vectorizer, n_top_words):\n    words = count_vectorizer.get_feature_names()\n    for topic_idx, topic in enumerate(model.components_):\n        print(\"\\nTopic #%d:\" % topic_idx)\n        print(\" \".join([words[i]\n                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n        \n# Tweak the two parameters below (use int values below 15)\nnumber_topics = 10\nnumber_words = 10\n\n# Create and fit the LDA model\nlda = LDA(n_components=number_topics)\nlda.fit(count_data)\n\n# Print the topics found by the LDA model\nprint(\"Topics found via LDA:\")\nprint_topics(lda, count_vectorizer, number_words)","39b63094":"Data cleaning","eaf62ef9":"Word Cloud","77fdc991":"Using LDA to identify the hottest topic","e7b550cb":"Year wise Papers published","8df33e7a":"In this we will use NIPS dataset to identify the hottest Machine learning topic","a9f77be1":"Tokenization using count vectorizer"}}