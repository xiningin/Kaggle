{"cell_type":{"659a4935":"code","0925b2e4":"code","61a6c774":"code","cbce4997":"code","ae1f1768":"code","98bbb92d":"code","08d2f03d":"code","4023feb0":"code","0486d3d1":"code","8f3169a0":"code","71e5f8a7":"code","473f32b1":"code","d33e78e9":"code","ad29c604":"code","8744d5f2":"code","029a692c":"code","5f6adbb7":"code","6a5964cd":"code","2196cb5c":"code","2949b1eb":"code","faa3a5a6":"code","68c19694":"code","f209cd28":"code","f932e365":"code","164825c5":"code","c44443f3":"code","67092a58":"code","d4befe48":"code","6dcf2124":"code","fa92c258":"code","3756eadf":"code","b06627a3":"code","2efa7efb":"code","33baa30e":"code","7882ac24":"code","eb02a4a7":"code","e24ba7dd":"code","d57bd12a":"code","0cb966e2":"code","3e50a031":"code","c2f770d4":"code","208de561":"code","f7fb550b":"code","2fd54157":"code","6809ca8a":"code","3db1a75f":"code","a1a37ff9":"code","181a2fe5":"code","c36e4897":"code","bc77d1c6":"code","0c79948b":"code","a2f91329":"code","7b47bbfe":"code","8cd154ea":"code","5b7915c8":"code","e7cad097":"code","c90cc62f":"code","27fbdfc0":"code","71d2eab1":"code","54dfef47":"code","ebcceb64":"code","aff0f07c":"code","e497cd82":"code","5a2df6c1":"code","5245199c":"markdown","24477ce8":"markdown","eddbc8f1":"markdown","a761ce4a":"markdown","30b3bcb2":"markdown","87c9fbba":"markdown"},"source":{"659a4935":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","0925b2e4":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","61a6c774":"df = pd.read_csv('..\/input\/water-potability\/water_potability.csv')\ndf.head()","cbce4997":"df.isnull().sum()","ae1f1768":"df.info()","98bbb92d":"# Check for balance of the data in target variable","08d2f03d":"df.shape","4023feb0":"import plotly.express as px","0486d3d1":"fig = px.histogram(df['Potability'])\nfig.update_layout(bargap=0.2)\nfig.show()","8f3169a0":"# Correlation plot\n\nfig, ax = plt.subplots(figsize=(12,10))\nsns.heatmap(df.corr(), annot=True, annot_kws = {'size':9}, xticklabels=df.columns, yticklabels=df.columns, ax=ax)","71e5f8a7":"import plotly.express as px\n\nfig = px.scatter_matrix(df, df.drop('Potability', axis=1), height=1250, width=1250,)\nfig.show()","473f32b1":"na_cols = ['ph', 'Sulfate', 'Trihalomethanes']","d33e78e9":"df2 = df.dropna(subset = na_cols)","ad29c604":"df2.head()","8744d5f2":"df2.shape","029a692c":"df2.isnull().sum()","5f6adbb7":"from sklearn.model_selection import train_test_split","6a5964cd":"df2.reset_index(inplace=True, drop=True)","2196cb5c":"# df2.drop(['index'], axis=1, inplace=True)","2949b1eb":"df2.head()","faa3a5a6":"y1 = df2.loc[:, 'Potability']","68c19694":"y1.head()","f209cd28":"X1 = df2.drop(['Potability'], axis=1)","f932e365":"train_x, test_x, train_y, test_y = train_test_split(X1, y1, test_size=0.25, random_state=0)","164825c5":"# Logistic Regression\n\nfrom sklearn.linear_model import LogisticRegression\nclassifier1 = LogisticRegression(random_state=0)\nclassifier1.fit(train_x, train_y)","c44443f3":"pred1 = classifier1.predict(test_x)","67092a58":"from sklearn.metrics import confusion_matrix\ncm1 = confusion_matrix(test_y, pred1)","d4befe48":"cm1","6dcf2124":"(308+3)\/test_x.shape[0]","fa92c258":"df3 = df.drop(['Potability'], axis=1)","3756eadf":"df3.head()","b06627a3":"df3.isnull().sum()","2efa7efb":"y2 = df['Potability']","33baa30e":"df3.drop(na_cols, axis=1, inplace=True)","7882ac24":"df3.head()","eb02a4a7":"train_x2, test_x2, train_y2, test_y2 = train_test_split(df3, y2, test_size=0.25, random_state=0)","e24ba7dd":"classifier2 = LogisticRegression(random_state=0, max_iter=1000)\nclassifier2.fit(train_x2, train_y2)","d57bd12a":"pred2 = classifier2.predict(test_x2)","0cb966e2":"cm2 = confusion_matrix(test_y2, pred2)\ncm2","3e50a031":"# DecisionTree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import mean_absolute_error\n\ntree1 = DecisionTreeClassifier(random_state=0)\ntree1.fit(train_x2, train_y2)\npred3 = tree1.predict(test_x2)","c2f770d4":"mean_absolute_error(test_y2, pred3)","208de561":"from sklearn.metrics import precision_score","f7fb550b":"precision_score(test_y2, pred2, average='macro')","2fd54157":"precision_score(test_y2, pred3, average='macro')","6809ca8a":"X = df.drop('Potability', axis=1)","3db1a75f":"X.shape","a1a37ff9":"y = df['Potability']\ny.shape","181a2fe5":"train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n","c36e4897":"from sklearn.impute import SimpleImputer\n\nmy_imputer = SimpleImputer()\nimputed_train_X = pd.DataFrame(my_imputer.fit_transform(train_X))\nimputed_test_X = pd.DataFrame(my_imputer.transform(test_X))","bc77d1c6":"imputed_train_X.columns = train_X.columns\nimputed_test_X.columns = test_X.columns","0c79948b":"imputed_test_X.isnull().sum()","a2f91329":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier","7b47bbfe":"forest_model = RandomForestClassifier(n_estimators=100, random_state=0)\nforest_model.fit(imputed_train_X, train_y)\n","8cd154ea":"forest_preds = forest_model.predict(imputed_test_X)\nprint(mean_absolute_error(test_y, forest_preds))\nprint(precision_score(test_y, forest_preds, average='macro'))","5b7915c8":"tree_model2 = DecisionTreeClassifier(random_state=0)\ntree_model2.fit(imputed_train_X, train_y)\ntree_preds = tree_model2.predict(imputed_test_X)\n\nprint(mean_absolute_error(test_y, tree_preds))\nprint(precision_score(test_y, tree_preds, average='macro'))","e7cad097":"from mlxtend.preprocessing import minmax_scaling\n\nscaled_X = minmax_scaling(X, columns = X.columns)","c90cc62f":"fig, ax = plt.subplots(1,2)\nsns.distplot(X['Solids'], ax=ax[0])\nax[0].set_title(\"Original data\")\nsns.distplot(scaled_X['Solids'], ax=ax[1])\nax[1].set_title(\"Scaled data\")","27fbdfc0":"train_X3, test_X3, train_y3, test_y3 = train_test_split(scaled_X, y, train_size=0.8, test_size=0.2, random_state=0)\n\n","71d2eab1":"train_X3.isnull().sum()","54dfef47":"my_imputer = SimpleImputer()\nimputed_train_X3 = pd.DataFrame(my_imputer.fit_transform(train_X3))\nimputed_test_X3 = pd.DataFrame(my_imputer.transform(test_X3))","ebcceb64":"imputed_train_X3.columns = train_X3.columns\nimputed_test_X3.columns = test_X3.columns","aff0f07c":"imputed_train_X3.isnull().sum()","e497cd82":"forest_model2 = RandomForestClassifier(n_estimators=100, random_state=0)\nforest_model2.fit(imputed_train_X3, train_y3)\nforest_preds2 = forest_model2.predict(imputed_test_X3)\n\nprint(mean_absolute_error(test_y3, forest_preds2))\nprint(precision_score(test_y3, forest_preds2, average='macro'))","5a2df6c1":"from sklearn.metrics import accuracy_score\n\nprint(accuracy_score(test_y3, forest_preds2))","5245199c":"## Approach 2: dropping the columns with nan values","24477ce8":"# Different approaches of dealing with missing values\n## Assumption 1:-\nIf the data is missing then dropping the rows with nan values","eddbc8f1":"### Random Forest","a761ce4a":"### Random Forest gives the best result with accuracy_score of 69.66%","30b3bcb2":"The decision tree gave a better precision_score than Logistic regression in approach 2 that was to drop columns with nan values\n\n## Approach 3: filling the Nan values using imputer","87c9fbba":"## scaling the data"}}