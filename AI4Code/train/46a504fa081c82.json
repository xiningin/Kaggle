{"cell_type":{"bcea5c05":"code","69543b84":"code","389f3f76":"code","66b9656a":"code","f454b695":"code","096dd10b":"code","3d1cc925":"code","a3378877":"code","58d55ea6":"code","4ca5f8a1":"code","d08fd74e":"code","b5c11ac0":"code","618dced3":"code","fa58f5ce":"code","bd987481":"code","537091bc":"code","b66f612b":"code","f93a0f14":"code","7b07ced2":"code","271ae91a":"code","7042d116":"code","f35fa65d":"code","0a7ffd49":"code","1e3de47e":"code","ea5e06b4":"code","ad06314e":"markdown","0f840690":"markdown","eb8476ac":"markdown","557d5ad0":"markdown","0b644ad2":"markdown","51710ab1":"markdown","7929b119":"markdown","4d1b48eb":"markdown","758d6fef":"markdown","050654c0":"markdown","0881a7a6":"markdown","285d7a44":"markdown","55ba233f":"markdown","67aa0043":"markdown","4482078e":"markdown","1c35711b":"markdown","a8afbde5":"markdown","f63df225":"markdown","e7ae6f39":"markdown","e6cd7850":"markdown","d7178f8d":"markdown","caa995cc":"markdown","87461e3c":"markdown"},"source":{"bcea5c05":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","69543b84":"import pandas as pd\n\ndataset=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndataset.head()","389f3f76":"print(dataset.isnull().sum())","66b9656a":"import missingno as msno\nmsno.matrix(dataset)","f454b695":"dataset.fillna(dataset.mean(), inplace=True)\nprint(dataset.isnull().sum())","096dd10b":"dataset.drop(['PassengerId','Name','SibSp','Parch','Ticket','Cabin','Embarked'],axis='columns',inplace=True)\ndataset.head()","3d1cc925":"import seaborn as sns\nsns.pairplot(dataset, hue=\"Survived\", palette=\"Set2\", diag_kind=\"kde\", height=2.5)","a3378877":"data=dataset.drop('Survived',axis='columns')\ntarget=dataset['Survived']\ndata.head()","58d55ea6":"target.head()","4ca5f8a1":"data.columns","d08fd74e":"num_cols = data._get_numeric_data().columns\nnum_cols","b5c11ac0":"data[num_cols].hist(bins=15, figsize=(15, 6), layout=(1, 3))","618dced3":"cat_cols=data.select_dtypes('object').columns\ncat_cols","fa58f5ce":"sns.boxplot(data['Pclass'])","bd987481":"sns.boxplot(data['Age'])","537091bc":"sns.boxplot(data['Fare'])","b66f612b":"from sklearn.preprocessing import LabelEncoder\n\nle_sex=LabelEncoder()\n\ndata['sex']=le_sex.fit_transform(data['Sex'])\n\ndata=data.drop(['Sex'],axis='columns')\ninputs.head()","f93a0f14":"from sklearn.model_selection import train_test_split\n\nx_train,x_test,y_train,y_test=train_test_split(data,target,test_size=0.2,random_state=0)","7b07ced2":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nimport time\n\nmodel=DecisionTreeClassifier()\nstart=time.time()\nmodel.fit(x_train,y_train)\nstop=time.time()\n\ny_pred=model.predict(x_test)\nprint(\"Time taken is : \"+str((stop-start)*100)+\" ms\")\nprint(\"Accuracy of this model on the test set is : \"+str(accuracy_score(y_test,y_pred)*100)+\" %\")","271ae91a":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nimport time\n\nmodel1=RandomForestClassifier(n_estimators=10)\nstart=time.time()\nmodel1.fit(x_train,y_train)\nstop=time.time()\n\ny_pred=model1.predict(x_test)\nprint(\"Time taken is : \"+str((stop-start)*100)+\" ms\")\nprint(\"Random Forest Classifer accuracy is : \"+str(accuracy_score(y_test,y_pred)*100)+\" %\")","7042d116":"from xgboost import XGBClassifier\nmy_model = XGBClassifier(n_estimators=1000, learning_rate=0.05, n_jobs=4)\nmy_model.fit(x_train, y_train, \n             early_stopping_rounds=5, \n             eval_set=[(x_test, y_test)], \n             verbose=False)\ny_pred=my_model.predict(x_test)\nprint(\"Time taken is : \"+str((stop-start)*100)+\" ms\")\nprint(\"Random Forest Classifer accuracy is : \"+str(accuracy_score(y_test,y_pred)*100)+\" %\")","f35fa65d":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","0a7ffd49":"test_data.drop(['PassengerId','Name','SibSp','Parch','Ticket','Cabin','Embarked'],axis='columns',inplace=True)\ntest_data.fillna(dataset.mean(), inplace=True)\ntest_data['sex']=le_sex.fit_transform(test_data['Sex'])\ndata=test_data.drop(['Sex'],axis='columns')\ndata.head()","1e3de47e":"predictions = model.predict(data)\n\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","ea5e06b4":"def index2word(user_stat):\n    if(user_stat==[0]):\n        print(\"--------User status--------\")\n        print(\"RIP This User did not survive Titanic\")\n    else:\n        print(\"--------User status--------\")\n        print(\"Congratulations..You made it!\")\nuser1_status=model.predict([[3,22,5.044,1]])\nindex2word(user1_status)\nuser2_status=model.predict([[1,38.0,71.2833,0]])\nindex2word(user2_status)","ad06314e":"**Submissions**","0f840690":"i'm pretty sure 0th one was Jack and 1st one is Rose. 2nd one is that a-hole Cal hockley.","eb8476ac":"We are using a normal generic Decision Tree classifier to classify whether you survived or not..uh i mean the passanger survivied or not.","557d5ad0":"The Titanic data is obtained from the kaggle website. This data is a part of a kaggle competition.","0b644ad2":"**Decision Tree**","51710ab1":"Now we will use a random forest model to determine how much accuracy we will get using this robust classifier.","7929b119":"Before training the model we wish to split the data into training and testing datasets.","4d1b48eb":"The NULL values can also be visualised using the missingno library. The white portions are the row values which are missing corresponding to the feature columns.","758d6fef":"We do see some outliers in the data. But for time being we will keep it as it is as the data is diverse.","050654c0":"*We will have to do all the preprocessing again for the test data*","0881a7a6":"Our poor computer is not that advanced AI which will understand male and female., but we want that information. So what do we do?, We label encode it which means that encode all the male values to 1 and all the female values to 0. Feminazis thinking 0 is better than 1 or the other way around.","285d7a44":"We chose the Survival index as the target variable.So we kick it out from the dataset but keep it with us as a target variable for training our model.","55ba233f":"Checking how many NULL values are there under each data column field.","67aa0043":"Now let's see what's the fate of our only categorical column \"SEX\".","4482078e":"fillna fills the NaN values with a given number with which you want to substitute. It gives you an option to fill according to the index of rows of a pd.DataFrame or on the name of the columns in the form of a python dict. Inplace means it fills in the place of the old value. Here we choose to replace the NULL values with the mean of the column.","1c35711b":"OUTLIERS","a8afbde5":"**XGBoost**","f63df225":"We will now write it into the submission.csv file to submit the results on the test.csv and then submit it to the competition","e7ae6f39":"We obtain all the numerical columns here for our analysis. Since histograms are only possible on numerical data.","e6cd7850":"**Random Forest**","d7178f8d":"## Data preprocessing","caa995cc":"We hell don't care about the names and their tickets like Rose did'nt care about Jack's. So we drop the columns. Actually we could have done the NULL checking after dropping but i studied in Canara ..so we all do ulta palta things there.","87461e3c":"## Model Training"}}