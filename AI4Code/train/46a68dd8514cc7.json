{"cell_type":{"01017955":"code","e8f35bb7":"code","5e9e541d":"code","ed2f5a0e":"code","7c7cea99":"code","3e478705":"code","d098623a":"code","ec0a8024":"code","990d7a47":"code","2156fde0":"code","01ebfca7":"code","afa41fc0":"code","370a3717":"code","906d6cb5":"code","25c6e658":"code","c92d5dd3":"code","f62307d3":"code","17d89071":"code","8edb8431":"code","0e2e520a":"code","d02240ba":"code","532141c5":"code","957b5b38":"code","f913ba24":"markdown","45f02d30":"markdown","693261ac":"markdown","f71311a3":"markdown","89df3b98":"markdown"},"source":{"01017955":"seed = 300","e8f35bb7":"from math import *\nimport math\nimport numpy as np\nimport pandas as pd","5e9e541d":"Train = pd.read_csv(\"..\/input\/hta-tagging\/train.csv\")\nTrain.head(5)","ed2f5a0e":"Test = pd.read_csv(\"..\/input\/hta-tagging\/test.csv\")\nTest.head(5)","7c7cea99":"def ReadFileToDataFrame(df,path):\n    for i in range(len(df.Filename)):\n        Filename = df.Filename[i];\n        CurrentFile = \"..\/input\/hta-tagging\/{2}\/{2}\/{0}\/{1}\".format(Filename.split(\"-\")[0],Filename,path);\n        File = open(CurrentFile, \"r\");\n        contents = File.read();\n        contents = contents.replace(\"\\r\\n\",\"\\n\")\n        contents = contents.replace(\"\\r\",\"\\n\")\n        df.Filename[i] = contents\n        continue;\n    df = df.rename(columns={\"Filename\":\"Text\"},inplace=True);\nReadFileToDataFrame(Train,\"train-data\");\nTrain.head(5)","3e478705":"import codecs\ndef ReadTestFileToDataFrame(df,path): # \u0e40\u0e19\u0e37\u0e48\u0e2d\u0e07\u0e08\u0e32\u0e01 Test Set \u0e21\u0e35\u0e44\u0e1f\u0e25\u0e4c Encoding cp1252 \u0e2d\u0e22\u0e39\u0e48 \u0e08\u0e36\u0e07\u0e15\u0e49\u0e2d\u0e07\u0e2d\u0e48\u0e32\u0e19\u0e14\u0e49\u0e27\u0e22\u0e27\u0e34\u0e18\u0e35\u0e35\u0e49\n    df[\"Text\"] = [\"\"]*len(df.Id);\n    for i in range(len(df.Id)):\n        Filename = df.Id[i];\n        CurrentFile = \"..\/input\/hta-tagging\/{2}\/{2}\/{0}\/{1}\".format(Filename.split(\"-\")[0],Filename,path);\n        def Do(File):\n            contents = File.read();\n            contents = contents.replace(\"\\r\\n\",\"\\n\")\n            contents = contents.replace(\"\\r\",\"\\n\")\n            df.Text[i] = contents\n        try:\n            with codecs.open(CurrentFile, encoding='cp1252') as File:\n                Do(File);\n        except:\n            with codecs.open(CurrentFile, encoding='utf-8') as File:\n                Do(File);\n        continue;\n    df = df.rename(columns={\"Filename\":\"Text\"},inplace=True);\nReadTestFileToDataFrame(Test,\"test-data\");\nTest.head(5)","d098623a":"from sklearn.preprocessing import OneHotEncoder\ndef AnsEncoder(df, col_name):\n    for i in range(len(df[col_name])):\n        val = 0;\n        txt = df.loc[i,col_name];\n        if (txt == \"P\"): val = 2;\n        if (txt == \"Q\"): val = 1;\n        if (txt == \"N\"): val = 0;\n        df.loc[i,col_name] = val;\n        continue;\n    df[col_name] = pd.to_numeric(df[col_name]);","ec0a8024":"AnsEncoder(Train, \"Blinding of intervention\");\nAnsEncoder(Train, \"Blinding of Outcome assessment\");\nTrain.head(5)","990d7a47":"def remove_ref(text):\n    newtext = \"\";\n    for line in text.split(\"\\n\"):\n        if (line.lower()==\"references\" or line.lower()==\"reference\"): break;\n        else: newtext += line + \"\\n\";\n    return text;\n\nTrain.Text = Train.Text.apply(lambda x : remove_ref(x))\nTest.Text = Test.Text.apply(lambda x : remove_ref(x))","2156fde0":"def FindBeforeColon(text):\n    def kwreplace(cutted):\n        cutted = cutted.lower();\n        if (\"key\" in cutted): cutted = \"key\";\n        elif (\"objective\" in cutted): cutted = \"objective\";\n        elif (\"reference\" in cutted): cutted = \"reference\";\n        elif (\"method\" in cutted): cutted = \"method\";\n        elif (cutted.endswith(\"es\")): cutted = cutted[:-2];\n        elif (cutted.endswith(\"s\")): cutted = cutted[:-1];\n        return cutted;\n    tmptxt = \"\";\n    curtopic = \"\";\n    topic = [];\n    for line in text.split(\"\\n\"):\n        if (\":\" in line):\n            cutted = line.split(\":\")[0];\n            if (len(cutted)>0):\n                if (len(cutted.split(\" \")) < 6 and cutted[0] in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\" and (not \"Author\" in cutted)):\n                    cutted = kwreplace(cutted);\n                    if (curtopic != \"\"):\n                        topic.append((curtopic, tmptxt));\n                        tmptxt = \"\";\n                    curtopic = cutted;\n                    tmptxt = \"\".join(line.split(\":\")[1:]);\n                    continue;\n        if (len(line)>0):\n            if (not \" \" in line and line[0] in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"):\n                if (curtopic != \"\"):\n                        topic.append((curtopic, tmptxt));\n                curtopic = kwreplace(line);\n                tmptxt = \"\";\n                continue;\n        tmptxt += \"\\n\" + line;\n    return topic;","01ebfca7":"TO = [];\ni = 0;\nfor txt in Train.Text:\n    TO.append((i,FindBeforeColon(txt)));\n    i += 1\n\nTestO = [];\ni = 0;\nfor txt in Test.Text:\n    TestO.append((i,FindBeforeColon(txt)));\n    i += 1;","afa41fc0":"SelectedCols = [\"Text\",\"method\",\"key\"]","370a3717":"def WriteToPD(df,arr):\n    arrlength = len(arr);\n    PlaceholderList = [None]*df.shape[0];\n    for idx, optionlist in arr:\n        if (idx % 100 == 0):\n            print(\"{0}\/{1} Completed\".format(idx,arrlength));\n        for option, text in optionlist:\n            if option in SelectedCols:\n                if not option in df:\n                    df[option] = PlaceholderList;\n                df.loc[idx,option] = text;","906d6cb5":"WriteToPD(Train,TO)\nTrain.head()","25c6e658":"WriteToPD(Test,TestO)\nTrain.head()","c92d5dd3":"from sklearn.feature_extraction.text import TfidfVectorizer;\n\nclass TFIDFVector:\n    def __init__(this,train,val):\n        print(\"- TF-IDF Vector: Initializing\")\n        \n        this.tfv = TfidfVectorizer(min_df=3,  max_features=None, \n            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n            stop_words = 'english');\n        \n        print(\"- TF-IDF Vector: Preparing\");\n        \n        # \u0e16\u0e49\u0e32 Train \u0e40\u0e1b\u0e47\u0e19 Array 2 \u0e21\u0e34\u0e15\u0e34\n        if type(train[0]) != str:\n            tl2 = [];\n            for l in train:\n                tl2 += [txt for txt in l if txt != None];\n            for l in val:\n                tl2 += [txt for txt in l if txt != None];\n            print(\"- TF-IDF Vector: Fitting, This might take a while\");\n            this.tfv.fit(tl2);\n            print(\"- TF-IDF Vector: Fitted\");\n            \n            del(tl2);\n        else: # \u0e16\u0e49\u0e32 Train \u0e40\u0e1b\u0e47\u0e19 Array 1 \u0e21\u0e34\u0e15\u0e34\n            print(\"- TF-IDF Vector: Fitting, This might take a while\");\n            this.tfv.fit(list(train)+list(val));\n            print(\"- TF-IDF Vector: Fitted\");\n            \n        print(\"- TF-IDF Vector: Initialized\")\n        \n    def CreateVector(this, val, reduceshape = True):\n        # \u0e2a\u0e23\u0e49\u0e32\u0e07 Vector \u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a 1 Column (Train \u0e2b\u0e23\u0e37\u0e2d Validation) \u0e43\u0e19 Dataframe\n        print(\"- TF-IDF Vector: Creating Vector\")\n        # \u0e16\u0e49\u0e32 Train \u0e40\u0e1b\u0e47\u0e19 Array 2 \u0e21\u0e34\u0e15\u0e34\n        if type(val[0]) != str:\n            ValLength = len(val);\n            tmplist = []; i = 0;\n            \n            for ll in val:\n                if (i % max(ValLength\/\/10,1) == 0): print(\"- TF-IDF Vector: Creating Vector {0}\/{1} Completed\".format(i,ValLength));\n                tmplist.append((this.tfv.transform(['' if txt is None else txt for txt in ll])));\n                i += 1;\n            \n            v = np.stack(np.array([x.toarray() for x in tmplist]))\n            del(tmplist)\n            \n            if (reduceshape):\n                nsamples = v.shape[0];\n                value2 = np.prod(v.shape[1:])\n                v = v.reshape((nsamples,value2))\n            \n            to_return = v;\n            \n        else: \n            to_return = this.tfv.transform(val)\n        \n        print(\"- TF-IDF Vector: Vector Created\")\n        return to_return;\n        ","f62307d3":"import spacy;\nfrom sklearn.svm import SVC\nfrom sklearn.multioutput import MultiOutputRegressor\nclass SVMModel:\n    def __init__(this):\n        return;\n    def Train(this,X, Y):\n        print(\"SVMModel: Training Step will be combined with Predict State\")\n        this.X = X; this.Y = Y;\n    def SetVector(this,Vector):\n        this.VC = Vector;\n    def Predict(this,XVal):\n        X = this.VC.CreateVector(this.X); Y = this.Y;\n        del(this.X);\n        \n        this.svc = SVC(random_state=seed)\n        \n        print(\"SVMModel: Training\")\n        this.svc.fit(X, Y); del(X); del(Y);\n        print(\"SVMModel: Finished Training\")\n        \n        print(\"SVMModel: Predicting\");\n        valv = this.VC.CreateVector(XVal);\n        del(XVal);\n        tR = this.svc.predict(valv);\n        del(valv);\n        print(\"SVMModel: Predicted\");\n        \n        return tR;","17d89071":"def PredictModel(TX,TY,VX,Model):\n    print(\"Initializing Model\")\n    model = Model;\n    print(\"Training Model\")\n    model.Train((TrainX),(TrainY));\n    print(\"Predicting\")\n    global PredictedY; # Global for Debugging Perpous\n    PredictedY = model.Predict(VX);\n    return PredictedY.astype(int);","8edb8431":"Train","0e2e520a":"Test","d02240ba":"from sklearn.metrics import accuracy_score as ScoreAcc\nfrom sklearn.model_selection import train_test_split as TTS;\n\nTrainX, ValX, TrainY, ValY = TTS(Train[SelectedCols], Train['Blinding of intervention'], test_size=0.2, random_state = seed);\n_1, _2, _3, ValY2 = TTS(Train[SelectedCols], Train['Blinding of Outcome assessment'], test_size=0.2, random_state = seed);\n# if ((TrainX != _1).any() or (ValX != _2).any()): raise Exception();\nTrainX = np.array(TrainX);\nTrainY = np.array(TrainY);\nValX = np.array(ValX);\nValY = np.array(ValY);\nValY2 = np.array(ValY2);\nTrainY2 = Train['Blinding of Outcome assessment']; TrainY2 = np.array(TrainY2);\nTestX = Test[SelectedCols]; TestX = np.array(TestX);\n\nVector = TFIDFVector(np.array(Train[SelectedCols]), TestX);\n\nValX = Vector.CreateVector(ValX)\n\nSVM = SVMModel();\nSVM.SetVector(Vector);\nPredA = PredictModel(TrainX, TrainY , TestX, SVM);\nVPredA = SVM.svc.predict(ValX);\nAccA = ScoreAcc(ValY,VPredA)\n\nSVM = SVMModel();\nSVM.SetVector(Vector);\nPredB = PredictModel(TrainX, TrainY2, TestX, SVM);\nVPredB = SVM.svc.predict(ValX)\nAccB = ScoreAcc(ValY2,VPredB);\n\ndef Convert(i):\n    if i == 0: return \"N\";\n    if i == 1: return \"Q\";\n    if i == 2: return \"P\";\n\n\nFinalPred = [Convert(PredA[i])+Convert(PredB[i]) for i in range(len(PredA))];","532141c5":"Test.Prediction = FinalPred;\nSubmissionTest = Test[[\"Id\",\"Prediction\"]];\nSubmissionTest.to_csv(\"submission.csv\",index=False)\nSubmissionTest.head(5);","957b5b38":"def Convert(i):\n    if i == 0: return \"N\";\n    if i == 1: return \"Q\";\n    if i == 2: return \"P\";\n\nFinalPred = [Convert(VPredA[i])+Convert(VPredB[i]) for i in range(len(VPredA))];\n\nCorrectAns = [Convert(ValY[i])+Convert(ValY2[i]) for i in range(len(ValY))];\nfrom sklearn.metrics import accuracy_score as ScoreAcc\nFinAcc = ScoreAcc(CorrectAns,FinalPred)*100;\nprint(\"A set          = {0:.2f}%\".format(AccA))\nprint(\"B set          = {0:.2f}%\".format(AccB))\nprint(\"\u0e04\u0e30\u0e41\u0e19\u0e19\u0e17\u0e35\u0e48\u0e04\u0e32\u0e14\u0e27\u0e48\u0e32\u0e08\u0e30\u0e44\u0e14\u0e49 = {0:.2f}%\".format(FinAcc))","f913ba24":"\u0e43\u0e19 Notebook \u0e19\u0e35\u0e49 \u0e21\u0e31\u0e19\u0e2d\u0e32\u0e08\u0e08\u0e30\u0e44\u0e21\u0e48 Perfect \u0e41\u0e15\u0e48\u0e2d\u0e32\u0e08\u0e17\u0e33\u0e43\u0e2b\u0e40\u0e04\u0e38\u0e13\u0e44\u0e14\u0e49 Score \u0e2a\u0e39\u0e07\u0e44\u0e14\u0e49\n(\u0e04\u0e33\u0e40\u0e15\u0e37\u0e2d\u0e19 \u0e43\u0e0a\u0e49 Memory \u0e08\u0e33\u0e19\u0e27\u0e19\u0e21\u0e32\u0e01 \u0e41\u0e01\u0e49\u0e44\u0e21\u0e48\u0e17\u0e31\u0e19\u0e2a\u0e48\u0e07 \u0e41\u0e25\u0e30\u0e22\u0e31\u0e07\u0e21\u0e35\u0e1a\u0e31\u0e01\u0e21\u0e32\u0e01\u0e21\u0e32\u0e22 \u0e41\u0e15\u0e48\u0e2d\u0e32\u0e08\u0e21\u0e35\u0e2a\u0e48\u0e27\u0e19\u0e21\u0e35\u0e1b\u0e23\u0e30\u0e42\u0e22\u0e0a\u0e19\u0e4c\u0e2d\u0e22\u0e39\u0e48\u0e1a\u0e49\u0e32\u0e07 \u0e44\u0e21\u0e48\u0e21\u0e32\u0e01\u0e01\u0e47\u0e19\u0e49\u0e2d\u0e22)","45f02d30":"# Data Preprocessing","693261ac":"# Model","f71311a3":"# Vector","89df3b98":"# Prepare Data"}}