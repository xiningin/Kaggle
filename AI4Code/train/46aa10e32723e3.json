{"cell_type":{"76c20687":"code","ce11fd13":"code","457d63f1":"code","740bcfe8":"code","14b17f3e":"code","909d9865":"code","3a08aa4d":"code","0badd7c6":"code","7277ada1":"code","b9ff2c6f":"code","512bb9e9":"code","ede75cb7":"code","2964f7c5":"code","d072f6ca":"code","08e947d2":"code","8761c4b0":"code","13a6d7a0":"code","c77cee48":"code","3afe9a19":"code","43ebc398":"code","7319082e":"code","6ace5bf5":"code","2ec152e0":"code","b7268e44":"code","c3e872f4":"code","449cec3b":"code","86da39f5":"code","939f5903":"code","6d13a95f":"code","8f0b5f9b":"code","46fdf1b3":"markdown","a890cb92":"markdown","8114b358":"markdown","0e3b9a27":"markdown","03afc3d0":"markdown","5010c44d":"markdown","93385266":"markdown","55e06c79":"markdown","981dd19d":"markdown","e326384d":"markdown","9c328244":"markdown","c0b50521":"markdown","12dc1229":"markdown","e8db5f80":"markdown","ccaa1328":"markdown","d6d835ec":"markdown"},"source":{"76c20687":"# for numerical analysis\nimport numpy as np \n# to store and process in a dataframe\nimport pandas as pd \n\n# for ploting graphs\nimport matplotlib.pyplot as plt\n# advancec ploting\nimport seaborn as sns\n\n# image processing\nimport matplotlib.image as mpimg\n\n# train test split\nfrom sklearn.model_selection import train_test_split\n# model performance metrics\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# utility functions\nfrom tensorflow.keras.utils import to_categorical\n# sequential model\nfrom tensorflow.keras.models import Sequential\n# layers\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout","ce11fd13":"# list of files\n! ls ..\/input\/fashionmnist\/","457d63f1":"# import train and test dataset\ntrain = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\ntest = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')","740bcfe8":"# data shape\nprint(train.shape)\nprint(train.shape)","14b17f3e":"# train head\ntrain.head(4)","909d9865":"# test head\ntest.head(4) ","3a08aa4d":"# looking for missing values\nprint(train.isna().sum().sum())\nprint(test.isna().sum().sum())","0badd7c6":"# actural item corresponding to each label\nitem = {0: 'T-shirt\/top', 1: 'Trouser', 2: 'Pullover', 3: 'Dress', 4: 'Coat',\n        5: 'Sandal', 6: 'Shirt', 7: 'Sneaker', 8: 'Bag', 9: 'Ankle boot'}","7277ada1":"# label count\n\nplt.figure(figsize=(10, 3))\n\nplt.subplot(1, 2, 1)\nsns.countplot(train['label'], palette=['#333333' for i in range(10)])\nplt.title('train labels count')\nplt.plot()\n\nplt.subplot(1, 2, 2)\nsns.countplot(test['label'], palette=['#fb0203' for i in range(10)])\nplt.title('test labels count')\nplt.plot()","b9ff2c6f":"# first few train images with labels\nfig, ax = plt.subplots(figsize=(18, 8))\nfor ind, row in train.iloc[:8, :].iterrows():\n    plt.subplot(2, 4, ind+1)\n    plt.title(item[row[0]])\n    img = row.to_numpy()[1:].reshape(28, 28)\n    fig.suptitle('Train images', fontsize=24)\n    plt.axis('off')\n    plt.imshow(img, cmap='magma')","512bb9e9":"# first few test images with labels\nfig, ax = plt.subplots(figsize=(18, 8))\nfor ind, row in test.iloc[:8, :].iterrows():\n    plt.subplot(2, 4, ind+1)\n    plt.title(item[row[0]])\n    img = row.to_numpy()[1:].reshape(28, 28)\n    fig.suptitle('Test images', fontsize=24)\n    plt.axis('off')\n    plt.imshow(img, cmap='magma')","ede75cb7":"# split into image and labels and convert to numpy array\nX_train = train.iloc[:, 1:].to_numpy()\ny_train = train['label'].to_numpy()\n\nX_test = test.iloc[:, 1:].to_numpy()\ny_test = test['label'].to_numpy()\n\nfor i in [X_train, y_train, X_test, y_test]:\n    print(i.shape)","2964f7c5":"# reshaping images\nX_train = X_train.reshape(-1, 28, 28, 1)\nX_test = X_test.reshape(-1, 28, 28, 1)","d072f6ca":"# fix data type\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')","08e947d2":"# normalizing images\nX_train = X_train\/255.0\nX_test = X_test\/255.0","8761c4b0":"# one hot encoding targets\ny_train_enc = to_categorical(y_train, num_classes=10)\ny_test_enc = to_categorical(y_test, num_classes=10)","13a6d7a0":"# shape\nfor i in [X_train, y_train_enc, X_test, y_test_enc]:\n    print(i.shape)","c77cee48":"# train validation split\nX_train, X_val, y_train_enc, y_val_enc = train_test_split(X_train, y_train_enc, test_size=0.3)\nfor i in [X_train, y_train_enc, X_val, y_val_enc]:\n    print(i.shape)","3afe9a19":"INPUT_SHAPE = (28,28,1)\nOUTPUT_SHAPE = 10\nBATCH_SIZE = 128\nEPOCHS = 10\nVERBOSE = 2","43ebc398":"model = Sequential()\n\nmodel.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=INPUT_SHAPE))\nmodel.add(MaxPool2D((2,2)))\n\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPool2D((2,2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(10, activation='softmax'))","7319082e":"# If the targets are one-hot encoded, use categorical_crossentropy.\n# But if the targets are integers, use sparse_categorical_crossentropy","6ace5bf5":"model.compile(optimizer='adam', \n              loss='categorical_crossentropy', \n              metrics=['accuracy'])","2ec152e0":"model.summary()","b7268e44":"history = model.fit(X_train, y_train_enc,\n                    epochs=EPOCHS,\n                    batch_size=BATCH_SIZE,\n                    verbose=VERBOSE,\n                    validation_split=0.3)","c3e872f4":"plt.figure(figsize=(14, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\n\nplt.savefig('.\/foo.png')\nplt.show()","449cec3b":"# model loss and accuracy on validation set\nmodel.evaluate(X_val, y_val_enc)","86da39f5":"# predicted values\ny_pred_enc = model.predict(X_test)\n\n# decoding predicted values\ny_pred = [np.argmax(i) for i in y_pred_enc]\n\nprint(y_pred_enc[0])\nprint(y_pred[0])","939f5903":"# predicted targets of each images\nfig, ax = plt.subplots(figsize=(18, 8))\nfor ind, row in enumerate(X_test[:8]):\n    plt.subplot(2, 4, ind+1)\n    plt.title(item[y_pred[ind]])\n    img = row.reshape(28, 28)\n    fig.suptitle('Predicted values', fontsize=24)\n    plt.axis('off')\n    plt.imshow(img, cmap='cividis')","6d13a95f":"print(classification_report(y_test, y_pred))","8f0b5f9b":"# y_pred_item = [item[i] for i in y_pred]\n# y_test_item = [item[i] for i in y_test]\n\nfig, ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, \n            cbar=False, fmt='1d', cmap='Blues', ax=ax)\nax.set_title('Confusion Matrix', loc='left', fontsize=16)\nax.set_xlabel('Predicted')\nax.set_ylabel('Actual')\nax.set_xticklabels(item.values())\nax.set_yticklabels(item.values(), rotation=0)\nplt.show()","46fdf1b3":"### Evaluating model","a890cb92":"### Defining CNN model","8114b358":"### Model parameters","0e3b9a27":"### Model summary","03afc3d0":"### Model fitting ","5010c44d":"# Libraries","93385266":"## About the Dataset\n> * Fashion-MNIST is a dataset of of a training set of 60,000 examples and a test set of 10,000 examples.  \n> * Each example is a 28x28 grayscale image, associated with a label from 10 classes.  \n  \n> * Each training and test example is assigned to one of the following labels:\n  \n> > * 0 T-shirt\/top  \n> > * 1 Trouser  \n> > * 2 Pullover  \n> > * 3 Dress  \n> > * 4 Coat  \n> > * 5 Sandal  \n> > * 6 Shirt  \n> > * 7 Sneaker  \n> > * 8 Bag  \n> > * 9 Ankle boot  \n\n## Task\n> * To come up with a model that can predict label for each image","55e06c79":"### Predicting on test","981dd19d":"### Label count","e326384d":"# Data","9c328244":"### Accuracy and loss","c0b50521":"### Train and test images","12dc1229":"# EDA","e8db5f80":"### Compile modle","ccaa1328":"# CNN","d6d835ec":"# Preprocessing"}}