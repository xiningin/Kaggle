{"cell_type":{"e8ca8382":"code","8ef50f82":"code","89119d15":"code","6b14c490":"code","11eff928":"code","a470bf46":"code","8b05a3f7":"code","601a29a6":"code","d587b07d":"code","ab5449f7":"code","e1c07cbd":"code","fa442334":"code","7f7a8b3b":"code","9d209c5e":"code","2cc73595":"code","af83a1a8":"code","cf1c85c2":"code","b0693424":"code","0a5b6baf":"code","d76723a2":"code","628141ea":"code","db475fb6":"code","da284245":"code","be0d9bd0":"code","57adcd6a":"code","19222f6e":"code","2d99017a":"code","55902931":"code","ae30523f":"code","34f1f949":"code","e08aaddd":"code","b14adb39":"code","929538d0":"code","cec2c0a8":"code","376c9a12":"code","995ce3a5":"code","eed89485":"code","75aaaddd":"code","380cb8f3":"code","407173fe":"code","8286086d":"code","405f8aa7":"code","fcff20eb":"code","8396b644":"code","7409a82b":"code","5bf4b15f":"code","1ea10c6b":"code","7dd5ea2d":"code","1e6fcd28":"code","cb8e537a":"markdown","fe2da434":"markdown","c9cf8653":"markdown","785646e6":"markdown","b4b2a89a":"markdown","0c57f183":"markdown","d6eb9450":"markdown","1efc3f1d":"markdown","dfc63d7e":"markdown","3ee70209":"markdown","9f5effac":"markdown"},"source":{"e8ca8382":"# Basic libraries\nimport pandas as pd\nimport numpy as np\nimport time\nimport gc\nimport sys\nimport pickle\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# open cv\nimport cv2\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nimport plotly","8ef50f82":"import tensorflow as tf\ntf.__version__","89119d15":"# To generate GIFs\n!pip install -q imageio\n!pip install -q git+https:\/\/github.com\/tensorflow\/docs","6b14c490":"import glob\nimport imageio\nimport PIL\nfrom tensorflow.keras import layers\n\nfrom IPython import display","11eff928":"%%time\n# data loading\ndf=pd.read_pickle(\"..\/input\/wm811k-wafer-map\/LSWMD.pkl\")\ndf.info()","a470bf46":"df.head()","8b05a3f7":"# change img data to list\nimg_data = df[\"waferMap\"].values\ndf.drop(\"waferMap\", axis=1, inplace=True)\n\n# change data type\ndf[\"dieSize\"] = df[\"dieSize\"].astype(\"uint16\")\ndf[\"waferIndex\"] = df[\"waferIndex\"].astype(\"uint8\")\n\n# dieSize\ndiesize = np.array(df[\"dieSize\"].values)\ndf.drop(\"dieSize\", axis=1, inplace=True)\n\n# WaferIndex\nwaferindex = np.array(df[\"waferIndex\"].values)\ndf.drop(\"waferIndex\", axis=1, inplace=True)\n\n# lotName\nlotname = np.array(df[\"lotName\"].values)\ndf.drop(\"lotName\", axis=1, inplace=True)\n\n# trainTestLabel\nttlabel = np.array(df[\"trianTestLabel\"].values)\ndf.drop(\"trianTestLabel\", axis=1, inplace=True)\n\n# failureType\nfailuretype = np.array(df[\"failureType\"].values)\ndf.drop(\"failureType\", axis=1, inplace=True)","601a29a6":"# trainTestLabel\nttlabel = ttlabel.astype(\"object\")\nttlabel = [ str(obj).replace(\"[[\", \"\").replace(\"]]\", \"\") for obj in ttlabel ]\nttlabel = np.array(ttlabel)\n\n# failureType\nfailuretype = failuretype.astype(\"object\")\nfailuretype = [ str(obj).replace(\"[[\", \"\").replace(\"]]\", \"\") for obj in failuretype ]\nfailuretype = np.array(failuretype)","d587b07d":"del df\ngc.collect()","ab5449f7":"# train and test data\n\n# image data\ntrain_img = img_data[ttlabel==\"'Training'\"]\n#test_img = img_data[ttlabel==\"'Test'\"]\n\n# mode\ntrain_mode = failuretype[ttlabel==\"'Training'\"]\n#test_mode = failuretype[ttlabel==\"'Test'\"]\n\n# diesize\ntrain_die = diesize[ttlabel==\"'Training'\"]\n#test_die = diesize[ttlabel==\"'Test'\"]","e1c07cbd":"# image size distribution\nsample = np.random.choice(train_img, 1000, replace=False)\n\nx = [ img.shape[1] for img in sample ]\ny = [ img.shape[0] for img in sample ]\n\n# image size plot\nplt.figure(figsize=(6,6))\nplt.scatter(x,y)\nplt.xlabel(\"width\")\nplt.ylabel(\"height\")","fa442334":"# checking wafer map images\nmode = np.unique(train_mode)\n\nfig, ax = plt.subplots(len(mode),5, figsize=(20,4*len(mode)))\n\nfor i in range(len(mode)):\n    mode_img = train_img[train_mode==mode[i]]\n    for j in range(5):\n        img = mode_img[j]\n    \n        ax[i,j].imshow(img, cmap=\"gray\")\n        ax[i,j].grid([])\n        ax[i,j].set_title(mode[i])\n        ax[i,j].set_xticks([])\n        ax[i,j].set_yticks([])","7f7a8b3b":"# diesize distribution\nplt.figure(figsize=(10,6))\nsns.distplot(train_die)\nplt.xlabel(\"diesize\")\nplt.ylabel(\"frequency\")","9d209c5e":"# large die image\nfig, ax = plt.subplots(1,5, figsize=(20,4))\nimg_list = train_img[train_die>20000]\nfor i in range(5):\n    ax[i].imshow(img_list[i], cmap=\"gray\")\n    ax[i].set_title(\"size:{}\".format(img_list[i].shape))\n    ax[i].grid([])","2cc73595":"# change to image size (28,28)\ntrain_img = np.array([cv2.resize(img, dsize=(28,28)) for img in train_img])\n#test_img = np.array([cv2.resize(img, dsize=(64,64)) for img in test_img])","af83a1a8":"# change to binary, only failure chip\ndef bin_img(img, lwr_thre=1, upr_thre=2):\n    ret,img = cv2.threshold(img, lwr_thre, upr_thre, cv2.THRESH_BINARY)\n    img = img\/2\n    img = img.astype(np.float32)\n    return img\n\ntrain_img = np.array([bin_img(img) for img in train_img])\n#test_img = np.array([bin_img(img) for img in test_img])","cf1c85c2":"# checking wafer map images\nmode = np.unique(train_mode)\n\nfig, ax = plt.subplots(len(mode),5, figsize=(20,4*len(mode)))\n\nfor i in range(len(mode)):\n    mode_img = train_img[train_mode==mode[i]]\n    for j in range(5):\n        img = mode_img[j]\n    \n        ax[i,j].imshow(img, cmap=\"gray\")\n        ax[i,j].grid([])\n        ax[i,j].set_title(mode[i])\n        ax[i,j].set_xticks([])\n        ax[i,j].set_yticks([])","b0693424":"# memory cleaning\nprint(pd.DataFrame([[val for val in dir()], [sys.getsizeof(eval(val)) for val in dir()]],\n                   index=['name','size']).T.sort_values('size', ascending=False).reset_index(drop=True))","0a5b6baf":"del mode_img, failuretype, ttlabel, lotname\ngc.collect()","d76723a2":"train_img.shape","628141ea":"train_img = train_img[train_mode==\"'Edge-Ring'\"]","db475fb6":"# image dataset\ntrain_img.shape","da284245":"# shape change for tensorflow calculation\ntrain_img = train_img.reshape(train_img.shape[0], 28, 28, 1).astype('float32')","be0d9bd0":"train_img.shape","57adcd6a":"# Difine size\nBUFFER_SIZE = train_img.shape[0]\nBATCH_SIZE = 128","19222f6e":"# Batch and shuffle the data\ntrain_dataset = tf.data.Dataset.from_tensor_slices(train_img).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)","2d99017a":"train_dataset","55902931":"# difine generator\ndef make_generator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,))) # input is length 100 value.\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Reshape((7, 7, 256)))\n    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n\n    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n    assert model.output_shape == (None, 7, 7, 128)\n    \n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    assert model.output_shape == (None, 14, 14, 64)\n    \n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n    assert model.output_shape == (None, 28, 28, 1)\n\n    return model","ae30523f":"# generator model\nmake_generator_model().summary()","34f1f949":"# define model function\ngenerator = make_generator_model()\n\n# create random noise\nnoise = tf.random.normal([1, 100])\ngenerated_image = generator(noise, training=False)\n\n# check the 1st generated image\nplt.imshow(generated_image[0, :, :, 0], cmap='gray')","e08aaddd":"def make_discriminator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n                                     input_shape=[28, 28, 1]))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1))\n\n    return model","b14adb39":"# discriminator_model\nmake_discriminator_model().summary()","929538d0":"# difine discriminator function\ndiscriminator = make_discriminator_model()\n# check the 1st discriminated image\ndecision = discriminator(generated_image)\nprint (decision)","cec2c0a8":"# This method returns a helper function to compute cross entropy loss\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)","376c9a12":"# difine discriminator loss function\ndef discriminator_loss(real_output, fake_output):\n    # Compare the discriminator predictions in the real image with the array of 1\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    # and compare the discriminator predictions in the fake (generated) image with the array of 0\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss","995ce3a5":"# difine generator loss function\ndef generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)","eed89485":"# difine optimizers\n# generator, with Adam\ngenerator_optimizer = tf.keras.optimizers.Adam(1e-4)\n# discriminator, with Adam\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)","75aaaddd":"# difine check point\ncheckpoint_dir = '.\/training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)","380cb8f3":"# difine training params\nEPOCHS = 50\nnoise_dim = 100\nnum_examples_to_generate = 16\n\n# We will reuse this seed overtime (so it's easier)\n# to visualize progress in the animated GIF\nseed = tf.random.normal([num_examples_to_generate, noise_dim])","407173fe":"# check random noise distribution\nfig, ax = plt.subplots(1,3, figsize=(30,6))\nfor i in range(3):\n    sns.distplot(seed[i], ax=ax[i])","8286086d":"# Notice the use of `tf.function`\n# This annotation causes the function to be \"compiled\".\n@tf.function\ndef train_step(images):\n    noise = tf.random.normal([BATCH_SIZE, noise_dim]) # create random noise\n    \n    # with syntax\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape: # tf.GradientTape() is calc function of differential.\n        # gererated result from noise\n        generated_images = generator(noise, training=True)\n        \n        # real output is prediction from real images\n        real_output = discriminator(images, training=True)\n        # fake output is prediction from fake(generated) images\n        fake_output = discriminator(generated_images, training=True)\n        \n        # calc each loss\n        # generated loss\n        gen_loss = generator_loss(fake_output)\n        # discriminated loss\n        disc_loss = discriminator_loss(real_output, fake_output)\n        \n        # calc gradients of generator\n        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n        # calc gradients of discriminator\n        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n        \n        # the gradient is used to update the generator and discriminator.\n        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))","405f8aa7":"def train(dataset, epochs):\n    # each epoch\n    for epoch in range(epochs):\n        start = time.time()\n        \n        # each batch, calc train_step function\n        for image_batch in dataset:\n            train_step(image_batch)\n\n        # Produce images for the GIF as we go\n        display.clear_output(wait=True)\n        generate_and_save_images(generator,\n                             epoch + 1,\n                             seed)\n\n        # Save the model every 15 epochs\n        if (epoch + 1) % 15 == 0:\n            checkpoint.save(file_prefix = checkpoint_prefix)\n\n        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n\n    # Generate after the final epoch\n    display.clear_output(wait=True)\n    generate_and_save_images(generator,\n                           epochs,\n                           seed)","fcff20eb":"def generate_and_save_images(model, epoch, test_input):\n  # Notice `training` is set to False.\n  # This is so all layers run in inference mode (batchnorm).\n    predictions = model(test_input, training=False)\n\n    fig = plt.figure(figsize=(16,16))\n\n    for i in range(predictions.shape[0]):\n        plt.subplot(4, 4, i+1)\n        plt.imshow(predictions[i, :, :, 0], cmap='gray')\n        plt.axis('off')\n\n    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n    plt.show()","8396b644":"# execution training\ntrain(train_dataset, EPOCHS)","7409a82b":"checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))","5bf4b15f":"# Display a single image using the epoch number\ndef display_image(epoch_no):\n    return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))","1ea10c6b":"display_image(EPOCHS)","7dd5ea2d":"# create animation images\nanim_file = 'dcgan.gif'\n\nwith imageio.get_writer(anim_file, mode='I') as writer:\n    filenames = glob.glob('image*.png')\n    filenames = sorted(filenames)\n    for filename in filenames:\n        image = imageio.imread(filename)\n        writer.append_data(image)\n    image = imageio.imread(filename)\n    writer.append_data(image)","1e6fcd28":"import tensorflow_docs.vis.embed as embed\nembed.embed_file(anim_file)","cb8e537a":"# Notebook, GAN","fe2da434":"Data size too large, so change to light processing","c9cf8653":"# Dataloading","785646e6":"# Libraries","b4b2a89a":"### Let's try to execute the image generation of the wafer map by GAN.","0c57f183":"## tensor flow","d6eb9450":"### Reference\nhttps:\/\/www.tensorflow.org\/tutorials\/generative\/dcgan","1efc3f1d":"# EDA","dfc63d7e":"# Modeling","3ee70209":"## Image data size","9f5effac":"Select Edge ring shapes"}}