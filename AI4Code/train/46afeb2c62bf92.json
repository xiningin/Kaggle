{"cell_type":{"bcb23d63":"code","0ff19db6":"code","dbe571e0":"code","8fe47a5d":"code","c976b6df":"code","8f6cac91":"code","fa6de898":"code","bb251512":"code","9959090c":"code","495e7985":"code","24e4a508":"code","3f061ba2":"code","b8682599":"code","56145bca":"code","87573752":"code","10a09609":"code","225794eb":"code","19285662":"markdown","0b537bac":"markdown","8a292308":"markdown","5639bab0":"markdown","148c2ee4":"markdown","9bb6cc95":"markdown","df58736b":"markdown","68ffbc66":"markdown","58dfc73c":"markdown","947d5eff":"markdown","0b64b7c5":"markdown","c709ff94":"markdown","47015ebd":"markdown","8582d1fc":"markdown","56db1c2e":"markdown","4a1e6aa5":"markdown"},"source":{"bcb23d63":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0ff19db6":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense","dbe571e0":"df = pd.read_csv('\/kaggle\/input\/concrete_data.csv')\ndf.head()","8fe47a5d":"df.shape","c976b6df":"df.isnull().sum().sum()","8f6cac91":"features = ['Cement', 'Blast Furnace Slag', 'Fly Ash', 'Water', \n            'Superplasticizer','Coarse Aggregate', 'Fine Aggregate', 'Age']\nX = df[features]\ny = df['Strength']\nn_features = len(features)","fa6de898":"def baseline_model(n_features):\n    \n    model = Sequential()\n    model.add(Dense(10, activation = 'relu', input_shape = (n_features,)))\n    model.add(Dense(1))\n    \n    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n    return model","bb251512":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nmse_list = []\n\nfor i in range(0, 50):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n\n    my_model = baseline_model(n_features)\n    my_model.fit(X_train, y_train, epochs = 50, verbose = 1)\n    preds = my_model.predict(X_test)\n\n    mse = mean_squared_error(y_test, preds)\n    mse_list.append(mse)","9959090c":"#Saving and loading the model\nmy_model.save('BASELINE_MODEL_extended.h5')\n#my_model = keras.models.load_model('BASELINE_MODEL_extended.h5')","495e7985":"from statistics import mean, stdev\n\nprint('Mean of MSE - ',mean(mse_list))\nprint('Standard Deviation of MSE -',stdev(mse_list))","24e4a508":"from sklearn import preprocessing\nmse_list = []\n\nfor i in range(0,50):\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n    \n    #Normalizing the training and testing data with sklearn.StandardScaler\n    scaler = preprocessing.StandardScaler().fit(X_train)\n    scaler.transform(X_test)\n\n    my_model = baseline_model(n_features)\n    my_model.fit(X_train, y_train, epochs = 50, verbose = 1)\n    preds = my_model.predict(X_test)\n\n    mse = mean_squared_error(y_test, preds)\n    mse_list.append(mse)","3f061ba2":"print('Mean of MSE - ',mean(mse_list))\nprint('Standard Deviation of MSE -',stdev(mse_list))","b8682599":"mse_list = []\n\nfor i in range(0,50):\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n    \n    #Normalizing the training and testing data with sklearn.StandardScaler\n    scaler = preprocessing.StandardScaler().fit(X_train)\n    scaler.transform(X_test)\n\n    my_model = baseline_model(n_features)\n    my_model.fit(X_train, y_train, epochs = 100, verbose = 1)\n    preds = my_model.predict(X_test)\n\n    mse = mean_squared_error(y_test, preds)\n    mse_list.append(mse)","56145bca":"print('Mean of MSE - ',mean(mse_list))\nprint('Standard Deviation of MSE -',stdev(mse_list))","87573752":"def modified_baseline_model(n_features):\n    \n    model = Sequential()\n    model.add(Dense(10, activation = 'relu', input_shape = (n_features,)))\n    model.add(Dense(10, activation = 'relu'))\n    model.add(Dense(10, activation = 'relu'))\n    model.add(Dense(1))\n    \n    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n    return model","10a09609":"from sklearn import preprocessing\nmse_list = []\n\nfor i in range(0,50):\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n    \n    #Normalizing the training and testing data with sklearn.StandardScaler\n    scaler = preprocessing.StandardScaler().fit(X_train)\n    scaler.transform(X_test)\n\n    my_model = modified_baseline_model(n_features)\n    my_model.fit(X_train, y_train, epochs = 50, verbose = 1)\n    preds = my_model.predict(X_test)\n\n    mse = mean_squared_error(y_test, preds)\n    mse_list.append(mse)","225794eb":"print('Mean of MSE - ',mean(mse_list))\nprint('Standard Deviation of MSE -',stdev(mse_list))","19285662":"### Setting up Keras Dependencies","0b537bac":"### *THE END*\n***************************************","8a292308":"### PART D: Modified baseline model","5639bab0":"By using a modified model with three hidden layers, the model performed better then the Normalized basline model and \neven the one with increased epochs. There is a significant reduction in average MSE.","148c2ee4":"### Reading the data","9bb6cc95":"### Part B: Normalized Baseline Model","df58736b":"# Analyzing strength of Concrete with Keras\n\n*This project is done as the Course Project of **Introduction to Deep Learning & Neural Networks with Keras** offered by IBM in Coursera*\n","68ffbc66":"As it can be seen that the average MSE has reduced from 376.02 to 287.57 by using Normalized data","58dfc73c":"### Organizing the data","947d5eff":"The data has been read and contains 1030 rows which correspond to 1030 data points.\nThe data also has no missing values.","0b64b7c5":"Increasing the epohs have significantly reduced the MSE as compared to the Normalized Baseline Model","c709ff94":"### Preliminary EDA","47015ebd":"### Setting up the Kaggle Environment","8582d1fc":"### Setting up the baseline model","56db1c2e":"### Part A: Deploy the baseline model","4a1e6aa5":"### PART C: Increased epochs"}}