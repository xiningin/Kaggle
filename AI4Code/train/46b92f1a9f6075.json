{"cell_type":{"915d58a0":"code","0ff02ebb":"code","529d63d0":"code","b2c905e0":"code","cbe3a7fd":"code","40bd05d0":"code","e79adba8":"code","c9d72931":"code","5b49ae78":"code","44068bb1":"code","55c816f3":"code","fda658f6":"code","3dc76791":"code","2885653c":"code","563bd654":"code","b29e9da9":"code","0fcb5dfc":"code","43175ee2":"code","28b01958":"code","12ede776":"code","c60f29b2":"code","4cb652bb":"code","411c6edb":"code","70374fc5":"code","fb8a0e73":"code","e13f8d00":"code","67e0238e":"code","2b9b6871":"markdown","46588e96":"markdown","f17f10c8":"markdown","b61bb32c":"markdown","8b82a326":"markdown","f56f7a64":"markdown","5de46008":"markdown","7f7775ae":"markdown"},"source":{"915d58a0":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.offsetbox import OffsetImage, AnnotationBbox\nplt.rcParams[\"figure.figsize\"] = (6, 6)\nplt.rcParams[\"figure.dpi\"] = 200\nplt.rcParams[\"font.size\"] = 14\nplt.rcParams['font.family'] = ['sans-serif']\nplt.rcParams['font.sans-serif'] = ['DejaVu Sans']\nplt.style.use('ggplot')\nsns.set_style(\"whitegrid\", {'axes.grid': False})\nplt.rcParams['image.cmap'] = 'viridis'","0ff02ebb":"from pathlib import Path\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom skimage.io import imread\nfrom skimage.util import montage\nfrom tqdm import tqdm\ntqdm.pandas() # hack progressbars into pandas\nmontage_rgb = lambda x, **kwargs: np.stack([montage(x[:, :, :, i], **kwargs) for i in range(x.shape[3])], -1)","529d63d0":"satellite_dir = Path('..\/input\/satellite-images-of-hurricane-damage\/')\nimage_df = pd.DataFrame({'path': list(satellite_dir.glob('**\/*.jp*g'))})\nimage_df.sample(3)","b2c905e0":"image_df['damage'] = image_df['path'].map(lambda x: x.parent.stem)\nimage_df['data_split'] = image_df['path'].map(lambda x: x.parent.parent.stem)\nimage_df['location'] = image_df['path'].map(lambda x: x.stem)\nimage_df['lat'] = image_df['location'].map(lambda x: float(x.split('_')[0]))\nimage_df['lon'] = image_df['location'].map(lambda x: float(x.split('_')[-1]))\nimage_df.sample(3)","cbe3a7fd":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\nfor c_group, c_rows in image_df.groupby(['damage']):\n    ax1.plot(c_rows['lat'], c_rows['lon'], '.', label=c_group, alpha=0.5)\nax1.legend()\nax1.set_title('Data by Damage Type')\nfor c_group, c_rows in image_df.groupby(['data_split']):\n    ax2.plot(c_rows['lat'], c_rows['lon'], '.', label=c_group, alpha=0.5)\nax2.legend()\nax2.set_title('Data by Group')","40bd05d0":"fig, m_axs = plt.subplots(1, 2, figsize=(20, 10))\nfor c_ax, (c_cat, c_rows) in zip(m_axs, image_df.groupby(['damage'])):\n    img_stack = np.stack(c_rows.sample(121)['path'].map(imread), 0)\n    c_ax.imshow(montage_rgb(img_stack))\n    c_ax.set_title(c_cat)\n    c_ax.axis('off')","e79adba8":"fig, m_axs = plt.subplots(2, 2, figsize=(20, 20))\nfor c_ax, (c_cat, c_rows) in zip(m_axs.flatten(), image_df.groupby(['data_split'])):\n    img_stack = np.stack(c_rows.sample(121)['path'].map(imread), 0)\n    c_ax.imshow(montage_rgb(img_stack))\n    c_ax.set_title(c_cat)\n    c_ax.axis('off')","c9d72931":"test_image = Image.open(image_df['path'].iloc[1010]) # normal image\n# convert to 8bit color (animated GIF) and then back\nweb_image = test_image.convert('P', palette='WEB', dither=None)\nfew_color_image = web_image.convert('RGB')\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\nax1.imshow(test_image)\nax2.imshow(few_color_image)","5b49ae78":"print('Unique colors before', len(set([tuple(rgb) for rgb in np.array(test_image).reshape((-1, 3))])))\nprint('Unique colors after', len(set([tuple(rgb) for rgb in np.array(few_color_image).reshape((-1, 3))])))","44068bb1":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6))\nfor c_channel, c_name in enumerate(['red', 'green', 'blue']):\n    ax1.hist(np.array(test_image)[:, :, c_channel].ravel(), \n             color=c_name[0], \n             label=c_name, \n             bins=np.arange(256), \n             alpha=0.5)\n    ax2.hist(np.array(few_color_image)[:, :, c_channel].ravel(), \n             color=c_name[0], \n             label=c_name, \n             bins=np.arange(256), \n             alpha=0.5)","55c816f3":"idx_to_color = np.array(web_image.getpalette()).reshape((-1, 3))\/255.0","fda658f6":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6))\nax1.imshow(few_color_image)\ncounts, bins = np.histogram(web_image, bins=np.arange(256))\nfor i in range(counts.shape[0]):\n    ax2.bar(bins[i], counts[i], color=idx_to_color[i])\nax2.set_yscale('log')\nax2.set_xlabel('Color Id')\nax2.set_ylabel('Pixel Count')","3dc76791":"def color_count_feature(in_path):\n    raw_image = Image.open(in_path) \n    web_image = raw_image.convert('P', palette='WEB', dither=None)\n    counts, bins = np.histogram(np.array(web_image).ravel(), bins=np.arange(256))\n    return counts*1.0\/np.prod(web_image.size) # normalize output","2885653c":"%%time\nimage_df['color_features'] = image_df['path'].progress_map(color_count_feature)","563bd654":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 10))\ncombined_features = np.stack(image_df['color_features'].values, 0)\nax1.imshow(combined_features)\nax1.set_title('Raw Color Counts')\nax1.set_xlabel('Color')\nax1.set_ylabel('Frequency')\nax1.set_aspect(0.01)\ncolor_wise_average = np.tile(np.mean(combined_features, 0, keepdims=True), (combined_features.shape[0], 1)).clip(1\/(128*128), 1)\nax2.imshow(combined_features\/color_wise_average, vmin=0.05, vmax=20)\nax2.set_title('Normalized Color Counts')\nax2.set_xlabel('Color')\nax2.set_ylabel('Frequency')\nax2.set_aspect(0.01)","b29e9da9":"from sklearn.decomposition import PCA\nxy_pca = PCA(n_components=2)\nxy_coords = xy_pca.fit_transform(combined_features)\nimage_df['x'] = xy_coords[:, 0]\nimage_df['y'] = xy_coords[:, 1]","0fcb5dfc":"fig, ax1 = plt.subplots(1,1, figsize=(15, 15))\nfor c_group, c_row in image_df.groupby('damage'):\n    ax1.plot(c_row['x'], c_row['y'], '*', label=c_group)\nax1.legend()\n","43175ee2":"def show_xy_images(in_df, image_zoom=1):\n    fig, ax1 = plt.subplots(1,1, figsize=(10, 10))\n    artists = []\n    for _, c_row in in_df.iterrows():\n        c_img = Image.open(c_row['path']).resize((64, 64))\n        img = OffsetImage(c_img, zoom=image_zoom)\n        ab = AnnotationBbox(img, (c_row['x'], c_row['y']), xycoords='data', frameon=False)\n        artists.append(ax1.add_artist(ab))\n    ax1.update_datalim(in_df[['x', 'y']])\n    ax1.autoscale()\n    ax1.axis('off')\nshow_xy_images(image_df.sample(200))","28b01958":"image_df['path'] = image_df['path'].map(str) # saving pathlib objects causes problems\nimage_df.to_json('color_features.json')","12ede776":"image_df.sample(3)","c60f29b2":"from keras.applications import resnet50\nfrom keras import models, layers\npretrained_model = resnet50.ResNet50(include_top=False, weights='imagenet')\nfeature_model = models.Sequential(name='just_features')\nprep_layer = layers.Conv2D(3, \n                           kernel_size=(1, 1), \n                           weights=[np.expand_dims(np.expand_dims(np.eye(3), 0), 0), \n                                    np.array([-103.9, -116.78, -123.68])],\n                           input_shape=(None, None, 3),\n                          name='PreprocessingLayer')\nfeature_model.add(prep_layer)\nfeature_model.add(pretrained_model)\nfeature_model.add(layers.GlobalAveragePooling2D())\nfeature_model.save('feature_model.h5')\nfeature_model.summary()","4cb652bb":"%%time\nimage_df['resnet_features'] = image_df['path'].progress_map(lambda x: feature_model.predict(np.expand_dims(imread(x), 0))[0])","411c6edb":"image_df.to_json('resnet_features.json')","70374fc5":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 10))\ncombined_features = np.stack(image_df['resnet_features'].values, 0)\nax1.imshow(combined_features)\nax1.set_title('Raw Feature Values')\nax1.set_xlabel('Color')\nax1.set_ylabel('Frequency')\nax1.set_aspect(0.01)\ncolor_wise_average = np.tile(np.mean(combined_features, 0, keepdims=True), (combined_features.shape[0], 1))\ncolor_wise_std = np.tile(np.std(combined_features, 0, keepdims=True), (combined_features.shape[0], 1)).clip(0.01, 10)\nax2.imshow((combined_features-color_wise_average)\/color_wise_std, vmin=-2, vmax=2, cmap='RdBu')\nax2.set_title('Normalized Feature Values')\nax2.set_xlabel('Color')\nax2.set_ylabel('Frequency')\nax2.set_aspect(0.01)","fb8a0e73":"from sklearn.decomposition import PCA\nxy_pca = PCA(n_components=2)\nxy_coords = xy_pca.fit_transform(combined_features)\nimage_df['x'] = xy_coords[:, 0]\nimage_df['y'] = xy_coords[:, 1]","e13f8d00":"fig, ax1 = plt.subplots(1,1, figsize=(15, 15))\nfor c_group, c_row in image_df.groupby('damage'):\n    ax1.plot(c_row['x'], c_row['y'], '*', label=c_group)\nax1.legend()","67e0238e":"show_xy_images(image_df.groupby('damage').apply(lambda x: x.sample(100)))","2b9b6871":"# Simple Features","46588e96":"### Reduce the number of colors\nCurrently we have $ \\underbrace{2^8}_{\\textrm{8-bit}}$ and $\\underbrace{3 \\textrm{channel}}_{\\textrm{Red, Green, Blue}}$. This means we have $2^{8^3} \\rightarrow 16,581,375$ different colors. \nWe can convert the image to 8-bit format to reduce the number of colors by a factor of 65536","f17f10c8":"# Deep-learned Features\nHere we take features from a pre-trained deep learning model to experiment with instead of just color features. These features give us information about the shapes, objects, and more complicated features than just color.","b61bb32c":"## Damage vs No Damage","8b82a326":"## Visualize ResNet Features","f56f7a64":"## Different Splits","5de46008":"# Stratification of Data\n","7f7775ae":"# Image Previews"}}