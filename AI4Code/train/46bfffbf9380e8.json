{"cell_type":{"915dfd41":"code","94179979":"code","6b7a57e9":"code","1dce924c":"code","e9f349f8":"code","09d136e5":"code","8e772fca":"code","d778fec7":"code","7fc1f4ce":"code","187cbf60":"code","a9d83552":"code","90373c67":"code","82f2fc6b":"code","ec2012a3":"code","63ca6b8b":"code","86064363":"code","9c47fb95":"code","056c263f":"code","ee017ba0":"code","0d56fe26":"code","4211b32c":"code","0ce2af12":"code","38f8c0e0":"markdown","1cc7cba6":"markdown","9683453e":"markdown","6db002d9":"markdown"},"source":{"915dfd41":"import numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","94179979":"link = '\/kaggle\/input\/covid19-in-world-countrieslatest-data\/worldwide covid data.csv'\ndf = pd.read_csv(link)\n\ndf","6b7a57e9":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nplt.figure(figsize=(20, 20))\nsns.heatmap(df.isnull(), cbar=False)","1dce924c":"def NaN_info(df):\n    global null_view\n    try:\n        null_view = df[[col for col in df.columns if df[col].isna().sum() > 0]].isna().sum().sort_values(ascending = True)\n        null_view = pd.DataFrame(null_view, columns=['NANs'])\n        null_view['PERCENT'] = null_view.NANs.apply(lambda x: round((x\/len(df))*100, 2))\n        null_view['TYPE'] = df.dtypes\n    except:\n        return null_view\n    return null_view\n\nNaN_info(df)","e9f349f8":"def nan_predict(df,\n                skip_features_from_prediction_where_percent_missing_data_more_than = 100,\n                include_features_as_predictors_where_perc_missing_data_less_than = 50,\n                apply_fast_predictor_where_missing_data_less_than_percent = 100,\n                use_n_rows_for_train_not_more_than = 1000000000,    #  If your dataframe is large\n                randomizedSearchCV_iter_plus_perc_missing_data = 10,\n                n_estimators_parameter_for_LightGBM = 2000,\n                target_feature = None,   # For prediction at the end\n                ): \n    \n    import random\n    import pandas as pd\n    import numpy as np\n\n    # Disabling warnings\n    import sys\n    import warnings\n    if not sys.warnoptions:\n        warnings.simplefilter(\"ignore\")\n\n    from lightgbm import LGBMClassifier\n    from lightgbm import LGBMRegressor\n    \n    from sklearn.model_selection import RandomizedSearchCV\n    from sklearn.model_selection import ShuffleSplit\n    from sklearn.model_selection import train_test_split\n    from sklearn.metrics import mean_absolute_error\n    from sklearn.metrics import accuracy_score\n    from sklearn.metrics import f1_score\n    from sklearn.preprocessing import LabelEncoder\n    \n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    %matplotlib inline\n    \n    \n\n    global counter_all_predicted_values\n    counter_all_predicted_values = 0\n    \n    global numeric_features\n    numeric_features = []\n    \n    global best_params\n    \n    \n    PARAMS  =  {'num_leaves': [12, 50, 120, 200, 300, 400, 500],   #np.arange(200, 600, step=100),\n                'max_depth': [4, 8, 12, 16],\n                'learning_rate': [0.001, 0.01, 0.1],\n                'n_estimators': [n_estimators_parameter_for_LightGBM],\n                'subsample': [0.1, 0.3, 0.5],\n                'feature_fraction': [0.1, 0.3, 0.5],\n                'bagging_fraction': [0.1, 0.3, 0.5],\n                'bagging_seed': np.arange(1, 3, step=1),\n                'lambda_l1': [0.2],\n                'lambda_l2': [0.1],\n                'min_child_samples': np.arange(2, 6, step=2),\n                'min_split_gain': [0.0001, 0.001]\n               }\n    \n    \n    CV = ShuffleSplit(n_splits=2, test_size=0.25, random_state=0)\n    \n    \n    \n\n    def NaN_info(df):\n        global null_view\n        try:\n            null_view = df[[col for col in df.columns if df[col].isna().sum() > 0]].isna().sum().sort_values(ascending = True)\n            null_view = pd.DataFrame(null_view, columns=['NANs'])\n            null_view['PERCENT'] = null_view.NANs.apply(lambda x: round((x\/len(df))*100, 2))\n            null_view['TYPE'] = df.dtypes\n        except:\n            return null_view\n        return null_view\n    \n    \n    def numeric_features(df):\n        num_features = [feature for feature in df.columns if df[feature].dtype in ['int64', 'float64']]\n        return num_features\n    \n    \n    def integer_features(df):\n        global int_features\n        int_features = [feature for feature in df.columns if df[feature].dtype in ['int64']]\n        return int_features\n\n\n    def encoding(work_predictors, df):\n        feature_power = 0.5          # Skew handling\n        for j in work_predictors:\n            el_type = df[j].dtype\n            if el_type == 'object':\n                df[j].replace(np.nan, 'NoNoNo', inplace=True)\n                labelencoder = LabelEncoder()\n                df.loc[:, j] = labelencoder.fit_transform(df.loc[:, j])\n            else:\n                df[j] = df[j]**feature_power\n        return df, work_predictors\n\n\n    def hyperparms_tuning(CV, X_train, X_test, y_train, y_test, n_iter_for_RandomizedSearchCV, PARAMS, alg, scoring):\n        global best_params\n        global pred_test_lgb\n\n        lgbm = alg(random_state = 0)\n        lgbm_randomized = RandomizedSearchCV(estimator=lgbm, \n                                            param_distributions=PARAMS, \n                                            n_iter=n_iter_for_RandomizedSearchCV, \n                                            scoring=scoring, \n                                            cv=CV, \n                                            verbose=0,\n                                            n_jobs = -1)\n\n        lgbm_randomized.fit(X_train, y_train)\n        \n        best_params = lgbm_randomized.best_params_\n        pred_test_lgb = lgbm_randomized.predict(X_test)\n        return best_params, pred_test_lgb\n\n    \n    def predict_regressor(best_params, X, y, miss_df):\n        print('Best parameters:')\n        print(best_params)\n        print('')\n        global pred_miss\n        lgbm = LGBMRegressor(**best_params, n_jobs=-1, random_state=0)\n        lgbm = lgbm.fit(X, y)\n        pred_miss = list(lgbm.predict(miss_df))\n        print('-------------------------------')\n        print(f\"The first 100 predicted missing values: \\n{pred_miss[:100]}\")\n        return pred_miss\n\n\n    def predict_classifier(best_params, X, y, miss_df):\n        print('Best parameters:')\n        print(best_params)\n        print('')\n        global pred_miss\n        lgbm = LGBMClassifier(**best_params, n_jobs=-1, random_state=0)\n        lgbm = lgbm.fit(X, y)\n        pred_miss = list(lgbm.predict(miss_df))\n        print('-------------------------------')\n        print(f\"The first 100 predicted missing values: \\n{pred_miss[:100]}\")\n        return pred_miss\n    \n    \n    def imput_missing_value_to_main_df(df, miss_indeces, pred_miss, el):\n        df.loc[miss_indeces, el] = pred_miss[:]\n        return df\n    \n    \n    \n    \n    # Go)\n\n    plt.figure(figsize=(20, 5))\n    sns.heatmap(df.isnull(), cbar=False)\n    \n    \n    print(NaN_info(df))\n    print('\\n\\n\\n')\n    \n    all_features = list(df.columns)\n    df_indeces = list(df.index)\n    df.reset_index(drop=True, inplace=True)\n    \n    integer_features(df)\n\n    delete_miss_features = list(\n        (null_view.loc[null_view['PERCENT'] > skip_features_from_prediction_where_percent_missing_data_more_than]).index)\n    print(f'Exclude from the prediction, because missing data more than \\\n    {skip_features_from_prediction_where_percent_missing_data_more_than}% :\\n{delete_miss_features}')\n    print('')\n    all_miss_features = list(null_view.index)\n\n    for delete_feature in delete_miss_features:\n        all_miss_features.remove(delete_feature)\n        \n    \n    if target_feature in all_miss_features:  # moving target_feature to end of the prediction\n        all_miss_features.append(all_miss_features.pop(all_miss_features.index(target_feature)))\n        \n    \n    for el in all_miss_features:\n        print('\\n')\n        \n        # select features as predictors\n        NaN_info(df)\n        lot_of_miss_features = list(\n            (null_view.loc[null_view['PERCENT'] > include_features_as_predictors_where_perc_missing_data_less_than]).index)\n        now_predictors = list(set(all_features)-set(lot_of_miss_features))\n        work_predictors = list(set(now_predictors) - set([el]))\n\n        \n        # missing data (data for prediction)\n        miss_indeces = list((df[pd.isnull(df[el])]).index)\n        miss_df = df.iloc[miss_indeces][:]\n        miss_df = miss_df[work_predictors]\n        encoding(work_predictors, df=miss_df)\n\n        \n        # data without NaN rows (X data for train, evaluation of model)\n        work_indeces = list(set(df_indeces) - set(miss_indeces))\n        if len(work_indeces) > use_n_rows_for_train_not_more_than:\n            randomlist = random.sample(range(0, len(work_indeces)), use_n_rows_for_train_not_more_than)\n            work_indeces = [work_indeces[i] for i in randomlist]\n        \n        work_df = df.iloc[work_indeces][:]\n        encoding(work_predictors, df=work_df)\n        X = work_df[work_predictors]\n        y = work_df[el]\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n\n        \n        # Info\n        feature_type = df[el].dtypes\n        percent_missing_data = null_view['PERCENT'][el]\n        print(f'Feature: {el},   type: {feature_type},   missing values: {percent_missing_data}%\\n')    \n        print(f'Shape for train dataframe: {(X.shape)}')\n        print(f'Unused features as predictors, because missing data more than {include_features_as_predictors_where_perc_missing_data_less_than}% :')\n        print(lot_of_miss_features)\n        print('')\n        \n        \n        # PREDICTIONS\n        if percent_missing_data < apply_fast_predictor_where_missing_data_less_than_percent:\n            \n            # FAST Predictions without tuning hyperparameters\n            \n            print('FAST prediction without tuning hyperparameters\\n')\n            best_params = {}\n            if feature_type == 'object' or feature_type == 'bool':\n                print('FAST CLASSIFIER:')\n                labelencoder = LabelEncoder()\n                y_train = labelencoder.fit_transform(y_train)\n                y_test = labelencoder.fit_transform(y_test)\n                lgbm = LGBMClassifier(n_jobs=-1, random_state=0)\n                lgbm = lgbm.fit(X_train, y_train)\n\n                pred_test_lgb_FAST = lgbm.predict(X_test)\n                accuracy = accuracy_score(y_test, pred_test_lgb_FAST)\n                print('Evaluations:')\n                print(f'first 10 y_test: {y_test[:10]}')\n                print(f'first 10 y_pred: {pred_test_lgb_FAST[:10]}\\n')\n                f1 = f1_score(y_test, pred_test_lgb_FAST, average='weighted')\n                print(f'accuracy_score:      {accuracy}')\n                print(f'f1_score (weighted): {f1}')\n                \n                predict_classifier(best_params, X, y, miss_df)\n                counter_all_predicted_values += len(miss_indeces)\n                imput_missing_value_to_main_df(df, miss_indeces, pred_miss, el)\n\n            elif feature_type == 'float64' or feature_type == 'int64':\n                print('FAST REGRESSOR:')\n                \n                lgbm = LGBMRegressor(n_jobs=-1, random_state=0)\n                lgbm = lgbm.fit(X_train, np.log1p(y_train))\n\n                pred_test_lgb_FAST = lgbm.predict(X_test)\n                pred_test_lgb_FAST = np.expm1(pred_test_lgb_FAST)\n                MAE = mean_absolute_error(y_test,pred_test_lgb_FAST)\n                y_te = list(round(y_test[:10], 1))\n                y_pred = list(np.round(pred_test_lgb_FAST[:10], 1))\n                print('Evaluations:')\n                print(f'first 10 y_test: {y_te}')\n                print(f'first 10 y_pred: {y_pred}\\n')\n                print(f'mean_absolute_error: {MAE}')\n                print(f'mean for {el}: {df[el].mean()}')\n                \n                predict_regressor(best_params, X, y, miss_df)\n                counter_all_predicted_values += len(miss_indeces)\n                imput_missing_value_to_main_df(df, miss_indeces, pred_miss, el)\n\n            else:\n                print(f\"unprocessed feature: {el} - {feature_type} type\")\n                \n                  \n        else:\n            \n            # ADVANCED Predictions with tuning hyperparameters\n            \n            n_iter_for_RandomizedSearchCV = int(randomizedSearchCV_iter_plus_perc_missing_data + percent_missing_data * 1)\n            print(f'Iteration for RandomizedSearchCV: {n_iter_for_RandomizedSearchCV}\\n')\n            \n            if feature_type == 'object' or feature_type == 'bool':\n                print('ADVANCED CLASSIFIER:')\n                labelencoder = LabelEncoder()\n                y_train = labelencoder.fit_transform(y_train)\n                y_test = labelencoder.fit_transform(y_test)\n                hyperparms_tuning(CV, X_train, X_test, y_train, y_test, n_iter_for_RandomizedSearchCV, PARAMS, alg=LGBMClassifier, scoring='f1_weighted')\n                accuracy = accuracy_score(y_test, pred_test_lgb)\n                print('Evaluations:')\n                print(f'first 10 y_test: {y_test[:10]}')\n                print(f'first 10 y_pred: {pred_test_lgb[:10]}\\n')\n                f1 = f1_score(y_test, pred_test_lgb, average='weighted')\n                print(f'accuracy_score:      {accuracy}')\n                print(f'f1_score (weighted): {f1}')\n                \n                predict_classifier(best_params, X, y, miss_df)\n                counter_all_predicted_values += len(miss_indeces)\n                imput_missing_value_to_main_df(df, miss_indeces, pred_miss, el)\n\n            elif feature_type == 'float64' or feature_type == 'int64':\n                print('ADVANCED REGRESSOR:')\n                hyperparms_tuning(CV, X_train, X_test, y_train, y_test, n_iter_for_RandomizedSearchCV, PARAMS, alg=LGBMRegressor, scoring='neg_mean_squared_error')\n                MAE = mean_absolute_error(y_test,pred_test_lgb)\n                y_te = list(round(y_test[:10], 1))\n                y_pred = list(np.round(pred_test_lgb[:10], 1))\n                print('Evaluations:')\n                print(f'first 10 y_test: {y_te}')\n                print(f'first 10 y_pred: {y_pred}\\n')\n                print(f'mean_absolute_error: {MAE}')\n                print(f'mean for {el}: {df[el].mean()}')\n                \n                predict_regressor(best_params, X, y, miss_df)\n                counter_all_predicted_values += len(miss_indeces)\n                imput_missing_value_to_main_df(df, miss_indeces, pred_miss, el)\n\n            else:\n                print(f\"unprocessed feature: {el} - {feature_type} type\")\n        \n        del now_predictors\n        del work_predictors\n        del miss_indeces\n        del miss_df        \n        del work_df\n        del X\n        del y\n        del X_train\n        del X_test\n        del y_train\n        del y_test\n        del pred_test_lgb_FAST\n\n        \n        \n    plt.figure(figsize=(20, 5))\n    sns.heatmap(df.isnull(), cbar=False)\n\n\n\n        \n    for feature in int_features:\n        df[[feature]] = df[[feature]].astype('int64')\n        \n    df.index = df_indeces\n\n    print('\\n\\n\\n')\n    print(f'These features have not been processed, because missing data more than {skip_features_from_prediction_where_percent_missing_data_more_than}%')\n    print(NaN_info(df))\n    print('\\n\\n\\n')\n    print(f'{counter_all_predicted_values} values have been predicted and replaced')\n    print('\\n')\n    \n    del counter_all_predicted_values\n    del numeric_features\n\n    return df","09d136e5":"nan_predict(df)","8e772fca":"df = df.sort_values(by='Deaths\/1M population', ascending=False)\ndf = df.reset_index(drop=True)\ndf[0:3]","d778fec7":"# df['idx_of_TotalTests\/TotalCases'] = df['Total Tests']\/df['Total Cases']\n# df","7fc1f4ce":"target = ['Deaths\/1M population']\npredictors = list(set(list(df.columns))-set(target))\npredictors","187cbf60":"research = predictors[:]\nresearch.remove('Country')\nprint(research)","a9d83552":"from sklearn import linear_model\n\nfor el in research:\n    plt.figure(figsize=(10, 8))\n    sl_regr = linear_model.LinearRegression()\n\n    train_x = np.asanyarray(df[[el]])\n    train_y = np.asanyarray(df[target])\n    sl_regr.fit(train_x, train_y)\n    \n    plt.scatter(df[[el]], df[target])\n    plt.plot(train_x, sl_regr.coef_[0]*train_x + sl_regr.intercept_, '-r')\n    \n    plt.xlabel(el)\n    plt.ylabel(target)\n    plt.show()","90373c67":"import plotly.graph_objs as go\ndef plots(df, baseline, feature1, feature2):\n    trace1 = go.Scatter(\n                        x=df[baseline], \n                        y=df[feature1], \n                        name=feature1, \n                        marker=dict(color = '#FFB3F7',\n                                 line=dict(color='#000000',width=1)))\n    trace2 = go.Scatter(\n                        x=df[baseline], \n                        y=df[feature2], \n                        name=feature2, \n                        marker=dict(color = '#47E0FF',\n                                 line=dict(color='#000000',width=1)))\n    layout = go.Layout(hovermode='closest', \n                       title = f'Countries' ,\n                       xaxis = dict(title = 'Country'), \n                       yaxis = dict(title = 'Deaths\/1M population'), \n                       template= \"plotly_dark\")\n    fig = go.Figure(data = [trace1, trace2], layout=layout)\n    return fig.show()","82f2fc6b":"df1 = df.copy()\n\ndef normalization(df, columns):\n    for col in columns:\n        min_x = df[col].min()\n        max_x = df[col].max()\n        df[col] = (df[col] - min_x) \/ (max_x - min_x)\n    return df\n\n\nresearch = list(df.columns)\nresearch.remove('Country')\nnormalization(df1, research)","ec2012a3":"plots(df1, 'Country', 'Deaths\/1M population', 'Total Cases\/1M population')","63ca6b8b":"plots(df1, 'Country', 'Deaths\/1M population', 'Tests\/1M population')","86064363":"plots(df1, 'Country', 'Deaths\/1M population', 'Population')","9c47fb95":"from sklearn.preprocessing import LabelEncoder\n\n\ndef encoding(df):\n    for j in df.columns:\n        el_type = df[j].dtype\n        if el_type == 'object':\n            df[j].replace(np.nan, 'Without_data', inplace=True)\n            labelencoder = LabelEncoder()\n            df.loc[:, j] = labelencoder.fit_transform(df.loc[:, j])\n        elif el_type == 'bool':\n            df.loc[:, j] = df[j].replace({False: 0, True: 1})\n    return df\n\nencoding(df)","056c263f":"df = df.drop(columns=['Total Deaths'])\ndf","ee017ba0":"# train_test_split_ordered works correctly with test_size = 0.1, 0.2, 0.25, 0.33, 0.5 \n\ndef train_test_split_ordered(df, target_feature, test_size=0.33, verbose=0, research_iter=0):\n    \n    import matplotlib.pyplot as plt\n    from lightgbm import LGBMRegressor\n    from lightgbm import LGBMClassifier \n    from sklearn.inspection import permutation_importance\n    from sklearn.model_selection import train_test_split\n    from sklearn.metrics import mean_absolute_error\n    from sklearn.metrics import f1_score\n\n    \n    global df_work\n    \n    \n    CLASSIFIER_FOR_UNIQUE_VALUES_LESS_THAN = 50\n    \n\n    df_work = pd.DataFrame()\n    important_functions = []\n    predictors = []\n    ordered_columns = []\n    \n    \n    def get_predictors(df, target_feature):\n        predictors = list(df.columns)\n        predictors.remove(target_feature)\n        return predictors\n    \n    \n    def get_X(df, predictors):\n        X = df[predictors]\n        return X\n    \n    \n    def get_y(df, target_feature):\n        y = df[[target_feature]]\n        return y\n    \n    \n    def regression_score(train_X, test_X, train_y, test_y):\n        model = LGBMRegressor(random_state=0).fit(train_X, train_y)\n        predict = model.predict(test_X)\n        return mean_absolute_error(predict, test_y)\n    \n    \n    def classification_accuracy(train_X, test_X, train_y, test_y):\n        model = LGBMClassifier(random_state=0).fit(train_X, train_y.values.ravel())\n        predict = model.predict(test_X)\n        return f1_score(predict, test_y.values.ravel(), average='weighted')\n    \n    \n    def get_research(X, y, target_feature, test_size, research_iter):\n        RESULTS = pd.DataFrame()\n        print('\\n-----------------------------------')\n        if len(y.value_counts()) > CLASSIFIER_FOR_UNIQUE_VALUES_LESS_THAN:\n            print('Regression research by sklearn.model_selection.train_test_split:\\n')\n            for random_state in range(0,research_iter):\n                train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=test_size, random_state=random_state)\n                RESULTS.loc[random_state, 'score'] = regression_score(train_X, test_X, train_y, test_y)\n            print(f'Regression MAE with random_state from 0 to {research_iter - 1}:')\n        else:\n            print('Classification research by sklearn.model_selection.train_test_split:\\n')\n            print(f'Target function has {len(y.value_counts())} unique values.')\n            for random_state in range(0,research_iter):\n                train_X, test_X, train_y, test_y = train_test_split(X, y, stratify=y, test_size=test_size, random_state=random_state)\n                RESULTS.loc[random_state, 'score'] = classification_accuracy(train_X, test_X, train_y, test_y)\n            print(f'classification F1_SCORE(average=\"weighted\") with random_state from 0 to {research_iter - 1}:')\n\n        print(f'max:  {RESULTS.score.max()}')\n        print(f'mean: {RESULTS.score.mean()}')\n        print(f'min:  {RESULTS.score.min()}\\n')\n        del RESULTS\n        return 0\n    \n    \n    def keep_primary_index(df):\n        df[['__primary_idx']] = list(df.index)\n        return df\n    \n    \n    def order_and_sort_table(df, important_functions):\n        df = df[important_functions]\n        df = df.sort_values(by=important_functions, ascending=True)\n        df = df.reset_index(drop=True)\n        if verbose:\n            print('\\n-----------------------------------')\n            print(f'The Table has been sorted by columns:\\n{important_functions}')\n        return df\n\n    \n    def get_important_functions(X, y):\n        if verbose:\n            print('\\n-----------------------------------')\n            print('Get functions ordered by importance\\n')\n        train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.33, random_state=0)\n\n        if len(y.value_counts()) > CLASSIFIER_FOR_UNIQUE_VALUES_LESS_THAN:\n            alg = LGBMRegressor(n_jobs=-1, random_state=0)\n        else:\n            alg = LGBMClassifier(n_jobs=-1, random_state=0)\n            \n        feature_names = [X.columns]\n        model = alg.fit(train_X, train_y.values.ravel())        \n        result = permutation_importance(model, test_X, test_y.values.ravel(), n_repeats=10)\n        importances = pd.Series(result.importances_mean, index=feature_names)\n        importances = importances.sort_values(ascending=False)\n        if verbose:\n            print(importances)\n            fig, ax = plt.subplots()\n            \n            importances.plot.bar(yerr=result.importances_std, ax=ax)\n            ax.set_title(\"Feature importances using permutation on full model\")\n            ax.set_ylabel(\"Mean accuracy decrease\")\n            fig.tight_layout()            \n            plt.show()\n            \n        for el in importances.index:\n            important_functions.append(el[0])\n        return important_functions\n    \n    \n    def order_columns(important_functions, target_feature):\n        important_functions.insert(0, target_feature)\n        if verbose:\n            print('\\n-----------------------------------')\n            print(f'The columns has been ordered as follows:\\n {important_functions}')\n        return important_functions\n\n    \n    # split works correctly with test_size = 0.1, 0.2, 0.25, 0.33, 0.5 \n    def train_test_split_ordered(X, y, test_size=0.33):\n        train_indexes = []\n        test_indexes = []\n        indexes = list(X.index)\n\n        for el in indexes:\n            if el % int(1\/test_size):\n                train_indexes.append(el)\n            else:\n                test_indexes.append(el)\n\n        train_X = X.iloc[train_indexes]\n        test_X = X.iloc[test_indexes]\n        train_y = y.iloc[train_indexes]\n        test_y = y.iloc[test_indexes]\n        print('\\n-----------------------------------')\n        print('The split has been made.')\n        return train_X, test_X, train_y, test_y\n    \n    \n\n    \n#     df = keep_primary_index(df)\n    predictors = get_predictors(df, target_feature)\n    if research_iter:\n        get_research(get_X(df, predictors), get_y(df, target_feature), target_feature, test_size, research_iter)\n    \n    df_work = order_and_sort_table(df, [target_feature]+predictors)\n    \n    predictors = get_predictors(df_work, target_feature)\n    important_functions = get_important_functions(get_X(df_work, predictors), get_y(df_work, target_feature))\n    \n    ordered_columns = order_columns(important_functions, target_feature)\n    df_work = order_and_sort_table(df_work, ordered_columns)\n    predictors = get_predictors(df_work, target_feature)\n    \n    if research_iter:\n        get_research(get_X(df_work, predictors), get_y(df_work, target_feature), target_feature, test_size, research_iter)\n\n    train_X, test_X, train_y, test_y = \\\n    train_test_split_ordered(get_X(df_work, predictors), get_y(df_work, target_feature), test_size=test_size)\n\n    print('\\n-----------------------------------')\n    if  len(train_y.value_counts()) > CLASSIFIER_FOR_UNIQUE_VALUES_LESS_THAN:\n        print(f'The final result MAE of the custom split:\\n{regression_score(train_X, test_X, train_y, test_y)}')\n    else:\n        print(f'The final result F1_SCORE(average=\"weighted\") of the custom split:\\n{classification_accuracy(train_X, test_X, train_y, test_y)}')\n    \n    return train_X, test_X, train_y, test_y","0d56fe26":"target = 'Deaths\/1M population'\ntrain_X, test_X, train_y, test_y = train_test_split_ordered(df, target, test_size=0.33, verbose=1, research_iter=100)","4211b32c":"import shap\nfrom xgboost import XGBRegressor\n\n\nmodel = XGBRegressor(random_state=0).fit(train_X, train_y)\n\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(test_X)\n\nplt.title(target)\nplt.gcf().subplots_adjust()\nshap.summary_plot(shap_values, test_X, max_display=train_X.shape[1], show=True, plot_size=(10, 12))\n\n# plt.savefig(\"shap_\"+target+\"_.png\")\n# plt.savefig(\"shap_\"+target+\"_.pdf\")\nplt.close()","0ce2af12":"from matplotlib import pyplot as plt\nfrom pdpbox import pdp\nfrom lightgbm import LGBMRegressor\n\n\nmodel = LGBMRegressor(random_state=0).fit(train_X, train_y)\n\nfor feature in list(train_X.columns):\n    print('\\n\\n\\n\\n')\n    pdp_dist = pdp.pdp_isolate(model=model,\n                               dataset=test_X,\n                               model_features=test_X.columns, \n                               feature=feature)\n\n    pdp.pdp_plot(pdp_dist, feature)\n    plt.title(target)  \n#     plt.savefig(\"pdp_\"+feature+\"_.png\", dpi=100)\n    plt.show()\n    plt.close()","38f8c0e0":"# Moratality Research","1cc7cba6":"# Conclusion\n\n# 1) High 'Total Cases\/1M population' - increases moratality   \n\n# 2) High 'Tests\/1M population' - decreases moratality   ","9683453e":"### Drop 'Total Deaths'","6db002d9":"# Normalized"}}