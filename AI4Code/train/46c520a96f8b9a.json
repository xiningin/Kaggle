{"cell_type":{"7afb4ea2":"code","76a1e8d2":"code","cd00a294":"code","83905e6f":"code","c374d4e8":"code","4ef1fefe":"code","7abd736d":"code","c219e227":"code","4d05f3e7":"code","dfc5ea61":"code","dbb6f294":"code","8d320334":"code","629005be":"code","ec4203f8":"code","517a40b8":"code","7a210b11":"code","d9fb92ac":"code","e7344c77":"code","f6569a1b":"code","6d0917ce":"code","f616706e":"code","16c09602":"code","4e930cd7":"code","ad36780a":"code","850f86a3":"markdown","1bd784c9":"markdown","5653f826":"markdown","bc957c70":"markdown","3104a56e":"markdown","ac125439":"markdown","9ae293a5":"markdown","014c6cd8":"markdown","b11ccd7d":"markdown","18850e32":"markdown","fc9f4df9":"markdown","1e626de0":"markdown","8b4dd4c1":"markdown","eb12b784":"markdown","d35b000a":"markdown","91de0672":"markdown","ebf47e77":"markdown","dd65a942":"markdown","8559d247":"markdown","d010ff67":"markdown","2785b0e8":"markdown","cf7881f5":"markdown","fd54293e":"markdown","f0e7b51e":"markdown","b453b19d":"markdown","ef4dc24f":"markdown","5f2428ce":"markdown","579b9804":"markdown","edf14bb9":"markdown","5fdb64da":"markdown","4f771777":"markdown","a6971181":"markdown","dde8bddc":"markdown","cbf77e3e":"markdown","e79aee81":"markdown","c9398e7b":"markdown","29db1139":"markdown","58cf9f4e":"markdown","da1862e4":"markdown","4ce32728":"markdown","d1b8fac4":"markdown"},"source":{"7afb4ea2":"\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os,cv2\nfrom IPython.display import Image\nfrom keras.preprocessing import image\nfrom keras import optimizers\nfrom keras import layers,models\nfrom keras.applications.imagenet_utils import preprocess_input\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras import regularizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16\nprint(os.listdir(\"..\/input\"))\n\nimport numpy as np\n\n","76a1e8d2":"train_dir=\"..\/input\/train\/train\"\ntest_dir=\"..\/input\/test\/test\"\ntrain=pd.read_csv('..\/input\/train.csv')\n\ndf_test=pd.read_csv('..\/input\/sample_submission.csv')","cd00a294":"train.head(5)\ntrain.has_cactus=train.has_cactus.astype(str)","83905e6f":"print('out dataset has {} rows and {} columns'.format(train.shape[0],train.shape[1]))","c374d4e8":"train['has_cactus'].value_counts()","4ef1fefe":"print(\"The number of rows in test set is %d\"%(len(os.listdir('..\/input\/test\/test'))))","7abd736d":"Image(os.path.join(\"..\/input\/train\/train\",train.iloc[0,0]),width=250,height=250)","c219e227":"datagen=ImageDataGenerator(rescale=1.\/255)\nbatch_size=150","4d05f3e7":"train_generator=datagen.flow_from_dataframe(dataframe=train[:15001],directory=train_dir,x_col='id',\n                                            y_col='has_cactus',class_mode='binary',batch_size=batch_size,\n                                            target_size=(150,150))\n\n\nvalidation_generator=datagen.flow_from_dataframe(dataframe=train[15000:],directory=train_dir,x_col='id',\n                                                y_col='has_cactus',class_mode='binary',batch_size=50,\n                                                target_size=(150,150))","dfc5ea61":"model=models.Sequential()\nmodel.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.Conv2D(64,(3,3),activation='relu',input_shape=(150,150,3)))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.Conv2D(128,(3,3),activation='relu',input_shape=(150,150,3)))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.Conv2D(128,(3,3),activation='relu',input_shape=(150,150,3)))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512,activation='relu'))\nmodel.add(layers.Dense(1,activation='sigmoid'))\n         ","dbb6f294":"model.summary()","8d320334":"model.compile(loss='binary_crossentropy',optimizer=optimizers.rmsprop(),metrics=['acc'])\n","629005be":"epochs=10\nhistory=model.fit_generator(train_generator,steps_per_epoch=100,epochs=10,validation_data=validation_generator,validation_steps=50)","ec4203f8":"acc=history.history['acc']  ##getting  accuracy of each epochs\nepochs_=range(0,epochs)    \nplt.plot(epochs_,acc,label='training accuracy')\nplt.xlabel('no of epochs')\nplt.ylabel('accuracy')\n\nacc_val=history.history['val_acc']  ##getting validation accuracy of each epochs\nplt.scatter(epochs_,acc_val,label=\"validation accuracy\")\nplt.title(\"no of epochs vs accuracy\")\nplt.legend()\n\n\n\n\n    ","517a40b8":"acc=history.history['loss']    ##getting  loss of each epochs\nepochs_=range(0,epochs)\nplt.plot(epochs_,acc,label='training loss')\nplt.xlabel('No of epochs')\nplt.ylabel('loss')\n\nacc_val=history.history['val_loss']  ## getting validation loss of each epochs\nplt.scatter(epochs_,acc_val,label=\"validation loss\")\nplt.title('no of epochs vs loss')\nplt.legend()","7a210b11":"model_vg=VGG16(weights='imagenet',include_top=False)\nmodel_vg.summary()","d9fb92ac":"def extract_features(directory,samples,df):\n    \n    \n    features=np.zeros(shape=(samples,4,4,512))\n    labels=np.zeros(shape=(samples))\n    generator=datagen.flow_from_dataframe(dataframe=df,directory=directory,x_col='id',\n                                            y_col='has_cactus',class_mode='other',batch_size=batch_size,\n                                            target_size=(150,150))\n    i=0\n    for input_batch,label_batch in generator:\n        feature_batch=model_vg.predict(input_batch)\n        features[i*batch_size:(i+1)*batch_size]=feature_batch\n        labels[i*batch_size:(i+1)*batch_size]=label_batch\n        i+=1\n        if(i*batch_size>samples):\n            break\n    return(features,labels)\n\ntrain.has_cactus=train.has_cactus.astype(int)\nfeatures,labels=extract_features(train_dir,17500,train)\ntrain_features=features[:15001]\ntrain_labels=labels[:15001]\n\nvalidation_features=features[15000:]\nvalidation_labels=labels[15000:]\n\n","e7344c77":"#df_test.has_cactus=df_test.has_cactus.astype(str)\ntest_features,test_labels=extract_features(test_dir,4000,df_test)","f6569a1b":"train_features=train_features.reshape((15001,4*4*512))\nvalidation_features=validation_features.reshape((2500,4*4*512))\n\ntest_features=test_features.reshape((4000,4*4*512))\n","6d0917ce":"model=models.Sequential()\nmodel.add(layers.Dense(212,activation='relu',kernel_regularizer=regularizers.l1_l2(.001),input_dim=(4*4*512)))\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Dense(1,activation='sigmoid'))\n","f616706e":"model.compile(optimizer=optimizers.rmsprop(),loss='binary_crossentropy',metrics=['acc'])","16c09602":"history=model.fit(train_features,train_labels,epochs=30,batch_size=15,validation_data=(validation_features,validation_labels))","4e930cd7":"y_pre=model.predict_proba(test_features)","ad36780a":"df=pd.DataFrame({'id':df_test['id'] })\ndf['has_cactus']=y_pre\ndf.to_csv(\"submission.csv\",index=False)\n","850f86a3":"### Displaying an image","1bd784c9":"## A brief intro to CNN[](#2) <a id='2'> <\/a><br>","5653f826":"As you know,data should be processed into appropriatly pre-processed floating point \ntensors before being fed to our network.So the steps for getting it into our network are roughly ","bc957c70":"we will make use of ImageDataGenerator method available in keras to do all the preprocessing.","3104a56e":"In this step we will specify 3 important things related to our model\n","ac125439":"The convolution operation is the building block of a convolutional neural network as the name suggests it.\nNow, in the field of computer vision, an image can be expressed as a matrix of RGB values.\nTherefore, let\u2019s consider the 6x6 matrix below as a part of an image:\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*aGSthcPASa2OT1UBm7paOA.png)\nAnd the filter will be the following matrix:\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*591OPcvDKUN9liZ_VQ1M5g.png)\nThen, the convolution involves superimposing the filter onto the image matrix, adding the product of the values from the filter and and the values from the image matrix, which will generate a 4x4 convoluted layer.\n\nThis is very hard to put in words, but here is a nice animation that explains the convolution:\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*VJCoCYjnjBBtWDLrugCBYQ.gif)","9ae293a5":"## Compiling our model","014c6cd8":"### Maxpooling","b11ccd7d":"Convolutions are defined on two key parameters\n- The size of patches that are extracted from input feature map..ie here 3x3\n- The number of filters computed from convolutions","18850e32":"### Displaying summary of our network","fc9f4df9":"![](https:\/\/media.giphy.com\/media\/BmmfETghGOPrW\/giphy.gif)","1e626de0":"### Define a densely connected network","8b4dd4c1":"- loss: we will set our loss as binary_crossentropy since we are\n   attacking a binary classification problem\n- optimizer : optimizers shape and mold your model into its most accurate possible form by futzing with the weights.\n- metrics : This is the evaluation criteria that we choose to evaluate our model","eb12b784":"## Evaluating our model[](#4)<a id=\"4\"><\/a><br>","d35b000a":"## Improving our model using VGG16[](#5)<a id=\"5\"><\/a><br> ","91de0672":"Here we will use keras fit_generator() method instead of fit() method because we have used ImageDataGenerator to generate values.\n","ebf47e77":"# **Introduction**","dd65a942":"### Loading required libraries","8559d247":"Maxpooling consist of extracting features from input feature map and outputig maximum value of each channel.\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*Ziqq69FhwOAbBi9-FNruAA.png)","d010ff67":"## Building our model [](#3) <a id=\"3\"><\/a><br> ","2785b0e8":"### Extracting features using VGG16","cf7881f5":"and it's no rocket science,its fun.","fd54293e":"## making prediction","f0e7b51e":"- Instantiating the VGG16 convolution base","b453b19d":"## Making a submission[](#6)<a id=\"6\"><\/a><br>","ef4dc24f":"## Getting a basic idea","5f2428ce":"- Read the picture files\n- Decode JPEG content to RGB pixels\n- Convert this into floating tensors\n- Rescale pixel values (between 0 to 255) to [0,1] interval.","579b9804":"Now,after preprocessing is done with our data we will split our dataset to\ntraining and validation for training our model and validating the result repectively.\nWe will take first 15000 images to train our data and last 2500 images to validate our model later.\n","edf14bb9":"![](https:\/\/blog.algorithmia.com\/wp-content\/uploads\/2018\/05\/word-image.png)","5fdb64da":"**In this kernel,we will be learning about Convolution neural networks.We will learn**\n- [how to prepare your data to feed to a neural network](#1)\n- [how convolution neural network works](#2)\n- [how to implement cnn in keras](#3)\n- [how to evaluvate your results](#4)\n- [how to use keras pretrained network to improve your model](#5)\n- [how to predict and  create a submission](#6)\n   ","4f771777":"we will plot our results using matplotlib.first we will plot training and validation accuracy.","a6971181":"### If you guys like my kernel,please do consider upvoting it.","dde8bddc":"### Reshaping our features to feed into our dense layers","cbf77e3e":"**if you like my kernel,please consider upvoting**","e79aee81":"### Splitting our train and validation dataset","c9398e7b":"### Setting our directories","29db1139":"**flow_from_dataframe Method**\n\nThis method is useful when the images are clustered in only one folder. To put in other words images from different class\/labels reside in only one folder. Generally, with such kind of data, some text files containing information on class and other parameters are provided. In this case, we will create a dataframe using pandas and text files provided, and create a meaningful dataframe with columns having file name (only the file names, not the path) and other classes to be used by the model. For this method, arguments to be used are:\n\n    dataframe value : Dataframe having meaningful data (file name, class columns are a must)\n    directory value : The path to the parent directory containing all images.\n    x_col value : which will be the name of column(in dataframe) having file names\n    y_col value : which will be the name of column(in dataframe) having class\/label","58cf9f4e":"## Data preparation [](#1)  <a id=\"1\"><\/a> <br>","da1862e4":"### Fitting our model ","4ce32728":"Now we will plot training loss and validation loss vs number of epochs","d1b8fac4":"[](http:\/\/)Now we will build our network.We will build our model such that it contains\n5 **Conv2D + Maxpooling2D stages** with **relu** activation function."}}