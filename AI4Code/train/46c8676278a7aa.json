{"cell_type":{"f2ec8f24":"code","43fbf2be":"code","cce68473":"code","091517ba":"code","c1b8530d":"code","ba943044":"code","2287aef4":"code","b0aedc0c":"code","a36a8a13":"code","4b5a1d01":"code","0dc1833a":"code","5eb3c634":"code","db649bec":"code","6b5c4486":"code","712342dd":"code","ac5a9291":"code","344a3eb4":"code","ebe5f5e0":"code","9c6d3090":"code","adb63069":"markdown","e650fb9a":"markdown","d993d144":"markdown","76647acd":"markdown"},"source":{"f2ec8f24":"import pandas as pd\nimport numpy as np\nimport keras\nfrom tensorflow.keras import layers, optimizers, callbacks, utils, losses, metrics, backend as K\nfrom keras.models import Sequential\nimport tensorflow_addons as tfa\nimport tensorflow as tf\nfrom keras.layers import Flatten, Activation, Dropout,BatchNormalization\nfrom keras.layers import Dense\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import activations,callbacks\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import plot_confusion_matrix, roc_auc_score, plot_roc_curve, classification_report\nfrom matplotlib import pyplot as plt\nplt.style.use('dark_background')\nfrom sklearn.preprocessing import OneHotEncoder\nimport warnings\nwarnings.filterwarnings(\"ignore\")","43fbf2be":"initial_csv = pd.read_csv('..\/input\/dataset\/train.csv') # to follow the preprocess function\ntrain= pd.read_csv('..\/input\/dataset\/train.csv')\ntarget=train['target']","cce68473":"train_data = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/train.csv')\ntest_data = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/test.csv')\n\n#combine train and test data vertically\nX_nums = np.vstack([\n    train_data.iloc[:, 20:-1].to_numpy(),\n    test_data.iloc[:, 20:].to_numpy()\n])\nX_nums = (X_nums - X_nums.mean(0)) \/ X_nums.std(0) #normalize\n\n#stack the categorical data\nX_cat = np.vstack([\n    train_data.iloc[:, 1:20].to_numpy(),\n    test_data.iloc[:, 1:20].to_numpy()\n])\n#encode the categoricals\nencoder = OneHotEncoder(sparse=False)\nX_cat = encoder.fit_transform(X_cat)\n\n#join the categorical and continuous data horizontally\nX = np.hstack([X_cat, X_nums])\ny = train_data['target'].to_numpy().reshape(-1, 1)","091517ba":"train = X[:300000,:]\ntarget = train_data.iloc[:300000,-1]\nx_train, x_test, y_train, y_test = train_test_split(train, target, test_size=0.2)","c1b8530d":"x_train.shape","ba943044":"def preprocess_x(df):\n    try: df.set_index('id',inplace=True)\n    except: pass\n\n    df = pd.get_dummies(df, drop_first=False)\n    for col in pd.get_dummies(initial_csv.drop(columns=['target']), drop_first=False).columns:\n        if col not in df.columns:\n            df[col]=0\n\n    return df\n\ndef preprocess(df):\n    try: df.set_index('id',inplace=True)\n    except: pass\n\n    x = df.drop(columns=['target'])\n    x = preprocess_x(x)\n    return x\n\ntrain = preprocess(train)","2287aef4":"train.shape","b0aedc0c":"x_train, x_test, y_train, y_test = train_test_split(train, target, test_size=0.2)\n","a36a8a13":"print(\"x_train\",x_train.shape)\nprint(\"x_test\",x_test.shape)\nprint(\"y_train\",y_train.shape)\nprint(\"y_test\",y_test.shape)","4b5a1d01":"model = Sequential()\n\nmodel.add(Dense(300, activation='relu',input_dim=642)) # depends on the shape of train !\nmodel.add(Dropout(0.3))\nmodel.add(Dense(300, activation='relu'))\n#model.add(Dropout(0.3))\n#model.add(Dense(30, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()","0dc1833a":"tf.keras.metrics.AUC(\n    num_thresholds=200,\n    curve=\"ROC\",\n    summation_method=\"interpolation\",\n    name= 'val_AUC',\n    dtype=None,\n    thresholds=None,\n    multi_label=False,\n    label_weights=None,\n)","5eb3c634":"model.compile(\n        optimizer=tfa.optimizers.SWA(tf.keras.optimizers.Adam(learning_rate=0.0001)),\n        loss=losses.BinaryCrossentropy(),\n        metrics=metrics.AUC(name=\"AUC\"))\n \n\n\nes = callbacks.EarlyStopping(monitor='val_AUC', \n                             min_delta=0.0000001,\n                             patience=5, \n                             mode='max', \n                             baseline=None, \n                             restore_best_weights=True,\n                             verbose=1)\n\nplateau  = callbacks.ReduceLROnPlateau(monitor='val_loss',\n                                       factor=0.5,\n                                       patience=2,\n                                       mode='max',\n                                       min_delta=0.00001,\n                                       cooldown=0,\n                                       min_lr=1e-7,\n                                       verbose=1) \n\nsb = callbacks.ModelCheckpoint('.\/nn_model.w8',\n                               save_weights_only=True,\n                               save_best_only=True,\n                               verbose=1,\n                               monitor='val_AUC',\n                               mode='max')\n","db649bec":"\n\"\"\"\nhistory=model.fit(x=x_train,\n                  y=y_train,\n                  validation_data=(x_test, y_test),\n                  batch_size=256,\n                  epochs=20,\n                  shuffle=False,\n                  verbose=1,\n                  callbacks=[es,sb,plateau])\n\"\"\"\n\nhistory=model.fit(x=x_train,\n                  y=y_train,\n                  validation_data=(x_test, y_test),\n                  epochs=20)\n","6b5c4486":"plt.figure(figsize=(20,10)) \nloss = history.history['AUC']\nval_loss = history.history['val_AUC']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'y', label='Training AUC')\nplt.plot(epochs, val_loss, 'r', label='Validation AUC')\nplt.title('Training and validation AUC')\nplt.xlabel('Epochs')\nplt.ylabel('AUC')\nplt.legend()\nplt.show()","712342dd":"pred=model.predict(x_test)","ac5a9291":"print(roc_auc_score(y_test, pred))","344a3eb4":"np.mean(y_test)","ebe5f5e0":"np.mean(pred)","9c6d3090":"np.mean(y_train)","adb63069":"<h3> Model definition <h3>","e650fb9a":"<h2> Get_dummies encoding <h2>","d993d144":"<h1> Training <h1>","76647acd":"<h1> Encoding One Hot <h1>"}}