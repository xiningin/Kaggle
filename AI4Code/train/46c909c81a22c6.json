{"cell_type":{"d4ed4563":"code","fb799b00":"code","d39891d7":"code","7a6b69b4":"code","37812fad":"code","6c6e4dc8":"code","6a2e0b27":"code","f3c4ba8b":"code","e8b905db":"code","6b74c0a2":"code","29033692":"code","91952591":"code","98e87893":"code","f189d7e9":"code","aec105d7":"code","caa22a9a":"code","a02646a6":"code","47b32bef":"code","b43e929a":"code","503cb30f":"code","e5eeb19e":"code","e543f56f":"code","2cdc2613":"code","207003f7":"code","6dcc1406":"code","fb8866a4":"code","f810a0f1":"code","b383de64":"code","16aef39d":"code","c34d26a3":"code","df8571b2":"markdown","2dbc4b65":"markdown","d916a004":"markdown","20bb57af":"markdown","6aeea9ab":"markdown","4a4f4126":"markdown","b1841be1":"markdown","ec66fbd7":"markdown","e5a41edc":"markdown","08549b7d":"markdown","5f3660c9":"markdown","b703c64e":"markdown","46aabe4c":"markdown","27cb2af0":"markdown"},"source":{"d4ed4563":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fb799b00":"train_df=pd.read_csv('..\/input\/ventilator-pressure-prediction\/train.csv')\ntest_df=pd.read_csv('..\/input\/ventilator-pressure-prediction\/test.csv')","d39891d7":"train_df.shape # Shape is needed to be validated for building the model","7a6b69b4":"train_df.info()  # To get the idea about different type of features in dataset","37812fad":"train_df['u_out'].value_counts()","6c6e4dc8":"train_df.isnull().sum() ","6a2e0b27":"Y=train_df['pressure'] # Separating our traget Feature","f3c4ba8b":"train_df['u_in_cumsum'] = (train_df['u_in']).groupby(train_df['breath_id']).cumsum()\n\ntest_df['u_in_cumsum'] = (test_df['u_in']).groupby(test_df['breath_id']).cumsum()","e8b905db":"x=train_df.drop('u_out',axis=1)\ny=train_df['u_out']","6b74c0a2":"from sklearn.feature_selection import mutual_info_regression\n# Mutual info regression will provide a mesure of dependence between the Features and Traget-variable\n\nxtr=train_df.drop(['pressure','id'],axis=1)[:70000]\n# Visualizing the dependence using first 70,000 rows\n\nytr=train_df['pressure'][:70000]","29033692":"mi_score=mutual_info_regression(xtr,ytr)\n# Providing the features and Target-variable as input\n\nmi_score=pd.Series(mi_score,index=xtr.columns)\n#converting the scores to a pandas series and providing the columns as index for the scores\n\nmi_score=mi_score.sort_values(ascending=False)\n# Sorting the scores in descending order\n\nmi_score*100\n# Getting the percentage-dependece out of 100","91952591":"from sklearn.preprocessing import StandardScaler\nxtr=StandardScaler().fit_transform(train_df.drop(['pressure','R','C','id'],axis=1))\nxte=StandardScaler().fit_transform(test_df.drop(['R','C','id'],axis=1))","98e87893":"import tensorflow.keras as keras\nfrom tensorflow.keras import layers,callbacks","f189d7e9":"\"\"\"model=keras.Sequential([\n    layers.Dense(27,input_shape=(5,),activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.4),\n    \n    layers.Dense(108,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.4),\n    \n    layers.Dense(324,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.4),\n    \n    layers.Dense(522,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.4),\n    \n    layers.Dense(819,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.4),\n    \n    layers.Dense(927,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.4),\n    \n    layers.Dense(720,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.4),\n    \n    layers.Dense(522,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.4),\n    \n    layers.Dense(288,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.4),\n    \n    layers.Dense(1,activation='linear')\n    \n])\"\"\"","aec105d7":"model=keras.Sequential([\n    layers.Dense(64,input_shape=(5,),activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.5),\n    \n    layers.Dense(224,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.5),\n    \n    layers.Dense(624,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.5),\n    \n    layers.Dense(312,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.5),\n    \n    layers.Dense(1,activation='relu')\n    \n])","caa22a9a":"model.summary()","a02646a6":"from sklearn.model_selection import train_test_split\nxtr,xval,ytr,yval=train_test_split(xtr,train_df['pressure'],test_size=0.3,random_state=51)","47b32bef":"model.compile(optimizer='adamax',loss='mean_absolute_error',metrics=['mean_absolute_error'])","b43e929a":"call=keras.callbacks.EarlyStopping(min_delta=0.0001,restore_best_weights=True,patience=8)\nhistory=model.fit(xtr,ytr,validation_data=(xval,yval),epochs=45,batch_size=64,callbacks=[call])","503cb30f":"model_training=pd.DataFrame(history.history)","e5eeb19e":"model_training","e543f56f":"model_training.loc[:,['loss','val_loss']].plot()","2cdc2613":"model_training.loc[:,['mean_absolute_error','val_mean_absolute_error']].plot()","207003f7":"model.evaluate(xte)","6dcc1406":"xte","fb8866a4":"ypred=model.predict(xte)","f810a0f1":"sample=pd.read_csv('..\/input\/ventilator-pressure-prediction\/sample_submission.csv')","b383de64":"sample","16aef39d":"ypred=pd.DataFrame(ypred)","c34d26a3":"sub=pd.DataFrame({'id':test_df['id'],'pressure':ypred[0]})\nsub.to_csv('subbb.csv',index=False)","df8571b2":"# Looking for Null-values","2dbc4b65":"# Fitting the model using `Callback` function","d916a004":"# Submitting *`Predictions`*","20bb57af":"# <1.5 **`Mean_Absolute_Error`**","6aeea9ab":"# Selecting the *`Best-Features`*","4a4f4126":"# Approach to solve this `problem`:\n### * Explore the *dataset*\n### * Lookout for *missing values*\n### * Create new **features**\n### * Choose the corerct features to be the part of `training data`\n### * Scale the *dataset*\n### * Build the `model`\n### * Split the **dataset**\n### * Optimize & Fit the model\n### * Make & Submit **Predictions**","b1841be1":"# Creating new `Features`","ec66fbd7":"# Splitting the `Dataset` into:\n#### * Training set\n#### * Validation set","e5a41edc":"# Creating *predictions*","08549b7d":"# Building the Neural **`Model`**","5f3660c9":"# Visualizing the **`Epoch`** History","b703c64e":"#### Compiling the model","46aabe4c":"# Exploring the *dataset*","27cb2af0":"# Scaling the `final`-Features"}}