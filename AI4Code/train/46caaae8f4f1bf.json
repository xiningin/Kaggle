{"cell_type":{"a3c56803":"code","15ef4df5":"code","0ea4fbc7":"code","e2dd8940":"code","b24be092":"code","f6b85dce":"code","992b09d7":"code","dce18a7d":"code","6fb73241":"code","be559dc6":"code","aa04488b":"code","a59acbfa":"code","01a09105":"code","1a6de304":"code","f810cc11":"code","c318abac":"code","b7a89b2f":"code","8a97e4e7":"markdown","921000d6":"markdown","a6a9ec58":"markdown"},"source":{"a3c56803":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","15ef4df5":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","0ea4fbc7":"df= pd.read_csv('..\/input\/mushroom-classification\/mushrooms.csv')\ndf.head()","e2dd8940":"X=df.drop('class', 1)\ny=df['class']","b24be092":"y = y.map({'p': 'Posionous', 'e': 'Edible'})","f6b85dce":"X.info()","992b09d7":"cat_cols= X.select_dtypes(include='object').columns.tolist()\nfor col in cat_cols:\n    print (f\" col name : {col}, N Unique : {X[col].nunique()}\")","dce18a7d":"for col in cat_cols:\n    X[col]=X[col].astype(\"category\")\n    X[col]=X[col].cat.codes","6fb73241":"X.head()","be559dc6":"from sklearn.preprocessing import StandardScaler\nX_std= StandardScaler().fit_transform(X)","aa04488b":"from sklearn.decomposition import PCA","a59acbfa":"X_pca = PCA(n_components=2).fit_transform(X_std)\nX_pca","01a09105":"X_pca = np.vstack((X_pca.T, y)).T\nX_pca","1a6de304":"df_pca = pd.DataFrame(X_pca, columns=['1st_Component', '2nd_Component', 'class'])\ndf_pca.head()","f810cc11":"plt.figure(figsize=(8, 8))\nsns.scatterplot(data=df_pca, hue='class', x='1st_Component', y='2nd_Component')\nplt.show()","c318abac":"from sklearn.manifold import TSNE\n\nX_tsne = TSNE().fit_transform(X_std)\nX_tsne = np.vstack((X_tsne.T, y)).T\ndf_tsne = pd.DataFrame(X_tsne, columns=['Dim1', 'Dim2', 'class'])\ndf_tsne.head()","b7a89b2f":"plt.figure(figsize=(8, 8))\nsns.scatterplot(data=df_tsne, hue='class', x='Dim1', y='Dim2')\nplt.show()","8a97e4e7":"* Since all the input features are object types. we need to encode it into numeric\n* Let's check the number of unique values in each feature","921000d6":"by this resule we can see that t-SNE outperforms than PCA","a6a9ec58":"* Since the number of classes in each features are not very high, we can chage the features into categories and encode them.\n* We need not to worry about the priorities in categorical encoding using the following method."}}