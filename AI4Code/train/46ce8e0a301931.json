{"cell_type":{"546d269c":"code","f9769a1d":"code","7cf7297f":"code","108a9f5a":"code","3b060d7b":"code","3101ff01":"code","b0adcd8c":"code","30b40494":"code","64d3c4ac":"code","5caa4cfe":"code","200ca995":"code","58ade173":"code","e5f641be":"code","0cb68c10":"code","59e11ca2":"code","c641bdc2":"code","f219a8d0":"code","4095ae5b":"code","2345a0a0":"code","bda1d5b7":"markdown","5a893beb":"markdown","f0cbdf4e":"markdown"},"source":{"546d269c":"!pip install mglearn","f9769a1d":"import mglearn\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport matplotlib as mpl","7cf7297f":"! wget -nc http:\/\/ai.stanford.edu\/~amaas\/data\/sentiment\/aclImdb_v1.tar.gz -P data\n! tar xzf data\/aclImdb_v1.tar.gz --skip-old-files -C data","108a9f5a":"!tree -dL 2 data\/aclImdb","3b060d7b":"!rm -r data\/aclImdb\/train\/unsup","3101ff01":"from sklearn.datasets import load_files\n\nreviews_train = load_files(\"data\/aclImdb\/train\/\")\n# load_files returns a bunch, containing training texts and training labels\ntext_train, y_train = reviews_train.data, reviews_train.target\nprint(\"type of text_train: {}\".format(type(text_train)))\nprint(\"length of text_train: {}\".format(len(text_train)))\nprint(\"text_train[6]:\\n{}\".format(text_train[6]))","b0adcd8c":"text_train = [doc.replace(b\"<br \/>\", b\" \") for doc in text_train]","30b40494":"np.unique(y_train)","64d3c4ac":"print(\"Samples per class (training): {}\".format(np.bincount(y_train)))","5caa4cfe":"reviews_test = load_files(\"data\/aclImdb\/test\/\")\ntext_test, y_test = reviews_test.data, reviews_test.target\nprint(\"Number of documents in test data: {}\".format(len(text_test)))\nprint(\"Samples per class (test): {}\".format(np.bincount(y_test)))\ntext_test = [doc.replace(b\"<br \/>\", b\" \") for doc in text_test]","200ca995":"from sklearn.feature_extraction.text import CountVectorizer\nvect = CountVectorizer().fit(text_train)\nX_train = vect.transform(text_train)\nprint(\"X_train:\\n{}\".format(repr(X_train)))","58ade173":"feature_names = vect.get_feature_names()\nprint(\"Number of features: {}\".format(len(feature_names)))\nprint(\"First 20 features:\\n{}\".format(feature_names[:20]))\nprint(\"Features 20010 to 20030:\\n{}\".format(feature_names[20010:20030]))\nprint(\"Every 2000th feature:\\n{}\".format(feature_names[::2000]))","e5f641be":" X_train.toarray()","0cb68c10":"sorted(vect.vocabulary_)[:5]","59e11ca2":"len(sorted(vect.vocabulary_))","c641bdc2":"manyWordCount = sorted( X_train.toarray().sum(axis=0),reverse=True)","f219a8d0":"manyWordCount[:5]","4095ae5b":"manyWordSentence = sorted(X_train.toarray().sum(axis=1),reverse=True)","2345a0a0":"manyWordSentence[:5]","bda1d5b7":"# sentence word count","5a893beb":"# make sentence word count dataframe","f0cbdf4e":"# word total count"}}