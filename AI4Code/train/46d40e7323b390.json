{"cell_type":{"90b96135":"code","6b9272e1":"code","10c362f7":"code","a376f765":"code","f4594ce1":"code","87fc2902":"code","be4be96a":"code","49727544":"code","341fa359":"code","494caef9":"code","df4a25e1":"code","4f1ed51b":"code","01158d8b":"code","58acd84a":"code","ec511b5a":"code","d67657c7":"code","98d84f37":"code","8624b360":"code","ea9a3fdd":"code","c6f25127":"code","4781dd58":"code","0f16c1fa":"code","bf1ebd4d":"code","bb2dbf51":"code","a2492890":"code","999c1022":"code","21bdf0b5":"code","95134fac":"code","ec522f10":"code","e6a68abe":"code","9f713243":"code","ff4a9407":"code","435623d0":"code","348e826b":"code","319bbd4e":"code","df311417":"code","3cf770cd":"code","dd704bbe":"code","23d80ba0":"code","4a601e88":"code","9a9045aa":"code","faa1adf7":"code","953b0579":"code","54f714df":"code","5387fc2b":"code","6e52820b":"code","9e8427f6":"code","a3c15ca6":"code","e6770999":"code","9bc5e220":"code","8e8dbf6c":"code","d2ea5dc9":"code","71231f1a":"code","8becfe9e":"code","3e33dd89":"code","a4b3710b":"code","bfd170fc":"code","7c30c106":"code","a6b89b7b":"code","22ccae57":"code","a5e94229":"code","2a102dd7":"markdown","d03cfb2f":"markdown","2685d035":"markdown","8273f75e":"markdown","792eee24":"markdown","b1fde78e":"markdown","b3d8aa9a":"markdown","536b7f6d":"markdown","708bb53f":"markdown","c5e397f4":"markdown","30de0c90":"markdown","160e8d38":"markdown","821f656e":"markdown","780771dc":"markdown","aa75c508":"markdown","01e61331":"markdown","3729c184":"markdown"},"source":{"90b96135":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, plot_confusion_matrix\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","6b9272e1":"TRAIN_DATA_PATH = \"..\/input\/titanic\/train.csv\"\nTEST_DATA_PATH = \"..\/input\/titanic\/test.csv\"","10c362f7":"data = pd.read_csv(TRAIN_DATA_PATH)\ndata.head()","a376f765":"data.info()","f4594ce1":"# Checking for duplicacy\nlen(data[\"PassengerId\"].unique()) == data.shape[0]","87fc2902":"data.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\"],inplace=True)","be4be96a":"data.head()","49727544":"print(data.isnull().sum())\ndata.isnull().sum().plot(kind = \"bar\")\nplt.title(\"NaN values Plot\")\nplt.show()","341fa359":"# Checking the data if it is balanced or not\n\ncounts = data[\"Survived\"].value_counts()\ndiag_cols = [\"Not Survived\", \"Survived\"]\ndiag_counts = [counts[0], counts[1]]\n\nnd = (diag_counts[0] \/ sum(diag_counts))*100\nd = (diag_counts[1] \/ sum(diag_counts)) * 100\n\nprint(f\"Survived: {d}%\")\nprint(f\"Not Survived: {nd}%\")\n\nprint()\n\nplt.figure(figsize = (10, 8))\nsns.barplot(x = diag_cols, y = diag_counts)\nplt.show()","494caef9":"data[\"Pclass\"].unique()","df4a25e1":"data[\"Pclass\"].value_counts().sort_values().plot(kind = \"bar\")\nplt.show()","4f1ed51b":"data.groupby(\"Pclass\")[\"Survived\"].mean()","01158d8b":"data.head()","58acd84a":"data[\"Sex\"].value_counts().plot(kind = \"bar\")\nplt.show()","ec511b5a":"data.groupby(\"Sex\")[\"Survived\"].mean()","d67657c7":"sex_map = {\"female\":1, \"male\":0}\ndata[\"Sex\"] = data[\"Sex\"].map(sex_map).values.copy()","98d84f37":"data.head()","8624b360":"print(f\"Number of missing values in Age: {data['Age'].isnull().sum()}\")","ea9a3fdd":"plt.figure(figsize = (11, 7))\nsns.histplot(data[\"Age\"], kde=True, bins = 50)\nplt.title(\"Age Distribution\")\nplt.show()","c6f25127":"data[\"Age\"].fillna(data[\"Age\"].mean(), inplace=True)","4781dd58":"plt.figure(figsize = (11, 7))\nsns.histplot(data[\"Age\"], kde=True, bins = 50)\nplt.title(\"Age Distribution after Random Sample Inputation\")\nplt.show()","0f16c1fa":"print(f\"Number of missing values in Age: {data['Age'].isnull().sum()}\")","bf1ebd4d":"data.head()","bb2dbf51":"data[\"SibSp\"].unique()","a2492890":"data[\"SibSp\"].value_counts().plot(kind = \"bar\")\nplt.show()","999c1022":"data.groupby(\"SibSp\")[\"Survived\"].mean()","21bdf0b5":"data.head()","95134fac":"data[\"Parch\"].unique()","ec522f10":"data[\"Parch\"].value_counts().plot(kind = \"bar\")\nplt.show()","e6a68abe":"data.head()","9f713243":"plt.figure(figsize = (11, 7))\nsns.histplot(data[\"Fare\"], kde=True, bins = 50)\nplt.title(\"Fare Distribution\")\nplt.show()","ff4a9407":"data[\"Fare\"].isnull().sum()","435623d0":"print(f\"Number of missing values in Cabin: {data['Cabin'].isnull().sum()}\")","348e826b":"data.drop(columns = [\"Cabin\"], inplace = True)","319bbd4e":"data.head()","df311417":"data[\"Embarked\"].unique()","3cf770cd":"data[\"Embarked\"].fillna(data[\"Embarked\"].mode()[0], inplace = True)","dd704bbe":"data.head()","23d80ba0":"data[\"Embarked\"].unique()","4a601e88":"data.groupby(\"Embarked\")[\"Survived\"].mean()","9a9045aa":"embark_map = {\n    \"S\":0,\n    \"Q\":1,\n    \"C\":2\n}\n\ndata[\"Embarked\"] = data[\"Embarked\"].map(embark_map).values","faa1adf7":"data.head()","953b0579":"continuous_data_cols = [\"Age\", \"Fare\"]\nplt.figure(figsize = (10,10))\nsns.pairplot(data[continuous_data_cols+[\"Survived\"]], hue=\"Survived\")\nplt.show()","54f714df":"test_data = pd.read_csv(TEST_DATA_PATH)\n\ntest_data.drop(columns = [\"Name\", \"Cabin\", \"Ticket\"], inplace = True)\n\nprint(\"Missing Values\")\nprint(test_data.isnull().sum())\n\ntest_data[\"Age\"].fillna(test_data[\"Age\"].mean(), inplace = True)\n\ntest_data['Fare'].fillna(test_data[\"Fare\"].mean() ,inplace = True)\n\ntest_data[\"Sex\"] = test_data[\"Sex\"].map(sex_map)\ntest_data[\"Embarked\"] = test_data[\"Embarked\"].map(embark_map)\n\n\nprint()\nprint(\"Missing Values\")\nprint(test_data.isnull().sum())\n\ntest_data.head()","5387fc2b":"all_columns = list(data.columns)\nX = data[all_columns[1:]]\ny = data[\"Survived\"]\nscaler = StandardScaler()\nX = scaler.fit_transform(X)","6e52820b":"all_models = {\n    \"xgb_model\":XGBClassifier(eval_metric = \"logloss\",random_state=18),\n    \"rf_model\":RandomForestClassifier(random_state = 18),\n    \"logistic_model\":LogisticRegression(),\n    \"svm_model\":SVC(),\n    \"ada_model\":AdaBoostClassifier(RandomForestClassifier(random_state = 18))\n}\n\nfor model_name in all_models:\n    print(f\"Model Name: {model_name}\")\n    cv_score = cross_val_score(all_models[model_name],X, y, cv = 5)\n    print(cv_score)\n    print(f\"Mean Score: {np.mean(cv_score)}\")\n    print()","9e8427f6":"# Splitting the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 24)\nprint(f\"Train Data: {X_train.shape}. {y_train.shape}\")\nprint(f\"Test Data: {X_test.shape}. {y_test.shape}\")","a3c15ca6":"svm_model = SVC()\nsvm_model.fit(X_train, y_train)\n\nprint(\"On Test Data\")\npredictions = svm_model.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_test, predictions)}\")\nprint(f\"Precision: {precision_score(y_test, predictions)}\")\nprint(f\"Recall: {recall_score(y_test, predictions)}\")\nplot_confusion_matrix(svm_model, X_test, y_test)\nplt.show()\n\nprint()\n\nprint(\"On Train Data\")\npredictions = svm_model.predict(X_train)\nprint(f\"Accuracy: {accuracy_score(y_train, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_train, predictions)}\")\nprint(f\"Precision: {precision_score(y_train, predictions)}\")\nprint(f\"Recall: {recall_score(y_train, predictions)}\")\nplot_confusion_matrix(svm_model, X_train, y_train)\nplt.show()","e6770999":"param_grid = {'C': [0.1, 1, 10, 100, 1000], \n              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n              'kernel': ['rbf']} \n  \ngrid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 0)\ngrid.fit(X_train, y_train)\n\nprint(\"Best Params:\",grid.best_params_)\nprint(\"Best Estimator\", grid.best_estimator_)","9bc5e220":"svm_model = SVC(C=1000, gamma=0.01)\nsvm_model.fit(X_train, y_train)\n\nprint(\"On Test Data\")\npredictions = svm_model.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_test, predictions)}\")\nprint(f\"Precision: {precision_score(y_test, predictions)}\")\nprint(f\"Recall: {recall_score(y_test, predictions)}\")\nplot_confusion_matrix(svm_model, X_test, y_test)\nplt.show()\n\nprint()\n\nprint(\"On Train Data\")\npredictions = svm_model.predict(X_train)\nprint(f\"Accuracy: {accuracy_score(y_train, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_train, predictions)}\")\nprint(f\"Precision: {precision_score(y_train, predictions)}\")\nprint(f\"Recall: {recall_score(y_train, predictions)}\")\nplot_confusion_matrix(svm_model, X_train, y_train)\nplt.show()","8e8dbf6c":"rf_model = RandomForestClassifier(random_state = 18)\nrf_model.fit(X_train, y_train)\n\nprint(\"On Test Data\")\npredictions = rf_model.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_test, predictions)}\")\nprint(f\"Precision: {precision_score(y_test, predictions)}\")\nprint(f\"Recall: {recall_score(y_test, predictions)}\")\nplot_confusion_matrix(rf_model, X_test, y_test)\nplt.show()\n\nprint()\n\nprint(\"On Train Data\")\npredictions = rf_model.predict(X_train)\nprint(f\"Accuracy: {accuracy_score(y_train, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_train, predictions)}\")\nprint(f\"Precision: {precision_score(y_train, predictions)}\")\nprint(f\"Recall: {recall_score(y_train, predictions)}\")\nplot_confusion_matrix(rf_model, X_train, y_train)\nplt.show()","d2ea5dc9":"n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\nmax_features = ['auto', 'sqrt']\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4]\nbootstrap = [True, False]\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\n\nrf = RandomForestClassifier(random_state = 24)\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, random_state=24, n_jobs = -1)\nrf_random.fit(X_train, y_train)\n\nprint(\"Best Params:\",rf_random.best_params_)\nprint(\"Best Estimator\", rf_random.best_estimator_)","71231f1a":"rf_model = RandomForestClassifier(bootstrap=False, max_depth=80, min_samples_leaf=2,\n                       min_samples_split=5, n_estimators=600, random_state=24)\nrf_model.fit(X_train, y_train)\n\nprint(\"On Test Data\")\npredictions = rf_model.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_test, predictions)}\")\nprint(f\"Precision: {precision_score(y_test, predictions)}\")\nprint(f\"Recall: {recall_score(y_test, predictions)}\")\nplot_confusion_matrix(rf_model, X_test, y_test)\nplt.show()\n\nprint()\n\nprint(\"On Train Data\")\npredictions = rf_model.predict(X_train)\nprint(f\"Accuracy: {accuracy_score(y_train, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_train, predictions)}\")\nprint(f\"Precision: {precision_score(y_train, predictions)}\")\nprint(f\"Recall: {recall_score(y_train, predictions)}\")\nplot_confusion_matrix(rf_model, X_train, y_train)\nplt.show()","8becfe9e":"xgb_model = XGBClassifier(random_state = 18)\nxgb_model.fit(X_train, y_train)\n\nprint(\"On Test Data\")\npredictions =xgb_model.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_test, predictions)}\")\nprint(f\"Precision: {precision_score(y_test, predictions)}\")\nprint(f\"Recall: {recall_score(y_test, predictions)}\")\nplot_confusion_matrix(xgb_model, X_test, y_test)\nplt.show()\n\nprint()\n\nprint(\"On Train Data\")\npredictions =xgb_model.predict(X_train)\nprint(f\"Accuracy: {accuracy_score(y_train, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_train, predictions)}\")\nprint(f\"Precision: {precision_score(y_train, predictions)}\")\nprint(f\"Recall: {recall_score(y_train, predictions)}\")\nplot_confusion_matrix(xgb_model, X_train, y_train)\nplt.show()","3e33dd89":"ada_model = AdaBoostClassifier()\nada_model.fit(X_train, y_train)\n\nprint(\"On Test Data\")\npredictions = ada_model.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_test, predictions)}\")\nprint(f\"Precision: {precision_score(y_test, predictions)}\")\nprint(f\"Recall: {recall_score(y_test, predictions)}\")\nplot_confusion_matrix(ada_model, X_test, y_test)\nplt.show()\n\nprint()\n\nprint(\"On Train Data\")\npredictions = ada_model.predict(X_train)\nprint(f\"Accuracy: {accuracy_score(y_train, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_train, predictions)}\")\nprint(f\"Precision: {precision_score(y_train, predictions)}\")\nprint(f\"Recall: {recall_score(y_train, predictions)}\")\nplot_confusion_matrix(ada_model, X_train, y_train)\nplt.show()","a4b3710b":"voting_model = VotingClassifier(\n    [\n        (\"rf_model\", RandomForestClassifier(bootstrap=False, max_depth=80, min_samples_leaf=2,\n                       min_samples_split=5, n_estimators=600, random_state=24)),\n        (\"xgb_model\", XGBClassifier(eval_metric=\"logloss\", random_state = 18)),\n        (\"svm_model\", SVC(C=1000, gamma=0.01))\n    ]\n)\n\nvoting_model.fit(X_train, y_train)\n\nprint(\"On Test Data\")\npredictions = voting_model.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_test, predictions)}\")\nprint(f\"Precision: {precision_score(y_test, predictions)}\")\nprint(f\"Recall: {recall_score(y_test, predictions)}\")\nplot_confusion_matrix(voting_model, X_test, y_test)\nplt.show()\n\nprint()\n\nprint(\"On Train Data\")\npredictions = voting_model.predict(X_train)\nprint(f\"Accuracy: {accuracy_score(y_train, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_train, predictions)}\")\nprint(f\"Precision: {precision_score(y_train, predictions)}\")\nprint(f\"Recall: {recall_score(y_train, predictions)}\")\nplot_confusion_matrix(voting_model, X_train, y_train)\nplt.show()","bfd170fc":"voting_model = VotingClassifier(\n    [\n        (\"rf_model\", RandomForestClassifier(bootstrap=False, max_depth=80, min_samples_leaf=2,\n                       min_samples_split=5, n_estimators=600, random_state=24)),\n        (\"xgb_model\", XGBClassifier(eval_metric=\"logloss\",random_state = 18)),\n        (\"ada_model\", AdaBoostClassifier())\n    ]\n)\n\nvoting_model.fit(X_train, y_train)\n\nprint(\"On Test Data\")\npredictions = voting_model.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_test, predictions)}\")\nprint(f\"Precision: {precision_score(y_test, predictions)}\")\nprint(f\"Recall: {recall_score(y_test, predictions)}\")\nplot_confusion_matrix(voting_model, X_test, y_test)\nplt.show()\n\nprint()\n\nprint(\"On Train Data\")\npredictions = voting_model.predict(X_train)\nprint(f\"Accuracy: {accuracy_score(y_train, predictions)}\")\nprint(f\"F1 Score: {f1_score(y_train, predictions)}\")\nprint(f\"Precision: {precision_score(y_train, predictions)}\")\nprint(f\"Recall: {recall_score(y_train, predictions)}\")\nplot_confusion_matrix(voting_model, X_train, y_train)\nplt.show()","7c30c106":"test_data.head()","a6b89b7b":"final_voting_model = VotingClassifier(\n    [\n        (\"rf_model\", RandomForestClassifier(bootstrap=False, max_depth=80, min_samples_leaf=2,\n                       min_samples_split=5, n_estimators=600, random_state=24)),\n        (\"xgb_model\", XGBClassifier(eval_metric=\"logloss\", random_state = 18)),\n        (\"svm_model\", SVC(C=1000, gamma=0.01))\n    ]\n)\n\nfinal_voting_model.fit(X, y)","22ccae57":"test_X = test_data.iloc[:, 1:]\ntest_X = scaler.transform(test_X)\ntest_predictions = final_voting_model.predict(test_X)","a5e94229":"submission = pd.DataFrame({\n    \"PassengerId\":test_data[\"PassengerId\"].values,\n    \"Survived\":test_predictions\n})\nsubmission.head()","2a102dd7":"## Hyperparameter Tuning for SVM Model","d03cfb2f":"## Exploring the Data","2685d035":"## Univariate Analysis","8273f75e":"## Voting Classifier (RandomForest + XGBoost + SVM)","792eee24":"## Checking for best Baseline Model","b1fde78e":"## XGBoost Model","b3d8aa9a":"## Adaboost Model","536b7f6d":"We can see that is no duplicacy present in the data. Let us drop the PassengerId, Name, Ticket from the data.","708bb53f":"## Cleaning the Test Data","c5e397f4":"## SVM Model","30de0c90":"Here we an see that the survivors mostly belonged to class 1 which is obvious. The 1st class people were given more priority than the 2nd and 3rd class people.","160e8d38":"## Bivariate Analysis","821f656e":"## Hyperparameter Tuning for Random Forest Model","780771dc":"## RandomForest Model","aa75c508":"Using mean imputation let us fill the missing values in the age feature.","01e61331":"## Voting Classifier (RandomForest + XGBoost + AdaBoost)","3729c184":"Here we an see that the survivors were mostly feamle which is obvious. Let us change the encoding for the Sex feature. Let us replace it with the values generated using Target Guided Encoding."}}