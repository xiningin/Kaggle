{"cell_type":{"9c5ff7cc":"code","cc52130f":"code","5f04af83":"code","275e48e4":"code","b7be28a6":"code","2740de97":"code","6bdf4020":"code","dc9b766b":"code","5b35659d":"code","fa92b718":"code","0f276272":"code","bbdffc3c":"code","ea1e24ed":"code","1c6e6f6f":"code","ce092977":"code","edbd43c1":"markdown","69d844f7":"markdown"},"source":{"9c5ff7cc":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\nfrom keras.models import Sequential,load_model\nimport keras","cc52130f":"train_images = pd.read_csv(\"..\/input\/emnist\/emnist-balanced-train.csv\",header=None)\ntest_images = pd.read_csv(\"..\/input\/emnist\/emnist-balanced-test.csv\",header=None)\nmap_images = pd.read_csv(\"..\/input\/emnist\/emnist-balanced-mapping.txt\",header=None) \n#The 1st row would be treated as header if not set header to none.","5f04af83":"train_images","275e48e4":"plt.imshow(np.rot90(np.fliplr(train_images.iloc[1,1:].values.reshape(28,28)))) ## We'll learn about this later\nprint(chr(97)) # 36 in labels column maps to 36 --> 97 in map_images ","b7be28a6":"# Seperating labels from features in training and test data.\ntrain_x = train_images.iloc[:,1:]  \ntrain_y = train_images.iloc[:,0]  \ntrain_x = train_x.values\n\ntest_x = test_images.iloc[:,1:]\ntest_y = test_images.iloc[:,0]\ntest_x = test_x.values\n\n# ascii_map just for the convenince, i've removed the first column in map_images.\nascii_map = []\nfor i in map_images.values:\n    ascii_map.append(i[0].split()[1])\n\n# Uncomment the below line to know about the labels present in our dataset\n# for i in ascii_map: \n#     print(chr(int(i)))\nplt.imshow(np.rot90(np.fliplr(train_x[1].reshape(28,28))))","2740de97":"# The images in train_images are not in a proper orientation,hence to make them appropriate for training & testing data.\n\ndef rot_flip(image):\n    image = image.reshape([28, 28])\n    image = np.fliplr(image)\n    image = np.rot90(image)\n    return image","6bdf4020":"train_x = np.apply_along_axis(rot_flip,1,train_x)\ntest_x = np.apply_along_axis(rot_flip,1,test_x)\nplt.imshow(train_x[2])\ntrain_x.shape","dc9b766b":"train_x = train_x.astype('float32')\ntrain_x = train_x\/255.0\n\ntest_x = test_x.astype('float32')\ntest_x = test_x\/255.0\n\ntrain_x = train_x.reshape(-1, 28,28, 1)   #Equivalent to (112800,28,28,1)\ntest_x = test_x.reshape(-1, 28,28, 1)   #Equivalent to (18800,28,28,1)","5b35659d":"model = Sequential()\nmodel.add(Conv2D(32,(3,3),input_shape = (28,28,1),activation = 'relu'))\nmodel.add(Conv2D(64,(3,3),activation = 'relu'))\nmodel.add(MaxPool2D(2,2))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(47,activation='softmax'))","fa92b718":"model.compile(optimizer = 'adam',loss= \"sparse_categorical_crossentropy\", metrics=['accuracy'])\nmodel.summary()","0f276272":"history = model.fit(\n    train_x,\n    train_y,\n    validation_data = (test_x,test_y),\n    epochs = 20,\n)","bbdffc3c":"ascii_map = []\nfor i in map_images.values:\n    ascii_map.append(i[0].split()[1])\n\n\n# Adding character to associated ASCII Value\ncharacter = []\nfor i in ascii_map:\n    character.append(chr(int(i)))\n# plt.imshow(np.rot90(np.fliplr(train_x[1].reshape(28,28))))\ncharacter = pd.DataFrame(character)","ea1e24ed":"ascii_map = pd.DataFrame(ascii_map)\nascii_map[\"Character\"] = character\nascii_map.to_csv(\"mapping.csv\",index=False,header=True)","1c6e6f6f":"from keras.preprocessing import image\nimport cv2\n\nimg_sh_lst = []\nimg = image.load_img(\"..\/input\/alphabet-prediction-set\/downloada.png\",target_size=(28,28))\nx = image.img_to_array(img)\nprint(x.shape)\nx = x\/255.0\n\ngray_image = cv2.cvtColor(x, cv2.COLOR_BGR2GRAY)\ngray_image = np.expand_dims(gray_image, axis=-1)\nplt.imshow(gray_image)\ngray_image = np.expand_dims(gray_image, axis=0)\ncl = model.predict(gray_image)\ncl = list(cl[0])\n\nprint(\"Prediction : \",ascii_map[\"Character\"][cl.index(max(cl))])\n","ce092977":"print(tf.__version__)","edbd43c1":"## **Data Preprocessing**","69d844f7":"## EMNIST-Balanced(Extended MNIST) Dataset CSV Structure :\n* Each row represents a single image of shape -> (1,784) There are a total of 784 columns.\n* The first column contains the labels for each image \n* **Example** : The 0th row in the above dataframe represents and image the pixel for this image starts from 1st column and the point (1,0) i.e 36 is the label for this image in the 0th column.\n* In the map_images.txt file 36 maps to 97 which is ASCII Value for \"a\".\n* 47 Labels in map_images represent digits(0->9),alphabets(A-Z & a,b,d,..t)."}}