{"cell_type":{"d0609941":"code","abda7ef8":"code","5a47e3b2":"code","f0d16657":"code","01a93f06":"code","3017edf1":"code","a6bec6dc":"code","8585c419":"code","9f4ccd89":"code","cd1dcfe6":"code","222f9712":"code","0603fd35":"code","7e4c4410":"code","218828f7":"code","58ceea0c":"code","2cb78c69":"code","67c66c23":"code","dd004e15":"code","09e68e40":"code","d61f5bd7":"code","9b942567":"code","fab452f9":"code","039e19b2":"code","b1dd39d2":"code","a70cdc8e":"code","d07b483e":"code","075630e5":"code","13fafbbd":"code","b83b4705":"code","72a1a71c":"code","34782e01":"code","f49190f7":"code","e4158121":"markdown","071bf5b8":"markdown","bca75ff1":"markdown","36300d7e":"markdown","7ef18591":"markdown","b935e919":"markdown","fdab3ad9":"markdown","aaafc9bc":"markdown","a3b50438":"markdown","13f16eb2":"markdown","ca403fed":"markdown"},"source":{"d0609941":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","abda7ef8":"data = pd.read_csv(r\"..\/input\/twitter-user-gender-classification\/gender-classifier-DFE-791531.csv\",encoding='latin-1')","5a47e3b2":"data.head()","f0d16657":"data.info()","01a93f06":"data = pd.concat([data.gender,data.description],axis=1)","3017edf1":"data.head()","a6bec6dc":"data.dropna(axis = 0, inplace = True)","8585c419":"data.gender = [1 if each == \"female\" else 0 for each in data.gender]","9f4ccd89":"data.gender.unique()","cd1dcfe6":"import re","222f9712":"first_description = data.description[4]\nfirst_description","0603fd35":"description = re.sub(\"[^a-zA-Z]\",\" \",first_description) # Don't choose a to z and A to Z, another ones replace with space","7e4c4410":"description","218828f7":"description = description.lower()\ndescription","58ceea0c":"import nltk # natural language tool kit\nnltk.download(\"stopwords\") # downloading into corpus file\nfrom nltk.corpus import stopwords # importing from corpus file","2cb78c69":"# description = description.split()\n# tokenizer from nltk can be used instead of split\n# but if we use split, words like \"shouldn't\" don't seperate like \"should\" and \"not\"\ndescription = nltk.word_tokenize(description)","67c66c23":"print(description)","dd004e15":"description = [ word for word in description if not word in set(stopwords.words(\"english\"))]","09e68e40":"print(description)","d61f5bd7":"import nltk as nlp","9b942567":"lemma = nlp.WordNetLemmatizer()\ndescription = [ lemma.lemmatize(word) for word in description ]","fab452f9":"print(description)","039e19b2":"description = \" \".join(description)\nprint(description)","b1dd39d2":"description_list = []\nfor description in data.description:\n    description = re.sub(\"[^a-zA-Z]\",\" \",description)\n    description = description.lower()\n    description = nltk.word_tokenize(description)\n    description = [ word for word in description if not word in set(stopwords.words(\"english\"))]\n    lemma = nlp.WordNetLemmatizer()\n    description = [ lemma.lemmatize(word) for word in description ]\n    description = \" \".join(description)\n    description_list.append(description)","a70cdc8e":"from sklearn.feature_extraction.text import CountVectorizer\nmax_features = 500","d07b483e":"count_vectorizer = CountVectorizer(max_features=max_features,stop_words=\"english\",)","075630e5":"sparce_matrix = count_vectorizer.fit_transform(description_list).toarray()","13fafbbd":"print(\"Most common {} words : {}\".format(max_features,count_vectorizer.get_feature_names()))","b83b4705":"y = data.iloc[:,0].values # male ofr female classes\nx = sparce_matrix","72a1a71c":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.1, random_state = 42)","34782e01":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(x_train,y_train)","f49190f7":"y_pred = nb.predict(x_test)\n\nprint(\"accuracy: \",nb.score(y_pred.reshape(-1,1),y_test))\n","e4158121":"<a id=\"4\"><\/a> <br>\n## Lemmatization\n* Finding root of words\n* EX:\n    * love -> loved","071bf5b8":"<a id=\"9\"><\/a> <br>\n## Naive Bayes","bca75ff1":"<a id=\"6\"><\/a> <br>\n# Bag of words","36300d7e":"<a id=\"5\"><\/a> <br>\n## Data Cleaning","7ef18591":"<a id=\"1\"><\/a> <br>\n# Loading Data","b935e919":"<a id=\"10\"><\/a> <br>\n## Prediction","fdab3ad9":"<a id=\"7\"><\/a> <br>\n# Text Classification","aaafc9bc":"# Introduction\n\n1. [Loading Data](#1)\n1. [Preprocessing Data](#2)\n    * [Stopwords](#3)\n    * [Lemmatization](#4)\n    * [Data Cleaning](#5)\n1. [Bag of words](#6)\n1. [Text Classification](#7)\n    * [Train Test Split](#8)\n    * [Naive Bayes](#9)\n    * [Data Prediction](#10)","a3b50438":"<a id=\"8\"><\/a> <br>\n## Train Test Split","13f16eb2":"<a id=\"2\"><\/a> <br>\n# Preprocessing Data\n* Regular Expression : RE","ca403fed":"<a id=\"3\"><\/a> <br>\n## Stopwords\n* Irrelavent words for exapmle : the, and.."}}