{"cell_type":{"fe68602a":"code","33c8a569":"code","91afca9c":"code","c9c2a241":"code","b0976e57":"code","724125b0":"code","3e11067b":"code","452d86d5":"code","a0dfa4dc":"code","8a1915dd":"code","7bd61bec":"code","f4631657":"code","b61c502f":"code","bf70ae2a":"code","66739510":"code","7e653f98":"code","8ac7da53":"code","7f6ef71d":"code","cfdef8f8":"code","2916d7b8":"code","33ec4836":"code","8177b1cb":"code","60518bf6":"code","6a9641c6":"code","855df0b1":"code","42ffcc9c":"code","712f25a6":"code","ddfc00ea":"code","8cdc5706":"code","c942ec71":"code","7245c900":"code","b77a85ef":"code","f6a9cca1":"code","6246c3df":"code","cf7dc77c":"code","9f82906a":"code","0a79419c":"code","3c05b3b5":"code","5641cb74":"code","6cd5207f":"code","7fa04791":"code","a78a3cdc":"markdown","2513e6c0":"markdown","54634ffb":"markdown","0882cd74":"markdown","26480af5":"markdown","23bb4b63":"markdown","860a9a2c":"markdown","a0893a83":"markdown","ceda72f0":"markdown","73d82188":"markdown","da645a9f":"markdown","3910eb30":"markdown","c7420eb9":"markdown","72572e5b":"markdown","fa4a0e77":"markdown","a2bef188":"markdown","fa7eeceb":"markdown","2f56ffee":"markdown","27f14e32":"markdown","d19f2f91":"markdown","ee304086":"markdown","31f94812":"markdown","e8b7c420":"markdown","f15eac54":"markdown","6455cbff":"markdown","1fb3c9b2":"markdown","333e8578":"markdown","f96d12c7":"markdown","60da5b91":"markdown","6b528d6d":"markdown","a24d4204":"markdown","bc321c52":"markdown","6f68af11":"markdown","5d3dbf53":"markdown","663f3744":"markdown","a8a328d5":"markdown","3d23de95":"markdown","2e6e44f5":"markdown","2a368746":"markdown","366b7f95":"markdown","9c4d841c":"markdown","9f78ff16":"markdown","8d5e34d2":"markdown","9f292212":"markdown","ef42eb2a":"markdown","0eeed12d":"markdown","56431e3a":"markdown"},"source":{"fe68602a":"# Libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\nimport os\nimport json\nimport random\nimport glob\nimport seaborn as sns\nfrom pathlib import Path\nfrom PIL import Image, ImageOps\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nimport psutil\nimport random\nimport os\nimport time\nimport sys\nimport math\nfrom contextlib import contextmanager","33c8a569":"dataset_path = Path('..\/input\/indoor-location-navigation')\nos.listdir(dataset_path)","91afca9c":"train_sites = os.listdir(dataset_path\/\"train\")\nprint(f'There are {len(train_sites)} sites in the training set')","c9c2a241":"example_site = os.listdir(dataset_path\/\"train\")[10]\nexample_site_path = dataset_path\/\"train\"\/example_site\nprint('Floors for example site:')\nprint(os.listdir(example_site_path))","b0976e57":"floors_per_site = []\nfor i in os.listdir(dataset_path\/\"train\"): floors_per_site.append(len(os.listdir(dataset_path\/\"train\"\/i)))\nprint(f'There are a total of {sum(floors_per_site)} floors. On average, each site has {np.mean(floors_per_site)} floors')","724125b0":"print('Path text files for example floor:')\nprint(os.listdir(example_site_path\/'B1'))","3e11067b":"print(f\"There are {len(list((dataset_path\/'train').rglob('*.txt')))} path text files in the training set\")","452d86d5":"print(f\"There are {len(os.listdir(dataset_path\/'test'))} path text files in the test set\")","a0dfa4dc":"print(f'There are {len(os.listdir(dataset_path\/\"metadata\"))} sites in the metadata, just like the training set')","8a1915dd":"metadata_example_site = os.listdir(dataset_path\/\"metadata\")[10]\nmetadata_example_site_path = dataset_path\/\"metadata\"\/metadata_example_site\nmetadata_example_floor_path = dataset_path\/\"metadata\"\/metadata_example_site\/os.listdir(metadata_example_site_path)[0]\nprint(os.listdir(metadata_example_floor_path))","7bd61bec":"Image.open(metadata_example_floor_path\/'floor_image.png')","f4631657":"##################### In comment because Large Output Data ########################\n\n\n# with open(metadata_example_floor_path\/'geojson_map.json') as geojson_map:\n#     data = json.load(geojson_map)\n#     geojson_map.close()\n# print(data)","b61c502f":"with open(metadata_example_floor_path\/'floor_info.json') as floor_info:\n    data = json.load(floor_info)\n    floor_info.close()\nprint(data)","bf70ae2a":"example_floor_path = example_site_path\/'B1'\nexample_txt_path = example_floor_path\/os.listdir(example_floor_path)[0]\nwith open(example_txt_path) as example_txt:\n    data = example_txt.read()\n    example_txt.close()\n\n##################### In comment because Large Output Data ########################\n# print(data)","66739510":"def load_trace_as_dataframe(filepath):\n    # Returns trace dataframe sorted by timestamp\n    \n    names = ['time', 'type'] + [f'col_{i}' for i in range(1, 9)]\n    \n    trace_df = pd.read_csv(\n        filepath, sep='\\t', comment='#', header=None, names=names\n    )\n    \n    trace_df.sort_values(by='time', inplace=True)\n    trace_df.reset_index(drop=True, inplace=True)\n    return trace_df","7e653f98":"def extract_feature_df(trace_df, \n                       feature_name, \n                       col_names=('x', 'y', 'z', 'accuracy')):\n    \n    \n#     Extracts feature dataframe from trace dataframe by feature name.\n    \n#     Suitable for features: \n#     ----------------------\n#         TYPE_WAYPOINT, if set col_names=('x', 'y'),\n#         TYPE_ACCELEROMETER,\n#         TYPE_GYROSCOPE,\n#         TYPE_MAGNETIC_FIELD, \n#         TYPE_ROTATION_VECTOR,\n        \n#         TYPE_ACCELEROMETER_UNCALIBRATED, \n#                     if set col_names=('x', 'y', 'z', 'x_2', 'y_2', 'z_2', 'accuracy'),\n                    \n#         TYPE_GYROSCOPE_UNCALIBRATED, \n#                     if set col_names=('x', 'y', 'z', 'x_2', 'y_2', 'z_2', 'accuracy'),\n                    \n#         TYPE_MAGNETIC_FIELD_UNCALIBRATED, \n#                     if set col_names=('x', 'y', 'z', 'x_2', 'y_2', 'z_2', 'accuracy')\n    \n    \n    feature_df = trace_df[trace_df['type'] == feature_name].copy()\n    for i, col in enumerate(col_names, start=1):\n        feature_df[col] = feature_df[f'col_{i}'].astype('float64')\n        \n    feature_df.drop(columns=[f'col_{i}' for i in range(1, 9)], inplace=True)\n    feature_df.drop(columns=['type'], inplace=True)\n    feature_df.reset_index(drop=True, inplace=True)\n    \n    return feature_df","8ac7da53":"def load_points(filepath):\n    # Takes the path to the trace file.\n    # Returns pandas dataframe which consists of device locations \n    # as x and y coordinates (values from TYPE_WAYPOINT) and their timestamps.\n    \n    trace_df = load_trace_as_dataframe(filepath)\n    points_df = extract_feature_df(\n        trace_df, 'TYPE_WAYPOINT', col_names=('x', 'y')\n    )\n    \n    return points_df","7f6ef71d":"def visualize_many_traces_on_the_map(traces_dataframes, map_image, width, height, \n                                     traces_filenames=None, \n                                     figsize=None):\n    \n\n#     Draws traces on the floor map.\n    \n#     Parameters\n#     ----------\n#         traces_dataframes: list of pandas DataFrames\n#             Each DataFrame should consist of device locations as x and y \n#             coordinates and their timestamps.\n\n#         map_image : numpy.array\n#             Image of floor map.\n\n#         width : float,\n#             Width of floor. Should be taken from floor_info.json\n\n#         height : float, \n#             Height of floor. Should be taken from floor_info.json\n\n#         traces_filenames : list of strings, optional, default: None\n#             List of filenames. Used to display the legend. \n#             There will be no legend if you pass traces_filenames=None\n\n#         figsize : (float, float), optional, default: None\n#             Size of the result image in terms of matplotlib.\n    \n\n    \n    fig = plt.figure(figsize=figsize)\n    ax = plt.subplot(111)\n\n    plt.imshow(map_image, extent=[0, width, 0, height])\n\n    if traces_filenames:\n        \n        for filename, points in zip(traces_filenames, traces_dataframes):\n            plt.scatter(points['x'], points['y'], label=filename)\n            plt.plot(points['x'], points['y'])\n            \n        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n    else:\n        for points in traces_dataframes:\n            plt.scatter(points['x'], points['y'])\n            plt.plot(points['x'], points['y'])\n\n\n    plt.show()","cfdef8f8":"def visualize_single_trace_on_the_map(points_df, map_image, width, height, \n                                      scaling_coef=0.3, figsize=None):\n    \n    \n#     Draws single trace on the floor map.\n    \n#     Parameters\n#     ----------\n#         points_df: pandas DataFrame\n#             Should consist of device locations as x and y \n#             coordinates and their timestamps.\n\n#         map_image : numpy.array\n#             Image of floor map.\n\n#         width : float,\n#             Width of floor. Should be taken from floor_info.json\n\n#         height : float, \n#             Height of floor. Should be taken from floor_info.json\n\n#         scaling_coef : float\n#             Scaling Coefficient. \n\n#         figsize : (float, float), optional, default: None\n#             Size of the result image in terms of matplotlib.\n    \n    \n    \n    fig = plt.figure(figsize=figsize)\n    ax = plt.subplot(111)\n\n    plt.imshow(map_image, extent=[0, width, 0, height])\n    plt.plot(points_df['x'], points_df['y'], linewidth=5, linestyle='-', color='blue')\n\n    for i in range(len(points_df)):\n        ax.text(\n            points_df.loc[i, 'x'], points_df.loc[i, 'y'], i, \n            ha=\"center\", size=15, \n            bbox=dict(boxstyle=\"circle, pad=0.3\", \n                      fc=\"cyan\", lw=2)\n        )\n \n    x_min, x_max = points_df['x'].min(), points_df['x'].max()\n    y_min, y_max = points_df['y'].min(), points_df['y'].max()\n\n    ax.set_xlim(x_min - scaling_coef*(x_max - x_min), x_max + scaling_coef*(x_max - x_min))\n    ax.set_ylim(y_min - scaling_coef*(y_max - y_min), y_max + scaling_coef*(y_max - y_min))\n\n    plt.show()\n","2916d7b8":"def plot_trace_features(feature_df, timestamps=None, figsize=None):\n    \n\n#     Plots the trace features.\n    \n#     Parameters\n#     ----------\n#         feature_df : pandas DataFrame\n#             Can be exctracted from trace dataframe \n#             using extract_feature_df function.\n        \n#         timestamps : array-like, optional, default: None\n#             Array of timestamps. \n#             Used to mark timestamps on the chart in the form of vertical lines.\n#             Pass timestamps=None if you don't want to use this feature.\n\n#         figsize : (float, float), optional, default: None\n#             Size of the result image in terms of matplotlib.\n    \n#     Suitable for features: \n#     ----------------------\n#         TYPE_ACCELEROMETER \n#         TYPE_GYROSCOPE \n#         TYPE_MAGNETIC_FIELD \n#         TYPE_ROTATION_VECTOR \n#         TYPE_ACCELEROMETER_UNCALIBRATED \n#         TYPE_GYROSCOPE_UNCALIBRATED \n#         TYPE_MAGNETIC_FIELD_UNCALIBRATED\n   \n    \n    fig = plt.figure(figsize=figsize)\n    ax = plt.subplot(111)\n\n    for col in ['x', 'y', 'z']:\n        plt.plot(feature_df['time'], feature_df[col], label=col)\n\n\n    if points_df is not None:\n        xmin, xmax, ymin, ymax = plt.axis()\n\n        for i, timestamp in enumerate(timestamps):\n            plt.axvline(x=timestamp, c='k', ls='--')\n\n            ax.text(\n            timestamp, ymax, i, \n            ha=\"center\", size=15, \n            bbox=dict(boxstyle=\"circle, pad=0.3\", \n                      fc=\"white\", lw=2)\n            )\n    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n    plt.show()","33ec4836":"data_path = '\/kaggle\/input\/indoor-location-navigation'\nfloor = '5a0546857ecc773753327266\/F1'\nfloor_metadata_dir = os.path.join(data_path, 'metadata', floor)\nfloor_train_dir = os.path.join(data_path, 'train', floor)","8177b1cb":"paths = []\nfor filename in os.listdir(floor_train_dir):\n    if '.txt' not in filename:\n        continue\n    points = load_points(os.path.join(floor_train_dir, filename))\n    paths.append((filename, points))\n\npaths = sorted(paths, key=lambda path: len(path[1]), reverse=True)\npaths = paths[:20]\n\n\ntraces_dataframes = [trace for filename, trace in paths]\ntraces_filenames = [filename for filename, trace in paths]","60518bf6":"MAP_IMAGE = plt.imread(\n    os.path.join(floor_metadata_dir, 'floor_image.png')\n)\n\nwith open(os.path.join(floor_metadata_dir, 'floor_info.json')) as f:\n    content = f.read()\n    floor_info = json.loads(content)\n\nMAP_HEIGHT = float(floor_info['map_info']['height'])\nMAP_WIDTH = float(floor_info['map_info']['width'])\n    \nfloor_info","6a9641c6":"visualize_many_traces_on_the_map(\n    traces_dataframes, MAP_IMAGE, MAP_WIDTH, MAP_HEIGHT, \n    traces_filenames=traces_filenames, \n    figsize=(15, 12)\n)","855df0b1":"filename='5e15b0171506f2000638fe49.txt'\ntrace_filepath = os.path.join(floor_train_dir, filename)\n\ntrace_df = load_trace_as_dataframe(trace_filepath)\ntrace_df","42ffcc9c":"points_df = extract_feature_df(trace_df, 'TYPE_WAYPOINT', col_names=('x', 'y'))\npoints_df.head()","712f25a6":"visualize_single_trace_on_the_map(\n    points_df, MAP_IMAGE, MAP_WIDTH, MAP_HEIGHT, figsize=(10, 8)\n)","ddfc00ea":"acc_df = extract_feature_df(trace_df, 'TYPE_ACCELEROMETER')\nacc_df.head()","8cdc5706":"sns.pairplot(acc_df[['x', 'y', 'z']])\nplt.show()","c942ec71":"gyro_df = extract_feature_df(trace_df, 'TYPE_GYROSCOPE')\ngyro_df.head()","7245c900":"magn_df = extract_feature_df(trace_df, 'TYPE_MAGNETIC_FIELD')\nmagn_df.head()","b77a85ef":"rot_df = extract_feature_df(trace_df, 'TYPE_ROTATION_VECTOR')\nrot_df.head()","f6a9cca1":"sns.pairplot(rot_df[['x', 'y', 'z']])\nplt.show()","6246c3df":"import numpy as np\nimport pandas as pd\nimport scipy.stats as stats\nfrom pathlib import Path\nimport glob\n\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\n\nimport psutil\nimport random\nimport os\nimport time\nimport sys\nimport math\nfrom contextlib import contextmanager","cf7dc77c":"N_SPLITS = 20\nSEED = 1234","9f82906a":"LOG_PATH = Path(\".\/log\/\")\nLOG_PATH.mkdir(parents=True, exist_ok=True)","0a79419c":"@contextmanager\ndef timer(name: str):\n    t0 = time.time()\n    p = psutil.Process(os.getpid())\n    m0 = p.memory_info()[0] \/ 2. ** 30\n    try:\n        yield\n    finally:\n        m1 = p.memory_info()[0] \/ 2. ** 30\n        delta = m1 - m0\n        sign = '+' if delta >= 0 else '-'\n        delta = math.fabs(delta)\n        print(f\"[{m1:.1f}GB({sign}{delta:.1f}GB): {time.time() - t0:.3f}sec] {name}\", file=sys.stderr)\n\n\ndef set_seed(seed=1234):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n\n    \ndef comp_metric(xhat, yhat, fhat, x, y, f):\n    intermediate = np.sqrt(np.power(xhat-x, 2) + np.power(yhat-y, 2)) + 15 * np.abs(fhat-f)\n    return intermediate.sum()\/xhat.shape[0]\n\n\ndef score_log(df: pd.DataFrame, num_files: int, nam_file: str, data_shape: tuple, n_fold: int, seed: int, mpe: float):\n    score_dict = {'n_files': num_files, 'file_name': nam_file, 'shape': data_shape, 'fold': n_fold, 'seed': seed, 'score': mpe}\n    # noinspection PyTypeChecker\n    df = pd.concat([df, pd.DataFrame.from_dict([score_dict])])\n    df.to_csv(LOG_PATH \/ f\"log_score.csv\", index=False)\n    return df\n","3c05b3b5":"set_seed(SEED)\nfeature_dir = \"..\/input\/indoor-navigation-and-location-wifi-features\"\ntrain_files = sorted(glob.glob(os.path.join(feature_dir, '*_train.csv')))\ntest_files = sorted(glob.glob(os.path.join(feature_dir, '*_test.csv')))\nsubm = pd.read_csv('..\/input\/indoor-location-navigation\/sample_submission.csv', index_col=0)","5641cb74":"lgb_params = {'objective': 'root_mean_squared_error',\n              'boosting_type': 'gbdt',\n              'n_estimators': 50000,\n              'learning_rate': 0.1,\n              'num_leaves': 90,\n              'colsample_bytree': 0.4,\n              'subsample': 0.6,\n              'subsample_freq': 2,\n              'bagging_seed': SEED,\n              'reg_alpha': 8,\n              'reg_lambda': 2,\n              'random_state': SEED,\n              'n_jobs': -1\n              }\n\nlgb_f_params = {'objective': 'multiclass',\n                'boosting_type': 'gbdt',\n                'n_estimators': 50000,\n                'learning_rate': 0.1,\n                'num_leaves': 90,\n                'colsample_bytree': 0.4,\n                'subsample': 0.6,\n                'subsample_freq': 2,\n                'bagging_seed': SEED,\n                'reg_alpha': 10,\n                'reg_lambda': 2,\n                'random_state': SEED,\n                'n_jobs': -1\n                }","6cd5207f":"# score_df = pd.DataFrame()\n# oof = list()\n# predictions = list()\n# for n_files, file in enumerate(train_files):\n#     data = pd.read_csv(file, index_col=0)\n#     test_data = pd.read_csv(test_files[n_files], index_col=0)\n\n#     oof_x, oof_y, oof_f = np.zeros(data.shape[0]), np.zeros(data.shape[0]), np.zeros(data.shape[0])\n#     preds_x, preds_y = 0, 0\n#     preds_f_arr = np.zeros((test_data.shape[0], N_SPLITS))\n\n#     kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n#     for fold, (trn_idx, val_idx) in enumerate(kf.split(data.iloc[:, :-4])):\n#         X_train = data.iloc[trn_idx, :-4]\n#         y_trainx = data.iloc[trn_idx, -4]\n#         y_trainy = data.iloc[trn_idx, -3]\n#         y_trainf = data.iloc[trn_idx, -2]\n\n#         X_valid = data.iloc[val_idx, :-4]\n#         y_validx = data.iloc[val_idx, -4]\n#         y_validy = data.iloc[val_idx, -3]\n#         y_validf = data.iloc[val_idx, -2]\n\n#         modelx = lgb.LGBMRegressor(**lgb_params)\n#         with timer(\"fit X\"):\n#             modelx.fit(X_train, y_trainx,\n#                        eval_set=[(X_valid, y_validx)],\n#                        eval_metric='rmse',\n#                        verbose=True,\n#                        early_stopping_rounds=5\n#                        )\n\n#         modely = lgb.LGBMRegressor(**lgb_params)\n#         with timer(\"fit Y\"):\n#             modely.fit(X_train, y_trainy,\n#                        eval_set=[(X_valid, y_validy)],\n#                        eval_metric='rmse',\n#                        verbose=True,\n#                        early_stopping_rounds=5\n#                        )\n#         modelf = lgb.LGBMClassifier(**lgb_f_params)\n#         with timer(\"fit F\"):\n#             modelf.fit(X_train, y_trainf,\n#                        eval_set=[(X_valid, y_validf)],\n#                        eval_metric='multi_logloss',\n#                        verbose=True,\n#                        early_stopping_rounds=5\n#                        )\n\n#         oof_x[val_idx] = modelx.predict(X_valid)\n#         oof_y[val_idx] = modely.predict(X_valid)\n#         oof_f[val_idx] = modelf.predict(X_valid).astype(int)\n\n#         preds_x += modelx.predict(test_data.iloc[:, :-1]) \/ N_SPLITS\n#         preds_y += modely.predict(test_data.iloc[:, :-1]) \/ N_SPLITS\n#         preds_f_arr[:, fold] = modelf.predict(test_data.iloc[:, :-1]).astype(int)\n\n#         score = comp_metric(oof_x[val_idx], oof_y[val_idx], oof_f[val_idx],\n#                             y_validx.to_numpy(), y_validy.to_numpy(), y_validf.to_numpy())\n#         print(f\"fold {fold}: mean position error {score}\")\n#         score_df = score_log(score_df, n_files, os.path.basename(file), data.shape, fold, SEED, score)\n\n#     print(\"*+\"*40)\n#     print(f\"file #{n_files}, shape={data.shape}, name={os.path.basename(file)}\")\n#     score = comp_metric(oof_x, oof_y, oof_f,\n#                         data.iloc[:, -4].to_numpy(), data.iloc[:, -3].to_numpy(), data.iloc[:, -2].to_numpy())\n#     oof.append(score)\n#     print(f\"mean position error {score}\")\n#     print(\"*+\"*40)\n#     score_df = score_log(score_df, n_files, os.path.basename(file), data.shape, 999, SEED, score)\n\n#     preds_f_mode = stats.mode(preds_f_arr, axis=1)\n#     preds_f = preds_f_mode[0].astype(int).reshape(-1)\n#     test_preds = pd.DataFrame(np.stack((preds_f, preds_x, preds_y))).T\n#     test_preds.columns = subm.columns\n#     test_preds.index = test_data[\"site_path_timestamp\"]\n#     test_preds[\"floor\"] = test_preds[\"floor\"].astype(int)\n#     predictions.append(test_preds)","7fa04791":"# all_preds = pd.concat(predictions)\n# all_preds = all_preds.reindex(subm.index)\n# all_preds.to_csv('submission.csv')\n# all_preds.head(20)","a78a3cdc":"<b>TYPE_WAYPOINT<\/b>","2513e6c0":"| Feature                           | Values |       |        |        |                   |        |           |                                   |\n|:----------------------------------|:------:|:-----:|:------:|:-------|:-----------------:|:------:|:---------:|:---------------------------------:|\n|TYPE_WAYPOINT                      |X axis  |Y axis |       |         |                   |        |           |                                   |\n|TYPE_ACCELEROMETER                 |X axis  |Y axis |Z axis |accuracy |                   |        |           |                                   |\n|TYPE_GYROSCOPE                     |X axis  |Y axis |Z axis |accuracy |                   |        |           |                                   | \n|TYPE_MAGNETIC_FIELD                |X axis  |Y axis |Z axis |accuracy |                   |        |           |                                   | \n|TYPE_ROTATION_VECTOR               |X axis  |Y axis |Z axis |accuracy |                   |        |           |                                   |\n|TYPE_ACCELEROMETER_UNCALIBRATED    |X axis  |Y axis |Z axis |X axis   |Y axis             |Z axis  |accuracy   |                                   |\n|TYPE_GYROSCOPE_UNCALIBRATED        |X axis  |Y axis |Z axis |X axis   |Y axis             |Z axis  |accuracy   |                                   |\n|TYPE_MAGNETIC_FIELD_UNCALIBRATED   |X axis  |Y axis |Z axis |X axis   |Y axis             |Z axis  |accuracy   |                                   |\n|TYPE_WIFI                          |ssid    |bssid  |RSSI   |frequency|last seen timestamp|        |           |                                   |\n|TYPE_BEACON                        |UUID    |MajorID|MinorID|Tx Power |RSSI               |Distance|MAC Address|same with Unix time, padding data  |\n\u200b","54634ffb":"<b>Let's look at a single floor of a single site<\/b>","0882cd74":"<b>TYPE_GYROSCOPE<\/b>","26480af5":"<b>Explore 'geojson_map.json' file<\/b>","23bb4b63":"<b>In this notebook I have tried my best to explain all the topics\/aspects, related to this competition, at easiest form. <\/b>","860a9a2c":"We are going to use the images in the .png format to display the locations. The other two files associated with each floor are in .json format. The floor_info.json describes the size of the location (height and width), while the geojson_map.json is a file for geospatial visualization (it is possible to reproduce a raster image in .png format using the *geopandas* library applied to this .json file).","a0893a83":"<h4>Test Dataset<\/h4>","ceda72f0":"<h4>Loading floor map and its size<\/h4>","73d82188":"\n<h3>Path text files<\/h3>\n<b>Brief here. Each Column is described in detail in session (Deep Dive) below<\/b>\n<p><\/p>\nLet's look more closely at the path text files and how to process them.\n\nThe [GitHub README](https:\/\/github.com\/location-competition\/indoor-location-competition-20) provides more information about the text file format:\n\n> The first column is Unix Time in millisecond. In specific, we use SensorEvent.timestamp for sensor data and system time for WiFi and Bluetooth scans.\n> \n>The second column is the data type (ten in total).\n>\n>TYPE_ACCELEROMETER\n>\n>TYPE_MAGNETIC_FIELD\n>\n>TYPE_GYROSCOPE\n>\n>TYPE_ROTATION_VECTOR\n>\n>TYPE_MAGNETIC_FIELD_UNCALIBRATED\n>TYPE_GYROSCOPE_UNCALIBRATED\n>\n>TYPE_ACCELEROMETER_UNCALIBRATED\n>\n>TYPE_WIFI\n>\n>TYPE_BEACON\n>\n>TYPE_WAYPOINT: ground truth location labeled by the surveyor\n>\n>Data values start from the third column.\n>\n>Column 3-5 of TYPE_ACCELEROMETER\u3001TYPE_ACCELEROMETER\u3001TYPE_GYROSCOPE\u3001TYPE_ROTATION_VECTOR are SensorEvent.values[0-2] from the callback function onSensorChanged(). Column 6 is SensorEvent.accuracy.\n>\n>Column 3-8 of TYPE_ACCELEROMETER_UNCALIBRATED\u3001TYPE_GYROSCOPE_UNCALIBRATED\u3001TYPE_MAGNETIC_FIELD_UNCALIBRATED are SensorEvent.values[0-5] from the callback function onSensorChanged(). Column 9 is SensorEvent.accuracy.","da645a9f":"<h2><center>Baseline Model 1<\/h2><\/center>\n<center><img src =\"https:\/\/lightgbm.readthedocs.io\/en\/latest\/_images\/LightGBM_logo_black_text.svg \" width = \"400\" height = \"400\"\/><\/center> ","3910eb30":"Some utility code\n\n1. A timer\n2. A seed setter\n3. A intermediate metric finder\n4. A score logger","c7420eb9":"Get file path from kaggle ","72572e5b":"Create some tuned paratmeters for the LGB ( These will be tweaked to get the best performance)","fa4a0e77":"Save the predictions into the same format as required ","a2bef188":"<b>So every site has about 5 floors. In each floor are the path trace text files with the data<\/b>","fa7eeceb":"<b>Note that the data is organized by the sites and floors. Let's see how many sites do we have in train dataset?<\/b>","2f56ffee":"Get all the data in our nb env","27f14e32":"<h4>Visualization of Traces (Paths) on the Floor Map<\/h4>","d19f2f91":"<b>TYPE_MAGNETIC_FIELD<\/b>","ee304086":"<h4>Loading coordinates of paths points<\/h4>","31f94812":"<h2><center>Data Exploration and Data Understanding (EDA)<\/h2><\/center>\n<center><img src =\"https:\/\/luminousmen.com\/media\/exploratory-data-analysis.jpg \" width = \"400\" height = \"400\"\/><\/center>   \n\n\n\n<b>In this section, I will drive you through all the important aspects of Data so that we can understand the Data which is the most important thing to ace the competition.<\/b>","e8b7c420":"\n\n```\n\u2514\u2500\u2500\u2500train                                                        \/\/raw data from two sites\n      \u2514\u2500\u2500\u2500site1\n      |     \u2514\u2500\u2500\u2500B1                                               \/\/traces from one floor\n      |     |   \u2514\u2500\u2500\u25005dda14a2c5b77e0006b17533.txt                 \/\/trace file                             \n      |     |   | ...\n      |     |\n      |     |\n      |     \u2514\u2500\u2500\u2500F1\n      |     | ...\n      |\n      \u2514\u2500\u2500\u2500site2\n```","f15eac54":"<h4>Features Visualization<\/h4>\nLet's take a closer look at single trace (path) and its attributes.","6455cbff":"<b>To summarize, this is how the training data is structured:<\/b>","1fb3c9b2":"<h2>Understand the Data<\/h2>\nFirst, we need to understand the input data. The folder \"indoor-location-navigation\" contains 3 subdirectories, \"metadata\", \"test\", and \"train\", respectively.\nThe following schematic shows the data structure in the \"metadata\" folder, as it is given in the \"Data Description\" tab.","333e8578":"<h2>Data Organization<\/h2>\n\n<h4>Training Dataset<\/h4>","f96d12c7":"<center><h2>Understand The Competition<\/center><\/h2>\nOur smartphone goes everywhere with us and with permission, apps can use our location to provide contextual information. We get driving directions, find a store, or receive alerts for nearby promotions. These handy features are enabled by GPS, which requires outdoor exposure for the best accuracy.\n\nCurrent positioning solutions have poor accuracy, particularly in multi-level buildings.\n\n<b>In this competition, our task is to predict the indoor position of smartphones based on real-time sensor data.<\/b>","60da5b91":"<b>TYPE_ROTATION_VECTOR<\/b>","6b528d6d":"Here is a table of the attributes we need to deal with in this competition. \n\nAs you can see it contains feature names and its params. We will describe some of these features in more detail below.\n\nEach feature can be extracted from trace as dataframe with params as columns. For this we are using function `extract_feature_df` which is suitable for all features except TYPE_WIFI and TYPE_BEACON.\n\nThe table is taken from [competition's official github repo](https:\/\/github.com\/location-competition\/indoor-location-competition-20).","a24d4204":"<h4>Train Data path files count<\/h4>","bc321c52":"<center><img src =\"http:\/\/static.dist10.cn\/Fh7Zz-ipJRPZRM9bE1p7Dsu7YLpJ\/section3_bg.png?imageView2\/5\/w\/1440\/h\/600 \" width = \"800\" height = \"800\"\/><\/center>   ","6f68af11":"<h4>Define some Functions\/Tools that we will use for EDA<\/h4>","5d3dbf53":"<h2><center>Deep Dive into EDA<\/h2>","663f3744":"<center><img src =\"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRSq7tFWVYNmxhjebh_havbaBkI5UmrewSEKw&usqp=CAU \" width = \"400\" height = \"400\"\/><\/center>  ","a8a328d5":"Splitting the data into train and validation and passed them through LGBm and then ssaving the predicitions into pred","3d23de95":"<h1><center>Indoor Location & Navigation<\/h1><\/center>\n<h2><center>Identify the position of a smartphone in a shopping mall<\/h2><\/center>","2e6e44f5":"<h3>Refrences<\/h3>\n\n\nhttps:\/\/www.kaggle.com\/harshsharma511\/indoor-location-navigation-eda\n\nhttps:\/\/www.kaggle.com\/harshsharma511\/basic-eda-traces-and-features-visualization\n\nhttps:\/\/www.kaggle.com\/harshsharma511\/lightgbm-regressor","2a368746":"<b>Explore 'floor_image.png' file<\/b>","366b7f95":"<b>Below is Light GBM code. Commented because very large output.<\/b>","9c4d841c":"<h4>Metdata Organization<\/h4>","9f78ff16":"![Kaggle Indoor Location.PNG](attachment:b5ac40a4-c8da-493d-ad9a-c1a3c0b5f920.PNG)","8d5e34d2":"<b>Explore 'floor_info.json' file<\/b>","9f292212":"<b>TYPE_ACCELEROMETER<\/b>","ef42eb2a":"<b>Path File<\/b>","0eeed12d":"<b>Now each site is organized by Floors<\/b>","56431e3a":"<b>Let's Explore Text File<\/b>"}}