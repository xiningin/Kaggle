{"cell_type":{"e8895242":"code","edf0f629":"code","822c17a8":"code","717cad73":"code","f78667d1":"code","d0afa19c":"code","d17b1f9d":"code","9a34d950":"code","ed3104ad":"code","0502ef0e":"code","c943a350":"code","60770d09":"code","eaabbeb3":"code","d1d2fa4e":"code","b1301ac7":"code","cb0449d0":"code","fe621431":"code","4f92aff5":"code","60d80d8a":"code","89711382":"markdown","e28c6106":"markdown","837800cc":"markdown","be3c11d7":"markdown","2719debb":"markdown","34ceaebe":"markdown","7d4b3873":"markdown","fbfee9b8":"markdown","840b42f4":"markdown"},"source":{"e8895242":"import os\nimport shutil\n\n# \u6570\u636e\u96c6\u89e3\u538b\u4e4b\u540e\u7684\u76ee\u5f55\noriginal_dataset_dir = '\/data\/nextcloud\/dbc2017\/files\/jupyter\/train'\n# \u5b58\u653e\u5c0f\u6570\u636e\u96c6\u7684\u76ee\u5f55\nbase_dir = '\/data\/nextcloud\/dbc2017\/files\/jupyter\/\/cats_and_dogs_small'\nos.mkdir(base_dir)","edf0f629":"# \u5efa\u7acb\u8bad\u7ec3\u96c6\u3001\u9a8c\u8bc1\u96c6\u3001\u6d4b\u8bd5\u96c6\u76ee\u5f55\ntrain_dir = os.path.join(base_dir, 'train')\nos.mkdir(train_dir)\nvalidation_dir = os.path.join(base_dir, 'validation')\nos.mkdir(validation_dir)\ntest_dir = os.path.join(base_dir, 'test')\nos.mkdir(test_dir)\n\n# \u5c06\u732b\u72d7\u7167\u7247\u6309\u7167\u8bad\u7ec3\u3001\u9a8c\u8bc1\u3001\u6d4b\u8bd5\u5206\u7c7b\ntrain_cats_dir = os.path.join(train_dir, 'cats')\nos.mkdir(train_cats_dir)\n\ntrain_dogs_dir = os.path.join(train_dir, 'dogs')\nos.mkdir(train_dogs_dir)\n\nvalidation_cats_dir = os.path.join(validation_dir, 'cats')\nos.mkdir(validation_cats_dir)\n\nvalidation_dogs_dir = os.path.join(validation_dir, 'dogs')\nos.mkdir(validation_dogs_dir)\n\ntest_cats_dir = os.path.join(test_dir, 'cats')\nos.mkdir(test_cats_dir)\n\ntest_dogs_dir = os.path.join(test_dir, 'dogs')\nos.mkdir(test_dogs_dir)","822c17a8":"# \u5207\u5272\u6570\u636e\u96c6\n# \u8bad\u7ec3\u96c6:\u9a8c\u8bc1\u96c6:\u6d4b\u8bd5\u96c6\n# 3:1:1\n# \u732b\u56fe\u7247\u8bad\u7ec3\u96c6\nfnames = ['cat.{}.jpg'.format(i) for i in range(3000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dat = os.path.join(train_cats_dir, fname)\n    shutil.copyfile(src, dat)\n# \u732b\u56fe\u7247\u9a8c\u8bc1\u96c6 \u9a8c\u8bc1\u96c6\u7528\u4e8e\u201c\u8bad\u7ec3\u201d\u6a21\u578b\u7684\u8d85\u53c2\u6570\nfnames = ['cat.{}.jpg'.format(i) for i in range(3000, 4000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dat = os.path.join(validation_cats_dir, fname)\n    shutil.copyfile(src, dat)\n# \u732b\u56fe\u7247\u6d4b\u8bd5\u96c6 \u6d4b\u8bd5\u96c6\u7528\u4e8e\u4f30\u8ba1\u6a21\u578b\u5bf9\u6837\u672c\u7684\u6cdb\u5316\u8bef\u5dee\nfnames = ['cat.{}.jpg'.format(i) for i in range(4000, 5000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dat = os.path.join(test_cats_dir, fname)\n    shutil.copyfile(src, dat)\n# \u72d7\u56fe\u7247\u8bad\u7ec3\u96c6\nfnames = ['dog.{}.jpg'.format(i) for i in range(3000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dat = os.path.join(train_dogs_dir, fname)\n    shutil.copyfile(src, dat)\n# \u72d7\u56fe\u7247\u9a8c\u8bc1\u96c6\nfnames = ['dog.{}.jpg'.format(i) for i in range(3000, 4000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dat = os.path.join(validation_dogs_dir, fname)\n    shutil.copyfile(src, dat)\n\nfnames = ['dog.{}.jpg'.format(i) for i in range(4000, 5000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dat = os.path.join(test_dogs_dir, fname)\n    shutil.copyfile(src, dat)","717cad73":"!nvidia-smi","f78667d1":"from keras import layers\nfrom keras import models\nimport matplotlib.pyplot as plt\nfrom keras import optimizers\nfrom keras.preprocessing.image import ImageDataGenerator\n\nbase_dir = '\/data\/nextcloud\/dbc2017\/files\/jupyter\/\/cats_and_dogs_small'\n\ntrain_dir = base_dir+'\/train'\nvalidation_dir = base_dir+'\/validation'","d0afa19c":"# \u7b80\u5355\u7248cnn\u7f51\u7edc\u6a21\u578b\nmodel = models.Sequential()\n#   CBAPD\n# 32\u4e2a\u5377\u79ef\u6838 \u5377\u79ef\u548c\u5c3a\u5bf8\u4e3a3\u00d73 \u6fc0\u6d3b\u51fd\u6570\u4e3arelu \u8f93\u5165\u56fe\u7247\u5c3a\u5bf8150\u00d7150 3\u901a\u9053\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n# \u6c60\u5316\u5c42\u5377\u79ef\u5c3a\u5bf8\u4e3a2\u00d72\nmodel.add(layers.MaxPool2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPool2D((2, 2)))\n\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPool2D((2, 2)))\n\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPool2D((2, 2)))\n\n# \u62c9\u76f4\u5c42\nmodel.add(layers.Flatten())\n# \u4e22\u5f03\u5c42\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])\n\n# \u8c03\u6574\u50cf\u7d20\u503c \u5c060~255\u533a\u95f4\u7684\u50cf\u7d20\u503c\u51cf\u5c11\u52300~1\u533a\u95f4\u4e2d\uff0cCnn\u66f4\u559c\u6b22\u5904\u7406\u5c0f\u7684\u8f93\u5165\u503c\ntrain_datagen = ImageDataGenerator(rescale=1. \/ 255, )\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    directory=train_dir,\n    target_size=(150, 150),\n    batch_size=20,\n    class_mode='binary'\n)\n\nvalidation_generator = test_datagen.flow_from_directory(\n    directory=validation_dir,\n    target_size=(150, 150),\n    batch_size=20,\n    class_mode='binary'\n)\n# \u4f7f\u7528fit_genertor\u5728\u6a21\u578b\u4e2d\u586b\u5145\u6570\u636e\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=100,\n    epochs=30,\n    validation_data=validation_generator,\n    validation_steps=50\n)\n# \u4fdd\u5b58\u6a21\u578b\nmodel.save('cats_and_dogs_small_0.h5')","d17b1f9d":"model.load_weights('cats_and_dogs_small_0.h5')\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n# \u663e\u793aacc\u66f2\u7ebf\uff0closs\u66f2\u7ebf\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","9a34d950":"from keras import layers\nfrom keras import models\nimport matplotlib.pyplot as plt\nfrom keras import optimizers\nfrom keras.preprocessing.image import ImageDataGenerator\n\nbase_dir = '\/data\/nextcloud\/dbc2017\/files\/jupyter\/\/cats_and_dogs_small'\n\ntrain_dir = base_dir+'\/train'\nvalidation_dir = base_dir+'\/validation'\n# train_dir = r'\/kaggle\/working\/cats_and_dogs_small\/train'\n# validation_dir = r'\/kaggle\/working\/cats_and_dogs_small\/validation'base_dir","ed3104ad":"# \u4f18\u5316\u7248\u672cdata augmentation\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\nmodel.add(layers.MaxPool2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPool2D((2, 2)))\n\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPool2D((2, 2)))\n\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPool2D((2, 2)))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])\n\n\n\n# \u8c03\u6574\u50cf\u7d20\u503c\n# \u4f7f\u7528\u6570\u636e\u589e\u5f3a\u4f18\u5316\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255, \n    rotation_range=40, \n    width_shift_range=0.2, \n    height_shift_range=0.2, \n    shear_range=0.2, \n    zoom_range=0.2,\n    horizontal_flip=True\n)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    directory=train_dir,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='binary'\n)\n\nvalidation_generator = test_datagen.flow_from_directory(\n    directory=validation_dir,\n    target_size=(150, 150),\n    batch_size=32, # \u8c03\u5927\n    class_mode='binary'\n)\n\n# \u4f7f\u7528\u5b9e\u65f6\u6570\u636e\u589e\u76ca\u7684\u6279\u6570\u636e\u5bf9\u6a21\u578b\u8fdb\u884c\u62df\u5408\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=100,\n    epochs=100, # \u8c03\u5927\n    validation_data=validation_generator,\n    validation_steps=50\n)\n\nmodel.save('cats_and_dogs_small_1.h5')\n# 1 hour","0502ef0e":"# \u8fd9\u4e2a\u7248\u672c\u7684\u6a21\u578b\u9700\u8981\u8bad\u7ec3\u4e00\u4e2a\u5c0f\u65f6 \u53ef\u4ee5\u76f4\u63a5\u52a0\u8f7d\u6a21\u578b\u53c2\u6570\nmodel.load_weights('cats_and_dogs_small_1.h5')\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","c943a350":"from keras.applications import VGG16\nimport os\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\nimport matplotlib.pyplot as plt\n\n# Downloading data from https:\/\/github.com\/fchollet\/deep-learning-models\/releases\/download\/v0.1\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n# vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n# \u653e\u5728 .keras\/models\n# \u4e0d\u589e\u52a0\u6570\u636e\u91cf \u4f7f\u7528\u9884\u8bad\u7ec3\u7f51\u7edc\nconv_base = VGG16(weights='imagenet',\n                  include_top=False, #\u662f\u5426\u5305\u542b\u5168\u8fde\u63a5\u5206\u7c7b\u5668 \u663e\u7136\u5728ImageNet\u6709\u4e0a\u5343\u5206\u7c7b\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u4e0d\u9700\u8981\u7684\n                  input_shape=(150, 150, 3))\n\nbase_dir = '\/data\/nextcloud\/dbc2017\/files\/jupyter\/\/cats_and_dogs_small'\n\ntrain_dir = base_dir+'\/train'\nvalidation_dir = base_dir+'\/validation'\ntest_dir=base_dir+'\/test'\n\n# base_dir = '\/kaggle\/working\/cats_and_dogs_small'\n# train_dir = os.path.join(base_dir, 'train')\n# validation_dir = os.path.join(base_dir, 'validation')\n# test_dir = os.path.join(base_dir, 'test')","60770d09":"datagen = ImageDataGenerator(rescale=1.\/255)\nbatch_size = 20\n\n# \u4ece\u9884\u8bad\u7ec3\u7684baseline\u5377\u79ef\u5c42\u4e2d\u63d0\u53d6\u7279\u5f81\ndef extarct_features(directory, sample_count):\n    features = np.zeros(shape=(sample_count, 4, 4, 512))\n    labels = np.zeros(shape=(sample_count))\n    generator = datagen.flow_from_directory(\n        directory,\n        target_size=(150, 150),\n        batch_size=batch_size,\n        class_mode='binary'\n    )\n\n    i = 0\n    for inputs_batch, labels_batch in generator:\n        features_batch = conv_base.predict(inputs_batch)\n        features[i * batch_size : (i + 1) * batch_size] = features_batch\n        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n        i += 1\n        if i * batch_size >= sample_count:\n            break\n\n    return features, labels\n\n\ntrain_features, train_labels = extarct_features(train_dir, 2000)\nvalidation_features, validation_labels = extarct_features(validation_dir, 1000)\ntest_features, test_labels = extarct_features(test_dir, 1000)\n\ntrain_features = np.reshape(train_features, (2000, 4 * 4 * 512))\nvalidation_features = np.reshape(validation_features, (1000, 4 * 4 * 512))\ntest_features = np.reshape(test_features, (1000, 4 * 4 * 512))\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n              loss='binary_crossentropy',\n              metrics=['acc'])\n\nhistory = model.fit(train_features, train_labels,\n                    epochs=30,\n                    batch_size=20,\n                    validation_data=(validation_features, validation_labels))\nmodel.save('cats_and_dogs_small_2.h5')\n# epoch=30 \n# 1 min","eaabbeb3":"model.load_weights('cats_and_dogs_small_2.h5')\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()\n\n\n# \u9a8c\u8bc1\u96c6\u51c6\u786e\u7387\u5df2\u7ecf\u8fbe\u523090%\uff0c\u8981\u597d\u4e8e\u4e4b\u524d\uff0c\u4e00\u8d2f\u5728\u5c0f\u7684\u6570\u636e\u96c6\u4e0a\u505a\u8bad\u7ec3\u3002\n#\n# \u4f46\u4ecd\u7136\u6709\u8fc7\u62df\u5408\u7684\u95ee\u9898\uff0c\u5f88\u53ef\u80fd\u662f\u56e0\u4e3a\u6211\u4eec\u5e76\u6ca1\u6709\u7528\u5230\u6570\u636e\u589e\u5f3a\n#\n# \u4e0b\u4e00\u4e2a\u7248\u672c\u4e2d\u6211\u4eec\u5c06\u52a0\u4e0a\u6570\u636e\u589e\u5f3a","d1d2fa4e":"from keras.applications import VGG16\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\nimport matplotlib.pyplot as plt\n\nbase_dir = '\/data\/nextcloud\/dbc2017\/files\/jupyter\/\/cats_and_dogs_small'\n\ntrain_dir = base_dir+'\/train'\nvalidation_dir = base_dir+'\/validation'\ntest_dir=base_dir+'\/test'\n# train_dir = r'\/kaggle\/working\/cats_and_dogs_small\/train'\n# validation_dir = r'\/kaggle\/working\/cats_and_dogs_small\/validation'","b1301ac7":"conv_base = VGG16(weights='imagenet',\n                  include_top=False,\n                  input_shape=(150, 150, 3))\nconv_base.trainable = False\n\n\nmodel = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\n# \u589e\u52a0\u4e86\u6570\u636e\u589e\u5f3a\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    directory=train_dir,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n    directory=validation_dir,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='binary')\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizers.RMSprop(lr=2e-5),\n              metrics=['acc'])\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=100,\n    epochs=100,\n    validation_data=validation_generator,\n    validation_steps=50)\n\nmodel.save('cats_and_dogs_small_3.h5')\n# epoch=100\n# 1 hour","cb0449d0":"# \u8fd9\u4e2a\u7248\u672c\u7684\u6a21\u578b\u9700\u8981\u8bad\u7ec3\u4e00\u4e2a\u5c0f\u65f6 \u53ef\u4ee5\u76f4\u63a5\u52a0\u8f7d\u6a21\u578b\u53c2\u6570\nmodel.load_weights('cats_and_dogs_small_3.h5')\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()\n\n# \u589e\u5927\u6570\u636e\u96c6\n# \u6709\u6548\u7684\u89e3\u51b3\u4e86\u8fc7\u62df\u5408\u7684\u95ee\u9898","fe621431":"from keras.applications import VGG16\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\nimport matplotlib.pyplot as plt\n\nbase_dir = '\/data\/nextcloud\/dbc2017\/files\/jupyter\/\/cats_and_dogs_small'\n\ntrain_dir = base_dir+'\/train'\nvalidation_dir = base_dir+'\/validation'\ntest_dir=base_dir+'\/test'\n\n# train_dir = r'\/kaggle\/working\/cats_and_dogs_small\/train'\n# validation_dir = r'\/kaggle\/working\/cats_and_dogs_small\/validation'\n# test_dir = r'\/kaggle\/working\/cats_and_dogs_small\/test'","4f92aff5":"conv_base = VGG16(weights='imagenet',\n                  include_top=False,\n                  input_shape=(150, 150, 3))\nset_trainable = False\n\n# \u5fae\u8c03\n# \u89e3\u51bb\u4e4b\u524d\u56fa\u5b9a\u7684vgg16\u6a21\u578b\n# 1\u5728\u4e00\u4e2a\u5df2\u7ecf\u8bad\u7ec3\u597d\u7684baseline\u7f51\u7edc\u4e0a\u6dfb\u52a0\u81ea\u5b9a\u4e49\u7f51\u7edc\n# 2\u51bb\u7ed3baseline\u7f51\u7edc\n# 3\u8bad\u7ec3\u6211\u4eec\u6240\u6dfb\u52a0\u7684\u90e8\u5206\n# 4\u89e3\u51bb\u4e00\u4e9bbaseline\u7f51\u7edc\u4e2d\u7684\u5377\u79ef\u5c42\n# 5\u5c06\u6211\u4eec\u6240\u6dfb\u52a0\u7684\u90e8\u5206\u4e0e\u89e3\u51bb\u7684\u5377\u79ef\u5c42\u76f8\u8fde\u63a5\nfor layer in conv_base.layers:\n    if layer.name == 'block5_conv1':\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False\n\n\nmodel = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest')\n\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    directory=train_dir,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n    directory=validation_dir,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='binary')\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizers.RMSprop(lr=1e-5),\n              metrics=['acc'])\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=100,\n    epochs=100,\n    validation_data=validation_generator,\n    validation_steps=50\n)\nmodel.save('cats_and_dogs_small_4.h5')\n# epoch=100\n# 1 hour","60d80d8a":"# \u8fd9\u4e2a\u7248\u672c\u7684\u6a21\u578b\u9700\u8981\u8bad\u7ec3\u4e00\u4e2a\u5c0f\u65f6 \u53ef\u4ee5\u76f4\u63a5\u52a0\u8f7d\u6a21\u578b\u53c2\u6570\nmodel.load_weights('cats_and_dogs_small_4.h5')\n\n\ndef smooth_curve(points, factor=0.8):\n    smoothed_points = []\n    for point in points:\n        if smoothed_points:\n            previous = smoothed_points[-1]\n            smoothed_points.append(int(previous * factor + point * (1 - factor)))\n        else:\n            smoothed_points.append(point)\n\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\n# epochs = range(1, len(acc) + 1)\n# plt.plot(epochs, smooth_curve(acc), 'bo', label='Smoothed training acc')\n# plt.plot(epochs, smooth_curve(val_acc), 'b', label='Smoothed validation acc')\n# plt.title('Training and validation accuracy')\n# plt.legend()\n\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Smoothed training acc')\nplt.plot(epochs, val_acc, 'b', label='Smoothed validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\n# plt.plot(epochs, smooth_curve(loss), 'bo', label='Smoothed training loss')\n# plt.plot(epochs, smooth_curve(val_loss), 'b', label='Smoothed validation loss')\n# plt.title('Training and validation loss')\n# plt.legend()\n\nplt.plot(epochs, loss, 'bo', label='Smoothed training loss')\nplt.plot(epochs, val_loss, 'b', label='Smoothed validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(150, 150),\n    batch_size=20,\n    class_mode='binary'\n)\ntest_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\nprint('test acc:', test_acc)","89711382":"# \u4f18\u5316\u7248\u672c(3)\u2014\u9884\u8bad\u7ec3\u7f51\u7edc\u4e4b\u7279\u5f81\u63d0\u53d6 vgg16 data augmentation\n\u5728\u4f18\u5316\u7248\u672c\u4e8c\u4e2d\u6dfb\u52a0\u4e86\u6570\u636e\u589e\u5f3a data augmentation\uff0c\u53bb\u9664\u4e86dropout","e28c6106":"# \u6574\u7406\u6570\u636e\u96c6","837800cc":"\u901a\u8fc7\u8bad\u7ec3\u66f2\u7ebf\u89c2\u5bdf\u51fa\u6a21\u578b\uff0c\u4ea7\u751f\u8fc7\u62df\u5408\u73b0\u8c61\u3002\n\u8fc7\u62df\u5408\u89e3\u51b3\u65b9\u6cd5\uff1a\n\u6570\u636e\u6e05\u6d17\n\u589e\u5927\u8bad\u7ec3\u96c6\n\u91c7\u7528\u6b63\u5219\u5316\n\u589e\u5927\u6b63\u5219\u5316\u53c2\u6570","be3c11d7":"\u9700\u8981\u4fee\u6539\u597d\u8def\u5f84","2719debb":"# \u4f18\u5316\u7248\u672c(1)\u2014\u589e\u5927\u6570\u636e\uff08data augmentation\uff09","34ceaebe":"# \u5efa\u7acb\u7b80\u5355\u7248CNN\u7f51\u7edc\u6a21\u578b","7d4b3873":"# \u4f18\u5316\u7248\u672c(4)\u2014\u9884\u8bad\u7ec3\u7f51\u7edc\u4e4b\u5fae\u8c03\u6a21\u578b ","fbfee9b8":"\u4f7f\u7528\u9884\u8bad\u7ec3\u7f51\u7edc\u6a21\u578b \u51c6\u786e\u7387\u5df2\u7ecf\u8fbe\u5230\u4e8690%\u3002\n\u4ea7\u751f\u4e86\u8fc7\u62df\u5408\u95ee\u9898\n\u9700\u8981\u589e\u5f3a\u6570\u636e","840b42f4":"# \u4f18\u5316\u7248\u672c(2)\u2014\u9884\u8bad\u7ec3\u7f51\u7edc\u4e4b\u7279\u5f81\u63d0\u53d6  vgg16\n\u4e0d\u589e\u52a0\u6570\u636e\u91cf\uff0c\u9884\u5148\u8bad\u7ec3\u7f51\u7edc"}}