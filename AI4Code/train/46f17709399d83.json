{"cell_type":{"6eb2322d":"code","0731c702":"code","099bb52e":"code","8babf2da":"code","0131857a":"code","1847a19a":"code","6b6f3d45":"code","8f1ea2de":"code","053b1148":"code","de55094b":"code","d6170641":"code","cbb8ba18":"code","7f25d3d4":"code","4dcf01d5":"code","ba7d300a":"code","fbf54622":"code","abee8ef7":"code","949555e1":"code","73f98951":"code","ab1d742b":"code","6df5b767":"code","f7703821":"code","77c21914":"code","11fe2a12":"code","b9bafc4f":"code","7169bc0e":"code","642056c4":"code","d6dbfeaf":"code","86aaf183":"code","1028e53f":"code","1fea33fe":"code","d27e37e6":"code","998e3e1f":"code","6eaef171":"code","6662d7e3":"code","8b9a3e5c":"code","04c8652f":"code","6915abd7":"code","8af7bde0":"code","7233b3a5":"code","83e1b22c":"code","ee977344":"code","893a34d4":"code","00e7f001":"code","19726c0e":"code","a9c8aa7b":"code","a3cd19b0":"code","84deb49a":"code","4640d7ed":"code","25ef4551":"code","a73daec3":"code","dd3ecb36":"code","3703c16d":"code","90325822":"code","5be8fe43":"code","b4adf692":"code","0fdaff82":"code","3464deb8":"code","371f4b05":"markdown","06332bd1":"markdown","76fe042d":"markdown","ac60cd26":"markdown","6157f157":"markdown","870e274e":"markdown","17d67308":"markdown","2617ad82":"markdown","c7b1a355":"markdown","85c870ec":"markdown","886b9ba0":"markdown","1c29a5c5":"markdown","eb5a2e92":"markdown","cbb58f39":"markdown","9b2caccb":"markdown","7b6aa9f0":"markdown","c432a2b1":"markdown","4c84a50f":"markdown","27f56458":"markdown","4cc8ecf9":"markdown","a7b6a9c0":"markdown","4dd30a9c":"markdown","39717c01":"markdown","e6a3a07f":"markdown","c5162a72":"markdown","1d3ba544":"markdown","2b8aef02":"markdown","22027349":"markdown","259d4f67":"markdown","4bf38b79":"markdown","31851368":"markdown","07262141":"markdown","857cc474":"markdown","e14ecd96":"markdown","a9651745":"markdown","f2bca723":"markdown","5c63522e":"markdown","d7ab8c49":"markdown","0d220c85":"markdown","59096d9c":"markdown","063b713d":"markdown","d013278c":"markdown","396eba5c":"markdown","54315851":"markdown","38c9a9d0":"markdown","debd7c71":"markdown","7899d94d":"markdown","c90afb53":"markdown","5ec50941":"markdown","a86b8a04":"markdown","3f6afd7c":"markdown"},"source":{"6eb2322d":"#Required packages\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport statsmodels.api as sm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","0731c702":"pd.options.display.max_rows=None\npd.options.display.max_columns=None","099bb52e":"titanic_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","8babf2da":"submit_df = pd.DataFrame()\nsubmit_df['PassengerId'] = test_df['PassengerId']","0131857a":"titanic_df.head()","1847a19a":"test_df.head()","6b6f3d45":"titanic_df.shape","8f1ea2de":"test_df.shape","053b1148":"titanic_df.info()","de55094b":"test_df.info()","d6170641":"titanic_df.describe()","cbb8ba18":"test_df.describe()","7f25d3d4":"titanic_df.isnull().sum()","4dcf01d5":"test_df.isnull().sum()","ba7d300a":"titanic_df.dtypes","fbf54622":"test_df.dtypes","abee8ef7":"titanic_df.skew(axis = 0, skipna = True)","949555e1":"test_df.skew(axis = 0, skipna = True)","73f98951":"fig, ax =plt.subplots(2,2, figsize=(10, 8))\nsns.distplot(titanic_df[\"Fare\"], ax=ax[0][0])\nsns.distplot(titanic_df[\"Age\"], ax=ax[0][1])\nsns.distplot(titanic_df[\"SibSp\"], ax=ax[1][0])\nsns.distplot(titanic_df[\"Parch\"], kde_kws={'bw':0.1}, ax=ax[1][1])\nfig.tight_layout(pad=3.0)\n# fig.show()","ab1d742b":"fig, ax =plt.subplots(2,2, figsize=(10, 8))\nsns.countplot(\"Embarked\", data=titanic_df, ax=ax[0][0])\nsns.countplot(\"Survived\", data=titanic_df, ax=ax[0][1])\nsns.countplot(\"Pclass\", data=titanic_df, ax=ax[1][0])\nsns.countplot(\"Sex\", data=titanic_df, ax=ax[1][1])\nfig.tight_layout(pad=3.0)\n# fig.show()","6df5b767":"fig, ax =plt.subplots(2,2, squeeze=False, figsize=(12, 8))\nsns.countplot(\"Embarked\", hue='Survived', data=titanic_df, ax=ax[0][0])\nsns.countplot(\"Sex\", hue='Survived', data=titanic_df, ax=ax[0][1])\nsns.countplot(\"Pclass\", hue='Survived', data=titanic_df, ax=ax[1][0])\nfig.tight_layout(pad=3.0)\nfig.delaxes(ax[1][1])\n# fig.show()","f7703821":"fig, ax =plt.subplots(2, 2, squeeze=False, figsize=(10,8))\nsns.boxplot(x='Survived', y='Age', data=titanic_df, ax=ax[0][0])\nsns.boxplot(x='Survived', y='Fare', data=titanic_df, ax=ax[0][1])\nsns.boxplot(x='Survived', y='SibSp', data=titanic_df, ax=ax[1][0])\nsns.boxplot(x='Survived', y='Parch', data=titanic_df, ax=ax[1][1])\nfig.tight_layout(pad=3.0)\n# fig.show()","77c21914":"sns.catplot(x=\"Parch\", y=\"Age\", col=\"Survived\", data=titanic_df, height=5, aspect=.8)","11fe2a12":"sns.catplot(x=\"SibSp\", y=\"Age\", col=\"Survived\", data=titanic_df, height=5, aspect=.8)","b9bafc4f":"sns.catplot(x=\"SibSp\", y=\"Fare\", col=\"Survived\", data=titanic_df, height=5, aspect=.8)","7169bc0e":"sns.catplot(x=\"Parch\", y=\"Fare\", col=\"Survived\", data=titanic_df, height=5, aspect=.8)","642056c4":"sns.catplot(x=\"Sex\", y=\"Age\", col=\"Survived\", data=titanic_df, height=5, aspect=.8)","d6dbfeaf":"sns.catplot(x=\"Sex\", y=\"Fare\", col=\"Survived\", data=titanic_df, height=5, aspect=.8)","86aaf183":"sns.catplot(x=\"Pclass\", y=\"Age\", col=\"Survived\", data=titanic_df, height=5, aspect=.8)","1028e53f":"sns.catplot(x=\"Pclass\", y=\"Fare\", col=\"Survived\", data=titanic_df, height=5, aspect=.8)","1fea33fe":"sns.catplot(x=\"Embarked\", y=\"Age\", col=\"Survived\", data=titanic_df, height=5, aspect=.8)","d27e37e6":"sns.catplot(x=\"Embarked\", y=\"Fare\", col=\"Survived\", data=titanic_df, height=5, aspect=.8)","998e3e1f":"fig, ax =plt.subplots(3, 2, squeeze=False, figsize=(10,8))\nsns.scatterplot(x='Age', y='Fare', hue='Survived', data=titanic_df, ax=ax[0][0])\nsns.scatterplot(x='SibSp', y='Age', hue='Survived', data=titanic_df, ax=ax[0][1])\nsns.scatterplot(x='Parch', y='Age', hue='Survived', data=titanic_df, ax=ax[1][0])\nsns.scatterplot(x='SibSp', y='Fare', hue='Survived', data=titanic_df, ax=ax[1][1])\nsns.scatterplot(x='Parch', y='Fare', hue='Survived', data=titanic_df, ax=ax[2][0])\nfig.tight_layout(pad=3.0)\nfig.delaxes(ax[2][1])\n# fig.show()","6eaef171":"fig, ax =plt.subplots(2, 2, squeeze=False, figsize=(10,8))\nsns.boxplot(titanic_df['Age'], ax=ax[0][0])\nsns.boxplot(titanic_df['Fare'], ax=ax[0][1])\nsns.boxplot(titanic_df['SibSp'], ax=ax[1][0])\nsns.boxplot(titanic_df['Parch'], ax=ax[1][1])\nfig.tight_layout(pad=3.0)\n# fig.show()","6662d7e3":"for i in (test_df.select_dtypes(include ='object').columns):\n    if(i != 'Survived'):\n        data_crosstab = pd.crosstab(titanic_df[i], titanic_df['Survived'], margins = False)\n        stat, p, dof, expected = stats.chi2_contingency(data_crosstab)\n        prob=0.95\n        alpha = 1.0 - prob\n        if p <= alpha:\n            print(i, ' : Dependent (reject H0)')\n        else:\n            print(i, ' : Independent (fail to reject H0)')","8b9a3e5c":"corr_train = titanic_df.corr()\ncorr_train","04c8652f":"titanic_df['Survived'].value_counts()","6915abd7":"sum(titanic_df['Survived'] == 1) \/ len(titanic_df)","8af7bde0":"#code for doing oversampling to balance the unbalanced dataset here\n\n# from imblearn.over_sampling import SMOTE\n# X_train = titanic_df.loc[:, titanic_df.columns != 'Survived']\n# y_train = titanic_df.loc[:, titanic_df.columns == 'Survived']\n# sm = SMOTE(random_state = 2) \n# X_train_res, y_train_res = sm.fit_sample(X_train, y_train)","7233b3a5":"print('For Training Data: ')\nfor i in titanic_df.columns:\n    if((titanic_df[i].isnull().sum()) > 0):\n        p = ((titanic_df[i].isnull().sum()) \/ len(titanic_df[i])) * 100\n        print('Proportion of null values in ', i, ' column is ', p)","83e1b22c":"data = titanic_df.copy()\ndata.drop(data[(data['Age'].isna()) & (data['Survived']==1)].index,axis=0,inplace=True)\n#Test data appended so there is no need to process it separately\ndata = data.append(test_df)\ndata[\"Embarked\"]=data['Embarked'].fillna(data['Embarked'].mode()[0])\n#Imputing Age column with the mean value of Age column in the dataset\ndata['Age']= data['Age'].fillna(data['Age'].mean())\n#Imputing Cabin column with 0 value and rest all values are replcaed by 1\ndata[\"Cabin\"] = data['Cabin'].fillna(0)\ndata.loc[data['Cabin']!=0,'Cabin'] = 1\ndata[\"Cabin\"]=data[\"Cabin\"].astype('int64')","ee977344":"df_corr=data.loc[:,[\"Survived\",\"Cabin\"]]\nsns.heatmap(df_corr.corr(), annot = True, vmin=-1, vmax=1, center= 0, cmap= 'coolwarm')","893a34d4":"#Creating feature_final dataframe to store all the final features which we'll input to the model\nfeature_final=pd.DataFrame()\nfeature_final['Survived']=data['Survived']\nfeature_final['PassengerId']=data['PassengerId']\nfeature_final['Cabin']=data['Cabin']\nfeature_final['Fare']=data['Fare']\nfeature_final['SibSp']=data['SibSp']\nfeature_final['Parch']=data['Parch']\nfeature_final['Sex']=data['Sex']\n#For sex column, I am replacing male with 0 and female with 1, and finally converted sex column to integer data type (to remove dummy variable trap)\nfeature_final.loc[feature_final['Sex']=='male','Sex'] = 0\nfeature_final.loc[feature_final['Sex'] == 'female','Sex'] = 1\nfeature_final['Sex']=feature_final['Sex'].astype('int64')\n#Pclass column is converted to integer data type\ndata['Pclass'] = data['Pclass'].astype('int64')\nfeature_final['Pclass']= data['Pclass']\n#Creating dummy for Embarked column\ndata['Embarked'] = pd.Categorical(data['Embarked'])\ndfdummies = pd.get_dummies(data['Embarked'], prefix = 'Embarked')\nfeature_final = pd.concat([feature_final, dfdummies], axis=1)","00e7f001":"#As age column contains lot of outliers, so it is needed to remove it, binning is one of the way to treat outlier\nbins = [0,18,35,45,62,200]\n#The above values are decided based on the plot for Age column\nlabels = ['Child','Teen','Youth','Old','Very_Old']\ndata['Age_binned'] = pd.cut(data['Age'], bins=bins, labels=labels)\n#converting Age to Dummies and Adding to newly created DataFrame\ndata['Age_binned'] = pd.Categorical(data['Age_binned'])\nfeature_final['Age']= data['Age_binned']","19726c0e":"#Creating a new column Is_Alone based on whether we have 0 family members or more\nfeature_final.loc[feature_final['SibSp']+feature_final['Parch'] == 0,'Is_Alone'] = 0\nfeature_final['Is_Alone']=feature_final['Is_Alone'].fillna(1)\nfeature_final['Is_Alone']=feature_final['Is_Alone'].astype('int64')","a9c8aa7b":"#Name column contains title, which is an important information to feed to model\ntitles = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\ndataset = data.copy()\n# extract titles\ndataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n# replace titles with a more common title or as Rare\ndataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr',\\\n                                        'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ndataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\ndataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\ndataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n# convert titles into numbers\ndataset['Title'] = dataset['Title'].map(titles)\n# filling NaN with 0, to get safe\ndataset['Title'] = dataset['Title'].fillna(0)\ndata['Title'] = dataset['Title']\nfeature_final['Title']=dataset['Title']","a3cd19b0":"#From ticket column, we can extract information which kind of ticket is bought \ndata['Deck'] = data['Ticket'].apply(lambda x: x.split(' ')[0].split('\/')[0].split('.')[0])\ndata['Deck'] = data['Deck'].apply(lambda x: 'Gen' if x.isnumeric()  else x)\ndata['Deck'] = pd.Categorical(data['Deck'])\ndfdummies = pd.get_dummies(data['Deck'], prefix = 'Deck')\nfeature_final = pd.concat([feature_final, dfdummies], axis=1)","84deb49a":"AgeList = { 'Child':1,'Teen':2, 'Youth':3, 'Old':4,'Very_Old':5}\nfeature_final['Age']= feature_final['Age'].map(AgeList)","4640d7ed":"train_df = feature_final.loc[feature_final['Survived'].notnull()]\ntest_df = feature_final.loc[feature_final['Survived'].isna()]","25ef4551":"logreg = LogisticRegression(max_iter=1000)\nY_train = train_df['Survived']\nX_train = train_df.drop(['Survived','PassengerId'],axis=1)\nlogreg.fit(X_train,Y_train)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)","a73daec3":"acc_log","dd3ecb36":"# Imputing Fare column with mean value\ntest_df['Fare'] = test_df['Fare'].fillna(test_df['Fare'].mean())\n# Dropping unnecessary columns from test dataset\ntest= test_df.drop(['Survived','PassengerId'],axis=1)","3703c16d":"##For running grid search making parameter dictionary\n# param_grid = {\n#               \"n_estimators\": [10, 18, 22],\n#               \"min_samples_split\": [1, 2, 4, 10, 15, 20],\n#               \"criterion\" : ['gini', 'entropy'],\n#               \"min_samples_leaf\": [1, 5, 10, 20, 50, 70, 100],\n#               \"n_estimators\": [100, 400, 700, 1000, 1500]}","90325822":"##Performing grid search to find best parameters\n# rf = RandomForestClassifier(n_estimators=100, max_features='auto', oob_score=True, random_state=1, n_jobs=-1)\n# clf = GridSearchCV(estimator=rf, param_grid=param_grid, n_jobs=-1)\n# clf.fit(X_train, Y_train)\n##Printing the best parameters\n# clf.bestparams","5be8fe43":"#Fitting the model\nrandom_forest = RandomForestClassifier(criterion = \"gini\", \n                                       min_samples_leaf = 1, \n                                       min_samples_split = 10,   \n                                       n_estimators=100, \n                                       max_features='auto', \n                                       oob_score=True, \n                                       random_state=1, \n                                       n_jobs=-1)\n\nrandom_forest.fit(X_train, Y_train)\nrandom_forest.score(X_train, Y_train)","b4adf692":"#Predicting Result for Test dataset\nY_prediction = random_forest.predict(test).astype(int)","0fdaff82":"#Storing the prediction in Survived column of submit_df dataframe\nsubmit_df['Survived'] = Y_prediction","3464deb8":"# For saving the result to submit.csv file\nsubmit_df.to_csv(\"submit.csv\", index=False)","371f4b05":"Loading the train and test dataset","06332bd1":"Interpretation of above results:\n    \nFrom above, we conclude that, passenger who are in first class are survived more, despite of old age being a factor, and most of the passenger from third class died despite of their age","76fe042d":"Finding the data types of each and every column of train dataset","ac60cd26":"## Univariate Analysis\nMethod to perform uni-variate analysis will depend on whether the variable type is categorical or continuous.","6157f157":"Interpretation of above result:\n\nFrom above plot, we can observe, that passenger having more than four number of sibling\/spouse are not at all survived\n\nPassenger between age of 20 and 60, and 0 and 1 number of sibling\/spouse are the one who died most and even survived most\n\nPassenger having more than 4 number of sibling\/spouse are not at all survived","870e274e":"#### Univariate Analysis for continuous variables**","17d67308":"Interpretation of above result (train dataset):\n\n'PassengerId' column is not at all skewed\n\n'Survived' column is right skewed (but not too much) as the skewness value is positive and small\n\n'Pclass' column is left skewed as the skewness value is negative\n\n'Age' column is right skewed as the skewness value is positive\n\n'SibSp' column is right skewed as the skewness value is positive\n\n'Parch' column is right skewed as the skewness value is positive\n\n'Fare' column is right skewed as the skewness value is positive","2617ad82":"Finding the shape of training dataset (number of rows and columns in it)","c7b1a355":"Finding the total number of null values in each and every column of test dataset","85c870ec":"From above we can interpret that cabin column has good effect on Survived column, so we won't drop it","886b9ba0":"Interpretation of above results:\n\nPassenger having more than three number of parent\/children, are the one who did not survive except very few\n\nPasenger having 0 and 1 number of parent\/children, and paid the highest fare, are the one who survived","1c29a5c5":"Generating descriptive statistics about the train dataset. Descriptive statistics include those that summarize the central tendency, dispersion and shape of a dataset's distribution, excluding null values. The output will vary depending on what is provided.**","eb5a2e92":"## Understanding data","cbb58f39":"Interpretation of above results:\n\nFrom above, we can conclude that, passenger who are in first class, paid more are survived, but passenger in first class who paid less are died, may be those less paid passenger are in first class due to some lottery or free services","9b2caccb":"Different categories in which variables are present in test dataset\nPredictor Variable: PassengerId, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\n\nNumeric Variable: PassengerId, Age, SibSp, Parch, Fare\n\nDiscrete Variable: SibSp, Parch\n\nContinuous Variable: Age, Fare\n\nCategorical Variable: Pclass, Name, Sex, Ticket, Cabin, Embarked","7b6aa9f0":"Printing the top five rows of training dataset","c432a2b1":"Interpretation:\n\nFrom above, we found that:\n\n'Fare' is skewed towards right side and outliers are also present\n\n'Age' is skewed towards right but not too much and number of outliers are also less\n\n'SibSp' is skewed towards right and outliers are also present\n\n'Parch' is skewed towards right and outliers are also present","4c84a50f":"Interpretation of above results (train):\n\n'Age' column contains outliers, and these outliers are above age 65, median age of passenger is around 30\n\n'Fare' column contains outliers, and these outliers are above 90, median fare of passenger is around 15 dollar\n\n'SibSp' column contains outliers, median number of sibling\/spouse is 0, most of the passenger has 0 or 1 number of Sibling\/Spouse\n\n'Parch' column contains outliers, median number of parent\/child is 0, most of the passenger has 0 or 1 number of Parent\/Child\n\n","27f56458":"Finding the shape of test dataset (number of rows and columns in it)","4cc8ecf9":"Interpretation of above result:\n\nFrom above we can see that, number of survived passenger is less than that of died, survived percentage is around 38 which is less than 50% and so we need to do either oversampling or undersampling to make balance in the dataset.","a7b6a9c0":"Interpretation of above results:\n\nMost of the passenger embarked from S port are survived and died both, but most of the passenger embarked from Q port are died, and the passenger who survived also are young, so obviously, young passenger can help them themselves\n\n","4dd30a9c":"Code for removing limit on the display of number of rows and columns","39717c01":"Interpretation of above results:\n\nHere, for every categorical variable, we are finding contingency table (Contingency Table is one of the techniques for exploring two or even more variables. It is basically a tally of counts between two or more categorical variables.)\n\nThen this contingency table is passed to perform chi square test (The chi-square test of independence works by comparing the categorically coded data that you have collected (known as the observed frequencies) with the frequencies that you would expect to get in each cell of a table by chance alone).\n\nIn terms of a p-value and a chosen significance level (alpha), the test can be interpreted as follows:\n\nIf p-value <= alpha: significant result, reject null hypothesis (H0), dependent. If p-value > alpha: not significant result, fail to reject null hypothesis (H0), independent.\n\nFrom above we can tell that, Pclass, Sex, Ticket and Embarked are variables which are effecting target variable (Survived). So we'll keep these and drop the rest of the variable","e6a3a07f":"Interpretation of above results:\n\n'Embarked' column contains, three embarkation ports and most people ar from S port\n\n'Survived' column contains two values, number of people who died are more as compare to number of people who survived\n\n'Pclass' represents different classes, total three class, and most passenger booked third class (lower) because that is comparatively cheaper than other classes\n\n'Sex' contains two values, and number of male passenger are more as compare to that of female","c5162a72":"Printing the skewness values of different columns in train dataset (Positive values indicates data is right skewed, negative values indicates data is left skewed, and zero value indicates data is not at all skewed)","1d3ba544":"Interpretation of above result:\n\nFrom Fig 1, we can say that most of the people between age 20 and 40 (both inclusive) died and survived also\n\nFrom Fig 2, we can say that median fare of people who died is less than median fare of people who survived, which implies more passenger who paid more is survived\n\nFrom Fig 3, we can say that, most of the people having 0 or 1 sibling\/spouse died and survived\n\nFrom Fig 4, we can say that, most of the people having 0 or 1 Parent\/children survived and the people having 0 parent\/children mostly died, as they have no relative to save them","2b8aef02":"#### For finding correlation between numerical features\n\n-1: perfect negative linear correlation\n\n+1:perfect positive linear correlation and\n\n0: No correlation","22027349":"Interpretation of above results:\n\nFrom above, we can conclude that, male paid even more fare than female are died, but female who even paid less are survived\n","259d4f67":"#### Fitting logistic regression model","4bf38b79":"Interpretation of above results:\n\nFrom Fig 1, we can conclude that, passenger in every age, who paid more fare are survived more\n\nFrom Fig 2, we can conclude that, passenger having less number of sibling\/spouse are survived more despite having more age\n\nFrom Fig 3, we can conclude that, passenger having less number of parent\/children are survived more despite having more age\n\nFrom Fig 4, we can conclude that, passenger having less number of sibling\/spouse and paid more fare are survived most\n\nFrom Fig 5, we can conclude that, passenger having less number of parent\/child and paid more fare are survived most","31851368":"Interpretation of above results:\n\nFrom above plot, we observed that, passenger having more than four spouse\/sibling are not at all survived\n\nPassenger who paid more, and having less number of sibling\/spouse are survived","07262141":"Interpretation of above results:\n\nFrom above, we can conclude that, more number of male died as compare to female, and the male who died most are having ages between 20 and 40, while the female of same age survived the most","857cc474":"#### Chi-Square Test:\n\nThis test is used to derive the statistical significance of relationship between the variables. Chi-square is based on the difference between the expected and observed frequencies in one or more categories in the two-way table.","e14ecd96":"Finding the data types of each and every column of test dataset","a9651745":"Importing the required libraries","f2bca723":"Interpretation of above result (test dataset):\n\n'PassengerId' column is not at all skewed\n\n'Survived' column is right skewed (but not too much) as the skewness value is positive and small\n\n'Pclass' column is left skewed as the skewness value is negative\n\n'Age' column is right skewed as the skewness value is positive\n\n'SibSp' column is right skewed as the skewness value is positive\n\n'Parch' column is right skewed as the skewness value is positive\n\n'Fare' column is right skewed as the skewness value is positive","5c63522e":"Generating descriptive statistics about the test dataset. Descriptive statistics include those that summarize the central tendency, dispersion and shape of a dataset's distribution, excluding null values. The output will vary depending on what is provided.","d7ab8c49":"#### Finding the proportion of survived and died passenger from the given dataset","0d220c85":"Interpretation of above results:\n\nMost of the passenger who are embarked from C port and paid more are survived, and same for passenger embarked from S port","59096d9c":"Printing the top five rows of test dataset","063b713d":"Different categories in which variables are present in train dataset\nPredictor Variable: PassengerId, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\n\nTarget Variable: Survived\n\nNumeric Variable: PassengerId, Age, SibSp, Parch, Fare\n\nDiscrete Variable: SibSp, Parch\n\nContinuous Variable: Age, Fare\n\nCategorical Variable: Survived, Pclass, Name, Sex, Ticket, Cabin, Embarked","d013278c":"## Bivariate Analysis","396eba5c":"Interpretation of above result:\n\nFrom above plot, we can observe that passenger having more than two number of parent or children are rarely survived, most of them are died\n\nAlso, passenger having less than two number of parent\/children are died, may be because they do not have family member to save them\n\nPassenger whose age is above 60 are rarely survived","54315851":"Interpretation of above:\n\nFor 'Embarked' column more passengers were picked up from S port, in which number of people survived are less as compared to death. For people picked up from C port, number of survived people are more. For people picked up from Q port, survived people are less\n\nFor 'Sex' column, number of males are more as compare to that of female. But more number of male died as compare to female\n\nFor 'Pclass' column, despite of having more passengers in third class, proportion of people died is much more than the proportion of people survived, while for other two classes, these proportions does not differ much","38c9a9d0":"Interpretattion of above results:\n\nThere is not much correlation between different variables, which implies they effect target variable in different way, and thus no need to drop them from dataset, based on this evidence\n\n","debd7c71":"Creating a new dataframe submit and storing the passenger id of test dataset in it","7899d94d":"### For detecting outliers","c90afb53":"Printing the skewness values of different columns in test dataset (Positive values indicates data is right skewed, negative values indicates data is left skewed, and zero value indicates data is not at all skewed)\n","5ec50941":"### Train Data ","a86b8a04":"#### Missing Value Treatment","3f6afd7c":"Finding the total number of null values in each and every column of train dataset"}}