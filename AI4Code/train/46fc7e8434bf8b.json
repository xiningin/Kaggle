{"cell_type":{"b37fc6bb":"code","4c82840b":"code","557335b4":"code","5742e248":"code","99446ca9":"code","05427c38":"code","564e9683":"code","8f01180e":"code","f2f15f78":"code","b689fb96":"code","800a0d32":"code","be0866fb":"code","18b4cf52":"code","e53947f3":"code","aa88414d":"code","45ebd4cf":"code","7b0cce0c":"code","48a28ed2":"code","90efb6b7":"code","5483894c":"code","ed8ad018":"markdown","03f2b5ed":"markdown","5ae30cbd":"markdown","27c17f0a":"markdown","e1a47bd8":"markdown","aca16402":"markdown","aedd51fd":"markdown","5e9c8357":"markdown"},"source":{"b37fc6bb":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline \n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","4c82840b":"heart = pd.read_csv(\"..\/input\/heart-attack-analysis-prediction-dataset\/heart.csv\")","557335b4":"heart.head()","5742e248":"heart.info()\n#Data doesn't have null values","99446ca9":"heart.describe()","05427c38":"heart.output.value_counts()\n#Data is not skewed as both outputs are nearly evenly divided","564e9683":"heart[heart.duplicated()]\n#One row is a duplicate","8f01180e":"heart.drop_duplicates(inplace=True)\n#Removed duplicated values","f2f15f78":"corr_matrix = heart.drop(['output'], axis=1).corr()\nfig, ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(corr_matrix, annot=True)\nplt.show()\n#Input data are not related to each other, therefore there is no redundant information","b689fb96":"heart.corr()['output'][:].sort_values(ascending=False)\n#Correlation to our output variable","800a0d32":"X = heart.drop(['output'], axis=1)\ny = heart['output']","be0866fb":"categorical_cols = []\nnumerical_cols = []\n\nfor col in X.columns:\n    if (X[col].nunique() <= 5):\n        categorical_cols.append(col)\n    else:\n        numerical_cols.append(col)\n        \n#Separating categorical from numerical data","18b4cf52":"X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n#Encoding categorical columns","e53947f3":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","aa88414d":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\nX_test[numerical_cols] = scaler.transform(X_test[numerical_cols])","45ebd4cf":"from sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\npred = model.predict(X_test)\nprint(accuracy_score(pred,y_test))","7b0cce0c":"from sklearn.tree import DecisionTreeClassifier\n\nmodel = DecisionTreeClassifier()\nmodel.fit(X_train, y_train)\n\npred = model.predict(X_test)\nprint(accuracy_score(pred,y_test))","48a28ed2":"from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier()\nmodel.fit(X_train, y_train)\n\npred = model.predict(X_test)\nprint(accuracy_score(pred,y_test))","90efb6b7":"from sklearn.svm import SVC\n\nmodel = SVC()\nmodel.fit(X_train, y_train)\n\npred = model.predict(X_test)\nprint(accuracy_score(pred,y_test))\n","5483894c":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\nmodel = GridSearchCV(LogisticRegression(penalty='l2'), param_grid)\nmodel.fit(X_train, y_train)\n\npred = model.predict(X_test)\nprint(accuracy_score(pred,y_test))\n","ed8ad018":"## Importing Data","03f2b5ed":"## Importing Essential Libraries","5ae30cbd":"## Exploratory Data Analysis","27c17f0a":"## Splitting Test and Training","e1a47bd8":"## Dealing with Categorical and Numerical data","aca16402":"## Tuning Hyperparameters of Best Model","aedd51fd":"## Testing Various Models","5e9c8357":"## Scaling Dataset"}}