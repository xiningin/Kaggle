{"cell_type":{"0bec7a16":"code","7d0b1bbe":"code","ac9ca36d":"code","b30fb3c1":"code","23337535":"code","31dcb66a":"code","4e2fcdb8":"code","c5d5664a":"code","b23f1006":"code","fc23fcfd":"code","8b478507":"code","c2072c75":"code","ae5fc5e5":"code","51e15b88":"code","0ba1f471":"code","0f7f8e00":"code","5124923f":"code","95387791":"code","19f34ca4":"code","9740ba24":"code","371a9cbe":"code","3daf088d":"code","dbc16244":"code","83c08879":"code","44a5e1ff":"code","0c2a4cb5":"code","a79bb768":"code","3c800b9b":"code","f8f010f9":"code","af3df8fe":"code","1d303d9f":"code","6a91f77b":"code","b1803b13":"code","d3c89a4a":"code","5f1218a9":"code","870151f7":"code","a8c7de89":"code","9b4d816c":"code","de854b53":"code","6170aff5":"code","d7e1ad76":"code","f4b969bd":"code","87139f1d":"code","f3002a47":"code","4a21aebd":"code","08c9ab05":"code","82c89cfb":"code","e93eb7fd":"code","ead4be99":"code","c9f07c44":"code","656a5c1e":"code","164c1dbe":"code","b39657b3":"code","3d017080":"code","4c411d17":"code","1bc05a9d":"code","dc9f9248":"code","2d8121e3":"code","4da3afe6":"code","d0de2bd1":"code","165369ff":"code","a6a00b83":"code","d7c35151":"markdown","d3d6db81":"markdown","ebe2f216":"markdown","42d8922f":"markdown","22c4869d":"markdown","31d111ca":"markdown","8ed3f5b9":"markdown","8c1ddf3f":"markdown","00c7160d":"markdown","3318eb51":"markdown","507e81f7":"markdown","3bce2bda":"markdown","150d0c02":"markdown","635943eb":"markdown","0a421e46":"markdown","fda54c12":"markdown","7d99d8be":"markdown","9cf4033a":"markdown","da131d9d":"markdown","d8f5e50c":"markdown","4c580dd8":"markdown","35231143":"markdown","09767ae4":"markdown","a1597137":"markdown","c7e7ef99":"markdown","8da14380":"markdown","90327a72":"markdown"},"source":{"0bec7a16":"## NumPy is a package in Python used for Scientific Computing. NumPy package is used to perform different operations. The ndarray (NumPy Array) is a multidimensional array used to store values of same datatype.\nimport numpy as np\n## Pandas is a Python package providing fast, flexible, and expressive data structures designed to make working with \u201crelational\u201d or \u201clabeled\u201d data both easy and intuitive. It aims to be the fundamental high-level building block for doing practical, real world data analysis in Python.\nimport pandas as pd\n## Matplotlib is a Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. Matplotlib can be used in Python scripts, the Python and IPython shells, the Jupyter notebook, web application servers, and four graphical user interface toolkits.\nimport matplotlib\nimport matplotlib.pyplot as plt\n## Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.\nimport seaborn as sns","7d0b1bbe":"## `%matplotlib` is a magic function in IPython. With this, the output of plotting commands is displayed inline within frontends like the Jupyter notebook, directly below the code cell that produced it. The resulting plots will then also be stored in the notebook document.\n%matplotlib inline","ac9ca36d":"dataset = pd.read_csv(\"..\/input\/smart-home-dataset-with-weather-information\/HomeC.csv\")\ndataset.info()","b30fb3c1":"dataset.head()","23337535":"tmp_str = \"Feature(attribute)     DataType\"; \nprint(tmp_str+\"\\n\"+\"-\"*len(tmp_str))\nprint(dataset.dtypes)","31dcb66a":"## Return a tuple representing the dimensionality of the DataFrame.\nprint(\"Shape of the data: {} --> n_rows = {}, n_cols = {}\".format(dataset.shape, dataset.shape[0],dataset.shape[1]))","4e2fcdb8":"## pandas.DataFrame.head: This function returns the first n rows for the object based on position. \n#It is useful for quickly testing if your object has the right type of data in it.\ndataset.head(10)","c5d5664a":"## This function returns last n rows from the object based on position. \n#It is useful for quickly verifying data, for example, after sorting or appending rows.\ndataset.tail(10)","b23f1006":"dataset = dataset[0:-1] ## == dataset[0:dataset.shape[0]-1] == dataset[0:len(dataset)-1] == dataset[:-1]\ndataset.tail()","fc23fcfd":"## pandas.DataFrame.columns: The column labels of the DataFrame.\ndataset.columns","8b478507":"# Python string method replace() returns a copy of the string in which the occurrences of old have been replaced with new, \n#optionally restricting the number of replacements to max.\ndataset.columns = [col.replace(' [kW]', '') for col in dataset.columns]\ndataset.columns","c2072c75":"dataset['sum_Furnace'] = dataset[['Furnace 1','Furnace 2']].sum(axis=1)\ndataset['avg_Kitchen'] = dataset[['Kitchen 12','Kitchen 14','Kitchen 38']].mean(axis=1)","ae5fc5e5":"dataset = dataset.drop(['Kitchen 12','Kitchen 14','Kitchen 38'], axis=1)\ndataset = dataset.drop(['Furnace 1','Furnace 2'], axis=1)\ndataset.columns","51e15b88":"dataset['time'].head()","0ba1f471":"import time \nprint(' start ' , time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(1451624400)))","0f7f8e00":"import time \nprint(' start ' , time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(int(dataset['time'].iloc[0]))))","5124923f":"time_index = pd.date_range('2016-01-01 05:00', periods=len(dataset),  freq='min')  \ntime_index = pd.DatetimeIndex(time_index)\ndataset = dataset.set_index(time_index)\ndataset = dataset.drop(['time'], axis=1)\ndataset.iloc[np.r_[0:5,-5:0]].iloc[:,0] #numpy.r is the simple way to build up arrays quickly,\n#you can use the array to index your dataframe. For example, here I want to see the first and the last 5 samples","95387791":"dataset.shape","19f34ca4":"dataset['temperature'].plot(figsize=(25,5))","9740ba24":"## pandas.DataFrame.resample: Convenience method for frequency conversion and resampling of time series. \ndataset['temperature'].resample(rule='D').mean().plot(figsize=(25,5)) #D calendar day frequency","371a9cbe":"import matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = (25,5)","3daf088d":"dataset.columns","dbc16244":"fig, axes = plt.subplots(nrows=2, ncols=1)\ndataset['use'].resample('D').mean().plot(ax=axes[0]) #D calendar day frequency\ndataset['House overall'].resample('D').mean().plot(ax=axes[1]) #D calendar day frequency","83c08879":"dataset = dataset.drop(columns=['House overall'])\ndataset.shape","44a5e1ff":"## pandas.Series.value_counts: Return a Series containing counts of unique values.\ndataset['icon'].value_counts()","0c2a4cb5":"## pandas.Series.value_counts: Return a Series containing counts of unique values.\ndataset['summary'].value_counts()","a79bb768":"dataset = dataset.drop(columns=['summary', 'icon'])\ndataset.shape","3c800b9b":"## pandas.Series.unique: Uniques are returned in order of appearance. Hash table-based unique, therefore does NOT sort.\ndataset['cloudCover'].unique()","f8f010f9":"dataset[dataset['cloudCover']=='cloudCover'].shape","af3df8fe":"dataset['cloudCover'][56:60]","1d303d9f":"dataset['cloudCover'].replace(['cloudCover'], method='bfill', inplace=True)\ndataset['cloudCover'] = dataset['cloudCover'].astype('float')\ndataset['cloudCover'].unique()","6a91f77b":"dataset['cloudCover'][56:60]","b1803b13":"dataset.info()","d3c89a4a":"dataset = dataset.resample('D').mean()\nprint(\"Shape of daily dataset: {} --> n_rows = {}, n_cols = {}\".format(dataset.shape, dataset.shape[0],dataset.shape[1]))","5f1218a9":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nnp.random.seed(42)\ntf.random.set_seed(42)","870151f7":"usedf = dataset['use']","a8c7de89":"usedf.head()","9b4d816c":"usedf=usedf.to_frame()","de854b53":"usedf.head()","6170aff5":"usedf.info()","d7e1ad76":"# This function is used to prepare the time-series data\n# according to the problem definition.\ndef add_lags(series, times):\n  cols = []\n  column_index = []\n  for time in times:\n    cols.append(series.shift(-time))\n    lag_fmt = \"t+{time}\" if time > 0 else \"t{time}\" if time < 0 else \"t\"\n    column_index += [(lag_fmt.format(time=time), col_name)\n        for col_name in series.columns]\n  df = pd.concat(cols, axis=1)\n  df.columns = pd.MultiIndex.from_tuples(column_index)\n  return df","f4b969bd":"X = add_lags(usedf, times=range(-30+1,1)).iloc[30:-5]\ny = add_lags(usedf, times=[5]).iloc[30:-5]","87139f1d":"X.head()","f3002a47":"y.head()","4a21aebd":"train_slice = slice(None, \"2016-10-30\")","08c9ab05":"test_slice = slice(\"2016-11-1\", None)","82c89cfb":"# Split the dataset into 80% training and 20% testing as follows\nX_train, y_train = X.loc[train_slice], y.loc[train_slice]\nX_test, y_test = X.loc[test_slice], y.loc[test_slice]","e93eb7fd":"print(X_train.shape)","ead4be99":"print(X_test.shape)","c9f07c44":"def multilevel_df_to_ndarray(df):\n  shape = [-1] + [len(level) for level in df.columns.remove_unused_levels().levels]\n  return df.values.reshape(shape)","656a5c1e":"X_train_3D = multilevel_df_to_ndarray(X_train)\nX_test_3D = multilevel_df_to_ndarray(X_test)","164c1dbe":"print(X_train_3D.shape)","b39657b3":"print(X_test_3D.shape)","3d017080":"y_train = y_train.values\ny_test = y_test.values","4c411d17":"print(y_train.shape)","1bc05a9d":"print(y_test.shape)","dc9f9248":"model_LSTM = keras.models.Sequential()\nmodel_LSTM.add(keras.layers.LSTM(units = 100, return_sequences = True,input_shape = X_train_3D.shape[1:]))\nmodel_LSTM.add(keras.layers.LSTM(units = 50))\nmodel_LSTM.add(keras.layers.Dense(1))\nmodel_LSTM.summary()\n","2d8121e3":"model_LSTM.compile(loss='mse', optimizer='adam', metrics=['mae'])","4da3afe6":"history_LSTM = model_LSTM.fit(x=X_train_3D, y=y_train,epochs=50, validation_split=0.1, batch_size=32)","d0de2bd1":"test_loss, test_mae = model_LSTM.evaluate(x=X_test_3D, y=y_test)","165369ff":"print(test_loss, test_mae)","a6a00b83":"model_LSTM = keras.models.Sequential()\nmodel_LSTM.add(keras.layers.LSTM(units = 100, return_sequences = True,input_shape = X_train_3D.shape[1:]))\nmodel_LSTM.add(keras.layers.LSTM(units = 50))\nmodel_LSTM.add(keras.layers.Dense(1))\nmodel_LSTM.summary()\n","d7c35151":"> Wee see that the last row is invalid, so let's remove it.","d3d6db81":"#Import Packages","ebe2f216":"> We replace this missing valuess with the next valid observation  we have.","42d8922f":"> We would like to convert this large number that represents a unix timestamp (i.e. \"1284101485\") to a readable date. So, one idea is to now when is the `start time`.","22c4869d":"> They are same. It's better to remove one of them.","31d111ca":"> We have 500K rows and each row shows the home status at a specific `minute`.\nLet's plot the `temperature` data and see what is the result.","8ed3f5b9":"# Time-Series Prediction with LSTM\n\n","8c1ddf3f":"#Exercise: Hyper Parameter Tuning","00c7160d":"> Here are the `rule`s you can use:\n- B         business day frequency\n- C         custom business day frequency (experimental)\n- D         calendar day frequency\n- W         weekly frequency\n- M         month end frequency\n- SM        semi-month end frequency (15th and end of month)\n- BM        business month end frequency\n- CBM       custom business month end frequency\n- MS        month start frequency\n- SMS       semi-month start frequency (1st and 15th)\n- BMS       business month start frequency\n- CBMS      custom business month start frequency\n- Q         quarter end frequency\n- BQ        business quarter endfrequency\n- QS        quarter start frequency\n- BQS       business quarter start frequency\n- A         year end frequency\n- BA, BY    business year end frequency\n- AS, YS    year start frequency\n- BAS, BYS  business year start frequency\n- BH        business hour frequency\n- H         hourly frequency\n- T, min    minutely frequency\n- S         secondly frequency\n- L, ms     milliseconds\n- U, us     microseconds\n- N         nanoseconds","3318eb51":"> We see that for some rows we have an invalid value for `cloudCover`. ","507e81f7":"> It seems `use` and `House overall` show the same data. Let's visualize these two columns.","3bce2bda":"> Let's have a look at name and data type of each feature (column).","150d0c02":"> Sometimes we are only interest in an aggregated result. To make it easy, we can make a new column and save the desired result in that new column.\n> For example: if we are interested in the `total` energy usage by both `furnaces` or the `average` usage of all `kitchens`:","635943eb":"> Let's clean the columns names by removing the `[kW]` uint.","0a421e46":"> Columns `summary` and `icon` are not numerical. ","fda54c12":"### The weather and energy dataset\nThe dataset contains the readings with a time span of 1 minute of house appliances in kW from a smart meter and weather conditions of that particular region.\n\n#### Data Columns Descriptions:\n(source: Data Source: https:\/\/www.kaggle.com\/taranvee\/smart-home-dataset-with-weather-information)\n##### Index \n- **time**\n    * Time of the readings, with a time span of 1 minute.\n\n##### Energy Usage \n- **use [kW]**\n    * Total energy consumption\n- **gen [kW]**\n    * Total energy generated by means of solar or other power generation resources\n- **House overall [kW]**\n    * overall house energy consumption\n- **Dishwasher [kW]** \n    * energy consumed by specific appliance\n- **Furnace 1 [kW]**\n    * energy consumed by specific appliance\n- **Furnace 2 [kW]**\n    * energy consumed by specific appliance\n- **Home office [kW]**\n    * energy consumed by specific appliance\n- **Fridge [kW]**\n    * energy consumed by specific appliance\n- **Wine cellar [kW]**\n    * energy consumed by specific appliance\n- **Garage door [kW]**\n    * energy consumed by specific appliance\n- **Kitchen 12 [kW]**\n    * energy consumption in kitchen 1\n- **Kitchen 14 [kW]**\n    * energy consumption in kitchen 2\n- **Kitchen 38 [kW]**\n    * energy consumption in kitchen 3\n- **Barn [kW]**\n    * energy consumed by specific appliance\n- **Well [kW]**\n    * energy consumed by specific appliance\n- **Microwave [kW]**\n    * energy consumed by specific appliance\n- **Living room [kW]**\n    * energy consumption in Living room\n- **Solar [kW]**\n    * Solar power generation\n\n##### Weather\n- **temperature**:\n    * Temperature is a physical quantity expressing hot and cold.\n- **humidity**:\n    * Humidity is the concentration of water vapour present in air.\n- **visibility**:\n    * Visibility sensors measure the meteorological optical range which is defined as the length of atmosphere over which a beam of light travels before its luminous flux is reduced to 5% of its original value.\n\n- **apparentTemperature**:\n    * Apparent temperature is the temperature equivalent perceived by humans, caused by the combined effects of air temperature, relative humidity and wind speed. The measure is most commonly applied to the perceived outdoor temperature.\n- **pressure**: \n    * Falling air pressure indicates that bad weather is coming, while rising air pressure indicates good weather\n- **windSpeed**:\n    * Wind speed, or wind flow speed, is a fundamental atmospheric quantity caused by air moving from high to low pressure, usually due to changes in temperature.\n- **cloudCover**:\n    * Cloud cover (also known as cloudiness, cloudage, or cloud amount) refers to the fraction of the sky obscured by clouds when observed from a particular location. Okta is the usual unit of measurement of the cloud cover.\n- **windBearing**:\n    * In meteorology, an azimuth of 000\u00b0 is used only when no wind is blowing, while 360\u00b0 means the wind is from the North. True Wind Direction True North is represented on a globe as the North Pole. All directions relative to True North may be called \"true bearings.\"\n- **dewPoint**:\n    * the atmospheric temperature (varying according to pressure and humidity) below which water droplets begin to condense and dew can form.\n- **precipProbability**:\n    * A probability of precipitation (POP), also referred to as chance of precipitation or chance of rain, is a measure of the probability that at least some minimum quantity of precipitation will occur within a specified forecast period and location.\n- **precipIntensity**:\n    * The intensity of rainfall is a measure of the amount of rain that falls over time. The intensity of rain is measured in the height of the water layer covering the ground in a period of time. It means that if the rain stays where it falls, it would form a layer of a certain height.\n \n##### Others\n- **summary**:\n    * Report generated by the by the data collection systm (apparently!).\n    * Including:\n    ```\n    Clear, Mostly Cloudy, Overcast, Partly Cloudy, Drizzle,\n       Light Rain, Rain, Light Snow, Flurries, Breezy, Snow,\n       Rain and Breezy, Foggy, Breezy and Mostly Cloudy,\n       Breezy and Partly Cloudy, Flurries and Breezy, Dry,\n       Heavy, Snow.\n    ```\n- **icon**:\n    * The icon that is used by the data collection systm (apparently!).\n    * Including:\n    ```\n    cloudy, clear-night, partly-cloudy-night, clear-day, partly-cloudy-day, rain, snow, wind, fog.\n    ```\n    ","7d99d8be":"> It may seem too noisy to you. We can `resample` data by taking the `average temperature` every `day` and then plot it.","9cf4033a":"The number of parameters of LSTM:\nInput vectors of size m \nOutput vectors of size n \n4(nm + n^2 )\nLSTM with  bias vectors: 4(nm + n^2 + n) (default in keras )\n\n=4 ( 100 x 1 + 100x100 + 100) = 4x 10200 = 40,800\n\n= 4 (50 x 100 + 50x50 +50) = 4x7500 = 30200\n\n= 50 + 1 = 51","da131d9d":">  Data publisher says the dataset contains the readings with a time span of `1 minute` of house appliances\nin `kW` from a `smart meter` and `weather conditions` of that particular region.\nSo, we set `freq='min'` and convert Uinx time to readable date.","d8f5e50c":"#Energy Usage Prediction using LSTM","4c580dd8":"> There are plenty of ways deal with this kind of invalid values. The simplest one is to remove rows that include this invalid value. but more sophisticated way is to replace them. see this: https:\/\/pandas.pydata.org\/pandas-docs\/stable\/user_guide\/missing_data.html","35231143":"#Data Preprocessing","09767ae4":"#Dataset Analysis","a1597137":"* In this dataset, time is recorded in the [Unix Time](https:\/\/en.wikipedia.org\/wiki\/Unix_time) format.\n> Unix Time represents the number of seconds that have passed since `00:00:00 UTC Thursday, 1 January 1970`.","c7e7ef99":"> If you do not need old columns, you can drop them.","8da14380":"#Feature Engineering","90327a72":"Now, we look at the dataset columns"}}