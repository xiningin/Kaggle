{"cell_type":{"02f45943":"code","4e874519":"code","7f1848d7":"code","ee1d7eef":"code","c70f2083":"code","0b5a6e95":"code","475b6820":"code","a591eefa":"code","5f18a2bf":"code","1f4f718d":"code","ec7e60a5":"code","794b8b45":"code","fae3fb73":"code","ab5f3017":"code","70097d13":"markdown","44c57530":"markdown","b57f8c40":"markdown","fb58b61c":"markdown","db3d53fa":"markdown","12ec17ba":"markdown","b9c0abcd":"markdown","1adf636c":"markdown","343f58aa":"markdown","b7033150":"markdown","f3f4ce5d":"markdown","5e1dc605":"markdown"},"source":{"02f45943":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\n\n#Import Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nsns.set()\n%matplotlib inline\nwarnings.filterwarnings(\"ignore\")","4e874519":"df = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\ndf.head()","7f1848d7":"df.info()","ee1d7eef":"df.describe()","c70f2083":"print('Data shape:', df.shape)\nX = df.iloc[:, :-1]\ny = df.iloc[:, -1]\nprint('X shape:',X.shape)\nprint('y shape:',y.shape)","0b5a6e95":"classes = {0:'Not Fraud', 1:'Fraud'}\nclasses_names = ['Not Fraud', 'Fraud']\nprint(df.Class.value_counts().rename(index = classes))","475b6820":"X_train, X_test, y_train, y_test = X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33, random_state=0, shuffle=True)\n\n#Train\nprint('X_train shape:',X_train.shape)\nprint('y_train shape:',y_train.shape)\n\n#Test\nprint('X_test shape:',X_test.shape)\nprint('y_test:',y_test.shape)","a591eefa":"#Logistic Regression Model\nLogisticRegressionModel = LogisticRegression(max_iter=200)\nLogisticRegressionModel.fit(X_train, y_train)\nLogisticRegressionModel_y_pred = LogisticRegressionModel.predict(X_test)\n\n\n#Score\nLogisticRegressionModel_TrainScore =  round(LogisticRegressionModel.score(X_train, y_train) * 100, 2)\nLogisticRegressionModel_TestScore = round(LogisticRegressionModel.score(X_test, y_test) * 100, 2)\n\nprint('Logistic Regression Train Score: ', LogisticRegressionModel_TrainScore)\nprint('Logistic Regression Test Score: ', LogisticRegressionModel_TestScore)\n\n\n#Confusion Matrix\nLogisticRegressionModel_CM = confusion_matrix(y_test, LogisticRegressionModel_y_pred)\nLogisticRegressionModel_ConfusionMatrix = pd.DataFrame(LogisticRegressionModel_CM, index=classes_names, columns=classes_names)\n\nsns.heatmap(LogisticRegressionModel_ConfusionMatrix, annot=True, cbar=None, cmap=\"OrRd\", fmt = 'g')\nplt.title(\"Logistic Regression Confusion Matrix\"), plt.tight_layout()\nplt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")\nplt.show()","5f18a2bf":"#SVC Model\nSVCModel = SVC(kernel= 'rbf', max_iter=100, C=1.0, gamma='auto')\nSVCModel.fit(X_train, y_train)\nSVCModel_y_pred = SVCModel.predict(X_test)\n\n#Score\nSVCModel_TrainScore =  round(SVCModel.score(X_train, y_train) * 100, 2)\nSVCModel_TestScore = round(SVCModel.score(X_test, y_test) * 100, 2)\n\nprint('SVC Train Score: ', SVCModel_TrainScore)\nprint('SVC Test Score: ',SVCModel_TestScore)\n\n\n#Confusion Matrix\nSVCModel_CM = confusion_matrix(y_test, SVCModel_y_pred)\nSVCModel_ConfusionMatrix = pd.DataFrame(SVCModel_CM, index=classes_names, columns=classes_names)\n\nsns.heatmap(SVCModel_ConfusionMatrix, annot=True, cbar=None, cmap=\"Purples\", fmt = 'g')\n\nplt.title(\"SVC Confusion Matrix\"), plt.tight_layout()\nplt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")\nplt.show()","1f4f718d":"#Decision Tree Model\nDecisionTreeModel = DecisionTreeClassifier(criterion='gini',max_depth=5,random_state=33) #criterion can be entropy\nDecisionTreeModel.fit(X_train, y_train)\nDecisionTreeModel_y_pred = DecisionTreeModel.predict(X_test)\n\n\n#Score\nDecisionTreeModel_TrainScore =  round(DecisionTreeModel.score(X_train, y_train) * 100, 2)\nDecisionTreeModel_TestScore = round(DecisionTreeModel.score(X_test, y_test) * 100, 2)\n\nprint('Decision Tree Train Score: ' , DecisionTreeModel_TrainScore)\nprint('Decision Tree Test Score: ' , DecisionTreeModel_TestScore)\n\n\n#Confusion Matrix\nDecisionTreeModel_CM = confusion_matrix(y_test, DecisionTreeModel_y_pred)\nDecisionTreeModel_ConfusionMatrix = pd.DataFrame(DecisionTreeModel_CM, index=classes_names, columns=classes_names)\n\nsns.heatmap(DecisionTreeModel_ConfusionMatrix, annot=True, cbar=None, cmap=\"Blues\", fmt = 'g')\nplt.title(\"Decision Tree Confusion Matrix\"), plt.tight_layout()\nplt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")\nplt.show()","ec7e60a5":"#Random Forest Model\nRandomForestModel = RandomForestClassifier(criterion = 'gini',n_estimators=200,max_depth=5,random_state=33, n_jobs=-1)\nRandomForestModel.fit(X_train, y_train)\nRandomForestModel_y_pred = RandomForestModel.predict(X_test)\n\n\n#Score\nRandomForestModel_TrainScore =  round(RandomForestModel.score(X_train, y_train) * 100, 2)\nRandomForestModel_TestScore = round(RandomForestModel.score(X_test, y_test) * 100, 2)\n\nprint('RandomForestModel Train Score: ' , RandomForestModel_TrainScore)\nprint('RandomForestModel Test Score: ' , RandomForestModel_TestScore)\n\n\n#Confusion Matrix\nRandomForestModel_CM = confusion_matrix(y_test, RandomForestModel_y_pred)\nRandomForestModel_ConfusionMatrix = pd.DataFrame(RandomForestModel_CM, index=classes_names, columns=classes_names)\n\nsns.heatmap(RandomForestModel_ConfusionMatrix, annot=True, cbar=None, cmap=\"Greens\", fmt = 'g')\nplt.title(\"Random Forest Confusion Matrix\"), plt.tight_layout()\nplt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")\nplt.show()","794b8b45":"models = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Support Vector Machines', 'Decision Tree', 'Random Forest'],\n    'Train Score': [LogisticRegressionModel_TrainScore, SVCModel_TrainScore, DecisionTreeModel_TrainScore, RandomForestModel_TrainScore],\n    'Test Score': [LogisticRegressionModel_TestScore, SVCModel_TestScore, DecisionTreeModel_TestScore, RandomForestModel_TestScore]})\n\nmodels.sort_values(['Train Score', 'Test Score'], ascending=[False, False])","fae3fb73":"fig, ax = plt.subplots(2, 2,figsize=(20,15))\nfig.tight_layout(pad=10.0)\nsns.set(font_scale=2)\n\nsns.heatmap(LogisticRegressionModel_ConfusionMatrix, ax=ax[0][0], annot=True, cbar=None, cmap=\"Reds\", fmt = 'g')\nax[0][0].set_title(\"Logistic Regression\", fontsize=18)\nax[0][0].set_ylabel(\"True Class\"), ax[0][0].set_xlabel(\"Predicted Class\")\n\n\nsns.heatmap(SVCModel_ConfusionMatrix, ax=ax[0][1], annot=True, cbar=None, cmap=\"Purples\", fmt = 'g')\nax[0][1].set_title(\"SVC\", fontsize=18)\nax[0][1].set_ylabel(\"True Class\"), ax[0][1].set_xlabel(\"Predicted Class\")\n\n\nsns.heatmap(DecisionTreeModel_ConfusionMatrix, ax=ax[1][0], annot=True, cbar=None, cmap=\"Blues\", fmt = 'g')\nax[1][0].set_title(\"Decision Tree\", fontsize=18)\nax[1][0].set_ylabel(\"True Class\"), ax[1][0].set_xlabel(\"Predicted Class\")\n\n\nsns.heatmap(RandomForestModel_ConfusionMatrix, ax=ax[1][1], annot=True, cbar=None, cmap=\"Greens\", fmt = 'g')\nax[1][1].set_title(\"Random Forest\", fontsize=18),\nax[1][1].set_ylabel(\"True Class\"), ax[1][1].set_xlabel(\"Predicted Class\")\n\nplt.show()","ab5f3017":"importance = RandomForestModel.feature_importances_\n\nplt.figure(figsize=(30,15))\nplt.ylabel('Importance', fontsize=18), plt.xlabel('Features', fontsize=18)\nplt.title(\"Relation between Features and Importance\", fontsize=18)\nplt.plot(X.columns, importance, 'o-', color=\"#2492ff\", markersize=10, label=\"Training score\")\nplt.show()","70097d13":"Import needed libraries.","44c57530":"We apply the ***1st*** model ***LogisticRegression***","b57f8c40":"**Split the data to *X* and *Y***","fb58b61c":"**The number of Fraud and Not Fraud**","db3d53fa":"**Import Data**","12ec17ba":"We apply the ***4th*** model ***RandomForest***","b9c0abcd":"We apply the ***3rd*** model ***DecisionTree***","1adf636c":"**We use *Random Forest Model* to know the importance of each *Feature*.**","343f58aa":"Split the data to 4 parts: ***X_train***, ***X_test***, ***y_train***, ***y_test***","b7033150":"We apply the ***2nd*** model ***SVC***","f3f4ce5d":"The best model is **Decision Tree Model**.\n\nThe most 3 **Important Features** are: \"**V17**\", \"**V12**\", \"**V14**\".","5e1dc605":"**We compare between models scores and accuracies**"}}