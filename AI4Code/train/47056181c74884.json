{"cell_type":{"0dae7afd":"code","9ac01d52":"code","035698c4":"code","3d0f2df8":"code","3502ff56":"code","58c6417f":"code","b7263e9b":"code","5975e546":"code","261dcb52":"code","1960386e":"code","75fc6753":"code","955b093f":"code","50d9f150":"code","37c36bc2":"code","e7192570":"code","822c3e51":"code","2c67e0c0":"code","d83833a8":"code","dab2b13e":"code","877ac1f9":"code","1bfeef23":"code","71b05a56":"code","75f1b1a4":"code","a527ced0":"code","6f8a758e":"code","32fb9200":"code","f129ccb8":"code","e20e45ef":"code","38735eb3":"code","b3d33b45":"code","8521c4eb":"code","f2470e3f":"code","34dff7ca":"code","3bee3c6c":"code","70a76f80":"code","fe6cccb2":"code","8d087dc4":"code","fb5c219e":"code","c4221832":"code","e68ba7c4":"code","1403ec7c":"code","b195efc7":"code","73a7f125":"code","88dee06e":"code","49a803f5":"code","5436378f":"code","fbe11a1e":"code","83819626":"code","b851660b":"code","c8f53f90":"code","f23eaf8e":"code","db50071d":"code","d80a7434":"code","44d0c80b":"code","dc949165":"code","38e6b299":"code","2b3a5f8a":"code","94454118":"code","b3360e0f":"code","7712bd4a":"code","10a24f08":"code","8abd3b35":"code","206f3749":"code","db8a3aa4":"code","bc738569":"code","7e4519a3":"code","8cf107d1":"code","bf19a9ad":"code","5643d2ab":"code","f3c7a1bd":"code","49e8f16c":"code","c3059d9f":"code","69570fbd":"code","e9a47d54":"code","71ccb506":"code","be5d280d":"code","c2f0a714":"code","14640041":"code","0d194628":"code","3ec4027f":"code","765a867f":"code","57b88702":"code","255e11bc":"code","1d27fe18":"code","48d176e6":"code","bc7fd1ac":"code","97bc8517":"code","0826871c":"code","46e67d1a":"code","d7eed459":"code","cbc3d90a":"code","45569cff":"code","cdf36095":"code","159e20fc":"code","9baf7191":"code","b94ad3d2":"code","40e63624":"code","701fc6e6":"code","f065c7ca":"code","2a6ff288":"code","18597afd":"code","9f943bc6":"code","87c3ccea":"code","c9c197fb":"code","ff6df6c9":"markdown","cc257b25":"markdown","7cb24441":"markdown","42392f24":"markdown","9cf70f2c":"markdown","3cc67e16":"markdown","561c2b4a":"markdown","c003706c":"markdown","7bef9b3e":"markdown","ce0c7be1":"markdown","c108f9e1":"markdown","71a1b7d1":"markdown","b2865aa1":"markdown","f774f536":"markdown","3274b01d":"markdown","57d520b4":"markdown","12995d9f":"markdown","eaba6cc5":"markdown","ce5ba733":"markdown","6f7ee927":"markdown","25a47639":"markdown","b4b5db04":"markdown","29f3e879":"markdown","54a3ca26":"markdown","f5b6e1d1":"markdown","55948cf6":"markdown","dc874f62":"markdown","688ab791":"markdown","e0aadc7c":"markdown","79752556":"markdown","9199c89c":"markdown","4398bed9":"markdown"},"source":{"0dae7afd":"from shutil import copy\ncopy('..\/input\/air-ticket-fare-prediction\/Test.csv','.\/Test.csv')\ncopy('..\/input\/air-ticket-fare-prediction\/Train.csv','.\/Train.csv')\ncopy('..\/input\/air-ticket-fare-prediction\/Sample_Submission.csv','.\/Sample_Submission.csv')","9ac01d52":"import gc\nimport math\nimport PIL \nimport pandas as pd\nimport numpy as np\nimport seaborn \nimport datetime\nimport random\nimport warnings\nimport holidays\nimport datetime\nimport xgboost as xgb\nfrom scipy import stats\nfrom pandas.tseries.holiday import USFederalHolidayCalendar as calendar\nfrom sklearn.linear_model import LinearRegression,Ridge,Lasso\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split , GridSearchCV,cross_val_score,cross_val_predict,cross_validate,RandomizedSearchCV\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error,explained_variance_score,max_error,r2_score,median_absolute_error,mean_squared_log_error\nfrom sklearn.feature_selection import VarianceThreshold,SelectKBest,f_regression\nfrom sklearn.preprocessing import MinMaxScaler,normalize,StandardScaler,RobustScaler\nfrom sklearn.preprocessing import OneHotEncoder,LabelEncoder\nfrom sklearn.decomposition import PCA\nimport featuretools as ft\nfrom sklearn.svm import SVR\nfrom mlxtend.feature_selection import SequentialFeatureSelector,ExhaustiveFeatureSelector","035698c4":"test_data = pd.read_csv('Test.csv')\ntrain_data = pd.read_csv('Train.csv')\nsample_data = pd.read_csv('Sample_Submission.csv')","3d0f2df8":"train_data.head()","3502ff56":"test_data.head()","58c6417f":"sample_data","b7263e9b":"train_data.describe()","5975e546":"train_data.info()","261dcb52":"train_data.isnull().sum()   ## WE have no null values","1960386e":"test_data.isnull().sum()","75fc6753":"train_data.duplicated().sum()","955b093f":"train_data = train_data.drop_duplicates()","50d9f150":"train_data.shape","37c36bc2":"train_data_1 = train_data.copy()\ntest_data_1 = test_data.copy()","e7192570":"const_feature = []\nuniq_val_count = []\nunique_cols = dict()\nfor col in list(train_data.columns):\n    uniq_val_count.append(train_data[col].nunique())\n    if(train_data[col].nunique()==1):\n        const_feature.append(col)\n    \nprint('\\n\\n\\nConstant Features are   :',const_feature)\nprint('\\n\\nALL FEATURES WITH UNIQUE VALUES : \\n')\npd.DataFrame({'COLUMN NAMES':list(train_data.columns) ,'UNIQUE VALUES COUNT':uniq_val_count})\n\n\n# Removing the constant feature\ntrain_data=train_data.drop(columns=const_feature)\n\n# Removing the constant feature\ntest_data=test_data.drop(columns=const_feature)","822c3e51":"# Hence We don't need to remove any Value","2c67e0c0":"train_data","d83833a8":"### Assign 0 for unknown classes\n\nclass LabelEncoderExt(object):\n    def __init__(self):\n        self.label_encoder = LabelEncoder()\n\n    def fit(self, data_list):\n        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n        self.classes_ = self.label_encoder.classes_\n        return self\n\n    def transform(self, data_list):\n        new_data_list = list(data_list)\n        for unique_item in np.unique(data_list):\n            if unique_item not in self.label_encoder.classes_:\n                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n        return self.label_encoder.transform(new_data_list)\n    \n    ","dab2b13e":"details = ['Airline','Source','Destination','Total_Stops','Additional_Info']\n\nlabel_enc_list = dict()\n\n\nfor col in range(len(details)):\n    label_encoder = LabelEncoderExt()\n    label_encoder.fit(train_data[details[col]])\n    train_data[details[col]] = label_encoder.transform(train_data[details[col]])\n    label_enc_list[details[col]]=label_encoder\n","877ac1f9":"for col in range(len(details)):\n    test_data[details[col]] = label_enc_list[details[col]].transform(test_data[details[col]])","1bfeef23":"train_data","71b05a56":"test_data","75f1b1a4":"time_cols = ['Dep_Time']\ntime_dur = ['Duration']\ndate_cols = ['Date_of_Journey']\n\nfor col in date_cols:\n    train_data['{}_month'.format(col)] =  pd.to_datetime(train_data['{}'.format(col)],format='%d-%m-%Y').dt.month\n    train_data['{}_day'.format(col)] =  pd.to_datetime(train_data['{}'.format(col)],format='%d-%m-%Y').dt.day\n    train_data['{}_year'.format(col)] =  pd.to_datetime(train_data['{}'.format(col)],format='%d-%m-%Y').dt.year\n\nfor col in time_cols:\n    train_data['{}_hour'.format(col)] =  pd.to_datetime(train_data['{}'.format(col)],format='%H:%M').dt.hour\n    train_data['{}_minutes'.format(col)] =  pd.to_datetime(train_data['{}'.format(col)],format='%H:%M').dt.minute\n\n    ","a527ced0":"x=train_data['Duration'].map(lambda x: x.replace('h',':').replace(' ','').replace('m',':'))\ndef mapper(elems):\n    if elems[0] == '':\n        return int(elems[1])\n        \n    elif elems[1] == '':\n        return int(int(elems[0])*60)\n    else:\n        return int(int(elems[0])*60 + int(elems[1]))\n        \ny = x.map(lambda i : mapper(i.split(':')))\n","6f8a758e":"train_data['Duration_minutes'] = y","32fb9200":"train_data = train_data.sort_values(by='Date_of_Journey').reset_index(drop=True)\n#train_data = train_data.drop(columns=['Date_of_Journey','Dep_Time','Arrival_Time','Duration'])","f129ccb8":"for col in date_cols:\n    test_data['{}_month'.format(col)] =  pd.to_datetime(test_data['{}'.format(col)],format='%d-%m-%Y').dt.month\n    test_data['{}_day'.format(col)] =  pd.to_datetime(test_data['{}'.format(col)],format='%d-%m-%Y').dt.day\n    test_data['{}_year'.format(col)] =  pd.to_datetime(test_data['{}'.format(col)],format='%d-%m-%Y').dt.year\n\nfor col in time_cols:\n    test_data['{}_hour'.format(col)] =  pd.to_datetime(test_data['{}'.format(col)],format='%H:%M').dt.hour\n    test_data['{}_minutes'.format(col)] =  pd.to_datetime(test_data['{}'.format(col)],format='%H:%M').dt.minute\n\nx=test_data['Duration'].map(lambda x: x.replace('h',':').replace(' ','').replace('m',':'))\n        \ny = x.map(lambda i : mapper(i.split(':')))\n\ntest_data['Duration_minutes'] = y\n\ntest_data = test_data.drop(columns=['Dep_Time','Arrival_Time','Duration'])","e20e45ef":"#train_data = train_data.drop(columns = ['Date_of_Journey_year'] )\n#test_data = test_data.drop(columns = ['Date_of_Journey_year'] )\n","38735eb3":"train_data.head()","b3d33b45":"test_data.head()","8521c4eb":"plt.figure(figsize=(25,8))\nplt.title('Correlation Matrix\\n')\nseaborn.heatmap(train_data.corr(),annot=True)\nplt.show()","f2470e3f":"plt.figure(figsize=(25,8))\nplt.title('Covariance Matrix\\n')\nseaborn.heatmap(train_data.cov(),annot=True)\nplt.show()","34dff7ca":"for col in ['Airline','Source', 'Destination','Additional_Info','Total_Stops']:\n    plt.style.use('classic')\n    plt.figure(figsize=(15,15))\n    plt.pie(train_data_1[col].value_counts(),labels=train_data_1[col].unique(),shadow=True,autopct='%0.1f%%')\n    plt.title('\\nCount of {}'.format(col))\n    plt.show()","3bee3c6c":"features = train_data.columns\n\nfor col in features:\n    plt.style.use('dark_background')\n    plt.figure(figsize=(15,15))\n    plt.bar(list(train_data[col].value_counts().index),list(train_data[col].value_counts()),color = random.sample(['maroon','yellow'],1))            \n    plt.title('\\nCount Plot of {}'.format(col))\n    plt.show()","70a76f80":"x_val = list(set(train_data.columns) - set(['Price']))\ny_val = 'Price'\nfor col in x_val:\n    plt.style.use('dark_background')\n    plt.figure(figsize=(15,15))\n    plt.scatter(train_data[col],train_data['Price'],color=random.sample(['yellow','maroon','blue','pink'],1),linewidth = .5)\n    plt.title('{} V\/S {}'.format(col,y_val))\n    plt.xlabel(col)\n    plt.ylabel(y_val)\n    plt.show()","fe6cccb2":"data = train_data.copy()","8d087dc4":"for col in list(set(data.columns) - set(['Price','Date_of_Journey','Dep_Time','Arrival_Time','Duration'])):\n    plt.figure(figsize=(15,15))\n    seaborn.distplot(data[col],color='maroon')\n    plt.show()","fb5c219e":"train_data1 = train_data.copy()\ntest_data1 = test_data.copy()","c4221832":"def mode(a):\n    u, c = np.unique(a, return_counts=True)\n    return u[c.argmax()]","e68ba7c4":"airline_mean = train_data.groupby('Airline').mean().round()\nsrc_mean = train_data.groupby('Source').mean().round()\ndes_mean = train_data.groupby('Destination').mean().round()\n\nairline_mean_test = test_data.groupby('Airline').mean().round()\nsrc_mean_test = test_data.groupby('Source').mean().round()\ndes_mean_test = test_data.groupby('Destination').mean().round()\n","1403ec7c":"train_data.columns = ['Airline', 'Date_of_Journey', 'Source', 'Destination', 'Dep_Time','Arrival_Time', 'Duration', 'Total_Stops', 'Additional_Info', 'Price','Date_of_Journey_month', 'Date_of_Journey_day', 'Date_of_Journey_year','Dep_Time_hour', 'Dep_Time_minutes', 'Duration_minutes']\ntest_data.columns = ['Airline', 'Date_of_Journey', 'Source', 'Destination', 'Total_Stops','Additional_Info', 'Date_of_Journey_month', 'Date_of_Journey_day','Date_of_Journey_year', 'Dep_Time_hour', 'Dep_Time_minutes','Duration_minutes']","b195efc7":"train_data.columns","73a7f125":"# Chech the time of the day - Morning,Evening,etc\ndef time_of_day(x):\n    if (x > 4) and (x <= 8):\n        #'Early Morning'\n        return 0\n    elif (x > 8) and (x <= 12 ):\n        # 'Morning'\n        return 1\n    elif (x > 12) and (x <= 16):\n        # Noon\n        return 2\n    elif (x > 16) and (x <= 20) :\n        #'Eve'\n        return 3\n    elif (x > 20) and (x <= 24):\n        # 'Night'\n        return 4\n    elif (x <= 4):\n        # 'Late Night'\n        return 5\n","88dee06e":"def check_is_holiday(x):\n    if x not  in holiday_lis:\n        return 0\n    else: return 1\n    \n#train_data['Date_of_Journey'].apply(lambda x: check_is_holiday(x))","49a803f5":"def check_month_time(x):\n    if x in range(1,10):\n        return 0\n    elif x in range(10,20):\n        return 1 \n    else: \n        return 2","5436378f":"def is_month_end(x):\n    if x<5 or x>25:\n        return 1\n    else:\n        return 0","fbe11a1e":"holiday_lis = []\nholiday_season = {}\nholiday_season_lis = []\n\nfor date in holidays.UnitedStates(years = train_data['Date_of_Journey_year'].unique()).items():\n    holiday_lis.append(str(date[0]))\n    holiday_season['Start'] = date[0]-datetime.timedelta(days=7)\n    holiday_season['End'] = date[0]+datetime.timedelta(days=7)\n    holiday_season_lis.append(holiday_season)\n    ","83819626":"holiday_lis =  list(holidays.India(years= [2018,2019,2020]))\nholiday_lis.extend(list(holidays.UnitedStates(years= [2018,2019,2020])))\nholiday_lis.extend(list(holidays.England(years= [2018,2019,2020])))","b851660b":"train_data['IsWeekEnd'] = np.where((pd.to_datetime(train_data['Date_of_Journey'],format='%d-%m-%Y').dt.dayofweek) < 5,0,1) \ntrain_data['TimeOfDay'] = train_data['Dep_Time_hour'].apply(time_of_day)\ntrain_data['TimeOfMonth'] = train_data['Date_of_Journey_day'].apply(lambda x: check_month_time(x))\ntrain_data['WeekDay'] = pd.to_datetime(train_data['Date_of_Journey'],format='%d-%m-%Y').dt.dayofweek\n\ntest_data['IsWeekEnd'] = np.where((pd.to_datetime(test_data['Date_of_Journey'],format='%d-%m-%Y').dt.dayofweek) < 5,0,1) \ntest_data['TimeOfDay'] = test_data['Dep_Time_hour'].apply(time_of_day)\ntest_data['TimeOfMonth'] = test_data['Date_of_Journey_day'].apply(lambda x: check_month_time(x))\ntest_data['WeekDay'] = pd.to_datetime(train_data['Date_of_Journey'],format='%d-%m-%Y').dt.dayofweek\n\ntrain_data['IsMonthEnd'] = train_data['Date_of_Journey_day'].apply(lambda x: is_month_end(x))\ntest_data['IsMonthEnd'] = test_data['Date_of_Journey_day'].apply(lambda x: is_month_end(x))","c8f53f90":"set(train_data.columns) - set(test_data.columns)","f23eaf8e":"train_data = train_data.drop(columns = {'Arrival_Time', 'Dep_Time', 'Duration'})","db50071d":"train_data = train_data.drop(columns = {'Date_of_Journey'})\ntest_data = test_data.drop(columns = {'Date_of_Journey'})","d80a7434":"train_data = train_data.drop(columns = {'Date_of_Journey_year'})\ntest_data = test_data.drop(columns = {'Date_of_Journey_year'})","44d0c80b":"x_data = train_data[set(train_data.columns)-set(['Price'])] \ny_data = pd.DataFrame(train_data['Price'])","dc949165":"x_data","38e6b299":"y_data","2b3a5f8a":"categorical_features = set(x_data.columns)\nnumerical_features = ['Duration_minutes']","94454118":"x_data_c = pd.get_dummies(x_data[categorical_features],columns =categorical_features )\nx_test_c = pd.get_dummies(test_data[categorical_features],columns =categorical_features )","b3360e0f":"x_data_c.shape,x_test_c.shape","7712bd4a":"x_test_missing = list(set(x_data_c.columns) - set(x_test_c.columns))\nx_test_missing","10a24f08":"x_train_missing = list(set(x_test_c.columns) - set(x_data_c.columns) )\nx_train_missing","8abd3b35":"for col in x_test_missing:\n    x_test_c[col] =  0","206f3749":"x_test_c= x_test_c.drop(columns = x_train_missing)","db8a3aa4":"x_data_c.shape,x_test_c.shape","bc738569":"x_train_c,x_eval_c = train_test_split(x_data_c,test_size=0.2,shuffle=False)\nx_train_c.shape,x_eval_c.shape","7e4519a3":"x_train,x_eval,y_train,y_eval = train_test_split(x_data,y_data,test_size=0.2,shuffle=False)\nx_test = test_data","8cf107d1":"x_train_c.shape,y_train.shape,x_eval_c.shape,y_eval.shape,x_test_c.shape","bf19a9ad":"y_train['Price'] = np.log(y_train['Price'])\ny_eval['Price'] = np.log(y_eval['Price'])","5643d2ab":"x_train_n = x_train[numerical_features]\nx_test_n = x_test[numerical_features]","f3c7a1bd":"x_test_n","49e8f16c":"numerical_features = x_train_n.columns","c3059d9f":"x_s = MinMaxScaler()\ny_s = MinMaxScaler()\n\n\nx_train_n = pd.DataFrame(x_s.fit_transform(x_train_n),columns =numerical_features)\nx_test_n = pd.DataFrame(x_s.fit_transform(x_test_n),columns =numerical_features)\nx_eval_n = pd.DataFrame(x_s.fit_transform(x_eval[numerical_features]),columns =numerical_features)\n\n\ny_train = pd.DataFrame(y_s.fit_transform(y_train),columns =['Price'])\ny_eval = pd.DataFrame(y_s.fit_transform(y_eval),columns =['Price'])\n","69570fbd":"x_train_n.shape","e9a47d54":"x_train_n.shape,x_test_n.shape,x_eval_n.shape,y_train.shape,y_eval.shape","71ccb506":"x_train = x_train_n.merge(x_train_c,left_index=True,right_index=True).reset_index(drop=True)\nx_train.shape","be5d280d":"x_eval = x_eval_n.merge(x_eval_c.reset_index(drop=True),left_index=True,right_index=True).reset_index(drop=True)\nx_eval.shape","c2f0a714":"x_test =x_test_n.merge(x_test_c,left_index=True,right_index=True).reset_index(drop=True)\nx_test.shape","14640041":"x_train = x_train.drop(columns=['Duration_minutes'])\nx_test = x_test.drop(columns=['Duration_minutes'])\nx_eval = x_eval.drop(columns=['Duration_minutes'])","0d194628":"def evaluate_metrics(x,y_true,y_pred,mod):\n    mean_abs_error = mean_absolute_error(y_true,y_pred)\n    mean_sq_error = mean_squared_error(y_true,y_pred)\n    root_mean_sq_error = mean_squared_error(y_true,y_pred)**0.5\n    r2_scr = r2_score(y_true,y_pred)\n    median_abs_score = median_absolute_error(y_true,y_pred)\n    explained_variance = explained_variance_score(y_true,y_pred)\n    return mean_abs_error,mean_sq_error,root_mean_sq_error,r2_scr,median_abs_score,explained_variance  ","3ec4027f":"def plot_regression_line(x,y_t,y_p):\n    plt.scatter(x,y_t,color='red',label = 'Y TRUE')\n    plt.scatter(x,y_p,color='yellow',linewidth = 0.5,label = 'Y PREDICTED')\n    #plt.xlim(-0.00000000000001,0.000000000000001)\n    plt.xlabel('ENTRY NO.')\n    plt.ylabel('PRICE')\n    plt.legend()\n    plt.title('ENTRY NO. V\/S {} Regression Line\\n'.format('delay'))\n    plt.show()","765a867f":"def select_features(x_train,y_train,x_test,x_eval1,k):\n    fs = SelectKBest(score_func = f_regression,k=k)\n    fs.fit(x_train,y_train)\n    col_indices = fs.get_support(indices=True)\n    x_features = x_train.columns[col_indices]\n    x_train_fs = pd.DataFrame(fs.transform(x_train),columns=x_features)\n    x_test_fs = pd.DataFrame(fs.transform(x_test),columns=x_features)\n    x_eval_fs = pd.DataFrame(fs.transform(x_eval1),columns=x_features)\n    return x_train_fs,x_test_fs,x_eval_fs,fs,x_features,col_indices\n\n\nx_train_fs,x_test_fs,x_eval_fs,fs,x_features,col_indices = select_features(x_train,y_train,x_test,x_eval,'all')\n\nfor i in range(len(fs.scores_[col_indices])):\n    print(\"\\n\",x_features[i],\"    \",fs.scores_[col_indices][i])\n    \n","57b88702":"reg_metrics = dict()\npredicted_price = dict()","255e11bc":"gc.collect()","1d27fe18":"train_data.corr()['Price']","48d176e6":"ridge = Ridge()\nparameters = {'alpha':[x for x in [0.0005,0.0001,0.00021,0.0006,0.1,0.001,0.005,0.008,0.1,0.5,1,0.1,0.09,0.08,0.06,0.05,0.03,0.01,0.02,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.999,1]]}  \n\nridge_reg = GridSearchCV(ridge,param_grid = parameters,verbose=1)\nridge_reg = ridge_reg.fit(x_eval_fs,y_eval)\n\nalpha = ridge_reg.best_params_['alpha']\n\nprint(\"\\n\\nBest Alpha:  \",ridge_reg.best_params_,\"\\nScore:  \",ridge_reg.best_score_)\n\nridge_mod = Ridge(alpha=alpha)\nridge_mod=ridge_mod.fit(x_train_fs,y_train)\ny_pred = ridge_mod.predict(x_eval_fs)\nmean_abs_error,mean_sq_error,root_mean_sq_error,r2_scr,median_abs_score,explained_variance = evaluate_metrics(x_eval_fs,y_eval,y_pred,ridge_mod)\nscr = ridge_mod.score(x_eval_fs,y_eval)\nprint(\"\\n\\n\\nMETRICS  :\\n\\nMean Absolute Error :  \",mean_abs_error,\"\\nScore :   \",scr,\"\\nMean Squared Error :  \",mean_sq_error,\"\\nRoot Mean Squared Error :  \",root_mean_sq_error,\"\\nR2 Square :  \",r2_scr,\"\\nMedian Absolute Score :  \",median_abs_score,\"\\nExplained Variance Score :  \",explained_variance)","bc7fd1ac":"reg_metrics['RIDGE REGRESSION'] = [mean_abs_error,scr,mean_sq_error,root_mean_sq_error,r2_scr,median_abs_score,explained_variance]    \npredicted_price['ridge_regression_price'] = np.exp(y_s.inverse_transform(ridge_mod.predict(x_test_fs))).reshape(ridge_mod.predict(x_test_fs).shape[0]).round()\nplot_regression_line(x_eval_fs.index,y_eval,y_pred)","97bc8517":"y_eval= np.array(y_eval)","0826871c":"# Hyper Parameter tuning using the train data\n\nlasso_reg = Lasso()\nparameters = {'alpha':[x for x in [0.0005,0.0001,0.00021,0.0006,0.1,0.00071,0.00070,0.00072,0.00073,0.00079,0.1,0.5,1]]}  \nlasso_reg = GridSearchCV(lasso_reg,param_grid=parameters,verbose=1)\nlasso_reg.fit(x_train_fs,y_train)\n\nprint(\"\\n\\n\\nBest Alpha : \",lasso_reg.best_params_,\"\\nBest Score : \",lasso_reg.best_score_)\n\nlasso_reg = Lasso(alpha=0.0001)\nlasso_reg = lasso_reg.fit(x_train_fs,y_train)\ny_pred = np.array(lasso_reg.predict(x_eval_fs))\n\nmean_abs_error,mean_sq_error,root_mean_sq_error,r2_scr,median_abs_score,explained_variance = evaluate_metrics(x_eval_fs,np.array(y_eval).reshape(y_eval.shape[0],1),y_pred.reshape(y_pred.shape[0],1),ridge_mod)\nscr = lasso_reg.score(x_eval_fs,y_eval)\nprint(\"METRICS  :\\n\\nMean Absolute Error :  \",mean_abs_error,\"\\nScore :   \",scr,\"\\nMean Squared Error :  \",mean_sq_error,\"\\nRoot Mean Squared Error :  \",root_mean_sq_error,\"\\nR2 Square :  \",r2_scr,\"\\nMedian Absolute Score :  \",median_abs_score,\"\\nExplained Variance Score :  \",explained_variance)    ","46e67d1a":"y_test_pred = lasso_reg.predict(x_test_fs)\ny_test_pred = y_test_pred.reshape(y_test_pred.shape[0],1)\npredicted_price['lasso_regression_price'] = np.exp(y_s.inverse_transform(y_test_pred).reshape(lasso_reg.predict(x_test_fs).shape[0])).round()\nreg_metrics['LASSO REGRESSION'] = [mean_abs_error,scr,mean_sq_error,root_mean_sq_error,r2_scr,median_abs_score,explained_variance]    \nplot_regression_line(x_eval_fs.index,y_eval,y_pred)","d7eed459":"gc.collect()","cbc3d90a":"%%time\n\n# Performing Grid-Search\n#gsc = GridSearchCV(estimator = RandomForestRegressor(),param_grid={'max_depth':[9,10],'n_estimators':(500,1000)},cv=5,scoring = 'neg_mean_squared_error',verbose=1,n_jobs=-1)\n#grid_result = gsc.fit(x_train,y_train)\n#best_params = grid_result.best_params_\n#print(\"\\n\\nBest Params : \\n\",best_params)\n\nrfr = RandomForestRegressor(max_depth=13,n_estimators=100,random_state=False,verbose=True) \n\nrfr.fit(x_train_fs,y_train)\n\ny_pred = rfr.predict(x_eval_fs)\n\nscr = rfr.score(x_eval_fs,y_eval)\n\nmean_abs_error,mean_sq_error,root_mean_sq_error,r2_scr,median_abs_score,explained_variance = evaluate_metrics(x_eval_fs,y_eval,y_pred,rfr)\n\nprint(\"METRICS  :\\n\\nMean Absolute Error :  \",mean_abs_error,\"\\nScore :   \",scr,\"\\nMean Squared Error :  \",mean_sq_error,\"\\nRoot Mean Squared Error :  \",root_mean_sq_error,\"\\nR2 Square :  \",r2_scr,\"\\nMedian Absolute Score :  \",median_abs_score,\"\\nExplained Variance Score :  \",explained_variance)    ","45569cff":"predicted_price['random_forest_price'] = np.exp(y_s.inverse_transform(rfr.predict(x_test_fs).reshape(rfr.predict(x_test_fs).shape[0],1))).reshape(ridge_mod.predict(x_test_fs).shape[0]).round()\nreg_metrics['RANDOM FOREST'] = [mean_abs_error,scr,mean_sq_error,root_mean_sq_error,r2_scr,median_abs_score,explained_variance]    \nplot_regression_line(x_eval_fs.index,y_eval,y_pred)","cdf36095":"dtr = DecisionTreeRegressor(max_depth = 8,random_state= 2)\ndtr.fit(x_train,y_train)\ny_pred1 = dtr.predict(x_eval)\nmean_abs_error,mean_sq_error,root_mean_sq_error,r2_scr,median_abs_score,explained_variance = evaluate_metrics(x_eval,y_eval,y_pred,dtr)\nscr = dtr.score(x_eval,y_eval)\nprint(\"METRICS  :\\n\\nMean Absolute Error :  \",mean_abs_error,\"\\nScore :   \",scr,\"\\nMean Squared Error :  \",mean_sq_error,\"\\nRoot Mean Squared Error :  \",root_mean_sq_error,\"\\nR2 Square :  \",r2_scr,\"\\nMedian Absolute Score :  \",median_abs_score,\"\\nExplained Variance Score :  \",explained_variance)   ","159e20fc":"reg_metrics['DECISION TREE'] = [mean_abs_error,scr,mean_sq_error,root_mean_sq_error,r2_scr,median_abs_score,explained_variance]\npredicted_price['decision_tree_price'] = np.exp(y_s.inverse_transform(dtr.predict(x_test_fs).reshape(rfr.predict(x_test_fs).shape[0],1))).reshape(ridge_mod.predict(x_test_fs).shape[0]).round()\nplot_regression_line(x_eval.index,y_eval,y_pred)","9baf7191":"xgb_model = xgb.XGBRegressor(max_depth = 12,eta = 0.3,n_estimators = 100,objective = 'reg:squarederror',gamma = 0.01)\nxgb_model.fit(x_train,y_train)\ny_pred = xgb_model.predict(x_eval)\nmean_abs_error,mean_sq_error,root_mean_sq_error,r2_scr,median_abs_score,explained_variance = evaluate_metrics(x_eval,y_eval,y_pred,dtr)\nscr = xgb_model.score(x_eval,y_eval)\nprint(\"METRICS  :\\n\\nMean Absolute Error :  \",mean_abs_error,\"\\nScore :   \",scr,\"\\nMean Squared Error :  \",mean_sq_error,\"\\nRoot Mean Squared Error :  \",root_mean_sq_error,\"\\nR2 Square :  \",r2_scr,\"\\nMedian Absolute Score :  \",median_abs_score,\"\\nExplained Variance Score :  \",explained_variance)   ","b94ad3d2":"x_test = x_test[x_train.columns]\nreg_metrics['XGB_REGRESSION'] = [mean_abs_error,scr,mean_sq_error,root_mean_sq_error,r2_scr,median_abs_score,explained_variance]\npredicted_price['xgb_regression_price'] = np.exp(y_s.inverse_transform(xgb_model.predict(x_test).reshape(rfr.predict(x_test_fs).shape[0],1))).reshape(ridge_mod.predict(x_test_fs).shape[0]).round()\nplot_regression_line(x_eval.index,y_eval,y_pred)","40e63624":"metric_names = [\"MEAN ABSOLUTE ERROR\",\"MODEL SCORE\",\"MEAN SQUARED ERROR\",\"ROOT MEAN SQUARED ERROR\",\"R2 SCORE\",\"MEDIAN ABSOLUTE ERROR\",\"EXPLAINED VARIANCE SCORE\"]","701fc6e6":"for col in reg_metrics.keys():\n    reg_metrics[col] = np.around(reg_metrics[col],4).astype('str')","f065c7ca":"computed_metrics = pd.DataFrame(reg_metrics,index = metric_names).T\ncomputed_metrics.T","2a6ff288":"test_data_1.columns","18597afd":"test_data_1.columns = ['AIRLINE','DATE OF JOURNEY','SOURCE','DESTINATION','DEPARTURE TIME','ARRIVAL TIME','DURATION','TOTAL STOPS','ADDITIONAL INFO']\n\noutput = test_data_1\n\noutput['PREDICTED PRICE(RIDGE REGRESION)'] = predicted_price['ridge_regression_price']\noutput['PREDICTED PRICE(LASSO REGRESION)'] = predicted_price['lasso_regression_price']\noutput['PREDICTED PRICE(RANDOM FOREST REGRESION)'] = predicted_price['random_forest_price']\noutput['PREDICTED PRICE(DECISION TREE REGRESION)'] = predicted_price[ 'decision_tree_price']\noutput['PREDICTED PRICE(XGBOOST REGRESION)'] = predicted_price['xgb_regression_price']","9f943bc6":"output","87c3ccea":"output['PREDICTED PRICE(RANDOM FOREST REGRESION)'].to_csv('PREDICTED PRICE(RANDOM FOREST REGRESION).csv')\noutput['PREDICTED PRICE(XGBOOST REGRESION)'].to_csv('PREDICTED PRICE(XGBOOST REGRESION).csv')\noutput['PREDICTED PRICE(DECISION TREE REGRESION)'].to_csv('PREDICTED PRICE(DECISION TREE REGRESION).csv')","c9c197fb":"computed_metrics[\"ROOT MEAN SQUARED ERROR\"].to_frame().T","ff6df6c9":"### TEST - TRAIN - EVALUATION DATA SPLIT","cc257b25":"### Merging the Categorical and Numerical Data","7cb24441":"### COMPUTED METRICS","42392f24":"### AIR TICKET FARE PREDICTION - MISHA DEY - 1828166","9cf70f2c":" ### COMPUTATION OF OUR ESTIMATED PAYMENT DATE ","3cc67e16":"### ONE-HOT ENCODING THE CATEGORICAL FEATURES","561c2b4a":"selection = VarianceThreshold(threshold=0.01) # of more that 99% values are same -- we remove the column\n\ncols = list(set(train_data.columns) - set(['Dep_Time','Date_of_Journey_year','Arrival_Time','Duration']))\n\nselection.fit(train_data[cols])\n\nprint(\"No. of Features that are Quasi-Constant : \",(len(cols) - sum(selection.get_support())))\n\nquasi_ = list(selection.get_support())\n\nfor i in range(len(quasi_)):\n    if quasi_[i] == False:\n        print(\"The Quasi-Constant Feature in train data is  :\",cols[i])\n        train_data=train_data.drop(columns=[cols[i]])\nfor i in range(len(quasi_)):\n    if quasi_[i] == False:\n        print(\"The Quasi-Constant Feature in test data is  :\",cols[i])\n        test_dataset=test_dataset.drop(columns=[cols[i]])\n","c003706c":"### BAR PLOT ","7bef9b3e":"### 4. DECISION TREE REGRESSOR","ce0c7be1":"### COVARIANCE MATRIX","c108f9e1":"### DATE-TIME CONVERSION","71a1b7d1":"### DISTRIBUTION PLOTS","b2865aa1":"### 5. XGB REGRESSOR","f774f536":"### 1. RIDGE REGRESSION","3274b01d":"### EXTRACTING MORE INFO FROM THE DEPARTURE DATE AND TIME","57d520b4":"### FEATURE ENGINEERING AND FEATURE GENERATION","12995d9f":"### FILTERING OUT THE QUASI-CONSTANT FEATURE","eaba6cc5":"### EXPLORATORY DATA ANALYSIS","ce5ba733":"### SCATTER PLOTS ","6f7ee927":"### CORRELATION MATRIX","25a47639":"### DATA VISUALIZATION","b4b5db04":"### SCALING THE NUMERICAL FEATURES","29f3e879":"### FILTERING OUT THE CONSTANT FEATURES","54a3ca26":"### LABEL ENCODING OF CATEGORICAL FEATURES","f5b6e1d1":"### Removing the duplicate values","55948cf6":"### 2. LASSO REGRESSION","dc874f62":" ### 3. RANDOM FOREST REGRESSOR","688ab791":"### Removing the Null Values","e0aadc7c":"### MODEL TRAINING , PREDICTION AND EVALUATION","79752556":"### PIE PLOT","9199c89c":"### FINAL ROOT MEAN SQUARE VALUES","4398bed9":"### LOG TRANSFORMATION OF 'PRICE' COLUMN"}}