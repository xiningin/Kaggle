{"cell_type":{"e6a8b611":"code","0bfd1da8":"code","d776e017":"code","8d1c8264":"code","065b4d1a":"code","f5104ea7":"code","8cbaa93b":"code","38cb4788":"code","93192496":"code","bfe78b66":"code","b4374620":"code","ce1c4206":"code","cb9f5f66":"code","3fe3f511":"code","7bd9e132":"code","2aed9344":"code","ae3a84f0":"code","2d3bb142":"code","889415f6":"code","38be8bda":"code","abc36326":"code","dc6e57d4":"code","49b25f0c":"code","fe55efa7":"code","f81c55b6":"code","1d17a48c":"code","b8647d8f":"code","6b4aecbf":"code","60b6abf9":"code","d9ce5d01":"code","737b7711":"code","b80e0031":"code","ce2abe64":"code","e58c5f2b":"code","da72b7ae":"code","51fb77fa":"code","4c9e30c9":"code","3e8f6c38":"code","65513384":"code","66faa08a":"code","bc675164":"code","66a36747":"code","2b3dba28":"code","7261d406":"code","feb15b96":"code","b5cfc99a":"code","6902829c":"code","ea55f4f5":"code","0e6e1c37":"code","b499244b":"code","5d4e4857":"code","36387c04":"code","e7caebb7":"code","fb579645":"code","6c0c11b9":"code","295a313a":"code","d72b1d88":"code","04b0cd73":"code","a7db2941":"code","72e8b0a6":"code","c8e4b7d2":"code","cf2ab7c2":"code","2df55d7f":"code","3c4388df":"code","5f65c6d7":"code","bad67d1b":"code","6ffc5be6":"code","52fb38fe":"code","efb8092e":"code","cc2d9c0f":"markdown","64725217":"markdown","1a762d50":"markdown","5cbbd107":"markdown","97490e81":"markdown","066c404a":"markdown","1a9a9e53":"markdown","c7f3e697":"markdown","e303f6b5":"markdown","6bdb0405":"markdown","2011c3c2":"markdown","ffb14900":"markdown","07b8de31":"markdown","9d86a364":"markdown","35d51ac4":"markdown","923f02e4":"markdown","398b204d":"markdown","e69a3f48":"markdown","d6a42a9b":"markdown","d5701b15":"markdown","c9f9d6f2":"markdown","ecf78525":"markdown","0e3ccdef":"markdown","23fbdb3a":"markdown","3058d79c":"markdown","2c249aa8":"markdown","3281bef1":"markdown","877f13bf":"markdown","77318974":"markdown","8af4257f":"markdown","79e75beb":"markdown","8df49fb6":"markdown","dc3ce234":"markdown","1cd1ccea":"markdown","707416e6":"markdown","6b8342da":"markdown","8ed8b3a7":"markdown","12edac6d":"markdown","2243e0cb":"markdown","d267681c":"markdown"},"source":{"e6a8b611":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0bfd1da8":"!pip install -Uqq fastbook kaggle waterfallcharts treeinterpreter dtreeviz\nimport fastbook\nfastbook.setup_book()","d776e017":"#hide\nfrom fastbook import *\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\nfrom fastai.tabular.all import *\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom dtreeviz.trees import *\nfrom IPython.display import Image, display_svg, SVG\n\npd.options.display.max_rows = 20\npd.options.display.max_columns = 8","8d1c8264":"path = '\/kaggle\/input\/tabular-playground-series-jul-2021\/'\ntrain = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jul-2021\/train.csv', low_memory= False)\ntrain.head()\n","065b4d1a":"target_carbon_monoxide = train.target_carbon_monoxide.values\ntarget_benzene = train.target_benzene.values\ntarget_nitrogen_oxides = train.target_nitrogen_oxides.values\n","f5104ea7":"train_carbon_monoxide = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jul-2021\/train.csv', low_memory= False)\ntrain_carbon_monoxide.drop(['target_benzene','target_nitrogen_oxides'], axis=1, inplace= True)\ntrain_carbon_monoxide.head()\n","8cbaa93b":"train_benzene = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jul-2021\/train.csv', low_memory= False)\ntrain_benzene.drop(['target_carbon_monoxide','target_nitrogen_oxides'], axis=1, inplace= True)\ntrain_benzene.head()\n","38cb4788":"train_nitrogen_oxides = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jul-2021\/train.csv', low_memory= False)\ntrain_nitrogen_oxides.drop(['target_carbon_monoxide','target_benzene'], axis=1, inplace= True)\ntrain_benzene.head()","93192496":"test = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jul-2021\/test.csv', low_memory= False)\ntest.head()\n\n","bfe78b66":"sample_submission = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jul-2021\/sample_submission.csv',low_memory=False)\nsample_submission","b4374620":"train.columns","ce1c4206":"dep_var_tcm = 'target_carbon_monoxide'\ndep_var_tb = 'target_benzene'\ndep_var_tno ='target_nitrogen_oxides'","cb9f5f66":"train_carbon_monoxide[dep_var_tcm]= np.log(train_carbon_monoxide[dep_var_tcm])\ntrain_benzene[dep_var_tb]= np.log(train_benzene[dep_var_tb])\ntrain_nitrogen_oxides[dep_var_tno]= np.log(train_nitrogen_oxides[dep_var_tno])","3fe3f511":"train_carbon_monoxide = add_datepart(train_carbon_monoxide, 'date_time')\ntrain_benzene = add_datepart(train_benzene, 'date_time')\ntrain_nitrogen_oxides = add_datepart(train_nitrogen_oxides, 'date_time')","7bd9e132":"' '.join(o for o in train_carbon_monoxide.columns if o.startswith('date'))\n' '.join(o for o in train_benzene.columns if o.startswith('date'))\n' '.join(o for o in train_nitrogen_oxides.columns if o.startswith('date'))","2aed9344":"train_nitrogen_oxides.head()","ae3a84f0":"train_nitrogen_oxides.columns","2d3bb142":"test = add_datepart(test, 'date_time')\n' '.join(o for o in test.columns if o.startswith('date'))","889415f6":"procs = [Categorify, FillMissing]","38be8bda":"#first for train_carbon_monoxide\ncond = (train_carbon_monoxide.date_timeYear<2011) & (train_carbon_monoxide.date_timeMonth<10)\n\ntrain_cm_idx = np.where( cond)[0]\ntrain_bz_idx =np.where(cond)[0]\ntrain_no_idx= np.where(cond)[0]\nvalid_cm_idx = np.where(~cond)[0]\nvalid_bz_idx = np.where(~cond)[0]\nvalid_no_idx = np.where(~cond)[0]\n\nsplits_cm = (list(train_cm_idx),list(valid_cm_idx))\nsplits_bz = (list(train_bz_idx),list(valid_bz_idx))\nsplits_no = (list(train_no_idx),list(valid_no_idx))\n","abc36326":"print(len(splits_cm[1]))","dc6e57d4":"cont_cm,cat_cm = cont_cat_split(train_carbon_monoxide, 1, dep_var=dep_var_tcm)\ncont_bz,cat_bz = cont_cat_split(train_benzene, 1, dep_var=dep_var_tb)\ncont_no,cat_no = cont_cat_split(train_nitrogen_oxides, 1, dep_var=dep_var_tno)","49b25f0c":"from fastai.tabular import *\n#for NN\ndata_cm = TabularDataLoaders.from_df(train_carbon_monoxide, cat_names=cat_cm, cont_names=cont_cm, procs=procs, \n                                 y_names=\"target_carbon_monoxide\", bs=64)\ndata_bz = TabularDataLoaders.from_df(train_benzene, cat_names=cat_bz, cont_names=cont_bz, procs=procs, \n                                 y_names=\"target_benzene\", bs=64)\ndata_no = TabularDataLoaders.from_df(train_nitrogen_oxides, cat_names=cat_no, cont_names=cont_no, procs=procs, \n                                 y_names=\"target_nitrogen_oxides\", bs=64)","fe55efa7":"to_cm = TabularPandas(train_carbon_monoxide, procs, cat_cm, cont_cm, y_names=dep_var_tcm, splits=splits_cm)\nto_bz = TabularPandas(train_benzene, procs, cat_bz, cont_bz, y_names=dep_var_tb, splits=splits_bz)\nto_no = TabularPandas(train_nitrogen_oxides, procs, cat_no, cont_no, y_names=dep_var_tno, splits=splits_no)","f81c55b6":"len(to_bz.train),len(to_bz.valid)","1d17a48c":"to_bz.show(3)","b8647d8f":"to_bz.items.head(3)","6b4aecbf":"#if required saved the processed dataset using below given code and load it.\n#save_pickle(path\/'to.pkl',to)\n#To read this back later, you would type:\n#to = (path\/'to.pkl').load()","60b6abf9":"xs_cm,y_cm = to_cm.train.xs,to_cm.train.y\nxs_bz,y_bz = to_bz.train.xs,to_bz.train.y\nxs_no,y_no = to_no.train.xs,to_no.train.y\nvalid_xs_cm,valid_y_cm = to_cm.valid.xs,to_cm.valid.y\nvalid_xs_bz,valid_y_bz = to_bz.valid.xs,to_bz.valid.y\nvalid_xs_no,valid_y_no = to_no.valid.xs,to_no.valid.y","d9ce5d01":"print(xs_cm.columns)","737b7711":"#First doing some Decision tree evaluation on carbon monoxide dataset\nm_cm= DecisionTreeRegressor(max_leaf_nodes=4)\nm_cm.fit(xs_cm, y_cm);","b80e0031":"draw_tree(m_cm, xs_cm, size=10, leaves_parallel=True, precision=2)","ce2abe64":"samp_idx = np.random.permutation(len(y_cm))[:500]\ndtreeviz(m_cm, xs_cm.iloc[samp_idx], y_cm.iloc[samp_idx], xs_cm.columns, dep_var_tcm,\n        fontname='DejaVu Sans', scale=1.6, label_fontsize=10,\n        orientation='LR')","e58c5f2b":"m_cm = DecisionTreeRegressor()\nm_bz=DecisionTreeRegressor()\nm_no=DecisionTreeRegressor()\n\nm_cm.fit(xs_cm, y_cm);\nm_bz.fit(xs_bz, y_bz);\nm_no.fit(xs_no, y_no);","da72b7ae":"def r_mse(pred,y): return round(math.sqrt(((pred-y)**2).mean()), 6)\ndef m_rmse(m, xs, y): return r_mse(m.predict(xs), y)","51fb77fa":"m_rmse(m_cm, xs_cm, y_cm)\nm_rmse(m_bz, xs_bz, y_bz)\nm_rmse(m_no, xs_no, y_no)","4c9e30c9":"m_rmse(m_cm, valid_xs_cm, valid_y_cm)\n","3e8f6c38":"m_cm.get_n_leaves(), len(xs_cm)","65513384":"m_cm = DecisionTreeRegressor(min_samples_leaf=25)\nm_cm.fit(to_cm.train.xs, to_cm.train.y)\nm_rmse(m_cm, xs_cm, y_cm), m_rmse(m_cm, valid_xs_cm, valid_y_cm)","66faa08a":"#Checking number of leaves again\nm_cm.get_n_leaves()","bc675164":"pred_cm = m_cm.predict(test)\npred_bz= m_bz.predict(test)\npred_no= m_no.predict(test)","66a36747":"## create submission for DTR\n#sample_submission[sample_submission.columns[1]] = pred_cm\n#sample_submission[sample_submission.columns[2]] = pred_bz\n#sample_submission[sample_submission.columns[3]] = pred_no\n#sample_submission\n","2b3dba28":"#sample_submission.to_csv('submission_clf_gscv.csv', index=False)","7261d406":"def rf(xs, y, n_estimators=40, max_samples=4902,\n       max_features=0.5, min_samples_leaf=5, **kwargs):\n    return RandomForestRegressor(n_jobs=-1, n_estimators=n_estimators,\n        max_samples=max_samples, max_features=max_features,\n        min_samples_leaf=min_samples_leaf, oob_score=True).fit(xs, y)","feb15b96":"m_cm = rf(xs_cm, y_cm);\nm_bz = rf(xs_bz, y_bz);\nm_no = rf(xs_no, y_no);","b5cfc99a":"\nm_rmse(m_cm, xs_cm, y_cm), m_rmse(m_cm, valid_xs_cm, valid_y_cm)\n\n","6902829c":"def rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)","ea55f4f5":"#for carbon monoxide dataset\nfi_cm = rf_feat_importance(m_cm, xs_cm)\nfi_cm[:10]","0e6e1c37":"#for benzene dataset\nfi_bz = rf_feat_importance(m_bz, xs_bz)\nfi_bz[:10]","b499244b":"#for nitrogen oxide dataset\nfi_no = rf_feat_importance(m_no, xs_no)\nfi_no[:10]","5d4e4857":"def plot_fi(fi):\n    return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)\n\nplot_fi(fi_no[:30]);","36387c04":"#for cm\nto_keep_cm = fi_cm[fi_cm.imp>0.008].cols\nlen(to_keep_cm)","e7caebb7":"#for bz\nto_keep_bz = fi_bz[fi_bz.imp>0.008].cols\nlen(to_keep_bz)","fb579645":"#for cm\nto_keep_no = fi_no[fi_no.imp>0.008].cols\nlen(to_keep_no)","6c0c11b9":"xs_imp_cm = xs_cm[to_keep_cm]\nxs_imp_bz = xs_bz[to_keep_bz]\nxs_imp_no = xs_no[to_keep_no]","295a313a":"valid_xs_imp_cm = valid_xs_cm[to_keep_cm]\nvalid_xs_imp_bz = valid_xs_bz[to_keep_bz]\nvalid_xs_imp_no = valid_xs_no[to_keep_no]","d72b1d88":"m_cm = rf(xs_imp_cm, y_cm)","04b0cd73":"m_rmse(m_cm, xs_imp_cm, y_cm), m_rmse(m_cm, valid_xs_imp_cm, valid_y_cm)","a7db2941":"cluster_columns(xs_imp_cm)","72e8b0a6":"cluster_columns(xs_imp_bz)","c8e4b7d2":"cluster_columns(xs_imp_no)","cf2ab7c2":"train_carbon_monoxide.dtypes","2df55d7f":"max_y_cm= np.max(train_carbon_monoxide['target_carbon_monoxide'])*1.2\ny_range_cm = torch.tensor([0, max_y_cm])\ny_range_cm","3c4388df":"max_y_bz= np.max(train_benzene['target_benzene'])*1.2\ny_range_bz = torch.tensor([0, max_y_bz])\ny_range_bz","5f65c6d7":"max_y_no= np.max(train_nitrogen_oxides['target_nitrogen_oxides'])*1.2\ny_range_no = torch.tensor([0, max_y_no])\ny_range_no","bad67d1b":"#learner for carbon_monoxide dataset\nlearn_cm = tabular_learner(data_cm, layers=[1000,500], \n                        y_range=y_range_cm, metrics=rmse)\n#learner for benzene dataset\nlearn_bz = tabular_learner(data_bz, layers=[1000,500], \n                        y_range=y_range_bz, metrics=rmse)\n#learner for nitrogen oxides dataset\nlearn_no = tabular_learner(data_no, layers=[1000,500], \n                        y_range=y_range_no, metrics=rmse)","6ffc5be6":"learn_cm.model","52fb38fe":"learn_bz.model","efb8092e":"print(pred_no)","cc2d9c0f":"Only 12 columns here. 'target_carbon_monoxide','target_benzene','target_nitrogen_oxides' are the target columns.","64725217":"In this one, date_timeDayofyear, date_timeElapsed, date_timeWeek are merging very early and two of these can be removed.","1a762d50":"Defining our dependednt and independent variables first","5cbbd107":"**feature importance**","97490e81":"Saving the pre-processed dataset to be used at later stage directly","066c404a":"First trying decision trees","1a9a9e53":"We can display the same information using Terence Parr's treeviz library:","c7f3e697":"Now we will tell TabularPandas which columns are coninuous and which are categorical. We will do it automatically using function cont_cat_split","e303f6b5":"We will do the same for test dataset","6bdb0405":"Our validation RMSE has definitly improved compared to DecisionTreesregressor","2011c3c2":"Model is overfitting big time and the reason is we have as many leaf_nodes as data points","ffb14900":"date_timeDayofyear and date_timeElapsed are very close , so we can remove for carbon_monoxide dataset, let's see the same for nitrogen_oxides and benzene","07b8de31":"\nNo, obvious outliers seen here, so no modification of dataset is required","9d86a364":"Let's see the result","35d51ac4":"We will create a small function to check the RMSE","923f02e4":"We need to take care of the dates properly. We would want our model to make decisions based on the knowledge how recent a date or what day of the week is it or a month. To do this, we replace every date column with a set of date metadata columns, such as holiday, day of week, and month. These columns provide categorical data that we suspect will be useful.We will use fastai's add_datapart function to do this.","398b204d":"No such dependent variables left","e69a3f48":"For simplicity the number of nodes are just 4. Let's see how it looks.","d6a42a9b":"Creating the decision tree first","d5701b15":"That's way better DT","c9f9d6f2":"Let's create a bigger decision tree for all three datasets, here we are not passing any stopping criteria such as max_leaf_nodes","ecf78525":"Look at the data","0e3ccdef":" **There are three target columns. So we will treat this problem as three different problem. I will be proceeding with three datasets one for each target**","23fbdb3a":" we want to limit the gases conc to be within the history gases conc values, so we need to calculate the y_range. Note that we multiplied the maximum of Saleprice by 1.2 so when we apply sigmoid the upper limit will also be covered","3058d79c":"We can make a decision tree because our data is all numeric and has no missing values","2c249aa8":"Specifying low_memory = False, which is True by default , helps pandas look into the entire dataset","3281bef1":"Our evaluation metric is root mean squared log error(RMSLE) between the actual and predicted values.We will take the log of dependent variables  and we will get what we need.\n","877f13bf":"Creating a random forest classifier","77318974":"Let's get the prediction using DTregressor on all the three datasets","8af4257f":"This check was on the training set, let's check the validation set","79e75beb":"Removing the columns with low importance. Let's try keeping the columns with a feature importance 0.008","8df49fb6":"The reson is sklearn's default settings which allow it to continue splitting nodes until there is one item in each leaf node. Change the stopping rule to ensure every leaf node contains at least 25 auction records","dc3ce234":"Using fastai's TabularPandas and TabularProc to do preprocessing of the data","1cd1ccea":"Accuracy is almost same, but there are lesser columns to deal with","707416e6":"Decision trees have never been visualized better than the above picture.The top node represents the initial model before any splits have been done, when all the data is in one group. We can see it predicts a value of 0.41 for the logarithm of the 'target_carbon_monoxide','target_benzene','target_nitrogen_oxides' columns. It gives a mean squared error of 0.48. We can also see that there are 4902 entries which is equal to our training set. Final information is that decision criterion for best split was found at column sensor2.","6b8342da":"For all the three datasets sensor2 dataset is the most important, others keep going up and down. As this stat was also proven by decision trees","8ed8b3a7":"This notebook is based on the fastai colab notebook: https:\/\/colab.research.google.com\/github\/fastai\/fastbook\/blob\/master\/09_tabular.ipynb#scrollTo=KuB9u4cudJMx","12edac6d":"Removing redundant features","2243e0cb":"That's much better","d267681c":"Because this is a TimeSeries we have to careful when doing the partition for train and validation set. If we will take a closer look at the date range in the test set, we will discover that it covers 4 month period from Jan 2011, which is later in time than any date in the training set. Its a good design becuase we have to make a model which predict in the future. So, if we want to have a useful validation set, we want the validation set to be later in the time than the training set. Our training set ends by December 2010, so we will define narrower training set which consists of the training data from before November 2010, and we'll define a validation set consisting of data after Novemebr 2010"}}