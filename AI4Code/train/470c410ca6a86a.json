{"cell_type":{"be02ef2d":"code","f0f75e6d":"code","f9ef96af":"code","ef6362db":"code","868fc817":"code","dc48fdd3":"code","9544e708":"code","f6f309ab":"code","648eb99a":"code","19f8d1cd":"code","adc9611c":"code","df30107e":"code","3e872ea0":"code","428d6678":"code","60647654":"code","8ac0d3a7":"code","51a8cc07":"code","facafa22":"code","8cc16299":"code","c4ce8f4c":"code","0bd24920":"code","dd2fe653":"code","12c4fe5a":"code","64210f36":"code","790e5e64":"code","797fd84e":"code","5bfdd224":"code","2a698be8":"code","3c81ca83":"code","aec2a2a5":"code","08a211b8":"code","4f113597":"code","0004c7fc":"code","d19bdd8f":"code","882d9ef3":"code","f4250e98":"code","0f65d2aa":"code","78dc99cb":"code","b02ae06d":"code","5dc3df3c":"code","92ec8b12":"code","4479c7e4":"code","c82b4061":"code","25db1985":"code","e46fcd85":"code","f3cbd7ec":"code","76dd23d0":"code","9ffa183c":"code","641587e1":"code","745fea5b":"code","475bba37":"code","5261d044":"code","f55bd782":"code","2dfb3362":"code","90f2d57f":"code","cf0e95e1":"code","211fc1d1":"code","56de1371":"code","8606ca8c":"code","8b3270de":"code","b5c29c79":"code","28348ae2":"code","d5d01018":"code","f32debf5":"code","8e73ca51":"code","ffdd739d":"code","8c1ed991":"code","0c0d864e":"code","fb63b28a":"code","2de029e6":"code","ca6f31f2":"markdown","4594319b":"markdown","f849b1fe":"markdown","46cddaa4":"markdown","8e2f65d3":"markdown","c7e0249a":"markdown","0192e5ae":"markdown","6687e8b9":"markdown","068120a0":"markdown","c31f32f3":"markdown","3ec8581e":"markdown","21f400fe":"markdown","30f70f02":"markdown","6076fe85":"markdown","511409be":"markdown","51302a27":"markdown","0855a542":"markdown","8c0443d0":"markdown","f0b450f5":"markdown","12efd9e3":"markdown","ecbcba1e":"markdown","e2f05363":"markdown","3c1cfdd1":"markdown","986c34aa":"markdown","4a80153a":"markdown","11d29701":"markdown","fbb96548":"markdown","e5600f83":"markdown","7fa15e1e":"markdown","a91dadfe":"markdown","521f7bd0":"markdown","eac3f668":"markdown","b2dfbf7d":"markdown","6f49c145":"markdown"},"source":{"be02ef2d":"import numpy as np\n\nimport matplotlib.pyplot as plt\nimport matplotlib\n%matplotlib inline\n\nplt.gray()\n\nimport skimage.filters\n\nimport scipy.ndimage\n\nimport sklearn.feature_extraction\nimport sklearn.cluster\n\nimport skimage.feature\nimport skimage.transform\n\nimport PIL\n\nimport sys\nfor name, module in sorted(sys.modules.items()):\n    if name in ['numpy', 'matplotlib', 'skimage', 'scipy', 'sklearn', 'PIL']:\n        if hasattr(module, '__version__'): \n            print(name, module.__version__)","f0f75e6d":"def plot_file(filename):\n    image = plt.imread(filename)\n    hist = np.histogram(image - image.mean(),\n                        bins=np.arange(image.min(),\n                                       image.max(),\n                                       1\/256))\n\n    fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n    \n    axes[0].imshow(image, interpolation='nearest')\n    axes[0].axis('off')\n    axes[0].set_title(filename[-20:])\n    \n    axes[1].plot(hist[1][:-1], hist[0], lw=2)\n    axes[1].set_title('histogram of gray values')\n    \n    plt.show()","f9ef96af":"plot_file('..\/input\/train\/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_red.png')\nplot_file('..\/input\/train\/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_green.png')\nplot_file('..\/input\/train\/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_blue.png')\nplot_file('..\/input\/train\/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_yellow.png')","ef6362db":"def plot_cut(uuid, title, threashold_function):\n    \"\"\"Takes an uuid, a title for the plot and a function to apply on the image and obtain a threashold\n    and plot the black and white image generated by the binary result of the inequality image > threashold\"\"\"\n    \n    def set_title(title, threashold):\n        if np.shape(threashold) != ():\n            plt.title('%s threashold=[%s]' % (title, str(np.shape(threashold))))\n        else:\n            plt.title('%s threashold=%0.3f' % (title, threashold))\n\n    red    = f'..\/input\/train\/{uuid}_red.png'\n    green  = f'..\/input\/train\/{uuid}_green.png'\n    blue   = f'..\/input\/train\/{uuid}_blue.png'\n    yellow = f'..\/input\/train\/{uuid}_yellow.png'\n    \n    fig = plt.figure(figsize=(15, 4))\n    fig.suptitle(title, fontsize=24)\n    \n    plt.subplot(1,4,1)\n    image = plt.imread(red)\n    threashold = threashold_function(image)\n    plt.imshow(image > threashold)\n    set_title('red', threashold)\n\n    plt.subplot(1,4,2)\n    image = plt.imread(green)\n    threashold = threashold_function(image)\n    plt.imshow(image > threashold)\n    set_title('green', threashold)\n\n    plt.subplot(1,4,3)\n    image = plt.imread(blue)\n    threashold = threashold_function(image)\n    plt.imshow(image > threashold)\n    set_title('blue', threashold)\n\n    plt.subplot(1,4,4)\n    image = plt.imread(yellow)\n    threashold = threashold_function(image)\n    plt.imshow(image > threashold)\n    set_title('yellow', threashold)\n\n    plt.show()","868fc817":"plot_cut('002daad6-bbc9-11e8-b2bc-ac1f6b6435d0', \"zero\", lambda image: 0)\n\nplot_cut('002daad6-bbc9-11e8-b2bc-ac1f6b6435d0', \"%5 percentile\", lambda image: np.percentile(image, 5))\n\nplot_cut('002daad6-bbc9-11e8-b2bc-ac1f6b6435d0', \"mean\", lambda image: image.mean())\n\nplot_cut('002daad6-bbc9-11e8-b2bc-ac1f6b6435d0', \"%95 percentile\", lambda image: np.percentile(image, 95))","dc48fdd3":"plot_cut('002daad6-bbc9-11e8-b2bc-ac1f6b6435d0', \"skimage.filters.threshold_otsu\", skimage.filters.threshold_otsu)\nplot_cut('002daad6-bbc9-11e8-b2bc-ac1f6b6435d0', \"skimage.filters.threshold_yen\", skimage.filters.threshold_yen)\nplot_cut('002daad6-bbc9-11e8-b2bc-ac1f6b6435d0', \"skimage.filters.threshold_isodata\", skimage.filters.threshold_isodata)\nplot_cut('002daad6-bbc9-11e8-b2bc-ac1f6b6435d0', \"skimage.filters.threshold_li\", skimage.filters.threshold_li)\nplot_cut('002daad6-bbc9-11e8-b2bc-ac1f6b6435d0', \n         \"skimage.filters.threshold_local(image, block_size=3)\", \n         lambda image: skimage.filters.threshold_local(image, block_size=3))\nplot_cut('002daad6-bbc9-11e8-b2bc-ac1f6b6435d0', \n         \"skimage.filters.threshold_local(image, block_size=7)\", \n         lambda image: skimage.filters.threshold_local(image, block_size=7))\ntry:\n    plot_cut('002daad6-bbc9-11e8-b2bc-ac1f6b6435d0', \"skimage.filters.threshold_minimum\", skimage.filters.threshold_minimum)\nexcept:\n    pass\nplot_cut('002daad6-bbc9-11e8-b2bc-ac1f6b6435d0', \"skimage.filters.threshold_niblack\", skimage.filters.threshold_niblack)\nplot_cut('002daad6-bbc9-11e8-b2bc-ac1f6b6435d0', \"skimage.filters.threshold_sauvola\", skimage.filters.threshold_sauvola)\nplot_cut('002daad6-bbc9-11e8-b2bc-ac1f6b6435d0', \"skimage.filters.threshold_triangle\", skimage.filters.threshold_triangle)","9544e708":"image = plt.imread('..\/input\/train\/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_yellow.png')\n\ncutted = np.array(image > skimage.filters.threshold_li(image))","f6f309ab":"cutted.shape, cutted.dtype","648eb99a":"cutted.shape[0] * cutted.shape[1]","19f8d1cd":"(cutted.shape[0] * cutted.shape[1]) \/ 8","adc9611c":"(cutted.shape[0] * cutted.shape[1]) \/ 8 \/ 8","df30107e":"packed = np.zeros((int(cutted.shape[0] \/ 8), int(cutted.shape[1] \/ 8)),\n                  dtype=np.uint64)\n\nfor x in range(cutted.shape[0]):\n    for y in range(cutted.shape[1]):\n        new_bit = np.uint64(int(cutted[x][y]) << (x % 8) << ((y % 8) * 8))\n        packed[int(x\/8)][int(y\/8)] = np.bitwise_or(packed[int(x\/8)][int(y\/8)], new_bit)\n\nplt.figure(figsize=(15, 4))\n\nplt.subplot(1,3,1)\nplt.title(f'original {str(image.nbytes)} bytes')\nplt.imshow(image)\n\nplt.subplot(1,3,2)\nplt.title(f'cutted {str(cutted.nbytes)} bytes')\nplt.imshow(cutted)\n\nplt.subplot(1,3,3)\nplt.title(f'packed {str(packed.nbytes)} bytes')\nplt.imshow(packed)","3e872ea0":"re = np.zeros((cutted.shape[0],cutted.shape[1]), dtype=bool)\n\nfor x in range(cutted.shape[0]):\n    for y in range(cutted.shape[1]):\n        re[x][y] = np.bitwise_and(np.uint64(1 << (x % 8) + (y % 8) * 8 ), packed[int(x\/8)][int(y\/8)])\n\nplt.figure(figsize=(15, 4))\n\nplt.subplot(1,3,1)\nplt.title('original')\nplt.imshow(image)\n\nplt.subplot(1,3,2)\nplt.title('cutted')\nplt.imshow(cutted)\n\nplt.subplot(1,3,3)\nplt.title('decompressed')\nplt.imshow(re)","428d6678":"plt.imshow(packed)","60647654":"def pack_image(cutted):\n    packed = np.zeros((int(cutted.shape[0] \/ 8), int(cutted.shape[1] \/ 8)),\n                      dtype=np.uint64)\n    for x in range(cutted.shape[0]):\n        for y in range(cutted.shape[1]):\n            new_bit = np.uint64(int(cutted[x][y]) << (x % 8) << ((y % 8) * 8))\n            packed[int(x\/8)][int(y\/8)] = np.bitwise_or(packed[int(x\/8)][int(y\/8)], new_bit)\n    return packed\n%timeit pack_image(cutted)","8ac0d3a7":"%timeit skimage.transform.resize(cutted, (cutted.shape[0]\/8,cutted.shape[1]\/8), mode='reflect')","51a8cc07":"re = skimage.transform.resize(cutted, (cutted.shape[0]\/8,cutted.shape[1]\/8), mode='reflect')\nplt.imshow(re)","facafa22":"def pack_image2(img):\n    xres, yres = np.shape(img)\n    xres = int(xres \/ 8)\n    yres = int(yres \/ 8)\n    p = np.empty((xres,yres))\n    for x in range(xres):\n        for y in range(yres):\n            p[x][y] = int(\"\".join(img[x*8:(x*8)+8,y*8:(y*8)+8].flatten().astype(int).astype(str)), 2)\n    return p\n\n%timeit pack_image2(cutted)","8cc16299":"packed.shape, packed.dtype","c4ce8f4c":"packed.flatten().shape","0bd24920":"im_noise = cutted + 0.2 * np.random.randn(*cutted.shape)","dd2fe653":"plt.title('cutted with noise')\nplt.imshow(im_noise)","12c4fe5a":"im_noise.dtype","64210f36":"cutted.dtype","790e5e64":"hist = np.histogram(im_noise - im_noise.mean(),\n                    bins=np.arange(im_noise.min(),\n                                   im_noise.max(),\n                                   1\/256))\nplt.plot(hist[1][:-1], hist[0], lw=2)\nplt.title('histogram of gray values \"cutted with noise\" image')","797fd84e":"hist = np.histogram(image - image.mean(),\n                    bins=np.arange(image.min(),\n                                   image.max(),\n                                   1\/256))\nplt.plot(hist[1][:-1], hist[0], lw=2)\nplt.title('original image histogram of gray values')","5bfdd224":"plt.figure(figsize=(15,15))\nplt.subplot(1,3,1)\nplt.title('cutted')\nplt.imshow(cutted)\n\nplt.subplot(1,3,2)\nplt.title('binary_opening(cutted)')\nopen_img = scipy.ndimage.binary_opening(cutted)\nplt.imshow(open_img)\n\nplt.subplot(1,3,3)\nplt.title('binary_closing(binary_opening(cutted))')\nclose_img = scipy.ndimage.binary_closing(open_img)\nplt.imshow(close_img)","2a698be8":"eroded_img = scipy.ndimage.binary_erosion(cutted)\nreconstruct_img = scipy.ndimage.binary_propagation(eroded_img, mask=cutted)\ntmp = np.logical_not(reconstruct_img)\neroded_tmp = scipy.ndimage.binary_erosion(tmp)\nreconstruct_final = np.logical_not(scipy.ndimage.binary_propagation(eroded_tmp, mask=tmp))","3c81ca83":"plt.imshow(reconstruct_final)","aec2a2a5":"%%time\nimage = plt.imread('..\/input\/train\/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_blue.png')\ncutted = image > image.mean()\n\ngraph = sklearn.feature_extraction.image.img_to_graph(image, mask=cutted)\ngraph.data = np.exp(-graph.data\/graph.data.std())\n\nlabels = sklearn.cluster.spectral_clustering(graph, n_clusters=20, eigen_solver='arpack')\nlabel_im = -np.ones(cutted.shape)\nlabel_im[cutted] = labels","08a211b8":"plt.imshow(label_im, cmap='nipy_spectral')","4f113597":"%%time\nlabel_im, nb_labels = scipy.ndimage.label(image > image.mean())","0004c7fc":"plt.imshow(label_im, cmap='nipy_spectral')","d19bdd8f":"np.unique(label_im).size","882d9ef3":"def disk_structure(n):\n    struct = np.zeros((2 * n + 1, 2 * n + 1))\n    x, y = np.indices((2 * n + 1, 2 * n + 1))\n    mask = (x - n)**2 + (y - n)**2 <= n**2\n    struct[mask] = 1\n    return struct.astype(np.bool)\n\ndef granulometry(data, sizes=None):\n    s = max(data.shape)\n    if sizes is None:\n        sizes = range(1, int(s\/2), 2)\n    granulo = [scipy.ndimage.binary_opening(data, \\\n        structure=disk_structure(n)).sum() for n in sizes]\n    return granulo","f4250e98":"im = plt.imread('..\/input\/train\/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_blue.png')\nmask = im > im.mean()\ngranulo = granulometry(mask, sizes=np.arange(1, 10, 1))","0f65d2aa":"granulo","78dc99cb":"plt.figure(figsize=(12, 4.4))\n\nplt.subplot(121)\nplt.imshow(mask, cmap=plt.cm.gray)\nopened = scipy.ndimage.binary_opening(mask, structure=disk_structure(10))\nopened_more = scipy.ndimage.binary_opening(mask, structure=disk_structure(14))\nplt.contour(opened, [0.5], colors='b', linewidths=1)\nplt.contour(opened_more, [0.5], colors='r', linewidths=1)\nplt.axis('off')\nplt.subplot(122)\nplt.plot(np.arange(1, 10, 1), granulo, 'ok', ms=8)\n\nplt.subplots_adjust(wspace=0.02, hspace=0.15, top=0.95, bottom=0.15, left=0, right=0.95)\nplt.show()","b02ae06d":"def plot_granulos(filename, sizes=np.arange(1, 10, 1)):\n    im = plt.imread(filename)\n    mask = im > skimage.filters.threshold_li(im)\n    granulo = granulometry(mask, sizes=sizes)\n\n    plt.figure(figsize=(12, 4.4))\n\n    plt.subplot(121)\n    plt.imshow(mask, cmap=plt.cm.gray)\n    opened = scipy.ndimage.binary_opening(mask, structure=disk_structure(1))\n    opened_more = scipy.ndimage.binary_opening(mask, structure=disk_structure(4))\n    plt.contour(opened, [0.5], colors='b', linewidths=1)\n    plt.contour(opened_more, [0.5], colors='r', linewidths=1)\n    plt.axis('off')\n    plt.subplot(122)\n    plt.plot(sizes, granulo, 'ok', ms=8)\n\n    plt.subplots_adjust(wspace=0.02, hspace=0.15, top=0.95, bottom=0.15, left=0, right=0.95)\n    plt.show()","5dc3df3c":"plot_granulos('..\/input\/train\/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_red.png')\nplot_granulos('..\/input\/train\/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_green.png')\nplot_granulos('..\/input\/train\/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_blue.png')\nplot_granulos('..\/input\/train\/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_yellow.png')","92ec8b12":"image = plt.imread('..\/input\/train\/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_blue.png')\n\ns = np.linspace(0, 2*np.pi, 400)\nx = 150 + 50*np.cos(s)\ny = 150 + 50*np.sin(s)\ninit = np.array([x, y]).T\n\nfiltered = skimage.filters.gaussian(image, 2)","4479c7e4":"plt.subplot(1,2,1)\nplt.imshow(image)\n\nplt.subplot(1,2,2)\nplt.imshow(filtered)","c82b4061":"snake = skimage.segmentation.active_contour(filtered,\n                                            init,\n                                            alpha=0.002,\n                                            beta=10,\n                                            gamma=0.01)\n\nfig, ax = plt.subplots(figsize=(7, 7))\nax.imshow(image)\nax.plot(init[:, 0], init[:, 1], '--r', lw=3)\nax.plot(snake[:, 0], snake[:, 1], '-b', lw=3)\nax.set_xticks([]), ax.set_yticks([])\nax.axis([0, image.shape[1], image.shape[0], 0])\n\nplt.show()","25db1985":"image = plt.imread('..\/input\/train\/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_green.png')\n\nblobs_log = skimage.feature.blob_log(image, max_sigma=30, num_sigma=10, threshold=.1)\n\n# Compute radii in the 3rd column.\nblobs_log[:, 2] = blobs_log[:, 2] * (2 ** .5)\n\nblobs_dog = skimage.feature.blob_dog(image, max_sigma=30, threshold=.1)\nblobs_dog[:, 2] = blobs_dog[:, 2] * (2 ** .5)\n\nblobs_doh = skimage.feature.blob_doh(image, max_sigma=30, threshold=.01)\n\nblobs_list = [blobs_log, blobs_dog, blobs_doh]\ncolors = ['yellow', 'lime', 'red']\ntitles = ['Laplacian of Gaussian', 'Difference of Gaussian',\n          'Determinant of Hessian']\nsequence = zip(blobs_list, colors, titles)\n\nfig, axes = plt.subplots(1, 3, figsize=(9, 3), sharex=True, sharey=True)\nax = axes.ravel()\n\nfor idx, (blobs, color, title) in enumerate(sequence):\n    ax[idx].set_title(title)\n    ax[idx].imshow(image, interpolation='nearest')\n    for blob in blobs:\n        y, x, r = blob\n        c = plt.Circle((x, y), r, color=color, linewidth=2, fill=False)\n        ax[idx].add_patch(c)\n\nplt.tight_layout()\nplt.show()","e46fcd85":"image = plt.imread('..\/input\/train\/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_red.png')\nedges = skimage.feature.canny(image)\n\nplt.imshow(edges)\nplt.title('Canny detector');","f3cbd7ec":"fill_image = scipy.ndimage.binary_fill_holes(edges)\n\nplt.imshow(fill_image)\nplt.title('filling the holes');","76dd23d0":"red    = plt.imread('..\/input\/train\/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_red.png')\ngreen  = plt.imread('..\/input\/train\/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_green.png')\nblue   = plt.imread('..\/input\/train\/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_blue.png')\nyellow = plt.imread('..\/input\/train\/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_yellow.png')","9ffa183c":"def to_rgba(img):\n    (nro_channels, resolutionx, resolutiony) = np.shape(img)\n    r = [[[1, 0, 0, img[0][i][j]] for i in range(resolutionx)] for j in range(resolutiony)]\n    g = [[[0, 1, 0, img[1][i][j]] for i in range(resolutionx)] for j in range(resolutiony)]\n    b = [[[0, 0, 1, img[2][i][j]] for i in range(resolutionx)] for j in range(resolutiony)]\n    y = [[[1, 1, 0, img[3][i][j]] for i in range(resolutionx)] for j in range(resolutiony)]\n    return np.array([r,g,b,y])","641587e1":"%time r = to_rgba([red, green, blue, yellow])","745fea5b":"plt.figure(figsize=(15,15))\nfor i in range(4):\n    plt.imshow(r[i])","475bba37":"def to_rgba2(img):\n    r = np.transpose(np.vectorize(lambda x: (1,0,0,x))(img[0]))\n    g = np.transpose(np.vectorize(lambda x: (0,1,0,x))(img[1]))\n    b = np.transpose(np.vectorize(lambda x: (0,0,1,x))(img[2]))\n    y = np.transpose(np.vectorize(lambda x: (1,1,0,x))(img[3]))\n    return np.array([r,g,b,y])","5261d044":"%time r = to_rgba2([red, green, blue, yellow])","f55bd782":"plt.figure(figsize=(15,15))\nfor i in range(4):\n    plt.imshow(r[i])","2dfb3362":"red     = PIL.Image.open('..\/input\/train\/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_red.png')\ngreen   = PIL.Image.open('..\/input\/train\/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_green.png')\nblue    = PIL.Image.open('..\/input\/train\/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_blue.png')\nyellow  = PIL.Image.open('..\/input\/train\/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_yellow.png')","90f2d57f":"type(red)","cf0e95e1":"red.format","211fc1d1":"red.mode","56de1371":"S1 = PIL.ImageChops.blend(red,green,0.5)\nS2 = PIL.ImageChops.blend(blue,yellow,0.5)\nS3 = PIL.ImageChops.blend(S1,S2,0.5)\nS3","8606ca8c":"plt.imshow(np.asarray(S3))","8b3270de":"red.convert('RGB')","b5c29c79":"red.mode","28348ae2":"rgb = PIL.Image.merge('RGB', (red, green, blue))\nrgb","d5d01018":"y = PIL.Image.merge('RGB', (yellow, yellow, PIL.Image.new('L', (yellow.width, yellow.height))))\ny","f32debf5":"rgby = PIL.ImageChops.add(rgb, y)\nrgby","8e73ca51":"image = plt.imread('..\/input\/train\/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_blue.png')*255\nimage = image.astype(int)\nelevation_map = skimage.filters.sobel(image\/255)\n\nplt.imshow(elevation_map)\nplt.title('elevation map')","ffdd739d":"markers = np.zeros_like(image)\nmarkers[image > 0] = 1\nmarkers[image > 25] = 2\nmarkers[image > 30] = 3\nmarkers[image > 35] = 4\n\nplt.imshow(markers, cmap='nipy_spectral')\nplt.title('markers')","8c1ed991":"segmentation = skimage.morphology.watershed(elevation_map, markers)\n\nplt.imshow(segmentation)\nplt.title('segmentation')","0c0d864e":"segmentation = scipy.ndimage.binary_fill_holes(segmentation - 1)\nlabeled, _ = scipy.ndimage.label(segmentation)\nimage_label_overlay = skimage.color.label2rgb(labeled, image=image\/255)\n\nfig, axes = plt.subplots(1, 2, figsize=(8, 3))\naxes[0].imshow(image, cmap=plt.cm.gray, interpolation='nearest')\naxes[0].contour(segmentation, [0.5], linewidths=1.2, colors='y')\naxes[1].imshow(image_label_overlay, interpolation='nearest')\n\nplt.tight_layout()\n\nplt.show()","fb63b28a":"np.unique(labeled).size","2de029e6":"image = plt.imread('..\/input\/train\/002daad6-bbc9-11e8-b2bc-ac1f6b6435d0_blue.png')\n\nfig = plt.figure(figsize=(10, 6))\nax1 = plt.subplot2grid((2, 4), (0, 0), colspan=4)\nax1.imshow(image)\n\nax2 = plt.subplot2grid((2, 4), (1, 0))\nax3 = plt.subplot2grid((2, 4), (1, 1))\nax4 = plt.subplot2grid((2, 4), (1, 2))\nax5 = plt.subplot2grid((2, 4), (1, 3))\n\n# apply threshold\nthresh = skimage.filters.threshold_otsu(image)\nbw = skimage.morphology.closing(image > thresh, skimage.morphology.square(2))\nax2.imshow(bw)\n\n# remove artifacts connected to image border\ncleared = skimage.segmentation.clear_border(bw)\nax3.imshow(cleared)\n\n# label image regions\nlabel_image = skimage.measure.label(cleared)\nax4.imshow(label_image)\nimage_label_overlay = skimage.color.label2rgb(label_image, image=image)\n\n\n#fig, ax = plt.subplots(figsize=(10, 6))\nax5.imshow(image_label_overlay)\n\nfor region in skimage.measure.regionprops(label_image):\n    # take regions with large enough areas\n    if region.area >= 100:\n        # draw rectangle around segmented coins\n        ax1.text(int(region.centroid[1]), int(region.centroid[0]), region.label)\n        minr, minc, maxr, maxc = region.bbox\n        rect = matplotlib.patches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n                                            fill=False, edgecolor='red', linewidth=2)\n        ax1.add_patch(rect)\n\nax1.set_axis_off()\nplt.tight_layout()\nplt.show()","ca6f31f2":"The bitwise operations keeps the information but another options is use simple image reduction that are more efficient.","4594319b":"### Using skimage.filters thresholds","f849b1fe":"## Converting grayscale into a bitmap (boolean array) packet in 64bit words\n\nTake the yellow channel with the Li's threashold","46cddaa4":"## Cutting\n\nThe images are generated by marking the proteins with a fluorescent molecule.\nWhen the pixel have more intensity, then we see that in that point of the image\nthere are more protein of that kind.\n\nThis competition have the target of classify the images by guessing\nwhere is the main occurrence of the protein whose intensity is illustrated by the green image.\n\nThe image with uuid '002daad6-bbc9-11e8-b2bc-ac1f6b6435d0' used throughout the notebook is\nclassified by a human and supported by scientific evidence that the protein marked in the green image \nhave the main occurrence in the [Golgi apparatus](https:\/\/en.wikipedia.org\/wiki\/Golgi_apparatus)\n\nAs you can see in the plotting above, it occurs in other organelles but there are hot spots around\nthe nucclei. Maybe we can use some threashold to cut off the noise.","8e2f65d3":"# Playing with the images of the Protein Altas\n\n## Introduction\n\nIn this notebook, several image processing techniques are experimented. \nThe objective is just see the result of them when applied to the images of this dataset.\n\nThis is largely based on the tutorials of the correspoding python library.\n\nThe images are [fluorescence microscope](https:\/\/en.wikipedia.org\/wiki\/Fluorescence_microscope) images with four channels. The protein of interest is visualized in green, while reference markers for microtubules (red),\nendoplasmic reticulum (yellow) and nucleus (blue) outline the cell. This is why the images are suffixed the the\ncolor even though they are grayscale PNG images. For more information about the images \nof the Protein Atlas dataset see https:\/\/www.proteinatlas.org\/humancell\/organelle","c7e0249a":"We have got 512x512 matrix of boolean values. That is 262144 bits.","0192e5ae":"There are several ways of doing this. The result is the same.\nI left here only the naive approach and the one with the best speedup I have found.\nMay be you can use it to learn how to use np.vectorize.\n\nBut there are specialized functions to image conversion in the libraries like PIL.","6687e8b9":"## Doing granulometry with scipy.ndimage\n\nOptical granulometry is the process of measuring the different grain sizes in a granular material.\n[1](https:\/\/en.wikipedia.org\/wiki\/Optical_granulometry)","068120a0":"May be the patterns of the blobs could be used as a feature","c31f32f3":"### Starting with simple threasholds","3ec8581e":"## Doing blob detection with skimage\n\nSee https:\/\/en.wikipedia.org\/wiki\/Blob_detection","21f400fe":"Well may be i have used the wrong functions and\/or parameters.","30f70f02":"## Selecting the contour using skimage","6076fe85":"The following is a bit more optimized.","511409be":"## Using sklearn to do spectral clustering\n\nWell, we know that the 'blue' images are from nucleus and that the 'mean' theashold is the simplest and gives enclosed surfaces. Can we count it?","51302a27":"## Color visualization of the Protein Atlas images","0855a542":"### A first approach for creating an RGBA (Red, Green, Blue and Alpha)","8c0443d0":"## Canny edge detector with skimage.feature\n\nThe Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images. [1](https:\/\/en.wikipedia.org\/wiki\/Canny_edge_detector)","f0b450f5":"## Using PIL.Image to convert the 4 grayscale images into 1 RGB image","12efd9e3":"To show that the information was not lost we can recreate the boolean typed array from the one packed in 64bit integers","ecbcba1e":"### Using numpy array to convert 4 grayscale imagens into 4 red-green-blue-yellow images","e2f05363":"We can represent this information with 32768 bytes or 4096 [64bit](https:\/\/en.wikipedia.org\/wiki\/64-bit_computing) words.","3c1cfdd1":"## Conclusion\n\nWe explored some image processing techniques like segmentation and worked with the image encoding.\nMaybe they are not all useful for this competition but their use with microscope image was very interesting.\nI have got some insights and a better understanding of the images and of the techniques.\n\nSend your comments and if you fork the notebook or use some function\/code\/idea somewhere else,\nI will be glad to see your improvements.","986c34aa":"# Using skimage to do region based segmentation","4a80153a":"Each threashold function makes a different black and white representation of the grayscale (intensity level) image.\n\n(Maybe) We can use this as a compressed input (I sweare that I am not doing [early optimization](http:\/\/wiki.c2.com\/?PrematureOptimization):) or a feature [engeeneared](https:\/\/en.wikipedia.org\/wiki\/Feature_engineering)\nwith our knowledge of the meaning of the data. What do you think? Comments are welcomed.","11d29701":"In the plots above, we see that the mean value of intensity is a robust choice to outline locations \n(red, blue and yellow channels). The nucleus is outlined with few artfacts.\n\nTo the green channel, the 95% percentile is a better choice. With this threashold\nwe can see the Golgi apparatus outlined.","fbb96548":"## Adding noise to image","e5600f83":"Simple, fast and acceptable result..","7fa15e1e":"## Using scipy.ndimage to remove artifacts\n\nVisual artifacts (also artefacts) are anomalies apparent during visual representation \nas in digital graphics and other forms of imagery, particularly microscopy. \n[1](https:\/\/en.wikipedia.org\/wiki\/Visual_artifact)\n\nWe start with the 'cutted' image and try to remove artifacts using the functions\nprovided by the scipy.ndimage python library.","a91dadfe":"## Using scipy.ndimage to do segmentation\n\n(An easier way to count nucleos)","521f7bd0":"![notmnist.png](attachment:notmnist.png)","eac3f668":"With this approach, we can have taken an 1 Magabyte image and converted into a meaningful 32 Kilobyte one.\n\nThis 64x64 grayscale image below does not looks like the 28x26 images from the [n-mnist](https:\/\/www.garrickorchard.com\/datasets\/n-mnist) dataset:","b2dfbf7d":"### A more complex example","6f49c145":"## Plotting the image with the histogram\n\nThe histogram is centered in the mean to be more meaningful."}}