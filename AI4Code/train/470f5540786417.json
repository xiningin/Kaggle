{"cell_type":{"1ef6ae20":"code","fa22ccbf":"code","5adef240":"code","4b41c624":"code","3b725074":"code","d33be018":"code","27f3d1b1":"code","776885dd":"code","289fb5a3":"code","a5024af8":"code","b8447d43":"code","24400952":"code","6cec2e1e":"code","7724977e":"code","a587e5a1":"code","5e9ec8af":"code","61345c62":"code","8e4637e2":"code","8ca6e0c3":"code","8f50bd88":"code","4c5f69bf":"code","f394b85d":"code","38a12433":"code","663a4a0c":"code","07ce2ff7":"markdown","ed992d9c":"markdown","64605930":"markdown","19798257":"markdown","1358bdef":"markdown"},"source":{"1ef6ae20":"# Data Processing\nimport numpy as np\nimport pandas as pd\n\n# Data Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom mpl_toolkits.basemap import Basemap\n\n# Machine Learning\nfrom sklearn.linear_model import LinearRegression, BayesianRidge\nfrom sklearn.metrics import r2_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix","fa22ccbf":"# Plot Settings\nplt.style.use('ggplot')\nsns.set_palette('pastel')\n\nplt.rcParams['figure.figsize'] = (10, 6)\nplt.rcParams['xtick.labelsize'] = 12\nplt.rcParams['ytick.labelsize'] = 12\n\n# Colors\nseverity_cols = {\n    1: 'palegreen',\n    2: 'papayawhip',\n    3: 'lightsalmon',\n    4: 'tomato'\n}","5adef240":"# Load from csv and print time needed\n%time raw_df = pd.read_csv('..\/input\/us-accidents\/US_Accidents_June20.csv')","4b41c624":"# Update col type\nraw_df['Start_Time'] = pd.to_datetime(raw_df['Start_Time'])\nraw_df['End_Time'] = pd.to_datetime(raw_df['End_Time'])\nraw_df['Severity'] = raw_df['Severity'].astype('category')\nraw_df['State'] = raw_df['State'].astype('category')","3b725074":"# Colomun categories\nroad_params = [\n    'Amenity', \n    'Bump', \n    'Crossing',\n    'Give_Way', \n    'Junction', \n    'No_Exit',\n    'Railway', \n    'Roundabout', \n    'Station',\n    'Stop', \n    'Traffic_Calming',\n    'Traffic_Signal', \n    'Turning_Loop']\n\nweather_params = [\n    'Weather_Timestamp',\n    'Temperature(F)',\n    'Wind_Chill(F)',\n    'Humidity(%)',\n    'Pressure(in)',\n    'Visibility(mi)',\n    'Wind_Direction',\n    'Wind_Speed(mph)',\n    'Precipitation(in)',\n    'Weather_Condition'\n]","d33be018":"# Missing values\n\n# Preprocessing\nmissing_values = raw_df.isna().sum() \/ len(raw_df)\n\n# Visualization\nplt.figure(figsize=(14, 14))\nplt.title('Missing Data')\nplt.xlabel('% of rows with missing data')\nmissing_values.plot(kind='barh');","27f3d1b1":"# Params\nlon, lat = raw_df['Start_Lng'].values, raw_df['Start_Lat'].values\nleft, right, bot, top = -140, -40, 22, 52\n\n# Draw a map. \nm = Basemap(projection='merc', \n            llcrnrlat=bot, \n            urcrnrlat=top, \n            llcrnrlon=left, \n            urcrnrlon=right, \n            lat_ts=20, \n            resolution='c')\n\nm.drawcoastlines()\nm.drawmapboundary()\n\nvcol = [severity_cols[i] for i in raw_df['Severity']]\n\nx, y = m(lon, lat)\nm.scatter(x, y, 1, marker='o', color=vcol)\nplt.title('Accidents representation map by severity level')\nplt.show()","776885dd":"plt.title('Accidents by State')\nraw_df.groupby('State').size().sort_values().plot(kind='bar');","289fb5a3":"plt.title('Severity level proportion')\nraw_df.groupby('Severity').size().plot(kind='pie', colors = severity_cols.values(), autopct='%1.0f%%');","a5024af8":"raw_df['Month_Code'] = raw_df['Start_Time'].dt.year.astype(str) + '_' + raw_df['Start_Time'].dt.month.astype(str).str.zfill(2)\nplt.title('Number of accidents by month')\nraw_df.groupby('Month_Code').size().plot();","b8447d43":"df_17_20 = raw_df[(raw_df['Month_Code'] < '202000') & (raw_df['Month_Code'] > '201799')]\nplt.title('Number of accidents by month')\ndf_17_20.groupby('Month_Code').size().plot();","24400952":"# Number of accidents by month - total 2017, 2018, 2019\nplt.title('Number of accidents by month - Total from January 2017 to December 2019')\ndf_17_20.groupby(df_17_20['Start_Time'].dt.month).size().plot(kind='bar');","6cec2e1e":"# Number of accidents by hour - total 2017, 2018, 2019\nplt.title('Number of accidents by hour of the day')\nplt.xlabel('Hour of the accident')\nraw_df.groupby(raw_df['Start_Time'].dt.hour).size().plot(kind='bar');","7724977e":"# Number of accidents by month - total 2017, 2018, 2019\nstate_and_month = df_17_20.groupby(['State', df_17_20['Start_Time'].dt.month]).size().unstack()\nplt.figure(figsize=(20, 6))\nsns.heatmap(state_and_month.T, square=True, linewidths =.5, cmap=\"YlGnBu\");","a587e5a1":"# % of accident including road params\nroad_param_percent = raw_df.loc[:, road_params].sum() \/ len(raw_df)\nplt.title('Presence of road element near accidents')\nplt.xlabel('% of total of accidents')\nroad_param_percent.sort_values().plot(kind='barh');","5e9ec8af":"# % of accident by Weather_Condition\nacc_by_weather_condition = raw_df.groupby('Weather_Condition').size() \/ len(raw_df)\nacc_by_weather_condition = acc_by_weather_condition[acc_by_weather_condition > 0.005]\nplt.title('Presence of weather condition during accidents')\nplt.xlabel('% of total of accidents')\nacc_by_weather_condition.sort_values().plot(kind='barh');","61345c62":"# Feature Engineering\nraw_df['Duration'] = (raw_df['End_Time'] - raw_df['Start_Time']).dt.seconds \/ 60 # Minutes\nraw_df['Start_Hour'] = raw_df['Start_Time'].dt.hour\n\npredictors = road_params + ['Start_Hour'] + ['State']\n\nXl = raw_df.loc[:, predictors].dropna()\nXl = pd.get_dummies(Xl)\n\nyl = raw_df.loc[Xl.index, 'Duration']","8e4637e2":"# Plot distribution of Duration\nplt.figure(figsize=(16, 8))\nplt.title('Histogram of duration of impact on traffic (in minutes)')\nraw_df['Duration'].clip(upper=600).plot(kind='hist', bins=100) # clipped data\nplt.xlabel('Time in minutes')\nplt.xticks(range(0, 601, 60));","8ca6e0c3":"# Create Linear Model\nregr = LinearRegression()\nmodel1 = regr.fit(Xl, yl)\nmodel1.score(Xl, yl)","8f50bd88":"# Create Bayesian Model\nbaye = BayesianRidge()\nmodel2 = baye.fit(Xl, yl)\nmodel2.score(Xl, yl)","4c5f69bf":"# Create Random Forest\nclf = RandomForestClassifier(n_estimators=10,\n                            random_state=0, \n                             n_jobs=-1)\n\ndf_resampled = raw_df.groupby('Severity').apply(lambda x: x.sample(25000)).reset_index(drop=True)\n\nXrf = raw_df.loc[:, predictors].dropna()\n%time Xrf = pd.get_dummies(Xrf)\nyrf = raw_df.loc[Xrf.index, 'Severity']\n\nXrfrs = df_resampled.loc[:, predictors].dropna()\nXrfrs = pd.get_dummies(Xrfrs)\nyrfrs = df_resampled.loc[Xrfrs.index, 'Severity']\n\n\nmodel3 = clf.fit(Xrfrs, yrfrs)\nprint(model3.score(Xrfrs, yrfrs))\nprint(model3.score(Xrf, yrf))","f394b85d":"yp = model3.predict(Xrfrs)\nconf_mat = confusion_matrix(yrfrs, yp)\nprint(conf_mat)","38a12433":"yp = model3.predict(Xrf)\nconf_mat = confusion_matrix(yrf, yp)\nprint(conf_mat)","663a4a0c":"sns.heatmap(conf_mat,cmap=\"YlGnBu\", \n             annot=True, square=True, \n             yticklabels=range(1, 5), \n             xticklabels=range(1, 5))\nplt.title('Confusion matrix of accidents\u2019 severity level prediction');","07ce2ff7":"## Study","ed992d9c":"## Data Wrangling","64605930":"## Exploratory Data Analysis","19798257":"## Load Data","1358bdef":"## Predictions"}}