{"cell_type":{"4b589c06":"code","66cb805c":"code","4203a209":"code","f3ad49b9":"code","04a72ef7":"code","3e12dd7b":"code","fd37fa1a":"code","cb22a5e1":"code","99595d87":"code","ff6de287":"code","f11457b2":"code","9ed83dd6":"code","5db9150b":"markdown"},"source":{"4b589c06":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","66cb805c":"path ='\/kaggle\/input\/quora-insincere-questions-classification\/train.csv'\ntrain =pd.read_csv(path, nrows=1000)\ntrain.head()","4203a209":"# coverting every character to lower case\ndocs = train['question_text'].str.lower()\ndocs.head()","f3ad49b9":"## Use Regular Expressions i.e Remove non-alphabets \ndocs =  docs.str.replace('[^a-z ]','')","04a72ef7":"## Remove Commonly used Words\nimport nltk    # nltk is a inbuilt function which gives commonly used words in a list\nstopwords = nltk.corpus.stopwords.words('english')\nstemmer = nltk.stem.PorterStemmer()\n\ndef clean_sentence(doc):\n    words =doc.split(' ')\n    words_clean =[stemmer.stem(word) for word in words if word not in stopwords]\n    return ' '.join(words_clean)\n    \ndocs =docs.apply(clean_sentence)\ndocs.head()","3e12dd7b":"## Stemming \nstemmer = nltk.stem.PorterStemmer()\nstemmer.stem('playing')","fd37fa1a":"## Term Frequency - Inverse Document Frequency (TF=IDF)","cb22a5e1":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\ndtm_vectorizer = CountVectorizer()\n\ntrain_X,validate_X,train_y,valdiate_y =train_test_split(docs,train['target'],test_size =0.2,random_state=1)\n\ndtm_vectorizer.fit(train_X)\ndtm_train = dtm_vectorizer.transform(train_X) \ndtm_validate = dtm_vectorizer.transform(validate_X)","99595d87":"df_dtm_train = pd.DataFrame(dtm_train.toarray(),columns = dtm_vectorizer.get_feature_names(), index = train_X.index)\ndf_dtm_train","ff6de287":"df_dtm_train.sum().sort_values(ascending=False).head(20).plot.bar()","f11457b2":"from sklearn.naive_bayes import MultinomialNB\n\nmodel = MultinomialNB().fit(dtm_train,train_y)\nvalidate_y_pred =model.predict(dtm_validate)\n\nfrom sklearn.metrics import accuracy_score,f1_score\nprint(accuracy_score(valdiate_y,validate_y_pred))\nprint(f1_score(valdiate_y,validate_y_pred))","9ed83dd6":"from nltk.sentiment import SentimentIntensityAnalyzer\nsentiment_analyzer=SentimentIntensityAnalyzer()\nsentiment_analyzer.polarity_scores('i like india')","5db9150b":"****#Text Cleaning****"}}