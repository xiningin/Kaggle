{"cell_type":{"fb89b821":"code","47233959":"code","2734af7f":"code","0045d13c":"code","53bb6d01":"code","00ad80ab":"code","76d42d5b":"code","b35f02c9":"code","55f9a3de":"code","f6c019e8":"code","132b5c26":"code","563bff61":"code","4580b05f":"code","dd21b735":"code","1f362ed9":"code","fbf535c0":"code","d2ccb626":"code","0fd35fe6":"code","8a06fdb7":"code","a1e1fa7e":"code","aed42539":"code","967f9f06":"code","c3014aac":"code","8551b602":"code","d97bf78d":"code","45bf6f05":"code","a586a57b":"code","b5b53d77":"code","f30f7ba7":"code","211b5b60":"code","9e0b1120":"code","2fe97d28":"code","8461a166":"code","495651b5":"code","f939bd9d":"code","df2d94dc":"code","7588fcb6":"code","2cbd5156":"code","f3771e7b":"code","744fd4b4":"code","19a54a43":"code","59c5a057":"code","13c80a4e":"code","81985de3":"code","3904f0b3":"code","ca372644":"code","bfb7c894":"code","e8bec553":"code","cd134380":"code","38a2601c":"code","62648172":"code","9d2f56fd":"code","3bef4ead":"code","4ad38847":"code","f00d0e12":"code","44740b60":"code","be8f67ee":"code","2d988a77":"markdown"},"source":{"fb89b821":"import numpy as np\nimport pandas as pd\nfrom sklearn import linear_model\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndata = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')","47233959":"data.head()\n","2734af7f":"def comp_plot(col):\n    fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n\n    data[col].value_counts(normalize=True).plot(kind='bar', figsize=(15,5), ax=ax1)\n    ax1.set_title('Train set')\n    test[col].value_counts(normalize=True).plot(kind='bar', figsize=(15,5), ax=ax2)\n    ax2.set_title('Test set')\n    print('For Train data set', '\\n', data[col].value_counts(normalize='True'), '\\n')\n    print('For Test data set', '\\n',test[col].value_counts(normalize='True'))\n    \n    return 0\n\ncomp_plot('Sex')","0045d13c":"comp_plot('Pclass')","53bb6d01":"Sur = data.Survived.value_counts(normalize='True')\nprint(Sur)\ndata['Survived'].value_counts(normalize=True).plot(kind='bar')\n\n#only 38% of people survived","00ad80ab":"fig, (ax1, ax2)  = plt.subplots(1, 2, sharey=True, figsize=(15,5))\ndata.hist(column='Age', ax=ax1)\nax1.set_title('Histogram of Age-Train set')\ntest.hist(column='Age', ax=ax2)\nax2.set_title('Histogram of Age-Test set')","76d42d5b":"fig, (ax1, ax2)  = plt.subplots(1, 2, sharey=True, figsize=(15,5))\ndata.hist(column='Fare', ax=ax1)\nax1.set_title('Histogram of Fare-Train set')\ntest.hist(column='Fare', ax=ax2)\nax2.set_title('Histogram of Fare-Test set')","b35f02c9":"fig, (ax1, ax2)  = plt.subplots(1, 2, figsize=(15,5))\nsns.scatterplot(x='Pclass', y='Age', hue='Survived', data=data, ax=ax1)\nsns.scatterplot(x='Pclass', y='Fare', hue='Survived', size='Survived', data=data, ax=ax2)","55f9a3de":"fig, (ax1, ax2)  = plt.subplots(1, 2, figsize=(15,5))\nsns.scatterplot(x='Survived', y='Fare', data=data, ax=ax1)\nsns.scatterplot(x='Survived', y='Age', data=data, ax=ax2)","f6c019e8":"df_sur_gen = data.groupby(['Sex'])['Survived'].value_counts(normalize = 'True').unstack('Survived')\nprint(df_sur_gen)\ndf_sur_gen.plot(kind='bar', stacked=True)","132b5c26":"df_class = data.groupby(['Pclass'])['Survived'].value_counts(normalize=True).unstack('Survived')\nprint(df_class)\ndf_class.plot(kind='bar', stacked=True)\n# 62% of class 1 people survived\n# 47% of class 2 people survived\n# 24% of class 3 people survived","563bff61":"data.isnull().sum()","4580b05f":"test.isnull().sum()","dd21b735":"mean_age = data.groupby(['Sex','Pclass'])['Age'].mean()\nmean_age.reset_index(name = 'm_Age')","1f362ed9":"def fill_Ages(row):\n    if pd.isnull(row['Age']):\n        return mean_age[row['Sex'],row['Pclass']]\n    else:\n        return row['Age']\n\ndata['Age'] =data.apply(fill_Ages, axis=1)","fbf535c0":"mean_age = test.groupby(['Sex','Pclass'])['Age'].mean()\nmean_age.reset_index(name = 'm_Age')\n\ntest['Age'] =test.apply(fill_Ages, axis=1)\n\ntest.Fare.fillna(test.Fare.mean(),inplace=True)","d2ccb626":"data.Cabin.fillna('Unknown', inplace=True)\ntest.Cabin.fillna('Unknown', inplace=True)","0fd35fe6":"data.Embarked.value_counts()","8a06fdb7":"data.Embarked.fillna('S', inplace=True)","a1e1fa7e":"data['Title'] = data.Name.str.extract(r',\\s*([^\\.]*)\\s*\\.',expand=False)\n\ntest['Title'] = test.Name.str.extract(r',\\s*([^\\.]*)\\s*\\.',expand=False)\n\ndata['Title'].value_counts()","aed42539":"# noble - 1\n# Mrs - 2\n# Miss - 3\n# Mr - 4\n# Workers - 5\n\ntitle_map = {'Lady':1, 'Master':1, 'the Countess':1, 'Jonkheer':1, 'Sir':1, 'Don':1, 'Dr':1,\n             'Mrs':2, 'Mme':2, 'Miss':3, 'Mlle':3, 'Ms':3,\n             'Mr':4, 'Capt': 5, 'Col':5, 'Major':5, 'Rev':5 }\n\ndata.Title = data.Title.map(title_map)\n\ntest.Title = test.Title.map(title_map)\n\ndata.drop('Name', axis=1, inplace=True) \ntest.drop('Name', axis=1, inplace=True)","967f9f06":"# less than 50 - 1\n# less than 100 - 2\n# less than 150 - 3\n# else - 3\n\ndef Fare_group(fare):\n    a = 0\n    if (fare <= 50):\n        a = 1\n    \n    elif (fare <= 100):\n        a = 2\n    \n    elif (fare <=150):\n        a = 3\n        \n    else:\n        a = 4\n\n    return a\n\n\ndata['Fare Group'] = data.Fare.map(Fare_group)\n#data.drop('Fare', axis=1, inplace=True)\n\ntest['Fare Group'] = test.Fare.map(Fare_group)  \n#test.drop('Fare', axis=1, inplace=True)","c3014aac":"# below 10 - 1\n# below 20 - 2\n# below 40 - 3\n# below 80 - 4\n\ndef Age_group(age):\n    a = 0\n    if (age <= 10):\n        a = 1 \n    \n    elif (age <= 20):\n        a = 2\n    \n    elif (age <=40):\n        a = 3\n        \n    else:\n        a = 4\n\n    return a\n\ndata['Age Group'] = data.Age.map(Age_group)\n#data.drop('Age', axis=1, inplace=True)\n\ntest['Age Group'] = test.Age.map(Age_group)  \n#test.drop('Age', axis=1, inplace=True)","8551b602":"data['Sex'] = data.Sex.apply(lambda x:1 if x=='female' else 2)   #converting column Sex into int format\ntest['Sex'] = test.Sex.apply(lambda x:1 if x=='female' else 2)","d97bf78d":"# S - 1\n# C - 2\n# Q - 3\n\ndata['Embarked'] = data.Embarked.apply(lambda x:1 if x=='S' else (2 if x=='C' else 3))\ntest['Embarked'] = test.Embarked.apply(lambda x:1 if x=='S' else (2 if x=='C' else 3))","45bf6f05":"data['No_fam_mem'] = data['SibSp'] + data['Parch']\ndata.drop(['SibSp','Parch', 'Ticket'], axis=1, inplace=True)\n\ntest['No_fam_mem'] = test['SibSp'] + test['Parch']\ntest.drop(['SibSp','Parch', 'Ticket'], axis=1, inplace=True)","a586a57b":"data.No_fam_mem.value_counts()","b5b53d77":"# travelling alone - 1\n# small fam - 2\n# large fam - 3\ndef fam_type(fam_size):\n    a = 0\n    if (fam_size==0):\n        a = 1\n    \n    elif (fam_size<= 5):\n        a = 2\n    \n    else:\n        a = 3\n\n    return a\n\ndata['Fam size'] = data.No_fam_mem.map(fam_type)\n\ndata.drop('No_fam_mem', axis=1, inplace=True)\n\ndata = data[['PassengerId', 'Pclass', 'Title', 'Sex', 'Age', 'Age Group', 'Fam size', 'Fare', 'Fare Group', 'Embarked', 'Cabin', 'Survived']]\n\n\n\ntest['Fam size'] = test.No_fam_mem.map(fam_type)\n\ntest.drop('No_fam_mem', axis=1, inplace=True)\n\ntest = test[['PassengerId', 'Pclass', 'Title', 'Sex', 'Age', 'Age Group', 'Fam size', 'Fare', 'Fare Group', 'Embarked', 'Cabin']]","f30f7ba7":"data.Cabin.value_counts()         #letter of cabin represent the deck","211b5b60":"data.Cabin = data.Cabin.map(lambda x: x[0])\ntest.Cabin = test.Cabin.map(lambda x: x[0])\n\ndata.Cabin.value_counts()","9e0b1120":"# Unknown-1, A-2, B-3, C-4, D-5, E-6, F-7, G-8, T-9\n\ndeck_map = {'U':1, 'A':2, 'B':3, 'C':4, 'D':5, 'E':6, 'F':7, 'G':8, 'T':9}\n\ndata['Deck'] = data['Cabin']\ndata.Deck = data.Deck.map(deck_map)\n\ndata.drop('Cabin', axis=1, inplace=True)\n\ntest['Deck'] = test['Cabin']\ntest.Deck = test.Deck.map(deck_map)\n\ntest.drop('Cabin', axis=1, inplace=True)","2fe97d28":"data.isnull().sum()","8461a166":"test.isnull().sum()","495651b5":"test.Title.fillna(3, inplace=True)","f939bd9d":"data['class_age'] = data['Pclass']*data['Age']\n\ndata['class_title'] = data['Pclass']*data['Title']\ndata['class_gen'] = data['Pclass']*data['Sex']\n\ndata['fam_fare'] = data['Fam size']*data['Fare']\n\ndata['em_fare'] = data['Embarked']*data['Fare']\n\ndata['title_age'] = data['Title']*data['Age']\n\n\ntest['class_age'] = test['Pclass']*test['Age']\n\ntest['class_title'] = test['Pclass']*test['Title']\ntest['class_gen'] = test['Pclass']*test['Sex']\n\ntest['fam_fare'] = test['Fam size']*test['Fare']\n\ntest['em_fare'] = test['Embarked']*test['Fare']\n\ntest['title_age'] = test['Title']*test['Age']","df2d94dc":"data.head()","7588fcb6":"data.drop(['Age', 'Fare'], axis=1, inplace=True)\ntest.drop(['Age', 'Fare'], axis=1, inplace=True)","2cbd5156":"cols = data.columns.tolist()\nprint(cols)","f3771e7b":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ncol_lst = [ 'Pclass', 'Title', 'Age Group', 'Fam size', 'Fare Group', 'Embarked',\n           'Deck', 'class_age', 'class_title', 'class_gen', 'fam_fare', 'em_fare', 'title_age']\n\ndata[col_lst] = scaler.fit_transform(data[col_lst])\ntest[col_lst] = scaler.fit_transform(test[col_lst])","744fd4b4":"data = data[['Pclass', 'Title', 'Sex', 'Age Group', 'Fam size', 'Fare Group', 'Embarked', 'Deck', 'class_age', \n             'class_title', 'class_gen', 'fam_fare', 'em_fare', 'title_age', 'Survived']]\n\ntest = test[['PassengerId', 'Pclass', 'Title', 'Sex', 'Age Group', 'Fam size', 'Fare Group', 'Embarked', 'Deck', 'class_age', \n             'class_title', 'class_gen', 'fam_fare', 'em_fare', 'title_age']]","19a54a43":"corr_mat = data.corr()\nnp.tril(np.ones(corr_mat.shape)).astype(np.bool)[0:5,0:5]\ndf_lt = corr_mat.where(np.tril(np.ones(corr_mat.shape)).astype(np.bool))\nplt.subplots(figsize=(15,10))\nsns.heatmap(df_lt, annot=True, cmap=\"Spectral\", fmt='.2g')","59c5a057":"from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, cross_val_predict, GridSearchCV\nfrom sklearn.metrics import accuracy_score\n#GridSearchCV - for selecting the best hyperparameter\n#StratifiedKFold  - divide categories in a uniform way\nfrom sklearn.metrics import accuracy_score\n\nkf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)  #StratifiedKFold\n\n#data_1 = data.drop('PassengerId', axis=1).copy()\ntest_2 = test.drop('PassengerId', axis=1).copy()\n\ntarget = data['Survived']\ntrain = data.drop('Survived', axis=1)","13c80a4e":"X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.3, random_state=1)   #Split the train data set\n#train_test_split(X, Y, test_size, random_state)\n# X,Y - dataset we are going to use for splitiing\n#test_size - define the size of the test set\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","81985de3":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier","3904f0b3":"#model.fit() is used to train the model on data\n#if y_test is the real labels for X_test, model.score(X_test, y_test)  compare predictions of the model against the real labels\n#model.score(X_train, y_train) measure the accuracy of the model against training data.This has nothing to do with test data\n#model.predict(X_test) predict labels for test set \n#model.score(X_test, y_test) and model.predict(X_test), accuracy_score(y_test, prediction) are both same","ca372644":"def model_score(model, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test):\n    model.fit(X_train, y_train)\n    model_score = model.score(X_test, y_test)*100\n    \n    return model_score","bfb7c894":"def cv_score(model):\n    cv_score = cross_val_score(model, train, target, cv=kf, scoring='accuracy')\n    return cv_score.mean()*100","e8bec553":"\nprint('Cross val score for LR  : ', cv_score(LogisticRegression()))\nprint('LR Score : ', model_score(LogisticRegression()),'\\n')\n\nprint('Cross val score for RF  : ', cv_score(RandomForestClassifier(n_estimators=100, max_depth=7, min_samples_split=2, \n                                                    min_samples_leaf=6, max_features='auto', random_state=1)))\nprint('RF Score : ', model_score(RandomForestClassifier(n_estimators=100, max_depth=15, min_samples_split=6, min_samples_leaf=6, \n                                    max_features='auto', random_state=1)), '\\n')\n\nprint('Cross val score for SVC : ', cv_score(SVC(C=30)))\nprint('SVC Score : ', model_score(SVC(C=30)), '\\n')\n\nprint('Cross val score for KNN : ', cv_score(KNeighborsClassifier(n_neighbors=50)))\nprint('KNN Score : ', model_score(KNeighborsClassifier(n_neighbors=50)), '\\n')\n\nprint('Cross val score for DT  : ', cv_score(DecisionTreeClassifier(max_depth=12, min_samples_split=2, random_state=1)))\nprint('DT Score : ', model_score(DecisionTreeClassifier(max_depth=12, min_samples_split=2, random_state=1)), '\\n')\n\n#Cross val score for LR  :  81.48189762796505\n#LR Score :  77.98507462686567 \n\n#Cross val score for RF  :  83.2808988764045\n#RF Score :  77.61194029850746 \n\n#Cross val score for SVC :  81.82272159800249\n#SVC Score :  77.98507462686567 \n\n#Cross val score for KNN :  80.13732833957553\n#KNN Score :  75.74626865671642 \n\n#Cross val score for DT  :  82.61173533083645\n#DT Score :  79.1044776119403","cd134380":"from xgboost import XGBClassifier, plot_importance\n\nxgbc = XGBClassifier(max_depth=15, min_child_weight=1, n_estimators=500, random_state=42, learning_rate=0.01,  \n                     eval_metric=[\"error\", \"logloss\"])\nxgbc.fit(X_train,y_train, early_stopping_rounds=15, eval_set=[(X_train, y_train), (X_test, y_test)], verbose=True)   \n# verbose=True print val_error and logloss for each iteration","38a2601c":"y_pred_xgbc = xgbc.predict(X_test)","62648172":"xgbc_score_train = xgbc.score(X_train, y_train)\nprint(\"Train Prediction Score\",xgbc_score_train*100)\nxgbc_score_test = accuracy_score(y_test,y_pred_xgbc)    # or print(xgbc.score(X_test, y_test)*100)\nprint(\"Test Prediction Score\",xgbc_score_test*100)","9d2f56fd":"results = xgbc.evals_result()\nepochs = len(results['validation_0']['error'])\nx_axis = range(0, epochs)\n# plot log loss\nfig, ax = plt.subplots()\nax.plot(x_axis, results['validation_0']['logloss'], label='Train')\nax.plot(x_axis, results['validation_1']['logloss'], label='Test')\nax.legend()\nplt.ylabel('Log Loss')\nplt.title('XGBoost Log Loss')\nplt.show()\n# plot classification error\nfig, ax = plt.subplots()\nax.plot(x_axis, results['validation_0']['error'], label='Train')\nax.plot(x_axis, results['validation_1']['error'], label='Test')\nax.legend()\nplt.ylabel('Classification Error')\nplt.title('XGBoost Classification Error')\nplt.show()","3bef4ead":"plot_importance(xgbc)\nplt.show()","4ad38847":"xgbc.fit(train, target)\n\nprediction_xgbc = xgbc.predict(test_2)","f00d0e12":"model=RandomForestClassifier(n_estimators=100, max_depth=7, min_samples_split=2,min_samples_leaf=6, max_features='auto', random_state=1)\nmodel.fit(train, target)\n\npred_dt = model.predict(test_2)","44740b60":"model = SVC( C=20)\nmodel.fit(train, target)\n\npred_svc = model.predict(test_2)","be8f67ee":"sub = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived':pred_svc})\nsub.to_csv('sample_submission.csv', index=False)","2d988a77":"# ************************************"}}