{"cell_type":{"5a5e97f8":"code","eda3a51e":"code","ec396af5":"code","ca880b58":"code","c1f942d1":"code","93213e6d":"code","2e3e913f":"code","8ef2ae21":"code","9f42543c":"code","3df42310":"code","bf71fd9f":"code","510c5e04":"code","479783b2":"code","ea913358":"code","0b283834":"code","eaac99ac":"code","ec6142bc":"code","7770e177":"code","dd027252":"code","b9c9da14":"code","1655abc2":"code","061c54a4":"code","4aa576dd":"code","b98fb954":"code","4c623fe9":"code","5896d128":"code","c2fabbad":"code","ee45031c":"code","845f2683":"code","83ac07ab":"code","e56b4967":"code","8e07eb55":"code","56a63daa":"code","6f074ae4":"code","3df5a8d0":"markdown","1f584d81":"markdown","7bc5e39c":"markdown","bd38c1c3":"markdown","2e96206b":"markdown","7d335352":"markdown","d01bbdb7":"markdown","eb3eaeb7":"markdown","7b3e5f2b":"markdown","2854c5df":"markdown","568f16b9":"markdown","e934f5bd":"markdown","2ae306de":"markdown","9292d3e9":"markdown","48475cb3":"markdown","4d3ceeb2":"markdown","e6157373":"markdown","3edef7aa":"markdown","ff359625":"markdown","039896f9":"markdown","f413038f":"markdown","4b5c8324":"markdown","d9776a4a":"markdown","1a6696ce":"markdown","b4f0c0d5":"markdown","59b54605":"markdown","374f6f78":"markdown","6a282bae":"markdown","b0dced66":"markdown","64d4cd49":"markdown","e6765455":"markdown","c9060575":"markdown","cac400b9":"markdown","df7f4cd7":"markdown","5c790620":"markdown","c3b67734":"markdown","4e110292":"markdown","e79d060a":"markdown","752c2817":"markdown","8850c689":"markdown","3c130377":"markdown","2c8aee08":"markdown","eb040400":"markdown","48b18ba9":"markdown","e6faa16c":"markdown","ff677c17":"markdown","e7a6adec":"markdown","4cef9d6b":"markdown","5849562a":"markdown","730e2f91":"markdown","2608a3f1":"markdown","c8a6345f":"markdown"},"source":{"5a5e97f8":"# linear algebra\nimport numpy as np \n# data processing\nimport pandas as pd \n# matplotlib and seaborn for plotting\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n# text processing libraries\nimport string\n# regular expression\nimport re\n# natural language processing\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk import FreqDist, word_tokenize\nfrom nltk.stem import WordNetLemmatizer,PorterStemmer\n# scikit-learn\nfrom sklearn import model_selection\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression","eda3a51e":"# Load data\ntrain = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")\nsub_sample = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/sample_submission.csv\")\n\ntrain.head()","ec396af5":"test.head()","ca880b58":"print('Training Data Shape',train.shape)","c1f942d1":"print('Testing Data Shape',test.shape)","93213e6d":"print('Sub Sample Data Shape',sub_sample.shape)\nsub_sample.head()","2e3e913f":"train['target'].value_counts()","8ef2ae21":"temp = train.groupby('target').count()['text'].reset_index()\ntemp['label'] = temp['target'].apply(lambda x : 'Disaster Tweet' if x==1 else 'Non Disaster Tweet')\ntemp","9f42543c":"sns.barplot(train['target'].value_counts().index,train['target'].value_counts()\n            ,palette='Spectral')\nplt.title('Comparing disaster tweets and non disaster tweets',fontsize=15)","3df42310":"train.isnull().sum()","bf71fd9f":"test.isnull().sum()","510c5e04":"train.keyword.nunique(),test.keyword.nunique()","479783b2":"# Set the width and height of the figure\nplt.figure(figsize=(9,6))\n# Bar chart showing amount of keywords values\nsns.barplot(y=train['keyword'].value_counts()[:10].index,\n            x=train['keyword'].value_counts()[:10])\n# Add title\nplt.title(' Top 10 Keyword ') \n# Add label for x axis\nplt.xlabel('COUNT')\n# Add label for y axis\nplt.ylabel('KEYWORD')\n# Rotate the label text for hotizontal axis\nplt.xticks(rotation=90) ","ea913358":"# create variables a,b (disaster , non-disaster)\na = train[train.target==1].keyword.value_counts().head(10)\nb = train[train.target==0].keyword.value_counts().head(10)\n# Set the width and height of the figure\nplt.figure(figsize=(13,5))\n# Bar chart showing amount of disaster keywords values\nplt.subplot(121)\nsns.barplot(a, a.index, color='orange')\n# Add title\nplt.title('Top keywords for disaster tweets')\n# Bar chart showing amount of non-disaster keywords values\nplt.subplot(122)\nsns.barplot(b, b.index, color='pink')\n# Add title\nplt.title('Top keywords for non-disaster tweets')\n# display a graph \nplt.show()","0b283834":"train.location.nunique(),test.location.nunique()","eaac99ac":"# Set the width and height of the figure\nplt.figure(figsize=(9,6))\n# Bar chart showing amount of location values and groups the top 10 location\nsns.countplot(y=train.location, order = train.location.value_counts().iloc[:10].index)\n# Add title\nplt.title('Top 10 locations')\n# display a graph \nplt.show()","ec6142bc":"# Replacing the ambigious locations name with Standard names\ntrain['location'].replace({'United States':'USA',\n                           'New York':'USA',\n                            \"London\":'UK',\n                            \"Los Angeles, CA\":'USA',\n                            \"Washington, D.C.\":'USA',\n                            \"California\":'USA',\n                             \"Chicago, IL\":'USA',\n                             \"Chicago\":'USA',\n                            \"New York, NY\":'USA',\n                            \"California, USA\":'USA',\n                            \"FLorida\":'USA',\n                            \"Nigeria\":'Africa',\n                            \"Kenya\":'Africa',\n                            \"Everywhere\":'Worldwide',\n                            \"San Francisco\":'USA',\n                            \"Florida\":'USA',\n                            \"United Kingdom\":'UK',\n                            \"Los Angeles\":'USA',\n                            \"Toronto\":'Canada',\n                            \"San Francisco, CA\":'USA',\n                            \"NYC\":'USA',\n                           \"Seattle\":'USA',\n                            \"Earth\":'Worldwide',\n                            \"Ireland\":'UK',\n                            \"London, England\":'UK',\n                            \"New York City\":'USA',\n                            \"Texas\":'USA',\n                            \"London, UK\":'UK',\n                            \"Atlanta, GA\":'USA',\n                            \"Mumbai\":\"India\"},inplace=True)\n\nsns.barplot(y=train['location'].value_counts()[:5].index,x=train['location'].value_counts()[:5])","7770e177":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\ntweet_len=train[train['target']==1]['text'].str.len()\nax1.hist(tweet_len,color='red')\nax1.set_title('disaster tweets')\n\ntweet_len=train[train['target']==0]['text'].str.len()\nax2.hist(tweet_len,color='blue')\nax2.set_title('Not disaster tweets')\nfig.suptitle('Characters in tweets',fontsize=20)\n\nplt.show()","dd027252":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\ntweet_len=train[train['target']==1]['text'].str.split().map(lambda x: len(x))\nax1.hist(tweet_len,color='red')\nax1.set_title('disaster tweets')\ntweet_len=train[train['target']==0]['text'].str.split().map(lambda x: len(x))\nax2.hist(tweet_len,color='blue')\nax2.set_title('Not disaster tweets')\nfig.suptitle('Words in a tweets',fontsize=20)\nplt.show()","b9c9da14":"for col in ['keyword', 'location']:\n    train[col] = train[col].fillna(f'no_{col}')\nfor col in ['keyword', 'location']:\n    test[col] = test[col].fillna(f'no_{col}')","1655abc2":"#train.head()\ntest.head()","061c54a4":"# Applying a first round of text cleaning techniques\n\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    text = re.sub(r'<.*?>',' ' ,text)\n    \n    return text\n\n# Applying the cleaning function to both test and training datasets\ntrain['text'] = train['text'].apply(lambda x: clean_text(x))\ntest['text'] = test['text'].apply(lambda x: clean_text(x))\n\n# Let's take a look at the updated text\ntrain['text'].head()","4aa576dd":"tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n\n# Tokenizing the training and the test set\ntrain['text'] = train['text'].apply(lambda x: tokenizer.tokenize(x))\ntest['text'] = test['text'].apply(lambda x: tokenizer.tokenize(x))\ntrain['text'].head()\n","b98fb954":"def remove_stopwords(text):\n    \"\"\"\n    Removing stopwords belonging to english language\n    \n    \"\"\"\n    words = [w for w in text if w not in stopwords.words('english')]\n    return words\n\n\n    train['text'] = train['text'].apply(lambda x : remove_stopwords(x))\n    test['text'] = test['text'].apply(lambda x : remove_stopwords(x))","4c623fe9":"def remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)","5896d128":"def stemming(words):\n     ps=PorterStemmer()\n     return [ps.stem(word) for word in words]\ntrain['text']=train['text'].apply(lambda x: stemming(x))\ntest['text']=test['text'].apply(lambda x: stemming(x))","c2fabbad":"def lemmatizing(words):\n            lemmatizer =WordNetLemmatizer()\n            return [lemmatizer.lemmatize(word) for word in words]\ntrain['text']=train['text'].apply(lambda x: lemmatizing(x))\ntest['text']=test['text'].apply(lambda x: lemmatizing(x))","ee45031c":"def final_text(words):\n     return ' '.join(words)\ntrain['text']=train['text'].apply(lambda x:final_text(x))\ntest['text']=test['text'].apply(lambda x:final_text(x))\ntrain.head(10)","845f2683":"test.head(10)","83ac07ab":"count_vectorizer = CountVectorizer()\ntrain_vectors = count_vectorizer.fit_transform(train['text'])\ntest_vectors = count_vectorizer.transform(test[\"text\"])\n","e56b4967":"tfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2))\ntrain_vectors = tfidf.fit_transform(train['text'])\ntest_vectors = tfidf.transform(test[\"text\"])","8e07eb55":"clf = LogisticRegression(C=0.9,max_iter=1000,penalty='l2')\nscores = model_selection.cross_val_score(clf, train_vectors, train[\"target\"], cv=7, scoring=\"f1\")\nscores","56a63daa":"clf.fit(train_vectors, train[\"target\"])","6f074ae4":"sample_submission = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/sample_submission.csv\")\nsample_submission[\"target\"] = clf.predict(test_vectors)\nsample_submission.to_csv(\"submission.csv\", index=False)","3df5a8d0":"* \u0e15\u0e23\u0e27\u0e08\u0e2a\u0e2d\u0e1a\u0e27\u0e48\u0e32 Train \u0e41\u0e25\u0e30 Test \u0e21\u0e35\u0e08\u0e33\u0e19\u0e27\u0e19 keyword \u0e17\u0e35\u0e48\u0e44\u0e21\u0e48\u0e0b\u0e49\u0e33\u0e01\u0e31\u0e19\u0e17\u0e31\u0e49\u0e07\u0e2b\u0e21\u0e14\u0e40\u0e17\u0e48\u0e32\u0e43\u0e14 \u0e43\u0e19 train data","1f584d81":"**Columns \u0e17\u0e31\u0e49\u0e07\u0e2b\u0e21\u0e14\u0e1b\u0e23\u0e30\u0e01\u0e2d\u0e1a\u0e14\u0e49\u0e27\u0e22 5 columns \u0e04\u0e37\u0e2d**\n1. **id** [ unique identifier ] \u0e40\u0e25\u0e02\u0e25\u0e33\u0e14\u0e31\u0e1a id \u0e02\u0e2d\u0e07\u0e1c\u0e39\u0e49\u0e43\u0e0a\u0e49\n2. **keyword** [ from that tweet ] \u0e04\u0e35\u0e22\u0e4c\u0e40\u0e27\u0e34\u0e23\u0e4c\u0e14\u0e17\u0e35\u0e48\u0e2d\u0e22\u0e39\u0e48\u0e43\u0e19 tweet \n3. **location** [ that tweet sent from ] \u0e1e\u0e34\u0e01\u0e31\u0e14\u0e02\u0e2d\u0e07\u0e1c\u0e39\u0e49\u0e43\u0e0a\u0e49\u0e07\u0e32\u0e19\n4. **text** [ of a tweet ] \u0e02\u0e49\u0e2d\u0e04\u0e27\u0e32\u0e21\u0e43\u0e19\u0e17\u0e27\u0e35\u0e15\n5. **target** - the label we want to predict [ 0 = non-disaster , 1 = disaster ] \n\n> \u0e0b\u0e36\u0e48\u0e07\u0e43\u0e19 test data \u0e08\u0e30\u0e44\u0e21\u0e48\u0e21\u0e35 column target \u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e43\u0e0a\u0e49\u0e17\u0e14\u0e2a\u0e2d\u0e1a model ","7bc5e39c":"**Cross Validation**\n* \u0e41\u0e1a\u0e48\u0e07\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e40\u0e23\u0e35\u0e22\u0e19\u0e23\u0e39\u0e49\u0e2d\u0e2d\u0e01\u0e40\u0e1b\u0e47\u0e19 k \u0e0a\u0e38\u0e14\u0e40\u0e17\u0e48\u0e32 \u0e46 \u0e01\u0e31\u0e19 \u0e41\u0e25\u0e30\u0e17\u0e33\u0e01\u0e32\u0e23\u0e04\u0e33\u0e19\u0e27\u0e19 error \u0e08\u0e33\u0e19\u0e27\u0e19 k \u0e23\u0e2d\u0e1a\n* \u0e43\u0e0a\u0e49\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e2a\u0e48\u0e27\u0e19\u0e17\u0e35\u0e48\u0e40\u0e2b\u0e25\u0e37\u0e2d (k-1 \u0e0a\u0e38\u0e14) \u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e17\u0e33\u0e01\u0e32\u0e23\u0e2a\u0e23\u0e49\u0e32\u0e07 model\n* \u0e40\u0e01\u0e47\u0e1a\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e17\u0e35\u0e48\u0e41\u0e1a\u0e48\u0e07\u0e44\u0e27\u0e49 1 \u0e0a\u0e38\u0e14 \u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e17\u0e33\u0e01\u0e32\u0e23 evaluate\n* \u0e27\u0e19\u0e17\u0e33\u0e0b\u0e49\u0e33\u0e08\u0e19\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e17\u0e38\u0e01\u0e2a\u0e48\u0e27\u0e19\u0e16\u0e39\u0e01\u0e19\u0e33\u0e21\u0e32\u0e17\u0e14\u0e2a\u0e2d\u0e1a","bd38c1c3":"* \u0e17\u0e33\u0e01\u0e32\u0e23\u0e25\u0e1a stop words \u0e43\u0e19\u0e20\u0e32\u0e29\u0e32\u0e2d\u0e31\u0e07\u0e01\u0e24\u0e29 \n\n> \u0e40\u0e0a\u0e48\u0e19 the, a, at, for, above, on, is, all \u0e40\u0e1b\u0e47\u0e19\u0e15\u0e49\u0e19 \u0e42\u0e14\u0e22\u0e43\u0e0a\u0e49 nltk library\n\u0e40\u0e19\u0e37\u0e48\u0e2d\u0e07\u0e08\u0e32\u0e01\u0e44\u0e21\u0e48\u0e21\u0e35\u0e04\u0e27\u0e32\u0e21\u0e2b\u0e21\u0e32\u0e22\u0e43\u0e19\u0e01\u0e32\u0e23\u0e43\u0e0a\u0e49\u0e27\u0e34\u0e40\u0e04\u0e23\u0e32\u0e30\u0e2b\u0e4c ","2e96206b":"**- Check data shape of each data set**","7d335352":"* Graph \u0e40\u0e1b\u0e23\u0e35\u0e22\u0e1a\u0e40\u0e17\u0e35\u0e22\u0e1a\u0e08\u0e33\u0e19\u0e27\u0e19\u0e02\u0e49\u0e2d\u0e04\u0e27\u0e32\u0e21\u0e17\u0e35\u0e48\u0e40\u0e1b\u0e47\u0e19 disaster \u0e01\u0e31\u0e1a non-disaster","d01bbdb7":"* 10 location \u0e17\u0e35\u0e48\u0e21\u0e35\u0e08\u0e33\u0e19\u0e27\u0e19\u0e2a\u0e39\u0e07\u0e17\u0e35\u0e48\u0e2a\u0e38\u0e14\u0e43\u0e19 Train data","eb3eaeb7":"* \u0e40\u0e1b\u0e23\u0e35\u0e22\u0e1a\u0e40\u0e17\u0e35\u0e22\u0e1a\u0e08\u0e33\u0e19\u0e27\u0e19\u0e15\u0e31\u0e27\u0e2d\u0e31\u0e01\u0e29\u0e23\u0e17\u0e27\u0e35\u0e15 \u0e23\u0e30\u0e2b\u0e27\u0e48\u0e32\u0e07\u0e17\u0e27\u0e35\u0e15\u0e17\u0e35\u0e48\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e02\u0e49\u0e2d\u0e07\u0e01\u0e31\u0e1a\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34\u0e41\u0e25\u0e30\u0e44\u0e21\u0e48\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e02\u0e49\u0e2d\u0e07\u0e01\u0e31\u0e1a\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34 ","7b3e5f2b":"* \u0e40\u0e2d\u0e32\u0e04\u0e33\u0e43\u0e19\u0e1b\u0e23\u0e30\u0e42\u0e22\u0e04\u0e21\u0e32\u0e40\u0e23\u0e35\u0e22\u0e07\u0e15\u0e48\u0e2d\u0e01\u0e31\u0e19 \u0e14\u0e49\u0e27\u0e22\u0e01\u0e32\u0e23 join word ","2854c5df":"\u0e40\u0e23\u0e32\u0e44\u0e14\u0e49\u0e40\u0e25\u0e37\u0e2d\u0e01\u0e43\u0e0a\u0e49 Logistic Regression \u0e43\u0e19\u0e01\u0e32\u0e23 predict probability \u0e42\u0e14\u0e22\u0e01\u0e33\u0e2b\u0e19\u0e14\u0e04\u0e48\u0e32 parameter C \u0e40\u0e17\u0e48\u0e32\u0e01\u0e31\u0e1a 0.9 \u0e41\u0e25\u0e30\u0e40\u0e01\u0e47\u0e1a\u0e43\u0e19\u0e15\u0e31\u0e27\u0e41\u0e1b\u0e23 clf \u0e08\u0e32\u0e01\u0e19\u0e31\u0e49\u0e19\u0e08\u0e36\u0e07\u0e04\u0e33\u0e19\u0e27\u0e19\u0e2b\u0e32\u0e04\u0e48\u0e32 error \u0e02\u0e2d\u0e07\u0e41\u0e15\u0e48\u0e25\u0e30\u0e23\u0e2d\u0e1a\u0e01\u0e32\u0e23\u0e04\u0e33\u0e19\u0e27\u0e19","568f16b9":"* **\u0e1b\u0e31\u0e0d\u0e2b\u0e32\u0e17\u0e35\u0e48\u0e1e\u0e1a** \u0e04\u0e37\u0e2d \u0e17\u0e27\u0e35\u0e15\u0e17\u0e35\u0e48\u0e22\u0e32\u0e27\u0e08\u0e30\u0e21\u0e35\u0e19\u0e49\u0e33\u0e2b\u0e19\u0e31\u0e01\u0e02\u0e2d\u0e07\u0e04\u0e33\u0e40\u0e22\u0e2d\u0e30\u0e01\u0e27\u0e48\u0e32\u0e17\u0e27\u0e35\u0e15\u0e17\u0e35\u0e48\u0e2a\u0e31\u0e49\u0e19\u0e01\u0e27\u0e48\u0e32 \u0e17\u0e33\u0e43\u0e2b\u0e49\u0e1c\u0e25\u0e25\u0e31\u0e1e\u0e18\u0e4c\u0e17\u0e35\u0e48\u0e44\u0e14\u0e49\u0e44\u0e21\u0e48\u0e41\u0e21\u0e48\u0e19\u0e22\u0e33 \u0e08\u0e36\u0e07\u0e40\u0e25\u0e37\u0e2d\u0e01\u0e43\u0e0a\u0e49\u0e40\u0e1b\u0e47\u0e19 TF-IDF \u0e41\u0e17\u0e19 \u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e41\u0e01\u0e49\u0e44\u0e02\u0e1b\u0e31\u0e0d\u0e2b\u0e32\u0e19\u0e35\u0e49","e934f5bd":"* \u0e41\u0e17\u0e19\u0e17\u0e35\u0e48\u0e0a\u0e48\u0e2d\u0e07\u0e27\u0e48\u0e32\u0e07 null \u0e14\u0e49\u0e27\u0e22\u0e04\u0e33\u0e27\u0e48\u0e32 \n\n> no_location \u0e43\u0e19\u0e04\u0e2d\u0e25\u0e31\u0e21\u0e19\u0e4c location\n\n> no_keyword \u0e43\u0e19\u0e04\u0e2d\u0e25\u0e31\u0e21\u0e19\u0e4c Keyword","2ae306de":"* \u0e17\u0e33\u0e01\u0e32\u0e23\u0e41\u0e17\u0e19\u0e17\u0e35\u0e48\u0e0a\u0e37\u0e48\u0e2d\u0e02\u0e2d\u0e07\u0e23\u0e31\u0e10\u0e15\u0e48\u0e32\u0e07\u0e46\u0e43\u0e2b\u0e49\u0e2d\u0e22\u0e39\u0e48\u0e43\u0e19\u0e23\u0e39\u0e1b\u0e41\u0e1a\u0e1a\u0e0a\u0e37\u0e48\u0e2d\u0e1b\u0e23\u0e30\u0e40\u0e17\u0e28 \n\n> \u0e43\u0e2b\u0e49\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e02\u0e2d\u0e07 Location \u0e41\u0e2a\u0e14\u0e07\u0e1c\u0e25\u0e40\u0e1b\u0e47\u0e19\u0e0a\u0e37\u0e48\u0e2d\u0e1b\u0e23\u0e30\u0e40\u0e17\u0e28","9292d3e9":"**- Target Distribution in ' Keyword '**","48475cb3":"* \u0e17\u0e33\u0e01\u0e32\u0e23 remove emoji \n\n> \u0e42\u0e14\u0e22\u0e01\u0e32\u0e23\u0e41\u0e17\u0e19 emoji \u0e40\u0e1b\u0e47\u0e19\u0e23\u0e2b\u0e31\u0e2a\u0e43\u0e19\u0e17\u0e38\u0e01\u0e46\u0e2b\u0e21\u0e27\u0e14\u0e2b\u0e21\u0e39\u0e48 \u0e41\u0e25\u0e30\u0e25\u0e1a\u0e42\u0e14\u0e22\u0e43\u0e0a\u0e49 library re","4d3ceeb2":"* \u0e15\u0e23\u0e27\u0e08\u0e2a\u0e2d\u0e1a\u0e08\u0e33\u0e19\u0e27\u0e19 Target\n\n> 0 \u0e40\u0e1b\u0e47\u0e19\u0e17\u0e27\u0e35\u0e15\u0e17\u0e35\u0e48\u0e44\u0e21\u0e48\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e02\u0e49\u0e2d\u0e07\u0e01\u0e31\u0e1a\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34 \u0e41\u0e25\u0e30\n> 1 \u0e40\u0e1b\u0e47\u0e19\u0e17\u0e27\u0e35\u0e15\u0e17\u0e35\u0e48\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e02\u0e49\u0e2d\u0e07\u0e01\u0e31\u0e1a\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34","e6157373":"> sahib singh ,\"NLP Starter for Beginners\", https:\/\/www.kaggle.com\/sahib12\/nlp-starter-for-beginners\n\n> Bavalpreet ,\"NLP with Disaster Tweets\" , https:\/\/www.kaggle.com\/bavalpreet26\/nlp-with-disaster-tweets","3edef7aa":"* \u0e17\u0e33 bag-of-word \u0e42\u0e14\u0e22\u0e01\u0e32\u0e23\u0e19\u0e31\u0e1a\u0e27\u0e48\u0e32\u0e21\u0e35\u0e04\u0e33\u0e46\u0e19\u0e31\u0e49\u0e19\u0e1b\u0e23\u0e32\u0e01\u0e0e\u0e17\u0e31\u0e49\u0e07\u0e2b\u0e21\u0e14\u0e01\u0e35\u0e48\u0e04\u0e23\u0e31\u0e49\u0e07\u0e43\u0e19\u0e1b\u0e23\u0e30\u0e42\u0e22\u0e04 \u0e41\u0e25\u0e49\u0e27\u0e19\u0e33\u0e04\u0e33\u0e28\u0e31\u0e1e\u0e17\u0e4c\u0e44\u0e1b\u0e43\u0e2a\u0e48\u0e14\u0e49\u0e27\u0e22 function CountVectorizer \u0e17\u0e35\u0e48\u0e08\u0e30\u0e41\u0e1b\u0e25\u0e07\u0e02\u0e49\u0e2d\u0e04\u0e27\u0e32\u0e21\u0e40\u0e1b\u0e47\u0e19 vector \u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e25\u0e14\u0e21\u0e34\u0e15\u0e34\u0e02\u0e2d\u0e07\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25 \u0e41\u0e25\u0e30\u0e19\u0e33\u0e44\u0e1b\u0e04\u0e33\u0e19\u0e27\u0e19\u0e44\u0e14\u0e49 \n\u0e42\u0e14\u0e22\u0e01\u0e32\u0e23\u0e19\u0e33\u0e01\u0e25\u0e38\u0e48\u0e21\u0e02\u0e2d\u0e07 token \u0e21\u0e35\u0e2a\u0e23\u0e49\u0e32\u0e07\u0e40\u0e1b\u0e47\u0e19 matrix \u0e42\u0e14\u0e22\u0e43\u0e0a\u0e49\u0e01\u0e25\u0e38\u0e48\u0e21\u0e02\u0e2d\u0e07\u0e04\u0e33\u0e17\u0e35\u0e48\u0e21\u0e35\u0e40\u0e1b\u0e47\u0e19\u0e15\u0e31\u0e27\u0e2d\u0e49\u0e32\u0e07\u0e2d\u0e34\u0e07 \u0e04\u0e33\u0e17\u0e35\u0e48\u0e21\u0e35\u0e43\u0e19\u0e1b\u0e23\u0e30\u0e42\u0e22\u0e04\u0e08\u0e30\u0e16\u0e39\u0e01\u0e15\u0e31\u0e49\u0e07\u0e04\u0e48\u0e32\u0e40\u0e1b\u0e47\u0e19 1 \u0e04\u0e33\u0e17\u0e35\u0e48\u0e44\u0e21\u0e48\u0e21\u0e35\u0e08\u0e30\u0e40\u0e1b\u0e47\u0e19 0 \n\n> \u0e40\u0e0a\u0e48\u0e19 \u0e21\u0e35\u0e01\u0e25\u0e38\u0e48\u0e21\u0e02\u0e2d\u0e07\u0e04\u0e33 [\u201cThis\u201d, \u201cis\u201d, \u201cam\u201d, \u201care\u201d, \u201ca\u201d, \u201cbe\u201d, \u201ctest\u201d, \u201cword\u201d, \u201csentence\u201d] \n\n> \u0e1b\u0e23\u0e30\u0e42\u0e22\u0e04 \u201cThis is a test sentence\u201d \u0e08\u0e30\u0e41\u0e1b\u0e25\u0e07\u0e40\u0e1b\u0e47\u0e19 matrix \u0e44\u0e14\u0e49\u0e14\u0e31\u0e07\u0e19\u0e35\u0e49 [1, 1, 0, 0, 1, 0, 1, 0 ,1]","ff359625":"# \u0e23\u0e32\u0e22\u0e07\u0e32\u0e19\u0e19\u0e35\u0e49\u0e40\u0e1b\u0e47\u0e19\u0e2a\u0e48\u0e27\u0e19\u0e2b\u0e19\u0e36\u0e48\u0e07\u0e02\u0e2d\u0e07\u0e27\u0e34\u0e0a\u0e32 DSI 206 Multimedia Representation Management","039896f9":"Testing Data \u0e21\u0e35 **4 columns** (id , keyword , location , text ) , \u0e41\u0e25\u0e30\u0e21\u0e35 **3263 rows**","f413038f":"\u0e19\u0e33 model \u0e17\u0e35\u0e48\u0e44\u0e14\u0e49\u0e21\u0e32 predict \u0e01\u0e31\u0e1a test_vectors \u0e41\u0e25\u0e30\u0e19\u0e33\u0e21\u0e32 check \u0e01\u0e31\u0e1a\u0e40\u0e09\u0e25\u0e22 \u0e04\u0e37\u0e2d target \u0e43\u0e19\u0e44\u0e1f\u0e25\u0e4c sample_submission \u0e08\u0e32\u0e01\u0e19\u0e31\u0e49\u0e19\u0e08\u0e36\u0e07\u0e2a\u0e23\u0e49\u0e32\u0e07\u0e44\u0e1f\u0e25\u0e4c csv \u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e17\u0e33\u0e01\u0e32\u0e23 submit \u0e1c\u0e25\u0e17\u0e35\u0e48\u0e44\u0e14\u0e49\u0e43\u0e19 kaggle ","4b5c8324":"* 10 keyword \u0e17\u0e35\u0e48\u0e21\u0e35\u0e08\u0e33\u0e19\u0e27\u0e19\u0e21\u0e32\u0e01\u0e17\u0e35\u0e48\u0e2a\u0e38\u0e14\u0e43\u0e19 Train data\n\n","d9776a4a":"**Target Distribution in ' location '**","1a6696ce":"Sub Sample \u0e21\u0e35 **2 columns** (id , target) , \u0e41\u0e25\u0e30\u0e21\u0e35 **3263 rows**\n","b4f0c0d5":"**- Reading Dataset**\n> \u0e19\u0e33\u0e40\u0e02\u0e49\u0e32\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e41\u0e25\u0e30\u0e40\u0e23\u0e35\u0e22\u0e01\u0e14\u0e39\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e2b\u0e31\u0e27\u0e04\u0e2d\u0e25\u0e31\u0e21\u0e19\u0e4c\u0e17\u0e31\u0e49\u0e07 Train \u0e41\u0e25\u0e30 Test data","59b54605":"# *> \u0e17\u0e33 Text Classification \u0e42\u0e14\u0e22\u0e01\u0e32\u0e23\u0e43\u0e0a\u0e49 Logistic Regression \u0e41\u0e25\u0e30 Cross Validation*","374f6f78":"* \u0e40\u0e1b\u0e23\u0e35\u0e22\u0e1a\u0e40\u0e17\u0e35\u0e22\u0e1a\u0e08\u0e33\u0e19\u0e27\u0e19\u0e04\u0e33\u0e43\u0e19\u0e17\u0e27\u0e35\u0e15 \u0e23\u0e30\u0e2b\u0e27\u0e48\u0e32\u0e07\u0e17\u0e27\u0e35\u0e15\u0e17\u0e35\u0e48\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e02\u0e49\u0e2d\u0e07\u0e01\u0e31\u0e1a\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34\u0e41\u0e25\u0e30\u0e44\u0e21\u0e48\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e02\u0e49\u0e2d\u0e07\u0e01\u0e31\u0e1a\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34 ","6a282bae":"* \u0e2a\u0e23\u0e49\u0e32\u0e07\u0e15\u0e32\u0e23\u0e32\u0e07\u0e1e\u0e37\u0e48\u0e2d\u0e40\u0e1b\u0e23\u0e35\u0e22\u0e1a\u0e40\u0e17\u0e35\u0e22\u0e1a\u0e08\u0e33\u0e19\u0e27\u0e19\u0e17\u0e27\u0e35\u0e15\u0e17\u0e35\u0e48\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e02\u0e49\u0e2d\u0e07\u0e41\u0e25\u0e30\u0e44\u0e21\u0e48\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e02\u0e49\u0e2d\u0e07\u0e01\u0e31\u0e1a\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34","b0dced66":"**- Check Class Distribution of two classes (0 and 1) using Train Data**","64d4cd49":"* Lemmatizing \u0e04\u0e37\u0e2d\u0e01\u0e32\u0e23\u0e17\u0e33\u0e43\u0e2b\u0e49\u0e04\u0e33\u0e17\u0e35\u0e48\u0e2d\u0e22\u0e39\u0e48\u0e43\u0e19\u0e23\u0e39\u0e1b\u0e41\u0e1a\u0e1a\u0e15\u0e48\u0e32\u0e07\u0e46 \u0e41\u0e1b\u0e25\u0e07\u0e01\u0e25\u0e31\u0e1a\u0e21\u0e32\u0e2d\u0e22\u0e39\u0e48\u0e43\u0e19\u0e23\u0e39\u0e1b\u0e1b\u0e01\u0e15\u0e34 root word\n\n> \u0e40\u0e0a\u0e48\u0e19 Feet \u0e40\u0e1b\u0e47\u0e19 Foot \/\/\nwolves \u0e40\u0e1b\u0e47\u0e19 wolf \/\/\nis,am,are \u0e40\u0e1b\u0e47\u0e19 be","e6765455":"* \u0e17\u0e33\u0e01\u0e32\u0e23\u0e41\u0e1a\u0e48\u0e07\u0e04\u0e33 \u0e42\u0e14\u0e22\u0e43\u0e0a\u0e49 RegexpTokenizer ","c9060575":"\u0e19\u0e33\u0e1c\u0e25\u0e17\u0e35\u0e48\u0e44\u0e14\u0e49\u0e21\u0e32 fit \u0e40\u0e02\u0e49\u0e32\u0e01\u0e31\u0e1a train_vector \u0e41\u0e25\u0e30 column target \u0e02\u0e2d\u0e07 train","cac400b9":"# References\n\n","df7f4cd7":"**\u0e23\u0e32\u0e22\u0e0a\u0e37\u0e48\u0e2d\u0e2a\u0e21\u0e32\u0e0a\u0e34\u0e01**\n\n1. \u0e19\u0e32\u0e07\u0e2a\u0e32\u0e27 \u0e0d\u0e32\u0e13\u0e34\u0e28\u0e32 \u0e08\u0e34\u0e19\u0e15\u0e19\u0e44\u0e0a\u0e22\u0e27\u0e31\u0e12\u0e19\u0e4c 6109656287\n2. \u0e19\u0e32\u0e07\u0e2a\u0e32\u0e27\u0e13\u0e31\u0e10\u0e0a\u0e22\u0e32 \u0e09\u0e31\u0e19\u0e40\u0e1f\u0e37\u0e48\u0e2d\u0e07\u0e1f\u0e39      6109656493\n3. \u0e19\u0e32\u0e07\u0e2a\u0e32\u0e27\u0e2d\u0e31\u0e0d\u0e27\u0e35\u0e13\u0e4c \u0e1e\u0e31\u0e19\u0e18\u0e4c\u0e1a\u0e39\u0e23\u0e13\u0e32\u0e19\u0e19\u0e17\u0e4c   6109656048","5c790620":"* Top 10 Keyword \u0e17\u0e35\u0e48\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34 \u0e41\u0e25\u0e30\u0e17\u0e35\u0e48\u0e44\u0e21\u0e48\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e01\u0e31\u0e1a\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34","c3b67734":"# *> TF-IDF*","4e110292":"> \u0e08\u0e32\u0e01\u0e01\u0e23\u0e32\u0e1f\u0e41\u0e2a\u0e14\u0e07\u0e43\u0e2b\u0e49\u0e40\u0e2b\u0e47\u0e19\u0e27\u0e48\u0e32 \u0e08\u0e33\u0e19\u0e27\u0e19\u0e17\u0e27\u0e35\u0e15\u0e17\u0e35\u0e48\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e02\u0e49\u0e2d\u0e07\u0e01\u0e31\u0e1a\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34\u0e21\u0e35\u0e08\u0e33\u0e19\u0e27\u0e19\u0e15\u0e31\u0e27\u0e2d\u0e31\u0e01\u0e29\u0e23\u0e43\u0e19\u0e17\u0e27\u0e35\u0e15\u0e2d\u0e22\u0e39\u0e48\u0e43\u0e19\u0e0a\u0e48\u0e27\u0e07 120-140 \n\u0e40\u0e0a\u0e48\u0e19\u0e40\u0e14\u0e35\u0e22\u0e27\u0e01\u0e31\u0e19\u0e01\u0e31\u0e1a\u0e17\u0e27\u0e35\u0e15\u0e17\u0e35\u0e48\u0e44\u0e21\u0e48\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e02\u0e49\u0e2d\u0e07\u0e01\u0e31\u0e1a\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34","e79d060a":"# 3. Modeling\n","752c2817":"**- Counting Number of Missing Values**","8850c689":"Training Data \u0e21\u0e35 **5 columns**** (id , keyword , location , text , target) , \u0e41\u0e25\u0e30\u0e21\u0e35 **7613 rows**","3c130377":"* \u0e17\u0e33\u0e01\u0e32\u0e23 Clean data \u0e42\u0e14\u0e22\u0e43\u0e0a\u0e49 Regular Expression \n\n> \u0e17\u0e33\u0e15\u0e31\u0e27\u0e2d\u0e31\u0e01\u0e29\u0e23\u0e43\u0e2b\u0e49\u0e40\u0e1b\u0e47\u0e19\u0e15\u0e31\u0e27\u0e1e\u0e34\u0e21\u0e1e\u0e4c\u0e40\u0e25\u0e47\u0e01\u0e17\u0e31\u0e49\u0e07\u0e2b\u0e21\u0e14\n\n> \u0e25\u0e1a\u0e40\u0e04\u0e23\u0e37\u0e48\u0e2d\u0e07\u0e2b\u0e21\u0e32\u0e22\u0e15\u0e48\u0e32\u0e07\u0e46\u0e17\u0e35\u0e48\u0e44\u0e21\u0e48\u0e15\u0e49\u0e2d\u0e07\u0e01\u0e32\u0e23 \u0e40\u0e0a\u0e48\u0e19 !\u20ac@%#*&~ \u0e23\u0e27\u0e21\u0e44\u0e1b\u0e16\u0e36\u0e07 URL , HTML , \u0e02\u0e36\u0e49\u0e19\u0e1a\u0e23\u0e23\u0e17\u0e31\u0e14\u0e43\u0e2b\u0e21\u0e48 , \u0e40\u0e04\u0e23\u0e37\u0e48\u0e2d\u0e07\u0e2b\u0e21\u0e32\u0e22\u0e27\u0e23\u0e23\u0e04\u0e15\u0e2d\u0e19 , \u0e04\u0e33\u0e17\u0e35\u0e48\u0e21\u0e35\u0e15\u0e31\u0e27\u0e40\u0e25\u0e02\u0e04\u0e31\u0e48\u0e19 ","2c8aee08":"* check \u0e41\u0e15\u0e48\u0e25\u0e30\u0e04\u0e2d\u0e25\u0e31\u0e21\u0e19\u0e4c\u0e02\u0e2d\u0e07 Test data \u0e27\u0e48\u0e32\u0e21\u0e35 missing values \u0e08\u0e33\u0e19\u0e27\u0e19\u0e40\u0e17\u0e48\u0e32\u0e43\u0e14\n","eb040400":"* \u0e17\u0e33 bag-of-word \u0e42\u0e14\u0e22\u0e01\u0e32\u0e23\u0e43\u0e0a\u0e49 TfidfVectorizer \u0e17\u0e35\u0e48\u0e40\u0e1b\u0e47\u0e19 function \u0e43\u0e0a\u0e49\u0e41\u0e1b\u0e25\u0e07\u0e02\u0e49\u0e2d\u0e04\u0e27\u0e32\u0e21\u0e40\u0e1b\u0e47\u0e19 vector \u0e40\u0e0a\u0e48\u0e19\u0e40\u0e14\u0e35\u0e22\u0e27\u0e01\u0e31\u0e19\u0e01\u0e31\u0e1a CountVectorizer\n\n> \u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e40\u0e1e\u0e34\u0e48\u0e21\u0e04\u0e27\u0e32\u0e21\u0e16\u0e39\u0e01\u0e15\u0e49\u0e2d\u0e07\u0e43\u0e19\u0e01\u0e32\u0e23\u0e19\u0e31\u0e1a \u0e42\u0e14\u0e22\u0e01\u0e32\u0e23\u0e43\u0e0a\u0e49 Term Frequency \u0e02\u0e2d\u0e07\u0e08\u0e33\u0e19\u0e27\u0e19\u0e04\u0e23\u0e31\u0e49\u0e07\u0e17\u0e35\u0e48\u0e04\u0e33\u0e19\u0e31\u0e49\u0e19\u0e1b\u0e23\u0e32\u0e01\u0e0f\u0e43\u0e19\u0e17\u0e27\u0e35\u0e15 \u0e04\u0e33\u0e19\u0e27\u0e13\u0e42\u0e14\u0e22\u0e43\u0e0a\u0e49\u0e2a\u0e39\u0e15\u0e23 TF = \u0e08\u0e33\u0e19\u0e27\u0e19\u0e04\u0e23\u0e31\u0e49\u0e07\u0e04\u0e33\u0e19\u0e31\u0e49\u0e19\u0e46\/\u0e08\u0e33\u0e19\u0e27\u0e19\u0e04\u0e33\u0e17\u0e31\u0e49\u0e07\u0e2b\u0e21\u0e14\u0e43\u0e19\u0e41\u0e15\u0e48\u0e25\u0e30\u0e17\u0e27\u0e35\u0e15\n\n> \u0e41\u0e25\u0e49\u0e27\u0e08\u0e36\u0e07\u0e19\u0e33\u0e21\u0e32\u0e04\u0e39\u0e13\u0e01\u0e31\u0e1a Inverse Document Frequency \u0e41\u0e25\u0e49\u0e27\u0e17\u0e33\u0e01\u0e32\u0e23 take log \n> \u0e27\u0e34\u0e18\u0e35\u0e19\u0e35\u0e49\u0e08\u0e36\u0e07\u0e40\u0e1b\u0e47\u0e19\u0e27\u0e34\u0e18\u0e35\u0e01\u0e32\u0e23\u0e2b\u0e32\u0e04\u0e27\u0e32\u0e21\u0e2a\u0e33\u0e04\u0e31\u0e0d\u0e02\u0e2d\u0e07\u0e04\u0e33 \u0e17\u0e35\u0e48\u0e43\u0e0a\u0e49\u0e41\u0e19\u0e27\u0e04\u0e34\u0e14\u0e27\u0e48\u0e32\u0e22\u0e34\u0e48\u0e07\u0e04\u0e33\u0e19\u0e31\u0e49\u0e19\u0e1b\u0e23\u0e32\u0e01\u0e0f\u0e19\u0e49\u0e2d\u0e22\u0e08\u0e30\u0e22\u0e34\u0e48\u0e07\u0e21\u0e35\u0e04\u0e27\u0e32\u0e21\u0e2a\u0e33\u0e04\u0e31\u0e0d\u0e21\u0e32\u0e01 \u0e42\u0e14\u0e22\u0e19\u0e33\u0e04\u0e48\u0e32 TF \u0e01\u0e31\u0e1a IDF \u0e21\u0e32\u0e04\u0e39\u0e13\u0e01\u0e31\u0e19","48b18ba9":"**- Import Library**\n\n> \u0e19\u0e33\u0e40\u0e02\u0e49\u0e32 library \u0e17\u0e35\u0e48\u0e15\u0e49\u0e2d\u0e07\u0e43\u0e0a\u0e49\u0e07\u0e32\u0e19","e6faa16c":"# 2. Data Cleaning\n\n> \u0e08\u0e32\u0e01\u0e01\u0e32\u0e23\u0e17\u0e35\u0e48\u0e44\u0e14\u0e49\u0e2a\u0e33\u0e23\u0e27\u0e08\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e41\u0e25\u0e49\u0e27 \u0e02\u0e31\u0e49\u0e19\u0e15\u0e2d\u0e19\u0e15\u0e48\u0e2d\u0e44\u0e1b \u0e04\u0e37\u0e2d \u0e01\u0e32\u0e23\u0e17\u0e33\u0e04\u0e27\u0e32\u0e21\u0e2a\u0e30\u0e2d\u0e32\u0e14\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25 \n\n> \u0e42\u0e14\u0e22\u0e01\u0e32\u0e23\u0e25\u0e1a data \u0e2a\u0e48\u0e27\u0e19\u0e17\u0e35\u0e48\u0e44\u0e21\u0e48\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e02\u0e49\u0e2d\u0e07\u0e2b\u0e23\u0e37\u0e2d\u0e2a\u0e48\u0e27\u0e19\u0e17\u0e35\u0e48\u0e44\u0e21\u0e48\u0e08\u0e33\u0e40\u0e1b\u0e47\u0e19\u0e2d\u0e2d\u0e01\u0e44\u0e1b \u0e43\u0e2b\u0e49\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e21\u0e35\u0e04\u0e38\u0e13\u0e20\u0e32\u0e1e\u0e21\u0e32\u0e01\u0e17\u0e35\u0e48\u0e2a\u0e38\u0e14 \u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e40\u0e15\u0e23\u0e35\u0e22\u0e21\u0e1e\u0e23\u0e49\u0e2d\u0e21\u0e43\u0e19\u0e01\u0e32\u0e23\u0e17\u0e33 model ","ff677c17":"# *> Bag-of-word*","e7a6adec":"> \u0e08\u0e32\u0e01\u0e01\u0e23\u0e32\u0e1f\u0e41\u0e2a\u0e14\u0e07\u0e43\u0e2b\u0e49\u0e40\u0e2b\u0e47\u0e19\u0e27\u0e48\u0e32 \u0e17\u0e27\u0e35\u0e15\u0e17\u0e35\u0e48\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e02\u0e49\u0e2d\u0e07\u0e01\u0e31\u0e1a\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34\u0e21\u0e35\u0e08\u0e33\u0e19\u0e27\u0e19\u0e04\u0e33\u0e2d\u0e22\u0e39\u0e48\u0e43\u0e19\u0e0a\u0e48\u0e27\u0e07 17-18 \u0e04\u0e33 \u0e21\u0e32\u0e01\u0e17\u0e35\u0e48\u0e2a\u0e38\u0e14 \u0e41\u0e25\u0e30\u0e17\u0e27\u0e35\u0e15\u0e17\u0e35\u0e48\u0e44\u0e21\u0e48\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e02\u0e49\u0e2d\u0e07\u0e01\u0e31\u0e1a\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34\u0e21\u0e35\u0e08\u0e33\u0e19\u0e27\u0e19\u0e04\u0e33\u0e2d\u0e22\u0e39\u0e48\u0e43\u0e19\u0e0a\u0e48\u0e27\u0e07 18-19 \u0e04\u0e33 \u0e21\u0e32\u0e01\u0e17\u0e35\u0e48\u0e2a\u0e38\u0e14","4cef9d6b":"* \u0e15\u0e23\u0e27\u0e08\u0e2a\u0e2d\u0e1a\u0e27\u0e48\u0e32 Train \u0e41\u0e25\u0e30 Test \u0e21\u0e35\u0e08\u0e33\u0e19\u0e27\u0e19 keyword \u0e17\u0e35\u0e48\u0e44\u0e21\u0e48\u0e0b\u0e49\u0e33\u0e01\u0e31\u0e19\u0e17\u0e31\u0e49\u0e07\u0e2b\u0e21\u0e14\u0e40\u0e17\u0e48\u0e32\u0e43\u0e14 \u0e43\u0e19 test data","5849562a":"> \u0e08\u0e30\u0e40\u0e2b\u0e47\u0e19\u0e27\u0e48\u0e32\u0e17\u0e27\u0e35\u0e15\u0e17\u0e35\u0e48\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e02\u0e49\u0e2d\u0e07\u0e01\u0e31\u0e1a\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34 (1) \u0e21\u0e35\u0e08\u0e33\u0e19\u0e27\u0e19\u0e19\u0e49\u0e2d\u0e22\u0e01\u0e27\u0e48\u0e32 \u0e17\u0e27\u0e35\u0e15\u0e44\u0e21\u0e48\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e02\u0e49\u0e2d\u0e07\u0e01\u0e31\u0e1a\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34 (0)","730e2f91":"# **1. Data Exploration**\n\n> \u0e02\u0e31\u0e49\u0e19\u0e15\u0e2d\u0e19\u0e41\u0e23\u0e01 \u0e15\u0e49\u0e2d\u0e07\u0e17\u0e33\u0e01\u0e32\u0e23\u0e2a\u0e33\u0e23\u0e27\u0e08\u0e41\u0e25\u0e30\u0e27\u0e34\u0e40\u0e04\u0e23\u0e32\u0e30\u0e2b\u0e4c\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e27\u0e48\u0e32 data \u0e02\u0e2d\u0e07\u0e40\u0e23\u0e32\u0e21\u0e35\u0e2d\u0e30\u0e44\u0e23\u0e1a\u0e49\u0e32\u0e07 \u0e2a\u0e32\u0e21\u0e32\u0e23\u0e16\u0e19\u0e33\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e2a\u0e48\u0e27\u0e19\u0e43\u0e14\u0e44\u0e1b\u0e43\u0e0a\u0e49\u0e07\u0e32\u0e19\u0e44\u0e14\u0e49 \n\n> \u0e41\u0e25\u0e30\u0e21\u0e35\u0e2a\u0e48\u0e27\u0e19\u0e43\u0e14\u0e17\u0e35\u0e48\u0e15\u0e49\u0e2d\u0e07\u0e17\u0e33\u0e01\u0e32\u0e23 clean \u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e17\u0e33\u0e43\u0e2b\u0e49 model \u0e17\u0e35\u0e48\u0e44\u0e14\u0e49\u0e19\u0e31\u0e49\u0e19\u0e21\u0e35\u0e1b\u0e23\u0e30\u0e2a\u0e34\u0e17\u0e18\u0e34\u0e20\u0e32\u0e1e\u0e21\u0e32\u0e01\u0e17\u0e35\u0e48\u0e2a\u0e38\u0e14","2608a3f1":"* \u0e40\u0e1b\u0e25\u0e35\u0e48\u0e22\u0e19\u0e04\u0e33\u0e43\u0e19\u0e17\u0e27\u0e35\u0e15\u0e43\u0e2b\u0e49\u0e2d\u0e22\u0e39\u0e48\u0e43\u0e19\u0e23\u0e39\u0e1b\u0e40\u0e14\u0e35\u0e22\u0e27\u0e01\u0e31\u0e19\u0e42\u0e14\u0e22\u0e01\u0e32\u0e23\u0e17\u0e33 Stemmimg\n\n> \u0e04\u0e37\u0e2d\u0e01\u0e32\u0e23\u0e15\u0e31\u0e14\u0e04\u0e33\u0e25\u0e07\u0e17\u0e49\u0e32\u0e22\u0e2d\u0e2d\u0e01 (\u0e40\u0e0a\u0e48\u0e19 s, es, ed, ing) \n\n> stem \u0e2a\u0e32\u0e21\u0e32\u0e23\u0e16\u0e40\u0e02\u0e35\u0e22\u0e19\u0e44\u0e14\u0e49\u0e2b\u0e25\u0e32\u0e22\u0e23\u0e39\u0e1b stemmimg, stemmed,stems \u0e40\u0e23\u0e32\u0e08\u0e30\u0e17\u0e33\u0e01\u0e32\u0e23\u0e41\u0e1b\u0e25\u0e07\u0e43\u0e2b\u0e49\u0e21\u0e31\u0e19\u0e2d\u0e22\u0e39\u0e48\u0e43\u0e19\u0e23\u0e39\u0e1b\u0e40\u0e14\u0e35\u0e22\u0e27\u0e04\u0e37\u0e2d stem","c8a6345f":"* check \u0e41\u0e15\u0e48\u0e25\u0e30\u0e04\u0e2d\u0e25\u0e31\u0e21\u0e19\u0e4c\u0e02\u0e2d\u0e07 Train data \u0e27\u0e48\u0e32\u0e21\u0e35 missing values \u0e08\u0e33\u0e19\u0e27\u0e19\u0e40\u0e17\u0e48\u0e32\u0e43\u0e14\n"}}