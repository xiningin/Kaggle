{"cell_type":{"85080a81":"code","b4503315":"code","1143b7bd":"code","4723dc96":"code","d0803c4b":"code","f58aa17a":"code","9abe454c":"code","b1f2ba6d":"code","7cb2f159":"code","05a1b6d0":"code","d8ca1fa1":"code","a3b91431":"code","5d436664":"code","cbeb9378":"code","1287298b":"code","f8ce1f25":"code","fe31323b":"code","5fd9a51f":"code","db27e205":"code","d203e786":"code","33d8343f":"code","21a3b1b0":"code","75383858":"code","17ad3e54":"code","f96aec82":"code","95552cbe":"code","183a1f39":"code","b89291d8":"code","18d60a03":"code","07d541fb":"code","cda9ff1d":"code","c03c5195":"code","3f3d0653":"code","5a57b1d5":"code","679dd73a":"code","47ebb056":"code","318d08a7":"code","08200e85":"code","8771da8d":"code","26547ac1":"code","328d5a9d":"code","aebd06f2":"code","4d4deeb6":"code","403843eb":"code","11f41a30":"code","11206f32":"code","4de0cfdc":"code","2fc1fc43":"code","f5031645":"code","901c031f":"code","aa51f442":"code","47362ab3":"code","91073a06":"code","54a860ab":"code","6b05f118":"code","9fefadee":"code","4dd2c205":"code","6b253fe2":"code","45a80511":"code","38984ba1":"code","a112a349":"code","5a34a392":"code","bef459f6":"code","2785a168":"code","f1274022":"markdown","f013953a":"markdown","b6a4f8c3":"markdown","81aeffe8":"markdown","2cf07db9":"markdown","cb4db497":"markdown","79052800":"markdown","3ce7606f":"markdown","b0cb3441":"markdown","88b8582f":"markdown","d0b7169c":"markdown","4f138b39":"markdown","8f2db8a1":"markdown","c15f405b":"markdown","5be2b717":"markdown","df383187":"markdown","2c81870a":"markdown","eeb94cd1":"markdown","a99d8e12":"markdown","4d5360a5":"markdown","e3bd01ef":"markdown","d7411c99":"markdown","e12ed732":"markdown","72080ac3":"markdown"},"source":{"85080a81":"# here we are importing important libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport plotly.express as px\nimport warnings\nwarnings.filterwarnings(\"ignore\")","b4503315":"# here we are installing dabl\n!pip install dabl","1143b7bd":"import dabl","4723dc96":"# here we are reading our dataset\nData = pd.read_csv(\"..\/input\/student-performance-dataset\/Student Performance.csv\")","d0803c4b":"# here we are printing first 5 lines of our dataset\nData.head()","f58aa17a":"# here we are checking if there is any NaN value or not\nData.isnull().sum()","9abe454c":"# here we are checking shape of our dataset\nData.shape","b1f2ba6d":"# here we are printing info of our dataset\nData.info()","7cb2f159":"# here we are printing summary of our dataset\nData.describe()","05a1b6d0":"# here we are printing name of all the columns\nData.columns.values","d8ca1fa1":"# here we are doing comparision of all other attribute with math marks\nplt.rcParams['figure.figsize'] = (12, 4)\nplt.style.use('classic')\ndabl.plot(Data, target_col = 'math score')","a3b91431":"# here we are doing comparision of all other attribute with reading marks\nplt.rcParams['figure.figsize'] = (10, 2)\nplt.style.use('bmh')\ndabl.plot(Data, target_col = 'reading score')","5d436664":"# here we are doing comparision of all other attribute with writing marks\nplt.rcParams['figure.figsize'] = (10, 2)\nplt.style.use('seaborn-pastel')\ndabl.plot(Data, target_col = 'writing score')","cbeb9378":"# here we are calculating probability of student scoring more the 60 marks in maths subject\nTotal_students = Data.shape[0]\nmore_than_60_score = Data[Data['math score'] >60 ].shape[0]\n\nprobability_of_students_scoring_more_than_60 = (more_than_60_score\/Total_students)*100\nprint(\"Probability of Students Scoring more than 60 marks in Maths :\", \n      probability_of_students_scoring_more_than_60)","1287298b":"# here we are calculating probability of student scoring more the 60 marks in reading subject\nTotal_students = Data.shape[0]\nmore_than_60_score = Data[Data['reading score'] >60 ].shape[0]\n\nprobability_of_students_scoring_more_than_60 = (more_than_60_score\/Total_students)*100\nprint(\"Probability of Students Scoring more than 60 marks in reading :\", \n      probability_of_students_scoring_more_than_60)","f8ce1f25":"# here we are calculating probability of student scoring more the 60 marks in writing subject\nTotal_students = Data.shape[0]\nmore_than_60_score = Data[Data['writing score'] >60 ].shape[0]\n\nprobability_of_students_scoring_more_than_60 = (more_than_60_score\/Total_students)*100\nprint(\"Probability of Students Scoring more than 60 marks in writing :\", \n      probability_of_students_scoring_more_than_60)","fe31323b":"# here we are checking probability of student passing in all three subjects(maths,reading,writing)\nTotal_students = Data.shape[0]\nnumber_of_students_passing_in_all_three_subjects = Data[(Data['math score'] > 40) &\n                                                  (Data['writing score'] > 40) & \n                                                  (Data['reading score'] > 40)].shape[0]\nprobability_of_students_passing_in_all_three_subjects = (number_of_students_passing_in_all_three_subjects\/Total_students)*100\nprint(\"The Probability of Students Passing in all the Subjects is :\",\n      (probability_of_students_passing_in_all_three_subjects))","5fd9a51f":"# here we are checking probability of student scoring more than 95 marks in three subjects(maths,reading\n# ,writing)\nTotal_students = Data.shape[0]\nnumber_of_students_scoring_more_than_95 = Data[(Data['math score'] > 95) &\n                                                  (Data['writing score'] > 95) & \n                                                  (Data['reading score'] > 95)].shape[0]\n\nprobability_of_students_scoring_more_than_95_in_all_subjects = (number_of_students_scoring_more_than_95\/Total_students)*100\nprint(\"The Probability of Students scoring more than 95 in all Subjects is:\",\n      (probability_of_students_scoring_more_than_95_in_all_subjects))","db27e205":"# here we are checking skweness for subject maths,reading,writing\nplt.subplot(1, 3, 1)\nsns.distplot(Data['math score'])\n\nplt.subplot(1, 3, 2)\nsns.distplot(Data['reading score'])\n\nplt.subplot(1, 3, 3)\nsns.distplot(Data['writing score'])\n\nplt.suptitle('Checking for Skewness', fontsize = 10)\nplt.show()","d203e786":"# here we are checking inference\n# lets take seed so that everytime the random values come out to be constant\nnp.random.seed(2)\n\n# lets take 200 sample values from the dataset of 1000 values\nsample_math_marks = np.random.choice(a= Data['math score'], size=200)\n\n# getting the sample mean\nprint (\"Sample mean for Math Scores:\", sample_math_marks.mean() )          \n\n# getting the population mean\nprint(\"Population mean for Math Scores:\", Data['math score'].mean())\n\n# lets take 200 sample values from the dataset of 1000 values\nsample_reading_marks = np.random.choice(a= Data['reading score'], size=200)\n\n# getting the sample mean\nprint (\"\\nSample mean for Reading Scores:\", sample_reading_marks.mean() )          \n\n# getting the population mean\nprint(\"Population mean for Reading Scores:\", Data['reading score'].mean())\n\n# lets take 200 sample values from the dataset of 1000 values\nsample_writing_marks = np.random.choice(a= Data['writing score'], size=200)\n\n# getting the sample mean\nprint (\"\\nSample mean for Writing Scores:\", sample_math_marks.mean() )          \n\n# getting the population mean\nprint(\"Population mean for Writing Scores:\", Data['writing score'].mean())","33d8343f":"# here we are checking confidence interval for maths\n# here we are importing the scipy package\nimport scipy.stats as stats\nimport math\n\n# lets seed the random values\nnp.random.seed(2)\n\n# here we are taking a sample size\nsample_size = 1000\nsample = np.random.choice(a= Data['math score'],\n                          size = sample_size)\nsample_mean = sample.mean()\n\n# here we are calculating z-critical value*\nz_critical = stats.norm.ppf(q = 0.95)  \n\n # here we are Check the z-critical value  \nprint(\"z-critical value: \",z_critical)                                \n\n# here we are getting the population standard deviation\npop_stdev = Data['math score'].std()  \n\n# checking the margin of error\nmargin_of_error = z_critical * (pop_stdev\/math.sqrt(sample_size)) \n\n# defining our confidence interval\nconfidence_interval = (sample_mean - margin_of_error,\n                       sample_mean + margin_of_error)  \n\n# here we are printing the results\nprint(\"Confidence interval:\",end=\" \")\nprint(confidence_interval)\nprint(\"True mean: {}\".format(Data['math score'].mean()))","21a3b1b0":"# here we are cheking confidence interval for reading\n# lets import the scipy package\nimport scipy.stats as stats\nimport math\n\n# lets seed the random values\nnp.random.seed(2)\n\n# lets take a sample size\nsample_size = 1000\nsample = np.random.choice(a= Data['reading score'],\n                          size = sample_size)\nsample_mean = sample.mean()\n\n# Get the z-critical value*\nz_critical = stats.norm.ppf(q = 0.95)  \n\n # Check the z-critical value  \nprint(\"z-critical value: \",z_critical)                                \n\n# Get the population standard deviation\npop_stdev = Data['reading score'].std()  \n\n# checking the margin of error\nmargin_of_error = z_critical * (pop_stdev\/math.sqrt(sample_size)) \n\n# defining our confidence interval\nconfidence_interval = (sample_mean - margin_of_error,\n                       sample_mean + margin_of_error)  \n\n# lets print the results\nprint(\"Confidence interval:\",end=\" \")\nprint(confidence_interval)\nprint(\"True mean: {}\".format(Data['reading score'].mean()))","75383858":"# here we are cheking confidence interval for writing\n# lets import the scipy package\nimport scipy.stats as stats\nimport math\n\n# lets seed the random values\nnp.random.seed(2)\n\n# lets take a sample size\nsample_size = 1000\nsample = np.random.choice(a= Data['writing score'],\n                          size = sample_size)\nsample_mean = sample.mean()\n\n# Get the z-critical value*\nz_critical = stats.norm.ppf(q = 0.95)  \n\n # Check the z-critical value  \nprint(\"z-critical value: \",z_critical)                                \n\n# Get the population standard deviation\npop_stdev = Data['writing score'].std()  \n\n# checking the margin of error\nmargin_of_error = z_critical * (pop_stdev\/math.sqrt(sample_size)) \n\n# defining our confidence interval\nconfidence_interval = (sample_mean - margin_of_error,\n                       sample_mean + margin_of_error)  \n\n# lets print the results\nprint(\"Confidence interval:\",end=\" \")\nprint(confidence_interval)\nprint(\"True mean: {}\".format(Data['writing score'].mean()))","17ad3e54":"# here we are calculating boys score for scoring 90 in all the subject\nData[(Data['gender'] == 'female') &\n     (Data['math score'] > 90) & \n     (Data['writing score'] > 90) &\n     (Data['reading score'] > 90)]    ","f96aec82":"# here we are checking the effect of lunch on student performance\nData[['lunch','gender','math score','writing score','reading score']].groupby(['lunch','gender']).agg('median')","95552cbe":"# here we are checking the effect of test preparation course on student performance\nData[['test preparation course',\n      'gender',\n      'math score',\n      'writing score',\n      'reading score']].groupby(['test preparation course','gender']).agg('median')","183a1f39":"# here we are checking the effect of race\/ethnicity on student performance\nData[['race\/ethnicity',\n      'math score',\n      'writing score',\n      'reading score']].groupby(['race\/ethnicity']).agg('median')","b89291d8":"# here we are comparing no of male and female\nplt.rcParams['figure.figsize'] = (10, 5)\nplt.style.use('seaborn-pastel')\nsns.countplot(Data['gender'], palette = \"hls\")\nplt.title('Comparison of Males and Females', fontweight = 20)\nplt.xlabel('Gender')\nplt.ylabel('Count')\nplt.show()","18d60a03":"# here we are visualizing the differnt parental education levels in our dataset\nplt.rcParams['figure.figsize'] = (10, 5)\nplt.style.use('seaborn-muted')\nsns.countplot(Data['race\/ethnicity'], palette=\"Paired\")\nplt.title('Comparison of various groups', fontweight = 30, fontsize = 20)\nplt.xlabel('Groups')\nplt.ylabel('Count')\nplt.show()","07d541fb":"# here we are visualizing the different groups in the our dataset\n\nplt.rcParams['figure.figsize'] = (15, 9)\nplt.style.use('fivethirtyeight')\nsns.countplot(Data['parental level of education'], palette=\"husl\")\nplt.title('Comparison of parent education', fontweight = 30, fontsize = 20)\nplt.xlabel('Degree')\nplt.ylabel('Count')\nplt.show()","cda9ff1d":"# here we are visualizing different types of lunch in our dataset\n\nplt.rcParams['figure.figsize'] = (10,5)\nplt.style.use('bmh')\nsns.countplot(Data['lunch'], palette = \"Set2\")\nplt.title('Comparison of different types of lunch', fontweight = 30, fontsize = 20)\nplt.xlabel('Types of lunch')\nplt.ylabel('Count')\nplt.show()","c03c5195":"# here we are visualizing maths score\n\nplt.rcParams['figure.figsize'] = (15,9)\nplt.style.use('dark_background')\nsns.countplot(Data['math score'], palette = \"Blues\")\nplt.title('Comparison of math scores', fontweight = 30, fontsize = 20)\nplt.xlabel('Score')\nplt.ylabel('Count')\nplt.xticks(rotation = 90)\nplt.show()","3f3d0653":"# here we are visualizing reading score\nplt.rcParams['figure.figsize'] = (15, 9)\nplt.style.use('seaborn-dark-palette')\nsns.countplot(Data['reading score'], palette = \"BuGn_r\")\nplt.title('Comparison of Reading scores', fontweight = 30, fontsize = 20)\nplt.xlabel('Score')\nplt.ylabel('Count')\nplt.xticks(rotation = 90)\nplt.show()","5a57b1d5":"# here we are visualizing writing score\nplt.rcParams['figure.figsize'] = (15, 9)\nplt.style.use('dark_background')\nsns.countplot(Data['writing score'], palette = \"GnBu_d\")\nplt.title('Comparison of Writing scores', fontweight = 30, fontsize = 20)\nplt.xlabel('Score')\nplt.ylabel('Count')\nplt.xticks(rotation = 90)\nplt.show()","679dd73a":"# here we are visualizing gender vs race\/etnicity \nplt.rcParams['figure.figsize'] = (10, 5)\nplt.style.use('classic')\nx = pd.crosstab(Data['gender'], Data['race\/ethnicity'])\nx.div(x.sum(1).astype(float), axis = 0).plot(kind = 'bar', stacked = False)\nplt.title('Gender vs Race', fontweight = 30, fontsize = 20)\nplt.xticks(rotation = 0)\nplt.show()","47ebb056":"# here we are comparison race\/ethnicity and parental level of education\n\nplt.rcParams['figure.figsize'] = (10,5)\nplt.style.use('bmh')\nx = pd.crosstab(Data['race\/ethnicity'], Data['parental level of education'])\nx.div(x.sum(1).astype(float), axis = 0).plot(kind = 'bar', stacked = 'True')\nplt.title('Race vs Parental Education', fontweight =20, fontsize = 20)\nplt.show()","318d08a7":"# here we are doing comparison of parental degree and test course\nplt.rcParams['figure.figsize'] = (12, 5)\nsns.countplot(x = 'parental level of education', data = Data, hue = 'test preparation course', palette = 'dark')\nplt.title('Parental Education vs Test Preparation Course', fontweight = 30, fontsize = 20)\nplt.show()","08200e85":"# here we are doing comparison of race\/ethnicity and test preparation course\nplt.rcParams['figure.figsize'] = (12, 5)\nsns.countplot(x = 'race\/ethnicity', data = Data,  hue = 'test preparation course', palette = 'dark')\nplt.title('Race vs Test Preparion', fontweight = 30, fontsize = 20)\nplt.show()\n","8771da8d":"# here we are doing compution of the total score for each student\nData['total_score'] = Data['math score'] + Data['reading score'] +Data['writing score']\n\nsns.distplot(Data['total_score'], color = 'crimson')\n\nplt.title('comparison of total score of all the students', fontweight = 30, fontsize = 20)\nplt.xlabel('total score scored by the students')\nplt.ylabel('count')\nplt.show()\n","26547ac1":"# here we are computing percentage for each of the students\nfrom math import *\nData['percentage'] = Data['total_score']\/3\n\nfor i in range(0, 1000):\n    Data['percentage'][i] = ceil(Data['percentage'][i])\n\nplt.rcParams['figure.figsize'] = (10, 5)\nsns.distplot(Data['percentage'], color = 'lightslategray')\n\nplt.title('Comparison of percentage scored by all the students', fontweight = 30, fontsize = 20)\nplt.xlabel('Percentage scored')\nplt.ylabel('Count')\nplt.show()","328d5a9d":"# here we are creating a new column math pass, this column will tell us whether the students are pass or fail\npassmarks = 40\nData['math_pass'] = np.where(Data['math score']< passmarks, 'Fail', 'Pass')","aebd06f2":"# here we are creating a new column reading pass  this column will tell us whether the students are pass or fail\nData['reading_pass'] = np.where(Data['reading score']< passmarks, 'Fail', 'Pass')","4d4deeb6":"# here we are creating a new column pass_writing, this column will tell us whether the\n# students are pass or fail\n\nData['writing_pass'] = np.where(Data['writing score']< passmarks, 'Fail', 'Pass')","403843eb":"# here we are checking which student is fail overall\nplt.rcParams['figure.figsize'] = (15, 9)\nData['status'] = Data.apply(lambda x : 'Fail' if x['math_pass'] == 'Fail' or \n                           x['reading_pass'] == 'Fail' or x['writing_pass'] == 'Fail'\n                           else 'pass', axis = 1)\nData['status'].value_counts(dropna = False).plot.pie(colors = ['grey', 'crimson'])\nplt.title('overall results', fontweight = 30, fontsize = 20)\nplt.xlabel('status')\nplt.ylabel('count')\nplt.show()","11f41a30":"# here we are importing library for label encoder\nfrom sklearn.preprocessing import LabelEncoder\n\n# here we are creating an encoder\nle = LabelEncoder()\n\n# label encoding for test preparation course\nData['test preparation course'] = le.fit_transform(Data['test preparation course'])\n\n# label encoding for lunch\nData['lunch'] = le.fit_transform(Data['lunch'])\n# here we are doing label encoding for race\/ethnicity\n# we have to map values to each of the categories\nData['race\/ethnicity'] = Data['race\/ethnicity'].replace('group A', 1)\nData['race\/ethnicity'] = Data['race\/ethnicity'].replace('group B', 2)\nData['race\/ethnicity'] = Data['race\/ethnicity'].replace('group C', 3)\nData['race\/ethnicity'] = Data['race\/ethnicity'].replace('group D', 4)\nData['race\/ethnicity'] = Data['race\/ethnicity'].replace('group E', 5)\n\n# label encoding for parental level of education\nData['parental level of education'] = le.fit_transform(Data['parental level of education'])\n\n#label encoding for gender\nData['gender'] = le.fit_transform(Data['gender'])\n\n# label encoding for pass_math\nData['math_pass'] = le.fit_transform(Data[\"math_pass\"])\n\n# label encoding for pass_reading\nData['reading_pass'] = le.fit_transform(Data['reading_pass'])\n\n# label encoding for pass_writing\nData['writing_pass'] = le.fit_transform(Data['writing_pass'])\n\n# label encoding for status\nData['status'] = le.fit_transform(Data['status'])","11206f32":"Data.head()","4de0cfdc":"# here we are splitting our dataset into the dependent and independent variables\nx = Data.iloc[:,:14]\ny = Data.iloc[:,13]\n\nprint(x.shape)\nprint(y.shape)","2fc1fc43":"# here we are importing the library\nfrom sklearn.model_selection import train_test_split\n# here we are spilting our dataset\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.25,random_state=45)","f5031645":"# here we are printing shape of x_train,x_test,y_train,y_train\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)","901c031f":"# here we are creating model\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression ()\nclassifier.fit(x_train,y_train)","aa51f442":"y_pred = classifier.predict(x_test)","47362ab3":"# calculating the classification accuracies\nprint(\"Training Accuracy :\", classifier.score(x_train, y_train))\nprint(\"Testing Accuracy :\", classifier.score(x_test, y_test))","91073a06":"# here we are importing librray for calculating accuracy\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n# here we are calculating accuracy rate of our model\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nacc_lg= accuracy_score(y_test, y_pred)\nacc_lg","54a860ab":"from sklearn.neighbors import KNeighborsClassifier\nclassifierr = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n                     weights='uniform')\nclassifierr.fit(x_train,y_train)","6b05f118":"y_pred = classifierr.predict(x_test)","9fefadee":"# calculating the classification accuracies\nprint(\"Training Accuracy :\", classifierr.score(x_train, y_train))\nprint(\"Testing Accuracy :\", classifierr.score(x_test, y_test))","4dd2c205":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)\nacc_knn = accuracy_score(y_test, y_pred)\nacc_knn","6b253fe2":"from sklearn.svm import SVC\nclassifier1 = SVC(kernel=\"linear\",random_state=0,C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma='scale',\n    max_iter=-1, probability=True,shrinking=True, tol=0.001,\n    verbose=False)\nclassifier1.fit(x_train,y_train)","45a80511":"y_pred = classifier1.predict(x_test)","38984ba1":"# calculating the classification accuracies\nprint(\"Training Accuracy :\", classifier1.score(x_train, y_train))\nprint(\"Testing Accuracy :\", classifier1.score(x_test, y_test))","a112a349":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)\nacc_svm = accuracy_score(y_test, y_pred)\nacc_svm","5a34a392":"# importing libraries for plotting roc_curve\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score","bef459f6":"classifiers = [LogisticRegression(random_state=0),\n               KNeighborsClassifier(),\n               SVC(random_state=0,probability=True), \n               ]\nresult_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\nfor cls in classifiers:\n    model = cls.fit(x_train, y_train)\n    yproba = model.predict_proba(x_test)[:,1]\n    \n    fpr, tpr, _ = roc_curve(y_test,  yproba)\n    auc = roc_auc_score(y_test, yproba)\n    \n    result_table = result_table.append({'classifiers':cls.__class__.__name__,\n                                        'fpr':fpr, \n                                        'tpr':tpr, \n                                        'auc':auc}, ignore_index=True)\nresult_table.set_index('classifiers', inplace=True)","2785a168":"fig = plt.figure(figsize=(8,6))\n\nfor i in result_table.index:\n    plt.plot(result_table.loc[i]['fpr'], \n             result_table.loc[i]['tpr'], \n             label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n    \nplt.plot([0,1], [0,1], color='orange', linestyle='--')\n\nplt.xticks(np.arange(0.0, 1.1, step=0.1))\nplt.xlabel(\"Flase Positive Rate\", fontsize=15)\n\nplt.yticks(np.arange(0.0, 1.1, step=0.1))\nplt.ylabel(\"True Positive Rate\", fontsize=15)\n\nplt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\nplt.legend(prop={'size':13}, loc='lower right')\n\nplt.show()","f1274022":"Now we can see that there are 1000 rows and 8 columns in dataset.","f013953a":"**LOGISTIC REGRESSION**","b6a4f8c3":"# Introduction","81aeffe8":"Grouping operations","2cf07db9":"In this following notebook i have done different different Visualization on dataset , i have done Inferential Statistics to get clear view and i have done classification to do prediction and at last i have drawn ROC curve for getting clear view of accuracy score.\n\n","cb4db497":"1. Importing important libraries\n2. Reading dataset\n3. Exploratory data analysis\n4. Data Visualization\n5. Inferential Statistics\n6. Label Encoder\n7. Building Model\n8. Classification models\n9. ROC Cruve\n10. Conclusion","79052800":"# Label Encoder","3ce7606f":"# Contents","b0cb3441":"# Conclusion","88b8582f":"# Data visualisation","d0b7169c":"above we saw that there is no skewness in all three subject","4f138b39":"# Buliding Models","8f2db8a1":"# Exploratory data analysis","c15f405b":"Now we are going to check that which factor effect the student performamce.","5be2b717":"here in a Receiver Operating Characteristic (ROC) curve the true positive rate (Sensitivity) is plotted in function of the false positive rate (100-Specificity) for different cut-off points. Each point on the ROC curve represents a sensitivity\/specificity pair corresponding to a particular decision threshold.","df383187":"# ROC Curve","2c81870a":"# Data Visualization","eeb94cd1":"**SUPPORT VECTOR MACHINE**","a99d8e12":"Thanks for reading. I hope you like my analysis and visualization and found it to be helpful. If you have any questions or suggestions, feel free to write them down in the comment section","4d5360a5":"# Classification Models","e3bd01ef":"**K NEAREST NEIGHBORS**","d7411c99":"# Importing Important Libraries","e12ed732":"# Reading Dataset","72080ac3":"# Inferential Statistics"}}