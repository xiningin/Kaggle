{"cell_type":{"cf71c244":"code","ff84e0fa":"code","130b3b68":"code","661e3b94":"code","67da0f96":"code","d30cab95":"code","da5f28a1":"code","9645ef8e":"code","fc891387":"code","f959bbee":"code","80077cfc":"code","c941b3bf":"code","6d608674":"code","2b6d0b69":"code","3a01705d":"code","26964015":"code","7d14a2e5":"code","283c38ac":"code","ad08cfcc":"code","9c362618":"code","e42b6278":"markdown","76db6d09":"markdown","da851253":"markdown","aeef8d11":"markdown","e3f34bdd":"markdown","7c8a7500":"markdown"},"source":{"cf71c244":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ff84e0fa":"#read metadata\ndf_skin = pd.read_csv('\/kaggle\/input\/skin-cancer-mnist-ham10000\/HAM10000_metadata.csv')\n\ndf_skin.head()","130b3b68":"# lesion names are given in the description of the challenge\nlesion_type_dict = {\n    'nv': 'Melanocytic nevi',\n    'mel': 'Melanoma',\n    'bkl': 'Benign keratosis-like lesions ',\n    'bcc': 'Basal cell carcinoma',\n    'akiec': 'Actinic keratoses',\n    'vasc': 'Vascular lesions',\n    'df': 'Dermatofibroma'\n}\n\nlesion_ID_dict = {\n    'nv': 0,\n    'mel': 1,\n    'bkl': 2,\n    'bcc': 3,\n    'akiec': 4,\n    'vasc': 5,\n    'df': 6\n}\n\nlesion_names = ['Melanocytic nevi','Melanoma','Benign keratosis-like lesions ',\n               'Basal cell carcinoma','Actinic keratoses','Vascular lesions',\n               'Dermatofibroma']\n\nlesion_names_short = ['nv','mel','bkl','bcc','akiec','vasc','df']\n\ndf_skin['lesion_type']=df_skin['dx'].map(lesion_type_dict)\ndf_skin['lesion_ID'] = df_skin['dx'].map(lesion_ID_dict)\n\nprint('Total number of images',len(df_skin))\nprint('The problem is unbalanced, since Melanocytic nevi is much more frequent that other labels')\n\ndf_skin['lesion_type'].value_counts()","661e3b94":"# read the first image\nfname_images = np.array(df_skin['image_id'])\nfile_to_read ='\/kaggle\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_1\/'+str(fname_images[0])+'.jpg'\n\nimport cv2\nfrom cv2 import imread, resize\n\nimg = imread(file_to_read)\nimg2 = resize(img,(227,227))\n\n# show one exampe image\n\nplt.figure(figsize=(10,5))\nplt.subplot(1,2,1)\nplt.imshow(img[:,:,::-1])\nplt.title('Original image')\nplt.subplot(1,2,2)\nplt.imshow(img2[:,:,::-1])\nplt.title('Resized image for AlexNet')\nplt.show()","67da0f96":"def produce_new_img(img2):\n    # produce new images by rotating of flipping the original one\n    # this helps to increase the dimension of the dataset, avoiding overfitting of a single class\n    imga = cv2.rotate(img2,cv2.ROTATE_90_CLOCKWISE)\n    imgb = cv2.rotate(img2,cv2.ROTATE_90_COUNTERCLOCKWISE)\n    imgc = cv2.rotate(img2,cv2.ROTATE_180)\n    imgd = cv2.flip(img2,0)\n    imge = cv2.flip(img2,1)\n    return imga,imgb,imgc,imgd,imge\n\nnew_img = produce_new_img(img2)\n\nplt.figure(figsize=(10,8))\nplt.subplot(2,3,1)\nplt.imshow(img2[:,:,::-1])\nfor i in range(5):\n    plt.subplot(2,3,2+i)\n    plt.imshow(new_img[i][:,:,::-1])\nplt.tight_layout()\nplt.show()","d30cab95":"# import images from 2 different folders\n\nX = []\ny = []\n\nlista1 = os.listdir('\/kaggle\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_1\/')\nlista2 = os.listdir('\/kaggle\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_2\/')\n\n\n#import images from folder 1\nfor i in range(len(lista1)):\n    fname_image = lista1[i]\n    fname_ID = fname_image.replace('.jpg','')\n    \n    #features \n    file_to_read ='\/kaggle\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_1\/'+str(fname_image)\n    img = imread(file_to_read)\n    img2 = resize(img,(227,227))\n    X.append(img2)\n    \n    #targets\n    output = np.array(df_skin[df_skin['image_id'] == fname_ID].lesion_ID)\n    y.append(output[0])\n    \n    # add more images for class between 1-6, rotating them \n    if output != 0:\n        new_img = produce_new_img(img2)\n        for i in range(5):\n            X.append(new_img[i])\n            y.append(output[0])\n       \n    if i % int(100) == 0:\n        print(i,'images loaded')\n\n# import images from folder 2\nfor i in range(len(lista2)):\n    fname_image = lista2[i]\n    fname_ID = fname_image.replace('.jpg','')\n    \n    #features\n    file_to_read ='\/kaggle\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_2\/'+str(fname_image)\n    img = imread(file_to_read)\n    img2 = resize(img,(227,227))\n    X.append(img2)\n    \n    #targets\n    output = np.array(df_skin[df_skin['image_id'] == fname_ID].lesion_ID)\n    y.append(output[0])\n    \n    # add more images for class between 1-6\n    if output != 0:\n        new_img = produce_new_img(img2)\n        for i in range(5):\n            X.append(new_img[i])\n            y.append(output[0])\n    \n    if i % int(100) == 0:\n        print(len(lista1)+i,'images loaded')","da5f28a1":"X = np.array(X)\ny = np.array(y)\n\n#convert targets in dummy variables, as required by softmax activation function\ny_dumm = np.array(pd.get_dummies(y))","9645ef8e":"from sklearn.model_selection import train_test_split\n\n# split in 80% training and 20% test data\nX_train, X_test, y_train, y_test = train_test_split(X, y_dumm, test_size=0.2, random_state=50,stratify=y)\n\n\nprint('Train dataset shape',X_train.shape)\nprint('Test dataset shape',X_test.shape)","fc891387":"import keras\nfrom keras.models import Sequential, load_model\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint\nfrom keras.layers.core import Dropout, Activation\nfrom keras.layers import Conv2D,BatchNormalization,MaxPool2D,Flatten,Dense","f959bbee":"from sklearn.utils.class_weight import compute_class_weight\ny_id = np.array(df_skin['lesion_ID'])\n\n# compute weights for the loss function, because the problem is unbalanced\nclass_weights = np.around(compute_class_weight(class_weight='balanced',classes=np.unique(y_id),y=y),2)\nclass_weights = dict(zip(np.unique(y_id),class_weights))\n\nprint('The problem is unbalanced. We need to provide class_weights ')\nprint(class_weights)","80077cfc":"# building AxelNet Neural Network\n\nmodel = Sequential([\n    \n    # 1st convolutional layer\n    Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3)),\n    BatchNormalization(),\n    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n    \n    # 2nd convolutional layer\n    Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n    BatchNormalization(),\n    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n    \n    # 3rd convolutional layer\n    Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    BatchNormalization(),\n    \n    # 4th convolutional layer\n    Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n    BatchNormalization(),\n    \n    # 5th convolutional layer\n    Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n    BatchNormalization(),\n    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n    \n    Flatten(),\n    \n    # 6th, Dense layer\n    Dense(4096, activation='relu'),\n    Dropout(0.5),\n    \n    # 7th Dense layer\n    Dense(4096, activation='relu'),\n    Dropout(0.5),\n    \n    # 8th output layer\n    Dense(7, activation='softmax')\n])\n\n# monitor\nearly_stopping_monitor = EarlyStopping(patience=100,monitor='val_accuracy')\nmodel_checkpoint_callback = ModelCheckpoint(filepath='best_model.hdf5',\n                                            save_weights_only=False,\n                                            monitor='val_accuracy',\n                                            mode='auto',\n                                            save_best_only=True,\n                                            verbose=1)\n    \n# compile model\nmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n\nprint(model.summary())\n\n# fit model\nhistory = model.fit(X_train,y_train,\n                    batch_size=128, \n                    epochs=1000,\n                    callbacks=[early_stopping_monitor,model_checkpoint_callback],\n                    validation_data=(X_test,y_test),\n                    class_weight=class_weights)","c941b3bf":"# show the history of the Neural Network training\n\nplt.plot(history.history['accuracy'],label='Training')\nplt.plot(history.history['val_accuracy'],label='Test')\nplt.grid()\nplt.xlabel('Number of epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.savefig('history_NN.png',dpi=300)\nplt.show()","6d608674":"#\u00a0load the best model\nbest_model = load_model('.\/best_model.hdf5')\n\n# compute predictions\ny_pred_prob = np.around(best_model.predict(X_test),3)\ny_pred = np.argmax(y_pred_prob,axis=1)\n\ny_test2 = np.argmax(y_test,axis=1)","2b6d0b69":"from sklearn.metrics import roc_auc_score\n\ntest_accuracy = np.sum(y_test2 == y_pred)\/len(y_pred)\nprint('Test accuracy',test_accuracy)\n\nprint('The roc-auc score is',roc_auc_score(y_test,y_pred_prob))","3a01705d":"pred_res = y_test2 == y_pred\n\nfor i in range(100):\n    print(i,np.sum(pred_res[i:i+16]))","26964015":"plt.figure(figsize=(16,16))\nfor i in range(16):\n    plt.subplot(4,4,i+1)\n    index = i+58\n    plt.imshow(X_test[index,:,:,::-1])\n    label_exp = lesion_names[y_test2[index]]  #expected label\n    label_pred = lesion_names[y_pred[index]]  #predicted label\n    label_pred_prob = round(np.max(y_pred_prob[index])*100)\n    plt.title('Expected:'+str(label_exp)+'\\n Pred.:'+str(label_pred)+' ('+str(label_pred_prob)+'%)')\nplt.ylabel('')\nplt.tight_layout()\nplt.savefig('final_figure.png',dpi=300)\nplt.show()","7d14a2e5":"print('Accuracy for label equal to 0')\nprint(np.mean(y_test2[y_test2 == 0] == y_pred[y_test2 == 0]))\n\nprint('Accuracy for label different from 0')\nprint(np.mean(y_test2[y_test2 != 0] == y_pred[y_test2 != 0]))","283c38ac":"acc_tot= []\n\nfor i in range(7):\n    acc_parz = round(np.mean(y_test2[y_test2 == i] == y_pred[y_test2 == i]),2)\n    lab_parz = lesion_names[i]\n    print('accuracy for',lab_parz,'=',acc_parz)\n    acc_tot.append(acc_parz)","ad08cfcc":"acc_tot = np.array(acc_tot)\nfreq = np.unique(y_test2,return_counts=True)[1]\n\nnp.sum(acc_tot*freq)\/np.sum(freq)","9c362618":"np.mean(acc_tot)","e42b6278":"# Convolutional Neural Network","76db6d09":"### import images","da851253":"# Check the performance","aeef8d11":"# Computing features and targets","e3f34bdd":"# Analysis of the target","7c8a7500":"### evaluation of accuracy"}}