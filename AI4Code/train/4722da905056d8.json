{"cell_type":{"ed7c83a9":"code","5fac8830":"code","e5beff47":"code","79ee1e3e":"code","18f97bfe":"code","c497fd45":"code","836484e2":"code","4d78d5f4":"code","6bbacc5a":"code","d2071cfa":"code","02516c89":"code","e27c8c66":"code","bbab0a75":"code","f35f35aa":"code","95958754":"code","c5f4a11d":"code","689a6b80":"code","5644b2fd":"code","9748a396":"code","aaa4ecc9":"code","eb8f6153":"code","b855b97e":"code","857d88f6":"code","59dd1ad4":"code","a2c0c7cc":"code","33ab1a7c":"markdown","f59221ef":"markdown","d4ab736d":"markdown","8056da54":"markdown","287f1c77":"markdown","7b9d9772":"markdown"},"source":{"ed7c83a9":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, plot_confusion_matrix\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.utils import class_weight\nfrom keras import models\nfrom keras import layers\nfrom keras import regularizers\nfrom keras import optimizers\nimport tensorflow as tf\nimport random as rn\n\nos.environ['PYTHONHASHSEED'] = '0'\nnp.random.seed(1)\nrn.seed(2)\ntf.random.set_seed(3)","5fac8830":"df = pd.read_csv('..\/input\/covid19-patient-precondition-dataset\/covid.csv')\n\n# display the first 5 rows\ndf.head()","e5beff47":"# display columns info\ndf.info()","79ee1e3e":"# the target column will be the death of the patient\n# patient survived if date_died == '9999-99-99'\ndf['death'] = df['date_died'].apply(lambda x: 0 if x == '9999-99-99' else 1)","18f97bfe":"# drop some unnecessary columns\ndf.drop(columns={\"id\",\"patient_type\",\n                 \"entry_date\",\"date_symptoms\",\n                 \"date_died\",\"pregnancy\"}, axis=1, inplace=True)","c497fd45":"# replace all missing values (97,98 and 99) with nan\ntemp = df['age'] # save age - you do not want to drop old people!\ndf = df.replace([97,98,99], [np.nan for i in range(3)])\ndf['age'] = temp\n\n# drop all nan rows\ndf = df.dropna()","836484e2":"# drop rows with covid_res == Awaiting Results \ndf=df[df['covid_res'] != 3]","4d78d5f4":"# replace all 1,2 values with 0,1\ntemp = df[['age','death']] # save age and death\ndf = df.replace([1,2], [0,1])\ndf[['age','death']] = temp","6bbacc5a":"# update index\ndf = df.reset_index(drop=True)","d2071cfa":"# display the first 5 rows of prepared data\ndf.head()","02516c89":"# display columns info of prepared data\ndf.info()","e27c8c66":"# there seems to be an imbalance of target classes\ndf['death'].value_counts().to_frame()","bbab0a75":"# split features and target\nX = df.loc[:, df.columns != 'death'].values\ny = np.array(df['death'])\n\n# train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state=1)\n\nprint(\"Train X: \", X_train.shape)\nprint(\"Train y: \", y_train.shape)\nprint(\"Test X: \", X_test.shape)\nprint(\"Test y: \", y_test.shape)","f35f35aa":"# normalize age\nageColumnIndex = df.columns.get_loc('age')\n\nmean = X_train[:,ageColumnIndex].mean(axis=0)\nX_train[:,ageColumnIndex] -= mean\nstd = X_train[:,ageColumnIndex].std(axis=0)\nX_train[:,ageColumnIndex] \/= std\n\nX_test[:,ageColumnIndex] -= mean\nX_test[:,ageColumnIndex] \/= std","95958754":"# use SMOTE oversampling method to solve the imbalance problem\nX_train_oversampled, y_train_oversampled = SMOTE().fit_resample(X_train, y_train)\n\nprint(\"Oversampled train X: \", X_train_oversampled.shape)\nprint(\"Oversampled train y: \", y_train_oversampled.shape)\n\npd.DataFrame(y_train_oversampled).value_counts()","c5f4a11d":"decTreClassifier = DecisionTreeClassifier()\ndecTreClassifier.fit(X_train_oversampled, y_train_oversampled)\n\ny_pred = decTreClassifier.predict(X_test)\n\nplot_confusion_matrix(decTreClassifier, X_test, y_test)\nprint(classification_report(y_test, y_pred))","689a6b80":"randForestClassifier = RandomForestClassifier(n_estimators=100)\nrandForestClassifier.fit(X_train_oversampled, y_train_oversampled)\n\ny_pred = randForestClassifier.predict(X_test)\n\nplot_confusion_matrix(randForestClassifier, X_test, y_test)\nprint(classification_report(y_test, y_pred))","5644b2fd":"# get features importance\nrf_feature_importance = pd.Series(randForestClassifier.feature_importances_,index=df.loc[:, df.columns != 'death'].columns).sort_values(ascending=False)\n\nsns.barplot(x = rf_feature_importance, y = rf_feature_importance.index)\n\nplt.title(\"RF feature importance\")\nplt.legend()\nplt.show()","9748a396":"gradientBoostingClassifier = GradientBoostingClassifier(learning_rate=1)\ngradientBoostingClassifier.fit(X_train_oversampled, y_train_oversampled)\n\ny_pred = gradientBoostingClassifier.predict(X_test)\n\nplot_confusion_matrix(gradientBoostingClassifier, X_test, y_test)\nprint(classification_report(y_test, y_pred))","aaa4ecc9":"# prepare validation data from train data\nX_train_new, X_val, y_train_new, y_val = train_test_split(X_train,\n                                                          y_train,\n                                                          test_size=0.15,\n                                                          random_state=1)\n\nprint(\"Train X: \", X_train_new.shape)\nprint(\"Train y: \", y_train_new.shape)\nprint(\"Val X: \", X_val.shape)\nprint(\"Val y: \", y_val.shape)\nprint(\"Test X: \", X_test.shape)\nprint(\"Test y: \", y_test.shape)","eb8f6153":"model = models.Sequential()\n\nmodel.add(layers.Dense(256, activation = \"relu\",\n                       kernel_regularizer=regularizers.l2(0.001),\n                       input_shape = (X_train_new.shape[1],)))\nmodel.add(layers.Dropout(0.3))\nmodel.add(layers.Dense(128, activation = \"relu\",\n                       kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(layers.Dropout(0.3))\nmodel.add(layers.Dense(64, activation = \"relu\",\n                       kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(layers.Dropout(0.3))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.summary()","b855b97e":"model.compile(optimizer=optimizers.Adam(lr=0.0001), \n              loss='binary_crossentropy', \n              metrics=['accuracy'])\n\n# use weights to solve the imbalance problem\ncomputed_weights = class_weight.compute_class_weight('balanced',\n                                                     np.unique(y_train_new),\n                                                     y_train_new)\nclass_weights = {0: computed_weights[0], 1: computed_weights[1]}\n\nhistory = model.fit(\n    X_train_new,y_train_new,\n    epochs=100,\n    batch_size=512,\n    validation_data = (X_val, y_val),\n    verbose=0,\n    class_weight=class_weights\n)","857d88f6":"history_dict = history.history\nepochs = range(1, len(history_dict['loss']) + 1)\n\nplt.plot(epochs, history_dict['loss'], 'bo', label='loss_values')\nplt.plot(epochs, history_dict['val_loss'], 'b', label='val_loss_values')\n\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","59dd1ad4":"plt.clf()\n\nplt.plot(epochs, history_dict['accuracy'], 'ro', label='acc_values')\nplt.plot(epochs, history_dict['val_accuracy'], 'r', label='val_acc_values')\n\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.show()","a2c0c7cc":"test_loss, test_acc = model.evaluate(X_test, y_test)\nprint(\"Test accuracy:\", test_acc)\nprint(\"Test loss:\", test_loss)","33ab1a7c":"<h2>Data preparation<\/h2> ","f59221ef":"<h2>Classification with Random Forest<\/h2>","d4ab736d":"<h2>Classification with simple ANN<\/h2>","8056da54":"<h2>Classification with Decision Tree<\/h2> ","287f1c77":"# **COVID-19 Prediction of Death**\n**Context**\n\nA health crisis of massive proportion such as the current COVID-9 pandemic provides us with an opportunity to ponder and reflect over what we can better in the way we deal with healthcare to make us humans be more prepared and enabled to combat such an event in the future.\nDuring the entire course of the pandemic, one of the main problems that healthcare providers have faced is the shortage of medical resources and a proper plan to efficiently distribute them.\nThey have been in the dark failing to understand how much resource they could even in the very next week as the COVID-19 curve has swayed very unpredictably. In these tough times, being able to predict what kind of resource an individual might require at the time of being tested positive or even before that will be of great help to the authorities as they would be able to procure and arrange for the resources necessary to save the life of that patient.\n\n**Content**\n\nWhile the above are lofty thoughts, procuring patient data of COVID-19 patients containing patient-specific information regarding patient history and habits is a different ball game altogether. This is mainly due to the regulatory security laws such as HIPAA and GDPR which makes it almost impossible for anyone to get hands-on PHI data. I spend literally days and nights searching for a suitable data-set, called up people I knew for any directions towards a data-set which might be of use to me. Finally, I found this data-set https:\/\/www.gob.mx\/salud\/documentos\/datos-abiertos-152127 which was released by the Mexican government. This data-set contains a huge number of anonymised patient-related information.\n\n**Columns**\n* id: ID of patient\n* sex: Female - 1, Male - 2\n* patient_type: Outpatient - 1, Inpatient - 2\n* entry_date: Date of Entry to hospital\n* date_symptoms: Date of first symptom\n* date_died: Date of death\n* intubed: Yes - 1, No - 2, Data missing or NA - 97,98,99\n* pneumonia: Yes - 1, No - 2, Data missing or NA - 97,98,99\n* age: Age\n* pregnancy: Yes - 1, No - 2, Data missing or NA - 97,98,99\n* diabetes: Yes - 1, No - 2, Data missing or NA - 97,98,99\n* copd: Yes - 1, No - 2, Data missing or NA - 97,98,99\n* asthma: Yes - 1, No - 2, Data missing or NA - 97,98,99\n* inmsupr: Yes - 1, No - 2, Data missing or NA - 97,98,99\n* hypertension: Yes - 1, No - 2, Data missing or NA - 97,98,99\n* other_disease: Yes - 1, No - 2, Data missing or NA - 97,98,99\n* cardiovascular: Yes - 1, No - 2, Data missing or NA - 97,98,99\n* obesity: Yes - 1, No - 2, Data missing or NA - 97,98,99\n* renal_chronic: Yes - 1, No - 2, Data missing or NA - 97,98,99\n* tobacco: Yes - 1, No - 2, Data missing or NA - 97,98,99\n* contact_other_covid: Yes - 1, No - 2, Data missing or NA - 97,98,99\n* covid_res: Positive - 1, Negative - 2, Awaiting Results - 3\n* icu: Yes - 1, No - 2, Data missing or NA - 97,98,99","7b9d9772":"<h2>Classification with Gradient Boosting<\/h2>"}}