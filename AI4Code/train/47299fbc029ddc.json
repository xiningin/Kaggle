{"cell_type":{"252e4917":"code","0659cc59":"code","604cce0c":"code","48b43d24":"code","0f14ca76":"code","93d18ec2":"code","0ca0b2e7":"code","0e3deb80":"code","d02b7590":"code","e36fc589":"code","1cd0de51":"code","0bdedd1d":"code","5331ed76":"code","37cfc222":"code","4ba68c28":"code","c468f51a":"code","236dc51d":"code","e126aacb":"code","2405217f":"code","1073e2f9":"code","3550f892":"code","4c7a878d":"code","3ef33eaa":"markdown","0d150732":"markdown","3e02b1ce":"markdown","8a82ee2f":"markdown","47ffd073":"markdown","cf6c535b":"markdown","aec6430f":"markdown","1eff3381":"markdown","82738d2c":"markdown","eb8522c3":"markdown","f0858441":"markdown","8e53773e":"markdown","04cc7919":"markdown","e765b6ad":"markdown","4c5c8c4a":"markdown","f32c7afc":"markdown","dee81d7a":"markdown","ef4ce1c9":"markdown","879c5c97":"markdown","863ee685":"markdown","82d599db":"markdown","85b57dfb":"markdown","a4ad9bf3":"markdown"},"source":{"252e4917":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib import rcParams\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","0659cc59":"data=pd.read_csv('..\/input\/zomato.csv')\ndata.head()\n# data.shape","604cce0c":"print(\"Percentage null or na values in df\")\n((data.isnull() | data.isna()).sum() * 100 \/ data.index.size).round(2)","48b43d24":"data.rate = data.rate.replace(\"NEW\", np.nan)\ndata.dropna(how ='any', inplace = True)","0f14ca76":"# data.url.unique()\n# data.address.unique()\n# data.phone.unique()\n# data[['location','listed_in(city)']]","93d18ec2":"del data['url']\ndel data['address']\ndel data['phone']\ndel data['location']\ndata.rename(columns={'approx_cost(for two people)': 'average_cost', 'listed_in(city)': 'locality','listed_in(type)': 'restaurant_type'}, inplace=True)\ndata.head()","0ca0b2e7":"X = data\nX.rate = X.rate.astype(str)\nX.rate = X.rate.apply(lambda x: x.replace('\/5',''))\nX.rate = X.rate.apply(lambda x: float(x))\nX.head()","0e3deb80":"rcParams['figure.figsize'] = 15,7\ng = sns.countplot(x=\"locality\",data=data, palette = \"Set1\")\ng.set_xticklabels(g.get_xticklabels(), rotation=90, ha=\"right\")\ng \nplt.title('locality',size = 20)","d02b7590":"rcParams['figure.figsize'] = 15,7\ng = sns.countplot(x=\"rest_type\",data=data, palette = \"Set1\")\ng.set_xticklabels(g.get_xticklabels(), rotation=90, ha=\"right\")\ng \nplt.title('rest_type',size = 20)","e36fc589":"plt.rcParams['figure.figsize'] = (3, 4)\nplt.style.use('_classic_test')\n\nX['online_order'].value_counts().plot.bar(color = 'cyan')\nplt.title('Online orders', fontsize = 20)\nplt.ylabel('Number of orders', fontsize = 15)\nplt.show()","1cd0de51":"# X[['online_order','rate']].groupby(['rate']).sum(axis=0)\nplt.rcParams['figure.figsize'] = (15, 9)\nx = pd.crosstab(X['rate'], X['online_order'])\nx.div(x.sum(1).astype(float), axis = 0).plot(kind = 'bar', stacked = True,color=['red','yellow'])\nplt.title('online order vs rate', fontweight = 30, fontsize = 20)\nplt.legend(loc=\"upper right\")\nplt.show()","0bdedd1d":"plt.rcParams['figure.figsize'] = (7, 9)\nplt.style.use('_classic_test')\n\nX['book_table'].value_counts().plot.bar(color = 'cyan')\nplt.title('Table booking', fontsize = 20)\nplt.ylabel('Number of bookings', fontsize = 15)\nplt.show()","5331ed76":"plt.rcParams['figure.figsize'] = (15, 9)\nx = pd.crosstab(X['rate'], X['book_table'])\nx.div(x.sum(1).astype(float), axis = 0).plot(kind = 'bar', stacked = True,color=['red','yellow'])\nplt.title('table booking vs rate', fontweight = 30, fontsize = 20)\nplt.legend(loc=\"upper right\")\nplt.show()","37cfc222":"X.head()\nX.average_cost = X.average_cost.apply(lambda x: x.replace(',',''))\nX.average_cost = X.average_cost.astype(int)\nfig, ax = plt.subplots(figsize=[16,4])\nsns.distplot(X['average_cost'],ax=ax)\nax.set_title('Cost Distrubution for all restaurants')","4ba68c28":"restaurantTypeCount=data['restaurant_type'].value_counts().sort_values(ascending=True)\nslices=[restaurantTypeCount[0],\n        restaurantTypeCount[1],\n        restaurantTypeCount[2],\n        restaurantTypeCount[3],\n        restaurantTypeCount[4],\n        restaurantTypeCount[5],\n        restaurantTypeCount[6]]\nlabels=['Pubs and bars','Buffet','Drinks & nightlife','Cafes','Desserts','Dine-out','Delivery ']\ncolors = ['#3333cc','#ffff1a','#ff3333','#c2c2d6','#6699ff','#c4ff4d','#339933']\nplt.pie(slices,colors=colors, labels=labels, autopct='%1.0f%%', pctdistance=.5, labeldistance=1.2,shadow=True)\nfig = plt.gcf()\nplt.title(\"Percentage of Restaurants according to their Type\", bbox={'facecolor':'2', 'pad':5})\n\nfig.set_size_inches(12,12)\nplt.show()","c468f51a":"# X.average_cost.describe()\n# maxi=X.average_cost.max()\n# mean=X.rate.mean()\n# print(mean)\nX= X.drop_duplicates(subset='name',keep='first')\n# dups_name = X1.pivot_table(index=['name'],aggfunc='size')\nnewdf=X[['name','average_cost','locality','rest_type','cuisines']].groupby(['average_cost'], sort = True)\nnewdf=newdf.filter(lambda x: x.mean() <= 1500)\nnewdf=newdf.sort_values(by=['average_cost'])\n\nnewdf_expensive=X[['name','average_cost','locality','rest_type','cuisines']].groupby(['average_cost'], sort = True)\nnewdf_expensive=newdf_expensive.filter(lambda x: x.mean() >= 3000)\nnewdf_expensive=newdf_expensive.sort_values(by=['average_cost'])\n# newdf","236dc51d":"newdf_rate=X[['name','rate']].groupby(['rate'], sort = True)\nnewdf_rate=newdf_rate.filter(lambda x: x.mean() >= 4.0)\nnewdf_rate=newdf_rate.sort_values(by=['rate'])\nX.rate.value_counts()\nX.rate.unique()\nX.nunique()\n# newdf_rate","e126aacb":"s1 = pd.merge(newdf, newdf_rate, how='inner', on=['name'])\n\ns2= pd.merge(newdf_expensive, newdf_rate, how='inner', on=['name'])\n\nprint(\"Cheap restaurants with low cost,high rating \\n\")\ns1","2405217f":"print(\"Expensive restaurants with high cost,high rating \\n\")\ns2","1073e2f9":"# X1.votes.describe()\nnewdf_votes=X[['name','votes']].groupby(['votes'], sort = True)\nnewdf_votes=newdf_votes.filter(lambda x: x.mean() >= 175)\nnewdf_votes=newdf_votes.sort_values(by=['votes'])\n# newdf_votes","3550f892":"s = pd.merge(s1, newdf_votes, how='inner', on=['name'])\ns=s.sort_values(by=['votes','rate'],ascending=False)\n\ns2 = s[s.cuisines == 'South Indian']\n\nprint(\"Top voted cheap South Indian restaurants in Bangalore,high votes,high rating\")\ns2","4c7a878d":"s = pd.merge(s2, newdf_votes, how='inner', on=['name'])\ns=s.sort_values(by=['average_cost'])\ns","3ef33eaa":"### Data Visualization","0d150732":"## Finding the best restaurants:-\n### The criteria for best restaurants would be  \n* **cheapest**,  \n* **highly rated**, \n* **reliable**(large number of votes) options.","3e02b1ce":"## We can also explore the expensive options :-\n\nHere, we are only picking up the restaurants that **cost more than** **3000**(half of most expensive restaurant) and are highest rated , have large votes.","8a82ee2f":"## These are the most reliable, highest rated and economical restaurants:- \n\nWe obtain this dataframe by simply taking the intersection of all the dataframes obtained above.\n\n\nThis dataframe obtained below shows the restaurants whose:\n* Cost is below **1500**\n* Rating is above **4.0**\n* Votes are above **175**","47ffd073":"\n\n*You can say that you have the table booking option for Highly rated restaurants.*\n\n\n","cf6c535b":"### Is there a relation between table booking option and rating of the restaurant?","aec6430f":"### Restaurant type distribution plot","1eff3381":"*You are more likely to receive a higher rating if your restaurant offers* **online order** *option.*","82738d2c":"**Now, we'll merge both the dataframes obtained above to get the intersection of both  i.e the highest rated and cheapest restaurants !!**","eb8522c3":"**Now lets find the highest rated restaurants i.e rating above 4.0**\n*Uncomment the last line in code below to get a clearer idea*","f0858441":"## Please upvote and feel free to give any feedback\/comment below!!","8e53773e":"#### Best restaurant options under 500 Rupees (average cost):-\n* **Brahmin's Coffee Bar** with average cost=100 and rating=4.8 and votes=2679\n* **CTR**  with average cost=150 and rating=4.7 and votes=4408\n* **Veena Stores** with average cost=150 and rating=4.5 and votes=2407\n* **O.G. Variar & Sons** with average cost=200 and rating=4.8 and votes=1156\n* **Mavalli Tiffin Room (MTR)** with average cost=250 and rating=4.5 and votes=2896\n* **Belgian Waffle Factory** with average cost=400 and rating=4.9 and votes=1746\n","04cc7919":"* Also, observe that these cheaper options (cost<500) are all either **Quick Bites, Cafe or Dessert Parlour**.\n* **Casual Dining restaurants** start above 600\n* 6 out of 10 of the cheapest restaurants serve **South Indian Cuisine**\n* As for the **location**, these cheap restaurant option are **scattered and not localised** to any specific location of the city.","e765b6ad":"As you can see the rate column is string type with an extra \/5 with all the ratings. This should be cleaned.It is important to convert the string back to float !!","4c5c8c4a":"\n\n*No surprises there!!*\n\n**The Oberoi Hotel, Karavalli and JW Marriott** make this high profile list\n\nInterestingly, all these restaurants have the **same location**- **Brigade Road**  and **same restaurant type**- **Fine dining**","f32c7afc":"### Find the most reliable restaurants: \n**Voted more the mean number of votes:- 175**  \n*Uncomment the last line in code below to get a clearer idea*","dee81d7a":"### Is there a relation between online order option and rating of the restaurant?","ef4ce1c9":"## Breakdown of this notebook:\n1. **Loading the dataset**: Load the data and import the libraries.\n1. **Data Cleaning**: \n     * Deleting redundant columns.\n     * Renaming the columns.\n     * Dropping duplicates.\n     * Cleaning individual columns.\n1. **Data Visualization:** Using plots to find relations between the features.\n1. **Finding the best cheap restaurants:** \n      * **Cheapest, Highest rated and largely voted**.\n      * Is there a **relation** between **cuisine,location and the cost**?\n1. **Exploring the best expensive restaurants.**\n      * Restaurants that are **expensive, Highest rated and largely voted**.\n      * Is there a **relation** between **restaurant type,location and the cost**?\n","879c5c97":"#### First step will be to find the restaurants with average cost 1\/4th the average cost of most expensive restaurant in our dataframe.\n\n\n*Let me explain:-*\nThe most **expensive** restaurant has an average meal cost= **6000**. We'll try to stay economical and only pick the restaurants that are** 1\/4th of 6000.**\n*Uncomment the comments in code below to get a clearer idea !*","863ee685":"### Cost distribution of all the restaurants in City","82d599db":"#### Other findings:-","85b57dfb":"#### Are the locations of restaurants localised to specific parts of city?","a4ad9bf3":"* If you look closely at each column of the dataframe closely you will notice that there are some columns that won't contribute to the ratings and reviews. The **url** or the full **address** of the restaurant or their **phone number** can't justify their ratings or reviews.\n* Note that only the address column is omitted from the dataframe and not the listed_in(city) column,because location details in listed_in(city) column can be very useful in extracting the information about the restaurants.\n* Also,location and listed_in(city) are the same columns.So, we **drop the location column**.\n* The names of columns are a bit non descriptive and confusing so its better to **rename** some of these columns."}}