{"cell_type":{"7e866c8e":"code","642998fc":"code","0696e774":"code","30274d06":"code","bc970c56":"code","e1bbaea0":"code","1dd94468":"code","436664bc":"code","d4595bd0":"code","978d7063":"code","91c8b562":"code","a4df831b":"code","9889503c":"code","cc70c5aa":"markdown","50dab0b3":"markdown","d9b376b1":"markdown","02ca4fc0":"markdown","70360475":"markdown","d82b49a7":"markdown","c15d8842":"markdown","8103bfce":"markdown"},"source":{"7e866c8e":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import Ridge, LinearRegression, Lasso\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom time import perf_counter\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import Markdown, display\n\ndef printmd(string):\n    # Print with Markdowns    \n    display(Markdown(string))\n\nimport warnings\nwarnings.filterwarnings(action='ignore')","642998fc":"# Load the data\ndf = pd.read_csv('..\/input\/university-salaries\/university-salaries\/salaries_final.csv')\n\n# Shuffle the data\ndf.sample(frac=1)\n\n# Display the first rows\ndf.head()","0696e774":"X = df[['Year','Primary Job Title', 'Department', 'College']]\ny = df['Base Pay']","30274d06":"# Construct a ColumnTransformer\ntransf = make_column_transformer( (MinMaxScaler(), ['Year']), \n                                (OneHotEncoder(), ['Primary Job Title', 'Department', 'College']),\n                                sparse_threshold=0)\n# Transform the data\nX_transf = transf.fit_transform(X)","bc970c56":"# Display the result of the transformation\npd.DataFrame(X_transf).iloc[:5,:15]","e1bbaea0":"# Split into train and test set\n# Note: There is a small data leakage for the year, because the dataset was transformed before\n#       spliting it\nX_train, X_test, y_train, y_test = train_test_split(X_transf, y, test_size=0.2, random_state=0)","1dd94468":"models = {\n#     \"LinearRegression\":{\"model\":LinearRegression() }, # LR isn't adapted in this case\n    \"Lasso\":{\"model\":Lasso() },\n    \"Ridge\":{\"model\":Ridge() },\n    \"DecisionTreeRegressor\":{\"model\":DecisionTreeRegressor() },\n    \"RandomForestRegressor\":{\"model\":RandomForestRegressor() },\n    \"MLPRegressor\":{\"model\":MLPRegressor() },\n    \"GradientBoostingRegressor\":{\"model\":GradientBoostingRegressor() },\n    \"AdaBoostRegressor\":{\"model\":AdaBoostRegressor() }\n}\n\n# Use the K-fold cross validation for each model\n# to get the mean validation accuracy and the mean training time\nk = 5\nfor name, m in models.items():\n    # Cross validation of the model\n    model = m['model']\n    result = cross_validate(model, X_train,y_train, cv = k, scoring='neg_mean_squared_error')\n    \n    # Mean accuracy and mean training time\n    result['test_score'] = result['test_score']\n    mean_RMSE = [(-x)**0.5 for x in result['test_score']] # Root Mean Square Error\n    mean_RMSE = sum(mean_RMSE)\/len(mean_RMSE)\n    mean_RMSE = round(mean_RMSE,4)\n    mean_fit_time = round( sum(result['fit_time']) \/ len(result['fit_time']), 4)\n    \n    # Add the result to the dictionary witht he models\n    m['mean_RMSE'] = mean_RMSE\n    m['Training time (sec)'] = mean_fit_time\n    \n    # Display the result\n    print(f\"{name:27} RMSE for {k}-fold CV: {mean_RMSE} - mean training time {mean_fit_time} sec\")","436664bc":"# Create a DataFrame with the results\nmodels_result = []\n\nfor name, v in models.items():\n    lst = [name, v['mean_RMSE'],v['Training time (sec)']]\n    models_result.append(lst)\n\ndf_results = pd.DataFrame(models_result, \n                          columns = ['model','RMSE','Training time (sec)'])\ndf_results.sort_values(by='RMSE', ascending=True, inplace=True)\ndf_results.reset_index(inplace=True,drop=True)\ndf_results","d4595bd0":"plt.figure(figsize = (15,5))\nsns.barplot(x = 'model', y = 'RMSE', data = df_results)\nplt.title(f'{k}-fold mean RMSE for each Model\\nSmaller is better', fontsize = 15)\n# plt.ylim(0.8,1.005)\nplt.xlabel('Model', fontsize=15)\nplt.ylabel('RMSE',fontsize=15)\nplt.xticks(rotation=90, fontsize=12)\nplt.show()","978d7063":"plt.figure(figsize = (15,5))\nsns.barplot(x = 'model', y = 'Training time (sec)', data = df_results)\nplt.title('Training time for each Model in sec\\nSmaller is better', fontsize = 15)\nplt.xticks(rotation=90, fontsize=12)\nplt.xlabel('Model', fontsize=15)\nplt.ylabel('Training time (sec)',fontsize=15)\nplt.show()","91c8b562":"# Get the model with the highest mean validation accuracy\nbest_model = df_results.iloc[0]\n\n# Fit the model\nmodel = models[best_model[0]]['model']\nmodel.fit(X_train,y_train)\n\n# Predict the labels with the data set\npred = model.predict(X_test)\n\nRMSE = mean_squared_error(y_test,pred)**0.5\nRMSE = int(RMSE)\nMAE = mean_absolute_error(y_test,pred)\nMAE = int(MAE)\n\n# Display the results\nprintmd(f'### Best Model: {best_model[0]}')\nprintmd(f'### RMSE: {RMSE}')\nprintmd(f'### MAE: {MAE}')\nprintmd(f'### Trained in: {best_model[2]:.2f} sec')","a4df831b":"# Concatenate the ratings of the test set\n# with the predictions of those ratings\npred_s = pd.Series(pred)\ny_test_s = y_test.reset_index(drop=True)\n\ndf_result = pd.concat([y_test_s,pred_s], axis = 1)\ndf_result.columns = ['Real', 'Predicted']\n\ndf_result['Real\/Pred'] = df_result['Real'] \/ df_result['Predicted']\n\n# Convert to integer to facilitate reading\nfor c in df_result.columns.drop('Real\/Pred'):\n    df_result[c] = df_result[c].astype('int')\n\ndf_result.sample(n = 10, random_state = 0)","9889503c":"df_result.plot.box()\nplt.title('Boxplot Real Salary VS Predicted Salary', fontsize = 15)\nplt.show()\n\ndf_result.plot.scatter(x='Real', y='Predicted')\nplt.title('Scatterplot Real Salary VS Predicted Salary', fontsize = 15)\nplt.show()","cc70c5aa":"# 1. Load and shuffle the data<a class=\"anchor\" id=\"1\"><\/a>","50dab0b3":"# 2. Data Preprocessing<a class=\"anchor\" id=\"2\"><\/a><a class=\"anchor\" id=\"2\"><\/a>","d9b376b1":"# Load the libraries","02ca4fc0":"# 5. Visualization of the result<a class=\"anchor\" id=\"5\"><\/a>","70360475":"# Overview\nThis data contains salaries of University of Vermont (UVM) faculty from 2009 to 2021. We present two datasets. The second dataset is richer because it contains information on faculty departments\/colleges; however, it contains less rows due to how we chose to join this data.\n\nsalaries_without_dept.csv contains all of the data we extracted from the PDFs. The four columns are: Year, Faculty Name, Primary Job Title, and Base Pay. There are 47,479 rows.\nsalaries_final.csv contains the same columns as, but also joins with data about the faculty's \"Department\" and \"College\" (for a total of six columns). There are only 14,470 rows in this dataset because we removed rows for which we could not identify the Department\/College of the faculty.\n\n# Data dictionary\nThe column definitions are self-explanatory, but the \"College\" abbreviation meanings are unclear to a non-UVM-affiliate. We've included data_dictionary.csv to explain what each \"College\" abbreviation means. You can use this dictionary to filter out miscellaneous \"colleges\" (e.g. UVM Libraries) and only include colleges within the undergraduate program (e.g. filter out College of Medicine).","d82b49a7":"# 3. Model comparison<a class=\"anchor\" id=\"3\"><\/a>","c15d8842":"# 4. Prediction metrics of the best model using the test set<a class=\"anchor\" id=\"4\"><\/a>","8103bfce":"# Predict Salary at the University\n## *Comparing 7 regression algorithms*\n\n![salary university](https:\/\/i.imgur.com\/9xhOHFU.png)\n  "}}