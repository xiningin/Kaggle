{"cell_type":{"fe209943":"code","3230b22c":"code","c3a3f576":"code","d636827c":"code","2fe31022":"code","53b3127a":"code","12e56d64":"code","9d29963b":"code","181dabec":"code","56bbc3ee":"code","89feb07a":"code","820244c8":"code","cc1ca3a5":"code","a5070256":"code","5fe52e21":"code","d839394e":"code","677fdc70":"code","9c81c7ae":"code","817f8fbb":"code","963e9989":"code","bfdd2985":"code","35b09290":"markdown","9bb0d9d0":"markdown","dbe015d1":"markdown","3d6ff1c1":"markdown","48357865":"markdown","77325294":"markdown","e85c4f8b":"markdown","cff71898":"markdown","32a538d0":"markdown","763bb517":"markdown","2ddccf9c":"markdown"},"source":{"fe209943":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","3230b22c":"!pip install git+https:\/\/github.com\/fastai\/fastai2 \nfrom fastai2.vision.all import *","c3a3f576":"# train and test csv\ntrain = pd.read_csv(\"\/kaggle\/input\/shopee-product-detection-student\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/shopee-product-detection-student\/test.csv\")\n# paths leading to images\ntrain_path = Path(\"\/kaggle\/input\/shopee-product-detection-student\/train\/train\/train\/\")\ntest_path = Path(\"\/kaggle\/input\/shopee-product-detection-student\/test\/test\/test\/\")","d636827c":"# add the category to filename for easier usage with fastai API\ntrain['filename'] = train.apply(lambda x: str(x.category).zfill(2) + '\/' + x.filename, axis=1)\ntrain","2fe31022":"# train in a 10% subset of the data\n# to speed up experimentation\n# comment these lines out to increase accuracy (but necessitates longer training time)\nfrom sklearn.model_selection import train_test_split\n_, train = train_test_split(train, test_size=0.1, stratify=train.category)","53b3127a":"item_tfms = [RandomResizedCrop(224, min_scale=0.75)]\nbatch_tfms = [*aug_transforms(), Normalize.from_stats(*imagenet_stats)]\ndef get_dls_from_df(df):\n    df = df.copy()\n    options = {\n        \"item_tfms\": item_tfms,\n        \"batch_tfms\": batch_tfms,\n        \"bs\": 32,\n    }\n    dls = ImageDataLoaders.from_df(df, train_path, **options)\n    return dls","12e56d64":"dls = get_dls_from_df(train)\ndls.show_batch()","9d29963b":"learn = cnn_learner(dls, resnet34, metrics=accuracy, path=\"\/kaggle\/working\")","181dabec":"slr = learn.lr_find()","56bbc3ee":"print(f\"Minimum\/10: {slr.lr_min:.2e}, steepest point: {slr.lr_steep:.2e}\")","89feb07a":"learn.fine_tune(2, 5e-3)","820244c8":"interp = ClassificationInterpretation.from_learner(learn)","cc1ca3a5":"interp.plot_confusion_matrix(figsize=(15,15), dpi=60)","a5070256":"# get the most confused labels with at least 10 incorrect predictions\ninterp.most_confused(10)","5fe52e21":"test_images = test.filename.apply(lambda fn: test_path\/fn)\ntest_dl = dls.test_dl(test_images)","d839394e":"preds = learn.get_preds(dl=test_dl, with_decoded=True)\npreds","677fdc70":"# save raw predictions\ntorch.save(preds, \"rawpreds\")","9c81c7ae":"submission  = test[[\"filename\"]]\nsubmission[\"category\"] = preds[2]","817f8fbb":"# zero-pad the submissions\nsubmission[\"category\"] = submission.category.apply(lambda c: str(c).zfill(2))","963e9989":"# preview\nsubmission","bfdd2985":"# save the submissions as CSV\nsubmission.to_csv(\"submission.csv\")","35b09290":"## Modeling, Training and Interpretation","9bb0d9d0":"## Predictions","dbe015d1":"* preds[0] -> probabilities\n* preds[1] -> ground truth (None in this case as we are training on the test set)\n* preds[2] -> decoded probabilities AKA our category\/label predictions","3d6ff1c1":"Create Test Dataloader from an existing dataloader (so that you can do TTA if you want to) .","48357865":"Use a pretrained ResNet-34 model. \n\nWe first find a good learning rate using fastai2's learning rate finder. Then, training is done in 2 steps:\n* Train only our custom head(42 classes) for 1 epoch\n* Train the whole thing for 2 epoch\n\nThese 2 steps are automatically done by the `fine_tune` method fastai2 provided (and it does a bunch other cool optimizations too)\n\nYou can definitely train for more than these 3 epochs to get better accuracy. Using bigger models will help too.","77325294":"This is a simple starter notebook for this challenge using the fastai2 library. \n\nAs someone new to Deep Learning, I know how hard it is just to setup a working pipeline. Therefore, this is just a simple demonstraation of how you might do a whole pipeline from loading data until generating submissions.\n\nFeel free to modify and improve on this code.\n\n*PS: you might be able to get 0.6 - 0.7 accuracy using this (even more when training with the whole dataset, not just 10% like below and also training for more epochs)*","e85c4f8b":"We need to then zero-pad the submissions ('01' instead of '1').","cff71898":"## Loading Data","32a538d0":"Plot confusion matrix to see how well our model classify specific categories.","763bb517":"## Submission","2ddccf9c":"We load the images easily using fastai2's API. We then crop and resize the image to 224x224 (the size the pre-trained model we will use was trained on) and then do some basic data augmentation and normalization (to ImageNet stats)"}}