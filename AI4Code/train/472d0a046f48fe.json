{"cell_type":{"864dd8e0":"code","567dd643":"code","606b2782":"code","c4a7cc82":"code","69a83f1c":"code","5317afe4":"code","16c9514e":"code","987112d6":"code","dec0a59a":"code","16de945a":"code","7a368a9c":"code","8918ea83":"code","9ace4085":"code","da63fee9":"code","52fc8862":"code","a2690599":"code","45de89a4":"code","0bad1c63":"code","3bd49b86":"code","b0ec0f6d":"code","e75615f7":"code","2710c014":"code","0fa73510":"code","8d45d98a":"code","4450633d":"code","7ca527f7":"code","23b6d56b":"code","02bc0962":"code","226f9c6e":"code","2fd66619":"code","f8593c14":"code","b75ea830":"code","5b27a1b4":"markdown","490988c9":"markdown","a07527a4":"markdown","3497dcc0":"markdown","e0afc59a":"markdown"},"source":{"864dd8e0":"# IMPORT MODULES\n\nimport os\nimport keras\nimport numpy as np  \nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom keras.models import Sequential\nfrom keras.layers import Flatten, Dense, Dropout, Embedding, LSTM\nfrom keras import regularizers, layers, preprocessing\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\nfrom sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\nimport tensorflow as tf\n\nprint(os.listdir(\"..\/input\"))","567dd643":"# Load the dataset.npy\n\nDataRaw = np.load('..\/input\/dataset.npy', allow_pickle=True)\nprint(type(DataRaw))\nprint(DataRaw.ndim)\nDataRaw","606b2782":"# As a dictionary\nDatadict = DataRaw[()]\nprint(Datadict)\n\n# As a dataframe\nDataDf = pd.DataFrame.from_dict(Datadict)\nprint(DataDf.shape)\nDataDf","c4a7cc82":"# Mean  \/ Max \/ Min column width\n\nDataDf.fillna('').astype(str).apply(lambda x:x.str.len()).max()","69a83f1c":"# Is the data balanced ?\n\nDataDf.groupby('resistant').size().plot.bar()\nplt.show()","5317afe4":"# Tokenize from characters to integers (sequences and then pad \/ truncate data)\n\nDatatok = DataDf.copy()\nmaxlen = 160 # cut off after this number of characters in a string\n\nmax_words = 4 # considers only the top number of characters in the dictionary A C T G\nmax_features = max_words\n\ntokenizer = Tokenizer(num_words=max_words, char_level=True)\ntokenizer.fit_on_texts(list(Datatok['genes']))\nsequences = tokenizer.texts_to_sequences(list(Datatok['genes']))\nword_index = tokenizer.word_index\nXpad = pad_sequences(sequences, maxlen=maxlen, padding='post', truncating='post', value=0)\n\nprint('Found %s unique tokens.' % len(word_index))\nprint('word_index', word_index)","16c9514e":"# Separate the label\n\nlabels = np.asarray(Datatok['resistant'])\nprint(Xpad.shape)\nprint(labels.shape)","987112d6":"# Check a sample\n\nrowNum = 37149\nprint(Datatok['genes'][rowNum])\nprint(sequences[rowNum])\nprint(Xpad[rowNum])\nprint(labels[rowNum])","dec0a59a":"# Create train & val and test datasets with inital shuffle (as the original dataset may be arranged)\n\ntraining_samples = int(Xpad.shape[0] * 0.9)\n# The validation is being taken by keras - below\n# test = remaining\n\nindices = np.arange(Xpad.shape[0])\nnp.random.shuffle(indices) # FOR TESTING PURPOSES comment it out - to keep indices as above\n\nXpad = Xpad[indices]\nlabels = labels[indices]\n\nx_train = Xpad[:training_samples]\ny_train = labels[:training_samples]\nx_test = Xpad[training_samples: ]\ny_test = labels[training_samples: ]\n\nprint('x_train', x_train.shape)\nprint('y_train', y_train.shape)\nprint('x_test', x_test.shape)\nprint('y_test', y_test.shape)","16de945a":"# Model ... 128 CNN window 27 & Bidirectional GRU accuracy = \n\nmodel = Sequential()\nmodel.add(Embedding(4, 1, input_length=maxlen))\nmodel.add(layers.Conv1D(128, 27, activation='relu'))\nmodel.add(layers.MaxPooling1D(9))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Conv1D(128, 9, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Bidirectional(layers.GRU(32, dropout=0.2, recurrent_dropout=0.2)))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\nmodel.summary()","7a368a9c":"# Train \/ Validate model\n\nhistory = model.fit(x_train, y_train,\nepochs = 10,\nbatch_size=32,\nvalidation_split=0.2)","8918ea83":"# Learning curves\n\n# VALIDATION LOSS curves\n\nplt.clf()\nhistory_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nepochs = range(1, (len(history_dict['loss']) + 1))\nplt.plot(epochs, loss_values, 'bo', label='Training loss')\nplt.plot(epochs, val_loss_values, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# VALIDATION ACCURACY curves\n\nplt.clf()\nacc_values = history_dict['acc']\nval_acc_values = history_dict['val_acc']\nepochs = range(1, (len(history_dict['acc']) + 1))\nplt.plot(epochs, acc_values, 'bo', label='Training acc')\nplt.plot(epochs, val_acc_values, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","9ace4085":"# Final Predict on test\n\nfinal_predictions = model.predict(x_test)\nprint(final_predictions)\n\n# Modify the raw final_predictions - prediction probs  - into 0 and 1\n# Cutoff point = 0.5\n\nPreds = final_predictions.copy()\nprint(len(Preds))\n\nPreds[ np.where( Preds >= 0.5 ) ] = 1\nPreds[ np.where( Preds < 0.5 ) ] = 0\nprint(Preds)","da63fee9":"# Confusion matrix\n\nconf_mx = confusion_matrix(y_test, Preds)\n\nTN = conf_mx[0,0]\nFP = conf_mx[0,1]\nFN = conf_mx[1,0]\nTP = conf_mx[1,1]\n\nprint ('TN: ', TN)\nprint ('FP: ', FP)\nprint ('FN: ', FN)\nprint ('TP: ', TP)\n\nrecall = TP\/(TP+FN)\nprecision = TP\/(TP+FP)\n\nprint (recall, precision)","52fc8862":"# Function to visualize the confusion matrix\n\ndef plot_confusion_matrix(cm,target_names,title='Confusion matrix',cmap=None,\n                          normalize=False):\n    import itertools\n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n    \n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()","a2690599":"plot_confusion_matrix(conf_mx, \n                      normalize    = False,\n                      target_names = ['resistant', 'sensistive'],\n                      title        = \"Confusion Matrix \")","45de89a4":"print ('precision ',precision_score(y_test, Preds))\nprint ('recall ',recall_score(y_test, Preds) )\nprint ('accuracy ',accuracy_score(y_test, Preds))\nprint ('F1 score ',f1_score(y_test, Preds))","0bad1c63":"# AUC\/ROC curves should be used when there are roughly equal numbers of observations for each class\n# Precision-Recall curves should be used when there is a moderate to large class imbalance\n\n# calculate AUC\nauc = roc_auc_score(y_test, Preds)\nprint('AUC: %.3f' % auc)\n# calculate roc curve\nfpr, tpr, thresholds = roc_curve(y_test, Preds)\nplt.plot([0, 1], [0, 1], linestyle='--')\n# plot the roc curve for the model\nplt.plot(fpr, tpr, marker='.')\nplt.title('ROC ')\nplt.show()","3bd49b86":"# calculate precision-recall curve\nprecision, recall, thresholds = precision_recall_curve(y_test, Preds)\n# calculate F1 score\nf1 = f1_score(y_test, Preds)\n# calculate average precision score\nap = average_precision_score(y_test, Preds)\nprint('f1=%.3f ap=%.3f' % (f1, ap))\nplt.plot([0, 1], [0.5, 0.5], linestyle='--')\n# plot the roc curve for the model\nplt.plot(recall, precision, marker='.')\nplt.show()","b0ec0f6d":"# From nucleotides to codons ... w\/o considering the start \/ stop codons as the data is synthetic and may not have these\n\nDataCod = DataDf.copy()\n\nCodons = list(DataCod['genes'])\nprint(len(Codons))\n\nfor n in range(len(Codons)):\n    Codons[n] = list([Codons[n][i:i+3] for i in range(0, len(Codons[n]), 3)])\n    \nDataCod['codons'] = Codons\nDataCod","e75615f7":"# Tokenize from codons to integers (sequences and then pad \/ truncate data)\n\nmaxlen = 53 # cut off after this number of codons in a list\n\nmax_words = 64 # considers only the top number of codons  in the dictionary (It finds 66 below because of 'a' and 'ga')\nmax_features = max_words\n\n#tokenizer = Tokenizer(num_words=max_words, char_level=True)\ntokenizer = Tokenizer(num_words=max_words)\ntokenizer.fit_on_texts(list(DataCod['codons']))\nsequences = tokenizer.texts_to_sequences(list(DataCod['codons']))\nword_index = tokenizer.word_index\nXpad = pad_sequences(sequences, maxlen=maxlen, padding='post', truncating='post', value=0)\n\nprint('Found %s unique tokens.' % len(word_index))\nprint('word_index', word_index)","2710c014":"# Separate the label\n\nlabels = np.asarray(DataCod['resistant'])\nprint(Xpad.shape)\nprint(labels.shape)","0fa73510":"# Check a sample\n\nrowNum = 37149\nprint(DataCod['genes'][rowNum])\nprint(DataCod['codons'][rowNum])\nprint(sequences[rowNum])\nprint(Xpad[rowNum])\nprint(labels[rowNum])","8d45d98a":"# Create train & val and test datasets with inital shuffle (as the original dataset may be arranged)\n\ntraining_samples = int(Xpad.shape[0] * 0.9)\n# The validation is being taken by keras - below\n# test = remaining\n\nindices = np.arange(Xpad.shape[0])\nnp.random.shuffle(indices) # FOR TESTING PURPOSES comment it out - to keep indices as above\n\nXpad = Xpad[indices]\nlabels = labels[indices]\n\nx_train = Xpad[:training_samples]\ny_train = labels[:training_samples]\nx_test = Xpad[training_samples: ]\ny_test = labels[training_samples: ]\n\nprint('x_train', x_train.shape)\nprint('y_train', y_train.shape)\nprint('x_test', x_test.shape)\nprint('y_test', y_test.shape)","4450633d":"# Model ... 64 CNN window 27 & Bidirectional GRU accuracy = 0.99\n\nmodel = Sequential()\nmodel.add(Embedding(64, 1, input_length=maxlen))\nmodel.add(layers.Conv1D(128, 27, activation='relu'))\nmodel.add(layers.MaxPooling1D(3))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Conv1D(128, 9, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Bidirectional(layers.GRU(32, dropout=0.2, recurrent_dropout=0.2)))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\nmodel.summary()","7ca527f7":"# Train \/ Validate model\n\nhistory = model.fit(x_train, y_train,\nepochs = 10,\nbatch_size=32,\nvalidation_split=0.2)","23b6d56b":"# Learning curves\n\n# VALIDATION LOSS curves\n\nplt.clf()\nhistory_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nepochs = range(1, (len(history_dict['loss']) + 1))\nplt.plot(epochs, loss_values, 'bo', label='Training loss')\nplt.plot(epochs, val_loss_values, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# VALIDATION ACCURACY curves\n\nplt.clf()\nacc_values = history_dict['acc']\nval_acc_values = history_dict['val_acc']\nepochs = range(1, (len(history_dict['acc']) + 1))\nplt.plot(epochs, acc_values, 'bo', label='Training acc')\nplt.plot(epochs, val_acc_values, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","02bc0962":"# Final Predict on test\n\nfinal_predictions = model.predict(x_test)\nprint(final_predictions)\n\n# Modify the raw final_predictions - prediction probs  - into 0 and 1\n# Cutoff point = 0.5\n\nPreds = final_predictions.copy()\nprint(len(Preds))\n\nPreds[ np.where( Preds >= 0.5 ) ] = 1\nPreds[ np.where( Preds < 0.5 ) ] = 0\nprint(Preds)","226f9c6e":"# Confusion matrix\n\nconf_mx = confusion_matrix(y_test, Preds)\n\nTN = conf_mx[0,0]\nFP = conf_mx[0,1]\nFN = conf_mx[1,0]\nTP = conf_mx[1,1]\n\nprint ('TN: ', TN)\nprint ('FP: ', FP)\nprint ('FN: ', FN)\nprint ('TP: ', TP)\n\nrecall = TP\/(TP+FN)\nprecision = TP\/(TP+FP)\n\nprint (recall, precision)","2fd66619":"plot_confusion_matrix(conf_mx, \n                      normalize    = False,\n                      target_names = ['resistant', 'sensistive'],\n                      title        = \"Confusion Matrix \")","f8593c14":"# AUC\/ROC curves should be used when there are roughly equal numbers of observations for each class\n# Precision-Recall curves should be used when there is a moderate to large class imbalance\n\n# calculate AUC\nauc = roc_auc_score(y_test, Preds)\nprint('AUC: %.3f' % auc)\n# calculate roc curve\nfpr, tpr, thresholds = roc_curve(y_test, Preds)\nplt.plot([0, 1], [0, 1], linestyle='--')\n# plot the roc curve for the model\nplt.plot(fpr, tpr, marker='.')\nplt.title('ROC ')\nplt.show()","b75ea830":"# calculate precision-recall curve\nprecision, recall, thresholds = precision_recall_curve(y_test, Preds)\n# calculate F1 score\nf1 = f1_score(y_test, Preds)\n# calculate average precision score\nap = average_precision_score(y_test, Preds)\nprint('f1=%.3f ap=%.3f' % (f1, ap))\nplt.plot([0, 1], [0.5, 0.5], linestyle='--')\n# plot the roc curve for the model\nplt.plot(recall, precision, marker='.')\nplt.show()","5b27a1b4":"# RESULTS\n* The guessing, sanity check, baseline accuracy is 50% as the dataset is balanced\n* All the results below are on the test dataset only - which the model was not exposed to during training \/ validation\n* Confusion matrix, precision , recall, F! score and ROC AUC in addition to accuracy","490988c9":"# DATA","a07527a4":"# Codons instead of nucleotides ... from 81% to 99%","3497dcc0":"# MODELS\n* There are several models below, all being Keras+TF and able to analyze sequences where order is important\n* No point in trying any shallow model as they cannot deal with ordered sequences","e0afc59a":"# GOALS\n* Binary classification supervised learning\n* Features: Genomic sequence, 4 letters with their order being very important\n* Label: True or False - whether resistant or not to an antibiotic (or class of antibiotics)\n* The genomic string should be tokenized first into the four letters G,C,T,A\n* The models should be able to deal with text sequences while considering the order\n* As the dataset is well balanced 0.502 being False with the others being True - the guessing accuracy \/ sanity check = 50%\n* Initial RNNs 67% \n* Conv1D + Bidirectional GRU = 81%\n* Presenting the model codons instead of nucleotides = 99%\n"}}