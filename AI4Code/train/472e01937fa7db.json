{"cell_type":{"70efe3d9":"code","2808d0e6":"code","d2c485b0":"code","75f84127":"code","aae3f4e6":"code","c8d3d27f":"code","efcbc508":"code","1f3ad4f2":"code","faf3e239":"code","e296aa88":"code","43afd752":"code","996c1c4f":"markdown","1d61d997":"markdown","7c81f44c":"markdown","db56d083":"markdown","f667ed6b":"markdown","34a3f54b":"markdown","67fcb1be":"markdown"},"source":{"70efe3d9":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport os.path\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\n\nfrom sklearn.metrics import confusion_matrix, classification_report","2808d0e6":"image_dir = Path('..\/input\/marvel-heroes\/marvel')","d2c485b0":"filepaths = list(image_dir.glob(r'**\/*.jpg'))\nlabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n\nfilepaths = pd.Series(filepaths, name='Filepath').astype(str)\nlabels = pd.Series(labels, name='Label')\n\nimage_df = pd.concat([filepaths, labels], axis=1)\n\nimage_df['Label'].value_counts()","75f84127":"samples = []\nfor category in image_df['Label'].unique():\n    category_slice = image_df.query(\"Label == @category\")\n    samples.append(category_slice.sample(200, random_state=1))\nimage_df = pd.concat(samples, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)\n\nimage_df['Label'].value_counts()","aae3f4e6":"image_df","c8d3d27f":"train_df, test_df = train_test_split(image_df, train_size=0.7, shuffle=True, random_state=1)","efcbc508":"train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n    validation_split=0.2\n)\n\ntest_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n)","1f3ad4f2":"train_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='training'\n)\n\nval_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='validation'\n)\n\ntest_images = test_generator.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=False\n)","faf3e239":"pretrained_model = tf.keras.applications.MobileNetV2(\n    input_shape=(224, 224, 3),\n    include_top=False,\n    weights='imagenet',\n    pooling='avg'\n)\n\npretrained_model.trainable = False ","e296aa88":"inputs = pretrained_model.input\nx = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\noutputs = tf.keras.layers.Dense(8, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=100,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ]\n)","43afd752":"results = model.evaluate(test_images, verbose=0)\npredictions = np.argmax(model.predict(test_images), axis=1)\n\nclass_names = list(test_images.class_indices.keys())\n\ncm = confusion_matrix(test_images.labels, predictions, labels=np.arange(8))\nclr = classification_report(test_images.labels, predictions, labels=np.arange(8), target_names=class_names)\n\nprint(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))\n\nplt.figure(figsize=(8, 8))\nsns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)\nplt.xticks(ticks=np.arange(8) + 0.5, labels=class_names, rotation=90)\nplt.yticks(ticks=np.arange(8) + 0.5, labels=class_names, rotation=0)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\nprint(\"Classification Report:\\n----------------------\\n\", clr)","996c1c4f":"# Getting Started","1d61d997":"# Training","7c81f44c":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/p1znpVnjZKA","db56d083":"# Results","f667ed6b":"# Loading Image Data","34a3f54b":"# Creating File DataFrame","67fcb1be":"# Task for Today  \n\n***\n\n## Marvel Character Image Classification  \n\nGiven *images of Marvel characters*, let's try to classifiy which **character** is present in a given image.\n\nWe will use a pretrained TensorFlow\/Keras CNN to make our predictions."}}