{"cell_type":{"496769b5":"code","af9322e2":"code","3b22b101":"code","44bb34a3":"code","a807045b":"code","b9e72f8f":"code","07797426":"code","26fda6b1":"code","c652fc29":"code","241434a1":"code","2b5e2dc7":"code","43d0b463":"code","1e319bc5":"code","99af90d9":"code","ed734a71":"code","ddeea675":"code","d22aeb1a":"code","19c2a3c5":"code","efd01e4b":"code","8e3f2148":"code","e6db082f":"code","6396e198":"code","27c22d6d":"code","8816a9ce":"code","d2a9f4ed":"code","b26b3376":"code","3c32f701":"code","0128c484":"code","7a29ff59":"code","cb6d9a2f":"code","8722686f":"code","33a5a9ca":"code","180a4cd5":"code","cc5126ff":"code","14018258":"code","d905d875":"markdown","48f5ec79":"markdown","4ff83cb4":"markdown","9a5801b5":"markdown","dad2980f":"markdown","e6c32918":"markdown","33c8f8a3":"markdown","0b30ac93":"markdown","8d926708":"markdown","6774d168":"markdown","92d9d977":"markdown","aded5e46":"markdown","eafb1291":"markdown"},"source":{"496769b5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","af9322e2":"import matplotlib.pyplot as plt\nimport squarify\nimport matplotlib.dates as dates\nfrom datetime import datetime\n\n%matplotlib inline","3b22b101":"df = pd.read_csv('\/kaggle\/input\/ecommerce-behavior-data-from-multi-category-store\/2019-Nov.csv')","44bb34a3":"df.head()","a807045b":"df.info()","b9e72f8f":"df.shape","07797426":"df.columns","26fda6b1":"visitor = df['user_id'].nunique()\nprint (\"visitors: {}\".format(visitor))","c652fc29":"d = df.loc[:,['event_time','user_id']]","241434a1":"d['event_time'] = d['event_time'].apply(lambda s: str(s)[0:10])\n","2b5e2dc7":"\nvisitor_by_date = d.drop_duplicates().groupby(['event_time'])['user_id'].agg(['count']).sort_values(by=['event_time'], ascending=True)","43d0b463":"x = pd.Series(visitor_by_date.index.values).apply(lambda s: datetime.strptime(s, '%Y-%m-%d').date())\ny = visitor_by_date['count']\nplt.rcParams['figure.figsize'] = (20,8)\n\nplt.plot(x,y)\nplt.show()","1e319bc5":"top_category_n = 30\ntop_category = df.loc[:,'category_code'].value_counts()[:top_category_n].sort_values(ascending=False)\nsquarify.plot(sizes=top_category, label=top_category.index.array, color=[\"red\",\"cyan\",\"green\",\"orange\",\"blue\",\"grey\"], alpha=.7  )\nplt.axis('off')\nplt.show()","99af90d9":"labels = ['view', 'cart','purchase']\nsize = df['event_type'].value_counts()\ncolors = ['yellowgreen', 'lightskyblue','lightcoral']\nexplode = [0, 0.1,0.1]\n\nplt.rcParams['figure.figsize'] = (8, 8)\nplt.pie(size, colors = colors, explode = explode, labels = labels, shadow = True, autopct = '%.2f%%')\nplt.title('Event_Type', fontsize = 20)\nplt.axis('off')\nplt.legend()\nplt.show()","ed734a71":"purchase = df.loc[df['event_type'] == 'purchase']\npurchase = purchase.dropna(axis='rows')\npurchase.head()","ddeea675":"top_sellers = purchase.groupby('brand')['brand'].agg(['count']).sort_values('count', ascending=False)\ntop_sellers.head(20)","d22aeb1a":"df_targets = df.loc[df[\"event_type\"].isin([\"cart\",\"purchase\"])].drop_duplicates(subset=['event_type', 'product_id','price', 'user_id','user_session'])\ndf_targets[\"is_purchased\"] = np.where(df_targets[\"event_type\"]==\"purchase\",1,0)\ndf_targets[\"is_purchased\"] = df_targets.groupby([\"user_session\",\"product_id\"])[\"is_purchased\"].transform(\"max\")\ndf_targets = df_targets.loc[df_targets[\"event_type\"]==\"cart\"].drop_duplicates([\"user_session\",\"product_id\",\"is_purchased\"])\ndf_targets['event_weekday'] = df_targets['event_time'].apply(lambda s: str(datetime.strptime(str(s)[0:10], \"%Y-%m-%d\").weekday()))\ndf_targets.dropna(how='any', inplace=True)\ndf_targets[\"category_code_level1\"] = df_targets[\"category_code\"].str.split(\".\",expand=True)[0].astype('category')\ndf_targets[\"category_code_level2\"] = df_targets[\"category_code\"].str.split(\".\",expand=True)[1].astype('category')","19c2a3c5":"cart_purchase_users = df.loc[df[\"event_type\"].isin([\"cart\",\"purchase\"])].drop_duplicates(subset=['user_id'])\ncart_purchase_users.dropna(how='any', inplace=True)\ncart_purchase_users_all_activity = df.loc[df['user_id'].isin(cart_purchase_users['user_id'])]","efd01e4b":"\nactivity_in_session = cart_purchase_users_all_activity.groupby(['user_session'])['event_type'].count().reset_index()\nactivity_in_session = activity_in_session.rename(columns={\"event_type\": \"activity_count\"})","8e3f2148":"del d # free memory","e6db082f":"\ndf_targets = df_targets.merge(activity_in_session, on='user_session', how='left')\ndf_targets['activity_count'] = df_targets['activity_count'].fillna(0)\ndf_targets.head()","6396e198":"df_targets.to_csv('training_data.csv')","27c22d6d":"df_targets.info()","8816a9ce":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import plot_importance\nfrom sklearn.utils import resample\nfrom sklearn import metrics","d2a9f4ed":"is_purcahase_set = df_targets[df_targets['is_purchased']== 1]\nis_purcahase_set.shape[0]","b26b3376":"not_purcahase_set = df_targets[df_targets['is_purchased']== 0]\nnot_purcahase_set.shape[0]","3c32f701":"n_samples = 500000\nis_purchase_downsampled = resample(is_purcahase_set,\n                                replace = False, \n                                n_samples = n_samples,\n                                random_state = 27)\nnot_purcahase_set_downsampled = resample(not_purcahase_set,\n                                replace = False,\n                                n_samples = n_samples,\n                                random_state = 27)","0128c484":"downsampled = pd.concat([is_purchase_downsampled, not_purcahase_set_downsampled])\ndownsampled['is_purchased'].value_counts()","7a29ff59":"features = downsampled.loc[:,['brand', 'price', 'event_weekday', 'category_code_level1', 'category_code_level2', 'activity_count']]","cb6d9a2f":"features.loc[:,'brand'] = LabelEncoder().fit_transform(downsampled.loc[:,'brand'].copy())\nfeatures.loc[:,'event_weekday'] = LabelEncoder().fit_transform(downsampled.loc[:,'event_weekday'].copy())\nfeatures.loc[:,'category_code_level1'] = LabelEncoder().fit_transform(downsampled.loc[:,'category_code_level1'].copy())\nfeatures.loc[:,'category_code_level2'] = LabelEncoder().fit_transform(downsampled.loc[:,'category_code_level2'].copy())\n\nis_purchased = LabelEncoder().fit_transform(downsampled['is_purchased'])\nfeatures.head()","8722686f":"print(list(features.columns))","33a5a9ca":"X_train, X_test, y_train, y_test = train_test_split(features, \n                                                    is_purchased, \n                                                    test_size = 0.3, \n                                                    random_state = 0)","180a4cd5":"from xgboost import XGBClassifier\nmodel = XGBClassifier(learning_rate=0.1)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)","cc5126ff":"print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))\nprint(\"fbeta:\",metrics.fbeta_score(y_test, y_pred, average='weighted', beta=0.5))","14018258":"plot_importance(model, max_num_features=10, importance_type ='gain')\nplt.rcParams['figure.figsize'] = (40,10)\nplt.show()","d905d875":"### By Category and Product\nWhich category customers interact the most? What brand the view to most?","48f5ec79":"## Feature importance","4ff83cb4":"## Split the data","9a5801b5":"## What brands the customers buy?","dad2980f":"## Train the model","e6c32918":"# Modeling: predict at time of addition to shopping cart if user will purchase a given product or not\n### Feature engineering\n\nRestructure the data to feed into the machine learning model. For this use case, I only target the data which customers have \"put\" the product in the cart.\n\nFurthermore, I add some new features into the training data set:\n\n- category_code_level1: category\n- category_code_level2: sub-category\n- event_weekday: weekday of the event\n- activity_count: number of activity in that session\n- is_purchased: whether the put in cart item is purchased\n\nThus, the training data set contains every non-duplicated cart transaction (within the same session, I only keep one record for a particular product in the cart) with above mentioned new feature. I will use those features, including the original price and brand to predict whether customers will eventually purchase the item in the cart.","33c8f8a3":"## event_type = \"purchase\", what item do customers buy?","0b30ac93":"## Save new data structure for modeling","8d926708":"**Prepare a dataframe for counting activity in the session**","6774d168":"# Know your Customers\nHow many customers visit the site?","92d9d977":"## Encode categorical variables","aded5e46":"# Vistors Daily Trend\nDoes traffic flunctuate by date?","eafb1291":"## Resampling training set"}}