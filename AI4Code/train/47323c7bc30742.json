{"cell_type":{"d4c90fdd":"code","aa60a621":"code","d36b7bf9":"code","3e89a892":"code","d96ef982":"code","db10fb97":"code","39443548":"code","8a2cfb3b":"code","c6a65bff":"markdown","efc20f4e":"markdown","960b85e1":"markdown"},"source":{"d4c90fdd":"import numpy as np\nimport pandas as pd\nimport spacy\nfrom spacy import displacy\nnlp = spacy.load(\"en_core_web_sm\")\nimport nltk\nfrom sklearn import *\nfrom sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport time","aa60a621":"test = pd.read_csv(\"..\/input\/test_stage_1.tsv\", delimiter=\"\\t\").rename(columns={\"A\": \"A_Noun\", \"B\": \"B_Noun\"})\nsub = pd.read_csv(\"..\/input\/sample_submission_stage_1.csv\")\ntest.shape, sub.shape","d36b7bf9":"gh_test = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/google-research-datasets\/gap-coreference\/master\/gap-test.tsv\", delimiter='\\t')\ngh_valid = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/google-research-datasets\/gap-coreference\/master\/gap-validation.tsv\", delimiter='\\t')\ntrain = pd.concat((gh_test, gh_valid)).rename(columns={'A': 'A_Noun', 'B': 'B_Noun'}).reset_index(drop=True)\ntrain.shape","3e89a892":"def name_replace(s, r1, r2):\n    s = str(s).replace(r1,r2)\n    for r3 in r1.split(\" \"):\n        s = str(s).replace(r3,r2)\n    return s\n\ndef get_features(df):\n    df['section_min'] = df[['Pronoun-offset', 'A-offset', 'B-offset']].min(axis=1)\n    df['Pronoun-offset2'] = df['Pronoun-offset'] + df['Pronoun'].map(len)\n    df['A-offset2'] = df['A-offset'] + df['A_Noun'].map(len)\n    df['B-offset2'] = df['B-offset'] + df['B_Noun'].map(len)                               \n    df['section_max'] = df[['Pronoun-offset2', 'A-offset2', 'B-offset2']].max(axis=1)\n    df['Text'] = df.apply(lambda r: name_replace(r['Text'], r['A_Noun'], 'subjectone'), axis=1)\n    df['Text'] = df.apply(lambda r: name_replace(r['Text'], r['B_Noun'], 'subjecttwo'), axis=1)\n    \n    df['A-dist'] = (df['Pronoun-offset'] - df['A-offset']).abs()\n    df['B-dist'] = (df['Pronoun-offset'] - df['B-offset']).abs()\n    return(df)\n\ntrain = get_features(train)\ntest = get_features(test)","d96ef982":"%%time\ndef get_nlp_features(s, w):\n    doc = nlp(str(s))\n    tokens = pd.DataFrame([[token.text, token.dep_] for token in doc], columns=['text', 'dep'])\n    return len(tokens[((tokens['text']==w) & (tokens['dep']=='poss'))])\n\ntrain['A-poss'] = train['Text'].map(lambda x: get_nlp_features(x, 'subjectone'))\ntrain['B-poss'] = train['Text'].map(lambda x: get_nlp_features(x, 'subjecttwo'))\ntest['A-poss'] = test['Text'].map(lambda x: get_nlp_features(x, 'subjectone'))\ntest['B-poss'] = test['Text'].map(lambda x: get_nlp_features(x, 'subjecttwo'))","db10fb97":"train = train.rename(columns={\"A-coref\": \"A\", \"B-coref\": \"B\"})\ntrain[\"A\"] = train[\"A\"].astype(int)\ntrain[\"B\"] = train[\"B\"].astype(int)\ntrain[\"NEITHER\"] = 1.0 - (train[\"A\"] + train[\"B\"])","39443548":"col = [\"Pronoun-offset\", \"A-offset\", \"B-offset\", \"section_min\", \"Pronoun-offset2\", \"A-offset2\", \"B-offset2\", \"section_max\", \"A-poss\", \"B-poss\", \"A-dist\", \"B-dist\"]\nx1, x2, y1, y2 = model_selection.train_test_split(train[col].fillna(-1), train[[\"A\", \"B\", \"NEITHER\"]], test_size=0.2, random_state=1)\nx1.head()","8a2cfb3b":"# set hyper parameters\nlgb_params = {\"learning_rate\": 0.01,\n              \"num_leaves\": 16,\n              \"min_data_in_leaf\": 20,\n              \"boosting\": \"gbdt\",\n              \"num_iterations\": 120,\n              \"bagging_fraction\": 0.6,\n              \"feature_fraction\": 1.0,\n              \"seed\": 42,\n              \"num_threads\": -1\n              }\n\"\"\"\nxgb_params = {\"eta\": 0.05,\n              \"max_depth\": 2,\n              \"n_estimators\": 120,\n              \"objective\": \"binary:logistic\",\n              \"eval_metric\": \"logloss\",\n              \"booster\": \"gbtree\",\n              \"subsample\": 0.6,\n              \"colsample_bytree\": 0.6,\n              \"seed\": 42,\n              \"n_jobs\": -1\n             }\n\"\"\"\n\n#model = multiclass.OneVsRestClassifier(ensemble.RandomForestClassifier(max_depth=7, n_estimators=1000, random_state=33))\n#model = multiclass.OneVsRestClassifier(xgb.XGBClassifier(**xgb_params))\nmodel = multiclass.OneVsRestClassifier(lgb.LGBMClassifier(**lgb_params))\n\n# 5 fold CV\nfolds = 5\nkf = KFold(n_splits=folds, shuffle=False, random_state=11)\ntrn = train[col].fillna(-1)\nval = train[[\"A\", \"B\", \"NEITHER\"]]\nscores = []\ni = 0\n\nfor train_index, test_index in kf.split(train):\n    x1, x2 = trn.iloc[train_index], trn.iloc[test_index]\n    y1, y2 = val.iloc[train_index], val.iloc[test_index]\n\n    model.fit(x1, y1)\n    score = metrics.log_loss(y2, model.predict_proba(x2))\n    print(str(i+1), \"log-loss:\", score)\n    scores.append(score)\n    i += 1\n\nprint(\"CV Score(log-loss):\", np.mean(scores))\n\n\nmodel.fit(train[col].fillna(-1), train[[\"A\", \"B\", \"NEITHER\"]])\nresults = model.predict_proba(test[col])\ntest[\"A\"] = results[:,0]\ntest[\"B\"] = results[:,1]\ntest[\"NEITHER\"] = results[:,2]\ntest[[\"ID\", \"A\", \"B\", \"NEITHER\"]].to_csv(\"submission.csv\", index=False)","c6a65bff":"# Model Training & Prediction","efc20f4e":"This kernel is based on https:\/\/www.kaggle.com\/shujian\/ml-model-example-with-train-test.  \nThanks S.L. for your excellent work!","960b85e1":"# Feature Extraction"}}