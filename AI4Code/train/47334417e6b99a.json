{"cell_type":{"845c0c42":"code","1222acd7":"code","1c11a3a8":"code","a346e22f":"code","08756088":"code","337ac53d":"code","e8e7a408":"code","fe6416ef":"code","cd0be857":"code","4190547a":"markdown","b8a7e9a9":"markdown","c576bdc7":"markdown","eddd8624":"markdown","c3e3d393":"markdown","58823852":"markdown","5db34a5c":"markdown"},"source":{"845c0c42":"import numpy as np\nimport os\nimport shutil\nimport cv2\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import Dense, Activation,Dropout,BatchNormalization, Input\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom sklearn.metrics import confusion_matrix, classification_report","1222acd7":"sdir=r'..\/input\/butterfly-images40-species\/butterflies_rev2'\ntrain_dir=os.path.join(sdir, 'train')\ntest_dir=os.path.join(sdir, 'test')\nvalid_dir=os.path.join(sdir, 'valid')","1c11a3a8":"img_shape=(128,128,3)\nimg_size=(img_shape[0], img_shape[1])\ntrain_ds=tf.keras.preprocessing.image_dataset_from_directory(\n            train_dir, image_size=img_size, seed=123, batch_size=30)\nvalid_ds=tf.keras.preprocessing.image_dataset_from_directory(\n            valid_dir, image_size=img_size, seed=123, batch_size=30)\ntest_ds=tf.keras.preprocessing.image_dataset_from_directory(\n            valid_dir, image_size=img_size, shuffle=False, batch_size=30) # set shuffle=False to keep file order","a346e22f":"class_names=train_ds.class_names\nytrue=[]\nfor images, label in test_ds:   \n    for e in label:\n        ytrue.append(class_names[e])\nprint (len(ytrue))\nprint (ytrue[0])    ","08756088":"class_names=train_ds.class_names\nclass_count=len(class_names)\nplt.figure(figsize=(20,20))\nfor images, labels in test_ds.take(1):\n    for i in range (25):\n        plt.subplot(5,5,i +1)\n        img=images[i]\/255  \n        plt.title(class_names[labels[i]], color='blue', fontsize=12)\n        plt.imshow(img)\n    plt.show()\n","337ac53d":"input=Input(shape=img_shape)\nx=tf.keras.applications.EfficientNetB3(include_top=False, weights=\"imagenet\", pooling='max')(input) \nx=tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\nx = Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n                bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\nx=Dropout(rate=.4, seed=123)(x)        \noutput=Dense(class_count, activation='softmax')(x)\nmodel=Model(inputs=input, outputs=output)\nmodel.compile(Adamax(lr=.001), loss='sparse_categorical_crossentropy', metrics=['accuracy']) ","e8e7a408":"rlronp=tf.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.5,  patience=1, verbose=1)\nepochs=10\nhistory=model.fit( train_ds, validation_data=valid_ds, epochs=epochs, verbose=1, callbacks=[rlronp])\n  ","fe6416ef":"ypred=[]\nerrors=0\ncount=0\npreds=model.predict(test_ds, verbose=1)\nfor i, p in enumerate(preds):\n    count +=1\n    index=np.argmax(p)\n    klass=class_names[index] \n    ypred.append(klass)  \n    if klass != ytrue[i]:\n        errors +=1\nacc= (count-errors)* 100\/count\nmsg=f'there were {count-errors} correct predictions in {count} tests for an accuracy of {acc:6.2f} % '\nprint (msg)\nypred=np.array(ypred)\nytrue=np.array(ytrue)\nclr = classification_report(ytrue, ypred, target_names=class_names)\nprint(\"Classification Report:\\n----------------------\\n\", clr)    ","cd0be857":"imgpath=r'..\/input\/butterfly-images40-species\/butterflies_rev2\/test\/adonis\/2.jpg'\nimg= plt.imread(imgpath)\nsimg=img\/255.0\nimg=cv2.resize(img, img_size)\nimg=np.expand_dims(img, axis=0)\npreds=model.predict(img)\nindex=np.argmax(preds[0])\nklass= class_names[index]\nplt.axis('off')\nplt.title(klass, color='blue', fontsize=14)\nplt.imshow(simg)\nprint('for image file ', imgpath, ' predicted class is ', klass, ' with probability ', preds[0][index]* 100, '%')","4190547a":"### create the Datasets","b8a7e9a9":"### make a prediction on a single image using the trained model","c576bdc7":"### given the dataset is not balanced and images were not augmented the results are rather good","eddd8624":"### define the directories ","c3e3d393":"### make predictions on test set, compute accuracy and create classification report","58823852":"### show some test images- Note with shuffle=False the test file order is preserved","5db34a5c":"### create the model, include image augmentation layers"}}