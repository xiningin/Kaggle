{"cell_type":{"86f0b0e7":"code","810ce95d":"code","6e04990d":"code","56e9a4ba":"code","0f824cb4":"code","cc7a769b":"code","2e1347b2":"code","f082f48e":"code","f0f77fc1":"code","20153178":"code","a56210d9":"code","5095dfa4":"code","12e862a5":"code","5d688ca3":"code","85073c07":"code","35c40b35":"code","448da6d5":"code","a8ef9d34":"code","52c1c19f":"code","a6aab008":"code","1e2bf15a":"code","46fd3e3d":"code","0a0f7c8b":"code","db2605b4":"code","f23c775b":"code","ed222af5":"code","40259eb7":"code","f0e0028a":"code","90a9b446":"code","43a8966e":"code","d16f95d7":"code","f11844af":"code","dcf92f5a":"code","3beea49a":"code","f664b7ab":"code","0c369771":"code","5e63beaf":"code","d986c381":"code","1735e41d":"code","defb82a5":"code","b91ee491":"code","1deecd01":"code","72788379":"code","96955811":"code","d8e822b7":"code","f0e8cfe6":"code","f89cbb25":"code","8821f0b2":"code","f396725c":"code","bf89930a":"code","7431ac52":"code","0ccadf69":"code","ba8a2944":"code","1764a92d":"code","3cf45ab2":"code","73316a69":"code","5cf9e0d9":"code","627bbfca":"code","3a886d68":"code","659d51c0":"code","8df0412e":"code","73fb19da":"code","b74b6899":"code","7ac10f79":"code","d32f19ca":"code","459403fe":"code","f1f54df1":"code","3d21e5a7":"code","dd4e9697":"code","f42dc109":"code","9db0e5d7":"code","e137eda3":"code","f00e51b0":"code","f7b47e32":"code","2662f07b":"code","0a3f66a2":"code","168eb4d0":"code","1b4a1b60":"code","419d2afc":"code","c9a11461":"code","79310bd4":"code","0bf8fed1":"code","b6459f1a":"code","0e77b7eb":"code","71403b57":"code","e4a5714d":"code","47286b7e":"code","495c1e73":"code","2a42b6ab":"code","8eca6e45":"code","e86175e2":"code","af4bac88":"code","eacfedc2":"code","ab43013d":"markdown","f51fdc54":"markdown","9720d4a5":"markdown","428c28ef":"markdown","f0acc525":"markdown","59e4ec8b":"markdown","1f6fe4e4":"markdown","93ff9a2d":"markdown","c96b3521":"markdown","4090a8f1":"markdown","c8f9c03b":"markdown","5f2cc4e0":"markdown","1135c073":"markdown","10b8a688":"markdown","d7aa794d":"markdown","90065fca":"markdown","dc212494":"markdown","eb5f7a9d":"markdown","cf7c13f1":"markdown","cb208ca4":"markdown","be3c5bfe":"markdown","02b738a8":"markdown"},"source":{"86f0b0e7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","810ce95d":"train_df = pd.read_csv(\"..\/input\/rossmann-store-sales\/train.csv\", low_memory=False)\nstore_df = pd.read_csv(\"..\/input\/rossmann-store-sales\/store.csv\")\n","6e04990d":"test_df = pd.read_csv(\"..\/input\/rossmann-store-sales\/test.csv\")\nsubmission_df = pd.read_csv(\"..\/input\/rossmann-store-sales\/sample_submission.csv\")","56e9a4ba":"train_df","0f824cb4":"store_df","cc7a769b":"test_df","2e1347b2":"submission_df","f082f48e":"\nmerged_df=train_df.merge(store_df,how='left',on='Store')\nmerged_test_df=test_df.merge(store_df,how='left',on='Store')","f0f77fc1":"merged_df","20153178":"merged_test_df","a56210d9":"merged_df.info()","5095dfa4":"def split_date(df):\n    df['Date'] = pd.to_datetime(df['Date'])\n    df['Year'] = df.Date.dt.year\n    df['Month'] = df.Date.dt.month\n    df['Day'] = df.Date.dt.day\n    df['WeekOfYear_x'] = df.Date.dt.isocalendar().week","12e862a5":"split_date(merged_df)\nsplit_date(merged_test_df)","5d688ca3":"merged_df","85073c07":"merged_df.info()","35c40b35":"merged_test_df","448da6d5":"merged_df.Open.value_counts()","a8ef9d34":"merged_df=merged_df[merged_df['Open']==1].copy()\n#merged_test_df=merged_test_df[merged_test_df['Open']==1].copy()","52c1c19f":"merged_df","a6aab008":"merged_test_df","1e2bf15a":"def comp_months(df):\n    df['CompetitionOpen'] = 12 * (df.Year - df.CompetitionOpenSinceYear) + (df.Month - df.CompetitionOpenSinceMonth)\n    df['CompetitionOpen'] = df['CompetitionOpen'].map(lambda x: 0 if x < 0 else x).fillna(0)","46fd3e3d":"comp_months(merged_df)\ncomp_months(merged_test_df)","0a0f7c8b":"merged_df[['Date', 'CompetitionDistance', 'CompetitionOpenSinceYear', 'CompetitionOpenSinceMonth', 'CompetitionOpen']].sample(20)","db2605b4":"merged_df=merged_df.rename(columns={\"WeekOfYear_x\":\"WeekOfYear\"})\nmerged_test_df=merged_test_df.rename(columns={\"WeekOfYear_x\":\"WeekOfYear\"})\n\nmerged_df.info()","f23c775b":"def check_promo_month(row):\n    month2str = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun',              \n                 7:'Jul', 8:'Aug', 9:'Sept', 10:'Oct', 11:'Nov', 12:'Dec'}\n    try:\n        months = (row['PromoInterval'] or '').split(',')\n        if row['Promo2Open'] and month2str[row['Month']] in months:\n            return 1\n        else:\n            return 0\n    except Exception:\n        return 0\n\ndef promo_cols(df):\n    # Months since Promo2 was open\n    df['Promo2Open'] = 12 * (df.Year - df.Promo2SinceYear) +  (df.WeekOfYear- df.Promo2SinceWeek)*7\/30.5\n    df['Promo2Open'] = df['Promo2Open'].map(lambda x: 0 if x < 0 else x).fillna(0) * df['Promo2']\n    # Whether a new round of promotions was started in the current month\n    df['IsPromo2Month'] = df.apply(check_promo_month, axis=1) * df['Promo2']","ed222af5":"promo_cols(merged_df)\npromo_cols(merged_test_df)","40259eb7":"merged_df.columns","f0e0028a":"input_cols=['Store', 'DayOfWeek', 'Promo', 'StateHoliday', 'SchoolHoliday', \n              'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpen', \n              'Day', 'Month', 'Year', 'WeekOfYear',  'Promo2', \n              'Promo2Open', 'IsPromo2Month']\ntarget_col=['Sales']","90a9b446":"input_x=merged_df[input_cols].copy()\ntarget_x=merged_df[target_col].copy()","43a8966e":"input_test=merged_test_df[input_cols].copy()","d16f95d7":"input_x","f11844af":"input_x.info()","dcf92f5a":"numeric_cols = ['Store', 'Promo', 'SchoolHoliday', \n              'CompetitionDistance', 'CompetitionOpen', 'Promo2', 'Promo2Open', 'IsPromo2Month',\n              'Day', 'Month', 'Year', 'WeekOfYear',  ]\ncategorical_cols = ['DayOfWeek', 'StateHoliday', 'StoreType', 'Assortment']","3beea49a":"input_x[numeric_cols].isna().sum()","f664b7ab":"input_test[numeric_cols].isna().sum()","0c369771":"max_distance=input_x['CompetitionDistance'].max()\nmax_distance","5e63beaf":"input_x['CompetitionDistance'].fillna(max_distance, inplace=True)\ninput_test['CompetitionDistance'].fillna(max_distance, inplace=True)","d986c381":"from sklearn.preprocessing import MinMaxScaler","1735e41d":"scaler = MinMaxScaler().fit(input_x[numeric_cols])","defb82a5":"input_x[numeric_cols] = scaler.transform(input_x[numeric_cols])\ninput_test[numeric_cols] = scaler.transform(input_test[numeric_cols])","b91ee491":"from sklearn.preprocessing import OneHotEncoder","1deecd01":"encoder = OneHotEncoder(sparse=False, handle_unknown='ignore').fit(input_x[categorical_cols])\nencoded_cols = list(encoder.get_feature_names(categorical_cols))","72788379":"input_x[encoded_cols] = encoder.transform(input_x[categorical_cols])\ninput_test[encoded_cols] = encoder.transform(input_test[categorical_cols])","96955811":"X = input_x[numeric_cols + encoded_cols]\nX_test = input_test[numeric_cols + encoded_cols]","d8e822b7":"X_test","f0e8cfe6":"from xgboost import XGBRegressor","f89cbb25":"model = XGBRegressor(random_state=42, n_jobs=-1, n_estimators=1500, max_depth=5)","8821f0b2":"%%time\nmodel.fit(X, target_x)","f396725c":"pred=model.predict(X)\npred","bf89930a":"test_preds = model.predict(X_test)\ntest_preds","7431ac52":"submission_df['Sales']  = test_preds","0ccadf69":"submission_df.to_csv('submission.csv', index=None)","ba8a2944":"model","1764a92d":"from sklearn.metrics import mean_squared_error\n\ndef rmse(a, b):\n    return mean_squared_error(a, b, squared=False)","3cf45ab2":"rmse(pred, target_x)","73316a69":"importance_df = pd.DataFrame({\n    'feature': X.columns,\n    'importance': model.feature_importances_\n}).sort_values('importance', ascending=False)","5cf9e0d9":"importance_df.head()","627bbfca":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10,6))\nplt.title('Feature Importance')\nsns.barplot(data=importance_df.head(10), x='importance', y='feature');","3a886d68":"from sklearn.model_selection import KFold","659d51c0":"def train_and_evaluate(X_train, train_targets, X_val, val_targets, **params):\n    model = XGBRegressor(random_state=42, n_jobs=-1, **params)\n    model.fit(X_train, train_targets)\n    train_rmse = rmse(model.predict(X_train), train_targets)\n    val_rmse = rmse(model.predict(X_val), val_targets)\n    return model, train_rmse, val_rmse","8df0412e":"kfold = KFold(n_splits=5)","73fb19da":"models = []\n\nfor train_idxs, val_idxs in kfold.split(X):\n    X_train, train_targets = X.iloc[train_idxs], target_x.iloc[train_idxs]\n    X_val, val_targets = X.iloc[val_idxs], target_x.iloc[val_idxs]\n    model, train_rmse, val_rmse = train_and_evaluate(X_train, \n                                                     train_targets, \n                                                     X_val, \n                                                     val_targets, \n                                                     max_depth=5, \n                                                     n_estimators=15)\n    models.append(model)\n    print('Train RMSE: {}, Validation RMSE: {}'.format(train_rmse, val_rmse))","b74b6899":"def test_params_kfold(n_splits, **params):\n    train_rmses, val_rmses, models = [], [], []\n    kfold = KFold(n_splits)\n    for train_idxs, val_idxs in kfold.split(X):\n        X_train, train_targets = X.iloc[train_idxs], targets.iloc[train_idxs]\n        X_val, val_targets = X.iloc[val_idxs], targets.iloc[val_idxs]\n        model, train_rmse, val_rmse = train_and_evaluate(X_train, train_targets, X_val, val_targets, **params)\n        models.append(model)\n        train_rmses.append(train_rmse)\n        val_rmses.append(val_rmse)\n    print('Train RMSE: {}, Validation RMSE: {}'.format(np.mean(train_rmses), np.mean(val_rmses)))\n    return models","7ac10f79":"from sklearn.model_selection import train_test_split","d32f19ca":"X_train, X_val, train_targets, val_targets = train_test_split(X, target_x, test_size=0.1)","459403fe":"def test_params(**params):\n    model = XGBRegressor(n_jobs=-1, random_state=42, **params)\n    model.fit(X_train, train_targets)\n    train_rmse = rmse(model.predict(X_train), train_targets)\n    val_rmse = rmse(model.predict(X_val), val_targets)\n    print('Train RMSE: {}, Validation RMSE: {}'.format(train_rmse, val_rmse))","f1f54df1":"?XGBRegressor","3d21e5a7":"model","dd4e9697":"test_params(max_depth=12)","f42dc109":"test_params(max_depth=8)","9db0e5d7":"test_params(max_depth=4)","e137eda3":"test_params(max_depth=14)","f00e51b0":"test_params(max_depth=13)","f7b47e32":"test_params(max_depth=5)","2662f07b":"test_params(learning_rate=0.4)","0a3f66a2":"test_params(learning_rate=0.8)","168eb4d0":"test_params(learning_rate=0.2)","1b4a1b60":"test_params(learning_rate=0.99)","419d2afc":"test_params (n_estimators=15)","c9a11461":"test_params(n_estimators=10)","79310bd4":"test_params (n_estimators=505)","0bf8fed1":"test_params (n_estimators=1000)","b6459f1a":"test_params (n_estimators=1500)","0e77b7eb":"model","71403b57":"model = XGBRegressor(n_jobs=-1, random_state=42, n_estimators=1500, \n                     learning_rate=0.99, max_depth=5, subsample=0.9, \n                     colsample_bytree=0.7)","e4a5714d":"%%time\nmodel.fit(X, target_x)","47286b7e":"pred=model.predict(X)","495c1e73":"rmse(pred,target_x)","2a42b6ab":"test_preds = model.predict(X_test)\ntest_preds","8eca6e45":"submission_df['Sales']  = test_preds","e86175e2":"submission_df","af4bac88":"##Save as csv\nsubmission_df.to_csv('submission.csv', index=None)","eacfedc2":"model","ab43013d":"## Additional Promotion\nWe can also add some additional columns to indicate how long a store has been running Promo2 and whether a new round of Promo2 starts in the current month.","f51fdc54":"### Feature importance\n\nJust like decision trees and random forests, XGBoost also provides a feature importance score for each column in the input.","9720d4a5":"#sure we need store open not close one to training model","428c28ef":"Here's a helper function to test hyperparameters with K-fold cross validation.","f0acc525":"# Enhancement Model By Hyperparameter Tuning and Regularization","59e4ec8b":"### only null with competiton distance , we will try to fill  with max distanceas far away from compatitor","1f6fe4e4":"## Check which cols have numeric and which categorical","93ff9a2d":"### Transfer data type for date and splite year ,month , day, weeks number","c96b3521":"## Competition\nNext, we can use the columns CompetitionOpenSince[Month\/Year] columns from store_df to compute the number of months for which a competitor has been open near the store.","4090a8f1":"## Merge store data with train and test data according to store number","c8f9c03b":"# Training Model\n## Gradient Boosting\n","5f2cc4e0":"### Prediction\n","1135c073":"### Impute missing numerical data","10b8a688":"Let's define a helper function `train_and_evaluate` which trains a model the given parameters and returns the trained model, training error and validation error.","d7aa794d":"### Scale Numeric Values\n\nLet's scale numeric values to the 0 to 1 range.","90065fca":"### Evaluation\n\nLet's evaluate the predictions using RMSE error.","dc212494":"let's to put all numeric data in one data frame","eb5f7a9d":"### Try to fill Null with max distance","cf7c13f1":"### after training with chossen parameters and fitting model","cb208ca4":"### Encode Categorical Columns\n","be3c5bfe":"## Let's add the predictions into `submission_df`.","02b738a8":"## Preprocessing and Feature Engineering\n"}}