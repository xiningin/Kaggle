{"cell_type":{"5dca4762":"code","433eebda":"code","82a66062":"code","f3a2c297":"code","d855d0fc":"code","fd2f48ad":"code","42d2a239":"code","2329f988":"code","41b14afe":"code","a3873f98":"code","9b7d603a":"code","7e69d12d":"code","15e6c514":"code","c078b04a":"code","6621f22e":"code","81394065":"code","43265454":"code","2b2bceb6":"code","8ae423d2":"code","10007a63":"code","075dd648":"code","1c2c5f52":"code","b1b08730":"code","2a3f6e83":"code","36d943a4":"code","c85d5199":"code","dfcc0aba":"code","7aee16e9":"code","f8e721ac":"code","4645f1c0":"code","e04461ce":"code","95d8e23c":"code","c96e1670":"code","6cea1070":"code","d07fafec":"code","16fd45d7":"code","92fbbaca":"code","839ce38d":"code","9372e44e":"markdown","fb0d7b27":"markdown","70f9ddb2":"markdown","326ace27":"markdown","d56450c9":"markdown","43913748":"markdown","fa1c74a8":"markdown","6231fea6":"markdown","96d12bd0":"markdown","2b6c72cf":"markdown","0f525b87":"markdown","1a7a8e93":"markdown","2f4d4060":"markdown","ab33b9bc":"markdown","d5503ee3":"markdown","82c338f3":"markdown","661d360d":"markdown","e358a635":"markdown","c31ead9f":"markdown","9fd13601":"markdown","faaf3868":"markdown","79cf0d53":"markdown","57c84283":"markdown","aa9920a8":"markdown","4d957a6c":"markdown","032d58c8":"markdown"},"source":{"5dca4762":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport re\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\npd.set_option('display.max_columns', None)","433eebda":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n\n# Storing the passenger_ids for submission\npassenger_ids = test_df['PassengerId']","82a66062":"train_df.head()","f3a2c297":"test_df.head()","d855d0fc":"train_df['Survived'].value_counts()","fd2f48ad":"train_df.info()","42d2a239":"test_df.info()","2329f988":"train_df.describe()","41b14afe":"test_df.describe()","a3873f98":"def hist_survived_vs_feature(feature, df=train_df, labels={}):\n\n    survived_mapping = df['Survived'].map({0: 'Dead', 1: 'Survived'})\n\n    fig = px.histogram(df, x=survived_mapping, width=800, color=feature, labels=labels)\n    fig.update_layout(\n        bargap=0.2,\n        xaxis_title_text='Survived',\n        yaxis_title_text='Survived count'\n    )\n    \n    return fig\n\nhist_survived_vs_feature('Pclass')","9b7d603a":"hist_survived_vs_feature('Sex')","7e69d12d":"fig = px.histogram(train_df, x='Age', color='Survived', barmode='overlay')\nfig","15e6c514":"hist_survived_vs_feature('SibSp')","c078b04a":"hist_survived_vs_feature('Parch')","6621f22e":"fig = px.histogram(train_df, x='Fare', color='Survived', barmode='overlay')\nfig","81394065":"df = train_df[train_df['Cabin'].notnull()]\ncabin_initials = df['Cabin'].map(lambda x: x[0])\n\nhist_survived_vs_feature(cabin_initials, df=df, labels={'color': 'cabin'})","43265454":"df = train_df[train_df['Embarked'].notnull()]\nhist_survived_vs_feature('Embarked', df=df)","2b2bceb6":"train_df.columns","8ae423d2":"# Combining the train and test data into a single dataset\ndataset = [train_df, test_df]\n\n# Preprocessing feature 'Name'\n\nfor df in dataset:\n    # Extracting title\n    df['Title'] = df['Name'].map(lambda x: re.search(r' ([A-Za-z]+)\\.', x).group().strip().replace('.', ''))\n\n# Unique titles in train data\ntrain_df['Title'].value_counts().index","10007a63":"# # Unique titles in test data\n\ntest_df['Title'].value_counts().index","075dd648":"# Mapping Mr, Miss, Mrs, Master and rest to numerical values\ntitle_mapping = {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Dr': 5, 'Rev': 5, 'Col': 5,\n                 'Major': 5, 'Mlle': 5, 'Ms': 5, 'Countess': 5, 'Lady': 5, 'Capt': 5,\n                 'Jonkheer': 5, 'Don': 5, 'Sir': 5, 'Mme': 5}\n\nfor df in dataset:\n    df['Title'] = df['Title'].map(title_mapping)\n\ntrain_df.head()","1c2c5f52":"def concat_dummies(feature_name):\n    global dataset\n    \n    new_train_df = pd.concat([train_df, pd.get_dummies(train_df[feature_name], prefix=feature_name)], axis=1)\n    new_test_df = pd.concat([test_df, pd.get_dummies(test_df[feature_name], prefix=feature_name)], axis=1)\n    dataset = [new_train_df, new_test_df]\n    \n    return new_train_df, new_test_df","b1b08730":"# Concatenating the one-hot encoded values with the train and test dataframes\ntrain_df, test_df = concat_dummies('Title')\n\ntrain_df.head()","2a3f6e83":"# Preprocessing feature 'Sex'\n\nsex_mapping = {'male': 0, 'female': 1}\n\nfor df in dataset:\n    df['Sex'] = df['Sex'].map(sex_mapping)\n    \ntrain_df.head()","36d943a4":"# Preprocessing feature 'Age'\n\nage_bins = [0, 5.99, 11.9, 17.9, 25.9, 47.9, 61.9, 80]\nage_labels = [i for i in range(1, 8)]\n\nfor df in dataset:\n    # Filling the missing values in each dataset with median of corresponding 'Title' feature\n    df['Age'] = df['Age'].fillna(df.groupby('Title')['Age'].transform('median'))\n    df['AgeGroup'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels)\n\ntrain_df.head()","c85d5199":"# Concatenating the one-hot encoded values with the train and test dataframes\ntrain_df, test_df = concat_dummies('AgeGroup')\n\ntrain_df.head()","dfcc0aba":"# Preprocessing features 'Parch' and 'SipSp'\n\ndef scale_feature(feature):\n    result = []\n    \n    # Applying min-max scaling to the 'Parch' and 'SipSp' features\n    for df in dataset:\n        feature_val = df[feature]\n        max_val = feature_val.max()\n        min_val = feature_val.min()\n        scaled_feature = (feature_val - min_val) \/ (max_val - min_val)\n        result.append(scaled_feature)\n        \n    return result\n\ntrain_df['SibSp'], test_df['SibSp'] = scale_feature('SibSp')\ntrain_df['Parch'], test_df['Parch'] = scale_feature('Parch')\n\ntrain_df.head()","7aee16e9":"# Preprocessing feature 'Fare'\n\n# Filling the missing values with the median of the corresponding passenger class\ntest_df['Fare'] = test_df['Fare'].fillna(test_df.groupby('Pclass')['Fare'].transform('median'))\ntrain_df['Fare'], test_df['Fare'] = scale_feature('Fare')\n\ntrain_df.head()","f8e721ac":"# Preprocessing feature 'Embarked'\n\n# Visualizing the count of passenger's embarkment across different passenger classes using bar chart\ndf = train_df[train_df['Embarked'].notnull()]\nclass_count = df.groupby(['Pclass', 'Embarked'])['Embarked'].count()\nC_count = class_count.loc[([1, 2, 3], 'C')]\nQ_count = class_count.loc[([1, 2, 3], 'Q')]\nS_count = class_count.loc[([1, 2, 3], 'S')]\n\np_class = [1, 2, 3]\nfig = go.Figure()\nfig.add_trace(go.Bar(x=p_class, y=C_count.tolist(), name='C'))\nfig.add_trace(go.Bar(x=p_class, y=Q_count.tolist(), name='Q'))\nfig.add_trace(go.Bar(x=p_class, y=S_count.tolist(), name='S'))\nfig.update_layout(\n    barmode='stack',\n    xaxis_title_text='Passenger class',\n    yaxis_title_text='Embarked station count'\n)\nfig.show()\n\n# Getting the same figure using histogram\nfig = px.histogram(df, x='Pclass', color='Embarked')\nfig.update_layout(\n    bargap=0.2,\n    xaxis_title_text='Passenger class',\n    yaxis_title_text='Embarked station count'\n)","4645f1c0":"# Filling the missing values with 'S' station as it covers 50% of the count on each class\ntrain_df['Embarked'] = train_df['Embarked'].fillna('S')\n# Concatenating the one-hot encoded values with the train and test dataframes\ntrain_df, test_df = concat_dummies('Embarked')\n\ntrain_df.head()","e04461ce":"# Dropping unwanted columns\ntrain_df = train_df.drop(['PassengerId', 'Name', 'Age', 'Ticket', 'Cabin', 'Embarked',\n                          'Title', 'AgeGroup'], axis=1)\ntest_df = test_df.drop(['PassengerId', 'Name', 'Age', 'Ticket', 'Cabin', 'Embarked',\n                          'Title', 'AgeGroup'], axis=1)\n\ntrain_df.head()","95d8e23c":"test_df.head()","c96e1670":"X = train_df.iloc[:, 1:].values\ny = train_df['Survived'].values\n\n# Splitting the train data into train and validation sets \nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1)\nX_test = test_df.values","6cea1070":"print(f'Shape of X_train: {X_train.shape}')\nprint(f'Shape of X_test: {X_val.shape}')\nprint(f'Shape of y_train: {y_train.shape}')\nprint(f'Shape of y_test: {y_val.shape}')","d07fafec":"# Building a Keras sequential model for the binary classification problem\nmodel = tf.keras.Sequential()\n# Adding dropout layer to avoid overfitting the train data\nmodel.add(tf.keras.layers.Dropout(0.25, input_shape=[20]))\nmodel.add(tf.keras.layers.Dense(25, activation='relu'))\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n\n# Using Adam optimizer with custom learning rate\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\nmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\nmodel.summary()","16fd45d7":"# Training the model for 10 epochs\nhistory = model.fit(\n    x=X_train,\n    y=y_train,\n    epochs=10,\n    batch_size=1,\n    validation_data=(X_val, y_val)\n)","92fbbaca":"# Predicting 'Survived' for test data\nprediction = model.predict(X_test)\n# Rounding the predictions to either 0 or 1\nrounded_prediction = np.where(prediction >= 0.5, 1, 0).flatten()\n\n# Creating a dataframe for submission\nsubmission_df = pd.DataFrame({\n    'PassengerId': passenger_ids,\n    'Survived': rounded_prediction\n})\n\nsubmission_df.head()","839ce38d":"# Outputting the dataframe as a CSV file for submission\nsubmission_df.to_csv('submission.csv', index=False)","9372e44e":"**Creating an histogram for Survived with respect to Sex**","fb0d7b27":"**Note: Passenger class is not one-hot encoded to maintain the ordinality of the feature**","70f9ddb2":"## Modelling","326ace27":"## Visualization","d56450c9":"**Scaling the parent\/children count and sibling\/spouse count to 0 - 1**","43913748":"**Getting the count of missing values of each feature in train data**","fa1c74a8":"**Creating an histogram for Survived with respect to Age**","6231fea6":"**Creating an histogram for Survived with respect to Cabin**","96d12bd0":"**Binning Age feature based on the trend in histogram and one-hot encoding them**\n\n* 0 - 5: Age Group 1\n* 6 - 11: Age Group 2\n* 12 - 17: Age Group 3\n* 18 - 25: Age Group 4\n* 26 - 47: Age Group 5\n* 48 - 61: Age Group 6\n* 61 - 80: Age Group 7","2b6c72cf":"**Encoding the passenger gender to numerical values**","0f525b87":"**Creating an histogram for Survived with respect to Passenger class **","1a7a8e93":"**One-hot encoding the embarked station**","2f4d4060":"**Creating an histogram for Survived with respect to Fare**","ab33b9bc":"**Extracting the titles from passenger names and one-hot encoding them**","d5503ee3":"**Scaling the passenger fare to 0 - 1**","82c338f3":"**Applying some statistical functions on train data**","661d360d":"**Exploring test data**","e358a635":"**Applying some statistical functions on test data**","c31ead9f":"**Creating an histogram for Survived with respect to Embarked station**","9fd13601":"**Getting the count of missing values of each feature in test data**","faaf3868":"## Feature Engineering","79cf0d53":"**Creating an histogram for Survived with respect to Sibling and Spouse count**","57c84283":"**Creating an histogram for Survived with respect to Parent and Children count**","aa9920a8":"**Getting the counts of survived and dead**","4d957a6c":"## Data Analysis","032d58c8":"**Exploring train data**"}}