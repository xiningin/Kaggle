{"cell_type":{"354bb860":"code","74f4a3b0":"code","3f8fce08":"code","664e0f72":"code","5309bac3":"code","202dfdb4":"code","0bad1152":"code","a57916cc":"code","d6b42350":"code","859fc1c7":"code","e21378bd":"code","5190b6ee":"code","3f001c6e":"code","c78a464a":"code","40c008f8":"code","8107433e":"code","a6caf1cc":"code","c47ec807":"code","1a2578da":"code","4ae41a2f":"code","e5e17566":"code","725dd494":"code","eb7bbb66":"code","2d2c2b43":"code","ae769ff5":"code","8ddf29b6":"code","a70db736":"code","f37a4bba":"code","560fbb43":"code","07a0c942":"code","dd6fa05e":"code","90ff4034":"code","9da628f9":"code","5267de21":"code","1dda0540":"code","87695ed0":"code","b554188f":"code","43bacc99":"code","a5f1c342":"code","0279af2a":"code","8537eff8":"markdown","7ab5b6a7":"markdown","6d8a5c70":"markdown","5cb5612d":"markdown","fed45cbf":"markdown","549507d4":"markdown","3de3bd7f":"markdown","b9030c32":"markdown","c42f10cd":"markdown","dfb535aa":"markdown","2985cd35":"markdown","2f440a40":"markdown","18814840":"markdown","fdeaa1cd":"markdown","2e415f60":"markdown","84e3bc2c":"markdown","a34fcada":"markdown","114a727b":"markdown","760a39a7":"markdown","3cf4818d":"markdown","80e4b89b":"markdown","b208c572":"markdown"},"source":{"354bb860":"!pip install dataprep","74f4a3b0":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.decomposition import PCA\n\nfrom dataprep.eda import create_report\nfrom dataprep.eda import plot_missing\nfrom dataprep.eda import plot_correlation\nfrom dataprep.eda import plot\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report, roc_curve\nfrom sklearn.model_selection import learning_curve, cross_val_score, GridSearchCV\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import RobustScaler,StandardScaler,MinMaxScaler\n\nimport warnings\nwarnings.filterwarnings('ignore')","3f8fce08":"data = pd.read_csv('..\/input\/predict-diabetes-based-on-diagnostic-measures\/diabetes.csv',decimal=\",\")\ndf = data.copy()\npd.set_option('display.max_row',df.shape[0])\npd.set_option('display.max_column',df.shape[1]) \ndf.head()","664e0f72":"plot_missing(df)","5309bac3":"print('There is' , df.shape[0] , 'rows')\nprint('There is' , df.shape[1] , 'columns')","202dfdb4":"# Eliminate duplicates\nprint('There are' , df.duplicated().sum() , 'duplicates')\ndf.loc[df.duplicated(keep=False),:]\ndf.drop_duplicates(keep='first',inplace=True)\nprint('There is now' , df.shape[0] , 'rows')\nprint('There is now' , df.shape[1] , 'columns')","0bad1152":"create_report(df)","a57916cc":"df['diabetes'].value_counts(normalize=True) #Classes d\u00e9s\u00e9quilibr\u00e9es","d6b42350":"for col in df.select_dtypes(\"object\"):\n    print(f'{col :-<50} {df[col].unique()}')","859fc1c7":"df=data.copy()\npd.set_option('display.max_row',df.shape[0])\npd.set_option('display.max_column',df.shape[1]) \ndf.head()","e21378bd":"def encoding(df):\n    code = {'female':1,\n            'male':0,\n            'No diabetes':1,\n            'Diabetes':0\n           }\n    for col in df.select_dtypes('object'):\n        df.loc[:,col]=df[col].map(code)        \n    return df\n\ndef imputation(df):\n    df = df.dropna(axis=0)\n    return df\n\ndef feature_engineering(df):\n    useless_columns = ['patient_number']\n    df = df.drop(useless_columns,axis=1)\n    return df\n\ndef preprocessing(df):\n    df = encoding(df)\n    df = feature_engineering(df)\n    df = imputation(df)\n    \n    X = df.drop('diabetes',axis=1)\n    y = df['diabetes']    \n\n    return df,X,y","5190b6ee":"df,_,_ = preprocessing(df)\ndf.head()","3f001c6e":"corr = df.corr(method='pearson').abs()\n\nfig = plt.figure(figsize=(8,6))\nsns.heatmap(corr, annot=True, cmap='tab10', vmin=-1, vmax=+1)\nplt.title('Pearson Correlation')\nplt.show()\n\nprint (df.corr()['diabetes'].abs().sort_values())","c78a464a":"df = data.copy()\ndf,X,y=preprocessing(df)\ndf['diabetes'].value_counts(normalize=True) #Classes d\u00e9s\u00e9quilibr\u00e9es","40c008f8":"# Class count\ncount_class_0, count_class_1 = df['diabetes'].value_counts()\n\n# Divide by class\ndf_class_0 = df[df['diabetes'] == 1]\ndf_class_1 = df[df['diabetes'] == 0]\n\nprint(count_class_0)\nprint(count_class_1)","8107433e":"df_class_0_under = df_class_0.sample(count_class_1,random_state=42)\ndf_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n\nprint('Random under-sampling:')\nprint(df_under['diabetes'].value_counts())\n\ndf_under['diabetes'].value_counts().plot(kind='bar', title='Count (target)');","a6caf1cc":"trainset, testset = train_test_split(df_under, test_size=0.2, random_state=42)\nprint(trainset['diabetes'].value_counts())\nprint(testset['diabetes'].value_counts())","c47ec807":"X_train = trainset.drop(['diabetes'],axis=1)\ny_train = trainset['diabetes']\nX_test = testset.drop(['diabetes'],axis=1)\ny_test = testset['diabetes']","1a2578da":"preprocessor = make_pipeline(MinMaxScaler())\n\nPCAPipeline = make_pipeline(StandardScaler(), PCA(n_components=3,random_state=42))\n\nRandomPipeline = make_pipeline(preprocessor,RandomForestClassifier(random_state=42))\nAdaPipeline = make_pipeline(preprocessor,AdaBoostClassifier(random_state=42))\nSVMPipeline = make_pipeline(preprocessor,SVC(random_state=42,probability=True))\nKNNPipeline = make_pipeline(preprocessor,KNeighborsClassifier())\nLRPipeline = make_pipeline(preprocessor,LogisticRegression(solver='sag',random_state=42))","4ae41a2f":"PCA_df = pd.DataFrame(PCAPipeline.fit_transform(X))\nPCA_df = pd.concat([PCA_df, y], axis=1)\nPCA_df.head()","e5e17566":"plt.figure(figsize=(8,8))\nsns.scatterplot(PCA_df[0],PCA_df[1],hue=PCA_df['diabetes'],palette=sns.color_palette(\"tab10\", 2))\nplt.show()","725dd494":"import plotly.express as px\nfigure1 = px.scatter_3d(PCA_df,\n        x=0, \n        y=1, \n        z=2, \n        color = 'diabetes',\n                       width=600, height=800)\nfigure1.update_traces(marker=dict(size=5,\n                              line=dict(width=0.2,\n                                        color='DarkSlateGrey')),\n                  selector=dict(mode='markers'))\n\nfigure1.show()","eb7bbb66":"dict_of_models = {'RandomForest': RandomPipeline,\n'AdaBoost': AdaPipeline,\n'SVM': SVMPipeline,\n'KNN': KNNPipeline,\n'LR': LRPipeline}","2d2c2b43":"def evaluation(model):\n    model.fit(X_train, y_train)\n    # calculating the probabilities\n    y_pred_proba = model.predict_proba(X_test)\n\n    # finding the predicted valued\n    y_pred = np.argmax(y_pred_proba,axis=1)\n    print('Accuracy = ', accuracy_score(y_test, y_pred))\n    print('-')\n    print(confusion_matrix(y_test,y_pred))\n    print('-')\n    print(classification_report(y_test,y_pred))\n    print('-')\n    \n    N, train_score, test_score = learning_curve(model, X_train, y_train, \n                                               cv=4, scoring='f1', \n                                               train_sizes=np.linspace(0.1,1,10))\n    plt.figure(figsize=(5,5))\n    plt.plot(N, train_score.mean(axis=1), label='train score')\n    plt.plot(N, test_score.mean(axis=1), label='validation score')\n    plt.legend()\n    plt.show()","ae769ff5":"for name, model in dict_of_models.items():\n    print('---------------------------------')\n    print(name)\n    evaluation(model)","8ddf29b6":"RandomPipeline.fit(X_train, y_train)\ny_proba = RandomPipeline.predict_proba(X_test)\ny_pred = np.argmax(y_proba,axis=1)\nprint(\"RandomForest : \", accuracy_score(y_test, y_pred))","a70db736":"y_pred_prob = RandomPipeline.predict_proba(X_test)[:,1]\n\nfpr,tpr,threshols=roc_curve(y_test,y_pred_prob)\n\nplt.plot(fpr,tpr,label='RandomForest ROC Curve')\nplt.xlabel(\"False Survivor Rate\")\nplt.ylabel(\"True SurvivorR Rate\")\nplt.title(\"andomForest ROC Curve\")\nplt.show()","f37a4bba":"from sklearn.model_selection import RandomizedSearchCV\nRandomPipeline.get_params().keys()","560fbb43":"hyper_params = {\n    'randomforestclassifier__n_estimators':[10,100,150,250,400,600],\n    'randomforestclassifier__criterion':['gini','entropy'],\n    'randomforestclassifier__min_samples_split':[2,6,12],\n    'randomforestclassifier__min_samples_leaf':[1,4,6,10],\n    'randomforestclassifier__max_features':['auto','srqt','log2',int,float],\n    'randomforestclassifier__n_jobs':[-1],\n    'randomforestclassifier__verbose':[0,1,2],\n    'randomforestclassifier__class_weight':['balanced','balanced_subsample'],\n    'randomforestclassifier__n_jobs':[-1],\n}","07a0c942":"RF_grid = RandomizedSearchCV(RandomPipeline,hyper_params,scoring='accuracy',n_iter=40)\nRF_grid.fit(X_train,y_train)\nypred = RF_grid.predict(X_test)","dd6fa05e":"print(classification_report(y_test,ypred))\nprint(accuracy_score(y_test, y_pred))","90ff4034":"err = []\n  \nfor i in range(1, 40):\n    \n    model = make_pipeline(preprocessor,KNeighborsClassifier(n_neighbors = i))\n    model.fit(X_train, y_train)\n    pred_i = model.predict(X_test)\n    err.append(np.mean(pred_i != y_test))\n  \nplt.figure(figsize =(10, 8))\nplt.plot(range(1, 40), err, color ='blue',\n                linestyle ='dashed', marker ='o',\n         markerfacecolor ='blue', markersize = 8)\n  \nplt.title('Mean Err = f(K)')\nplt.xlabel('K')\nplt.ylabel('Mean Err')","9da628f9":"KNNPipeline = make_pipeline(preprocessor,KNeighborsClassifier(n_neighbors = 34))\nKNNPipeline.fit(X_train, y_train)\ny_proba = KNNPipeline.predict_proba(X_test)\ny_pred = np.argmax(y_proba,axis=1)\nprint(\"KNN : \", accuracy_score(y_test, y_pred))","5267de21":"import xgboost as xgb\ngbm = xgb.XGBClassifier(\n     learning_rate = 0.02,\n     n_estimators= 2000,\n     max_depth= 4,\n     min_child_weight= 2,\n     #gamma=1,\n     gamma=0.9,                        \n     subsample=0.8,\n     colsample_bytree=0.8,\n     objective= 'binary:logistic',\n     eval_metric = 'logloss',\n     nthread= -1,\n     scale_pos_weight=1).fit(X_train, y_train)\nevaluation (gbm)","1dda0540":"SVMPipeline.fit(X_train, y_train)\ny_proba = SVMPipeline.predict_proba(X_test)\ny_pred = np.argmax(y_proba,axis=1)\nSVM_score = accuracy_score(y_test, y_pred)\nprint(\"SVM : \", SVM_score)","87695ed0":"y_pred_prob = SVMPipeline.predict_proba(X_test)[:,1]\n\nfpr,tpr,threshols=roc_curve(y_test,y_pred_prob)\n\nplt.plot(fpr,tpr,label='SVM ROC Curve')\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"SVM ROC Curve\")\nplt.show()","b554188f":"SVMPipeline.get_params().keys()","43bacc99":"from sklearn.utils.fixes import loguniform\n\nhyper_params = {\n    'svc__C': loguniform(1e0, 1e3),\n    'svc__gamma': loguniform(1e-4, 1e-3),\n    'svc__kernel': ['rbf'],\n    'svc__class_weight':['balanced', None]\n               }","a5f1c342":"SVM_grid = RandomizedSearchCV(SVMPipeline,hyper_params,scoring='accuracy',n_iter=40)\nSVM_grid.fit(X_train,y_train)\nypred = SVM_grid.predict(X_test)\nSVM_score = accuracy_score(y_test, y_pred)\nprint(classification_report(y_test,ypred))","0279af2a":"best_classifier = RF_grid\n\nthresholds = [0.3,0.4,0.5,0.6,0.7,0.8]\nbest_t = 0.3\nbest_acc = 0\nfor t in thresholds:\n    y_pred = (best_classifier.predict_proba(X_test)[:,1] >= t).astype(int)\n    acc = accuracy_score(y_test, y_pred)\n    if acc > best_acc:\n        best_acc=acc\n        best_t=t\nprint('Accuracy on test set :',round(best_acc*100),\"%\")\nprint('Best threshold :',best_t)","8537eff8":"<h2 id=\"t4\" style=\"margin-bottom: 18px\">Resampling<\/h2>\n\nA widely adopted technique for dealing with highly unbalanced datasets is called resampling. It consists of removing samples from the majority class (under-sampling) and \/ or adding more examples from the minority class (over-sampling).","7ab5b6a7":"Despite the advantage of balancing classes, these techniques also have their weaknesses (there is no free lunch). The simplest implementation of over-sampling is to duplicate random records from the minority class, which can cause overfitting. In under-sampling, the simplest technique involves removing random records from the majority class, which can cause loss of information.\n\nLet's implement a basic example, which uses the <code>DataFrame.sample<\/code> method to get random samples each class:","6d8a5c70":"<h1><center>\ud83c\udf6cDiabetes Data Analysis\ud83d\udd0e<\/center><\/h1>\n<h3><center>\ud83e\udda0(Prediction at the end)\ud83d\udd2e<\/center><\/h3>\n<center><img src= \"https:\/\/www.news-medical.net\/image.axd?picture=2020%2F4%2Fshutterstock_571889917.jpg\" alt =\"Diabetes\" style='width: 600px;'><\/center>\n\n<h3>Overview<\/h3>\n<p>\nDiabetes mellitus (DM), commonly known as just diabetes, is a group of metabolic disorders characterized by a high blood sugar level over a prolonged period of time. Symptoms often include frequent urination, increased thirst and increased appetite. If left untreated, diabetes can cause many health complications. Acute complications can include diabetic ketoacidosis, hyperosmolar hyperglycemic state, or death. Serious long-term complications include cardiovascular disease, stroke, chronic kidney disease, foot ulcers, damage to the nerves, damage to the eyes and cognitive impairment.\n<\/p>\n\n<h3>What are the symptoms of people with diabetes?<\/h3>\n\n<h4>People that have diabetes :<\/h4>\n\n* Urinate (pee) a lot, often at night\n* Are very thirsty\n* Lose weight without trying\n* Are very hungry\n* Have blurry vision\n* Have numb or tingling hands or feet\n* Feel very tired\n* Have very dry skin\n* Have sores that heal slowly\n* Have more infections than usual\n","5cb5612d":"# If you like please upvote !\n## Also check my other notebooks :\n#### \ud83d\udd0eEDA & Modelling\ud83d\udd2e - \ud83d\udc01Mice Trisomy (100% acc.) : https:\/\/www.kaggle.com\/dorianvoydie\/eda-modelling-mice-100-acc\n#### \ud83d\udd0eEDA & Modelling\ud83d\udd2e - \ud83e\ude7a\ud83c\udf97\ufe0fBreast Cancer Detection : https:\/\/www.kaggle.com\/dorianvoydie\/eda-modelling-breast-cancer-detection\n#### \ud83c\udf26\ud83c\udf21 Weather Forecasting \ud83d\udcc8 (98% acc.) : https:\/\/www.kaggle.com\/dorianvoydie\/weather-forecasting-98-acc\n#### \ud83d\udd0eEDA & Modelling\ud83d\udd2e - Heart Attack \ud83e\ude7a\ud83d\udc93 (90% Acc.) : https:\/\/www.kaggle.com\/dorianvoydie\/eda-modelling-heart-attack-90-accuracy-score\n#### \ud83d\udd0eEDA & Modelling\ud83d\udd2e - Mobile price (95.5% acc.) : https:\/\/www.kaggle.com\/dorianvoydie\/eda-modelling-95-5-acc-mobile-price\n#### \ud83d\udd0eEDA & Modelling\ud83d\udd2e - \ud83e\ude7a\ud83e\udde0 Stroke (74% acc.) : https:\/\/www.kaggle.com\/dorianvoydie\/eda-modelling-stroke-74-acc\n#### \u26a1\ud83d\udc32 Pokemon Stats \ud83e\udd4a\u2728 : https:\/\/www.kaggle.com\/dorianvoydie\/pokemon-stats\n#### \ud83d\udc1fFish Classification - Using CNN\ud83d\udd2e (97% acc.) : https:\/\/www.kaggle.com\/dorianvoydie\/fish-classification-using-cnn-97-acc\n#### \ud83d\udc89\ud83d\udc69\u200d\u2695\ufe0f Vaccine & COVID-19 Indicators\ud83d\udcc8 : https:\/\/www.kaggle.com\/dorianvoydie\/vaccine-covid-19-indicators","fed45cbf":"## Creating train and test sets","549507d4":"We have to resample the whole dataset here beacause it is unbalanced","3de3bd7f":"## Using RandomForest","b9030c32":"# Analysing freatures and target","c42f10cd":"## Using XGBoost","dfb535aa":"# Final accuracy : 96%","2985cd35":"# A bit of data engineering ...","2f440a40":"#### Default threshold is good","18814840":"# Tuning Threshold","fdeaa1cd":"![](https:\/\/raw.githubusercontent.com\/rafjaa\/machine_learning_fecib\/master\/src\/static\/img\/resampling.png)","2e415f60":"## Creating models","84e3bc2c":"## Using SVM","a34fcada":"### Optimization","114a727b":"# Best Estimator\n## We saw that **RandomForest** goes up to 96% accuracy on the testset","760a39a7":"## Using KNN","3cf4818d":"## PCA Analysis","80e4b89b":"# Modelling","b208c572":"# Training models\n## Models overview"}}