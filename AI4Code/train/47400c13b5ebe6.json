{"cell_type":{"1cc0c069":"code","89dcb248":"code","08670e86":"code","63810290":"code","392ee7da":"code","5cbcc9c6":"code","01580606":"code","cfcedf96":"code","61804bf8":"code","45a831fc":"code","624aa6fd":"code","a2b70803":"code","eba483e6":"code","c5918ef7":"code","a6ce98c7":"code","350e12e3":"code","93fc4ed3":"code","beac99f4":"code","c84494b0":"code","c49ad1ee":"code","259e57f6":"code","a2d4c264":"code","62d434c1":"code","836fbe2a":"code","05ee0933":"code","60523158":"markdown","db0d9374":"markdown","45b6565d":"markdown","55a74050":"markdown","1895557f":"markdown","230c831c":"markdown","812e8086":"markdown","fdf226e7":"markdown","6ad9900c":"markdown","9f98ea42":"markdown","4990e951":"markdown","f3ec44e3":"markdown","efbd1867":"markdown","9dfb277d":"markdown","a9639254":"markdown","adfd4633":"markdown","04d4700e":"markdown","272eb40e":"markdown","196ffc61":"markdown","1db383ec":"markdown","47336c81":"markdown","844bf914":"markdown","c311833c":"markdown","96394ce2":"markdown","3b5d2ebd":"markdown"},"source":{"1cc0c069":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","89dcb248":"import torch \nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport time\nimport torch.utils.data\nimport torch.optim as optim","08670e86":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device : \", device  )","63810290":"def read_images(path, num_img):\n    array = np.zeros([num_img, 64*32])\n    i = 0\n    for img in os.listdir(path):\n        img_path = path + \"\/\" + img\n        img = Image.open(img_path, mode = \"r\")\n        data = np.asarray(img, dtype = \"uint8\")\n        data = data.flatten()\n        array[i,:] = data\n        i += 1\n    return array","392ee7da":"test_path = \"\/kaggle\/input\/lsi-far-infrared-pedestrian-dataset\/LSIFIR\/Classification\/Test\"\ntrain_path = \"\/kaggle\/input\/lsi-far-infrared-pedestrian-dataset\/LSIFIR\/Classification\/Train\"\n\ntrain_negative_path = train_path + \"\/neg\"\nnum_train_negative_img = 43390\ntrain_positive_path = train_path + \"\/pos\"\nnum_train_positive_img = 10208\n\ntest_negative_path = test_path + \"\/neg\"\nnum_test_negative_img = 22050\ntest_positive_path = test_path + \"\/pos\"\nnum_test_positive_img = 5944\n","5cbcc9c6":"train_negative_array = read_images(train_negative_path,num_train_negative_img)\nx_train_negative_tensor = torch.from_numpy(train_negative_array[:42000,:])\nprint(\"x_train_negative_tensor: \",x_train_negative_tensor.size())\ny_train_negative_tensor = torch.zeros(42000,dtype = torch.long)\nprint(\"y_train_negative_tensor: \",y_train_negative_tensor.size())","01580606":"train_positive_array = read_images(train_positive_path,num_train_positive_img)\nx_train_positive_tensor = torch.from_numpy(train_positive_array[:10000,:])\nprint(\"x_train_positive_tensor: \",x_train_positive_tensor.size())\ny_train_positive_tensor = torch.ones(10000,dtype = torch.long)\nprint(\"y_train_positive_tensor: \",y_train_positive_tensor.size())","cfcedf96":"x_train = torch.cat((x_train_negative_tensor,x_train_positive_tensor),0)\ny_train = torch.cat((y_train_negative_tensor,y_train_positive_tensor),0)\nprint(\"x_train: \",x_train.size())\nprint(\"y_train: \",y_train.size())","61804bf8":"test_negative_array = read_images(test_negative_path,num_test_negative_img)\nx_test_negative_tensor = torch.from_numpy(test_negative_array[:18056,:])\nprint(\"x_test_negative_tensor: \",x_test_negative_tensor.size())\ny_test_negative_tensor = torch.zeros(18056,dtype = torch.long)\nprint(\"y_test_negative_tensor: \",y_test_negative_tensor.size())","45a831fc":"test_positive_array = read_images(test_positive_path,num_test_positive_img)\nx_test_positive_tensor = torch.from_numpy(test_positive_array)\nprint(\"x_test_positive_tensor: \",x_test_positive_tensor.size())\ny_test_positive_tensor = torch.zeros(num_test_positive_img,dtype = torch.long)\nprint(\"y_test_positive_tensor: \",y_test_positive_tensor.size())","624aa6fd":"x_test = torch.cat((x_test_negative_tensor, x_test_positive_tensor), 0)\ny_test = torch.cat((y_test_negative_tensor, y_test_positive_tensor), 0)\nprint(\"x_test: \",x_test.size())\nprint(\"y_test: \",y_test.size())","a2b70803":"plt.imshow(x_train[43876,:].reshape(64,32),cmap = \"gray\")\nplt.axis(\"off\")\nplt.legend()\nplt.show()","eba483e6":"num_epochs = 100\nnum_classes = 2\nbatch_size = 2000\nlearning_rate = 0.0001","c5918ef7":"train = torch.utils.data.TensorDataset(x_train,y_train)\n","a6ce98c7":"trainloader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = True)\n","350e12e3":"test = torch.utils.data.TensorDataset(x_test,y_test)","93fc4ed3":"testloader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False)","beac99f4":"def conv3x3(in_planes, out_planes, stride = 1):\n    return nn.Conv2d(in_planes, out_planes, kernel_size = 3, stride = stride, padding = 1, bias = False)    ","c84494b0":"def conv1x1(in_planes, out_planes, stride = 1):\n    return nn.Conv2d(in_planes, out_planes, kernel_size = 1, stride = stride, bias = False)","c49ad1ee":"class BasicBlock(nn.Module):\n    \n    expansion = 1\n    \n    def __init__(self,inplanes, planes, stride = 1, downsample = None):\n        super(BasicBlock,self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace = True)\n        self.drop = nn.Dropout(0.9)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n        \n    def forward(self, x):\n        identity = x\n        \n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.drop(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.drop(out)\n        \n        if self.downsample is not None:\n            identity = self.downsample(x)\n            \n        out += identity\n        out = self.relu(out)\n        return out","259e57f6":"class ResNet(nn.Module):\n    \n    def __init__(self, block, layers, num_classes = num_classes):\n        super(ResNet,self).__init__()\n        self.inplanes = 64\n        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride = 2, padding = 3, bias= False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace = True)\n        self.maxpool = nn.MaxPool2d(kernel_size= 3, stride = 2, padding = 1)\n        self.layer1 = self._make_layer(block, 64, layers[0], stride = 1)\n        self.layer2 = self._make_layer(block, 128, layers[1], stride = 2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride = 2)\n    \n        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n        self.fc = nn.Linear(256*block.expansion, num_classes)\n        \n        for m in self.modules():\n            if isinstance(m,nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode = \"fan_out\", nonlinearity = \"relu\")\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight,1)\n                nn.init.constant_(m.bias,0)\n                \n    def _make_layer(self, block, planes, blocks, stride = 1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes*block.expansion:\n            downsample = nn.Sequential(\n                    conv1x1(self.inplanes, planes*block.expansion, stride),\n                    nn.BatchNorm2d(planes*block.expansion))\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes*block.expansion\n        for _ in range(1,blocks):\n            layers.append(block(self.inplanes, planes))\n        \n        return nn.Sequential(*layers)\n        \n    \n    def forward(self,x):\n        \n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0),-1)\n        x = self.fc(x)\n        \n        return x","a2d4c264":"model = ResNet(BasicBlock,[2,2,2]).to(device)\n","62d434c1":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)","836fbe2a":"start = time.time()\n\ntrain_acc = []\ntest_acc = []\nloss_list = []\nuse_gpu = True\n\ntotal_step = len(trainloader)\nfor epoch in range(num_epochs):\n    for i, data in enumerate(trainloader):\n        \n        images, labels = data\n        images = images.view(batch_size, 1, 64, 32) # reshape\n        images = images.float() # float\n        \n        # use gpu\n        if use_gpu:\n            if torch.cuda.is_available():\n                images, labels = images.to(device), labels.to(device)\n                \n        # forward\n        outputs = model(images)\n        \n        # loss\n        loss = criterion(outputs, labels)\n        \n        # zero gradient\n        optimizer.zero_grad()\n        \n        # backward\n        loss.backward()\n        \n        # update weights\n        optimizer.step()\n    if epoch % 10 == 0:    \n        print(\"Epoch : \", epoch)\n    # train\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in trainloader:\n            images, labels= data\n            \n            images = images.view(batch_size,1,64,32)\n            images = images.float()\n            \n            # gpu\n            if use_gpu:\n                if torch.cuda.is_available():\n                    images, labels = images.to(device), labels.to(device)\n            \n            outputs = model(images)\n            \n            _, predicted = torch.max(outputs.data,1)\n            \n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    if epoch % 10 == 0:    \n        print(\"Accuracy Train %d %%\"%(100*correct\/total))\n    train_acc.append(100*correct\/total)\n\n    # test\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in testloader:\n            images, labels= data\n            \n            images = images.view(batch_size,1,64,32)\n            images = images.float()\n            \n            # gpu\n            if use_gpu:\n                if torch.cuda.is_available():\n                    images, labels = images.to(device), labels.to(device)\n            \n            outputs = model(images)\n            \n            _, predicted = torch.max(outputs.data,1)\n            \n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    if epoch % 10 == 0:    \n        print(\"Accuracy Test %d %%\"%(100*correct\/total))\n    test_acc.append(100*correct\/total)\n\n    loss_list.append(loss.item())\n    \nprint(\"**************\")\nprint(\"Train Is Done\")\nprint(\"**************\")\nend = time.time()\ntotal_time = (end-start)\/60\nprint(\"Process Time : \",total_time)","05ee0933":"fig, ax1 = plt.subplots()\n\nplt.plot(loss_list,label = \"Loss\",color = \"black\")\n\nax2 = ax1.twinx()\n\nax2.plot(np.array(test_acc)\/100,label = \"Test Acc\",color=\"green\")\nax2.plot(np.array(train_acc)\/100,label = \"Train Acc\",color= \"red\")\nax1.legend()\nax2.legend()\nax1.set_xlabel('Epoch')\nfig.tight_layout()\nplt.title(\"Loss vs Test Accuracy\")\nplt.show()","60523158":"# Visualization of Results","db0d9374":"**Defining Hyperparameters** ","45b6565d":"**Arranging Train Data for Needed Format to Process**","55a74050":"**Needed Libraries**","1895557f":"**Arranging Train Data for Needed Format to Process**","230c831c":"# Preparing Tests and Trains Data to Process them with Model","812e8086":"**Basic Block**","fdf226e7":"**Convolutional Layer with 1x1 Kernel**","6ad9900c":"**Train Our Network**","9f98ea42":"**Initializing Loss and Optimizer**","4990e951":"**Concat x_test and y_test Data**","f3ec44e3":"**Concat Test**","efbd1867":"**Read Train Positive**","9dfb277d":"**Concat x_train and y_train Data**","a9639254":"**Concat Train**","adfd4633":"**Convolutional Layer with 3x3 Kernel**","04d4700e":"# Visualize Data","272eb40e":"**Read Test Positive**","196ffc61":"# Compiling and Fitting Our CNN Model","1db383ec":"# Deep Residual Network Model ","47336c81":"**Device Configuration to Use GPU**\n\n> Note : This codes can be used to check that your computer use its CPU or GPU.","844bf914":"**Initializing Model**","c311833c":"# Implementing Deep Residual Network Basic Block","96394ce2":"**Read Train Negative**","3b5d2ebd":"**Read Test Negative**"}}