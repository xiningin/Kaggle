{"cell_type":{"1d1b8719":"code","769823c7":"code","7d7a1ca0":"code","e0f13edf":"code","1a5b3424":"code","fa3e435c":"code","6518636f":"code","b7bbe52e":"code","ec464741":"code","3bbd6c73":"markdown","88e80ab0":"markdown","633dff1b":"markdown"},"source":{"1d1b8719":"import pandas as pd\nimport numpy as np\nfrom PIL import Image\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\n\nimport torch\nfrom torch.utils.data import Dataset\n\nimport os\nimport json","769823c7":"DATA_DIR = \"\/kaggle\/input\/tensorflow-great-barrier-reef\/\"","7d7a1ca0":"train_df = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\ntrain_df.head(20)","e0f13edf":"train_df.shape","1a5b3424":"def vizualize(img, bboxes, class_name, color):\n    fig, ax = plt.subplots(1, 1, figsize=(20, 20))\n    plt.axis(\"off\")\n    ax.imshow(img)\n    for box in bboxes:\n        x, y, w, h = box\n        ax.add_patch(patches.Rectangle((x, y), w, h, edgecolor=color, fill=False, linewidth=2))\n        ax.text(x, y, class_name, bbox={\"facecolor\": color, \"alpha\": 0.9}, fontsize=11)\n    plt.show()","fa3e435c":"for _, row in train_df[20:22].iterrows():\n    bboxes = []\n    vid = row[\"video_id\"]\n    frame = row[\"video_frame\"]\n    annots = json.loads(row[\"annotations\"].replace(\"'\", '\"'))\n    for annot in annots:\n        x = annot[\"x\"]\n        y = annot[\"y\"]\n        w = annot[\"width\"]\n        h = annot[\"height\"]\n        bboxes.append([x, y, w, h])\n    img = np.array(Image.open(os.path.join(DATA_DIR, f\"train_images\/video_{vid}\/{frame}.jpg\")))\n    vizualize(img, bboxes, \"starfish\", \"orange\")","6518636f":"class StarfishDataset(Dataset):\n    def __init__(self, df, data_dir):\n        self.df = df.copy()\n        self.data_dir = data_dir\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        vid = row[\"video_id\"]\n        fid = row[\"video_frame\"]\n        annots = json.loads(row[\"annotations\"].replace(\"'\", '\"'))\n        \n        img = Image.open(os.path.join(self.data_dir, f\"video_{vid}\/{fid}.jpg\"))\n        img = np.array(img, dtype=np.float32) \/ 255\n        img = torch.from_numpy(img)\n        \n        bboxes = []\n        \n        for annot in annots:\n            x = annot[\"x\"]\n            y = annot[\"y\"]\n            w = annot[\"width\"]\n            h = annot[\"height\"]\n            bboxes.append([x, y, w, h])\n        \n        labels = torch.ones((len(bboxes), ))\n        \n        return img, bboxes\n    \n    def __len__(self):\n        return len(self.df)","b7bbe52e":"train_dataset = StarfishDataset(train_df, os.path.join(DATA_DIR, \"train_images\"))","ec464741":"train_dataset[20]","3bbd6c73":"# **Importing libraries**","88e80ab0":"# **Looking at data**","633dff1b":"# **Data for net**"}}