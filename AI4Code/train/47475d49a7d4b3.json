{"cell_type":{"bf80a06b":"code","186866b4":"code","c1581430":"code","3fca2ff0":"code","a2788fe0":"code","e130347d":"code","6fea97db":"code","22480dbd":"code","edcefb2f":"code","707e9649":"code","9c500d64":"code","41eaec48":"code","d74b6843":"code","d914d324":"code","0845a160":"code","6d4b71a9":"code","ff38e0a2":"code","b664adaa":"markdown","5eb3b5a9":"markdown","ee7b9419":"markdown","38b7f57e":"markdown","9e3c7093":"markdown","a5fe3477":"markdown","2849541a":"markdown","2a722866":"markdown","2ad712be":"markdown","0b187221":"markdown","30e4c10b":"markdown","e76992d9":"markdown","3b9980e0":"markdown","095dba82":"markdown","6b798d77":"markdown","18c5c4d4":"markdown","e91b4fbe":"markdown","4a312af1":"markdown","c65967d9":"markdown","b442306f":"markdown","62af0fa2":"markdown"},"source":{"bf80a06b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn.datasets\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\nfrom sklearn import metrics\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","186866b4":"# Importing dataset\nhp_dataset = sklearn.datasets.load_boston()\nprint(hp_dataset)","c1581430":"# The data looks very unorganized so we can load it into a pandas dataframe for more structure\nhp_data = pd.DataFrame(hp_dataset.data,columns=hp_dataset.feature_names)","3fca2ff0":"# Viewing first 5 rows of the dataframe\nhp_data.head()","a2788fe0":"# The price (target) column is missing so we add it\nhp_data['price'] = hp_dataset.target\n\nhp_data.head()","e130347d":"hp_data.info()","6fea97db":"hp_data.isnull().sum()","22480dbd":"# We can use a heatmap to check correlation between the variables.\ncorr = hp_data.corr()\nplt.figure(figsize=(8,8))\nsns.heatmap(corr,cbar=True,square=True,fmt='.1f',annot=True,cmap='Reds')","edcefb2f":"# We need to split the data\nX = hp_data.drop(['price'],axis=1) # We need all the variables (columns) as independent variables so we're just dropping the target column to make things easier.\ny = hp_data['price'] # Target\n\n# Then we split the data into training and testing data\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 2) # 80% data will be used for training the model and rest 20% for testing.","707e9649":"X.shape","9c500d64":"X_train.shape","41eaec48":"# We have already imported the model so we only need to load it now\nmodel = XGBRegressor()","d74b6843":"# Now we need to train the model\nmodel.fit(X_train,y_train) # fitting means training","d914d324":"train_pred = model.predict(X_train)\ntrain_pred","0845a160":"# Now we use R squared error (Basically comparing the original y_train and predictions and seeing difference\/error)\nRSQscore = metrics.r2_score(y_train,train_pred)\n\n# We can also check using mean absolute error\nMAEscore = metrics.mean_absolute_error(y_train,train_pred) # just finds difference between each and finds an average\n\n# Let's check\n\n# The closer ithe errors are to 0, the more accurate our model is.\nprint(\"R squared error:\",RSQscore) \nprint(\"Mean absolute error:\",MAEscore) ","6d4b71a9":"test_pred = model.predict(X_test)\ntest_pred","ff38e0a2":"# R squared error\nTestRSQscore = metrics.r2_score(y_test,test_pred)\n\n# Mean absolute error\nTestMAEscore = metrics.mean_absolute_error(y_test,test_pred)\n\n# Let's check\n\n# The closer ithe errors are to 0, the more accurate our model is.\nprint(\"R squared error:\",TestRSQscore) \nprint(\"Mean absolute error:\",TestMAEscore) ","b664adaa":"**Machine learning is divided into supervised and unsupervised learning. We train our model with data that we have previously acquired in supervised learning. In unsupervised learning, we have no data that we can train our model with.**\n\n**Supervised machine learning is divided into classification and regression. In classification, we predict discrete values, e.g. Yes\/No, Customer will purchase\/Won't purchase. But in regression, we predict continuous values, such as age, price, etc.**","5eb3b5a9":"# Supervised vs Unsupervised Machine Learning","ee7b9419":"**We're going to use XG Gradient Boost library. We have a lot of numerical data to train and this is a high accuracy algorithm for such cases.**","38b7f57e":"**This is a good visualization. We can make observations such as, as RM increases, price increases and as NOX increases, DIS decreases.**","9e3c7093":"So basically the workflow is like this: Import libraries and dataset -> check for missing values -> perform necessary imputation -> understand your variables -> split data -> train model -> check its accuracy -> improve model or try other ones.","a5fe3477":"# Correlation","2849541a":"**Good thing we have no missing values in this dataset so no imputation (replacing missing values with other appropriate ones) necessary.**","2a722866":"**This notebook is a guide for beginners into machine learning, linear regression to be more specific. There will be comments every step of the way so there is a clear understanding. We will be building a house price prediction system.**","2ad712be":"# Prediction and Evaluation of the Model","0b187221":"# Importing Libraries and dataset","30e4c10b":"**The R squared error is pretty good as it is very close to 0 but mean absolute is a little higher than we last saw with our training data, but it's not too bad, could be improved.**","e76992d9":"**But keep in mind that we used training data to check accuracy. We need to check using test data for a better understanding.**","3b9980e0":"# Splitting Data","095dba82":"As we can see, 404 rows are used for testing out of 506 which is about 79.8% of the data.","6b798d77":"**To get better accuracy, try different models or use more training data.**","18c5c4d4":"# Conclusion","e91b4fbe":"**First, we need to use the model to predict prices from the training data. Then, we check our model's accuracy using R squared error\/ Mean Square error\/ Mean Absolute error (for regression).**","4a312af1":"# Linear Regression","c65967d9":"**Both R squared error and MAE are pretty close to 0 so we our model must be quite accurate.**","b442306f":"# Introduction","62af0fa2":"# Missing values"}}