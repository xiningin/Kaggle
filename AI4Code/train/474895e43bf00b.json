{"cell_type":{"281927bf":"code","048c0cc2":"code","47aa40c1":"code","0160e240":"code","1647f563":"code","c6f35bd6":"code","bf691001":"code","5f4b6d98":"code","0e1196fc":"code","571f497b":"code","662f3679":"code","ea3c372c":"code","7c207b96":"code","3d0363f8":"code","62f379c9":"code","aeeea0b2":"code","298cac32":"code","7ec11756":"code","95ec052a":"code","5d5cd244":"code","0b7c9a79":"code","e3f1f649":"code","b587067f":"markdown","bb652a8a":"markdown","e5014f12":"markdown","bf42a7db":"markdown","708e152b":"markdown","e4026291":"markdown","5704bcf0":"markdown","a93e649a":"markdown","99392b83":"markdown","55a7daec":"markdown","3dd18ff4":"markdown","41853302":"markdown","28ed21ca":"markdown","34594e8f":"markdown","002b29e5":"markdown","e826bbc8":"markdown","5656c06e":"markdown","561a8ede":"markdown","49fddcc5":"markdown","d55c7e41":"markdown","df6d6390":"markdown","44d6b44e":"markdown"},"source":{"281927bf":"train='\/kaggle\/input\/fruits\/fruits-360\/Training\/'\ntest='\/kaggle\/input\/fruits\/fruits-360\/Test\/'","048c0cc2":"import numpy as np # linear algebra\nimport pandas as pd\nfrom glob import glob\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nfrom PIL import Image as im\nfrom tensorflow.keras import layers,models\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport cv2\n%matplotlib inline\n","47aa40c1":"X_train_img=np.array(glob(train+'\/**\/*.jpg',recursive=True))\nX_test_img=np.array(glob(test+'\/**\/*.jpg',recursive=True))","0160e240":"y_train=[]\nfor x in X_train_img:\n    y_train.append(x.split('\/')[6])\ny_train=pd.DataFrame(data=y_train,columns=['test'])","1647f563":"len(X_train_img)","c6f35bd6":"y_test=[]\nfor y in X_test_img:\n    y_test.append(y.split('\/')[6])\ny_test=pd.DataFrame(y_test,columns=['test'])","bf691001":"y_train.nunique()","5f4b6d98":"k=pd.concat([y_train.test,y_test.test])\nz=LabelEncoder()\np=z.fit_transform(k)\nclassifier=[[a,b] for a,b in zip(pd.DataFrame(p)[0].unique(),k.unique())]\ny_train=p[:len(y_train)]\ny_test=p[len(y_train):]","0e1196fc":"\ncv2.imread(X_train_img[1100]).shape","571f497b":"X_train=[]\nX_test=[]","662f3679":"\nfor i in range(len(X_train_img)):\n    X_train.append(cv2.imread(X_train_img[i]))","ea3c372c":"X_train=np.array(X_train)","7c207b96":"for j in range(len(X_test_img)):\n    X_test.append(cv2.imread(X_test_img[j]))","3d0363f8":"X_test=np.array(X_test)","62f379c9":"data_augmentation=models.Sequential([\n    layers.experimental.preprocessing.RandomFlip('horizontal_and_vertical',input_shape=(100,100,3)),\n    layers.experimental.preprocessing.RandomContrast(0.85),\n    layers.experimental.preprocessing.RandomRotation(0.1),\n    layers.experimental.preprocessing.RandomZoom(0.2)\n])","aeeea0b2":"CNN=models.Sequential([\n                      data_augmentation,\n                       #cnn\n                      layers.Conv2D(filters=20,kernel_size=(3,3),activation='relu'),\n                      layers.MaxPooling2D((2,2)),\n                       \n                       layers.Conv2D(filters=40,kernel_size=(3,3),activation='relu'),\n                       layers.MaxPooling2D((2,2)),\n                        layers.Conv2D(filters=80,kernel_size=(3,3),activation='relu'),\n                        layers.MaxPooling2D((2,2)),\n                       #dense=\n                        layers.Dropout(0.2),\n                       layers.Flatten(),\n                      layers.Dense(1024,activation='relu'),\n                      layers.Dense(512,activation='relu'),\n                      layers.Dense(131,activation='softmax')\n])\nCNN.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\nhistory=CNN.fit(X_train,y_train,epochs=25)","298cac32":"CNN.evaluate(X_test,y_test)","7ec11756":"\ny_pred=CNN.predict(X_test)\ny_pred[:10]","95ec052a":"# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.show()","5d5cd244":"# summarize history for loss\nplt.plot(history.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.show()","0b7c9a79":"y_pred_classes=[np.argmax(element) for element in y_pred]\nprint(\"Classfication report\\n\",classification_report(y_test,y_pred_classes))\n\n","e3f1f649":"\nplt.figure(figsize=(15,15))\nsns.heatmap(confusion_matrix(y_test,y_pred_classes))","b587067f":"**Preparing X_train**","bb652a8a":"PREPARING THE y_test","e5014f12":"Predicting fruit names by its image","bf42a7db":"**Preparing X_test**","708e152b":"# READING THE DATASET","e4026291":"**PREPARING Y_TRAIN AND Y_TEST**","5704bcf0":"All the images have same size, AFTER CHECKING THE CHANGES IN INDEX OF X_train_img","a93e649a":"# Training of the model on CNN ","99392b83":"Training of model using (3,3) grid and maxpooling2D in (2,2)","55a7daec":"Now y_train and y_test data preprocessing completed","3dd18ff4":"# DATA PREPROCESSING","41853302":"**Data augmentation **","28ed21ca":"![image.png](attachment:94fcc9f0-6077-4a04-8a3c-cd4bf22ba7bb.png)","34594e8f":"Content:\n* Reading the Dataset\n* importing library\n* Data preprocessing\n* Training\n* Testing\n* Confusion matrix visualisation and classification report","002b29e5":"# TESTING OF THE DATASET","e826bbc8":"EXTRACING ALL THE IMAGES USING THE GLOB ","5656c06e":"NOW I FIRST CONCAT THE BOTH y_train and y_test ,\nthen label encode them\nand after that again seperate both of them","561a8ede":"**PREPARING X_TRAIN AND X_TEST**","49fddcc5":"# Accuracy and Losses visualisation ","d55c7e41":"# IMPORTING THE LIBRARY","df6d6390":"PREPARING THE y_train","44d6b44e":"# CLASSIFICATION REPORT AND CONFUSION MATRIX"}}