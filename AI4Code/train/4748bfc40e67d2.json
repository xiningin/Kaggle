{"cell_type":{"4082f59f":"code","3e4ea283":"code","cb405737":"code","e3b28860":"code","b1054c9e":"code","0d8b20d0":"code","56b863f8":"code","c3246ebc":"code","d41f9c97":"code","27b3541d":"code","d101656e":"code","18e0695d":"code","d8ddbcbe":"code","a5745483":"code","f33e3a3c":"code","40468225":"code","7899a92f":"code","af4aaa77":"code","bcd8106f":"code","68f5a0a1":"code","579e44d6":"code","fe697ce4":"code","b8ea94e6":"code","55f7f14a":"code","935599e3":"code","37269df2":"code","07b43bed":"code","2f27d6a7":"code","34b2a3d1":"code","dfe8ce89":"code","eba23c9c":"code","9f09e957":"markdown","90b043f4":"markdown","9d625e56":"markdown","ba53c935":"markdown","489774d2":"markdown","b948aa90":"markdown","4a8cabfe":"markdown","dcdfde20":"markdown","ac86342b":"markdown","7cdf6cdb":"markdown","29d638fe":"markdown","5d545dd3":"markdown","f3e595fa":"markdown","adc8fc1e":"markdown","178404a7":"markdown","046da95e":"markdown","0025bb18":"markdown","c50db9bf":"markdown","dfd4cead":"markdown","4fef8363":"markdown","2407778e":"markdown","47760c6e":"markdown","8a7b323e":"markdown","ee8330d5":"markdown","abcd0682":"markdown"},"source":{"4082f59f":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nfrom os import listdir, makedirs, getcwd, remove\nfrom os.path import isfile, join, exists, isdir\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision\nfrom torchvision import transforms, datasets, models\nimport torchvision.models as models\nimport torch.optim.lr_scheduler as schedule\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n!ls ..\/input\/mnist-but-chinese\/MNIST_Chinese_Hackathon","3e4ea283":"train = pd.read_csv('\/kaggle\/input\/mnist-but-chinese\/MNIST_Chinese_Hackathon\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/mnist-but-chinese\/MNIST_Chinese_Hackathon\/test.csv')\nsample = pd.read_csv('\/kaggle\/input\/mnist-but-chinese\/MNIST_Chinese_Hackathon\/sample_submission.csv')","cb405737":"df_tr,df_val = train_test_split(train,random_state=42,test_size=0.2)\nprint('Training dataset shape ',df_tr.shape)\nprint('Validation dataset shape ',df_val.shape)","e3b28860":"import seaborn as sns\nsns.set_style('whitegrid')","b1054c9e":"plt.figure(figsize=(9,5))\n(train['code'].value_counts()\/len(train)*100).plot(kind='bar')\nplt.title('Training set distribution in %')\nplt.show()","0d8b20d0":"fig, ax = plt.subplots(1,2,figsize=(18,5))\nprint('Comparison between Training and Validation set')\n(df_tr['code'].value_counts()\/len(df_tr)*100).sort_index().plot(kind='bar',ax=ax[0],title='training set distribution')\n(df_val['code'].value_counts()\/len(df_val)*100).sort_index().plot(kind='bar',ax=ax[1],title='validation set distribution')\nplt.show()","56b863f8":"class builddataset(Dataset):\n    def __init__(self,data,root,transforms=None):\n        self.data = data \n        self.root = root\n        self.transforms = transforms\n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self,idx):\n        filename = self.root+'\/'+str(self.data.iloc[idx,0])\n        image = Image.open(filename)\n        label = torch.tensor(np.array(self.data.iloc[idx,1]-1))\n        if self.transforms:\n            image = self.transforms(image)\n        return (image,label)","c3246ebc":"from PIL import Image, ImageOps, ImageEnhance\nimport numbers\n\nclass RandomShift(object):\n    def __init__(self, shift):\n        self.shift = shift\n        \n    @staticmethod\n    def get_params(shift):\n        \"\"\"Get parameters for ``rotate`` for a random rotation.\n        Returns:\n            sequence: params to be passed to ``rotate`` for random rotation.\n        \"\"\"\n        hshift, vshift = np.random.uniform(-shift, shift, size=2)\n\n        return hshift, vshift \n    def __call__(self, img):\n        hshift, vshift = self.get_params(self.shift)\n        \n        return img.transform(img.size, Image.AFFINE, (1,0,hshift,0,1,vshift), resample=Image.BICUBIC, fill=1)","d41f9c97":"train_transforms = transforms.Compose([transforms.RandomRotation(10),\n                                       RandomShift(6),\n                                       transforms.Resize(64,64),\n                                       transforms.RandomResizedCrop(64),\n                                       transforms.ToTensor()])\n\nval_transforms = transforms.Compose([transforms.Resize(64,64),\n                                     transforms.ToTensor()])","27b3541d":"data_dir = '..\/input\/mnist-but-chinese\/MNIST_Chinese_Hackathon'","d101656e":"# Training and Validation Datasets\ntrain_ds = builddataset(df_tr,data_dir+'\/Training_Data',transforms=train_transforms)\nval_ds = builddataset(df_val,data_dir+'\/Training_Data',transforms=val_transforms)\n\n# Train and validation Dataloaders\ntrain_dl = DataLoader(train_ds,batch_size=32,shuffle=True)\nval_dl = DataLoader(val_ds,batch_size=32,shuffle=False)\n\ndataloader = {'train':train_dl,'val':val_dl}","18e0695d":"import time\nimport copy","d8ddbcbe":"def train_model(model,criterion,optimizer,scheduler,num_epochs):\n    since = time.time()\n    best_model_p = copy.deepcopy(model.state_dict())\n    best_accu = 0.0\n    for epoch in range(1,num_epochs+1):\n        if epoch%10 == 0:\n            print('Epoch: {}\/{}'.format(epoch,num_epochs))\n        for phase in ['train','val']:\n            if(phase=='train'):\n                model.train()\n            else:\n                model.eval()\n            running_loss = 0.0\n            running_corrects = 0.0\n            for inputs,targets in dataloader[phase]:\n                inputs=inputs.cuda()\n                targets=targets.cuda()\n                optimizer.zero_grad()\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _,preds = torch.max(outputs,1)\n                    targets = torch.flatten(targets)\n                    loss = criterion(outputs,targets)\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                running_loss += loss.item()*inputs.size(0)\n                running_corrects += torch.sum(preds == targets.data).double().item()\n            if phase=='train':\n                epoch_loss = running_loss\/len(train_ds)\n                epoch_accu = running_corrects\/len(train_ds)\n            else:\n                epoch_loss = running_loss\/len(val_ds)\n                epoch_accu = running_corrects\/len(val_ds)\n                scheduler.step(epoch_loss)\n            if epoch%10 == 0:\n                print(phase,' Loss: ',epoch_loss,' Accuracy: ',epoch_accu)\n            if phase=='val' and epoch_accu >= best_accu:\n                best_accu = epoch_accu\n                best_model_p = copy.deepcopy(model.state_dict())\n    time_taken = time.time()-since\n    print(\"Training Completed in time \",time_taken)\n    print(\"Best Accuracy \",best_accu)\n    model.load_state_dict(best_model_p)\n    return model","a5745483":"import torch.nn as nn\nimport torch.nn.functional as F","f33e3a3c":"class cnn_model1(nn.Module):\n    def __init__(self):\n        super(cnn_model1,self).__init__()\n        \n        self.Conv1 = nn.Conv2d(1,32,3,1,1) \n        self.Bn2d1 = nn.BatchNorm2d(32)\n        \n        self.Conv2 = nn.Conv2d(32,32,3,1,1) \n        self.Bn2d2 = nn.BatchNorm2d(32)\n        self.Max2 = nn.MaxPool2d(2,2)   \n        \n        self.Conv3 = nn.Conv2d(32,64,3,1,1)\n        self.Bn2d3 = nn.BatchNorm2d(64)\n        self.Max3 = nn.MaxPool2d(2,2)       \n        \n        self.Conv4 = nn.Conv2d(64,64,3,1,1) \n        self.Bn2d4 = nn.BatchNorm2d(64)\n        self.Max4 = nn.MaxPool2d(2,2)   \n        \n        \n        self.fc1 = nn.Linear(64*8*8,512)\n        self.Bn1d1 = nn.BatchNorm1d(512)\n        self.drop1 = nn.Dropout(p=0.5)\n        \n        self.fc2 = nn.Linear(512,512)\n        self.Bn1d2 = nn.BatchNorm1d(512)\n        self.drop2 = nn.Dropout(p=0.5)\n        self.fc3 = nn.Linear(512,15)\n    \n    def forward(self,x):\n        x = F.relu(self.Bn2d1(self.Conv1(x)))\n        x = self.Max2(F.relu(self.Bn2d2(self.Conv2(x))))\n        x = self.Max3(F.relu(self.Bn2d3(self.Conv3(x))))\n        x = self.Max4(F.relu(self.Bn2d4(self.Conv4(x))))\n        x = x.view(x.size(0),-1)\n        x = self.drop1(F.relu(self.Bn1d1(self.fc1(x))))\n        x = self.drop2(F.relu(self.Bn1d2(self.fc2(x))))\n        x = self.fc3(x)\n        return x","40468225":"model1 = cnn_model1()\nmodel1.cuda()\nprint('model1 in GPU')","7899a92f":"criterion1 = torch.nn.CrossEntropyLoss()\noptimizer1 = torch.optim.Adam(model1.parameters(),lr=0.003)\nscheduler1 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer1,patience=5,factor=0.2,min_lr=0.0000001)","af4aaa77":"trained_model1 = train_model(model1,criterion1,optimizer1,scheduler1,num_epochs=40)","bcd8106f":"class cnn_model2(nn.Module):\n    def __init__(self):\n        super(cnn_model2,self).__init__()\n        \n        self.Conv1 = nn.Conv2d(1,32,3,1,1)  \n        self.bn1 = nn.BatchNorm2d(32)\n        self.Conv2 = nn.Conv2d(32,32,3,1,1) \n        self.bn2 = nn.BatchNorm2d(32)\n        self.Conv3 = nn.Conv2d(32,32,4,2,1) \n        self.bn3 = nn.BatchNorm2d(32)\n        self.drop3 = nn.Dropout(p=0.4)\n        self.Conv4 = nn.Conv2d(32,64,3,1,1) \n        self.bn4 = nn.BatchNorm2d(64)\n        self.Conv5 = nn.Conv2d(64,64,3,1,1)\n        self.bn5 = nn.BatchNorm2d(64)\n        self.Conv6 = nn.Conv2d(64,64,4,2,1)\n        self.bn6 = nn.BatchNorm2d(64)\n        self.drop6 = nn.Dropout(p=0.4)\n        self.Conv7 = nn.Conv2d(64,64,3,1,1)\n        self.bn7 = nn.BatchNorm2d(64)\n        \n        self.drop_fc = nn.Dropout(p=0.4)\n        self.fc = nn.Linear(64*16*16,15)\n        \n    def forward(self,x):\n        x=F.relu(self.bn1(self.Conv1(x)))\n        x=F.relu(self.bn2(self.Conv2(x)))\n        x=self.drop3(F.relu(self.bn3(self.Conv3(x))))\n        x=F.relu(self.bn4(self.Conv4(x)))\n        x=F.relu(self.bn5(self.Conv5(x)))\n        x=self.drop6(F.relu(self.bn6(self.Conv6(x))))\n        x=F.relu(self.bn7(self.Conv7(x)))\n        x=x.view(x.size(0),-1)\n        x=self.drop_fc(x)\n        x=self.fc(x)\n        return x","68f5a0a1":"model2 = cnn_model2()\nmodel2.cuda()\nprint('model2 in GPU')","579e44d6":"criterion2 = torch.nn.CrossEntropyLoss()\noptimizer2 = torch.optim.Adam(model2.parameters(),lr=0.003)\nscheduler2 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer2,patience=5,factor=0.2,min_lr=0.0000001)","fe697ce4":"trained_model2 = train_model(model2,criterion2,optimizer2,scheduler2,num_epochs=40)","b8ea94e6":"def evaluate(model):\n    model.eval()\n    running_loss = 0\n    running_corrects = 0\n    for inputs,targets in dataloader['val']:\n        inputs = inputs.cuda()\n        targets = targets.cuda()\n        outputs = model(inputs)\n        _,preds = torch.max(outputs,1)\n        targets = torch.flatten(targets)\n        running_corrects += torch.sum(preds == targets.data)\n    print(\"Accuracy: \",running_corrects.item()\/len(val_ds))\n    return","55f7f14a":"print('Accuracy score on the validation set using CNN Model 1: ')\nevaluate(trained_model1)\n\nprint('Accuracy score on the validation set using CNN Model 2: ')\nevaluate(trained_model2)","935599e3":"class ensemble_average(nn.Module):\n    def __init__(self,model1,model2):\n        super(ensemble_average,self).__init__()\n        self.model1 = model1\n        self.model2 = model2\n    def forward(self,x):\n        self.model1.eval()\n        for params in self.model1.parameters():\n            params.requires_grad = False\n        self.model2.eval()\n        for params in self.model2.parameters():\n            params.requires_grad = False\n        out1 = self.model1(x)\n        out2 = self.model2(x)\n        out = (out1+out2)\/2\n        return out","37269df2":"ensembled_model = ensemble_average(trained_model1,trained_model2)","07b43bed":"print('Accuracy score on the validation set using ensembled(Average) model: ')\nevaluate(ensembled_model)","2f27d6a7":"# Building custom dataset for the test data\n\nclass buildtestdataset(Dataset):\n    def __init__(self,data,root,transforms=None):\n        self.data = data\n        self.root = root\n        self.transforms = transforms\n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self,idx):\n        filename = self.root+'\/'+str(self.data.iloc[idx,0])\n        image = Image.open(filename)\n        if self.transforms:\n            image = self.transforms(image)\n        return (image)","34b2a3d1":"def create_submission(model):\n    test_ds = buildtestdataset(test,data_dir+'\/Testing_Data',transforms=transforms.Compose([transforms.Resize(64,64),transforms.ToTensor()]))\n    test_dl = DataLoader(test_ds,batch_size=1,shuffle=False)\n    predictions = []\n    for inputs in test_dl:\n        inputs = inputs.cuda()\n        outputs = model(inputs)\n        _,preds = torch.max(outputs,1)\n        preds = preds.item()\n        predictions.append(preds)\n    sub = pd.DataFrame(zip(test.id,predictions),columns=['id','code'])\n    sub['code'] = sub['code']+1\n    sub.set_index('id',inplace=True)\n    return sub","dfe8ce89":"sub = create_submission(ensembled_model)\nsub.head()","eba23c9c":"sub.to_csv('final_submission.csv')","9f09e957":"#### Evaluating both the models using the validation dataset","90b043f4":"# MNIST but Chinese! Accuracy=99.515%","9d625e56":"So, clearly average ensembled model gives a better score than both the models.","ba53c935":"### Building the Custom Dataset","489774d2":"Here I didnt do much, just took the average output from the two models defined above. I tried some other techniques as well like using a fully connected layer to account for the outputs from the two models but this average ensemble technique gave a better score on the validation set as well as private leaderboard.","b948aa90":"### Model Ensembling","4a8cabfe":"RandomShift is a technique which helps in shifting the image in both horizontal and vertical directions by the give pixel degree.","dcdfde20":"Although both the models defined above work just fine, there is still some chance that these models dont generalize well. Hence, it is always useful to ensemble models to cancel the noise in the dataset and make the model as robust as possible.","ac86342b":"### Loading the csv files","7cdf6cdb":"### Ploting the distribution of the Datasets","29d638fe":"#### Architecture highlights\nIt follows the general design of the LeNet5 architecture with some changes:\n1. MaxPooling layers have been replaced by CNN layers with 2 strides thus forming learnable pooling layers.\n2. BatchNorm is used after every CNN layer and dropout layer is added wherever necessary.","5d545dd3":"### CNN Model Architecture 2","f3e595fa":"Data Augmentation techniques are used to transform the dataset and create more datapoints to increase the total training examples. This makes the model more robust in classifying unclear images","adc8fc1e":"### Data Augmentation","178404a7":"As there is not much difference between Train and Validation dataset, we will go with it","046da95e":"Creating the final submission","0025bb18":"## Overview\n\nMNIST Data but for Chinese Language is given, the task is to predict the Chinese character from the given image.\nThe training dataset has around 10000 images and the testing dataset has around 5000 images.\n\n### Acknowledgements\nI want to express my gratitude to the following people: Dr. K Nazarpour and Dr. M Chen from Newcastle University, who collected the data.","c50db9bf":"### Importing all the required libraries","dfd4cead":"#### The transformations for the training dataset that we use here are:-\n1. RandomRotation(10): It rotates the image randomly upto a degree of 10\n\n2. RandomShift(6): It shifts the image randomly by a pixel value of upto 6(i.e roughly 10% shift)\n\n3. RandomResizedCrop(64): Randomly crops out a section from the image and resizes it to 64 * 64 pixels.","4fef8363":"#### Spilting Dataset into 80% train and 20% validation","2407778e":"### CNN Model Architecture 1 ","47760c6e":"### Improvements that can be made:-\n1. Trying a different CNN architecture.\n2. Tuning the existing model parameters even more to perform better.\n3. Trying out other model ensemble techniques for better performance","8a7b323e":"#### Architecture highlights:\n1. 4 CNN layers each followed by BatchNorm.\n2. 3 MaxPooling layers used to shrink the image channel.\n3. 3 Fully connected layears used for final classification","ee8330d5":"### Data Description\n\nThe Training_data contains images of numbers written in chinese.\ntrain.csv has got a column 'code', it is a coded representation of the chinese numbers, this code is the target variable and the id column carries the name of the image in the Training_Data Folder and the code columns gives the corresponding code.\n\nThis is what the Chinese codes stand for, but not at all useful to us.\n\ncode==>Chinese number\n\n1) 1 ==> 0\n2) 2 ==> 1\n3) 3 ==> 2\n4) 4 ==> 3\n5) 5 ==> 4\n6) 6 ==> 5\n7) 7 ==> 6\n8) 8 ==> 7\n9) 9 ==> 8\n10) 10 ==> 9\n11) 11 ==> 10\n12) 12 ==> 100\n13) 13 ==> 1000\n14) 14 ==> 10000\n15) 15 ==> 100000000","abcd0682":"### Modelling"}}