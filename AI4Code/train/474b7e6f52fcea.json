{"cell_type":{"3bea01eb":"code","2aac86ae":"code","a22f93f3":"code","069e08e7":"code","1d95415c":"code","cdf3f2c1":"code","37d05101":"code","c0fa0eaa":"code","7758d07b":"code","98e6243c":"code","04eb77e8":"code","97322f9d":"markdown","d09ca603":"markdown","0fa6f5c8":"markdown","2c9fc006":"markdown","129b11fe":"markdown","0cab581a":"markdown","faf7786d":"markdown","a0bd59b7":"markdown","2d6c6683":"markdown","de9d61f2":"markdown","1b247223":"markdown","8dc4c3a2":"markdown","ff752eb7":"markdown","28f5c24e":"markdown","e8d8130d":"markdown","7207caa7":"markdown","d0177340":"markdown","a3ab1def":"markdown"},"source":{"3bea01eb":"#Import numerical libraries\nimport numpy as np\nfrom numpy import array\nimport pandas as pd\n\n#Import graphical plotting libraries\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n#Import resampling and modeling algorithms\nfrom sklearn.utils import resample # for Bootstrap sampling\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n#KFold CV\nfrom sklearn.model_selection import KFold, LeaveOneOut\nfrom sklearn.model_selection import cross_val_score\n\nimport warnings\nwarnings.filterwarnings('ignore')","2aac86ae":"data = pd.read_csv('..\/input\/handson-pima\/Hands on Exercise Feature Engineering_ pima-indians-diabetes (1).csv')\ndata.head()\n\nvalues = data.values","a22f93f3":"#Lets configure Bootstrap\n\nn_iterations = 10  #No. of bootstrap samples to be repeated (created)\nn_size = int(len(data) * 0.50) #Size of sample, picking only 50% of the given data in every bootstrap sample","069e08e7":"#Lets run Bootstrap\nstats = list()\nfor i in range(n_iterations):\n\n    #prepare train & test sets\n    train = resample(values, n_samples = n_size) #Sampling with replacement..whichever is not used in training data will be used in test data\n    test = np.array([x for x in values if x.tolist() not in train.tolist()]) #picking rest of the data not considered in training sample\n    \n    #fit model\n    model = DecisionTreeClassifier()\n    model.fit(train[:,:-1], train[:,-1]) #model.fit(X_train,y_train) i.e model.fit(train set, train label as it is a classifier)\n    \n    #evaluate model\n    predictions = model.predict(test[:,:-1]) #model.predict(X_test)\n    score = accuracy_score(test[:,-1], predictions) #accuracy_score(y_test, y_pred)\n    #caution, overall accuracy score can mislead when classes are imbalanced\n    \n    print(score)\n    stats.append(score)","1d95415c":"#Lets plot the scores to better understand this visually\n\nplt.hist(stats)\nplt.figure(figsize = (10,5))","cdf3f2c1":"#Lets find Confidence intervals\n\na = 0.95 # for 95% confidence\np = ((1.0 - a)\/2.0) * 100 #tail regions on right and left .25 on each side indicated by P value (border)\n                          # 1.0 is total area of this curve, 2.0 is actually .025 thats the space we would want to be \n                            #left on either side\nlower = max(0.0, np.percentile(stats,p))\n\np = (a + ((1.0 - a)\/ 2.0)) * 100 #p is limits\nupper = min(1.0, np.percentile(stats,p))\nprint('%.1f confidence interval %.1f%% and %.1f%%' %(a*100, lower*100, upper*100))","37d05101":"#Create separate arrays such that only values are considered as X, y\nvalues = data.values\nX = values[:,0:8]\ny = values[:,8]\n\n#Split the data into train,test set\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.50, random_state = 1)","c0fa0eaa":"#Lets configure Cross Validation\n#default value of n_splits = 10\nkfold = KFold(n_splits = 50, random_state = 7)\nmodel = LogisticRegression()\nresults = cross_val_score(model,X,y,cv = kfold)","7758d07b":"print(results)","98e6243c":"#What's the accuracy of this model using KFold CV\n\nprint('Accuracy:  %.3f%% (%.3f%%)' % (results.mean()*100.0, results.std()*100.0))","04eb77e8":"# scikit-learn k-fold cross-validation\n\n# data sample\ndata = array([10,20,30,40,50,60,70,80,90,100])\n# prepare cross validation\nloocv = LeaveOneOut()\n# enumerate splits\nfor train, test in loocv.split(data):\n    print('train: %s, test: %s' % (data[train], data[test]))","97322f9d":"Here the dataset k is split into k-1 train sets and 1 test set.","d09ca603":"### Agenda - LOOCV\n\n* Provide a dataset with values\n* Fit LOOCV and print the train, test set values\n* Calculate accuracy of this model","0fa6f5c8":"**As the no. of iterations are increased, this histogram tends to acquire a Normal distribution. Increasing the no. of iterations from 10 to 100 or 500 would give a better histogram.**","2c9fc006":"### Agenda - KFold CV\n\n* Fit Logistic Regression and compute cross_val_score\n* Calculate accuracy of this model","129b11fe":"# 1. Load packages and observe dataset","0cab581a":"*For further info: https:\/\/machinelearningmastery.com\/a-gentle-introduction-to-the-bootstrap-method\/*\n*and https:\/\/datascience.stackexchange.com\/questions\/32264\/what-is-the-difference-between-bootstrapping-and-cross-validation *","faf7786d":"Here each Bootstrap iteration sample would create one model and this model is tested against the Out of Bag (test data) of that sample, i.e we will test that sample with the test sample not part of that sample.\n\n**Thus we obtain accuracy scores for 10 samples.**","a0bd59b7":"Since 50 n_folds is requested hence you received 50 iterations of this test set. For 50 test sets, 50 training sets are created and it gives 50 different accuracy scores.","2d6c6683":"Here the data comprises of an array from 10 - 100, LOOCV will leave one of these values out as a test value.","de9d61f2":"# 3.b Cross Validation - Leave One Out CV","1b247223":"# 2. Bootstrap sampling method","8dc4c3a2":"Here a random function is used to create samples from original data. Within a sample set, there could be duplicates or more however 2 sample sets are unlikely to be 100% same. Due to the drawing with replacement, a bootstrapped data set may contain multiple instances of the same original cases, and may completely omit other original cases.\n\nThis technique is used in machine learning to estimate the skill of machine learning models when making predictions on data not included in the training set. This technique helps to fine tune the model even before we give it access to test data (real world data). This allows us to tweak the model hyperparameters to achieve the best score.\n\nBootstrapping is primarily used to establish empirical distribution functions for a widespread range of statistics.\n\nA desirable property of the results from estimating machine learning model skills is that the estimated skill can be presented with confidence intervals, a feature not readily available with other methods such as Cross Validation.","ff752eb7":"### Agenda - Bootstrap sampling\n\n* Configure bootstrap\n* Run bootstrap in train, test data and obtain accuracy scores\n* Visual representation using Histogram and derive Confidence levels ","28f5c24e":"### Confidence Intervals\nConfidence intervals refers to the % of all possible samples that can be expected to include the true population parameter.\n\nFor eg. 95% of all samples would be found in this interval range.","e8d8130d":"**This model is likely to give an accuracy score of 77.017 +- 10.621(std dev). Putting this in normal distribution, you will get the score as per Central Limit theorem**","7207caa7":"# Resampling Methods\n\nProcess of repeatedly drawing samples from a data set and refitting a given model on each sample with the goal of learning more about the fitted model. Resampling methods can be expensive since they require repeatedly performing the same statistical methods on N different subsets of the data.\n\n**Following are types of resampling methods:**\n* Bootstrap Sampling\n* K Fold Cross Validation\n* Leave One Out Cross Validation","d0177340":"Cross validation resamples without replacement and thus produces surrogate data sets that are smaller than the original. These data sets are produced in a systematic way so that after a pre-specified number k of surrogate data sets, each of the n original cases has been left out exactly once. This is called k-fold cross validation or leave-x-out cross validation with x = n\/k, e.g. leave-one-out cross validation omits 1 case for each surrogate set, i.e. k=n.\n\nPrimary purpose of CV is measuring performance of a model","a3ab1def":"# 3.a Cross Validation - KFold"}}