{"cell_type":{"b08e5661":"code","74241eae":"code","943ecd71":"code","7e03ef2c":"code","27ba30bf":"code","047edaaa":"code","cdb6e68d":"code","504dbb3e":"code","fdfd369c":"code","ee6e9ae2":"code","b2b9332d":"code","51757b0f":"code","e05f3da7":"code","4daa8959":"code","f7c2cf3b":"code","c9a4e57b":"code","abe2daac":"code","08296d13":"code","13877180":"code","6f9e2c18":"code","3b7abbfb":"code","8030411d":"code","c4736faa":"code","8fcf1046":"code","59591dd4":"code","c74daee9":"code","5ef880bd":"code","18f6f246":"code","98b13893":"code","c47c2c6f":"code","7fee663e":"code","42fbbf99":"code","61eb8913":"code","50dfd02f":"code","44395445":"code","a1e1c391":"code","1bfe527c":"code","78059de8":"code","2c6c4f02":"markdown","4fe73b17":"markdown","c1d13e21":"markdown","fb963536":"markdown","171bb579":"markdown","693f8f92":"markdown","6aca3095":"markdown","1f373179":"markdown","bf6e9663":"markdown","1b3cb9e9":"markdown","45798bb8":"markdown","3d5167b7":"markdown"},"source":{"b08e5661":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","74241eae":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly as pl\nimport plotly.express as px\nimport plotly.figure_factory as ff\n\nimport plotly.graph_objects as go\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)","943ecd71":"df = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')","7e03ef2c":"df.head()","27ba30bf":"df.shape","047edaaa":"df.info()","cdb6e68d":"cols = ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']\n\nfor i in range(len(cols)):\n    mean = df[cols[i]].mean()\n    df[cols[i]] = df[cols[i]].replace(0, mean)","504dbb3e":"df['Outcome'].value_counts()","fdfd369c":"vals = list(df['Outcome'].value_counts())\nlabel = ['Non-diabetic', 'Diabetic']","ee6e9ae2":"fig = go.Figure(data=[go.Pie(labels=label, values=vals, title = 'Diabetic and Non-Diabetic', hole = 0.45)])\nfig.show()","b2b9332d":"df['Pregnancies'].value_counts()","51757b0f":"sns.set_style('whitegrid')","e05f3da7":"plt.figure(figsize=(20,8))\nsns.countplot(x = 'Pregnancies', data = df, hue = 'Outcome')","4daa8959":"corr_fea = df.corr()\nplt.figure(figsize=(12,10))\nsns.heatmap(corr_fea, annot = True)","f7c2cf3b":"df['Glucose'].value_counts()","c9a4e57b":"diabetic_only = df.loc[df['Outcome'] == 1]","abe2daac":"diabetic_only.head()","08296d13":"sns.jointplot(data=diabetic_only, y=\"Age\", x=\"BloodPressure\", kind=\"hex\", height = 8)","13877180":"sns.jointplot(data=diabetic_only, y =\"Age\", x =\"BMI\", kind=\"hex\", height = 8)","6f9e2c18":"X =  df.drop('Outcome',  axis = 1)\ny = df['Outcome']","3b7abbfb":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","8030411d":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","c4736faa":"from xgboost import XGBClassifier\nclassifier = XGBClassifier()\nclassifier.fit(X_train, y_train)","8fcf1046":"from sklearn.metrics import confusion_matrix, accuracy_score\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","59591dd4":"from sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))","c74daee9":"from sklearn.naive_bayes import GaussianNB\n\n# create Gaussian Naive Bayes model object and train it with the data\nnb_model = GaussianNB()\n\nnb_model.fit(X_train, y_train.ravel())","5ef880bd":"# predict values using training data\nnb_predict_train = nb_model.predict(X_train)\n\n# import the performance metrics library from scikit learn\nfrom sklearn import metrics\n\n# check naive bayes model's accuracy\nprint(\"Accuracy: {0:.4f}\".format(metrics.accuracy_score(y_train,nb_predict_train)))\nprint()","18f6f246":"nb_predict_test=nb_model.predict(X_test)\n\nfrom sklearn import metrics\n\nprint(\"Accuracy:{0:.4f}\".format(metrics.accuracy_score(y_test,nb_predict_test)))","98b13893":"print(\"Confusion Matrix\")\nprint(\"{0}\".format(metrics.confusion_matrix(y_test,nb_predict_test)))\nprint(\"\")","c47c2c6f":"print(\"Classification Report\")\nprint(\"{0}\".format(metrics.classification_report(y_test,nb_predict_test)))","7fee663e":"from sklearn.ensemble import RandomForestClassifier\nrf_model = RandomForestClassifier(random_state=42) \nrf_model.fit(X_train,y_train.ravel())","42fbbf99":"rf_predict_train = rf_model.predict(X_train)\nprint(\"Accuracy: {0:.4f}\".format(metrics.accuracy_score(y_train,rf_predict_train)))\nprint()","61eb8913":"\nrf_predict_test = rf_model.predict(X_test)\nprint(\"Accuracy:{0:.4f}\".format(metrics.accuracy_score(y_test,rf_predict_test)))\nprint()\n","50dfd02f":"\nprint(\"Confusion Matrix\")\nprint(metrics.confusion_matrix(y_test, rf_predict_test) )\nprint(\"\")","44395445":"print(\"Classification Report\")\nprint(metrics.classification_report(y_test, rf_predict_test))","a1e1c391":"from sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nclassifier.fit(X_train, y_train)","1bfe527c":"y_pred = classifier.predict(X_test)\n","78059de8":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","2c6c4f02":"# TRAINING AND TESTING DATA ON DIFFERENT MODELS","4fe73b17":"### Most of the diabetic people that were of **age between 25 to 50** and was having blood pressure **between 60 to 80** approx. \n### But **Normal blood pressure of an adult is 120\/80 mm Hg** *(source: internet)*. We can say that Dibetic patients experience problem of low Blood Pressure.\n\nFor more info: https:\/\/www.diabetesselfmanagement.com\/blog\/when-is-blood-pressure-too-low\/#:~:text=Diabetic%20neuropathy%3A%20People%20who%20have,nerve%20damage%20called%20autonomic%20neuropathy.","c1d13e21":"# SCALING THE DATA","fb963536":"Some of the columns had zero values. So let's replace them with the mean","171bb579":"# RandomForestClassifier","693f8f92":"# KNeighborsClassifier","6aca3095":"## XGGBOOST","1f373179":"## Naive_bayes","bf6e9663":"# SPLITTING THE DATASET","1b3cb9e9":"### Most of the diabetic people that were of **age between 25 to 60** had BMI between 25 to 45 i.e. they were overweight or obese (Normal BMI is 18.5 \u2013 24.9 (source: internet)). \n","45798bb8":"# IMPORTING LIBRARIES","3d5167b7":"# IMPORTING DATASET"}}