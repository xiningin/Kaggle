{"cell_type":{"6b93252d":"code","142c7657":"code","b6a632d7":"code","05831941":"code","d664c918":"code","f391e60c":"code","9fa36812":"code","d1365a6a":"code","9b856bfd":"code","6a08c7e6":"code","67416319":"code","b5138d01":"markdown","afbfd6d2":"markdown","96f960b1":"markdown","2cd6642f":"markdown","8a185b93":"markdown","f968bec6":"markdown","41016897":"markdown","39b56eba":"markdown","328af327":"markdown","bf72bc98":"markdown","c562be25":"markdown","d5a3a376":"markdown","396d1fd0":"markdown","2d45372f":"markdown","eb716e0f":"markdown","488c7f9d":"markdown","f2181a6c":"markdown","74a22c7b":"markdown","95e5a1c8":"markdown","4defba30":"markdown"},"source":{"6b93252d":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt#visualization\nfrom PIL import  Image\n%matplotlib inline\nimport seaborn as sns#visualization\nimport itertools\nimport warnings\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\nwarnings.filterwarnings(\"ignore\")\nimport io\nimport plotly.offline as py#visualization\npy.init_notebook_mode(connected=True)#visualization\nimport plotly.graph_objs as go#visualization\nimport plotly.tools as tls#visualization\nimport plotly.figure_factory as ff#visualization","142c7657":"\nrandom_state = 42\nnp.random.seed(random_state)\ndf_train = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')\ndata = pd.read_csv('..\/input\/train.csv')\ndata.shape","b6a632d7":"data.describe()","05831941":"#labels\nlab = data[\"target\"].value_counts().keys().tolist()\n#values\nval = data[\"target\"].value_counts().values.tolist()\n\ntrace = go.Pie(labels = lab ,\n               values = val ,\n               marker = dict(colors =  [ 'royalblue' ,'lime'],\n                             line = dict(color = \"white\",\n                                         width =  1.3)\n                            ),\n               rotation = 90,\n               hoverinfo = \"label+value+text\",\n               hole = .5\n              )\nlayout = go.Layout(dict(title = \"class imbalance\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                       )\n                  )\n\ndata1 = [trace]\nfig = go.Figure(data = data1,layout = layout)\npy.iplot(fig)","d664c918":"features = [c for c in data.columns if c not in ['ID_code', 'target']]\nX = data[features].head(n=5000)\nY = data['target'].head(n=5000)\n\ndef tsne_plot(x1, y1, name=\"graph.png\"):\n    tsne = TSNE(n_components=2, random_state=0)\n    X_t = tsne.fit_transform(x1)\n\n    plt.figure(figsize=(20, 8))\n    plt.scatter(X_t[np.where(y1 == 0), 0], X_t[np.where(y1 == 0), 1], marker='o', color='g', linewidth='1', alpha=0.8, label='0')\n    plt.scatter(X_t[np.where(y1 == 1), 0], X_t[np.where(y1 == 1), 1], marker='o', color='r', linewidth='1', alpha=0.8, label='1')\n\n    plt.legend(loc='best');\n    plt.show();\n    \ntsne_plot(X, Y, \"tsne.png\")","f391e60c":"X = data.iloc[:,1:202]\n\npca = PCA(2)  \nprojected = pca.fit_transform(X)\n\nplt.figure(figsize=(20, 8))\nplt.scatter(projected[:, 0], projected[:, 1],\n            c=X['target'], edgecolor='none', alpha=0.5,\n            cmap=plt.cm.get_cmap('YlGnBu', 10))\nplt.xlabel('component 1')\nplt.ylabel('component 2')\nplt.colorbar();","9fa36812":"\ndef process_data(df_train, df_test):\n    idx = [c for c in df_train.columns if c not in ['ID_code', 'target']]\n    for df in [df_test, df_train]:\n        for feat in idx:\n            df['r2_'+feat] = np.round(df[feat], 2)\n            df['r2_'+feat] = np.round(df[feat], 2)\n        #df['sum'] = df[idx].sum(axis=1)\n        #df['min'] = df[idx].min(axis=1)\n        #df['max'] = df[idx].max(axis=1)\n        #df['mean'] = df[idx].mean(axis=1)\n        df['std'] = df[idx].std(axis=1)\n        df['skew'] = df[idx].skew(axis=1)\n        df['kurt'] = df[idx].kurtosis(axis=1)\n        df['med'] = df[idx].median(axis=1)\n    print('Train and test shape:',df_train.shape, df_test.shape)\n    return df_train, df_test\n\n\n#process_data(df_train,df_test)\n\n\ndef augment(x,y,t=2):\n    xs,xn = [],[]\n    for i in range(t):\n        mask = y>0\n        x1 = x[mask].copy()\n        ids = np.arange(x1.shape[0])\n        for c in range(x1.shape[1]):\n            np.random.shuffle(ids)\n            x1[:,c] = x1[ids][:,c]\n        xs.append(x1)\n\n    for i in range(t\/\/2):\n        mask = y==0\n        x1 = x[mask].copy()\n        ids = np.arange(x1.shape[0])\n        for c in range(x1.shape[1]):\n            np.random.shuffle(ids)\n            x1[:,c] = x1[ids][:,c]\n        xn.append(x1)\n\n    xs = np.vstack(xs)\n    xn = np.vstack(xn)\n    ys = np.ones(xs.shape[0])\n    yn = np.zeros(xn.shape[0])\n    x = np.vstack([x,xs,xn])\n    y = np.concatenate([y,ys,yn])\n    return x,y\n\n","d1365a6a":"\nlgb_params = {\n    \"objective\" : \"binary\",\n    \"metric\" : \"auc\",\n    \"boosting\": 'gbdt',\n    \"max_depth\" : -1,\n    \"num_leaves\" : 13,\n    \"learning_rate\" : 0.01,\n    \"bagging_freq\": 5,\n    \"bagging_fraction\" : 0.335,\n    \"feature_fraction\" : 0.041,\n    \"min_data_in_leaf\": 80,\n    \"min_sum_hessian_in_leaf\": 10,\n    \"tree_learner\": \"serial\",\n    \"boost_from_average\": \"false\",\n    \"num_threads\": 4,\n    \"scale_pos_weight\":0.8882836,\n    #\"lambda_l1\" : 5,\n    #\"lambda_l2\" : 5,\n    \"bagging_seed\" : random_state,\n    \"verbosity\" : -1,\n    \"seed\": random_state\n}","9b856bfd":"\ntarget = df_train['target']\nnum_folds = 8\nfeatures = [c for c in df_train.columns if c not in ['ID_code', 'target']]\n\nfolds = KFold(n_splits=num_folds, random_state=2319)\noof = np.zeros(len(df_train))\ngetVal = np.zeros(len(df_train))\npredictions = np.zeros(len(target))\nfeature_importance_df = pd.DataFrame()\n\nprint('Light GBM Model')\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train.values, target.values)):\n    X_train, y_train = df_train.iloc[trn_idx][features], target.iloc[trn_idx]\n    X_valid, y_valid = df_train.iloc[val_idx][features], target.iloc[val_idx]\n\n    #N = 2\n    #for i in range(N):\n        #print(\"fold split:{}\".format(fold_ + 1))\n        #print(\"fold N:{}\".format(i))\n\n    X_tr, y_tr = augment(X_train.values, y_train.values)\n    X_tr = pd.DataFrame(X_tr)\n\n    print(\"Fold idx:{}\".format(fold_ + 1))\n    trn_data = lgb.Dataset(X_tr, label=y_tr)\n    val_data = lgb.Dataset(X_valid, label=y_valid)\n    val_data = lgb.Dataset(df_train.iloc[val_idx][features], label=target.iloc[val_idx])\n\n    clf = lgb.train(lgb_params, trn_data, 1000000, valid_sets=[trn_data, val_data], verbose_eval=4000,\n                    early_stopping_rounds=4000)\n    oof[val_idx] = clf.predict(df_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    getVal[val_idx] += clf.predict(df_train.iloc[val_idx][features], num_iteration=clf.best_iteration) \/ folds.n_splits\n\n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = features\n    fold_importance_df[\"importance\"] = clf.feature_importance()\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n\n    predictions += clf.predict(df_test[features], num_iteration=clf.best_iteration) \/ folds.n_splits\n\nprint(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))\n","6a08c7e6":"\nnum_sub = 10\nprint('Saving the Submission File')\nsub = pd.DataFrame({\"ID_code\": df_test.ID_code.values})\nsub[\"target\"] = predictions\nsub.to_csv('submission{}.csv'.format(num_sub), index=False)\n","67416319":"cols = (feature_importance_df[[\"feature\", \"importance\"]]\n        .groupby(\"feature\")\n        .mean()\n        .sort_values(by=\"importance\", ascending=False)[:1000].index)\nbest_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\ndata=best_features.sort_values(by=\"importance\",ascending=False)\n\ndata = [go.Bar(\n            x=data['importance'],\n            y=data['feature'],\n            orientation = 'h'\n)]\n\nlayout = go.Layout(\n    title='Feature importance',\n    font=dict(family='Courier New, monospace', size=12, color='#9467bd'),\n    autosize=False,\n    width=1200,\n    height=2500,\n    plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n)\n\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig, filename='automargin')","b5138d01":"# <a id='2'>2.Libraries and Data<\/a>","afbfd6d2":"### <a id='3.3'>3.3.PCA<\/a>","96f960b1":"\n# <a id='6'>6.End notes<\/a>\n\n### References\n### https:\/\/www.kaggle.com\/gpreda\/santander-eda-and-prediction\n### https:\/\/www.kaggle.com\/roydatascience\/eda-pca-simple-lgbm-on-kfold-technique \n","2cd6642f":"### <a id='5.1'>5.1.Parameters<\/a>","8a185b93":"<h1><left><font size=\"6\"> Prediction with lightgbm model<\/font><\/center><\/h1>\n\n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/4\/4a\/Another_new_Santander_bank_-_geograph.org.uk_-_1710962.jpg\/640px-Another_new_Santander_bank_-_geograph.org.uk_-_1710962.jpg\"><\/img>\n","f968bec6":"### <a id='2.3'>2.3.Data Overview<\/a>","41016897":"- <a href='#1'>1.Introduction<\/a>\n    - <a href='#1.1'>1.1.overview<\/a>\n- <a href='#2'>2.Libraries and Data<\/a>\n    - <a href='#2.1'>2.1.Libraries<\/a>\n    - <a href='#2.2'>2.2.loading Data<\/a>\n    - <a href='#2.3'>2.3.Data overview<\/a>\n- <a href='#3'>3.Exploratory Data Analysis<\/a>\n    - <a href='#3.1'>3.1.class imbalance<\/a>\n    - <a href='#3.2'>3.2.TSNE plot<\/a>\n    - <a href='#3.3'>3.3.PCA<\/a>\n- <a href='#4'>4.Feature Engineering<\/a>\n    - <a href='#4.1'>4.1.New columns and augment<\/a>\n- <a href='#5'>5.Lightgbm Model Parameters and training<\/a>\n    - <a href='#5.1'>5.1.Parameters<\/a>\n    - <a href='#5.2'>5.2.Training<\/a>\n    - <a href='#5.3'>5.3.submission<\/a>\n    - <a href='#5.4'>5.4.Feature importance<\/a>\n- <a href='#6'>6.End notes<\/a>   \n    ","39b56eba":"### <a id='3.2'>3.2.TSNE plot<\/a>","328af327":"# <a id='3'>3.Exploratory Data Analysis<\/a>","bf72bc98":"### <a id='5.4'>5.4.Feature importance<\/a>","c562be25":"# <a id='4'>4.Feature Engineering<\/a>","d5a3a376":"# <a id='1'>1.Introduction<\/a>","396d1fd0":"### <a id='2.1'>2.1.Libraries<\/a>\n\nplotly and matplotlib are used for EDA. Lightgbm is used for training and prediction.","2d45372f":"### <a id='2.2'>2.2.Loading Data<\/a>","eb716e0f":"### <a id='5.3'>5.3.Submission<\/a>","488c7f9d":"### <a id='1.1'>1.1.overview<\/a>\n\nIn this challenge, Kagglers are invited to help identify which customers will make a specific transaction in the future, irrespective of the amount of money transacted. The data provided for this competition has the same structure as the real data we have available to solve this problem.","f2181a6c":"# <a id='5'>5.Lightgbm Model Parameters and training<\/a>","74a22c7b":"### <a id='5.2'>5.2.Training<\/a>","95e5a1c8":"### <a id='4.1'>4.1.New columns and augment<\/a>","4defba30":"### <a id='3.1'>3.1.class imbalance<\/a>"}}