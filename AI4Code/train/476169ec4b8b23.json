{"cell_type":{"40899677":"code","0943b1e4":"code","df08ebc0":"code","49e0afda":"code","721c8317":"code","7eea4075":"code","7aeba969":"code","1e5b8dd2":"code","4d2bc45c":"code","27a472c6":"code","c746ac33":"code","154d2677":"markdown","96b67d88":"markdown","a6c47714":"markdown","c1fb8e92":"markdown","d69efbb9":"markdown","237e354e":"markdown","a70c2ef8":"markdown","98e30a8e":"markdown","f507b84f":"markdown"},"source":{"40899677":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer, HashingVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier, PassiveAggressiveClassifier\nfrom sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\nfrom sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier, StackingClassifier, BaggingClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.gaussian_process import GaussianProcessClassifier","0943b1e4":"train = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")","df08ebc0":"train.head()","49e0afda":"vectorization_strategies = [\"tf-idf\", \"hasing\"]\nvectorization_strategy = vectorization_strategies[0]\nif vectorization_strategy == vectorization_strategies[0]:\n    vectorizer = TfidfVectorizer()\nif vectorization_strategy == vectorization_strategies[1]:\n    vectorizer = HashingVectorizer(n_features=2**14, alternate_sign=False)\n    #vectorizer = HashingVectorizer(alternate_sign=False)\ntrain_vec = vectorizer.fit_transform(train[\"text\"])\ntest_vec = vectorizer.transform(test[\"text\"])","721c8317":"x_train, x_val, y_train, y_val = train_test_split(train_vec, train[\"target\"], random_state=42)\nx_train.shape, x_val.shape, y_train.shape, y_val.shape","7eea4075":"from sklearn.metrics import confusion_matrix, accuracy_score\nimport seaborn as sns\ndef run_experiment(model, x_train, y_train, x_val, y_val):\n    model.fit(x_train, y_train)\n    y_pred = model.predict(x_val)\n    acc = accuracy_score(y_val, y_pred)\n    cm = confusion_matrix(y_val, y_pred)\n    print(\"Validation Accuracy:%.2f\"%(acc))\n    sns.heatmap(cm, annot=True)\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n    metric = dict()\n    metric[\"accuracy\"] = acc\n    metric[\"confusion_matrix\"] = cm\n    return model, metric","7aeba969":"models = []\nmetrics = []\nbase_models = [\n    # Linear Models\n    LogisticRegression(),\n    RidgeClassifier(),\n    SGDClassifier(),\n    # Naive Bayes\n    PassiveAggressiveClassifier(),\n    BernoulliNB(),\n    ComplementNB(),\n    MultinomialNB(),\n    # Tree\n    ExtraTreeClassifier(),\n    DecisionTreeClassifier(),\n    # Ensemble\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    GradientBoostingClassifier(),\n    # Neurlal Network\n    MLPClassifier(), \n    # Gaussian Process\n    #GaussianProcessClassifier(kernel=RBF(1.0))\n]\nfor model in base_models:\n    print(\"Classification with %s\"%(model))\n    model, metric = run_experiment(\n        model, \n        x_train, y_train, x_val, y_val\n    )\n    models.append(model)\n    metrics.append(metric)","1e5b8dd2":"estimators = [(str(model), model) for model in [LogisticRegression(), BernoulliNB(), ComplementNB(), MultinomialNB()]]\n# If \u2018hard\u2019, uses predicted class labels for majority rule voting. \n# If \u2018soft\u2019, predicts the class label based on the argmax of the sums of the predicted probabilities.\nvoting_classifier = VotingClassifier(estimators=estimators, voting='soft')\nvoting_classifier, _ = run_experiment(voting_classifier, x_train, y_train, x_val, y_val)","4d2bc45c":"stacking_classifier = StackingClassifier(estimators=estimators)\nstacking_classifier, _ = run_experiment(stacking_classifier, x_train, y_train, x_val, y_val)","27a472c6":"from sklearn.svm import SVC\nbagging_classfier = BaggingClassifier(base_estimator=SVC())\nbagging_classfier, _ = run_experiment(bagging_classfier, x_train, y_train, x_val, y_val)","c746ac33":"submit_types = [\"voting\", \"stacking\", \"bagging\", \"ensemble\"]\nsubmit_type = submit_types[3]\nif submit_type == submit_types[0]:\n    result = voting_classifier.predict(test_vec)\nif submit_type == submit_types[1]:\n    result = stacking_classifier.predict(test_vec)\nif submit_type == submit_types[2]:\n    result = bagging_classfier.predict(test_vec)\nif submit_type == submit_types[3]:\n    result = np.array(np.mean([classifier.predict_proba(test_vec)[:, 1] for classifier in [voting_classifier, stacking_classifier, bagging_classfier]], axis=0) > 0.5, dtype=int)\nsubmission = pd.DataFrame({\"id\": test[\"id\"], \"target\": result})\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","154d2677":"## Ensemble with StackingClassifier","96b67d88":"### Ensemble with Voting Classifier","a6c47714":"### Ensemble with Bagging Classfier","c1fb8e92":"# Text Classification with SKLearn","d69efbb9":"### Text Vectorization","237e354e":"### Modelling","a70c2ef8":"### Import datasets","98e30a8e":"## Submission","f507b84f":"### Train Validation Split"}}