{"cell_type":{"f1fdeb04":"code","b7f99a0b":"code","cd95e90d":"code","1f198c07":"code","d1785138":"code","ad38724c":"code","649a4d2f":"code","6d46d89e":"code","fc0bc3b4":"code","5f15ed32":"code","8eb941a2":"markdown","06736fd3":"markdown","60ce1507":"markdown","c5637044":"markdown","c79aa9ed":"markdown","d732951f":"markdown"},"source":{"f1fdeb04":"ComputeLB = False\nDogsOnly = True\n\nimport numpy as np, pandas as pd, os\nimport xml.etree.ElementTree as ET \nimport matplotlib.pyplot as plt, zipfile \nfrom PIL import Image \n\nROOT = '..\/input\/generative-dog-images\/'\nif not ComputeLB: ROOT = '..\/input\/'\nIMAGES = os.listdir(ROOT + 'all-dogs\/all-dogs\/')\nbreeds = os.listdir(ROOT + 'annotation\/Annotation\/') \n\nidxIn = 0; namesIn = []\nimagesIn = np.zeros((25000,64,64,3))\n\n# CROP WITH BOUNDING BOXES TO GET DOGS ONLY\nif DogsOnly:\n    for breed in breeds:\n        for dog in os.listdir(ROOT+'annotation\/Annotation\/'+breed):\n            try: img = Image.open(ROOT+'all-dogs\/all-dogs\/'+dog+'.jpg') \n            except: continue           \n            tree = ET.parse(ROOT+'annotation\/Annotation\/'+breed+'\/'+dog)\n            root = tree.getroot()\n            objects = root.findall('object')\n            for o in objects:\n                bndbox = o.find('bndbox') \n                xmin = int(bndbox.find('xmin').text)\n                ymin = int(bndbox.find('ymin').text)\n                xmax = int(bndbox.find('xmax').text)\n                ymax = int(bndbox.find('ymax').text)\n                w = np.min((xmax - xmin, ymax - ymin))\n                img2 = img.crop((xmin, ymin, xmin+w, ymin+w))\n                img2 = img2.resize((64,64), Image.ANTIALIAS)\n                imagesIn[idxIn,:,:,:] = np.asarray(img2)\n                #if idxIn%1000==0: print(idxIn)\n                namesIn.append(breed)\n                idxIn += 1\n                \n# RANDOMLY CROP FULL IMAGES\nelse:\n    x = np.random.choice(np.arange(20000),10000)\n    for k in range(len(x)):\n        img = Image.open(ROOT + 'all-dogs\/all-dogs\/' + IMAGES[x[k]])\n        w = img.size[0]; h = img.size[1];\n        if (k%2==0)|(k%3==0):\n            w2 = 100; h2 = int(h\/(w\/100))\n            a = 18; b = 0          \n        else:\n            a=0; b=0\n            if w<h:\n                w2 = 64; h2 = int((64\/w)*h)\n                b = (h2-64)\/\/2\n            else:\n                h2 = 64; w2 = int((64\/h)*w)\n                a = (w2-64)\/\/2\n        img = img.resize((w2,h2), Image.ANTIALIAS)\n        img = img.crop((0+a, 0+b, 64+a, 64+b))  \n        imagesIn[idxIn,:,:,:] = np.asarray(img)\n        namesIn.append(IMAGES[x[k]])\n        #if idxIn%1000==0: print(idxIn)\n        idxIn += 1\n    \n# DISPLAY CROPPED IMAGES\nx = np.random.randint(0,idxIn,25)\nfor k in range(5):\n    plt.figure(figsize=(15,3))\n    for j in range(5):\n        plt.subplot(1,5,j+1)\n        img = Image.fromarray( imagesIn[x[k*5+j],:,:,:].astype('uint8') )\n        plt.axis('off')\n        if not DogsOnly: plt.title(namesIn[x[k*5+j]],fontsize=11)\n        else: plt.title(namesIn[x[k*5+j]].split('-')[1],fontsize=11)\n        plt.imshow(img)\n    plt.show()","b7f99a0b":"from keras.models import Model\nfrom keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Reshape, BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.optimizers import SGD, Adam","cd95e90d":"# BUILD GENERATIVE NETWORK\ndirect_input = Input((10000,))\nx = Dense(2048, activation='elu')(direct_input)\nx = Reshape((8,8,32))(x)\nx = Conv2D(128, (3, 3), activation='elu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(64, (3, 3), activation='elu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(32, (3, 3), activation='elu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\ndecoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n\n# COMPILE\ndecoder = Model(direct_input, decoded)\ndecoder.compile(optimizer=Adam(lr=0.005), loss='binary_crossentropy')\n\n# DISPLAY ARCHITECTURE\ndecoder.summary()","1f198c07":"# TRAINING DATA\nidx = np.random.randint(0,idxIn,10000)\ntrain_y = imagesIn[idx,:,:,:]\/255.\ntrain_X = np.zeros((10000,10000))\nfor i in range(10000): train_X[i,i] = 1","d1785138":"# TRAIN NETWORK\nlr = 0.005\nfor k in range(50):\n    annealer = LearningRateScheduler(lambda x: lr)\n    h = decoder.fit(train_X, train_y, epochs = 10, batch_size=256, callbacks=[annealer], verbose=0)\n    if k%5==4: print('Epoch',(k+1)*10,'\/500 - loss =',h.history['loss'][-1] )\n    if h.history['loss'][-1]<0.54: lr = 0.001","ad38724c":"del train_X, train_y, imagesIn","649a4d2f":"from PIL import Image, ImageDraw\nfrom IPython.display import Image as IMG ","6d46d89e":"gifs = []\nsteps = 10\nfor k in range(5): \n    a = np.random.randint(10000)\n    b = np.random.randint(10000)\n    print('Walk in Latent Space - IMAGE ',k, ' = gif',k)\n    frames = []\n    plt.figure(figsize=(20,3))\n    for j in range(steps*2):\n        xx = np.zeros((10000))\n        theta = j%steps\/(steps-1)\n        if j>=steps: theta = 1-j%steps\/(steps-1)\n        xx[a] = theta; xx[b] = 1-theta\n        xx = xx\/(np.sqrt(xx.dot(xx.T)))\n        img = decoder.predict(xx.reshape((-1,10000)))\n        img = Image.fromarray( (255*img).astype('uint8').reshape((64,64,3)))\n        #img = img.resize((150,150))\n        frames.append(img)\n        if j < steps: \n            plt.subplot(1,steps,j+1)\n            plt.axis('off')\n            plt.imshow(img)\n    plt.show()\n    gifs.append(frames)","fc0bc3b4":"for index,gif in enumerate(gifs):\n    frames = gif\n    frames[0].save('dogs_'+str(index)+'.gif', format='GIF', append_images=frames[1:], save_all=True, duration=150, loop=0)","5f15ed32":"#IMG(filename='dogs_0.gif', width=200, height = 200)","8eb941a2":"**Generate the gifs**","06736fd3":"### Image 1\n\n<img src=\"dogs_0.gif\" height=\"200\" width=\"200\">\n<img src=\"dogs_1.gif\" height=\"200\" width=\"200\">\n\n---\n\n### Image 2\n\n<img src=\"dogs_2.gif\" height=\"200\" width=\"200\">\n<img src=\"dogs_3.gif\" height=\"200\" width=\"200\">\n\n---\n\n### Image 3\n\n<img src=\"dogs_4.gif\" height=\"200\" width=\"200\">\n<img src=\"dogs_5.gif\" height=\"200\" width=\"200\">\n\n---\n\n### Image 4\n\n<img src=\"dogs_6.gif\" height=\"200\" width=\"200\">\n<img src=\"dogs_7.gif\" height=\"200\" width=\"200\">\n\n---\n\n### Image 5\n\n<img src=\"dogs_8.gif\" height=\"200\" width=\"200\">\n<img src=\"dogs_9.gif\" height=\"200\" width=\"200\">","60ce1507":"### Train Generative Network","c5637044":"## Latent Walk \n\nIn the post **[Latent Walk Examples](https:\/\/www.kaggle.com\/c\/generative-dog-images\/discussion\/98719#latest-569381)** by [Chris Deotte](https:\/\/www.kaggle.com\/cdeotte) you can find more information about Latent Walks\n\n\n![](http:\/\/playagricola.com\/Kaggle\/exa7519.png)\n\n<br>\n\n### In this kernel I'm going to animate this walk. Like this:\n\n![](https:\/\/i1.wp.com\/media.scoutmagazine.ca\/2018\/12\/giphy-2.gif?fit=480%2C270&ssl=1)\n\n<br>\nAt the end, you'll be able to show your results as a gif :)\n\nMy **baseline** is the code from this amazing kernel: **[Supervised Generative Dog Net](https:\/\/www.kaggle.com\/cdeotte\/supervised-generative-dog-net)**\n","c79aa9ed":"# Walking in the Latent Space","d732951f":"### Build Generative Network"}}