{"cell_type":{"22b89a8f":"code","0c23652f":"code","9c5f6749":"code","47c4a8a5":"code","b0fa9cf5":"code","aa773f31":"code","07fe7b49":"code","9d5fdf4b":"code","d4a04370":"code","0afeffa9":"code","4083712c":"code","90b43c11":"code","0a996538":"code","fc45685d":"code","2c16b988":"code","f2c0bbe6":"code","d69a21c2":"code","78d3d23d":"code","a1f76ff8":"code","cd540e4a":"code","962c11d3":"code","a100a75a":"code","01a36be5":"code","cfd109df":"code","025dd80f":"code","fe87aed6":"code","d2f687d5":"code","4d902b79":"code","19677ee2":"code","c251a053":"code","e0d283ca":"code","c66ec0f7":"code","d675c2f9":"code","442ae25a":"code","ba06d895":"code","264018d2":"code","842e3131":"code","ec278890":"code","79b2a664":"code","163738cc":"code","e7531baf":"code","385d8ba0":"code","4d8e54e9":"code","fbd80bfd":"code","bd4668a2":"code","e841992a":"code","a9495fc1":"code","f124d06c":"code","aba4171c":"code","a28f4f5a":"code","074fff7a":"code","85117ed6":"code","9d3bff70":"code","f75c1173":"code","11f29f95":"code","287bdffe":"code","bf62036b":"code","86860036":"code","72672b86":"code","acd76eba":"code","0e8727fe":"code","6ab43482":"code","a12f7d2c":"code","eaa1548d":"code","40437401":"code","22101a8c":"code","a6fdfb4e":"code","154fd7d0":"code","015fd5a0":"code","8e7adedd":"code","e3c56a05":"code","1471cfc5":"code","cae78c0d":"code","0a58e404":"code","8f9f1cea":"code","a8eda5b4":"code","ed2eaafe":"code","cd302929":"code","503e3438":"code","2716fb61":"code","838bee8b":"code","86e7dd8d":"code","dac3189b":"code","df834720":"code","368bfe31":"code","4564f202":"code","1ea09ff0":"code","b4cb7ca6":"code","fe650171":"code","ef7a10b7":"code","a6bd2b81":"code","1b49417c":"code","eedf177f":"code","cd3dac9f":"code","6deda560":"code","d9164a5f":"code","eac46ab6":"code","9d11ecde":"code","cc02f5e2":"code","4d77406b":"code","75c6e399":"code","eab8b0be":"code","99b6c6b2":"code","202b96fd":"code","b5d35b7d":"code","4d69f7a9":"code","23eada39":"code","19b3153e":"code","471f0340":"code","585de383":"code","de7372c0":"code","706c5bf0":"code","aa8a7e7a":"code","5ab139f7":"code","9ccd1973":"code","6c9dcc56":"code","3ba15d29":"code","d805f3cf":"code","5f38483c":"code","e6d836a0":"code","2504cc03":"code","706a55d7":"code","0f034a8d":"code","ba79e918":"code","1fe5ff9b":"code","86b3bbb3":"markdown","4c0cd584":"markdown","62778024":"markdown","f47c653f":"markdown","43e4566a":"markdown","bd013007":"markdown","3831382d":"markdown","481eacab":"markdown","e1283842":"markdown","8fd66939":"markdown","a7870ba8":"markdown","d358892d":"markdown","16c6b25d":"markdown","54f0b75f":"markdown","fe100bcd":"markdown","5bb2426b":"markdown","156e13f4":"markdown","7520caa9":"markdown","99a26fcf":"markdown","9550ebb7":"markdown","455de264":"markdown","3ed64a3a":"markdown","df7165bf":"markdown","6b6c88d0":"markdown","12ac7dc4":"markdown","fe19c8fe":"markdown","342ee299":"markdown","f2ea8463":"markdown","1744b148":"markdown","41f047ef":"markdown","c7d64efc":"markdown","6a1a1d3c":"markdown","6069c9ca":"markdown","a6bb155a":"markdown","87da9872":"markdown","c033223c":"markdown","b2690109":"markdown","513f13e4":"markdown","8a21adfd":"markdown","4dcb085a":"markdown","98e3d9b0":"markdown","4ff48463":"markdown","399b11f3":"markdown","773c6550":"markdown","d5e71e1b":"markdown","e71b9133":"markdown","e700b3aa":"markdown","a64523d5":"markdown","56a98275":"markdown","23bfb80b":"markdown","fd028b6c":"markdown","4e161202":"markdown","f072bc77":"markdown","35f34d02":"markdown","d6a9f88f":"markdown","eb5a297d":"markdown","f5151eb5":"markdown","3e19ab81":"markdown","1447a1db":"markdown","54cd9521":"markdown","6170bf9e":"markdown","55ccda63":"markdown","812e2631":"markdown","2fc6ad25":"markdown","96e2204a":"markdown","87629239":"markdown","39b8cc7a":"markdown","88598c2b":"markdown","6808055f":"markdown","b8378d17":"markdown","b99be66d":"markdown","51bb3ba3":"markdown","97f8b946":"markdown","0d810abf":"markdown","dca4fdb7":"markdown","2dc4a941":"markdown","a02d30cd":"markdown","2bb60b44":"markdown","7c164f91":"markdown","1d8b2f75":"markdown"},"source":{"22b89a8f":"import pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom datetime import date\nfrom scipy import stats\nfrom scipy.stats import norm, skew #for some statistics\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.colors import n_colors\nfrom plotly.subplots import make_subplots","0c23652f":"import warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\npd.set_option(\"display.max_columns\",None)\npd.set_option(\"display.max_rows\",None)\nplt.style.use('seaborn')\n\nfrom collections import Counter\nimport datetime\nimport wordcloud\nimport json","9c5f6749":"df = pd.read_csv('..\/input\/startup-success-prediction\/startup data.csv')","47c4a8a5":"df.head(10)","b0fa9cf5":"df.info()","aa773f31":"df.columns","07fe7b49":"numeric=['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ndf_num=df.select_dtypes(include=numeric)\ndf_num.head(3)","9d5fdf4b":"df_cat=df.select_dtypes(include='object')\ndf_cat.head(3)","d4a04370":"df['status'] = df.status.map({'acquired':1, 'closed':0})","0afeffa9":"#Tipe data status diganti dari object ke int\ndf['status'].astype(int)","4083712c":"#labels dan status check similarity\nfor index, row in df.iterrows():\n    if row['labels']!=row['status']:\n        print(index, row['labels'], row['status'])","90b43c11":"#drop feature\ndf.drop([\"labels\"], axis=1, inplace=True)","0a996538":"describeNum = df.describe(include =['float64', 'int64', 'float', 'int'])\ndescribeNum.T.style.background_gradient(cmap='viridis',low=0.2,high=0.1)","fc45685d":"describeNumCat = df.describe(include=[\"O\"])\ndescribeNumCat.T.style.background_gradient(cmap='viridis',low=0.2,high=0.1)","2c16b988":"cats = ['state_code','zip_code','id','city','Unnamed: 6','name','founded_at','closed_at','first_funding_at','last_funding_at','state_code.1','category_code','object_id','status'] \nfor col in cats:\n    print(f'''Value count kolom {col}:''')\n    print(df[col].value_counts())\n    print()","f2c0bbe6":"null=pd.DataFrame(df.isnull().sum(),columns=[\"Null Values\"])\nnull[\"% Missing Values\"]=(df.isna().sum()\/len(df)*100)\nnull = null[null[\"% Missing Values\"] > 0]\nnull.style.background_gradient(cmap='viridis',low =0.2,high=0.1) ","d69a21c2":"# Checking Missing Values Column \ndf[[\"Unnamed: 6\", \"closed_at\", \"age_first_milestone_year\", \"age_last_milestone_year\", \"state_code.1\", \"status\"]].head(4)","78d3d23d":"df['Unnamed: 6'] = df.apply(lambda row: (row.city) + \" \" + (row.state_code) + \" \" +(row.zip_code)  , axis = 1)\ndf.head()","a1f76ff8":"# Total Missing Values kolom \"Unnamed: 6\"\ntotalNull = df['Unnamed: 6'].isnull().sum()\n\nprint('Total Missing Values Kolom \"Unnamed: 6\": ', totalNull)","cd540e4a":"df['closed_at'] = df['closed_at'].fillna(value=\"31\/12\/2013\")","962c11d3":"totalNull = df['closed_at'].isnull().sum()\n\nprint('Total Missing Values Kolom \"closed_at\": ', totalNull)","a100a75a":"df[['age_first_milestone_year','age_last_milestone_year','milestones']].head()","01a36be5":"df['age_first_milestone_year'] = df['age_first_milestone_year'].fillna(value=\"0\")\ndf['age_last_milestone_year'] = df['age_last_milestone_year'].fillna(value=\"0\")","cfd109df":"for index, row in df.iterrows():\n    if row['state_code']!=row['state_code.1']:\n        print(index, row['state_code'], row['state_code.1'])","025dd80f":"df.drop([\"state_code.1\"], axis=1, inplace=True)","fe87aed6":"null=pd.DataFrame(df.isnull().sum(),columns=[\"Null Values\"])\nnull[\"% Missing Values\"]=(df.isna().sum()\/len(df)*100)\nnull = null[null[\"% Missing Values\"] > 0]\nnull.style.background_gradient(cmap='viridis',low =0.2,high=0.1) ","d2f687d5":"df.corr()","4d902b79":"df['age_first_milestone_year'] = df.age_first_milestone_year.astype(float)\ndf['age_last_milestone_year'] = df.age_last_milestone_year.astype(float)","19677ee2":"features = ['age_first_funding_year','age_last_funding_year','age_first_milestone_year','age_last_milestone_year','relationships','funding_rounds','funding_total_usd','milestones','is_CA','is_NY','is_MA','is_TX','is_otherstate','is_software','is_web','is_mobile','is_enterprise','is_advertising','is_gamesvideo','is_ecommerce','is_biotech','is_consulting','is_othercategory','has_VC','has_angel','has_roundA','has_roundB','has_roundC','has_roundD','avg_participants','is_top500','status']\n\nplt.figure(figsize=(30,20))\nax = sns.heatmap(data = df[features].corr(),cmap='YlGnBu',annot=True)\n\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5,top - 0.5)","c251a053":"#number of variables for heatmap\ncols = df[features].corr().nlargest(10,'status')['status'].index\ncm = np.corrcoef(df[cols].values.T) \nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, cmap='YlGnBu', fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","e0d283ca":"fig, ax = plt.subplots()\n_ = plt.scatter(x=df['age_first_funding_year'], y=df['age_last_funding_year'], edgecolors=\"#000000\", linewidths=0.5)\n_ = ax.set(xlabel=\"age_first_funding_year\", ylabel=\"age_last_funding_year\")","c66ec0f7":"fig, ax = plt.subplots()\n_ = plt.scatter(x=df['age_first_milestone_year'], y=df['age_last_milestone_year'], edgecolors=\"#000000\", linewidths=0.5)\n_ = ax.set(xlabel=\"status\", ylabel=\"milestones\")","d675c2f9":"featuresNum = ['age_first_funding_year','age_last_funding_year','age_first_milestone_year','age_last_milestone_year','relationships','funding_rounds','funding_total_usd','milestones','avg_participants']\n\nplt.figure(figsize=(15, 7))\nfor i in range(0, len(featuresNum)):\n    plt.subplot(1, len(featuresNum), i+1)\n    sns.boxplot(y=df[featuresNum[i]], color='green', orient='v')\n    plt.tight_layout()","442ae25a":"cdf = df[\"founded_at\"].apply(lambda x: '' + x[:2]).value_counts() \\\n            .to_frame().reset_index() \\\n            .rename(columns={\"index\": \"year\", \"founded_at\": \"No_of_startup\"})\n\nfig, ax = plt.subplots()\n_ = sns.barplot(x=\"year\", y=\"No_of_startup\", data=cdf, \n                palette=sns.color_palette(['#003f5c', '#ffa600'], n_colors=7), ax=ax)\n_ = ax.set(xlabel=\"Year\", ylabel=\"No. of startup\")","ba06d895":"df[\"founded_at\"].apply(lambda x: '20:' + x[:2]).value_counts(normalize=False)","264018d2":"df[\"founded_at\"].apply(lambda x: '20:' + x[:2]).value_counts(normalize=True)","842e3131":"df[\"closed_at\"].apply(lambda x: '20:' + x[:2]).value_counts(normalize=True)","ec278890":"df_acquired = df[(df[\"status\"] == True)]\ndf_acquired.shape","79b2a664":"df_closed = df[(df[\"status\"] == False)]\ndf_closed.shape","163738cc":"value_counts = df[\"status\"].value_counts().to_dict()\nfig, ax = plt.subplots()\n_ = ax.pie(x=[value_counts[False], value_counts[True]], labels=['No', 'Yes'], \n           colors=['#003f5c', '#ffa600'], textprops={'color': '#040204'})\n_ = ax.axis('equal')\n_ = ax.set_title('Startup Acquired')","e7531baf":"fig, ax = plt.subplots(figsize=(12,8))\n\n_ = sns.countplot(x=\"category_code\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.category_code.value_counts().index)\n\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"Category\", ylabel=\"No. of startup\")\nplt.legend(bbox_to_anchor=(0.945, 0.90))","385d8ba0":"data1 = df[df['status']==1].groupby(['category_code']).agg({'status':'count'}).reset_index()\ndata1.columns=['category_code','total_success']\n\ndata2 = df[df['status']==0].groupby(['category_code']).agg({'status':'count'}).reset_index()\ndata2.columns=['category_code','total_closed']\n\ndata3=df.groupby(['category_code']).agg({'status':'count'}).reset_index()\ndata3.columns=['category_code','total_startup']\n\ndata1= data1.merge(data2, on='category_code')\ndata1= data1.merge(data3, on='category_code')\n\ndata1['success_rate']= round((data1['total_success'] \/ data1['total_startup']) * 100,2)\n\nmost_succes_rate = data1.sort_values('success_rate', ascending=False)\nmost_succes_rate","4d8e54e9":"fig, ax = plt.subplots(figsize=(10,7))\n_ = sns.barplot(x=\"category_code\", y=\"success_rate\", data=most_succes_rate,\n                palette=\"nipy_spectral\", ax=ax)\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"Category\", ylabel=\"Success Rate of Start Up\")","fbd80bfd":"funding_sorted_category = pd.pivot_table(df,\n              index=['category_code'],\n              values=['funding_total_usd'],\n              aggfunc=['sum']\n              ).reset_index()\nfunding_sorted_category.columns = ['category_code', 'funding_total_usd']\nfunding_sorted_category = funding_sorted_category.sort_values(['funding_total_usd'], ascending = False)\nfunding_sorted_category.head(10)","bd4668a2":"fig, ax = plt.subplots(figsize=(15,7))\n_ = sns.barplot(x=\"category_code\", y=\"funding_total_usd\", data=funding_sorted_category,\n                palette=\"nipy_spectral\", ax=ax)\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"Category\", ylabel=\"Total Funding USD\")","e841992a":"fig, ax = plt.subplots(figsize=(12,8))\n\n_ = sns.countplot(x=\"state_code\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.state_code.value_counts().index)\n\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"state_code\", ylabel=\"No. of startup\")\nplt.legend(bbox_to_anchor=(0.945, 0.90))","a9495fc1":"trending_statea = df.groupby(['state_code']).size().rename('num_startup').reset_index()\n\nmost_trending_statea = trending_statea[trending_statea.groupby('state_code')['num_startup'].transform(max) == trending_statea['num_startup']]\nmost_trending_statea = most_trending_statea.sort_values('num_startup', ascending=False)\nmost_trending_statea","f124d06c":"trending_statea = df_acquired.groupby(['state_code','category_code']).size().rename('num_startup').reset_index()\n\nmost_trending_statea = trending_statea[trending_statea.groupby('state_code')['num_startup'].transform(max) == trending_statea['num_startup']]\nmost_trending_statea = most_trending_statea.sort_values('num_startup', ascending=False)\nmost_trending_statea.head(10)","aba4171c":"trending_statec = df_closed.groupby(['state_code','category_code']).size().rename('num_startup').reset_index()\n\nmost_trending_statec = trending_statec[trending_statec.groupby('state_code')['num_startup'].transform(max) == trending_statec['num_startup']]\nmost_trending_statec = most_trending_statec.sort_values('num_startup', ascending=False)\nmost_trending_statec","a28f4f5a":"trending_categorya = df_acquired.groupby(['city','category_code']).size().rename('num_startup').reset_index()\n\nmost_trending_categorya = trending_categorya[trending_categorya.groupby('city')['num_startup'].transform(max) == trending_categorya['num_startup']]\nmost_trending_categorya = most_trending_categorya.sort_values('num_startup', ascending=False)\nmost_trending_categorya","074fff7a":"trending_categoryc = df_closed.groupby(['city','category_code']).size().rename('num_startup').reset_index()\n\nmost_trending_categoryc = trending_categoryc[trending_categoryc.groupby('city')['num_startup'].transform(max) == trending_categoryc['num_startup']].reset_index()\nmost_trending_categoryc = most_trending_categoryc.sort_values('num_startup', ascending=False)\nmost_trending_categoryc","85117ed6":"funding_sorted_city = pd.pivot_table(df,\n              index=['city'],\n              values=['funding_total_usd'],\n              aggfunc=['sum']\n              ).reset_index()\nfunding_sorted_city.columns = ['city', 'funding_total_usd']\nfunding_sorted_city = funding_sorted_city.sort_values(['funding_total_usd'], ascending = False)\nfunding_sorted_city = funding_sorted_city.head(10)\nfunding_sorted_city","9d3bff70":"fig, ax = plt.subplots(figsize=(10,7))\n_ = sns.barplot(x=\"city\", y=\"funding_total_usd\", data=funding_sorted_city,\n                palette=\"nipy_spectral\", ax=ax)\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"No of State\", ylabel=\"Number of Start Up\")","f75c1173":"df_what_in_kirkland = df[(df[\"city\"] == 'Kirkland')]\ndf_what_in_kirkland.shape","11f29f95":"df_what_in_kirkland.head()","287bdffe":"fig, ax = plt.subplots(figsize=(10,5))\n\n_ = sns.countplot(x=\"has_VC\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.has_VC.value_counts().index)\n\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"Has_VC\", ylabel=\"No. of startup\")\nplt.legend(bbox_to_anchor=(0.945, 0.90))","bf62036b":"fig, ax = plt.subplots(figsize=(10,5))\n\n_ = sns.countplot(x=\"is_top500\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.is_top500.value_counts().index)\n\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"is_top500\", ylabel=\"No. of startup\")\nplt.legend(bbox_to_anchor=(0.945, 0.90))","86860036":"#How many Startup have both 'acquired' status and is_top500?\nlen(df[(df[\"status\"] == True) & (df[\"is_top500\"] == True)].index)","72672b86":"#How many Startup have both 'closed' status and is_top500?\nlen(df[(df[\"status\"] == False) & (df[\"is_top500\"] == False)].index)","acd76eba":"df_acquired[\"is_top500\"].value_counts(normalize=True)","0e8727fe":"df_closed.founded_at=pd.to_datetime(df_closed.founded_at)\ndf_closed.closed_at=pd.to_datetime(df_closed.closed_at)","6ab43482":"df_closed['age_closed_startup'] = df_closed.apply(lambda row: (row.closed_at - row.founded_at) , axis=1)","a12f7d2c":"#df_closed['age_closed_startup'] = pd.to_numeric(df['age_closed_startup'].dt.days, downcast='int64')","eaa1548d":"df_closed['age_closed_startup'].head()","40437401":"df_closed['year'] = df_closed['age_closed_startup'].dt.days \/365","22101a8c":"df_closed.head(3)","a6fdfb4e":"(df_closed['age_closed_startup'].mean()) ","154fd7d0":"ratarata = round(2184 \/ 365) \nprint(\"Rata-Rata Startup Closed :\", ratarata ,\"tahun\")","015fd5a0":"fig, ax = plt.subplots(figsize=(17,10))\n\nsns.countplot(x=\"relationships\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.relationships.value_counts().index)\nplt.legend(bbox_to_anchor=(0.945, 0.90))","8e7adedd":"fig, ax = plt.subplots(figsize=(12,8))\n\nsns.countplot(x=\"funding_rounds\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.funding_rounds.value_counts().index)\n# plt.legend(bbox_to_anchor=(0.945, 0.90))","e3c56a05":"coba = df[(df[\"status\"] == 1)]\n\nfeatures = coba[[\"has_VC\",\"has_angel\",\"has_roundA\",\"has_roundB\",\"has_roundC\",\"has_roundD\"]]\n\nfig, ax = plt.subplots(figsize=(12,8))\n\na= np.random.choice([\"{}\".format(i) for i in [1,2,3,4,5,6]], size=(12,8))\ncoba = pd.DataFrame(a, columns=[\"has_{}\".format(i) for i in list(\"features\")])\n\nsns.countplot(x=\"variable\", hue=\"value\",palette=\"nipy_spectral\", data=pd.melt(features))\n\nplt.show()","1471cfc5":"import pandas as pd\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport shapefile as shp","cae78c0d":"import sys","0a58e404":"'geopandas' in sys.modules","8f9f1cea":"gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.longitude, df.latitude))","a8eda5b4":"print(gdf.head())","ed2eaafe":"street_map = gpd.read_file('..\/input\/json-map-file\/USA_States.shp')\n\nfig,ax = plt.subplots(figsize = (15,15))\nstreet_map.plot(ax = ax)","cd302929":"world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\nax = street_map.plot(figsize = (50,50))\n\n# We can now plot our ``GeoDataFrame``.\ngdf.plot(ax=ax, color='red')\n\nplt.show()","503e3438":"#check\nduplicate = df[df.duplicated()] \n  \nprint(\"Duplicate Rows :\")","2716fb61":"age=[\"age_first_funding_year\",\"age_last_funding_year\",\"age_first_milestone_year\",\"age_last_milestone_year\"]\n\nfor a in range(len(age)):\n    print(\"Is there any negative value in '{}' column  : {} \".format(age[a],(df[age[a]]<0).any()))","838bee8b":"df=df.drop(df[df.age_first_funding_year<0].index)\ndf=df.drop(df[df.age_last_funding_year<0].index)\ndf=df.drop(df[df.age_first_milestone_year<0].index)\ndf=df.drop(df[df.age_last_milestone_year<0].index)","86e7dd8d":"for a in range(len(age)):\n    print(\"Is there any negative value in '{}' column  : {} \".format(age[a],(df[age[a]]<0).any()))","dac3189b":"featuresNumfinal = ['age_first_funding_year','age_last_funding_year','age_first_milestone_year','age_last_milestone_year','funding_total_usd']\n\nplt.figure(figsize=(15, 7))\nfor i in range(0, len(featuresNumfinal)):\n    plt.subplot(1, len(featuresNumfinal), i+1)\n    sns.boxplot(y=df[featuresNumfinal[i]], color='green', orient='v')\n    plt.tight_layout()","df834720":"df[\"age_first_funding_year\"] = np.log1p(df[\"age_first_funding_year\"])\ndf[\"age_last_funding_year\"] = np.log1p(df[\"age_last_funding_year\"])\ndf[\"age_first_milestone_year\"] = np.log1p(df[\"age_first_milestone_year\"])\ndf[\"age_last_milestone_year\"] = np.log1p(df[\"age_last_milestone_year\"])\ndf[\"funding_total_usd\"] = np.log1p(df[\"funding_total_usd\"])","368bfe31":"featuresNumfinal = ['age_first_funding_year','age_last_funding_year','age_first_milestone_year','age_last_milestone_year','funding_total_usd']\n\nplt.figure(figsize=(15, 7))\nfor i in range(0, len(featuresNumfinal)):\n    plt.subplot(1, len(featuresNumfinal), i+1)\n    sns.boxplot(y=df[featuresNumfinal[i]], color='green', orient='v')\n    plt.tight_layout()","4564f202":"df['has_RoundABCD'] = np.where((df['has_roundA'] == 1) | (df['has_roundB'] == 1) | (df['has_roundC'] == 1) | (df['has_roundD'] == 1), 1, 0)\ndf.head()","1ea09ff0":"df['has_Investor'] = np.where((df['has_VC'] == 1) | (df['has_angel'] == 1), 1, 0)\ndf.head()","b4cb7ca6":"len(df[(df[\"has_RoundABCD\"] == 1)].index)","fe650171":"len(df[ (df['has_RoundABCD']  == 1) & (df['status']  == 1) ].index)","ef7a10b7":"len(df)","a6bd2b81":"923-490","1b49417c":"df['has_Seed'] = np.where((df['has_RoundABCD'] == 0) & (df['has_Investor'] == 1), 1, 0)\ndf.head()","eedf177f":"df['has_Seed'] == 1","cd3dac9f":"len(df[(df[\"has_Seed\"] == 1)].index)","6deda560":"df['invalid_startup'] = np.where((df['has_RoundABCD'] == 0) & (df['has_VC'] == 0) & (df['has_angel'] == 0), 1, 0)\ndf.head()","d9164a5f":"len(df[(df[\"invalid_startup\"] == 1)].index)","eac46ab6":"df.founded_at=pd.to_datetime(df.founded_at)\ndf.closed_at=pd.to_datetime(df.closed_at)","9d11ecde":"df['age_closed_startup'] = df.apply(lambda row: (row.closed_at - row.founded_at) , axis=1)","cc02f5e2":"df['age_closed_startup'].head()","4d77406b":"df['age_startup_year'] = df['age_closed_startup'].dt.days \/365","75c6e399":"fig, ax = plt.subplots(figsize=(12,8))\n\n_ = sns.countplot(x=\"relationships\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.relationships.value_counts().index)\n\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"relationships\", ylabel=\"No. of startup\")\nplt.legend(bbox_to_anchor=(0.945, 0.90))","eab8b0be":"# create a list of our conditions\nconditions = [\n    (df['relationships'] <= 5),\n    (df['relationships'] > 5) & (df['relationships'] <= 10),\n    (df['relationships'] > 10) & (df['relationships'] <= 16),\n    (df['relationships'] > 16)\n    ]\n\n# create a list of the values we want to assign for each condition\nvalues = ['4', '3', '2', '1']\n\n# create a new column and use np.select to assign values to it using our lists as arguments\ndf['tier_relationships'] = np.select(conditions, values)\n\n# display updated DataFrame\ndf.head()","99b6c6b2":"fig, ax = plt.subplots(figsize=(12,8))\n\n_ = sns.countplot(x=\"tier_relationships\", hue=\"status\", data=df, palette=\"nipy_spectral\",\n              order=df.tier_relationships.value_counts().index)\n\n_ = ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n_ = ax.set(xlabel=\"tier_relationships\", ylabel=\"No. of startup\")\nplt.legend(bbox_to_anchor=(0.945, 0.90))","202b96fd":"df['tier_relationships'] = df.tier_relationships.astype(int)","b5d35b7d":"df = df.drop(['state_code'],axis=1)\ndf = df.drop(['id'],axis=1)\ndf = df.drop(['Unnamed: 6'],axis=1)\ndf = df.drop(['category_code'],axis=1)\ndf = df.drop(['object_id'],axis=1)\ndf = df.drop(['zip_code'],axis=1)\ndf = df.drop(['founded_at'],axis=1)\ndf = df.drop(['closed_at'],axis=1)\ndf = df.drop(['first_funding_at'],axis=1)\ndf = df.drop(['last_funding_at'],axis=1)\ndf = df.drop(['city'],axis=1)\ndf = df.drop(['name'],axis=1)\ndf = df.drop(['Unnamed: 0'],axis=1)\ndf = df.drop(['latitude','longitude'],axis=1)\ndf = df.drop(['geometry'],axis=1)\ndf = df.drop(['age_closed_startup'],axis=1)\ndf = df.drop(['relationships'],axis=1)","4d69f7a9":"#Cek categorical\ncat_feature = df.select_dtypes(include='object')\ncat_feature.head()","23eada39":"from sklearn.model_selection import train_test_split\n# Split the data\n# Input\/independent variables\nX = df.drop('status', axis = 1) # her we are droping the output feature as this is the target and 'X' is input features, the changes are not \n                                # made inplace as we have not used 'inplace = True'\n\ny = df['status'] # Output\/Dependent variable","19b3153e":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","471f0340":"# lets print the shapes again \nprint(\"Shape of the X Train :\", X_train.shape)\nprint(\"Shape of the y Train :\", y_train.shape)\nprint(\"Shape of the X test :\", X_test.shape)\nprint(\"Shape of the y test :\", y_test.shape)","585de383":"# Model Build\nfrom sklearn.metrics import confusion_matrix, classification_report,accuracy_score,roc_curve, auc, precision_recall_curve, f1_score\nimport warnings\nwarnings.filterwarnings('ignore')","de7372c0":"import lightgbm as lgb\n#lightGBM model fit\ngbm = lgb.LGBMRegressor()\ngbm.fit(X_train,y_train)\ngbm.booster_.feature_importance()\n\n\n# importance of each attribute\nfea_imp_ = pd.DataFrame({'cols':X.columns, 'fea_imp':gbm.feature_importances_})\nfea_imp_.loc[fea_imp_.fea_imp > 0].sort_values(by=['fea_imp'], ascending = False)","706c5bf0":"from sklearn.feature_selection import RFE\n# create the Recursive Feature Elimination model and select 10 attributes\nrfe = RFE(gbm, 10)\nrfe = rfe.fit(X_train,y_train)\n\n# summarize the selection of the attributes\nprint(rfe.support_)\n\n# summarize the ranking of the attributes\nfea_rank_ = pd.DataFrame({'cols':X.columns, 'fea_rank':rfe.ranking_})\nfea_rank_.loc[fea_rank_.fea_rank > 0].sort_values(by=['fea_rank'], ascending = True)","aa8a7e7a":"from lightgbm import LGBMClassifier\nclf = LGBMClassifier()\n\nclf.fit(X_train,y_train)\n\ny_pred_lgb = clf.predict(X_test)\n\nprint(\"Training Accuracy :\", clf.score(X_train, y_train))\nprint(\"Testing Accuracy :\", clf.score(X_test, y_test))\n\ncm = confusion_matrix(y_test, y_pred_lgb)\nplt.rcParams['figure.figsize'] = (3, 3)\nsns.heatmap(cm, annot = True, cmap = 'YlGnBu', fmt = '.8g')\nplt.show()\n\ncr = classification_report(y_test, y_pred_lgb)\nprint(cr)\n\nprint(\"------------------------------------------\")\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_pred_lgb)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC Curves              =\",roc_auc)\n\nprecision, recall, thresholds = precision_recall_curve(y_test, y_pred_lgb)\nf1 = f1_score(y_test, y_pred_lgb)\nPrecision_Recall_lgbm = auc(recall, precision)\nprint(\"Precision-Recall Curves =\",Precision_Recall_lgbm)","5ab139f7":"from xgboost import XGBClassifier\n\n#train\nxgb = XGBClassifier()\n\nxgb.fit(X_train,y_train)\n\n#predict\ny_predicted_xgb = xgb.predict(X_test)\n\nprint(\"Training Accuracy :\", xgb.score(X_train, y_train))\nprint(\"Testing Accuracy :\", xgb.score(X_test, y_test))\n\n#eval\ncm = confusion_matrix(y_test, y_predicted_xgb)\nplt.rcParams['figure.figsize'] = (3, 3)\nsns.heatmap(cm, annot = True, cmap = 'YlGnBu', fmt = '.8g')\nplt.show()\n\ncr = classification_report(y_test, y_predicted_xgb)\nprint(cr)\n\nprint(\"------------------------------------------\")\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_predicted_xgb)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC Curves              =\",roc_auc)\n\nprecision, recall, thresholds = precision_recall_curve(y_test, y_predicted_xgb)\nf1 = f1_score(y_test, y_predicted_xgb)\nPrecision_Recall_xgb = auc(recall, precision)\nprint(\"Precision-Recall Curves =\",Precision_Recall_xgb)","9ccd1973":"from sklearn.ensemble import GradientBoostingClassifier\n#train\ngbc = GradientBoostingClassifier(learning_rate=0.02,\n                    max_depth=4,\n                    random_state=100, n_estimators=1000)\n\n\ngbc.fit(X_train,y_train)\n\n#predict\ny_predicted_gb = gbc.predict(X_test)\n\nprint(\"Training Accuracy :\", gbc.score(X_train, y_train))\nprint(\"Testing Accuracy :\", gbc.score(X_test, y_test))\n\n#eval\ncm = confusion_matrix(y_test, y_predicted_gb)\nplt.rcParams['figure.figsize'] = (3, 3)\nsns.heatmap(cm, annot = True, cmap = 'YlGnBu', fmt = '.8g')\nplt.show()\n\ncr = classification_report(y_test, y_predicted_gb)\nprint(cr)\n\n\nprint(\"------------------------------------------\")\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_predicted_gb)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC Curves              =\",roc_auc)\n\nprecision, recall, thresholds = precision_recall_curve(y_test, y_predicted_gb)\nf1 = f1_score(y_test, y_predicted_gb)\nPrecision_Recall_gbs = auc(recall, precision)\nprint(\"Precision-Recall Curves =\",Precision_Recall_gbs)","6c9dcc56":"from sklearn.ensemble import AdaBoostClassifier\n#train\nada = AdaBoostClassifier()\n\n\nada.fit(X_train,y_train)\n\n#predict\ny_predicted_ab = ada.predict(X_test)\n\nprint(\"Training Accuracy :\", ada.score(X_train, y_train))\nprint(\"Testing Accuracy :\", ada.score(X_test, y_test))\n\n#eval\ncm = confusion_matrix(y_test, y_predicted_ab)\nplt.rcParams['figure.figsize'] = (3, 3)\nsns.heatmap(cm, annot = True, cmap = 'YlGnBu', fmt = '.8g')\nplt.show()\n\ncr = classification_report(y_test, y_predicted_ab)\nprint(cr)\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_predicted_ab)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"roc_auc\",roc_auc)\n\nprint(\"------------------------------------------\")\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_predicted_ab)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC Curves              =\",roc_auc)\n\nprecision, recall, thresholds = precision_recall_curve(y_test, y_predicted_ab)\nf1 = f1_score(y_test, y_predicted_ab)\nPrecision_Recall_abs = auc(recall, precision)\nprint(\"Precision-Recall Curves =\",Precision_Recall_abs)","3ba15d29":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\n\nrf.fit(X_train,y_train)\n\n\ny_pred_rf = rf.predict(X_test)\n\nprint(\"Training Accuracy :\", rf.score(X_train, y_train))\nprint(\"Testing Accuracy :\", rf.score(X_test, y_test))\n\ncm = confusion_matrix(y_test, y_pred_rf)\nplt.rcParams['figure.figsize'] = (3, 3)\nsns.heatmap(cm, annot = True, cmap = 'YlGnBu', fmt = '.8g')\nplt.show()\n\ncr = classification_report(y_test, y_pred_rf)\nprint(cr)\n\n\nprint(\"------------------------------------------\")\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_pred_rf)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC Curves              =\",roc_auc)\n\nprecision, recall, thresholds = precision_recall_curve(y_test, y_pred_rf)\nf1 = f1_score(y_test, y_pred_rf)\nPrecision_Recall_rfs = auc(recall, precision)\nprint(\"Precision-Recall Curves =\",Precision_Recall_rfs)","d805f3cf":"from sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\n\nscores = {'LGBM':  { \n                             'precision_score': precision_score(y_test, y_pred_lgb),\n                             'recall_score': recall_score(y_test, y_pred_lgb)\n                         },        \n                 'GradientBoosting Classifier':  { \n                             'precision_score': precision_score(y_test, y_predicted_gb),\n                             'recall_score': recall_score(y_test, y_predicted_gb)\n                         },\n                 'Adaboost Classifier':  { \n                             'precision_score': precision_score(y_test, y_predicted_ab),\n                             'recall_score': recall_score(y_test, y_predicted_ab)\n                         },\n                 'XGBoost':  { \n                             'precision_score': precision_score(y_test, y_predicted_xgb),\n                             'recall_score': recall_score(y_test, y_predicted_xgb)\n                         },\n                 'Random Forest':  { \n                             'precision_score': precision_score(y_test, y_pred_rf),\n                            'recall_score': recall_score(y_test, y_pred_rf)\n                         }\n            }","5f38483c":"from sklearn.metrics import precision_score\n\n\nPrecision_Recall = {'LGBM':  { \n                             'Precision_Recall': Precision_Recall_lgbm\n                         },        \n                 'GradientBoosting Classifier':  { \n                             'Precision_Recall': Precision_Recall_gbs\n                         },\n                 'Adaboost Classifier':  { \n                             'Precision_Recall': Precision_Recall_abs\n                         },\n                 'XGBoost':  { \n                             'Precision_Recall': Precision_Recall_xgb\n                         },\n                 'Random Forest':  { \n                             'Precision_Recall': Precision_Recall_rfs\n                         }\n            }","e6d836a0":"scores = pd.DataFrame(scores)\n\n\nscores.plot(kind=\"barh\",figsize=(12, 12)).legend(loc='upper center', ncol=3, title=\"Machine Learning Model\")","2504cc03":"Precision_Recall = pd.DataFrame(Precision_Recall)\n\n\nPrecision_Recall.plot(kind=\"barh\",figsize=(15, 8)).legend(loc='upper center', ncol=3, title=\"Machine Learning Model\")","706a55d7":"# import pickle","0f034a8d":"# # Saving model to disk\n# pickle.dump(gbm, open('model.pkl','wb'))","ba79e918":"# # Loading model to compare the results\n# model = pickle.load(open('model.pkl','rb'))\n# print(model.predict([[2, 3, 4, 6, 3, 3, 375000, 3, 1, 6,]]))","1fe5ff9b":"# df2 = df[[\"status\",\"age_first_funding_year\",\"age_last_funding_year\",\"age_first_milestone_year\",\"age_last_milestone_year\",\"relationships\",\"funding_rounds\",\"funding_total_usd\",\"milestones\",\"avg_participants\"]]\n# df2.head(10)","86b3bbb3":"##  New Column \"age_startup_year\"","4c0cd584":"##### Feature importance by LGBM","62778024":"## Duplicate Values","f47c653f":"### Which State having most number of acquired Startup per category","43e4566a":"- **Analysis results in the dataset used there are Missing Values among them are**\n    - **Total Missing Values i.e. 1386**\n    - **Columns that have more than 50% of missing values**\n        - Variable 'closed_at' with a total percentage of 63.70% or a total of 588 columns.\n        - Variable 'Unnamed: 6' with a total percentage of 53.41% or a total of 493 columns.\n    - **Columns that have less than 50% of missing values** \n        - Variable 'age_first_milestone_year' with a total percentage of 16.46% or a total of 152 columns.\n        - Variable 'age_last_milestone_year' with a total percentage of 16.46% or a total of 152 columns.","bd013007":"## Import Libraries","3831382d":"### which funding_rounds related to acquired or closed startup?","481eacab":"### How many Startup are acquired or closed have?","e1283842":"### Statistical Summary","8fd66939":"# Summary","a7870ba8":"## Log-transformation of the funding and milestone year variable","d358892d":"### How many Startup have has_VC?","16c6b25d":"## Outliers","54f0b75f":"### Which city having most number of acquired Startup per category","fe100bcd":"- the **\"state_code\"** column and the **\"state_code.1\"** column must be the same, so the **\"state_code.1\"** column must be dropped. \n- column **\"state_code.1\"** has missing value in line 515.","5bb2426b":"## AdaBoost Classifier","156e13f4":"- Does the value listed on each column make sense?\n- age_first_funding_year and age_last_funding_year have the same min,max data, need to be checked again \n- Is the maximum\/minimum value still within the reasonable limit? \n- Min\/max that is too far from the mean\/median may be an indication of data input error \n- Is there a column with a significant difference between the mean and the median?\n- Differences between mean\/median indicate outlier or skewed distribution","7520caa9":"## Data type identification","99a26fcf":"## New Column \"has_RoundABCD\"","9550ebb7":"Now how to correlate between data variables. \n\nCorrelation is represented as a value between -1 and +1 where +1 indicates the highest positive correlation, -1 indicates the highest negative correlation, and 0 indicates no correlation.","455de264":"# Deploy Model","3ed64a3a":"### Which category has the largest number of startup","df7165bf":"# Exploratory Data Analysis","6b6c88d0":"### How many Startup have is_top500?","12ac7dc4":"css and js file for css js elements to work on webpage.Get it from here : https:\/\/materializecss.com\/getting-started.html","fe19c8fe":"### which relationship related to acquired or closed startup?","342ee299":"based on the correlation table above which says that **'views'** and **'likes'** are very positively correlated. then we then verify that by plotting a scatter plot between **'views'** and **'likes'** to visualize the relationship between those variables.","f2ea8463":"## Random Forest","1744b148":"### How many years on average the company closes","41f047ef":"## Negative value","c7d64efc":"### Mapping area startup ","6a1a1d3c":"Round A, Round B,Round C, Round D, VC, Angel = 0 earlier startup status acquired ????????? there is something strange about this data, the possibility of invalid data","6069c9ca":"Based on the results of the analysis obtained that the columns 'age_first_milestone_year' and 'age_last_milestone_year' have null values because the startup does not have milestones. this can be confirmed by looking at the 'milestones' column containing the data 0 must be accompanied by the null 'age_first_milestone_year' and 'age_last_milestone_year' columns. so we decided to fill that null column with a value of 0.","a6bb155a":"### Which State having most number of Startup","87da9872":"##  New Column \"tier_relationships\"","c033223c":"## GradientBoosting Classifier","b2690109":"### Drop column labels","513f13e4":"### Which category has the largest number Success Rate","8a21adfd":"## New Column \"has_Seed\"","4dcb085a":"### Scatter plot","98e3d9b0":"## Drop unused column for modelling","4ff48463":"## Data categorical","399b11f3":"## New Column \"invalid_startup\"","773c6550":"## Description","d5e71e1b":"Based on the results of the analysis obtained that the column **Unnamed: 6** is a combination of several other columns including columns **city, state_code, and zip_code**, then we decided that remove the contents of the column **Unnamed: 6** first and then fill in the data based on a combination of several related columns.","e71b9133":"### Handling Missing Value age_first_milestone_year and age_last_milestone_year","e700b3aa":"### Box plots","a64523d5":"### Changing 'status' data value","56a98275":"## LGBM Classifier","23bfb80b":"# Modeling","fd028b6c":"We see that **'age_first_milestones_year'** and **'age_last_milestones_year'** are really positively correlated whereas when one increases, the other also increases\u2014mostly.","4e161202":"## Problem Statement\n\n**Startup** is a business that has just been established and grown supported by digital services and has also become an important element of innovation systems and economies around the world. The **Startup** ecosystem is growing very rapidly and still needs a lot of funding to operate with a minimalist working group. So it is very important for VC to monitor the performance and performance of **Startup**, so that it can be used as a consideration to decide whether to fund a Startup to drive its growth or refuse to take part in funding. To monitor startup performance, it is important to analyze what makes a Startup successful and how to determine its success.\n\n## Goals\nThe goal to be achieved is to determine whether a StartUp will be successful or not.\n\n## Objective\nThe objective is to analyze startup behavior based on several variables, determine what variables affect startup success the most, then build a model that can predict the success of a StartUp.","f072bc77":"##### Recursive Feature Elimination(RFE)","35f34d02":"### Which State having most number of closed Startup per category","d6a9f88f":"total 563 startups or 60% of startups established in 2001","eb5a297d":"## XGBoost Classifier","f5151eb5":"### Handling Missing Value state_code.1","3e19ab81":"# Feature Engineering","1447a1db":"### Handling 'status' data type to int ","54cd9521":"##### Build Model","6170bf9e":"## Load Dataset","55ccda63":"## Numerical Approach","812e2631":"from the total data available as many as 63% of startups are still standing while the remaining 37% have been closed and most closed in 2001.","2fc6ad25":"### Which city having most number of total funding","96e2204a":"## Graphic Approach","87629239":"## Data numeric","39b8cc7a":"# Startup Success Prediction Model","88598c2b":"###  Handling Missing Value Unnamed: 6","6808055f":"## New Column \"has_Investor\"","b8378d17":"### Handling Missing Value closed_at","b99be66d":"# Data Preprocessing","51bb3ba3":"### Dataset collection founded years","97f8b946":"# Data Exploration","0d810abf":"### Correlation heatmap","dca4fdb7":"### Investing Feature on Acquired","2dc4a941":"## Missing Value ","a02d30cd":"- **Analysis results in the column contained Missing Values among them are** \n    - **Column \"Unnamed: 6\"** is a column of information from a combination of several tables including \n        - Column \"city\", \"state_code\", and \"zip_code\" \n    - **Column \"closed_at\"** is a column where StartUp **\"Closed\"** so that the empty data should be a StarUp whose status is still **\"Acquired\"** \n    - **Column age_first_milestone_year** is information on when milestones were first performed in units of the year \n        - This column has a total of 771 rows of data with a Mean of 3.055353 and a median of 2.520500 showing abnormal data distribution \n    - **Column age_Last_milestone_year** is information when the last milestone was done in units of years \n        - This column has a total of 771 rows of data with a Mean of 4.754423 and a median of 4.476700 that shows the distribution of data is abnormal","2bb60b44":"### Which category having most number of total funding","7c164f91":"### Categorical Value Counting","1d8b2f75":"### Which city having most number of closed Startup per category"}}