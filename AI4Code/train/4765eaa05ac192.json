{"cell_type":{"e95e9813":"code","47741481":"code","c09ffd3a":"code","b702d2d7":"code","a90d5ef3":"code","588f6434":"code","6c25eda5":"code","6e0e018f":"code","fb7f7f19":"code","61546f95":"code","0f4cd906":"code","5965f602":"code","313a1f51":"code","5ca3a59f":"code","d1e217f2":"code","b9d46076":"code","89e37f3e":"code","23860750":"code","0eed36c9":"code","5858d4af":"code","022ab6da":"code","9203e77d":"code","92000b8e":"code","aae4f455":"code","09ab5292":"code","9c35d6d2":"code","ecad03f3":"code","212ff949":"code","1392c39b":"code","78aebb76":"code","55f6f0fd":"markdown","2b2d1e16":"markdown","1e857c92":"markdown","7dcc3a41":"markdown","f21497da":"markdown","a49b2110":"markdown","fa969276":"markdown","222ab707":"markdown","1a806088":"markdown","88855862":"markdown","fb15450b":"markdown"},"source":{"e95e9813":"import pandas as pd\nimport numpy as np","47741481":"df = pd.read_csv(\"..\/input\/weather-dataset-rattle-package\/weatherAUS.csv\")\ndf.head()","c09ffd3a":"print(df.info())\nprint(\"----------------------------\")\nprint(df.shape)","b702d2d7":"df.Date = df.Date.apply(pd.to_datetime)\ndf['month'] = df.Date.apply(lambda x: x.month)\ndf['day'] = df.Date.apply(lambda x: x.day)\ndf['year'] = df.Date.apply(lambda x: x.year)\ndf.drop(['Date'], 1, inplace = True)\n","a90d5ef3":"df.head()","588f6434":"df.isnull().sum()","6c25eda5":"df.describe().T.style.bar(subset=['mean'], color='#205ff2')\\\n                            .background_gradient(subset=['std'], cmap='Reds')\\\n                             .background_gradient(subset=['50%'], cmap='coolwarm')","6e0e018f":"for feature in df.columns:\n    if df[feature].dtype not in ['int64', 'float64']:    #dtype means datatype\n        print(f\"{feature}:{df[feature].unique()}\")","fb7f7f19":"df['Sunshine'].describe()","61546f95":"df[\"Evaporation\"].describe()","0f4cd906":"from sklearn.impute import SimpleImputer\n\n\nimputer1 = SimpleImputer(missing_values=np.nan, strategy='mean')\nimputer2 =SimpleImputer(missing_values = np.nan, strategy = 'median')\ndf[['Evaporation']] = imputer2.fit_transform(df[['Evaporation']])\ndf[['Sunshine']] = imputer1.fit_transform(df[['Sunshine']])\ndf[['Cloud3pm']] = imputer2.fit_transform(df[['Cloud3pm']])\ndf[['Cloud9am']] = imputer1.fit_transform(df[['Cloud9am']])\n#mean and median are same for Pressure9am and Pressure3pm\ndf[['Pressure9am']] = imputer1.fit_transform(df[['Pressure9am']])\ndf[['Pressure3pm']] = imputer1.fit_transform(df[['Pressure3pm']])","5965f602":"df.isnull().sum()","313a1f51":"#Now we can drop missing values and encode categricals\ndf = df.dropna()\n\n#encoding categorical variables to numeric ones\nfrom sklearn.preprocessing import LabelEncoder\nfor c in df.columns:\n    if df[c].dtype=='object':    #Since we are encoding object datatype to integer\/float\n        lbl = LabelEncoder()\n        lbl.fit(list(df[c].values))\n        df[c] = lbl.transform(df[c].values)","5ca3a59f":"df.head()","d1e217f2":"df.RainTomorrow.value_counts()","b9d46076":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ndf.hist(figsize=(20,16), color = 'r');\nplt.show();  #showing the charts of different columns\n#This also helps in finding number of counts in each column","89e37f3e":"df.RainToday.value_counts()","23860750":"zero  = df[df['RainTomorrow']==0]   #zero values in outcome column\none = df[df['RainTomorrow']==1]  # one values in outcome column\nfrom sklearn.utils import resample\ndf_minority_upsampled = resample(one, replace = True, n_samples = 80537) \n#concatenate\ndf = pd.concat([zero, df_minority_upsampled])\n\nfrom sklearn.utils import shuffle\ndf = shuffle(df) # shuffling so that there is particular sequence","0eed36c9":"zero  = df[df['RainToday']==0]   #zero values in outcome column\none = df[df['RainToday']==1]  # one values in outcome column\nfrom sklearn.utils import resample\ndf_minority_upsampled = resample(one, replace = True, n_samples = 108000) \n#concatenate\ndf = pd.concat([zero, df_minority_upsampled])\n\nfrom sklearn.utils import shuffle\ndf = shuffle(df) # shuffling so that there is particular sequence","5858d4af":"df.hist(figsize=(20,16), color = 'r');\nplt.show();","022ab6da":"#Checking which columns are mostly correlated with the target\ndf.corr().abs()['RainTomorrow'].sort_values(ascending = False)","9203e77d":"X = df.drop(['RainTomorrow'], axis = 1)\ny = df['RainTomorrow']","92000b8e":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\n\nfs = SelectKBest(score_func=f_classif, k=15)\n# apply feature selection\nX_selected = fs.fit_transform(X, y)\nprint(X_selected.shape)","aae4f455":"# Get columns to keep and create new dataframe with those only\ncols = fs.get_support(indices=True)\nX_new = X.iloc[:,cols]","09ab5292":"X_new","9c35d6d2":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size = 0.25, random_state = 42)\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","ecad03f3":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n  # create model\nmodel = Sequential()\nmodel.add(Dense(1024, input_dim= 15, activation='relu'))\nmodel.add(Dense(712, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nearly_stopping = keras.callbacks.EarlyStopping( patience = 12, min_delta = 0.001,\n                                               restore_best_weights =True )\n# Compile model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n# Fit the model\nhistory = model.fit(X_train, y_train, epochs=50, batch_size=100, \n                     validation_data=(X_test, y_test),\n                    verbose=1)\n# evaluate the model\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n","212ff949":"model.evaluate(X_test, y_test)","1392c39b":"model.evaluate(X_train, y_train)","78aebb76":"predictions =(model.predict(X_test)>0.5).astype(\"int32\")\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, predictions))","55f6f0fd":"# Feature Selection","2b2d1e16":"## Upvote if you like it or fork it! This helps us motivate to produce more notebooks for the community \ud83d\ude0a","1e857c92":"# Preprocessing","7dcc3a41":"75% is 10.6 we can impute missing values with mean","f21497da":"# Model building","a49b2110":"Not much difference between train and test results, thus no overfitting!","fa969276":"Similarly after checking I would impute missing values for cloud3pm, cloud9am","222ab707":"Our target column **RainTomorrow** is highly **imbalanced** with No values 94906 and Yes value 26884\n\nAlso we would balance RainToday column","1a806088":" 75% is 7.4, we can impute missing values with median.","88855862":"#### 93% Accuracy","fb15450b":"# Scaling and Splitting"}}