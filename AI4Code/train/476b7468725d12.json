{"cell_type":{"49794f3c":"code","ff5be406":"code","d007437d":"code","3078e817":"code","fda9a92f":"code","805a8148":"code","730a65ab":"code","c85925ea":"code","aa7f8735":"code","f5fb9985":"code","44bcb0b4":"code","bd823e29":"code","65e5e7bd":"code","e49ea52e":"code","74fb6a79":"code","de495357":"code","aa5451a8":"code","7a64b801":"code","62f44e5f":"code","c4127c70":"code","66eb5b25":"code","b33f547c":"code","89dcfbdd":"code","8b294973":"code","323ebcb0":"code","5db028b0":"code","4b5ce3be":"code","31c2cdfd":"code","172db0c2":"code","f700fa79":"code","64c01fe1":"code","95124538":"code","75395c13":"code","5f3393a1":"code","e6d61ef9":"code","a1614a60":"code","3829b439":"code","b8263485":"code","6f4ad31b":"code","0f2e74a5":"code","f714fa37":"code","4f03f889":"code","9d5e40ee":"code","b484aa62":"code","700e4d11":"code","b3c579e2":"code","e1e16832":"code","83506f84":"code","29b7d3d5":"code","124d8de7":"code","d7abcead":"code","949ac5ec":"code","42388e11":"code","8db9016c":"code","77f094fe":"code","c8ca38fb":"code","1b5f888e":"code","625b5510":"code","b1c9b1f6":"code","4f7b2abe":"code","50d9269a":"code","fe3924a1":"code","f9eddf45":"code","e119bc8f":"code","d75bd360":"code","a82f2d37":"code","0998d33f":"code","7a473693":"code","9b35729b":"code","5def6242":"code","a6d02477":"markdown","0b262d36":"markdown","0424f0b5":"markdown","c6fef828":"markdown","6db072c3":"markdown","09b39f0a":"markdown","a67ac2a2":"markdown","729e7797":"markdown","a7acde93":"markdown","876be8e2":"markdown","74b6cec0":"markdown","caa26095":"markdown","88e75571":"markdown","82ba1bda":"markdown","196934ce":"markdown","b93bec73":"markdown","1627c7dc":"markdown","d5dfbda3":"markdown","b1f3ca2b":"markdown","3285db8a":"markdown","9b6cbff7":"markdown","0ade48fc":"markdown","ffbb07ee":"markdown","a7c87d1c":"markdown","5c8cf64c":"markdown","f8756b6c":"markdown","53f7a887":"markdown","44e4d69c":"markdown","d4ff369a":"markdown","ebbf376f":"markdown","a5203fe5":"markdown","495204c4":"markdown","eab61b25":"markdown","3f427f2b":"markdown","a389a26c":"markdown","824ceb3e":"markdown","bb7defa6":"markdown","22009cbb":"markdown","cbe3f8a3":"markdown","80ba5bee":"markdown","b6d81b7e":"markdown","f9b2b399":"markdown"},"source":{"49794f3c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as  plt\nimport seaborn as sns\nfrom datetime import timedelta\nplt.style.use('fivethirtyeight')\n","ff5be406":"! pwd","d007437d":"df = pd.read_csv('\/kaggle\/input\/saudi-arabia-weather-history\/weather-sa-2017-2019-clean.csv')\ndf.shape","3078e817":"df.head()","fda9a92f":"df.info()","805a8148":"# Unnamed: 0 is irrlevent \n# date and time are duplicated features \ndelete_col =['Unnamed: 0','date','time' ]\ndf.drop(delete_col, axis =1 , inplace =True)","730a65ab":"#replace space to NULL if found in the datafram\ndf = df.replace(\" \", np.nan).replace(\"N\/A\", np.nan ).replace(\"NA\", np.nan).replace(\"\", np.nan)","c85925ea":"df['humidity'] = df['humidity'].str.replace('%',' ').astype('float')\n","aa7f8735":"df.isnull().sum()","f5fb9985":"# Here to display the means per city.\ndf.groupby(by='city')[['humidity','barometer']].mean().reset_index()\n","44bcb0b4":"# now filling the missing values with means for each city\ndf['humidity'] = df['humidity'].fillna(df.groupby('city')['humidity'].transform('mean'))\n","bd823e29":"df['barometer'] = df['barometer'].fillna(df.groupby('city')['barometer'].transform('mean'))\n","65e5e7bd":"df.isnull().sum()","e49ea52e":"df.describe()","74fb6a79":"df['weather'].unique()","de495357":"# creating the target `rain`\ndf['rain'] = df['weather'].str.contains('rain|shower|thunderstorm|thundershowers', case = False ,regex=True)\n","aa5451a8":"# lets check a sample\ndf.groupby('weather')['rain'].unique().sample(20)","7a64b801":"df['rain'].value_counts()","62f44e5f":"# Now we don't need the weather column because we on intrested in rain.\ndf.drop('weather', axis =1 , inplace =True)","c4127c70":"df.loc[:,'temp':'visibility'].describe()","66eb5b25":"num_cols=df.loc[:,'temp':'visibility'].select_dtypes(include=['int64','float64']).columns.tolist() # a revised list of numerical features  \n\n\n#sns.set_style('darkgrid')\n#sns.set_palette(\"Spectral\" )\nfor i in num_cols:\n   \n    fig, axs = plt.subplots(1,2,figsize=(15, 3))\n\n    sns.histplot(df[i],bins=20, kde=True,ax=axs[0]);\n    sns.boxplot(x= df[i], ax = axs[1], color='#99befd', fliersize=1);\n    \n    axs[0].axvline(df[i].mean(), color='r', linewidth=2, linestyle='--', label='Mean')\n    axs[0].legend()","b33f547c":"# find outliers for temp variable\ncolumns = df.loc[:,'temp':'visibility'].columns\n\n\nfor f in columns:\n    IQR = df[f].quantile(0.75) - df[f].quantile(0.25)\n    Lower_fence = df[f].quantile(0.25) - (IQR * 1.5)\n    Upper_fence = df[f].quantile(0.75) + (IQR * 1.5)\n    print(f,' outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))\n","89dcfbdd":"correlation = df.corr()","8b294973":"plt.figure(figsize=(16,12))\nplt.title('Correlation Heatmap of Rain in Saudi Arabia Dataset')\nax = sns.heatmap(correlation, square=True, annot=True, fmt='.2f', linecolor='white')\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)\nax.set_yticklabels(ax.get_yticklabels(), rotation=30)           \nplt.show()","323ebcb0":"sns.pairplot(df.loc[:,'year':'visibility'].sample(3000) ,hue='year')","5db028b0":"#check labels target\nf, ax = plt.subplots(figsize=(8, 5))\nplt.title('Number of rains in Saudi Arabia b\/w 2017 -2019')\nax = sns.countplot(x=\"rain\", data=df, palette=\"Set1\")\nplt.show()","4b5ce3be":"df['rain'].value_counts()","31c2cdfd":"city_rain_rate = pd.DataFrame(df.groupby(by=['city','year'])['rain'].sum())","172db0c2":"city_rain_rate = city_rain_rate.reset_index()","f700fa79":"plt.subplots(figsize=(14, 7))\n\n\nsns.set_style('darkgrid')\nsns.set_palette(\"Spectral\" )\nsns.barplot(data=city_rain_rate, x=\"city\", y=\"rain\", ci=None, hue='year')\nplt.title('Number of rains in Saudi Arabia per city b\/w 2017 - 2019')\nplt.xlabel('City' )\nplt.ylabel('Rain Count')\nplt.xticks(rotation=35)\nsns.despine()\n\nplt.show()","64c01fe1":"df.loc[:,'temp':'visibility'].describe()","95124538":"# setting the outliers to max or min value \ndf['temp'] = np.where(df['temp']<-1.5 , -1.5 , df['temp'])\ndf['wind'] = np.where(df['wind']>37.0, 37.0, df['wind'])\ndf['wind'] = np.where(df['wind']<0, 0, df['wind'])\ndf['visibility'] = np.where(df['visibility']>32.5, 32.5, df['visibility'])\ndf['visibility'] = np.where(df['visibility']<0, 0, df['visibility'])\ndf['barometer'] = np.where(df['barometer']>1036.0, 1036.0, df['barometer'])\ndf['barometer'] = np.where(df['barometer']<996.0 , 996.0 , df['barometer'])","75395c13":"df.loc[:,'temp':'visibility'].describe()","5f3393a1":"num_cols=df.loc[:,'temp':'visibility'].select_dtypes(include=['int64','float64']).columns.tolist() # a revised list of numerical features  \n\nfor i in num_cols:\n   \n    fig, axs = plt.subplots(1,2,figsize=(15, 3))\n\n    sns.histplot(df[i],bins=20, kde=True,ax=axs[0]);\n    sns.boxplot(x= df[i], ax = axs[1], color='#99befd', fliersize=1);\n    \n    axs[0].axvline(df[i].mean(), color='r', linewidth=2, linestyle='--', label='Mean')\n    axs[0].legend()","e6d61ef9":"c = pd.get_dummies(df['city'], drop_first=True)\n\ndf  = pd.concat([c,df], axis=1 )","a1614a60":"df.drop('city' , axis =1 , inplace= True)","3829b439":"df.head()","b8263485":"df['rain'].value_counts()","6f4ad31b":"X = df.drop(['rain'], axis=1)\ny = df['rain']","0f2e74a5":"#check labels target\nfig, axs = plt.subplots(1,2,figsize=(15, 3))\nplt.subplot(1, 2, 1)\n\nplt.title('Number of rains before resampling')\nax = sns.countplot(x=\"rain\", data=df, palette=\"Set1\")\n\nplt.subplot(1, 2, 2)\nfig = sns.scatterplot(data=df, x=\"temp\", y=\"barometer\", hue=\"rain\")\nfig.set_xlabel('temp')\nfig.set_ylabel('Pressure')\nfig.set_title('The relationship between the temperature and pressure');\nplt.show()","f714fa37":"from imblearn.over_sampling import SMOTE","4f03f889":"oversample = SMOTE()\nX, y = oversample.fit_resample(X, y)","9d5e40ee":"# df_resampled just for visualiation\ndf_resampled = pd.concat([X,y], axis =1)","b484aa62":"df_resampled['rain'].value_counts()","700e4d11":"#just to just to illustrate the difference\nfig, axs = plt.subplots(1,2,figsize=(15, 3))\nplt.subplot(1, 2, 1)\n\nplt.title('Number of rains after resampling')\nax = sns.countplot(x=\"rain\", data=df_resampled, palette=\"Set1\")\n\nplt.subplot(1, 2, 2)\nfig = sns.scatterplot(data=df_resampled, x=\"temp\", y=\"barometer\", hue=\"rain\")\nfig.set_xlabel('temp')\nfig.set_ylabel('Pressure')\nfig.set_title('The relationship between the temperature and pressure');\nplt.show()","b3c579e2":"# first lets split to train and test sets\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)","e1e16832":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n","83506f84":"X_train.shape , X_test.shape","29b7d3d5":"# train a logistic regression model on the training set\nfrom sklearn.linear_model import LogisticRegression\n\n# instantiate the model\nlg = LogisticRegression(solver= 'liblinear', C=1000)\n\n# fit the model\nlg.fit(X_train, y_train)","124d8de7":"# predict the test set\ny_pred_lg = lg.predict(X_test)","d7abcead":"from sklearn.metrics import accuracy_score\n\nprint('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred_lg)))\nprint('Training set score: {:.4f}'.format(lg.score(X_train, y_train)))","949ac5ec":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y_pred_lg))","42388e11":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred_lg)\nlg_cm = pd.DataFrame(cm)\nlg_score = accuracy_score(y_test, y_pred_lg)","8db9016c":"# visualisng confusing matrix\ndef vcm(cm):\n    group_names = ['True Neg','False Pos','False Neg','True Pos']\n    group_counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n    group_percentages = [\"{0:.2%}\".format(value) for value in cm.flatten()\/np.sum(cm)]\n    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n    labels = np.asarray(labels).reshape(2,2)\n    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues')\n\nvcm(cm)","77f094fe":"import tensorflow as tf\n#Initializing the ANN\nann = tf.keras.models.Sequential()\ntf.__version__ # checking tf version","c8ca38fb":"# Adding the input layer and the first hidden layer\n\nann.add(tf.keras.layers.Dense(units=6, activation='relu'))","1b5f888e":"# Adding the second hidden layer\nann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n","625b5510":"# Adding the output layer\nann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))","b1c9b1f6":"# Compiling the ANN\nann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","4f7b2abe":"# Training the ANN on the Training set\nann.fit(X_train, y_train, batch_size = 3200, epochs = 100)","50d9269a":"y_pred_ann = ann.predict(X_test)\ny_pred_ann = (y_pred_ann > 0.5)\n","fe3924a1":"ann_score = accuracy_score(y_test, y_pred_ann)\nann_score\n\nprint('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred_ann)))","f9eddf45":"print(classification_report(y_test, y_pred_ann))","e119bc8f":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred_ann)\n\n# visualisng confusing matrix\nvcm(cm)","d75bd360":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\nclassifier.fit(X_train, y_train)","a82f2d37":"y_pred_rf = classifier.predict(X_test)","0998d33f":"print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred_rf)))\nprint('Training set score: {:.4f}'.format(classifier.score(X_train, y_train)))","7a473693":"print(classification_report(y_test, y_pred_rf))","9b35729b":"cm = confusion_matrix(y_test, y_pred_rf)\nrf_score =accuracy_score(y_test, y_pred_rf)\n\n# visualisng confusing matrix\nvcm(cm)","5def6242":"print('LogisticRegression :' , round(lg_score * 100,2) , '%')\nprint('Artificial Neural Network :' , round(ann_score* 100,2), '%')\nprint('RandomForestClassifier' , round(rf_score* 100,2), '%')","a6d02477":"### 2.3 Dealing with missing values","0b262d36":"- `temp`  outliers are values < -1.5 or > 50.5\n- `wind`  outliers are values < -11.0 or > 37.0\n- `humidity`  outliers are values < -40.0 or > 112.0\n- `barometer`  outliers are values < 996.0 or > 1036.0\n- `visibility`  outliers are values < -11.5 or > 32.5\n","0424f0b5":"I just showed the current rain observation with 3327 out of 249023 . Next I will implement SMOTE for balancing the data.","c6fef828":"### 2.1 Lets Drop irrelated and duplicated features","6db072c3":"this barchat shows that most of the rain was 2018 most of the time.\n\n","09b39f0a":"it is obvious that `weather` in the dataset represents the weather phenomenas, which are in a text format. and multiple phenomena merged together. Since we are predicting the rain only, So we will extract the keywords `rain` and it's synonyms and placed in a new column shows the result whether is rained or not raind on that day.","a67ac2a2":"### 4.1 Engineering outliers in numerical variables","729e7797":"# 3. EDA","a7acde93":"### 2.2 Lets convert feature `humidity` to Numerical","876be8e2":"3327 observations was rained and 245696 was not so, data is imbalnced ","74b6cec0":"### confusing Matrix on random Forest","caa26095":"### 4.2 Feature Scaling","88e75571":"# 5. Model","82ba1bda":"### confusing Matrix on ANN","196934ce":"### Confusing Matrix on logistic regression model","b93bec73":"Thank you.","1627c7dc":"#### 3.2 Explorering rain cross cities and years","d5dfbda3":"### 3.1 identify outliers","b1f3ca2b":"### 2.4 Extract and create the target ","3285db8a":"We have seen above (3.1) that the  `wind`, `temp`, `visibility`, `barometer`  columns contain outliers. I will use IQR approach to capture maximum and minimum values and remove outliers from the above variables.","9b6cbff7":"Lets discover patterns and relationships between variables in the dataset.","0ade48fc":"We can see that too many outliers on `wind`, and few on `temp`, `visibility`, `barometer` and shows skewed distribution. So, I will use interquantile range to find outliers.","ffbb07ee":"Lets check weather phenomena","a7c87d1c":"Apply one HostEncoding to the city variables","5c8cf64c":"#### I decide to get means of the humidity and barometer per each city to be replaced with missing values.\n","f8756b6c":"In Conclusion, I have cleaned up the dataset by replacing the missing values with mean per city. \nIn addion, I extracted the `Rain` from the `weather` to form up the target. Further more, I have reseted the outliers to the minimum and maximum values then I have balanced the data with SMOTE and the Feature Scaling is implemented.\n\nFinaly, I have train the traing dataset with three models and get the accuracy, recall, precision and F1-score:\n\n1- `LogisticRegression`.\n\n2- `Artificial Neural Network` (ANN).\n\n3- `RandomForestClassifier`.\n\nIt seems that, `RandomForestClassifier` was the best model fit with accuracy score `99.59 %`.\n","53f7a887":"# 2. Loading the data and data cleaning","44e4d69c":"It show that we have 10 Numerical with int and float variable and 5 Categorical variable with object datatype","d4ff369a":"We have 17 missing values in `humidity`\nand 71 missing value in `barometer`","ebbf376f":"### 5.3 Artificial Neural Network (ANN) model\n\n","a5203fe5":"### 4.1  Deal with imbalanced","495204c4":"checking the means for `humidity` and `barometer` for each city.","eab61b25":"#### Predicting the Test set results","3f427f2b":"### 5.1 logistic regression model\n\n","a389a26c":"dataset are not balnced to I will implement RandomUnderSampler","824ceb3e":"This project is aim to use historical weather data like temperature, humidity, windspeed, visibility and the pressure, and predict whater was rained or not. the target is extracted from `weather` Since the purpose is to predict the rain only.\n","bb7defa6":"SMOTE has balanced my data equaly with 245696 in each label.","22009cbb":"# 4. Features Engineering","cbe3f8a3":"### 6. Conclusion ","80ba5bee":"### 5.3 Random Forest","b6d81b7e":"There no stronge positive relationship between the features\n - `barometer` and `humidity` positively correlated with correlation coefficient = 0.29. \n - `temp`and `month` positively correlated with correlation coefficient = 0.23. \n - `temp`and `hours` positively correlated with correlation coefficient = 0.21.\n - `wind`and `hours` positively correlated with correlation coefficient = 0.20.\n - `temp`and `wind`  positively correlated with correlation coefficient = 0.24.\n\n - `temp`and `barometer`  Negatively correlated with correlation coefficient = -0.68.\n - `temp`and `humidity`  Negatively correlated with correlation coefficient = -0.60.\n\n Also the pattren in pairplot Illustrate the relations.\n \n ","f9b2b399":"# 1. Import the libraries "}}