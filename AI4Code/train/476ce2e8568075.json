{"cell_type":{"0b7a8a15":"code","6adb7ef3":"code","851696d2":"code","b691e56c":"code","b393d2c7":"code","9c077f1c":"code","a8bbce55":"code","15b4d4e5":"code","213ae13f":"code","21e96cf6":"code","0750011b":"code","4292d1db":"code","b3cf6ced":"code","adfe4d9f":"code","0e1d1bd9":"code","1165cc7c":"code","b91ebfe3":"code","58879a1b":"code","50d3b9a2":"code","32f1026b":"code","b9bf9726":"code","0a13ce41":"code","956a2d0f":"code","5fd451f1":"code","ad847916":"code","90e503b8":"code","f732fe52":"code","715f447b":"code","5134379d":"code","f7c698ed":"code","a1470bdc":"code","69f02752":"code","0905173f":"code","bcb422e8":"code","7b294bc8":"code","e29cb532":"code","316b2a30":"code","d4137361":"code","2b299526":"code","4e3f1356":"code","dbd1a5f5":"code","f5e54717":"code","53633fed":"code","1fb834a3":"code","694806e4":"code","5e92c81c":"code","0c7c0f1c":"code","8ef43a3d":"code","f90acb02":"code","203a0b80":"code","6e475f4a":"code","6e8c708e":"code","3d849252":"code","4d092f01":"code","d973a0b6":"code","bdafd3f5":"code","2f2b6c6d":"code","83a48c07":"code","f7320941":"markdown","f1ad4f90":"markdown","b6d9674d":"markdown","8e7170ee":"markdown","6ea5ae5b":"markdown","498b771a":"markdown","8d49858f":"markdown","3a30411b":"markdown","d5caf8d1":"markdown","9a728402":"markdown","ecef0a4e":"markdown","07e8de8b":"markdown","5f8e24aa":"markdown","6250cb2a":"markdown","5abc988c":"markdown","8d31bcfd":"markdown","26c78a85":"markdown","e68cce81":"markdown","16da2302":"markdown","43185f3f":"markdown"},"source":{"0b7a8a15":"!pip install split-folders","6adb7ef3":"import os\nimport gc\nimport PIL\nimport pytz\nimport time\nimport shutil\nimport random\nimport splitfolders\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nimport albumentations as A\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom collections import Counter\nfrom datetime import datetime,timezone\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import confusion_matrix,classification_report","851696d2":"import warnings\nwarnings.filterwarnings(\"ignore\")","b691e56c":"os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'","b393d2c7":"print(\"Tensorflow Version:\",tf.__version__)","9c077f1c":"print(\"GPU\",\"available!!\" if tf.config.list_physical_devices(\"GPU\") else \"not available!\")","a8bbce55":"src_root_folder = \"\/kaggle\/input\/rock-classification\/Dataset\"\ndst_root_folder = \"\/kaggle\/working\/rock-classification\/Dataset\"\nsrc_rock_sub_classes = []\ndst_rock_sub_classes = []\nrock_classes = os.listdir(src_root_folder)\nfor rock_class in rock_classes:\n    sub_classes = os.listdir(os.path.join(src_root_folder,rock_class))\n    for sub_class in sub_classes:\n        src_rock_sub_classes.append(os.path.join(src_root_folder,rock_class,sub_class))\n        dst_rock_sub_classes.append(os.path.join(dst_root_folder,sub_class))","15b4d4e5":"for src, dst in zip(src_rock_sub_classes,dst_rock_sub_classes):\n    shutil.copytree(src,dst)","213ae13f":"root_folder = \"\/kaggle\/working\/rock-classification\/Dataset\"","21e96cf6":"def find_filepaths(root_folder):\n    filepaths = []\n    for dirname, _, filenames in os.walk(root_folder):\n        for filename in filenames:\n            filepaths.append(os.path.join(dirname, filename))\n    return filepaths","0750011b":"def del_corrupted_images(filepaths):\n    del_count = 0\n    for filepath in filepaths:\n        try:\n            fobj = open(filepath,'rb')\n            is_JFIF =  b'JFIF' in fobj.peek(10)\n        finally:\n            fobj.close()\n        if not is_JFIF:\n            del_count += 1\n            os.remove(filepath)\n    print(f\"Total {del_count} corrupted image deleted\")\n    return None","4292d1db":"filepaths = find_filepaths(root_folder)\ntotal_images_before_deletion = len(filepaths)\nprint(f\"Total images before deletion = {total_images_before_deletion}\")","b3cf6ced":"filepaths = find_filepaths(root_folder)\ndel_corrupted_images(filepaths)","adfe4d9f":"filepaths = find_filepaths(root_folder)\ntotal_images_after_deletion = len(filepaths)\nprint(f\"Total images after deletion = {total_images_after_deletion}\")","0e1d1bd9":"input_dir = \"\/kaggle\/working\/rock-classification\/Dataset\"\noutput_dir =  \"\/kaggle\/working\/rock-classification\/SplitDataset\"","1165cc7c":"splitfolders.ratio(input_dir, output=output_dir, seed=1337, ratio=(.8,.1,.1), group_prefix=None)","b91ebfe3":"print(os.listdir(output_dir))","58879a1b":"IMG_SHAPE = (224,224,3) # Required for MobileNetV3\ntrain_dataset_dir = \"\/kaggle\/working\/rock-classification\/SplitDataset\/train\"\nval_dataset_dir = \"\/kaggle\/working\/rock-classification\/SplitDataset\/val\"\ntest_dataset_dir = \"\/kaggle\/working\/rock-classification\/SplitDataset\/test\"","50d3b9a2":"rock_classes = os.listdir(train_dataset_dir)\nfilepaths = find_filepaths(train_dataset_dir)\nprint(f\"----- Trainig Set Info -----\")\nprint(f\"Rock Classes = {rock_classes}\")\nprint(f\"Toatal rock classes = {len(rock_classes)}\")\nprint(f\"Total number of images = {len(filepaths)}\")","32f1026b":"rock_classes = os.listdir(val_dataset_dir)\nfilepaths = find_filepaths(val_dataset_dir)\nprint(f\"----- Validation Set Info -----\")\nprint(f\"Rock Classes = {rock_classes}\")\nprint(f\"Toatal rock classes = {len(rock_classes)}\")\nprint(f\"Total number of images = {len(filepaths)}\")","b9bf9726":"rock_classes = os.listdir(test_dataset_dir)\nfilepaths = find_filepaths(test_dataset_dir)\nprint(f\"----- Test Set Info -----\")\nprint(f\"Rock Classes = {rock_classes}\")\nprint(f\"Toatal rock classes = {len(rock_classes)}\")\nprint(f\"Total number of images = {len(filepaths)}\")","0a13ce41":"def min_max_scalar(img, scale_range =(0, 1)):\n    \n    px_min = scale_range[0]\n    px_max = scale_range[1]\n    img = img.astype('float32')\n    img = img\/img.max()\n    scaled_img = img * (px_max - px_min) + px_min\n    return scaled_img\n\ndef resize(img,size):\n    resized_img = img.resize(size, Image.ANTIALIAS)\n    resized_img_array = np.asarray(resized_img)\n    return resized_img_array","956a2d0f":"def load_and_prepare_dataset(dataset_dir,IMG_SHAPE):\n    \n    rock_classes = os.listdir(dataset_dir)\n    \n    filepaths = find_filepaths(dataset_dir)\n    no_of_total_images = len(filepaths)\n    \n    data = np.zeros((no_of_total_images,*IMG_SHAPE),dtype='float32')\n    label = []\n    ix = 0\n    \n    for class_label in rock_classes:\n        class_path = os.path.join(dataset_dir, class_label)\n        for img in os.listdir(class_path):\n            image = Image.open(os.path.join(class_path, img))\n            resized_image = resize(image,IMG_SHAPE[:-1])\n            image_array = min_max_scalar(resized_image)\n            if image_array.shape == IMG_SHAPE:\n                data[ix]=image_array\n                label.append(class_label)\n            else:\n                image_array=np.stack((image_array,)*3, axis=-1)\n                data[ix]=image_array\n                label.append(class_label)\n            ix += 1\n    label = np.asarray(label)\n    label = label.reshape((-1,1))\n        \n    return data,label","5fd451f1":"X_train,y_train = load_and_prepare_dataset(train_dataset_dir,IMG_SHAPE)\nX_val,y_val = load_and_prepare_dataset(val_dataset_dir,IMG_SHAPE)\nX_test,y_test = load_and_prepare_dataset(test_dataset_dir,IMG_SHAPE)","ad847916":"print(f\"Shape of X_train = {X_train.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of X_val = {X_val.shape}\")\nprint(f\"Shape of y_val = {y_val.shape}\")\nprint(f\"Shape of X_test = {X_test.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","90e503b8":"def show_unique_images(X,y,idx=0):\n    y = np.squeeze(y)\n    unique = np.unique(y)\n    index=[]\n    for i in unique:\n        try:\n            r = np.where(y==i)\n            index.append (r[0][idx])\n        except:\n            pass\n    \n    images=[]\n    labels=[]\n    for i in index:\n        images.append(X[i])\n        labels.append(y[i])\n    \n    plt.figure(figsize=(16,9))\n    \n    for i in range(np.unique(y).size):\n        ax = plt.subplot(1,7, i+1)\n        \n        plt.imshow(images[i])\n        plt.title(labels[i])\n        plt.axis(\"off\")\n        \n    return None\n","f732fe52":"show_unique_images(X_test,y_test)","715f447b":"classes = Counter(np.squeeze(y_train).tolist()).keys()\nvalues =Counter(np.squeeze(y_train).tolist()).values()\nrock_count_per_class_before_smote = dict(zip(classes,values))\nprint(rock_count_per_class_before_smote)","5134379d":"fig = plt.figure(figsize = (10, 5))\n \nrock_names = list(rock_count_per_class_before_smote.keys())\nrock_counts = list(rock_count_per_class_before_smote.values())\nplt.bar(rock_names,rock_counts,color =['c','orange','m','b','g','r','maroon'],width = 0.4)\nplt.tight_layout()  ","f7c698ed":"# Reshaping is important for feeding the data into fit_resample method of SMOTE class\nX_train = X_train.reshape((-1,IMG_SHAPE[0]*IMG_SHAPE[1]*IMG_SHAPE[2]))\nprint(f\"Shape of data is {X_train.shape}\")\nprint(f\"Shape of label is {y_train.shape}\")\nprint(f\"Data type of data is {type(X_train)}\")\nprint(f\"Data type of label is {type(y_train)}\")","a1470bdc":"smote = SMOTE(random_state=42)\nX_train = X_train.reshape((-1,IMG_SHAPE[0]*IMG_SHAPE[1]*IMG_SHAPE[2]))\nX_train, y_train = smote.fit_resample(X_train,y_train)","69f02752":"print(f\"Shape of X_train : {X_train.shape}\")\nprint(f\"Shape of y_train : {y_train.shape}\")","0905173f":"X_train = X_train.reshape((-1,*IMG_SHAPE))\ny_train = y_train.reshape((-1,1))\nprint(f\"Shape of X_train : {X_train.shape}\")\nprint(f\"Shape of y_train : {y_train.shape}\")","bcb422e8":"classes = Counter(np.squeeze(y_train).tolist()).keys()\nvalues =Counter(np.squeeze(y_train).tolist()).values()\nrock_count_per_class_after_smote = dict(zip(classes,values))\nprint(rock_count_per_class_after_smote)","7b294bc8":"fig = plt.figure(figsize = (10, 5))\n \nrock_names = list(rock_count_per_class_after_smote.keys())\nrock_counts = list(rock_count_per_class_after_smote.values())\nplt.bar(rock_names,rock_counts,color =['c','orange','m','b','g','r','maroon'],width = 0.4)\nplt.tight_layout()  ","e29cb532":"def one_hot_encoder(array):\n    encoded_array = []\n    unique = np.unique(array)\n    for item in array:\n        encoded_item = item == unique\n        encoded_array.append(encoded_item)\n    encoded_array = np.asarray(encoded_array)\n    encoded_array = encoded_array.astype(int)\n    return encoded_array","316b2a30":"y_train_encoded = one_hot_encoder(y_train)\ny_val_encoded = one_hot_encoder(y_val)\ny_test_encoded = one_hot_encoder(y_test)","d4137361":"print(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_train_encoded = {y_train_encoded.shape}\")\nprint(f\"Shape of y_val = {y_val.shape}\")\nprint(f\"Shape of y_val_encoded = {y_val_encoded.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")\nprint(f\"Shape of y_test_encoded = {y_test_encoded.shape}\")","2b299526":"class PrettyPrint(tf.keras.callbacks.Callback):\n    \n    def __init__(self,batches):\n        super(PrettyPrint,self).__init__()\n        self.batches = batches\n        self.lr = None\n\n    \n    def print_in_color(self,txt_msg,fore_tupple,back_tupple,):\n        #prints the text_msg in the foreground color specified by fore_tupple with the background specified by back_tupple \n        #text_msg is the text, fore_tupple is foregroud color tupple (r,g,b), back_tupple is background tupple (r,g,b)\n        rf,gf,bf=fore_tupple\n        rb,gb,bb=back_tupple\n        msg='{0}' + txt_msg\n        mat='\\33[38;2;' + str(rf) +';' + str(gf) + ';' + str(bf) + ';48;2;' + str(rb) + ';' +str(gb) + ';' + str(bb) +'m' \n        print(msg .format(mat), flush=True)\n        print('\\33[0m', flush=True) # returns default print color to back to black\n        return None\n\n    def on_train_begin(self, logs=None):\n        msg=f\"{'Epoch':^10s}{'Train_Loss':^12s}{'Train_Acc':^12s}{'Val_Loss':^12s}{'Val_Acc':^12s}{'LR':^12s}{'Duration':^10s}\"\n        self.print_in_color(msg, (0, 255, 76), (55,65,80))\n        self.lr = float(tf.keras.backend.get_value(self.model.optimizer.lr))\n\n        \n    def on_train_end(self, logs=None):\n        msg='Training is completed - model is set with weights for the epoch with the lowest loss'\n        self.print_in_color(msg,  (255,100,255), (55,65,80))\n        \n    def on_train_batch_end(self, batch, logs=None):\n        acc=logs.get('accuracy')* 100  # get training accuracy \n        loss=logs.get('loss')\n        msg='{0:20s}processing batch {1:4s} of {2:5s} accuracy= {3:8.3f}  loss: {4:8.5f}'.format(' ', str(batch), str(self.batches), acc, loss)\n        print(msg, '\\r', end='') # prints over on the same line to show running batch count\n        \n    def on_epoch_begin(self,epoch, logs=None):\n        self.start_time = time.time()\n        \n    def on_epoch_end(self, epoch, logs=None):\n        end_time =time.time()\n        duration = end_time-self.start_time\n        \n        lr = self.lr\n        current_lr = float(tf.keras.backend.get_value(self.model.optimizer.lr))\n        if self.lr != current_lr:\n            self.lr = current_lr \n            \n        train_acc = logs.get('accuracy')*100\n        train_loss = logs.get('loss')\n        val_acc = logs.get('val_accuracy')*100\n        val_loss =logs.get('val_loss')\n        \n        msg = f\"{str(epoch+1):^10s}{train_loss:^12.3f}{train_acc:^12.3f}{val_loss:^12.5f}{val_acc:^12.5f}{lr:^12.9f}{duration:^10.3f}\"\n        self.print_in_color (msg,(0,255,255), (55,65,80))\n    ","4e3f1356":"from tensorflow.keras.applications.mobilenet import MobileNet\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout,BatchNormalization\nfrom tensorflow.keras.optimizers import Adamax\nfrom tensorflow.keras.regularizers import l1_l2","dbd1a5f5":"BaseModel = MobileNet(weights='imagenet', include_top=False, input_shape= IMG_SHAPE )","f5e54717":"output_size = len(y_train_encoded[0])\nprint(f\"Output Size = {output_size}\")","53633fed":"model = Sequential()\n\nmodel.add(BaseModel)\n\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(256, activation='relu',\n                kernel_regularizer=l1_l2(0.01),\n                bias_regularizer=l1_l2(0.01)))\n\nmodel.add(BatchNormalization())\nmodel.add(Dropout(.3))\nmodel.add(Dense(output_size, activation='softmax'))\n\nmodel.summary()","1fb834a3":"model.compile(loss='categorical_crossentropy',\n              optimizer=Adamax(learning_rate=0.001),\n              metrics=['accuracy']) ","694806e4":"batch_size = 32\ntrain_steps=int(len(y_train)\/batch_size)\nbatches=train_steps","5e92c81c":"color_print = PrettyPrint(batches)\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",factor=0.5,\n                                                 patience=1,verbose=0)\nearly_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",patience=5,verbose=0,\n                                              restore_best_weights=True)\n\ncallbacks = [color_print,reduce_lr,early_stop]","0c7c0f1c":"# Check if all the shapes are ok \nprint(X_train.shape[0]==y_train_encoded.shape[0])\nprint(type(X_train) == type(y_train_encoded))\nprint(X_train.shape)\nprint(y_train_encoded.shape)\nprint(X_val.shape)\nprint(y_val_encoded.shape)","8ef43a3d":"history = model.fit(X_train,y_train_encoded, \n                    validation_data=(X_val,y_val_encoded),\n                    batch_size=batch_size, epochs=30,verbose=0,\n                    callbacks=callbacks)","f90acb02":"def plot_accuracy_loss(history):\n    f,ax = plt.subplots(1,2,figsize=(12,6))\n    \n    ax[0].plot([None]+history.history['accuracy'],'o-')\n    ax[0].plot([None]+history.history['val_accuracy'],'o-')\n    ax[0].legend(['Train Accuracy','Validation Accuracy'],loc = 0)\n    ax[0].set_title('Training & Validation accuracy')\n    ax[0].set_xlabel('Epoch')\n    ax[0].set_ylabel('Accuracy')\n\n    ax[1].plot([None]+history.history['loss'],'o-')\n    ax[1].plot([None]+history.history['val_loss'],'o-')\n    ax[1].legend(['Training Loss','Validation Loss'],loc = 0)\n    ax[1].set_title('Training & Validation loss')\n    ax[1].set_xlabel('Epoch')\n    ax[1].set_ylabel('Loss')\n    \n    plt.style.use('ggplot')\n    plt.tight_layout()\n    plt.show()\n    \n    return None\n","203a0b80":"plot_accuracy_loss(history)","6e475f4a":"result = model.evaluate(X_test,y_test_encoded)\nprint(result)","6e8c708e":"predictions =np.argmax(model.predict(X_test), axis=-1)\nprint(predictions)","3d849252":"def label_encoder(string):\n    rock_classes = ['Basalt','Coal', 'Granite','Limestone','Marble','Quartzite', 'Sandstone']\n    for i,rock in enumerate(rock_classes):\n        if string == rock:\n            return i\ny_test_enc = np.asarray(list(map(label_encoder,np.squeeze(y_test).tolist())))\nprint(y_test_enc)","4d092f01":"print(classification_report(y_test_enc,predictions))","d973a0b6":"def display_confusion_matrix(confusion_matrix,labels):\n    conf_matrix_df = pd.DataFrame(confusion_matrix,\n                         index = labels,\n                         columns = labels)\n    plt.figure(figsize=(15,6))\n    sns.heatmap(conf_matrix_df, annot=True)\n    plt.title('Confusion Matrix')\n    plt.ylabel('Actal Values')\n    plt.xlabel('Predicted Values')\n    plt.show()\n    return None","bdafd3f5":"labels = ['Basalt','Coal', 'Granite','Limestone','Marble','Quartzite', 'Sandstone']\nconf_matrix = confusion_matrix(y_test_enc,predictions)\ndisplay_confusion_matrix(conf_matrix,labels)","2f2b6c6d":"def save_model(model, model_dir, prefix, time=False):\n    \n    local_timezone = pytz.timezone('Asia\/Dhaka')\n    utc_time = datetime.now()\n    x = utc_time.replace(tzinfo=timezone.utc).astimezone(tz=local_timezone)\n    \n    if time:\n        time = str(x.day)+\"-\"+str(x.month)+\"-\"+str(x.year)+\"--\"+x.strftime(\"%I\")+\":\"+x.strftime(\"%M\")+x.strftime(\"%p\")\n        save_format = prefix+\"--\"+time+ \".h5\"\n    else:\n        save_format = prefix+\".h5\"\n    \n    model_path = os.path.join(model_dir,save_format)\n    print(f\"Saving model to: {model_path}...\")\n    model.save(model_path)\n    \n    return model_path\n\n\ndef load_model(model_path):\n    print(f\"Loading saved model from: {model_path}\")\n    model = load_model(model_path,custom)\n    return model","83a48c07":"model_dir = \".\/rock-classification\/SavedModels\"\nif not os.path.exists(model_dir):\n    os.mkdir(model_dir)\nprefix = \"MobileNet-Adamax\"\nmodel_path = save_model(model,model_dir,prefix,time=True)\nprint(model_path)","f7320941":"### **Defining the Model**","f1ad4f90":"## Visualizing the rock classes","b6d9674d":"## Installing and Importing libraries","8e7170ee":"## Deleting corrupted Images","6ea5ae5b":"## Save and Load Model","498b771a":"### Training the Model","8d49858f":"### **Compiling the model**","3a30411b":"## Applying SMOTE to remove data imbalance","d5caf8d1":"## Spliting dataset into train, val and test folders","9a728402":"## Class distribution after smote","ecef0a4e":"## Build, Compile & Train the Model","07e8de8b":"## Loading and preparing the data\n#### 1. `Load the data`\n#### 2. `Resize images`\n#### 3. `Normalize pixels`","5f8e24aa":"## Class distribution before smote","6250cb2a":"## Custom Callback","5abc988c":"## Making sub-class-wise folders","8d31bcfd":"## One hot encoding","26c78a85":"### Plot loss and accuracy","e68cce81":"## Acknowledgements\n### 1. [SMOTE for imbalanced classification](https:\/\/machinelearningmastery.com\/smote-oversampling-for-imbalanced-classification\/)\n### 2. [Gerry's notebook on custom callback](https:\/\/www.kaggle.com\/gpiosenka\/f1-score-99-custom-callback-you-may-like)","16da2302":"### **Callbacks**","43185f3f":"## Evaluate Model's performance"}}