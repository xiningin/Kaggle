{"cell_type":{"355d686a":"code","9e068f03":"code","0121f855":"code","02d9b4ea":"code","d14da70d":"code","ee9440ef":"code","734130be":"code","1a93ab1d":"code","ca91038a":"code","f12c6d39":"code","20d5a88c":"code","141bb61a":"markdown","e0292c20":"markdown","b762d493":"markdown","b81fe4b1":"markdown","b04526dd":"markdown","230169e0":"markdown","3804fc93":"markdown","bc086f3d":"markdown"},"source":{"355d686a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mlxtend.frequent_patterns import apriori,association_rules\nimport zipfile\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","9e068f03":"zf1 = zipfile.ZipFile('..\/input\/instacart-market-basket-analysis\/order_products__prior.csv.zip')\norder_prod = pd.read_csv(zf1.open('order_products__prior.csv'))\nzf2 = zipfile.ZipFile('..\/input\/instacart-market-basket-analysis\/products.csv.zip')\nprod = pd.read_csv(zf2.open('products.csv'))","0121f855":"data = pd.merge(order_prod,prod,how='inner',on='product_id')\ndata.head()","02d9b4ea":"data = data[data['order_id']<10000]","d14da70d":"df_item = data[['order_id','product_name']].copy()\ndf_item.rename(columns={'order_id':'order','product_name':'items'},inplace=True)\ndf_item['temp']=1","ee9440ef":"df = df_item.groupby(['order','items'])['temp'].sum().unstack().fillna(0)","734130be":"def myencoder(i):\n    if i <= 0:\n        return 0\n    elif i>=1:\n        return 1","1a93ab1d":"df.applymap(myencoder)","ca91038a":"freq_itemsets = apriori(df,min_support=0.01,use_colnames=True)\nfreq_itemsets","f12c6d39":"rules = association_rules(freq_itemsets,metric='lift',min_threshold=1)\nrules.sort_values(by='confidence',ascending=False)","20d5a88c":"rules[(rules['confidence']>0.16) & (rules['lift']>2)]","141bb61a":"Importing files in script using **zipfile** library(csv's are zipped) and pandas to read file.\n\n*Note: Didn't use zip compression in read_csv as zip file contains more than one file.*","e0292c20":"**Frequent Itemsets Mining**","b762d493":"Filtering rules based on some of my own assumptions.\n\nNote: The chosen threshold for confidence and lift is entirely upto my trial and test. No technical way used.","b81fe4b1":"An encoder to covert numbers greater than 1 to 1 and less than 0 to 0.","b04526dd":"Making transaction data ready for Frequent item set mining.","230169e0":"Sampling data of first **10000 order** transactions from total population, due to memory constraint.","3804fc93":"Merging the files to get a single dataframe with both order and item details","bc086f3d":" **Association Rules Mining**"}}