{"cell_type":{"d6561562":"code","bdb4113a":"code","607aa25d":"code","1bf09f7a":"code","b5374615":"code","d343e4e0":"code","91550be9":"code","c0ade649":"code","805fcd45":"code","4e16c403":"code","88fd2c26":"code","c010c810":"code","d15db0df":"code","bec644d9":"code","a633fa99":"code","c97dc1d2":"code","9e3aa18b":"markdown","4632c5b4":"markdown","331f8f7c":"markdown","acaa381d":"markdown","7380f9de":"markdown","93b130b9":"markdown","6aa3dc56":"markdown","c8762e80":"markdown","be5d5249":"markdown","9223f049":"markdown","6f9c4870":"markdown","1bafa0f6":"markdown"},"source":{"d6561562":"import pandas as pd\ndata = pd.read_csv(\"..\/input\/3dprinter\/data.csv\", sep = \",\")","bdb4113a":"data.head()","607aa25d":"data.isnull().sum()","1bf09f7a":"for column in data.columns:\n    print(\"{} : {}\".format(column,data[column].unique()))","b5374615":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf = data.copy()\ndf[\"infill_pattern\"] = le.fit_transform(data[\"infill_pattern\"])\ndf[\"material\"] = le.fit_transform(data[\"material\"])\n\n        ","d343e4e0":"df.head()","91550be9":"corr = df.corr()\ncorr.style.background_gradient(cmap='coolwarm').set_precision(3)\n","c0ade649":"import matplotlib.pyplot as plt\nplt.rcParams.update({'font.size': 12})","805fcd45":"import seaborn as sns\n\nsns.pairplot(df)","4e16c403":" sns.pairplot(df,vars=[\"material\", \"nozzle_temperature\"])","88fd2c26":" sns.pairplot(data,vars=[\"fan_speed\", \"nozzle_temperature\"],diag_kind=\"kde\",hue=\"material\")","c010c810":" sns.pairplot(df,vars=[\"material\", \"print_speed\"])","d15db0df":"y_data = df.material.values\nx_data = df.drop([\"material\",\"print_speed\",\"infill_pattern\",\"bed_temperature\",\"layer_height\"],axis=1)","bec644d9":"# normalization \nfrom sklearn.preprocessing import MinMaxScaler\n\nmm = MinMaxScaler()\n\nx_norm = mm.fit_transform(x_data)\n\n# train test split\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x_norm,y_data,test_size = 0.3,random_state=1)\n\n\n\n\n\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 3) # n_neighbors = k\nknn.fit(x_train,y_train)\nprediction = knn.predict(x_test)\nprint(\" {} nn score: {} \".format(3,knn.score(x_test,y_test)))\n\nscore_list = []\nfor each in range(1,8):\n    knn2 = KNeighborsClassifier(n_neighbors = each)\n    knn2.fit(x_train,y_train)\n    score_list.append(knn2.score(x_test,y_test))\n    print(\" {} nn score: {} \".format(each,knn2.score(x_test,y_test)))\n    \nplt.plot(range(1,8),score_list)\nplt.xlabel(\"k values\")\nplt.ylabel(\"accuracy\")\nplt.show()","a633fa99":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.layers import Input, Dense, Flatten\nfrom keras.optimizers import SGD\nfrom keras.layers.normalization import BatchNormalization\n\ny = df.material.values\nx = df.drop([\"material\"],axis=1)\nx_norm = mm.fit_transform(x)\n\nmodel = Sequential()\nmodel.add(Dense(32,input_dim=11))\nmodel.add(BatchNormalization(axis = -1))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(16))\nmodel.add(Activation('softmax'))\n\nmodel.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(x_norm,y, epochs=500, batch_size =32, validation_split= 0.20)","c97dc1d2":"import numpy as np\n\na1 = 4 #layer_height*100\na2 = 5 #wall_thickness\na3 = 60 #infill_density\na4 = 0 #infilkk_pattern\na5 = 232 #nozzle_temperature \na6 = 74 #bed_temperature\na7 = 90 #print_speed\na8 = 100 #fan_speed\na9 = 150 #roughness\na10 = 30 #tension_strenght\na11 = 200 #elangation*100\n\ntahmin = np.array([a1,a2,a3,a4,a5,a6,a7,a8,a9,a10,a11]).reshape(1,11)\nprint(model.predict_classes(tahmin))\n\nif model.predict_classes(tahmin) == 0: \n    print(\"Material is ABS\")\nelse:   \n    print(\"Material is PLA.\")","9e3aa18b":"# 3D Printer DataSet for Mechanical Engineers","4632c5b4":"Converting categorical variable to Numerical","331f8f7c":"In ANN all the input variables as well as output variables can be included (though it's not necessary and should be avoided if data is too big), but it can find out important features by itself so it won't make much difference ","acaa381d":"Good for us that there are no \"nan\" or \"null\" values","7380f9de":"Import Data","93b130b9":"**Dropping all the variables which have 0 correlation with material , it would also reduce the computation time**","6aa3dc56":"Above matrix and graph shows that **layer height** ,*nozzle temperature*, *bed temperature*, *print speed*, *fan speed* affect the **output variables**, here output variables are* not material type*s.\n\nSome variables for ex **bed temperature**,**nozzle temperature** and **fan speed** are **linearly dependent** and can be combined but, for using FFN we can allow all variables , later we can try dropping some linearly dependent variables","c8762e80":"- Above plot shows that , **nozzle temperature** would be a deciding factor in predicting material type\n- It means that if material is **abs** then nozzle temperature reaches to higher level in comparision to when material is **pla** ","be5d5249":"Now we can see how features affect eachother through correlation matrix","9223f049":"This prediction could have also been easily made looking at the Nozzle temperature only, I don't understand why this problem is being solved with ANN when actually a Decision Tree classifier could have been used easily to predict the material used as input\n","6f9c4870":"-Above plot clearly shows that cooling is not very effective in **abs** because the nozzle_temperature is increasing at a higher rate","1bafa0f6":"Pairplot takes some time, be patient"}}