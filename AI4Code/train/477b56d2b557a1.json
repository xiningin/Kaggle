{"cell_type":{"0ee897c4":"code","525c4080":"code","41cb984d":"code","dddec29b":"code","09d08068":"code","29c2852b":"code","2515c5b7":"code","d554b151":"markdown","f76b6ab7":"markdown","e9f6bc6d":"markdown","5ae675f8":"markdown","310d83b8":"markdown","0665d665":"markdown"},"source":{"0ee897c4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","525c4080":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans","41cb984d":"dataset = pd.read_csv('..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv')\nprint(dataset)\nprint(\"##############\")\nprint(dataset.head())\nx = dataset.iloc[:,[3,4]].values","dddec29b":"wcss = []\n\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n    kmeans.fit(x)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1,11),wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","09d08068":"\nkmeans = KMeans(n_clusters = 5, init='k-means++', random_state=42 )\ny_kmeans = kmeans.fit_predict(x)","29c2852b":"plt.scatter(x[y_kmeans == 0, 0], x[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(x[y_kmeans == 1, 0], x[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(x[y_kmeans == 2, 0], x[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(x[y_kmeans == 3, 0], x[y_kmeans == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\nplt.scatter(x[y_kmeans == 4, 0], x[y_kmeans == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroids')\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()","2515c5b7":"import plotly.express as px\nfig = px.scatter_3d(dataset,x=\"Gender\",y=\"Age\",z=\"Spending Score (1-100)\",color=\"Age\")\nfig.show()","d554b151":"Many algorithm used for Clustering, but we use k-mean algorithm.\n\n**K-Mean**  K-means clustering is one of the simplest and popular unsupervised machine learning algorithm.\nThe mean in the K-means refers to averaging of the data.","f76b6ab7":"Using the elbow method to find the optimal number of clusters : ","e9f6bc6d":"Read csv file : ","5ae675f8":"Training the K-Means model on the dataset : ","310d83b8":"Import libraries :\n","0665d665":"Visualising the clusters"}}