{"cell_type":{"3f93213e":"code","e75ff6eb":"code","514a648b":"code","58ba06e3":"code","cc900beb":"code","b6a2e977":"code","5c2cbc29":"code","7e37dc7e":"code","07fc9a2e":"code","03d53054":"code","f0932376":"code","9530e67e":"code","af02c2d3":"code","09ed2950":"code","2fcd3615":"code","3b2fcdfc":"code","5fa71722":"code","9834758e":"code","b3beccd3":"code","91d0e6bd":"code","07e30b0d":"code","fb4c5445":"code","7833f567":"code","7912ce4a":"code","3e1c5403":"code","78052dac":"code","6ab0fa94":"code","788345c2":"code","800f45f8":"code","0474c424":"code","40bc87b5":"code","97a63911":"code","1e841373":"code","fbc233bb":"code","b59b1082":"code","cf29985a":"code","0bd19739":"code","2b61bc10":"code","f6d0113b":"code","30139676":"code","41eebd6a":"code","1f60dd4e":"code","a5ec30c9":"code","475e66c9":"code","03ecc3a7":"code","5dbbdcfb":"code","679d08ab":"code","0903444b":"code","305c2573":"code","28fcd777":"code","d611e3a7":"code","d9b5e45f":"code","62fc5c23":"code","3db5d330":"code","f013de4d":"code","95378ce4":"code","65f8ddb5":"code","adbb290a":"code","166a4e2b":"code","8405baec":"code","ad2ffc9d":"code","9f90a005":"code","a8882b7c":"code","dd43d585":"code","8568899f":"code","73408211":"code","8e8cf995":"code","38755a2f":"markdown","b58975d2":"markdown","4789eb26":"markdown","9176313a":"markdown","f7cfaa21":"markdown","aea4d2a6":"markdown","44450ff0":"markdown","5e7e034f":"markdown","f57ddf8e":"markdown","ed5b5489":"markdown","39d5e725":"markdown","a0b71913":"markdown","8165f958":"markdown","ac8d13b0":"markdown","5137a25d":"markdown","a29ea3b5":"markdown","4192d2a6":"markdown","2b11a947":"markdown","12c302d3":"markdown","996aa513":"markdown","5ef59497":"markdown","f1432f18":"markdown","d262c5a6":"markdown","e57d42c8":"markdown","fe748668":"markdown","213889bd":"markdown","008bf466":"markdown","35e3e0d1":"markdown","5d3cb3cd":"markdown","91f7a204":"markdown","52b09f8e":"markdown","22cedc30":"markdown","6a768094":"markdown","8bf92804":"markdown","5c1c3e6f":"markdown","e3816268":"markdown","e5a33b00":"markdown","6bbd4fec":"markdown","b4cae006":"markdown","18c943ee":"markdown","21cac326":"markdown","51d4918b":"markdown","54a77ae1":"markdown","b81da553":"markdown","31356432":"markdown","1766053e":"markdown","4413e1bf":"markdown","3965b176":"markdown"},"source":{"3f93213e":"import os\nimport numpy as np\nimport shutil\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport itertools\n\n\nfrom skimage.filters import gaussian\nfrom skimage.util import random_noise\nimport matplotlib.image as mpimg\n\nfrom sklearn.model_selection import train_test_split\n\n\n\nimport tensorflow\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.models import model_from_json\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPool2D,Dropout,MaxPooling2D\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n","e75ff6eb":"# accsess the data files and dir\ncancer_rays_dir     = os.listdir(\"..\/input\/breast-histopathology-images\/IDC_regular_ps50_idx5\") \nall_rays_dir        = \"all_rays_dir\"  # is this path we will put all the images\ncancer_rays_dir_str =\"..\/input\/breast-histopathology-images\/IDC_regular_ps50_idx5\/\"","514a648b":"print(cancer_rays_dir)\nprint(len(cancer_rays_dir)) ","58ba06e3":"os.mkdir(all_rays_dir)\n","cc900beb":"all_rays_dir_lst = os.listdir('.\/all_rays_dir') ","b6a2e977":"#Here we will move the images, but by adding a small part in their path, which indicates that they are negative or positive\nfor patient in cancer_rays_dir:   \n    path_0 = cancer_rays_dir_str + str(patient) + '\/0'\n    path_1 = cancer_rays_dir_str + str(patient) + '\/1'\n    file_list_0 = os.listdir(path_0)   \n    file_list_1 = os.listdir(path_1)\n    for fname in file_list_0:\n            src = os.path.join(path_0, fname)\n            dst = os.path.join(all_rays_dir, fname)\n            shutil.copyfile(src, dst)\n    for fname in file_list_1:\n        src = os.path.join(path_1, fname)\n        dst = os.path.join(all_rays_dir, fname)\n        shutil.copyfile(src, dst)","5c2cbc29":"all_rays_dir_lst = os.listdir('.\/all_rays_dir') \nlen(all_rays_dir_lst)","7e37dc7e":"data = pd.DataFrame(all_rays_dir_lst, columns=['image_id'])\ndata.head()\n","07fc9a2e":"#Based on the addition that we added earlier in the path, we divide the data\ndef extract_target(x):\n    a = x.split('_')\n    b = a[4]\n    target = b[5] \n    return target\n\ndata['target'] = data['image_id'].apply(extract_target)\n\ndata.head(10)","03d53054":"def extract_patient_id(x):\n    # split into a list\n    a = x.split('_')\n    patient_id = a[0]\n    \n    return patient_id\ndata['patient_id'] = data['image_id'].apply(extract_patient_id)\ndata.head()","f0932376":"data['target'].value_counts()","9530e67e":"data.target = data.target.astype(np.int)\nfig, ax = plt.subplots(5,10,figsize=(20,10))\npos_selection = np.random.choice(data[data.target ==1].index, size=50, replace=False,)\nneg_selection = np.random.choice(data[data.target ==0].index, size=50, replace=False,)\nfor n in range(5):\n    for m in range(10):\n        idx = neg_selection[m + 10*n]\n        path =os.path.join(all_rays_dir,data.loc[idx, 'image_id'])\n        image = mpimg.imread(path)\n        ax[n,m].imshow(image)\n        ax[n,m].grid(False)\n\n\n","af02c2d3":"fig, ax = plt.subplots(5,10,figsize=(20,10))\nfor n in range(5):\n    for m in range(10):\n        idx = pos_selection[m + 10*n]\n        path =os.path.join(all_rays_dir,data.loc[idx, 'image_id'])\n        image = mpimg.imread(path)\n        ax[n,m].imshow(image)\n        ax[n,m].grid(False)\n","09ed2950":"cancer_perc = data.groupby(\"patient_id\").target.value_counts()\/ data.groupby(\"patient_id\").target.size()\ncancer_perc = cancer_perc.unstack()\n\nfig, ax = plt.subplots(1,3,figsize=(20,5))\nsns.distplot(data.groupby(\"patient_id\").size(), ax=ax[0], color=\"Orange\", kde=False, bins=30)\nax[0].set_xlabel(\"Number of patches\")\nax[0].set_ylabel(\"Frequency\");\nax[0].set_title(\"How many patches do we have per patient?\");\nsns.distplot(cancer_perc.loc[:, 1]*100, ax=ax[1], color=\"Tomato\", kde=False, bins=30)\nax[1].set_title(\"How much percentage of an image is covered by IDC?\")\nax[1].set_ylabel(\"Frequency\")\nax[1].set_xlabel(\"% of patches with IDC\");\nsns.countplot(data.target, palette=\"Set2\", ax=ax[2]);\nax[2].set_xlabel(\"no(0) versus yes(1)\")\nax[2].set_title(\"How many patches show IDC?\");","2fcd3615":"def extract_coords(df):\n    coord = df.path.str.rsplit(\"_\", n=4, expand=True)\n    coord = coord.drop([0, 1, 4], axis=1)\n    coord = coord.rename({2: \"x\", 3: \"y\"}, axis=1)\n    coord.loc[:, \"x\"] = coord.loc[:,\"x\"].str.replace(\"x\", \"\", case=False).astype(np.int)\n    coord.loc[:, \"y\"] = coord.loc[:,\"y\"].str.replace(\"y\", \"\", case=False).astype(np.int)\n    df.loc[:, \"x\"] = coord.x.values\n    df.loc[:, \"y\"] = coord.y.values\n    return df\n\ndef get_cancer_dataframe(patient_id, cancer_id):\n    path = cancer_rays_dir_str + patient_id + \"\/\" + cancer_id\n    files = os.listdir(path)\n    dataframe = pd.DataFrame(files, columns=[\"filename\"])\n    path_names = path + \"\/\" + dataframe.filename.values\n    dataframe = dataframe.filename.str.rsplit(\"_\", n=4, expand=True)\n    dataframe.loc[:, \"target\"] = np.int(cancer_id)\n    dataframe.loc[:, \"path\"] = path_names\n    dataframe = dataframe.drop([0, 1, 4], axis=1)\n    dataframe = dataframe.rename({2: \"x\", 3: \"y\"}, axis=1)\n    dataframe.loc[:, \"x\"] = dataframe.loc[:,\"x\"].str.replace(\"x\", \"\", case=False).astype(np.int)\n    dataframe.loc[:, \"y\"] = dataframe.loc[:,\"y\"].str.replace(\"y\", \"\", case=False).astype(np.int)\n    return dataframe\ndef get_patient_dataframe(patient_id):\n    df_0 = get_cancer_dataframe(patient_id, \"0\")\n    df_1 = get_cancer_dataframe(patient_id, \"1\")\n    patient_df = df_0.append(df_1)\n    return patient_df","3b2fcdfc":"example = get_patient_dataframe(data.patient_id.values[0])\nexample.head()","5fa71722":"fig, ax = plt.subplots(5,3,figsize=(20, 27))\n\npatient_ids = data.patient_id.unique()\n\nfor n in range(5):\n    for m in range(3):\n        patient_id = patient_ids[m + 3*n]\n        example_df = get_patient_dataframe(patient_id)\n        \n        ax[n,m].scatter(example_df.x.values, example_df.y.values, c=example_df.target.values, cmap=\"coolwarm\", s=20);\n        ax[n,m].set_title(\"patient \" + patient_id)\n        ax[n,m].set_xlabel(\"y coord\")\n        ax[n,m].set_ylabel(\"x coord\")","9834758e":"data.target = data.target.astype(np.int)\nrandom_image_path = np.random.choice(data[data.target ==0].index, size=1, replace=False,)\npath =os.path.join(all_rays_dir,data.loc[random_image_path[0], 'image_id'])\nimage = mpimg.imread(path)\nplt.imshow(image)","b3beccd3":"gaussian_image = gaussian(image)\nplt.imshow(gaussian_image)","91d0e6bd":"noise_image = random_noise(image)\nplt.imshow(noise_image)","07e30b0d":"noise_gaussian_image = random_noise(gaussian_image)\nplt.imshow(noise_gaussian_image)","fb4c5445":"os.mkdir('image_processing') #We create a new file to process the data in\nos.mkdir('image_processing\/noise_images')","7833f567":"#Here we take the image from the normal images folder, process it, and then save it in the new file\nfor normal_image in all_rays_dir_lst :\n    path        = all_rays_dir+'\/'+ normal_image\n    img         = mpimg.imread( path ,0)\n    noise_image = random_noise(img)\n    fname       = normal_image\n    new_path    = os.path.join('image_processing\/noise_images',fname)\n    mpimg.imsave(new_path, noise_image)\n    ","7912ce4a":"os.mkdir( 'image_processing\/processd_data_train')\nos.mkdir( 'image_processing\/processd_data_test')\nos.mkdir( 'image_processing\/processd_data_train\/zeros')\nos.mkdir( 'image_processing\/processd_data_train\/ones')\nos.mkdir( 'image_processing\/processd_data_test\/zeros')\nos.mkdir( 'image_processing\/processd_data_test\/ones')\n","3e1c5403":"\nprocessd_lst = os.listdir('image_processing\/noise_images')\nprocessd_lst_str = 'image_processing\/noise_images'\nprocessd_data = pd.DataFrame(processd_lst, columns=['image_id'])\nprocessd_data.head()","78052dac":"def extract_target(x):\n    a = x.split('_')\n    b = a[4]\n    target = b[5] \n    return target\n\nprocessd_data['target'] = processd_data['image_id'].apply(extract_target)\n\nprocessd_data.head(10)","6ab0fa94":"processd_data['target'].value_counts()","788345c2":"y = processd_data['target']\nprocessd_train, processd_test = train_test_split(processd_data, test_size=0.10, random_state=101, stratify=y)\nprocessd_test_pls =processd_test.image_id\nprocessd_train_pls =processd_train.image_id","800f45f8":"processd_data.set_index('image_id', inplace=True)\nfor image in processd_test_pls:\n    fname = image\n    target = processd_data.loc[image,'target']\n    if target == '0':\n        label = 'zeros'\n    if target == '1':\n        label = 'ones'\n    src = os.path.join(processd_lst_str, fname)\n    dst = os.path.join(\"image_processing\/processd_data_test\", label, fname)\n    shutil.copyfile(src, dst)\n","0474c424":"for image in processd_train_pls:\n    fname  = image\n    target = processd_data.loc[image,'target']\n    \n    if target == '0':\n        label = 'zeros'\n    if target == '1':\n        label = 'ones'\n    src = os.path.join(processd_lst_str, fname)\n    dst = os.path.join('image_processing\/processd_data_train', label, fname)\n    shutil.copyfile(src, dst)","40bc87b5":"print(len(os.listdir('image_processing\/processd_data_train\/zeros')))\nprint(len(os.listdir('image_processing\/processd_data_train\/ones')))\nprint(len(os.listdir('image_processing\/processd_data_test\/zeros')))\nprint(len(os.listdir('image_processing\/processd_data_test\/ones')))","97a63911":"processd_lst = os.listdir('image_processing\/noise_images')\nprocessd_lst_str = 'image_processing\/noise_images'\nprocessd_data = pd.DataFrame(processd_lst, columns=['image_id'])\ndef extract_target(x):\n    a = x.split('_')\n    b = a[4]\n    target = b[5] \n    return target\n\nprocessd_data['target'] = processd_data['image_id'].apply(extract_target)\n\nprocessd_data.head(10)","1e841373":"os.mkdir( 'image_processing\/model_tst')\nos.mkdir( 'image_processing\/model_tst\/trainig')\nos.mkdir( 'image_processing\/model_tst\/testing')          \nos.mkdir( 'image_processing\/model_tst\/trainig\/zeros')\nos.mkdir( 'image_processing\/model_tst\/trainig\/ones')\nos.mkdir( 'image_processing\/model_tst\/testing\/zeros')\nos.mkdir( 'image_processing\/model_tst\/testing\/ones')","fbc233bb":"df_0 = processd_data[processd_data['target'] == '0'].sample(10000, random_state=101)\ndf_1 = processd_data[processd_data['target'] == '1'].sample(10000, random_state=101)\ntest_data =pd.DataFrame(data)\ntest_data = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\ntest_y = test_data['target']\ntest_data_train, test_data_test = train_test_split(test_data, test_size=0.10, random_state=101, stratify=test_y)\nsts_train = test_data_train.image_id\ntst_test  = test_data_test.image_id\ntest_data.set_index('image_id', inplace=True)\nfor image in sts_train:\n    fname  = image\n    target = test_data.loc[image,'target']\n    \n    if target == '0':\n        label = 'zeros'\n    if target == '1':\n        label = 'ones'\n    src = os.path.join(all_rays_dir, fname)\n    dst = os.path.join('image_processing\/model_tst\/trainig', label, fname)\n    shutil.copyfile(src, dst)\nfor image in tst_test:\n    fname  = image\n    target = test_data.loc[image,'target']\n    \n    if target == '0':\n        label = 'zeros'\n    if target == '1':\n        label = 'ones'\n    src = os.path.join(all_rays_dir, fname)\n    dst = os.path.join('image_processing\/model_tst\/testing', label, fname)\n    shutil.copyfile(src, dst)    \n","b59b1082":"processd_data.target = processd_data.target.astype(np.int)\nfig, ax = plt.subplots(5,4,figsize=(30,20))\npos_selection = np.random.choice(processd_data[processd_data.target==1].index.values, size=20, replace=False)\nneg_selection = np.random.choice(processd_data[processd_data.target==0].index.values, size=20, replace=False)\nfor n in range(5):\n    for m in range(4):\n        idx = pos_selection[m + 4*n]\n        path =os.path.join(processd_lst_str,processd_data.loc[idx, 'image_id'])\n        image = mpimg.imread(path)\n        ax[n,m].imshow(image)\n        ax[n,m].grid(False)","cf29985a":"fig, ax = plt.subplots(5,4,figsize=(30,20))\nfor n in range(5):\n    for m in range(4):\n        idx = neg_selection[m + 4*n]\n        path =os.path.join(processd_lst_str,processd_data.loc[idx, 'image_id'])\n        image = mpimg.imread(path)\n        ax[n,m].imshow(image)\n        ax[n,m].grid(False)","0bd19739":"data_processd_test_generation = ImageDataGenerator(rescale=1.0\/255)\ntrain_generation_processd = data_processd_test_generation.flow_from_directory(\"image_processing\/model_tst\/trainig\", target_size=(50,50), batch_size=10,class_mode='categorical')\ntest_generation_processd = data_processd_test_generation.flow_from_directory(\"image_processing\/model_tst\/testing\",target_size=(50,50),batch_size=10,class_mode='categorical')","2b61bc10":"my_model_im_processd =Sequential()\nmy_model_im_processd.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(50,50,3),activation='relu'))\nmy_model_im_processd.add(MaxPool2D(pool_size=(2,2)))\n\n\nmy_model_im_processd.add(Flatten())\n\nmy_model_im_processd.add(Dense(128,activation='relu'))\n\nmy_model_im_processd.add(Dense(2,activation='softmax'))\n\nmy_model_im_processd.compile(loss = 'categorical_crossentropy', optimizer ='adam', metrics= ['accuracy'])","f6d0113b":"early_stop = EarlyStopping(monitor='val_loss',patience=2)\nmy_model_im_processd.fit_generator(train_generation_processd,validation_data=test_generation_processd,epochs=60, verbose=1,callbacks=early_stop)","30139676":"os.mkdir( 'image_processing\/normal')\nos.mkdir( 'image_processing\/normal\/model_tst') \nos.mkdir( 'image_processing\/normal\/model_tst\/trainig')\nos.mkdir( 'image_processing\/normal\/model_tst\/testing')\nos.mkdir( 'image_processing\/normal\/model_tst\/trainig\/zeros')\nos.mkdir( 'image_processing\/normal\/model_tst\/trainig\/ones')\nos.mkdir( 'image_processing\/normal\/model_tst\/testing\/zeros')\nos.mkdir( 'image_processing\/normal\/model_tst\/testing\/ones')","41eebd6a":"data = pd.DataFrame(all_rays_dir_lst, columns=['image_id'])\ndata['target'] = data['image_id'].apply(extract_target)\ndf_0 = data[data['target'] == '0'].sample(10000, random_state=101)\ndf_1 = data[data['target'] == '1'].sample(10000, random_state=101)\ntest_data =pd.DataFrame(data)\ntest_data = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\ntest_y = test_data['target']\ntest_data_train, test_data_test = train_test_split(test_data, test_size=0.10, random_state=101, stratify=test_y)\nsts_train = test_data_train.image_id\ntst_test  = test_data_test.image_id\ntest_data.set_index('image_id', inplace=True)\nfor image in sts_train:\n    fname  = image\n    target = test_data.loc[image,'target']\n    \n    if target == '0':\n        label = 'zeros'\n    if target == '1':\n        label = 'ones'\n    src = os.path.join(all_rays_dir, fname)\n    dst = os.path.join('image_processing\/normal\/model_tst\/trainig', label, fname)\n    shutil.copyfile(src, dst)\nfor image in tst_test:\n    fname  = image\n    target = test_data.loc[image,'target']\n    \n    if target == '0':\n        label = 'zeros'\n    if target == '1':\n        label = 'ones'\n    src = os.path.join(all_rays_dir, fname)\n    dst = os.path.join('image_processing\/normal\/model_tst\/testing', label, fname)\n    shutil.copyfile(src, dst)    \n","1f60dd4e":"data_normal_test_generation = ImageDataGenerator(rescale=1.0\/255)\ntrain_generation_normal = data_normal_test_generation.flow_from_directory(\"image_processing\/normal\/model_tst\/trainig\", target_size=(50,50), batch_size=10,class_mode='categorical')\ntest_generation_normal = data_normal_test_generation.flow_from_directory(\"image_processing\/normal\/model_tst\/testing\",target_size=(50,50),batch_size=10,class_mode='categorical')","a5ec30c9":"my_model_im_norm =Sequential()\nmy_model_im_norm.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(50,50,3),activation='relu'))\nmy_model_im_norm.add(MaxPool2D(pool_size=(2,2)))\n\n\nmy_model_im_norm.add(Flatten())\n\nmy_model_im_norm.add(Dense(128,activation='relu'))\nmy_model_im_norm.add(Dense(2,activation='softmax'))\n\nmy_model_im_norm.compile(loss = 'categorical_crossentropy', optimizer ='adam', metrics= ['accuracy'])","475e66c9":"early_stop = EarlyStopping(monitor='val_loss',patience=2)\nmy_model_im_processd.fit_generator(train_generation_normal,validation_data=test_generation_normal,epochs=60, verbose=1,callbacks=early_stop)","03ecc3a7":"data = pd.DataFrame(all_rays_dir_lst, columns=['image_id'])\ndef extract_target(x):\n    a = x.split('_')\n    b = a[4]\n    target = b[5] \n    return target\n\ndata['target'] = data['image_id'].apply(extract_target)\n\ndata.head()","5dbbdcfb":"y = data['target']\ndata_train, data_test = train_test_split(data, test_size=0.10, random_state=101, stratify=y)","679d08ab":"print(data_train.shape)\nprint(data_test.shape)","0903444b":"os.mkdir( 'train_dir')\nos.mkdir('test_dir')","305c2573":"os.mkdir( 'train_dir\/zeros')\nos.mkdir( 'train_dir\/ones')\n\nos.mkdir( 'test_dir\/zeros')\nos.mkdir( 'test_dir\/ones')\n","28fcd777":"train = data_train.image_id\ntest  = data_test.image_id","d611e3a7":"data.set_index('image_id', inplace=True)\nfor image in train:\n    fname  = image\n    target = data.loc[image,'target']\n    \n    if target == '0':\n        label = 'zeros'\n    if target == '1':\n        label = 'ones'\n    src = os.path.join(all_rays_dir, fname)\n    dst = os.path.join('train_dir', label, fname)\n    shutil.copyfile(src, dst)","d9b5e45f":"for image in test:\n    fname = image\n    target = data.loc[image,'target']\n    if target == '0':\n        label = 'zeros'\n    if target == '1':\n        label = 'ones'\n    src = os.path.join(all_rays_dir, fname)\n    dst = os.path.join(\"test_dir\", label, fname)\n    shutil.copyfile(src, dst)\n","62fc5c23":"print('non-IDC train      =',len(os.listdir('train_dir\/zeros')))\nprint('IDC train          =',len(os.listdir('train_dir\/ones')))\nprint('non-IDC validation =',len(os.listdir('test_dir\/zeros')))\nprint('IDC validation     =',len(os.listdir('test_dir\/ones')))","3db5d330":"data_generation = ImageDataGenerator(rescale=1.0\/255)","f013de4d":"train_generation = data_generation.flow_from_directory(\n                                        \"train_dir\",\n                                        target_size=(25,25),\n                                        batch_size=10,\n                                        class_mode='categorical')\ntest_generation = data_generation.flow_from_directory(\n                                        \"test_dir\",\n                                        target_size=(25,25),\n                                        batch_size=10,\n                                        class_mode='categorical')\n\n","95378ce4":"my_model =Sequential()\nmy_model.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(25,25,3),activation='relu'))\nmy_model.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(25,25,3),activation='relu'))\nmy_model.add(MaxPool2D(pool_size=(2,2)))\nmy_model.add(Dropout(.3))\n\nmy_model.add(Flatten())\n\nmy_model.add(Dense(256,activation='relu'))\n\nmy_model.add(Dense(2,activation='softmax'))\n\nmy_model.compile(loss = 'categorical_crossentropy', optimizer ='adam', metrics= ['accuracy'])","65f8ddb5":"my_model.summary()","adbb290a":"my_model.fit_generator(train_generation,validation_data=test_generation,epochs=60, verbose=1,callbacks=early_stop)","166a4e2b":"losse = pd.DataFrame(my_model.history.history)\nlosse.head()","8405baec":"losse[['accuracy','val_accuracy']].plot()","ad2ffc9d":"losse[['loss','val_loss']].plot()\n","9f90a005":"val_loss, val_acc = \\\nmy_model.evaluate_generator(test_generation)\n\nprint('val_loss:', val_loss)\nprint('val_acc:', val_acc)","a8882b7c":"model_json = my_model.to_json()","dd43d585":"with open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\nmy_model.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")","8568899f":"json_file = open('model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\nloaded_model.load_weights(\"model.h5\")\nprint(\"Loaded model from disk\")\n \nloaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n","73408211":"class Api_service :\n    def __init__(self,img_file_path):\n        self.img_file_path = img_file_path\n    def prediction_function(self) :\n        predict_generation = data_generation.flow_from_directory(\n                                            self.img_file_path,\n                                            target_size=(25,25),\n                                            batch_size=10,\n                                            class_mode='categorical')\n\n        prediction = loaded_model.predict_generator(predict_generation)\n        has_cancer = 'The percentage of cancer : '+ str(round(prediction[0][0]*100,2)) + \"%\"\n        has_no_cancer='Percentage of no cancer : ' + str(round(prediction[0][1]*100,2)) + '%'\n        return has_cancer,has_no_cancer \n","8e8cf995":"prediction = Api_service(\"image_processing\/normal\/model_tst\/trainig\")\nx,y        = prediction.prediction_function()\nprint(x)\nprint(y)","38755a2f":"># Outputs and Outcomes","b58975d2":"> # Exploratory Data Analysis","4789eb26":"> #  Get & Adjust Data","9176313a":"### First: the processed images","f7cfaa21":"### Insights:\n\n- We see a large variation in the concentration of cells\n- Sometimes we don't have the full tissue information. It seems that tissue patches have been discarded or lost during preparation.","aea4d2a6":"-  the images we processed and the noraml are tested on the same model to see which the best in the accuracy","44450ff0":"# Processing  and Normal test","5e7e034f":"![17080.jpg](attachment:17080.jpg)","f57ddf8e":"> # Processing and selection\nit's time to work on our data..","ed5b5489":"-  A small sample is taken for testing (20,000) images","39d5e725":"##### We can see 279 files for each patient named with their id, and each file contains x-ray images of its owner","a0b71913":"- After several attempts, we made a good model design\n- Our model have a good acc = 85%\n- over fitting is so small \n- We're ready to create APIs","8165f958":"## Healthy patches:\n","ac8d13b0":"- Here we show pictures of some of the processed carcinogenic images","5137a25d":"### Insights\n\n- Patches with cancer look more violet and crowded than healthy ones. \n- In fact, we could not determine the actual difference between the two types with the naked eye, but I think that the model is able to detect hidden patterns in these images that enable us to determine the state of each image.","a29ea3b5":"### what is the structure of our data?","4192d2a6":"**Our goal:** Given a patient and a patch of a tissue slice predict wheather it contains IDC or not.","2b11a947":"#### First of all, let's take a look at the nature of the mammograms...","12c302d3":"> # Save &Loaded Model","996aa513":"# Cancer patches:","5ef59497":"# Data Spliting & Generation","f1432f18":"##### Now we have 277,524 images, what a number!","d262c5a6":"### Then, it's time to put images in a data_frame for easy access:","e57d42c8":"# Image Processing ","fe748668":"> # Import  Libraries ","213889bd":"## conclusion : Normal images are the best in modeling ","008bf466":"### Let's ask some questions that will help us get to know more our data:\n- do all patients have the same number of mammograms?\n- what is the percentage of cancer (IDC) that each mammogram shows? \n- how many healthy and cancered mammograms are in the data?","35e3e0d1":"## model results :","5d3cb3cd":"### Insights\n- Most of the mammograms are light pink, but there are some dark ones too","91f7a204":"-  Processing using (random_noise) function","52b09f8e":"### To facilitate the process of dealing with screening mammograms images, we will collect all the images in one place, while retaining ownership of each image and its class as well...","22cedc30":"### Insights:\n- The number of image patches per patient varies a lot\n- Most of the photos have a percentage that is not large, but there are other photos that have a percentage of up to 80%\n- the smaller number of mammograms had cancer","6a768094":" - Breast cancer is the second leading cause of cancer deaths among U.S. women, it is a type of cancer that starts when cells begin to grow out of control\n - Most breast cancers begin in the ducts that  carry milk to the nipple (ductal cancers), \n - Breast cancer can spread when the cancer cells get into the blood or lymph system and are carried to other parts of the body. \n - Cancerous breast tumors are detected by a special type of examination, which is screening mammogram","8bf92804":"### Second: the normal images","5c1c3e6f":"Detection of breast cancer on screening mammography is challenging as an image classification task because the tumors themselves occupy only a small portion of the image of the entire breast. For example, a full-field digital mammography (FFDM) image is typically 4000\u2009\u00d7\u20093000 pixels while a potentially cancerous region of interest (ROI) can be as small as 100\u2009\u00d7\u2009100 pixels.\n\n","e3816268":">> # CODE","e5a33b00":"- we will use this class to connect the web app to the model","6bbd4fec":" This explains the large number that we have in the data, which is more than **a quarter of a million** images!","b4cae006":">> # ENTRO","18c943ee":"#  *Finally we have finished*\n\n-from [https:\/\/github.com\/Ziad-o-Yusef\/breast-cancer-detection-using-cnn-DL-] You can view the project in GitHub as well as web application files \n","21cac326":"> # APIs &  Web Localization","51d4918b":"> # Modeling","54a77ae1":"- Here we show pictures of some of the normal images that have been processed","b81da553":"># Model design","31356432":" # Breast Cancer Detection using deep learning\n","1766053e":"-  Apply some processing properties","4413e1bf":"#### It also seems that the number of healthy rays is greater than the number of infected rays, good news!","3965b176":"### Well let's take a closer look at the shape of the patches and their distribution in each mammogram using Binary objective visualization for each tissue slice:"}}