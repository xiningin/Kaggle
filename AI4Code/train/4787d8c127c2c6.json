{"cell_type":{"90a05009":"code","c40fc6a3":"code","07460715":"code","94fd0bd5":"code","8192784d":"code","1afd6b8c":"code","5295be76":"code","73ec3c4a":"code","cfbeaa19":"code","852adc7b":"code","c793aee6":"code","b5cd19fc":"code","d04be7c7":"code","2ff4d4f3":"code","8f9e79f0":"code","66cd951d":"code","7bc1cb80":"code","5cc4cc7f":"code","e26ab0ca":"code","7ab782df":"code","71ae3184":"code","e8d174cd":"code","2709f987":"code","92ea741c":"code","9f594361":"code","540dcaff":"code","6f9c2750":"code","a592d781":"code","650f94ab":"code","758d7aa0":"code","c838b3ac":"code","b81e5b35":"code","bde20e39":"code","b6c8ebe6":"code","548ec850":"code","1d076ca7":"code","ed74fc4d":"code","bd5290e8":"code","65148a5d":"code","b93f5c03":"code","353fc550":"code","1ca3944a":"code","b5c926dc":"code","6f15c46d":"code","47e0d7d9":"code","2cd65b0b":"code","2a25320f":"code","068df48b":"code","32b0e85f":"code","5e4e66e3":"code","4ca9ce3a":"code","bf32ee92":"code","c02fa54c":"code","99fd5eb8":"code","441b76a8":"code","9ddb1acf":"markdown","25bcc3e2":"markdown","a1b524e9":"markdown","c00e31ae":"markdown","ab5e07df":"markdown","e4c3fa25":"markdown","fcf80529":"markdown","5663c521":"markdown","fc40a817":"markdown","0227b737":"markdown","c354dc58":"markdown","6d8eeabd":"markdown","548b3d96":"markdown","12b9c44b":"markdown","cfe67acd":"markdown","0507c2e1":"markdown","72ea1116":"markdown","8232b2d0":"markdown","94ea0f91":"markdown","76319c7a":"markdown","ea7ff554":"markdown","773fe98b":"markdown","6c991f46":"markdown","07603985":"markdown","19d41fcb":"markdown","67c082e3":"markdown","9aa4b1e6":"markdown","e3fd95dc":"markdown","56ede5e2":"markdown","64812e09":"markdown","3b297375":"markdown"},"source":{"90a05009":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c40fc6a3":"# Importing all the necessary libraries\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","07460715":"# Reading and making a copy of the dataset\n\nmain_df = pd.read_csv(\"\/kaggle\/input\/customer-personality-analysis\/marketing_campaign.csv\", sep=\"\\t\")\ndf = main_df.copy()\ndf.head()","94fd0bd5":"# Checking the shape of the dataset\n\ndf.shape","8192784d":"# Finding the basic information regarding dataset\n\ndf.info()","1afd6b8c":"# Finding the number of unique values present in each column\n\ndf.nunique()","5295be76":"# Checking if any NaN is present in column or not\n\ndf.isna().any()","73ec3c4a":"# Checking for null value using heatmap\n\nsns.heatmap(df.isnull())","cfbeaa19":"# Dropping columns because they will not contribute anything in model building\n\ndf=df.drop(columns=[\"Z_CostContact\", \"Z_Revenue\"],axis=1)\ndf.head()","852adc7b":"# Finding the correlation between the feature column\n\nplt.figure(figsize=(20,20))\nsns.heatmap(df.corr(), annot=True)\nplt.show()","c793aee6":"# Checking for correlation by unstacking data\n\ncorr = df.corr()\nc1 = corr.abs().unstack()\nc1.sort_values(ascending = False)[24:50:2]","b5cd19fc":"# Filling the missing value in the income my mean\n\ndf['Income'] = df['Income'].fillna(df['Income'].mean())\ndf.isna().any() ","d04be7c7":"df.head()","2ff4d4f3":"# Checking number of unique categories present in the \"Marital_Status\"\n\ndf['Marital_Status'].value_counts()  ","8f9e79f0":"df['Marital_Status'] = df['Marital_Status'].replace(['Married', 'Together'],'relationship')\ndf['Marital_Status'] = df['Marital_Status'].replace(['Divorced', 'Widow', 'Alone', 'YOLO', 'Absurd'],'Single')","66cd951d":"# Count of different values present in Marital_Status\n\ndf['Marital_Status'].value_counts()  ","7bc1cb80":"# Combining different dataframe into a single column to reduce the number of dimension\n\ndf['Kids'] = df['Kidhome'] + df['Teenhome']\ndf['Expenses'] = df['MntWines'] + df['MntFruits'] + df['MntMeatProducts'] + df['MntFishProducts'] + df['MntSweetProducts'] + df['MntGoldProds']\ndf['TotalAcceptedCmp'] = df['AcceptedCmp1'] + df['AcceptedCmp2'] + df['AcceptedCmp3'] + df['AcceptedCmp4'] + df['AcceptedCmp5'] + df['Response']\ndf['NumTotalPurchases'] = df['NumWebPurchases'] + df['NumCatalogPurchases'] + df['NumStorePurchases'] + df['NumDealsPurchases']","5cc4cc7f":"# Deleting some column to reduce dimension and complexity of model\n\ncol_del = [\"AcceptedCmp1\" , \"AcceptedCmp2\", \"AcceptedCmp3\" , \"AcceptedCmp4\",\"AcceptedCmp5\", \"Response\",\"NumWebVisitsMonth\", \"NumWebPurchases\",\"NumCatalogPurchases\",\"NumStorePurchases\",\"NumDealsPurchases\" , \"Kidhome\", \"Teenhome\",\"MntWines\", \"MntFruits\", \"MntMeatProducts\", \"MntFishProducts\", \"MntSweetProducts\", \"MntGoldProds\"]\ndf=df.drop(columns=col_del,axis=1)\ndf.head()","e26ab0ca":"# Adding a column \"Age\" in the dataframe\n\ndf['Age'] = 2015 - df[\"Year_Birth\"]","7ab782df":"df['Education'].value_counts()","71ae3184":"# Changing category into UG and PG only\n\ndf['Education'] = df['Education'].replace(['PhD','2n Cycle','Graduation', 'Master'],'PG')  \ndf['Education'] = df['Education'].replace(['Basic'], 'UG')","e8d174cd":"# Number of days a customer was engaged with company\n\n# Changing Dt_customer into timestamp format\ndf['Dt_Customer'] = pd.to_datetime(df.Dt_Customer)\ndf['first_day'] = '01-01-2015'\ndf['first_day'] = pd.to_datetime(df.first_day)\ndf['day_engaged'] = (df['first_day'] - df['Dt_Customer']).dt.days","2709f987":"df=df.drop(columns=[\"ID\", \"Dt_Customer\", \"first_day\", \"Year_Birth\", \"Dt_Customer\", \"Recency\", \"Complain\"],axis=1)\ndf.shape","92ea741c":"fig = px.bar(df, x='Marital_Status', y='Expenses', color=\"Education\")\nfig.show()","9f594361":"fig = px.bar(df, x='Marital_Status', y='Expenses', color=\"Marital_Status\")\nfig.show()","540dcaff":"fig = px.histogram (df, x = \"Expenses\",  facet_row = \"Marital_Status\",  template = 'plotly_dark')\nfig.show ()","6f9c2750":"fig = px.histogram (df, x = \"Expenses\",  facet_row = \"Education\",  template = 'plotly_dark')\nfig.show ()","a592d781":"fig = px.histogram (df, x = \"NumTotalPurchases\",  facet_row = \"Education\",  template = 'plotly_dark')\nfig.show ()","650f94ab":"fig = px.histogram (df, x = \"Age\",  facet_row = \"Marital_Status\",  template = 'plotly_dark')\nfig.show ()","758d7aa0":"fig = px.histogram (df, x = \"Income\",  facet_row = \"Marital_Status\",  template = 'plotly_dark')\nfig.show ()","c838b3ac":"fig =  px.pie (df, names = \"Marital_Status\", hole = 0.4, template = \"gridon\")\nfig.show ()","b81e5b35":"fig =  px.pie (df, names = \"Education\", hole = 0.4, template = \"plotly_dark\")\nfig.show ()","bde20e39":"sns.barplot(x = df['Expenses'],y = df['Education']);\nplt.title('Total Expense based on the Education Level');","b6c8ebe6":"sns.barplot(x = df['Income'],y = df['Education']);\nplt.title('Total Income based on the Education Level');","548ec850":"df.describe()","1d076ca7":"sns.heatmap(df.corr(), annot=True)","ed74fc4d":"cate = []\nfor i in df.columns:\n    if (df[i].dtypes == \"object\"):\n        cate.append(i)\n\nprint(cate)","bd5290e8":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler","65148a5d":"df['Marital_Status'].value_counts()","b93f5c03":"lbl_encode = LabelEncoder()\nfor i in cate:\n    df[i]=df[[i]].apply(lbl_encode.fit_transform)","353fc550":"df1 = df.copy()","1ca3944a":"scaled_features = StandardScaler().fit_transform(df1.values)\nscaled_features_df = pd.DataFrame(scaled_features, index=df1.index, columns=df1.columns)","b5c926dc":"scaled_features_df.head()","6f15c46d":"from sklearn.cluster import KMeans","47e0d7d9":"wcss=[]\nfor i in range (1,11):\n kmeans=KMeans(n_clusters=i,init='k-means++',random_state=42)\n kmeans.fit(scaled_features_df)\n wcss.append(kmeans.inertia_)\nplt.figure(figsize=(16,8))\nplt.plot(range(1,11),wcss, 'bx-')\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","2cd65b0b":"from sklearn.metrics import silhouette_score ","2a25320f":"\nsilhouette_scores = []\nfor i in range(2,10):\n    m1=KMeans(n_clusters=i, random_state=42)\n    c = m1.fit_predict(scaled_features_df)\n    silhouette_scores.append(silhouette_score(scaled_features_df, m1.fit_predict(scaled_features_df))) \nplt.bar(range(2,10), silhouette_scores) \nplt.xlabel('Number of clusters', fontsize = 20) \nplt.ylabel('S(i)', fontsize = 20) \nplt.show()","068df48b":"silhouette_scores","32b0e85f":"# Getting the maximum value of silhouette score and adding 2 in index because index starts from 2.\n\nsc=max(silhouette_scores)\nnumber_of_clusters=silhouette_scores.index(sc)+2\nprint(\"Number of Cluster Required is : \", number_of_clusters)","5e4e66e3":"# Training a predicting using K-Means Algorithm.\n\nkmeans=KMeans(n_clusters=number_of_clusters, random_state=42).fit(scaled_features_df)\npred=kmeans.predict(scaled_features_df)\n\n\n# Appending those cluster value into main dataframe (without standard-scalar)\n\ndf['cluster'] = pred + 1","4ca9ce3a":"df.head()","bf32ee92":"scaled_features_df.head()","c02fa54c":"df['Education'].value_counts()","99fd5eb8":"pl = sns.countplot(x=df[\"cluster\"])\npl.set_title(\"Distribution Of The Clusters\")\nplt.show()","441b76a8":"# Clusters interpretation \nsns.set(rc={'axes.facecolor':'black', 'figure.facecolor':'black', 'axes.grid' : False, 'font.family': 'Ubuntu'})\n\nfor i in df:\n    diag = sns.FacetGrid(df, col = \"cluster\", hue = \"cluster\", palette = \"Set1\")\n    diag.map(plt.hist, i, bins=6, ec=\"k\") \n    diag.set_xticklabels(rotation=25, color = 'white')\n    diag.set_yticklabels(color = 'white')\n    diag.set_xlabels(size=16, color = 'white')\n    diag.set_titles(size=16, color = '#f01132', fontweight=\"bold\")\n    diag.fig.set_figheight(6)","9ddb1acf":"**Here we are using Silhouette score to measure the value of K**","25bcc3e2":"### Clustering ","a1b524e9":"#### Based on above information we can divide customer into 3 parts:- \n\n1. **Highly Active Customer** :- These customers belong to cluster one.\n2. **Moderately Active Customer** :- These customers belong to cluster two.\n3. **Least Active Customer** :-  These customers belong to cluster third.","c00e31ae":"<center> <img src=\"https:\/\/blog-assets.freshworks.com\/freshdesk\/wp-content\/uploads\/2020\/06\/18152022\/Blog_Banner_v1-01-1024x410.jpg\"> <\/center>","ab5e07df":"**35% of the customer are single whereas more 64% are in relationship.**","e4c3fa25":"**Less number of single customer**","fcf80529":"### Silhouette Score","5663c521":"* Here we have only 3 object type datatype and rest are numerical.","fc40a817":"**As it is not very clear from the elbow method that which value of K to choose.**","0227b737":"**Note :-**\n\n**As we can see here that weightage of customer are more in cluster 1 as compare to other.**","c354dc58":"* Income column have some missing value in it so we will need to fill it by by either mean or median.","6d8eeabd":"#### Context\n\n**Problem Statement**\n\nCustomer Personality Analysis is a detailed analysis of a company\u2019s ideal customers. It helps a business to better understand its customers and makes it easier for them to modify products according to the specific needs, behaviors and concerns of different types of customers. \n\nCustomer personality analysis helps a business to modify its product based on its target customers from different types of customer segments. For example, instead of spending money to market a new product to every customer in the company\u2019s database, a company can analyze which customer segment is most likely to buy the product and then market the product only on that particular segment.\n\n\n#### Content\n\n**Attributes**\n\n**People**\n\n* ID: Customer's unique identifier\n* Year_Birth: Customer's birth year\n* Education: Customer's education level\n* Marital_Status: Customer's marital status\n* Income: Customer's yearly household income\n* Kidhome: Number of children in customer's household\n* Teenhome: Number of teenagers in customer's household\n* Dt_Customer: Date of customer's enrollment with the company\n* Recency: Number of days since customer's last purchase\n* Complain: 1 if customer complained in the last 2 years, 0 otherwise\n\n**Products**\n\n* MntWines: Amount spent on wine in last 2 years\n* MntFruits: Amount spent on fruits in last 2 years\n* MntMeatProducts: Amount spent on meat in last 2 years\n* MntFishProducts: Amount spent on fish in last 2 years\n* MntSweetProducts: Amount spent on sweets in last 2 years\n* MntGoldProds: Amount spent on gold in last 2 years\n\n**Promotion**\n\n* NumDealsPurchases: Number of purchases made with a discount\n* AcceptedCmp1: 1 if customer accepted the offer in the 1st campaign, 0 otherwise\n* AcceptedCmp2: 1 if customer accepted the offer in the 2nd campaign, 0 otherwise\n* AcceptedCmp3: 1 if customer accepted the offer in the 3rd campaign, 0 otherwise\n* AcceptedCmp4: 1 if customer accepted the offer in the 4th campaign, 0 otherwise\n* AcceptedCmp5: 1 if customer accepted the offer in the 5th campaign, 0 otherwise\n* Response: 1 if customer accepted the offer in the last campaign, 0 otherwise\n\n**Place**\n\n* NumWebPurchases: Number of purchases made through the company\u2019s web site\n* NumCatalogPurchases: Number of purchases made using a catalogue\n* NumStorePurchases: Number of purchases made directly in stores\n* NumWebVisitsMonth: Number of visits to company\u2019s web site in the last month\n\n#### Target\n\nNeed to perform clustering to summarize customer segments.","548b3d96":"#### Characteristics of Least Active Customer\n\n- **In terms of Education**\n - Least Active Customer are from UG backgroud\n\n    \n- **In terms of Marital_status**\n - Number of people in relationship are approx. equal to single people\n\n- **In terms of Income**\n - Income of Least active customer are very less or say negligible.\n    \n- **In terms of Kids**\n - Only few of these customer have child.\n\n- **In terms of Expenses**\n - Expenses of Least Active customer are very less or say negligible.\n\n\n- **In terms of Age**\n - Age of these customer are between 15 to 30.\n\n\n- **In terms of day_engaged**\n - Least Active customer are not much enrolled with company for longer time.","12b9c44b":"* 0 means PG and 1 means UG\n* There are very less customer from UG background","cfe67acd":"* It is used to calculate how one variable is correlated\/ dependent on other variable.\n* Extreme values signify high correlation.\n* Multicollinear variables with correlation more than a threshold are usually dropped from the dataset.","0507c2e1":"#### Characteristics of Moderately Active Customer\n\n- **In terms of Education**\n - Moderately Active Customer are also from PG backgroud\n\n\n- **In terms of Marital_status**\n - Number of people in relationship are slightly more as compare to single people\n\n\n- **In terms of Income**\n - Income of Moderately active customer are higher as compare to other customer.\n\n\n- **In terms of Kids**\n - Moderately active customer have less number of childern as compare to highly active customer ( Max. customer has no child ).\n\n\n- **In terms of Expenses**\n - Expenses of Moderately Active customer are more as compare to Active.\n - These customer spent avg. of approx. 500-2000 unit money.\n\n\n- **In terms of Age**\n - Age of these customer are between 25 to 75.\n - Maximum customer age are between 35 to 60.\n\n\n- **In terms of day_engaged**\n - Moderately Active customer are slightly less engaged with company as compare to Highly Active Customer.\n ","72ea1116":"** More than 97% customer are from PG background. and Approx. 2% are from UG.","8232b2d0":"### Report ","94ea0f91":"### Preprocessing of the dataset","76319c7a":"**NOTE** \n* In above cell \"Z_CostContact\" and \"Z_Revenue\" have same value in all the rows that's why they are not going to contribute anything in the model building. So we can drop them.  ","ea7ff554":"### Standardization ","773fe98b":"### EDA","6c991f46":"### About Dataset","07603985":"* No two columns are too much correlated with each other so we can't drop any column on the basis of correlation.","19d41fcb":"#### Characteristics of Highly Active Customer\n\n- **In terms of Education**\n - Highly Active Customer are from PG background\n\n\n- **In terms of Marital_status**\n - Number of people in relationship are approx. two times of single people\n\n\n- **In terms of Income**\n - Income of Highly active customer are little less as compare to Moderately active customer.\n \n \n- **In terms of Kids**\n - Highly active customer have more number of children as compare to other customer ( avg. of 1 child ).\n \n \n- **In terms of Expenses**\n - Expenses of Highly Active customer are less as compare to moderate.\n - These customer spent avg. of approx. 100-200 unit money.\n\n\n- **In terms of Age**\n - Age of these customer are between 25 to 75.\n - Maximum customer age are between 40 to 50.\n\n\n- **In terms of day_engaged**\n - Highly Active customer are more loyal as they engaged with company for longer period of time.","67c082e3":"### Visualization","9aa4b1e6":"* In the above cell we are grouping 'Married', 'Together' as \"relationship\" \n* Whereas 'Divorced', 'Widow', 'Alone', 'YOLO', 'Absurd' as \"Single\"","e3fd95dc":"### Elbow Method ","56ede5e2":"### Model Building","64812e09":"### Label Encoding","3b297375":"**Please like this notebook\ud83d\udc4d, If it helped you in learning something new\ud83d\ude42 and do check my other notebook.**"}}