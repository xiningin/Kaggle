{"cell_type":{"d3b79fd9":"code","34ab908a":"code","bff585d2":"code","30ae41e6":"code","bbb5304d":"code","1e00e38f":"code","763db5a7":"code","a1df8dec":"code","3e6ddab0":"code","82744e8d":"code","f30724ff":"code","7410447c":"code","88944e79":"code","573980da":"code","28b5b59f":"code","bfaa7b7a":"code","a17e32ea":"code","6b3d077c":"code","44f8a271":"code","9e2631e3":"code","44cd775f":"code","4145fb1e":"code","1832c2d0":"markdown","ec250fdc":"markdown","3dde2eb6":"markdown","e974afc2":"markdown","cdfc466d":"markdown","80172147":"markdown","387c4cd7":"markdown","7aa13cf9":"markdown","ce3607e4":"markdown"},"source":{"d3b79fd9":"# Import libraries \nimport pandas as pd \nimport numpy as np \n\nimport matplotlib.pyplot as plt \nimport seaborn as sns","34ab908a":"# Load the data\nhfi_data = pd.read_csv('..\/input\/python\/edhec-hedgefundindices.csv',\n                           header=0, index_col=0, parse_dates=True)\nhfi_data.shape","bff585d2":"hfi_data.head()","30ae41e6":"# Convert to percentages \nhfi_data = hfi_data\/100\nhfi_data.index = hfi_data.index.to_period('M')\nhfi_data.head()","bbb5304d":"# Calculate the standard deviation \nstd = hfi_data.std(ddof=0)\nstd.sort_values(ascending=False)","1e00e38f":"# Calculate the standard deviation for returns which have negative values \nsemi_std = hfi_data[hfi_data<0].std(ddof=0)\nsemi_std.sort_values(ascending=False)","763db5a7":"comparison = pd.concat([std, semi_std], axis=1)\ncomparison.columns = [\"Standard Deviation\", \"Semi-Deviation\"]\ncomparison.plot.bar(title=\"Standard Deviation vs Semideviation\")","a1df8dec":"np.percentile(hfi_data, 5, axis=0)","3e6ddab0":"def var_historic(r, level=5):\n    '''\n    ARG\n        r: Dataframe with the returns\n        level: percentile level\n    Returns \n        percentile for each column\n    '''\n    # Check the type of data\n    if isinstance(r, pd.DataFrame):\n        return r.aggregate(var_historic, level=level)\n    \n    elif isinstance(r, pd.Series):\n        return -np.percentile(r, level)\n    else: \n        raise TypeError(\"Expected r to be a series or dataframe\")","82744e8d":"var_historic(hfi_data, level=5) ","f30724ff":"from scipy.stats import norm","7410447c":"# Compute the z score assuming the data is gaussian \n# Percent point function\nz = norm.ppf(0.05)\nz","88944e79":"# Compute the gaussian VaR\nvar_gauss = -(hfi_data.mean() + z*hfi_data.std(ddof=0))\nvar_gauss","573980da":"# Make a skewness function \ndef skewness(r):\n    '''\n        ARGS:\n            Series or Dataframe\n        \n        RETURNS: \n            Float or a series data with the calculated skewness\n    '''\n    \n    # Calculate the demeaned returns \n    demeaned_r = r - r.mean()\n    \n    # Use the population standard deviation, ddof=0\n    sigma_r = r.std(ddof=0)\n    \n    # Calculate the expectation of the demeaned returns raised to the third power\n    exp = (demeaned_r**3).mean()\n    \n    # Calcualte the skew\n    skew = exp\/sigma_r**3\n    return skew","28b5b59f":"# Make a kurtosis function \ndef kurtosis(r):\n    '''\n        ARGS:\n            Series or Dataframe\n        \n        RETURNS: \n            Float or a series data with the calculated kurtosis\n    '''\n    \n    # Calculate the demeaned returns \n    demeaned_r = r - r.mean()\n    \n    # Use the population standard deviation, ddof=0\n    sigma_r = r.std(ddof=0)\n    \n    # Calculate the expectation of the demeaned returns raised to the fourth power\n    exp = (demeaned_r**4).mean()\n    \n    # Calcualte the skew\n    kurt = exp\/sigma_r**4\n    return kurt","bfaa7b7a":"# Update z \nk = kurtosis(hfi_data)\ns = skewness(hfi_data)\nz = norm.ppf(0.05)\nz = (z + (z**2 - 1)*s\/6 + (z**3 - 3*z)*(k-3)\/24 - (2 * z**3 - 5*z)*(s**2)\/36)","a17e32ea":"mcf_var = -(hfi_data.mean() + z*hfi_data.std(ddof=0))\nmcf_var","6b3d077c":"# Calculate the skewness and kurtosis \nstats = pd.concat([s, k], axis=1)\nstats.columns = [\"Skewness\", \"Kurtosis\"]\nstats","44f8a271":"# Compare all three by plotting \nresults = [var_gauss, mcf_var, var_historic(hfi_data, level=5)]\ncomparison=pd.concat(results, axis=1)\ncomparison.columns = [\"Gaussian\", \"Cornish-Fisher\", \"Historic\"]\ncomparison","9e2631e3":"\n# Plot the comparison DataFrame\nax = comparison.plot.bar(title=\"Hedge Fund Indices: VaR\")\nax.set_xlabel(\"Indices\")\nax.set_ylabel(\"Value at Risk\")","44cd775f":"# Create a cvar function \ndef cvar_historic(r, level=5):\n    \"\"\"\n        Computes the conditional VaR of Series or DataFrame\n    \"\"\"\n    \n    if isinstance(r, pd.Series): \n        is_beyond = r <= -var_historic(r, level=5) \n        return -r[is_beyond].mean()\n    elif isinstance(r, pd.DataFrame):\n        return r.aggregate(cvar_historic, level=level)\n    else: \n        raise TypeError(\"Expected a dataframe or series\")","4145fb1e":"cvar_historic(hfi_data, level=5)","1832c2d0":"#### Parametric VaR - Gaussian \n\nz-score = $ \\frac{x - \\mu}{\\sigma} $","ec250fdc":"## Preprocessing","3dde2eb6":"#### Cornish Fisher VaR (Non Gaussian)\nAdjustments made for Skewness and Kurtosis","e974afc2":"### Conditional VaR or Beyond VaR\n\n$$ CVaR = -E(R| R \\leq VaR) $$","cdfc466d":"## Semideviation\n\nFormula \n\n$$\\sigma_{semi} = \\sqrt{\\frac{1}{N}\\sum_{x_{t} \\leq \\bar{x}} (x_{t} - \\bar{x})^{2}}$$ \n\n<p style=\"text-align:center;\"> N = number of entries which fall below the mean.<\/p> ","80172147":"# Calculating downside risk measures","387c4cd7":"#### Comparison","7aa13cf9":"## Value at Risk (VaR) and Conditional VaR \n\nWe will try three different methods to calculate the VaR\n\n* Historical VaR\n* Parametric VaR - Gaussian \n* Modified Cornish-Fisher VaR","ce3607e4":"### Historic VaR"}}