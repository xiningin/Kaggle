{"cell_type":{"cab04d9b":"code","33b58a9b":"code","778b732f":"code","b3214a90":"code","8082921c":"code","004fecd4":"code","9304c8b5":"code","f69ff127":"code","5d54cd5b":"code","3664470a":"code","6d85f298":"code","9f6c0753":"code","b3b989e9":"code","04e868c0":"code","4832308c":"code","c01d3f13":"code","432e91ee":"code","77049223":"code","9f6f14b4":"code","86405d4f":"code","408ec37f":"code","dd888006":"code","f10802cd":"code","fce6bc31":"code","14132053":"code","5b94f378":"code","92597988":"code","b6d4a17b":"code","bf0f4e5e":"code","9b03420f":"code","a809b477":"code","84c4f809":"code","7c9a9ff2":"code","9c06e86a":"code","9dff6679":"code","94106879":"code","8819f36c":"code","0a697f7c":"markdown","4154a23e":"markdown","02516245":"markdown","79aa0c90":"markdown","087457ab":"markdown","bd01eab5":"markdown","e7ab0be4":"markdown","ec20dc26":"markdown","f1dcba5b":"markdown"},"source":{"cab04d9b":"# init\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom wordcloud import WordCloud, STOPWORDS\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport time\nimport warnings \nwarnings.filterwarnings('ignore')","33b58a9b":"# define some functions\ndef count_ngrams(dataframe, column, begin_ngram, end_ngram):\n    # adapted from https:\/\/stackoverflow.com\/questions\/36572221\/how-to-find-ngram-frequency-of-a-column-in-a-pandas-dataframe\n    word_vectorizer = CountVectorizer(ngram_range=(begin_ngram,end_ngram), analyzer='word')\n    sparse_matrix = word_vectorizer.fit_transform(df[column].dropna())\n    frequencies = sum(sparse_matrix).toarray()[0]\n    most_common = pd.DataFrame(frequencies, \n                               index=word_vectorizer.get_feature_names(), \n                               columns=['frequency']).sort_values('frequency',ascending=False)\n    most_common['ngram'] = most_common.index\n    most_common.reset_index()\n    return most_common\n\ndef word_cloud_function(df, column, number_of_words):\n    # adapted from https:\/\/www.kaggle.com\/benhamner\/most-common-forum-topic-words\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    word_string=str(popular_words_nonstop)\n    wordcloud = WordCloud(stopwords=STOPWORDS,\n                          background_color='white',\n                          max_words=number_of_words,\n                          width=1000,height=1000,\n                         ).generate(word_string)\n    plt.clf()\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()\n\ndef word_bar_graph_function(df, column, title, nvals=50):\n    # adapted from https:\/\/www.kaggle.com\/benhamner\/most-common-forum-topic-words\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    plt.barh(range(nvals), [word_count_dict[w] for w in reversed(popular_words_nonstop[0:nvals])])\n    plt.yticks([x + 0.5 for x in range(nvals)], reversed(popular_words_nonstop[0:nvals]))\n    plt.title(title)\n    plt.show()","778b732f":"# load metadata\nt1 = time.time()\n# df = pd.read_csv('\/kaggle\/input\/CORD-19-research-challenge\/2020-03-13\/all_sources_metadata_2020-03-13.csv')\ndf = pd.read_csv('..\/input\/CORD-19-research-challenge\/metadata.csv') # adjust to change in data\nt2 = time.time()\nprint('Elapsed time:', t2-t1)","b3214a90":"df.head()","8082921c":"df.describe(include='all')","004fecd4":"df.journal.value_counts()","9304c8b5":"# plot top 10 only\ndf.journal.value_counts()[0:10].plot(kind='bar')\nplt.grid()\nplt.show()","f69ff127":"df.source_x.value_counts().plot(kind='bar')\nplt.show()","5d54cd5b":"df.has_pdf_parse.value_counts().plot(kind='bar')\nplt.show()","3664470a":"df.publish_time.value_counts()","6d85f298":"df.license.value_counts()","9f6c0753":"# show example\ndf.title[0]","b3b989e9":"# show example\ndf.title[1]","04e868c0":"# show most frequent words in titles\nplt.figure(figsize=(10,10))\nword_bar_graph_function(df,column='title', \n                        title='Most common words in the TITLES of the papers in the CORD-19 dataset',\n                        nvals=20)","4832308c":"# evaluate 3-grams (takes some time)\nt1 = time.time()\nthree_gram = count_ngrams(df,'title',3,3)\nt2 = time.time()\nprint('Elapsed time:', t2-t1)","c01d3f13":"three_gram[0:20]","432e91ee":"# plot most frequent 3-grams\nfig = px.bar(three_gram.sort_values('frequency',ascending=False)[0:10], \n             x=\"frequency\", \n             y=\"ngram\",\n             title='Top Ten 3-Grams in TITLES of Papers in CORD-19 Dataset',\n             orientation='h')\nfig.show()","77049223":"# evaluate bigrams (takes some time)\nt1 = time.time()\nbi_gram = count_ngrams(df,'title',2,2)\nt2 = time.time()\nprint('Elapsed time:', t2-t1)","9f6f14b4":"bi_gram[0:20]","86405d4f":"# plot most frequent bigrams\nfig = px.bar(bi_gram.sort_values('frequency',ascending=False)[2:12], \n             x=\"frequency\", \n             y=\"ngram\",\n             title='Top Ten relevant bigrams in TITLES of Papers in CORD-19 Dataset',\n             orientation='h')\nfig.show()","408ec37f":"# word cloud\nplt.figure(figsize=(10,10))\nword_cloud_function(df,column='title',number_of_words=50000)","dd888006":"def word_finder(i_word, i_text):\n    found = str(i_text).find(i_word)\n    if found == -1:\n        result = 0\n    else:\n        result = 1\n    return result","f10802cd":"# define keyword\nmy_keyword = 'enzyme'","fce6bc31":"# partial function for mapping\nword_indicator_partial = lambda text: word_finder(my_keyword, text)\n# build indicator vector (0\/1) of hits\nkeyword_indicator = np.asarray(list(map(word_indicator_partial, df.title)))","14132053":"# number of hits\nprint('Number of hits for keyword <', my_keyword, '> : ', keyword_indicator.sum())","5b94f378":"# add index vector as additional column\ndf['selection'] = keyword_indicator","92597988":"# select only hits from data frame\ndf_hits = df[df['selection']==1]","b6d4a17b":"# show results\ndf_hits","bf0f4e5e":"# store result in CSV file\ndf_hits.to_csv('demo_keyword_search.csv')","9b03420f":"# show example\ndf.abstract[3]","a809b477":"# show most frequent words in abstracts\nplt.figure(figsize=(10,10))\nword_bar_graph_function(df,column='abstract',\n                        title='Most common words in the ABSTRACTS of the papers in the CORD-19 dataset',\n                        nvals=20)","84c4f809":"# word cloud\nplt.figure(figsize=(10,10))\nword_cloud_function(df,column='abstract',number_of_words=50000)","7c9a9ff2":"# evaluate 3-grams (takes some time)\nt1 = time.time()\nthree_gram_abs = count_ngrams(df,'abstract',3,3)\nt2 = time.time()\nprint('Elapsed time:', t2-t1)","9c06e86a":"three_gram_abs[0:20]","9dff6679":"# plot most frequent 3-grams\nfig = px.bar(three_gram_abs.sort_values('frequency',ascending=False)[0:10], \n             x=\"frequency\", \n             y=\"ngram\",\n             title='Top Ten 3-Grams in ABSTRACTS of Papers in CORD-19 Dataset',\n             orientation='h')\nfig.show()","94106879":"# evaluate bigrams (takes some time)\nt1 = time.time()\nbi_gram_abs = count_ngrams(df,'abstract',2,2)\nt2 = time.time()\nprint('Elapsed time:', t2-t1)","8819f36c":"bi_gram_abs[0:50]","0a697f7c":"# Evaluation of Metadata","4154a23e":"# Search for specific keyword in titles","02516245":"### Import data","79aa0c90":"Ok, this seems to need a little bit of cleaning up for systematic evaluation.","087457ab":"# Evaluate abstracts","bd01eab5":"[CORD-19](https:\/\/www.kaggle.com\/allen-institute-for-ai\/CORD-19-research-challenge) is a resource of over 24,000 scholarly articles, including over 12,000 with full text, about COVID-19 and the coronavirus group. ","e7ab0be4":"*Based on\/Forked from https:\/\/www.kaggle.com\/paultimothymooney\/most-common-words-in-the-cord-19-dataset*","ec20dc26":"# First glance","f1dcba5b":"# Evaluate titles"}}