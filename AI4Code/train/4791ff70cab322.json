{"cell_type":{"bcc7500e":"code","669a56de":"code","576914e3":"code","3aabc39f":"code","e59b0c38":"code","9507cdbb":"code","7781e8a3":"code","55a44900":"code","c530689e":"code","9ec7dd8d":"code","fb88d2b3":"code","e8c5aae7":"code","1620cc9c":"code","47a47e3a":"code","a0001192":"code","4c63b4c8":"code","6925775b":"code","78e84664":"code","b55b41f9":"code","bbd029a7":"code","2674737c":"code","e89f0224":"code","ca06cd51":"code","1a2be6f0":"code","784e6dfb":"code","5c738427":"code","024b3fe0":"code","9da05066":"code","aaaf9666":"code","c0dbbda1":"code","602e69e2":"code","dc795257":"code","09b77fe5":"code","b2bb0f78":"code","3e48fa6c":"code","ca7e61ab":"code","2661c77c":"code","e2e314aa":"code","966dbd35":"code","8778bb1b":"code","b8b7b384":"code","15c28126":"code","120cc50c":"code","bcf61ff7":"code","dfc65854":"code","6fcbf426":"code","13306c03":"markdown","7552bff4":"markdown","4a366a80":"markdown","2710f6df":"markdown","484b16a9":"markdown","c4154855":"markdown","6706f289":"markdown","bbed604d":"markdown","7afdf2e8":"markdown","2d7ca7c8":"markdown","33348898":"markdown","f8a6f21f":"markdown","54b88b74":"markdown","19daf784":"markdown","ac6b2f80":"markdown","dd4231f6":"markdown","4314eb46":"markdown","3e9351cd":"markdown"},"source":{"bcc7500e":"#importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom imblearn.over_sampling import SMOTE\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import BatchNormalization\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.metrics import classification_report","669a56de":"#loading data and showing the first five rows\ndf = pd.read_csv('..\/input\/loan-data\/loan_data.csv')\nloan_df = df\nloan_df.head()","576914e3":"loan_df.describe()","3aabc39f":"loan_df.shape","e59b0c38":"loan_df.isnull().sum()","9507cdbb":"loan_df.columns = [c.replace('.', '_') for c in loan_df.columns]","7781e8a3":"loan_df = pd.get_dummies(loan_df,prefix='purpose',drop_first=True)","55a44900":"loan_df['not_fully_paid'].value_counts()","c530689e":"features_to_plot = ['credit_policy', 'int_rate', 'installment', 'log_annual_inc', 'dti',\n            'fico', 'days_with_cr_line', 'revol_util', 'revol_bal']\n\nfig, axes = plt.subplots(int(len(features_to_plot)\/3),3, figsize=(15, 12))\naxes = axes.ravel()\n\nfor ax in axes:\n    ax.set_axis_off()\n    \nfor i in range(len(features_to_plot)):\n    \n    axes[i].hist(loan_df[loan_df['not_fully_paid']==0][features_to_plot[i]], alpha=0.5, color='black', bins=30, label='Settled')\n    axes[i].hist(loan_df[loan_df['not_fully_paid']==1][features_to_plot[i]], alpha=0.5, color='red', bins=30, label='Defaulted')    \n    axes[i].legend(prop={'size': 10})\n    axes[i].set_title(str(features_to_plot[i]))\n    axes[i].set_axis_on()\n \n\nfig.tight_layout()\nplt.show()","9ec7dd8d":"plt.hist(np.log(loan_df[loan_df['not_fully_paid']==0]['revol_bal'] + 1), alpha=0.5, color='black', bins=30, label='Settled')\nplt.hist(np.log(loan_df[loan_df['not_fully_paid']==1]['revol_bal'] + 1), alpha=0.5, color='red', bins=30, label='Defaulted')    \nplt.legend(prop={'size': 10})\nplt.title('revol_bal')\nplt.xlabel('log revol_bal')\nplt.ylabel('Frequancy')\nplt.show()\n\nloan_df['revol_bal_log'] = np.log(loan_df.revol_bal + 1)","fb88d2b3":"loan_df = loan_df.drop('revol_bal', axis = 1)","e8c5aae7":"df.groupby('purpose')['not_fully_paid'].count().plot(kind='bar', color='black', alpha=0.5, label = 'All')\ndf.groupby('purpose')['not_fully_paid'].sum().plot(kind='bar', color='red', alpha=0.5, label = 'Not fully paid')\nplt.rcParams[\"figure.figsize\"] = (10,6)\nplt.xlabel('Loan Purposes')\nplt.ylabel('Frequency')\nplt.legend()\nplt.show()","1620cc9c":"def ANN(train_features, test_features, train_targets, test_targets, loss):\n    model = Sequential()\n    model.add(Dense(100, input_dim=train_features.shape[1], activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.3))\n\n    model.add(Dense(50, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.3))\n\n    model.add(Dense(20, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.3))\n\n    model.add(Dense(1, activation='sigmoid'))\n\n    # Fit the model\n    model.compile(optimizer='adam', loss = loss, metrics = 'accuracy')\n    history = model.fit(train_features, train_targets, epochs = 400, verbose = 0)\n    \n    test_preds = model.predict(test_features)\n    test_preds_mapped = np.where(test_preds > 0.5, 1, 0)\n    \n    print('\\nThe confusion matris is: \\n')\n    print(confusion_matrix(test_targets, test_preds_mapped))\n    print('\\nThe classification report is: \\n')\n    print(classification_report(test_targets, test_preds_mapped))\n    \n    return test_preds","47a47e3a":"class_0 = loan_df[loan_df['not_fully_paid'] == 0]\nclass_1 = loan_df[loan_df['not_fully_paid'] == 1]","a0001192":"class_0.shape, class_1.shape","4c63b4c8":"X = loan_df.drop('not_fully_paid', axis = 1)\ny = loan_df['not_fully_paid']\n\ntrain_features, test_features, train_targets, test_targets = train_test_split(X, y, test_size=0.33, stratify = y, random_state=42)\nscale = StandardScaler()\nscale.fit(train_features)\ntrain_features = scale.transform(train_features)\ntest_features = scale.transform(test_features)","6925775b":"train_targets.value_counts()","78e84664":"test_preds = ANN(train_features, test_features, train_targets, test_targets, 'binary_crossentropy')","b55b41f9":"X = loan_df.drop('not_fully_paid', axis = 1)\ny = loan_df['not_fully_paid']\ntrain_features, test_features, train_targets, test_targets = train_test_split(X, y, test_size=0.33, stratify = y, random_state=42)","bbd029a7":"train_targets.value_counts()","2674737c":"train_set = train_features.copy()\ntrain_set['not_fully_paid'] = train_targets\nclass_0 = train_set[train_set['not_fully_paid'] == 0]\nclass_1 = train_set[train_set['not_fully_paid'] == 1]\n\nclass_0_undersample = class_0.sample(class_1.shape[0])\nloan_df_undersample = pd.concat([class_0_undersample, class_1], axis = 0)","e89f0224":"class_0_undersample.shape, class_1.shape, loan_df_undersample.shape","ca06cd51":"train_features = loan_df_undersample.drop('not_fully_paid', axis = 1)\ntrain_targets = loan_df_undersample['not_fully_paid']\n\nscale = StandardScaler()\nscale.fit(train_features)\ntrain_features = scale.transform(train_features)\ntest_features = scale.transform(test_features)","1a2be6f0":"train_targets.value_counts()","784e6dfb":"test_targets.value_counts()","5c738427":"train_preds = ANN(train_features, test_features, train_targets, test_targets, 'binary_crossentropy')","024b3fe0":"X = loan_df.drop('not_fully_paid', axis = 1)\ny = loan_df['not_fully_paid']\ntrain_features, test_features, train_targets, test_targets = train_test_split(X, y, test_size=0.33, stratify = y, random_state=42)","9da05066":"train_targets.value_counts()","aaaf9666":"train_set = train_features.copy()\ntrain_set['not_fully_paid'] = train_targets\nclass_0 = train_set[train_set['not_fully_paid'] == 0]\nclass_1 = train_set[train_set['not_fully_paid'] == 1]\n\nclass_1_oversample = class_1.sample(class_0.shape[0], replace = True)\nloan_df_oversample = pd.concat([class_0, class_1_oversample], axis = 0)","c0dbbda1":"train_features = loan_df_oversample.drop('not_fully_paid', axis = 1)\ntrain_targets = loan_df_oversample['not_fully_paid']\n\nscale = StandardScaler()\nscale.fit(train_features)\ntrain_features = scale.transform(train_features)\ntest_features = scale.transform(test_features)","602e69e2":"train_targets.value_counts()","dc795257":"test_targets.value_counts()","09b77fe5":"train_preds = ANN(train_features, test_features, train_targets, test_targets, 'binary_crossentropy')","b2bb0f78":"X = loan_df.drop('not_fully_paid', axis = 1)\ny = loan_df['not_fully_paid']","3e48fa6c":"train_features, test_features, train_targets, test_targets = train_test_split(X, y, test_size=0.33, stratify = y, random_state=42)\ntrain_set = train_features.copy()\ntrain_set['not_fully_paid'] = train_targets\n\nX = train_set.drop('not_fully_paid', axis = 1)\ny = train_set['not_fully_paid']","ca7e61ab":"smote = SMOTE(sampling_strategy='minority')","2661c77c":"train_features, train_targets = smote.fit_resample(X,y)","e2e314aa":"train_targets.value_counts()","966dbd35":"scale = StandardScaler()\nscale.fit(train_features)\ntrain_features = scale.transform(train_features)\ntest_features = scale.transform(test_features)","8778bb1b":"train_preds = ANN(train_features, test_features, train_targets, test_targets, 'binary_crossentropy')","b8b7b384":"def get_batch(majority_class, minority_class, start, end):\n    loan_df_ensembeled = pd.concat([majority_class[start:end], minority_class], axis = 0)\n    train_features = loan_df_ensembeled.drop('not_fully_paid', axis = 1)\n    train_targets = loan_df_ensembeled['not_fully_paid']\n                                \n    return train_features, train_targets","15c28126":"X = loan_df.drop('not_fully_paid', axis = 1)\ny = loan_df['not_fully_paid']\ntrain_features, test_features, train_targets, test_targets = train_test_split(X, y, test_size=0.33, stratify = y, random_state=42)\n\ntrain_set = train_features.copy()\ntrain_set['not_fully_paid'] = train_targets\n\nmajority_class = train_set[train_set['not_fully_paid'] == 0]\nminority_class = train_set[train_set['not_fully_paid'] == 1]","120cc50c":"majority_class.shape, minority_class.shape","bcf61ff7":"test_preds_dict = {}\nfor i in range(1,6):\n    train_features, train_targets = get_batch(majority_class, minority_class, (i-1) * 1027, i * 1027)\n    scale = StandardScaler()\n    scale.fit(train_features)\n    train_features = scale.transform(train_features)\n    test_features = scale.transform(test_features)\n    test_preds_dict[i] = ANN(train_features, test_features, train_targets, test_targets, 'binary_crossentropy')   \n\ntrain_features, train_targets = get_batch(majority_class, minority_class.sample(5390 - 5 * 1027), (5) * 1027, 5390)\nscale = StandardScaler()\nscale.fit(train_features)\ntrain_features = scale.transform(train_features)\ntest_features = scale.transform(test_features)\ntest_preds_dict[6] = ANN(train_features, test_features, train_targets, test_targets, 'binary_crossentropy')","dfc65854":"test_preds = test_preds_dict[1] + test_preds_dict[2] + test_preds_dict[3] + test_preds_dict[4] + test_preds_dict[5] + test_preds_dict[6] \ntest_preds = test_preds \/ 6","6fcbf426":"test_preds_mapped = np.where(test_preds > 0.5, 1, 0)\n\nprint('\\nThe confusion matris is: \\n')\nprint(confusion_matrix(test_targets, test_preds_mapped))\nprint('\\nThe classification report is: \\n')\nprint(classification_report(test_targets, test_preds_mapped))","13306c03":"## Approach 1 :  Undersampling majority class","7552bff4":"## Approach 4 :  Use of Ensemble with undersampling ","4a366a80":"# Conclusion: \n","2710f6df":"# Neural Network Classification","484b16a9":"`No null values detected`","c4154855":"`It seems that most of the features follow a normal distribution, except for revol_bal. To fix this, we should apply a log formula.`","6706f289":"the dataset is unbalanced and as a result the precision of event = 1 is low. To tackle this problem four different methods including undersampling, oversampling, SMOTE, and ensemble method with undersampling were implemented. Amoung these approaches, oversampling is the promising method.","bbed604d":"`F1-score for event = 1 is low and it needs to be improved. The skewed dataset is the reason behind the difference between F1-score of two classes. `","7afdf2e8":"# Credit Classification from LendingClub.com \n\nLending Club connects people who need money (borrowers) with people who have money (investors). Hopefully, as an investor you would want to invest in people who showed a profile of having a high probability of paying you back. I will use lending data from 2007-2010 and be trying to classify and predict whether or not the borrower paid back their loan in full.\n\nYou can download the data from <a href=\"https:\/\/www.lendingclub.com\/investing\/peer-to-peer\" target=\"_blank\">here<\/a>.","2d7ca7c8":"`The dataset is imbalanced and needs to be modified so there are balanced number of samples in each class. 4 methods will be implemented in this code to evaluate and compare different strategies for handling imbalanced dataset.`","33348898":"# Data pre-processing","f8a6f21f":"# Evaluating the model based on the balanced dataset","54b88b74":"## Feature Scaling and Dataset Spliting (unbalanced)","19daf784":"## Approach 2 :  Oversampling minority class by duplication","ac6b2f80":"## Approach 3 :  SMOTE","dd4231f6":"# Evaluating the model based on an unbalanced training set","4314eb46":"# Here are what the columns represent:\n\n***\n* **credit.policy**: 1 if the customer meets the credit underwriting criteria of LendingClub.com, and 0 otherwise.\n***\n* **purpose**: The purpose of the loan (takes values \"creditcard\", \"debtconsolidation\", \"educational\", \"majorpurchase\", \"smallbusiness\", and \"all_other\").\n***\n* **int.rate**: The interest rate of the loan, as a proportion (a rate of 11% would be stored as 0.11). Borrowers judged by LendingClub.com to be more risky are assigned higher interest rates.\n***\n* **installment**: The monthly installments owed by the borrower if the loan is funded.\n***\n* **log.annual.inc**: The natural log of the self-reported annual income of the borrower.\n***\n* **dti**: The debt-to-income ratio of the borrower (amount of debt divided by annual income).\n***\n* **fico**: The FICO credit score of the borrower.\n***\n* **days.with.cr.line**: The number of days the borrower has had a credit line.\n***\n* **revol.bal**: The borrower's revolving balance (amount unpaid at the end of the credit card billing cycle).\n***\n* **revol.util**: The borrower's revolving line utilization rate (the amount of the credit line used relative to total credit available).\n***\n* **inq.last.6mths**: The borrower's number of inquiries by creditors in the last 6 months.\n***\n* **delinq.2yrs**: The number of times the borrower had been 30+ days past due on a payment in the past 2 years.\n***\n* **pub.rec**: The borrower's number of derogatory public records (bankruptcy filings, tax liens, or judgments).\n***","3e9351cd":"# Exploratory Data Analysis"}}