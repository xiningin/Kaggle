{"cell_type":{"40be057b":"code","9c15108d":"code","3d17bb12":"code","ec63b060":"code","ca770b6e":"code","1dbb0d59":"code","26f533a1":"code","3b7f5d43":"code","697923d1":"code","eda728b1":"code","b59be349":"code","15dcc32d":"code","14b3eac9":"code","6527054c":"code","b974f529":"code","75919b16":"code","81145531":"code","9965996c":"code","174536da":"code","35a9b5ef":"code","399df0e8":"code","d969fade":"code","efda10ae":"code","ec37f4e3":"code","9c74a03d":"code","a9e14f97":"code","1d2208d3":"code","4e0293b0":"code","d7f83a5f":"code","f32f7741":"code","7535e9e9":"code","324807d0":"code","eb20b8c9":"code","d61bc603":"code","6aabf47e":"code","846c4f14":"code","c4303b56":"code","78e84418":"code","7b2e7dff":"code","9d4e4a8b":"code","172e2e55":"code","de2b634b":"code","b7fc72ab":"code","172aaadf":"code","d3eba0d7":"code","2a084166":"code","11eb63da":"code","34a3b79a":"code","23b78770":"code","17557511":"code","c9f464ba":"code","d5dd3f95":"code","e1edc68f":"code","49a5a1fc":"code","8a3cdc8a":"code","d937e856":"code","bf054124":"code","512ee4db":"code","d9903579":"code","ef371595":"code","311d3a5f":"code","9e8ca74f":"markdown","ff75e9e6":"markdown","dcf2b920":"markdown","f68c9028":"markdown","808d10d3":"markdown","96d66616":"markdown","ce6c33fd":"markdown","5f698816":"markdown","58ea1bd9":"markdown","5accbca1":"markdown","5e4d0925":"markdown","0e0fb685":"markdown","38eb3cee":"markdown","006dba3e":"markdown","2f0da631":"markdown","8baa1f85":"markdown","8f92580c":"markdown","c12f9086":"markdown","f7a78c3b":"markdown","c2a5bf34":"markdown","f403fea8":"markdown","1eabb144":"markdown"},"source":{"40be057b":"!nvidia-smi","9c15108d":"# Additional installations for Augmentor\n!pip install git+https:\/\/github.com\/mjkvaak\/ImageDataAugmentor","3d17bb12":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport zipfile\nimport csv\nimport sys\nimport os\n\nimport tensorflow as tf\n\n\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications.efficientnet import EfficientNetB5 # for efficientNet attempt\nimport tensorflow.keras.models as Model\nimport tensorflow.keras.layers as Layer\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\n# Augmentation\nimport albumentations as a\nfrom ImageDataAugmentor.image_data_augmentor import *\n\n# Visualization\nimport PIL\nfrom PIL import ImageOps, ImageFilter\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline\n\nprint(os.listdir(\"..\/input\"))\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)\nprint('Keras        :', tf.keras.__version__)","ec63b060":"# Main setup\n\nEPOCHS               = 8\nBATCH_SIZE           = 32\nLR                   = 1e-4\nVAL_SPLIT            = 0.15 #test size\n\nCLASS_NUM            = 10  # number of classes\nIMG_SIZE             = 224 # image size\nIMG_CHANNELS         = 3   # RGB has 3 channels\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '..\/input\/'\nPATH = \"..\/working\/car\/\" #DIR","ca770b6e":"# Set random seed \nos.makedirs(PATH,exist_ok=True)\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)  \nPYTHONHASHSEED = 0","1dbb0d59":"train_df = pd.read_csv(DATA_PATH+\"train.csv\")\nsample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\ntrain_df.head()","26f533a1":"train_df.info()","3b7f5d43":"train_df.Category.value_counts()\n# distribution is even enough","697923d1":"print('Unpack pictures')\n# Will unzip the files so that you can see them..\nfor data_zip in ['train.zip', 'test.zip']:\n    with zipfile.ZipFile(\"..\/input\/\"+data_zip,\"r\") as z:\n        z.extractall(PATH)\n        \nprint(os.listdir(PATH))","eda728b1":"print('Examples (random sample)')\nplt.figure(figsize=(12,8))\n\nrandom_image = train_df.sample(n=9)\nrandom_image_paths = random_image['Id'].values\nrandom_image_cat = random_image['Category'].values\n\nfor index, path in enumerate(random_image_paths):\n    im = PIL.Image.open(PATH+f'train\/{random_image_cat[index]}\/{path}')\n    plt.subplot(3,3, index+1)\n    plt.imshow(im)\n    plt.title('Class: '+str(random_image_cat[index]))\n    plt.axis('off')\nplt.show()","b59be349":"image = PIL.Image.open(PATH+'\/train\/0\/100380.jpg')\nimgplot = plt.imshow(image)\nplt.show()\nimage.size","15dcc32d":"# Documentation: https:\/\/github.com\/albu\/albumentations\n\naugmentations = a.Compose([\n    a.GaussianBlur(p=0.05), # add Gauss bluring and noise with 5% probability\n    a.GaussNoise(p=0.05),\n    a.ShiftScaleRotate(shift_limit=0.0625, \n                       scale_limit=0.01, \n                       interpolation=1, \n                       border_mode=4, \n                       rotate_limit=20, \n                       p=.75), # shift, scale, rotate with higher than default probablity can be useful for variety \n#     in our images \n    a.RandomBrightness(limit=0.2, p=0.5),\n    \n#     Add some more aumentations with default parameters\n    \n    a.HorizontalFlip(), # as we take a look on car's model it may vary with different mirroring,\n                        # then to get better result we can turn it on NO VERTICAL FLIP because cars are always in horizontal\n    a.HueSaturationValue(), # random hue and saturation\n    a.RGBShift(),\n    a.FancyPCA(alpha=0.1, \n               always_apply=False, \n               p=0.5),\n    a.Resize(IMG_SIZE, IMG_SIZE),\n    \n    #  add OneOfs with default 50% probability for brightness contrast\n    a.OneOf([\n        a.RandomBrightnessContrast(brightness_limit=0.3, \n                                                contrast_limit=0.3),\n        a.RandomBrightnessContrast(brightness_limit=0.1, \n                                                contrast_limit=0.1)],\n        p=0.5)\n])\n","14b3eac9":"# Common datagen for train and test based on Augmentor\n\ndatagen = ImageDataAugmentor(\n                        rescale=1.\/255,\n                        augment=augmentations, \n                        seed=RANDOM_SEED,\n                        validation_split=VAL_SPLIT)","6527054c":"# Wrap our data into generator:\n\ntrain_datagen = datagen.flow_from_directory(\n    PATH+'train\/',      # DIR\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, \n    subset='training') # set as training data\n\ntest_datagen = datagen.flow_from_directory(\n    PATH+'train\/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True,\n    subset='validation') # set as validation data","b974f529":"# Let's take a look on augmented cars images\ntrain_datagen.show_data(rows=3, cols=5)","75919b16":"# Here we choose one of 2 models to compare\n# base_model = Xception(weights='imagenet', include_top=False, input_shape = input_shape)\nbase_model = EfficientNetB5(weights='imagenet', include_top=False, input_shape = input_shape)","81145531":"# base_model.summary()","9965996c":"# freeze the pre-trained model weights, train only the top layers\nbase_model.trainable = False","174536da":"model = Model.Sequential()\nmodel.add(base_model)","35a9b5ef":"# Set new head\n\n# Add pooling layer\nmodel.add(Layer.GlobalAveragePooling2D())\n\n# Add a fully-connected layer\nmodel.add(Layer.Dense(256, \n                      activation='relu', \n                      bias_regularizer=l2(1e-4),\n                      activity_regularizer=l2(1e-5)))\n\n# Add batch normalization\nmodel.add(Layer.BatchNormalization())\nmodel.add(Layer.Dropout(0.25)) # and dropout\n# model.add(Layer.BatchNormalization())\n# model.add(Layer.Dropout(0.25))\n\n# And a final layer for 10 classes\nmodel.add(Layer.Dense(CLASS_NUM, activation='softmax'))\n\n# This is the model we will train\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","399df0e8":"model.summary()","d969fade":"# Check the trainable status of the individual layers (should be False for base model and True for head)\nfor layer in model.layers:\n    print(layer, layer.trainable)","efda10ae":"# Add checkpoint function to save best model\ncheckpoint = ModelCheckpoint('best_model.hdf5', \n                             monitor = ['val_accuracy'], \n                             verbose = 1,\n                             mode = 'max')\n\n# Add LR scheduler (decrease rate exponentialy after 4 epoch)\n# ARTICLE APPLIED: https:\/\/towardsdatascience.com\/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6\nlr_scheduler = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2, #let's reduce LR 5 times\n                              patience=2, # if no improvement after 2 epoch - reduce LR\n                              min_lr=0.0000001,\n                              verbose=1,\n                              mode='auto')\n\n# Add early stop\nearlystop = EarlyStopping(monitor = 'val_accuracy',\n                          patience = 4,\n                          restore_best_weights = True)\n\ncallbacks_list = [checkpoint, earlystop, lr_scheduler]","ec37f4e3":"history = model.fit(\n        train_datagen,\n        steps_per_epoch = len(train_datagen),\n        validation_data = test_datagen, \n        validation_steps = len(test_datagen),\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)","9c74a03d":"# Save the model and upload best_model\nmodel.save('..\/working\/model_last.hdf5')\nmodel.load_weights('best_model.hdf5')","a9e14f97":"scores = model.evaluate(test_datagen, steps=len(test_datagen), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","1d2208d3":"def plot_history(history):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs = range(len(acc))\n\n    plt.plot(epochs, acc, 'b', label='Training acc')\n    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n\n    plt.figure()\n\n    plt.plot(epochs, loss, 'b', label='Training loss')\n    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n\n    plt.show()\n","4e0293b0":"plot_history(history)","d7f83a5f":"base_model.trainable = True\n\n# Fine-tune starting point\nstart_point = len(base_model.layers)\/\/2\n\n# Keep all other layers frozen\nfor layer in base_model.layers[:start_point]:\n    layer.trainable =  False","f32f7741":"# Compile new model\nmodel.compile(loss=\"categorical_crossentropy\", \n              optimizer=optimizers.Adam(lr=LR), \n              metrics=[\"accuracy\"])\nmodel.summary()","7535e9e9":"# Check the trainable status\nfor layer in model.layers:\n    print(layer, layer.trainable)","324807d0":"# Fit again\nhistory = model.fit(\n        train_datagen,\n        steps_per_epoch = len(train_datagen),\n        validation_data = test_datagen, \n        validation_steps = len(test_datagen),\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)","eb20b8c9":"model.load_weights('best_model.hdf5') ","d61bc603":"scores = model.evaluate(test_datagen, steps=len(test_datagen), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","6aabf47e":"plot_history(history)","846c4f14":"base_model.trainable = True","c4303b56":"# Compile new model\nmodel.compile(loss=\"categorical_crossentropy\", \n              optimizer=optimizers.Adam(lr=LR), \n              metrics=[\"accuracy\"])\nmodel.summary()","78e84418":"# Check the trainable status\nfor layer in model.layers:\n    print(layer, layer.trainable)","7b2e7dff":"# Fit again\nhistory = model.fit(\n        train_datagen,\n        steps_per_epoch = len(train_datagen),\n        validation_data = test_datagen, \n        validation_steps = len(test_datagen),\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)","9d4e4a8b":"model.load_weights('best_model.hdf5') \nscores = model.evaluate(test_datagen, steps=len(test_datagen), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","172e2e55":"plot_history(history)","de2b634b":"# Save as last model\nmodel.save('..\/working\/model_last.hdf5')","b7fc72ab":"test_gen = ImageDataAugmentor(rescale=1.\/255) # rescale=1.\/255 \ntest_sub_generator = test_gen.flow_from_dataframe(dataframe=sample_submission,\n                                            directory=PATH+'test_upload\/',\n                                            x_col=\"Id\",\n                                            y_col=None,\n                                            shuffle=False,\n                                            class_mode=None,\n                                            target_size=(IMG_SIZE, IMG_SIZE),\n                                            batch_size=BATCH_SIZE)","172aaadf":"test_sub_generator.reset()\npredictions = model.predict(test_sub_generator, steps=len(test_sub_generator), verbose=1) \npredictions = np.argmax(predictions, axis=-1) # multiple categories\nlabel_map = (train_datagen.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","d3eba0d7":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, \n                          columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload\/','')\n\nsubmission.to_csv('submission.csv', index=False)","2a084166":"submission.head()","11eb63da":"EPOCHS               = 7 # keep 7 because at epoch 8 we had slight overfitting\nBATCH_SIZE           = 8\nLR                   = 1e-4 # start with this LR \nVAL_SPLIT            = 0.15 #test size\n\nCLASS_NUM            = 10  # number of classes\nIMG_SIZE             = 512 # image size\nIMG_CHANNELS         = 3   # RGB has 3 channels\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)","34a3b79a":"train_datagen = datagen.flow_from_directory(\n    PATH+'train\/',      # DIR\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, \n    subset='training') # set as training data\n\ntest_datagen = datagen.flow_from_directory(\n    PATH+'train\/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True,\n    subset='validation') # set as validation data\n\ntest_sub_generator = test_gen.flow_from_dataframe(dataframe=sample_submission,\n                                            directory=PATH+'test_upload\/',\n                                            x_col=\"Id\",\n                                            y_col=None,\n                                            shuffle=False,\n                                            class_mode=None,\n                                            target_size=(IMG_SIZE, IMG_SIZE),\n                                            batch_size=BATCH_SIZE)","23b78770":"# Keep last model\nmodel.summary()","17557511":"# Check the trainable status\nfor layer in model.layers:\n    print(layer, layer.trainable)","c9f464ba":"# Fit again\nhistory = model.fit(\n        train_datagen,\n        steps_per_epoch = len(train_datagen),\n        validation_data = test_datagen, \n        validation_steps = len(test_datagen),\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)","d5dd3f95":"# Accuracy\nmodel.load_weights('best_model.hdf5') \nscores = model.evaluate(test_datagen, steps=len(test_datagen), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","e1edc68f":"# Save as last model\nmodel.save('..\/working\/model_last.hdf5')","49a5a1fc":"# PREDICTIONS\ntest_sub_generator.reset()\npredictions = model.predict(test_sub_generator, steps=len(test_sub_generator), verbose=1) \npredictions = np.argmax(predictions, axis=-1) # multiple categories\nlabel_map = (train_datagen.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]\n\nfilenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, \n                          columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload\/','')\n\nsubmission.to_csv('submission_size_batch.csv', index=False)","8a3cdc8a":"#  Add augmentation to validation set\ntest_gen = ImageDataAugmentor(\n                        rescale=1.\/255,\n                        augment=augmentations, \n                        seed=RANDOM_SEED,\n                        validation_split=VAL_SPLIT\n                       )\n\ntest_sub_generator = test_gen.flow_from_dataframe(dataframe=sample_submission,\n                                            directory=PATH+'test_upload\/',\n                                            x_col=\"Id\",\n                                            y_col=None,\n                                            shuffle=False,\n                                            class_mode=None,\n                                            target_size=(IMG_SIZE, IMG_SIZE),\n                                            batch_size=BATCH_SIZE)","d937e856":"STEPS = 50\npredictions = []\n\nfor i in range(STEPS):\n    x = model.predict(test_sub_generator, verbose=1) \n    predictions.append(x)\n\navg_prediction = np.mean(predictions, axis=0) # take average from predictions we have","bf054124":"predictions = np.argmax(avg_prediction, axis=-1) # multiple categories\nlabel_map = (train_datagen.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]\nfilenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, \n                          columns=['Id', 'Category'])\n\nsubmission['Id'] = submission['Id'].replace('test_upload\/','')","512ee4db":"# Check current accuracy\nscores = model.evaluate(test_datagen, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","d9903579":"submission.head()","ef371595":"# Save submission\nsubmission.to_csv('submission_tta.csv', index=False)","311d3a5f":"# Clean PATH\n# import shutil\n# shutil.rmtree(PATH)","9e8ca74f":"# Improvements","ff75e9e6":"# Conclusion","dcf2b920":"## Change Image and Batch size","f68c9028":"### Download Xception\/EfficientNetB5:","808d10d3":"#### The best model is based on EfficientNetB5 with:\n     100% unfrozen layers \n     8 as batch size\n     7 epochs\n     512px as Img size\n   Got **95.58%** accuracy and **96.45%** on kaggle submission\n \n #### Techniques and functions used for the project:\n* Transfer learning with fine-tuning \n* 2 base models: Xception and EfficientNetB5\n* Batch Normalization added and callbacks \n* Advanced Albumentations package for augmentation\n* Leraning rate managing techique\n* Test Time Augmentation (just tested)","96d66616":"# EDA \/ Data Analysis","ce6c33fd":"# !pip freeze > requirements.txt","5f698816":"# SETUP","58ea1bd9":"### Data generation","5accbca1":"# Build the model","5e4d0925":"### We got a good result but could be better, accuracy is still low, let's try to apply fine tuning and unfreeze some layers.","0e0fb685":"### Unfreeze 100% of layers in base model","38eb3cee":"#### Clean working path","006dba3e":"### Unfreeze 50% of layers in base model","2f0da631":"# Image classification\n\n### Idea: to take ready-to-use neural network Xception (or another one) from ImageNet and improve it . ","8baa1f85":"# Data preparation","8f92580c":"# Fine-tuning","c12f9086":"## Test Time Augmentation \n#### https:\/\/towardsdatascience.com\/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d","f7a78c3b":"## Train model","c2a5bf34":"### Got 95,5% on submission, let's try to improve","f403fea8":"# Predictions","1eabb144":"### Data augmentation with Albumentations "}}