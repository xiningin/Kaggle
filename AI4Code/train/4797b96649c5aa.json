{"cell_type":{"1b3fb95b":"code","99177c95":"code","f3d2d1e5":"code","ee17ae5c":"code","07d1bbd3":"code","03662cf9":"code","1b60c89f":"code","67a25d12":"code","a19599f2":"code","c95c6d07":"code","de0aa090":"code","18916097":"code","dfefc977":"code","ae3ef03e":"code","d958448c":"code","b458b2f7":"code","cef36e47":"code","fd5cedd7":"code","fbd0893b":"code","711a0c8e":"code","303e741d":"code","658a6d34":"code","b3bf9eaa":"code","caca4136":"code","851e7638":"code","faca485c":"code","8b7f8a9b":"code","0996d1a0":"code","51d0f7ea":"code","abc05214":"code","49287372":"code","3f2cbc46":"code","66864af6":"code","59f40ba9":"code","3c784c3c":"code","09503279":"code","08a65524":"code","6da19cfc":"code","3a2d17c2":"code","4e3a9b12":"code","f9a339a8":"code","eeb1377f":"code","82f194f6":"code","1a98ca95":"code","c84e847e":"markdown","e955c067":"markdown","29071316":"markdown","09864747":"markdown","3da5dd56":"markdown","140543cf":"markdown","4535ee04":"markdown","31131573":"markdown","ac020af2":"markdown","fd4d1a91":"markdown","0aa3427f":"markdown","17982cbf":"markdown","b92fd06c":"markdown","786150b8":"markdown","d62d0292":"markdown","af721666":"markdown","910c1d34":"markdown","0062a2e1":"markdown","4dee8c39":"markdown"},"source":{"1b3fb95b":"# Ignore  the warnings\nimport warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\n# data visualisation and manipulation\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport seaborn as sns\nimport missingno as msno\n#configure\n# sets matplotlib to inline and displays graphs below the corressponding cell.\n% matplotlib inline  \nstyle.use('fivethirtyeight')\nsns.set(style='whitegrid',color_codes=True)\n\n#import the necessary modelling algos.\n\n#classifiaction.\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC,SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\n#regression\nfrom sklearn.linear_model import LinearRegression,Ridge,Lasso,RidgeCV\nfrom sklearn.ensemble import RandomForestRegressor,BaggingRegressor,GradientBoostingRegressor,AdaBoostRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\n\n#model selection\nfrom sklearn.model_selection import train_test_split,cross_validate\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\n\n#evaluation metrics\nfrom sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error # for regression\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score  # for classification\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n ","99177c95":"train=pd.read_csv(r'..\/input\/train.csv')\ntest=pd.read_csv(r'..\/input\/test.csv')\ndf=train.copy()\ntest_df=test.copy()\ndf.head()","f3d2d1e5":"df.columns.unique()","ee17ae5c":"df.info()","07d1bbd3":"df.isnull().sum()  # implies no null values and hence no imputation needed ::).","03662cf9":"msno.matrix(df)  # just to visualize. no missing value.","1b60c89f":"# let us consider season.\ndf.season.value_counts()","67a25d12":"#sns.factorplot(x='season',data=df,kind='count',size=5,aspect=1)\nsns.factorplot(x='season',data=df,kind='count',size=5,aspect=1.5)","a19599f2":"#holiday\ndf.holiday.value_counts()\nsns.factorplot(x='holiday',data=df,kind='count',size=5,aspect=1) # majority of data is for non holiday days.","c95c6d07":"#holiday\ndf.workingday.value_counts()\nsns.factorplot(x='workingday',data=df,kind='count',size=5,aspect=1) # majority of data is for working days.","de0aa090":"#weather\ndf.weather.value_counts()","18916097":"sns.factorplot(x='weather',data=df,kind='count',size=5,aspect=1)  \n# 1-> spring\n# 2-> summer\n# 3-> fall\n# 4-> winter","dfefc977":"df.describe()","ae3ef03e":"# just to visualize.\nsns.boxplot(data=df[['temp',\n       'atemp', 'humidity', 'windspeed', 'casual', 'registered', 'count']])\nfig=plt.gcf()\nfig.set_size_inches(10,10)","d958448c":"# can also be visulaized using histograms for all the continuous variables.\ndf.temp.unique()\nfig,axes=plt.subplots(2,2)\naxes[0,0].hist(x=\"temp\",data=df,edgecolor=\"black\",linewidth=2,color='#ff4125')\naxes[0,0].set_title(\"Variation of temp\")\naxes[0,1].hist(x=\"atemp\",data=df,edgecolor=\"black\",linewidth=2,color='#ff4125')\naxes[0,1].set_title(\"Variation of atemp\")\naxes[1,0].hist(x=\"windspeed\",data=df,edgecolor=\"black\",linewidth=2,color='#ff4125')\naxes[1,0].set_title(\"Variation of windspeed\")\naxes[1,1].hist(x=\"humidity\",data=df,edgecolor=\"black\",linewidth=2,color='#ff4125')\naxes[1,1].set_title(\"Variation of humidity\")\nfig.set_size_inches(10,10)","b458b2f7":"#corelation matrix.\ncor_mat= df[:].corr()\nmask = np.array(cor_mat)\nmask[np.tril_indices_from(mask)] = False\nfig=plt.gcf()\nfig.set_size_inches(30,12)\nsns.heatmap(data=cor_mat,mask=mask,square=True,annot=True,cbar=True)","cef36e47":"# # seperating season as per values. this is bcoz this will enhance features.\nseason=pd.get_dummies(df['season'],prefix='season')\ndf=pd.concat([df,season],axis=1)\ndf.head()\nseason=pd.get_dummies(test_df['season'],prefix='season')\ntest_df=pd.concat([test_df,season],axis=1)\ntest_df.head()","fd5cedd7":"# # # same for weather. this is bcoz this will enhance features.\nweather=pd.get_dummies(df['weather'],prefix='weather')\ndf=pd.concat([df,weather],axis=1)\ndf.head()\nweather=pd.get_dummies(test_df['weather'],prefix='weather')\ntest_df=pd.concat([test_df,weather],axis=1)\ntest_df.head()","fbd0893b":"# # # now can drop weather and season.\ndf.drop(['season','weather'],inplace=True,axis=1)\ndf.head()\ntest_df.drop(['season','weather'],inplace=True,axis=1)\ntest_df.head()\n\n\n# # # also I dont prefer both registered and casual but for ow just let them both.","711a0c8e":"df[\"hour\"] = [t.hour for t in pd.DatetimeIndex(df.datetime)]\ndf[\"day\"] = [t.dayofweek for t in pd.DatetimeIndex(df.datetime)]\ndf[\"month\"] = [t.month for t in pd.DatetimeIndex(df.datetime)]\ndf['year'] = [t.year for t in pd.DatetimeIndex(df.datetime)]\ndf['year'] = df['year'].map({2011:0, 2012:1})\ndf.head()","303e741d":"test_df[\"hour\"] = [t.hour for t in pd.DatetimeIndex(test_df.datetime)]\ntest_df[\"day\"] = [t.dayofweek for t in pd.DatetimeIndex(test_df.datetime)]\ntest_df[\"month\"] = [t.month for t in pd.DatetimeIndex(test_df.datetime)]\ntest_df['year'] = [t.year for t in pd.DatetimeIndex(test_df.datetime)]\ntest_df['year'] = test_df['year'].map({2011:0, 2012:1})\ntest_df.head()","658a6d34":"# now can drop datetime column.\ndf.drop('datetime',axis=1,inplace=True)\ndf.head()","b3bf9eaa":"cor_mat= df[:].corr()\nmask = np.array(cor_mat)\nmask[np.tril_indices_from(mask)] = False\nfig=plt.gcf()\nfig.set_size_inches(30,12)\nsns.heatmap(data=cor_mat,mask=mask,square=True,annot=True,cbar=True)","caca4136":"df.drop(['casual','registered'],axis=1,inplace=True)","851e7638":"df.head()","faca485c":"# with hour.\nsns.factorplot(x=\"hour\",y=\"count\",data=df,kind='bar',size=5,aspect=1.5)","8b7f8a9b":"sns.factorplot(x=\"month\",y=\"count\",data=df,kind='bar',size=5,aspect=1.5)\n# note that month affects season and that effects wheteher people take bike or not. like climate conditions rainy,hazy etc... .","0996d1a0":"sns.factorplot(x=\"year\",y=\"count\",data=df,kind='bar',size=5,aspect=1.5)\n# 0 for 2011 and 1 for 2012. Hence demand has increased over the years.","51d0f7ea":"sns.factorplot(x=\"day\",y='count',kind='bar',data=df,size=5,aspect=1)","abc05214":"# for temp\nplt.scatter(x=\"temp\",y=\"count\",data=df,color='#ff4125')","49287372":"new_df=df.copy()\nnew_df.temp.describe()\nnew_df['temp_bin']=np.floor(new_df['temp'])\/\/5\nnew_df['temp_bin'].unique()\n# now we can visualize as follows\nsns.factorplot(x=\"temp_bin\",y=\"count\",data=new_df,kind='bar')","3f2cbc46":"# and similarly we can do for other continous variables and see how it effect the target variable.","66864af6":"df.head()","59f40ba9":"df.columns.to_series().groupby(df.dtypes).groups","3c784c3c":"x_train,x_test,y_train,y_test=train_test_split(df.drop('count',axis=1),df['count'],test_size=0.25,random_state=42)","09503279":"models=[RandomForestRegressor(),AdaBoostRegressor(),BaggingRegressor(),SVR(),KNeighborsRegressor()]\nmodel_names=['RandomForestRegressor','AdaBoostRegressor','BaggingRegressor','SVR','KNeighborsRegressor']\nrmsle=[]\nd={}\nfor model in range (len(models)):\n    clf=models[model]\n    clf.fit(x_train,y_train)\n    test_pred=clf.predict(x_test)\n    rmsle.append(np.sqrt(mean_squared_log_error(test_pred,y_test)))\nd={'Modelling Algo':model_names,'RMSLE':rmsle}   \nd\n    ","08a65524":"rmsle_frame=pd.DataFrame(d)\nrmsle_frame","6da19cfc":"sns.factorplot(y='Modelling Algo',x='RMSLE',data=rmsle_frame,kind='bar',size=5,aspect=2)","3a2d17c2":"sns.factorplot(x='Modelling Algo',y='RMSLE',data=rmsle_frame,kind='point',size=5,aspect=2)","4e3a9b12":"#for random forest regresion.\nno_of_test=[500]\nparams_dict={'n_estimators':no_of_test,'n_jobs':[-1],'max_features':[\"auto\",'sqrt','log2']}\nclf_rf=GridSearchCV(estimator=RandomForestRegressor(),param_grid=params_dict,scoring='neg_mean_squared_log_error')\nclf_rf.fit(x_train,y_train)\npred=clf_rf.predict(x_test)\nprint((np.sqrt(mean_squared_log_error(pred,y_test))))","f9a339a8":"clf_rf.best_params_","eeb1377f":"# for KNN\nn_neighbors=[]\nfor i in range (0,50,5):\n    if(i!=0):\n        n_neighbors.append(i)\nparams_dict={'n_neighbors':n_neighbors,'n_jobs':[-1]}\nclf_knn=GridSearchCV(estimator=KNeighborsRegressor(),param_grid=params_dict,scoring='neg_mean_squared_log_error')\nclf_knn.fit(x_train,y_train)\npred=clf_knn.predict(x_test)\nprint((np.sqrt(mean_squared_log_error(pred,y_test))))\n","82f194f6":"clf_knn.best_params_","1a98ca95":"pred=clf_rf.predict(test_df.drop('datetime',axis=1))\nd={'datetime':test['datetime'],'count':pred}\nans=pd.DataFrame(d)\nans.to_csv('submission.csv',index=False) # saving to a csv file for predictions on kaggle.\n","c84e847e":"######  HERE ALL THE VARIABLES OR FEATURES ARE NUMERIC AND THE TARGET VARIABLE THAT WE HAVE TO PREDICT IS THE count VARIABLE. HENCE THIS IS A TYPICAL EXAMPLE OF A REGRESSION PROBLEM AS THE count VARIABLE IS CONTINUOUS VARIED.","e955c067":"###### A SHORT DESCRIPTION OF THE FEATURES.\n\ndatetime - hourly date + timestamp  \n\nseason -  1 = spring, 2 = summer, 3 = fall, 4 = winter \n\nholiday - whether the day is considered a holiday\n\nworkingday - whether the day is neither a weekend nor holiday\n\nweather -\n\n1: Clear, Few clouds, Partly cloudy, Partly cloudy \n\n2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist \n\n3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds \n\n4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \n\ntemp - temperature in Celsius\n\natemp - \"feels like\" temperature in Celsius\n\nhumidity - relative humidity\n\nwindspeed - wind speed\n\ncasual - number of non-registered user rentals initiated\n\nregistered - number of registered user rentals initiated\n\ncount - number of total rentals","29071316":"######  NOW RANDOM FORETS REGRESSOR GIVES THE LEAST RMSLE. HENCE WE USE IT TO MAKE PREDICTIONS ON KAGGLE.","09864747":"######  NOTE THAT THERE ARE OTHER MODELLING ALGOS LIKE LINEAR REGRESSION ,RIDGE AND RIDGECV BUT THE PROBLEM IS THAT THOSE MODELS ARE PREDICTING NEGATIVE VALUES FOR THE COUNT TARGET WHICH IS NOT POSSIBLE.                                                                                                                                                                                                                                                                                                                  NOW I DONT KNOW WHAT TO DO IN THOSE CASES :::) !!!!!!!!!!!!!!!","3da5dd56":"######  NOW LET'S TUNE A BIT...","140543cf":"# BIKE SHARING DEMAND","4535ee04":"######  now most importantly split the date and time as the time of day is expected to effect the no of bikes. for eg at office hours like early mornning or evening one would expect a greater demand of rental bikes.","31131573":"######  now the demand is highest for bins 6 and 7 which is about tempearure  30-35(bin 6) and 35-40 (bin 7).","ac020af2":"###### NOW THE DATA EXPLORATION ,ANALYSIS AND VISUALIZATION  AND PREPROCESSING HAS BEEN DONE AND NOW WE CAN MOVE TO MODELLING PART.","fd4d1a91":"######  NOW WE  CAN DO SOME FEATURE ENGINEERING AND GET SOME NEW FEATURES AND DROP SOME USELESS OR LESS RELEVANT FEATURES.","0aa3427f":"######  note that the highest demand is in hours from say 7-10 and the from 15-19. this is bcoz in most of the metroploitan cities this is the        peak office time and so more people would be renting bikes. this is just one of the plausible reason.","17982cbf":"###### note that this way this is hard to visualze. a better way is to convert the 'temp' variable into intervals or so called bins and then treat it like a discrete variable.","b92fd06c":"###### NOW LETS HAVE A LOOK AT OUR NEW FEATURES.","786150b8":"######  INFERENCES FROM THE ABOVE HEATMAP--\n\n1. self realtion i.e. of a feature to itself is equal to 1 as expected.\n\n2. temp and atemp are highly related as expected.\n \n3. humidity is inversely related to count as expected as the weather is humid people will not like to travel on a bike.\n\n4. also note that casual and working day are highly inversely related as you would expect.\n\n5. Also note that count and holiday are highly inversely related as you would expect.\n\n6. Also note that temp(or atemp) highly effects the count. \n\n7. Also note that weather and count are highly inversely related. This is bcoz for uour data as weather increases from (1 to 4) implies that  weather is getting more worse and so lesser people will rent bikes.\n\n8. registered\/casual and count are highly related which indicates that most of the bikes that are rented are registered.\n\n9. similarly we can draw some more inferences like weather and humidity and so on... .\n","d62d0292":"**Please star\/upvote if u find it helpful.**","af721666":"###### NOW LET SEE HOW COUNT VARIES WITH DIFFERENT FEATURES.","910c1d34":"######  NOW AFTER SEEING THE DISTRIBUTION OF VARIOUS DISCRETE AS WELL AS CONTINUOUS VARIABLES WE CAN SEE THE INTERREALTION B\/W THEM USING A HEAT MAP.","0062a2e1":"######  NOW WE CAN EXPLORE OUR FEATURES. FIRST LETS EXPLORE THE DISTRIBUTION OF VARIOUS DISCRETE FEATURES LIKE weather , season etc... .","4dee8c39":"######  NOW WE CAN  ALSO SEE DISTRIBUTION OF CONTINOUS VARIABLES."}}