{"cell_type":{"736bb6ca":"code","1def6e2c":"code","a2dca29c":"code","fe6f1648":"code","f1010c37":"code","12b9e5ef":"code","965cd018":"code","287b5049":"code","6692e4b5":"code","822b24a3":"code","2b1c4436":"code","53b96107":"code","3f7f6487":"code","22eb9be5":"code","f60abe3a":"code","4be5fd8c":"code","6cc7ab8c":"code","3e297133":"code","9377707c":"code","884910f9":"code","f2b4ae78":"code","899efa73":"markdown","efa11aed":"markdown","58f43dab":"markdown","d8442aee":"markdown","905ca89c":"markdown","825cc2b5":"markdown","64655329":"markdown"},"source":{"736bb6ca":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\n\nimport gensim\nimport pyLDAvis.gensim # for visualization\nfrom gensim.models import CoherenceModel","1def6e2c":"df = pd.read_csv('..\/input\/turkishnews70000\/turkish_news_70000.csv', index_col='id')\ndf.head()","a2dca29c":"df['text'] = df['text'].astype(str)","fe6f1648":"news_df = df[['text']]\nnews_df.head()","f1010c37":"# create a set of punctuations\npunctuation_set = string.punctuation\n\n# create a set of stopwords\nstopwords_set = stopwords.words('turkish')\n\n# let's add some more stop words\nstopwords_set.extend(['bir', 'kadar', 'sonra'])","12b9e5ef":"def clean_dataset(text):\n    # lowercase operation\n    text = text.lower()\n    # new line remove\n    text = text.replace(\"\\\\n\", \"\")\n    # remove numbers\n    text = re.sub(\"[0-9]+\", \"\", text)\n    # remove punctuations\n    text = \"\".join(list(map(lambda x:x if x not in punctuation_set else \" \", text)))\n    # remove stopwords\n    text = \" \".join([i for i in text.split() if i not in stopwords_set])\n    # remove a word which is one letter in the text\n    text = \" \".join([i for i in text.split() if len(i) > 1])\n    \n    return text","965cd018":"news_df['text'] = news_df['text'].apply(lambda x: clean_dataset(x))","287b5049":"news_df['cleaned_text'] = news_df.iloc[5].text","6692e4b5":"news_df['cleaned_text'].iloc[5]","822b24a3":"news_df['cleaned_text_token'] = news_df['cleaned_text'].apply(lambda x: x.split())","2b1c4436":"news_df.drop(['text'], axis=1, inplace=True)","53b96107":"news_df.head(5)","3f7f6487":"#list of word - dictionary \ntokenized_text = news_df['cleaned_text_token']\nword_list = gensim.corpora.Dictionary(tokenized_text)\n\n# filter list of word\n# word_list.filter_extremes(no_below=1, no_above=0.7)","22eb9be5":"# vectorized terms\ndocument_term_matrix = [word_list.doc2bow(term) for term in tokenized_text]","f60abe3a":"lda_model = gensim.models.ldamodel.LdaModel(\n                                            corpus= document_term_matrix,\n                                            id2word= word_list,\n                                            num_topics = 15,\n                                            passes = 10\n                                           )","4be5fd8c":"# Most repeated words in created topics \ntopics = lda_model.print_topics(num_words=7)\n\nfor topic in topics:\n    print(topic)","6cc7ab8c":"pyLDAvis.enable_notebook()\nvis = pyLDAvis.gensim.prepare(lda_model, document_term_matrix, dictionary=lda_model.id2word, mds='mmds')\npyLDAvis.display(vis)","3e297133":"topic_number_range_list = range(9,30,3)\n\ncoherence_score_list = list()\ntopic_number_list = list()\n\nfor topic_number in topic_number_range_list:\n    lda_model = gensim.models.ldamodel.LdaModel(\n                                                corpus= document_term_matrix,\n                                                id2word= word_list,\n                                                num_topics = topic_number,\n                                                passes = 10\n                                                )\n    \n    coherence_model_lda = CoherenceModel(\n                                        model = lda_model,\n                                        texts = tokenized_text,\n                                        dictionary = word_list,\n                                        coherence='c_v'\n                                        ) \n    \n    temp_coherence_score_lda = coherence_model_lda.get_coherence()\n    coherence_score_list.append(temp_coherence_score_lda)\n    topic_number_list.append(topic_number)","9377707c":"plt.plot(topic_number_list, coherence_score_list, \"-\")\nplt.xlabel(\"Topic Numbers\")\nplt.ylabel(\"Coherence Scores\")\n\nplt.show()","884910f9":"topics = lda_model.print_topics(num_words=7)\ntopics = sorted(topics, key = lambda x: x[0])\n\nfor topic in topics:\n    print(topic)","f2b4ae78":"pyLDAvis.enable_notebook()\nvis = pyLDAvis.gensim.prepare(lda_model, document_term_matrix, dictionary=lda_model.id2word, mds='mmds')\npyLDAvis.display(vis)","899efa73":"**Choosing best topic by Coherence Score**","efa11aed":"**Uploading data set**","58f43dab":"**LDA MODEL TRAINING**","d8442aee":"**MODEL VISUALIZATION**","905ca89c":"***What we are going to do in cleaning part***\n\n**-> Make all of words to lowercase**\n\n**-> Remove stopwords**\n\n**-> Remove punctuations**\n\n**-> Remove numbers**\n\n**-> Remove unnecesary word which we see**","825cc2b5":"**Necessary Libraries**","64655329":"**Preparing Data & Cleaning**"}}