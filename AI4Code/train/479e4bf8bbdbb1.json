{"cell_type":{"f1ab9611":"code","e8a910f0":"code","81091c4e":"code","7f1f6edc":"code","12ec2428":"code","19c7f746":"code","f6d63304":"code","dbc885e5":"code","4357f59d":"code","1b795574":"code","ff273d11":"code","1b081c68":"code","97f8426a":"code","662b875d":"code","d966d2d7":"code","11439c97":"code","527210c1":"code","a4879d04":"code","76a2fd65":"code","7f92695f":"code","16e0c432":"code","9dad83fd":"code","ce296d48":"code","5b6e4cab":"code","f0685db6":"code","e9077aa7":"code","04b7b929":"code","c802dc81":"code","f99906a0":"code","795ba500":"code","034e9c39":"code","8b2b7ee5":"code","d55e3d81":"code","8b3d03eb":"code","e63a3ae0":"code","fe06cb72":"code","065e8146":"code","58c4525c":"code","59617b3e":"code","42f04715":"code","e26a761f":"code","4f4c7a81":"code","f24f7fd6":"code","1cf922f9":"code","eca928f1":"code","f53d6c1c":"code","d82feb1e":"code","a8c1ce88":"code","b78065ce":"code","aa8ffecf":"code","ad1b9c7a":"code","80286efa":"code","2bd9d9e8":"code","2c9038ff":"code","9bb80a61":"code","b8479605":"code","cc959fc8":"code","686764bb":"markdown","f680313f":"markdown","5e08da25":"markdown","c1dfb0ea":"markdown","baa5c0b1":"markdown","3ff8eb77":"markdown","53609c2b":"markdown","dba83f8f":"markdown","03cd9b5d":"markdown","8cac73bd":"markdown","20e0ff37":"markdown","3fc03a38":"markdown","7b77a61e":"markdown","dc069845":"markdown","e3a5bfdb":"markdown","302a4e58":"markdown"},"source":{"f1ab9611":"# importing libraries\nimport os, time, random, sys\nos.environ['PYTHONHASHSEED']=str(1)\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set_style('whitegrid')\nplt.style.use('seaborn-deep')\nplt.style.use('fivethirtyeight')\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.serif'] = 'Ubuntu'\nplt.rcParams['font.monospace'] = 'Ubuntu Mono'\nplt.rcParams['font.size'] = 10\nplt.rcParams['axes.labelsize'] = 12\nplt.rcParams['axes.titlesize'] = 12\nplt.rcParams['xtick.labelsize'] = 8\nplt.rcParams['ytick.labelsize'] = 8\nplt.rcParams['legend.fontsize'] = 12\nplt.rcParams['figure.titlesize'] = 14\nplt.rcParams['figure.figsize'] = (12, 8)\n\npd.options.mode.chained_assignment = None\npd.options.display.float_format = '{:.2f}'.format\npd.set_option('display.max_columns', 200)\npd.set_option('display.width', 400)\nimport warnings\nwarnings.filterwarnings('ignore')\nimport sklearn.metrics as skm\nimport sklearn.model_selection as skms\nimport sklearn.preprocessing as skp\nimport sklearn.utils as sku\nfrom skimage.io import imread\nfrom skimage.transform import resize\nseed = 12","e8a910f0":"import tensorflow as tf\nimport tensorflow_addons as tfa\nprint(\"TF version:-\", tf.__version__)\nimport keras as k\nfrom keras import backend as K","81091c4e":"def runSeed():\n    global seed\n    os.environ['PYTHONHASHSEED']=str(seed)\n    tf.random.set_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n\nrunSeed()\n\n## Checking the GPU configuration\n!nvidia-smi","7f1f6edc":"basePath = '\/kaggle\/input\/hackerearth-deep-learning-challenge-holidayseason\/dataset\/'\ntrainPath = basePath + 'train\/'\ndf_base = pd.read_csv('\/kaggle\/input\/hackerearth-deep-learning-challenge-holidayseason\/dataset\/train.csv')\ndf_base.head()","12ec2428":"print(\"Dataset has\",df_base.shape[0],\"samples\")\nprint(\"Count of samples\")\ndf_base['Class'].value_counts().reset_index()","19c7f746":"# def scanImgFeatures(path):\n#     features = []\n#     files = sorted(os.listdir(path))\n#     for x in files:\n#         fp = os.path.join(path, x)\n#         img = imread(fp)\/255.0\n#         features.append(img)\n#     return np.array(features), files\n\ndef showImage(img):\n    plt.figure(figsize=(4,4))\n    plt.imshow(img)\n    plt.show()\n\n# def getPathLabels(p):\n#     return [df_base[df_base['Image'] == x].iloc[0,1] for x in p]","f6d63304":"# train_data_img, train_files_img = scanImgFeatures(trainPath)\n# test_data_img, test_files_img = scanImgFeatures(testPath)\n# train_labels = getPathLabels(train_files_img)\n# showImage(test_data_img[0])","dbc885e5":"# shuffle samples\ndf_shuffle = df_base.sample(frac=1, random_state=seed).reset_index(drop=True)\n\n# remove irrelevant columns\ndf_shuffle.drop(['Image'], axis=1, inplace=True)\ndf_y = df_shuffle.pop('Class')\n\n# split into train dev and test\ny_train, y_valid = skms.train_test_split(df_y, train_size=0.9, random_state=seed, stratify=df_y)","4357f59d":"print(f\"Train set has {y_train.shape[0]} records out of {len(df_shuffle)} which is {round(y_train.shape[0]\/len(df_shuffle)*100)}%\")\nprint(f\"Test set has {y_valid.shape[0]} records out of {len(df_shuffle)} which is {round(y_valid.shape[0]\/len(df_shuffle)*100)}%\")","1b795574":"# stratified split check\nprint(y_train.value_counts())\nprint(y_valid.value_counts())","ff273d11":"# divide df_base to df_train and df_valid\ndf_train = df_base.iloc[y_train.index.tolist(), :].reset_index(drop=True)\nprint(\"Train data:\",df_train['Class'].value_counts())\n\ndf_valid = df_base.iloc[y_valid.index.tolist(), :].reset_index(drop=True)\nprint(\"Validation data:\",df_valid['Class'].value_counts())","1b081c68":"# constants\nbatch_size = 128\nimg_dim = 224\ndef getImgTensor(img_d):\n    return (img_d, img_d, 3)\ngetImgTensor(img_dim)","97f8426a":"# reading training and validation separately to prevent overlapping \n\ntrain_datagen = k.preprocessing.image.ImageDataGenerator(rescale=1.\/255, \n#                                                          shear_range=0.2, \n                                                         zoom_range=0.2, \n                                                         horizontal_flip=True, \n#                                                          width_shift_range=0.1, \n#                                                          height_shift_range=0.1\n                                                        )\n\ntrain_generator=train_datagen.flow_from_dataframe(dataframe=df_train,\n                                                  directory=trainPath,\n                                                  x_col=\"Image\",\n                                                  y_col=\"Class\",\n                                                  subset=\"training\",\n                                                  batch_size=batch_size,\n                                                  color_mode=\"rgb\",\n                                                  seed=seed,\n                                                  shuffle=True,\n                                                  class_mode=\"categorical\",\n                                                  target_size=getImgTensor(img_dim)[:2])","662b875d":"# generate class weights as classes are imbalanced\nclass_weights = sku.class_weight.compute_class_weight('balanced',\n                                                      np.unique(train_generator.classes), \n                                                      train_generator.classes)\ntrain_class_weights = {i:x for i, x in enumerate(class_weights)}\ntrain_class_weights","d966d2d7":"batch = train_generator.next()[0]\nshowImage(batch[0])\nshowImage(batch[1])","11439c97":"valid_datagen = k.preprocessing.image.ImageDataGenerator(rescale=1.\/255)\n\nvalid_generator=valid_datagen.flow_from_dataframe(dataframe=df_valid,\n                                                  directory=trainPath,\n                                                  x_col=\"Image\",\n                                                  y_col=\"Class\",\n                                                  subset=\"training\",\n                                                  batch_size=batch_size,\n                                                  color_mode=\"rgb\",\n                                                  seed=seed,\n                                                  shuffle=True,\n                                                  class_mode=\"categorical\",\n                                                  target_size=getImgTensor(img_dim)[:2])","527210c1":"test_datagen = k.preprocessing.image.ImageDataGenerator(rescale=1.\/255)\n\ntest_generator=test_datagen.flow_from_directory(basePath, \n                                                batch_size=1,\n                                                color_mode=\"rgb\",\n                                                seed=seed,\n                                                shuffle=False,\n                                                classes=['test'],\n                                                target_size=getImgTensor(img_dim)[:2])","a4879d04":"def plotModelHistory(h):\n    fig, ax = plt.subplots(1, 2, figsize=(15,4))\n    ax[0].plot(h.history['loss'])   \n    ax[0].plot(h.history['val_loss'])\n    ax[0].legend(['loss','val_loss'])\n    ax[0].title.set_text(\"Train loss vs Validation loss\")\n\n    ax[1].plot(h.history['categorical_accuracy'])   \n    ax[1].plot(h.history['val_categorical_accuracy'])\n    ax[1].legend(['categorical_accuracy','val_categorical_accuracy'])\n    ax[1].title.set_text(\"Train accuracy vs Validation accuracy\")\n\n    print(\"Max. Training Accuracy\", max(h.history['categorical_accuracy']))\n    print(\"Max. Validation Accuracy\", max(h.history['val_categorical_accuracy']))","76a2fd65":"class myCallback(k.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        ACCURACY_THRESHOLD = 0.98\n        if(logs.get('val_categorical_accuracy') > ACCURACY_THRESHOLD):\n            print(\"\\n\\nStopping training as we have reached %2.2f%% accuracy!\" %(ACCURACY_THRESHOLD*100))   \n            self.model.stop_training = True","7f92695f":"def trainModel(model, epochs, optimizer, vb=1, modelName='model'):\n    bestModelPath = '.\/'+modelName+'_model.hdf5'\n    callback = myCallback()\n    callbacks_list = [\n        callback,\n        k.callbacks.ReduceLROnPlateau(monitor = 'val_loss', patience = 5, verbose = 1, min_lr=0.00001), \n        k.callbacks.EarlyStopping(monitor = 'val_loss', patience = 15, verbose = 1, restore_best_weights = True), \n        k.callbacks.ModelCheckpoint(filepath=bestModelPath, monitor='val_loss', verbose=1, save_best_only=True)\n    ]\n    model.compile(optimizer=optimizer,\n                  loss='categorical_crossentropy',\n                  metrics=[k.metrics.CategoricalAccuracy(), k.metrics.Precision(), k.metrics.Recall()]\n    )\n    train_generator.reset()\n    if (train_generator.n%train_generator.batch_size) == 0:\n        steps_per_epoch = int(train_generator.n\/train_generator.batch_size)\n    else:\n        steps_per_epoch = (train_generator.n\/\/train_generator.batch_size) + 1\n\n    if (valid_generator.n%valid_generator.batch_size) == 0:\n        validation_steps = int(valid_generator.n\/valid_generator.batch_size)\n    else:\n        validation_steps = (valid_generator.n\/\/valid_generator.batch_size) + 1\n\n    return model.fit_generator(generator=train_generator, steps_per_epoch=steps_per_epoch, \n                               validation_data=valid_generator, validation_steps=validation_steps, \n                               epochs=epochs, verbose=vb, \n#                                class_weight=train_class_weights,\n                               callbacks=callbacks_list)","16e0c432":"# evaluate model with time\ndef evaluateModel(model, path=True):\n    batch_size = valid_generator.batch_size\n    num_train_sequences = valid_generator.n\n    valid_generator.reset()\n    steps_per_epoch = 0\n    if (valid_generator.n%valid_generator.batch_size) == 0:\n        steps_per_epoch = int(valid_generator.n\/valid_generator.batch_size)\n    else:\n        steps_per_epoch = int(valid_generator.n\/\/valid_generator.batch_size) + 1\n\n    t1 = time.time()\n    if path:\n        model = k.models.load_model(model)\n    eval_results = model.evaluate_generator(valid_generator, steps=steps_per_epoch)\n    t2 = time.time()\n    print(f'\\nLoss: {eval_results[0]}, Accuracy: {eval_results[1]}, Precision: {eval_results[2]}, Recall: {eval_results[3]}')\n    print(f'Prediction Time per Image: {(t2-t1)\/valid_generator.n}')","9dad83fd":"# predict images using model\ndef predictModel(modelPath):\n    batch_size = test_generator.batch_size\n    num_train_sequences = test_generator.n\n    steps_per_epoch = 0\n    if (test_generator.n%test_generator.batch_size) == 0:\n        steps_per_epoch = int(test_generator.n\/test_generator.batch_size)\n    else:\n        steps_per_epoch = int(test_generator.n\/\/test_generator.batch_size) + 1\n\n    test_generator.reset()\n\n    t1 = time.time()\n    model = k.models.load_model(modelPath)\n    predictions = model.predict_generator(test_generator, steps=steps_per_epoch, verbose=1)\n    t2 = time.time()\n    print(f'Prediction Time per Image: {(t2-t1)\/test_generator.n}')\n    \n    print(\"Generating Predictions file..\")    \n    labels = (train_generator.class_indices)\n    labels = dict((v,k) for k,v in labels.items())\n    predicted_class_indices=np.argmax(predictions, axis=1)\n    predictions_label = [labels[k] for k in predicted_class_indices]\n    filenames = list(map(lambda x: x.split('\/')[-1], test_generator.filenames))\n    submission=pd.DataFrame({\n        \"Image\":filenames, \n        \"Class\":predictions_label\n    })\n    submission_file = \"submission_\"+modelPath.split('\/')[-1].split('_')[0]+\".csv\"\n    submission.to_csv(submission_file,index=False)\n    print(f\"Submission file with {len(submission.values)} rows generated:\", submission_file)\n    submission.head()","ce296d48":"img_dim=224\nmobilenet = k.applications.MobileNetV2(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\nmobilenet.trainable = False\n\nmodel = k.models.Sequential([\n                             mobilenet,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.3),\n                             k.layers.Dense(256, activation='relu'),\n#                              k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.25),\n#                              k.layers.Dense(128, activation='relu'),\n#                              k.layers.BatchNormalization(),\n#                              k.layers.Dropout(0.25),\n                             k.layers.Dense(6, activation='softmax')\n])\nprint(model.summary())","5b6e4cab":"history_1 = trainModel(model, 50, 'adam', modelName='mobilenet')","f0685db6":"plotModelHistory(history_1)","e9077aa7":"img_dim=224\nresnet152 = k.applications.ResNet152V2(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\nresnet152.trainable = False\n\nmodel_2 = k.models.Sequential([\n                             resnet152,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.3),\n#                              k.layers.Dense(1024, activation='relu'),\n#                              k.layers.BatchNormalization(),\n#                              k.layers.Dropout(0.3),\n\n#                              k.layers.Dense(512, activation='relu'),\n#                              k.layers.BatchNormalization(),\n#                              k.layers.Dropout(0.3),\n\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.25),\n                             k.layers.Dense(6, activation='softmax')\n])\nprint(model_2.summary())","04b7b929":"history_2 = trainModel(model_2, 20, 'adam', modelName='resnet152')","c802dc81":"plotModelHistory(history_2)","f99906a0":"img_dim=224\ninceptionv3 = k.applications.InceptionV3(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\ninceptionv3.trainable = False\n\nmodel_3 = k.models.Sequential([\n                             inceptionv3,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.3),\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.25),\n#                              k.layers.Dense(128, activation='relu'),\n#                              k.layers.BatchNormalization(),\n#                              k.layers.Dropout(0.2),\n                             k.layers.Dense(6, activation='softmax')\n])\nprint(model_3.summary())","795ba500":"history_3 = trainModel(model_3, 50, 'adam', modelName='inceptionv3')","034e9c39":"plotModelHistory(history_3)","8b2b7ee5":"img_dim=331\nnasnet = k.applications.nasnet.NASNetLarge(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\nnasnet.trainable = False\n\nmodel_4 = k.models.Sequential([\n                             nasnet,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.3),\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.25),\n#                              k.layers.Dense(128, activation='relu'),\n#                              k.layers.BatchNormalization(),\n#                              k.layers.Dropout(0.2),\n                             k.layers.Dense(6, activation='softmax')\n])\nprint(model_4.summary())","d55e3d81":"history_4 = trainModel(model_4, 50, k.optimizers.Adam(1e-4), modelName='nasnet_large')","8b3d03eb":"plotModelHistory(history_4)","e63a3ae0":"img_dim=224\ninceptionresnet = k.applications.InceptionResNetV2(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\ninceptionresnet.trainable = False\n\nmodel_5 = k.models.Sequential([\n                             inceptionresnet,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.3),\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.25),\n#                              k.layers.Dense(128, activation='relu'),\n#                              k.layers.BatchNormalization(),\n#                              k.layers.Dropout(0.2),\n                             k.layers.Dense(6, activation='softmax')\n])\nprint(model_5.summary())","fe06cb72":"history_5 = trainModel(model_5, 50, k.optimizers.Adam(1e-4), modelName='inceptionresnet')","065e8146":"plotModelHistory(history_5)","58c4525c":"img_dim=224\ndensenet152 = k.applications.DenseNet169(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\ndensenet152.trainable = False\n\nmodel_6 = k.models.Sequential([\n                             densenet152,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.3),\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.25),\n#                              k.layers.Dense(128, activation='relu'),\n#                              k.layers.BatchNormalization(),\n#                              k.layers.Dropout(0.2),\n                             k.layers.Dense(6, activation='softmax')\n])\nprint(model_6.summary())","59617b3e":"history_6 = trainModel(model_6, 50, 'adam', modelName='densenet169')","42f04715":"plotModelHistory(history_6)","e26a761f":"img_dim=224\nmodel_7 = k.models.Sequential([\n                             k.layers.Conv2D(128, 3, activation='relu', input_shape=getImgTensor(img_dim)),\n                             k.layers.MaxPooling2D(2),\n\n                             k.layers.Conv2D(128, 3, activation='relu'),\n                             k.layers.MaxPooling2D(2),\n\n                             k.layers.Conv2D(128, 3, activation='relu'),\n                             k.layers.MaxPooling2D(2),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.3),\n    \n                             k.layers.Conv2D(256, 3, activation='relu'),\n                             k.layers.MaxPooling2D(2),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.3),\n\n                             k.layers.Conv2D(256, 3, activation='relu'),\n                             k.layers.MaxPooling2D(2),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.4),\n\n                             k.layers.Conv2D(256, 3, activation='relu'),\n                             k.layers.MaxPooling2D(2),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.3),\n    \n                             k.layers.Flatten(),\n\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.2),\n\n                             k.layers.Dense(128, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.2),\n\n                             k.layers.Dense(64, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.2),\n\n                             k.layers.Dense(6, activation='softmax')\n])\nprint(model_7.summary())","4f4c7a81":"history_7 = trainModel(model_7, 50, 'adam', modelName='custom')","f24f7fd6":"plotModelHistory(history_7)","1cf922f9":"# mobile net\nimg_dim=224\nevaluateModel('.\/mobilenet_model.hdf5')","eca928f1":"# resnet152\nimg_dim=224\nevaluateModel('.\/resnet152_model.hdf5')","f53d6c1c":"# inceptionv3\nimg_dim=224\nevaluateModel('.\/inceptionv3_model.hdf5')","d82feb1e":"# nasnet\nimg_dim=331\nevaluateModel('.\/nasnet_large_model.hdf5')\n# evaluateModel(model_4, False)","a8c1ce88":"# inceptionresnet\nimg_dim=224\nevaluateModel('.\/inceptionresnet_model.hdf5')","b78065ce":"# densenet169\nimg_dim=224\nevaluateModel('.\/densenet169_model.hdf5')","aa8ffecf":"# custom\nimg_dim=224\nevaluateModel('.\/custom_model.hdf5')","ad1b9c7a":"# mobile net\nimg_dim=224\npredictModel('.\/mobilenet_model.hdf5')","80286efa":"# resnet152\nimg_dim=224\npredictModel('.\/resnet152_model.hdf5')","2bd9d9e8":"# inceptionv3\nimg_dim=224\npredictModel('.\/inceptionv3_model.hdf5')","2c9038ff":"# nasnet\nimg_dim=331\npredictModel('.\/nasnet_large_model.hdf5')","9bb80a61":"# inceptionresnet\nimg_dim=224\npredictModel('.\/inceptionresnet_model.hdf5')","b8479605":"# densenet169\nimg_dim=224\npredictModel('.\/densenet169_model.hdf5')","cc959fc8":"# custom\nimg_dim=224\npredictModel('.\/custom_model.hdf5')","686764bb":"## Train NASNetLarge - Heavy Model","f680313f":"## Train MobileNetV2 - Light Model","5e08da25":"# Data Preparation\n","c1dfb0ea":"# Model Prediction","baa5c0b1":"# HackerEarth DL Challenge - Holiday Season\n\nYou work for a social media platform. Your task is to create a solution using deep learning to discern whether a post is holiday-related in an effort to better monetize the platform.\n\nClasses:-\n- Miscellaneous\n- Christmas_Tree\n- Jacket\n- Candle\n- Airplane\n- Snowman\n\n# Reading & Understanding Data\n## Importing Libraries","3ff8eb77":"## Train ResNet152 - Heavy Model","53609c2b":"## Split Train & Validation Sets","dba83f8f":"# Model Building","03cd9b5d":"# Model Evaluation","8cac73bd":"### Loading Dataset","20e0ff37":"### About the dataset","3fc03a38":"## Train InceptionV3 - Medium Model","7b77a61e":"## Train DenseNet169 - Light Model","dc069845":"## Setup Image Generator","e3a5bfdb":"## Custom Conv2D Model","302a4e58":"## Train InceptionResNetV2 - Heavy Model"}}