{"cell_type":{"e76aafcd":"code","f2cd7493":"code","b60cb0d5":"code","666c0c5a":"code","272035f0":"code","1a7b7ab4":"code","25a1bb3e":"code","5a133585":"code","ce4ea071":"code","6e37eb2b":"code","2663e178":"code","92b4645d":"code","a33b8eea":"code","cc7ab6cc":"code","e2eb2ec8":"code","2acab828":"code","397bd630":"code","a5b583b2":"code","8dd0f4de":"code","af677dc9":"code","8ed44be5":"code","6396d538":"code","57b2146f":"code","b7cc80e7":"code","45f1586e":"code","c9699e61":"code","83308dcb":"code","edb3b12d":"code","01ad8552":"code","05252ebb":"code","dd231816":"code","9cd42a21":"code","39b3c661":"code","cba71dc8":"code","35dd4ea6":"code","4be86f0b":"code","35d0b9bd":"code","1dea1474":"code","d7fe556d":"code","0467fe49":"code","891a8afc":"code","debb78c9":"code","8b97254e":"code","b16310e2":"code","ad219ad2":"code","e622bf9d":"code","8f0f840f":"code","ccfc7d57":"code","7bc0b041":"code","9b9c30d8":"code","f2d0e5d4":"code","508d9196":"code","60b4c160":"code","2ca3586c":"code","50c385cd":"code","69d2faee":"code","0c97d74b":"code","34f4d71f":"code","2a9e24a0":"code","239c17a1":"markdown"},"source":{"e76aafcd":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f2cd7493":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom pylab import rcParams\n# Definir tamanho padr\u00e3o para os gr\u00e1ficos\nrcParams['figure.figsize'] = 17, 4\n\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score","b60cb0d5":"# Carregando os datasets de treino e teste\ntrain = pd.read_csv('..\/input\/data-train-competicao-ml-1-titanic\/train.csv')\ntest = pd.read_csv('..\/input\/data-train-competicao-ml-1-titanic\/test.csv')\nidentificador = test['PassengerId']","666c0c5a":"## Join train and test datasets in order to obtain the same number of features during categorical conversion\ntrain_len = len(train) #guarda o tamanho do train para divis\u00e3o do dataset depois\ndataset =  pd.concat(objs=[train, test], axis=0).reset_index(drop=True)","272035f0":"# Analise dos datasets\nlen(train)","1a7b7ab4":"len(test)","25a1bb3e":"len(dataset)","5a133585":"# Fill empty and NaNs values with NaN\ndataset = dataset.fillna(np.nan)\n\n# Check for Null values\ndataset.isnull().sum()","ce4ea071":"# Infos\ndataset.info()","6e37eb2b":"dataset.head()","2663e178":"dataset.describe()","92b4645d":"# -----Analisando dados numericos-----\n# Correlation matrix between numerical values (SibSp Parch Age and Fare values) and Survived \ng = sns.heatmap(dataset[[\"Survived\",\"SibSp\",\"Parch\",\"Age\",\"Fare\"]].corr(), annot=True, fmt = \".2f\", cmap = \"coolwarm\")","a33b8eea":"# Explore SibSp feature vs Survived\ng = sns.catplot(x=\"SibSp\",y=\"Survived\",data=dataset,kind=\"bar\", height= 6 , palette = \"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","cc7ab6cc":"# Explore Parch feature vs Survived\ng  = sns.catplot(x=\"Parch\",y=\"Survived\",data=dataset,kind=\"bar\", height= 6, palette = \"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","e2eb2ec8":"# Explore Age vs Survived\ng = sns.FacetGrid(dataset, col='Survived')\ng = g.map(sns.distplot, \"Age\")","2acab828":"# Explore Age distribution \ng = sns.kdeplot(dataset[\"Age\"][(dataset[\"Survived\"] == 0) & (dataset[\"Age\"].notnull())], color=\"Red\", shade = True)\ng = sns.kdeplot(dataset[\"Age\"][(dataset[\"Survived\"] == 1) & (dataset[\"Age\"].notnull())], ax =g, color=\"Blue\", shade= True)\ng.set_xlabel(\"Age\")\ng.set_ylabel(\"Frequency\")\ng = g.legend([\"Not Survived\",\"Survived\"])","397bd630":"# -----Analisando dados categoricos-----\n# Explorar Sex vs Survived\ng = sns.barplot(x=\"Sex\",y=\"Survived\",data=dataset)\ng = g.set_ylabel(\"Survival Probability\")","a5b583b2":"dataset[[\"Sex\",\"Survived\"]].groupby('Sex').mean()","8dd0f4de":"# Explore Pclass vs Survived\ng = sns.catplot(x=\"Pclass\",y=\"Survived\",data=dataset,kind=\"bar\", height= 6 , palette = \"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","af677dc9":"# Explore Pclass vs Survived by Sex\ng = sns.catplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=dataset, height= 6, kind=\"bar\", palette=\"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","8ed44be5":"# Detectar valores nulos de embark\ndataset[\"Embarked\"].isnull().sum()","6396d538":"#Fill Embarked nan values of dataset set with 'S' most frequent value\ndataset[\"Embarked\"] = dataset[\"Embarked\"].fillna(\"S\")","57b2146f":"# Explore Embarked vs Survived \ng = sns.catplot(x=\"Embarked\", y=\"Survived\",  data=dataset, height= 6, kind=\"bar\", palette=\"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","b7cc80e7":"# Explore Pclass vs Embarked \ng = sns.catplot(\"Pclass\", col=\"Embarked\",  data=dataset, height=6, kind=\"count\", palette=\"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"Count\")","45f1586e":"#----- Preenchendo valores null -----\n# Explore Age vs Sex, Parch , Pclass and SibSP\ng = sns.catplot(y=\"Age\",x=\"Sex\",data=dataset,kind=\"box\")\ng = sns.catplot(y=\"Age\",x=\"Sex\",hue=\"Pclass\", data=dataset,kind=\"box\")\ng = sns.catplot(y=\"Age\",x=\"Parch\", data=dataset,kind=\"box\")\ng = sns.catplot(y=\"Age\",x=\"SibSp\", data=dataset,kind=\"box\")","c9699e61":"# convert Sex into categorical value 0 for male and 1 for female\ndataset[\"Sex\"] = dataset[\"Sex\"].map({\"male\": 0, \"female\":1})","83308dcb":"# correlation map pra saber qual das categorias usar pra determinar age\ng = sns.heatmap(dataset[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\"]].corr(),cmap=\"BrBG\",annot=True)","edb3b12d":"# Filling missing value of Age \n\n## Fill Age with the median age of similar rows according to Pclass, Parch and SibSp\n# Index of NaN age rows\nindex_NaN_age = list(dataset[\"Age\"][dataset[\"Age\"].isnull()].index)\n\nfor i in index_NaN_age :\n    age_med = dataset[\"Age\"].median()\n    age_pred = dataset[\"Age\"][((dataset['SibSp'] == dataset.iloc[i][\"SibSp\"]) & (dataset['Parch'] == dataset.iloc[i][\"Parch\"]) & (dataset['Pclass'] == dataset.iloc[i][\"Pclass\"]))].median()\n    if not np.isnan(age_pred) :\n        dataset['Age'].iloc[i] = age_pred\n    else :\n        dataset['Age'].iloc[i] = age_med","01ad8552":"# ----- Feature engineering -----\n# Gives the length of the name\ndataset['Name_length'] = dataset['Name'].apply(len)","05252ebb":"# Tamanho do nome vs survived \ng = sns.catplot(x=\"Survived\", y = \"Name_length\",data = dataset, kind=\"box\")","dd231816":"dataset[\"Name\"].head()","9cd42a21":"# Get Title from Name\ndataset_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in dataset[\"Name\"]]\ndataset[\"Title\"] = pd.Series(dataset_title)\ndataset[\"Title\"].head()","39b3c661":"g = sns.countplot(x=\"Title\",data=dataset)\ng = plt.setp(g.get_xticklabels(), rotation=45) ","cba71dc8":"# Convert to categorical values Title \ndataset[\"Title\"] = dataset[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ndataset[\"Title\"] = dataset[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\ndataset[\"Title\"] = dataset[\"Title\"].astype(int)","35dd4ea6":"g = sns.countplot(dataset[\"Title\"])\ng = g.set_xticklabels([\"Master\",\"Miss\/Ms\/Mme\/Mlle\/Mrs\",\"Mr\",\"Rare\"])","4be86f0b":"g = sns.catplot(x=\"Title\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_xticklabels([\"Master\",\"Miss-Mrs\",\"Mr\",\"Rare\"])\ng = g.set_ylabels(\"survival probability\")","35d0b9bd":"# Drop Name variable\ndataset.drop(labels = [\"Name\"], axis = 1, inplace = True)","1dea1474":"# Create a family size descriptor from SibSp and Parch\ndataset[\"Fsize\"] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1","d7fe556d":"g = sns.catplot(x=\"Fsize\",y=\"Survived\",data = dataset, kind = \"point\")\ng = g.set_ylabels(\"Survival Probability\")","0467fe49":"# Create new feature of family size\ndataset['Single'] = dataset['Fsize'].map(lambda s: 1 if s == 1 else 0)\ndataset['SmallF'] = dataset['Fsize'].map(lambda s: 1 if  s == 2  else 0)\ndataset['MedF'] = dataset['Fsize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ndataset['LargeF'] = dataset['Fsize'].map(lambda s: 1 if s >= 5 else 0)","891a8afc":"g = sns.catplot(x=\"Single\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_ylabels(\"Survival Probability\")\ng = sns.catplot(x=\"SmallF\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_ylabels(\"Survival Probability\")\ng = sns.catplot(x=\"MedF\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_ylabels(\"Survival Probability\")\ng = sns.catplot(x=\"LargeF\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_ylabels(\"Survival Probability\")","debb78c9":"# convert to indicator values Title and Embarked \ndataset = pd.get_dummies(dataset, columns = [\"Title\"])\ndataset = pd.get_dummies(dataset, columns = [\"Embarked\"], prefix=\"Em\")","8b97254e":"dataset.head()","b16310e2":"dataset[\"Cabin\"].head()","ad219ad2":"dataset[\"Cabin\"].describe()","e622bf9d":"dataset[\"Cabin\"].isnull().sum()","8f0f840f":"# Replace the Cabin number by the type of cabin 'X' if not\ndataset[\"Cabin\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in dataset['Cabin'] ])","ccfc7d57":"g = sns.countplot(dataset[\"Cabin\"],order=['A','B','C','D','E','F','G','T','X'])","7bc0b041":"g = sns.catplot(y=\"Survived\",x=\"Cabin\",data=dataset,kind=\"bar\",order=['A','B','C','D','E','F','G','T','X'])\ng = g.set_ylabels(\"Survival Probability\")","9b9c30d8":"dataset = pd.get_dummies(dataset, columns = [\"Cabin\"],prefix=\"Cabin\")","f2d0e5d4":"dataset[\"Ticket\"]","508d9196":"## Treat Ticket by extracting the ticket prefix. When there is no prefix it returns X. \n\nTicket = []\nfor i in list(dataset.Ticket):\n    if not i.isdigit() :\n        Ticket.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(' ')[0]) #Take prefix\n    else:\n        Ticket.append(\"X\")\n        \ndataset[\"Ticket\"] = Ticket\ndataset[\"Ticket\"].head()","60b4c160":"dataset = pd.get_dummies(dataset, columns = [\"Ticket\"], prefix=\"T\")","2ca3586c":"# Create categorical values for Pclass\ndataset[\"Pclass\"] = dataset[\"Pclass\"].astype(\"category\")\ndataset = pd.get_dummies(dataset, columns = [\"Pclass\"],prefix=\"Pc\")","50c385cd":"#----- Treinamento do modelo -----\ntreino = dataset[:train_len]\nteste = dataset[train_len:]\nteste.drop(labels=[\"Survived\"],axis = 1,inplace=True)\n\nskf = StratifiedKFold(n_splits=5, random_state=420, shuffle=True)\nX = treino.drop('Survived', axis=1).values\ny = treino['Survived'].values\nmedia_treino =[]\nmedia_teste = []\nmedia_validacao =[]","69d2faee":"contador = 1\nfor indice_treino, indice_validacao in skf.split(X,y):    \n    X_treino = X[indice_treino]\n    y_treino = y[indice_treino]    \n    X_validacao = X[indice_validacao]\n    y_validacao = y[indice_validacao]\n    modelo = GradientBoostingClassifier(random_state=420)\n    modelo.fit(X_treino, y_treino)\n    \n    y_pred = modelo.predict_proba(X_treino)\n    y_pred = y_pred[:,1]\n    score_treino = roc_auc_score(y_treino, y_pred)  \n    print(\"Treino n\u00famero {} : {}\".format(contador, score_treino))\n\n    y_validacao_pred = modelo.predict_proba(X_validacao)\n    y_validacao_pred = y_validacao_pred[:,1]\n    score_validacao = roc_auc_score(y_validacao, y_validacao_pred)\n    print(\"Validacao n\u00famero {} : {} \\n\".format(contador, score_validacao))\n\n    contador += 1\n\n    X_teste = teste\n    y_pred_teste = modelo.predict_proba(X_teste)\n    y_pred_teste = y_pred_teste[:, 1]  \n\n    media_treino.append(score_treino)  \n    media_validacao.append(score_validacao)\n    media_teste.append(y_pred_teste)\n\nprint(\"Media de todos treinos {}:\".format(np.mean(media_treino)))\nprint(\"Media de todas valida\u00e7\u00f5es {}:\".format(np.mean(media_validacao)))","0c97d74b":"mediafinal_pred = np.mean(media_teste, axis=0)","34f4d71f":"resultado = pd.concat([identificador, pd.DataFrame(mediafinal_pred, columns=['Survived'])], axis=1)\nresultado","2a9e24a0":"# gerando arquivos para submiss\u00e3o na competi\u00e7\u00e3o\nresultado.to_csv('submission.csv', index=False)","239c17a1":"Refer\u00eancia principal\nhttps:\/\/www.kaggle.com\/yassineghouzam\/titanic-top-4-with-ensemble-modeling"}}