{"cell_type":{"c438a818":"code","7f8b992a":"code","eacbb0fb":"code","96024bf8":"code","99fdf0df":"code","4e52a8dd":"code","30915d1e":"code","a74c3026":"code","48f4e8d7":"code","b44452cc":"code","b3c08fe4":"code","5d0e0252":"code","80999aca":"code","979be3f8":"code","e0015782":"code","ef9d0353":"code","2315126e":"code","8df5e5fd":"code","843210ba":"code","76b71b7e":"code","8321ddff":"code","91f5804d":"code","e03aa15e":"code","2d857973":"code","35f1c0fb":"code","e9d09b1e":"code","ed65f2b3":"code","be6af680":"code","8309a0e1":"code","4f9af7cd":"code","4bfb173a":"code","8e875836":"code","9809b0ca":"code","0003803c":"code","d944bfe8":"code","7964ec2a":"code","0ea3f5d8":"code","39510847":"code","fae665d8":"code","f0e5c30e":"code","82f5db1b":"code","702cafed":"markdown","f493f7d2":"markdown","d42c75f5":"markdown","12fc318c":"markdown","21675211":"markdown","84d6877a":"markdown","51aedacd":"markdown","6aff42f4":"markdown","45a6d9c1":"markdown","82b3c277":"markdown","963a5985":"markdown"},"source":{"c438a818":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf","7f8b992a":"data = pd.read_csv('..\/input\/age-gender-and-ethnicity-face-data-csv\/age_gender.csv')","eacbb0fb":"data","96024bf8":"data.isnull().sum()","99fdf0df":"data = data.drop('img_name', axis=1)","4e52a8dd":"{column: list(data[column].unique()) for column in ['gender', 'ethnicity', 'age']}","30915d1e":"data['age'] = pd.qcut(data['age'], q=4, labels=[0, 1, 2, 3])","a74c3026":"data","48f4e8d7":"print(len(data['pixels'][0].split(' ')))\nprint(np.sqrt(2304))","b44452cc":"num_pixels = 2304\nimg_height = 48\nimg_width = 48","b3c08fe4":"target_columns = ['gender', 'ethnicity', 'age']\n\ny = data[target_columns]\nX = data.drop(target_columns, axis=1)","5d0e0252":"y","80999aca":"X","979be3f8":"X = pd.Series(X['pixels'])\nX = X.apply(lambda x: x.split(' ')) # Get array of pixels\nX = X.apply(lambda x: np.array(list(map(lambda z: np.int(z), x)))) # Turn all pixels into type int\nX = np.array(X) # Make array a numpy array \nX = np.stack(np.array(X), axis=0) # Rearange the numpy arrays from many small arrays to fewer I think. \n                                  # Ex.: [array([1,4,2 ..., 7]), array([...]),] => [[[1,4,2 ..., 7], [...]]]\nX = np.reshape(X, (-1, 48, 48)) # Reshape the array to same amounts of columns (images), but each image should be 48x48 because of image size\nX.shape # (length, 48, 48)","e0015782":"plt.figure(figsize=(10, 10))\n\nfor index, image in enumerate(np.random.randint(2000, 3000, 9)):\n    plt.subplot(3, 3, index + 1)\n    plt.imshow(X[image])\n#     plt.axis('off')\n    plt.xlabel(\n        \"Age:\"+str(y['age'].iloc[index])+\n        \"  Ethnicity:\"+str(y['ethnicity'].iloc[index])+\n        \"  Gender:\"+ str(y['gender'].iloc[index])\n    )\n\nplt.show()","ef9d0353":"y","2315126e":"y_gender = np.array(y['gender'])\ny_ethnicity = np.array(y['ethnicity'])\ny_age = np.array(y['age'])","8df5e5fd":"X.shape","843210ba":"def build_model(num_classes, activation='softmax', loss='sparse_categorical_crossentropy'):\n    \n    inputs = tf.keras.Input(shape=(img_height, img_width, 1))\n    x = tf.keras.layers.experimental.preprocessing.Rescaling(1.\/255)(inputs)\n    x = tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu')(x)\n    x = tf.keras.layers.MaxPooling2D()(x)\n    x = tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n    x = tf.keras.layers.MaxPooling2D()(x)\n    x = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n    x = tf.keras.layers.MaxPooling2D()(x)\n    x = tf.keras.layers.Flatten()(x)\n    x = tf.keras.layers.Dense(128, activation='relu')(x)\n    outputs = tf.keras.layers.Dense(num_classes, activation=activation)(x)\n    \n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n    \n    \n    model.compile(\n        optimizer='adam',\n        loss=loss,\n        metrics=['accuracy']\n    )\n    \n    return model","76b71b7e":"{column: list(data[column].unique()) for column in ['gender', 'ethnicity', 'age']}","8321ddff":"X_gender_train, X_gender_test, y_gender_train, y_gender_test = train_test_split(X, y_gender, train_size=0.7)\nX_ethnicity_train, X_ethnicity_test, y_ethnicity_train, y_ethnicity_test = train_test_split(X, y_ethnicity, train_size=0.7)\nX_age_train, X_age_test, y_age_train, y_age_test = train_test_split(X, y_age, train_size=0.7)","91f5804d":"gender_model = build_model(1, activation='sigmoid', loss='binary_crossentropy')\n\ngender_history = gender_model.fit(\n    X_gender_train,\n    y_gender_train,\n    validation_split=0.2,\n    batch_size=64,\n    epochs=7,\n    callbacks=[tf.keras.callbacks.ReduceLROnPlateau()],\n    verbose=0\n)","e03aa15e":"fig = px.line(\n    gender_history.history,\n    y=['loss', 'val_loss'],\n    labels={'index': \"Epoch\", 'value': \"Loss\"},\n    title=\"Gender Model\"\n)\n\nfig.show()","2d857973":"gender_acc = gender_model.evaluate(X_gender_test, y_gender_test)[1]","35f1c0fb":"import os","e9d09b1e":"# Using Keras ImageDataGenerator function. And divide all pixels in image by 255\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,\n)\ndatagen","ed65f2b3":"# Create a \"validation generator\", which we will later pass to the gender_model\nimage_generator = datagen.flow_from_directory(\n    '\/kaggle\/input\/images\/', # Using the working directory, which will create classes from all subfolders (i.e. MALE and FEMALE), and assign the respective classes to each image\n    target_size=(48, 48), # Make image 48x48 pixels\n    class_mode='binary', # Binary because the model outputs 1D binary labels,\n    color_mode='grayscale'\n)","be6af680":"new_X, new_y = image_generator.next() # .next() allows us to grab the image batch (of size 4 in this case) and store the image data in new_X and the labels in new_y","8309a0e1":"print(new_X.shape)\nprint(new_y)","4f9af7cd":"gender_lookup = ['FEMALE', 'MALE']\nimage_generator.class_indices # We can get the class labels that have been assigned to each name via .class_indices","4bfb173a":"# Display the images\nplt.figure(figsize=(10, 10))\nfor i in range(len(new_X)):\n    plt.subplot(2, 2, i + 1)\n    plt.xlabel(f\"Gender: {gender_lookup[int(new_y[i])]}\")\n    plt.imshow(np.squeeze(new_X[i]))\nplt.show()","8e875836":"# Get size of images\nnew_X.shape","9809b0ca":"# Perfrom actual prediction\ngender_model.predict(new_X) # The model predicts female for every image","0003803c":"# Evaluate model\ngender_model.evaluate(new_X, new_y) # Which yields a 50% accuracy","d944bfe8":"# ethnicity_model = build_model(5, activation='softmax', loss='sparse_categorical_crossentropy')\n\n# ethnicity_history = ethnicity_model.fit(\n#     X_ethnicity_train,\n#     y_ethnicity_train,\n#     validation_split=0.2,\n#     batch_size=64,\n#     epochs=8,\n#     callbacks=[tf.keras.callbacks.ReduceLROnPlateau()],\n#     verbose=0\n# )","7964ec2a":"# fig = px.line(\n#     ethnicity_history.history,\n#     y=['loss', 'val_loss'],\n#     labels={'index': \"Epoch\", 'value': \"Loss\"},\n#     title=\"Ethnicity Model\"\n# )\n\n# fig.show()","0ea3f5d8":"# ethnicity_acc = ethnicity_model.evaluate(X_ethnicity_test, y_ethnicity_test)[1]","39510847":"# age_model = build_model(4, activation='softmax', loss='sparse_categorical_crossentropy')\n\n# age_history = age_model.fit(\n#     X_age_train,\n#     y_age_train,\n#     validation_split=0.2,\n#     batch_size=64,\n#     epochs=7,\n#     callbacks=[tf.keras.callbacks.ReduceLROnPlateau()],\n#     verbose=0\n# )","fae665d8":"# fig = px.line(\n#     age_history.history,\n#     y=['loss', 'val_loss'],\n#     labels={'index': \"Epoch\", 'value': \"Loss\"},\n#     title=\"Age Model\"\n# )\n\n# fig.show()","f0e5c30e":"# age_acc = age_model.evaluate(X_age_test, y_age_test)[1]","82f5db1b":"# fig = px.bar(\n#     x=[\"Gender\", \"Ethnicity\", \"Age\"],\n#     y=[gender_acc, ethnicity_acc, age_acc],\n#     labels={'x': \"\", 'y': \"Accuracy\"},\n#     color=[\"Gender\", \"Ethnicity\", \"Age\"],\n#     title=\"Model Performance\"\n# )\n\n# fig.show()","702cafed":"# Big thanks to Gabriel Atkin!\n\nThis notebook is basicly his work. Check out his youtube channel here: https:\/\/www.youtube.com\/channel\/UCbKLhYeFDAhRh43D-0CehsA\n***\n\nAnd watch a video about this exact dataset here:\nhttps:\/\/youtu.be\/JuX3Rk7j554","f493f7d2":"## Ethnicity Model","d42c75f5":"# Preprocessing","12fc318c":"# Visualization","21675211":"# Training","84d6877a":"### Test model with own images (Predict)","51aedacd":"# Getting Started","6aff42f4":"## Gender Model","45a6d9c1":"## Age Model","82b3c277":"# Task for Today  \n***\n## Gender, Ethnicity, and Age Classification  \n\nGiven the face image data, let's see if we can correctly classify the **gender**, **ethnicity**, and **age** of a person.  \n  \nWe will use three different TensorFlow CNNs to make our predictions.","963a5985":"# Results"}}