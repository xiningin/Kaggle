{"cell_type":{"1663fb8e":"code","78228d71":"code","538d4d02":"code","53b0cd1f":"code","95e8798e":"code","119b2a90":"code","3ba94bef":"code","8042e441":"code","273923b6":"code","d7e0e526":"code","5541a19d":"code","6ddb2784":"code","1a1a89f2":"code","61a66776":"code","e32e8ccf":"code","67e2ef3d":"code","f99c9e8c":"code","d7810ea8":"code","3348615d":"code","4988f108":"code","a2a67820":"code","a09afb41":"code","dbe2d835":"code","db938b1e":"code","fa63c068":"code","a707e3f2":"code","db967d5d":"code","8e9d89dc":"code","a633054d":"code","2a9c6976":"code","1326693e":"code","b37d5bf3":"code","9e946c36":"code","150773c4":"code","332ddf3d":"code","887bf573":"code","1ca312e4":"code","47eb9ea7":"code","a0ff13e7":"code","2875c031":"code","14259b0e":"code","47ae18a9":"code","fde9f991":"code","260f7794":"code","2870ecb2":"code","824ffd57":"code","8d54e201":"code","c10b9826":"code","e602dc81":"code","7c50836b":"code","df7cf9b6":"code","f79c179b":"code","c2703c72":"code","9e04966d":"code","766d4aa8":"code","67f274cc":"code","af7ea6a8":"code","17c43dd1":"code","d2e62330":"code","4e4ae0d0":"code","68fd2370":"code","cff0ef92":"code","6cccc028":"code","e1461494":"code","45f6ac5f":"code","427a2372":"code","4f2a97e0":"code","7094546c":"code","0a7177e2":"code","f0289b34":"code","207043e9":"code","67af707a":"code","342109c4":"code","5f21961a":"code","e1465a29":"code","079e922d":"code","265bcbf9":"code","b279f650":"code","06c34a9a":"code","2876a1d4":"code","a40a40ac":"code","cd598bea":"code","f41c7aa5":"code","94da7a64":"code","b49a0dc9":"code","e7be0f42":"code","54dae318":"code","1f5f3609":"code","98dde129":"code","2dedc2f2":"code","5a624069":"code","d2a984b8":"code","ad4403c7":"code","38d373dc":"markdown","0fcdf202":"markdown","00345ab8":"markdown","ff2421ab":"markdown","63f9a5b1":"markdown","740ca224":"markdown","96b550ca":"markdown","89072c1f":"markdown","44d364f3":"markdown","5e1e194d":"markdown","d63dcd0f":"markdown","3f57eb51":"markdown"},"source":{"1663fb8e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","78228d71":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.manifold import TSNE\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom datetime import datetime\nimport random\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import KFold, GridSearchCV\nfrom sklearn.metrics import r2_score as r2","538d4d02":"TRAIN_DATASET_PATH = '\/input\/real-estate-price-prediction-moscow\/train.csv'\nTEST_DATASET_PATH = '\/input\/real-estate-price-prediction-moscow\/test.csv'\nSUBMIT_DATASET_PATH = '\/input\/real-estate-price-prediction-moscow\/sample_submission.csv'","53b0cd1f":"train_data = pd.read_csv(TRAIN_DATASET_PATH)\ntest_df = pd.read_csv(TEST_DATASET_PATH)\nsubmit = pd.read_csv(SUBMIT_DATASET_PATH)","95e8798e":"def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):\n    print(\"Train R2:\\t\" + str(round(r2(train_true_values, train_pred_values), 3)))\n    print(\"Test R2:\\t\" + str(round(r2(test_true_values, test_pred_values), 3)))\n    \n    plt.figure(figsize=(18,10))\n    \n    plt.subplot(121)\n    sns.scatterplot(x=train_pred_values, y=train_true_values)\n    plt.xlabel('Predicted values')\n    plt.ylabel('True values')\n    plt.title('Train sample prediction')\n    \n    plt.subplot(122)\n    sns.scatterplot(x=test_pred_values, y=test_true_values)\n    plt.xlabel('Predicted values')\n    plt.ylabel('True values')\n    plt.title('Test sample prediction')\n\n    plt.show()","119b2a90":"plt.scatter(train_data['Square'], train_data['Price'])","3ba94bef":"%matplotlib inline","8042e441":"plt.figure(figsize = (16, 8))\ntrain_data['Price'].hist()","273923b6":"target = train_data['Price']","d7e0e526":"target.mean()","5541a19d":"target.median()","6ddb2784":"target_bins = target \/\/ 10000 * 10000","1a1a89f2":"target_bins.mode()","61a66776":"plt.figure(figsize = (16, 8))\n\nsns.distplot(target, bins=50)\nplt.title('Distribution of price')\n\ny = np.linspace(0, 0.000005, 10)\nplt.plot([target.mean()] * 10, y, label='mean', linestyle=':', linewidth=4)\nplt.plot([target.median()] * 10, y, label='median', linestyle='--', linewidth=4)\nplt.plot([target_bins.mode()] * 10, y, label='mode', linestyle='-.', linewidth=4)\n\nplt.legend()","e32e8ccf":"target_bins.value_counts().iloc[:10]","67e2ef3d":"train_data_num_features = train_data.select_dtypes(include=['float64', 'float32', 'float16'])\ntrain_data_num_features.drop('Price', axis=1, inplace=True)","f99c9e8c":"train_data_num_features.hist(figsize=(16,16), bins=20, grid=False)","d7810ea8":"train_data.sort_values(by ='Square' ).tail(30)","3348615d":"train_data.loc[(train_data['Square'] < 10)|(train_data['Square'] > 300), 'Square']  = train_data['Square'].median()","4988f108":"train_data['Square'].median()","a2a67820":"train_data['Square'].sort_values()","a09afb41":"lr = LinearRegression()","dbe2d835":"x_train = train_data['Square']\nx_train = np.array(x_train).reshape(-1, 1)\n","db938b1e":"y_train = train_data['KitchenSquare']\ny_train.describe()","fa63c068":"lr.fit(x_train, y_train)","a707e3f2":"pred = lr.predict(np.array(train_data['Square']).reshape(-1,1))","db967d5d":"pred","8e9d89dc":"train_data['KitchenSquare_estm'] = pred","a633054d":"train_data.loc[ (train_data['KitchenSquare'] > train_data['Square']\/2) | (train_data['KitchenSquare'] < 4), 'KitchenSquare'] = \\\ntrain_data.loc[ (train_data['KitchenSquare'] > train_data['Square']\/2) | (train_data['KitchenSquare'] < 4), 'KitchenSquare_estm']\ntrain_data","2a9c6976":"train_data.loc[ train_data['LifeSquare'] <10]","1326693e":"lsq_data = train_data.loc[ train_data['LifeSquare'].notna()] # \u0432\u044b\u0434\u0435\u043b\u044f\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043a\u0438 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438\nlsq_x_train = np.array(lsq_data['Square']).reshape(-1,1) \nlsq_y_train = lsq_data['LifeSquare']\nlr_lsq = LinearRegression()\nlr_lsq.fit(lsq_x_train, lsq_y_train)\nls_na = train_data.loc[ train_data['LifeSquare'].isna()]\nls_test = np.array(train_data['Square']).reshape(-1,1)\nls_pred = lr_lsq.predict(ls_test)\nlsna_series = pd.DataFrame(ls_pred, columns = ['LifeSquare'])\ntrain_data.loc[(train_data['LifeSquare'].isna()) | (train_data['LifeSquare'] <10) | (train_data['LifeSquare'] > train_data['Square'] \/ 1.2)  , 'LifeSquare' ] = lsna_series","b37d5bf3":"lsq_x_train = np.array(lsq_data['Square']).reshape(-1,1) ","9e946c36":"lsq_y_train = lsq_data['LifeSquare']","150773c4":"lr_lsq = LinearRegression()","332ddf3d":"lr_lsq.fit(lsq_x_train, lsq_y_train)","887bf573":"ls_na = train_data.loc[ train_data['LifeSquare'].isna()] # \u0432\u044b\u0434\u0435\u043b\u044f\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435, \u0433\u0434\u0435 \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u0435\u0442 LifeSquare","1ca312e4":"ls_test = np.array(train_data['Square']).reshape(-1,1) # \u0433\u043e\u0442\u043e\u0432\u0438\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438","47eb9ea7":"ls_pred = lr_lsq.predict(ls_test) #\u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044f \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442 \u0434\u0430\u043d\u043d\u044b\u0435 LifeSquare","a0ff13e7":"ls_pred # \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f LifeSquare \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u0435 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0435\u0439","2875c031":"lsna_series = pd.DataFrame(ls_pred, columns = ['LifeSquare'])","14259b0e":"train_data.loc[(train_data['LifeSquare'].isna()) | (train_data['LifeSquare'] <10) | (train_data['LifeSquare'] > train_data['Square'] \/ 1.2)  , 'LifeSquare' ] = lsna_series","47ae18a9":"train_data.describe()","fde9f991":"train_data.loc[(train_data['Rooms'] == 0) | (train_data['Rooms'] > 10), 'Rooms'] = train_data['Rooms'].mean()","260f7794":"train_data['HouseFloor'].sort_values().unique()","2870ecb2":"train_data['Floor'].sort_values().unique()","824ffd57":"train_data['HouseFloor_outlier'] = 0\ntrain_data.loc[train_data['HouseFloor'] == 0, 'HouseFloor_outlier'] = 1\ntrain_data.loc[train_data['Floor'] > train_data['HouseFloor'], 'HouseFloor_outlier'] = 1\ntrain_data.loc[train_data['Floor'] == 0 , 'HouseFloor_outlier'] = 1\nfloor_outliers = train_data.loc[train_data['Floor'] > train_data['HouseFloor'] ].index\ntrain_data.loc[train_data['Floor'] == 0 , 'HouseFloor_outlier'] = 1\ntrain_data.loc[train_data['Floor'] > train_data['HouseFloor'], 'Floor' ] = train_data.loc[train_data['Floor']\\\n    > train_data['HouseFloor'], 'HouseFloor' ]\ntrain_data.loc[train_data['HouseFloor'] > 80, 'HouseFloor' ] = 9\ntrain_data.loc[train_data['HouseYear'] > 2020, 'HouseYear'] = 2020","8d54e201":"train_data.loc[train_data['Floor'] == 0 , 'Floor'] = 1","c10b9826":"train_data.loc[train_data['Floor'] > train_data['HouseFloor'], 'Floor' ] = train_data.loc[train_data['Floor']\\\n    > train_data['HouseFloor'], 'HouseFloor' ]","e602dc81":"train_data.loc[train_data['Floor'] > train_data['HouseFloor']]","7c50836b":"train_data.describe()","df7cf9b6":"train_data.loc[train_data['HouseFloor'] > 80, 'HouseFloor' ] = 9","f79c179b":"train_data.loc[train_data['HouseYear'] > 2020, 'HouseYear'] = 2020","c2703c72":"train_data['HouseYear'].min()","9e04966d":"train_data.drop('Healthcare_1', axis=1, inplace=True)","766d4aa8":"class DataPreprocessing:\n    \"\"\"\u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0438\u0441\u0445\u043e\u0434\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\"\"\"\n\n    def __init__(self):\n        \"\"\"\u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u043a\u043b\u0430\u0441\u0441\u0430\"\"\"\n        self.medians=None\n        self.kitchen_square_quantile = None\n        \n    def fit(self, X):\n        \"\"\"\u0421\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u043a\"\"\"       \n        # \u0420\u0430\u0441\u0447\u0435\u0442 \u043c\u0435\u0434\u0438\u0430\u043d\n        self.medians = X.median()\n\n    \n    def transform(self, X):\n        \"\"\"\u0422\u0440\u0430\u043d\u0441\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445\"\"\"\n\n        # Rooms\n        X['Rooms_outlier'] = 0\n        X.loc[(X['Rooms'] == 0) | (X['Rooms'] >= 6), 'Rooms_outlier'] = 1\n        \n        X.loc[X['Rooms'] == 0, 'Rooms'] = 1\n        X.loc[X['Rooms'] >= 6, 'Rooms'] = self.medians['Rooms']\n        \n        # KitchenSquare\n        \n        x_train = X['Square']\n        x_train = np.array(x_train).reshape(-1, 1)\n        y_train = X['KitchenSquare']\n        y_train.describe()\n        lr = LinearRegression()\n        lr.fit(x_train, y_train)\n        pred = lr.predict(np.array(X['Square']).reshape(-1,1))\n        X['KitchenSquare_estm'] = pred\n        X.loc[ (X['KitchenSquare'] > X['Square']\/2) | (X['KitchenSquare'] < 4), 'KitchenSquare'] = X.loc[ (X['KitchenSquare'] > X['Square']\/2) | (X['KitchenSquare'] < 4), 'KitchenSquare_estm']\n        \n        # HouseFloor, Floor\n        X['HouseFloor_outlier'] = 0\n        X.loc[X['HouseFloor'] == 0, 'HouseFloor_outlier'] = 1\n        X.loc[X['Floor'] > X['HouseFloor'], 'HouseFloor_outlier'] = 1\n        X.loc[X['Floor'] == 0 , 'HouseFloor_outlier'] = 1\n        floor_outliers = X.loc[X['Floor'] > X['HouseFloor'] ].index\n        X.loc[X['Floor'] == 0,'Floor' ] = 1\n        train_data.loc[train_data['Floor'] > train_data['HouseFloor'], 'Floor' ] = train_data.loc[train_data['Floor']\\\n    > train_data['HouseFloor'], 'HouseFloor' ]\n        X.loc[X['HouseFloor'] > 80, 'HouseFloor' ] = 9\n        \n\n        \n        # HouseYear\n        current_year = datetime.now().year\n        \n        X['HouseYear_outlier'] = 0\n        X.loc[X['HouseYear'] > current_year, 'HouseYear_outlier'] = 1\n        \n        X.loc[X['HouseYear'] > current_year, 'HouseYear'] = current_year\n        \n        # Healthcare_1\n        if 'Healthcare_1' in X.columns:\n            X.drop('Healthcare_1', axis=1, inplace=True)\n            \n        # LifeSquare\n        lsq_data = X.loc[ X['LifeSquare'].notna()] # \u0432\u044b\u0434\u0435\u043b\u044f\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043a\u0438 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438\n        lsq_x_train = np.array(lsq_data['Square']).reshape(-1,1) \n        lsq_y_train = lsq_data['LifeSquare']\n        lr_lsq = LinearRegression()\n        lr_lsq.fit(lsq_x_train, lsq_y_train)\n        ls_na = X.loc[ X['LifeSquare'].isna()]\n        ls_test = np.array(X['Square']).reshape(-1,1)\n        ls_pred = lr_lsq.predict(ls_test)\n        lsna_series = pd.DataFrame(ls_pred, columns = ['LifeSquare'])\n        X.loc[(X['LifeSquare'].isna()) | (X['LifeSquare'] <10) | (X['LifeSquare'] > X['Square'] \/ 1.2)  , 'LifeSquare' ] = lsna_series\n        \n        return X","67f274cc":"binary_to_numbers = {'A': 0, 'B': 1}\n\ntrain_data['Ecology_2'] = train_data['Ecology_2'].replace(binary_to_numbers)\ntrain_data['Ecology_3'] = train_data['Ecology_3'].replace(binary_to_numbers)\ntrain_data['Shops_2'] = train_data['Shops_2'].replace(binary_to_numbers)","af7ea6a8":"district_size = train_data['DistrictId'].value_counts().reset_index()\\\n                    .rename(columns={'index':'DistrictId', 'DistrictId':'DistrictSize'})\n\ndistrict_size","17c43dd1":"train_data = train_data.merge(district_size, on='DistrictId', how='left') # \u043c\u0435\u0440\u0434\u0436\u0438\u043c \u0440\u0430\u0437\u043c\u0435\u0440 \u0440\u0430\u0439\u043e\u043d\u0430\ntrain_data.head()","d2e62330":"train_data['IsDistrictLarge'] = (train_data['DistrictSize'] > 100).astype(int)","4e4ae0d0":"bins = [0, 3, 5, 9, 15, train_data['Floor'].max()]\npd.cut(train_data['Floor'], bins=bins, labels=False)","68fd2370":"class FeatureGenetator():\n    \"\"\"\u0413\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u044f \u043d\u043e\u0432\u044b\u0445 \u0444\u0438\u0447\"\"\"\n    \n    def __init__(self):\n        self.DistrictId_counts = None\n        self.binary_to_numbers = None\n        self.med_price_by_district = None\n        self.med_price_by_floor_year = None\n        self.house_year_max = None\n        self.floor_max = None\n        \n    def fit(self, X, y=None):\n        \n        X = X.copy()\n        \n        # Binary features\n        self.binary_to_numbers = {'A': 0, 'B': 1}\n        \n        # DistrictID\n        self.district_size = X['DistrictId'].value_counts().reset_index() \\\n                               .rename(columns={'index':'DistrictId', 'DistrictId':'DistrictSize'})\n                \n        # Target encoding\n        ## District, Rooms\n        df = X.copy()\n        \n        if y is not None:\n            df['Price'] = y.values\n            \n            self.med_price_by_district = df.groupby(['DistrictId', 'Rooms'], as_index=False).agg({'Price':'median'})\\\n                                            .rename(columns={'Price':'MedPriceByDistrict'})\n            \n            self.med_price_by_district_median = self.med_price_by_district['MedPriceByDistrict'].median()\n            \n            \n            df['PricePerSq'] = df['Price'] \/ df['Square']\n            self.med_price_sq_by_district_x = df.groupby(['DistrictId'], as_index=False).agg({'PricePerSq':'mean'})\\\n                            .rename(columns={'PricePerSq':'MedPriceSqByDistrict_x'})\n            self.med_price_sq_by_district_y = df.groupby(['DistrictId'], as_index=False).agg({'PricePerSq':'median'})\\\n                            .rename(columns={'PricePerSq':'MedPriceSqByDistrict_y'})\n            \n            \n            \n        ## floor, year\n        if y is not None:\n            self.floor_max = df['Floor'].max()\n            self.house_year_max = df['HouseYear'].max()\n            df['Price'] = y.values\n            df = self.floor_to_cat(df)\n            df = self.year_to_cat(df)\n            self.med_price_by_floor_year = df.groupby(['year_cat', 'floor_cat'], as_index=False).agg({'Price':'median'}).\\\n                                            rename(columns={'Price':'MedPriceByFloorYear'})\n            self.med_price_by_floor_year_median = self.med_price_by_floor_year['MedPriceByFloorYear'].median()\n            \n            \n        \n    def transform(self, X):\n        \n        # Binary features\n        X['Ecology_2'] = X['Ecology_2'].map(self.binary_to_numbers)  # self.binary_to_numbers = {'A': 0, 'B': 1}\n        X['Ecology_3'] = X['Ecology_3'].map(self.binary_to_numbers)\n        X['Shops_2'] = X['Shops_2'].map(self.binary_to_numbers)\n        \n        # DistrictId, IsDistrictLarge\n        X = X.merge(self.district_size, on='DistrictId', how='left')\n        \n        X['new_district'] = 0\n        X.loc[X['DistrictSize'].isna(), 'new_district'] = 1\n        \n        X['DistrictSize'].fillna(5, inplace=True)\n        \n        X['IsDistrictLarge'] = (X['DistrictSize'] > 100).astype(int)\n        \n        # More categorical features\n        X = self.floor_to_cat(X)  # + \u0441\u0442\u043e\u043b\u0431\u0435\u0446 floor_cat\n        X = self.year_to_cat(X)   # + \u0441\u0442\u043e\u043b\u0431\u0435\u0446 year_cat\n        \n        # Target encoding\n        if self.med_price_by_district is not None:\n            X = X.merge(self.med_price_by_district, on=['DistrictId', 'Rooms'], how='left')\n            X.fillna(self.med_price_by_district_median, inplace=True)\n            \n            \n        if self.med_price_sq_by_district_x is not None:\n            X = X.merge(self.med_price_sq_by_district_x, on=['DistrictId'], how='left')\n            X.fillna(self.med_price_by_district_median, inplace=True)\n            \n        if self.med_price_sq_by_district_y is not None:\n            X = X.merge(self.med_price_sq_by_district_y, on=['DistrictId'], how='left')\n            X.fillna(self.med_price_by_district_median, inplace=True)\n            \n            \n            \n            \n            \n        if self.med_price_by_floor_year is not None:\n            X = X.merge(self.med_price_by_floor_year, on=['year_cat', 'floor_cat'], how='left')\n            X.fillna(self.med_price_by_floor_year_median, inplace=True)\n        \n        return X\n    \n    def floor_to_cat(self, X):\n        bins = [0, 3, 5, 9, 15, self.floor_max]\n        X['floor_cat'] = pd.cut(X['Floor'], bins=bins, labels=False)\n\n        X['floor_cat'].fillna(-1, inplace=True) \n        return X\n     \n    def year_to_cat(self, X):\n        bins = [0, 1941, 1945, 1980, 2000, 2010, self.house_year_max]\n        X['year_cat'] = pd.cut(X['HouseYear'], bins=bins, labels=False)\n\n        X['year_cat'].fillna(-1, inplace=True)\n        return X","cff0ef92":"train_df = pd.read_csv(TRAIN_DATASET_PATH)\ntest_df = pd.read_csv(TEST_DATASET_PATH)\n\npreprocessor = DataPreprocessing()\npreprocessor.fit(train_df)\n\ntrain_df = preprocessor.transform(train_df)\ntest_df = preprocessor.transform(test_df)\ntrain_df.shape, test_df.shape","6cccc028":"train_df.columns","e1461494":"features_gen = FeatureGenetator()\nfeatures_gen.fit(train_df.drop(columns='Price'), train_df['Price'])\n\ntrain_df = features_gen.transform(train_df)\ntest_df = features_gen.transform(test_df)\ntrain_df.shape, test_df.shape","45f6ac5f":"train_df","427a2372":"feature_names = ['Rooms', 'Square', 'LifeSquare', 'KitchenSquare', 'Floor', 'HouseFloor', 'HouseYear',\n                 'Ecology_1', 'Ecology_2', 'Ecology_3', 'Social_1', 'Social_2', 'Social_3',\n                 'Helthcare_2', 'Shops_1', 'Shops_2']\n\nnew_feature_names = ['Rooms_outlier', 'HouseFloor_outlier', 'HouseYear_outlier', 'DistrictSize',\n                     'new_district', 'IsDistrictLarge',  'MedPriceByDistrict', 'MedPriceByFloorYear', 'MedPriceSqByDistrict_x', 'MedPriceSqByDistrict_y']\n\ntarget_name = 'Price'","4f2a97e0":"X = train_df[feature_names + new_feature_names]\ny = train_df[target_name]\n\ntest_df = test_df[feature_names + new_feature_names]","7094546c":"X = train_df[feature_names + new_feature_names]\ny = train_df[target_name]","0a7177e2":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True, random_state=42)","f0289b34":"parameters = {\n    'n_estimators': [50],\n    'max_features': np.arange(5, 6),\n    'max_depth': np.arange(5, 6),\n}\n\nclf = GridSearchCV(\n    estimator=RandomForestRegressor(),\n    param_grid=parameters,\n    scoring='accuracy',\n    cv=5,\n)","207043e9":"rf_model = RandomForestRegressor(random_state=21, criterion='mse', n_estimators = 150, max_features = 8, max_depth = 10, min_samples_leaf = 3)\n","67af707a":"rf_model.fit(X_train, y_train)","342109c4":"y_train_preds = rf_model.predict(X_train)\ny_test_preds = rf_model.predict(X_test)\n\nevaluate_preds(y_train, y_train_preds, y_test, y_test_preds)","5f21961a":"extra = ExtraTreesRegressor(random_state=21, criterion='mse', min_samples_leaf = 3)","e1465a29":"extra.fit(X_train, y_train)","079e922d":"extra_train_preds = extra.predict(X_train)\nextra_test_preds = extra.predict(X_test)\n\nevaluate_preds(y_train, extra_train_preds, y_test, extra_test_preds)","265bcbf9":"gr_tree = GradientBoostingRegressor(random_state=23, criterion='mse', min_samples_leaf = 5,\\\n                                    n_estimators = 40, max_features = 6, max_depth = 8)","b279f650":"gr_tree.fit(X_train, y_train)","06c34a9a":"gr_tree_train_preds = gr_tree.predict(X_train)\ngr_tree_test_preds = gr_tree.predict(X_test)\n\nevaluate_preds(y_train, gr_tree_train_preds, y_test, gr_tree_test_preds)","2876a1d4":"cv_score = cross_val_score(rf_model, X, y, scoring='r2', cv=KFold(n_splits=3, shuffle=True, random_state=21))\ncv_score.mean()","a40a40ac":"feature_importances = pd.DataFrame(zip(X_train.columns, gr_tree.feature_importances_), columns=['feature_name', 'importance'])\n\nfeature_importances.sort_values(by='importance', ascending=False)","cd598bea":"submit","f41c7aa5":"test_df.columns","94da7a64":"train_df.columns","b49a0dc9":"predictions = rf_model.predict(test_df[feature_names + new_feature_names])","e7be0f42":"submit['Price'] = predictions\nsubmit.head()","54dae318":"submit.to_csv('gr_tree_davoyan.csv', index=False)","1f5f3609":"med_price_by_district_sq = train_df.groupby(['DistrictId'], as_index=False).agg({'Price':'median'})\\\n                            .rename(columns={'Price':'MedPriceByDistrict'})\n\nmed_price_by_district_sq.head()","98dde129":"train_df['PricePerSq'] = train_df['Price'] \/ train_df['Square']","2dedc2f2":"med_price_sq_by_district = train_df.groupby(['DistrictId'], as_index=False).agg({'PricePerSq':'mean'})\\\n                            .rename(columns={'PricePerSq':'MedPriceSqByDistrict'})\n\nmed_price_sq_by_district","5a624069":"train_df = train_df.merge(med_price_sq_by_district, on='DistrictId', how='left')","d2a984b8":"train_df","ad4403c7":"train_df['Rooms'].max()","38d373dc":"\u041f\u0440\u043e\u0431\u0443\u0435\u043c \u043d\u043e\u0432\u0443\u044e \u0444\u0438\u0447\u0443: \u043f\u043e\u0441\u0447\u0438\u0442\u0430\u0442\u044c \u0441\u0440\u0435\u0434\u043d\u044e\u044e \u0446\u0435\u043d\u0443 \u0437\u0430 \u043a\u0432\u0430\u0434\u0440\u0430\u0442 \u043f\u043e \u0440\u0430\u0439\u043e\u043d\u0430\u043c","0fcdf202":"\u041f\u043e\u0447\u0438\u0441\u0442\u0438\u043c \u0432\u044b\u0431\u0440\u043e\u0441\u044b \u0432 \u0440\u0443\u043c\u0441","00345ab8":"\u0420\u0430\u0441\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0446\u0435\u043b\u0435\u0432\u0443\u044e \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0443\u044e","ff2421ab":"\u041d\u043e\u0432\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438","63f9a5b1":"\u041d\u0430\u0442\u0440\u0435\u043d\u0438\u0440\u0443\u0435\u043c \u043b\u0438\u043d\u0435\u0439\u043d\u0443\u044e \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044e, \u0447\u0442\u043e\u0431\u044b \u043f\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0443 \u043a\u0432\u0430\u0440\u0442\u0438\u0440\u044b \u0443\u0433\u0430\u0434\u044b\u0432\u0430\u043b\u0430 \u0440\u0430\u0437\u043c\u0435\u0440 \u043a\u0443\u0445\u043d\u0438","740ca224":"\u041f\u043e\u0447\u0438\u0441\u0442\u0438\u043c \u044d\u0442\u0430\u0436\u043d\u043e\u0441\u0442\u0438","96b550ca":"\u0420\u0430\u0437\u0431\u0438\u0432\u0430\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u043d\u0430 \u0442\u0440\u0435\u0439\u043d \u0438 \u0442\u0435\u0441\u0442","89072c1f":"\u041e\u0442\u0440\u0430\u0431\u0430\u0442\u044b\u0432\u0430\u0435\u043c \u0445\u0432\u043e\u0441\u0442\u044b \u0432 square","44d364f3":"\u0427\u0438\u0441\u0442\u0438\u043c lifesquare, \u0437\u0430\u043f\u043e\u043b\u043d\u0438\u043c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f\u043c\u0438","5e1e194d":"\u0420\u0430\u0431\u043e\u0442\u0430\u0435\u043c \u0441 KitchenSquare","d63dcd0f":"\u0412\u0438\u0437\u0443\u0430\u043b\u044c\u043d\u043e \u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0433\u0434\u0435 \u0435\u0441\u0442\u044c \u0432\u044b\u0431\u0440\u043e\u0441\u044b","3f57eb51":"\u041d\u0430\u0439\u0434\u0435\u043c \u0432\u044b\u0431\u0440\u043e\u0441\u044b \u043f\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0443 \u043a\u0443\u0445\u043d\u0438 \u0438 \u0437\u0430\u043c\u0435\u043d\u0438\u043c \u043d\u0430 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u043b\u0438\u043d\u0435\u0439\u043d\u043e\u0439 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438"}}