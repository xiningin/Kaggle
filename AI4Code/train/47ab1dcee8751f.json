{"cell_type":{"74303ae1":"code","efce151b":"code","9161c717":"code","a34d4051":"code","bdc15c00":"code","cbac7a2c":"code","bd225948":"code","2764fed1":"code","39d81197":"code","d7192b81":"code","50fdb869":"code","039bda32":"code","8aad0a3e":"markdown","bbe7a2c3":"markdown","be169405":"markdown","d8d147fd":"markdown","ec45ebdd":"markdown"},"source":{"74303ae1":"import os\nimport pickle\nfrom multiprocessing import Pool\n\nimport numpy as np\nimport tensorflow as tf\nimport pandas as pd\nfrom tqdm.auto import tqdm\nimport json","efce151b":"from kaggle_secrets import UserSecretsClient\n\nsecrets = UserSecretsClient()\n\nos.environ['KAGGLE_USERNAME'] = secrets.get_secret(\"KAGGLE_USERNAME\")\nos.environ['KAGGLE_KEY'] = secrets.get_secret(\"KAGGLE_KEY\")","9161c717":"def to_feature(value, dtype):\n    if dtype in ['int', 'int64', 'uint32', 'uint64', 'bool', 'enum']:\n        return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n    \n    if dtype in ['float', 'double', 'float32', 'float64']:\n        return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n    \n    if dtype in ['string', 'bytes']:\n        return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n    \n    else:\n        error_msg = (\n            f\"dtype '{dtype}' not recognized. You need to use a dtype compatible with TF protos.\"\n            \"See: https:\/\/www.tensorflow.org\/tutorials\/load_data\/tfrecord\"\n        )\n        raise ValueError(error_msg)\n\ndef to_example(feature):\n    return tf.train.Example(features=tf.train.Features(feature=feature))\n\ndef serialize(example):\n    return example.SerializeToString()\n\ndef deserialize(string):\n    return tf.train.Example.FromString(string)","a34d4051":"os.makedirs('\/kaggle\/dataset\/', exist_ok=True)\n\n# Change below\nmeta = dict(\n    id=\"xhlulu\/seti-tfrecords-test\",\n    title=\"SETI Test Split in TF Records\",\n    isPrivate=False,\n    licenses=[dict(name=\"other\")]\n)\n\nwith open('\/kaggle\/dataset\/dataset-metadata.json', 'w') as f:\n    json.dump(meta, f)","bdc15c00":"# First time only:\n!touch \/kaggle\/dataset\/dummy.txt\n!kaggle datasets create -p \"\/kaggle\/dataset\" --dir-mode zip\n!rm \/kaggle\/dataset\/dummy.txt","cbac7a2c":"labels = pd.read_csv('..\/input\/seti-breakthrough-listen\/sample_submission.csv')\nlabels.head()","bd225948":"split = 'test'\nn_jobs = 8\n\nN = labels.shape[0]\nchunk_size = np.ceil(N \/ (n_jobs * 10)).astype(int)\nindices = np.arange(0, N, chunk_size)","2764fed1":"def write_record(arg):\n    chunk, idx, chunk_size, split = arg\n    \n    record_path = f\"\/kaggle\/dataset\/{split}-{chunk}.tfrecord\"\n    chunk_df = labels.values[idx: idx+chunk_size]\n    \n    print(\"Starting to write\", record_path)\n    with tf.io.TFRecordWriter(record_path) as writer:\n        for idx, target in chunk_df:\n            path = os.path.join(\"..\/input\/seti-breakthrough-listen\", split, idx[0], idx + '.npy')\n            X = np.load(path)\n\n            feature = {\n                \"X\": to_feature(X.flatten(), 'float'),\n            }\n\n            example = to_example(feature)\n            serialized = serialize(example)\n            writer.write(serialized)\n        \n    print(\"Finished to write\", record_path)","39d81197":"args = [\n    (chunk, idx, chunk_size, split)\n    for chunk, idx in enumerate(indices)\n]","d7192b81":"%%time\nwith Pool(4) as p:\n    p.map(write_record, args)","50fdb869":"!kaggle datasets version -p \"\/kaggle\/dataset\" -m \"Updated via notebook\" --dir-mode zip","039bda32":"# def parse_train_example(example):\n#     feature_description = {\n#         \"X\": tf.io.FixedLenFeature((6, 273, 256), tf.float32),\n#         \"y\": tf.io.FixedLenFeature([], tf.int64)\n#     }\n\n#     example = tf.io.parse_single_example(example, feature_description)\n#     X = tf.transpose(example['X'], (0, 2, 1))\n    \n#     return X, example['y']\n\n# def parse_test_example(example):\n#     feature_description = {\n#         \"X\": tf.io.FixedLenFeature((6, 273, 256), tf.float32)\n#     }\n\n#     example = tf.io.parse_single_example(example, feature_description)\n#     X = tf.transpose(example['X'], (0, 2, 1))\n    \n#     return X\n\n\n# parsed_dataset = (\n#     tf.data.TFRecordDataset([f\"\/kaggle\/dataset\/train-{chunk}.tfrecord\" for chunk in range(4)])\n#     .map(parse_train_example)\n# )","8aad0a3e":"## Initialize Kaggle Dataset Metadata","bbe7a2c3":"## Code for reading TF Records\n\nOnly for reference, not run here","be169405":"## Upload dataset","d8d147fd":"## Helper functions","ec45ebdd":"## Start generating TF Records"}}