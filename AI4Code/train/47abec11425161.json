{"cell_type":{"f776fabe":"code","5ca64a24":"code","3beec690":"code","8fe0a9d6":"code","3edae13d":"code","6a359ce1":"code","e50fae6a":"code","f41d527d":"code","7c2b8a28":"code","2807fb6f":"code","fa7139b9":"code","7585baaa":"code","14eaad7a":"code","81f4c133":"code","361d367c":"code","e18f2075":"code","9f75cc5a":"code","c5122946":"code","743bea9f":"code","38b738c9":"code","9dcd5b1e":"code","83959a49":"code","a9e4a950":"code","ab3d0850":"code","89b6a970":"code","49d4b83a":"code","d24ac5e7":"markdown","5a92c014":"markdown","ab973fab":"markdown","20699023":"markdown","e59c9ca4":"markdown","1ac92c79":"markdown","45488304":"markdown","87e155c7":"markdown","324c5d43":"markdown","f75dec4d":"markdown"},"source":{"f776fabe":"!pip install loguru\nfrom loguru import logger","5ca64a24":"# !pip install numerapi\n# import numerapi","3beec690":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport sys\nimport gc\nimport pathlib\nimport joblib\nimport math\nimport random\nimport time\nfrom typing import List, NoReturn, Union, Tuple, Optional, Text, Generic, Callable, Dict\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom sklearn import metrics\nfrom sklearn import decomposition\nfrom sklearn import linear_model\nfrom scipy import stats\nfrom tqdm.notebook import tqdm\nimport umap\nfrom catboost import CatBoostRegressor, CatBoostClassifier\nimport lightgbm as lgb\nimport xgboost as xgb\nimport operator\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom scipy.stats import spearmanr\nfrom deap import algorithms, base, creator, tools, gp\n\n# visualize\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nimport seaborn as sns\nfrom matplotlib import pyplot\nfrom matplotlib.ticker import ScalarFormatter\nimport plotly.graph_objects as go\nimport plotly.express as px\npd.options.plotting.backend = \"plotly\"\nsns.set_context(\"talk\")\nstyle.use('fivethirtyeight')\n\nimport warnings\nwarnings.filterwarnings('ignore')","8fe0a9d6":"INPUT_TRAIN_DIR = '..\/input\/numerai-train-to-feather-nomi\/'\nINPUT_TEST_DIR = '..\/input\/numerai-test-to-feather-nomi\/'\nOUTPUT_DIR = ''\nSEED = 42\ntarget = 'target'\nprediction = 'prediction'","3edae13d":"def get_int(x):\n    try:\n        return int(x[3:])\n    except:\n        return 1000 # live era!\n    \ndef load_data():\n    # load data\n    train = pd.read_feather(pathlib.Path(INPUT_TRAIN_DIR + 'train.feather'))\n    tournament = pd.read_feather(pathlib.Path(INPUT_TEST_DIR + 'test.feather'))\n    \n    # split valid and test\n    valid = tournament[tournament[\"data_type\"] == \"validation\"].reset_index(drop = True)\n    \n    # era int\n    train[\"era\"] = train[\"era\"].apply(get_int)\n    valid[\"era\"] = valid[\"era\"].apply(get_int)\n    tournament[\"era\"] = tournament[\"era\"].apply(get_int)\n\n    return train, valid, tournament\n\ntrain, valid, tournament = load_data()","6a359ce1":"print(train.shape)\ntrain.head()","e50fae6a":"print(valid.shape)\nvalid.head()","f41d527d":"print(tournament.shape)\ntournament.head()","7c2b8a28":"features = train.columns[train.columns.str.startswith('feature')].values.tolist()","2807fb6f":"all_data = pd.concat([train[features + ['era', target]], \n                      tournament[features + ['era', target]]], \n                      ignore_index=True)\nprint(all_data.shape)","fa7139b9":"len_train = len(train)\nvalid_era = valid['era'].values\n\ndel train, valid, tournament\ngc.collect()","7585baaa":"%%time\n\npca = decomposition.IncrementalPCA(n_components=100)\nemb = pca.fit_transform(all_data[features].values)\nfor i in range(emb.shape[1]):\n    all_data[f'pca_{i+1}'] = emb[:, i]\n    \nprint(all_data.shape)","14eaad7a":"plt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.ylim([0, 1])\nplt.xlabel('n_components')\nplt.ylabel('explained variance')\nplt.title('PCA using the tournament data')","81f4c133":"# cast to uint8 to save memory\nfor f in tqdm([k for k in all_data.columns.values.tolist() if k.startswith('pca')]):\n    all_data[f] = all_data[f].rank().astype(np.uint8)","361d367c":"train = all_data.iloc[:len_train]\ntournament = all_data.iloc[len_train:]\nvalid = tournament.loc[tournament['era'].isin(valid_era), :]\n\ndel all_data\ngc.collect()","e18f2075":"%%time\n\nbase_model = lgb.LGBMRegressor(max_depth=3, feature_fraction=0.4, seed=42)\nbase_model.fit(train[features], train[target], eval_set=[(valid[features], valid[target])],\n            verbose=100)\nfi = base_model.booster_.feature_importance(importance_type=\"gain\")","9f75cc5a":"fi_df = pd.DataFrame()\nfi_df['features'] = features\nfi_df['importance'] = fi\nfi_df = fi_df.sort_values(by='importance', ascending=False)\n\nfig, ax = plt.subplots(1, 1, figsize=(6, 30))\nsns.barplot(x='importance', y='features', data=fi_df.iloc[:40], ax=ax)\nax.set_title('base model')\nplt.savefig('base_feature_importance.png', bbox_inches='tight')","c5122946":"%%time\nnew_feats = [f for f in train.columns.values.tolist() if f not in [target, 'era', ]]\nmodel = lgb.LGBMRegressor(max_depth=3, feature_fraction=0.4, seed=42)\nmodel.fit(train[new_feats], train[target], eval_set=[(valid[new_feats], valid[target])],\n            verbose=100)\nfi = model.booster_.feature_importance(importance_type=\"gain\")","743bea9f":"fi_df = pd.DataFrame()\nfi_df['features'] = new_feats\nfi_df['importance'] = fi\nfi_df = fi_df.sort_values(by='importance', ascending=False)\n\nfig, ax = plt.subplots(1, 1, figsize=(6, 30))\nsns.barplot(x='importance', y='features', data=fi_df.iloc[:40], ax=ax)\nax.set_title('+PCA model')\nplt.savefig('pca_feature_importance.png', bbox_inches='tight')","38b738c9":"# naming conventions\nPREDICTION_NAME = prediction\nTARGET_NAME = target\nEXAMPLE_PRED = 'example_prediction'\n\n# ---------------------------\n# Functions\n# ---------------------------\ndef valid4score(valid : pd.DataFrame, pred : np.ndarray, load_example: bool=True, save : bool=False) -> pd.DataFrame:\n    \"\"\"\n    Generate new valid pandas dataframe for computing scores\n    \n    :INPUT:\n    - valid : pd.DataFrame extracted from tournament data (data_type='validation')\n    \n    \"\"\"\n    valid_df = valid.copy()\n    \n    if load_example:\n        valid_df[EXAMPLE_PRED] = pd.read_csv(EXP_DIR + 'valid_df.csv')['prediction'].values\n    \n    if save==True:\n        valid_df.to_csv(OUTPUT_DIR + 'valid_df.csv', index=False)\n        logger.debug('Validation dataframe saved!')\n        \n    valid_df['prediction'] = pd.Series(pred).rank(pct=True, method=\"first\").values\n    valid_df.rename(columns={target: 'target'}, inplace=True)\n    \n    return valid_df\n\ndef compute_corr(valid_df : pd.DataFrame):\n    \"\"\"\n    Compute rank correlation\n    \n    :INPUT:\n    - valid_df : pd.DataFrame where at least 2 columns ('prediction' & 'target') exist\n    \n    \"\"\"\n    \n    return np.corrcoef(valid_df[\"target\"], valid_df['prediction'])[0, 1]\n\ndef compute_max_drawdown(validation_correlations : pd.Series):\n    \"\"\"\n    Compute max drawdown\n    \n    :INPUT:\n    - validation_correaltions : pd.Series\n    \"\"\"\n    \n    rolling_max = (validation_correlations + 1).cumprod().rolling(window=100, min_periods=1).max()\n    daily_value = (validation_correlations + 1).cumprod()\n    max_drawdown = -(rolling_max - daily_value).max()\n    \n    return max_drawdown\n\ndef compute_val_corr(valid_df : pd.DataFrame):\n    \"\"\"\n    Compute rank correlation for valid periods\n    \n    :INPUT:\n    - valid_df : pd.DataFrame where at least 2 columns ('prediction' & 'target') exist\n    \"\"\"\n    \n    # all validation\n    correlation = compute_corr(valid_df)\n    logger.debug(\"rank corr = {:.4f}\".format(correlation))\n    return correlation\n    \ndef compute_val_sharpe(valid_df : pd.DataFrame):\n    \"\"\"\n    Compute sharpe ratio for valid periods\n    \n    :INPUT:\n    - valid_df : pd.DataFrame where at least 2 columns ('prediction' & 'target') exist\n    \"\"\"\n    # all validation\n    d = valid_df.groupby('era')[['target', 'prediction']].corr().iloc[0::2,-1].reset_index()\n    me = d['prediction'].mean()\n    sd = d['prediction'].std()\n    max_drawdown = compute_max_drawdown(d['prediction'])\n    logger.debug('sharpe ratio = {:.4f}, corr mean = {:.4f}, corr std = {:.4f}, max drawdown = {:.4f}'.format(me \/ sd, me, sd, max_drawdown))\n    \n    return me \/ sd, me, sd, max_drawdown\n    \ndef feature_exposures(valid_df : pd.DataFrame):\n    \"\"\"\n    Compute feature exposure\n    \n    :INPUT:\n    - valid_df : pd.DataFrame where at least 2 columns ('prediction' & 'target') exist\n    \"\"\"\n    feature_names = [f for f in valid_df.columns\n                     if f.startswith(\"feature\")]\n    exposures = []\n    for f in feature_names:\n        fe = spearmanr(valid_df['prediction'], valid_df[f])[0]\n        exposures.append(fe)\n    return np.array(exposures)\n\ndef max_feature_exposure(fe : np.ndarray):\n    return np.max(np.abs(fe))\n\ndef feature_exposure(fe : np.ndarray):\n    return np.sqrt(np.mean(np.square(fe)))\n\ndef compute_val_feature_exposure(valid_df : pd.DataFrame):\n    \"\"\"\n    Compute feature exposure for valid periods\n    \n    :INPUT:\n    - valid_df : pd.DataFrame where at least 2 columns ('prediction' & 'target') exist\n    \"\"\"\n    # all validation\n    fe = feature_exposures(valid_df)\n    fe1, fe2 = feature_exposure(fe), max_feature_exposure(fe)\n    logger.debug('feature exposure = {:.4f}, max feature exposure = {:.4f}'.format(fe1, fe2))\n     \n    return fe1, fe2\n\n# to neutralize a column in a df by many other columns\ndef neutralize(df, columns, by, proportion=1.0):\n    scores = df.loc[:, columns]\n    exposures = df[by].values\n\n    # constant column to make sure the series is completely neutral to exposures\n    exposures = np.hstack(\n        (exposures,\n         np.asarray(np.mean(scores)) * np.ones(len(exposures)).reshape(-1, 1)))\n\n    scores = scores - proportion * exposures.dot(\n        np.linalg.pinv(exposures).dot(scores))\n    return scores \/ scores.std()\n\n\n# to neutralize any series by any other series\ndef neutralize_series(series, by, proportion=1.0):\n    scores = series.values.reshape(-1, 1)\n    exposures = by.values.reshape(-1, 1)\n\n    # this line makes series neutral to a constant column so that it's centered and for sure gets corr 0 with exposures\n    exposures = np.hstack(\n        (exposures,\n         np.array([np.mean(series)] * len(exposures)).reshape(-1, 1)))\n\n    correction = proportion * (exposures.dot(\n        np.linalg.lstsq(exposures, scores, rcond=None)[0]))\n    corrected_scores = scores - correction\n    neutralized = pd.Series(corrected_scores.ravel(), index=series.index)\n    return neutralized\n\n\ndef unif(df):\n    x = (df.rank(method=\"first\") - 0.5) \/ len(df)\n    return pd.Series(x, index=df.index)\n\ndef get_feature_neutral_mean(df):\n    feature_cols = [c for c in df.columns if c.startswith(\"feature\")]\n    df.loc[:, \"neutral_sub\"] = neutralize(df, [PREDICTION_NAME],\n                                          feature_cols)[PREDICTION_NAME]\n    scores = df.groupby(\"era\").apply(\n        lambda x: np.corrcoef(x[\"neutral_sub\"].rank(pct=True, method=\"first\"), x[TARGET_NAME])).mean()\n    return np.mean(scores)\n\ndef compute_val_mmc(valid_df : pd.DataFrame):    \n    # MMC over validation\n    mmc_scores = []\n    corr_scores = []\n    for _, x in valid_df.groupby(\"era\"):\n        series = neutralize_series(pd.Series(unif(x[PREDICTION_NAME])),\n                                   pd.Series(unif(x[EXAMPLE_PRED])))\n        mmc_scores.append(np.cov(series, x[TARGET_NAME])[0, 1] \/ (0.29 ** 2))\n        corr_scores.append(np.corrcoef(unif(x[PREDICTION_NAME]).rank(pct=True, method=\"first\"), x[TARGET_NAME]))\n\n    val_mmc_mean = np.mean(mmc_scores)\n    val_mmc_std = np.std(mmc_scores)\n    val_mmc_sharpe = val_mmc_mean \/ val_mmc_std\n    corr_plus_mmcs = [c + m for c, m in zip(corr_scores, mmc_scores)]\n    corr_plus_mmc_sharpe = np.mean(corr_plus_mmcs) \/ np.std(corr_plus_mmcs)\n    corr_plus_mmc_mean = np.mean(corr_plus_mmcs)\n\n    logger.debug(\"MMC Mean = {:.6f}, MMC Std = {:.6f}, CORR+MMC Sharpe = {:.4f}\".format(val_mmc_mean, val_mmc_std, corr_plus_mmc_sharpe))\n\n    # Check correlation with example predictions\n    corr_with_example_preds = np.corrcoef(valid_df[EXAMPLE_PRED].rank(pct=True, method=\"first\"),\n                                          valid_df[PREDICTION_NAME].rank(pct=True, method=\"first\"))[0, 1]\n    logger.debug(\"Corr with example preds: {:.4f}\".format(corr_with_example_preds))\n    \n    return val_mmc_mean, val_mmc_std, corr_plus_mmc_sharpe, corr_with_example_preds\n    \ndef score_summary(valid_df : pd.DataFrame):\n    score_df = {}\n    \n    try:\n        score_df['correlation'] = compute_val_corr(valid_df)\n    except:\n        print('ERR: computing correlation')\n    try:\n        score_df['corr_sharpe'], score_df['corr_mean'], score_df['corr_std'], score_df['max_drawdown'] = compute_val_sharpe(valid_df)\n    except:\n        print('ERR: computing sharpe')\n    try:\n        score_df['feature_exposure'], score_df['max_feature_exposure'] = compute_val_feature_exposure(valid_df)\n    except:\n        print('ERR: computing feature exposure')\n    try:\n        score_df['mmc_mean'], score_df['mmc_std'], score_df['corr_mmc_sharpe'], score_df['corr_with_example_xgb'] = compute_val_mmc(valid_df)\n    except:\n        print('ERR: computing MMC')\n    \n    return pd.DataFrame.from_dict(score_df, orient='index')","9dcd5b1e":"# prediction for valid periods   \npred = base_model.predict(valid[features])\nvalid_df = valid4score(valid, pred, load_example=False, save=False)","83959a49":"# scores\nscore_df = pd.DataFrame()\nprint('------------------')\nprint('ALL:')\nprint('------------------')\nall_ = score_summary(valid_df).rename(columns={0: 'all'})\n\nprint('------------------')\nprint('VALID 1:')\nprint('------------------')\nval1_ = score_summary(valid_df.query('era < 150')).rename(columns={0: 'val1'})\n\nprint('------------------')\nprint('VALID 2:')\nprint('------------------')\nval2_ = score_summary(valid_df.query('era > 150')).rename(columns={0: 'val2'})","a9e4a950":"# scores\nscore_df = pd.concat([all_, val1_, val2_], axis=1)\nscore_df.style.background_gradient(cmap='viridis', axis=0)","ab3d0850":"# prediction for valid periods   \npred = model.predict(valid[new_feats])\nvalid_df = valid4score(valid, pred, load_example=False, save=False)","89b6a970":"# scores\nscore_df = pd.DataFrame()\nprint('------------------')\nprint('ALL:')\nprint('------------------')\nall_ = score_summary(valid_df).rename(columns={0: 'all'})\n\nprint('------------------')\nprint('VALID 1:')\nprint('------------------')\nval1_ = score_summary(valid_df.query('era < 150')).rename(columns={0: 'val1'})\n\nprint('------------------')\nprint('VALID 2:')\nprint('------------------')\nval2_ = score_summary(valid_df.query('era > 150')).rename(columns={0: 'val2'})","49d4b83a":"# scores\nscore_df = pd.concat([all_, val1_, val2_], axis=1)\nscore_df.style.background_gradient(cmap='viridis', axis=0)","d24ac5e7":"# Load data\nI have already saved the data in the feather format elsewhere such that I can load the data really quickly. ","5a92c014":"# Validation Score (pca model)","ab973fab":"# +PCA","20699023":"# Validation Score","e59c9ca4":"# Baseline","1ac92c79":"![numerai](https:\/\/numer.ai\/homepage\/img\/Numerai-Logo-Side-Black.png)\n\n\n# Motivation\nHi everyone, how is your Numerai life going?:D\n\nThis is my second kaggle notebook regarding the Numerai Tournament. The first one is [metric learning and live era](https:\/\/www.kaggle.com\/code1110\/numerai-metric-learning-and-live-era), so have a visit if you are interested.\n\nThe motivation in this current notebook is quite simple: I would love to have **a better feature**. \n\nIn a normal tabular data science competition, you can generate new features manually by making sense of what each feature means. In the numerai tournament, it is not possible because all the features are anonymous.\n\nHere I employ a **genetic algorithm** to generate new features which can predict our target well.\n\nI don't get into the detail of the algorithm here, but you might want to visit the followings if you are interested:\n\n- [Genetic Algorithm with DEAP](https:\/\/www.kaggle.com\/marlesson\/genetic-algorithm-with-deap)\n- [\u907a\u4f1d\u7684\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u306b\u3088\u308b\u7279\u5fb4\u91cf\u751f\u6210](https:\/\/qiita.com\/overlap\/items\/e7f1077ef8239f454602)\n\nSo shall we begin?\n\n## Data\nTournament data here is for R240. I only use a part of validation data, so the round itself does not matter.\n\n## Reference\n- [Genetic Algorithm with DEAP](https:\/\/www.kaggle.com\/marlesson\/genetic-algorithm-with-deap)\n- [\u907a\u4f1d\u7684\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u306b\u3088\u308b\u7279\u5fb4\u91cf\u751f\u6210](https:\/\/qiita.com\/overlap\/items\/e7f1077ef8239f454602)","45488304":"# Libraries\nWhat we need here...","87e155c7":"# Validation Score (base model)","324c5d43":"Correlation got better with PCA but sharpe went worse...it is totally up to you if you use PCA features or not!","f75dec4d":"# PCA"}}