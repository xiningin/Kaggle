{"cell_type":{"e18cf67d":"code","66de34ea":"code","b362b4dc":"code","840c890a":"code","60ea44c5":"code","905b2880":"code","5ee6716c":"code","9fb38f69":"code","8a0c57e0":"code","1f749207":"code","ae25eb4d":"code","43a49f11":"code","ea0d1e9e":"code","a1fda350":"code","01ae7dcf":"code","a24f7a8f":"code","f3707fd3":"code","840b72ae":"code","0633be82":"code","47329982":"code","697e77a5":"code","20419b58":"code","3446b63a":"code","73fc0ae4":"code","bd0cb555":"code","e280aa24":"code","7caf7389":"code","eaab958f":"code","d961dc82":"code","a451992f":"code","7ec90bef":"code","045a50a0":"code","c40c83df":"markdown","0356f829":"markdown","1aab931d":"markdown","552bf826":"markdown","c41442c2":"markdown","6d982668":"markdown","1657199e":"markdown","bc694486":"markdown","325533b9":"markdown","3841b545":"markdown","646f02db":"markdown","a2694e5e":"markdown","da0befd6":"markdown","5395b904":"markdown","c595753d":"markdown","10db0b53":"markdown","2770d7d4":"markdown","5c006026":"markdown","79c74497":"markdown","22e555d0":"markdown"},"source":{"e18cf67d":"import torch\nimport torchvision\nimport shutil\nimport os\nimport random\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as tt\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom fastai.vision.data import ImageDataLoaders,DataLoaders\nfrom fastai.learner import Learner\nfrom fastai.callback.all import *\nfrom IPython.display import Image\nfrom torchvision.utils import save_image\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\nfrom fastai.metrics import accuracy","66de34ea":"path='\/kaggle\/input\/microsoft-catsvsdogs-dataset\/PetImages'\ntargets=os.listdir(path)\nprint(targets)","b362b4dc":"data_dir='\/kaggle\/data'\ntrain_path=data_dir+'\/train'\nvalid_path=data_dir+'\/valid'\ntest_path=data_dir+'\/test'","840c890a":"def make_dirs():\n    if not os.path.isdir(data_dir):\n        os.mkdir(data_dir)\n        os.mkdir(train_path)\n        os.mkdir(valid_path)\n        os.mkdir(test_path)\n        for label in targets:\n            os.mkdir(os.path.join(train_path,label))\n            os.mkdir(os.path.join(valid_path,label))\n            os.mkdir(os.path.join(test_path,label))\ndef check_dirs():\n    print(f'{data_dir}: {os.path.isdir(data_dir)}')\n    print(f'{train_path}: {os.path.isdir(train_path)}')\n    print(f'{valid_path}: {os.path.isdir(valid_path)}')\n    print(f'{test_path}: {os.path.isdir(test_path)}')\n    for label in targets:\n        print(f'{os.path.join(train_path,label)}: {os.path.isdir(os.path.join(train_path,label))}')\n        print(f'{os.path.join(valid_path,label)}: {os.path.isdir(os.path.join(valid_path,label))}')\n        print(f'{os.path.join(test_path,label)}: {os.path.isdir(os.path.join(test_path,label))}')","60ea44c5":"make_dirs()","905b2880":"check_dirs()","5ee6716c":"def find_image_size():\n    for folder in os.listdir(path):\n        folder_path=os.path.join(path,folder)\n        for file in os.listdir(folder_path):\n            img_path=os.path.join(folder_path,file)\n            image=cv2.imread(img_path)\n            return image.shape\nimg_shape=find_image_size()\nprint(img_shape)","9fb38f69":"train_valid_path=path\ntesting_path=path","8a0c57e0":"def load_train_images(n=5000):\n    for folder in os.listdir(train_valid_path):\n        folder_path=os.path.join(train_valid_path,folder)\n        print(f'Loading the training images for {folder}')\n        dest=os.path.join(train_path,folder)\n        for file in tqdm(random.sample(os.listdir(folder_path),n)):\n            file_path=os.path.join(folder_path,file)\n            shutil.copy(file_path,dest)\ndef load_valid_images(n=2000):\n    for folder in os.listdir(train_valid_path):\n        folder_path=os.path.join(train_valid_path,folder)\n        print(f'Loading the validation images for {folder}')\n        dest=os.path.join(valid_path,folder)\n        for file in tqdm(random.sample(os.listdir(folder_path),n)):\n            file_path=os.path.join(folder_path,file)\n            shutil.copy(file_path,dest)\ndef load_test_images(n=1000):\n    for folder in os.listdir(testing_path):\n        folder_path=os.path.join(testing_path,folder)\n        print(f'Loading the test images for {folder}')\n        dest=os.path.join(test_path,folder)\n        for file in tqdm(random.sample(os.listdir(folder_path),n)):\n            file_path=os.path.join(folder_path,file)\n            shutil.copy(file_path,dest)","1f749207":"load_train_images()","ae25eb4d":"load_valid_images()","43a49f11":"load_test_images()","ea0d1e9e":"if os.path.isdir('\/kaggle\/data\/train\/Cat\/666.jpg'):\n    os.remove('\/kaggle\/data\/train\/Cat\/666.jpg')\nif os.path.isdir('\/kaggle\/data\/train\/Dog\/11072.jpg'):\n    os.remove('\/kaggle\/data\/train\/Dog\/11072.jpg')","a1fda350":"batch_size=25\nepochs=30","01ae7dcf":"train_tfms=tt.Compose([tt.Resize((150,150)),tt.RandomHorizontalFlip(),tt.ToTensor()])\nvalid_test_tfms=tt.Compose([tt.Resize((150,150)),tt.ToTensor()])","a24f7a8f":"train_ds=ImageFolder(root=train_path,transform=train_tfms)\nvalid_ds=ImageFolder(root=valid_path,transform=valid_test_tfms)\ntest_ds=ImageFolder(root=test_path,transform=valid_test_tfms)","f3707fd3":"class MyDataLoader(torch.utils.data.DataLoader):\n    def __init__(self,dataset, batch_size=1, shuffle=False, sampler=None,\n           batch_sampler=None, num_workers=0, collate_fn=None,\n           pin_memory=False, drop_last=False, timeout=0,\n           worker_init_fn=None, prefetch_factor=2,*,\n           persistent_workers=False,device=None):\n        super().__init__(dataset=dataset, batch_size=batch_size, shuffle=shuffle, sampler=sampler,\n           batch_sampler=batch_sampler, num_workers=num_workers, collate_fn=collate_fn,\n           pin_memory=pin_memory, drop_last=drop_last, timeout=timeout,\n           worker_init_fn=worker_init_fn, prefetch_factor=prefetch_factor,\n           persistent_workers=persistent_workers)\n        self.device=device","840b72ae":"device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","0633be82":"def to_device(data,device):\n    if isinstance(data,(list,tuple)):\n        return [to_device(x,device) for x in data]\n    return data.to(device)\nclass DeviceDataLoader():\n    def __init__(self,dl,device):\n        self.dl=dl\n        self.device=device\n    def __iter__(self):\n        for b in self.dl:\n            yield to_device(b,self.device)\n    def __len__(self):\n        return len(self.dl)","47329982":"train_dl=DeviceDataLoader(MyDataLoader(dataset=train_ds,batch_size=batch_size,shuffle=True,pin_memory=True,device=device),device)\nvalid_dl=DeviceDataLoader(MyDataLoader(dataset=valid_ds,batch_size=batch_size,shuffle=False,pin_memory=True,device=device),device)\ntest_dl=DeviceDataLoader(MyDataLoader(dataset=test_ds,batch_size=batch_size,shuffle=False,pin_memory=True,device=device),device)","697e77a5":"for images,labels in train_dl:\n    print(images.shape)\n    print(images)\n    print(labels)\n    break","20419b58":"def nn_grp(ni,nf,ks=3,st=1):\n    return nn.Sequential(\n        nn.Conv2d(in_channels=ni,out_channels=nf,kernel_size=ks,stride=st,padding=ks\/\/2),\n        nn.BatchNorm2d(nf),\n        nn.ReLU(inplace=True),\n        nn.Conv2d(in_channels=nf,out_channels=nf,kernel_size=ks,stride=st,padding=ks\/\/2),\n        nn.BatchNorm2d(nf),\n        nn.ReLU(inplace=True),\n        nn.AvgPool2d(kernel_size=ks,stride=2,padding=ks\/\/2)\n    )","3446b63a":"def make_model(img_size=150):\n    steps=int(np.log2(img_size))\n    model=[]\n    ni,nf=3,16\n    model+=[nn_grp(ni=ni,nf=nf)]\n    steps-=1\n    for i in range(steps):\n        model+=[nn_grp(ni=nf,nf=nf*2)]\n        nf*=2\n    model+=[\n        nn.Flatten(),\n        nn.Linear(in_features=nf*4,out_features=len(targets)),\n        nn.Sigmoid()\n    ]\n    return nn.Sequential(*model)","73fc0ae4":"model=make_model()","bd0cb555":"model","e280aa24":"data=ImageDataLoaders(train_dl,valid_dl)","7caf7389":"learner=Learner(data,model,loss_func=F.cross_entropy,metrics=[accuracy])","eaab958f":"learner.lr_find()","d961dc82":"learner.fit_one_cycle(epochs,9e-4,wd=1e-4)","a451992f":"learner.recorder.plot_loss()","7ec90bef":"def predict(dl):\n    pred,labels=learner.get_preds(dl=dl)\n    _,pred=torch.max(pred,dim=1)\n    return torch.sum(pred==labels).item()\/len(labels)","045a50a0":"print(predict(test_dl)*100)","c40c83df":"Printing the accuracy on the test set, which is 95.2% in this case","0356f829":"Making functions to load the training,testing and validation images to their respective paths","1aab931d":"Using the lr_find method to find the appropriate learning rate","552bf826":"Training the model(or learner) (My validation accuracy comes out to be 94%)","c41442c2":"Plotting the losses","6d982668":"Creating the training,validation and testing datasets","1657199e":"Making new directories where the training,validation and testing images will be stored","bc694486":"Making functions to move things onto the GPU. I have made a DeviceDataLoader class to move my dataloader to the GPU. If I don't make this class I get an error(that my model is on GPU but my input,dataloaders in this case, are not)","325533b9":"Making functions to create the above directories and check whether they have been properly created","3841b545":"These two images were not being identified for some reason, so I decided to remove them","646f02db":"Making my model","a2694e5e":"Prining a batch of image. I do this to check whether I should scale down the pixel values or not","da0befd6":"Declaring the transformations to be applied to my training and validation\/testing images","5395b904":"Making a function to predict on the test dataloader","c595753d":"Making a learner class using ImageDataLoader","10db0b53":"Loading my training and validation dataloaders into FastAI ImageDataLoaders class so that I can use the learner class to train my model using the train_dl and validate using valid_dl","2770d7d4":"Finding the image size so I know the input size I am working with","5c006026":"Checking whether the GPU is available","79c74497":"I had to make my own dataloader, if I don't I get an error later that \"DataLoader does not have an attribute named device\"","22e555d0":"Making the path in which my data is stored, along with the target classes"}}