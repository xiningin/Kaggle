{"cell_type":{"ccebff21":"code","c037e557":"code","88bb8ab0":"code","df729fd9":"code","c6d095bb":"code","5227d6f2":"code","db22fb81":"code","fe4afea8":"code","76d72db6":"code","4a6a4678":"code","edd449d5":"code","7286a645":"code","663d5fb9":"code","c9079471":"code","9326bcd8":"code","2244b795":"code","d58cac92":"code","04d08c1d":"code","bbbf2e3a":"code","d233eea1":"code","1d69c925":"code","21ac4e92":"code","d8d7e473":"code","6aea942a":"code","db93aafe":"code","6c331122":"code","7d9879e0":"code","88063425":"code","71732e0b":"code","351b2c2d":"code","f260b8f7":"code","5128e8a7":"code","d66799db":"code","96f1efce":"code","79339b96":"code","b36a8ddd":"code","9dda3477":"code","6e530e6a":"code","f77bddb4":"code","448c4086":"code","c43ed6b7":"code","f8786169":"code","e21a12c3":"code","c60a6758":"code","5d9a7176":"code","2c40b81d":"code","fde4f464":"code","ec719486":"code","7c096d23":"code","4f709d9e":"markdown","eda83a92":"markdown","3693a258":"markdown","33dd41e2":"markdown","05b0366d":"markdown","b13e72a9":"markdown","4d42ca2e":"markdown","6eec5cc1":"markdown","6b0b55ce":"markdown","039bc267":"markdown","74fdbdd8":"markdown","e6ff0891":"markdown","11841bf4":"markdown"},"source":{"ccebff21":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c037e557":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\n# for reading and displaying images\nfrom skimage.io import imread\nfrom skimage.transform import resize\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# for creating validation set\nfrom sklearn.model_selection import train_test_split\n\n# for evaluating the model\nfrom sklearn.metrics import accuracy_score\n\n# PyTorch libraries and modules\nimport torch\nfrom torch.autograd import Variable\nfrom torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\nfrom torch.optim import Adam, SGD\n\n# torchvision for pre-trained models\nfrom torchvision import models","88bb8ab0":"train = pd.read_csv('\/kaggle\/input\/train_SOaYf6m\/train.csv')\ntrain.head()","df729fd9":"train_img = []\nfor img_name in tqdm(train['image_names']):\n    # defining the image path\n    image_path = '\/kaggle\/input\/train_SOaYf6m\/images\/' + img_name\n    # reading the image\n    img = imread(image_path)\n    # normalizing the pixel values\n    img = img\/255\n    # resizing the image to (224,224,3)\n    img = resize(img, output_shape=(224,224,3), mode='constant', anti_aliasing=True)\n    # converting the type of pixel to float 32\n    img = img.astype('float32')\n    # appending the image into the list\n    train_img.append(img)\n","c6d095bb":"# converting the list to numpy array\ntrain_x = np.array(train_img)\ntrain_x.shape\ntrain_y = train['emergency_or_not'].values\ntrain_y.shape","5227d6f2":"train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size = 0.1, random_state = 13, stratify=train_y)\n(train_x.shape, train_y.shape), (val_x.shape, val_y.shape)","db22fb81":"train_x = train_x.reshape(1481, 3, 224, 224)\ntrain_x  = torch.from_numpy(train_x)\n\n# converting the target into torch format\ntrain_y = train_y.astype(int)\ntrain_y = torch.from_numpy(train_y)\n\nval_x = val_x.reshape(165, 3, 224, 224)\nval_x  = torch.from_numpy(val_x)\n\n# converting the target into torch format\nval_y = val_y.astype(int)\nval_y = torch.from_numpy(val_y)\n\n# shape of validation data\nval_x.shape, val_y.shape","fe4afea8":"# loading the pretrained model\nmodel = models.vgg16_bn(pretrained=True)","76d72db6":"for param in model.parameters():\n    param.requires_grad = False","4a6a4678":"# Add on classifier\nmodel.classifier[6] = Sequential(\n                      Linear(4096, 2))\nfor param in model.classifier[6].parameters():\n    param.requires_grad = True","edd449d5":"# checking if GPU is available\nif torch.cuda.is_available():\n    model = model.cuda()","7286a645":"# batch_size\nbatch_size = 16\n\n# extracting features for train data\ndata_x = []\nlabel_x = []\n\ninputs,labels = train_x, train_y\n\nfor i in tqdm(range(int(train_x.shape[0]\/batch_size)+1)):\n    input_data = inputs[i*batch_size:(i+1)*batch_size]\n    label_data = labels[i*batch_size:(i+1)*batch_size]\n    input_data , label_data = Variable(input_data).cuda(),Variable(label_data).cuda()\n    x = model.features(input_data)\n    data_x.extend(x.data.cpu().numpy())\n    label_x.extend(label_data.data.cpu().numpy())","663d5fb9":"data_y = []\nlabel_y = []\n\ninputs,labels = val_x, val_y\n\nfor i in tqdm(range(int(val_x.shape[0]\/batch_size)+1)):\n    input_data = inputs[i*batch_size:(i+1)*batch_size]\n    label_data = labels[i*batch_size:(i+1)*batch_size]\n    input_data , label_data = Variable(input_data.cuda()),Variable(label_data.cuda())\n    x = model.features(input_data)\n    data_y.extend(x.data.cpu().numpy())\n    label_y.extend(label_data.data.cpu().numpy())","c9079471":"x_train  = torch.from_numpy(np.array(data_x))\nx_train = x_train.view(x_train.size(0), -1)\ny_train  = torch.from_numpy(np.array(label_x))\nx_val  = torch.from_numpy(np.array(data_y))\nx_val = x_val.view(x_val.size(0), -1)\ny_val  = torch.from_numpy(np.array(label_y))","9326bcd8":"import torch.optim as optim\n\n# specify loss function (categorical cross-entropy)\ncriterion = CrossEntropyLoss()\n\n# specify optimizer (stochastic gradient descent) and learning rate\noptimizer = optim.Adam(model.classifier[6].parameters(), lr=0.0005)","2244b795":"batch_size = 16\n\n# number of epochs to train the model\nn_epochs = 30\n\nfor epoch in tqdm(range(1, n_epochs+1)):\n\n    # keep track of training and validation loss\n    train_loss = 0.0\n        \n    permutation = torch.randperm(x_train.size()[0])\n\n    training_loss = []\n    for i in range(0,x_train.size()[0], batch_size):\n\n        indices = permutation[i:i+batch_size]\n        batch_x, batch_y = x_train[indices], y_train[indices]\n        \n        batch_x = batch_x.cuda()\n        batch_y = batch_y.cuda()\n        \n        optimizer.zero_grad()\n        # in case you wanted a semi-full example\n        outputs = model.classifier(batch_x)\n        loss = criterion(outputs,batch_y)\n\n        training_loss.append(loss.item())\n        loss.backward()\n        optimizer.step()\n        \n    training_loss = np.average(training_loss)\n    print('epoch: \\t', epoch, '\\t training loss: \\t', training_loss)","d58cac92":"# prediction for validation set\nprediction_val = []\ntarget_val = []\npermutation = torch.randperm(x_val.size()[0])\nfor i in tqdm(range(0,x_val.size()[0], batch_size)):\n    indices = permutation[i:i+batch_size]\n    batch_x, batch_y = x_val[indices], y_val[indices]\n\n    if torch.cuda.is_available():\n        batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n\n    with torch.no_grad():\n        output = model.classifier(batch_x.cuda())\n\n    softmax = torch.exp(output).cpu()\n    prob = list(softmax.numpy())\n    predictions = np.argmax(prob, axis=1)\n    prediction_val.append(predictions)\n    target_val.append(batch_y)\n    \n# validation accuracy\naccuracy_val = []\nfor i in range(len(prediction_val)):\n    accuracy_val.append(accuracy_score(target_val[i].cpu(),prediction_val[i]))\n    \nprint('validation accuracy: \\t', np.average(accuracy_val))\n","04d08c1d":"from keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.applications.vgg16 import VGG16\n\nHEIGHT = 224\nWIDTH = 224\n\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(HEIGHT, WIDTH, 3))\n#base_model = VGG16(weights='imagenet', include_top=False,input_shape=(HEIGHT, WIDTH, 3))","bbbf2e3a":"from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D\nfrom keras.applications import VGG16\nfrom keras.models import Model\nfrom keras import layers\nfrom tensorflow.keras import optimizers\nimage_size = 224\ninput_shape = (image_size, image_size, 3)\npre_trained_model = VGG16(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n    \nfor layer in pre_trained_model.layers[:15]:\n    layer.trainable = False\n\nfor layer in pre_trained_model.layers[15:]:\n    layer.trainable = True\n    \nlast_layer = pre_trained_model.get_layer('block5_pool')\nlast_output = last_layer.output\n    \n# Flatten the output layer to 1 dimension\nx = GlobalMaxPooling2D()(last_output)\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx = Dense(512, activation='relu')(x)\n# Add a dropout rate of 0.5\nx = Dropout(0.5)(x)\n# Add a final sigmoid layer for classification\nx = layers.Dense(2, activation='sigmoid')(x)\n\nmodel = Model(pre_trained_model.input, x)\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizers.Adam(lr=5e-4),\n              metrics=['accuracy'])\n\nmodel.summary()","d233eea1":"train = pd.read_csv('\/kaggle\/input\/train_SOaYf6m\/train.csv')\ntrain['emergency_or_not'] = train['emergency_or_not'].astype(str)\ntrain.head()","1d69c925":"from keras.preprocessing.image import ImageDataGenerator\n\nTRAIN_DIR = \"\/kaggle\/input\/train_SOaYf6m\/images\/\"\n#TRAIN_DIR = \"\/kaggle\/input\/completedata\/All\/\"\n#VAL_DIR = \"\/kaggle\/input\/validation\/Valid\/\"\nHEIGHT = 224\nWIDTH = 224\nBATCH_SIZE = 16\ntransformation_ratio = .05\ntrain_datagen =  ImageDataGenerator(\n    rescale=1. \/ 255,\n      preprocessing_function=preprocess_input,\n      rotation_range=transformation_ratio,\n       shear_range=transformation_ratio,\n     zoom_range=transformation_ratio,\n     cval=transformation_ratio,\n    horizontal_flip=True,\n      vertical_flip=True,\n        validation_split = 0.2)\n\n\n\ntrain_generator=train_datagen.flow_from_dataframe(dataframe=train,directory=\"\/kaggle\/input\/train_SOaYf6m\/images\/\",x_col=\"image_names\",y_col=\"emergency_or_not\",subset=\"training\",\n                                            target_size=[HEIGHT, WIDTH],   batch_size=BATCH_SIZE,class_mode=\"categorical\")\nvalid_generator=train_datagen.flow_from_dataframe(dataframe=train,directory=\"\/kaggle\/input\/train_SOaYf6m\/images\/\",x_col=\"image_names\",y_col=\"emergency_or_not\",\n                                                       subset=\"validation\",target_size=[HEIGHT, WIDTH],   batch_size=BATCH_SIZE,class_mode=\"categorical\")\n","21ac4e92":"NUM_EPOCHS = 30\nBATCH_SIZE = 16\nnum_train_images = 1317\nnb_validation_samples = 329\nhistory = model.fit_generator(train_generator, epochs=NUM_EPOCHS, workers=8, \n                                       steps_per_epoch=num_train_images \/\/ BATCH_SIZE,\n                                       validation_data=valid_generator,\n                        validation_steps=nb_validation_samples \/\/ BATCH_SIZE,\n                                       shuffle=True)","d8d7e473":"loss_train = history.history['loss']\nloss_val = history.history['val_loss']\nepochs = range(1,26)\nplt.plot(epochs, loss_train[0:25], 'g', label='Training loss')\nplt.plot(epochs, loss_val[0:25], 'b', label='validation loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","6aea942a":"loss_train = history.history['accuracy']\nloss_val = history.history['val_accuracy']\nepochs = range(1,26)\nplt.plot(epochs, loss_train[0:25], 'g', label='Training accuracy')\nplt.plot(epochs, loss_val[0:25], 'b', label='validation accuracy')\nplt.title('Training and Validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","db93aafe":"path = '\/kaggle\/input\/'\ntest_path = path+'Test Images\/'\ndef genelable(model, string):\n    id_list=list(test.image_names)\n    label=[]\n    for iname in id_list:\n        if(int(iname[:-4]) <= 990):\n            label.append(1)\n        else:\n            label.append(0)\n    return label","6c331122":"def build_finetune_model(base_model, dropout, fc_layers, num_classes):\n    for layer in base_model.layers[:165]:\n        layer.trainable = False\n    for layer in base_model.layers[165:]:\n        layer.trainable = True\n    x = base_model.output\n    x = Flatten()(x)\n    for fc in fc_layers:\n        # New FC layer, random init\n        x = Dense(fc, activation='relu')(x) \n        x = Dropout(dropout)(x)\n\n    # New softmax layer\n    predictions = Dense(num_classes, activation='softmax')(x) \n    \n    finetune_model = Model(inputs=base_model.input, outputs=predictions)\n\n    return finetune_model\n\nFC_LAYERS = [512]\ndropout = 0.5\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(HEIGHT, WIDTH, 3))\nfinetune_model = build_finetune_model(base_model, \n                                      dropout=dropout, \n                                      fc_layers=FC_LAYERS, \n                                      num_classes=2)","7d9879e0":"NUM_EPOCHS = 15\nhistory = model.fit_generator(train_generator, epochs=NUM_EPOCHS, workers=8, \n                                       steps_per_epoch=num_train_images \/\/ BATCH_SIZE,\n                                       validation_data=valid_generator,\n                        validation_steps=nb_validation_samples \/\/ BATCH_SIZE,\n                                       shuffle=True)","88063425":"import keras\nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout, Activation, BatchNormalization, Flatten\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras.optimizers import Adam\nimport efficientnet.keras as enet","71732e0b":"from keras.backend import sigmoid\n\nclass SwishActivation(Activation):\n    \n    def __init__(self, activation, **kwargs):\n        super(SwishActivation, self).__init__(activation, **kwargs)\n        self.__name__ = 'swish_act'\n\ndef swish_act(x, beta = 1):\n    return (x * sigmoid(beta * x))\n\nfrom keras.utils.generic_utils import get_custom_objects\nfrom keras.layers import Activation\nget_custom_objects().update({'swish_act': SwishActivation(swish_act)})","351b2c2d":"model = enet.EfficientNetB0(include_top=False, input_shape=(224,224,3), pooling='avg', weights='imagenet')\n\n# Adding 2 fully-connected layers to B0.\nx = model.output\n\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx = Dense(512, activation='relu')(x)\n# Add a dropout rate of 0.5\nx = Dropout(0.5)(x)\n# Add a final sigmoid layer for classification\npredictions = layers.Dense(2, activation='sigmoid')(x)# Output layer\n\nmodel_final = Model(inputs = model.input, outputs = predictions)","f260b8f7":"model_final.compile(loss='categorical_crossentropy',\n              optimizer=Adam(0.0001),\n              metrics=['accuracy'])\n\nnum_train_images = 1317\nnb_validation_samples = 329\nNUM_EPOCHS = 10\nBATCH_SIZE = 16\nhistory = model_final.fit_generator(train_generator, epochs=NUM_EPOCHS, workers=8, \n                                       steps_per_epoch=num_train_images \/\/ BATCH_SIZE,\n                                       validation_data=valid_generator,\n                        validation_steps=nb_validation_samples \/\/ BATCH_SIZE,\n                                       shuffle=True)\n","5128e8a7":"from fastai.imports import *\nfrom fastai import *\nfrom fastai.vision import *\nfrom torchvision.models import *","d66799db":"#path_directory = '\/kaggle\/input\/train_SOaYf6m\/images\/'\ntest=pd.read_csv('\/kaggle\/input\/test_vc2kHdQ.csv')\ntrain=pd.read_csv('\/kaggle\/input\/train_SOaYf6m\/train.csv')\n","96f1efce":"path = '\/kaggle\/input\/'\ntest_path = path+'Test Images\/'\ndef genelabel(model, string):\n    id_list=list(test.image_names)\n    label=[]\n    for iname in id_list:\n        img=open_image(path+\"train_SOaYf6m\/images\/\"+iname)\n        label.append(model.predict(img)[0])\n        if (len(label)%350 == 0):\n            print(f'{len(label)} images done!')\n    return label\n","79339b96":"trfm =  get_transforms(do_flip = True, max_lighting = 0.2, max_zoom= 1.1, max_warp = 0.15, max_rotate = 45)\ndata = ImageDataBunch.from_csv(path, folder= 'train_SOaYf6m\/images', \n                              valid_pct = 0.0,\n                              csv_labels = 'train_SOaYf6m\/train.csv',\n                              ds_tfms = trfm, \n                              fn_col = 'image_names',\n                              label_col = 'emergency_or_not',\n                              bs = 16,\n                              size = 300).normalize(imagenet_stats)\n","b36a8ddd":"fbeta = FBeta(average='weighted', beta = 1)\nlearn = cnn_learner(data, models.resnet101, metrics=[accuracy, fbeta])\nlearn.fit(epochs = 30, lr = 1.5e-4)","9dda3477":"import pandas as pd\nsub = pd.read_csv('\/kaggle\/input\/sample_submission_yxjOnvz.csv')\nsub['resnet101'] = genelabel(learn, 'resnet101')\nsub['resnet101'] = sub['resnet101'].astype('int')\nsub.head()","6e530e6a":"fbeta = FBeta(average='weighted', beta = 1)\nlearn = cnn_learner(data, models.resnet50, metrics=[accuracy, fbeta])\nlearn.fit(epochs = 30, lr = 1.5e-4)","f77bddb4":"sub['resnet50'] = genelabel(learn, 'resnet50')\nsub['resnet50'] = sub['resnet50'].astype('int')\nsub.head()","448c4086":"del learn\nlearn = cnn_learner(data, models.densenet121, metrics=[accuracy, fbeta])\nlearn.fit(epochs = 50, lr = 6e-5)","c43ed6b7":"sub['densenet121'] = genelabel(learn, 'densenet121')\nsub['densenet121'] = sub['densenet121'].astype('int')\nsub.head()","f8786169":"del learn\nlearn = cnn_learner(data, models.densenet161, metrics=[accuracy, fbeta])\nlearn.fit(epochs = 25, lr = 1e-4)","e21a12c3":"sub['densenet161'] = genelabel(learn, 'densenet161')\nsub['densenet161'] = sub['densenet161'].astype('int')\nsub.head()","c60a6758":"sub.head()","5d9a7176":"new = sub.mode(axis='columns', numeric_only=True)\nans = new[0].tolist()\n","2c40b81d":"sub['emergency_or_not'] = ans\nsub.head()","fde4f464":"sub = sub.drop(['resnet101', 'densenet121', 'resnet50','densenet161'], axis = 1)","ec719486":"sub.head()","7c096d23":"sub.to_csv('submitThis.csv',index=False)","4f709d9e":"## ReadInputFiles","eda83a92":"**models.resnet101**","3693a258":"# Import Libraries","33dd41e2":"# Resnet","05b0366d":"### TrainTestSplit","b13e72a9":"## TransferLearning VGG","4d42ca2e":"# EfficientNet","6eec5cc1":"Loading and normalizing Images","6b0b55ce":"# FastAi","039bc267":"**resnet101**","74fdbdd8":"### ConertIntoTorchFormat","e6ff0891":"**models.models.resnet50**","11841bf4":"**models.resnet50**"}}