{"cell_type":{"21b99fc0":"code","e21bd14c":"code","d10c33bb":"code","e0f9df65":"code","c22b4110":"code","1bd45e35":"code","e0880624":"code","eb990b48":"code","b2da6de0":"code","1cff2328":"code","7f0b8c28":"code","45f2f8ea":"markdown","133ba220":"markdown","e2958fd1":"markdown","778b5348":"markdown","78a36a48":"markdown","fff4cfd8":"markdown","996ba433":"markdown","d3681a37":"markdown","c7649e93":"markdown","3ae038d7":"markdown","967426a9":"markdown"},"source":{"21b99fc0":"import cv2\nimport numpy as np\nimport os\nfrom matplotlib import pyplot as plt\n\n#see files in kaggle directory\n#listfiles=os.listdir(\"..\/input\")\n#print(listfiles)","e21bd14c":"# We will be previewing images alongthe way, so lets create a function\ndef previewImg(text,img_preview,grayscale=False):\n    #plt.imshow(img_preview)\n    if grayscale==False:\n        #convert a color image from BGR to RGB before previewing\n        plt.imshow(cv2.cvtColor(img_preview, cv2.COLOR_BGR2RGB))\n    else:\n        #option for Grayscale images\n        plt.imshow(cv2.cvtColor(img_preview, cv2.COLOR_GRAY2RGB))\n    plt.title(text)\n    plt.show()\n","d10c33bb":"#load the example.  It is a white piece, the most difficult to detect!\nimg_example=cv2.imread('..\/input\/example_2_Base Image.jpg')\n\n#load a background, so we can extract it and make it easy to detect the object.\nimg_bg=cv2.imread('..\/input\/background_backlit_A.jpg')","e0f9df65":"# our starting Point\npreviewImg('Background Image',img_bg)\npreviewImg('Example Image',img_example)","c22b4110":"# Background - Gray\nimg_bg_gray=cv2.cvtColor(img_bg, cv2.COLOR_BGR2GRAY)\npreviewImg(\"Background Gray\",img_bg_gray,True)\n# Image - Gray\nimg_gray=cv2.cvtColor(img_example, cv2.COLOR_BGR2GRAY)\npreviewImg(\"Image Gray\",img_gray,True)","1bd45e35":"# Calculate Difference\ndiff_gray=cv2.absdiff(img_bg_gray,img_gray)\npreviewImg(\"Pre-Diff\",diff_gray,True)","e0880624":"# Diff Blur\ndiff_gray_blur = cv2.GaussianBlur(diff_gray,(5,5),0)\npreviewImg(\"Pre-Diff Blur\",diff_gray_blur,True)","eb990b48":"# find otsu's threshold value with OpenCV function\nret, img_tresh = cv2.threshold(diff_gray_blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\npreviewImg(\"Otsu Treshold\",img_tresh,True)","b2da6de0":"# let's now draw the contour\na1, arr_cnt, a2 = cv2.findContours(img_tresh, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n\n# let's copy the example image, so we don't paint over it\nimg_with_allcontours=img_example.copy()\n\ncv2.drawContours(img_with_allcontours, arr_cnt, -1, (0,255,0), 3)\npreviewImg('Contours',img_with_allcontours)\n\n# !!! It may be possible that various contours are showing at this stage, we'll solve that below.","1cff2328":"# Just in case, we need to make sure we 'weed out' any contour noise that might generate as images have variations.\n\n# get the dimensions of the image\nheight, width, channels = img_example.shape\n\n# shorten the variable names\nw=width\nh=height\n\nvalidcontours=[]\ncontour_index=-1\n\n# iterate through each contour found\nfor i in arr_cnt:\n\n    contour_index=contour_index+1\n    ca=cv2.contourArea(i)\n\n    # Calculate W\/H Ratio of image\n    x,y,w,h = cv2.boundingRect(i)\n    aspect_ratio = float(w)\/h\n\n    # Flag as edge_noise if the object is at a Corner\n    # Contours at the edges of the image are most likely not valid contours\n    edge_noise=False\n    # if contour starts at x=0 then it's on th edge\n    if x==0:\n        edge_noise=True\n    if y==0:\n        edge_noise=True\n    # if the contour x value + its contour width exceeds image width, it is on an edge\n    if (x+w)==width:\n        edge_noise=True\n    if (y+h)==height:\n        edge_noise=True\n            \n    # DISCARD noise with measure by area (1x1 round plate dimensions is 1300)\n    # if by any chance a contour is drawn on one pixel, this catches it.\n    if ca>1300:\n\n        # DISCARD as noise if W\/H ratio > 7 to 1 (1x6 plate is 700px to 100px)\n        # the conveyor belt has a join line that sometimes is detected as a contour, this ignores it based on w\/h ratio\n        if aspect_ratio<=6:\n            \n            # DISCARD if at the Edge\n            if edge_noise==False:\n                validcontours.append(contour_index)\n\n# copy the original picture\nimg_withcontours=img_example.copy()\n                \n# call out if more than 1 valid contour is found\nif len(validcontours)>1:\n    print(\"There is more than 1 object in the picture\")\nelse:\n    if len(validcontours)==1:\n        print(\"One object detected\")\n    else:\n        print(\"No objects detected\")\n        # FYI: code below will most likely error out as it tries to iterate on an array\n    \n# it might be possible we have more than 1 validcontour, iterating through them here\n# if there is zero contours, this most likely will error out\nfor i in validcontours:                           \n    cv2.drawContours(img_withcontours, arr_cnt,validcontours[i], (0,255,0), 3)\n    previewImg('Contours',img_withcontours)\n\n","7f0b8c28":"# Display a Bounding Rectangle\nimg_withrectangle=img_example.copy()\nfor i in validcontours:\n    x,y,w,h = cv2.boundingRect(arr_cnt[i])\n    cv2.rectangle(img_withrectangle,(x,y),(x+w,y+h),(0,255,0),2)\n    previewImg('Bounding Rectangle',img_withrectangle)","45f2f8ea":"**Step 2**\n\nThe background is the same in each images, so we will subtract the background from the base image to make sure the object is much more detectable.\n\nThe output is the \"difference\" between both images (you can play around and skipt his step).","133ba220":"**Optional Step**\n\nIt may be possible that we have more than one object\/Lego piece in the picture or the algorithm is detecting some noise as contours.\n\nThis step here let's us eliminate these \"noises\".   The data set I'm running this Kernel on is cleaned, this would only apply to real case scenarios.\n\nI run 3 conditions:\n* minimum area to consider an object (e.g. anything smaller than a 1x1 brick I will consider noise).\n* if the object is sitting in an edge (the brick is clipped)\n* if the object has a ratio that exceeds the objects (in this case, the 1x6 plate is the thinnest piece to detect, anything with a longer ratio will be considered noise)","e2958fd1":"**Staring Point**\n\nVisually this is our starting point (I'm using our defined function above).","778b5348":"**Step 5**\n\nWe use the image from Step 4 to detect the contour using OpenCV findContours function and draw them in green color.\n\nWe now have the contours, so we will draw them on top of the Original image.","78a36a48":"**Optional Step**\n\nIf you need to crop the image, it will be useful to be able to identify a rectangle.\n\nTo achieve this, use OpenCV bounding rectangle function.","fff4cfd8":"**Step 4**\n\nNow we apply Thresholding, which means that the algorithm will decide to placer pixels in either the background or foreground (binary).\n\nWe use the Otsu algorithm which iterates across the ideal values for this separation.","996ba433":"**Step 1**\n\nWe know proceed to convert these images to Grayscale, and then preview them.","d3681a37":"**Step 3**\n\nApply some Gaussian blur, which makes the image smoother between pixels (and helps us focus the detection on sharper contours).","c7649e93":"Let's load the starting point.  The example image and it's background.","3ae038d7":"I want to show you what each image looks like after each step, so I am creating a function that will make it easy to preview each image as we go.\n\nOpenCV uses BGR while matplotlib uses RGB, so we need to make sure that put these conversion in so the picture look accurate (you can try previewing without these if you like to test).","967426a9":"**Overview**\n\nIn this example, we are going to use Open CV to detect the Lego piece.  The background of this data set is white, so the best place to test the approach is with a white piece.\n\n**Setup**\n\nWe start by importing the libraries we need.  OpenCV imshow doesn't work in this notebook, so we'll need to use matplotlib."}}