{"cell_type":{"b765da88":"code","7ead03b5":"code","15b6bc9a":"code","30ff8292":"code","ea5f708c":"code","aa81b74f":"code","46526604":"code","0ed8c0d2":"code","15791276":"code","4932bc2c":"code","442ff730":"code","8a9ee68f":"code","9c8b8426":"code","5ad85661":"code","810fbe53":"code","bd000276":"code","7dccd7b1":"code","71b6a938":"code","75f56374":"code","a884a3cb":"code","9027ba8c":"code","43e1d321":"code","9f5ebc06":"code","dcb56adb":"code","ed003424":"code","7a9baf8c":"code","52a1113e":"code","b9548981":"code","8e447af8":"code","62c7586d":"code","ed76957a":"code","9b0b0be3":"code","4db94473":"code","1306ea3c":"code","99489d1c":"code","436a4118":"code","1c91f335":"markdown","d3c362d9":"markdown","dd22d11a":"markdown","9467bee8":"markdown","b841896b":"markdown","fc7fa7a1":"markdown","e7383e56":"markdown","4ae223cc":"markdown","6cd9fb69":"markdown","695873d8":"markdown","3e85a6ed":"markdown","80e25d31":"markdown","5b1d91fe":"markdown","dea028f5":"markdown","4852118a":"markdown","234a8912":"markdown","3363cffa":"markdown","5f4ff23f":"markdown","eabb6a06":"markdown","99c4caa2":"markdown","8e00a7fd":"markdown","cb559a8f":"markdown","78e8b9fa":"markdown","197047d0":"markdown","20aad125":"markdown","d91d41bb":"markdown","58e57608":"markdown","93385561":"markdown","67f1638b":"markdown"},"source":{"b765da88":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport datetime\nimport os\n#print(os.listdir(\"..\/input\"))\n\nimport time\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","7ead03b5":"#make wider graphs\nsns.set(rc={'figure.figsize':(12,5)});\nplt.figure(figsize=(12,5));","15b6bc9a":"#import first 10,000,000 rows of train and all test data\ntrain = pd.read_csv('..\/input\/train.csv', nrows=10000000)\ntest = pd.read_csv('..\/input\/test.csv')","30ff8292":"train.head()","ea5f708c":"test.head()","aa81b74f":"variables = ['ip', 'app', 'device', 'os', 'channel']\nfor v in variables:\n    train[v] = train[v].astype('category')\n    test[v]=test[v].astype('category')","46526604":"#set click_time and attributed_time as timeseries\ntrain['click_time'] = pd.to_datetime(train['click_time'])\ntrain['attributed_time'] = pd.to_datetime(train['attributed_time'])\ntest['click_time'] = pd.to_datetime(test['click_time'])\n\n#set as_attributed in train as a categorical\ntrain['is_attributed']=train['is_attributed'].astype('category')","0ed8c0d2":"train.describe()","15791276":"train.isnull().sum()","4932bc2c":"plt.figure(figsize=(10, 6))\ncols = ['ip', 'app', 'device', 'os', 'channel']\nuniques = [len(train[col].unique()) for col in cols]\nsns.set(font_scale=1.2)\nax = sns.barplot(cols, uniques, log=True)\nax.set(xlabel='Feature', ylabel='log(unique count)', title='Number of unique values per feature (from 10,000,000 samples)')\nfor p, uniq in zip(ax.patches, uniques):\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height + 10,\n            uniq,\n            ha=\"center\") \n# for col, uniq in zip(cols, uniques):\n#     ax.text(col, uniq, uniq, color='black', ha=\"center\")","442ff730":"#double check that 'attributed_time' is not Null for all values that resulted in download (i.e. is_attributed == 1)\ntrain[['attributed_time', 'is_attributed']][train['is_attributed']==1].describe()","8a9ee68f":"#set click_id to categorical, for cleaner statistics view\ntest['click_id']=test['click_id'].astype('category')\ntest.describe()","9c8b8426":"plt.figure(figsize=(6,6))\n#sns.set(font_scale=1.2)\nmean = (train.is_attributed.values == 1).mean()\nax = sns.barplot(['App Downloaded (1)', 'Not Downloaded (0)'], [mean, 1-mean])\nax.set(ylabel='Proportion', title='App Downloaded vs Not Downloaded')\nfor p, uniq in zip(ax.patches, [mean, 1-mean]):\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()\/2.,\n            height+0.01,\n            '{}%'.format(round(uniq * 100, 2)),\n            ha=\"center\")","5ad85661":"#temporary table to see ips with their associated count frequencies\ntemp = train['ip'].value_counts().reset_index(name='counts')\ntemp.columns = ['ip', 'counts']\ntemp[:10]","810fbe53":"#add temporary counts of ip feature ('counts') to the train table, to see if IPs with high counts have conversions\ntrain= train.merge(temp, on='ip', how='left')","bd000276":"#check top 10 values\ntrain[train['is_attributed']==1].sort_values('counts', ascending=False)[:10]","7dccd7b1":"train[train['is_attributed']==1].ip.describe()","71b6a938":"#convert 'is_attributed' back to numeric for proportion calculations\ntrain['is_attributed']=train['is_attributed'].astype(int)","75f56374":"proportion = train[['ip', 'is_attributed']].groupby('ip', as_index=False).mean().sort_values('is_attributed', ascending=False)\ncounts = train[['ip', 'is_attributed']].groupby('ip', as_index=False).count().sort_values('is_attributed', ascending=False)\nmerge = counts.merge(proportion, on='ip', how='left')\nmerge.columns = ['ip', 'click_count', 'prop_downloaded']\n\nax = merge[:300].plot(secondary_y='prop_downloaded')\nplt.title('Conversion Rates over Counts of 300 Most Popular IPs')\nax.set(ylabel='Count of clicks')\nplt.ylabel('Proportion Downloaded')\nplt.show()\n\nprint('Counversion Rates over Counts of Most Popular IPs')\nprint(merge[:20])\n","a884a3cb":"proportion = train[['app', 'is_attributed']].groupby('app', as_index=False).mean().sort_values('is_attributed', ascending=False)\ncounts = train[['app', 'is_attributed']].groupby('app', as_index=False).count().sort_values('is_attributed', ascending=False)\nmerge = counts.merge(proportion, on='app', how='left')\nmerge.columns = ['app', 'click_count', 'prop_downloaded']\n\nax = merge[:100].plot(secondary_y='prop_downloaded')\nplt.title('Conversion Rates over Counts of 100 Most Popular Apps')\nax.set(ylabel='Count of clicks')\nplt.ylabel('Proportion Downloaded')\nplt.show()\n\nprint('Counversion Rates over Counts of Most Popular Apps')\nprint(merge[:20])","9027ba8c":"proportion = train[['os', 'is_attributed']].groupby('os', as_index=False).mean().sort_values('is_attributed', ascending=False)\ncounts = train[['os', 'is_attributed']].groupby('os', as_index=False).count().sort_values('is_attributed', ascending=False)\nmerge = counts.merge(proportion, on='os', how='left')\nmerge.columns = ['os', 'click_count', 'prop_downloaded']\n\nax = merge[:100].plot(secondary_y='prop_downloaded')\nplt.title('Conversion Rates over Counts of 100 Most Popular Operating Systems')\nax.set(ylabel='Count of clicks')\nplt.ylabel('Proportion Downloaded')\nplt.show()\n\nprint('Counversion Rates over Counts of Most Popular Operating Systems')\nprint(merge[:20])","43e1d321":"proportion = train[['device', 'is_attributed']].groupby('device', as_index=False).mean().sort_values('is_attributed', ascending=False)\ncounts = train[['device', 'is_attributed']].groupby('device', as_index=False).count().sort_values('is_attributed', ascending=False)\nmerge = counts.merge(proportion, on='device', how='left')\nmerge.columns = ['device', 'click_count', 'prop_downloaded']\n\nprint('Count of clicks and proportion of downloads by device:')\nprint(merge)","9f5ebc06":"proportion = train[['channel', 'is_attributed']].groupby('channel', as_index=False).mean().sort_values('is_attributed', ascending=False)\ncounts = train[['channel', 'is_attributed']].groupby('channel', as_index=False).count().sort_values('is_attributed', ascending=False)\nmerge = counts.merge(proportion, on='channel', how='left')\nmerge.columns = ['channel', 'click_count', 'prop_downloaded']\n\nax = merge[:100].plot(secondary_y='prop_downloaded')\nplt.title('Conversion Rates over Counts of 100 Most Popular Apps')\nax.set(ylabel='Count of clicks')\nplt.ylabel('Proportion Downloaded')\nplt.show()\n\nprint('Counversion Rates over Counts of Most Popular Channels')\nprint(merge[:20])","dcb56adb":"train_smp = pd.read_csv('..\/input\/train_sample.csv')","ed003424":"train_smp.head(7)","7a9baf8c":"#convert click_time and attributed_time to time series\ntrain_smp['click_time'] = pd.to_datetime(train_smp['click_time'])\ntrain_smp['attributed_time'] = pd.to_datetime(train_smp['attributed_time'])","52a1113e":"#round the time to nearest hour\ntrain_smp['click_rnd']=train_smp['click_time'].dt.round('H')  \n\n#check for hourly patterns\ntrain_smp[['click_rnd','is_attributed']].groupby(['click_rnd'], as_index=True).count().plot()\nplt.title('HOURLY CLICK FREQUENCY');\nplt.ylabel('Number of Clicks');\n\ntrain_smp[['click_rnd','is_attributed']].groupby(['click_rnd'], as_index=True).mean().plot()\nplt.title('HOURLY CONVERSION RATIO');\nplt.ylabel('Converted Ratio');","b9548981":"#extract hour as a feature\ntrain_smp['click_hour']=train_smp['click_time'].dt.hour","8e447af8":"train_smp.head(7)","62c7586d":"train_smp[['click_hour','is_attributed']].groupby(['click_hour'], as_index=True).count().plot(kind='bar', color='#a675a1')\nplt.title('HOURLY CLICK FREQUENCY Barplot');\nplt.ylabel('Number of Clicks');\n\ntrain_smp[['click_hour','is_attributed']].groupby(['click_hour'], as_index=True).count().plot(color='#a675a1')\nplt.title('HOURLY CLICK FREQUENCY Lineplot');\nplt.ylabel('Number of Clicks');","ed76957a":"train_smp[['click_hour','is_attributed']].groupby(['click_hour'], as_index=True).mean().plot(kind='bar', color='#75a1a6')\nplt.title('HOURLY CONVERSION RATIO Barplot');\nplt.ylabel('Converted Ratio');\n\ntrain_smp[['click_hour','is_attributed']].groupby(['click_hour'], as_index=True).mean().plot( color='#75a1a6')\nplt.title('HOURLY CONVERSION RATIO Lineplot');\nplt.ylabel('Converted Ratio');","9b0b0be3":"#adapted from https:\/\/stackoverflow.com\/questions\/9103166\/multiple-axis-in-matplotlib-with-different-scales\n#smonek's answer\n\n\ngroup = train_smp[['click_hour','is_attributed']].groupby(['click_hour'], as_index=False).mean()\nx = group['click_hour']\nymean = group['is_attributed']\ngroup = train_smp[['click_hour','is_attributed']].groupby(['click_hour'], as_index=False).count()\nycount = group['is_attributed']\n\n\nfig = plt.figure()\nhost = fig.add_subplot(111)\n\npar1 = host.twinx()\n\nhost.set_xlabel(\"Time\")\nhost.set_ylabel(\"Proportion Converted\")\npar1.set_ylabel(\"Click Count\")\n\n#color1 = plt.cm.viridis(0)\n#color2 = plt.cm.viridis(0.5)\ncolor1 = '#75a1a6'\ncolor2 = '#a675a1'\n\np1, = host.plot(x, ymean, color=color1,label=\"Proportion Converted\")\np2, = par1.plot(x, ycount, color=color2, label=\"Click Count\")\n\nlns = [p1, p2]\nhost.legend(handles=lns, loc='best')\n\nhost.yaxis.label.set_color(p1.get_color())\npar1.yaxis.label.set_color(p2.get_color())\n\nplt.savefig(\"pyplot_multiple_y-axis.png\", bbox_inches='tight')","4db94473":"sns.barplot('click_hour', 'is_attributed', data=train_smp)\nplt.title('HOURLY CONVERSION RATIO');\nplt.ylabel('Converted Ratio');","1306ea3c":"train_smp['timePass']= train_smp['attributed_time']-train_smp['click_time']\n#check:\ntrain_smp[train_smp['is_attributed']==1][:15]","99489d1c":"train_smp['timePass'].describe()","436a4118":"#check first 10,000,000 of actual train data\ntrain['timePass']= train['attributed_time']-train['click_time']\ntrain['timePass'].describe()","1c91f335":"There appear to be a few peaks for channels at reasonable click quantity, but overall the pattern holds same as for categories above.  ","d3c362d9":"**Quick Notes\/Observations** :\n- There are only 18717 attributed_time values.  This means only 18,717 out of 10,000,000 clicks resulted in a download.  That's less than 0.2% !\n- There are ip adresses that trigger  a click over 50 thousand times.  Seems strange that one ip address would click that often in a span of just 4 days.  Does that mean that ip address encoded is not device id, but network id?  (explore this below)\n- First click in train set is on 2017-11-06 14:32:21.  Test clicks start on  2017-11-10.  Based on data specifications, train coveres a 4 day period.  This means that the train and test data do not overlap, but test data is taken the day after train data ends.\n-Train data is ordered by timestamp.  (therefore batches pulled in order cover limited time span)\n- 2017-11-06 was a Monday.   2017-11-10 was a Friday.  i.e. Train is Mon-Thur, Test is Friday\n-There is no missing data in Test.  Missing values in train appear to be only for attributed_time, where there isn't any value due to no app download.","dd22d11a":"This notebook is built using some of ideas in the book by *anokas* at  https:\/\/www.kaggle.com\/anokas\/talkingdata-adtracking-eda  .  I suggest reviewing that book first.\n\nFor this part I use  the first 10 million rows from train ( as the complete sets are too big for this kernel) and the full test data.\n\nNote:  in the notebook I sometimes refer to downloads as conversions.  i.e. is_attributed == 1  means the click converted.","9467bee8":"And number of conversions by hours:","b841896b":"The proportions may be more reliable if estimated on full data.  With the random sample it's  hard too tell because the variability is too high, especially for the hours with low click counts.   i.e. the fewer clicks\/conversions, the wider margin of the estimated conversion ratio.  (see below)","fc7fa7a1":"It takes as long as (almost) 20 hours to go from click to purchase and as little as 4 seconds.  \n\nThe 4 seconds seems to low to make a decision.  This person would have either seen the ad before, or already been aware of the product some other way.\n\nDoes that mean the ad was clicked on multiple times, but only one click was counted as conversion?   Or did the person click on the ad specifically with the intent to download?  (eg, if channel is something like google search, the ad could be clicked during search results view and app downloaded immediately because that's what the person intended to do right away)\n\nRaises questions to explore:\n   - How accurately are conversions tracked? How are clicks and downloads linked?  What happens if download after multiple clicks?  Is there a way to identify likely same users (same IP, Device, etc...)","e7383e56":"### Look into attributed_time\nIt could be useful to learn more about conversions that did take place.\nLet's see how much time passed from clicking on the ad to downloading it.","4ae223cc":"Conversions are noisy and do not appear to correlate with how popular an IP is.","6cd9fb69":"Now lets do a quick inspection of train and test data main statistics","695873d8":"Same story. For values in the thousands the boundary on the ratio is very low, roughly between 0.0006 and 0.003, but as counts on OS become lower, the ratio starts fluxuating more wildely.","3e85a6ed":"### Conversions by Device\n\nDevices are extremely disproportionately distributed, with number one device used almost 94% of time.  For that device proportion download was 0.001326. (0.13%)","80e25d31":"let's overlay the two graphs to see if patterns correlate in any way","5b1d91fe":"Only a small proportion of clicks were followed by a download:","dea028f5":"Here minimum time from click to download is virtually instanteneous.  How is this possible?  It is clearly not a result of a human decision made from clicking on an ad seen for the first time.","4852118a":"### Check actual train data (the first 10,000,000)\ndouble check the same feature on the first 10 million rows of train data:","234a8912":"*this graph is adapted from https:\/\/www.kaggle.com\/anokas\/talkingdata-adtracking-eda*:","3363cffa":"### Conversions by App\n\nCheck 100 most popular apps by click count:","5f4ff23f":"### Conversions by Channel\n","eabb6a06":"There is no clear hourly time pattern in ratios, however there is a definete pattern in frequency of clicks based on time of day.\n\nLets extract the hour of day from each day as a separate feature, and see combined trend (merge the 4 days together by hour).","99c4caa2":"### Conversion rates over Counts of 300 most popular IPs","8e00a7fd":"### Explore ip counts.  Check if multiple ips have any downloads.\n\nAt this point I was trying to figure out what 'ip' were actually encoding.  My original understanding that ips were user specific did not hold up to scrutiny.\nIf ip repeated too many times, was it a bot?  This does not appear to be true, as repeated ips do convert.  See below:","cb559a8f":"ip, app, device, os and channel are actually categorical variables encoded as integers.   Set them as categories for analysis.","78e8b9fa":"### Conversions by OS\nLook at top 100 operating systems by click count","197047d0":"Convert date stamps to date\/time type.","20aad125":"Quick check to make sure that Nan values in 'attribute_time' are only for samples that did not convert.  Check that counts of 'attributed_time' values is same as count of converted clicks.","d91d41bb":"Let's check number of clicks by hour:","58e57608":"# Checking for time patterns\n\nRound the click time down to an hour of the day to see if there are any hourly patterns.\n\nFor this part cannot use the first n rows from train data, as it's organized by time.  To get a genral idea for the pattern, will use train data from the randomly sampled 100000 train set provided by organizers.","93385561":"There is a again a huge difference in clicks per app, with minimum of one click on an app and max at almost 13 million.  The proportion flucuates more as the counts go down, since each additional click has larger impact on the proportion value.  In general, for apps with counts in the thousands the ratio stays within 0.0001 - 0.0015 boundary.  For less popular apps it fluxuates more widely.  ","67f1638b":"So high frequency ip counts do get conversions.   Up to 56 downloads for one ip.  Each IP must be for some network with many devices."}}