{"cell_type":{"fd05ba46":"code","eca1c535":"code","3b2bd574":"code","053a8494":"code","4ecd9cca":"code","f187d9e6":"code","99beb082":"code","f7f8466d":"code","4dad695b":"code","448d8371":"code","cad43dfb":"code","474bba93":"code","8ea347d0":"code","3893891d":"code","704bdf96":"code","36b9f59b":"code","f64ef7b4":"code","1dea008a":"code","2537a187":"code","25e9b425":"code","a11ac061":"code","ba564239":"code","f8161990":"code","6ed1a678":"code","5d98eb19":"code","fe1b7ef8":"code","d321b624":"code","044a76e2":"code","89a2995b":"code","9e808892":"code","bb0f7698":"code","1b762779":"code","7ca9dbc5":"code","7b504761":"code","d18b2210":"code","416b0113":"code","567a4c3a":"code","3f37e278":"code","00038394":"code","9eca789a":"code","8998bf31":"code","e7dce197":"code","75e5645c":"code","f392e3f2":"code","bf20147c":"code","e5846cf4":"code","cfb0263e":"code","872e64ec":"code","2c846eda":"code","b14d0d5a":"code","8d5f3dc1":"code","df89561a":"code","539e8826":"code","e2d03036":"code","2fbe5408":"code","73e8247a":"code","c3244053":"code","b527c30b":"code","2196b023":"code","fc399b9d":"code","bea59d9e":"code","aeb754d1":"code","33082427":"code","c2079436":"code","de668620":"code","1d24f2ae":"code","12409b40":"code","0b16b314":"code","4c2502ee":"code","b34a5b63":"code","561b5eec":"code","c52fa4d9":"code","55227084":"code","89cfe8be":"code","4a32e6c4":"code","8dbf9d24":"code","22331283":"code","a11db52f":"code","69102a5d":"code","2408478e":"code","2c7c1ed0":"code","ba77fb75":"code","d86566c0":"code","1ae6db18":"code","3418979b":"code","08d833cf":"code","3e754ea5":"code","39e55dbe":"code","415aec4e":"code","3c5defbf":"code","9977991d":"code","37d176fc":"code","129e3c05":"code","d2ee8c43":"code","f6d0595a":"code","25a2a33f":"code","f50d295b":"code","0bfcee0e":"code","2ad45df1":"code","238db143":"code","790bf852":"code","81527ec9":"code","66c2876c":"code","300464fa":"code","d3c78fd4":"code","1a35d574":"code","f2137203":"code","246250af":"code","7a966954":"code","e4a8406c":"code","1fa5ab63":"code","8e10e435":"code","8b6e4faa":"code","991b7dd0":"code","13236765":"code","2f638591":"code","ba65052b":"code","10feaa07":"code","295edf1d":"code","a71c94de":"code","ecf9aa07":"code","06e30bb1":"code","ad403c2a":"code","2368cc71":"code","366471af":"code","1fbe0f26":"code","75df7f1e":"code","8b5ffabf":"code","5de7d19d":"code","366296b2":"markdown","7d39c132":"markdown","c6274695":"markdown","8ba340ac":"markdown","a7700ddf":"markdown","9bc6eb6e":"markdown","edf56b9f":"markdown","d61d1612":"markdown","f1396708":"markdown","0544d029":"markdown","e7aa562b":"markdown","2e5a7024":"markdown","859cc45d":"markdown","9d9fd3fc":"markdown","cb009446":"markdown","bfd98718":"markdown","0a85da48":"markdown","27c4cf2b":"markdown","ebe28548":"markdown","6057192c":"markdown","245fc515":"markdown","6945dd62":"markdown","a8729a15":"markdown","792d3ec8":"markdown","5959e828":"markdown","2036c183":"markdown","1feb1400":"markdown","30b0f450":"markdown","69ac7fd6":"markdown","845e1f11":"markdown","11d58a08":"markdown","d0f58009":"markdown","647d3894":"markdown","70c9c65f":"markdown","26908a34":"markdown","0a64ea9a":"markdown","2725d1c7":"markdown","2af0bd7b":"markdown","ccd3ce41":"markdown","44dc2884":"markdown"},"source":{"fd05ba46":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n%matplotlib inline","eca1c535":"df = pd.read_csv('..\/input\/ames-housing-dataset\/AmesHousing.csv')","3b2bd574":"df.head()","053a8494":"df.info()","4ecd9cca":"df.corr()['SalePrice'].sort_values()","f187d9e6":"sns.scatterplot(data=df , x='Overall Qual',y='SalePrice')\nplt.axhline(y=200000,color='r')","99beb082":"df[(df['Overall Qual']>8)&(df['SalePrice']<200000)][['Overall Qual','SalePrice']]","f7f8466d":"sns.scatterplot(x='Gr Liv Area', y='SalePrice', data=df)\nplt.axhline(y=200000, color='r')\nplt.axvline(x=4000, color='r')\nplt.axhline(y=700000, color='r')","4dad695b":"df[(df['Gr Liv Area']>4000) & (df['SalePrice']<400000)][['SalePrice', 'Gr Liv Area']]\n","448d8371":"df[(df['Gr Liv Area']>4000) & (df['SalePrice']>700000)][['SalePrice', 'Gr Liv Area']]","cad43dfb":"df[(df['Overall Qual']>8)&(df['SalePrice']>700000)][['Overall Qual','SalePrice']]","474bba93":"#Remove the outliers:\nindex_drop=df[(df['Gr Liv Area']>4000) & (df['SalePrice']<400000) ].index\ndf=df.drop(index_drop, axis=0)","8ea347d0":"sns.boxplot(x='Overall Qual', y='SalePrice', data=df)","3893891d":"index_drop=df[(df['Gr Liv Area']>4000) & (df['SalePrice']>700000) ].index\ndf=df.drop(index_drop, axis=0)","704bdf96":"sns.scatterplot(x='Gr Liv Area', y='SalePrice', data=df)\nplt.axhline(y=200000, color='r')\nplt.axvline(x=4000, color='r')","36b9f59b":"sns.scatterplot(x='Overall Qual', y='SalePrice', data=df)\nplt.axhline(y=200000,color='r')","f64ef7b4":"df[(df['Overall Qual']>8)&(df['SalePrice']<200000)][['Overall Qual','SalePrice']]","1dea008a":"#Remove the outliers:\nindex_drop=df[(df['Overall Qual']>8) & (df['SalePrice']<200000) ].index\nindex_drop=df[(df['Overall Qual']==8 ) & (df['SalePrice']>500000) ].index\ndf=df.drop(index_drop, axis=0)","2537a187":"sns.scatterplot(x='Overall Qual', y='SalePrice', data=df)\n","25e9b425":"index_drop=df[(df['Overall Qual']==6) & (df['SalePrice']>400000) ].index\ndf=df.drop(index_drop, axis=0)\nsns.scatterplot(x='Overall Qual', y='SalePrice', data=df)\n","a11ac061":"index_drop=df[(df['Overall Qual']==9) & (df['SalePrice']<200000) ].index\ndf=df.drop(index_drop, axis=0)\nsns.scatterplot(x='Overall Qual', y='SalePrice', data=df)\n","ba564239":"sns.boxplot(x='Overall Qual', y='SalePrice', data=df)","f8161990":"\n\nsns.scatterplot(x='Gr Liv Area', y='SalePrice', data=df)\nplt.axhline(y=500000,color='r')","6ed1a678":"index_drop=df[(df['Gr Liv Area']>2000) & (df['SalePrice']>500000) ].index\ndf=df.drop(index_drop, axis=0)\nsns.scatterplot(x='Gr Liv Area', y='SalePrice', data=df)","5d98eb19":"sns.scatterplot(x='Garage Cars',y='SalePrice',data=df)","fe1b7ef8":"df[(df['Garage Cars']>4) & (df['SalePrice']<200000)][['SalePrice', 'Garage Cars']]\n","d321b624":"index_drop=df[(df['Garage Cars']>4) & (df['SalePrice']<200000) ].index\ndf=df.drop(index_drop, axis=0)","044a76e2":"sns.scatterplot(x='Garage Cars',y='SalePrice',data=df)","89a2995b":"df[(df['Garage Cars']==4) & (df['SalePrice']>400000)]['SalePrice']\n","9e808892":"index_drop=df[(df['Garage Cars']==4) & (df['SalePrice']>400000) ].index\ndf=df.drop(index_drop, axis=0)","bb0f7698":"sns.scatterplot(x='Garage Cars',y='SalePrice',data=df)","1b762779":"sns.scatterplot(x='Garage Area',y='SalePrice',data=df)\nplt.axvline(x=1200, color='r')","7ca9dbc5":"df[(df['Garage Area']>1200)]['SalePrice']\n","7b504761":"index_drop=df[(df['Garage Area']>1200)].index\ndf=df.drop(index_drop, axis=0)","d18b2210":"sns.scatterplot(x='Garage Area',y='SalePrice',data=df)\nplt.axvline(x=1200, color='r')\nplt.axhline(y=30000, color='r')","416b0113":"df[(df['Garage Area']>400) & (df['SalePrice']<30000)][['SalePrice', 'Garage Cars']]\n","567a4c3a":"index_drop=df[(df['Garage Area']>400) & (df['SalePrice']<30000) ].index\ndf=df.drop(index_drop, axis=0)\nsns.scatterplot(x='Garage Area',y='SalePrice',data=df)\nplt.axvline(x=1200, color='r')\nplt.axhline(y=30000, color='r')","3f37e278":"df.head()","00038394":"df= df.drop('PID', axis=1)","9eca789a":"df.isnull()","8998bf31":"\ndf.isnull().sum()","e7dce197":"\n100*(df.isnull().sum()\/len(df))","75e5645c":"def missing_percent(df):\n    nan_percent= 100*(df.isnull().sum()\/len(df))\n    nan_percent= nan_percent[nan_percent>0].sort_values()\n    return nan_percent","f392e3f2":"nan_percent= missing_percent(df)","bf20147c":"nan_percent","e5846cf4":"plt.figure(figsize=(12,6))\nsns.barplot(x=nan_percent.index, y=nan_percent)\nplt.xticks(rotation=90)","cfb0263e":"#every Feature with missing data must be checked!\n#We choose a threshold of 1%. It means, if there is less than 1% of a feature are missing,\n#then we will consider just dropping that rows\n\nplt.figure(figsize=(12,6))\nsns.barplot(x=nan_percent.index, y=nan_percent)\nplt.xticks(rotation=90)\n\n#Set 1% threshold:\nplt.ylim(0,1)","872e64ec":"nan_percent[nan_percent<1]","2c846eda":"nan_percent[nan_percent<1].index","b14d0d5a":"df[df['Electrical'].isnull()]","8d5f3dc1":"df[df['Garage Area'].isnull()]","df89561a":"df= df.dropna(axis=0, subset=['Electrical', 'Garage Area'])","539e8826":"nan_percent= missing_percent(df)\n\nplt.figure(figsize=(12,6))\nsns.barplot(x=nan_percent.index, y=nan_percent)\nplt.xticks(rotation=90)\nplt.ylim(0,1)","e2d03036":"df[df['Total Bsmt SF'].isnull()]","2fbe5408":"df[df['Bsmt Half Bath'].isnull()]","73e8247a":"df[df['Bsmt Full Bath'].isnull()]","c3244053":"\n#Numerical Columns fill with 0:\nbsmt_num_cols= ['BsmtFin SF 1', 'BsmtFin SF 2', 'Bsmt Unf SF','Total Bsmt SF' ,'Bsmt Full Bath', 'Bsmt Half Bath']\ndf[bsmt_num_cols]=df[bsmt_num_cols].fillna(0)\n\n#String Columns fill with None:\nbsmt_str_cols= ['Bsmt Qual', 'Bsmt Cond', 'Bsmt Exposure', 'BsmtFin Type 1', 'BsmtFin Type 2']\ndf[bsmt_str_cols]= df[bsmt_str_cols].fillna('None')","b527c30b":"nan_percent= missing_percent(df)\n\nplt.figure(figsize=(12,6))\nsns.barplot(x=nan_percent.index, y=nan_percent)\nplt.xticks(rotation=90)\nplt.ylim(0,1)","2196b023":"df[\"Mas Vnr Type\"]= df[\"Mas Vnr Type\"].fillna(\"None\")\ndf[\"Mas Vnr Area\"]= df[\"Mas Vnr Area\"].fillna(0)","fc399b9d":"   nan_percent= missing_percent(df)\n\nplt.figure(figsize=(12,6))\nsns.barplot(x=nan_percent.index, y=nan_percent)\nplt.xticks(rotation=90)","bea59d9e":"df[['Garage Type', 'Garage Yr Blt', 'Garage Finish', 'Garage Qual', 'Garage Cond']]","aeb754d1":"#Filling the missing Value:\nGar_str_cols= ['Garage Type', 'Garage Finish', 'Garage Qual', 'Garage Cond']\ndf[Gar_str_cols]=df[Gar_str_cols].fillna('None')\n\ndf['Garage Yr Blt']=df['Garage Yr Blt'].fillna(0)","33082427":"nan_percent= missing_percent(df)\n\nplt.figure(figsize=(12,6))\nsns.barplot(x=nan_percent.index, y=nan_percent)\nplt.xticks(rotation=90)\n","c2079436":"df= df.drop(['Fence', 'Alley', 'Misc Feature','Pool QC'], axis=1)","de668620":"nan_percent= missing_percent(df)\n\nplt.figure(figsize=(12,6))\nsns.barplot(x=nan_percent.index, y=nan_percent)\nplt.xticks(rotation=90)","1d24f2ae":"#Filling in Fireplace Quality based on dataset documentation:\ndf['Fireplace Qu']= df['Fireplace Qu'].fillna('None')","12409b40":"nan_percent= missing_percent(df)\n\nplt.figure(figsize=(12,6))\nsns.barplot(x=nan_percent.index, y=nan_percent)\nplt.xticks(rotation=90)","0b16b314":"df['Neighborhood'].unique()","4c2502ee":"plt.figure(figsize=(8,12))\nsns.boxplot(data=df, x='Lot Frontage', y='Neighborhood')","b34a5b63":"#Impute missing data based on other columns:\n\ndf.groupby('Neighborhood')['Lot Frontage']","561b5eec":"df.groupby('Neighborhood')['Lot Frontage'].mean()","c52fa4d9":"df.groupby('Neighborhood')['Lot Frontage'].transform(lambda val: val.fillna(val.mean()))","55227084":"df['Lot Frontage']=df.groupby('Neighborhood')['Lot Frontage'].transform(lambda val: val.fillna(val.mean()))","89cfe8be":"nan_percent= missing_percent(df)\n\nplt.figure(figsize=(12,6))\nsns.barplot(x=nan_percent.index, y=nan_percent)\nplt.xticks(rotation=90)","4a32e6c4":"df['Lot Frontage']= df['Lot Frontage'].fillna(0)","8dbf9d24":"nan_percent= missing_percent(df)","22331283":"nan_percent","a11db52f":"df.head()","69102a5d":"df.info()","2408478e":"df['Paved Drive']","2c7c1ed0":"df['MS SubClass'].unique()","ba77fb75":"#Convert to String:\ndf['MS SubClass']= df['MS SubClass'].apply(str)","d86566c0":"df.info()\n#or: df['MS SubClass'].dtype","1ae6db18":"df.select_dtypes(include='object')","3418979b":"df_num= df.select_dtypes(exclude='object')\ndf_obj= df.select_dtypes(include='object')","08d833cf":"df_num.info()","3e754ea5":"df_obj.info()","39e55dbe":"# Converting objects to number by one-hot encoding(drop_first=True:removes multi-collinearity)\ndf_obj= pd.get_dummies(df_obj, drop_first=True)","415aec4e":"df_obj.shape","3c5defbf":"Final_df= pd.concat([df_num, df_obj], axis=1)","9977991d":"Final_df.head()","37d176fc":"Final_df.shape","129e3c05":"Final_df.info()","d2ee8c43":"X=Final_df.drop('SalePrice', axis=1)\ny=Final_df['SalePrice']","f6d0595a":"X","25a2a33f":"y","f50d295b":"#split dataset to train and test(using sickit learn)\nfrom sklearn.model_selection import train_test_split","0bfcee0e":"X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.2, random_state=101)","2ad45df1":"#train the model\nfrom sklearn.linear_model import LinearRegression","238db143":"linear_regression_model= LinearRegression()","790bf852":"linear_regression_model.fit(X_train,y_train)","81527ec9":"pd.DataFrame(linear_regression_model.coef_ ,X.columns, columns=[\"coeficients\"])","66c2876c":"#prediction\ny_pred=linear_regression_model.predict(X_test)","300464fa":"#Evaluating\nfrom sklearn import metrics\nMAE=metrics.mean_absolute_error(y_test,y_pred)\nMSE=metrics.mean_squared_error(y_test,y_pred)\nRMSE=np.sqrt(MSE)\n\npd.DataFrame([MAE,MSE,RMSE],index=['MAE','MSE','RMSE'],columns=['metrics'])","d3c78fd4":"#compare the metrics to the mean of terget variable\nFinal_df['SalePrice'].mean()","1a35d574":"#Residual\ntest_residual = y_test - y_pred","f2137203":"sns.displot(test_residual, bins=25,kde=True)","246250af":"sns.scatterplot(x=y_test,y=test_residual) #i think it has pattern\nplt.axhline(y=0, color='red', ls='--')","7a966954":"from sklearn.preprocessing import PolynomialFeatures\npolynomial_converter = PolynomialFeatures(degree=2 ,include_bias=False)\npolynomial_features = polynomial_converter.fit_transform(X)","e4a8406c":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()","1fa5ab63":"scaler.fit(X_train)\nX_train=scaler.transform(X_train)\nX_test=scaler.transform(X_test)","8e10e435":"from sklearn.linear_model import RidgeCV\nridge_cv_model = RidgeCV(alphas=(0.1, 1.0, 10.0), scoring='neg_mean_absolute_error') #scoring calculate based on our metrics. cv=None is equals to leave_one_out technique\nridge_cv_model.fit(X_train, y_train)","8b6e4faa":"print(f'the best hyperparameters value is: {ridge_cv_model.alpha_}')","991b7dd0":"y_pred_ridge = ridge_cv_model.predict(X_test)","13236765":"from sklearn.metrics import mean_absolute_error, mean_squared_error\nMAE = mean_absolute_error(y_test, y_pred_ridge)\nMSE = mean_squared_error (y_test, y_pred_ridge)\nRMSE = np.sqrt(MSE)\n\npd.DataFrame([MAE,MSE,RMSE],index=['MAE','MSE','RMSE'],columns=['metrics'])","2f638591":"ridge_cv_model.coef_ #now coefficients are smaller","ba65052b":"from sklearn.linear_model import LassoCV","10feaa07":"lasso_cv_model = LassoCV(eps = 0.1 , n_alphas=100, cv=5)","295edf1d":"lasso_cv_model.fit(X_train,y_train)","a71c94de":"lasso_cv_model.alpha_","ecf9aa07":"y_pred_lasso = lasso_cv_model.predict(X_test)","06e30bb1":"#let's Evaluate again\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nMAE = mean_absolute_error(y_test, y_pred_lasso)\nMSE = mean_squared_error (y_test, y_pred_lasso)\nRMSE = np.sqrt(MSE)\n\npd.DataFrame([MAE,MSE,RMSE],index=['MAE','MSE','RMSE'],columns=['metrics'])","ad403c2a":"lasso_cv_model.coef_ #eliminated some features","2368cc71":"from sklearn.linear_model import ElasticNetCV","366471af":"elastic_model = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1],cv=5,max_iter=100000)","1fbe0f26":"elastic_model.fit(X_train,y_train)","75df7f1e":"y_pred_elastic = elastic_model.predict(X_test)","8b5ffabf":"#let's Evaluate again\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nMAE = mean_absolute_error(y_test, y_pred_elastic)\nMSE = mean_squared_error (y_test, y_pred_elastic)\nRMSE = np.sqrt(MSE)\n\npd.DataFrame([MAE,MSE,RMSE],index=['MAE','MSE','RMSE'],columns=['metrics'])","5de7d19d":"elastic_model.coef_","366296b2":"****Remove the Columns with more than 80% missing values****","7d39c132":"**we can show these ouliers by box plot too**","c6274695":"**Removing the PID (We already have an index, so we don't need PID unique identifier.** \n\n**becuase it doesn't have any information and can't help our learning models)**\n\n\n**note that:if PID could give us some information we do not have to drop them we should change them to another feature instead.**","8ba340ac":"If only a few rows are missing some values, then it might just be a good idea to drop those rows.\n\nWhat does this cost you in terms of performace? It essentialy removes potential training\/testing data, but if its only a few rows, its unlikely to change performance.\n\nSometimes it is a good idea to remove a feature entirely if it has too many null values. However, you should carefully consider why it has so many null values, in certain situations null could just be used as a separate category.\n\n(Take for example a feature column for the number of cars that can fit into a garage. Perhaps if there is no garage then there is a null value, instead of a zero. It probably makes more sense to quickly fill the null values in this case with a zero instead of a null. Only you can decide based off your domain expertise and knowledge of the data set!)\n","a7700ddf":"**let's see who are these outliers? it seems probably these values are given wrong.**","9bc6eb6e":"**we can check for the rest of the data to see if they are outliers or not and then drop them.**\n\n**\u0645\u0627 \u0628\u0627\u06cc\u062f \u0627\u06cc\u0646 \u06a9\u0627\u0631\u0648 \u0628\u0631\u0627\u06cc \u0647\u0645\u0647  \u06cc \u062f\u0627\u062f\u0647 \u0647\u0627\u06cc\u06cc \u06a9\u0647 \u0628\u0647 \u0646\u0638\u0631 \u067e\u0631\u062a \u0647\u0633\u062a\u0646 \u0627\u0646\u062c\u0627\u0645 \u0628\u062f\u06cc\u0645 \u0627\u0645\u0627 \u0627\u0648\u0646\u0627\u06cc\u06cc \u06a9\u0647 \u0647\u0645\u0628\u0633\u062a\u06af\u06cc \u0628\u06cc\u0634\u062a\u0631\u06cc \u062f\u0627\u0631\u0646 \u062a\u0627\u062b\u06cc\u0631 \u0628\u06cc\u0634\u062a\u0631\u06cc \u062f\u0631 \u0645\u062f\u0644 \u0645\u0627 \u062f\u0627\u0631\u0646\u062f.**","edf56b9f":"# Why Data Cleaning?\n**this technique prepare our data set for modeling and analysis.**\n\n**it creates usable features for the model.because for most algorithm we need to make sure features are float or int**\n\n**In data cleaning we will deal with some issues:**\n* Outliers data\n* Missing data\n* Categorical data\n\n# Categorical data:\n**three approaches in feature extraction:**\n* Extracting information: convert non-number information to int or float.\n* Combining information: like polynomial regression.\n* Transforming information: common for string data. it converts categorical variables from string to number.(integer encoding **|** one-hot encoding)\n\n![encoding.jpg](attachment:74936af0-74c9-4a85-b1a5-1e2d43f9e008.jpg)\n\n**Note:in one-hot encoding we alwayes have multi-collinearity.so we eliminate of the columns.**","d61d1612":"**\"Overal Quality\" has the most correlation with sale price and then \"Gr Liv Area\". these features has the most impact on SalePrice.**","f1396708":"**After checking the data documentation,\nit shows that missing value (two rows) in Basement Features are becouse of there is no basement in these rows\nDecision: Filling in data based on column: numerical basement & string descriptive:**","0544d029":"### 1-Ridge Regression","e7aa562b":"**let's get started:**","2e5a7024":"**Make a Function to calculate the percent of missing data in each columns (feature) and then sort it**","859cc45d":"****","9d9fd3fc":"# Linear Regression","cb009446":"**Now, the Dataset is Ready for any Machine Learing Model & Analysis**","bfd98718":"A- Numerical Columns to Categorical\nWe need to be careful when it comes to encoding categorical as numbers. We want to make sure that the numerical relationship makes sense for model. For example, the encoding MSSubClass is essentially just a code per class","0a85da48":"**Garage Columns:\nBased on the dataset documentation, NaN in Garage Columns seems to indicate no garage.\nDecision: Fill with 'None' or 0**","27c4cf2b":"**\u0628\u0627 \u062a\u0648\u062c\u0647 \u0628\u0647 \u062f\u0627\u062f\u0647 \u0647\u0627\u06cc \u0642\u0628\u0644\u06cc \u06a9\u0647 \u0628\u0627 \u0638\u0631\u0641\u06cc\u062a \u06af\u0627\u0631\u0627\u0698 \u06a9\u0645\u062a\u0631 \u0642\u06cc\u0645\u062a \u0628\u0627\u0644\u0627\u062a\u0631\u06cc \u062f\u0627\u0631\u0646\u062f. \u062f\u0627\u062f\u0647 \u06cc \u067e\u0646\u062c\u0645 \u0628\u0647 \u0627\u062d\u062a\u0645\u0627\u0644 \u0632\u06cc\u0627\u062f \u062f\u0627\u062f\u0647 \u06cc \u067e\u0631\u062a \u0627\u0633\u062a.**","ebe28548":"**Imputation of Missing Data**\n\nColumns: Lot Frontage\n\nWe assume that the Lot Frontage is related to what a Neighborhood a house is in","6057192c":"**now you see the outliers are eliminated**","245fc515":"**we want to know which one has the mosr=t correlation with \"SalePrice\"**","6945dd62":"# missing data:\n[https:\/\/en.wikipedia.org\/wiki\/Missing_data](http:\/\/)","a8729a15":"**Dropping Rows(based on domain knowledge):**","792d3ec8":"**Working base on Rows Missing Data**","5959e828":"B- Creating Dummy Variables","2036c183":"# Polynomial Regressoion with regularization","1feb1400":"**let's check another faeture with high correlation.**","30b0f450":"**3-Dealing with Categorical Data**","69ac7fd6":"**How Much Data is Missing?**","845e1f11":"**now we want recognize the outliers by scatter plot**","11d58a08":"# Outliers data:\n**detect outliers:**\n* box plot\n* Standard deviation(data>mean+3sigma , data<mean-3sigma)\n* utilize visualization plots\n[https:\/\/en.wikipedia.org\/wiki\/Outlier](http:\/\/)\n\n[https:\/\/towardsdatascience.com\/a-brief-overview-of-outlier-detection-techniques-1e0b2c19e561](http:\/\/)","d0f58009":"**In missing data we have to do one of these three tasks: 1)keep 2)drop 3)fill with another value.**","647d3894":"### 2-LASSO regularization:","70c9c65f":"**Working based on Columns Missing Data**","26908a34":"**Mas Vnr Features:**\n\n**Based on the Dataset Document File, missing values for 'Mas Vnr Type' and 'Mas Vnr Area' means the house doesn't have any mansonry veneer. so, we decide to fill the missing value as below:**","0a64ea9a":"**plot the feature with missing indicating the percent of missing data**","2725d1c7":"### 3-Elastic Net","2af0bd7b":"**as we saw these rows are equal to the previous table so definitely they are outliers.**\n\n**so we concider them as outliers.so we have to eliminate these ouliers to have a better modeling.**","ccd3ce41":"**we can see that for example in overal quality=10 we have two house that has a price below 200000**","44dc2884":"**The percent of missing data in any feature:**"}}