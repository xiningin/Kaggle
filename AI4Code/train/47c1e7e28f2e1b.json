{"cell_type":{"b1dbeb84":"code","252de156":"code","6998c9ec":"code","c0564efd":"code","b3776a2b":"code","c7cc5077":"code","3ed546f4":"code","f51fce6e":"code","6f839809":"code","e2f4f212":"code","f086a0bd":"markdown","d991fd02":"markdown","e6941c6d":"markdown","0378f6ca":"markdown","15a46c85":"markdown","0b9cd4ef":"markdown","45e4e4bb":"markdown","3151110d":"markdown"},"source":{"b1dbeb84":"import seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport os\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom sklearn import model_selection\nfrom keras import models, layers\n","252de156":"# this is for visualization\n# we can skip this part (not important)\n\nclass skeras() :\n    def save_history_history(fname, history_history, fold=''):\n        np.save(os.path.join(fold, fname), history_history)\n\n\n    def load_history_history(fname, fold=''):\n        history_history = np.load(os.path.join(fold, fname)).item(0)\n        return history_history\n\n\n    def plot_acc(history, title=None):\n        # summarize history for accuracy\n        if not isinstance(history, dict):\n            history = history.history\n\n        plt.plot(history['acc'])\n        plt.plot(history['val_acc'])\n        if title is not None:\n            plt.title(title)\n        plt.ylabel('Accracy')\n        plt.xlabel('Epoch')\n        plt.legend(['Training data', 'Validation data'], loc=0)\n        # plt.show()\n\n\n    def plot_loss(history, title=None):\n        # summarize history for loss\n        if not isinstance(history, dict):\n            history = history.history\n\n        plt.plot(history['loss'])\n        plt.plot(history['val_loss'])\n        if title is not None:\n            plt.title(title)\n        plt.ylabel('Loss')\n        plt.xlabel('Epoch')\n        plt.legend(['Training data', 'Validation data'], loc=0)\n        # plt.show()\n\n\n    def plot_history(history):\n        plt.figure(figsize=(15, 5))\n        plt.subplot(1, 2, 1)\n        plot_acc(history)\n        plt.subplot(1, 2, 2)\n        plot_loss(history)\n\n\n    def plot_loss_acc(history):\n        plot_loss(history, '(a) Loss trajectory')\n        plt.show()            \n        plot_acc(history, '(b) Accracy trajectory')\n        plt.show()\n\n\n    def plot_acc_loss(history):\n        plot_acc(history, '(a) Accracy trajectory')\n        plt.show()\n        plot_loss(history, '(b) Loss trajectory')\n        plt.show()","6998c9ec":"fname='..\/input\/deepfake1\/fake_aaqaifqrwn.mp4_result.csv'\ndata = pd.read_csv(fname, usecols=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18],engine='python', skipfooter=3).values.reshape(-1)\ntype(data)","c0564efd":"# bring our data as pandas dataframe\ndef load_data(fname='..\/input\/deepfake1\/fake_aaqaifqrwn.mp4_result.csv'):\n        \n    # usecols=[1] means only passangers count\n    dataset = pd.read_csv(fname, usecols=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18], engine='python', skipfooter=3)        \n        \n    # we change data type from dataframe to 1-dimension numpy \n    data = dataset.values.reshape(-1)\n        \n    # check\n    plt.plot(data)\n    plt.xlabel('Time'); plt.ylabel('#Passengers')\n    plt.title('Original Data')\n    plt.show()\n\n    # data normalize (because LSTM learn 0~1 values)\n    data_dn = (data - np.mean(data)) \/ np.std(data) \/ 5\n    plt.plot(data_dn)\n    plt.xlabel('Time'); plt.ylabel('Normalized #Passengers')\n    plt.title('Normalized data by $E[]$ and $5\\sigma$')\n    plt.show()\n\n    return data_dn    \n","b3776a2b":"# this function makes dataset for Using Rate of change about D months predict next month passanger count\ndef get_Xy(data, D=300):\n    # make X and y\n    X_l = []\n    y_l = []\n    N = len(data) # 144\n    assert N > D, \"N should be larger than D, where N is len(data)\"\n    for ii in range(N-D-1): # 0 ~ 131\n        X_l.append(data[ii:ii+D])\n        y_l.append(data[ii+D])\n    X = np.array(X_l)\n    X = X.reshape(X.shape[0], X.shape[1], 1)\n    y = np.array(y_l)\n    print(X.shape, y.shape)\n    return X, y","c7cc5077":"data = pd.read_csv(fname, usecols=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18],engine='python', skipfooter=3).values.reshape(-1)\n\n# we can check x = (131,12,1), y = (131)\nprint(get_Xy(data))","3ed546f4":"class Dataset:\n    \n    # initialize (data name & D (time-series length))\n    def __init__(self, fname='..\/input\/international-airline-passengers\/international-airline-passengers.csv', D=12):\n        data_dn = load_data(fname=fname)\n        X, y = get_Xy(data_dn, D=D)\n        X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)  \n        \n        # after initializing , we can see output when we use this class\n        self.X, self.y = X, y\n        self.X_train, self.X_test, self.y_train, self.y_test = X_train, X_test, y_train, y_test   \n\n    \n","f51fce6e":"def rnn_model(shape):\n    \n    # input (12,1)\n    m_x = layers.Input(shape=shape) #X.shape[1:]\n    \n    # hidden (10)\n    m_h = layers.LSTM(10)(m_x)\n    \n    # output (1)\n    m_y = layers.Dense(1)(m_h)\n    m = models.Model(m_x, m_y)\n    \n    # show me summary about model\n    m.compile('adam', 'mean_squared_error')\n    m.summary()\n    \n    return m","6f839809":"class Machine():\n    def __init__(self):\n        # bring data\n        self.data = Dataset()\n        \n        # input data size (12,1)\n        shape = self.data.X.shape[1:]\n        \n        # make LSTM model\n        self.model = rnn_model(shape)\n        \n    def run(self, epochs=400):\n        d = self.data\n        \n        # we made internal variables in Class Dataset()\n        X_train, X_test, y_train, y_test = d.X_train, d.X_test, d.y_train, d.y_test\n        X, y = d.X, d.y\n        \n        # training\n        m = self.model \n        h = m.fit(X_train, y_train, epochs=epochs, validation_data=[X_test, y_test], verbose=0)\n\n        # after training show us training curve\n        skeras.plot_loss(h)\n        plt.title('History of training')\n        plt.show()\n\n        # evaluate() show us training efficiency after training\n        yp = m.predict(X_test)\n        print('Loss:', m.evaluate(X_test, y_test))\n        \n        # make two graph for comparing\n        plt.plot(yp, label='Origial')\n        plt.plot(y_test, label='Prediction')\n        plt.legend(loc=0)\n        plt.title('Validation Results')\n        plt.show()\n        \n        #   upside         >>>>>>>>>>>>>      we cant find out Time series relationship\n        #-----------------------------------------------------------------------------------------------\n        #   downside       >>>>>>>>>>>>>      we use seaborn and pandas's dataframe to find Time series relationship\n        \n        yp = m.predict(X_test).reshape(-1)\n        print('Loss:', m.evaluate(X_test, y_test))  \n        print(yp.shape, y_test.shape)\n\n        df = pd.DataFrame()\n        df['Sample'] = list(range(len(y_test))) * 2\n        # Sample column's first = purpose order, second = predict order\n        df['Normalized #Passengers'] = np.concatenate([y_test, yp], axis=0)\n        df['Type'] = ['Original'] * len(y_test) + ['Prediction'] * len(yp)\n\n        plt.figure(figsize=(7, 5))\n        sns.barplot(x=\"Sample\", y=\"Normalized #Passengers\", hue=\"Type\", data=df)\n        plt.ylabel('Normalized #Passengers')\n        plt.show()\n        \n        yp = m.predict(X)\n        plt.plot(yp, label='Origial')\n        plt.plot(y, label='Prediction')\n        plt.legend(loc=0)\n        plt.title('All Results')\n        plt.show()\n","e2f4f212":"def main():        \n    machine = Machine() \n    machine.run(epochs=400)\n\nif __name__ == '__main__' :\n    main()","f086a0bd":"# Simple Time series LSTM \n\nLSTM (Long term Short Term memory)\n* **RNN (Recurrent Neural Network)** has problem about long term memory, **LSTM** has improvement about that\n* Our **Time series LSTM** is focusing on predicting passanger's count on next month, when **LSTM** gets passanger's count during before 12 months\n\n<hr>\n\nHow to use this notebook :\n\nThere is only minimum explanation\n\nThis notebook could be helpful for who want to see how code works right away\n\nPlease upvote if it was helpful !\n\n<hr>\n\n## Content\n1. [Libraries import](#one)\n2. [Prepare Data](#two)\n3. [Modeling](#three)\n4. [Training & Evaluation](#four)\n\n<hr>","d991fd02":"## Reference\n* Coding chef 3 minute deep learning  - [ex5_1_lstm_imdb](https:\/\/github.com\/jskDr\/keraspp\/blob\/master\/ex5_2_lstm_airplane.py)\n* [Simple LSTM](https:\/\/www.kaggle.com\/gigunlee\/beginner-simple-lstm)","e6941c6d":"<a id=\"one\"><\/a>\n# 1. Libraries import","0378f6ca":"<a id=\"four\"><\/a>\n# 4. Training & Evaluation","15a46c85":"* We need to put **'international-airline-passengers.csv'** in our input data\n* 144 rows\n* Data has 2 columns (Month and passangers)\n* **Month** ex) 1949-01, **passangers** ex) 112","0b9cd4ef":"<a id=\"two\"><\/a>\n# 2. Prepare Data","45e4e4bb":"**Here is important**\n\nwe will make time series dataset\n\n* x = last 12 months passanger count     ex) 1(Jan) ~ 12(Dec)\n* y = right after x month                ex ) 13(1)(Jan)\n","3151110d":"<a id=\"three\"><\/a>\n# 3. Modeliing"}}