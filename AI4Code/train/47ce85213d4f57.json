{"cell_type":{"245a0782":"code","0135c253":"code","4c364c94":"code","02881df9":"code","ae9c48c7":"code","08dfe3da":"code","c6f0965f":"code","7d97def1":"code","dd0f9ea7":"code","b681b246":"code","e08dd7a3":"code","cabc4616":"code","a09bea03":"code","664a06c0":"code","93d78490":"code","f1099336":"code","54ae76c8":"code","03e5f0b9":"code","675fbc7b":"code","8cbf0ac8":"code","50232453":"code","a1a04e46":"code","c087a3d0":"code","7c5cb04a":"code","5ab4178d":"code","64cd313e":"code","d57589f5":"code","a96212c6":"code","7b808973":"markdown","c1fe5973":"markdown"},"source":{"245a0782":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0135c253":"import warnings\nwarnings.filterwarnings('ignore')","4c364c94":"## importing the dataset \ntitanic = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')","02881df9":"## let's check the head\ntitanic.head()","ae9c48c7":"## let's check the shape\ntitanic.shape","08dfe3da":"# let's check info of dataset\ntitanic.info()","c6f0965f":"## converted pclass into object type \ntitanic['Pclass']=titanic['Pclass'].astype('str')","7d97def1":"## check for null values\nround(100*(titanic.isnull().sum()\/titanic.shape[0]),2)","dd0f9ea7":"## cabin has 77% null values hence removing it \ntitanic.drop('Cabin',axis=1,inplace=True)","b681b246":"## remove rows don't have Embarked \ntitanic = titanic[~titanic['Embarked'].isnull()]","e08dd7a3":"## impute the missing values with mean of the Age \nage_mean = titanic['Age'].mean()\ntitanic['Age'].fillna(age_mean,inplace=True)","cabc4616":"## computing the mean fare \nfare_mean = titanic['Fare'].mean()\n","a09bea03":"## checking after removing null values\nround(100*(titanic.isnull().sum()\/titanic.shape[0]),2)","664a06c0":"## impute male as 1 and female as 0\n\ntitanic['Sex'].replace({'male':1,'female':0},inplace=True)","93d78490":"##  create dummies for Embarked\n\nstat = pd.get_dummies(titanic['Embarked'],drop_first=True)\ntitanic = pd.concat([titanic,stat],axis=1)\ntitanic.drop('Embarked',axis=1,inplace=True)","f1099336":"## drop those column which is not required for our model building\n\ntitanic.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)","54ae76c8":"## split data into X and y\n\ny = titanic.pop('Survived')\nX = titanic\n\n## store variable that we are going to use \n\nvals = X.columns.tolist()\n","03e5f0b9":"## using statndard scaler to scale our numerical data\n\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\n\npt = StandardScaler()\n\nX = pt.fit_transform(X)\n\ny = y.to_numpy()","675fbc7b":"## import libraries for deep neural network\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.callbacks import EarlyStopping","8cbf0ac8":"## make our sequential model with activation function relu and sigmoid as it is a binary classification\n\nmodel = Sequential([\n    Dense(units=16, input_shape = (8,) ,activation='relu'),\n    Dense(units=32, activation='relu'),\n    Dense(units=2, activation='softmax')\n])","50232453":"## use early stopping criteria so that we can stop our training when val_accuracy is not getting increased after 25 iterations\n\nearlystopping = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=25)","a1a04e46":"## compile our model with adam optimizer and learning rate 0.0001\n\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])","c087a3d0":"## fit our model in training and test data with early stopping criteria\n\nhistory = model.fit(X ,y , batch_size=10 , validation_split=0.1, epochs=1000, verbose=2 , callbacks = earlystopping)","7c5cb04a":"print(len(history.history['val_accuracy'])) ## number of iterations required to fix validation accuracy ","5ab4178d":"## let's make our test data \n\ntitanic_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n\n## converted pclass into object type \n\ntitanic_test['Pclass']=titanic['Pclass'].astype('str')\n\n## impute null age values\n\ntitanic_test['Age'].fillna(age_mean,inplace=True)\n\n## impute male as 1 and female as 0\n\ntitanic_test['Sex'].replace({'male':1,'female':0},inplace=True)\n\n##  create dummies for Embarked\n\nstat = pd.get_dummies(titanic_test['Embarked'],drop_first=True)\ntitanic_test = pd.concat([titanic_test,stat],axis=1)\n\nX_test = pt.transform(titanic_test[vals])","64cd313e":"## now predict with our pre trained model\n\npredictions = model.predict(\n      x=X_test\n    , batch_size=10\n    , verbose=0\n) ","d57589f5":"## let's make our prediction rounded as it is have probability distribution\n\nrounded_predictions = np.argmax(predictions, axis=-1)\n","a96212c6":"## store our result to submit\n\ntitanic_test['Survived'] = rounded_predictions\n\nres = titanic_test[['PassengerId','Survived']]\n\nres.to_csv(\"Submission_titanic.csv\",index=False) ## final submission file","7b808973":"# Titanic survival prediction using ANN","c1fe5973":"**ANN**\n* What is An Artificial Neural Network?\nAn Artificial Neural Network is an information processing model that is inspired by the way biological nervous systems, such as the brain, process information. They are loosely modeled after the neuronal structure of the mamalian cerebral cortex but on much smaller scales. In simpler terms it is a simple mathematical model of the brain which is used to process nonlinear relationships between inputs and outputs in parallel like a human brain does every second.\n\ncheck out the link for more clarification on ANN :[https:\/\/medium.com\/@jamesdacombe\/an-introduction-to-artificial-neural-networks-with-example-ad459bb6941b](http:\/\/)"}}