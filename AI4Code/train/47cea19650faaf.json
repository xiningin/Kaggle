{"cell_type":{"b9310fa1":"code","a4f259f7":"code","de12e9d4":"code","8d0f90b3":"code","988003b6":"code","e5e83121":"code","3a760729":"code","3a794463":"code","8f2f98d6":"code","aee47b89":"code","afd5673c":"code","2da2d2b9":"code","1aa6f406":"code","a0fd31a9":"code","9261fcb9":"code","dd23d0c4":"code","b5a16df7":"code","1bec796c":"code","3d5b5acf":"code","3820790e":"code","ea88fcc5":"code","2c869411":"code","a1e3a746":"code","a7a17be7":"code","2315d87f":"code","8ac749a8":"code","54981f6d":"code","0ec1ed51":"code","fb3497af":"code","d3800413":"code","429e6e38":"code","41924e24":"code","70c58ab3":"code","a92818f0":"code","acaa724a":"code","f03d9668":"code","dc93ea24":"code","700ece87":"code","fc1afb65":"code","17651b0e":"code","e5614f04":"code","22455a2d":"code","37ccbe6d":"code","ccbc8cac":"code","e36b2776":"code","016acd7b":"code","e091b655":"code","96d9b329":"code","ca1f16e2":"code","8e55eb8c":"code","619b1c65":"code","af85a748":"code","c3b9831e":"markdown","dd89d3c1":"markdown","c8f26136":"markdown","e4a53053":"markdown","ebf71b0d":"markdown","2d991eb4":"markdown","dfef591f":"markdown","da2fcb48":"markdown","106040ab":"markdown","d5eb55ac":"markdown","9cb5577f":"markdown","e1dac1d8":"markdown"},"source":{"b9310fa1":"# import all important libraries \n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport seaborn as sns\n\nfrom pandas.plotting import scatter_matrix\nfrom scipy import stats\nfrom keras import backend as K\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.compose import ColumnTransformer\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping, LambdaCallback\n\n%matplotlib inline\n\nprint(\"Libraries imported.\")\nprint(tf.__version__)","a4f259f7":"path = \"..\/input\/suginami-data\/suginamiku_cleaned_data_1m.csv\"\n\nsuginami_data = pd.read_csv(path, index_col=0)\nsuginami_data.head(2)","de12e9d4":"suginami_data.info()","8d0f90b3":"selected_columns = [\"location\",\"building_structure\",\"nearest_station\",\"distance_to_station\",\n                    \"area\",\"maximum_coverage_ratio\",\n                    \"maximum_floor_area_ratio\",\"building_age\",\"price\"]\n\nnum_attributes = [\"distance_to_station\",\"area\",\"maximum_coverage_ratio\",\n                    \"maximum_floor_area_ratio\",\"building_age\"]\n\ncat_attributes = [\"building_structure\",\"location\",\"nearest_station\"]\n\nlabel = \"price\"","988003b6":"dataset = suginami_data[selected_columns].copy()","e5e83121":"# historgram plots\n\ndataset.hist(bins=50, figsize=(20,15))\nplt.show()","3a760729":"# check for correlations \n\ncorr_matrix = dataset.corr()\nprint(corr_matrix[\"price\"].sort_values(ascending=False))","3a794463":"scatter_matrix(dataset, figsize=(14, 12))","8f2f98d6":"# split the dataset\n\ntrain_set, test_set = train_test_split(dataset, test_size=0.1, random_state=42)\nprint(len(train_set))\nprint(len(test_set))","aee47b89":"def lin_reg(x):\n    lm = LinearRegression()\n\n    pearson_coef, p_value = stats.pearsonr(train_set[x], train_set[\"price\"])\n    print(\"Pearson Coefficient =\",pearson_coef, \"and P-value =\", p_value)\n    print(\"\")\n\n    lm.fit(train_set[[x]], train_set[\"price\"])\n\n    print(\"Slope: \", lm.coef_)\n    print(\"Intercept: \", lm.intercept_)\n    print(\"\")\n    if float(lm.coef_) >= 0:\n        print(\"Linear Model: price =\", lm.intercept_, \"+\", float(lm.coef_), \"*\", x)\n    else:\n        print(\"Linear Model: price =\", lm.intercept_, float(lm.coef_), \"*\", x)","afd5673c":"area_lm = lin_reg(\"area\")","2da2d2b9":"building_age_lm = lin_reg(\"building_age\")","1aa6f406":"time_to_station = lin_reg(\"distance_to_station\")","a0fd31a9":"# Multiple linear regression model using all numerical attributes. \n\nmul_reg = LinearRegression()\n\nmul_reg.fit(train_set[num_attributes], train_set[label])\n\nprint(\"Slope: \", mul_reg.coef_)\nprint(\"Intercept: \", mul_reg.intercept_)","9261fcb9":"lin_predictions = mul_reg.predict(train_set[num_attributes])\nlin_mse = mean_squared_error(train_set[label], lin_predictions)\nlin_rmse = np.sqrt(lin_mse)\nprint(\"Prediction error: $\",int(lin_rmse))","dd23d0c4":"# function that compares predictions vs actual values\n\ndef plot_com(actual, preds):\n    plt.figure(figsize=(12, 8))\n\n    ax1 = sns.distplot(actual, hist=False, color=\"r\", label=\"Actual Value\")\n    sns.distplot(preds, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)\n\n    plt.title('Actual vs Fitted Values for Price')\n    plt.xlabel('Price (in dollars)')\n\n    plt.show()\n    plt.close()","b5a16df7":"plot_com(train_set[label], lin_predictions)","1bec796c":"tree_reg = DecisionTreeRegressor(random_state=42)\ntree_reg.fit(train_set[num_attributes], train_set[label])","3d5b5acf":"tree_predictions = tree_reg.predict(train_set[num_attributes])\ntree_mse = mean_squared_error(train_set[label], tree_predictions)\ntree_rmse = np.sqrt(tree_mse)\nprint(\"Prediction error: $\",int(tree_rmse))","3820790e":"plot_com(train_set[label], tree_predictions)","ea88fcc5":"forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\nforest_reg.fit(train_set[num_attributes], train_set[label])","2c869411":"forest_predictions = forest_reg.predict(train_set[num_attributes])\nforest_mse = mean_squared_error(train_set[label], forest_predictions)\nforest_rmse = np.sqrt(forest_mse)\nprint(\"Prediction error: $\",int(forest_rmse))","a1e3a746":"plot_com(train_set[label], forest_predictions)","a7a17be7":"input = [(\"scale\",StandardScaler()),\n         (\"polynomial\",PolynomialFeatures(include_bias=False)),\n         (\"model\",LinearRegression())]\n\npipe = Pipeline(input)\npipe.fit(train_set[num_attributes], train_set[label])","2315d87f":"pipe_predictions = pipe.predict(train_set[num_attributes])\npipe_mse = mean_squared_error(train_set[label], pipe_predictions)\npipe_rmse = np.sqrt(pipe_mse)\nprint(\"Prediction error: $\",int(pipe_rmse))","8ac749a8":"plot_com(train_set[label], pipe_predictions)","54981f6d":"# import normalized data for DNN model\n\npath = \"..\/input\/suginami-data\/suginamiku_data_norm_1m.csv\"\n\nnorm_data = pd.read_csv(path, index_col=0)\n\nnorm_dataset = norm_data.copy()\nnorm_dataset.head(2)","0ec1ed51":"# features\n\nX = norm_dataset.iloc[:, :5]\nprint(X.head())\n\n# labels\n\nY = norm_dataset.iloc[:, -1]\nprint(Y.head())","fb3497af":"X_arr = X.values\nY_arr = Y.values\n\nprint(\"X_arr shape: \", X_arr.shape)\nprint(\"Y_arr shape: \", Y_arr.shape)","d3800413":"X_train, X_test, y_train, y_test = train_test_split(X_arr, Y_arr, test_size = 0.1, shuffle = True, random_state=0)\n\nprint(\"X_train shape: \", X_train.shape)\nprint(\"y_train shape: \", y_train.shape)\nprint(\"X_test shape: \", X_test.shape)\nprint(\"y_test shape: \", y_test.shape)","429e6e38":"def root_mean_squared_error(y_true, y_pred):\n        return K.sqrt(K.mean(K.square(y_pred - y_true)))","41924e24":"def dnn_model():\n    \n    model = Sequential([\n        Dense(10, input_shape = (5,), activation = \"relu\"),\n        Dense(20, activation = \"relu\"),\n        Dense(5, activation = \"relu\"),\n        Dense(1)])\n\n    model.compile(\n        optimizer = \"rmsprop\", \n        loss = root_mean_squared_error, \n        metrics = [\"accuracy\"])\n    \n    return model\n\ndnn_reg = dnn_model()\ndnn_reg.summary()","70c58ab3":"early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 5)\n\npreds_on_untrained = dnn_reg.predict(X_test)\n\nhistory = dnn_reg.fit(\n    X_train, y_train,\n    validation_data = (X_test, y_test),\n    epochs = 100,\n    callbacks = [early_stopping],\n    verbose = 0)","a92818f0":"print(\"---Training loss---\")\nprint(history.history[\"loss\"])\nprint(\"\")\nprint(\"---Validation loss---\")\nprint(history.history[\"val_loss\"])","acaa724a":"price_max = dataset[\"price\"].max()\nprint(price_max)\nprice_min = dataset[\"price\"].min()\nprint(price_min)\n\ndef convert_price_values(pred):\n    return int((pred*(price_max-price_min) + price_min))","f03d9668":"loss_usd = []\n\nfor l in history.history[\"loss\"]:\n    loss_usd.append(convert_price_values(l))","dc93ea24":"val_loss_usd = []\n\nfor l in history.history[\"val_loss\"]:\n    val_loss_usd.append(convert_price_values(l))","700ece87":"print(\"Prediction loss:\",loss_usd)\nprint(\"Validation loss:\",val_loss_usd)","fc1afb65":"def plot_loss(history):\n    plt.plot(history.history['loss'], label='loss')\n    plt.plot(history.history['val_loss'], label='val_loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Error [Price]')\n    plt.legend()\n    plt.grid(True)\n\nplot_loss(history)","17651b0e":"preds = dnn_reg.predict(X_train)\n\nprice_preds = [convert_price_values(y) for y in preds]\nprice_labels = [convert_price_values(y) for y in y_train]\nplot_com(price_labels, price_preds)","e5614f04":"num_pipeline = Pipeline([\n        (\"scale\",StandardScaler()),\n        (\"polynomial\",PolynomialFeatures(include_bias=False)),\n])","22455a2d":"full_pipeline = ColumnTransformer([\n    (\"num\", num_pipeline, num_attributes),\n    (\"cat\", OneHotEncoder(), cat_attributes)\n])","37ccbe6d":"nc_pipe = full_pipeline.fit_transform(train_set)","ccbc8cac":"nc_tree_reg = DecisionTreeRegressor()\nnc_tree_reg.fit(nc_pipe, train_set[\"price\"])","e36b2776":"nc_tree_predictions = nc_tree_reg.predict(nc_pipe)\nnc_tree_mse = mean_squared_error(train_set[\"price\"], nc_tree_predictions)\nnc_tree_rmse = np.sqrt(nc_tree_mse)\nprint(\"Prediction error: $\",int(nc_tree_rmse))","016acd7b":"plot_com(train_set[label], nc_tree_predictions)","e091b655":"# create interaction terms\ninteraction = PolynomialFeatures(degree=3, include_bias=False, interaction_only=True)\nX_inter = interaction.fit_transform(train_set[num_attributes])","96d9b329":"inter_reg = LinearRegression()\ninter_reg.fit(X_inter, train_set[label])","ca1f16e2":"inter_predictions = inter_reg.predict(X_inter)\ninter_mse = mean_squared_error(train_set[label], inter_predictions)\ninter_rmse = np.sqrt(inter_mse)\nprint(\"Prediction error: $\",int(inter_rmse))","8e55eb8c":"plot_com(train_set[label], inter_predictions)","619b1c65":"models_errors = {\"Model\":[\"Multiple Linear Regression\",\"Decision Tree Regression\",\"Random Forest Regression\",\n                          \"DNN Regression\", \"MLR with Polynomial Features\",\"MLR with Interaction Terms\",\n                          \"Decision Tree with Num&Cat Attributes\"],\n                  \"Prediction Error (USD)\":[lin_rmse,tree_rmse,forest_rmse,\n                                            convert_price_values(history.history[\"loss\"][-1]),\n                                            pipe_rmse,inter_rmse,nc_tree_rmse]}\n\ncom_table = pd.DataFrame(data=models_errors)","af85a748":"com_table.sort_values(by=[\"Prediction Error (USD)\"], inplace=True, ascending=False)\ncom_table.reset_index(drop=True, inplace=True)\ncom_table","c3b9831e":"### Random Forest Regression Model","dd89d3c1":"### Predicting Tokyo Apartment Prices | Suginami Ward\n\n\nNotebook Author: NGUYEN Dai Truong Thanh\n\n#### Background\n\nTokyo is the capital and the most populus city of Japan. The price of residential area in Tokyo has an average increase of 2.5% for the past 7 consecutive years. Specifically, Toshima-ku's land price increased by 10.9% compared to 1 year before. It is the second-highest increase in price among Tokyo's residential areas. (Reference: https:\/\/www.realestate-tokyo.com\/news\/standard-land-prices-tokyo-2019\/)\n\nThis project is a part of my data science seminar at Ritsumeikan APU. \n\nIn this project, I used the data from the Land General Information System of the Japanese Ministry of Land, Infrastructure, Transport, and Tourism to analyze the real estate landscape of two wards of Tokyo, Toshima Ward and Suginami Ward. *The dataset used in this notebook includes prices below $1 million*\n\n##### The goal is to predict house prices by training various ML models and selecting the one with the least error.\n\n#### Note: \nThis notebook only contains the machine learning step of the project. All previous steps including Data Cleaning, Exploratory Analysis, and Feature Selection were completed in separate notebooks.\n\n<img src= \"https:\/\/d1ix9yerv4y8lr.cloudfront.net\/blog\/wp-content\/uploads\/2019\/07\/tokyo-ops-7-19.jpg\" alt =\"Titanic\" style='width: 800px;'>","c8f26136":"### Model Performances on Train Dataset","e4a53053":"### Multiple Linear Regression with Interaction Terms","ebf71b0d":"### Multiple Linear Regression Model","2d991eb4":"### Linear Regression Models","dfef591f":"* area has **very strong positive** correlation with price.\n* distance_to_station has **weak positive** correlation with price.\n* maximum_coverage_ratio and maximum_floor_area_ratio have **weak negative** correlations with price.\n* building_age has **negative** correlation with price.","da2fcb48":"### Deep Neural Network Regression Model","106040ab":"#### Multiple linear regression model to predict price of a building in Suginami-ku:\n\n> price = 230090.40 - 3246.72\\*distance_to_station + 5925.56\\*area - 93877.31\\*maximum_coverage_ratio + 5942.13\\*maximum_floor_area_ratio - 5082.79\\*building_age ","d5eb55ac":"### Decision Tree Regression with Numerical & Categorical Attributes","9cb5577f":"### Decision Tree Regression Model","e1dac1d8":"### Linear Regression Model with Polynomial Features"}}