{"cell_type":{"a78cd9fe":"code","3259a388":"code","1b87a474":"code","dad70104":"code","5b2da8f4":"code","38c8b13d":"code","c2e50182":"code","170ff2d8":"code","aac303dd":"code","618efee5":"code","f1bbfa5d":"code","0367c4a6":"code","871c1caa":"code","7eaef8f7":"code","dc221e6e":"code","6bcc7fd0":"code","bee5ad64":"code","e07b5a30":"code","21926b9c":"code","ef0c62e4":"code","3a2a1db7":"code","b44f3c26":"code","55452064":"code","750df8de":"code","57bf0873":"code","13e4a7bf":"code","bb035450":"code","2faf6d18":"code","995657a9":"code","fca2806e":"code","d8e9dc37":"markdown","bc951a3d":"markdown"},"source":{"a78cd9fe":"#Loading packages and libraries required for data analysis\nimport numpy as np\nimport pandas as pd\nimport re\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#For data visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","3259a388":"#Reading dataset\ndf = pd.read_csv('..\/input\/lemona\/Lemonade.csv')\ndf.head()","1b87a474":"#Creating new column (Revenue)\ndf['Revenue'] = df['Price'] * df['Sales']\ndf.head()","dad70104":"# Print desciptive statistics\ndf.describe()","5b2da8f4":"df.describe(include='O')","38c8b13d":"df.info()","c2e50182":"df.count()","170ff2d8":"# Data Visualization\nsns.pairplot(df)","aac303dd":"#Comparing weekdays Sales\nsns.barplot(x='Day',y='Sales',data=df)\ndf.groupby('Day',as_index=False).Sales.mean()","618efee5":"#Grasping important columns\ndf1 = df[['Sales', 'Temperature', 'Rainfall', 'Flyers', 'Price', 'Revenue']]\ndf1.head()","f1bbfa5d":"#Find the correlation between the variables in the dataset.Export to excel to check for muticollinearity\ndf1.corr()","0367c4a6":"# Checking for Outlier in Flyers\nsns.boxplot(data=df1, x=df1['Flyers'])","871c1caa":"# Treating Flyers Outlier\nQ1 = df1['Flyers'].quantile(0.25)\nQ3 = df1['Flyers'].quantile(0.75)\nIQR = Q3 - Q1\nprint(Q1)\nprint(Q3)\nprint(IQR)\n\nLower_Whisker = Q1 - 1.5*IQR\nUpper_Whisker = Q3 + 1.5*IQR\nprint(Lower_Whisker, Upper_Whisker)\n\ndf1 = df1[df1['Flyers'] < Upper_Whisker]\n\ndf1.shape\n\nsns.boxplot(data = df1, x = df1['Flyers'])","7eaef8f7":"df1.head()","dc221e6e":"from sklearn import model_selection\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split, GridSearchCV","6bcc7fd0":"X = np.array(df1.drop(['Sales'], 1))\ny = np.array(df1['Sales'])\n\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X,y,test_size=0.2)","bee5ad64":"print(\"X_train shape: {}\".format(X_train.shape))\nprint(\"y_train shape: {}\".format(y_train.shape))\n\nprint(\"X_test shape: {}\".format(X_test.shape))\nprint(\"y_test shape: {}\".format(y_test.shape))","e07b5a30":"# Linear Regression\nlr = LinearRegression()\nlr.fit(X_train, y_train)\n#y_pred = lr.predit(X_test)\n\nlr.score(X_test, y_test)\n\nacc_lr = round(lr.score(X_test, y_test)*100,2)","21926b9c":"#Stochastic Gradient Descent (SGD):\nsgd = linear_model.SGDClassifier(max_iter=5, tol=None)\nsgd.fit(X_train, y_train)\n#y_pred = sgd.predict(X_test)\n\nsgd.score(X_test, y_test)\n\nacc_sgd = round(sgd.score(X_test, y_test) * 100, 2)","ef0c62e4":"#Random Forest:\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, y_train)\n#y_pred = random_forest.predict(X_test)\n\nrandom_forest.score(X_test, y_test)\n\nacc_random_forest = round(random_forest.score(X_test, y_test) * 100, 2)","3a2a1db7":"#Gaussian Naive Bayes:\ngaussian = GaussianNB() \ngaussian.fit(X_train, y_train)  \n#y_pred = gaussian.predict(X_test) \n\ngaussian.score(X_test, y_test)\n\nacc_gaussian = round(gaussian.score(X_test, y_test) * 100, 2)","b44f3c26":"#Perceptron:\nperceptron = Perceptron(max_iter=5)\nperceptron.fit(X_train, y_train)\n#y_pred = perceptron.predict(X_test)\n\nperceptron.score(X_test, y_test)\n\nacc_perceptron = round(perceptron.score(X_test, y_test) * 100, 2)","55452064":"#Linear Support Vector Machine:\nsvm = LinearSVC()\nsvm.fit(X_train, y_train)\n#y_pred = svm.predict(X_test)\n\nsvm.score(X_test, y_test)\n\nacc_svm = round(svm.score(X_test, y_test) * 100, 2)","750df8de":"#Decision Tree\ndecision_tree = DecisionTreeClassifier() \ndecision_tree.fit(X_train, y_train)  \n#y_pred = decision_tree.predict(X_test)  \n\ndecision_tree.score(X_test, y_test)\n\nacc_decision_tree = round(decision_tree.score(X_test, y_test) * 100, 2)","57bf0873":"#Gradient Boost Classifier\ngbk = GradientBoostingClassifier()\nne = np.arange(1,20)\ndep = np.arange(1,10)\nparam_grid = {'n_estimators' : ne,'max_depth' : dep}\ngbk_cv = GridSearchCV(gbk, param_grid=param_grid, cv=5)\ngbk_cv.fit(X, y)\n#y_pred = gbk_cv.predict(X_test)\n\ngbk_cv.score(X_test, y_test)\n\nacc_gbk = round(gbk_cv.score(X_test, y_test)*100, 2)","13e4a7bf":"#Which is the best Model ?\nresults = pd.DataFrame({\n    'Model': ['Linear Regression', 'Stochastic Gradient Decent', 'Random Forest', 'Gaussian Naive Bayes','Perceptron', \n              'Support Vector Machines', 'Decision Tree', 'Gradient Boost Classifier'],\n    'Score': [acc_lr, acc_sgd, acc_random_forest, acc_gaussian, acc_perceptron, acc_svm, acc_decision_tree, acc_gbk]})\n\nresult_df = results.sort_values(by='Score', ascending=False)\nresult_df = result_df.set_index('Score')\nresult_df.head(8)","bb035450":"y_pred = gbk_cv.predict(X_test)","2faf6d18":"plt.scatter(y_test, y_pred)","995657a9":"sales_pred = pd.DataFrame({'Sales': y_test, 'pred_sales': y_pred})\nprint(sales_pred)","fca2806e":"# Converting rest to excel.csv file\n\nsales_pred = pd.DataFrame({'Sales': y_test, 'pred_sales': y_pred}).to_csv('Lemonade_Sales_Pred.csv')","d8e9dc37":"#### Testing different Predictive Models","bc951a3d":"###### From the results above Gradient Boost Classifier will return a prediction accuracy of 100% whereas Linear Regression will return prediction accuracy of 99%. Hence we will use Gradient Boost Classifier for our prediction."}}