{"cell_type":{"123b6b81":"code","2727bf4a":"code","10ac456d":"code","4b83069e":"code","9ef61506":"code","a67bb8ba":"code","a9fd1a85":"code","04f36893":"code","1150cc47":"markdown"},"source":{"123b6b81":"# Imports\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models\nimport time\nimport matplotlib.pyplot as plt","2727bf4a":"# Define transforms for the training data and testing data\n# Normalization based on ImageNet training values\ndata_dir = \"\/kaggle\/input\/cat-and-dog\/\"\n\ntrain_transforms = transforms.Compose([transforms.RandomRotation(35),\n                                       transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n                                       transforms.ColorJitter(),\n                                       transforms.RandomHorizontalFlip(),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize([0.485, 0.456, 0.406],\n                                                            [0.229, 0.224, 0.225])])\n\ntest_transforms = transforms.Compose([transforms.Resize(255),\n                                      transforms.CenterCrop(224),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406],\n                                                           [0.229, 0.224, 0.225])])\n\n# Pass transforms in data\ntrain_data = datasets.ImageFolder(data_dir + '\/training_set\/training_set', transform=train_transforms)\ntest_data = datasets.ImageFolder(data_dir + '\/test_set\/test_set', transform=test_transforms)\n\n# Load train and test loaders\ntrainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\ntestloader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True)","10ac456d":"# Helper function to show images\ndef image_convert(img):\n    img = img.clone().cpu().numpy()\n    img = img.transpose(1,2,0)\n    std = [0.5,0.5,0.5]\n    mean = [0.5,0.5,0.5]\n    img = img*std + mean\n    return img\n\n\ndef plot_10():\n        iter_ = iter(trainloader)\n        images,labels = next(iter_)\n        an_ = {'0':'cat','1':'dog'}\n        \n        plt.figure(figsize=(20,10))\n        for idx in range(10):\n            plt.subplot(2,5,idx+1)\n            img = image_convert(images[idx])\n            label = labels[idx]\n            plt.imshow(img)\n            plt.title(an_[str(label.numpy())])\n        plt.show()\n        \nplot_10()","4b83069e":"# Set devide based on GPU availability\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndevice","9ef61506":"# Load ResNet50 pretrained model\nmodel = models.resnet50(pretrained=True)\n\nmodel","a67bb8ba":"# Turn off gradients for our model\n# Avoid gradiente descent again\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Define a new classifier to our cat and dog data\n# Starts with 2048 because it's a requirement of ResNet\nclassifier = nn.Sequential(nn.Linear(2048, 512),\n                           nn.ReLU(),\n                           nn.Dropout(p=0.2),\n                           nn.Linear(512, 256),\n                           nn.ReLU(),\n                           nn.Dropout(p=0.2),\n                           nn.Linear(256, 2),\n                           nn.LogSoftmax(dim=1))\n\n# Change model classifier\nmodel.fc = classifier\n\n# Criterion function\ncriterion = nn.NLLLoss()\n\n# Set optimizer and learning rate\noptimizer = optim.Adam(model.fc.parameters(), amsgrad=True)\n\n# Send model to GPU\nmodel.to(device)","a9fd1a85":"# Train and validate our model\n\n# Explain the model\nprint('Model: Resnet50 + 3 Layers + Dropout 0.2')\nprint('Criterion: NLLLoss \/ Optimizer: Adam')\n\n# Set controls\nepochs = 5\nrunning_loss = 0\ntest_loss = 0\naccuracy = 0 \n\n# Run epochs\nfor epoch in range(epochs):\n  \n    start_time = time.time()\n    \n    # Train loop    \n    for images, labels in trainloader:        \n        # Move input and label tensors to GPU\n        images, labels = images.to(device), labels.to(device)\n        \n        # Zero gradients\n        optimizer.zero_grad()\n        \n        # Get log probabilities\n        logps = model(images)\n        # Get loss from criterion\n        loss = criterion(logps, labels)\n        # Backward pass loss\n        loss.backward()\n        # Optimizer step\n        optimizer.step()\n        \n        # Keeping track on loss\n        running_loss += loss.item()\n        \n    # Put model in evaluation mode\n    model.eval()\n        \n    # Stops gradient descent\n    with torch.no_grad():\n        # Run a test loop and get accuracy of our model\n        for images, labels in testloader:\n            # Move input and label tensors to GPU\n            images, labels = images.to(device), labels.to(device)\n            \n            # Get log probabilities\n            logps = model(images)\n            # Get loss from criterion\n            loss = criterion(logps, labels)\n            # Keeping track on testing loss\n            test_loss += loss.item()\n            \n            # Calculate accuracy\n            ps = torch.exp(logps)\n            top_p, top_class = ps.topk(1, dim=1)\n            equals = top_class == labels.view(*top_class.shape)\n            accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n            \n            \n    print(f'Epoch {epoch+1}\/{epochs}.. '\n          f'Train loss: {running_loss\/len(trainloader):.3f}.. '\n          f'Test loss: {test_loss\/len(testloader):.3f}.. '\n          f'Test accuracy: {accuracy\/len(testloader):.3f}')\n            \n    elapsed_time = time.time() - start_time\n    print(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n    \n    # Reset controls\n    running_loss = 0        \n    test_loss = 0\n    accuracy = 0            \n    \n    # Put model back in training mode\n    model.train()","04f36893":"import numpy as np\n\n# Helper function to view predict images\ndef plot_predict_images():\n\n    label_dict = ['cat','dog']\n \n    iter_ = iter(testloader)\n    images,labels = next(iter_)\n    images = images.to(device)\n    pred_labels = labels.to(device)\n\n    \n    img_out = model.forward(images)\n    value, index_val = torch.max(img_out, 1)\n\n    fig = plt.figure(figsize=(35,9))\n    for idx in np.arange(10):\n        ax = fig.add_subplot(2,5,idx+1)\n        plt.imshow(image_convert(images[idx]))\n        label = labels[idx]  \n        pred_label = pred_labels[idx]\n        ax.set_title('Act {},pred {}'.format(label_dict[label],label_dict[pred_label]))\n        \nplot_predict_images()","1150cc47":"# IESB - Miner II - Pytorch - Cat and Dog\n\n## Transfer Learning - Resnet50"}}