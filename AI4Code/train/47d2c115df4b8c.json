{"cell_type":{"bcd6ddda":"code","59a7e7f3":"code","45d37f6a":"code","718471c2":"code","9b54ceca":"code","84bf9be7":"code","08c100cc":"code","8ae17533":"code","0c012aae":"code","d70f507e":"code","49a7b8c0":"markdown","4ba91153":"markdown","4418b97a":"markdown","cd271ef5":"markdown","e49bdc9b":"markdown","1651a575":"markdown","4e2b93b4":"markdown","32d27d85":"markdown","f841986c":"markdown","b4a7ab8a":"markdown","2b7f2e36":"markdown","5a97eee3":"markdown","873246c5":"markdown","9f775353":"markdown","c76bd25e":"markdown","31078427":"markdown","dd181ee6":"markdown","11357261":"markdown","35517083":"markdown"},"source":{"bcd6ddda":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","59a7e7f3":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport string\nfrom wordcloud import WordCloud","45d37f6a":"df = pd.read_csv('..\/input\/amazon-fine-food-reviews\/Reviews.csv')\ndf.head(2)","718471c2":"print(df.shape)\nprint(df.isnull().values.any())\ndf.dropna(axis = 0 , inplace = True)\nprint(df.shape)","9b54ceca":"df.drop_duplicates(subset=['Score','Text'],keep='first',inplace=True)\nprint(df.shape)\ndf.head(2)","84bf9be7":"plt.figure(figsize=(10,10))\n\nax = sns.countplot(x=df[\"Score\"],  data=df, order = df[\"Score\"].value_counts().index )\nfor p, label in zip(ax.patches, df[\"Score\"].value_counts()):\n    #print(p)\n    #print(label)\n    ax.annotate(label, (p.get_x()+0.25, p.get_height()+0.5))","08c100cc":"df.groupby('ProductId').count()","8ae17533":"df_products = df.groupby('ProductId').filter(lambda x: len(x) >= 500)\ndf_product_groups = df_products.groupby('ProductId')","0c012aae":"print(len(df_products))\nprint(len(df_product_groups))","d70f507e":"plt.figure(figsize=(20,20))\nsns.countplot(y=\"ProductId\",  hue=\"Score\", data=df_products);","49a7b8c0":"# 1.Importing Data and Preprocessing ","4ba91153":"### Score Value Count ","4418b97a":"So we can see that there were lot of duplicate values in our dataset.We have removed them so the number of rows of data has reduced from 568454 to 393661.","cd271ef5":"### Products with More than 500 Reviews","e49bdc9b":"So there are 11 Products which have more than 500 reviews.As we have seen earlier that there are around 67563 product Ids in the dataset.Only 11 products have mre than 500 reviews.It also means these 11 are the products which sell the most.This is in line with Paretos 80-20 Principle.We can say that very few (20%) products in general will drive 80% of the sales.","1651a575":"### Distribution the Reviews","4e2b93b4":"### Recently I published a self help book titled Inspiration: Thoughts on Spirituality, Technology, Wealth, Leadership and Motivation. The preview of the book can be read from the Amazon link https:\/\/lnkd.in\/gj7bMQA","32d27d85":"We can see tha the product B007JFMH8M has most good reviews.","f841986c":"### Missing Values ","b4a7ab8a":"Here we can see that most of the times the review score is 5 or 4.This is because if a product is selling on Amazon it has to be good.People buy the products after reading the previous reviews.If the reviews score for a product is low it wont sell much on Amazon.\n\nAlso we can see that the score is highly unbalanced dataset.So if we are going to classify review based on score we need to balance the dataset first.","2b7f2e36":"We can see that there are 67563 types of products in the dataset.","5a97eee3":"### Importing Data ","873246c5":"### Duplicate Values","9f775353":"### Importing Python Modules","c76bd25e":"# TO BE CONTINUED ","31078427":"In this notebook we will explore the text data availabe in the dataset of Amazon Fine Food.We will do exploratory Data Analysis with the data.We will be covering following topics \n\n1.Data Import and Preprocessing \n\n2.Exploratry Data Analysis (EDA) \n\n3.Conclusion \n\n### You can refer to my other notebooks from https:\/\/www.kaggle.com\/binuthomasphilip\/code","dd181ee6":"### No of Products in Dataset","11357261":"We can see that we had arounf 43 records with null values.We have removed them from our dataset.","35517083":"### You can refer to my other notebooks from https:\/\/www.kaggle.com\/binuthomasphilip\/code"}}