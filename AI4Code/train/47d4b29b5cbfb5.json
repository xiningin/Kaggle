{"cell_type":{"527e462c":"code","c7e291df":"code","3047f670":"code","bac0c8ce":"code","947b7c92":"code","9ac77c82":"code","c8b50f5f":"code","48cb5d69":"code","a8fff93f":"code","65d58913":"code","c130a12d":"code","c8cafb93":"code","c60e786b":"markdown","a847bdea":"markdown","8f05b29d":"markdown"},"source":{"527e462c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as se\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c7e291df":"gebdf = pd.read_csv('\/kaggle\/input\/gibberish-text-classification\/Gibberish.csv', encoding= 'unicode_escape')\n\ngebdf.head()","3047f670":"gebdf.info()","bac0c8ce":"# Let's explore the number of words each row has\nword_count = list()\nfor row in gebdf.iterrows():\n    word_count.append(len(row[1][0].split()))\n#     print(row[1][0])\n#     break","947b7c92":"gebdf['counts'] = word_count\n\ngebdf.head()","9ac77c82":"#checking the word counts per each row, we will only consider gebrish words of one\nse.distplot(word_count)","c8b50f5f":"gebdf = gebdf.loc[gebdf['counts'] ==1] #select only rows with single word","48cb5d69":"np.random.randint(0, high=len(gebdf), size=500) # sample of generating gebrish statement randomly","a8fff93f":"# drop old index and set new\ngebdf = gebdf.reset_index(drop=True)","65d58913":"gebphrase = list()\ngebcolumn = list()\nfor phrase in range(0,1000): #generating 1000 phrases\n    for i in np.random.randint(0, high=len(gebdf), size=500): #size is the number of words per phrase\n        gebphrase.append(gebdf['Response'][i])\n    gebcolumn.append(' '.join(gebphrase))\n    del gebphrase[:] # this is important to avoid commulatively overloading the list ","c130a12d":"# let's count the words for each row\nword_count = list()\nfor phrase in gebcolumn:\n    word_count.append(len(phrase.split()))\n    \n# plot the distribution of the number of words that we have generated\nse.distplot(word_count)","c8cafb93":"# have a look at one of the phrases\ngebcolumn[0]","c60e786b":"Cool so all the new phrases are made of 500 gibberish words.","a847bdea":"We will use the randomly generated numbers to point us to random rows and putting all of the words in those rows together will give us phrases of 500 gebberish words.","8f05b29d":"Majority of the rows has less than 5 words but there are rows with more words. To create a uniform number of words per phrase we need to fix to only use rows with one word."}}