{"cell_type":{"c6fd3a09":"code","b598bfd0":"code","419c1fb1":"code","17986f68":"code","d3c672d0":"code","dc7a230b":"code","ffa426b0":"code","c1c97695":"code","b58cb8ee":"code","9a5f273d":"code","1ce47222":"code","b620fc7e":"code","d2d3fcaa":"markdown","d94f7f62":"markdown","1b14e80d":"markdown","9ffa314d":"markdown","d0017812":"markdown","31a932c9":"markdown"},"source":{"c6fd3a09":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'\nfrom datetime import datetime\ndatetime.now().strftime(\"%Y\/%m\/%d %H:%M:%S\")","b598bfd0":"from io import StringIO\nfrom IPython.display import Image\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom matplotlib import rcParams \nimport seaborn as sns\nfrom pydot import graph_from_dot_data\n\nfrom sklearn.model_selection import cross_val_score, cross_validate\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import export_graphviz\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\nfrom lightgbm.sklearn import LGBMClassifier\n\ndef matplotlib_config():\n    rcParams['font.family'] = 'sans-serif'\n    rcParams['font.sans-serif'] = \\\n            ['Hiragino Maru Gothic Pro', 'Yu Gothic', 'Meirio', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP']\n    rcParams['figure.figsize'] = 12, 8\n    rcParams[\"font.size\"] = 12\n\nmatplotlib_config()","419c1fb1":"df_train = pd.read_csv('..\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('..\/input\/titanic\/test.csv')\n\ndf_train.head()","17986f68":"fillnas = {\n    'Age': df_train['Age'].median(),\n    'Fare': df_train['Fare'].median(),\n    'Cabin': 'Unknown',\n    'Embarked': df_train['Embarked'].mode(),\n}\n\ndef preprocess(df, is_test=False):\n    x = df.copy()\n    \n    for k, v in fillnas.items():\n        x[k].fillna(v, inplace=True)\n\n    x['is male'] = x['Sex']=='male'\n    \n    x['family size'] = x['SibSp'] + x['Parch'] + 1\n    x['is alone'] = x['family size']==1\n    \n    x['Unknown Cabin'] = x['Cabin']=='Unknown'\n    \n    df_embarked = pd.get_dummies(x['Embarked'])\n    for col in df_embarked:\n        x[f'Embarked_{col}'] = df_embarked[col]\n    \n    x.drop(columns=['PassengerId', 'Name', 'Sex', 'SibSp', 'Parch', 'Ticket', 'Cabin', 'Embarked'], inplace=True)\n    \n    if is_test:\n        return x\n    else:\n        y = x['Survived']\n        x.drop(columns='Survived', inplace=True)\n        return x, y\n\ntrain_x, train_y = preprocess(df_train)\ntest_x = preprocess(df_test, is_test=True)\ntrain_x.head()\ntest_x.head()","d3c672d0":"clf = DecisionTreeClassifier(min_samples_split=50, max_depth=5)\n\nresults = cross_validate(\n    clf,\n    train_x,\n    train_y,\n    cv=5,\n    return_train_score=True,\n    return_estimator=True\n)\n\nbest_clf = results['estimator'][np.argmax(results['test_score'])]\nscore = (results['test_score'].mean(), results['test_score'].std())\nprint(f'Accuracy: {score[0]:0.2f} \u00b1 {score[1]:0.2f}')\n\ndef tree2graph(clf):\n    tmp = StringIO()\n\n    export_graphviz(\n        clf,\n        feature_names=train_x.columns,\n        class_names=('Survived', 'Not Survived'),\n        out_file=tmp,\n        filled=True,\n        rounded=True\n    )\n    return graph_from_dot_data(tmp.getvalue())[0]\n\ngraph = tree2graph(best_clf)\ngraph.write_png('DecisionTree.png')\nImage(graph.create_png())\n\ndf_importance = pd.DataFrame()\ndf_importance['feature'] = train_x.columns\ndf_importance['importance'] = best_clf.feature_importances_\ndf_importance.sort_values('importance', ascending=False)","dc7a230b":"clf = RandomForestClassifier(min_samples_split=50)\n\nresults = cross_validate(\n    clf,\n    train_x,\n    train_y,\n    cv=5,\n    return_train_score=True,\n    return_estimator=True\n)\n\nbest_clf = results['estimator'][np.argmax(results['test_score'])]\nscore = (results['test_score'].mean(), results['test_score'].std())\nprint(f'Accuracy: {score[0]:0.2f} \u00b1 {score[1]:0.2f}')\n\ndf_importance = pd.DataFrame()\ndf_importance['feature'] = train_x.columns\ndf_importance['importance'] = best_clf.feature_importances_\ndf_importance.sort_values('importance', ascending=False)","ffa426b0":"%%time\nclfs = {\n    'SVC': SVC(),\n    'NB': GaussianNB(),\n    'RF': RandomForestClassifier(),\n    'AdaBoost': AdaBoostClassifier(),\n    'LightGBM': LGBMClassifier()\n}\n\ndef train(clf, X, y):\n    results = cross_validate(\n        clf, X, y, cv=5,\n        return_train_score=True,\n        return_estimator=True\n    )\n\n    best_clf = results['estimator'][np.argmax(results['test_score'])]\n    mean, std = (results['test_score'].mean(), results['test_score'].std())\n    return best_clf, mean, std\n\nbest_clfs = []\nresults = []\nfor name, clf in clfs.items():\n    best_clf, mean, std = train(clf, train_x, train_y)\n    best_clfs.append(best_clf)\n    results.append((name, mean, std))\n\nresults","c1c97695":"preds = np.zeros((len(best_clfs), len(test_x)))\nfor i, best_clf in enumerate(best_clfs):\n    preds[i, :] = best_clf.predict(test_x)","b58cb8ee":"sub = pd.DataFrame(df_test['PassengerId'])\nsub['Survived'] = list(map(int, preds[4, :]))\nsub.to_csv('Results_LightGBM.csv', index=False)","9a5f273d":"sub = pd.DataFrame(df_test['PassengerId'])\nsub['Survived'] = list(map(int, preds[3, :]))\nsub.to_csv('Results_AdaBoost.csv', index=False)","1ce47222":"sub = pd.DataFrame(df_test['PassengerId'])\nsub['Survived'] = list(map(int, preds[2, :]))\nsub.to_csv('Results_RF.csv', index=False)","b620fc7e":"marge_pred = (preds[2, :] + preds[3, :] + preds[4, :]) >= 2\nsub = pd.DataFrame(df_test['PassengerId'])\nsub['Survived'] = list(map(int, marge_pred))\nsub.to_csv('Results_marge_LightGBM_AdaBoost_RF.csv', index=False)","d2d3fcaa":"# Preprocessing","d94f7f62":"# Visualizing Feature Importance","1b14e80d":"# Writing Result Files","9ffa314d":"# Expemriments","d0017812":"# Description(Japanese)\n\n\u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3067\u306f\uff12\u3064\u306e\u3053\u3068\u3092\u884c\u3063\u3066\u3044\u307e\u3059\u3002  \n\uff11\u3064\u306f\u30c7\u30fc\u30bf\u306e\u524d\u51e6\u7406\u3068\u7279\u5fb4\u91cf\u91cd\u8981\u5ea6\u306e\u53ef\u8996\u5316\u3067\u3059\u3002  \n\u3082\u3046\uff11\u3064\u306fscikit-learn\u53ca\u3073LightGBM\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u306e\u8907\u6570\u306e\u5206\u985e\u30e2\u30c7\u30eb\u3092\u8a66\u3057\u307e\u3057\u305f\u3002  \n\n## \u7279\u5fb4\u91cf\u91cd\u8981\u5ea6\u306e\u53ef\u8996\u5316\n\u6c7a\u5b9a\u6728\u304a\u3088\u3073\u30e9\u30f3\u30c0\u30e0\u30d5\u30a9\u30ec\u30b9\u30c8\u3092\u7528\u3044\u3066\u7279\u5fb4\u91cf\u91cd\u8981\u5ea6\u3092\u53ef\u8996\u5316\u3057\u3066\u3044\u307e\u3059\u3002  \n\u672c\u5f53\u306f\u3053\u3053\u3067\u524d\u51e6\u7406\u306e\u59a5\u5f53\u6027\u306a\u3069\u3092\u691c\u8a3c\u3059\u3079\u304d\u3067\u3059\u304c\u884c\u3063\u3066\u3044\u307e\u305b\u3093\u3002  \n\u7cbe\u5ea6\u3092\u6c42\u3081\u308b\u306b\u306f\u3053\u3053\u3089\u3078\u3093\u304c\u91cd\u8981\u306b\u306a\u308a\u305d\u3046\u3067\u3059\u3002  \n\n## \u4f7f\u7528\u3057\u305f\u5206\u985e\u30e2\u30c7\u30eb\n\u4f7f\u7528\u3057\u305f\u30e2\u30c7\u30eb\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3067\u3059\u3002\u307e\u305f\u30c7\u30d5\u30a9\u30eb\u30c8\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u4f7f\u7528\u3057\u3066\u3044\u307e\u3059\u3002\n- SVC  \n    \u30ab\u30fc\u30cd\u30eb\u6cd5\u306b\u57fa\u3065\u304f\u30b5\u30dd\u30fc\u30c8\u30d9\u30af\u30bf\u30fc\u30de\u30b7\u30f3\u3092\u4f7f\u3063\u305f\u5206\u985e\n- GaussianNB  \n    \u30ac\u30a6\u30b9\u5206\u5e03\u306b\u57fa\u3065\u3044\u305f\u30ca\u30a4\u30fc\u30ba\u30d9\u30a4\u30ba\u3092\u4f7f\u3063\u305f\u5206\u985e\n- RandomForest  \n    \u30e9\u30f3\u30c0\u30e0\u30d5\u30a9\u30ec\u30b9\u30c8\u3068\u547c\u3070\u308c\u308b\u8907\u6570\u306e\u6c7a\u5b9a\u6728\u3092\u4f7f\u3063\u305f\u5206\u985e\n- AdaBoost  \n    \u9069\u5fdc\u7684\u306a\u30a2\u30f3\u30b5\u30f3\u30d6\u30eb\u5b66\u7fd2\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u4f7f\u3063\u305f\u5206\u985e\uff08\u30d0\u30c3\u30af\u30a8\u30f3\u30c9\u306e\u5206\u985e\u5668\u306f\u6c7a\u5b9a\u6728\uff09\n- LightGBM\n    \u8efd\u91cf\u306a\u6c7a\u5b9a\u6728\u306e\u30a2\u30f3\u30b5\u30f3\u30d6\u30eb\u5b66\u7fd2\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u4f7f\u3063\u305f\u5206\u985e\n\n\u691c\u8a3c\u306b\u306f5\u5206\u5272\u4ea4\u5dee\u691c\u8a3c\u6cd5\u3092\u7528\u3044\u307e\u3057\u305f\u3002  \n\u7d50\u679c\u306f\u6b21\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n  \n### SVC << GaussianNB << RandomForest < AdaBoost < LightGBM  \n  \n\u3053\u3053\u3067\u306f\u5b9f\u9a13\u7684\u306bRandomForest,AdaBoost,LightGBM  \n\u305d\u3057\u3066\u305d\u308c\u305e\u308c\u306e\u30de\u30fc\u30b8\u3092Test\u7d50\u679c\u3092\u63d0\u51fa\u3057\u305f\u3068\u3053\u308d\u3001  \n\u6b21\u306e\u30b9\u30b3\u30a2\u304c\u5f97\u3089\u308c\u3066\u3044\u307e\u3059\u3002  \n\n| RandomForest | AdaBoost | LightGBM | Marge |\n| ---- | ---- | ---- | ---- |\n| 0.754 | 0.766 | 0.744 | 0.756 |","31a932c9":"# Setting config and Loading data"}}