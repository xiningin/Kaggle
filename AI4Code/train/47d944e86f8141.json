{"cell_type":{"7eb09cd1":"code","dca4a3b1":"code","dc68c273":"code","bb221672":"code","62df0f65":"code","056fdad4":"code","6311aec7":"code","4b4be9ff":"code","f1990017":"code","bbc8db43":"code","1bc44812":"code","b4d6dd5a":"code","2fa3e0ac":"code","e7ecd6c5":"code","ec5f6014":"code","40269e83":"code","240e158f":"code","1a2e4be0":"code","7524e83f":"markdown","fab0b339":"markdown","56d324ce":"markdown","7115e9a0":"markdown","124a81a2":"markdown","b4ebb45e":"markdown","8343533b":"markdown","12d3a2c6":"markdown"},"source":{"7eb09cd1":"train_dir = \"\/kaggle\/input\/food11-image-dataset\/training\"\nval_dir   = \"\/kaggle\/input\/food11-image-dataset\/validation\"\ntest_dir  = \"\/kaggle\/input\/food11-image-dataset\/evaluation\"","dca4a3b1":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntarget_size = (224,224)\nbatch_size = 16\n\n# Data Generator\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n#    rotation_range=40,\n#    width_shift_range=0.2,\n#    height_shift_range=0.2,\n#    shear_range=0.2,\n#    zoom_range=0.2,\n#    horizontal_flip=True,\n#    vertical_flip=True\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=target_size,\n    batch_size=batch_size,\n    color_mode='rgb',    \n    shuffle=True,\n    seed=42,\n    class_mode='categorical')","dc68c273":"valid_datagen = ImageDataGenerator(rescale=1.\/255)\n\nvalid_generator = valid_datagen.flow_from_directory(\n    val_dir,\n    target_size=target_size,\n    batch_size=batch_size,\n    color_mode='rgb',\n    shuffle=False,    \n    class_mode='categorical')","bb221672":"test_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=target_size,\n    batch_size=batch_size,\n    color_mode='rgb',\n    shuffle=False,    \n    class_mode='categorical')","62df0f65":"labels = list(test_generator.class_indices.keys())\nprint(labels)","056fdad4":"import tensorflow.keras as keras\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense","6311aec7":"!pip install -q efficientnet","4b4be9ff":"#from tensorflow.keras.applications import NASNetMobile\n#base_model=NASNetMobile(input_shape=(224,224,3), weights='imagenet',include_top=False)\n\nimport efficientnet.tfkeras as efn\nbase_model = efn.EfficientNetB7(input_shape=(224,224,3), weights='imagenet', include_top=False)","f1990017":"num_classes = len(labels) # food-11","bbc8db43":"# Add Extra Layers to Model\nx=base_model.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(512,activation='relu')(x) \nx=Dense(64,activation='relu')(x) \nout=Dense(num_classes,activation='softmax')(x) #final layer with softmax activation\n\nmodel=Model(inputs=base_model.input,outputs=out)","1bc44812":"# For Transfer Learning\nbase_model.trainable = False","b4d6dd5a":"model.summary()","2fa3e0ac":"# Compile Model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])","e7ecd6c5":"num_epochs = 30\nSTEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n\/\/valid_generator.batch_size\nSTEP_SIZE_TEST =test_generator.n\/\/test_generator.batch_size","ec5f6014":"model.fit(train_generator, steps_per_epoch=STEP_SIZE_TRAIN, epochs=num_epochs, \n          validation_data=valid_generator, validation_steps=STEP_SIZE_VALID)","40269e83":"# Evaluate Model\nloss, acc = model.evaluate(test_generator, steps=STEP_SIZE_TEST)\nprint(\"The accuracy of the model is {:.3f}\\nThe Loss in the model is {:.3f}\".format(acc,loss))","240e158f":"import numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix\n\npreds=model.predict(test_generator)\ny_pred = np.argmax(preds,axis=1)\ny_actual = test_generator.classes\ncm = confusion_matrix(y_actual, y_pred)\nprint(cm)","1a2e4be0":"print(classification_report(y_actual, y_pred, target_names=labels))","7524e83f":"## Build Model","fab0b339":"# Food-11 Classification\n## EfficientNetB7 Transfer Learning","56d324ce":"## classification report","7115e9a0":"## Train Model ","124a81a2":"## Data Augmentation","b4ebb45e":"## Evaluate Model","8343533b":"## Confusion Matrix","12d3a2c6":"### tensorflow 2.6 keras application models \n* tensorflow.keras.applications.DenseNet121\n* tensorflow.keras.applications.DenseNet169\n* tensorflow.keras.applications.DenseNet201\n* tensorflow.keras.applications.EfficientNetB7\n* tensorflow.keras.applications.InceptionResNetV2\n* tensorflow.keras.applications.InceptionV3\n* tensorflow.keras.applications.MobileNetV2\n* tensorflow.keras.applications.MobileNetV3Large\n* tensorflow.keras.applications.MobileNetV3Small\n* tensorflow.keras.applications.NASNetLarge\n* tensorflow.keras.applications.NASNetMobile\n* tensorflow.keras.applications.ResNet50V2\n* tensorflow.keras.applications.ResNet101V2\n* tensorflow.keras.applications.ResNet152V2\n* tensorflow.keras.applications.VGG16\n* tensorflow.keras.applications.VGG19\n* tensorflow.keras.applications.Xception"}}