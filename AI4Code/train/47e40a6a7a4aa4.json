{"cell_type":{"bf1d0adf":"code","b2e514f1":"code","80d3bc89":"code","ea972ac5":"code","cf2cabd2":"code","d845aa41":"code","d464aaa5":"code","0e4d53e6":"code","e4313885":"code","d0aeac5c":"code","f9d321f2":"code","a56fecec":"code","2a104165":"code","835bfffc":"code","aabb2e94":"code","302a60f9":"code","df700415":"code","dcc666d2":"code","b123ffdd":"code","f0ac072e":"code","0c95cfca":"code","419d8f04":"code","00466225":"code","cdbe4380":"code","1080eb5b":"code","bb90b802":"code","837d79db":"code","04f64b7e":"code","d613b7b0":"code","f125c85e":"code","47ff0581":"code","59ef753b":"code","f741e410":"markdown","60a24d3a":"markdown","121aa6a0":"markdown","455e722e":"markdown","f850b657":"markdown","fcc76fee":"markdown","06b20c3a":"markdown","6366a2b3":"markdown","152b5764":"markdown","9ebb5342":"markdown","79236abb":"markdown","f3fe0de8":"markdown"},"source":{"bf1d0adf":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom nltk.corpus import stopwords\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence,text\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation,Flatten\nfrom keras.layers import  Embedding, LSTM,Bidirectional,SimpleRNN\nfrom keras import metrics, regularizers\nfrom keras.optimizers import RMSprop\nfrom sklearn.utils import shuffle\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","b2e514f1":"df=pd.read_csv('\/kaggle\/input\/tweets-of-trump-and-trudeau\/tweets.csv')","80d3bc89":"df=shuffle(df)\ndf.info()","ea972ac5":"print(df.head())\ndf.drop(columns='id',inplace=True)\ndf.head()","cf2cabd2":"df.describe()","d845aa41":"df.status[0]","d464aaa5":"df = df.apply(lambda x: x.astype(str).str.lower())\ndf.head()","0e4d53e6":"df.author.unique()","e4313885":"df.isnull().any()","d0aeac5c":"df[df.status.duplicated()].count()","f9d321f2":"for status in df.status[0:10]:\n    print(status)","a56fecec":"df['status']=df.status.str.replace(r'http[s]?:(?:[a-zA-Z]|[0-9]|[$-_@.& +]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','',regex=True)\ndf['status']=df.status.str.replace(r'\\@\\w*\\b','',regex=True)\ndf['status']=df.status.str.replace(r'\\#\\w*\\b','',regex=True)\ndf['status']=df.status.str.replace(r'\\b\\d+','',regex=True)\ndf['status']=df.status.str.replace(r'\\W*\\b\\w{1,2}\\b','',regex=True)\ndf['status']=df['status'].str.findall('\\w{2,}').str.join(' ')","2a104165":"for status in df.status[0:40]:\n    print(status)","835bfffc":"stop_words = stopwords.words('english')    \nstop_words","aabb2e94":"df['status'] = df['status'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))","302a60f9":"print(\"Minimum kelime say\u0131s\u0131 ..:\" ,df['status'].str.split().str.len().min())\nprint(\"Maximum kelime say\u0131s\u0131 ..:\" ,df['status'].str.split().str.len().max())\nprint(\"Maximum kelime say\u0131s\u0131 ..:\" ,df['status'].str.split().str.len().mean())","df700415":"df[df['status'].str.split().str.len()<3]","dcc666d2":"df[df['status'].str.split().str.len()<3].count()","b123ffdd":"df.drop(df[df['status'].str.split().str.len()<3].index,inplace=True)\ndf.reset_index(drop=True, inplace=True)","f0ac072e":"df.author.value_counts()","0c95cfca":"le = LabelEncoder()\ntags = le.fit_transform(df.author)","419d8f04":"num_max = 10000\nmax_len = 14\n## The process of enumerating words\ntok = Tokenizer(num_words=num_max)\ntok.fit_on_texts(df.status)","00466225":"print(df.status[10])\n\nfor item in df.status[10].split():    \n    print(tok.word_index[item])","cdbe4380":"cnn_texts_seq = tok.texts_to_sequences(df.status)\ncnn_texts_mat = sequence.pad_sequences(cnn_texts_seq,maxlen=max_len,padding='post')","1080eb5b":"print('***************************************************')\nprint(df.status[10])\nprint(cnn_texts_mat[10])\nprint('***************************************************')\n","bb90b802":"X_train,X_test,y_train,y_test=train_test_split(cnn_texts_mat,tags,test_size=0.15, random_state=42)","837d79db":"labels = 'X_train', 'X_test'\nsizes = [len(X_train), len(X_test)]\nexplode = (0, 0.1)\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',shadow=True, startangle=90)\nax1.axis('equal')\nplt.title(\"% Oran\")\nplt.show()","04f64b7e":"batch_size=8\nverbose=1\nvalidation_split=0.1\nnum_max=10000","d613b7b0":"model=Sequential()\nmodel.add(Embedding(num_max,max_len, trainable=True,input_length=max_len))\nmodel.add(SimpleRNN(128,activation='relu',kernel_regularizer=regularizers.l2(0.001),return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(SimpleRNN(64,activation='relu',kernel_regularizer=regularizers.l2(0.001),return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(SimpleRNN(32,activation='relu',kernel_regularizer=regularizers.l2(0.001),return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(Bidirectional(LSTM(16,activation='relu',kernel_regularizer=regularizers.l2(0.001),return_sequences=True)))\nmodel.add(Dropout(0.2))\nmodel.add(Bidirectional(LSTM(4,activation='relu',kernel_regularizer=regularizers.l2(0.001))))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer=RMSprop(lr=0.001),metrics=['acc'])\nmodel.summary()","f125c85e":"history=model.fit(X_train, y_train, epochs=10, batch_size=batch_size,verbose=verbose,validation_split=validation_split)","47ff0581":"model.evaluate(X_test, y_test, verbose=0)","59ef753b":"plt.plot(history.history['acc'], label='Acc')\nplt.plot(history.history['val_acc'], label='Val Acc')\nplt.ylabel('Acc')\nplt.xlabel('Epoch Say\u0131s\u0131')\nplt.legend(loc=\"upper left\")\nplt.show()","f741e410":"#### ****Cleaning if the tweet length is less than 3 and index reset****","60a24d3a":"#### ****Data set null values?****","121aa6a0":"#### ****Sample vectorization****","455e722e":"#### ****Data set tweet word lengths****","f850b657":"#### ****Cleaning stop words****","fcc76fee":"#### ****Data set duplicate values****","06b20c3a":"#### ****Dataset after****","6366a2b3":"#### ****Padding max_len=14****","152b5764":"#### ****Data set values****","9ebb5342":"#### ****Data set is converted to lowercase****","79236abb":"#### ****Clear dataset unwanted values****","f3fe0de8":"#### ****Data set unique values****"}}