{"cell_type":{"5b861ceb":"code","cecb4323":"code","e41416b5":"code","b3f827b2":"code","2e855e0f":"code","ade6bf40":"code","2cd385fb":"code","d5b576ae":"code","96056341":"code","60488cd0":"code","dea9320d":"markdown","a9bf7ccf":"markdown","0123722b":"markdown","d8f2930d":"markdown","e8068f41":"markdown","21fd5482":"markdown"},"source":{"5b861ceb":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os","cecb4323":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ndata=pd.read_csv('\/kaggle\/input\/mall-customerscsv\/Mall_Customers.csv')\ndata.head(5)\n ","e41416b5":"x=data.iloc[:,[3,4]].values\n","b3f827b2":"import scipy.cluster.hierarchy as sch\ndendrogan=sch.dendrogram(sch.linkage(x,method=\"ward\"))\nplt.title(\"Dendrogram\")\nplt.xlabel(\"Customers\") ## Customers(Observation Points) rows\nplt.ylabel(\"Euclidian Distances\")##\nplt.show()\n## x: 1-100 customers\n## y: euclidian distance","2e855e0f":"from sklearn.cluster import AgglomerativeClustering\nhc=AgglomerativeClustering(n_clusters=5, affinity=\"euclidean\", linkage=\"ward\")\nhc","ade6bf40":"y_hc=hc.fit_predict(x)\ny_hc","2cd385fb":"plt.scatter(x[y_hc == 0, 0],x[y_hc == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(x[y_hc == 1, 0], x[y_hc == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(x[y_hc == 2, 0],x[y_hc == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(x[y_hc == 3, 0], x[y_hc == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\nplt.scatter(x[y_hc == 4, 0], x[y_hc == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()","d5b576ae":"from sklearn.cluster import AgglomerativeClustering\nhc=AgglomerativeClustering(n_clusters=3, affinity=\"euclidean\", linkage=\"ward\")\nhc\n","96056341":"y_hc=hc.fit_predict(x)\ny_hc","60488cd0":"plt.scatter(x[y_hc == 0, 0],x[y_hc == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(x[y_hc == 1, 0], x[y_hc == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(x[y_hc == 2, 0],x[y_hc == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(x[y_hc == 3, 0], x[y_hc == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\nplt.scatter(x[y_hc == 4, 0], x[y_hc == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()","dea9320d":"## Using the dendrogram to find the optimal number of clusters","a9bf7ccf":"## Visualising the clusters","0123722b":"## Importing the dataset","d8f2930d":"# Hierarchical Clustering","e8068f41":"## Training the Hierarchical Clustering model on the dataset","21fd5482":"## Importing the libraries"}}