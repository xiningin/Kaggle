{"cell_type":{"cf7838c7":"code","2428aed0":"code","0b8bb6ef":"code","1a016546":"code","6b94e06d":"code","31e05d02":"code","180da574":"code","e4880138":"code","3f9437b4":"code","789c6039":"code","6f2a9a2f":"code","b4c0753f":"code","9ab0389d":"code","61591822":"code","42fa0010":"code","ec2dff55":"code","1e907080":"code","75df5288":"code","7f5181b6":"code","12e71c24":"code","832766aa":"code","b2f66d8b":"code","cc4c049a":"code","978252c2":"code","893f59c1":"code","9b589ddb":"code","5a8fc172":"code","f2c9a64d":"code","5ddcbd32":"code","7caec572":"code","53ab5124":"code","7facb28c":"code","7e610ab5":"code","e46fe2d4":"code","e5590b6d":"code","0aa09d5c":"code","4a41cb4f":"code","fc195697":"code","6c915b47":"markdown","92198e09":"markdown","c4e5b1ba":"markdown","0680f4bb":"markdown","d2d9d2b2":"markdown","8e5ccbbe":"markdown","e7017ea6":"markdown","8f663a7d":"markdown","e17d7b98":"markdown","27055f76":"markdown","5f10e7bd":"markdown","c12e00fd":"markdown","16b9c537":"markdown","f1699ebe":"markdown","ca947820":"markdown"},"source":{"cf7838c7":"import numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelBinarizer, LabelEncoder, OrdinalEncoder\nfrom sklearn.base import TransformerMixin\n\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report, plot_confusion_matrix\n\n\npd.options.mode.chained_assignment = None\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","2428aed0":"df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","0b8bb6ef":"df.head()","1a016546":"df.describe()","6b94e06d":"df.info()","31e05d02":"df.hist(figsize=(16,8));","180da574":"# Check for duplicated data\ndf.duplicated().sum()","e4880138":"# Split the training data\ndf_train,df_val = train_test_split(df, test_size=0.2, random_state=42)","3f9437b4":"print('Shape:', df_train.shape)\ndf_train.head()","789c6039":"print('Shape:',df_test.shape)\ndf_val.head()","6f2a9a2f":"# Check missing value\npd.DataFrame({\n    'Train Total': df_train.isna().sum(),\n    'Train Percentage': df_train.isna().sum()*100\/df_train.shape[0],\n    'Validation Total': df_val.isna().sum(),\n    'Validation Percentage': df_val.isna().sum()*100\/df_val.shape[0],\n    'Test Total': df_test.isna().sum(),\n    'Test Percentage': df_test.isna().sum()*100\/df_test.shape[0]\n})","b4c0753f":"# handling missing value training data\ndf_train['Age'].fillna(df_train['Age'].mean(), inplace=True)\ndf_train.drop(columns='Cabin', axis=1,inplace=True)\ndf_train.dropna(subset=['Embarked'],axis=0, inplace=True)\n\n# handling missing value validation data\ndf_val['Age'].fillna(df_train['Age'].mean(), inplace=True)\ndf_val.drop(columns='Cabin', axis=1,inplace=True)\n\n# handling missing value test data\ndf_test['Age'].fillna(df_train['Age'].mean(), inplace=True)\ndf_test.drop(columns='Cabin', axis=1,inplace=True)\ndf_test.dropna(subset=['Embarked'],axis=0, inplace=True)","9ab0389d":"pd.DataFrame({\n    'Train': df_train.isna().sum(),\n    'Validation': df_val.isna().sum(),\n    'Test': df_test.isna().sum(),\n})","61591822":"# Extract Title from Name\nfor dataframe in (df_train,df_val,df_test):\n    dataframe['Title'] = dataframe['Name'].apply(lambda s : s.split(',')[1].split('.')[0].strip())\n","42fa0010":"df_train.head()","ec2dff55":"for dataframe in (df_train,df_val,df_test):\n    dataframe.drop(columns=[\"Name\",\"Ticket\",\"Fare\"],inplace=True)","1e907080":"# Simplify the column SibSp and Parch by combining this column and store it in FamilySize\nfor dataframe in (df_train,df_val,df_test):\n    dataframe['FamilySize'] = dataframe['SibSp'] + dataframe['Parch'] + 1\n\nfor dataframe in (df_train,df_val,df_test):\n    dataframe.drop(columns=['SibSp','Parch'], inplace=True)","75df5288":"df_train.head()","7f5181b6":"sns.barplot(x='Sex',y=\"Survived\",data=df_train)","12e71c24":"sns.barplot(x='FamilySize',y=\"Survived\",data=df_train)","832766aa":"sns.barplot(x='Title',y=\"Survived\",data=df_train)","b2f66d8b":"sns.barplot(x='Embarked',y=\"Survived\",data=df_train)","cc4c049a":"sns.barplot(x='Pclass',y=\"Survived\",data=df_train)","978252c2":"sns.histplot(data=df_train, x=\"Age\", kde=True)","893f59c1":"X_train = df_train.drop(columns=['Survived','PassengerId'])\ny_train = df_train['Survived']\nX_val = df_val.drop(columns=['Survived','PassengerId'])\ny_val = df_val['Survived']\nX_test = df_test.drop(columns=['PassengerId'])\npassanger_id = df_test['PassengerId']","9b589ddb":"# class MyLabelBinarizer(TransformerMixin):\n#     def __init__(self, *args, **kwargs):\n#         self.encoder = LabelBinarizer(*args, **kwargs)\n#     def fit(self, x, y=0):\n#         self.encoder.fit(x)\n#         return self\n#     def transform(self, x, y=0):\n#         return self.encoder.transform(x)","5a8fc172":"preprocess = make_column_transformer(\n    (OrdinalEncoder(),['Sex']),\n    (OneHotEncoder(handle_unknown = 'ignore'),['Embarked','Title']),\n    (StandardScaler(),['Age'])\n)\n\npipeline = Pipeline([\n    ('preprocess',preprocess),\n])\n\nX_train_transformed = pipeline.fit_transform(X_train)","f2c9a64d":"# Logistic Regression\nlr = LogisticRegression()\nlr.fit(X_train_transformed, y_train)\n\n# Support Vector Machine\nsvc = SVC()\nsvc.fit(X_train_transformed, y_train)\n\n# Random Forest\nrf = RandomForestClassifier()\nrf.fit(X_train_transformed, y_train)\n\n# K Nearest Neighbor\nknn = KNeighborsClassifier()\nknn.fit(X_train_transformed, y_train)\n\nprint('Train Successful')","5ddcbd32":"# Logistic Regression\nX_val_transformed = pipeline.transform(X_val)\ny_val_pred = lr.predict(X_val_transformed)\nlr_acc = accuracy_score(y_val_pred,y_val)\nprint('======Logistic Regression======')\nprint(classification_report(y_val, y_val_pred))\n\n# Support Vector Machine\nX_val_transformed = pipeline.transform(X_val)\ny_val_pred = svc.predict(X_val_transformed)\nsvc_acc = accuracy_score(y_val_pred,y_val)\nprint('======SVM======')\nprint(classification_report(y_val, y_val_pred))\n\n# Random Forest\nX_val_transformed = pipeline.transform(X_val)\ny_val_pred = rf.predict(X_val_transformed)\nrf_acc = accuracy_score(y_val_pred,y_val)\nprint('======Random Forest======')\nprint(classification_report(y_val, y_val_pred))\n\n# K Nearest Neighbor\nX_val_transformed = pipeline.transform(X_val)\ny_val_pred = knn.predict(X_val_transformed)\nknn_acc = accuracy_score(y_val_pred,y_val)\nprint('======KNN======')\nprint(classification_report(y_val, y_val_pred))","7caec572":"acc_result = pd.DataFrame({\n    'Logistic Regression': [lr_acc],\n    'SVM':[svc_acc],\n    'Random Forest': [rf_acc],\n    'K Nearest Neighbor': [knn_acc]\n},index=['Score'])\n\nacc_result.T","53ab5124":"# logistic regression\nplot_confusion_matrix(lr, X_val_transformed, y_val)  ","7facb28c":"# SVM\nplot_confusion_matrix(svc, X_val_transformed, y_val)  ","7e610ab5":"# Random Forest\nplot_confusion_matrix(rf, X_val_transformed, y_val) ","e46fe2d4":"# KNN\nplot_confusion_matrix(knn, X_val_transformed, y_val) ","e5590b6d":"lr_score = cross_val_score(lr, X_val_transformed, y_val, cv=5).mean()\nsvc_score = cross_val_score(svc, X_val_transformed, y_val, cv=5).mean()\nrf_score = cross_val_score(rf, X_val_transformed, y_val, cv=5).mean()\nknn_score = cross_val_score(knn, X_val_transformed, y_val, cv=5).mean()","0aa09d5c":"crosval_result = pd.DataFrame({\n    'Logistic Regression': [lr_score],\n    'SVM':[svc_score],\n    'Random Forest': [rf_score],\n    'K Nearest Neighbor': [knn_score]\n},index=['Score'])\n\ncrosval_result.T","4a41cb4f":"parameters = {\n    'penalty' : ['l2'],\n    'C' : [1,0.1,0.5,0.01],\n    'solver':['lbfgs']\n}\ngrid = GridSearchCV(estimator=LogisticRegression(),param_grid=parameters)\ngrid.fit(X_train_transformed, y_train)\nprint(grid.best_params_)\nprint(grid.best_score_)","fc195697":"X_test_transformed = pipeline.transform(X_test)\ny_final = lr.predict(X_test_transformed)\n\nsubmission = pd.DataFrame({\n        \"PassengerId\": passanger_id,\n        \"Survived\": y_final\n    })\nsubmission.to_csv('submission.csv', index=False)\nprint('Successfully save to csv')","6c915b47":"We have missing values for Age, Cabin in all dataset, only missing Fare in Test dataset, and Embarked in training dataset.\n- Age -> The data is almost normally distributed, so we can impute the value using mean.\n- Cabin -> All dataset have more than 70% missing values in this category, we can drop this column.\n- Fare -> Lets remove the row of missing value in this category.","92198e09":"## VII. Data Preprocessing","c4e5b1ba":"The classic Titanic ML competition is simple machine learning case to create model that predicts which passengers survived the Titanic shipwrek.  \nOn April 15, 1912, during her maiden voyage, the widely considered \u201cunsinkable\u201d RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren\u2019t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\n**Work Flow**  \nI. Business Understanding  \nII. Import Package  \nIII. Data Loading  \nIV. Data Understanding  \nV. Data Cleaning and Transformation  \nVI. Exploratory Data Analysis  \nVII. Data Preprocessing  \nVIII. Model Selection  \nIX. Fine-Tune Model  \nX. Submission","0680f4bb":"## IX. Fine-Tuning Model","d2d9d2b2":"## II. Import Package","8e5ccbbe":"Ticket, Name, and Fare features seem not that important so we can drop this column","e7017ea6":"## I. Business Understanding","8f663a7d":"## III. Data Loading","e17d7b98":"## X. Submission","27055f76":"### Cross Validation","5f10e7bd":"## VIII. Model Selection","c12e00fd":"## V. Data Cleaning and Transformation","16b9c537":"## IV. Data Understanding","f1699ebe":"## VI. Exploratory Data Analysis","ca947820":"The training dataset consists of the following features:  \n- PassengerId -> Id of Passanger, integer\n- Survived -> This is the label column explaining whether the passanger survived or not, integer (0,1)\n- Pclass -> Ticket class, string\n- Name -> Name contains firstname, title, and lastname, string\n- Sex -> Gender, string (male,female)\n- Age -> Age in years, float\n- SibSp -> Number of siblings\/spouse abroad, integer\n- Parch -> Number of parents\/children, integer\n- Ticket -> Ticket Number, string\n- Fare -> Passanger fare, float\n- Cabin -> Cabin number, string\n- Embarked -> port of embarktion, string"}}