{"cell_type":{"76725c9b":"code","785eaf05":"code","c719ef46":"code","4807da25":"code","e27f5090":"code","a9d3a21d":"code","8272352c":"code","6b4eaef4":"markdown","925c7cff":"markdown","d1c57e7c":"markdown","fce20f22":"markdown","7500410e":"markdown","f88d2fc8":"markdown","0da5bfec":"markdown","d24a6a98":"markdown","9cb33fa6":"markdown"},"source":{"76725c9b":"import numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.models import Model\n\n\ndef preprocess(array):\n    \"\"\"\n    Normalizes the supplied array and reshapes it into the appropriate format.\n    \"\"\"\n\n    array = array.astype(\"float32\") \/ 255.0\n    array = np.reshape(array, (len(array), 28, 28, 1))\n    return array\n\n\ndef noise(array):\n    \"\"\"\n    Adds random noise to each image in the supplied array.\n    \"\"\"\n\n    noise_factor = 0.4\n    noisy_array = array + noise_factor * np.random.normal(\n        loc=0.0, scale=1.0, size=array.shape\n    )\n\n    return np.clip(noisy_array, 0.0, 1.0)\n\n\ndef display(array1, array2):\n    \"\"\"\n    Displays ten random images from each one of the supplied arrays.\n    \"\"\"\n\n    n = 10\n\n    indices = np.random.randint(len(array1), size=n)\n    images1 = array1[indices, :]\n    images2 = array2[indices, :]\n\n    plt.figure(figsize=(20, 4))\n    for i, (image1, image2) in enumerate(zip(images1, images2)):\n        ax = plt.subplot(2, n, i + 1)\n        plt.imshow(image1.reshape(28, 28))\n        plt.gray()\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\n        ax = plt.subplot(2, n, i + 1 + n)\n        plt.imshow(image2.reshape(28, 28))\n        plt.gray()\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\n    plt.show()","785eaf05":"# Since we only need images from the dataset to encode and decode, we\n# won't use the labels.\n(train_data, _), (test_data, _) = mnist.load_data()\n\n# Normalize and reshape the data\ntrain_data = preprocess(train_data)\ntest_data = preprocess(test_data)\n\n# Create a copy of the data with added noise\nnoisy_train_data = noise(train_data)\nnoisy_test_data = noise(test_data)\n\n# Display the train data and a version of it with added noise\ndisplay(train_data, noisy_train_data)","c719ef46":"input = layers.Input(shape=(28, 28, 1))\n\n# Encoder\nx = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input)\nx = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\nx = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n\n# Decoder\nx = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\nx = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\nx = layers.Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n\n# Autoencoder\nautoencoder = Model(input, x)\nautoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\nautoencoder.summary()","4807da25":"autoencoder.fit(\n    x=train_data,\n    y=train_data,\n    epochs=50,\n    batch_size=128,\n    shuffle=True,\n    validation_data=(test_data, test_data),\n)","e27f5090":"predictions = autoencoder.predict(test_data)\ndisplay(test_data, predictions)","a9d3a21d":"autoencoder.fit(\n    x=noisy_train_data,\n    y=train_data,\n    epochs=100,\n    batch_size=128,\n    shuffle=True,\n    validation_data=(noisy_test_data, test_data),\n)","8272352c":"predictions = autoencoder.predict(noisy_test_data)\ndisplay(noisy_test_data, predictions)","6b4eaef4":"## Build the autoencoder\nWe are going to use the Functional API to build our convolutional autoencoder.","925c7cff":"## Train the model\nNow that we know that our autoencoder works, let's retrain it using the noisy\ndata as our input and the clean data as our target. We want our autoencoder to\nlearn how to denoise the images.","d1c57e7c":"## Introduction\nThis example demonstrates how to implement a deep convolutional autoencoder\nfor image denoising, mapping noisy digits images from the MNIST dataset to\nclean digits images. This implementation is based on an original blog post\ntitled [Building Autoencoders in Keras](https:\/\/blog.keras.io\/building-autoencoders-in-keras.html)\nby [Fran\u00e7ois Chollet](https:\/\/twitter.com\/fchollet).","fce20f22":"Title: Convolutional autoencoder for image denoising\nAuthor: [Santiago L. Valdarrama](https:\/\/twitter.com\/svpino)\nDate created: 2021\/03\/01\nLast modified: 2021\/03\/01\nDescription: How to train a deep convolutional autoencoder for image denoising.","7500410e":"## Prepare the data","f88d2fc8":"## Make predictions\nLet's now predict on the noisy data and display the results of our autoencoder.\nNotice how the autoencoder does an amazing job at removing the noise from the\ninput images.","0da5bfec":"Let's predict on our test dataset and display the original image together with\nthe prediction from our autoencoder.\nNotice how the predictions are pretty close to the original images, although\nnot quite the same.","d24a6a98":"Now we can train our autoencoder using `train_data` as both our input data\nand target. Notice we are setting up the validation data using the same\nformat.","9cb33fa6":"## Setup"}}