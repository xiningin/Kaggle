{"cell_type":{"a8b08aca":"code","58373be3":"code","7e9db39a":"code","406c2c92":"code","d053ed4c":"code","b4f5d90a":"code","4dcfcb77":"code","f5910438":"code","a3e80edc":"code","ae9b94f8":"code","12edef4f":"code","ef9dea40":"code","11084714":"code","dc38e52f":"code","0110e0e3":"code","ffe4d79e":"code","d27de9ce":"code","7719fe7f":"code","b8c118c2":"code","96681d06":"code","9f3d587f":"code","9b407f73":"code","84d9e52d":"code","16c7d21e":"code","10d34def":"code","54c67751":"code","55609fd0":"code","da6655c9":"code","d7974557":"code","fd2c60d6":"code","5f5ff06d":"code","9cd99c66":"code","633d695f":"code","db5b2f2a":"code","202d8848":"markdown","8a960848":"markdown","41a7b46f":"markdown","41c29953":"markdown","b3a4aab7":"markdown","b08ee278":"markdown","d88d0902":"markdown","25827f8b":"markdown","52b77b91":"markdown","6deb6980":"markdown","c0c4792f":"markdown","6eac1c5c":"markdown","b57df4c6":"markdown","42bceae3":"markdown","1cc076a2":"markdown","a6d04dea":"markdown","456efc04":"markdown","d9f5a090":"markdown","fd1c5f75":"markdown","6f5d668b":"markdown"},"source":{"a8b08aca":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","58373be3":"import pandas as pd\nfile_path = '..\/input\/police-violence-in-the-us\/police_killings.csv'\nmy_data = pd.read_csv(file_path)\nstate_sum = my_data.groupby(['State', \"Victim's race\"]).count()\nstate_sum[\"Victim's name\"].head()","7e9db39a":"race_AK = state_sum.loc['AK'][\"Victim's name\"].index\nimport matplotlib.pyplot as plt\nlabels = race_AK\nsizes = state_sum.loc['AK'][\"Victim's name\"]\nexplode = (0.3, 0, 0, 0, 0, 0) \n\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, explode = explode, labels=labels, autopct='%1.1f%%', shadow=True, startangle=150)\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\nax1.set_title('Police Killings as Percentage')\n","406c2c92":"import matplotlib.pyplot as plt\ndef create_pie_chart(input_df, state):\n# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n    labels = input_df.loc[state][\"Victim's name\"].index\n    sizes = input_df.loc[state][\"Victim's name\"]\n    \n    explode_len = len(input_df.loc[state][\"Victim's name\"].index)\n    zero_list = [0]*explode_len\n    if input_df.loc[state][\"Victim's name\"].index[0] == 'Black':\n        zero_list[0] = 0.2\n    elif input_df.loc[state][\"Victim's name\"].index[1] == 'Black':\n        zero_list[1] = 0.2\n    elif input_df.loc[state][\"Victim's name\"].index[2] == 'Black':\n        zero_list[2] = 0.2\n        \n    explode = tuple(zero_list)\n\n    fig1, ax1 = plt.subplots()\n    ax1.pie(sizes, explode = explode, labels=labels, autopct='%1.1f%%',\n            shadow=True, startangle=180)\n    ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n    ax1.set_title('Police Killings by Race as Percentage')\n    return plt.show()","d053ed4c":"create_pie_chart(state_sum, 'VA')","b4f5d90a":"import pandas as pd\ndemo_filepath = '..\/input\/us-state-population-with-demographic-info-2017\/Demographic_by_state.xlsx'\nmy_data2 = pd.read_excel(demo_filepath)\n","4dcfcb77":"my_data2 = my_data2.set_index('State')\nmy_data2 = my_data2.rename(columns = {'Hispanic (of any race)' : 'Hispanic', 'Non-Hispanic White' : 'White', 'Non-Hispanic Black' : 'Black', 'Non-Hispanic Asian' : 'Asian', 'Non-Hispanic American Indian' : 'Native American'})\nmy_data2 = my_data2.sort_index()\nmy_data2.head()","f5910438":"my_data.columns\nmy_data[\"Victim's race\"].unique()\nhispanic_data = my_data[my_data[\"Victim's race\"] == 'Hispanic']\nhispanic_data.head()\nsorted_hm = hispanic_data[[\"Victim's name\", 'State']]\nhispanic_group = sorted_hm.groupby('State')[\"Victim's name\"].nunique()\nhispanic_df = hispanic_group.to_frame()\nhispanic_df = hispanic_df.rename(columns = {\"Victim's name\" : 'Hispanic Police Killings'})\nhispanic_df.head()","a3e80edc":"def pull_race_data(data, race):\n    new_data = data[data[\"Victim's race\"] == race]\n    sort_data = new_data[[\"Victim's name\", \"State\"]]\n    data_grouped = sort_data.groupby('State')[\"Victim's name\"].nunique()\n    data_df = data_grouped.to_frame()\n    data_df = data_df.rename(columns = {\"Victim's name\" : race + ' Police Killings'})\n    return data_df","ae9b94f8":"black_df = pull_race_data(my_data, 'Black')\nwhite_df = pull_race_data(my_data, 'White')\nnative_df = pull_race_data(my_data, 'Native American')\nother_df = pull_race_data(my_data, 'Unknown race')","12edef4f":"police_killing_total = my_data[[\"Victim's name\", 'State']]\nmurder_state_total = police_killing_total.groupby('State')[\"Victim's name\"].nunique()\nmurder_total_df = murder_state_total.to_frame()\nmurder_total_df = murder_total_df.rename(columns = {\"Victim's name\" : 'Total Police Killings'})\nmurder_total_df.head()","ef9dea40":"hispanic_df['Total Police Killings'] = murder_total_df['Total Police Killings']\nhispanic_df[['Hispanic Population', 'Total State Pop']] = my_data2[['Hispanic', 'Total population']]\n\nblack_df['Total Police Killings'] = murder_total_df['Total Police Killings']\nblack_df[['Black Population', 'Total State Pop']] = my_data2[['Black', 'Total population']]\n\nwhite_df['Total Police Killings'] = murder_total_df['Total Police Killings']\nwhite_df[['White Population', 'Total State Pop']] = my_data2[['White', 'Total population']]\n\nnative_df['Total Police Killings'] = murder_total_df['Total Police Killings']\nnative_df[['Native American Population', 'Total State Pop']] = my_data2[['Native American', 'Total population']]\n\n","11084714":"native_df.head()","dc38e52f":"hispanic_df['Hispanic PK as Percentage'] = 100*(hispanic_df['Hispanic Police Killings'] \/ hispanic_df['Total Police Killings'])\nwhite_df['White PK as Percentage'] = 100*(white_df['White Police Killings'] \/ white_df['Total Police Killings'])\nblack_df['Black PK as Percentage'] = 100*(black_df['Black Police Killings'] \/ black_df['Total Police Killings'])\nnative_df['Native PK as Percentage'] = 100*(native_df['Native American Police Killings'] \/ native_df['Total Police Killings'])","0110e0e3":"native_df.head()","ffe4d79e":"hispanic_df['Hispanic Pop as Percentage'] = 100*(hispanic_df['Hispanic Population'] \/ hispanic_df['Total State Pop'])\nwhite_df['White Pop as Percentage'] = 100*(white_df['White Population'] \/ white_df['Total State Pop'])\nblack_df['Black Pop as Percentage'] = 100*(black_df['Black Population'] \/ black_df['Total State Pop'])\nnative_df['Native Pop as Percentage'] = 100*(native_df['Native American Population'] \/ native_df['Total State Pop'])","d27de9ce":"native_df.head()","7719fe7f":"Compare_perc_df = pd.DataFrame([hispanic_df['Hispanic PK as Percentage'], hispanic_df['Hispanic Pop as Percentage'], white_df['White PK as Percentage'], white_df['White Pop as Percentage'], black_df['Black PK as Percentage'], black_df['Black Pop as Percentage'], native_df['Native PK as Percentage'],  native_df['Native Pop as Percentage']])\nCompare_perc_df = Compare_perc_df.transpose()\nCompare_perc_df = Compare_perc_df.fillna(0)","b8c118c2":"Compare_perc_df.head()","96681d06":"highest_diff_b = pd.DataFrame([Compare_perc_df['Black PK as Percentage'] - Compare_perc_df['Black Pop as Percentage']]).transpose()","9f3d587f":"highest_diff_b.sort_values(0, ascending = False).head()","9b407f73":"RI_compare = Compare_perc_df.loc['RI']\nDC_compare = Compare_perc_df.loc['DC']\nIL_compare = Compare_perc_df.loc['IL']\nNJ_compare = Compare_perc_df.loc['NJ']\nMD_compare = Compare_perc_df.loc['MD']\n","84d9e52d":"import matplotlib.pyplot as plt\ndef create_pie_charts(input_list, state):\n# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n    labels = 'Hispanic', 'White', 'Black', 'Native American'\n    sizes1 = input_list[[0, 2, 4, 6]]\n    sizes2 = input_list[[1, 3, 5, 7]]\n    explode = (0, 0, 0.3, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\n    fig, (ax1, ax2) = plt.subplots(1,2)\n    ax1.pie(sizes1, explode = explode, labels=labels, autopct='%1.1f%%',\n            shadow=True, startangle=150)\n    ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n    ax2.pie(sizes2, explode = explode, labels=labels, autopct='%1.1f%%',\n            shadow=True, startangle=150)\n    ax2.axis('equal')\n    ax1.set_title('Police Murder Rate as Percentage', fontsize = 10)\n    ax2.set_title('Population as Percentage', fontsize = 10)\n    fig.suptitle(state)\n    \n    fig.savefig(state + '_Police.png')\n    return plt.show()","16c7d21e":"create_pie_charts(RI_compare, 'Rhode Island')","10d34def":"create_pie_charts(DC_compare, 'District of Columbia')","54c67751":"create_pie_charts(IL_compare, 'Illinois')","55609fd0":"create_pie_charts(NJ_compare, 'New Jersey')","da6655c9":"create_pie_charts(MD_compare, 'Maryland')","d7974557":"def per_100000(population_cleaned, race):\n    _per_100000 = 100000*(population_cleaned[race + ' Police Killings'] \/ population_cleaned[race + ' Population'])\n    return _per_100000","fd2c60d6":"native_per_100k = per_100000(native_df, 'Native American')\nblack_per_100k = per_100000(black_df, 'Black')\nwhite_per_100k = per_100000(white_df, 'White')\nhispanic_per_100k = per_100000(hispanic_df, 'Hispanic')\n","5f5ff06d":"compare_per_100k = pd.DataFrame([native_per_100k, white_per_100k, black_per_100k, hispanic_per_100k]).transpose()\ncompare_per_100k = compare_per_100k.rename(columns = {0: 'Native American', 1: 'White', 2:'Black', 3:'Hispanic'})\ncompare_per_100k = compare_per_100k.fillna(0)\ncompare_per_100k.head()","9cd99c66":"compare_per_100k = compare_per_100k.sort_index()\ncompare_per_100k.head()","633d695f":"import numpy as np\nper_ten = compare_per_100k[['Native American',\n                      'White', 'Black', 'Hispanic']]\n\nx = np.arange(len(per_ten))  # the label locations\nwidth = 0.2  # the width of the bars\n\nfig, ax = plt.subplots(figsize=(25,10))\ni = 0\nfor elt in per_ten.columns:\n    barplot = ax.bar(x + width\/2 + (i-3)*width, per_ten[elt], width)\n    i+=1\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Police Killings')\nax.set_title('Police Killings by Race per 100,000')\nax.set_xticks(x)\nax.set_xticklabels(per_ten.index, rotation=30, horizontalalignment='right')\nax.legend(['Native American', 'White Populaton', 'Black Population', 'Hispanic Population'])\n\nfig.tight_layout()\n\nplt.show()","db5b2f2a":"import numpy as np\nper_ten = compare_per_100k[['White', 'Black', 'Hispanic']]\n\nx = np.arange(len(per_ten))  # the label locations\nwidth = 0.2  # the width of the bars\n\nfig, ax = plt.subplots(figsize=(25,10))\ni = 0\nfor elt in per_ten.columns:\n    barplot = ax.bar(x + width\/2 + (i-3)*width, per_ten[elt], width)\n    i+=1\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Police Killings')\nax.set_title('Police Killings by Race per 100,000')\nax.set_xticks(x)\nax.set_xticklabels(per_ten.index, rotation=30, horizontalalignment='right')\nax.legend(['White Populaton', 'Black Population', 'Hispanic Population'])\n\nfig.tight_layout()\n\nplt.show()","202d8848":"Create the police killing percentage column for each population, and create the column for population as a percentage for each state","8a960848":"Sort the data and test one state on dataset:","41a7b46f":"Create a function to save myself time for each race:","41c29953":"Police brutality of minority groups, especially the black community in America has lead to protests and riots all over the world in 2020. This notebook uses the police brutality dataset and a population dataset for race in each state to compare the numbers and identify states where police killings happen more frequently to minorities. First the dataset is imported, next a pie chart to compare percentage of killings by race, third the population dataset is imported and a comparison of the pie chart with an equivalent pie chart for population percentage, and finally a graph depicting the police killings per 100,000 for each demographic.","b3a4aab7":"Create a function to allow for all state symbols to be input:","b08ee278":"Import the data to police violence dataset:","d88d0902":"Combine all my data into single DataFrames to be used for the graphics:","25827f8b":"Sort the data based upon the state abbreviation for easy readability:","52b77b91":"The data although useful doesn't really convey much meaning, so I imported state population data to give some perspective on the numbers.\nTo simplify the project I utilized population data from: \"2017 1-year American Community Survey estimates, U.S. Census Bureau\"","6deb6980":"Those 5 states are used for comparison in the pie charts:","c0c4792f":"In some states the population for Native Americans is so low, that a single police killing can result in a very skewed per 100,000 individuals (e.g. in Vermont only 1 Native American was killed between 2015 and 2020, but the population of Native Americans in Vermont is less than 2,000 thus it results in a massive spike per 100,000 individuals). I removed Native Americans for the last graph just to give another perspective when comparing between Black individuals, White individuals and Hispanic individuals.","6eac1c5c":"Create a graphics comparing Police killings per 100,000 individuals for each population by state:","b57df4c6":"Index the dataset by states and rename the columns for ease of use:","42bceae3":"Now an attempt to compare across all states at once using each police killings per 100,000 in each population with a simple function:","1cc076a2":"Pull the total killings per state:","a6d04dea":"Test function on any Virginia:","456efc04":"Combine all the data into a single DataFrame to be manipulated in pandas and later used for numpy graphics. Some data is missing for certain demographics for each state so NaN values are replaced with 0:","d9f5a090":"Function for multiple pie charts is created for ease of comparison:","fd1c5f75":"Identify and pull out the hispanic data for police killings for each state:","6f5d668b":"Now that everything is in a single DataFrame to play with, identifying the states with the worst difference for black individuals is identified:"}}