{"cell_type":{"234a20f6":"code","9b0f7834":"code","3dbeeb9f":"code","7e38455d":"code","c680a804":"code","2f6c1fa1":"code","cdd8329d":"code","568289ca":"code","19a1cf9f":"code","8d8bf949":"code","b1081fc2":"code","bd4f7242":"code","0b7133fd":"code","15a42ba4":"code","8f57b900":"code","fc7d83c2":"code","c506b5b8":"code","f9ff4d14":"code","81367eed":"code","bbb79751":"code","47aa72f0":"code","c0c199d5":"code","5a346606":"code","8c4d0ecd":"code","14f15531":"code","e1754783":"code","52aa64b2":"code","da3bfb85":"code","bf1d29c3":"code","507d9aff":"code","ac97ce7f":"code","b4ee2b52":"code","7a077790":"code","1f7d59d7":"code","1eef04f4":"code","0549c49b":"code","fe6bbf39":"code","bea426a1":"code","0a59d99f":"code","0e2a4a5b":"code","132e8737":"code","a384f148":"code","b6f2856c":"code","4098dcce":"code","f5921155":"code","579aeaa7":"code","7a453fca":"code","8800217d":"code","294b59b2":"code","b10077ad":"code","b0aea6e9":"code","a150389d":"code","08ecedac":"code","8f8de153":"code","af21e0d5":"code","14ee41e5":"code","bc1a5a1f":"code","b6390b6c":"code","ea7f7351":"code","21f5e1de":"code","b446f73b":"code","ffeee4b2":"code","47efb7f4":"code","11c30932":"code","0152437d":"code","90615ca5":"code","0e2b8381":"code","96198862":"code","f2be33ee":"code","9f74c0a2":"code","c5f83b4f":"code","5705b8d0":"code","97fa6878":"code","cc900f0b":"code","d0c2e14c":"code","8a44156c":"code","175f6fe9":"code","c6e8eb1e":"code","ea194c3d":"code","26640764":"code","28ea7974":"code","3f6af77f":"code","cb0b0717":"markdown","73b219de":"markdown","9b8cd97d":"markdown","93bf7434":"markdown","6907d492":"markdown","b263513c":"markdown","09180e4a":"markdown","26a98820":"markdown","80c5724f":"markdown","0ae88eb4":"markdown","1e994118":"markdown","7c61d671":"markdown","69234e5d":"markdown","805c845c":"markdown","0312ce98":"markdown","cc0fe8f8":"markdown","f3207d4b":"markdown","54024eb1":"markdown","68f542bf":"markdown"},"source":{"234a20f6":"!pip install math\n!pip install mpl_toolkits\n!pip install info_gain\n!pip install sklearn\n!pip install info_gain","9b0f7834":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import StandardScaler # Used for scaling of data\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans, AffinityPropagation\nimport warnings\nfrom sklearn import preprocessing\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nfrom mpl_toolkits.mplot3d import Axes3D \nfrom info_gain import info_gain\nfrom sklearn.linear_model import LogisticRegression\n","3dbeeb9f":"train=pd.read_csv(\"..\/input\/german_credit_train.csv\")","7e38455d":"train.head()","c680a804":"train.info()","2f6c1fa1":"train.nunique()","cdd8329d":"ax = train['Risk'].value_counts().plot(kind='bar',\n                                    figsize=(14,8),\n                                    title=\"Risk Values\")\nax.set_xlabel(\"Risk Good or Bad\")\nax.set_ylabel(\"Frequency\")","568289ca":"count_no_sub = len(train[train['Risk']=='good'])\ncount_sub = len(train[train['Risk']=='bad'])\npct_of_no_sub = count_no_sub\/(count_no_sub+count_sub)\nprint(\"percentage of good is\", pct_of_no_sub*100)\npct_of_sub = count_sub\/(count_no_sub+count_sub)\nprint(\"percentage of bad\", pct_of_sub*100)","19a1cf9f":"def scatters(data, h=None, pal=None):\n    fig, (ax1, ax2, ax3) = plt.subplots(3,1, figsize=(8,8))\n    sns.scatterplot(x=\"Credit amount\",y=\"Duration\", hue=h, palette=pal, data=data, ax=ax1)\n    sns.scatterplot(x=\"Age\",y=\"Credit amount\", hue=h, palette=pal, data=data, ax=ax2)\n    sns.scatterplot(x=\"Age\",y=\"Duration\", hue=h, palette=pal, data=data, ax=ax3)\n    plt.tight_layout()","8d8bf949":"scatters(train, h=\"Sex\")","b1081fc2":"ax = train['Housing'].value_counts().plot(kind='bar',\n                                    figsize=(14,8),\n                                    title=\"Housing\")\nax.set_xlabel(\"Housing own or not\")\nax.set_ylabel(\"Frequency\")","bd4f7242":"def boxes(x,y,h,r=45):\n    fig, ax = plt.subplots(figsize=(10,6))\n    box = sns.boxplot(x=x,y=y, hue=h, data=train)\n    box.set_xticklabels(box.get_xticklabels(), rotation=r)\n    fig.subplots_adjust(bottom=0.2)\n    plt.tight_layout()\n    ","0b7133fd":"boxes(\"Purpose\",\"Credit amount\",\"Sex\")","15a42ba4":"boxes(\"Purpose\",\"Credit amount\",\"Job\")","8f57b900":"boxes(\"Purpose\",\"Duration\",\"Sex\")","fc7d83c2":"boxes(\"Job\",\"Duration\",\"Sex\")","c506b5b8":"fig = plt.figure(figsize=(10,6))\nax = fig.add_subplot(111, projection='3d')\nax.scatter(train[\"Credit amount\"], train[\"Duration\"], train[\"Job\"])\nax.set_xlabel(\"Credit amount\")\nax.set_ylabel(\"Duration\")\nax.set_zlabel(\"Job\")","f9ff4d14":"fig = plt.figure(figsize=(10,6))\nax = fig.add_subplot(111, projection='3d')\nax.scatter(train[\"Credit amount\"], train[\"Duration\"], train[\"Age\"])\nax.set_xlabel(\"Credit amount\")\nax.set_ylabel(\"Duration\")\nax.set_zlabel(\"Age\")","81367eed":"columns = [\"Age\",\"Credit amount\", \"Duration\"]\nclust_train = train.loc[:,columns]","bbb79751":"def distributions(data):\n    fig, (ax1, ax2, ax3) = plt.subplots(3,1, figsize=(12,12))\n    sns.distplot(data[\"Age\"], ax=ax1)\n    sns.distplot(data[\"Credit amount\"], ax=ax2)\n    sns.distplot(data[\"Duration\"], ax=ax3)\n    plt.tight_layout()","47aa72f0":"distributions(clust_train)","c0c199d5":"cluster_log = np.log(clust_train)\ndistributions(cluster_log)","5a346606":"cluster_log.head()","8c4d0ecd":"sns.heatmap(train.corr())\nplt.show()","14f15531":"train.drop([\"Unnamed: 0\"], axis = 1, inplace = True) \n  ","e1754783":"train = train.fillna(0)","52aa64b2":"train.head()","da3bfb85":"\ncategories = ['Age','Sex','Job','Housing','Saving accounts','Checking account','Credit amount','Duration','Purpose',]\n\n\nX, Y = train[categories], train.Risk\n#from info_gain import info_gain","bf1d29c3":"#ig  = info_gain.info_gain(X, Y)\n#iv  = info_gain.intrinsic_value(fruit, colour)\n#igr = info_gain.info_gain_ratio(fruit, colour)\n","507d9aff":"ig  = info_gain.info_gain(X['Age'], Y)\nig","ac97ce7f":"ig  = info_gain.info_gain(X['Sex'], Y)\nig","b4ee2b52":"ig  = info_gain.info_gain(X['Job'], Y)\nig","7a077790":"ig  = info_gain.info_gain(X['Housing'], Y)\nig","1f7d59d7":"ig  = info_gain.info_gain(X['Saving accounts'], Y)\nig","1eef04f4":"ig  = info_gain.info_gain(X['Checking account'], Y)\nig","0549c49b":"ig  = info_gain.info_gain(X['Credit amount'], Y)\nig","fe6bbf39":"ig  = info_gain.info_gain(X['Duration'], Y)\nig","bea426a1":"ig  = info_gain.info_gain(X['Purpose'], Y)\nig","0a59d99f":"train['Job'].value_counts()","0e2a4a5b":"train['Housing'].value_counts()","132e8737":"train['Saving accounts'].value_counts()","a384f148":"train['Checking account'].value_counts()","b6f2856c":"train['Purpose'].value_counts()","4098dcce":"tmp=train","f5921155":"matplotlib.pyplot.boxplot(tmp['Credit amount'])","579aeaa7":"matplotlib.pyplot.boxplot(tmp['Duration'])","7a453fca":"matplotlib.pyplot.boxplot(tmp['Age'])","8800217d":"train['Credit amount']=cluster_log['Credit amount']","294b59b2":"train['Duration']=cluster_log['Duration']","b10077ad":"train['Age']=cluster_log['Age']","b0aea6e9":"train1=train","a150389d":"matplotlib.pyplot.boxplot(train['Credit amount'])","08ecedac":"matplotlib.pyplot.boxplot(cluster_log['Duration'])","8f8de153":"matplotlib.pyplot.boxplot(cluster_log['Age'])","af21e0d5":"#import numpy as np\n#import pandas as pd\n\"\"\"outliers=[]\ndef detect_outlier(data_1):\n    \n    threshold=1.1\n    mean_1 = np.mean(data_1)\n    std_1 =np.std(data_1)\n    for y in data_1:\n        z_score= (y - mean_1)\/std_1 \n        if np.abs(z_score) > threshold:\n            outliers.append(y)\n    return outliers\noutliers=detect_outlier(train1['Credit amount'])\noutliers\nminval=min(outliers)\nmedian = train1['Credit amount'].median()\nmedian\ntrain1.loc[train1['Credit amount'] >=minval, 'Credit amount'] = median\n\n\"\"\"","14ee41e5":"train['Saving accounts'] = le.fit_transform(train['Saving accounts'].astype(str))\ntrain['Checking account'] = le.fit_transform(train['Checking account'].astype(str))\ntrain['Sex'] = le.fit_transform(train['Sex'].astype(str))\ntrain['Housing'] = le.fit_transform(train['Housing'].astype(str))\ntrain['Purpose'] = le.fit_transform(train['Purpose'].astype(str))","bc1a5a1f":"train['Risk'] = le.fit_transform(train['Risk'].astype(str))","b6390b6c":"train.head()","ea7f7351":"clms = ['Age','Sex','Job','Housing','Saving accounts','Checking account','Credit amount','Duration','Purpose',]\n","21f5e1de":"\nfrom sklearn import metrics\nX_train, X_test, y_train, y_test = train_test_split(train[clms], train['Risk'], test_size=0.3, random_state=0)\n","b446f73b":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)","ffeee4b2":"y_pred = logreg.predict(X_test)\nprint('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))","47efb7f4":"from sklearn.metrics import confusion_matrix\nconfusion_matrix = confusion_matrix(y_test, y_pred)\nprint(confusion_matrix)","11c30932":"scaler = StandardScaler()  \nscaler.fit(X_train)\n\nX_train = scaler.transform(X_train)  \nX_test = scaler.transform(X_test)  ","0152437d":"from sklearn.neighbors import KNeighborsClassifier  \nclassifier = KNeighborsClassifier(n_neighbors=2)  \nclassifier.fit(X_train, y_train) ","90615ca5":"y_pred = classifier.predict(X_test)  ","0e2b8381":"y_pred = classifier.predict(X_test)\nprint('Accuracy of Knn classifier on test set: {:.2f}'.format(classifier.score(X_test, y_test)))","96198862":"from sklearn.ensemble import RandomForestClassifier\nclf=RandomForestClassifier(n_estimators=200)\n\n","f2be33ee":"#Train the model using the training sets y_pred=clf.predict(X_test)\nclf.fit(X_train,y_train)\n\ny_pred=clf.predict(X_test)","9f74c0a2":"from sklearn import metrics\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","c5f83b4f":"#importance based selection\nclms = ['Age','Saving accounts','Checking account','Credit amount','Duration']","5705b8d0":"from sklearn import metrics\nX_train, X_test, y_train, y_test = train_test_split(train[clms], train['Risk'], test_size=0.3, random_state=0)\n","97fa6878":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)","cc900f0b":"y_pred = logreg.predict(X_test)\nprint('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))","d0c2e14c":"from sklearn.metrics import confusion_matrix\nconfusion_matrix = confusion_matrix(y_test, y_pred)\nprint(confusion_matrix)","8a44156c":"scaler = StandardScaler()  \nscaler.fit(X_train)\n\nX_train = scaler.transform(X_train)  \nX_test = scaler.transform(X_test)  ","175f6fe9":"from sklearn.neighbors import KNeighborsClassifier  \nclassifier = KNeighborsClassifier(n_neighbors=2)  \nclassifier.fit(X_train, y_train) ","c6e8eb1e":"y_pred = classifier.predict(X_test)\nprint('Accuracy of Knn classifier on test set: {:.2f}'.format(classifier.score(X_test, y_test)))","ea194c3d":"from sklearn.ensemble import RandomForestClassifier\nclf=RandomForestClassifier(n_estimators=100)\n\n","26640764":"#Train the model using the training sets y_pred=clf.predict(X_test)\nclf.fit(X_train,y_train)\n\ny_pred=clf.predict(X_test)","28ea7974":"#Train the model using the training sets y_pred=clf.predict(X_test)\nclf.fit(X_train,y_train)\n\ny_pred=clf.predict(X_test)","3f6af77f":"from sklearn import metrics\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","cb0b0717":"**Top 5 Rows**<br>\nusing head function can view top 5 rows","73b219de":"**Gender based Job and Duration boxplot** ","9b8cd97d":"**Target Percentages:**\ncalculating good and bad percentage value\n","93bf7434":"**Unique Values Count by Each Column**<br>\nusing unique command can see the count of unique values in each column","6907d492":"# **Machine Learning**: <br>\n   Machine learning is an application of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. Machine learning focuses on the development of computer programs that can access data and use it learn for themselves.\n <br> <br>\n\nThree Types of Learning: <br>\n    1 Supervised Learning <br>\n    2 Unsupervised Learning <br>\n    3 Reinforcement Learning\n  <br> <br>\n Supervised Learning: <br>\n     Supervised learning as the name indicates the presence of a supervisor as a teacher. Basically supervised learning is a learning in which we teach or train the machine using data which is well labeled that means some data is already tagged with the correct answer. After that, the machine is provided with a new set of examples(data) so that supervised learning algorithm analyses the training data(set of training examples) and produces a correct outcome from labeled data. <br>\n     \n For instance:  <br>  suppose you are given an basket filled with different kinds of fruits. Now the first step is to train the machine with all different fruits one by one like this:<br>\n .![alt text](https:\/\/media.geeksforgeeks.org\/wp-content\/uploads\/fruits-basket.jpg)\n \n \n If shape of object is rounded and depression at top having color Red then it will be labelled as \u2013Apple.<br>\nIf shape of object is long curving cylinder having color Green-Yellow then it will be labelled as \u2013Banana<br>\n\n\nClassification: <br>A classification problem is when the output variable is a category, such as \u201cRed\u201d or \u201cblue\u201d or \u201cdisease\u201d and \u201cno disease\u201d.<br>\n\nRegression: <br>A regression problem is when the output variable is a real value, such as \u201cdollars\u201d or \u201cweight\u201d.<br>\n\nUnsupervised learning:<br>\n     Unsupervised learning is the training of machine using information that is neither classified nor labeled and allowing the algorithm to act on that information without guidance. Here the task of machine is to group unsorted information according to similarities, patterns and differences without any prior training of data.<br>\n\nUnlike supervised learning, no teacher is provided that means no training will be given to the machine. Therefore machine is restricted to find the hidden structure in unlabeled data by our-self.\n<br>\nFor instance:<br>\n suppose it is given an image having both dogs and cats which have not seen ever.![alt text](https:\/\/media.geeksforgeeks.org\/wp-content\/uploads\/cat-and-dogs.jpg)\n \n Clustering: <br>A clustering problem is where you want to discover the inherent groupings in the data, such as grouping customers by purchasing behavior.<br>\n \nAssociation: <br>An association rule learning problem is where you want to discover rules that describe large portions of your data, such as people that buy X also tend to buy Y.<br>\n\nReinforcement learning: <br>Reinforcement. It is about taking suitable action to maximize reward in a particular situation. It is employed by various software and machines to find the best possible behavior or path it should take in a specific situation. Reinforcement learning differs from the supervised learning in a way that in supervised learning the training data has the answer key with it so the model is trained with the correct answer itself whereas in reinforcement learning, there is no answer but the reinforcement agent decides what to do to perform the given task. In the absence of training dataset, it is bound to learn from its experience.<br>\n\nExample : <br>The problem is as follows: We have an agent and a reward, with many hurdles in between. The agent is supposed to find the best possible path to reach the reward. The following problem explains the problem more easily.\n![alt text](https:\/\/cdncontribute.geeksforgeeks.org\/wp-content\/uploads\/Untitled-95.png)\n\nThe above image shows robot, diamond and fire. The goal of the robot is to get the reward that is the diamond and avoid the hurdles that is fire. The robot learns by trying all the possible paths and then choosing the path which gives him the reward with the least hurdles. Each right step will give the robot a reward and each wrong step will subtract the reward of the robot. The total reward will be calculated when it reaches the final reward that is the diamond.<br>\n\nMain points in Reinforcement learning \u2013<br>\n\n<br>Input: The input should be an initial state from which the model will start<br>\nOutput: There are many possible output as there are variety of solution to a particular problem<br>\nTraining: The training is based upon the input, The model will return a state and the user will decide to reward or punish the model based on its output.<br>\nThe model keeps continues to learn.<br>\nThe best solution is decided based on the maximum reward.<br>\n","b263513c":"**3D plot for Credit amount,Duration and Job**","09180e4a":"# **Bank Customer Segmentation**\nIn this kernel I will perform segmentation of German bank customers. The first step is to read necessary libraries. We will use:\n\npandas - to manipulate data frames<br>\nnumpy - providing linear algebra<br>\nseaborm - to create nice visualizations<br>\nmatplotlib - basic tools for visualizations<br>\nscikit-learn - machine learning library<br>\nmpl_toolkits - tool for 3d visualization<br>\ninfo_gain - tool for important feature finding<br>","26a98820":"**Housing frequency Based Bar Plot**","80c5724f":"**Job based Purpose and Duration boxplot**","0ae88eb4":"**Reading data:**\ndata in format of csv file comma seperated value","1e994118":"**Gender based Purpose and Credit amount boxplot**","7c61d671":"**3D plot for Credit amount,Duration and Age**","69234e5d":"**Data information**<br>\nusing info command can View data informations ","805c845c":"# **Visualization**","0312ce98":"**Function for boxplot**","cc0fe8f8":"**Gender based credit amount and duration Scatterplot**","f3207d4b":"**Visualizing Target Column**<br>\nTarget column is having two types of output's good and bad. visualizing data using frequency","54024eb1":"# **Context**<br>\nThe original dataset contains 1000 entries with 20 categorial\/symbolic attributes prepared by Prof. Hofmann. In this dataset, each entry represents a person who takes a credit by a bank. Each person is classified as good or bad credit risks according to the set of attributes. The link to the original dataset can be found below.<br>\n\n**Content**<br>\nIt is almost impossible to understand the original dataset due to its complicated system of categories and symbols. Thus, I wrote a small Python script to convert it into a readable CSV file. Several columns are simply ignored, because in my opinion either they are not important or their descriptions are obscure. The selected attributes are:<br>\n\n<br><br>\nAge (numeric)<br>\nSex (text: male, female)<br>\nJob (numeric: 0 - unskilled and non-resident, 1 - unskilled and <br>resident, 2 - skilled, 3 - highly skilled)<br>\nHousing (text: own, rent, or free)<br>\nSaving accounts (text - little, moderate, quite rich, rich)<br>\nChecking account (numeric, in DM - Deutsch Mark)<br>\nCredit amount (numeric, in DM)<br>\nDuration (numeric, in month)<br>\nPurpose (text: car, furniture\/equipment, radio\/TV, domestic <br>appliances, repairs, education, business, vacation\/others)<br>\n<br>\nhttps:\/\/archive.ics.uci.edu\/ml\/datasets\/Statlog+%28German+Credit+Data%29","68f542bf":"**Job based Purpose and Credit amount boxplot**"}}