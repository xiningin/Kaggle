{"cell_type":{"a4310dfa":"code","65521011":"code","acb31327":"code","ecf0ac22":"code","d1fabc29":"code","faeaa001":"code","4405970e":"code","8de220f0":"code","33c22fb8":"code","41d7e69a":"code","f39284f5":"code","5170d4fc":"code","c69fbbdc":"code","ec220de7":"code","94cb2ced":"code","4c980f82":"code","d1ae664c":"code","a142949e":"code","192cb38f":"code","2013f253":"code","48e923f3":"code","c2db7cf2":"code","6cb08f5a":"code","e5d04567":"code","cc79b120":"code","f51c18dc":"code","f625b168":"code","58543398":"code","96be5966":"code","f358bab7":"code","23bb8073":"code","24ec7738":"code","22f8fa6a":"code","479b877a":"code","af118e8d":"code","c369934e":"code","d3792d4e":"code","ed79c03f":"code","a7fd0c34":"code","8758f719":"code","cbdb53bd":"code","e668c21f":"code","7bd14070":"code","35f20ab6":"markdown","370af92d":"markdown","b7d07edf":"markdown"},"source":{"a4310dfa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nimport gc\n\nplt.rcParams[\"figure.figsize\"] = (10,6)\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","65521011":"test = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv')\ntest.info()","acb31327":"test.head()","ecf0ac22":"sales = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\nsales.info()","d1fabc29":"sales.head()","faeaa001":"sales = sales.rename(columns={'date_block_num':'month_num'})\nsales['date'] = pd.to_datetime(sales['date'], dayfirst=True)\nsales['month'] = sales['date'].dt.month\n","4405970e":"time_dim = ['date', 'month', 'month_num']","8de220f0":"label= 'item_cnt_day'\ny_label= 'item_cnt_month'","33c22fb8":"sales.describe()","41d7e69a":"sns.distplot(sales[label], hist=False)","f39284f5":"min_thresh, max_thresh = np.percentile(sales[label], [0.5,99.9995])\nsales= sales[sales[label].between(min_thresh, max_thresh)]\nprint (min_thresh, max_thresh)","5170d4fc":"sns.distplot(sales['item_price'], hist=False)","c69fbbdc":"min_thresh, max_thresh = np.percentile(sales['item_price'], [0.5,99.5])\nsales= sales[sales['item_price'].between(min_thresh, max_thresh)]\nprint (min_thresh, max_thresh)","ec220de7":"nunique = [len(sales[i].unique()) for i in sales.columns]\nsns.barplot(sales.columns, nunique)\nnunique","94cb2ced":"pd.pivot_table( sales, 'month_num', 'shop_id', aggfunc='max').plot()","4c980f82":"sales.groupby('date')[label].sum().plot(title=\"sales by date\")","d1ae664c":"tmp=sales.groupby('shop_id')[label].count()\ntmp.plot(kind='bar', title=\"sales by shop\")\ntop = tmp.sort_values().tail().index.tolist()\nworst = tmp.sort_values().head().index.tolist()\ntop","a142949e":"tmp=sales.groupby('shop_id')['date'].nunique()\ntmp.plot(kind='bar', title=\"unique dates by shop\")\ntop = tmp.sort_values().tail().index.tolist()\nworst = tmp.sort_values().head().index.tolist()\ntop","192cb38f":"set(test['shop_id'].unique()).issubset(sales['shop_id'].unique())\n","2013f253":"set(test['item_id'].unique()).issubset(sales['item_id'].unique())\n","48e923f3":"tmp=sales[sales['shop_id'].isin(test['shop_id'].unique())] .groupby('shop_id')['date'].nunique()\ntmp.plot(kind='bar', title=\"unique dates by shop from test set\")","c2db7cf2":"sales = pd.pivot_table(sales, label, [ 'month_num', 'shop_id', 'item_id', 'item_price', 'month'], aggfunc=['mean', 'sum']).reset_index()\nsales.columns = sales.columns.droplevel(1)\nsales.head()","6cb08f5a":"g= sns.barplot('month', 'mean', data=sales, palette='tab20', n_boot=100)\ng.set(title=\"Average sales by Month (date & store)\")","e5d04567":"g= sns.barplot('month', 'sum', data=sales, palette='tab20', n_boot=100)\ng.set(title=\"Average sales by Month (date & store)\")","cc79b120":"tmp=sales.groupby('month')['shop_id'].nunique()\ntmp.plot(kind='bar', title=\"unique shops by month\")","f51c18dc":"tmp=sales.groupby('month_num')['shop_id'].nunique()\ntmp.plot(kind='bar', title=\"unique shops by month num\")","f625b168":"label = 'sum'","58543398":"tmp = sales[sales['shop_id'].isin(top)].copy()\ntmp = pd.pivot_table(tmp, label, ['month_num', 'shop_id'], aggfunc='sum').reset_index()\n\ng= sns.FacetGrid(tmp, row='shop_id', aspect = 6)\ng.map(plt.plot, 'month_num', label)\n# sales.groupby('date')[label].sum().plot(title=\"sales by date\")","96be5966":"tmp = sales[sales['shop_id'].isin(worst)].copy()\ntmp = pd.pivot_table(tmp, label, ['month_num', 'shop_id'], aggfunc='sum').reset_index()\n\ng= sns.FacetGrid(tmp, row='shop_id', aspect = 3)\ng.map(plt.plot, 'month_num', label)\n# sales.groupby('date')[label].sum().plot(title=\"sales by date\")","f358bab7":"tmp = test[['ID', 'shop_id', 'item_id']] .copy()\ntmp = tmp.loc[tmp.index.repeat(34)]\ntmp ['month_num'] = [np.mod(i, 34) for i in range(7282800)]\nmerge = pd.merge(tmp, sales, 'left', ['shop_id', 'item_id', 'month_num'], suffixes=('_y', ''))\nmerge ['sum'] = merge ['sum'].fillna(0)\nmerge ['mean'] = merge ['mean'].fillna(0)\nmerge\n","23bb8073":"print ([merge[i].count() for i in merge .columns])","24ec7738":"tmp= pd.pivot_table(merge.dropna(), 'month_num', ['shop_id', 'item_id'], aggfunc=[max, min]).reset_index()\ntmp.columns = tmp.columns.droplevel(1)\ntmp['status'] = tmp.apply(lambda x: True if (x['max'] >30) & (x['max'] - x['min']>13) else False,1)","22f8fa6a":"merge = pd.merge(merge, tmp[['shop_id', 'item_id', 'status']], 'left', ['shop_id', 'item_id'])\nmerge.info()","479b877a":"shop=59\nitem=5037\ntmp= merge[(merge['shop_id']==shop) & (merge['item_id']==item)].copy()\nsns.lineplot('month_num' , 'sum', data=tmp)","af118e8d":"tmp = pd.pivot_table (sales, 'item_price', ['shop_id', 'item_id'] ).reset_index()\n# tmp.columns = tmp.columns.droplevel(1)\n# tmp.columns = ['shop_id', 'item_id', 'mean_price']\nmerge = pd.merge(merge[['ID', 'shop_id', 'item_id', 'month_num', 'month','mean','sum', 'status']] , tmp, 'left', ['shop_id', 'item_id'])\nmerge.head()","c369934e":"merge['month'] = np.mod(merge['month_num']+1, 12)\nmerge['status'] = merge['status'].fillna(False)\nmerge['item_price'] = merge['item_price'].fillna(0)","d3792d4e":"X = merge[['shop_id', 'item_id', 'month_num', 'month', 'status', 'item_price']].values\ny = merge['mean'].values\n\n","ed79c03f":"X_test= test.copy()\nX_test = pd.merge(X_test, merge[['shop_id', 'item_id', 'status', 'item_price']], 'left', ['shop_id', 'item_id'])\nX_test.drop_duplicates(inplace=True)\nX_test['month_num']= 34\nX_test['month']= 11\nX_test","a7fd0c34":"X_test_data = X_test[['shop_id', 'item_id', 'month_num', 'month', 'status', 'item_price']] .values","8758f719":"from sklearn.ensemble import RandomForestRegressor\n\nreg = RandomForestRegressor(random_state=1, n_estimators=50)\nreg.fit(X, y)\n","cbdb53bd":"X_test [y_label] = reg.predict(X_test_data)","e668c21f":"tmp = X_test[['ID', y_label]].copy()\nprint (len(tmp))\ntmp.to_csv('sub3_rf', index=False)","7bd14070":"[['shop_id', 'item_id', 'month_num', 'month', 'status', 'item_price']]\nreg.feature_importances_","35f20ab6":"\ntest[y_label] = sales[label].median()\ntmp = test[['ID', y_label]].copy()\nprint (len(tmp))\ntmp.to_csv('sub0_median', index=False)","370af92d":"**1 - Loading Data**","b7d07edf":"**2 - EDA**"}}