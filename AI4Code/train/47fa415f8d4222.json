{"cell_type":{"6604c58d":"code","a07d7307":"code","b29cc2c8":"code","bc664c8c":"code","7ae28e1c":"code","c2b3bde9":"code","66eb348c":"code","320db5e5":"code","43881c24":"code","389a836d":"code","0bb7932b":"code","707d9fbb":"code","15da976e":"code","04bbdcbb":"code","008b4854":"code","6b1259b8":"code","fe55d9b0":"code","ac33c9c6":"code","69f93945":"code","ee352b06":"code","27d39164":"code","c8ab4e6e":"code","24deebdd":"code","5346444f":"code","41d63a10":"code","9012b51c":"code","4f3a93cf":"code","e84f325a":"code","570f8e62":"code","55af6c74":"code","2836529b":"code","98167a9d":"code","dead625d":"code","2fa9e907":"code","7162a8c7":"code","5aadb894":"code","03e1da88":"code","2aedbd0f":"code","18fe9eb0":"code","2cbda610":"code","bb4bce62":"code","b6971f0b":"code","d23f0758":"code","8dfef7c7":"code","564af393":"code","5c320891":"code","a59b74e2":"code","08e9887a":"code","264d3c14":"code","46de3180":"code","8b157d33":"code","0f342cd7":"code","30be488a":"code","1e1dbb6a":"code","b17f474e":"code","ea2ca759":"code","877d1773":"markdown","df62cc97":"markdown","1b170438":"markdown","7973faa0":"markdown","3b28e9af":"markdown","abbb076d":"markdown","c9315ecd":"markdown","b33ca932":"markdown","5973282f":"markdown","f787ba2a":"markdown","2f562365":"markdown","15bfd1ad":"markdown","fe80246a":"markdown","919a59c0":"markdown","f1582c25":"markdown","7e79b72c":"markdown","1c818e38":"markdown","fb8b7095":"markdown","068525c7":"markdown","9fec82a4":"markdown","946e2e9c":"markdown","ccdabf3d":"markdown","c1e926e0":"markdown","f7e080ec":"markdown","10a6aac9":"markdown","a1282295":"markdown","a39a4c47":"markdown","e902a7c9":"markdown","1a92f63f":"markdown","fc163483":"markdown","11cc55f1":"markdown","caf7eb06":"markdown","2281f6a7":"markdown","27b89cc9":"markdown","dada2a5c":"markdown","a14d8a9b":"markdown","83a4c027":"markdown","c1989c00":"markdown","6d6e1b90":"markdown","5b4ff3bc":"markdown","4d2c6da5":"markdown","6f0a5b31":"markdown","582a30c9":"markdown","108e92ce":"markdown","beb4c35a":"markdown","661c638b":"markdown","b537dd91":"markdown","c3e56e39":"markdown","7345bb81":"markdown","9b4244c9":"markdown","a578a044":"markdown"},"source":{"6604c58d":" pip install tweepy","a07d7307":"import pandas as pd\nimport numpy as np\nimport requests\nimport os\nimport tweepy\nimport json\nimport matplotlib.pyplot as plt\nimport re","b29cc2c8":"# Open the csv file\ndf = pd.read_csv('\/kaggle\/input\/data-wrangling\/wrangle\/twitter-archive-enhanced-2.csv')\ndf.head()","bc664c8c":"# Download tweet image predictions TSV using the Requests library and write it to image_predictions.tsv\nurl = 'https:\/\/d17h27t6h515a5.cloudfront.net\/topher\/2017\/August\/599fd2ad_image-predictions\/image-predictions.tsv'\nresponse = requests.get(url)\nwith open('image_predictions.tsv', mode='wb') as file:\n    file.write(response.content)\n    \n# Import the tweet image predictions TSV file into a DataFrame\nimages_df = pd.read_csv('..\/input\/data-wrangling\/wrangle\/image-predictions-3.tsv', sep = '\\t')\nresponse\n","7ae28e1c":"images_df.head()","c2b3bde9":"import tweepy\nfrom tweepy import OAuthHandler\nimport json\nfrom timeit import default_timer as timer\n\n# Query Twitter API for each tweet in the Twitter archive and save JSON in a text file\n# These are hidden to comply with Twitter's API terms and conditions\nconsumer_key = 'HIDDEN'\nconsumer_secret = 'HIDDEN'\naccess_token = 'HIDDEN'\naccess_secret = 'HIDDEN'\n\nauth = OAuthHandler(consumer_key, consumer_secret)\nauth.set_access_token(access_token, access_secret)\n\napi = tweepy.API(auth, wait_on_rate_limit=True)\n\n# NOTE TO STUDENT WITH MOBILE VERIFICATION ISSUES:\n# df_1 is a DataFrame with the twitter_archive_enhanced.csv file. You may have to\n# change line 17 to match the name of your DataFrame with twitter_archive_enhanced.csv\n# NOTE TO REVIEWER: this student had mobile verification issues so the following\n# Twitter API code was sent to this student from a Udacity instructor\n# Tweet IDs for which to gather additional data via Twitter's API\ntweet_ids = df.tweet_id.values\nlen(tweet_ids)\n\n# Query Twitter's API for JSON data for each tweet ID in the Twitter archive\ncount = 0\nfails_dict = {}\nstart = timer()\n# Save each tweet's returned JSON as a new line in a .txt file\nwith open('tweet_json.txt', 'w') as outfile:\n    # This loop will likely take 20-30 minutes to run because of Twitter's rate limit\n    for tweet_id in tweet_ids:\n        count += 1\n        print(str(count) + \": \" + str(tweet_id))\n        try:\n            tweet = api.get_status(tweet_id, tweet_mode='extended')\n#             print(\"Success\")\n            json.dump(tweet._json, outfile)\n            outfile.write('\\n')\n        except tweepy.TweepError as e:\n#             print(\"Fail\")\n            fails_dict[tweet_id] = e\n            pass\nend = timer()\nprint(end - start)\nprint(fails_dict)","66eb348c":"# my API keys\nconsumer_key = 'consumer_key'\nconsumer_secret = 'consumer_secret'\naccess_token = 'access_token'\naccess_secret = 'access_secret'","320db5e5":"\n#Tweepy Query\nauth = tweepy.OAuthHandler(consumer_key, consumer_secret)\nauth.set_access_token(access_token, access_secret)\napi = tweepy.API(auth, wait_on_rate_limit=True,\n                  wait_on_rate_limit_notify=True)","43881c24":"with open('..\/input\/data-wrangling\/wrangle\/tweet_json') as json_f:\n    tweets_df = pd.DataFrame(columns = ['tweet_id','favorites','retweets'])\n    \n    for info in json_f:\n        tweets = json.loads(info)\n        data = {'tweet_id': tweets['id'],'favorites': tweets['favorite_count'],\n                                      'retweets': tweets['retweet_count']}\n        ser = pd.Series(data)\n        tweets_df = tweets_df.append(data,ignore_index=True)\ntweets_df.head()","389a836d":"df.head()","0bb7932b":"df.info()","707d9fbb":"df.describe()\n","15da976e":"df.tweet_id.duplicated().sum()\n","04bbdcbb":"sum(df.rating_numerator.isnull())\n","008b4854":"sum(df.rating_denominator.isnull())\n","6b1259b8":"images_df.info()","fe55d9b0":"images_df.describe()","ac33c9c6":"tweets_df.info()","69f93945":"tweets_df.describe()","ee352b06":"\ntweets_df['tweet_id'] = tweets_df['tweet_id'].apply(pd.to_numeric, errors='coerce')\ntweets_df['favorites'] = tweets_df['favorites'].apply(pd.to_numeric, errors='coerce')\ntweets_df['retweets'] = tweets_df['retweets'].apply(pd.to_numeric, errors='coerce')","27d39164":"# Make a copy of the tables before cleaning\ndf_clean = df.copy()\nimages_df_clean = images_df.copy()\ntweets_df_clean = tweets_df.copy()","c8ab4e6e":"from functools import reduce\ndf_clean = [df_clean, images_df_clean, tweets_df_clean]\ntwitter_dogs = reduce(lambda left, right:  pd.merge(left, right, on = 'tweet_id'), df_clean)","24deebdd":"twitter_dogs.head()","5346444f":"twitter_dogs['name'].value_counts()","41d63a10":"twitter_dogs.info()\n","9012b51c":"twitter_dogs['dog_type'] = twitter_dogs['text'].str.extract('(doggo|floofer|pupper|puppo)')\n","4f3a93cf":"twitter_dogs.head()\n","e84f325a":"twitter_dogs = twitter_dogs[np.isnan(twitter_dogs.retweeted_status_id)]","570f8e62":"twitter_dogs.info()\n","55af6c74":"ratings = df.text.str.extract('((?:\\d+\\.)?\\d+)\\\/(\\d+)', expand=True)","2836529b":"twitter_dogs.rating_numerator = ratings","98167a9d":"twitter_dogs.info()","dead625d":"twitter_dogs.drop(['source','img_num','in_reply_to_status_id', 'in_reply_to_user_id',], axis=1, inplace=True)\n","2fa9e907":"twitter_dogs.head()","7162a8c7":"twitter_dogs.info()\n","5aadb894":"twitter_dogs['tweet_id'] = twitter_dogs['tweet_id'].astype(str)\n","03e1da88":"twitter_dogs.info()","2aedbd0f":"twitter_dogs['timestamp'] = twitter_dogs['timestamp'].str.slice(start=0, stop=-6)\ntwitter_dogs['timestamp'] = pd.to_datetime(twitter_dogs['timestamp'], format = \"%Y-%m-%d %H:%M:%S\")","18fe9eb0":"twitter_dogs.info()","2cbda610":"twitter_dogs['name'][twitter_dogs['name'].str.match('[a-z]+')] = 'None'","bb4bce62":"twitter_dogs.name[twitter_dogs.name == 'None'].value_counts()","b6971f0b":"twitter_dogs.name.value_counts().sort_index(ascending=False)","d23f0758":"twitter_dogs = twitter_dogs[twitter_dogs.retweeted_status_id.isnull()]","8dfef7c7":"len(twitter_dogs[twitter_dogs.retweeted_status_id.isnull() == False])","564af393":"twitter_dogs.drop(['retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp'], axis=1, inplace=True)\n","5c320891":"twitter_dogs.info()","a59b74e2":"twitter_dogs.to_csv('twitter_archive_master.csv', encoding='utf-8', index=False)\n","08e9887a":"import datetime\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nplt.rcParams[\"figure.figsize\"] = [12, 9]","264d3c14":"twitter_dogs.timestamp = pd.to_datetime(twitter_dogs['timestamp'], format='%Y-%m-%d %H:%M:%S.%f')\n\nmonthly_tweets = twitter_dogs.groupby(pd.Grouper(key = 'timestamp', freq = \"M\")).count().reset_index()\nmonthly_tweets = monthly_tweets[['timestamp', 'tweet_id']]","46de3180":"plt.figure(figsize=(10, 8))\nplt.xlim([datetime.date(2015, 11, 30), datetime.date(2017, 7, 30)]) \n\nplt.xlabel('Year and Month')\nplt.ylabel('Tweets Count')\n\nplt.plot(monthly_tweets.timestamp, monthly_tweets.tweet_id)\nplt.title('WeRateDogs Tweets over Time');","8b157d33":"sns.boxplot(x=\"dog_type\", y=\"favorites\", data=twitter_dogs).set_title('Dog categories with total of favorites');\n","0f342cd7":"ax = twitter_dogs.rating_numerator.sort_index().value_counts().plot(kind='bar', title = 'Dog Rating distribution')\nax.set_xlabel(\"Rating out of 10\")\nax.set_ylabel(\"Number of Dogs\")\nplt.savefig('rating_dist')","30be488a":"{i:j for i,j in  twitter_dogs.iterrows()}[0]\n# twitter_dogs['rating_numerator'].astype(float)","1e1dbb6a":"twitter_dogs['dog_breed'] = ['None' for i in range(len(twitter_dogs))]\n# twitter_dogs['rating_numerator'] = twitter_dogs['rating_numerator'].astype(float)\n\nfor i, row in twitter_dogs.iterrows():\n\n    if row.p1_dog:\n        twitter_dogs.loc[i,'dog_breed'] = row.p1\n    elif row.p2_dog and float(row.rating_numerator) >= 10:\n        twitter_dogs.loc[i,'dog_breed'] = row.p2\n    elif row.p3_dog and float(row.rating_numerator) >= 10:\n        twitter_dogs.loc[i,'dog_breed'] = row.p3\n    else:\n        twitter_dogs.loc[i,'dog_breed'] = 'None'\n        \n        \ndog_breed = twitter_dogs.groupby('dog_breed').filter(lambda x: len(x) >= 25)\n\ndog_breed['dog_breed'].value_counts().plot(kind = 'barh')\nplt.title('Most Rated Dog Breed')\nplt.xlabel('Count')\nplt.ylabel('Breed of dog');","b17f474e":"\ntwitter_dogs.name.value_counts()[0:10].plot(kind='barh', figsize=(15,8), title='Most Common Dog Names').set_xlabel(\"Number of Dogs\");\n\n","ea2ca759":"# sns.barplot(y=\"name\", x=\"retweets\", data = twitter_dogs.iloc[0:30]).set_title('top 30 dog names with highest retweets rate');\n# sns.catplot(y=\"name\", x=\"retweets\", kind=\"box\", data = twitter_dogs.iloc[0:30])","877d1773":"### (5)astype","df62cc97":"### code","1b170438":"### code","7973faa0":"### (4)","3b28e9af":"## define\n### (9)Keep only original tweets.","abbb076d":"### test","c9315ecd":"### code","b33ca932":"## Define\n### (2)Create one column for the various dog types: doggo, floofer, pupper, puppo ","5973282f":"# Cleaning Data","f787ba2a":"### test","2f562365":"# Visualizing Data","15bfd1ad":"# Twitter Counts Dataframe Analysis\n\n","fe80246a":"### (1)","919a59c0":"### Storing Data","f1582c25":"# sources \n## https:\/\/stackabuse.com\/reading-and-writing-json-to-a-file-in-python\/\n## https:\/\/stackoverflow.com\/questions\/7370801\/how-to-measure-elapsed-time-in-python?answertab=oldest#tab-top\n## https:\/\/docs.python.org\/3\/library\/datetime.html\n## https:\/\/github.com\/Abhishek20182\/Wrangle-and-Analyze-Data","7e79b72c":"### test ","1c818e38":"### test","fb8b7095":"### test","068525c7":"### (3)","9fec82a4":"### test","946e2e9c":"## Define\n### (6)Change tweet_id from an integer to a string","ccdabf3d":"## define \n### (4)Ratings with decimal values incorrectly extracted","c1e926e0":"### df Dataframe Analysis","f7e080ec":"### test","10a6aac9":"### test","a1282295":"## Define\n### (7)Change the timestamp to correct datetime format\n","a39a4c47":"# define\n### (10)delete the empty retweet-related columns","e902a7c9":"### Image predictions for dogs(tsv file), we will download it programatically as a url by using request library.","1a92f63f":"### test","fc163483":"### code","11cc55f1":"# Define\n\n\n### (1)Merge the clean versions of df, images, and tweets_df dataframes Correct the dog types (Quality)\n### (2)Create one column for the various dog types: doggo, floofer, pupper, puppo             (Tidiness) \n### (3)Delete retweets                                                                        (Quality)\n### (4)Remove columns no longer needed columns                                                (Quality)\n### (5)Ratings with decimal values incorrectly extracted                                      (Quality)\n### (6)Change tweet_id from an integer to a string                                            (Quality)\n### (7)Change the timestamp to correct datetime format                                        (Tidiness)\n### (8)Correct naming issues                                                                  (Quality)\n### (9)delete the empty retweet-related columns                                               (Quality)\n### (10)Keep only original tweets.","caf7eb06":"### code","2281f6a7":"### code","27b89cc9":"### Twitter archive (csv file)","dada2a5c":"# Define\n## (1)Merge the clean versions of df, images, and tweets_df dataframes Correct the dog types\n","a14d8a9b":"# Assess","83a4c027":"## we will\n### (1) Visualizing the total number of tweets over time to see whether that number increases, or decreases, over time.\n### (2) Find out the dog category with the highest favorites rate\n### (3) number of dogs have rating out of 10\n### (4) Visualizing the most popular dog breed.\n### (5) Visualizing the most popular dog names.\n### (6) Top 30 dog names with highest retweets rate","c1989c00":"### (6)","6d6e1b90":"### Gather","5b4ff3bc":"### code","4d2c6da5":"### Twitter info which is on twitter servers encompassed in Twitter archieve , we will download it by Tweepy library.\n","6f0a5b31":"## Define \n### (3) Delete retweets","582a30c9":"### (2)","108e92ce":"### test","beb4c35a":"## Define\n### (8)Correct naming issues","661c638b":"# Wrangling process will consists of the following:\n\n## Define\n## Code\n## Test","b537dd91":"### code","c3e56e39":"# Images Dataframe Analysis\n","7345bb81":"## Define\n### (5)Remove columns no longer needed columns \n","9b4244c9":"### code","a578a044":"### code"}}