{"cell_type":{"61c3ebc9":"code","c86de4b2":"code","e5e60c93":"code","87d31735":"code","a9c9c0ec":"code","8f3a587f":"code","bd35c252":"code","0ac4cd30":"code","146e6095":"code","b72ae45f":"code","aa47eb8b":"code","22b4dc3b":"code","e7e74929":"code","88a5b22c":"code","197bba59":"code","cf9ccb11":"code","2c495b87":"code","4e6fcf88":"code","ed5dcb92":"code","38618f9a":"code","8716af9b":"code","2e4da25e":"code","90dda97c":"code","42a09d64":"code","2c9d4952":"code","a4631a43":"code","dd43d3b1":"code","13a35f07":"code","9e03a1b7":"code","2b67963d":"code","576bfefd":"code","65c3d1e0":"code","9fde7fc5":"code","372194c7":"code","92b322bf":"markdown"},"source":{"61c3ebc9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c86de4b2":"import re\nimport string\n\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.preprocessing.text import Tokenizer\nfrom tensorflow.python.keras.layers import Embedding, GRU, Dense\nfrom tensorflow.python.keras.preprocessing.sequence import pad_sequences","e5e60c93":"df = pd.read_csv(\"\/kaggle\/input\/turkish-movie-sentiment-analysis-dataset\/turkish_movie_sentiment_dataset.csv\")\ndf.head()","87d31735":"df.shape","a9c9c0ec":"comments = lambda x : x[23:-24]\n\ndf[\"comment\"] = df[\"comment\"].apply(comments)\ndf[\"comment\"].head()","8f3a587f":"floatize = lambda x : float(x[0:-2])\n\ndf[\"point\"] = df[\"point\"].apply(floatize)\ndf[\"point\"].value_counts()","bd35c252":"df.drop(df[df[\"point\"] == 3].index, inplace = True)\ndf[\"point\"] = df[\"point\"].replace(1, 0)\ndf[\"point\"] = df[\"point\"].replace(2, 0)\ndf[\"point\"] = df[\"point\"].replace(4, 1)\ndf[\"point\"] = df[\"point\"].replace(5, 1)\ndf[\"point\"].value_counts()","0ac4cd30":"df.reset_index(inplace = True)\ndf.drop(\"index\", axis = 1, inplace = True)\ndf.head()","146e6095":"df[\"comment\"] = df[\"comment\"].apply(lambda x: x.lower())\ndf.head()","b72ae45f":"def remove_punctuation(text):\n    no_punc = [words for words in text if words not in string.punctuation]\n    word_wo_punc = \"\".join(no_punc)\n    return word_wo_punc\n\ndf[\"comment\"] = df[\"comment\"].apply(lambda x: remove_punctuation(x))\ndf[\"comment\"] = df[\"comment\"].apply(lambda x: x.replace(\"\\r\", \" \"))\ndf[\"comment\"] = df[\"comment\"].apply(lambda x: x.replace(\"\\n\", \" \"))\n\ndf.head()","aa47eb8b":"def remove_numeric(corpus):\n    output = \"\".join(words for words in corpus if not words.isdigit())\n    return output\n\ndf[\"comment\"] = df[\"comment\"].apply(lambda x: remove_numeric(x)) \ndf.head()","22b4dc3b":"target = df[\"point\"].values.tolist()\ndata = df[\"comment\"].values.tolist()\n\ncutoff = int(len(data)*0.80)\n\nX_train, X_test = data[:cutoff], data[cutoff:]\ny_train, y_test = target[:cutoff], target[cutoff:]","e7e74929":"num_words = 10000\ntokenizer = Tokenizer(num_words = num_words)\ntokenizer.fit_on_texts(data)\n# tokenizer.word_index","88a5b22c":"X_train_tokens = tokenizer.texts_to_sequences(X_train)\nX_test_tokens = tokenizer.texts_to_sequences(X_test)\n\nprint([X_train[1000]])\nprint(X_train_tokens[1000])","197bba59":"num_tokens = [len(tokens) for tokens in X_train_tokens + X_test_tokens]\nnum_tokens = np.array(num_tokens)\nnum_tokens","cf9ccb11":"np.mean(num_tokens)","2c495b87":"np.max(num_tokens)","4e6fcf88":"max_tokens = np.mean(num_tokens) + (2*np.std(num_tokens))\nmax_tokens = int(max_tokens)\nmax_tokens","ed5dcb92":"np.sum(num_tokens < max_tokens) \/ len(num_tokens)","38618f9a":"X_train_pad = pad_sequences(X_train_tokens, maxlen = max_tokens) \nX_test_pad = pad_sequences(X_test_tokens, maxlen = max_tokens)\n\nprint(X_train_pad.shape)\nprint(X_test_pad.shape)","8716af9b":"np.array(X_train_tokens[800])","2e4da25e":"X_train_pad[2000]","90dda97c":"idx = tokenizer.word_index\ninverse_map = dict(zip(idx.values(), idx.keys()))\n\ndef tokens_to_string(tokens):\n    words = [inverse_map[token] for token in tokens if token != 0]\n    text = \" \".join(words) # Kelimeler aralar\u0131nda bo\u015fluk b\u0131rak\u0131larak ard arda yaz\u0131lacakt\u0131r.\n    return text","42a09d64":"tokens_to_string(X_train_tokens[350])","2c9d4952":"embedding_size = 50\nmodel = Sequential()\nmodel.add(Embedding(input_dim = num_words, output_dim = embedding_size, input_length = max_tokens, name = \"embedding_layer\"))\nmodel.add(GRU(units = 16, return_sequences = True))\nmodel.add(GRU(units = 8, return_sequences = True))\nmodel.add(GRU(units = 4))\nmodel.add(Dense(1, activation = \"sigmoid\"))","a4631a43":"optimizer = Adam(lr = 1e-3)\nmodel.compile(loss = \"binary_crossentropy\", optimizer = optimizer, metrics = [\"accuracy\"])\nmodel.summary()","dd43d3b1":"X_train_pad = np.array(X_train_pad)\ny_train = np.array(y_train)\n\nmodel.fit(X_train_pad, y_train, epochs = 5, batch_size = 256)","13a35f07":"y_pred = model.predict(X_test_pad[0:1000])\ny_pred = y_pred.T[0]\n# y_pred","9e03a1b7":"cls_pred = np.array([1.0 if p > 0.5 else 0.0 for p in y_pred])\ncls_true = np.array(y_test[0:1000])","2b67963d":"incorrect = np.where(cls_pred != cls_true)\nincorrect = incorrect[0]\n# incorrect","576bfefd":"len(incorrect)","65c3d1e0":"idx = incorrect[10]\nX_test[idx]","9fde7fc5":"y_pred[idx]","372194c7":"cls_true[idx]","92b322bf":"# [Github](https:\/\/github.com\/kubrakurt\/turkish_movie_sentiment_analysis)"}}