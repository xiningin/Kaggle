{"cell_type":{"4abfdc28":"code","3a80107b":"code","4047da97":"code","ab749342":"code","3f24d884":"code","d3cead21":"code","cb4d6dcb":"code","7126d94d":"code","7ac9ee73":"code","203a8a0c":"code","4350377b":"code","301bfde8":"code","0009694d":"code","68f27919":"code","472bf44f":"code","81f78cac":"code","ee440c4e":"code","60f5e2e1":"code","4a65c1fa":"code","bf53c0fd":"code","c0779b41":"code","91dacbd3":"code","837a21bc":"code","82902765":"code","d6432923":"code","71a7c690":"code","88a7dc71":"code","ec61bb03":"code","d1efce8a":"code","4bcfc65d":"code","a47a2bfa":"code","e957a8df":"code","f8d8449b":"code","a2c543fe":"code","7d4f9c04":"code","9fbcb62f":"code","e5204a86":"code","84fd3043":"code","ea098f89":"code","3de6e45d":"code","6c8955de":"code","4abcb107":"markdown","1c0972f4":"markdown","128da67f":"markdown","ed0a8a66":"markdown","c2f1cb7d":"markdown","9b03b2c0":"markdown","041c7ce4":"markdown","01bc7838":"markdown","35808bcc":"markdown","3e95c8a3":"markdown","c87ac70a":"markdown","d352ce80":"markdown","25e5e571":"markdown","0a993b8a":"markdown","cac61c97":"markdown","5319554a":"markdown","2223c6cf":"markdown","aa561c4c":"markdown","e6e23487":"markdown"},"source":{"4abfdc28":"import os #paths to file\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\nimport warnings# warning filter\n\n\n#ploting libraries\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\n# ML libraries\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\n#ML models\nfrom xgboost import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression","3a80107b":"df = pd.read_csv(\"..\/input\/loan-prediction-problem-dataset\/train_u6lujuX_CVtuZ9i.csv\")\ndf.head()","4047da97":"df.describe()","ab749342":"df.info()\n","3f24d884":"df.isnull().sum()\n","d3cead21":"df['Gender'] = df[\"Gender\"].fillna(df['Gender'].mode()[0])\ndf['Married'] = df[\"Married\"].fillna(df['Married'].mode()[0])\ndf['Self_Employed'] = df[\"Self_Employed\"].fillna(df['Self_Employed'].mode()[0])\ndf['Dependents'] = df[\"Dependents\"].fillna(df['Dependents'].mode()[0])\ndf['LoanAmount'] = df[\"LoanAmount\"].fillna(df['LoanAmount'].mode()[0])\ndf['Loan_Amount_Term'] = df[\"Loan_Amount_Term\"].fillna(df['Loan_Amount_Term'].mode()[0])\ndf['Credit_History'] = df[\"Credit_History\"].fillna(df['Credit_History'].mode()[0])\n\n","cb4d6dcb":"null_cols = ['Credit_History', 'Self_Employed', 'LoanAmount','Dependents', 'Loan_Amount_Term', 'Gender', 'Married']\nfor col in null_cols:\n    print(f\"\\n{col}:\\n{df[col].value_counts()}\\n\",\"-\"*50)","7126d94d":"sns.countplot(x ='Dependents', data = df)","7ac9ee73":"sns.countplot(x ='Credit_History', data = df)\n","203a8a0c":"sns.boxplot(x=\"LoanAmount\", data=df)\n","4350377b":"Q1 = df['LoanAmount'].quantile(0.25)\nQ3 = df['LoanAmount'].quantile(0.75)\nIQR = Q3 - Q1","301bfde8":"low_lim = Q1 - 1.5 * IQR\nup_lim = Q3 + 1.5 * IQR\nprint('low_limit is', low_lim)\nprint('up_limit is', up_lim)","0009694d":"df['Total_Income']=df['ApplicantIncome'] + df['CoapplicantIncome']\ndf.head()","68f27919":"df.drop('Loan_ID',axis=1,inplace=True)\n","472bf44f":"df.head()","81f78cac":"len(df)-len(df.drop_duplicates())","ee440c4e":"df.info()","60f5e2e1":"from sklearn.preprocessing import LabelEncoder\ncols=['Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area', 'Loan_Status', 'Dependents']\nle=LabelEncoder()\nfor col in cols:\n    df[col]=le.fit_transform(df[col])\n\n","4a65c1fa":"df.head()","bf53c0fd":"X = df.drop(columns=['Loan_Status'], axis=1)\ny = df['Loan_Status']\n#make data balanced\nfrom imblearn import under_sampling, over_sampling\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.combine import SMOTEENN\nSMOTENN = SMOTEENN()\nX,y = SMOTENN.fit_resample(X,y)\n#ros = RandomOverSampler (random_state = 42)\n#X, y = ros.fit_resample(X,y)\n","c0779b41":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)","91dacbd3":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()","837a21bc":"X_train_scaled = sc.fit_transform(x_train)\nX_test_scaled = sc.fit_transform(x_test)","82902765":"from sklearn.metrics import accuracy_score, confusion_matrix, f1_score,classification_report, roc_curve","d6432923":"from sklearn.tree import DecisionTreeClassifier","71a7c690":"dt = DecisionTreeClassifier(criterion= 'gini',max_depth=11 , random_state=42)\ndt.fit(X_train_scaled,y_train)\ndt_pred = dt.predict(X_test_scaled)\nprint(classification_report(y_test, dt_pred))\nDT_SC = accuracy_score(dt_pred,y_test)\nprint('Accuracy_Score of Decision Tree: ', accuracy_score(y_test, dt_pred))\nmatrix=confusion_matrix(y_test, dt_pred)","88a7dc71":"plt.figure(figsize = (8,4))\nsns.heatmap(matrix , annot = True, cmap=\"YlOrBr\")","ec61bb03":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=7)\nknn.fit(X_train_scaled,y_train)\nknn_pred = knn.predict(X_test_scaled)\nprint(classification_report(y_test, knn_pred))\nKN_SC = accuracy_score(knn_pred,y_test)\nprint('Accuracy_Score of KNeighbors Classifier: ', accuracy_score(y_test, knn_pred))\nmatrix1=confusion_matrix(y_test, knn_pred)","d1efce8a":"from sklearn.linear_model import LogisticRegression","4bcfc65d":"logreg = LogisticRegression()\nlogreg.fit(X_train_scaled, y_train)\nlogreg_pred = logreg.predict(X_test_scaled)\nprint(classification_report(y_test, logreg_pred))\nLR_SC = accuracy_score(logreg_pred,y_test)\nprint('Accuracy Score of Logistic Regression: ', accuracy_score(y_test, logreg_pred))\nmatrix2=confusion_matrix(y_test, logreg_pred)","a47a2bfa":"plt.figure(figsize = (8,4))\nsns.heatmap(matrix2 , annot = True, cmap=\"rocket\")","e957a8df":"from sklearn.svm import SVC","f8d8449b":"svm = SVC()\nsvm.fit(X_train_scaled, y_train)\nsvm_pred = svm.predict(X_test_scaled)\nprint(classification_report(y_test, svm_pred))\nSVM_SC = accuracy_score(svm_pred,y_test)\nprint('Accuracy Score of Super Vector Machine: ', accuracy_score(y_test, svm_pred))\nmatrix3=confusion_matrix(y_test, svm_pred)","a2c543fe":"plt.figure(figsize = (8,4))\nsns.heatmap(matrix3 , annot = True, cmap=\"magma\")","7d4f9c04":"from sklearn.ensemble import RandomForestClassifier","9fbcb62f":"RF = RandomForestClassifier()\nRF.fit(X_train_scaled, y_train)\nRF_pred = RF.predict(X_test_scaled)\nprint(classification_report(y_test, RF_pred))\nRF_SC = accuracy_score(RF_pred,y_test)\nprint('Accuracy Score of Random Forest Classifier: ', accuracy_score(y_test, RF_pred))\nmatrix4=confusion_matrix(y_test, RF_pred)","e5204a86":"plt.figure(figsize = (8,4))\nsns.heatmap(matrix4 , annot = True, cmap=\"magma\")","84fd3043":"from xgboost import XGBClassifier","ea098f89":"XG = XGBClassifier()\nXG.fit(X_train_scaled, y_train)\nxg_pred = XG.predict(X_test_scaled)\nprint(classification_report(y_test, xg_pred))\nXGB_SC = accuracy_score(xg_pred,y_test)\nprint('Accuracy Score of XGBClassifier: ', accuracy_score(y_test, xg_pred))\nmatrix5=confusion_matrix(y_test, xg_pred)","3de6e45d":"plt.figure(figsize = (8,4))\nsns.heatmap(matrix5 , annot = True, cmap=\"Blues\")","6c8955de":"score = [DT_SC,RF_SC,XGB_SC,LR_SC , SVM_SC , KN_SC]\nModels = pd.DataFrame({\n    'n_neighbors': [\"Decision Tree\",\"Random Forest\",\"XGBoost\", \"Logistic Regression\" , \"SVM\" , \"KNeighborsClassifier\"],\n    'Score': score})\nModels.sort_values(by='Score', ascending=False)","4abcb107":"**Logistic Regression**","1c0972f4":"**Check duplication**","128da67f":"dealing with outliers","ed0a8a66":"# Modeling","c2f1cb7d":"# Libraries","9b03b2c0":"# Details\n The dataset contains a set of 613 records under 13 attributes:\n\n","041c7ce4":"Each value will be replaced by the most frequent value (mode).\n\nEx. Credit_History has 50 null values and has 2 unique values 1.0 (475 times) or 0.0 (89 times) therefore each null value will be replaced by the mode 1.0 so now it will show in our data 525 times.","01bc7838":"**KNeighborsClassifier**","35808bcc":"# preview data","3e95c8a3":"**xgboost Classifier**","c87ac70a":"**Decsion Tree**","d352ce80":"# Drop don`t need data","25e5e571":"we will not remove outliers bec it doesn`t effect on data","0a993b8a":"**SVM**","cac61c97":"**Random Forest Classifier**","5319554a":"# EDA","2223c6cf":"# Check and Dealing with missing Data","aa561c4c":"target value: Loan_Status","e6e23487":"Check Outliers"}}