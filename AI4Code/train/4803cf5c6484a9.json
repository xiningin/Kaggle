{"cell_type":{"1741b03a":"code","e5bfcdc1":"code","0f6c20a8":"code","503b9f86":"code","8449c785":"code","b094fc7f":"code","721f908a":"code","0f2f6128":"code","c74056ba":"code","47d318ab":"code","27263be3":"code","780a172e":"code","8607aa80":"code","203ea486":"code","8a6824e5":"code","7f330966":"code","e1c0acca":"code","9d1e9878":"code","16bdc218":"code","729cd3b1":"code","6e1c3845":"code","b13039e6":"code","d11e9b15":"code","be2a066e":"code","2a4ba771":"code","57c3ef7e":"code","4480db5f":"code","86d8fced":"code","6c6f8bbb":"code","13ff5141":"code","850c37be":"code","8b6ff133":"code","cc44f86d":"markdown","87628853":"markdown","f108e2b9":"markdown","a725961a":"markdown","21a51643":"markdown","5785e056":"markdown","b5e527ae":"markdown","96a07d26":"markdown","0f5cf9c1":"markdown","89178f68":"markdown","36b24b06":"markdown","ad112dc2":"markdown","4c9edee1":"markdown"},"source":{"1741b03a":"!pip install tensorflow_datasets > \/dev\/null","e5bfcdc1":"import time\nimport numpy as np\nimport gc\nimport pandas as pd\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_datasets as tfds\nfrom keras import backend as K\n\nfrom tensorflow.keras.layers import Dense, Input, BatchNormalization, Dropout, concatenate, GlobalAveragePooling1D\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam, SGD\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn import metrics\n\nprint(\"Version: \", tf.__version__)\nprint(\"Eager mode: \", tf.executing_eagerly())\nprint(\"Hub version: \", hub.__version__)\nprint(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")\n\nstart = time.time()\npd.options.display.max_colwidth = 1500","0f6c20a8":"# My Parameters\nBATCH_SIZE = 512\nSEED=42","503b9f86":"print(\"Word Cloud Function..\")\nstopwords = set(STOPWORDS)\nsize = (20,10)\n\ndef cloud(text, title, stopwords=stopwords, size=size):\n    \"\"\"\n    Function to plot WordCloud\n    Includes: \n    \"\"\"\n    # Setting figure parameters\n    mpl.rcParams['figure.figsize']=(10.0,10.0)\n    mpl.rcParams['font.size']=12\n    mpl.rcParams['savefig.dpi']=100\n    mpl.rcParams['figure.subplot.bottom']=.1 \n    \n    # Processing Text\n    # Redundant when combined with my Preprocessing function\n    wordcloud = WordCloud(width=1600, height=800,\n                          background_color='black',\n                          stopwords=stopwords,\n                         ).generate(str(text))\n    \n    # Output Visualization\n    fig = plt.figure(figsize=size, dpi=80, facecolor='k',edgecolor='k')\n    plt.imshow(wordcloud,interpolation='bilinear')\n    plt.axis('off')\n    plt.title(title, fontsize=50,color='y')\n    plt.tight_layout(pad=0)\n    plt.show()","8449c785":"train_data, test_data = tfds.load(name=\"imdb_reviews\", split=[\"train\", \"test\"], \n                                  batch_size=-1, as_supervised=True)\n\ntrain_examples, train_labels = tfds.as_numpy(train_data)\ntest_examples, test_labels = tfds.as_numpy(test_data)","b094fc7f":"np.save(\"train_examples\", train_examples)\nnp.save(\"train_labels\", train_labels)\n\nnp.save(\"test_examples\", test_examples)\nnp.save(\"test_labels\", test_labels)","721f908a":"!ls","0f2f6128":"print(\"Training entries: {}, test entries: {}\".format(len(train_examples), len(test_examples)))","c74056ba":"input_len = [len(x) for x in np.concatenate((train_examples, test_examples), axis=0)]\nprint(\"Input Lengths:\\nAverage {:.1f} +\/- {:.1f}\\nMax {} Min {}\".format(np.mean(input_len), np.std(input_len), np.max(input_len), np.min(input_len)))","47d318ab":"train_examples[:10]","27263be3":"train_labels[:10]","780a172e":"# Look at class balance..\nunique_elements, counts_elements = np.unique(train_labels, return_counts=True)\nprint(\"Frequency of unique values of the said array:\")\nprint(np.asarray((unique_elements, counts_elements)))","8607aa80":"%%time\nmodel = \"https:\/\/tfhub.dev\/google\/tf2-preview\/gnews-swivel-20dim\/1\"\nhub_layer = hub.KerasLayer(model, output_shape=[], input_shape=[], \n                           dtype=tf.string, trainable=True, name='gnews_embedding')","203ea486":"hub_layer(train_examples[:3])","8a6824e5":"def build_model(embed):\n    \n    model = Sequential([\n        Input(shape=[], dtype=tf.string),\n        embed,\n        Dropout(.2),\n        Dense(16, activation='relu'),\n        Dropout(.2),\n        Dense(1, activation='sigmoid')\n    ])\n    model.compile(Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return model\n\nmodel = build_model(hub_layer)\nmodel.summary()","7f330966":"es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, verbose=1, mode='min')\ncheckpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True)\n\nhistory = model.fit(\n                    train_examples,\n                    train_labels,\n                    epochs=40,\n                    batch_size=BATCH_SIZE,\n                    validation_split = .2,\n                    shuffle = True,\n                    callbacks = [checkpoint, es],\n                    verbose=1)\n\nmodel.load_weights('model.h5')\nresults = model.evaluate(test_examples, test_labels)\nprint(results)","e1c0acca":"history_dict = history.history\nhistory_dict.keys()\n\nacc = history_dict['accuracy']\nval_acc = history_dict['val_accuracy']\nloss = history_dict['loss']\nval_loss = history_dict['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nf, ax = plt.subplots(1,2, figsize = [11,4])\n\n# \"bo\" is for \"blue dot\"\nax[0].plot(epochs, loss, 'r', label='Training loss')\n# b is for \"solid blue line\"\nax[0].plot(epochs, val_loss, 'b', label='Validation loss')\nax[0].set_title('Training and validation loss')\nax[0].set_xlabel('Epochs')\nax[0].set_ylabel('Loss')\nax[0].legend()\n\nax[1].plot(epochs, acc, 'r', label='Training acc')\nax[1].plot(epochs, val_acc, 'b', label='Validation acc')\nax[1].set_title('Training and validation accuracy')\nax[1].set_xlabel('Epochs')\nax[1].set_ylabel('Accuracy')\nax[1].legend()\n\nplt.tight_layout()\n\nplt.show()","9d1e9878":"# Test Predictions\ntest_pred = model.predict(test_examples, batch_size = BATCH_SIZE)\nresults_pd = pd.DataFrame.from_dict({'text': test_examples, 'pred': test_pred[:,0], 'ground_truth': test_labels})\nresults_pd['error'] = results_pd['ground_truth'] - results_pd['pred']\n\nprint(\"Look at False Negative\")\ndisplay(results_pd.sort_values(by = 'error', ascending=False).iloc[:10])\n\nprint(\"Look at False Positives\")\ndisplay(results_pd.sort_values(by = 'error', ascending=True).iloc[:10])","16bdc218":"# Clear Memory\nK.clear_session()\n\ndel history\ndel model\n_ = gc.collect()","729cd3b1":"%%time\nmodule_url = 'https:\/\/tfhub.dev\/google\/universal-sentence-encoder-large\/4'\nUSE_embed = hub.KerasLayer(module_url, trainable=False, name='USE_embedding')","6e1c3845":"USE_embed(train_examples[:3])","b13039e6":"def build_model(embed):\n    \n    model = Sequential([\n        Input(shape=[], dtype=tf.string),\n        embed,\n        Dropout(.2),\n        Dense(16, activation='relu'),\n        Dropout(.2),\n        Dense(1, activation='sigmoid')\n    ])\n    model.compile(Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return model\n\nmodel = build_model(USE_embed)\nmodel.summary()","d11e9b15":"MAX_LEN = 2058\n\nsmall_train_examples = np.array([x[:MAX_LEN] for x in train_examples])\nsmall_test_examples = np.array([x[:MAX_LEN] for x in test_examples])","be2a066e":"es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, verbose=1, mode='min')\ncheckpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True)\n\nhistory = model.fit(\n                    small_train_examples,\n                    train_labels,\n                    epochs=40,\n                    batch_size=BATCH_SIZE,\n                    validation_split = .2,\n                    shuffle = True,\n                    callbacks = [checkpoint, es],\n                    verbose=1)\n\nmodel.load_weights('model.h5')\nresults = model.evaluate(small_test_examples, test_labels)\nprint(results)","2a4ba771":"history_dict = history.history\nhistory_dict.keys()\n\nacc = history_dict['accuracy']\nval_acc = history_dict['val_accuracy']\nloss = history_dict['loss']\nval_loss = history_dict['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nf, ax = plt.subplots(1,2, figsize = [11,4])\n\n# \"bo\" is for \"blue dot\"\nax[0].plot(epochs, loss, 'r', label='Training loss')\n# b is for \"solid blue line\"\nax[0].plot(epochs, val_loss, 'b', label='Validation loss')\nax[0].set_title('Training and validation loss')\nax[0].set_xlabel('Epochs')\nax[0].set_ylabel('Loss')\nax[0].legend()\n\nax[1].plot(epochs, acc, 'r', label='Training acc')\nax[1].plot(epochs, val_acc, 'b', label='Validation acc')\nax[1].set_title('Training and validation accuracy')\nax[1].set_xlabel('Epochs')\nax[1].set_ylabel('Accuracy')\nax[1].legend()\n\nplt.tight_layout()\n\nplt.show()","57c3ef7e":"# Test Predictions\ntest_pred = model.predict(small_test_examples, batch_size = BATCH_SIZE)\nresults_pd = pd.DataFrame.from_dict({'text': test_examples, 'pred': test_pred[:,0], 'ground_truth': test_labels})\nresults_pd['error'] = results_pd['ground_truth'] - results_pd['pred']\n\nprint(\"Look at False Negative\")\ndisplay(results_pd.sort_values(by = 'error', ascending=False).iloc[:10])\n\nprint(\"Look at False Positives\")\ndisplay(results_pd.sort_values(by = 'error', ascending=True).iloc[:10])","4480db5f":"# USE output shape..\nUSE_embed([small_train_examples[0]])['outputs'].numpy().shape","86d8fced":"%%time\nfull_labels = np.concatenate((train_labels, test_labels))\nfull_txt = np.concatenate((small_train_examples, small_test_examples))\n\nbatch_size = 500\nembeddings = []\n\nfor b in range(0, full_txt.shape[0] \/\/ batch_size):\n    embeddings.extend(USE_embed(full_txt[batch_size*b: batch_size*(b+1)])['outputs'].numpy())","6c6f8bbb":"kmeans = KMeans(n_clusters=3, random_state=SEED).fit(embeddings)\nprint(\"Silhouette Coefficient: %0.3f\"% metrics.silhouette_score(embeddings, kmeans.labels_, sample_size=1000))\n\n# Prepare DataFrame\ndf = pd.DataFrame.from_dict({\"Text\": full_txt,\n                             \"Labels\": np.concatenate((train_labels, test_labels)),\n                             \"Clusters\": kmeans.labels_})","13ff5141":"print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(full_labels, kmeans.labels_))\nprint(\"Completeness: %0.3f\" % metrics.completeness_score(full_labels, kmeans.labels_))\nprint(\"V-measure: %0.3f\" % metrics.v_measure_score(full_labels, kmeans.labels_))\nprint(\"Adjusted Rand-Index: %.3f\"\n      % metrics.adjusted_rand_score(full_labels, kmeans.labels_))\nprint(\"Silhouette Coefficient: %0.3f\"\n      % metrics.silhouette_score(embeddings, full_labels, sample_size=1000))\n\ndisplay(pd.crosstab(df['Clusters'], df['Labels']))","850c37be":"for c in sorted(df['Clusters'].unique()):\n    cloud(df.loc[df.Clusters == c,\"Text\"].astype(str).str.title().values, title=f\"Cluster ID: {c}\", size=[8,5])\n    display(df.loc[df.Clusters == c,:].sample(5, random_state=SEED))","8b6ff133":"print(\"Notebook Runtime: %0.2f Minutes\"%((time.time() - start)\/60))","cc44f86d":"Let's also print the first 10 labels.","87628853":"#### Model Evaluation","f108e2b9":"## Build the model\n\nThe neural network is created by stacking layers\u2014this requires three main architectural decisions:\n\n* How to represent the text?\n* How many layers to use in the model?\n* How many *hidden units* to use for each layer?\n\nIn this example, the input data consists of sentences. The labels to predict are either 0 or 1.\n\nOne way to represent the text is to convert sentences into embeddings vectors. We can use a pre-trained text embedding as the first layer, which will have two advantages:\n*   we don't have to worry anout text preprocessing,\n*   we can benefit from transfer learning.\n\nFor this example we will use a model from [TensorFlow Hub](https:\/\/www.tensorflow.org\/hub) called [google\/tf2-preview\/gnews-swivel-20dim\/1](https:\/\/tfhub.dev\/google\/tf2-preview\/gnews-swivel-20dim\/1).\n\nThere are three other models to test for the sake of this tutorial:\n* [google\/tf2-preview\/gnews-swivel-20dim-with-oov\/1](https:\/\/tfhub.dev\/google\/tf2-preview\/gnews-swivel-20dim-with-oov\/1) - same as [google\/tf2-preview\/gnews-swivel-20dim\/1](https:\/\/tfhub.dev\/google\/tf2-preview\/gnews-swivel-20dim\/1), but with 2.5% vocabulary converted to OOV buckets. This can help if vocabulary of the task and vocabulary of the model don't fully overlap.\n* [google\/tf2-preview\/nnlm-en-dim50\/1](https:\/\/tfhub.dev\/google\/tf2-preview\/nnlm-en-dim50\/1) - A much larger model with ~1M vocabulary size and 50 dimensions.\n* [google\/tf2-preview\/nnlm-en-dim128\/1](https:\/\/tfhub.dev\/google\/tf2-preview\/nnlm-en-dim128\/1) - Even larger model with ~1M vocabulary size and 128 dimensions.","a725961a":"## Explore the data \n\nLet's take a moment to understand the format of the data. Each example is a sentence representing the movie review and a corresponding label. The sentence is not preprocessed in any way. The label is an integer value of either 0 or 1, where 0 is a negative review, and 1 is a positive review.","21a51643":"## GNEWS Embeddings Model","5785e056":"Let's now build the full model:","b5e527ae":"## Universal Sentence Encoding Clustering","96a07d26":"#### Fit Kmeans ","0f5cf9c1":"## Download the IMDB dataset\n\nThe IMDB dataset is available on [TensorFlow datasets](https:\/\/github.com\/tensorflow\/datasets). The following code downloads the IMDB dataset to your machine (or the colab runtime):","89178f68":"Let's print first 10 examples.","36b24b06":"## Universal Sentence Encoding Embeddings Model","ad112dc2":"Let's first create a Keras layer that uses a TensorFlow Hub model to embed the sentences, and try it out on a couple of input examples. Note that the output shape of the produced embeddings is a expected: `(num_examples, embedding_dimension)`.","4c9edee1":"# IMDB USE and GNEWS Embedding Models\n\n_By Nick Brooks, February 2020_\n\n\n# TF Hub for TF2: Text classification with movie reviews (preview)\n\nSOURCE: https:\/\/github.com\/tensorflow\/hub\/blob\/master\/examples\/colab\/tf2_text_classification.ipynb\n\nThis notebook classifies movie reviews as *positive* or *negative* using the text of the review. This is an example of *binary*\u2014or two-class\u2014classification, an important and widely applicable kind of machine learning problem. \n\nWe'll use the [IMDB dataset](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/datasets\/imdb) that contains the text of 50,000 movie reviews from the [Internet Movie Database](https:\/\/www.imdb.com\/). These are split into 25,000 reviews for training and 25,000 reviews for testing. The training and testing sets are *balanced*, meaning they contain an equal number of positive and negative reviews. \n\nThis notebook uses [tf.keras](https:\/\/www.tensorflow.org\/guide\/keras), a high-level API to build and train models in TensorFlow, and [TensorFlow Hub](https:\/\/www.tensorflow.org\/hub), a library and platform for transfer learning. For a more advanced text classification tutorial using `tf.keras`, see the [MLCC Text Classification Guide](https:\/\/developers.google.com\/machine-learning\/guides\/text-classification\/)."}}