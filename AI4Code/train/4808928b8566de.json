{"cell_type":{"5e6466c1":"code","08696fd1":"code","adce8f3a":"code","578f04c2":"code","2dfea5e6":"code","e2fc265c":"code","3677621c":"code","80561793":"code","16c591cd":"code","51ec308f":"code","32db9e8f":"code","423da0c7":"code","26010393":"code","31f18896":"code","59bbd81c":"code","66519509":"code","b0dee208":"code","bb690189":"code","63e2be3b":"code","803a067a":"code","793cd238":"code","83446567":"code","281b09cf":"code","da85ce9d":"code","e3543264":"code","05634a23":"code","3d0e15cb":"code","77061eda":"code","5742ec49":"code","00c7bc5c":"code","9743b2be":"code","6af500cd":"code","abdcd1fd":"code","01538791":"code","e3d727ac":"code","cd05d4a3":"code","d0613894":"markdown","1d8cf8ee":"markdown","46b72c5a":"markdown","e5eb59bd":"markdown","244fa283":"markdown","c20a44f6":"markdown"},"source":{"5e6466c1":"# Loading necessary libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","08696fd1":"# Loading the data\n\ncities_predict = pd.read_csv('..\/input\/cities_predict.csv')","adce8f3a":"# Checking the variables\n\ncities_predict.info()","578f04c2":"# We extract all nummerical values\nonly_nummerical = cities_predict.iloc[:,:28]","2dfea5e6":"# We extract the regions column (that we want to predict)\nregion = cities_predict.iloc[:,29]","e2fc265c":"# We extract the nomad_score column (that we want to predict)\nnomad_score = cities_predict.iloc[:,28]","3677621c":"print('### Nummerical values ###')\nprint(only_nummerical.head(3))\n\nprint('### Regions ###')\nprint(region.head(3))\n\nprint('### Nomad Score ###')\nprint(nomad_score.head(3))","80561793":"# We use the standard scaler here but you can experiment with other approaches to that\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\nscaled_inputs = scaler.fit_transform(only_nummerical)","16c591cd":"# Define X for clustering as the scaled inputs\nX = scaled_inputs","51ec308f":"# Reduce dimensions to 10\nfrom sklearn.decomposition import PCA\n\npca = PCA(n_components=5)\nX_scaled = pca.fit_transform(X)","32db9e8f":"# We import KMeans and creade a model object\nfrom sklearn.cluster import KMeans\n\n# Let's start first with 3\nmodel = KMeans(n_clusters = 3)","423da0c7":"# Fit the model\n\nmodel.fit(X_scaled)","26010393":"# Define a new dataframe with cities and regions\ncities_regions = cities_predict.loc[:,'region':]","31f18896":"# Get cluster labels into this dataframe!\ncities_regions['cluster'] = model.labels_","59bbd81c":"# We can try to visualize our documents using TSNE - \n# an approach for visualizing high-dimensional data\n\n# Import the module first\nfrom sklearn.manifold import TSNE\n\n# And instantiate\ntsne = TSNE()\n\n# Let's try to boil down the 100 dimensions into 2\nvisualization = tsne.fit_transform(X)","66519509":"# Import the plotting library\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","b0dee208":"# Plot the trump_tweet map\nplt.figure(figsize=(15,15))\nsns.scatterplot(visualization[:,0],visualization[:,1], \n             \n           hue=cities_regions.cluster, legend='full')","bb690189":"# Evaluate the clusters vs. regions\npd.crosstab(cities_regions['region'],cities_regions['cluster'])","63e2be3b":"cities_regions[(cities_regions.cluster == 2) & (cities_regions.region == 'Africa')]['place_slug']","803a067a":"X = scaled_inputs","793cd238":"# Encoding categorical data\nfrom sklearn.preprocessing import LabelEncoder","83446567":"# Define the label encoder to transform region names to numbers\nlabelencoder_y = LabelEncoder()\ny = labelencoder_y.fit_transform(*****)","281b09cf":"# Splitting the dataset into the Training set and Test set\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(*****, y, test_size = 0.2, random_state = 21)","da85ce9d":"# We first import and train a Logistic Regression\n\nfrom sklearn.linear_model import LogisticRegression\n\nclassifier = LogisticRegression()\n\nclassifier.fit(*****, y_train)","e3543264":"# Applying k-Fold Cross Validation\nfrom sklearn.model_selection import cross_val_score\n\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n\nprint(accuracies.mean())\nprint(accuracies.std())","05634a23":"# Check the accuracy of the model\nclassifier.score(X_test, y_test)","3d0e15cb":"# Predicting the test set results from the test-set inputs\ny_pred = classifier.predict(*****)","77061eda":"# Transforming nummerical labels back to Region-names\n\ntrue_regions = labelencoder_y.inverse_transform(y_test)\n\npredicted_regions = labelencoder_y.inverse_transform(*****)","5742ec49":"# Creating a pandas DataFrame and cross-tabulation\n\ndf = pd.DataFrame({'true_regions': true_regions, 'predicted_regions': predicted_regions}) \n\npd.crosstab(*****, df.predicted_regions)","00c7bc5c":"# Our inputs are still the same\n\nX = *****","9743b2be":"# Our output is the Nomad Score\n\ny = nomad_score","6af500cd":"# Splitting the dataset into the Training set and Test set (since we have a new output variable)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, *****, test_size = 0.2, random_state = 21)","abdcd1fd":"# Let's fit a simple linear regression model\n\nfrom sklearn.linear_model import LinearRegression\n\nregressor = LinearRegression()\n\nregressor.fit(*****, *****)","01538791":"from sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\n \n\npredictions = cross_val_predict(estimator = regressor, X = X_train, y = y_train, cv = 10)\n\n# RMSE (np.sqrt stands for quare-root)\nprint(np.sqrt(mean_squared_error(y_train, predictions)))\n\n# r2_scores\nprint(r2_score(y_train, predictions))\n\n# Scoring the regressor (r2-score) on the test-set\nregressor.score(X_test, y_test)","e3d727ac":"\n# Predicting from the held back X_test\ny_pred = regressor.predict(*****)","cd05d4a3":"sns.regplot(y_test, y_pred)","d0613894":"## *Predicting* the Nomad Score\nIn the following we will try to predict the nomad score (a continuous variable)","1d8cf8ee":"## Classification of regions\n\nIn the following you will be using various classification models to predict the region for each city given only the nummerical variables in cities_predict ","46b72c5a":"## Clustering the Cities\n\nLet's try to use the variables in the data to cluster the cities into some \"latent\" groups\n\nWhat do you expect could be a good way to structure the cities?","e5eb59bd":"Since you are not expected to use the Nomad Score for Region-prediction, we can use the same inputs for the classification and the regression exercise below. Therefore, we can feature-scale it already at this point. Here, for the sake of simplicity we standardize all variables but you may experiment with leaving out dummy variables (0\/1).","244fa283":"k-fold cross-validation is different with regression problems\noften you will see people using the r2_score (the more the better) and the RMSE\nRoot Mean Square Error (the lower the better)\nFor a regression probme sklearn will perform k-fold cross validation and return the predicted values (for each slice)\nUsing those and the real values (y_train) you can calculate r2_scores and RMSE","c20a44f6":"# Predicting Regions and the *Nomad Score* from city-characteristics\n## *This is an exercise notebook and therefore will give errors if executed as is* ## \n\n![nomad](http:\/\/www.investospain.es\/wp-content\/uploads\/sites\/342\/2017\/08\/DigitalNomad.jpg)\n\nThis data has been scraped from[ Nomadlist.io ](http:\/\/nomadlist.io) and contains data on 730 cities worldwide that digital nomads prefer to spend time in.\n\nThe data is a mix between community collected indicators and variables aggregated from public sources.\n\nThe data has been cleaned up and missing values imputed.\n\nIn the first part of this notebook you will use unsupervised machine lerarning techniques to cluster the cities. With this info at hand, we will explore what brought individual cities together.\n\nIn the second part, we will use supervised ML to solve one classification taks \u2013 predicting the task \u2013 and one regression taks \u2013 predicting the nomad score."}}