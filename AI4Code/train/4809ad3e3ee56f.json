{"cell_type":{"3ec1eb8a":"code","ac1284da":"code","ba914e73":"code","16cf187d":"code","ea90eb3a":"code","bd5a494b":"code","9bac568d":"code","c4623e52":"code","933c6dd5":"code","71285f5f":"code","82b71aa1":"code","0062418e":"code","62c92604":"code","7ce5704e":"code","9b1fbe96":"code","313c077f":"code","ae866338":"code","c45e96f4":"code","aeca4881":"code","deede369":"code","d335f69c":"code","ef44017d":"code","6bc6f9f3":"code","b13bb07a":"code","230e47f5":"code","8c8cfa18":"code","6e7ae08f":"code","00ecf584":"code","4c11db27":"code","a8d980bf":"code","da56bed1":"code","41eff53e":"code","c38f548e":"code","87f6512c":"markdown","84efd6f0":"markdown","54f66941":"markdown","409d228a":"markdown"},"source":{"3ec1eb8a":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ac1284da":"df = pd.read_csv('\/kaggle\/input\/weather-dataset-rattle-package\/weatherAUS.csv')\ndf.head()","ba914e73":"# A function that outputs information about the data\ndef df_info(df, name=None, flag = False):\n    if name is not None:\n        print(f'df = {name}')\n        print('--------------------')\n    \n    print(f'size df : {df.shape[0]} x {df.shape[1]} ')\n    print('--------------------')\n        \n    if df.isnull().sum().sum() == 0:\n        print('not missing values!')\n    else:\n        print('Missing values:')\n        counter = 0\n        for col in df.columns:\n            if df[col].isna().sum():\n                print(col,'TYPE: ', df[col].dtypes, 'MISSING VALUES: ', df[col].isna().sum(),\n                     f'({df[col].isna().sum()\/df.shape[0]:.2%})')\n                if df[col].isna().sum()\/df.shape[0] > 0.2:\n                    counter += 1\n            else:\n                print(col,'TYPE: ', df[col].dtypes, 'MISSING VALUES: ', df[col].isna().sum(),)\n        if counter > 0:\n            print('--------------------')\n            print(f'Missing values >20% in {counter} features')\n    if flag:\n        print('--------------------')\n        print(df.info())\n        print('--------------------')\n        print(df.describe())","16cf187d":"df_info(df, 'Rain in Australian')","ea90eb3a":"# drop ,where missing values 40 %\ndf = df.drop(['Evaporation', 'Sunshine', 'Cloud9am', 'Cloud3pm'], axis=1)","bd5a494b":"# Also I'm deleted sample with \"RainTomorrow\" = NaN, because this is predict_value\ndf = df.drop(df[df['RainTomorrow'].isna()].index)\ndf = df.reset_index(drop=True)\ndf = df.fillna(df.groupby('Location').transform('median'))\ndf = df.fillna(df.median())","9bac568d":"df_info(df, 'Rain in Australian')","c4623e52":"#List of categorical features with NaN\nfeatures_obj_with_NaN = [i for i in df.columns if (df[i].dtypes == 'object' and df[i].isnull().values.any())]\n#List of categorical features (delete  'Date' and 'RainTomorrow')\nfeatures_obj = [i for i in df.columns if df[i].dtypes == 'object']\nfeatures_obj.pop(0)\nfeatures_obj.pop()","933c6dd5":"# Replace NaN with the most popular word\nfor col in features_obj_with_NaN:\n#     print(col, '----')\n#     print(df[col].value_counts())\n    df[col] = df[col].fillna(df[col].value_counts().index[0])","71285f5f":"# Check!\ndf_info(df, 'Rain in Australian')","82b71aa1":"# Unbalanced data \nax = df['RainTomorrow'].value_counts().plot.bar(color= ['lightgreen', 'blue']);\n\nplt.title('Quantity of each class in the dataset', fontsize = 15)\nplt.xticks(rotation=0)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nfor i in ax.patches:\n    if i.get_height() == 110316:\n        ax.text(i.get_x() + 0.08, i.get_height()-10000, i.get_height(), fontsize=16,\n                    color='black')\n    else:\n        ax.text(i.get_x() + 0.1, i.get_height()-10000, i.get_height(), fontsize=16,\n                    color='white')\nax.set_xticklabels(['No rain','Rain!'])    \nplt.show()","0062418e":"# Date processing\ndf['Date'] = pd.to_datetime(df['Date'])\ndf['day'] = df['Date'].dt.day\ndf['month'] = df['Date'].dt.month\ndf['year'] = df['Date'].dt.year\ndf = df.drop(['Date'], axis=1)","62c92604":"# Processing of categorical features by the method 'One-Hot-Encoding'\ndf_cat = df[features_obj]\ndf = df.drop(features_obj, axis=1)\ndf_cat = pd.get_dummies(df_cat)\ndf[df_cat.columns] = df_cat","7ce5704e":"# split df into X and y \ny = df['RainTomorrow']\nX = df.drop(['RainTomorrow'], axis=  1)\ny = y.apply(lambda x : 1 if x == 'Yes' else 0)","9b1fbe96":"del df","313c077f":"#Standardize features\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X)\nX = scaler.transform(X)","ae866338":"# split X and y into training and testing sets\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=17)","c45e96f4":"# A function that outputs information: \"F1-score, ROC-AUC\"\nfrom sklearn.metrics import f1_score, accuracy_score, recall_score, classification_report, roc_auc_score  \ndef info_result(y_true, y_pred, model=None):\n    roc_auc = roc_auc_score(y_true, y_pred) \n    table = classification_report(y_true, y_pred)  \n    if model:\n        print(f'model :{model}')\n    print(f'ROC-AUC score: {roc_auc:.2%}')\n    print(table)\n    print('----')\n          ","aeca4881":"from sklearn.linear_model import SGDClassifier, LogisticRegression, RidgeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nmodels = [SGDClassifier(), \n          LogisticRegression(max_iter=200, n_jobs=-1, class_weight=\"balanced\"),\n          RidgeClassifier()]\nfor model in models:\n    \n    model.fit(X_train, y_train)\n    pred = model.predict(X_test)\n    info_result(y_test, pred, str(model))","deede369":"del models","d335f69c":"%%time\nfrom sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier()\nmodel.fit(X_train, y_train)\npred = model.predict(X_test)\ninfo_result(y_test, pred, str(model))","ef44017d":"#importing all libraries\nimport torch\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np \nimport math\nimport random\nimport torch.nn as nn\n#fix_random_state\nrandom.seed(17)\nnp.random.seed(17)\ntorch.manual_seed(17)\ntorch.cuda.manual_seed(17)","6bc6f9f3":"# Checking device: cuda or cpu\ntorch.cuda.is_available()\nprint(torch.cuda.get_device_name(0))\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice ","b13bb07a":"#cast to torchTensor\nX_train = torch.FloatTensor(X_train)\nX_test = torch.FloatTensor(X_test)\ny_train = torch.FloatTensor(y_train.values)\ny_test = torch.FloatTensor(y_test.values)\nX_test = X_test.to(device)","230e47f5":"# Let's create RainDataset with DataLoader\n\nclass AustralianRainDataset(Dataset):\n    def __init__(self):\n        self.x = X_train\n        self.y = y_train\n        self.n_samples = X_train.shape[0]\n        \n    def __getitem__(self, index):\n        return self.x[index], self.y[index]\n        \n    def __len__(self):\n        return self.n_samples","8c8cfa18":"dataset = AustralianRainDataset()\n# first_data = dataset[0]\n# x_sample, y_sample = first_data","6e7ae08f":"# Example\n# dataloader = DataLoader(dataset=dataset, batch_size = 4, shuffle= True)\n# dataiter = iter(dataloader)\n# data = dataiter.next()\n# features,labels = data \n# print(features,labels)","00ecf584":"#Create NetWork \nclass NeuralNetwork(nn.Module):\n    def __init__(self, first_neurons, n_hidden_neurons):\n        super().__init__()\n        self.fc1 = nn.Linear(first_neurons, n_hidden_neurons)\n        self.activ1 = nn.ReLU()\n        self.fc2 = nn.Linear(n_hidden_neurons, n_hidden_neurons)\n        self.activ2 = nn.ReLU()\n        self.fc3 = nn.Linear(n_hidden_neurons, 2)\n        \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.activ1(x)\n        x = self.fc2(x)\n        x = self.activ2(x)\n        x = self.fc3(x)\n        return x\n","4c11db27":"myNet = NeuralNetwork(114, 114)\nmyNet = myNet.to(device)\nmyNet.parameters()\n# list(myNet.parameters())\nloss = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(myNet.parameters(),  lr = 10 **(-4))","a8d980bf":"from sklearn.metrics import *\nacc_list = []\nf_1_list = []\nauc_list  = []\n\ndef training(model, batch_size, epochs, loss, optimizer):\n    global acc_list, f_1_list, auc_list    \n    for epoch in range(epochs):\n        dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n        for (X_batch,y_batch) in dataloader:\n            optimizer.zero_grad()\n            X_batch = X_batch.to(device)\n            y_batch = y_batch.to(device)\n\n            preds = model.forward(X_batch)\n            loss_value = loss(preds, y_batch.long())\n            loss_value.backward()\n            optimizer.step()\n\n        test_preds = model.forward(X_test)\n        pred  = test_preds.argmax(dim=1).to('cpu')\n        f1 = f1_score(y_test, pred)\n        auc_score = roc_auc_score(y_test, pred)\n        acc = accuracy_score(y_test, pred)\n        acc_list.append(acc)\n        f_1_list.append(f1)\n        auc_list.append(auc_score)\n        if (epoch + 1) % 5 == 0:\n            print(f'epoch: {epoch + 1}, acc:{acc:.2%}, f1:{f1:.2%}, auc: {auc_score:.2%}')\n","da56bed1":"%%time \nepoch = 100\nbatch_size = 400\ntraining(myNet, batch_size, epoch, loss, optimizer)","41eff53e":"acc_max = max(acc_list)\nf1_max = max(f_1_list)\nauc_max = max(auc_list)\nacc_list = np.array(acc_list) * 10000 \/\/ 1 \/ 100\nf_1_list = np.array(f_1_list) * 10000 \/\/ 1 \/ 100\nauc_list  = np.array(auc_list) * 10000 \/\/ 1 \/ 100","c38f548e":"plt.figure(figsize=(15, 5))\n\nplt.subplot(1,3,1)\nplt.title('Accuracy', fontsize = 15 );\nplt.grid(True)\nplt.xlabel('epoch', fontsize=14)\nplt.plot(acc_list, color='red', label = f'max_value:{acc_max:.2%}');\nplt.legend();\n\nplt.subplot(1,3,2)\nplt.title('AUC_score', fontsize = 15 );\nplt.grid(True)\nplt.xlabel('epoch', fontsize=14)\nplt.plot(auc_list , color='darkblue', label = f'max_value:{auc_max:.2%}');\nplt.legend();\n\nplt.subplot(1,3,3)\nplt.title('F1-score', fontsize = 15 );\nplt.grid(True)\nplt.xlabel('epoch', fontsize=14)\nplt.plot(f_1_list, color='darkorange', label = f'max_value:{f1_max:.2%}');\nplt.legend();","87f6512c":"# 1.Data processing","84efd6f0":"# 3. Random-forest","54f66941":"# 5. NeuralNetwork (Pytorch)","409d228a":"# 2. ML-models"}}