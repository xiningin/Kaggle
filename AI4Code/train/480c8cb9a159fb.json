{"cell_type":{"59b500ed":"code","c309701c":"code","06e0918a":"code","54ff7481":"code","299f0ad1":"code","34c6ae2d":"code","0e50936f":"code","795cfd36":"code","00849474":"code","79b0cc72":"code","4b5e94f6":"code","9feeb88a":"code","2e5e8027":"code","dc33d712":"markdown","fb5b28ef":"markdown","8edbb389":"markdown","46243818":"markdown","38a35e8d":"markdown","56a413f8":"markdown"},"source":{"59b500ed":"!pip install -q nnAudio\n!pip install -q timm","c309701c":"import os\nimport time\nimport math\nimport glob\nimport random\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport scipy as sp\nimport tensorflow as tf  # for reading TFRecord Dataset\nimport tensorflow_datasets as tfds  # for making tf.data.Dataset to return numpy arrays\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport timm\nfrom kaggle_datasets import KaggleDatasets\nfrom nnAudio.Spectrogram import CQT1992v2\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold\nfrom tqdm import tqdm","06e0918a":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","54ff7481":"class CFG:\n    debug = False\n    print_freq = 50\n    num_workers = 4\n    model_name = \"tf_efficientnet_b0_ns\"\n    qtransform_params = {\"sr\": 2048, \"fmin\": 20, \"fmax\": 1024, \"hop_length\": 24, \"bins_per_octave\": 12}\n    scheduler = \"CosineAnnealingLR\"\n    epochs = 3\n    T_max = 3\n    lr = 1e-4\n    min_lr = 1e-7\n    batch_size = 64\n    weight_decay = 1e-3\n    gradient_accumulation_steps = 1\n    max_grad_norm = 1000\n    seed = 42\n    target_size = 1\n    target_col = \"target\"\n    n_fold = 5\n    trn_fold = [0, 1, 2, 3, 4]\n    train = True\n\nif CFG.debug:\n    CFG.epochs = 1","299f0ad1":"def seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","34c6ae2d":"# ====================================================\n# Dataset\n# ====================================================\nclass TestDataset(torch.utils.data.Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['file_path'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def apply_transform(self, waves):\n        waves = waves \/ np.max(waves, axis=1)[:, None]\n        waves = torch.from_numpy(waves).float()\n        return waves\n\n    def __getitem__(self, idx):\n        file_path = self.file_names[idx]\n        waves = np.load(file_path)\n        image = self.apply_transform(waves)\n        image = image.squeeze().numpy()\n        if self.transform:\n            image = self.transform(image=image)['image']\n        return image # , label","0e50936f":"class CustomModel(nn.Module):\n    def __init__(self, cfg, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        self.wave_transform = CQT1992v2(**CFG.qtransform_params)\n        self.model = timm.create_model(self.cfg.model_name, pretrained=pretrained, in_chans=3)\n        self.n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(self.n_features, self.cfg.target_size)\n\n    def forward(self, x):\n        waves = []\n        for i in range(3):\n            waves.append(self.wave_transform(x[:, i]))\n        x = torch.stack(waves, dim=1)\n        output = self.model(x)\n        return output\n","795cfd36":"def get_test_file_path(image_id):\n    return \"..\/input\/g2net-gravitational-wave-detection\/test\/{}\/{}\/{}\/{}.npy\".format(\n        image_id[0], image_id[1], image_id[2], image_id)","00849474":"df_sub = pd.read_csv(\"..\/input\/g2net-gravitational-wave-detection\/sample_submission.csv\")\ndf_sub['file_path'] = df_sub['id'].apply(get_test_file_path)\n\ntest_dataset = TestDataset(df_sub)\ntest_loader = torch.utils.data.DataLoader(\n    test_dataset, \n    batch_size=512,\n    num_workers=CFG.num_workers, \n    shuffle=False,\n    pin_memory=True, \n    drop_last=False\n)\n\nbest_loss_models = [torch.load(state, map_location=device)[\"model\"] \n                    for state in sorted(glob.glob(\"..\/input\/g2net-read-from-tfrecord-train-with-pytorch\/*best_loss.pth\"))]\nbest_score_models = [torch.load(state, map_location=device)[\"model\"]\n                     for state in sorted(glob.glob(\"..\/input\/g2net-read-from-tfrecord-train-with-pytorch\/*best_score.pth\"))]\n\nbest_loss_model = CustomModel(CFG)\nbest_score_model = CustomModel(CFG)","79b0cc72":"def inference(model, states, data_loader, device):\n    \n    model.to(device)\n    tk0 = tqdm(enumerate(data_loader), total=len(data_loader))\n    probs = []\n    \n    for idx, images in tk0:\n        \n        images = images.to(device)\n        avg_preds = []\n        for state in states:\n            model.load_state_dict(state)\n            model.eval()\n            with torch.no_grad():\n                preds = model(images)\n            \n            avg_preds.append(preds.sigmoid().cpu().numpy())\n        \n        avg_preds = np.mean(avg_preds, axis=0)\n        probs.append(avg_preds)\n\n    probs = np.concatenate(probs)\n    return probs\n","4b5e94f6":"preds = inference(best_score_model, best_score_models, test_loader, device)\n# preds_2 = inference(best_loss_model, best_loss_models, test_loader, device)","9feeb88a":"df_sub[\"target\"] = preds\ndf_sub.drop([\"file_path\"], axis=1, inplace=True)\ndf_sub.to_csv(\"submission.csv\", index=False)","2e5e8027":"df_sub","dc33d712":"# Packages","fb5b28ef":"# CFG","8edbb389":"# About\n\nThis notebook is the inference part of [@hidehisaarai1213](https:\/\/www.kaggle.com\/hidehisaarai1213)'s [G2Net: Read from TFRecord & Train with PyTorch](https:\/\/www.kaggle.com\/hidehisaarai1213\/g2net-read-from-tfrecord-train-with-pytorch) notebook. It is also based on [@yasufuminakama](https:\/\/www.kaggle.com\/yasufuminakama)'s [G2Net \/ efficientnet_b7 \/ baseline [training]](https:\/\/www.kaggle.com\/yasufuminakama\/g2net-efficientnet-b7-baseline-training) notebook. \n\n\n**This code is based on again [@yasufuminakama](https:\/\/www.kaggle.com\/yasufuminakama)'s original [G2Net \/ efficientnet_b7 \/ baseline [inference]\n](https:\/\/www.kaggle.com\/yasufuminakama\/g2net-efficientnet-b7-baseline-inference) notebook.**\n\nPlease show your support to original authors as well!!!","46243818":"# Dataset","38a35e8d":"# Model","56a413f8":"# Inference"}}