{"cell_type":{"f17950d6":"code","6aa9ba1f":"code","9f988fe6":"code","c0cf38f1":"code","a74d29a7":"code","2b5aa354":"code","c1d1837d":"code","43feaf9d":"code","c80c80a9":"code","6899f3ff":"code","76762c50":"code","4f1e205e":"code","d7aab510":"code","4091e571":"code","31921098":"code","0016bbf6":"code","4fcfe59b":"code","defcc449":"code","b8e4bbd9":"code","2b97f9b8":"code","13a09507":"code","125e1ce3":"code","b65fcfd1":"code","fcd7f90a":"code","edada7f3":"code","3efa4617":"code","3b2d55e4":"code","f19338d2":"code","482fe815":"code","1cd4bea7":"code","cfcc7984":"code","8163ef9d":"code","91979df4":"code","16d76e58":"code","b311526d":"code","28a6b1a8":"code","6b6d9598":"code","2a6bbc28":"code","de348a18":"code","96e288cc":"code","70566d61":"code","514c6c31":"code","40069793":"code","124668d0":"code","6c68b504":"code","28ed171a":"code","ce071ab9":"code","498a2448":"code","f8bfbd6f":"code","a024f206":"code","87191365":"code","a3042187":"code","1646935c":"code","ad30e534":"code","503fdab9":"code","6bc8f19e":"code","7310b9ac":"code","c3d6977f":"code","107ced48":"code","cbfb394d":"code","4a2d1f8e":"code","c1136d48":"code","48eea880":"code","482ab955":"code","6925f5c4":"code","f4ea1474":"code","8a1594aa":"code","9ec2f703":"code","0643a2b7":"code","b1236e39":"code","1f95c4c4":"code","7946551a":"code","c08750a6":"code","cd15f1e9":"code","ba944bca":"code","c58eb7e0":"code","1b29c623":"code","f941f6f7":"code","0ff3e831":"code","4104ea1a":"code","963aa781":"code","38f5c1f2":"code","a27bb70d":"code","3097ee1c":"code","1fe5c341":"code","0c61455f":"code","3bc16f0a":"code","96a10570":"code","6465fec9":"code","fb1e335a":"code","c5d3658b":"code","021092d6":"code","04540908":"code","77f18679":"code","9527a656":"code","c74f8be6":"code","d84b550b":"code","012f145d":"code","5fb2b7d2":"code","3c77491f":"code","b684e1d0":"code","85d8b2c0":"code","5ef6d2f9":"code","89e0e508":"code","f022bc6c":"code","32bf6402":"code","1370f869":"code","bd8130f2":"code","42e5a233":"code","843df370":"code","0dd3dc50":"code","0da803e1":"code","1469a20e":"code","47ca0e6f":"code","814a5a52":"code","09121e01":"code","7713ce38":"code","79bc6884":"code","83295e75":"code","61b71255":"code","ca2a0377":"code","c9460030":"code","5c8399d2":"code","7a3935a6":"code","422d0d7b":"code","86d322d9":"code","350dfe48":"code","ba19c602":"code","53861625":"code","e279e943":"code","94eb74aa":"code","bae10d42":"code","e6b02a9c":"code","de2a09ff":"code","661a1161":"code","a10ff2cb":"code","b6bbe917":"code","ce35bd66":"code","8ac75b35":"code","afe5077f":"code","99aff0e2":"code","2e9b3f6d":"code","cd24818f":"code","27310cde":"code","d939ae96":"code","b4f0ed80":"code","eb63c867":"code","14a7c599":"code","d8cd14f0":"code","c29f6c92":"code","6c71cd6b":"code","45dbc6ac":"code","f7a22afe":"code","7af5806c":"code","c0013df7":"code","849078ae":"code","5ccd1f53":"code","e59e8870":"code","54980ec2":"code","6835fab5":"code","7ba82c84":"code","a74c5f84":"code","8599d6ae":"code","74a9d661":"code","9eebc383":"code","47b71980":"code","9a0127ce":"code","2d4d5bda":"code","0d0c3779":"code","2a39feec":"code","ed1d9827":"code","63a74ced":"code","189541e6":"code","342159c0":"code","1a39c6e2":"code","1fd26aaa":"code","ad857b47":"code","00310447":"code","b66f10bc":"markdown","9327d7ea":"markdown","6610b62a":"markdown","0fddc0b7":"markdown","a6da3ced":"markdown","63c04e2d":"markdown","c0494a38":"markdown","7ed7c5c5":"markdown","71909c98":"markdown","98a7f60d":"markdown","9561f562":"markdown"},"source":{"f17950d6":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","6aa9ba1f":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import r2_score","9f988fe6":"df = pd.read_csv(\"..\/input\/top-beer-information\/beer_data_set.csv\")","c0cf38f1":"df.drop(df.query('Description == \"error entering this description\"').index, inplace=True)","a74d29a7":"signs = { ord(x) : ' ' for x in ['.', ',', ':', ';', '-', '&', '!', \"'\",'\"', '\u2013', '\u2019', '\/', '\\\\', '(', ')', '\u201c', '\u201d', '\u2018', '?', '\\t'] }\ndf['Desc'] = df.Description.apply(lambda x: str.lower(x.translate(signs))[6:].replace('  ', ' ').replace('  ', ' ').replace('  ', ' '))","2b5aa354":"df.rename(columns={'Ave Rating': 'Rating'}, inplace=True)","c1d1837d":"vectorizer = CountVectorizer(max_features=200)\nlst = vectorizer.fit_transform(df.Desc).todense().tolist()\nlst2 = [sum(l) for l in lst]\ndf2 = df[np.array(lst2) > 0]","43feaf9d":"def perfect_split(X, y):\n  \"\"\"\n    X_train, X_test, X_val, y_train, y_test, y_val = perfect_split(X, y)\n  \"\"\"\n  X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=0.22, random_state=6437)\n  X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val, test_size=0.506, random_state=6154)\n  return X_train, X_test, X_val, y_train, y_test, y_val \n\ndef perfect_train_test_split(X, y):\n  \"\"\"\n    X_train, X_test_val, y_train, y_test_val = perfect_train_test_split(X, y)\n  \"\"\"\n  return train_test_split(X, y, test_size=0.22, random_state=6437)","c80c80a9":"def score_model(model, X, y, agr='variance_weighted'):\n  return r2_score(y, model.predict(X), multioutput=agr)\n\ndef my_r2_score(y_true, y_pred, agr='variance_weighted'):\n  return r2_score(y_true, y_pred, multioutput=agr)","6899f3ff":"## Basic Test Score ###\n\nvectorizer = CountVectorizer(max_features=140)\nX = vectorizer.fit_transform(df2.Desc).todense().tolist()\ncols = ['Astringency', 'Body', 'Alcohol', 'Bitter', 'Sweet', 'Sour', 'Salty', 'Hoppy', 'Spices', 'Malty']\ny = df2[cols]\n\nX_train, X_test_val, y_train, y_test_val = perfect_train_test_split(X, y)\nX_train, X_test, X_val, y_train, y_test, y_val = perfect_split(X, y)\n\nmodel = Ridge()\nmodel.fit(X_train, y_train)\nscore_model(model, X_test, y_test)","76762c50":"good_words = ['coffee', 'sour', 'chocolate', 'bourbon', 'hop', 'hops', 'barleywine', 'stout', 'berliner', 'butter', 'cinnamon', 'smoked', 'rye', 'wild', 'ipa', 'porter', 'tart', 'chile',\n              'brettanomyces','ginger', 'kvass', 'rice', 'gueuze', 'orange', 'honey', 'belgian', 'rolled', 'raspberries', 'malts', 'imperial', 'hopped', 'fruit', 'apple', 'hoppy', 'flanders',\n              'pilsner', 'lager', 'pale', 'black', 'chili', 'ibu', 'vanilla', 'spices', 'citrus', 'espresso', 'framboise', 'barrels', 'maple', 'light', 'malt', 'pumpkin', 'lambic', 'wheat',\n              'nibs', 'gose', 'whiskey', 'brandy', 'quadrupel', 'scotch', 'brown', 'regular', 'caramel', 'palehops', 'farmhouse', 'centennial', 'pluots', 'apricots', 'aged', 'rivertown', 'pine',\n              'brut', 'blackberries', 'fermented', 'adds', 'blond', 'cumin', 'clove', 'malty', 'blueberries', 'bock', 'milk', 'chipotle', 'spontaneous', 'nutty', 'tartness', 'doppelbock', 'double',\n              'crisp', 'roasters', 'gruit', 'forza', 'smoke', 'smokey', 'champagne', 'rum', 'fruity', 'serrano', 'salt', 'syrup', 'raisins', 'maturated', 'filtered', 'amarillo', 'bitter', 'libation',\n              'rich', 'bender', 'virtually', 'pepper', 'roses', 'full', 'dan', 'carmelized', 'baltic', 'oud', 'hopping', 'issued', 'gin', 'britain', 'duchesse', 'smokebeer', 'chocolatey', 'koshihikari',\n              'branches', 'smoky', 'choklat', 'bazaar', 'slide', 'sap', 'mac', 'floral', 'yuengling', 'lime', 'jalapenos', 'fermentation', 'printed', 'strong', 'tropical', 'vol', 'bakery', 'foudres',\n              'gusty', 'soured', 'feauring', 'cantillon', 'kaldi', 'rosemary', 'blondes', 'kumquats', 'christmas']","4f1e205e":"vectorizer = CountVectorizer(vocabulary=good_words)\nX = vectorizer.fit_transform(df2.Desc).todense().tolist()\n#X2 = [vec + [sum(vec)] for vec in X]\n\ncols = ['Astringency', 'Body', 'Alcohol', 'Bitter', 'Sweet', 'Sour', 'Salty', 'Hoppy', 'Spices', 'Malty']\ny = df2[cols]","d7aab510":"X_train, X_test_val, y_train, y_test_val = perfect_train_test_split(X, y)\nX_train, X_test, X_val, y_train, y_test, y_val = perfect_split(X, y)","4091e571":"import __main__\ndef pairplot(ser1, ser2, **kwargs):\n  sns.pairplot(pd.DataFrame(zip(__main__.__dict__[ser1], __main__.__dict__[ser2]), columns=[ser1, ser2]), **kwargs)\n  plt.show()","31921098":"import __main__\ndef print_err(y_pred_name, y_test, r=4, space=10):\n  print(f'{y_pred_name:{space}}{round(mean_squared_error(y_test, __main__.__dict__[y_pred_name], squared=False), r)}')\n\ndef r2(y_test, y_pred_name, r=4, space=10):\n  print(f'{y_pred_name:{space}}{round(r2_score(y_test, __main__.__dict__[y_pred_name]), r)}')","0016bbf6":"def round2(num): return round(num, 2)\ndef round3(num): return round(num, 3)\ndef round4(num): return round(num, 4)\ndef round5(num): return round(num, 5)\n\ndef print_round(num, r=4): print(round(num, r))\ndef print_round2(num, r=2): print(round(num, r))\ndef print_round3(num, r=3): print(round(num, r))\ndef print_round4(num, r=4): print(round(num, r))\ndef print_round5(num, r=5): print(round(num, r))","4fcfe59b":"def get_graph_min(x, y, r = 4):\n  best = min(y)\n  return [(x[0], round(x[1], r)) for x in zip(x, y) if x[1] == best][0]\n\ndef get_graph_max(x, y, r = 4):\n  best = max(y)\n  return [(x[0], round(x[1], r)) for x in zip(x, y) if x[1] == best][0]","defcc449":"def show_res(x, y):\n  sns.scatterplot(x=x, y=y)\n  plt.show()\n  res = get_graph_max(x=x, y=y)\n  print_round(res[1] - y[0])\n  print(res)","b8e4bbd9":"def combine_preds(pred1, pred2, a):\n  return a * np.array(pred2) + (1 - a) * np.array(pred1)","2b97f9b8":"def ForestOpt(pred_train, y_train, pred_test, dep=4, est=100, state=22):\n  X2, y2 = pred_train, y_train\n\n  model2 = RandomForestRegressor(max_depth=dep, n_estimators=est, random_state=state)\n  model2.fit(X2.reshape(-1, 1), y2)\n\n  return model2.predict(pred_test.reshape(-1, 1))","13a09507":"def Final_ForestOpt(pred_tr, y_train, pred):\n  pred3 = ForestOpt(pred_tr, y_train, pred, dep=3, est=40)\n  pred4 = ForestOpt(pred_tr, y_train, pred, dep=4, est=40)\n  a = 0.39\n  pred34 = a * pred4 + (1 - a) * pred3\n  return pred34","125e1ce3":"vectorizer = CountVectorizer()\nvectorizer.fit(df2.Desc)\n\nsum_words = vectorizer.transform(df.Desc).sum(axis=0)\nwords_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\nwords_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\nvocab = [x[0] for x in words_freq]\n\nprint(f'len(vocab) = {len(vocab)}')\nprint('\\nMost common words:')\nprint(vocab[:11])","b65fcfd1":"voc = vocab[:5000]\n\nnums = []\nscores = []\nscores_test = []\nv = [voc[0]]\n\nfor i in range(1, len(voc)):\n  curr = voc[i]\n  if curr in v: continue\n  vectorizer = CountVectorizer(vocabulary = v + [curr])\n  X = vectorizer.fit_transform(df2.Desc).todense().tolist()\n\n  X_train, X_test, y_train, y_test = perfect_train_test_split(X, y)\n  \n  model = Ridge()\n  model.fit(X_train, y_train)\n  score = model.score(X_train, y_train)\n  if len(scores) == 0 or score > scores[-1] + 0.002:\n      v.append(curr)\n      scores.append(score)\n      scores_test.append(model.score(X_test, y_test))\n      nums.append(i)","fcd7f90a":"sns.scatterplot(x=nums, y=scores)\nsns.scatterplot(x=nums, y=scores_test)\nplt.show()\nget_graph_max(x=nums, y=scores)","edada7f3":"cols = ['Astringency', 'Body', 'Alcohol', 'Bitter', 'Sweet', 'Sour', 'Salty', 'Hoppy', 'Spices', 'Malty']\ny = df2[cols]\nX_train, X_test_val, y_train, y_test_val = perfect_train_test_split(df2.Desc, y)","3efa4617":"def find_good_words(vocab, seed, min_improve = 0.002):\n  scores = []\n  v = seed[:]\n  vectorizer = CountVectorizer(vocabulary = v)\n  X = vectorizer.fit_transform(X_train).todense().tolist()\n  model = Ridge()\n  model.fit(X, y_train)\n  prev_score = r2_score(y_train, model.predict(X), multioutput='variance_weighted')\n\n  for i in range(len(vocab)):\n    if i % 100 == 0: print(i)\n    curr = vocab[i]\n    if curr in v: continue\n    vectorizer = CountVectorizer(vocabulary = v + [curr])\n    X = vectorizer.fit_transform(X_train).todense().tolist()\n    model = Ridge()\n    model.fit(X, y_train)\n    score = r2_score(y_train, model.predict(X), multioutput='variance_weighted')\n    if score > prev_score + min_improve:\n        v.append(curr)\n        scores.append((score, score - prev_score, curr, i))\n        prev_score = score\n        \n  return scores  ","3b2d55e4":"def find_good_words2(vocab, seed):\n  scores = []\n  v = seed[:]\n  vectorizer = CountVectorizer(vocabulary = v)\n  X = vectorizer.fit_transform(X_train).todense().tolist()\n  X2 = [vec + [sum(vec)] for vec in X]\n  model = Ridge()\n  model.fit(X2, y_train)\n  base_score = r2_score(y_train, model.predict(X2), multioutput='variance_weighted')\n\n  for i in range(len(vocab)):\n    if i % 100 == 0: print(i)\n    curr = vocab[i]\n    if curr in v: continue\n    vectorizer = CountVectorizer(vocabulary = v + [curr])\n    X = vectorizer.fit_transform(X_train).todense().tolist()\n    X2 = [vec + [sum(vec)] for vec in X]\n    model = Ridge()\n    model.fit(X2, y_train)\n    score = r2_score(y_train, model.predict(X2), multioutput='variance_weighted')\n    scores.append((score, score - base_score, curr, i))\n        \n  return scores  ","f19338d2":"def visualize_res(res):\n  sns.scatterplot(x=[x[3] for x in res], y=[x[0] for x in res])\n  plt.show()\n\n  sns.displot([x[1] for x in res], bins=50)\n  plt.show()","482fe815":"def print_res(res, r=5, space1=9, space2=5, head=100):\n  for x in list([(round(x[1], r), x[3], x[2]) for x in sorted(res, key=lambda x: -x[1])])[:head]:\n    print(f'{x[0]:<{space1}} {x[1]:<{space2}} {x[2]}')\n\ndef print_res2(res, r=5, space1=9, space2=5, head=100):\n  i = 0\n  for x in list([(round(x[1], r), x[3], x[2]) for x in sorted(res, key=lambda x: -x[1])])[:head]:\n    print(f'{i:<3} {x[0]:<{space1}} {x[1]:<{space2}} {x[2]}')\n    i = i+1","1cd4bea7":"res0 = find_good_words(vocab[:100], [''])","cfcc7984":"visualize_res(res0)","8163ef9d":"for x in list([(round3(x[1]), x[3], x[2]) for x in sorted(res0, key=lambda x: -x[1])]):\n  print(f'{x[0]:<7} {x[1]:<4} {x[2]}')","91979df4":"seed0 = [x[2] for x in sorted(res0, key=lambda x: -x[1])][:7]\nseed0","16d76e58":"res1 = find_good_words(vocab[:1000], seed0, 0.005)","b311526d":"print_res(res1)","28a6b1a8":"seed1 = [x[2] for x in sorted(res1, key=lambda x: -x[1])][1:5]\nseed1","6b6d9598":"res2 = find_good_words(vocab[:2000], seed0 + seed1, 0.002)","2a6bbc28":"visualize_res(res2[1:])","de348a18":"print_res(res2, 4)","96e288cc":"seed2 = [x[2] for x in sorted(res2, key=lambda x: -x[1])][1:10]\nseed2","70566d61":"res3 = find_good_words(vocab[:1000], seed0 + seed1 + seed2, 0.002)","514c6c31":"[x[2] for x in sorted(res2, key=lambda x: -x[1])][10:20]","40069793":"print_res(res3, 5, 9, 5)","124668d0":"visualize_res(res3[1:])","6c68b504":"seed3 = [x[2] for x in sorted(res3, key=lambda x: -x[1])][1:28]\nseed3","28ed171a":"res4 = find_good_words(vocab[1:2000], seed0 + seed1 + seed2 + seed3, 0.002)","ce071ab9":"print_res(res4, 5)","498a2448":"seed4 = [x[2] for x in sorted(res4, key=lambda x: -x[1])][1:5]\nseed4","f8bfbd6f":"len(seed0 + seed1 + seed2 + seed3 + seed4)","a024f206":"scores = []\nv = (seed0 + seed1 + seed2 + seed3 + seed4)[:]\nvectorizer = CountVectorizer(vocabulary = v)\nX = vectorizer.fit_transform(X_train).todense().tolist()\nmodel = Ridge()\nmodel.fit(X, y_train)\nbase_score = r2_score(y_train, model.predict(X), multioutput='variance_weighted')\n\nfor curr in v:\n  vectorizer = CountVectorizer(vocabulary = [x for x in v if x != curr])\n  X = vectorizer.fit_transform(X_train).todense().tolist()\n  model = Ridge()\n  model.fit(X, y_train)\n  score = r2_score(y_train, model.predict(X), multioutput='variance_weighted')\n  scores.append((score, base_score - score, curr))","87191365":"sns.displot([(round(x[1], 5)) for x in sorted(scores, key=lambda x: -x[1])][20:], bins=40)","a3042187":"[(round(x[1], 5), x[2]) for x in sorted(scores, key=lambda x: -x[1])]","1646935c":"seed5 = [x[2] for x in sorted(scores, key=lambda x: -x[1])][:45]\nseed5","ad30e534":"res6 = find_good_words(vocab[0:1000], seed5, 0.002)","503fdab9":"print_res(res6)","6bc8f19e":"seed6 = [x[2] for x in sorted(res6, key=lambda x: -x[1])][:5]\nseed6","7310b9ac":"res7 = find_good_words(vocab[:2000], seed5 + seed6, 0.0015)","c3d6977f":"print_res(res7)","107ced48":"visualize_res(res7)","cbfb394d":"seed7 = [x[2] for x in sorted(res7, key=lambda x: -x[1])][:14]\nseed7","4a2d1f8e":"res8 = find_good_words(vocab[:5000], seed5 + seed6 + seed7, 0.0012)","c1136d48":"print_res(res8)","48eea880":"visualize_res(res8)","482ab955":"seed8 = [x[2] for x in sorted(res8, key=lambda x: -x[1])][:18]\nseed8","6925f5c4":"len(seed5 + seed6 + seed7 + seed8)","f4ea1474":"scores = []\nv = (seed5 + seed6 + seed7 + seed8)[:]\nvectorizer = CountVectorizer(vocabulary = v)\nX = vectorizer.fit_transform(X_train).todense().tolist()\nmodel = Ridge()\nmodel.fit(X, y_train)\nbase_score = r2_score(y_train, model.predict(X), multioutput='variance_weighted')\n\nfor curr in v:\n  vectorizer = CountVectorizer(vocabulary = [x for x in v if x != curr])\n  X = vectorizer.fit_transform(X_train).todense().tolist()\n  model = Ridge()\n  model.fit(X, y_train)\n  score = r2_score(y_train, model.predict(X), multioutput='variance_weighted')\n  scores.append((score, base_score - score, curr))","8a1594aa":"sns.displot([(round(x[1], 5)) for x in sorted(scores, key=lambda x: -x[1])][60:], bins=40)","9ec2f703":"[(round(x[1], 5), x[2]) for x in sorted(scores, key=lambda x: -x[1])]","0643a2b7":"res9 = find_good_words(vocab[:10000], seed5 + seed6 + seed7 + seed8, 0.001)","b1236e39":"print_res(res9)","1f95c4c4":"visualize_res(res9)","7946551a":"seed9 = [x[2] for x in sorted(res9, key=lambda x: -x[1])]\nseed9","c08750a6":"len(seed5 + seed6 + seed7 + seed8 + seed9)","cd15f1e9":"scores = []\nv = (seed5 + seed6 + seed7 + seed8 + seed9)[:]\nvectorizer = CountVectorizer(vocabulary = v)\nX = vectorizer.fit_transform(X_train).todense().tolist()\nX2 = [vec + [sum(vec)] for vec in X]\nmodel = Ridge()\nmodel.fit(X2, y_train)\nbase_score = r2_score(y_train, model.predict(X2), multioutput='variance_weighted')\nfor curr in v:\n  vectorizer = CountVectorizer(vocabulary = [x for x in v if x != curr])\n  X = vectorizer.fit_transform(X_train).todense().tolist()\n  X2 = [vec + [sum(vec)] for vec in X]\n  model = Ridge()\n  model.fit(X2, y_train)\n  score = r2_score(y_train, model.predict(X2), multioutput='variance_weighted')\n  scores.append((score, base_score - score, curr))","ba944bca":"sns.displot([(round(x[1], 5)) for x in sorted(scores, key=lambda x: -x[1])][90:], bins=40)","c58eb7e0":"[(round(x[1], 5), x[2]) for x in sorted(scores, key=lambda x: -x[1])]","1b29c623":"seed10 = [x[2] for x in sorted(scores, key=lambda x: -x[1])][:103]\nseed10","f941f6f7":"len(seed10)","0ff3e831":"seed10 = ['coffee', 'sour', 'chocolate', 'bourbon', 'hops', 'berliner', 'hop', 'butter', 'barleywine', 'cinnamon', 'smoked', 'stout', 'rice', 'spices', 'ipa', 'wild', 'brettanomyces', 'ginger', 'tart', 'citrus', 'porter', 'rye', 'gueuze', 'pale', 'lager', 'rolled', 'maple', 'hopped', 'ibu', 'malts', 'kvass', 'brut', 'pilsner', 'raspberries', 'barrels', 'black', 'imperial', 'regular', 'nibs', 'light', 'belgian', 'gose', 'whiskey', 'hoppy', 'scotch', 'caramel', 'honey', 'chile', 'fermented', 'aged', 'centennial', 'rivertown', 'vanilla', 'brown', 'bock', 'smoky', 'milk', 'raisins', 'espresso', 'framboise', 'blackberries', 'flanders', 'smokey', 'libation', 'apricots', 'blueberries', 'clove', 'doppelbock', 'malt', 'apple', 'adds', 'koshihikari', 'orange', 'fruit', 'peppers', 'wheat', 'rich', 'strong', 'quadrupel', 'roses', 'pluots', 'fermentation', 'farmhouse', 'lambic', 'pine', 'rum', 'forza', 'chili', 'cumin', 'brandy', 'dan', 'maturated', 'rosemary', 'tropical', 'spontaneous', 'foraged', 'oud', 'bitter', 'filtered', 'lime', 'britain', 'cherries', 'pepper']","4104ea1a":"res11 = find_good_words2(vocab, seed10)","963aa781":"print_res(res11, head=200)","38f5c1f2":"[x[2] for x in sorted(res11, key=lambda x: -x[1])][:200]","a27bb70d":"visualize_res(res11)","3097ee1c":"[(round5(x[1]), x[3], x[2]) for x in sorted(res11, key=lambda x: -x[1])][:20]","1fe5c341":"sns.displot([x[1] for x in sorted(res11, key=lambda x: -x[1])][:200], bins=50)","0c61455f":"len([x[1] for x in sorted(res11, key=lambda x: -x[1]) if x[1] > 0.0006])","3bc16f0a":"vocab2 = [x[2] for x in sorted(res11, key=lambda x: -x[1])]\nlen(vocab2)","96a10570":"scores = []\nv = seed10[:]\nvectorizer = CountVectorizer(vocabulary = v)\nX = vectorizer.fit_transform(X_train).todense().tolist()\nX2 = [vec + [sum(vec)] for vec in X]\nmodel = Ridge()\nmodel.fit(X2, y_train)\nprev_score = r2_score(y_train, model.predict(X2), multioutput='variance_weighted')\n\nX_tv = vectorizer.fit_transform(X_test_val).todense().tolist()\nX_test_val2 = [vec + [sum(vec)] for vec in X_tv]\nprev_score2 = r2_score(y_test_val, model.predict(X_test_val2), multioutput='variance_weighted')\n\nfor i in range(len(vocab2[:3000])):\n  if i % 100 == 0: print(i)\n  curr = vocab[i]\n  if curr in v: continue\n  vectorizer = CountVectorizer(vocabulary = v + [curr])\n  X = vectorizer.fit_transform(X_train).todense().tolist()\n  X2 = [vec + [sum(vec)] for vec in X]\n  model = Ridge()\n  model.fit(X2, y_train)\n  score = r2_score(y_train, model.predict(X2), multioutput='variance_weighted')\n  \n  X_tv = vectorizer.fit_transform(X_test_val).todense().tolist()\n  X_test_val2 = [vec + [sum(vec)] for vec in X_tv]\n  score2 = r2_score(y_test_val, model.predict(X_test_val2), multioutput='variance_weighted')\n\n  if score > prev_score + 0.00025:\n      v.append(curr)\n      scores.append((score, score - prev_score, curr, i, score2, score2 - prev_score2))\n      prev_score = score\n      prev_score2 = score2","6465fec9":"def find_good_words3(vocab, seed, min_improve = 0.002):\n  scores = []\n  v = seed[:]\n  vectorizer = CountVectorizer(vocabulary = v)\n  X = vectorizer.fit_transform(X_train).todense().tolist()\n  X2 = [vec + [sum(vec)] for vec in X]\n  model = Ridge()\n  model.fit(X2, y_train)\n  prev_score = r2_score(y_train, model.predict(X2), multioutput='variance_weighted')\n\n  X_tv = vectorizer.fit_transform(X_test_val).todense().tolist()\n  X_test_val2 = [vec + [sum(vec)] for vec in X_tv]\n  prev_score2 = r2_score(y_test_val, model.predict(X_test_val2), multioutput='variance_weighted')\n\n  for i in range(len(vocab)):\n    if i % 100 == 0: print(i)\n    curr = vocab[i]\n    if curr in v: continue\n    vectorizer = CountVectorizer(vocabulary = v + [curr])\n    X = vectorizer.fit_transform(X_train).todense().tolist()\n    X2 = [vec + [sum(vec)] for vec in X]\n    model = Ridge()\n    model.fit(X2, y_train)\n    score = r2_score(y_train, model.predict(X2), multioutput='variance_weighted')\n    \n    X_tv = vectorizer.fit_transform(X_test_val).todense().tolist()\n    X_test_val2 = [vec + [sum(vec)] for vec in X_tv]\n    score2 = r2_score(y_test_val, model.predict(X_test_val2), multioutput='variance_weighted')\n\n    if score > prev_score + min_improve:\n        v.append(curr)\n        scores.append((score, score - prev_score, curr, i, score2, score2 - prev_score2))\n        prev_score = score\n        prev_score2 = score2\n\n  return scores","fb1e335a":"l, r = 0, 300\n\nsns.scatterplot(x=range(l, r), y=[x[4] for x in scores][l:r])\nplt.show()\n\nsns.scatterplot(x=[x[3] for x in scores][l:r], y=[x[0] for x in scores][l:r])\nsns.scatterplot(x=[x[3] for x in scores][l:r], y=[x[4] for x in scores][l:r])\nplt.show()\n\nsns.scatterplot(x=range(l, r), y=[x[0] for x in scores][l:r])\nsns.scatterplot(x=range(l, r), y=[x[4] for x in scores][l:r])\nplt.show()\n\nsns.scatterplot(x=[x[3] for x in scores][l:r], y=[x[1] for x in scores][l:r])\nsns.scatterplot(x=[x[3] for x in scores][l:r], y=[x[5] for x in scores][l:r])\nplt.show()","c5d3658b":"visualize_res(scores)","021092d6":"print_res(scores, head=10)","04540908":"res12 = find_good_words3(vocab2[:1000], seed10, 0.00055)","77f18679":"print_res(res12)","9527a656":"len(res12)","c74f8be6":"visualize_res(res12)","d84b550b":"len(res12)","012f145d":"l, r = 0, 113\n\nsns.scatterplot(x=range(l, r), y=[x[4] for x in res12][l:r])\nplt.show()\n\nsns.scatterplot(x=[x[3] for x in res12][l:r], y=[x[4] for x in res12][l:r])\nplt.show()\n\nsns.scatterplot(x=[x[3] for x in res12][l:r], y=[x[5] for x in res12][l:r])\nplt.hlines(y=0, xmin=0, xmax=200, colors=['red'])\nplt.show()\n\nsns.scatterplot(x=[x[3] for x in res12][l:r], y=[x[0] for x in res12][l:r])\nsns.scatterplot(x=[x[3] for x in res12][l:r], y=[x[4] for x in res12][l:r])\nplt.show()\n\nsns.scatterplot(x=range(l, r), y=[x[0] for x in res12][l:r])\nsns.scatterplot(x=range(l, r), y=[x[4] for x in res12][l:r])\nplt.show()\n\nsns.scatterplot(x=[x[3] for x in res12][l:r], y=[x[1] for x in res12][l:r])\nsns.scatterplot(x=[x[3] for x in res12][l:r], y=[x[5] for x in res12][l:r])\nplt.show()","5fb2b7d2":"res13 = find_good_words3(vocab2[:1000], seed10, 0.00055)","3c77491f":"visualize_res(res13)","b684e1d0":"sns.displot(sorted([x[1] for x in res13], reverse=True)[70:], bins = 50, height=5)","85d8b2c0":"plt.plot(sorted([x[1] for x in res13], reverse=True))","5ef6d2f9":"len(res13)","89e0e508":"l, r = 0, 130\n\nsns.scatterplot(x=range(l, r), y=[x[4] for x in res13][l:r])\nplt.show()\n\nsns.scatterplot(x=[x[3] for x in res13][l:r], y=[x[4] for x in res13][l:r])\nplt.show()\n\nsns.scatterplot(x=[x[3] for x in res13][l:r], y=[x[5] for x in res13][l:r])\nplt.hlines(y=0, xmin=0, xmax=1000, colors=['red'])\nplt.show()\n\nsns.scatterplot(x=[x[3] for x in res13][l:r], y=[x[0] for x in res13][l:r])\nsns.scatterplot(x=[x[3] for x in res13][l:r], y=[x[4] for x in res13][l:r])\nplt.show()\n\nsns.scatterplot(x=range(l, r), y=[x[0] for x in res13][l:r])\nsns.scatterplot(x=range(l, r), y=[x[4] for x in res13][l:r])\nplt.show()\n\nsns.scatterplot(x=[x[3] for x in res13][l:r], y=[x[1] for x in res13][l:r])\nsns.scatterplot(x=[x[3] for x in res13][l:r], y=[x[5] for x in res13][l:r])\nplt.show()","f022bc6c":"print_res2(res13)","32bf6402":"seed11 = [x[2] for x in sorted(res13, key=lambda x: -x[1])][:57]\nseed11","1370f869":"len(set(seed10 + seed11))","bd8130f2":"scores = []\nv = (seed10 + seed11)[:]\nvectorizer = CountVectorizer(vocabulary = v)\nX = vectorizer.fit_transform(X_train).todense().tolist()\nX2 = [vec + [sum(vec)] for vec in X]\nmodel = Ridge()\nmodel.fit(X2, y_train)\nbase_score = r2_score(y_train, model.predict(X2), multioutput='variance_weighted')\n\nfor curr in v:\n  vectorizer = CountVectorizer(vocabulary = [x for x in v if x != curr])\n  X = vectorizer.fit_transform(X_train).todense().tolist()\n  X2 = [vec + [sum(vec)] for vec in X]\n  model = Ridge()\n  model.fit(X2, y_train)\n  score = r2_score(y_train, model.predict(X2), multioutput='variance_weighted')\n  scores.append((score, base_score - score, curr))","42e5a233":"plt.plot([x[1] for x in scores[:]])","843df370":"sns.displot([(round(x[1], 5)) for x in sorted(scores, key=lambda x: -x[1])][100:], bins=40)","0dd3dc50":"[(round(x[1], 5), x[2]) for x in sorted(scores, key=lambda x: -x[1])]","0da803e1":"seed12 = [x[2] for x in sorted(scores, key=lambda x: -x[1])][:-2]\nseed12","1469a20e":"len(seed12)","47ca0e6f":"res14 = find_good_words3(vocab2[:300], seed12, 0.00064)","814a5a52":"print_res2(res14, r=6)","09121e01":"plt.plot([x[4] for x in res14])\nplt.show()\n\nplt.plot([x[5] for x in res14])\nplt.plot([x[1] for x in res14])\nplt.hlines(y=0, xmin=0, xmax=30, colors=['red'])\nplt.show()","7713ce38":"seed13 = [x[2] for x in sorted(res14, key=lambda x: -x[1])][:4]","79bc6884":"len(seed12+seed13)","83295e75":"scores = []\nv = (seed12 + seed13)[:]\nvectorizer = CountVectorizer(vocabulary = v)\nX = vectorizer.fit_transform(X_train).todense().tolist()\nX2 = [vec + [sum(vec)] for vec in X]\nmodel = Ridge()\nmodel.fit(X2, y_train)\nbase_score = r2_score(y_train, model.predict(X2), multioutput='variance_weighted')\n\nX_tv = vectorizer.fit_transform(X_test_val).todense().tolist()\nX_test_val2 = [vec + [sum(vec)] for vec in X_tv]\nbase_score2 = r2_score(y_test_val, model.predict(X_test_val2), multioutput='variance_weighted')\n\nfor curr in v:\n  vectorizer = CountVectorizer(vocabulary = [x for x in v if x != curr])\n  X = vectorizer.fit_transform(X_train).todense().tolist()\n  X2 = [vec + [sum(vec)] for vec in X]\n  model = Ridge()\n  model.fit(X2, y_train)\n  score = r2_score(y_train, model.predict(X2), multioutput='variance_weighted')\n\n  X_tv = vectorizer.fit_transform(X_test_val).todense().tolist()\n  X_test_val2 = [vec + [sum(vec)] for vec in X_tv]\n  score2 = r2_score(y_test_val, model.predict(X_test_val2), multioutput='variance_weighted')\n  scores.append((score, base_score - score, curr, score2, base_score2 - score2))","61b71255":"plt.plot([x[0] for x in scores])\nplt.show()\n\nplt.plot([x[1] for x in scores])\nplt.show()\n\nplt.plot([x[4] for x in scores])\nplt.hlines(y=0, xmin=0, xmax=160, colors=['red'])\nplt.show()\n\nplt.plot([x[4] for x in scores])\nplt.plot([x[1] for x in scores])\nplt.hlines(y=0, xmin=0, xmax=160, colors=['red'])\nplt.show()","ca2a0377":"def print_res3(res, r=5, space1=9, space2=5, head=100):\n  i = 0\n  for x in list([(round(x[1], r), x[3], x[2]) for x in sorted(res, key=lambda x: -x[1])])[:head]:\n    print(f'{i:<3} {x[0]:<{space1}} {x[1]:<{space2}} {x[2]}')\n    i = i+1","c9460030":"for x in list([(round5(x[1]), round5(x[4]), x[2]) for x in sorted(scores, key=lambda x: -x[1])]):\n  print(f'{x[0]:<9} {x[1]:<9} {x[2]}')","5c8399d2":"seed14 = [x[2] for x in sorted(scores, key=lambda x: -x[1])][:-2]\nseed14","7a3935a6":"len(seed14)","422d0d7b":"scores = []\nv = (seed14)[:]\nvectorizer = CountVectorizer(vocabulary = v)\nX = vectorizer.fit_transform(df2.Desc).todense().tolist()\nX2 = [vec + [sum(vec)] for vec in X]\nmodel = Ridge()\nmodel.fit(X2, y)\nbase_score = r2_score(y, model.predict(X2), multioutput='variance_weighted')\n\nfor curr in v:\n  vectorizer = CountVectorizer(vocabulary = [x for x in v if x != curr])\n  X = vectorizer.fit_transform(df2.Desc).todense().tolist()\n  X2 = [vec + [sum(vec)] for vec in X]\n  model = Ridge()\n  model.fit(X2, y)\n  score = r2_score(y, model.predict(X2), multioutput='variance_weighted')\n  scores.append((score, base_score - score, curr))","86d322d9":"for x in list([(round5(x[1]), x[2]) for x in sorted(scores, key=lambda x: -x[1])]):\n  print(f'{x[0]:<9} {x[1]}')","350dfe48":"good_words = [x[2] for x in sorted(scores, key=lambda x: -x[1])][:150]\ngood_words","ba19c602":"alphas, scores, scores2 = [], [], []\n\nfor i in range(40):\n  a = i\n  model = Ridge(alpha=a)\n  model.fit(X_train, y_train)\n\n  alphas.append(a)\n  scores.append(r2_score(y_train, model.predict(X_train), multioutput='variance_weighted'))\n  scores2.append(r2_score(y_val, model.predict(X_val), multioutput='variance_weighted'))\n\nshow_res(alphas, scores)\nshow_res(alphas, scores2)","53861625":"alphas, scores, scores2 = [], [], []\n\nfor i in range(200):\n  a = i \/ 10\n  model = Ridge(alpha=a)\n  model.fit(X_train, y_train)\n\n  alphas.append(a)\n  scores.append(r2_score(y_train, model.predict(X_train), multioutput='variance_weighted'))\n  scores2.append(r2_score(y_val, model.predict(X_val), multioutput='variance_weighted'))\n\nshow_res(alphas, scores)\nshow_res(alphas, scores2)","e279e943":"model = Ridge(alpha=0)\nmodel.fit(X, y)\nr2_score(y, model.predict(X), multioutput='variance_weighted')","94eb74aa":"sorted(list(zip([int(sum(np.abs(x))) for x in model.coef_.T], good_words)), key = lambda x: -x[0])[:10]","bae10d42":"sorted(list(zip([int(sum(np.abs(x))) for x in model.coef_.T], good_words)), key = lambda x: x[0])[:10]","e6b02a9c":"lst = [next(i for i, x in enumerate(good_words) if x == word) for word in [x[1] for x in sorted(list(zip([int(sum(np.abs(x))) for x in model.coef_.T], good_words)), key = lambda x: -x[0])]]\nplt.plot(lst)\nsns.regplot(x=np.array(range(150)), y=lst)\nplt.show()\nprint(f'\\nCorr: {round3(pd.Series(range(150)).corr(pd.Series(lst)))}')","de2a09ff":"model = Ridge(alpha=11.8)\nmodel.fit(X, y)\nr2_score(y, model.predict(X), multioutput='variance_weighted')","661a1161":"lst = [next(i for i, x in enumerate(good_words) if x == word) for word in [x[1] for x in sorted(list(zip([int(sum(np.abs(x))) for x in model.coef_.T], good_words)), key = lambda x: -x[0])]]\nplt.plot(lst)\nsns.regplot(x=np.array(range(150)), y=lst)\nplt.show()\nprint(f'\\nCorr: {round3(pd.Series(range(150)).corr(pd.Series(lst)))}')","a10ff2cb":"sorted(list(zip([int(sum(np.abs(x))) for x in model.coef_.T], good_words)), key = lambda x: -x[0])[:10]","b6bbe917":"sorted(list(zip([int(sum(np.abs(x))) for x in model.coef_.T], good_words)), key = lambda x: x[0])[:10]","ce35bd66":"print('Zero vectors count:')\nprint(f'{len([x for x in [sum(vec) for vec in X] if x == 0])} \/ {len(X)}')\n\nprint('\\nMean y of them:')\nprint_round(np.mean([np.mean(x[1]) for x in [(sum(vec[0]), vec[1]) for vec in zip(X, y.values.tolist())] if x[0] == 0]))\n\nprint('\\nIntercept (pred of them):')\nprint_round(np.mean(model.intercept_))","8ac75b35":"sums = [sum(vec) for vec in X]\nsums = np.array(sums)\nsns.displot(sums, bins=25, height=4)\nplt.show()","afe5077f":"def ForestOpt(pred_train, y_train, pred_test, dep=4, est=10, state=22):\n  X2, y2 = pred_train, y_train\n\n  model2 = RandomForestRegressor(max_depth=dep, n_estimators=est, random_state=state)\n  model2.fit(X2.reshape(-1, y_train.shape[1]), y2)\n\n  return model2.predict(pred_test.reshape(-1, y_train.shape[1]))","99aff0e2":"model = Ridge()\nmodel.fit(X_train, y_train)\nscore_model(model, X_test, y_test)","2e9b3f6d":"pred_tr = model.predict(X_train)\npred_val = model.predict(X_val)\npred_test = model.predict(X_test)","cd24818f":"pred = pred_val\npred2 = ForestOpt(pred_tr, y_train, pred, dep=12, est=200)\n\nprint_round(my_r2_score(y_val, pred))\nprint_round(my_r2_score(y_val, pred2))","27310cde":"pred = pred_val\ndeps, scores = [], []\n\nfor i in range(1, 20):\n  pred2 = ForestOpt(pred_tr, y_train, pred, dep=i, est=40)\n  deps.append(i)\n  scores.append(my_r2_score(y_val, pred2))\n  \nshow_res(deps, scores)","d939ae96":"pred = pred_val\ndeps, scores = [], []\n\nfor i in range(10, 100, 10):\n  pred2 = ForestOpt(pred_tr, y_train, pred, dep=8, est=i)\n  deps.append(i)\n  scores.append(my_r2_score(y_val, pred2))\n  \nshow_res(deps, scores)","b4f0ed80":"pred = pred_val\ndeps, scores = [], []\n\nfor i in range(30, 60):\n  pred2 = ForestOpt(pred_tr, y_train, pred, dep=8, est=i)\n  deps.append(i)\n  scores.append(my_r2_score(y_val, pred2))\n  \nshow_res(deps, scores)","eb63c867":"pred = pred_val\ndeps, scores = [], []\n\nfor i in range(350):\n  if i % 100 == 0: print(i)\n  pred2 = ForestOpt(pred_tr, y_train, pred, dep=8, est=38, state=i)\n  deps.append(i)\n  scores.append(my_r2_score(y_val, pred2))\n  \nshow_res(deps, scores)","14a7c599":"pred = pred_val\ndeps, scores = [], []\n\nfor i in range(30, 60):\n  pred2 = ForestOpt(pred_tr, y_train, pred, dep=9, est=i)\n  deps.append(i)\n  scores.append(my_r2_score(y_val, pred2))\n  \nshow_res(deps, scores)","d8cd14f0":"pred = pred_val\ndeps, scores = [], []\n\nfor i in range(100):\n  if i % 10 == 0: print(i)\n  pred2 = ForestOpt(pred_tr, y_train, pred, dep=9, est=38, state=i)\n  deps.append(i)\n  scores.append(my_r2_score(y_val, pred2))\n  \nshow_res(deps, scores)","c29f6c92":"pred = pred_val\ndeps, scores = [], []\n\nfor i in range(30, 60):\n  pred2 = ForestOpt(pred_tr, y_train, pred, dep=10, est=i, state=8)\n  deps.append(i)\n  scores.append(my_r2_score(y_val, pred2))\n  \nshow_res(deps, scores)","6c71cd6b":"pred = pred_val\ndeps, scores = [], []\n\nfor i in range(100):\n  if i % 10 == 0: print(i)\n  pred2 = ForestOpt(pred_tr, y_train, pred, dep=10, est=49, state=i)\n  deps.append(i)\n  scores.append(my_r2_score(y_val, pred2))\n  \nshow_res(deps, scores)","45dbc6ac":"pred1 = ForestOpt(pred_tr, y_train, pred, dep=9, est=38, state=54)\npred2 = ForestOpt(pred_tr, y_train, pred, dep=10, est=49, state=8)\n\nalphas, scores = [], []\n\nfor i in range(100):\n  a = i \/ 100\n  pred12 = combine_preds(pred1, pred2, a)\n  scores.append(my_r2_score(y_val, pred12))\n  alphas.append(i)\n  \nshow_res(alphas, scores)","f7a22afe":"model = Ridge(alpha=11.8)\nmodel.fit(X_train, y_train)\nscore_model(model, X_test, y_test)","7af5806c":"pred_tr = model.predict(X_train)\npred_val = model.predict(X_val)\npred_test = model.predict(X_test)\n\npred = pred_val","c0013df7":"pred1 = ForestOpt(pred_tr, y_train, pred, dep=9, est=38, state=54)\npred2 = ForestOpt(pred_tr, y_train, pred, dep=10, est=49, state=8)\n\nalphas, scores = [], []\n\nfor i in range(100):\n  a = i \/ 100\n  pred12 = combine_preds(pred1, pred2, a)\n  scores.append(my_r2_score(y_val, pred12))\n  alphas.append(i)\n  \nshow_res(alphas, scores)","849078ae":"X_train, X_test_val, y_train, y_test_val = perfect_train_test_split(X, y)","5ccd1f53":"model = RandomForestRegressor(max_depth=12, n_estimators=200, random_state=22)\nmodel.fit(X_train, y_train)","e59e8870":"score_model(model, X_test_val, y_test_val)","54980ec2":"if True:\n  depths, scores, scores2 = [], [], []\n\nfor i in range(1, 100, 1):\n  model = RandomForestRegressor(max_depth=i, n_estimators=100, random_state=22)\n  model.fit(X_train, y_train)\n  \n  depths.append(i)\n  scores.append(score_model(model, X_test_val, y_test_val))\n  scores2.append(score_model(model, X_train, y_train))\n  \nsns.scatterplot(x=depths, y=scores)\nsns.scatterplot(x=depths, y=scores2)\nplt.show()","6835fab5":"if True:\n  depths, scores = [], []\n\nfor i in range(15, 150, 5):\n  model = RandomForestRegressor(max_depth=i, n_estimators=50, random_state=22)\n  model.fit(X_train, y_train)\n  \n  depths.append(i)\n  scores.append(score_model(model, X_test_val, y_test_val))\n  \nshow_res(depths, scores)","7ba82c84":"if True:\n  depths, scores = [], []\n\nfor i in range(10, 200, 10):\n  model = RandomForestRegressor(max_depth=30, n_estimators=i, random_state=22)\n  model.fit(X_train, y_train)\n  \n  depths.append(i)\n  scores.append(score_model(model, X_test_val, y_test_val))\n  \nshow_res(depths, scores)","a74c5f84":"if True:\n  depths, scores = [], []\n\nfor i in range(100, 1000, 100):\n  model = RandomForestRegressor(max_depth=30, n_estimators=i, random_state=22)\n  model.fit(X_train, y_train)\n  \n  depths.append(i)\n  scores.append(score_model(model, X_test_val, y_test_val))\n  \nshow_res(depths, scores)","8599d6ae":"if True:\n  depths, scores = [], []\n\nfor i in range(30, 60, 2):\n  model = RandomForestRegressor(max_depth=i, n_estimators=200, random_state=22)\n  model.fit(X_train, y_train)\n  \n  depths.append(i)\n  scores.append(score_model(model, X_test_val, y_test_val))\n  \nshow_res(depths, scores)","74a9d661":"if True:\n  depths, scores = [], []\n\nfor i in range(35, 50, 1):\n  model = RandomForestRegressor(max_depth=i, n_estimators=400, random_state=22)\n  model.fit(X_train, y_train)\n  \n  depths.append(i)\n  scores.append(score_model(model, X_test_val, y_test_val))\n  \nshow_res(depths, scores)","9eebc383":"if True:\n  depths, scores = [], []\n\nfor i in range(100, 300, 10):\n  model = RandomForestRegressor(max_depth=40, n_estimators=i, random_state=22)\n  model.fit(X_train, y_train)\n  \n  depths.append(i)\n  scores.append(score_model(model, X_test_val, y_test_val))\n  \nshow_res(depths, scores)","47b71980":"X_train, X_test, X_val, y_train, y_test, y_val = perfect_split(X, y)\n\nstates, scores2, scores3 = [], [], []\n\nfor i in range(200):\n  if i % 10 == 0: print(i)\n  model = RandomForestRegressor(max_depth=40, n_estimators=300, random_state=i)\n  model.fit(X_train, y_train)\n  \n  states.append(i)\n  scores2.append(score_model(model, X_val, y_val))\n  scores3.append(score_model(model, X_test, y_test))","9a0127ce":"sns.scatterplot(x=states, y=scores2)\nsns.scatterplot(x=states, y=scores3)\nplt.show()\npairplot('scores2', 'scores3')","2d4d5bda":"pd.DataFrame(data={'scores2':scores2, 'scores3':scores3}).corr()","0d0c3779":"get_graph_max(states, scores2)\n[x for x in sorted(zip(states, scores2), key=lambda x: -x[1])][:10]","2a39feec":"forest_model = RandomForestRegressor(max_depth=40, n_estimators=300, random_state=6)\nforest_model.fit(X_train, y_train)","ed1d9827":"print(f'Train:      {round3(score_model(model, X_train, y_train))}')\nprint(f'Val:        {round3(score_model(model, X_val, y_val))}')\nprint(f'Test:       {round3(score_model(model, X_test, y_test))}')\n\nprint()\nprint(f'Test Min:   {round3(np.min(scores3))}')\nprint(f'Test Ave:   {round3(np.mean(scores3))}')\nprint(f'Test Max:   {round3(np.max(scores3))}')","63a74ced":"class FinalLinearModel:\n  \n  def fit(self, X, y):\n    self.linear_model = Ridge(alpha=11.8)\n    self.linear_model.fit(X, y)\n    self.fit_forest_opt(X, y)\n\n  def fit_forest_opt(self, X, y):\n    pred_tr = self.linear_model.predict(X)\n\n    self.forest_opt_model1 = RandomForestRegressor(max_depth=9, n_estimators=38, random_state=54)\n    self.forest_opt_model1.fit(pred_tr.reshape(-1, y.shape[1]), y)\n\n    self.forest_opt_model2 = RandomForestRegressor(max_depth=10, n_estimators=49, random_state=8)\n    self.forest_opt_model2.fit(pred_tr.reshape(-1, y.shape[1]), y)\n    \n\n  def predict(self, X):\n    pred = self.linear_model.predict(X)\n    pred = self.apply_forest_opt(pred)\n    return pred\n\n  def apply_forest_opt(self, pred):\n    pred1 = self.forest_opt_model1.predict(pred.reshape(-1, pred.shape[1]))\n    pred2 = self.forest_opt_model2.predict(pred.reshape(-1, pred.shape[1]))\n    a = 0.5\n    pred12 = a * pred2 + (1 - a) * pred1\n    return pred12","189541e6":"linear_model = FinalLinearModel()\nlinear_model.fit(X_train, y_train)","342159c0":"print('R2:')\nprint(f'Train: {round3(r2_score(y_train, linear_model.predict(X_train)))}')\nprint(f'Val:   {round3(r2_score(y_val, linear_model.predict(X_val)))}')\nprint(f'Test:  {round3(r2_score(y_test, linear_model.predict(X_test)))}')\n\nprint('\\nRMSE:')\nprint(f'Train: {round3(mean_squared_error(y_train, linear_model.predict(X_train), squared=False))}')\nprint(f'Val:   {round3(mean_squared_error(y_val, linear_model.predict(X_val), squared=False))}')\nprint(f'Test:  {round3(mean_squared_error(y_test, linear_model.predict(X_test), squared=False))}')\nprint(f'Dummy: {round3(mean_squared_error(y, [np.mean(y)] * len(y), squared=False))}')","1a39c6e2":"class FinalModel:\n  \n  def fit(self, X, y):\n    self.linear_model = FinalLinearModel()\n    self.linear_model.fit(X, y)\n\n    self.forest_model = RandomForestRegressor(max_depth=40, n_estimators=300, random_state=6)\n    self.forest_model.fit(X, y)\n\n  def predict(self, X):\n    pred1 = self.linear_model.predict(X)\n    pred2 = self.forest_model.predict(X)\n    a = 0.7\n    return a * pred1 + (1 - a) * pred2","1fd26aaa":"final_model = FinalModel()\nfinal_model.fit(X_train, y_train)","ad857b47":"alphas, scores , scores2 = [], [], []\n\nfor i in range(100):\n  a = i \/ 100\n  alphas.append(i)\n  scores.append(my_r2_score(y_val, final_model.predict(X_val, a)))\n  scores2.append(my_r2_score(y_test, final_model.predict(X_test, a)))\n\nshow_res(alphas, scores)","00310447":"print('R2:')\nprint(f'Train: {round(r2_score(y_train, final_model.predict(X_train)), 3)}')\nprint(f'Val:   {round(r2_score(y_val, final_model.predict(X_val)), 3)}')\nprint(f'Test:  {round(r2_score(y_test, final_model.predict(X_test)), 3)}')\n\nprint('\\nRMSE:')\nprint(f'Train: {round(mean_squared_error(y_train, final_model.predict(X_train), squared=False), 3)}')\nprint(f'Val:   {round(mean_squared_error(y_val, final_model.predict(X_val), squared=False), 3)}')\nprint(f'Test:  {round(mean_squared_error(y_test, final_model.predict(X_test), squared=False), 3)}')\nprint(f'Dummy: {round(mean_squared_error(y, [np.mean(y)] * len(y), squared=False), 3)}')","b66f10bc":"# Final Model Class (0.49)","9327d7ea":"X Sums Distribution","6610b62a":"# Coef Analysis","0fddc0b7":"# Ridge Alpha (0.45)","a6da3ced":"# Final Linear Model Class (0.46)","63c04e2d":"# Import and Prep (0.3)","c0494a38":"Random State","7ed7c5c5":"# Forest Opt (0.46)","71909c98":"# Random Forest Model (0.41)","98a7f60d":"Zero Vectors, Intercept","9561f562":"# Vocabulary Selection (0.44)"}}