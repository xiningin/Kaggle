{"cell_type":{"f8d73e31":"code","0615a5ba":"code","14416e1a":"code","ecf87a13":"code","c21a538b":"code","a57d8e68":"code","db380288":"code","8b16afa6":"code","0484236b":"code","aac5c48c":"code","20f0f85c":"code","284670f6":"code","763117a1":"code","6601302f":"code","9072da63":"code","fc41f73c":"code","690a3476":"code","0f349c6f":"code","2bcc9af5":"code","00730179":"code","807c6d23":"code","4a4c9c5b":"code","e6600edf":"code","991991a2":"code","8a952758":"code","e65a4844":"code","f3f77379":"code","47857e20":"code","7662b7c4":"code","45da5f77":"code","a63953bd":"code","9a4dcc2c":"code","de14a2fa":"code","d300aae6":"code","e994e584":"code","8dc3b903":"code","ca02b43a":"code","91d07503":"code","6e8f5d50":"code","e1ee580a":"code","a9fe98fe":"code","d2ef6895":"code","10323bd4":"code","a3879c10":"code","b9dc70ba":"code","d25fb91a":"code","ea6c39f1":"code","24d8f6e1":"code","3f6af743":"code","8e15e2c7":"code","8325e17d":"code","04ff4721":"code","b0e575ad":"code","2b5f5523":"code","f5f7fefe":"code","950e1a07":"code","5cb235d2":"code","c18c9fcd":"code","8c60ab10":"code","f7139e38":"code","10a1f627":"code","f46f5775":"code","150f20d2":"code","bafe0b7b":"code","9eade602":"code","f145e5ce":"code","5b5d2b68":"code","bb1285ad":"code","2aa2162e":"code","4688b4fa":"code","752c1899":"code","ec260d12":"code","d3acc840":"code","f3cafa45":"code","af4d2fd3":"code","746acb77":"code","6a837c11":"code","eefd089e":"code","6bee226e":"code","41f96bc5":"code","b11303ee":"code","a35da043":"code","1fc23dae":"code","6ed6fb40":"code","5cb88c51":"code","0cb079ed":"code","4e14ed15":"code","91a6f71a":"code","d6237fa3":"code","dabf3254":"code","d8615313":"code","79aba3b0":"code","f9e3bbbc":"code","6d524a01":"code","bad83c3e":"code","0c92c374":"code","146d9a0b":"code","d9408ec5":"code","1bb7ad0c":"code","ea16eb5d":"code","20339b7c":"code","6f1742dc":"code","56faceb6":"code","b0c5a3f0":"code","8270f427":"code","4c5c556e":"code","7acc6b1c":"code","ed5d04e4":"code","9ad59d3c":"code","cfb2bc60":"code","af08c1cd":"code","cf6983b9":"code","86bb9a02":"code","44c883dd":"code","1ab3dc46":"code","6c37f79b":"code","9e034fe5":"code","f934c012":"code","28f51e06":"code","4b1c932b":"code","17261c2c":"code","e969ce6f":"code","4d3cadf6":"code","c26a49ba":"code","55954289":"code","78739dd9":"code","a6f678ac":"code","cfc5ad9a":"code","ac75d06c":"code","055546ee":"code","76deaae2":"code","484610ce":"code","0d2a5e7b":"code","608a473d":"code","1c1fae52":"code","175e934e":"code","92120459":"code","dbbbf006":"code","c6006801":"code","3f366ee0":"code","f78264fe":"markdown","16183279":"markdown","50ac2742":"markdown","062585c3":"markdown","f0572f72":"markdown","aa8d7f51":"markdown","4949af8d":"markdown","c32a50f2":"markdown","a0a259f2":"markdown","758814a5":"markdown","236faef9":"markdown","25fbf9ab":"markdown","cd6bb41b":"markdown","40505189":"markdown","9ad2a9a3":"markdown","728a78fd":"markdown","1bf4c2d8":"markdown","8227e15e":"markdown","e9f75adf":"markdown","b3157f4a":"markdown","14ea890f":"markdown","40a6a24e":"markdown","6d5e97a4":"markdown","334567c7":"markdown","a57968ca":"markdown","3c0a50ac":"markdown"},"source":{"f8d73e31":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","0615a5ba":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport json\n\nfrom collections import Counter\n\nimport itertools\n\nimport re\nimport string\nimport collections\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error\n\n%matplotlib inline\n%precision 3\npd.set_option('precision', 3)\n\nimport warnings\nwarnings.filterwarnings('ignore')","14416e1a":"#\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u53d6\u308b\n#\ntrain = pd.read_csv('..\/input\/tmdb-box-office-prediction\/train.csv')\n#\ntest = pd.read_csv('..\/input\/tmdb-box-office-prediction\/test.csv')","ecf87a13":"print(train.shape,test.shape)\ntrain.columns","c21a538b":"train.loc[train['id'] == 391,'runtime'] = 96 #The Worst Christmas of My Life\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntrain.loc[train['id'] == 592,'runtime'] = 90 #\u0410 \u043f\u043e\u0443\u0442\u0440\u0443 \u043e\u043d\u0438 \u043f\u0440\u043e\u0441\u043d\u0443\u043b\u0438\u0441\u044c\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntrain.loc[train['id'] == 925,'runtime'] = 86 #\u00bfQui\u00e9n mat\u00f3 a Bambi?\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntrain.loc[train['id'] == 978,'runtime'] = 93 #La peggior settimana della mia vita\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntrain.loc[train['id'] == 1256,'runtime'] = 92 #Cry, Onion!\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntrain.loc[train['id'] == 1542,'runtime'] = 93 #All at Once\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntrain.loc[train['id'] == 1875,'runtime'] = 93 #Vermist\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntrain.loc[train['id'] == 2151,'runtime'] = 108 #Mechenosets\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntrain.loc[train['id'] == 2499,'runtime'] = 86 #Na Igre 2. Novyy Uroven\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntrain.loc[train['id'] == 2646,'runtime'] = 98 #My Old Classmate\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntrain.loc[train['id'] == 2786,'runtime'] = 111 #Revelation\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntrain.loc[train['id'] == 2866,'runtime'] = 96 #Tutto tutto niente niente\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b","a57d8e68":"test.loc[test['id'] == 3244,'runtime'] = 93 #La caliente ni\u00f1a Julietta\t\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntest.loc[test['id'] == 4490,'runtime'] = 90 #Pancho, el perro millonario\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntest.loc[test['id'] == 4633,'runtime'] = 108 #Nunca en horas de clase\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntest.loc[test['id'] == 6818,'runtime'] = 90 #Miesten v\u00e4lisi\u00e4 keskusteluja\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\n\ntest.loc[test['id'] == 4074,'runtime'] = 103 #Shikshanachya Aaicha Gho\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntest.loc[test['id'] == 4222,'runtime'] = 91 #Street Knight\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntest.loc[test['id'] == 4431,'runtime'] = 96 #Plus one\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntest.loc[test['id'] == 5520,'runtime'] = 86 #Glukhar v kino\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntest.loc[test['id'] == 5845,'runtime'] = 83 #Frau M\u00fcller muss weg!\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntest.loc[test['id'] == 5849,'runtime'] = 140 #Shabd\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntest.loc[test['id'] == 6210,'runtime'] = 104 #The Last Breath\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntest.loc[test['id'] == 6804,'runtime'] = 140 #Chaahat Ek Nasha...\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b\ntest.loc[test['id'] == 7321,'runtime'] = 87 #El truco del manco\u306e\u4e0a\u6620\u6642\u9593\u3092\u8abf\u3079\u3066\u5165\u529b","db380288":"df = pd.concat([train, test]).set_index(\"id\")","8b16afa6":"df.loc[df.index == 90,'budget'] = 30000000\ndf.loc[df.index == 118,'budget'] = 60000000\ndf.loc[df.index == 149,'budget'] = 18000000\ndf.loc[df.index == 464,'budget'] = 20000000\ndf.loc[df.index == 819,'budget'] = 90000000\ndf.loc[df.index == 1112,'budget'] = 6000000\ndf.loc[df.index == 1131,'budget'] = 4300000\ndf.loc[df.index == 1359,'budget'] = 10000000\ndf.loc[df.index == 1570,'budget'] = 15800000\ndf.loc[df.index == 1714,'budget'] = 46000000\ndf.loc[df.index == 1865,'budget'] = 80000000\ndf.loc[df.index == 2602,'budget'] = 31000000","0484236b":"#columns\u3092\u78ba\u8a8d\u3057\u3001\u9664\u5916\u3059\u308b\u5909\u6570\u3092drop\nprint(df.columns)\n# \u4f7f\u308f\u306a\u3044\u5217\u3092\u6d88\u3059\ndf = df.drop([\"poster_path\", \"status\", \"original_title\"], axis=1) # \"overview\",  \"imdb_id\", ","aac5c48c":"# log\u3092\u53d6\u3063\u3066\u304a\u304f\ndf[\"log_revenue\"] = np.log10(df[\"revenue\"])\n# homepage: \u6709\u7121\u306b\n#df[\"homepage\"] =  ~df['homepage'].isnull()\ndf['has_homepage'] = 1\ndf.loc[pd.isnull(df['homepage']) ,\"has_homepage\"] = 0","20f0f85c":"dfdic_feature = {}","284670f6":"%%time\n# JSON text \u3092\u8f9e\u66f8\u578b\u306e\u30ea\u30b9\u30c8\u306b\u5909\u63db\nimport ast\ndict_columns = ['belongs_to_collection', 'genres', 'production_companies',\n                'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\n\nfor col in dict_columns:\n       df[col]=df[col].apply(lambda x: [] if pd.isna(x) else ast.literal_eval(x) )","763117a1":"# \u5404\u30ef\u30fc\u30c9\u306e\u6709\u7121\u3092\u8868\u3059 01 \u306e\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u3092\u4f5c\u6210\ndef count_word_list(series):\n    len_max = series.apply(len).max() # \u30b8\u30e3\u30f3\u30eb\u6570\u306e\u6700\u5927\u5024\n    tmp = series.map(lambda x: x+[\"nashi\"]*(len_max-len(x))) # list\u306e\u9577\u3055\u3092\u305d\u308d\u3048\u308b\n    \n    word_set = set(sum(list(series.values), [])) # \u5168\u30b8\u30e3\u30f3\u30eb\u540d\u306eset\n    for n in range(len_max):\n        word_dfn = pd.get_dummies(tmp.apply(lambda x: x[n]))\n        word_dfn = word_dfn.reindex(word_set, axis=1).fillna(0).astype(int)\n        if n==0:\n            word_df = word_dfn\n        else:\n            word_df = word_df + word_dfn\n    \n    return word_df#.drop(\"nashi\", axis=1)","6601302f":"df[\"genre_names\"] = df[\"genres\"].apply(lambda x : [ i[\"name\"] for i in x])\n","9072da63":"df[\"genre_names\"]","fc41f73c":"df.columns","690a3476":"dfdic_feature[\"genre\"] = count_word_list(df[\"genre_names\"])\n# TV movie \u306f1\u4ef6\u3057\u304b\u306a\u3044\u306e\u3067\u524a\u9664\ndfdic_feature[\"genre\"] = dfdic_feature[\"genre\"].drop(\"TV Movie\", axis=1)\ndfdic_feature[\"genre\"].head()","0f349c6f":"# train\u5185\u306e\u4f5c\u54c1\u6570\u304c10\u4ef6\u672a\u6e80\u306e\u8a00\u8a9e\u306f \"small\" \u306b\u96c6\u7d04\nn_language = df.loc[:train.index[-1], \"original_language\"].value_counts()\nlarge_language = n_language[n_language>=10].index\ndf.loc[~df[\"original_language\"].isin(large_language), \"original_language\"] = \"small\"","2bcc9af5":"df[\"original_language\"] = df[\"original_language\"].astype(\"category\")","00730179":"# one_hot_encoding\n#dfdic_feature[\"original_language\"] = pd.get_dummies(df[\"original_language\"])\n#dfdic_feature[\"original_language\"] = dfdic_feature[\"original_language\"].loc[:, dfdic_feature[\"original_language\"].sum()>0]\n#dfdic_feature[\"original_language\"].head()","807c6d23":"df[\"production_names\"] = df[\"production_companies\"].apply(lambda x : [ i[\"name\"] for i in x])\n#.fillna(\"[{'name': 'nashi'}]\").map(to_name_list)","4a4c9c5b":"tmp = count_word_list(df[\"production_names\"])","e6600edf":"# train\u5185\u306e\u4ef6\u6570\u304c\u591a\u3044\u7269\u306e\u307f\u9078\u3076\ndef select_top_n(df, topn=9999, nmin=2):  # topn:\u4e0a\u4f4dtopn\u4ef6, nmin:\u4f5c\u54c1\u6570nmin\u4ee5\u4e0a\n#    if \"small\" in df.columns:\n#        df = df.drop(\"small\", axis=1)\n    n_word = (df.loc[train[\"id\"]]>0).sum().sort_values(ascending=False)\n    # \u4f5c\u54c1\u6570\u304cnmin\u4ef6\u672a\u6e80\n    smallmin = n_word[n_word<nmin].index\n    # \u4e0a\u4f4dtopn\u4ef6\u306b\u5165\u3063\u3066\u3044\u306a\u3044\n    smalln = n_word.iloc[topn+1:].index\n    small = set(smallmin) | set(smalln)\n    # \u4ef6\u6570\u306e\u5c11\u306a\u3044\u30bf\u30b0\u306e\u307f\u306e\u4f5c\u54c1\n    df[\"small\"] = df[small].sum(axis=1) #>0\n    \n    return df.drop(small, axis=1)","991991a2":"# train\u306b50\u672c\u4ee5\u4e0a\u4f5c\u54c1\u306e\u3042\u308b\u4f1a\u793e\n#dfdic_feature[\"production_companies\"] = select_top_n(tmp, nmin=50)\n#dfdic_feature[\"production_companies\"].head()","8a952758":"# \u56fd\u540d\u306e\u30ea\u30b9\u30c8\u306b\ndf[\"country_names\"] = df[\"production_countries\"].apply(lambda x : [ i[\"name\"] for i in x])\ndf_country = count_word_list(df[\"country_names\"])","e65a4844":"# 2\u304b\u56fd\u3060\u3063\u305f\u3089\u30010.5\u305a\u3064\u306b\ndf_country = (df_country.T\/df_country.sum(axis=1)).T.fillna(0)","f3f77379":"# 30\u4f5c\u54c1\u4ee5\u4e0a\u306e\u56fd\u306e\u307f\n#dfdic_feature[\"production_countries\"] = select_top_n(df_country, nmin=30)\n#dfdic_feature[\"production_countries\"].head()","47857e20":"df[\"keyword_list\"] = df[\"Keywords\"].apply(lambda x : [ i[\"name\"] for i in x])","7662b7c4":"df[\"num_Keywords\"] = df[\"keyword_list\"].apply(len)","45da5f77":"#crew\u306ename\ndf_lang = pd.DataFrame(df['spoken_languages'])\nlist_lang_names = list(df_lang['spoken_languages'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\ndf_lang['num_spoken_languages'] = df_lang['spoken_languages'].apply(lambda x: len(x) if x != {} else 0)\ndf_lang['all_spoken_languages'] = df_lang['spoken_languages'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\ntop_lang_names = [m[0] for m in Counter([i for j in list_lang_names for i in j]).most_common(15)]\nfor g in top_lang_names:\n    df_lang[g] = df_lang['all_spoken_languages'].apply(lambda x: 1 if g in x else 0)","a63953bd":"df_lang.rename(columns ={'English':'spoken_en',\n 'Fran\u00e7ais':'spoken_fr',\n 'Espa\u00f1ol':'spoken_es',\n 'Deutsch':'spoken_gr',\n 'P\u0443\u0441\u0441\u043a\u0438\u0439':'spoken_sv',\n 'Italiano':'spoken_it',\n '\u65e5\u672c\u8a9e':'spoken_ja',\n '\u666e\u901a\u8bdd':'spoken_ch1',\n '\u0939\u093f\u0928\u094d\u0926\u0940':'spoken_in',\n '':'spoken_unknown',\n '\u0627\u0644\u0639\u0631\u0628\u064a\u0629':'spoken_arb',\n 'Portugu\u00eas':'spoken_por',\n '\u5e7f\u5dde\u8bdd \/ \u5ee3\u5dde\u8a71':'spoken_ch2',\n '\ud55c\uad6d\uc5b4\/\uc870\uc120\ub9d0':'spoken_kr',\n 'Polski':'spoken_pol'}, inplace =True)","9a4dcc2c":"df_lang.drop(columns=['spoken_languages', 'all_spoken_languages'], inplace = True)","de14a2fa":"df[\"language_names\"] = df[\"spoken_languages\"].apply(lambda x : [ i[\"name\"] for i in x])\ndf[\"n_language\"] = df[\"language_names\"].apply(len)\n# \u6b20\u640d\u5024\u306f\uff11\u306b\u3059\u308b(\u30c7\u30fc\u30bf\u3092\u898b\u308b\u3068\u7121\u58f0\u6620\u753b\u3067\u306f\u306a\u3044)\ndf.loc[df[\"n_language\"]==0, \"n_language\"] = 1","d300aae6":"# \u82f1\u8a9e\u304c\u542b\u307e\u308c\u308b\u304b\u5426\u304b\ndf[\"speak_English\"] = df[\"language_names\"].apply(lambda x : \"English\" in x)","e994e584":"df['speak_English'] = pd.get_dummies(df['speak_English'])","8dc3b903":"df['speak_English']","ca02b43a":"#Since only last two digits of year are provided, this is the correct way of getting the year.\ndf[['release_month','release_day','release_year']]=df['release_date'].str.split('\/',expand=True).replace(np.nan, -1).astype(int)\n# Some rows have 4 digits of year instead of 2, that's why I am applying (df['release_year'] < 100) this condition\ndf.loc[ (df['release_year'] <= 19) & (df['release_year'] < 100), \"release_year\"] += 2000\ndf.loc[ (df['release_year'] > 19)  & (df['release_year'] < 100), \"release_year\"] += 1900\n\nreleaseDate = pd.to_datetime(df['release_date']) \ndf['release_dayofweek'] = releaseDate.dt.dayofweek\ndf['release_quarter'] = releaseDate.dt.quarter","91d07503":"df['mean_revenue_year'] = df.groupby('release_year')['revenue'].transform('mean')\ndf['mean_revenue_year'].plot(figsize=(15,5))\nplt.xticks(np.arange(1920,2018,4))","6e8f5d50":"df['mean_revenue_year']","e1ee580a":"df['mean_revenue_month'] = df.groupby('release_month')['revenue'].transform('mean')\n\ndf['mean_revenue_month'].plot(figsize=(15,5))\nplt.xticks(np.arange(1,13))","a9fe98fe":"df['mean_revenue_day'] = df.groupby('release_day')['revenue'].transform('mean')\n\ndf['mean_revenue_day'].plot(figsize=(15,5))\nplt.xticks(np.arange(1,32))","d2ef6895":"df['mean_dayofweek'] = df.groupby('release_dayofweek')['revenue'].transform('mean')\n\ndf['mean_dayofweek'].plot(figsize=(15,5))\nplt.xticks(np.arange(0,7))","10323bd4":"df['mean_quarter'] = df.groupby('release_quarter')['revenue'].transform('mean')\n\ndf['mean_quarter'].plot(figsize=(15,5))\nplt.xticks(np.arange(1,5))","a3879c10":"##import datetime\n# \u516c\u958b\u65e5\u306e\u6b20\u640d1\u4ef6 id=3829\n# May,2000 (https:\/\/www.imdb.com\/title\/tt0210130\/) \n# \u65e5\u306f\u4e0d\u660e\u30021\u65e5\u3092\u5165\u308c\u3066\u304a\u304f\n##df.loc[3829, \"release_date\"] = \"5\/1\/00\"\n\n##df[\"release_year\"] = pd.to_datetime(df[\"release_date\"]).dt.year.astype(int)\n# \u5e74\u306e20\u4ee5\u964d\u3092\u30012020\u5e74\u3088\u308a\u5f8c\u306e\u672a\u6765\u3068\u5224\u5b9a\u3057\u3066\u3057\u307e\u3046\u306e\u3067\u3001\u88dc\u6b63\u3002\n##df.loc[df[\"release_year\"]>2020, \"release_year\"] = df.loc[df[\"release_year\"]>2020, \"release_year\"]-100\n\n##df[\"release_month\"] = pd.to_datetime(df[\"release_date\"]).dt.month.astype(int)\n##df[\"release_day\"] = pd.to_datetime(df[\"release_date\"]).dt.day.astype(int)\n\n# datetime\u578b\u306b\n##df[\"release_date\"] = df.apply(lambda s: datetime.datetime(\n##    year=s[\"release_year\"],month=s[\"release_month\"],day=s[\"release_day\"]), axis=1)\n\n##df[\"release_dayofyear\"] = df[\"release_date\"].dt.dayofyear\n##df[\"release_dayofweek\"] = df[\"release_date\"].dt.dayofweek\n\n# \u6708\u3001\u66dc\u65e5\u306f \u30ab\u30c6\u30b4\u30ea\u578b\u306b\n##df[\"release_month\"] = df[\"release_month\"].astype('category')\n##df[\"release_dayofweek\"] = df[\"release_dayofweek\"].astype('category')","b9dc70ba":"# collection \u540d\u3092\u62bd\u51fa\ndf[\"collection_name\"] = df[\"belongs_to_collection\"].apply(lambda x : x[0][\"name\"] if len(x)>0 else \"nashi\")\n# \u7121\u3044\u5834\u5408\u3001\"nashi\"\u306b","d25fb91a":"# \u30b7\u30ea\u30fc\u30ba\u306e\u4f5c\u54c1\u6570\n#df = pd.merge( df, df.groupby(\"collection_name\").count()[[\"budget\"]].rename(columns={\"budget\":\"count_collection\"}), \n#         on=\"collection_name\", how=\"left\")\n# index\u304c\u305a\u308c\u308b\u306e\u3067\u3001\u623b\u3059\n#df.index = df.index+1\n\ndf[\"count_collection\"] = df[\"collection_name\"].apply(lambda x : (df[\"collection_name\"]==x).sum())\n# \u30b7\u30ea\u30fc\u30ba\u4ee5\u5916\u306e\u5834\u54080\ndf.loc[df[\"collection_name\"]==\"nashi\", \"count_collection\"] = 0\n\n","ea6c39f1":"# \u30b7\u30ea\u30fc\u30ba\u4f55\u4f5c\u76ee\u304b\ndf[\"number_in_collection\"] = df.sort_values(\"release_date\").groupby(\"collection_name\").cumcount()+1\n# \u30b7\u30ea\u30fc\u30ba\u4ee5\u5916\u306e\u5834\u54080\ndf.loc[df[\"collection_name\"]==\"nashi\", \"number_in_collection\"] = 0\n\n","24d8f6e1":"# \u540c\u30b7\u30ea\u30fc\u30ba\u306e\u81ea\u5206\u3088\u308a\u524d\u306e\u4f5c\u54c1\u306e\u5e73\u5747log(revenue)\ndf[\"collection_av_logrevenue\"] = [ df.loc[(df[\"collection_name\"]==row[\"collection_name\"]) & \n                                          (df[\"number_in_collection\"]<row[\"number_in_collection\"]),\n                                          \"log_revenue\"].mean() \n     for key,row in df.iterrows() ]\n","3f6af743":"# \u6b20\u640d(nashi) \u306e\u5834\u5408\u3001nashi \u3067\u306e\u5e73\u5747\ndf.loc[df[\"collection_name\"]==\"nashi\", \"collection_av_logrevenue\"] = df.loc[df[\"collection_name\"]==\"nashi\", \"log_revenue\"].mean()","8e15e2c7":"# train \u306b\u7121\u304ftest\u3060\u3051\u306b\u3042\u308b\u30b7\u30ea\u30fc\u30ba\u306e\u5834\u5408\u3001\u30b7\u30ea\u30fc\u30ba\u3082\u306e\u5168\u90e8\u306e\u5e73\u5747\ncollection_mean = df.loc[df[\"collection_name\"]!=\"nashi\", \"log_revenue\"].mean()  # \u30b7\u30ea\u30fc\u30ba\u3082\u306e\u5168\u90e8\u306e\u5e73\u5747\ndf[\"collection_av_logrevenue\"] = df[\"collection_av_logrevenue\"].fillna(collection_mean)  \n","8325e17d":"df_features = pd.concat(dfdic_feature, axis=1)","04ff4721":"df.columns","b0e575ad":"df[[\"original_language\", \"collection_name\"]] = df[[\"original_language\", \"collection_name\"]].astype(\"category\")","2b5f5523":"df_use = df[['budget', 'has_homepage', 'popularity','runtime','n_language', \n             \"num_Keywords\", \"speak_English\",\n             'release_year', 'release_month','release_day','release_dayofweek', \n             'mean_revenue_year','mean_revenue_day','collection_av_logrevenue' ,\"count_collection\",\"number_in_collection\"\n            ]]\ndf_use.head()","f5f7fefe":"df_use = pd.get_dummies(df_use)","950e1a07":"train_add = pd.read_csv('..\/input\/tmdb-competition-additional-features\/TrainAdditionalFeatures.csv')\ntest_add = pd.read_csv('..\/input\/tmdb-competition-additional-features\/TestAdditionalFeatures.csv')\ntrain_add.head()","5cb235d2":"df = pd.merge(df, pd.concat([train_add, test_add]), on=\"imdb_id\", how=\"left\")","c18c9fcd":"add_cols = [\"popularity2\", \"rating\", \"totalVotes\"]\ndf[add_cols] = df[add_cols].fillna(df[add_cols].mean())","8c60ab10":"train2 = pd.read_csv('..\/input\/tmdb-box-office-prediction-more-training-data\/additionalTrainData.csv')\ntrain3 = pd.read_csv('..\/input\/tmdb-box-office-prediction-more-training-data\/trainV3.csv')\ntrain3.head()","f7139e38":"#\u5168\u3066\u5c0f\u6587\u5b57\u306b\u5909\u63db\ndef lower_text(text):\n    return text.lower()\n\n#\u8a18\u53f7\u306e\u6392\u9664\ndef remove_punct(text):\n    text = text.replace('-', ' ')  # - \u306f\u5358\u8a9e\u306e\u533a\u5207\u308a\u3068\u307f\u306a\u3059\n    table=str.maketrans('','',string.punctuation)\n    return text.translate(table)\n\ndef remove_stopwords(words, stopwords):#\u4e0d\u8981\u306a\u5358\u8a9e\u3092\u524a\u9664\n    words = [word for word in words if word not in stopwords]\n    return words","10a1f627":"# \u82f1\u8a9e\u3067\u3088\u304f\u4f7f\u3046\u5358\u8a9e\u304c\u5165\u3063\u3066\u3044\u306a\u3044\u6587\u7ae0\u3092\u78ba\u8a8d\n#df.loc[df[\"overview\"].apply(lambda x : str(x)).apply(lambda x : lower_text(x)\n#                                ).str.contains(\"nan|the|where|with|from|and|for|his|her|over\")==False, \"overview\"]\n#train3.loc[train3[\"overview\"].apply(lambda x : str(x)).apply(lambda x : lower_text(x)).str.contains(\"nan|the|where|with|from|and|for|his|her|over\")==False, \"overview\"]","f46f5775":"no_english_overview_id = [157, 2863, 4616]   # \u4e0a\u306e\u30c7\u30fc\u30bf\u3092\u76ee\u3067\u78ba\u8a8d\nno_english_tagline_id = [3255, 3777, 4937]   # Tfidf \u3067\u975e\u82f1\u8a9e\u306e\u5358\u8a9e\u304c\u3042\u3063\u305f\u3082\u306e","150f20d2":"#\u5358\u8a9e\u6570\ndf['overview_word_count'] = df['overview'].apply(lambda x: len(str(x).split()))\n#\u6587\u5b57\u6570\n#df['overview_char_count'] = df['overview'].apply(lambda x: len(str(x)))\n# \u8a18\u53f7\u306e\u500b\u6570\n#df['overview_punctuation_count'] = df['overview'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))","bafe0b7b":"# \u524d\u51e6\u7406\ndf['_overview']=df['overview'].apply(lambda x : str(x)\n                            ).apply(lambda x : lower_text(x)).apply(lambda x : remove_punct(x))\n","9eade602":"#\u5358\u8a9e\u6570\ndf['tagline_word_count'] = df['tagline'].apply(lambda x: len(str(x).split()))\n#\u6587\u5b57\u6570\n#df['tagline_char_count'] = df['tagline'].apply(lambda x: len(str(x)))\n# \u8a18\u53f7\u306e\u500b\u6570\n#df['tagline_punctuation_count'] = df['tagline'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))","f145e5ce":"df['_tagline']=df['tagline'].apply(lambda x : str(x)\n                                 ).apply(lambda x : lower_text(x)).apply(lambda x : remove_punct(x))\n","5b5d2b68":"#\u5358\u8a9e\u6570\ndf['title_word_count'] = df['title'].apply(lambda x: len(str(x).split()))\n#\u6587\u5b57\u6570\n#df['title_char_count'] = df['title'].apply(lambda x: len(str(x)))\n# \u8a18\u53f7\u306e\u500b\u6570\n#df['title_punctuation_count'] = df['title'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n","bb1285ad":"df_use2 = df[[\"has_homepage\",\"runtime\",'budget']]","2aa2162e":"#cast\u306e\u4e2d\u306b\u3042\u308b\u4ff3\u512a\u306e\u540d\u524d\u3092\u30ea\u30b9\u30c8\u5316\u3055\u305b\u308b\nlist_of_cast_names = list(df['cast'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\ndf['num_cast'] = df['cast'].apply(lambda x: len(x) if x != {} else 0)\n","4688b4fa":"list_of_cast_genders = list(df['cast'].apply(lambda x: [i['gender'] for i in x] if x != {} else []).values)\n\ndf['genders_0_cast'] = df['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\ndf['genders_1_cast'] = df['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\ndf['genders_2_cast'] = df['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))    ","752c1899":"#crew\u306ename\nlist_of_crew_names = list(df['crew'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\ndf['num_crew'] = df['crew'].apply(lambda x: len(x) if x != {} else 0)\n","ec260d12":"department_count = pd.Series(Counter([job for lst in df[\"crew\"].apply(lambda x : [ i[\"department\"] for i in x]).values for job in lst]))\ndepartment_count.sort_values(ascending=False).head(5)","d3acc840":"job_count = pd.Series(Counter([job for lst in df[\"crew\"].apply(lambda x : [ i[\"job\"] for i in x]).values for job in lst]))\njob_count.sort_values(ascending=False).head(5)","f3cafa45":"df_crew = { idx : pd.DataFrame([ [crew[\"department\"], crew[\"job\"], crew[\"name\"]] \n                        for crew in x], columns=[\"department\", \"job\", \"name\"]) \n    for idx, x in df[\"crew\"].iteritems() }","af4d2fd3":"df_crew = pd.concat(df_crew)","746acb77":"def select_job(list_dict, key, value):\n    return [ dic[\"name\"] for dic in list_dict if dic[key]==value]","6a837c11":"for department in department_count.index:\n    df['dep_{}_num'.format(department)] = df[\"crew\"].apply(select_job, key=\"department\", value=department).apply(len)","eefd089e":"df_crewname = pd.DataFrame([], index=df.index)\nfor job in [\"Producer\", \"Director\", \"Screenplay\", \"Casting\", \"Original Music Composer\"]:\n    col = 'job_{}_list'.format(job)\n    df[col] = df[\"crew\"].apply(select_job, key=\"job\", value=job)\n\n    top_list = [m[0] for m in Counter([i for j in df[col] for i in j]).most_common(15)]\n    for i in top_list:\n        df_crewname['{}_{}'.format(job,i)] = df[col].apply(lambda x: i in x)","6bee226e":"for job in [\"Sound\", \"Art\", \"Costume & Make-Up\", \"Camera\", \"Visual Effects\"]:\n    col = 'department_{}_list'.format(job)\n    df[col] = df[\"crew\"].apply(select_job, key=\"department\", value=job)\n\n    top_list = [m[0] for m in Counter([i for j in df[col] for i in j]).most_common(15)]\n    for i in top_list:\n        df_crewname['{}_{}'.format(job,i)] = df[col].apply(lambda x: i in x)","41f96bc5":"list(df)","b11303ee":"import pickle\nwith open(\"\/kaggle\/input\/private-jhk\/df_use_nagano.pkl\",\"rb\") as fr:\n    df_use_nagano = pickle.load(fr)","a35da043":"df_use_nagano","1fc23dae":"df_use_nagano = df_use_nagano[['production_countries_count', 'production_companies_count']]","6ed6fb40":"df_use4 = df[add_cols]","5cb88c51":"df_input = pd.concat([df_use, df_use4, df_features,df_use_nagano], axis=1) # .drop(\"belongs_to_collection\", axis=1) ","0cb079ed":"# \u6b20\u6e2c\u30ca\u30b7\u3092\u78ba\u8a8d\ndf_input.isnull().sum().sum()","4e14ed15":"df[\"ln_revenue\"] = np.log(df[\"revenue\"]+1)","91a6f71a":"df_input['log_budget'] = np.log10(df_input['budget'])","d6237fa3":"df_input['budget\/popularity1'] = df_input['budget']\/df_input['popularity']\ndf_input['budget\/popularity2'] = df_input['budget']\/df_input['popularity2']\ndf_input['budget\/runtime'] = df_input['budget']\/df_input['runtime']","dabf3254":"sns.distplot(df_input['budget\/popularity1'])\nplt.show()","d8615313":"sns.distplot(df_input['budget\/popularity2'])\nplt.show()","79aba3b0":"sns.distplot(df_input['budget\/runtime'])\nplt.show()","f9e3bbbc":"df_input['_popularity_mean_year']=df['popularity']\/df.groupby(\"release_year\")[\"popularity\"].transform('mean')\ndf_input['_budget_runtime_ratio']=df['budget']\/df['runtime']\ndf_input['_budget_popularity_ratio']=df['budget']\/df['popularity']\ndf_input['_budget_year_ratio']=df['budget']\/(df['release_year']*df['release_year'])\ndf_input['_releaseYear_popularity_ratio']=df['release_year']\/df['popularity']\ndf_input['_releaseYear_popularity_ratio2']=df['popularity']\/df['release_year']\ndf_input['_popularity_totalVotes_ratio']=df['totalVotes']\/df['popularity']\ndf_input['_rating_popularity_ratio']=df['rating']\/df['popularity']\ndf_input['_rating_totalVotes_ratio']=df['totalVotes']\/df['rating']\ndf_input['_totalVotes_releaseYear_ratio']=df['totalVotes']\/df['release_year']\ndf_input['_budget_rating_ratio']=df['budget']\/df['rating']\ndf_input['_runtime_rating_ratio']=df['runtime']\/df['rating']\ndf_input['_budget_totalVotes_ratio']=df['budget']\/df['totalVotes']","6d524a01":"cols = df_input.loc[:, df_input.isnull().sum()>0].columns\ndf_input.loc[:, cols] = df_input[cols].fillna(df_input[cols].mean())","bad83c3e":"# \u4fdd\u5b58\nimport pickle\nwith open('df_input.pkl', 'wb') as f:\n      pickle.dump(df_input , f)","0c92c374":"# \u6570\u5024\u5316\u3067\u304d\u3044\u5217\u3092\u78ba\u8a8d\nno_numeric = df_input.apply(lambda s:pd.to_numeric(s, errors='coerce')).isnull().all()\nno_numeric[no_numeric]","146d9a0b":"df_input.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in df_input.columns]","d9408ec5":"[df_input.isnull().sum()]","1bb7ad0c":"X_all = df_input  # .drop([\"collection_av_logrevenue\"], axis=1)\nX_all.drop([0],inplace = True)\ny_all = df[\"ln_revenue\"]\ny_all.index = X_all.index","ea16eb5d":"X_all.drop(columns = ['budget'],inplace = True)","20339b7c":"train.shape","6f1742dc":"'''\nX_all = X_all.drop(columns = ['__genre____Fantasy__',\n '__original_language____cn__',\n '__original_language____it__',\n '__production_companies____Columbia_Pictures_Corporation__',\n '__original_language____ko__',\n '__production_companies____Walt_Disney_Pictures__',\n '__production_companies____Twentieth_Century_Fox_Film_Corporation__',\n '__original_language____ta__',\n '__genre____History__',\n '__production_companies____TriStar_Pictures__',\n '__production_companies____Metro_Goldwyn_Mayer__MGM___',\n '__production_countries____Russia__',\n '__original_language____small__',\n '__production_companies____Warner_Bros___',\n '__genre____War__',\n '__original_language____ru__',\n '__production_countries____Hong_Kong__',\n '__genre____Animation__',\n '__production_companies____Columbia_Pictures__',\n '__original_language____ja__',\n '__production_companies____New_Line_Cinema__',\n '__original_language____de__',\n '__genre____Science_Fiction__',\n '__production_countries____Spain__',\n '__genre____Adventure__',\n '__genre____Mystery__',\n '__original_language____es__',\n '__genre____Music__',\n '__genre____Horror__',\n '__original_language____hi__',\n '__original_language____en__',])\n '''","56faceb6":"[ c for c in X_all.columns if \"revenue\" in str(c)]","b0c5a3f0":"#\u6a19\u6e96\u5316\n#X_train_all_mean = X_all[:3000].mean()\n#X_train_all_std  = X_all[:3000].std()\n#X_all = (X_all-X_train_all_mean)\/X_train_all_std","8270f427":"test_X = X_all.iloc[3000:]","4c5c556e":"test_X.shape","7acc6b1c":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import mean_squared_error \nfrom sklearn.preprocessing import StandardScaler","ed5d04e4":"train_X, val_X, train_y, val_y = train_test_split(X_all.iloc[:3000], \n                                                  y_all.iloc[:3000], \n                                                  test_size=0.25, random_state=1)","9ad59d3c":"from sklearn.model_selection import KFold\n\nrandom_seed = 2019\nk = 10\nfold = list(KFold(k, shuffle = True, random_state = random_seed).split(train))\nnp.random.seed(random_seed)","cfb2bc60":"from xgboost.sklearn import XGBRegressor\nfrom sklearn.model_selection import GridSearchCV\n\nxgb = XGBRegressor()\n\n'''\nparams = {'nthread':[4], #when use hyperthread, xgboost may become slower\n              'objective':['reg:linear'],\n              'learning_rate': [0.03], #so called `eta` value\n              'max_depth': [4],\n              'min_child_weight': [4],\n              'silent': [1],\n              'subsample': [0.7],\n              'colsample_bytree': [0.3],\n              'n_estimators': [500]}\n\nxgb_grid = GridSearchCV(xgb,\n                        params,\n                        cv = 4,\n                        n_jobs = 5,\n                        verbose=True)\n\nxgb_grid.fit(train_X, train_y)\nprint(xgb_grid.best_score_)\nprint(xgb_grid.best_params_)\n'''","af08c1cd":"xgb_model = XGBRegressor(max_depth=4, \n                            min_child_weight=4,\n                            learning_rate=0.03, \n                            n_estimators=500, \n                            objective='reg:linear',\n                            nthread = 4,\n                            gamma=1.3,  \n                            silent=1,\n                            subsample=0.7, \n                            colsample_bytree=0.3, \n                            colsample_bylevel=0.5)\nxgb_model.fit(train_X,train_y)\nxgb_prediction = xgb_model.predict(val_X)\nxgb_rmse = mean_squared_error(val_y, xgb_prediction)","cf6983b9":"plt.figure(figsize=(20,20))\nimportances = pd.Series(xgb_model.feature_importances_, index = X_all.columns)\nimportances = importances.sort_values()\nimportances.plot(kind = \"barh\")\nplt.title(\"imporance in the xgboost Model\")\nplt.show()","86bb9a02":"import math\n\nmath.sqrt(xgb_rmse)","44c883dd":"xgb_pred = xgb_model.predict(test_X)","1ab3dc46":"pred_xgb = pd.DataFrame(np.exp(xgb_pred)-1,columns=[\"revenue\"])\npred_xgb","6c37f79b":"test_id = test[\"id\"]","9e034fe5":"sub=pd.concat([test_id, pred_xgb],axis=1)\nsub.to_csv('TMDB_xgb.csv',index=False)","f934c012":"from lightgbm import LGBMRegressor\n\nlgbm = LGBMRegressor()\n'''\nparams = {'n_estimators': [500],\n          'objection' :['regressor'],\n          'metric':['rmse'],\n          'max_depth ': [2],\n          'num_leaves':[10],\n          'min_child_samples':[500],\n          'learning_rate':[0.01],\n          'boosting ': ['gbdt'],\n          'num_iterations' : [1500],\n          'min_data_in_leaf': [10],\n          'bagging_freq ': [1],\n          'bagging_fraction ': [0.9],\n          'feature_fraction' : [0.7],\n          'importance_type':['gain'],\n          'use_best_model':[True]}\n\nlgbm_grid = GridSearchCV(estimator=lgbm, param_grid=params,cv=4, n_jobs=5, verbose=True)\n\nlgbm_grid.fit(train_X, train_y)\nprint(lgbm_grid.best_score_)\nprint(lgbm_grid.best_params_)\n'''","28f51e06":"lgbm_model = LGBMRegressor(n_estimators= 500,\n          objection ='regressor',\n          metric='rmse',\n          max_depth = 2,\n          num_leaves=10,\n          min_child_samples=500,\n          learning_rate=0.01,\n          boosting = 'gbdt',\n          num_iterations = 1500,\n          min_data_in_leaf= 10,\n          bagging_freq = 1,\n          bagging_fraction = 0.9,\n          feature_fraction = 0.7,\n          importance_type='gain',\n          use_best_model=True)\nlgbm_model.fit(train_X, train_y)\nlgbm_prediction = lgbm_model.predict(val_X)\nlgbm_rmse = mean_squared_error(val_y, lgbm_prediction)","4b1c932b":"plt.figure(figsize=(20,20))\nimportances = pd.Series(lgbm_model.feature_importances_, index = X_all.columns)\nimportances = importances.sort_values()\nimportances.plot(kind = \"barh\")\nplt.title(\"imporance in the LightGBM Model\")\nplt.show()","17261c2c":"math.sqrt(lgbm_rmse)","e969ce6f":"lgbm_pred = lgbm_model.predict(test_X)","4d3cadf6":"pred_lgbm = pd.DataFrame(np.exp(lgbm_pred)-1,columns=[\"revenue\"])\npred_lgbm","c26a49ba":"sub=pd.concat([test_id, pred_lgbm],axis=1)\nsub.to_csv('TMDB_lgbm.csv',index=False)","55954289":"from catboost import CatBoostRegressor\n'''\ncat = CatBoostRegressor()\n\nparams = {'iterations' : [2000], \n                                 'learning_rate' : [0.01], \n                                 'depth' : [6], \n                                 'eval_metric' : ['RMSE'],\n                                 'colsample_bylevel' : [0.6],\n                                 'bagging_temperature' : [0.1],\n                                 'early_stopping_rounds' : [200]}\n\ncat_grid = GridSearchCV(estimator=cat, param_grid=params,cv=4, n_jobs=5, verbose=True)\n\ncat_grid.fit(train_X, train_y)\nprint(cat_grid.best_score_)\nprint(cat_grid.best_params_)\n'''\n","78739dd9":"cat_model = CatBoostRegressor(iterations=2000, \n                                 learning_rate=0.01, \n                                 depth=6, \n                                 eval_metric='RMSE',\n                                 colsample_bylevel=0.6,\n                                 bagging_temperature = 0.1,\n                                 metric_period = None,\n                                 early_stopping_rounds=200)\ncat_model.fit(train_X, train_y)\ncat_prediction = cat_model.predict(val_X)\ncat_rmse = mean_squared_error(val_y, cat_prediction)","a6f678ac":"math.sqrt(cat_rmse)","cfc5ad9a":"plt.figure(figsize=(20,20))\nimportances = pd.Series(cat_model.feature_importances_, index = X_all.columns)\nimportances = importances.sort_values()\nimportances.plot(kind = \"barh\")\nplt.title(\"imporance in the CatBoost Model\")\nplt.show()","ac75d06c":"cat_pred = cat_model.predict(test_X)","055546ee":"pred_cat = pd.DataFrame(np.exp(cat_pred)-1,columns=[\"revenue\"])\npred_cat","76deaae2":"sub=pd.concat([test_id, pred_cat],axis=1)\nsub.to_csv('TMDB_cat.csv',index=False)","484610ce":"ansamble = 0.4 * pred_lgbm[\"revenue\"] + 0.2 * pred_xgb[\"revenue\"] + 0.4 * pred_cat[\"revenue\"]","0d2a5e7b":"sub3=pd.concat([test_id, ansamble],axis=1)\nsub3","608a473d":"sub3.to_csv('TMDB_ansamble.csv',index=False)","1c1fae52":"ansamble2 = 0.35 * pred_lgbm[\"revenue\"] + 0.3 * pred_xgb[\"revenue\"] + 0.35 * pred_cat[\"revenue\"]","175e934e":"sub4=pd.concat([test_id, ansamble2],axis=1)\nsub4","92120459":"sub4.to_csv('TMDB_ansamble2.csv',index=False)","dbbbf006":"ansamble = 0.2 * pred_lgbm[\"revenue\"] + 0.2 * pred_xgb[\"revenue\"] + 0.6 * pred_cat[\"revenue\"]","c6006801":"sub5=pd.concat([test_id, ansamble],axis=1)\nsub5","3f366ee0":"sub3.to_csv('TMDB_ansamble3.csv',index=False)","f78264fe":"## \u8abf\u3079\u305f\u6b20\u6e2c\u30c7\u30fc\u30bf","16183279":"## release_date","50ac2742":"## spoken laguages","062585c3":"## belongs to collection","f0572f72":"## Additional data","aa8d7f51":"# TMDB prediction","4949af8d":"## Crew","c32a50f2":"df['genders_0_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\ndf['genders_1_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\ndf['genders_2_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))","a0a259f2":"# \u5b66\u7fd2\u7528\u30c7\u30fc\u30bf\u4f5c\u6210","758814a5":"# budget","236faef9":"## cast","25fbf9ab":"## Keyword","cd6bb41b":"# \u8a00\u8a9e\u51e6\u7406","40505189":"## \u6574\u7406","9ad2a9a3":"## genres","728a78fd":"## overview","1bf4c2d8":"## production contries","8227e15e":"## \u6574\u5f62","e9f75adf":"## title\u306e\u524d\u51e6\u7406","b3157f4a":"## original language","14ea890f":"# Popularity","40a6a24e":"## \u9023\u7d50","6d5e97a4":"### \u82f1\u8a9e\u4ee5\u5916","334567c7":"# \u5404\u5217\u306e\u51e6\u7406","a57968ca":"## production company","3c0a50ac":"## df\u4f5c\u6210"}}