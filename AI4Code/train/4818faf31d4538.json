{"cell_type":{"c6c1264b":"code","3c569606":"code","5132bfa2":"code","4f6ccd94":"markdown","7fe45303":"markdown","bc562e69":"markdown","c5a083a6":"markdown"},"source":{"c6c1264b":"\"Importing necessary packages\"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport gensim\nfrom gensim.models import LdaModel\nfrom gensim.corpora import Dictionary\nimport pyLDAvis.gensim\npyLDAvis.enable_notebook()\n\n#pd.set_option('display.expand_frame_repr', False)\n\nimport sklearn\nfrom sklearn.externals import joblib\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, make_scorer, accuracy_score\nfrom sklearn import preprocessing\nfrom mean_w2v import MeanEmbeddingVectorizer #custom function\n\nimport ipywidgets as widgets\nfrom ipywidgets import Button, Layout\nfrom IPython.display import display, HTML, clear_output\n\nfrom lime import lime_text\nfrom lime.lime_text import LimeTextExplainer\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\"Prep dataset for LDA topic modelling\"\ndfeng = pd.read_csv(\"..\/input\/rp-manglish-tweets-on-kl-rapid-transit\/\/Eng_traindata_processed.csv\")\ndfmal = pd.read_csv(\"..\/input\/rp-manglish-tweets-on-kl-rapid-transit\/\/Malay_traindata_processed.csv\")\ndfeng['textfin'] = dfeng['textfin'].astype('str')\ndfmal['textfin'] = dfmal['textfin'].astype('str')\ncorpus_mal = dfmal['textfin'].tolist()\ncorpus_eng = dfeng['textfin'].tolist()\ntrain_eng_texts = [doc.split(\" \") for doc in corpus_eng]\ntrain_mal_texts = [doc.split(\" \") for doc in corpus_mal]\ndfmal_txt = pd.DataFrame(dfmal[['text','textfin']]);df_comb = pd.DataFrame(dfeng[['text','textfin']])\ndf_comb = df_comb.append(dfmal_txt, ignore_index = True)\n\n\"pyldaviz function. pyldaviz provides interactive visualization of topic modelling results \"\ndef show_pyldavis(docs,passes,num_topics,no_below=0):  \n    bigram = gensim.models.Phrases(docs, min_count=5, threshold=100) # higher threshold fewer phrases.\n    bigram_mod = gensim.models.phrases.Phraser(bigram)\n    texts = [bigram_mod[doc] for doc in docs]  \n    dictionary = Dictionary(texts)\n    dictionary.filter_extremes(no_below=no_below)\n    dictionary.compactify()  \n    corpus = [dictionary.doc2bow(text) for text in texts]\n    ldamodel = gensim.models.LdaMulticore(corpus=corpus, num_topics=num_topics, \n                                        id2word=dictionary,\n                                        random_state=100,\n                                        chunksize=100,\n                                        passes=passes,\n                                        alpha=\"asymmetric\",\n                                        eta=0.91)\n    viz = pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)\n    return pyLDAvis.display(viz)","3c569606":"#print(\"Visualisation of LDA model of Manglish tweets\")\n#print(\"Instruction:\")\n#print(\"1) Hover your mouse on the circles to explore the topic-terms distribution\")\n#print(\"2) You may also explore the top terms across all topics by hover the mouse over to the right side panel\")\n#print(\"3) Event tweet is detected in the first topic\/Topic 1. It is the biggest circle plot with the highest terms prevalence\")\npd.options.display.max_colwidth = 50000\nshow_pyldavis(train_eng_texts,50,5,no_below=4)","5132bfa2":"#print(\"Visualisation of LDA model of English tweets\")\n#print(\"Instruction:\")\n#print(\"1) Hover your mouse on the circles to explore the topic-terms distribution\")\n#print(\"2) You may also explore the top terms across all topics by hover the mouse over to the right side panel\")\n#print(\"3) Event tweet is detected in the first topic\/Topic 1. It is the biggest circle plot with the highest terms prevalence\")\n#pd.options.display.max_colwidth = 5000\nshow_pyldavis(train_mal_texts,50,8)","4f6ccd94":"#### 1) LDA Manglish model plot","7fe45303":"**Instruction:**\n* Hover your mouse on the circles to explore the topic-terms distribution\n* You may also explore the top terms across all topics by hover the mouse over to the right side panel\n\n**What i discovered?**\n* LDA was able to distinguish event tweet topic from non-event tweet topics clearly.\n* The model works for both English and Manglish tweets.\n* For both English and Manglish tweets data, **Topic 1 was identified as the topic representing event tweets**. \n* Topic 1 is the largest topic as it comprises the highest prevalence of terms. \n* Topic 1 also seemed indenpendent of other topics as majority of its terms occur almost exclusively in the event tweet topic, and not shared with other topics.  \n* The non-event tweet topics includes topic on rapid transit payment methods and topic on train conditions. ","bc562e69":"**Read the main notebook first before going through this notebook:**\nlink to main notebook: https:\/\/www.kaggle.com\/shashikay\/rp-detecting-event-tweet-and-sentiment\n\n**This notebook display LDA outputs for Manglish and English rapid transit related tweets **","c5a083a6":"#### 2) LDA English model plot"}}