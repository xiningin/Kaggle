{"cell_type":{"7bd36ec2":"code","67ae5966":"code","36c47b1d":"code","f439f346":"code","baf7aac3":"code","24a04477":"code","c896770c":"code","38b6ea60":"code","b5210c36":"code","bf4beb10":"code","37e75ef0":"code","fa197e4e":"code","a7ecf6cf":"code","0c19a5f4":"code","ddc47678":"code","31ea312b":"code","b6114068":"code","9bddac27":"code","0a75cb47":"code","3d868f14":"code","55f557f3":"markdown","08f2f96b":"markdown","fb2d800f":"markdown","6976e46b":"markdown","f1d45a73":"markdown","1889f04a":"markdown","5c68a1ca":"markdown","e69a6785":"markdown"},"source":{"7bd36ec2":"import tensorflow as tf\nimport numpy as np\nimport random\nimport os\nimport time\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.callbacks import *\nfrom sklearn.metrics import *\nfrom tensorflow.keras.models import load_model\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # ignore warning :)\n\n# tensorboard = TensorBoard(log_dir='mylog')\n\ngpus = tf.config.experimental.list_physical_devices(device_type='GPU')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(device=gpu, enable=True)\n    \ntrain_tfrecord = 'XRay_train.tfrecords'\ntest_tfrecord = 'XRay_test.tfrecords'\ntrain_percentage = 0.8  # Proportion of training set\n\nrandom.seed(20)\n\ninput_path='\/kaggle\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/'","67ae5966":"learning_rate = 0.001\nbuffer_size = 512\nbatch_size = 16\nepochs = 20\n\nimg_size = 224","36c47b1d":"def read_directory():\n    data_filenames = []\n    data_labels = []\n\n    for filename in os.listdir(input_path + 'COVID-19'):\n        data_filenames.append(input_path + 'COVID-19\/' + filename)\n        data_labels.append(0)\n\n    for filename in os.listdir(input_path + 'NORMAL'):\n        data_filenames.append(input_path + 'NORMAL\/' + filename)\n        data_labels.append(1)\n\n    for filename in os.listdir(input_path + 'Viral Pneumonia'):\n        data_filenames.append(input_path + 'Viral Pneumonia\/' + filename)\n        data_labels.append(2)\n        \n    data_size = len(data_labels)\n\n    tmp_uni = list(zip(data_filenames, data_labels))\n\n    random.shuffle(tmp_uni)\n\n    train_size = int(data_size * train_percentage)\n    print('Size of training set\uff1a', train_size)\n    print('Size of test set\uff1a', data_size - train_size)\n\n    train_list = tmp_uni[0:train_size]\n    test_list = tmp_uni[train_size:]\n\n    train_filenames, train_labels = zip(*train_list)\n    test_filenames, test_labels = zip(*test_list)\n\n    return train_filenames, train_labels, test_filenames, test_labels","f439f346":"def build_train_tfrecord(train_filenames, train_labels):  # Generate TFRecord of training set \n    with tf.io.TFRecordWriter(train_tfrecord)as writer:\n        for filename, label in zip(train_filenames, train_labels):\n            image = open(filename, 'rb').read()\n\n            feature = {\n                'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])),  # img > Bytes\n                'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))  # label > Int\n            }\n\n            example = tf.train.Example(features=tf.train.Features(feature=feature))\n            writer.write(example.SerializeToString())\n\n\ndef build_test_tfrecord(test_filenames, test_labels):  # Generate TFRecord of test set\n    with tf.io.TFRecordWriter(test_tfrecord)as writer:\n        for filename, label in zip(test_filenames, test_labels):\n            image = open(filename, 'rb').read()\n\n            feature = {\n                'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])),\n                'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n            }\n\n            example = tf.train.Example(features=tf.train.Features(feature=feature))\n            writer.write(example.SerializeToString())","baf7aac3":"def _parse_example(example_string):\n    feature_description = {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'label': tf.io.FixedLenFeature([], tf.int64),\n    }\n\n    feature_dict = tf.io.parse_single_example(example_string, feature_description)\n    feature_dict['image'] = tf.io.decode_png(feature_dict['image'], channels=3)\n    feature_dict['image'] = tf.image.resize(feature_dict['image'], [img_size, img_size]) \/ 255.0\n    return feature_dict['image'], feature_dict['label']\n\n\ndef get_train_dataset(train_tfrecord):  # read TFRecord\n    raw_train_dataset = tf.data.TFRecordDataset(train_tfrecord)\n    train_dataset = raw_train_dataset.map(_parse_example)\n\n    return train_dataset\n\n\ndef get_test_dataset(test_tfrecord):\n    raw_test_dataset = tf.data.TFRecordDataset(test_tfrecord)\n    test_dataset = raw_test_dataset.map(_parse_example)\n\n    return test_dataset\n\n\ndef data_Preprocessing(train_dataset, test_dataset):\n    train_dataset = train_dataset.shuffle(buffer_size)\n    train_dataset = train_dataset.batch(batch_size)\n    train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n\n    test_dataset = test_dataset.batch(batch_size)\n    test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n\n    return train_dataset, test_dataset","24a04477":"class CNN(tf.keras.Model):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = tf.keras.layers.Conv2D(\n            filters=32,\n            kernel_size=[3, 3],\n            padding='same',\n            activation=tf.nn.relu,\n            input_shape=(img_size, img_size, 3)\n        )\n        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n        self.conv2 = tf.keras.layers.Conv2D(\n            filters=64,\n            kernel_size=[5, 5],\n            padding='same',\n            activation=tf.nn.relu\n        )\n        self.pool2 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n        self.flatten = tf.keras.layers.Reshape(target_shape=(int(img_size\/4) * int(img_size\/4) * 64,))\n        self.dense1 = tf.keras.layers.Dense(units=512, activation=tf.nn.relu)\n        self.drop1 = tf.keras.layers.Dropout(0.5)\n        self.dense2 = tf.keras.layers.Dense(units=3, activation='softmax')\n\n    def call(self, inputs):\n        x = self.conv1(inputs)\n        x = self.pool1(x)\n        x = self.conv2(x)\n        x = self.pool2(x)\n        x = self.flatten(x)\n        x = self.dense1(x)\n        x = self.drop1(x)\n        output = self.dense2(x)\n        return output","c896770c":"def Xception_model():\n    xception = tf.keras.applications.Xception(weights='imagenet',include_top=False, input_shape=[img_size,img_size,3])\n    xception.trainable= True\n    model = tf.keras.Sequential([\n        xception,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(3, activation='softmax')\n    ])\n\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n        loss=tf.keras.losses.sparse_categorical_crossentropy,\n        metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n    )\n    \n    return model","38b6ea60":"def VGG16_model():\n    vgg16 = tf.keras.applications.VGG16(weights='imagenet',include_top=False, input_shape=[img_size,img_size,3])\n    vgg16.trainable= True\n    model = tf.keras.Sequential([\n        vgg16,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(3, activation='softmax')\n    ])\n\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n        loss=tf.keras.losses.sparse_categorical_crossentropy,\n        metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n    )\n    \n    return model","b5210c36":"def ResNet50_model():\n    res50 = tf.keras.applications.ResNet50(weights='imagenet',include_top=False, input_shape=[img_size,img_size,3])\n    res50.trainable= True\n    model = tf.keras.Sequential([\n        res50,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(3, activation='softmax')\n    ])\n\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n        loss=tf.keras.losses.sparse_categorical_crossentropy,\n        metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n    )\n    \n    return model","bf4beb10":"def ResNet50V2_model():\n    res50v2 = tf.keras.applications.ResNet50V2(weights='imagenet',include_top=False, input_shape=[img_size,img_size,3])\n    res50v2.trainable= True\n    model = tf.keras.Sequential([\n        res50v2,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(3, activation='softmax')\n    ])\n\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n        loss=tf.keras.losses.sparse_categorical_crossentropy,\n        metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n    )\n    \n    return model","37e75ef0":"def InceptionV3_model():\n    incpV3 = tf.keras.applications.InceptionV3(weights='imagenet',include_top=False, input_shape=[img_size,img_size,3])\n    incpV3.trainable= True\n    model = tf.keras.Sequential([\n        incpV3,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(3, activation='softmax')\n    ])\n\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n        loss=tf.keras.losses.sparse_categorical_crossentropy,\n        metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n    )\n    \n    return model","fa197e4e":"def MobileNetV2_model():\n    mobV2 = tf.keras.applications.MobileNetV2(weights='imagenet',include_top=False, input_shape=[img_size,img_size,3])\n    mobV2.trainable= True\n    model = tf.keras.Sequential([\n        mobV2,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(3, activation='softmax')\n    ])\n\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n        loss=tf.keras.losses.sparse_categorical_crossentropy,\n        metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n    )\n    \n    return model","a7ecf6cf":"def DenseNet121_model():\n    den121 = tf.keras.applications.DenseNet121(weights='imagenet',include_top=False, input_shape=[img_size,img_size,3])\n    den121.trainable= True\n    model = tf.keras.Sequential([\n        den121,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(3, activation='softmax')\n    ])\n\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n        loss=tf.keras.losses.sparse_categorical_crossentropy,\n        metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n    )\n    \n    return model","0c19a5f4":"def ResNet101V2_model():\n    res101v2 = tf.keras.applications.ResNet101V2(weights='imagenet',include_top=False, input_shape=[img_size,img_size,3])\n    res101v2.trainable= True\n    model = tf.keras.Sequential([\n        res101v2,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(3, activation='softmax')\n    ])\n\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n        loss=tf.keras.losses.sparse_categorical_crossentropy,\n        metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n    )\n    \n    return model","ddc47678":"def InceptionResNetV2_model():\n    incp_res_v2 = tf.keras.applications.InceptionResNetV2(weights='imagenet',include_top=False, input_shape=[img_size,img_size,3])\n    incp_res_v2.trainable= True\n    model = tf.keras.Sequential([\n        incp_res_v2,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(3, activation='softmax')\n    ])\n\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n        loss=tf.keras.losses.sparse_categorical_crossentropy,\n        metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n    )\n    \n    return model","31ea312b":"def scheduler(epoch,lr):\n    if epoch<8:\n        return lr\n    else:\n        return lr*0.9\ncallback = tf.keras.callbacks.LearningRateScheduler(scheduler,verbose=1)\n\n# class_weight = {0:6.14, 1:1., 2:1.}","b6114068":"def train():\n    time_start = time.time()\n    \n#     model = Xception_model()\n#     model = VGG16_model()\n#     model = ResNet50_model()\n#     model = ResNet50V2_model()\n#     model = InceptionV3_model()\n#     model = MobileNetV2_model()\n#     model = DenseNet121_model()\n#     model = ResNet101V2_model()\n    model = InceptionResNetV2_model()\n    \n    model.summary()\n    \n    train_history = model.fit(train_dataset, epochs=epochs, callbacks=[callback])\n\n    model.save('mymodel.h5')\n    \n    print('Model saved.')\n    \n    time_end = time.time()\n    print('Training Time:', time_end - time_start)\n    print('\\n')\n\n    return train_history","9bddac27":"def show_train_history(train_history, index):\n    plt.plot(train_history.history[index])\n    plt.title('Train History')\n    plt.ylabel(index)\n    plt.xlabel('Epoch')\n    plt.show()","0a75cb47":"def test(test_labels):\n    test_labels = np.array(test_labels)\n    model = load_model('\/kaggle\/working\/mymodel.h5')\n    \n    print('Testing:')\n    \n    model.evaluate(test_dataset)\n    \n    predIdxs = model.predict(test_dataset)\n    predIdxs = np.argmax(predIdxs, axis=1) \n\n    target_names = ['COVID-19', 'NORMAL', 'Viral Pneumonia']\n    print('\\n')\n    print(classification_report(test_labels, predIdxs, target_names=target_names, digits=5))","3d868f14":"if __name__ == \"__main__\":\n    train_filenames, train_labels, test_filenames, test_labels = read_directory()\n\n    build_train_tfrecord(train_filenames, train_labels)\n    build_test_tfrecord(test_filenames, test_labels)\n\n    train_dataset = get_train_dataset(train_tfrecord)\n    test_dataset = get_test_dataset(test_tfrecord)\n\n    print('Info of train_dataset', type(train_dataset))\n    print('Info of test_dataset', type(test_dataset))\n\n    train_dataset, test_dataset = data_Preprocessing(train_dataset, test_dataset) \n\n    train_history = train()\n    \n    test(test_labels)\n    \n    show_train_history(train_history, 'sparse_categorical_accuracy')\n    \n    # Avoid filling up the disk, if you want to save the tfrecords, just '#' these lines:\n    for filename in os.listdir('\/kaggle\/working'): \n        if 'X' in filename: # Delete the tfrecord.\n            os.remove('\/kaggle\/working\/' + filename)","55f557f3":"# Intro: \nThis script classifies the images to 3 categories: **COVID-19**, **NORMAL** and **Viral Pneumonia**. This script also includes the use of **tfrecord**.  \nThis notebook aims at compareing the performances of different models on this classification problem.","08f2f96b":"# Run Now\uff01","fb2d800f":"# Decode TFRecord and get data","6976e46b":"# Build TFRecord","f1d45a73":"# Initialization","1889f04a":"# Model","5c68a1ca":"# Train&Test","e69a6785":"# Load data"}}