{"cell_type":{"63852ce7":"code","f9e461d8":"code","b746170f":"code","4e61f491":"code","9ec538cc":"code","82373332":"code","478693fe":"code","8045140b":"code","158bb7c1":"code","2ac0b0e2":"code","7dfc5b89":"code","8518c227":"code","6b678242":"code","acab39c5":"code","43f6f61c":"markdown","34bea94d":"markdown"},"source":{"63852ce7":"import os\nimport pickle\nimport librosa\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport soundfile as sf\nfrom sklearn.svm import SVC\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report","f9e461d8":"def extract_features(x, path):\n    X, sample_rate = sf.read(path, dtype='float32')\n    # Mcc\n    Mcc = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=47)\n    Mcc = np.mean(Mcc.T, axis=0)\n    # chroma_stft\n    chroma_stft = librosa.feature.chroma_stft(y=X, sr=sample_rate,n_chroma=12, n_fft=4096)\n    chroma_stft = np.mean(chroma_stft.T, axis=0)\n    # chroma_cqt\n    chroma_cqt = librosa.feature.spectral_bandwidth(y=X, sr=sample_rate)\n    chroma_cqt = np.mean(chroma_cqt.T, axis=0)\n    # tonnetz\n    tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate, chroma=chroma_cqt)\n    # melspectrogram\n    melspectrogram = librosa.feature.melspectrogram(y=X, sr=sample_rate)\n    melspectrogram = np.mean(melspectrogram.T, axis=0)\n    # spectral_centroid\n    spectral_centroid = librosa.feature.spectral_centroid(y=X, sr=sample_rate)\n    spectral_centroid = np.mean(spectral_centroid.T, axis=0)\n    # spectral_contrast\n    spectral_contrast = librosa.feature.spectral_contrast(y=X, sr=sample_rate)\n    spectral_contrast = np.mean(spectral_contrast.T, axis=0)\n    feature = np.hstack((Mcc, chroma_stft, chroma_cqt, melspectrogram, spectral_centroid, spectral_contrast, tonnetz))\n    x.append(feature)","b746170f":"def LabelEncoder(arr, le):\n    le.fit(arr)\n    print(le.classes_)\n    Y = le.fit_transform(arr)\n    return Y","4e61f491":"X = []\nY = []\n\nTrain_Data = ['..\/input\/urdu-language-speech-dataset\/Angry\/', \n              '..\/input\/urdu-language-speech-dataset\/Happy\/', \n              '..\/input\/urdu-language-speech-dataset\/Neutral\/', \n              '..\/input\/urdu-language-speech-dataset\/Sad\/']\nfor path in Train_Data:\n    for file in os.listdir(path):\n        print('*', end='')\n        file_path = path+file\n        extract_features(X, file_path)\n        Y.append(file_path.split('\/')[3])\n    print('\\nFeatures Extract From',path,'Completed!')\n\nX = np.array(X)\nY = np.array(Y)\nprint('\\nX Train Shape : ', X.shape)\nprint('Y Train Shape : ', Y.shape)","9ec538cc":"le = preprocessing.LabelEncoder()\nY = LabelEncoder(Y, le)","82373332":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\nprint('X Train Shape : ', X_train.shape)\nprint('Y Train Shape : ', Y_train.shape)\nprint('X Test Shape : ', X_test.shape)\nprint('Y Test Shape : ', Y_test.shape)","478693fe":"model = SVC(kernel='linear', gamma=0.001, C=1)\nmodel.fit(X_train, Y_train)","8045140b":"pickle.dump(model, open('SVC_Model.sav', 'wb'))","158bb7c1":"model_SVC = pickle.load(open('SVC_Model.sav', 'rb'))","2ac0b0e2":"Y_Predict = model_SVC.predict(X_test)\nprint('Y Predict :')\nprint(Y_Predict)\nprint('\\nY Test :')\nprint(Y_test)","7dfc5b89":"print(accuracy_score(Y_Predict, Y_test)*100)\nprint('')\nprint(confusion_matrix(Y_Predict, Y_test))\nprint('')\nprint(classification_report(Y_Predict, Y_test))","8518c227":"X = np.concatenate((X_train, X_test))\nshape = X.shape[1]\nprint('X Shape : ',X.shape)\nleft = X[:, :int(shape\/2)]\nright = X[:, int(shape\/2):]\nprint('Left Shape Before Mean : ',left.shape)\nprint('Right Shape Before Mean : ',right.shape)\nleft = np.mean(left, axis=1)\nright = np.mean(right, axis=1)\nprint('Left Shape After Mean : ',left.shape)\nprint('Right Shape After Mean : ',right.shape)\n\nY = np.concatenate((Y_train, Y_test))\nprint('Y Shape : ',Y.shape)","6b678242":"data = {\n    'Left Half' : left,\n    'Right Half' : right,\n    'Lable' : le.inverse_transform(Y)\n}\nplt.figure(figsize=(8,8))\nsns.scatterplot(data=data, x='Left Half', y='Right Half', hue='Lable')\nplt.grid(True)\nplt.show()","acab39c5":"X = []\npath = '..\/input\/urdu-language-speech-dataset\/Sad\/SM25_F34_S084.wav'\nextract_features(X, path)\ny_pre = model_SVC.predict(X)\nle.inverse_transform(y_pre)","43f6f61c":"**Features Using For Classification.**\n1. Mcc \n2. chroma_stft\n3. chroma_cqt\n4. tonnetz\n5. melspectrogram\n6. spectral_centroid\n7. spectral_contrast","34bea94d":"## For Sad > SM25_F34_S084.wav"}}