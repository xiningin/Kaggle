{"cell_type":{"fb4172fa":"code","9621b9de":"code","5cfd0270":"code","43f92d75":"code","445b7067":"code","3bb4c47b":"code","d48e5044":"code","1dfe0ac0":"code","f8140b32":"code","73d2c170":"markdown","c7c35f51":"markdown","913112b4":"markdown","122f5bd8":"markdown","b3d05c1d":"markdown","65b51d54":"markdown","fe031f85":"markdown","1c362c13":"markdown"},"source":{"fb4172fa":"import numpy as np \nimport pandas as pd \nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA, TruncatedSVD\nimport matplotlib.patches as mpatches\nimport time\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport collections\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import NearMiss\nfrom imblearn.metrics import classification_report_imbalanced\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\nfrom collections import Counter\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.metrics import confusion_matrix","9621b9de":"df = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\ndf.head()","5cfd0270":"sss = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n\nfor train_index, test_index in sss.split(df.drop('Class',axis=1), df['Class']):\n    print(\"Train:\", train_index, \"Test:\", test_index)\n    dftr, dfte = df.iloc[train_index], df.iloc[test_index]\n    break","43f92d75":"std_scaler = StandardScaler()\n\ndftr['scaled_amount'] = std_scaler.fit_transform(dftr['Amount'].values.reshape(-1,1))\ndfte['scaled_amount'] = std_scaler.transform(dfte['Amount'].values.reshape(-1,1))\n\ndftr['scaled_time'] = std_scaler.fit_transform(dftr['Time'].values.reshape(-1,1))\ndfte['scaled_time'] = std_scaler.transform(dfte['Time'].values.reshape(-1,1))\n\ndftr.drop(['Time','Amount'], axis=1, inplace=True)\ndfte.drop(['Time','Amount'], axis=1, inplace=True)\n","445b7067":"XXte = dfte.drop('Class',axis =1)\nyyte = dfte['Class']","3bb4c47b":"fraud_df = dftr[dftr['Class'] == 1]\nnonf_df = dftr[dftr['Class'] == 0].sample(frac=1)[:len(fraud_df)]\nnordis_df = pd.concat([fraud_df, nonf_df]).sample(frac=1, random_state=42)\n\nprint('positive\/number of sample:',nordis_df.Class.sum()\/len(nordis_df))\nX = nordis_df.drop('Class',axis =1)\ny = nordis_df['Class']","d48e5044":"X, y = dftr.drop('Class',axis =1),dftr['Class']","1dfe0ac0":"log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n\ngrid_log_reg = GridSearchCV(LogisticRegression(), log_reg_params, scoring = 'f1')\ngrid_log_reg.fit(X, y)\n\nclassifier = grid_log_reg.best_estimator_\nprint('Logistic Regression')\nprint('cross val scores on train set:',cross_val_score(classifier, X, y, cv=5, scoring = 'f1'))\nprint('-------------'*5)\nprint('-------------'*5)\nprint('result on imbalance test set(original)')\nypre = classifier.predict(XXte)\nprint(classification_report(yyte,ypre))\nprint('confusion matrix')\nprint(confusion_matrix(yyte,ypre))","f8140b32":"# log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n\n# grid_log_reg = GridSearchCV(LogisticRegression(), log_reg_params, scoring = 'f1')\n# grid_log_reg.fit(X, y)\n\n# classifier = grid_log_reg.best_estimator_\n# print('Logistic Regression')\n# print('cross val scores on train set:',cross_val_score(classifier, X, y, cv=5))\n# print('-------------'*5)\n# print('-------------'*5)\n# print('result on imbalance test set(original)')\n# ypre = classifier.predict(XXte)\n# print(classification_report(yyte,ypre))\n# print('confusion matrix')\n# print(confusion_matrix(yyte,ypre))\n\n# knears_params = {\"n_neighbors\": list(range(2,5,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n\n# grid_knears = GridSearchCV(KNeighborsClassifier(), knears_params, scoring = 'f1')\n# grid_knears.fit(X, y)\n# # KNears best estimator\n# knears_neighbors = grid_knears.best_estimator_\n\n# classifier = knears_neighbors\n# print('-------------'*5)\n# print('-------------'*5)\n# print('Knear')\n# print('cross val scores on train set:',cross_val_score(classifier, X, y, cv=5))\n# print('-------------'*5)\n# print('-------------'*5)\n# print('result on imbalance test set(original)')\n# ypre = classifier.predict(XXte)\n# print(classification_report(yyte,ypre))\n# print('confusion matrix')\n# print(confusion_matrix(yyte,ypre))\n\n\n# svc_params = {'C': [0.5, 0.7, 0.9, 1], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear']}\n# grid_svc = GridSearchCV(SVC(), svc_params, scoring = 'f1')\n# grid_svc.fit(X, y)\n\n# # SVC best estimator\n# svc = grid_svc.best_estimator_\n\n# classifier = svc\n# print('-------------'*5)\n# print('-------------'*5)\n# print('SVC')\n# print('cross val scores on train set:',cross_val_score(classifier, X, y, cv=5))\n# print('-------------'*5)\n# print('-------------'*5)\n# print('result on imbalance test set(original)')\n# ypre = classifier.predict(XXte)\n# print(classification_report(yyte,ypre))\n# print('confusion matrix')\n# print(confusion_matrix(yyte,ypre))\n\n# tree_params = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,4,1)), \n#               \"min_samples_leaf\": list(range(5,7,1))}\n# grid_tree = GridSearchCV(DecisionTreeClassifier(), tree_params, scoring = 'f1')\n# grid_tree.fit(X, y)\n\n# # tree best estimator\n# tree_clf = grid_tree.best_estimator_\n\n# classifier = tree_clf\n# print('-------------'*5)\n# print('-------------'*5)\n# print('Tree')\n# print('cross val scores on train set:',cross_val_score(classifier, X, y, cv=5))\n# print('-------------'*5)\n# print('-------------'*5)\n# print('result on imbalance test set(original)')\n# ypre = classifier.predict(XXte)\n# print(classification_report(yyte,ypre))\n# print('confusion matrix')\n# print(confusion_matrix(yyte,ypre))","73d2c170":"1. First split train\/test set proportionally","c7c35f51":"Fraud detection \n\nsteps:\n\n1.train\/test splitting \n\n2.train set undersampling\n\n3.classifiers trained on train set, evaluated on test set","913112b4":"6.train classifier and evaluate on imbalance test set","122f5bd8":"4. undersample train set","b3d05c1d":"3. Make test set, this is imbalance and the final criterion evaluating a classifier","65b51d54":"2. standardlize train set and then transform test set","fe031f85":"5. reduce dimensionality to visulize the data","1c362c13":"(1) Logistic Regression\n\n(2) Knear\n\n(3) SVC\n\n(4) Decision Tree"}}