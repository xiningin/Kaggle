{"cell_type":{"c78c7066":"code","40f05364":"code","c986a4cc":"code","f86e6fa8":"code","16e97751":"code","90dd8f51":"code","1fa4c3e6":"code","802e8c73":"code","5b7a0404":"code","0b7ed78f":"code","7da5aff9":"code","dee9888b":"code","c4c65a23":"code","133404b5":"code","5d58710f":"code","2de51b6a":"code","e362d9f6":"code","9cb15259":"code","4a83ca14":"code","380a0053":"code","2b8cbfc6":"code","ef95bf84":"code","38ece2ec":"code","99d91bb9":"code","9fc3cbce":"code","2a0e16e3":"code","25151814":"code","99cd6967":"code","de847421":"code","2eb76b7f":"code","80eaeb9c":"code","0047491b":"code","3026f9de":"code","2477411b":"code","875b6079":"code","3406217a":"code","60dc5a49":"code","667ccb94":"code","87eec475":"code","51930137":"code","f09cca86":"code","de9d1efa":"code","a6fb19c6":"code","64112acb":"code","41c11bf4":"code","b043e1f1":"code","ddd51c1f":"code","2b46be59":"code","8eaca00a":"code","de25e8b0":"code","fced6d0f":"code","38ecc900":"code","70a2ed1d":"code","43449441":"code","2be8a08e":"code","b79ccafc":"code","37093b0b":"code","7363082a":"code","e74ac38b":"code","fb9780ec":"code","7189f196":"code","f55a1440":"code","9eca2fa7":"markdown","2ec249ad":"markdown","4a9931a5":"markdown","82bf99ad":"markdown","f9be269e":"markdown","d6de1cc5":"markdown","d31c2005":"markdown","e3530a31":"markdown","7b04ff13":"markdown","75a6706d":"markdown","b2968bf4":"markdown","0fa5b618":"markdown","c62b0082":"markdown","8fe672c3":"markdown","95719384":"markdown"},"source":{"c78c7066":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","40f05364":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport json\nimport gc\nimport sys\nimport math\n\nfrom pandas.io.json import json_normalize\nfrom datetime import datetime\n\nfrom sklearn.metrics import mean_squared_error\nimport time\nfrom pandas.core.common import SettingWithCopyWarning\nimport warnings\nimport lightgbm as lgb\nfrom sklearn.model_selection import GroupKFold\n\n# I don't like SettingWithCopyWarnings ...\nwarnings.simplefilter('error', SettingWithCopyWarning)\ngc.enable()\n%matplotlib inline","c986a4cc":"gc.enable()\n\nfeatures = ['channelGrouping', 'date', 'fullVisitorId', 'visitId',\\\n       'visitNumber', 'visitStartTime', 'device.browser',\\\n       'device.deviceCategory', 'device.isMobile', 'device.operatingSystem',\\\n       'geoNetwork.city', 'geoNetwork.continent', 'geoNetwork.country',\\\n       'geoNetwork.metro', 'geoNetwork.networkDomain', 'geoNetwork.region',\\\n       'geoNetwork.subContinent', 'totals.bounces', 'totals.hits',\\\n       'totals.newVisits', 'totals.pageviews', 'totals.transactionRevenue',\\\n       'trafficSource.adContent', 'trafficSource.campaign',\\\n       'trafficSource.isTrueDirect', 'trafficSource.keyword',\\\n       'trafficSource.medium', 'trafficSource.referralPath',\\\n       'trafficSource.source', 'customDimensions']\n\n","f86e6fa8":"def load_df(csv_path):\n    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n    ans = pd.DataFrame()\n    dfs = pd.read_csv(csv_path, sep=',',\n            converters={column: json.loads for column in JSON_COLUMNS}, \n            dtype={'fullVisitorId': 'str'}, # Important!!\n            chunksize=100000)\n    for df in dfs:\n        df.reset_index(drop=True, inplace=True)\n        for column in JSON_COLUMNS:\n            column_as_df = json_normalize(df[column])\n            column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n            df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n\n        #print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n        use_df = df[features]\n        del df\n        gc.collect()\n        ans = pd.concat([ans, use_df], axis=0).reset_index(drop=True)\n        #print(ans.shape)\n    return ans","16e97751":"%%time\ntrain = load_df('\/kaggle\/input\/ga-customer-revenue-prediction\/train_v2.csv')\ntest = load_df('\/kaggle\/input\/ga-customer-revenue-prediction\/test_v2.csv')\n\nprint('train date:', min(train['date']), 'to', max(train['date']))\nprint('test date:', min(test['date']), 'to', max(test['date']))","90dd8f51":"train.describe()","1fa4c3e6":"list(train.columns.values)\n","802e8c73":"train.shape\n","5b7a0404":"test.shape","0b7ed78f":"list(test.columns.values)","7da5aff9":"train.head()","dee9888b":"test.head()","c4c65a23":"# code chunk that I saw in Gabriel Preda kernel\ndef missing_values(data):\n    total = data.isnull().sum().sort_values(ascending = False) # getting the sum of null values and ordering\n    percent = (data.isnull().sum() \/ data.isnull().count() * 100 ).sort_values(ascending = False) #getting the percent and order of null\n    df = pd.concat([total, percent], axis=1, keys=['Total', 'Percent']) # Concatenating the total and percent\n    print(\"Total columns at least one Values: \")\n    print (df[~(df['Total'] == 0)]) # Returning values of nulls different of 0\n    \n    print(\"\\n Total of Sales % of Total: \", round((train[train['totals.transactionRevenue'] != np.nan]['totals.transactionRevenue'].count() \/ len(train['totals.transactionRevenue']) * 100),4))\n    \n    return ","133404b5":"# calling the missing values function\nmissing_values(train) ","5d58710f":"# only train feature\nfor c in train.columns.values:\n    if c not in test.columns.values: print(c)","2de51b6a":"train['totals.transactionRevenue'].fillna(0, inplace=True)\ntrain['totals.transactionRevenue'] = np.log1p(train['totals.transactionRevenue'].astype(float))\nprint(train['totals.transactionRevenue'].describe())","e362d9f6":"test['totals.transactionRevenue'] = np.nan","9cb15259":"all_data = train.append(test, sort=False).reset_index(drop=True)","4a83ca14":"print(all_data.info())","380a0053":"null_cnt = train.isnull().sum().sort_values()\nprint(null_cnt[null_cnt > 0])","2b8cbfc6":"for col in ['trafficSource.keyword',\n            'trafficSource.referralPath',\n            'trafficSource.adContent']:\n    all_data[col].fillna('unknown', inplace=True)\n\n# fillna numeric feature\nall_data['totals.pageviews'].fillna(1, inplace=True)\nall_data['totals.newVisits'].fillna(0, inplace=True)\nall_data['totals.bounces'].fillna(0, inplace=True)\nall_data['totals.pageviews'] = all_data['totals.pageviews'].astype(int)\nall_data['totals.newVisits'] = all_data['totals.newVisits'].astype(int)\nall_data['totals.bounces'] = all_data['totals.bounces'].astype(int)\n\n# fillna boolean feature\nall_data['trafficSource.isTrueDirect'].fillna(False, inplace=True)","ef95bf84":"# drop constant column\nconstant_column = [col for col in all_data.columns if all_data[col].nunique() == 1]\n#for c in constant_column:\n#    print(c + ':', train[c].unique())\n\nprint('drop columns:', constant_column)\nall_data.drop(constant_column, axis=1, inplace=True)","38ece2ec":"# pickup any visitor\nall_data[all_data['fullVisitorId'] == '7813149961404844386'].sort_values(by='visitNumber')[\n    ['date','visitId','visitNumber','totals.hits','totals.pageviews']].head(20)","99d91bb9":"train_rev = train[train['totals.transactionRevenue'] > 0].copy()\nprint(len(train_rev))\ntrain_rev.head()","9fc3cbce":"def plotCategoryRateBar(a, b, colName, topN=np.nan):\n    if topN == topN: # isNotNan\n        vals = b[colName].value_counts()[:topN]\n        subA = a.loc[a[colName].isin(vals.index.values), colName]\n        df = pd.DataFrame({'All':subA.value_counts() \/ len(a), 'Revenue':vals \/ len(b)})\n    else:\n        df = pd.DataFrame({'All':a[colName].value_counts() \/ len(a), 'Revenue':b[colName].value_counts() \/ len(b)})\n    df.sort_values('Revenue').plot.barh(colormap='jet')","2a0e16e3":"print('unique customDimensions count:', train['customDimensions'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'customDimensions')","25151814":"format_str = '%Y%m%d'\nall_data['formated_date'] = all_data['date'].apply(lambda x: datetime.strptime(str(x), format_str))\nall_data['_year'] = all_data['formated_date'].apply(lambda x:x.year)\nall_data['_month'] = all_data['formated_date'].apply(lambda x:x.month)\nall_data['_quarterMonth'] = all_data['formated_date'].apply(lambda x:x.day\/\/8)\nall_data['_day'] = all_data['formated_date'].apply(lambda x:x.day)\nall_data['_weekday'] = all_data['formated_date'].apply(lambda x:x.weekday())\n\nall_data.drop(['date','formated_date'], axis=1, inplace=True)","99cd6967":"plotCategoryRateBar(all_data, train_rev, 'channelGrouping')\n","de847421":"print('train all:', len(train))\nprint('train unique fullVisitorId:', train['fullVisitorId'].nunique())\nprint('train unique visitId:', train['visitId'].nunique())\nprint('-' * 30)\nprint('test all:', len(test))\nprint('test unique fullVisitorId:', test['fullVisitorId'].nunique())\nprint('test unique visitId:', test['visitId'].nunique())\n\n#print('common fullVisitorId:', len(pd.merge(train, test, how='inner', on='fullVisitorId'))) # 183434","2eb76b7f":"print(all_data['visitNumber'].value_counts()[:5])\nprint('-' * 30)\nprint(all_data['totals.newVisits'].value_counts())\nprint('-' * 30)\nprint(all_data['totals.bounces'].value_counts())","80eaeb9c":"all_data['_visitStartHour'] = all_data['visitStartTime'].apply(\n    lambda x: str(datetime.fromtimestamp(x).hour))","0047491b":"print('unique browser count:', train['device.browser'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'device.browser', 10)\n","3026f9de":"pd.crosstab(all_data['device.deviceCategory'], all_data['device.isMobile'], margins=False)\n\nall_data['isMobile'] = True\nall_data.loc[all_data['device.deviceCategory'] == 'desktop', 'isMobile'] = False","2477411b":"print('unique operatingSystem count:', train['device.operatingSystem'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'device.operatingSystem', 10)","875b6079":"print('unique geoNetwork.city count:', train['geoNetwork.city'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'geoNetwork.city', 10)","3406217a":"print('unique geoNetwork.region count:', train['geoNetwork.region'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'geoNetwork.region', 10)","60dc5a49":"print('unique geoNetwork.subContinent count:', train['geoNetwork.subContinent'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'geoNetwork.subContinent', 10)","667ccb94":"print('unique geoNetwork.continent count:', train['geoNetwork.continent'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'geoNetwork.continent')","87eec475":"print('unique geoNetwork.metro count:', train['geoNetwork.metro'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'geoNetwork.metro', 10)","51930137":"print('unique geoNetwork.networkDomain count:', train['geoNetwork.networkDomain'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'geoNetwork.networkDomain', 10)","f09cca86":"print(all_data['totals.hits'].value_counts()[:10])\n\nall_data['totals.hits'] = all_data['totals.hits'].astype(int)","de9d1efa":"print(all_data['totals.pageviews'].value_counts()[:10])\n\nall_data['totals.pageviews'] = all_data['totals.pageviews'].astype(int)","a6fb19c6":"print('unique trafficSource.adContent count:', train['trafficSource.adContent'].nunique())\n\nplotCategoryRateBar(all_data, train_rev, 'trafficSource.adContent', 10)\n\nall_data['_adContentGMC'] = (all_data['trafficSource.adContent'] == 'Google Merchandise Collection').astype(np.uint8)","64112acb":"print('unique trafficSource.campaign count:', train['trafficSource.campaign'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'trafficSource.campaign', 10)\n\nall_data['_withCampaign'] = (all_data['trafficSource.campaign'] != '(not set)').astype(np.uint8)","41c11bf4":"print(all_data['trafficSource.isTrueDirect'].value_counts())\nplotCategoryRateBar(all_data, train_rev, 'trafficSource.isTrueDirect')","b043e1f1":"print('unique trafficSource.keyword count:', train['trafficSource.keyword'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'trafficSource.keyword', 10)","ddd51c1f":"print('unique trafficSource.medium count:', train['trafficSource.medium'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'trafficSource.medium')","2b46be59":"print('unique trafficSource.referralPath count:', train['trafficSource.referralPath'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'trafficSource.referralPath', 10)\n\nall_data['_referralRoot'] = (all_data['trafficSource.referralPath'] == '\/').astype(np.uint8)","8eaca00a":"print('unique trafficSource.source count:', train['trafficSource.source'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'trafficSource.source', 10)\n\nall_data['_sourceGpmall'] = (all_data['trafficSource.source'] == 'mall.googleplex.com').astype(np.uint8)","de25e8b0":"_='''\n'''\nall_data['_meanHitsPerDay'] = all_data.groupby(['_day'])['totals.hits'].transform('mean')\nall_data['_meanHitsPerWeekday'] = all_data.groupby(['_weekday'])['totals.hits'].transform('mean')\nall_data['_meanHitsPerMonth'] = all_data.groupby(['_month'])['totals.hits'].transform('mean')\nall_data['_sumHitsPerDay'] = all_data.groupby(['_day'])['totals.hits'].transform('sum')\nall_data['_sumHitsPerWeekday'] = all_data.groupby(['_weekday'])['totals.hits'].transform('sum')\nall_data['_sumHitsPerMonth'] = all_data.groupby(['_month'])['totals.hits'].transform('sum')\n\nfor feature in ['totals.hits', 'totals.pageviews']:\n    info = all_data.groupby('fullVisitorId')[feature].mean()\n    all_data['_usermean_' + feature] = all_data.fullVisitorId.map(info)\n    \nfor feature in ['visitNumber']:\n    info = all_data.groupby('fullVisitorId')[feature].max()\n    all_data['_usermax_' + feature] = all_data.fullVisitorId.map(info)\n\ndel info","fced6d0f":"all_data['_source.country'] = all_data['trafficSource.source'] + '_' + all_data['geoNetwork.country']\nall_data['_campaign.medium'] = all_data['trafficSource.campaign'] + '_' + all_data['trafficSource.medium']\nall_data['_browser.category'] = all_data['device.browser'] + '_' + all_data['device.deviceCategory']\nall_data['_browser.os'] = all_data['device.browser'] + '_' + all_data['device.operatingSystem']","38ecc900":"null_cnt = all_data.isnull().sum().sort_values()\nprint(null_cnt[null_cnt > 0])","70a2ed1d":"all_data.drop(['visitId','visitStartTime'],axis=1,inplace=True)\n\nfor i, t in all_data.loc[:, all_data.columns != 'fullVisitorId'].dtypes.iteritems():\n    if t == object:\n        all_data[i].fillna('unknown', inplace=True)\n        all_data[i] = pd.factorize(all_data[i])[0]\n        #all_data[i] = all_data[i].astype('category')","43449441":"all_data.info()\n","2be8a08e":"train = all_data[all_data['totals.transactionRevenue'].notnull()]\ntest = all_data[all_data['totals.transactionRevenue'].isnull()].drop(['totals.transactionRevenue'], axis=1)","b79ccafc":"test.shape","37093b0b":"train_id = train['fullVisitorId']\ntest_id = test['fullVisitorId']\n\nY_train_reg = train.pop('totals.transactionRevenue')\n#Y_train_cls = (Y_train_reg.fillna(0) > 0).astype(np.uint8)\nX_train = train.drop(['fullVisitorId'], axis=1)\nX_test  = test.drop(['fullVisitorId'], axis=1)\n\nprint(X_train.shape, X_test.shape)","7363082a":"del all_data, train, test, train_rev\ngc.collect()\n\nprint(pd.DataFrame([[val for val in dir()], [sys.getsizeof(eval(val)) for val in dir()]],\n                   index=['name','size']).T.sort_values('size', ascending=False).reset_index(drop=True)[:10])","e74ac38b":"from sklearn.model_selection import StratifiedKFold, GroupKFold\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgb\nparams={'learning_rate': 0.01,\n        'objective':'regression',\n        'metric':'rmse',\n        'num_leaves': 31,\n        'verbose': 1,\n        'random_state':42,\n        'bagging_fraction': 0.6,\n        'feature_fraction': 0.6\n       }\n\nfolds = GroupKFold(n_splits=5)\n\noof_preds = np.zeros(X_train.shape[0])\nsub_preds = np.zeros(X_test.shape[0])\nfor fold_, (trn_, val_) in enumerate(folds.split(X_train, Y_train_reg, groups=train_id)):\n    trn_x, trn_y = X_train.iloc[trn_], Y_train_reg.iloc[trn_]\n    val_x, val_y = X_train.iloc[val_], Y_train_reg.iloc[val_]\n    \n    reg = lgb.LGBMRegressor(**params, n_estimators=3000)\n    reg.fit(trn_x, trn_y, eval_set=[(val_x, val_y)], early_stopping_rounds=50, verbose=500)\n    \n    oof_preds[val_] = reg.predict(val_x, num_iteration=reg.best_iteration_)\n    sub_preds += reg.predict(X_test, num_iteration=reg.best_iteration_) \/ folds.n_splits\n\npred = sub_preds","fb9780ec":"# Plot feature importance\nfeature_importance = reg.feature_importances_\nfeature_importance = 100.0 * (feature_importance \/ feature_importance.max())\nsorted_idx = np.argsort(feature_importance)\nsorted_idx = sorted_idx[len(feature_importance) - 30:]\npos = np.arange(sorted_idx.shape[0]) + .5\n\nplt.figure(figsize=(12,8))\nplt.barh(pos, feature_importance[sorted_idx], align='center')\nplt.yticks(pos, X_train.columns[sorted_idx])\nplt.xlabel('Relative Importance')\nplt.title('Variable Importance')\nplt.show()","7189f196":"submission = pd.DataFrame({'fullVisitorId':test_id, 'PredictedLogRevenue':pred})\n\nsubmission[\"PredictedLogRevenue\"] = np.expm1(submission[\"PredictedLogRevenue\"])\nsubmission[\"PredictedLogRevenue\"] = submission[\"PredictedLogRevenue\"].apply(lambda x : 0.0 if x < 0 else x)\nsubmission[\"PredictedLogRevenue\"] = submission[\"PredictedLogRevenue\"].fillna(0.0)\n\nsubmission_sum = submission[['fullVisitorId', 'PredictedLogRevenue']].groupby('fullVisitorId').sum().reset_index()\nsubmission_sum[\"PredictedLogRevenue\"] = np.log1p(submission_sum[\"PredictedLogRevenue\"])\nsubmission_sum.to_csv(\"submission.csv\", index=False)\nsubmission_sum.head(20)","f55a1440":"submission_sum['PredictedLogRevenue'].describe()\n","9eca2fa7":"**Problem Statement**\n\nThe 80\/20 rule has proven true for many businesses\u2013only a small percentage of customers produce most of the revenue. As such, marketing teams are challenged to make appropriate investments in promotional strategies.\n\n**GStore**\n\nRStudio, the developer of free and open tools for R and enterprise-ready products for teams to scale and share work, has partnered with Google Cloud and Kaggle to demonstrate the business impact that thorough data analysis can have.\n\nIn this kaggle competition,we are challenged to analyze a Google Merchandise Store (also known as GStore, where Google swag is sold) customer dataset to predict revenue per customer.\n\n**File Descriptions**\n\ntrain.csv - the training set - contains the same data as the BigQuery rstudio_train_set.\ntest.csv - the test set - contains the same data as the BigQuery rstudio_test_set.\nsampleSubmission.csv - a sample submission file in the correct format. Contains all fullVisitorIds in test.csv.\n\n**Data Fields**\n\nfullVisitorId- A unique identifier for each user of the Google Merchandise Store.\n\nchannelGrouping - The channel via which the user came to the Store.\n\ndate - The date on which the user visited the Store.\n\ndevice - The specifications for the device used to access the Store.\n\ngeoNetwork - This section contains information about the geography of the user.\n\nsessionId - A unique identifier for this visit to the store.\n\nsocialEngagementType - Engagement type, either \"Socially Engaged\" or \"Not Socially Engaged\".\n\ntotals - This section contains aggregate values across the session.\n\ntrafficSource - This section contains information about the Traffic Source from which the session originated.\n\nvisitId - An identifier for this session. This is part of the value usually stored as the _utmb cookie. \nThis is only unique to the user. For a completely unique ID, we should use a combination of fullVisitorId and visitId.\n\nvisitNumber - The session number for this user. If this is the first session, then this is set to 1.\n\nvisitStartTime - The timestamp (expressed as POSIX time).","2ec249ad":"**Google Analytics Customer Revenue Prediction\n**","4a9931a5":"**Prediction**","82bf99ad":"**Objectives:**\n1- I will explore if we have some difference between the browser and if browser is significant to predict sells. \n\n2- Which countrys and continents have more acesses and sales ? How it's distributed?!\n\n3- Which type of device are most normal in our dataset?\n\n4- What's the mobile % of accesses? \n\n5- Which is the most frequent Operational System? \n\n6- What's the most frequent channelGrouping ?\n\n7- Whats the most frequent Weekdays, months, days, year with highest accesses and revenue?\n\nAnd another bunch of ideas that I will have when start exploring.","f9be269e":"**ChannelGrouping\n\nThe channel via which the user came to the Store.**","d6de1cc5":"**fullVisitorId**\n\nA unique identifier for each user of the Google Merchandise Store.\n\n**visitId**\n\nAn identifier for this session. This is part of the value usually stored as the _utmb cookie. This is only unique to the user.\n\nFor a completely unique ID, you should use a combination of fullVisitorId and visitId.\n\n\n**newVisits**","d31c2005":"**Aggregate**","e3530a31":"**trafficSource**","7b04ff13":"**Date**","75a6706d":"**Knowing the missing values\u00b6**","b2968bf4":"**geoNetwork**","0fa5b618":"***Device***","c62b0082":"**Custom Dimensions**","8fe672c3":"**totals**","95719384":"**Select feature **"}}