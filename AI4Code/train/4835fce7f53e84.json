{"cell_type":{"038a0b02":"code","06e13c3c":"code","04fdb2fb":"code","df3c4112":"code","1b145ab1":"code","f2244384":"code","b9d9acd8":"code","0f7e90ae":"code","7c53d069":"code","ee17084d":"code","1307a8b4":"code","809026a8":"code","72cfb449":"markdown","8a993b57":"markdown","914fd9a6":"markdown","889556be":"markdown","a690f8e6":"markdown","f559e673":"markdown","1285c613":"markdown","1df3246c":"markdown","c3f20009":"markdown","83cb8fd8":"markdown","5328a19e":"markdown","5bea272c":"markdown","579666d7":"markdown"},"source":{"038a0b02":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# Any results you write to the current directory are saved as output.","06e13c3c":"fnc = pd.read_csv(\"\/kaggle\/input\/trends-assessment-prediction\/fnc.csv\")\nfnc","04fdb2fb":"sample_submission = pd.read_csv(\"\/kaggle\/input\/trends-assessment-prediction\/sample_submission.csv\")\nsample_submission.head()","df3c4112":"loading = pd.read_csv(\"\/kaggle\/input\/trends-assessment-prediction\/loading.csv\")\nloading.head()","1b145ab1":"train_scores = pd.read_csv(\"\/kaggle\/input\/trends-assessment-prediction\/train_scores.csv\")\ntrain_scores.fillna(train_scores.mean(),inplace=True)","f2244384":"df_merge = fnc.merge(loading,on='Id')\ndf_merge","b9d9acd8":"train = train_scores.merge(df_merge,on='Id').drop(['age','domain1_var1','domain1_var2','domain2_var1','domain2_var2'],axis=1)\ntrain","0f7e90ae":"test = pd.DataFrame(sample_submission['Id'].apply(lambda x: int(x.split('_')[0]))).merge(df_merge,on='Id').drop_duplicates().reset_index(drop=True)\ntest","7c53d069":"# from tensorflow import keras\n# from tensorflow.keras.models import Sequential\n# from tensorflow.keras.layers import Dense\n# from sklearn.model_selection import KFold,cross_val_score\n\n# def my_model():\n#     model = Sequential()\n#     model.add(Dense(1404,input_dim=1404,kernel_initializer='normal',activation='relu'))\n#     model.add(Dense(702,kernel_initializer='normal',activation='relu'))\n#     model.add(Dense(5,kernel_initializer='normal'))\n    \n#     model.compile(loss='mean_absolute_error',optimizer='adam')\n#     return model\n\n# # clf = keras.wrappers.scikit_learn.KerasRegressor(build_fn=my_model,epochs=50,batch_size=125,verbose=0)\n# clf = my_model()\n# clf.fit(train.iloc[:,1:],train_scores.iloc[:,1:],epochs=25,batch_size=100,validation_split=0.25,verbose=2)\n","ee17084d":"# preds = clf.predict(test.iloc[:,1:])\n# output = pd.DataFrame(preds)\n# output.insert(0,'Id',test['Id'].apply(lambda x:str(x)))\n# output.columns = train_scores.columns\n\n# final = pd.DataFrame()\n# for col in ['age','domain1_var1','domain1_var2','domain2_var1','domain2_var2']:\n#     temp = pd.DataFrame(output['Id'].apply(lambda x:str(x)+ '_' + col))\n#     temp['Predicted'] = output[col]\n#     final = pd.concat([final,temp])\n# final.head()","1307a8b4":"from sklearn.model_selection import train_test_split\nimport lightgbm as lgb\n\nparam = {'objective':'regression',\n        'metric':'rmse',\n        'bossting_type':'gbdt',\n        'learning_rate':0.01,\n        'max_depth':-1}\n\noutput = pd.DataFrame()\n\nfor target in ['age','domain1_var1','domain1_var2','domain2_var1','domain2_var2']:\n    X_train,X_val,y_train,y_val = train_test_split(train.iloc[:,1:],train_scores[target],test_size=0.2,shuffle=True,random_state=20)\n    train_data = lgb.Dataset(X_train,label=y_train)\n    val_data = lgb.Dataset(X_val,label=y_val)\n    \n    bst = lgb.train(param,train_data,10000,early_stopping_rounds=15,valid_sets=[val_data],verbose_eval=-1)\n    \n    temp = pd.DataFrame(test['Id'].apply(lambda x:str(x)+ '_'+ target))\n    temp['Predicted'] = bst.predict(test.iloc[:,1:])\n    output = pd.concat([output,temp])\n","809026a8":"output = sample_submission.drop('Predicted',axis=1).merge(output,on='Id',how='left')\noutput.to_csv('sbumission.csv',index=False)\noutput","72cfb449":"## Combine all features into one dataframe df_merge","8a993b57":"## Load fnc (features for training)","914fd9a6":"## Load loading (features for training)","889556be":"## Load train_scores (contains true labels for the training)","a690f8e6":"### fill NaN values with mean values here, could be improved later","f559e673":"## Select all IDs that need to predict in sample_submission along with their features in df_merge","1285c613":"# Load Datasets","1df3246c":"# Output the result","c3f20009":"## Load sample_submission (IDs to predict)","83cb8fd8":"# LightGB Model","5328a19e":"## Selecting all indices in df_merge that contain true labels in train_scores, and drop all target columns","5bea272c":"# NN Model using Keras","579666d7":"## For all 5 target variables (age,domain1_var1\/2,domain2_var1\/2), train the LGB model with fixed parameters"}}