{"cell_type":{"d1f7dbb7":"code","18d0b8b5":"code","313c5133":"code","7f880012":"code","491e372e":"code","e0523087":"code","001b56ed":"code","25587691":"code","b1ab9ccc":"code","541f3d7a":"code","4a593d70":"code","3fc68ea5":"code","14a5b88a":"code","988b073a":"code","20597fc7":"code","8d75e46b":"code","e33a860a":"code","fc2e3961":"code","9ab76144":"code","af2d24cf":"code","bd6e0302":"code","1f69237f":"code","9c677a9f":"code","19a759ca":"code","c58c0020":"code","8ef1c497":"code","a032f5d7":"code","d384fa2e":"code","da9c7ee1":"code","3174cb1a":"code","5173b425":"code","7190bfdd":"code","6ecbed09":"code","fbab3209":"code","827f8432":"code","d655ba50":"code","2bf1616e":"code","229d9fe7":"code","d2ac0abe":"code","8a58cc0c":"code","a811e377":"code","8efdcf9b":"code","5e2004e5":"code","a66084d9":"code","1c500f81":"code","34c029db":"code","a15bcf14":"code","89aab8db":"code","5ec1cb9c":"code","d13b5e76":"code","8b3f589d":"code","be2e9b65":"code","999da06a":"code","457106c2":"code","81c5b5ca":"markdown","443e0f73":"markdown","0fcf09df":"markdown","9dc3c754":"markdown","3aa18084":"markdown","047627c1":"markdown","57d31161":"markdown","451474ef":"markdown","3554a73c":"markdown","a5af6fd8":"markdown","1098fc4c":"markdown","b8abcbd7":"markdown","c1e55410":"markdown","8c79c6c5":"markdown","b35f03d8":"markdown","c94896d5":"markdown","0b5e7243":"markdown","ab05ee87":"markdown","15f8521b":"markdown"},"source":{"d1f7dbb7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","18d0b8b5":"import os\nimport pandas as pd\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sns #Visualization\nfrom sklearn.linear_model import LinearRegression","313c5133":"df_class = pd.read_csv('\/kaggle\/input\/iris\/Iris.csv')\nprint('\\nNumber of rows and columns in the data set: ',df_class.shape)\nprint('')","7f880012":"print(df_class.head())","491e372e":"plt.figure(figsize=(12,4))\nsns.heatmap(df_class.isnull(),cbar=False,cmap='coolwarm',yticklabels=False)\nplt.title('Missing value in the dataset')","e0523087":"df_class.isnull().sum()","001b56ed":"print(df_class.info())","25587691":"df_class.nunique()","b1ab9ccc":"df_class.info()","541f3d7a":"# Scaling for Numerical data set\n#from sklearn.preprocessing import StandardScaler\n#sc=StandardScaler()\n#data_numerical.iloc[:,1:] =sc.fit_transform(data_numerical.iloc[:,1:])  ","4a593d70":"# Lets verify the dummay variable process\nprint('Columns in original data frame:\\n',df_class.columns.values) #original dataframe column names\nprint('\\nNumber of rows and columns in the dataset:',df_class.shape) #previous dataframe shape\n#print('\\nColumns in data frame after encoding dummy variable:\\n',df_Loan.columns.values) #original dataframe column names\n#print('\\nNumber of rows and columns in the dataset:',df_Loan.shape) #updated data frame shape","3fc68ea5":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test =train_test_split(df_class.drop(['Species'],axis=1),df_class.Species,test_size=0.30,random_state=0)# chane zero to 20,10","14a5b88a":"from sklearn.svm import SVC\nsvc_model=SVC()","988b073a":"svc_model.fit(X_train,y_train)\nsvm_pred=svc_model.predict(X_test)\n","20597fc7":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score","8d75e46b":"\ncm=confusion_matrix(y_test,svm_pred)\nprint(cm)\n\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(y_test,svm_pred))","e33a860a":"print(\"SVM  -> \",accuracy_score(y_test,svm_pred)*100)","fc2e3961":"print(confusion_matrix(y_test,svm_pred))\nprint(classification_report(y_test,svm_pred))\nprint(accuracy_score(y_test, svm_pred))","9ab76144":"from sklearn import naive_bayes\nNaive = naive_bayes.GaussianNB()","af2d24cf":"# fit the training dataset on the NB classifier\nNaive.fit(X_train,y_train)# predict the labels on validation dataset\npredictions_NB= Naive.predict(X_test)# Use accuracy_score function to get the accuracy\nprint(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, y_test)*100)","bd6e0302":"print(confusion_matrix(y_test,predictions_NB))\nprint(classification_report(y_test,predictions_NB))\nprint(accuracy_score(y_test,predictions_NB))","1f69237f":"from sklearn.neighbors import KNeighborsClassifier","9c677a9f":"knn = KNeighborsClassifier(n_neighbors=3)","19a759ca":"knn.fit(X_train, y_train)","c58c0020":"knn_pred = knn.predict(X_test)","8ef1c497":"print(\"Accuracy:\",accuracy_score(y_test, knn_pred))","a032f5d7":"print(confusion_matrix(y_test,knn_pred))\nprint(classification_report(y_test,knn_pred))\nprint(accuracy_score(y_test,knn_pred))\nprint('erroe')\n\nprint(1-accuracy_score(y_test,knn_pred))","d384fa2e":"from sklearn.tree import DecisionTreeClassifier","da9c7ee1":"dtc = DecisionTreeClassifier()","3174cb1a":"# Train Decision Tree Classifer\ndtc.fit(X_train,y_train)\n\n#Predict the response for test dataset\ndtc_pred = dtc.predict(X_test)","5173b425":"print(confusion_matrix(y_test,dtc_pred))\nprint(classification_report(y_test,dtc_pred))\nprint(accuracy_score(y_test,dtc_pred))","7190bfdd":"from sklearn.ensemble import RandomForestClassifier, VotingClassifier","6ecbed09":"voting_clf = VotingClassifier(estimators=[('SVC', SVC()), ('DTree', dtc), ('NaiveBayes', Naive),('KNN',knn)], voting='hard')\nvoting_clf.fit(X_train, y_train)\n\n","fbab3209":"preds = voting_clf.predict(X_test)","827f8432":"print(confusion_matrix(y_test,preds))\nprint(classification_report(y_test,preds))\nprint(accuracy_score(y_test,preds))\nprint('error')\nprint(1-accuracy_score(y_test,preds))","d655ba50":"random_forest = RandomForestClassifier(n_estimators=10, random_state=12)","2bf1616e":"random_forest.fit(X_train,y_train)","229d9fe7":"rf=random_forest.predict(X_test)","d2ac0abe":"print(confusion_matrix(y_test,rf))\nprint(classification_report(y_test,rf))\nprint(accuracy_score(y_test,rf))\nprint('error')\nprint(1-accuracy_score(y_test,rf))","8a58cc0c":"from sklearn.model_selection import KFold\n#kf=KFold(n_splits=5,shuffle=True)","a811e377":"kf=KFold(n_splits=10,shuffle=True)","8efdcf9b":"data=df_class.drop(['Species'],axis=1)\nprint(data.head)","5e2004e5":"plt.figure(figsize=(12,4))\nsns.heatmap(data.isnull(),cbar=False,cmap='coolwarm',yticklabels=False)\nplt.title('Missing value in the dataset')","a66084d9":"rf_k=RandomForestClassifier(n_estimators=10)","1c500f81":"from sklearn.model_selection import cross_val_score\nacc_rf=cross_val_score(rf_k,data,df_class.Species,scoring='accuracy',cv=10)","34c029db":"print(acc_rf.mean())\nprint('error')\nprint(1-(acc_rf.mean()))\n","a15bcf14":"\narray=[10,20,40,60,80,100]\nfor i in range(0,6):\n  random_forest = RandomForestClassifier(n_estimators=array[i])\n  random_forest.fit(X_train,y_train)\n  rf_predict=random_forest.predict(X_test)\n  print('Accuracy of Rain Forest when estimate is ',array[i], ' : ',accuracy_score(y_test,rf_predict))","89aab8db":"k_folds = KFold(n_splits=20,shuffle=True)","5ec1cb9c":"from sklearn.ensemble import AdaBoostClassifier\nada_boost = AdaBoostClassifier(n_estimators=10, random_state=12)","d13b5e76":"results = cross_val_score(ada_boost, X_train, y_train, cv=k_folds)","8b3f589d":"print(results.mean()*100)","be2e9b65":"ada_boost.fit(X_train,y_train)\nada_predict=ada_boost.predict(X_test)","999da06a":"print(confusion_matrix(y_test,ada_predict))\nprint(classification_report(y_test,ada_predict))\nprint(accuracy_score(y_test,ada_predict))\nprint('error')\nprint(1-accuracy_score(y_test,ada_predict))","457106c2":"array=[10,20,40,60,80,100]\nfor i in range(0,6):\n  ada_boost = AdaBoostClassifier(n_estimators=array[i], random_state=12)\n  ada_boost.fit(X_train,y_train)\n  ada_predict=ada_boost.predict(X_test)\n  print('Accuracy when estimate is ',array[i], ' : ',accuracy_score(y_test,ada_predict))","81c5b5ca":"<h3>Bagging<\/h3>","443e0f73":"**Confusion matrix** and **Accuracy** score","0fcf09df":"**Classification Report**","9dc3c754":"<h3>Stacking<\/h3>","3aa18084":"<H1> ENSEMBLE <H1>","047627c1":"<h1> Decision Tree <h1>","57d31161":"Try KNN model with different number of K and perform evaluation.","451474ef":"<h2>Voting Classifier<\/h2>","3554a73c":"Find the sum of null values in each feature\/column","a5af6fd8":"Check the features will null using heat map","1098fc4c":"<h1>Classification<\/h1>","b8abcbd7":"Importing **evaluation** libraries","c1e55410":"<h1>Naive Bayes<\/h1>","8c79c6c5":"<h2> Random Forest Classifier<\/h2>","b35f03d8":"<h3> Boosting<\/h3>","c94896d5":"Distributing data in **training and testing**\n","0b5e7243":"Importing SVM and creating the model","ab05ee87":"<h1>SUPPORT VECTOR CLASSIFIER<\/h1>\nCreating the **SVM model** and run prediction on testing data","15f8521b":"<h1>K-nearest Neighbour<h1>"}}