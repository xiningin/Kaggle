{"cell_type":{"9e0b4156":"code","996ba137":"code","0bcc5f7e":"code","0752d0c3":"code","9e5132aa":"code","5c792d76":"code","05dcb963":"code","7e9eda60":"code","41f36ea1":"code","c4997907":"code","a440c1bc":"code","88af4d4a":"code","43d5491d":"code","23a9f493":"code","dfc4b1f0":"code","a6b674e9":"code","84cb20d7":"code","79f9532f":"code","b5ce0190":"code","6d0ef509":"code","1b6dac1a":"code","4e1ba3fb":"code","522bf2e3":"code","08878aff":"code","5a314f45":"code","82c93612":"code","58202c65":"code","1f695b6c":"code","046063f5":"code","4e40fd92":"code","ab9b318c":"code","8e9f0cc2":"code","b70db56f":"code","54b7bceb":"code","d2b34864":"code","26a11df5":"code","dd661091":"code","47d610e2":"code","2d364160":"code","c9c507b9":"code","164da836":"code","8db43a09":"code","21499a24":"code","b4a5024c":"markdown","72277e44":"markdown","cd9985b5":"markdown","b61aef78":"markdown","b9e0c459":"markdown","829612b4":"markdown","d94b76d5":"markdown","e1c4a336":"markdown","a563f5b6":"markdown","06094861":"markdown","e5202577":"markdown","826c2f37":"markdown","662a8afd":"markdown","b7214eaf":"markdown","c71a862a":"markdown","c17770f0":"markdown"},"source":{"9e0b4156":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","996ba137":"# importing all the required libreries\nimport numpy as np\nimport pandas as pd\nfrom scipy.stats import skew\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","0bcc5f7e":"# loading the dataset\ndf = pd.read_csv('..\/input\/the-boston-houseprice-data\/boston.csv')","0752d0c3":"df.head()","9e5132aa":"# peaking at the diffrent labels in the dataset\n\ndf.columns","5c792d76":"# checking the number of rows and columns of the dataset\n\ndf.shape ","05dcb963":"# checking for duplicate data\n\ndf.duplicated().sum() ","7e9eda60":"# getting the information about dataframe\n\ndf.info() ","41f36ea1":"# checking for columns which has null values\n\ndf.isnull().sum()","c4997907":"# correlation using heatmap\n\nplt.figure(figsize=(10,8))\nsns.heatmap(df.corr(), annot = True)","a440c1bc":"# correlation matrix\n\ncorrelation=df.corr()\n\n# correlation with price\n\ncorrelation[\"MEDV\"].sort_values(ascending=False)","88af4d4a":"# correlation using scatter matrix\n\nfrom pandas.plotting import scatter_matrix \nattributes = [\"MEDV\",\"LSTAT\",\"RM\",\"PTRATIO\",\"INDUS\",\"TAX\"]\nsns.pairplot(df[attributes],kind=\"scatter\")","43d5491d":"# plotting RM vs MEDV\n\nsns.scatterplot(x=\"RM\", y=\"MEDV\", data=df)","23a9f493":"# plotting LSTAT vs MEDV\n\nsns.scatterplot(x=\"LSTAT\", y=\"MEDV\", data=df)","dfc4b1f0":"df.head()","a6b674e9":"# plotting to see which column has the most skewness\n\ncol_name = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n        'PTRATIO', 'B', 'LSTAT', 'MEDV']\nskw = []\nfor col in df:\n    skw.append(skew(df[col]))\nnew_df = pd.DataFrame({\"Column\":col_name,\"Skew\":skw})\nplt.figure(figsize=(15,7))\nsns.scatterplot(data=new_df, x=\"Column\", y=\"Skew\")\nplt.show()","84cb20d7":"# analysing which column has low correlation and high skewness\n\nnew_df['Correlation'] = correlation[\"MEDV\"].tolist()\nnew_df.sort_values(by='Correlation',ascending=False)","79f9532f":"# defining a function for plotting the histograms\n\ndef hst(dfrm):    \n    sns.set_palette(\"pastel\")\n    sns.histplot(data=dfrm)\n    plt.title(\"Skewness\")\n    plt.show()","b5ce0190":"# plotting for the features whose skewness we are going to modify \n\nhst(df[\"CHAS\"]) \nhst(df[\"ZN\"]) \nhst(df[\"B\"]) \nhst(df[\"DIS\"]) \nhst(df[\"AGE\"]) ","6d0ef509":"# Since CHAS has only 2 types of values\n# Lets modify the skewness of +vely skewed ZN and DIS\n\ndf[\"ZN\"] = np.log1p(df[\"ZN\"])\ndf[\"DIS\"] = np.log1p(df[\"DIS\"])\n\nskew(df[\"ZN\"]), skew(df[\"DIS\"])","1b6dac1a":"#checking the skewness of AGE squared\n\nskew(np.square(df[\"AGE\"]))","4e1ba3fb":"df[\"AGE\"] = np.square(df[\"AGE\"])","522bf2e3":"skew(np.power(df[\"B\"],9))","08878aff":"# Removing the column B\n\ndf.drop('B', inplace=True, axis=1)","5a314f45":"df.head()","82c93612":"X = df.drop(columns=[\"MEDV\"],axis=1)\ny = df[\"MEDV\"]","58202c65":"from sklearn.preprocessing import StandardScaler\n\nfor col in X:\n    ss = StandardScaler()\n    df[col] = ss.fit_transform(X[[col]])","1f695b6c":"X.shape, y.shape","046063f5":"from sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error","4e40fd92":"# Performing train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y,train_size=0.8,random_state=42)","ab9b318c":"# creating the object\n\nmodel = LinearRegression()","8e9f0cc2":"# creating the object\n\nmodel.fit(X_train,y_train)","b70db56f":"# finding the accuracy\n\nacr = model.score(X_test,y_test)*100\nacr","54b7bceb":"# finding the Root Mean Squared Error\n\ny_predict = model.predict(X_test) \nrmse= np.sqrt(mean_squared_error(y_predict,y_test))\nrmse","d2b34864":"from sklearn.ensemble import RandomForestRegressor\n\n# creating the object\n\nmodel1 = RandomForestRegressor()","26a11df5":"# fitting the training values\n\nmodel1.fit(X_train,y_train)","dd661091":"# finding the accuracy\n\nacr1 = model1.score(X_test,y_test)*100\nacr1","47d610e2":"# finding the Root Mean Squared Error\n\ny_predict1 = model1.predict(X_test)\nrmse1 = np.sqrt(mean_squared_error(y_predict1,y_test))\nrmse1","2d364160":"from sklearn.tree import DecisionTreeRegressor\n\n# creating the object\n\nmodel2 = DecisionTreeRegressor()","c9c507b9":"# fitting the training values\n\nmodel2.fit(X_train,y_train)","164da836":"# finding the accuracy\n\nacr2 = model2.score(X_test,y_test)*100","8db43a09":"# finding the Root Mean Squared Error\n\ny_predict2=model2.predict(X_test)\nrmse2= np.sqrt(mean_squared_error(y_predict2,y_test))\nrmse2","21499a24":"rslt=pd.DataFrame({\n    \"Model used\" : ['Linear Regression','Random Forest' ,'Decision Tree'],\n    \"RMSE\" :[rmse,rmse1,rmse2],\n    \"Accuracy(%)\":[acr,acr1,acr2]\n})\n\nrslt.sort_values(\"Accuracy(%)\", ascending=False)","b4a5024c":"# **House Price Prediction**","72277e44":"> ***From the above we see that the negetive skewness of AGE column can be impoved***","cd9985b5":"# Result\/Outcome","b61aef78":"> ***Hear we can see that RM, LSTAT and PRRATIO have a strong correlation with MEDV(PRICE)***","b9e0c459":"> ***So the columns whose skew scymmetry we should improve are***\n> - ***CHAS -> Because very highly skewed and less correlated with MEDV***\n> - ***ZN -> Because highly skewed and less correlated with MEDV***\n> - ***B -> Because highly skewed and less correlated with MEDV***\n> - ***DIS-> Because highly skewed and less correlated with MEDV***\n> - ***AGE-> Because highly skewed and less correlated with MEDV***","829612b4":"> ***From the above we can see that some of the features are highly skewed***\n\n> ***But we should improve the skew scymmetry of only some of them keeping in mind\nof their correlation with MEDV.***\n\n> ***So, when is the skewness too much?  The rule of thumb seems to be:***\n> - ***If the skewness is between -0.5 and 0.5, the data are fairly symmetrical***\n> - ***If the skewness is between -1 and \u2013 0.5 or between 0.5 and 1, the data are moderately skewed***\n> - ***If the skewness is less than -1 or greater than 1, the data are highly skewed.***\n\n\n> ***So from this we can conclude that taking the square root gives us a semmetric skew \nand since we have all +ve values in MEDV column, we can say that a square root transformation would be appropriate.***\n\n\n> ***Check [hear](https:\/\/stats.stackexchange.com\/questions\/107610\/what-is-the-reason-the-log-transformation-is-used-with-right-skewed-distribution) or [hear](https:\/\/www.spcforexcel.com\/knowledge\/basic-statistics\/are-skewness-and-kurtosis-useful-statistics) to get some details about log transformation, squar root transformation and skewness of a plot.***","d94b76d5":"> ***From the above we see that the column B is very hard to transform and since its correlation with MEDV is not that good so it would be a good idea to drop the column***","e1c4a336":"> ***Hear we can see LSTAT and RM have a good relation with MEDV***","a563f5b6":"## Using Random Forest ","06094861":"## Checking the skewness","e5202577":"# Scaling","826c2f37":"# **Preprocessing**\n## **Checking for Correlation**","662a8afd":"> ***From the above we can see LSTAT, PTRAIO and  RM have a strong correlation with MEDV***","b7214eaf":"# **Model** \n\n## Using Linear Regression","c71a862a":"## Using Decission Tree","c17770f0":"# **Exploratory Data Analysis (EDA)**"}}