{"cell_type":{"3103c2ab":"code","1728f9a4":"code","ab54df46":"code","1427426b":"code","a0b442d1":"code","f67ffbe4":"code","ccc22201":"code","0bdd0cdd":"code","914d4204":"code","500f773f":"code","ab77fc89":"code","45ec2416":"code","2dac4f7f":"code","c3225f26":"markdown","c2119179":"markdown","880d8875":"markdown","484743e3":"markdown","9b60e4da":"markdown","37ba227c":"markdown","9d528659":"markdown","8e0fc001":"markdown","d5a13372":"markdown","5735b5b3":"markdown","af153bf1":"markdown","5bf51184":"markdown"},"source":{"3103c2ab":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import signal\nfrom sklearn import linear_model\nfrom sklearn.metrics import roc_curve, roc_auc_score, auc\nimport pickle\nimport matplotlib\nimport matplotlib.gridspec as gridspec\n\nmatplotlib.rcParams['pdf.fonttype'] = 42\nmatplotlib.rcParams['svg.fonttype'] = 'none'","1728f9a4":"#%% main script params\n\n# input parameters\nnum_axons = 100\n\n# neuron model parameters\nconnections_per_axon = 5\nnum_synapses = connections_per_axon * num_axons\n\nv_reset     = -80\nv_threshold = -55\ncurrent_to_voltage_mult_factor = 3\nrefreactory_time_constant = 15\n\nmodel_type = 'F&F'\n#model_type = 'I&F'\n\n# synapse non-learnable parameters\nif model_type == 'F&F':\n    tau_rise_range  = [1,16]\n    tau_decay_range = [8,24]\nelif model_type == 'I&F':\n    tau_rise_range  = [1,1]\n    tau_decay_range = [24,24]\n\ntau_rise_vec  = np.random.uniform(low=tau_rise_range[0] , high=tau_rise_range[1] , size=(num_synapses, 1))\ntau_decay_vec = np.random.uniform(low=tau_decay_range[0], high=tau_decay_range[1], size=(num_synapses, 1))\n\n# synapse learnable parameters\nsynaptic_weights_vec = np.random.normal(size=(num_synapses, 1))\n\nsave_figures = True\nsave_figures = False\nall_file_endings_to_use = ['.png', '.pdf', '.svg']\n\ndata_folder   = '..\/input\/fiter-and-fire-paper\/results_data_capacity\/'\nfigure_folder = '\/kaggle\/working\/'\n","ab54df46":"def create_single_PSP_profile(tau_rise, tau_decay, temporal_filter_length=50):\n\n    safety_factor = 1.5\n    if tau_rise >= (tau_decay \/ safety_factor):\n        tau_decay = safety_factor * tau_rise\n\n    exp_r = signal.exponential(M=temporal_filter_length, center=0, tau=tau_rise , sym=False)\n    exp_d = signal.exponential(M=temporal_filter_length, center=0, tau=tau_decay, sym=False)\n\n    post_syn_potential = exp_d - exp_r\n    post_syn_potential \/= post_syn_potential.max()\n\n    return post_syn_potential\n\n\ndef construct_normlized_synaptic_filter(tau_rise_vec, tau_decay_vec):\n\n    num_synapses = tau_rise_vec.shape[0]\n    temporal_filter_length = int(4 * tau_decay_vec.max()) + 1\n\n    syn_filter = np.zeros((num_synapses, temporal_filter_length))\n\n    for k, (tau_r, tau_d) in enumerate(zip(tau_rise_vec, tau_decay_vec)):\n        syn_filter[k,:] = create_single_PSP_profile(tau_r, tau_d, temporal_filter_length=temporal_filter_length)\n\n    return syn_filter\n\n\ndef simulate_filter_and_fire_cell_training(presynaptic_input_spikes, synaptic_weights, tau_rise_vec, tau_decay_vec,\n                                           refreactory_time_constant=20, v_reset=-75, v_threshold=-55, current_to_voltage_mult_factor=2):\n\n    temporal_filter_length = int(5 * refreactory_time_constant) + 1\n    refreactory_filter = signal.exponential(M=temporal_filter_length,center=0,tau=refreactory_time_constant,sym=False)[np.newaxis,:]\n\n    # padd input and get all synaptic filters\n    normlized_syn_filter = np.flipud(construct_normlized_synaptic_filter(tau_rise_vec, tau_decay_vec))\n    padded_input = np.hstack((np.zeros(normlized_syn_filter.shape), presynaptic_input_spikes))\n\n    # calc local currents\n    local_normlized_currents = np.zeros(presynaptic_input_spikes.shape)\n    for k in range(normlized_syn_filter.shape[0]):\n        local_normlized_currents[k] = signal.convolve(padded_input[k], normlized_syn_filter[k], mode='valid')[1:]\n\n    # multiply by weights to get the somatic current\n    soma_current = signal.convolve(local_normlized_currents, synaptic_weights, mode='valid')\n\n    # simulate the cell\n    soma_voltage = v_reset + current_to_voltage_mult_factor * soma_current.ravel()\n    output_spike_times_in_ms = []\n    # after a spike inject current that is exactly required to bring the cell back to v_reset (this current slowly decays)\n    for t in range(len(soma_voltage)):\n        # after a spike inject current that is exactly required to bring the cell back to v_reset (this current slowly decays)\n        if (soma_voltage[t] > v_threshold) and ((t + 1) < len(soma_voltage)):\n            t_start = t + 1\n            t_end = min(len(soma_voltage), t_start + temporal_filter_length)\n            soma_voltage[t_start:t_end] -= (soma_voltage[t + 1] - v_reset) * refreactory_filter.ravel()[:(t_end - t_start)]\n            output_spike_times_in_ms.append(t)\n\n    return local_normlized_currents, soma_voltage, output_spike_times_in_ms\n\n\ndef simulate_filter_and_fire_cell_inference(presynaptic_input_spikes, synaptic_weights, tau_rise_vec, tau_decay_vec,\n                                            refreactory_time_constant=20, v_reset=-75, v_threshold=-55, current_to_voltage_mult_factor=2):\n\n    temporal_filter_length = int(5 * refreactory_time_constant) + 1\n    refreactory_filter = signal.exponential(M=temporal_filter_length,center=0,tau=refreactory_time_constant,sym=False)[np.newaxis,:]\n\n    # padd input and get all synaptic filters\n    normlized_syn_filter = construct_normlized_synaptic_filter(tau_rise_vec, tau_decay_vec)\n    padded_input = np.hstack((np.zeros(normlized_syn_filter.shape), presynaptic_input_spikes))\n\n    # calc somatic current\n    weighted_syn_filter  = synaptic_weights * normlized_syn_filter\n    soma_current = signal.convolve(padded_input, weighted_syn_filter, mode='valid')[:,1:]\n\n    # simulate the cell\n    soma_voltage = v_reset + current_to_voltage_mult_factor * soma_current.ravel()\n    output_spike_times_in_ms = []\n    # after a spike inject current that is exactly required to bring the cell back to v_reset (this current slowly decays)\n    for t in range(len(soma_voltage)):\n\n        # after a spike inject current that is exactly required to bring the cell back to v_reset (this current slowly decays)\n        if (soma_voltage[t] > v_threshold) and ((t + 1) < len(soma_voltage)):\n            t_start = t + 1\n            t_end = min(len(soma_voltage), t_start + temporal_filter_length)\n            soma_voltage[t_start:t_end] -= (soma_voltage[t + 1] - v_reset) * refreactory_filter.ravel()[:(t_end - t_start)]\n            output_spike_times_in_ms.append(t)\n\n    return soma_voltage, output_spike_times_in_ms\n\n\n# use local currents as \"features\" and fit a linear model to the data\ndef prepare_training_dataset(local_normlized_currents, desired_output_spikes, spike_safety_range_ms=10, negative_subsampling_fraction=0.1):\n\n    # remove all \"negative\" time points that are too close to spikes\n    desired_output_spikes_LPF = signal.convolve(desired_output_spikes, np.ones((spike_safety_range_ms,)), mode='same') > 0.1\n    desired_timepoints = ~desired_output_spikes_LPF\n\n    # massivly subsample the remaining timepoints\n    desired_timepoints[np.random.rand(desired_timepoints.shape[0]) > negative_subsampling_fraction] = 0\n    desired_timepoints[desired_output_spikes > 0.1] = 1\n\n    X = local_normlized_currents.T[desired_timepoints,:]\n    y = desired_output_spikes[desired_timepoints]\n\n    return X, y","1427426b":"# generate sample input\nstimulus_duration_ms = 60000\n\naxons_input_spikes = np.random.rand(num_axons, stimulus_duration_ms) < 0.001\n\npresynaptic_input_spikes = np.kron(np.ones((connections_per_axon,1)), axons_input_spikes)\n\nassert presynaptic_input_spikes.shape[0] == num_synapses, 'number of synapses doesnt match the number of presynaptic inputs'\n\n# generate desired pattern of output spikes\nrequested_number_of_output_spikes = 40\nmin_time_between_spikes_ms = 125\n\ndesired_output_spike_times = min_time_between_spikes_ms * np.random.randint(int(stimulus_duration_ms \/ min_time_between_spikes_ms), size=requested_number_of_output_spikes)\ndesired_output_spike_times = np.sort(np.unique(desired_output_spike_times))\n\ndesired_output_spikes = np.zeros((stimulus_duration_ms,))\ndesired_output_spikes[desired_output_spike_times] = 1.0\n\nprint('number of requested output spikes = %d' %(requested_number_of_output_spikes))\n\n# simulate cell with normlized currents\nlocal_normlized_currents, soma_voltage, output_spike_times_in_ms = simulate_filter_and_fire_cell_training(presynaptic_input_spikes,\n                                                                                                          synaptic_weights_vec, tau_rise_vec, tau_decay_vec,\n                                                                                                          refreactory_time_constant=refreactory_time_constant,\n                                                                                                          v_reset=v_reset, v_threshold=v_threshold,\n                                                                                                          current_to_voltage_mult_factor=current_to_voltage_mult_factor)\n\noutput_spikes = np.zeros((stimulus_duration_ms,))\ntry:\n    output_spikes[np.array(output_spike_times_in_ms)] = 1.0\nexcept:\n    print('no output spikes created')","a0b442d1":"from warnings import simplefilter\nfrom sklearn.exceptions import ConvergenceWarning\nsimplefilter(\"ignore\", category=ConvergenceWarning)\n\n# fit linear model to local currents\nlogistic_reg_model = linear_model.LogisticRegression(C=30000, fit_intercept=True, penalty='l2', max_iter=3000)\n\nspike_safety_range_ms = 1\nnegative_subsampling_fraction = 0.99\n\nX, y = prepare_training_dataset(local_normlized_currents, desired_output_spikes,\n                                spike_safety_range_ms=spike_safety_range_ms,\n                                negative_subsampling_fraction=negative_subsampling_fraction)\n\n# fit model\nlogistic_reg_model.fit(X,y)\n\nprint('number of data points = %d (%.2f%s positive class)' %(X.shape[0], 100 * y.mean(),'%'))\n\ny_hat = logistic_reg_model.predict_proba(X)[:,1]\n\n# calculate AUC\ntrain_AUC = roc_auc_score(y, y_hat)\n\nfitted_output_spike_prob = logistic_reg_model.predict_proba(local_normlized_currents.T)[:,1]\nfull_AUC = roc_auc_score(desired_output_spikes, fitted_output_spike_prob)\n\n# get desired FP threshold\ndesired_false_positive_rate = 0.004\n\nfpr, tpr, thresholds = roc_curve(desired_output_spikes, fitted_output_spike_prob)\n\ndesired_fp_ind = np.argmin(abs(fpr-desired_false_positive_rate))\nif desired_fp_ind == 0:\n    desired_fp_ind = 1\n\nactual_false_positive_rate = fpr[desired_fp_ind]\ntrue_positive_rate         = tpr[desired_fp_ind]\ndesired_fp_threshold       = thresholds[desired_fp_ind]\n\nAUC_score = auc(fpr, tpr)\n\nprint('AUC = %.4f' %(AUC_score))\nprint('at %.4f FP rate, TP = %.4f' %(actual_false_positive_rate, true_positive_rate))\n\noutput_spikes_after_learning = fitted_output_spike_prob > desired_fp_threshold\n\nplt.close('all')\nplt.figure(figsize=(25,12))\nplt.subplot(2,1,1);\nplt.plot(1.05 * y - 0.025); plt.title('train AUC = %.5f' %(train_AUC))\nplt.plot(y_hat); plt.xlabel('training samples'); plt.legend(['GT', 'prediction'])\n\nplt.subplot(2,1,2);\nplt.plot(1.05 * desired_output_spikes - 0.025); plt.title('full trace AUC = %.5f' %(full_AUC))\nplt.plot(fitted_output_spike_prob); plt.xlabel('time [ms]'); plt.legend(['GT', 'prediction'])","f67ffbe4":"#%% Display Input Raster, input and output before and after learning\n\nplt.close('all')\nfig = plt.figure(figsize=(20,16))\ngs_figure = gridspec.GridSpec(nrows=9,ncols=1)\ngs_figure.update(left=0.04, right=0.95, bottom=0.05, top=0.95, wspace=0.1, hspace=0.4)\n\nax_axons           = plt.subplot(gs_figure[:6,:])\nax_before_learning = plt.subplot(gs_figure[6,:])\nax_after_learning  = plt.subplot(gs_figure[7,:])\nax_desired_output  = plt.subplot(gs_figure[8,:])\n\nsyn_activation_time, syn_activation_index = np.nonzero(axons_input_spikes.T)\nsyn_activation_time = syn_activation_time \/ 1000\n\nmin_time_sec = 0\nmax_time_sec = stimulus_duration_ms \/ 1000\n\ntime_sec = np.linspace(min_time_sec, max_time_sec, output_spikes.shape[0])\n\nax_axons.scatter(syn_activation_time, syn_activation_index, s=2, c='k'); ax_axons.set_title('input axons raster', fontsize=15)\nax_axons.set_xlim(min_time_sec, max_time_sec);\nax_axons.set_xticks([])\nax_axons.spines['top'].set_visible(False)\nax_axons.spines['bottom'].set_visible(False)\nax_axons.spines['left'].set_visible(False)\nax_axons.spines['right'].set_visible(False)\n\nax_before_learning.plot(time_sec, output_spikes, c='k'); ax_before_learning.set_title('before learning', fontsize=15)\nax_before_learning.set_xlim(min_time_sec, max_time_sec);\nax_before_learning.set_xticks([])\nax_before_learning.set_yticks([])\nax_before_learning.spines['top'].set_visible(False)\nax_before_learning.spines['bottom'].set_visible(False)\nax_before_learning.spines['left'].set_visible(False)\nax_before_learning.spines['right'].set_visible(False)\n\nax_after_learning.plot(time_sec, output_spikes_after_learning, c='k'); ax_after_learning.set_title('after learning', fontsize=15)\nax_after_learning.set_xlim(min_time_sec, max_time_sec);\nax_after_learning.set_xticks([])\nax_after_learning.set_yticks([])\nax_after_learning.spines['top'].set_visible(False)\nax_after_learning.spines['bottom'].set_visible(False)\nax_after_learning.spines['left'].set_visible(False)\nax_after_learning.spines['right'].set_visible(False)\n\nax_desired_output.plot(time_sec, desired_output_spikes, c='k'); ax_desired_output.set_title('desired output (num spikes = %d)' %(requested_number_of_output_spikes), fontsize=15);\nax_desired_output.set_xlim(min_time_sec, max_time_sec);\nax_desired_output.set_yticks([]);\nax_desired_output.spines['top'].set_visible(False)\nax_desired_output.spines['bottom'].set_visible(False)\nax_desired_output.spines['left'].set_visible(False)\nax_desired_output.spines['right'].set_visible(False)\n","ccc22201":"#%% Load pickle file with previously stored results and check that it's OK\n\nresults_filename = data_folder + 'FF_vs_IF_capacity_comparision__num_axons_200__sim_duration_sec_120__num_mult_conn_6__rand_rep_18.pickle'\n\nloaded_script_results_dict = pickle.load(open(results_filename, \"rb\" ))\n\nprint('-----------------------------------------------------------------------------------------------------------')\nprint('loaded_script_results_dict.keys():')\nprint('----------')\nprint(loaded_script_results_dict.keys())\nprint('-----------------------------------------------------------------------------------------------------------')\nprint('loaded_script_results_dict[\"script_main_params\"].keys():')\nprint('----------')\n[print(x) for x in loaded_script_results_dict['script_main_params'].keys()]\nprint('-----------------------------------------------------------------------------------------------------------')\nprint('num_axons =', loaded_script_results_dict['script_main_params']['num_axons'])\nprint('stimulus_duration_sec =', loaded_script_results_dict['script_main_params']['stimulus_duration_sec'])\nprint('min_time_between_spikes_ms =', loaded_script_results_dict['script_main_params']['min_time_between_spikes_ms'])\nprint('refreactory_time_constant =', loaded_script_results_dict['script_main_params']['refreactory_time_constant'])\nprint('num_random_iter =', loaded_script_results_dict['script_main_params']['num_random_iter'])\nprint('spike_safety_range_ms =', loaded_script_results_dict['script_main_params']['spike_safety_range_ms'])\nprint('negative_subsampling_fraction =', loaded_script_results_dict['script_main_params']['negative_subsampling_fraction'])\nprint('-----------------------------------------------------------------------------------------------------------')\n","0bdd0cdd":"#%% extract params\n\nprocessed_res_curves = loaded_script_results_dict['processed_res_curves']\nall_results_curves   = loaded_script_results_dict['all_results_curves']\n\nnum_axons = loaded_script_results_dict['script_main_params']['num_axons']\nstimulus_duration_sec = loaded_script_results_dict['script_main_params']['stimulus_duration_sec']","914d4204":"num_plots = len(all_results_curves.keys())\n\nnum_random_iterations = 5\n\nfig = plt.figure(figsize=(30,15));\nfor key, value in all_results_curves.items():\n    plt.errorbar(value['num_spikes'], value['mean_AUC'], yerr=value['std_AUC'] \/ np.sqrt(num_random_iterations), label=key, lw=4)\nplt.legend(loc='lower left', fontsize=23, ncol=2)\nplt.title('learning to place precisly timed output spikes (random input, %d sec window, %d axons)' %(stimulus_duration_sec, num_axons), fontsize=24)\nplt.ylabel('accuracy at 1ms precision (AUC)', fontsize=24)\nplt.xlabel('num requested spikes to place', fontsize=30);","500f773f":"filename_str = 'FF_vs_IF_capacity_comparision__num_axons_%d__sim_duration_sec_120__num_mult_conn_6__rand_rep_18.pickle'\nnum_axons_list = sorted([100, 112, 125, 137, 150, 162, 175, 187, 200, 212, 225, 237])\nall_filenames_str = [filename_str %(x) for x in num_axons_list]\n\nmodel_keys = list(loaded_script_results_dict['processed_res_curves'].keys())\nconnections_per_axon_2C = loaded_script_results_dict['processed_res_curves'][model_keys[0]]['connections_per_axon']\n\nprecisely_timed_spikes_per_axon_2C = {}\nprecisely_timed_spikes_per_axon_error_2C = {}\nfor key in model_keys:\n    precisely_timed_spikes_per_axon_2C[key] = np.zeros((len(all_filenames_str), len(connections_per_axon_2C)))\n    precisely_timed_spikes_per_axon_error_2C[key] = np.zeros((len(all_filenames_str), len(connections_per_axon_2C)))\n\nfor k, (curr_num_axons, curr_filename) in enumerate(zip(num_axons_list, all_filenames_str)):\n    curr_results_filename = data_folder + curr_filename\n    curr_loaded_results_dict = pickle.load(open(curr_results_filename, \"rb\" ))\n\n    for key in model_keys:\n        precisely_timed_spikes_per_axon_2C[key][k,:] = curr_loaded_results_dict['processed_res_curves'][key]['num_almost_perfectly_placed_spikes'] \/ curr_num_axons\n\n        for j, (num_M_conn, num_spikes) in enumerate(zip(curr_loaded_results_dict['processed_res_curves'][key]['connections_per_axon'],\n                                                         curr_loaded_results_dict['processed_res_curves'][key]['num_almost_perfectly_placed_spikes'])):\n\n            model_connections_str = '%s, %d connections' %(key, num_M_conn)\n            error_index = list(curr_loaded_results_dict['all_results_curves'][model_connections_str]['num_spikes']).index(num_spikes)\n            error_scale = (curr_loaded_results_dict['all_results_curves'][model_connections_str]['num_spikes'][error_index + 1] -\n                           curr_loaded_results_dict['all_results_curves'][model_connections_str]['num_spikes'][max(0, error_index - 1)])\n\n            if error_index > 1:\n                error_scale \/= 2\n\n            precisely_timed_spikes_per_axon_error_2C[key][k,j] = error_scale \/ curr_num_axons\n\nnum_plots = len(processed_res_curves.keys())\n\ncolor_map = {}\ncolor_map['I&F'] = '0.05'\ncolor_map['F&F'] = 'orange'\n\nfig = plt.figure(figsize=(30,12));\nfor key in processed_res_curves.keys():\n    y_error = precisely_timed_spikes_per_axon_2C[key].std(axis=0)\n    plt.errorbar(connections_per_axon_2C, precisely_timed_spikes_per_axon_2C[key].mean(axis=0), yerr=y_error, label=key, lw=4, color=color_map[key])\nplt.title('learning to place precisely timed output spikes (random input, %d sec window, %d axons)' %(stimulus_duration_sec, num_axons), fontsize=24)\nplt.xlabel('Number of Multiple Contacts - M', fontsize=24)\nplt.ylabel('Number of Accuractly Timed Spikes\\n per Input Axon', fontsize=24);\nplt.legend(loc='upper left', fontsize=40)\nplt.yticks([0.15,0.3,0.45]);","ab77fc89":"filename_str = 'FF_vs_IF_capacity_comparision__num_axons_%d__sim_duration_sec_120__num_mult_conn_5__rand_rep_12.pickle'\n\nnum_axons_list = sorted([50,100,200,300,400])\nnum_multiple_conn_list = [1,3,5,10]\n\nall_filenames_str = [filename_str %(x) for x in num_axons_list]\n\nFF_num_placed_spikes = {}\nIF_num_placed_spikes = {}\n\nfor num_M_conn in num_multiple_conn_list:\n\n    FF_num_placed_spikes[num_M_conn] = {}\n    FF_num_placed_spikes[num_M_conn]['num_accurately_placed_spikes'] = []\n    FF_num_placed_spikes[num_M_conn]['num_accurately_placed_spikes_error'] = []\n\n    IF_num_placed_spikes[num_M_conn] = {}\n    IF_num_placed_spikes[num_M_conn]['num_accurately_placed_spikes'] = []\n    IF_num_placed_spikes[num_M_conn]['num_accurately_placed_spikes_error'] = []\n\n    for curr_num_axons, curr_filename in zip(num_axons_list, all_filenames_str):\n\n        curr_results_filename = data_folder + curr_filename\n        curr_loaded_results_dict = pickle.load(open(curr_results_filename, \"rb\" ))\n\n        FF_ind = list(curr_loaded_results_dict['processed_res_curves']['F&F']['connections_per_axon']).index(num_M_conn)\n        FF_num_spikes = curr_loaded_results_dict['processed_res_curves']['F&F']['num_almost_perfectly_placed_spikes'][FF_ind]\n\n        FF_error_index = list(curr_loaded_results_dict['all_results_curves']['F&F, %d connections' %(num_M_conn)]['num_spikes']).index(FF_num_spikes)\n        FF_error_scale = (curr_loaded_results_dict['all_results_curves']['F&F, %d connections' %(num_M_conn)]['num_spikes'][FF_error_index + 1] -\n                          curr_loaded_results_dict['all_results_curves']['F&F, %d connections' %(num_M_conn)]['num_spikes'][max(0, FF_error_index - 1)])\n\n        if FF_error_index > 1:\n            FF_error_scale \/= 2\n\n        IF_ind = list(curr_loaded_results_dict['processed_res_curves']['I&F']['connections_per_axon']).index(num_M_conn)\n        IF_num_spikes = curr_loaded_results_dict['processed_res_curves']['I&F']['num_almost_perfectly_placed_spikes'][IF_ind]\n\n        IF_error_index = list(curr_loaded_results_dict['all_results_curves']['I&F, %d connections' %(num_M_conn)]['num_spikes']).index(IF_num_spikes)\n        IF_error_scale = (curr_loaded_results_dict['all_results_curves']['F&F, %d connections' %(num_M_conn)]['num_spikes'][IF_error_index + 1] -\n                          curr_loaded_results_dict['all_results_curves']['F&F, %d connections' %(num_M_conn)]['num_spikes'][max(0, IF_error_index - 1)])\n\n        if IF_error_index > 1:\n            IF_error_scale \/= 2\n\n        FF_num_placed_spikes[num_M_conn]['num_accurately_placed_spikes'].append(FF_num_spikes)\n        FF_num_placed_spikes[num_M_conn]['num_accurately_placed_spikes_error'].append(FF_error_scale)\n        IF_num_placed_spikes[num_M_conn]['num_accurately_placed_spikes'].append(IF_num_spikes)\n        IF_num_placed_spikes[num_M_conn]['num_accurately_placed_spikes_error'].append(IF_error_scale)\n\n\nfig = plt.figure(figsize=(25,16))\n\nfor M in [10,3]:\n    plt.errorbar(num_axons_list, FF_num_placed_spikes[M]['num_accurately_placed_spikes'], yerr=FF_num_placed_spikes[M]['num_accurately_placed_spikes_error'], label='F&F (M = %d)' %(M), lw=5)\nplt.errorbar(num_axons_list, IF_num_placed_spikes[1]['num_accurately_placed_spikes'], yerr=FF_num_placed_spikes[1]['num_accurately_placed_spikes_error'], label='I&F', lw=5)\n\nplt.legend(loc='upper left', fontsize=30)\nplt.title('Capacity Linearly scales with Number of Axons', fontsize=30)\nplt.ylabel('Number of Accuratley Timed Spikes', fontsize=25)\nplt.xlabel('Number of Input Axons', fontsize=25);","45ec2416":"plt.close('all')\nfig = plt.figure(figsize=(25,16))\ngs_figure = gridspec.GridSpec(nrows=13,ncols=6)\ngs_figure.update(left=0.04, right=0.95, bottom=0.05, top=0.95, wspace=0.45, hspace=0.4)\n\nax_axons            = plt.subplot(gs_figure[:4,:4])\nax_before_learning  = plt.subplot(gs_figure[4,:4])\nax_after_learning   = plt.subplot(gs_figure[5,:4])\nax_desired_output   = plt.subplot(gs_figure[6,:4])\nax_acc_per_n_spikes = plt.subplot(gs_figure[8:,:4])\n\nax_n_spikes_m_cons  = plt.subplot(gs_figure[:6,4:])\nax_n_spikes_n_axons = plt.subplot(gs_figure[7:,4:])\n\n# 2 A\nbefore_color = '0.15'\nafter_color  = 'blue'\ntarget_color = 'red'\n\nsyn_activation_time, syn_activation_index = np.nonzero(axons_input_spikes.T)\nsyn_activation_time = syn_activation_time \/ 1000\n\nmin_time_sec = 0\nmax_time_sec = stimulus_duration_ms \/ 1000\n\ntime_sec = np.linspace(min_time_sec, max_time_sec, output_spikes.shape[0])\n\nax_axons.scatter(syn_activation_time, syn_activation_index, s=3, c='k'); ax_axons.set_title('Input Axons Raster', fontsize=18)\nax_axons.set_xlim(min_time_sec, max_time_sec);\nax_axons.set_xticks([])\nax_axons.set_yticks([0,25,50,75,100])\nax_axons.set_yticklabels([0,25,50,75,100],fontsize=15)\nax_axons.spines['top'].set_visible(False)\nax_axons.spines['bottom'].set_visible(False)\nax_axons.spines['left'].set_visible(False)\nax_axons.spines['right'].set_visible(False)\n\nax_before_learning.plot(time_sec, output_spikes, c=before_color, lw=2.5);\nax_before_learning.set_title('Before Learning', fontsize=17, color=before_color)\nax_before_learning.set_xlim(min_time_sec, max_time_sec);\nax_before_learning.set_xticks([])\nax_before_learning.set_yticks([])\nax_before_learning.spines['top'].set_visible(False)\nax_before_learning.spines['bottom'].set_visible(False)\nax_before_learning.spines['left'].set_visible(False)\nax_before_learning.spines['right'].set_visible(False)\n\nax_after_learning.plot(time_sec, output_spikes_after_learning, c=after_color, lw=2.5);\nax_after_learning.set_title('After Learning', fontsize=17, color=after_color)\nax_after_learning.set_xlim(min_time_sec, max_time_sec);\nax_after_learning.set_xticks([])\nax_after_learning.set_yticks([])\nax_after_learning.spines['top'].set_visible(False)\nax_after_learning.spines['bottom'].set_visible(False)\nax_after_learning.spines['left'].set_visible(False)\nax_after_learning.spines['right'].set_visible(False)\n\nax_desired_output.plot(time_sec, desired_output_spikes, c=target_color, lw=2.5);\nax_desired_output.set_title('Desired Output (num spikes = %d)' %(requested_number_of_output_spikes), fontsize=17, color=target_color);\nax_desired_output.set_xlim(min_time_sec, max_time_sec);\nax_desired_output.set_yticks([]);\nax_desired_output.set_xticks([0,15,30,45,60])\nax_desired_output.set_xticklabels([0,15,30,45,60],fontsize=15)\nax_desired_output.spines['top'].set_visible(False)\nax_desired_output.spines['bottom'].set_visible(False)\nax_desired_output.spines['left'].set_visible(False)\nax_desired_output.spines['right'].set_visible(False)\nax_desired_output.set_xlabel('time (sec)', fontsize=17);\n\n\n# 2 B\nnum_plots = len(all_results_curves.keys())\n\nkey_to_label_map = {\n    'F&F, 1 connections' : 'F&F (M =  1)',\n    'F&F, 2 connections' : 'F&F (M =  2)',\n    'F&F, 3 connections' : 'F&F (M =  3)',\n    'F&F, 5 connections' : 'F&F (M =  5)',\n    'F&F, 10 connections': 'F&F (M = 10)',\n    'F&F, 15 connections': 'F&F (M = 15)',\n    'I&F, 1 connections' : 'I&F (M =  1)',\n    'I&F, 2 connections' : 'I&F (M =  2)',\n    'I&F, 3 connections' : 'I&F (M =  3)',\n    'I&F, 5 connections' : 'I&F (M =  5)',\n    'I&F, 10 connections': 'I&F (M = 10)',\n    'I&F, 15 connections': 'I&F (M = 15)'}\n\nkey_to_color_map = {\n    'F&F, 1 connections' : 'blue',\n    'F&F, 2 connections' : 'orange',\n    'F&F, 3 connections' : 'green',\n    'F&F, 5 connections' : 'crimson',\n    'F&F, 10 connections': 'brown',\n    'F&F, 15 connections': 'purple',\n    'I&F, 1 connections' : 'gray',\n    'I&F, 2 connections' : 'gray',\n    'I&F, 3 connections' : 'gray',\n    'I&F, 5 connections' : 'gray',\n    'I&F, 10 connections': 'gray',\n    'I&F, 15 connections': 'gray'}\n\nkeys_ordering = ['I&F, 1 connections', 'I&F, 2 connections', 'I&F, 3 connections', 'I&F, 5 connections', 'I&F, 10 connections', 'I&F, 15 connections',\n                 'F&F, 1 connections', 'F&F, 2 connections', 'F&F, 3 connections', 'F&F, 5 connections', 'F&F, 10 connections', 'F&F, 15 connections']\n\n# for key, value in all_results_curves.items():\nfor key in keys_ordering:\n    value = all_results_curves[key]\n    curr_color = key_to_color_map[key]\n    curr_label = key_to_label_map[key]\n    if curr_color == 'gray':\n        ax_acc_per_n_spikes.errorbar(value['num_spikes'], value['mean_AUC'], yerr=value['std_AUC'] \/ np.sqrt(num_random_iterations),\n                                     label=curr_label, color=curr_color, lw=3, alpha=0.6)\n    else:\n        ax_acc_per_n_spikes.errorbar(value['num_spikes'], value['mean_AUC'], yerr=value['std_AUC'] \/ np.sqrt(num_random_iterations),\n                                     label=curr_label, color=curr_color, lw=3)\n\nax_acc_per_n_spikes.legend(loc='lower left', fontsize=18, ncol=2)\nax_acc_per_n_spikes.set_title('Placing Precisely Timed output Spikes', fontsize=18)\nax_acc_per_n_spikes.set_ylabel('Accuracy at 1ms Precision (AUC)', fontsize=17)\nax_acc_per_n_spikes.set_xlabel('Number of Requried Precisely Timed Spikes', fontsize=17);\nax_acc_per_n_spikes.spines['top'].set_visible(False)\nax_acc_per_n_spikes.spines['right'].set_visible(False)\nax_acc_per_n_spikes.set_yticks([0.7,0.8,0.9,1.0])\nax_acc_per_n_spikes.set_yticklabels([0.7,0.8,0.9,1.0],fontsize=15)\nax_acc_per_n_spikes.set_xticks([0,50,100,150,200])\nax_acc_per_n_spikes.set_xticklabels([0,50,100,150,200],fontsize=15)\n\n\n# 2 C\nfor key in processed_res_curves.keys():\n    y_error = precisely_timed_spikes_per_axon_2C[key].std(axis=0)\n    ax_n_spikes_m_cons.errorbar(connections_per_axon_2C, precisely_timed_spikes_per_axon_2C[key].mean(axis=0), yerr=y_error, label=key, lw=4, color=color_map[key])\n\nax_n_spikes_m_cons.legend(loc='upper left', fontsize=22)\nax_n_spikes_m_cons.set_title('Placing Precisely Timed output Spikes', fontsize=18)\nax_n_spikes_m_cons.set_xlabel('Number of Multiple Contacts - M', fontsize=17)\nax_n_spikes_m_cons.set_ylabel('Number of Precisely Timed Spikes \/ Input Axon', fontsize=17);\nax_n_spikes_m_cons.spines['top'].set_visible(False)\nax_n_spikes_m_cons.spines['right'].set_visible(False)\nax_n_spikes_m_cons.set_yticks([0.15,0.3,0.45])\nax_n_spikes_m_cons.set_ylim([0.08,0.53])\nax_n_spikes_m_cons.set_yticklabels([0.15,0.3,0.45], fontsize=15)\nax_n_spikes_m_cons.set_xticks([1,2,3,5,10,15])\nax_n_spikes_m_cons.set_xticklabels([1,2,3,5,10,15], fontsize=15)\n\n\n# 2 D\nfor M in [10,3]:\n    ax_n_spikes_n_axons.errorbar(num_axons_list, FF_num_placed_spikes[M]['num_accurately_placed_spikes'], yerr=FF_num_placed_spikes[M]['num_accurately_placed_spikes_error'], label='F&F (M = %d)' %(M), lw=5)\nax_n_spikes_n_axons.errorbar(num_axons_list, IF_num_placed_spikes[1]['num_accurately_placed_spikes'], yerr=FF_num_placed_spikes[1]['num_accurately_placed_spikes_error'], label='I&F', lw=5)\n\nax_n_spikes_n_axons.legend(loc='upper left', fontsize=22)\nax_n_spikes_n_axons.set_title('Capacity Linearly Scales with Number of Axons', fontsize=18)\nax_n_spikes_n_axons.set_ylabel('Number of Precisely Timed Spikes', fontsize=17)\nax_n_spikes_n_axons.set_xlabel('Number of Input Axons', fontsize=17);\nax_n_spikes_n_axons.set_yticks([0,100,200])\nax_n_spikes_n_axons.set_yticklabels([0,100,200], fontsize=15)\nax_n_spikes_n_axons.set_xticks(num_axons_list)\nax_n_spikes_n_axons.set_xticklabels(num_axons_list, fontsize=15)\nax_n_spikes_n_axons.spines['top'].set_visible(False)\nax_n_spikes_n_axons.spines['right'].set_visible(False)","2dac4f7f":"save_figures = True\n\n# save figure\nif save_figures:\n    figure_name = 'F&F_capacity_Figure_2_%d' %(np.random.randint(200))\n    for file_ending in all_file_endings_to_use:\n        if file_ending == '.png':\n            fig.savefig(figure_folder + figure_name + file_ending, bbox_inches='tight')\n        else:\n            fig.savefig(figure_folder + figure_name + file_ending, bbox_inches='tight')","c3225f26":"# Helper functions","c2119179":"# Fig 2D","880d8875":"## Display Input Raster & output spikes before and after learning","484743e3":"# Load pickle file with previously stored results and check that it's OK","9b60e4da":"## extract relevent params","37ba227c":"## Fit linear model to local currents and display GT vs prediction\n","9d528659":"# Figure 2 Full","8e0fc001":"## Save full figure in several different file formats","d5a13372":"## Generate sample input","5735b5b3":"# Fig 2C","af153bf1":"# Main script params","5bf51184":"# Fig 2B"}}