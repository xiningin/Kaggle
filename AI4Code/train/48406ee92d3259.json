{"cell_type":{"2c287625":"code","f09cf701":"code","cadd31c9":"code","4507c456":"code","434b790c":"code","16758a0f":"code","12518a0d":"code","56f8ff48":"code","c44f89dd":"code","f23cb399":"code","020f8469":"code","1ad852a0":"code","df03f891":"code","8f682178":"code","5fba7681":"code","7fa7563e":"markdown","57067441":"markdown"},"source":{"2c287625":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f09cf701":"import tensorflow\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.layers import GlobalMaxPooling2D\nfrom tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input\nimport numpy as np\nfrom numpy.linalg import norm\nimport os\nfrom tqdm import tqdm\nimport pickle\nimport cv2","cadd31c9":"model = ResNet50(weights='imagenet',include_top=False,input_shape=(224,224,3))\nmodel.trainable = False","4507c456":"model = tensorflow.keras.Sequential([\n    model,\n    GlobalMaxPooling2D()\n])","434b790c":"def extract_features(img_path,model):\n    img = image.load_img(img_path,target_size=(224,224))\n    img_array = image.img_to_array(img)\n    expanded_img_array = np.expand_dims(img_array, axis=0)\n    preprocessed_img = preprocess_input(expanded_img_array)\n    result = model.predict(preprocessed_img).flatten()\n    normalized_result = result \/ norm(result)\n\n    return normalized_result","16758a0f":"filenames = []\n\nfor file in os.listdir('\/kaggle\/input\/fashion-product-images-small\/images'):\n    filenames.append(os.path.join('\/kaggle\/input\/fashion-product-images-small\/images',file))","12518a0d":"feature_list = []\n\nfor file in tqdm(filenames):\n    \n    feature_list.append(extract_features(file,model))","56f8ff48":"pickle.dump(feature_list,open('embeddings.pkl','wb'))\npickle.dump(filenames,open('filenames.pkl','wb'))","c44f89dd":"feature_list = np.array(pickle.load(open('embeddings.pkl','rb')))\nfilenames = pickle.load(open('filenames.pkl','rb'))","f23cb399":"model = ResNet50(weights='imagenet',include_top=False,input_shape=(224,224,3))\nmodel.trainable = False\n\nmodel = tensorflow.keras.Sequential([\n    model,\n    GlobalMaxPooling2D()\n])","020f8469":"img = image.load_img('\/kaggle\/input\/fashion-product-images-small\/images\/32077.jpg',target_size=(224,224))\nimg_array = image.img_to_array(img)\nexpanded_img_array = np.expand_dims(img_array, axis=0)\npreprocessed_img = preprocess_input(expanded_img_array)\nresult = model.predict(preprocessed_img).flatten()\nnormalized_result = result \/ norm(result)","1ad852a0":"from sklearn.neighbors import NearestNeighbors\nneighbors = NearestNeighbors(n_neighbors=6,algorithm='brute',metric='euclidean')\nneighbors.fit(feature_list)","df03f891":"distances,indices = neighbors.kneighbors([normalized_result])","8f682178":"print(indices)","5fba7681":"for file in indices[0][1:6]:\n    temp_img = cv2.imread(filenames[file])\n    cv2.imshow('output',cv2.resize(temp_img,(512,512)))\n    cv2.waitKey(0)","7fa7563e":"# **All Code working fine bt i upload all the code without Run.**\n# **I hope u like my code**","57067441":"# To check, how my model will work ..."}}