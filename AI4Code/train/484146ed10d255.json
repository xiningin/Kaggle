{"cell_type":{"68243293":"code","b3e37dcb":"code","be0dedfb":"code","c7262d3b":"code","57a535ec":"code","a053bc49":"markdown","143d7d5d":"markdown"},"source":{"68243293":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.metrics import mean_squared_error,accuracy_score\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nimport numpy as np\nimport pandas as pd \nfrom sklearn.model_selection import GridSearchCV","b3e37dcb":"# Read dataset\ndf = pd.read_csv('..\/input\/alldriverdataset\/25_features_in_one_row.csv')\n\n# Drop rows with NA values\ndf = df.dropna(axis = 0)\n\n# Divide dataset into input features, output labels\nX, y = df.drop(['Unnamed: 0', 'DrivingStyle', 'DriverID'], axis = 1), df['DrivingStyle']\n\n# encoding categorical values\nX = pd.get_dummies(X)\n\nscaler = StandardScaler()\nscaler.fit(X)\nX = scaler.transform(X)\n\n# split dataset into train & test\nX_train, X_rem, y_train, y_rem = train_test_split(X, y, test_size=0.40, shuffle = True, random_state=42)\nX_dev, X_test, y_dev, y_test = train_test_split(X_rem, y_rem, test_size=0.50, shuffle = True, random_state=42)","be0dedfb":"# creating & fitting model \n# clf = RandomForestClassifier(n_estimators = 200, max_depth=40, random_state=0)\nclf = RandomForestClassifier(random_state=0)\nclf.fit(X_train, y_train)\n\n# Prediction\npredicted = clf.predict(X_test)\n\n# Metrics calculation\nprint(confusion_matrix(y_test,predicted))\nprint(classification_report(y_test,predicted))","c7262d3b":"# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 10, stop = 200, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\n# max_depth = [2,4]\n\n# Minimum number of samples required to split a node\n# min_samples_split = [2, 5]\n# Minimum number of samples required at each leaf node\n# min_samples_leaf = [1, 2]\n\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n\nparam_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n#                'max_depth': max_depth,\n#                'min_samples_split': min_samples_split,\n#                'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\n\nrf_Model = RandomForestClassifier()\n\nrf_Grid = GridSearchCV(estimator = rf_Model, param_grid = param_grid, cv = 3, verbose=2, n_jobs = 4)\n\nrf_Grid.fit(X_train, y_train)\n\nrf_Grid.best_params_","57a535ec":"print (f'Train Accuracy - : {rf_Grid.score(X_train,y_train):.3f}')\nprint (f'Test Accuracy - : {rf_Grid.score(X_test,y_test):.3f}')","a053bc49":"# data preprocessing","143d7d5d":"# import modules"}}