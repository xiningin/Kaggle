{"cell_type":{"d210245f":"code","8bb5cd3d":"code","78765d20":"code","22e5394f":"code","7fc3487c":"code","66f42d1c":"code","755669b5":"code","b07428b8":"code","006f6a30":"markdown","f1c96234":"markdown","2b5a30ad":"markdown"},"source":{"d210245f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8bb5cd3d":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport csv\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import MinMaxScaler\nimport warnings\nfrom sklearn.feature_selection import SelectFromModel\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import cross_val_score\nimport csv\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB, MultinomialNB\nfrom sklearn.neural_network import MLPClassifier\nimport warnings\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import linear_model\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nwarnings.filterwarnings('ignore')\n","78765d20":"dataset = pd.read_csv(\"..\/input\/titanic\/train.csv\")\nTestDataset = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ndef uniquify_me(*lister):\n    auxiliaryList = []\n\n    for word in lister:\n\n        if word not in auxiliaryList:\n            \n            auxiliaryList.append(word)\n\n    return auxiliaryList\ndef DataPreProcessing():                    \n\t\n    global dataset\n    global TestDataset\n    fillNa_value = np.float(0.0)\n    \n    # TestDataset = TestDataset.loc[:, TestDataset.columns != 'PassengerId']\n#     TestDataset = TestDataset.loc[:, TestDataset.columns != 'Cabin']\n#     TestDataset = TestDataset.loc[:, TestDataset.columns != 'Embarked']\n#     TestDataset = TestDataset.loc[:, TestDataset.columns != 'Ticket']\n#     TestDataset = TestDataset.loc[:, TestDataset.columns != 'Pclass']\n    # TestDataset = TestDataset.loc[:, TestDataset.columns != 'Fare']\n\n    # ########   ##############  >>>>>>>>>>  Filling Na by Mean <<<<<<<<<<<<<<<\n    \n    TestDataset['Embarked'].fillna('S',inplace=True)\n    TestDataset['Pclass'].fillna(3,inplace=True)\n    TestDataset['Fare'].fillna(TestDataset['Fare'].mean(),inplace=True)\n\n    dataset['Embarked'].fillna('S',inplace=True)\n    dataset['Pclass'].fillna(3,inplace=True)\n    dataset['Fare'].fillna(dataset['Fare'].mean(),inplace=True)\n\n    TestDataset.fillna(fillNa_value,inplace=True)\n    dataset.fillna(fillNa_value,inplace=True)\n \n    #############################################################################\n\n\n\n    # for abc in TestDataset[\"Age\"]:\n    # print(type(fillNa_value))\n    # for x in TestDataset[\"Age\"]:\n    # \tprint(type(x))\n    # \texit()\n    # kill = \n    ##############################  Family as feature #######################\n    \n    TestDataset['Family'] = TestDataset['SibSp'] + TestDataset['Parch'] + 1\n    dataset['Family'] = dataset['SibSp'] + dataset['Parch'] + 1\n\n    ##################################### Dealing with Tickets #########################################\n#     '''\n    index = 0\n\n    num = 1\n    a = 0\n    tiketo = pd.DataFrame(columns = TestDataset[\"Ticket\"])\n\n    while(a < len(TestDataset[\"Ticket\"])):\n    \tb = a+1\n    \twhile(b < len(TestDataset[\"Ticket\"])-1):\n    \t\tif(TestDataset[\"Ticket\"][a] == TestDataset[\"Ticket\"][b]):\n    \t\t\tTestDataset[\"Ticket\"][b] = num\n    \t\tb+=1\n    \ta+=1\n    \tnum+=1\n\n    index = 0\n\n    for a in TestDataset[\"Ticket\"]:\n    \tif(type(a) == type(\"asdkjb\")):\n    \t\tTestDataset[\"Ticket\"][index] = num\n    \t\tnum += 1\n    \tindex += 1\n\n\n    index = 0\n\n    num = 1\n    a = 0\n    tiketo = pd.DataFrame(columns = dataset[\"Ticket\"])\n\n    while(a < len(dataset[\"Ticket\"])):\n    \tb = a+1\n    \twhile(b < len(dataset[\"Ticket\"])-1):\n    \t\tif(dataset[\"Ticket\"][a] == dataset[\"Ticket\"][b]):\n    \t\t\tdataset[\"Ticket\"][b] = num\n    \t\tb+=1\n    \ta+=1\n    \tnum+=1\n\n    index = 0\n\n    for a in dataset[\"Ticket\"]:\n    \tif(type(a) == type(\"asdkjb\")):\n    \t\tdataset[\"Ticket\"][index] = num\n    \t\tnum += 1\n    \tindex += 1\n\n\n    # ................................................................................................\n    a = 0\n\n    while(a < len(dataset[\"Ticket\"])):\n    \tb = a+1\n    \twhile(b < len(dataset[\"Ticket\"])-1):\n    \t\tif(dataset[\"Ticket\"][a] == dataset[\"Ticket\"][b]):\n    \t\t\tdataset[\"Ticket\"][b] = num\n    \t\tb+=1\n    \ta+=1\n    \tnum+=1\n\n    index = 0\n\n    for a in dataset[\"Ticket\"]:\n    \tif(type(a) == type(\"asdkjb\")):\n    \t\tdataset[\"Ticket\"][index] = num\n    \t\tnum += 1\n    \tindex += 1\n        # '''\n\n        ############################# Adressing Missing Ages ########################################\n    \n    \n    index = 0\n    for age,sex,name,spo in zip(TestDataset[\"Age\"],TestDataset[\"Sex\"],TestDataset[\"Name\"],TestDataset[\"SibSp\"]) :\n        if( sex == 'female'):\n            if \"Mrs.\" in name:\n                if age == fillNa_value:\n                    TestDataset[\"Age\"][index] = 33.5\n\n            elif \"Miss\" in name:\n                if age == fillNa_value:\n                    TestDataset[\"Age\"][index]  = 17.8\n\n        else:\n            if \"Mr.\" in name:\n                if age == fillNa_value:\n                    TestDataset[\"Age\"][index]  = 23.3\n                    \n        index += 1\n\n\n    index = 0\n    for age,sex,name,spo in zip(dataset[\"Age\"],dataset[\"Sex\"],dataset[\"Name\"],dataset[\"SibSp\"]) :\n        if( sex == 'female'):\n            if \"Mrs.\" in name:\n                if age == fillNa_value:\n                    dataset[\"Age\"][index] = 33.5\n            elif \"Miss\" in name:\n\n                if age == fillNa_value:\n                    dataset[\"Age\"][index]  = 17.8\n\n        else:\n            if \"Mr.\" in name:\n                \n                if age == fillNa_value:\n                    dataset[\"Age\"][index]  = 23.3\n\n\n    for xyz,sex in zip(TestDataset[\"Name\"],TestDataset[\"Sex\"]):\n        if \"Mr.\" in xyz:\n            TestDataset.replace(xyz,1,inplace = True)\n        elif(\"Mrs.\" in xyz):\n            TestDataset.replace(xyz,2,inplace = True)\n        elif(\"Miss.\" in xyz):\n            TestDataset.replace(xyz,3,inplace = True)\t\n        elif(\"Don.\" in xyz):\n            TestDataset.replace(xyz,4,inplace = True)\t\n        elif(\"Dr.\" in xyz):\n            if sex == \"male\" :\n                TestDataset.replace(xyz,5,inplace = True)\n            else:\n                TestDataset.replace(xyz,6,inplace = True)\n        elif(\"Ms.\" in xyz):\n            TestDataset.replace(xyz,7,inplace = True)\n        elif(\"Lady.\" in xyz):\n            TestDataset.replace(xyz,8,inplace = True)\n        elif(\"Capt.\" in xyz):\n            TestDataset.replace(xyz,9,inplace = True)\n        elif(\"Master.\" in xyz):\n            TestDataset.replace(xyz,10,inplace = True)\n        elif(\"Dona.\" in xyz):\n            TestDataset.replace(xyz,11,inplace = True)\n        elif(\"Col.\" in xyz):\n            TestDataset.replace(xyz,12,inplace = True)\t\t\n        elif(\"Rev.\" in xyz):\n            TestDataset.replace(xyz,13,inplace = True)\n        elif(\"Mme.\" in xyz):\n            TestDataset.replace(xyz,14,inplace = True)\n        elif(\"Major.\" in xyz):\n            TestDataset.replace(xyz,15,inplace = True)\n        elif(\"Sir.\" in xyz):\n            TestDataset.replace(xyz,16,inplace = True)\n        elif(\"Mlle.\" in xyz):\n            TestDataset.replace(xyz,17,inplace = True)\n        elif(\"Countess.\" in xyz):\n            TestDataset.replace(xyz,18,inplace = True)\n        elif(\"Jonkheer.\" in xyz):\n            TestDataset.replace(xyz,19,inplace = True)\t\t\t\t\n        else:\n            TestDataset.replace(xyz,0,inplace = True)\n\n\n    TestDataset.replace('male',1,inplace=True)\n    TestDataset.replace('female',2,inplace=True)\n    TestDataset.replace('Q',1,inplace=True)\n    TestDataset.replace('S',2,inplace=True)\n    TestDataset.replace('C',3,inplace=True)\n\n\n    dataset.fillna(fillNa_value,inplace=True)\n    dataset = dataset.loc[:, dataset.columns != 'PassengerId']\n#     dataset = dataset.loc[:, dataset.columns != 'Cabin']\n#     dataset = dataset.loc[:, dataset.columns != 'Embarked']\n#     dataset = dataset.loc[:, dataset.columns != 'Ticket']\n#     dataset = dataset.loc[:, dataset.columns != 'Pclass']\n    # dataset = dataset.loc[:, dataset.columns != 'Fare']\n\n\n\n#     '''\n    # Dealing with Cabin column\n    lister = []\t\n    # TestDataset[\"Cabin\"].fillna(0,inplace = True)\n    for x in TestDataset[\"Cabin\"] :\n    \tif x == fillNa_value:\n    \t\tpass\n    \telse:\n    \t\tlister.append(x)\n\n    for x in dataset[\"Cabin\"] :\n    \tif x == fillNa_value:\n    \t\tpass\n    \telse:\n    \t\tlister.append(x)\n\n    lister = uniquify_me(*lister)\n    number = 1\n    for cabin in lister:\n    \tTestDataset.replace(cabin,number,inplace  = True)\n    \tdataset.replace(cabin,number,inplace  = True)\n    \tnumber += 1\n#     '''\n\n    for xyz,sex in zip(dataset[\"Name\"],dataset[\"Sex\"]):\n\n        if(\"Mr.\" in xyz):\n            dataset.replace(xyz,1,inplace = True)\n        elif(\"Mrs.\" in xyz):\n            dataset.replace(xyz,2,inplace = True)\n        elif(\"Miss.\" in xyz):\n            dataset.replace(xyz,3,inplace = True)\t\n        elif(\"Don.\" in xyz):\n            dataset.replace(xyz,4,inplace = True)\t\n        elif(\"Dr.\" in xyz):\n            if sex == \"male\" :\n                dataset.replace(xyz,5,inplace = True)\n            else:\n                dataset.replace(xyz,6,inplace = True)\n        elif(\"Ms.\" in xyz):\n            dataset.replace(xyz,7,inplace = True)\n        elif(\"Lady.\" in xyz):\n            dataset.replace(xyz,8,inplace = True)\n        elif(\"Capt.\" in xyz):\n            dataset.replace(xyz,9,inplace = True)\n        elif(\"Master.\" in xyz):\n            dataset.replace(xyz,10,inplace = True)\n        elif(\"Dona.\" in xyz):\n            dataset.replace(xyz,11,inplace = True)\n        elif(\"Col.\" in xyz):\n            dataset.replace(xyz,12,inplace = True)\t\t\n        elif(\"Rev.\" in xyz):\n            dataset.replace(xyz,13,inplace = True)\t\n        elif(\"Mme.\" in xyz):\n            dataset.replace(xyz,14,inplace = True)\n        elif(\"Major.\" in xyz):\n            dataset.replace(xyz,15,inplace = True)\n        elif(\"Sir.\" in xyz):\n            dataset.replace(xyz,16,inplace = True)\n        elif(\"Mlle.\" in xyz):\n            dataset.replace(xyz,17,inplace = True)\n        elif(\"Countess.\" in xyz):\n            dataset.replace(xyz,18,inplace = True)\n        elif(\"Jonkheer.\" in xyz):\n            dataset.replace(xyz,19,inplace = True)\t\t\t\n        else:\n            dataset.replace(xyz,0,inplace = True)\n\n\n    dataset.replace('male',1,inplace=True)\n    dataset.replace('female',2,inplace=True)\n    dataset.replace('Q',1,inplace=True)\n    dataset.replace('S',2,inplace=True)\n    dataset.replace('C',3,inplace=True)\n\n    dataset['Fare']\t= dataset['Fare']\/(dataset['SibSp']+dataset['Parch']+1)\n    TestDataset['Fare']\t= TestDataset['Fare']\/(TestDataset['SibSp']+TestDataset['Parch']+1)\n        \n        \n        # AGE Divided by 100\n    # TestDataset[\"Age\"] = TestDataset[\"Age\"]\n    # dataset[\"Age\"] = dataset[\"Age\"]\n\n    # dataset = dataset.loc[:, dataset.columns != 'Parch']\n    # TestDataset = TestDataset.loc[:, TestDataset.columns != 'Parch']\n    # dataset = dataset.loc[:, dataset.columns != 'SibSp']\n    # TestDataset = TestDataset.loc[:, TestDataset.columns != 'SibSp']\n\n    ############################################## Saving all the processed data #################################################\n\n    # print(TestDataset.describe())\n\n    # TestDataset = TestDataset.loc[:, TestDataset.columns != 'Parch']\n    # TestDataset = TestDataset.loc[:, TestDataset.columns != 'SibSp']\n    # dataset = dataset.loc[:, dataset.columns != 'Parch']\n    # dataset = dataset.loc[:, dataset.columns != 'SibSp']\n    \n#     for a in ['Age','SibSp','Parch','Fare']:\n#         TestDataset[a] = Remove_Outliers(TestDataset[a])\n#         dataset[a] = Remove_Outliers(dataset[a] )\n\n    print('done---------------------------------------------')\n\n\n\n\n    # exit()\n\n    TestDataset.to_csv(\"file_name_Test.csv\", sep=',')\n    dataset.to_csv(\"file_name_train.csv\", sep=',')\n\n    dataset = pd.read_csv(\"file_name_train.csv\")\n    TestDataset = pd.read_csv(\"file_name_Test.csv\")\n\n    print(\"new file written\")\n\n\n    ##############################################################################################################################\n\n    X = dataset.loc[:, dataset.columns != 'Survived']\n    Y = dataset['Survived']\t\n\n    X_Test = TestDataset.loc[:, TestDataset.columns != 'Survived']\n\n    scaler = MinMaxScaler()\n    scaler.fit(X)\n    X = scaler.transform(X)\n\n    X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size = 0.3,random_state = 12)\n\n    # print(dataset.head())\n\n    print(\"\\n\\npreprocessing done\\n\\n \")\n    return X_train,X_test,y_train,y_test,X,Y,X_Test\nDataPreProcessing()","22e5394f":"def Read_the_processed_data():\n\n    dataset = pd.read_csv(\"file_name_train.csv\")\n    TestDataset = pd.read_csv(\"file_name_Test.csv\")\n    ''',index_col=\"Age\"\n    ,index_col=\"Age\"'''\n    del TestDataset['Unnamed: 0']\n    del dataset['Unnamed: 0']\n    X_Test = TestDataset.loc[:, TestDataset.columns != 'Survived']\n\n    print(\"reading done\")\n\n    # print(dataset.head())\n\n    X = dataset.loc[:, dataset.columns != 'Survived']\n    Y = dataset['Survived']\t\n    '''\n    print(\"shapes before and after transformation\")\n    print(X.shape)\n\n    clf = RandomForestClassifier(\n                                n_estimators = 300,\n                                max_depth = 15, \n                                random_state = 15,\n                                max_features = 4,\n                                max_leaf_nodes = 60\n                                )\n    clf = clf.fit(X, Y)\n\n    model = SelectFromModel(clf, prefit=True)\n    X_new = model.transform(X)\n    print(X_new)\n    # X_new_TestDataset = model.transform(X_Test)\n    exit()\n\n    \n    TestDataset = X_new_TestDataset\n    X = X_new\n    print(X.shape)\n    '''\n\n    \n    X_train,X_test,y_train,y_test = train_test_split(\n                                                        X,Y,\n                                                        test_size = 0.3,\n                                                        random_state = 12\n                                                        )\n\n\n    return X_train,X_test,y_train,y_test,X,Y,X_Test\n\nRead_the_processed_data()","7fc3487c":"X_train,X_test,y_train,y_test,X,Y,X_Test = Read_the_processed_data()\nTo_pred = X_Test[\"PassengerId\"]\nX_Test = X_Test.loc[:,X_Test.columns != 'PassengerId']\n\nX.shape","66f42d1c":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\nmodel = keras.Sequential([\n    layers.Dense(11, activation='relu', input_shape=[11]),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n    layers.Dense(50, activation='relu'), \n#     layers.BatchNormalization(),\n#     layers.Dropout(0.3),\n    layers.Dense(50, activation='relu'), \n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(1, activation='sigmoid'),\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy'],\n)\n\nearly_stopping = keras.callbacks.EarlyStopping(\n    patience=10,\n    min_delta=0.001,\n    restore_best_weights=True,\n)\n\nhistory = model.fit(\n    X[0:600], Y[0:600],\n    validation_data=(X[600:891], Y[600:891]),\n    batch_size=512,\n    epochs=1000,\n    callbacks=[early_stopping]\n)","755669b5":"history_df = pd.DataFrame(history.history)\n# Start the plot at epoch 5\nhistory_df.loc[5:, ['loss', 'val_loss']].plot()\nhistory_df.loc[5:, ['binary_accuracy', 'val_binary_accuracy']].plot()\n\nprint((\"Best Validation Loss: {:0.4f}\" +\\\n      \"\\nBest Validation Accuracy: {:0.4f}\")\\\n      .format(history_df['val_loss'].min(), \n              history_df['val_binary_accuracy'].max()))","b07428b8":"\nPId = To_pred\nprint(\"here you go --------------------------- \")\nprint(To_pred.shape)\npred = TrainMeFinally()\nprint(pred.shape)\n# exit()\n# Start writing it to a csv file\nwith open('innovators.csv', 'w', newline='') as file:\n\twriter = csv.writer(file)\n\t# print(map(lambda x:[x], pred))\n\tzipped_lists=zip(PId,pred)\n\twriter.writerow(('PassengerId','Survived'))\n\tfor row in zipped_lists:\n\t\twriter.writerow(row)\n\n\nprint(\"done\")","006f6a30":"# Load data","f1c96234":"# Creating our model to classify","2b5a30ad":"# Pre processing"}}