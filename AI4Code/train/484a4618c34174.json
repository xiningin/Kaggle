{"cell_type":{"7c2f5a14":"code","e46f8a20":"code","9bd928c7":"code","8604223a":"code","d6015420":"code","f1124c27":"code","01349de5":"markdown","01334415":"markdown","7b2d3fae":"markdown","ac2ffaa9":"markdown","525571ab":"markdown","20fc50bf":"markdown","790791d3":"markdown","ae66db33":"markdown","e878d439":"markdown","3e1f01df":"markdown"},"source":{"7c2f5a14":"# download runtime and unpack\n!wget https:\/\/download.knime.org\/analytics-platform\/linux\/knime_4.1.2.linux.gtk.x86_64.tar.gz\n!tar xvzf knime_4.1.2.linux.gtk.x86_64.tar.gz\n!rm knime_4.1.2.linux.gtk.x86_64.tar.gz\n!unzip .\/knime_4.1.2\/knime-workspace.zip -d .\/knime_4.1.2\/knime-workspace\/\n!rm .\/knime_4.1.2\/knime-workspace.zip\n# copy the workflow\n!cp -R \/kaggle\/input\/knime-cat-publ .\/knime_4.1.2\/knime-workspace\/\n# set memory settings for the runtime\n!sed -i 's\/Xmx2048m\/Xmx10240m\/g' .\/knime_4.1.2\/knime.ini\n# install runtime extensions - python and H2O integrations\n!.\/knime_4.1.2\/knime -application org.eclipse.equinox.p2.director -nosplash -consolelog -r 'http:\/\/update.knime.com\/analytics-platform\/4.1,http:\/\/update.knime.com\/community-contributions\/4.1,http:\/\/update.knime.com\/community-contributions\/trusted\/4.1,http:\/\/update.knime.com\/partner\/4.1' -i 'org.knime.features.python2.feature.group,org.knime.features.ext.h2o.feature.group,org.knime.features.datageneration.feature.group' -d .\/knime_4.1.2\/\n# install the wrapper python package\n!pip install knime\n# used in the workflow\n!pip install dfply","e46f8a20":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport knime\n\n# Any results you write to the current directory are saved as output.\nknime.executable_path = \".\/knime_4.1.2\/knime\"\nworkspace = \".\/knime_4.1.2\/knime-workspace\"\nworkflow = \"knime-cat-publ\/cat_publ\/cat_publ\"","9bd928c7":"knime.Workflow(workflow_path=workflow,workspace_path=workspace)","8604223a":"with knime.Workflow(workflow_path=workflow,workspace_path=workspace) as wf:\n    wf.execute()","d6015420":"# Alternatively wf can be executed through the command-line processor directly (instead of Python wrapper - you'll get more detailed output)\n#!.\/knime_4.1.2\/knime -nosplash -application org.knime.product.KNIME_BATCH_APPLICATION -workflowDir=\".\/knime_4.1.2\/knime-workspace\/knime-cat-publ\/cat_publ\"","f1124c27":"rm -rf knime_4.1.2","01349de5":"Download, unpack and configure KNIME runtime.\nMove the unpacked workflow (pipeline) from knime-cat-publ datasource to the workspace directory.\nIf you want to see\/edit the workflow - need to download KNIME Analytics Platform from their website (it is standalone, portable java application) - and then import cat_publ.knwf (provided with the source) into your local workspace (from the GUI).  ","01334415":"What happens here (ohe metanode internals):\n* low cardinality features selected (only)\n* missing values imputed\n* columns one hot encoded\n* low variance columns removed\n* correlation matrix computed and highly correlated features removed (the extra instance)","7b2d3fae":"Import and visualize the workflow (pipeline)","ac2ffaa9":"Import and set variables","525571ab":"###### Finally found some time - and wanted to share with you something new, that I use extensivelly both in my work and on Kaggle.\n###### What is KNIME?:\n* it is open source\/free, heavy lifting DS\/DE platform\/framework (Java based, allows for out-of-memory datasets to be processed)\n* it allows for complete DS\/ML pipelines to be created, mostly in visual manner\n* it packs also (pretty much) every existing ML framework\/library out there\n* it also has full Python and R integrations and allows to freely mix those in the same pipeline  \n\nSmall disclaimer before we continue: This is NOT and AD, I don't work for KNIME, nor they are paying me. It is just something that I like and find extremely usefull - and wanted to share with you.","20fc50bf":"Cleanup","790791d3":"Hopefully you liked it (please upvote) - and saw something new today. Let me know if you have any questions in the comments :)","ae66db33":"What happens here:\n* source files are read in data_in metanode and concatenated after (vertically)\n* labeling is performed in lbl metanode\n* one hot encoding in ohe (see example below)\n* target encoding in tgt_enc node - using code from this great kernel (please upvote): https:\/\/www.kaggle.com\/caesarlupum\/2020-20-lines-target-encoding\n* Z-score normalization in prep\n* H2O GLM + LGB models - blended in subm_blend  \n\nOf course there is a lot of functionality inside the metanodes. Here is an example of how ohe metanode looks like under the hood:","e878d439":"Finally - run the workflow","3e1f01df":"![image.png](attachment:image.png)"}}