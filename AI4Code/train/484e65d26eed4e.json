{"cell_type":{"aa3d6090":"code","0e585a3d":"code","2b939021":"code","908a96f3":"code","270aefc9":"code","5174965c":"code","42bb60ee":"code","49a3c904":"code","b9da6ae9":"code","4669dd18":"code","a9f37b4a":"code","ae3f3eb7":"code","dd060866":"code","891f7031":"code","1088a8c1":"code","7c340f0d":"code","f29ea308":"code","d6cdb0a9":"code","5b2fce34":"code","cfb645aa":"code","c911234c":"code","032d5141":"code","ff5d3f5a":"code","7d970e72":"code","8d71b1fe":"code","7e3843ba":"code","670aca21":"code","41f3c9ea":"code","1e785895":"code","9febcc49":"code","eefa5872":"code","c17ada26":"code","aaa5e512":"code","fc2746fc":"code","4a1d60d3":"code","9117b9f0":"code","86d41a37":"code","5d207e92":"code","d10bdef6":"code","71e65b20":"code","2f30fcfd":"code","c4a95866":"code","f3b918aa":"code","f0036ad9":"code","2f8dc7e3":"code","a9b289b5":"code","01960731":"code","3523a86e":"code","6890d457":"code","c2084a6c":"code","fc5742cc":"code","64614f74":"code","690ece7e":"code","5f64c608":"code","844dff3a":"code","a00f7ab8":"code","34c59c08":"code","8b3ac2b3":"code","83eb5d3d":"code","72ab150a":"code","51cec5cf":"code","8f47b984":"code","61902679":"code","ea57ac90":"code","33218552":"code","f344243a":"code","912ec53d":"code","721283f6":"code","2e6af64e":"code","d64462ee":"code","8b2e3c93":"code","af1c932f":"code","6f591af5":"code","d2506a52":"code","55c1f790":"code","bf04f6f6":"code","0145cbe4":"code","7d785c0d":"code","6c580f16":"markdown","e01b46e2":"markdown","c8a07c5e":"markdown","b65fef51":"markdown","27028b6a":"markdown","04add901":"markdown","c691a05d":"markdown","fb8a2472":"markdown","73ecf106":"markdown","5bec7794":"markdown","16dfe905":"markdown","a27a5252":"markdown","2aa4ba02":"markdown","a933b30a":"markdown","5880b370":"markdown","90105efd":"markdown","c24d189d":"markdown","b9daef97":"markdown","25eed86b":"markdown","9dec1bd6":"markdown","4563f388":"markdown","2afc8e51":"markdown","826f05c9":"markdown"},"source":{"aa3d6090":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","0e585a3d":"import pandas as pd\ntrain= pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","2b939021":"train.head()","908a96f3":"train.shape ","270aefc9":"test.shape","5174965c":"train.info()","42bb60ee":"test.info()","49a3c904":"train.isnull().sum()","b9da6ae9":"test.isnull().sum()","4669dd18":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()","a9f37b4a":"def bar_chart(feature):\n    Survived = train[train['Survived']==1][feature].value_counts()\n    dead = train[train['Survived']==0][feature].value_counts()\n    df = pd.DataFrame([Survived,dead])\n    df.index = ['Survived','Dead']\n    df.plot(kind='bar',stacked=True, figsize=(10,5))","ae3f3eb7":"bar_chart('Pclass')","dd060866":"bar_chart('SibSp')","891f7031":"bar_chart('Embarked')","1088a8c1":"train.head(711)","7c340f0d":"train_test_data = [train, test]\n\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","f29ea308":"train['Title'].value_counts()","d6cdb0a9":"test['Title'].value_counts()","5b2fce34":"title_mapping = {'Mr': 0, 'Miss': 1, 'Mrs': 2,\n                'Master': 3, 'Dr':3, 'Rev':3, 'Col': 3, 'Major': 3, 'Mlle':3, 'Countess':3, \n                'Ms': 3, 'Lady': 3, 'Jonkheer': 3, 'Don': 3, 'Dona': 3, 'Mme': 3, 'Capt':3, 'Sir':3}\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Title'].map(title_mapping)","cfb645aa":"train.head(891)","c911234c":"test.head()","032d5141":"bar_chart('Title')","ff5d3f5a":"# delete unncessary feature from dataset\n\ntrain.drop('Name', axis=1, inplace=True)\ntest.drop('Name', axis=1, inplace=True)","7d970e72":"train.head()","8d71b1fe":"test.head()","7e3843ba":"sex_mapping = {'male': 0, 'female': 1}\nfor dataset in train_test_data:\n    dataset['Sex'] = dataset['Sex'].map(sex_mapping)","670aca21":"bar_chart('Sex')","41f3c9ea":"print(train)","1e785895":"#filling missing age values with median age for each title (Mr, Mrs, Miss, Others)\n\ntrain['Age'].fillna(train.groupby('Title')['Age'].transform('median'), inplace=True)\ntest['Age'].fillna(train.groupby('Title')['Age'].transform('median'), inplace=True)","9febcc49":"train.info()","eefa5872":"train.head()","c17ada26":"facet = sns.FacetGrid(train, hue='Survived', aspect=4)\nfacet.map(sns.kdeplot,'Age',shade=True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\n\nplt.show()","aaa5e512":"facet = sns.FacetGrid(train, hue='Survived', aspect=4)\nfacet.map(sns.kdeplot,'Age',shade=True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(0,20)\nplt.show()","fc2746fc":"facet = sns.FacetGrid(train, hue='Survived', aspect=4)\nfacet.map(sns.kdeplot,'Age',shade=True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(30,40)\nplt.show()","4a1d60d3":"for dataset in train_test_data:\n    dataset.loc[dataset['Age'] <= 16, 'Age'] = 0,\n    dataset.loc[(dataset['Age']> 16) & (dataset['Age'] <= 26), 'Age'] = 1,\n    dataset.loc[(dataset['Age']> 26) & (dataset['Age'] <= 36), 'Age'] = 2,\n    dataset.loc[(dataset['Age']> 36) & (dataset['Age'] <= 62), 'Age'] = 3,\n    dataset.loc[dataset['Age']> 62, 'Age'] = 4","9117b9f0":"train.head()","86d41a37":"bar_chart('Age')","5d207e92":"Pclass1 = train[train['Pclass']==1]['Embarked'].value_counts()\nPclass2 = train[train['Pclass']==2]['Embarked'].value_counts()\nPclass3 = train[train['Pclass']==3]['Embarked'].value_counts()\n\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class', '2nd class', '3rd class']\ndf.plot(kind='bar', stacked=True, figsize=(10,5))","d10bdef6":"# filling missing embark with S embark\n\nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')","71e65b20":"train.info()","2f30fcfd":"train.head()","c4a95866":"#changing S,C,Q to numeric values\nembarked_mapping = {'S': 0, 'C': 1, 'Q': 2}\nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)","f3b918aa":"train['Fare'].fillna(train.groupby('Pclass')['Fare'].transform('median'), inplace = True)\ntest['Fare'].fillna(test.groupby('Pclass')['Fare'].transform('median'), inplace=True)","f0036ad9":"facet = sns.FacetGrid(train, hue='Survived', aspect=4)\nfacet.map(sns.kdeplot,'Fare', shade=True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\n\nplt.show()","2f8dc7e3":"facet = sns.FacetGrid(train, hue='Survived', aspect=4)\nfacet.map(sns.kdeplot,'Fare', shade=True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0,20)","a9b289b5":"facet = sns.FacetGrid(train, hue='Survived', aspect=4)\nfacet.map(sns.kdeplot,'Fare', shade=True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0,30)","01960731":"facet = sns.FacetGrid(train, hue='Survived', aspect=4)\nfacet.map(sns.kdeplot,'Fare', shade=True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0)","3523a86e":"# Binning on Fare\n\nfor dataset in train_test_data:\n    dataset.loc[dataset['Fare'] <= 17, 'Fare'] = 0,\n    dataset.loc[(dataset['Fare']> 17) & (dataset['Fare'] <= 30), 'Fare'] = 1,\n    dataset.loc[(dataset['Fare']> 30) & (dataset['Fare'] <= 100), 'Fare'] = 2,\n    dataset.loc[dataset['Fare'] >100, 'Fare'] = 3\n","6890d457":"train.head()","c2084a6c":"train.Cabin.value_counts()","fc5742cc":"for dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].str[:1]","64614f74":"Pclass1 = train[train['Pclass']==1]['Cabin'].value_counts()\nPclass2 = train[train['Pclass']==2]['Cabin'].value_counts()\nPclass3 = train[train['Pclass']==3]['Cabin'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class', '2nd class', '3rd class']\ndf.plot(kind = 'bar', stacked=True, figsize=(10,5))","690ece7e":"cabin_mapping = {'A': 0, 'B': 0.4, 'C': 0.8, 'D': 1.2, 'E': 1.6, 'F': 2, 'G': 2.4, 'T': 2.8}\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].map(cabin_mapping)","5f64c608":"train['Cabin'].fillna(train.groupby('Pclass')['Cabin'].transform('median'),inplace=True)\ntest['Cabin'].fillna(test.groupby('Pclass')['Cabin'].transform('median'), inplace=True)","844dff3a":"train['FamilySize'] = train['SibSp'] + train['Parch'] + 1\ntest['FamilySize'] = test['SibSp'] + test['Parch'] + 1","a00f7ab8":"facet = sns.FacetGrid(train, hue='Survived', aspect=4)\nfacet.map(sns.kdeplot, 'FamilySize',shade = True)\nfacet.set(xlim=(0, train['FamilySize'].max()))\nfacet.add_legend()\nplt.xlim(0)","34c59c08":"family_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5:1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4 }\nfor dataset in train_test_data:\n    dataset['FamilySize'] = dataset['FamilySize'].map(family_mapping)","8b3ac2b3":"train.head()","83eb5d3d":"pd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)","72ab150a":"features_drop = ['Ticket', 'SibSp', 'Parch']\ntrain = train.drop(features_drop, axis=1)\ntest = test.drop(features_drop, axis=1)\ntrain = train.drop(['PassengerId'], axis=1)","51cec5cf":"train_data = train.drop('Survived', axis=1)\ntarget = train['Survived']\n\ntrain_data.shape, target.shape","8f47b984":"train_data.head(891)","61902679":"# importing classifier modules\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n\nimport numpy as np","ea57ac90":"train.info()","33218552":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)","f344243a":"clf = KNeighborsClassifier(n_neighbors = 13)\nscoring = 'accuracy'\nscore = cross_val_score(clf,train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","912ec53d":"# Knn score\nround(np.mean(score)*100, 2)","721283f6":"clf = DecisionTreeClassifier()\nscoring = 'accuracy'\nscore = score = cross_val_score(clf,train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","2e6af64e":"# decision tree score\nround(np.mean(score)*100,2)","d64462ee":"clf = RandomForestClassifier(n_estimators=13)\nscoring = 'accuracy'\nscore = score = cross_val_score(clf,train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","8b2e3c93":"# random forest score\nround(np.mean(score)*100,2)\n","af1c932f":"clf = GaussianNB()\nscoring = 'accuracy'\nscore = score = cross_val_score(clf,train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","6f591af5":"# Naive bayes score\nround(np.mean(score)*100,2)","d2506a52":"clf = SVC()\nscoring = 'accuracy'\nscore = score = cross_val_score(clf,train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","55c1f790":"round(np.mean(score)*100,2)","bf04f6f6":"clf = SVC()\nclf.fit(train_data, target)\n\ntest_data = test.drop('PassengerId', axis=1).copy()\nprediction = clf.predict(test_data)","0145cbe4":"submission = pd.DataFrame({\n    'PassengerId': test['PassengerId'],\n    'Survived': prediction\n})\nsubmission.to_csv('submission.csv', index=False)","7d785c0d":"submission = pd.read_csv('submission.csv')\nsubmission.head(10)","6c580f16":"### Age\n\nuse Title's median age to fill the missing values","e01b46e2":"### Binning\ngrouping into buckets based on age\n\n****Feature vector map:****\n* child: 0\n* Young: 1\n* Adult: 2\n* Mid-age: 3\n* Senior: 4","c8a07c5e":"#### 1.3 Naive Bayes","b65fef51":"### Data Dictionary\n\n* survival \tSurvival \t0 = No, 1 = Yes\n* pclass \tTicket class \t1 = 1st, 2 = 2nd, 3 = 3rd\n* sex \tSex \t\n* Age \tAge in years \t\n* sibsp \t# of siblings \/ spouses aboard the Titanic \t\n* parch \t# of parents \/ children aboard the Titanic \t\n* ticket \tTicket number \t\n* fare \tPassenger fare \t\n* cabin \tCabin number \t\n* embarked \tPort of Embarkation \tC = Cherbourg, Q = Queenstown, S = Southampton","27028b6a":"> ### Bar chart for categories\n* Pclass\n* Sex\n* SibSp (number of siblings and spouse)\n* Parch (number of parents and children)\n* embarked\n* cabin","04add901":"### Sex\n* male: 0\n* female: 1","c691a05d":"#### 1.1 kNN","fb8a2472":"# Version 5 of Titanic: Machine learning from disaster","73ecf106":"> Missing values in age","5bec7794":"#### 1.4 Svm","16dfe905":"### Family Size","a27a5252":"### Embarked\nfilling missing values in Embarked column","2aa4ba02":"### Testing","a933b30a":"### Name","5880b370":"### import python lib for visualization","90105efd":"# Exploratory data analysis","c24d189d":"### Modeling","b9daef97":"### Title map\n* Mr: 0\n* Miss: 1\n* Mrs : 2\n* Others: 3","25eed86b":"#### 1.2 Decision Tree","9dec1bd6":"#### 1. Cross validation(K-fold)","4563f388":"### Fare\nfilling missing values in fare with medium fare of each Pclass","2afc8e51":"### Cabin","826f05c9":"# Collecting the data"}}