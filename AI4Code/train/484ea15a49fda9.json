{"cell_type":{"e5a7633e":"code","9f2c1a71":"code","e199c8bd":"code","09082479":"code","000f4979":"code","86df9ff6":"code","5d8946a0":"code","45331e85":"markdown"},"source":{"e5a7633e":"## 0. Install required packages\n\n!pip install xgboost pandas python-dateutil","9f2c1a71":"## 1. Reading data into a pandas DataFrame, and inspecting the columns a bit\n\nimport pandas as pd\ndf = pd.read_csv(\"..\/input\/train_electricity.csv\")\n\nprint(\"Dataset has\", len(df), \"entries.\")\n\nprint(f\"\\n\\t{'Column':20s} | {'Type':8s} | {'Min':12s} | {'Max':12s}\\n\")\nfor col_name in df.columns:\n    col = df[col_name]\n    print(f\"\\t{col_name:20s} | {str(col.dtype):8s} | {col.min():12.1f} | {col.max():12.1f}\")","e199c8bd":"## 2. Adding some datetime related features\n\ndef add_datetime_features(df):\n    features = [\"Year\", \"Week\", \"Day\", \"Dayofyear\", \"Month\", \"Dayofweek\",\n                \"Is_year_end\", \"Is_year_start\", \"Is_month_end\", \"Is_month_start\",\n                \"Hour\", \"Minute\",]\n    one_hot_features = [\"Month\", \"Dayofweek\"]\n\n    datetime = pd.to_datetime(df.Date * (10 ** 9))\n\n    df['Datetime'] = datetime  # We won't use this for training, but we'll remove it later\n\n    for feature in features:\n        new_column = getattr(datetime.dt, feature.lower())\n        if feature in one_hot_features:\n            df = pd.concat([df, pd.get_dummies(new_column, prefix=feature)], axis=1)\n        else:\n            df[feature] = new_column\n    return df\n\ndf = add_datetime_features(df)\ndf.columns","09082479":"## 3. Split data into train \/ validation (leaving the last six months for validation)\n\nfrom dateutil.relativedelta import relativedelta\n\neval_from = df['Datetime'].max() + relativedelta(months=-6)  # Here we set the 6 months threshold\ntrain_df = df[df['Datetime'] < eval_from]\nvalid_df = df[df['Datetime'] >= eval_from]\n\nprint(f\"Train data: {train_df['Datetime'].min()} -> {train_df['Datetime'].max()} | {len(train_df)} samples.\")\nprint(f\"Valid data: {valid_df['Datetime'].min()} -> {valid_df['Datetime'].max()} | {len(valid_df)} samples.\")","000f4979":"## 4. Prepare data for XGBoosting (DataFrame --> DMatrix)\n\nimport xgboost as xgb\n\nlabel_col = \"Consumption_MW\"  # The target values are in this column\nto_drop = [label_col, \"Date\", \"Datetime\"]  # Columns we do not need for training\n\nxg_trn_data = xgb.DMatrix(train_df.drop(columns=to_drop), label=train_df[label_col])\nxg_vld_data = xgb.DMatrix(valid_df.drop(columns=to_drop), label=valid_df[label_col])","86df9ff6":"## 5. Train (mostly with default parameters; it overfits like hell)\n\nnum_round = 300\nxgb_param = {\"objective\": \"reg:squarederror\" if xgb.__version__ > '0.82' else 'reg:linear',\n            'eta': 0.1, 'booster': 'gbtree', 'max_depth': 5}\nwatchlist = [(xg_trn_data, \"train\"), (xg_vld_data, \"valid\")]\n\nbst = xgb.train(xgb_param, xg_trn_data, num_round, watchlist)","5d8946a0":"## 6. Read test dataset, use the bst for prediction, save submission csv\n\ntest_df = pd.read_csv(\"..\/input\/test_electricity.csv\")\ntest_df = add_datetime_features(test_df)\nxgb_test_data = xgb.DMatrix(test_df.drop(columns=[\"Date\", \"Datetime\"]))\n\nsolution_df = pd.DataFrame(test_df[\"Date\"])\nsolution_df[\"Consumption_MW\"] = bst.predict(xgb_test_data)\nsolution_df.to_csv(\"sample_submission.csv\", index=False)\nprint(\"Done!\")","45331e85":"# Electricity - Demo training with XGBoost\n\nThe current notebook demonstrates training an XGBoost model on the `electricity` dataset.\n\nThe following steps are performed:\n\n  0. Install some needed python packages.\n  1. The train set is read into a DataFrame.\n  2. Do some preprocessing: datetime features are manually extracted from the timestamp.\n  3. Split the labelled data in two: training \/ validation.\n  4. Prepare data for xgboost.\n  5. Train an XGBoost model.\n  6. Prepare a Kaggle submission on test data."}}