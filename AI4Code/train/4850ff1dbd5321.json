{"cell_type":{"9f47f481":"code","0e2ce9f9":"code","2b86cf51":"code","e85890f4":"code","f1f6e731":"code","6b38c454":"code","052d01a7":"code","12572573":"code","9dbade62":"code","b8334f90":"code","1082fc54":"code","4ad3f089":"code","7387008c":"code","0e484770":"code","c35565aa":"code","45b7e649":"markdown"},"source":{"9f47f481":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.metrics import accuracy_score\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","0e2ce9f9":"import requests\nfrom bs4 import BeautifulSoup\nfrom nltk.tokenize import sent_tokenize,word_tokenize\nfrom nltk.corpus import stopwords\nfrom string import punctuation","2b86cf51":"def textAnalysis(articleURL):\n#     articleURL=\"https:\/\/arstechnica.com\/cars\/2018\/10\/honda-will-use-gms-self-driving-technology-invest-2-75-billion\/\"\n    response = requests.get(articleURL)\n    response.encoding = 'utf-8'\n    data = response.text\n    soup = BeautifulSoup(data, features=\"html.parser\")\n    print(soup)\n\n","e85890f4":"    #In Kaggle I can't put all of the code under the if block while it's in different kernals or else i would. \n    if soup.find('article').text:\n        print(\"Article has article tag\")\n    else: \n        print(\"Aerticle has no article tag\")\n   ","f1f6e731":"    text = ' '.join(map(lambda p: p.text, soup.find_all('article')))\n\n    text = text.replace(\"\\n\", \" \")\n    text = text.replace(\"'s\", \"\")\n    text = text.replace(\".\", \". \")\n    print(text)","6b38c454":"    text.encode('ascii', 'ignore')\n    print(text)\n                                               ","052d01a7":"    sents = sent_tokenize(text)\n    sents","12572573":"    word_sent = word_tokenize(text.lower())\n    word_sent","9dbade62":"        _stopwords = set(stopwords.words('english') + list(punctuation))\n        _stopwords","b8334f90":"    # Filter out stopword\n    word_sent=[word for word in word_sent if word not in _stopwords]\n    word_sent","1082fc54":"    from nltk.probability import FreqDist\n    freq = FreqDist(word_sent)\n    freq\n","4ad3f089":"    from heapq import nlargest\n    nlargest(10, freq, key=freq.get)","7387008c":"    # We want to create a signifcant score ordered by highest frequency\n    from collections import defaultdict\n    ranking = defaultdict(int)\n    for i,sent in enumerate(sents):\n        for w in word_tokenize(sent.lower()):\n            if w in freq:\n                ranking[i] += freq[w]\n    ranking","0e484770":"    # Top 4 Sentences\n    sents_idx = nlargest(3, ranking, key=ranking.get)\n    sents_idx","c35565aa":"def main():\n     textAnalysis(\"https:\/\/arstechnica.com\/cars\/2018\/10\/honda-will-use-gms-self-driving-technology-invest-2-75-billion\/\")","45b7e649":"# TL;DR - Automated Gist\n## Find the most important words\n### Word Importance = Word Frequency\n## Compute a significance score for sentences based on words they contain\n### Significant score = Sum(Word Importance)\n## Pick the top most significant sentences\n\n* Retrieve Text\n* Preprocess Text\n* Extract Sentences\n\n#### Source: PluralSight - Natural Langauge Processing"}}