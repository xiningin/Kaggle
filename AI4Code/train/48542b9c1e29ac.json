{"cell_type":{"4e32f6b6":"code","fb8a560b":"code","519189f2":"code","0e6bfaeb":"code","2245cbde":"code","6d48cd2f":"code","97f25dcc":"code","bc3fcd56":"code","ab019594":"code","3d47fd33":"code","7a1b1b6d":"code","12bb702f":"code","985a9f10":"code","acb2830f":"code","d07788fd":"code","95c8813c":"code","ec4ca8db":"code","9e5112f5":"code","57f82ec1":"code","aac8a01d":"code","a230d4d7":"code","8b4e4773":"code","d70fec2f":"code","05ab7fb7":"code","ced72663":"code","fe366eab":"code","055459f6":"code","3b9b4841":"markdown"},"source":{"4e32f6b6":"import numpy as np\nimport pandas as pd \n#from keras.preprocessing.image import ImageDataGenerator, load_img\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport random\nimport os\nprint(os.listdir(\"\/kaggle\/input\/catdog-small\/\"))","fb8a560b":"path='\/kaggle\/input\/catdog-small\/data\/'","519189f2":"FAST_RUN = True\nIMAGE_WIDTH=64\nIMAGE_HEIGHT=64\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS=3","0e6bfaeb":"filenames = os.listdir(path)\ncategories = []\nfor filename in filenames:\n    category = filename.split('.')[0]\n    if category == 'dog':\n        categories.append(1)\n    else:\n        categories.append(0)\n\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n})","2245cbde":"df.head()","6d48cd2f":"df.tail()","97f25dcc":"df['category'].value_counts().plot.bar()","bc3fcd56":"sample = random.choice(filenames)\nimage = load_img(path+sample)\nplt.imshow(image)","ab019594":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n\nmodel = Sequential()\n\nmodel.add(Dense(32, activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\nmodel.add(BatchNormalization())\n#model.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(BatchNormalization())\n#model.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\n#model.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2, activation='softmax')) # 2 because we have cat and dog classes\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.summary()","3d47fd33":"\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\n#to prevent over fitting we will stop the learning after 10 epochs and val_loss value not decreased\nearlystop = EarlyStopping(patience=10)","7a1b1b6d":"# We will reduce the learning rate when then accuracy not increase for 2 steps\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","12bb702f":"callbacks = [earlystop, learning_rate_reduction]","985a9f10":"df[\"category\"] = df[\"category\"].replace({0: 'cat', 1: 'dog'}) \ntrain_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\ntrain_df = train_df.reset_index(drop=True)\nvalidate_df = validate_df.reset_index(drop=True)","acb2830f":"total_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]\nbatch_size=4","d07788fd":"train_datagen = ImageDataGenerator(\n    rotation_range=15,\n    #rescale=1.\/255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    path, \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","95c8813c":"#validation_datagen = ImageDataGenerator(rescale=1.\/255)\nvalidation_datagen = ImageDataGenerator()\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate_df, \n    path, \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","ec4ca8db":"# example_df = train_df.sample(n=1).reset_index(drop=True)\n# example_generator = train_datagen.flow_from_dataframe(\n#     example_df, \n#     path, \n#     x_col='filename',\n#     y_col='category',\n#     target_size=IMAGE_SIZE,\n#     class_mode='categorical'\n# )","9e5112f5":"epochs=5 if FAST_RUN else 50\nhistory = model.fit_generator(\n    train_generator, \n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=total_validate\/\/batch_size,\n    steps_per_epoch=total_train\/\/batch_size,\n    callbacks=callbacks\n)","57f82ec1":"# epochs=5 if FAST_RUN else 50\n# history = model.fit_generator(\n#     train_generator, \n#     epochs=epochs,\n#     validation_data=validation_generator,\n#     validation_steps=total_validate\/\/batch_size,\n#     steps_per_epoch=total_train\/\/batch_size,\n#     callbacks=callbacks\n# )","aac8a01d":"model.save_weights(\"model.h5\")","a230d4d7":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\nax1.plot(history.history['loss'], color='b', label=\"Training loss\")\nax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\nax1.set_xticks(np.arange(1, epochs, 1))\nax1.set_yticks(np.arange(0, 1, 0.1))\n\nax2.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax2.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nax2.set_xticks(np.arange(1, epochs, 1))\n\nlegend = plt.legend(loc='best', shadow=True)\nplt.tight_layout()\nplt.show()","8b4e4773":"# predict = model.predict_generator(validation_generator)\n# predict","d70fec2f":"### from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n\nmodel = Sequential()\n\nmodel.add(Conv2D(64, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n#model.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\n#model.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\n#model.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2, activation='softmax')) # 2 because we have cat and dog classes\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.summary()","05ab7fb7":"\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\n#to prevent over fitting we will stop the learning after 10 epochs and val_loss value not decreased\nearlystop = EarlyStopping(patience=10)\n# We will reduce the learning rate when then accuracy not increase for 2 steps\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\ncallbacks = [earlystop, learning_rate_reduction]","ced72663":"df[\"category\"] = df[\"category\"].replace({0: 'cat', 1: 'dog'}) \ntrain_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\ntrain_df = train_df.reset_index(drop=True)\nvalidate_df = validate_df.reset_index(drop=True)\ntotal_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]\nbatch_size=4","fe366eab":"train_datagen = ImageDataGenerator()\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    path, \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","055459f6":"epochs=5 if FAST_RUN else 50\nhistory = model.fit_generator(\n    train_generator, \n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=total_validate\/\/batch_size,\n    steps_per_epoch=total_train\/\/batch_size,\n    callbacks=callbacks\n)","3b9b4841":"Input Layer: It represent input image data. It will reshape image into single diminsion array. Example your image is 64x64 = 4096, it will convert to (4096,1) array.\nConv Layer: This layer will extract features from image.\nPooling Layer: This layerreduce the spatial volume of input image after convolution.\nFully Connected Layer: It connect the network from a layer to another layer\nOutput Layer: It is the predicted values layer."}}