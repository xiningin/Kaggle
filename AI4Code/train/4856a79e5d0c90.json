{"cell_type":{"2d186b5e":"code","ee4d9f50":"code","ad04e284":"code","d13fbd98":"code","e2ddbd5d":"code","8dcfb518":"code","bafed389":"code","cfb827de":"code","fd14ab7b":"code","f9b5f77f":"code","33b7cde6":"code","297c1b06":"code","b99a8788":"code","110ae7ec":"code","7be8615a":"code","f812da85":"code","dbfed0f3":"code","a67d3652":"code","4125994e":"code","f7a9d7cf":"code","014b09e2":"markdown","f87431b8":"markdown","86f9b2b2":"markdown","92888eea":"markdown"},"source":{"2d186b5e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport re\n\n# Modelling Algorithms\n\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn import linear_model\n\n# Modelling Helpers\nfrom sklearn.preprocessing import Imputer , Normalizer , scale\nfrom sklearn.feature_selection import RFECV\n\n# Visualisation\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\n\n\nfrom sklearn.utils import shuffle","ee4d9f50":"# get TMDB Box Office Prediction train & test csv files as a DataFrame\ntrain = pd.read_csv(\"\/kaggle\/input\/tmdb-box-office-prediction\/train.csv\")\ntest  = pd.read_csv(\"\/kaggle\/input\/tmdb-box-office-prediction\/test.csv\")","ad04e284":"# deal with release day\n#train.loc[test['release_date'].isnull() == True, 'release_date'] = '01\/01\/98'\ntest.loc[test['release_date'].isnull() == True, 'release_date'] = '01\/01\/98'\ndef fix_date(x):\n    \"\"\"\n    Fixes dates which are in 20xx\n    \"\"\"\n    year = x.split('\/')[2]\n    if int(year) <= 19:\n        return x[:-2] + '20' + year\n    else:\n        return x[:-2] + '19' + year\ntrain['release_date'] = train['release_date'].apply(lambda x: fix_date(x))\ntest['release_date'] = test['release_date'].apply(lambda x: fix_date(x))\ntrain['release_date'] = pd.to_datetime(train['release_date'])\ntest['release_date'] = pd.to_datetime(test['release_date'])\nprint(type(train['release_date'][0]))\ndef process_date(df):\n    date_parts = [\"year\", \"weekday\", \"month\", 'weekofyear', 'day', 'quarter']\n    for part in date_parts:\n        part_col = 'release_date' + \"_\" + part\n        df[part_col] = getattr(df['release_date'].dt, part).astype(int)\n    \n    return df\n\ntrain = process_date(train)\ntest = process_date(test)\nprint(train['release_date'])","d13fbd98":"# Shuffle data\ntr_shuffle = shuffle(train, random_state = 43).reset_index(drop=True)\n\n#selected_features = {\"budget\",\"popularity\", \"release_date_year\", \"release_date_day\", \"release_date_weekday\", \"release_date_month\"}\n# Split into training and validation data set\n#data_train=tr_shuffle[0:2499]\n#data_validate=tr_shuffle[2500:2999]\n# Create input and out for training and validation set\n#data_tr_x = data_train[selected_features]\n#data_tr_y = data_train[{\"revenue\"}]\n#data_val_x = data_validate[selected_features]\n#data_val_y = data_validate[{\"revenue\"}]\n#data_val_title = data_validate[{\"original_title\"}]\n\n# Select features\nselected_features = {\"budget\",\"popularity\", \"release_date_year\", \"release_date_day\", \"release_date_weekday\", \"release_date_month\"}\n\ntr_shuffle_revenue = tr_shuffle[\"revenue\"]\n#create x\ntr_shuffle_feature_list = tr_shuffle[selected_features]\n# create title for validation\n#tr_shuffle_title = tr_shuffle[{\"original_title\"}]\ntrain_genres = tr_shuffle[{\"genres\"}]\n#print(train_genres.genres.unique())\n#print(train_genres)\n#vec = DictVectorizer()\n#train_genres.head()\np = re.compile(r'\\d+')\nidList = []\nfor index, row in train_genres.iterrows():\n    #print(row)\n    for col in row.iteritems():\n        if(type(col[1]) is not str):\n            continue\n        if(len(col[1]) <= 2):\n                continue\n        allIDs = p.findall(col[1])\n        for id in allIDs:\n            idNum = eval(id);\n            if idNum not in idList:\n                idList.append(idNum)\n#train_genres.genres.unique()\n\n\nprint(idList)\nColumn_Names = []\nfor id in idList:\n    name= 'Genre'+ str(id)\n    Column_Names.append(name)\n\n\ntrain_genre_list = pd.DataFrame()\nidx = 0\nfor name in Column_Names:\n    train_genre_list.insert(idx,name,np.zeros(len(train_genres)))\n    idx = idx + 1\n\n\n#print(train_genre_list)\nfor rowidx, row in train_genres.iterrows():\n    for col in row.iteritems():\n        if(type(col[1]) is not str):\n            continue\n        if(len(col[1]) <= 2):\n                continue\n        allIDs = p.findall(col[1])\n        for id in allIDs:\n            idNum = eval(id);\n            train_genre_list.loc()\n            train_genre_list[Column_Names[idList.index(idNum)]].loc[rowidx]=1\n            #print(each_row)   \n    #train_genre_list.\n#vec.fit_transform(train_genres).toarray()\n\n\nprint(train_genre_list)\n    \ntr_shuffle_feature_list.join(train_genre_list )\n# Split into training and validation data set of feature list\ndata_train=tr_shuffle_feature_list[0:2499]\ndata_validate=tr_shuffle_feature_list[2500:2999]\n#slip into training and validation for y\ndata_train_y=tr_shuffle_revenue[0:2499]\ndata_validate_y=tr_shuffle_revenue[2500:2999]\n\ndata_tr_x = data_train\ndata_tr_y = data_train_y\ndata_val_x = data_validate\ndata_val_y = data_validate_y\ndata_val_title = tr_shuffle[{\"original_title\"}][2500:2999]\n","e2ddbd5d":"\ndef plot_correlation_map( df ):\n    corr = train.corr()\n    _ , ax = plt.subplots( figsize =( 23 , 22 ) )\n    cmap = sns.diverging_palette( 220 , 10 , as_cmap = True )\n    _ = sns.heatmap(\n        corr, \n        cmap = cmap,\n        square=True, \n        cbar_kws={ 'shrink' : .9 }, \n        ax=ax, \n        annot = True, \n        annot_kws = { 'fontsize' : 12 }\n    )\n\ndef plot_distribution( df , var , target , **kwargs ):\n    row = kwargs.get( 'row' , None )\n    col = kwargs.get( 'col' , None )\n    facet = sns.FacetGrid( df , hue=target , aspect=4 , row = row , col = col )\n    facet.map( sns.kdeplot , var , shade= True )\n    facet.set( xlim=( 0 , df[ var ].max() ) )\n    facet.add_legend()","8dcfb518":"train.corr()\nprint(train[\"release_date_day\"])","bafed389":"# edit cast Show first main caracter in first movie with ID and name\nprint(train.cast.shape[0])\n#for index in train.cast:\n#    print(int((index.split('\\'id\\':'))[1].split(',')[0]))\n#    print((index.split('\\'name\\': \\''))[1].split('\\',')[0])\nprint(int((train.cast[1].split('\\'id\\':'))[1].split(',')[0]))\nprint((train.cast[1].split('\\'name\\': \\''))[1].split('\\',')[0])","cfb827de":"np.count_nonzero(train.budget)","fd14ab7b":"train.describe()\n","f9b5f77f":"data=pd.concat([train['budget'],train['revenue']],axis=1)\ndata.plot.scatter(x='budget',y='revenue',xlim=(0,1e7),ylim=(0,1e8))","33b7cde6":"#plot_correlation_map(train)","297c1b06":"## Splitting into Test and validation data and feature selection\n#\n## Selecting features Budget and Popularity\n#train_mod = train[{\"budget\",\"popularity\"}]\n#\n## Selecting the first 2001 indices of the training data for training\n#train_train = train_mod[0:2000]\n## Selecting the rest of the training data for validation\n#train_val= train_mod[2001:2999]\n#\n## Obtain labels\n#train_mod_y = train[{\"revenue\"}]\n#train_train_y = train_mod_y[0:2000]\n#train_val_y= train_mod_y[2001:2999]\n#train_val_title = train[\"original_title\"][2001:2999]","b99a8788":"# Initialize and train a linear regression (Lasso) model\n\nmodel1 = linear_model.Lasso(alpha=1.2, normalize = False, tol = 1e-3)\nmodel1.fit(data_tr_x,data_tr_y.values.ravel())\n# Evaluate on the training data\nres1 = model1.predict(data_val_x)\n# Obtain R2 score (ordinary least square)\nacc_lasso = model1.score(data_val_x, data_val_y)\nacc_lasso_trained = model1.score(data_tr_x, data_tr_y)\nprint(acc_lasso, acc_lasso_trained)\n# Create the table for comparing predictions with labels\nevaluation = pd.DataFrame({'Title': data_val_title.values.ravel(),'Prediction': res1.round(), 'Actual revenue': data_val_y.values.ravel(), 'Relative error': res1\/data_val_y.values.ravel()})\nevaluation","110ae7ec":"# Initialize and train a ridge regression model\n\nmodel2 = linear_model.Ridge(alpha=100000.0)\nmodel2.fit(data_tr_x,data_tr_y.values.ravel())\n# Evaluate on the training data\nres2 = model2.predict(data_val_x)\n# Obtain R2 score (ordinary least square)\nacc_ridge = model2.score(data_val_x, data_val_y)\nacc_ridge_trained = model2.score(data_tr_x, data_tr_y)\n# Create the table for comparing predictions with labels\nevaluation = pd.DataFrame({'Title': data_val_title.values.ravel(),'Prediction': res2.round(), 'Actual revenue': data_val_y.values.ravel(), 'Relative error': res2\/data_val_y.values.ravel()})\nevaluation","7be8615a":"# Initialize and train a elasticNet model\nmodel3 = linear_model.ElasticNet(random_state = 0)\nmodel3.fit(data_tr_x,data_tr_y.values.ravel())\n# Evaluate on the training data\nres3 = model3.predict(data_val_x)\n# Obtain R2 score (ordinary least square)\nacc_elasticNet = model3.score(data_val_x, data_val_y)\nacc_elasticNet_trained = model3.score(data_tr_x, data_tr_y)\n# Create the table for comparing predictions with labels\nevaluation = pd.DataFrame({'Title': data_val_title.values.ravel(),'Prediction': res3.round(), 'Actual revenue': data_val_y.values.ravel(), 'Relative error': res3\/data_val_y.values.ravel()})\nevaluation","f812da85":"# model 4\nimport lightgbm as lgb\nimport eli5\n#data_tr_y = np.log1p(data_tr_y)\n#data_val_y = np.log1p(data_val_y)\nparams = {'num_leaves': 50,\n         'min_data_in_leaf': 20,\n         'objective': 'regression',\n         'max_depth': 6,\n         'learning_rate': 0.01,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.9,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.9,\n         \"bagging_seed\": 11,\n         \"metric\": 'rmse',\n         \"lambda_l1\": 0.2,\n         \"verbosity\": -1}\nmodel4 = lgb.LGBMRegressor(**params, n_estimators = 20000, nthread = 4, n_jobs = -1)\nmodel4.fit(data_val_x, data_val_y, \n        eval_set=[(data_tr_x,data_tr_y.values.ravel()), (data_val_x, data_val_y)], eval_metric='rmse',\n        verbose=1000, early_stopping_rounds=2000)\nacc_lgb = model4.score(data_val_x, data_val_y)\nacc_lgb_trained = model4.score(data_tr_x, data_tr_y)\n\neli5.show_weights(model4, feature_filter=lambda x: x != '<BIAS>')","dbfed0f3":"models = pd.DataFrame({\n    'Model': ['Ridge regression', 'Lasso', 'ElasticNet', 'lgb'],\n    'Score': [acc_ridge, acc_lasso, acc_elasticNet, acc_lgb],\n    'Score for training data': [acc_ridge_trained, acc_lasso_trained, acc_elasticNet_trained, acc_lgb_trained]})\nmodels.sort_values(by='Score', ascending=False)","a67d3652":"# Function for displaying evaluation metrics\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\nr2=[0] * 3\nrms= [0] * 3\nmae = [0] * 3\n\ndef evaluateModels(predictions, ground_truth, model_names):\n    for idx, prediction in enumerate(predictions):\n        r2[idx] = r2_score(ground_truth, prediction)\n        rms[idx] = np.sqrt(mean_squared_error(ground_truth, prediction))\n        mae[idx] = mean_absolute_error(ground_truth, prediction)\n    \n    scores = pd.DataFrame({\n    'Model': model_names,\n    'R2': r2,\n    'RMS': rms,\n    'MAE': mae})\n    print(scores)\n    # Create error array\n    prediction_error = ground_truth - predictions\n    print(type(prediction_error))\n    ax = sns.boxplot(data = np.transpose(prediction_error), orient = 'h')\n    #return [r2, rms, mae]\n                   ","4125994e":"# Evaluate and compare the different models\nprediction_vector = [res1, res2, res3]\nmodel_names = ['Ridge regression', 'Lasso', 'ElasticNet']\nevaluateModels(prediction_vector, data_val_y.values.ravel(), model_names)","f7a9d7cf":"# Show the top 5 prediction (with minimum error) and the bottom 5 predictions\n# \nmodelres = res1\nabsolute_error =  np.abs(modelres - data_val_y.values.ravel())\nrelative_error = absolute_error\/data_val_y.values.ravel()\n\nevaluation = pd.DataFrame({'Title': data_val_title.values.ravel(), 'budget': data_val_x['budget'].values.ravel(), 'popularity': data_val_x['popularity'].values.ravel(),'Prediction': modelres.round(), 'Actual revenue': data_val_y.values.ravel(), 'Absolute error 1': absolute_error, 'Relative error 1': relative_error})\n\nevaluation.sort_values(by=['Relative error 1'])","014b09e2":" **EVALUATION**","f87431b8":"**Visualization**","86f9b2b2":"Content\n\nImport Libraries\nLoad data\nData Preparation\n  Missing values imputation\n  Feature Engineering\nModeling\n  Build the model\nEvaluation\n  Model performance\n  Feature importance\n  Who gets the best performing model?","92888eea":"**Training**"}}