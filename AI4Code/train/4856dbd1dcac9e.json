{"cell_type":{"a5247e8e":"code","b1218711":"code","54c52c74":"code","23d12d51":"code","b8e77ec5":"code","9d8222b4":"code","056f16c8":"code","937e758d":"code","e678eeb7":"code","ebc2f91c":"code","00ef59da":"code","10ee2eb6":"code","b8cccb6d":"code","70be1107":"code","ed990a4f":"code","c37a373a":"code","f553aebb":"code","fbbe66a1":"code","2b818aaf":"code","cb1566f7":"code","28d2ae2c":"code","a198c7db":"code","b91d7e4e":"code","46653483":"code","ca69ada8":"code","bcbee3c2":"code","401a65c0":"code","d5e98032":"code","f1d3e780":"code","dea0bcf5":"code","4d349ec4":"code","9006e528":"code","f761ed23":"code","81b51d59":"code","0b97f23a":"code","ad644ab0":"code","5bd74d97":"code","b8a1047d":"code","746f5beb":"code","bfe42c7f":"code","69388586":"code","41cf5335":"code","4658a619":"code","5c3f5444":"code","43814214":"code","967dba67":"code","8796d393":"markdown","15d3dcf1":"markdown","76118e75":"markdown","1b13db13":"markdown","bc642f11":"markdown","20800549":"markdown","2cb2871a":"markdown","22dcc54d":"markdown","6ea93f1a":"markdown","f272b249":"markdown"},"source":{"a5247e8e":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_moons, make_circles, make_classification\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn import linear_model, svm, gaussian_process\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.metrics import accuracy_score","b1218711":"df_train_original = pd.read_csv('..\/input\/train.csv')\ndf_test_original = pd.read_csv('..\/input\/test.csv')","54c52c74":"df_train = df_train_original\ndf_test = df_test_original\n\ndf_train = df_train.drop(['Name'], axis=1)\ndf_test = df_test.drop(['Name'], axis=1)\n\ndf_train = df_train.drop(['Cabin'], axis=1)\ndf_test = df_test.drop(['Cabin'], axis=1)\n\ndf_train = df_train.drop(['Ticket'], axis=1)\ndf_test = df_test.drop(['Ticket'], axis=1)\n\ndf_train = df_train.drop(['SibSp'], axis=1)\ndf_test = df_test.drop(['SibSp'], axis=1)\n\ndf_train = df_train.drop(['Parch'], axis=1)\ndf_test = df_test.drop(['Parch'], axis=1)","23d12d51":"all_data = pd.concat((df_train.loc[:,'Sex':'Fare'],\n                     df_test.loc[:,'Sex':'Fare']))","b8e77ec5":"all_data = pd.get_dummies(all_data)","9d8222b4":"all_data = all_data.fillna(all_data.mean())\n#all_data = all_data.fillna(0)","056f16c8":"X_train = all_data[:df_train.shape[0]]","937e758d":"X_test = all_data[df_train.shape[0]:]","e678eeb7":"# Cria o y, ou seja, o que ser\u00e1 previsto, apenas com o campo \"Survived\"\ny = df_train.Survived","ebc2f91c":"from sklearn.ensemble import GradientBoostingRegressor\nimport statsmodels.formula.api as smf\nfrom sklearn.preprocessing import scale\ngbr = GradientBoostingRegressor()\n\ngbr.fit(X_train, y)","00ef59da":"yhat_Train = gbr.predict(X_train)\n","10ee2eb6":"yhat_Train","b8cccb6d":"yhat_test = gbr.predict(X_test)","70be1107":"yhat_test","ed990a4f":"yhat_rounded = [round(x,ndigits=None) for x in yhat_test]\nyhat_rounded = [int(x) for x in yhat_rounded]\n\nyhat_gbr = yhat_rounded\nprint ('# # # # Esse \u00e9 o yhat com o m\u00e9todo Gradiente Descendente # # # #')\nprint ('# # # # Ou seja, a previs\u00e3o se Esse \u00e9 o yhat com o m\u00e9todo Gradiente Descendente # # # #')\nprint (yhat_gbr)","c37a373a":"# Gerando um CSV para o resultado obtido com o Gradiente Descendente:\ndf_test_gbr = df_test\ndf_test_gbr['Survived'] = yhat_gbr\ndf_test_gbr = df_test_gbr.drop(['Pclass'], axis=1)\ndf_test_gbr = df_test_gbr.drop(['Sex'], axis=1)\ndf_test_gbr = df_test_gbr.drop(['Age'], axis=1)\ndf_test_gbr = df_test_gbr.drop(['Fare'], axis=1)\ndf_test_gbr = df_test_gbr.drop(['Embarked'], axis=1)\ndf_test_gbr.to_csv('Titanic_GBR.csv', index = False)","f553aebb":"# 3) Aplly Logistic Regression Model\nfrom sklearn.linear_model import LogisticRegression\n\n# Logistic Regression\nlogreg = LogisticRegression()","fbbe66a1":"logreg.fit(X_train, y)","2b818aaf":"yhat_test = logreg.predict(X_test)","cb1566f7":"yhat_test","28d2ae2c":"# Gerando um CSV para o resultado obtido com o Gradiente Descendente:\ndf_test_logreg = df_test\ndf_test_logreg['Survived'] = yhat_test\ndf_test_logreg = df_test_logreg.drop(['Pclass'], axis=1)\ndf_test_logreg = df_test_logreg.drop(['Sex'], axis=1)\ndf_test_logreg = df_test_logreg.drop(['Age'], axis=1)\ndf_test_logreg = df_test_logreg.drop(['Fare'], axis=1)\ndf_test_logreg = df_test_logreg.drop(['Embarked'], axis=1)\ndf_test_logreg.to_csv('Titanic_LOGREG.csv', index = False)","a198c7db":"# 5) Aplly XGBOOST Model\nfrom xgboost import XGBClassifier","b91d7e4e":"xgb = XGBClassifier()\nxgb.fit(X_train, y)","46653483":"yhat_test = xgb.predict(X_test)","ca69ada8":"yhat_test","bcbee3c2":"# Gerando um CSV para o resultado obtido com o Gradiente Descendente:\ndf_test_xgboost = df_test\ndf_test_xgboost['Survived'] = yhat_test\ndf_test_xgboost = df_test_xgboost.drop(['Pclass'], axis=1)\ndf_test_xgboost = df_test_xgboost.drop(['Sex'], axis=1)\ndf_test_xgboost = df_test_xgboost.drop(['Age'], axis=1)\ndf_test_xgboost = df_test_xgboost.drop(['Fare'], axis=1)\ndf_test_xgboost = df_test_xgboost.drop(['Embarked'], axis=1)\ndf_test_xgboost.to_csv('Titanic_XGBOOST.csv', index = False)","401a65c0":"# 6) Aplly KNeighbors Model\nknn = KNeighborsClassifier()\nknn.fit(X_train, y)\n","d5e98032":"knn_test = knn.predict(X_test)","f1d3e780":"knn_test","dea0bcf5":"# Gerando um CSV para o resultado obtido com o KNeighbors Model:\ndf_test_knn = df_test\ndf_test_knn['Survived'] = knn_test\ndf_test_knn = df_test_knn.drop(['Pclass'], axis=1)\ndf_test_knn = df_test_knn.drop(['Sex'], axis=1)\ndf_test_knn = df_test_knn.drop(['Age'], axis=1)\ndf_test_knn = df_test_knn.drop(['Fare'], axis=1)\ndf_test_knn = df_test_knn.drop(['Embarked'], axis=1)\ndf_test_knn.to_csv('Titanic_KNN.csv', index = False)","4d349ec4":"# Aplly SVC Model\nsvc = SVC(probability=True)\nsvc.fit(X_train, y)","9006e528":"svc_test = svc.predict(X_test)","f761ed23":"svc_test","81b51d59":"# Gerando um CSV para o resultado obtido com o SVC Model:\ndf_test_svc = df_test\ndf_test_svc['Survived'] = svc_test\ndf_test_svc = df_test_svc.drop(['Pclass'], axis=1)\ndf_test_svc = df_test_svc.drop(['Sex'], axis=1)\ndf_test_svc = df_test_svc.drop(['Age'], axis=1)\ndf_test_svc = df_test_svc.drop(['Fare'], axis=1)\ndf_test_svc = df_test_svc.drop(['Embarked'], axis=1)\ndf_test_svc.to_csv('Titanic_SVC.csv', index = False)","0b97f23a":"# Aplly Decision Tree Model\ndtc = DecisionTreeClassifier()\ndtc.fit(X_train, y)","ad644ab0":"dtc_test = dtc.predict(X_test)","5bd74d97":"dtc_test","b8a1047d":"# Gerando um CSV para o resultado obtido com o Decision Tree Model:\ndf_test_dtc = df_test\ndf_test_dtc['Survived'] = dtc_test\ndf_test_dtc = df_test_dtc.drop(['Pclass'], axis=1)\ndf_test_dtc = df_test_dtc.drop(['Sex'], axis=1)\ndf_test_dtc = df_test_dtc.drop(['Age'], axis=1)\ndf_test_dtc = df_test_dtc.drop(['Fare'], axis=1)\ndf_test_dtc = df_test_dtc.drop(['Embarked'], axis=1)\ndf_test_dtc.to_csv('Titanic_DTC.csv', index = False)","746f5beb":"# Aplly GaussianNB Model\ngnb = GaussianNB()\ngnb.fit(X_train, y)","bfe42c7f":"gnb_test = gnb.predict(X_test)","69388586":"gnb_test","41cf5335":"# Gerando um CSV para o resultado obtido com o GaussianNB Model:\ndf_test_gnb = df_test\ndf_test_gnb['Survived'] = gnb_test\ndf_test_gnb = df_test_gnb.drop(['Pclass'], axis=1)\ndf_test_gnb = df_test_gnb.drop(['Sex'], axis=1)\ndf_test_gnb = df_test_gnb.drop(['Age'], axis=1)\ndf_test_gnb = df_test_gnb.drop(['Fare'], axis=1)\ndf_test_gnb = df_test_gnb.drop(['Embarked'], axis=1)\ndf_test_gnb.to_csv('Titanic_GNB.csv', index = False)","4658a619":"# Aplly Neural Model\nnn = MLPClassifier(hidden_layer_sizes=(100,100,50))\nnn.fit(X_train, y)","5c3f5444":"nn_test = nn.predict(X_test)","43814214":"nn_test","967dba67":"# Gerando um CSV para o resultado obtido com o Neural Model:\ndf_test_nn = df_test\ndf_test_nn['Survived'] = nn_test\ndf_test_nn = df_test_nn.drop(['Pclass'], axis=1)\ndf_test_nn = df_test_nn.drop(['Sex'], axis=1)\ndf_test_nn = df_test_nn.drop(['Age'], axis=1)\ndf_test_nn = df_test_nn.drop(['Fare'], axis=1)\ndf_test_nn = df_test_nn.drop(['Embarked'], axis=1)\ndf_test_nn.to_csv('Titanic_NN.csv', index = False)","8796d393":"# Substitui os campos nulos pelas m\u00e9dias da coluna em quest\u00e3o\n","15d3dcf1":"# 3) Dropando as colunas e adicionando em um novo df.\n","76118e75":"# 2) Aplly Gradient Boost Model\n\n","1b13db13":"# creating matrices for sklearn:\n\n# Cria Matriz X_train utilizando a Matriz com todos os dados all_data: do inicio da matriz (:) at\u00e9 o fim  da matriz df_train.shape[0]","bc642f11":"# Cria Matriz X_test utilizando a Matriz com todos os dados all_data: a partir do \u00faltimo registro matriz df_train.shape[0], ou seja, todos os registros que n\u00e3o estiverem em df_train\n","20800549":"# concatena os dados do treino e teste, apenas entres os campos \"Pclass\" e \"Embarked\"\n# Ou seja, o campo \"PassengerId\" de ambos DFs ser\u00e3o deletados e o campo \"Survived\" do DF Treino","2cb2871a":"# Get_Dummies para transformar categoricos em Num\u00e9ricos\n","22dcc54d":"# 1) Import all Library that will be used\n","6ea93f1a":"# 2) Data treatment and cleaning\n","f272b249":"# Cria o y, ou seja, o que ser\u00e1 previsto, apenas com o campo \"Survived\"\n"}}