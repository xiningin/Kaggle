{"cell_type":{"9c490f1f":"code","e93effcb":"code","8eaf12b1":"code","ce0f50e7":"code","0f1c987a":"code","e870059d":"code","0962bed1":"code","03365961":"code","765a7b6a":"code","3928ec25":"code","8163da8a":"code","a5255bb9":"code","bb4176bf":"code","2d169c40":"code","609f294c":"code","8e0c700d":"code","a9981d51":"code","d8fc39be":"code","a55ff707":"code","b8ea96f8":"code","3ffe1f6f":"code","ebea2ab9":"code","fd5a6bd8":"code","f3363117":"code","dbbb985f":"code","60b7bc03":"code","e30113a7":"code","37e1ddb8":"code","2b396b34":"code","216373bd":"code","14f4b4fa":"code","fd7a44dc":"code","7d2dfa73":"code","cfacb592":"code","e9940cb7":"code","45eb2267":"code","956a42ec":"code","d0262c17":"code","7fa55c5a":"code","c9535ee7":"code","17ebf1c7":"markdown","ba30106b":"markdown","b6f88dcc":"markdown","6871f597":"markdown","63f924b9":"markdown","a98a57b7":"markdown","cbe11c21":"markdown","eff072c8":"markdown","66000a52":"markdown","8ac7f166":"markdown","81b48775":"markdown","8af263f5":"markdown","2151441d":"markdown"},"source":{"9c490f1f":"import pandas as pd\r\nimport numpy as np\r\nfrom pathlib import Path\r\nimport os\r\nimport os.path\r\nimport seaborn as sns\r\nimport matplotlib.pyplot as plt \r\nimport cv2\r\nplt.style.use('seaborn')","e93effcb":"Flowers_All_Path = Path(\"..\/input\/flowers-recognition\/flowers\")","8eaf12b1":"Flowers_Path = list(Flowers_All_Path.glob(r\"*\/*.jpg\"))","ce0f50e7":"Flowers_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Flowers_Path))\r\n","0f1c987a":"image_path = pd.Series(Flowers_Path,name=\"ImagePath\").astype(str)","e870059d":"image_lables = pd.Series(Flowers_Labels,name=\"Type\")","0962bed1":"display(image_path.head())","03365961":"df = pd.concat([image_path,image_lables],axis=1)","765a7b6a":"df.head()","3928ec25":"df.shape","8163da8a":"df = df.sample(frac=1).reset_index(drop=True)","a5255bb9":"df.head()","bb4176bf":"df.shape","2d169c40":"plt.style.use('seaborn')\r\nsns.countplot(x='Type', data=df)\r\nplt.show()","609f294c":"import random\r\n\r\nfig,ax=plt.subplots(5,2)\r\nfig.set_size_inches(15,15)\r\nfor i in range(5):\r\n    for j in range (2):\r\n        l=random.randint(0,len(df[['Type']].values))\r\n        ax[i,j].imshow(plt.imread(df.iloc[l,0]))\r\n        ax[i,j].set_title(df.iloc[l,1])\r\n        \r\nplt.tight_layout()","8e0c700d":"from sklearn.preprocessing import LabelEncoder\r\nfrom tensorflow.keras.utils import to_categorical\r\nle = LabelEncoder()","a9981d51":"X = df.iloc[:,0]\r\ny = df.iloc[:,1]","d8fc39be":"y = le.fit_transform(y)\n# y = to_categorical(y,5)","a55ff707":"flower_imgs = []\r\nfor i in X:\r\n    img = cv2.imread(i)\r\n    img = cv2.resize(img, (64,64))\r\n    flower_imgs.append(img)","b8ea96f8":"flower_imgs = np.array(flower_imgs)","3ffe1f6f":"X = flower_imgs","ebea2ab9":"np.unique(y)","fd5a6bd8":"from sklearn.model_selection import train_test_split","f3363117":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.4, shuffle=True)","dbbb985f":"X_test.shape,X_train.shape","60b7bc03":"# X_train = X_train.reshape(2593, 64*64*3)\nX_train = X_train.astype('float32')\/255\n\n# X_test = X_test.reshape(1730, 64*64*3)\nX_test = X_test.astype('float32')\/255","e30113a7":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D","37e1ddb8":"class myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(logs.get('accuracy')>=0.98):\n      print(\"\\nReached at desired accuracy so cancelling training!\")\n      self.model.stop_training = True","2b396b34":"model = Sequential([Conv2D(16,(3,3),activation=\"relu\",input_shape=(64,64,3)),\n                    MaxPooling2D((2,2)),\n                    Conv2D(32,(3,3),activation=\"relu\", padding='same'),\n                    MaxPooling2D((2,2)),\n                    Conv2D(64,(3,3),activation=\"relu\", padding='same'),\n                    MaxPooling2D((2,2)),\n                    Conv2D(128,(2,2),activation=\"relu\", padding='same'),\n                    MaxPooling2D((2,2)),\n                    Conv2D(256,(2,2),activation=\"relu\", padding='same'),\n                    MaxPooling2D((2,2)),\n                    Flatten(),\n                    Dense(512, activation='relu'),   \n                    Dense(5, activation='softmax')])","216373bd":"model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","14f4b4fa":"callback = myCallback()","fd7a44dc":"history = model.fit(X_train,y_train, epochs = 500,callbacks=[callback], batch_size=512)","7d2dfa73":"plt.style.use('seaborn')\r\npd.DataFrame(history.history).plot()\r\nplt.xlabel(\"Epochs\")\r\nplt.tight_layout()","cfacb592":"loss,acc = model.evaluate(X_test,y_test)\r\nplt.style.use('seaborn')\r\nsns.barplot(data=pd.DataFrame([{'Loss':loss,\"Accuracy\":acc}])*100)\r\nplt.ylabel(\"Percentage\")\r\nplt.title(\"Model Evaluation\")\r\nplt.tight_layout()","e9940cb7":"y_pred = model.predict(X_test)","45eb2267":"import random\nfig,ax=plt.subplots(5,2)\nfig.set_size_inches(15,15)\nfor i in range(5):\n    for j in range (2):\n        l=random.randint(0,len(X_test))\n        ax[i,j].imshow(X_test[l])\n        ax[i,j].set_title(\"Actual Name: \" + \"\".join(le.inverse_transform([y_test[l]]))+\n        \"\\nPredicted Name: \" + \"\".join(le.inverse_transform(y_pred.argmax(1))[l]))\n        \nplt.tight_layout()","956a42ec":"from sklearn.metrics import accuracy_score\nprint(\"Accuracy {:.3f}\".format(accuracy_score(y_test,y_pred.argmax(1))*100))","d0262c17":"from sklearn.metrics import confusion_matrix","7fa55c5a":"confusion_matrix(y_test,y_pred.argmax(1))","c9535ee7":"sns.heatmap(confusion_matrix(y_test,y_pred.argmax(1)), xticklabels=le.inverse_transform(np.unique(y_test)), yticklabels=le.inverse_transform(np.unique(y_test)), annot=True)","17ebf1c7":"WORKFLOW : <br>\r\nLoad Data <brr>\r\nEncode labels.<br>\r\nCreate Model<br>\r\nCompilation Step (Note : Its a Multiclass Classification problem , select loss , metrics according to it)<br>\r\nTrain the Model.<br>\r\nIf the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .<br>\r\nPrediction should be > 85%<br>\r\nEvaluation Step<br>\r\nPrediction<br>\r\n\r\n\r\n","ba30106b":"Flowers Recognition <br>\r\nDataset Description:<br>\r\n\r\nThis dataset contains 4242 images of flowers.<br>\r\nThe data collection is based on the data flicr, google images, yandex images.<br>\r\nYou can use this datastet to recognize plants from the photo.<br>\r\n\r\nAttribute Information:<br>\r\nThe pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion.<br>\r\nFor each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. <br>\r\n<b>Also explore how to resize images in tensorflow and then resize all the images to a same size. <\/b> <br>\r\nThis is a Multiclass Classification Problem.<br>\r\n\r\n\r\n","b6f88dcc":"# Prediction","6871f597":"## Standardizing images array","63f924b9":"## Compile","a98a57b7":"# Model","cbe11c21":"## Training","eff072c8":"# Features and target seperating + Label and Categorical Encoding","66000a52":"## Reading images data path to get image in array formats","8ac7f166":"### Accuracy Score of True and Predicted Values","81b48775":"## Prediction Visualization with Test Data","8af263f5":"## Model Evaluation","2151441d":"## Transforming and converting target values to categorical values"}}