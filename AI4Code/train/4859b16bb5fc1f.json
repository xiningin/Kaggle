{"cell_type":{"26bab349":"code","e716dfc0":"code","1011deaa":"code","633fc052":"code","0a6584ab":"code","4e40eb79":"code","3d85493f":"code","953bf31f":"code","33095dc5":"code","a3c3e6cb":"code","ac305252":"code","ca1ad983":"code","5c318dcb":"code","537b84b3":"code","62417a7b":"code","ebb4c3dc":"code","e2f59158":"code","b5e8f032":"code","6cf79186":"code","b3aea908":"code","3d8c4c20":"code","d4615849":"markdown","285be292":"markdown","95395396":"markdown","d6e87f5a":"markdown","f63864d0":"markdown","05bf356b":"markdown","73ce66a9":"markdown","d14a6baf":"markdown"},"source":{"26bab349":"import numpy as np\nimport keras\nfrom keras.utils import np_utils\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator \nimport tensorflow.keras.layers as Layers\nimport tensorflow.keras.models as Models\nimport sklearn.utils as shuffle\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom keras.callbacks import LearningRateScheduler","e716dfc0":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","1011deaa":"train.head()","633fc052":"plt.figure(figsize = (15,15))\nsns.catplot(x = 'label', kind = 'count' ,data = train, palette = \"pastel\")\nplt.title(\"Distribution according to label\")\nplt.show()","0a6584ab":"y = train[\"label\"]\ntrain.drop([\"label\"], axis = 1, inplace = True)","4e40eb79":"train.head()","3d85493f":"y.head()","953bf31f":"y.unique()","33095dc5":"y = np_utils.to_categorical(y, 10)","a3c3e6cb":"y.shape","ac305252":"train.shape","ca1ad983":"def image_show(train):\n    fig = plt.figure(figsize = (20,20))\n    fig.suptitle(\"Few Images from the dataset\")\n    for i in range(15):\n        index = np.random.randint(train.shape[0])\n        plt.subplot(10,10,i+1)\n        plt.imshow(train[index][:,:, 0])\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n    plt.show()  ","5c318dcb":"train = train.values.reshape(-1,28,28,1)","537b84b3":"test = test.values.reshape(-1,28,28,1)","62417a7b":"image_show(train)","ebb4c3dc":"train = train \/ 255","e2f59158":"test = test \/ 255","b5e8f032":"image_generator= ImageDataGenerator(rotation_range = 10,zoom_range = 0.10,width_shift_range=0.1,height_shift_range=0.1)\n","6cf79186":"model = [0] * 10\nfor i in range(10):\n    model[i] = Models.Sequential()\n    model[i].add(Layers.Conv2D(64, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\n    model[i].add(Layers.BatchNormalization())\n    model[i].add(Layers.Conv2D(64, kernel_size = 3, activation='relu'))\n    model[i].add(Layers.BatchNormalization())\n    model[i].add(Layers.Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n    model[i].add(Layers.BatchNormalization())\n    model[i].add(Layers.Dropout(0.4))\n    model[i].add(Layers.Conv2D(128, kernel_size = 3, activation='relu'))\n    model[i].add(Layers.BatchNormalization())\n    model[i].add(Layers.Conv2D(128, kernel_size = 3, activation='relu'))\n    model[i].add(Layers.BatchNormalization())\n    model[i].add(Layers.Conv2D(128, kernel_size = 5, strides=2, padding='same', activation='relu'))\n    model[i].add(Layers.BatchNormalization())\n    model[i].add(Layers.Dropout(0.4))\n    model[i].add(Layers.Conv2D(256, kernel_size = 4, activation='relu'))\n    model[i].add(Layers.BatchNormalization())\n    model[i].add(Layers.Flatten())\n    model[i].add(Layers.Dense(512, activation = 'relu'))\n    model[i].add(Layers.Dropout(0.4))\n    model[i].add(Layers.Dense(10, activation='softmax'))\n    model[i].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","b3aea908":"call_back =  LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\nhistory = [0] * 10\nepochs = 30\nfor i in range(10):\n    train_x, val_x, train_y, val_y = train_test_split(train, y, test_size = 0.1)\n    history[i] = model[i].fit_generator(image_generator.flow(train_x,train_y, batch_size= 64),\n        epochs = 30, steps_per_epoch = (train_x.shape[0]\/\/ 64) ,  \n        validation_data = (val_x,val_y), callbacks=[call_back], verbose= 0)\n    print(\"CNN {0:d}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}\".format(\n        i+1,epochs,max(history[i].history['accuracy']),max(history[i].history['val_accuracy']) ))\n","3d8c4c20":"results = np.zeros((test.shape[0],10)) \nfor i in range(10):\n    results = results + model[i].predict(test)\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"MNIST.csv\",index=False)","d4615849":"# CNN Network","285be292":"**If you like please upvote**","95395396":"# Prediction","d6e87f5a":"# Importing Libraries","f63864d0":"**Loading data**","05bf356b":"**Visualizing predicting label**","73ce66a9":"**Image Augmentation**","d14a6baf":"# Visualizing Images"}}