{"cell_type":{"29f22dcc":"code","e2494d85":"code","803b91e9":"code","605aa4e8":"code","43b9f3ab":"code","ba5cdde3":"code","4fd37c60":"code","5c5c5cbd":"code","0f3c15cf":"code","c652ef5d":"code","c1c6ecb4":"code","7c357e36":"code","3cc175ec":"code","ab785473":"code","8621b8e8":"code","99bd0f09":"code","d51a8583":"code","0f1af937":"code","03118c3a":"code","4d666a81":"code","48250c7b":"code","0fa739a5":"code","b2c50d01":"code","4c1b7979":"code","718032a5":"code","7e3cd534":"code","085dca81":"code","dca30dd8":"code","5eace9f8":"code","403e0df3":"code","be1ccd8f":"code","2a135105":"code","62bf80fe":"code","c761fafc":"code","aa4fcf47":"code","23b8d004":"code","dfc59520":"code","63cd2601":"code","c67203e4":"code","dc813e81":"code","3e5f0bdb":"code","b9d3bbde":"code","44b792a9":"code","090e638b":"code","8c570fda":"code","4724ad59":"code","af180d94":"code","41f0ee37":"code","a6014daf":"code","d527ee93":"code","fcabec55":"code","b2221c5d":"code","4fc83cee":"code","31418103":"code","95f2905e":"code","76b5afaa":"code","b1efd353":"code","1da7d3f9":"code","6ab8e4a5":"code","13a2802a":"code","b47686ef":"code","44bac9dd":"code","018660b6":"code","b2542e79":"code","5dfcd693":"code","5322cb11":"code","fa5d5250":"code","a4d487d8":"code","2a03ff65":"code","f591b528":"code","c1de24bb":"code","fe769f0b":"code","171df170":"code","a75924dd":"code","1453cdc9":"code","f43fb638":"code","383d7c16":"code","9f8a8916":"code","a4a5a9a5":"code","cbfe3139":"code","7ce65667":"code","813309be":"code","9687d606":"code","339d8c6a":"code","cb038c52":"code","a4f5ca35":"code","b8b341f7":"code","47635efa":"code","e23e2ffc":"code","44396b7f":"code","79367c1a":"code","d5fa46ac":"code","9567adfd":"code","623f60a0":"code","c70b943a":"code","1f6ef798":"code","f76c3cb0":"code","ed062ed1":"code","b08bf370":"code","f2455953":"code","faf93183":"markdown","d9629e3e":"markdown","7d9f9a63":"markdown","e98521de":"markdown","fbe27a1d":"markdown","12e6b5f6":"markdown","658dd1f1":"markdown","0744c85a":"markdown","6687c054":"markdown","ea8d5afa":"markdown","4319b2e0":"markdown","89f48645":"markdown","3278d0a5":"markdown","30790b84":"markdown","cedaeff0":"markdown","8387d09e":"markdown","dd5aaeda":"markdown","66747863":"markdown","da93c7b5":"markdown","2fd9bee9":"markdown","14bfabe4":"markdown","41a24ece":"markdown","ca643253":"markdown","cde5223f":"markdown","4abcda9b":"markdown","7d7c3f57":"markdown","82baf5f2":"markdown","aa0f0d06":"markdown","531a1046":"markdown","76c9362d":"markdown","8841bc5c":"markdown","8e2557b5":"markdown","c596a93e":"markdown","bee608c6":"markdown","ccb9b806":"markdown","4434c543":"markdown","7d051e65":"markdown","88ce312b":"markdown","8c459860":"markdown","a23cc075":"markdown","26d63756":"markdown","959293c5":"markdown","a6ba6559":"markdown","08fefc38":"markdown"},"source":{"29f22dcc":"# Import libraries\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score","e2494d85":"# Load data\n\ndf = pd.read_csv(\"..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv\")","803b91e9":"# First look at the dataset\n\ndf.head()","605aa4e8":"# Total number of rows and columns\n\ndf.shape","43b9f3ab":"df.info()","ba5cdde3":"# Data spread between people having experienced of a stroke or not\n\ndf['stroke'].value_counts()","4fd37c60":"#Plotting the count of the target\n\nncount = len(df['stroke'])\nax = sns.countplot(x=df['stroke'])\nfor p in ax.patches:\n    x=p.get_bbox().get_points()[:,0]\n    y=p.get_bbox().get_points()[1,1]\n    ax.annotate('{:.1f}%'.format(100.*y\/ncount), (x.mean(), y), \n            ha='center', va='bottom') # set the alignment of the text\nplt.savefig('stroke_count.png')","5c5c5cbd":"# Percentage of people having had a stroke in this dataset\n\nlen(df[df['stroke'] == 1])\/len(df)*100","0f3c15cf":"df.isna().sum()","c652ef5d":"# Dropping the missing values\n\ndf.dropna(inplace = True)","c1c6ecb4":"# Checking \n\ndf.isna().sum()","7c357e36":"df.info()","3cc175ec":"df.drop(columns=['id'], inplace=True)","ab785473":"# Checking\n\ndf.head()","8621b8e8":"#Data spread between male and female\n\ndf['gender'].value_counts()","99bd0f09":"#Dropping 'Other' by selecting rows where gender 1= Other\n\ndf = df.loc[df[\"gender\"] != 'Other']","d51a8583":"#Visualise stroke counts gender wise\n\nsns.countplot(x=df[\"stroke\"], hue=df[\"gender\"])\nplt.savefig('stroke_gender.png')","0f1af937":"#Visualise the spread of the mean for the age variable\n\nfig = sns.FacetGrid(data=df, hue=\"stroke\", aspect=4)\nfig.map(sns.kdeplot, \"age\", shade=True)\nfig.add_legend()\nplt.savefig('stroke_age.png')","03118c3a":"#Count hypertension\n\ndf['hypertension'].value_counts()","4d666a81":"#Visualise proportion of people having hypertension between the 2 groups\n\ndf_hypertension = df.groupby(['hypertension','stroke'])['hypertension'].count()\ndf_hypertension_total = df.groupby(['hypertension'])['hypertension'].count()\ndf_hypertension_fig = df_hypertension \/ df_hypertension_total * 100\ndf_hypertension_fig = df_hypertension_fig.unstack()\ndf_hypertension_fig.plot.bar(stacked=True, figsize=(6,6), width=0.5)\nplt.savefig('stroke_hypertension.png')","48250c7b":"#Count heart disease\n\ndf['heart_disease'].value_counts()","0fa739a5":"#Visualise proportion of people having heart disease between the 2 groups\n\ndf_heart = df.groupby(['heart_disease','stroke'])['heart_disease'].count()\ndf_heart_total = df.groupby(['heart_disease'])['heart_disease'].count()\ndf_heart_fig = df_heart \/ df_heart_total * 100\ndf_heart_fig = df_heart_fig.unstack()\ndf_heart_fig.plot.bar(stacked=True, figsize=(6,6), width=0.5)\nplt.savefig('stroke_heart.png')","b2c50d01":"#Count ever_married\n\ndf['ever_married'].value_counts()","4c1b7979":"#Plotting stacked bar to see the proportion of people having stroke in this group\n\ndf_married = df.groupby(['ever_married','stroke'])['ever_married'].count()\ndf_married_total = df.groupby(['ever_married'])['ever_married'].count()\ndf_married_fig = df_married \/ df_married_total * 100\ndf_married_fig = df_married_fig.unstack()\ndf_married_fig.plot.bar(stacked=True, figsize=(6,6), width=0.5)\nplt.savefig('stroke_married.png')","718032a5":"#Count work_type\n\ndf['work_type'].value_counts()","7e3cd534":"#Plot\n\ndf_work = df.groupby(['work_type','stroke'])['work_type'].count()\ndf_work_total = df.groupby(['work_type'])['work_type'].count()\ndf_work_fig = df_work \/ df_work_total * 100\ndf_work_fig = df_work_fig.unstack()\ndf_work_fig.plot.bar(stacked=True, figsize=(7,7), width=0.75)\nplt.savefig('stroke_work.png')","085dca81":"#Count residence_type\n\ndf['Residence_type'].value_counts()","dca30dd8":"#Plot\n\ndf_residence = df.groupby(['Residence_type','stroke'])['Residence_type'].count()\ndf_residence_total = df.groupby(['Residence_type'])['Residence_type'].count()\ndf_residence_fig = df_residence \/ df_residence_total * 100\ndf_residence_fig = df_residence_fig.unstack()\ndf_residence_fig.plot.bar(stacked=True, figsize=(6,6), width=0.5)\nplt.savefig('stroke_residence.png')","5eace9f8":"#Spread avg_glucose_level\n\nfig = sns.FacetGrid(data=df, hue=\"stroke\", aspect=4)\nfig.map(sns.kdeplot, \"avg_glucose_level\", shade=True)\nfig.add_legend()","403e0df3":"sns.violinplot(x=\"stroke\", y=\"avg_glucose_level\", data=df)\nplt.savefig('stroke_glucose.png')","be1ccd8f":"#Spread bmi\n\nfig = sns.FacetGrid(data=df, hue=\"stroke\", aspect=4)\nfig.map(sns.kdeplot, \"bmi\", shade=True)\nfig.add_legend()\nplt.savefig('stroke_bmi.png')","2a135105":"#Count smoking_status\n\ndf['smoking_status'].value_counts()","62bf80fe":"#Plot\n\ndf_smoking = df.groupby(['smoking_status','stroke'])['smoking_status'].count()\ndf_smoking_total = df.groupby(['smoking_status'])['smoking_status'].count()\ndf_smoking_fig = df_smoking \/ df_smoking_total * 100\ndf_smoking_fig = df_smoking_fig.unstack()\ndf_smoking_fig.plot.bar(stacked=True, figsize=(7,7), width=0.5)\nplt.savefig('stroke_smoking.png')","c761fafc":"from sklearn.preprocessing import LabelEncoder","aa4fcf47":"enc=LabelEncoder()","23b8d004":"#Encoding gender variable\n\ndf['gender']=enc.fit_transform(df['gender'])","dfc59520":"df.head()","63cd2601":"#Encoding marital status\n\ndf['ever_married']=enc.fit_transform(df['ever_married'])","c67203e4":"df.head()","dc813e81":"# Encode variables with more than 2 Classes\n\ndf = pd.get_dummies(df, columns= [i for i in df.columns if df[i].dtypes=='object'],drop_first=True)","3e5f0bdb":"#Check\n\ndf.head()","b9d3bbde":"df.info()","44b792a9":"df.describe()","090e638b":"sns.pairplot(df)\nplt.savefig('stroke_pairplot.png')","8c570fda":"df.corr()","4724ad59":"plt.figure(figsize=(15,15))\nsns.heatmap(df.corr(),annot=True)\nplt.savefig('stroke_corr_heat.png')","af180d94":"y=df['stroke'].ravel()","41f0ee37":"y","a6014daf":"X=df.drop('stroke', axis=1)","d527ee93":"X","fcabec55":"#Scaling X \n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()","b2221c5d":"X_scale=scaler.fit_transform(X)","4fc83cee":"X_scale[:5]","31418103":"X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.3, stratify=y, shuffle=True, random_state=42)","95f2905e":"X_train","76b5afaa":"X_test","b1efd353":"y_train","1da7d3f9":"plt.hist(y_train)","6ab8e4a5":"y_test","13a2802a":"plt.hist(y_test)","b47686ef":"from sklearn.linear_model import LogisticRegression","44bac9dd":"lr=LogisticRegression(random_state=42)","018660b6":"lr.fit(X_train, y_train)","b2542e79":"y_pred_lr=lr.predict(X_test)","5dfcd693":"accuracy_score(y_test, y_pred_lr)","5322cb11":"print(classification_report(y_test,y_pred_lr))","fa5d5250":"from sklearn.ensemble import RandomForestClassifier","a4d487d8":"rf=RandomForestClassifier(random_state=42)","2a03ff65":"rf.fit(X_train, y_train)","f591b528":"y_pred_rf=rf.predict(X_test)","c1de24bb":"print(classification_report(y_test,y_pred_rf))","fe769f0b":"confusion_matrix(y_test, y_pred_rf)","171df170":"from sklearn.tree import DecisionTreeClassifier","a75924dd":"dt=DecisionTreeClassifier(random_state=42)","1453cdc9":"dt.fit(X_train, y_train)","f43fb638":"y_pred_dt=dt.predict(X_test)","383d7c16":"print(classification_report(y_test,y_pred_dt))","9f8a8916":"confusion_matrix(y_test, y_pred_dt)","a4a5a9a5":"from sklearn.neighbors import KNeighborsClassifier","cbfe3139":"knn=KNeighborsClassifier()","7ce65667":"knn.fit(X_train, y_train)","813309be":"y_pred_knn=knn.predict(X_test)","9687d606":"print(classification_report(y_test,y_pred_knn))","339d8c6a":"confusion_matrix(y_test, y_pred_knn)","cb038c52":"#Using over-sampling method\n\nfrom imblearn.over_sampling import SMOTE","a4f5ca35":"sm = SMOTE()\nX_oversampled, y_oversampled = sm.fit_resample(X, y)","b8b341f7":"#Data after oversampling\n\nsns.countplot(x = y_oversampled, data = df)\nplt.savefig('stroke_oversampled.png')","47635efa":"# Train again with the new data\n\nX_train, X_test, y_train, y_test = train_test_split(X_oversampled, y_oversampled, test_size = 0.2, random_state = 42)","e23e2ffc":"#Logistic Regression\nlr = LogisticRegression(max_iter=1000, random_state=42)\nlr.fit(X_train, y_train)\nlr_pred = lr.predict(X_test)\nprint(confusion_matrix(lr_pred, y_test))\nprint(classification_report(lr_pred, y_test))","44396b7f":"#Decision Tree\ndt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)\ndt_pred = dt.predict(X_test)\nprint(confusion_matrix(dt_pred, y_test))\nprint(classification_report(dt_pred, y_test))","79367c1a":"#KNN\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\nknn_pred = knn.predict(X_test)\nprint(confusion_matrix(knn_pred, y_test))\nprint(classification_report(knn_pred, y_test))","d5fa46ac":"#Random forest\nrf = RandomForestClassifier(random_state=42)\nrf.fit(X_train, y_train)\nrf_pred = rf.predict(X_test)\nprint(confusion_matrix(rf_pred, y_test))\nprint(classification_report(rf_pred, y_test))","9567adfd":"conf_mat = confusion_matrix(rf_pred, y_test)\nsns.heatmap(conf_mat.T, annot=True, fmt='d', cbar=False,\n          xticklabels=['No','Yes'],\n          yticklabels=['No','Yes'] )\nplt.xlabel('Actuals')\nplt.ylabel('Predicted')\nplt.savefig('stroke_over_rf_cm.png')","623f60a0":"# Creating the feature importances dataframe\n\nfeature_importance = np.array(rf.feature_importances_)\nfeature_names = np.array(X.columns)\n\nfeat_imp = pd.DataFrame({'feature_names':feature_names,'feature_importance':feature_importance})","c70b943a":"plt.figure(figsize=(10,8))\nsns.barplot(x=feat_imp['feature_importance'], y=feat_imp['feature_names'])\nplt.savefig('stroke_feature_imp.png')","1f6ef798":"from sklearn import tree\n\nfn = df.columns\ncn = [\"Yes\",\"No\"]\n\nfig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (40,15))\n\ntree.plot_tree(rf.estimators_[0],\n               feature_names = fn, \n               class_names=cn,\n               filled = True);\nplt.savefig('stroke_over_tree.png')","f76c3cb0":"pred_prob1 = lr.predict_proba(X_test)\npred_prob2 = dt.predict_proba(X_test)\npred_prob3 = knn.predict_proba(X_test)\npred_prob4 = rf.predict_proba(X_test)","ed062ed1":"from sklearn.metrics import roc_curve\n\n# roc curve for models\nfpr1, tpr1, thresh1 = roc_curve(y_test, pred_prob1[:,1], pos_label=1)\nfpr2, tpr2, thresh2 = roc_curve(y_test, pred_prob2[:,1], pos_label=1)\nfpr3, tpr3, thresh3 = roc_curve(y_test, pred_prob3[:,1], pos_label=1)\nfpr4, tpr4, thresh4 = roc_curve(y_test, pred_prob4[:,1], pos_label=1)\n\n# roc curve for tpr = fpr \nrandom_probs = [0 for i in range(len(y_test))]\np_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)","b08bf370":"from sklearn.metrics import roc_auc_score\n\n# auc scores\nauc_score1 = roc_auc_score(y_test, pred_prob1[:,1])\nauc_score2 = roc_auc_score(y_test, pred_prob2[:,1])\nauc_score3 = roc_auc_score(y_test, pred_prob3[:,1])\nauc_score4 = roc_auc_score(y_test, pred_prob4[:,1])\n\nprint(auc_score1)\nprint(auc_score2)\nprint(auc_score3)\nprint(auc_score4)","f2455953":"plt.plot(fpr1, tpr1, linestyle='--',color='orange', label='Logistic Regression')\nplt.plot(fpr2, tpr2, linestyle='--',color='green', label='Decision Tree')\nplt.plot(fpr3, tpr3, linestyle='--',color='yellow', label='KNN')\nplt.plot(fpr4, tpr4, linestyle='--',color='red', label='Random Forest')\nplt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n# title\nplt.title('ROC curve')\n# x label\nplt.xlabel('False Positive Rate')\n# y label\nplt.ylabel('True Positive rate')\n\nplt.legend(loc='best')\nplt.savefig('ROC',dpi=300)\nplt.show()\nfig.savefig('multiple_roc_curve.png')","faf93183":"The dataset is very imbalanced => important to keep it in mind when cleaning and training, as well as when choosing the metrics.","d9629e3e":"#### Glucose level","7d9f9a63":"We have now 4908 entries for 16 variables and all our data are either in numerical format so that we can perform the training later.\n","e98521de":"The graph confirms that smoking is a risk factor for stroke. ","fbe27a1d":"## Exploratory analysis and data preparation","12e6b5f6":"### 2. Split the data into training and testing sets ","658dd1f1":"### Further exploratory analysis and visualisation","0744c85a":"After removing the null values, we have left with 4909 entries. ","6687c054":"#### KNN","ea8d5afa":"### Drop the id column\nThe ID column was useful to identify the patients but it will not have any impact on the models, so we can drop it.","4319b2e0":"There is no real difference between the two groups in terms of BMI.","89f48645":"After sampling, random forest leads to the best results in terms of metrics as we can see with the ROC curve and a F1 score of .96 ","3278d0a5":"The variables that have the highest correlation score with stroke are: age, heart disease, glucose level and hypertension, which is what we suspected.","30790b84":"## Training","cedaeff0":"#### Logistic regression","8387d09e":"#### Residence type","dd5aaeda":"### 3. Creating models","66747863":"#### Smoking status","da93c7b5":"#### Decision Tree","2fd9bee9":"This is my very first project in machine learning using Python. \n\nThe purpose was to find the best model to predict stroke.\n\nI would like to thank the mentor who helped me with the oversampling method as well as the other authors who inspired me some lines of code \ud83d\ude4f","14bfabe4":"The distribution of average glucose level between the two classes is almost similar. There are only a slightly difference for the average glucose level above 150 where more people is experiencing stroke.","41a24ece":"### Handling missing values","ca643253":"#### Hypertension","cde5223f":"### Encoding categorical data","4abcda9b":"The dataset consists of 10 metrics for a total of 5110 patients. We have demographic data (gender, age, marital status, type of work and residence) as well as health data including hypertension, heart disease, average glucose level, body mass index (BMI), smoking status and whether the patient has experienced a stroke.","7d7c3f57":"#### BMI","82baf5f2":"### Handling imbalanced data with sampling","aa0f0d06":"#### Heart disease","531a1046":"The larger proportion of people experiencing stroke for this population can be correlated with what we have seen for age.","76c9362d":"There are 201 null values in the 'bmi' column.","8841bc5c":"#### Gender","8e2557b5":"It's not suprising to see that there is a higher risk of stroke when the patient get older.","c596a93e":"Environmental factors can be a risk factor for stroke but there is no difference in this dataset. ","bee608c6":"#### Work type","ccb9b806":"Nevertheless, the coefficients are very low (between .14 and .2)","4434c543":"There is 1 row with \"Other\", we can drop it. ","7d051e65":"In proportion, there are more people experiencing stroke in the group with hypertension.","88ce312b":"#### Marital status","8c459860":"1. With imbalanced data, the accuracy is not a metric that we can take into account because it is based on the the larger part of the target. In other words, this model is very accurate predincting when a people is not having a stroke, which is obviously what we don't need...\n2. The poor result in class 1 of the target is expected because of the imbalanced dataset as well as the limited correlation among the variables. ","a23cc075":"#### Age","26d63756":"### Exploring each variable","959293c5":"Same constatation as with the group having hypertension, there is a larger proportion of people experiencing stroke.","a6ba6559":"#### Random Forest","08fefc38":"### 1. Set the independent (X) and the dependent variable (y)"}}