{"cell_type":{"c9362d71":"code","d087baed":"code","514acf40":"code","80445883":"code","15b3495b":"code","15f634a5":"code","c6c6a3e3":"code","7702ff71":"code","ecffe191":"code","e72c095b":"code","c5b3f40c":"code","b3178e7d":"code","3460104a":"code","fadc7328":"code","d76c90fc":"code","d614be93":"code","66a88613":"code","c204f9aa":"code","787ad27d":"code","5b0bdf7c":"code","752dec13":"code","703cc18c":"markdown","92645503":"markdown","3746b6c9":"markdown","999d32d9":"markdown","0fb36316":"markdown","5723c5eb":"markdown","30dcb407":"markdown","68512adb":"markdown","b8fc3fba":"markdown","4caef4c4":"markdown","0fe68bda":"markdown","e30424bc":"markdown","ab2ad01a":"markdown","8c52d94a":"markdown","ce321ffe":"markdown","6b1bc302":"markdown","ff128617":"markdown","407a36d7":"markdown","cd9f06b6":"markdown","22086728":"markdown","5435f405":"markdown","7c40774a":"markdown","9ca2d2c7":"markdown"},"source":{"c9362d71":"import os\nfrom PIL import Image\nimport numpy as np\nimport keras\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom cv2 import cv2\nimport matplotlib.pyplot as plt\nfrom keras.layers.normalization import BatchNormalization","d087baed":"path = '..\/input\/fruit-and-vegetable-image-recognition\/train\/'\nfruits = []\nfor x in os.listdir(path):\n    fruits.append(x)","514acf40":"data=[]\nlabels=[]\nim_w = 224\nim_h = 224","80445883":"for x in range(len(fruits)):\n    sub_path = path+fruits[x]+'\/'\n    for y in os.listdir(sub_path):        \n        img_path = sub_path+y  \n        last = img_path[-12:]\n        imag=cv2.imread(img_path)  \n        if last == 'Image_56.jpg':\n            continue\n        if last == 'Image_96.jpg': \n            continue\n        img_from_ar = Image.fromarray(imag, 'RGB')\n        resized_image = img_from_ar.resize((im_w, im_h))\n        data.append(np.array(resized_image))\n        labels.append(x)","15b3495b":"categories=np.array(data)\nlabels=np.array(labels)\n\ns=np.arange(categories.shape[0])\nnp.random.shuffle(s)\ncategories=categories[s]\nlabels=labels[s]\n\nnum_classes=len(np.unique(labels))\ndata_length=len(categories)","15f634a5":"(x_train,x_test)=categories[(int)(0.1*data_length):],categories[:(int)(0.1*data_length)]\nx_train = x_train.astype('float32')\/255\nx_test = x_test.astype('float32')\/255\ntrain_length=len(x_train)\ntest_length=len(x_test)\n\n(y_train,y_test)=labels[(int)(0.1*data_length):],labels[:(int)(0.1*data_length)]\n\ny_train=keras.utils.to_categorical(y_train,num_classes)\ny_test=keras.utils.to_categorical(y_test,num_classes)","c6c6a3e3":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(im_w,im_h,3)))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\n#model.add(Dropout(0.3))\nmodel.add(Dense(36, activation = 'softmax'))","7702ff71":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()\nearly_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=17)\nhistory = model.fit(x_train,y_train,batch_size=50, epochs=90,verbose=1, validation_split=0.33, callbacks=[early_stop])\n\nscore = model.evaluate(x_test, y_test, verbose=1)\nprint('\\n', 'Test accuracy:', score[1])","ecffe191":"plt.plot(history.history['val_loss'])\nplt.plot(history.history['loss'])\nplt.title(\"Model Loss\")\nplt.ylabel(\"Loss\")\nplt.xlabel('Time')\nplt.legend(['val_loss', 'loss'], loc='upper left')\nplt.show()","e72c095b":"plt.plot(history.history['val_accuracy'])\nplt.plot(history.history['accuracy'])\nplt.title(\"Model Accuracy\")\nplt.ylabel(\"Epocs\")\nplt.xlabel('Time')\nplt.legend(['val_accuracy', 'acc'], loc='upper left')\nplt.show()","c5b3f40c":"#An empty list for prediction and accuracy\npred_list = []\nacc_list = []","b3178e7d":"def convert_to_array(img):\n    im = cv2.imread(img)\n    img = Image.fromarray(im, 'RGB')\n    image = img.resize((im_w, im_h))\n    return np.array(image)","3460104a":"def get_fruit_name(label):\n    return fruits[label] ","fadc7328":"def predict_fruit(file):\n    print(\"Predicting .................................\")\n    ar=convert_to_array(file)\n    ar=ar\/255\n    a=[]\n    a.append(ar)\n    a=np.array(a)\n    score=model.predict(a,verbose=1)\n    #print(score)\n    label_index=np.argmax(score)\n    #print(label_index)\n    acc=np.max(score)\n    fruit=get_fruit_name(label_index)\n    pred_list.append(fruit)\n    acc_list.append(acc)\n    print(\"The predicted fruit is a \"+fruit+\" with accuracy =    \"+str(acc))","d76c90fc":"test_path = '..\/input\/fruit-and-vegetable-image-recognition\/test\/'\nt_fruits = []\nfor x in os.listdir(test_path):\n    t_fruits.append(x)","d614be93":"for x in range(len(t_fruits)):\n    sub_path = test_path+t_fruits[x]+'\/'\n    for y in os.listdir(sub_path):\n        img_path = sub_path+y\n        predict_fruit(img_path)","66a88613":"real_fruits = []\nfor f in fruits:\n    for i in range(10):\n        real_fruits.append(f)","c204f9aa":"complist = list(zip(pred_list, real_fruits, acc_list))","787ad27d":"tp,fp = 0,0\nfor i in range(len(complist)):\n    if complist[i][0] == complist[i][1]:\n        tp += 1\n    else:\n        fp += 1","5b0bdf7c":"rate = tp\/(tp+fp)\ntp,fp,rate","752dec13":"complist","703cc18c":"Creating a list in test directory. These are real images and they will be compare with the predicted results.This list will be a kind of manual confusion matrix. ","92645503":"This is the part of compiling our created model. Using adam for optimize, categorical crossentropy for loss function. Fitting our train data and putting an early stop to prevent waste of time and ascending data loss. Model shuld work at least 17 times. (this is my optional number for this model)","3746b6c9":"Shuffling labels and datas","999d32d9":"Checking the prediction is true or false.","0fb36316":"# **Importing necessery libraries. **\n* os : reading files\n* pil, cv2 : image process\n* numpy : calculations\n* matploplib : visualization\n* keras, tensorflow : machine learning  ","5723c5eb":"Creating a precision rate. ","30dcb407":"Predicting images in test list.","68512adb":"Main function for prediction, accuracy score and the result.","b8fc3fba":"Creating a loop to read images from train directory, than converting images to numpy arrays. Adding labels to the belonging images. 2 images looks exist in directory but they are curropted somehow, so skipping them. ","4caef4c4":"Function for the result what prediction is.","0fe68bda":"Full view of the list","e30424bc":"Creating a table including real images, predicted images and score for per image.","ab2ad01a":"Prepare datas and categories before model create. ","8c52d94a":"# Prediction side","ce321ffe":"# Evaluation and bugs for process\n\nLots of the predictions are succesfull but there are mistakes. Some categories such as corns-sweetcorns, pepper-chili-paprika kinds are looks same so its very difficult to differanciet even with the human eyes. Creating a new model for this close species or retrain with much more image data count will be affective. ","6b1bc302":"Creating a list for images in test directory. ","ff128617":"# Model Create","407a36d7":"This is our model for convolutional neural network. Keras Conv2D class will be used. Relu function for activation, maxpooliing and batch normalization. We have 36 different categories so dense is 36 at last and softmax will be used. ","cd9f06b6":"Describe image sizes and creating empty data list and label list. Datas will be our images converted from jpg to numpy arrays.","22086728":"Function is setting the images size same as set before. Converting image to numpy for prediction.","5435f405":"Model loss visual","7c40774a":"Model accuracy visual","9ca2d2c7":"Making a list of fruits and vegatables. Using os library to get images from train directory."}}