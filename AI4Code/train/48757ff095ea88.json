{"cell_type":{"ab68d2aa":"code","a6911c09":"code","32896cce":"code","e09a1ae8":"code","3e6d8c10":"code","ce1193d1":"code","fa9e100f":"code","cb43dba5":"code","ad47bc18":"code","34edd541":"code","6fa963e2":"code","723c5137":"code","d5c66b4b":"code","628f1b15":"code","26906aaf":"code","6070d3ff":"code","f3d5c62e":"code","027fe571":"code","c67e459e":"code","990b7b9b":"code","52c51b34":"code","7632118e":"code","a8b4aab4":"code","9b998dfb":"code","fd53530e":"markdown"},"source":{"ab68d2aa":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"..\/input\/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a6911c09":"#!pip install lightgbm\nfrom numpy import mean, std\nimport seaborn as sns\nfrom matplotlib import *\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score, RepeatedStratifiedKFold\nfrom sklearn.metrics import accuracy_score\n\nfrom xgboost                          import XGBClassifier\nfrom catboost                         import CatBoostClassifier\nfrom lightgbm                         import LGBMClassifier\nfrom sklearn.ensemble                 import VotingClassifier\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","32896cce":"import pandas as pd\nimport numpy as np\ntrain_data = pd.read_csv('\/kaggle\/input\/hcareanalytics\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/hcareanalytics\/test.csv')\n#sample_submission = pd.read_csv('\/kaggle\/input\/topicmodel\/healthcare\/sample_submission.csv')\ntrain_data.columns = train_data.columns.str.lower().str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\ntest_data.columns = test_data.columns.str.lower().str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')","e09a1ae8":"print('Train Data Shape: ', train_data.shape)\nprint('Test Data Shape: ', test_data.shape)\ntrain_data.head()","3e6d8c10":"train_data.dtypes","ce1193d1":"train_data.isnull().sum()","fa9e100f":"train_data.nunique()","cb43dba5":"train_data.columns","ad47bc18":"# Unique values for all the columns\nfor col in train_data.columns[~(train_data.columns.isin(['case_id', 'patientid', 'admission_deposit']))].tolist():\n    print(\" Unique Values --> \" + col, ':', len(train_data[col].unique()), ': ', train_data[col].unique())","34edd541":"i = 1\nfor column in train_data.columns[~(train_data.columns.isin(['case_id', 'patientid', 'admission_deposit']))].tolist():\n    plt.figure(figsize = (60, 10))\n    plt.subplot(4, 4, i)\n    sns.barplot(x = train_data[column].value_counts().index, y = train_data[column].value_counts())\n    i += 1\n    plt.show()","6fa963e2":"sns.boxplot(x = 'visitors_with_patient', data = train_data, orient = 'v' )\nsns.despine()","723c5137":"plt.figure(figsize = (20, 6))\nsns.barplot(x = train_data.groupby(['severity_of_illness'])['visitors_with_patient'].value_counts().index, y = train_data.groupby(['severity_of_illness'])['visitors_with_patient'].value_counts())\nplt.xticks(rotation = 90)\nsns.despine()","d5c66b4b":"train_data.isnull().sum()","628f1b15":"train_data['city_code_patient'] = train_data['city_code_patient'].fillna(17.0)\ntest_data['city_code_patient'] = test_data['city_code_patient'].fillna(17.0)\ntrain_data = train_data.fillna('NaN')\ntest_data = test_data.fillna('NaN')\n\n\nfor column in train_data.columns[~(train_data.columns.isin(['case_id', 'stay']))].tolist():\n\n    le = LabelEncoder()\n\n    if column == 'city_code_patient':\n        train_data['city_code_patient'] = train_data['city_code_patient'].astype('str')\n        test_data['city_code_patient'] = test_data['city_code_patient'].astype('str')\n        train_data['city_code_patient'] = le.fit_transform(train_data['city_code_patient'])\n        test_data['city_code_patient'] = le.transform(test_data['city_code_patient'])\n    \n    elif column == 'bed_grade':\n        bedGrade = {1: '1',2: '2', 3: '3', 4: '4', np.nan: '5'}\n        train_data['bed_grade'] = train_data['bed_grade'].map(bedGrade)\n        test_data['bed_grade'] = test_data['bed_grade'].map(bedGrade)\n        train_data['bed_grade'] = train_data['bed_grade'].fillna('NaN')\n        test_data['bed_grade'] = test_data['bed_grade'].fillna('NaN')\n    \n    else:\n        train_data[column] = le.fit_transform(train_data[column])\n        test_data[column] = le.fit_transform(test_data[column])","26906aaf":"train_data.head()","6070d3ff":"train_data.isnull().sum()","f3d5c62e":"ss = StandardScaler()\n\nfor column in train_data.columns[~(train_data.columns.isin(['case_id', 'stay']))].tolist():\n    train_data[[column]] = ss.fit_transform(train_data[[column]])\n    test_data[[column]] = ss.fit_transform(test_data[[column]])","027fe571":"# Partitioning the features and the target\n\nX = train_data[train_data.columns[~(train_data.columns.isin(['case_id', 'stay']))].tolist()].values\ny = train_data['stay'].values","c67e459e":"# kfold, scores = KFold(n_splits = 6, shuffle = True, random_state = 22), list()\n# for train, test in kfold.split(X):\n#     X_train, X_test = X[train], X[test]\n#     y_train, y_test = y[train], y[test]\n    \n#     model = LGBMClassifier(random_state = 0, max_depth = 6, n_estimators = 200, bagging_fraction=0.9, feature_fraction=0.9, subsample_freq = 2,importance_type = \"gain\",verbosity = -1, max_bin = 60,num_leaves = 300,boosting_type = 'dart',learning_rate=0.1, scale_pos_weight=2.5)\n#     model.fit(X_train, y_train)\n#     preds = model.predict(X_test)\n#     score = accuracy_score(y_test, preds)\n#     scores.append(score)\n#     print('Validation Accuracy:', score)\n# print(\"Average Validation Accuracy: \", sum(scores)\/len(scores))","990b7b9b":"# #### using kfold gridserch\n\n# from sklearn.model_selection import RandomizedSearchCV \n# from sklearn.model_selection import StratifiedKFold, GridSearchCV, learning_curve, cross_val_score\n# lgb = LGBMClassifier(random_state =1, shuffle = True)\n# kfold = StratifiedKFold(n_splits=6)\n\n# lgb_param_grid_best = {'learning_rate':[0.095], \n#                   'reg_lambda':[0.4],\n#                   'gamma': [1],\n#                   'subsample': [0.6],\n#                   'max_depth': [6],\n#                   'n_estimators': [1000]\n#               }\n\n# gs_lgb = GridSearchCV(lgb, param_grid = lgb_param_grid_best, cv=kfold, n_jobs= -1, verbose = 1)\n\n# gs_lgb.fit(X,y)\n\n# lgb_best = gs_lgb.best_estimator_\n# print(f'LGB GridSearch best params: {gs_lgb.best_params_}')\n# print(f'LGB GridSearch best score: {gs_lgb.best_score_}')\n\n# predictions = gs_lgb.predict(test_data[test_data.columns[~(test_data.columns.isin(['case_id']))].tolist()].values)\n# submission = pd.DataFrame({'case_id': test_data['case_id'], 'Stay': predictions.ravel()})\n# submission.to_csv('av_healthcare_v1.csv', index = False)\n# submission.head()","52c51b34":"lgb1 = LGBMClassifier(  bagging_fraction=1, feature_fraction=0.9, subsample_freq = 2,importance_type = \"gain\",verbosity = -1, max_bin = 60,num_leaves = 300,boosting_type = 'dart',learning_rate=0.15, n_estimators=494, max_depth=5, scale_pos_weight=2.5)\n\n\nlgb1.fit(X,y)\n#y_pred_lgb1 = lgb1.predict(test).astype(int)   \nprint(\"Accuracy_Score:\",lgb1.score(X,y))\n \npredictions = lgb1.predict(test_data[test_data.columns[~(test_data.columns.isin(['case_id']))].tolist()].values)\nsubmission = pd.DataFrame({'case_id': test_data['case_id'], 'Stay': predictions.ravel()})\nsubmission.to_csv('av_healthcare_v1.csv', index = False)\nsubmission.head()\n\n# Accuracy_Score: 0.4392629020405856   best till now","7632118e":"submission.to_csv('av_healthcare_v1.csv', index = False)\nsubmission.head()","a8b4aab4":"# kfold, scores = KFold(n_splits = 6, shuffle = True, random_state = 0), list()\n# for train, test in kfold.split(X):\n#     X_train, X_test = X[train], X[test]\n#     y_train, y_test = y[train], y[test]\n    \n#     model = LGBMClassifier(learning_rate=0.1,random_state = 0, max_depth = 6, n_estimators = 200, verbose = 100)\n#     model.fit(X_train, y_train)\n#     preds = model.predict(X_test)\n#     score = accuracy_score(y_test, preds)\n#     scores.append(score)\n#     print('Validation Accuracy:', score)\n# print(\"Average Validation Accuracy: \", sum(scores)\/len(scores))","9b998dfb":"# predictions = model.predict(test_data[test_data.columns[~(test_data.columns.isin(['case_id']))].tolist()].values)\n# submission = pd.DataFrame({'case_id': test_data['case_id'], 'Stay': predictions.ravel()})\n# submission.to_csv('av_healthcare_v1.csv', index = False)\n# submission.head()","fd53530e":"## Exploratory Data Analysis"}}