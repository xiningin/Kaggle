{"cell_type":{"545bd7cd":"code","71621203":"code","79ce8d1a":"code","dc86438a":"code","406319f8":"code","858747d4":"code","5dad2ed8":"code","2db03650":"code","3fe2e3b2":"code","1cabff1b":"code","42329189":"code","a4890471":"code","b85a7c66":"code","bde17b52":"code","49779c29":"markdown","5c0dd5ce":"markdown","2da28b62":"markdown","33ac3527":"markdown","28f24edf":"markdown","872d9b0a":"markdown","d76087ac":"markdown","8123260e":"markdown","c4e100c2":"markdown","f8c4e96f":"markdown","a1ed1089":"markdown","0b657061":"markdown"},"source":{"545bd7cd":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\nimport pandas as pd\nimport time\nimport glob\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nimport os\nimport cv2\nimport shutil\nfrom sklearn.metrics import confusion_matrix, classification_report","71621203":"malaria_dir='..\/input\/cell-images-for-detecting-malaria\/cell_images\/Parasitized'\nhealthy_dir='..\/input\/cell-images-for-detecting-malaria\/cell_images\/Uninfected'\ndirlist=[malaria_dir, healthy_dir]\nclasses=['Malaria', 'Healthy']\nfilepaths=[]\nlabels=[]\nfor d,c in zip(dirlist, classes):\n    flist=os.listdir(d)\n    for f in flist:\n        fpath=os.path.join (d,f)\n        filepaths.append(fpath)\n        labels.append(c)\nprint ('filepaths: ', len(filepaths), '   labels: ', len(labels))","79ce8d1a":"Fseries=pd.Series(filepaths, name='file_paths')\nLseries=pd.Series(labels, name='labels')\ndf=pd.concat([Fseries,Lseries], axis=1)\ndf=pd.DataFrame(np.array(df).reshape(27560,2), columns = ['file_paths', 'labels'])\nprint(df['labels'].value_counts())","dc86438a":"plt.figure(figsize=(14,10))\nfor i in range(20):\n    random = np.random.randint(1,len(df))\n    plt.subplot(4,5,i+1)\n    plt.imshow(cv2.imread(df.loc[random,\"file_paths\"]))\n    plt.title(df.loc[random, \"labels\"], size = 10, color = \"black\") \n    plt.xticks([])\n    plt.yticks([])\n    \nplt.show()","406319f8":"train_df, test_df = train_test_split(df, train_size=0.95, random_state=0)\ntrain_df, valid_df = train_test_split(train_df, train_size=0.9, random_state=0)","858747d4":"print(train_df.labels.value_counts())\nprint(valid_df.labels.value_counts())\nprint(test_df.labels.value_counts())","5dad2ed8":"target_size=(299,299)\nbatch_size=64","2db03650":"train_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input, horizontal_flip=True)\ntest_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.inception_resnet_v2.preprocess_input)\ntrain_gen = train_datagen.flow_from_dataframe(train_df, x_col='file_paths', y_col='labels', target_size=target_size, batch_size=batch_size, color_mode='rgb', class_mode='binary')\nvalid_gen = test_datagen.flow_from_dataframe(valid_df, x_col='file_paths', y_col='labels', target_size=target_size, batch_size=batch_size, color_mode='rgb', class_mode='binary')\ntest_gen = test_datagen.flow_from_dataframe(test_df, x_col='file_paths', y_col='labels', target_size=target_size, batch_size=batch_size, color_mode='rgb', class_mode='binary')","3fe2e3b2":"base_model = tf.keras.applications.InceptionResNetV2(include_top=False, input_shape=(299,299,3))","1cabff1b":"model = tf.keras.Sequential([\n    base_model, \n    tf.keras.layers.GlobalAveragePooling2D(), \n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.BatchNormalization(), \n    tf.keras.layers.Dropout(0.2), \n    tf.keras.layers.Dense(1, activation='sigmoid')\n])","42329189":"lr=0.001\nmodel.compile(loss='binary_crossentropy', optimizer=Adam(lr=lr), metrics=['accuracy'])","a4890471":"patience = 1\nstop_patience = 3\nfactor = 0.5\n\ncallbacks = [\n    tf.keras.callbacks.ModelCheckpoint(\"classify_model.h5\", save_best_only=True, verbose = 0),\n    tf.keras.callbacks.EarlyStopping(patience=stop_patience, monitor='val_loss', verbose=1),\n    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=factor, patience=patience, verbose=1)\n]","b85a7c66":"epochs = 30\nhistory = model.fit(train_gen, validation_data=valid_gen, epochs=epochs, callbacks=callbacks, verbose=1)","bde17b52":"best_model = model\nbest_model.load_weights('.\/classify_model.h5')\nbest_model.evaluate(test_gen)","49779c29":"# **Callbacks**","5c0dd5ce":"# **Model**","2da28b62":"# **Visualize Images**","33ac3527":"Looks like we can do some horizontal flips in ImageDataGenerator. ","28f24edf":"# **Predictions**","872d9b0a":"# **InceptionResNetV2 Model**","d76087ac":"Dataset is balanced.","8123260e":"# **Create Dataframe from Images**","c4e100c2":"# **Model Training**","f8c4e96f":"# **Import Relevant Libraries**","a1ed1089":"# **Image Data Generator**","0b657061":"# **Splitting Dataframe into Train, Valid, and Test**"}}