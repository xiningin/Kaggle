{"cell_type":{"ee9fcfe3":"code","55488541":"code","77f23107":"code","0b6c5178":"code","3fd89588":"code","75939428":"code","cb014c40":"code","68b73151":"code","4d0ae714":"code","93452d2d":"code","82b15d05":"code","8d9ddc1e":"code","a6a39642":"code","7b0818c9":"code","a39c04c2":"code","2595f584":"code","cd880cbf":"code","95f44beb":"code","a66fa511":"code","a73db615":"code","947dfab0":"code","573f79b9":"code","d749fa2f":"code","63936fda":"code","90624368":"code","8389f26f":"code","3c36426e":"code","d2d8a0ad":"code","bc0d75ed":"code","e1b2f481":"code","a1fd0e01":"code","3dffc70b":"code","5fdf0560":"code","2764b3bb":"code","7ae019a8":"code","a19e0f58":"code","a76bde63":"code","8e2b45c9":"code","9ec9a356":"markdown","b3f06f39":"markdown","83695f21":"markdown","61077692":"markdown","2779b9bf":"markdown","6989ed75":"markdown","31cedd55":"markdown","b6bc03a6":"markdown","c7d1fef0":"markdown","40dde821":"markdown","6e14801d":"markdown","0acc3483":"markdown","8ffbbc98":"markdown","021b0a2f":"markdown","b0de4548":"markdown","fea77a3d":"markdown","b324ec61":"markdown","9e104790":"markdown","855ead45":"markdown","c3202600":"markdown","0586ea3e":"markdown","66abe8a0":"markdown","a0062c7d":"markdown","78a09d7e":"markdown","87579292":"markdown","3f042931":"markdown","79f8d2d2":"markdown","ecbdd2f2":"markdown","fde8f916":"markdown","9ec3097b":"markdown","fef43bac":"markdown","0c23720b":"markdown","fe99f5ed":"markdown","698e920e":"markdown","92bc585d":"markdown","e3276eaf":"markdown","5ddbe9c0":"markdown","0e1e858b":"markdown","6efe43af":"markdown","be49d000":"markdown","9603bfb6":"markdown","eb3c3178":"markdown","984a14ca":"markdown","b7095c0c":"markdown","216d56f3":"markdown","3a9e898f":"markdown","cdaa7857":"markdown","6015986d":"markdown","3fcf8a02":"markdown","22e8bbc7":"markdown","ebeb742d":"markdown","752c91e6":"markdown","48a5bf3b":"markdown","b227e81a":"markdown","2e6e4100":"markdown"},"source":{"ee9fcfe3":"# This file contains all my ids for foursquare and google\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nCLIENT_ID = user_secrets.get_secret(\"CLIENT_ID\")\nCLIENT_SECRET = user_secrets.get_secret(\"CLIENT_SECRET\")\nGOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n\n\n# Others imports:\nfrom IPython.display import Image\nimport pickle\nimport json\nimport requests\nimport folium\nimport pandas as pd\n\n# !pip install shapely\nimport shapely.geometry\n\n# !pip install pyproj\nimport pyproj\n\nimport math\n\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\n","55488541":"def get_coordinates(api_key, address, verbose=False):\n    try:\n        url = 'https:\/\/maps.googleapis.com\/maps\/api\/geocode\/json?key={}&address={}'.format(api_key, address)\n        response = requests.get(url).json()\n        if verbose:\n            print('Google Maps API JSON result =>', response)\n        results = response['results']\n        geographical_data = results[0]['geometry']['location'] # get geographical coordinates\n        lat = geographical_data['lat']\n        lon = geographical_data['lng']\n        return [lat, lon]\n    except:\n        return [None, None]\n    \naddress = 'Pr\u00e9fecture de Versailles, Versailles, Frances'\nVersailles_center = get_coordinates(GOOGLE_API_KEY, address)\nprint('Coordinate of {}: {}'.format(address, Versailles_center))","77f23107":"def lonlat_to_xy(lon, lat):\n    proj_latlon = pyproj.Proj(proj='latlong',datum='WGS84')\n    proj_xy = pyproj.Proj(proj=\"utm\", zone=33, datum='WGS84')\n    xy = pyproj.transform(proj_latlon, proj_xy, lon, lat)\n    return xy[0], xy[1]\n\ndef xy_to_lonlat(x, y):\n    proj_latlon = pyproj.Proj(proj='latlong',datum='WGS84')\n    proj_xy = pyproj.Proj(proj=\"utm\", zone=33, datum='WGS84')\n    lonlat = pyproj.transform(proj_xy, proj_latlon, x, y)\n    return lonlat[0], lonlat[1]\n\ndef calc_xy_distance(x1, y1, x2, y2):\n    dx = x2 - x1\n    dy = y2 - y1\n    return math.sqrt(dx*dx + dy*dy)\n\nprint('Coordinate transformation check')\nprint('-------------------------------')\nprint('Versailles center longitude={}, latitude={}'.format(Versailles_center[1], Versailles_center[0]))\nx, y = lonlat_to_xy(Versailles_center[1], Versailles_center[0])\nprint('Versailles center UTM X={}, Y={}'.format(x, y))\nlo, la = xy_to_lonlat(x, y)\nprint('Versailles center longitude={}, latitude={}'.format(lo, la))","0b6c5178":"Versailles_center_x, Versailles_center_y = lonlat_to_xy(Versailles_center[1], Versailles_center[0]) # City center in Cartesian coordinates\nnb_k = 10\nradius = 100\nk = math.sqrt(3) \/ 2 # Vertical offset for hexagonal grid cells\nx_min = Versailles_center_x - radius*10\nx_step = radius*2\ny_min = Versailles_center_y - radius*2 - (int(nb_k\/k)*k*radius*2 - radius*10)\/2\ny_step = radius*2 * k \n\nlatitudes = []\nlongitudes = []\ndistances_from_center = []\nxs = []\nys = []\nfor i in range(0, int(nb_k\/k)):\n    y = y_min + i * y_step\n    x_offset = radius if i%2==0 else 0\n    for j in range(0, nb_k):\n        x = x_min + j * x_step + x_offset\n        distance_from_center = calc_xy_distance(Versailles_center_x, Versailles_center_y, x, y)\n        if (distance_from_center <= 6001):\n            lon, lat = xy_to_lonlat(x, y)\n            latitudes.append(lat)\n            longitudes.append(lon)\n            distances_from_center.append(distance_from_center)\n            xs.append(x)\n            ys.append(y)\n            \nmap_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nfolium.Marker(Versailles_center, popup='Prefecture').add_to(map_versailles)\nfor lat, lon in zip(latitudes, longitudes):\n    folium.Circle([lat, lon], radius=radius, color='blue', fill=False).add_to(map_versailles)\nmap_versailles","3fd89588":"def get_address(api_key, latitude, longitude, verbose=False):\n    try:\n        url = 'https:\/\/maps.googleapis.com\/maps\/api\/geocode\/json?key={}&latlng={},{}'.format(api_key, latitude, longitude)\n        response = requests.get(url).json()\n        if verbose:\n            print('Google Maps API JSON result =>', response)\n        results = response['results']\n        address = results[0]['formatted_address']\n        return address\n    except:\n        return None\n\naddr = get_address(GOOGLE_API_KEY, Versailles_center[0], Versailles_center[1])\nprint('Reverse geocoding check')\nprint('-----------------------')\nprint('Address of [{}, {}] is: {}'.format(Versailles_center[0], Versailles_center[1], addr))","75939428":"addresses = []\ncompteur = 0\n\ndf_locations = pd.DataFrame()\nloaded = False\ntry:\n    with open('locations.pkl', 'rb') as f:\n        df_locations = pickle.load(f)\n    print('Location data loaded from pickle.')\n    loaded = True\nexcept:\n    pass\n\n\nif not loaded:\n    print('Obtaining location addresses: ', end='')\n    for lat, lon in zip(latitudes, longitudes):\n        compteur = compteur + 1\n        address = get_address(GOOGLE_API_KEY, lat, lon)\n        if address is None:\n            address = 'NO ADDRESS'\n        address = address.replace(', France', '') # We don't need country part of address\n        addresses.append(address)\n        if compteur > 500:\n            print(\"Urgency exit\")\n            break\n    #     print(compteur)\n        print(' .', end='')\n    print(' done.')","cb014c40":"if not loaded:\n    addresses","68b73151":"\nif not loaded:\n    df_locations = pd.DataFrame({'Address': addresses,\n                                 'Latitude': latitudes,\n                                 'Longitude': longitudes,\n                                 'X': xs,\n                                 'Y': ys,\n                                 'Distance from center': distances_from_center})\n\ndf_locations.head(10)","4d0ae714":"df_locations.to_pickle('.\/locations.pkl')    ","93452d2d":"foursquare_client_id = CLIENT_ID\nfoursquare_client_secret = CLIENT_SECRET","82b15d05":"# Category IDs corresponding to Italian restaurants were taken from Foursquare web site \n# (https:\/\/developer.foursquare.com\/docs\/resources\/categories):\n\nfood_category = '4d4b7105d754a06374d81259' # 'Root' category for all food-related venues\n\n# We will add some asian categories, and also take away food, and healthy food. These category are the one that\n# may be competitor\nasian_restaurant_categories = ['4bf58dd8d48988d142941735','4bf58dd8d48988d145941735', '4bf58dd8d48988d111941735',\n                                '4bf58dd8d48988d1d2941735', '4bf58dd8d48988d1d1941735', '4bf58dd8d48988d14a941735',\n                              '56aa371be4b08b9a8d57350b', '4bf58dd8d48988d1cb941735', '4bf58dd8d48988d1e0931735',\n                              '4bf58dd8d48988d16c941735', '4bf58dd8d48988d16f941735', '5283c7b4e4b094cb91ec88d7',\n                              '4bf58dd8d48988d1bd941735', '4bf58dd8d48988d1c5941735', '4bf58dd8d48988d1c7941735']\n\ndef is_restaurant(categories, specific_filter=None):\n    restaurant_words = ['Restaurant', 'restaurant', 'diner', 'taverna', 'steakhouse', 'Brasserie', 'Creperie', 'Caf\u00e9',\n                       'Truck', 'Sandwich', 'Pizza']\n    restaurant = False\n    specific = False\n    for c in categories:\n        category_name = c[0].lower()\n        category_id = c[1]\n        for r in restaurant_words:\n            if r in category_name:\n                restaurant = True\n        if 'fast food' in category_name:\n            restaurant = False\n        if not(specific_filter is None) and (category_id in specific_filter):\n            specific = True\n            restaurant = True\n    return restaurant, specific\n\ndef get_categories(categories):\n    return [(cat['name'], cat['id']) for cat in categories]\n\ndef format_address(location):\n    address = ', '.join(location['formattedAddress'])\n    return address\n\ndef get_venues_near_location(lat, lon, category, client_id, client_secret, radius=500, limit=100):\n    version = '20180724'\n    url = 'https:\/\/api.foursquare.com\/v2\/venues\/explore?client_id={}&client_secret={}&v={}&ll={},{}&categoryId={}&radius={}&limit={}'.format(\n        client_id, client_secret, version, lat, lon, category, radius, limit)\n    try:\n        results = requests.get(url).json()['response']['groups'][0]['items']\n        venues = [(item['venue']['id'],\n                   item['venue']['name'],\n                   get_categories(item['venue']['categories']),\n                   (item['venue']['location']['lat'], item['venue']['location']['lng']),\n                   format_address(item['venue']['location']),\n                   item['venue']['location']['distance']) for item in results]        \n    except:\n        venues = []\n    return venues","8d9ddc1e":"# Let's now go over our neighborhood locations and get nearby restaurants; we'll also maintain \n# a dictionary of all found restaurants and all found italian restaurants\n\ndef get_restaurants(lats, lons):\n    from tqdm.autonotebook import tqdm\n    tqdm.pandas()\n    restaurants = {}\n    asian_restaurants = {}\n    location_restaurants = []\n\n    print('Obtaining venues around candidate locations:', end='')\n    pbar = tqdm(total=len(lats))\n    for lat, lon in zip(lats, lons):\n        # Using radius=350 to meke sure we have overlaps\/full coverage so we don't miss any restaurant (we're using dictionaries to remove any duplicates resulting from area overlaps)\n        venues = get_venues_near_location(lat, lon, food_category, foursquare_client_id, \n                                          foursquare_client_secret, radius=350, limit=100)\n#         with open('1. venues.txt', 'w') as outfile:\n#             json.dump(venues, outfile)\n        area_restaurants = []\n#         print(venues)\n        \n        for venue in venues:            \n#             with open('2. venue.txt', 'w') as outfile:\n#                 json.dump(venue, outfile)\n            venue_id = venue[0]\n            venue_name = venue[1]\n            venue_categories = venue[2]\n            venue_latlon = venue[3]\n            venue_address = venue[4]\n            venue_distance = venue[5]\n            is_res, is_asian = is_restaurant(venue_categories, specific_filter=asian_restaurant_categories)\n            if is_res:\n                x, y = lonlat_to_xy(venue_latlon[1], venue_latlon[0])\n                restaurant = (venue_id, venue_name, venue_latlon[0], venue_latlon[1], venue_address, \n                              venue_distance, is_asian, x, y)\n#                 print(\"\\n\" + str(restaurant))\n                if venue_distance<=100:\n                    area_restaurants.append(restaurant)\n                restaurants[venue_id] = restaurant\n                if is_asian:\n                    asian_restaurants[venue_id] = restaurant\n        pbar.update(1)        \n        \n        location_restaurants.append(area_restaurants)\n#         print(' .', end='')\n    pbar.close()\n#     print(' done.')\n    return restaurants, asian_restaurants, location_restaurants\n\n# Try to load from local file system in case we did this before\nrestaurants = {}\nasian_restaurants = {}\nlocation_restaurants = []\nloaded = False\ntry:\n    with open('restaurants_350.pkl', 'rb') as f:\n        restaurants = pickle.load(f)\n    with open('asian_restaurants_350.pkl', 'rb') as f:\n        asian_restaurants = pickle.load(f)\n    with open('location_restaurants_350.pkl', 'rb') as f:\n        location_restaurants = pickle.load(f)\n    print('Restaurant data loaded.')\n    loaded = True\nexcept:\n    pass\n\n# If load failed use the Foursquare API to get the data\nif not loaded:\n    restaurants, asian_restaurants, location_restaurants = get_restaurants(latitudes, longitudes)\n    \n    # Let's persists this in local file system\n    with open('restaurants_350.pkl', 'wb') as f:\n        pickle.dump(restaurants, f)\n    with open('asian_restaurants_350.pkl', 'wb') as f:\n        pickle.dump(asian_restaurants, f)\n    with open('location_restaurants_350.pkl', 'wb') as f:\n        pickle.dump(location_restaurants, f)\n        ","a6a39642":"import numpy as np\n\nprint('Total number of restaurants:', len(restaurants))\nprint('Total number of Asian restaurants:', len(asian_restaurants))\nprint('Percentage of Asian restaurants: {:.2f}%'.format(len(asian_restaurants) \/ len(restaurants) * 100))\nprint('Average number of restaurants in neighborhood:', np.array([len(r) for r in location_restaurants]).mean())","7b0818c9":"map_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nfolium.Marker(Versailles_center, popup='Prefecture').add_to(map_versailles)\nfor res in restaurants.values():\n    lat = res[2]; lon = res[3]\n    is_asian = res[6]\n    color = 'red' if is_asian else 'blue'\n    label = '{}'.format(res[1])\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker([lat, lon], radius=3, color=color, fill=True, fill_color=color,                         \n                        popup=label, fill_opacity=1, parse_html=False).add_to(map_versailles)\nmap_versailles","a39c04c2":"# 'Root' category for all universities venues\nuniv_category = ['4d4b7105d754a06372d81259']\n\ndef get_meta_venues(lats, lons, meta_category):\n    from tqdm.autonotebook import tqdm\n    tqdm.pandas()\n    meta_venues = {}\n    neighborhoods_venues = []\n\n#     print('Obtaining venues around candidate locations:', end='')\n    pbar = tqdm(total=len(lats), desc = 'Obtaining venues', unit= ' coord')\n    for lat, lon in zip(lats, lons):\n        # Using radius=350 to meke sure we have overlaps\/full coverage so we don't miss any restaurant (we're using dictionaries to remove any duplicates resulting from area overlaps)\n        area_meta_venues = []\n        for i, category in enumerate(meta_category):\n            venues = get_venues_near_location(lat, lon, category, foursquare_client_id, \n                                              foursquare_client_secret, radius=350, limit=100)\n            for venue in venues:\n                venue_id = venue[0]\n                venue_name = venue[1]\n                venue_categories = venue[2]\n                venue_latlon = venue[3]\n                venue_address = venue[4]\n                venue_distance = venue[5]\n\n                x, y = lonlat_to_xy(venue_latlon[1], venue_latlon[0])\n                restaurant = (venue_id, venue_name, venue_latlon[0], venue_latlon[1], \n                              venue_address, venue_distance, is_asian, x, y)\n                if venue_distance<=100:\n                    area_meta_venues.append(restaurant)\n                meta_venues[venue_id] = restaurant\n\n            neighborhoods_venues.append(area_meta_venues)\n#         print(' .', end='')\n        pbar.update(1)\n    pbar.close()\n#     print(' done.')\n    return meta_venues, neighborhoods_venues\n\n\n\n# plantage = plantage # Just to make sure we won't go after this point\n\n# Try to load from local file system in case we did this before\nmeta_univ = {}\nneighborhoods_univ = []\nloaded = False\ntry:\n    with open('meta_univ_350.pkl', 'rb') as f:\n        meta_univ = pickle.load(f)\n    with open('neighborhoods_univ_350.pkl', 'rb') as f:\n        neighborhoods_univ = pickle.load(f)\n    print('Universities data loaded.')\n    loaded = True\nexcept:\n    pass\n\nif not loaded:\n    meta_univ, neighborhoods_univ = get_meta_venues(latitudes, longitudes, univ_category)\n    \n    # Let's persists this in local file system\n    with open('meta_univ_350.pkl', 'wb') as f:\n        pickle.dump(meta_univ, f)\n    with open('neighborhoods_univ_350.pkl', 'wb') as f:\n        pickle.dump(neighborhoods_univ, f)\n        \nprint('Total number of universities:', len(meta_univ))\nprint('Average number of universities in neighborhood:', np.array([len(r) for r in neighborhoods_univ]).mean())\n\nmap_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nfolium.Marker(Versailles_center, popup='Prefecture').add_to(map_versailles)\nfor res in meta_univ.values():\n    lat = res[2]; lon = res[3]\n    is_univ = res[6]\n    color = 'blue' \n    label = '{}'.format(res[1])\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker([lat, lon], radius=3, color=color, fill=True, fill_color=color,                         \n                        popup=label, fill_opacity=1, parse_html=False).add_to(map_versailles)\nmap_versailles","2595f584":"# 'Root' category for all companies venues\ncompanies_category = ['4d4b7105d754a06375d81259', '4d4b7105d754a06378d81259', '4d4b7105d754a06379d81259',\n                     '4d4b7104d754a06370d81259']\n\n# Try to load from local file system in case we did this before\nmeta_company = {}\nneighborhoods_company = []\nloaded = False\ntry:\n    with open('meta_company_350.pkl', 'rb') as f:\n        meta_company = pickle.load(f)\n    with open('neighborhoods_company_350.pkl', 'rb') as f:\n        neighborhoods_company = pickle.load(f)\n    print('Companies data loaded.')\n    loaded = True\nexcept:\n    pass\n\nif not loaded:\n    meta_company, neighborhoods_company = get_meta_venues(latitudes, longitudes, companies_category)\n    \n    # Let's persists this in local file system\n    with open('meta_company_350.pkl', 'wb') as f:\n        pickle.dump(meta_company, f)\n    with open('neighborhoods_company_350.pkl', 'wb') as f:\n        pickle.dump(neighborhoods_company, f)\n        \nprint('Total number of companies:', len(meta_company))\nprint('Average number of companies in neighborhood:', np.array([len(r) for r in neighborhoods_company]).mean())\n\nmap_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nfolium.Marker(Versailles_center, popup='Prefecture').add_to(map_versailles)\nfor res in meta_company.values():\n    lat = res[2]; lon = res[3]\n    is_company = res[6]\n    color = 'red'\n    label = '{}'.format(res[1])\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker([lat, lon], radius=3, color=color, fill=True, fill_color=color,                         \n                        popup=label, fill_opacity=1, parse_html=False).add_to(map_versailles)\nmap_versailles","cd880cbf":"map_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nfolium.Marker(Versailles_center, popup='Prefecture').add_to(map_versailles)\nfor res in meta_company.values():\n    lat = res[2]; lon = res[3]\n    color = 'green'\n    label = '{}'.format(res[1])\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker([lat, lon], radius=3, color=color, fill=True, fill_color=color,                         \n                        popup=label, fill_opacity=1, parse_html=False).add_to(map_versailles)\nfor res in meta_univ.values():\n    lat = res[2]; lon = res[3]\n    color = 'yellow'\n    label = '{}'.format(res[1])\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker([lat, lon], radius=3, color=color, fill=True, fill_color=color,                         \n                        popup=label, fill_opacity=1, parse_html=False).add_to(map_versailles)\nfor res in restaurants.values():\n    lat = res[2]; lon = res[3]\n    is_asian = res[6]\n    color = 'red' if is_asian else 'blue'\n    label = '{}'.format(res[1])\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker([lat, lon], radius=3, color=color, fill=True, fill_color=color,                         \n                        popup=label, fill_opacity=1, parse_html=False).add_to(map_versailles)\nmap_versailles","95f44beb":"Image(\"..\/input\/versailles_size.PNG\")","a66fa511":"# 'Root' category for all companies venues\ncustomer_category = ['4d4b7105d754a06375d81259', '4d4b7105d754a06378d81259', '4d4b7105d754a06379d81259',\n                     '4d4b7104d754a06370d81259', '4d4b7105d754a06372d81259']\n\n# Try to load from local file system in case we did this before\nmeta_customers = []\nneighborhoods_customers = []\nloaded = False\ntry:\n    with open('meta_customers_350.pkl', 'rb') as f:\n        meta_customers = pickle.load(f)\n    with open('neighborhoods_customers_350.pkl', 'rb') as f:\n        neighborhoods_customers = pickle.load(f)\n    print('Companies data loaded.')\n    loaded = True\nexcept:\n    pass\n\nif not loaded:\n    from tqdm.autonotebook import tqdm\n    pbar1 = tqdm(total=len(customer_category), desc = 'Cycling categories', unit= ' categories')\n    for category in customer_category:\n        meta_customer, neighborhoods_customer = get_meta_venues(latitudes, longitudes, [category])\n        meta_customers.append(meta_customer)\n        neighborhoods_customers.append(neighborhoods_customer)\n        pbar1.update(1)\n    pbar1.close()\n    \n    # Let's persists this in local file system\n    with open('meta_customers_350.pkl', 'wb') as f:\n        pickle.dump(meta_customers, f)\n    with open('neighborhoods_customers_350.pkl', 'wb') as f:\n        pickle.dump(neighborhoods_customers, f)\n        \nprint('Total number of customers:', len(meta_customers))\nprint('Average number of customers in neighborhood:', np.array([len(r) for r in neighborhoods_customers]).mean())\n\nmap_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nfolium.Marker(Versailles_center, popup='Prefecture').add_to(map_versailles)\nfor meta_customer in meta_customers:\n    for res in meta_customer.values():\n        lat = res[2]; lon = res[3]\n        color = 'red'\n        label = '{}'.format(res[1])\n        label = folium.Popup(label, parse_html=True)\n        folium.CircleMarker([lat, lon], radius=3, color=color, fill=True, fill_color=color,                         \n                            popup=label, fill_opacity=1, parse_html=False).add_to(map_versailles)\nmap_versailles","a73db615":"counts = []\nfor i, neighborhoods_customer in enumerate(neighborhoods_customers):\n    counts.append([len(res) for res in neighborhoods_customers[i]])\nfinal_count= []\nlen(counts[0])\nfor m in range(len(counts[0])):\n    final_count.append(0)\n    for n in range(len(counts)):\n        final_count[m] = final_count[m] + counts[n][m]\nlen(final_count)","947dfab0":"# location_customers_count = [len(res) for res in neighborhoods_customers]\ncounts = []\nfor i, neighborhoods_customer in enumerate(neighborhoods_customers):\n    counts.append([len(res) for res in neighborhoods_customers[i]])\nlocation_customers_count= []\nlen(counts[0])\nfor m in range(len(counts[0])):\n    location_customers_count.append(0)\n    for n in range(len(counts)):\n        location_customers_count[m] = location_customers_count[m] + counts[n][m]\n\ndf_locations['Customers in area'] = location_customers_count\n\nprint('Average number of customers in every area with radius=100m:', np.array(location_customers_count).mean())\n\ndf_locations.head(5)","573f79b9":"df_locations.sort_values(by='Customers in area', ascending=False).head(10)","d749fa2f":"restaurant_latlons = [[res[2], res[3]] for res in restaurants.values()]\n\ncustomers_latlons = []\nfor meta_customer in meta_customers:\n    customers_latlons.append([[res[2], res[3]] for res in meta_customer.values()])","63936fda":"from folium import plugins\nfrom folium.plugins import HeatMap\n\nmap_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nfolium.TileLayer('cartodbpositron').add_to(map_versailles) #cartodbpositron cartodbdark_matter\nfor customers_latlon in customers_latlons:\n    HeatMap(customers_latlon).add_to(map_versailles)\n# folium.Marker(Versailles_center).add_to(map_versailles)\nfolium.Circle(Versailles_center, radius=100, fill=False, color='white').add_to(map_versailles)\nfolium.Circle(Versailles_center, radius=300, fill=False, color='white').add_to(map_versailles)\nfolium.Circle(Versailles_center, radius=500, fill=False, color='white').add_to(map_versailles)\nmap_versailles","90624368":"map_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nfolium.TileLayer('cartodbpositron').add_to(map_versailles) #cartodbpositron cartodbdark_matter\nHeatMap(restaurant_latlons).add_to(map_versailles)\nfolium.Marker(Versailles_center, popup='Prefecture').add_to(map_versailles)\nfolium.Marker([48.804394, 2.131718], popup='La boite a Bobun',\n    icon=folium.Icon(color='red', icon='info-sign')).add_to(map_versailles)\nfolium.Circle(Versailles_center, radius=100, fill=False, color='white').add_to(map_versailles)\nfolium.Circle(Versailles_center, radius=300, fill=False, color='white').add_to(map_versailles)\nfolium.Circle(Versailles_center, radius=500, fill=False, color='white').add_to(map_versailles)\nmap_versailles","8389f26f":"from folium import plugins\nfrom folium.plugins import HeatMap\n\nmap_versailles = folium.Map(location=[48.806812, 2.131194], zoom_start=16)\nfolium.TileLayer('cartodbpositron').add_to(map_versailles) #cartodbpositron cartodbdark_matter\nfor customers_latlon in customers_latlons:\n    HeatMap(customers_latlon).add_to(map_versailles)\n# folium.Marker(Versailles_center).add_to(map_versailles)\nfolium.Marker([48.804394, 2.131718], popup='La boite a Bobun',\n    icon=folium.Icon(color='red', icon='info-sign')).add_to(map_versailles)\nfolium.Marker([48.806350, 2.131048], popup='Good spot',\n    icon=folium.Icon(color='green')).add_to(map_versailles)\nfolium.Circle([48.806350, 2.131048], radius=300, color='white', fill=True, fill_opacity=0.4).add_to(map_versailles)\nmap_versailles","3c36426e":"map_versailles = folium.Map(location=[48.806812, 2.131194], zoom_start=16)\nfolium.TileLayer('cartodbpositron').add_to(map_versailles) #cartodbpositron cartodbdark_matter\nHeatMap(restaurant_latlons).add_to(map_versailles)\nfolium.Marker(Versailles_center, popup='Prefecture').add_to(map_versailles)\nfolium.Marker([48.804394, 2.131718], popup='La boite a Bobun',\n    icon=folium.Icon(color='red', icon='info-sign')).add_to(map_versailles)\nfolium.Marker([48.806350, 2.131048], popup='Good spot',\n    icon=folium.Icon(color='green')).add_to(map_versailles)\nfolium.Circle([48.806350, 2.131048], radius=300, color='white', fill=True, fill_opacity=0.4).add_to(map_versailles)\nmap_versailles","d2d8a0ad":"# We plot the area where we'll search for good localisation\nroi_x_min = Versailles_center_x -1000\nroi_y_max = Versailles_center_y\nroi_width = 1500\nroi_height = 1500\nroi_center_x = roi_x_min\nroi_center_y = roi_y_max\nroi_center_lon, roi_center_lat = xy_to_lonlat(roi_center_x, roi_center_y)\nroi_center = [roi_center_lat, roi_center_lon]\n\nmap_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nfor customers_latlon in customers_latlons:\n    HeatMap(customers_latlon).add_to(map_versailles)\nfolium.Marker(Versailles_center).add_to(map_versailles)\nfolium.Circle(Versailles_center, radius=700, color='white', fill=True, fill_opacity=0.4).add_to(map_versailles)\nmap_versailles","bc0d75ed":"k = math.sqrt(3) \/ 2 # Vertical offset for hexagonal grid cells\nnb_k = 20 #51 a la base\nx_step = 100\ny_step = 100 * k \nroi_y_min = roi_center_y - 700\n\nroi_latitudes = []\nroi_longitudes = []\nroi_xs = []\nroi_ys = []\nfor i in range(0, int(nb_k\/k)):\n    y = roi_y_min + i * y_step\n    x_offset = (nb_k-1) if i%2==0 else 0\n    for j in range(0, 51):\n        x = roi_x_min + j * x_step + x_offset\n        d = calc_xy_distance(roi_center_x, roi_center_y, x, y)\n        if (d <= 2501):\n            lon, lat = xy_to_lonlat(x, y)\n            roi_latitudes.append(lat)\n            roi_longitudes.append(lon)\n            roi_xs.append(x)\n            roi_ys.append(y)\n\nprint(len(roi_latitudes), 'candidate neighborhood centers generated.')","e1b2f481":"def count_restaurants_nearby(x, y, restaurants, radius=150):    \n    count = 0\n    for res in restaurants.values():\n        res_x = res[7]; res_y = res[8]\n        d = calc_xy_distance(x, y, res_x, res_y)\n        if d<=radius:\n            count += 1\n    return count\n\ndef find_nearest_restaurant(x, y, restaurants):\n    d_min = 100000\n    for res in restaurants.values():\n        res_x = res[7]; res_y = res[8]\n        d = calc_xy_distance(x, y, res_x, res_y)\n        if d<=d_min:\n            d_min = d\n    return d_min\n\ndef count_customers_nearby(x, y, customers, radius=150):    \n    count = 0\n    for meta_customer in meta_customers:\n        for res in meta_customer.values():\n            res_x = res[7]; res_y = res[8]\n            d = calc_xy_distance(x, y, res_x, res_y)\n            if d<=radius:\n                count += 1\n    return count\n\nroi_restaurant_counts = []\nroi_asian_restaurants = []\nroi_customer = []\n\nprint('Generating data on location candidates... ', end='')\nfor x, y in zip(roi_xs, roi_ys):\n    count = count_restaurants_nearby(x, y, restaurants, radius=100)\n    roi_restaurant_counts.append(count)\n    \n    distance = find_nearest_restaurant(x, y, asian_restaurants)\n    roi_asian_restaurants.append(distance)\n    \n    custom = count_customers_nearby(x, y, meta_customers)\n    roi_customer.append(custom)\nprint('done.')\n","a1fd0e01":"# Let's put this into dataframe\ndf_roi_locations = pd.DataFrame({'Latitude':roi_latitudes,\n                                 'Longitude':roi_longitudes,\n                                 'X':roi_xs,\n                                 'Y':roi_ys,\n                                 'Restaurants nearby':roi_restaurant_counts,\n                                 'Distance to Asian restaurant':roi_asian_restaurants,\n                                 'Customers':roi_customer})\n\ndf_roi_locations.sort_values(by='Customers', ascending=False).head(10)\n# df_roi_locations.head()","3dffc70b":"good_res_count = np.array((df_roi_locations['Restaurants nearby']<=2))\nprint('Locations with no more than two restaurants nearby:', good_res_count.sum())\n\ngood_asi_distance = np.array(df_roi_locations['Distance to Asian restaurant']>=100)\nprint('Locations with no Asian restaurants within 400m:', good_asi_distance.sum())\n\ngood_custmer_count = np.array(df_roi_locations['Customers']>=10)\nprint('Locations with more than 10 customers:', good_custmer_count.sum())\n\ngood_locations = np.logical_and(good_custmer_count, good_res_count, good_asi_distance)\nprint('Locations with both conditions met:', good_locations.sum())\n\ndf_good_locations = df_roi_locations[good_locations]\n","5fdf0560":"good_latitudes = df_good_locations['Latitude'].values\ngood_longitudes = df_good_locations['Longitude'].values\n\ngood_locations = [[lat, lon] for lat, lon in zip(good_latitudes, good_longitudes)]\n\nmap_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nfolium.TileLayer('cartodbpositron').add_to(map_versailles)\nHeatMap(restaurant_latlons).add_to(map_versailles)\nfolium.Circle(Versailles_center, radius=700, color='white', fill=True, fill_opacity=0.6).add_to(map_versailles)\nfolium.Marker(Versailles_center).add_to(map_versailles)\nfor lat, lon in zip(good_latitudes, good_longitudes):\n    folium.CircleMarker([lat, lon], radius=2, color='blue', fill=True, \n                        fill_color='blue', fill_opacity=1).add_to(map_versailles) \nmap_versailles","2764b3bb":"map_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nHeatMap(good_locations, radius=35).add_to(map_versailles)\nfolium.Marker(Versailles_center).add_to(map_versailles)\nfor lat, lon in zip(good_latitudes, good_longitudes):\n    folium.CircleMarker([lat, lon], radius=2, color='blue', fill=True, \n                        fill_color='blue', fill_opacity=1).add_to(map_versailles)\nmap_versailles","7ae019a8":"from sklearn.cluster import KMeans\n\nnumber_of_clusters = 15\n\ngood_xys = df_good_locations[['X', 'Y']].values\nkmeans = KMeans(n_clusters=number_of_clusters, random_state=0).fit(good_xys)\n\ncluster_centers = [xy_to_lonlat(cc[0], cc[1]) for cc in kmeans.cluster_centers_]\n\nmap_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nfolium.TileLayer('cartodbpositron').add_to(map_versailles)\nfor customers_latlon in customers_latlons:\n    HeatMap(customers_latlon).add_to(map_versailles)\nfolium.Circle(Versailles_center, radius=700, color='white', fill=True, fill_opacity=0.4).add_to(map_versailles)\nfolium.Marker(Versailles_center).add_to(map_versailles)\nfor lon, lat in cluster_centers:\n    folium.Circle([lat, lon], radius=80, color='green', fill=True, fill_opacity=0.25).add_to(map_versailles) \nfor lat, lon in zip(good_latitudes, good_longitudes):\n    folium.CircleMarker([lat, lon], radius=2, color='blue', fill=True, fill_color='blue', \n                        fill_opacity=1).add_to(map_versailles)\nmap_versailles","a19e0f58":"map_versailles = folium.Map(location=Versailles_center, zoom_start=15)\nfolium.Marker(Versailles_center).add_to(map_versailles)\nfor lat, lon in zip(good_latitudes, good_longitudes):\n    folium.Circle([lat, lon], radius=250, color='#00000000', fill=True, fill_color='#0066ff', \n                  fill_opacity=0.07).add_to(map_versailles)\nfor lat, lon in zip(good_latitudes, good_longitudes):\n    folium.CircleMarker([lat, lon], radius=2, color='blue', fill=True, fill_color='blue', \n                        fill_opacity=1).add_to(map_versailles)\nfor lon, lat in cluster_centers:\n    folium.Circle([lat, lon], radius=80, color='green', fill=False).add_to(map_versailles) \nmap_versailles","a76bde63":"map_versailles = folium.Map(location=[48.806620, 2.132041], zoom_start=16)\nfolium.Marker(Versailles_center).add_to(map_versailles)\nfor lon, lat in cluster_centers:\n    folium.Circle([lat, lon], radius=60, color='green', fill=False).add_to(map_versailles) \nfor lat, lon in zip(good_latitudes, good_longitudes):\n    folium.Circle([lat, lon], radius=250, color='#0000ff00', fill=True, fill_color='#0066ff', \n                  fill_opacity=0.07).add_to(map_versailles)\nfor lat, lon in zip(good_latitudes, good_longitudes):\n    folium.CircleMarker([lat, lon], radius=2, color='blue', fill=True, fill_color='blue', \n                        fill_opacity=1).add_to(map_versailles)\nmap_versailles","8e2b45c9":"candidate_area_addresses = []\nprint('==============================================================')\nprint('Addresses of centers of areas recommended for further analysis')\nprint('==============================================================\\n')\nfor lon, lat in cluster_centers:\n    addr = get_address(GOOGLE_API_KEY, lat, lon).replace(', France', '')\n    candidate_area_addresses.append(addr)    \n    x, y = lonlat_to_xy(lon, lat)\n    d = calc_xy_distance(x, y, Versailles_center_x, Versailles_center_y)\n    print('{}{} => {:.1f}km from Prefecture'.format(addr, ' '*(50-len(addr)), d\/1000))\n    ","9ec9a356":"<a href=\"https:\/\/cognitiveclass.ai\"><img src = \"https:\/\/ibm.box.com\/shared\/static\/9gegpsmnsoo25ikkbl4qzlvlyjbgxs5x.png\" width = 400> <\/a>","b3f06f39":"## Results and Discussion <a name=\"results\"><\/a>","83695f21":"After visualization of data we can conclude:\n* Competitors are scattered around the city, but there are just a few real competitors (actually only one is doing Vietnamese baguette and Bubble tea in Versailles)\n* Very close to the prefecture there are just a few companies (in the 100\/200m radius), they are 300m south and north.\n\nWe will now focus on spotting worker area more than competitors, we will try do determine where are clusters more of the worker.\n\nIn order to do that, we will use the **k mean clustering method**.","61077692":"Let's now see all the collected restaurants in our area of interest on map, and let's also show Asian restaurants in different color.","2779b9bf":"### K mean clustering\n\nLet's do the kmean clustering to see what will be the result.","6989ed75":"Now let's create a grid of area candidates, equaly spaced, centered around city center and within ~1.5km from Prefecture. Our neighborhoods will be defined as circular areas with a radius of 100 meters, so our neighborhood centers will be 200 meters apart.\n\nTo accurately calculate distances we need to create our grid of locations in Cartesian 2D coordinate system which allows us to calculate distances in meters (not in latitude\/longitude degrees). Then we'll project those coordinates back to latitude\/longitude degrees to be shown on Folium map. So let's create functions to convert between WGS84 spherical coordinate system (latitude\/longitude degrees) and UTM Cartesian coordinate system (X\/Y coordinates in  meters).","31cedd55":"#### Zoom north west","b6bc03a6":"OK. Now let's calculate two most important things for each location candidate: **number of restaurants in vicinity** (we'll use radius of **150 meters**) and **number of customers**.","c7d1fef0":"So, on this map we can see all potential competitors, take away restaurant, healthy restaurant. Asian restaurant are in red.\n\nNo we need to analyse companies\/university localisation and cluster and cross both analysis.\n\nWe need to remember that the target are worker wanting to buy healthy fast food for breakfast and lunch, we don't aim the evening. Also, another target can be universities.","40dde821":"## Conclusion <a name=\"conclusion\"><\/a>","6e14801d":"Foursquare credentials are defined in hidden cell bellow.","0acc3483":"### Background<a name=\"Background\"><\/a>","8ffbbc98":"Looking good. What we have now is a clear indication of zones with low number of restaurants in vicinity, and *no* Asian restaurants at all nearby, and good numbers of customers.\n\nLet us now **cluster** those locations to create **centers of zones containing good locations**. Those zones, their centers and addresses will be the final result of our analysis. ","021b0a2f":"Let's see how this looks on a map.","b0de4548":"#### Universities visualization","fea77a3d":"...and let's now save\/persist this data into local file.","b324ec61":"#### Restaurants visualization","9e104790":"This project can be reused for other cities, just think about changing clustering size to adapt to your city.\n\nAlso, I have created\/modify a huge quantity of function in order to adapt. \n\nIt's very far from being perfect, a lot of work can be done, other source of data can be found, but in the end the result seams to correlate with the real world, when we know the city, the area predicted seams correct.","855ead45":"Let's visualize the data we have so far: city center location and candidate neighborhood centers:","c3202600":"### Neighborhood Candidates\n\nLet's create latitude & longitude coordinates for centroids of our candidate neighborhoods. We will create a grid of cells covering our area of interest which is aprox. 1.5km killometers centered around **Versailles** city center.\n\nLet's first find the latitude & longitude of Versailles city center, using specific, well known address and Google Maps geocoding API.\n\nWe'll consider the Prefecture to be the city center, as a lot of companies are around.","0586ea3e":"This analysis shows that we must consider other criterias than just number of restaurant.\n\nVersailles is a little city, so the concentration of restaurant is quite high, in this analysis I tried to corrolate the number of restaurant and quantity of potential customer.\n\nIn opposit to  what I was thinking, the Prefecture area is not very crowded, mainly because building are big (French old style building, full of empty space and big garden).\n\nAlso, I was able to discover that there are not a lot of competitor on this business area, which is very good.\n\n15 good potential places are foud, I personnaly think that the one in the north is better.\n\nWe must just take care of one thing, I thing the api didn't return all data, we are missing a lot of companies, the map is still good, and the result can be trusted, but we should cross check data with other data source.\n\nIn order to be more accurate, it could be possible to give a weight to customers for example, a university with 1000 student would then weight more than a hair cut company with two employees.","66abe8a0":"As expected, the restaurants are also in this area, but if we look at the first map, we can see that **we almost have no competitors in this area**.\n\nThe only competitor is indicated in red, and actually they are **not making bubble tea**, and the sandwitch are not real vietnamese style.","a0062c7d":"#### City partitionning","78a09d7e":"## Analysis <a name=\"analysis\"><\/a>","87579292":"## Table of contents\n* [Introduction: Business Problem](#introduction)\n* [Data](#data)\n* [Methodology](#methodology)\n* [Analysis](#analysis)\n* [Results and Discussion](#results)\n* [Conclusion](#conclusion)","3f042931":"This notebook is highly inspirated by the template given in the course. I will keep the idea of clustering the city by area and then plot heatmap to find better area.\n\nI will change some data:\n* Country\/City: France\n* Goal: Open a restaurant\/little shop for workers in weekday and maybe saturday\n\nSo, I will cross data from working days, and localisations.\n\nI will use the following API:\n* Foursquare API: to find restaurant\/venues\n* Google API: reverse geolocalisation","79f8d2d2":"Not bad - our clusters represent groupings of most of the candidate locations and cluster centers are placed nicely in the middle of the zones 'rich' with location candidates.\n\nAddresses of those cluster centers will be a good starting point for exploring the neighborhoods to find the best possible location based on neighborhood specifics.\n\nLet's see those zones on a city map without heatmap, using shaded areas to indicate our clusters:","ecbdd2f2":"# Capstone Project - The Battle of the Neighborhoods (Week 2)\n### Applied Data Science Capstone by IBM\/Coursera","fde8f916":"Let's perform some basic explanatory data analysis and derive some additional info from our raw data. First let's count the **number of business in every area candidate**:","9ec3097b":"OK, we now have the coordinates of centers of neighborhoods\/areas to be evaluated, equally spaced (distance from every point to it's neighbors is exactly the same) and within ~1.5km from Prefecture. \n\nLet's now use Google Maps API to get approximate addresses of those locations.","fef43bac":"OK. Let us now **filter** those locations: we're interested only in **locations with no more than two restaurants in radius of 250 meters**, and **no asian restaurants in radius of 100 meters**, and **more than 10 customers**.","0c23720b":"#### Companies visualization","fe99f5ed":"### Problem <a name=\"Problem\"><\/a>","698e920e":"\n\n## Introduction<a name=\"introduction\"><\/a>","92bc585d":"We can clearly identify here an area with a lot of customer and few competitors >>> See the **green marker**.\n\nThe white circle indicate an area 300m wide. We can see that a lot of worker are inside, and the main competitor is not in the center.","e3276eaf":"#### Basics functions","5ddbe9c0":"## Methodology <a name=\"methodology\"><\/a>","0e1e858b":"This study can be used by anyone interested by opening a restaurant. Or any other business. \n\nMaybe they will need to modify some data. \n\n**Personal interest**:\n\nActually, I plan to open this business, so this study is done very seriously, the survey also. This study is going to be a part of a business plan to give to bank in order to optain a mortgage to start a business.","6efe43af":"The mains areas are in the north of prefecture, usualy around 400\/500m away, it's not a big surprise.","be49d000":"### Interest  <a name=\"Interest\"><\/a>","9603bfb6":"Let's create a **hexagonal grid of cells**: we offset every other row, and adjust vertical row spacing so that **every cell center is equally distant from all it's neighbors**.","eb3c3178":"## Data <a name=\"data\"><\/a>","984a14ca":"Looking good. Let's now place all this into a Pandas dataframe.","b7095c0c":"#### Creation and visualization of customer group:","216d56f3":"Good, we have a map with the big companies and universities, we can then already see main areas with potential customers.","3a9e898f":"As the goal of this is to create a business plan in the end, we need to make sure data from api are correct. We also need to check that customer could be interested in this specific business. \n\nIn order to do so, a survey in Paris and Versailles will be done in addition to data gathering. I\u2019ll go in the cities and check at different hours if restaurants are working, if streets are full and so on, and what king of restaurant works well. This survey will allow to validate the data analysis done here.","cdaa7857":"Let's zoom in on candidate areas in **north, on the March\u00e9 Notre Dame**:","6015986d":"#### 10 first areas","3fcf8a02":"### Foursquare\nNow that we have our location candidates, let's use Foursquare API to get info on restaurants in each neighborhood.\n\nWe're interested in venues in 'food' category, but only the ones who can be competitors, this mean food truck, quick food, take away, healthy, not restaurant taking too long.\n\n**We will also list all companies and university to evaluate the customer pool**.","22e8bbc7":"#### Imports","ebeb742d":"### Global map of worker\/students versus Restaurants","752c91e6":"Finaly, let's **reverse geocode those candidate area centers to get the addresses** which can be presented to stakeholders.","48a5bf3b":"We can clearly identify **two big cluster, on north, on south**. \n\nLet's create another heatmap map showing **heatmap\/density of restaurants**.","b227e81a":"We can identify two mains areas, one south, the other one north as expected.\n\nLet's see heatmap:","2e6e4100":"Asian food is growing stronger in France lately. Asian restaurants are very often crowded especially in Paris area. \n\nIn Paris center and \u2018little crown\u2019, Vietnamese baguettes and Bubble tea are opening everywhere, and are always full whatever is the hour.  \n\nThis project aims to estimate the best localization to open such a business in Versailles city, just nearby Paris.\n\nPrior launching any restaurant, it\u2019s important to know if the business as a good opportunity. In order to do so, this report will try to gather data about other restaurant localization, competitors and best localization. \n\nThese data could be use for a business plan afterward"}}