{"cell_type":{"14285b51":"code","c2ed84a6":"code","9c97063e":"code","0dd63933":"code","f61e6459":"code","b93614eb":"code","8f897603":"code","4689f03f":"code","49bfcf44":"code","2a3f8de9":"code","ce01c163":"code","fa9a797d":"code","710a3a99":"code","0f755993":"code","c3fbe369":"code","7905fce3":"code","99e80447":"code","7c8fbebe":"code","98c621ee":"code","0242db15":"code","8f386b77":"code","941c6cf7":"code","ff8ac0b6":"code","0b3b04c2":"code","7c086a52":"code","618dc04b":"code","d5b6ec47":"code","b2e53595":"code","ac5c52f4":"code","427abfc8":"code","e57bac0e":"code","0fcf4b4c":"code","a2fef5e2":"code","f01715a9":"code","03dde163":"code","083ea533":"code","f4c89017":"code","5ca6b858":"code","050cf43c":"code","57a3fbe0":"code","537a9d02":"code","8892dbac":"code","0bc9002d":"code","7938fcb6":"code","dfbcc3b3":"code","3f5a2bcf":"code","bae31ebb":"code","e32c5647":"markdown","7732e8d5":"markdown","f67aca41":"markdown","8867db4e":"markdown","660c0c7b":"markdown","00c4bf6c":"markdown","83ab5b22":"markdown","0513d303":"markdown","613ec340":"markdown","ef419bad":"markdown","e3f90565":"markdown"},"source":{"14285b51":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c2ed84a6":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndata=pd.read_csv('..\/input\/ks-projects-201801.csv')","9c97063e":"data.shape","0dd63933":"data.head()","f61e6459":"data.columns.values","b93614eb":"data.drop('ID', axis = 1, inplace = True)\ndata.drop('goal', axis = 1, inplace = True)\ndata.drop('pledged', axis = 1, inplace = True)\ndata.drop('usd pledged', axis = 1, inplace = True)","8f897603":"data['deadline']=pd.to_datetime(data['deadline'], format=\"%Y\/%m\/%d\").dt.date\ndata['launched']=pd.to_datetime(data['launched'], format=\"%Y\/%m\/%d\").dt.date","4689f03f":"data['days'] = (data['deadline'] - data['launched']).dt.days\ndata['launch_year']=pd.to_datetime(data['launched'], format=\"%Y\/%m\/%d\").dt.year","49bfcf44":"data.head()","2a3f8de9":"data.isnull().sum()","ce01c163":"data['state'].value_counts()","fa9a797d":"success_projects = data[data['state'] == 'successful']['state'].count()\nfail_projects  = data[data['state'] == 'failed']['state'].count()\nothers_projects  = (\n    data[data['state'] == 'canceled']['state'].count() +\n    data[data['state'] == 'live']['state'].count() +\n    data[data['state'] == 'undefined']['state'].count() +\n    data[data['state'] == 'suspended']['state'].count())","710a3a99":"total=success_projects+fail_projects+others_projects\nsuc=success_projects\/total\nfail=fail_projects\/total\nother=others_projects\/total","0f755993":"sizes = [suc, fail, other]\nlabels=\"suc\",\"fail\",\"others\"\nexplode = (0.1, 0, 0)\nplt.pie(sizes,labels=labels,explode=explode,\nautopct='%1.1f%%', shadow=True, startangle=140)\nplt.title(\"Total Success Rate\")","c3fbe369":"#Plotting the Main_category Distrubation\nplt.subplots(figsize=(19,5))\nsns.countplot(x=\"main_category\",data=data)","7905fce3":"plt.subplots(figsize=(19,5))\nsns.countplot(x=\"country\",data=data)","99e80447":"data[\"launch_year\"]=data['launch_year'].apply(str)","7c8fbebe":"ax = sns.countplot(data.launch_year)\nplt.xlabel(\"Year\")\nplt.ylabel(\"Number of Campaigns\")\nplt.title(\"Number of Campaigns vs Year\")\nplt.show(ax)","98c621ee":"launchyear = data.launch_year.value_counts().index","0242db15":"backersort = []\nfor i in launchyear:\n    new = data[data.launch_year == i]\n    backersort.append((i,new.backers.sum()))\nbackersort = pd.DataFrame(backersort, columns = [\"Y\u0131l\",\"Backers\"])\nax = sns.barplot(x=\"Y\u0131l\", y=\"Backers\", data=backersort)","8f386b77":"datasuccess = data[data.state == \"successful\"]\ndatafail = data[data.state == \"failed\"]","941c6cf7":"suc_categories = datasuccess.groupby(\"main_category\")[\"usd_pledged_real\"].sum()\nsuc_categories=suc_categories\/1000000\nfailed_categories = datafail.groupby(\"main_category\")[\"usd_pledged_real\"].sum()\nfailed_categories=failed_categories\/1000000","ff8ac0b6":"failed_categories_goals = datafail.groupby(\"main_category\")[\"usd_goal_real\"].sum()\nfailed_categories_goals=failed_categories_goals\/1000000\nsuccess_categories_goals = datasuccess.groupby(\"main_category\")[\"usd_goal_real\"].sum()\nsuccess_categories_goals=success_categories_goals\/1000000","0b3b04c2":"f, axarr = plt.subplots(2,2, figsize=(30, 10), sharex=True)\nax1=failed_categories_goals.plot.bar(ax=axarr[0][0])\nax1.set_title(\"Most Failed Categories in USD Goals\")\nax2=success_categories_goals.plot.bar(ax=axarr[1][0])\nax2.set_title(\"Most Successful Categories in USD Goals\")\nax3=suc_categories.plot.bar(ax=axarr[0][1])\nax3.set_title(\"Money raised (in USD Million) by Main Category \")\nax4=failed_categories.plot.bar(ax=axarr[1][1])\nax4.set_title(\"Money reduced (in USD Million) by Main Category \")","7c086a52":"f, axarr = plt.subplots(2,1, figsize=(20, 6), sharex=True)\nax=sns.countplot(datasuccess.main_category,ax=axarr[0])\nax.set_title(\"Successful Campaigns Main Categories\")\nax1=sns.countplot(datafail.main_category,ax=axarr[1])\nax1.set_title(\"Failed Main Campaigns Categories\")","618dc04b":"data.corr()","d5b6ec47":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nobjects = [\"category\",\"main_category\",\"currency\",\"state\",\"country\"]\nfor i in objects:  \n    data[i] = le.fit_transform(data[i])\n\ncorr = data.corr()\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(20, 20))\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(900, 100, as_cmap=True)\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, annot=True, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5},annot_kws={'size': 12})\nplt.savefig('corr.png')","b2e53595":"#State = 3 success,fail=1\nsuccessrate = []\nfor i in launchyear:\n    try:\n        new = data[data.launch_year == i]\n        successrate.append((i,new.state.value_counts()[3] \/ new.state.value_counts().sum()))\n    except:\n        successrate.append((i,0))\n\nsuccessrate = pd.DataFrame(successrate, columns = [\"Y\u0131l\",\"Oran\"])\nax = sns.barplot(x=\"Y\u0131l\", y=\"Oran\", data=successrate)  \nax.set_title(\"Successful Rate\")\nax.set_xlabel(\"Year\")\nax.set_ylabel(\"Ratio\")\n","ac5c52f4":"#Data Splitting Libraries\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nfrom sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n\n#Classification Libraries\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier","427abfc8":"data_for_model=pd.read_csv('..\/input\/ks-projects-201801.csv')","e57bac0e":"#Datetime Processing\ndata_for_model['deadline']=pd.to_datetime(data_for_model['deadline'], format=\"%Y\/%m\/%d\")\ndata_for_model['launched']=pd.to_datetime(data_for_model['launched'], format=\"%Y\/%m\/%d\")\n\ndata_for_model['days'] = (data_for_model['deadline'] - data_for_model['launched']).dt.days\ndata_for_model['launch_year']=pd.to_datetime(data_for_model['launched'], format=\"%Y\/%m\/%d\").dt.year\ndata_for_model.drop(['ID',\"name\",\"category\",\"launched\",\"currency\",\"deadline\",\"usd pledged\",\"goal\",\"pledged\"], axis = 1, inplace = True)","0fcf4b4c":"data_for_model[\"launch_year\"]=data_for_model['launch_year'].apply(str) #it has to be string.","a2fef5e2":"data_for_model.corr()","f01715a9":"#Relationship with backers and usd pledged real data\nsns.jointplot(x=\"backers\", y=\"usd_pledged_real\", data=data_for_model, kind=\"reg\");","03dde163":"print(\"Unbalanced Data shape\", len(data))\ndatafail = data_for_model[data_for_model.state == \"failed\"]\ndatasuccess = data_for_model[data_for_model.state == \"successful\"]\ndata_for_model = pd.concat([datafail.sample(len(datasuccess), random_state=5), datasuccess])\nprint(\"Balanced data shape:\", len(data))","083ea533":"data_for_model.state.value_counts()","f4c89017":"def state_process(cell_value):\n    if cell_value == 'successful':\n        return 1\n    else:\n        return 0    \ndata_for_model.state = data_for_model.state.apply(state_process)","5ca6b858":"data_for_model.head()","050cf43c":"print('Original Features:\\n', list(data.columns), '\\n')\ndata_for_model= pd.get_dummies(data_for_model)\nprint('Features after One-Hot Encoding:\\n', list(data_for_model.columns))","57a3fbe0":"data_for_model.shape","537a9d02":"X = data_for_model.iloc[:,data_for_model.columns != 'state']\ny = data_for_model.state\nprint(\"X Columns: \",list(X.columns))","8892dbac":"def ML_training(X,y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n    \n    log_lm = LogisticRegression()\n\n    log_lm.fit(X_train, y_train)\n    logy_pred = log_lm.predict(X_test)\n    acclr = accuracy_score(y_test, logy_pred)*100\n    logquestions = pd.DataFrame({'features': X.columns,'Coef': (log_lm.coef_[0])*100})\n    logquestions = logquestions.sort_values(by='Coef', ascending=False)\n    ##############################\n    dtree=DecisionTreeClassifier()\n\n    dtree.fit(X_train, y_train)\n    dtreey_pred = dtree.predict(X_test)\n    accdtree = accuracy_score(y_test, dtreey_pred)*100\n    \n    dtreequestions = importance(dtree)\n    ##############################\n    rf = RandomForestClassifier(n_estimators=150,random_state=431, max_depth=6, min_weight_fraction_leaf =0.1)\n\n    rf.fit(X_train, y_train)\n    rfy_pred = rf.predict(X_test)\n    accrf = accuracy_score(y_test, rfy_pred)*100\n    \n    accquestions = importance(rf)\n    \n    # Reporting\n    print(\"Logistic Regression Report\")\n    print(classification_report(y_test, logy_pred))\n    print(confusion_matrix(y_test,logy_pred))\n    print(logquestions)\n    print(\"------------------------------------------------------\")\n    \n    print(\"Decision Tree Report\")\n    print(classification_report(y_test, dtreey_pred))\n    print(confusion_matrix(y_test,dtreey_pred))\n    print(dtreequestions)\n    print(\"------------------------------------------------------\")\n    \n    print(\"Random Forest Report\")\n    print(classification_report(y_test, rfy_pred))\n    print(confusion_matrix(y_test,rfy_pred))\n    print(accquestions)\n    print(\"------------------------------------------------------\")\n    ","0bc9002d":"def importance(model):\n    questions = pd.DataFrame({'features': X.columns,'importance': (model.feature_importances_)*100})\n    questions.sort_values(by='importance', ascending=False)\n    questions = questions.sort_values(by='importance', ascending=False)\n    return questions","7938fcb6":"ML_training(X,y)","dfbcc3b3":"from keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.noise import GaussianNoise\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import PReLU\nfrom keras.utils import np_utils\nfrom sklearn.preprocessing import MinMaxScaler","3f5a2bcf":"def ANN_training(X,y):\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n    \n    scaler = MinMaxScaler((-1,1))\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    clf = Sequential()\n    clf.add(Dense(input_shape = (X.shape[1],), units = 10, activation = 'relu'))\n    clf.add(Dense(units = 6, activation = 'relu'))\n    clf.add(Dense(units = 1, activation = 'sigmoid'))\n    clf.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = ['accuracy'])\n    clf.fit(X_train, y_train, batch_size = 100, nb_epoch = 10)\n\n    # Predicting results\n    y_pred = clf.predict(X_test, batch_size = 10)\n    y_pred = (y_pred > 0.5)\n\n    cm = confusion_matrix(y_test, y_pred)\n    print(cm)","bae31ebb":"ANN_training(X,y)","e32c5647":"This notebook created by Ali Akay","7732e8d5":"There is a nice correlation between usd_pledged_real and backers","f67aca41":"As you can see these graphs, technology goals are really high but there are a lot of Technology Campaigns which is failed.","8867db4e":"There is a correlation between backers and usd_pledged_real and also of course country and currency :)","660c0c7b":"ML Models","00c4bf6c":"We are going to create a model about  Campaigns  which is failed and successful.","83ab5b22":"ANN Model","0513d303":"It is increasing number of campaigns until 2016.","613ec340":"- Our ANN model can predict to sucessfull and failed states with 0.9986 acc.\n- The most important features is\n  - usd_pledged_real\n  - backers\n  - usd_goal_real","ef419bad":"Let's Start Modelling","e3f90565":"There are a lot of columns of pledged but I am going to use usd_pledged_real because, this one is converted from the real one."}}