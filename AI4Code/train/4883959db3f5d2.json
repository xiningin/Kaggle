{"cell_type":{"ca2a5021":"code","1fc67e4d":"code","c9b66323":"code","8e77015e":"code","7d742b78":"code","d241277f":"code","07714bf9":"code","75b674ab":"code","5fc777fa":"code","42738514":"code","7cb7092c":"code","8ed58529":"code","90e8a86c":"code","af0136c6":"code","8bff71a9":"code","a3460a6a":"code","0c293e57":"code","4e3c71c6":"code","a4030914":"code","7350bf83":"code","7ac36c17":"code","db66a1d1":"code","bb4ae77b":"code","3a72f12f":"code","dc55ea4a":"code","5b1df8c4":"code","6e52e217":"code","dfa45b07":"code","7f13035f":"code","019056ca":"markdown","e6ab7c8e":"markdown","009fdf30":"markdown","b7c23ed3":"markdown","b94d6d1e":"markdown","b7966a91":"markdown","e2414d85":"markdown","767e2b3d":"markdown","dc56ae0e":"markdown","312edb11":"markdown","1f23f22d":"markdown","8d2585e7":"markdown","97361521":"markdown","20a8686a":"markdown","103d9b30":"markdown","c81eb9b6":"markdown","ba90bed8":"markdown","b5050948":"markdown","150486d6":"markdown","6c487c9a":"markdown","917a0f36":"markdown","ab16f13f":"markdown","1742d344":"markdown","e7c13a3c":"markdown","5908fdac":"markdown","2567fba0":"markdown","5a9cb4fb":"markdown","7ffadcae":"markdown","ab647108":"markdown","f07664a3":"markdown","34abd255":"markdown","26243ebf":"markdown","93edb37d":"markdown","cb431000":"markdown","999731a9":"markdown","77044b7d":"markdown","c2400711":"markdown","4d976520":"markdown"},"source":{"ca2a5021":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn import tree\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neighbors import NearestCentroid\nfrom sklearn.naive_bayes import GaussianNB","1fc67e4d":"# Wczytanie i transformacja danych\ndf = pd.read_csv('..\/input\/fifa19\/data.csv', index_col = 0)\ndf.head()","c9b66323":"df.columns","8e77015e":"# Pozbycie si\u0119 zb\u0119dnych kolumn\ndf = df.drop(columns=['ID', 'Name', 'Age', 'Photo', 'Nationality', 'Flag', 'Overall', 'Potential', 'Club', 'Club Logo'])\ndf = df.drop(columns=['Value', 'Wage', 'Special', 'International Reputation', 'Work Rate', 'Body Type', 'Real Face'])\ndf = df.drop(columns=['Jersey Number', 'Joined', 'Loaned From', 'Contract Valid Until', 'LS', 'ST', 'RS', 'LW'])\ndf = df.drop(columns=['LF', 'CF', 'RF', 'RW', 'LAM', 'CAM', 'RAM', 'LM', 'LCM', 'CM', 'RCM', 'RM', 'LWB', 'LDM'])\ndf = df.drop(columns=['CDM', 'RDM', 'RWB', 'LB', 'LCB', 'CB', 'RCB', 'RB', 'Release Clause'])","7d742b78":"df.isnull().sum() # liczba warto\u015bci NaN dla ka\u017cdej kolumny","d241277f":"df.dropna(inplace = True)","07714bf9":"df.describe().T # opis danych numerycznych","75b674ab":"norm_list = [\"Weak Foot\", \"Skill Moves\"]\n\nfor n in norm_list:\n    df[n] = 100 * df[n]\/df[n].max() #normalizacja 0-100\n\ndf[norm_list].head()","5fc777fa":"df.drop(columns = [\"Position\"]).describe(include=['object']).T","42738514":"def ft_to_inch(ft): # funkcja do zamiany jednostki [stopy+cale] na [cale]\n    x = [int(i) for i in ft.split(\"'\")] \n    x[1] += x[0] * 12\n    return x[1]\n\ndf[\"Height\"] = df[\"Height\"].map(lambda x: ft_to_inch(x))\ndf[\"Height\"] = round(100*df[\"Height\"]\/df[\"Height\"].max(), 0) # normalizacja 0-100\ndf[\"Height\"].describe()","7cb7092c":"df[\"Weight\"] = df[\"Weight\"].map(lambda x:  int(round(int(x[:-3]), 0)))\ndf[\"Weight\"] = round(100*df[\"Weight\"]\/df[\"Weight\"].max(), 0)\ndf[\"Weight\"].describe()","8ed58529":"df['isLeft'] = df[\"Preferred Foot\"].map(lambda x: 0 if x == \"Right\" else 1)\ndf.drop(columns=[\"Preferred Foot\"], inplace = True)\ndf['isLeft'].describe()","90e8a86c":"len(df.Position.unique())","af0136c6":"df.groupby(\"Position\")[\"Position\"].count().sort_values(ascending = False)","8bff71a9":"df.groupby(\"Position\")[\"Position\"].count().sort_values(ascending = False).plot(kind = 'bar', figsize=(20,10))","a3460a6a":"df = df[(df.Position != 'RAM') & (df.Position != 'LAM') & (df.Position != 'RF') & (df.Position != 'LF')]","0c293e57":"defe = ['RWB', 'RCB', 'RB', 'LWB', 'LCB', 'LB', 'CB'] # obro\u0144cy\nfwd = ['ST', 'RW', 'RS', 'LW', 'LS', 'CF'] # napastnicy\nmid = ['RM', 'RDM', 'RCM', 'LDM', 'LCM', 'CM', 'CDM', 'CAM', 'LM'] # pomocnicy\ngk = ['GK'] # bramkarz\nall_pos = fwd + mid + defe + gk # wszystkie pozycje","4e3c71c6":"# wykres dla preferowanej nogi\ndict1 = {}\nfor p in all_pos:\n    dict1[p] = df[df.Position == p].groupby('isLeft')['isLeft'].count()[1] \/ df[df.Position == p].count()[\"isLeft\"]\n\nlfoot = pd.DataFrame.from_dict(dict1, orient='index').sort_values(by = 0, ascending = False)\nlfoot.plot.bar(legend = False)","a4030914":"rl = {}\nrl['R'] = df[df.Position.str.startswith('R')].groupby('isLeft')['isLeft'].count()[1] \/ df[df.Position.str.startswith('R')].count()[\"Position\"]\nrl['L'] = df[df.Position.str.startswith('L')].groupby('isLeft')['isLeft'].count()[1] \/ df[df.Position.str.startswith('L')].count()[\"Position\"]\nplt.bar(range(len(rl)), list(rl.values()), align='center')\nplt.xticks(range(len(rl)), list(rl.keys()))","7350bf83":"isLeft = df[\"isLeft\"]\ndf.drop(columns = [\"isLeft\"], inplace = True)","7ac36c17":"for p in [fwd, mid, defe, gk]: \n    dff = df.loc[df['Position'].isin(p)].groupby('Position', as_index=True).mean()\n    plt.figure(figsize=(20,len(p)\/2),dpi = 80)\n    sns.heatmap(dff, cmap=\"bone\", annot=True, vmin = 10, vmax = 90)","db66a1d1":"plt.figure(figsize=(20,16),dpi = 80)\nsns.heatmap(df.corr(),annot = df.corr()) #mapa ciep\u0142a z korelacj\u0105","bb4ae77b":"\"Liczba atrybut\u00f3w przed scalaniem: \" + str(len(list(df.drop(columns=['Position']).select_dtypes(exclude=[\"object\"]).columns)))","3a72f12f":"thr = 0.9 #pr\u00f3g wsp\u00f3\u0142czynnika korelacji, atrybuty skorelowane ponad pr\u00f3g zostan\u0105 scalone\n\ndff = df.select_dtypes(['number']).copy()\ncorr = dff.corr()\ncontinueLoop = True\nattr_id = 0;\nwhile(continueLoop):\n    continueLoop = False\n    for i in range(0,len(corr)):\n        attrs = [i]\n        for j in range(0,len(corr)):\n            if(i != j and corr.iloc[i,j] > thr):\n                attrs.append(j)\n        if (len(attrs) > 1):\n            attr_name = 'attr_' + str(attr_id)\n            attr_names = []\n            for k in attrs:\n                attr_names.append(dff.columns[k])\n            print('Combining ' + str(attr_names) + ' into ' + attr_name)\n            attr_id = attr_id + 1\n            dff[attr_name] = dff.iloc[:,attrs].mean(axis=1)\n            dff = dff.drop(dff.columns[attrs], axis=1)\n            continueLoop = True\n            corr = dff.corr()\n            break;     \nplt.figure(figsize=(14,10),dpi = 80)\nsns.heatmap(dff.corr(),annot = dff.corr())\n\"Liczba atrybut\u00f3w po scalaniu: \" + str(len(dff.columns))","dc55ea4a":"# SelectKBest\ny = df['Position'] #target\nX = dff #nasz zbi\u00f3r\n\nn = len(X.columns) - 2 #K - ile najlepszych atrybut\u00f3w uwzgl\u0119dniamy w modelu\n\nbestfeatures = SelectKBest(score_func=chi2, k=n)\nfit = bestfeatures.fit(X,y)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns)\n#concat two dataframes for better visualization \nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nfeatureScores.columns = ['Specs','Score']  #naming the dataframe columns\nfeatureScores.nlargest(n,'Score').set_index('Specs').plot(kind='bar', figsize=(20,10))\n\nX = X[featureScores.nlargest(n,'Score').iloc[:,0].values].join(isLeft)","5b1df8c4":"#parametry modeli sprawdzane przez GridSearch\ndt = {KNeighborsClassifier() : {'n_neighbors': np.arange(57, 63, 2)},\n      NearestCentroid() : {'metric': ['euclidean', 'manhattan']},\n      GaussianNB() : {},\n      DecisionTreeClassifier() : {'max_depth': np.arange(5, 12)}}\n\nbest_estimator = None #zmienna best_estimator zachowa najlepszy model (z 4 wybranych) z najlepszymi parametrami \ntmp = 0\n\nfor key in dt:\n    m = GridSearchCV(key, dt[key]) #przekazujemy model wraz z list\u0105 parametr\u00f3w do GridSearch\n    m.fit(X, y)\n    \n    if m.best_score_ > tmp:\n        best_estimator = m.best_estimator_\n        tmp = m.best_score_\n    \n    print ('Model {}'.format(type(key).__name__))\n    print ('Najlepszy wynik : {}'.format(m.best_score_))\n    print ('Najlepsze parametry: {}'.format(m.best_params_))\n    print('\\n\\n')","6e52e217":"model = best_estimator\n\n#podzia\u0142 danych na treningowe i testowe\ntrain_x, val_x, train_y, val_y = train_test_split(X, y, random_state = 0, test_size = 0.2) \n\nmodel.fit(train_x, train_y)\nwynik_test = model.predict(val_x)\n\nprint(\"Wykres kolumnowy - do jakiej pozycji model przypisa\u0142 pi\u0142karzy wzgl\u0119dem ich prawdziwej pozycji:\")\nmp_test = pd.crosstab(val_y, wynik_test)\n\nf = plt.figure(figsize=(20, 20))\n\nax = []\nrate_df = pd.Series({})\n\nj = 0\n    \nfor i in range(0, len(mp_test.index)):\n    r = mp_test.iloc[i]\n    r = r[r != 0].sort_values(ascending=False)\n    cname = mp_test.index[i]\n    \n    f.tight_layout()\n    \n    ax.append(f.add_subplot(6, 4,i+1))\n    ax[i].title.set_text(cname)\n    ax[i].bar(r.index, r, width = 0.8)\n    \n    if cname in mp_test.columns:\n        rate_df[cname] = mp_test.iloc[i][j] \/ mp_test.iloc[i].sum()\n        j += 1\n    else:\n        rate_df[cname] = 0\n    \nplt.show()\n\nprint(\"Procent poprawnego dopasowania pi\u0142karzy na konkretnej pozycji:\")\nprint(rate_df.sort_values(ascending=False))\n        \nrate_df.sort_values(ascending=False).plot(kind = 'bar', figsize=(20,10))","dfa45b07":"#Podzia\u0142 na GK, DEF, MID i FWD\nresults = pd.DataFrame({})\nresults['real'] = val_y\nresults['pred'] = wynik_test\nresults['pred'] = results['pred'].map(lambda x: 'GK' if x in gk else ('DF' if x in defe else ('MF' if x in mid else 'FW')))\nresults['real'] = results['real'].map(lambda x: 'GK' if x in gk else ('DF' if x in defe else ('MF' if x in mid else 'FW')))\na = (len(results[results['pred'] == results['real']]) \/ len(results)) * 100\nprint('Skuteczno\u015b\u0107 modelu wynosi', a, '%')","7f13035f":"cross_val_score(estimator=best_estimator, X=X, y=y, cv=5).mean()","019056ca":"Z powy\u017ceszego wykresu mo\u017cemy odczyta\u0107 wiele ciekawych zale\u017cno\u015bci. Na pierwszy rzut oka wyra\u017anie wida\u0107 jak mocno skorelowane s\u0105 atrybuty bramkarskie i jak jednoznacznie s\u0105 w stanie odr\u00f3\u017ani\u0107 bramkarza od innych. \n\nMamy r\u00f3wnie\u017c poka\u017an\u0105 grup\u0119 atrybut\u00f3w, kt\u00f3re odr\u00f3\u017cniaj\u0105 **pi\u0142karzy ofensywnych od defensywnych**. S\u0105 to m.in:\n- Skill Moves (wy\u017csze dla ofensywnych)\n- Finishing (wy\u017csze dla ofensywnych)\n- Volleys (wy\u017csze dla ofensywnych)\n- Agression (wy\u017csza dla defensywnych\n- Interceptions (wy\u017csze dla defensywnych)\n \nMamy r\u00f3wnie\u017c par\u0119 atrybut\u00f3w, kt\u00f3re moocniej wyr\u00f3\u017aniaj\u0105 **obro\u0144c\u00f3w od pomocnik\u00f3w i napastnik\u00f3w**, np:\n- Weak Foot\n- LongShots\n- Composure\n\nZ naszych danych mo\u017cemy r\u00f3wnie\u017c wyra\u017anie wyr\u00f3\u017cni\u0107 **graczy graj\u0105cyh po bokach od tych graj\u0105cych na \u015brodku**. Gracze graj\u0105cy na skrzyd\u0142ach s\u0105 zwykle szybsi i zwinniejsi. S\u0105 to atrybuty:\n- Crossing\n- Dribbling\n- Acceleration\n- SprintSpeed\n\nSzczeg\u00f3lnie r\u00f3\u017cnice pomi\u0119dzy \u015brodkowymi, a bocznymi graczami wida\u0107 w\u015br\u00f3d obro\u0144c\u00f3w. \u015arodkowi obro\u0144cy s\u0142yn\u0105 np: z dobrej gry g\u0142ow\u0105, za\u015b boczni obro\u0144cy z szybko\u015bci i dobrych do\u015brodkowa\u0144. R\u00f3\u017cnice te obrazuj\u0105 atrybuty:\n- HeadingAccuracy\n- Curve (tak\u017ce LF i RF)\n- Balance\n- Positioning\n\nW danych nie wida\u0107 natomiast atrybutu, kt\u00f3ry wyra\u017anie rodziela\u0142 by pomocnik\u00f3w od reszty. Wiele ich atrybut\u00f3w jest zbli\u017cone warto\u015bciami do napastnik\u00f3w. Najlepsze wydaj\u0105 si\u0119 by\u0107 atrybuty LongPassing oraz Finishing.\n\n## Scalanie skorelowanych atrybut\u00f3w\n\nZ racji, \u017ce wiele atrybut\u00f3w wskazuje na te same zale\u017cno\u015bci, prawdopodnie wiele z nich jest r\u00f3wnie\u017c mocno skorelowanych. Mo\u017cemy po\u0142aczy\u0107 najbardziej skorelowane atrybuty ze sob\u0105, aby upro\u015bci\u0107 sobie model.","e6ab7c8e":"Z powy\u017cszego wykresu wynika, \u017ce po\u0142owa pi\u0142karzy graj\u0105cych na lewej stronie jest lewono\u017cna, kiedy na prawej stronie gra takich pi\u0142karzy ledwie 10%. Atrybut \"isLeft\" przyda si\u0119 zatem w naszym modelu, do rozr\u00f3\u017cniania po kt\u00f3rej stronie gra pi\u0142karz.\n\nAtrybut binarny \"isLeft\" b\u0119dziemy przechwywa\u0107 osobno, aby nie przeszkadza\u0142 w analizie atrybut\u00f3w numerycznych.","009fdf30":"Mamy tylko 3 atrybuty kategoryczne. Mo\u017cemy je jednak \u0142atwo przekonwertowa\u0107: Height i Weight na numeryczne i Preferred Foot na binarny.\n\nAtrybut Height mo\u017cemy zamieni\u0107 na numeryczny zmieniaj\u0105c jednostki na cale. Dodatkowo znormalizujemy go, aby jego warto\u015bci by\u0142y wyskalowane tak samo jak atrybuty umiej\u0119tno\u015bci, co u\u0142atwi dalsz\u0105 analiz\u0119 danych.","b7c23ed3":"## Wst\u0119p","b94d6d1e":"Z mapy ciep\u0142a widzimy, \u017ce najbardziej skorelowane s\u0105 atrybuty bramkarskie.  Widzimy r\u00f3wnie\u017c wysok\u0105 korelacj\u0119 pomi\u0119dzy atrybutami defensywnymi (Marking, Interceptions, StandingTackle, SlidingTackle). Atrybuty dot. szybko\u015bci,  SprintSpeed oraz Acceleration, tak\u017ce s\u0105 mocno skorelowane. \n\nAby po\u0142\u0105czy\u0107 najbardziej skorelowane atrybuty u\u017cyli\u015bmy funkcji, kt\u00f3ra scala ze sob\u0105 wszystkie atrybuty ze wsp\u00f3\u0142czynnikime korelacji powy\u017cej zadanego progu. Jako warto\u015b\u0107 scalonego atrybutu przyjmuje si\u0119 \u015bredni\u0105 arytmetyczn\u0105 ze sk\u0142adowych atrybut\u00f3w.","b7966a91":"Na koniec, atrybut Preferred Foot mo\u017cemy uczyni\u0107 atrybutem binarnym. Pi\u0142karzom lewono\u017cnym przypiszemy warto\u015b\u0107 1, a prawono\u017cnym 0, za\u015b sam atrybut nazwiemy isLeft.","e2414d85":"## Import niezb\u0119dnych bibliotek","767e2b3d":"## Weryfikacja najlepszego modelu","dc56ae0e":"Wiele atrybut\u00f3w mo\u017cemy od razu odrzuci\u0107, poniewa\u017c nie pasuj\u0105 do naszego modelu (nie maj\u0105 wp\u0142ywu na pozycj\u0119 na jakiej gra pi\u0142karz). Te atrybuty to:\n- ID, \n- Name,\n- Age,\n- Photo, \n- Nationality, \n- Flag,\n- Overall,\n- Potential, \n- Club, \n- Club Logo, \n- Value, \n- Wage, \n- Special, \n- International Reputation, \n- Work Rate,\n- Body Type - atrybut ten jest u\u017cywany do okre\u015blenia modelu zawodnika w grze, dysponujemy bardziej szczeg\u00f3\u0142owymi atrybutami fizycznymi;\n- Real Face, \n- Jersey Number, \n- Joined, \n- Loaned From, \n- Contract Valid Until, \n- 'LS', 'ST', 'RS', 'LW', 'LF', 'CF', 'RF', 'RW', 'LAM', 'CAM', 'RAM', 'LM', 'LCM', 'CM', 'RCM', 'RM', 'LWB', 'LDM', 'CDM', 'RDM', 'RWB', 'LB', 'LCB', 'CB', 'RCB', 'RB', \n- Release Clause.","312edb11":"Project I did for college for my data analysis class. Although **it is in Polish**, the code might be helpful to understand the process.\n\nBasically, the task was to build a classifier, which would determine the player's position based on his physical atributtes and skills, such as dribbling, shooting, etc.","1f23f22d":"\n\nPodobnie mo\u017cemy uczyni\u0107 atrybut Weight numerycznym, usuwaj\u0105c przyrostek lbs z ka\u017cdego rekordu. R\u00f3wnie\u017c normalizujemy ten atrybut 0-100.","8d2585e7":"#### Opis atrybut\u00f3w numerycznych:","97361521":"Z wykresu wida\u0107, \u017ce gracze graj\u0105cy z lewej strony s\u0105 cz\u0119\u015bciej lewono\u017cni, ni\u017c ci graj\u0105cy z prawej (zw\u0142acza jest to widoczne dla obro\u0144c\u00f3w). Aby lepiej pokaza\u0107 t\u0119 zale\u017cno\u015b\u0107, mo\u017cemy stworzy\u0107 analogiczny wykres, gdzie pi\u0142karzy podzielimy na graj\u0105cych na prawej stronie (R) i na lewej (L).","20a8686a":"Widzimy, \u017ce pozycje RAM, LAM, RF i LF maj\u0105 bardzo ma\u0142o przedstawicieli - \u0142\u0105cznie jest ich tylko 73 dla ponad 18000 rekord\u00f3w w ca\u0142ym zbiorze. Nie warto uwzgl\u0119dnia\u0107 w modelu tak nielicznych zbior\u00f3w, poniewa\u017c s\u0105 ma\u0142o reprezentatywne i mog\u0105 negatywnie wp\u0142yn\u0105\u0107 na dok\u0142adno\u015b\u0107 modelu. Z tego wzgl\u0119du wyrzucimy te pozycje z danych.","103d9b30":"Zadali\u015bmy 4 modele klasyfikacji omawiane na zaj\u0119ciach wraz ze zbiorem parametr\u00f3w: \n* K najbli\u017cszych s\u0105siad\u00f3w\n* Naiwny klasyfikator bayesowski\n* Metoda najbli\u017cszych prototyp\u00f3w\n* Drzewo decyzyjne\n\nNarz\u0119dzie GridSearchCV sprawdza dok\u0142adno\u015b\u0107 danego modelu dla ka\u017cdego zestawu parametr\u00f3w, kt\u00f3re podamy. Dok\u0142adno\u015b\u0107 jest sprawdzana metod\u0105 walidacji krzy\u017cowej (cross validation), dzi\u0119ki czemu nie musimy dzieli\u0107 danych na zestaw treningowy i walidacyjny. W ten spos\u00f3b b\u0119dziemy w stanie dobra\u0107 najlepsze parametry dla ka\u017cdego modelu. Nast\u0119pnie, spo\u015br\u00f3d 4 modeli, wybierzemy ten z najwi\u0119ksz\u0105 dok\u0142adno\u015bci\u0105.","c81eb9b6":"# Podsumowanie","ba90bed8":"Seria FIFA jest najpopularniejsz\u0105 seri\u0105 gier o pi\u0142ce no\u017cnej. Gra FIFA19, wydana w 2018 roku przez EA Vancouver, jest 26 cz\u0119\u015bci\u0105 tej serii. Dane z tej gry, zawieraj\u0105ce cechy ka\u017cdego pi\u0142karza, zosta\u0142y udost\u0119pnione na stronie Kaggle. Na ich podstawie b\u0119dziemy chcieli utworzy\u0107 model, kt\u00f3ry okre\u015bli pozycj\u0119 na jakiej powinien gra\u0107 pi\u0142karz bior\u0105c pod uwag\u0119 jego cechy.","b5050948":"Jak wida\u0107, skuteczno\u015b\u0107 naszego modelu przy podziale pi\u0142karzy tylko na 4 podstawowe pozycje jest bardzo wysoka - ponad 87%. Bior\u0105c pod uwag\u0119, \u017ce nie optymalizowali\u015bmy naszego modelu dla takiej klasyfikacji, prawdopodbnie da\u0142oby si\u0119 uzyska\u0107 jeszcze wy\u017csz\u0105 dok\u0142\u0105dno\u015b\u0107. |","150486d6":"## Wst\u0119pna obr\u00f3bka danych\nLista atrybut\u00f3w:","6c487c9a":"# Okre\u015blanie pozycji pi\u0142karza na podstawie jego umiej\u0119tno\u015bci\n#### Krzysztof M, Marcin K, Seweryn B\n\n\u0179r\u00f3d\u0142o danych: https:\/\/www.kaggle.com\/karangadiya\/fifa19","917a0f36":"## Wczytanie danych","ab16f13f":"Najskuteczniejszym modelem w naszym zadaniu okaza\u0142 si\u0119 by\u0107 klasyfikator K najbli\u017cszych s\u0105siad\u00f3w (k = 59).","1742d344":"### Atrybuty kategoryczne\n\nAnaliz\u0119 zaczniemy od jedynego nienumerycznego atrybutu, czyli isLeft (stworzonego z Preferred Foot). Najpierw przedstawimy wykres pokazuj\u0105cy jaki procent pi\u0142karzy na danej pozycji jest lewono\u017cny.","e7c13a3c":"Nasz atrybut decyzyjny ma wiele unikalnych warto\u015bci. Mo\u017cliwe, \u017ce dla poszczeg\u00f3lne pozycje maj\u0105 bardzo ma\u0142o reprezentant\u00f3w i b\u0119dziemy mogli je zignorowa\u0107. Sprawdzamy zatem ile jest pi\u0142akrzy na poszczeg\u00f3lnych pozycjach.","5908fdac":"Sprawdzamy braki w danych:","2567fba0":"#### Opis atrybut\u00f3w kategorycznych:","5a9cb4fb":"Najlepsza, bezb\u0142\u0119dna skuteczno\u015b\u0107 jest dla **GK** (bramkarza). Nie jest to jednak zaskoczeniem, poniewa\u017c cechy bramkarskie wyra\u017anie odr\u00f3\u017cnia\u0142y go od innych. \n\nDobr\u0105 skuteczno\u015b\u0107 (powy\u017cej 80%) mamy tak\u017ce dla pozycji **ST, CB, CM**. Oznacza to, \u017ce dla 4 najliczniejszych pozycji (i najbardziej podstawowych) nasz model radzi dobie bardzo dobrze.\n\nNi\u017csz\u0105 skuteczno\u015b\u0107 (40-50%) mamy dla pozycji **LB, RB, CAM, CDM**. Pozycje RB i LB cz\u0119sto s\u0105 mylone ze sob\u0105 przez model. CDM jest bardzo cz\u0119sto mylony z CM i rzadziej z obro\u0144cami. CAM jest czesto brany jako CM, LM lub RM.\n\nSkuteczno\u015b\u0107 na poziomie ~20% mamy dla pozycji **LM, RM**. Pozycje te s\u0105 cz\u0119sto mylone ze sob\u0105, ale tak\u017ce z ST i CM.\n\nNiemal zerow\u0105 skuteczno\u015b\u0107 mamy dla pozycji **LW, LCM, RCB, LCB**.\n\nDla a\u017c 9 spo\u015br\u00f3d 23 pozycji mamy zerow\u0105 dok\u0142adno\u015b\u0107 przypasowania. S\u0105 to: **RCM, LWB, RWB, LDM, RDM, RS, CF, RW, LS**. W naszych danych brakuje atrybut\u00f3w, kt\u00f3re s\u0105 w stanie wyra\u017anie oddzieli\u0107 te pozycje od reszty.\n\n## O niskiej dok\u0142adno\u015bci modelu\nGeneralnie, dok\u0142adno\u015b\u0107 poni\u017cej 50% w klasyfikacji wydaje si\u0119 by\u0107 ma\u0142o zadowalaj\u0105ca. Jest to jednak przede wszystkim wina nie \u017ale dopasowanego modelu, a danych. W naszych danych bowiem zwyczajnie brakuje atrybut\u00f3w, kt\u00f3re by\u0142yby w stanie wyra\u017anie rozr\u00f3\u017cni\u0107 wi\u0119kszo\u015b\u0107 pozycji. Dla najabrdziej charakterystycznych: GK, ST, CB, CM nasz model radzi sobie bardzo dobrze. Jednak\u017ce te bardziej specyficzne, jak: LCM, LS, RCB, s\u0105 zbyt ma\u0142o charakterystyczne, by nasz model m\u00f3g\u0142 je rozr\u00f3\u017cni\u0107. \n\nAby udowodni\u0107 t\u0119 tez\u0119, sprawd\u017amy skuteczno\u015b\u0107 modelu przy dopasowywaniu pi\u0142karzy do 4 grup (napastnicy, pomocnicy, obro\u0144cy, bramkarze). U\u017cyjemy tych samych danych testowych i predykcji modelu.","7ffadcae":"Wygl\u0105da na to, \u017ce 48 rekord\u00f3w nie zawiera danych. Jest to zaledwie 0.3% naszego zbioru, wi\u0119c usuwamy te rekordy.","ab647108":"Skuteczno\u015b\u0107 uzyskanej klasyfikacji dla wszystkich pozycji jest r\u00f3wna ~48.3% (u\u017cywaj\u0105c walidacji krzy\u017cowej na ca\u0142ym zbiorze). Bior\u0105c pod uwag\u0119 liczb\u0119 pozycji, do kt\u00f3rych nasz model mia\u0142 przypisywa\u0107 pi\u0142karzy (23), nie jest to wynik z\u0142y. \u015awiadczy on jedynie o tym, \u017ce w naszych danych nie by\u0142o cech pozwalaj\u0105cych na tak dok\u0142adny podzia\u0142.\n\nZasadniczo w pi\u0142ce no\u017cnej mamy 4 pozycje: bramkarz, obro\u0144ca, pomocnik i napastnik. I patrz\u0105c pod tym k\u0105tem, pi\u0142karze na poszczeg\u00f3lnych pozycjach wyra\u017anie r\u00f3\u017ani\u0105 si\u0119 od siebie. Napastnik ma lepsze wyko\u0144czenie, pomocnik lepsze podania, obro\u0144ca w\u015blizgi, za\u015b bramkarz ma zupe\u0142nie inny zestaw. Fifa rozr\u00f3\u017cnia jednak wiele wi\u0119cej pozycji, bardzo specyficznych. S\u0105 one cz\u0119sto zwi\u0105zane bardziej z formacjami, ni\u017c z konkretnymi cechami pi\u0142karza. Je\u017celi mamy a\u017c 23 r\u00f3\u017cne pozycje (oryginalnie w danych by\u0142o 27!) logicznym jest, \u017ce wi\u0119kszo\u015b\u0107 z nich b\u0119dzie bardzo podobna. Podsumowuj\u0105c, mo\u017cemy rozr\u00f3\u017cnia\u0107 pozycje pi\u0142karzy po ich cechach fizycznych i umiejetno\u015bciach, ale ma to sens tylko do pewnego stopnia dok\u0142adno\u015bci - 23 pozycje to troch\u0119 za du\u017co.","f07664a3":"Pozosta\u0142e pozycje mo\u017cemy pogrupowa\u0107, aby u\u0142atwi\u0107 sobi\u0119 dalsz\u0105 analiz\u0119. Naturlany wydaje si\u0119 by\u0107 podzia\u0142 na napastnik\u00f3w, pomocnik\u00f3w, obro\u0144c\u00f3w i bramkarzy.","34abd255":"W wyniku scalania mocno skorelowanych atrybut\u00f3w (powy\u017cej 0.9), uda\u0142o nam si\u0119 zredukowa\u0107 ilo\u015b\u0107 atrybut\u00f3w z 38 do 28","26243ebf":"## Wyb\u00f3r parametr\u00f3w\n\nTrzeba pami\u0119ta\u0107, \u017ce nasz model ma klasyfikowa\u0107 pi\u0142karzy do 23 pozycji. My jeste\u015bmy w stanie naocznie zauwa\u017cy\u0107 w danych jedynie zale\u017cno\u015bci pomi\u0119dzy du\u017cymi grupami pi\u0142karzy, np.: r\u00f3\u017cnice pomi\u0119dzy ofensywnyni i defensywnymi czy bocznymi i \u015brodkowymi. Nasz model musi by\u0107 jednak znacznie dok\u0142adniejszy i uwzgl\u0119dnia\u0107 atrybuty pokazujace r\u00f3\u017cnice pomi\u0119dzy specyficznymi pozycjami. Trudno jest dobra\u0107 \"r\u0119cznie\" atrybuty dla tak skomplikowanego klasyfikatora. W zwi\u0105zku postanowili\u015bmy wspom\u00f3c si\u0119 gotowym narz\u0119dziem do doboru parametr\u00f3w - **SelectKBest**.\n\nNarz\u0119dzie SelectKBest jest u\u017cywane w zadaniach klasyfikacji do doboru najlepszych atrybut\u00f3w. Przy pomocy wybranej funkcji ocenenia atrybuty i wybiera K najlepszych.\n\nU\u017cyli\u015bmy dw\u00f3ch funkcji oceny: domy\u015bln\u0105 (ANOVA F) oraz chi2 (test chi-kwadrat) oraz kilka warto\u015bci liczby K najlepszych atrybut\u00f3w uwzgl\u0119dnionych w modelu, aby znale\u017a\u0107 konfiguracj\u0119 daj\u0105c\u0105 najdok\u0142adniejszy model.\n\nNajdok\u0142adniejszy model otrzymali\u015bmy odrzucaj\u0105c 2 najgorsze atrybuty wed\u0142ug funkcji chi2: Reactions, Height. Oznacza to, \u017ce u\u017cyli\u015bmy 27 atrybut\u00f3w. ","93edb37d":"Tworzymy model z najlepszym wynikiem i parametrami wskazanymi przed GridSearchCV - **klasyfiaktor k najbli\u017cszych s\u0105siad\u00f3w (k = 59)**. Tym razem jednak trenujemy go na danych testowych, poniewa\u017c chcemy przeanalizowa\u0107 dok\u0142adno\u015b\u0107 jego klasyfikacji na nowych danych (walidacyjnych).\n\nPoniewa\u017c mamy du\u017co pozycji, zamiast macierzy pomy\u0142ek, tworzymy wykresy kolumnowe, kt\u00f3re poka\u017c\u0105 do jakiej pozycji model przypisa\u0142 pi\u0142karzy wzgl\u0119dem ich prawdziwej pozycji.","cb431000":"Najlepsz\u0105 dok\u0142adno\u015b\u0107 klasyfikacji otrzymujemy dla klasyfiaktora k najbli\u017cszych s\u0105siad\u00f3w (k = 59): ~48.3%\n\nNiemal identyczny, jednak minimalnie ni\u017cszy wynik mamy dla drzewa decyzyjnego (max. g\u0142\u0119dboko\u015b\u0107 8): ~48.2%.\n\nNaiwny klasyfikator bayesowski jest ju\u017c wyra\u017anie mniej dok\u0142adny: ~43.7%.\n\nMetoda najbli\u017cszego prototypu daje wyra\u017anie najgorszy wynik spo\u015br\u00f3d badanych modeli: ~34.5%","999731a9":"### Atrybuty numeryczne","77044b7d":"Z uwagi na du\u017c\u0105 ilo\u015b\u0107 numerycznych atrybut\u00f3w opisowych oraz wiele unikalnych warto\u015bci atrybutu decyzyjnego, mamy ograniczone mo\u017cliwo\u015bci tworzenia czytelnych wykres\u00f3w. W wizualizacji dla zadania\u0144 klasyfikacji \u015bwietnie sprawdza si\u0119 seaborn.pairplot z podzia\u0142em na poszczeg\u00f3lne grupy (atrybut hue). Tutaj jednak mamy 23 pozycje do rozr\u00f3\u017cnienia i taki wykres by\u0142by zupe\u0142nie nieczytelny. Z tego wzgl\u0119du przedstawimy dane w postaci mapy ciep\u0142a, gdzie warto\u015bciami b\u0119d\u0105 \u015brednie warto\u015bci danego atrybutu dla pi\u0142karzy na danej pozycji.","c2400711":"Niemal wszystkie brane przez nas atrybuty s\u0105 znormalizowane 0-100, co pomo\u017ce nam przy analizie i tworzeniu modelu.\n\nAtrybuty Weak Foot oraz Skill Moves, kt\u00f3re s\u0105 podane w skali 1-5, znormalizujemy 0-100, aby dopasowa\u0107 je do reszty.","4d976520":"## Eksploracyjna Analiza Danych\nSprawdzamy ile unikalnych warto\u015b\u0107 ma nasz atrybut decyzyjny:"}}