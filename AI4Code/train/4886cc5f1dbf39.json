{"cell_type":{"a780f188":"code","f722d993":"code","dc652fc7":"code","17f17d84":"code","49c80c86":"code","331f8c3d":"code","e593f198":"code","d8299832":"code","5ab75f42":"code","28935473":"markdown","2ef4d2ed":"markdown","f17879c9":"markdown","59fde9bb":"markdown","90122aa3":"markdown","c1ddcc8c":"markdown"},"source":{"a780f188":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.python.keras.utils.vis_utils import plot_model\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f722d993":"train_dir = \"..\/input\/waste-classification-data\/DATASET\/TRAIN\"\nval_dir = \"..\/input\/waste-classification-data\/DATASET\/TEST\"\n\n        \n\ntrain_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=40,\n                                                                width_shift_range=0.2,\n                                                                height_shift_range=0.2, \n                                                                shear_range=0.2,\n                                                                zoom_range=0.2,\n                                                                horizontal_flip=True,\n                                                                rescale=1.\/255)\n#split test data to validation and tesing \nval_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255,\n                                                              validation_split=0.5)\n\n\n\ntrain_set = train_datagen.flow_from_directory(train_dir, class_mode = 'binary',\n                                              batch_size = 32, \n                                              target_size=(65,65))\n\nval_set = val_datagen.flow_from_directory(val_dir, class_mode = 'binary',\n                                              batch_size = 32, \n                                              target_size=(65,65),\n                                              subset= 'training')\n\ntest_set = val_datagen.flow_from_directory(val_dir, class_mode = 'binary',\n                                              batch_size = 32, \n                                              target_size=(65,65),\n                                              subset= 'validation')","dc652fc7":"def conv_block(inputs, filters):\n    x = tf.keras.layers.Conv2D(filters, 3, padding='same')(inputs)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    x = tf.keras.layers.MaxPool2D()(x)\n    return x","17f17d84":"def create_model():\n    inputs = tf.keras.Input(shape=(65, 65, 3))\n    \n    x = conv_block(inputs, 32)\n    x = conv_block(x, 64)\n    x = conv_block(x, 128)\n    x = conv_block(x, 256)\n\n    \n    x = tf.keras.layers.Flatten()(x)\n    \n    x = tf.keras.layers.Dense(4096, activation = 'relu')(x)\n    x = tf.keras.layers.Dropout(0.5)(x)\n        \n    x = tf.keras.layers.Dense(4096, activation = 'relu')(x)\n    \n    output = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n    \n    func_model = tf.keras.models.Model(inputs = inputs, outputs=output)\n    \n    return func_model","49c80c86":"model = create_model()","331f8c3d":"METRICS = [\n          'accuracy',\n          tf.metrics.TruePositives(name='tp'),\n          tf.metrics.FalsePositives(name='fp'),\n          tf.metrics.TrueNegatives(name='tn'),\n          tf.metrics.FalseNegatives(name='fn'), \n          tf.metrics.Precision(name='precision'),\n          tf.metrics.Recall(name='recall'),\n          \n    ]\nadam = tf.keras.optimizers.Adam()    \nmodel.compile(optimizer = adam, loss ='binary_crossentropy', metrics = METRICS)\nlr_reduce = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.3\n                                                  , patience=5, verbose=2, \n                                                  mode='max')\n\n\nhistory = model.fit(train_set, validation_data = val_set, epochs =30, \n                    callbacks=[lr_reduce])","e593f198":"model.summary()\n","d8299832":"model.evaluate(test_set)\n","5ab75f42":"acc=history.history['accuracy']\nval_acc=history.history['val_accuracy']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n#print(history.history['lr'])\nepochs=range(len(acc)) # Get number of epochs\nrec = history.history['recall']\nper = history.history['precision']\nval_rec = history.history['val_recall']\nval_perc = history.history['val_precision']\n\n\n# Plot training and validation accuracy per epoch\nplt.figure()\n\nplt.plot(epochs, acc, 'r')\nplt.plot(epochs, val_acc, 'b')\nplt.ylabel('Accuracy')\nplt.xlabel('epochs')\nplt.legend(['train', 'val'])\nplt.title('Training and validation accuracy')\n\n\n# Plot training and validation loss per epoch\nplt.figure()\n\nplt.plot(epochs, loss, 'r')\nplt.plot(epochs, val_loss, 'b')\nplt.xlabel('Epochs')\nplt.ylabel('loss')\nplt.legend(['train loss', 'val loss'])\nplt.title('Training and validation loss')","28935473":"define convolutional block","2ef4d2ed":"plots","f17879c9":"create the model","59fde9bb":"Applying data augmanation and resizing data","90122aa3":"compile and fit the data","c1ddcc8c":"Import librarys"}}