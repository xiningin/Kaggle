{"cell_type":{"15b4bebb":"code","3090c56c":"code","868df490":"code","8791a1a2":"code","bca176eb":"code","5b54776d":"code","f626c7bf":"code","c3897587":"code","d9df1b55":"code","b2f254d6":"code","9a029a8e":"code","f065bdb3":"code","2785103d":"code","6dec8546":"code","2adc1948":"code","e161e05e":"code","a7baebe7":"code","f6d2399d":"code","6bb4193f":"code","6657bf58":"code","9ffaf6ba":"code","887d8780":"code","4e7f94fe":"code","05d78af1":"code","aaaede6c":"code","7309ace4":"code","e3ccf5d6":"code","a34dcb08":"code","ae49ac17":"code","5ec302f5":"code","84f4ed24":"code","ea9da67f":"code","b6b88920":"code","03502451":"code","bf7ef081":"code","8039e457":"code","ce88ef93":"code","06e9ff88":"code","e4ef004b":"code","4a106d87":"code","8dab6917":"code","89d6973f":"code","64e46bb5":"code","97faf3e6":"code","f19c8d33":"code","9853a255":"code","28248c61":"code","1c735f67":"code","dc10ea69":"code","6754b180":"code","92996af6":"code","e19af5c5":"code","9ea03f61":"code","6c7b8bf5":"code","7b47bfb8":"code","5c7b744c":"code","c01fba63":"code","593056ee":"code","aec36216":"code","c08f6cae":"code","74b2a80b":"code","6fa8c202":"code","480cfc42":"code","1eee273a":"code","5a8106e2":"code","e3ea87c5":"code","b5b2fde0":"code","4aeb475f":"code","c4f9e7cf":"code","05d6f4a3":"code","470d6846":"code","75dee0ce":"code","f92acef9":"code","6480bebc":"code","7d261824":"code","e2864f2b":"code","b9c7c415":"code","025e229e":"code","ba4ec3c6":"code","7ab8fbb2":"code","036b7ccf":"code","29c530f9":"code","6af06e7f":"code","fbcf7479":"code","a7f68ec6":"code","22b7bb0b":"code","f61318a5":"code","30c0d787":"code","ee9b2be5":"code","37b472f6":"code","687a71e4":"code","fa2cf051":"code","562877d7":"code","b690fc42":"code","c057c3c9":"code","05ba6aab":"markdown","3840c195":"markdown","b22f9d7c":"markdown","2d6d4fab":"markdown","4fab400e":"markdown","3f0c9488":"markdown","73d5b182":"markdown","ccadeeaa":"markdown","250105c7":"markdown","4ba0e331":"markdown","f76ea658":"markdown","4e9e6bb8":"markdown","9924a061":"markdown","40f3adf6":"markdown","a6189cbe":"markdown","a1ed098c":"markdown","cef73f69":"markdown","b6c4e242":"markdown","d130be5a":"markdown","338b21b4":"markdown","f8625872":"markdown","de8c5d13":"markdown","1db4c48b":"markdown","64bb51cf":"markdown","9820b190":"markdown","19b77279":"markdown","f933e8d2":"markdown","de307c24":"markdown","0d048c9b":"markdown","dbd60055":"markdown","10370d5c":"markdown","cbcf91cf":"markdown","2a35991d":"markdown","30260534":"markdown","d5a29426":"markdown","809bec18":"markdown","20d2d60a":"markdown","07331565":"markdown","cbf53226":"markdown","109fe276":"markdown","41f034a5":"markdown","df8731e2":"markdown","7e571a4d":"markdown","af25a519":"markdown","73ec8fd1":"markdown","531e72c4":"markdown","209e1420":"markdown","d6999865":"markdown","bef91b2f":"markdown","c5437992":"markdown","cc6658ac":"markdown","723f4b26":"markdown","c5a746ed":"markdown","e5405805":"markdown","14231efa":"markdown","dad98551":"markdown","cff1adfa":"markdown","d9b98387":"markdown","85423566":"markdown","de912253":"markdown","2696694c":"markdown","955d1443":"markdown","d2392b7e":"markdown","e4c57976":"markdown","5bd076ca":"markdown","c6480109":"markdown","cac8c642":"markdown","512e8968":"markdown","f900dc69":"markdown","bd682f93":"markdown","ec97bcdb":"markdown","c4ed229c":"markdown","2684c636":"markdown","cddfdfff":"markdown","ac2f8576":"markdown","7f93af89":"markdown","1952ad7c":"markdown","c9c2c64e":"markdown","170148e1":"markdown","af109f32":"markdown","ba6ee224":"markdown","9084de34":"markdown","9b27fedd":"markdown","9555be17":"markdown","6bb3f77a":"markdown","863416cb":"markdown"},"source":{"15b4bebb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3090c56c":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\nimport warnings\n# current version of seaborn generates a bunch of warnings that we'll ignore\nwarnings.filterwarnings('ignore')\nsns.set_style('whitegrid')\n\nimport missingno as msno # missing data visualization module for Python\n#import pandas_profiling\n\nimport gc\nimport datetime\n\n%matplotlib inline\ncolor = sns.color_palette()","868df490":"df = pd.read_csv('\/kaggle\/input\/ecommerce-data\/data.csv', header= 0, encoding= 'unicode_escape')","8791a1a2":"df.head()","bca176eb":"df.rename(columns={\"InvoiceNo\":\"invoice_num\", \n                   \"StockCode\":\"stock_code\", \n                  \"Description\":\"description\", \n                  \"Quantity\":\"quantity\", \n                  \"InvoiceDate\":\"invoice_date\", \n                  \"UnitPrice\":\"unit_price\", \n                  \"CustomerID\":\"customer_id\", \n                  \"Country\":\"country\"}, inplace=True)","5b54776d":"df.info()","f626c7bf":"df['invoice_date']=pd.to_datetime(df.invoice_date, format='%m\/%d\/%Y %H:%M')","c3897587":"df['description']=df.description.str.lower()","d9df1b55":"df.head()","b2f254d6":"df.info()","9a029a8e":"df.isnull().sum().sort_values(ascending=False)","f065bdb3":"df_miss=df[df.isnull().any(axis=1)]\ndf_miss.head()","2785103d":"df_miss.head()","6dec8546":"df_miss[\"day\"] = df_miss['invoice_date'].map(lambda x: x.day)\ndf_miss[\"month\"] = df_miss['invoice_date'].map(lambda x: x.month)\ndf_miss[\"year\"] = df_miss['invoice_date'].map(lambda x: x.year)","2adc1948":"df_miss['daymonth']=df_miss['day'].astype(str)+'\/'+df_miss['month'].astype(str)\ndf_miss['daymonthyear']=df_miss['daymonth'].astype(str)+'\/'+df_miss['year'].astype(str)\ndf_miss['monthyear']=df_miss['month'].astype(str)+'\/'+df_miss['year'].astype(str)","e161e05e":"df_miss.head()","a7baebe7":"fig, ax = plt.subplots(figsize=(20,6)) \nax = sns.countplot(x='daymonthyear', data=df_miss)\nax.set_xticklabels(ax.get_xticklabels(),rotation = 90);","f6d2399d":"sns.displot(df_miss['daymonthyear'].value_counts())","6bb4193f":"df_miss['daymonthyear'].value_counts()[:20]","6657bf58":"df_new=df.dropna()","9ffaf6ba":"#check if there a are missing values in the new dataframe\ndf_new.isnull().sum().sort_values(ascending=False)","887d8780":"df_new.info()","4e7f94fe":"df_new[df_new.duplicated()].head()","05d78af1":"df_new.duplicated().sum()","aaaede6c":"df_new.drop_duplicates(inplace=True)","7309ace4":"df_new.duplicated().sum()","e3ccf5d6":"df_new['customer_id']=df_new.customer_id.astype('int64')","a34dcb08":"df_new.describe()","ae49ac17":"np.sum(df_new['quantity'] < 0)","5ec302f5":"canceled_orders = df_new[df_new['invoice_num'].apply(lambda x: x[0]=='C')]\ncanceled_orders.head()","84f4ed24":"(canceled_orders['quantity'] < 0).sum()","ea9da67f":"print('The percentage of canceled orders is: {} %'.format(round(canceled_orders.shape[0]\/df_new.shape[0]*100,2)))","b6b88920":"discounts = df_new[df_new['stock_code'].apply(lambda order: order=='D')]\ndiscounts.head()","03502451":"discounts.shape","bf7ef081":"df[df['stock_code'].apply(lambda order: order=='D')].shape[0]","8039e457":"df_new = df_new[df_new['quantity'] > 0]\ndf_new.sort_values(by='stock_code', ascending=False, inplace=True)\ndf_new.head()","ce88ef93":"df_new.info()","06e9ff88":"import re\nspec_list=[]\nfor code in df_new.stock_code:\n    x=re.findall(r\"^\\w{1}$|\\D[A-Z]+\\D|[A-Z]\\d\", code)\n    if x not in spec_list:\n        if len(x) >0 :\n            spec_list.append(x)\nspec_list","e4ef004b":"spec_list[5] = ['BANK CHARGES']","4a106d87":"spec_list2=[item for sublist in spec_list for item in sublist]\nspec_list2","8dab6917":"df_new[df_new['stock_code'].apply(lambda x: x in spec_list2)]","89d6973f":"df_new = df_new[~df_new['stock_code'].isin(spec_list2)]","64e46bb5":"print(\"The number of transactions is: \", df_new.shape[0])","97faf3e6":"df_new['amount_spent']=df_new['quantity'] * df_new['unit_price']","f19c8d33":"df_new.head()","9853a255":"df_new=df_new[['invoice_num', 'invoice_date', 'stock_code', 'description', 'quantity', 'unit_price', 'amount_spent', 'customer_id', 'country']]","28248c61":"df_new.head()","1c735f67":"df_new.insert(loc=2, column='yearmonth', value=df_new['invoice_date'].map(lambda x: 100 * x.year + x.month))\ndf_new.insert(loc=3, column='month', value=df_new.invoice_date.dt.month)\ndf_new.insert(loc=4, column='day', value=(df_new.invoice_date.dt.dayofweek) + \n              1) # +1 is used to make Monday=1.....until Sunday=7\ndf_new.insert(loc=5, column='hour', value=df_new.invoice_date.dt.hour)","dc10ea69":"df_new.head()","6754b180":"orders=df_new.groupby(by=['customer_id','country'], as_index=False)['invoice_num'].count()\norders.head()","92996af6":"plt.subplots(figsize=(15,6))\nplt.plot(orders.customer_id, orders.invoice_num)\nplt.xlabel('Customer ID')\nplt.ylabel('Number of Orders')\nplt.title('Number of Orders for Different Customers')\nplt.show()","e19af5c5":"orders.sort_values(by='invoice_num', ascending=False).head()","9ea03f61":"money_spent = df_new.groupby(by=['customer_id','country'], as_index=False)['amount_spent'].sum()\nmoney_spent.head()","6c7b8bf5":"plt.subplots(figsize=(15,6))\nplt.plot(money_spent.customer_id, money_spent.amount_spent)\nplt.xlabel('Customers ID')\nplt.ylabel('Money spent (Dollar)')\nplt.title('Money Spent for different Customers')\nplt.show()","7b47bfb8":"money_spent.sort_values(by='amount_spent', ascending=False).head()","5c7b744c":"ax = df_new.groupby('invoice_num')['yearmonth'].unique().value_counts().sort_index().plot(kind='bar',color=color[0],figsize=(15,6))\nax.set_xlabel('Month',fontsize=15)\nax.set_ylabel('Number of Orders',fontsize=15)\nax.set_title('Number of orders for different Months (1st Dec 2010 - 9th Dec 2011)',fontsize=15)\nax.set_xticklabels(('Dec_10','Jan_11','Feb_11','Mar_11','Apr_11','May_11','Jun_11','July_11','Aug_11','Sep_11','Oct_11','Nov_11','Dec_11'), rotation='horizontal', fontsize=13)\nplt.show()","c01fba63":"ax = df_new.groupby('invoice_num')['day'].unique().value_counts().sort_index().plot(kind='bar',color=color[0],figsize=(10,5))\nax.set_xlabel('Day',fontsize=15)\nax.set_ylabel('Number of Orders',fontsize=15)\nax.set_title('Number of orders for different Days',fontsize=15)\nax.set_xticklabels(('Mon','Tue','Wed','Thur','Fri','Sun'), rotation='horizontal', fontsize=15)\nplt.show()","593056ee":"#ax = df_new.groupby('invoice_num')['hour'].unique().value_counts().iloc[:-1].sort_index().plot(kind='bar',color=color[0],figsize=(15,6))\n#ax.set_xlabel('Hour',fontsize=15)\n#ax.set_ylabel('Number of Orders',fontsize=15)\n#ax.set_title('Number of orders for different Hours',fontsize=15)\n#ax.set_xticklabels(range(6,21), rotation='horizontal', fontsize=15)\n#plt.show()","aec36216":"df_new.unit_price.describe()","c08f6cae":"plt.subplots(figsize=(12,6))\nsns.boxplot(df_new.unit_price)\nplt.show()","74b2a80b":"plt.subplots(figsize=(12,6))\nsns.boxplot(df_new[df_new['unit_price'] < 10].unit_price)\nplt.show()","6fa8c202":"df_free=df_new[df_new['unit_price'] == 0]\ndf_free.head()","480cfc42":"df_free.yearmonth.value_counts().sort_index()","1eee273a":"ax = df_free.yearmonth.value_counts().sort_index().plot(kind='bar',figsize=(12,6), color=color[0])\nax.set_xlabel('Month',fontsize=15)\nax.set_ylabel('Frequency',fontsize=15)\nax.set_title('Frequency for different Months (Dec 2010 - Dec 2011)',fontsize=15)\nax.set_xticklabels(('Dec_10','Jan_11','Feb_11','Mar_11','Apr_11','May_11','July_11','Aug_11','Oct_11','Nov_11'), rotation='horizontal', fontsize=13)\nplt.show()","5a8106e2":"group_country_orders = df_new.groupby('country')['invoice_num'].count().sort_values()\n# del group_country_orders['United Kingdom']\n\n# plot number of unique customers in each country (with UK)\nplt.subplots(figsize=(15,8))\ngroup_country_orders.plot(kind='barh', fontsize=12, color=color[0])\nplt.xlabel('Number of Orders', fontsize=12)\nplt.ylabel('Country', fontsize=12)\nplt.title('Number of Orders for different Countries', fontsize=12)\nplt.show()","e3ea87c5":"group_country_orders = df_new.groupby('country')['invoice_num'].count().sort_values()\ndel group_country_orders['United Kingdom']\n\n# plot number of unique customers in each country (without UK)\nplt.subplots(figsize=(15,8))\ngroup_country_orders.plot(kind='barh', fontsize=12, color=color[0])\nplt.xlabel('Number of Orders', fontsize=12)\nplt.ylabel('Country', fontsize=12)\nplt.title('Number of Orders for different Countries', fontsize=12)\nplt.show()","b5b2fde0":"group_country_amount_spent = df_new.groupby('country')['amount_spent'].sum().sort_values()\n# del group_country_orders['United Kingdom']\n\n# plot total money spent by each country (with UK)\nplt.subplots(figsize=(15,8))\ngroup_country_amount_spent.plot(kind='barh', fontsize=12, color=color[0])\nplt.xlabel('Money Spent (Dollar)', fontsize=12)\nplt.ylabel('Country', fontsize=12)\nplt.title('Money Spent by different Countries', fontsize=12)\nplt.show()","4aeb475f":"group_country_amount_spent = df_new.groupby('country')['amount_spent'].sum().sort_values()\ndel group_country_amount_spent['United Kingdom']\n# plot total money spent by each country (without UK)\nplt.subplots(figsize=(15,8))\ngroup_country_amount_spent.plot(kind='barh', fontsize=12, color=color[0])\nplt.xlabel('Money Spent (Dollar)', fontsize=12)\nplt.ylabel('Country', fontsize=12)\nplt.title('Money Spent by different Countries', fontsize=12)\nplt.show()","c4f9e7cf":"df_new.head()","05d6f4a3":"df_new['stock_code'].nunique()","470d6846":"most_sold_products=df_new.groupby(by=['stock_code','description'])['quantity'].sum().sort_values(ascending=False).iloc[:50]\ndf_top_prod=most_sold_products.to_frame().reset_index()\ndf_top_prod.head()","75dee0ce":"plt.subplots(figsize=(15,8))\nmost_sold_products.plot(kind='bar', fontsize=12, color=color[0])\nplt.xlabel('Product ID', fontsize=12)\nplt.ylabel('Amount sold', fontsize=12)\nplt.title('Most sold products', fontsize=12)\nplt.show()","f92acef9":"most_profitable_product = df_new.groupby(by=['stock_code','description'])['amount_spent'].sum().sort_values(ascending=False).iloc[:50]\ndf_prof_prod = most_profitable_product.to_frame().reset_index().head()","6480bebc":"plt.subplots(figsize=(15,8))\nmost_profitable_product.plot(kind='bar', fontsize=12, color=color[0])\nplt.xlabel('Product ID', fontsize=12)\nplt.ylabel('Total earning', fontsize=12)\nplt.title('Most sold products', fontsize=12)\nplt.show()","7d261824":"df_new.reset_index().head()","e2864f2b":"df_3=df_new.drop_duplicates(subset=['stock_code','unit_price','description'])","b9c7c415":"df_3.sort_values(by=['stock_code','quantity'], inplace=True, ascending=False)\ndf_3.head()","025e229e":"import collections\n\nitems_dict = collections.defaultdict(dict)\n\nfor product in df_3.iterrows():\n    items_dict[product[1][6]][product[1][8]]=[product[1][9]][0]","ba4ec3c6":"df_4=pd.DataFrame(list(items_dict.items()),columns = ['stock_code','quantity_price'])\ndf_4.head()","7ab8fbb2":"df_5=df_4[df_4.quantity_price.apply(lambda x: len(x.keys())>1)]\ndf_5.head()","036b7ccf":"price_list=[]\nfor el in df_5.quantity_price:\n    price_list.append(len(el.keys()))\ndf_5['counts']=price_list    \ndf_5=df_5.sort_values(by='counts', ascending=False)","29c530f9":"plt.hist(df_5['counts'], bins=100,color='#0504aa',alpha=0.7, rwidth=0.85)\nplt.xlabel('No of different unit price')\nplt.show()","6af06e7f":"df_5['counts'].value_counts()","fbcf7479":"for i in range(1,10): #check first 10 products ordered by the quantity of different unit prices\n    print('Number: ', i)\n    keys=list(df_5.iloc[i-1:i].quantity_price.values[0].keys())\n    values=list(df_5.iloc[i-1:i].quantity_price.values[0].values())\n    plt.plot(keys, values)\n    plt.show()","a7f68ec6":"#most sold products dataframe\ndf_top_prod.head()","22b7bb0b":"#check the number of transactions related to these top sold products\ndf_top_50 = df_new[df_new['description'].isin(df_top_prod['description'])]\ndf_top_50.info()","f61318a5":"print('The top 50 most old products account for the {} % of the total transactions'.format(np.round(len(df_top_50)\/len(df_new),2)))","30c0d787":"df_top_50.stock_code.value_counts()","ee9b2be5":"df_new[df_new['stock_code'] == '23843']","37b472f6":"#most profitable products\ndf_prof_prod.head()","687a71e4":"df_top_50[df_top_50['stock_code'].isin(df_prof_prod.stock_code)].stock_code.value_counts()","fa2cf051":"df_top1 = df_new[df_new['stock_code'] == '85123A']\ndf_top2 = df_new[df_new['stock_code'] == '22423']\ndf_top3 = df_new[df_new['stock_code'] == '85099B']","562877d7":"# creating a purchase day feature\ndf_top1['order_purchase_date'] = df_top1.invoice_date.dt.date\n\n# creating an aggregation\nsales_per_purch_date = df_top1.groupby('order_purchase_date', as_index=False).quantity.sum()\nax = sns.lineplot(x=\"order_purchase_date\", y=\"quantity\", data=sales_per_purch_date)\nax.set_title('Sales per day for the Most sold product')","b690fc42":"# creating a purchase day feature\ndf_top2['order_purchase_date'] = df_top2.invoice_date.dt.date\n\n# creating an aggregation\nsales_per_purch_date = df_top2.groupby('order_purchase_date', as_index=False).quantity.sum()\nax = sns.lineplot(x=\"order_purchase_date\", y=\"quantity\", data=sales_per_purch_date)\nax.set_title('Sales per day for the Second most sold product')","c057c3c9":"# creating a purchase day feature\ndf_top3['order_purchase_date'] = df_top3.invoice_date.dt.date\n\n# creating an aggregation\nsales_per_purch_date = df_top3.groupby('order_purchase_date', as_index=False).quantity.sum()\nax = sns.lineplot(x=\"order_purchase_date\", y=\"quantity\", data=sales_per_purch_date)\nax.set_title('Sales per day for the Third most sold product')","05ba6aab":"Excuding prodicts with just one unit_price, most of the products has 2 or 3 unit prices.","3840c195":"November looks like the month with most orders","b22f9d7c":"## How many orders per day?","2d6d4fab":"Quantity has negative values and unit price has a minimum value of 0","4fab400e":"## Is there any relationship between the missing data?","3f0c9488":"By analyzing the first 5 values of the dataframe we can see that the quantity has a negative values, is this true for all canceled orders?","73d5b182":"It could be interesting to see how the product with stock code '23843' is in the top 50 with just 1 transaction","ccadeeaa":"### How many free items are sold on each month?","250105c7":"## How much money spent by the customers?","4ba0e331":"How many orders for each country?","f76ea658":"## Missing data analysis and handling","4e9e6bb8":"It looks like Thursday is the day with most orders","9924a061":"## Which products are the most sold?","40f3adf6":"The presence of special items will be checked through a regex","a6189cbe":"Moreover, it looks like there are some discounts among the canceled orders. They will be analyzed as well.","a1ed098c":"## Change columns type","cef73f69":"# Discover Patterns","b6c4e242":"### Canceled orders analysis","d130be5a":"Now it is possible to check all the transactions related to these special items:","338b21b4":"## How many orders by the customers?","f8625872":"There are so other types of transactions included in the dataset. They will be dropped.<br>\nThe special transations are: POST ( postage), M ( manual), Bank charges and C2 ( carriage)","de8c5d13":"On average, we see that the companies give 2 items for free each month. No free items were given on June 2011 and Sept 2011","1db4c48b":"## Check for transactions of special items:","64bb51cf":"## How much money spent by each country?","9820b190":"This plot looks messy, but its clear that during some days there have been more missing values than others.<br>\nIn particular the days with most missing values are:","19b77279":"The top 5 most profitable products with a number of transaction higher than 1000, have the 'stock code' : 85123A, 22423, 85099B","f933e8d2":"## Data format cleaning","de307c24":"It could be interesting to check if during these days something happend and caused the missing values.","0d048c9b":"The portion of dataframe where some values are missing is the following:","dbd60055":"Next, the 'customer_id' column will be converted to 'int' from 'float' since customersID are integer numbers.","10370d5c":"We will plot the number of order by customer_id","cbcf91cf":"### Check the items with mutiple price per unit","2a35991d":"The company issued 77 discounts","30260534":"# Sold product Analysis","d5a29426":"In this dataframe the quantity is the sum of all the sold quantites for each products. We need all tha single transactions related to these top psold products.","809bec18":"The following project is about the analysis of a transnational data set which contains all the transactions occurring between 01\/12\/2010 and 09\/12\/2011 for a UK-based and registered non-store online retail. <br>\nThe company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.\"\nThe aim is to extract useful insights about the customers of the online stores.","20d2d60a":"We can see that during some days, more than 2500 customers_id are missing. We will now check the days where most cusomers id are missing.","07331565":"# Time series analysis for top sold products","cbf53226":"## How does the price change in relation to the purchased quantity?","109fe276":"# E-COMMERCE company analysis","41f034a5":"### The TOP 5 most highest money spent","df8731e2":"Now the dataframe does not have any missing values","7e571a4d":"# Feature Engineering","af25a519":"These plots do not show a clear pattern in the data. It could be interesting to try to predict the future sales.","73ec8fd1":"# Discover Patterns for each Country","531e72c4":"# Exploratory Data Analysis (EDA)","209e1420":"Excluding the United Kingdom, Germany, France and EIRE are the two countries where customers spent the most money.","d6999865":"There are orders with 0 unit price (free items)","bef91b2f":"Now, all the canceled orders will be dropped.","c5437992":"We will add a column 'Amount spent'","cc6658ac":"We will reorder the columns for easier reference","723f4b26":"['BANK ', 'CHARGES'] will be renamed into ['BANK CHARGES']:","c5a746ed":"The column related to the transaction date will be converted from 'object' (a simple string basically) to the very convenient date format \"date-time\" in pandas.","e5405805":"For further analysis, the rows with missing values will be dropped and a new df called 'df_new' will be defined","14231efa":"# Data Cleaning","dad98551":"To simplify the further analysis, the columns will be renamed as follows:","cff1adfa":"Now the dataset looks cleaner and is ready for EDA","d9b98387":"There are 8872 transactions with negative quantity. We will investigate if they are related to canceled orders or mistakes.","85423566":"## How much does the price per unit relate to quantity?","de912253":"There are 3659 different sold products in the dataset","2696694c":"Yes, as expetcted all the transactions with negative values are canceled orders.","955d1443":"## Discounts","d2392b7e":"The column invoice_num has the count of invoice_num for each customer<br>\nThe equivalent code in SQL would be:<br>\nSELECT customer_id, country, count(invoice_num)<br>\nFROM df_new<br>\nGROUP BY customer_id, country<br>\nORDER BY customer_id;<br>","e4c57976":"### There are indeed lots of transactions related to these top sold products","5bd076ca":"Excluding the UK, customers from the Netherlands, EIRE, Germany, France and Australia spent the most money on the website.","c6480109":"No, all the discounts are correctly included in the transactions with negative values","cac8c642":"392732-391183=1549 elements have been dropped","512e8968":"### TOP 5 profitable products","f900dc69":"Then, the spec_list will be transformed into into a single list:","bd682f93":"Are there other discounts in the original dataset?","ec97bcdb":"There are some null values for description and customer id.<br>\nIn particular the exact number of missing values in each column is:","c4ed229c":"These plots shows that generally the unit price decresases with increasing quantity with some exceptions.","2684c636":"There are indeed some peaks in quantity sold for these product.","cddfdfff":"For similar reason as above, we will exclude UK for this analysis.","ac2f8576":"Moreover, the description column will be converter into lower case.","7f93af89":"### I will create a dictionary of dictionaries to include the unit price and quantities for each item","1952ad7c":"# Discover Patterns for Unit Price","c9c2c64e":"Number of orders for different Months (1st Dec 2010 - 9th Dec 2011)","170148e1":"## Duplicated Values handling","af109f32":"There are 5225 duplicated transactions<br>\nThese transaction will be dropped from the dataset.","ba6ee224":"We will create columns for day, month, year","9084de34":"# Most profitable products","9b27fedd":"### The TOP 5 most number of orders is:","9555be17":"The company is based in UK, so it seems natural that the country with most sold items is UK.<br>\nFor further analysis, UK will be dropped","6bb3f77a":"This transaction is related to the most sold product.","863416cb":"It looks like the majority of products have unit_price lower than 10. We will use 10 as a threshold value to deeper explore the unit_price."}}