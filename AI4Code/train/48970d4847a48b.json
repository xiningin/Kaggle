{"cell_type":{"d7092c8f":"code","9d6717b3":"code","0e153041":"code","ec5a4a75":"code","600f0e1d":"code","a11f4463":"code","16996cfa":"code","034664d9":"code","1181241b":"code","c38fa33d":"code","8882971b":"code","95a7439b":"code","c6ad30c7":"code","59147a2e":"code","2c0c283a":"code","f64fa218":"code","e3cad8c4":"code","5667d51f":"code","b29fba8c":"markdown","02dd6abc":"markdown","c78019a9":"markdown","8f72c472":"markdown","32cd8641":"markdown","cbfd8802":"markdown"},"source":{"d7092c8f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport keras.layers as layers\nfrom sklearn.model_selection import train_test_split\nimport random\nimport tensorflow_probability as tfp\nimport tensorflow_addons as tfa","9d6717b3":"from tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom keras import backend as K\n\nbatch_size= 32\nimage_size = [256, 256]\n\n\nds = image_dataset_from_directory(\n    '..\/input\/screwanomalies-detection\/screw\/train',\n    labels=None,\n    image_size=image_size,\n    interpolation='nearest',\n    batch_size=batch_size,\n    shuffle=True,\n)\n\ndef convert_to_float(image):\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    return image\n\n\ndef trans1(img):\n    return tfa.image.rotate(tf.image.flip_left_right(tf.image.flip_up_down(img)),-.2,fill_mode=\"reflect\",interpolation=\"bilinear\")\n\ndef trans2(img):\n    return tfa.image.rotate(img,-.2,fill_mode=\"reflect\",interpolation=\"bilinear\")\n\ndef trans3(img):\n    return tfa.image.rotate(img,.2,fill_mode=\"reflect\",interpolation=\"bilinear\")\n    \nds1,ds2,ds3,ds4 = ds,ds.map(trans2),ds.map(trans3),ds.map(trans1)\n\nds = ds1#.concatenate(ds2).concatenate(ds3)#.concatenate(ds4)\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nds = (\n    ds\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)","0e153041":"ds_a = image_dataset_from_directory(\n    '..\/input\/screwanomalies-detection\/screw\/test\/scratch_neck',\n    labels=None,\n    image_size=image_size,\n    interpolation='nearest',\n    batch_size=batch_size,\n    shuffle=True,\n)\nprint(type(ds))\n\ndef convert_to_float(image):\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    return image\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nds_a = (\n    ds_a\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)","ec5a4a75":"# custom invert gradiant for last layers decoder\n\n\n@tf.custom_gradient\ndef grad_reverse(x):\n    y = tf.identity(x)\n    def custom_grad(dy):\n        return - 1* dy\n    return y, custom_grad","600f0e1d":"a,b = image_size\nshape=(a, b,3)\n\n\nencoder_inputs = keras.Input(shape=shape)\nx = layers.Conv2D(32, 4, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\nx = layers.GaussianNoise(stddev=15)(x)\nx = layers.MaxPooling2D(2)(x)\nx = layers.BatchNormalization()(x)\nx = layers.Dropout(.2)(x)\n\nx = layers.Conv2D(64, 4, activation=\"relu\", strides=2, padding=\"same\")(x)\nx = layers.MaxPooling2D(2)(x)\nx = layers.BatchNormalization()(x)\nx = layers.Dropout(.2)(x)\n\nx = layers.Conv2D(65, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n\n\nencoder = keras.Model(encoder_inputs, x, name=\"encoder\")\nencoder.summary()","a11f4463":"a,b,c,d = x.shape\nlatent_inputs = keras.Input(shape=(b,c,d))\n\nx = layers.Conv2DTranspose(256, 3, activation=\"relu\", strides=1, padding=\"same\")(latent_inputs)\nx = layers.BatchNormalization()(x)\nx = layers.UpSampling2D(2)(x)\nx = layers.Dropout(.2)(x)\n\nx = layers.Conv2DTranspose(128, 5, activation=\"relu\", strides=2, padding=\"same\")(x)\nx = layers.BatchNormalization()(x)\n#x = layers.UpSampling2D(2)(x)\nx = layers.Dropout(.2)(x)\n\nx = layers.Conv2DTranspose(64, 9, activation=\"relu\", strides=4, padding=\"same\")(x)\nx = layers.BatchNormalization()(x)\n\nx = layers.Conv2D(32, 5, activation=\"relu\", strides=1, padding=\"same\")(x)\ndecoder_outputs = layers.Conv2D(3, 5, activation=\"sigmoid\", padding=\"same\")(x)\ndecoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\ndecoder.summary()","16996cfa":"discriminator_inputs = keras.Input(shape=shape)\n\nx = layers.Conv2D(32, 4, activation=\"relu\", strides=2, padding=\"same\")(discriminator_inputs)\nx = layers.MaxPooling2D(2)(x)\nx = layers.BatchNormalization()(x)\nx = layers.Dropout(.2)(x)\n\nx = layers.Conv2D(64, 4, activation=\"relu\", strides=2, padding=\"same\")(x)\nx = layers.MaxPooling2D(2)(x)\nx = layers.BatchNormalization()(x)\nx = layers.Dropout(.2)(x)\nx = layers.Flatten()(x)\nx = layers.Dense(128,activation=\"relu\")(x)\nx = layers.Dropout(.2)(x)\nx = layers.Dense(128,activation=\"relu\")(x)\ndiscriminator_outputs = layers.Dense(1,activation=\"sigmoid\")(x)\ndiscriminator = keras.Model(discriminator_inputs, discriminator_outputs, name=\"discriminator\")\ndiscriminator.summary()","034664d9":"class AE(keras.Model):\n    def __init__(self, encoder, decoder, **kwargs):\n        super(AE, self).__init__(**kwargs)\n        self.encoder = encoder\n        self.decoder = decoder\n        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n        self.reconstruction_loss_tracker = keras.metrics.Mean(\n            name=\"reconstruction_loss\"\n        )\n        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n        \n        \n    def call(self,x):\n        z = self.encoder(x)\n        reconstruction = self.decoder(z)\n        return z,reconstruction\n\n    \n    @property\n    def metrics(self):\n        return [\n            self.total_loss_tracker,\n            self.reconstruction_loss_tracker,\n            self.kl_loss_tracker,\n        ]\n\n    def train_step(self, data):\n        with tf.GradientTape() as tape:\n            z = self.encoder(data)\n            \n            reconstruction = self.decoder(z_inv_grad)\n            reconstruction_loss = tf.reduce_mean(tf.reduce_sum(keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)))\n\n            \n            total_loss = reconstruction_loss\n        grads = tape.gradient(total_loss, self.trainable_weights)\n        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n        self.total_loss_tracker.update_state(total_loss)\n        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n        return {\n            \"loss\": self.total_loss_tracker.result(),\n            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n        }","1181241b":"from keras import backend as K\nclass AE_GAN(keras.Model):    \n\n    def __init__(self, encoder,decoder, discriminator, opti_vae=keras.optimizers.Adam(), opti_disc=keras.optimizers.Adam(), opti3=keras.optimizers.Adam(), **kwargs):\n        super(AE_GAN, self).__init__(**kwargs)\n        \n        self.encoder = encoder\n        self.decoder = decoder\n        self.discriminator = discriminator\n        \n        self.ae_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n        self.correlation_loss_tracker = keras.metrics.Mean(name=\"cr_loss\")\n        self.disc_loss_tracker = keras.metrics.Mean(name=\"disc_loss\")\n        self.gen_loss_tracker = keras.metrics.Mean(name=\"gen_loss\")\n        self.disc_loss = keras.losses.BinaryCrossentropy()\n        \n        self.ae_optimizer = opti_vae\n        self.gen_optimizer = opti3\n        self.disc_optimizer = opti_disc\n        \n    def call(self,x):\n        z = self.encoder(x)\n        reconstruction = self.decoder(z)\n        return z,reconstruction\n\n    @property\n    def metrics(self):\n        return [\n            self.ae_loss_tracker,\n            self.reconstruction_loss_tracker,\n            self.kl_loss_tracker,\n            self.correlation_loss_tracker,\n            self.disc_loss_tracker,\n            self.gen_loss_tracker\n        ]\n\n    def train_step(self, data):        \n        batch_size = K.shape(data)[0]    \n        \n        with tf.GradientTape() as enc_tape, tf.GradientTape() as dec_tape, tf.GradientTape() as disc_tape:\n            \n            z = self.encoder(data)\n            reconstruction = self.decoder(z)\n            \n            reconstruction_loss = tf.reduce_mean(\n            tf.reduce_sum(keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)))\n            \n            \n            # GAN\n            #batch_size = 12\n            #recon_vect = z#tf.random.normal((batch_size, latent_dim))\n            contruction = reconstruction\n            combined_images = tf.concat([data, contruction], axis=0)\n            data_l,recon_l = tf.zeros((batch_size, 1)),tf.ones((batch_size, 1))\n            combined_l = tf.concat([data_l, recon_l], axis=0)\n            tot_predictions = self.discriminator(combined_images)\n            r_prediction = self.discriminator(contruction)\n\n            discr_loss = self.disc_loss(combined_l,tot_predictions)\n            #fake labels : \n            #gen_loss =  self.disc_loss(recon_l,r_prediction)\n            gen_loss = tf.math.maximum(self.disc_loss(data_l,r_prediction) - discr_loss,.0001)\n        \n            #=========\n            ae_loss = reconstruction_loss  + gen_loss #+.1*coorelation_loss \n\n        grad_ae = enc_tape.gradient(ae_loss, self.encoder.trainable_weights+self.decoder.trainable_weights)       \n        grad_discr = disc_tape.gradient(discr_loss, self.discriminator.trainable_weights)\n        #grad_gen = dec_tape.gradient(gen_loss, self.decoder.trainable_weights)\n        \n        \n        #self.gen_optimizer.apply_gradients(zip(grad_gen, self.decoder.trainable_weights))\n        \n        self.ae_optimizer.apply_gradients(zip(grad_ae,self.encoder.trainable_weights+self.decoder.trainable_weights))\n        self.disc_optimizer.apply_gradients(zip(grad_discr, self.discriminator.trainable_weights))\n\n                                           \n        self.ae_loss_tracker.update_state(ae_loss)\n        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n        self.disc_loss_tracker.update_state(discr_loss)\n        self.gen_loss_tracker.update_state(gen_loss)\n        \n        return {\n            \"vae_loss\": self.ae_loss_tracker.result(),\n            \"disc_loss\": self.disc_loss_tracker.result(),\n            \"gen_los\": self.gen_loss_tracker.result(),\n        }","c38fa33d":"def get_lr_callback(epoch,lr):\n    lr_start   = 0.00001\n    lr_max     = 0.005#0.00000125 * 1 * batch_size\n    lr_min     = 0.0001\n    lr_ramp_ep = 10\n    lr_sus_ep  = 2\n    lr_decay   = 0.9\n    cycle = 5\n    \n    def lrfn(epoch):\n        if epoch < lr_ramp_ep: lr = (lr_max - lr_start) \/ lr_ramp_ep * epoch + lr_start\n        elif epoch < lr_ramp_ep + lr_sus_ep: lr = lr_max\n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n        return lr\n    \n    return lrfn(epoch)\n\nlr_callback = tf.keras.callbacks.LearningRateScheduler(get_lr_callback, verbose=True)\nx = [x for x in range(150)]\nplt.plot(x,[get_lr_callback(x,.1) for x in x])\nplt.show()","8882971b":"model = AE_GAN(encoder,decoder, discriminator,opti_vae=keras.optimizers.Adam(), opti_disc=keras.optimizers.Adam())\nmodel.compile()","95a7439b":"history = model.fit(ds, epochs=250,verbose=1,callbacks=[lr_callback])","c6ad30c7":"import pandas as pd\nhistory_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['vae_loss']].plot()","59147a2e":"def diff(a,b):\n    img = abs(a-b)\n    treshhold = .2\n    img = layers.Activation(\"relu\")(img-treshhold)\n    #m,M = tf.reduce_min(img),tf.reduce_max(img)\n    #norm = (img-m)\/(M-m)\n    return layers.Activation(\"relu\")(img)*255","2c0c283a":"digit_size, _ = image_size\nn = 4\nfigure = np.zeros((digit_size*3, digit_size * n,3))\nimg = list(ds)[0]\n\nfor i in range(n):\n    _,b_img = model(img)\n    a = list(b_img)[i]\n    figure[\n                 0*digit_size :  digit_size,\n                i * digit_size :  (i+1)* digit_size,\n            ] = list(img)[i]\n    figure[\n                 1*digit_size :  2*digit_size,\n                i * digit_size :  (i+1)* digit_size,\n            ] = a\n    \n    figure[\n                 2*digit_size :  3*digit_size,\n                i * digit_size :  (i+1)* digit_size,\n            ] = diff(a,list(img)[i])\n\n\nfigsize = 5   \nplt.figure(figsize=(figsize*n, figsize*3))\nplt.imshow(figure)\nplt.show()","f64fa218":"n = 3\n\nfigure = np.zeros((digit_size*3, digit_size * n,3))\nimg = list(ds_a)[0]\nfor i in range(n):\n    _,b_img = model(img)\n    a = list(b_img)[i]\n    figure[\n                 0*digit_size :  digit_size,\n                i * digit_size :  (i+1)* digit_size,\n            ] = list(img)[i]\n    figure[\n                 1*digit_size :  2*digit_size,\n                i * digit_size :  (i+1)* digit_size,\n            ] = a\n    \n    figure[\n                 2*digit_size :  3*digit_size,\n                i * digit_size :  (i+1)* digit_size,\n            ] = diff(a,list(img)[i])\n\nfigsize = 10  \nplt.figure(figsize=(figsize*n, figsize*3))\nplt.imshow(figure)\nplt.show()","e3cad8c4":"import seaborn as sns\ni = 0\n_,b_img = model(img)\na = list(b_img)[i]\nim = diff(a,list(img)[i])\nim  = tf.math.reduce_mean(im,2)\nf, ax = plt.subplots(figsize=(6, 5))\nf = sns.heatmap(im)","5667d51f":"i = 2\n_,b_img = model(img)\na = list(b_img)[i]\nim = diff(a,list(img)[i])\nim  = tf.math.reduce_mean(im,2)\nf, ax = plt.subplots(figsize=(6, 5))\nf = sns.heatmap(im)","b29fba8c":"#  **Results Analyse**","02dd6abc":"# **Data Augmentation**","c78019a9":"# **Training**","8f72c472":"# On training set","32cd8641":"# **Making my model**","cbfd8802":"# On test set"}}