{"cell_type":{"5eb6f9ff":"code","e9d3e0f7":"code","62037cad":"code","f052ab99":"code","47933ba6":"code","e237ebb2":"code","776556be":"code","72c78c3e":"code","b8ecfe49":"code","847ee99a":"code","f77aaca2":"code","562f2e20":"code","8e85acf4":"code","2fb4544d":"code","3fd14134":"code","bf14dc28":"code","ec226839":"code","2f7f8576":"code","86b8b0c2":"markdown","e970a420":"markdown","bd695b67":"markdown","b9fc85b9":"markdown","a8ca7b41":"markdown","e9acf4e3":"markdown","b53d086c":"markdown","5ff83ee9":"markdown","00671453":"markdown","b32ffd0a":"markdown","f70546ab":"markdown","3d428e47":"markdown","1f1deb64":"markdown","d9270719":"markdown"},"source":{"5eb6f9ff":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e9d3e0f7":"df = pd.read_csv(\"\/kaggle\/input\/ecommerce-data\/data.csv\" , encoding = \"ISO-8859-1\")\nprint(df)\n\n\n\n\n\n","62037cad":"print (\"Rows     : \" ,df.shape[0])\nprint (\"Columns  : \" ,df.shape[1])\nprint (\"\\nFeatures : \\n\" ,df.columns.tolist())\nprint (\"\\nMissing values :  \", df.isnull().sum().values.sum())\nprint (\"\\nUnique values :  \\n\",df.nunique())","f052ab99":"df.dropna(inplace=True)","47933ba6":"print (\"Rows     : \" ,df.shape[0])\nprint (\"Columns  : \" ,df.shape[1])\nprint (\"\\nFeatures : \\n\" ,df.columns.tolist())\nprint (\"\\nMissing values :  \", df.isnull().sum().values.sum())\nprint (\"\\nUnique values :  \\n\",df.nunique())","e237ebb2":"df_Country=df.groupby('Country').count()\ndf_country = df_Country.sort_values('InvoiceNo', ascending=[False])\n\ndf_country1 = df_country.drop(df_country[df_country.InvoiceNo < 1000].index)\ndf_country2= df_country1[['InvoiceNo']]\nprint(df_country)","776556be":"df_country2.plot.bar(figsize=(10,8))\n#plt.title(label='Countrywise_sales(Top-10 Country)',\n       #  fontsize='20',\n        # color='green')\n#plt.ylabel('sales')","72c78c3e":"df_2=df_Country\ndf_2\ndf_2=df_2.drop('United Kingdom')\ndf_2 = df_2.sort_values('InvoiceNo', ascending=[False])\ndf_2=df_2[['InvoiceNo']]\ndf_2.plot.bar(figsize=(20,10))","b8ecfe49":"df.InvoiceDate = pd.to_datetime(df.InvoiceDate) \ndf.info()","847ee99a":"df['new_date'] = [d.date() for d in df['InvoiceDate']] # to separate date and time from invoice date and create columns for it\ndf['new_time'] = [d.time() for d in df['InvoiceDate']]\ndf.new_date = pd.to_datetime(df.new_date)\ndf['year'] = df['new_date'].dt.year\ndf['month'] = df['new_date'].dt.month\ndf['date'] = df['new_date'].dt.day\ndf['hour'] = df['InvoiceDate'].dt.hour\ndf[\"period\"] = df[\"year\"].astype(str) + df[\"month\"].astype(str)\nprint(df)\n","f77aaca2":"df_monthwise=df.groupby('period').count()\ndf_period = df_monthwise.sort_values('period', ascending=[True])\ndf_period=df_period[['InvoiceNo']]","562f2e20":"df_period=df_period.plot.bar(figsize=(20,10))\ndf_period.set_xticklabels(['Dec-2010','jan-2011','oct-2011','nov-2011','dec-2011','feb-2011','march-2011','april-2011','may-2011','june-2011','july-2011','aug-2011','sept-2011'])\n#plt.title(label='monthwise sales from 1-dec-2010 to 09-dec-2011',\n #        fontsize='25',\n  #       color='green')","8e85acf4":"df_date=df.groupby('date').count()\ndf2=df_date['InvoiceNo']\ndf_daywise=df2.plot.bar(figsize=(20,10))","2fb4544d":"df_hour=df.groupby('hour').count()\ndf9=df_hour[\"InvoiceNo\"]\ndf_timewise=df9.plot.bar(figsize=(10,5))","3fd14134":"df.loc[df[['Quantity']].idxmax()]","bf14dc28":"df_stock=df.groupby('StockCode').count()\nrslt_df = df_stock.sort_values(by = 'Quantity', ascending = False) \nrslt_df.reset_index()\nrslt_df1 = rslt_df.drop(rslt_df[rslt_df.InvoiceNo < 20].index)","ec226839":"df9=rslt_df1[\"InvoiceNo\"]\ndf10=df9.head(20)\ndf_stock=df10.plot.bar(figsize=(15,10))","2f7f8576":"df1=df.loc[(df.StockCode == '85132A'), ['StockCode','Description']]\ndf2=df.loc[(df.StockCode == '22423'), ['StockCode','Description']]\ndf3=df.loc[(df.StockCode == '85099B'), ['StockCode','Description']]\ndf4=df.loc[(df.StockCode == '84879'), ['StockCode','Description']]\ndf5=df.loc[(df.StockCode == '47566'), ['StockCode','Description']]\nprint(df1.head(1))\nprint(df2.head(1))\nprint(df3.head(1))\nprint(df4.head(1))\nprint(df5.head(1))","86b8b0c2":"## <span style='font-family:\"Times New Roman\"'><span style='color:black'>__Overall, we consider that the company receives the highest number of orders in November 2011 since we do not have the full month of data for December 2011.__\n ","e970a420":"  ##  <span style='font-family:\"Times New Roman\"'> <span styel=''><span style='color:black'> Our data have some missing values. Lets drop missing values. Now the question arises what is the need of removing data.Missing data can reduce the statistical power of a study and can produce biased estimates, leading to invalid conclusions.","bd695b67":"### * As the company is UK Based , around __89%__ of sales occurs in __United Kingdom__ only\n### * Maximum sales happened at november-2011 as we dont have complete data for december-2011\n### * Maximum sales happens in first week of each month\n### *  In terms of hours, there are no transactions after 8:00pm until the next day at 6:00am.\n### *  Besides, we notice that the company receives the highest number of orders at 12:00pm. One of the reasons could be due to the fact that most customers make purchases during lunch hour between 12:00pm \u2014 2:00pm.\n### * CHARLIE + LOLA BISCUITS TINS is the most saled product \n","b9fc85b9":"#    <span style='font-family:\"Times New Roman\"'> <span styel=''><span style='color:red'> __EXPLORATORY DATA ANALYSIS OF E-COMMERCE DATA__","a8ca7b41":"## <span style='font-family:\"Times New Roman\"'><span style='color:black'> Lets add some more columns in our data for further analysis","e9acf4e3":"## <span style='font-family:\"Times New Roman\"'><span style='color:black'> Now we have added some columns like date ,month ,year in our data","b53d086c":"##   <span style='font-family:\"Times New Roman\"'> <span styel=''><span style='color:black'> Now we have successfully loaded our data.Lets check for the missing values of data.\n   ","5ff83ee9":" ##   <span style='font-family:\"Times New Roman\"'> <span styel=''><span style='color:black'> Now we have dropped missing values. Lest start analysis ","00671453":"<img src=https:\/\/miro.medium.com\/max\/540\/1*Ipr4zoMxipIzZEE4S0hleQ.jpeg width=\"350\">","b32ffd0a":"## <span style='font-family:\"Times New Roman\"'><span style='color:green'> In terms of hours, there are no transactions after 8:00pm until the next day at 6:00am.\n## <span style='font-family:\"Times New Roman\"'><span style='color:green'> Besides, we notice that the company receives the highest number of orders at 12:00pm. One of the reasons could be due to the fact that most customers make purchases during lunch hour between 12:00pm \u2014 2:00pm.\n","f70546ab":"## <span style='font-family:\"Times New Roman\"'> <span styel=''><span style='color:black'>__As the company is uk based so maximum sales happens in united kingdom only. for comparison in other countries , for our simplicity lets drop row for united kingdom and compare sales in   other countries__\n","3d428e47":"## <span style='font-family:\"Times New Roman\"'><span style='color:black'> __from this graph we can observe that after united kingdom top five countries with maximum sales are Germany. France , EIRE ,Spain , Netherland respectively__","1f1deb64":"## <span style='font-family:\"Times New Roman\"'><span style='color:black'> __Maximum sales happen on 5th to 8th of each month.And sales decreases on last week of month__\n## <span style='font-family:\"Times New Roman\"'><span style='color:black'>  __One of the reason for this is salary of most of the peoples happens at first week of month__    ","d9270719":"# <span style='font-family:\"Times New Roman\"'> <span styel=''><span style='color:red'> __CONCLUSION:__"}}