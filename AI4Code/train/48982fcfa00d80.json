{"cell_type":{"6a244f7a":"code","4cdb29f4":"code","ae763884":"code","167bab9d":"code","90575d03":"code","0670f991":"code","16068077":"code","a899b68f":"code","9e4ec509":"code","cf0e760a":"code","100b9613":"code","122566c1":"code","db2a2566":"code","fb4526da":"code","f4ef0e7b":"code","53da215b":"code","50c88584":"code","b235de3b":"code","3952d548":"code","4144a51c":"code","41992586":"code","68ae2872":"code","82d26e9c":"code","8f4da4f3":"code","da815a77":"code","50677b7e":"code","52b68792":"code","e9ddc3d5":"code","7967b9b3":"code","bf6fcdfc":"code","0b0a1be7":"code","77167f07":"code","df670b4a":"code","9ad876a0":"code","55ae6b6f":"code","58b36975":"code","81d2af69":"code","ce176011":"code","35c108b8":"code","7bc193d4":"code","3967ac34":"markdown","ec1d9141":"markdown","bbe36a17":"markdown","278a9cb2":"markdown","0310b8c3":"markdown","04c31d7e":"markdown","d7843f69":"markdown","60b7d105":"markdown","794e6c75":"markdown","77386812":"markdown","086486ce":"markdown","f81844f2":"markdown","a681903b":"markdown","9dea17ee":"markdown","f472a2fc":"markdown","58d04832":"markdown","9e8071f2":"markdown","72c3035b":"markdown","9f9609a8":"markdown","e3fd7020":"markdown","320741db":"markdown","72b3edbf":"markdown","89f1d8c2":"markdown","7ea7b392":"markdown","e3427d04":"markdown","a8c1d5b1":"markdown","707266ed":"markdown","b0c3a49a":"markdown","392b55ad":"markdown"},"source":{"6a244f7a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4cdb29f4":"import pandas as pd\npd.set_option('max_columns', 100)\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport re\nfrom collections import Counter\nfrom wordcloud import WordCloud\nfrom datetime import datetime\nimport nltk\nfrom nltk.corpus import stopwords","ae763884":"df = pd.read_csv('..\/input\/amazon-top-50-bestselling-books-2009-2019\/bestsellers with categories.csv')\ndf.head()","167bab9d":"df.tail()","90575d03":"df.info()","0670f991":"df = df.drop_duplicates(subset = ['Name'])\ndf.tail()","16068077":"df.isnull().sum()","a899b68f":"df.describe()","9e4ec509":"df[df['Price'] == 0]","cf0e760a":"df = df[df['Price'] != 0]","100b9613":"fig = plt.figure(figsize = (15,5))\n\nfig.add_subplot(1,3,1)\nsns.distplot(df['Price'])\n\nfig.add_subplot(1,3,2)\nsns.distplot(np.log1p(df['Price']))\nplt.xlabel('log1p(price)')\n\nfig.add_subplot(1,3,3)\nsns.distplot(np.log(df['Price']))\nplt.xlabel('log(price)')\n\nplt.tight_layout()\nplt.show()","122566c1":"df['log(price)'] = np.log1p(df['Price'])","db2a2566":"def preprocess(rows):\n    title = str(rows).lower()\n    title = re.sub(\"[^a-zA-Z_]\", ' ', title)\n    #title = re.sub('[+-\\\/|]', ' ', title)\n    #title = re.sub('[!#\\\"~*)(,.:;?]', ' ', title)\n    #title = \"\".join(re.findall('[a-zA-Z0-9\\s]', title))\n    return title\n\ndf['process_name'] = df['Name'].apply(preprocess)\ndf['process_name'].head()","fb4526da":"df['name_character_length'] = df['process_name'].apply(lambda x : len(x.strip()))\ndf['name_word_length'] = df['process_name'].apply(lambda x : len(x.split(' ')))","f4ef0e7b":"fig = plt.figure(figsize = (15,10))\n\nfig.add_subplot(3,2,1)\nsns.distplot(df['name_character_length'])\nplt.title('Distribution of character length in name')\n\nfig.add_subplot(3,2,2)\nsns.distplot(df['name_word_length'])\nplt.title('Distribution of word length in name')\n\n\nfig.add_subplot(3,2,3)\nsns.scatterplot(df['name_character_length'], df['Price'])\n\nfig.add_subplot(3,2,4)\nsns.scatterplot(df['name_word_length'], df['Price'])\n\nfig.add_subplot(3,2,5)\nsns.scatterplot(df['name_character_length'], df['log(price)'])\n\n\nfig.add_subplot(3,2,6)\nsns.scatterplot(df['name_word_length'], df['log(price)'])\n\nplt.tight_layout()\nplt.show()\n","53da215b":"name_words = []\nenglish_stopwords = stopwords.words('english')\n#english_stopwords.append('book', 'books')\nfor element in df['process_name'].values:\n    name_words.extend(element.split(' '))\n\nname_words = [word for word in name_words if word not in english_stopwords]","50c88584":"print(\"Total no of words : \", len(name_words))\nprint(\"Total unique words : \", len(set(name_words)))","b235de3b":"name_reqs = {i[0] : i[1] for i in Counter(name_words).most_common(100)}\nplt.figure(figsize = (20,20))\nwordcloud = WordCloud(width=800,height=600,min_font_size=10, background_color = 'white').generate_from_frequencies(name_reqs)\nplt.imshow(wordcloud)\nplt.tight_layout()","3952d548":"list_word = Counter(name_words).most_common(30)\ndf_words = pd.DataFrame(list_word, columns = ['word', 'frequency'])\ndf_words = df_words.drop(df.index[0])\ndf_words.head()","4144a51c":"temp_df = df[['process_name', 'Price', 'log(price)']]","41992586":"words_list = df_words.word.values.tolist()\nfor word in words_list:\n    temp_df[word] = temp_df['process_name'].apply(lambda x : 1 if word in x else 0)\n    \ntemp_df.head()","68ae2872":"words = dict()\nwords['word'] = []\nwords['mean_price'] = []\nwords['median_price'] = []\n\nfor word in words_list:\n    words['word'].append(word)\n    words['mean_price'].append(temp_df[temp_df[word] == 1]['Price'].mean())\n    words['median_price'].append(temp_df[temp_df[word] == 1]['Price'].median())\n    ","82d26e9c":"words = pd.DataFrame(words)","8f4da4f3":"fig = plt.figure(figsize = (15, 10))\n\nfig.add_subplot(2,1,1)\nsns.barplot(words['word'], words['mean_price'], label = \"average price of the books with words\", order = words['word'])\nplt.axhline(df['Price'].mean(), linestyle = \":\", label = \"average mean price of all the books\")\nplt.xticks(rotation = 45)\nplt.title(\"Plot showing average price of books with most frequent words\")\nplt.legend()\n\nfig.add_subplot(2,1,2)\nsns.barplot(words['word'], words['median_price'], label = \"median price of the books with words\")\nplt.axhline(df['Price'].median(), linestyle = \":\", label = \"median mean price of all the books\")\nplt.xticks(rotation = 45)\nplt.title(\"Plot showing Median price of books with most frequent words\")\nplt.legend()\n\nplt.tight_layout()\nplt.show()","da815a77":"plt.figure(figsize = (15, 5))\nsns.distplot(df['log(price)'], label = \"Price distribution of overall dataset\")\nsns.distplot(np.log1p(words['mean_price']), label = \"Average Price distribution records with frequent words\")\nsns.distplot(np.log1p(words['median_price']), label = \"Median Price distribution of records with frequent words\")\nplt.legend()\nplt.grid(linestyle = \":\")\nplt.xlabel(\"Price Distribution\")\nplt.title(\"Price Distribution of books having top 30 most frequent words in name vs Overall data\")\nplt.show()","50677b7e":"df_author = df[['Author', 'Price']]\n\nauthors = dict()\nauthors['author'] = []\nauthors['mean_price'] = []\n\nfor n in df_author['Author'].unique().tolist():\n    authors['author'].append(n)\n    authors['mean_price'].append(df_author[df_author['Author'] == n]['Price'].mean())","52b68792":"authors = pd.DataFrame(authors)\nauthors = authors.sort_values('mean_price', ascending = False).reset_index(drop = True)","e9ddc3d5":"plt.figure(figsize =(100,100))\nsns.barplot(authors['author'], authors['mean_price'], label = 'mean price for each author')\nplt.axhline(df['Price'].mean(), label = 'overall mean price')\nplt.axhline(df['Price'].median(), label = 'overall median price')\nplt.xticks(rotation = 90)\nplt.title('Average price of books sold by each author')\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n","7967b9b3":"authors.iloc[0:10,]","bf6fcdfc":"fig = plt.figure(figsize = (15,5))\nsns.distplot(df['User Rating'])\nplt.title('Distribution of user ratings')\nplt.tight_layout()\nplt.show()","0b0a1be7":"fig = plt.figure(figsize = (15,5))\n\nfig.add_subplot(2,1,1)\nsns.scatterplot(df['User Rating'], df['Price'])\nplt.title('price against user rating')\n\nfig.add_subplot(2,1,2)\nsns.scatterplot(np.log1p(df['User Rating']), np.log1p(df['Price']))\nplt.title('log(price) against log(user rating)')\n\nplt.tight_layout()","77167f07":"fig = plt.figure(figsize = (15,5))\nsns.distplot(df['Reviews'])\nplt.title('Distribution of reviews')\nplt.tight_layout()\nplt.show()","df670b4a":"fig = plt.figure(figsize = (15,5))\n\nfig.add_subplot(2,1,1)\nsns.scatterplot(df['Reviews'], df['Price'])\nplt.title('price against reviews')\n\nfig.add_subplot(2,1,2)\nsns.scatterplot(np.log1p(df['Reviews']), np.log1p(df['Price']))\nplt.title('log(price) against log(reviews)')\n\nplt.tight_layout()","9ad876a0":"plt.figure(figsize = (15,5))\nplt.pie(df['Genre'].value_counts(), labels = ['Non Fiction', 'Fiction'], autopct=\"%.1f%%\")\nplt.title('distribution of genres')\nplt.tight_layout()\n","55ae6b6f":"genre = df.groupby('Genre')['Reviews'].agg(['count', 'mean', 'median'])\ngenre","58b36975":"fig = plt.figure(figsize = (15,5))\n\nfig.add_subplot(1,2,1)\nsns.barplot(y= 'mean' , x= genre.index, data=genre)\nplt.title('mean reviews across genres')\n\nfig.add_subplot(1,2,2)\nsns.barplot(y= 'median' , x= genre.index, data=genre)\nplt.title('median reviews across genres')\n\nplt.tight_layout()\n\n\n#how to combine using seaborn? send help","81d2af69":"fig = plt.figure(figsize = (15, 5))\n\nfig.add_subplot(1,2,1)\nsns.boxplot(x = df['Genre'], y = df['Reviews'])\n\nfig.add_subplot(1,2,2)\nsns.violinplot(x = df['Genre'], y = df['Reviews'])\n\nplt.tight_layout()","ce176011":"#plt.figure(figsize = (15, 10))\npivot = pd.pivot_table(df, index =('Year','Genre'), aggfunc = np.mean)\npivot\n#sns.heatmap(pivot, annot = True, fmt = 'g')\n#plt.xticks(labels = ['Non Fiction', 'Fiction'])\n#plt.show()","35c108b8":"pivot = pd.pivot_table(df, index = 'Year', columns = 'Genre', values = 'Price' )\npivot","7bc193d4":"plt.figure(figsize = (15,5))\nsns.heatmap(pivot, annot = True)\nplt.tight_layout()","3967ac34":"In this section, I attempted to use a pivot table for the first time. Indexing by year and genre, we can get the average of each other features. ","ec1d9141":"# Data Visualisation ","bbe36a17":"# Loading Data","278a9cb2":"I added log(price) into our dataframe.","0310b8c3":"Using 'values' = price would give you the price for each data point. ","04c31d7e":"Again, there seem to be no relationship between reviews and price as seen from the scatter plot. Is there any way to draw relationships? Am i doing this wrong?","d7843f69":"**Name**","60b7d105":"**Year**","794e6c75":"Firstly, I needed to clean the titles. Then, we are able to obtain character length and word length. ","77386812":"**Genre**","086486ce":"Most titles have around 25 characters and about a total of 5 words. I attempted to visualise the relationship between price and words. However, as seen from the scatterplot, there seems to be no clear relationship.","f81844f2":"Using a describe function can catch some anomalies from the very start. Look at the minimum price for some books. They are basically free and those are anomalies. ","a681903b":"We can also use groupby functions to split genres and count the number of reviews each genre has. ","9dea17ee":"Price seems to increase with rating. But it may not be conclusive as data is also cluttered at higher ratings. ","f472a2fc":"From the distribution above, there is no clear relationship that price is affected by the words used. ","58d04832":"The visualisations above shows you the average price of the book containing the most frequent words. Books that have different editions are more expensive on average. Perhaps because the books are textbooks (usually many editions printed) which are usually already more expensive. ","9e8071f2":"# Data cleaning","72c3035b":"There are only 2 main genres. Fiction and non-fiction. There are more non-fiction books than fiction books in this dataset.","9f9609a8":"Books that are unpriced should be removed from the data set. ","e3fd7020":"**User Rating**","320741db":"# Importing the right libraries\n","72b3edbf":"It is also possible to better visualise a pivot table through a heatmap which i thought was pretty cool. ","89f1d8c2":"**Reviews**","7ea7b392":"**Author**","e3427d04":"I plotted a total of three distributions of price. As seen from the first plot, the distribution is skewed. Therefore, i used a log function to create a more even distribution as seen from the second and third plot. ","a8c1d5b1":"I decided to remove books that are of the same title but published in a different year. ","707266ed":"From the wordcloud, you could see the most common words. ","b0c3a49a":"**Price**","392b55ad":"There seems to be no missing data in this dataset. "}}