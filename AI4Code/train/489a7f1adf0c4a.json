{"cell_type":{"60c01e37":"code","672cbe0f":"code","85d34905":"code","e1e922d4":"code","0ed73b7c":"code","1e2b9698":"code","7e237c1f":"code","6c8c06c8":"code","12973b0d":"code","a64a7da1":"code","1f33cca0":"code","b4b219f0":"code","085a7826":"code","b05f56b5":"code","ef86335c":"code","325737b7":"code","e0032259":"code","ede0fe3e":"code","178cca02":"code","afb11e15":"code","ac466bbc":"code","fce12c4b":"code","315f8369":"code","3449e72a":"code","8518f1cd":"code","2b0eaf3e":"code","30450cf4":"code","895e04ab":"code","cb061cf3":"code","eea7058e":"markdown","96386057":"markdown","8680b92a":"markdown","10dbccfe":"markdown"},"source":{"60c01e37":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","672cbe0f":"TRAIN_PATH = '..\/input\/titanic\/train.csv'\nTEST_PATH = '..\/input\/titanic\/test.csv'\nLABELS_COL = 'Survived'","85d34905":"train = pd.read_csv(TRAIN_PATH)\ntrain.head(5)","e1e922d4":"train.info()","0ed73b7c":"train['Cabin'].value_counts()\ntrain['Cabin'].isna().sum() # Create a category of for unkown cabin.","1e2b9698":"train['Age'].isna().sum() # Fill by average age.","7e237c1f":"train['Embarked'].value_counts()\ntrain['Embarked'].isna().sum() # Fill by most frequent.","6c8c06c8":"train.describe()","12973b0d":"labels = train[LABELS_COL]\nprint('Length of training set is {}'.format(len(labels)))","a64a7da1":"X_train, X_test, y_train, y_test = train_test_split(train, labels, test_size=0.2, random_state=42)","1f33cca0":"class SqueezeDataset(BaseEstimator, TransformerMixin):\n    def __init__(self, columns):\n        self.dummy_cols = columns\n    \n    def fit(self, X, y=None):\n        return self # nothing else to do\n    \n    def transform(self, X, y=None):\n        X = X.drop(self.dummy_cols, axis=1)\n        return X\n    \n    \nclass FillNas(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        self.age_col = 'Age'\n        self.cabin_col = 'Cabin'\n        self.embarked_col = 'Embarked'\n    \n    def fit(self, X, y=None):\n        return self # nothing else to do\n    \n    def transform(self, X, y=None):\n        age_mean = X[self.age_col].mean()\n        X[self.age_col].fillna(age_mean, inplace=True)\n        \n        unique_cabins = list(set(X[self.cabin_col]))\n        X[self.cabin_col] = [unique_cabins.index(c) for c in X[self.cabin_col]]\n        \n        most_frequent_embarking = X[self.embarked_col].value_counts()[0]\n        X[self.embarked_col].fillna(most_frequent_embarking, inplace=True)\n        \n        unique_embarking = list(set(X[self.embarked_col]))\n        X[self.embarked_col] = [unique_embarking.index(e) for e in X[self.embarked_col]]\n        \n        return X\n    \nclass Binarize(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        self.gender_col = 'Sex'\n        \n    def fit(self, X, y=None):\n        return self # nothing else to do\n        \n    def transform(self, X, y=None):\n        X[self.gender_col] = [1 if s == 'male' else 0 for s in X[self.gender_col]]\n        return X","b4b219f0":"data_pipline = Pipeline([\n    ('squeeze', SqueezeDataset([LABELS_COL, 'Name', 'Ticket', 'Fare', 'PassengerId'])),\n    ('fillnas', FillNas()),\n    ('binarize', Binarize()),\n    ('scale', StandardScaler())\n])","085a7826":"preprocesed_training_set = data_pipline.fit_transform(X_train)\npreprocesed_training_set","b05f56b5":"preprocesed_training_set.shape","ef86335c":"logistic_classifier = LogisticRegression(random_state=0, solver='lbfgs')\nnaive_b_classifer = GaussianNB()\nsvm_classifier = SVC(kernel='linear', random_state=0)\nsgd_ckassifier = SGDClassifier()\nknn_classifier = KNeighborsClassifier()\ndecision_tree_classifier = DecisionTreeClassifier()\nrandom_forest_classifier = RandomForestClassifier(n_estimators=200)","325737b7":"models = [logistic_classifier, naive_b_classifer, svm_classifier, sgd_ckassifier, knn_classifier, decision_tree_classifier, random_forest_classifier]\nconfusion_matrices = []\naccuracies = []\ntest_set = data_pipline.fit_transform(X_test)\nfor i, m in enumerate(models):\n    m.fit(preprocesed_training_set, y_train)\n    y_pred = m.predict(test_set)\n    cm = confusion_matrix(y_test, y_pred)\n    confusion_matrices.append(cm)\n    ac = accuracy_score(y_test, y_pred)\n    accuracies.append(ac)","e0032259":"accuracies","ede0fe3e":"test = pd.read_csv(TEST_PATH)","178cca02":"test.info()","afb11e15":"test_pipeline = Pipeline([\n    ('squeeze', SqueezeDataset(['Name', 'Ticket', 'Fare', 'PassengerId'])),\n    ('fillnas', FillNas()),\n    ('binarize', Binarize()),\n    ('scale', StandardScaler())\n])\npreproced_test_data = test_pipeline.fit_transform(test)","ac466bbc":"predictions = random_forest_classifier.predict(preproced_test_data)\npredictions.shape","fce12c4b":"Columns = ['PassengerId', 'Survived']\nrows = [[r['PassengerId'], predictions[i-1]] for i, r in test.iterrows()]\npredictions_df = pd.DataFrame(np.array(rows), columns=Columns)\npredictions_df.to_csv(index=False)","315f8369":"import tensorflow as tf","3449e72a":"activation_fn='elu'","8518f1cd":"model = tf.keras.Sequential([\n    tf.keras.layers.Dense(64, input_shape=(7,),activation=activation_fn),\n    tf.keras.layers.Dense(32, activation=activation_fn),\n    tf.keras.layers.Dense(16, activation=activation_fn),\n    tf.keras.layers.Dense(8, activation=activation_fn),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.compile(optimizer='Adam', loss=tf.keras.losses.binary_crossentropy, metrics=['accuracy'])","2b0eaf3e":"model.fit(preprocesed_training_set, y_train, epochs=10)","30450cf4":"tf_predictions = model.predict(preproced_test_data)\ntf_predictions = [1 if p>0.5 else 0 for p in tf_predictions]","895e04ab":"tf_predictions","cb061cf3":"Columns = ['PassengerId', 'Survived']\nrows = [[r['PassengerId'], tf_predictions[i-1]] for i, r in test.iterrows()]\npredictions_df = pd.DataFrame(np.array(rows), columns=Columns)\npredictions_df.to_csv(index=False)","eea7058e":"## Data preprocessing pipelines using custom transformers in scikit learn\n* Remove unneccesary columns\n* Fill unknowns\n* Convert strings to numbers\n* Normalize the data","96386057":"## With Neural Nets","8680b92a":"## Preprocess test data set","10dbccfe":"## Classification problem.\nSince this problem is about finding whether a person will live or die in ship wrek. Basically it is a binary clasification (0 or 1, yes or no).\nWe have set of algorithms which does that, we will start from those algorithms.\n#### Available Algorithms\n* Logistic regression\n* Naive Bayes\n* Stochastic Gradient Descent\n* KNN\n* SVM\n* Decission tress\n* Random Forest\n* Nueral Nets\n"}}