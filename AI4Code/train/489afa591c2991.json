{"cell_type":{"2ee005eb":"code","e3e09451":"code","4c8a9ddc":"code","007f8210":"code","9f4ce0c2":"code","8eadf4bf":"markdown","3baaf8f7":"markdown","a414fdd4":"markdown","19edcac5":"markdown","4c2e8d5c":"markdown"},"source":{"2ee005eb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e3e09451":"train = pd.read_csv('..\/input\/ventilator-pressure-prediction\/train.csv',index_col='id')\ntest  = pd.read_csv('..\/input\/ventilator-pressure-prediction\/test.csv', index_col='id')\n\n# breathing patterns blocks are 80 rows long \n# this function computes the average pattern for a feature\ndef compute_mean(df,feature):\n    return np.reshape(np.array(df[feature]),(-1,80)).mean(axis=0) \n\n","4c8a9ddc":"# let's compute the average target pattern \np_mean = compute_mean(train,'pressure')\n\n# repeat the pattern by the number of breathing patterns in the train file \np_mean_tile = np.tile(p_mean,(1,train.shape[0]\/\/80)).transpose()\n\n# create a new column in train with the average breathing pattern\ntrain['p_mean'] = p_mean_tile\nprint(f'train set MAE for average pattern: {np.mean(np.abs(np.array(train[\"pressure\"])-np.array(train[\"p_mean\"]))):.3f}')\n","007f8210":"p_mean_tile = np.tile(p_mean,(1,test.shape[0]\/\/80)).transpose()\ntest['pressure'] = p_mean_tile\n\n# produce the submission file\ntest['pressure'].to_csv('submission_average.csv',header=True)","9f4ce0c2":"# indices in which u_out = 0.\nu_out_idx = train[train['u_out']==0].index\n\nprint(f'train set MAE for average pattern (restricted to u_out=0): {np.mean(np.abs(np.array(train.iloc[u_out_idx][\"pressure\"])-np.array(train.iloc[u_out_idx][\"p_mean\"]))):.3f}')","8eadf4bf":"# 4. Let's fix the scoring estimation\nLet's recompute the MAE taking u_out into account.","3baaf8f7":"# 0. Looking for an EDA?\nCheck this [EDA](https:\/\/www.kaggle.com\/carlmcbrideellis\/ventilator-pressure-eda-and-simple-submission) EDA by [Ellis](https:\/\/www.kaggle.com\/carlmcbrideellis) \n\n# 1. Motivation\n\nI wrote this notebook for some simple sanity checks and an easy and simple baseline solution. The idea was to compute the **average of all breathing patterns** and then compute the MAE against the target in the train set. After that, submit the same average pattern to compare against the MAE on the public score. ","a414fdd4":"# 5. Result\nNow we get **MAE=6.575**, which is closer to the **public score** of **6.358** for this simple averaging solution.","19edcac5":"# 2. Submit!\nWe got an expected MAE of 3.141. Okay, now let's make a submission file!","4c2e8d5c":"# 3. Something is not right...\nTo my surprise the **public score** was **6.358**, which is hugely different from the above **estimation** of **3.141**. I wondered what was the issue. Could the train and test sets be rather different? Unlikely. After reading Ellis EDA it became clear.\nThe scoring is only performed in part of the breathing patterns. More specifically, scoring happens when the feature u_out is 0. When u_out is 1, the breathing \"pressure\" is close to zero. This makes the overall MAE smaller when the entire breathing pattern is included."}}