{"cell_type":{"62af3bf3":"code","01bb5924":"code","5a739507":"code","484271a3":"code","3bd849a7":"code","a52ce238":"code","6484df1b":"code","ab186a55":"code","b9df6a25":"code","31f2d193":"code","f66adeac":"code","a8412a46":"code","b8930a80":"code","14c0990b":"code","5b7e2384":"code","602ff6cb":"code","cd92f6ad":"code","dfca7b59":"code","b3dc13b0":"code","a61e436d":"code","047c023c":"markdown","f01f9bc0":"markdown","b8bdc1e8":"markdown","af5ca8b9":"markdown","94c7a3fb":"markdown","d763f64c":"markdown","35962693":"markdown","5ce83c81":"markdown","a108029c":"markdown","e2e83ec3":"markdown","921158b4":"markdown","b71479b1":"markdown","87d6d45f":"markdown","8ee8aa20":"markdown","544ed12e":"markdown","5228563c":"markdown","d8ffb7fe":"markdown","56c71cab":"markdown","f5896b69":"markdown","212538ed":"markdown","1d8bb256":"markdown","74478fbc":"markdown","040a19a8":"markdown","2c62690e":"markdown"},"source":{"62af3bf3":"import numpy as np # linear algebra\nimport matplotlib.pyplot as plt # to make plots\nplt.rcParams.update({'font.size': 14}) # to change plots' font size\n\nimport seaborn as sns # statistical data visualization\nimport pandas as pd # data processing, I\/O csv using pd.read_csv()\nimport warnings\nwarnings.filterwarnings(\"ignore\") # hide warnings","01bb5924":"df = pd.read_csv('..\/input\/transactions-from-a-bakery\/BreadBasket_DMS.csv') # importing csv file\ndf.head() # showing first five entries","5a739507":"df.duplicated().value_counts()","484271a3":"df.info()","3bd849a7":"df['Item'].value_counts().sort_values(ascending=False).to_frame()","a52ce238":"sums = df['Item'].value_counts().sum()\nprint(f'Total number of item is {sums}')","6484df1b":"df['Item'].value_counts().sort_values(ascending=False).to_frame().head(10)","ab186a55":"df = df[ df['Item'] != 'NONE' ] # deleting entries with 'Item' == 'NONE'","b9df6a25":"df['Item'].value_counts().sort_values(ascending=False).to_frame().head(10)","31f2d193":"Item_count = df['Item'].value_counts()\nother = Item_count[Item_count <= 379 ] # Brownie count is 379\ndf['Item'] = df['Item'].replace(other.index, 'Others')\n\ndel Item_count\n\ndf['Item'].value_counts().sort_values(ascending=False).to_frame().head(10)","f66adeac":"df['Date'] = df['Date'].astype('datetime64[ns]')","a8412a46":"fig = df['Item'].value_counts(normalize=True).sort_values().to_frame().plot(kind='barh',\n                                                              title='Normalized top 10 most-selling items',\n                                                             grid=True, legend=False)","b8930a80":"other.head(4).div(sums).to_frame().plot(kind='barh', title='Normalized top 4 items in Others', grid=True, legend=False)\nplt.gca().invert_yaxis()","14c0990b":"transaction_time_series = df['Date'].value_counts().to_frame().sort_index()\nfig = transaction_time_series.plot(kind='line', legend=False, title='Number of Transactions by Date',\n                                  ylabel='Transactions')\nfig.set_xlim(pd.Timestamp('2016-10-30'), pd.Timestamp('2017-04-09'))\nfig.set_ylim(0, 300)\nplt.show()","5b7e2384":"transaction_time_series_weekdays = transaction_time_series [ transaction_time_series.index.dayofweek.isin([0,1,2,3,4]) ]\ntransaction_time_series_weekdays = transaction_time_series_weekdays.reset_index()\nfig = transaction_time_series_weekdays['Date'].plot(kind='line', legend=False, title='Weekdays Transactions by day',\n                                  ylabel='Transactions')\nfig.set_xlim(0, 112)\nfig.set_ylim(0, 300)\nplt.show()","602ff6cb":"transaction_time_series['Days'] = transaction_time_series.index.dayofweek\ntransaction_per_day = transaction_time_series.set_index('Days')\ntransaction_per_day = transaction_per_day.rename(columns={'Date':'Transaction'})\ntransaction_per_day = transaction_per_day.reset_index()\nfig = transaction_per_day.boxplot(by='Days', column=['Transaction'])\nplt.title('')\nplt.xticks([1,2,3,4,5,6,7], ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\nplt.ylabel('Transactions')\nplt.show()","cd92f6ad":"import matplotlib.colors as colors\nimport matplotlib.dates as mdates\ntimehist = pd.to_datetime(df['Time'],format=\"%H:%M:%S\")\nfig, ax = plt.subplots(1,1)\n#create histogram, get bin position for label\nN, bins, patches = ax.hist(timehist, bins = 11, facecolor='blue')\n# Setting color\nfracs = ((N**(1 \/ 5)) \/ N.max())\nnorm = colors.Normalize(fracs.min(), fracs.max())\n \nfor thisfrac, thispatch in zip(fracs, patches):\n    color = plt.cm.RdBu(norm(thisfrac))\n    thispatch.set_facecolor(color)\n#set xticks at bin edges\nplt.xticks(bins)\nax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H\"))\nax.grid(b = True, color ='grey',\n        linestyle ='-.', linewidth = 0.5,\n        alpha = 0.8)\nplt.xlim(pd.to_datetime(-2208985200, unit='s'), pd.to_datetime(-2208906000, unit='s'))\nplt.title('Transactions by time of the day')\nplt.ylabel('Transactions')\nplt.xlabel('Hour')\nplt.show()","dfca7b59":"count_transaction = df.groupby(['Transaction']).cumcount() + 1\ncounts = count_transaction.to_frame().value_counts().to_numpy()\n\nplt.bar(['1','2','3','>3'], [counts[0]-counts[1], counts[1]-counts[2],\n                                  counts[2]-counts[3], counts[3]])\nplt.title('Number of items in one Transaction')\nplt.ylabel('Frequency')\nplt.xlabel('Number of items')\nplt.show()","b3dc13b0":"item_map = {'Coffee':3, 'Bread':2, 'Tea':3,\n           'Cake':2, 'Pastry':2, 'Sandwich':2,\n           'Medialuna':2, 'Hot chocolate':3, 'Cookies':2, 'Others':5}\ndf['mapped'] = df[['Item']].applymap(item_map.get)\ntrans_map = df.groupby('Transaction')['mapped'].prod().value_counts()\n\nlabels = ['1','2','3']\nbeverage_only = np.array([trans_map.loc[3], trans_map.loc[9], trans_map.loc[27]])\nfood_only = np.array([trans_map.loc[2], trans_map.loc[4], trans_map.loc[8]])\nfood_beverage_mixed = np.array([0, trans_map.loc[6], trans_map.loc[12]+trans_map.loc[18]])\nothers_only = np.array([trans_map.loc[5], trans_map.loc[25], trans_map.loc[125]])\nfood_others_mixed = np.array([0, trans_map.loc[10], trans_map.loc[20]+trans_map.loc[50]])\nbeverage_others_mixed = np.array([0, trans_map.loc[15], trans_map.loc[45]+trans_map.loc[75]])\nfood_beverage_others = np.array([0, 0, trans_map.loc[30]])\nwidth = 0.35\n\nplt.figure(figsize=(15,6))\nplt.bar(labels, food_beverage_mixed, width, label='Food & Beverage')\nplt.bar(labels, food_only, width, bottom=food_beverage_mixed, label='Food only')\nplt.bar(labels, beverage_only, width, bottom=food_only+food_beverage_mixed, label='Beverage only')\nplt.bar(labels, food_others_mixed, width, bottom=food_only+food_beverage_mixed+beverage_only,\n        label='Food & Others')\nplt.bar(labels, beverage_others_mixed, width, bottom=food_only+food_beverage_mixed+beverage_only+food_others_mixed,\n        label='Beverage & Others')\nplt.bar(labels, food_beverage_others, width, bottom=food_only+food_beverage_mixed+beverage_only+food_others_mixed+beverage_others_mixed,\n        label='Food & Beverage & Others')\nplt.bar(labels, others_only, width, bottom=food_beverage_others+food_only+food_beverage_mixed+beverage_only+food_others_mixed+beverage_others_mixed,\n        label='Others only')\n\nplt.xlabel('Number of items')\nplt.ylabel('Frequency')\nplt.title('Grouped Items in one Transaction')\nplt.legend()\n\nplt.show()","a61e436d":"from collections import Counter\n\ngroup = []\nfood_beverage_group_pre = []\nfood_beverage_group = []\n\ngroups = df.groupby('Transaction')['Item'].agg(list).to_frame()\nfor i in groups['Item']:\n    member = list(dict.fromkeys(i))\n    group.append(member)\n    \ntrans_group = df.groupby('Transaction')['mapped'].prod()\nfor i in range(len(trans_group)):\n    if trans_group.iloc[i] == 6:\n        food_beverage_group_pre.append(group[i])\n\nfor t in food_beverage_group_pre:\n    t.sort()\n    food_beverage_group.append(', '.join(map(str, t)))\n    \nfood_beverage_occurence = dict(Counter(food_beverage_group))\n\ndel food_beverage_group_pre\ndel food_beverage_group\n\nfood_beverage_occurence = pd.DataFrame.from_dict(food_beverage_occurence, orient='index', columns=['occurence'])\nfood_beverage_occurence.div(trans_map.loc[6]).sort_values('occurence').plot(kind='barh', figsize=(15,6), grid=True)\nplt.title('Food and Beverage for 2 items in one Transaction, Normalized')\nplt.legend(['Occurences in fraction'], loc='lower right')\nplt.show()","047c023c":"## 3. Preprocessing\n\nNext, we are going to:\n- clean values from `Item`, by deleting `NONE` transactions and aggregating all remaining transactions (outside top 10) to `Others`\n- turn the datatype of column `Date` to *datetime64[ns]*","f01f9bc0":"Next, we are going to look for **distinct products that are sold** in this shop, from the most popular product","b8bdc1e8":"It is easier to look at the trend by *looking only to the weekdays*:","af5ca8b9":"### 4.1. Business plan from knowing 10 most selling items\n\nOur normalized top 10 most selling items are shown in the barplot below.\n\nWe can see that`Others` (more than 80 irrelevant items combined) are the most selling items, taking almost one-third of all the transactions. However, it is not easy to determine the specific item that customer will buy at a particular moment. This is because the specific item only contributes less than 2.5% from the total sales.\n\nIn real business situation, we generally want to *avoid overstocking*. In this case, we want to avoid it especially because *quality of food items decrease overtime*.","94c7a3fb":"As stated before, transaction with index 1 and 2 have the same entries. Let's see how many duplicate entries are there","d763f64c":"### 4.6. Business plan from knowing items that are generally bought together\n\nLet's take a closer look for Food \\& Beverage combination when two items are bought at the same time. This is a more detailed view on bottom bar for two items in one transaction from the upper figure.\n\nAs expected, `Bread`-`Coffee` *combination is the most frequent combination of all*. However, it's not preferable to give discount to that particular combination since it will reduce our profit. Generally, *it's better to pair our popular products with less popular ones*. For example, we can see in the figure below that `Bread` (our most popular food) can go quite well with `Tea`, while `Coffee` (our most popular beverage) can go quite well with `Cookies`. Therefore, **it is a viable option to give discounts to Bread-Tea and Coffee-Cookies combination**. This way, as mentioned in **Analysis 4.5.**, we hope to *reduce single-item-purchase in one transaction by encouraging them to spend more on discounted combinations* and get more revenue from the customers.","35962693":"Now, we are going to turn the datatype of column `Date` to *datetime64[ns]* to make it easier to analyze.","5ce83c81":"# Bakery Sales Dataset Analysis","a108029c":"### 4.2. Business plan from knowing trend of total transaction overtime\n\nOur number of transactions per day is shown below.\n\nWe can see that *there are no significant increases nor decreases* in the number of transactions. Since we only have less than 6 months of data, it is also unclear whether these systematic ups and downs happen due to season or not.\n\nThis rather *moderate trend* signifies that our *customers come to our store regularly*, but the *number of customers doesn't increase* either. If this situation happens in our store, it is better to check our marketing methods. It is possible that our **marketing methods were not as effective as it should be and we should focus our resources to reach the market**. For example, we can [develop a first-time customer program](https:\/\/www.webstaurantstore.com\/article\/105\/restaurant-marketing.html) to attract new customers.","e2e83ec3":"For example, let us look at our top 4 items in `Others`:\n\n1. `Brownie`: according to [this source](https:\/\/www.marthastewart.com\/264302\/tips-for-perfect-brownies),\n\n> Store cut brownie squares in an airtight container at room temperature; they're best eaten within 1 to 2 days.\n\nThus, it might be not economical to stock `Brownie`, especially because they are *sold less than 2% of the time*. Another strategy is to stock freshly baked `Brownie` everyday and give it a discount after rush hours end (see **Analysis 4.4.**)\n\n\n2. `Farm House`: according to [this source](https:\/\/www.bloomberg.com\/profile\/company\/0294374D:LN),\n\n> Cornish Farmhouse Frozen Foods Ltd was founded in 1974. The company's line of business includes the wholesale distribution of packaged quick-frozen vegetables, juices, meats, fish, and other deep freeze products.\n\nFrozen foods are known to have long expiration date. And so, though the demand was quite low, it is okay to keep `Farm House` food in stock just in case.\n\n\n3. `Muffin`: according to [this source](https:\/\/www.stilltasty.com\/fooditems\/index\/17741),\n\n> Properly stored, freshly baked muffins will last for about 1 to 2 days at normal room temperature.\n\nThus, it might be better if we can substitute the demand for `Muffin` to other items. Luckily, `Cookie` or `Brownie` can be a good substitute for `Muffin`. Therefore, we can discontinue `Muffin` from the store without losing too many customers.\n\n4. `Juice`: We know that `Farm House` distributes packages of frozen juices. Most fruits can go bad quickly so it is better if we substitute `Juice` by using `Farm House` frozen juices.\n\nWe can continue this analysis for more items in `Others` if we want to","921158b4":"## 2. Overview of the Dataset\n\nOur dataset consists of 21293 columns of transactions from 2016-10-30 to 2017-04-09 with details as follows:\n- `Date`: date of the transaction in *yyyy-mm-dd* format\n- `Time`: time when transaction occurs in *24-hour* format\n- `Transaction`: identifier for single transaction because a transaction can take several entries (buying more than one product in a transaction)\n- `Item`: name of the product that is being sold in particular entry (row)","b71479b1":"We found that there is `NONE` item with 786 transactions. Possibly it is because someone cancelled the order after the data was put on the computer. In the next part, we are going to deal with this item.\n\nNevertheless, we can focus our attention to the **top 10 best-selling products** as our most relevant data","87d6d45f":"By analyzing the dataset [here](https:\/\/www.kaggle.com\/sulmansarwar\/transactions-from-a-bakery), we conclude that the *best business plans* for this bakery are:\n1. We focus on keeping top 9 best-selling products and products with longer lifespan. Items that have shorter lifespan will be discounted after rush hours at 5 p.m.\n2. We will evaluate and generate new marketing plan to attract more segments of customers. One possible marketing strategy is to implement first-time customer program.\n3. We need to prepare more items on Fridays, Sundays, and especially Saturdays. Also, It is better to go with risk-taker approach by preparing more items in the store every day, since we are going to do some serious marketing from now on.\n4. We need to prepare for rush hours from 7 a.m. to 5 p.m., especially 9 a.m. to 3 p.m.\n5. We can optimize our bakery sales by making Food \\& Beverage dicounts, e.g. for Bread-Tea and Coffee-Cookies combination. Also, we should consider making family packages and discounts.","8ee8aa20":"### 4.4. Business plan from knowing the busiest hours in the bakery\n\nHistogram of transactions grouped by time of the day is shown below.\n\nWe can see that most transactions happen between 7 a.m. to 5 p.m. Also, there are few transactions happen after 7 p.m. From this information, we can optimize our work hours. For example, we can **close our store earlier at around 7 p.m. without losing too many customers**.\n\nI also mentioned about giving discounts after rush hours in **Analysis 4.1.** From knowing the transaction hours, we can give discounts to items with shorter expiration dates after the rush hours. It is important to *avoid giving discounts in rush hours* because we might lose some revenue. In this case, we can try **putting discounts for short-lived items** (e.g. `Bread`, `Pastry`, `Brownie`) **after 5 p.m**. This way, we can also attract another type of customers (the *discount hunters*) that usually don't buy items in our store.\n\nLastly, it is important to know that the peak of rush hours happen in around 11 a.m. If our marketing plan from **Analysis 4.2.** succeed, **it is possible that situation in the store around 11 a.m. gets very busy and we might need to hire part-time staffs from 11 a.m. to 3 p.m.**","544ed12e":"## 1. Dataset Context\n\nThis is sales data of a bakery, we can access the data [here](https:\/\/www.kaggle.com\/sulmansarwar\/transactions-from-a-bakery). According to the source, this dataset is:\n\n> The dataset consists of 21293 observations from a bakery. The data file contains four variables, Date, Time, Transaction ID and Item. Transaction ID ranges from 1 through 9684. However, there are some skipped numbers in Transaction IDs. Also, there are duplicated entries, as shown in observation # 2 and \\#3. Besides, the Item contains \"Adjustment\", \"NONE\", and \"Afternoon with the baker\". While the entries of \"Adjustment\" and \"NONE\" are straight forward, \"Afternoon with the baker\" may be a real purchase.\n\nBut first, we need to import relevant packages and the dataset.","5228563c":"## 4. Analysis","d8ffb7fe":"There are two *extreme solutions* to this problem:\n1. We stop buying items in `Others` and give relevant substitutes to our customer from our top 10 items\n2. We maximize our customers' satisfaction by keep buying all items in `Others`\n\nHowever, as you can guess, these two solutions are not the best solution. We need to optimize between these options.\n\nOne way to optimize is by looking at another items in `Others`. For example, take 4 items then consider *their expiration time and adequacy of substitution* from the top 9 items","56c71cab":"We found that there are **95 distinct products** and the total number of item is 21293, with some items only sold once.\n\nSince it is going to be hard to analyze everything, we are going to **focus on the most relevant data, that is the top 10 best-selling products** in the shop","f5896b69":"We managed to delete entries with `NONE`, now we are going to aggregate remaining less popular products starting from `Brownie` into one category, `Others`","212538ed":"For the analysis, we will start from the most general analysis into the more specific ones.\n\nWe will focus on determining the *best business plans* from knowing:\n- top 10 most selling items\n- trend of total transactions overtime\n- comparison of sales between days in the week\n- the busiest hours for the bakery\n- number of items that are bought in a single transaction\n- items that are usually bought together","1d8bb256":"## 5. Conclusion\n\nBy analyzing the dataset, we conclude that the *best business plans* for this bakery are:\n1. We focus on keeping top 9 best-selling products and products with longer lifespan. Items that have shorter lifespan will be discounted after rush hours at 5 p.m.\n2. We will evaluate and generate new marketing plan to attract more segments of customers. One possible marketing strategy is to implement first-time customer program.\n3. We need to prepare more items on Fridays, Sundays, and especially Saturdays. Also, It is better to go with risk-taker approach by preparing more items in the store every day, since we are going to do some serious marketing from now on.\n4. We need to prepare for rush hours from 7 a.m. to 5 p.m., especially 9 a.m. to 3 p.m.\n5. We can optimize our bakery sales by making Food \\& Beverage dicounts, e.g. for Bread-Tea and Coffee-Cookies combination. Also, we should consider making family packages and discounts.","74478fbc":"### 4.3. Business plan from knowing the comparison of transactions between days in the week\n\nBoxplot of transactions grouped by days is shown below.\n\nWe can see that there are no *significant differences between weekdays except for Fridays*. Most likely it happens because Fridays come before weekends and many people spend their money for snacks at Fridays. Therefore, we need to **increase our stock on Fridays compared to other weekdays**.\n\nWeekends are good opportunity to increase our sales because we can see that there are *more transactions per day on Weekends compared to weekdays*. Also, we can see that *Saturdays have the highest average transactions per day* of all. However, we need to take account of the spread for a particular day. For example, although Saturdays have the highest average sales per day, *Saturdays also have the widest spread for transactions per day* of all. **These spread may cause our transactions prediction to be inaccurate and some items left unpurchased**.\n\nThere are, again, two extreme approaches to this problem:\n1. *Cautious approach*: we make a safer choice by **setting items equal to the median**\n2. *Risk taker approach*: we take risks by producing items **more than the median sales by adding a fraction of spread** (measured by interquartile range) on that specific day\n\nSince our bakery will be doing some marketing from now on (from previous **Analysis 4.2.**), it is **generally better to take some risk**.","040a19a8":"**Important assumption**: Since there are so many duplicate entries, We are going to **assume that duplicate entries are two valid entries**. Those two entries mean someone is buying two products of the same type.","2c62690e":"### 4.5. Business plan from knowing number of items bought in single transactions\n\nNumber of items in one transaction and a more detailed stacked barplot is shown below.\n\nWe can see that the most frequent number of items sold in one transaction is one. This is not good for various reasons. The first reason is *we miss the opportunity of getting more revenue from one transaction*, here's why. Generally most people need to eat and drink, so it is quite unusual to buy any food without buying any beverage or vice versa. We can **encourage those people who only buy one item in a transaction to spend more by making food and beverage combination discounts**. That way, we can get more revenue from the same person. However, we need to watch out because *food and beverage combinations are the most popular combination if someone buys two items in one transaction*. We need to manage the amount of discount so we get more revenue in total.\n\nThat *food and beverage combination discount will also be effective for the exact same reason*. Since most of our customers who buy more than one item generally buy food and beverage, **our appropriate promotion should make them more happy and hence increases their loyalty to our store**.\n\nWe can also see that *only a little fraction of our transaction has more than three items*. Generally this means it is **quite unusual for a family to visit our store**. This insight can be used when we are evaluating and thinking about marketing strategies from **Analysis 4.2.** For example, **we can create packages and discounts for families**. That way, we can increase transactions that have more number of items.\n\nCuriously, for two and three items in one transaction, *combination of beverage and others are unexpectedly high*. We remember that we determined `Others` quite arbitrarily by aggregating non-top 9 items. It is quite easy to include more items before aggregating the remaining items into `Others`. However, we will not pursue it any further for now. Just keep in mind that *we can always include more items in our pre-processing steps*."}}