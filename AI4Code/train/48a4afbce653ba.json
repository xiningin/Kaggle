{"cell_type":{"6a2f35b1":"code","d1a0e555":"code","004525a4":"code","5051a903":"code","7dab4846":"code","0701e8b7":"code","6cbcb078":"code","86c62094":"code","e35ae660":"code","a35e65c0":"code","5af67934":"code","20c74f8c":"code","bfd0628a":"code","d747f0b4":"code","344eca4a":"code","ccffc8ae":"code","0ce13b0f":"code","19f520f4":"code","8fbfe37c":"code","3017ee6c":"code","440e53c1":"code","501ff3a0":"code","37cff23f":"code","ba3699b1":"code","f6a4fedd":"code","472858ea":"code","6391a98f":"code","bf220b35":"code","ebe844f8":"code","38b02f0a":"code","549a9b45":"code","7037f4d2":"code","c45bc917":"code","a1ade80b":"code","75ff13b0":"code","83211f0c":"code","c2ae5c82":"markdown","cf8028b8":"markdown","aa8b5ded":"markdown","caa39f5f":"markdown","4f3e4b98":"markdown","b8872359":"markdown","89e5854e":"markdown","30427d0e":"markdown","23e684d4":"markdown","7ec53082":"markdown","ca180b67":"markdown","17b3cece":"markdown","b3acadf8":"markdown","84824f31":"markdown","2541d978":"markdown"},"source":{"6a2f35b1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d1a0e555":"from sklearn import svm # for Discriminator\nfrom sklearn.model_selection import train_test_split # for train-test split \nfrom sklearn.preprocessing import StandardScaler # for feature scaling\nfrom sklearn.model_selection import GridSearchCV # for fine-tuning\nfrom sklearn.metrics import make_scorer, balanced_accuracy_score # for evaluation\nfrom sklearn.pipeline import make_pipeline # for prediction","004525a4":"# for Generator\nfrom scipy import stats # for sampling\nfrom fitter import Fitter # for fitting the best distribution\nimport copy # for copying nested dictionaries","5051a903":"import matplotlib.pyplot as plt  # for visualization \nimport seaborn as sns  # for coloring \n\n# set style of graphs\nplt.style.use('dark_background')\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5","7dab4846":"df = pd.read_csv(\"\/kaggle\/input\/nba-games\/games.csv\")\ndf.head() ","0701e8b7":"# sort dataframe by date\ndf = df.sort_values(by='GAME_DATE_EST').reset_index(drop = True)\n# drop empty entries, data before 2004 contains NaN\ndf = df.loc[df['GAME_DATE_EST'] >= \"2004-01-01\"].reset_index(drop=True)\n# check null\ndf.isnull().values.any() ","6cbcb078":"# replace Team ID with Names\ndf_names = pd.read_csv('\/kaggle\/input\/nba-games\/teams.csv')\ndf_names.head()","86c62094":"# We have two columns to replace, there are 'HOME_TEAM_ID' and 'VISITOR_TEAM_ID'\n\ndf_names = df_names[['TEAM_ID', 'NICKNAME']]\n\n# replace 'HOME_TEAM_ID' with names in df_names\nhome_names = df_names.copy() # copy the names data\nhome_names.columns = ['HOME_TEAM_ID', 'NICKNAME'] # change the column names before merging\n# merge names according to df on \"ID\"\nresult_1 = pd.merge(df['HOME_TEAM_ID'], home_names, how =\"left\", on=\"HOME_TEAM_ID\")  \ndf['HOME_TEAM_ID'] = result_1['NICKNAME']\n\n# replace 'VISITOR_TEAM_ID' with names in df_names\nvisitor_names = df_names.copy() # copy the names data\nvisitor_names.columns = ['VISITOR_TEAM_ID', 'NICKNAME'] # change the column names before merging\n# merge names according to df on \"ID\"\nresult_2 = pd.merge(df['VISITOR_TEAM_ID'], visitor_names, how = \"left\", on=\"VISITOR_TEAM_ID\")\ndf['VISITOR_TEAM_ID'] = result_2['NICKNAME']","e35ae660":"# final dataframe\ndf.head()","a35e65c0":"# we want to try and predict the 2019-2020 NBA play off results starting 2020-08 >\n# hence, this portion of the data is held out\ndf = df.loc[df['GAME_DATE_EST'] < '2020-08-01'].reset_index(drop=True)","5af67934":"feature_list = list(df.columns)\nfeature_list","20c74f8c":"#\u270dTo predict win\/loss of a game, we can use one of the two ways:\n\n#1. Select only one feature (points), the win\/loss prediction is just based on which team has the higher point.\n#2. Select features other than points, the win\/loss is then based on the prediction of a classifier which takes those features as inputs.\n\n# In this notebook, we will use option (2) as it offers better range of uncertainty for simulation.\n\nselected_features = [\n    'FG_PCT_home', 'FT_PCT_home', 'FG3_PCT_home', 'AST_home', 'REB_home',\n    'FG_PCT_away', 'FT_PCT_away', 'FG3_PCT_away', 'AST_away', 'REB_away',\n    ]\n\n# check the features we selected\nX = df[selected_features]\nX.head()","bfd0628a":"# check the targets\ny = df['HOME_TEAM_WINS']\ny.head()","d747f0b4":"# turn them into numpy arrays for training\n\nX = X.to_numpy()\ny = y.to_numpy()","344eca4a":"# train test split\nX_train, X_test, y_train, y_test = train_test_split(\n    X, \n    y, \n    test_size=0.3, random_state=42)\n\nprint(\"X shape\", X_train.shape, \"y shape\", y_train.shape)","ccffc8ae":"# feature scaling\n\nscaler = StandardScaler() # initialize an instance \nX_train = scaler.fit_transform(X_train) ","0ce13b0f":"%%time \n\n# train SVM\n\nclf = svm.SVC(kernel='linear') # initialize a model\nclf.fit(X_train, y_train) # fit(train) it with the training data and targets\n\n# check test score \ny_pred = clf.predict(X_test) \nprint('balanced accuracy score:', balanced_accuracy_score(y_test, y_pred)) ","19f520f4":"%%time \n\n# fine-tuning hyperparameters\n\nscoring = make_scorer(balanced_accuracy_score)\nparam_grid = {'C': [0.1, 1, 10],  \n              'gamma': [1,0.1,0.01]} #\n\ngrid = GridSearchCV(svm.SVC(kernel='linear'), param_grid, scoring = scoring, refit=True, verbose=2) \ngrid.fit(X_train, y_train)","8fbfe37c":"# print the best model's hyperparameters\nDis = grid.best_estimator_\nprint(Dis) ","3017ee6c":"# Like before, we had held out data from 2019-2020 playoff for real testing\n# Though large data is essential for fitting, for time-series problems, we give priority to the recent data most reflective of team's recent ability.\n# Since we aim to predict 2019-2020 playoff, here we will just fit the data from that regular session which starts in Oct, 2019.\n\ndf_ = df.loc[df['GAME_DATE_EST'] > '2019-10-01'].reset_index(drop=True)\ndf_.head()","440e53c1":"# here we define the list of common distributions for fitting\n# use more distributions with fewer data points, because the distribution will be less \"normal\"\n\nselected_distributions = [\n    'norm','t', 'f', 'chi', 'cosine', 'alpha', \n    'beta', 'gamma', 'dgamma', 'dweibull',\n    'maxwell', 'pareto', 'fisk']\n","501ff3a0":"unique_teams = df['HOME_TEAM_ID'].unique() # extract all the unique teams\n\n# Since we don't care about whether the team was a host or visitor in each game, \n# we can just combine the features for all games.\n\n# Get all the data for teams\nall_team_sim_data = {}\n\nfor team_name in unique_teams:\n    \n    # find games where the team is either the host or guest\n    df_team = df_.loc[(df_['HOME_TEAM_ID'] == team_name) | (df_['VISITOR_TEAM_ID'] == team_name)]\n    # it is home team, select the first 5 features\n    df_1 = df_team.loc[df_team['HOME_TEAM_ID'] == team_name][selected_features[:5]]\n    # it is guest team, select the first 5 features\n    df_0 = df_team.loc[df_team['VISITOR_TEAM_ID'] == team_name][selected_features[5:]]\n\n    # combine them\n    df_0.columns = df_1.columns # before concating, match the column names\n    df_s = pd.concat([df_1, df_0], axis = 0)\n    \n    # convert the pandas.DataFrame to numpy array\n    all_team_sim_data[team_name] = df_s.to_numpy()","37cff23f":"%%time\n\n# data format:\n#   team_name => list of feature distributions => distionary with distribution name and parameters\n#   e.g.,\n#   megadata = {\n      #'Timberwolves': [{'beta': (0.23, 0.3, 0.3, 0.4)}, {'nor': (0.23, 0.3,)}, ..], \n      #'Warriors':[{}, {},...]\n      #  }\n    \nmegadata = {} # store the data that our Generator will rely on\nfor team_name in unique_teams:\n    \n    feature_dis_paras = []\n    data = all_team_sim_data[team_name]\n    \n    # 5 features for each team\n    for i in range(5): \n        f = Fitter(data[:, i]) # initalize a Fitter instance\n        f.distributions = selected_distributions # use only the selected distributions (faster)\n        f.fit() # do the fitting \n        best_paras = f.get_best(method='sumsquare_error') # get the best fitted paras\n        feature_dis_paras.append(best_paras)\n        \n    megadata[team_name] = feature_dis_paras\n    \nprint('Features for all teams have been fitted!')","ba3699b1":"\nDATA = megadata.copy() # data that Generator must rely on\n\nGEN = {\n 'alpha': stats.alpha.rvs,\n 'beta': stats.beta.rvs,\n 'chi': stats.chi.rvs,\n 'cosine': stats.cosine.rvs,\n 'dgamma': stats.dgamma.rvs,\n 'dweibull':stats.dweibull.rvs,\n 'f':stats.f.rvs,\n 'fisk':stats.fisk.rvs,\n 'gamma': stats.gamma.rvs,\n 'maxwell':stats.maxwell.rvs,\n 'norm':stats.norm.rvs,\n 'pareto':stats.pareto.rvs,\n 't':stats.t.rvs,\n}","f6a4fedd":"# feature scaler + fine-turned SVM \nDIS = make_pipeline(scaler, Dis)","472858ea":"class Game:\n    \n    '''\n    \n    A game between two teams:\n    \n    - feature values sampled from Generator\n    - win\/loss predicted by Discriminator\n    \n    '''\n    \n    def __init__ (self, random_state = None):\n        \n        self.random_state = random_state # keep this to None for making simulations \n    \n    def predict(self, team1, team2, num_games = 1):\n        \n        ''' predict the win or loss of  n game(s) played by two tems'''\n        \n        assert num_games >= 1, \"at least one game must be played\"\n        # output numpy array\n        team_1_feature_data = DATA[team1]\n        team_2_feature_data = DATA[team2]\n        features = []\n        for feature_paras_1 in team_1_feature_data:\n            sample_1 = self.sampling(feature_paras_1, size = num_games) # gives a list if num_games> 1\n            features.append(sample_1) \n            \n        for feature_paras_2 in team_2_feature_data:\n            sample_2 = self.sampling(feature_paras_2, size = num_games) # gives a list if num_games> 1\n            features.append(sample_2)\n            \n        features = np.array(features).T \n        win_loss = DIS.predict(features)\n        \n        return list(win_loss) # a list of win\/loss from num_games\n    \n    \n    def sampling(self, dic, size = 1, random_state = None):\n        \n        '''generate feature values used for making win\/loss prediction'''\n                        \n        dis_name = list(dic.keys())[0] # get the type\n        paras = list(dic.values())[0] # get the paras\n    \n        # get sample\n        sample = GEN[dis_name](*paras, size = size,  random_state =  random_state)\n            \n        return sample ","6391a98f":"class FinalTournament(Game):\n    \n    ''' Best-of-7 elimination, 16 teams, 4 rounds in total to win championship '''\n    \n    def __init__(self, n_games_per_group = 7, winning_threshold = 4, random_state = None):\n\n        self.n_games_per_group  = n_games_per_group\n        self.winning_threshold = winning_threshold\n        self.team_list = None\n        self.rounds = {} # keep track the number of times a team wins at each round \n        super().__init__(random_state)\n        \n    \n    def simulate(self, group_list, n_simulation = 1, probs = True):\n        \n        ''' simulate the entire playoff n times and also record the accumulated wins'''\n             \n        # update the list of teams\n        self.rounds = {}\n        self.team_list = [i[0] for i in group_list] + [i[1] for i in group_list]\n        \n        for i in range(n_simulation):\n            cham = self.one_time_simu(group_list)\n        if probs:\n            self.rounds_probs =  self._compute_probs()\n            \n    \n    def one_time_simu(self, group_list, verbose = False, probs = False):\n        \n        ''' simulate the entire playoff once and also record the accumulated wins'''\n        \n        # update the list of teams if haven't done so\n        if self.team_list == None: \n            self.team_list = [i[0] for i in group_list] + [i[1] for i in group_list]\n        round_number, done = 0, 0\n        while not done: \n            all_group_winners, group_list = self.play_round(group_list)\n            # retrive round stats\n            try:\n                updated_round_stats = self.rounds[round_number]\n            except KeyError:\n                updated_round_stats = {}\n                for team in self.team_list:\n                    updated_round_stats[team] = 0\n            # if a team wins, record + 1 \n            for winner in all_group_winners:\n                try: \n                    updated_round_stats[winner] += 1\n                except KeyError:\n                    pass     \n            self.rounds[round_number] = updated_round_stats\n            if verbose:\n                print('{} round played'.format(round_number))\n            if probs:\n                self.rounds_probs = self._compute_probs()\n            if type(group_list) != list: # if it becomes the final\n                done = 1\n            round_number += 1\n            \n        return group_list\n\n        \n    def play_round(self, group_list):\n        \n        '''play a round of games based of a list of paired teams'''\n        \n        all_group_winners = [] \n        # play each group and get the group winner\n        for group in group_list:\n            winner = self.play_n_games(group[0], group[1])\n            all_group_winners.append(winner)\n        \n        if len(all_group_winners) > 1:\n            new_group_list = []         \n            for index in range(0, len(all_group_winners), 2):\n                # first winner, second winner\n                new_group = [all_group_winners[index], all_group_winners[index + 1]]\n                new_group_list.append(new_group)\n                \n            return all_group_winners, new_group_list\n        else:  \n            return all_group_winners, winner\n        \n        \n    def play_n_games(self, team1, team2):\n        \n        '''simulate data, and then use our classifier to predict win\/loss'''\n        \n        result = Game().predict(team1, team2, self.n_games_per_group)\n        if sum(result[:4]) == self.winning_threshold or sum(result) >= self.winning_threshold:\n            winner = team1 # home team wins\n        else:\n            winner = team2 # visitor team wins\n            \n        return winner\n    \n    \n    def _compute_probs(self):\n        \n        '''prob = wins for a team \/ sum of wins for all teams at a particular round'''\n        \n        rounds_probs = copy.deepcopy(self.rounds)\n        for round_number, round_stats in rounds_probs.items():\n            m = np.sum(list(round_stats.values()))\n            for k, v in rounds_probs[round_number].items():\n                rounds_probs[round_number][k] = v \/ m\n                \n        return rounds_probs","bf220b35":"# the below roster is based on 2019-2020 NBA playoffs\n# https:\/\/en.wikipedia.org\/wiki\/2019%E2%80%9320_NBA_season\n\ngroup_list = [\n     # Eastern Conference\n     ('Bucks', 'Magic'),  # group A \n     ('Pacers', 'Heat'), # group B\n    \n     ('Celtics', '76ers'), # group C\n     ('Raptors', 'Nets'), # group D\n    \n     # Western Conference\n     ('Lakers','Trail Blazers'),  # group E\n     ('Rockets','Thunder'), # group F\n    \n     ('Nuggets', 'Jazz'), # group G\n     ('Clippers', 'Mavericks')] # group H","ebe844f8":"%%time\n\n# initiate a playoff\nplayoff = FinalTournament()\n# simulate the playoff 5,000 times\nplayoff.simulate(group_list, n_simulation = 5000)","38b02f0a":"# see the winning probabilities from 5,000 playoffs\nplayoff.rounds_probs","549a9b45":"def plotting(rounds_data):\n    \n    rounds_stats = list(rounds_data.values())\n    team_names = list(rounds_stats[0].keys())\n    \n    # x is number of rounds used for labels, y is a 2-D array of (n_teams, n_rounds) used for data\n    x = list(rounds_data.keys())\n    y = np.array([list(r.values()) for r in rounds_stats]).T \n    \n    # we need at least 16 different colors, one for each team\n    c_1 =  sns.color_palette('tab10', n_colors = 10)\n    c_2 =  sns.color_palette(\"pastel\", n_colors = 10)\n    color_map = c_1 + c_2 \n    \n    fig = plt.figure()\n    plt.stackplot(x, y, labels = team_names, colors = color_map) \n    plt.legend(bbox_to_anchor=(1.1, 1.1), loc = 'upper left', fontsize=13)\n    plt.xticks(x, fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.xlabel('Round Number', fontsize = 15)\n    plt.title('Winning probabilities by all Teams & Rounds', pad = 20, fontsize = 24)\n    plt.tight_layout()\n    plt.show()\n    \n    return fig","7037f4d2":"# check that a team's wins should get less and less in later rounds\nfig = plotting(playoff.rounds)","c45bc917":"# plot the results: probabilities of winning for all teams at each round\nfig = plotting(playoff.rounds_probs)","a1ade80b":"# extract games played by Bucks and Raptors\n\ndf_br_1 = df.loc[(df['HOME_TEAM_ID'] == 'Bucks') & (df['VISITOR_TEAM_ID'] == 'Raptors')].reset_index(drop=True)\ndf_br_2 = df.loc[(df['HOME_TEAM_ID'] == 'Raptors') & (df['VISITOR_TEAM_ID'] == 'Bucks')].reset_index(drop=True)\n","75ff13b0":"print('Bucks won {} out of {} when being the home team'.format(\n    sum(df_br_1['HOME_TEAM_WINS']), df_br_1.shape[0])) \nprint('Bucks won {} out of {} when being the away team'.format(\n    df_br_2.shape[0] - sum(df_br_2['HOME_TEAM_WINS']), df_br_2.shape[0])) ","83211f0c":"# bucks against Rapters\nprint(\"Bucks' chance of winning against Raptors: \", (18 + 16) \/(35 + 36))","c2ae5c82":"### \ud83e\udd14 Debug: Why Raptors was able to beat Bucks?\n\nFrom our observations, though Bucks' chances of winning in the early rounds are less than in later rounds,it still is much better than Raptors, how did Bucks lose? One hypothesis is that a strong team(e.g., Bucks), when facing particular type of opponent(e.g., Raptors), may become weaker. To comfirm this hypothesis, we can check the performance of Bucks when up against Raptors in our data.","cf8028b8":"# 1. Data Cleaning","aa8b5ded":"## Our Goal: \n\nOur goal is to predict the probability of winning for each team and at each round of the playoff, in order to see who may win the championship.","caa39f5f":"## Workflow:\n\n1. Data cleaning\n2. Fit a win\/loss Discriminator(D)\n3. Fit a feature Generator(G)\n4. Run n_simulations with both D and G according to the rules of playoff\n5. Visualization","4f3e4b98":"### \ud83c\udf17 Results Comparison (actual 2019-2020 NBA playoff results)\n\nIn the actual 2019-2020 playoff, **Bucks** had lost to **Toronto Raptors** narrowly (3-4) at the 1st round. Lakers had, as we predicted, beat both **Nuggets** and **Heat** in the last two rounds and became the champion. These are mostly consistent with our model's predictions given the above observations. And since our model have not seen the 2019-2020 playoff data, it didn't \"cheat\" to get the results.","b8872359":"### \u261d\ufe0f Observations\n\n1. Based on overall winning probabilities, the top 3 teams are: **Bucks > Lakers > Nuggets**.\n\n2. Based on winning probabilities in the final round, the top 3 teams are: **Bucks > Lakers > Heat**.\n\n3. **Bucks** has a much higher overall chance of winning, if it can get through the early rounds.\n\n4. If we were the **Lakers**, we would avoid the **Bucks**; if we were the **Heat** or **Nuggets**, we would avoid both the **Bucks** and **Lakers**.","89e5854e":"# 3. Fitting a Generator","30427d0e":"\u261d\ufe0fThe above explains why Bucks lost: It has little less than random chance of winning against Raptors. In sum, when we train the win\/loss classifier, we should take into account which teams are competing as well!","23e684d4":"## Background:\n\n1. NBA playoff is a best-of-seven elimination tournament.\n2. There are 16 competing teams; 8 initial pairs.\n3. Each pair will play up-to 7 games, so it takes 4 games to win.\n4. A total of 4 rounds are required to win the championship \ud83c\udfc6.","7ec53082":"# 4. Simulation","ca180b67":"# 2. Fitting an SVM win\/loss discriminator","17b3cece":"# Predicting NBA playoff results with simulation","b3acadf8":"# 5. Visualization & Analysis","84824f31":"## Fitting SVM ","2541d978":"## \ud83d\ude42 Improvements\n\n1. **Use more and better features**: Powerful simulations usually have more variables to cover more scenarios of the playoff. Using player level statistics is one way to go.\n\n2. **Use better win\/loss model**: Our trained SVM Discriminator only has about 70%+ accuracy, it is sufficient but nowhere near perfect. Improvements can be achieved by adding more data features or using a more powerful model such as Neural Network or ensemble model.\n\n3. **Do better at distribution fitting**: In the projects, we used only a handful of distributions to speed up the fitting. To reduce the fitting errors, we can use more complex distributions. The lower the fitting error, the more realistic the samples we can generate.\n\n4. **Run more simulations**: Should we have more variables to account for in our win\/loss Discriminator, we need to run more simulations to get the precise probabilities."}}