{"cell_type":{"3d8076f6":"code","5a5e9517":"code","b49d6f2d":"code","1837c877":"code","07724e49":"code","1777c9cc":"code","995f1622":"code","5f791aec":"code","9cadcab8":"code","56a5c85d":"code","f0606dc4":"code","913e644b":"code","832298a2":"code","cfec859a":"code","f69ccbff":"code","8db90a55":"markdown","402eb331":"markdown","4b475aae":"markdown","6f8cd99e":"markdown","39170af4":"markdown","cf27fa71":"markdown","e2494dde":"markdown","38d4d5d0":"markdown","e3f6078f":"markdown","d96f9072":"markdown","8225a087":"markdown","ea7932af":"markdown","2f432e1c":"markdown","95c0d2e0":"markdown","584b76c5":"markdown","524e3aae":"markdown"},"source":{"3d8076f6":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","5a5e9517":"import os\nimport cv2\nimport keras\nimport numpy as np\nimport tensorflow as tf\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import load_model  \nfrom keras.utils import plot_model\nfrom keras import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D,Flatten,Softmax,Activation,Dense,Dropout\nfrom keras.callbacks import Callback,ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score,auc\n#from skimage.transform import rescale, resize\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nimport pickle\nfrom skimage import measure\nfrom skimage import morphology\nfrom skimage.transform import resize\nfrom sklearn.cluster import KMeans","b49d6f2d":"def split_target_dir(target_dir,output_dir):\n    target_list=[target_dir+os.sep+file for file in os.listdir(target_dir)]\n    for target in target_list:\n        img_split=split_lung_parenchyma(target,15599,-96)\n        dst=target.replace(target_dir,output_dir)\n        dst_dir=os.path.split(dst)[0]\n        if not os.path.exists(dst_dir):\n            os.makedirs(dst_dir)\n        cv2.imencode('.jpg', img_split)[1].tofile(dst)\n    print(f'Target list done with {len(target_list)} items')\n    \ndef split_lung_parenchyma(target,size,thr):\n    img=cv2.imdecode(np.fromfile(target,dtype=np.uint8),cv2.IMREAD_GRAYSCALE)\n    try:\n        img_thr= cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV,size,thr).astype(np.uint8)\n    except:\n        img_thr= cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV,999,thr).astype(np.uint8)\n    img_thr=255-img_thr\n    img_test=measure.label(img_thr, connectivity = 1)\n    props = measure.regionprops(img_test)\n    img_test.max()\n    areas=[prop.area for prop in props]\n    ind_max_area=np.argmax(areas)+1\n    del_array = np.zeros(img_test.max()+1)\n    del_array[ind_max_area]=1\n    del_mask=del_array[img_test]\n    img_new = img_thr*del_mask\n    mask_fill=fill_water(img_new)\n    img_new[mask_fill==1]=255\n    img_out=img*~img_new.astype(bool)\n    return img_out\n\ndef fill_water(img):\n    copyimg = img.copy()\n    copyimg.astype(np.float32)\n    height, width = img.shape\n    img_exp=np.zeros((height+20,width+20))\n    height_exp, width_exp = img_exp.shape\n    img_exp[10:-10, 10:-10]=copyimg\n    mask1 = np.zeros([height+22, width+22],np.uint8)   \n    mask2 = mask1.copy()\n    mask3 = mask1.copy()\n    mask4 = mask1.copy()\n    cv2.floodFill(np.float32(img_exp), mask1, (0, 0), 1) \n    cv2.floodFill(np.float32(img_exp), mask2, (height_exp-1, width_exp-1), 1) \n    cv2.floodFill(np.float32(img_exp), mask3, (height_exp-1, 0), 1) \n    cv2.floodFill(np.float32(img_exp), mask4, (0, width_exp-1), 1)\n    mask = mask1 | mask2 | mask3 | mask4\n    output = mask[1:-1, 1:-1][10:-10, 10:-10]\n    return output","1837c877":"def normal(X):\n  norm= np.linalg.norm(X)\n  n= X\/norm\n  return n","07724e49":"def read_image(target_dir):\n    x = cv2.imread(target_dir)\n    x = cv2.resize(x,(200,200))\n    global i\n    print(i)\n    i=i+1\n    return x\ni=1;","1777c9cc":"def predict_comparision(y_predict,y_test):\n    tp,tn,fp,fn = 0,0,0,0\n    y_predict_index = np.argmax(y_predict,axis = 1)\n    y_test_index = np.argmax(y_test,axis = 1)\n    m = len(y_predict_index)\n    for i in range(m):\n        if y_predict_index[i] == 0:\n            if y_test_index[i]==0:\n                tp +=1    \n            else:\n                fp +=1\n        else:\n            if y_test_index[i]==1:\n                tn +=1\n            else:\n                fn += 1 \n    return tp,tn,fp,fn","995f1622":"def VGG_Simple():\n    model=Sequential()\n    model.add(Conv2D(64,(3,3),strides=(1,1),input_shape=(200,200,1),padding='same',activation='relu',kernel_initializer='uniform'))\n    model.add(Conv2D(64,(3,3),strides=(1,1),padding='same',kernel_initializer='uniform',activation='relu'))\n    model.add(MaxPooling2D((2,2)))\n    model.add(Conv2D(32,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))\n    model.add(Conv2D(32,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))\n    model.add(MaxPooling2D((2,2)))\n    model.add(Conv2D(16,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))\n    model.add(Conv2D(16,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))\n    model.add(MaxPooling2D((2,2)))\n    model.add(Flatten())\n    model.add(Dense(64,activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(32,activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(3,activation='softmax'))\n    return model","5f791aec":"class RocAucEvaluation(Callback):\n    def __init__(self, validation_data=()):\n        super(Callback, self).__init__()\n        self.x_val,self.y_val = validation_data\n    def on_epoch_end(self, epoch, log={}):\n        y_pred = self.model.predict(self.x_val)\n        AUC1 = roc_auc_score(self.y_val[:,0], y_pred[:,0])\n        AUC2 = roc_auc_score(self.y_val[:,1], y_pred[:,1])\n        AUC3 = roc_auc_score(self.y_val[:,2], y_pred[:,2])\n        print('val_AUC NiCT epoch:%d: %.6f' % (epoch+1, AUC1))\n        print('val_AUC pCT epoch:%d: %.6f' % (epoch+1, AUC2))\n        print('val_AUC nCT epoch:%d: %.6f' % (epoch+1, AUC3))\n        print()","9cadcab8":"tr1='..\/input\/preprocessed-ct-scans-for-covid19\/CT scans\/NiCT\/'\ntr2='..\/input\/preprocessed-ct-scans-for-covid19\/CT scans\/pCT\/'\ntr3='..\/input\/preprocessed-ct-scans-for-covid19\/CT scans\/nCT\/'\ntl1=[tr1+file for file in os.listdir(tr1)]\ntl2=[tr2+file for file in os.listdir(tr2)]\ntl3=[tr3+file for file in os.listdir(tr3)]\ntarget_list= tl1+tl2+tl3\nprint(\"The number of non-informative images: \",len(tl1))\nprint(\"The number of positive images: \",len(tl2))\nprint(\"The number of negative images: \",len(tl3))","56a5c85d":"fig= plt.figure(figsize=(20,10))\nindex= tl1[0]\na= fig.add_subplot(1,3,1)\na.set_title('Non-informative Image')\nplt.imshow(plt.imread(index))\n\nindex= tl2[0]\na= fig.add_subplot(1,3,2)\na.set_title('Positive Image')\nplt.imshow(plt.imread(index))\n\nindex= tl3[0]\na= fig.add_subplot(1,3,3)\na.set_title(\"Negative Image\")\nplt.imshow(plt.imread(index))","f0606dc4":"##Skip this cell if you want to use the pickle object for data loading\n\ny_list=to_categorical(np.concatenate(np.array([[0]*len(tl1),\n                                               [1]*len(tl2),\n                                               [2]*len(tl3)])),3)\nX=np.array([read_image(file) for file in target_list])","913e644b":"f= '..\/input\/pickle-file-of-ct-scans\/train_lung.pickle'\nwith open(f, 'rb') as file: \n    X_train,X_val,y_train,y_val=pickle.load(file)\n\nprint(X_train.shape)\nprint(X_val.shape)\nprint(y_train.shape)\nprint(y_val.shape)\n","832298a2":"X_train= normal(X_train)\nX_val= normal(X_val)","cfec859a":"#X_train, X_val, y_train, y_val = train_test_split(X, y_list, test_size=0.2, stratify=y_list)\ncheckpoint = ModelCheckpoint('vggnormal.model',save_weights_only = False, monitor='val_loss', verbose=1,save_best_only=True,mode='auto',period=1)\nRocAuc = RocAucEvaluation(validation_data=(X_val,y_val))","f69ccbff":"model=VGG_Simple()\nmodel.compile(optimizer=keras.optimizers.Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\nhistory = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val),batch_size=64, callbacks=[checkpoint,RocAuc],verbose=1)","8db90a55":"**Function for reading an image from a directory**","402eb331":"**Load the pickle file and check it's shapes**","4b475aae":"**Now let's import the required modules**","6f8cd99e":"**Get images and their respective labels into numpy arrays**\n\n**This process takes a while. For our working purpose we saved the loaded data into a pickle. We added the pickle file to this notebook for quick loading. But if want to apply other techniques (augmentation, data generator), I suggest to change the read_img function for your suitable work.** ","39170af4":"**The defined callbacks**","cf27fa71":"**Function for computing the True positive, true negative, false positive and false negative values**","e2494dde":"**A function to normalize the image data**","38d4d5d0":"**Now, let's plot one image from each of the classes**","e3f6078f":"**Create a model, compile it and train it using the loaded data**","d96f9072":"**Get all the image directories into a single list**","8225a087":"# Keras implementation on COVID-19 CT Scans\n\n**In this notebook, I applied a simple vgg model using keras. This is just a starter code for this data to see how a keras model can be applied to an image dataset.**","ea7932af":"**Applying normalization to the training and validation images.**","2f432e1c":"**Class for Keras callbacks. We use this callback for the AUC value**","95c0d2e0":"**The following functions were used to extract the lung parenchyma from the original images. We won't use these functions in this notebook. I added them to give you an idea about how we got the images. **","584b76c5":"**First Let's check whether the GPU is enabled or not**","524e3aae":"**Function for creating a simple CNN model**"}}