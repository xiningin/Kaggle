{"cell_type":{"8c59b6d5":"code","2f6d2f6b":"code","fa257d55":"code","16f7f8a8":"code","c0d7446c":"code","69fda55a":"code","04f77e14":"code","1bda96bf":"code","5cf2b7a4":"code","c04e3c32":"code","e47064e2":"code","cd91d631":"code","07d64e65":"code","e122014c":"code","94900ba1":"code","940f8e5f":"code","499e9835":"code","e8e927c1":"code","9d1d9395":"code","18516e73":"markdown","f4da047a":"markdown","fc5aa997":"markdown","1f718a77":"markdown","e0cd9e79":"markdown","2ba134ae":"markdown","8e05c5e3":"markdown","8f44d1fd":"markdown","be5e6585":"markdown","c34e3ccb":"markdown","3da4bf44":"markdown","26501f80":"markdown","2d5980e5":"markdown","a44271df":"markdown","6c247688":"markdown","925894b8":"markdown","4ac87113":"markdown","62e9e171":"markdown","2fdc165d":"markdown"},"source":{"8c59b6d5":"import numpy as np \nfrom numpy import random\nimport pandas as pd\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = (20,20)\npd.options.display.max_rows = None","2f6d2f6b":"import my_utils as my\ndir(my)","fa257d55":"train_raw = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv').drop('Id', axis = 1)\ntest_raw = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv').drop('Id', axis = 1)\nprint(train_raw.shape, test_raw.shape)","16f7f8a8":"train_raw = train_raw.sort_values('SalePrice').reset_index(drop = True)\nprint(train_raw.shape)\ntrain_raw.head()","c0d7446c":"valid_rows = range(0, train_raw.shape[0], 4)\npd.Series(valid_rows).tail()","69fda55a":"X_valid = train_raw.iloc[valid_rows, :].reset_index(drop = True)\nX_train = train_raw.drop(valid_rows, axis=0).reset_index(drop = True)\nX_test = test_raw\nprint(X_train.shape, X_valid.shape)","04f77e14":"num_cols, obj_cols = my.col_types(X_test)\nprint('Numeric columns:', list(num_cols))\nprint('-  -  -')\nprint('Object columns:',obj_cols)","1bda96bf":"X_new = pd.DataFrame()\nfor i in range(25):\n    X_new = pd.concat([X_train, X_new])\nprint(X_train.shape, '->', X_new.shape)","5cf2b7a4":"#List of cols to distort\ncols_to_distort = ['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n                   'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n                   '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea',\n                   'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch',\n                   '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'SalePrice']\n\n#Array of random factors in range 90% - 110%\nrand = random.uniform(low=0.9, high=1.1, size=(X_new.shape[0], len(cols_to_distort)))\n\nX_new[cols_to_distort] = X_new[cols_to_distort] * rand\nX_train = pd.concat([X_train, X_new]).reset_index(drop= True)\n\nprint(X_train.shape)","c04e3c32":"y_train = X_train['SalePrice']\ny_valid = X_valid['SalePrice']\n\nX_train = X_train.drop('SalePrice', axis=1)\nX_valid = X_valid.drop('SalePrice', axis=1)\n\nprint(X_train.shape, y_train.shape, X_valid.shape, y_valid.shape, X_test.shape)","e47064e2":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(X_train[num_cols])\nX_train[num_cols] = scaler.transform(X_train[num_cols])\nX_valid[num_cols] = scaler.transform(X_valid[num_cols])\nX_test[num_cols] = scaler.transform(X_test[num_cols])","cd91d631":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy = 'most_frequent')\nimputer.fit(X_train)\nX_train_imp = imputer.transform(X_train)\nX_valid_imp = imputer.transform(X_valid)\nX_test_imp = imputer.transform(X_test)","07d64e65":"X_train = pd.DataFrame(X_train_imp, columns = X_train.columns)\nX_valid = pd.DataFrame(X_valid_imp, columns = X_valid.columns)\nX_test = pd.DataFrame(X_test_imp, columns = X_test.columns)","e122014c":"from sklearn.preprocessing import OneHotEncoder\nencoder = OneHotEncoder(sparse = False)\nMerged = pd.concat([X_train, X_valid, X_test])\nfitted = encoder.fit(Merged[obj_cols])\n\ndef enc (df, fit):\n    df_new = fit.transform(df[obj_cols])\n    df = df.drop(obj_cols, axis=1)\n    df = df.join(pd.DataFrame(df_new))\n    return df\n\nX_train_enc = enc(X_train, fitted).astype(float)\nX_valid_enc = enc(X_valid, fitted).astype(float)\nX_test_enc = enc(X_test, fitted).astype(float)","94900ba1":"print(train_raw.shape, test_raw.shape)\nprint(X_train_enc.shape, y_train.shape, X_valid_enc.shape, y_valid.shape, X_test_enc.shape)","940f8e5f":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.callbacks import EarlyStopping\ntf.random.set_seed(17)\n\nmodel = keras.Sequential([\n                        layers.Dense(512, activation = 'relu', input_shape = [X_train_enc.shape[1]]),\n                        layers.Dense(512, activation = 'relu'),\n                        layers.Dense(512, activation = 'relu'),\n                        layers.Dense(512, activation = 'relu'),\n                        layers.Dense(1)\n                        ])\nmodel.compile(\n            optimizer='adam',\n            loss='mean_squared_logarithmic_error',\n            metrics=['mean_squared_logarithmic_error'],\n            )\n\nearly_stopping = keras.callbacks.EarlyStopping(\n    patience=5,\n    min_delta=0.001,\n    restore_best_weights=True,\n)\nhistory = model.fit(\n    X_train_enc, y_train,\n    batch_size = 32,\n    epochs=20,\n    validation_data=(X_valid_enc, y_valid),\n    callbacks=[early_stopping],\n)","499e9835":"plt.rcParams[\"figure.figsize\"] = (4,4)\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot(title=\"MSLE\")","e8e927c1":"pred_nn = pd.DataFrame(model.predict(X_test_enc))\npred_nn.head(3)","9d1d9395":"sub = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\nsub['SalePrice'] = pred_nn[0]\nsub.to_csv('submission.csv', index = False)","18516e73":"Encode categorical columns","f4da047a":"Fill NaN by most frequent values","fc5aa997":"I use my utils script, you can find it [here](https:\/\/www.kaggle.com\/paveltrusov\/my-utils)","1f718a77":"Sort values by ```SalePrice``` in order to have balanced validation set","e0cd9e79":"#### Now I create additional train set, generated from the original one\nI will use original set and multiply it **25 times**","2ba134ae":"#### Summary\nIn my case I got RMSLE **0.15005** after submission, that is much better than it was [before](https:\/\/www.kaggle.com\/paveltrusov\/house-prices-keras-simple-neural-network) augmentation - 0.41864.<br>\nThus, even such a primitive approach improves the results a lot.<br>\nPlease note: results may vary from run to run regardless of random seed","8e05c5e3":"#### Title\nHere I'm going to [continue](https:\/\/www.kaggle.com\/paveltrusov\/house-pricing-keras-nn) to play with House pricing copetition using Keras<br>\nIn this notebook I will try to use data augmentation to achive better results","8f44d1fd":"Return original column names","be5e6585":"Split train set for train\/validation","c34e3ccb":"Minmax scaling for numerical columns","3da4bf44":"Generate and export submissions","26501f80":"Extract target column","2d5980e5":"Then I distort the added data so that the neural network does not get the same data twice","a44271df":"I take every 4th row from sorted train_set to use it for validation","6c247688":"By this function I get lists of object and numerical features","925894b8":"Generate predictions","4ac87113":"Check raw and modified data sets size","62e9e171":"Check metrics","2fdc165d":"#### Configure and run NN"}}