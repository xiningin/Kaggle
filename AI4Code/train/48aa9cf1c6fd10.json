{"cell_type":{"494530fd":"code","e6f9a427":"code","abae7d5a":"code","f0080f3d":"code","f3c5b7c4":"code","cca168ac":"code","818081a5":"code","c7b8ffd3":"code","0c46bd1a":"code","35aac303":"code","1061a6e6":"code","ad965636":"code","2437384f":"code","bce414d0":"code","7bb653dc":"code","8ccebb28":"code","83e04574":"code","546ab7aa":"code","3b76acd8":"code","74d87e3d":"code","17e0aa93":"code","0bfd2b15":"markdown","5f836880":"markdown","69ce1256":"markdown","980c3e81":"markdown","32ab3ee2":"markdown","49fc8e23":"markdown","87281b2f":"markdown","b37e2b4f":"markdown","e8573cde":"markdown","9860a6da":"markdown","8275e880":"markdown","62877e9c":"markdown","78659fcd":"markdown","85af444e":"markdown","d6c58ade":"markdown","9ca4b609":"markdown","475b97ec":"markdown"},"source":{"494530fd":"!pip install ftfy\n!pip install gensim\n\n\nimport random\nimport numpy as np\nimport pandas as pd\nimport copy \nfrom scipy.stats import uniform\nfrom scipy.stats import loguniform as sp_loguniform\nimport requests\nimport io\n\nfrom ftfy import fix_text\nimport string\nimport re\nfrom gensim.test.utils import common_texts\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\n","e6f9a427":"train = pd.read_csv(\"..\/input\/sentiment-analysis-pmr3508\/data_train.csv\")\ntrain.info()","abae7d5a":"train.head()","f0080f3d":"train = train.drop_duplicates(keep='first')\ntrain.shape","f3c5b7c4":"train.loc[:,'positive'].value_counts() ","cca168ac":"train_X = train['review']\ntrain_Y = train['positive']\n\ntrain_X.head()","818081a5":"train_Y.head()","c7b8ffd3":"def preptext(text):\n    txt=text.replace(\"<br \/>\",\" \") #retirando tags\n    txt=fix_text(txt) #consertando Mojibakes (Ver https:\/\/pypi.org\/project\/ftfy\/)\n    txt=txt.lower() #passando tudo para min\u00fasculo\n    txt=txt.translate(str.maketrans('', '', string.punctuation)) #retirando toda pontua\u00e7\u00e3o\n    txt=txt.replace(\" \u2014 \", \" \") #retirando h\u00edfens\n    txt=re.sub(\"\\d+\", ' <number> ', txt) #colocando um token especial para os n\u00fameros\n    txt=re.sub(' +', ' ', txt) #deletando espa\u00e7os extras\n    return txt\n\ntrain_X = train_X.apply(preptext)","0c46bd1a":"train_X.head()","35aac303":"train_X = train_X.apply(lambda x: x.split())\ntrain_X.head()","1061a6e6":"d2v = Doc2Vec.load(\"..\/input\/sentiment-analysis-pmr3508\/doc2vec\")\n\ndef emb(txt, model, normalize=False): \n    model.random.seed(42)\n    x=model.infer_vector(txt, steps=20)\n    \n    if normalize: return(x\/np.sqrt(x@x))\n    else: return(x)\n    \ntrain_X = [emb(x, d2v) for x in train_X] \ntrain_X = np.array(train_X)\n\ntrain_X.shape","ad965636":"train_X","2437384f":"validation = pd.read_csv(\"..\/input\/sentiment-analysis-pmr3508\/data_test1.csv\") #importa\u00e7\u00e3o\n\nvalidation_X = validation['review'].tolist()\nvalidation_Y = validation['positive']\n\nvalidation_X = [preptext(x).split() for x in validation_X]\nvalidation_X = [emb(x, d2v) for x in validation_X] \nvalidation_X = np.array(validation_X)\n\nvalidation_X","bce414d0":"test = pd.read_csv(\"..\/input\/sentiment-analysis-pmr3508\/data_test2_X.csv\") #importa\u00e7\u00e3o\n\nsubmission_X = test['review'].tolist()\nsubmission_X = [preptext(x).split() for x in submission_X]\nsubmission_X = [emb(x, d2v) for x in submission_X]                   \nsubmission_X = np.array(submission_X)\n\nsubmission_X","7bb653dc":"MLP = MLPClassifier(early_stopping=True)\nHL_size = [x for x in range(20, 131, 10)]\nalpha = sp_loguniform(0.000001, 0.1)\nparameters_1HL= {'hidden_layer_sizes': HL_size , 'alpha': alpha}\n\nMLP_1HL = RandomizedSearchCV(MLP, parameters_1HL, n_jobs=4, verbose=1, scoring=\"roc_auc\")\nMLP_1HL.fit(train_X, train_Y) #CLASSIFICADOR 1\n\nprint(\"CLASSIFICADOR 1 (MLP_1HL): Melhor AUC ROC = \", MLP_1HL.best_score_ )\nprint(\"                         : Melhores Par\u00e2metros= \",MLP_1HL.best_params_)","8ccebb28":"# Hiperpar\u00e2metros a serem otimizados\nHL2_size = [[x,y] for x in range(20, 131, 10) for y in range(20, 131, 10)]\nparameters_2HL = {'hidden_layer_sizes':HL2_size, 'alpha': alpha}\n\n# Busca de Hiperpar\u00e2metros\nMLP_2HL = RandomizedSearchCV(MLP, parameters_2HL, n_jobs=4, verbose=1, scoring=\"roc_auc\")\nMLP_2HL.fit(train_X, train_Y)\n\nprint(\"CLASSIFICADOR 2 MLP_2HL: Melhor AUC ROC = \", MLP_2HL.best_score_ )\nprint(\"                       : Melhores Par\u00e2metros= \",MLP_2HL.best_params_)","83e04574":"num_neigh = [x for x in range(70, 131, 10)] #poss\u00edveis numeros de vizinhos que ser\u00e3o considerados na busca : 70,80,...,130\nparameters_KNN = {'n_neighbors': num_neigh}\n\nKNeighbors= KNeighborsClassifier()\n\nKNN = RandomizedSearchCV(KNeighbors, parameters_KNN, n_jobs=4, verbose=1, scoring=\"roc_auc\")\nKNN.fit(train_X, train_Y)\n\nprint(\"CLASSIFICADOR 3 KNN : Melhor AUC ROC = \", KNN.best_score_)\nprint(\"                    : N\u00famero de vizinhos = \", KNN.best_params_['n_neighbors'])","546ab7aa":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression(solver=\"liblinear\")\n\n# Hyperparameters\nparameters_LR = dict(C=np.linspace(0.01, 10, 100),penalty=[\"l1\", \"l2\"],)\n\n# Research\nLog_Reg = RandomizedSearchCV(logreg,parameters_LR,scoring=\"roc_auc\",cv=2,n_iter=50, n_jobs=-1,)\nLog_Reg = Log_Reg.fit(train_X, train_Y)\n\n\nprint(\"CLASSIFICADOR 4 REG LOG: Melhor AUC ROC = \", Log_Reg.best_score_ )\nprint(\"                       : Melhores Par\u00e2metros= \", Log_Reg.best_params_)","3b76acd8":"Classificador_1_auc = roc_auc_score(validation_Y, MLP_1HL.predict_proba(validation_X)[:,1])\nprint('AUC Classificador 1 (MLP_1HL):' , Classificador_1_auc)\n\nClassificador_2_auc = roc_auc_score(validation_Y, MLP_2HL.predict_proba(validation_X)[:,1])\nprint('AUC Classificador 2 (MLP_2HL):',Classificador_2_auc)\n\nClassificador_3_auc = roc_auc_score(validation_Y, KNN.predict_proba(validation_X)[:,1])\nprint('AUC Classificador 3 (KNN)    :',Classificador_3_auc)\n\nClassificador_4_auc = roc_auc_score(validation_Y, Log_Reg.predict_proba(validation_X)[:,1])\nprint('AUC Classificador 4 (LogReg) :',Classificador_4_auc)\n","74d87e3d":"submission_Y = MLP_2HL.predict_proba(submission_X)[:,1]\nsubmission = {'positive': submission_Y}\nsubmission = pd.DataFrame(submission)\n\nsubmission.head(10)","17e0aa93":"submission.to_csv(\"submission.csv\", index = True, index_label = 'Id')\nprint(\"O arquivo submission.csv com os resultados foi exportado!\")","0bfd2b15":"### 4.3) K Nearest Neighbors (KNN)\n\nPara este classificador, o procedimento ser\u00e1 an\u00e1logo ao utilizado nas Redes Neurais. Entretanto, no caso de KNN, o hiperpar\u00e2metro a ser otimizado \u00e9 o **n\u00famero de vizinhos** que s\u00e3o considerados para a classifica\u00e7\u00e3o. ","5f836880":"   # PMR3508 - Aprendizado de M\u00e1quina e Reconhcimento de Padr\u00f5es\n                                    An\u00e1lise de Sentimentos com Redes Neurais\n\n                                          Paolla Furquim Daud - 9345533\n                                    \nNeste Exerc\u00edcio Programa iremos manipular uma base de dados contendo reviews de filmes para realizar uma An\u00e1lise de Sentimentos. Ou seja, utilizando de t\u00e9cnicas de processamento de linguagem natural e treinando classificadores, iremos determinar se o car\u00e1ter do texto avaliando o filme \u00e9 positivo ou negativo. Para isso, vamos seguir os seguintes passos :\n\n1) Instala\u00e7\u00e3o e Importa\u00e7\u00f5es de Pacotes e Bibiotecas Necess\u00e1rias\n\n2) Importa\u00e7\u00e3o e Visualiza\u00e7\u00e3o Geral dos Dados Dispon\u00edveis\n\n3) Pr\u00e9 Processamento da Base de Dados\n\n4) Treinamento e Valida\u00e7\u00e3o de Diferentes Classificadores\n\n5) Sele\u00e7\u00e3o do Melhor Modelo (Crit\u00e9rio AUC ROC)\n\n6) Aplica\u00e7\u00e3o na Base de Teste e Exporta\u00e7\u00e3o dos Resultados\n\n## 1) Instala\u00e7\u00e3o e Importa\u00e7\u00f5es de Pacotes e Bibiotecas Necess\u00e1rias\n\nNa sess\u00e3o abaixo realizamos a **instala\u00e7\u00e3o** de todas as bibliotecas que ser\u00e3o necess\u00e1rias ao longo do programa, tanto para o processamento inicial dos textos, que transformar\u00e1 a entrada inicial em atributos semelhantes aos que estamos acostumados a ver (vetoriza\u00e7\u00e3o), quanto para a implementa\u00e7\u00e3o dos diferentes classificadores (redes neurais, KNN e Regressor Log\u00edstico).","69ce1256":"##### PR\u00c9-PROCESSAMENTO DA BASE DE SUBMISS\u00c3O","980c3e81":"## 5) Sele\u00e7\u00e3o do Melhor Modelo (Crit\u00e9rio AUC ROC)\n\nApesar de j\u00e1 termos obtidos valores da AUC com a base de treinos, vamos **reavaliar os modelos** instanciados no item anterior utilizando novos dados. Assim, evitamos quaisquer interfer\u00eancia de vi\u00e9s e overfitting aos dados originais. Ent\u00e3o, vamos usar os modelos instanciados e treinados no item 4 para classificar as reviews da **base de valida\u00e7\u00e3o (\"data_test1.csv\")**. O classificador que mostrar melhor desempenho ser\u00e1 ent\u00e3o utilizado para classificar a base que ser\u00e1 submetida.\n","32ab3ee2":"### 4.4) Regress\u00e3o Log\u00edstica ","49fc8e23":"## 2) Importa\u00e7\u00e3o e Visualiza\u00e7\u00e3o Geral dos Dados Dispon\u00edveis\n\nAgora podemos voltar nossa aten\u00e7\u00e3o para a base de dados com a qual lidaremos. Primeiramente podemos import\u00e1-la e realizar uma visualiza\u00e7\u00e3o de seu formato, para que possamos decidir os pr\u00f3ximos passos :","87281b2f":"Ap\u00f3s essas transforma\u00e7\u00f5es, nossa nova entrada agora tem 50 colunas num\u00e9ricas. Estas colunas ser\u00e3o os **atributos de entrada para os algoritmos de ML.**\n\nPor fim, antes de prosseguirmos para o treinamento dos algoritmos, vamos **repetir todas as a\u00e7\u00f5es realizadas na base de treino nas bases de valida\u00e7\u00e3o e de submiss\u00e3o**, para que fiquem no mesmo formato.\n\n##### PR\u00c9-PROCESSAMENTO DA BASE DE VALIDA\u00c7\u00c3O","b37e2b4f":"### 4.2) MLP - 2 Camadas Ocultas\n\nPara o MLP de 2 camadas ocultas, o procedimento adotado \u00e9 o mesmo. Por\u00e9m, precisamos otimizar o tamanho de ambas as camadas, portanto o hiperpar\u00e2metro size \u00e9 duplo, ambos os valores variam no mesmo intervalo especificado anteriormente, o primeiro determina o tamanho da primeira camada oculta, enquanto o segundo par\u00e2metro d\u00e1 o tamanho da segunda. O classificador com os par\u00e2metros utilizados \u00e9 instanciado com o nome **Classificador_2**","e8573cde":"Os textos est\u00e3o muito mais uniformes, o que permitir\u00e1 que os algoritmos de ML sejam capazes de interpret\u00e1-los adequadamente, facilitando o reconhecimento de padr\u00f5es que indiquem as suas classes.\n\nO \u00faltimo passo no pr\u00e9-processamento dos dados \u00e9 o embedding (encapsulamento) das reviews em atributos. Para isso, vamos seguir as instru\u00e7\u00f5es disponibilizadas no Moodle. Primeiramente precisamos realizar a **vetoriza\u00e7\u00e3o dos textos** - transformar o string em um vetor onde cada palavra ocupa um \u00edndice.","9860a6da":"## 4) Treinamento e Valida\u00e7\u00e3o de Diferentes Classificadores\n\nAgora que os dados est\u00e3o preparados, podemos testar diferentes m\u00e9todos de classifica\u00e7\u00e3o na base de treino, para verificar qual tem um desempenho melhor na tarefa. Como descrito no item 3.b das etapas do trabalho, iremos testar 2 redes neurais do sci-kit learn com uma camada e duas camadas ocultas, al\u00e9m de dois classificadores alternativos : Regress\u00e3o Log\u00edstica e KNN.\n\n\n### 4.1) MLP -  1 Camada Oculta\n\nPrecisamos otimizar os hiperpar\u00e2metros **alpha** e **layer_size** do MLP. Para isso, vamos utilizar o m\u00e9todo *RandomizedSearch*, que testa diferentes classificadores dentro de combina\u00e7\u00f5es aleat\u00f3rias dos diferentes valores especificados para os hiper par\u00e2metros. Variamos alpha entre 0.000001 e 0.1 com a fun\u00e7\u00e3o *loguniform* , e os valores de x (tamanho da camada oculta) v\u00e3o de 20 a 130, de 10 em 10. O crit\u00e9rio utilizado para comparar os classificadores \u00e9 a AUC (\u00e1rea debaixo da curva ROC).\n\nUma vez obtidos os melhores hiperpar\u00e2metros, podemos observ\u00e1-los, bem como o valor da AUC obtido, e instanciamos o classificador correspondente, que daqui em diante ser\u00e1 chamado de **Classificador_1**\n","8275e880":"Podemos ent\u00e3o focar no **pr\u00e9-processamento da train_X**, transformando e interpretando a entrada original (linguagem natural) em uma forma mais adequada para os algoritmos de aprendizado de m\u00e1quina.\n\nO primeiro passo \u00e9 **uniformizar os textos**. Para isso, vamos utilizar a fun\u00e7\u00e3o preptext dispon\u00edvel no Moodle, fornecida pelo monitor. Essa fun\u00e7\u00e3o recebe os textos das reviews e realiza uma limpeza **removendo sinais ortogr\u00e1ficos (pontua\u00e7\u00e3o), transformando todos os caracteres em min\u00fasculas, etc:**","62877e9c":"Conforme se pode observar, a base \u00e9 composta por **2 colunas**, a primeira chamada **\"review\"** contendo a entrada (texto) e a segunda chamada **\"positive\"**, com a sua respectiva classe (0 para false, e portanto review negativa, 1 para true, review positiva). Temos um total de **24984 linhas**, e podemos ver que todas as entradas possuem ambas as colunas preenchidas (non-null). Assim, **n\u00e3o \u00e9 necess\u00e1rio se preocupar com tratamento de dados faltantes**. Por\u00e9m, \u00e9 necess\u00e1rio verificar se dentre essas existem **dados replicados**:","78659fcd":"Podemos visualizar agora os dados de entrada ap\u00f3s a transforma\u00e7\u00e3o :","85af444e":"Como podemos ver nos resultados obtidos acima, o **Classificador 2 ( MLP 2 camadas ocultas)** apresentou melhor desempenho segundo a m\u00e9trica escolhida (AUC-ROC). Assim, ele ser\u00e1 usado para gerar o output final \n\n## 6) Aplica\u00e7\u00e3o na Base de Teste e Exporta\u00e7\u00e3o dos Resultados\nFinalmente, com o modelo de classificador que demonstrou melhor performance, podemos predizer os resultados da base de submiss\u00e3o, e export\u00e1-los no formato .csv","d6c58ade":"Para realizar o **embedding** - transformar os vetores de palavras em atributos num\u00e9ricos-, iremos utilizar o arquivo Doc2Vec j\u00e1 treinado, dispo\u00edvel no Moodle e a fun\u00e7\u00e3o emb, fornecida pelo monitor:","9ca4b609":"Foram detectadas linhas repetidas na base original. Para evitar que elas causem vi\u00e9s no nosso algoritmo, **as duplicadas foram deletadas**, mantendo apenas uma de cada, com o n\u00famero de linhas caindo de 24984 para **24888** (uma perda de apenas aproximadamente **0.5%** dos dados originais)\n\nPor \u00faltimo, \u00e9 interessante analisar a **distribui\u00e7\u00e3o dos dados** dispon\u00edveis nas classes:","475b97ec":"Temos 12461 reviews positivas e 12427 negativas. Dessa forma, h\u00e1 uma **quantidade semelhante de reviews positivas e negativas** na base de dados, e portanto n\u00e3o \u00e9 necess\u00e1rio se preocupar com desbalanceamento entre as classes.\n\n\n## 3) Pr\u00e9 Processamento da Base de Dados\n\nAgora vamos dividir nossa base de treino, colocando a entrada na vari\u00e1vel train_X e a classifica\u00e7\u00e3o na vari\u00e1vel train_Y."}}