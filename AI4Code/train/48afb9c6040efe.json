{"cell_type":{"be205add":"code","745ecc46":"code","e6cfa425":"code","18d2066d":"code","70b9ad5f":"code","7e307a2d":"code","ad9c0b70":"code","daf3e0a4":"code","9fa8f4b0":"code","e8992e1e":"code","4c99fcf8":"code","0dee64ee":"code","ea350e9b":"code","1a9a4c84":"code","75883b1d":"code","d7db1d95":"code","7e935023":"code","70d3fa8c":"code","47f82d98":"code","ed2ef955":"code","3bd99204":"code","65f0ae30":"code","c921dc67":"code","afcd999e":"code","9e0a2e05":"code","56706b9b":"code","cf297097":"code","b23b644e":"code","70f9c8ea":"code","cda32d20":"code","cdc99752":"code","36c177dd":"code","65fee39c":"code","91d19278":"code","cf4dff9f":"code","5fd47ee8":"code","5e2faa73":"markdown","f4d11a8c":"markdown","8fa9cb6d":"markdown","05dd2396":"markdown","c390fee8":"markdown","0976dfab":"markdown","d950466e":"markdown","c487f643":"markdown","1023cece":"markdown","8f578771":"markdown","ce4a4a77":"markdown","c33f4577":"markdown","b31ea98d":"markdown","2f021547":"markdown","379a955e":"markdown","a0661a25":"markdown","3173e7c1":"markdown","8d74c529":"markdown","acef3c05":"markdown"},"source":{"be205add":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n","745ecc46":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn import ensemble\nfrom matplotlib import style\nfrom sklearn.ensemble import VotingRegressor\n\nimport datetime # \u0434\u043b\u044f \u0440\u0430\u0431\u043e\u0442\u044b \u0441\u043e \u0432\u0440\u0435\u043c\u043d\u0435\u043c\nimport gc # \u0441\u0431\u043e\u0440\u0449\u0438\u043a \u043c\u0443\u0441\u043e\u0440\u0430\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score\n\nfrom lightgbm import LGBMRegressor\n\n%matplotlib inline\n\nstyle.use('fivethirtyeight')\n%matplotlib inline\n\nTEST_DATASET_PATH = '\/kaggle\/input\/realestatepriceprediction\/test.csv'\nTRAIN_DATASET_PATH = '\/kaggle\/input\/realestatepriceprediction\/train.csv'\n\ntest_data = pd.read_csv(TEST_DATASET_PATH)\ntrain_data = pd.read_csv(TRAIN_DATASET_PATH)","e6cfa425":"df = pd.read_csv('\/kaggle\/input\/realestatepriceprediction\/train.csv')\n\nX = df.drop('Price', axis=1)\ny = df[['Price']]\n\nX_final = pd.read_csv('\/kaggle\/input\/realestatepriceprediction\/test.csv')\n\n# test DATA\npreds_final = pd.DataFrame()\npreds_final['Id'] = X_final['Id'].copy()\n\nX.set_index('Id', inplace=True)\nX_final.set_index('Id', inplace=True)\n\nprint('\u0421\u0442\u0440\u043e\u043a \u0432\u0441\u0435\u0433\u043e \u0442\u0440\u0435\u0439\u043d\u0435:' ,  X.shape[0])\nprint('\u0421\u0442\u0440\u043e\u043a \u0432\u0441\u0435\u0433\u043e \u0442\u0435\u0441\u0442\u0435', X_final.shape[0])","18d2066d":"X_final.head(10)","70b9ad5f":"X['DistrictId'] = X['DistrictId'].astype(str)\nX_final['DistrictId'] = X_final['DistrictId'].astype(str)","7e307a2d":"X.head(8)","ad9c0b70":"X.dtypes","daf3e0a4":"X['Rooms'].value_counts()\n","9fa8f4b0":"X['KitchenSquare'].value_counts().sort_values()","e8992e1e":"X['HouseFloor'].sort_values().unique()","4c99fcf8":"X['Floor'].sort_values().unique()","0dee64ee":"X['HouseFloor'].sort_values().unique()","ea350e9b":"#Emissions\n(X['Floor'] > X['HouseFloor']).sum()","1a9a4c84":"X['HouseYear'].sort_values().unique()","75883b1d":"X[X['HouseYear'] > 2020].head()","d7db1d95":"import seaborn as sns\n\nnan_df = (X.isna().sum() \/ X.shape[0]).reset_index()\nnan_df.columns=['feature', 'nan_percent']\n\nplt.figure(figsize=(16,4))\nsns.barplot(nan_df['feature'], nan_df['nan_percent'])\nplt.title('Percent Missing')\nplt.ylabel('Missing', fontsize=12)\nplt.xlabel('Features', fontsize=12)\nplt.xticks(rotation=90)\nplt.show()\n","7e935023":"X.DistrictId.nunique()","70d3fa8c":"dict(X['DistrictId'].value_counts())","47f82d98":"class F_Imputer:\n    \n    \"\"\"Gap filling and emission handling\"\"\"\n    \n    def __init__(self):\n        self.medians=None\n        \n    def fit(self, X):\n        self.medians = X.median()\n    \n    def transform(self, X):\n        \n        # Rooms\n        X['Rooms_outlier'] = 0\n        X.loc[(X['Rooms'] == 0) | (X['Rooms'] >= 6), 'Rooms_outlier'] = 1\n        \n        X.loc[X['Rooms'] == 0, 'Rooms'] = 1\n        X.loc[X['Rooms'] >= 6, 'Rooms'] = self.medians['Rooms']\n        \n        # KitchenSquare\n        X.loc[X['KitchenSquare'] < 3, 'KitchenSquare'] = 3\n        X.loc[X['KitchenSquare'] > 1000, 'KitchenSquare'] = X.loc[X['KitchenSquare'] > 1000, 'KitchenSquare'] \/ 10\n        \n        # HouseFloor, Floor\n        X['HouseFloor_outlier'] = 0\n        X.loc[X['HouseFloor'] == 0, 'HouseFloor_outlier'] = 1\n        X.loc[X['Floor'] > X['HouseFloor'], 'HouseFloor_outlier'] = 1\n        \n        X.loc[X['HouseFloor'] == 0, 'HouseFloor'] = self.medians['HouseFloor']\n        X.loc[X['Floor'] > X['HouseFloor'], 'Floor'] = X.loc[X['Floor'] > X['HouseFloor'], 'HouseFloor']\n        \n        # HouseYear\n        current_year = now = datetime.datetime.now().year\n        \n        X['HouseYear_outlier'] = 0\n        X.loc[X['HouseYear'] > current_year, 'HouseYear_outlier'] = 1\n        \n        X.loc[X['HouseYear'] > current_year, 'HouseYear'] = current_year\n        \n        # Healthcare_1\n        if 'Healthcare_1' in X.columns:\n            X.drop('Healthcare_1', axis=1, inplace=True)\n            \n        # LifeSquare\n        X['LifeSquare_nan'] = X['LifeSquare'].isna() * 1\n        \n        condition = (X['LifeSquare'].isna()) &\\\n                      (~X['Square'].isna()) & \\\n                      (~X['KitchenSquare'].isna())\n        \n        X.loc[condition, 'LifeSquare'] = X.loc[condition, 'Square'] - X.loc[condition, 'LifeSquare'] - X.loc[condition, 'KitchenSquare']\n        \n        # Square\n        X.loc[X['Square'] > 400, 'Square'] = X.loc[X['Square'] > 400, 'Square'] \/ 10\n        \n        # HouseYear\n        \n        X.loc[X['HouseYear'] == 20052011, 'HouseYear'] = int((2005 + 2011) \/ 2)\n        X.loc[X['HouseYear'] == 4968, 'HouseYear'] = 1968\n        \n        return X","ed2ef955":"imputer = F_Imputer()\n\nimputer.fit(X)\n\nX = imputer.transform(X)\nX_final = imputer.transform(X_final)","3bd99204":"class F_Genetator():\n    \"\"\"Generate New Features\"\"\"\n    \n    def __init__(self):\n        self.DistrictId_counts = None\n        self.binary_to_numbers = None\n        self.med_price_by_district = None\n        \n    def fit(self, X, y=None):\n        \n        X = X.copy()\n        \n        # DistrictID\n        district = X['DistrictId'].value_counts()\n        district = district[district > 50]\n        \n        self.DistrictId_counts = dict(district)\n        \n        # Binary features\n        self.binary_to_numbers = {'A': 0, 'B': 1}\n        \n        # Target encoding\n        ## District\n        df = X.copy()\n        \n        if y is not None:\n            df['Price'] = y.values\n            \n            df['DistrictId_popular'] = df['DistrictId'].copy()\n            df.loc[~df['DistrictId_popular'].isin(district.keys().tolist())] = np.nan\n            \n            self.med_price_by_district = df.groupby(['DistrictId_popular', 'Rooms'], as_index=False).agg({'Price':'median'}).\\\n                                            rename(columns={'Price':'MedPriceByDistrict',\n                                                           'DistrictId_popular': 'DistrictId'})\n            \n        ## floor, year\n        if y is not None:\n            df['Price'] = y.values\n            df = self.floor_to_cat(df)\n            df = self.year_to_cat(df)\n            self.med_price_by_floor_year = df.groupby(['year_cat', 'floor_cat'], as_index=False).agg({'Price':'median'}).\\\n                                            rename(columns={'Price':'MedPriceByFloorYear'})\n        \n\n        \n    def transform(self, X):\n        \n        # DistrictId\n        X['DistrictId_count'] = X['DistrictId'].map(self.DistrictId_counts)\n        \n        X['new_district'] = 0\n        X.loc[X['DistrictId_count'].isna(), 'new_district'] = 1\n        \n        X['DistrictId_count'].fillna(5, inplace=True)\n        \n        # Binary features\n        X['Ecology_2'] = X['Ecology_2'].map(self.binary_to_numbers)\n        X['Ecology_3'] = X['Ecology_3'].map(self.binary_to_numbers)\n        X['Shops_2'] = X['Shops_2'].map(self.binary_to_numbers)\n        \n        # More categorical features\n        X = self.floor_to_cat(X)\n        X = self.year_to_cat(X) \n        \n        # Target encoding\n        if self.med_price_by_district is not None:\n            X = X.merge(self.med_price_by_district, on=['DistrictId', 'Rooms'], how='left')\n        if self.med_price_by_floor_year is not None:\n            X = X.merge(self.med_price_by_floor_year, on=['year_cat', 'floor_cat'], how='left')\n        \n        return X\n    \n    @staticmethod\n    def floor_to_cat(X):\n        \n        X['floor_cat'] = np.nan\n        \n        X.loc[X['Floor'] < 3, 'floor_cat'] = 1  \n        X.loc[(X['Floor'] >= 3) & (X['Floor'] <= 5), 'floor_cat'] = 2\n        X.loc[(X['Floor'] > 5) & (X['Floor'] <= 9), 'floor_cat'] = 3\n        X.loc[(X['Floor'] > 9) & (X['Floor'] <= 15), 'floor_cat'] = 4\n        X.loc[X['Floor'] > 15, 'floor_cat'] = 5\n            \n        return X\n     \n    @staticmethod\n    def year_to_cat(X):\n        \n        X['year_cat'] = np.nan\n        \n        X.loc[X['HouseYear'] < 1941, 'year_cat'] = 1\n        X.loc[(X['HouseYear'] >= 1941) & (X['HouseYear'] <= 1945), 'year_cat'] = 2\n        X.loc[(X['HouseYear'] > 1945) & (X['HouseYear'] <= 1980), 'year_cat'] = 3\n        X.loc[(X['HouseYear'] > 1980) & (X['HouseYear'] <= 2000), 'year_cat'] = 4\n        X.loc[(X['HouseYear'] > 2000) & (X['HouseYear'] <= 2010), 'year_cat'] = 5\n        X.loc[(X['HouseYear'] > 2010), 'year_cat'] = 6\n            \n        return X\n            ","65f0ae30":"features = F_Genetator()\n\nfeatures.fit(X, y)\n\nX = features.transform(X)\nX_final = features.transform(X_final)","c921dc67":"# remove quality signs for speed\nr_features = ['Rooms', 'Square', 'LifeSquare', 'KitchenSquare', 'Floor', 'Ecology_1', 'Social_1', 'Shops_1',\n                    \n                   'HouseFloor', 'HouseYear',\n                   \n                  'DistrictId_count',   'Ecology_3', 'Shops_2',\n                  'MedPriceByDistrict',\n                  'MedPriceByFloorYear','Ecology_2','Rooms_outlier', 'LifeSquare_nan', 'new_district','HouseYear_outlier']\n\nX = X[r_features]\nX_final = X_final[r_features]\n\n#after F_importances delete 'Ecology_2','Rooms_outlier', 'LifeSquare_nan', 'new_district','HouseYear_outlier',","afcd999e":"model = LGBMRegressor(max_depth=33,\n                             min_samples_leaf=10,\n                             n_estimators=300,\n                             random_state=41)\n\ncv_score = cross_val_score(model, X, y, \n                           scoring='r2', \n                           cv=KFold(n_splits=5, shuffle=True, random_state=41))\n# cv_score\nmean = cv_score.mean()\nstd = cv_score.std()\n\nprint('R2: {:.3f} +- {:.3f}'.format(mean, std))","9e0a2e05":"model.fit(X, y)","56706b9b":"def plot_f_importances(importances, X):\n    \n    indices = np.argsort(importances)[::-1]\n\n    plt.figure(figsize = (20, 6))\n    plt.title(\"Feature importances\", fontsize=16)\n    plt.bar(range(X.shape[1]), importances[indices] \/ importances.sum(),\n           color=\"darkblue\", align=\"center\")\n    plt.xticks(range(X.shape[1]), X.columns[indices], rotation = 90, fontsize=14)\n    plt.xlim([-1, X.shape[1]])\n\n    plt.tight_layout()\n    # plt.savefig('fe.jpg')\n    plt.show()\n    \nplot_f_importances(importances = model.feature_importances_, X=X)","cf297097":"model.get_params","b23b644e":"\nnp.arange(0.01, 0.05, 0.01)","70f9c8ea":"parameters = [{\n    'max_bin': np.arange(90, 120, 10),\n    'n_estimators': np.arange(4000, 7000, 1000),\n    'learning_rate': np.arange(0.01, 0.05, 0.01)\n}]","cda32d20":"clf = GridSearchCV(\n    estimator=LGBMRegressor(random_state=41),\n    param_grid=parameters,\n    scoring='neg_mean_squared_error',\n    cv=4,\n    n_jobs=-1,\n)","cdc99752":"\nclf.fit(X, y)","36c177dd":"\nclf.best_params_","65fee39c":"model = LGBMRegressor(max_bin=110,\n    n_estimators=4000,\n    learning_rate=0.01)\n\ncv_score = cross_val_score(model, X, y, \n                           scoring='r2', \n                           cv=KFold(n_splits=5, shuffle=True, random_state=41))\n# cv_score\nmean = cv_score.mean()\nstd = cv_score.std()\n\nprint('R2: {:.3f} +- {:.3f}'.format(mean, std))","91d19278":"model.fit(X, y)","cf4dff9f":"y_pred_final = model.predict(X_final)\n# test DATA Learn\n\n\npreds_final['Price'] = y_pred_final\npreds_final.to_csv('predictions.csv', index=False)\n\npreds_final.head(10)","5fd47ee8":"preds_final.shape","5e2faa73":"# Rooms","f4d11a8c":"# 4. Model","8fa9cb6d":"Emissions 4968,20052011","05dd2396":"# 3. Feature engineering","c390fee8":"# Tunning LGBMRegressor","0976dfab":"# HouseYear","d950466e":"# Filling out NaN","c487f643":"Need delete Healthcare_1\nFill LifeSquare","1023cece":"2014, 1970, and <3  =Emissions","8f578771":"# Floor, HouseFloor","ce4a4a77":"# 1. Min EDA","c33f4577":"# 1.2 Feature engineering","b31ea98d":"0 room, 19 room, 10 room =Emissions","2f021547":"# 1.1 Emissions","379a955e":"0, 99, 117 =Emissions","a0661a25":"# 2. Data cleaning","3173e7c1":"# DistrictId","8d74c529":"# Test tunning LGBMRegressor  for best params","acef3c05":"Fill LifeSquare"}}