{"cell_type":{"f9a8a1a2":"code","7bf7f3fb":"code","a8fef7b2":"code","67e568b6":"code","2e4bc850":"code","9c1002d7":"code","ea16119b":"code","0dd7c83f":"code","62ec4614":"code","b13be184":"code","ad087157":"code","8f8feb16":"code","85a28120":"code","fb54c098":"code","2dee00be":"code","381025b4":"code","a4519642":"code","8665e634":"code","057c4f6b":"code","e9b08243":"code","054b86ab":"code","1a924cc8":"code","06cf43e6":"markdown","af032ba8":"markdown","2ece30a4":"markdown","e20d9564":"markdown","4cf4fd32":"markdown","ed9629f6":"markdown","d910c9ee":"markdown","f4d60cd6":"markdown"},"source":{"f9a8a1a2":"# Start by importing the bq_helper module and calling on the specific active_project and dataset_name for the BigQuery dataset.\nimport bq_helper\nfrom bq_helper import BigQueryHelper\n# https:\/\/www.kaggle.com\/sohier\/introduction-to-the-bq-helper-package\n\nfrom google.cloud import bigquery\nimport pandas as pd\npatents_research = bq_helper.BigQueryHelper(active_project=\"patents-public-data\",\n                                   dataset_name=\"google_patents_research\")","7bf7f3fb":"# View table names under the google_patents_research data table\nbq_assistant = BigQueryHelper(\"patents-public-data\", \"google_patents_research\")\nbq_assistant.list_tables()","a8fef7b2":"# View the first three rows of the publications data table\nbq_assistant.head(\"publications\", num_rows=3)","67e568b6":"# View the last 3 rows of the publications data table\n# bq_assistant.last(\"publications\", num_rows=3) ##no such command? ","2e4bc850":"# View information on all columns in the trials data table\nbq_assistant.table_schema(\"publications\")","9c1002d7":"query_count = \"\"\"\nSELECT count(*)\nFROM\n  `patents-public-data.google_patents_research.publications`\n\"\"\"\nprint(bq_assistant.estimate_query_size(query_count))\npatents_research.query_to_pandas_safe(query_count)\n\n### 121 million rows\/patents","ea16119b":"# query_country = \"\"\"\n# SELECT DISTINCT\n#   country\n# FROM\n#   `patents-public-data.google_patents_research.publications`\n# LIMIT\n#   500;\n#         \"\"\"\n# query_country = patents_research.query_to_pandas_safe(query_country, max_gb_scanned=25)\n# query_country\n\n#### 'United States' , 'Eurasian Patent Office' , 'United Kingdom' , 'WIPO (PCT)' , 'EUIPO' , 'USSR - Soviet Union' ...","0dd7c83f":"query1 = \"\"\"\nSELECT \n  publication_number, top_terms, title\nFROM\n  `patents-public-data.google_patents_research.publications`\nWHERE\n(ARRAY_LENGTH(top_terms)> 0) AND (title_translated = FALSE) \nAND (CHAR_LENGTH(title)>2)\nAND (country = \"United States\" OR country = \"USA\")\nAND (publication_description LIKE \"Patent%\")\n\nLIMIT 4123456 OFFSET 12123456\n;\n        \"\"\"\n\n# cpc, ## cpc.code causes error, and returning the cpc seems to cause memory issues + be much slower for some reason  \n##   (LEN(top_terms)>1)\n# (NOT isnull(title))\n# AND (publication_description LIKE \"%atent%\")\n\n# publication_description - Patent , [china :  Granted Patent , Granted patent for invention ..  ]\n\n#  LIMIT\n#    27123456\n\n## could filter by last letter(2) of publication_number , corresponds to patent kind \/ type. (e.g. A = patent, granted)\n\nprint(bq_assistant.estimate_query_size(query1))\n","62ec4614":"df = patents_research.query_to_pandas_safe(query1, max_gb_scanned=50)\n\ndf.head(20) ## with an offset of 13123456 , and no special other filtering, we see the first patent in 2012","b13be184":"# response1 = df\nprint(df.shape)","ad087157":"df.tail(30)","8f8feb16":"# print(df[\"publication_description\"].value_counts())","85a28120":"print(df.shape[0])\n# df = response1.drop([\"title_translated\",\"country\"],axis=1,errors=\"ignore\")\ndf = df.drop_duplicates(subset=[\"publication_number\",\"title\"])\nprint(df.shape[0])\ndf","fb54c098":"df.to_csv(\"sample_usa_patents_research_k_bq_terms_last.csv.gz\",index=False,compression=\"gzip\")","2dee00be":"# response1","381025b4":"### https:\/\/www.kaggle.com\/shaileshshettyd\/china-patents-contributions\ntop_terms = pd.DataFrame(df[\"top_terms\"].tolist())\n\ntop_terms = pd.DataFrame(top_terms.values.flatten())\ntop_terms.columns = ['top_terms']\n\ntop_terms = top_terms.dropna(axis=0,how='all')\ntop_terms.shape","a4519642":"# 9 millions terms\ntop_terms.sample(5)","8665e634":"#  unique terms\ntop_terms.top_terms.nunique()","057c4f6b":"df_agg = pd.DataFrame(top_terms.sample(frac=0.02).groupby('top_terms')['top_terms'].count())\n\ndf_agg.columns = ['counter']\ndf_agg = df_agg.sort_values('counter', ascending=False)\n# df_agg = df_agg.head(30)\n\n# df_agg.tail(5)\n\ndf_agg.head(50)","e9b08243":"df_agg.tail(30)","054b86ab":"# # from pandas import json_normalize\n# from pandas.io.json import json_normalize\ndef get_nested_codes(row):\n    ls = []\n#     row = json_normalize(row)\n    for i in row:\n        ls.append(i[\"code\"])\n    return(ls)","1a924cc8":"# print(df[\"cpc\"][0])\n# df[\"cpc\"] = df[\"cpc\"].apply(get_nested_codes)\n# print(df[\"cpc\"][0])","06cf43e6":"##### analyze the top terms","af032ba8":"### export\n*If we have cpc, we'd also want to export the cpc codes\n* kernels have limit on file size","2ece30a4":"### Frequently occuring salient terms","e20d9564":"# How to Query Google Patents Research Data (BigQuery)\n[Click here](https:\/\/www.kaggle.com\/mrisdal\/safely-analyzing-github-projects-popular-licenses) for a detailed notebook demonstrating how to use the bq_helper module and best practises for interacting with BigQuery datasets.","4cf4fd32":"* USA patent publication_description :\n* Patent application publication                                       1094262\n* Patent                                                               1002229\n* Patent ( having previously published pre-grant publication)           554164\n* Patent ( no pre-grant publication)                                    131266\n* Design patent                                                         112373\n* Reissue patent                                                          5675\n* Plant patent ( no pre-grant publication)                                2233\n* Patent application publication ( corrected publication)                 1586\n* Plant patent application publication                                    1525\n* Plant patent                                                            1243\n* Plant patent ( having previously published pre-grant publication)       1078\n* Patent application publication ( republication)                          326","ed9629f6":"## Example SQL Query\nWhat countries do some of these patents belong to?","d910c9ee":"#### get the top terms (and cpcs), for publications which have any\n* queries about 45 GB. \n\n* OFFSEt ->  skip the first X million with offset  . (data seems to be ordered by date, despite filing date not being in this table)\n\n* could combine with full patent table to get filing date here.. \n    * https:\/\/www.kaggle.com\/dhimananubhav\/china-2-million-patents-for-invention#Publications-from-China-%F0%9F%87%A8%F0%9F%87%B3","f4d60cd6":"## Importance of Knowing Your Query Sizes\n\nIt is important to understand how much data is being scanned in each query due to the free 5TB per month quota. For example, if a query is formed that scans all of the data in a particular column, given how large BigQuery datasets are it wouldn't be too surprising if it burns through a large chunk of that monthly quota!\n\nFortunately, the bq_helper module gives us tools to very easily estimate the size of our queries before running a query. Start by drafting up a query using BigQuery's Standard SQL syntax. Next, call the estimate_query_size function which will return the size of the query in GB. That way you can get a sense of how much data is being scanned before actually running your query."}}