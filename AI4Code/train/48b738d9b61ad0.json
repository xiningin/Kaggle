{"cell_type":{"0ec6b35f":"code","260c0f2f":"code","45b7321d":"code","761af807":"code","25cdb808":"code","33ecad9f":"code","9f45fd26":"code","26459184":"code","463437f4":"code","a9d0e29c":"code","935c3f26":"code","52a40c80":"code","373ae812":"code","53f6730d":"code","3ab2cae2":"code","8b33c325":"code","33acfb60":"code","2a80b01a":"code","964abe05":"code","3f38d472":"code","b55b38e4":"markdown","c7215668":"markdown","f0f3230c":"markdown","157143e5":"markdown","475bfd46":"markdown"},"source":{"0ec6b35f":"pip install keras -U","260c0f2f":"import nltk\nnltk.download('stopwords')","45b7321d":"from keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer\nimport pandas as pd\nimport numpy as np \nimport keras.utils as ku\nfrom sklearn.model_selection import train_test_split\nfrom nltk.corpus import stopwords\nimport re\nfrom keras.utils import plot_model\nfrom keras.models import Model\nfrom keras.layers import Input,Embedding, LSTM, Dense\nfrom keras.layers import Dense\nfrom keras.layers.recurrent import LSTM\nimport matplotlib.pyplot as plt","761af807":"df = pd.read_csv(\"..\/input\/twitter-airline-sentiment\/Tweets.csv\" ,encoding=\"utf-8\")","25cdb808":"df.shape","33ecad9f":"df.info()","9f45fd26":"df.head()","26459184":"df['text'] = df['text'].str.strip()\ndf['text'] = df['text'].apply(lambda x: x.lower())\ndf['text'] = df['text'].apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x))\ndf['text'] = df['text'].apply(lambda x: re.sub(\"\\s+\", \" \", x))","463437f4":"x = df['text']\ny = df['airline_sentiment']","a9d0e29c":"words = []\nfor i in range(len(x)):\n    words.extend(x[i].split())\n\nwords = list(set(words))\n    \nstop_words = set(stopwords.words('english'))\n\nfiltered_words = [w for w in words if not w in stop_words] \n\nmax_words = len(filtered_words)\n\nprint(\"Max Words =  \", max_words)","935c3f26":"y = y.astype('category')\ny = y.cat.codes\ny                                 # 1  --> \"neutral\", 2 --> \"positive\", 3 -->\"negative\"","52a40c80":"max_len = len(max(x,key = len))\nprint(\"Max Length of String = \",max_len)","373ae812":"tokenizer = Tokenizer( num_words=max_words )\ntokenizer.fit_on_texts(x)\nx_seq = tokenizer.texts_to_sequences(x)\nx_seq = pad_sequences(x_seq,maxlen = max_len, padding='pre')\nx_seq[1]","53f6730d":"y = y.values.reshape(-1,1)\nx_train, x_test, y_train, y_test = train_test_split(x_seq, y, test_size=0.40, random_state=42)\nprint(\"Training Data = \",len(x_train))\nprint(\"Testing Data = \",len(x_test))","3ab2cae2":"input = Input(shape=(max_len,))\nembed = Embedding(input_dim= max_words,output_dim=512,input_length=max_len )(input)\nlstm_1 = LSTM(128, return_sequences=True , dropout=0.4 )(embed)\nlstm_2 = LSTM(64,dropout=0.3 )(lstm_1)\ndense_1 = Dense(32 , activation='relu')(lstm_2)\npredictions = Dense(3,activation='softmax')(dense_1)\nmodel = Model(inputs=input, outputs=predictions)","8b33c325":"print(model.summary())","33acfb60":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","2a80b01a":"model.fit(x_train,y_train ,verbose=1,epochs=12 , validation_data=(x_test[:2000],y_test[:2000]))","964abe05":"# plot graph\nplot_model(model, to_file='multiple_outputs.png')","3f38d472":"score,acc = model.evaluate(x_test, y_test,verbose = 1)\nprint('Test score:', score)\nprint('Test accuracy:', acc)\nprint()\nscore,acc = model.evaluate(x_train, y_train,verbose = 1)\nprint('Training score:', score)\nprint('Training accuracy:', acc)","b55b38e4":"### **Import Model & Layer using Functional API**","c7215668":"## **Thank You**","f0f3230c":"## **Import Dataframe**","157143e5":"## **Import Library**","475bfd46":"## **Data Preprocessing**"}}