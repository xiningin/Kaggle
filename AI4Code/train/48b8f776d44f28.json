{"cell_type":{"7d270935":"code","4375c223":"code","5fe1a8d6":"code","766c5786":"code","bd32a024":"code","308333a3":"code","c90229a8":"code","ace1a6ae":"code","b3d15023":"code","6c97734a":"code","7079c70f":"code","ab37d4dc":"code","acf45950":"code","d3c78f72":"code","77daf228":"markdown","6fb716cd":"markdown","8ce6e96b":"markdown","af0b213e":"markdown","3271a195":"markdown","51f524be":"markdown","57b868f4":"markdown","8cfa5bd9":"markdown","857b6500":"markdown","74ef7706":"markdown","6e4fefe7":"markdown","0cbd0992":"markdown","389f5cdc":"markdown","4a94188e":"markdown"},"source":{"7d270935":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Reshape, Dropout, Dense \nfrom tensorflow.keras.layers import Flatten, BatchNormalization\nfrom tensorflow.keras.layers import Activation, ZeroPadding2D\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import UpSampling2D, Conv2D\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.layers import GaussianNoise\nfrom tensorflow.keras.layers import Conv2DTranspose\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import initializers\nfrom tensorflow.keras.constraints import MinMaxNorm\nimport numpy as np\nfrom numpy import random\n\nfrom PIL import Image\nfrom tqdm import tqdm\nimport os \nimport time\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.mixed_precision import experimental as mixed_precision\n\n#format time into something more readable\ndef hms_string(sec_elapsed):\n    h = int(sec_elapsed \/ (60 * 60))\n    m = int((sec_elapsed % (60 * 60)) \/ 60)\n    s = sec_elapsed % 60\n    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n\n#policy = mixed_precision.Policy('mixed_float16')\n#mixed_precision.set_policy(policy)","4375c223":"generate_res = (64,64)\nPHOTO_PATH = \"\/kaggle\/input\/anime-faces\/data\/data\"\nDATA_PATH = \"\/kaggle\/working\/training_64_64.npy\"#'\/kaggle\/input\/animefacedataset\/images'\nMODEL_PATH = \"\/kaggle\/working\/\"\nSAVE_PATH = '\/kaggle\/working\/'\nSEED_SIZE = 128\nBATCH_SIZE = 128\nEPOCHS = 50 ## Increase this for better generated image \nimg_width = 64\nimg_height = 64\nchannels = 3\nn_critic = 5\nlearning_rate = 1e-4\nbeta1 = 0\nbeta2 = 0.9","5fe1a8d6":"training_data = []\nfor filename in tqdm(os.listdir(PHOTO_PATH)):\n    path = os.path.join(PHOTO_PATH,filename)\n    image = Image.open(path).resize((img_width,\n            img_height),Image.ANTIALIAS)\n    training_data.append(np.asarray(image))\ntraining_data = np.reshape(training_data,(-1,img_width,\n            img_height,channels))\ntraining_data = training_data.astype(np.float32)\ntraining_data = training_data \/ 127.5 - 1 #images should be normalised to [-1,1]\nprint(np.shape(training_data))\nnp.save(\"training_64_64.npy\",training_data) #This gets saved in \/kaggle\/working\/","766c5786":"def build_generator(seed):\n    model = Sequential()\n    model.add(Conv2DTranspose(512, input_shape = (1,1,seed), kernel_size=4, strides=1, padding='valid',use_bias=False))\n    model.add(Activation(\"relu\"))\n    \n    #model.add(Dropout(0.5))\n    model.add(Conv2DTranspose(256, kernel_size=4, strides=2, padding='same',use_bias=False))\n    #model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n    \n    #model.add(Dropout(0.5))\n    model.add(Conv2DTranspose(128, kernel_size=4, strides=2, padding='same',use_bias=False))\n    #model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n\n    #model.add(Dropout(0.5))\n    model.add(Conv2DTranspose(64, kernel_size=4, strides=2, padding='same',use_bias=False))\n    #model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n\n    #model.add(Dropout(0.5))\n    model.add(Conv2DTranspose(3, kernel_size=4, strides=2, padding='same',use_bias=False))\n    model.add(Activation(\"tanh\", dtype = 'float32'))\n    model.summary()\n    return model\n","bd32a024":"def build_discriminator(input_size):\n    \n    model = Sequential()\n\n    model.add(Conv2D(64, kernel_size=4, strides=2, input_shape=input_size, padding=\"same\"))\n    #model.add(GaussianNoise(1))\n    model.add(LeakyReLU(alpha=0.2))\n    \n    #model.add(Dropout(0.25))\n    model.add(Conv2D(128, kernel_size=4, strides=2, padding=\"same\",use_bias=False))\n    #model.add(GaussianNoise(1))\n    #model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    \n    #model.add(Dropout(0.25))\n    model.add(Conv2D(256, kernel_size=4, strides=2, padding=\"same\",use_bias=False))\n    #model.add(GaussianNoise(1))\n    #model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    \n    #model.add(Dropout(0.25))\n    model.add(Conv2D(512, kernel_size=4, strides=2, padding=\"same\",use_bias=False))\n    #model.add(GaussianNoise(1))\n    #model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n\n    #model.add(Dropout(0.25))\n    model.add(Conv2D(1, kernel_size=4, strides=1, padding=\"valid\",use_bias=False))\n    model.add(Flatten())\n    model.add(Activation('linear', dtype = 'float32'))\n    model.summary()\n    return model\n\n","308333a3":"training_data = np.load(DATA_PATH)\ntrain_dataset = tf.data.Dataset.from_tensor_slices(training_data[:int(len(training_data)\/BATCH_SIZE)*BATCH_SIZE]).shuffle(int(len(training_data)\/BATCH_SIZE)*BATCH_SIZE).batch(BATCH_SIZE)\ntraining_data = []","c90229a8":"discriminator = build_discriminator((img_height,img_width,channels))#tf.keras.models.load_model(\"\/kaggle\/working\/face_discriminator.h5\")#\ngenerator = build_generator(SEED_SIZE)#tf.keras.models.load_model(\"\/kaggle\/working\/face_generator.h5\")","ace1a6ae":"def discriminator_loss(real_output,fake_output,penalty):\n    return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output) + penalty\n\ndef generator_loss(seed):\n    fake_images = generator(seed,training=True)\n    fake_output = discriminator(fake_images,training=True)\n    return -tf.reduce_mean(fake_output)\n\ngenerator_optimizer = Adam(learning_rate,beta1,beta2) \n#generator_optimizer = mixed_precision.LossScaleOptimizer(generator_optimizer, loss_scale='dynamic')\n\ndiscriminator_optimizer = Adam(learning_rate,beta1,beta2)\n#discriminator_optimizer = mixed_precision.LossScaleOptimizer(discriminator_optimizer, loss_scale='dynamic')","b3d15023":"@tf.function\ndef train_disc(real_images,seed):\n    with tf.GradientTape() as disc_tape:\n        \n        fake_images = generator(seed,training=True)\n        real_output = discriminator(real_images,training=True)\n        fake_output = discriminator(fake_images,training=True)\n        g_penalty = gradient_penalty(real_images,fake_images)\n        disc_loss = discriminator_loss(real_output,fake_output,g_penalty)\n        #scaled_disc_loss = discriminator_optimizer.get_scaled_loss(disc_loss)\n        \n        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)#(scaled_disc_loss, discriminator.trainable_variables)\n        #gradients_of_discriminator = discriminator_optimizer.get_unscaled_gradients(gradients_of_discriminator)\n    \n        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n    return tf.reduce_mean(real_output),g_penalty","6c97734a":"def gradient_penalty(real_images,fake_images):\n    t = np.random.uniform(size=[BATCH_SIZE, 1, 1, 1], low=0., high=1.).astype(\"float32\")\n    penalty_images = t* fake_images + (1-t)* real_images\n    penalty_output = discriminator(penalty_images,training=True)\n    penalty_grads = tf.gradients(penalty_output, [penalty_images])[0]\n    slopes = tf.sqrt(1e-8 + tf.reduce_sum(tf.square(penalty_grads), axis=[1, 2, 3]))\n    gradient_penalty = tf.reduce_mean((slopes - 1.) ** 2)            \n    gradient_penalty = gradient_penalty * 10\n    \n    return gradient_penalty\n","7079c70f":"@tf.function\ndef train_gen(seed):\n    with tf.GradientTape() as gen_tape:\n        gen_loss = generator_loss(seed)\n        \n        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)#(scaled_gen_loss, generator.trainable_variables)\n        #gradients_of_generator = generator_optimizer.get_unscaled_gradients(gradients_of_generator) \n        \n        #scaled_gen_loss = generator_optimizer.get_scaled_loss(gen_loss)\n        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    \n    return tf.reduce_mean(gen_loss)","ab37d4dc":"def train(dataset, epochs):\n  start = time.time()\n  for epoch in range(epochs):\n    epoch_start = time.time()\n\n    gen_loss_list = []\n    disc_loss_list = []\n    penalty_list = []\n\n    for i,image_batch in enumerate(dataset):\n      seed = np.random.normal(size=[BATCH_SIZE,1,1, SEED_SIZE]).astype(\"float32\")\n      disc_loss, penalty = train_disc(image_batch,seed)\n      disc_loss_list.append(disc_loss)\n      penalty_list.append(penalty)\n\n      \n      if i % n_critic == 0:\n        gen_loss = train_gen(seed)\n        gen_loss_list.append(gen_loss)\n       \n      \n    g_loss = sum(gen_loss_list) \/ len(gen_loss_list)\n    d_loss = sum(disc_loss_list) \/ len(disc_loss_list)\n    penalty = sum(penalty_list) \/ len(penalty_list)\n    \n    if epoch%20 == 0:\n        \n        generator.save(os.path.join(SAVE_PATH,\"face_generator.h5\"))\n        discriminator.save(os.path.join(SAVE_PATH,\"face_discriminator.h5\"))\n\n    epoch_elapsed = time.time()-epoch_start\n    print (f'Epoch {epoch+1}, fake output={g_loss},real output={d_loss}, penalty = {penalty}, {hms_string(epoch_elapsed)}')\n        \n\n  elapsed = time.time()-start\n  print (f'Training time: {(elapsed)}')","acf45950":"train(train_dataset,EPOCHS)\ngenerator.save(os.path.join(SAVE_PATH,\"face_generator.h5\"))\ndiscriminator.save(os.path.join(SAVE_PATH,\"face_discriminator.h5\"))\nprint(SEED_SIZE)","d3c78f72":"noise = tf.random.normal([1,1,1, 128])\ngenerator = tf.keras.models.load_model(os.path.join(SAVE_PATH,\"face_generator.h5\"))\ngenerated_image = generator.predict(noise)\ngenerated_image = (generated_image + 1) * 127.5\nplt.imshow(np.squeeze(generated_image).astype('uint8'))","77daf228":"Define gen and disc loss as well as Adam optimizers","6fb716cd":"Define Descriminator model","8ce6e96b":"Define Generator Model","af0b213e":"Function to calculate Gradient Penalty ","3271a195":"Run training save model","51f524be":"Importing Dependencies\n","57b868f4":"Training Loop\n","8cfa5bd9":"Generator train function\n","857b6500":"Discriminator train dunction","74ef7706":"Initializing generator and discriminator model","6e4fefe7":"Display Random generated image","0cbd0992":"First we'll need to convert the images to numpy arrays and store as training_64_64.npy","389f5cdc":"Loading saved images such that training_data % batch_size == 0\n","4a94188e":"Defining Parameters"}}