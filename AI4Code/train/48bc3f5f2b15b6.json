{"cell_type":{"932cba52":"code","45257bf2":"code","04e6f25d":"code","0efd6bd8":"code","acb75ec6":"code","0111f80d":"code","f0bd3b52":"code","fe9d6848":"code","25d59af6":"code","7d4e51d5":"code","8e11fb13":"code","62b52594":"code","00c9f954":"code","ce82f4c6":"code","011f6873":"code","8b4999b1":"code","c5411eef":"code","8ba92f1d":"code","b67429c2":"code","a9152560":"code","a605f185":"markdown","5a7f8788":"markdown","ddcfa44a":"markdown","648b5e79":"markdown","1b5f72c3":"markdown","c1ec6220":"markdown","cf609bb5":"markdown","022874a2":"markdown","8a6c97dc":"markdown","7121df8b":"markdown","718939aa":"markdown"},"source":{"932cba52":"! pip install -q \/kaggle\/input\/readability\/readability-0.3.1-py3-none-any.whl\n! pip install -q \/kaggle\/input\/syntok\/syntok-1.3.1-py3-none-any.whl\nfrom textblob import TextBlob\nimport readability\nimport syntok.segmenter as segmenter\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","45257bf2":"train_data = pd.read_csv('\/kaggle\/input\/commonlitreadabilityprize\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/commonlitreadabilityprize\/test.csv')","04e6f25d":"train_data.info()\ntrain_data.head()","0efd6bd8":"test_data.info()\ntest_data.head()","acb75ec6":"pd.read_csv('\/kaggle\/input\/commonlitreadabilityprize\/sample_submission.csv')","0111f80d":"def sentiment_analysis(text):\n    return TextBlob(text).sentiment.polarity","f0bd3b52":"def tokenize(text):\n    \"\"\"Tokenizing and creating excerpts in the format suggested in the README of readability project.\"\"\"\n    return '\\n\\n'.join(\n        '\\n'.join(\n            ' '.join(token.value for token in sentence)\n            for sentence in paragraph)\n        for paragraph in segmenter.analyze(text))","fe9d6848":"train_data.loc[:,'readability_object'] = train_data.apply(lambda row: readability.getmeasures(tokenize(row.excerpt), lang='en'), axis=1)","25d59af6":"train_data.info()\ntrain_data.head()","7d4e51d5":"train_data.loc[0, 'readability_object']['readability grades'].keys()","8e11fb13":"readability_grades = pd.DataFrame(train_data['id'])\nreadability_grades.loc[:, 'Kincaid'] = train_data.apply(lambda row: row.readability_object['readability grades']['Kincaid'], axis=1)\nreadability_grades.loc[:, 'ARI'] = train_data.apply(lambda row: row.readability_object['readability grades']['ARI'], axis=1)\nreadability_grades.loc[:, 'Coleman-Liau'] = train_data.apply(lambda row: row.readability_object['readability grades']['Coleman-Liau'], axis=1)\nreadability_grades.loc[:, 'FleschReadingEase'] = train_data.apply(lambda row: row.readability_object['readability grades']['FleschReadingEase'], axis=1)\nreadability_grades.loc[:, 'GunningFogIndex'] = train_data.apply(lambda row: row.readability_object['readability grades']['GunningFogIndex'], axis=1)\nreadability_grades.loc[:, 'LIX'] = train_data.apply(lambda row: row.readability_object['readability grades']['LIX'], axis=1)\nreadability_grades.loc[:, 'SMOGIndex'] = train_data.apply(lambda row: row.readability_object['readability grades']['SMOGIndex'], axis=1)\nreadability_grades.loc[:, 'RIX'] = train_data.apply(lambda row: row.readability_object['readability grades']['RIX'], axis=1)\nreadability_grades.loc[:, 'DaleChallIndex'] = train_data.apply(lambda row: row.readability_object['readability grades']['DaleChallIndex'], axis=1)\nreadability_grades.loc[:, 'target'] = train_data['target']","62b52594":"readability_grades.info()\nreadability_grades.head()","00c9f954":"read_corr = readability_grades.corr()\nread_corr.info()\nread_corr","ce82f4c6":"fig, ax =plt.subplots(figsize=(8, 6))\nplt.title(\"Correlation Plot\")\nsns.heatmap(read_corr,\n            mask=np.zeros_like(read_corr, dtype=np.bool),\n            cmap=sns.diverging_palette(220, 10, as_cmap=True),\n            square=True, ax=ax)\nplt.show()","011f6873":"read_corr.target","8b4999b1":"X = pd.DataFrame(train_data['id'])\nX.loc[:,'readability'] = train_data.apply(lambda row: row.readability_object['readability grades']['SMOGIndex'], axis=1)\nX.loc[:,'sentiment'] = train_data.apply(lambda row: sentiment_analysis(row.excerpt), axis=1)\nX.loc[:,'characters_per_word'] = train_data.apply(lambda row: row.readability_object['sentence info']['characters_per_word'], axis=1)\nX.loc[:,'syll_per_word'] = train_data.apply(lambda row: row.readability_object['sentence info']['syll_per_word'], axis=1)\nX.loc[:,'words_per_sentence'] = train_data.apply(lambda row: row.readability_object['sentence info']['words_per_sentence'], axis=1)\nX.loc[:,'sentences_per_paragraph'] = train_data.apply(lambda row: row.readability_object['sentence info']['sentences_per_paragraph'], axis=1)\nX.loc[:,'type_token_ratio'] = train_data.apply(lambda row: row.readability_object['sentence info']['type_token_ratio'], axis=1)\nX.loc[:,'characters'] = train_data.apply(lambda row: row.readability_object['sentence info']['characters'], axis=1)\nX.loc[:,'syllables'] = train_data.apply(lambda row: row.readability_object['sentence info']['syllables'], axis=1)\nX.loc[:,'words'] = train_data.apply(lambda row: row.readability_object['sentence info']['words'], axis=1)\nX.loc[:,'wordtypes'] = train_data.apply(lambda row: row.readability_object['sentence info']['wordtypes'], axis=1)\nX.loc[:,'sentences'] = train_data.apply(lambda row: row.readability_object['sentence info']['sentences'], axis=1)\nX.loc[:,'long_words'] = train_data.apply(lambda row: row.readability_object['sentence info']['long_words'], axis=1)\nX.loc[:,'complex_words'] = train_data.apply(lambda row: row.readability_object['sentence info']['complex_words'], axis=1)\nX.loc[:,'complex_words_dc'] = train_data.apply(lambda row: row.readability_object['sentence info']['complex_words_dc'], axis=1)\nX.loc[:,'tobeverb'] = train_data.apply(lambda row: row.readability_object['word usage']['tobeverb'], axis=1)\nX.loc[:,'auxverb'] = train_data.apply(lambda row: row.readability_object['word usage']['auxverb'], axis=1)\nX.loc[:,'conjunction'] = train_data.apply(lambda row: row.readability_object['word usage']['conjunction'], axis=1)\nX.loc[:,'pronoun'] = train_data.apply(lambda row: row.readability_object['word usage']['pronoun'], axis=1)\nX.loc[:,'preposition'] = train_data.apply(lambda row: row.readability_object['word usage']['preposition'], axis=1)\nX.loc[:,'nominalization'] = train_data.apply(lambda row: row.readability_object['word usage']['nominalization'], axis=1)","c5411eef":"X.info()\nX.head()","8ba92f1d":"corr = X.corr()\ncorr.info()\ncorr","b67429c2":"fig, ax =plt.subplots(figsize=(8, 6))\nplt.title(\"Correlation Plot\")\nsns.heatmap(corr,\n            mask=np.zeros_like(corr, dtype=np.bool),\n            cmap=sns.diverging_palette(220, 10, as_cmap=True),\n            square=True, ax=ax)\nplt.show()","a9152560":"tar_corr = pd.merge(X, train_data['target'], left_index=True, right_index=True).corr().loc['target']\ntar_corr","a605f185":"As expected, the readability grades are highly correlated with each other. So, using some or all of them will increase redundancy. Therefore, we will chose a single best readability grade, the one which is most correlated with target variable.","5a7f8788":"In this notebook, I will be making observations regarding the data provided in the [CommonLit Readability Prize](https:\/\/www.kaggle.com\/c\/commonlitreadabilityprize\/overview).\n\nI have made some submissions in the competitions.\n- [Decision Tree with score 0.941](https:\/\/www.kaggle.com\/aniketsharma00411\/commonlit-readability-decision-tree)\n- [Random Forest with score 0.780](https:\/\/www.kaggle.com\/aniketsharma00411\/commonlit-readability-random-forest)\n\nI will be using the observations I make in this notebook to improve these models and create further better models using other Regression techniques.\n\nAs in the other notebooks, I will be using the [readability](https:\/\/pypi.org\/project\/readability\/) Python package to create features from excerpts.","ddcfa44a":"The readability module provides 9 readability grades. By definition none of these are better than other.\n\nSo, to decide which one to use we will calculate a correlation matrix of these with our target value and then take the grade with the higest correlation value.","648b5e79":"# Functions","1b5f72c3":"Now, we will take all the features readabiltiy module can give us and then remove them by calculating their correlation with each other and with the target variable.","c1ec6220":"I am using the [readability](https:\/\/pypi.org\/project\/readability\/) and [syntok](https:\/\/pypi.org\/project\/syntok\/) to evaluate readability of each excerpt and [textblob](https:\/\/pypi.org\/project\/textblob\/) for sentiment analysis.","cf609bb5":"# Initialization","022874a2":"We can see that following groups of features has high correlation\n - characters_per_word and syll_per_word\n - characters and syllables\n - long_words, complex_words and complex_words_dc\n - sentences and sentences_per_paragraph\n \nSo, for all these three groups, we can only take one features.","8a6c97dc":"Correlations of features with target are **not very high** but still reasonable.\n\nWe can still remove features with very less correlation values like sentiment.","7121df8b":"# Creating Features","718939aa":"**SMOGIndex** is the most correlated with the target variable. So, it is best to use it for training."}}