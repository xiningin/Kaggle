{"cell_type":{"d9263411":"code","7143ce12":"code","10bb776b":"code","7bd08837":"code","60608d1c":"code","432ddc79":"code","dad36258":"code","4707739d":"code","fc90a60c":"code","5fff1993":"code","6f72e8f2":"code","86c40fa3":"code","9e879f32":"code","473a38b2":"markdown","bfd14105":"markdown","36235016":"markdown"},"source":{"d9263411":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom itertools import combinations\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7143ce12":"d_full = df = pd.read_csv(\n    '\/kaggle\/input\/real-time-advertisers-auction\/Dataset.csv',\n    parse_dates=[\"date\"]\n)\n","10bb776b":"d_full.shape","7bd08837":"d_full.info()","60608d1c":"d_full.describe()","432ddc79":"feats_const = []\nfeats_empty = []\nfeats_rare = []\nthr = int(d_full.shape[0]*.05)\nfor col in d_full:\n    v_counts = dict(d_full[col].value_counts())\n    v_min = min(v_counts.values())\n    v_max = max(v_counts.values())\n    if len(v_counts)==0:\n        feats_empty.append(col)\n    elif len(v_counts)==1:\n        feats_const.append(col)\n    if v_max<thr:\n        feats_rare.append(col)\n    print(f\"{col}: {len(v_counts)}\")\n#     elif len(v_counts)<=20:\n#         feats_cat.append(col)\n#         print(f\"{col}: {v_counts}\")\nprint(f\"rare={feats_rare}\")\nprint(f\"empty={feats_empty}\")\nprint(f\"const={feats_const}\")\n","dad36258":"d_full.head(5)","4707739d":"# target computation\ntarget = \"CPM\"\n\n#calculating CPM\n#calculating the value that the Advertisers Bid for the month of June\n# CPM(the value which was the winning bid value) = \n#((revenue of the publisher*100)\/revenue_share_percentage)\/measurable_impressions)*1000\n\ndef weird_division(n, d):\n    return n \/ d if d else 0\n\nd_full['CPM'] = d_full.apply(\n    lambda x: weird_division(((x['total_revenue']*100)),x['measurable_impressions'])*1000 , \n    axis=1\n)\n\nd_full = d_full[d_full.CPM >= 0].reset_index(drop=True)\n","fc90a60c":"d_full[\"wday\"] = d_full.date.dt.weekday","5fff1993":"feats_cat = [\n    'ad_type_id',\n    'ad_unit_id',\n    'advertiser_id',\n    'device_category_id',\n    'geo_id',\n    'integration_type_id',\n    'line_item_type_id',\n    'os_id',\n    'site_id',\n    \"wday\"\n]\nfeats_num = [\n    'measurable_impressions', \n    'total_impressions', \n    'viewable_impressions',            \n]\n\n\nfor arg1, arg2 in combinations(feats_num, 2):\n    col_trg = f\"{arg1}\/{arg2}\"\n    d_full[col_trg] = d_train[arg1]\/d_train[arg2]\n    feats_num.append(col_trg)\n    \n    col_trg = f\"{arg1}*{arg2}\"\n    d_full[col_trg] = d_train[arg1]*d_train[arg2]\n    feats_num.append(col_trg)\n\nfor num, den in combinations(feats_cat, 2):\n    col_trg = f\"{num}*{den}\"\n    d_full[col_trg] = d_train[num]*d_train[den]\n    feats_cat.append(col_trg)\n\n\nfeats = feats_cat + feats_num","6f72e8f2":"d_train = d_full[d_full.date < '2019-06-22'].reset_index(drop=True)\nd_test = d_full[d_full.date >= '2019-06-22'].reset_index(drop=True)\n\nd_train = d_train[d_train.CPM<d_train.CPM.quantile(.95)].reset_index(drop=True)\nd_test = d_test[d_test.CPM<d_test.CPM.quantile(.95)].reset_index(drop=True)\n","86c40fa3":"prm_lgb = {\n    'n_estimators': 300, \n    'learning_rate': 0.07, \n    'num_leaves': 60,\n    \n    'reg_alpha': 0.5,\n    'reg_lambda': 0.5, \n\n    'objective': 'tweedie', \n    'tweedie_variance_power': 1.25,\n}\n\nest = lgb.LGBMRegressor(**prm_lgb)\n\nest.fit(\n    d_train[feats], d_train[target], \n    eval_metric=['mse'], \n    categorical_feature=feats_cat\n)","9e879f32":"mean_squared_error(\n    y_true=d_test[target],\n    y_pred=est.predict(d_test[feats]), \n)\n","473a38b2":"# 1. Common info","bfd14105":"# 2. Data preparation","36235016":"# 3. Prediction"}}