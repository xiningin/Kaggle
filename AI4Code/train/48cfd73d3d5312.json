{"cell_type":{"d5983774":"code","f4a1f251":"code","b3f69dd0":"code","855bc53d":"code","138d67fb":"code","fa63a31e":"code","5ec0b964":"markdown","cef72ab1":"markdown","213b17de":"markdown"},"source":{"d5983774":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f4a1f251":"import os\nimport cv2 as cv\nimport sys\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimg = cv.imread(\"\/kaggle\/input\/fruits\/fruits-360_dataset\/fruits-360\/Training\/Quince\/73_100.jpg\")\n\n#opencv uses BGR colours, so they're in the wrong order for matplotlib, which uses RGB. Switch to the matplotlib format to display\nRGB_img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n\nplt.imshow(RGB_img)\nplt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\nplt.show()","b3f69dd0":"from fastai.vision.all import *\nimport random\nrandom.seed(55)\n\n#define the root path of the images, which is just our input folder here on Kaggle\npath = '\/kaggle\/input'\n\nimages = get_image_files(path)\n\ndef label_func(image_path):\n    \"\"\"Process and return the folder in which the image to be loaded is found.\"\"\"\n    name = image_path.parent.name.replace('_', ' ').split()\n    name = [x.title() for x in name if not x.isdigit()]\n    name = ' '.join(name)\n    return name\n\n#load the images into an ImageDataLoaders object. We resize everything to 224px, and keep 20% as the validation set. \n#We could use set batch_tfms=aug_transforms() if we wanted more training data, but we should have enough for a good result.\n#dls = ImageDataLoaders.from_path_func(path, random.sample(images, int(len(images)\/5)), label_func, item_tfms=Resize(224), valid_pct=0.2) #shorter experimental data\ndls = ImageDataLoaders.from_path_func(path, images, label_func, item_tfms=Resize(224), valid_pct=0.2) #full data\n\n#take a look at a sample of the images, with labels\ndls.show_batch()","855bc53d":"learn = cnn_learner(dls, resnet34, metrics=error_rate)\nlearn.fine_tune(1)","138d67fb":"learn.predict(images[-1])","fa63a31e":"learn.show_results()","5ec0b964":"# Identifying Images of Fruit\n\nIn this project, we will be using a simple implementation of fastai methods to classify the different kinds of fruit from the images. Let's start by taking a look at the data.","cef72ab1":"We can now get the file names with fastai's get_image_files function, and use those to load the images into an ImageDataLoader object. Since the folder names are the labels, we need to create a label function that retrieves that. Since there is some variation in capitalisation and format between titles - in particular, some have labels like Apple_1 - we also want to cut out numbers and underscores.\n\nWhen we load the images, we're going to resise them to fit the model that will be used in our classifier. In this case, that's resnet34, so we resize them to 224px squares. This also means that we don't have to worry about the different image sizes present in the dataset.","213b17de":"And now for the actual training - we have enough data to get good results with minimal epochs, which is good because training with that many images takes a while."}}