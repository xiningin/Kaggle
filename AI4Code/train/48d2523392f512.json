{"cell_type":{"c4f2bf7b":"code","a62e1959":"code","f0e055f1":"code","0196f086":"code","8a5b8f26":"code","3717e31f":"code","c15aef4b":"code","5bc66525":"code","661913de":"code","82f1324a":"code","8bc40cb5":"code","0ba2e6f2":"code","43704cc4":"code","c8b450b7":"code","ca638e59":"code","977ee088":"code","73bfbc6b":"code","4aeafc7e":"code","afd28b7f":"code","55442c8d":"code","10b20c91":"code","69779f8e":"code","148a508f":"code","ed1792e7":"code","0b3b7c53":"code","61775778":"code","99d146cb":"code","9f0eb33c":"code","61418ba1":"code","36407d9d":"code","f540e6ff":"code","bb0d396f":"code","095d63ee":"code","9f0c3b64":"code","651de641":"code","fb7bf4cd":"code","409277e8":"code","062f2072":"code","6685a68f":"code","c3b2c59a":"code","6af8b118":"code","29196b7b":"code","afbb196d":"code","e9be4445":"code","2c55c58b":"code","5c03fb16":"code","3fe99199":"code","9c1074b6":"code","1ba87332":"code","e3b7da90":"markdown","40abe8ab":"markdown","20bae35f":"markdown","4451b396":"markdown","50dfbdd0":"markdown","a7430eac":"markdown","5d694ee8":"markdown","6c40e81f":"markdown","66b8302b":"markdown","db22906b":"markdown","e538f432":"markdown","fc85aa13":"markdown","ad8d5c4b":"markdown","4aa7dbc1":"markdown","dca57c7c":"markdown","9e33845e":"markdown","8250c55e":"markdown"},"source":{"c4f2bf7b":"!nvidia-smi","a62e1959":"!conda install '\/kaggle\/input\/pydicom-conda-helper\/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y\n\n!pip install --no-deps -U ..\/input\/pytorch-image-models\/\n!pip install --no-deps -U ..\/input\/effdet-latestvinbigdata-wbf-fused\/omegaconf-2.0.6-py3-none-any.whl\n!pip install --no-deps -U ..\/input\/effdet-latestvinbigdata-wbf-fused\/pycocotools-2.0.2\/\n!pip install --no-deps -U ..\/input\/efficientdetpytorch\/\n!pip install --no-deps -U ..\/input\/ensemble-boxes-104\/ensemble_boxes-1.0.4\n!pip install \/kaggle\/input\/mishcuda\/mish-cuda\/\n\n!pip install '\/kaggle\/input\/mmdetectionv2140\/addict-2.4.0-py3-none-any.whl' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/yapf-0.31.0-py2.py3-none-any.whl' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/terminal-0.4.0-py3-none-any.whl' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/terminaltables-3.1.0-py3-none-any.whl' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/mmcv_full-1_3_8-cu110-torch1_7_0\/mmcv_full-1.3.8-cp37-cp37m-manylinux1_x86_64.whl' --no-deps\n!pip install '\/kaggle\/input\/mmdetectionv2140\/mmpycocotools-12.0.3\/mmpycocotools-12.0.3' --no-deps\n\n!cp -r \/kaggle\/input\/mmdetectionv2140\/mmdetection-2.14.0 \/kaggle\/working\/\n!mv \/kaggle\/working\/mmdetection-2.14.0 \/kaggle\/working\/mmdetection\n!pip install -e '\/kaggle\/working\/mmdetection\/'","f0e055f1":"import sys, warnings, pandas\npandas.reset_option(\"all\")\nwarnings.filterwarnings('ignore')\nsys.path.append('..\/input\/siimfisabiorsna-covid19-checkpoints\/pytorch-toolbelt\/pytorch-toolbelt-develop\/')\nsys.path.append('..\/input\/ttach-pytorch\/')\nsys.path.append('..\/input\/siim-code\/classification_code\/')\nsys.path.append('.\/mmdetection\/')","0196f086":"import gc, json, cv2\n\nimport albumentations as albu\nfrom albumentations.pytorch import ToTensorV2\n\nfrom tqdm.auto import tqdm\nfrom fastai.vision.all import *\nfrom fastai.medical.imaging import get_dicom_files\n\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\nimport ttach as tta\nfrom timm.models import load_checkpoint\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom src.defaults import get_cfg\nfrom src.models import build_model, create_backbone\nfrom heng_inference_binary_multiaux_final import Net,\\\n     BenchPredictHengBinary","8a5b8f26":"df = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\nif df.shape[0] == 2477:\n    fast_sub = True\nelse:\n    fast_sub = False\nprint(fast_sub)","3717e31f":"filepaths = get_dicom_files(\"\/kaggle\/input\/siim-covid19-detection\/test\/\", recurse=True)\nif fast_sub:\n    filepaths = filepaths[:5]\ntest_df = pd.DataFrame({'filepath': filepaths.map(lambda x: str(x))})\ntest_df['image_id'] = test_df.filepath.map(lambda x: str(x).split('\/')[-1].replace('.dcm', '') + '_image')\ntest_df['study_id'] = test_df.filepath.map(lambda x: str(x).split('\/')[-3].replace('.dcm', '') + '_study')\ndisplay_df(test_df.head())","c15aef4b":"label2name   = {0: 'atypical', 1: 'indeterminate', 2: 'negative', 3: 'typical'}\nclass_labels = ['0', '1', '2', '3']\n\nIMG_SIZE  = 1024\nTEST_PATH = '\/kaggle\/tmp\/test\/'\nos.makedirs(TEST_PATH, exist_ok=True)","5bc66525":"def read_xray(path, voi_lut = True, fix_monochrome = True):\n    dicom = pydicom.read_file(path)\n    if voi_lut: \n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else: \n        data = dicom.pixel_array\n        \n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8) \n    return data\n\ndef resize(array, size, keep_ratio=True, resample=Image.LANCZOS):\n    im = Image.fromarray(array)\n    if keep_ratio: \n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    return im\n\ndef resize_and_save(file_path):\n    base_dir = TEST_PATH\n    xray = read_xray(file_path)\n    img  = resize(xray, IMG_SIZE, keep_ratio=True)\n    filename = file_path.split('\/')[-1].split('.')[0]\n    img.save(os.path.join(base_dir, f'{filename}.png'))\n    return filename.replace('dcm','') + '_image', xray.shape[0], xray.shape[1]\n\ndef serialize(paths):\n    info = []\n    dim0 = []\n    dim1 = []\n    iterator = tqdm(paths, total=len(paths), dynamic_ncols=True )\n    for idx , p in enumerate(iterator): \n        i, d0, d1 = resize_and_save(p)\n        info.append(i)  \n        dim0.append(d0)\n        dim1.append(d1)\n    return info, dim0, dim1","661913de":"filepaths = test_df.filepath.iloc[:test_df.shape[0]]\n(info, dim0, dim1) = serialize(filepaths)","82f1324a":"df = pd.DataFrame({'image_id': list(info)})\ndf['image_path'] = TEST_PATH + df.image_id.map(lambda x: x.replace('_image','')) + '.png'\ndf['dim0'] = list(dim0)\ndf['dim1'] = list(dim1)\n\ntest_df = pd.merge(test_df, df, on='image_id', how='left')\ntest_df.drop(columns=['filepath'], inplace=True)\ndisplay_df(test_df.head())","8bc40cb5":"image_df = test_df.drop(columns=[\"study_id\"], inplace=False)\nstudy_df = test_df.drop(columns=[\"image_id\"], inplace=False)\ntest_df.loc[:, class_labels] = 0\ndisplay_df(test_df.head())","0ba2e6f2":"class LoadImages(Dataset):\n    def __init__(self, df, transform):\n        self.file_names = L(list(df.image_path.iloc[:test_df.shape[0]]))\n        self.transform  = transform\n\n    def __len__(self): \n        return len(self.file_names)\n\n    def __getitem__(self, idx):\n        file_name = self.file_names[idx]\n        assert os.path.exists(file_name)\n        image = cv2.imread(file_name)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = self.transform(image=image)['image']\n        return image\n    \ndef pre_processing(sz, *args, **kwargs):\n    return albu.Compose([\n        albu.Resize(sz, sz), \n        albu.ToFloat(p=1.0, max_value=255.0), \n        ToTensorV2(p=1.0)\n    ])\n\ndef get_tta_transforms(): \n    return tta.Compose([tta.HorizontalFlip()])\n\n\nclass BenchPredict(nn.Module):\n    def __init__(self, model):\n        super(BenchPredict, self).__init__()\n        self.model = model\n    \n    def forward(self, input):\n        logits = self.model(input)['output']\n        return F.softmax(logits)\n\n\n@torch.no_grad()\ndef get_preds(model, test_loader):\n    batch_probs = []\n    for i, (images) in enumerate(tqdm(test_loader, dynamic_ncols=True, leave=False)):\n        images = images.cuda()\n        y_preds= model(images)\n        batch_probs.append(y_preds)\n        del y_preds, images\n        gc.collect()\n        torch.cuda.empty_cache()\n    return torch.cat(batch_probs).data.cpu().numpy()\n\n@delegates(load_checkpoint)\ndef make_model(cfg, state, **kwargs):\n    model = build_model(cfg)\n    load_checkpoint(model, state, **kwargs)\n    bench = BenchPredict(model=model)\n    bench.cuda()\n    bench.eval()\n    return bench\n\ndef get_PredictionString(row, df, thr=0.0):\n    string = ''\n    for idx in list(df.columns[1:]):\n        conf =  row[idx]\n        if conf>thr:\n            string += f'{idx} {conf:.6f} 0 0 1 1 '\n    string = string.strip()\n    return string","43704cc4":"used_models = [\n    '..\/input\/studymodelsbest\/001cf4cc-8939v2l_noisy_Fine\/fold1\/model_best.pth.tar',\n    '..\/input\/studymodelsbest\/001cf4cc-8939v2l_noisy_Fine\/fold3\/model_best.pth.tar',\n    '..\/input\/studymodelsbest\/001cf4cc-8939v2l_noisy_Fine\/fold4\/model_best.pth.tar',\n    '..\/input\/studymodelsbest\/001cf4cc-8939v2m_noisy640\/fold0\/model_best.pth.tar',\n    '..\/input\/studymodelsbest\/7f8543b6-6957eb5_Noisy\/fold2\/model_best.pth.tar',\n    \n    '..\/input\/studymodelsbest\/7f8543b6-6957eb7_noisy640_Fine\/fold3\/model_best.pth.tar',\n    \n    '..\/input\/study-models-best-part2\/6957eb7_noisy640_Fine\/fold2\/model_best.pth.tar',\n    '..\/input\/study-models-best-part2\/8939v2l_640_rotate\/fold1\/model_best.pth.tar',\n    '..\/input\/study-models-best-part2\/8939v2l_noisy512_50_hard\/fold3\/model_best.pth.tar',\n    '..\/input\/study-models-best-part2\/8939v2l_noisy_512_rotate_Fine\/fold4\/model_best.pth.tar',\n    '..\/input\/study-models-best-part2\/8939v2m_1024_noisy\/fold0\/model_best.pth.tar',\n]\n    \nconfigs = [    \n    '..\/input\/studymodelsbest\/001cf4cc-8939v2l_noisy_Fine\/fold1\/config.yaml',\n    '..\/input\/studymodelsbest\/001cf4cc-8939v2l_noisy_Fine\/fold3\/config.yaml',\n    '..\/input\/studymodelsbest\/001cf4cc-8939v2l_noisy_Fine\/fold4\/config.yaml',\n    '..\/input\/studymodelsbest\/001cf4cc-8939v2m_noisy640\/fold0\/config.yaml',\n    '..\/input\/studymodelsbest\/7f8543b6-6957eb5_Noisy\/fold2\/config.yaml',\n    \n    '..\/input\/studymodelsbest\/7f8543b6-6957eb7_noisy640_Fine\/fold3\/config.yaml',\n    \n    '..\/input\/study-models-best-part2\/6957eb7_noisy640_Fine\/fold2\/config.yaml',\n    '..\/input\/study-models-best-part2\/8939v2l_640_rotate\/fold1\/config.yaml',\n    '..\/input\/study-models-best-part2\/8939v2l_noisy512_50_hard\/fold3\/config.yaml',\n    '..\/input\/study-models-best-part2\/8939v2l_noisy_512_rotate_Fine\/fold4\/config.yaml',\n    '..\/input\/study-models-best-part2\/8939v2m_1024_noisy\/fold0\/config.yaml'\n]\n\npreds = []\n\nfor c, chkpt in tqdm(zip(configs, used_models), total=len(used_models), dynamic_ncols=True):\n    CFG = get_cfg()\n    CFG.merge_from_file(c)\n    CFG.MODEL.BACKBONE.PRETRAINED = False\n\n    transform = pre_processing(sz=CFG.INPUT.INPUT_SIZE)\n    dset = LoadImages(test_df, transform=transform)\n    dl = DataLoader(dset, batch_size=16)\n    \n    model = make_model(CFG, chkpt)\n    ttas = get_tta_transforms()\n    model = tta.ClassificationTTAWrapper(model, ttas) \n    \n    predict = get_preds(model, dl)\n    preds.append(predict)\n    \n    del model, dl,dset, predict\n    gc.collect(); torch.cuda.empty_cache()","c8b450b7":"used_models = [\n    '..\/input\/siimfisabiorsna-covid19-checkpoints\/8f5d9473-4fda\/tf_efficientnetv2_m_in21ft1k_pcam_4x_512_auxv1_mish_sam_ns_fold0-8f5d9473-4fda.pth.tar',\n    '..\/input\/siimfisabiorsna-covid19-checkpoints\/8f5d9473-4fda\/tf_efficientnetv2_m_in21ft1k_pcam_4x_512_auxv1_mish_sam_ns_fold1-8f5d9473-4fda.pth.tar',\n    '..\/input\/siimfisabiorsna-covid19-checkpoints\/8f5d9473-4fda\/tf_efficientnetv2_m_in21ft1k_pcam_4x_512_auxv1_mish_sam_ns_fold2-8f5d9473-4fda.pth.tar',\n    '..\/input\/siimfisabiorsna-covid19-checkpoints\/8f5d9473-4fda\/tf_efficientnetv2_m_in21ft1k_pcam_4x_512_auxv1_mish_sam_ns_fold3-8f5d9473-4fda.pth.tar',\n    '..\/input\/siimfisabiorsna-covid19-checkpoints\/8f5d9473-4fda\/tf_efficientnetv2_m_in21ft1k_pcam_4x_512_auxv1_mish_sam_ns_fold4-8f5d9473-4fda.pth.tar',\n\n]\n    \nconfigs = [\n    '..\/input\/siimfisabiorsna-covid19-checkpoints\/8f5d9473-4fda\/config.yml',\n    '..\/input\/siimfisabiorsna-covid19-checkpoints\/8f5d9473-4fda\/config.yml',\n    '..\/input\/siimfisabiorsna-covid19-checkpoints\/8f5d9473-4fda\/config.yml',\n    '..\/input\/siimfisabiorsna-covid19-checkpoints\/8f5d9473-4fda\/config.yml',\n    '..\/input\/siimfisabiorsna-covid19-checkpoints\/8f5d9473-4fda\/config.yml'\n]\n\nv2m_preds = []\n\nfor c, chkpt in tqdm(zip(configs, used_models), total=len(used_models), dynamic_ncols=True):\n    CFG = get_cfg()\n    CFG.merge_from_file(c)\n    CFG.MODEL.BACKBONE.PRETRAINED = False\n\n    transform = pre_processing(sz=CFG.INPUT.INPUT_SIZE)\n    dset = LoadImages(test_df, transform=transform)\n    dl = DataLoader(dset, batch_size=16)\n    \n    model = make_model(CFG, chkpt)\n    model = tta.ClassificationTTAWrapper(model, get_tta_transforms()) \n    \n    predict = get_preds(model, dl)\n    v2m_preds.append(predict)\n    \n    del model, dl,dset, predict\n    torch.cuda.empty_cache(); gc.collect()","ca638e59":"@delegates(load_checkpoint)\ndef load_binary_model(state, **kwargs):\n    model = Net()\n    load_checkpoint(model, state, **kwargs)\n    bench = BenchPredictHengBinary(binary_model=model)\n    bench.cuda()\n    bench.eval()\n    return bench","977ee088":"used_models = [\n    '..\/input\/covid-binary-models\/eb6ns_512_binary_multimask_noisy_new\/eb6ns_512_binary_multimask_noisy_fold0_1374.pth',\n    '..\/input\/covid-binary-models\/eb6ns_512_binary_multimask_noisy_new\/eb6ns_512_binary_multimask_noisy_fold1_1408_ext.pth',\n    '..\/input\/covid-binary-models\/eb6ns_512_binary_multimask_noisy_new\/eb6ns_512_binary_multimask_noisy_fold2_1376_ext.pth',\n    '..\/input\/covid-binary-models\/eb6ns_512_binary_multimask_noisy_new\/eb6ns_512_binary_multimask_noisy_fold3_1377_ext.pth',\n    '..\/input\/covid-binary-models\/eb6ns_512_binary_multimask_noisy_new\/eb6ns_512_binary_multimask_noisy_fold4_1343.pth',\n]\n\nbinary_preds = []\n\nfor chkpt in tqdm(used_models, total=len(used_models), dynamic_ncols=True):\n\n    transform = pre_processing(sz=512)\n    dset = LoadImages(test_df, transform=transform)\n    dl   = DataLoader(dset, batch_size=16)\n\n    ttas  = get_tta_transforms() \n    \n    model = load_binary_model(chkpt)\n    model = tta.ClassificationTTAWrapper(model, ttas) \n    \n    predict = get_preds(model, dl)\n    binary_preds.append(predict)\n    \n    del model, dl, dset, predict\n    torch.cuda.empty_cache()\n    gc.collect()","73bfbc6b":"final_mix_preds_study = np.mean(preds, axis=0)\nfinal_v2m_preds_study = np.mean(v2m_preds, axis=0)\nstudy_final_preds = 0.85*final_mix_preds_study + 0.15*final_v2m_preds_study\n\ntest_df.loc[:test_df.shape[0], class_labels] = study_final_preds\nstudy_df = test_df.groupby(['study_id'])[class_labels].mean().reset_index()\nstudy_df.rename(columns={'study_id': 'id'}, inplace=True)\nstudy_df.columns = ['id',\"atypical\", \"indeterminate\", \"negative\", \"typical\"]\n\nstudy_df['PredictionString'] = study_df.apply(partial(get_PredictionString, df=study_df), axis=1)\nstudy_df.to_csv('.\/study_df.csv', index=False)\ndisplay_df(study_df.head())","4aeafc7e":"# Mean of 5 fold binary model predictions\nbinary_predictions = np.mean(binary_preds, axis=0)\n# Store binary predictions\ntest_df.loc[:test_df.shape[0], 'none'] = binary_predictions\n# Prepare a dataframe with only none predictions\nbin_df = test_df[[\"study_id\", \"image_id\", \"none\"]]\n# Sort values to ensure same indices\nbin_df = bin_df.sort_values(by='image_id', ascending=True)\nbin_df.head()","afd28b7f":"# Mean of 5 fold v2m predictions\nclass_labels = [\"atypical\", \"indeterminate\", \"negative\", \"typical\"]\npreds2 = np.mean(v2m_preds, axis=0)\ntest_df.loc[:test_df.shape[0], class_labels] = preds2\n# Store v2m predictions\nv2m_df = test_df[[\"study_id\", \"image_id\", \"negative\"]]\n# Prepare a dataframe with only none predictions\nv2m_df = v2m_df.rename(columns=dict(negative='none'), inplace=False)\n# Sort values to ensure same indices\nv2m_df = v2m_df.sort_values(by='image_id', ascending=True)\nv2m_df.head()","55442c8d":"binary_submission = v2m_df.copy()\nbinary_submission['none'] = 0.6*v2m_df['none'].values + 0.4*bin_df['none'].values\n\nbinary_submission = binary_submission.reset_index(inplace=False, drop=True)\nbinary_submission.to_csv('.\/binary_submission.csv', index=False)\ndisplay_df(binary_submission.head())","10b20c91":"def format_prediction_string(boxes, scores, labels):\n    \"generate a single prediction string given boxes, scores and labels\"\n    pred_strings = []\n    if len(boxes) > 0 :\n        for j in zip(labels, scores, boxes):\n            pred_strings.append(\"opacity {0:.4f} {1} {2} {3} {4}\".format(j[1], j[2][0], j[2][1], j[2][2], j[2][3]))\n    else:\n        pred_strings.append(\"none 1 0 0 1 1\")\n    return \" \".join(pred_strings)\n\n\ndef write_submission(test_images_ids, result_boxes, result_scores, result_labels, score_thr):\n    \"write submissions in pandas dataframe format\"\n    results = []\n    \n    for i, image in enumerate(test_images_ids):\n        image_id   = test_images_ids[i]\n        cur_boxes  = np.array(result_boxes[i])\n        cur_scores = np.array(result_scores[i])\n        cur_labels = np.array(result_labels[i])\n\n        score_filter = cur_scores >= score_thr\n        cur_boxes    = cur_boxes[score_filter]\n        cur_scores   = cur_scores[score_filter]\n        cur_labels   = cur_labels[score_filter]\n        \n        result = {'image_id': image_id, 'PredictionString': format_prediction_string(cur_boxes, cur_scores, cur_labels)}\n        results.append(result)\n    \n    return pd.DataFrame(results, columns=['image_id', 'PredictionString'])","69779f8e":"from ensemble_boxes import *\nfrom effdet import unwrap_bench\nfrom effdet import create_model as create_det\nfrom effdet.config import get_efficientdet_config","148a508f":"class LoadDetectionDatset(Dataset):\n    \"\"\"Object Detection Dataset\"\"\"\n    def __init__(self, image_paths, augmentations, img_size):\n        self.image_paths = image_paths\n        self.augmentations = augmentations\n        self.img_size = img_size\n        \n    def __len__(self): \n        return len(self.image_paths)\n    \n    def __getitem__(self, index: int):\n        image_path = self.image_paths[index]\n        image = cv2.cvtColor(cv2.imread(str(image_path)), cv2.COLOR_BGR2RGB)\n        image = self.augmentations(image=image)['image']\n        \n        image_id = str(image_path).split(os.path.sep)[-1].split('.')[0] + '_image'\n        ann = dict(img_idx=index, img_size=self.img_size)\n        return image, ann, image_id","ed1792e7":"@torch.no_grad()        \ndef make_predictions(dl, net, score_threshold=0.001):\n    predictions = {}\n    \n    for batch in tqdm(dl, dynamic_ncols=True, smoothing=0):\n        image, ann, image_id = batch\n        images = torch.stack(image).cuda().float()\n        \n        target = {}\n        target['img_scale'] = torch.tensor([1]*images.shape[0]).float().cuda()\n        target['img_size']  = torch.tensor([a['img_size'] for a in ann]).cuda().float()\n\n        with torch.no_grad():\n            det = net(images, img_info=target)\n            for i in range(images.shape[0]):\n                boxes  = det[i].detach().cpu().numpy()[:,:4]    \n                scores = det[i].detach().cpu().numpy()[:,4]\n                indexes= np.where(scores > score_threshold)[0]\n                boxes  = boxes[indexes]\n                predictions[image_id[i]] = ({'boxes': boxes[indexes], 'scores': scores[indexes]})\n    return predictions","0b3b7c53":"@delegates(weighted_boxes_fusion)\ndef merge_boxes_from_models(all_models_boxes, all_models_scores, all_models_labels,n_images, **kwargs):\n    n_variants = len(all_models_boxes)\n    assert len(all_models_scores) == n_variants\n    assert len(all_models_labels) == n_variants\n    \n    print(len(all_models_boxes), len(all_models_scores), len(all_models_labels))\n\n    result_boxes  = []\n    result_scores = []\n    result_labels = []\n    \n    for ii in tqdm(range(n_images), dynamic_ncols=True, smoothing=0):\n        pred_boxes  = []\n        pred_scores = []\n        pred_labels = []\n        max_value = 10000\n        \n        for vi in range(n_variants):\n            cur_pred_boxes  = np.array(all_models_boxes[vi][ii],  copy=False)\n            cur_pred_scores = np.array(all_models_scores[vi][ii], copy=False)\n            cur_pred_labels = np.array(all_models_labels[vi][ii], copy=False)\n            \n            cur_pred_boxes  = cur_pred_boxes \/ max_value\n\n            pred_boxes.append(cur_pred_boxes)\n            pred_scores.append(cur_pred_scores)\n            pred_labels.append(cur_pred_labels)\n\n        pred_boxes, pred_scores, pred_labels = weighted_boxes_fusion(\n            pred_boxes, pred_scores, pred_labels, **kwargs)\n        \n        pred_boxes = np.round(pred_boxes * max_value).astype(int)\n\n        assert len(pred_boxes) == len(pred_scores)\n        assert len(pred_boxes) == len(pred_scores)\n        assert len(pred_boxes) == len(pred_labels)\n        \n        result_boxes.append(pred_boxes)\n        result_scores.append(pred_scores)\n        result_labels.append(pred_labels)\n    \n    return result_boxes, result_scores, result_labels","61775778":"imagenames = image_df.image_path.values.tolist()\nimage_ids  = L(imagenames).map(lambda x: x.split(os.path.sep)[-1].split('.')[0] + '_image')\n\ndef collate_fn(batch): return tuple(zip(*batch))\n\nstates1 = [\n    '..\/input\/psuedo-models-covid\/d3_896_stage1_psuedo_ema\/model_best_d3_896_stage1_psuedo_fold0_5811.pth.tar',\n    '..\/input\/psuedo-models-covid\/d3_896_stage1_psuedo_ema\/model_best_d3_896_stage1_psuedo_fold1_5814.pth.tar',\n    '..\/input\/psuedo-models-covid\/d3_896_stage1_psuedo_ema\/model_best_d3_896_stage1_psuedo_fold2_6012.pth.tar',\n    '..\/input\/psuedo-models-covid\/d3_896_stage1_psuedo_ema\/model_best_d3_896_stage1_psuedo_fold3_5738.pth.tar',\n    '..\/input\/psuedo-models-covid\/d3_896_stage1_psuedo_ema\/model_best_d3_896_stage1_psuedo_fold4_6182.pth.tar',\n]\n    \nMODEL = 'tf_efficientdet_d3_ap'\nbase_conf = get_efficientdet_config(MODEL)\nSZ = 896\nprint(\"Image dims:\", SZ)\n    \ntest_transforms = pre_processing(SZ)\n\nds = LoadDetectionDatset(imagenames, test_transforms, img_size=[SZ, SZ])\ndl = DataLoader(ds, batch_size=12, num_workers=2, collate_fn=collate_fn)\n\n\npredictions = []\nfor i in tqdm(states1, dynamic_ncols=True):\n    bench = create_det(\n        model_name=MODEL, bench_task='predict', \n        num_classes=1, bench_labeler=True,\n        soft_nms=False, pretrained_backbone=False, \n        image_size = [SZ,SZ])\n    \n    load_checkpoint(unwrap_bench(bench), i, use_ema=True)\n    bench.cuda()\n    bench.eval() \n    \n    preds = make_predictions(dl, bench)\n    predictions.append(preds)\n    \n    del bench, preds\n    gc.collect()\n    torch.cuda.empty_cache()\n    \ndel ds, dl\ngc.collect()\ntorch.cuda.empty_cache()","99d146cb":"all_folds_boxes  = []\nall_folds_scores = []\nall_folds_labels = []\n\nfor prediction in tqdm(predictions, smoothing=0, dynamic_ncols=True,):\n    pred_boxes = []; pred_scores = []; pred_labels = []\n\n    for image_index in image_ids:\n        pred_boxes.append(prediction[image_index]['boxes'].tolist()) \n        pred_scores.append(prediction[image_index]['scores'].tolist())\n        pred_labels.append(np.ones(prediction[image_index]['scores'].shape[0]).tolist())\n    pred_boxes, pred_scores, pred_labels = np.array(pred_boxes), np.array(pred_scores), np.array(pred_labels)\n\n    for i, image in enumerate(image_ids):\n        image_id = image_ids[i]\n        image_height, image_width = image_df.loc[image_df.image_id == image_id, ['dim0', 'dim1']].values[0]\n\n        if len(pred_boxes[i]) > 0:\n            xscale = image_width \/ SZ\n            yscale = image_height \/ SZ\n            pred_boxes[i][:, [0, 2]] = (pred_boxes[i][:, [0, 2]] * xscale).astype(int)\n            pred_boxes[i][:, [1, 3]] = (pred_boxes[i][:, [1, 3]] * yscale).astype(int)\n\n    all_folds_boxes.append(pred_boxes)\n    all_folds_scores.append(pred_scores)\n    all_folds_labels.append(pred_labels)\n    \n    \nresult_boxes, result_scores, result_labels = merge_boxes_from_models(\n    all_folds_boxes, all_folds_scores, all_folds_labels, \n    n_images=len(image_ids), weights=None, iou_thr=0.60, conf_type='avg')\n\nd3_preds = write_submission(image_ids, result_boxes, result_scores, result_labels, score_thr=0.0001)\nd3_preds.to_csv('efdet2_sub1.csv',index=False)\nd3_preds.head()","9f0eb33c":"imagenames = image_df.image_path.values.tolist()\nimage_ids  = L(imagenames).map(lambda x: x.split(os.path.sep)[-1].split('.')[0] + '_image')\n\ndef collate_fn(batch): return tuple(zip(*batch))\n\nstates1 = [\n    '..\/input\/covid-models-new\/d5_stage1\/model_best_d5_fold0_5698.pth.tar',\n    '..\/input\/covid-models-new\/model_best_d5_fold1_5654_stage2.pth.tar',\n    '..\/input\/covid-models-new\/model_best_d5_fold2_6040_stage2.pth.tar',\n    '..\/input\/covid-models-new\/d5_stage1\/model_best_d5_fold3_5577.pth.tar',\n    '..\/input\/covid-models-new\/d5_stage1\/model_best_d5_fold4_6100.pth.tar'\n]\n    \nMODEL = 'tf_efficientdet_d5_ap'\nbase_conf = get_efficientdet_config(MODEL)\nSZ = 512\nprint(\"Image dims:\", SZ)\n    \ntest_transforms = pre_processing(SZ, norm=None)\n\nds = LoadDetectionDatset(imagenames, test_transforms, img_size=[SZ, SZ])\ndl = DataLoader(ds, batch_size=6, collate_fn=collate_fn)\n\npredictions = []\nfor i in tqdm(states1, dynamic_ncols=True):\n    bench = create_det(\n        model_name=MODEL, bench_task='predict', \n        num_classes=1, bench_labeler=True,\n        soft_nms=False, pretrained_backbone=False, \n        image_size = [SZ,SZ])\n    \n    load_checkpoint(unwrap_bench(bench), i, use_ema=True)\n    bench.cuda()\n    bench.eval() \n    \n    preds = make_predictions(dl, bench)\n    predictions.append(preds)\n    \n    del bench, preds\n    gc.collect()\n    torch.cuda.empty_cache()\n    \ndel ds, dl\ngc.collect()\ntorch.cuda.empty_cache()","61418ba1":"all_folds_boxes  = []\nall_folds_scores = []\nall_folds_labels = []\n\nfor prediction in tqdm(predictions, smoothing=0, dynamic_ncols=True,):\n    pred_boxes = []; pred_scores = []; pred_labels = []\n\n    for image_index in image_ids:\n        pred_boxes.append(prediction[image_index]['boxes'].tolist()) \n        pred_scores.append(prediction[image_index]['scores'].tolist())\n        pred_labels.append(np.ones(prediction[image_index]['scores'].shape[0]).tolist())\n    pred_boxes, pred_scores, pred_labels = np.array(pred_boxes), np.array(pred_scores), np.array(pred_labels)\n\n    for i, image in enumerate(image_ids):\n        image_id = image_ids[i]\n        image_height, image_width = image_df.loc[image_df.image_id == image_id, ['dim0', 'dim1']].values[0]\n\n        if len(pred_boxes[i]) > 0:\n            xscale = image_width \/ SZ\n            yscale = image_height \/ SZ\n            pred_boxes[i][:, [0, 2]] = (pred_boxes[i][:, [0, 2]] * xscale).astype(int)\n            pred_boxes[i][:, [1, 3]] = (pred_boxes[i][:, [1, 3]] * yscale).astype(int)\n\n    all_folds_boxes.append(pred_boxes)\n    all_folds_scores.append(pred_scores)\n    all_folds_labels.append(pred_labels)\n    \n    \nresult_boxes, result_scores, result_labels = merge_boxes_from_models(\n    all_folds_boxes, all_folds_scores, all_folds_labels, \n    n_images=len(image_ids), weights=None, iou_thr=0.60, conf_type='avg')\n\nd5_preds = write_submission(image_ids, result_boxes, result_scores, result_labels, score_thr=0.0001)\nd5_preds.to_csv('efdet2_sub2.csv',index=False)\nd5_preds.head()","36407d9d":"import sys\nsys.path.append('..\/input\/simmyolov5\/')\n\nSUB_DIR_1 = '\/kaggle\/tmp\/sub\/'\nSUB_DIR_2 = '\/kaggle\/tmp\/sub2\/'\n\nos.makedirs(SUB_DIR_1, exist_ok=True)\nos.makedirs(SUB_DIR_2, exist_ok=True)\nos.makedirs('\/kaggle\/working\/subm', exist_ok=True)","f540e6ff":"def txt2pandas(Idxs, fold,num,sub):\n    image_ids = []\n    PredictionStrings = []\n    \n    for Idx in tqdm(Idxs, dynamic_ncols=True):\n        H,W = image_df.loc[image_df.image_id == Idx, ['dim0', 'dim1']].values[0]\n        Idx = Idx.split('_')[0]\n        txt_label = os.path.join(sub, f'fold{fold}\/labels\/{Idx}.txt')\n        bboxes = []\n    \n        if os.path.isfile(txt_label):\n            in1 = open(txt_label, 'r')\n            lines = in1.readlines()\n            in1.close()\n\n            for line in lines:\n                arr = line.strip().split(' ')\n                class_id = 'opacity'\n                x = float(arr[1])\n                y = float(arr[2])\n                w = float(arr[3])\n                h = float(arr[4])\n                x1 = x - (w \/ 2)  \n                x2 = x + (w \/ 2)    \n                y1 = y - (h \/ 2)\n                y2 = y + (h \/ 2)\n                conf = arr[5]\n\n                x1 = int(round(x1 * W))\n                y1 = int(round(y1 * H))\n                x2 = int(round(x2 * W))\n                y2 = int(round(y2 * H))\n\n                bboxes.append(f\"{class_id} {conf} {x1} {y1} {x2} {y2}\")\n        else:\n            print(txt_label)\n            class_id = 'none'\n            conf = 1.0\n            [x1, y1, x2, y2] = [0, 0, 1, 1]\n            bboxes.append(f\"{class_id} {conf} {x1} {y1} {x2} {y2}\")\n\n        image_ids.append(Idx)\n        PredictionStrings.append(' '.join(bboxes))\n    \n    detections = pd.DataFrame()    \n    detections['image_id'] = image_ids\n    detections['image_id'] = detections['image_id'].map(lambda x: x + '_image')\n    detections['PredictionString'] = PredictionStrings\n    detections.to_csv(f'\/kaggle\/working\/subm\/yolo_fold{fold}{num}.csv', index=False)\n    print(f'Dataframe saved to \/kaggle\/working\/subm\/yolo_fold{fold}{num}.csv')","bb0d396f":"!python \/kaggle\/input\/simmyolov5\/detect.py --imgsz 640 --conf-thres 0.001 --iou-thres 0.5 \\\n        --save-txt --save-conf --exist-ok --nosave \\\n        --weights ..\/input\/psuedo-models-covid\/yolov5l6_640_psuedo\/yolov5l6_640_fold0.pt \\\n        --source {TEST_PATH} --project {SUB_DIR_1} --name fold0\n\n!python \/kaggle\/input\/simmyolov5\/detect.py --imgsz 640 --conf-thres 0.001 --iou-thres 0.5 \\\n        --save-txt --save-conf --exist-ok --nosave \\\n        --weights ..\/input\/psuedo-models-covid\/yolov5l6_640_psuedo\/yolov5l6_640_fold1.pt \\\n        --source {TEST_PATH} --project {SUB_DIR_1} --name fold1\n\n!python \/kaggle\/input\/simmyolov5\/detect.py --imgsz 640 --conf-thres 0.001 --iou-thres 0.5 \\\n        --save-txt --save-conf --exist-ok --nosave \\\n        --weights ..\/input\/psuedo-models-covid\/yolov5l6_640_psuedo\/yolov5l6_640_fold2.pt \\\n        --source {TEST_PATH} --project {SUB_DIR_1} --name fold2\n\n!python \/kaggle\/input\/simmyolov5\/detect.py --imgsz 640 --conf-thres 0.001 --iou-thres 0.5 \\\n        --save-txt --save-conf --exist-ok --nosave \\\n        --weights ..\/input\/psuedo-models-covid\/yolov5l6_640_psuedo\/yolov5l6_640_fold3.pt \\\n        --source {TEST_PATH} --project {SUB_DIR_1} --name fold3\n\n!python \/kaggle\/input\/simmyolov5\/detect.py --imgsz 640 --conf-thres 0.001 --iou-thres 0.5 \\\n        --save-txt --save-conf --exist-ok --nosave \\\n        --weights ..\/input\/psuedo-models-covid\/yolov5l6_640_psuedo\/yolov5l6_640_fold4.pt \\\n        --source {TEST_PATH} --project {SUB_DIR_1} --name fold4\n\n\nIdxs = image_df.image_id.values.tolist()\nfor i in range(0, 5):  txt2pandas(Idxs, i,0,SUB_DIR_1)\n!rm -r {SUB_DIR_1}","095d63ee":"!python \/kaggle\/input\/simmyolov5\/detect.py --imgsz 640 --conf-thres 0.001 --iou-thres 0.5 \\\n        --save-txt --save-conf --exist-ok --nosave \\\n        --weights ..\/input\/psuedo-models-covid\/yolov5x_640_psuedo\/yolov5x_640_fold0.pt  \\\n        --source {TEST_PATH} --project {SUB_DIR_2} --name fold0\n\n!python \/kaggle\/input\/simmyolov5\/detect.py --imgsz 640 --conf-thres 0.001 --iou-thres 0.5 \\\n        --save-txt --save-conf --exist-ok --nosave \\\n        --weights ..\/input\/psuedo-models-covid\/yolov5x_640_psuedo\/yolov5x_640_fold1.pt \\\n        --source {TEST_PATH} --project {SUB_DIR_2} --name fold1\n\n!python \/kaggle\/input\/simmyolov5\/detect.py --imgsz 640 --conf-thres 0.001 --iou-thres 0.5 \\\n        --save-txt --save-conf --exist-ok --nosave \\\n        --weights ..\/input\/psuedo-models-covid\/yolov5x_640_psuedo\/yolov5x_640_fold2.pt \\\n        --source {TEST_PATH} --project {SUB_DIR_2} --name fold2\n\n!python \/kaggle\/input\/simmyolov5\/detect.py --imgsz 640 --conf-thres 0.001 --iou-thres 0.5 \\\n        --save-txt --save-conf --exist-ok --nosave \\\n        --weights ..\/input\/psuedo-models-covid\/yolov5x_640_psuedo\/yolov5x_640_fold3.pt \\\n        --source {TEST_PATH} --project {SUB_DIR_2} --name fold3\n\n!python \/kaggle\/input\/simmyolov5\/detect.py --imgsz 640 --conf-thres 0.001 --iou-thres 0.5 \\\n        --save-txt --save-conf --exist-ok --nosave \\\n        --weights ..\/input\/psuedo-models-covid\/yolov5x_640_psuedo\/yolov5x_640_fold4.pt  \\\n        --source {TEST_PATH} --project {SUB_DIR_2} --name fold4\n\nfor i in range(0, 5): txt2pandas(Idxs, i,1, SUB_DIR_2)  \n    \n!rm -r {SUB_DIR_2}","9f0c3b64":"@delegates(weighted_boxes_fusion)\ndef run_wbf(subm_list, out_path=None, **kwargs):\n    max_value = 10000\n    preds   = []\n    checker = None\n    \n    for path in subm_list:\n        s = pd.read_csv(path)\n        s.sort_values('image_id', inplace=True)\n        s.reset_index(drop=True, inplace=True)\n        ids = s['image_id']\n        if checker:\n            if tuple(ids) != checker:\n                print(set(checker) - set(ids))\n                print('Different IDS!', len(tuple(ids)), path)\n                exit()\n        else:\n            checker = tuple(ids)\n        preds.append(s['PredictionString'].values)\n\n    if out_path is None:\n        out_path = '\/kaggle\/working\/' + 'ensemble_iou_{}.csv'.format(iou_same)\n    \n    out = open(out_path, 'w')\n    \n    out.write('image_id,PredictionString\\n')\n    \n    for j, id in enumerate(tqdm(list(checker))):\n        \n        boxes_list = []\n        scores_list = []\n        labels_list = []\n        empty = True\n        for i in range(len(preds)):\n            boxes = []\n            scores = []\n            labels = []\n            p1 = preds[i][j]\n            if str(p1) != 'nan':\n                arr = p1.strip().split(' ')\n                for k in range(0, len(arr), 6):\n                    cls = 1 if arr[k] == 'opacity' else 0\n                    prob = float(arr[k + 1])\n                    x1 = float(arr[k + 2]) \/ max_value\n                    y1 = float(arr[k + 3]) \/ max_value\n                    x2 = float(arr[k + 4]) \/ max_value\n                    y2 = float(arr[k + 5]) \/ max_value\n                    boxes.append([x1, y1, x2, y2])\n                    scores.append(prob)\n                    labels.append(cls)\n\n            boxes_list.append(boxes)\n            scores_list.append(scores)\n            labels_list.append(labels)\n\n        boxes, scores, labels = weighted_boxes_fusion(boxes_list, scores_list, labels_list, **kwargs)\n\n        if len(boxes) == 0:\n            out.write('{},none 1 0 0 1 1\\n'.format(id, ))\n        else:\n            final_str = ''\n            for i in range(len(boxes)):\n                cls = int(labels[i])\n                prob = scores[i]\n                x1 = int(boxes[i][0] * max_value)\n                y1 = int(boxes[i][1] * max_value)\n                x2 = int(boxes[i][2] * max_value)\n                y2 = int(boxes[i][3] * max_value)\n                if cls == 0:\n                    final_str += '{} {} {} {} {} {} '.format('none', prob, 0, 0, 1, 1)\n                else:\n                    final_str += '{} {} {} {} {} {} '.format('opacity', prob, x1, y1, x2, y2)\n            out.write('{},{}\\n'.format(id, final_str.strip()))\n\n    out.close()\n    print(f\"Results ---> {out_path}\")\n    return out_path","651de641":"subm_list1 = [\n    '\/kaggle\/working\/subm\/yolo_fold00.csv',\n    '\/kaggle\/working\/subm\/yolo_fold10.csv',\n    '\/kaggle\/working\/subm\/yolo_fold20.csv',\n    '\/kaggle\/working\/subm\/yolo_fold30.csv',\n    '\/kaggle\/working\/subm\/yolo_fold40.csv'\n]\n\nsubm_list2 = [\n    '\/kaggle\/working\/subm\/yolo_fold01.csv',\n    '\/kaggle\/working\/subm\/yolo_fold11.csv',\n    '\/kaggle\/working\/subm\/yolo_fold21.csv',\n    '\/kaggle\/working\/subm\/yolo_fold31.csv',\n    '\/kaggle\/working\/subm\/yolo_fold41.csv'\n]\n\n\nrun_wbf(subm_list1, out_path='\/kaggle\/working\/yolo_v5_sub1.csv',  iou_thr=0.60)\nrun_wbf(subm_list2, out_path='\/kaggle\/working\/yolo_v5_sub2.csv',  iou_thr=0.60)\n\nyolo_sub1 = pd.read_csv('\/kaggle\/working\/yolo_v5_sub1.csv' )\nyolo_sub2 = pd.read_csv('\/kaggle\/working\/yolo_v5_sub2.csv' )","fb7bf4cd":"import mmdet\nimport mmcv\n\nfrom mmcv import Config\nfrom mmcv.runner import load_checkpoint\nfrom mmdet.apis import set_random_seed, inference_detector, \\\n     init_detector, show_result_pyplot, single_gpu_test\nfrom mmdet.datasets import build_dataset, build_dataloader\nfrom mmdet.models import build_detector","409277e8":"baseline_cfg_path = \"..\/input\/detsiim\/retinanet_x101_64x4d_fpn_without_empty\/fold0\/retinanet_x101_64x4d_fpn_siim_fold0.py\"\ncfg = Config.fromfile(baseline_cfg_path)\n\nWEIGHTS_FILES = [\n    \"..\/input\/detsiim\/retinanet_x101_64x4d_fpn_without_empty\/fold0\/best_bbox_mAP_50_epoch_12.pth\",\n    \"..\/input\/detsiim\/retinanet_x101_64x4d_fpn_without_empty\/fold1\/best_bbox_mAP_50_epoch_8.pth\",\n    \"..\/input\/detsiim\/retinanet_x101_64x4d_fpn_without_empty\/fold2\/best_bbox_mAP_50_epoch_10.pth\",\n    \"..\/input\/detsiim\/retinanet_x101_64x4d_fpn_without_empty\/fold3\/best_bbox_mAP_50_epoch_14.pth\",\n    \"..\/input\/detsiim\/retinanet_x101_64x4d_fpn_without_empty\/fold4\/best_bbox_mAP_50_epoch_7.pth\",\n]\n\nassert [os.path.isfile(w) for w in WEIGHTS_FILES]","062f2072":"score_threshold = cfg.model.test_cfg.score_thr\n\ndef format_pred(boxes: np.ndarray, scores: np.ndarray, labels: np.ndarray) -> str:\n    pred_strings = []\n    for label, score, bbox in zip(labels, scores, boxes):\n        xmin, ymin, xmax, ymax = bbox.astype(np.int64)\n        pred_strings.append(f\"opacity {score:.16f} {xmin} {ymin} {xmax} {ymax}\")\n    return \" \".join(pred_strings)\n\nfor i, weights in enumerate(tqdm(WEIGHTS_FILES,  dynamic_ncols=True)):\n    results = []\n    model = init_detector(cfg, weights, device='cuda:0')\n    model.eval()\n\n    with torch.no_grad():\n        for index, row in tqdm(image_df.iterrows(), total=image_df.shape[0], dynamic_ncols=True):\n            original_H, original_W = (int(row.dim0), int(row.dim1))\n            predictions = inference_detector(model, row.image_path)\n            boxes, scores, labels = (list(), list(), list())\n\n            for k, cls_result in enumerate(predictions):\n                if cls_result.size != 0:\n                    if len(labels) == 0:\n                        boxes  = np.array(cls_result[:, :4])\n                        scores = np.array(cls_result[:, 4])\n                        labels = np.array([k]*len(cls_result[:, 4]))\n                    else:    \n                        boxes  = np.concatenate((boxes, np.array(cls_result[:, :4])))\n                        scores = np.concatenate((scores, np.array(cls_result[:, 4])))\n                        labels = np.concatenate((labels, [k]*len(cls_result[:, 4])))\n                    \n            indexes = np.where(scores > score_threshold)\n            boxes   = boxes[indexes]\n            scores  = scores[indexes]\n            labels  = labels[indexes]\n            \n            IMAGE_DIMS = cv2.imread(row.image_path).shape[:2]\n\n            if len(labels) != 0:\n                h_ratio = original_H\/IMAGE_DIMS[0]\n                w_ratio = original_W\/IMAGE_DIMS[1]\n                boxes[:, [0, 2]] *= w_ratio\n                boxes[:, [1, 3]] *= h_ratio\n                result = {\"image_id\": row.image_id, \"PredictionString\": format_pred(boxes, scores, labels)}\n                results.append(result)\n    del model\n    torch.cuda.empty_cache()\n    gc.collect()\n    detection_df = pd.DataFrame(results, columns=['image_id', 'PredictionString'])\n    detection_df.to_csv(f'retinanet_x101_64x4d_fpn_fold_{i}.csv', index=False)","6685a68f":"retina_subs = [\n    '\/kaggle\/working\/retinanet_x101_64x4d_fpn_fold_0.csv',\n    '\/kaggle\/working\/retinanet_x101_64x4d_fpn_fold_1.csv',\n    '\/kaggle\/working\/retinanet_x101_64x4d_fpn_fold_2.csv',\n    '\/kaggle\/working\/retinanet_x101_64x4d_fpn_fold_3.csv',\n    '\/kaggle\/working\/retinanet_x101_64x4d_fpn_fold_4.csv',\n]\n\n\nrun_wbf(retina_subs, out_path='\/kaggle\/working\/retinanet_x101_64x4d_fpn_sub.csv',  iou_thr=0.60)\nretinanet_sub = pd.read_csv('\/kaggle\/working\/retinanet_x101_64x4d_fpn_sub.csv')","c3b2c59a":"@delegates(weighted_boxes_fusion)\ndef merge_boxes_from_models(test_files, test_filenames, **kwargs):\n    n_images   = len(test_filenames)\n    n_variants = len(test_files)\n\n    result_boxes = []\n    result_scores = []\n    result_labels = []\n    for ii in tqdm(range(n_images), dynamic_ncols=True):\n        image_id = test_filenames[ii]\n        pred_variants = pred_locations[image_id]\n        assert len(pred_variants) == n_variants\n\n        pred_boxes = []\n        pred_scores = []\n        pred_labels = []\n        max_value = 10000\n        for vi in range(n_variants):\n            if len(pred_variants[vi]) > 0:\n                cur_pred_labels, cur_pred_scores, cur_pred_boxes = list(zip(*pred_variants[vi]))\n            else:\n                cur_pred_labels = []\n                cur_pred_scores = []\n                cur_pred_boxes = []\n            cur_pred_boxes = np.array(cur_pred_boxes, copy=False)\n            cur_pred_scores = np.array(cur_pred_scores, copy=False)\n            cur_pred_labels = np.array(cur_pred_labels, copy=False)\n\n            # WBF expects the coordinates in 0-1 range.\n            cur_pred_boxes = cur_pred_boxes \/ max_value\n\n            pred_boxes.append(cur_pred_boxes)\n            pred_scores.append(cur_pred_scores)\n            pred_labels.append(cur_pred_labels)\n\n        pred_boxes, pred_scores, pred_labels = weighted_boxes_fusion(pred_boxes, pred_scores, pred_labels, **kwargs)\n        pred_boxes = np.round(pred_boxes * max_value).astype(int)\n\n        assert len(pred_boxes) == len(pred_scores)\n        assert len(pred_boxes) == len(pred_scores)\n        assert len(pred_boxes) == len(pred_labels)\n        result_boxes.append(pred_boxes)\n        result_scores.append(pred_scores)\n        result_labels.append(pred_labels)\n\n    return result_boxes, result_scores, result_labels","6af8b118":"test_files = [\n    '.\/efdet2_sub1.csv', \n    '.\/efdet2_sub2.csv',  \n    '.\/yolo_v5_sub1.csv', \n    '.\/yolo_v5_sub2.csv', \n    '.\/retinanet_x101_64x4d_fpn_sub.csv'\n]\n\nprint('# models', len(test_files))\nprint(test_files)\n\npred_locations = {}\n\nfor model_index in range(len(test_files)):\n    # load table\n    with open(test_files[model_index], mode='r') as infile:\n        # open reader\n        reader = csv.reader(infile)\n        # skip header\n        next(reader, None)\n        # loop through rows\n        for rows in reader:\n            # retrieve information\n            filename = rows[0]\n            # print(rows[0])\n            parts = rows[1].split()\n            # print(parts)\n            assert len(parts) % 6 == 0\n            locations = []\n            for ind in range(len(parts) \/\/ 6):\n                #label = int(parts[ind * 6])\n                label = parts[ind * 6]\n                label = 1 if label == 'opacity' else 0\n                score = float(parts[ind * 6 + 1])\n                location = int(float(parts[ind * 6 + 2])), int(float(parts[ind * 6 + 3])), \\\n                           int(float(parts[ind * 6 + 4])), int(float(parts[ind * 6 + 5]))\n                if score > 0 and label < 14:\n                    locations.append((label, score, location))\n            if filename in pred_locations:\n                pred_locations[filename].append(locations)\n            else:\n                pred_locations[filename] = [locations]\n                \n                \ntest_filenames = [*pred_locations]\ntest_filenames.sort()\n\nresult_boxes, result_scores, result_labels = merge_boxes_from_models(\n    test_files, test_filenames, weights=[0.22,0.23,0.25,0.2,0.1], \n    iou_thr=0.625, conf_type='avg', allows_overflow=True)","29196b7b":"image_df = write_submission(test_filenames, result_boxes, result_scores, result_labels, 0)\nimage_df.head()","afbb196d":"image_preds_df = pd.merge(image_df, binary_submission, on='image_id')\nimage_preds_df = image_preds_df.drop(columns=['study_id'])\nimage_preds_df.columns = ['id', 'PredictionString', 'none']\nimage_preds_df.head()","e9be4445":"for i in tqdm(range(0,image_preds_df.shape[0])):\n    if image_preds_df.loc[i,'PredictionString'] == \"none 1 0 0 1 1\":\n        image_preds_df.loc[i,'PredictionString']='none 1 0 0 1 1'\n        continue\n    \n    image_split = image_preds_df.loc[i,'PredictionString'].split()\n    binary_none = image_preds_df.loc[i,'none']\n    image_df_list = []\n    preds_for_none = 0\n    final_image = []\n    \n    for j in range(int(len(image_split) \/ 6)):\n        if j==0:\n            preds_for_none = 1 - ((float(image_split[6 * j + 1])**0.20)*(1-binary_none)**0.80)\n        else:\n            preds_for_none = preds_for_none\n\n        image_df_list.append([\n            'opacity',\n            (float(image_split[6 * j + 1])**0.80)*(1-binary_none)**0.20,\n            image_split[6 * j + 2],\n            image_split[6 * j + 3],\n            image_split[6 * j + 4],\n            image_split[6 * j + 5]\n        ])\n    image_df_list = sorted(image_df_list, key = lambda x: x[1], reverse=True)\n    for k in range(len(image_df_list)):\n        image_df_list[k][1] = str(image_df_list[k][1])\n        final_image.extend(image_df_list[k])\n\n    image_preds_df.loc[i,'PredictionString'] = ' '.join(final_image)\n\n    image_preds_df.loc[i,'PredictionString'] = image_preds_df.loc[i,'PredictionString'] + ' none ' + \\\n    str(preds_for_none) + ' 0 0 1 1'\n    image_preds_df.loc[i,'none'] = preds_for_none","2c55c58b":"image_df = image_preds_df[['id','PredictionString']].copy()\nimage_df.head()","5c03fb16":"submission = pd.concat([study_df[['id','PredictionString']],image_df],axis=0)\nsubmission = submission[['id','PredictionString']]\nsubmission.head()","3fe99199":"submission.tail()","9c1074b6":"!rm -r \/kaggle\/working\/\n!rm -r \/kaggle\/tmp\/","1ba87332":"submission.to_csv('submission.csv',index=False)","e3b7da90":"## Study Level Predictions","40abe8ab":"## Generate Final Submission","20bae35f":"## Submission for opactity only","4451b396":"## + Yolov5 Models\n- yolov5l6_640_psuedo\n- yolov5x_640_psuedo","50dfbdd0":"## Dependencies","a7430eac":"## Merge all Image Level (Detection) Predictions","5d694ee8":"## Process Binary Predictions","6c40e81f":"## Serialization of Test Images","66b8302b":"## v2m Predictions","db22906b":"## Study : Mix Model Predictions","e538f432":"## Binary Predictions","fc85aa13":"## + Efficientnet Models\n- D3 (pseudo + ema) (896)\n- D5 (ema) (512)","ad8d5c4b":"## Add Binary None Predictions to Image Level (Opacity) Predictions","4aa7dbc1":"## Process Study Predictions","dca57c7c":"## Image Level Predictions (Detection Models)","9e33845e":"## + MMdetection (retinanet_x101_64x4d_fpn)","8250c55e":"## Imports and Env Setup"}}