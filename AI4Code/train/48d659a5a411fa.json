{"cell_type":{"2320ce1d":"code","8051a46e":"code","d30c8fa9":"code","0c9e8fc3":"code","d55e5347":"code","2701a40e":"code","ed11e6ca":"code","f038c4ca":"code","64cb341d":"code","97503ec8":"code","703334dd":"code","7d92a991":"code","8e34412f":"code","acfda2ad":"code","6c02108b":"code","7509d7a6":"code","f9b77c42":"code","6fa6abf9":"code","88fef573":"code","13753a48":"code","1f91b0ce":"code","69325830":"code","4fbda498":"code","bead0c2d":"code","635daedb":"code","2f657fe6":"code","0b32d42a":"code","66bf34f1":"code","27dad159":"code","fcdaf0d7":"code","491a7adc":"code","307b8248":"code","13e550d9":"markdown","d3c5fd34":"markdown","1d4707bb":"markdown","43b45b54":"markdown"},"source":{"2320ce1d":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n# Scalers\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import shuffle\n\n# Models\nfrom sklearn.linear_model import LogisticRegression #logistic regression\nfrom sklearn.linear_model import Perceptron\nfrom sklearn import svm #support vector Machine\nfrom sklearn.ensemble import RandomForestClassifier #Random Forest\nfrom sklearn.neighbors import KNeighborsClassifier #KNN\nfrom sklearn.naive_bayes import GaussianNB #Naive bayes\nfrom sklearn.tree import DecisionTreeClassifier #Decision Tree\nfrom sklearn.model_selection import train_test_split #training and testing data split\nfrom sklearn import metrics #accuracy measure\nfrom sklearn.metrics import confusion_matrix #for confusion matrix\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.neural_network import MLPClassifier\n\n# Cross-validation\nfrom sklearn.model_selection import KFold #for K-fold cross validation\nfrom sklearn.model_selection import cross_val_score #score evaluation\nfrom sklearn.model_selection import cross_val_predict #prediction\nfrom sklearn.model_selection import cross_validate\n\n# GridSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\n#Visualization\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\nimport plotly.express as px\nimport plotly.io as pio\npio.templates.default = \"plotly_dark\"\ndata_dir = '..\/input\/titanic\/'\nos.listdir(data_dir)","8051a46e":"data = pd.read_csv(data_dir+'train.csv')\ntest_df = pd.read_csv(data_dir+'test.csv')\ndf = data.append(test_df) # The entire data: train + test.","d30c8fa9":"df.info()","0c9e8fc3":"df.describe()","d55e5347":"df.head()","2701a40e":"print('Rows     :',df.shape[0])\nprint('Columns  :',df.shape[1])\nprint('\\nFeatures :\\n     :',df.columns.tolist())\nprint('\\nMissing values    :',df.isnull().values.sum())\nprint('\\nUnique values :  \\n',df.nunique())","ed11e6ca":"df['Embarked'].value_counts()\n","f038c4ca":"M = df[(df['Embarked'] == 'S')]\nB = df[(df['Embarked'] == 'C')]\nK  = df[(df['Embarked'] == 'Q')]\n\ntrace = go.Bar(x = (len(M), len(B),len(K)), y = ['S','C','Q'], orientation = 'h', opacity = 0.8, marker=dict(\n        color=['red','green','blue'],\n        line=dict(color='#000000',width=1.5)))\n\nlayout = dict(title =  'Count of target variable')\n                    \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)","64cb341d":"labels = data['Sex'].value_counts()[:10].index\nvalues = data['Embarked'].value_counts()[:10].values\ncolors=['#2678bf','#98adbf']\n\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, textinfo='label+percent',\n                             insidetextorientation='radial',marker=dict(colors=colors))])\nfig.show()","97503ec8":"fig = px.scatter(data, x=\"Age\", y=\"Fare\", color=\"Survived\", facet_col=\"Survived\",\n           color_continuous_scale=px.colors.sequential.Viridis, render_mode=\"webgl\")\nfig.show()","703334dd":"fig = px.scatter(data, x=\"Age\", y=\"Fare\", color=\"Sex\", facet_col=\"Sex\",\n           color_continuous_scale=px.colors.sequential.Viridis, render_mode=\"webgl\")\nfig.show()","7d92a991":"data_to_plot = data.dropna()\nfig = px.violin(data_to_plot, y=\"Fare\", x=\"Embarked\", color=\"Embarked\", box=True, points=\"all\")\nfig.show()","8e34412f":"#correlation map\nf, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(df.corr(), annot=True, linewidth=\".5\", fmt=\".2f\", ax = ax)\nplt.title(\"Correlation Map\",fontsize=20)\nplt.show()","acfda2ad":"f,ax=plt.subplots(1,2,figsize=(18,8))\ndf['Embarked'].value_counts().plot.pie(explode=[0,0.1,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('Class Count')\nax[0].set_ylabel('Count')\nsns.countplot('Embarked',data=df,ax=ax[1],order=df['Embarked'].value_counts().index)\nax[1].set_title('Count of Target')\nplt.show()","6c02108b":"f,ax=plt.subplots(1,2,figsize=(18,8))\nsns.violinplot(\"Embarked\",\"Age\", hue=\"Embarked\", data=df,ax=ax[0])\nax[0].set_title('Age and Target')\nsns.violinplot(\"Embarked\",\"Fare\", hue=\"Embarked\", data=df,ax=ax[1])\nax[1].set_title('Fare  and Target')\nplt.show()","7509d7a6":"f,ax=plt.subplots(1,2,figsize=(20,10))\ndf[df['Sex']=='male'].Age.plot.hist(ax=ax[0],bins=20,edgecolor='black',color='red')\nax[0].set_title('Sex:male')\n\ndf[df['Sex']=='female'].Age.plot.hist(ax=ax[1],color='green',bins=20,edgecolor='black')\nax[1].set_title('Sex:female')\n\nplt.show()","f9b77c42":"pd.crosstab(data.Age,data.Survived).plot(kind=\"bar\",figsize=(20,6))\nplt.title('Survived Frequency for Ages')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.show()","6fa6abf9":"pd.crosstab(data.Pclass,data.Survived).plot(kind=\"bar\",figsize=(15,6),color=['#DAA7A6','#FF5933' ])\nplt.title('Pclass Distribution')\nplt.xlabel('Pclass')\nplt.xticks(rotation = 0)\nplt.ylabel('Frequency')\nplt.show()\n","88fef573":"pd.crosstab(data.Embarked,data.Survived).plot(kind=\"bar\",figsize=(15,6),color=['#11E5AA','#BB1190' ])\nplt.title('Embarked Frequenct w.r.t Survived')\nplt.xlabel('Embarked')\nplt.xticks(rotation = 0)\nplt.ylabel('Frequency')\nplt.show()","13753a48":"data['Sex'].replace(['male','female'],[0,1],inplace=True)\ntest_df['Sex'].replace(['male','female'],[0,1],inplace=True)","1f91b0ce":"df['Fare'].fillna(df['Fare'].median(), inplace = True)\n\n# Making Bins\ndf['FareBin'] = pd.qcut(df['Fare'], 5)\n\nlabel = LabelEncoder()\ndf['FareBin_Code'] = label.fit_transform(df['FareBin'])\n\ndata['FareBin_Code'] = df['FareBin_Code'][:891]\ntest_df['FareBin_Code'] = df['FareBin_Code'][891:]\n\ndata.drop(['Fare'], 1, inplace=True)\ntest_df.drop(['Fare'], 1, inplace=True)","69325830":"df['Age'].fillna(df['Fare'].median(), inplace = True)\n\ndf['AgeBin'] = pd.qcut(df['Age'], 4)\n\nlabel = LabelEncoder()\ndf['AgeBin_Code'] = label.fit_transform(df['AgeBin'])\n\ndata['AgeBin_Code'] = df['AgeBin_Code'][:891]\ntest_df['AgeBin_Code'] = df['AgeBin_Code'][891:]\n\ndata.drop(['Age'], 1, inplace=True)\ntest_df.drop(['Age'], 1, inplace=True)","4fbda498":"data['fam_count'] = data['SibSp']+data['Parch']\ntest_df['fam_count'] = test_df['SibSp']+test_df['Parch']\n\nsize = {\n    0:'alone',\n    1:'small',\n    2:'small',\n    3:'small',\n    4:'large',\n    5:'large',\n    6:'large',\n    7:'large',\n    10:'large'\n}\n\ndata['family_size'] = data['fam_count'].map(size)\ntest_df['family_size'] = test_df['fam_count'].map(size)","bead0c2d":"def create_dummies(df, column_name):\n    dummies = pd.get_dummies(df[column_name], prefix=column_name)\n    df = pd.concat([df,dummies],axis=1)\n    df.drop(column_name, axis=1, inplace=True)\n    return df","635daedb":"data = create_dummies(data,'Embarked')\ndata = create_dummies(data,'Pclass')\ndata = create_dummies(data,'family_size')","2f657fe6":"test_df = create_dummies(test_df,'Embarked')\ntest_df = create_dummies(test_df,'Pclass')\ntest_df = create_dummies(test_df,'family_size')","0b32d42a":"df_test = test_df.copy()","66bf34f1":"data.head()","27dad159":"data.drop(['Name', 'PassengerId', 'Ticket', 'Cabin'], axis = 1, inplace = True)\ntest_df.drop(['Name','PassengerId', 'Ticket', 'Cabin'], axis = 1, inplace = True)","fcdaf0d7":"def get_X_and_y(dataset, target_name):\n    X=dataset.drop(target_name, axis=1)\n    y=dataset[target_name]\n    sc = StandardScaler()\n    X=sc.fit_transform(X)    \n    return X, y","491a7adc":"X,y = get_X_and_y(data,target_name='Survived')","307b8248":"model = RandomForestClassifier(n_estimators = 100, max_depth = 5,random_state = 1)\nmodel.fit(X,y)\npredictions = model.predict(test_df)\n\noutput = pd.DataFrame({'PassengerId': df_test.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","13e550d9":"## * Predictive Model *","d3c5fd34":"## * Feature Engineering *","1d4707bb":"# The Challenge\n<b> The sinking of the Titanic is one of the most infamous shipwrecks in history.On April 15, 1912, during her maiden voyage, the widely considered \u201cunsinkable\u201d RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren\u2019t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.In this challenge, we ask you to build a predictive model that answers the question: \u201cwhat sorts of people were more likely to survive?\u201d using passenger data (ie name, age, gender, socio-economic class, etc) <\/b>","43b45b54":"## *  Exploratory Data Analysis *"}}