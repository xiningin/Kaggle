{"cell_type":{"48174ea0":"code","e11d2279":"code","f565a8c4":"code","d14d9294":"code","e2596d1a":"code","23f4496a":"code","bc47222b":"code","4f457947":"code","f39e06ea":"code","6d5bbb6a":"code","bcd02e46":"code","a64d1119":"code","f5bb645f":"code","0c1eb4a5":"code","56092d89":"code","19b7f868":"code","8517b5b0":"code","2bce739b":"code","ae7c78f0":"code","5c61b2c4":"code","fc6bc11c":"code","d9d89f1c":"code","2db9e15c":"code","6e584645":"code","d5ba5341":"code","b272a6ad":"code","e0c89130":"code","fa1669df":"code","363c14f0":"code","113151cd":"code","dafc3c0a":"code","ba87ce7d":"code","73d3757a":"code","defbba2d":"code","28c95a31":"code","bbfb43bb":"code","e4668483":"code","8fd89cdd":"code","cb9e252c":"code","9e2451e8":"code","d539ec88":"code","d567802e":"markdown","1f27af18":"markdown","4e69528c":"markdown","d70dc2a3":"markdown","1c1e0135":"markdown","a045a076":"markdown","4bad339a":"markdown","5e7c778b":"markdown","ba5368f6":"markdown","eb7951b3":"markdown","7933857c":"markdown","32a1626c":"markdown","fe7be7fe":"markdown","24a38a89":"markdown","d0fd56c6":"markdown","98ba2c23":"markdown","db52afdb":"markdown","9d379111":"markdown","b9e31796":"markdown","1620b867":"markdown","82ad8c10":"markdown","41fa6909":"markdown","ebecebe1":"markdown","858f4e36":"markdown","0ac7ab58":"markdown","ad9785ae":"markdown","8bfdbd3e":"markdown","7641c654":"markdown","2aedb6fc":"markdown","613c0852":"markdown","869fa53e":"markdown","c76aeb19":"markdown","9eacc9ed":"markdown","b41c8e7c":"markdown","35fc26a8":"markdown","5647a8d0":"markdown","4cd3be80":"markdown","34acab52":"markdown","5268457b":"markdown","13cea6c1":"markdown"},"source":{"48174ea0":"import pandas as pd\n# prophet by Facebook\nfrom fbprophet import Prophet\nfrom sklearn.metrics import mean_absolute_error\nimport warnings; warnings.simplefilter('ignore')\nimport matplotlib.pyplot as plt\nfrom IPython.display import HTML\nimport os\n\n","e11d2279":"pd.set_option('display.max_columns', None)","f565a8c4":"url='..\/input\/Min-Max Daily Analyse.csv'\ndf = pd.read_csv(url, sep=',')\ndf.head()","d14d9294":"\n#url = 'https:\/\/raw.githubusercontent.com\/kmkarakaya\/ML_tutorials\/master\/data\/Min-Max%20Daily%20Analyse.csv'\n#df = pd.read_csv(url, sep=';')\n#df.head()","e2596d1a":"df['Range'] = df['Max']-df['Min']\ndf.head()","23f4496a":"import datetime \nday_name= ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday','Sunday']\ndf['Day'] = [ day_name[i] for i in pd.to_datetime(df['Date']).dt.dayofweek]\ndf= df[['Date','Day','Min','Max','Range']]\ndf.head()","bc47222b":"df.describe()","4f457947":"#df['ds'] = pd.to_datetime(df['Day'],  dayfirst = True)\ndf.plot(x='Date',   figsize=(15, 5))\n","f39e06ea":"def prediction_Prophet(feature):\n  dfNew = pd.DataFrame()\n  dfNew['ds'] = pd.to_datetime(df['Date'],  dayfirst = True)\n  dfNew['y'] = df[[feature]].copy()\n  \n  #print(dfNew.tail())\n\n  m = Prophet(daily_seasonality=True )\n  m.fit(dfNew)\n  horizon= 1\n  future = m.make_future_dataframe(periods=horizon)\n  forecast = m.predict(future)\n  print('\\nForcasted  {} values \\n {}\\n'.format(feature, forecast[['ds',  'yhat', 'yhat_lower', 'yhat_upper']].tail()))\n  fig1 = m.plot(forecast)\n  #fig2 = m.plot_components(forecast)\n  return forecast","6d5bbb6a":"pred=prediction_Prophet('Range')\n\ndf['Range_By_Prophet']=pred['yhat_upper']\n\nprint('Anamolies for range values\\n', df[df['Range']>df['Range_By_Prophet']][['Date','Day','Range','Range_By_Prophet']])","bcd02e46":"pred=prediction_Prophet('Min')\n\ndf['Min_By_Prophet']=pred['yhat_lower']\nprint('Anamolies for min values\\n', df[df['Min']<df['Min_By_Prophet']][['Date','Day','Min','Min_By_Prophet']])\n","a64d1119":"pred=prediction_Prophet('Max')\n\ndf['Max_By_Prophet']=pred['yhat_upper']\nprint('Anamolies for Max values\\n', df[df['Max']>df['Max_By_Prophet']][['Date','Day','Max','Max_By_Prophet']])","f5bb645f":"df.plot(title=\"comparison\",x='Date',y=['Min','Max', 'Min_By_Prophet','Max_By_Prophet'],figsize=(20, 6))","0c1eb4a5":"df.plot(title=\"comparison\",x='Date',y=['Range','Range_By_Prophet'],figsize=(20, 6))","56092d89":"print('Mean of Min', df['Min'].mean())\nprint('Standart Deviation of Min', df['Min'].std())\nprint('Expected minimum value for of Min', df['Min'].mean()-2*df['Min'].std())\ndf['Min_Calculated']=df['Min'].mean()-2*df['Min'].std()\nprint('Anamolies for Min values\\n', df[df['Min']<df['Min_Calculated']][['Date','Day','Min','Min_Calculated']])","19b7f868":"print('Mean of Max', df['Max'].mean())\nprint('Standart Deviation of Max', df['Max'].std())\nprint('Expected minimum value for of Max', df['Max'].mean()+2*df['Max'].std())\ndf['Max_Calculated']=df['Max'].mean()+2*df['Max'].std()\nprint('Anamolies for Max values\\n', df[df['Max']>df['Max_Calculated']][['Date','Day','Max','Max_Calculated']])","8517b5b0":"print('Mean of Range', df['Range'].mean())\nprint('Standart Deviation of Range', df['Range'].std())\nmaxRange=df['Range'].mean()+2*df['Range'].std()\nprint('Expected maximum value for of Range', maxRange)\ndf['Range_Calculated']=maxRange\nprint('Anamolies for Range values\\n', df[df['Range']>df['Range_Calculated']][['Date','Day','Range','Range_Calculated']])","2bce739b":"df.plot(title=\"comparison\",x='Date',y=['Min','Max', 'Min_Calculated','Max_Calculated'],figsize=(20, 6))\n","ae7c78f0":"df.plot(title=\"Range\",x='Date',y=['Range','Range_Calculated'],figsize=(20, 6))","5c61b2c4":"CodesOfInterest=['anomaly']\ndef hover(hover_color=\"#ffff99\"):\n    return dict(selector=\"tr:hover\",\n                props=[(\"background-color\", \"%s\" % hover_color)])\ndef showSummary(fontSize='12px'):\n  summary =pd.DataFrame()\n  \n  summary= anomaly[(anomaly.isin(CodesOfInterest)==True).any(1)]\n  styles = [\n    hover(),\n    dict(selector=\"th\", props=[(\"font-size\", fontSize),\n                               (\"text-align\", \"center\")]),\n    dict(selector=\"tr\", props=[(\"font-size\", fontSize),\n                               (\"text-align\", \"center\")]),      \n    dict(selector=\"caption\", props=[(\"caption-side\", \"bottom\")])\n  ]\n  html = (summary.style.set_table_styles(styles)\n          .set_caption(\"Hover to highlight.\"))\n  print(' Number of detected anomalies: ', len(summary) )\n  return html","fc6bc11c":"anomaly = pd.DataFrame()\nanomaly = df[['Date','Day','Min','Max','Range']].copy()\nanomaly['Min_anomaly_Prophet']= df['Min']\nanomaly['Max_anomaly_Prophet']= df['Max']\nanomaly['Range_anomaly_Prophet']=df['Range']\n\nanomaly['Min_anomaly_Calculated']= df['Min']\nanomaly['Max_anomaly_Calculated']= df['Max']\nanomaly['Range_anomaly_Calculated']= df['Range']\n","d9d89f1c":"df.columns","2db9e15c":"anomaly['Min_anomaly_Prophet'][df['Min']<df['Min_By_Prophet']]= 'anomaly'\nanomaly['Min_anomaly_Prophet'][df['Min']>=df['Min_By_Prophet']]= ''\n\nanomaly['Max_anomaly_Prophet'][df['Max']>df['Max_By_Prophet']]= 'anomaly'\nanomaly['Max_anomaly_Prophet'][df['Max']<=df['Max_By_Prophet']]= ''\n\nanomaly['Range_anomaly_Prophet'][df['Range']>df['Range_By_Prophet']]= 'anomaly'\nanomaly['Range_anomaly_Prophet'][df['Range']<=df['Range_By_Prophet']]= ''\n\nanomaly['Min_anomaly_Calculated'][df['Min']<df['Min_Calculated']]= 'anomaly'\nanomaly['Min_anomaly_Calculated'][df['Min']>=df['Min_Calculated']]= ''\n\nanomaly['Max_anomaly_Calculated'][df['Max']>df['Max_Calculated']]= 'anomaly'\nanomaly['Max_anomaly_Calculated'][df['Max']<=df['Max_Calculated']]= ''\n\nanomaly['Range_anomaly_Calculated'][df['Range']>df['Range_Calculated']]= 'anomaly'\nanomaly['Range_anomaly_Calculated'][df['Range']<=df['Range_Calculated']]= ''\n\n\n","6e584645":"showSummary('11px')\n","d5ba5341":"def predict_SMA(feature):\n  window= 7\n  sma = df[feature].rolling(window=window).mean()\n  rstd = df[feature].rolling(window=window).std()\n  bands = pd.DataFrame()\n  bands['Date']=  (df['Date']).copy()\n  bands['Date'] = pd.to_datetime(bands['Date'], dayfirst=True)\n  bands['sma'] = sma \n  bands['lower'] = sma - 2 * rstd\n  bands['upper'] = sma + 2 * rstd\n  bands = bands.join(df[feature])\n  bands = bands.set_index('Date')\n  fig = plt.figure(figsize=(20, 6))\n  ax = bands.plot(title=feature,  figsize=(20, 6))\n  ax.fill_between(bands.index, bands['lower'], bands['upper'], color='#ADCCFF', alpha=0.4)\n  ax.set_xlabel('Date')\n  ax.set_ylabel(feature)\n  ax.grid()\n  plt.show()\n  return bands","b272a6ad":"bands = predict_SMA('Min')\nbands.reset_index(inplace=True)\nmin= df['Min'].min()\nbands['lower'].fillna(min , inplace=True)\ndf['Min_SMA']= bands['lower'].copy()\nprint('Anamolies for SMA_Min values\\n', df[df['Min']<df['Min_SMA']][['Date','Min', 'Min_SMA']])\n\n","e0c89130":"bands = predict_SMA('Max')\nbands.reset_index(inplace=True)\nmax= df['Max'].max()\nbands['upper'].fillna(max , inplace=True)\n\ndf['Max_SMA']= bands['upper'].copy()\nprint('Anamolies for Max_SMA values\\n', df[df['Max']>df['Max_SMA']][['Date','Max', 'Max_SMA']])","fa1669df":"bands = predict_SMA('Range')\nbands.reset_index(inplace=True)\nmax= df['Range'].max()\nbands['upper'].fillna(max , inplace=True)\ndf['Range_SMA']= bands['upper'].copy()\nprint('Anamolies for Range_SMA values\\n', df[df['Range']>=df['Range_SMA']][['Date','Range', 'Range_SMA']])","363c14f0":"anomaly['Min_anomaly_SMA']= df['Min']\nanomaly['Max_anomaly_SMA']= df['Max']\nanomaly['Range_anomaly_SMA']= df['Range']\n\nanomaly['Min_anomaly_SMA'][df['Min']<df['Min_SMA']]= 'anomaly'\nanomaly['Min_anomaly_SMA'][df['Min']>=df['Min_SMA']]= ''\n\nanomaly['Max_anomaly_SMA'][df['Max']>df['Max_SMA']]= 'anomaly'\nanomaly['Max_anomaly_SMA'][df['Max']<=df['Max_SMA']]= ''\n\nanomaly['Range_anomaly_SMA'][df['Range']>df['Range_SMA']]= 'anomaly'\nanomaly['Range_anomaly_SMA'][df['Range']<=df['Range_SMA']]= ''\n","113151cd":"showSummary('10px')","dafc3c0a":"def predict_EMA(feature):\n  window= 3\n  ema = df[feature].ewm(span=window,adjust=False).mean()\n  rstd = df[feature].rolling(window=window).std()\n  bands = pd.DataFrame()\n  bands['Date']=  (df['Date']).copy()\n  bands['Date'] = pd.to_datetime(bands['Date'], dayfirst=True)\n  bands['ema'] = ema \n  bands['lower'] = ema - 2 * rstd\n  bands['upper'] = ema + 2 * rstd\n  bands = bands.join(df[feature])\n  bands = bands.set_index('Date')\n  fig = plt.figure(figsize=(20, 6))\n  ax = bands.plot(title=feature,  figsize=(20, 6))\n  ax.fill_between(bands.index, bands['lower'], bands['upper'], color='#ADCCFF', alpha=0.4)\n  ax.set_xlabel('Date')\n  ax.set_ylabel(feature)\n  ax.grid()\n  plt.show()\n  return bands","ba87ce7d":"bands= predict_EMA('Min')\nbands.reset_index(inplace=True)\nmin= df['Min'].min()\nbands['lower'].fillna(min , inplace=True)\ndf['Min_EMA']= bands['lower'].copy()\nprint('Anamolies for EMA_Min values\\n', df[df['Min']<df['Min_EMA']][['Date','Min', 'Min_EMA']])","73d3757a":"bands = predict_EMA('Max')\nbands.reset_index(inplace=True)\nmax= df['Max'].max()\nbands['upper'].fillna(max , inplace=True)\ndf['Max_EMA']= bands['upper'].copy()\nprint('Anamolies for EMA_Max values\\n', df[df['Max']>df['Max_EMA']][['Date','Max', 'Max_EMA']])","defbba2d":"bands = predict_EMA('Range')\nbands.reset_index(inplace=True)\nmax= df['Range'].max()\nbands['upper'].fillna(max , inplace=True)\ndf['Range_EMA']= bands['upper'].copy()\nprint('Anamolies for EMA_Range values\\n', df[df['Range']>df['Range_EMA']][['Date','Range', 'Range_EMA']])","28c95a31":"anomaly['Min_anomaly_EMA']= df['Min']\nanomaly['Max_anomaly_EMA']= df['Max']\nanomaly['Range_anomaly_EMA']= df['Range']\n\nanomaly['Min_anomaly_EMA'][df['Min']<df['Min_EMA']]= 'anomaly'\nanomaly['Min_anomaly_EMA'][df['Min']>=df['Min_EMA']]= ''\n\nanomaly['Max_anomaly_EMA'][df['Max']>df['Max_EMA']]= 'anomaly'\nanomaly['Max_anomaly_EMA'][df['Max']<=df['Max_EMA']]= ''\n\nanomaly['Range_anomaly_EMA'][df['Range']>df['Range_EMA']]= 'anomaly'\nanomaly['Range_anomaly_EMA'][df['Range']<=df['Range_EMA']]= ''","bbfb43bb":"showSummary('9px')","e4668483":"anomaly.info()","8fd89cdd":"anomaly=anomaly[(anomaly.isin(CodesOfInterest)==True).any(1)]\n\n#Apply pd.Series.value_counts to all the columns of the dataframe, it will give you the count of unique values for each row\nvoting= anomaly.iloc[:,5:14].apply(pd.Series.value_counts, axis=1)\nvoting.iloc[:,1:2]\nanomaly['Vote_Number']=voting.iloc[:,1:2]\nanomaly['Vote_Ratio']=voting.iloc[:,1:2]\/9*100\nanomaly.plot.bar(x='Date', y='Vote_Number')\nprint(anomaly[['Date','Day', 'Vote_Number']])","cb9e252c":"print(\"Total Number of detected anomalies: \",len(anomaly))\nthreshold= 50\nprint(\"Number of Anomalies over the threshold ({}%) voting: {} \".format(threshold,len(anomaly[anomaly['Vote_Ratio']>threshold] )))\nprint(anomaly[anomaly['Vote_Ratio']>threshold][['Date','Day','Vote_Number','Min','Max','Range']])","9e2451e8":"anomaly['Vote_Number'].describe()","d539ec88":"anomaly.to_csv('anomaly.csv')","d567802e":"## NOTES:\n* You can acess the notebook on  [COLAB](https:\/\/colab.research.google.com\/drive\/1Q9KPbgEXHbcJqUmsilPZntbtkGxSFdyA?usp=sharing), [GITHUB](https:\/\/github.com\/kmkarakaya\/ML_tutorials\/blob\/master\/Anomaly_Detection_in_A_Time_Series.ipynb), or [Kaggle](https:\/\/www.kaggle.com\/kmkarakaya\/anomaly-detection-in-time-series-using-voting) \n\n* you can **watch** it on <font color=\"red\"> YOUTUBE <\/font> in [TURKISH](https:\/\/www.youtube.com\/watch?v=7MhZ2DDg89Y) or in [ENGLISH](https:\/\/youtu.be\/cy7vzuuADBc)\n\n* you can download the data from [GITHUB](https:\/\/github.com\/kmkarakaya\/ML_tutorials\/blob\/master\/data\/Min-Max%20Daily%20Analyse.csv) or [Kaggle](https:\/\/www.kaggle.com\/kmkarakaya\/car-battery-measurements)","1f27af18":"# Thank you\nMurat Karakaya\n\nFirst Submission: 09\/05\/2020","4e69528c":"# How you can improve\n* Add more prediction methods such as:\n\n>* [Arima](https:\/\/www.machinelearningplus.com\/time-series\/arima-model-time-series-forecasting-python\/)\n>*  [Autoregressive (AR)](https:\/\/machinelearningmastery.com\/autoregression-models-time-series-forecasting-python\/) \n\n* Implement Weighted Voting scheme\n\n* Apply what you have learned in here to a different data set\n\n* Write a comment to me\n","d70dc2a3":"## For Min","1c1e0135":"#Prediction Method 2: Mean + 2 SD\n[More about Normal distribution & Standard Deviation](https:\/\/anomaly.io\/anomaly-detection-normal-distribution\/index.html) \n## Key Concepts:\n* A **normal distribution** is a very common probability distribution that approximates the behavior of many natural phenomena.\n\n* The **standard deviation**, called sigma (\u03c3), defines how far the normal distribution is spread around the mean.\n\n## Mathematical Rules:\n\nWhen a metric is normally distributed it follows some interesting laws:\n\n* The **mean** and the **median** are the same: both are equal to 1000 in this case. This is because of the perfectly symmetric \u201cbell-shape\u201d.\n\n* The standard deviation, called sigma (\u03c3), in this example \u03c3 = 20.\n* 68% of all values fall between [mean-\u03c3, mean+\u03c3]; for the example this is [980, 1020].\n* 95% of all values fall between [mean-2*\u03c3, mean+2*\u03c3]; for the example, [960, 1040].\n* 99,7% of all values fall between [mean-3*\u03c3, mean+3*\u03c3]; in the example, [940; 1060].\n\nThe last 3 rules are also known as the **68\u201395\u201399.7 rule** or the \u201c**three-sigma rule of thumb**\u201d.\n\n\n\n<img border=\"0\" alt=\"W3Schools\" src=\"https:\/\/github.com\/kmkarakaya\/ML_tutorials\/blob\/master\/images\/3-sigma-rules.png?raw=true\" width=\"500\" height=\"500\">\n\n","a045a076":"# Summary\n","4bad339a":"## Run the Prophet Model","5e7c778b":"# Prediction Method 1: Facebook's Prophet Model\n\nAs a prediction method, we will use Prophet. \n\n[More about Prophet](https:\/\/facebook.github.io\/prophet\/docs\/quick_start.html#python-api) \n\n\n","ba5368f6":"## For Range","eb7951b3":"#  Data Collection & Preprocessing\n\nA car tracking company collects the data automatically.\nCar battery (accumulator) supplies the electric to the tracking device and tracking device logs electric supply in in miliamperes (mA). The number of the logs during a day varies according to the usage of the car. \n\nFor simplify the problem, we selected one car with a diminishing battery (accumulator). Then, we processed the data such that for each day we have minimum and maximum  of the recorded current values.\n\n# Goal\n\nOur goal is to find the anomalies in the electric consumption due to battery or tracking device malfunction.\n\n","7933857c":"## Load data\n\nLet's begin with importing dependicies and data.","32a1626c":"#Summary","fe7be7fe":"### For Min","24a38a89":"## Compare the predictions with collected data ","d0fd56c6":"## For Range","98ba2c23":"## For Min \n","db52afdb":"# Export the Anomaly Report","9d379111":"## Compare the predictions with collected data \n","b9e31796":"### For Range","1620b867":"### For Range\n","82ad8c10":"### For Max values","41fa6909":"## Prepare a Train & Predict function for  the Prophet Model\n","ebecebe1":"# Conclusion\n\nGiven the data set and using the Prophet, SMA, EMA to forecast the anomaly:\n* Data has ONLY **90 days**\n* Majority Voting provides a fitering mechanism of the predicted anomalies by various methods\n* We analyze the anomaly in a day by using 3 observation: **min, max, and range** values of current in mA.\n* The four selected methods detected **22 anomalies** out of 90 data samples\n* **EMA** has predicted almost no anomalies\n* Thus, we remove it, only use the rest **three methods** in Majority Voting\n* We decided that there are **3 anomalies** by setting the Majority Voting **threshold 50%**\n","858f4e36":"#Summary\n","0ac7ab58":"# You can <font color=\"red\"> watch <\/font>  this notebook at **Murat Karakaya Akademi** channel on ***YOUTUBE*** in [TURKISH](https:\/\/www.youtube.com\/watch?v=7MhZ2DDg89Y) or in [ENGLISH](https:\/\/youtu.be\/cy7vzuuADBc)","ad9785ae":"## Add meta data\n","8bfdbd3e":"### For Min Values","7641c654":"## For Max","2aedb6fc":"## Prepare a Train & Predict function for SMA\n","613c0852":"## Visualize the data in a plot.\n","869fa53e":"## Create New Feature","c76aeb19":"# Method\nWe will use an **ensembling** with **Majority Voting** implementing 4 prediction methods:\n* [Facebook's Prophet](https:\/\/facebook.github.io\/prophet\/) \n* [Anomaly Detection with the Normal Distribution](https:\/\/anomaly.io\/anomaly-detection-normal-distribution\/index.html)\n* [Simple Moving Average](https:\/\/towardsdatascience.com\/anomaly-detection-def662294a4e) \n* [Exponential Moving Average](https:\/\/towardsdatascience.com\/anomaly-detection-def662294a4e)","9eacc9ed":"## Prepare a Train & Predict function for SMA","b41c8e7c":"# Anomaly Detection in Time Series using Voting Scheme\n\nIn this notebook, we will predict if a GPS tracking device consumes **abnormal** amounts of current from the car battery (accumulator).\n\n**Keywords & Concepts**:\n* **Abnormal**: deviating from what is normal or usual, typically in a way that is undesirable or worrying.\n\n* **Anomaly**: something that deviates from what is standard, normal, or expected.\n\n* **Ensemble**: Ensemble methods are techniques that create multiple models and then combine them to produce improved results. \n\n* **Voting Scheme**: Voting is one of the easiest ensemble methods. the first step is to create multiple classification\/regression models using some training dataset. Each base model can be created using different splits of the same training dataset and same algorithm, or using the same dataset with different algorithms, or any other method. \n\n* **Majority Voting**: Every model makes a prediction (votes) for each test instance and the final output prediction is the one that receives more than half of the votes. If none of the predictions get more than half of the votes, we may say that the ensemble method could not make a stable prediction for this instance. Although this is a widely used technique, you may try the most voted prediction (even if that is less than half of the votes) as the final prediction. \n\n* **Weighted Voting**: Unlike majority voting, where each model has the same rights, we can increase the importance of one or more models. In weighted voting you count the prediction of the better models multiple times. Finding a reasonable set of weights is up to you.\n\n\n\n","35fc26a8":"# Prediction Method 4: Exponential Moving Average (EMA)\n\nEMA(t)\n\nEMA(t0)=(1\u2212\u03b1)\n\nEMA(t\u22121)+\u03b1 p(t)=p(t0)\n \nwhere p(t) is the price at time t and \u03b1 is called the decay parameter for the EMA. \n\n\u03b1 is related to the lag as\n\u03b1=1\/L+1\n\nand the length of the window (span) M as\n\u03b1=2\/M+1.\n\nThe reason why EMA reduces the lag is that it puts more weight on more recent observations, whereas the SMA weights all observations equally by 1\/M.\n","5647a8d0":"# Prediction Method 3: Simple Moving Average (SMA)\n\n\nLet's calculate Simple Moving Average with 3 days window\n","4cd3be80":"### For Max","34acab52":"## For Max \n","5268457b":"You can download from Github as well","13cea6c1":"## Explore Data\n\n"}}