{"cell_type":{"514cd334":"code","f5fbc6f5":"code","d011c7cb":"code","a6743a1f":"code","e22ddb85":"code","27499196":"code","839b2ad8":"code","e7528ffe":"code","e77bdce8":"code","3ab37fb5":"code","bd7e8b57":"code","407836d5":"code","5ea0ae93":"code","3b7e776b":"code","ae3628bd":"code","35907977":"code","47f5b121":"code","40608079":"code","5cd3e1c9":"code","da1b09b0":"code","9de793f4":"markdown","676e1450":"markdown","c461edff":"markdown","87061076":"markdown","3f0bf2a4":"markdown"},"source":{"514cd334":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n%matplotlib inline\nimport matplotlib.pyplot as plt\npd.set_option('display.max_columns', None)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f5fbc6f5":"#Loading train and test_data\ndata_train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndata_test = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","d011c7cb":"#exploring the train set\n#visualizing correlation matrix to find dependent features\nhousing = data_train.copy()\ncorr_matrix = housing.corr()\n\nimport seaborn as sns\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n# Add title\nplt.title(\"Correlation matrix of dataset\")\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr_matrix, mask=mask, cmap=cmap, vmax=1, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","a6743a1f":"print(\"Correlation coefficient 'GarageYrBlt' \/ 'YearBuilt': '{:.1%}\".format(corr_matrix.loc['GarageYrBlt', 'YearBuilt']))\nprint(\"Correlation coefficient '1stFlrSF' \/ 'TotalBsmtSF': '{:.1%}\".format(corr_matrix.loc['1stFlrSF', 'TotalBsmtSF']))\nprint(\"Correlation coefficient 'TotRmsAbvGrd' \/ 'GrLivArea': '{:.1%}\".format(corr_matrix.loc['TotRmsAbvGrd', 'GrLivArea']))\nprint(\"Correlation coefficient 'GarageArea' \/ 'GarageCars': '{:.1%}\".format(corr_matrix.loc['GarageArea', 'GarageCars']))","e22ddb85":"# Visualize correlation of columns to SalePrice\n#experimenting with feature combinations\n#housing[\"LowQualFinSF_per_GrLivArea\"] = housing[\"LowQualFinSF\"]\/housing[\"GrLivArea\"]\n#housing[\"LotArea_per_LotFrontage\"] = housing[\"LotArea\"]\/housing[\"LotFrontage\"]\ncorr_matrix = corr_matrix.drop('GarageYrBlt')\ncorr_matrix = corr_matrix.drop('1stFlrSF')\ncorr_matrix = corr_matrix.drop('TotRmsAbvGrd')\ncorr_matrix = corr_matrix.drop('GarageArea')\ncorr_matrix[\"SalePrice\"].sort_values(ascending=False)","27499196":"# Bar chart showing average arrival delay for Spirit Airlines flights by month\nplt.figure(figsize=(50,6))\nplt.xticks(rotation=45)\nsns.barplot(x=corr_matrix[\"SalePrice\"].sort_values(ascending=False).index, y=corr_matrix[\"SalePrice\"].sort_values(ascending=False))","839b2ad8":"#'SalePrice' needs to be dropped\n#Remaining relevant numerical features are saved in relevant_num_features\ncorr_matrix = corr_matrix.drop('SalePrice')\nrelevant_num_features = corr_matrix['SalePrice'].sort_values(ascending=False).loc[:'BsmtUnfSF'].index\nrelevant_num_features","e7528ffe":"#Calculating percentage of empty values in each column\nn_nan = []\nfor col in housing.columns:\n    n_nan.append(int(housing[col].isna().sum(axis=0))\/len(housing.index))\nnan_percentage = pd.DataFrame(n_nan, index = housing.columns)\n\n# showing the ten highest features with NaN values\nnan_percentage = nan_percentage.iloc[:,0].sort_values(ascending=False)\nnan_percentage[:10]","e77bdce8":"# Categorical features with low relevance are saved in relevant_num_features\n# so they can be dropped later\nlow_relevant_cat = nan_percentage[:4].index\nlow_relevant_cat","3ab37fb5":"# creating helper function to clean up dataset\ndef select_relevant_data(df,relevant_num_features,low_relevant_cat):\n    #devide data into numerical and categorical data\n    df_cat = df.select_dtypes(include=object)\n    df_cat = df_cat.drop(low_relevant_cat, axis = 1)\n    df_num = df.select_dtypes(include=np.number)\n    df_num = df_num.loc[:,relevant_num_features]\n    \n    return pd.concat([df_cat, df_num], axis=1)","bd7e8b57":"# creating label vector y_train and remove it from data_train\n# cleaning data from train and test_set using helper function\ny_train = data_train['SalePrice']\ndata_train = data_train.drop('SalePrice', axis = 1)\ndata_train = select_relevant_data(data_train,relevant_num_features,low_relevant_cat)\ndata_test = select_relevant_data(data_test,relevant_num_features,low_relevant_cat)","407836d5":"#splitting training data into features and labels\nX_train = data_train\nX_train_cat = X_train.select_dtypes(include=object)\nX_train_num = X_train.select_dtypes(include=np.number)\nX_test = data_test\nX_test_cat = X_test.select_dtypes(include=object)\nX_test_num = X_test.select_dtypes(include=np.number)","5ea0ae93":"#prepare data for ML algorithm\n#For number features impute NaN values with median. Standard scale features.\n#For categorical features use ordinal encoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.compose import ColumnTransformer\n\nnum_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy=\"median\")),\n    ('std_scaler', StandardScaler()),\n])\n\ncat_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='constant', fill_value='-1')),\n    ('ordinal_encoder', OrdinalEncoder()),\n])\n\n\nnum_attribs = list(X_train_num)\ncat_attribs = list(X_train_cat)\n\nfull_pipeline = ColumnTransformer([\n(\"num\", num_pipeline, num_attribs),\n(\"cat\", cat_pipeline, cat_attribs),\n])\n\n#pipeline has to be fitted to training and test set in order for the ordinal_encoder to work for for both sets\nX_fit = X_train.append(X_test, ignore_index=True)\nfull_pipeline.fit(X_fit)\nX_train_prepared = full_pipeline.transform(X_train)","3b7e776b":"# Using XGBoostRegressor to model SalePrice\n# Using GridSearchCV to test different parameter sets\nimport xgboost\nfrom sklearn.model_selection import GridSearchCV\n\nxgb_reg = xgboost.XGBRegressor()\n\n# A parameter grid for XGBoost\nparam_grid =  {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0.5, 1, 1.5, 2, 5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5]\n        }\n\ngrid_search = GridSearchCV(xgb_reg, param_grid, cv=5,\n                           scoring='neg_mean_squared_error',\n                           return_train_score=True)\ngrid_search.fit(X_train_prepared, y_train)","ae3628bd":"print(grid_search.best_params_)\nprint(grid_search.best_estimator_)","35907977":"cvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)","47f5b121":"final_model = grid_search.best_estimator_","40608079":"X_test_prepeared = full_pipeline.transform(X_test)\npredictions = final_model.predict(X_test_prepeared)","5cd3e1c9":"ImageId = np.arange(1461,1461+len(predictions))\nSalePrice = np.array(predictions)\nnew_submission = pd.DataFrame({'Id': ImageId, 'SalePrice': SalePrice})\nnew_submission.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","da1b09b0":"new_submission","9de793f4":"Next, I check which features of the dataset can be removed because they don't contain enough data (> 50% missing values)","676e1450":"Removing features with | correlation coefficient | < 0.20\n- **BedroomAbvGr**                  0.168213\n- **ScreenPorch**                   0.111447\n- **PoolArea**                      0.092404\n- **MoSold**                        0.046432\n- **3SsnPorch**                     0.044584\n- **BsmtFinSF2**                   -0.011378\n- **BsmtHalfBath**                 -0.016844\n- **MiscVal**                      -0.021190\n- **Id**                           -0.021917\n- **LowQualFinSF**                 -0.025606\n- **YrSold**                       -0.028923\n- **OverallCond**                  -0.077856\n- **MSSubClass**                   -0.084284\n- **EnclosedPorch**                -0.128578\n- **KitchenAbvGr**                 -0.135907\n\n**'SalePrice'** column needs to be removed!","c461edff":"Dropping **'PoolQC'**, **'MiscFeature'**, **'Alley'** and **'Fence'** columns because more than 50% of the values are empty. All features are categorical features.","87061076":"Removing the following features: **'GarageYrBlt'**, **'1stFlrSF'**, **'TotRmsAbvGrd'** and **'GarageArea'**","3f0bf2a4":"If correlation between two columns is high (>0.8) one of them can be dropped because they don't add much more information:"}}