{"cell_type":{"7c2d07d0":"code","e11f5f1e":"code","85c9390b":"code","f8794992":"code","5648d41d":"code","9e27a6ba":"code","aee6a123":"code","1f6f283a":"code","fc7a4d89":"code","3675faf6":"code","c272174d":"code","2ea5b9ee":"code","e2b85f26":"code","389ed636":"code","3a060fcb":"code","c13ebc14":"code","c563a223":"markdown","f46f536d":"markdown","6d8bb1c1":"markdown"},"source":{"7c2d07d0":"%config Completer.use_jedi = False","e11f5f1e":"import os\nimport datetime\nimport glob\nimport time\nimport cv2\nimport itertools\nfrom tqdm.notebook import tqdm\nimport shutil\n\nfrom PIL import Image\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\n\nimport torchvision.transforms as transforms\nfrom torchvision.utils import make_grid","85c9390b":"img_path = '..\/input\/gan-getting-started\/'\nmonet_path = glob.glob(img_path + 'monet_jpg\/*')\nphoto_path = glob.glob(img_path + 'photo_jpg\/*')\n\nprint('Dataset')\nprint(f'- monet data : {len(monet_path)}\\n- photo data : {len(photo_path)}')","f8794992":"class Custom_dataset(Dataset):\n    def __init__(self, img_path : list , transforms = None, mode = 'train'):\n        super().__init__()\n\n        self.path_monet = img_path[0]\n        self.path_photo = img_path[1]\n        self.transforms = transforms\n        self.mode = mode\n        \n    def __getitem__(self, idx):\n        if self.mode == 'train':\n            monet_img = self.path_monet[idx]\n            monet_img = Image.open(monet_img).convert('RGB')\n            monet_img = self.transforms(monet_img)\n            \n            photo_idx = np.random.randint(0, len(self.path_photo))\n            photo_img = self.path_photo[photo_idx]\n            photo_img = Image.open(photo_img).convert('RGB')\n            photo_img = self.transforms(photo_img)\n            \n            return monet_img, photo_img\n    \n    def __len__(self):\n        if self.mode == 'train':\n            return len(self.path_monet)\n        elif self.mode == 'test':\n            return len(self.path_photo)","5648d41d":"def show_img(img):\n    img = make_grid(img, nrow = 6).permute([1, 2, 0]).detach().numpy()\n    plt.figure(figsize = (12, 8))\n    plt.imshow(img)\n    plt.show()","9e27a6ba":"img_path = [monet_path, photo_path]\nsample_transform = transforms.Compose([\n    transforms.ToTensor()\n])\nsample = Custom_dataset(img_path = img_path, transforms = sample_transform, mode = 'train')\nsample_loader = DataLoader(sample, batch_size = 6)\nsample_monet, sample_photo = next(iter(sample_loader))","aee6a123":"print('Monet data')\nshow_img(sample_monet)\n\nprint('Photo data')\nshow_img(sample_photo)","1f6f283a":"# Define Conv Block\n'''\n1. Conv_up\n2. Conv_down\n3. Residual_block\n'''\n\n# 1.Conv_up\nclass Conv_up(nn.Module):\n    '''\n    convTranspose - instanceNorm - ReLU - (dropout)\n    '''\n    def __init__(self, in_ch, out_ch, kernel_size = 4, stride = 2, \n                 padding = 1, output_padding = 1, drop_out = True):\n        super().__init__()\n        \n        self.convT = nn.ConvTranspose2d(in_ch, out_ch,\n                                       kernel_size = kernel_size,\n                                       stride = stride,\n                                       padding = padding,\n                                       output_padding = output_padding,\n                                       bias = False)\n        self.instance_norm = nn.InstanceNorm2d(out_ch)\n        self.relu = nn.ReLU()\n        self.drop_out = drop_out\n        \n    def forward(self, x):\n        x = self.convT(x)\n        x = self.instance_norm(x)\n        x = self.relu(x)\n        if self.drop_out:\n            x = nn.Dropout2d(0.5)(x)\n\n        return x\n\n# 2. Conv_down\nclass Conv_down(nn.Module):\n    '''\n    Conv2d - instanceNorm - LeakyReLU\n    '''\n    def __init__(self, in_ch, out_ch,\n                 kernel_size = 4,\n                 stride = 2,\n                 padding = 1,\n                 batch_Norm = True):\n        super().__init__()\n        \n        self.conv = nn.Conv2d(in_ch, out_ch,\n                             kernel_size = kernel_size,\n                             stride = stride,\n                             padding = padding,\n                             bias = True)\n        self.instance_norm = nn.InstanceNorm2d(out_ch)\n        self.relu = nn.ReLU()\n        self.batch = batch_Norm\n        \n    def forward(self, x):\n        x = self.conv(x)\n        if self.batch:\n            x = self.instance_norm(x)\n        x = self.relu(x)\n        \n        return x\n    \n# 3. Residual_block\nclass Residual_block(nn.Module):\n    '''\n    Conv2d - InstanceNorm - Relu - Conv2d - InstanceNorm\n    '''\n    def __init__(self, in_ch, out_ch, kernel_size = 3, stride = 1, padding = 1):\n        super().__init__()\n        \n        self.res = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch,\n                     kernel_size = kernel_size,\n                     stride = stride,\n                     padding = padding,\n                     padding_mode = 'reflect',\n                     bias = False),\n            nn.InstanceNorm2d(out_ch),\n            nn.ReLU(),\n            nn.Conv2d(out_ch, out_ch,\n                     kernel_size = kernel_size,\n                     stride = stride,\n                     padding = padding,\n                     padding_mode = 'reflect',\n                     bias = False),\n            nn.InstanceNorm2d(out_ch)\n        )\n    \n    def forward(self, x):\n        return x + self.res(x)","fc7a4d89":"class Discriminator(nn.Module):\n    '''\n    C64 - C128 - C256 - C512 - C512 - 1\n    '''\n    def __init__(self, n_features = 64):\n        super().__init__()\n        \n        self.main = nn.Sequential(\n            Conv_down(3, n_features, batch_Norm = False),\n            Conv_down(n_features * 1, n_features * 2),\n            Conv_down(n_features * 2, n_features * 4),\n            Conv_down(n_features * 4, n_features * 8, stride = 1),\n            nn.Conv2d(n_features * 8, 1, 4, 1, 1, bias = False)\n        )\n    \n    def forward(self, x):\n        x = self.main(x)\n        \n        return x\n    \ndef test():\n    D = Discriminator()\n    x = torch.randn(1, 3, 256, 256)\n    out = D(x)\n    print(out.shape)\n    print('Discriminator is OK')\n    \ntest()","3675faf6":"class Generator(nn.Module):\n    '''\n    kernel   D64 - D128 - D256 - R256 * n - U128 - U64 - U3\n    filter   7x7 - 3x3  - 3x3  -          -  3x3 - 3x3 - 7x7\n    stride    1     2      2       1          2     2     1\n    '''\n    def __init__(self, n_features = 64, n_res = 9):\n        super().__init__()\n        \n        self.main = nn.Sequential(\n            nn.ReflectionPad2d(3),\n            Conv_down(3, n_features, 7, 1, 0, False),\n            Conv_down(n_features * 1, n_features * 2, 3, 2),\n            Conv_down(n_features * 2, n_features * 4, 3, 2),\n            *[\n                Residual_block(n_features * 4, n_features * 4) for _ in range(n_res)\n            ],\n            Conv_up(n_features * 4, n_features * 2, 3, 2, 1),\n            Conv_up(n_features * 2, n_features * 1, 3, 2, 1),\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(n_features, 3, 7, 1, 0, bias = False),\n            nn.Tanh()   \n        )\n        \n    def forward(self, x):\n        x = self.main(x)\n        \n        return x\n    \ndef test():\n    G = Generator()\n    x = torch.randn(1, 3, 256, 256)\n    out = G(x)\n    print(out.shape)\n    print('Generator is OK')\n    \ntest()","c272174d":"# weight initialization \ndef weight_init(m : 'model'):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('Instance') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)","2ea5b9ee":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n# Define Generator\n# monet -> photo\nnetG_A = Generator().to(device)\n# photo -> monet\nnetG_B = Generator().to(device)\n\n# Define Discrimator\nnetD_A = Discriminator().to(device)\nnetD_B = Discriminator().to(device)\n\n# weight initialization\nweight_init(netG_A)\nweight_init(netG_B)\nweight_init(netD_A)\nweight_init(netD_B)\n\n# setting\nEPOCHS = 100\nlr = 2e-4\nb1 = 0.5\nb2 = 0.999\n\n# optimizer\nnetG_optim = optim.Adam(itertools.chain(netG_A.parameters(), netG_B.parameters()), lr = lr, betas = (b1, b2))\nnetD_optim = optim.Adam(itertools.chain(netD_A.parameters(), netD_B.parameters()), lr = lr, betas = (b1, b2))","e2b85f26":"# Data loader\ntransform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize([0.5, 0.5, 0.5], \n                                [0.5, 0.5, 0.5])\n])\n\ntrain_dataset = Custom_dataset([monet_path, photo_path], transforms = transform, mode = 'train')\ntrain_loader = DataLoader(train_dataset, batch_size = 1, shuffle = True)","389ed636":"# loss function\n'''\n1. GAN loss - L2\n2. Cycle loss - L1\n3. Identity loss - L1\n'''\n\nGAN_LOSS = nn.MSELoss()\nCycle_LOSS = nn.L1Loss()\nIdentity_LOSS = nn.L1Loss()\n\ndef train_model(EPOCHS = EPOCHS):\n    train_hist = {}\n    train_hist['G_losses'] = []\n    train_hist['D_losses'] = []\n    \n    print('train is starting')\n    \n    for epoch in range(EPOCHS):\n        t = time.time()\n        \n        netG_A.train()\n        netG_B.train()\n        \n        netD_A.train()\n        netD_B.train()\n        \n        G_losses = 0\n        D_losses = 0\n        \n        for A, B in train_loader:\n            # A : monet, B : photo\n            A, B = A.to(device), B.to(device)\n            \n            A2B = netG_A(A) # fake B\n            B2A = netG_B(B) # fake A\n            \n            pred_real_A = netD_A(A)\n            pred_fake_A = netD_A(B2A.detach())\n            \n            # GAN LOSS for Discrimiator\n            D_A_loss = GAN_LOSS(pred_real_A, torch.ones_like(pred_real_A)) +\\\n                        GAN_LOSS(pred_fake_A, torch.zeros_like(pred_fake_A))\n\n            pred_real_B = netD_B(B)\n            pred_fake_B = netD_B(A2B.detach())\n            \n            D_B_loss = GAN_LOSS(pred_real_B, torch.ones_like(pred_real_B)) +\\\n                        GAN_LOSS(pred_fake_B, torch.zeros_like(pred_fake_B))\n            \n            D_loss = (D_A_loss + D_B_loss) \/ 2\n                    \n            \n            A2B2A = netG_B(A2B) # fake A\n            B2A2B = netG_A(B2A) # fake B\n            \n            pred_fake_A = netD_A(B2A)\n            pred_fake_B = netD_B(A2B)\n            \n            # GAN LOSS for Generator\n            \n            G_GAN_loss = GAN_LOSS(pred_fake_A, torch.ones_like(pred_fake_A)) +\\\n                          GAN_LOSS(pred_fake_B, torch.ones_like(pred_fake_B))\n            \n            # Cycle LOSS\n            G_Cycle_loss = Cycle_LOSS(A2B2A, A) + Cycle_LOSS(B2A2B, B)\n            \n            # Identity LOSS\n            G_identity_loss = Identity_LOSS(netG_A(B), B) + Identity_LOSS(netG_B(A), A)\n            \n            G_loss = G_GAN_loss + 10 * G_Cycle_loss + 5 * G_identity_loss\n               \n            # backward Generator\n            netG_optim.zero_grad()\n            G_loss.backward()\n            netG_optim.step()\n         \n            # backward Discriminator\n            netD_optim.zero_grad()\n            D_loss.backward()\n            netD_optim.step()     \n            \n            D_losses += D_loss \/ len(train_loader)\n            G_losses += G_loss \/ len(train_loader)\n            \n        print(f'[{epoch + 1}\/{EPOCHS}]\\tD_loss : {D_losses:.6f}\\tG_loss : {G_losses:.6f}\\ttime : {time.time() - t:.3f}s')\n     \n        train_hist['G_losses'].append(G_losses.item())\n        train_hist['D_losses'].append(D_losses.item())\n\n        # save model per 10epochs\n        if (epoch + 1) % 10 == 0:\n            if not os.path.exists('\/kaggle\/working\/model_G'):\n                os.makedirs('\/kaggle\/working\/model_G')\n\n            if not os.path.exists('\/kaggle\/working\/model_D'):\n                os.makedirs('\/kaggle\/working\/model_D')\n\n            # save Generator\n            torch.save(netG_A, '\/kaggle\/working\/model_G\/' + f'netG(uNet)_A{epoch + 1}.pt')\n            torch.save(netG_B, '\/kaggle\/working\/model_G\/' + f'netG(uNet)_B{epoch + 1}.pt')\n\n            # save Discriminator\n            torch.save(netD_A, '\/kaggle\/working\/model_D\/' + f'netD(uNet)_A{epoch + 1}.pt')\n            torch.save(netD_B, '\/kaggle\/working\/model_D\/' + f'netD(uNet)_B{epoch + 1}.pt')\n\n            print(f'Model is saved at {epoch + 1}epochs')\n\n\n    return train_hist","3a060fcb":"train_hist = train_model(EPOCHS)","c13ebc14":"plt.plot(train_hist['G_losses'], label = 'G loss')\nplt.plot(train_hist['D_losses'], label = 'D loss')\nplt.legend()\nplt.show()","c563a223":"## Modeling","f46f536d":"## Data loader","6d8bb1c1":"## Train"}}