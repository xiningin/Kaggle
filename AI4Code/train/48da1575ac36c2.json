{"cell_type":{"5f0a8d0f":"code","edbe834b":"code","bae77d43":"code","b2291b80":"code","d5408580":"code","93dc634b":"code","c84a0a71":"code","3974491e":"code","1920087a":"code","5ad4aeb3":"code","8edfd889":"code","f64c6ec2":"code","67a2da5b":"code","db4912a7":"code","a1e817a7":"code","0ee41254":"code","29c8a3b4":"code","2aeaef7f":"code","ed7878eb":"code","19eeb37c":"markdown","43f4b239":"markdown","e1aa7c35":"markdown","8a494f74":"markdown","83d6cd0b":"markdown","b96a647a":"markdown","ec735d5d":"markdown","168a5e9e":"markdown"},"source":{"5f0a8d0f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport PIL\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nimport pathlib\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","edbe834b":"train_dir = pathlib.Path(\"\/kaggle\/input\/covid19-image-dataset\/Covid19-dataset\/train\")\ntest_dir = pathlib.Path(\"\/kaggle\/input\/covid19-image-dataset\/Covid19-dataset\/test\")","bae77d43":"train_count = len(list(train_dir.glob('*\/*.*')))\ntest_count = len(list(test_dir.glob('*\/*.*')))\n\nprint(\"Images in Training set : {} \\nImages in Test det : {}\".format(train_count,test_count))","b2291b80":"covid_train = list(train_dir.glob(\"Covid\/*\"))\npnemonia_train = list(train_dir.glob(\"Viral Pneumonia\/*\"))\nnormal_train = list(train_dir.glob(\"Normal\/*\"))","d5408580":"print(\"Sample Image for Covid-19 X-Ray\")\ncovid_img = PIL.Image.open(covid_train[1])\nprint(\"Size = \",covid_img.size)\ncovid_img","93dc634b":"print(\"Sample Image for Normal X_Ray\")\nnormal_img = PIL.Image.open(normal_train[2])\nprint(\"Size = \",normal_img.size)\nnormal_img","c84a0a71":"print(\"Sample Image for Pnemonia X_Ray\")\npnemonia_img = PIL.Image.open(pnemonia_train[2])\nprint(\"Size = \",pnemonia_img.size)\npnemonia_img","3974491e":"batch_size = 16\nimg_h = 300\nimg_w = 300","1920087a":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  train_dir,\n  image_size=(img_h, img_w),\n  batch_size=batch_size)","5ad4aeb3":"test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  test_dir,\n  image_size =(img_h,img_w),\n  batch_size = batch_size)","8edfd889":"class_names = train_ds.class_names\nprint(class_names)","f64c6ec2":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")","67a2da5b":"# Checking image size and batch size\nfor image_batch, labels_batch in train_ds:\n    print(image_batch.shape)\n    print(labels_batch.shape)\n    break","db4912a7":"# Normalizing layer to normalize the data before applying model\n\nnormalizing_layer = layers.experimental.preprocessing.Rescaling(1.\/255)\n","a1e817a7":"num_classes = 3\n\nmodel = Sequential([\n    normalizing_layer,\n    layers.Conv2D(16,3, padding = \"same\", activation = \"relu\"),\n    layers.MaxPooling2D(),\n    layers.Conv2D(32,3, padding = \"same\", activation = \"relu\"),\n    layers.MaxPooling2D(),\n    layers.Flatten(),\n    layers.Dense(128,activation = \"relu\"),\n    layers.Dense(num_classes)\n])","0ee41254":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","29c8a3b4":"epochs=15\nhistory = model.fit(\n  train_ds,\n  validation_data=test_ds,\n  epochs=epochs)","2aeaef7f":"model.summary()","ed7878eb":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()\n","19eeb37c":"## Importing and analysing Data","43f4b239":"## Import Libraries","e1aa7c35":"## Visualizing the dataset","8a494f74":"## Load in tensorflow and preprocessing","83d6cd0b":"## Making and applying model","b96a647a":"We can see a darker path in covid lung X-Ray, no visible differeence in normal and pnemonia X-Ray","ec735d5d":"## Steps\n* Load files\n* View files from each class\n* Load in tensorflow \n* Preprocess\n* Apply Model\n* Check accuracy\n* Tune model to improve Accuracy if required\n* Result","168a5e9e":"* Image has 3 channels"}}