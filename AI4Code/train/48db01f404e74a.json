{"cell_type":{"647ddfe9":"code","d98ff47c":"code","bc8417b1":"code","7d5a4921":"code","d2ff5c79":"code","839d579f":"code","5865cd3a":"code","0870c737":"code","73b6094d":"code","dbad3ebd":"code","1b2c0ba9":"code","9cc4d37f":"code","af6233b0":"code","a35c15ae":"code","2ebd73df":"code","8834010e":"code","74c95f6f":"code","92a5933f":"code","35b5b6ce":"code","a8cb4c0e":"code","07736aa2":"code","4783c6c1":"code","e9c920e4":"markdown","9265c3cd":"markdown","bad742dc":"markdown","52475485":"markdown","5c808a5d":"markdown","b38efae0":"markdown","0845c716":"markdown","ec4362d6":"markdown","39e93f87":"markdown","42fa8837":"markdown","5e179ea8":"markdown","c05a5cf0":"markdown","c2b92c00":"markdown","b0f3d6f8":"markdown","9b92e8fc":"markdown","b01fc9fc":"markdown","d136481a":"markdown","17b62ff0":"markdown","0f95cd1b":"markdown"},"source":{"647ddfe9":"import pylab\nimport calendar\nimport numpy as np\nimport pandas as pd\nimport seaborn as sn\nfrom scipy import stats\nimport missingno as msno\nfrom datetime import datetime\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom scipy.stats import kendalltau\nimport warnings\nmatplotlib.style.use('ggplot')\npd.options.mode.chained_assignment = None\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","d98ff47c":"train = pd.read_csv('..\/input\/zillow-prize-1\/train_2016_v2.csv',\n                    parse_dates = ['transactiondate']) # parsing data as date type\nproperties = pd.read_csv('..\/input\/zillow-prize-1\/properties_2016.csv')","bc8417b1":"print('shape of train :', train.shape)\nprint('shape of properties :', properties.shape)","7d5a4921":"merged = pd.merge(train,properties,on=\"parcelid\",how=\"left\")","d2ff5c79":"merged.head(3).transpose().head(10)","839d579f":"missingValueColumns = merged.columns[merged.isnull().any()].tolist()\nmsno.bar(merged[missingValueColumns],\\\n            figsize=(20,8),color=\"#34495e\",fontsize=12,labels=True,)","5865cd3a":"msno.matrix(merged[missingValueColumns], width_ratios = (10, 1), \\\n           figsize=(20,8), fontsize = 12, sparkline=True, labels = True)","0870c737":" msno.heatmap(merged[missingValueColumns],figsize=(20,20))","73b6094d":"from sklearn import model_selection, preprocessing\nimport xgboost as xgb\nimport warnings\nwarnings.filterwarnings('ignore')\n\nmergedFilterd = merged.fillna(-999)\n\nfor f in mergedFilterd.columns:\n    if mergedFilterd[f].dtype == 'object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(mergedFilterd[f].values))\n        mergedFilterd[f] = lbl.transform(list(mergedFilterd[f].values))\n\ntrain_y = mergedFilterd.logerror.values\ntrain_x = mergedFilterd.drop([\"parcelid\", \"transactiondate\", \"logerror\"], axis=1)\n        \nxgb_params = {\n    'eta': 0.05,\n    'max_depth': 8,\n    'subsample': 0.7,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'silent': 1\n}\n\ndtrain = xgb.DMatrix(train_x, train_y, feature_names = train_x.columns.values)\n# silent 0 means printing running messages, 1 means silent mode.\n# right now, verbosity parameter works as silent\nmodel = xgb.train(dict(xgb_params, verbosity=0), dtrain, num_boost_round=10)","dbad3ebd":"featureImportance = model.get_fscore()\nfeatures = pd.DataFrame()\nfeatures['features'] = featureImportance.keys()\nfeatures['importance'] = featureImportance.values()\nfeatures.sort_values(by=['importance'], ascending = False, inplace = True)\n\nfig, ax = plt.subplots()\nfig.set_size_inches(20,10)\nplt.xticks(rotation=90)\nsn.barplot(data=features.head(15),x=\"importance\",y=\"features\",ax=ax,orient=\"h\",color=\"#34495e\")","1b2c0ba9":"topfeatures = features['features'].tolist()[:20]\ncorrmatt = merged[topfeatures].corr()\nmask = np.array(corrmatt)\nmask[np.tril_indices_from(mask)] = False\nfig, ax = plt.subplots()\nfig.set_size_inches(20, 10)\nsn.heatmap(corrmatt, mask=mask, vmax = 0.8, square = True)","9cc4d37f":"# url : https:\/\/ysyblog.tistory.com\/122\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndef calculate_vif_(x):\n    variables = list(x.columns)\n    vif = {variable:variance_inflation_factor(exog=x.values, exog_idx=ix) for ix, variable in enumerate(list(x.columns))}\n    return vif\n\nnumericalcol = []\nfor f in merged.columns:\n    if merged[f].dtype != 'object' and f not in [\"parcelid\", \"transactiondate\", \"logerror\"]:\n        numericalcol.append(f)\nmergedfiltered = merged[numericalcol].fillna(-999)\nvifdict = calculate_vif_(mergedfiltered)\n\nvifdf = pd.DataFrame()\nvifdf['variables'] = vifdict.keys()\nvifdf['vifscore'] = vifdict.values()\nvifdf.sort_values(by = ['vifscore'], ascending=False, inplace = True)\nvalidvariables = vifdf[vifdf['vifscore']<=5]\nvariableswithmc = vifdf[vifdf['vifscore']>5]\n\nfig, (ax1, ax2) = plt.subplots(ncols = 2)\nfig.set_size_inches(20, 8)\nsn.barplot(data = validvariables, x='vifscore', y='variables', ax=ax1, orient='h')\nsn.barplot(data=variableswithmc.head(5),x=\"vifscore\",y=\"variables\",ax=ax2,orient=\"h\",color=\"#34495e\")\nax1.set(xlabel='VIF Scores', ylabel='Features',title=\"Valid Variables Without Multicollinearity\")\nax2.set(xlabel='VIF Scores', ylabel='Features',title=\"Variables Which Exhibit Multicollinearity\")","af6233b0":"ulimit = np.percentile(merged.logerror.values, 99)\nllimit = np.percentile(merged.logerror.values, 1)\nmerged['logerror'].iloc[merged['logerror']>ulimit] = ulimit\nmerged['logerror'].iloc[merged['logerror']<llimit] = llimit\n\nfig, ax = plt.subplots()\nfig.set_size_inches(20, 5)\nsn.distplot(merged.logerror.values, bins = 50, kde=False, ax=ax)\nax.set(xlabel = 'logerror', ylabel = 'vif score', title='distribution of dependent variable')","a35c15ae":"train['year'] = train.transactiondate.map(lambda x: str(x).split('-')[0])\ntrain['month'] = train.transactiondate.map(lambda x: str(x).split('-')[1])\ntrain['day'] = train.transactiondate.map(lambda x: str(x).split('-')[2].split()[0])\n\ntraingroupedmonth = train.groupby(['month'])['logerror'].mean().to_frame().reset_index()\ntraingroupedday = train.groupby(['day'])['logerror'].mean().to_frame().reset_index()\nfig, (ax1, ax2) = plt.subplots(nrows = 2)\nfig.set_size_inches(20, 15)\n\nsn.pointplot(x=traingroupedmonth['month'], y=traingroupedday['logerror'],\n             data=traingroupedmonth, join = True, ax=ax1)\nax1.set(xlabel = 'month of the year', ylabel = 'log error', title ='average log error across month of 2016', label = 'big')\n\nsn.countplot(x=train['month'], data = train, ax=ax2)\nax2.set(xlabel='Month Of The Year', ylabel='No Of Occurences',title=\"No Of Occurunces Across Month In 2016\",label='big')","2ebd73df":"fig,(ax1,ax2)= plt.subplots(nrows=2)\nfig.set_size_inches(20,15)\n\nsn.pointplot(x=traingroupedday[\"day\"], y=traingroupedday[\"logerror\"], data=traingroupedday, join=True,ax=ax1,color=\"#34495e\")\nax1.set(xlabel='Day Of The Month', ylabel='Log Error',title=\"Average Log Error Across Days Of The Month In 2016\",label='big')\n\nsn.countplot(x=train[\"day\"], data=train,ax=ax2,color=\"#34495e\")\nax2.set(xlabel='Day Of The Month', ylabel='No Of Occurences',title=\"No Of Occurences Across Days Of The Month In 2016\",label='big')","8834010e":"fig, ax1 = plt.subplots()\nfig.set_size_inches(20, 10)\nmerged['yearbuilt'] = merged['yearbuilt'].map(lambda x:str(x).split('.')[0])\nyearmerged = merged.groupby(['yearbuilt', 'numberofstories'])[\"parcelid\"].count().unstack('numberofstories').fillna(0)\nyearmerged.plot(kind='bar', stacked=True,ax=ax1)","74c95f6f":"cols = [\"bathroomcnt\",\"bedroomcnt\",\"roomcnt\",\"numberofstories\",\"logerror\",\"calculatedfinishedsquarefeet\"]\nmergedFiltered = merged[cols].dropna()\nfor col in cols:\n    ulimit = np.percentile(mergedFiltered[col].values, 99.5)\n    llimit = np.percentile(mergedFiltered[col].values, 0.5)\n    mergedFiltered[col].iloc[mergedFiltered[col]>ulimit] = ulimit\n    mergedFiltered[col].iloc[mergedFiltered[col]<llimit] = llimit","92a5933f":"plt.figure(figsize=(8, 8))\nsn.jointplot(x = mergedFiltered.calculatedfinishedsquarefeet.values, \n             y = mergedFiltered.logerror.values, size = 10, kind = 'hex')\nplt.ylabel('log error', fontsize = 12)\nplt.xlabel('calculated finished square feet', fontsize = 12)\nplt.show()","35b5b6ce":"fig, ax = plt.subplots()\nfig.set_size_inches(20, 5)\nsn.boxplot(x='bedroomcnt', y='logerror', data = mergedFiltered, ax=ax)\nax.set(ylabel='log error', xlabel = 'bedroom count', title = 'bedroom count vs log error')","a8cb4c0e":"fig,ax= plt.subplots()\nfig.set_size_inches(20,5)\nsn.boxplot(x=\"roomcnt\", y=\"logerror\", data=mergedFiltered,ax=ax,color=\"#34495e\")\nax.set(ylabel='Log Error',xlabel=\"Room Count\",title=\"Room Count Vs Log Error\")","07736aa2":"fig,ax= plt.subplots()\nfig.set_size_inches(20,5)\nsn.boxplot(x=\"numberofstories\", y=\"logerror\", data=mergedFiltered,ax=ax,color=\"#34495e\")\nax.set(ylabel='Log Error',xlabel=\"No Of Storeys\",title=\"No Of Storeys Vs Log Error\")","4783c6c1":"from mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib import pyplot\nfig = pylab.figure()\nfig.set_size_inches(20,10)\nax = Axes3D(fig)\n\nax.scatter(mergedFiltered.bathroomcnt, mergedFiltered.bedroomcnt, mergedFiltered.logerror)\nax.set_xlabel('Bathroom Count')\nax.set_ylabel('Bedroom Count')\nax.set_zlabel('Log Error');\npyplot.show()","e9c920e4":"### Let's Merge train and properties to facilitate EDA","9265c3cd":"#### This kernel used dataset from the Zillow Prize: Zillow\u2019s Home Value Prediction and copied from the 'Zillow EDA On Missing Values & Multicollinearity' written by Vivek Srinivasan.\n\n#### Introduction to 'Zillow EDA On Missing Values & Multicollinearity' : [URL](https:\/\/www.kaggle.com\/viveksrinivasan\/zillow-eda-on-missing-values-multicollinearity)\n\n#### Thanks for sharing kernel, Vivek Srinivasan.","bad742dc":"### Missing Value Analysis","52475485":"### Calculated Finished Square Feet Vs Log Error","5c808a5d":"### Bedroom count vs log error","b38efae0":"### Top Features Selection","0845c716":"### Bivariate Analysis","ec4362d6":"### Shape of the dataset","39e93f87":"### Univariate Analysis\nDependent variable logerror follows nice normal distribution","42fa8837":"### First Few rows of data","5e179ea8":"### No Of Storeys Vs Log Error","c05a5cf0":"### No Of Storey Over The Years\nIt is quite interesting to notice people started building more of 2 or 3 storey buildings After 1950","c2b92c00":"### Bedroom Vs Bathroom Vs Log Error\u00b6","b0f3d6f8":"### Correlation Analysis","9b92e8fc":"### The notebook covers following topics\n\n- Missing Value Analysis\n- Correlation Analysis\n- Top Contributing Features (Through XGBoost)\n- Correlation Analysis \n- Multicollinearity Analysis (reference info = [URL](https:\/\/ko.wikipedia.org\/wiki\/%EB%8B%A4%EC%A4%91%EA%B3%B5%EC%84%A0%EC%84%B1))\n- Univariate Analysis (reference info = [URL](https:\/\/mansoostat.tistory.com\/23))\n- Bivariate Analysis","b01fc9fc":"### Multicollinearity Analysis","d136481a":"### Reading in Dataset","17b62ff0":"### Room Count Vs Log Error","0f95cd1b":"### Global Imports"}}