{"cell_type":{"aa7d7804":"code","d1d76fc3":"code","484439fa":"code","7d2917f8":"code","e5f031db":"code","2ce6c5ac":"code","39f652dd":"code","e85f0244":"code","d62afbac":"code","f716227a":"code","6400ded5":"code","ec7db55b":"code","8fcab5ad":"code","c28bda4c":"code","49f300fc":"code","7d9abb97":"code","2b371ee7":"code","119e18bd":"code","2abf9185":"code","7eeee971":"code","ee16eb38":"code","37b2f98c":"code","d793320d":"code","ed9a4996":"code","6086832f":"code","ca330de5":"code","0c700104":"code","c6f207d0":"code","9da395ce":"code","02c0af4c":"code","57f3885b":"code","eee109e3":"code","b614c254":"code","615739b3":"code","c6aace83":"markdown"},"source":{"aa7d7804":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d1d76fc3":"Train=pd.read_csv('..\/input\/covid19-global-forecasting-week-1\/train.csv')","484439fa":"Train['Lat'].fillna(12.5,inplace=True)\nTrain['Long'].fillna(-70.0,inplace=True)","7d2917f8":"Train['Province\/State'].fillna(\"NA\",inplace=True)","e5f031db":"Lat_longs=Train[['Province\/State', 'Country\/Region','Lat','Long']].groupby(['Country\/Region','Province\/State']).mean()\nplt.scatter(Lat_longs['Lat'],Lat_longs['Long'],linewidths=.001)","2ce6c5ac":"from sklearn.cluster import KMeans\nclusters=np.arange(2,21,1)\nwss=[]\nfor i in clusters:\n    cl=KMeans(n_clusters=i,max_iter=200)\n    cl.fit(Lat_longs)\n    wss.append(cl.inertia_)","39f652dd":"plt.plot(wss)","e85f0244":"cl_4=KMeans(n_clusters=4,max_iter=2000)\ncl_4.fit(Lat_longs)\nLat_longs['Clusters']=cl_4.predict(Lat_longs)+1\nplt.scatter('Lat','Long',linewidths=.001,c='Clusters',data=Lat_longs)","d62afbac":"Train['Clusters']=cl_4.predict(Train[['Lat','Long']])+1\nTrain['Date']=pd.to_datetime(Train['Date'])\nRegions=Lat_longs.index\nl=len(Regions)\nl","f716227a":"First_ConfirmedCases=[]\nFirst_Fatalities=[]\nfor i in range(l):\n    temp_dataset=Train[(Train['Country\/Region']==Regions[i][0]) & (Train['Province\/State']==Regions[i][1])]\n    First_ConfirmedCases.append(temp_dataset['Date'][temp_dataset['ConfirmedCases']>0].min())\n    First_Fatalities.append(temp_dataset['Date'][temp_dataset['Fatalities']>0].min())\nCountry=[]\nState=[]\nfor i in range(l):\n    Country.append(Regions[i][0])\n    State.append(Regions[i][1])\n#pd.Series(First_Fatalities)\nDates_cases_Fatalities=pd.DataFrame({'Country\/Region':Country,\n                                     'Province\/State':State,\n                                     'First_ConfirmedCases':First_ConfirmedCases,\n                                     'First_Fatalities':First_Fatalities})\n#Train['First_ConfirmedCases'].fillna(Train['Date'].max(),inplace=True)\n#Train['First_Fatalities'].fillna(Train['Date'].max(),inplace=True)\nTrain=Train.merge(Dates_cases_Fatalities)","6400ded5":"Train['Date_After_First_Fatalities']=Train['Date']-Train['First_Fatalities']\nTrain['Date_After_First_ConfirmedCases']=Train['Date']-Train['First_ConfirmedCases']\nTrain['Date_After_First_Fatalities']=Train['Date_After_First_Fatalities'].dt.days\nTrain['Date_After_First_ConfirmedCases']=Train['Date_After_First_ConfirmedCases'].dt.days\nTrain['Date_After_First_Fatalities'][Train['Date_After_First_Fatalities']<0]=0\nTrain['Date_After_First_ConfirmedCases'][Train['Date_After_First_ConfirmedCases']<0]=0","ec7db55b":"Train.sort_values(by='Date',inplace=True)\nTrain_7=Train.iloc[0*284:(59-7)*284]\nTrain_6=Train.iloc[1*284:(59-6)*284]\nTrain_5=Train.iloc[2*284:(59-5)*284]\nTrain_4=Train.iloc[3*284:(59-4)*284]\nTrain_3=Train.iloc[4*284:(59-3)*284]\nTrain_2=Train.iloc[5*284:(59-2)*284]\nTrain_1=Train.iloc[6*284:(59-1)*284]\nTrain_0=Train.iloc[7*284:(59-0)*284]\nTrain_7.sort_values(by=['Province\/State','Country\/Region'],inplace=True)\nTrain_6.sort_values(by=['Province\/State','Country\/Region'],inplace=True)\nTrain_5.sort_values(by=['Province\/State','Country\/Region'],inplace=True)\nTrain_4.sort_values(by=['Province\/State','Country\/Region'],inplace=True)\nTrain_3.sort_values(by=['Province\/State','Country\/Region'],inplace=True)\nTrain_2.sort_values(by=['Province\/State','Country\/Region'],inplace=True)\nTrain_1.sort_values(by=['Province\/State','Country\/Region'],inplace=True)\nTrain_0.sort_values(by=['Province\/State','Country\/Region'],inplace=True)","8fcab5ad":"Train_0['ConfirmedCases_lag_1']=np.array(Train_1['ConfirmedCases'])\nTrain_0['Fatalities_lag_1']=np.array(Train_1['Fatalities'])\n\nTrain_0['ConfirmedCases_lag_2']=np.array(Train_2['ConfirmedCases'])\nTrain_0['Fatalities_lag_2']=np.array(Train_2['Fatalities'])\n\nTrain_0['ConfirmedCases_lag_3']=np.array(Train_3['ConfirmedCases'])\nTrain_0['Fatalities_lag_3']=np.array(Train_3['Fatalities'])\n\nTrain_0['ConfirmedCases_lag_4']=np.array(Train_4['ConfirmedCases'])\nTrain_0['Fatalities_lag_4']=np.array(Train_4['Fatalities'])\n\n\nTrain_0['ConfirmedCases_lag_5']=np.array(Train_5['ConfirmedCases'])\nTrain_0['Fatalities_lag_5']=np.array(Train_5['Fatalities'])\n\nTrain_0['ConfirmedCases_lag_6']=np.array(Train_6['ConfirmedCases'])\nTrain_0['Fatalities_lag_6']=np.array(Train_6['Fatalities'])\n\nTrain_0['ConfirmedCases_lag_7']=np.array(Train_7['ConfirmedCases'])\nTrain_0['Fatalities_lag_7']=np.array(Train_7['Fatalities'])\nTrain_0.sort_values('Province\/State',inplace=True)\nTrain_0.sort_values('Country\/Region',inplace=True)","c28bda4c":"Final_data=Train_0[['Date', 'Province\/State', 'Country\/Region','ConfirmedCases', 'Fatalities', 'Clusters',\n       'Date_After_First_ConfirmedCases', 'Date_After_First_Fatalities',\n                    'ConfirmedCases_lag_1',\n       'Fatalities_lag_1', 'ConfirmedCases_lag_2', 'Fatalities_lag_2',\n       'ConfirmedCases_lag_3', 'Fatalities_lag_3', 'ConfirmedCases_lag_4',\n       'Fatalities_lag_4', 'ConfirmedCases_lag_5', 'Fatalities_lag_5',\n       'ConfirmedCases_lag_6', 'Fatalities_lag_6', 'ConfirmedCases_lag_7',\n       'Fatalities_lag_7']]\nFinal_data.fillna(0,inplace=True)","49f300fc":"D_1=Final_data[['Date', 'Province\/State', 'Country\/Region','Clusters','Date_After_First_ConfirmedCases', 'Date_After_First_Fatalities']]\nD_2=Final_data.drop(['Date', 'Province\/State', 'Country\/Region','Clusters','Date_After_First_ConfirmedCases', 'Date_After_First_Fatalities'],axis=1)\nD_2=np.log(D_2+0.8)\nD_2[D_1.columns]=D_1\nD_2['ConfirmedCases_Difference_1']=D_2['ConfirmedCases']-D_2['ConfirmedCases_lag_1']\nD_2['ConfirmedCases_Difference_2']=D_2['ConfirmedCases_lag_1']-D_2['ConfirmedCases_lag_2']\nD_2['ConfirmedCases_Difference_3']=D_2['ConfirmedCases_lag_2']-D_2['ConfirmedCases_lag_3']\nD_2['ConfirmedCases_Difference_4']=D_2['ConfirmedCases_lag_3']-D_2['ConfirmedCases_lag_4']\nD_2['ConfirmedCases_Difference_5']=D_2['ConfirmedCases_lag_4']-D_2['ConfirmedCases_lag_5']\nD_2['ConfirmedCases_Difference_6']=D_2['ConfirmedCases_lag_5']-D_2['ConfirmedCases_lag_6']\nD_2['ConfirmedCases_Difference_7']=D_2['ConfirmedCases_lag_6']-D_2['ConfirmedCases_lag_7']\n\nD_2['Fatalities_Difference_1']=D_2['Fatalities']-D_2['Fatalities_lag_1']\nD_2['Fatalities_Difference_2']=D_2['Fatalities_lag_1']-D_2['Fatalities_lag_2']\nD_2['Fatalities_Difference_3']=D_2['Fatalities_lag_2']-D_2['Fatalities_lag_3']\nD_2['Fatalities_Difference_4']=D_2['Fatalities_lag_3']-D_2['Fatalities_lag_4']\nD_2['Fatalities_Difference_5']=D_2['Fatalities_lag_4']-D_2['Fatalities_lag_5']\nD_2['Fatalities_Difference_6']=D_2['Fatalities_lag_5']-D_2['Fatalities_lag_6']\nD_2['Fatalities_Difference_7']=D_2['Fatalities_lag_6']-D_2['Fatalities_lag_7']\n#Final_data=D_2\n#del D_1,D_2","7d9abb97":"D_2[['2','3','4']]=pd.get_dummies(D_2['Clusters'].astype(str),drop_first=True)\nD_2.sort_values(['Date','Country\/Region','Province\/State'],inplace=True)","2b371ee7":"Covariates_target=D_2[['2', '3', '4',\n     'Date_After_First_ConfirmedCases','Date_After_First_Fatalities', \n     'ConfirmedCases_Difference_7','Fatalities_Difference_7',\n    'ConfirmedCases_Difference_6','Fatalities_Difference_6',\n    'ConfirmedCases_Difference_5','Fatalities_Difference_5',\n    'ConfirmedCases_Difference_4','Fatalities_Difference_4',\n    'ConfirmedCases_Difference_3','Fatalities_Difference_3',\n    'ConfirmedCases_Difference_2','Fatalities_Difference_2',\n    'ConfirmedCases_Difference_1','Fatalities_Difference_1']]\nINFO=D_2[['Date', 'Province\/State', 'Country\/Region']]\nTarget=Covariates_target[['ConfirmedCases_Difference_1','Fatalities_Difference_1']]\nCovariates=Covariates_target.drop(['ConfirmedCases_Difference_1','Fatalities_Difference_1'],axis=1)\nTarget_1=Covariates_target['ConfirmedCases_Difference_1']\nTarget_2=Covariates_target['Fatalities_Difference_1']\nfrom sklearn.model_selection import train_test_split\nCovariates_Train,Covariates_Test,Target_1_Train,Target_1_Test,Target_2_Train,Target_2_Test= train_test_split(Covariates,Target_1,Target_2, test_size=0.33, random_state=42)","119e18bd":"from xgboost import XGBRegressor\nmodel = XGBRegressor(learning_rate=0.1,gamma=0.001,n_estimators=200,reg_lambda=.9,\n                      booster='gbtree',max_depth=2,subsample=1,rate_drop=0,\n                     sampling_method=\"gradient_based\")\neval_set = [(Covariates_Test.values, Target_1_Test.values)]\nmodel.fit(Covariates_Train.values, Target_1_Train.values, early_stopping_rounds=5, eval_set=eval_set, verbose=True)","2abf9185":"model_1 = XGBRegressor(learning_rate=0.1,gamma=0.001,n_estimators=77,reg_lambda=1,\n                      booster='gbtree',max_depth=2,subsample=1,rate_drop=0,\n                     sampling_method=\"gradient_based\")\nmodel_1.fit(Covariates_Train.values, Target_1_Train.values, verbose=True)","7eeee971":"model = XGBRegressor(learning_rate=0.01,gamma=0.001,n_estimators=5000,reg_lambda=1,\n                      booster='gbtree',max_depth=6,subsample=1,rate_drop=0,\n                     sampling_method=\"gradient_based\")\neval_set = [(Covariates_Test.values, Target_2_Test.values)]\nmodel.fit(Covariates_Train.values, Target_2_Train.values, early_stopping_rounds=5, eval_set=eval_set, verbose=True)","ee16eb38":"model_2 = XGBRegressor(learning_rate=0.01,gamma=0.001,n_estimators=436,reg_lambda=1,\n                      booster='gbtree',max_depth=6,subsample=1,rate_drop=0,\n                     sampling_method=\"gradient_based\")\nmodel_2.fit(Covariates.values, Target_2.values,verbose=True)","37b2f98c":"Test_to_submit=pd.read_csv('..\/input\/covid19-global-forecasting-week-1\/test.csv')\nTest_to_submit['Lat'].fillna(12.5,inplace=True)\nTest_to_submit['Long'].fillna(-70.0,inplace=True)\nTest_to_submit.fillna(\"NA\",inplace=True)\nTest_to_submit['Clusters']=cl_4.predict(Test_to_submit[['Lat','Long']])+1\nTest_to_submit['Clusters']=Test_to_submit['Clusters'].astype(str)\ndummy_temp=pd.get_dummies(Test_to_submit['Clusters'],drop_first=True)\nTest_to_submit[dummy_temp.columns]=dummy_temp\ndel dummy_temp\nTest_to_submit","d793320d":"Test_to_submit=Test_to_submit.merge(Dates_cases_Fatalities)\nTest_to_submit['Date']=pd.to_datetime(Test_to_submit['Date'])\nTest_to_submit['Date_After_First_Fatalities']=Test_to_submit['Date']-Test_to_submit['First_Fatalities']\nTest_to_submit['Date_After_First_ConfirmedCases']=Test_to_submit['Date']-Test_to_submit['First_ConfirmedCases']\nTest_to_submit['Date_After_First_Fatalities']=Test_to_submit['Date_After_First_Fatalities'].dt.days\nTest_to_submit['Date_After_First_ConfirmedCases']=Test_to_submit['Date_After_First_ConfirmedCases'].dt.days","ed9a4996":"Test_to_submit.sort_values(by='Date',inplace=True)","6086832f":"Test_to_submit=Test_to_submit[['ForecastId','Date','2', '3', '4', 'Date_After_First_ConfirmedCases','Date_After_First_Fatalities']]","ca330de5":"temp=Covariates_target[INFO['Date']==INFO['Date'].max()]\ntemp.drop(['2', '3', '4',\n           'Date_After_First_ConfirmedCases','Date_After_First_Fatalities', \n           'ConfirmedCases_Difference_7','Fatalities_Difference_7'],axis=1,inplace=True)\ntemp.columns=['ConfirmedCases_Difference_7', 'Fatalities_Difference_7',\n       'ConfirmedCases_Difference_6', 'Fatalities_Difference_6',\n       'ConfirmedCases_Difference_5', 'Fatalities_Difference_5',\n       'ConfirmedCases_Difference_4', 'Fatalities_Difference_4',\n       'ConfirmedCases_Difference_3', 'Fatalities_Difference_3',\n       'ConfirmedCases_Difference_2', 'Fatalities_Difference_2']\ntemp.index=np.arange(0,284)\n","0c700104":"Test_Dates=Test_to_submit['Date'].unique()\nl=len(Test_Dates)","c6f207d0":"i=0\nConfirmedCases_Forecasted=[]\nFatalities_Forecasted=[]\n\n\nfor i in range(l):\n    fixed_part=Test_to_submit[Test_to_submit['Date']==Test_Dates[i]].drop(['ForecastId', 'Date'],axis=1)\n    fixed_part.index=np.arange(0,284)\n    cov=fixed_part\n    cov[temp.columns]=temp\n\n\n    pred_1=list(model_1.predict(cov.values))\n    temp['ConfirmedCases_Difference_1']=pred_1\n    ConfirmedCases_Forecasted=ConfirmedCases_Forecasted+pred_1\n\n    pred_2=list(model_2.predict(cov.values))\n    temp['Fatalities_Difference_1']=pred_2\n    Fatalities_Forecasted=Fatalities_Forecasted+pred_2\n\n    temp.drop(['ConfirmedCases_Difference_7', 'Fatalities_Difference_7'],axis=1,inplace=True)\n    temp.columns=['ConfirmedCases_Difference_7', 'Fatalities_Difference_7',\n           'ConfirmedCases_Difference_6', 'Fatalities_Difference_6',\n           'ConfirmedCases_Difference_5', 'Fatalities_Difference_5',\n           'ConfirmedCases_Difference_4', 'Fatalities_Difference_4',\n           'ConfirmedCases_Difference_3', 'Fatalities_Difference_3',\n           'ConfirmedCases_Difference_2', 'Fatalities_Difference_2']\n    temp.index=np.arange(0,284)","9da395ce":"Forecasted=pd.DataFrame({'ConfirmedCases_Forecasted':ConfirmedCases_Forecasted,'Fatalities_Forecasted':Fatalities_Forecasted})","02c0af4c":"Last_Days_Records=D_2[D_2['Date']==D_2['Date'].max()][['ConfirmedCases', 'Fatalities']]\nLast_Days_ConfirmedCases=Last_Days_Records['ConfirmedCases']\nLast_Days_Fatalities=Last_Days_Records['Fatalities']","57f3885b":"ConfirmedCases_Forecasted=np.array(Forecasted['ConfirmedCases_Forecasted'])\nFatalities_Forecasted=np.array(Forecasted['Fatalities_Forecasted'])\nLast_Days_ConfirmedCases=np.array(Last_Days_ConfirmedCases)\nLast_Days_Fatalities=np.array(Last_Days_Fatalities)\ni=0\nConfirmedCases=np.array([])\nFatalities=np.array([])\nfor i in range(43):\n    Last_Days_ConfirmedCases=ConfirmedCases_Forecasted[(i*284):((i+1)*284)]+Last_Days_ConfirmedCases\n    ConfirmedCases=np.concatenate((ConfirmedCases,Last_Days_ConfirmedCases))\n\n    Last_Days_Fatalities=Fatalities_Forecasted[(i*284):((i+1)*284)]+Last_Days_Fatalities\n    Fatalities=np.concatenate((Fatalities,Last_Days_Fatalities))\n","eee109e3":"ConfirmedCases=np.exp(ConfirmedCases)-0.8\nFatalities=np.exp(Fatalities)-0.8\nTest_to_submit['ConfirmedCases']=np.round(ConfirmedCases)\nTest_to_submit['Fatalities']=np.round(Fatalities)","b614c254":"Test_to_submit.sort_values('ForecastId',inplace=True)","615739b3":"Test_to_submit[['ForecastId','ConfirmedCases','Fatalities']].to_csv('submission.csv',index=False)","c6aace83":"# Cluster Base Model\n\nThe notebook contains the remaining steps:\n\n- **Step 1:** 4 Clusters were made based on the geographic locations.\n- **Step 2:** First the target variables, ConfiredCases and Fatalities are transformed using modified log transformation or mathematically, $X_1=log(X+0.8)$, where $X_1$ is the transformed variable and $X$ is the actual variable.\n- **Step 3:** Then a first difference is taken from the modified variable. At time $t$, the differenced variables are of the form $D_t=X_{1(t)}-X_{1(t-1)}$\n- **Step 4:** These differences are taken as a sequence dataset and used for forecasting using two separate XGBOOST models. Cluster number from step 1 and difference in days between the date and first cases and first fatalities are also taken as covariates.\n- **Step 5:** Finally two seperate forecasts have been made based on the difference variables.\n"}}