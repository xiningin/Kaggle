{"cell_type":{"b7bd5032":"code","96fde35b":"code","2f19d65f":"code","ee51fd4a":"code","305321a2":"code","3fe1815d":"code","4e16e726":"code","b564b544":"code","47334c84":"code","3c1151cd":"code","5bab892c":"code","cebbbcc9":"code","0f37b01a":"code","eb8e8154":"markdown","a736b0cc":"markdown","591c8d7b":"markdown"},"source":{"b7bd5032":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","96fde35b":"df = pd.read_csv(\"\/kaggle\/input\/spam-text-message-classification\/SPAM text message 20170820 - Data.csv\")","2f19d65f":"df['Category'].value_counts()","ee51fd4a":"spam = df[df['Message'].str.contains(\"win\" and \"free\")]\nspam['Category'].value_counts()","305321a2":"ham_message_length = []\nspam_message_length = []\nfor i in df.values:\n    if(i[0] == \"ham\"):\n        ham_message_length.append(len(i[1]))\n    else:\n        spam_message_length.append(len(i[1]))\nham_message_length        ","3fe1815d":"import pandas as pd\nfrom gensim.models.word2vec import Word2Vec\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom keras.layers import Dense, Dropout, Conv1D, MaxPool1D, GlobalMaxPool1D, Embedding, Activation\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.snowball import PorterStemmer\nfrom sklearn import preprocessing","4e16e726":"def preprocess_text(sen):\n    # Remove punctuations and numbers\n    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n\n    # Single character removal\n    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n\n    # Removing multiple spaces\n    sentence = re.sub(r'\\s+', ' ', sentence)\n    \n    stops = stopwords.words('english')\n    #print(stops)\n    porter = PorterStemmer()\n    for word in sentence.split():\n        if word in stops:\n            sentence = sentence.replace(word, '')\n        sentence = sentence.replace(word, porter.stem(word))\n    return sentence.lower()\ndf['Message'] = df['Message'].apply(preprocess_text)","b564b544":"mes = []\nfor i in df['Message']:\n    mes.append(i.split())\nprint(mes[:2])","47334c84":"word2vec_model = Word2Vec(mes, size=500, window=3, min_count=1, workers=16)\nprint(word2vec_model)","3c1151cd":"token = Tokenizer(7229)\ntoken.fit_on_texts(df['Message'])\ntext = token.texts_to_sequences(df['Message'])\ntext = pad_sequences(text, 75)","5bab892c":"le = preprocessing.LabelEncoder()\ny = le.fit_transform(df['Category'])\ny = to_categorical(y)","cebbbcc9":"x_train, x_test, y_train, y_test = train_test_split(np.array(text), y, test_size=0.2, stratify=y)","0f37b01a":"import tensorflow as tf\nann = tf.keras.models.Sequential()\nann.add(tf.keras.layers.Dense(units = 110,activation = 'relu'))\nann.add(tf.keras.layers.Dense(units = 110,activation = 'relu'))\nann.add(tf.keras.layers.Dense(units = 2,activation = 'sigmoid'))\nann.compile(optimizer = 'adam', loss = 'binary_crossentropy' , metrics = ['accuracy'])\nann.fit(x_train,y_train,batch_size = 32, epochs = 100)","eb8e8154":"Applying word2vec model","a736b0cc":"Pre processing the data","591c8d7b":"ANN"}}