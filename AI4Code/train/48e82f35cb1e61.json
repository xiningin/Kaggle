{"cell_type":{"a1e50bef":"code","f4b3fb72":"code","44208db7":"code","e74ea280":"code","67cc3979":"code","df386233":"code","45e7ff2d":"code","e3a02928":"code","cf8ff77e":"code","3e57b18e":"code","2de22a47":"code","472047d1":"code","bbf04bea":"code","fc90f257":"code","279bf937":"code","b2bd7ee1":"code","5ca4841c":"code","835fee0e":"code","74480369":"code","7ddf7b89":"code","223327f3":"code","1985625c":"code","575f8d1b":"code","77d8d8ca":"code","22746bbb":"code","4a3af1a2":"code","c041dd04":"code","36570839":"code","b82aad0e":"code","1940f8b9":"code","020d97d2":"code","cfd55fad":"code","0224891e":"code","aab142d1":"code","e24a76ba":"code","260a870d":"code","35373c3e":"code","21e93056":"code","aea7a92f":"code","a6990963":"code","cd28cfa7":"code","fef67831":"code","ab783b38":"code","63f2df40":"code","8fdf3469":"code","10a505b8":"code","7800b671":"code","887b0491":"code","526a8057":"code","023f8307":"code","7c7caf78":"code","0ec8110e":"code","b7860761":"code","395889dc":"code","a1733137":"code","3f9aeaf9":"code","66305ac6":"code","adfbd2d2":"code","0565dc8a":"code","5ed9be47":"code","13b5734a":"code","b27e9eec":"code","b9ab944b":"code","1f2877b0":"code","44cea805":"code","e96e63af":"code","893f205b":"code","08cc447e":"code","8dd01da2":"code","86b2a8b2":"code","bf237d38":"code","a132fb91":"code","93b1ab93":"code","208357e3":"code","ab563b0d":"code","c9becd5c":"code","aec645ab":"code","a99b25ca":"code","88a7d530":"code","864ab62b":"code","6234141d":"code","5541dfb7":"code","45c8e313":"code","cf4efba0":"code","e5089a85":"code","db88213e":"code","2f2fca68":"code","26c76469":"code","52cd8f14":"code","66081544":"code","d1cd9fc6":"code","c87f35e5":"code","e4b45e8c":"code","d2f14b50":"code","cdd4f999":"code","5185a787":"code","44489a95":"code","0cd379d8":"code","2580021b":"code","fbf80623":"code","6dab4290":"code","3075a66c":"code","7d72a353":"code","04fe387e":"code","448c4f4e":"code","f7c18d22":"code","6ab31634":"code","84bd6c8b":"code","43382c8d":"code","10fe224c":"code","8a03c1d3":"code","c590dcd4":"code","110db4b8":"code","db6a0fbf":"code","cb1a6911":"code","42db8787":"code","f3b1cdf3":"code","adab202d":"code","73afb361":"code","7c401b0e":"code","7d7224b5":"code","d4cecc5a":"code","5185bbfa":"code","bdbdce6b":"code","5775db2d":"code","7886b59d":"code","d8b0f776":"code","2d44de15":"code","b4c71351":"code","b229da53":"code","e71b5de8":"code","8e3032ed":"code","ed7a44c1":"code","a9fd7258":"code","bc4c1218":"code","99c27663":"code","c114ab6a":"code","cd454b69":"code","7f5f3690":"code","2d5546d6":"code","ff79beaf":"code","2818c835":"code","36416e26":"code","52d60b51":"code","f6560c86":"code","ed4bb5ed":"code","d3d2827a":"code","5c7a161e":"code","9c65eec4":"code","aed5a5f5":"code","a459ead1":"code","464ac69f":"code","81151875":"markdown","e08bb859":"markdown","21573ad9":"markdown","66ffa0b4":"markdown","bc35424a":"markdown","774b463a":"markdown","90270142":"markdown","10dd4841":"markdown","7bc4bfc0":"markdown","2327345a":"markdown","162c03f7":"markdown","fb728b74":"markdown","38982262":"markdown","1315b24e":"markdown","1acd8c11":"markdown","5b4cf53f":"markdown","f6a5713b":"markdown","d0653ad8":"markdown","9216cfc8":"markdown","f1c400ec":"markdown","da3b03c7":"markdown","9f6c91c9":"markdown","92e4e99f":"markdown","2d7b4e9e":"markdown","e5e7959c":"markdown","94a004e4":"markdown","891731f8":"markdown","b1fc4f11":"markdown","1fe68c11":"markdown","7a21fe64":"markdown","79c13f2c":"markdown","b800a849":"markdown","979da103":"markdown","acf8cefd":"markdown","bdd5d70b":"markdown","05007885":"markdown","1259cf79":"markdown","a7643ef5":"markdown","26a8965d":"markdown","060c99c7":"markdown","4fdd1ea9":"markdown","37416075":"markdown","6e75254d":"markdown","81b0dfcd":"markdown","b88b7871":"markdown","df354670":"markdown","aecef7da":"markdown","5238a09f":"markdown","68662d9c":"markdown","f69e4b45":"markdown","ef0f0f3e":"markdown","235509de":"markdown","7889aecb":"markdown","b6f1188a":"markdown","f23aa578":"markdown","b816362b":"markdown","572e682f":"markdown","66197fab":"markdown","325683a5":"markdown","c9974257":"markdown","9f1a68d8":"markdown","d29da70e":"markdown","b239692b":"markdown","d5bd7239":"markdown","1528be0d":"markdown","3ad686da":"markdown"},"source":{"a1e50bef":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","f4b3fb72":"# Load train data\ndf = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","44208db7":"df.info()","e74ea280":"df.head()","67cc3979":"# Describe dataset \ndf.describe().T","df386233":"# Find the percentage of missing values in dataframe\nmissing_df = pd.DataFrame({\n    \"Columns\": df.columns[df.isnull().sum()>0],\n    \"Values\": df[df.columns[df.isnull().sum()>0]].isnull().sum()\/len(df)*100\n})\nmissing_df = missing_df.reset_index(drop=True)\nmissing_df","45e7ff2d":"all_missing_df = df.isnull().sum()\nall_missing_df = all_missing_df.reset_index()\nall_missing_df.T","e3a02928":"df.info()","cf8ff77e":"var_numerical = []\nvar_categorical = []","3e57b18e":"var_numerical = df.select_dtypes(exclude=['object']).columns\nvar_categorical = df.select_dtypes(include=['object']).columns","2de22a47":"print(var_numerical)","472047d1":"print(var_categorical)","bbf04bea":"# Function to label the count on top of each bar in graph\ndef label_values(ax, spacing=5):\n    total = 0\n    for rect in ax.patches:\n        total += rect.get_height()\n    for rect in ax.patches:\n        \n        y_value = rect.get_height()\n        x_value = rect.get_x() + rect.get_width() \/ 2\n\n        space = spacing\n        \n        va = 'bottom'\n        \n        if y_value < 0:\n            space *= -1\n            va = 'top'\n    \n        label = \"{:.2f}, {:.2f}\".format(y_value, y_value\/total*100)\n        ax.annotate(\n            label,                      \n            (x_value, y_value),         \n            xytext=(0, space),          \n            textcoords=\"offset points\", \n            ha='center',                \n            va=va)                      ","fc90f257":"# Plot the target variable\nsns.distplot(x = df[\"SalePrice\"])\nplt.show()\nsns.boxplot(y = df[\"SalePrice\"])\nplt.show()","279bf937":"# Plot the target variable\nsns.distplot(x = np.log(df[\"SalePrice\"]))\nplt.show()\nsns.boxplot(y = np.log(df[\"SalePrice\"]))\nplt.show()","b2bd7ee1":"df[(df[\"SalePrice\"]> 600000)].T","5ca4841c":"df[\"SalePrice\"] = df[\"SalePrice\"].apply(lambda x: np.log(x))","835fee0e":"# Countplot for each categorical variable\nfor column in var_categorical:\n    print(column.title())\n    plt.figure(figsize=(16, 7))\n    ax = sns.countplot(x = df[column])\n    label_values(ax)\n    plt.show()","74480369":"# Boxplot for all the numerical variables\nfor column in var_numerical:\n    print(column.title())\n    plt.figure(figsize=(16, 7))\n    ax = sns.boxplot(x = df[column])\n    label_values(ax)\n    plt.show()","7ddf7b89":"# Distplot for all the numerical variables\nfor column in var_numerical:\n    print(column.title())\n    plt.figure(figsize=(16, 6))\n    ax = sns.distplot(x = df[column])\n    label_values(ax)\n    plt.show()","223327f3":"#### Drop the Id column\ndf = df.drop(['Id'], axis = 1)\ndf_test_id = df_test[\"Id\"]\ndf_test = df_test.drop(['Id'], axis = 1)","1985625c":"var_numerical = list(set(var_numerical) - set(['Id']))","575f8d1b":"log_transform_columns = ['MSSubClass',\n 'LotFrontage',\n 'LotArea',\n 'MasVnrArea',\n 'BsmtFinSF1',\n 'BsmtFinSF2',\n 'BsmtUnfSF',\n 'TotalBsmtSF',\n '1stFlrSF',\n '2ndFlrSF',\n 'LowQualFinSF',\n 'GrLivArea',\n 'BsmtFullBath',\n 'BsmtHalfBath',\n 'GarageYrBlt',\n 'WoodDeckSF',\n 'OpenPorchSF',\n 'EnclosedPorch',\n '3SsnPorch',\n 'ScreenPorch',\n 'PoolArea',\n 'MiscVal']","77d8d8ca":"for col in log_transform_columns:\n    df[col] = df[col].apply(lambda x: 0 if np.log(x)<0 else np.log(x))\n    df_test[col] = df_test[col].apply(lambda x: 0 if np.log(x)<0 else np.log(x))","22746bbb":"high_missing_columns = list(missing_df[missing_df[\"Values\"] > 50][\"Columns\"].values)","4a3af1a2":"high_missing_columns","c041dd04":"# Fill null value with NA as pool is not available in some home. It can be important for our analysis so we will not drop it\ndf[\"PoolQC\"] = df[\"PoolQC\"].fillna('NA')\ndf_test[\"PoolQC\"] = df_test[\"PoolQC\"].fillna('NA')","36570839":"# Fill null value with NA as Alley is not available in some home. It can be important for our analysis so we will not drop it\ndf[\"Alley\"] = df[\"Alley\"].fillna('NA')\ndf_test[\"Alley\"] = df_test[\"Alley\"].fillna('NA')","b82aad0e":"# Fill null value with NA as fence is not available in some home. It can be important for our analysis so we will not drop it\ndf[\"Fence\"] = df[\"Fence\"].fillna('NA')\ndf_test[\"Fence\"] = df_test[\"Fence\"].fillna('NA')","1940f8b9":"# Fill null value with NA as MiscFeature is not available in some home. It can be important for our analysis so we will not drop it\ndf[\"MiscFeature\"] = df[\"MiscFeature\"].fillna('NA')\ndf_test[\"MiscFeature\"] = df_test[\"MiscFeature\"].fillna('NA')","020d97d2":"for column in var_categorical:\n    print(column.title())\n    plt.figure(figsize=(16, 6))\n    ax = sns.boxplot(x = df[column], y = df[\"SalePrice\"])\n    label_values(ax)\n    plt.show()","cfd55fad":"for column in var_numerical:\n    print(column.title())\n    plt.figure(figsize=(16, 6))\n    ax = sns.scatterplot(x = df[column], y = df[\"SalePrice\"])\n    label_values(ax)\n    plt.show()","0224891e":"corr = df[var_numerical].corr()","aab142d1":"plt.figure(figsize = (16, 20))\nsns.heatmap(corr, annot = True)\nplt.show()","e24a76ba":"df = df.drop([\"GarageCars\", \"GarageYrBlt\", \"1stFlrSF\"], axis = 1)\ndf_test = df_test.drop([\"GarageCars\", \"GarageYrBlt\", \"1stFlrSF\"], axis = 1)","260a870d":"# We will remove the column name from var_numerical and var_categorical columns \nfor col in [\"GarageCars\", \"GarageYrBlt\", \"1stFlrSF\"]:\n    if col in var_numerical:\n        var_numerical = list(set(var_numerical) - set([col]))\n    elif col in var_categorical:\n        var_categorical = list(set(var_categorical) - set([col]))","35373c3e":"sns.boxplot(x = df[\"FireplaceQu\"], y = df[\"SalePrice\"])\nplt.show()","21e93056":"# Based on the description of the columns we not that null values has no fireplace at home so we will impute \n# null values with NA\ndf[\"FireplaceQu\"] = df[\"FireplaceQu\"].fillna('NA')\ndf_test[\"FireplaceQu\"] = df_test[\"FireplaceQu\"].fillna('NA')","aea7a92f":"plt.figure(figsize=(16, 10))\nsns.boxplot(x = df[\"Neighborhood\"], y= df[\"LotFrontage\"])\nplt.show()","a6990963":"# LotFrontage - Numerical variable - Impute it based on the Neighborhood values\n# As lot frontage is based on the neighborhood as we can see in the above box plot \ndf[\"LotFrontage\"] = df.groupby(by=[\"Neighborhood\"])['LotFrontage'].transform(lambda x: x.fillna(x.median()))\ndf_test[\"LotFrontage\"] = df_test.groupby(by=[\"Neighborhood\"])['LotFrontage'].transform(lambda x: x.fillna(x.median()))","cd28cfa7":"remaining_missing_df = df[df.columns[df.isnull().sum()>0]].isnull().sum()\/len(df)*100","fef67831":"remaining_missing_df","ab783b38":"remaining_missing_list = list(remaining_missing_df.keys())","63f2df40":"column_to_replace_null_with_NA = ['BsmtExposure', 'GarageFinish', 'GarageType', 'BsmtQual', 'GarageCond', \n                                  'GarageQual', 'BsmtCond', 'BsmtFinType2', 'BsmtFinType1']\ndf[column_to_replace_null_with_NA] = df[column_to_replace_null_with_NA].fillna('NA')\ndf_test[column_to_replace_null_with_NA] = df_test[column_to_replace_null_with_NA].fillna('NA')","8fdf3469":"remaining_missing_list = list(set(remaining_missing_list) - set(column_to_replace_null_with_NA))","10a505b8":"# Impute the categorical variables with the mode of its values\n# Impute the numerical variables with the median of its values\nfor col in remaining_missing_list:\n    if col in var_numerical:\n        df[col] = df[col].fillna(df[col].median())\n    elif col in var_categorical:\n        df[col] = df[col].fillna(df[col].mode()[0])","7800b671":"# Drop the year built column and take age of house into consideration\ndf[\"BuiltAge\"] = df[\"YearBuilt\"].apply(lambda x: max(df[\"YearBuilt\"]) - x)\ndf = df.drop(['YearBuilt'], axis = 1)\n\ndf_test[\"BuiltAge\"] = df_test[\"YearBuilt\"].apply(lambda x: max(df_test[\"YearBuilt\"]) - x)\ndf_test = df_test.drop(['YearBuilt'], axis = 1)","887b0491":"df[\"RemodAddAge\"] = df[\"YearRemodAdd\"].apply(lambda x: max(df[\"YearRemodAdd\"]) - x)\ndf = df.drop(['YearRemodAdd'], axis = 1)\n\ndf_test[\"RemodAddAge\"] = df_test[\"YearRemodAdd\"].apply(lambda x: max(df_test[\"YearRemodAdd\"]) - x)\ndf_test = df_test.drop(['YearRemodAdd'], axis = 1)","526a8057":"def combine(x):\n    ind = x.index\n    ans = []\n    for i in ind:\n        ans.append(pd.to_datetime(str(x[0]) +\"\/\" + str(df[\"YrSold\"][i]), format='%m\/%Y'))\n    return ans\n\ndef combine_test(x):\n    ind = x.index\n    ans = []\n    for i in ind:\n        ans.append(pd.to_datetime(str(x[0]) +\"\/\" + str(df_test[\"YrSold\"][i]), format='%m\/%Y'))\n    return ans","023f8307":"df[\"MonthYearSold\"] = df[[\"MoSold\"]].apply(combine)\ndf_test[\"MonthYearSold\"] = df_test[[\"MoSold\"]].apply(combine_test)","7c7caf78":"# We will take the number of days sold difference into consideration\ndf[\"SoldDateDiff\"] = df[\"MonthYearSold\"].apply(lambda x: max(df[\"MonthYearSold\"]) - x)\ndf = df.drop([\"MonthYearSold\", \"MoSold\", \"YrSold\"], axis = 1)\n\ndf_test[\"SoldDateDiff\"] = df_test[\"MonthYearSold\"].apply(lambda x: max(df_test[\"MonthYearSold\"]) - x)\ndf_test = df_test.drop([\"MonthYearSold\", \"MoSold\", \"YrSold\"], axis = 1)","0ec8110e":"df[\"SoldDateDiff\"] = df[\"SoldDateDiff\"].apply(lambda x: str(x)[:-14])\n\ndf_test[\"SoldDateDiff\"] = df_test[\"SoldDateDiff\"].apply(lambda x: str(x)[:-14])","b7860761":"# We will remove the column name from var_numerical and var_categorical columns \nfor col in [\"YearBuilt\", \"YearRemodAdd\", \"MonthYearSold\", \"MoSold\", \"YrSold\"]:\n    if col in var_numerical:\n        var_numerical = list(set(var_numerical) - set([col]))\n    elif col in var_categorical:\n        var_categorical = list(set(var_categorical) - set([col]))","395889dc":"# Plot to the distribution of the new derived columns\nsns.distplot(x = df[\"BuiltAge\"])\nplt.show()\nsns.scatterplot(x = df[\"BuiltAge\"], y = df[\"SalePrice\"])\nplt.show()","a1733137":"# Plot to the distribution of the new derived columns\nsns.distplot(x = df[\"RemodAddAge\"])\nplt.show()\nsns.scatterplot(x = df[\"RemodAddAge\"], y = df[\"SalePrice\"])\nplt.show()","3f9aeaf9":"# Plot to the distribution of the new derived columns\nsns.distplot(x = df[\"SoldDateDiff\"])\nplt.show()\nsns.scatterplot(x = df[\"SoldDateDiff\"], y = df[\"SalePrice\"])\nplt.show()","66305ac6":"var_numerical = var_numerical + ['BuiltAge', 'RemodAddAge', 'SoldDateDiff']","adfbd2d2":"# We will use the label encoding on the ordinal variable \nordinal_col = ['BsmtQual', 'BsmtCond', 'BsmtExposure','BsmtFinType1','BsmtFinType2',\n 'HeatingQC','KitchenQual', 'FireplaceQu','GarageQual','GarageCond','PoolQC']\nnominal_col = list(set(var_categorical) - set(ordinal_col))","0565dc8a":"df[nominal_col].nunique()","5ed9be47":"df[\"Condition2\"].value_counts()","13b5734a":"df = df.drop(['Condition2'], axis = 1)\n\ndf_test = df_test.drop(['Condition2'], axis = 1)","b27e9eec":"df[\"Utilities\"].value_counts()","b9ab944b":"df = df.drop([\"Utilities\"], axis = 1)\n\ndf_test = df_test.drop(['Utilities'], axis = 1)","1f2877b0":"var_categorical = list(set(var_categorical) - set(['Utilities', 'Condition2']))\nnominal_col = list(set(nominal_col)-set(['Utilities', 'Condition2']))","44cea805":"col_with_multiple_labels = ['Exterior1st', 'Exterior2nd', 'Neighborhood']","e96e63af":"def top_labels(df, col, label_cnt):\n    top = list(df[col].value_counts().sort_values(ascending=False).head(label_cnt).index)\n    for categories in top:\n        df[col+ \"_\" +str(categories)]=np.where(df[col]==categories,1,0)\n        print(col + \"_\" + str(categories))\n    print(top)\n    return top\n\ndef top_labels_test(df_test, col, max_col, top):\n    print(\"Top Labels: \", top)\n    for categories in top:\n        df_test[col+ \"_\" +str(categories)]=np.where(df_test[col]==categories,1,0)\n        print(col + \"_\" + str(categories))","893f205b":"df[\"Exterior1st\"].value_counts()","08cc447e":"top_exterior1st_labels = top_labels(df, 'Exterior1st', 10)\ndf = df.drop(['Exterior1st'], axis = 1)\n\ntop_labels_test(df_test, 'Exterior1st', 10, top_exterior1st_labels)\ndf_test = df_test.drop(['Exterior1st'], axis = 1)","8dd01da2":"df[\"Exterior2nd\"].value_counts()","86b2a8b2":"top_exterior2nd_label = top_labels(df, 'Exterior2nd', 8)\ndf = df.drop(['Exterior2nd'], axis = 1)\n\ntop_labels_test(df_test, 'Exterior2nd', 8, top_exterior2nd_label)\ndf_test = df_test.drop(['Exterior2nd'], axis = 1)","bf237d38":"top_neighborhood_labels = top_labels(df, 'Neighborhood', 10)\ndf = df.drop(['Neighborhood'], axis = 1)\n\ntop_labels_test(df_test, 'Neighborhood', 10, top_neighborhood_labels)\ndf_test = df_test.drop(['Neighborhood'], axis = 1)","a132fb91":"nominal_col = list(set(nominal_col) - set(['Exterior1st', 'Exterior2nd', 'Neighborhood']))","93b1ab93":"df[\"Functional\"].value_counts()","208357e3":"top_functional_labels = top_labels(df, 'Functional', 3)\ndf = df.drop(['Functional'], axis = 1)\n\ntop_labels_test(df_test, 'Functional', 3, top_functional_labels)\ndf_test = df_test.drop(['Functional'], axis = 1)","ab563b0d":"df[\"Heating\"].value_counts()","c9becd5c":"top_heating_labels = top_labels(df, 'Heating', 2)\ndf = df.drop(['Heating'], axis = 1)\n\ntop_labels_test(df_test, 'Heating', 2, top_heating_labels)\ndf_test = df_test.drop(['Heating'], axis = 1)","aec645ab":"df[\"SaleType\"].value_counts()","a99b25ca":"top_saletype_labels = top_labels(df, 'SaleType', 3)\ndf = df.drop(['SaleType'], axis = 1)\n\ntop_labels_test(df_test, 'SaleType', 3, top_saletype_labels)\ndf_test = df_test.drop(['SaleType'], axis = 1)","88a7d530":"df[\"RoofMatl\"].value_counts()","864ab62b":"top_garagecond_labels = top_labels(df, 'RoofMatl', 2)\ndf = df.drop(['RoofMatl'], axis = 1)\n\ntop_labels_test(df_test, 'RoofMatl', 2, top_garagecond_labels)\ndf_test = df_test.drop(['RoofMatl'], axis = 1)","6234141d":"df[\"Condition1\"].value_counts()","5541dfb7":"top_condition1_labels = top_labels(df, 'Condition1', 5)\ndf = df.drop(['Condition1'], axis = 1)\n\ntop_labels_test(df_test, 'Condition1', 5, top_condition1_labels)\ndf_test = df_test.drop(['Condition1'], axis = 1)","45c8e313":"nominal_col = list(set(nominal_col)-set(['Condition1', 'RoofMatl','SaleType', 'Heating', 'Functional']))","cf4efba0":"# Make dummy variables for the nominal columns\ndf = pd.get_dummies(df, columns=nominal_col, drop_first=True)\ndf_test = pd.get_dummies(df_test, columns=nominal_col, drop_first=True)","e5089a85":"df.head()","db88213e":"corr = df.corr()","2f2fca68":"# Calculate the highly correlated features\n# https:\/\/stackoverflow.com\/questions\/29294983\/how-to-calculate-correlation-between-all-columns-and-remove-highly-correlated-on\n\ndef highly_correlated_features(dataset, threshold):\n    high_correlated_features = []\n    col_corr = set() # Set of all the names of deleted columns\n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if (corr_matrix.iloc[i, j] >= threshold) and (corr_matrix.columns[j] not in col_corr):\n                colname = corr_matrix.columns[i] # getting the name of column\n                col_corr.add(colname)\n                if colname in dataset.columns:\n                    high_correlated_features.append(colname)\n    return high_correlated_features\n\ndef highly_negative_correlated_features(dataset, threshold):\n    high_correlated_features = []\n    col_corr = set() # Set of all the names of deleted columns\n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if (corr_matrix.iloc[i, j] <= threshold) and (corr_matrix.columns[j] not in col_corr):\n                colname = corr_matrix.columns[i] # getting the name of column\n                col_corr.add(colname)\n                if colname in dataset.columns:\n                    high_correlated_features.append(colname)\n    return high_correlated_features","26c76469":"positively_high_correlated_value = highly_correlated_features(df, 0.7)\nnegatively_high_correlated_value = highly_negative_correlated_features(df, -0.7)","52cd8f14":"plt.figure(figsize=(16, 16))\nsns.heatmap(df[list(set(positively_high_correlated_value + negatively_high_correlated_value))].corr(), annot=True)\nplt.show()","66081544":"df = df.drop(['SaleCondition_Partial'], axis = 1)\ndf_test = df_test.drop(['SaleCondition_Partial'], axis = 1)","d1cd9fc6":"remaining_missing_df_test = df_test[df_test.columns[df_test.isnull().sum()>0]].isnull().sum()\/len(df_test)*100\nprint(remaining_missing_df_test)\nremaining_missing_df_test = list(remaining_missing_df_test.index)\nremaining_missing_df_test","c87f35e5":"for col in remaining_missing_df_test:\n    if col in var_numerical:\n        df_test[col] = df_test[col].fillna(0.0)\n    elif col in var_categorical:\n        df_test[col] = df_test[col].fillna('NA')","e4b45e8c":"# Label Encoding categorical variables from x\nfrom sklearn.preprocessing import LabelEncoder\n# Feature scaling\nfrom sklearn.preprocessing import MinMaxScaler, RobustScaler","d2f14b50":"def label_imputation(x):\n    if x==\"Ex\":\n        return 5\n    elif x==\"Gd\":\n        return 4\n    elif x==\"TA\":\n        return 3\n    elif x==\"Fa\":\n        return 2\n    elif x==\"Po\":\n        return 1\n    else:\n        return 0","cdd4f999":"for col in ordinal_col:\n    df[col] = df[col].apply(label_imputation)\n    df_test[col] = df_test[col].apply(label_imputation)","5185a787":"# Divide the train data into X and y\n\ny_train = df.pop('SalePrice')\nX_train = df","44489a95":"# Divide the test data into X\nX_test = df_test","0cd379d8":"X_train.shape, y_train.shape, X_test.shape","2580021b":"for col in list(X_train.columns):\n    if col not in list(X_test.columns):\n        X_train = X_train.drop([col], axis = 1)","fbf80623":"var_numerical = list(set(var_numerical) - set(['SalePrice']))","6dab4290":"# We will use MinMaxScaler for all the numerical variables as some variables are showing very high range of \n# values and many of them are not normally distributed\n# We have remove some columns very high skew in data so we will use robust scaler\nscaler = RobustScaler()","3075a66c":"# Fit and Transform the data\n# Fit will calculate our Min and Max values\n# Transform will operate on standardisation function and scales our values\nX_train[var_numerical] = scaler.fit_transform(X_train[var_numerical])\n# Transform will operate on standardisation function and scales our values\nX_test[var_numerical] = scaler.transform(X_test[var_numerical])","7d72a353":"from sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LinearRegression\n# Importing RFE (recursive feature elimination)\nfrom sklearn.feature_selection import RFE","04fe387e":"# Model evaluation function\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, explained_variance_score\nfrom sklearn.model_selection import cross_val_score\n# Grid Search CV for hyperparameter tuning\nfrom sklearn.model_selection import GridSearchCV\n# K Fold cross validation\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error, r2_score","448c4f4e":"lr = LinearRegression()\nlr.fit(X_train, y_train)","f7c18d22":"y_pred_train_lr = lr.predict(X_train)\ny_pred_test_lr = lr.predict(X_test)\n\nmetric_lr = []\nr2_train_lr = r2_score(y_train, y_pred_train_lr)\nprint(\"R2 Train Score: \", r2_train_lr)\nmetric_lr.append(r2_train_lr)\n\nmse_train_lr = mean_squared_error(y_train, y_pred_train_lr)\nprint(\"Mean Squared Train Error: \", mse_train_lr)\nmetric_lr.append(mse_train_lr**0.5)","6ab31634":"linear_beta = pd.DataFrame(index=X_train.columns)\nlinear_beta.rows = X_train.columns\nlinear_beta[\"Linear Regression\"] = abs(lr.coef_)","84bd6c8b":"pd.set_option('display.max_rows', None)\nlinear_beta.sort_values(by = 'Linear Regression', ascending=False)","43382c8d":"# running RFE \n# For the first model we are taking half features\nrfe = RFE(lr, 50)   \nrfe = rfe.fit(X_train, y_train)","10fe224c":"# Columns with RFE Support as True\ncol = X_train.columns[rfe.support_]\nlen(col)","8a03c1d3":"lr_with_rfe = LinearRegression()\nlr_with_rfe.fit(X_train[col], y_train)\ny_train_pred_rfe = lr_with_rfe.predict(X_train[col])\ny_test_pred_rfe = lr_with_rfe.predict(X_test[col])\n\nprint(\"Linear regression train r2_score: \", r2_score(y_train, y_train_pred_rfe))","c590dcd4":"seed = 50","110db4b8":"# Initialisation of ridge linear regression model\nridge_lr = Ridge(random_state = seed)","db6a0fbf":"# Create the param grid for logistic regression\nparam_ridge_lr = {\n    'alpha': [0.0001, 0.0002, 0.0004, 0.0008, 0.001, 0.01, 0.05, 0.1, \n 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]\n}\nprint(param_ridge_lr)","cb1a6911":"folds_ridge = KFold(n_splits = 4, shuffle = True, random_state=100)","42db8787":"grid_ridge = GridSearchCV(estimator = ridge_lr, scoring= 'neg_root_mean_squared_error', param_grid = param_ridge_lr, cv = folds_ridge, \n                           verbose=0, return_train_score=True, n_jobs=3)\ngrid_ridge.fit(X_train, y_train)","f3b1cdf3":"pd.DataFrame(grid_ridge.cv_results_)[['param_alpha', 'mean_test_score', 'mean_train_score']]","adab202d":"#Fitting Ridge model for best ridge parameter and printing coefficients which have been penalised\nalpha = grid_ridge.best_estimator_.alpha\nridge = Ridge(alpha=alpha, random_state=seed)\n\nridge = ridge.fit(X_train, y_train)\nridge","73afb361":"y_pred_train = ridge.predict(X_train)\ny_pred_test_ridge = ridge.predict(X_test)\n\nmetric2 = []\nr2_train_lr = r2_score(y_train, y_pred_train)\nprint(\"R2 Train Score: \", r2_train_lr)\nmetric2.append(r2_train_lr)\n\nmse_train_lr = mean_squared_error(y_train, y_pred_train)\nprint(\"Mean Squared Train Error: \", mse_train_lr)\nmetric2.append(mse_train_lr**0.5)","7c401b0e":"sns.scatterplot(y = y_train - y_pred_train, x = y_pred_train)\nplt.show()","7d7224b5":"sns.scatterplot(y = y_train , x = y_pred_train)\nplt.ylabel(\"Y-Train\")\nplt.xlabel(\"Y-Train-Predict\")\nplt.title(\"Ridge Regression (train vs pred train)\")\nplt.show()","d4cecc5a":"ridge_beta = pd.DataFrame(index=X_train.columns)\nridge_beta.rows = X_train.columns\nridge_beta[\"Ridge with best alpha\"] = abs(ridge.coef_)\npd.set_option('display.max_rows', None)\nridge_beta = ridge_beta.sort_values(by = 'Ridge with best alpha', ascending=False)\nridge_beta","5185bbfa":"len(ridge_beta[ridge_beta[\"Ridge with best alpha\"]==0])","bdbdce6b":"# Initialise the lasso model\nlasso_lr = Lasso(random_state = 50)","5775db2d":"# Create the param grid for logistic regression\nparam_lasso_lr = {\n    'alpha': [0.0001, 0.0002, 0.0004, 0.0008, 0.001, 0.01, 0.05, 0.1, \n 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]\n}\nprint(param_lasso_lr)","7886b59d":"folds_lasso = KFold(n_splits = 3, shuffle = True, random_state=100)","d8b0f776":"grid_lasso = GridSearchCV(estimator = lasso_lr, scoring= 'neg_root_mean_squared_error', param_grid = param_lasso_lr, \n                          cv = folds_lasso, verbose=0, return_train_score=True, n_jobs=3)\ngrid_lasso.fit(X_train, y_train)","2d44de15":"pd.DataFrame(grid_lasso.cv_results_)[['param_alpha', 'mean_test_score', 'mean_train_score']]","b4c71351":"#Fitting lasso model for best alpha and printing coefficients which have been penalised\nalpha = grid_lasso.best_estimator_.alpha\nlasso = Lasso(alpha=alpha)\n\nlasso = lasso.fit(X_train, y_train)\nlasso","b229da53":"y_pred_train_lasso = lasso.predict(X_train)\ny_pred_test_lasso = lasso.predict(X_test)\n\nmetric3 = []\nr2_train_lr = r2_score(y_train, y_pred_train_lasso)\nprint(\"R2 Train Score: \", r2_train_lr)\nmetric3.append(r2_train_lr)\n\n\nmse_train_lr = mean_squared_error(y_train, y_pred_train_lasso)\nprint(\"Mean Squared Train Error: \", mse_train_lr)\nmetric3.append(mse_train_lr**0.5)","e71b5de8":"sns.scatterplot(y = y_train , x = y_pred_train_lasso)\nplt.ylabel(\"Y-Train\")\nplt.xlabel(\"Y-Train-Predict\")\nplt.title(\"Lasso Regression (train vs pred train)\")\nplt.show()","8e3032ed":"lasso_beta = pd.DataFrame(index=X_train.columns)\nlasso_beta.rows = X_train.columns\nlasso_beta[\"Lasso with the best parameter\"] = abs(lasso.coef_)","ed7a44c1":"pd.set_option('display.max_rows', None)\nlasso_beta = lasso_beta.sort_values(by = 'Lasso with the best parameter', ascending=False)\nlasso_beta","a9fd7258":"len(lasso_beta[lasso_beta[\"Lasso with the best parameter\"]==0])","bc4c1218":"from sklearn.ensemble import RandomForestRegressor","99c27663":"rfr = RandomForestRegressor(n_estimators=100, random_state=50)\nrfr.fit(X_train, y_train)","c114ab6a":"y_pred_train_rfr = rfr.predict(X_train)\ny_pred_test_rfr = rfr.predict(X_test)\n\nmetric4 = []\nr2_train_rfr = r2_score(y_train, y_pred_train_rfr)\nprint(\"R2 Train Score: \", r2_train_rfr)\nmetric4.append(r2_train_rfr)\n\n\nmse_train_rfr = mean_squared_error(y_train, y_pred_train_rfr)\nprint(\"Mean Squared Train Error: \", mse_train_rfr)\nmetric4.append(mse_train_rfr**0.5)","cd454b69":"from xgboost import XGBRegressor","7f5f3690":"xgb = XGBRegressor(n_estimators=100, random_state=50)\nxgb.fit(X_train, y_train)","2d5546d6":"y_pred_train_xgb = xgb.predict(X_train)\ny_pred_test_xgb = xgb.predict(X_test)\n\nmetric5 = []\nr2_train_xgb = r2_score(y_train, y_pred_train_xgb)\nprint(\"R2 Train Score: \", r2_train_xgb)\nmetric5.append(r2_train_xgb)\n\n\nmse_train_xgb = mean_squared_error(y_train, y_pred_train_xgb)\nprint(\"Mean Squared Train Error: \", mse_train_xgb)\nmetric5.append(mse_train_xgb**0.5)","ff79beaf":"# Creating a table which contain all the metrics\n\nlr_table = {'Metric': ['R2 Score (Train)',\n                       'MSE (Train)'], \n            'Linear Regression': metric_lr\n           }\nlr_metric = pd.DataFrame(lr_table ,columns = ['Metric', 'Linear Regression'] )\n\nrg_metric = pd.Series(metric2, name = 'Ridge Regression')\nls_metric = pd.Series(metric3, name = 'Lasso Regression')\nrfr_metric = pd.Series(metric4, name = 'Random Forest Regression')\nxgb_metric = pd.Series(metric5, name = 'XGBoost Regression')\n\nfinal_metric = pd.concat([lr_metric, rg_metric, ls_metric, rfr_metric, xgb_metric], axis = 1)\n\nfinal_metric","2818c835":"betas = pd.DataFrame(index=X_train.columns)","36416e26":"betas.rows = X_train.columns","52d60b51":"betas['Linear Regression'] = lr.coef_\nbetas['Ridge'] = ridge.coef_\nbetas['Lasso'] = lasso.coef_","f6560c86":"pd.set_option('display.max_rows', None)\nbetas","ed4bb5ed":"df_sub = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")\ndf_sub.head()","d3d2827a":"df_sub_lr = pd.DataFrame({\n    \"Id\": df_test_id,\n    \"SalePrice\": np.exp(y_pred_test_lr)\n})\ndf_sub_lr.to_csv('submission_lr.csv', index = False)","5c7a161e":"df_sub_rfe = pd.DataFrame({\n    \"Id\": df_test_id,\n    \"SalePrice\": np.exp(y_test_pred_rfe)\n})\ndf_sub_rfe.to_csv('submission_rfe.csv', index = False)","9c65eec4":"df_sub_lasso = pd.DataFrame({\n    \"Id\": df_test_id,\n    \"SalePrice\": np.e**(y_pred_test_lasso)\n})\ndf_sub_lasso.to_csv('submission_lasso.csv', index = False)","aed5a5f5":"df_sub_ridge = pd.DataFrame({\n    \"Id\": df_test_id,\n    \"SalePrice\": np.exp(y_pred_test_ridge)\n})\ndf_sub_ridge.to_csv('submission_ridge.csv', index = False)","a459ead1":"df_sub_rfr = pd.DataFrame({\n    \"Id\": df_test_id,\n    \"SalePrice\": np.exp(y_pred_test_rfr)\n})\ndf_sub_rfr.to_csv('submission_rfr.csv', index = False)","464ac69f":"df_sub_xgb = pd.DataFrame({\n    \"Id\": df_test_id,\n    \"SalePrice\": np.exp(y_pred_test_xgb)\n})\ndf_sub_xgb.to_csv('submission_xgb.csv', index = False)","81151875":"### Categorical Variables","e08bb859":"We will use log transform target variable to handle the outlier values.","21573ad9":"# ii. Linear Regression with RFE ","66ffa0b4":"# Exploratory Data Ananlysis","bc35424a":"#### Lets observe the changes in the coefficients after regularization","774b463a":"Highly positively correlated features: <br\/>\n1. GarageArea v\/s GarageCars (0.89) <br\/>\n2. GarageYrBit v\/s YearBuilt (0.83) <br\/>\n3. 1stFlrSF v\/s TotalBsmtSF (0.81)","90270142":"--------------------------------------------------------------------------------------------------------------","10dd4841":"We can see there is no abnormal variable in here (variable which is out of its range)","7bc4bfc0":"For columns 'Exterior2nd', 'Exterior1st' and 'Neighbourhood', we will use one hot encoding for multiclass variables. <br\/>\nBased on the winning solution of KDD 2009 Cup i.e. we are going to limit the number of categories in the these 3 variables to 10 most frequent labels.","2327345a":"So we will drop one of the variable in highly correlated features","162c03f7":"#### Ridge regression with best parameter ","fb728b74":"#### FireplaceQu: Fireplace quality\n\n       Ex\tExcellent - Exceptional Masonry Fireplace\n       Gd\tGood - Masonry Fireplace in main level\n       TA\tAverage - Prefabricated Fireplace in main living area or Masonry Fireplace in basement\n       Fa\tFair - Prefabricated Fireplace in basement\n       Po\tPoor - Ben Franklin Stove\n       NA\tNo Fireplace","38982262":"#### Fence: Fence quality\n\t\t\n       GdPrv\tGood Privacy\n       MnPrv\tMinimum Privacy\n       GdWo\tGood Wood\n       MnWw\tMinimum Wood\/Wire\n       NA\tNo Fence","1315b24e":"By looking into the id column we can say that there is no duplicate rows.","1acd8c11":"#### MasVnrType: Masonry veneer type\n\n       BrkCmn\tBrick Common\n       BrkFace\tBrick Face\n       CBlock\tCinder Block\n       None\tNone\n       Stone\tStone\n       \n#### MasVnrArea: Masonry veneer area in square feet\n\n#### BsmtExposure: Refers to walkout or garden level walls\n\n       Gd\tGood Exposure\n       Av\tAverage Exposure (split levels or foyers typically score average or above)\t\n       Mn\tMimimum Exposure\n       No\tNo Exposure\n       NA\tNo Basement\n\t\n#### BsmtFinType1: Rating of basement finished area\n\n       GLQ\tGood Living Quarters\n       ALQ\tAverage Living Quarters\n       BLQ\tBelow Average Living Quarters\t\n       Rec\tAverage Rec Room\n       LwQ\tLow Quality\n       Unf\tUnfinshed\n       NA\tNo Basement\n\n#### BsmtFinType2: Rating of basement finished area (if multiple types)\n\n       GLQ\tGood Living Quarters\n       ALQ\tAverage Living Quarters\n       BLQ\tBelow Average Living Quarters\t\n       Rec\tAverage Rec Room\n       LwQ\tLow Quality\n       Unf\tUnfinshed\n       NA\tNo Basement\n\n#### BsmtCond: Evaluates the general condition of the basement\n\n       Ex\tExcellent\n       Gd\tGood\n       TA\tTypical - slight dampness allowed\n       Fa\tFair - dampness or some cracking or settling\n       Po\tPoor - Severe cracking, settling, or wetness\n       NA\tNo Basement\n       \n#### GarageQual: Garage quality\n\n       Ex\tExcellent\n       Gd\tGood\n       TA\tTypical\/Average\n       Fa\tFair\n       Po\tPoor\n       NA\tNo Garage\n\t\t\n#### GarageCond: Garage condition\n\n       Ex\tExcellent\n       Gd\tGood\n       TA\tTypical\/Average\n       Fa\tFair\n       Po\tPoor\n       NA\tNo Garage\n\n#### BsmtQual: Evaluates the height of the basement\n\n       Ex\tExcellent (100+ inches)\t\n       Gd\tGood (90-99 inches)\n       TA\tTypical (80-89 inches)\n       Fa\tFair (70-79 inches)\n       Po\tPoor (<70 inches\n       NA\tNo Basement\n       \n#### Electrical: Electrical system\n\n       SBrkr\tStandard Circuit Breakers & Romex\n       FuseA\tFuse Box over 60 AMP and all Romex wiring (Average)\t\n       FuseF\t60 AMP Fuse Box and mostly Romex wiring (Fair)\n       FuseP\t60 AMP Fuse Box and mostly knob & tube wiring (poor)\n       Mix\tMixed\n       \n#### GarageType: Garage location\n\t\t\n       2Types\tMore than one type of garage\n       Attchd\tAttached to home\n       Basment\tBasement Garage\n       BuiltIn\tBuilt-In (Garage part of house - typically has room above garage)\n       CarPort\tCar Port\n       Detchd\tDetached from home\n       NA\tNo Garage\n       \n#### GarageFinish: Interior finish of the garage\n\n       Fin\tFinished\n       RFn\tRough Finished\t\n       Unf\tUnfinished\n       NA\tNo Garage","5b4cf53f":"#### Define the numerical and categorical columns in the dataframe","f6a5713b":"# Impute test missing values","d0653ad8":"# i. Univariate Analysis","9216cfc8":"# iv. Lasso Regression with hyperparameter tuning","f1c400ec":"# Scaling numerical variables","da3b03c7":"# iii. Bivariate Analysis ","9f6c91c9":"# iii. Ridge Regression with hyperparameter tuning","92e4e99f":"While predicting we have to be careful about transforming the log prediction back to its normal form.","2d7b4e9e":"# Log Transform the skewed columns","e5e7959c":"# ii. Segmented Univariate Analysis","94a004e4":"# Number of distinct values in variables\nfor i, column in enumerate(df.columns):\n    print(\"{}. \".format(i) + str(column.title()) + \": {}\". format(df[column].nunique()))\n    if df[column].nunique() <= 10:\n        var_categorical.append(column)\n    else:\n        var_numerical.append(column)","891731f8":"#### Linear Regression feature coefficient values in descending order","b1fc4f11":"Using the same concept of multiclass one hot encoding, we will create one hot encoding for other categorical columns.","1fe68c11":"# Model Building","7a21fe64":"var_numerical = var_numerical + ['BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', \n                                   'KitchenAbvGr', 'Fireplaces', 'PoolArea', 'YrSold', 'GarageCars']","79c13f2c":"# Form target and predictor variables","b800a849":"#### Ridge with best alpha feature coefficient values in descending order","979da103":"#### Lasso regression with best parameter ","acf8cefd":"var_categorical = var_categorical + ['Neighborhood', 'Exterior1st', 'Exterior2nd']","bdd5d70b":"var_numerical = list(set(var_numerical) - set(['Neighborhood', 'Exterior1st', 'Exterior2nd']))","05007885":"#### PoolQC: Pool quality <br>\n       Ex   Excellent <br>\n       Gd\tGood <br>\n       TA\tAverage\/Typical <br>\n       Fa\tFair <br>\n       NA\tNo Pool","1259cf79":"# i. Linear Regression","a7643ef5":"#### MiscFeature: Miscellaneous feature not covered in other categories\n\t\t\n       Elev\tElevator\n       Gar2\t2nd Garage (if not described in garage section)\n       Othr\tOther\n       Shed\tShed (over 100 SF)\n       TenC\tTennis Court\n       NA\tNone","26a8965d":"# vi. XGBoost Regressor","060c99c7":"# Label Encoding for ordinal columns","4fdd1ea9":"#### Alley: Type of alley access to property\n\n       Grvl\tGravel\n       Pave\tPaved\n       NA \tNo alley access","37416075":"### Numerical Variables","6e75254d":"#### Lasso with best parameter feature coefficient values in descending order","81b0dfcd":"sns.pairplot(df[var_numerical])\nplt.show()","b88b7871":"# <font color='red'> Advanced Regression <\/font>","df354670":"As we can see some variables shows a linear relationship with target variable. Hence, we can use regression method.","aecef7da":"We can see that SaleType_New and SaleCondition_Partial has very high correlation (0.99), so we will drop one of them.","5238a09f":"The company is looking at prospective properties to buy to enter the market. You are required to build a regression model using regularisation in order to predict the actual value of the prospective properties and decide whether to invest in them or not.\n\n \n\nThe company wants to know:\n\n    - Which variables are significant in predicting the price of a house, and\n    - How well those variables describe the price of a house.","68662d9c":"There is no highly negative correlated features.","f69e4b45":"You are required to model the price of houses with the available independent variables. This model will then be used by the management to understand how exactly the prices vary with the variables. They can accordingly manipulate the strategy of the firm and concentrate on areas that will yield high returns. Further, the model will be a good way for management to understand the pricing dynamics of a new market.","ef0f0f3e":"A US-based housing company named **Surprise Housing** has decided to enter the Australian market. The company uses data analytics to purchase houses at a price below their actual values and flip them on at a higher price. For the same purpose, the company has collected a data set from the sale of houses in Australia. ","235509de":"### Target Variable","7889aecb":"# Derived Columns","b6f1188a":"# Predictions","f23aa578":"var_numerical ","b816362b":"Based on the columns descriptions of the columns we will impute the values.\nIf columns has NA values in there category type then we will impute null values with 'NA' value","572e682f":"We have see we have lower r2 score with 50 features so we will not drop more features.","66197fab":"We can drop the condition2 column because it has mostly one value in it.","325683a5":"# Impute missing values based on our analysis","c9974257":"var_categorical = list(set(var_categorical) - set(['BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n                                                  'BedroomAbvGr', 'KitchenAbvGr', 'Fireplaces', 'PoolArea', \n                                                   'YrSold', 'GarageCars']))","9f1a68d8":"## Surprise Housing","d29da70e":"#### Lets observe the changes in the coefficients after regularization","b239692b":"# v. Random Forest Regressor","d5bd7239":"# Handle Missing Values in columns (High missing values only for now)","1528be0d":"## Business Goal ","3ad686da":"# Loading Dataset"}}