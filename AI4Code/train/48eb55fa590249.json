{"cell_type":{"42fdc9d0":"code","507dc772":"code","1576ee9a":"code","6979e3d2":"code","5ce7c42d":"code","4eabbf64":"code","014ee692":"code","ca763d3b":"code","14bc1254":"code","c79a3792":"code","db20648f":"code","0615d28e":"code","0d645290":"code","426077c2":"code","059260fc":"code","c59c7876":"code","4667cdbe":"code","c06f66dd":"code","16e91d23":"code","8a3badad":"code","c4c79066":"code","654bc360":"code","aeb24e51":"code","0eab5a2e":"code","c3acf88c":"code","6bc78074":"code","1840dc78":"code","3e9f13b4":"code","16d872c6":"code","08ecc0ac":"code","ced765b9":"code","27fc8f0c":"code","a20cb99f":"code","c62f38ad":"code","b800e7d1":"code","0b244085":"code","84dbcbc3":"code","e38a794f":"code","0d151a94":"code","956a07c0":"code","9b26fe70":"code","ae166418":"code","0f21b02e":"code","5e25bcd2":"code","d1f047e9":"code","194d41dd":"code","d782d66b":"code","3ad59fee":"code","3fef82c1":"code","eb9a2dd6":"code","b408a362":"code","a79f267f":"code","3c5ed40e":"code","e3b4b735":"code","e7863458":"code","8d55e963":"code","5b7574e8":"code","330c45eb":"code","b284b62b":"code","22274a47":"code","9ed6063e":"code","d2f6252f":"code","05372b9f":"code","16bc21ee":"code","e2020495":"code","fa27da1f":"code","e1e85c24":"code","86930325":"code","bb97be25":"code","ea280964":"code","17abd8db":"code","86ed25a0":"code","205adb8e":"code","3dac7db1":"code","fcfa12fd":"code","63c2c064":"code","87b5520d":"code","24000d6b":"code","6d499e57":"code","fea0c756":"code","611d5714":"code","212cefe9":"code","b4ebcf1c":"code","504169fd":"code","aa177f44":"code","205b00a7":"code","dee02a03":"code","48d3ebad":"code","b7a91b70":"code","c09a3d9a":"code","c9fb5360":"code","ff67b105":"code","fd71ead3":"code","8b43e744":"code","77eb5c8e":"code","012f4d91":"code","f5b25f8c":"code","8318fae1":"code","1eb2960b":"code","52b623eb":"code","32095567":"code","629d53b5":"code","200a711a":"code","0601b6f5":"code","0e3cd866":"code","4f6ed4aa":"code","62e1ffd3":"code","9f2e4495":"code","52261195":"code","172953d1":"code","4f82904d":"code","48fc4d70":"code","db7f08ed":"code","9f00e55a":"code","19679a37":"code","39cc6098":"code","c007b95d":"code","6a875bd9":"code","6b644d81":"code","cfc4f1e9":"code","0b938009":"code","1e8b81d3":"code","0b152be0":"code","66424390":"code","e45c914f":"code","7cffeac2":"code","fdd4647c":"code","764e1499":"code","20661cd9":"code","f5d23b87":"code","ca6e4686":"code","716e22ed":"code","be5daeb5":"code","736f5f1e":"code","011bcb95":"code","9b379c79":"code","59155f7a":"code","a02dae66":"code","ebb51928":"code","ac16b025":"code","4083f0a9":"code","00ffd99b":"code","8c8ea7e1":"code","64604218":"code","83197028":"code","094591bc":"code","d7e4ff14":"code","9b5b0566":"code","c3ec24b0":"code","e7dc0b4b":"code","cbd4c51b":"code","bdf29f06":"code","1b265d30":"code","f43ec208":"markdown","0e98fae4":"markdown","85216030":"markdown","507d8a82":"markdown","b47ae971":"markdown","52e76536":"markdown","3b5ba8e3":"markdown","6ac41b17":"markdown","91721bbb":"markdown","2366ff94":"markdown","90907754":"markdown","9b6e8a2a":"markdown","4680ff85":"markdown","c07e16b8":"markdown","1bbd44ff":"markdown","aa046e72":"markdown","6c6859d5":"markdown","049d37f0":"markdown","07ecc0ae":"markdown","adfb51dd":"markdown","91564e34":"markdown","db27671e":"markdown","7e42ee3f":"markdown","51934301":"markdown","e8e5494d":"markdown","9e2ee067":"markdown","e28c3fd0":"markdown","c120ab4a":"markdown","74f812fd":"markdown","bf7c0212":"markdown","d9bd0b92":"markdown","c01e247c":"markdown","9f01484e":"markdown","474af036":"markdown","b51223fc":"markdown","e7d4df86":"markdown","386a7797":"markdown","cdd6517e":"markdown","f58138f7":"markdown","e7aabfb2":"markdown","fd8388d2":"markdown","e7c41fb5":"markdown","8dcfe695":"markdown","7536ec32":"markdown","bdd5738b":"markdown","2d89e4f9":"markdown","ddfbd4da":"markdown","5a6067dc":"markdown","52e14436":"markdown","9e2201e8":"markdown","a5bce449":"markdown","04ae1a16":"markdown","14077b4a":"markdown","6daaaeca":"markdown","68cd4f6f":"markdown","8ea97475":"markdown","860f124f":"markdown","e3f48d11":"markdown","ad146741":"markdown","49a6bd4b":"markdown","32b62399":"markdown"},"source":{"42fdc9d0":"!pip install texthero","507dc772":"!pip install jupyter_dash","1576ee9a":"# Basic libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport datetime as dt\nfrom scipy import stats\nimport json\n\n# NLP libraries\nimport texthero as hero\nfrom nltk.tokenize import ToktokTokenizer\n\n# Data visualization libraries\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n\n\n# Sklearn libraries\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection\n\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import preprocessing\nfrom xgboost import XGBClassifier\nfrom xgboost import plot_importance\n\n","6979e3d2":"df = pd.read_csv('\/kaggle\/input\/online-retail-ii-uci\/online_retail_II.csv')","5ce7c42d":"df = df.dropna(subset=[\"Customer ID\"])","4eabbf64":"print('Duplicate entries: {}'.format(df.duplicated().sum()))\ndf.drop_duplicates(inplace = True)","014ee692":"df['Discount'] = 0\nfor index, col in  df[df['StockCode']=='D'].iterrows():\n    invoice = col['Invoice']\n    price = col['Price']\n    \n    df.loc[(df.Invoice == invoice), 'Discount'] = price\n    ","ca763d3b":"df['Postage'] = 0\nfor index, col in  df[df['StockCode']=='POST'].iterrows():\n    invoice = col['Invoice']\n    price = col['Price']\n    \n    df.loc[(df.Invoice == invoice), 'Postage'] = price\n    ","14bc1254":"list_special_codes = df[df['StockCode'].str.contains('^[a-zA-Z]+', regex=True)]['StockCode'].unique()\nlist_special_codes ","c79a3792":"for code in list_special_codes : \n    df = df[df['StockCode']!= code]","db20648f":"#This part was inspired by Fabien Daniel's brilliant work in his Notebook on customer segmentation.\n\ndf_cleaned = df.copy(deep = True)\ndf_cleaned['QuantityCanceled'] = 0\n\nentry_to_remove = [] ; doubtfull_entry = []\n\nfor index, col in  df.iterrows():\n    if (col['Quantity'] > 0) or col['Description'] == 'Discount': continue        \n    df_test = df[(df['Customer ID'] == col['Customer ID']) &\n                         (df['StockCode']  == col['StockCode']) & \n                         (df['InvoiceDate'] < col['InvoiceDate']) & \n                         (df['Quantity']   > 0)].copy()\n    #_________________________________\n    # Cancelation WITHOUT counterpart\n    if (df_test.shape[0] == 0): \n        doubtfull_entry.append(index)\n    #________________________________\n    # Cancelation WITH a counterpart\n    elif (df_test.shape[0] == 1): \n        index_order = df_test.index[0]\n        df_cleaned.loc[index_order, 'QuantityCanceled'] = -col['Quantity']\n        entry_to_remove.append(index)        \n    #______________________________________________________________\n    # Various counterparts exist in orders: we delete the last one\n    elif (df_test.shape[0] > 1): \n        df_test.sort_index(axis=0 ,ascending=False, inplace = True)        \n        for ind, val in df_test.iterrows():\n            if val['Quantity'] < -col['Quantity']: continue\n            df_cleaned.loc[ind, 'QuantityCanceled'] = -col['Quantity']\n            entry_to_remove.append(index) \n            break    ","0615d28e":"print(\"entry_to_remove: {}\".format(len(entry_to_remove)))\nprint(\"doubtfull_entry: {}\".format(len(doubtfull_entry)))","0d645290":"df_cleaned.drop(entry_to_remove, axis = 0, inplace = True)\ndf_cleaned.drop(doubtfull_entry, axis = 0, inplace = True)\nremaining_entries = df_cleaned[(df_cleaned['Quantity'] < 0) & (df_cleaned['StockCode'] != 'D')]\nprint(\"nb of entries to delete: {}\".format(remaining_entries.shape[0]))\nremaining_entries[:5]","426077c2":"df_cleaned.drop(remaining_entries.index, axis = 0, inplace = True)","059260fc":"product_df = df_cleaned.drop(columns=['StockCode', 'Invoice', 'Customer ID', 'Price', 'Quantity', 'InvoiceDate', 'Country'])\nproduct_df['Description'] = df['Description'].pipe(hero.clean)","c59c7876":"tw = hero.visualization.top_words(product_df['Description']).head(40)\n\nfig = px.bar(tw)\nfig.show()","4667cdbe":"token = ToktokTokenizer()","c06f66dd":"def TagExtractor(text, tags):\n    \n    words=token.tokenize(text)\n    \n    filtered = [w for w in words if  w in tags]\n    \n    return ' '.join(map(str, filtered))","16e91d23":"def TagRemove(text, tags):\n    \n    words=token.tokenize(text)\n    \n    filtered = [w for w in words if not w in tags]\n    \n    return ' '.join(map(str, filtered))","8a3badad":"colors = ['black', 'blue', 'brown', 'gold', 'green', 'grey', 'orange', 'pink', 'purple', 'red', 'silver', 'white', 'yellow', 'ivory']","c4c79066":"product_df['ProductColor'] = product_df['Description'].apply(lambda x: TagExtractor(x, colors)) ","654bc360":" product_df['Description'] = product_df['Description'].apply(lambda x: TagRemove(x, colors)) ","aeb24e51":"tw = hero.visualization.top_words(product_df['ProductColor']).head(20)\n\nfig = px.bar(tw)\nfig.show()","0eab5a2e":"Design = ['gingham', 'butterfly', 'chocolate', 'zinc', 'hearts', 'star', 'skull', 'dolly', 'wood', 'retro', 'strawberry',\n         'mini', 'polkadot', 'spot', 'cream', 'rose', 'spaceboy', 'ceramic', 'glasse', 'vintage', 'retrospot', 'heart',\n         'spots', 'skulls', 'scandinavian', 'london', 'french', 'wooden', 'woodland', 'bakelike', 'feltrcraft', 'porcelain',\n         'spaceboy', 'glass', 'traditional', 'bird', 'birds', 'flower', 'antique', 'tube']","c3acf88c":"product_df['Design'] = product_df['Description'].apply(lambda x: TagExtractor(x, Design)) ","6bc78074":"stop_words = ['set', 'pack', 'small', 'large']","1840dc78":" product_df['Description'] = product_df['Description'].apply(lambda x: TagRemove(x, (Design+stop_words))) ","3e9f13b4":"tw = hero.visualization.top_words(product_df['Design']).head(20)\n\nfig = px.bar(tw)\nfig.show()","16d872c6":"Categories = ['bag', 'box', 'cake', 'christmas', 'hanging', 'light', 'holder', 'sign', 'jumbo', 'lunch', 'paper', 'tea', 'card',\n              'cases', 'decoration', 'water', 'bottle', 'mug', 'party', 'garden', 'wrap', 'bowl', 'birthday', \n              'photo', 'frame', 'candle', 'key', 'ring', 'travel', 'egg', 'cup', \n              'lights', 'cutlery', 'candles', 'door', 'gift', 'clock', 'trinket', \n              'drawer', 'stand', 'pencils', 'ribbons', 'napkins', 'notebook', 'photo', 'alarm', 'dog',\n             'kitchen', 'storage', 'childrens', 'cup', 'cat', 'wall', 'art', 'cushion', 'cover', 'popcorn', 'soap', 'baking', 'door']\n","08ecc0ac":"product_df['Categories'] = product_df['Description'].apply(lambda x: TagExtractor(x, Categories)) ","ced765b9":"pd.DataFrame(product_df['Categories'].value_counts()).to_excel('product_categories.xlsx')","27fc8f0c":"product_tags = pd.read_excel('\/kaggle\/input\/product-categories\/product_categories V2.xlsx')","a20cb99f":"product_tags.head()","c62f38ad":"product_df = product_df.reset_index().merge(product_tags, on='Categories', how='left').set_index('index')","b800e7d1":"product_df.loc[(product_df.Description =='wicker'), 'Labels'] = 'Wicker'\n\nproduct_df.loc[(product_df.Description =='assorted colour ornament'), 'Labels'] = 'Home Decoration'\n\nproduct_df.loc[(product_df.Description =='tissues'), 'Labels'] = 'Essentials'\n\nproduct_df.loc[(product_df.Description =='chalkboard'), 'Labels'] = 'Stationary'\n\nproduct_df.loc[(product_df.Description =='milk jug'), 'Labels'] = 'Tableware'\n\nproduct_df.loc[(product_df.Description =='measuring spoons'), 'Labels'] = 'Baking'\n\nproduct_df.loc[(product_df.Description =='snap cards'), 'Labels'] = 'Cards'","0b244085":"product_df.loc[(product_df.Description =='regency cakestand tier'), 'Labels'] = 'Cake Decoration'\n\nproduct_df.loc[(product_df.Description =='heart wicker small'), 'Labels'] = 'Hanging Decoration'\n\nproduct_df.loc[(product_df.Description =='heart wicker large'), 'Labels'] = 'Hanging Decoration'\n\nproduct_df.loc[(product_df.Description =='edwardian parasol'), 'Labels'] = 'Essentials'\n\nproduct_df.loc[(product_df.Description =='regency teacup saucer'), 'Labels'] = 'Tea'\n\nproduct_df.loc[(product_df.Description =='natural slate heart chalkboard'), 'Labels'] = 'Home Decoration'\n\nproduct_df.loc[(product_df.Description =='french metal door sign'), 'Labels'] = 'Door Sign'\n\nproduct_df.loc[(product_df.Description =='love building block word'), 'Labels'] = 'Home Decoration'\n\nproduct_df.loc[(product_df.Description =='vintage snap cards'), 'Labels'] = 'Cards'\n\nproduct_df.loc[(product_df.Description =='scottie dog hot water bottle'), 'Labels'] = 'Water Bottle'\n\nproduct_df.loc[(product_df.Labels =='Holders'), 'Labels'] = 'Holding Decoration'","84dbcbc3":"for label in ['Decorative Storage', 'Hanging Decoration', 'Lights', 'Candles', 'Door Signs', 'Wall Signs', 'Wicker', 'Clocks',\n             'Storage', 'Frame', 'Photo Frame', 'Wall Art', 'Holding Decoration', 'Popcorn Holder']:\n    product_df.loc[(product_df.Labels ==label), 'Labels'] = 'Home Decoration'","e38a794f":"for label in ['Lunch Bags', 'Jumbo Bags', 'Jumbo Shopper']:\n    product_df.loc[(product_df.Labels ==label), 'Labels'] = 'Bags'","0d151a94":"for label in ['Cards', 'Paper', 'Cushions', 'Wraps', 'Gift Wraps']:\n    product_df.loc[(product_df.Labels ==label), 'Labels'] = 'Gifts'","956a07c0":"for label in ['Water Bottle', 'Essentials', 'Travel', 'Pets', 'Jewelry']:\n    product_df.loc[(product_df.Labels ==label), 'Labels'] = 'Other'","9b26fe70":"for label in ['Cake Decoration', 'Birthday']:\n    product_df.loc[(product_df.Labels ==label), 'Labels'] = 'Party'","ae166418":"for label in ['Tea', 'Baking', 'Kitchen', 'Soap']:\n    product_df.loc[(product_df.Labels ==label), 'Labels'] = 'Tableware'","0f21b02e":"product_df['Labels'].value_counts().sum() \/product_df['Labels'].shape[0]*100","5e25bcd2":"X = product_df.dropna(subset=['Labels']).drop_duplicates(subset=['Description'])['Description']\nX_test = product_df[product_df['Labels'].isnull()]['Description']","d1f047e9":"X.shape, X_test.shape","194d41dd":"le = preprocessing.LabelEncoder()","d782d66b":"y = le.fit_transform(product_df.dropna(subset=['Labels']).drop_duplicates(subset=['Description'])['Labels'])","3ad59fee":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.4, random_state = 46) # Do 60\/40 split","3fef82c1":"X_vectorizer = TfidfVectorizer(analyzer = 'word',\n                            )","eb9a2dd6":"X_train = X_vectorizer.fit_transform(X_train)\nX_val =  X_vectorizer.transform(X_val)\nX_test_tfidf = X_vectorizer.transform(X_test)","b408a362":"def print_score(y_pred, clf):\n    print(\"Clf: \", clf.__class__.__name__)\n    print(\"Accuracy score: {}\".format(accuracy_score(y_val, y_pred)))\n    print(\"---\")    ","a79f267f":"dummy = DummyClassifier(strategy='prior')\nsgd = SGDClassifier()\nmn = MultinomialNB()\nsvc = LinearSVC()\nperceptron = Perceptron()\npac = PassiveAggressiveClassifier()\nmlpc = MLPClassifier()\nrfc = RandomForestClassifier()\nxgb = XGBClassifier()\n\n\nfor classifier in [dummy, sgd, mn, svc, perceptron, pac, mlpc, rfc, xgb]:\n    classifier.fit(X_train, y_train)\n    y_pred = classifier.predict(X_val)\n    print_score(y_pred, classifier)","3c5ed40e":"y_pred_test = rfc.predict(X_test_tfidf) ","e3b4b735":"prods_non_labeled = pd.DataFrame()","e7863458":"prods_non_labeled['Description']= X_test","8d55e963":"prods_non_labeled['Labels'] = le.inverse_transform(y_pred_test)","5b7574e8":"prods_non_labeled","330c45eb":"product_df.loc[(product_df.Labels.isnull()), 'Labels'] = prods_non_labeled['Labels']","b284b62b":"product_df","22274a47":"product_df.shape, df.shape","9ed6063e":"df_cleaned['ProductColor'] = product_df['ProductColor']\ndf_cleaned['Design'] = product_df['Design']\ndf_cleaned['Labels'] = product_df['Labels']","d2f6252f":"df_cleaned['Labels'].value_counts(dropna=False)","05372b9f":"# Total price feature\n\ndf_cleaned['TotalPrice'] = df_cleaned['Price'] * (df_cleaned['Quantity'] - df_cleaned['QuantityCanceled'])","16bc21ee":"df_cleaned['TotalPrice'].describe()","e2020495":"df_cleaned[df_cleaned['TotalPrice']<0]","fa27da1f":"df_cleaned.drop(df_cleaned[df_cleaned['TotalPrice']<0].index, axis = 0, inplace = True)","e1e85c24":"z = np.abs(stats.zscore(df_cleaned['TotalPrice']))\nthreshold = 10\n\ndf_cleaned_outliers = df_cleaned.copy(deep=True)\ndf_cleaned_outliers['Outliers'] = z\n\ndf_cleaned_outliers[df_cleaned_outliers['Outliers']>threshold]","86930325":"df_cleaned.drop(df_cleaned_outliers[df_cleaned_outliers['Outliers']>threshold].index, axis = 0, inplace = True)","bb97be25":"df_cleaned['InvoiceDate'] = pd.to_datetime(df_cleaned['InvoiceDate'])","ea280964":"df_cleaned['Year'] = df_cleaned[\"InvoiceDate\"].apply(lambda x: x.year)\ndf_cleaned['Month'] = df_cleaned[\"InvoiceDate\"].apply(lambda x: x.month)\ndf_cleaned['MonthYear'] = df_cleaned[\"InvoiceDate\"].apply(lambda x: x.strftime(\"%B %Y\"))\ndf_cleaned['Weekday'] = df_cleaned[\"InvoiceDate\"].apply(lambda x: x.weekday())\ndf_cleaned['Day'] = df_cleaned[\"InvoiceDate\"].apply(lambda x: x.day)\ndf_cleaned['Hour'] = df_cleaned[\"InvoiceDate\"].apply(lambda x: x.hour)","17abd8db":"df_cleaned['InvoiceDate'].min()","86ed25a0":"df_cleaned['InvoiceDate'].max()","205adb8e":"NOW = dt.datetime(2011,12,10)","3dac7db1":"df_cleaned.shape[0] \/ df_cleaned['Invoice'].value_counts().count() ","fcfa12fd":"custom_aggregation = {}\ncustom_aggregation[\"InvoiceDate\"] = lambda x:x.iloc[0]\ncustom_aggregation[\"Customer ID\"] = lambda x:x.iloc[0]\ncustom_aggregation[\"TotalPrice\"] = \"sum\"","63c2c064":"rfmTable = df_cleaned.groupby(\"Invoice\").agg(custom_aggregation)","87b5520d":"rfmTable[\"Recency\"] = NOW - rfmTable[\"InvoiceDate\"]\nrfmTable[\"Recency\"] = pd.to_timedelta(rfmTable[\"Recency\"]).astype(\"timedelta64[D]\")","24000d6b":"rfmTable.head(5)","6d499e57":"custom_aggregation = {}\n\ncustom_aggregation[\"Recency\"] = [\"min\", \"max\"]\ncustom_aggregation[\"InvoiceDate\"] = lambda x: len(x)\ncustom_aggregation[\"TotalPrice\"] = \"sum\"","fea0c756":"rfmTable_final = rfmTable.groupby(\"Customer ID\").agg(custom_aggregation)","611d5714":"rfmTable_final.columns = [\"min_recency\", \"max_recency\", \"frequency\", \"monetary_value\"]","212cefe9":"rfmTable_final.head(5)","b4ebcf1c":"first_customer = df_cleaned[df_cleaned['Customer ID']==12346.0]\nfirst_customer.head(5)","504169fd":"quantiles = rfmTable_final.quantile(q=[0.25,0.5,0.75])\nquantiles = quantiles.to_dict()","aa177f44":"segmented_rfm = rfmTable_final","205b00a7":"def RScore(x,p,d):\n    if x <= d[p][0.25]:\n        return 1\n    elif x <= d[p][0.50]:\n        return 2\n    elif x <= d[p][0.75]: \n        return 3\n    else:\n        return 4\n    \ndef FMScore(x,p,d):\n    if x <= d[p][0.25]:\n        return 4\n    elif x <= d[p][0.50]:\n        return 3\n    elif x <= d[p][0.75]: \n        return 2\n    else:\n        return 1","dee02a03":"segmented_rfm['r_quartile'] = segmented_rfm['min_recency'].apply(RScore, args=('min_recency',quantiles,))\nsegmented_rfm['f_quartile'] = segmented_rfm['frequency'].apply(FMScore, args=('frequency',quantiles,))\nsegmented_rfm['m_quartile'] = segmented_rfm['monetary_value'].apply(FMScore, args=('monetary_value',quantiles,))\nsegmented_rfm.head()","48d3ebad":"segmented_rfm['RFMScore'] = segmented_rfm.r_quartile.map(str) + segmented_rfm.f_quartile.map(str) + segmented_rfm.m_quartile.map(str)\nsegmented_rfm.head()","b7a91b70":"segmented_rfm[segmented_rfm['RFMScore']=='111'].sort_values('monetary_value', ascending=False)","c09a3d9a":"segmented_rfm.head(5)","c9fb5360":"segmented_rfm = segmented_rfm.reset_index()","ff67b105":"segmented_rfm.head(5)","fd71ead3":"df_cleaned.shape","8b43e744":"df_cleaned = pd.merge(df_cleaned,segmented_rfm, on='Customer ID')","77eb5c8e":"df_cleaned = df_cleaned.drop(columns=['r_quartile', 'f_quartile', 'm_quartile'])","012f4d91":"for label in df_cleaned['Labels'].unique():\n    col = 'Label_{}'.format(label)        \n    df_temp = df_cleaned[df_cleaned['Labels'] == label]\n    price_temp = df_temp['TotalPrice']\n    df_cleaned.loc[:, col] = price_temp\n    df_cleaned[col].fillna(0, inplace = True)","f5b25f8c":"df_cleaned['RFMScore'] = df_cleaned['RFMScore'].astype(int)","8318fae1":"df_cleaned.loc[(df_cleaned.RFMScore == 111), 'Segment'] = 'Best Customers'","1eb2960b":"df_cleaned.loc[(df_cleaned.RFMScore == 311), 'Segment'] = 'Almost Lost'","52b623eb":"df_cleaned.loc[(df_cleaned.RFMScore == 411), 'Segment'] = 'Lost Customers'","32095567":"df_cleaned.loc[(df_cleaned.RFMScore == 444), 'Segment'] = 'Bad Customers'","629d53b5":"for code in [112, 113, 114, 212, 213, 214, 312, 313, 314, 412, 413, 414] : \n    df_cleaned.loc[(df_cleaned.RFMScore == code), 'Segment'] = 'Loyal Customers'","200a711a":"for code in [121, 131, 141, 221, 231, 241, 321, 331, 341, 421, 431, 441] : \n    df_cleaned.loc[(df_cleaned.RFMScore == code), 'Segment'] = 'Big Spenders'","0601b6f5":"for code in [211, 222, 122, 123, 223] : \n    df_cleaned.loc[(df_cleaned.RFMScore == code), 'Segment'] = 'Good Customers'","0e3cd866":"for code in [322, 232, 132, 242, 142, 224, 124] : \n    df_cleaned.loc[(df_cleaned.RFMScore == code), 'Segment'] = 'Average Customer'","4f6ed4aa":"df_cleaned.loc[df_cleaned.Segment.isnull()]['RFMScore'].value_counts()","62e1ffd3":"for code in df_cleaned.loc[df_cleaned.Segment.isnull()]['RFMScore'].value_counts().index : \n    df_cleaned.loc[(df_cleaned.RFMScore == code), 'Segment'] = 'Not So Good Customers'","9f2e4495":"new_cust = []\nfor value in df_cleaned[df_cleaned['InvoiceDate']>='2011-10-01 07:45:00']['Customer ID'].value_counts().index:\n    if value not in df_cleaned[df_cleaned['InvoiceDate']<'2011-10-01 07:45:00']['Customer ID'].value_counts().index :\n        new_cust.append(value)","52261195":"df_cleaned_new_cust = df_cleaned[df_cleaned['Customer ID'].isin(new_cust)]","172953d1":"df_cleaned_old_cust = df_cleaned[~df_cleaned['Customer ID'].isin(new_cust)]","4f82904d":"(df_cleaned_new_cust.shape, df_cleaned_old_cust.shape)","48fc4d70":"custom_aggregation = {}\ncustom_aggregation[\"Customer ID\"] = lambda x:x.iloc[0]\nfor label in df_cleaned['Labels'].unique():\n    col = 'Label_{}'.format(label)  \n    custom_aggregation[col] = \"sum\"\n\ncustom_aggregation[\"Quantity\"] = 'sum'\ncustom_aggregation[\"Price\"] = 'mean'\ncustom_aggregation[\"TotalPrice\"] = 'sum'\ncustom_aggregation[\"QuantityCanceled\"] = \"sum\"\ncustom_aggregation[\"Postage\"] = lambda x:x.iloc[0]\ncustom_aggregation[\"Discount\"] = lambda x:x.iloc[0]\n\n\ncustom_aggregation[\"min_recency\"] = lambda x:x.iloc[0]\ncustom_aggregation[\"max_recency\"] = lambda x:x.iloc[0]\ncustom_aggregation[\"frequency\"] = lambda x:x.iloc[0]\ncustom_aggregation[\"monetary_value\"] = lambda x:x.iloc[0]\n\ncustom_aggregation[\"Segment\"] = lambda x:x.iloc[0]","db7f08ed":"df_grouped_train = df_cleaned_old_cust.groupby(\"Invoice\").agg(custom_aggregation)","9f00e55a":"df_grouped_test = df_cleaned_new_cust.groupby(\"Invoice\").agg(custom_aggregation)","19679a37":"custom_aggregation = {}\n\nfor label in df_cleaned['Labels'].unique():\n    col = 'Label_{}'.format(label)  \n    custom_aggregation[col] = \"sum\"\n\ncustom_aggregation[\"Quantity\"] = 'mean'\ncustom_aggregation[\"Price\"] = 'mean'\ncustom_aggregation[\"TotalPrice\"] = 'mean'\ncustom_aggregation[\"QuantityCanceled\"] = \"sum\"\ncustom_aggregation[\"Postage\"] = \"sum\"\ncustom_aggregation[\"Discount\"] = \"sum\"\n\n\ncustom_aggregation[\"min_recency\"] = lambda x:x.iloc[0]\ncustom_aggregation[\"max_recency\"] = lambda x:x.iloc[0]\ncustom_aggregation[\"frequency\"] = lambda x:x.iloc[0]\ncustom_aggregation[\"monetary_value\"] = lambda x:x.iloc[0]\ncustom_aggregation[\"Segment\"] = lambda x:x.iloc[0]\n","39cc6098":"df_grouped_final_train = df_grouped_train.groupby(\"Customer ID\").agg(custom_aggregation)","c007b95d":"df_grouped_final_test = df_grouped_test.groupby(\"Customer ID\").agg(custom_aggregation)","6a875bd9":"X_train = df_grouped_final_train.drop(columns=['Segment'])","6b644d81":"y_train = df_grouped_final_train['Segment']","cfc4f1e9":"le_label = preprocessing.LabelEncoder()","0b938009":"y_train = le_label.fit_transform(y_train)","1e8b81d3":"X_test = df_grouped_final_test.drop(columns=['Segment'])","0b152be0":"y_test = df_grouped_final_test['Segment']","66424390":"y_test = le_label.transform(y_test)","e45c914f":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 46) # Do 80\/20 split","7cffeac2":"scaler = preprocessing.StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\nX_test = scaler.transform(X_test)","fdd4647c":"def print_score(y_pred, clf):\n    print(\"Clf: \", clf.__class__.__name__)\n    print(\"Accuracy score: {}\".format(accuracy_score(y_val, y_pred)))\n    print(\"---\")    ","764e1499":"dummy = DummyClassifier(strategy='prior')\nsgd = SGDClassifier()\nmn = MultinomialNB()\nsvc = LinearSVC()\nperceptron = Perceptron()\npac = PassiveAggressiveClassifier()\nmlpc = MLPClassifier()\nrfc = RandomForestClassifier()\nxgb = XGBClassifier()\n\n\nfor classifier in [dummy, sgd, svc, perceptron, pac, mlpc, rfc, xgb]:\n    classifier.fit(X_train, y_train)\n    y_pred = classifier.predict(X_val)\n    print_score(y_pred, classifier)","20661cd9":"y_pred = xgb.predict(X_test)\naccuracy_score(y_test, y_pred)","f5d23b87":"plot_importance(xgb)","ca6e4686":"custom_aggregation = {}\n\ncustom_aggregation[\"InvoiceDate\"] = lambda x:x.iloc[0]\ncustom_aggregation[\"MonthYear\"] = lambda x:x.iloc[0]\n\ncustom_aggregation[\"TotalPrice\"] = 'sum'","716e22ed":"sales_invoices_montly = df_cleaned.groupby('MonthYear').agg(custom_aggregation).sort_values(by='InvoiceDate')\nsales_invoices_montly.head()","be5daeb5":"data = [go.Scatter(x=sales_invoices_montly.index, \n                   y=sales_invoices_montly['TotalPrice'])]\n\nlayout = go.Layout(title=\"Total sales\", title_x=0.5)\n\nfig = go.Figure(data=data, layout=layout)\nfig.update_xaxes(type='category')\n\nfig.show()","736f5f1e":"year_options = []\nfor year in df_cleaned['Year'].unique():\n    year_options.append({'label':str(year), 'value':year})\nyear_options.append({'label':'All', 'value':'All'})","011bcb95":"customer_country=df_cleaned[['Country','Customer ID']].drop_duplicates()\ndf_cleaned_grouped = customer_country.groupby(['Country'])['Customer ID'].aggregate('count').reset_index().sort_values('Customer ID', ascending=False)\n\n\nfiltered_df_2009 = df_cleaned[df_cleaned['Year']==2009]\ncustomer_country_2009=filtered_df_2009[['Country','Customer ID']].drop_duplicates()\nfiltered_df_2009_grouped = customer_country_2009.groupby(['Country'])['Customer ID'].aggregate('count').reset_index().sort_values('Customer ID', ascending=False)\n\nfiltered_df_2010 = df_cleaned[df_cleaned['Year']==2010]\ncustomer_country_2010=filtered_df_2010[['Country','Customer ID']].drop_duplicates()\nfiltered_df_2010_grouped = customer_country_2010.groupby(['Country'])['Customer ID'].aggregate('count').reset_index().sort_values('Customer ID', ascending=False)\n\nfiltered_df_2011 = df_cleaned[df_cleaned['Year']==2011]\ncustomer_country_2011=filtered_df_2011[['Country','Customer ID']].drop_duplicates()\nfiltered_df_2011_grouped = customer_country_2011.groupby(['Country'])['Customer ID'].aggregate('count').reset_index().sort_values('Customer ID', ascending=False)","9b379c79":"data = [go.Choropleth(\n                locations = df_cleaned_grouped['Country'],\n                locationmode = 'country names',\n                z = df_cleaned_grouped['Customer ID'],\n                text = df_cleaned_grouped['Country'],\n                colorscale = 'Rainbow',\n                marker_line_color='darkgray',\n                marker_line_width=0.5,\n                colorbar_title = 'Customers',\n                ),\n        go.Choropleth(\n                locations = filtered_df_2009_grouped['Country'],\n                locationmode = 'country names',\n                z = filtered_df_2009_grouped['Customer ID'],\n                text = filtered_df_2009_grouped['Country'],\n                colorscale = 'Rainbow',\n                marker_line_color='darkgray',\n                marker_line_width=0.5,\n                colorbar_title = 'Customers',\n                ),\n        go.Choropleth(\n                locations = filtered_df_2010_grouped['Country'],\n                locationmode = 'country names',\n                z = filtered_df_2010_grouped['Customer ID'],\n                text = filtered_df_2010_grouped['Country'],\n                colorscale = 'Rainbow',\n                marker_line_color='darkgray',\n                marker_line_width=0.5,\n                colorbar_title = 'Customers',\n                ),\n        go.Choropleth(\n                locations = filtered_df_2011_grouped['Country'],\n                locationmode = 'country names',\n                z = filtered_df_2011_grouped['Customer ID'],\n                text = filtered_df_2011_grouped['Country'],\n                colorscale = 'Rainbow',\n                marker_line_color='darkgray',\n                marker_line_width=0.5,\n                colorbar_title = 'Customers',\n                ),\n       ]","59155f7a":"layout = go.Layout(\n                title_text='Our customers',\n                title_x=0.5,\n                geo=dict(\n                    showframe=False,\n                    showcoastlines=False,\n                    projection_type='equirectangular'\n                ),\n                )","a02dae66":"fig = go.Figure(data=data, layout=layout)","ebb51928":"# Add dropdown \nfig.update_layout( \n    updatemenus=[ \n        dict( \n            active=0, \n            buttons=list([ \n                dict(label=\"All\", \n                     method=\"update\", \n                     args=[{\"visible\": [True, False, False, False]}, \n                           {\"title\": \"All customers\"}]), \n                dict(label=\"2009\", \n                     method=\"update\", \n                     args=[{\"visible\": [False, True, False, False]}, \n                           {\"title\": \"Customers in 2009\", \n                            }]), \n                dict(label=\"2010\", \n                     method=\"update\", \n                     args=[{\"visible\": [False, False, True, False]}, \n                           {\"title\": \"Customers in 2010\", \n                            }]), \n                dict(label=\"2011\", \n                     method=\"update\", \n                     args=[{\"visible\": [False, False, False, True]}, \n                           {\"title\": \"Customers in 2011\", \n                            }]), \n            ]), \n        ) \n    ]) \n  \nfig.show() ","ac16b025":"df_cleaned.groupby('Country')['TotalPrice'].sum().sort_values(ascending=False)[:6]","4083f0a9":"countries = ['EIRE', 'Netherlands', 'Germany', 'France', 'Australia'] \n\ncountries_options = []\ndata = []\nfor country in countries:\n    year_options.append({'label':str(country), 'value':country})\n\nfor country in countries:\n    df_segment = df_cleaned[df_cleaned['Country']==country]\n    df_segment_grouped = df_segment.groupby('MonthYear').agg(custom_aggregation).sort_values(by='InvoiceDate')\n    \n    data.append(go.Bar(x=df_segment_grouped.index, \n                   y=df_segment_grouped['TotalPrice']))\n    \n","00ffd99b":"layout = go.Layout(\n                title_text='Our customers',\n                title_x=0.5,\n                geo=dict(\n                    showframe=False,\n                    showcoastlines=False,\n                    projection_type='equirectangular'\n                ),\n                )","8c8ea7e1":"fig = go.Figure(data=data, layout=layout)","64604218":"# Add dropdown \nfig.update_layout( \n    updatemenus=[ \n        dict( \n            active=0, \n            buttons=list([ \n                dict(label=countries[0], \n                     method=\"update\", \n                     args=[{\"visible\": [True, False, False, False, False]}, \n                           {\"title\": \"{} sells\".format(countries[0])}]), \n                dict(label=countries[1], \n                     method=\"update\", \n                     args=[{\"visible\": [False, True, False, False, False]}, \n                           {\"title\": \"{} sells\".format(countries[1])}]), \n                dict(label=countries[2], \n                     method=\"update\", \n                     args=[{\"visible\": [False, False, True, False, False]}, \n                           {\"title\": \"{} sells\".format(countries[2])}]), \n                dict(label=countries[3], \n                     method=\"update\", \n                     args=[{\"visible\": [False, False, False, True, False]}, \n                           {\"title\": \"{} sells\".format(countries[3])}]), \n                dict(label=countries[4], \n                     method=\"update\", \n                     args=[{\"visible\": [False, False, False, False, True]}, \n                           {\"title\": \"{} sells\".format(countries[4])}]), \n                \n            ]), \n        ) \n    ]) \n  \nfig.show() ","83197028":"i = 1\nj = 1\ndata = []\nsegment_names = ['Best Customers', 'Big Spenders', 'Good Customers', 'Loyal Customers', 'Average Customer', \n                 'Not So Good Customers', 'Almost Lost', 'Lost Customers', 'Bad Customers']\nfor segment in segment_names:\n    df_segment = df_cleaned[df_cleaned['Segment']==segment]\n    df_segment_grouped = df_segment.groupby('MonthYear').agg(custom_aggregation).sort_values(by='InvoiceDate')\n    \n    data.append(go.Scatter(x=df_segment_grouped.index, \n                   y=df_segment_grouped['TotalPrice']))\n    \nfig = make_subplots(rows=3, cols=3, shared_yaxes=True, vertical_spacing=0.19, subplot_titles=(segment_names[0], segment_names[1], segment_names[2], segment_names[3], segment_names[4], segment_names[5], \n                                  segment_names[6], segment_names[7], segment_names[8]))    \n    \nk = 0\nfor i in range(1,4):\n    for j in range(1,4):\n        fig.add_trace(data[k], row=i, col=j)\n        k+=1\n\n\nfig.update_layout(height=1000, width=1000, title_text=\"Sales Through segments\", title_x=0.5\n                  )\nfor i in fig['layout']['annotations']:\n    i['font'] = dict(size=10,color='#ff0000')\nfig.show()","094591bc":"most_sold_prod = df_cleaned.groupby(['Description'])['Quantity'].sum().sort_values(ascending=False)[:10]\n\ndata = [go.Bar(x=most_sold_prod.index, \n               y=most_sold_prod.values)]\n\nlayout = go.Layout(title=\"TOP 10 most sold products\", title_x=0.5)\n\nfig = go.Figure(data=data, layout=layout)\n\nfig.show()","d7e4ff14":"i = 1\nj = 1\ndata = []\nprod_names= []\nfor product in most_sold_prod.index[0:9]:\n    df_product = df_cleaned[df_cleaned['Description']==product]\n    df_product_grouped = df_product.groupby('MonthYear').agg(custom_aggregation).sort_values(by='InvoiceDate')\n    \n    data.append(go.Scatter(x=df_product_grouped.index, \n                   y=df_product_grouped['TotalPrice']))\n    prod_names.append(product)\n    \nfig = make_subplots(rows=3, cols=3, vertical_spacing=0.19, subplot_titles=(prod_names[0], prod_names[1], prod_names[2], prod_names[3], prod_names[4], prod_names[5], \n                                  prod_names[6], prod_names[7], prod_names[8]))    \n    \nk = 0\nfor i in range(1,4):\n    for j in range(1,4):\n        fig.add_trace(data[k], row=i, col=j)\n        k+=1\n\n\nfig.update_layout(height=1000, width=1000, title_text=\"Best products monthly sales\", title_x=0.5\n                  )\nfor i in fig['layout']['annotations']:\n    i['font'] = dict(size=10,color='#ff0000')\nfig.show()","9b5b0566":"prod_categories = df_cleaned.groupby('Labels')['TotalPrice'].sum()","c3ec24b0":"data = [go.Pie(labels=prod_categories.index, \n                   values=prod_categories.values)]\n\nlayout = go.Layout(title=\"Total sales through product categories\", title_x=0.5)\n\nfig = go.Figure(data=data, layout=layout)\n\nfig.show()","e7dc0b4b":"hourly_sales = df_cleaned.groupby('Hour')['TotalPrice'].sum().sort_index(ascending=True)\nhourly_sales","cbd4c51b":"data = [go.Bar(x=hourly_sales.index, \n               y=hourly_sales.values)]\n\nlayout = go.Layout(title=\"Hourly sales\", title_x=0.5)\n\nfig = go.Figure(data=data, layout=layout)\n\nfig.show()","bdf29f06":"weekday_sales = df_cleaned.groupby('Weekday')['TotalPrice'].sum().sort_index(ascending=True)\n\ndata = [go.Bar(x=weekday_sales.index, \n               y=weekday_sales.values)]\n\nlayout = go.Layout(title=\"Weekday sales\", title_x=0.5)\n\nfig = go.Figure(data=data, layout=layout)\n\nfig.show()\n","1b265d30":"day_sales = df_cleaned.groupby('Day')['TotalPrice'].sum().sort_index(ascending=True)\n\ndata = [go.Bar(x=day_sales.index, \n               y=day_sales.values)]\n\nlayout = go.Layout(title=\"Day of the month sales\", title_x=0.5)\n\nfig = go.Figure(data=data, layout=layout)\n\nfig.show()\n","f43ec208":"<br><br>\n<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\n     <b>  I used the same process for the design and category. We can see that there are several kind of collections in there. I don't know if this feature will be useful but it wouldn't hurt keeping it for later, especially for the future dashboard. <\/b><br><br>\n<\/div>","0e98fae4":"<br><br>\n<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\n     <b> I've now landed on the fun and last part of this notebook. I'll use my labeled data in order to train classifiers and validate results on it. Once this is done, I'll simply choose the best classifiers and predict labels for the test data. This was the plan but it didn't go that smoothly. <\/b><br><br>\n<\/div>","85216030":"<h2 id=\"desc_clean\" style=\"font-family:verdana;\"> \n         2.1 Cleaning the description\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#desc_clean\">\u00b6<\/a>\n\n<\/h2>","507d8a82":"<h1 id=\"clean\" style=\"font-family:verdana;\"> \n    <center>1. Cleaning Data \ud83e\uddf9\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#clean\">\u00b6<\/a>\n    <\/center>\n<\/h1>","b47ae971":"<h2 id=\"prod_sells\" style=\"font-family:verdana;\"> \n         6.4 Most sold products\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#prod_sells\">\u00b6<\/a>\n\n<\/h2>","52e76536":"<br><br>\n<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\n     <b> In this dataset, there are several specific transactions which aren't products. For example, we can have a line with 'Discount' as a description. This probably means that the customer had a discount during his purchase. Before deleting lines that aren't product, I'll create 2 features : discount and postage in which I'll store different discounts and postage customers had.<\/b><br><br>\n<\/div>","3b5ba8e3":"<h1 id=\"sup_learn\" style=\"font-family:verdana;\"> \n    <center>5. Supervised Learning \n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#sup_learn\">\u00b6<\/a>\n    <\/center>\n<\/h1>","6ac41b17":"<h2 id=\"countries\" style=\"font-family:verdana;\"> \n         6.3 Customers' Segments\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#countries\">\u00b6<\/a>\n\n<\/h2>","91721bbb":"<h2 id=\"prod_color\" style=\"font-family:verdana;\"> \n         2.2 Product's color \ud83c\udf08\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#prod_color\">\u00b6<\/a>\n\n<\/h2>","2366ff94":"<br><br>\n<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\n     <b>Since duplicates values aren't following one another in the dataset, I could think that the customer added the same product in his basket several times without updating the quantity. The choice is here also hard to make. But, by trying this experiment on a few websites, it seems that the quantity is always updated when you add the same product. So I'll consider them as duplicates even though this data is from 2010.<\/b><br><br>\n<\/div>","90907754":"***","9b6e8a2a":"<h1 id=\"Feature_engin\" style=\"font-family:verdana;\"> \n    <center>3. Feature Engineering\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#Feature_engin\">\u00b6<\/a>\n    <\/center>\n<\/h1>","4680ff85":"<h2 id=\"feature_prep\" style=\"font-family:verdana;\"> \n         5.1 Preparing my features\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#feature_prep\">\u00b6<\/a>\n\n<\/h2>","c07e16b8":"<h1 id=\"products_tag\" style=\"font-family:verdana;\"> \n    <center>2. Product Tagging \ud83c\udfea\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#products_tag\">\u00b6<\/a>\n    <\/center>\n<\/h1>","1bbd44ff":"***","aa046e72":"<h2 id=\"canceled\" style=\"font-family:verdana;\"> \n         1.4 Canceled Orders\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#canceled\">\u00b6<\/a>\n\n<\/h2>","6c6859d5":"***","049d37f0":"***","07ecc0ae":"***","adfb51dd":"<h1 style=\"font-family:verdana;\"> <center> Customer Segmentation on Online Retail V2 and Data Visualization with Plotly <\/center> <\/h1>\n\n\n***","91564e34":"<h1 id=\"data_vis\" style=\"font-family:verdana;\"> \n    <center>6. Data Visualization with Dash for Jupyter\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#data_vis\">\u00b6<\/a>\n    <\/center>\n<\/h1>","db27671e":"<br><br>\n<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\n     <b>   I decided that I had too many categories and wanted to squeeze them into 10 new labels. <\/b><br><br>\n<\/div>","7e42ee3f":"<br><br>\n<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\n    <b> This online e-commerce platform has expended through the years internationally. It would be interesting to see how they're doing today.  <\/b><br><br>\n<\/div>","51934301":"<h2 id=\"model_train\" style=\"font-family:verdana;\"> \n         5.2 Training models and comparing performance\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#model_train\">\u00b6<\/a>\n\n<\/h2>","e8e5494d":"<br><br>\n<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\n    <b> This graph clearly shows that seasonality and especially Christmas has a massive impact on sales. In both 2010 and 2011 sells are growing from august to december <\/b><br><br>\n<\/div>","9e2ee067":"***","e28c3fd0":"<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\"> 2 years after working on the \"Online Retail Dataset\" I wanted to come back to this project and see if I could push it further and make the best out of this data. <span style=\"color:green;\"> Luckily <\/span> for me, a V2 of the dataset emerged and we now have the 2009 data. More data equals more fun so let's give it a try. \n    \n<div style=\"font-size:15px; font-family:verdana;\"> This new project will be in divided in 3 parts: <br><br>\n    \n<ol>\n    <li>Data cleaning <\/li>\n    <li>Product Tagging <\/li>\n    <li>Feature Engineering <\/li>\n    <li>Customer Segmentation <\/li>\n    <li>Training a supervised model on customer categories <\/li>\n    <li><span style=\"color:green;\">Data visualization with dash for jupyter <\/span><\/li>\n     \n<\/ol>\n\n<\/div>\n\n<br>\n    \n<br><br>\n","c120ab4a":"<br><br>\n<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\n    <b> This score was predictable since I created my segments on RFM Score only and xgboost can easily recreate segments I've done. In a real context this model would be useful to speed up customer segmentation but here itsn't that useful. The positive aspect of it is that we tested it on new customers in the last 2 months with limited number of transactions. This means that we can classify customers with only a few transactions which is quite powerful. <\/b><br><br>\n<\/div>","74f812fd":"<h3 id=\"prod_cat_man\" style=\"font-family:verdana;\"> \n         2.4.1 Semi manually tagging products\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#prod_cat_man\">\u00b6<\/a>\n\n<\/h3>","bf7c0212":"<h2 id=\"dupplicates\" style=\"font-family:verdana;\"> \n         1.3 Stock Code\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#dupplicates\">\u00b6<\/a>\n\n<\/h2>","d9bd0b92":"<br><br>\n<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\n    <b> Here, I decided to separate my data in train data and test data. My test data will be new customers in the 2 last months of this dataset. Train data will be the remaining customers. <\/b><br><br>\n<\/div>","c01e247c":"<h2 id=\"prod_exp\" style=\"font-family:verdana;\"> \n         3.4 Product categories expenses \n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#prod_exp\">\u00b6<\/a>\n\n<\/h2>","9f01484e":"<h2 id=\"time_features\" style=\"font-family:verdana;\"> \n         3.2 Time Features\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/time_features\">\u00b6<\/a>\n\n<\/h2>","474af036":"<br><br>\n<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\n     <b>  To extract colors I basically made a list of colors and wrote a function which will iterate in the dataframe, and each product description will be divided in words. And, if we find one of the colors in the product description we put it in a list. This feature could be very interesting because we could know if a customer has a favourite color which could lead to personalized marketing campaigns for the company. <\/b><br><br>\n<\/div>","b51223fc":"<br><br>\n<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\n     <b>  From this graph, I decided to make 3 different features out of the product description : color, category and design. I'll group several thing in design since it would like product caracteristics. For example, \"Retrospot\", \"Vintage\", \"Feltcraft\", ...\n    And in categories we'll have something like \"Cake\", \"Christmas\", \"Bottle\", ...\n         I also took a look at bi-grams even though I didn't put it in this notebook. <\/b> <br><br>\n<\/div>","e7d4df86":"<h2 id=\"total_price\" style=\"font-family:verdana;\"> \n         3.1 Total Price\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/total_price\">\u00b6<\/a>\n\n<\/h2>","386a7797":"<br><br>\n<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\n    <b> The work done on product categories doesn't seem to be very representative of the real sells, I'll rework this part in a new version. <\/b><br><br>\n<\/div>","cdd6517e":"<h2 id=\"prod_cat\" style=\"font-family:verdana;\"> \n         2.4 Product's category\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#prod_cat\">\u00b6<\/a>\n\n<\/h2>","f58138f7":"<br><br>\n<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\n     <b>  I'll take this opportunity to try a new nlp library I recently discovered : TextHero in order to clean my data. It is pretty convenient since with one line of code I can do several processing functions like lower_case, removing strop words, lemmatization, ... <\/b> <br><br>\n    \n<\/div>","e7aabfb2":"***","fd8388d2":"<h3 id=\"prod_cat_auto\" style=\"font-family:verdana;\"> \n         2.4.2 Training classification algorithms \n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#prod_cat_auto\">\u00b6<\/a>\n\n<\/h3>","e7c41fb5":"<br><br>\n<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\n     <b> We can't have more quantities canceled than bought initially. I'm deleting these lines. <\/b><br><br>\n<\/div>","8dcfe695":"<h1 id=\"cust_segm\" style=\"font-family:verdana;\"> \n    <center>4. Custumer Segmentation\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#cust_segm\">\u00b6<\/a>\n    <\/center>\n<\/h1>","7536ec32":"<br><br>\n<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\n    <b> It seems that our segment categories can be improved. As I said earlier this should be done in partnership with the marketing team. For example, the segment \"Not So Good Customers\" seems to have better sells than the average customers. The problem seems to be in december 2010 because there was a massive decrease in sells this month. We also have a good representation of the segment \"Best customers\" since they have the biggest sales. Lastly, we can see graphically why we labeled these categories \"almost lost\" and \"lost customers\"  <\/b><br><br>\n<\/div>","bdd5738b":"<h2 id=\"rfm\" style=\"font-family:verdana;\"> \n         3.3 RFM Principle\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#rfm**\">\u00b6<\/a>\n\n<\/h2>","2d89e4f9":"<br><br>\n<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\n    <b> When you're working on a profesional project, this step should be done in close collaboration with the client (or the marketing team) <\/b><br><br>\n<\/div>","ddfbd4da":"<br><br>\n<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\n     <b>  From here, I took it on excel. I renamed and grouped categories into labels in order to have something more reliable for the classifiers later on. <\/b><br><br>\n    \n<\/div>","5a6067dc":"<br><br>\n<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\n     <b> One last finishing touch and we're done. With this semi-manual work almost 60% of the data is tagged which should give us enough data for the next step <\/b><br><br>\n<\/div>","52e14436":"<h2 id=\"prod_des\" style=\"font-family:verdana;\"> \n         2.3 Product's design\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#prod_des\">\u00b6<\/a>\n\n<\/h2>","9e2201e8":"***","a5bce449":"<h2 id=\"sales\" style=\"font-family:verdana;\"> \n         6.1 Total Sales\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#sales\">\u00b6<\/a>\n\n<\/h2>","04ae1a16":"<h2 id=\"duplicates\" style=\"font-family:verdana;\"> \n         1.2 Duplicate values\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#duplicates\">\u00b6<\/a>\n\n<\/h2>","14077b4a":"<h2 id=\"time_graphs\" style=\"font-family:verdana;\"> \n         6.5 Time Features\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#time_graphs\">\u00b6<\/a>\n\n<\/h2>","6daaaeca":"<h2 id=\"countries\" style=\"font-family:verdana;\"> \n         6.2 Customers through the world map\n        <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#countries\">\u00b6<\/a>\n\n<\/h2>","68cd4f6f":"<br><br>\n<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\n     <b> We could have better results by tuning some parameterers but for now I'm going to keep it that way and come back to it later. <\/b><br><br>\n<\/div>","8ea97475":"<p style=\"font-size:15px; font-family:verdana; line-height: 1.7em\"> After an exploratory analysis of the dataset, it appears that <span style=\"color:crimson;\"> 22% <\/span>of the customer ids are missing which is very problematic since I want to do a <span style=\"color:crimson;\"> Customer <\/span> Segmentation later. I've tried looking at the invoice number or date without success. It's a shame that we have to lose 22% of the data but we don't have a choice.","860f124f":"<br><br>\n<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\n    <b> I really can't believe that there's a day in the week where sells are dropping that drastically. It must be an error. <\/b><br><br>\n<\/div>","e3f48d11":"<center style=\"font-family:cursive; font-size:18px; color:#159364;\">This is a work in progress, feel free to suggest any graphics that you would like to see. <br>I'm going to add more visualizations and then create a dashboard that I'll share with you.<br> Thank you for taking your time to read my notebook \ud83d\ude4f <\/center>","ad146741":"<br><br>\n<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\n    <b> Let's clean the outliers real quick. I'll delete transactions which are 10 times greater than usual. <\/b><br><br>\n<\/div>","49a6bd4b":"<br><br>\n<div class=\"alert alert-block alert-info\" style=\"font-size:15px; font-family:verdana; line-height: 1.7em\">\n    <b> This graph would be much more interesting if I could do it in Dash since we could select whatever product we're interested into and see its sells through the year. I'll incorporate it in my future dashboard. The main information we can drive from this graph is that we shouldn't keep the following products in the database \"Paper craft\" and \"Storage Jar\" since there are so much canceled ordrers. <\/b><br><br>\n<\/div>","32b62399":"> <h2 id=\"missing\" style=\"font-family:verdana;\"> \n>          1.1 Missing data \ud83d\udc7b\n>         <a class=\"anchor-link\" href=\"https:\/\/www.kaggle.com\/miljan\/product-tagging-for-e-commerce-work-in-progress\/#missing\">\u00b6<\/a>\n> \n<\/h2>"}}