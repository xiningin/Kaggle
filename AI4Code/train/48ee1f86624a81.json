{"cell_type":{"6a1b63ec":"code","1107d19d":"code","27fa57b3":"code","bd85efca":"code","cc9744da":"code","b275d083":"code","5da0c147":"code","d3dafda0":"code","7396a86b":"code","c0a8e9b2":"code","02f04cfd":"code","914640de":"code","f858fc6f":"code","9759f806":"code","3dfb4279":"code","2e14bb41":"markdown","083cd6c5":"markdown","b9c0f3b3":"markdown","d5754ffb":"markdown"},"source":{"6a1b63ec":"! pip install nb_black -q","1107d19d":"%load_ext nb_black","27fa57b3":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set(style=\"ticks\", color_codes=True)","bd85efca":"data = pd.read_csv(\"..\/input\/yelp-reviews-dataset\/yelp.csv\")\ndata[\"length\"] = data.text.apply(len)\ndata.drop([\"business_id\", \"review_id\", \"user_id\", \"type\"], axis=1, inplace=True)\ndata.head()","cc9744da":"data.describe()","b275d083":"data.info()","5da0c147":"sns.countplot(y=\"stars\", data=data)\nplt.title(\"Counting by stars\")","d3dafda0":"g = sns.FacetGrid(data=data, col=\"stars\", col_wrap=5)\ng.fig.suptitle(\"Dists by stars\")\ng.map(plt.hist, \"length\", bins=10)\n","7396a86b":"filter_bad_good = data.stars.isin([1, 5])\ndata_bad_good = data[filter_bad_good]","c0a8e9b2":"sns.countplot(data_bad_good[\"stars\"])\nplt.title(\"Count by stars again...\")","02f04cfd":"import string\nfrom nltk.corpus import stopwords\nimport nltk\n\nstemmer = nltk.RSLPStemmer()\nstopwords = list(stopwords.words(\"english\"))\npunctuation = [word for word in string.punctuation]\npunctuation += ['...', '  ', '\\n']\n\n\n\ndef remove_punctuation(serie, stopwords):\n    aux = list()\n    for el in serie:\n        for word in stopwords:\n            el = el.replace(word,' ')\n        aux.append(el)\n    return aux\n\ndef remove_stopwords(serie, stopwords):\n    tokenizer = nltk.WordPunctTokenizer()\n\n    result_serie= list()\n    for row in serie:\n        aux = list()\n        text_row = tokenizer.tokenize(row.lower())\n        for word in text_row:\n            if word not in stopwords: # stopwords\n                aux.append(word)\n        result_serie.append(' '.join(aux))\n    return result_serie\n","914640de":"data_bad_good.text = data_bad_good.text.str.lower()\ndata_bad_good.text = remove_stopwords(data_bad_good.text, punctuation)\ndata_bad_good.text = remove_stopwords(data_bad_good.text, stopwords)","f858fc6f":"from sklearn.feature_extraction.text import CountVectorizer\n\nvectorize = CountVectorizer()\n\nX = vectorize.fit_transform(data_bad_good.text)\nY = data_bad_good.stars.map({5: 1, 1: 0}).values\nprint(\"How many features (bag of words): \", len(vectorize.get_feature_names()))","9759f806":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, Y, test_size=0.2, random_state=42\n)\n\nmodel = MultinomialNB()\n\nmodel.fit(X_train, y_train)\n\n\n# Let's see the results\npredictions = model.predict(X_test)\naccuracy = accuracy_score(y_test, predictions) * 100\nprint(\"The accuracy was %.2f%%\" % accuracy)","3dfb4279":"from sklearn.metrics import confusion_matrix\n\nm_c = confusion_matrix(y_test, predictions)\nplt.figure(figsize=(5, 4))\nsns.heatmap(m_c, annot=True, cmap=\"Reds\", fmt=\"d\").set(xlabel=\"Predict\", ylabel=\"Real\")","2e14bb41":"# Importing libs and dataset","083cd6c5":"# NLP before Machine Learning","b9c0f3b3":"# Machine Learning","d5754ffb":"Transforming our dataset"}}