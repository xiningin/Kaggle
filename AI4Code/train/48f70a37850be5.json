{"cell_type":{"7e467bc1":"code","64d4eb78":"code","1f08dc03":"code","1f27b8fa":"code","d77cce27":"code","5855360d":"code","e6cfad5f":"code","97909f39":"code","9049530a":"code","105f6198":"code","4ca14597":"code","819be57e":"code","7a6dd984":"code","01cfde3d":"code","135662c0":"code","df6be6eb":"code","ef9fb783":"code","229c88f6":"code","f1c7eba7":"code","d0767899":"code","85dc2553":"code","63a68351":"code","90f8b6e4":"code","abd8bb56":"code","1829c87b":"code","f36f7ed3":"code","f9820415":"code","41a5e46d":"code","da34732e":"code","8ba4a5ee":"code","f79063ce":"code","f16c8f34":"code","622f7ede":"code","98b2dc91":"code","2742651e":"code","00f9f547":"code","fdd980e2":"code","4f160657":"code","22a58956":"code","cdae25dc":"code","93afe89c":"markdown","709a0836":"markdown","ae941c76":"markdown","434573f4":"markdown","0e1adcb6":"markdown","8506294e":"markdown"},"source":{"7e467bc1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","64d4eb78":"import matplotlib.pyplot as plt\nfrom copy import copy\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nfrom sklearn.preprocessing import MinMaxScaler\nimport plotly.offline as py\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n","1f08dc03":"!pip install jupyterthemes","1f27b8fa":"from jupyterthemes import jtplot\njtplot.style(theme=\"monokai\", context=\"notebook\",ticks=True,grid=False)","d77cce27":"df = pd.read_csv(\"..\/input\/global-land-temperatures-by-country\/GlobalLandTemperaturesByCountry.csv\")\ndf.head()","5855360d":"df.info()\n# we see that 577462 rows and 4 columns in our dataset\n# 2 of columns have numerical values while two of them have non-numerical values","e6cfad5f":"df[\"Country\"].nunique()\n#It seems there 243 countries in the dataset","97909f39":"df.isnull().sum()\n# It seems we have missing data in two columns","9049530a":"df.describe()\n# we get overall statistical information about the dataset","105f6198":"df[df[\"AverageTemperature\"] > 36]","4ca14597":"country_group= df.groupby(by=\"Country\").count().reset_index()\ncountry_group.sort_values(by=\"AverageTemperature\",ascending=False)","819be57e":"fig=px.bar(country_group, x=\"Country\",y=\"AverageTemperature\")\nfig.show()","7a6dd984":"fig=px.bar(country_group, x=\"Country\",y=\"AverageTemperatureUncertainty\")\nfig.show()","01cfde3d":"px.histogram(country_group,x=\"AverageTemperature\")","135662c0":"#Because missing data, we can not have a good distribution, lets ignore countries that has lwer than 1500 average temperature\ncountry_group[country_group[\"AverageTemperature\"]> 1500]","df6be6eb":"px.histogram(country_group[country_group[\"AverageTemperature\"]> 1500],x=\"AverageTemperature\")","ef9fb783":"df[\"AverageTemperature\"].fillna(df[\"AverageTemperature\"].mean(),inplace=True)\ndf[\"AverageTemperatureUncertainty\"].fillna(df[\"AverageTemperatureUncertainty\"].mean(),inplace=True)\ndf.isnull().sum()","229c88f6":"df[\"Country\"].unique()\n#Here we see that some countries are dublicated with an extra parantheses in order to refer them they are in Europe\n# We need to get rid of them","f1c7eba7":"duplicates=list()\nfor i in df[\"Country\"].unique():\n    if \"(\" in i:\n        duplicates.append(i)\nduplicates","d0767899":"df=df.replace(duplicates,[\"Congo\",\"Denmark\",\"Falkland Islands\",\"France\",\"Netherlands\",\"United Kingdom\"])\n                            \ndf[\"Country\"].unique() \n#Now our data is without duplicates","85dc2553":"countries = df[\"Country\"].unique().tolist()\ncountries[:3]","63a68351":"mean_temperatures = list()\nfor i in countries:\n    mean_temperatures.append(df[df[\"Country\"]==i][\"AverageTemperature\"].mean())\nmean_temperatures[:3]","90f8b6e4":"#Lets visualize average temperatures by Country in the world map:\ndata = [dict(type =\"choropleth\",\n       locations = countries,\n       z = mean_temperatures,\n       locationmode = \"country names\")]\n\nlayout = dict(title = \"Average Global Country Temperatures\",\n             geo = dict(showframe = False,\n                       showocean = True,\n                        oceancolor = \"aqua\",\n                         projection = dict(type = \"orthographic\")))\nfig = dict(data = data, layout=layout)\npy.iplot(fig, validate = False, filename = \"worldmap\")","abd8bb56":"#Lets creat a new visualization that shows global temperature change within a animation:\ndf[\"Year\"] = df[\"dt\"].apply(lambda x : x.split(\"-\")[0]) #We create a new column for years, because we will animate it by year\ndf.head()","1829c87b":"# we will use plotly express fro this animation\nfig = px.choropleth(data_frame = df,\n                   locations = \"Country\",\n                   locationmode = \"country names\",\n                   color = \"AverageTemperature\",\n                   hover_name = \"Country\",\n                   animation_frame = \"Year\",\n                   color_continuous_scale = px.colors.sequential.OrRd)\nfig.show()","f36f7ed3":"df_global = df.groupby(\"Year\").mean().reset_index()\ndf_global# Here we group data by Year and create a new data frame which takes care of the mean of everything according to the groups","f9820415":"#Because we have a lot of missing data before 1850, we will get rid of the data before 1850\ndf_global[\"Year\"] = df_global[\"Year\"].apply(lambda x : int(x))\ndf_global = df_global[df_global[\"Year\"] >= 1850]\ndf_global.head()","41a5e46d":"data = go.Scatter(x=df_global[\"Year\"],\n                  y=df_global[\"AverageTemperature\"],\n                  name=\"Average Temperature\",\n                line = dict(color=\"red\"))\nlayout = go.Layout(xaxis = dict(title=\"Year\"),\n                   yaxis = dict(title =\"Average Temperature in Celcius\"),\n                   title = \"Global Avreage Temperature Since 1850\",\n                  showlegend=False)\nfig = go.Figure(data=data,layout = layout)\npy.iplot(fig)\n#As we can see there is a significant increase in global climate","da34732e":"# we will visualize a specific country\nnorway_df = df[df[\"Country\"]== \"Norway\"].reset_index(drop=True)\nnorway_df","8ba4a5ee":"fig = px.line(title = \"Norway Temperature Data\")\nfig.add_scatter(x = norway_df[\"Year\"], y = norway_df[\"AverageTemperature\"], name = \"Norway Temperature Over Years\")\nfig.show()","f79063ce":"df_global.head() # we will look at the data within a global scale","f16c8f34":"series = df_global[\"AverageTemperature\"].values\ntime = df_global[\"Year\"].values\nplt.figure(figsize=(20, 15))\nplt.plot(time, series)\nplt.xlabel(\"Time\")\nplt.ylabel(\"Value\")\nplt.grid(True)","622f7ede":"#Forecasts the mean of the last few values.If window_size=1, then this is equivalent to naive forecast\"\"\"\ndef moving_average_forecast(series, window_size):\n    forecast = []\n    for time in range(len(series) - window_size):\n        forecast.append(series[time:time + window_size].mean())\n    return np.array(forecast)","98b2dc91":"split_time =150 \ntime_train = time[:split_time]\nseries_train = series[:split_time]\ntime_test = time[split_time:]\nseries_test = series[split_time:]\nmoving_avg = moving_average_forecast(series, 1)[split_time - 1:]\n\nplt.figure(figsize=(15, 10))\nplt.plot(time_test, series_test)\nplt.xlabel(\"Time\")\nplt.ylabel(\"Value\")\n\nplt.figure(figsize=(15, 10))\nplt.plot(time_test, moving_avg)\nplt.xlabel(\"Time\")\nplt.ylabel(\"Value\")\n","2742651e":"import tensorflow\nprint(tensorflow.keras.metrics.mean_squared_error(series_test, moving_avg).numpy())\nprint(tensorflow.keras.metrics.mean_absolute_error(series_test, moving_avg).numpy())\n#The results are good","00f9f547":"df_global","fdd980e2":"series = df[\"AverageTemperature\"]\ntime = df[\"Year\"].values\nwindow_size = 1\nbatch_size = 10","4f160657":"import tensorflow as tf\ndef windowed_dataset(series, window_size, batch_size):\n    series = tf.expand_dims(series, axis=-1)\n    ds = tf.data.Dataset.from_tensor_slices(series)\n    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n    ds = ds.map(lambda w: (w[:-1], w[1:]))\n    return ds.batch(batch_size).prefetch(1)","22a58956":"window_size = 1\nbatch_size = 10\ntrain_set = windowed_dataset(time_train, window_size, batch_size)\nprint(train_set)\nprint(time_train.shape)\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Conv1D(filters=32, kernel_size=5,\n                      strides=1, padding=\"causal\",\n                      activation=\"relu\",\n                      input_shape=[None, 1]),\n  tf.keras.layers.LSTM(64, return_sequences=True),\n  tf.keras.layers.LSTM(64, return_sequences=True),\n  tf.keras.layers.Dense(30, activation=\"relu\"),\n  tf.keras.layers.Dense(10, activation=\"relu\"),\n  tf.keras.layers.Dense(1),\n  tf.keras.layers.Lambda(lambda x: x * 400)\n])\n\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(\n    lambda epoch: 1e-8 * 10**(epoch \/ 20))\noptimizer = tf.keras.optimizers.SGD(lr=1e-8, momentum=0.9)\nmodel.compile(loss=tf.keras.losses.Huber(),\n              optimizer=optimizer,\n              metrics=[\"mae\"])\nhistory = model.fit(train_set, epochs=100, callbacks=[lr_schedule])","cdae25dc":"pd.DataFrame(model.history.history).plot()","93afe89c":"## 1. Exploratory Data Analysis:","709a0836":"## 2.  Data Cleaning and Feature Engineering:","ae941c76":"<font colot = \"blue\">\nIn statistics, a moving average is a calculation used to analyze data points by creating a series of averages of different subsets of the full data set. In finance, a moving average (MA) is a stock indicator that is commonly used in technical analysis. The reason for calculating the moving average of a stock is to help smooth out the price data by creating a constantly updated average price.","434573f4":"## 4. Moving Average Method:","0e1adcb6":"## 3. Data Visualization:","8506294e":"## 5. Deep Neural Networks for Time Series"}}