{"cell_type":{"2c14189d":"code","0ee8d439":"code","d0977ee6":"code","2bd87d0b":"code","c56d2fc3":"code","df0da447":"code","b343ac2a":"code","b523547d":"code","739479cd":"code","5a71ff35":"code","3e5da082":"code","c540e2f7":"code","3da3172f":"code","10886a10":"code","22d591e8":"code","7b729fbb":"code","175fe5d5":"code","aad881a1":"code","ff0f038c":"code","4b6f3b43":"code","eb2b76e2":"code","7b1ec1c7":"code","b84921e2":"code","50374958":"code","1d7e2bc7":"markdown"},"source":{"2c14189d":"import gc\nimport os\nimport random\nimport time\n\nimport category_encoders as ce\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.base import clone\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold\nfrom tqdm import tqdm\nfrom xgboost import XGBClassifier","0ee8d439":"SEED = 42\nrandom.seed(SEED)\nos.environ['PYTHONHASHSEED'] = str(SEED)\nnp.random.seed(SEED)","d0977ee6":"input_dir = '..\/input\/fraud-data\/fraud_data.h5'","2bd87d0b":"train = pd.read_hdf(input_dir, key='train')\ntest = pd.read_hdf(input_dir, key='test')","c56d2fc3":"train.shape","df0da447":"test.shape","b343ac2a":"ntrain = train.shape[0]\nntest = test.shape[0]","b523547d":"X = train.drop('isFraud', axis=1)\ny = train['isFraud'].copy()\ndel train\ngc.collect()","739479cd":"train_test = pd.concat((X, test), sort=False)\ndel X, test\ngc.collect()","5a71ff35":"cat_fea = ['ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6',\n           'addr1', 'addr2', 'P_emaildomain', 'R_emaildomain',\n           'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9',\n           'DeviceType', 'DeviceInfo'] + ['id_' + str(i) for i in range(12, 39)]","3e5da082":"gc.collect()","c540e2f7":"train_test = train_test[cat_fea]\ngc.collect()","3da3172f":"for col in tqdm(train_test.columns):\n    if train_test[col].dtype == 'float64':\n        train_test[col] = train_test[col].astype(np.float32)\n    if (train_test[col].dtype == 'int64'):\n        train_test[col] = train_test[col].astype(np.int32)","10886a10":"gc.collect()","22d591e8":"train_test.shape","7b729fbb":"val_set = train_test.iloc[ntrain - int(0.2 * ntrain):ntrain, :].index\n\nX_train = train_test.iloc[:ntrain, :]\nX_test = train_test.iloc[ntrain:, :]\n\nX_train_sub = X_train[~X_train.index.isin(val_set)]\ny_train = y[~y.index.isin(val_set)]\n\nX_val = X_train[X_train.index.isin(val_set)]\ny_val = y[y.index.isin(val_set)]\n\ndel val_set\ngc.collect()","175fe5d5":"def none_validation(encoder, X, y, X_test, epochs):\n    cv = KFold(n_splits=epochs, shuffle=True, random_state=SEED)\n\n    loc_encoder = clone(encoder)\n    loc_encoder.fit(X, y)\n    \n    X_test_enc = loc_encoder.transform(X_test)\n    X_enc = loc_encoder.transform(X)\n    for tr_idx, val_idx in cv.split(X_enc, y.values): \n        X_tr, X_vl = X_enc[tr_idx], X_enc[val_idx]\n        y_tr, y_vl = y.values[tr_idx], y.values[val_idx]\n        \n        yield X_tr, y_tr, X_vl, y_vl, X_test_enc\n        \n        del X_tr, X_vl, y_tr, y_vl, tr_idx, val_idx\n        gc.collect()\n        \n    del loc_encoder, X_enc, X_test_enc\n    gc.collect()\n\n\ndef single_validation(encoder, X, y, X_test, epochs):\n    cv = KFold(n_splits=epochs, shuffle=True, random_state=SEED)\n\n    for tr_idx, val_idx in cv.split(X.values, y.values): \n        X_tr, X_vl = X.values[tr_idx], X.values[val_idx]\n        y_tr, y_vl = y.values[tr_idx], y.values[val_idx]\n\n        loc_encoder = clone(encoder)\n        loc_encoder.fit(X_tr, y_tr)\n        \n        yield loc_encoder.transform(X_tr), y_tr, loc_encoder.transform(X_vl), y_vl, loc_encoder.transform(X_test.values)\n        \n        del loc_encoder, X_tr, X_vl, y_tr, y_vl\n        gc.collect()\n        \n        \ndef double_validation(encoder, X, y, X_test, epochs):\n    cv = KFold(n_splits=epochs, shuffle=True, random_state=SEED)\n\n    for tr_idx, val_idx in cv.split(X.values, y.values): \n        X_tr, X_vl = X.values[tr_idx], X.values[val_idx]\n        y_tr, y_vl = y.values[tr_idx], y.values[val_idx]\n        \n        X_tr_enc = np.zeros(X_tr.shape)\n        X_vl_enc = np.zeros(X_vl.shape)\n        X_test_enc = np.zeros(X_test.shape)\n        \n        for sub_tr_idx, sub_val_idx in cv.split(X_tr, y_tr): \n            \n            sub_X_tr, sub_X_vl = X_tr[sub_tr_idx], X_tr[sub_val_idx]\n            sub_y_tr, sub_y_vl = y_tr[sub_tr_idx], y_tr[sub_val_idx]\n                        \n            loc_encoder = clone(encoder)\n            loc_encoder.fit_transform(sub_X_tr, sub_y_tr)\n                                                        \n            _X_test_enc = loc_encoder.transform(X_test.values)            \n            if X_test_enc is None:\n                X_test_enc = np.zeros(_X_test_enc.shape)\n            X_test_enc += _X_test_enc\n            \n            _X_vl_enc = loc_encoder.transform(X_vl)            \n            if X_vl_enc is None:\n                X_vl_enc = np.zeros(_X_vl_enc.shape)\n            X_vl_enc += _X_vl_enc     \n            \n            X_tr_enc[sub_val_idx] += loc_encoder.transform(sub_X_vl)\n            \n            del loc_encoder, sub_tr_idx, sub_val_idx, sub_X_tr, sub_X_vl,sub_y_tr, sub_y_vl, _X_test_enc, _X_vl_enc\n            gc.collect()\n        \n        yield X_tr_enc, y_tr, X_vl_enc \/ epochs, y_vl, X_test_enc \/ epochs\n        \n        del X_tr, X_vl, y_tr, y_vl, X_tr_enc, X_vl_enc, X_test_enc, tr_idx, val_idx\n        gc.collect()\n\n    \ndef get_solution(X_train, y_train, X_test, encoder, validation, verbose=False):  \n    def solution(params):\n        EPOCHS = params['folds']        \n        y_preds = np.zeros(X_test.shape[0])\n       \n        for bag, (X_tr, y_tr, X_vl, y_vl, X_test_enc) in enumerate(validation(encoder, X_train, y_train, X_test, EPOCHS)): \n            model = XGBClassifier(**params)                             \n            model.fit(X_tr, y_tr)\n\n            if verbose:                    \n                y_pred_train = model.predict_proba(X_vl)[:,1]\n                print('[{}] ROC AUC {}'.format(bag + 1, roc_auc_score(y_vl, y_pred_train)))\n                del y_pred_train\n\n            del X_tr, X_vl, y_tr, y_vl\n            gc.collect()\n\n            y_preds += model.predict_proba(X_test_enc)[:,1]\n            del model, X_test_enc\n            gc.collect()  \n\n        return y_preds \/ EPOCHS\n    \n    return solution","aad881a1":"single_val_encoders = [    \n    ce.CatBoostEncoder(return_df=False, handle_unknown='return_nan', handle_missing='return_nan', random_state=SEED),\n    ce.JamesSteinEncoder(return_df=False, handle_unknown='return_nan', handle_missing='return_nan', random_state=SEED),\n    ce.LeaveOneOutEncoder(return_df=False, handle_unknown='return_nan', handle_missing='return_nan', random_state=SEED),\n    ce.MEstimateEncoder(return_df=False, handle_unknown='return_nan', handle_missing='return_nan', random_state=SEED),\n    ce.OrdinalEncoder(return_df=False, handle_unknown='return_nan', handle_missing='return_nan'),\n    ce.TargetEncoder(return_df=False, handle_unknown='return_nan', handle_missing='return_nan'),\n    ce.WOEEncoder(return_df=False, handle_unknown='return_nan', handle_missing='return_nan', random_state=SEED)\n]\n\nmulti_val_encoders = [\n#     ce.BackwardDifferenceEncoder(return_df=False, handle_unknown='return_nan', handle_missing='return_nan'),\n#     ce.BaseNEncoder(return_df=False, handle_unknown='return_nan', handle_missing='return_nan'),\n    ce.BinaryEncoder(return_df=False, handle_unknown='return_nan', handle_missing='return_nan'),\n    ce.HashingEncoder(return_df=False),\n#     ce.HelmertEncoder(return_df=False, handle_unknown='return_nan', handle_missing='return_nan'),\n#     ce.OneHotEncoder(return_df=False, handle_unknown='return_nan', handle_missing='return_nan'),\n#     ce.SumEncoder(return_df=False, handle_unknown='return_nan', handle_missing='return_nan'),\n#     ce.PolynomialEncoder(return_df=False, handle_unknown='return_nan', handle_missing='return_nan')\n]\n\nencoders = single_val_encoders + multi_val_encoders","ff0f038c":"scores = pd.DataFrame(columns=['None Validation', 'Single Validation', 'Double Validation'])","4b6f3b43":"params = {\n    'folds': 3,\n    'n_estimators': 500,\n    'max_depth': 9,\n    'learning_rate': 0.05,        \n    'tree_method': 'gpu_hist',\n    'random_state': SEED\n}","eb2b76e2":"for enc in encoders:\n    \n    start = time.perf_counter()\n    \n    y_val_pred = get_solution(X_train_sub, y_train, X_val, encoder=enc, validation=none_validation, verbose=True)(params)\n\n    print(enc.__class__.__name__, roc_auc_score(y_val, y_val_pred), time.perf_counter() - start)   \n    scores.loc[enc.__class__.__name__, 'None Validation'] = roc_auc_score(y_val, y_val_pred)","7b1ec1c7":"for enc in encoders:\n    \n    start = time.perf_counter()\n    \n    y_val_pred = get_solution(X_train_sub, y_train, X_val, encoder=enc, validation=single_validation, verbose=True)(params)\n\n    print(enc.__class__.__name__, roc_auc_score(y_val, y_val_pred), time.perf_counter() - start)   \n    scores.loc[enc.__class__.__name__, 'Single Validation'] = roc_auc_score(y_val, y_val_pred)","b84921e2":"for enc in single_val_encoders:\n    \n    start = time.perf_counter()\n    \n    y_val_pred = get_solution(X_train_sub, y_train, X_val, encoder=enc, validation=double_validation, verbose=True)(params)\n\n    print(enc.__class__.__name__, roc_auc_score(y_val, y_val_pred), time.perf_counter() - start)  \n    scores.loc[enc.__class__.__name__, 'Double Validation'] = roc_auc_score(y_val, y_val_pred)","50374958":"scores","1d7e2bc7":"I've created benchmark of different category encoding schemes. Only a few of multi-valued category encoders (e.g. binary encoder) were tried because of exploding features count and memory considerations. The currently obtained results are:\n* single validation scheme is always better than none validation\n* target encoders works best when used in double validation scheme (which is the slowest one unfortunately)\n* weight of evidence, binary encoder and (surprisingly) ordinal encoder were the best one\n* good result of ordinal encoder comes from the fact that the implementation that was used (from category_encoders module) doesn't assign a new numerical values to encoded features when they already contain one; apparently some of the features (e.g. card1, card2) even that are considered as categorical, contais also some numerical information and probably some hidden order (something like bigger card number is newer or similar)"}}