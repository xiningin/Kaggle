{"cell_type":{"91433229":"code","c0dbbce4":"code","553f983c":"code","a572e97f":"code","1ccec54e":"code","8f12b4c9":"code","6bacf0b5":"code","de7950cf":"code","63c2dcd1":"code","36159b00":"code","8e10bb5d":"code","c401f332":"code","9798f5fd":"code","9474d3e7":"code","8e870172":"markdown","f13261f4":"markdown"},"source":{"91433229":"!pip install -qq git+https:\/\/www.github.com\/ildoonet\/tf-pose-estimation","c0dbbce4":"!pip install -qq pycocotools","553f983c":"%load_ext autoreload\n%autoreload 2\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = (8, 8)\nplt.rcParams[\"figure.dpi\"] = 125\nplt.rcParams[\"font.size\"] = 14\nplt.rcParams['font.family'] = ['sans-serif']\nplt.rcParams['font.sans-serif'] = ['DejaVu Sans']\nplt.style.use('ggplot')\nsns.set_style(\"whitegrid\", {'axes.grid': False})","a572e97f":"%matplotlib inline\nimport tf_pose\nimport cv2\nfrom glob import glob\nfrom tqdm import tqdm_notebook\nfrom PIL import Image\nimport numpy as np\nimport os\ndef video_gen(in_path):\n    c_cap = cv2.VideoCapture(in_path)\n    while c_cap.isOpened():\n        ret, frame = c_cap.read()\n        if not ret:\n            break\n        yield c_cap.get(cv2.CAP_PROP_POS_MSEC), frame[:, :, ::-1]\n    c_cap.release()","1ccec54e":"video_paths = glob('..\/input\/mcgregor\/*.mp4')\nc_video = video_gen(video_paths[0])\nfor _ in range(300):\n    c_ts, c_frame = next(c_video)\nplt.imshow(c_frame)","8f12b4c9":"from tf_pose.estimator import TfPoseEstimator\nfrom tf_pose.networks import get_graph_path, model_wh\ntfpe = tf_pose.get_estimator()","6bacf0b5":"humans = tfpe.inference(npimg=c_frame, upsample_size=4.0)\nprint(humans)","de7950cf":"new_image = TfPoseEstimator.draw_humans(c_frame[:, :, ::-1], humans, imgcopy=False)\nfig, ax1 = plt.subplots(1, 1, figsize=(10, 10))\nax1.imshow(new_image[:, :, ::-1])","63c2dcd1":"body_to_dict = lambda c_fig: {'bp_{}_{}'.format(k, vec_name): vec_val \n                              for k, part_vec in c_fig.body_parts.items() \n                              for vec_name, vec_val in zip(['x', 'y', 'score'],\n                                                           (part_vec.x, 1-part_vec.y, part_vec.score))}\nc_fig = humans[0]\nbody_to_dict(c_fig)","36159b00":"MAX_FRAMES = 13000\nbody_pose_list = []\nfor vid_path in tqdm_notebook(video_paths, desc='Files'):\n    c_video = video_gen(vid_path)\n    c_ts, c_frame = next(c_video)\n    out_path = '{}_out.avi'.format(os.path.split(vid_path)[1])\n    out = cv2.VideoWriter(out_path,\n                          cv2.VideoWriter_fourcc('M','J','P','G'),\n                          10, \n                          (c_frame.shape[1], c_frame.shape[0]))\n    for (c_ts, c_frame), _ in zip(c_video, \n                                  tqdm_notebook(range(MAX_FRAMES), desc='Frames')):\n        bgr_frame = c_frame[:,:,::-1]\n        humans = tfpe.inference(npimg=bgr_frame, upsample_size=4.0)\n        for c_body in humans:\n            body_pose_list += [dict(video=out_path, time=c_ts, **body_to_dict(c_body))]\n        new_image = TfPoseEstimator.draw_humans(bgr_frame, humans, imgcopy=False)\n        out.write(new_image)\n    out.release()\n","8e10bb5d":"import pandas as pd\nbody_pose_df = pd.DataFrame(body_pose_list)\nbody_pose_df.describe()","c401f332":"fig, m_axs = plt.subplots(1, 2, figsize=(15, 5))\nfor c_ax, (c_name, c_rows) in zip(m_axs, body_pose_df.groupby('video')):\n    for i in range(17):\n        c_ax.plot(c_rows['time'], c_rows['bp_{}_y'.format(i)], label='x {}'.format(i))\n    c_ax.legend()\n    c_ax.set_title(c_name)","9798f5fd":"fig, m_axs = plt.subplots(1, 2, figsize=(15, 5))\nfor c_ax, (c_name, n_rows) in zip(m_axs, body_pose_df.groupby('video')):\n    for i in range(17):\n        c_rows = n_rows.query('bp_{}_score>0.6'.format(i)) # only keep confident results\n        c_ax.plot(c_rows['bp_{}_x'.format(i)], c_rows['bp_{}_y'.format(i)], label='BP {}'.format(i))\n    c_ax.legend()\n    c_ax.set_title(c_name)","9474d3e7":"body_pose_df.to_csv('body_pose_ufc.csv', index=False)","8e870172":"## Libraries we need\nInstall tf_pose and pycocotools","f13261f4":"# Overview\nThe kernel shows how to use the [tf_pose_estimation](https:\/\/github.com\/ildoonet\/tf-pose-estimation) package in Python on a series of running videos."}}