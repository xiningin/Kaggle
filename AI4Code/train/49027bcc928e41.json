{"cell_type":{"b5cbdbf8":"code","2125fdb5":"code","390cd1f9":"code","a0248fb8":"code","59379a4c":"code","3e9439f4":"code","0b15bcdb":"code","a0379865":"code","cc1eabf5":"code","6947d925":"code","2beda9b3":"code","59562d4c":"code","2cba486a":"code","c47183cf":"markdown","81c377fe":"markdown"},"source":{"b5cbdbf8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2125fdb5":"#Importing important libraries\n\nimport pandas as pd             #library for tabular data\nimport numpy as np              #library for manupulating array\nimport matplotlib.pyplot as plt #library for visualization\nimport matplotlib.image as mpimg\nfrom sklearn.model_selection import train_test_split  #for dividing data into train and validation\n%matplotlib inline\nfrom keras.callbacks import ReduceLROnPlateau,EarlyStopping\n\n#Importing important library for CNN model\nimport keras \nfrom keras.utils.np_utils import to_categorical \nfrom keras.optimizers import RMSprop          # module for optimizers \nfrom keras.preprocessing.image import ImageDataGenerator      # module for image augmentation","390cd1f9":"train=pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\ntrain.head()","a0248fb8":"x=train.iloc[:,1:].values.astype('float32') #values changes it into array \ny=train['label'] \nx.shape","59379a4c":"learning_rate=ReduceLROnPlateau(monitor='val_loss',patience=3,verbose=1,factor=0.5,min_lr=0.0001)\nearlystop=EarlyStopping(monitor='val_loss',patience=87,verbose=1)","3e9439f4":"x=x.reshape(42000,28,28,1) # (28*28*1=784)  #cnn model take array in form of size with color channel  for gray-(150,150,1)& for color (150,150,3)\ntest=test.values.reshape(len(test),28,28,1)","0b15bcdb":"test.shape\nx=x\/255.0\ntest=test\/255.0 #scaling value between 0-1\ny=to_categorical(y,num_classes=10)\nxtrain,xvalid,ytrain,yvalid=train_test_split(x,y,test_size=0.1,random_state=49)\n","a0379865":"model=keras.models.Sequential([\n    keras.layers.Conv2D(16,(3,3),activation='relu',padding='same',input_shape=(28,28,1)),\n    keras.layers.Conv2D(16,(3,3),activation='relu',padding='same',input_shape=(28,28,1)),\n                              keras.layers.BatchNormalization(axis=1),\n                              keras.layers.Conv2D(64,(3,3),activation='relu',padding='same'),\n    keras.layers.Conv2D(64,(3,3),activation='relu',padding='same'),\n                              keras.layers.MaxPooling2D(2,2),\n    keras.layers.Dropout(0.3),\n    keras.layers.Conv2D(128,(3,3),activation='relu',padding='same'),\n                              keras.layers.MaxPooling2D(2,2),\n                            \n                            \n                        keras.layers.Conv2D(128,(3,3),activation='relu',padding='same'),\n                              keras.layers.MaxPooling2D(2,2),\n                              keras.layers.Dropout(0.4),\n                              keras.layers.Flatten(),\n                              keras.layers.Dense(1286,activation='relu'),\n                              keras.layers.Dropout(0.1),\n                              keras.layers.Dense(10,activation='softmax')])\nmodel.compile(optimizer=RMSprop(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n\n","cc1eabf5":"data_augment=ImageDataGenerator(rescale=1.0\/255.0,width_shift_range=0.3,height_shift_range=0.3,rotation_range=35)\nbatch_train=data_augment.flow((xtrain,ytrain),batch_size=90)\nbatch_valid=data_augment.flow((xvalid,yvalid),batch_size=20)\n","6947d925":"history=model.fit(xtrain,ytrain,epochs=100,steps_per_epoch=420,validation_data=(xvalid,yvalid),verbose=1,validation_steps=41,callbacks=[learning_rate,earlystop])","2beda9b3":"model.evaluate(test)","59562d4c":"predictions = model.predict_classes(test, verbose=0)\n\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": predictions})\nsubmissions.to_csv(\"DR.csv\", index=False, header=True)","2cba486a":"submissions","c47183cf":" **Loading of dataset into train and test folder with help of pandas library**","81c377fe":"**CNN model for trainig model**"}}