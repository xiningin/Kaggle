{"cell_type":{"9ec69915":"code","d7edf0a0":"code","91188bea":"code","e46c6df3":"code","158414f8":"code","9f62ce2e":"code","884b5914":"code","26411192":"code","a3a3abe9":"code","66237d0a":"code","b0080df4":"code","fa224797":"code","32f0d795":"code","84be57e2":"code","805aaca3":"code","2b561eb3":"code","32130783":"code","9d4f5dda":"code","9a10fc26":"code","311e3554":"code","1f2375d6":"code","686137b9":"markdown","199d1263":"markdown","c293cd62":"markdown","7040b4ba":"markdown","e22f22e9":"markdown","88bef9c7":"markdown","405a40b9":"markdown","7a7a0339":"markdown","8ebd784b":"markdown","8fc4361a":"markdown"},"source":{"9ec69915":"# packages\nimport numpy as np \nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","d7edf0a0":"# read files\ndf_train = pd.read_csv('..\/input\/commonlitreadabilityprize\/train.csv')\ndf_test = pd.read_csv('..\/input\/commonlitreadabilityprize\/test.csv')\nsub = pd.read_csv('..\/input\/commonlitreadabilityprize\/sample_submission.csv')","91188bea":"# preview training data\ndf_train.head()","e46c6df3":"# show (full) test set\ndf_test","158414f8":"# more details for training data\ndf_train.info()","9f62ce2e":"# basis stats for numerical columns\ndf_train.describe()","884b5914":"# plot target\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,6))\nax1.hist(df_train.target, bins=50)\nax1.grid()\nax1.set_title('Target')\nax2.boxplot(df_train.target, vert=False)\nax2.grid()   \nax2.set_title('Target - Boxplot')\nplt.show()","26411192":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10,6))\nax1.hist(df_train.standard_error, bins=50)\nax1.grid()\nax1.set_title('Standard Error')\nax2.boxplot(df_train.standard_error, vert=False)\nax2.grid()   \nax2.set_title('Standard Error - Boxplot')\nplt.show()","a3a3abe9":"# scatter plot standard error \/ target\nplt.scatter(df_train.target, df_train.standard_error)\nplt.title('Standard Error vs Target')\nplt.xlabel('Target')\nplt.ylabel('Standard Error')\nplt.grid()\nplt.show()","66237d0a":"# let's look at the \"outlier\":\ndf_train[df_train.standard_error==0]","b0080df4":"# remove \"outlier\" row\ndf_train = df_train[df_train.standard_error!=0]","fa224797":"# add a few features\ndf_train['n_char'] = df_train.excerpt.str.len()\ndf_train['n_word'] = df_train.excerpt.str.split().map(lambda x : len(x))\ndf_train['char_per_word'] = df_train.n_char \/ df_train.n_word","32f0d795":"# plot distributions of new features\ndf_train.n_char.plot(kind='hist', bins=25)\nplt.title('Number of characters')\nplt.grid()\nplt.show()\n\ndf_train.n_word.plot(kind='hist', bins=25)\nplt.title('Number of words')\nplt.grid()\nplt.show()\n\ndf_train.char_per_word.plot(kind='hist', bins=25)\nplt.title('Characters per word')\nplt.grid()\nplt.show()","84be57e2":"# correlations\ncorr_pearson = df_train[['n_char','n_word','char_per_word',\n                         'target','standard_error']].corr(method='pearson')\nfig = plt.figure(figsize = (6,5))\nsns.heatmap(corr_pearson, annot=True, \n            cmap='RdYlGn', vmin=-1, vmax=+1)\nplt.title('Pearson Correlation')\nplt.show()","805aaca3":"# target vs number of characters\nsns.jointplot(data=df_train, x='n_char', y='target', \n              kind='reg', scatter_kws = {'alpha': 0.25})\nplt.show()","2b561eb3":"# target vs number of words\nsns.jointplot(data=df_train, x='n_word', y='target',\n              kind='reg', scatter_kws = {'alpha': 0.25})\nplt.show()","32130783":"# target vs characters per word\nsns.jointplot(data=df_train, x='char_per_word', y='target', \n              kind='reg', scatter_kws = {'alpha': 0.25})\nplt.show()","9d4f5dda":"top5 = df_train.nlargest(5,columns=['target'])\ntop5","9a10fc26":"# show full text\nfor i in range(5):\n    print(top5.reset_index().excerpt[i])\n    print()","311e3554":"bot5 = df_train.nsmallest(5,columns=['target'])\nbot5","1f2375d6":"# show full text\nfor i in range(5):\n    print(bot5.reset_index().excerpt[i])\n    print()","686137b9":"### We see quite some correlation between the target and our new features. This could be used to build a first simple baseline model.","199d1263":"#### We can probably delete this row.","c293cd62":"# Extreme cases","7040b4ba":"# Correlations","e22f22e9":"### Most readable examples:","88bef9c7":"#### Not sure, what the purpose of the standard error column is here. Maybe it could be used as a weight in training (higher standard error ~ lower weight)?","405a40b9":"#### Nice smile :-)","7a7a0339":"# Feature Engineering","8ebd784b":"### Most difficult examples:","8fc4361a":"# Target Exploration"}}