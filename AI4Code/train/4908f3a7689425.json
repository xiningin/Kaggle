{"cell_type":{"0d059960":"code","4658183e":"code","928f2fdd":"code","0fffead6":"code","22f8ca3b":"code","25ecdc8d":"code","e1041b16":"code","4260b997":"code","e5139c9a":"code","a6e7c91d":"code","bc4b7891":"code","7b47bc09":"code","03b3c2c5":"code","287d6bb7":"code","d17295ec":"code","188041aa":"code","ee206814":"markdown","02cc22a3":"markdown","8b7bb2bc":"markdown","bb6a2544":"markdown","1df1d977":"markdown","847b0dcc":"markdown","65f41b3d":"markdown"},"source":{"0d059960":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n%matplotlib inline","4658183e":"data = pd.read_csv(\"..\/input\/creditcard.csv\")\ndata.head()","928f2fdd":"count_classes = pd.value_counts(data['Class'], sort = True).sort_index()\ncount_classes.plot(kind = 'bar')\nplt.title(\"Fraud class histogram\")\nplt.xlabel(\"Class\")\nplt.ylabel(\"Frequency\")","0fffead6":"from sklearn.preprocessing import StandardScaler\n\ndata['normAmount'] = StandardScaler().fit_transform(pd.DataFrame(data['Amount']))\ndata = data.drop(['Time','Amount'],axis=1)\ndata.head()","22f8ca3b":"#x = data.loc[:, data.columns != 'Class']\n#y = data.loc[:, data.columns == 'Class']\nx =  data.drop(['Class'],axis = 1)\ny =  data['Class']","25ecdc8d":"fraud_indices = np.array(data[data.Class == 1].index)","e1041b16":"len(data[data.Class == 0])","4260b997":"# Number of data points in the minority class\nnumber_records_fraud = len(data[data.Class == 1])\nfraud_indices = np.array(data[data.Class == 1].index)\n\n# Picking the indices of the normal classes\nnormal_indices = data[data.Class == 0].index\n\n# Out of the indices we picked, randomly select \"x\" number (number_records_fraud)\nrandom_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace = False)\n#random_normal_indices = np.array(random_normal_indices)\n\n# Appending the 2 indices\nunder_sample_indices = np.concatenate([fraud_indices,random_normal_indices])\n\n# Under sample dataset\nunder_sample_data = data.iloc[under_sample_indices,:]\n\n#X_undersample = under_sample_data.iloc[:, under_sample_data.columns != 'Class']\n#y_undersample = under_sample_data.ix[:, under_sample_data.columns == 'Class']\nX_undersample = under_sample_data.drop(['Class'],axis = 1)\nY_undersample = under_sample_data['Class']\n# Showing ratio\nprint(\"Percentage of normal transactions: \", len(under_sample_data[under_sample_data.Class == 0])\/len(under_sample_data))\nprint(\"Percentage of fraud transactions: \", len(under_sample_data[under_sample_data.Class == 1])\/len(under_sample_data))\nprint(\"Total number of transactions in resampled data: \", len(under_sample_data))","e5139c9a":"from sklearn.model_selection import train_test_split\n\n# Whole dataset\nX_train, X_test, Y_train, Y_test = train_test_split(x,y,test_size = 0.3, random_state = 0)\n\nprint(\"Number transactions train dataset: \", len(X_train))\nprint(\"Number transactions test dataset: \", len(X_test))\nprint(\"Total number of transactions: \", len(X_train)+len(X_test))\n\n# Undersampled dataset\nX_train_undersample, X_test_undersample, Y_train_undersample, Y_test_undersample = train_test_split(X_undersample\n                                                                                                   ,Y_undersample\n                                                                                                   ,test_size = 0.3\n                                                                                                   ,random_state = 0)\nprint(\"\")\nprint(\"Number transactions train dataset: \", len(X_train_undersample))\nprint(\"Number transactions test dataset: \", len(X_test_undersample))\nprint(\"Total number of transactions: \", len(X_train_undersample)+len(X_test_undersample))\n","a6e7c91d":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix,accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier","bc4b7891":"param_grid = {'C' : [0.01 , 0.1 , 1 , 10 , 100],'gamma' : [1,0.1,0.01,0.001]}","7b47bc09":"grid = GridSearchCV(SVC(),param_grid ,refit = True,verbose = 2)\n","03b3c2c5":"grid.fit(X_train_undersample,Y_train_undersample)","287d6bb7":"grid.best_estimator_","d17295ec":"grid_predictions = grid.predict(X_test)","188041aa":"print('Accuracy Score',accuracy_score(Y_test,grid_predictions))\nprint(confusion_matrix(Y_test,grid_predictions))\nprint(classification_report(Y_test,grid_predictions))","ee206814":"This is my First Attempt in getting hands. I have tried using grid search with SVC classifier to improve the Accuracy on the undersampled data which I got reference from one of the kaggle solutions.\nPlease share your valuable feedback. ","02cc22a3":"# Checking the target classes","8b7bb2bc":"#### 2. Assigning X and Y. No resampling.","bb6a2544":"# Loading the dataset","1df1d977":"* Using Grid Search to find the best hyper-parameter value ","847b0dcc":"reshape will not work in new versions , hence we have to use pd.DataFrame","65f41b3d":"# Splitting data into train and test set. "}}