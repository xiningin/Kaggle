{"cell_type":{"da79d517":"code","1c22909f":"code","a9eee771":"code","61ca80ae":"code","ce4e0333":"code","505ef807":"code","a377c232":"code","c7ff2d3d":"code","78f8620b":"code","b1f17df9":"code","bb0649a2":"code","d8d2e437":"code","3492ca38":"code","c994c523":"code","fd562d47":"code","4215e541":"code","2ebebeb3":"code","0cb81fa2":"code","acee1e78":"code","3ca9c66e":"code","19ce3c87":"code","cf996030":"code","4bdd47d8":"code","86743ae0":"code","463b25a9":"code","588fbce7":"code","28df5341":"code","47582e16":"code","4db3d924":"code","edcdc32c":"code","3ff68767":"code","4d79bb28":"code","7169e52c":"code","2f91d0ba":"code","5d362502":"code","3d83dcf5":"code","37aa52e3":"code","7232b5ad":"code","5e26a2fc":"code","ca3fe692":"code","474f1d50":"code","9ca9cbd2":"code","7eb836ed":"code","77d41b6d":"code","b1758f38":"code","c7c2fd83":"code","a719aa24":"code","e5c49fa7":"code","0c76471c":"code","7c063d0b":"code","21001be8":"code","13c4e83f":"code","0ddd0ba2":"code","e874f6c1":"code","944a608a":"code","32381b78":"code","388e2edc":"code","fd4f5cb8":"code","45a930b9":"code","36a65248":"code","ee48ba34":"code","84c3520e":"code","31faf616":"code","f8c03f1e":"code","540ac570":"code","ceb99b0f":"code","54412342":"code","7d7f454b":"code","3618a595":"code","6d38bd25":"code","b1078fe3":"code","d50c07b1":"code","1ebb046c":"code","a7e5b224":"code","f9139b83":"code","5bd095d4":"code","d8893e4b":"code","f8903c0c":"code","2d45a229":"code","abd8536d":"code","2a53305f":"code","650fe05a":"code","5db3e450":"code","f81fea66":"code","02816eb8":"code","82eb6d87":"code","f3e6ba1c":"code","c5cb23c6":"code","a87f06dd":"code","c3fd42ae":"markdown","a244e48b":"markdown","d6eed611":"markdown","e2446b65":"markdown","6758cc7e":"markdown","1cc14d15":"markdown","01816067":"markdown","774dcaaa":"markdown","4edb4a36":"markdown","6cd69e5d":"markdown","232b934c":"markdown","919e711f":"markdown","65ab19f1":"markdown","fe2334df":"markdown","0aa85d67":"markdown","9eb83fc0":"markdown","17827d8b":"markdown","84b20e1e":"markdown","6d9b62f0":"markdown","8a18b915":"markdown","6dd89c05":"markdown","0b498213":"markdown","470636e3":"markdown","35133f1c":"markdown","f5fafdc3":"markdown","5778bf36":"markdown","dd6d5554":"markdown","d9729501":"markdown","51e6ef0d":"markdown","efde54f5":"markdown","c5f29492":"markdown","83882ff2":"markdown","ae594e31":"markdown","d31348b5":"markdown","6b4dce1c":"markdown","beb9d90c":"markdown","5eaa96f1":"markdown","3b563f16":"markdown","f3aee34a":"markdown","e6e59f7c":"markdown","cf7483cc":"markdown","2ec66c6a":"markdown","365852ec":"markdown","76f19c76":"markdown","becf752d":"markdown","88da48de":"markdown","806ae815":"markdown","d43e4490":"markdown","83b73e26":"markdown","e30ce2db":"markdown","4a19bc34":"markdown","772119c4":"markdown","2896b374":"markdown","0bd16028":"markdown","9e7163a4":"markdown","99304108":"markdown","9efcf9f3":"markdown","adb9d0d9":"markdown","4efcab80":"markdown","e33ba9f7":"markdown","711b6228":"markdown","9483de65":"markdown","cc241b90":"markdown","c9fbb892":"markdown","6882e3f9":"markdown","f8752f1a":"markdown","f635600e":"markdown","ff5d6fca":"markdown","d0421791":"markdown"},"source":{"da79d517":"# !pip install comet_ml","1c22909f":"#from comet_ml import Experiment","a9eee771":"#experiment = Experiment(api_key=\"KocQlMUqLsntXlqfK65whOpu7\",\n#                       project_name=\"Team_RM_4\", workspace=\"ghp042\")","61ca80ae":"# !pip install spacy\n# import spacy.cli\n# spacy.cli.download(\"en_core_web_lg\")\n\n# !pip install nltk\n# import nltk\n# nltk.download('all')\n\n# !pip install emoji\n# !pip install pickle","ce4e0333":"# import packages\nimport pandas as pd\nimport numpy as np\nimport pickle\nimport bz2\nimport _pickle as cPickle\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set_style('darkgrid')\n\nimport re\nimport emoji\nimport string\nimport spacy\nimport nltk\nfrom spacy import displacy\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nfrom nltk import TreebankWordTokenizer, SnowballStemmer\n\nnlp = spacy.load('en_core_web_lg')\nstop_words = stopwords.words('english')\npd.set_option('display.max_colwidth', 500)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","505ef807":"# Load Data\ntrain_data = pd.read_csv('..\/input\/climate-change-belief-analysis\/train.csv',index_col='tweetid')\ntest_data = pd.read_csv('..\/input\/climate-change-belief-analysis\/test.csv',index_col='tweetid')","a377c232":"print(f'Train data shape:\\t{train_data.shape}\\nTest data shape:\\t{test_data.shape}')","c7ff2d3d":"# count the entries per column and save them in a dataframe\ncategories = train_data['sentiment'].value_counts().to_frame()\ncategories.index.rename('categories',inplace=True)\ncategories.rename({'sentiment':'no_of_entries'},axis=1,inplace=True)\ncategories['percentage'] = [round(count\/len(train_data),2) for count in categories['no_of_entries']]\ncategories","78f8620b":"# plot a bar chart which shows the distribution of the entries\nplt.figure(figsize=(8,5))\n\nplt.bar(x=['1','2','0','-1'],height=categories['no_of_entries'])\nplt.title('Number of entries per category')\nplt.xlabel('Categories')\nplt.ylabel('Number of entries')\nplt.show()\n#del categories","b1f17df9":"train_data.head()","bb0649a2":"test_data.head()","d8d2e437":"pd.DataFrame(train_data.isnull().sum(),columns=['mising_values'])","3492ca38":"print(f\"Length before check:\\t{len(train_data)}\")\n\nblanks = [] # store the indices of the space's tweets\n\nfor index, sent, mess in train_data.itertuples():\n    if type(mess)==str:\n        if mess.isspace():\n            blanks.append(index)\n\n# drop rows from dataframe if there are any empty tweets\/strings            \ntrain_data.drop(blanks,axis=0,inplace=True)\n\nprint(f\"Length after check:\\t{len(train_data)}\")","c994c523":"print(f'''Number of tweets that might not form an english sentence:\n      {len([tweet for tweet in train_data.message if len(tweet)<=5])}''')","fd562d47":"# all_tokens = []\n\n# bag_of_words = {}\n\n# for tweet in train_data.message:\n    \n#     for word in nlp(tweet):\n#         if word.text not in frequency.keys():\n#             frequency[word.text] = 1\n            \n#             if word.text not in all_tokens:\n#                 all_tokens.append(token.text)\n#         else:\n#             frequency[word.text] += 1\n            \n#             if word.text not in all_tokens:\n#                 all_tokens.append(token.text)","4215e541":"from keras import Sequential\nfrom keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom keras.layers import Embedding, SpatialDropout1D, LSTM, Dense, Dropout\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n\nfrom sklearn.metrics import classification_report,accuracy_score\nfrom sklearn.model_selection import train_test_split, GridSearchCV","2ebebeb3":"# split into dependent and independent arrays\nX = train_data['message'].values\ny = train_data['sentiment'].values\n\n# split into training and testing data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)","0cb81fa2":"# SVC pipeline\nsvc_clf = Pipeline([('vectorizer',TfidfVectorizer()),('SVC',SVC())])\n\n# LinearSVC pipeline\nlinear_svc_clf = Pipeline([('vectorizer',TfidfVectorizer()),\n                            ('Linear_SVC',LinearSVC())])\n\n# Random Forest Classiffier pipeline\nrandom_f_clf = Pipeline([('vectorizer',TfidfVectorizer()),\n                         ('Random_Forest',RandomForestClassifier())])\n\n# MultinomialNB pipeline\nmultinom_clf = Pipeline([('vectorizer',TfidfVectorizer()),('Multinomial',\n                                                    MultinomialNB())])\n\n# logistic Regression pipeline\nlogistic_clf = Pipeline([('vectorizer',TfidfVectorizer()),('Logistic_regr',\n                                LogisticRegression(multi_class='ovr'))])\n\n# K Neighbors Classifier\nk_near_clf = Pipeline([('vectorizer',TfidfVectorizer()),('KNeighbors',\n                                        KNeighborsClassifier(n_jobs=2))])\n\n# Ada Boost Classifier\nada_boost_clf = Pipeline([('vectorizer',TfidfVectorizer()),('AdaBoost',\n                                                AdaBoostClassifier())])\n\n# Gradient Boost Classifier\ngboost_clf = Pipeline([('vectorizer',TfidfVectorizer()),('GradientBoost',\n                                                GradientBoostingClassifier())])","acee1e78":"# create a dictionary of all the untrained models\ntrain_models = {'Logistic_regression':logistic_clf,\n                  'SVC':svc_clf,'LinearSVC':linear_svc_clf,\n                  'MultinomialNB':multinom_clf,'Random_Forest':random_f_clf,\n                  'KNeighbors':k_near_clf, 'AdaBoost':ada_boost_clf,\n                  'GradientBoost':gboost_clf}","3ca9c66e":"def models_to_train(X_train,X_test,y_train,y_test,train_models):\n    '''\n    Train models and return a dataframe of their perfomance. The function\n    also returns the trained models for later use.\n    \n    Parameters\n    ----------\n    X_train : numpy array\n        A numpy array of the shape (len(X_train), n), where n is any integer\n        greater than 0.\n    X_test : numpy array\n        A numpy array of the shape (len(X_test), n), where n is any integer\n        greater than 0.\n    y_train : numpy array\n        A numpy array of the shape(len(y_train),), with the values being the\n        categories or target values.\n    \n    y_train : numpy array\n        A numpy array of the shape(len(y_train),), with the values being the\n        categories or target values\n    trained_models : dict\n       A dictionary of untrained models\/pipelines.\n\n    Returns\n    -------\n    dataframe : pandas.core.frame.DataFrame\n        A pandas dataframe with two columns; weighted average f1 score and the\n        accuracy score of each model.\n    dictionary : dict\n        A dictionary of all the trained models\n    '''\n    trained_models = train_models.copy()\n    performance = {} # dictionary to store performance\n    i = 1\n    \n    for name,model in trained_models.items():\n        \n        print(f'Training model {i} of {len(trained_models)}: {name}')\n        i+=1\n        # fit the model\n        model.fit(X_train, y_train)\n        \n        # prediction of y\n        y_predicted = model.predict(X_test)\n\n        # calculate the weighted average score and the accuracy score.\n        weighted_avg = classification_report(y_test,y_predicted)[-15:-11]\n        acc_score = accuracy_score(y_test,y_predicted)\n\n        performance[name] = {'weighted_average':float(weighted_avg),\n                            'accuracy_score':round(acc_score,4)}\n\n        #print(f\"{name}:\\n{classification_report(y_test,y_predicted)}\\n\")\n    \n    # convert the performance dictionary to a dataframe\n    performance = pd.DataFrame(performance).T.sort_values(by='weighted_average',\n                                                          ascending=False)\n    \n    return performance, trained_models","19ce3c87":"# run the function to train the models\nperformance, trained_models = models_to_train(X_train,X_test,y_train,y_test,\n                                              train_models)","cf996030":"def sequence_model(df,performance,col='message',epochs=5):\n    '''\n    Return a dataframe of performance and a trained model.\n    \n    Parameters\n    ----------\n    df : pandas.core.frame.DataFrame\n        A pandas dataframe with the columns 'sequence' and 'message'.\n    \n    performance : pandas.core.frame.DataFrame\n        A pandas dataframe with performance metrices for previously\n        trained models.\n        \n    Returns\n    -------\n    dataframe : pandas.core.frame.DataFrame\n        A performance dataframe with the weighted f1 scores and the \n        accuracy score of each model trained.\n    keras model : keras.engine.sequential.Sequential\n        A sequential model that can be used for predictions.\n    '''\n    \n    max_no_words, max_sequence, embedding = 50000, 250, 100\n\n    tokenizer = Tokenizer(num_words=max_no_words)\n    tokenizer.fit_on_texts(df[col].values)\n    word_index  = tokenizer.word_index\n\n    X = tokenizer.texts_to_sequences(df[col].values)\n    X = pad_sequences(X,maxlen=max_sequence)\n\n    y = to_categorical(df['sentiment'].values,num_classes=4)\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n                                                        random_state=4)\n    \n    # instantiate a sequential model.\n    model = Sequential()\n    \n    # add layers to the model\n    model.add(Embedding(max_no_words,embedding,input_length=X.shape[1]))\n    model.add(SpatialDropout1D(0.2))\n    model.add(LSTM(100,dropout=0.2,recurrent_dropout=0.2))\n    model.add(Dense(4,activation='softmax'))\n    model.compile(loss='categorical_crossentropy',optimizer='adam',\n                  metrics=['accuracy'])\n\n    # fit the model with 6 epochs of batxh size 50.\n    model.fit(X_train,y_train,epochs=epochs,batch_size=50,\n            callbacks=[EarlyStopping(monitor='val_loss',\n            patience=3, min_delta=0.0001)],verbose=1,validation_split=0.1)\n    \n    # make predictions\n    y_predicted = model.predict(X_test)\n    y_predicted = y_predicted.argmax(axis=1)\n    y_test=y_test.argmax(axis=1)\n\n    # calculate performance matrices\n    weighted_avg = classification_report(y_test,y_predicted)[-15:-11]\n    acc_score = accuracy_score(y_test,y_predicted)\n    \n    model_performance = pd.Series(data={'weighted_average':weighted_avg,\n                      'accuracy_score':acc_score},name='Sequential')\n    \n    performance = performance.append(model_performance,\n                                     ignore_index=False).astype('float')\n    \n    performance = performance.sort_values(by='weighted_average',ascending=False)\n    \n    return performance, model","4bdd47d8":"performance, model = sequence_model(train_data,performance)\ntrained_models['Sequential'] = model","86743ae0":"# # save the model\n# # with bz2.BZ2File(\"base_sequence.pbz2\", \"wb\") as f:\n# #     cPickle.dump(model, f)\n\n# # load the saved model and add it to the trained_models dictionary\n# model = cPickle.load(bz2.BZ2File(\"..\/input\/performances\/base_sequence.pbz2\", \"rb\"))\n# trained_models['Sequential'] = model\n\n# # save the performance dataframe and load it.\n# # performance.to_csv('base_performance.csv')\n# performance = pd.read_csv('..\/input\/performances\/base_performance.csv',index_col=0)","463b25a9":"performance","588fbce7":"def model_scores(performance):\n    '''Create a bar chart of the weighted f1 score and the accuracy score.'''\n    \n    x = list(performance.index)\n    height = [i*100 for i in performance.weighted_average]\n    fig= plt.figure(figsize=(12,6))\n    plt.bar(x,height,label='weighted_avg',)\n    plt.bar(x,height=[i*100 for i in performance.accuracy_score],alpha=0.2,label='accuracy')\n    plt.title('Weighted Average F1 score')\n    plt.xlabel('Models')\n    plt.ylabel('Weighted Avg in %')\n    plt.legend()\n    plt.xticks(rotation=45)\n    \n    return fig","28df5341":"_ = model_scores(performance)","47582e16":"def distribution_of_sentiment(trained_models,X_test):\n    '''Create a pandas dataframe with the counts of each classification per model.\n    \n    Parameters\n    ----------\n    trained_models : dict\n        A dictionary of trained models.\n    X_test : numpy array\n        A numpy array with the 'message' content from the train dataframe.\n        \n    Returns\n    -------\n    dataframe: pandas.core.frame.DataFrame\n        A pandas dataframe with the count of classifications per model.\n    '''\n    \n    predictions = pd.DataFrame(trained_models['Logistic_regression'].predict(X_test),\n                               columns=['Logistic_regression'])\n    predictions = pd.DataFrame(predictions['Logistic_regression'].value_counts())\n\n    for name in trained_models.keys():\n\n        if name != 'Sequential':\n            predictions[name] = pd.Series(trained_models[name].predict(X_test)).value_counts()\n\n        else:\n            tokenizer = Tokenizer(num_words=50000)\n            tokenizer.fit_on_texts(X_test)\n\n            seq = trained_models[name].predict(pad_sequences(\n                    tokenizer.texts_to_sequences(X_test),maxlen=250)).argmax(axis=1)\n\n            data = []\n            for x in seq:\n                if x !=3:\n                    data.append(x)\n                else:\n                    data.append(-1)\n\n            predictions[name] = pd.Series(data).value_counts()\n            \n    predictions.fillna(0,inplace=True)\n    \n    return predictions","4db3d924":"predictions = distribution_of_sentiment(trained_models,X_test)\npredictions.T\n\n#predictions = pd.read_csv(\"..\/input\/performances\/predictions.csv\",index_col=0).T","edcdc32c":"def sentiment_figures(predictions):\n    '''Return a figure that visualises the classifications per model.'''\n    \n    fig, ax = plt.subplots(3,3,figsize=(11,6))\n    \n    count=0\n    \n    for row in range(3):\n        for column in range(3):\n            mask = predictions.columns[count]\n            ax[row,column].bar(x=['1','2','0','-1'],height=predictions[mask])\n            ax[row,column].set_title(mask)\n            count +=1\n\n    plt.tight_layout()\n    \n    return fig","3ff68767":"_ = sentiment_figures(predictions)","4d79bb28":"# import the resampling package\nfrom sklearn.utils import resample","7169e52c":"def UpSampleData(train_data):\n    '''Return dataframes with upsampled sentiment categories'''\n    \n    # split the data by sentiment\n    sent_1 = train_data[train_data.sentiment==1]\n    sent_2 = train_data[train_data.sentiment==2]\n    sent_0 = train_data[train_data.sentiment==0]\n    sent_3 = train_data[train_data.sentiment==-1]\n\n    # resample the data\n    sent_2 = resample(sent_2,replace=True,n_samples=len(sent_1),random_state=4)\n    sent_1 = resample(sent_1,replace=True,n_samples=int(len(sent_1)*1.6),random_state=4)\n    sent_0 = resample(sent_0,replace=True,n_samples=int(len(sent_2)*0.8),random_state=4)\n    sent_3 = resample(sent_3,replace=True,n_samples=len(sent_3)*4,random_state=4)\n    \n    return sent_1,sent_2,sent_0,sent_3\n\nsent_1,sent_2,sent_0,sent_3 = UpSampleData(train_data)","2f91d0ba":"# display the distributions\nfig, ax = plt.subplots(1,2,figsize=(13,5))\nprint('\\n\\t\\t\\t\\tNumber of entries per category')\nax[0].bar(x=['1','2','0','-1'],height=categories['no_of_entries'])\nax[1].bar(x=['1','2','0','-1'],height=[len(sent_1),len(sent_2),len(sent_0),len(sent_3)])\nax[0].set_ylabel('Number of entries')\nplt.show()\nprint('\\t\\t\\t\\t\\tSentiment Categories\\n')","5d362502":"new_train_data = pd.concat([sent_1,sent_2,sent_3,sent_0])\nnew_train_data.head()","3d83dcf5":"# # Do NOT Execute!! Load Pickle files!\n# # split into dependent and independent arrays\n# X = new_train_data['message'].values\n# y = new_train_data['sentiment'].values\n\n# # split into training and testing data\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)\n\n# sampled_performance, sampled_trained_models = models_to_train(X_train,X_test,y_train,y_test,train_models)\n# sampled_performance, sampled_model = sequence_model(new_train_data,sampled_performance)\n# sampled_trained_models['Sequential'] = sampled_model","37aa52e3":"# # save the models as pickle files.\n# for name, model in sampled_trained_models.items():\n#   filename = name+'.pbz2'\n#   print(filename)\n#   with bz2.BZ2File(filename,'wb') as file:\n#     cPickle.dump(model,file)\n\n# sampled_performance.to_csv('sampled_performance.csv')","7232b5ad":"# sampled_performance =pd.read_csv('..\/input\/performances\/sampled_performance.csv',index_col=0)\n# sampled_performance","5e26a2fc":"_ = model_scores(sampled_performance)","ca3fe692":"def remove_entity(tweet):\n    '''Return a tweet without any entities.\n    '''\n    doc = nlp(tweet)\n    \n    # list to store entities\n    entity = [x.text for x in doc.ents]\n    \n    # list of words without any entities\n    tweet = [word.text for word in doc if word.text not in entity]\n    \n    # return a string\n    return ' '.join(tweet)","474f1d50":"train_data['message'] = train_data['message'].apply(remove_entity)","9ca9cbd2":"train_data['message'].loc[911385]","7eb836ed":"emoji.demojize(train_data['message'].loc[911385])#.replace('_',' ').replace(':','')","77d41b6d":"def demojize_tweet(df,col):\n    '''Return a dataframe with no emojis.\n    '''\n    df[col] = df[col].apply(emoji.demojize)\n    df[col] = df[col].apply(lambda x: x.replace(':','').replace('_',' '))\n    \n    return df","b1758f38":"# apply the function\ntrain_data = demojize_tweet(train_data,'message')","c7c2fd83":"train_data['message'].loc[911385]","a719aa24":"def remove_links(df,col):\n    '''Return a tweet without any mentions (@), #'s nor links'''\n    \n    # Remove urls\n    pattern_url = r'http[s]?:\/\/(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n    pattern_url_1 = r'http[s]?\/\/(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n    \n    mentions_H = r'\\@\\w+|\\#'\n    \n    df[col] = df[col].replace(to_replace = pattern_url, value = 'url', regex = True)\n    df[col] = df[col].replace(to_replace = pattern_url_1, value = 'url', regex = True)\n    df[col] = df[col].replace(to_replace = mentions_H, value = '', regex = True)\n    \n    return df","e5c49fa7":"# store the cleaned tweets\ntrain_data = remove_links(train_data,'message')","0c76471c":"train_data.head()","7c063d0b":"def remove_punc(tweet):\n    'Return a string without any punctuation.'\n    \n    tokens = word_tokenize(tweet)\n    tokens = [w.lower() for w in tokens]\n    table = str.maketrans('', '', string.punctuation+'0123456789')\n    \n    return ' '.join([w.translate(table) for w in tokens])","21001be8":"train_data['message'] = train_data['message'].apply(remove_punc)","13c4e83f":"train_data.head()","0ddd0ba2":"def remove_stop_words(tweet):\n    tokens = TreebankWordTokenizer().tokenize(tweet)\n    return ' '.join([t for t in tokens if t not in stopwords.words('english')])","e874f6c1":"train_data['message'] = train_data['message'].apply(remove_stop_words)","944a608a":"def stem_tweets(tweet):\n    tokens = TreebankWordTokenizer().tokenize(tweet)\n    return ' '.join([SnowballStemmer('english').stem(word) for word in  tokens])","32381b78":"pd.DataFrame(train_data['message'].apply(stem_tweets)).head()","388e2edc":"def lemmatize_tweets(tweet):\n    tokens = TreebankWordTokenizer().tokenize(tweet)\n    return ' '.join([WordNetLemmatizer().lemmatize(word) for word in tokens])","fd4f5cb8":"train_data['message'] = train_data['message'].apply(lemmatize_tweets)","45a930b9":"train_data.head()","36a65248":"sent_1,sent_2,sent_0,sent_3 = UpSampleData(train_data)\nclean_train_data = pd.concat([sent_1,sent_2,sent_3,sent_0])","ee48ba34":"# split into dependent and independent arrays\nX = clean_train_data['message'].values\ny = clean_train_data['sentiment'].values\n\n# split into training and testing data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)","84c3520e":"# run the functions to train the models\npost_prep_performance, post_prep_trained_models = models_to_train(X_train,X_test,y_train,y_test,train_models)\npost_prep_performance, post_prep_model = sequence_model(clean_train_data,post_prep_performance,epochs=4)\npost_prep_trained_models['Sequential'] = post_prep_model","31faf616":"# # with bz2.BZ2File('post_prep_model.pbz2','wb') as file:\n# #      cPickle.dump(post_prep_model,file)\n\n# post_prep_model = cPickle.load(bz2.BZ2File(\"..\/input\/performances\/post_prep_model.pbz2\", \"rb\"))\n# post_prep_trained_models['Sequential'] = post_prep_model\n\n\n# # post_prep_performance.to_csv('post_prep_performance.csv')\n# post_prep_performance = pd.read_csv('..\/input\/performances\/post_prep_performance.csv',index_col=0)","f8c03f1e":"# create a dataframe for all trials\nrelative_performance = performance.merge(sampled_performance,\n                        left_index=True,right_index=True,\n                        suffixes=('_raw', '_upsampled')).merge(\n                        post_prep_performance,left_index=True,\n                        right_index=True,suffixes=('', '_clean'))\n# columns to remove\nremove1 = list(relative_performance.columns)[1]\nremove2 = list(relative_performance.columns)[3]\nremove3 = list(relative_performance.columns)[-1]\n\n# \nrelative_performance.drop([remove1,remove2,remove3],axis=1,inplace=True)\ndel remove1, remove2, remove3\nrelative_performance","540ac570":" def all_models_performance(relative_performance):\n    ''' plot the changes in the scores pre and post data transformation.'''\n    fig = plt.figure(figsize=(10,6))\n\n    for col in relative_performance.T.columns:\n        plt.plot(relative_performance.T[col],label=col)\n        plt.legend()\n      \n    plt.title('Weigted Average f1 score')\n    plt.ylabel('F1 Score')\n  \n    return fig\n\n_ = all_models_performance(relative_performance)","ceb99b0f":"post_prep_predictions = distribution_of_sentiment(post_prep_trained_models,X_test)\n_ = sentiment_figures(post_prep_predictions)","54412342":"# print the classification report for the multinomial naives bayes\n#print(classification_report(post_prep_trained_models['MultinomialNB'].predict(X_test),y_test))","7d7f454b":"_ = model_scores(post_prep_performance)","3618a595":"relative_performance.sort_values(by='weighted_average',ascending=False,inplace=True)\nrelative_performance[relative_performance['weighted_average']>0.8]","6d38bd25":"# specify the parameters to be used\nparameters = {'kernel':('rbf','poly'), \n              'C':(0.25,1.0),\n              'gamma': (1,2)}\n\n# create a pipeline\nsvc_grid = Pipeline([('vectorizer',TfidfVectorizer()),\n                    ('SVC',GridSearchCV(estimator=SVC(),param_grid=parameters,\n                                        scoring='f1_weighted', cv=5))])","b1078fe3":"# create a dictionary of models to train\ntune_models = {'SVC':svc_grid}","d50c07b1":"# split into dependent and independent arrays\nX = clean_train_data['message'].values\ny = clean_train_data['sentiment'].values\n\n# split into training and testing data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)","1ebb046c":"# train the model\ntuned_performance, tuned_model = models_to_train(X_train,X_test,y_train,y_test,\n                                                 tune_models)","a7e5b224":"# #tuned_performance.to_csv('tuned_performance.csv')\n# tuned_performance = pd.read_csv('..\/input\/performances\/tuned_performance.csv',index_col=0)","f9139b83":"# y_pred =tuned_model['SVC'].predict(test_data.message.values)\n# pd.DataFrame(data = y_pred,index = list(test_data.index),columns=['sentiment']).reset_index().rename({'index':'tweetid'},axis=1).set_index('tweetid').to_csv('submit_me.csv')\n","5bd095d4":"# specify the parameters to be used\nparameters = {'C':(0.25,0.5,0.75,1.0)}\n\n# create a pipeline with the gridsearchcv\nlinear_svc_grid = Pipeline([('vectorizer',TfidfVectorizer()),\n                            ('Linear_SVC',GridSearchCV(estimator=LinearSVC(),\n                              param_grid=parameters,scoring='f1_weighted',cv=5))])","d8893e4b":"linsvc_model = {'LinearSVC': linear_svc_grid}","f8903c0c":"linsvc_performance, linsvc_model = models_to_train(X_train,X_test,\n                                                  y_train,y_test, linsvc_model)\n\n# add the LinearSVC model to the tuned models dictionary\n#tuned_model[list(linsvc_model.keys())[0]] = list(linsvc_model.values())[0]\n\ntuned_performance = pd.concat([tuned_performance,linsvc_performance])","2d45a229":"# specify the parameters to be used\nparameters = {'C':(0.25,0.5,0.75,1.0),\n              'solver':('lbfgs','saga','newton-cg')}\n\n# create a pipeline with the gridsearchcv\nlogistic_grid = Pipeline([('vectorizer',TfidfVectorizer()),('Logistic_regr',\n                                GridSearchCV(estimator=LogisticRegression(),\n                                param_grid=parameters,scoring='f1_weighted',\n                                cv=5))])","abd8536d":"logic_model = {'Logistic_regression':logistic_grid}","2a53305f":"log_performance, log_model = models_to_train(X_train,X_test,\n                                            y_train,y_test, logic_model)\n\n# add the LinearSVC model to the tuned models dictionary\n#tuned_model[list(log_model.keys())[0]] = list(log_model.values())[0]\n\ntuned_performance = pd.concat([tuned_performance,log_performance])","650fe05a":"tuned_performance","5db3e450":"# merge the new performance with the relative performance dataframe\ntunned_re_performance = relative_performance.merge(tuned_performance,\n                                            how='left',left_index=True,\n                                            right_index=True, suffixes=(' ','_tuned'))\n\n# drop the accuracy score column & sort accordingly\ntunned_re_performance.drop('accuracy_score',axis=1,inplace=True)\ntunned_re_performance.sort_values(by=list(tunned_re_performance.columns)[-1],\n                                  ascending=False,inplace=True)\n\ntunned_re_performance","f81fea66":"# display the performance of the tunned models.\n_ = all_models_performance(tunned_re_performance)","02816eb8":"sampled_performance","82eb6d87":"# split into dependent and independent arrays\nX = train_data['message'].values\ny = train_data['sentiment'].values\n\n# split into training and testing data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n                                                    random_state=4)\n\ntrain_models = {'SVC':svc_clf}\n\n# train the model\nsampled_performance, sampled_trained_models = models_to_train(X_train,X_test,\n                                                  y_train,y_test,train_models)\n\n# make predictions and return a dataframe.\ny_pred = sampled_trained_models['SVC'].predict(test_data.message.values)\npd.DataFrame(data = y_pred,index = list(test_data.index),\n             columns=['sentiment']).reset_index().rename({'index':'tweetid'},\n                          axis=1).set_index('tweetid').to_csv('submit_me.csv')","f3e6ba1c":"#batch_size = 50\n#num_classes = 4\n#epochs = 5\n#num_nodes = 4\n#optimizer = 'adam'\n#activation = 'softmax'\n\n\n\n\n#params={'batch_size':batch_size,\n        # 'epochs':epochs,\n        # 'layer1_type':'Dense',\n        # 'layer1_num_nodes':num_nodes,\n        # 'layer1_activation':activation,\n        # 'optimizer':optimizer\n        # }\n\n\n#metrics = {'performance':performance}\n#experiment.log_metrics(metrics)\n\n#experiment.log_parameters(params)\n","c5cb23c6":"#experiment.end()","a87f06dd":"#experiment.display()","c3fd42ae":"In the code cells below, we can see that the performance of the models has dropped after cleaning the data. This can be anticipated as we have removed multiple elements from the tweets in the data frame. We start by creating a dataframe with the weighted average f1 scores for all the experiments done by far.","a244e48b":"Train the tuned model.","d6eed611":"Below we go back to investigationg how each model has classified the sentiments when we made prdictions. As it can be seen, there aren't any anomalies in the distribution of the classifications. The distributions are as we could anticipate them to be. Unlike with the base models, the Multinomial Naives Bayes model has seen a significant improvement in its performance.The model has done better than the Gradient Boost, Ada Boost and the K nearest neighbors models in terms of it's weighted average f1 score.","e2446b65":"The code cell below splits the data into all the sentiments (0,1,2,-1). After splitting the data in that manner, we use the resampling package to upsample the entries per category. Here we increased category 1 (Pro) by 20% of the length of category 1 entries. Category 2 (news) was increased to the length of the original category 1 entries. Category 0 (Neutral) was increaed to 80% of the length of the new category 2. The last category was increased by a factor of 4.","6758cc7e":"As it can be seen above, the sentiment belonging to category 1 (Pro climate change belief) is significantly higher than the other categories. In comparison to category -1 (Anti climate change belief), if a model were to be trained with this two categories only, the model not be a good classifier as it would penalise the smaller category by predicting category 1 more often. In the data processing section of this notebook, we will look into methods like resampling to try and balance the distribution of the entries.","1cc14d15":"From the plots below, we can see that the distribution of the classifications follows that of the original dataframe. The multinomialNB model has however done a bad job at classifying the sentiments. The model proves to classify most of the tweets as either 1 (Pro climate change belief) or as 2 (News). As per the models we have trained, this explains or rather is consistent with how the Multinomial model's accuracy and f1-weighted average score is performing the worst amongst our models.\n\nIn this activity, were interested in finding out if there might be any anomalies between the distribution of the sentiment classifications in the original data and the classifications from the predictions in the models. As it can be seen, the distributions are what we would have expected.","01816067":"The accuracy score is consistently above the the weighted average f1 score for all the models that have been trained. This can be attributed to the imbalance in the entries of the sentiment column in the original data. This will however be explored in the nect section as we preprocess our data to try and improve the performance of our model.\n\nFrom the models that we have trained by far, the LinearSVC is currently outperforming all the other models that have been trained on the same data. We will however opt to work on improving the performance of all our models in an attempt to get a model that will perform best.","774dcaaa":"## Missing Values\nIn this section we will be looking out for any missing values (i.e: np.nan values) and or all the tweets that are just empty strings.\n- In the code cell below, we can see that no column of the train data has np.nan values.","4edb4a36":"## Performance Evaluation\nThe dataframe displayed below shows the weighted average f1 score and the accuracy scores for all the base models that have been trained. The LinearSVC model has outperformed all the base models. This is followed by the Sequential neural network model.\n","6cd69e5d":"### Demojize the data\nConvert the emojis in the tweets to their meaning or descriptions. This will help us derive meaning out of the presence of emojis in tweets. The first code cell below shows the raw tweet. The following code cell shows how we demojize a tweet to return its text description.","232b934c":"### Remove Punctuations\nRemove the punctuations from the tweets and return the cleaned tweet. The returned tweet will be in lowwer case. The numbers in tweets will also be removed as they provide us with no information with regards to predicting a customer's sentiment.","919e711f":"# Base Models\nTrain models with minimal data preprocessing.\nGiven the nature of the feature (message column), we will apply the term frequency\u2013inverse document frequency Vectorizer (TfidfVectorizer) to the data so that it can be converted to a matrix of TF-IDF features, which are numerical and a machine learning algorithm can understand.\n\n**Models to be trained**:\n- Logistic Regression\n- Support Vector Classification (SVC)\n- Linear SVC\n- Multinomial Naive Bayes classifier\n- Random Forest Classifier\n- Neural Network Sequence model\n- K Nearest Neighbors Classifier\n- Ada Boost Classifier\n- Gradient Boost Classifier\n\n\nAll of the above models will be trained through pipelines.\n\n###### task: import packages\nImport packages that will make the modelling possible.","65ab19f1":"# Dictionaries for data to log into Comet","fe2334df":"As per the classification report for the multinomialNB model, we can see that the model has improved its predictive accuracy and the precision in classifying the sentiments.","0aa85d67":"###### task: apply the lemmatization method","9eb83fc0":"Below we merge the above dataframe with the relative performace dataframe defined in the data transformation section.","17827d8b":"## Models to tune\nHere we select models to use in this section.\nBelow we display the performance of the models sorted from the best performing model to the worst. We then trim the relative performance to the top five models.","84b20e1e":"###### Conclude\nIn this section we managed to import packages, load data, descibe the features and the target variable. We have also managed to look at the head (top five entries) of the dataframes. We have looked at the possibility of empty strings, np.nan values and even tweets (messages) that might not be sufficient enough to form an english sentence that makes sense. After this exploration, we have't performed any transformation on the data.\n\nBefore we go into any Data transformation or hyperparameter tunning, we fit models with the raw data. Once we have looked at the models before any preprocessing, we will then explore different methods of how we can go about preprocessing our data to better improve the performance of our models.","6d9b62f0":"## Performance Evaluation\nThe dataframe displayed below shows the weighted average f1 score as well as the accuracy scores of the models post the hyperparameter tuning experiment.","8a18b915":"###### upsample the transformed train data","6dd89c05":"As it can be seen in the dataframe above, the upsampling has improved the performance of the models significantly. However, the cleaning of the data has reduced that performance gained from resampling. As it can be seen in the line graph below, the upsampled data by far performs best as it consistently improves the performance across all models. The Ada Boost model on the contrary, is not impacted significantly by the process of upsampling. If anything, it is decreasing as we upsample and clean. The gradient boost is also not impacted significantly by upsampling (relative to the other models). This can be an indication of the two model's resistance to overfitting during the training of the models.","0b498213":"The tweet in the code cell above reflects a transformed tweet without anu emojis, yet maintaining the same information from what an emoji might convey.","470636e3":"###### task: create a function that will demojize the tweets\nThe function below takes a tweet that has emojis, demojize the tweets and then cleans the tweet. The cleaning of the tweet is only limited to removing the collons and the under scores created by the descriptions of the emojis.","35133f1c":"###### task: define a neural network function\nThe neural network will use the Sequential method with a maximum number of words of 50000, maximum sequence of 250 and an embedding of 100. The function will first tokenize the data, split it accordingly and then train a Sequencial model. We will be doing a recurrent network. This is done to make sure that there is little to no linearity in the features that are used to train the model. Once the model has been trained, we return a dataframe of the weighted average f1 score as well as the accuracy score. Like the previous function, we will be returning the trained model too so that it can be reused later if need be","f5fafdc3":"###### task: Display the number of entries per category in the sentiment column\nThis is done to try and understand the distribution of entries in the sentiment column. Given that this is our target variable (sentiment), it is important that the data is somewhat balanced to avoid bias towards the categories with higher entries. That is, to reduce the likelihood that predictions will classify tweets as the category with the most entries.\n\nBelow we have created a dataframe that shows the number of entries per category and the percentage of those entries as a faction of the total entries.","5778bf36":"###### task: split the data into train tests arrays\nGiven the decline in performance post cleaning the data, we have opted to use the uncleaned, yet upsampled data to train the tuned models. Here we split the data into train test data arrays.","dd6d5554":"# Hyperparameter Tunning\nIn this section we are going to explore tunning the parameters for the best performing models from out base models. In the previous section we have established that the performance of the Gradient boosting and the Ada boosting models is relatively low. The inclusion of this models in this section would be redundant as we do not anticipate that they would improve in their performance.\n\nFrom this section going forward, we will only include models with a weighted average f1 score above 0.80.","d9729501":"- Here we seek to remove any empty strings from the 'message' column.","51e6ef0d":"###### task: display the head of both the test and train data","efde54f5":"# Data Transformation\nIn this section, we are going to explore different ways we can go about transforming the data in an attempt to try and improve the performance of our models. This includes the removal of links, special characters, entities etc.","c5f29492":"The experiment to try and upscale the data has paid off as all the base models have improved their performance, be it the accuracy score or the weighted average f1 score. The Support Vector Classifier and the Random forest classifier  have outperformned the other models post the upsampling. This can be attributed to the presence of more information for the models to train on. This might be an indication of overfitting more than it might be an indication of the improvement in performance. Before we conclude this section, we explore other ways of transforming the data and see how that will impact the performance thereof.\n\nPlease note that the transformation below will be done on the original train_data dataframe. This is for computational efficiency. Upon completion of the transformation, the data will be upsampled to reflect the experiment above.","83882ff2":"Lastly we revisit the weighted average f1 score bar graph. As it can be seen here, the SVC and the Random forest perform best.","ae594e31":"## Data resampling\nA we have already identified in section 2 of this notebook (Data Exploration), the data is not balanced ; that is, there are more entries for one sentiment relative to the other. For that reason, we have explored the upsampling as well as the downsampling method to try and balance out the data. However, upon doing that experiment, we realised that the data doesn't really have to be balanced as people are being gradually becoming aware of the impact of climate change and global warming.\n\nFor that reason, it should be expected that more and more people would be in support of the climate change belief. Given that realisation, we opted to rather upsample all the entries per sentiment. This was done to preserve the reflection of reality of the data as well as to try and improve the performance of the models.","d31348b5":"As it can be seen from the above, there aren't any np.nan values nor are there any empty strings from the train_data dataframe.\nWhat we are going to explore next is if there are any tweets that might not be sufficient in length to form an english sentence (say a tweet with one, two or maybe even three words).","6b4dce1c":"### Logistic Regression\nFor the logistic regression model, we are going to be using four regularization (C) values and cross validate the model 5 times. The gridsearchcv object will thus return the best performing model parameters. Like with the linearsvc above, the model will be applied to the upsampled, but not cleaned data. In the code cell below, we start off by creating a pipeline for the model training.","beb9d90c":"# Introduction\n\n## Context\n\nKaggle is hosting a **Climate Change Belief Analysis** competition which aims to predict an individual's belief in climate change based on historical tweet data.\n\nThe results from the prediction will help companies better understand their customer's perception on climate change. Such an analysis or prediction will help companies determine how their products will be recieved; thus guiding their marketing strategy and their production processes. The models to me trained are to be deployed to a Streamlit application which can be used remotely through the use of an AWS ec2 instance.\n\n\n## Problem Statement\n\nCompanies are looking to create products and services that are environmentally friendly. They would thus like to understand their consumers' view on climate change. To address this, we are going to create Machine Learning models that are able to classify whether or not a person believes in climate change, based on their novel tweet data. Correct classification of a tweet will help companies understand consumer sentiment, which will further guide their business strategies.\n\n\n## Data Sets\n\nThe data sets provided by host of the competition provide us with a message (tweet) and the tweet id. The tweets are related to the topic of climate change. \n\nThe data sets used in the notebook:\n    - train.csv : data used to train models; loaded as train_data in our notebook.\n    - test.csv : data used to test the models; loaded as test_data in our notebook.\n    \nThe train.csv data sis composed of 15819 tweets whilst the test.csv is composed of 10546 tweets. Below we go through the data sets to try and understand its composition further.","5eaa96f1":"# Comet- Version control setup","3b563f16":"### Remove stop words\nHere we remove the stop words that might be in the tweets provided.","f3aee34a":"Below we upload the saved dataframe.","e6e59f7c":"Now that we have tunned out models, in the next section of the notebook we are going to look at how the experiment above has affected each model's performance.","cf7483cc":"## Variable Descriptions\n\n- **sentiment**: Sentiment of tweet (pro, anti, neutral,news).\n\n- **message**: Tweet body (raw tweet).\n\n- **tweetid**: Twitter unique id (unique integer).\n\n## Target Variable (sentiment)\n-  **1 : Pro** --> the tweet supports the belief of a man-made climate change.\n-  **2 : News** --> the tweet links to factual news about climate change.\n-  **0 : Neutral** --> the tweet neither supports nor refutes the belief of a man-made climate change.\n- **-1 : Anti** --> the tweet does not believe in a man made climate change\n\n###### task: display the shape of the data sets\nHere we display the shape of both the test and the train data to get an understanding of the features in the data sets. Below, we can see that the train data has 15819 rows of tweets and 2 columns. The columns would be the sentiment as well as the message. However, the test data only has one column (message). From the models that will be trained, we should be able to create a sentiment column for the test data too. The entries for this column will be predicted from the train data.","2ec66c6a":"# Data Exploration\n## Import packages and load data files\n###### task: import and load data\nWe start off by importing packages and loading data","365852ec":"In the code cell below, we create a dictionary that will store tuned pipeline models.","76f19c76":"Apply the function above and add the returned model to the trained models dictionary returned by the models_to_train() function. Due to the time it takes for the model to train, we have saved it as a .pbz2 file (compressed pickle file). Here we simply load the model.","becf752d":"### Support Vector Classifier\nFor the parameter tunning of the support vector classifier, we will be using the sklearn GridSearchCV module. In this experiment, we will be seeking to get the best performing parameters by altering the kernel, C and the gamma of the svc model. The kernels tested are the Radial-basis function (rbf) and the polynomial kernel. This are followed by C values (Regularization parameter) of 0.25 and 1.0. We will also do the experiment using gamma values 1 and 2.\n\nWe will also do a cross validation for the models and then take the best performing model from the experiment. The grid search will use the weighted average f1 scores to rank the performances of each train in the grid search process. In the code cell below, we are creating a pipeline which we are to use in training the svc model.","88da48de":"# Summary and Conclusion\nIn this notebook we explored data which entailed tweets related to climate change and their belief on whether the user\/tweet is pro, neutral or anti the belief. The data had a sentiment category of News as well, this were tweets that entailed relevant information regarding the topic at hand.\n\nWe started off by exploring the data, then trained base models, transformed them and lastly, we tried tuning hyperparameters to try and improve the performance of the models.\n\nOur top five models in this notebook are the LinearSVC, SVC, Random forest, logidtic regression and a sequential neural network that we have trained. The performance metric that we were more interested in was the weighted average f1 score. This is mainly because the f1 score is a measure of accuracy which considers both the precision and recall scores.\n\nWe have thus built predictive models which businesses can use to better understand their customer's take on climate change. Such a model can prove important in guiding business in terms of the strategies to be adopted in production, marketing etc.","806ae815":"## Create pipelines\n###### task: create pipelines with a vectorizer.\nThe pipelines created here are to be used to train the specified models above. The pipelines will apply the TfidfVectorizer to the training data before it fits the model. The TfidfVectorizer will tokenize the tweets, learn the vocabulary and inverse document frequency weightings to create numeric vectors which can be understood by prediction models.","d43e4490":"Train the tuned model.","83b73e26":"##### Conclusion\nIn this section we trained base mosels with the raw data and minimal data preprocessing and little to no hyperparameter tuning. This was done with the intention to get an idea of which models can be ideal to train going forward, given their performance (weighted average f1 score). From our experiment, we have seen that the LinearSVC as well as the Sequential model have the highest weighted average f1 scores.\n\nIn the following sections, we are going to explore multiple methods to try and improve the performance of our models.","e30ce2db":"In the code cell below, we create a dictionary that will store the tuned logistic regression pipeline model.\n","4a19bc34":"### Impact of Upsampling\nHere we look at how upsampling might have affected the performance of our base models by calling the models_to_train() and the sequence_model() functions we defined in the previous section.\n\nDue to the amount of time it takes the models below to train, we have comented out the code post the training and saving of the output from the experiment.","772119c4":"## Split the data\nSplit the train_data into training and testing data. This is to make sure that there isn't any leakage of information when we actually fit the test_data that we imported. To avoid overfitting, we are using the train_data to train and test our models.","2896b374":"###### Conclusion\nIn the process of transforming and tunning the parameters, we have ended up with a decline in performance, for that reason, we are going to use the models post upsampling but before parameter tunning as by far they are the best performing models.\n\nIn the dataframe displayed below, we display the performance from the upsampling section. ","0bd16028":"### Linear Support Vector Cassifier\nFor the LinearSVC, we are going to be using four regularization (C) values and cross validate the model 5 times. The gridsearchcv object will thus return the best performing model parameters. Like with the svc above, the model will be applied to the upsampled, but not cleaned data. In the code cell below, we start off by creating a pipeline for the model training.","9e7163a4":"###### task: display the head of the data","99304108":"### Remove links\nHere we seek to remove links from tweets as they don't offer us much information in terms of predicting a customer's belief on the topic of climate change. In this section we will also remove the **@** references and the **#**'s from tweets.","9efcf9f3":"Below we train the tuned model using the function models_to_train() which was defined in the Base Models section. Due to the time it takes to train the below model, we have saved the output in a csv file.","adb9d0d9":"Execute the code cell below.","4efcab80":"###### task: try the stemmer","e33ba9f7":"The function above trains the logistic regression, svc, linear svc, multinomialNB and the random forest classiffier. The code cell below applies the above defined function:","711b6228":"In the code cell below, we create a dictionary that will store the tuned LinearSVC pipeline model.","9483de65":"## Clean the data\n### Remove Entities\nThe entities in the tweets don't really help us understand a customer's sentiment. For that reason, we have opted to exclude the entities from the train_data (message column). This will be replaced with an empty string.","cc241b90":"As per the data in the dataframe above, we can see that the three models that have been tuned haven't seen much improvement relative to the performance of the models when we upsampled the data. Below is a graphical display of how the weighted average f1 score has changed from the initial base model training.","c9fbb892":"###### Conclusion\nIn this section we looked and upsampling and cleaning the data in the dataframe. We have seen how the models perform better when the data is upsampled. This has resulted in the SVC and the random forest having significant improvements in their performance. Prior to the above exploration, the Linear SVC model was outperforming all the base models that were trained in the Base Models section. The experiment above however suggests that the model is doing just as well as the csv and the random forest.\n\nIn the following section of the notebook, we  will be looking at different hyperparameter tunning methods to try and improve the performance further.","6882e3f9":"###### task: visualize at the distribution of the classifications of all the trained models\nIn this section we are looking at how the models have distributed the classifications across the sentiment entries. We start off by creating a dataframe that stores the counts of each classification.","f8752f1a":"## Performance Evaluation\nIn this section we are going to evaluate the performance of the base models post the transformation of our data. We start off by splitting the data into training and test data. We will be using the functions that were defined earlier for the evaluation below:","f635600e":"## Stemming and Lemmatization\nWhat we are going to try to do in this section is to explore how we can reduce the words in tweets to their root. For this we will explore the Stemming and Lemmatization methods. We start by first exploring the stemming method. Stemming refers to the process of reducing each word to its root or base. However, stemming has a shortfall in that the roots can sometimes not be english words. For that reason, we explore the Lemmatization method which returns english words.\n\nWe will thus apply the lemmatization method to our dataset. The lemmatization method is relatively slower than the stemmer method. But for the sake of having roots or bases that are english words, we will apply lemmatization.","ff5d6fca":"## Kaggle Submission","d0421791":"## Train base models\nIn this section we define functions that tests the five models mentioned above (logistic regression, svc, linear svc, multinomial naive's Bayes, the random classifier and a Neural Network with muliple layers). Once the models are trained, we return a performance dataframe with the weighted average F1 scores as well as the accuracy scores of the models trained. We are interested in the performance of the weighted average f1 score as it adjusts for the precision and the recall scores. The functions will also return the trained models so that they can be used to evaluate other metrices."}}