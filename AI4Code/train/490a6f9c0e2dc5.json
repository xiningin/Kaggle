{"cell_type":{"06e48dd4":"code","16a6f158":"code","41f67035":"code","ce75b91e":"code","87352131":"code","7b57b6f3":"code","ce88bab7":"code","905d8b2d":"code","6557686a":"code","2f9af6d0":"code","bd06dc4e":"code","4b69cfe5":"code","f165124d":"code","ae9b0f23":"code","daaebd59":"code","c979e834":"code","4b25e2df":"code","bf642973":"markdown","26d3888e":"markdown","1483e060":"markdown","6ce38371":"markdown","ae93fa63":"markdown","fd300744":"markdown","ca2b434a":"markdown"},"source":{"06e48dd4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","16a6f158":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype\n\ndf = pd.read_csv('..\/input\/insurance-premium-prediction\/insurance.csv')\ndf.head()","41f67035":"df.info()","ce75b91e":"df.describe(include = 'all')","87352131":"num_list = []\ncat_list = []\n\nfor column in df:\n    plt.figure(column, figsize = (5,5))\n    plt.title(column)\n    if is_numeric_dtype(df[column]):\n        df[column].plot(kind = 'hist')\n        num_list.append(column)\n    elif is_string_dtype(df[column]):\n        # show only the TOP 10 value count in each categorical data\n        df[column].value_counts()[:10].plot(kind = 'bar')\n        cat_list.append(column)\n        \nprint(num_list)\nprint(cat_list)","7b57b6f3":"correlation = df.corr()\nsns.heatmap(correlation, cmap = \"GnBu\", annot = True)","ce88bab7":"sns.pairplot(df,height = 2.5)","905d8b2d":"# pairplot with hue\nfor i in range(0, len(cat_list)):\n    hue_cat = cat_list[i]\n    sns.pairplot(df, hue = hue_cat)","6557686a":"# Categorical Data Encoding using One-Hot vs. Label Encoding\n\n# One Hot Encoding using get dummies\n# df = pd.get_dummies(df, columns = cat_list)\n\n# Label Encoding\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelEncoder\n\n\nfor i in cat_list:\n    df[i] = LabelEncoder().fit_transform(df[i])\n\ndf.head()","2f9af6d0":"# log transformation\n\ndf['log_expenses'] = np.log2(df['expenses'] +1)\n\nplt.figure(1)\n\ndf['expenses'].plot(kind = 'hist')\n\nplt.figure(2)\ndf['log_expenses'].plot(kind = 'hist')\n\nprint(df)\ndf = df.drop(['expenses'], axis=1)","bd06dc4e":"# X - input features matrix\nX = df.drop(['log_expenses'], axis=1)\n\n# y - output target vector\ny = df[\"log_expenses\"]\n\n# split into train and test set\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","4b69cfe5":"sns.pairplot(df,height = 1.5)","f165124d":"plt.figure(column, figsize = (10,10))\ncorrelation = df.corr()\nsns.heatmap(correlation, cmap = \"GnBu\", annot = True)","ae9b0f23":"from sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression(normalize = True)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\ncoef = model.coef_\nintercept = model.intercept_\n\nplt.figure(1, figsize = (18,6))\nsns.barplot(x = X_train.columns, y = coef, palette = \"GnBu\")","daaebd59":"# transform expenses predictions to original scale\nexpenses_pred = 2**y_pred\nplt.figure(0)\nsns.histplot(y_pred, bins = 50)\nplt.figure(1)\nsns.histplot(expenses_pred, bins = 50)","c979e834":"import sklearn.metrics as metrics\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\n\n# Error Distribution\nplt.figure()\nsns.histplot((y_test - y_pred), bins = 50 )\n\n# MAE, MSE, RMSE\nprint('MAE:', metrics.mean_absolute_error(y_test, y_pred))\nprint('MSE:', metrics.mean_squared_error(y_test, y_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n\n# R Squared - Coefficient of Determination\nprint('R Squared:', round(model.score(X_test, y_test),2))","4b25e2df":"# Stochastic Gradient Descent (SGD)\n\nfrom sklearn.linear_model import SGDRegressor\n\nsgd_model = SGDRegressor(eta0=0.01, max_iter= 10000, learning_rate = 'adaptive')\nsgd_model.fit(X_train, y_train)\ny_pred = sgd_model.predict(X_test)\n\n\n# model evaluation\nplt.figure()\nsns.histplot((y_test - y_pred), bins = 50)\n\nprint(\"R Squared:\", round(sgd_model.score(X_test, y_test))) \nprint('MAE:', metrics.mean_absolute_error(y_test, y_pred))\nprint('MSE:', metrics.mean_squared_error(y_test, y_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","bf642973":"# Compare with Stochastic Gradient Descent (SGD)","26d3888e":"# A Simple Practical Guide to Linear Regression\nThis notebook provides a practical guide to implement linear regression, walking through the model building lifecycle: EDA, feature engineering, model implementation and model evaluation. Please visit article \"[A Practical Guide to Linear Regression](https:\/\/towardsdatascience.com\/a-practical-guide-to-linear-regression-3b1cb9e501a6)\" for step by step guide or visit [my website](http:\/\/www.visual-design.net) for more articles like this. \n![Linear Regression Cheatsheet](https:\/\/miro.medium.com\/max\/1400\/1*_xszvgfP2xIQz7krzbJMOA.png)","1483e060":"# Linear Regression Model\n- split dataset into train, test\n- build the model\n- transform expenses predictions to original scale","6ce38371":"# EDA\n- correlation analysis\n- pairplot\n- pairplot with hue","ae93fa63":"# Load Dataset","fd300744":"# Model Evaluation\n- error distribution\n- MAE, MSE, RMSE\n- R Squared","ca2b434a":"# Feature Engineering\n- encode categorical data\n- log transformation"}}