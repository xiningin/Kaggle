{"cell_type":{"68887c6f":"code","2245e843":"code","647deebd":"code","2984ed2b":"code","d65c89ad":"code","df6ae5d5":"code","bb63ff34":"code","967a6ac5":"code","5103833f":"code","d429b472":"code","2d423a57":"code","f75cc89d":"code","4a2a4fbe":"code","7ec5881d":"code","8219c83a":"code","79c8d14d":"code","808a6739":"code","0a34e899":"code","f9466fa1":"code","e105bc77":"code","0aaf5496":"code","0ae7d88c":"code","dde07394":"code","93faa504":"code","c7801656":"code","04165188":"code","639fb07b":"code","49b82fa0":"code","d3f0fdfc":"code","eafc18a0":"code","6166b6cf":"code","5662e72b":"code","15c93e34":"code","c46f6a9d":"code","b434372e":"code","c8a873d5":"code","bf59acaf":"code","70a54009":"code","245fd16e":"code","b1a8e06b":"markdown","c2121e6e":"markdown","6f51c0de":"markdown","a8b75379":"markdown","46c60e83":"markdown","15eba4c9":"markdown","d80b0b65":"markdown","184a89eb":"markdown","e5b85341":"markdown","d0699854":"markdown","d7639af2":"markdown","330d9fec":"markdown","fb7b51d3":"markdown","7db0c9b8":"markdown","e177abbc":"markdown","bc0b49ca":"markdown","7b1e636b":"markdown","303f7eef":"markdown","6387ce2d":"markdown","b350e264":"markdown","b608a7f2":"markdown","37596584":"markdown","90e66cdf":"markdown","dfbc6290":"markdown","57c609ba":"markdown","91aa29b4":"markdown","bb64e36c":"markdown","e020a40d":"markdown","b505aef1":"markdown","c2466d96":"markdown","4bc36f4d":"markdown","fbe91642":"markdown","8c99a7bf":"markdown","3557307f":"markdown","7cee31f5":"markdown","6fac465f":"markdown","3fb62fd0":"markdown"},"source":{"68887c6f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2245e843":"# import necessary libraries\n\n# File read and EDA(Data Cleansing & Transformations)\nimport numpy as np  \nimport pandas as pd \n\n# EDA Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns","647deebd":"mc_data = pd.read_json('..\/input\/clothing-fit-dataset-for-size-recommendation\/modcloth_final_data.json', lines=True)\nmc_data.head() # displays first 5 records in the dataframe","2984ed2b":"mc_data.columns = ['item_id', 'waist', 'mc_size', 'quality', 'cup_size', 'hips', 'bra_size', 'category', 'bust', 'height', 'user_name', 'length', 'fit', 'user_id', 'shoe_size', 'shoe_width', 'review_summary', 'review_test']","d65c89ad":"mc_data.info()","df6ae5d5":"missing_data_sum = mc_data.isnull().sum()\nmissing_data = pd.DataFrame({'total_missing_values': missing_data_sum,'percentage_of_missing_values': (missing_data_sum\/mc_data.shape[0])*100})\nmissing_data","bb63ff34":"mc_data.dtypes","967a6ac5":"mc_data.nunique()","5103833f":"def countplot(indipendent_features):\n  plt.figure(figsize=(25, 25))\n  for loc, feature in enumerate(indipendent_features):\n    ax = plt.subplot(3, 4, loc+1)\n    ax.set_xlabel('{}'.format(feature), fontsize=10)\n    chart = sns.countplot(mc_data[feature])\n    chart.set_xticklabels(chart.get_xticklabels(), rotation=90)\n  return None","d429b472":"uniques_data = ['quality', 'cup_size', 'bra_size', 'category', 'length', 'fit',  'shoe_size', 'shoe_width', 'height', 'bust', 'mc_size']\ncountplot(uniques_data)","2d423a57":"# replacing bust unformatted value with mean 38 which is taken from the values 37 & 39 \nmc_data.at[mc_data[mc_data.bust == '37-39'].index[0],'bust'] = '38'","f75cc89d":"def height_in_cms(ht):\n  if ht.lower() != 'nan':\n    ht = ht.replace('ft','').replace('in', '')\n    h_ft = int(ht.split()[0])\n    if len(ht.split()) > 1:\n      h_inch = int(ht.split()[1])\n    else:\n      h_inch = 0\n    h_inch += h_ft * 12\n    h_cm = round(h_inch * 2.54, 1)\n    return h_cm\n\nmc_data.height = mc_data.height.astype(str).apply(height_in_cms)\nmc_data.head()","4a2a4fbe":"mc_data.height.fillna(value=mc_data.height.mean(), inplace=True)\nmc_data.height.isnull().sum()","7ec5881d":"def plot_outlier(feature):\n  plt.figure(figsize=(25, 6))\n  ax = sns.boxplot(x=feature, linewidth=2.5)\nplot_outlier(mc_data.height)","8219c83a":"def get_outliers_range(datacolumn):\n  sorted(datacolumn)\n  Q1,Q3 = np.percentile(datacolumn , [25,75])\n  IQR = Q3 - Q1\n  lower_range = Q1 - (1.5 * IQR)\n  upper_range = Q3 + (1.5 * IQR)\n  return lower_range,upper_range","79c8d14d":"\nht_lower_range,ht_upper_range = get_outliers_range(mc_data.height)\nht_lower_range,ht_upper_range","808a6739":"mc_data[(mc_data.height < ht_lower_range) | (mc_data.height > ht_upper_range)]","0a34e899":"mc_df = mc_data.drop(mc_data[(mc_data.height < ht_lower_range) | (mc_data.height > ht_upper_range)].index)\n\nmc_df.reset_index(drop=True, inplace=True)\nmc_df.shape","f9466fa1":"plot_outlier(mc_df.height)","e105bc77":"def plot_dist(df, indipendent_features):\n  plt.figure(figsize=(25, 20))\n  for loc, feature in enumerate(indipendent_features):\n    ax = plt.subplot(3, 3, loc+1)\n    sns.distplot(df[feature]) # you can try histplot as well\n  return None","0aaf5496":"plot_dist(mc_data, ['height', 'waist', 'mc_size', 'quality', 'hips', 'bra_size', 'shoe_size'])","0ae7d88c":"from sklearn.impute import KNNImputer\nimputer = KNNImputer(n_neighbors=10)\n\n# finding imputation using other features (it will take couple of minutes to complete the execution)\nmc_data_knn_ind_features = mc_df[['waist', 'hips', 'bra_size', 'bust', 'height', 'shoe_size']]\n\ndf_filled = imputer.fit_transform(mc_data_knn_ind_features)\n\n\nknn_numeric_imputations = pd.DataFrame(data=df_filled, columns=['waist', 'hips', 'bra_size', 'bust', 'height', 'shoe_size'])\n\n\n# remove the existing numeric columns (waist, height, hips, bra_size, bust, shoe_size ) from the main dataframe and concatenate  with knn imputed data\n#mc_df = mc_data\nmc_new_df = mc_df.drop(['waist', 'hips', 'bra_size', 'bust', 'height', 'shoe_size'], axis=1)\n\n\n","dde07394":"# concat the imputations data with mc data frame\nmc = pd.concat([mc_new_df, knn_numeric_imputations], axis=1)\nmc.isnull().sum()","93faa504":"plot_outlier(mc.shoe_size)","c7801656":"ss_lower_range,ss_upper_range = get_outliers_range(mc.shoe_size)\n#print(ss_lower_range,ss_upper_range)\n\nmc.drop(mc[(mc.shoe_size < ss_lower_range) | (mc.shoe_size > ss_upper_range)].index, axis=0, inplace=True) # found 390 observations \nplot_outlier(mc.shoe_size)","04165188":"def convert_cup_size_to_cms(cup_size_code):\n  if cup_size_code == 'aa':\n    return 10, 11\n  if cup_size_code == 'a':\n    return 12, 13\n  if cup_size_code == 'b':\n    return 14, 15\n  if cup_size_code == 'c':\n    return 16, 17\n  if cup_size_code == 'd':\n    return 18, 19\n  if cup_size_code == 'dd\/e':\n    return 20, 21\n  if cup_size_code == 'ddd\/f':\n    return 22, 23\n  if cup_size_code == 'dddd\/g':\n    return 24, 25\n  if cup_size_code == 'h':\n    return 26, 27\n  if cup_size_code == 'i':\n    return 28, 29\n  if cup_size_code == 'j':\n    return 30, 31\n  if cup_size_code == 'k':\n    return 32, 33 \n  else:\n    return str('unknown')","639fb07b":"mc['cup_size_in_cms'] = mc.cup_size.apply(convert_cup_size_to_cms)\nmc.head()","49b82fa0":"def split_cup_size_data(data, index):\n  if data.lower() == 'unknown':\n    return 0\n  value = data.replace('(','').replace(')','').replace(',','')\n  return value.split()[index]\n\nmc['cup_size_start_in_cms'] =  mc.cup_size_in_cms.astype(str).apply(lambda x : split_cup_size_data(x, 0))\nmc['cup_size_end_in_cms'] =  mc.cup_size_in_cms.astype(str).apply(lambda x : split_cup_size_data(x, 1))\nmc.head()","d3f0fdfc":"mc['cup_size_start_in_cms'] = mc.cup_size_start_in_cms.astype('int')\nmc['cup_size_end_in_cms'] = mc.cup_size_end_in_cms.astype('int')\n\n\n# missing values imputation with mean\nmc['cup_size_start_in_cms']  = mc.cup_size_start_in_cms.mask(mc.cup_size_start_in_cms==0).fillna(value=mc.cup_size_start_in_cms.mean())\nmc['cup_size_end_in_cms']  = mc.cup_size_end_in_cms.mask(mc.cup_size_end_in_cms==0).fillna(value=mc.cup_size_end_in_cms.mean())","eafc18a0":"mc[mc.cup_size.isnull()]","6166b6cf":"# drop the columns which are used for reference\nmc = mc.drop(['cup_size', 'cup_size_in_cms'], axis = 1)\nmc.reset_index(drop=True,  inplace=True)","5662e72b":"def countplot_wrt_target(indipendent_features, df):\n  plt.figure(figsize=(28, 10))\n  for loc, feature in enumerate(indipendent_features):\n    ax = plt.subplot(1, 3, loc+1)\n    ax.set_xlabel('{}'.format(feature), fontsize=10)\n    chart = sns.countplot(x=df[feature], hue=df.fit)\n    chart.set_xticklabels(chart.get_xticklabels(), rotation=90)\n  return None\n","15c93e34":"countplot_wrt_target(['category', 'length', 'quality'], mc)","c46f6a9d":"# fill NaN with average shoe width category (this is just an assumption)\nmc.shoe_width = mc.shoe_width.fillna('average')","b434372e":"# Use above chart to convert shoe width data such as 'wide','average','narrow' to inches\nmc['shoe_width_in_inches'] = np.where(((mc.shoe_size >= 5) & (mc.shoe_size < 5.5)) & (mc.shoe_width == 'narrow') , 2.81, \nnp.where(((mc.shoe_size >= 5) & (mc.shoe_size < 5.5)) & (mc.shoe_width == 'average') , 3.19, \nnp.where(((mc.shoe_size >= 5) & (mc.shoe_size < 5.5)) & (mc.shoe_width == 'wide') , 3.56,\nnp.where(((mc.shoe_size >= 5.5) & (mc.shoe_size < 6)) & (mc.shoe_width == 'narrow') , 2.87, \nnp.where(((mc.shoe_size >= 5.5) & (mc.shoe_size < 6)) & (mc.shoe_width == 'average') , 3.25, \nnp.where(((mc.shoe_size >= 5.5) & (mc.shoe_size < 6)) & (mc.shoe_width == 'wide') , 3.62, \nnp.where(((mc.shoe_size >= 6) & (mc.shoe_size < 6.5)) & (mc.shoe_width == 'narrow') , 2.94, \nnp.where(((mc.shoe_size >= 6) & (mc.shoe_size < 6.5)) & (mc.shoe_width == 'average') , 3.31, \nnp.where(((mc.shoe_size >= 6) & (mc.shoe_size < 6.5)) & (mc.shoe_width == 'wide') , 3.69,\nnp.where(((mc.shoe_size >= 6.5) & (mc.shoe_size < 7)) & (mc.shoe_width == 'narrow') , 3, \nnp.where(((mc.shoe_size >= 6.5) & (mc.shoe_size < 7)) & (mc.shoe_width == 'average') , 3.37, \nnp.where(((mc.shoe_size >= 6.5) & (mc.shoe_size < 7)) & (mc.shoe_width == 'wide') , 3.75,\nnp.where(((mc.shoe_size >= 7) & (mc.shoe_size < 7.5)) & (mc.shoe_width == 'narrow') , 3.06, \nnp.where(((mc.shoe_size >= 7) & (mc.shoe_size < 7.5)) & (mc.shoe_width == 'average') , 3.44, \nnp.where(((mc.shoe_size >= 7) & (mc.shoe_size < 7.5)) & (mc.shoe_width == 'wide') , 3.81, \nnp.where(((mc.shoe_size >= 7.5) & (mc.shoe_size < 8)) & (mc.shoe_width == 'narrow') , 3.12, \nnp.where(((mc.shoe_size >= 7.5) & (mc.shoe_size < 8)) & (mc.shoe_width == 'average') , 3.5, \nnp.where(((mc.shoe_size >= 7.5) & (mc.shoe_size < 8)) & (mc.shoe_width == 'wide') , 3.87, \nnp.where(((mc.shoe_size >= 8) & (mc.shoe_size < 8.5)) & (mc.shoe_width == 'narrow') , 3.19, \nnp.where(((mc.shoe_size >= 8) & (mc.shoe_size < 8.5)) & (mc.shoe_width == 'average') , 3.56, \nnp.where(((mc.shoe_size >= 8) & (mc.shoe_size < 8.5)) & (mc.shoe_width == 'wide') , 3.94, \nnp.where(((mc.shoe_size >= 8.5) & (mc.shoe_size < 9)) & (mc.shoe_width == 'narrow') , 3.25, \nnp.where(((mc.shoe_size >= 8.5) & (mc.shoe_size < 9)) & (mc.shoe_width == 'average') , 3.62, \nnp.where(((mc.shoe_size >= 8.5) & (mc.shoe_size < 9)) & (mc.shoe_width == 'wide') , 4, \nnp.where(((mc.shoe_size >= 9) & (mc.shoe_size < 9.5)) & (mc.shoe_width == 'narrow') , 3.37, \nnp.where(((mc.shoe_size >= 9) & (mc.shoe_size < 9.5)) & (mc.shoe_width == 'average') , 3.69, \nnp.where(((mc.shoe_size >= 9) & (mc.shoe_size < 9.5)) & (mc.shoe_width == 'wide') , 4.06, \nnp.where(((mc.shoe_size >= 9.5) & (mc.shoe_size < 10)) & (mc.shoe_width == 'narrow') , 3.37, \nnp.where(((mc.shoe_size >= 9.5) & (mc.shoe_size < 10)) & (mc.shoe_width == 'average') , 3.75, \nnp.where(((mc.shoe_size >= 9.5) & (mc.shoe_size < 10)) & (mc.shoe_width == 'wide') , 4.12, \nnp.where(((mc.shoe_size >= 10) & (mc.shoe_size < 10.5)) & (mc.shoe_width == 'narrow') , 3.44, \nnp.where(((mc.shoe_size >= 10) & (mc.shoe_size < 10.5)) & (mc.shoe_width == 'average') , 3.75, \nnp.where(((mc.shoe_size >= 10) & (mc.shoe_size < 10.5)) & (mc.shoe_width == 'wide') , 4.19, \nnp.where(((mc.shoe_size >= 10.5) & (mc.shoe_size < 11)) & (mc.shoe_width == 'narrow') , 3.5, \nnp.where(((mc.shoe_size >= 10.5) & (mc.shoe_size < 11)) & (mc.shoe_width == 'average') , 3.87, \nnp.where(((mc.shoe_size >= 10.5) & (mc.shoe_size < 11)) & (mc.shoe_width == 'wide') , 4.19, \nnp.where(((mc.shoe_size >= 11) & (mc.shoe_size < 12)) & (mc.shoe_width == 'narrow') , 3.56, \nnp.where(((mc.shoe_size >= 11) & (mc.shoe_size < 12)) & (mc.shoe_width == 'average') , 3.94, \nnp.where(((mc.shoe_size >= 11) & (mc.shoe_size < 12)) & (mc.shoe_width == 'wide') , 4.19,\nnp.nan)))))))))))))))))))))))))))))))))))))))","c8a873d5":"# drop the refrence colum shoe_width\nmc.drop(['shoe_width'], axis=1, inplace=True)","bf59acaf":"# lets replace NaN values with unknown for the feature length\nmc.length = mc.length.fillna('unknown')","70a54009":"# apply one hot encoding using dummies\n\nlength_dummies  = pd.get_dummies(mc['length'])\nlength_dummies.columns = ['just_right','slightly_long','very_short','slightly_short','very_long', 'length_unkown']\n\ncategory_dummies  = pd.get_dummies(mc['category'])\ncategory_dummies.columns = ['new','dresses','wedding','sale','tops', 'bottoms','outerwear']\n\nmodel_input_df = pd.concat([mc, length_dummies,category_dummies], axis = 1)\nmodel_input_df.drop(['length'], axis=1, inplace=True)\nmodel_input_df.drop(['category'], axis=1, inplace=True)\n\n# target variable \nfit = {'small':0, 'fit':1, 'large':2}\nmodel_input_df['fit'] = model_input_df['fit'].map(fit)\n","245fd16e":"# since there is no value add to the features like item_id , user_id and user_name\n\nmodel_input_df.drop(['item_id'], axis=1, inplace=True)\n\nmodel_input_df.drop(['user_id'], axis=1, inplace=True)\n\nmodel_input_df.drop(['user_name'], axis=1, inplace=True)\nmodel_input_df.head()","b1a8e06b":"# Column names are inconsistent\nSome of the column names are having space and rest of them are having underscore in between them. Hence try to be consistent by adding underscore instead of space\n\n> for your information, size is the keyword in pandas , make sure to change the feature name \"size\" to some user defined name like \"mc_size\"\nhttps:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.size.html","c2121e6e":"> Check Data types which are having numerical\/categorical data","6f51c0de":"*Out of 18 columns, only 6 columns have complete data. And columns such as waist , bust, shoe_size, show_width and hips are highly sparse*","a8b75379":"# feature shoe_width : used open source data to identify shoe width based on shoe size\n\n![image.png](attachment:image.png)\n\nReference link : https:\/\/images-na.ssl-images-amazon.com\/images\/I\/71u90X9oX3S.pdf","46c60e83":"## EDA - Exploratory Data Analysis","15eba4c9":"# Height feature - Convert US units to Metric units (ft & in to cm).","d80b0b65":"> lets try to see the visualization for categorical data against the dependent feature fit\n","184a89eb":"> Take Away \"There are 199 outliers\". which is 0.2% of total number observations. Hence we can remove\/drop\/delete these outliers","e5b85341":"clearly, there are few outliers, using IQR cutoff range values remove there observations","d0699854":"![image.png](attachment:image.png)\nsource taken from https:\/\/www.blitzresults.com\/en\/bra-size\/\n\nAdding two new columns for the feture \"cup_size\" in order to convert the measurements into centimeters and then imputing missing values with mean values. ","d7639af2":"# Unique number of observations for each feature","330d9fec":"# Applied one-hot encoding for the features length & category ","fb7b51d3":"# Numeric features distributions Visualization ","7db0c9b8":"*With this, we can clearly understand there is no unique data entirely for one feature to make the index if any.\nAnd just to make a note the columns item_id and user_id are repeating.*","e177abbc":"*pandas library identifies item_id, waist, mc_size, quality, hips, bra_size, user_id, shoe_size are numeric And cup_size, category, bust, height, user_name, length, fit, shoe_width, review_summary , review_test are object type . Take away from this is \"There are some numeric data columns are fall under Object types\" . Hence we need to handle the misclassification of these data types. For example, bust data contains numeric values but its dtype is Object.*","bc0b49ca":"> lets double check the NaN values imputations for the newly added features","7b1e636b":"\n### This notebook is intended for Data Preprocessing\/EDA\/Feature Engineering practice purpose. Feel free to comment the best practices if any. \n\n\n> #### Thanks for your time by Soujanya G","303f7eef":"# Read input json data","6387ce2d":"*Few observations*\n* cup_size contains some format which might represents the measurement\n* shoe_size 38 is an outlier , there we can see lot of variance \n* height column also having few outliers (May be we can see those things after converting categorical data into numeric values)\n* there are categorical data exists such as shoe_width, category, length, fit and height. \n* For the feature bust - clearly there is one observation with different data, hence we need to format it i.e \"37 - 39\". Will try to replace this value with mean\n","b350e264":"> If the dataset is having less number of observations then we can see the unique data resides in each feature(There are 82790 observations)","b608a7f2":"> Take away \"there are so many outliers\" exists. Here I have used Inter Quartile Range calculation to find the lower range and upper range cutoff. \nSo the outlier would be anything less than the lower range cutoff(144.7) or anything more than the upper range cutoff(185.5) is an outlier.  \\\n\nNote: there are different techniques to identify the outliers \nPlease check out this link for more details on this\nhttps:\/\/statisticsbyjim.com\/basics\/outliers\/\n","37596584":"> Check the lower and upper cutoff range values for the outliers","90e66cdf":"> we successfully converted metrics to centimetres. Now lets handle the missing values with mean imputation and then look into the outliers for this height feature. Use box\/scatter plot for outliers visualization","dfbc6290":"# Sparse Data\n\nGiven data is having lot of missing values , for example look at the columns such as shoe_size and show_width.\n\n> lets check the missing values percentage for each feature","57c609ba":"# **About the dataset**\n\nIn this notebook, we will use modcloth_final_data.json as input dataset","91aa29b4":"# Conclusion:\n\n* Applied knn algorithm to impute the missing numeric feature data\n* Used one-hot encoding for categorical feature data\n* Handled outliers using IQR\n* Transformed categorical measurement data into numerical format\n* Left with text data imputation such as review_summary & review_test. \n* Apply PCA if you want to reduce the number of features for further modelling\n* for the better visualization, please refer to Aditya Agrawal's notebook. (it does not make any sense to rebuild the visualization after seeing this kernel)\nhttps:\/\/www.kaggle.com\/agrawaladitya\/step-by-step-data-preprocessing-eda#EDA---Exploratory-Data-Analysis\n\n\n\n## Happy learning!!\n##### something is better than nothing...\n","bb64e36c":"## Categorical data to Numeric using one-hot encoding","e020a40d":"> when we dont find any ascending\/descending order between the category values one way to overcome this problem is \"by using one hot encoding\".\n\n> \n","b505aef1":"# Handling shoe-size outliers","c2466d96":"# Missing Values Handling for numeric features\n\n> as we see there are lot of missing values in this dataset. Since the data is highly sparse, i am trying to use KNN algorith to impute the relavant features.","4bc36f4d":"# Transform some of categorical variables to numeric ","fbe91642":"> Lets count how many outliers exists for this height feature\n","8c99a7bf":"> Lets look again the height feature using box plot to see the handling of outlier ","3557307f":"> we successfully done the imputations for some of the numeric features","7cee31f5":"> see the total number of observations, column names and datatypes info ","6fac465f":"### feature : Cup size - used open source data to convert measurements into numerical data","3fb62fd0":"> Lets look into unique observations which are having less uniqueness"}}