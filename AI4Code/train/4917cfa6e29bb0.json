{"cell_type":{"d04fe083":"code","245c5efd":"code","73bf90f3":"code","782e352e":"code","26c57add":"code","442c8c21":"code","b5b2e7c2":"code","6dd197f7":"code","4388766f":"code","59b1750d":"code","6121cfd5":"code","afda9fc4":"code","b68c89b0":"code","c0d0bf41":"code","d4b6ec8e":"markdown","69b63b83":"markdown","f2d60b9e":"markdown","58df1f49":"markdown","50a7691a":"markdown","19603e02":"markdown","3e82e1d3":"markdown","5f41b2cd":"markdown","291481ba":"markdown","a046546c":"markdown","c382ff42":"markdown"},"source":{"d04fe083":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, Flatten, Input, Conv2D, MaxPool2D, BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","245c5efd":"# load data\nX = np.load('..\/input\/Sign-language-digits-dataset\/X.npy')\nY = np.load('..\/input\/Sign-language-digits-dataset\/Y.npy')\nimg_size = 64\nprint('X shape: ',X.shape)\nprint('Y shape: ',Y.shape)","73bf90f3":"# sample data representation\nplt.subplot(1, 2, 1)\nplt.imshow(X[700], cmap = 'gray')\nplt.axis('off')\nplt.subplot(1, 2, 2)\nplt.imshow(X[900], cmap = 'gray')\nplt.axis('off')\nplt.show()","782e352e":"datagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.10,\n    height_shift_range=0.10,\n    zoom_range=0.10\n)","26c57add":"# test and train splite\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)\nprint('x_train shape: ',x_train.shape)\nprint('x_test shape: ',x_test.shape)\n# axis representing grey-scale\nx_train = x_train[:, :, :, np.newaxis]\nx_test = x_test[:, :, :, np.newaxis]\nprint('x_train shape: ',x_train.shape)\nprint('x_test shape: ',x_test.shape)","442c8c21":"# We fit the data generator with our training data.\ndatagen.fit(x_train)","b5b2e7c2":"# Create CNN model\nmodel = Sequential()\n# firs layer\nmodel.add(Conv2D(filters = 64, kernel_size = (4,4),padding = 'Same', \n                 activation ='relu', input_shape = (64,64,1)))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.3))\n# second layer\nmodel.add(Conv2D(filters = 64, kernel_size = (4,4),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=(2,2)))\nmodel.add(Dropout(0.3))\n# fully connected\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","6dd197f7":"# Change the learning rate\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)","4388766f":"# model compile\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","59b1750d":"history1 = model.fit(x_train, y_train, batch_size=32, epochs=10)\nscore = model.evaluate(x_test, y_test, verbose=0)","6121cfd5":"print('Loss: {:.4f}  Accuaracy: {:.4}%'.format(score[0],score[1]))\nplt.plot(history1.history['loss'], color='b', label=\"validation loss\")\nplt.title(\"Test Loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","afda9fc4":"model.compile(loss='categorical_crossentropy',optimizer = optimizer ,metrics=['accuracy'])\nhistory2 = model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),steps_per_epoch=64, epochs=10)\nscore = model.evaluate(x_test, y_test, verbose=0)","b68c89b0":"print('Loss: {:.4f}  Accuaracy: {:.4}%'.format(score[0],score[1]))\n# Plot the loss and accuracy curves for training and validation \nplt.plot(history2.history['loss'], color='b', label=\"validation loss\")\nplt.title(\"Test Loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","c0d0bf41":"# confusion matrix\n# Predict the values from the validation dataset\nY_pred = model.predict(x_test)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(y_test,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","d4b6ec8e":"# Load Data\n* In this data there are 2062 sign language digits images.\n* At the beginning of tutorial we will use only sign 0 and 1 for simplicity. \n* In data, sign zero is between indexes 204 and 408. Number of zero sign is 205.\n* Also sign one is between indexes 822 and 1027. Number of one sign is 206. Therefore, we will use 205 samples from each classes(labels).\n* Lets prepare our X and Y arrays. X is image array (zero and one signs) and Y is label array (0 and 1).","69b63b83":"# INTRODUCTION\n* I wouldn't try my second deep learning experience.\n* I created and tested a convolutional neural network model using the Keras library.\n* I wish you good readings.","f2d60b9e":"# Data Split Train And Test\n* We divide 80% of our data into training and 20% test data.","58df1f49":"# Content\n* Introduction\n* Import Library\n* Load Data\n* Sample Data Representation\n* Data Augmentation\n* Data Split Train And Test\n*  Create Convolutional Neural Network Model\n* Conclusion","50a7691a":"* Let's visualize our model's predictions.","19603e02":"# Data Augmentation\nIf we have larger and diverse data in machine learning, we can better train our models. In order to achieve this in image processing, we can diversify our data by rotating, moving, zooming in or out of the images.","3e82e1d3":"* We will first train our model with real data.","5f41b2cd":"* We are now training our model with the data we transform.","291481ba":"# Create Convolutional Neural Network Model\n* conv => max pool => dropout => conv => max pool => dropout => fully connected\n* Our deep learning model consists of two hidden layers.","a046546c":"# Sample Data Representation\n* We are plotting our sample data.","c382ff42":"# Conclusion\n* A notebook I've made to try what I've learned more about deep learning and try to better understand deep learning.\n* I'm new to programming. I'm even more new in data science, machine learning, deep learning and artificial intelligence. But I am working. And I'il be an artificial intelligence developer. Your comments are very important to me.\n* Thank you for reading my notebook. Waiting for your criticism."}}