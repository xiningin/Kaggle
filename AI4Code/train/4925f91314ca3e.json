{"cell_type":{"8a974bbd":"code","14b56412":"code","73a804e7":"code","b141f062":"code","0c3b177c":"code","ead63315":"code","469eca72":"code","2c2f91c2":"code","8b0bbb6d":"code","8cf942ea":"code","3f5d8446":"code","42cb80a9":"code","0ee20c16":"code","8bae33a1":"code","97f3beda":"code","7e05159c":"code","8ff0b21f":"code","b14b21e1":"code","a0b70eb9":"code","cd12d8e5":"code","d1247604":"code","ce9939e6":"markdown","4c3fccdc":"markdown"},"source":{"8a974bbd":"import numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns\nimport cv2\nfrom os import listdir\nfrom os.path import isfile, join\nimport yaml","14b56412":"import torch\nfrom IPython.display import Image, clear_output","73a804e7":"# shutil.copytree, essential but can run only once\nif  'yolov5' in os.listdir('\/kaggle\/working\/'):\n    print('WOW')\nelse:\n    shutil.copytree('\/kaggle\/input\/yolov5-official-v31-dataset\/yolov5', '\/kaggle\/working\/yolov5') ","b141f062":"os.chdir('\/kaggle\/working\/yolov5')\nclear_output()\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","0c3b177c":"os.listdir('\/kaggle\/working\/')","ead63315":"#!rm -rf sample1","469eca72":"# shutil.copytree, essential but can run only once\nif 'sample1' in os.listdir('\/kaggle\/working\/'):\n    print('exist1')\nelse:\n    shutil.copytree('\/kaggle\/input\/stanford-dogs-dataset\/images\/Images\/n02091244-Ibizan_hound', '\/kaggle\/working\/sample1')","2c2f91c2":"!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source ..\/sample1\/ --save-txt --save-conf","8b0bbb6d":"!ls","8cf942ea":"!ls runs\/detect\/exp3\/labels","3f5d8446":"#!rm -rf \/kaggle\/working\/yolov5\/runs\/detect\/exp\n#!rm -rf \/kaggle\/working\/yolov5\/runs\/detect\/exp2\n#!rm -rf \/kaggle\/working\/yolov5\/runs\/detect\/exp3","42cb80a9":"a=np.loadtxt('\/kaggle\/working\/yolov5\/runs\/detect\/exp\/labels\/n02091244_3315.txt')\nprint(a)\n# last column is confidence value","0ee20c16":"from matplotlib import animation, rc\nrc('animation', html='jshtml')","8bae33a1":"def create_animation(ims):\n    fig=plt.figure(figsize=(7,7))\n    #plt.axis('off')\n    im=plt.imshow(cv2.cvtColor(ims[5],cv2.COLOR_BGR2RGB))\n    \n    def animate_func(i):\n        im.set_array(cv2.cvtColor(ims[i],cv2.COLOR_BGR2RGB))\n        return [im]\n\n    return animation.FuncAnimation(fig, animate_func, frames=len(ims), interval=1000)","97f3beda":"imgdir1 ='\/kaggle\/working\/yolov5\/runs\/detect\/exp\/' ","7e05159c":"paths0=[]\nfor dirname, _, filenames in os.walk(imgdir1):\n    for filename in filenames:\n        paths0+=[os.path.join(dirname, filename)]     \npaths0[0:5]","8ff0b21f":"paths1=[]\nfor item in paths0:\n    if item[-4:]=='.jpg':\n        paths1+=[item]\npaths1[0:5]","b14b21e1":"order=[]\nfor item in paths1:\n    order+=[int(item[0:-4].split('_')[-1])]\npaths2=pd.DataFrame(paths1)\npaths2[1]=order\npaths2.columns=['path','int']\npaths2=paths2.sort_values('int')\npaths3=paths2['path'].tolist()\npaths3[0:5]","a0b70eb9":"images0=[]\nfor i in tqdm(range(0,len(paths3),1)):\n    images0+=[cv2.imread(paths3[i])]","cd12d8e5":"print(len(images0))","d1247604":"create_animation(np.array(images0))","ce9939e6":"# YOLOv5","4c3fccdc":"# Create animation"}}