{"cell_type":{"4041d9aa":"code","a756a535":"code","ae9ec2cb":"code","dfe3346b":"code","7cb992a3":"code","24c123a3":"code","0abf37dd":"code","f66ea539":"code","45b59ba0":"code","3498afe7":"code","1f46aa98":"code","0a6ef0e3":"code","bf74334f":"code","c49be0dd":"code","59792e8a":"code","38ff4464":"code","e6c5aa7e":"code","7ceefb5c":"code","af1980cd":"code","9695cb72":"code","39a1fd52":"code","0ea03130":"code","a16a650c":"code","047e2532":"code","35ea3368":"code","442358d8":"code","fd4b84e8":"code","0d47b2b4":"code","1f42944f":"code","c3b07b30":"code","9c42076b":"code","956abdb4":"code","f7fe7fb3":"code","8704256c":"code","c6de9932":"code","3f8527f1":"code","907c8d96":"code","b0ccbfbd":"code","0d32c7a6":"code","9d9900f2":"code","dce24fa7":"code","093caf00":"code","05d8312f":"code","cb8e6198":"code","c09dff6b":"code","37ea0f78":"code","3b093526":"code","6fa3980c":"code","ffb802f3":"code","219e9043":"code","9af7c4e7":"code","51b35ecc":"code","978de8e4":"code","13a605bc":"code","76c81142":"code","9c9dedea":"code","41f34a6a":"code","016555dd":"code","57332606":"code","5b019d97":"code","9d9f4e23":"code","25a2c8d3":"code","797d3729":"markdown","a2acd191":"markdown","db3da491":"markdown","4d0ffdd7":"markdown","0b706cf6":"markdown","b7a407ef":"markdown","74e374cd":"markdown","dbb071fa":"markdown","70e58cad":"markdown","4e74a72c":"markdown","cc728905":"markdown","ec663bcc":"markdown","da65d008":"markdown","7160491d":"markdown","7c9b0ebc":"markdown","f49d40c4":"markdown","b5689b17":"markdown","b609a2f1":"markdown"},"source":{"4041d9aa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a756a535":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntrain.head()","ae9ec2cb":"train.info()","dfe3346b":"train.isnull().sum()","7cb992a3":"test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest.head()","24c123a3":"test.info()","0abf37dd":"test.isnull().sum()","f66ea539":"gender_submission = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\ngender_submission.head()","45b59ba0":"gender_submission.info()","3498afe7":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set() # setting seaborn default for plots","1f46aa98":"import matplotlib.ticker as mtick\nimport matplotlib.pyplot as plt\n\ndef bar_chart(feature):\n    train.groupby(['Survived',feature]).size().groupby(level=0).apply(\n        lambda x: 100 * x \/ x.sum()\n    ).unstack().plot(kind='bar',stacked=True)\n\n    plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter())\n    plt.show()","0a6ef0e3":"bar_chart('Sex')","bf74334f":"bar_chart('Pclass')","c49be0dd":"bar_chart('SibSp')","59792e8a":"bar_chart('Parch')","38ff4464":"bar_chart('Embarked')","e6c5aa7e":"train_test_data = [train, test]","7ceefb5c":"for dataset in train_test_data:\n    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","af1980cd":"train['Title'].value_counts()","9695cb72":"test['Title'].value_counts()","39a1fd52":"title_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2}\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Title'].map(title_mapping).fillna(3)","0ea03130":"train['Title'].value_counts(dropna=False)","a16a650c":"bar_chart('Title')","047e2532":"sex_mapping = {\"male\": 0, \"female\": 1}\nfor dataset in train_test_data:\n    dataset['Sex'] = dataset['Sex'].map(sex_mapping)","35ea3368":"bar_chart('Sex')","442358d8":"train['Age'].value_counts(dropna=False)","fd4b84e8":"# fill missing age with median age for each title (Mr, Mrs, Miss, Others)\nfor dataset in train_test_data:\n    dataset[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)","0d47b2b4":"train['Age'].value_counts(dropna=False)","1f42944f":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\n \nplt.show()","c3b07b30":"for dataset in train_test_data:\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 24), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 24) & (dataset['Age'] <= 34), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 34) & (dataset['Age'] <= 62), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 62, 'Age'] = 4","9c42076b":"bar_chart('Age')","956abdb4":"### Embarked","f7fe7fb3":"for dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')","8704256c":"embarked_mapping = {\"S\": 0, \"C\": 1, \"Q\": 2}\nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)","c6de9932":"# fill missing Fare with median fare for each Pclass\ntrain[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntest[\"Fare\"].fillna(test.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntrain.head(50)","3f8527f1":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\n \nplt.show()","907c8d96":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0, 100)\n","b0ccbfbd":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(15, 20)","0d32c7a6":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(20, 30)","9d9900f2":"for dataset in train_test_data:\n    dataset.loc[ dataset['Fare'] <= 17, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 17) & (dataset['Fare'] <= 30), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 100), 'Fare'] = 2\n    dataset.loc[ dataset['Fare'] > 100, 'Fare'] = 3","dce24fa7":"bar_chart('Fare')","093caf00":"train['Cabin'].value_counts()","05d8312f":"for dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].str[:1]","cb8e6198":"bar_chart('Cabin')","c09dff6b":"cabin_mapping = {\n    \"A\": 0,\n    \"B\": 1,\n    \"C\": 2,\n    \"D\": 3,\n    \"E\": 4,\n    \"F\": 5,\n    \"G\": 6,\n    \"T\": 7\n}\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].map(cabin_mapping)\n    dataset['Cabin'] = dataset['Cabin'].fillna(8)","37ea0f78":"train['Cabin'].value_counts(dropna=False)","3b093526":"for dataset in train_test_data:\n    dataset[\"FamilySize\"] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1","6fa3980c":"features_drop = ['Name', 'Ticket', 'SibSp', 'Parch']\ntrain = train.drop(features_drop, axis=1)\ntest = test.drop(features_drop, axis=1)\ntrain = train.drop(['PassengerId'], axis=1)","ffb802f3":"train.info()","219e9043":"test.info()","9af7c4e7":"train_data = train.drop('Survived', axis=1)\ntarget = train['Survived']\n\ntrain_data.shape, target.shape","51b35ecc":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n\nimport numpy as np","978de8e4":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)","13a605bc":"def mean(score):\n    return round(np.mean(score)*100, 2)","76c81142":"clf = KNeighborsClassifier(n_neighbors = 13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(f'score = {score}',\n      f'\\n\\n' +\n      f'mean = {mean(score)}')","9c9dedea":"clf = DecisionTreeClassifier()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(f'score = {score}',\n      f'\\n\\n' +\n      f'mean = {mean(score)}')","41f34a6a":"clf = RandomForestClassifier(n_estimators=13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(f'score = {score}',\n      f'\\n\\n' +\n      f'mean = {mean(score)}')","016555dd":"clf = GaussianNB()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(f'score = {score}',\n      f'\\n\\n' +\n      f'mean = {mean(score)}')","57332606":"clf = SVC()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(f'score = {score}',\n      f'\\n\\n' +\n      f'mean = {mean(score)}')","5b019d97":"clf = SVC()\nclf.fit(train_data, target)\n\ntest_data = test.drop(\"PassengerId\", axis=1).copy()\nprediction = clf.predict(test_data)","9d9f4e23":"submission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": prediction\n    })\n\nsubmission.to_csv('submission.csv', index=False)","25a2c8d3":"submission = pd.read_csv('submission.csv')\nsubmission.head()","797d3729":"## Name","a2acd191":"# References\n\nThis notebook is created by learning from the following notebooks:\n* [minsuk-heo \/ kaggle-titanic](https:\/\/github.com\/minsuk-heo\/kaggle-titanic\/blob\/master\/titanic-solution.ipynb)","db3da491":"## Cabin","4d0ffdd7":"# Create the models","0b706cf6":"Binning\/Converting Numerical Age to Categorical Variable\n\nfeature vector map:\n* child: 0\n* young: 1\n* adult: 2\n* mid-age: 3\n* senior: 4","b7a407ef":"# Explore the data","74e374cd":"## Fare","dbb071fa":"## Naive Bayes","70e58cad":"# Titanic Survivors\n1. Explore the data\n2. Implement features\n3. Create the models\n4. Test the models\n5. References","4e74a72c":"## Age","cc728905":"## Ramdom Forest","ec663bcc":"## Sex","da65d008":"## Family Size","7160491d":"## SVM","7c9b0ebc":"## Decision Tree","f49d40c4":"# Prepare the data","b5689b17":"## kNN","b609a2f1":"# Testing"}}