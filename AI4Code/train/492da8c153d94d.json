{"cell_type":{"e9805bb8":"code","2eb654e6":"code","529b91c4":"code","b9a9dc20":"code","f89be6ce":"code","7d440bab":"code","68ac4ef1":"code","beaeee1d":"code","42a34d55":"code","bccade71":"code","1a0bf601":"code","425cc1d2":"code","ac8c785d":"code","09ca725d":"code","bd78e75b":"code","ada436d8":"code","a889606c":"code","51868758":"code","0f928ff2":"code","c61d5348":"code","b9428b43":"code","f4318c8c":"code","ea31e901":"code","ccf6e282":"code","7c44415e":"code","becf24cc":"code","455f2f64":"code","8a7dc6c3":"code","eaa40c9d":"code","76f20f0d":"code","37374aa6":"code","b08da354":"code","7d645a55":"code","6714445e":"code","9b84f3de":"code","eb08704b":"code","7c805e7b":"code","4a2710c8":"code","64571f78":"code","3e3c6ff5":"code","95b28f27":"code","4a24e15d":"code","6eb49f03":"code","aa1284c5":"markdown","f3c00397":"markdown","31e9efc3":"markdown","3cf13621":"markdown","f5e604c7":"markdown","f8e0bed3":"markdown","64dd2970":"markdown","5d5dbd51":"markdown","46c8f050":"markdown","2e7f4050":"markdown","f6b91912":"markdown","9bf825a5":"markdown","59215c3d":"markdown","8b2d8769":"markdown","2fdf7446":"markdown"},"source":{"e9805bb8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport itertools\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=Warning)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2eb654e6":"train = pd.read_csv(\"..\/input\/chaii-hindi-and-tamil-question-answering\/train.csv\")\ntest = pd.read_csv(\"..\/input\/chaii-hindi-and-tamil-question-answering\/test.csv\")\nsample = pd.read_csv(\"..\/input\/chaii-hindi-and-tamil-question-answering\/sample_submission.csv\")","529b91c4":"train.head()","b9a9dc20":"train.isnull().sum()","f89be6ce":"train[\"language\"].value_counts()","7d440bab":"#Codes by Pooja Jain https:\/\/www.kaggle.com\/jainpooja\/av-guided-hackathon-predict-youtube-likes\/notebook\n\ntext_cols = ['context', 'question', 'answer_text', 'language']\n\nfrom wordcloud import WordCloud, STOPWORDS\n\nwc = WordCloud(stopwords = set(list(STOPWORDS) + ['|']), random_state = 42)\nfig, axes = plt.subplots(2, 2, figsize=(20, 12))\naxes = [ax for axes_row in axes for ax in axes_row]\n\nfor i, c in enumerate(text_cols):\n  op = wc.generate(str(train[c]))\n  _ = axes[i].imshow(op)\n  _ = axes[i].set_title(c.upper(), fontsize=24)\n  _ = axes[i].axis('off')\n\n#_ = fig.delaxes(axes[4])","68ac4ef1":"#Code by Alaa Sedeeq https:\/\/www.kaggle.com\/alaasedeeq\/commonlit-readability-eda\/execution\n\n#Define a function to plot a bar plot easily\n\ndef bar_plot(train,x,x_title,y,title,colors=None,text=None):\n    fig = px.bar(x=x,\n                 y=y,\n                 text=text,\n                 labels={x: x_title.title()},          # replaces default labels by column name\n                 data_frame=train,\n                 color=colors,\n                 barmode='group',\n                 template=\"simple_white\",\n                 color_discrete_sequence=px.colors.qualitative.Prism)\n    \n    texts = [train[col].values for col in y]\n    for i, t in enumerate(texts):\n        fig.data[i].text = t\n        fig.data[i].textposition = 'inside'\n        \n    fig['layout'].title=title\n\n    for trace in fig.data:\n        trace.name = trace.name.replace('_',' ').title()\n\n    fig.update_yaxes(tickprefix=\"\", showgrid=True)\n\n    fig.show()","beaeee1d":"#Code by Alaa Sedeeq https:\/\/www.kaggle.com\/alaasedeeq\/commonlit-readability-eda\/notebook\n\n# lets define a function to plot a histogram plot easily\n\ndef hist_plot(train,x,title):\n    fig = px.histogram(x=train[x],\n                       color_discrete_sequence=colors,\n                       opacity=0.8)\n\n    fig['layout'].title=title\n    fig.update_yaxes(tickprefix=\"\", showgrid=True)\n    fig.show()","42a34d55":"#Code by Alaa Sedeeq https:\/\/www.kaggle.com\/alaasedeeq\/commonlit-readability-eda\/comments#1292516\n\n#Find words spreading (each word frequency)\nfreq_d = pd.Series(' '.join(train['answer_text']).split()).value_counts()\n#Plot the words distribution\nfig = px.line(freq_d,\n              title='The word frequency visualization')\nfig.update_layout(showlegend=False)","bccade71":"#Code by Alaa Sedeeq https:\/\/www.kaggle.com\/alaasedeeq\/commonlit-readability-eda\/notebook\n\nprepared_as_text = [line for line in train['answer_text']]\ntext_prepared_results = '\/n'.join(prepared_as_text)\n\ntext= ' '.join(t for t in train['answer_text'])\nwords_list= text.split()","1a0bf601":"#Code by Alaa Sedeeq https:\/\/www.kaggle.com\/alaasedeeq\/commonlit-readability-eda\/notebook\n\nword_freq= {}\n\nfor word in set(words_list):\n    word_freq[word]= words_list.count(word)\n    \n#sorting the dictionary \nword_freq = dict(sorted(word_freq.items(), reverse=True, key=lambda item: item[1]))","425cc1d2":"#sort the data and put it in a data frame for the visualization\nword_freq_temp = dict(itertools.islice(word_freq.items(), 25))\nword_freq_df = pd.DataFrame(word_freq_temp.items(),columns=['word','count']).sort_values('count',ascending=False)","ac8c785d":"#Code by Alaa Sedeeq https:\/\/www.kaggle.com\/alaasedeeq\/commonlit-readability-eda\/comments#1292516\n\nbar_plot(word_freq_df.reset_index(),\n         'word',\n         'Words',\n         ['count'],\n         title='Top 20 frequent words')","09ca725d":"import nltk \nimport string\nfrom wordcloud import WordCloud\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\nfrom nltk.stem import WordNetLemmatizer\nfrom textblob import TextBlob,Word\nfrom collections import Counter","bd78e75b":"#Code by Alaa Sedeeq https:\/\/www.kaggle.com\/alaasedeeq\/commonlit-readability-eda\/comments#1292516\n#Bigrams\nfrom nltk.util import ngrams    \n\ndef get_n_grans_count(text, n_grams, min_freq):\n    output = {}\n    tokens = nltk.word_tokenize(text)\n\n    #Create the n_gram\n    if n_grams == 2:\n        gs = nltk.bigrams(tokens)\n        \n    elif n_grams == 3:\n        gs = nltk.trigrams(tokens)\n\n    else:\n        return 'Only 2_grams and 3_grams are supported'\n    #compute frequency distribution for all the bigrams in the text\n    fdist = nltk.FreqDist(gs)\n    for k,v in fdist.items():\n        if v > min_freq:\n            index = ' '.join(k)\n            output[index] = v\n    \n    return output","ada436d8":"#two_grams = get_n_grans_count(text, n_grams=2, min_freq=10)\n#two_grams_train = pd.DataFrame(data=two_grams.items())\n#two_grams_train = two_grams_train.sort_values(by=1,ascending=False).rename(columns={0:'Two grams',1:'Count'})\n#two_grams_train","a889606c":"#Code by Alaa Sedeeq https:\/\/www.kaggle.com\/alaasedeeq\/commonlit-readability-eda\/notebook\n\nthree_grams = get_n_grans_count(text, n_grams=3, min_freq=0)\nthree_grams_train = pd.DataFrame(data=three_grams.items())\nthree_grams_train = three_grams_train.sort_values(by=1,ascending=False).rename(columns={0:'Three grams',1:'Count'})\nthree_grams_train","51868758":"#Code by Alaa Sedeeq https:\/\/www.kaggle.com\/alaasedeeq\/commonlit-readability-eda\/notebook\n\nbar_plot(three_grams_train.iloc[:20],\n         'Three grams',\n         'Three grams',\n         ['Count'],\n         title='Top 20 frequent trigram')","0f928ff2":"def wordcloud(text,stopwords,ngram=1):\n    # text: if ngram>1, text should be a dictionary\n    wordcloud = WordCloud(width=1400, \n                          height=800,\n                          random_state=2021,\n                          background_color='black',\n                          colormap='Set2',\n                          stopwords=stop)\n    if ngram ==1:\n        wordc = wordcloud.generate(' '.join(text))\n    else:\n        wordc = wordcloud.generate_from_frequencies(text)\n    plt.figure(figsize=(20,10), facecolor='k')\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.tight_layout(pad=0)\n    \nwordcloud(train['answer_text'],stop)","c61d5348":"#Code by Alaa Sedeeq https:\/\/www.kaggle.com\/alaasedeeq\/commonlit-readability-eda\/notebook\n\nthree_grams_temp = {j.replace(' ','_') : k for j, k in three_grams.items()}\n\nwordcloud(three_grams_temp,stop,ngram=3)","b9428b43":"#Code by Alaa Sedeeq https:\/\/www.kaggle.com\/alaasedeeq\/commonlit-readability-eda\/notebook\n\nwords_length = {}\n\nfor word in set(words_list):\n    words_length[word] = len(word)\n    \nwords_length = dict(sorted(words_length.items(), reverse=True, key=lambda item: item[1]))\n#sort the data and put it in a data frame for the visualization\nword_length_temp = dict(itertools.islice(words_length.items(), 25))\nwords_length_train = pd.DataFrame(words_length.items(),columns=['word','count']).sort_values('count',ascending=False)","f4318c8c":"#Code by Alaa Sedeeq https:\/\/www.kaggle.com\/alaasedeeq\/commonlit-readability-eda\/notebook\n\ntrain['sentence_len']= train['answer_text'].str.len()\nprint('Max length     : {} \\nMin length     : {} \\nAverage Length : {}'.\\\n      format(max(train['sentence_len']),min(train['sentence_len']),train['sentence_len'].mean()))","ea31e901":"#Code by Alaa Sedeeq https:\/\/www.kaggle.com\/alaasedeeq\/commonlit-readability-eda\/notebook\n\n#the longest sentence we have\ntrain[train['sentence_len']==max(train['sentence_len'])]['answer_text'].values[0]","ccf6e282":"#the shortest sentence we have\ntrain[train['sentence_len']==min(train['sentence_len'])]['answer_text'].values[0]","7c44415e":"#Code by Alaa Sedeeq https:\/\/www.kaggle.com\/alaasedeeq\/commonlit-readability-eda\/notebook\n\ncolors = px.colors.qualitative.Prism\n\nhist_plot(train,\n          'sentence_len',\n          title='Sentences lenght distribution with spaces')","becf24cc":"#Code by Alaa Sedeeq https:\/\/www.kaggle.com\/alaasedeeq\/commonlit-readability-eda\/notebook\n\ncolors = px.colors.qualitative.Prism\n\n# lets define a function to plot a histogram plot easily\n\ndef hist_plot(train,x,title):\n    fig = px.histogram(x=train[x],\n                       color_discrete_sequence=colors,\n                       opacity=0.8)\n\n    fig['layout'].title=title\n    fig.update_yaxes(tickprefix=\"\", showgrid=True)\n    fig.show()","455f2f64":"#Code by Alaa Sedeeq https:\/\/www.kaggle.com\/alaasedeeq\/commonlit-readability-eda\/notebook\n\ncolors = px.colors.qualitative.Prism\n\ntrain['sentence_len_no_sp']= train['answer_text'].str.split().map(lambda x: len(x))\n\nhist_plot(train,\n          'sentence_len_no_sp',\n          title='Sentences lengh distribution without spaces')","8a7dc6c3":"from gensim.models import Word2Vec\nimport gensim","eaa40c9d":"corpus = ['\u0905\u092e\u0947\u0930\u093f\u0915\u0940 \u0915\u094d\u0930\u0928\u094d\u0924\u093f\u0915\u093e\u0930\u0940 \u092f\u0941\u0926\u094d\u0927', '\u0924\u0947\u0930\u0939 \u0909\u0924\u094d\u0924\u0930 \u0905\u092e\u0947\u0930\u093f\u0915\u0940 \u0909\u092a\u0928\u093f\u0935\u0947\u0936\u094b\u0902 \u0915\u0947 \u092c\u0940\u091a \u090f\u0915 \u0938\u0948\u0928\u094d\u092f \u0938\u0902\u0918\u0930\u094d\u0937 \u0925\u093e', '\u092c\u0926\u0932\u0947 \u0915\u0947 \u0932\u093f\u090f \u0906\u0924\u0941\u0930 \u092b\u093c\u094d\u0930\u093e\u0928\u094d\u0938 \u0928\u0947']","76f20f0d":"stop_words = ['\u090f\u0915', '\u0926\u0942\u0938\u0930\u0947', '\u0928\u0939\u0940\u0902', '\u092a\u0942\u0930\u093e', '\u0935', '\u0935\u0947', '\u0932\u093f\u092f\u0947', '\u0915\u094b\u0908', '\u0935\u0939\u093e\u0901', '\u0909\u0938\u0940']","37374aa6":"def remove_stop_words(corpus):\n    results = []\n    for text in corpus:\n        tmp = text.split(' ')\n        for stop_word in stop_words:\n            if stop_word in tmp:\n                tmp.remove(stop_word)\n        results.append(\" \".join(tmp))\n        \n    return results","b08da354":"corpus = remove_stop_words(corpus)","7d645a55":"words = []\nfor text in corpus:\n    for word in text.split(' '):\n        words.append(word)\n        \nwords = set(words)","6714445e":"words","9b84f3de":"\"\"\"Data Generation\"\"\"\n\nword2int = {}\n\nfor i,word in enumerate(words):\n    word2int[word] = i\n    \nsentences = []\nfor sentence in corpus:\n    sentences.append(sentence.split())\n    \nWINDOW_SIZE = 2\n\ndata = []\nfor sentence in sentences:\n    for idx, word in enumerate(sentence):\n        for neighbor in sentence[max(idx - WINDOW_SIZE, 0): min(idx + WINDOW_SIZE, len(sentence) + 1)]:\n            if neighbor !=word:\n                data.append([word, neighbor])","eb08704b":"for text in corpus:\n    print(text)\n\ndf = pd.DataFrame(data, columns = ['input', 'label'])","7c805e7b":"df.head(10)","4a2710c8":"#Third row, 2nd column - Tamil\n\n#'\u0b9a\u0bb0\u0bcd \u0b85\u0bb2\u0bc6\u0b95\u0bcd\u0bb8\u0bbe\u0ba3\u0bcd\u0b9f\u0bb0\u0bcd \u0b83\u0baa\u0bbf\u0bb3\u0bc6\u0bae\u0bbf\u0b99\u0bcd (Sir Alexander Fleming) (\u0b86\u0b95\u0bb8\u0bcd\u0b9f\u0bcd 6, 1881 \u2013 \u0bae\u0bbe\u0bb0\u0bcd\u0b9a\u0bcd 11, 1955) \ntrain.iloc[2,1]","64571f78":"#Ninth row, 2nd column - Tamil\n\n#\u0ba8\u0bc6\u0bb2\u0bcd\u0b9a\u0ba9\u0bcd \u0bae\u0ba3\u0bcd\u0b9f\u0bc7\u0bb2\u0bbe (Nelson Rolihlahla Mandela, 18 \u0b9a\u0bc2\u0bb2\u0bc8 1918 \u2013 5 \u0ba4\u0bbf\u0b9a\u0bae\u0bcd\u0baa\u0bb0\u0bcd 2013), \u0ba4\u0bc6\u0ba9\u0bcd\u0ba9\u0bbe\u0baa\u0bcd\u0baa\u0bbf\u0bb0\u0bbf\u0b95\u0bcd\u0b95\u0bbe\u0bb5\u0bbf\u0ba9\u0bcd \u0bae\n \ntrain.iloc[9,1]","3e3c6ff5":"#1079 row, 2nd column - Hindi\n\n#\"\u092b\u093c\u094d\u0930\u0940\u0921\u094d\u0930\u093f\u0915 \u0935\u093f\u0932\u093f\u092f\u092e \u0905\u0917\u0938\u094d\u0924 \u092b\u094d\u0930\u094b\u092c\u0947\u0932 (Friedrich Wilhelm August Fr\u00f6bel ; \u091c\u0930\u094d\u092e\u0928 \u0909\u091a\u094d\u091a\u093e\u0930\u0923\n\ntrain.iloc[1079,1]","95b28f27":"#1095 row, 2nd column - Hindi\n\n#Ameriki Krantik - American Revolutionary War\n\ntrain.iloc[1095,1]","4a24e15d":"#Sixth row, 2nd column - Tamil\n\n#'\u0b85\u0bb2\u0bc6\u0b95\u0bcd\u0bb8\u0bbe\u0ba3\u0bcd\u0b9f\u0bb0\u0bcd \u0b95\u0bbf\u0bb0\u0b95\u0bbe\u0bae\u0bcd \u0baa\u0bc6\u0bb2\u0bcd ( Alexander Graham Bell, \u0bae\u0bbe\u0bb0\u0bcd\u0b9a\u0bcd 3, 1847 - \u0b86\u0b95\u0bb8\u0bcd\u0b9f\u0bcd 2, 1922) \u0b93\u0bb0\u0bcd \u0b85\u0bb1\u0bbf\u0bb5\u0bbf\u0baf\u0bb2\u0bbe\u0bb3\u0bb0\u0bcd\n\ntrain.iloc[6,1]","6eb49f03":"#1084th row, 2nd column - Hindi\n\n#Mesoamerica or Meso-America ( Spanish : Mesoam\u00e9rica )\n\ntrain.iloc[1084,1]","aa1284c5":"#The snippet for Bigrams didn't work. Maybe it's the languages. I've no clue. ","f3c00397":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcQXDuHQQ8V8q6svMrfqBGXnb9GtJybwr22ceagcHVSgGWZCb7NGU4tDiIHb0DJpZatcNxI&usqp=CAU)brightzoom.blogspot.com","31e9efc3":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRq5sL6Pl7iTaUsxZxm6ClKJ4dZIfYDStodlA&usqp=CAU)unacademy.com","3cf13621":"#Let's start \"reading\" Tamil and Hindi. ","f5e604c7":"Sentence level analysis\n\nSentence level analysis Text statistics include sentence length distribution, minimum, maximum, and average length. To check the sentence length distribution. Code and output are as follows:\n\nby Alaa Sedeeq https:\/\/www.kaggle.com\/alaasedeeq\/commonlit-readability-eda\/notebook","f8e0bed3":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcQ4Q52tkjv6sadOwDzoo-F4iGfgYPDhYL97AaqyD-70Q5Xj6riAr7dXGgOo18JykBWQD2M&usqp=CAU)vikatan.com","64dd2970":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #001f3f;\"><b style=\"color:#03e8fc;\">Tamil and Hindi Languages<\/b><\/h1><\/center>\n\n\n<h1><span class=\"label label-default\" style=\"background-color:black;border-radius:100px 100px; font-weight: bold; font-family:Garamond; font-size:20px; color:#03e8fc; padding:10px\">Tamil<\/span><\/h1><br>\n\n\"Tamil (\/\u02c8t\u00e6m\u026al\/; \u0ba4\u0bae\u0bbf\u0bb4\u0bcd Tami\u1e3b , About this soundpronunciation (help\u00b7info)) is a Dravidian language natively spoken by the Tamil people of South Asia. Tamil is the official language of the Indian state of Tamil Nadu, and of the sovereign nations of Singapore and Sri Lanka.\"\n\n\"Tamil is spoken by significant minorities in the four other South Indian states of Kerala, Karnataka, Andhra Pradesh and Telangana and the Union Territory of the Andaman and Nicobar Islands. It is also spoken by the Tamil diaspora found in many countries, including Malaysia, South Africa, United Kingdom, United States, Canada, Australia and Mauritius. Tamil is also natively spoken by Sri Lankan Moors.\"\n\nhttps:\/\/en.wikipedia.org\/wiki\/Tamil_language\n\n\n<h1><span class=\"label label-default\" style=\"background-color:black;border-radius:100px 100px; font-weight: bold; font-family:Garamond; font-size:20px; color:#03e8fc; padding:10px\">Hindi<\/span><\/h1><br>\n\n\"Hindi (Devanagari: \u0939\u093f\u0928\u094d\u0926\u0940, ISO: Hind\u012b), or more precisely Modern Standard Hindi (Devanagari: \u092e\u093e\u0928\u0915 \u0939\u093f\u0928\u094d\u0926\u0940, ISO: M\u0101nak Hind\u012b), is an Indo-Aryan language spoken chiefly in India. Hindi has been described as a standardised and Sanskritised register of the Hindustani language, which itself is based primarily on the Khariboli dialect of Delhi and neighbouring areas of Northern India.\"\n\n\"Hindi, written in the Devanagari script, is one of the two official languages of the Government of India, along with the English language. It is an official language in 9 States and 3 Union Territories and an additional official language in 3 other States. Hindi is also one of the 22 scheduled languages of the Republic of India. Hindi is sometimes erroneously reported as the national language of India.\"\n\nhttps:\/\/en.wikipedia.org\/wiki\/Hindi\n\n\n\n","5d5dbd51":"#Words analysis","46c8f050":"#Modern Art","2e7f4050":"![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/7\/79\/Mesoamerica_english.PNG\/330px-Mesoamerica_english.PNG)en.wikipedia.org","f6b91912":"#Words length","9bf825a5":"![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/8\/8a\/Faroe_stamp_079_europe_%28fleming%29.jpg\/272px-Faroe_stamp_079_europe_%28fleming%29.jpg)ta.wikipedia.org","59215c3d":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRDCMcvBUA-t5IfMyeFHwPjla1IOWQjnk-2Tw&usqp=CAU)penmai.com","8b2d8769":"![](https:\/\/d3viohk6mc296s.cloudfront.net\/posts_6fd4d074-50fe-4e6d-aba9-d3a78c70f974.jpg)circle.page","2fdf7446":"#Trigrams"}}