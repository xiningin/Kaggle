{"cell_type":{"9bf06934":"code","ae5c4d40":"code","8b7e1ef1":"code","f48b82ff":"code","56b17cb6":"code","faf4bfa8":"code","93154bfb":"code","ea1259cc":"code","3250c261":"code","409d9218":"code","74ecc4f7":"code","158df616":"code","054a8e22":"markdown","48d0402d":"markdown","9c1b597c":"markdown","adf142a1":"markdown","f5c81424":"markdown","8c546ec7":"markdown"},"source":{"9bf06934":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","ae5c4d40":"import pandas as pd\n\n# Read csv dataset using pandas, see docs here:\n# https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.read_csv.html?highlight=csv#pandas.read_csv\n# Use only Lyrics and Year cols (3 and 4)\ndef ingest_train():\n    data = pd.read_csv('..\/input\/billboard_lyrics_1964-2015.csv', encoding='latin-1', usecols=[3,4])\n    return data","8b7e1ef1":"data = ingest_train()","f48b82ff":"# stats about the dataset\ndata.describe()","56b17cb6":"# data headers (column names) with some rows for context\ndata.head()","faf4bfa8":"# Import some utils to clean the data\nimport nltk\nfrom nltk import word_tokenize, sent_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import *","93154bfb":"from nltk.corpus import wordnet as wn\ndef get_lemma(word):\n    lemma = wn.morphy(word)\n    if lemma is None:\n        return word\n    else:\n        return lemma\n    \nfrom nltk.stem.wordnet import WordNetLemmatizer\ndef get_lemma2(word):\n    return WordNetLemmatizer().lemmatize(word)","ea1259cc":"# Stopwords and punctuation\nfrom nltk.tokenize import WordPunctTokenizer\nimport re\ntokenizer = WordPunctTokenizer()\n\ndef clean_data(text):\n        lower_case = text.lower() if (type(text) is str) else text\n        tokens = tokenizer.tokenize(lower_case)\n        tokens = [token for token in tokens if len(token) > 4]\n        tokens = [get_lemma(token) for token in tokens]\n        return tokens\n\n","3250c261":"# Clean lyrics for each song\ntext_data = []\nfor index, song in enumerate(data.Lyrics):\n    if (type(song) is str): \n        song = clean_data(song)\n        text_data.append(song)\n        \n","409d9218":"\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nfrom wordcloud import WordCloud, STOPWORDS\n\n\npopular_words = []\nfor t in data.Lyrics:\n    popular_words.append(t)\npopular_words = pd.Series(popular_words).str.cat(sep=' ')\nfrom wordcloud import WordCloud\n\nwordcloud = WordCloud(width=1600, height=800,max_font_size=200, background_color='white').generate(popular_words)\nplt.figure(figsize=(12,10))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()\n\n","74ecc4f7":"\nfrom gensim import corpora\ndictionary = corpora.Dictionary(text_data)\ncorpus = [dictionary.doc2bow(text) for text in text_data]\n\n\nimport pickle\npickle.dump(corpus, open('corpus.pkl', 'wb'))\ndictionary.save('dictionary.gensim')\n\n# Find 5 topics\nimport gensim\nNUM_TOPICS = 5\n#ignore warnings for deprecated numpy function in lda\nimport warnings\n\ntopics = []\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n    ldamodel.save('model5.gensim')\n\n    topics = ldamodel.print_topics(num_words=4)\n    for topic in topics:\n        print(topic)\n\n","158df616":"dictionary = gensim.corpora.Dictionary.load('dictionary.gensim')\ncorpus = pickle.load(open('corpus.pkl', 'rb'))\nlda = gensim.models.ldamodel.LdaModel.load('model5.gensim')\n\nimport pyLDAvis.gensim\nlda_display = pyLDAvis.gensim.prepare(lda, corpus, dictionary)\npyLDAvis.display(lda_display)","054a8e22":"# Most popular words in the past 50 years of songs","48d0402d":"# Lemmatize words (find root)","9c1b597c":"# Clean the Data","adf142a1":"# Visualize the topics in a graph","f5c81424":"# Topic Modeling","8c546ec7":"# Import dataset from CSV"}}