{"cell_type":{"a6f1f520":"code","1c259d40":"code","8e248282":"code","5d02e600":"code","8b0cc1f6":"code","aad8631b":"code","9572a1d6":"code","d2e6a5b3":"code","a07603f8":"code","2d97e86c":"code","441ee1df":"code","216eb9ce":"code","c9171615":"code","331e3867":"code","01ff583d":"code","4aeb676a":"code","204f81b6":"code","eb96edab":"code","eb21c7d9":"code","4fdf6b11":"code","848334cb":"code","1938c94c":"code","e6981a79":"code","cea68b99":"code","4923c7d4":"code","103a6d36":"code","ad82f466":"code","020c3cf2":"markdown","ad9daa99":"markdown","d662ad1f":"markdown","a9f39d69":"markdown","a97c0bcc":"markdown"},"source":{"a6f1f520":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom catboost import CatBoostClassifier, Pool","1c259d40":"train_df = pd.read_csv('..\/input\/tabular-playground-series-dec-2021\/train.csv')\ntest_df = pd.read_csv('..\/input\/tabular-playground-series-dec-2021\/test.csv')\nFEATURES = [col for col in train_df.columns if col not in ['Id', 'Cover_Type']]","8e248282":"data = []\n\nfor f in train_df.columns:\n    if f == 'Cover_Typet':\n        role = 'target'\n    elif f == 'id':\n        role = 'id'\n    else:\n        role = 'input'\n        \n    if 'Type' in f or 'Area' in f or f == 'Cover_Typet' or f == 'Id':\n        level = 'nominal'\n    elif 'cat' in f or f == 'Id':\n        level = 'nominal'\n    elif train_df[f].dtype == float:\n        level = 'interval'\n    elif train_df[f].dtype == int:\n        level = 'ordinal'\n        \n    keep = True\n    \n    if f == 'Id':\n        keep = False\n    \n    dtype = train_df[f].dtype\n    \n    f_dict = {\n        'varname' : f,\n        'role' : role,\n        'level' : level,\n        'keep' : keep,\n        'dtype' : dtype\n    }\n    \n    data.append(f_dict)\n    \nmeta = pd.DataFrame(data, columns = ['varname', 'role', 'level', 'keep', 'dtype'])\nmeta.set_index('varname', inplace=True)","5d02e600":"meta","8b0cc1f6":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n\n    return df","aad8631b":"train_df = reduce_mem_usage(train_df)\ntest_df = reduce_mem_usage(test_df)","9572a1d6":"train_df.info()","d2e6a5b3":"v = train_df.columns\nfor f in v:\n    dist_value = train_df[f].value_counts().shape[0]\n    print('Variables {:>40} has {} distinct values'.format(f, dist_value))","a07603f8":"train_df = train_df.drop(index = int(np.where(train_df['Cover_Type'] == 5)[0]))\ntrain_df.head()","2d97e86c":"v = test_df.columns\nfor f in v:\n    dist_value = test_df[f].value_counts().shape[0]\n    print('Variables {:>40} has {} distinct values'.format(f, dist_value))","441ee1df":"missing = 0\nfor f in train_df.columns:\n    missing += train_df[f].isnull().sum()\n    print(\"Variables : {:>30}\\t missings : {}\".format(f, train_df[f].isnull().sum()))\nprint(\"Sum of missing_value : {}\".format(missing))","216eb9ce":"v = meta[(meta.level == 'nominal') & meta.keep].index\ntrain_df[v].describe()","c9171615":"for i in v:\n    print(i)","331e3867":"v = meta[(meta.level == 'ordinal') & meta.keep].index\nfor i in v:\n    print(i)","01ff583d":"s1 = train_df.sample(frac=0.2)\ns2 = test_df.sample(frac=0.2)","4aeb676a":"i = 1\nplt.figure()\nfig, ax = plt.subplots(2, 5,figsize=(20, 12))\nfor f in v:\n    plt.subplot(2, 5, i)\n    sns.histplot(s1[f], color=\"blue\", kde=True, bins=100, label='train_'+f)\n    sns.histplot(s2[f], color=\"olive\", kde=True, bins=100, label='test_'+f)\n    plt.xlabel(f, fontsize=9); plt.legend()\n    i += 1\nplt.show()","204f81b6":"def corr_heatmap(v):\n    correlations = train_df[v].corr()\n\n    # Create color map ranging between two colors\n    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n    fig, ax = plt.subplots(figsize=(30,10))\n    sns.heatmap(correlations, cmap=cmap, vmax=1.0, center=0, fmt='.2f',\n                square=True, linewidths=.5, annot=True, cbar_kws={\"shrink\": .75})\n    plt.show();\n\ncorr_heatmap(v)","eb96edab":"train_df['Cover_Type'].value_counts()","eb21c7d9":"sns.catplot(x=\"Cover_Type\", kind=\"count\", palette=\"ch:.25\", data=train_df)","4fdf6b11":"test_df.columns","848334cb":"# train data\ntarget = train_df['Cover_Type']\ntrain_df.drop(columns=['Id', 'Cover_Type', 'Soil_Type7', 'Soil_Type15'], axis=1, inplace=True)\n\n# test data \ntest_df.drop(columns=['Id', 'Soil_Type7', 'Soil_Type15'], axis=1, inplace=True)\nFEATURES.remove('Soil_Type7')\nFEATURES.remove('Soil_Type15')","1938c94c":"train_df[\"mean\"] = train_df[FEATURES].mean(axis=1)\ntrain_df[\"std\"] = train_df[FEATURES].std(axis=1)\ntrain_df[\"min\"] = train_df[FEATURES].min(axis=1)\ntrain_df[\"max\"] = train_df[FEATURES].max(axis=1)\n\ntest_df[\"mean\"] = test_df[FEATURES].mean(axis=1)\ntest_df[\"std\"] = test_df[FEATURES].std(axis=1)\ntest_df[\"min\"] = test_df[FEATURES].min(axis=1)\ntest_df[\"max\"] = test_df[FEATURES].max(axis=1)\n\nFEATURES.extend(['mean', 'std', 'min', 'max'])","e6981a79":"train_df.head()","cea68b99":"scaler = StandardScaler()\ntrain_df = scaler.fit_transform(train_df)\ntest_df = scaler.transform(test_df)","4923c7d4":"X_train, X_val, y_train, y_val = train_test_split(train_df, target, test_size=0.2, shuffle =True)","103a6d36":"cat_params = {\n    'iterations': 20000,\n    'learning_rate': 0.03,\n    'od_wait': 1000,\n    'depth': 7,\n    'task_type' : 'GPU',\n    'l2_leaf_reg': 5,\n    'eval_metric': 'Accuracy',\n    'devices' : '0',\n    'verbose' : 1000\n}\ncat = CatBoostClassifier(**cat_params)\ncat.fit(X_train, y_train, eval_set=(X_val, y_val))","ad82f466":"submission = pd.read_csv('..\/input\/tabular-playground-series-dec-2021\/sample_submission.csv')\nsubmission['Cover_Type'] = cat.predict(test_df)\nsubmission.to_csv(\"submission.csv\",index=False)\n","020c3cf2":"# Data at first sight","ad9daa99":"# loading data","d662ad1f":"# reduce memory","a9f39d69":"# Metadata\n- To facilitate the data management, we'll store meta-information about the variables in a DataFrame. This will be helpful when we want to select specific variables for analysis, visualization, modeling, ...","a97c0bcc":"# visualization"}}