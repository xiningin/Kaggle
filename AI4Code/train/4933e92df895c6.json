{"cell_type":{"b071ba9e":"code","635bdb79":"code","8efd0f5c":"code","4ba2424e":"code","ce676cdb":"code","cac49ebd":"code","5340c7a3":"code","b5b05547":"code","30b3d8c1":"code","71e52d17":"code","0527aded":"code","91d81974":"markdown","45eb50bb":"markdown","686dd565":"markdown","c4f68bf5":"markdown","bfb80343":"markdown","e6f417ab":"markdown","f29b2364":"markdown"},"source":{"b071ba9e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn.model_selection import train_test_split\nimport lightgbm\nfrom sklearn.metrics import roc_auc_score\n\nimport matplotlib.pylab as plt","635bdb79":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8efd0f5c":"input_dir = '\/kaggle\/input\/santander-customer-transaction-prediction\/'\ndf_train = pd.read_csv(input_dir + '\/train.csv')\ndf_train","4ba2424e":"var_columns = [c for c in df_train.columns if c not in ['ID_code','target']]\n\nX = df_train.loc[:,var_columns]\ny = df_train.loc[:,'target']\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train.shape, X_valid.shape, y_train.shape, y_valid.shape","ce676cdb":"train_data = lightgbm.Dataset(X_train, label=y_train)\nvalid_data = lightgbm.Dataset(X_valid, label=y_valid)","cac49ebd":"parameters = {'objective': 'binary',\n              'metric': 'auc',\n              'is_unbalance': 'true',\n              'boosting': 'gbdt',\n              'num_leaves': 63,\n              'feature_fraction': 0.5,\n              'bagging_fraction': 0.5,\n              'bagging_freq': 20,\n              'learning_rate': 0.01,\n              'verbose': -1\n             }","5340c7a3":"model_lgbm = lightgbm.train(parameters,\n                            train_data,\n                            valid_sets=valid_data,\n                            num_boost_round=5000,\n                            early_stopping_rounds=50)","b5b05547":"y_train_pred = model_lgbm.predict(X_train)\ny_valid_pred = model_lgbm.predict(X_valid)\n\nprint(\"AUC Train: {:.4f}\\nAUC Valid: {:.4f}\".format(roc_auc_score(y_train, y_train_pred),\n                                                    roc_auc_score(y_valid, y_valid_pred)))","30b3d8c1":"df_test = pd.read_csv(input_dir + '\/test.csv')\ndf_sample_submission = pd.read_csv(input_dir + '\/sample_submission.csv')","71e52d17":"X_test = df_test.loc[:,var_columns]\ndf_sample_submission['target'] = model_lgbm.predict(X_test)\ndf_sample_submission","0527aded":"output_dir = '\/kaggle\/working\/'\ndf_sample_submission.to_csv(output_dir + \"04_lgbm_scores.csv\", index=False)","91d81974":"### Step3: Find predictions for test data\nRead the test and sample submission data","45eb50bb":"Specify the parameters for LightGBM","686dd565":"## Step1: Read Training Data from CSV\nUse pandas `read_csv` function to read train.csv","c4f68bf5":"# Santander Customer Transaction Prediction - Light GBM\n\nIn the Kaggle competition, the objective is to identify which customer will make a transaction in the future.\n\n**Link to the competition**: https:\/\/www.kaggle.com\/c\/santander-customer-transaction-prediction\/  \n**Type of Problem**: Classification  \n**Metric for evalution**: AOC (Area Under Curve)\n\nThis Python 3 environment comes with many helpful analytics libraries installed\nIt is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python","bfb80343":"## Step2: Create a simple Light GBM Model and evaluate performance\nLightGBM has function `Dataset` to read the data. This is required for using LightGBM.","e6f417ab":"Separate the data into independent and dependent variables.  \nUse sklearn's `train_test_split` function to separate the data into training and validation data","f29b2364":"Train the LightGBM model for maximum 5000 rounds. Early stopping criteria is 50 iterations."}}