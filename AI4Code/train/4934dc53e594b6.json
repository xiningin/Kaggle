{"cell_type":{"2b32d79d":"code","0bd552df":"code","27fc23fc":"code","2e002923":"code","daceacd9":"code","966acde7":"code","5658fcde":"code","9ab1752e":"code","cb6d8374":"code","5e8e5850":"code","0e09a14d":"code","87255c45":"code","abd0ea66":"code","d30774aa":"code","3dacb5e1":"code","c6693f0a":"code","64db6fd2":"code","18d47b70":"code","3c612d4b":"code","7594ed69":"code","5dd9f3be":"code","d3f43d4e":"code","2782eabd":"code","57a4c376":"code","a31cc526":"code","f3a309f3":"code","4883ecb8":"code","dcd9da96":"code","d674f7f6":"code","f9087677":"code","3c86810d":"code","be7daa0b":"code","8692ef51":"code","fd235f10":"markdown","5b5371ab":"markdown","2002bda8":"markdown","aed1a0ba":"markdown","dd4c4043":"markdown","24374d02":"markdown","d9d36671":"markdown","5e01dbc8":"markdown","ef95c80e":"markdown","607cc7d0":"markdown","1f57073d":"markdown","2f86e669":"markdown","17c21fa3":"markdown","a9f8be4a":"markdown","8fcc2631":"markdown","f08244c4":"markdown"},"source":{"2b32d79d":"import numpy as np\n\ndef sigmoid(t):\n    return 1\/(1 + np.e**-t)\n\nrange_vals = np.linspace(-10, 10, 50)\n\nsigmoid_values = sigmoid(range_vals)","0bd552df":"import matplotlib.pyplot as plt\n\nplt.plot(range_vals, sigmoid_values)\nplt.title(\"Sigmoid Function\")\nplt.xlabel(\"t\")\nplt.ylabel(\"sigmoid(t)\")\nplt.show()","27fc23fc":"X = [20, 23, 24, 25, 30, 35, 40, 50, 53, 55, 60, 65, 70] # Weights\ny = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1] # Obese or not","2e002923":"plt.plot(X[:7], y[:7], 'bo', color=\"black\")\nplt.plot(X[7:], y[7:], 'bo', color='red')\nplt.show()","daceacd9":"X = np.array(X).reshape(-1, 1)\ny = np.array(y).reshape(-1, 1)","966acde7":"from sklearn.linear_model import LinearRegression\n\nreg = LinearRegression().fit(X, y)","5658fcde":"y_pred = reg.predict(X)","9ab1752e":"plt.plot(X[:7], y[:7], 'bo', color=\"black\")\nplt.plot(X[7:], y[7:], 'bo', color='red')\nplt.plot(X, y_pred)\nplt.show()","cb6d8374":"sig_log_vals = sigmoid(np.linspace(-100, 100, 90))\n\nplt.plot(X[:7], y[:7], 'bo', color=\"black\")\nplt.plot(X[7:], y[7:], 'bo', color=\"red\")\nplt.plot(sig_log_vals)\nplt.show()","5e8e5850":"from sklearn.linear_model import LogisticRegression\n\nlogit_reg = LogisticRegression().fit(X, y.ravel())","0e09a14d":"logit_reg.coef_","87255c45":"logit_reg.intercept_","abd0ea66":"print(logit_reg.predict([[10]]))\nprint(logit_reg.predict([[56]]))","d30774aa":"y_pred = logit_reg.predict(X)","3dacb5e1":"y_pred","c6693f0a":"import pandas as pd","64db6fd2":"df = pd.read_csv(r'..\/input\/heart-disease-prediction-using-logistic-regression\/framingham.csv')","18d47b70":"df.head()","3c612d4b":"df.info()","7594ed69":"df.mean()","5dd9f3be":"df = df.fillna(df.mean())","d3f43d4e":"df.info()","2782eabd":"X = df.iloc[:, :-1] # X has all columns except the last column because it is the column we have to make predictions for.\ny = df.iloc[:, -1]  # y has last column\n\nX = np.array(X)\ny = np.array(y)","57a4c376":"from sklearn.preprocessing import StandardScaler\n\nX = StandardScaler().fit_transform(X)","a31cc526":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)","f3a309f3":"chd = LogisticRegression()","4883ecb8":"chd.fit(X_train, y_train)","dcd9da96":"chd.score(X_test, y_test)","d674f7f6":"y_pred = chd.predict(X_test)","f9087677":"print(\"Predicted Values (top 10):- \\n\")\ny_pred[:10]","3c86810d":"from sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_test, y_pred)","be7daa0b":"def plot_confusion_matrix(cm, classes,\n                        normalize=False,\n                        title='Confusion matrix',\n                        cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n","8692ef51":"import itertools\n\nplot_confusion_matrix(cm, [\"No risk of CHD\", \"Risk of CHD\"])","fd235f10":"Thanks for reading!","5b5371ab":"As we can see this data has many Null values.\n\nSo we will replace this Null value by the mean. Using this pandas function :","2002bda8":"#### Prediction","aed1a0ba":"#### Coefficient and intercept of fitted model","dd4c4043":"Now, let us fit Linear Regression in this data...","24374d02":"### About dataset:\n\n\u2022 Sex: male or female(Nominal)\n\n\u2022 Age: Age of the patient;(Continuous - Although the recorded ages have been truncated to whole numbers, the concept of age is continuous)\n\n\u2022 Current Smoker: whether or not the patient is a current smoker (Nominal)\n\n\u2022 Cigs Per Day: the number of cigarettes that the person smoked on average in one day.(can be considered continuous as one can have any number of cigarettes, even half a cigarette.)\n\n\u2022 BP Meds: whether or not the patient was on blood pressure medication (Nominal)\n\n\u2022 Prevalent Stroke: whether or not the patient had previously had a stroke (Nominal)\n\n\u2022 Prevalent Hyp: whether or not the patient was hypertensive (Nominal)\n\n\u2022 Diabetes: whether or not the patient had diabetes (Nominal)\n\n\u2022 Tot Chol: total cholesterol level (Continuous)\n\n\u2022 Sys BP: systolic blood pressure (Continuous)\n\n\u2022 Dia BP: diastolic blood pressure (Continuous)\n\n\u2022 BMI: Body Mass Index (Continuous)\n\n\u2022 Heart Rate: heart rate (Continuous - In medical research, variables such as heart rate though in fact discrete, yet are considered continuous because of large number of possible values.)\n\n\u2022 Glucose: glucose level (Continuous)\n\n\u2022 10 year risk of coronary heart disease CHD (binary: \u201c1\u201d, means \u201cYes\u201d, \u201c0\u201d means \u201cNo\u201d)","d9d36671":"We can see that our model is Predicting Weight 10 as 'NOT obese' and Weight 55 as 'Obese', which is True as per our data!","5e01dbc8":"# Logistic Regression\n\n_class sklearn.linear_model.LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)_\n\nValue of Logistic regression strictly ranges from 0 to 1. Therefore, it can be used in Classification purpose like if Specifed email is Spam (1) or Not-Spam\/Ham (0) {OR a tumour is malignant\/cancerous or NOT}\n\nIf value is greater than 0.5 (> 0.5) it is classified in class 1 (Spam in this case) and if it is less than 0.5 (< 0.5) it is classified in class 0 (Ham in this case).\n\nIf model is predicting values very close to 1 like 0.90, 0.97, 0.99, etc... means model is strongly definite that it is in class 1 and vice versa.\n\n###### Now, Let us study about Mathematical formula of Logistic Regression\n\nFirst, it is essential to know the formula of Sigmoid function or Logistic Function which is:\n\n<img src=\"https:\/\/latex.codecogs.com\/gif.latex?%5Cdpi%7B150%7D%20sigmoid%28t%29%20%3D%20%5Cfrac%7B1%7D%7B1%20&plus;%20e%5E%7B-t%7D%7D\" title=\"sigmoid(t) = \\frac{1}{1 + e^{-t}}\" \/>\n\n\nBasically, Sigmoid Function takes any value (from -$ \\infty $ to +$ \\infty $) and convert it to the range {0, 1}\n\n###### Now, Let's understand sigmoid function by visualization...","ef95c80e":"### Making model","607cc7d0":"### Making Logistic Regression Algorithm with Scikit learn","1f57073d":"As you can see this is not at all a Good Technique and Linear Regression Fails to do this...\n\nHere, Sigmoid or Logistic Function comes in to play. Let me show you the data and Sigmoid function in one plot and you will automatically understand why is it so","2f86e669":"## Working with Real world Dataset\n\nNow, we will work with Real world dataset and make predictions using Logistic regression\n\n### About Dataset :\n\nThe dataset is publically available on the Kaggle website, and it is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. The classification goal is to predict whether the patient has 10-year risk of future coronary heart disease (CHD).The dataset provides the patients\u2019 information. It includes over 4,000 records and 15 attributes.\n\n### Importing Dataset with Pandas:","17c21fa3":"### Train Test Split","a9f8be4a":"Logistic Regression is used for Binary Classification as we discussed above then why we call it as Logistic 'Regression'? This is because we use Regression approach and then set a threshold, above or below, we can classify it to a specific class.\n\nLet us consider a completely ficticious dataset of a Person being Obese or NOT by their given Weight.\n\nObese == 1\n\nNot Obese == 0\n\nLet us Plot this...","8fcc2631":"We have succesfully got rid of the nan\/Null values! Now we can fit our DataFrame","f08244c4":"Our model is performing good, but it has predicted 'No risk of CHD' for 117 people which actually have 'Risk of CHD'."}}