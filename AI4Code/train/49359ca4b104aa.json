{"cell_type":{"916ddeae":"code","b885672b":"code","d513abbc":"code","44f994b1":"code","61034b81":"code","d22fa85e":"code","03b582bd":"code","4a43b3bc":"code","5bd8688e":"code","abf9c9b3":"code","0c6f2314":"code","9f46f306":"markdown","ff84aa3b":"markdown","72dbcded":"markdown","80cd7863":"markdown","4a50d329":"markdown","04edefb3":"markdown"},"source":{"916ddeae":"import numpy as np\nimport pandas as pd\npd.set_option('max_columns', None)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nimport tensorflow as tf\n\nfrom sklearn.metrics import confusion_matrix, classification_report","b885672b":"data = pd.read_csv('..\/input\/supply-chain-analysis-and-modeling\/SCMS_Delivery_History_Dataset.csv')","d513abbc":"data","44f994b1":"data.info()","61034b81":"def preprocess_inputs(df, label_mapping):\n    df = df.copy()\n    \n    # Drop ID column\n    df = df.drop('ID', axis=1)\n    \n    # Drop missing target rows\n    missing_target_rows = df[df['Shipment Mode'].isna()].index\n    df = df.drop(missing_target_rows, axis=0).reset_index(drop=True)\n    \n    # Fill missing values\n    df['Dosage'] = df['Dosage'].fillna(df['Dosage'].mode()[0])\n    df['Line Item Insurance (USD)'] = df['Line Item Insurance (USD)'].fillna(df['Line Item Insurance (USD)'].mean())\n    \n    # Drop date columns with too many missing values\n    df = df.drop(['PQ First Sent to Client Date', 'PO Sent to Vendor Date'], axis=1)\n    \n    # Extract date features\n    for column in ['Scheduled Delivery Date', 'Delivered to Client Date', 'Delivery Recorded Date']:\n        df[column] = pd.to_datetime(df[column])\n        df[column + ' Year'] = df[column].apply(lambda x: x.year)\n        df[column + ' Month'] = df[column].apply(lambda x: x.month)\n        df[column + ' Day'] = df[column].apply(lambda x: x.day)\n        df = df.drop(column, axis=1)\n    \n    # Drop numeric columns with too many missing values\n    df = df.drop(['Weight (Kilograms)', 'Freight Cost (USD)'], axis=1)\n    \n    # Drop high-cardinality columns\n    df = df.drop(['PQ #', 'PO \/ SO #', 'ASN\/DN #'], axis=1)\n    \n    # Binary encoding\n    df['Fulfill Via'] = df['Fulfill Via'].replace({'Direct Drop': 0, 'From RDC': 1})\n    df['First Line Designation'] = df['First Line Designation'].replace({'No': 0, 'Yes': 1})\n    \n    # One-hot encoding\n    for column in df.select_dtypes('object').columns.drop('Shipment Mode'):\n        dummies = pd.get_dummies(df[column], prefix=column)\n        df = pd.concat([df, dummies], axis=1)\n        df = df.drop(column, axis=1)\n    \n    # Split df into X and y\n    y = df['Shipment Mode']\n    X = df.drop('Shipment Mode', axis=1)\n    \n    # Encode the labels\n    y = y.replace(label_mapping)\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n    \n    # Scale X\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)\n    \n    return X_train, X_test, y_train, y_test","d22fa85e":"LABEL_MAPPING = {\n    'Air': 0,\n    'Truck': 1,\n    'Air Charter': 2,\n    'Ocean': 3\n}\n\nX_train, X_test, y_train, y_test = preprocess_inputs(data, label_mapping=LABEL_MAPPING)","03b582bd":"X_train","4a43b3bc":"y_train.value_counts()","5bd8688e":"X_train.shape","abf9c9b3":"inputs = tf.keras.Input(shape=(771,))\nx = tf.keras.layers.Dense(128, activation='relu')(inputs)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\noutputs = tf.keras.layers.Dense(4, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    validation_split=0.2,\n    batch_size=32,\n    epochs=100,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ]\n)","0c6f2314":"y_pred = np.argmax(model.predict(X_test), axis=1)\n\ncm = confusion_matrix(y_test, y_pred, labels=list(LABEL_MAPPING.values()))\nclr = classification_report(y_test, y_pred, labels=list(LABEL_MAPPING.values()), target_names=list(LABEL_MAPPING.keys()))\n\nprint(\"Test Set Accuracy: {:.2f}%\".format(model.evaluate(X_test, y_test, verbose=0)[1] * 100))\n\nplt.figure(figsize=(8, 8))\nsns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)\nplt.xticks(ticks=[0.5, 1.5, 2.5, 3.5], labels=list(LABEL_MAPPING.keys()))\nplt.yticks(ticks=[0.5, 1.5, 2.5, 3.5], labels=list(LABEL_MAPPING.keys()))\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\nprint(\"Classification Report:\\n----------------------\\n\", clr)","9f46f306":"# Task for Today  \n\n***\n\n## Supply Chain Shipment Type Prediction  \n\nGiven *supply chain data*, let's try to predict the **mode of transport** for a given shipment.\n\nWe will use a TensorFlow\/Keras neural network to make our predictions.","ff84aa3b":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/oM4Wl2zbexU","72dbcded":"# Training","80cd7863":"# Results","4a50d329":"# Preprocessing","04edefb3":"# Getting Started"}}