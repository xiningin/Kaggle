{"cell_type":{"d93192f0":"code","12c87163":"code","e431081b":"code","04c5fb7f":"code","6f1ee2a5":"code","3dc56ee3":"code","95265afe":"code","48ff7f69":"code","d83a2136":"code","9ec05a06":"code","0dbbb6a8":"code","abdea641":"code","42f044cc":"code","e5270f59":"code","058f2505":"code","a249be9b":"code","e47d1717":"code","3f754695":"code","877cc38e":"code","45d3969e":"code","a025dba1":"code","147029a9":"code","b7ba9ef4":"code","e1474f3b":"code","ed544884":"markdown","f18c0f30":"markdown","c8afe574":"markdown","b3025f79":"markdown","50ecc7a3":"markdown","2f6816c7":"markdown","36e89adc":"markdown","c1b4ff7d":"markdown","0efe32d8":"markdown"},"source":{"d93192f0":"import os\nimport random\n\nimport numpy as np\nimport pandas as pd\nimport cv2\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\n\n\n%matplotlib inline","12c87163":"def seed_everything(seed=42):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True","e431081b":"INPUT_DIR = '..\/input\/ailab-ml-training-1\/'\n\nPATH = {\n    'train': os.path.join(INPUT_DIR, 'train.csv'),\n    'sample_submission': os.path.join(INPUT_DIR, 'sample_submission.csv'),\n    'train_image_dir': os.path.join(INPUT_DIR, 'train_images\/train_images'),\n    'test_image_dir': os.path.join(INPUT_DIR, 'test_images\/test_images'),\n}\n\nID = 'fname'\nTARGET = 'label'\n\nSEED = 42\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nseed_everything(SEED)\n\nPARAMS = {\n    'valid_size': 0.2,\n    'batch_size': 64,\n    'epochs': 5,\n    'lr': 0.001,\n    'valid_batch_size': 256,\n    'test_batch_size': 256,\n}","04c5fb7f":"train_df = pd.read_csv(PATH['train'])\nsample_submission_df = pd.read_csv(PATH['sample_submission'])","6f1ee2a5":"print(f'number of train data: {len(train_df)}')\nprint(f'number of test data: {len(sample_submission_df)}')","3dc56ee3":"print(f'number of unique label: {train_df[TARGET].nunique()}')","95265afe":"sns.countplot(train_df[TARGET])\nplt.title('train label distribution')\nplt.show()","48ff7f69":"train_df.head()","d83a2136":"sample = train_df.groupby(TARGET).first().reset_index()\n\nfig, ax = plt.subplots(2, 5)\nfig.set_size_inches(4 * 5, 4 * 2)\n\nfor i, row in sample.iterrows():\n    fname, label = row[ID], row[TARGET]\n    img = cv2.imread(os.path.join(PATH['train_image_dir'], fname))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    ax[i\/\/5,i%5].imshow(img, 'gray')\n    ax[i\/\/5,i%5].set_title(f'{fname} - label: {label}')","9ec05a06":"print(f'shape of image: {img.shape}')","0dbbb6a8":"class KMNISTDataset(Dataset):\n    def __init__(self, fname_list, label_list, image_dir, transform=None):\n        super().__init__()\n        self.fname_list = fname_list\n        self.label_list = label_list\n        self.image_dir = image_dir\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.fname_list)\n    \n    def __getitem__(self, idx):\n        fname = self.fname_list[idx]\n        label = self.label_list[idx]\n        \n        image = cv2.imread(os.path.join(self.image_dir, fname))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        if self.transform is not None:\n            image = self.transform(image)\n        \n        return image, label","abdea641":"class MLP(nn.Module):\n    def __init__(self, input_dim=28*28, hidden_dim=128, output_dim=10):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, output_dim)\n        self.activation = nn.ReLU()\n    \n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        x = self.fc1(x)\n        x = self.activation(x)\n        x = self.fc2(x)\n        \n        return x","42f044cc":"train_df, valid_df = train_test_split(\n    train_df, test_size=PARAMS['valid_size'], random_state=SEED, shuffle=True\n)\ntrain_df = train_df.reset_index(drop=True)\nvalid_df = valid_df.reset_index(drop=True)","e5270f59":"print(f'number of train data: {len(train_df)}')\nprint(f'number of valid data: {len(valid_df)}')","058f2505":"transform = transforms.Compose([\n    transforms.ToTensor(),\n])\n\ntrain_dataset = KMNISTDataset(train_df[ID], train_df[TARGET], PATH['train_image_dir'], transform=transform)\nvalid_dataset = KMNISTDataset(valid_df[ID], valid_df[TARGET], PATH['train_image_dir'], transform=transform)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=PARAMS['batch_size'], shuffle=True)\nvalid_dataloader = DataLoader(valid_dataset, batch_size=PARAMS['valid_batch_size'], shuffle=False)","a249be9b":"model = MLP().to(DEVICE)\noptim = Adam(model.parameters(), lr=PARAMS['lr'])\ncriterion = nn.CrossEntropyLoss()","e47d1717":"def accuracy_score_torch(y_pred, y):\n    y_pred = torch.argmax(y_pred, axis=1).cpu().numpy()\n    y = y.cpu().numpy()\n\n    return accuracy_score(y_pred, y)","3f754695":"for epoch in range(PARAMS['epochs']):\n    model.train()\n    train_loss_list = []\n    train_accuracy_list = []\n    \n    for x, y in train_dataloader:\n        x = x.to(dtype=torch.float32, device=DEVICE)\n        y = y.to(dtype=torch.long, device=DEVICE)\n        \n        optim.zero_grad()\n        y_pred = model(x)\n        loss = criterion(y_pred, y)\n        loss.backward()\n        optim.step()\n        \n        train_loss_list.append(loss.item())\n        train_accuracy_list.append(accuracy_score_torch(y_pred, y))\n    \n    model.eval()\n    valid_loss_list = []\n    valid_accuracy_list = []\n\n    for x, y in valid_dataloader:\n        x = x.to(dtype=torch.float32, device=DEVICE)\n        y = y.to(dtype=torch.long, device=DEVICE)\n        \n        with torch.no_grad():\n            y_pred = model(x)\n            loss = criterion(y_pred, y)\n        \n        valid_loss_list.append(loss.item())\n        valid_accuracy_list.append(accuracy_score_torch(y_pred, y))\n    \n    print('epoch: {}\/{} - loss: {:.5f} - accuracy: {:.3f} - val_loss: {:.5f} - val_accuracy: {:.3f}'.format(\n        epoch,\n        PARAMS['epochs'], \n        np.mean(train_loss_list),\n        np.mean(train_accuracy_list),\n        np.mean(valid_loss_list),\n        np.mean(valid_accuracy_list)\n    ))","877cc38e":"transform = transforms.Compose([\n    transforms.ToTensor(),\n])\n\ntest_dataset = KMNISTDataset(\n    sample_submission_df[ID],\n    sample_submission_df[TARGET],\n    PATH['test_image_dir'],\n    transform=transform\n)\n\ntest_dataloader = DataLoader(test_dataset, batch_size=PARAMS['test_batch_size'], shuffle=False)","45d3969e":"model.eval()\npredictions = []\n\nfor x, _ in test_dataloader:\n    x = x.to(dtype=torch.float32, device=DEVICE)\n    \n    with torch.no_grad():\n        y_pred = model(x)\n        y_pred = torch.argmax(y_pred, axis=1).cpu().numpy()\n        y_pred = y_pred.tolist()\n        \n    predictions += y_pred","a025dba1":"sample_submission_df[TARGET] = predictions","147029a9":"sample_submission_df.to_csv('submission.csv', index=False)\nfrom IPython.display import FileLink\nFileLink('submission.csv')","b7ba9ef4":"sns.countplot(sample_submission_df[TARGET])\nplt.title('test prediction label distribution')\nplt.show()","e1474f3b":"fig, ax = plt.subplots(2, 5)\nfig.set_size_inches(4 * 5, 4 * 2)\n\nfor i, row in sample_submission_df.iloc[:10,:].iterrows():\n    fname, label = row[ID], row[TARGET]\n    img = cv2.imread(os.path.join(PATH['test_image_dir'], fname))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    ax[i\/\/5,i%5].imshow(img, 'gray')\n    ax[i\/\/5,i%5].set_title(f'{fname} - label: {label}')","ed544884":"# \u5b66\u7fd2","f18c0f30":"# \u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30a4\u30f3\u30dd\u30fc\u30c8","c8afe574":"# \u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f","b3025f79":"# \u4e88\u6e2c\u78ba\u8a8d","50ecc7a3":"# Dataset\u30af\u30e9\u30b9\u306e\u5b9a\u7fa9","2f6816c7":"# \u81ea\u4f5c\u95a2\u6570\u306e\u5b9a\u7fa9","36e89adc":"# Module\u30af\u30e9\u30b9\u306e\u5b9a\u7fa9","c1b4ff7d":"# \u30c7\u30fc\u30bf\u306e\u78ba\u8a8d","0efe32d8":"# \u4e88\u6e2c"}}