{"cell_type":{"974468f0":"code","40839119":"code","aa15d91f":"code","5b2ff2ba":"code","a06d73a9":"code","889252e3":"code","ba4dab8a":"code","e8e060a9":"code","9a617279":"code","9a4a56a5":"code","64eaa72a":"code","ea234dfc":"code","46396cb6":"code","8aa062a7":"code","4ea07ec0":"code","2b24ecee":"code","f06f748e":"code","eb111250":"code","33f9ff32":"code","d7e98eff":"code","1d0d4391":"code","232b13be":"code","4053c156":"code","21a88cf5":"code","88cf39d6":"code","c7ac72c6":"code","77b0a2b1":"code","15ffcff3":"code","6833e1ce":"code","c605d94d":"code","318deeda":"code","b7b43906":"markdown","5df5373e":"markdown","9e2696e8":"markdown","b5d13773":"markdown","53cc6507":"markdown","70185f97":"markdown","0faf1ad8":"markdown","75fb9b2a":"markdown","1d567c71":"markdown","02d5adee":"markdown"},"source":{"974468f0":"import numpy as np\nimport pandas as pd\nimport itertools\nimport glob\nimport os\nimport copy\nimport cv2\nimport math\nimport shutil\nfrom PIL import Image\nfrom sklearn.metrics import accuracy_score\nfrom IPython.display import Video, display\nfrom tqdm.auto import tqdm\nfrom multiprocessing import Pool\nfrom matplotlib import pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom scipy.spatial import KDTree\nfrom scipy.optimize import linear_sum_assignment\nfrom scipy.spatial import distance\nimport random\nimport sys\n# sys.path.append('..\/input\/easydict-master\/easydict-master\/')\n# # https:\/\/github.com\/mikel-brostrom\/Yolov5_DeepSort_Pytorch\n# sys.path.append('..\/input\/yolov5-deepsort-pytorch\/Yolov5_DeepSort_Pytorch-master\/Yolov5_DeepSort_Pytorch-master\/deep_sort_pytorch\/')\n# from deep_sort.deep_sort import DeepSort\n# from utils.parser import get_config\nimport warnings\nwarnings.simplefilter('ignore')","40839119":"## Install helmet-assignment helper code\n!pip install ..\/input\/helmet-assignment-helpers\/helmet-assignment-main\/ > \/dev\/null 2>&1\nfrom helmet_assignment.score import NFLAssignmentScorer, check_submission\nfrom helmet_assignment.features import add_track_features\nfrom helmet_assignment.video import video_with_predictions","aa15d91f":"! pip install ..\/input\/pip-install-sort\/filterpy-1.4.5.zip\nsys.path.append('..\/input\/sort-github\/sort-master\/')\nfrom sort import Sort","5b2ff2ba":"def calc_dif_angle(theta1, theta2):\n    theta_large, theta_small = np.zeros_like(theta1), np.zeros_like(theta2)\n    theta_large = np.max(np.array([theta1, theta2]), axis=0)\n    theta_small = np.min(np.array([theta1, theta2]), axis=0)\n\n    dif1 = theta_large - theta_small\n    dif2 = np.pi + theta_small - theta_large\n    return np.min(np.array([dif1, dif2]), axis=0)\n\ndef calc_loss_angles(angles, target_angle, thres = 0.4):\n    dif = calc_dif_angle(angles, np.ones_like(angles) * target_angle)\n    loss = dif * dif\n    loss[dif > thres] = np.abs(dif[dif > thres]) # Huber loss\n    return np.sum(loss)\n\ndef calc_optimal_angle(angles):\n    angle_opt = 0\n    loss_opt = 1e9\n    for ang in np.linspace(0, np.pi, 100):\n        loss = calc_loss_angles(angles, ang)\n        if loss < loss_opt:\n            loss_opt = loss\n            angle_opt = ang\n    return angle_opt\n\ndef loss_func(cand_scale, dif_list):\n    loss_residual = np.sum([\n        np.min([np.abs(dif % cand_scale), np.abs(cand_scale - dif % cand_scale)]\n              ) ** 2 for dif in dif_list]) # \u5272\u3063\u305f\u3042\u307e\u308a\n    loss_multipled = np.sum([np.max(dif \/\/ cand_scale - 1, 0) for dif in dif_list]) # n\u500d\u306a\u3089\u3001n-1\u3092\u7f70\u5247\u3068\u3057\u3066\u4e0e\u3048\u308b\uff08n >= 1\u306a\u3089\u306a\u3057\uff09\n    loss_under = np.sum([np.max(cand_scale \/\/ dif - 1, 0) for dif in dif_list]) # 1\/n\u500d\u306a\u3089\u3001n-1\u3092\u7f70\u5247\u3068\u3057\u3066\u4e0e\u3048\u308b\uff08n <= 1\u306a\u3089\u306a\u3057\uff09\n    return loss_residual + loss_multipled + loss_under\n\ndef get_optimal_dif(dif_list, view):\n    opt_dif = 0\n    opt_loss = 1e9\n    if view == 'Sideline':\n        candidates = np.arange(100, 250, 5)\n    else:\n        candidates = np.arange(70, 170, 5)\n        \n    for x in candidates:\n        loss = loss_func(x, dif_list)\n        if loss < opt_loss:\n            opt_dif = x\n            opt_loss = loss\n    return opt_dif\n\ndef get_average_dist_from_lines(line_pos_list, view):\n    sets = []\n    min_thres = 30\n    for d in sorted(line_pos_list):\n        if len(sets) == 0:\n            sets.append([d])\n        else:\n            if d - sets[-1][-1] < min_thres:\n                sets[-1].append(d)\n            else:\n                sets.append([d])\n    pos_list = np.array([np.mean(set_pos) for set_pos in sets])\n    \n    if True:\n        dist_pred = get_optimal_dif(pos_list[1:] - pos_list[:-1], view)\n    else:\n        dist_pred = np.mean(pos_list[1:] - pos_list[:-1])\n    # print(*pos_list, sep=',')\n    # print(*pos_list[1:] - pos_list[:-1], sep=',')\n    return dist_pred\n\ndef predict_line_parameters(img, view = 'Endzone'):\n    kernel_size = 40\n    img_dif_threshold = 70\n\n    kernel = np.ones((kernel_size, kernel_size)) \/ kernel_size **2\n    img_morph = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n    counter = 0\n\n    while True:\n        img_dif = np.linalg.norm(img_morph - np.median(img, axis=(0, 1)), axis=2)\n        img_field = np.copy(img)\n        img_field[img_dif > img_dif_threshold - counter * 10] = 0\n        edges = cv2.Canny(img_field, 50, 150, apertureSize = 3)\n        lines = cv2.HoughLines(edges, 1, np.pi\/180, 200)\n        if lines is None:\n            return np.nan, np.nan\n        if len(lines) < 100:\n            break\n        counter += 1\n        if img_dif_threshold - counter * 10 < 0:\n            return np.nan, np.nan\n    \n    if lines is None:\n        return np.nan, np.nan\n    if len(lines) > 100:\n        return np.nan, np.nan\n\n    # Drop duplicates\n    lines_new = np.copy(lines)\n    thres_angle = 0.1\n    thres_dist = 20\n    idx = 0\n    while len(lines_new) > idx:\n        dif_dist = lines_new[:, 0, 0] - lines_new[idx, 0, 0]\n        dif_angle = calc_dif_angle(lines_new[:, 0, 1], np.ones_like(lines_new[:, 0, 1]) * lines_new[idx, 0, 1])\n        duplicate = (dif_dist < thres_dist) & (dif_angle < thres_angle) & (dif_dist > 0) & (dif_angle > 0)\n        lines_new = lines_new[~duplicate]\n        idx += 1\n\n    if view == 'Sideline':\n        lines_new = lines_new[np.abs(lines_new[:, 0, 1] - np.pi \/ 2) > np.pi \/ 4]\n    else:\n        lines_new = lines_new[np.abs(lines_new[:, 0, 1] - np.pi \/ 2) < np.pi \/ 4]\n    lines_new = lines_new[lines_new[:, 0, 1] != 0] # Remove edges\n\n    # Calculate angles (Took a lot of time defining optimal angle...)\n    theta_pred = calc_optimal_angle(lines_new[:, 0, 1])\n    lines_same_direction = lines_new[calc_dif_angle(lines_new[:, 0, 1], np.ones_like(lines_new[:, 0, 1]) * theta_pred) < 0.4]\n    if len(lines_same_direction) == 0:\n        return np.nan, np.nan\n\n    if view == 'Sideline':\n        ym = 360\n        rho = lines_same_direction[:, 0, 0]\n        theta = lines_same_direction[:, 0, 1]\n        xms = (rho - ym * np.sin(theta)) \/ np.cos(theta)\n        dist_pred = get_average_dist_from_lines(xms, view) * np.abs(np.cos(theta_pred))\n    else:\n        xm = 640\n        rho = lines_same_direction[:, 0, 0]\n        theta = lines_same_direction[:, 0, 1]\n        yms = (rho - xm * np.cos(theta)) \/ np.sin(theta)\n        dist_pred = get_average_dist_from_lines(yms, view) * np.abs(np.sin(theta_pred))\n\n    return theta_pred, dist_pred","a06d73a9":"from scipy.spatial import KDTree\nimport numpy as np\n\nclass ICP(object):\n    def __init__(self, pointsA, pointsB):\n        self.pointsA = pointsA\n        self.pointsB = pointsB\n        self.kdtree = KDTree(self.pointsA)\n        self.loss = 0\n\n    def calculate(self, iter):\n        old_points = np.copy(self.pointsB)\n        new_points = np.copy(self.pointsB)\n\n        try:\n            for i in range(iter):\n                neighbor_idx = self.kdtree.query(old_points)[1]\n                targets = self.pointsA[neighbor_idx]\n                R, T = calcRigidTranformation(old_points, targets)\n                new_points = np.dot(R, old_points.T).T + T\n                if  np.sum(np.abs(old_points - new_points)) < 1e-10:\n                    break\n\n                old_points = np.copy(new_points)\n\n                self.loss = np.mean(np.linalg.norm(targets - new_points, axis=1))\n        except:\n            return new_points\n\n        return new_points\n\ndef calcRigidTranformation(MatA, MatB):\n    A, B = np.copy(MatA), np.copy(MatB)\n\n    centroid_A = np.mean(A, axis=0)\n    centroid_B = np.mean(B, axis=0)\n\n    A -= centroid_A\n    B -= centroid_B\n\n    H = np.dot(A.T, B)\n    U, S, V = np.linalg.svd(H)\n    R = np.dot(V.T, U.T)\n    T = np.dot(-R, centroid_A) + centroid_B\n\n    return R, T","889252e3":"def calculate_hungarian_matching(pos_helmets_input, pos_tracking_input, rate_x2y,\n                                 # conf_helmets,\n                                ):\n    pos_helmets = np.copy(pos_helmets_input)\n    pos_tracking = np.copy(pos_tracking_input)\n    pos_helmets[:, 0] *= rate_x2y\n    pos_tracking[:, 0] *= rate_x2y\n    dist_matrix = distance.cdist(pos_helmets, pos_tracking, metric='euclidean')\n    # dist_matrix \/= conf_helmets.reshape(-1, 1)\n    helmets_idx, tracking_idx = linear_sum_assignment(dist_matrix)\n    dist = np.array([dist_matrix[i, j] for i, j in zip(helmets_idx, tracking_idx)])\n    return dist, helmets_idx, tracking_idx","ba4dab8a":"def calculate_hungarian_matching_with_team(\n        pos_helmets_input,\n        pos_tracking_input,\n        rate_x2y,\n        # conf_helmets,\n        team_helmets,\n        labels_tracking,\n        team_dif_penalty,\n    ):\n    \"\"\"\n    pos_helmets: np.ndarray\n    pos_tracking: np.ndarray\n    rate_x2y: float\n    team_helmets: [0 or 1]\n    team_tracking: ['Hn' for 'Vn']\n    \"\"\"\n    dist_sum_opt = 1e9\n    dist_opt = None\n    helmets_idx_opt = None\n    tracking_idx_opt = None\n    team_cand = ['H', 'V']\n\n    for cand_1 in team_cand:\n        team_tracking = np.array([cand_1 in label for label in labels_tracking]) * 1\n        pos_helmets = np.copy(pos_helmets_input)\n        pos_tracking = np.copy(pos_tracking_input)\n        pos_helmets[:, 0] *= rate_x2y\n        pos_tracking[:, 0] *= rate_x2y\n        dist_matrix = distance.cdist(pos_helmets, pos_tracking, metric='euclidean')\n        for i in range(len(pos_helmets)):\n            for j in range(len(pos_tracking)):\n                if team_helmets[i] != team_tracking[j]:\n                    # dist_matrix[i, j] *= team_dif_penalty\n                    # dist_matrix[i, j] += team_dif_penalty\n                    dist_matrix[i, j] = np.sqrt(dist_matrix[i, j] ** 2 + team_dif_penalty ** 2)\n        # dist_matrix \/= conf_helmets.reshape(-1, 1)\n        helmets_idx, tracking_idx = linear_sum_assignment(dist_matrix)\n        dist = np.array([dist_matrix[i, j] for i, j in zip(helmets_idx, tracking_idx)])\n\n        if np.sum(dist) < dist_sum_opt:\n            dist_sum_opt = np.sum(dist)\n            dist_opt = dist\n            helmets_idx_opt = helmets_idx\n            tracking_idx_opt = tracking_idx\n\n    return dist_opt, helmets_idx_opt, tracking_idx_opt","e8e060a9":"def get_icp_results(pos_helmets, pos_tracking, theta_init, initial_scale_x, initial_scale_y):\n    pos_helmets_scaled = np.copy(pos_helmets)\n    pos_helmets_scaled[:, 0] = pos_helmets_scaled[:, 0] * initial_scale_x\n    pos_helmets_scaled[:, 1] = pos_helmets_scaled[:, 1] * initial_scale_y\n\n    initial_rot = np.array([[np.cos(theta_init), np.sin(theta_init)],\n                            [-np.sin(theta_init), np.cos(theta_init)]])\n    pos_helmets_initialized = pos_helmets_scaled @ initial_rot\n    pos_helmets_initialized -= np.mean(pos_helmets_initialized, axis=0) - np.mean(pos_tracking, axis=0)\n\n    icp = ICP(pos_tracking, pos_helmets_initialized)\n    pos_helmets_icp = icp.calculate(3000)\n\n    return pos_helmets_icp, icp.loss","9a617279":"class MonteCarloICP:\n    def __init__(self, initial_scale_factor, view, num_iter, rate_x2y):\n        self.scale_factors = initial_scale_factor\n        self.num_iter = num_iter\n        self.view = view\n        self.rate_x2y = rate_x2y\n\n    def get_icp_results_montecarlo(self,\n                                   pos_helmets_input,\n                                   pos_tracking_input,\n                                   theta_init,\n                                   # conf_helmets,\n                                   tracking_orientation,\n                                   helmets_scale,\n                                   helmets_cluster=None,\n                                   labels_tracking=None):\n        # ###### PARAMETERS ######\n        # pixel_per_line_cand_sideline=np.hstack([np.arange(150, 250, 10), np.arange(250, 701, 50)])\n        # # pixel_per_line_cand_sideline=np.arange(150, 250, 10)\n        # pixel_per_line_cand_endzone=np.hstack([np.arange(60, 160, 15), np.arange(200, 401, 40)])\n        # # pixel_per_line_cand_endzone=np.arange(60, 160, 15)\n        # ###### PARAMETERS ######\n\n\n        opt_loss = 1e9\n        pos_helmets_opt = None\n        self.opt_params = None # Dont forget to initialize!!!!\n        for i in range(self.num_iter):\n            if self.view == 'Sideline':\n                # pixel_per_line = random.choice(PIXEL_PER_LINE_CAND_SIDELINE)\n                pixel_per_line = random.choice(LINE_PER_HELMET_CAND_SIDELINE * helmets_scale)\n            else:\n                # pixel_per_line = random.choice(PIXEL_PER_LINE_CAND_ENDZONE)\n                pixel_per_line = random.choice(LINE_PER_HELMET_CAND_ENDZONE * helmets_scale)\n            # pixel_per_line = pixel_per_line_init\n            \n            if np.isnan(theta_init):\n                if self.view == \"Sideline\":\n                    theta_init = random.gauss(0, np.pi \/ 8)\n                else:\n                    theta_init = random.gauss(np.pi \/ 2, np.pi \/ 8)\n\n            initial_scale_x = self.scale_factors[0] \/ pixel_per_line * np.exp(np.log(SCALE_RATE_EXP) * (0.5 - np.random.random()) * 2)\n            initial_scale_y = self.scale_factors[1] \/ pixel_per_line * np.exp(np.log(SCALE_RATE_EXP) * (0.5 - np.random.random()) * 2)\n            forward_shift_scale = random.random() * 0.4\n\n            # Copy variables\n            pos_tracking = np.copy(pos_tracking_input)\n            pos_helmets = np.copy(pos_helmets_input)\n\n            pos_tracking += forward_shift_scale * np.array([\n                np.cos((- tracking_orientation + 90) \/ 180 * np.pi),\n                np.sin((- tracking_orientation + 90) \/ 180 * np.pi)]\n            ).T\n\n            pos_helmets_icp, icp_loss = get_icp_results(\n                pos_helmets, pos_tracking,\n                theta_init, initial_scale_x, initial_scale_y)\n\n            if helmets_cluster is None:\n                dist, helmets_idx, tracking_idx = calculate_hungarian_matching(\n                    pos_helmets_icp,\n                    pos_tracking,\n                    self.rate_x2y,\n                    # conf_helmets,\n                )\n            else:\n                dist, helmets_idx, tracking_idx = calculate_hungarian_matching_with_team(\n                    pos_helmets_icp,\n                    pos_tracking,\n                    self.rate_x2y,\n                    # conf_helmets,\n                    helmets_cluster,\n                    labels_tracking,\n                    TEAM_DIF_PENALTY\n                )\n            score = np.sum(dist)\n            if score < opt_loss:\n                opt_loss = score\n                pos_helmets_opt = pos_helmets_icp\n                self.opt_params = (initial_scale_x, initial_scale_y, forward_shift_scale)\n            \n        return pos_helmets_opt, opt_loss","9a4a56a5":"def apply_icp_per_frame_by_team(args, predict_optimal_theta=False):\n    # ###### PARAMETERS ######\n    # num_particles=100\n    # rate_x2y={'Endzone': 0.5, 'Sideline': 1.0}\n    # scale_factor={'Endzone': [2, 4.5], 'Sideline': [4, 10]}\n    # team_dif_penalty=2.0\n    # ###### PARAMETERS ######\n\n    game_play, view, frame, tracking_frame, helmets_frame, theta_line, video_dir = args\n    tracking_frame = tracking_frame[~tracking_frame.duplicated('player')] # drop duplicates!\n\n    pos_tracking = tracking_frame[['x', 'y']].values\n    labels_tracking = tracking_frame['player'].values\n    helmets_frame = helmets_frame[helmets_frame['conf'] > CONF_THRE]\n    pos_helmets = helmets_frame[['x', 'y']].values\n    pos_helmets[:, 0] *= -1\n\n    if 'cluster_id' not in helmets_frame.columns:\n        helmets_frame['cluster_id'] = -1\n\n    # Get theta pred from image\n    if predict_optimal_theta:\n        ### FFMPEG MODE ###\n        image = Image.open(f'\/kaggle\/working\/temp\/{frame}.png')\n        image = np.array(image)\n\n        # ### NORMAL EXTRACTION MODE ###\n        # cap = cv2.VideoCapture(f'{video_dir}\/{game_play}_{view}.mp4')\n        # cap.set(cv2.CAP_PROP_POS_FRAMES, frame-1) # optional\n        # success, image = cap.read()\n\n        theta_line, pixel_per_line = predict_line_parameters(image, view=view)        \n        if np.isnan(theta_line):\n            if view == 'Sideline':\n                theta_cand_list = list(np.linspace(- np.pi \/ 4, np.pi \/ 4, 5))\n                theta_cand_list += list(np.linspace(- np.pi \/ 4 + np.pi, np.pi \/ 4 + np.pi, 5))\n            else:\n                theta_cand_list = list(np.linspace(np.pi \/ 4, 3 * np.pi \/ 4, 5))\n                theta_cand_list += list(np.linspace(np.pi \/ 4 + np.pi, 3 * np.pi \/ 4 + np.pi, 5))\n        else:\n            theta_cand_list = [\n                theta_line,\n                np.pi + theta_line\n            ]\n    else:\n        theta_cand_list = [theta_line]\n\n    # Start ICP\n    micp = MonteCarloICP(SCALE_FACTOR[view], view, num_iter=NUM_PARTICLES, rate_x2y=RATE_X2Y[view])\n    opt_loss = 1e9\n    pos_helmets_opt = None\n    idx_of_interest = [True for _ in pos_helmets]\n    for i, theta_cand in enumerate(theta_cand_list):\n        pos_helmets_icp, icp_loss = micp.get_icp_results_montecarlo(\n            pos_helmets,\n            pos_tracking,\n            theta_cand,\n            # helmets_frame['conf'].values,\n            tracking_frame['o'].values,\n            helmets_scale = (helmets_frame['width'].mean() + helmets_frame['height'].mean()) \/ 2,\n            helmets_cluster = helmets_frame['cluster_id'].iloc[idx_of_interest].values if helmets_frame['cluster_id'].nunique() > 1 else None,\n            labels_tracking = labels_tracking\n        )\n        if opt_loss > icp_loss:\n            opt_loss = icp_loss\n            pos_helmets_opt = pos_helmets_icp\n            opt_micp = micp\n            opt_theta = theta_cand\n\n    # if len(pos_helmets) > NUM_HELMETS_THRES_FOR_OUTSIDERS:\n    if helmets_frame[helmets_frame['conf'] > CONF_THRE].shape[0] > NUM_HELMETS_THRES_FOR_OUTSIDERS:\n        # print('Try here too')\n        counter = 0\n        while counter < NUM_ITER_OUTSIDERS:\n            for i, theta_cand in enumerate(theta_cand_list):\n                thres_y_top = random.choice(np.arange(40, 201, 40))\n                thres_y_bottom = 720 - random.choice(np.arange(40, 201, 40))\n                idx_of_interest_tmp = (pos_helmets[:, 1] > thres_y_top) & (pos_helmets[:, 1] < thres_y_bottom)\n                if np.sum(idx_of_interest_tmp) < 15:\n                    continue\n                pos_helmets_without_edges = pos_helmets[idx_of_interest_tmp]\n\n                pos_helmets_icp, icp_loss = micp.get_icp_results_montecarlo(\n                    pos_helmets_without_edges,\n                    pos_tracking,\n                    theta_cand,\n                    # helmets_frame['conf'].values[idx_of_interest_tmp],\n                    tracking_frame['o'].values,\n                    helmets_scale = (helmets_frame['width'].mean() + helmets_frame['height'].mean()) \/ 2,\n                    helmets_cluster = helmets_frame['cluster_id'].iloc[idx_of_interest_tmp].values if helmets_frame['cluster_id'].nunique() > 1 else None,\n                    labels_tracking = labels_tracking\n                )\n                if opt_loss > icp_loss:\n                    opt_loss = icp_loss\n                    pos_helmets_opt = pos_helmets_icp\n                    opt_micp = micp\n                    idx_of_interest = idx_of_interest_tmp\n                    opt_theta = theta_cand\n            counter += 1\n\n    # Post Processing\n    pos_tracking_tmp = pos_tracking + opt_micp.opt_params[2] * np.array([\n        np.cos((- tracking_frame['o'] + 90) \/ 180 * np.pi),\n        np.sin((- tracking_frame['o'] + 90) \/ 180 * np.pi)]\n    ).T\n\n    if helmets_frame['cluster_id'].nunique() == 1:\n        dist, helmets_idx, tracking_idx = calculate_hungarian_matching(\n           pos_helmets_opt,\n           pos_tracking_tmp,\n           RATE_X2Y[view],\n           # helmets_frame['conf'].values[idx_of_interest],\n        )\n    else:\n        dist, helmets_idx, tracking_idx = calculate_hungarian_matching_with_team(\n            pos_helmets_opt,\n            pos_tracking_tmp,\n            RATE_X2Y[view],\n            # helmets_frame['conf'].values[idx_of_interest],\n            helmets_frame['cluster_id'].values[idx_of_interest],\n            labels_tracking,\n            TEAM_DIF_PENALTY\n        )\n    labels_predicted = labels_tracking[tracking_idx] # [idx_of_interest]\n    helmets_pred_frame = helmets_frame.iloc[idx_of_interest].iloc[helmets_idx].copy()\n    helmets_pred_frame['label'] = labels_predicted\n    helmets_pred_frame['opt_loss'] = opt_loss\n    helmets_pred_frame['matching_dist'] = dist\n\n    if predict_optimal_theta:\n        return opt_theta\n    else:\n        return helmets_pred_frame","64eaa72a":"def apply_icp_multiprocess_by_team(helmets, tracking_processed, video_dir):\n    ###### PARAMETERS ######\n    clusterization_rate_thres=1e9\n    clusterization_dist_thres=0\n    clusterization_helmet_shrink_rate=0.7\n    ###### PARAMETERS ######\n\n    df_results_icp_list = []\n    df_results_icp = pd.DataFrame()\n    game_play2tracking = dict(tuple(tracking_processed.groupby('game_play')))\n    for video, helmets_video in helmets.groupby('video'):\n        game_play = video.split('_')[0] + '_' + video.split('_')[1]\n        view = video.split('_')[2].split('.')[0]\n        tracking_video = game_play2tracking[game_play] # tracking_processed[tracking_processed['game_play'] == game_play]\n        helmets_video = helmets_video[helmets_video['conf'] > CONF_THRE]\n        video_name = f'{game_play}_{view}'\n\n        ### FFMPEG ###\n        video_file = f'{video_dir}\/{video_name}.mp4'\n        if os.path.exists('\/kaggle\/working\/temp'):\n            shutil.rmtree('\/kaggle\/working\/temp')\n        os.mkdir('\/kaggle\/working\/temp')\n        !ffmpeg \\\n            -hide_banner \\\n            -loglevel fatal \\\n            -nostats \\\n            -i $video_file temp\/%d.png\n        ### FFMPEG ###\n\n        helmets_clusterized_video = helmet_clusterization_video(helmets_video,\n                                                              clusterization_rate_thres,\n                                                              clusterization_dist_thres,\n                                                              clusterization_helmet_shrink_rate)\n        p = Pool(processes=4)\n        submission_df_list = []\n\n        tracking_video_dict = dict(list(tracking_video.groupby('frame')))\n        helmets_video_dict = dict(list(helmets_clusterized_video.groupby('frame')))\n\n        args_frame_1 = (game_play, view, 1, tracking_video_dict[1], helmets_video_dict[1], np.nan, video_dir)\n        optimal_theta = apply_icp_per_frame_by_team(args_frame_1, predict_optimal_theta=True)\n\n        data_video_list = [(game_play, view, int(k), tracking_video_dict[k], helmets_video_dict[k], optimal_theta, video_dir) \\\n                           for k in helmets_video_dict.keys()]\n        with tqdm(total=len(data_video_list)) as pbar:\n            for this_df in p.imap(apply_icp_per_frame_by_team, data_video_list):\n                df_results_icp_list.append(this_df)\n                pbar.update(1)\n        p.close()\n\n        ### Delete the results of FFMPEG ###\n        shutil.rmtree('\/kaggle\/working\/temp')\n        ### Delete the results of FFMPEG ###\n\n    df_results_icp = pd.concat(df_results_icp_list, axis=0)\n    return df_results_icp","ea234dfc":"def helmet_clusterization_video(helmets_video, rate_thres, dist_thres, helmet_shrink_rate, using_gt=False):\n    def return_mean_helmets(d):\n        radius_x = d.height \/ 2 * helmet_shrink_rate \n        radius_y = d.width \/ 2 * helmet_shrink_rate\n        center_x = d.top + d.height \/ 2\n        center_y = d.left + d.width \/ 2\n        return np.mean(image[max([int(center_x - radius_x), 0]): int(center_x + radius_x),\n                                                max([int(center_y - radius_y), 0]): int(center_y + radius_y)], axis=(0, 1))\n        # return np.mean(image[d.top: d.top + d.height, d.left: d.left + d.width,], axis=(0, 1)), axis=1)\n\n    helmets_info_video_list = []\n    helmets_ans_video_list = []\n    for frame in sorted(helmets_video['frame'].unique()):\n        helmets_frame = helmets_video[helmets_video['frame'] == frame]\n\n        image = Image.open(f'\/kaggle\/working\/temp\/{frame}.png')\n        image = np.array(image)\n        image[:, :, 1] = 0\n        # helmets_info_frame = helmets_frame.apply(lambda d: np.mean(\n        #     image[np.max([int(d.y - radius), 0]): int(d.y + radius),\n        #           np.max([int(d.x - radius), 0]): int(d.x + radius)],\n        #     axis=(0, 1)), axis=1)\n        # helmets_info_frame = helmets_frame.apply(lambda d: np.mean(\n        #    image[d.top: d.top + d.height, d.left: d.left + d.width,],\n        #     axis=(0, 1)), axis=1)\n        helmets_info_frame = helmets_frame.apply(return_mean_helmets, axis=1)\n        helmets_info_frame = np.array([data for data in helmets_info_frame.values])\n        helmets_info_video_list.append(helmets_info_frame)\n        if using_gt:\n            helmets_ans_video_list.append(helmets_frame['label'].apply(lambda x: 'H' in x).values * 1)\n\n    helmets_info_video = np.vstack(helmets_info_video_list)\n    if using_gt:\n        helmets_ans_video = np.hstack(helmets_ans_video_list)\n\n    try:\n        pred = KMeans(n_clusters=2).fit_predict(helmets_info_video)\n    except:\n        print('DETECTED ERROR IN Kmeans!!!!! OH NO!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n        import traceback\n        traceback.print_exc()\n        df_tmp = helmets_video.copy()\n        df_tmp['cluster_id'] = -1\n        return df_tmp\n\n    same_rate = np.sum(pred) \/ np.sum(1 - pred)\n    dist = np.linalg.norm(\n        helmets_info_video[pred == 1].mean(axis=0) - helmets_info_video[pred == 0].mean(axis=0)\n    )\n\n    df_tmp = helmets_video.copy()\n    df_tmp['cluster_id'] = pred\n\n    detected_anomaly = False\n    if dist < dist_thres:\n        detected_anomaly = True\n    if same_rate > rate_thres or same_rate < 1 \/ rate_thres:\n        detected_anomaly = True\n\n    if detected_anomaly:\n        df_tmp['cluster_id'] = -1\n\n    print(helmets_video['video'].unique()[0],\n          df_tmp['cluster_id'].sum(),\n          df_tmp['cluster_id'].shape[0] - df_tmp['cluster_id'].sum(),\n          dist)\n    if detected_anomaly:\n        print('ANOMALY DETECTED!')\n    else:\n        print('Use team info for this video')\n\n    if using_gt:\n        acc_rate = (helmets_ans_video == pred).sum() \/ len(pred)\n        print('======================================================')\n        print(video)\n        print('accuracy: {}'.format(np.max((acc_rate, 1-same_rate))))\n        print('class num: {0} to {1}'.format(np.sum(pred), len(pred) - np.sum(pred)))\n        print('metric? :{}'.format(dist))\n        if detected_anomaly:\n            print('DETECTED ANOMALY! NOT USING THIS VIDEO')\n\n    return df_tmp","46396cb6":"def my_add_sort_label_col(df_pred_video, tracking_video):\n    print('Use my add_sort_label_col')\n    sort_cluster_label_counts = df_pred_video.groupby('sort_cluster')['label'].value_counts()\n    sort_cluster_label_counts = sort_cluster_label_counts.to_frame().rename({'label': 'label_counts'}, axis=1).reset_index()\n\n    sort_clusters = sorted(df_pred_video['sort_cluster'].unique())\n    labels_in_frame = sorted(tracking_video['player'].unique())\n    df_dist = pd.DataFrame(np.ones((len(sort_clusters), len(labels_in_frame))), columns=labels_in_frame, index=sort_clusters) * 1e-5\n    for _, (sort_cluster, label, label_counts) in sort_cluster_label_counts.iterrows():\n        df_dist.loc[sort_cluster, label] = label_counts\n    df_dist = 1 \/ df_dist\n\n    df_updated_list = []\n    for frame, df_frame in df_pred_video.groupby('frame'):\n        dist_matrix = df_dist.loc[df_frame['sort_cluster'].values, :].values\n        sort_cluster_idx, label_idx = linear_sum_assignment(dist_matrix)\n        df_frame['label_sort'] = df_dist.columns[label_idx]\n        df_updated_list.append(df_frame)\n    df_pred_video_finalized = pd.concat(df_updated_list)\n    return df_pred_video_finalized","8aa062a7":"# def add_sort_label_col(out):\n#     # Find the top occuring label for each deepsort_cluster\n#     sortlabel_map = out.groupby('sort_cluster')['label'].value_counts() \\\n#         .sort_values(ascending=False).to_frame() \\\n#         .rename(columns={'label':'label_count'}) \\\n#         .reset_index() \\\n#         .groupby(['sort_cluster']) \\\n#         .first()['label'].to_dict()\n#     # Find the # of times that label appears for the deepsort_cluster.\n#     sortlabelcount_map = out.groupby('sort_cluster')['label'].value_counts() \\\n#         .sort_values(ascending=False).to_frame() \\\n#         .rename(columns={'label':'label_count'}) \\\n#         .reset_index() \\\n#         .groupby(['sort_cluster']) \\\n#         .first()['label_count'].to_dict()\n\n#     out['label_sort'] = out['sort_cluster'].map(sortlabel_map)\n#     out['label_count_sort'] = out['sort_cluster'].map(sortlabelcount_map)\n\n#     return out\n\ndef apply_sort(df_pred, tracking):\n    df_pred_updated_list = []\n    game_play2tracking = dict(tuple(tracking.groupby('game_play')))\n    for video, df_pred_video in tqdm(df_pred.groupby('video'), total=df_pred['video'].nunique(), desc='Apply SORT'):\n        # if np.random.rand() > 0.1:\n        #     continue\n        game_play = video.split('_')[0] + '_' + video.split('_')[1]\n        view = video.split('_')[2].split('.')[0]\n        tracking_video = game_play2tracking[game_play] # tracking_processed[tracking_processed['game_play'] == game_play]\n\n        mot_tracker = Sort(max_age=MAX_AGE, min_hits=MIN_HITS, iou_threshold=IOU_THRESHOLD)\n        res = []\n        for frame, df_pred_frame in tqdm(df_pred_video.groupby(['frame']), total=df_pred_video['frame'].nunique()):\n            df_pred_frame['right'] = df_pred_frame['left'] + df_pred_frame['width']\n            df_pred_frame['bottom'] = df_pred_frame['top'] + df_pred_frame['height']\n            dets = df_pred_frame[['left', 'top', 'right', 'bottom', 'conf']].values\n            trackers = mot_tracker.update(dets)\n\n            df_pred_frame_tracked = pd.DataFrame(trackers, columns=['left', 'top', 'right', 'bottom', 'sort_cluster'])\n\n            df_pred_frame_tracked['x'] = (df_pred_frame_tracked['left'] + df_pred_frame_tracked['right']) \/ 2\n            df_pred_frame_tracked['y'] = (df_pred_frame_tracked['top'] + df_pred_frame_tracked['bottom']) \/ 2\n\n            dist_matrix = distance.cdist(df_pred_frame[['x', 'y']].values, df_pred_frame_tracked[['x', 'y']].values, metric='euclidean')\n            d0_idx, d1_idx = linear_sum_assignment(dist_matrix)\n\n            df_pred_frame_aligned = df_pred_frame_tracked.iloc[d1_idx, :]\n            df_pred_frame_aligned.index = df_pred_frame.index[d0_idx]\n            df_pred_frame_updated = pd.concat([df_pred_frame.iloc[d0_idx], df_pred_frame_aligned['sort_cluster']], axis=1)\n            res.append(df_pred_frame_updated)\n        df_pred_video_updated = pd.concat(res)\n\n        # ## OLD VERSION\n        # df_pred_video_updated = add_sort_label_col(df_pred_video_updated)\n        # df_pred_video_updated['label_sort'] = df_pred_video_updated['label_sort'].fillna(df_pred_video_updated['label'])\n        # df_pred_video_updated = df_pred_video_updated.drop('label', axis=1).rename(columns={'label_sort':'label'})\n\n        # df_pred_video_updated = df_pred_video_updated.sort_values('label_count_sort', ascending=False)\n\n        # df_pred_video_updated = df_pred_video_updated.loc[\n        #     ~df_pred_video_updated[['video_frame', 'label']].duplicated()]\n        # # df_pred_video_updated = drop_duplicates_with_relabeling(df_pred_video_updated)\n\n        ## NEW VERSION\n        df_pred_video_updated = my_add_sort_label_col(df_pred_video_updated, tracking_video)\n        df_pred_video_updated['label_sort'] = df_pred_video_updated['label_sort'].fillna(df_pred_video_updated['label'])\n        df_pred_video_updated = df_pred_video_updated.drop('label', axis=1).rename(columns={'label_sort':'label'})\n\n        df_pred_updated_list.append(df_pred_video_updated)\n\n        if debug:\n            eval_video(df_pred_video, labels, video)\n            eval_video(df_pred_video_updated, labels, video)\n            print('Shape: {0} -> {1}'.format(df_pred_video.shape[0], df_pred_video_updated.shape[0]))\n    df_pred_sort = pd.concat(df_pred_updated_list)\n    return df_pred_sort","4ea07ec0":"# def drop_duplicates_with_relabeling(pred_video):\n#     pred_video = add_sort_label_col(pred_video)\n#     pred_video['label_sort'] = pred_video['label_sort'].fillna(pred_video['label'])\n#     pred_video = pred_video.sort_values('label_count_sort', ascending=False)\n#     sort_cluster_label_counts = pred_video.groupby('sort_cluster')['label'].value_counts()\n\n#     res_list = []\n#     labels_video_set = set(pred_video['label'].unique())\n#     for frame, df_pred_frame_tmp in  pred_video.sort_values('frame').groupby('frame'):\n#         # Add primaries\n#         df_pred_frame_tmp = df_pred_frame_tmp.sort_values('label_count_sort', ascending=False)\n#         df_pred_frame_tmp_safe = df_pred_frame_tmp[~df_pred_frame_tmp['label_sort'].duplicated()]\n#         df_pred_frame_tmp_remaining = df_pred_frame_tmp[df_pred_frame_tmp['label_sort'].duplicated()]\n#         labels_in_use_set = set(df_pred_frame_tmp_safe['label_sort'])\n#         labels_left_set = labels_video_set - labels_in_use_set\n\n#         # Add secondaries\n#         additionals = []\n#         for _, df_remain in df_pred_frame_tmp_remaining.iterrows():\n#             for label_sort in dict(sort_cluster_label_counts[df_remain['sort_cluster']]):\n#                 if not label_sort in labels_left_set:\n#                     continue\n#                 df_remain['label_sort'] = label_sort\n#                 df_remain['how_sort'] = 'secondary' \n#                 additionals.append(df_remain)\n#                 break\n#         if len(additionals) > 0:\n#             df_additionals = pd.concat(additionals, axis=1).T\n#             df_pred_frame_tmp_safe = pd.concat([df_pred_frame_tmp_safe, df_additionals])\n#             df_pred_frame_tmp_safe = df_pred_frame_tmp_safe[~df_pred_frame_tmp_safe['label_sort'].duplicated()]\n#             labels_left_set -= set(df_additionals['label_sort'])\n\n#         # Add remainings\n#         # \u3053\u3053\u306e\u51e6\u7406\u306f,cluster\u304c\u5404\u30d5\u30ec\u30fc\u30e0\u3067\u88ab\u3089\u306a\u3044\u3053\u3068\u304c\u524d\u63d0\u3002DeepSORT\u3067\u306f\u304a\u305d\u3089\u304f\u3046\u307e\u304f\u3044\u304b\u306a\u3044\u306f\u305a\u3002\n#         if len(labels_left_set) >= len(df_pred_frame_tmp_remaining):\n#             df_pred_frame_tmp_remaining = df_pred_frame_tmp[~df_pred_frame_tmp['sort_cluster'].isin(df_pred_frame_tmp_safe['sort_cluster'])]\n#             df_pred_frame_tmp_remaining['label_sort'] = np.random.choice(\n#                 list(labels_left_set),\n#                 len(df_pred_frame_tmp_remaining),\n#                 replace=False\n#             )\n#             df_pred_frame_tmp_safe = pd.concat([df_pred_frame_tmp_safe, df_pred_frame_tmp_remaining])\n\n#         res_list.append(df_pred_frame_tmp_safe)\n\n#     df_pred_video_updated_added = pd.concat(res_list)\n#     df_pred_video_updated_added = df_pred_video_updated_added.drop('label', axis=1).rename(columns={'label_sort':'label'})\n#     return df_pred_video_updated_added","2b24ecee":"def frames_list_to_segment_list(frames):\n    segment_list = []\n    start_frame = -1\n    prev_frame = -1\n    for frame in frames:\n        if prev_frame == -1:\n            prev_frame = frame\n        if start_frame == -1:\n            start_frame = frame\n    \n        if frame - prev_frame >= 2:\n            segment_list.append([start_frame, prev_frame])\n            start_frame = frame\n\n        prev_frame = frame\n    segment_list.append([start_frame, prev_frame])\n    return segment_list\n\ndef get_closest_label(frame, df_pred_video, query_label):\n    df_pred_frame = df_pred_video[df_pred_video['frame'] == frame]\n    df_pred_frame['dx'] = df_pred_frame['x'] - df_pred_frame[df_pred_frame['label'] == query_label]['x'].values[0]\n    df_pred_frame['dy'] = df_pred_frame['y'] - df_pred_frame[df_pred_frame['label'] == query_label]['y'].values[0]\n    dist = np.sqrt(df_pred_frame['dx'].values**2 + df_pred_frame['dy']**2)\n    dist[dist==0] = 1e9\n    closest_id = np.argmin(dist)\n    closest_label = df_pred_frame['label'].values[closest_id]\n    closest_pos = df_pred_frame[['x', 'y']].values[closest_id]\n    relative_pos = df_pred_frame[df_pred_frame['label'] == query_label][['x', 'y']].values[0] - closest_pos\n    return closest_label, closest_pos, relative_pos\n\ndef get_data(df_video, frame, label):\n    return df_video[(df_video['frame'] == frame) & (df_video['label'] == label)]\n\ndef get_base_data(df_video, frame0, frame1, target_label):\n    df_base = df_video[(df_video['frame'] >= frame0) & (df_video['frame'] <= frame1) & (df_video['label'] == target_label)]\n    return df_base","f06f748e":"def add_ghost_simple(df_pred):\n    update_list = []\n\n    for video, df_pred_video in tqdm(df_pred.groupby('video')):\n        df_pred_video_updated = df_pred_video.copy()\n\n        video_name = video[:-4]\n\n        for label in df_pred_video['label'].unique():\n            # if label != 'H90':\n            #     continue\n            df_pred_video = df_pred_video.sort_values('frame')\n            cond_visible = np.array([label in labels.values for _, labels in df_pred_video.groupby('frame')['label']])\n            non_visible_frames = df_pred_video['frame'].unique()[~cond_visible]\n\n            non_visible_segment_list = frames_list_to_segment_list(non_visible_frames)\n            for seg in non_visible_segment_list:\n                closest_labels = [0, 0]\n                closest_pos_list = [0, 0]\n                relative_pos_list = [0, 0]\n\n                for i in range(len(seg)):\n                    frame_tmp = seg[i] - (-1)**i\n                    if frame_tmp not in df_pred_video.frame.unique():\n                        closest_labels[i] = 'NaN'\n                    else:\n                        closest_labels[i], closest_pos_list[i], relative_pos_list[i] = get_closest_label(frame_tmp, df_pred_video, label)\n\n                if closest_labels[0] == closest_labels[1] and closest_labels[0] != 'NaN' and np.mean(np.linalg.norm(relative_pos_list, axis=1)) < 30:\n                    relative_pos = np.mean(relative_pos_list, axis=0)\n                    if np.linalg.norm(relative_pos) == 0:\n                        relative_pos = [1, 1]\n                    bases_df = get_base_data(df_pred_video, seg[0], seg[1], closest_labels[0])\n                    bases_df['label'] = label\n                    bases_df['left'] += relative_pos[0]\n                    bases_df['top'] += relative_pos[1]\n                    update_list.append(bases_df)\n    df_pred_updated = pd.concat([df_pred, pd.concat(update_list)])\n    df_pred_updated = df_pred_updated.sort_values('frame')\n    return df_pred_updated\n","eb111250":"def add_ghosts(df_pred, tracking):\n    update_list = []\n\n    for video, df_pred_video in tqdm(df_pred.groupby('video')):\n        game_play = video.split('_')[0] + '_' + video.split('_')[1]\n        tracking_video = tracking[tracking['game_play'] == game_play]\n\n        closest_labels_to_frame = {}\n        # Iterate over frames to detect frames that are close enough\n        for frame, df_pred_frame in df_pred_video.sort_values('frame').groupby('frame'):\n            dist_thres = (df_pred_frame['width'].mean() + df_pred_frame['height'].mean()) \/ 2 * 1.\n\n            pos_helmets = df_pred_frame[['x', 'y']].values\n            dist = distance.cdist(pos_helmets, pos_helmets, metric='euclidean') + np.eye(len(pos_helmets)) * 1e9\n            closest_idxs = np.argmin(dist, axis=1)\n            for label0_idx, label1_idx in enumerate(closest_idxs):\n                if dist[label0_idx, label1_idx] > dist_thres:\n                    continue\n                if closest_idxs[label1_idx] == label0_idx:\n                    label0 = df_pred_frame['label'].values[label0_idx]\n                    label1 = df_pred_frame['label'].values[label1_idx]\n                    key = sorted([label0, label1])[0] + '_' + sorted([label0, label1])[1]\n                    if key not in closest_labels_to_frame.keys():\n                        closest_labels_to_frame[key] = set()\n                    closest_labels_to_frame[key].add(frame)\n\n        tracking_dist_thres = 1.5\n        for label0_label1, frames in closest_labels_to_frame.items():\n            label0, label1 = label0_label1.split('_')\n            pred_label0 = df_pred_video[df_pred_video['label'] == label0]\n            pred_label1 = df_pred_video[df_pred_video['label'] == label1]\n            frames = sorted(list(frames))\n            non_visible_seg_list = []\n            prev_frame_visible = frames[0]\n            for frame_visible in frames:\n                if frame_visible - prev_frame_visible > 1:\n                    non_visible_seg_list.append([prev_frame_visible + 1, frame_visible - 1])\n                prev_frame_visible = frame_visible\n\n            for frame0, frame1 in non_visible_seg_list:\n                # Check the distance between two tracking data\n                tracking_0 = tracking_video[(tracking_video['player'] == label0) & (tracking_video['frame'] >= frame0) & (tracking_video['frame'] <= frame1)][['x', 'y']].values\n                tracking_1 = tracking_video[(tracking_video['player'] == label1) & (tracking_video['frame'] >= frame0) & (tracking_video['frame'] <= frame1)][['x', 'y']].values\n                if len(tracking_0) != len(tracking_1):\n                    continue\n                if np.linalg.norm(tracking_0 - tracking_1, axis=1).max() > tracking_dist_thres:\n                    continue\n\n               #  print(\"Complete! frame: {0} to {1}, label: {2} and {3}\".format(frame0, frame1, label0, label1))\n                relative_pos_0to1 = (pred_label1[pred_label1['frame'] == frame0 - 1][['x', 'y']].values + pred_label1[pred_label1['frame'] == frame1 + 1][['x', 'y']].values) - \\\n                                                     (pred_label0[pred_label0['frame'] == frame0 - 1][['x', 'y']].values  + pred_label0[pred_label0['frame'] == frame1 + 1][['x', 'y']].values)\n                relative_pos_0to1 \/= 2\n                # if np.linalg.norm(relative_pos_0to1) < 5:\n                #    print('here')\n                #    relative_pos_0to1 = np.array([[2, 2]])\n\n                # Complement missing label0 with label1\n                df_label0_complemented = pred_label1[(pred_label1['frame'] >= frame0) & (pred_label1['frame'] <= frame1)]\n                df_label0_complemented['label'] = label0\n                df_label0_complemented['left'] -= relative_pos_0to1[0][0]\n                df_label0_complemented['top'] -= relative_pos_0to1[0][1]\n                df_label0_complemented = df_label0_complemented[~df_label0_complemented['frame'].isin(pred_label0['frame'].values)]\n\n                # Complement missing label0 with label1\n                df_label1_complemented = pred_label0[(pred_label0['frame'] >= frame0) & (pred_label0['frame'] <= frame1)]\n                df_label1_complemented['label'] = label1\n                df_label1_complemented['left'] += relative_pos_0to1[0][0]\n                df_label1_complemented['top'] += relative_pos_0to1[0][1]\n                df_label1_complemented = df_label1_complemented[~df_label1_complemented['frame'].isin(pred_label1['frame'].values)]\n\n                update_list.append(df_label0_complemented)\n                update_list.append(df_label1_complemented)\n                # print(relative_pos_0to1)\n    df_pred_updated = pd.concat([df_pred, pd.concat(update_list)])\n    df_pred_updated = df_pred_updated[~df_pred_updated[['video_frame', 'label']].duplicated()]\n    df_pred_updated = df_pred_updated[~df_pred_updated[[\"video_frame\", \"left\", \"width\", \"top\", \"height\"]].duplicated()]\n\n    return df_pred_updated","33f9ff32":"def clip_edges(df):\n    df['right'] = df['left'] + df['width']\n    df['bottom'] = df['top'] + df['height']\n    df[['top', 'bottom']] = np.clip(df[['top', 'bottom']].values.astype(int), 0, 720)\n    df[['left', 'right']] = np.clip(df[['left', 'right']].values.astype(int), 0, 1280)\n    df['width'] = df['right'] - df['left']\n    df['height'] = df['bottom'] - df['top']\n    return df","d7e98eff":"def generate_video(submission_df, labels):\n    submission_df['video'] = submission_df['video_frame'].str.split('_').str[:3].str.join('_') + '.mp4'\n    debug_videos = submission_df['video'].unique()\n    debug_labels = labels.query('video in @debug_videos')\n    scorer = NFLAssignmentScorer(debug_labels)\n    scorer.score(submission_df)\n\n    # Create video showing predictions for one of the videos.\n    video_out = video_with_predictions(\n        f'..\/input\/nfl-health-and-safety-helmet-assignment\/train\/{debug_videos[0]}',\n        scorer.sub_labels)\n    \n    frac = 0.60 # scaling factor for display\n    display(Video(data=video_out,\n                  embed=True,\n                  height=int(720*frac),\n                  width=int(1280*frac))\n           )\n    \ndef eval_sub(submission_df, labels):\n    submission_df['video'] = submission_df['video_frame'].str.split('_').str[:3].str.join('_') + '.mp4'\n    for video, sub in submission_df.groupby('video'):\n        scorer = NFLAssignmentScorer(labels[labels['video'] == video])\n        baseline_score = scorer.score(submission_df[submission_df['video'] == video])\n        print(f\"Score @ {video}: {baseline_score:0.4f}\")\n    print('============')\n    scorer = NFLAssignmentScorer(labels)\n    baseline_score = scorer.score(submission_df)\n    print(f\"validation score {baseline_score:0.4f}\")\n    \n\ndef save_sub(submission_df, filename, all_cols = False):\n    ss = pd.read_csv('..\/input\/nfl-health-and-safety-helmet-assignment\/sample_submission.csv')\n\n    # Final Checks\n    if not all_cols:\n        submission_df = submission_df[ss.columns]\n    submission_df = submission_df.loc[\n        ~submission_df[['video_frame','label']].duplicated()]\n\n    if not all_cols:\n        # Condition 4\n        submission_df['left'] = submission_df['left'].astype(np.int64)\n        submission_df['top'] = submission_df['top'].astype(np.int64)\n        submission_df['width'] = submission_df['width'].astype(np.int64)\n        submission_df['height'] = submission_df['height'].astype(np.int64)\n        submission_df = clip_edges(submission_df)\n\n        # Condition 1\n        submission_df = submission_df.loc[~submission_df[['video_frame', 'label']].duplicated()]\n\n        # Condition 2\n        submission_df = submission_df.loc[~submission_df[['video_frame', 'left', 'top', 'width', 'height']].duplicated()]\n\n        # Condition 3\n        res = []\n        for video_frame, df_frame in submission_df.groupby('video_frame'):\n            if len(df_frame) > 22:\n                df_frame = df_frame.loc[:22]\n            res.append(df_frame)\n        submission_df = pd.concat(res)\n        \n        submission_df = submission_df[ss.columns]\n\n        ok_for_submission = check_submission(submission_df)\n        if not ok_for_submission:\n            raise ValueError\n    submission_df.to_csv(filename, index=False)\n\ndef eval_video(submission_df, labels, video):\n    submission_df['video'] = submission_df['video_frame'].str.split('_').str[:3].str.join('_') + '.mp4'\n    scorer = NFLAssignmentScorer(labels[labels['video'] == video])\n    baseline_score = scorer.score(submission_df[submission_df['video'] == video])\n    print(f\"validation score @{video}: {baseline_score:0.4f}\")\n    ","1d0d4391":"n_test_videos = len(os.listdir('..\/input\/nfl-health-and-safety-helmet-assignment\/test\/'))\n# Run in debug mode unless during submission\nif n_test_videos == 6:\n    debug = True\nelse:\n    debug = False\n\n# Configurables\nn_debug_samples = 1\nrandom_state = 42\nCONF_THRE = 0.3\nmax_iter = 1000\nDIG_STEP = 3\nDIG_MAX = DIG_STEP*10\n\n# Read in the data.\n\nBASE_DIR = '..\/input\/nfl-health-and-safety-helmet-assignment'\n\nlabels = pd.read_csv(f'{BASE_DIR}\/train_labels.csv')\nif debug:\n    tracking = pd.read_csv(f'{BASE_DIR}\/train_player_tracking.csv')\n    helmets = pd.read_csv(f'{BASE_DIR}\/train_baseline_helmets.csv')\n    video_dir = BASE_DIR + '\/train'\nelse:\n    tracking = pd.read_csv(f'{BASE_DIR}\/test_player_tracking.csv')\n    helmets = pd.read_csv(f'{BASE_DIR}\/test_baseline_helmets.csv')\n    video_dir = BASE_DIR + '\/test'\n\ntracking = add_track_features(tracking)","232b13be":"def add_cols(df):\n    df['game_play'] = df['video_frame'].str.split('_').str[:2].str.join('_')\n    if 'video' not in df.columns:\n        df['video'] = df['video_frame'].str.split('_').str[:3].str.join('_') + '.mp4'\n    return df\n\nif debug:\n    helmets = add_cols(helmets)\n    labels = add_cols(labels)\n    # Select `n_debug_samples` worth of videos to debug with\n    sample_videos = labels['video'].drop_duplicates() \\\n        .sample(n_debug_samples, random_state=random_state).tolist()\n    # sample_videos = ['57586_004152_Endzone.mp4', '57586_004152_Sideline.mp4']\n    sample_gameplays = ['_'.join(x.split('_')[:2]) for x in sample_videos]\n    tracking = tracking[tracking['game_play'].isin(sample_gameplays)]\n    helmets = helmets[helmets['video'].isin(sample_videos)]\n    labels = labels[labels['video'].isin(sample_videos)]\n    print(sample_videos)\ntracking.shape, helmets.shape, labels.shape","4053c156":"helmets['video'] = helmets['video_frame'].str.split('_').str[:3].str.join('_') + '.mp4'\nhelmets['view'] = helmets['video_frame'].str.split('_').str[2].astype(str)\nhelmets['frame'] = helmets['video_frame'].str.split('_').str[3].astype(np.int64)\nhelmets['x'] = helmets['left'] + helmets['width'] \/ 2.0\nhelmets['y'] = helmets['top'] + helmets['height'] \/ 2.0\n\ntracking_merged_list = []\nfor video, df_pred_video in tqdm(helmets.groupby('video')):\n    game_play = video.split('_')[0] + '_' + video.split('_')[1]\n    tracking_video = tracking[tracking['game_play'] == game_play]\n    est_frame_to_tracking_video = dict(list(tracking_video.groupby('est_frame')))\n    keys = np.array(list(est_frame_to_tracking_video.keys()))\n    for frame_id in df_pred_video['frame'].unique():\n        opt_idx = np.argmin(np.abs(keys - frame_id))\n        tmp = est_frame_to_tracking_video[keys[opt_idx]].copy()\n        tmp['frame'] = frame_id\n        tracking_merged_list.append(tmp)\ntracking_processed = pd.concat(tracking_merged_list)","21a88cf5":"# ICP\nLINE_PER_HELMET_CAND_SIDELINE = np.arange(8, 10, 0.1) # \u3053\u308c\u304cendzone\u3068\u9055\u3046\u306e\u306f\u3001\u304a\u305d\u3089\u304f\u4e0b\u8a18\u306escale factor\u304c\u9055\u3046\u305b\u3044\uff1f\nLINE_PER_HELMET_CAND_ENDZONE = np.arange(4, 5, 0.1)\n\n# Monte-carlo ICP\nNUM_PARTICLES = 100\nRATE_X2Y = {'Endzone': 0.5, 'Sideline': 1.0}\nSCALE_FACTOR = {'Endzone': [2, 4.5], 'Sideline': [4, 10]}\nTEAM_DIF_PENALTY = 2.0\nNUM_ITER_OUTSIDERS = 6\nSCALE_RATE_EXP = 0.7\nNUM_HELMETS_THRES_FOR_OUTSIDERS = 24\n\n# Team clusterization\nCLUSTERIZATION_RATE_THRES = 1e9\nCLUSTERIZATION_DIST_THRES = 0\nCLUSTERIZATION_HELMET_SHRINK_RATE = 0.7\n\n# SORT\nMAX_AGE = 1\nMIN_HITS = 3\nIOU_THRESHOLD = 0.3","88cf39d6":"df_results_icp = apply_icp_multiprocess_by_team(helmets, tracking_processed, video_dir)","c7ac72c6":"if debug:\n    eval_sub(df_results_icp, labels)\nsave_sub(df_results_icp, 'submission_icp.csv', all_cols=True)\n# save_sub(df_results_icp, 'submission.csv')","77b0a2b1":"df_results_sort = apply_sort(df_results_icp, tracking_processed)","15ffcff3":"if debug:\n    eval_sub(df_results_sort, labels)\nsave_sub(df_results_sort, 'submission_sort.csv', all_cols=True)\n# save_sub(df_results_deepsort, 'submission.csv')","6833e1ce":"df_results_simple_ghosts = add_ghost_simple(df_results_sort)\nsave_sub(df_results_simple_ghosts, 'submission_few_ghosts.csv', all_cols=True)\n\ndf_results_plenty_ghosts = add_ghosts(df_results_simple_ghosts, tracking_processed)\nsave_sub(df_results_plenty_ghosts, 'submission_plenty_ghosts.csv', all_cols=True)","c605d94d":"if debug:\n    eval_sub(df_results_plenty_ghosts, labels)\nsave_sub(df_results_plenty_ghosts, 'submission.csv')","318deeda":"# if debug:\n#     generate_video(df_results_plenty_ghosts, labels)","b7b43906":"## Ghost detection","5df5373e":"## others","9e2696e8":"# Prepare","b5d13773":"## icp","53cc6507":"## SORT","70185f97":"# Ghost Detection","0faf1ad8":"# Functions\n## line param pred","75fb9b2a":"# ICP","1d567c71":"# SORT","02d5adee":"# Video"}}