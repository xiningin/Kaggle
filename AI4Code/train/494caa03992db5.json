{"cell_type":{"0b38f218":"code","5d6ca93c":"code","11d67a0f":"code","1dc4cb4f":"code","5e37a86a":"code","a3aa175f":"code","19edf748":"code","24de9f85":"code","3d0304d7":"code","052bcf09":"code","b3e48ca9":"code","006dd0b0":"markdown"},"source":{"0b38f218":"# Import Package\nimport copy\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report","5d6ca93c":"#Define Variable\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\nimage_path = '..\/input\/kermany2018\/OCT2017 \/'\ninput_size = 299\n\nmean = [0.224, 0.224, 0.224]\nstd = [0.1551, 0.1551, 0.1551]\n\ndataset_ratio = 0.9\n\nbatch_size = 128\nnum_epoch = 20\nCLASS_NAMES = list(os.listdir(image_path + 'train'))\n\npretrained_model = 'inceptionv3'\ntrain_md = 'mod'","11d67a0f":"# Load Dataset and Transform\ntrain_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.RandomResizedCrop(input_size),\n    transforms.Normalize((mean), (std))\n])\n\nval_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.CenterCrop(input_size),\n    transforms.Normalize((mean), (std))\n])\n\ntest_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize((input_size, input_size)),\n    transforms.Normalize((mean), (std))\n])\n\nimage_dataset = {\n    'train': torchvision.datasets.ImageFolder(os.path.join(image_path, 'train'), train_transform),\n    'val': torchvision.datasets.ImageFolder(os.path.join(image_path, 'val'), val_transform),\n    'test': torchvision.datasets.ImageFolder(os.path.join(image_path, 'test'), test_transform)\n}\n\ndata_loader = {\n    x: torch.utils.data.DataLoader(image_dataset[x], batch_size=batch_size,\n                                    shuffle=True, num_workers=4)\n    for x in ['train', 'val', 'test']\n}","1dc4cb4f":"# Train Function\ndef train_model():\n    accuracy_epoch = { 'train': [], 'val': [] }\n    loss_epoch = { 'train': [], 'val': [] }\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epoch):\n\n        for phase in ['train', 'val']:\n            model.train() if phase == 'train' else model.eval()\n\n            loop = tqdm(enumerate(data_loader[phase]), total=len(data_loader[phase]))\n            loop.set_description(f\"Epoch [{epoch + 1}\/{num_epoch}]\")\n\n            running_loss = 0.0\n            running_corrects = 0\n            running_num = 0\n\n            for batch_idx, (inputs, labels) in loop:\n                inputs, labels = inputs.to(device), labels.to(device)\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                running_num += len(labels.data)\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(labels == preds)\n\n                loop.set_postfix(loss=(running_loss \/ running_num),\n                                 acc=(running_corrects.double() \/ running_num).item())\n\n            accuracy_epoch[phase].append((running_corrects.double() \/ running_num).item())\n            loss_epoch[phase].append(running_loss \/ running_num)\n\n            if phase == 'val' and accuracy_epoch[phase][epoch] >= best_acc:\n                best_acc = accuracy_epoch[phase][epoch]\n                best_model_wts = copy.deepcopy(model.state_dict())\n    model.load_state_dict(best_model_wts)\n\n    return { 'model': model, 'accuracy': accuracy_epoch, 'loss': loss_epoch }","5e37a86a":"# Build Function\ndef build_model(model_n, mmode=''):\n    if model_n == 'resnet18':\n        model = torchvision.models.resnet18(pretrained=True)\n    elif model_n == 'inceptionv3':\n        model = torchvision.models.inception_v3(pretrained=True)\n        model.aux_logits = False\n    elif model_n == 'resnext50_32x4d':\n        model = torchvision.models.resnext50_32x4d(pretrained=True)\n    elif model_n == 'vgg19':\n        model = torchvision.models.vgg19(pretrained=True)\n    elif model_n == 'vgg13':\n        model = torchvision.models.vgg13(pretrained=True)\n    elif model_n == 'resnet50':\n        model = torchvision.models.resnet50(pretrained=True)\n    elif model_n == 'nn-1':\n        model = nn.Sequential(\n            nn.Conv2d(3, 128, kernel_size=3, stride=1, padding=1),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(64, 16, kernel_size=3, stride=1, padding=1),\n            nn.MaxPool2d(2, 2),\n            nn.Flatten(),\n            nn.Linear(16 * 28 * 28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Linear(256, 32),\n            nn.ReLU(),\n            nn.Linear(32, 16),\n            nn.ReLU(),\n            nn.Linear(16, 4),\n            nn.ReLU()\n        )\n    else:\n        return 'No model with the name'\n\n    if mmode == '':\n        num_ftrs = model.fc.in_features\n        model.fc = nn.Linear(num_ftrs, 4)\n    elif mmode == 'mod':\n        num_ftrs = model.fc.in_features\n        model.fc = nn.Sequential(\n            nn.BatchNorm1d(num_ftrs),\n            nn.Linear(num_ftrs, 128),\n            nn.ReLU(),\n            nn.BatchNorm1d(128),\n            nn.Linear(128, 4)\n        )\n    elif mmode == 'nnbasic':\n        pass\n\n    model = model.to(device)\n\n    return model","a3aa175f":"# Training Model\nmodel = build_model(pretrained_model, train_md)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters())\n\noutput = train_model()","19edf748":"# Save Model\ntorch.save(output, '\/kaggle\/working\/inceptionv3-1_1.pth')","24de9f85":"# Accuracy and Loss Value Plot\nfig, ax = plt.subplots(1, 2, figsize=(14, 6))\n\naccuracy = pd.DataFrame(output['accuracy'])\nloss_value = pd.DataFrame(output['loss'])\n\nsns.lineplot(data=accuracy, ax=ax[0])\nax[0].set_title('Training Accuracy')\nax[0].set_xticks([0, 5, 10, 15, 20])\nax[0].set_ylim([0.8, None])\nax[0].set_xlabel('Epoch')\nax[0].set_ylabel('Accuracy')\n\nsns.lineplot(data=loss_value, ax=ax[1])\nax[1].set_title('Training Loss')\nax[1].set_xticks([0, 5, 10, 15, 20])\nax[1].set_xlabel('Epoch')\nax[1].set_ylabel('Loss Value')","3d0304d7":"# Test Model\nmodel = output['model']\nmodel = model.to(device)\nlabel_true, label_pred = [], []\n\nwith torch.no_grad():\n    for inputs, labels in data_loader['test']:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n\n        label_true.extend(labels.detach().cpu().numpy())\n        label_pred.extend(preds.detach().cpu().numpy())","052bcf09":"# Confusion Matrix Plot\nc_metrics = confusion_matrix(label_true, label_pred)\n\nplt.title('Confusion Matrix')\nsns.heatmap(c_metrics, \n    annot=True, \n    xticklabels=CLASS_NAMES, \n    yticklabels=CLASS_NAMES,\n    cmap='Greens', \n    fmt='g'\n)\nplt.xlabel('Predicted Values')\nplt.ylabel('Actual Values')\nplt.show()","b3e48ca9":"# Evaluation\nc_report = classification_report(label_true, label_pred, digits=3)\nprint(classification_report)","006dd0b0":"# Classification Of OCT Images using InceptionV3 (BN Modification)"}}