{"cell_type":{"36b53df4":"code","41250c20":"code","09165203":"code","21e1cbc3":"code","2c1c845b":"code","88ee1dca":"code","a1fb690a":"code","a5c300a5":"code","f7c1af63":"code","634930a9":"code","2ffd7a15":"code","63527fd8":"code","90074514":"code","19c8c469":"code","2867f263":"code","7b4aa830":"code","8cf747ba":"code","fac29ac5":"code","c32a215d":"code","4b8d7650":"code","9509cbbb":"code","74f4d3b3":"code","c668ac82":"code","e4f368d1":"code","8f4a6464":"code","538f1327":"code","1c5df0bc":"code","10e7a7fc":"code","8e69bfe8":"code","d7e51369":"code","572e9114":"code","8be550fa":"code","a85f03ba":"code","f0eed589":"code","13e8bb4e":"code","e4008f38":"code","2beca57c":"code","49eee49d":"code","83b07098":"code","048dc0e9":"code","aba42e7c":"code","bd24a588":"markdown","2503189e":"markdown","2b94c38d":"markdown","e033544d":"markdown","ba2b0533":"markdown","e31591cb":"markdown"},"source":{"36b53df4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.style as style\nstyle.use('fivethirtyeight')\nimport seaborn as sns\nfrom matplotlib.ticker import FuncFormatter\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","41250c20":"%%time\n\ntrain = pd.read_pickle(\"..\/input\/riiid-train-data-multiple-formats\/riiid_train.pkl.gzip\")\ntrain['prior_question_had_explanation'] = train['prior_question_had_explanation'].astype('boolean')\nprint(\"Train size:\", train.shape)","09165203":"train.memory_usage(deep=True)","21e1cbc3":"train.info()","2c1c845b":"%%time\n\nquestions = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/questions.csv')\nlectures = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/lectures.csv')\nexample_test = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/example_test.csv')\nexample_sample_submission = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/example_sample_submission.csv')","88ee1dca":"cids = train.content_id.value_counts()[:30]\n\nfig = plt.figure(figsize=(12,6))\nax = cids.plot.bar()\nplt.title(\"Thirty most used content id's\")\nplt.xticks(rotation=90)\nax.get_yaxis().set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ','))) #add thousands separator\nplt.show()","a1fb690a":"#1 year = 31536000000 ms\nts = train['timestamp']\/(31536000000\/12)\nfig = plt.figure(figsize=(12,6))\nts.plot.hist(bins=100)\nplt.title(\"Histogram of timestamp\")\nplt.xticks(rotation=0)\nplt.xlabel(\"Months between this user interaction and the first event completion from that user\")\nplt.show()","a5c300a5":"correct = train[train.answered_correctly != -1].answered_correctly.value_counts(ascending=True)\n\nfig = plt.figure(figsize=(12,4))\ncorrect.plot.barh()\nfor i, v in zip(correct.index, correct.values):\n    plt.text(v, i, '{:,}'.format(v), color='white', fontweight='bold', fontsize=14, ha='right', va='center')\nplt.title(\"Questions answered correctly\")\nplt.xticks(rotation=0)\nplt.show()","f7c1af63":"user_percent = train[train.answered_correctly != -1].groupby('user_id')['answered_correctly'].agg(Mean='mean', Answers='count')\nprint(f'the highest number of questions answered by a user is {user_percent.Answers.max()}')","634930a9":"user_percent = user_percent.query('Answers <= 1000').sample(n=200, random_state=1)\n\nfig = plt.figure(figsize=(12,6))\nx = user_percent.Answers\ny = user_percent.Mean\nplt.scatter(x, y, marker='o')\nplt.title(\"Percent answered correctly versus number of questions answered User\")\nplt.xticks(rotation=0)\nplt.xlabel(\"Number of questions answered\")\nplt.ylabel(\"Percent answered correctly\")\nz = np.polyfit(x, y, 1)\np = np.poly1d(z)\nplt.plot(x,p(x),\"r--\")\n\nplt.show()","2ffd7a15":"example_test.shape","63527fd8":"example_test.head()","90074514":"batches_test = set(list(example_test.task_container_id.unique()))\nbatches_train = set(list(train.task_container_id.unique()))\nprint(f'All batches in example_test are also in train is {batches_test.issubset(batches_train)}.')","19c8c469":"user_test = set(list(example_test.user_id.unique()))\nuser_train = set(list(train.user_id.unique()))\n\nprint(f'User_ids in example_test but not in train: {user_test - user_train}.')","2867f263":"#this clears everything loaded in RAM, including the libraries\n%reset -f","7b4aa830":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","8cf747ba":"import sys\nsys.path.append('\/kaggle\/input\/riiid-test-answer-prediction')\nimport riiideducation","fac29ac5":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.style as style\nstyle.use('fivethirtyeight')\nimport seaborn as sns\n\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\n\nimport gc\nimport sys\npd.set_option('display.max_rows', None)","c32a215d":"%%time\ncols_to_load = ['row_id', 'user_id', 'answered_correctly', 'content_id', 'prior_question_had_explanation', 'prior_question_elapsed_time']\ntrain = pd.read_pickle(\"..\/input\/riiid-train-data-multiple-formats\/riiid_train.pkl.gzip\")[cols_to_load]\ntrain['prior_question_had_explanation'] = train['prior_question_had_explanation'].astype('boolean')\n\nprint(\"Train size:\", train.shape)","4b8d7650":"%%time\n\nquestions = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/questions.csv')\nlectures = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/lectures.csv')\nexample_test = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/example_test.csv')\nexample_sample_submission = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/example_sample_submission.csv')","9509cbbb":"print(train.shape)\ntrain.head()","74f4d3b3":"%%time\n#adding user features\nuser_df = train[train.answered_correctly != -1].groupby('user_id').agg({'answered_correctly': ['count', 'mean']}).reset_index()\nuser_df.columns = ['user_id', 'user_questions', 'user_mean']\n\nuser_lect = train.groupby([\"user_id\", \"answered_correctly\"]).size().unstack()\nuser_lect.columns = ['Lecture', 'Wrong', 'Right']\nuser_lect = user_lect[['Lecture']].fillna(0).astype('int8')\n#user_lect = user_lect.astype('int8')\nuser_lect['watches_lecture'] = np.where(user_lect.Lecture > 0, 1, 0)\nuser_lect = user_lect.reset_index()\nuser_lect = user_lect[['user_id', 'watches_lecture']]\n\nuser_df = user_df.merge(user_lect, on = \"user_id\", how = \"left\")\ndel user_lect\nuser_df.head()","c668ac82":"%%time\n#adding content features\ncontent_df = train[train.answered_correctly != -1].groupby('content_id').agg({'answered_correctly': ['count', 'mean']}).reset_index()\ncontent_df.columns = ['content_id', 'content_questions', 'content_mean']\ncontent_df.head()","e4f368d1":"%%time\n#using one of the validation sets composed by tito\ncv2_train = pd.read_pickle(\"..\/input\/riiid-cross-validation-files\/cv2_train.pickle\")['row_id']\ncv2_valid = pd.read_pickle(\"..\/input\/riiid-cross-validation-files\/cv2_valid.pickle\")['row_id']","8f4a6464":"train = train[train.answered_correctly != -1]\n\n#save mean before splitting\n#please be aware that there is an issues with train.prior_question_elapsed_time.mean()\n#see https:\/\/www.kaggle.com\/c\/riiid-test-answer-prediction\/discussion\/195032\nmean_prior = train.prior_question_elapsed_time.astype(\"float64\").mean()\n\nvalidation = train[train.row_id.isin(cv2_valid)]\ntrain = train[train.row_id.isin(cv2_train)]\n\nvalidation = validation.drop(columns = \"row_id\")\ntrain = train.drop(columns = \"row_id\")\n\ndel cv2_train, cv2_valid\ngc.collect()","538f1327":"def data_pipeline(df, user_df, content_df, label_enc, mode='train'):\n    df = df.merge(user_df, on = \"user_id\", how = \"left\")\n    df = df.merge(content_df, on = \"content_id\", how = \"left\")\n    df['content_questions'].fillna(0, inplace = True)\n    df['content_mean'].fillna(0.5, inplace = True)\n    df['watches_lecture'].fillna(0, inplace = True)\n    df['user_questions'].fillna(0, inplace = True)\n    df['user_mean'].fillna(0.5, inplace = True)\n    df['prior_question_elapsed_time'].fillna(mean_prior, inplace = True)\n    df['prior_question_had_explanation'].fillna(False, inplace = True)\n\n    if mode =='train':\n        label_enc.fit(df['prior_question_had_explanation'])\n\n    df['prior_question_had_explanation'] = label_enc.transform(df['prior_question_had_explanation'])    \n    df[['content_questions', 'user_questions']] = df[['content_questions', 'user_questions']].astype(int)\n    return df, label_enc","1c5df0bc":"#Your notebook tried to allocate more memory than is available. It has restarted.\n#label_enc = LabelEncoder()\n#train, label_enc = data_pipeline(train, user_df, content_df, label_enc, mode='train')\n#train.sample(5)","10e7a7fc":"#validation, _ = data_pipeline(validation, user_df, content_df, label_enc, mode='validation')\n#validation.sample(5)","8e69bfe8":"label_enc = LabelEncoder()\n\ntrain = train.merge(user_df, on = \"user_id\", how = \"left\")\ntrain = train.merge(content_df, on = \"content_id\", how = \"left\")\ntrain['content_questions'].fillna(0, inplace = True)\ntrain['content_mean'].fillna(0.5, inplace = True)\ntrain['watches_lecture'].fillna(0, inplace = True)\ntrain['user_questions'].fillna(0, inplace = True)\ntrain['user_mean'].fillna(0.5, inplace = True)\ntrain['prior_question_elapsed_time'].fillna(mean_prior, inplace = True)\ntrain['prior_question_had_explanation'].fillna(False, inplace = True)\n\nlabel_enc.fit(train['prior_question_had_explanation'])\n\ntrain['prior_question_had_explanation'] = label_enc.transform(train['prior_question_had_explanation'])\ntrain[['content_questions', 'user_questions']] = train[['content_questions', 'user_questions']].astype(int)\ntrain.sample(5)","d7e51369":"validation = validation.merge(user_df, on = \"user_id\", how = \"left\")\nvalidation = validation.merge(content_df, on = \"content_id\", how = \"left\")\nvalidation['content_questions'].fillna(0, inplace = True)\nvalidation['content_mean'].fillna(0.5, inplace = True)\nvalidation['watches_lecture'].fillna(0, inplace = True)\nvalidation['user_questions'].fillna(0, inplace = True)\nvalidation['user_mean'].fillna(0.5, inplace = True)\nvalidation['prior_question_elapsed_time'].fillna(mean_prior, inplace = True)\nvalidation['prior_question_had_explanation'].fillna(False, inplace = True)\n\nvalidation['prior_question_had_explanation'] = label_enc.transform(validation['prior_question_had_explanation'])\nvalidation[['content_questions', 'user_questions']] = validation[['content_questions', 'user_questions']].astype(int)\nvalidation.sample(5)","572e9114":"# features = ['user_questions', 'user_mean', 'content_questions', 'content_mean', 'watches_lecture',\n#             'prior_question_elapsed_time', 'prior_question_had_explanation']\n\nfeatures = ['user_questions', 'user_mean', 'content_questions', 'content_mean', 'prior_question_elapsed_time']\n\n\n#for now just taking 10.000.000 rows for training\ntrain = train.sample(n=10_000_000, random_state = 1)\n\ny_train = train['answered_correctly']\ntrain = train[features]\n\ny_val = validation['answered_correctly']\nvalidation = validation[features]","8be550fa":"params = {'objective': 'binary',\n          'metric': 'auc',\n          'seed': 2020,\n          'learning_rate': 0.1, #default\n          \"boosting_type\": \"gbdt\" #default\n         }","a85f03ba":"lgb_train = lgb.Dataset(train, y_train, categorical_feature = None)\nlgb_eval = lgb.Dataset(validation, y_val, categorical_feature = None)\n\ndel train, y_train, validation, y_val\ngc.collect()","f0eed589":"%%time\nmodel = lgb.train(\n    params, lgb_train,\n    valid_sets=[lgb_train, lgb_eval],\n    verbose_eval=50,\n    num_boost_round=10000,\n    early_stopping_rounds=8\n)","13e8bb4e":"lgb.plot_importance(model)\nplt.show()","e4008f38":"env = riiideducation.make_env()","2beca57c":"iter_test = env.iter_test()","49eee49d":"for (test_df, sample_prediction_df) in iter_test:\n    test_df = test_df.merge(user_df, on = \"user_id\", how = \"left\")\n    test_df = test_df.merge(content_df, on = \"content_id\", how = \"left\")\n    test_df['content_questions'].fillna(0, inplace = True)\n    test_df['content_mean'].fillna(0.5, inplace = True)\n    test_df['watches_lecture'].fillna(0, inplace = True)\n    test_df['user_questions'].fillna(0, inplace = True)\n    test_df['user_mean'].fillna(0.5, inplace = True)\n    test_df['prior_question_elapsed_time'].fillna(mean_prior, inplace = True)\n    test_df['prior_question_had_explanation'].fillna(False, inplace = True)\n    test_df['prior_question_had_explanation'] = label_enc.transform(test_df['prior_question_had_explanation'])\n    test_df[['content_questions', 'user_questions']] = test_df[['content_questions', 'user_questions']].astype(int)\n    test_df['answered_correctly'] =  model.predict(test_df[features])\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])","83b07098":"#last batch overview\n#submission_test_df = test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']]\n#submission_test_df.to_csv('submission.csv')","048dc0e9":"#submission_test_df.shape","aba42e7c":"#submission_test_df","bd24a588":"### Test data","2503189e":"Inspired by: https:\/\/www.kaggle.com\/erikbruin\/riiid-comprehensive-eda-baseline\/notebook","2b94c38d":"### Riiid Answer Correctness Prediction \nhttps:\/\/www.kaggle.com\/c\/riiid-test-answer-prediction\n\nIn this competition, your challenge is to create algorithms for \"Knowledge Tracing,\" the modeling of student knowledge over time. The goal is to accurately predict how students will perform on future interactions. You will pair your machine learning skills using Riiid\u2019s EdNet data.","e033544d":"### Deep Learning Adventures Present\n### Attention and Transformers Bonus Edition | Applications of transformers for a non-NLP task\n### https:\/\/www.meetup.com\/Deep-Learning-Adventures\/events\/281617686\n\nHello dear friends \ud83c\udf0e \ud83c\udf0d,\n\nWe hope you are enjoying our latest sessions \ud83c\udfd6\ufe0f deploying models and cool applications to our phones \ud83d\udcf1 and edge devices \ud83d\udd79\ufe0f\n\nOur friend Dmitri has offered to lead some very interesting papers, code and content all on the attention mechanism in deep learning models and transformers! \ud83d\ude32\n\nAttention and Transformers Bonus Edition | Applications of transformers for a non-NLP task\n\n- Kaggle competition on knowledge tracing:\nRiiid Answer Correctness Prediction\nTrack knowledge states of 1M+ students in the wild\nhttps:\/\/www.kaggle.com\/c\/riiid-test-answer-prediction\/overview\n\n- Dmitri's approach, ranked # 54 out of 3,395 participants (top 2%).\nhttps:\/\/github.com\/dlevonian\/riiid-prediction \u2705\n\n- Presentation: https:\/\/docs.google.com\/presentation\/d\/1QWWgewJ12unyPUDRpnOLsygl1_0lVCwpWSJZGIRB1YY\/edit?usp=sharing\n\nThe recording of this cool event \ud83d\ude0e is available at:\nhttps:\/\/bit.ly\/dla-transformers","ba2b0533":"### Lets use the Competition API to bring in the test data and make a submission\nhttps:\/\/www.kaggle.com\/sohier\/competition-api-detailed-introduction\/notebook","e31591cb":"### Baseline model"}}