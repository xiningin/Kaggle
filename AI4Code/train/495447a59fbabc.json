{"cell_type":{"2cb1002e":"code","2773408b":"code","0e3c5657":"code","e6611c4f":"code","ecdd9a82":"code","70e3ffcb":"code","8ba7d7a8":"code","8570b5d1":"code","7fa77453":"code","f5e9b141":"code","c2bee9f3":"code","c01f25bd":"code","7a5cc5e1":"code","848ab58b":"code","2af24766":"code","6f6229ce":"code","b4859e31":"markdown","007d655f":"markdown","e3050cd9":"markdown","cc72f2bd":"markdown","32b139c9":"markdown","066a5e29":"markdown","4274b824":"markdown","67e2677c":"markdown","523e56b8":"markdown","e2b70f56":"markdown","92b2b2ce":"markdown"},"source":{"2cb1002e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2773408b":"# importing all the modules\nimport os\nimport pathlib\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn \nimport tensorflow as tf\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom IPython import display","0e3c5657":"# setting up the data directory\nDATA_DIR=\"\/kaggle\/input\/audio-cats-and-dogs\/cats_dogs\/\"\n\n# setting up path for train and test data\ntrain_dir=DATA_DIR+\"\/train\"\ntest_dir=DATA_DIR+\"\/test\"","e6611c4f":"\n# get the train files\nfile_train = tf.io.gfile.glob(train_dir + '\/*\/*')\n# shuffle \nfile_train = tf.random.shuffle(file_train)\n\ntrain_ds=file_train\n\n# get the test files\nfile_test = tf.io.gfile.glob(test_dir + '\/*\/*')\n# shuffle \nfile_test = tf.random.shuffle(file_test)\n\n\ntest_ds=file_test\nprint(\"Shape of train data:- \", train_ds.shape)\nprint(\"Shape of test data:- \",file_test.shape)","ecdd9a82":"# Function to get waveform and it's label\ndef get_waveform_label(file):\n  # get the label\n  lab = tf.strings.split(file, os.path.sep)[-2]\n  # read the binalry file \n  audio_binary = tf.io.read_file(file)\n  # decode the file \n  audio, _ = tf.audio.decode_wav(audio_binary)\n  # sqeeze tha audio\n  waveform=tf.squeeze(audio, axis=-1)\n  return waveform, lab\n\n# get waveforms and labels of all files\nAUTO = tf.data.AUTOTUNE\nfiles_ds = tf.data.Dataset.from_tensor_slices(train_ds)\nwaveform_ds = files_ds.map(get_waveform_label, num_parallel_calls=AUTO)\n","70e3ffcb":"# number of rows and columns of plot\nrow,col = 2,2\nn = row*col\nfig, axs = plt.subplots(row, col, figsize=(9, 9))\n\n# plotting waveforms\nfor i, (audio, label) in enumerate(waveform_ds.take(n)):\n  r = i \/\/ col\n  c = i % col\n  ax = axs[r][c]\n  ax.plot(audio.numpy())\n\n  label = label.numpy().decode('utf-8')\n  ax.set_title(label)\n\nplt.show()","8ba7d7a8":"# function to get the spectogram and the labels\ndef get_spectrogram_label(audio, label):\n  # apply padding\n  padding = tf.zeros([300000] - tf.shape(audio), dtype=tf.float32)\n  # get the spectogram of the audio\n  wave = tf.cast(audio, tf.float32)\n  eq_length = tf.concat([wave, padding], 0)\n  spectrogram = tf.signal.stft(\n      eq_length, frame_length=210, frame_step=110)    \n  spectrogram = tf.abs(spectrogram)\n  spectrogram = tf.expand_dims(spectrogram, -1)\n  # get associated label of the audio\n  label_id = tf.argmax(label == labels)\n  # return the spectogram and the label\n  return spectrogram, label_id\n\n# get all the labels from the dataset   \nlabels = np.array([\"cat\",\"dog\"])\n\n# get the labels and spectogram\nspectrogram_ds = waveform_ds.map(\n    get_spectrogram_label, num_parallel_calls=AUTO)","8570b5d1":"# function to plot the spectogram\ndef plot_spect(spectrogram, ax):\n  # Converting frequencies to log and transpose to repesent time on x axis\n  log_spec = np.log(spectrogram.T)\n  height = log_spec.shape[0]\n  width = log_spec.shape[1]\n  X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n  Y = range(height)\n  ax.pcolormesh(X, Y, log_spec)\n\n# plot using a subplot\nrows = 2\ncols = 2\nn = rows*cols\nfig, axes = plt.subplots(rows, cols, figsize=(9, 9))\nfor i, (spectrogram, label_id) in enumerate(spectrogram_ds.take(n)):\n  r = i \/\/ cols\n  c = i % cols\n  ax = axes[r][c]\n  # function call\n  plot_spect(np.squeeze(spectrogram.numpy()), ax)\n  # set the title label\n  ax.set_title(labels[label_id.numpy()])\n  ax.axis('off')\nplt.show()","7fa77453":"# function to preprocess the data\ndef preprocess(file):\n  files_ds = tf.data.Dataset.from_tensor_slices(file)\n  # get waveforms and labels\n  output_ds = files_ds.map(get_waveform_label, num_parallel_calls=AUTO)\n  # get spectogram and labels\n  output_ds = output_ds.map(\n      get_spectrogram_label,  num_parallel_calls=AUTO)\n # return the data\n  return output_ds\n\n# train test and validate data\ntrain_ds = spectrogram_ds\n\ntest_ds = preprocess(test_ds)","f5e9b141":"# initialize a batch size\nbatch_size = 64\n# batch train and validate data\ntrain_ds = train_ds.batch(batch_size)\n# cache and prefetch the data\ntrain_ds = train_ds.cache().prefetch(AUTO)","c2bee9f3":"# building the model\nfor spectrogram, _ in spectrogram_ds.take(1):\n  input_shape = spectrogram.shape\nprint('Input shape:', input_shape)\nnum_labels = len(labels)\n# normalize adapt \nnorm_layer = preprocessing.Normalization()\nnorm_layer.adapt(spectrogram_ds.map(lambda x, _: x))\n\n# adding layers\nmodel = models.Sequential([\n    layers.Input(shape=input_shape),\n    preprocessing.Resizing(32, 32), \n    norm_layer,\n    layers.Conv2D(32, 3, activation='relu'),\n    layers.Conv2D(32, 3, activation='relu'),\n    layers.Conv2D(64, 3, activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Dropout(0.25),\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(num_labels),\n])\n\nmodel.summary()","c01f25bd":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(),\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy'],\n)","7a5cc5e1":"EPOCHS = 15\nhistory = model.fit(\n    train_ds,  \n    epochs=EPOCHS,\n)","848ab58b":"# initialize empty list to save the audio and labels\nt_audio = []\nt_labels = []\n\n# load in the labels and audio from test dataset\nfor audio, label in test_ds:\n  t_audio.append(audio.numpy())\n  t_labels.append(label.numpy())\n\n# convert the lists to a numpy array\nt_audio = np.array(t_audio)\nt_labels = np.array(t_labels)","2af24766":"# Feed in the data for prediction\ny_pred = np.argmax(model.predict(t_audio), axis=1)\n\n# store the original labels for testing the accuracy\ny_true = t_labels\n\n# get the testing accuracy\ntest_acc = sum(y_pred == y_true) \/ len(y_true)\nprint(f'Test set accuracy: {test_acc:.0%}')","6f6229ce":"conf_mtx = tf.math.confusion_matrix(y_true, y_pred) \nplt.figure(figsize=(10, 10))\nseaborn.heatmap(conf_mtx, xticklabels=labels, yticklabels=labels, \n            annot=True, fmt='g')\nplt.xlabel('Prediction')\nplt.ylabel('Label')\nplt.show()","b4859e31":"### Since we have a limited dataset so I have not build the validation data, though it is always prefered to construct a validation dataset to develop a scalable model.","007d655f":"#### test model for accuracy","e3050cd9":"### Confusion matrix","cc72f2bd":"#### construct spectrogram","32b139c9":"#### Setting up paths for directories","066a5e29":"#### Get waveform and label associated","4274b824":"# This notebook is about building audio recorgnition model using tensorflow","67e2677c":"#### Importing all the required module","523e56b8":"#### Distribute the train and test data","e2b70f56":"### Built the model","92b2b2ce":"#### Let's preprocess the test file as well"}}