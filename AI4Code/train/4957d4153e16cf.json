{"cell_type":{"c7afd949":"code","ab97d9e4":"code","c667f6b8":"code","7653d21c":"code","071edbed":"code","c6e8bfe3":"code","a121357b":"code","0a85f745":"code","013a63e5":"code","a6bc942a":"code","a68881c8":"code","e25542d2":"code","80967337":"code","cb448bd4":"code","e8132868":"code","0b8943fa":"code","287d3ecd":"code","7fa500b0":"code","33d65252":"code","0310575c":"code","13a83011":"code","c917ad55":"code","aa0c6112":"code","de682481":"code","33e8cb91":"code","f51d64dc":"code","4638058d":"code","2d059aa9":"markdown","25b3ab34":"markdown","fa2619cb":"markdown","fb30a296":"markdown","9e0cb287":"markdown","d1182315":"markdown","9eae5769":"markdown","76b93e07":"markdown","4d62b49a":"markdown","8ac38c1e":"markdown","87f7d4d4":"markdown","e5be2806":"markdown","387b3a4e":"markdown","57431af7":"markdown","0809a2d5":"markdown","006b2ccb":"markdown","a112a35d":"markdown","a86b07db":"markdown","1a28366e":"markdown","90bafa5a":"markdown","5f64bc79":"markdown","fe9bf341":"markdown"},"source":{"c7afd949":"import pandas as pd\nimport numpy as np\n\nimport xgboost as xgb\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.metrics import mean_squared_error as mse\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\nfrom sklearn.decomposition import PCA\nfrom sklearn.compose import ColumnTransformer\n\nfrom sklearn.pipeline import Pipeline\nfrom scikitplot.estimators import plot_learning_curve\n\n\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\n\npd.options.display.max_columns = 250\npd.options.display.max_rows = 250\n\nseed = 2021\nnp.random.seed(2021)","ab97d9e4":"train = pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv', index_col='Id')\ntest = pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv', index_col='Id')","c667f6b8":"train.sample(15)","7653d21c":"train.describe()","071edbed":"plt.hist(train['SalePrice'], bins = 40);","c6e8bfe3":"offset_log = 20000\nplt.hist(np.log2(train['SalePrice'] + offset_log), bins = 40);","a121357b":"plt.figure(figsize = (20, 20))\nsns.heatmap(train.corr(), cmap = \"coolwarm\", annot=True, fmt='.1f', linewidths=0.1);","0a85f745":"plt.figure(figsize = (20, 20))\nsns.heatmap(train.corr()>0.7, cmap = \"coolwarm\", annot=True, fmt='.1f', linewidths=0.1);","013a63e5":"df = pd.concat([train, test])","a6bc942a":"cnt = 0\nmax_in_row = 6\nfor x in df.select_dtypes(np.number).columns.values:\n    data = df[x].fillna(0)\n    plt.figure(cnt\/\/max_in_row, figsize=(25,4))\n    plt.title(x)\n    plt.subplot(1, max_in_row, (cnt)%max_in_row + 1)\n    sns.distplot(data, bins = 50, kde=0);\n    cnt += 1","a68881c8":"train = train.drop(train['LotArea'][ train['LotArea'] > 57000 ].index)\ntrain = train.drop(train['LotFrontage'][ train['LotFrontage'] > 200 ].index)\ntrain = train.drop(train['TotalBsmtSF'][ train['TotalBsmtSF'] > 6000 ].index)\ntrain = train.drop(train['3SsnPorch'][ train['3SsnPorch'] > 360 ].index)\ntrain = train.drop(train['MasVnrArea'][ train['MasVnrArea'] > 1300 ].index)\ntrain = train.drop(train['GrLivArea'][ train['GrLivArea'] > 5100 ].index)\ntrain = train.drop(train['2ndFlrSF'][ train['2ndFlrSF'] > 1870 ].index)\ntrain = train.drop(train['BsmtUnfSF'][ train['BsmtUnfSF'] > 2140 ].index)\ntrain = train.drop(train['BsmtFinSF1'][ train['BsmtFinSF1'] > 5000 ].index)\ntrain = train.drop(train['MasVnrArea'][ train['MasVnrArea'] > 1300 ].index)","e25542d2":"categorical_feats_none = [\n    'PoolQC', 'Alley', 'Fence', 'FireplaceQu', 'GarageCond', 'GarageQual', 'GarageType', 'Utilities',\n    'MiscFeature', 'GarageFinish', 'BsmtFinType2', 'BsmtFinType1', 'BsmtExposure', 'BsmtCond', 'BsmtQual', 'MasVnrType',\n    'MasVnrType', 'KitchenQual', 'KitchenQual', 'MSZoning', 'SaleType', 'Exterior1st', 'Exterior2nd', 'Electrical', 'Functional'\n]\n\nnumeric_feats = [\n    'GarageYrBlt', 'MasVnrArea', 'GarageCars', 'BsmtHalfBath', 'BsmtFullBath', 'GarageArea', 'BsmtUnfSF', 'BsmtFinSF2', 'BsmtFinSF1', 'TotalBsmtSF'\n]","80967337":"df = pd.concat([train, test])","cb448bd4":"for col in categorical_feats_none:\n    df[col] = df[col].fillna('None')\n    \nfor col in numeric_feats:\n    df[col] = df[col].fillna(0)","e8132868":"df['LotFrontage'] = df.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\ndf['TotalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\ndf['Total_porch_sf'] = df['OpenPorchSF'] + df['3SsnPorch'] + df['EnclosedPorch'] + df['ScreenPorch'] + df['WoodDeckSF']\ndf['Total_Bathrooms'] = (df['FullBath'] + 0.5 * df['HalfBath'] + df['BsmtFullBath'] + 0.5 * df['BsmtHalfBath'])\ndf['Pool'] = df['PoolArea'].map(lambda x: 1 if x > 0 else 0)\ndf['Garage'] = df['GarageArea'].map(lambda x: 1 if x > 0 else 0)\ndf['Fireplace'] = df['Fireplaces'].map(lambda x: 1 if x > 0 else 0)\ndf['Basement'] = df['TotalBsmtSF'].map(lambda x: 1 if x > 0 else 0)","0b8943fa":"cat_feats = df.select_dtypes(np.object).columns.values\nnum_feats = df.select_dtypes(np.number).columns.values","287d3ecd":"df_numb = df[num_feats]\ndf_cat = pd.get_dummies(df[cat_feats])","7fa500b0":"df = pd.concat([df_numb, df_cat], axis = 1)","33d65252":"def run_model_cv(model, X, y):\n    \n    scores = []\n    \n    folds = KFold(n_splits=3, shuffle=True, random_state=0)\n    for train_index, test_index in folds.split(X, y):\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n        \n        model.fit(X_train, y_train)\n        \n        y_pred = model.predict(X_test)\n        scores.append(mae(y_test, y_pred))\n        \n    return np.mean(scores), np.std(scores)","0310575c":"def get_X_y(data):\n    black_list = ['SalePrice']\n    feats = [x for x in data.columns if x not in black_list]\n    \n    X = data[ feats ]\n    y = data['SalePrice']\n    \n    X_train = X.iloc[:train.shape[0]]\n    X_test = X.iloc[train.shape[0]:]\n    y_train = y.iloc[:train.shape[0]]\n    \n    return X_train, y_train, X_test","13a83011":"X_train, y_train, X_test = get_X_y(df)","c917ad55":"def train_model_log(model, X_train, y_train):\n    offset_log = 20000\n\n    y_train = np.log2( y_train + offset_log)\n    model.fit(X_train, y_train)\n\n    return model\n\ndef train_model(model, X_train, y_train):\n    \n    model.fit(X_train, y_train)\n\n    return model","aa0c6112":"def model_predict_log(model, X_test):\n    offset_log = 20000\n    \n    y_pred = model.predict(X_test)\n    y_pred = np.exp2( y_pred ) - offset_log\n    return y_pred\n\ndef model_predict(model, X_test):\n    y_pred = model.predict(X_test)\n    \n    return y_pred","de682481":"xgb_model = xgb.XGBRegressor(learning_rate=0.01, n_estimators=5000, max_depth=3, subsample=0.7,\n                       colsample_bytree=0.7, scale_pos_weight=1, reg_alpha=0.00006, random_state=seed)","33e8cb91":"run_model_cv(xgb_model, X_train.values, y_train.values)","f51d64dc":"model = train_model(xgb_model, X_train, y_train)\ny_pred = model_predict(xgb_model, X_test)","4638058d":"output = pd.DataFrame({'Id': test.index,\n                       'SalePrice': y_pred})\noutput.to_csv('submission.csv', index=False)","2d059aa9":"## Distribution of continuous features","25b3ab34":"## Save submission","fa2619cb":"## The Purpose of notebook\nI will try to maximize the accuracy in house price prediction","fb30a296":"## Read data","9e0cb287":"## One-hot encoding `cat_feats`","d1182315":"#### Fill nan","9eae5769":"## Example data","76b93e07":"## function to split data","4d62b49a":"## Target with log normalization","8ac38c1e":"## Functions to get predict label","87f7d4d4":"# Housing Prices prediction","e5be2806":"## Score function with cv","387b3a4e":"## Simple feature engineering","57431af7":"## Target - `SalePrice`","0809a2d5":"## Score model on training data in mae metric","006b2ccb":"## Heatmap correlation","a112a35d":"## Import libs","a86b07db":"## List of features to fill nan","1a28366e":"## Model - XGBoostRegressor","90bafa5a":"## Predict","5f64bc79":"## Functions to train model","fe9bf341":"## Remove outliers"}}