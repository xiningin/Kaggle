{"cell_type":{"703e647d":"code","d06437bf":"code","e584e245":"code","a8a71411":"code","02ff1d53":"code","9e06f458":"code","5cb8c26b":"code","fd162fe0":"code","9740792d":"code","213a9849":"code","49b31bed":"code","03df18b8":"code","b540909a":"code","946f34e4":"markdown","440a5d4a":"markdown","37d2b1f8":"markdown","d8c0f654":"markdown","b406920d":"markdown","2c7d3597":"markdown","b8faefec":"markdown","12ab3ed2":"markdown","38e8e4b5":"markdown","4677ceb2":"markdown","24014860":"markdown"},"source":{"703e647d":"import spacy\nimport random\nfrom collections import Counter #for counting\nimport seaborn as sns #for visualization\nimport matplotlib.pyplot as plt\nimport pandas as pd\nplt.style.use('seaborn')\nsns.set(font_scale=2)\nimport json\ndef pretty_print(pp_object):\n    print(json.dumps(pp_object, indent=2))\n    \nfrom IPython.display import Markdown, display\ndef printmd(string, color=None):\n    colorstr = \"<span style='color:{}'>{}<\/span>\".format(color, string)\n    display(Markdown(colorstr))","d06437bf":"!python -m spacy download en_core_web_lg\nnlp = spacy.load('en_core_web_lg')\n# python -m spacy download en_vectors_web_lg","e584e245":"tweets = pd.read_csv(\"..\/input\/all_djt_tweets.csv\")","a8a71411":"def explain_text_entities(text):\n    doc = nlp(text)\n    for ent in doc.ents:\n        print(f'Entity: {ent}, Label: {ent.label_}, {spacy.explain(ent.label_)}')","02ff1d53":"explain_text_entities(tweets['text'][9])","9e06f458":"one_sentence = tweets['text'][0]\ndoc = nlp(one_sentence)\nspacy.displacy.render(doc, style='ent',jupyter=True)","5cb8c26b":"one_sentence = tweets['text'][240]\ndoc = nlp(one_sentence)\nspacy.displacy.render(doc, style='ent',jupyter=True)","fd162fe0":"one_sentence = tweets['text'][300]\ndoc = nlp(one_sentence)\nspacy.displacy.render(doc, style='ent',jupyter=True)","9740792d":"one_sentence = tweets['text'][450]\ndoc = nlp(one_sentence)\nspacy.displacy.render(doc, style='ent',jupyter=True)","213a9849":"def redact_names(text):\n    doc = nlp(text)\n    redacted_sentence = []\n    for ent in doc.ents:\n        ent.merge()\n    for token in doc:\n        if token.ent_type_ == \"PERSON\":\n            redacted_sentence.append(\"[REDACTED]\")\n        else:\n            redacted_sentence.append(token.string)\n    return \"\".join(redacted_sentence)","49b31bed":"printmd(\"**Before**\", color=\"blue\")\none_sentence = tweets['text'][450]\ndoc = nlp(one_sentence)\nspacy.displacy.render(doc, style='ent',jupyter=True)\nprintmd(\"**After**\", color=\"blue\")\none_sentence = redact_names(tweets['text'][450])\ndoc = nlp(one_sentence)\nspacy.displacy.render(doc, style='ent',jupyter=True)\n\nprintmd(\"Notice that `Obama W.H.` was removed\", color=\"#6290c8\")","03df18b8":"example_text = tweets['text'][9]\ndoc = nlp(example_text)\nspacy.displacy.render(doc, style='ent', jupyter=True)\n\nfor idx, sentence in enumerate(doc.sents):\n    for noun in sentence.noun_chunks:\n        print(f\"sentence {idx+1} has noun chunk '{noun}'\")","b540909a":"one_sentence = tweets['text'][300]\ndoc = nlp(one_sentence)\nspacy.displacy.render(doc, style='ent', jupyter=True)\n\nfor token in doc:\n    print(token, token.pos_)","946f34e4":"# What is NLP?\n\n<img src='https:\/\/www.rw3.com\/wp-content\/uploads\/2017\/09\/natural-Language-processing.jpg'>\n\nNatural Language Processing is the use of machines to manipulate natural language. Here, we focus on written language, or in simpler words: text.\n\n# NLP with spaCy\n\n<img src='https:\/\/nlpforhackers.io\/wp-content\/uploads\/2018\/03\/spaCy.png'>\n\nspaCy is a free open-source library for Natural Language Processing in Python. \n\nIt features NER, POS tagging, dependency parsing, word vectors and more. The name spaCy comes from spaces + Cython. This is because spaCy started off as an industrial grade solution for tokenization - and eventually expanding to other challenges. Cython allows spaCy to be incredibly fast as compared to other solutions like NLTK. \n\n\nSome Applications of NLP\n\n*  Sentiment Analysis on Social Media\n*  Automated Customer Service\n*  Chatbots, such as that of Uber, Intercom\n","440a5d4a":"## Part-of-Speech Tagging\n\nSometimes, we want to quickly pull out keywords, or keyphrases from a larger body of text. This helps us mentally paint a picture of what this text is about. This is particularly helpful in analysis of texts like long emails or essays.\n\nAs a quick hack, we can pull out all relevant \"nouns\". This is because most keywords are in fact nouns of some form.\n\n### Noun Chunks\nWe need noun chunks. Noun chunks are noun phrases - not a single word, but a short phrase which describes the noun. For example, \"the blue skies\" or \"the world\u2019s largest conglomerate\".\n\nTo get the noun chunks in a document, simply iterate over doc.noun_chunks:\n","37d2b1f8":"# Named Entity Recognition aka NER\n\n> spaCy can recognise various types of named entities in a document, by asking the model for a prediction. Because models are statistical and strongly depend on the examples they were trained on, this doesn't always work perfectly and might need some tuning later, depending on your use case.\n> \n>  -- from  [spaCy docs](https:\/\/spacy.io\/usage\/linguistic-features#section-named-entities)\n\n## Entities Explained\n\n| Type | \tDescription|\n|:---|:---\n| PERSON |\tPeople, including fictional. |\n| NORP | Nationalities or religious or political groups.| \n| FAC|  \tBuildings, airports, highways, bridges, etc.| \n| ORG|  \tCompanies, agencies, institutions, etc.| \n| GPE|  \tCountries, cities, states.| \n| LOC|  \tNon-GPE locations, mountain ranges, bodies of water.| \n| PRODUCT|  \tObjects, vehicles, foods, etc. (Not services.)| \n| EVENT|  \tNamed hurricanes, battles, wars, sports events, etc.| \n| WORK_OF_ART|  \tTitles of books, songs, etc.| \n| LAW|  \tNamed documents made into laws.| |\n| LANGUAGE|  \tAny named language.| \n| DATE|  \tAbsolute or relative dates or periods.| \n| TIME|  \tTimes smaller than a day.| \n| PERCENT|  \tPercentage, including \"%\".| \n| MONEY|  \tMonetary values, including unit.| \n| QUANTITY|  \tMeasurements, as of weight or distance.| \n| ORDINAL|  \t\"first\", \"second\", etc.| \n| CARDINAL|  \tNumerals that do not fall under another type.| \n\nLet's look at some examples of above in real world sentences. We will also use the `spacy.explain()` on all entities for one example - to build a quick mental model of how these things work.","d8c0f654":"## Data\nWe explore some tweets from President Donald Trump\n\n![](https:\/\/screenshotscdn.firefoxusercontent.com\/images\/69402d7a-bfec-4cd4-9c57-cca42b6e7b86.png)\n\n## What's In Here?\nIn this kernel, we will learn how to use spaCy in Python to generate questions and answers from *any free text*. We will learn about named entitiy recognition, dependency parsing, part of speech tagging, and more!\n\n1. [Named Entity Recognition](#Named-Entity-Recognition-aka-NER),  visualization with `displacy` and **redacting names automatically without a dictionary**!\n2. [Part of Speech Tagging](#Part-of-Speech-Tagging), and exploring what Trump says with *word clouds*!","b406920d":"Let's continue exploring NER for some more examples, with different entities: ","2c7d3597":"## What have we learned?\n- Named Entity Recognition\n- POS Tagging\n- Noun Chunks","b8faefec":"## Redacting Names\n\nOne simple use case for NER is to automatically redact names. This is important and quite useful. \n\nFor example, \n\n- to ensure that your company data actually complies with GDPR \n- when journalists wants to publish a large set of documents while still hiding the identity of their sources\n\nWe do this redaction by following broad steps:\n\n```markdown\n1. find all PERSON names\n2. replace these by a filler like [\"REDACTED\"]\n```","12ab3ed2":"## Installing SpaCy","38e8e4b5":"# Introduction\n- In this kernel, you will learn what about NLP and how to apply it using a famous library called [SpaCy](https:\/\/spacy.io)","4677ceb2":"You might notice that Part-of-Speech tagging is different from our NER results. In this particular example, `Stock Market` is not an entity, but definitely a noun. \n\nWhat are the \"Parts of Speech that we can pull out of such sentences? ","24014860":"## References\n> https:\/\/spacy.io\/api\/doc<br>\n> https:\/\/www.analyticsvidhya.com\/blog\/2017\/04\/natural-language-processing-made-easy-using-spacy-%E2%80%8Bin-python\/<br>\n>https:\/\/towardsdatascience.com\/a-short-introduction-to-nlp-in-python-with-spacy-d0aa819af3ad<br>"}}