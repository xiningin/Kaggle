{"cell_type":{"8e2959d3":"code","d176f09f":"code","32a81b1d":"code","50ae293a":"code","f86ed6f7":"code","2a2594db":"code","9e1177c6":"code","15265ee1":"code","2ccb759a":"code","193b35fe":"code","105b6d49":"code","8c261bfd":"code","02a6e6f2":"code","aae28cfc":"code","305bb2a8":"code","b63d59a8":"code","18537ce8":"code","f4dd1fcb":"code","72c58ccf":"code","22f825e3":"code","a46f6188":"code","b6d9ae59":"code","fffe6277":"code","f78808ac":"code","cc3ba492":"code","98f256ed":"code","37c976bf":"code","b430a419":"code","fb24d5f6":"code","f111286c":"code","f63fcb04":"markdown","f3b5446a":"markdown","92a319fd":"markdown"},"source":{"8e2959d3":"import numpy as np # linear algebra\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom scipy.stats import skew\nimport xgboost as xgb\nimport lightgbm as lgb\nimport catboost as cat\nfrom sklearn.metrics import mean_squared_error","d176f09f":"train = pd.read_csv('\/kaggle\/input\/forest-data\/Forest_Cover_participants_Data\/train.csv')\ntrain.head()","32a81b1d":"test = pd.read_csv('\/kaggle\/input\/forest-data\/Forest_Cover_participants_Data\/test.csv')\ntest.head()","50ae293a":"train.info()","f86ed6f7":"train.isnull().sum()","2a2594db":"for i in train.columns:\n    for j in train.columns:\n        correlation_matrix = train[i].corr(train[j]).round(2)\n        if correlation_matrix > 0.7:\n            if(i != j):\n                print(i,j,correlation_matrix)\n\n        elif correlation_matrix < -0.7:\n            if(i !=j):\n                print(i,j,correlation_matrix)","9e1177c6":"train.corr()['Cover_Type'].sort_values(ascending=False)","15265ee1":"for i in train.columns:\n    a = train[i].skew()\n    if a >1:\n        print(i,a)","2ccb759a":"train.head()","193b35fe":"# train.drop(columns=['Hillshade_9am','Wilderness_Area_1'],inplace=True)\n# test.drop(columns=['Hillshade_9am','Wilderness_Area_1'],inplace=True)","105b6d49":"x = train.drop(columns='Cover_Type')\ny = train['Cover_Type']","8c261bfd":"\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=7)","02a6e6f2":"\n\n\npredic1 = np.mean(y_pred_totcb1, 0)\npredic1","aae28cfc":"# cate_features_index = np.where(x.dtypes == object) [0]; cate_features_index","305bb2a8":"\n# err=[]\n# y_pred_totcb=[]\n\n# fold=KFold(n_splits=5, random_state=1234)\n# for train_index, test_index in fold.split(x,y):\n#     X_train, X_test = x.iloc[train_index], x.iloc[test_index]\n#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n#     m1 = cat.CatBoostClassifier(iterations=50000, learning_rate=0.01, random_seed=1234)\n#     m1.fit(X_train,y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=500,verbose=100)\n#     preds = m1.predict(X_test)\n#     print(\"err: \",np.sqrt(mean_squared_error(y_test,preds)))\n#     err.append(np.sqrt(mean_squared_error(y_test,preds)))\n#     p2 = m1.predict_proba(test)\n#     y_pred_totcb.append(p2)\n# np.mean(err)","b63d59a8":"# model_2 = xgb.XGBClassifier(\n#  learning_rate =0.01,\n#  n_estimators=5000,\n#  max_depth=1,\n#  colsample_bytree=0.8,\n#  seed=100,\n#  eval_metric='mlogloss',\n#  gamma=0.8\n#  )\n# #model.fit(X_train, y_train)\n# model_2.fit(X_train, y_train, eval_metric='mlogloss', \n#           eval_set=[(X_test, y_test)], early_stopping_rounds=500, verbose=100)","18537ce8":"xgb_model = xgb.XGBClassifier(\n learning_rate =0.01,\n n_estimators=5000,\n max_depth=1,\n colsample_bytree=0.8,\n seed=100,\n eval_metric='mlogloss'\n )","f4dd1fcb":"xgb_model.fit(X_train, y_train)","72c58ccf":"y_pred=xgb_model.predict_proba(test)","22f825e3":"model_1 = lgb.LGBMClassifier(\n    boosting_type='gbdt',\n    objective='multiclass',\n learning_rate =0.01,\n n_estimators=5000,\n colsample_bytree=0.8,\n    eval_metric='logloss'\n )\n#model.fit(X_train, y_train)\nmodel_1.fit(X_train, y_train, eval_metric='logloss', \n          eval_set=[(X_test, y_test)], early_stopping_rounds=500, verbose=100)","a46f6188":"lgb_model = lgb.LGBMClassifier(\n    boosting_type='gbdt',\n    objective='multiclass',\n learning_rate =0.01,\n n_estimators=4441,\n colsample_bytree=0.8\n )","b6d9ae59":"lgb_model.fit(X_train, y_train)","fffe6277":"y_pred1=lgb_model.predict_proba(test)","f78808ac":"submission=pd.DataFrame(y_pred)\nsubmission[submission<0.05]=0\nsubmission[submission>0.95]=1\nsubmission.head(10)","cc3ba492":"final = y_pred1*0.1 + y_pred*0.2 + y_pred2*0.7\ns=pd.DataFrame(final)\ns[s<0.05]=0\ns[s>0.95]=1\ns = np.round(s,1)\nprint(s.head())\ns.to_csv('submission_final.csv',index=False)","98f256ed":"catmodel = cat.CatBoostClassifier()","37c976bf":"catmodel.fit(X_train, y_train)","b430a419":"y_pred2=catmodel.predict_proba(test)","fb24d5f6":"cat = catmodel.predict(X_test)","f111286c":"final = y_pred1*0.1 + y_pred*0.2 + y_pred2*0.7\ns=pd.DataFrame(final)\ns[s<0.05]=0\ns[s>0.95]=1\ns = np.round(s,1)\nprint(s.head())\ns.to_csv('submission_final.csv',index=False)","f63fcb04":"**as they have high co relation between so we will remove one of them**","f3b5446a":"****As we see our target vaiable is not highly correlated to any of the feaurer ****","92a319fd":"# Checking Correlation between features"}}