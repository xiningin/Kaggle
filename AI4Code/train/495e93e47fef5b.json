{"cell_type":{"9d05384d":"code","ba226374":"code","0e3d698e":"code","4e885a64":"code","3e7535d5":"code","7f81a2bc":"code","05e95568":"code","eedddddd":"code","a0ac7b0c":"markdown","e6192e8c":"markdown","2c3a39a3":"markdown","0fa0071c":"markdown"},"source":{"9d05384d":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.pipeline import Pipeline\n\noriginal_train = pd.read_csv('..\/input\/train.csv')\n\nval = original_train.sample(frac=0.2, random_state=1234)\ntrain = original_train.drop(val.index)\nsample = train.sample(frac=0.1, random_state=42) # Small sample of the training set for testing code more quickly\nprint(len(val), len(train), len(sample))\ndel original_train","ba226374":"sample.head()","0e3d698e":"# Implement as a subclass of scikit-learn's count vectorizer\nclass HistogramVectorizer(CountVectorizer):\n    def __init__(self, input='content', encoding='utf-8',\n                 decode_error='strict', strip_accents=None, lowercase=True,\n                 preprocessor=None, tokenizer=None, analyzer='word',\n                 stop_words=None, token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n                 ngram_range=(1, 1), max_df=1.0, min_df=1,\n                 max_features=None, vocabulary=None, binary=False,\n                 dtype=np.float64, positive_class_label=1, bins=25):\n        \"\"\"See CountVectorizer for params\n        positive_class_label: The label that specifies the positive class, used in fit\n        bins: the number of features to generate \"\"\" \n        super(HistogramVectorizer, self).__init__(input=input, encoding=encoding, decode_error=decode_error,\n            strip_accents=strip_accents, lowercase=lowercase,\n            preprocessor=preprocessor, tokenizer=tokenizer, analyzer=analyzer,\n            stop_words=stop_words, token_pattern=token_pattern,\n            ngram_range=ngram_range, max_df=max_df, min_df=min_df,\n            max_features=max_features, vocabulary=vocabulary, binary=binary,\n            dtype=dtype)\n        self.positive_class_label = positive_class_label\n        self.bins = bins\n        \n    def fit(self, raw_documents, y):\n        X = super(HistogramVectorizer, self).fit_transform(raw_documents)\n        \n        total_counts = np.sum(X, axis=0)\n        pos = super(HistogramVectorizer, self).transform(raw_documents[y == self.positive_class_label])\n        positive_counts = np.sum(pos, axis=0)\n        self.precision_scores = positive_counts \/ total_counts\n\n        return self\n        \n    def transform(self, raw_documents, copy=True):\n        X = super(HistogramVectorizer, self).transform(raw_documents)\n        docs, words = X.shape\n        ranges = np.linspace(0, 1, num=self.bins)\n        score_counts = np.zeros((docs, self.bins))\n\n        # Todo look at vectorizing\n        for doc_index in range(0, docs):\n            indices = X[doc_index,:].nonzero()\n            for word_index in indices[1]:    \n                score = self.precision_scores[0, word_index]\n                bin_index = np.searchsorted(ranges, score)\n                score_counts[doc_index, bin_index] += 1\n        \n        normalized = score_counts \/ np.sum(score_counts, axis=1)[:,None]\n        return np.nan_to_num(normalized)\n            ","4e885a64":"vectorizer = HistogramVectorizer(min_df=2, max_df=0.5)\nclassifier = GaussianNB()\ntrain_df = train\nvectorizer.fit(train_df[\"question_text\"], train_df[\"target\"])\ntrain_features = vectorizer.transform(train_df[\"question_text\"])\nclassifier.fit(train_features, train_df[\"target\"])\ntrain_preds = classifier.predict(train_features)\n\n# Training set performance\nprint(accuracy_score(train_preds, train_df[\"target\"]))\nprint(f1_score(train_preds, train_df[\"target\"]))","3e7535d5":"val_features = vectorizer.transform(val[\"question_text\"])\nval_preds = classifier.predict(val_features)\n\nprint(accuracy_score(val_preds, val[\"target\"]))\nprint(f1_score(val_preds, val[\"target\"]))","7f81a2bc":"pos = vectorizer.transform(val[val[\"target\"] == 1][\"question_text\"])\nneg = vectorizer.transform(val[val[\"target\"] == 0][\"question_text\"])","05e95568":"import matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nmean_pos = pos.mean(axis=0)\nmean_neg = neg.mean(axis=0)\nbar_width = 1\/30\nbins = np.linspace(0, 1, 25)\n\ny_dims = (0, 0.4)\nx_dims = (0, 1)\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10,3))\n\naxes[0].set_title('Insincere Questions (mean)')\naxes[0].bar(bins, mean_pos, width=bar_width, align='edge')\naxes[0].set_ylim(y_dims)\naxes[0].set_xlim(x_dims)\naxes[1].set_title('Sincere Questions (mean)')\naxes[1].bar(bins, mean_neg, width=bar_width, align='edge')\naxes[1].set_ylim(y_dims)\naxes[1].set_xlim(x_dims)\n","eedddddd":"fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10,6))\ny_dims = (0, 0.5)\naxes[0, 0].set_title('Insincere Questions')\naxes[0, 0].bar(bins, pos[0], width=bar_width, align='edge')\naxes[0, 0].set_ylim(y_dims)\naxes[0, 0].set_xlim(x_dims)\naxes[1, 0].bar(bins, pos[1], width=bar_width, align='edge')\naxes[1, 0].set_ylim(y_dims)\naxes[1, 0].set_xlim(x_dims)\naxes[0, 1].set_title('Sincere Questions')\naxes[0, 1].bar(bins, neg[0], width=bar_width, align='edge')\naxes[0, 1].set_ylim(y_dims)\naxes[0, 1].set_xlim(x_dims)\naxes[1, 1].bar(bins, neg[1], width=bar_width, align='edge')\naxes[1, 1].set_ylim(y_dims)\naxes[1, 1].set_xlim(x_dims)","a0ac7b0c":"# Visualizing how documents are represented","e6192e8c":"The insincere questions have a distribution that's shifted a little to the right. I notice that the full distribution isn't really being used, which I believe is due to this dataset being quite imbalanced and the scoring method I used here (precision) not really accounting for that.","2c3a39a3":"So on it's own this isn't performing terribly well, but maybe with more tweaking it might be useful as part of an ensemble.","0fa0071c":"This is an approach to the Quora Insincere Questions Classification competition on Kaggle using the features based on the distribution of scores from a word counting approach in my MCS Thesis [Compact Features for Sentiment Analysis'](http:\/\/lgaud.github.io\/Papers\/Thesis_CompactFeaturesForSentimentAnalysis.pdf), also published in a  [Paper from Canadian AI 2011)](http:\/\/lgaud.github.io\/Papers\/CompactFeaturesForSentimentAnalysis.pdf)\n\nMy original implementation was in Java (using Weka and other APIs), and I hadn't previously implemented in Python. I thought it would be worthwhile trying it out on this dataset, as it's a similar binary problem as the problems I looked at in my thesis, and the approach worked relatively well on noisy texts. I don't expect it to perform amazingly on it's own but it may be useful as part of an ensemble.\n\nI've just implemented here using the parameters I found worked relatively well across the problems I looked at in my thesis and haven't made an effort to tune it.\nParams\nIn my thesis for sentiment (and also subjectivity, agreement, and pleasantness), I focused on using 25 bins with Naive Bayes and SVM classifiers, and I used precision to score (count in positive docs \/ total count)"}}