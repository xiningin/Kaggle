{"cell_type":{"800261d0":"code","518e193d":"code","10477e88":"code","b3c8c043":"code","11835cfe":"code","ac0312c9":"code","b36dfac0":"code","4a82b19c":"code","ac8d161f":"code","2d03d862":"code","15eca432":"code","4217e140":"code","798b160d":"code","956af83b":"code","7d333182":"code","12104b63":"code","3fb4bc77":"markdown","a4dceb6a":"markdown","0016e69c":"markdown","545bc253":"markdown","99d2d9c6":"markdown","9fd4d347":"markdown"},"source":{"800261d0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","518e193d":"heart = pd.read_csv('\/kaggle\/input\/heart-failure-prediction\/heart.csv')\nheart","10477e88":"sns.pairplot(heart)","b3c8c043":"heart.isnull().sum()","11835cfe":"heart.describe()","ac0312c9":"coltypes = {'binary':[],\n           'categorical':[],\n           'numerical':[]}\n\nfor col in heart.columns:\n    if min(heart[col])==0 and max(heart[col])==1 and heart[col].nunique()==2:\n        coltypes['binary'].append(col)\n    elif heart[col].dtype==object:\n        coltypes['categorical'].append(col)\n    else:\n        coltypes['numerical'].append(col)\n        \nfor coltype, cols in coltypes.items():\n    print(f'{coltype}:')\n    for col in cols:\n        print(f'- {col}')\n    print()","b36dfac0":"for col in ['RestingBP', 'Cholesterol']:\n    heart[col] = heart[col].replace({0:np.nan})\n    mean_val = heart[col].mean()\n    heart[col] = heart[col].replace({np.nan:mean_val})\nheart.describe()","4a82b19c":"for col in coltypes['numerical']:\n    Q1 = heart[col].quantile(0.25)\n    Q3 = heart[col].quantile(0.75)\n    IQR = Q3-Q1\n    lower_bound = Q1 - 3*IQR\n    mask = heart[col]< lower_bound\n    heart.loc[mask,col] = lower_bound\n    upper_bound = Q3 + 3*IQR\n    mask = heart[col]> upper_bound\n    heart.loc[mask,col] = upper_bound\n    \nheart.describe()","ac8d161f":"for col in coltypes['categorical']:\n    print(heart[col].value_counts())","2d03d862":"for col in coltypes['categorical']:\n    one_hot = pd.get_dummies(heart[col],prefix=col)\n    heart = pd.merge(heart.drop(col,axis=1), one_hot, left_index=True, right_index=True)\nheart\n                ","15eca432":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(heart.drop('HeartDisease',axis=1), heart['HeartDisease'], shuffle=True, stratify=heart['HeartDisease'], test_size=0.2, random_state=42)","4217e140":"from xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics","798b160d":"\nmodels = {\n    'xgb' : XGBClassifier(random_state=42),\n    'rf': RandomForestClassifier(random_state=42),\n    'lr': LogisticRegression(solver='liblinear'),\n    'dt': DecisionTreeClassifier()\n}\n\nbest_algo = {'algo':None, 'f1': -np.inf, 'acc': -np.inf}\ny_preds = {}\nfor algo, model in models.items():\n    print('#'*10 + ' ' + algo.upper() + ' ' + '#'*10)\n    model.fit(x_train,y_train)\n    y_preds[algo] = model.predict(x_test)\n    \n    print(metrics.classification_report(y_test,y_preds[algo]))\n    print('-'*40)\n    print()\n\n    f1 = metrics.f1_score(y_test, y_preds[algo])\n    acc = metrics.accuracy_score(y_test, y_preds[algo])\n    \n    if f1>best_algo['f1']:\n        best_algo['algo'] = algo\n        best_algo['f1'] = f1\n        best_algo['acc'] = acc\n        \n\nprint('-'*40)\nprint(f'BEST ALGO: {best_algo}')","956af83b":"fpr, tpr, thresholds = metrics.roc_curve(y_test, y_preds[best_algo['algo']])\nroc_auc = metrics.auc(fpr, tpr)\ndisplay = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n                                 estimator_name=best_algo['algo'])\ndisplay.plot()\nplt.show()","7d333182":"feat_imp = pd.DataFrame({\n    'Features': x_train.columns,\n    'Importances': models[best_algo['algo']].feature_importances_}).sort_values('Importances')\nfeat_imp.set_index('Features').plot(kind='barh', figsize=[12,8])\nplt.show()","12104b63":"import shap\nexplainer = shap.TreeExplainer(models[best_algo['algo']], check_additivity='False')\nshap_values = explainer.shap_values(x_train)\n\nshap.summary_plot(shap_values[1], x_train)","3fb4bc77":"# EDA and Data Cleaning","a4dceb6a":"next we will cap the numerical values to remove outliers. It will be capped at Q1 - 3 * IQR and Q3 + 3 * IQR","0016e69c":"Convert categorical columns using one hot encoding","545bc253":"# Machine Learning","99d2d9c6":"Based on the shap values, ST_Slope and ChestPainTypes are the top predictors. When the ST_Slope is not 'Up', but 'Flat' there is higher probability of heart disease. 'ASY' type for chest pain is also more likely to have heart disease","9fd4d347":"The rest of the columns are numerical, with null values represented as 0. For cholesterol and resting blood pressure, it is not possible to get a value of 0, but this number is seen in the columns. Therefore, zeroes in the dataset for these 2 columns will be replaced with the mean"}}