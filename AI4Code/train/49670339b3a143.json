{"cell_type":{"c6fd1bdf":"code","b2bba172":"code","3f19bfd0":"code","a9dbfcbc":"code","dfed6cb6":"code","ea7dfc10":"code","e0b1afcc":"code","edff96c4":"code","1edff86d":"code","527c0876":"code","ab49d494":"code","0de7ccd6":"code","bd51a7d3":"code","cccaed66":"code","586fe94a":"code","56bb3616":"code","404199f8":"code","853c8315":"code","d5fde0d4":"code","d902e887":"code","dac22621":"code","66e7bdad":"code","2924a70a":"code","05781278":"code","ee60be7e":"code","4130af45":"code","73f93347":"code","d3b7d060":"code","a4660e76":"markdown","b777ab10":"markdown","efeac569":"markdown","b6d632bf":"markdown","77ce776d":"markdown","a7dd759b":"markdown","8d8b71c2":"markdown","b54c7e2e":"markdown","f977c28e":"markdown","d663c065":"markdown","70bcc6c7":"markdown","43a595e7":"markdown","9e3ba3cc":"markdown","044b1783":"markdown","ff796125":"markdown","3d8b3a75":"markdown","9db04dbd":"markdown","3cd53cf5":"markdown","ca52ce4e":"markdown","a2f2764d":"markdown","02aed3d6":"markdown","894328d0":"markdown"},"source":{"c6fd1bdf":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport random\nimport glob # to find files\nimport seaborn as sns\n\nfrom sklearn.metrics import confusion_matrix,classification_report\n\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras.applications.vgg16 import preprocess_input\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\nprint(\"K\u00fct\u00fcphaneler dahil edildi.\")","b2bba172":"# variables for data paths\npath = '..\/input\/chest-xray-pneumonia\/chest_xray\/'\n\n# train directory\ntrain_folder=path+\"train\/\"\ntrain_normal_dir=train_folder+\"NORMAL\/\"\ntrain_pneu_dir=train_folder+\"PNEUMONIA\/\"\n# test directory\ntest_folder=path+\"test\/\"\ntest_normal_dir=test_folder+\"NORMAL\/\"\ntest_pneu_dir=test_folder+\"PNEUMONIA\/\"\n# validation directory\nval_folder=path+\"val\/\"\nval_normal_dir=val_folder+\"NORMAL\/\"\nval_pneu_dir=val_folder+\"PNEUMONIA\/\"\n\n# variables for image size\nimg_width=196\nimg_height=196\n\n# variable for model\nbatch_size=64\nepochs=10","3f19bfd0":"# Train Dataset\ntrain_class_names=os.listdir(train_folder)\nprint(\"Train class names: %s\" % (train_class_names))\n# print(\"\\n\")\n\n# Test Dataset\ntest_class_names=os.listdir(test_folder)\nprint(\"Test class names: %s\" % (test_class_names))\n# print(\"\\n\")\n\n# Validation Dataset\nval_class_names=os.listdir(val_folder)\nprint(\"Validation class names: %s\" % (val_class_names))\n","a9dbfcbc":"# declaration of functions\n\n# Function get name of xray type\ndef Get_Xray_Type(argument):\n    switcher = {\n        \"NORMAL\": \"Normal\",\n        \"PNEUMONIA\": \"Pneumonia\",\n    }\n    return switcher.get(argument, \"Invalid X-ray\")\n# Get_Xray_Type(\"NORMAL\") # this is how the function can be called\n\nprint(\"Declaration of functions completed.\")","dfed6cb6":"# E\u011fitim,Test ve Do\u011frulama verilerinin analizi\n\n# t\u00fcm dosyalarda ara jpeg i\u00e7eren\ntrain_normal_cases = glob.glob(train_normal_dir + '*jpeg')\ntrain_pneu_cases = glob.glob(train_pneu_dir + '*jpeg')\n\ntest_normal_cases = glob.glob(test_normal_dir + '*jpeg')\ntest_pneu_cases = glob.glob(test_pneu_dir + '*jpeg')\n\nval_normal_cases = glob.glob(val_normal_dir + '*jpeg')\nval_pneu_cases = glob.glob(val_pneu_dir + '*jpeg')\n\n# create lists for train, test & validation cases, create labels as well\ntrain_list = []\ntest_list = []\nval_list = []\n\nfor x in train_normal_cases:\n    train_list.append([x, \"Normal\"])\n    \nfor x in train_pneu_cases:\n    train_list.append([x, \"Pneumonia\"])\n    \nfor x in test_normal_cases:\n    test_list.append([x, \"Normal\"])\n    \nfor x in test_pneu_cases:\n    test_list.append([x, \"Pneumonia\"])\n    \nfor x in val_normal_cases:\n    val_list.append([x, \"Normal\"])\n    \nfor x in val_pneu_cases:\n    val_list.append([x, \"Pneumonia\"])\n\n# create dataframes\ntrain_df = pd.DataFrame(train_list, columns=['image', 'Diagnos'])\nprint(train_df.shape)\ntest_df = pd.DataFrame(test_list, columns=['image', 'Diagnos'])\nprint(test_df.shape)\nval_df = pd.DataFrame(val_list, columns=['image', 'Diagnos'])\nprint(val_df.shape)","ea7dfc10":"train_df","e0b1afcc":"# plotting the Train, Test and Validation image data\n\nplt.figure(figsize=(20,5))\n\nplt.subplot(1,3,1)\nsns.countplot(train_df['Diagnos'])\nplt.title('Train data')\n\nplt.subplot(1,3,2);\nsns.countplot(test_df['Diagnos'])\nplt.title('Test data')\n\nplt.subplot(1,3,3)\nsns.countplot(val_df['Diagnos'])\nplt.title('Validation data')\nplt.show()","edff96c4":"# Plotting raw images just for review\n\nplt.figure(figsize=(20,8))\nfor i,img_path in enumerate(train_df[train_df['Diagnos'] == \"Pneumonia\"][0:4]['image']):\n    plt.subplot(2,4,i+1)\n    plt.axis('off')\n    img = plt.imread(img_path)\n    plt.imshow(img, cmap='gray')\n    plt.title('Pneumonia')\n    \nfor i,img_path in enumerate(train_df[train_df['Diagnos'] == \"Normal\"][0:4]['image']):\n    plt.subplot(2,4,4+i+1)\n    plt.axis('off')\n    img = plt.imread(img_path)\n    plt.imshow(img, cmap='gray')\n    plt.title('Normal')","1edff86d":"# Preparing Training image data (image array and class name) for processing\n\n# Declaring variables\nx=[] # to store array value of the images\ny=[] # to store the labels of the images\n\nfor folder in os.listdir(train_folder):\n    image_list=os.listdir(train_folder+\"\/\"+folder)\n    for img_name in image_list:\n        # Loading images\n        img=image.load_img(train_folder+\"\/\"+folder+\"\/\"+img_name,target_size=(img_width,img_height))\n        \n        # Converting to arrary\n        img=image.img_to_array(img)\n        \n        # Transfer Learning: this is to apply preprocess of VGG16 model to our images before passing it to VGG16\n        img=preprocess_input(img) #  Optional step\n        \n        # Appending the arrarys\n        x.append(img) # appending image array\n        y.append(train_class_names.index(folder)) # appending class index to the array\nprint(\"Preparing Training Dataset Completed.\")","527c0876":"y","ab49d494":"import cv2\nimport matplotlib.pyplot as plt\ntrain_list=[]\nkernel=np.zeros((5,5),)\nfor i in x:\n    img=i\/255.0\n    img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    mask = cv2.erode(img,(5,5),iterations =2)\n    mask = cv2.morphologyEx(mask,cv2.MORPH_OPEN,(5,5))\n    img = cv2.dilate(mask,(5,5),iterations = 1)\n    arka_plan=cv2.medianBlur(img,5)\n    maske=cv2.addWeighted(img,1,arka_plan,-1,255)\n    son_img=cv2.bitwise_and(maske,img)\n    train_list.append(img)\n    \n        ","0de7ccd6":"# Preparing validation images data (image array and class name) for processing\n\n# Declaring variables\nval_images=[]\nval_images_Original=[]\nval_image_label=[] # to store the labels of the images\n\nfor folder in os.listdir(val_folder):\n    image_list=os.listdir(val_folder+\"\/\"+folder)\n    for img_name in image_list:\n        # Loading images\n        img=image.load_img(val_folder+\"\/\"+folder+\"\/\"+img_name,target_size=(img_width,img_height))\n        \n        # Converting to arrarys\n        img=image.img_to_array(img)\n        \n        # Saving original images, will be used just for display at the end\n        val_images_Original.append(img.copy())\n        \n        # Transfer Learning: this is to apply preprocess of VGG16 to our images before passing it to VGG16\n        img=preprocess_input(img) #  Optional step\n        \n        # Appending arrays\n        val_images.append(img) # appending image array\n        val_image_label.append(val_class_names.index(folder))\n        \n        \nprint(\"Preparing Validation Dataset Completed.\")","bd51a7d3":"import cv2\nimport matplotlib.pyplot as plt\nval_list=[]\nfor i in val_images:\n    img=i\/255.0\n    img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    mask = cv2.erode(img,(5,5),iterations =2)\n    mask = cv2.morphologyEx(mask,cv2.MORPH_OPEN,(5,5))\n    img = cv2.dilate(mask,(5,5),iterations = 1)\n    arka_plan=cv2.medianBlur(img,5)\n    maske=cv2.addWeighted(img,1,arka_plan,-1,255)\n    son_img=cv2.bitwise_and(maske,img)\n    val_list.append(img)","cccaed66":"# Preparing test images data (image array and class name) for processing\n\n# Declaring variables\ntest_images=[]\ntest_images_Original=[]\ntest_image_label=[] # to store the labels of the images\n\nfor folder in os.listdir(test_folder):\n    image_list=os.listdir(test_folder+\"\/\"+folder)\n    for img_name in image_list:\n        # Loading images\n        img=image.load_img(test_folder+\"\/\"+folder+\"\/\"+img_name,target_size=(img_width,img_height))\n        \n        # Converting to arrarys\n        img=image.img_to_array(img)\n        \n        # Saving original images, will be used just for display at the end\n        test_images_Original.append(img.copy())\n        \n        # Transfer Learning: this is to apply preprocess of VGG16 to our images before passing it to VGG16\n        img=preprocess_input(img) #  Optional step\n        \n        # Appending arrays\n        test_images.append(img) # appending image array\n        test_image_label.append(test_class_names.index(folder))\n      \n        \nprint(\"Preparing Test Dataset Completed.\")","586fe94a":"import cv2\nimport matplotlib.pyplot as plt\ntest_list=[]\nfor i in test_images:\n    img=i\/255.0\n    img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    mask = cv2.erode(img,(5,5),iterations =2)\n    mask = cv2.morphologyEx(mask,cv2.MORPH_OPEN,(5,5))\n    img = cv2.dilate(mask,(5,5),iterations = 1)\n    arka_plan=cv2.medianBlur(img,5)\n    maske=cv2.addWeighted(img,1,arka_plan,-1,255)\n    son_img=cv2.bitwise_and(maske,img)\n    test_list.append(img)","56bb3616":"plt.imshow(test_list[3],cmap=\"gray\")","404199f8":"# Verifying the output\n\n# Training Dataset\nprint(\"Training Dataset\")\n\ntrain_list=np.array(train_list) # Converting to np arrary to pass to the model\nprint(train_list.shape)\n\n#y=to_categorical(y) # onehot encoding of the labels\n# print(y)\ny = np.array(y)\nprint(y.shape)\n\n# ===========\n\n# Test Dataset\nprint(\"Test Dataset\")\n\ntest_images=np.array(test_images) \nprint(test_images.shape)\n\ntest_image_label=np.array(test_image_label) # onehot encoding of the labels)\nprint(test_image_label.shape)\n\n# ===========\n\n# Validation Dataset\nprint(\"Validation Dataset\")\n\nval_images=np.array(val_images) \nprint(val_images.shape)\n\nval_image_label=np.array(val_image_label) # onehot encoding of the labels)\nprint(val_image_label.shape)","853c8315":"from tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D,Dropout,Flatten\ntrain_list=np.array(train_list)\ntrain_list=train_list.reshape(-1,196,196,1)\ntest_list=np.array(test_list)\ntest_list=test_list.reshape(-1,196,196,1)\ntest_images=np.array(test_images)\ntest_images=test_images.reshape(-1,196,196,1)\n\ny=np.array(y)","d5fde0d4":"model = Sequential()\nmodel.add(Conv2D(32,3,activation = 'relu',padding = 'Same' ,input_shape =train_list.shape[1:]))\nmodel.add(Conv2D(32,3,activation = 'relu',padding = 'Same'))\nmodel.add(MaxPool2D(pool_size = (2,2), strides = 2))\nmodel.add(Conv2D(32,3,activation = 'relu',padding = 'Same'))\nmodel.add(MaxPool2D(pool_size = (2,2), strides = 2))\nmodel.add(Conv2D(32,3,activation = 'relu', padding = 'Same'))\nmodel.add(MaxPool2D(pool_size = (2,2), strides = 1))\nmodel.add(Conv2D(32,3,activation = 'relu', padding = 'Same'))\nmodel.add(MaxPool2D(pool_size = (2,2), strides = 1))\nmodel.add(Conv2D(32,3,activation = 'relu', padding = 'Same'))\nmodel.add(MaxPool2D(pool_size = (2,2), strides = 1))\nmodel.add(Conv2D(32,3,activation = 'relu', padding = 'Same'))\nmodel.add(MaxPool2D(pool_size = (2,2), strides = 1))\nmodel.add(Flatten())\nmodel.add(Dense(256,activation = 'relu'))\nmodel.add(Dense(1, activation = \"sigmoid\"))\nmodel.summary()","d902e887":"# Train the Model\n\nfrom sklearn.model_selection import train_test_split\nxtrain, xtest, ytrain, ytest = train_test_split(train_list,y,test_size=0.2,random_state=5)\n# print(xtrain)\n# print(xtest)\n# print(ytrain)\n# print(ytest)\n\nprint(\"Train ve Test i\u00e7in veri b\u00f6lme tamamland\u0131.\")","dac22621":"model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n\nprint(\"Model Derleme tamamland\u0131.\")","66e7bdad":"#keras k\u00fct\u00fcphanessinden ImageDataGenerator kullan\u0131rsak model do\u011frulamam\u0131z daha d\u00fc\u015f\u00fck \u00e7\u0131kt\u0131\u011f\u0131 i\u00e7in kullanm\u0131yoruz.\n#loss: 0.0659 - accuracy: 0.9741 - val_loss: 0.3147 - val_accuracy: 0.8942","2924a70a":"from keras.callbacks import ReduceLROnPlateau\nlr=ReduceLROnPlateau(monitor=\"val_accuracy\",\n                     pateince=3,\n                     verbose=1,mode=\"auto\",\n                     factor=0.25,\n                     min_lr=0.000001)","05781278":"#history = model.fit(train_list,y,epochs=50,batch_size=80,verbose=True,validation_data=(test_list,test_image_label),callbacks = [lr])\n\n#print(\"Fitting the model completed.\")","ee60be7e":"history = model.fit(train_list,y,epochs=50,batch_size=80,verbose=True,validation_data=(test_list,test_image_label),callbacks = [lr])\n\nprint(\"Fitting the model completed.\")","4130af45":"plt.figure(figsize = (10,7))\nplt.subplot(1,2,1)\nplt.plot(history.history['loss'], label = 'train_loss')\nplt.plot(history.history['val_loss'],label = 'val_loss')\nplt.ylim(0,1)\nplt.subplot(1,2,2)\nplt.plot(history.history['accuracy'], label  = 'train_accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.ylim(0.9,1)\nplt.legend()\nplt.show()","73f93347":"print(classification_report(ytest,model.predict(xtest).round()))","d3b7d060":"import seaborn as sn\nsns.heatmap(confusion_matrix(ytest,model.predict(xtest).round()),annot=True)","a4660e76":"**Veri K\u00fcmesini Do\u011frulama**","b777ab10":"**Do\u011frulama g\u00f6r\u00fcnt\u00fc verilerinin haz\u0131rlanmas\u0131**","efeac569":"<a id=\"11\"><\/a>\n<font color=\"blue\" size=+2.5><b>4.1 Model Olu\u015fturma<\/b><\/font>\n<br\/>","b6d632bf":"<a id=\"1\"><\/a>\n<font color=\"blue\" size=+2.5><b>1.1  Pn\u00f6moni(zat\u00fcrre) nedir ?<\/b><\/font>\n<br\/>\n<br\/>\n![image.png](http:\/\/madicanacdnstorage.blob.core.windows.net\/main\/Assets\/photo\/r\/zaturre-53690-95217_t.jpg)\nHalk aras\u0131nda zat\u00fcrre olarak bilinen Pn\u00f6moni akci\u011ferlerin klinik ve radyolojik olarak tespit edilen inflamasyonudur. Y\u00fcksek riskli bir hastal\u0131k olan zat\u00fcrre \u00fclkemizde \u00f6l\u00fcmlerde be\u015finci, infeksiyon hastal\u0131klar\u0131nda birinci s\u0131radad\u0131r.\n\n**ZAT\u00dcRRE YAN\u0130 PN\u00d6MON\u0130 BEL\u0130RT\u0130LER\u0130 NELERD\u0130R?**\n\n**Tipik Zat\u00fcrre Belirtileri:**\n\n\nAkut ve g\u00fcr\u00fclt\u00fcl\u00fc bir tablo ile ba\u015flayan zat\u00fcrredir. \u00dc\u015f\u00fcme ve titreme ile y\u00fckselen ate\u015f, \u00f6ks\u00fcr\u00fck, sar\u0131 ye\u015fil veya pas renginde koyu balgam, ci\u011fer zar\u0131 tutulmu\u015fsa nefes al\u0131p verirken yan a\u011fr\u0131lar\u0131 ve nefes darl\u0131\u011f\u0131 \u015fikayetleri tipik zat\u00fcrrenin ilk belirtileri aras\u0131ndad\u0131r. Tipik zat\u00fcrre belirtisi olarak solunum yetmezli\u011fi ya\u015fanabilir. **Akci\u011fer grafisinde lober tutulum olur**. Kanda l\u00f6kosit(WBC-Beyaz k\u00fcre) ve CRP y\u00fckselmesi, form\u00fclde sola kayma olur. Etkenler genellikle Streptococcus Pneumoniae, Hemophilus Influenza, gram negatif aeroblar ve anaerob basillerdir.\n\n**A Tipik Zat\u00fcrre Belirtileri:**\n\nSubakut ve sinsi bir ba\u015flang\u0131\u00e7 vard\u0131r. Eklem ve kas a\u011fr\u0131lar\u0131, halsizlik, i\u015ftahs\u0131zl\u0131k gibi \u00f6n belirtiler g\u00f6r\u00fcl\u00fcr. Kuru \u00f6ks\u00fcr\u00fck, h\u0131\u015f\u0131rt\u0131l\u0131 solunum, akci\u011fer d\u0131\u015f\u0131 organlar\u0131n tutulumuna ba\u011fl\u0131 ba\u015f ve kar\u0131n a\u011fr\u0131lar\u0131 gibi \u015fikayetler A tipik zat\u00fcrre belirtileri aras\u0131ndad\u0131r. **Radyolojide yamal\u0131 infiltrasyon ve parakardiyak tutulum g\u00f6r\u00fcl\u00fcr**. Kanda l\u00f6kosit(WBC) normal veya d\u00fc\u015f\u00fckt\u00fcr. Etkenler Mycoplasma Pneumoniae , Chlamydia Pneumoniae ( TWAR) , Legionella Pneumoniae, vir\u00fcsler (Influenza ,RSV,Adenov\u0131rus,Coronavirus) dir.\n\n\n","77ce776d":"<a id=\"4\"><\/a>\n<font color=\"blue\" size=+2.5><b>2.1 Kurulumlar<\/b><\/font>\n* Numpy\n* Pandas\n* Matplotlib\n* Seaborn\n* Keras\n* Tensorflow","a7dd759b":"<a id=\"11\"><\/a>\n<font color=\"blue\" size=+2.5><b>4.2 Model E\u011fitme<\/b><\/font>\n<br\/>","8d8b71c2":"# Model Derleme","b54c7e2e":"<a id=\"top\"><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">\u0130\u00e7erik Tablosu<\/h3>\n\n<font color=\"blue\" size=+1><b>Giri\u015f<\/b><\/font>\n* [1. Pn\u00f6moni(zat\u00fcrre) nedir ?](#1)\n\n<font color=\"blue\" size=+1><b>K\u00fct\u00fcphaneler<\/b><\/font>\n* [1. Kurulum](#4)\n* [2. \u0130\u00e7e Aktar\u0131lanlar ](#5)\n    \n<font color=\"blue\" size=+1><b> Verileri Y\u00fckleme ve G\u00f6r\u00fcnt\u00fcleme<\/b><\/font>\n* [1. De\u011fi\u015fkenleri Belirtme ](#6)\n* [2. Veri Setleri ](#7)\n* [3. Verilerin Do\u011frulanmas\u0131 ](#8)\n* [4. Verilerin G\u00f6rselle\u015ftirilmesi ](#9)\n* [5. Verilerin \u00d6n haz\u0131rl\u0131\u011f\u0131 ](#10)    \n\n<font color=\"blue\" size=+1><b> Model Olu\u015fturma ve E\u011fitme<\/b><\/font>\n* [1. Model Olu\u015fturma ](#11)\n* [2. Model E\u011fitme ](#12)\n    \n<font color=\"blue\" size=+1><b> Model Tahminleri <\/b><\/font> \n* [1. Tahminler ](#13)","f977c28e":"***G\u00f6rselle\u015ftirme i\u00e7in Verilerin Haz\u0131rlanmas\u0131***","d663c065":"<a id=\"7\"><\/a>\n<font color=\"blue\" size=+2.5><b>3.2 Veri Setleri<\/b><\/font>\n<br\/>","70bcc6c7":"<a id=\"10\"><\/a>\n<font color=\"blue\" size=+2.5><b>3.5 Verilerin \u00d6n Haz\u0131rl\u0131\u011f\u0131<\/b><\/font>\n<br\/>","43a595e7":"<a id=\"9\"><\/a>\n<font color=\"blue\" size=+2.5><b>3.4 Verilerin G\u00f6rselle\u015ftirilmesi<\/b><\/font>\n<br\/>","9e3ba3cc":"<a id=\"5\"><\/a>\n\n\n<font color=\"blue\" size=+2.5><b>2. K\u00fct\u00fcphaneler<\/b><\/font>","044b1783":"<a id=\"6\"><\/a>\n<font color=\"blue\" size=+2.5><b>3.1 De\u011fi\u015fkenleri Belirtme<\/b><\/font>","ff796125":"<a id=\"5\"><\/a>\n<font color=\"blue\" size=+2.5><b>2.2 \u0130\u00e7e Aktar\u0131lanlar<\/b><\/font>","3d8b3a75":"**test g\u00f6r\u00fcnt\u00fc verilerinin haz\u0131rlanmas\u0131**","9db04dbd":"# Model Fit","3cd53cf5":"# **Fonksiyonlar**","ca52ce4e":"**Ham G\u00f6r\u00fcnt\u00fclerin g\u00f6r\u00fcnt\u00fclenmesi**","a2f2764d":"<a id=\"8\"><\/a>\n<font color=\"blue\" size=+2.5><b>3.3 Verilerin Do\u011frulanmas\u0131<\/b><\/font>\n<br\/>","02aed3d6":"**E\u011fitim g\u00f6r\u00fcnt\u00fc verilerinin Haz\u0131rlanmas\u0131**","894328d0":"<font color=\"blue\" size=+1><b>Referans <\/b><\/font>\n<br\/>\n<br\/>\n[viratkothari](http:\/\/https:\/\/www.kaggle.com\/viratkothari)\n<br\/>\nhttps:\/\/www.kaggle.com\/viratkothari\/chest-x-ray-image-classification-using-vgg16\n"}}