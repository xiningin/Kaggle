{"cell_type":{"b60c0e29":"code","12d5abeb":"code","80393dc9":"code","db6d137a":"code","1f44eaad":"code","130be751":"code","757c46f3":"code","6029310a":"code","c051beaa":"code","67634c86":"code","05c7eee4":"code","b81973c1":"code","c498e269":"code","64e14e14":"code","d492db70":"code","126106c6":"markdown","a7786720":"markdown","491b5d26":"markdown","b4fbe6e9":"markdown","e714396b":"markdown","11a72e0e":"markdown","11a25f89":"markdown","73951689":"markdown"},"source":{"b60c0e29":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport os.path\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split","12d5abeb":"# Create a list with the filepaths\ntrain_dir = Path('..\/input\/10-monkey-species\/training\/training')\ntrain_filepaths = list(train_dir.glob(r'**\/*.jpg'))\ntest_dir = Path('..\/input\/10-monkey-species\/validation\/validation')\ntest_filepaths = list(test_dir.glob(r'**\/*.jpg'))","80393dc9":"def proc_img(filepath):\n    \"\"\" Create a DataFrame with the filepath and the labels of the pictures\n    \"\"\"\n    labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepath))\n\n    filepath = pd.Series(filepath, name='Filepath').astype(str)\n    labels = pd.Series(labels, name='Label')\n\n    # Concatenate filepaths and labels\n    df = pd.concat([filepath, labels], axis=1)\n\n    # Shuffle the DataFrame and reset index\n    df = df.sample(frac=1).reset_index(drop = True)\n    \n    return df\n\n# Create a DataFrame with the filepaths and the labels of the picture\ntrain_df = proc_img(train_filepaths)\ntest_df = proc_img(test_filepaths)\n\nprint(f'Number of pictures: {train_df.shape[0]}\\n')\nprint(f'Number of different labels: {len(train_df.Label.unique())}\\n')\nprint(f'Labels: {train_df.Label.unique()}')\n\n# The DataFrame with the filepaths in one column and the labels in the other one\ntrain_df.head(5)","db6d137a":"# Name mapping:\nname_dic = {'n0':'alouatta palliata', \n            'n1':'erythrocebus patas', \n            'n2':'cacajao calvus', \n            'n3':'macaca fuscata', \n            'n4':'cebuella pygmea', \n            'n5':'cebus capucinus', \n            'n6':'mico argentatus', \n            'n7':'saimiris ciureus', \n            'n8':'aotus nigriceps', \n            'n9':'trachypithecus johnii'}\n\n# Map the labels into the DataFrames\ntrain_df['Label'] = train_df['Label'].apply(lambda n: name_dic[n])\ntest_df['Label'] = test_df['Label'].apply(lambda n: name_dic[n])","1f44eaad":"# Create a DataFrame with one Label of each category\ndf_unique = train_df.copy().drop_duplicates(subset=[\"Label\"]).reset_index()\n\n# Display 10 picture of the dataset\nfig, axes = plt.subplots(nrows=2, ncols=5, figsize=(15, 7),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(df_unique.Filepath[i]))\n    ax.set_title(df_unique.Label[i])\nplt.tight_layout(pad=0.5)\nplt.show()","130be751":"train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n    validation_split=0.2\n)\n\ntest_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n)\n\ntrain_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=0,\n    subset='training',\n    rotation_range=30,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\"\n)\n\nval_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=0,\n    subset='validation',\n    rotation_range=30,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\"\n)\n\ntest_images = test_generator.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=False\n)","757c46f3":"# Load the pretained model\npretrained_model = tf.keras.applications.MobileNetV2(\n    input_shape=(224, 224, 3),\n    include_top=False,\n    weights='imagenet',\n    pooling='avg'\n)\n\npretrained_model.trainable = False","6029310a":"inputs = pretrained_model.input\n\nx = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\n\noutputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=50,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ]\n)","c051beaa":"pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()\nplt.title(\"Accuracy\")\nplt.show()","67634c86":"pd.DataFrame(history.history)[['loss','val_loss']].plot()\nplt.title(\"Loss\")\nplt.show()","05c7eee4":"# Predict the label of the test_images\npred = model.predict(test_images)\npred = np.argmax(pred,axis=1)\n\n# Map the label\nlabels = (train_images.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npred = [labels[k] for k in pred]\n\n# Display the result\nprint(f'The first 5 predictions: {pred[:5]}')","b81973c1":"from sklearn.metrics import accuracy_score\ny_test = list(test_df.Label)\nacc = accuracy_score(y_test,pred)\nprint(f'Accuracy on the test set: {acc * 100:.2f}%')","c498e269":"from sklearn.metrics import classification_report\nclass_report = classification_report(y_test, pred, zero_division=1)\nprint(class_report)","64e14e14":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\ncf_matrix = confusion_matrix(y_test, pred, normalize='true')\nplt.figure(figsize = (20,15))\nsns.heatmap(cf_matrix, annot=False, xticklabels = sorted(set(y_test)), yticklabels = sorted(set(y_test)))\nplt.title('Normalized Confusion Matrix', fontsize = 23)\nplt.show()","d492db70":"# Display 15 picture of the dataset with their labels\nfig, axes = plt.subplots(nrows=4, ncols=5, figsize=(15, 12),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(test_df.Filepath.iloc[i]))\n    ax.set_title(f\"True: {test_df.Label.iloc[i].split('_')[0]}\\nPredicted: {pred[i].split('_')[0]}\")\nplt.tight_layout()\nplt.show()","126106c6":"# 1. Loading and preprocessing<a class=\"anchor\" id=\"1\"><\/a>","a7786720":"# 3. Train the model<a class=\"anchor\" id=\"3\"><\/a>\n","491b5d26":"# 2. Load the Images with a generator and Data Augmentation<a class=\"anchor\" id=\"2\"><\/a>","b4fbe6e9":"# 4. Visualize the result<a class=\"anchor\" id=\"4\"><\/a>","e714396b":"# 5. Examples of prediction<a class=\"anchor\" id=\"5\"><\/a>\n","11a72e0e":"# Table of contents\n\n[<h3>1. Loading and preprocessing<\/h3>](#1)\n\n[<h3>2. Load the Images with a generator and Data Augmentation<\/h3>](#2)\n\n[<h3>3. Train the model<\/h3>](#3)\n\n[<h3>4. Visualize the result<\/h3>](#4)\n\n[<h3>5. Example of predictions<\/h3>](#5)","11a25f89":"<img src=\"https:\/\/i.imgur.com\/qUaYVes.png\"\/> ","73951689":"# Monkey classifier with transfer learning"}}