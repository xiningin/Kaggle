{"cell_type":{"e7a97e9f":"code","18bf52a1":"code","9fb1bdb8":"code","f89d5ede":"code","53802e4a":"code","3976ee7d":"code","29d8c315":"code","fab0e407":"code","56c23b12":"code","93957a27":"code","26eb6457":"code","f5273aed":"code","0fbf4646":"code","ed65579d":"code","947f5d10":"code","b687ec8c":"code","250913ad":"code","2b89d004":"code","2c2e7b60":"code","84a92b5a":"code","0a76b70e":"code","2d507c8c":"code","c971d800":"code","91843510":"markdown","e7aefe88":"markdown","45e56655":"markdown","2a6d581a":"markdown","e5215346":"markdown","dfed443a":"markdown","f4c27dec":"markdown","4da5eca6":"markdown","93419b1f":"markdown","b4f10da4":"markdown","fe6eeeaf":"markdown","1beb3bc4":"markdown","82613cd6":"markdown","dcad7da7":"markdown","171f6231":"markdown","e3101180":"markdown","bcb0c3af":"markdown","624cebc8":"markdown","e60e8793":"markdown","10d32849":"markdown","cbe656a7":"markdown","c99110ec":"markdown","0613cc82":"markdown","54d2e9b9":"markdown","4acddbeb":"markdown","1d658873":"markdown","ce968d1d":"markdown","f02d8d95":"markdown","c04e3ff7":"markdown","f04f5cc8":"markdown"},"source":{"e7a97e9f":"import pandas as pd\nimport os\nimport numpy as np\nimport seaborn as sns\nimport warnings\nimport tensorflow as tf\nfrom matplotlib import pylab as plt\nfrom IPython.core.interactiveshell import InteractiveShell\nfrom sklearn.metrics import confusion_matrix\n\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)\nwarnings.simplefilter(action=\"ignore\", category=Warning)\nInteractiveShell.ast_node_interactivity = 'all'\n\n%reload_ext autoreload\n%autoreload 2\n\nsns.set_style('whitegrid')\nsns.set_context('paper', font_scale=1.5)\nplt.style.use('fivethirtyeight')\npd.set_option(\"display.width\", 100)\npd.set_option(\"display.max_columns\", 25)\npd.set_option(\"display.max_rows\", 25)\n\nprint(tf.__version__)\nprint(\"Setup complete!\")","18bf52a1":"raw = \"..\/input\/early-diabetes-classification\/diabetes_data.csv\"\ndiabetes_data = pd.read_csv(raw, sep=\";\")\ndiabetes_data ","9fb1bdb8":"# getting the information \ndiabetes_data.info()","f89d5ede":"# Getting the uniqueness categorical variable\ncategorical = diabetes_data.select_dtypes([\"category\", \"object\"]).columns\nfor cat_col in categorical:\n    print(f\"{cat_col} : {diabetes_data[cat_col].nunique()} unique values(s)\")","53802e4a":"# Getting the uniqueness discrete and continuous variables\nnumeric = diabetes_data.select_dtypes([\"int\", \"float\"]).columns\nfor num_col in numeric: # print every unique values\n    print(f\"{num_col} : {diabetes_data[num_col].nunique()} unique values(s)\")","3976ee7d":"# Get the features and label form our data\nfeatures, label = diabetes_data.drop(columns=[\"class\"]), diabetes_data[\"class\"] \nprint(f\"Shape: {diabetes_data.shape}\") # print-out the car shape\nprint(f\"N-Dimension: {diabetes_data.ndim}\") # print-out the car n-dimensional \nprint(f\"Features Shape: {features.shape}\") # print-out the features shape\nprint(f\"Features N-Dimension: {features.ndim}\") # print-out the features n-dimension\nprint(f\"Label Shape: {label.shape}\") # print-out the label shape\nprint(f\"Label N-Dimension: {label.ndim}\") # print-out the label n-dimension","29d8c315":"# Get the number of missing data points per column\nmissing_values_count = diabetes_data.isnull().sum()\n# Look at the missing points\nmissing_values_count.to_frame()","fab0e407":"# let's make a correlation matrix\nplt.figure(figsize=(24, 14))\nsns.heatmap(diabetes_data.corr(), annot=True);","56c23b12":"diabetes_data.corr()['class'].sort_values(ascending=False) # the correlation","93957a27":"# checking skewness value\n# if value lies between -0.5 to 0.5  then it is normal otherwise skewed\nskew_value = diabetes_data.skew().sort_values(ascending=False)\nskew_value","26eb6457":"# let's plot it\nplt.figure(figsize=(24, 8)) # figuring the size\n# makes count plot \nsns.countplot(x='gender', data=diabetes_data)\n# title\nplt.title('Gender', fontname='monospace', fontweight='bold', fontsize=15)\n# x-label\nplt.xlabel('Gender');","f5273aed":"plt.figure(figsize=(24, 8))\nsns.distplot(diabetes_data['age'], kde=True, color=\"black\");","0fbf4646":"from sklearn.compose import make_column_transformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\n\ndef preprocessing_data(data):\n    \"\"\"Returns Data that have been preprocessed and split\"\"\"\n    # Create a columns transformer\n    features_num = [\"polyuria\", \"age\", \"polydipsia\", \"sudden_weight_loss\", \"weakness\", \\\n                    \"polyphagia\", \"genital_thrush\", \"visual_blurring\", \"itching\", \"irritability\", \\\n                    \"delayed_healing\", \"partial_paresis\", \"muscle_stiffness\", \"alopecia\", \"obesity\"]\n    features_cat = ['gender']\n\n    preprocessor = make_column_transformer(\n        (StandardScaler(), features_num),\n        (OneHotEncoder(), features_cat),\n    )\n    \n    # Create X & y (features and label)\n    X = data.drop(columns=[\"class\"])\n    y = data[\"class\"]\n    \n    # Build our train and test sets\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    \n    # Fit the columns transformer to our training data\n    preprocessor.fit(X_train)\n    \n    # Transform training and test data with normalization (MinMaxScaler) and encoder (OneHotEncoder, LabelEncoder)\n    X_train_normal = preprocessor.transform(X_train)\n    X_test_normal = preprocessor.transform(X_test)\n    \n    # X_train and X_test (features)\n    X_train, X_test = tf.constant(X_train_normal), tf.constant(X_test_normal)\n    \n    # y_train and y_test (label)\n    y_train, y_test = tf.constant(y_train), tf.constant(y_test)\n    \n    return X_train, X_test, y_train, y_test\n\n# Call the function\nX_train, X_test, y_train, y_test = preprocessing_data(diabetes_data)\ninput_shape = [X_train.shape[1]]\nprint(\"Input shape: {}\".format(input_shape))","ed65579d":"# Checking the shape and dimension of rows and columns (features)\nX_train.shape, X_test.shape, X_train.ndim, X_test.ndim","947f5d10":"# Checking the shape and dimension of rows and columns (label)\ny_train.shape, y_test.shape, y_train.ndim, y_test.ndim","b687ec8c":"# Checking the type (features and label)\nX_train.dtype, X_test.dtype, y_train.dtype, y_test.dtype","250913ad":"# Checking the len (feature and label)\nlen(X_train), len(X_test), len(y_train), len(y_test)","2b89d004":"# Set the random seed\ntf.random.set_seed(42)\n\ndef model():\n    # Create the model\n    model = tf.keras.Sequential([\n        tf.keras.layers.Dense(128, activation=\"relu\", input_shape=input_shape, name=\"input_1\"),\n        tf.keras.layers.Dropout(rate=0.3),\n        tf.keras.layers.Dense(128, activation=\"relu\", name=\"input_2\"),\n        tf.keras.layers.Dropout(rate=0.3),\n        tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")\n    ], name=\"our_model\")\n\n    # Compile the model\n    model.compile(loss=tf.keras.losses.BinaryCrossentropy(), # binary since we are working with 2 clases (0 & 1)\n                    optimizer=tf.keras.optimizers.Adam(),\n                    metrics=['accuracy'])\n    \n    return model\n\nmodel = model()\n\n# Fit the model\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_test, y_test),\n    batch_size=32,\n    epochs=100,\n    verbose=1,\n)","2c2e7b60":"model.summary()","84a92b5a":"from tensorflow.keras.utils import plot_model\n\nplot_model(model=model, show_shapes=True)","0a76b70e":"pd.DataFrame(history.history).plot(figsize=(26, 8), title=\"History Curves\");","2d507c8c":"# Check kthe accuracy of our model\ny_pred = model.predict(X_test)\nloss, accuracy = model.evaluate(X_test, y_test)\nprint(f\"y_pred: {y_pred[0]}\")\nprint(f\"Model loss on the test set: {loss}\")\nprint(f\"Model accuracy on the test set: {(accuracy*100):.2f}%\")","c971d800":"# Note: the confusion matrix code we're about to ride is a remix of scikit-learn's plot confusion matrix function\nimport itertools\n\nfigsize = (10, 10)\n\n# Create the confusion matrix\ncm = confusion_matrix(y_test, tf.round(y_pred))\ncm_norm = cm.astype(\"float\") \/ cm.sum(axis=1)[:, np.newaxis] # normalize our confusion matrix\nn_classes = cm.shape[0]\n\n# Let's prettify it \nfig, ax = plt.subplots(figsize=figsize)\n# Create a matrix plot\ncax = ax.matshow(cm, cmap=plt.cm.Blues)\nfig.colorbar(cax)\n\n# Create classes\nclasses= False\n\nif classes:\n    labels = classes\nelse:\n    labels = np.arange(cm.shape[0])\n    \n# Label the axes\nax.set(\n    title='Confusion Matrix',\n    xlabel='Predicted Label',\n    ylabel='True Label',\n    xticks=np.arange(n_classes),\n    yticks=np.arange(n_classes),\n    xticklabels=labels,\n    yticklabels=labels\n)\n\n# Set x-axis labels to bottom\nax.xaxis.set_label_position(\"bottom\")\nax.xaxis.tick_bottom()\n\n# Adjust the label size \nax.yaxis.label.set_size(20)\nax.xaxis.label.set_size(20)\nax.title.set_size(20)\n\n# Set the threshold for diffenrent colors\nthreshold = (cm.max() + cm.min()) \/ 2.\n\n# Plot the text on each cell\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j] * 100:.1f}%)\",\n             horizontalalignment='center',\n             color='white' if cm[i, j] > threshold else 'black',\n             size=15);\nfig.show();","91843510":"We can see the features that associate with diabetic risk above... Let's check the skewness value","e7aefe88":"# **Read in updated DataFrame**\n\nLet's see the data and how it looks.","45e56655":"Looks good... Let's continue..","2a6d581a":"### **Check the missing value**\n\nLet's check the missing value...   \n\n> **Question:** How many missing data points do we have?\n\nLet's see how many we have in each column. ","e5215346":"*Let's get started...*\n\n# **Import Necessary Libraries**","dfed443a":"\n#### **Discrete and Continuous Variables**\nLet's have a look at Discrete and Continuous variables.","f4c27dec":"# **On Going...**","4da5eca6":"# **Target**\n\nPredict the Presence of Diabetes.","93419b1f":"#### **Next Updates will add More EDA, wait for it...**","b4f10da4":"## **History Curves**","fe6eeeaf":"# **Data Preprocessing**\n\nIn terms of scaling values, neural networks tend to prefer normalization.\n\nIf you're not sure on which to use, you could try both and see which performs better.","1beb3bc4":"### **Check the shape**\n\nLet's check the shape, n-dimension of our data, also the features and the label... It's important to check the shape and dimension of our data... ","82613cd6":"# **EDA (Explanatory Data Analysis)**\n\nIn statistics, exploratory data analysis is an approach of analyzing data sets to summarize their main characteristics, often using statistical graphics and other data visualization methods.","dcad7da7":"Hmm, great...\n\nHow bout the discrete and continuous variables? Let's have a look.","171f6231":"Looks like our model is good!","e3101180":"## **Age distribution**","bcb0c3af":"## **Gender Distribution**","624cebc8":"### **Let's plot the Confusion Matrix**","e60e8793":"# **Introduction**\n\nThank you [**Mr.Larxel**](https:\/\/www.kaggle.com\/andrewmvd) for creating this very intersting Data. Hope you're doing well as always.\n\nOkay, In this notebook, I'll create a Classification Model to predict Diabetes, and before we build our model, let me try to find some common features that associate with diabetic risk, okay, prepare your coffee, and let's get started.\n\nDon't forget to upvote if you found this notebook useful, and don't forget to give me a feedback!\n\nSorry if my english is bad.\n\n**regards,** <br>\n**Azmi**","10d32849":"Okay, great, now let's move on to Data Preprocessing...","cbe656a7":"Great! our data is not have a missing value, then let's visualize our data!","c99110ec":"## **Typical architecture of a classification neural network**\n\nThe word *typical* is on purpose.\n\nBecause the architecture of a classification neural network can widely vary depending on the problem you're working on.\n\nHowever, there are some fundamentals all deep neural networks contain:\n* An input layer.\n* Some hidden layers.\n* An output layer.\n\nMuch of the rest is up to the data analyst creating the model.\n\nThe following are some standard values you'll often use in your classification neural networks.\n\n| **Hyperparameter** | **Binary Classification** | **Multiclass classification** |\n| --- | --- | --- |\n| Input layer shape | Same as number of features (e.g. 5 for age, sex, height, weight, smoking status in heart disease prediction) | Same as binary classification |\n| Hidden layer(s) | Problem specific, minimum = 1, maximum = unlimited | Same as binary classification |\n| Neurons per hidden layer | Problem specific, generally 10 to 100 | Same as binary classification |\n| Output layer shape | 1 (one class or the other) | 1 per class (e.g. 3 for food, person or dog photo) |\n| Hidden activation | Usually [ReLU](https:\/\/www.kaggle.com\/dansbecker\/rectified-linear-units-relu-in-deep-learning) (rectified linear unit) | Same as binary classification |\n| Output activation | [Sigmoid](https:\/\/en.wikipedia.org\/wiki\/Sigmoid_function) | [Softmax](https:\/\/en.wikipedia.org\/wiki\/Softmax_function) |\n| Loss function | [Cross entropy](https:\/\/en.wikipedia.org\/wiki\/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression) ([`tf.keras.losses.BinaryCrossentropy`](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/losses\/BinaryCrossentropy) in TensorFlow) | Cross entropy ([`tf.keras.losses.CategoricalCrossentropy`](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/losses\/CategoricalCrossentropy) in TensorFlow) |\n| Optimizer | [SGD](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/optimizers\/SGD) (stochastic gradient descent), [Adam](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/optimizers\/Adam) | Same as binary classification |\n\n***Table 1:*** *Typical architecture of a classification network.* ***Source:*** *Adapted from page 295 of [Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow Book by Aur\u00e9lien G\u00e9ron](https:\/\/www.oreilly.com\/library\/view\/hands-on-machine-learning\/9781492032632\/)*","0613cc82":"# **About this Dataset**\n\nDiabetes is one of the fastest growing chronic life threatening diseases that have already affected $422$ million people worldwide according to the report of World Health Organization (WHO), in $2018$. Due to the presence of a relatively long asymptomatic phase, early detection of diabetes is always desired for a clinically meaningful outcome. Around $50$% of all people suffering from diabetes are undiagnosed because of its long-term asymptomatic phase.\n\nThis dataset contains $520$ observations with $17$ characteristics, collected using direct questionnaires and diagnosis results from the patients in the Sylhet Diabetes Hospital in Sylhet, Bangladesh.\n\n**Data from:**\n\nIslam M.M.F., Ferdousi R., Rahman S., Bushra H.Y. ($2020$) Likelihood Prediction of Diabetes at Early Stage Using Data Mining Techniques. In: Gupta M., Konar D., Bhattacharyya S., Biswas S. (eds) Computer Vision and Machine Intelligence in Medical Image Analysis. Advances in Intelligent Systems and Computing, vol $992$. Springer, Singapore. https:\/\/doi.org\/10.1007\/978-981-13-8798-2_12","54d2e9b9":"# **Let's Check our data**\n\nLet's check our data before we move on to the preprocessing steps...","4acddbeb":"# **Let's Evaluate it**","1d658873":"Looks like our model is good! let's see its Architecture...","ce968d1d":"Okay great! ","f02d8d95":"### **Uniqueness Categorical Variables**\nLet's have a look at categorical variables. How many unique values of these variables.","c04e3ff7":"Okay, the most distribution is Male...","f04f5cc8":"# **Okay, Let's build the Model**\n\n## Steps in modelling\n\nNow we know what data we have as well as the input and output shapes, let's see how we'd build a neural network to model it.\n\nIn TensorFlow, there are typically 3 fundamental steps to creating and training a model.\n\n1. **Creating a model** - piece together the layers of a neural network yourself (using the [functional](https:\/\/www.tensorflow.org\/guide\/keras\/functional) or [sequential API](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/Sequential)) or import a previously built model (known as transfer learning).\n2. **Compiling a model** - defining how a model's performance should be measured (loss\/metrics) as well as defining how it should improve (optimizer). \n3. **Fitting a model** - letting the model try to find patterns in the data (how does `X` get to `y`). \n\nLet's see these in action using the Sequential API to build a model for our regression data. And then we'll step through each."}}