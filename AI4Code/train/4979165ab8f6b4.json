{"cell_type":{"3dabf8e0":"code","410270ba":"code","37e3b23d":"code","a75cc0e4":"code","972c4a18":"code","de3c06a5":"code","cd52dac3":"code","9fe585fb":"code","f9af7da7":"code","3a69d24b":"code","5ed674b3":"code","4b2a0664":"code","4e499b7b":"code","7f24f9f0":"code","52090ca5":"code","c503730a":"code","5a3fb10f":"code","83f1d4cc":"code","0f22eb70":"code","f97e86f4":"code","60c1228b":"code","cfd63ca8":"code","c2d591f6":"code","587195d5":"code","f9a8266f":"code","f6baa0cf":"code","3df837f5":"markdown","dccfd371":"markdown","6ddaeb19":"markdown","c177960c":"markdown","c5fb02b9":"markdown","3e79898a":"markdown","869532e2":"markdown","bb34551c":"markdown","eeb9be29":"markdown","b3fb1c7e":"markdown","60d2f96c":"markdown","c7637e94":"markdown","3b0b93d8":"markdown","b3ce5d02":"markdown","6d06d107":"markdown","61658e8c":"markdown","e89931be":"markdown","e2769215":"markdown","8f0b33d9":"markdown","2dfbb93d":"markdown","86442293":"markdown","be566882":"markdown","5f26db12":"markdown","24db3972":"markdown","35485801":"markdown","3fca29b9":"markdown","6b26b020":"markdown","2a7d1406":"markdown","055ac2d4":"markdown","8b330ca5":"markdown","3dccdefa":"markdown","f03b4bb0":"markdown","4d0000af":"markdown","96c7084e":"markdown","c55e49ae":"markdown","7ab68fe5":"markdown","3cf83b67":"markdown","6ac3ec49":"markdown","1376b8bd":"markdown","9b90f441":"markdown","46511cc9":"markdown","7a9e7cc7":"markdown","829f01db":"markdown","b9a8f2db":"markdown","c0492950":"markdown","589ca9ea":"markdown","b174e049":"markdown","6d08b26d":"markdown"},"source":{"3dabf8e0":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\nfrom keras import layers\nfrom keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, Add\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout,GlobalMaxPooling2D, GlobalAveragePooling2D\nfrom keras.models import Model, Sequential\nfrom keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\nfrom keras.initializers import glorot_uniform\nfrom keras.optimizers import RMSprop\nimport keras.backend as K\nK.set_image_data_format(\"channels_last\")\nimport time\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom keras.preprocessing.image import ImageDataGenerator","410270ba":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/sample_submission.csv\")","37e3b23d":"label = np.array(train.label)\ndata = np.array(train.drop([\"label\"], axis=1))\n \n# Normalization and one hot\nX = data.reshape((42000, 28, 28, 1))\nX = X \/ 255\nenc = OneHotEncoder()\nY = enc.fit_transform(label.reshape((42000, 1))).toarray()\ntrain_x, val_x, train_y, val_y = train_test_split(X, Y, test_size=0.1, random_state=0)\n \n# Normalizetion\ntest_data = np.array(test)\ntest_data = test_data.reshape((28000, 28, 28, 1))\ntest_data = test_data \/ 255\n \n# Take a look at the data at will\nindex = 25351\nplt.imshow(data.reshape((42000, 28, 28))[index])\nlabel[index]","a75cc0e4":"datagen = ImageDataGenerator(featurewise_center=False, samplewise_center=False, featurewise_std_normalization=False, samplewise_std_normalization=False, zca_whitening=False, rotation_range=10, zoom_range=0.1, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=False, vertical_flip=False)\ndatagen.fit(train_x)","972c4a18":"model = [0] * 8\nfor j in range(0, 8):\n    model[j] = Sequential()\n    model[j].add(Conv2D(2 ** (j + 1), kernel_size=2, activation='relu', input_shape=(28,28,1)))\n    model[j].add(Flatten())\n    model[j].add(Dense(256, activation=\"relu\"))\n    model[j].add(Dense(10, activation='softmax'))\n    model[j].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    print(\"---------------------------------------------------------------------------------------------\")\n    print(str(2 ** (j + 1)) + \"\u4e2afilters:\")\n    start = time.time()\n    model[j].fit_generator(datagen.flow(train_x, train_y, batch_size=64), validation_data=(val_x, val_y), epochs=1, steps_per_epoch= len(train_x) \/\/ 64)\n    end = time.time()\n    print(str(end - start) + \"\u79d2\")\n    print(\"---------------------------------------------------------------------------------------------\")","de3c06a5":"model = [0] * 6\nfor j in range(6):\n    model[j] = Sequential()\n    model[j].add(Conv2D(32, kernel_size=2 + j, activation='relu', input_shape=(28,28,1)))\n    model[j].add(Flatten())\n    model[j].add(Dense(256, activation=\"relu\"))\n    model[j].add(Dense(10, activation='softmax'))\n    model[j].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    print(\"---------------------------------------------------------------------------------------------\")\n    print(\"\u8fc7\u6ee4\u5668\u5927\u5c0f\uff1a\" + str(2 + j))\n    start = time.time()\n    model[j].fit_generator(datagen.flow(train_x, train_y, batch_size=64), validation_data=(val_x, val_y), epochs=1, steps_per_epoch= len(train_x) \/\/ 64)\n    end = time.time()\n    print(str(end - start) + \"\u79d2\")\n    print(\"---------------------------------------------------------------------------------------------\")","cd52dac3":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation=\"relu\"))\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\nprint(\"---------------------------------------------------------------------------------------------\")\nprint(\"same\uff1a\")\nstart = time.time()\nmodel.fit_generator(datagen.flow(train_x, train_y, batch_size=64), validation_data=(val_x, val_y), epochs=20, steps_per_epoch= len(train_x) \/\/ 64)\nend = time.time()\nprint(str(end - start) + \"\u79d2\")\nprint(\"---------------------------------------------------------------------------------------------\")\n \nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=5, padding=\"valid\", activation='relu', input_shape=(28,28,1)))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation=\"relu\"))\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\nprint(\"---------------------------------------------------------------------------------------------\")\nprint(\"same\uff1a\")\nstart = time.time()\nmodel.fit_generator(datagen.flow(train_x, train_y, batch_size=64), validation_data=(val_x, val_y), epochs=1, steps_per_epoch= len(train_x) \/\/ 64)\nend = time.time()\nprint(str(end - start) + \"\u79d2\")\nprint(\"---------------------------------------------------------------------------------------------\")","9fe585fb":"model = [0] * 5\nfor j in range(5):\n    model[j] = Sequential()\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    \n    if j > 0:\n        model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    if j > 1:\n        model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    if j > 2:\n        model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    if j > 3:\n        model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    \n    model[j].add(Flatten())\n    model[j].add(Dense(256, activation=\"relu\"))\n    model[j].add(Dense(10, activation='softmax'))\n    model[j].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    print(\"---------------------------------------------------------------------------------------------\")\n    print(\"\u5377\u79ef\u5c42\u5c42\u6570\uff1a\" + str(1 + j))\n    start = time.time()\n    model[j].fit_generator(datagen.flow(train_x, train_y, batch_size=64), validation_data=(val_x, val_y), epochs=1, steps_per_epoch= len(train_x) \/\/ 64)\n    end = time.time()\n    print(str(end - start) + \"\u79d2\")\n    print(\"---------------------------------------------------------------------------------------------\")","f9af7da7":"model = [0] * 5\nfor j in range(5):\n    model[j] = Sequential()\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=j+2))\n    model[j].add(Flatten())\n    model[j].add(Dense(256, activation=\"relu\"))\n    model[j].add(Dense(10, activation='softmax'))\n    model[j].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    print(\"---------------------------------------------------------------------------------------------\")\n    print(\"\u6c60\u5316\u5927\u5c0f\uff1a\" + str(2 + j))\n    start = time.time()\n    model[j].fit_generator(datagen.flow(train_x, train_y, batch_size=64), validation_data=(val_x, val_y), epochs=1, steps_per_epoch= len(train_x) \/\/ 64)\n    end = time.time()\n    print(str(end - start) + \"\u79d2\")\n    print(\"---------------------------------------------------------------------------------------------\")","3a69d24b":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\nmodel.add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\nmodel.add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\nmodel.add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\nmodel.add(MaxPooling2D(pool_size=3, padding=\"same\"))\nmodel.add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\nmodel.add(MaxPooling2D(pool_size=3))\n \nmodel.add(Flatten())\nmodel.add(Dense(256, activation=\"relu\"))\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\nprint(\"---------------------------------------------------------------------------------------------\")\nprint(\"\u6700\u540e\u4e24\u5c42\u6c60\u5316\uff1a\")\nstart = time.time()\nmodel.fit_generator(datagen.flow(train_x, train_y, batch_size=64), validation_data=(val_x, val_y), epochs=1, steps_per_epoch= len(train_x) \/\/ 64)\nend = time.time()\nprint(str(end - start) + \"\u79d2\")\nprint(\"---------------------------------------------------------------------------------------------\")","5ed674b3":"model = [0] * 2\nfor j in range(2):\n    model[j] = Sequential()\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    \n    if j > 0:\n        model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n        model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n        model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n        model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n        model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n        model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n        model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    \n    model[j].add(Flatten())\n    model[j].add(Dense(256, activation=\"relu\"))\n    model[j].add(Dense(10, activation='softmax'))\n    model[j].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    print(\"---------------------------------------------------------------------------------------------\")\n    print(\"\u6a21\u5757\u5c42\u6570\uff1a\" + str(1 + j))\n    start = time.time()\n    model[j].fit_generator(datagen.flow(train_x, train_y, batch_size=64), validation_data=(val_x, val_y), epochs=1, steps_per_epoch= len(train_x) \/\/ 64)\n    end = time.time()\n    print(str(end - start) + \"\u79d2\")\n    print(\"---------------------------------------------------------------------------------------------\")","4b2a0664":"model = [0] * 2\nfor j in range(2):\n    model[j] = Sequential()\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    \n    model[j].add(Conv2D(32 * 2 ** (j + 1), kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(32 * 2 ** (j + 1), kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(32 * 2 ** (j + 1), kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(32 * 2 ** (j + 1), kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    model[j].add(Conv2D(32 * 2 ** j, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    \n    model[j].add(Flatten())\n    model[j].add(Dense(256, activation=\"relu\"))\n    model[j].add(Dense(10, activation='softmax'))\n    model[j].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    print(\"---------------------------------------------------------------------------------------------\")\n    print(\"\u65b0\u6a21\u5757filters\u6570\uff1a\" + str(32 * 2 ** (j + 1)))\n    start = time.time()\n    model[j].fit_generator(datagen.flow(train_x, train_y, batch_size=64), validation_data=(val_x, val_y), epochs=1, steps_per_epoch= len(train_x) \/\/ 64)\n    end = time.time()\n    print(str(end - start) + \"\u79d2\")\n    print(\"---------------------------------------------------------------------------------------------\")","4e499b7b":"model = [0] * 6\nfor j in range(6):\n    model[j] = Sequential()\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    \n    model[j].add(Conv2D(64, kernel_size=2 + j, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(64, kernel_size=2 + j, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(64, kernel_size=2 + j, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(64, kernel_size=2 + j, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    model[j].add(Conv2D(64, kernel_size=2 + j, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    \n    model[j].add(Flatten())\n    model[j].add(Dense(256, activation=\"relu\"))\n    model[j].add(Dense(10, activation='softmax'))\n    model[j].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    print(\"---------------------------------------------------------------------------------------------\")\n    print(\"\u65b0\u6a21\u5757\u8fc7\u6ee4\u5668\u5927\u5c0f\uff1a\" + str(2 + j))\n    start = time.time()\n    model[j].fit_generator(datagen.flow(train_x, train_y, batch_size=64), validation_data=(val_x, val_y), epochs=1, steps_per_epoch= len(train_x) \/\/ 64)\n    end = time.time()\n    print(str(end - start) + \"\u79d2\")\n    print(\"---------------------------------------------------------------------------------------------\")","7f24f9f0":"model = [0] * 5\nfor j in range(5):\n    model[j] = Sequential()\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    \n    model[j].add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=2 + j, padding=\"same\"))\n    model[j].add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=2 + j, padding=\"same\"))\n    \n    model[j].add(Flatten())\n    model[j].add(Dense(256, activation=\"relu\"))\n    model[j].add(Dense(10, activation='softmax'))\n    model[j].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    print(\"---------------------------------------------------------------------------------------------\")\n    print(\"\u65b0\u6a21\u5757\u6c60\u5316\u5927\u5c0f\uff1a\" + str(2 + j))\n    start = time.time()\n    model[j].fit_generator(datagen.flow(train_x, train_y, batch_size=64), validation_data=(val_x, val_y), epochs=1, steps_per_epoch= len(train_x) \/\/ 64)\n    end = time.time()\n    print(str(end - start) + \"\u79d2\")\n    print(\"---------------------------------------------------------------------------------------------\")","52090ca5":"model = [0] * 7\nfor j in range(7):\n    model[j] = Sequential()\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    if j == 0 or j == 3 or j == 4 or j == 6:\n        model[j].add(Dropout(0.1))\n    \n    model[j].add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    model[j].add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    if j == 1 or j == 3 or j == 5 or j == 6:\n        model[j].add(Dropout(0.1))\n    \n    model[j].add(Flatten())\n    model[j].add(Dense(256, activation=\"relu\"))\n    \n    if j == 2 or j == 4 or j == 5 or j == 6:\n        model[j].add(Dropout(0.1))\n    \n    model[j].add(Dense(10, activation='softmax'))\n    model[j].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    print(\"---------------------------------------------------------------------------------------------\")\n    print(\"\u6dfb\u52a0dropout\u7684\u65b9\u5f0f\uff1a\" + str(j))\n    start = time.time()\n    model[j].fit_generator(datagen.flow(train_x, train_y, batch_size=64), validation_data=(val_x, val_y), epochs=1, steps_per_epoch= len(train_x) \/\/ 64)\n    end = time.time()\n    print(str(end - start) + \"\u79d2\")\n    print(\"---------------------------------------------------------------------------------------------\")","c503730a":"model = [0] * 7\nfor j in range(7):\n    model[j] = Sequential()\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    \n    model[j].add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    model[j].add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    \n    model[j].add(Dropout(0.1 * (j + 1)))\n    \n    model[j].add(Flatten())\n    model[j].add(Dense(256, activation=\"relu\"))\n    \n    model[j].add(Dropout(0.1))\n    \n    model[j].add(Dense(10, activation='softmax'))\n    model[j].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    print(\"---------------------------------------------------------------------------------------------\")\n    print(\"\u7b2c\u4e00\u4e2adropout\u7684\u53c2\u6570\uff1a\" + str(0.1 * (j + 1)))\n    start = time.time()\n    model[j].fit_generator(datagen.flow(train_x, train_y, batch_size=64), validation_data=(val_x, val_y), epochs=1, steps_per_epoch= len(train_x) \/\/ 64)\n    end = time.time()\n    print(str(end - start) + \"\u79d2\")\n    print(\"---------------------------------------------------------------------------------------------\")","5a3fb10f":"model = [0] * 6\nfor j in range(6):\n    model[j] = Sequential()\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    model[j].add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    \n    model[j].add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    model[j].add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', input_shape=(28,28,1)))\n    model[j].add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    \n    model[j].add(Dropout(0.4))\n    \n    model[j].add(Flatten())\n    model[j].add(Dense(256, activation=\"relu\"))\n    \n    model[j].add(Dropout(0.2 + j * 0.1))\n    \n    model[j].add(Dense(10, activation='softmax'))\n    model[j].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    print(\"---------------------------------------------------------------------------------------------\")\n    print(\"\u7b2c\u4e8c\u4e2adropout\u7684\u53c2\u6570\uff1a\" + str(0.1 * (j + 2)))\n    start = time.time()\n    model[j].fit_generator(datagen.flow(train_x, train_y, batch_size=64), validation_data=(val_x, val_y), epochs=1, steps_per_epoch= len(train_x) \/\/ 64)\n    end = time.time()\n    print(str(end - start) + \"\u79d2\")\n    print(\"---------------------------------------------------------------------------------------------\")","83f1d4cc":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', kernel_initializer=glorot_uniform(seed=0), input_shape=(28,28,1)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', kernel_initializer=glorot_uniform(seed=0)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', kernel_initializer=glorot_uniform(seed=0)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', kernel_initializer=glorot_uniform(seed=0)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(MaxPooling2D(pool_size=3, padding=\"same\"))\nmodel.add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', kernel_initializer=glorot_uniform(seed=0)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    \nmodel.add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', kernel_initializer=glorot_uniform(seed=0)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', kernel_initializer=glorot_uniform(seed=0)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', kernel_initializer=glorot_uniform(seed=0)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', kernel_initializer=glorot_uniform(seed=0)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(MaxPooling2D(pool_size=3, padding=\"same\"))\nmodel.add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', kernel_initializer=glorot_uniform(seed=0)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    \nmodel.add(Dropout(0.4))\n    \nmodel.add(Flatten())\nmodel.add(Dense(256, activation=\"relu\", kernel_initializer=glorot_uniform(seed=0)))\n    \nmodel.add(Dropout(0.5))\n    \nmodel.add(Dense(10, activation='softmax', kernel_initializer=glorot_uniform(seed=0)))\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\nprint(\"---------------------------------------------------------------------------------------------\")\nprint(\"\u52a0BN\uff1a\")\nstart = time.time()\nmodel.fit_generator(datagen.flow(train_x, train_y, batch_size=64), validation_data=(val_x, val_y), epochs=1, steps_per_epoch= len(train_x) \/\/ 64)\nend = time.time()\nprint(str(end - start) + \"\u79d2\")\nprint(\"---------------------------------------------------------------------------------------------\")","0f22eb70":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', kernel_initializer=glorot_uniform(seed=0), input_shape=(28,28,1)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', kernel_initializer=glorot_uniform(seed=0)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', kernel_initializer=glorot_uniform(seed=0)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', kernel_initializer=glorot_uniform(seed=0)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(MaxPooling2D(pool_size=3, padding=\"same\"))\nmodel.add(Conv2D(32, kernel_size=5, padding=\"same\", activation='relu', kernel_initializer=glorot_uniform(seed=0)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    \nmodel.add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', kernel_initializer=glorot_uniform(seed=0)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', kernel_initializer=glorot_uniform(seed=0)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', kernel_initializer=glorot_uniform(seed=0)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', kernel_initializer=glorot_uniform(seed=0)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(MaxPooling2D(pool_size=3, padding=\"same\"))\nmodel.add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', kernel_initializer=glorot_uniform(seed=0)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(MaxPooling2D(pool_size=3, padding=\"same\"))\n    \nmodel.add(Dropout(0.4))\n    \nmodel.add(Flatten())\nmodel.add(Dense(256, activation=\"relu\", kernel_initializer=glorot_uniform(seed=0)))\n    \nmodel.add(Dropout(0.5))\n    \nmodel.add(Dense(10, activation='softmax', kernel_initializer=glorot_uniform(seed=0)))","f97e86f4":"model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","60c1228b":"print(\"---------------------------------------------------------------------------------------------\")\nstart = time.time()\nmodel.fit_generator(datagen.flow(train_x, train_y, batch_size=64), validation_data=(val_x, val_y), epochs=1, steps_per_epoch= len(train_x) \/\/ 64)\nend = time.time()\nprint(str(end - start) + \"\u79d2\")\nprint(\"---------------------------------------------------------------------------------------------\")","cfd63ca8":"predict = np.argmax(model.predict(test_data), axis=1)\n \nsample_submission[\"Label\"] = predict\nsample_submission.to_csv(\"1.csv\", index=False)","c2d591f6":"model.save_weights(\"my_model_weights_614_1.h5\")\n \nmodel.load_weights(\"my_model_weights_614_1.h5\")","587195d5":"model.load_weights(\"my_model_weights_600_2.h5\")\npredict_600_2 = np.argmax(model.predict(test_data), axis=1)\n \nmodel.load_weights(\"my_model_weights_628_2.h5\")\npredict_628_2 = np.argmax(model.predict(test_data), axis=1)\n \nmodel.load_weights(\"my_model_weights_642_2.h5\")\npredict_642_2 = np.argmax(model.predict(test_data), axis=1)","f9a8266f":"def combine_model(predict1, predict2, predict3):\n    not_equal_index = np.unique(np.hstack((np.where(predict1 != predict2)[0], np.where(predict1 != predict3)[0], np.where(predict2 != predict3)[0])))\n    predict = np.copy(predict1)\n    for i in not_equal_index:\n        if (predict2[i] == predict3[i]) and (predict2[i] != predict1[i]):\n            predict[i] = predict2[i]\n    return predict","f6baa0cf":"sample_submission[\"Label\"] = combine_model(predict_642_2, predict_600_2, predict_628_2)\nsample_submission.to_csv(\"1.csv\", index=False)","3df837f5":"3, 4, 5, 6, 7 all look good, **I chose 5** to continue to build.","dccfd371":"*Selection of kernel_size parameters for convolution layer of New Module*","6ddaeb19":"*Padding parameter selection*","c177960c":"If you are Chinese, you can check out my [blog](https:\/\/blog.csdn.net\/qq_33758867\/article\/details\/90047240).","c5fb02b9":"***Choose how to add pool layer***, starting with the last convolution layer, and adding a pool layer up to each convolution layer. The result of training observation is that the pool layer is added after the last convolution layer, or the pool layer is added after the countdown first and second convolution layer. **I chose to add the pooling layer to the bottom one or two layers, that is, the last two layers**.","3e79898a":"*3. train*","869532e2":"Perform rotation on the picture, move up and down left and right, and other operations to increase the amount of data. **Data augmentation is very effective**. Parameters such as **rotation_range, zoom_range, width_shift_range, and height_shift_range can be modified**. The following parameters are the version used by most people, but you can also explore parameters that are more effective for your own model.","bb34551c":"*5. Save model weights and load model weights*","eeb9be29":"**Usually after 80 epochs of training, there will be some models that can make the score reach 0.996 +. These models can help us raise the score to 0.997+. I have obtained some excellent models. You can save the weights of these models.**","b3fb1c7e":"Weights file can be downloaded from [here](https:\/\/pan.baidu.com\/s\/1T31ToVXSC7KWsSdcBjYkgQ%C2%A0#list\/path=%2F), extraction code: **ltu5**","60d2f96c":"Decided to use **5 layers of convolution, pool_size=3** continues to build.","c7637e94":"Still use **3**.","3b0b93d8":"**In this way, I can get a score of 0.99728, which should be top10%. Of course, by combining different models, I may be able to achieve a higher score. I have a maximum score of 0.99785 through a variety of combinations. Those who are interested can continue to explore higher scores.**","b3ce5d02":"*Select the parameters of the first dropout*, dropout parameter selection training using the loop may encounter some problems, you can manually modify the parameter values training observation.","6d06d107":"*Select the first layer kernel_size parameter*","61658e8c":"0.2, 0.5 is better, **choose 0.5**","e89931be":"*First select the first layer filters parameter*","e2769215":"*Voting function*, did not find the kind of direct vote on the forecast, I do not know if there is, I wrote one of my own.","8f0b33d9":"2, 3, 4 all look good.","2dfbb93d":"Choose the fifth way to add, that is, **add droupout after the second and third modules**","86442293":"**Data preprocessing**","be566882":"In digit recognizer, I initially learned to construct my own CNN model step by step, and finally used multi-model voting to get a good score. This article has a lot of training, and my GPU is not very good, 1050ti, which takes a lot of time. It is recommended that no GPU students do not train, you can take a look, then use the final model and the weight file I provided.","5f26db12":"**Build your own CNN step by step**. For the convenience of commit, all steps are trained for only one epoch. To achieve good results, you should train at least 20 epochs.","24db3972":"*load weight and Prediction*","35485801":"*Combine predict*","3fca29b9":"Similarly, there are many ways to *add batch normalization*,. You can add BN, to each convolution layer, or you can add some without adding some. I tried some ways, and the results were all good. Finally, **I chose to add BN to each convolution layer. This is also my final choice of the model**. Of course, the selection of full connection parameters and other operations also can be done, but after training observation found that the current model has a good effect, the subsequent attempt is no longer need, you can try it yourself.","6b26b020":"**Data augmentation**","2a7d1406":"With the two convolution pooling modules of the current model and the final fully connected module, a total of three modules are *selected to add dropout*. Each module is added separately, three modules are added, and any two modules are added in a total of 7 ways.","055ac2d4":"*Pool_size Parameter selection of New Module pool layer*","8b330ca5":"**Same seems a little better**, but it doesn't make much difference.","3dccdefa":"*2. Model compilation*","f03b4bb0":"3, 4, 5 are optional.","4d0000af":"*1. Final model*","96c7084e":"It feels like 3, 4, 5, 6 are all the same, **continue to use 5**","c55e49ae":"**Model training**","7ab68fe5":"**Choose 64**","3cf83b67":"0.1, 0.4, 0.5, 0.6, 0.7 all seem good, **choose 0.4**","6ac3ec49":"**Load Data**","1376b8bd":"Observe the cross-validation score of the training output and select the better parameters. My result was 32 or 64, and **I chose 32** to continue building.","9b90f441":"**Module Imports**","46511cc9":"A module count of **2** appears to be valid.","7a9e7cc7":"*Selection of filter parameters for convolution layer of New Module*","829f01db":"*Select pooling layer pool_size parameter*","b9a8f2db":"*4. predict and submit*","c0492950":"*Select the parameters for the second dropout*","589ca9ea":"**The model combination, using the simple voting method, using the model prediction of three scores of 0.996 +, basically can get the score of 0.997 +. Now take a model combination with a final score of 0.99728 as an example.**","b174e049":"*Select the number of convolution layers*","6d08b26d":"Based on the model that has been built, that is, the five layers of convolution layer plus the last two layers are pooled into a module, and *the number of modules required is selected*."}}