{"cell_type":{"6c46631c":"code","751c7808":"code","11a45fbb":"code","34c870e3":"code","f10d8b35":"code","368122c5":"code","856971f1":"code","1e2ce816":"code","75e7f83c":"code","22457beb":"code","aabbda5e":"code","62e3f1e2":"code","d10a8fde":"code","dc372fac":"code","c143da8d":"code","d7202d28":"code","2f38ed9e":"code","aaf8b4a5":"code","cf90c5b6":"code","de05b8ff":"code","e4e167ed":"code","cef66a14":"code","10c229f4":"code","0f6a256e":"code","1bd3a301":"code","c8b9b094":"code","15122949":"code","f664394c":"code","39c6194c":"markdown","06ea6801":"markdown","a220e7d1":"markdown","2921309d":"markdown","889e7b68":"markdown","b20395ea":"markdown","0f680c70":"markdown","ac1b1f96":"markdown","7ad7e277":"markdown","d898ff3f":"markdown","3a536068":"markdown","f5997b41":"markdown","97b4f9e6":"markdown","169ee043":"markdown","3acd506d":"markdown","22133963":"markdown","7310988f":"markdown","f5ade6d9":"markdown","7cb54b1e":"markdown","c60e16a7":"markdown","04c08610":"markdown","6334a3a7":"markdown","2217ef4e":"markdown","cc7a06dc":"markdown","36f3d2c3":"markdown","6b65afb8":"markdown","392f6b45":"markdown"},"source":{"6c46631c":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\nimport warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\ndf = pd.read_csv('\/kaggle\/input\/fivethirtyeight-candy-power-ranking-dataset\/candy-data.csv', index_col = 'competitorname')\n#df.sort_values('winpercent',ascending=False).head()\ndf.dropna(inplace = True)\ndf.head()","751c7808":"taste_features = ['chocolate', 'fruity', 'caramel', 'peanutyalmondy']\nphys_features = ['nougat', 'crispedricewafer', 'hard', 'bar', 'pluribus']","11a45fbb":"#ingredient correlation:\nplt.figure(figsize = (20,8))        \nsns.heatmap(df.loc[:,taste_features].corr(),annot=True, cmap = 'coolwarm')","34c870e3":"#physical property correlation:\nplt.figure(figsize = (20,8))        \nsns.heatmap(df.loc[:,phys_features].corr(),annot=True, cmap = 'coolwarm')","f10d8b35":"#physical property correlation:\nf, ax = plt.subplots(2,2, figsize = (16,10))\nfeature = \"chocolate\"\nsns.heatmap(df.loc[df[feature]==1,['sugarpercent', 'pricepercent', 'winpercent']].corr(),annot=True, cmap = 'coolwarm', ax=ax[0,0])\nsns.heatmap(df.loc[df[feature]==0,['sugarpercent', 'pricepercent', 'winpercent']].corr(),annot=True, cmap = 'coolwarm', ax=ax[0,1])    \nax[0,0].set_title(feature + \" = 1\")\nax[0,0].set_ylim([0,3])\nax[0,1].set_title(feature + \" = 0\")  \nax[0,1].set_ylim([0,3])\n\nsns.regplot(x=\"sugarpercent\", y=\"winpercent\",\n               truncate=True, data=df[df[feature]==1], ax = ax[1,0], label = \"with \"+feature, color = 'green')\nsns.regplot(x=\"sugarpercent\", y=\"winpercent\",\n               truncate=True, data=df[df[feature]==0], ax = ax[1,0], label = \"without \"+feature, color = 'red')\n#ax[1,0].set_title(cat)\n\nsns.regplot(x=\"pricepercent\", y=\"winpercent\",\n               truncate=True, data=df[df[feature]==1], ax = ax[1,1], label = \"with \"+feature, color = 'green')\nsns.regplot(x=\"pricepercent\", y=\"winpercent\",\n               truncate=True, data=df[df[feature]==0], ax = ax[1,1], label = \"without \"+feature, color = 'red')\nplt.legend()\nplt.show()\n\n#plt.tight_layout()    ","368122c5":"#physical property correlation:\nf, ax = plt.subplots(2,2, figsize = (16,10))\nfeature = \"fruity\"\nsns.heatmap(df.loc[df[feature]==1,['sugarpercent', 'pricepercent', 'winpercent']].corr(),annot=True, cmap = 'coolwarm', ax=ax[0,0])\nsns.heatmap(df.loc[df[feature]==0,['sugarpercent', 'pricepercent', 'winpercent']].corr(),annot=True, cmap = 'coolwarm', ax=ax[0,1])    \nax[0,0].set_title(feature + \" = 1\")\nax[0,0].set_ylim([0,3])\nax[0,1].set_title(feature + \" = 0\")  \nax[0,1].set_ylim([0,3])\n\nsns.regplot(x=\"sugarpercent\", y=\"winpercent\",\n               truncate=True, data=df[df[feature]==1], ax = ax[1,0], label = \"with \"+feature, color = 'green')\nsns.regplot(x=\"sugarpercent\", y=\"winpercent\",\n               truncate=True, data=df[df[feature]==0], ax = ax[1,0], label = \"without \"+feature, color = 'red')\n#ax[1,0].set_title(cat)\n\nsns.regplot(x=\"pricepercent\", y=\"winpercent\",\n               truncate=True, data=df[df[feature]==1], ax = ax[1,1], label = \"with \"+feature, color = 'green')\nsns.regplot(x=\"pricepercent\", y=\"winpercent\",\n               truncate=True, data=df[df[feature]==0], ax = ax[1,1], label = \"without \"+feature, color = 'red')\nplt.legend()\nplt.show()\n\n#plt.tight_layout()    ","856971f1":"#physical property correlation:\nf, ax = plt.subplots(2,2, figsize = (16,10))\nfeature = \"peanutyalmondy\"\nsns.heatmap(df.loc[df[feature]==1,['sugarpercent', 'pricepercent', 'winpercent']].corr(),annot=True, cmap = 'coolwarm', ax=ax[0,0])\nsns.heatmap(df.loc[df[feature]==0,['sugarpercent', 'pricepercent', 'winpercent']].corr(),annot=True, cmap = 'coolwarm', ax=ax[0,1])    \nax[0,0].set_title(feature + \" = 1\")\nax[0,0].set_ylim([0,3])\nax[0,1].set_title(feature + \" = 0\")  \nax[0,1].set_ylim([0,3])\n\nsns.regplot(x=\"sugarpercent\", y=\"winpercent\",\n               truncate=True, data=df[df[feature]==1], ax = ax[1,0], label = \"with \"+feature, color = 'green')\nsns.regplot(x=\"sugarpercent\", y=\"winpercent\",\n               truncate=True, data=df[df[feature]==0], ax = ax[1,0], label = \"without \"+feature, color = 'red')\n#ax[1,0].set_title(cat)\n\nsns.regplot(x=\"pricepercent\", y=\"winpercent\",\n               truncate=True, data=df[df[feature]==1], ax = ax[1,1], label = \"with \"+feature, color = 'green')\nsns.regplot(x=\"pricepercent\", y=\"winpercent\",\n               truncate=True, data=df[df[feature]==0], ax = ax[1,1], label = \"without \"+feature, color = 'red')\nplt.legend()\nplt.show()\n\n#plt.tight_layout()    ","1e2ce816":"import numpy as np\ndef correlation_ratio(categories, measurements):\n    fcat, _ = pd.factorize(categories)\n    cat_num = np.max(fcat)+1\n    y_avg_array = np.zeros(cat_num)\n    n_array = np.zeros(cat_num)\n    for i in range(0,cat_num):\n        cat_measures = measurements[np.argwhere(fcat == i).flatten()]\n        n_array[i] = len(cat_measures)\n        y_avg_array[i] = np.average(cat_measures)\n    y_total_avg = np.sum(np.multiply(y_avg_array,n_array))\/np.sum(n_array)\n    numerator = np.sum(np.multiply(n_array,np.power(np.subtract(y_avg_array,y_total_avg),2)))\n    denominator = np.sum(np.power(np.subtract(measurements,y_total_avg),2))\n    if numerator == 0:\n        eta = 0.0\n    else:\n        eta = np.sqrt(numerator\/denominator)\n    return eta","75e7f83c":"def makeCategorical(df,columns):\n    for col in columns:\n        df[col] = df[col].apply(lambda x:'with' if x==1 else \"without\")","22457beb":"makeCategorical(df,taste_features)\nmakeCategorical(df,phys_features)\ndf = df.dropna()\ndf.head()","aabbda5e":"corr_rat = {}\nfor f in taste_features+phys_features:\n    for m in ['sugarpercent','pricepercent','winpercent']:\n        corr_rat.setdefault(f,[]).append(correlation_ratio(df[f],df[m]))","62e3f1e2":"corr_rat_df = pd.DataFrame.from_dict(data=corr_rat,orient='index', columns=['sugarpercent','pricepercent','winpercent'])\ncorr_rat_df.plot(kind='bar',figsize=(10,8))\nplt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\nplt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\nplt.title(\"How different features affect Sweetness, Price and Win probability?\")\nplt.show()","d10a8fde":"df['winpercent_bool'] = df['winpercent'].apply(lambda x:1 if x>75 else 0)","dc372fac":"!pip install prince","c143da8d":"import prince\nfamd = prince.FAMD(\n     n_components=2,\n     n_iter=10,\n     copy=True,\n     check_input=True,\n     engine='auto',\n     random_state=42)\nfamd = famd.fit(df.drop(['winpercent','winpercent_bool'], axis='columns'))","d7202d28":"famd.explained_inertia_","2f38ed9e":"import math\ndf_column_correlation = famd.column_correlations(df)\nmax_cor_len = 0\nrot_ang = {}\nfor idx in df_column_correlation.index:\n    point = df_column_correlation.loc[idx].values\n    max_cor_len = max(math.sqrt(point[0]**2+point[1]**2),max_cor_len)\n    rot_ang[idx] = math.atan(point[1]\/point[0])","aaf8b4a5":"max_cor_len","cf90c5b6":"circle1 = plt.Circle((0, 0), 1, color='k', fill=False)\ncircle2 = plt.Circle((0, 0), 1, color='k', fill=False)\ncircle3 = plt.Circle((0, 0), 1, color='k', fill=False)\n\nf, ax = plt.subplots(1,3, figsize=(30,10))\nax[0].add_artist(circle1)  \nax[1].add_artist(circle2)  \nax[2].add_artist(circle3)  \n\nmax_len = 0\nfor idx in famd.column_correlations(df).index:\n    idx_name = idx.split(\"_\")\n    point = (famd.column_correlations(df)).loc[idx].values\n    point=point\/max_cor_len    \n    if idx_name[0] in taste_features and idx_name[1]==\"with\":\n        ax[0].arrow(0, 0, point[0], point[1], head_width=0.05, head_length=0.05, color = 'k')\n        #ax[0].annotate(idx_name[0],xy=tuple(point),xycoords='data', rotation=0, fontsize = 15, color='blue')\n    elif idx_name[0] in phys_features and idx_name[1]==\"with\":\n        ax[1].arrow(0, 0, point[0], point[1], head_width=0.05, head_length=0.05, color = 'k')\n        #ax[1].annotate(idx_name[0],xy=tuple(point),xycoords='data', rotation=0, fontsize = 15, color='blue') \n    elif idx in ['sugarpercent','pricepercent']:\n        ax[2].arrow(0, 0, point[0], point[1], head_width=0.05, head_length=0.05, color = 'k')\n        #ax[2].annotate(idx_name[0],xy=tuple(point),xycoords='data', rotation=0, fontsize = 15, color='blue')        \nfor i,axis in enumerate(ax):\n    axis.set_xlim([-1,1])\n    axis.set_ylim([-1,1])\n    axis.axis('equal')\n    axis.set_xlabel('component 0')\n    if i==0:\n        axis.set_ylabel('component 1')\nplt.show()","de05b8ff":"ax = famd.plot_row_coordinates(\n     df,\n     ax=None,\n     figsize=(15, 15),\n     x_component=0,\n     y_component=1,\n     labels=df.index,\n     color_labels=['win {}'.format(t) for t in df['winpercent_bool']],\n     ellipse_outline=True,\n     ellipse_fill=True,\n     show_points=True\n)","e4e167ed":"winners = famd.row_coordinates(df)[df.winpercent_bool==1]\nloosers = famd.row_coordinates(df)[df.winpercent_bool==0]","cef66a14":"import numpy as np\nwm_0, wm_1, w_2xconf_0, w2xconf_1,angle = prince.plot.build_ellipse(winners[0].astype(np.float),winners[1].astype(np.float))\nlm_0, lm_1, l_2xconf_0, l2xconf_1,angle = prince.plot.build_ellipse(loosers[0].astype(np.float),loosers[1].astype(np.float))","10c229f4":"#winner specifications:\nwinner_centroid = famd.inverse_transform([wm_0,wm_1])\nwinner_centroid.index = df_column_correlation.index\nwinner_centroid.columns = ['winner']","0f6a256e":"#winner specifications:\nlooser_centroid = famd.inverse_transform([lm_0,lm_1])\nlooser_centroid.index = df_column_correlation.index\nlooser_centroid.columns = ['looser']","1bd3a301":"pd.concat([winner_centroid,looser_centroid], axis = 1)","c8b9b094":"df_winner_looser = pd.concat([winner_centroid,looser_centroid], axis = 1)\nfor idx in df_winner_looser.index:\n    if df_winner_looser.loc[idx,'winner']>df_winner_looser.loc[idx,'looser']:\n        df_winner_looser.loc[idx,'winner'] = 1\n        df_winner_looser.loc[idx,'looser'] = 0\n    else:\n        df_winner_looser.loc[idx,'winner'] = 0\n        df_winner_looser.loc[idx,'looser'] = 1        ","15122949":"df_winner_looser.head(6)","f664394c":"with_idx = [idx for idx in df_winner_looser.index if idx.endswith('_with')]\ndf_winner_looser = df_winner_looser.loc[with_idx]\nfinal_idx = [idx.split(\"_\")[0] for idx in with_idx]\ndf_winner_looser.index = final_idx\ndf_winner_looser","39c6194c":"### Physical Properties Correlation:\nWe do the same calculation for physical features. Here the result is more intuitve. For example, it is clear that Nougat can not be Hard (negative correlation) or a crispy or rice wafer can not be hard. One interesting result is packaging: Packaging in bags is only positively correlated with hard candies. Soft candies are packed mostly in box packages.","06ea6801":"# Case Study: Expanding Candy brand\n## Description:\nin this case study, the final goal is to develop a data-driven pipeline which recommend customers those candies with high probability of being bought. \n\nData set used for this study: https:\/\/github.com\/fivethirtyeight\/data\/tree\/master\/candy-power-ranking","a220e7d1":"How do principal component related to the original features? The circle plot below shows different features in the space of principal components. For clarity I sketched them in different groups: Taste features, Shape features and finally continuous features. ","2921309d":"__2) Fruity__\n\n1) In contrast to chocolate, adding a fruity taste decreases the correlation between sugar and price. \n\n2) An __Interesting__ observation is that the relation between price and popularity experiences a transition by adding a fruity taste. While for candies without fruit the popularity and price are positively correlated, in those candies with fruity tastes, the popularity decreases as their price increase.","889e7b68":"The dataframe below shows the specification of the winner center and looser center next to each other.","b20395ea":"__2) Peanuty Almondy__\n\nSame __Interesting__ transition like `fruity` can be observed for `peanutyalmondy`. The candies with this taste should be offered in cheaper price.","0f680c70":"__Correlation Ratio__  is a measure of the relationship between the statistical dispersion within individual categories and the dispersion across the whole population or sample. In our data set we have 9 categorical variables. The continuous variables have dispersities however, we do not know if this dispersity is due to different categories or mainly due to dispersity across the whole population. In analysis above, we tried to somehow figure out, how continuous variables are affected by changing only a specific category. For instance we observed that the price-win relation for categories __with chocolate__ and __without chocolate__ are completely different. Correlatin ratio provides a possibility to analyse this hypothesis in a more systematic way. The formula to compute this measure is:\n\n$$\\eta^2 = \\frac{\\sigma^2_{\\bar{y}}}{\\sigma^2_y}$$\n\nwhere $\\sigma^2_{\\bar{y}}$ is the variance of the mean among different categories and $\\sigma^2_y$ is the whole variance of the data. $\\eta$ is a number between 0 and 1. $\\eta \\approx 0$ corresponds to the fact that the dispersity in the measurment is overall and independent of the categories. $\\eta \\approx 1$ corresponds to the fact that the dispersity is due to different categories. The function below measures the correlation ratio:","ac1b1f96":"After this step, we can use *FAMD* to reduce the dimensionality of the problem.","7ad7e277":"Intuitively we can classify the brands into two groups:\n\n1) winners with `winpercent`>75\n\n2) loosers with `winpercent`<=75\n\nwe add another column `winpercent_bool` to our data set and put 1 for winners and 0 for loosers","d898ff3f":"According to this figure, as also discussed before, `chocolate`, `peanutyalmondy` and `caramel` have almost the same nature and `fruity` has a completely different nature from these three. This is consistent with the heatmap shown before, where fruity was negatively correlated with other tastes. About the shapes, `bar`, `nougat` and `crispedricewafer` look almost the same while the bag package goes completely in a different direction. Considering figures left and middle, `chocolate`, `caramel` and `peanutyalmondy` usually come in the form of `bar`, `nougat` or `crispedricewafer` and packed in boxes (`plurbus`=0). If we add the right figure to this analysis, these candies are positively correlated with price. ","3a536068":"#### Effect of the taste:\nbelow we sketched the correlation heatmap in presence and absence of various tastes. Here are the results:\n\n__1) Chocolate__\n\n1) Adding chocolate increases the correlation between price and sugar. In other words, chocolate candies which are sweeter are more expensive. The same holds for candies without chocolate, but this correlation is weaker.\n\n2) Sweet chocolate candies are more probable to be bought than for instance bitter chocolate candies. For candies without chocolate, the correlation between sweetness and win is weaker\n\n2) __Interestingly__, for chocolate candies, the more pricey they are, the more likely they sell!","f5997b41":"Here, 68% of the total dispersity can be explained by `component 0` and 15% by `component1`. These to components together can explain 83% of the whole dispersity. It is not ideal but acceptable.","97b4f9e6":"### Taste Correlations:\nConsidering the Figure below, as expected, there is a clear correlation between different taste components. Interestingly, as shown in this map, `fruity` taste goes in a completely different direction as the other three tastes namely `caramel`, `chocolate`, `peanutyalmondy`. In fact, `fruity` is negatively correlated with other tastes, while the rest are positively correlated. Another fact is a very small correlation between `caramel` and `peanutyalmondy`, which is quite surprising because the popularity of some of the well-known brands such as *Mars* and *Sneakers* is due to the combination of these two tastes.  ","169ee043":"The plot below represents different brands in the coordinate system spanned by the principal components. The *winner* and *looser* brands are masked by different colors. Finally, the confidential intervals for each of these groups are visualized by two ellipses.","3acd506d":"To build a predictive model we specify the centroids of each groups `win = 1` (winners) and `win = 0` (loosers). The confidence region can be considered as the ellipses centered at these centroids as represented above. For each ellipse, the width and height are square roots of the covariance matrix of the data coordinates and the axis of the ellipses are the Eigenvectors of this covariance matrix. The class `plot` from `prince` has a method called `build_ellipse` which computes these quantities","22133963":"Here are the components of two ellipses:","7310988f":"Some of the interesting conclusions about this analysis:\n\n1) Candies containing __caramel, chocolate or peanut__ in the forms __bar, rice wafer__ and packed in __boxes__ are more probable to sell.\n\n2) Among the tastes, __Chocolate__ is the most effective component which affects the popularity (see bar plot of the correlation ratio). \n\n3) Among the tastes, __Fruity__ goes in a completly different direction as others.\n\n4) For chocolate candies, the more pricey they are, the more likely they sell!\n\n5) For fruity candies the popularity increases as their price decrases. In other words the cheapest one sell best!\n\n6) Sugar amount is independent of the ingredients (see correlation ratio plot). ","f5ade6d9":"### How different components affect the amount of sugar, price and winning likelihood?\n\nHere we look at the correlatin between `sugarpercent`, `pricepercent` and `winpercent` onece in the presence of a certain component like `chocolate` (`chocolate`=1) and once in the absence of that component. We want to see how a certain component changes the game.","7cb54b1e":"The data consists of information about 85 candy brands which was collected from internet. Each candy is featured by 4 `taste` related and 5 `appereance_physical` properties. In addition to that, the amount of sugar and the offered price is also given. The detailed description is as follows:\n\n__Taste Features__\n\n1) does it contains chocolate (`chocolate`=1) or not (`chocolate`=0)\n\n2) does it have a fruity taste (`fruity`=1) or not (`fruity`=0)\n\n3) does it contains caramel taste (`caramel`=1) or not (`caramel`=0)\n\n4) does it contains peanuty or almondy taste (`peanutyalmondy`=1) or not (`peanutyalmondy`=0)\n\n__Appereance Features__\n\n1) is it in the form of nougat (`nougat`=1) or not (`nougat`=0)\n\n2) is it crispy (`crispedricewafer`=1) or not (`crispedricewafer`=0)\n\n3) is it hard (`hard`=1) or soft (`hard`=0)\n\n4) is it like bar (`bar`=1) or not (`bar`=0)\n\n5) is it packed in bag (`pluribus`=1) or in bax (`pluribus`=0)\n\n__Price Factor__\n\n`pricepercent`: the offered price devided by a maximum price\n\n__Sugar Amount__\n\n`sugarpercent`: How much sugar does it contain devided by a maximum sugar amount\n\n__Win Probability__\n\n`winpercent`: To what percentage the product was accepted by the customers?","c60e16a7":"## Step 2: Factor Analysis of Mixed Data (FAMD)\n\nNow that we have seen, how strongly correlated the features are, we move forward to build our recommendation model. \n\nThe correlation between different features suggest that many of these features may be of the same nature. For instance it is not difficult to imagine that a crispy candy cannot be hard or caramel almost always contains a considerable amount of sugar. The abundant of different featurs, which are rather internally correlated overrates the data set. In addition, it causes unnecessary difficulty in visualization of data. Having all these points in mind, it makes scence if we try to use a *dimensional reduction* method in order to boil down the number of *redundant* features to real features.\n\nOur data set consists of both continuous and categorical data. We can convert all categorical data to continuous using for example *one-hot encoding* and use *principal component analysis*. There is, however, another method, which is specifically developed for mixed features. This method is called *FAMD* and in the rest of this report, we'll use this method to reduce the dimensionality of our features. \n\nFAMD has the same spirit as PCA. It tries to introduce new features as linear combinations of the original features. The new features should -to some extent- be able to explain the dispersity among data. In PCA this is done by diagonalizing the covariance matrix. The Eigenvectors of the covariance matrix are linear combination of the old features. On the new basis spanned by the Eigenvectors, the off-diagonal terms of the covariance matrix vanish, implying that the new features are no more correlated. \n\nTo my best knowledge, the only FAMD package available for python is called `prince`. Although, compared to the well-established R package `FactoMineR`, `prince` is poorly documented and developed, I still prefer to stick to python and hence would use `prince`.","04c08610":"The data above is consistent: whenever `..._with` for a winner exceeds `..._with` for a looser, `..._without` for the winner deceeds `..._without` for the looser. ","6334a3a7":"One can imagine that some of the features should be correlated with each other. For instance, from my experience, in most cases, chocolate and fruit taste don't match together. Or caramel shouldn't harm chocolate taste and so forth. These relations can be studied by simply computing the *Pearson Correlation* between different features.","2217ef4e":"__Interestingly__ among tastes `chocolate` and among shapes `bar` are the most impactful features, which cause dispersity in data. While `bar` affects mostly the dispersity of `price`, `chocolate` affects both `price` and `winpercent`. \n\nAnother __interesting__ obsservation is that non of the categorical features above affect `sugarpercent`. This conclusion seems to be reasonable. Candies are generally sweet. Different brands may contain different amount of sugar. But this amount is not that affected by taste and shape factors. Of course, as expected, `caramel` is naturally mixed with considerable amount of sugar and therefore has the most impact on sugar amount compared to other categories. But sugar can be added independently to any candy.","cc7a06dc":"`explained_inertia_` says, how much of the total inertia can be explained by which new feature. ","36f3d2c3":"We transform back the centers of the ellipses to see the original features of the winners and loosers:","6b65afb8":"## Step 1: Make scence of data\nLets take a look at the data:","392f6b45":"## Final Result and conclusion:\nThe dataframe below compares the ingredients of the winner and looser centers."}}