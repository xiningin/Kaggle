{"cell_type":{"b032373f":"code","12da7203":"code","fc94fa2e":"code","985ddfa3":"code","affe4819":"code","28293c9c":"code","6e79f9c4":"code","0a8f58f5":"code","6914ad7c":"code","e5f17fb5":"code","7f18a1c6":"code","6cc78d9c":"code","e5cf0fff":"code","7e3ac481":"code","b9b5ee91":"code","9dd8f5bb":"code","025f22b4":"code","4e36cf1c":"code","dcd1957d":"code","f3c736e1":"code","0f4a048f":"code","3d7311bd":"code","c974cf6a":"code","511eccf6":"code","17b605e6":"code","7ccefb37":"code","c757ad36":"code","4001aab9":"code","63eb77aa":"code","048f36bb":"code","28d252bd":"code","2e1e8d82":"code","49c91339":"code","a3959a87":"code","d7520142":"code","c53de64b":"code","6b23b68c":"code","1eb29403":"markdown","72d90eac":"markdown"},"source":{"b032373f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n","12da7203":"dt = pd.read_csv(\"\/kaggle\/input\/amazon-product-dataset-2020\/home\/sdf\/marketing_sample_for_amazon_com-ecommerce__20200101_20200131__10k_data.csv\")\nprint(\"Data Dimensions are: \", dt.shape)\nprint(\"Columns: \", dt.columns)","fc94fa2e":"dt.dropna(subset=['Category'], axis=0, inplace=True)\nprint(dt.info())","985ddfa3":"dt.head()","affe4819":"dt['Category'] = dt['Category'].str.split(\"|\").str[0].str.strip()","28293c9c":"dt.head(30)","6e79f9c4":"data = dt[['Product Name', 'Category']]","0a8f58f5":"data['Category'].unique()","6914ad7c":"data = data.drop_duplicates()\ndata.head()","e5f17fb5":"#filter_products","7f18a1c6":"filter_products = \"\"\"Category == 'Electronics' or Category == 'Cell Phones & Accessories' or Category == 'Beauty & Personal Care' or Category == 'Baby Products' or Category == 'Pet Supplies' or Category == 'Grocery & Gourmet Food' or Category == 'Clothing, Shoes & Jewelry'\"\"\"\n\ndata = data.query(filter_products)","6cc78d9c":"data['Category'] = data['Category'].replace(\"Cell Phones & Accessories\", \"Electronics\")\ndata['Category'] = data['Category'].replace(\"Clothing, Shoes & Jewelry\", \"Fashion\")\ndata['Category'] = data['Category'].replace(\"Beauty & Personal Care\", \"Personal Care & Grooming\")\ndata['Category'] = data['Category'].replace(\"Baby Products\", \"Personal Care & Grooming\")\ndata['Category'] = data['Category'].replace(\"Pet Supplies\", \"Grocery\")\ndata['Category'] = data['Category'].replace(\"Grocery & Gourmet Food\", \"Grocery\")","e5cf0fff":"data.Category.unique()","7e3ac481":"data.head()","b9b5ee91":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report","9dd8f5bb":"#nltk.download(\u2018stopwords\u2019)\n","025f22b4":"data['Product Name'] = data['Product Name'].astype(str)","4e36cf1c":"data['Product Name'] = data['Product Name'].apply(lambda x: \" \".join(x.lower() for x in x.split()))","dcd1957d":"## remove punctuation\ndata['Product Name'] = data['Product Name'].str.replace('[^\\w\\s]','')","f3c736e1":"stop = stopwords.words('english')\ndata['Product Name'] = data['Product Name'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))","0f4a048f":"st = PorterStemmer()\ndata['Product Name'] = data['Product Name'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))","3d7311bd":"cv = CountVectorizer(max_features = 1500)\nX = cv.fit_transform(data['Product Name']).toarray()\ny = data.iloc[:, -1].values","c974cf6a":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","511eccf6":"classifier = GaussianNB()\nclassifier.fit(X_train, y_train)","17b605e6":"y_pred_NB = classifier.predict(X_test)\ny_pred_NB","7ccefb37":"cm_NB = confusion_matrix(y_test, y_pred_NB) \ncm_NB","c757ad36":"cf_NB = classification_report(y_test, y_pred_NB)\ncf_NB","4001aab9":"test_data = pd.read_excel('..\/input\/search-terms\/Search terms.xlsx')","63eb77aa":"test_data.head()","048f36bb":"test_data['Search Term'] = test_data['Search Term'].astype(str)","28d252bd":"## remove punctuation\ntest_data['Search Term'] = test_data['Search Term'].str.replace('[^\\w\\s]','')","2e1e8d82":"stop = stopwords.words('english')\ntest_data['Search Term'] = test_data['Search Term'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))","49c91339":"st = PorterStemmer()\ntest_data['Search Term'] = test_data['Search Term'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))","a3959a87":"test_dataset = cv.fit_transform(test_data['Search Term']).toarray()","d7520142":"test_data['Category'] = classifier.predict(test_dataset) ","c53de64b":"test_data.head(20)","6b23b68c":"test_data.to_excel('question_2.xlsx')","1eb29403":"# Data Loading & Preparation","72d90eac":"Data contains 1048574 rows but maximum columns contain 584524 records. \n\nHalf of row are completely empty, so we will drop them. The tricky part is we can't drop all na rows as actual data set  also contain few NA entries. We need to keep them.\nWe will drop NA values where all entries are Null. \n\nAlso, we will drop last 5 empty columns."}}