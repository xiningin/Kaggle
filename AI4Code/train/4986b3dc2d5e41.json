{"cell_type":{"e1c891bd":"code","4ca6a832":"code","91abca3b":"code","e0a2b902":"code","a6412f50":"code","7e66ac52":"code","eaf2bc10":"code","bc5b386b":"code","cd2abe66":"code","7ad20bf0":"code","d20f12d7":"code","eb171910":"code","e88ab62e":"code","36607008":"code","87cd7d17":"code","86d210d6":"code","e3b7855d":"code","f3ee3a2e":"code","9ee0fe79":"code","23336255":"code","022f135f":"code","903f733c":"code","ddf43e60":"code","3fc4ce36":"code","0d93f940":"code","34fa1c15":"code","b878b817":"code","e0967062":"code","67ec1405":"code","468e1a54":"code","4290f80a":"code","b9a87cba":"code","1f3b0929":"code","e482ad83":"code","17525e4a":"code","f57dc668":"code","a198445b":"code","4f46502b":"code","f65a5f08":"code","6311f937":"code","526db4b0":"code","0ce0db44":"code","1c4bb10c":"code","1ae0abe3":"code","67338d46":"code","4634421f":"code","204c9641":"code","a6e17ac7":"code","cd4c165c":"code","ad24141f":"code","50a73b2f":"code","59e53ff9":"code","1581d92e":"code","18336e84":"code","4fc7dd3b":"markdown","562eba3b":"markdown","77a2cc94":"markdown","7388b2ab":"markdown","ba878d1d":"markdown","e309bd60":"markdown","93782b03":"markdown","ee2f0e2b":"markdown","3da71d7e":"markdown","67b4fc9a":"markdown","8fba4e63":"markdown","bb3af791":"markdown","1dba5290":"markdown","66640560":"markdown","9a525a16":"markdown","4af937ad":"markdown","9ccb4fda":"markdown","e9ad4384":"markdown","e62feabf":"markdown","339e4272":"markdown","7c73a246":"markdown","227b61bc":"markdown","1d1a0b3b":"markdown","8816b664":"markdown","966c4ff1":"markdown","b0329b88":"markdown","e60355c4":"markdown","6d78cac1":"markdown","96fd1389":"markdown","0a9c6a6a":"markdown","df8ee041":"markdown","52384a60":"markdown","7da2ce33":"markdown","fb4cf099":"markdown","665b4425":"markdown"},"source":{"e1c891bd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4ca6a832":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\npd.set_option('display.max_columns', None)\n","91abca3b":"df = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\", index_col=0)\n# Selecionei um subconjunto das vari\u00e1veis de entrada para fins de simplifica\u00e7\u00e3o\nFEATURES_ANALISAR = ['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea',  'Street', 'Alley', 'Neighborhood', 'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'CentralAir', 'BsmtCond', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenQual', 'Fireplaces', 'SalePrice']\ndf = df.loc[:, FEATURES_ANALISAR]\ndf","e0a2b902":"NominalCategorical = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'Neighborhood', 'HouseStyle', 'CentralAir', 'BsmtCond', 'KitchenQual']\nOrdinalCategorical = ['OverallQual', 'OverallCond', 'YearBuilt']\nNumeric = ['LotFrontage', 'LotArea', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'Fireplaces', 'SalePrice']\n","a6412f50":"print(\"{} linhas\\n{} colunas\/features.\".format(df.shape[0], df.shape[1]))","7e66ac52":"# Funcao do Pandas usada para contar o numero de valores vazios de cada coluna\ndata = df.isna().sum(axis=0)\ny = list(range(df.shape[1]))\nx = data.values\n\n# Criamos uma figura\nfig, ax = plt.subplots(figsize=(8, 10))\n\n# Plota as barras\nax.barh(y=y, width=x)\n\n# Adiciona informa\u00e7\u00f5es no gr\u00e1fico\nax.set_yticks(y)\nax.set_yticklabels(df.columns.values)\nax.set_title(\"Quantidade de vari\u00e1veis ausentes por coluna\")\nplt.show()","eaf2bc10":"df['Alley'].value_counts()","bc5b386b":"FEATURES_ANALISAR.remove('Alley')\ndf = df.loc[:, FEATURES_ANALISAR]\ndf_original = df.loc[:, FEATURES_ANALISAR]\ndf","cd2abe66":"# Criamos um dataframe com os dados de LotFrontage, Lot Area e SalePrice\ndf_imput_regress = pd.concat([df['LotFrontage'], df['LotArea'], df['SalePrice']], axis=1)\ndf_imput_regress.head()","7ad20bf0":"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\n# Criamos um objeto que far\u00e1 a Imputa\u00e7\u00e3o por Regress\u00e3o\nimp_mean = IterativeImputer(random_state=0)\n# Treinamos a regress\u00e3o com os dados disponiveis\nimp_mean.fit(df_imput_regress.values)\n\n# Agora, faremos uma regress\u00e3o nos mesmos dados usados no treinamento, para\n# gerar valores num\u00e9ricos para substituir os valores ausentes de LotFrontage\nX = df_imput_regress.values\nregr_output = imp_mean.transform(X)\nregr_output","d20f12d7":"# Agora substituimos a primeira coluna de X (output do regressor) no nosso dataframe df\ndf['LotFrontage'] = regr_output[:, 0]","eb171910":"df['LotFrontage'].isna().sum()","e88ab62e":"df['BsmtCond'].value_counts()","36607008":"#.fillna substitui o argumento nos dados ausentes\ndf['BsmtCond'] = df['BsmtCond'].fillna('TA')","87cd7d17":"df.isna().sum(axis=0)","86d210d6":"selected_columns = Numeric + OrdinalCategorical\ndf[selected_columns].head()\n","e3b7855d":"fig, axes = plt.subplots(nrows=1, ncols=10, figsize=(15, 5))\n\nfor i,col in enumerate(selected_columns):\n    axes[i].boxplot(df[col])\n    axes[i].set_title(col)\n\nplt.tight_layout()","f3ee3a2e":"fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(15, 15))\n# Quando criamos graficos com multiplas dimensoes, axes vira um array 2D. Ent\u00e3o\n# vamos transformar ele numa lista para iterar durante a cria\u00e7\u00e3o do grafico\naxes = axes.flatten()\n\n# Iterando de grafico em grafico\nfor i,ax in enumerate(axes):\n    ax.hist(df[selected_columns[i]])\n    ax.set_title(selected_columns[i])\n\nplt.tight_layout()","9ee0fe79":"fig, ax = plt.subplots()\n\nax.scatter(x=df['LotArea'], y=df['LotFrontage'])\nplt.show()","23336255":"print(\"Tamanho do dataset antes dos filtros: {}\".format(df.shape))\n\nmask = df['LotFrontage'] < 200\ndf = df[mask]\nmask = df['LotArea'] < 100000\ndf = df[mask]\n\nprint(\"Tamanho do dataset depois dos filtros: {}\".format(df.shape))","022f135f":"from scipy import stats\n\n# df[\"SalePrice\"]\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n\ndata = df[\"SalePrice\"]\nz_data = np.abs(stats.zscore(df[\"SalePrice\"]))\nax[0].hist(data)\nax[0].set_xlabel(\"Valores reais de SalePrice\")\nax[1].hist(z_data)\nax[1].set_xlabel(\"Valores Z de SalePrice\")\nax[1].vlines(x=3, ymin=0, ymax=850, colors='red')\nplt.show()","903f733c":"print(\"Tamanho do dataset antes dos filtros: {}\".format(df.shape))\n\nmask = np.abs(stats.zscore(df[\"SalePrice\"])) < 3\ndf = df[mask]\n\nprint(\"Tamanho do dataset depois dos filtros: {}\".format(df.shape))","ddf43e60":"df['RatioAreaFrontage'] = df['LotArea'] \/ df['LotFrontage']\n\ndf[['RatioAreaFrontage', 'LotArea', 'LotFrontage']]","3fc4ce36":"selected_columns = ['LotFrontage', 'LotArea', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'Fireplaces', 'OverallQual', 'OverallCond', 'YearBuilt', 'RatioAreaFrontage']\nx = df[selected_columns]\ny = df['SalePrice']","0d93f940":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import f_regression\n\n# k \u00e9 o numero de features que N\u00c3O ser\u00e3o jogadas foras. Vamos primeiro ver os resultados, depois eliminar alguma feature.\nk = x.shape[1]\n# Utilizamos um m\u00e9todo do sklearn para isso, usando a estrat\u00e9gia Chi Squared.\nselector = SelectKBest(f_regression, k=k)\nx_new = selector.fit_transform(x, y)","34fa1c15":"# Utilizo o log10 pois os valores s\u00e3o ou muito grandes, ou muito pequenos\nscores = -np.log10(selector.pvalues_)\n\nx_plot = list(range(len(scores)))\n\nfig, ax = plt.subplots(figsize=(8, 4))\nplt.bar(x_plot, scores)\nax.set_title(\"Score do m\u00e9todo f-regression para Feature Selection\")\nax.set_xticks(x_plot)\nax.set_xticklabels(selected_columns, rotation=45)\nplt.show()","b878b817":"print(\"Tamanho do dataset antes dos filtros: {}\".format(df.shape))\n\ndf = df.drop(['OverallCond'], axis=1)\n\nprint(\"Tamanho do dataset depois dos filtros: {}\".format(df.shape))","e0967062":"df['CentralAir'].value_counts()","67ec1405":"df['CentralAir'].replace(to_replace='Y', value=1, inplace=True)\ndf['CentralAir'].replace(to_replace='N', value=0, inplace=True)\n\ndf['CentralAir'].value_counts()","468e1a54":"selected_columns = ['LotFrontage', 'LotArea', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'Fireplaces', 'OverallQual', 'YearBuilt', 'RatioAreaFrontage', 'SalePrice']\ndf[selected_columns].describe()","4290f80a":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndata = df[selected_columns]\nscaler.fit(data)","b9a87cba":"# Reescalonamos os dados\ndata_scaled = scaler.transform(data)\n\n# Criamos um dataframe para facilitar a visualiza\u00e7\u00e3o\ndata_scaled = pd.DataFrame(data_scaled)\n# \"Devolvemos\" os nomes das features e os \u00edndices para o dataframe\ndata_scaled.columns = selected_columns\ndata_scaled.index = df.index\n\ndata_scaled.describe()","1f3b0929":"df = df.drop(selected_columns, axis=1)","e482ad83":"df = pd.concat([df, data_scaled], axis=1)","17525e4a":"df_original","f57dc668":"df","a198445b":"import pandas as pd\n\nprint(\"Trabalho 1 de IA\")\ndf = pd.read_csv(\"..\/input\/aula-2-ia-dataset\/CasasParaAlugar.csv\")\n","4f46502b":"df","f65a5f08":"df.head()","6311f937":"df['city'].value_counts().head(10).plot.bar()","526db4b0":"df['city'].value_counts().sort_index().plot.bar()","0ce0db44":"df['area'].value_counts().head(10).plot.bar()","1c4bb10c":"df['bathroom'].value_counts().head(10).plot.bar()","1ae0abe3":"df['animal'].value_counts().head(10).plot.bar()","67338d46":"df['hoa (R$)'].value_counts().sort_index().plot.area()","4634421f":"df.plot.scatter(x='area', y='hoa (R$)')","204c9641":"df.isnull().count()","a6e17ac7":"import seaborn as sns\nsns.countplot(df['city'].head(20))","cd4c165c":"ax = sns.distplot(df['area'], bins = 20, kde = False)","ad24141f":"sns.boxplot(x='city',\n           y ='area',\n           hue = 'bathroom',\n           data = df)","50a73b2f":"r = df.corr()\nsns.heatmap(r)","59e53ff9":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\ndata_train = pd.read_csv('..\/input\/aula-2-ia-dataset\/CasasParaAlugar.csv')\n#data_test = pd.read_csv('...\/input\/aula-2-ia-dataset\/CasasParaAlugar.csv')\n\ndata_train.sample(3)","1581d92e":"sns.barplot(x=\"city\", y=\"area\", hue=\"bathroom\", data=data_train);","18336e84":"sns.pointplot(x=\"city\", y=\"area\", hue=\"animal\", data=data_train,\n              palette={\"acept\": \"blue\", \"not acept\": \"pink\"},\n              markers=[\"*\", \"o\"], linestyles=[\"-\", \"--\"]);","4fc7dd3b":"Portanto, levando em considera\u00e7\u00e3o que \u00e9 poss\u00edvel que a presen\u00e7a de ar condicionado central possa valorizar a casa, podemos codificar 'Y'=1 e 'N'=0:","562eba3b":"Vamos fazer um gr\u00e1fico de dispers\u00e3o 2D das vari\u00e1veis LotArea e LotFrontage para verificar a rela\u00e7\u00e3o entre elas","77a2cc94":"O escalonador MinMax est\u00e1 ajustado para os dados presentes em selected_columns.\nAgora iremos reescalonar estes dados e verificar se eles est\u00e3o dentro de um intervalo [0,1]:","7388b2ab":"Vamos remover todos os dados com Z >= 3","ba878d1d":"Como a feature Alley tem a grande maioria dos dados ausentes, \u00e9 do tipo categ\u00f3rica e suas categorias est\u00e3o divididas em n\u00fameros muito similares (50 e 41), decidimos por excluir esta coluna da an\u00e1lise:","e309bd60":"Podemos perceber que 'TA' \u00e9 a categoria com maior presen\u00e7a. Iremos substitu\u00ed-la nos dados ausentes:","93782b03":"# Medi\u00e7\u00e3o, dele\u00e7\u00e3o e imputa\u00e7\u00e3o de dados ausentes","ee2f0e2b":"# Feature Selection","3da71d7e":"## Dataset \"Inicial\"","67b4fc9a":"Vamos continuar apenas com as vari\u00e1veis num\u00e9ricas e ordinais categ\u00f3rias codificadas em forma de n\u00fameros, por simplicidade.\n\nVamos descartar 1 feature usando o teste f-regression","8fba4e63":"### Detec\u00e7\u00e3o visual","bb3af791":"# Outliers","1dba5290":"Podemos perceber na tabela acima que os existem valores m\u00ednimos que come\u00e7am em 21 (Lot Frontage), 1300 (Lot Area) e 26.9 (RatioAreaFrontage). Al\u00e9m disso, os valores m\u00e1ximos de muitas tabelas s\u00e3o valores altos, como 182 (LotFrontage), 70761 (LotArea), entre outros.\n\nIsso pode resultar em problemas para o treinamento de uma rede neural, ent\u00e3o, vamos normalizar esses dados usando o estalonador MinMax do sklearn:","66640560":"Tamanho do dataset:","9a525a16":"Analisando os histogramas, diagrama de caixas e gr\u00e1fico de dispers\u00e3o, decidimos filtrar duas features:\n - Valores de LotArea maiores que 100000 ser\u00e3o exclu\u00eddos\n - Valores de LotFrontage maiores que 200 ser\u00e3o exclu\u00eddos","4af937ad":"Podemos perceber que a feature \"OverallCond\" apresenta os menores resultados, e portanto, vamos elimin\u00e1-la do nosso dataset.","9ccb4fda":"Olhando para a tabela do dataset, podemos perceber que a feature \"CentralAir\" tem apenas 2 valores, correspondentes a verdadeiro e falso: 'Y' e 'N':","e9ad4384":"## Dataset \"Final\"","e62feabf":"# Feature Engineering","339e4272":"Vamos criar uma nova feature de forma bem simples, dividindo a \u00c1rea do terreno pelo tamanho da frente do terreno, ou seja, LotArea\/LotFrontage","7c73a246":"Agora, como podemos perceber, LotFrontage n\u00e3o tem mais dados nulos","227b61bc":"Vamos novamente apenas tratar de vari\u00e1veis codificadas como n\u00fameros","1d1a0b3b":"# Data Scaling","8816b664":"Para detectar outliers, vamos utilizar 2 t\u00e9cnicas:\n - An\u00e1lise visual (atrav\u00e9s de boxplot e histogramas)\n - Z-Test, SE tiver alguma vari\u00e1vel float com distribui\u00e7\u00e3o normal ou normal com leve assimetria\n \nAl\u00e9m disto, neste momento vamos apenas verificar outliers de vari\u00e1veis codificadas de forma num\u00e9rica","966c4ff1":"#### Existem muito mais an\u00e1lises que podem ser feitas, e neste dataset existem MUUITAS outras vari\u00e1veis que precisariam ser tratadas para o dataset ficar adequado para o treinamento de uma rede neural.\n\n#### Ainda assim, estes s\u00e3o exemplos de alguns dos passos envolvidos na an\u00e1lise e pr\u00e9 processamento de dados antes da etapa de modelagem.","b0329b88":"### Detec\u00e7\u00e3o usando Z-Test","e60355c4":"# Feature Encoding","6d78cac1":"### BsmtCond\n\n\u00c9 uma vari\u00e1vei categ\u00f3rica ordinal. Portanto, n\u00e3o faria sentido substituir por um n\u00famero decimal, como por exemplo uma m\u00e9dia ou uma regress\u00e3o.\n\nEnt\u00e3o, iremos substituir os dados ausentes pelos dados que aparecem com maior frequ\u00eancia nesta feature.","96fd1389":"Temos 3 features que apresentam valores ausentes. Vamos analisar uma por uma come\u00e7ando por \n### Alley","0a9c6a6a":"### LotFrontage\n\nComo LotFrontage pode ser considerado como uma feature num\u00e9rica, podemos imputar os dados ausentes usando a t\u00e9cnica de Imputa\u00e7\u00e3o por Regress\u00e3o Linear.\n\nPor motivos de simplicidade, ser\u00e1 modelado uma regress\u00e3o para predizer os dados ausentes de LotFrontage levando em considera\u00e7\u00e3o apenas LotArea e SalePrice, ambas vari\u00e1veis num\u00e9ricas.","df8ee041":"#### Visualizando os resultados do f-regression","52384a60":"#### Todos os dados ausentes foram deletados ou substitu\u00eddos:","7da2ce33":"Olhando na tabela (e em alguma descri\u00e7\u00e3o do dataset, se dispon\u00edvel), decidimos o que \u00e9 categ\u00f3rico e num\u00e9rico","fb4cf099":"Como podemos ver, todos os valores m\u00ednimos est\u00e3o em 0 e todos os valores m\u00e1ximos est\u00e3o em 1. Os dados foram reescalonados com sucesso.\n\nAgora precisamos incorporar estes dados no nosso dataframe df:","665b4425":"Para a vari\u00e1vel SalePrice, vamos usar o m\u00e9todo Z-Test para remover outliers:"}}