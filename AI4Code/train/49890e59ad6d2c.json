{"cell_type":{"d330a65d":"code","7811514a":"code","60b91cf4":"code","a13d2291":"code","23794025":"code","9ca3b3b0":"code","5a4793f6":"code","bdefb832":"code","aafc51a5":"code","a69ced44":"code","9164c991":"code","6904fdfc":"code","b0b7036d":"code","4e40ed3a":"code","85243a99":"code","03872497":"code","4a36e4af":"code","4f58915b":"code","1994da71":"code","e86e5e69":"code","8a228fe0":"code","91fdec14":"code","d6b04ecf":"code","6d47048a":"code","93c5a888":"code","e6b886e0":"code","3c9def89":"code","1436be98":"code","4b6de687":"markdown","d38648b5":"markdown"},"source":{"d330a65d":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n\nfrom sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, \\\n    classification_report\n\nimport warnings\nimport missingno as msno\n\nwarnings.filterwarnings(\"ignore\")\n\npd.pandas.set_option(\"display.max_columns\", None)\npd.set_option(\"display.float_format\", lambda x: '%.2f' % x)\n\nlow_q1 = 0.05\nupper_q3 = 0.95\n\n###################################################################################################################################\ndef cat_summary(dataframe, categorical_columns, target, plot=False):\n    \"\"\"\n    -> Kategorik de\u011fi\u015fkenlerin s\u0131n\u0131flar\u0131n\u0131n oran\u0131n\u0131 ve targettaki medyan\u0131 g\u00f6sterir.\n\n    :param dataframe: \u0130\u015flem yap\u0131lacak dataframe\n    :param categorical_columns: Kategorik de\u011fi\u015fkenlerin adlar\u0131\n    :param target: Dataframe'de ilgilendi\u011fimiz de\u011fi\u015fken.\n    :param plot: Grafik \u00e7izdirmek i\u00e7in arg\u00fcman : True\/False\n\n    \"\"\"\n    for col in categorical_columns:\n        print(col, \" : \", dataframe[col].nunique(), \" unique classes.\\n\")\n\n        print(col, \" : \", dataframe[col].value_counts().sum(), \"\\n\")\n\n        print(pd.DataFrame({\"COUNT\": dataframe[col].value_counts(),\n                            \"RATIO ( % )\": 100 * dataframe[col].value_counts() \/ len(dataframe),\n                            \"TARGET_MEDIAN\": dataframe.groupby(col)[target].median(),\n                            \"TARGET_MEAN\": dataframe.groupby(col)[target].mean()}), end=\"\\n\\n\\n\")\n\n        if plot:\n            sns.countplot(x=col, data=dataframe)\n\n            plt.show()\n\n###################################################################################################################################\ndef outlier_thresholds(dataframe, variable, low_quantile=low_q1, up_quantile=upper_q3):\n    \"\"\"\n    -> Verilen de\u011ferin alt ve \u00fcst ayk\u0131r\u0131 de\u011ferlerini hesaplar ve d\u00f6nd\u00fcr\u00fcr.\n\n    :param dataframe: \u0130\u015flem yap\u0131lacak dataframe\n    :param variable: Ayk\u0131r\u0131 de\u011feri yakalanacak de\u011fi\u015fkenin ad\u0131\n    :param low_quantile: Alt e\u015fik de\u011ferin hesaplanmas\u0131 i\u00e7in bak\u0131lan quantile de\u011feri\n    :param up_quantile: \u00dcst e\u015fik de\u011ferin hesaplanmas\u0131 i\u00e7in bak\u0131lan quantile de\u011feri\n    :return: \u0130lk de\u011fer olarak verilen de\u011fi\u015fkenin alt s\u0131n\u0131r de\u011ferini, ikinci de\u011fer olarak \u00fcst s\u0131n\u0131r de\u011ferini d\u00f6nd\u00fcr\u00fcr\n    \"\"\"\n    quantile_one = dataframe[variable].quantile(low_quantile)\n\n    quantile_three = dataframe[variable].quantile(up_quantile)\n\n    interquantile_range = quantile_three - quantile_one\n\n    up_limit = quantile_three + 1.5 * interquantile_range\n\n    low_limit = quantile_one - 1.5 * interquantile_range\n\n    return low_limit, up_limit\n\n###################################################################################################################################\ndef has_outliers(dataframe, numeric_columns, plot=False):\n    \"\"\"\n    -> Say\u0131sal de\u011fi\u015fkenlerde ayk\u0131r\u0131 g\u00f6zlem var m\u0131?\n\n    -> Varsa iste\u011fe g\u00f6re box plot \u00e7izdirme g\u00f6revini yapar.\n\n    -> Ayr\u0131ca ayk\u0131r\u0131 g\u00f6zleme sahip de\u011fi\u015fkenlerin ismini g\u00f6nd\u00fcr\u00fcr.\n\n    :param dataframe:  \u0130\u015flem yap\u0131lacak dataframe\n    :param numeric_columns: Ayk\u0131r\u0131 de\u011ferleri bak\u0131lacak say\u0131sal de\u011fi\u015fken adlar\u0131\n    :param plot: Boxplot grafi\u011fini \u00e7izdirmek i\u00e7in bool de\u011fer al\u0131r. True\/False\n    :return: Ayk\u0131r\u0131 de\u011ferlere sahip de\u011fi\u015fkenlerin adlar\u0131n\u0131 d\u00f6ner\n    \"\"\"\n    variable_names = []\n\n    for col in numeric_columns:\n        low_limit, up_limit = outlier_thresholds(dataframe, col)\n\n        if dataframe[(dataframe[col] > up_limit) | (dataframe[col] < low_limit)].any(axis=None):\n            number_of_outliers = dataframe[(dataframe[col] > up_limit) | (dataframe[col] < low_limit)].shape[0]\n\n            print(col, \" : \", number_of_outliers, \" ayk\u0131r\u0131 g\u00f6zlem.\")\n\n            variable_names.append(col)\n\n            if plot:\n                sns.boxplot(x=dataframe[col])\n                plt.show()\n\n    return variable_names\n\n###################################################################################################################################\ndef label_encoder(dataframe, categorical_columns):\n    \"\"\"\n    2 s\u0131n\u0131fl\u0131 kategorik de\u011fi\u015fkeni 0-1 yapma\n\n    :param dataframe: \u0130\u015flem yap\u0131lacak dataframe\n    :param categorical_columns: Label encode yap\u0131lacak kategorik de\u011fi\u015fken adlar\u0131\n    :return:\n    \"\"\"\n    labelencoder = preprocessing.LabelEncoder()\n\n    for col in categorical_columns:\n\n        if dataframe[col].nunique() == 2:\n            dataframe[col] = labelencoder.fit_transform(dataframe[col])\n\n    return dataframe\n\n###################################################################################################################################\ndef one_hot_encoder(dataframe, categorical_columns, nan_as_category=False):\n    \"\"\"\n    Drop_first do\u011frusal modellerde yap\u0131lmas\u0131 gerekli\n\n    A\u011fa\u00e7 modellerde gerekli de\u011fil ama yap\u0131labilir.\n\n    dummy_na eksik de\u011ferlerden de\u011fi\u015fken t\u00fcrettirir.\n\n    :param dataframe: \u0130\u015flem yap\u0131lacak dataframe\n    :param categorical_columns: One-Hot Encode uygulanacak kategorik de\u011fi\u015fken adlar\u0131\n    :param nan_as_category: NaN de\u011fi\u015fken olu\u015ftursun mu? True\/False\n    :return: One-Hot Encode yap\u0131lm\u0131\u015f dataframe ve bu i\u015flem sonras\u0131 olu\u015fan yeni de\u011fi\u015fken adlar\u0131n\u0131 d\u00f6nd\u00fcr\u00fcr.\n    \"\"\"\n    original_columns = list(dataframe.columns)\n\n    dataframe = pd.get_dummies(dataframe, columns=categorical_columns,\n                               dummy_na=nan_as_category, drop_first=True)\n\n    new_columns = [col for col in dataframe.columns if col not in original_columns]\n\n    return dataframe, new_columns\n\n###################################################################################################################################\ndef rare_analyser(dataframe, categorical_columns, target, rare_perc):\n    \"\"\"\n     Data frame de\u011fi\u015fkenlerinin herhangi bir s\u0131n\u0131f\u0131, verilen e\u015fik de\u011ferden d\u00fc\u015f\u00fck frekansa sahipse bu de\u011fi\u015fkenleri g\u00f6sterir.\n\n    :param dataframe: \u0130\u015flem yap\u0131lacak dataframe\n    :param categorical_columns: Rare analizi yap\u0131lacak kategorik de\u011fi\u015fken adlar\u0131\n    :param target: Analizi yap\u0131lacak hedef de\u011fi\u015fken ad\u0131\n    :param rare_perc: Rare i\u00e7in s\u0131n\u0131r de\u011fer. Alt\u0131nda olanlar rare kategorisine girer.\n    :return:\n    \"\"\"\n    rare_columns = [col for col in categorical_columns\n                    if (dataframe[col].value_counts() \/ len(dataframe) < rare_perc).any(axis=None)]\n\n    for var in rare_columns:\n        print(var, \" : \", len(dataframe[var].value_counts()))\n\n        print(pd.DataFrame({\"COUNT\": dataframe[var].value_counts(),\n                            \"RATIO\": dataframe[var].value_counts() \/ len(dataframe),\n                            \"TARGET_MEAN\": dataframe.groupby(var)[target].mean(),\n                            \"TARGET_MEDIAN\": dataframe.groupby(var)[target].median()}),\n              end=\"\\n\\n\\n\")\n\n    print(len(rare_columns), \" adet rare s\u0131n\u0131fa sahip de\u011fi\u015fken var.\")","7811514a":"# Veri setini okuyal\u0131m\ndf = pd.read_csv(\"..\/input\/credit-risk\/credit_risk.csv\")","60b91cf4":"# \u0130lk 5 g\u00f6zleme bakal\u0131m\ndf.head()","a13d2291":"# Son 5 g\u00f6zleme bakal\u0131m\ndf.tail()","23794025":"# Genel olarak bilgi alal\u0131m\ndf.info()","9ca3b3b0":"# Gereksiz de\u011fi\u015fkeni d\u00fc\u015f\u00fcrelim\ndf.drop(\"Unnamed: 0\", axis=1, inplace=True)","5a4793f6":"# Eksik g\u00f6zlem var m\u0131 ? \ndf.isnull().sum()","bdefb832":"# Eksikliklikeri matris \u015feklinde g\u00f6sterir.\nmsno.matrix(df)\nplt.show()","aafc51a5":"# 0-1 \u015feklinde encode edilecek de\u011fi\u015fkenleri belirleyip, encode edelim.\nlabel_columns = [\"Sex\", \"Risk\"]\nlabel_encoder(df, label_columns)\n","a69ced44":"# Ayk\u0131r\u0131 g\u00f6zlem var m\u0131? Yok\nnumeric_columns = [\"Age\", \"Job\", \"Credit amount\", \"Duration\"]\n\nhas_outliers(df, numeric_columns)","9164c991":"# Nadir s\u0131n\u0131flar\u0131 ve oranlar\u0131n\u0131 g\u00f6zlemleyelim\ntemp_cat = [\"Sex\", \"Job\", \"Housing\", \"Saving accounts\", \"Checking account\", \"Duration\", \"Purpose\"]\n\nrare_analyser(df, temp_cat, \"Risk\", 0.5)\n\n# rare durations\nnums = [16, 22, 26, 40, 47, 54, 72]\nfor i in nums:\n    df = df.loc[~(df[\"Duration\"] == i)]\n","6904fdfc":"# Nadir s\u0131n\u0131f sorunlar\u0131n\u0131 \u00e7\u00f6zmek i\u00e7in s\u0131n\u0131flar\u0131 birle\u015ftirelim veya silelim.\ndf.loc[df[\"Duration\"] == 5, [\"Duration\"]] = 4\ndf.loc[df[\"Duration\"] == 7, [\"Duration\"]] = 4\ndf.loc[df[\"Duration\"] == 11, [\"Duration\"]] = 4\n\ndf.loc[df[\"Duration\"] == 8, [\"Duration\"]] = 6\ndf.loc[df[\"Duration\"] == 10, [\"Duration\"]] = 6\n\ndf.loc[df[\"Duration\"] == 12, [\"Duration\"]] = 9\n\ndf.loc[df[\"Duration\"] == 24, [\"Duration\"]] = 21\n\ndf.loc[df[\"Duration\"] == 28, [\"Duration\"]] = 27\ndf.loc[df[\"Duration\"] == 30, [\"Duration\"]] = 27\ndf.loc[df[\"Duration\"] == 33, [\"Duration\"]] = 27\n\ndf.loc[df[\"Duration\"] == 42, [\"Duration\"]] = 39\n\ndf.loc[df[\"Purpose\"] == \"domestic appliances\", [\"Purpose\"]] = \"furniture\/equipment\"\n\n# \u0130\u015flemler sonras\u0131 tekrar nadirliklere bakal\u0131m, do\u011fru i\u015flem yapt\u0131k m\u0131?\nrare_analyser(df, temp_cat, \"Risk\", 0.5)\n\n","b0b7036d":"# Age de\u011fi\u015fkeninden, Age_Range kategorik de\u011fi\u015fkeni t\u00fcretiliyor.\nbins = [18, 25, 40, 55, 100]\nnames = ['Young', 'Adult', 'Mature', 'Old']\ndf[\"Age_Range\"] = pd.cut(df['Age'], bins, labels=names)","4e40ed3a":"# Duration de\u011fi\u015fkeninden Year de\u011fi\u015fkeni t\u00fcretiliyor.\n# B\u00f6ylece ka\u00e7 y\u0131ll\u0131k m\u00fc\u015fteri oldu\u011fu anla\u015f\u0131lacak.\ndf[\"Year\"] = str(df[\"Duration\"])\ndf.loc[df[\"Duration\"] <= 12, \"Year\"] = \"0-1 year\"\ndf.loc[(df[\"Duration\"] > 12) & (df[\"Duration\"] <= 24), \"Year\"] = \"1-2 year\"\ndf.loc[(df[\"Duration\"] > 24) & (df[\"Duration\"] <= 36), \"Year\"] = \"2-3 year\"\ndf.loc[(df[\"Duration\"] > 36) & (df[\"Duration\"] <= 48), \"Year\"] = \"3-4 year\"\ndf.loc[(df[\"Duration\"] > 48) & (df[\"Duration\"] <= 60), \"Year\"] = \"4-5 year\"\ndf.loc[(df[\"Duration\"] > 60) & (df[\"Duration\"] <= 72), \"Year\"] = \"5-6 year\"\ndf.loc[(df[\"Duration\"] > 72) & (df[\"Duration\"] <= 84), \"Year\"] = \"6-7 year\"\n","85243a99":"# Status de\u011fi\u015fkeni Credit amount de\u011fi\u015fkeninden t\u00fcreyen, ekonomik s\u0131n\u0131f\u0131 simgeleyen de\u011fi\u015fken.\ndf[\"Status\"] = pd.qcut(df[\"Credit amount\"], 4, labels=[\"poor\", \"mid\", \"upper\", \"rich\"])","03872497":"# Eksik de\u011ferler dolduruluyor.\ndf[\"Saving accounts\"] = df.groupby([\"Sex\", \"Risk\", \"Age_Range\"])[\"Saving accounts\"].transform(\n    lambda x: x.fillna(x.mode()[0]))","4a36e4af":"# Eksik de\u011ferleri groupby alarak mant\u0131kl\u0131 \u015fekilde doldurmaya \u00e7al\u0131\u015fal\u0131m.\ndf[\"Checking account\"] = df.groupby([\"Sex\", \"Risk\", \"Age_Range\"])[\"Checking account\"].transform(\n    lambda x: x.fillna(x.mode()[0]))\n","4f58915b":"# Doldurmadan sonra tekrar nadirliklere bakal\u0131m. Kontrol ama\u00e7l\u0131d\u0131r.\nrare_analyser(df, temp_cat, \"Risk\", 0.5)","1994da71":"# Modele verilmeden \u00f6nce one-hot i\u015fleminden ge\u00e7ecek de\u011fi\u015fkenleri belirleyelim. Ayn\u0131 zamanda say\u0131sal de\u011fi\u015fkenlerimizi de.\ncategorical_columns = [\"Sex\", \"Housing\", \"Saving accounts\",\n                       \"Checking account\", \"Purpose\", \"Age_Range\",\n                       \"Year\"]\n\nnumeric_columns = [\"Age\", \"Job\", \"Credit amount\", \"Duration\"]","e86e5e69":"# De\u011ferler 0-1 \u015feklinde one-hot yard\u0131m\u0131 ile encode edildi.\none_hot_columns = [\"Housing\", \"Saving accounts\", \"Checking account\", \"Purpose\", \"Age_Range\", \"Year\", \"Status\"]\n\ndf, one_hot_encodeds = one_hot_encoder(df, one_hot_columns)","8a228fe0":"# One-hot sonras\u0131 olu\u015fan encode edilmi\u015f de\u011fi\u015fkenler\none_hot_encodeds","91fdec14":"# Verimizi train-test olarak b\u00f6lelim.\nX = df.drop(\"Risk\", axis=1)\ny = np.ravel(df[[\"Risk\"]])\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=357)","d6b04ecf":"# Do\u011fru b\u00f6lm\u00fc\u015f m\u00fcy\u00fcz? \u0130lk 5 g\u00f6zlemine bakal\u0131m.\nX_train.head()","6d47048a":"# Modellerimizde kullan\u0131lacak en iyi parametreyi bulmak i\u00e7in parametreleri belirleyelim. Bu parametreler GridSearchCV ile gezilecek en iyi olan\u0131 se\u00e7ilecek.\nrf_params = {\"max_depth\": [3, 5, 8],\n             \"max_features\": [8, 15, 25],\n             \"n_estimators\": [200, 500, 1000],\n             \"min_samples_split\": [2, 5, 10]}\n\nlgbm_params = {\"learning_rate\": [0.01, 0.1],\n               \"n_estimators\": [200, 500, 1000],\n               \"max_depth\": [3, 5, 8],\n               \"colsample_bytree\": [1, 0.8, 0.5]}\n\nxgb_params = {\"learning_rate\": [0.1, 0.01],\n              \"max_depth\": [3, 5, 8],\n              \"n_estimators\": [200, 500, 1000],\n              \"colsample_bytree\": [0.7, 1]}\n","93c5a888":"# Model nesnelerimizi olu\u015ftural\u0131m.\nrf = RandomForestClassifier(random_state=357)\nlgbm = LGBMClassifier(random_state=357)\nxgb = XGBClassifier(random_state=357)","e6b886e0":"# GridSearchCV yard\u0131m\u0131 ile parametreleri tek tek deneyelim ve en iyi parametreyi bulal\u0131m.\ngs_cv_rf = GridSearchCV(rf,\n                        rf_params,\n                        cv=10,\n                        n_jobs=-1,\n                        verbose=2).fit(X_train, y_train)\n\ngs_cv_lgbm = GridSearchCV(lgbm,\n                          lgbm_params,\n                          cv=10,\n                          n_jobs=-1,\n                          verbose=2).fit(X_train, y_train)\n\ngs_cv_xgb = GridSearchCV(xgb,\n                         xgb_params,\n                         cv=10,\n                         n_jobs=-1,\n                         verbose=2).fit(X_train, y_train)\n","3c9def89":"# Bulunan en iyi parametreler ile modelleri tune edelim.\nrf_tuned = RandomForestClassifier(**gs_cv_rf.best_params_, random_state=357).fit(X_train, y_train)\n\nlgbm_tuned = LGBMClassifier(**gs_cv_lgbm.best_params_, random_state=357).fit(X_train, y_train)\n\nxgb_tuned = XGBClassifier(**gs_cv_xgb.best_params_, random_state=357).fit(X_train, y_train)\n","1436be98":"# Sonu\u00e7lar\nmodels = [(\"RF\", rf_tuned),\n          (\"LGBM\", lgbm_tuned),\n          (\"XGB\", xgb_tuned)]\n\nresults = []\nnames = []\n\nfor name, model in models:\n    y_pred = model.predict(X_test)\n    acc = accuracy_score(y_test, y_pred)\n    msg = \"%s: (%f)\" % (name, acc)\n    print(msg)","4b6de687":"### Feature Engineering","d38648b5":"\n# Problem\n\n\n\n**Kredi riski s\u0131n\u0131fland\u0131rmak \u00fczere bir makine \u00f6\u011frenmesi modeli kurmak.**\n\n**Veri Seti Hikayesi**\n\nVeri seti kayna\u011f\u0131: https:\/\/archive.ics.uci.edu\/ml\/datasets\/statlog+(german+credit+data)\n\n- **1000 bireye ait g\u00f6zlemler var.**\n\n**De\u011fi\u015fkenler**\n\n- **Age**: Ya\u015f\n\n- **Sex**: Cinsiyet\n\n- **Job**: Meslek-Yetenek (0 - unskilled and non-resident, 1 - unskilled and resident, 2 - skilled, 3 - highly skilled)\n\n- **Housing**: Bar\u0131nma Durumu (own, rent, or free)\n\n- **Saving accounts**: Tasarruf Durumu (little, moderate, quite rich, rich)\n\n- **Checking account**: Vadesiz Hesap (DM - Deutsch Mark)\n\n- **Credit amount**: Kredi Miktar\u0131 (DM)\n\n- **Duration**: S\u00fcre (month)\n\n- **Purpose**: Ama\u00e7 (car, furniture\/equipment, radio\/TV, domestic appliances, repairs, education, business, vacation\/others)\n\n- **Risk**: Risk (Good, Bad Risk)\n    \n\n"}}