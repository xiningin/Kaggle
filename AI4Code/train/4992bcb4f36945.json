{"cell_type":{"d158abbf":"code","28e8715e":"code","ab00be72":"code","bab6c5e8":"code","4db53d91":"code","c94bf723":"code","0b09beea":"code","30190e70":"code","2f4c63f9":"code","5af78777":"code","9c87e46b":"code","a11abd7b":"code","3b607b7e":"code","28df4678":"code","806b77b3":"code","89dd84d8":"code","c476f2db":"code","b165980c":"code","2483a2cd":"code","b482ab1d":"code","483f5b39":"code","495d0cbc":"code","dd743c9d":"code","42369c12":"code","5942a083":"code","edbd3835":"code","1c83e17f":"code","b88c99f6":"code","0a0ab6b0":"code","564c67be":"code","e33387ea":"code","97b552d2":"code","d9fe4ad8":"code","b8024ebd":"code","5ca01b10":"code","ee4ee292":"code","065da2ea":"code","0d283c65":"code","de457811":"code","046c7de8":"code","fb0f035f":"code","ddab072b":"code","c5b63858":"code","4605d452":"code","17ce26c8":"markdown","adc16a7a":"markdown","0447243a":"markdown","e42d6307":"markdown","70aea614":"markdown","683fa648":"markdown","af202f8f":"markdown","65ce6cf9":"markdown","959ea653":"markdown","f42a34ca":"markdown","bec9cfad":"markdown","89b0ec25":"markdown","0de2f8f2":"markdown","23927332":"markdown","12af5745":"markdown","fc2bbe2d":"markdown","0f39e0c7":"markdown","36c1b246":"markdown","5e400936":"markdown","6a220cc7":"markdown","72371c59":"markdown","3730530e":"markdown"},"source":{"d158abbf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","28e8715e":"#import libaries\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly\nimport plotly.express as px\nfrom sklearn.model_selection import train_test_split\nimport statsmodels.api as sm\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error","ab00be72":"#Load Data\ndf=pd.read_csv('..\/input\/data-science-jobs\/Data_Science_Jobs.csv')","bab6c5e8":"#get first n rows\ndf.head()","4db53d91":"#check datatypes\ndf.dtypes","c94bf723":"#check missing column and count total missing column \nmissing_val_count_by_column=(df.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column>0])\ntotal_missing_column=df.isnull().any().sum()\nprint(\"Total no of column containg missing values :\",total_missing_column)","0b09beea":"#Rename titles\ndict={'Title':'Job Title','Title2':'Company Name','Keywords':'Min Experince','Skll6':'Skill6'}\ndf.rename(columns=dict,inplace=True)\n","30190e70":"# drop column with high missing value \ndf.drop(['Type','Type13','View','Keywords5','Industry_Type_2','Employment_Type'],axis=1,inplace=True)\n","2f4c63f9":"#fill missing value\ndf['starrating'].fillna(df['starrating'].mean(),inplace=True)\n","5af78777":"#drop rows with missing value\ndf.dropna(subset=[\"Skill5\",'Skill6','Skill7','Skill8','Role','Industry_Type_1','Functional_Area','Role_Category'],inplace=True)\ndisplay(df)","9c87e46b":"#Extracting only minimum years of experience \ndf['Min Experince'] = df['Min Experince'].apply(lambda x :x.split('-')[0])\n#value_count\ndf['Min Experince'].value_counts()\n","a11abd7b":"#Cleaning 'Location Column'\ndf['Location']=df['Location'].apply(lambda x:x.split('(')[0])\ndf['Location']=df['Location'].apply(lambda x:x.split(',')[0])\ndf['Location']=df['Location'].apply(lambda x:x.split('\/')[0])\n#sort index\ndf['Location'].value_counts().sort_index()","3b607b7e":"#Identifying similiar cities with different names and renaming them\ndf['Location'].replace({'Delhi NCR':'Delhi','Navi Mumbai':'Mumbai','Banaglore':'Bengaluru','Mumbai Suburbs':'Mumbai','Gurgaon Gurugram':'Gurgaon'},inplace=True)\ndf.Location.replace(['Not specified','India','india','Remote','Multiple'], 'Not Specified', inplace=True)\ndf['Location'].value_counts().sort_index()","28df4678":"#Cleaning Salary column \n#Replacing 'Not disclosed' with NaN \ndf['Salary']=df['Salary'].replace('Not disclosed','NaN').astype(object)","806b77b3":"#Spearate column for PA\ndf['PA']=df['Salary'].apply(lambda x: 1 if 'PA' in x else 0)","89dd84d8":"#Cleaning Salary \ndf['Salary']=df['Salary'].apply(lambda x:x.replace('PA',''))\ndf['Salary']=df['Salary'].apply(lambda x:x.replace(',','').replace('.',''))","c476f2db":"#Spearating Minimun and Maximum Salary \ndf['Min_Salary']= df['Salary'].apply(lambda x:min(str(x).split('-')))\ndf['Max_Salary']= df['Salary'].apply(lambda x:max(str(x).split('-')))","b165980c":"#Converting Min & Max salary datatypes \ndf['Min_Salary']=df['Min_Salary'].astype(float)\ndf['Max_Salary']=df['Max_Salary'].astype(float)\ndf.dtypes","2483a2cd":"#Filling NAN \ndf['Min_Salary'].fillna(df['Min_Salary'].mean(),inplace=True)\ndf['Max_Salary'].fillna(df['Max_Salary'].mean(),inplace=True)\ndisplay(df)","b482ab1d":"#Checkin any missing value\ndf['Max_Salary'].isnull().sum()\ndf['Min_Salary'].isnull().sum()","483f5b39":"#New avg salary column \ndf['avg_salary']=(df['Min_Salary']+df['Max_Salary'])\/2","495d0cbc":"#droping salary column to clean dataset \ndf_out=df.drop(['Salary'],axis=1)\ndisplay(df)","dd743c9d":"#Transefering  clean dataset \ndf_out.to_csv('Salary_data_cleaned.csv',index=False)","42369c12":"data=pd.read_csv('Salary_data_cleaned.csv')\ndata.head()\n","5942a083":"#plot starrating\ndata.starrating.hist()","edbd3835":"#plot avg salary\ndata.avg_salary.hist()","1c83e17f":"#boxplot avg salary and starrating\ndata.boxplot(column=['avg_salary','starrating'])","b88c99f6":"#Find Top Location \nLocs=pd.DataFrame(data=data.Location.value_counts())\nLocs.reset_index(inplace=True)\nLocs.columns=['Location','counts']\nfig=px.pie(Locs,values='counts',names='Location')\nfig.update_traces(textposition='inside',textinfo='percent+label')\nfig.show()\nprint(Locs)","0a0ab6b0":"#Location with Max Salary \nplt.bar(data['Location'],data['Max_Salary'],color='Green')\nplt.xticks(rotation=90)\nplt.xlabel('Location')\nplt.ylabel('Max_Salary')\nplt.show()","564c67be":"#Find Minimum Experience\nExperince=pd.DataFrame(data=data['Min Experince'].value_counts())\nExperince.reset_index(inplace=True)\nExperince.columns=['Min Experince','counts']\nfig=px.pie(Experince,values='counts',names='Min Experince')\nfig.update_traces(textposition='inside',textinfo='percent+label')\nfig.show()\nprint(Experince)","e33387ea":"#Find top Role Category\nRole=pd.DataFrame(data=data.Role_Category.value_counts())\nRole.reset_index(inplace=True)\nRole.columns=['Role_Category','counts']\nimport plotly.express as px\nfig = px.pie(Role, values='counts', names='Role_Category')\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()","97b552d2":"df = px.data.tips()\nfig = px.sunburst(data, path=['Role_Category','Role' ])\nfig.show()","d9fe4ad8":"#Top Skills\nSkills=data.Skill1.append([data.Skill2,data.Skill3,data.Skill4,data.Skill5,data.Skill6,data.Skill7,data.Skill8])\nSkills=Skills.str.lower() #Converting all the entries to lower case\nSkills.value_counts()\n\nSkill=pd.DataFrame(data=Skills.value_counts().head(20))\nSkill.reset_index(inplace=True)\nSkill.columns=['Skills','counts']\nimport plotly.express as px\nfig = px.pie(Skill, values='counts', names='Skills')\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()\n\n","b8024ebd":"#check columns\ndata.columns","5ca01b10":"#Build Models\ndf_model=data[['starrating','Skill1', 'Skill2', 'Skill3','Skill4', 'Skill5', 'Skill6', 'Skill7',\n       'Skill8','Min Experince','avg_salary','Role']]","ee4ee292":"#get dummy data\ndf_dum = pd.get_dummies(df_model)\ndisplay(df_dum)","065da2ea":"# train_test_split\nX=df_dum.drop('avg_salary',axis=1)\ny=df_dum.avg_salary.values\ntrain_X,test_X,train_y,test_y= train_test_split(X,y,train_size=0.8,test_size=0.2,random_state=42)","0d283c65":"#multiple linear regression \n\nX_sm= X = sm.add_constant(X)\nmodel=sm.OLS(y,X_sm)\nmodel.fit().summary()","de457811":"#Linear Regression\nlm=LinearRegression()\nlm.fit(train_X,train_y)\n\nnp.mean(cross_val_score(lm,train_X,train_y,scoring='neg_mean_absolute_error',cv=3))","046c7de8":"#RandomForest\nrf=RandomForestRegressor()\nrf.fit(train_X,train_y)\n\nnp.mean(cross_val_score(rf,train_X,train_y, scoring='neg_mean_absolute_error',cv=3))\n","fb0f035f":"#test model\ntpred_lm=lm.predict(test_X)\ntpred_rf=rf.predict(test_X)","ddab072b":"#MAE of test_y and testmodel predict lm\nmean_absolute_error(test_y,tpred_lm)","c5b63858":"#MAE of test_y and testmodel predict rf\nmean_absolute_error(test_y,tpred_rf)","4605d452":"mean_absolute_error(test_y,(tpred_lm+tpred_rf)\/2)","17ce26c8":"Extracting minimum year of experience using lambda function and spliting ","adc16a7a":"**Observation** : The top 3 location with Max_Salary for Data Science related job are:\n\n1.Bengaluru\n\n2.Delhi\n\n3.Chennai","0447243a":"we are 175 thousand off\n","e42d6307":"**Data Cleaning**","70aea614":"Cleaning Location column using lambda function  and sorting it using index","683fa648":"**Top 5 Skills data science**\n\nmachine learning\n\npython\n\nit skills\n\nbig data\n\nartificial intelligence","af202f8f":"Mean absolute error :64944","65ce6cf9":"****Model Building ****","959ea653":"Out of two model we came to conclusion that random forest works the best ","f42a34ca":"Mean absolute error:182525","bec9cfad":"**Top Role Categories**\n\nProgramming & Design\n\nAnalytics & BI\n\nSenior Management","89b0ec25":"This show the total missing value in each column and total no of column containg missing value .","0de2f8f2":"Renaming titles  using dictionary","23927332":"importing all necessary libaries","12af5745":"**Observation:** The top 5 location for Data Science related jobs are :\n\n1.Bengaluru with 38.8%\n\nMumbai with 9.58%\n\nPune with 8.11 %\n\nChennai with 6.88%\n\nDelhi with 6.38%","fc2bbe2d":"**Inspect Dataset**","0f39e0c7":"Transfering cleaned dataset to new csv","36c1b246":"Here we are 95 thousand off . So , this is the better result","5e400936":"**Loading Dataset**","6a220cc7":"**Data Analysis**","72371c59":"Hi,this is the first time I am making a contribution at kaggle .I like to give credit to  \"Nicky Eapen\" for his previous work with this dataset, it helped me a lot to contribute on this dataset .\n \n \n In this, we are going to anaylsis the datascience  job oppuruninty based on location, role,skill and make some prediction using salary .","3730530e":"**Observation:**\n\n17% of job posting requires 2year of minimum experince.\n\n10% of job posting are favourable for freshers with no experience.\n\nMore than 30% of job posting requires above 5 year of experince."}}