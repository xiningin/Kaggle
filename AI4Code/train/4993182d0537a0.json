{"cell_type":{"b12befa0":"code","f120a6ae":"code","31a464c1":"code","b1cfc41f":"code","a85bc3f6":"code","54d27d78":"code","42f4b9ef":"code","5cc7607d":"code","f1e6b520":"code","7ec249e0":"code","e01dc4ce":"code","8b3bc36c":"code","17a473a0":"code","f7e3b7d7":"code","42138063":"code","30719305":"code","ce4994be":"markdown","f1040660":"markdown","94d72df4":"markdown","37b8ae6f":"markdown","b8da1cdc":"markdown","12df41d2":"markdown","0c477ac5":"markdown","ba3f0c04":"markdown","75eb4db7":"markdown","d66f76d8":"markdown","4cace3e5":"markdown","d00e7713":"markdown","1171259b":"markdown","d5bc4730":"markdown","e1b605b6":"markdown","a467562a":"markdown"},"source":{"b12befa0":"from shutil import copyfile\n","f120a6ae":"copyfile(src=\"..\/input\/regressionmpdel\/regressionModel.py\",dst=\"..\/working\/regressionModel.py\")","31a464c1":"import regressionModel as rm\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm","b1cfc41f":"data = pd.read_csv(\"..\/input\/housesalesprediction\/kc_house_data.csv\")","a85bc3f6":"data.head()","54d27d78":"data.dtypes","42f4b9ef":"data = data.drop([\"id\",\"date\"],axis=1)\n","5cc7607d":"x = data.values\ny = np.expand_dims(x[:,0],axis=1)","f1e6b520":"x = np.delete(x,0,1)","7ec249e0":"x = rm.preProcess(x)","e01dc4ce":"a = int(x.shape[0] * 0.6)\nb = int(x.shape[0] * 0.2)\nxt = x[:a]\nyt = y[:a]\nxc = x[a:a+b]\nyc = y[a:a+b]\nxte = x[a+b:]\nyte = y[a+b:]\ntheta0 = np.random.random((x.shape[1],1))\nl = 0","8b3bc36c":"alphas = [0.001,0.01,0.1]\nnIterations = range(200)\nfor i,alpha in enumerate(alphas,1):\n    c = []\n    for nIter in tqdm(nIterations):\n        t = rm.gradientDescent(xc,yc,theta0,alpha,l,nIter)\n        c.append(rm.cost(xc,yc,t,0))\n    plt.plot(nIterations,c)\nplt.legend(alphas)\nplt.show()","17a473a0":"c1,c2 = [],[]\nnExp = range(1,a)\nfor i in tqdm(nExp):\n  t = rm.gradientDescent(xt[:i],yt[:i],theta0,0.1,l,25)\n  c1.append(rm.cost(xc,yc,t,0))\n  c2.append(rm.cost(xt,yt,t,0))","f7e3b7d7":"plt.plot(nExp,c1)\nplt.plot(nExp,c2)\nplt.legend([\"cross validation set\",\"training set\"])\nplt.show()","42138063":"theta = rm.gradientDescent(xt,yt,theta0,0.1,l,25)","30719305":"print(\"error: \",\"{:.2f}\".format(np.mean(100 * np.absolute(rm.predict(xc,theta) - yc)\/yc)),\"%\")","ce4994be":"<a id=\"train\"><\/a>\n<h2>5.Training the model<\/h2>","f1040660":"We see here that except the date all the other features are real numbers<\/p>\nSince we don't need the if and date, let's remove them","94d72df4":"We see here that 0.1 is the best learning rate with less than 25 iteration","37b8ae6f":"<a id=\"conclusion\"><\/a>\n<h2>6.Conclusion<\/h2>","b8da1cdc":"We see here that the cost stabilizes after a 1000 examples or so","12df41d2":"<a id=\"data\"><\/a>\n<h2>2.Inspecting and cleaning the Data<\/h2>","0c477ac5":"Now, we will seperate the set into 3 sets:\n<br>A training set with 60%\n<br>A cross validation set with 20%\n<br>A test set with 20%","ba3f0c04":"<a id=\"selection\"><\/a>\n<h2>4.Parameters selection<\/h2>","75eb4db7":"<nav>\n    <h1>Table of Content<\/h1>\n    <h5 style=\"padding-left:5%;\"><a href=\"#overview\">1.Problem overview<\/a><\/h5>\n    <h5 style=\"padding-left:5%;\"><a href=\"#data\">2.Inspecting and cleaning the Data<\/a><\/h5>\n    <h5 style=\"padding-left:5%;\"><a href=\"#setup\">3.Setting up the Data set<\/a><\/h5>\n    <h5 style=\"padding-left:5%;\"><a href=\"#selection\">4.Parameters selection<\/a><\/h5>\n    <h5 style=\"padding-left:5%;\"><a href=\"#train\">5.training the model<\/a><\/h5>\n    <h5 style=\"padding-left:5%;\"><a href=\"#conclusion\">6.Conclusion<\/a><\/h5>\n<\/nav>","d66f76d8":"Here will plot the cost against the number of iterations which also gives us the best learning rate,the cost against the number of examples and the cost against the regularization parameter","4cace3e5":"<a id=\"setup\"><\/a>\n<h2>3.Setting up the Data set<\/h2>","d00e7713":"Now, we will convert the data which is a pandas dataframe into a numpy matrix<\/p>\nWe will then seperate our prediction target from the set","1171259b":"<p>Let's first start with loading and inspecting the data<\/p>","d5bc4730":"Here, preProcess is used to normalize the features so that the convergence is faster","e1b605b6":"<p>\nWelcome, in this notebook we will be treating a linear regression problem which deals with predicting the price of houses we will solve this using gradient descent<\/p>\n<p>This dataset contains house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015.<\/p>","a467562a":"<a id=\"overview\"><\/a>\n<h2>1.Overview<\/h2>"}}