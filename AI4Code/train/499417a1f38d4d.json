{"cell_type":{"e55368d8":"code","ce324997":"code","3d04ab6f":"code","7aa31a25":"code","cbb46fc2":"code","b12623b1":"code","45b1bf83":"code","dcca45fb":"code","d630ed5d":"code","8f29de20":"code","a00fec73":"code","8ffb581c":"markdown","5ad2ee95":"markdown","1227d9ec":"markdown","72ff51da":"markdown","5efa452c":"markdown","0e162dd7":"markdown","663d8699":"markdown","8a0586dd":"markdown","2104c0f9":"markdown","e54dc9ff":"markdown","f5a69ad5":"markdown","224478f9":"markdown"},"source":{"e55368d8":"import pandas as pd\nimport numpy as np","ce324997":"datasix1 = pd.read_csv('\/kaggle\/input\/human-gait-phase-dataset\/data\/GP1_0.6_marker.csv')\ndataseven2 = pd.read_csv('\/kaggle\/input\/human-gait-phase-dataset\/data\/GP1_0.7_marker.csv')\ndatasix1.head()","3d04ab6f":"data1 = pd.DataFrame({'secim':np.zeros(12000)})\ndata2 = pd.DataFrame({'secim':np.ones(12000)})\n\ndata2 = pd.concat([dataseven2,data2],axis=1)\ndata1 = pd.concat([datasix1,data1],axis=1)\n\ndata = data1.append(data2,ignore_index=True)\ndata.head()","7aa31a25":"x = data.drop([\"secim\"],axis=1)\ny = data.secim.values\nx.head()","cbb46fc2":"from sklearn.model_selection import train_test_split\nx_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=1)","b12623b1":"from sklearn.svm import SVC\n\nsvm = SVC(random_state = 1)\nsvm.fit(x_train,y_train)\nprint(\"acc of svm is :\",svm.score(x_test,y_test))","45b1bf83":"from sklearn.naive_bayes import GaussianNB\n\nnb = GaussianNB()\nnb.fit(x_train,y_train)\nprint('accuracy of bayes in test data is :', nb.score(x_test,y_test))","dcca45fb":"from sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier()\ndt.fit(x_train,y_train)\nprint('Accuracy of dec tree in test data is:',dt.score(x_test,y_test))","d630ed5d":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators=100,random_state=1)\nrf.fit(x_train,y_train)\nprint('Random Forest accuracy on test data is : ',rf.score(x_test,y_test))","8f29de20":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(x_train,y_train)\nprint(\"test accuracy for Log Regressin is  {}\".format(lr.score(x_test,y_test)))","a00fec73":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors = 3) #n_neighbors = k\nknn.fit(x_train,y_train)\nprediction = knn.predict(x_test)\n\nprint(\"k={} nn score:{}\".format(3,knn.score(x_test,y_test)))","8ffb581c":"**Let's try SVM.**","5ad2ee95":"**As You see above, we use diffrent classifiers to understand the data is from 0.6 or 0.7 m\/s speed data.You can enhance the data and have better classifiers.Have Fun! :)**","1227d9ec":"**Naive Bayes Classifier**","72ff51da":"**Decision Tree Classifier.**","5efa452c":"**Let's import the data of 1st subject with 0.6 and 0.7 m\/s speed.**","0e162dd7":"**Random Forest Classifier**","663d8699":"**Here, I will show you some classifier examples.I just used 0.6 and 0.7 m\/s speed data to classify, but you can enhance the data and have a better classifier.I just show you simple classifier examples.**","8a0586dd":"**Knn with k = 3**","2104c0f9":"*Combine both 0.7 and 0.6 speed data with class of 0.6 m\/s speed data is 0 and class of 0.7 m\/s speed data is 1.* **Secim = class**","e54dc9ff":"**Logistic Regression Classifier**","f5a69ad5":"**Let's split the data as train and test.**","224478f9":"**Y = secim = classes , \nx = data without classes**"}}