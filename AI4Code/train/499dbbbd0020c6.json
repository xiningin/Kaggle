{"cell_type":{"3d890bb6":"code","89b9ee07":"code","13e69e9a":"code","80e03a63":"code","7e372982":"code","a050aae5":"code","d37f7586":"code","f8243968":"code","27ebde8b":"code","1e22d778":"code","6aaf8f05":"code","652c7349":"code","9a61401b":"code","6b8f78c5":"code","8b727149":"code","80455921":"code","95d39ee0":"code","346a1f38":"code","3f7552ca":"code","a40cb820":"code","592c37e0":"code","4dbda5cd":"code","c84719ed":"code","7c4b678a":"code","c343c5fd":"code","011e4af1":"code","50909405":"markdown","e459c9fd":"markdown"},"source":{"3d890bb6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","89b9ee07":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly as py\n\nimport plotly.graph_objs as go\nfrom sklearn.cluster import KMeans\n\nfrom scipy.cluster.hierarchy import linkage, dendrogram\nfrom sklearn.cluster import AgglomerativeClustering\n\nimport warnings\nimport os\n#\u00e7al\u0131\u015fma dizinimiz.\nprint(os.listdir(\"..\/input\"))","13e69e9a":"# We read the data.\ndata = pd.read_csv('..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv')","80e03a63":"data.head()","7e372982":"data.shape","a050aae5":"data.info()","d37f7586":"data.describe()","f8243968":"data.dtypes","27ebde8b":"print(pd.isnull(data).sum())","1e22d778":"data.corr()","6aaf8f05":"plt.figure(figsize=(4,4))\nsns.heatmap(data.corr(),annot=True)\nplt.show()","652c7349":"sns.pairplot(data)\nplt.show()","9a61401b":"labels=['Male','Female']\nsizes=[data.query('Gender==\"Male\"').Gender.count(),data.query('Gender==\"Female\"').Gender.count()]\nexplode = [0, 0.1]\ncolors = ['#12b3ff','#ffaaB9']\nplt.pie(sizes,labels=labels,colors=colors,explode=explode,shadow = False, autopct = '%.2f%%')\nplt.show()","6b8f78c5":"plt.figure(figsize=(15,4))\nsns.countplot(data.Age)\nplt.xlabel('Age')\nplt.ylabel('Number of People')\nplt.show()","8b727149":"plt.figure(1 , figsize = (15 , 6))\nfor gender in ['Male' , 'Female']:\n    plt.scatter(x = 'Age' , y = 'Annual Income (k$)' , data = data[data['Gender'] == gender] ,\n                s = 200 , alpha = 0.5 , label = gender)\nplt.xlabel('Age'),\nplt.ylabel('Annual Income') \nplt.title('Age vs Annual Income')\nplt.legend()\nplt.show()","80455921":"plt.figure(figsize=(20,7))\ngender = ['Male', 'Female']\nfor i in gender:\n    plt.scatter(x='Age',y='Spending Score (1-100)', data=data[data['Gender']==i],s = 200 , alpha = 0.5 , label = i)\nplt.legend()\nplt.xlabel(\"Age\")\nplt.ylabel(\"Spending Score (1-100)\")\nplt.title(\"Spending Score According to Age\")\nplt.show()","95d39ee0":"plt.figure(1 , figsize = (15 , 7))\nn = 0 \nfor cols in ['Age' , 'Annual Income (k$)' , 'Spending Score (1-100)']:\n    n += 1 \n    plt.subplot(1 , 3 , n)\n    plt.subplots_adjust(hspace = 0.5 , wspace = 0.5)\n    sns.violinplot(x = cols , y = 'Gender' , data = data, palette = 'vlag')\n    sns.swarmplot(x = cols , y = 'Gender' , data = data)\n    plt.ylabel('Gender' if n == 1 else '')\n    plt.title('Boxplots & Swarmplots' if n == 2 else '')\nplt.show()","346a1f38":"#We have determined that we will use the attributes in columns 2 through 4.\nX=data.iloc[:, [2,4]].values","3f7552ca":"# We use the bracket method to find the number of clusters.\n#For this, we must first find WCSS(the within\u200b-cluster sum of squares).\n#We will calculate the variation of WCSS with the number of clusters.\n#WCSS(the sum of the squares of the distances of each data point in all clusters from their respective center points\u0131)\n\n\n# We create an empty list.\nwcss = []\n#For the number of clusters, we create an increasing list from 1 to 10 with the range() function.\nfor i in range(1,11):\n    #K-means s\u0131n\u0131f\u0131ndan bir nesne \u00fcretiyoruz.\n    kmeans = KMeans(n_clusters= i, max_iter = 300, init='k-means++', n_init = 10, random_state=0)\n    #K\u00fcmeleme i\u015flemi yap\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\n#While creating an object we are sending some parameters to the constructor function (__init__).\n#The first of these is n_clusters, which is the number of clusters.\n#The for loop gives the number of clusters as a parameter to n_clusters, increasing by one each time it returns with the variable i. \n#The init parameter specifies the ideal cluster centers to select the starting points.\n#The kmeans++ parameter saves us from the random initialization trap, it allows us to choose good starting points.\n#The next parameter max_iter determines the maximum number of iterations the algorithm can take to reach its final state, the default is 300.\n#n_init determines how many different points the cluster center starting point can start from.\n#The last parameter, random_state, ensures that anyone who executes these operations will get the same results. \n#After the object is created, we perform the data fit with the object with the fit() method.\n#We give the X that we created earlier as a parameter.\n#We add the inerita_ property of the kmeans object to the wcss list we created before the for loop.  \nplt.figure(figsize=(10,3))\nplt.plot(range(1,11),wcss)\nplt.xlabel(\"number of k (cluster) value\")\nplt.ylabel(\"wcss\")\nplt.show()","a40cb820":"\n#We see from the chart that the ideal number of clusters would be 4. Now we repeat the working line for the set number 5 in the for loop.\n#We are creating an object of class K-means.\nkmeansmodel = KMeans(n_clusters= 4, init='k-means++', max_iter = 300, n_init = 10, random_state=0)\n\n\n#Cluster and predict\ny_kmeans= kmeansmodel.fit_predict(X)\n\n\n# We have determined the cluster center points.\ncentroids1 = kmeansmodel.cluster_centers_\n\n# Shows clusters on graph\nplt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, label = 'Cluster 1')\nplt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, label = 'Cluster 3')\nplt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 100, label = 'Cluster 4')\n\nplt.scatter(x = centroids1[: , 0] , y =  centroids1[: , 1] , s = 300 , c = 'yellow' , alpha = 0.8)\nplt.title('Clusters of Customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\n\nplt.legend()\nplt.show()","592c37e0":"x = data[['Age', 'Spending Score (1-100)', 'Annual Income (k$)']].values\nkm = KMeans(n_clusters = 5, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\nkm.fit(x)\nlabels = km.labels_\ncentroids = km.cluster_centers_","4dbda5cd":"import plotly.offline as py\nfrom plotly.offline import init_notebook_mode, iplot\n\ndata['labels'] =  labels\ntrace1 = go.Scatter3d(\n    x= data['Age'],\n    y= data['Spending Score (1-100)'],\n    z= data['Annual Income (k$)'],\n    mode='markers',\n     marker=dict(\n        color = data['labels'], \n        size= 10,\n        line=dict(\n            color= data['labels'],\n            width= 12\n        ),\n        opacity=0.8\n     )\n)\ndf = [trace1]\n\nlayout = go.Layout(\n    title = 'Character vs Gender vs Alive or not',\n    margin=dict(\n        l=0,\n        r=0,\n        b=0,\n        t=0  \n    ),\n    scene = dict(\n            xaxis = dict(title  = 'Age'),\n            yaxis = dict(title  = 'Spending Score'),\n            zaxis = dict(title  = 'Annual Income')\n        )\n)\n\nfig = go.Figure(data = df, layout = layout)\npy.iplot(fig)","c84719ed":"# We imported the AgglomerativeClustering class\nfrom sklearn.cluster import AgglomerativeClustering","7c4b678a":"# We generated an object from AgglomerativeClustering class\n# n_clusters = Number of clusters we will allocate\n# linkage and affinity = distance measurement methods\n# Changing the linkage and affinity parameters affects the success rate.\nag=AgglomerativeClustering(n_clusters=4,affinity='euclidean',linkage='ward')\n\n#Make clustering and prediction\npredict=ag.fit_predict(x)","c343c5fd":"# Dendogram graph display\nimport scipy.cluster.hierarchy as sch","011e4af1":"# x = our data\n# method = We give the same parameter as the linkage parameter of AgglomerativeClustering. ( 'ward' )\ndendrogram=sch.dendrogram(sch.linkage(x,method='ward'))\nplt.show()","50909405":"**K-Means**","e459c9fd":"**Elbow Method**"}}