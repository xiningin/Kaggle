{"cell_type":{"75ffca62":"code","0520a157":"code","0586f661":"code","b97eb73a":"code","a63c2ae0":"code","9353606c":"code","8b613a3f":"code","9b86f365":"code","a28ac33c":"code","b6c8c2f3":"code","0835de00":"code","4d7e26d4":"code","a3a59a79":"code","471062fe":"code","c91a81e3":"code","24424e42":"code","ddd9f5c2":"code","f61c301c":"code","be6e56bf":"code","f3ed5ea9":"code","1afc1d1e":"code","2c4aa101":"code","4eee4740":"code","2ff1bb51":"code","2fd24703":"code","940cfd0a":"code","a8c6c345":"code","87940a26":"code","92857907":"code","e6dfd125":"code","3c01a7a6":"code","e890022d":"code","6d067f3f":"markdown","d8a69b1c":"markdown","eabaa27f":"markdown","4937a642":"markdown","63a0eaea":"markdown","1dd0cf77":"markdown","095b7bc9":"markdown","710a5efd":"markdown","409e214a":"markdown","6fc449c4":"markdown","ab2877d3":"markdown","5740bd3d":"markdown","9b4271b4":"markdown","7a721c3b":"markdown","11473463":"markdown","70a6b3d5":"markdown","8225cc4e":"markdown","6a70d046":"markdown","00f9a70c":"markdown","a3c85090":"markdown","2d90bd39":"markdown","0086a07f":"markdown","cfaafcd9":"markdown","137b1f45":"markdown","6623a0ad":"markdown","d9f59d71":"markdown","5e8ffaf8":"markdown","3e3c4760":"markdown","2148e388":"markdown","1e612baa":"markdown","09d1c2a5":"markdown","bfb616ba":"markdown","c50a711e":"markdown","93cb00a5":"markdown","bb6b03a0":"markdown","4c547a07":"markdown","ab25057c":"markdown","58fef387":"markdown","fa31165f":"markdown","1c647c41":"markdown","70b35e1e":"markdown","ca45b820":"markdown","b7bb967c":"markdown","4eab61bf":"markdown","dc4d18c7":"markdown","02a07f4f":"markdown","0a209988":"markdown"},"source":{"75ffca62":"from IPython.display import Image","0520a157":"Image(\"..\/input\/kaggle-survey-image\/Kaggle.png\", width ='1000')","0586f661":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport squarify\nplt.style.use('fivethirtyeight')\n# You Can Change \nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport base64\nimport io\nfrom scipy.misc import imread\nimport codecs\nfrom IPython.display import HTML\nfrom matplotlib_venn import venn3\nimport re","b97eb73a":"survey_2019 = pd.read_csv('..\/input\/kaggle-survey-2019\/multiple_choice_responses.csv')\nquestion_2019 = pd.read_csv('..\/input\/kaggle-survey-2019\/questions_only.csv')\ncolumns_multiple_2019 = [col for col in list(survey_2019.columns) if re.search('Part_\\d{1,2}$', col)]\nmultiple_columns_list_2019 = [ [col]+col.split('_') for col in columns_multiple_2019 ]\nqa_multiple_2019 = pd.DataFrame(multiple_columns_list_2019).groupby([1])[0].apply(list)\nquestion_numbers_list_2019 = sorted([int(i.split('Q')[1]) for i in list(qa_multiple_2019.index)])\nquestion_list_2019 = [ 'Q{}'.format(i) for i in question_numbers_list_2019]\n#questions_2019 = ''.join([f'<li>{i}<\/li>' for i in question_list_2019])\nsurvey_2019['year'] = '2019'\n\nsurvey_2018 = pd.read_csv('..\/input\/kaggle-survey-2018\/multipleChoiceResponses.csv')\nquestion_2018 = pd.read_csv('..\/input\/kaggle-survey-2018\/SurveySchema.csv').iloc[0:1]\ndel question_2018['2018 Kaggle Machine Learning and Data Science Survey']\ncolumns_multiple_2018 = [col for col in list(survey_2018.columns) if re.search('Part_\\d{1,2}$', col)]\nmultiple_columns_list_2018 = [ [col]+col.split('_') for col in columns_multiple_2018 ]\nqa_multiple_2018 = pd.DataFrame(multiple_columns_list_2018).groupby([1])[0].apply(list)\nquestion_numbers_list_2018 = sorted([int(i.split('Q')[1]) for i in list(qa_multiple_2018.index)])\nquestion_list_2018 = [ 'Q{}'.format(i) for i in question_numbers_list_2018]\n#questions_2018 = ''.join([f'<li>{i}<\/li>' for i in question_list_2018])\nsurvey_2018['year'] = '2018'\n\nsurvey_2017 = pd.read_csv('..\/input\/kaggle-survey-2017\/multipleChoiceResponses.csv',encoding='ISO-8859-1')\nsurvey_2017['year'] = '2017'","a63c2ae0":"plt.subplots(figsize = (20, 20))\ngender_2019 = survey_2019[['year','Q2']].rename(columns = {'Q2' : 'GenderSelect'}).iloc[1:,]\ngender_2018 = survey_2018[['year','Q1']].rename(columns = {'Q1' : 'GenderSelect'}).iloc[1:,]\ngender_2017 = survey_2017[['year','GenderSelect']]\ngender_data = pd.concat([gender_2019,gender_2018,gender_2017])\ngender_data_prop = gender_data['GenderSelect'].groupby(gender_data['year']).value_counts(normalize = True).rename ('Prop').reset_index()\n\nsns.barplot(gender_data_prop['Prop'], gender_data_prop['GenderSelect'],palette='inferno_r', hue =gender_data_prop['year'])\nplt.legend()\nplt.show()","9353606c":"# tranform percentage\ncountry_2019 = survey_2019[['year','Q3']].rename(columns = {'Q3' : 'Country'}).iloc[1:,]\ncountry_2018 = survey_2018[['year','Q3']].rename(columns = {'Q3' : 'Country'}).iloc[1:,]\ncountry_2017 = survey_2017[['year','Country']]\ncountry_2019_prop = country_2019['Country'].groupby(country_2019['year']).value_counts(normalize = True).rename ('Prop').sort_values(ascending=False)[:10].reset_index()\ncountry_2018_prop = country_2018['Country'].groupby(country_2018['year']).value_counts(normalize = True).rename ('Prop').sort_values(ascending=False)[:10].reset_index()\ncountry_2017_prop = country_2017['Country'].groupby(country_2017['year']).value_counts(normalize = True).rename ('Prop').sort_values(ascending=False)[:10].reset_index()\n\n# plot\nf,ax=plt.subplots(1,3,figsize=(25,15))\nsns.barplot('Prop','Country', data=country_2019_prop , palette='inferno',ax=ax[0])\nax[0].set_xlabel('')\nax[0].set_title('Top 10 Countries by number of Response 2019')\nsns.barplot('Prop','Country', data=country_2018_prop , palette='inferno',ax=ax[1])\nax[1].set_xlabel('')\nax[1].set_ylabel('')\nax[1].set_title('Top 10 Countries by number of Response 2018')\nsns.barplot('Prop','Country', data=country_2017_prop , palette='inferno',ax=ax[2])\nax[2].set_xlabel('')\nax[2].set_ylabel('')\nax[2].set_title('Top 10 Countries by number of Response 2017')\nplt.subplots_adjust(wspace=1.0)\nplt.show()","8b613a3f":"age = {}\nfor i in survey_2019['Q1'].iloc[1:,].unique()[:-1]:\n    min = int(i.split('-')[0])\n    max = int(i.split('-')[1])\n    age.update({i : list(range(min,max+1))})\n    \ndef chage_categori_age(x):\n    for i in age.items():\n        if x in i[1]:\n            return i[0]\n        \nsurvey_2018['Q2'] = survey_2018['Q2'].iloc[1:,].apply(lambda x: '70+' if (x == '80+') | (x == '70-79') else x)\nsurvey_2017['Age'] = survey_2017['Age'].apply(chage_categori_age)","9b86f365":"# tranform percentage\nage_2019_prop = survey_2019['Q1'].groupby(country_2019['year']).value_counts(normalize = True).rename ('Prop').reset_index().rename(columns = {'Q1' : 'Age'})\nage_2018_prop = survey_2018['Q2'].groupby(country_2018['year']).value_counts(normalize = True).rename ('Prop').reset_index().rename(columns = {'Q2' : 'Age'})\nage_2017_prop = survey_2017['Age'].groupby(country_2017['year']).value_counts(normalize = True).rename ('Prop').reset_index()\n\n# plot\nf,ax=plt.subplots(1,3,figsize=(25,15))\nsns.barplot('Prop','Age', data=age_2019_prop , palette='summer',ax=ax[0])\nax[0].set_xlabel('')\nax[0].set_title('Age 2019')\nax[0].axvline(0.25, linestyle='dashed')\nax[0].axvline(0.10, linestyle='dashed', color = 'r')\nax[0].axhspan(2.5,3.5 ,facecolor='Blue', alpha=0.2) # hilight space\n\nsns.barplot('Prop','Age', data=age_2018_prop , palette='summer',ax=ax[1])\nax[1].set_xlabel('')\nax[1].set_ylabel('')\nax[1].set_title('Age 2018')\nax[1].axvline(0.25, linestyle='dashed')\nax[1].axvline(0.10, linestyle='dashed', color = 'r')\nax[1].axhspan(2.5,3.5 ,facecolor='Blue', alpha=0.2) # hilight space\n\nsns.barplot('Prop','Age', data=age_2017_prop , palette='summer',ax=ax[2])\nax[2].set_xlabel('')\nax[2].set_ylabel('')\nax[2].set_title('Age 2017')\nax[2].axvline(0.25, linestyle='dashed')\nax[2].axvline(0.10, linestyle='dashed', color = 'r')\nax[2].axhspan(3.5,4.5 ,facecolor='Blue', alpha=0.2) # hilight space\n\nplt.subplots_adjust(wspace=0.6)\nplt.show()","a28ac33c":"currentjob_2019_prop = survey_2019['Q5'].groupby(survey_2019['year']).value_counts(normalize = True).rename ('Prop').sort_values(ascending = False).reset_index().rename(columns = {'Q5' : 'CurrentJobTitleSelect'})[:10]\ncurrentjob_2018_prop = survey_2018['Q6'].groupby(survey_2018['year']).value_counts(normalize = True).rename ('Prop').sort_values(ascending = False).reset_index().rename(columns = {'Q6' : 'CurrentJobTitleSelect'})[:10]\ncurrentjob_2017_prop = survey_2017['CurrentJobTitleSelect'].groupby(survey_2017['year']).value_counts(normalize = True).rename ('Prop').sort_values(ascending = False).reset_index()[:10]\n\n# plot\nf,ax=plt.subplots(1,3,figsize=(25,15))\n\nsns.barplot('Prop','CurrentJobTitleSelect', data=currentjob_2019_prop , palette='BrBG',ax=ax[0])\nax[0].set_xlabel('')\nax[0].set_title('Top10 CurrentJobTitle 2019')\nax[0].axvline(0.20, linestyle='dashed')\nax[0].axvline(0.15, linestyle='dashed', color = 'r')\nax[0].axhspan(0.5,1.5 ,facecolor='Red', alpha=0.5) # hilight space\n\nsns.barplot('Prop','CurrentJobTitleSelect', data=currentjob_2018_prop , palette='BrBG',ax=ax[1])\nax[1].set_xlabel('')\nax[1].set_ylabel('')\nax[1].set_title('Top10 CurrentJobTitle 2018')\nax[1].axvline(0.20, linestyle='dashed')\nax[1].axvline(0.15, linestyle='dashed', color = 'r')\nax[1].axhspan(-0.5,0.5 ,facecolor='Red', alpha=0.5) # hilight space\n\nsns.barplot('Prop','CurrentJobTitleSelect', data=currentjob_2017_prop , palette='BrBG',ax=ax[2])\nax[2].set_xlabel('')\nax[2].set_ylabel('')\nax[2].set_title('Top10 CurrentJobTitle 2017')\nax[2].axvline(0.20, linestyle='dashed')\nax[2].axvline(0.15, linestyle='dashed', color = 'r')\n\nplt.subplots_adjust(wspace=0.6)\nplt.show()","b6c8c2f3":"survey_2019_e = survey_2019[survey_2019['Q5'] == 'Student'].iloc[1:,]\nsurvey_2018_e = survey_2018[survey_2018['Q6'] == 'Student'].iloc[1:,]\neducation_2019_prop = survey_2019_e['Q4'].groupby(survey_2019_e['year']).value_counts(normalize = True).rename ('Prop').sort_values(ascending = False).reset_index().rename(columns = {'Q4' : 'Formal Education'})[:10]\neducation_2018_prop = survey_2018_e['Q4'].groupby(survey_2018_e['year']).value_counts(normalize = True).rename ('Prop').sort_values(ascending = False).reset_index().rename(columns = {'Q4' : 'Formal Education'})[:10]\n\n# plot\nf,ax=plt.subplots(1,2,figsize=(25,15))\n\nsns.barplot('Prop','Formal Education', data=education_2019_prop , palette='RdYlGn',ax=ax[0])\nax[0].set_xlabel(' ')\nax[0].set_ylabel(' ')\nax[0].set_title('Formal Education 2019')\nax[0].axvline(0.40, linestyle='dashed')\nax[0].axhspan(-0.5,0.5 ,facecolor='Gray', alpha=0.5) # hilight space\n\nsns.barplot('Prop','Formal Education', data=education_2018_prop , palette='RdYlGn',ax=ax[1])\nax[1].set_xlabel(' ')\nax[1].set_ylabel(' ')\nax[1].set_title('Formal Education 2018')\nax[1].axvline(0.40, linestyle='dashed')\nax[1].axhspan(0.5,1.5 ,facecolor='Gray', alpha=0.5) # hilight space\n\nplt.subplots_adjust(wspace=1.0)\nplt.show()","0835de00":"question = 'Q13' # On which platforms have you begun or completed data science courses?\ncolumns_list_2019 = qa_multiple_2019[question]\nsurvey_2019 ['LearningPlatformSelect'] = survey_2019[columns_list_2019].apply(lambda x: \",\".join(x.dropna().astype(str)), axis=1).replace('',np.nan)\n\nquestion = 'Q36' # On which platforms have you begun or completed data science courses?\ncolumns_list_2018 = qa_multiple_2018[question]\nsurvey_2018['LearningPlatformSelect'] = survey_2018[columns_list_2018].apply(lambda x: \",\".join(x.dropna().astype(str)), axis=1).replace('',np.nan)","4d7e26d4":"learn_2019 = survey_2019['LearningPlatformSelect'].iloc[1:,].str.split(',')\nlearn_2018 = survey_2018['LearningPlatformSelect'].iloc[1:,].str.split(',')\nlearn_2017 = survey_2017['LearningPlatformSelect'].iloc[1:,].str.split(',')\n\nplatform_2019 = []\nplatform_2018 = []\nplatform_2017 = []\n\nfor i in learn_2019.dropna():\n    platform_2019.extend(i)\n    \nfor i in learn_2018.dropna():\n    platform_2018.extend(i)\n    \nfor i in learn_2017.dropna():\n    platform_2017.extend(i)\n\n    \nf, ax = plt.subplots(1,3, figsize = (18,8))\n\npd.Series(platform_2019).value_counts(normalize=True)[:10].sort_values(ascending=True).plot.barh(width = 0.9, color  = sns.color_palette('winter',15),ax = ax[0])\nax[0].set_title('Top 10 Platforms to Learn 2019', size = 15)\npd.Series(platform_2018).value_counts(normalize=True)[:10].sort_values(ascending=True).plot.barh(width = 0.9, color  = sns.color_palette('winter',15),ax = ax[1])\nax[1].set_title('Top 10 Platforms to Learn 2018', size = 15)\npd.Series(platform_2017).value_counts(normalize=True)[:10].sort_values(ascending=True).plot.barh(width = 0.9, color  = sns.color_palette('winter',15),ax = ax[2])\nax[2].set_title('Top 10 Platforms to Learn 2017', size = 15)\nplt.show()","a3a59a79":"question = 'Q24' # Which of the following ML algorithms do you use on a regular basis? (Select all that apply): - Selected Choice\ncolumns_list_2019 = qa_multiple_2019[question]\nsurvey_2019 ['MLTechniquesSelect'] = survey_2019[columns_list_2019].apply(lambda x: \"?\".join(x.dropna().astype(str)), axis=1).replace('',np.nan)","471062fe":"mlTech_2019 = survey_2019['MLTechniquesSelect'].iloc[1:,].str.split('?')\nmlTech_2017 = survey_2017['MLTechniquesSelect'].iloc[1:,].str.split(',')\nmlTech_ds_2019 = survey_2019[survey_2019['Q5'] =='Data Scientist']['MLTechniquesSelect'].iloc[1:,].str.split('?')\nmlTech_ds_2017 = survey_2017[survey_2017['CurrentJobTitleSelect'] =='Data Scientist']['MLTechniquesSelect'].iloc[1:,].str.split(',')\n\n\nml_2019 = []\nml_2017 = []\nml_ds_2019 = []\nml_ds_2017 = []\n\nfor i in mlTech_2019.dropna():\n    ml_2019.extend(i)\n    \nfor i in mlTech_2017.dropna():\n    ml_2017.extend(i)\n    \nfor i in mlTech_ds_2019.dropna():\n    ml_ds_2019.extend(i)\n    \nfor i in mlTech_ds_2017.dropna():\n    ml_ds_2017.extend(i)\n    \n    \nf, ax = plt.subplots(2,2, figsize = (25,15))\npd.Series(ml_2019).value_counts(normalize=True)[:10].sort_values(ascending=True).plot.barh(width = 0.9, color  = sns.color_palette('spring',15),ax = ax[0][0])\nax[0][0].set_title('Top 10 MLTech 2019', size = 15)\nax[0][0].axhspan(6.5,7.5 ,facecolor='Gray', alpha=0.5) # hilight space\nax[0][0].axhspan(5.5,6.5 ,facecolor='Gray', alpha=0.5) # hilight space\nax[0][0].axvline(0.10, linestyle='dashed', color= 'r')\npd.Series(ml_2017).value_counts(normalize=True)[:10].sort_values(ascending=True).plot.barh(width = 0.9, color  = sns.color_palette('spring',15),ax = ax[0][1])\nax[0][1].set_title('Top 10 MLTech 2017', size = 15)\nax[0][1].axhspan(1.5,2.5 ,facecolor='Gray', alpha=0.5) # hilight space\nax[0][1].axhspan(3.5,4.5 ,facecolor='Gray', alpha=0.5) # hilight space\nax[0][1].axvline(0.10, linestyle='dashed', color= 'r')\npd.Series(ml_ds_2019).value_counts(normalize=True)[:10].sort_values(ascending=True).plot.barh(width = 0.9, color  = sns.color_palette('winter',15),ax = ax[1][0])\nax[1][0].set_title('Top 10 Data Scientist MLTech 2019', size = 15)\nax[1][0].axhspan(6.5,7.5 ,facecolor='Gray', alpha=0.5) # hilight space\nax[1][0].axhspan(5.5,6.5 ,facecolor='Gray', alpha=0.5) # hilight space\nax[1][0].axvline(0.10, linestyle='dashed', color= 'r')\npd.Series(ml_ds_2017).value_counts(normalize=True)[:10].sort_values(ascending=True).plot.barh(width = 0.9, color  = sns.color_palette('winter',15),ax = ax[1][1])\nax[1][1].set_title('Top 10 Data Scientist MLTech 2017', size = 15)\nax[1][1].axhspan(1.5,2.5 ,facecolor='Gray', alpha=0.5) # hilight space\nax[1][1].axhspan(3.5,4.5 ,facecolor='Gray', alpha=0.5) # hilight space\nax[1][1].axvline(0.10, linestyle='dashed', color= 'r')\nplt.subplots_adjust(wspace=.6)\nplt.show()","c91a81e3":"question = 'Q28' # Which categories of computer vision methods do you use on a regular basis?  (Select all that apply) - Selected Choice\ncolumns_list_2019 = qa_multiple_2019[question]\nsurvey_2019 ['MLFramework'] = survey_2019[columns_list_2019].apply(lambda x: \",\".join(x.dropna().astype(str)), axis=1).replace('',np.nan)\n\nquestion = 'Q19' # What machine learning frameworks have you used in the past 5 years?\ncolumns_list_2018 = qa_multiple_2018[question]\nsurvey_2018['MLFramework'] = survey_2018[columns_list_2018].apply(lambda x: \",\".join(x.dropna().astype(str)), axis=1).replace('',np.nan)","24424e42":"mlFrame_2019 = survey_2019['MLFramework'].iloc[1:,].str.split(',')\nmlFrame_2018 = survey_2018['MLFramework'].iloc[1:,].str.split(',')\n\nmlfr_2019 = []\nmlfr_2018 = []\n\nfor i in mlFrame_2019.dropna():\n    mlfr_2019.extend(i)\n    \nfor i in mlFrame_2018.dropna():\n    mlfr_2018.extend(i)\n    \nf, ax = plt.subplots(1,2, figsize = (18,8))\n\npd.Series(mlfr_2019).value_counts(normalize=True)[:10].sort_values(ascending=True).plot.barh(width = 0.9, color  = sns.color_palette('inferno_r',15),ax = ax[0])\nax[0].set_title('Top 10 ML Framework 2019', size = 15)\npd.Series(mlfr_2018).value_counts(normalize=True)[:10].sort_values(ascending=True).plot.barh(width = 0.9, color  = sns.color_palette('inferno_r',15),ax = ax[1])\nax[1].set_title('Top 10 ML Framework 2018', size = 15)\n\nplt.show()","ddd9f5c2":"question = 'Q29' # Which categories of computer vision methods do you use on a regular basis?  (Select all that apply) - Selected Choice\ncolumns_list_2019 = qa_multiple_2019[question]\nsurvey_2019 ['Cloud'] = survey_2019[columns_list_2019].apply(lambda x: \"?\".join(x.dropna().astype(str)), axis=1).replace('',np.nan)\n\nquestion = 'Q15' # What machine learning frameworks have you used in the past 5 years?\ncolumns_list_2018 = qa_multiple_2018[question]\nsurvey_2018['Cloud'] = survey_2018[columns_list_2018].apply(lambda x: \"?\".join(x.dropna().astype(str)), axis=1).replace('',np.nan)","f61c301c":"cloud_2019 = survey_2019['Cloud'].iloc[1:,].str.split('?')\ncloud_2018 = survey_2018['Cloud'].iloc[1:,].str.split('?')\n\ncl_2019 = []\ncl_2018 = []\n\nfor i in cloud_2019.dropna():\n    cl_2019.extend(i)\n    \nfor i in cloud_2018.dropna():\n    cl_2018.extend(i)\n    \nf, ax = plt.subplots(1,2, figsize = (18,15))\n\npd.Series(cl_2019).value_counts(normalize=True)[:5].sort_values(ascending=True).plot.barh(width = 0.9,ax = ax[0])\nax[0].set_title('Top 5 Cloud 2019', size = 15)\nax[0].axvline(0.2, linestyle='dashed', color= 'r')\npd.Series(cl_2018).value_counts(normalize=True)[:5].sort_values(ascending=True).plot.barh(width = 0.9, ax = ax[1])\nax[1].set_title('Top 5 Cloud  2018', size = 15)\nax[1].axvline(0.2, linestyle='dashed', color= 'r')\nplt.subplots_adjust(wspace=.6)\nplt.show()","be6e56bf":"question = 'Q33'# Which automated machine learning tools (or partial AutoML tools) do you use on a regular basis?\ncolumns_list_2019 = qa_multiple_2019[question]\nsurvey_2019 ['AutoML'] = survey_2019[columns_list_2019].apply(lambda x: \"?\".join(x.dropna().astype(str)), axis=1).replace('',np.nan)","f3ed5ea9":"auto_2019 = survey_2019['AutoML'].iloc[1:,].str.split('?')\n\naml_2019 = []\n\nfor i in auto_2019.dropna():\n    aml_2019.extend(i)\n    \npd.Series(aml_2019).value_counts(normalize=True)[:5].sort_values(ascending=True).plot.barh(width = 0.9)\nplt.title('Top 5 Cloud 2019', size = 15)\nplt.show()","1afc1d1e":"question = 'Q18' # What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice \ncolumns_list_2019 = qa_multiple_2019[question]\nsurvey_2019 ['WorkToolsSelect'] = survey_2019[columns_list_2019].apply(lambda x: \",\".join(x.dropna().astype(str)), axis=1).replace('',np.nan)\n\nquestion = 'Q16' # What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice \ncolumns_list_2018 = qa_multiple_2018[question]\nsurvey_2018['WorkToolsSelect'] = survey_2018[columns_list_2018].apply(lambda x: \",\".join(x.dropna().astype(str)), axis=1).replace('',np.nan)","2c4aa101":"programm_2019 = survey_2019.dropna(subset = ['WorkToolsSelect']).iloc[1:,]\nprogramm_2018 = survey_2018.dropna(subset = ['WorkToolsSelect']).iloc[1:,]\nprogramm_2017 = survey_2017.dropna(subset = ['WorkToolsSelect'])","4eee4740":"python_2019 = programm_2019[(programm_2019['WorkToolsSelect'].str.contains('Python')) & (~programm_2019['WorkToolsSelect'].str.contains('R')) & (~programm_2019['WorkToolsSelect'].str.contains('SQL'))]\nR_2019 = programm_2019[(~programm_2019['WorkToolsSelect'].str.contains('Python')) & (programm_2019['WorkToolsSelect'].str.contains('R')) & (~programm_2019['WorkToolsSelect'].str.contains('SQL'))]\nSQL_2019 = programm_2019[(~programm_2019['WorkToolsSelect'].str.contains('Python')) & (~programm_2019['WorkToolsSelect'].str.contains('R'))& (programm_2019['WorkToolsSelect'].str.contains('SQL'))]\npython_R_2019 = programm_2019[(programm_2019['WorkToolsSelect'].str.contains('Python')) & (programm_2019['WorkToolsSelect'].str.contains('R'))& (~programm_2019['WorkToolsSelect'].str.contains('SQL'))]\npython_SQL_2019 = programm_2019[(programm_2019['WorkToolsSelect'].str.contains('Python')) & (~programm_2019['WorkToolsSelect'].str.contains('R'))& (programm_2019['WorkToolsSelect'].str.contains('SQL'))]\nR_SQL_2019 = programm_2019[(~programm_2019['WorkToolsSelect'].str.contains('Python')) & (programm_2019['WorkToolsSelect'].str.contains('R'))& (programm_2019['WorkToolsSelect'].str.contains('SQL'))]\nALL_2019 = programm_2019[(programm_2019['WorkToolsSelect'].str.contains('Python')) & (programm_2019['WorkToolsSelect'].str.contains('R'))& (programm_2019['WorkToolsSelect'].str.contains('SQL'))]\nOTHER_2019 = programm_2019[(~programm_2019['WorkToolsSelect'].str.contains('Python')) & (~programm_2019['WorkToolsSelect'].str.contains('R'))& (~programm_2019['WorkToolsSelect'].str.contains('SQL'))]\n\npython_2018 = programm_2018[(programm_2018['WorkToolsSelect'].str.contains('Python')) & (~programm_2018['WorkToolsSelect'].str.contains('R')) & (~programm_2018['WorkToolsSelect'].str.contains('SQL'))]\nR_2018 = programm_2018[(~programm_2018['WorkToolsSelect'].str.contains('Python')) & (programm_2018['WorkToolsSelect'].str.contains('R')) & (~programm_2018['WorkToolsSelect'].str.contains('SQL'))]\nSQL_2018 = programm_2018[(~programm_2018['WorkToolsSelect'].str.contains('Python')) & (~programm_2018['WorkToolsSelect'].str.contains('R'))& (programm_2018['WorkToolsSelect'].str.contains('SQL'))]\npython_R_2018 = programm_2018[(programm_2018['WorkToolsSelect'].str.contains('Python')) & (programm_2018['WorkToolsSelect'].str.contains('R'))& (~programm_2018['WorkToolsSelect'].str.contains('SQL'))]\npython_SQL_2018 = programm_2018[(programm_2018['WorkToolsSelect'].str.contains('Python')) & (~programm_2018['WorkToolsSelect'].str.contains('R'))& (programm_2018['WorkToolsSelect'].str.contains('SQL'))]\nR_SQL_2018 = programm_2018[(~programm_2018['WorkToolsSelect'].str.contains('Python')) & (programm_2018['WorkToolsSelect'].str.contains('R'))& (programm_2018['WorkToolsSelect'].str.contains('SQL'))]\nALL_2018 = programm_2018[(programm_2018['WorkToolsSelect'].str.contains('Python')) & (programm_2018['WorkToolsSelect'].str.contains('R'))& (programm_2018['WorkToolsSelect'].str.contains('SQL'))]\nOTHER_2018 = programm_2018[(~programm_2018['WorkToolsSelect'].str.contains('Python')) & (~programm_2018['WorkToolsSelect'].str.contains('R'))& (~programm_2018['WorkToolsSelect'].str.contains('SQL'))]\n\npython_2017 = programm_2017[(programm_2017['WorkToolsSelect'].str.contains('Python')) & (~programm_2017['WorkToolsSelect'].str.contains('R')) & (~programm_2017['WorkToolsSelect'].str.contains('SQL'))]\nR_2017 = programm_2017[(~programm_2017['WorkToolsSelect'].str.contains('Python')) & (programm_2017['WorkToolsSelect'].str.contains('R')) & (~programm_2017['WorkToolsSelect'].str.contains('SQL'))]\nSQL_2017 = programm_2017[(~programm_2017['WorkToolsSelect'].str.contains('Python')) & (~programm_2017['WorkToolsSelect'].str.contains('R'))& (programm_2017['WorkToolsSelect'].str.contains('SQL'))]\npython_R_2017 = programm_2017[(programm_2017['WorkToolsSelect'].str.contains('Python')) & (programm_2017['WorkToolsSelect'].str.contains('R'))& (~programm_2017['WorkToolsSelect'].str.contains('SQL'))]\npython_SQL_2017 = programm_2017[(programm_2017['WorkToolsSelect'].str.contains('Python')) & (~programm_2017['WorkToolsSelect'].str.contains('R'))& (programm_2017['WorkToolsSelect'].str.contains('SQL'))]\nR_SQL_2017 = programm_2017[(~programm_2017['WorkToolsSelect'].str.contains('Python')) & (programm_2017['WorkToolsSelect'].str.contains('R'))& (programm_2017['WorkToolsSelect'].str.contains('SQL'))]\nALL_2017 = programm_2017[(programm_2017['WorkToolsSelect'].str.contains('Python')) & (programm_2017['WorkToolsSelect'].str.contains('R'))& (programm_2017['WorkToolsSelect'].str.contains('SQL'))]\nOTHER_2017 = programm_2017[(~programm_2017['WorkToolsSelect'].str.contains('Python')) & (~programm_2017['WorkToolsSelect'].str.contains('R'))& (~programm_2017['WorkToolsSelect'].str.contains('SQL'))]","2ff1bb51":"f, ax = plt.subplots(1,3, figsize = (18,8))\n\nvenn3(subsets = (round(python_2019.shape[0]\/len(programm_2019),2) , \n                 round(R_2019.shape[0]\/len(programm_2019),2), \n                 round(SQL_2019.shape[0]\/len(programm_2019),2) ,\n                 round(python_R_2019.shape[0]\/len(programm_2019),2) ,\n                 round(python_SQL_2019.shape[0]\/len(programm_2019),2) ,\n                 round(R_SQL_2019.shape[0]\/len(programm_2019) ,2) ,\n                 round(ALL_2019.shape[0]\/len(programm_2019) ,2)),\n       set_labels = ('Python','R','SQL','Python + R','Python + SQL' , 'R + SQL', 'ALL' ) , ax = ax[0] )\nax[0].set_title('Percent of Users 2019')\n\nvenn3(subsets = (round(python_2018.shape[0]\/len(programm_2018),2) , \n                 round(R_2018.shape[0]\/len(programm_2018),2), \n                 round(SQL_2018.shape[0]\/len(programm_2018),2) ,\n                 round(python_R_2018.shape[0]\/len(programm_2018),2) ,\n                 round(python_SQL_2018.shape[0]\/len(programm_2018),2) ,\n                 round(R_SQL_2018.shape[0]\/len(programm_2018) ,2) ,\n                 round(ALL_2018.shape[0]\/len(programm_2018) ,2)),\n       set_labels = ('Python','R','SQL','Python + R','Python + SQL' , 'R + SQL', 'ALL') , ax = ax[1])\nax[1].set_title('Percent of Users 2018')\n\nvenn3(subsets = (round(python_2017.shape[0]\/len(programm_2017),2) , \n                 round(R_2017.shape[0]\/len(programm_2017),2), \n                 round(SQL_2017.shape[0]\/len(programm_2017),2) ,\n                 round(python_R_2017.shape[0]\/len(programm_2017),2) ,\n                 round(python_SQL_2017.shape[0]\/len(programm_2017),2) ,\n                 round(R_SQL_2017.shape[0]\/len(programm_2017) ,2) ,\n                 round(ALL_2017.shape[0]\/len(programm_2017) ,2)),\n       set_labels = ('Python','R','SQL','Python + R','Python + SQL' , 'R + SQL', 'ALL') , ax = ax[2])\nax[2].set_title('Percent of Users 2017')\nplt.show()\n\nprint('2019 OTHER Percentage : ' + str(round(OTHER_2019.shape[0]\/len(programm_2019) ,2)))\nprint('2018 OTHER Percentage : ' + str(round(OTHER_2018.shape[0]\/len(programm_2018) ,2)))\nprint('2017 OTHER Percentage : ' + str(round(OTHER_2017.shape[0]\/len(programm_2017) ,2)))","2fd24703":"f, ax = plt.subplots(1,2, figsize = (18,8))\n\n# 2019-Q19 or 2018-Q18 : What programming language would you recommend an aspiring data scientist to learn first? - Selected Choice \nsurvey_2019.iloc[1:,].dropna(subset =['Q19'])['Q19'].value_counts(normalize = True, ascending = True).plot.barh(width = 0.9, color =sns.color_palette('inferno_r',15) ,ax = ax[0])\nax[0].set_title('Recommend Programming Tool 2019', size = 15)\nsurvey_2018.iloc[1:,].dropna(subset =['Q18'])['Q18'].value_counts(normalize = True, ascending = True).plot.barh(width = 0.9, color =sns.color_palette('inferno_r',15) ,ax = ax[1])\nax[1].set_title('Recommend Programming Tool 2018', size = 15)\nplt.show()","940cfd0a":"#2019\npython_2019_1 = python_2019.copy()\nr_2019_1 = R_2019.copy()\nsql_2019_1 = SQL_2019.copy()\n\npython_2019_1['WorkToolsSelect_1'] = 'Python'\nr_2019_1['WorkToolsSelect_1']='R'\nsql_2019_1['WorkToolsSelect_1']='SQL'\n\npython_r_sql_2019 = pd.concat([python_2019_1,r_2019_1,sql_2019_1]).rename(columns = {'Q5' : 'CurrentJobTitleSelect'})\npython_r_sql_2019 = python_r_sql_2019['WorkToolsSelect_1'].groupby(python_r_sql_2019['CurrentJobTitleSelect']).value_counts(normalize = True).rename ('Prop').reset_index()\n\n\n#2018\npython_2018_1 = python_2018.copy()\nr_2018_1 = R_2018.copy()\nsql_2018_1 = SQL_2018.copy()\n\npython_2018_1['WorkToolsSelect_1'] = 'Python'\nr_2018_1['WorkToolsSelect_1']='R'\nsql_2018_1['WorkToolsSelect_1']='SQL'\n\npython_r_sql_2018 = pd.concat([python_2018_1,r_2018_1,sql_2018_1]).rename(columns = {'Q6' : 'CurrentJobTitleSelect'})\npython_r_sql_2018 = python_r_sql_2018['WorkToolsSelect_1'].groupby(python_r_sql_2018['CurrentJobTitleSelect']).value_counts(normalize = True).rename ('Prop').reset_index()\n\n#2017\npython_2017_1 = python_2017.copy()\nr_2017_1 = R_2017.copy()\nsql_2017_1 = SQL_2017.copy()\n\npython_2017_1['WorkToolsSelect_1'] = 'Python'\nr_2017_1['WorkToolsSelect_1']='R'\nsql_2017_1['WorkToolsSelect_1']='SQL'\n\npython_r_sql_2017 = pd.concat([python_2017_1,r_2017_1,sql_2017_1])\npython_r_sql_2017 = python_r_sql_2017['WorkToolsSelect_1'].groupby(python_r_sql_2017['CurrentJobTitleSelect']).value_counts(normalize = True).rename ('Prop').reset_index()\n\n\n#plot\nf, ax = plt.subplots(1,3, figsize = (25,15))\npython_r_sql_2019.pivot('CurrentJobTitleSelect','WorkToolsSelect_1','Prop').plot.barh(width=0.8, ax = ax[0])\nax[0].set_title('Percent Programmin Per Current Job 2019')\nax[0].axhspan(1.5,2.5 ,facecolor='Orange', alpha=0.25) # hilight space\nax[0].axhspan(9.5,10.5 ,facecolor='Orange', alpha=0.25) # hilight space\n\npython_r_sql_2018.pivot('CurrentJobTitleSelect','WorkToolsSelect_1','Prop').plot.barh(width=0.8, ax = ax[1])\nax[1].set_title('Percent Programmin Per Current Job 2018')\nax[1].set_ylabel('')\nax[1].axhspan(3.5,4.5 ,facecolor='Orange', alpha=0.25) # hilight space\nax[1].axhspan(18.5,19.5 ,facecolor='Orange', alpha=0.25) # hilight space\n\npython_r_sql_2017.pivot('CurrentJobTitleSelect','WorkToolsSelect_1','Prop').plot.barh(width=0.8, ax = ax[2])\nax[2].set_title('Percent Programmin Per Current Job 2017')\nax[2].set_ylabel('')\nax[2].axhspan(2.5,3.5 ,facecolor='Orange', alpha=0.25) # hilight space\nax[2].axhspan(14.5,15.5 ,facecolor='Orange', alpha=0.25) # hilight space\n\nplt.subplots_adjust(wspace=1.0)\nplt.show()","a8c6c345":"ds_data = survey_2019[survey_2019['Q5'] == 'Data Scientist'].iloc[1:,]","87940a26":"question = 'Q9' # Select any activities that make up an important part of your role at work: (Select all that apply) \ncolumns_list_2019 = qa_multiple_2019[question]\nds_data ['Activites'] = ds_data[columns_list_2019].apply(lambda x: \"?\".join(x.dropna().astype(str)), axis=1).replace('',np.nan)\nactivities_2019 = ds_data['Activites'].str.split('?')\n\nat_2019 = []\nfor i in activities_2019.dropna():\n    at_2019.extend(i)\n\nplt.figure(figsize = (15,10))\npd.Series(at_2019).value_counts(normalize=True)[:10].sort_values(ascending=True).plot.barh(width = 0.9, color  = sns.color_palette('inferno_r',15))\nplt.title('Data Scientist Importance Role', size = 15)\n\nplt.show()","92857907":"question = 'Q12' # Select any activities that make up an important part of your role at work: (Select all that apply) \ncolumns_list_2019 = qa_multiple_2019[question]\nds_data ['Media_Source'] = ds_data[columns_list_2019].apply(lambda x: \"?\".join(x.dropna().astype(str)), axis=1).replace('',np.nan)\nmedia_2019 = ds_data['Media_Source'].str.split('?')\n\nmd_2019 = []\nfor i in media_2019.dropna():\n    md_2019.extend(i)\n\nplt.figure(figsize = (15,10))\npd.Series(md_2019).value_counts(normalize=True)[:10].sort_values(ascending=True).plot.barh(width = 0.9, color  = sns.color_palette('inferno',15))\nplt.title('DataScientist Media Source', size = 15)\n\nplt.show()","e6dfd125":"plt.figure(figsize=(10,8))\ncode_2019 = ds_data['Q15'].value_counts(normalize = True).rename ('Prop').plot.pie(autopct='%1.1f%%',explode=[0.1,0,0,0,0,0,0], shadow=True,)\nplt.title('DataScientist Code Time', size = 15)\nplt.show()","3c01a7a6":"plt.figure(figsize=(10,8))\ncode_2019 = ds_data['Q23'].value_counts(normalize = True).rename ('Prop').plot.pie(autopct='%1.1f%%',explode=[0.2,0.1,0,0,0,0,0,0], shadow=True,)\nplt.title('DataScientist Code Time', size = 15)\nplt.show()","e890022d":"money_2019 = ds_data['Q11'].groupby(ds_data['year']).value_counts(normalize = True).rename ('Prop').sort_values(ascending=False).reset_index()\n# plot\nplt.figure(figsize=(25,15))\nsns.barplot('Prop','Q11', data=money_2019 , palette=sns.color_palette('viridis',15))\nplt.title('DataScientist Spent Money', size = 15)\nplt.show()","6d067f3f":"Different people may have different answers, **but the most answers are $0!!**\nThis may be because many people interact with other data scientists through published information such as Kaggle or Blog.","d8a69b1c":"### Student Education","eabaa27f":"Over the course of three years, much of society is changing as interest in data analysis and data science grows.\nWhat has changed in the last three years?","4937a642":"**Kaggle** is the world's largest data science platform and great playground where many people can learn and grow about data & data science & statistics.\nIt's also a great platform for statisticians, data analysts, and data scientists in the real world industry to share their analytical and machine learning methods.\nThe competition is survey data published by kaggle in 2019 and began in 2017.\nIn the three years from 2017 to 2019, many analytical & machine learning technologies were developed and further enhanced.\nThat's why I want to use the data for 2017, 2018 and 2019 to find time-to-time changes in the overall area.\nAnd the final analysis will be to analyze what data scientists have answered in 2019.\n\n**There are several limitations in this analysis.** \n* First. The questions aren't the same for every year. \n    * So I did a comparison of very similar questions.\n* Second, Since this is a survey, not everyone will answer with the appropriate credentials and there may be a fake response.\n\nLet's get some insights from this analysis.","63a0eaea":"## Age","1dd0cf77":"The above plot shows that the top countries from 2017 to 2019 are the United States and India.<br>\nHowever, when Kaggle's users think of more than a million, it is unlikely that most users will see the U.S. and India. <br>\n\"Where is Korea?.....\"","095b7bc9":"## Programming","710a5efd":"# How did it change over time?","409e214a":"If you look at it as a whole, you can see that men are overwhelmingly more important than women. <br>\nAlso, the difference between 2017 and 2019 is not clear. <br>\nThere are a few guesses about this. The part about the data is either that men are interested or that men are responding a lot.... <br>\n**I don't know exactly...haha**","6fc449c4":"## Fifth. *Do you have to spend a lot of money to be a data scientist?*","ab2877d3":"We can see that Python is the first language to recommend for the data scientist's introduction.\nMany people are recommending Python for the first entrance and it is as powerful as it is, so I think we can boost our commitment to the Ben Diagram above.","5740bd3d":"Many data scientists understand their data and play a role in influencing product or business decisions. Many data scientists understand their data and play a role in influencing product or business decisions. I think there are many roles for data scientists because they need to learn and know knowledge about various fields such as math, computer, and business.\n\nIn other words, you need to build up domain knowledge of the data you see.","9b4271b4":"Well, interestingly, it seems that the response rate of the Bachelor has increased, while that of the masters has decreased. Well, if we can make a funny guess from the above information, maybe it's because the masters is busy..","7a721c3b":"# Simple Visualization ","11473463":"## Automated machine learning tools","70a6b3d5":"## First. *What is important part of your role at work ?*","8225cc4e":"Recently, **\"Artificial Intelligence Makes Artificial Intelligence\"** came along with the introduction of Automated Machine Learning.\nIt was interesting to see that the FE and FS sections were able to save a lot of time and create models that are optimized for a given data. And I think it's a very efficient tool for real companies because it makes it easy to deploy models.\nHowever, so far, only the reform and classification are supported, and Google has its disadvantages.\nAs technology becomes more advanced over time, many analysts are likely to use it as well.","6a70d046":"# Conclusion","00f9a70c":"## Machine Learning Alforithm","a3c85090":"Looking at the current job of TOP10 you can see that the data scientist has had a high rate for three years.\nHowever, what's unusual is that starting in 2018, the percentage of study has suddenly risen.\nIt can be seen that many students are starting to pay a lot of attention to ML or DS technology.\n\n**So what would happen to the degrees of those who answered that they were students?**\nI want to know why many students answered that they are interested and therefore eager to get a higher education to become an expert.","2d90bd39":"## Second. *What platform do you get the data science news from?*","0086a07f":"Machine Learning Algorithm, which is used most frequently in 2017 and 2019, is Logistic (Linear) Regression. It is the most basic ML method, but it is also an easy to interpret and powerful algorithm, so it is an algorithm that you will try to use first at the start of the project. What we have looked carefully at is that the Boasting method is ranked higher than it was in 2017. In Kaggle, we can see that Xgboost and Catboost are very popular, and these results are shown in the above plot. In addition, it is possible to see that CNN and RNN are higher than 2017 and higher than other top-tier algorithms because Deep Learning is a hot algorithm.\n\nWhen looking at data scientists, it seems that they are using more Gradient Boosting techniques for the whole thing.","cfaafcd9":"## Fourth. *How many years have you used the machine learning methods?*","137b1f45":"I'd like to ask some questions to the data scientist. \n* \"What is important part of your role at work?\"\n* \"What platform do you get the data science news from?\"\n* \"How long have you used the code?\"\n* \"How many years have you used the machine learning methodology?\"\n* \"Do you have to spend a lot of money to be a data scientist?\" \n\nThese questions stem from my curiosity to become a data scientist.","6623a0ad":"## Recommend Programming","d9f59d71":"The overall weight indicates that the percentage mentioned in Coursera will increase from 2018.\nIn fact, many are being created and I also lectures mooc coursera or knowledge relating to data and statistics through.\nThe certificate of qualification for completion is also attractive.","5e8ffaf8":"As data grows, many people or businesses are using cloud services.\nThe most commonly used support appears to be Amazon Web Service, followed by Google Cloud Service.\nRecently, Kagle also introduced Google services.\nWe also see many cases of using Google Cloud as a Data Lake.\n**\"How will change occur next year? \"**","3e3c4760":"It's not enough yet, but thank you for watching. Please give us a lot of feedback. Also, please follow me from Kaggle. **I want to learn from you.**","2148e388":"# Platform To Laern","1e612baa":"The data scientists said they usually typed the code for three to five years.\nIf you ask the surrounding analysts and scientists, they say, \"The foundation of the code begins in two years.\"\n**I don't think it's wrong...OTL**","09d1c2a5":"Through this analysis, we have learned some facts.\n\n** Simple Data Analytis** \n\n1) Most of the respondents came from the United States, followed by India. The United States also had the largest number of data scientists after India.\n\n2) Most of the respondents are 20-35 years old, indicating that data science is quite popular with young people.\n\n3) Most of the respondents were students.It is thought that younger friends will learn and be interested in data science in the future.\n\n4) Many respondents are learning about data science using Mooc lectures like Coursera and Kaggle.\n\n**  Machine Laerning ** \n\n1) It is good to learn (Boasting techniques and Deep Learning).\n\n2) I recommend Python for the first time. Plus, I think SQL will be good. R is also recommended for convenience in statistical analysis if opportunity arises.\n\n3) To become a data scientist, increase your domain knowledge of that data.\n\n4) Let's listen to and learn from various data scientists through blogs or Kaggle\n\n5) From now on, let's practice code and machine learning methodology.","bfb616ba":"# About Data Scientist Answer","c50a711e":"# **Introduction**","93cb00a5":"## Gender","bb6b03a0":"Python is rapidly increasing in 2018 and 2019 compared to 2017.\nNoticeably, data analysts seemed to prefer R and SQL to Python in 2017, but by 2018 and 2019, Python was very dominant.\nStatisticians can also see a rise of approximately 20% in 2018 and 2019, although Python use was less than 10% in 2017.\nIt seems that those involved in the analysis also prefer Python to R.","4c547a07":"**1. Learning curve (R)**\n* To use python numpy, pandas, including matplotlib to learn a lot of data. But r in built-in graphics and basic matrix type by default.\n\n**2. Available libraries (no winning)**\n* Python packages index (pypi), with a package of more than 183,000 cran have a package of more than 12,000 are (compreged rarchive network).\n\n**3. Machine Running (Python)**\n* Python's tremendous growth in recent years has been partly affected by the rise in machine learning and artificial intelligence. Python offers many finely tuned libraries for image recognition, such as AlexNet, but R versions are also easy to develop.\n\n**4. Statistical accuracy (R)**\n*  Matloff pointed out that machine learning experts who advocate Python sometimes do not understand the statistical problems involved. R, on the other hand, was written by statisticians, it added.\n\n**5. Parallel operation (no win)**\n*  The basic versions of R and Python have weak support for multi-core operations. Python's multiprocessing package is not a good solution to other issues, nor is R's parallel package.\n\n**6. Uniformity of Language (Python)**\n*  Python won't be much of a mess if the version changes. However, R is changing into two different languages under the influence of RStudio. (R, Tidyverse)","ab25057c":"# Machine Learning","58fef387":"## Machine Learning FrameWork","fa31165f":"Overall, Machine Learning FrameWork is showing similar performance in 2018 and 2019.\nThe Skikit-Learn package is basically the FrameWork that you use when you study and learn about data because of the Framework that carries a lot of powerful functions.\nAlso, Tensorflow is Deep Learning OpenSource, a FrameWork used by many artificial intelligence engineers.","1c647c41":"## Country","70b35e1e":"Compared to 2017, the percentage of people who enjoy all three languages will decrease in 2018 and 2019.\nStrangely, the proportion of people using R & SQL decreases over time, while the proportion of people using Python & SQL increases.\nThis is the first language that Python is highly recommended for beginners and is also the first language to use when learning many data science basics. I'm using SQL, R, and Python. Because each language has its advantages and disadvantages, it is recommended to use all three.\nBased on the CNN article, if you look at the strengths and weaknesses of language..","ca45b820":"## CurrentJob ","b7bb967c":"## Third. *How long have you used the code?*","4eab61bf":"## Programming Used By Professionals","dc4d18c7":"Data scientists answered a lot of news from Blog or Kagle.\nIn fact, there are Discuss channels in Kaggle with many questions and answers, and I am also going to try to get into Kaggle with this competition. haha","02a07f4f":"The most to responses believed to have people in their 20s and 30s.\nAlso, people between the ages of 18 and 21 from 2018 can see their response rate rise.\nIf so, I think the response rate of students is likely to increase as well.","0a209988":"## Cloud Computing"}}