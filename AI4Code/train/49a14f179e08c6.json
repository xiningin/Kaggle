{"cell_type":{"805f3430":"code","0cc52022":"code","d4ee51fe":"code","b09b225d":"code","d91a829d":"code","7758c567":"code","42af68ff":"code","37663fe5":"code","501a82ed":"code","fca80732":"code","d06c64f5":"code","2df69994":"code","d1e59d26":"code","87674b73":"code","f22fe422":"code","9a2ea619":"code","f244afb7":"code","3e08cf3d":"code","40ff3ae2":"code","d50c262e":"code","ef30771c":"code","e5b31d7f":"code","80f6aaf2":"code","678ce06a":"code","914b8a99":"code","c5134bf3":"code","27a1f066":"code","7b4b6f83":"code","07c048af":"code","8c0cb458":"code","86393219":"code","4e964b01":"code","32b672cd":"code","0bf9f32b":"code","0df64044":"code","f57c2523":"code","cbba0df5":"code","b94c553d":"code","1b9ed06b":"markdown","4c27049b":"markdown","c917015d":"markdown","5f4a134d":"markdown","5ac14202":"markdown","91aeea62":"markdown","0567e692":"markdown","87967090":"markdown","d109f3d4":"markdown","71c876e4":"markdown","57252ac9":"markdown","636bfb2d":"markdown","2917b55d":"markdown"},"source":{"805f3430":"!pip install -q mlflow","0cc52022":"import numpy as np\nimport os\nimport cv2\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport random\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline","d4ee51fe":"import warnings\nwarnings.filterwarnings(\"ignore\")","b09b225d":"image_path_train = '..\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/CXR_png\/'\nmask_path_train = '..\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/masks\/'\nimage_path_test = '..\/input\/chest-xray-masks-and-labels\/Lung Segmentation\/test\/' ","d91a829d":"images = os.listdir(image_path_train)\nmask = os.listdir(mask_path_train)\nmask = [fName.split(\".png\")[0] for fName in mask]\nimage_file_name = [fName.split(\"_mask\")[0] for fName in mask]","7758c567":"check = [i for i in mask if \"mask\" in i]\nprint(\"Total mask that has modified name:\", len(check))","42af68ff":"testing_files = set(os.listdir(image_path_train)) & set(os.listdir(mask_path_train))\ntraining_files = check","37663fe5":"def getData(X_shape, flag = \"MONT\"):\n    im_array = []\n    mask_array = []\n    shape = (X_shape, X_shape)\n    # X_shape = image_size\n    if flag == \"MONT\":\n        for i in tqdm(testing_files): \n            \n            # im.shape = (X_shape, X_shape, 1)\n            im = cv2.imread(os.path.join(image_path_train, i), cv2.IMREAD_GRAYSCALE)\n            im = cv2.resize(im, shape)\n            im = cv2.equalizeHist(im)\n            # mask.shape = (X_shape, X_shape, 1)\n            mask = cv2.imread(os.path.join(mask_path_train, i), cv2.IMREAD_GRAYSCALE)\n            mask = cv2.resize(mask, shape)\n            \n            im_array.append(im)\n            mask_array.append(mask)\n    \n    if flag == \"SHEN\":\n        for i in tqdm(training_files): \n            \n            # im.shape = (X_shape, X_shape, 1)\n            im = cv2.imread(os.path.join(image_path_train, i.split(\"_mask\")[0] + \".png\"), cv2.IMREAD_GRAYSCALE)\n            im = cv2.resize(im, shape)\n            im = cv2.equalizeHist(im)\n            # mask.shape = (X_shape, X_shape, 1)\n            mask = cv2.imread(os.path.join(mask_path_train, i + \".png\"), cv2.IMREAD_GRAYSCALE)\n            mask = cv2.resize(mask, shape)\n            \n            im_array.append(im)\n            mask_array.append(mask)\n    # return list\n    return im_array, mask_array","501a82ed":"def get_test(X_shape, n_samples = 100):\n    im_array = []\n    shape = (X_shape, X_shape)\n    test_files = random.choices(list(os.listdir(image_path_test)), k=n_samples)\n    for i in tqdm(test_files):\n        im = cv2.imread(os.path.join(image_path_test, i), cv2.IMREAD_GRAYSCALE)\n        im = cv2.resize(im, shape)\n        im = cv2.equalizeHist(im)\n        im_array.append(im)\n    return im_array","fca80732":"dim, n_samples = 256, 50 # n_samples = [1, 96]\n\nimage_shen, mask_shen = getData(dim, flag = \"SHEN\")\nimage_mont, mask_mont = getData(dim, flag = \"MONT\")\nX_test = get_test(dim, n_samples = n_samples)","d06c64f5":"image_shen = np.array(image_shen).reshape(len(image_shen), dim, dim, 1)\nmask_shen = np.array(mask_shen).reshape(len(mask_shen), dim, dim, 1)\n\nimage_mont = np.array(image_mont).reshape(len(image_mont), dim, dim, 1)\nmask_mont = np.array(mask_mont).reshape(len(mask_mont), dim, dim, 1)\n\nX_test = np.array(X_test).reshape(len(X_test), dim, dim, 1)","2df69994":"print(image_shen.shape, mask_shen.shape)\nprint(image_mont.shape, mask_mont.shape)\nprint(X_test.shape)","d1e59d26":"i = 25\nfig, axs = plt.subplots(nrows=3, ncols=2, figsize=(9, 13))\naxs[0, 0].imshow(image_shen[i], cmap='gray')\naxs[0, 1].imshow(mask_shen[i], cmap='gray')\naxs[0, 0].set_ylabel('Shenzhen')\n\naxs[1, 0].imshow(image_mont[i], cmap='gray')\naxs[1, 1].imshow(mask_mont[i], cmap='gray')\naxs[1, 0].set_ylabel('Montgomery')\n\naxs[2, 0].imshow(X_test[i], cmap='gray')\naxs[2, 0].set_ylabel('NIH')\n\naxs[0, 0].set_title('CXR')\naxs[1, 0].set_title('CXR')\naxs[2, 0].set_title('CXR')\n\naxs[0, 1].set_title('mask')\naxs[1, 1].set_title('mask')\n\nfig.delaxes(axs[2, 1])","87674b73":"assert image_shen.shape == mask_shen.shape\nassert image_mont.shape == mask_mont.shape\nimages = np.concatenate((image_shen, image_mont), axis=0)\nmasks  = np.concatenate((mask_shen, mask_mont), axis=0)\n\nprint(images.shape, masks.shape)","f22fe422":"def apply_brightness_contrast(input_img, brightness = 0, contrast = 0):\n    \n    if brightness != 0:\n        if brightness > 0:\n            shadow = brightness\n            highlight = 255\n        else:\n            shadow = 0\n            highlight = 255 + brightness\n        alpha_b = (highlight - shadow) \/ 255.0\n        gamma_b = shadow\n        \n        buf = cv2.addWeighted(input_img, alpha_b, input_img, 0, gamma_b)\n    else:\n        buf = input_img.copy()\n    \n    if contrast != 0:\n        f = 131 * (contrast + 127) \/ (127 * (131 - contrast))\n        alpha_c = f\n        gamma_c = 127 * (1 - f)\n        \n        buf = cv2.addWeighted(buf, alpha_c, buf, 0, gamma_c)\n\n    return buf","9a2ea619":"def create_contrast_images_v1(b, c):\n    contrast_images = []\n    for i in tqdm(range(len(images)), \"contrast_images\"):\n        contrast_images.append(apply_brightness_contrast(images[i], brightness=b, contrast=c))\n    return contrast_images","f244afb7":"b, c = -40, -120\n\ncontrast_images_v1 = create_contrast_images_v1(b, c)\ncontrast_images_v1 = np.array(contrast_images_v1).reshape(len(contrast_images_v1), 256, 256, 1)\nprint(f'\\nshape = {contrast_images_v1.shape}')","3e08cf3d":"def create_contrast_images_v2(alpha, beta):\n    contrast_images_v2 = []\n    for i in tqdm(range(len(images)), \"contrast_images\"):\n        contrast_images_v2.append(cv2.addWeighted(images[i], alpha, images[i], 0, beta))\n    return contrast_images_v2","40ff3ae2":"alpha = 1.5 #@alpha\nbeta = 0.7 #@beta\n\ncontrast_images_v2 = create_contrast_images_v2(alpha, beta)\ncontrast_images_v2 = np.array(contrast_images_v2).reshape(len(contrast_images_v2), 256, 256, 1)\nprint(f'\\nshape = {contrast_images_v2.shape}')","d50c262e":"def noise(i: int = len(images)):\n    return np.random.randint(0, 255, size=(i, 256, 256, 1))\n\ndef noise_images(epsilon: float = 0.1):\n    noised = noise()\n    noised_img = []\n    for i in tqdm(range(len(images)), \"noise_images\"):\n        noised_img.append(noised[i] * epsilon + images[i])\n    \n    return noised_img\n\nnoised_images = noise_images(epsilon=0.1)\nnoised_images = np.array(noised_images).reshape(len(noised_images), 256, 256, 1)\nprint(f'\\nshape = {noised_images.shape}')","ef30771c":"i = 15\nfig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(20, 10))\n\nax1.imshow(images[i].reshape(256, 256), cmap='gray')\nax1.set_title('Original')\n\nax2.imshow(contrast_images_v1[i].reshape(256, 256), cmap='gray')\nax2.set_title('Contrast V1')\n\nax3.imshow(contrast_images_v2[i].reshape(256, 256), cmap='gray')\nax3.set_title('Contrast V2')\n\nax4.imshow(noised_images[i].reshape(256, 256), cmap='gray')\nax4.set_title('noise 0.1')\n\nax5.imshow(masks[i].reshape(256, 256), cmap='gray')\nax5.set_title('Mask');","e5b31d7f":"all_images = np.concatenate((images, contrast_images_v1, contrast_images_v2, noised_images), axis=0)\nall_masks  = np.concatenate((masks, masks, masks, masks), axis=0)","80f6aaf2":"all_images.shape, all_masks.shape","678ce06a":"X_train, X_val, Y_train, Y_val = train_test_split((all_images - 127.0) \/ 127.0, \n                                                  (all_masks > 127).astype(np.float32), \n                                                  test_size = 0.2, \n                                                  random_state = 2018)\nX_testNorm = (X_test - 127.0) \/ 127.0","914b8a99":"import tensorflow as tf\nimport tensorflow.keras\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport mlflow\nimport mlflow.tensorflow","c5134bf3":"def dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + 1) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n\ndef jaccard_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (intersection + 1.0) \/ (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n\ndef jaccard_coef_loss(y_true, y_pred):\n    return 1 - jaccard_coef(y_true, y_pred) ","27a1f066":"def bn_act(x, act=True):\n    x = tensorflow.keras.layers.BatchNormalization()(x)\n    if act == True:\n        x = tensorflow.keras.layers.Activation(\"relu\")(x)\n    return x\n\ndef conv_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n    conv = bn_act(x)\n    conv = tensorflow.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n    return conv\n\ndef stem(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n    conv = tensorflow.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n    conv = conv_block(conv, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n    \n    shortcut = tensorflow.keras.layers.Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n    shortcut = bn_act(shortcut, act=False)\n    \n    output = tensorflow.keras.layers.Add()([conv, shortcut])\n    return output\n\ndef residual_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n    res = conv_block(x, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n    res = conv_block(res, filters, kernel_size=kernel_size, padding=padding, strides=1)\n    \n    shortcut = tensorflow.keras.layers.Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n    shortcut = bn_act(shortcut, act=False)\n    \n    output = tensorflow.keras.layers.Add()([shortcut, res])\n    return output\n\ndef upsample_concat_block(x, xskip):\n    u = tensorflow.keras.layers.UpSampling2D((2, 2))(x)\n    c = tensorflow.keras.layers.Concatenate()([u, xskip])\n    return c","7b4b6f83":"def ResUNet():\n    f = [16, 32, 64, 128, 256]\n    inputs = tensorflow.keras.layers.Input((dim, dim, 1))\n    \n    ## Encoder\n    e0 = inputs\n    e1 = stem(e0, f[0])\n    e2 = residual_block(e1, f[1], strides=2)\n    e3 = residual_block(e2, f[2], strides=2)\n    e4 = residual_block(e3, f[3], strides=2)\n    e5 = residual_block(e4, f[4], strides=2)\n    \n    ## Bridge\n    b0 = conv_block(e5, f[4], strides=1)\n    b1 = conv_block(b0, f[4], strides=1)\n    \n    ## Decoder\n    u1 = upsample_concat_block(b1, e4)\n    d1 = residual_block(u1, f[4])\n    \n    u2 = upsample_concat_block(d1, e3)\n    d2 = residual_block(u2, f[3])\n    \n    u3 = upsample_concat_block(d2, e2)\n    d3 = residual_block(u3, f[2])\n    \n    u4 = upsample_concat_block(d3, e1)\n    d4 = residual_block(u4, f[1])\n    \n    outputs = tensorflow.keras.layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(d4)\n    model = tensorflow.keras.models.Model(inputs, outputs)\n    return model","07c048af":"metrics = [dice_coef, jaccard_coef,\n           'binary_accuracy', \n           tf.keras.metrics.Precision(), \n           tf.keras.metrics.Recall()]\n\nloss = [dice_coef_loss, \n        jaccard_coef_loss,\n        'binary_crossentropy']","8c0cb458":"mlflow.autolog()","86393219":"model = ResUNet()\nadam = tensorflow.keras.optimizers.Adam()\nmodel.compile(optimizer=adam, loss=loss, metrics=metrics)\nmodel.summary()","4e964b01":"weight_path=\"{}_res_unet.hdf5\".format('BEST')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)","32b672cd":"res = model.fit(X_train, Y_train, \n                validation_data=(X_val, Y_val), \n                batch_size=32, epochs=100,\n                callbacks=[checkpoint])","0bf9f32b":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\nax1.plot(res.history['loss'], '-', label = 'Loss')\nax1.plot(res.history['val_loss'], '-', label = 'Validation Loss')\nax1.legend()\n\nax2.plot(100 * np.array(res.history['binary_accuracy']), '-', \n         label = 'Accuracy')\nax2.plot(100 * np.array(res.history['val_binary_accuracy']), '-',\n         label = 'Validation Accuracy')\nax2.legend();","0df64044":"preds_val = model.predict(X_val)","f57c2523":"fig, axs = plt.subplots(nrows=5, ncols=3, figsize=(10, 20))\n\nfor i in range(5):\n    for j in range(3):\n        if j == 0:\n            axs[i, j].imshow(X_val[i + 10], cmap='gray')\n            axs[i, j].set_title('CXR')\n        elif j == 1:\n            axs[i, j].imshow(preds_val[i + 10], cmap='gray')\n            axs[i, j].set_title('predicted mask')\n       \n        elif j == 2:\n            axs[i, j].imshow(Y_val[i + 10], cmap='gray')\n            axs[i, j].set_title('Actual mask')","cbba0df5":"preds = model.predict(X_testNorm)","b94c553d":"fig, axs = plt.subplots(nrows=5, ncols=2, figsize=(10, 20))\n\nfor i in range(5):\n    for j in range(2):\n        if j != 1:\n            axs[i, j].imshow(X_testNorm[i + 10], cmap='gray')\n            axs[i, j].set_title('CXR')\n        else:\n            axs[i, j].imshow(preds[i + 10], cmap='gray')\n            axs[i, j].set_title('predicted mask')","1b9ed06b":"## plot model response","4c27049b":"# Loading images and masks","c917015d":"<br><br>\n\n## create_noise_images","5f4a134d":"**image size** = (256 x 256) \n\n_for memory matters_","5ac14202":"### images\n* 'CHNCXR_0242_0.png'\n* 'MCUCXR_0017_0.png'\n\n### mask\n* 'MCUCXR_0017_0.png'\n* 'CHNCXR_0337_1_mask.png'","91aeea62":"<br><br>\n\n## create_contrast_images_v2","0567e692":"# Data Augmetation\n\n\n* create_contrast_images_v1\n* create_contrast_images_v2\n* create_noise_images","87967090":"<br><br>\n\n## Check images","d109f3d4":"## prediction on test set","71c876e4":"# Dataset\n### Montgomery and Shenzhen for train\nhttps:\/\/www.kaggle.com\/nikhilpandey360\/chest-xray-masks-and-labels","57252ac9":"<br><br>\n\n## create_contrast_images_v1","636bfb2d":"# Prediction on Validation set","2917b55d":"# Rsidual U-Net\n\nbased on https:\/\/github.com\/nikhilroxtomar\/Deep-Residual-Unet?ref=morioh.com&utm_source=morioh.com"}}