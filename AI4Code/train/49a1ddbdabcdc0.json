{"cell_type":{"9534f897":"code","f48f4a3f":"code","965dcf63":"code","89b847aa":"code","8ef5efb0":"code","4190cb4b":"code","5e4b0334":"markdown","510ab0e6":"markdown","a8210e0e":"markdown","a0b53c2d":"markdown","bbd3224c":"markdown","496e7a12":"markdown"},"source":{"9534f897":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n#print(os.listdir(\"..\/input\"))\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\ndef convert_time(b):\n    return b[:2]\n\n# Any results you write to the current directory are saved as output.\npath=r'..\/input\/BreadBasket_DMS.csv'\ndf=pd.read_csv(path)","f48f4a3f":"#we`ll use this for analysis and keep the main dataframe separate, untouched\ndf_analysis=df.copy()\n#Get just the hour of day in the time column\ndf_analysis['Time']=df['Time'].apply(convert_time)\n\n#check whether it converted successfully.\ndf_analysis['Time'].head(2)","965dcf63":"#now lets find the top 5 most bought items in the bakery\ndf_most_bought=df_analysis.groupby(['Item'])['Item'].count()\ndf_most_bought=df_most_bought.sort_values(ascending=False)\ndf_top5=df_most_bought.head(5)\nplt.bar(df_top5.index,df_top5)\n","89b847aa":"#Now lets see what time of the day do we see the most sales\ndf_grpby=df_analysis.groupby('Time')['Time'].count()\n\nplt.xlabel('hr of the day in 24 hr format')\nplt.ylabel('sales made at the hour')\nplt.plot(df_grpby.index,\n        df_grpby)","8ef5efb0":"#lets see which were the busiest days of the year!\n#df_grpby=df_analysis.groupby(['Date','Time'])['Item'].count()\ndf_grpby=df_analysis.groupby(['Date'])['Item'].count()\ndf_grpby=df_grpby.sort_values(ascending=False)\ndf_top5_busiest=df_grpby.head(5)\nplt.xlabel('dates')\nplt.ylabel('transactions that day')\nplt.bar(df_top5_busiest.index,\n        df_top5_busiest)\n","4190cb4b":"busiest_day = df_analysis['Date']=='2017-02-04'\ndf_busiest_day=df_analysis[busiest_day].groupby(['Time'])['Item'].count()\nplt.xlabel('Hour of the day')\nplt.ylabel('transactions made')\nplt.plot(df_busiest_day.index,\ndf_busiest_day)\n\n","5e4b0334":"Huge rush of people on 4th of Feb, 2017 . \n\nLets see the time distribution for that day.","510ab0e6":"Now that we have our data in a format we want, lets do some analytics on it. Lets start off with the most bought items in the bakery.","a8210e0e":"Contrary to what we saw in the overall busiest time graph, This one paints a different picture, It's the busiest somewhere between 11 and 12 pm.\n\nStay tuned, there's more to come!","a0b53c2d":"So here we have time series data in a column Time and Date. For now , I will pay the most attention to time and for my analytical purposes, I'll adopt a quick-and-dirty method to handle time series data using the above convert time function.","bbd3224c":"Whoa! not a fan of tea. Coffee is holding up good, its almost twice as bread. Hmmm, Well at least they arent buying Pastries enough, That would be a dia-saster . (Presumably funny word play on Diabetes and Disaster). \n\nLets move on to see what times of the day we see the most traffic in the store.","496e7a12":"Someone's been busy! It seems to peak between 9 and 10 am . \"Cant miss that meeting, Looks like its espresso to go!\" . Must be the yuppies, With a coffee in one hand and a newspaper... oh sorry, cell phone in the other.\n\nLets check out what days of the year were the busiest for our bakery staff."}}