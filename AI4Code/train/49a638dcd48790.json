{"cell_type":{"0e171c7a":"code","72302087":"code","cada3fa9":"code","b8a749b5":"code","cd0b36a4":"code","915fc707":"code","7125f1a0":"code","5a1dcb1c":"code","b5fc38d5":"code","7820ad8b":"code","e41f3661":"code","57b68a8f":"code","b8373985":"code","bc7177c6":"code","f023ceda":"code","77f90c37":"code","4f408864":"code","8b1ed3b9":"code","df3ea358":"code","49d9666b":"code","114b70d4":"code","ef5d2194":"markdown","d8071101":"markdown","f325bfdc":"markdown","b406baa7":"markdown","4fe26034":"markdown","8b721c8d":"markdown","e658cc93":"markdown","1a6a24fd":"markdown","d60b99ec":"markdown","946700c9":"markdown","616ed51e":"markdown","9381e57b":"markdown","13e411de":"markdown","8dcd8003":"markdown","b589b3f5":"markdown","43d3a93d":"markdown","d7640a36":"markdown","249df54d":"markdown","47237b91":"markdown","e5b77bb2":"markdown","2237cbc9":"markdown"},"source":{"0e171c7a":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n#TF\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Sequential,Model\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.layers import Dense,Conv2D,Flatten,Dropout, Input, Concatenate, BatchNormalization\n#other\nfrom tqdm.notebook import tqdm\nimport pickle\nfrom PIL import Image\nfrom annoy import AnnoyIndex","72302087":"# dataset\ntrain_dir = \"\/kaggle\/input\/petfinder-pawpularity-score\/train\/\"\ntest_dir = \"\/kaggle\/input\/petfinder-pawpularity-score\/test\/\"\ntrain_table = pd.read_csv(\"\/kaggle\/input\/petfinder-pawpularity-score\/train.csv\")\ntest_table = pd.read_csv(\"\/kaggle\/input\/petfinder-pawpularity-score\/test.csv\")\n# set path\ntrain_table[\"Id\"] = train_dir + train_table[\"Id\"] + \".jpg\"\ntest_table[\"Id\"] = test_dir + test_table[\"Id\"] + \".jpg\"\n\nsample = pd.read_csv(\"\/kaggle\/input\/petfinder-pawpularity-score\/sample_submission.csv\")\ntrain_table.head(2)","cada3fa9":"def MobileNet_model():\n    base_model = keras.applications.mobilenet_v2.MobileNetV2(weights=\"imagenet\")\n    avg_pool_name = [l.name for l in base_model.layers][-2]\n    x = base_model.get_layer(avg_pool_name).output\n    model = Model(inputs=base_model.input, outputs=x)\n    return model\n\ndef img_yield(pathes, batch_size=32, size=(224,224)):\n    for i in tqdm(range(len(pathes) \/\/ batch_size+1)):\n        imgs = []\n        batch_pathes = pathes[i*batch_size : (1+i)*batch_size]\n        if len(batch_pathes)==0: break\n        for path in batch_pathes:\n            img = load_img(path, target_size=size)\n            img = tf.keras.applications.mobilenet_v2.preprocess_input(np.array(img))\n            imgs.append(img)\n        yield np.array(imgs)","b8a749b5":"model = MobileNet_model()\nembed_imgs = model.predict(img_yield(train_table[\"Id\"]))\nembed_imgs.shape","cd0b36a4":"annoy_model = AnnoyIndex(embed_imgs.shape[1])\nfor i, embed in enumerate(embed_imgs):\n    annoy_model.add_item(i, embed)\nannoy_model.build(i)","915fc707":"target_ID = 10\nN = 5\n\nids, distance = annoy_model.get_nns_by_item(target_ID, N, include_distances=True)\nprint(ids)\nprint(distance)","7125f1a0":"def show_img(ids):\n    imgs = [Image.open(train_table[\"Id\"][i]) for i in ids]\n    pawpularity = [train_table[\"Pawpularity\"][i] for i in ids]\n    fig, axes = plt.subplots(1, 5, figsize=(20,8))\n    for i, ax in zip(range(5), axes.ravel()):\n        ax.set_title(i+1)\n        ax.imshow(imgs[i])\n        if i == 0:\n            ax.set_title(f\"[target]\\nID:{ids[i]}\\npawpularity:{pawpularity[i]}\")\n        else:\n            ax.set_title(f\"ID:{ids[i]}\\npawpularity:{pawpularity[i]}\")\n        ax.axis(\"off\")\n    plt.show()","5a1dcb1c":"show_img(ids)","b5fc38d5":"distance_id = []\ndistance_vecotor = []\nfor i in tqdm(range(len(train_table[\"Id\"]))):\n    ids, distance = annoy_model.get_nns_by_item(i, 5, include_distances=True)\n    distance_id.append(ids)\n    distance_vecotor.append(distance)\n    \ndistance_of_nearest_img_vecotr = np.array(distance_vecotor)[:,1]\nplt.hist(distance_of_nearest_img_vecotr, bins=20)\nplt.title(\"distance of nearest image's vecotr histgram\")\nplt.show()","7820ad8b":"threshold = 0.4\ntarget_id = list(np.where(distance_of_nearest_img_vecotr<=threshold)[0])\ncheck_id = [distance_id[i] for i in target_id]\nprint(len(target_id))","e41f3661":"for i, ids in enumerate(check_id):\n    show_img(ids)","57b68a8f":"result_df = pd.DataFrame({\n    \"id_1\":np.array(check_id)[:,0], \n    \"id_2\":np.array(check_id)[:,1], \n    \"distance\":[distance_of_nearest_img_vecotr[i] for i in target_id], \n})\nresult_df[\"id_1_Paw\"] = result_df[\"id_1\"].map(lambda i: train_table[\"Pawpularity\"][i])\nresult_df[\"id_2_Paw\"] = result_df[\"id_2\"].map(lambda i: train_table[\"Pawpularity\"][i])\nresult_df[\"difference\"] = abs(result_df[\"id_1_Paw\"] - result_df[\"id_2_Paw\"])\nresult_df[\"Ave\"] = (result_df[\"id_1_Paw\"] + result_df[\"id_2_Paw\"]) \/ 2\nresult_df","b8373985":"def show_img_2(ids):\n    imgs = [Image.open(train_table[\"Id\"][i]) for i in ids]\n    pawpularity = [train_table[\"Pawpularity\"][i] for i in ids]\n    fig, axes = plt.subplots(1, 2, figsize=(8,4))\n    for i, ax in zip(range(2), axes.ravel()):\n        ax.set_title(i+1)\n        ax.imshow(imgs[i])\n        ax.set_title(f\"ID:{ids[i]}\\npawpularity:{pawpularity[i]}\")\n        ax.axis(\"off\")\n    plt.show()","bc7177c6":"discriminatory_id = [[462,9849],[1232,1485],[2622,4186],[3257,7204],[3662,5587],[3721,4077],[4496,4616],[8490,8792]]\nfor ids in discriminatory_id:\n    print(\"=\"*20,\"Delete\",\"=\"*20)\n    show_img_2(ids)","f023ceda":"need_process_df = pd.read_csv(\"..\/input\/petfinder-new-table\/pet_search.csv\")\nneed_process_df.head(7)","77f90c37":"new_scores = need_process_df[\"new_score\"].values\n\nfor i in range(len(need_process_df)):\n    if need_process_df[\"new_score\"][i]==\"-\":\n        continue\n    ids = list([need_process_df[\"id\"][i], int(need_process_df[\"dupulicate\"][i])])\n    print(\"=\"*20,\"Change value\",\"=\"*20)\n    print(f\"NEW score(ave): {new_scores[i]}\")\n    show_img_2(ids)\n    print()","4f408864":"new_train_table = train_table.copy()\n# Delete flag\ndelete_ids = [item for l in discriminatory_id for item in l]\n# Duplicate delete flag\n[delete_ids.append(l) for l in list(need_process_df[\"id\"][need_process_df[\"new_score\"]==\"-\"])]\n# make DELETE column\nnew_train_table[\"DELETE\"] = new_train_table.index.map(lambda x:1 if x in delete_ids else 0)\n# make NEW_SCORE columns\ntmp = need_process_df[need_process_df[\"new_score\"]!=\"-\"].copy()\ntmp[\"new_score\"] = tmp[\"new_score\"].astype(int)\nnew_train_table[\"NEW_SCORE\"] = new_train_table.index.map(lambda x:tmp[\"new_score\"][tmp[\"id\"]==x].values[0] if x in list(tmp[\"id\"]) else new_train_table[\"Pawpularity\"][x])\n\nnew_train_table.head()","8b1ed3b9":"new_train_table[\"DELETE\"].value_counts()","df3ea358":"new_train_table[new_train_table[\"DELETE\"]==1].head(5)","49d9666b":"new_train_table[new_train_table[\"Pawpularity\"]!=new_train_table[\"NEW_SCORE\"]].head(5)","114b70d4":"new_train_table.to_csv(\".\/new_table.csv\", index=None)","ef5d2194":"# 9. Additional editing (2021\/12\/2) \n## Score Variation","d8071101":"### Display the extracted image","f325bfdc":"I investigated the variation of CV and LB scores with swintransformer(large_224) in the following note.  \nhttps:\/\/www.kaggle.com\/showeed\/tf-swin-kfold-18-046  \n\nDuplicate removal was a good result, but using similar images as an average process was not so good.  \nI wonder how I should process them('\u03c9')\n\n![image.png](attachment:c2e42f41-a196-4ae4-9aa4-c0f3a009ae6d.png)","b406baa7":"# 7. Final(impressions)\nBy using annoy to search for similar images, we were able to find duplicate images with differences in the objective variable.  \nHow to update the dataset after this is still under consideration.  \nIf you have any good ideas, I would be happy to hear your comments.  \n\nThank you for seeing this through to the end!","4fe26034":"# ","8b721c8d":"# 3. Image feature\nThere are various models available, but since this is not a detailed analysis, we used mobilenet, which runs easily on cpu.","e658cc93":"# 2. load dataset and set path","1a6a24fd":"# 5. distance of images","d60b99ec":"## 8-2 Change the score of duplicate or extremely similar images.\n#### The new score is the average of the two images","946700c9":"### Get N close IDs and vectors by specifying IDs.","616ed51e":"## 8-1 Image pairs that are difficult to distinguish","9381e57b":"### View and verify the actual display","13e411de":"# 4. Build Annoy ","8dcd8003":"# 1. Library ","b589b3f5":"#### Checking the results side-by-side","43d3a93d":"## Overview\n### Extract similar images to see what the score looks like.\n#### Main use of annoy!!\n\n![image.png](attachment:134e17cd-b527-4f9e-a789-d232a94adbff.png)\n![image.png](attachment:ec3b76f6-b831-4fba-82bd-58a723f9ed2f.png)","d7640a36":"### Display the most similar image (target image, most similar image) in a DataFrame","249df54d":"# 6. Result","47237b91":"### For now, I set the threshold to 0.4 and extracted it.","e5b77bb2":"## 8-3 Add delete flag and new score to original data","2237cbc9":"# 8. Additional editing (2021\/11\/11) \n\n### I will share the results I visually checked from Similar images results.\nTired...\n\n\n### This is just my personal opinion, so please refer to it."}}