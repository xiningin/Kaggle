{"cell_type":{"a2545a46":"code","c3ecc9d1":"code","6ac6575a":"code","04253942":"code","bd15f04f":"code","5ee7168d":"code","2cc8bdce":"code","0ccda0a6":"code","34fa2a19":"code","c0503ae6":"markdown","e8475a4b":"markdown","cc188ced":"markdown","a1c6675c":"markdown","59d21b85":"markdown","399e0049":"markdown","94ee7198":"markdown"},"source":{"a2545a46":"import sys\nimport os\nimport time\nimport datetime\nimport random\nimport shutil\nimport tensorflow as tf\nimport tensorflow.keras.optimizers\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom shutil import copyfile\nfrom os import getcwd\n\nimport numpy as np\nimport matplotlib as mpimg\nimport matplotlib.pyplot as plt","c3ecc9d1":"#os.mkdir('\/kaggle\/working\/Images')\n#os.mkdir('\/kaggle\/working\/Images\/dandelion_v_other\/')\n#os.mkdir('\/kaggle\/working\/metrics\/')","6ac6575a":"def create_and_clear_dir_structure():\n    try:\n        if not os.path.isdir('\/kaggle\/working\/Images'):\n            os.mkdir('\/kaggle\/working\/Images') \n        \n        if os.path.isdir('\/kaggle\/working\/Images\/dandelion_v_other'):\n            print('Directory dandelion_v_other found. Clearing out for next build.')\n            shutil.rmtree('\/kaggle\/working\/Images\/dandelion_v_other\/')\n        else:\n            os.mkdir('\/kaggle\/working\/Images\/dandelion_v_other\/')\n            os.mkdir('\/kaggle\/working\/Images\/dandelion_v_other\/training')\n            os.mkdir('\/kaggle\/working\/Images\/dandelion_v_other\/testing')\n            os.mkdir('\/kaggle\/working\/Images\/dandelion_v_other\/training\/dandelion')\n            os.mkdir('\/kaggle\/working\/Images\/dandelion_v_other\/testing\/dandelion')\n            os.mkdir('\/kaggle\/working\/Images\/dandelion_v_other\/training\/other')\n            os.mkdir('\/kaggle\/working\/Images\/dandelion_v_other\/testing\/other')\n            \n        if not os.path.isdir('\/kaggle\/working\/metrics\/'):\n            os.mkdir('\/kaggle\/working\/metrics\/')\n            \n    except OSError as e:\n        print(f\"OS DIR ERR: {e}\")\n        pass\n\ncreate_and_clear_dir_structure()","04253942":"###----------SPLIT THE DATA INTO TRAIN\/TEST SETS-----------###\ndef split_data(SOURCE,TRAINING,TESTING,SPLIT_SIZE):\n    img_list = os.listdir(SOURCE)\n    random.shuffle(img_list)\n    length_of_list = len(img_list)\n    length_of_training_list = int(length_of_list*SPLIT_SIZE)\n    length_of_test_list = length_of_list - length_of_training_list\n    train_list = img_list[:length_of_training_list]\n    test_list = img_list[length_of_training_list:]\n\n    print(f\"size:{length_of_list}\")\n    print(f\"TRAIN size:{length_of_training_list}\")\n    print(f\"TEST size:{length_of_test_list}\")\n\n    for file in train_list:\n        full_img_path = SOURCE+file\n        #print(f\"TRAIN: {full_img_path}\")\n        if(os.path.getsize(full_img_path) < 0): #double check no 0 length image files\n            img_list.remove(file)\n            print(f\"Found 0 length image file: {file}\")\n            print(f\"File has been removed.\")\n        else:\n            copyfile(full_img_path,TRAINING+file)\n\n    for file in test_list:\n        full_img_path = SOURCE + file\n        #print(f\"TEST: {full_img_path}\")\n        if (os.path.getsize(full_img_path) < 0):  # double check no 0 length image files\n            img_list.remove(file)\n            print(f\"Found 0 length image file: {file}\")\n            print(f\"File has been removed.\")\n        else:\n            copyfile(full_img_path, TESTING + file)\n\nDANDELION_SOURCE_DIR   = \"\/kaggle\/input\/dandelionimages\/Images\/dandelion\/\"\nOTHER_SOURCE_DIR       = \"\/kaggle\/input\/dandelionimages\/Images\/other\/\"\nTRAINING_DANDELION_DIR = \"\/kaggle\/working\/Images\/dandelion_v_other\/training\/dandelion\/\"\nTESTING_DANDELION_DIR  = \"\/kaggle\/working\/Images\/dandelion_v_other\/testing\/dandelion\/\"\nTRAINING_OTHER_DIR     = \"\/kaggle\/working\/Images\/dandelion_v_other\/training\/other\/\"\nTESTING_OTHER_DIR      = \"\/kaggle\/working\/Images\/dandelion_v_other\/testing\/other\/\"\n\n\nsplit_ratio = 0.9\nsplit_data(DANDELION_SOURCE_DIR,TRAINING_DANDELION_DIR,TESTING_DANDELION_DIR,split_ratio)\nsplit_data(OTHER_SOURCE_DIR,TRAINING_OTHER_DIR,TESTING_OTHER_DIR,split_ratio)\n\nlen_of_training_len = len(os.listdir('\/kaggle\/working\/Images\/dandelion_v_other\/training\/dandelion\/')) + len(os.listdir('\/kaggle\/working\/Images\/dandelion_v_other\/training\/other\/'))\n\nprint(len(os.listdir('\/kaggle\/working\/Images\/dandelion_v_other\/training\/dandelion\/')))\nprint(len(os.listdir('\/kaggle\/working\/Images\/dandelion_v_other\/training\/other\/')))\nprint(len(os.listdir('\/kaggle\/working\/Images\/dandelion_v_other\/testing\/dandelion\/')))\nprint(len(os.listdir('\/kaggle\/working\/Images\/dandelion_v_other\/testing\/other\/')))","bd15f04f":"def create_model():\n    model = tf.keras.models.Sequential([\n        #we'll use 150x150 size and 3 color model\n        tf.keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)),\n        tf.keras.layers.MaxPooling2D(2,2),\n        tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n        tf.keras.layers.MaxPooling2D(2,2),\n        tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n        tf.keras.layers.MaxPooling2D(2,2),\n        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n        tf.keras.layers.MaxPooling2D(2, 2),\n        #Flatten the results fo feed into DNN\n        tf.keras.layers.Flatten(),\n        #pass into 512 neuron hidden layer\n        tf.keras.layers.Dense(512,activation='relu'),\n        #Single output neuron...its a dandelion or not\n        tf.keras.layers.Dense(1,activation='sigmoid')\n    ])\n\n    model.compile(optimizer=RMSprop(lr=1e-05),loss='binary_crossentropy',metrics=['accuracy'])\n    return model\n","5ee7168d":"def run_training(model):\n    TRAINING_DIR = '\/kaggle\/working\/Images\/dandelion_v_other\/training'\n    train_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        rotation_range = 40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest'\n    )\n\n    #train w\/batch size of 10\n    train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n                                                        batch_size=24,\n                                                        class_mode='binary',\n                                                        target_size=(150,150))\n\n    VALIDATION_DIR = '\/kaggle\/working\/Images\/dandelion_v_other\/testing'\n    validation_datagen = ImageDataGenerator( rescale= 1.\/255)\n\n\n    validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n                                                                  batch_size=24,\n                                                                  class_mode='binary',\n                                                                  target_size=(150,150))\n\n    checkpoint_path = \"\/kaggle\/working\/training_1\/cp.ckpt\"\n    checkpoint_dir = os.path.dirname(checkpoint_path)\n\n    # Create a callback that saves the model's weights\n    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                     save_weights_only=True,\n                                                     verbose=1)\n    \n    #4 epochs for testing, however 20-30 seems more appropriate for training\n    history = model.fit(train_generator,\n                                  epochs=20,verbose=1,\n                                  validation_data = validation_generator,\n                                  callbacks=[cp_callback])\n\n    return history","2cc8bdce":"model = create_model()\ntime_start = round(time.time())\nhistory = run_training(model)\ntime_end = round(time.time())","0ccda0a6":"def plot_history(history):\n    #-----------------------------------------------\n    # Get list of results on training and test data\n    # for each epoch\n    #-----------------------------------------------\n    acc     = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss    = history.history['loss']\n    val_loss= history.history['val_loss']\n\n    epochs = range(len(acc))\n\n    #-----------------------------------------------\n    #Plot train\/validation accuracy\n    #-----------------------------------------------\n    plt.plot(epochs,acc,'r',label=\"Training Accuracy\")\n    plt.plot(epochs,val_acc,'b',label=\"Validation Accuracy\")\n    plt.title('Training and validation accuracy')\n    plt.legend()\n    #-----------------------------------------------\n    #Plot train\/validation loss\n    #-----------------------------------------------\n    plt.plot(epochs,loss,'y',label=\"Training Loss\")\n    plt.plot(epochs,val_loss,'g',label=\"Validation Loss\")\n    plt.title('Training and validation loss')\n    plt.legend()\n\nplot_history(history)","34fa2a19":"last_completed_training = datetime.datetime.now()\nlast_completed_accuracy = history.history['accuracy']\nlast_completed_loss =  history.history['loss']\n\nacc      = np.array(history.history['accuracy']).mean()\nval_acc  = np.array(history.history['val_accuracy']).mean()\nloss     = np.array(history.history['loss']).mean()\nval_loss = np.array(history.history['val_loss']).mean()\n\nlast_date_time_of_completed_training = datetime.datetime.now().strftime(\"%c\")\nlength_of_time_for_training = time_end - time_start\n\nfp = open(\"\/kaggle\/working\/metrics\/metrics.csv\",\"w\")\nfp.write(\"Last_Accuracy;Last_Loss;Validation_Loss;Length_of_Training;Last_Training_Finish;Total_Images\\n\")\ndata_string = f\"{acc};{loss};{val_loss};{length_of_time_for_training};{last_date_time_of_completed_training};{len_of_training_len}\\n\"\nfp.write(data_string)\nfp.close()\n\ndef model_quality_save(acc,model,threshold=0.50):\n    if(acc > threshold):\n        print(f\"Model achieved {acc}% accuracy!\\nSaving dandy_model.h5 for use.\")\n        model.save('\/kaggle\/working\/saved_models\/dandy_model_latest.h5')\n    else:\n        #send message that model was not good with acc\/loss\/val_acc\/val_loss\n        print(f\"Model only made it to {acc}. Not saving. \")\n        pass\n\nprint(acc)\nmodel_quality_save(acc,model)\n\n","c0503ae6":"This project is a very simple binary image classification model for me to do some \"real world learning\": - Dandelions - Anything NOT dandelions :)\n\nInitial thoughts and findings: Need lots and lots more images. While the training results in decent accuracy, the validation loss is substantial. My initial 1,200+ images (50% dandelion\/50% not) seems woefully small. Maybe transfer learning (resnet, etc) is better way to go??\n\ndandelionimages contains Images\/dandelion and Images\/other. The dandelion_v_other was incorrectly part of .zip that was uploaded. Will fix shortly as this dir is a working dir for train\/test splits.","e8475a4b":"SETUP DIRECTORY STRUCTURE FOR TRAINING AND TESTING","cc188ced":"FUNCTION TO PROPERLY SPLIT UP OUR TRAIN\/TEST IMAGES ACCORDING TO OUR SPLIT-SIZE RATIO. USUALLY .9\/.1","a1c6675c":"TRAIN MODEL: Including ImageGenerator so we can just hand off images via flow_from_directory method","59d21b85":"BUILD MODEL","399e0049":"Summarize some of the data and metrics","94ee7198":"REVIEW VIA PLOTS"}}