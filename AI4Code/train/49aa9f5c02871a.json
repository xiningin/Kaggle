{"cell_type":{"f56a5c52":"code","fbb93a4f":"code","88a24010":"code","0048d109":"code","fdf3afb9":"code","30546138":"code","83f9a6d8":"code","6ea31619":"code","645a7f9f":"code","7f7a2d14":"code","76d8d0b5":"code","cc40c65f":"code","96f4fe6b":"code","4c07aa9c":"code","cb2e1926":"code","24cddbf7":"code","3dba7003":"code","5598e046":"code","384809ff":"code","d7522e70":"code","df2914f3":"code","ef35ae3a":"code","86df1d5d":"code","519b9f15":"markdown","25bb7a9f":"markdown"},"source":{"f56a5c52":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n\nimport statsmodels.api as sm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom scipy import stats\nstats.chisquares = lambda chisq , df : stats.chi2.sf(chisq, df)\n\nsns.set()","fbb93a4f":"#load the data\nraw_data = pd.read_csv('\/kaggle\/input\/admittancerecord\/2.01. Admittance.csv')\nraw_data","88a24010":"data = raw_data.copy()\ndata['Admitted'] = data['Admitted'].map({'Yes' : 1, 'No' : 0})\ndata","0048d109":"y= data['Admitted']\nx1 = data['SAT']","fdf3afb9":"\nx = sm.add_constant(x1)\n\nreg_log= sm.Logit(y,x)\nresults_log = reg_log.fit()\n\n\ndef f(x, b0,b1):\n    return np.array(np.exp(b0 + x * b1) \/ (1 + np.exp(b0 + x * b1)))\n\nf_scored = np.sort(f(x1, results_log.params[0], results_log.params[1]))\nx_score = np.sort(np.array(x1))","30546138":"# create a scatter plot to view the data\n\nplt.scatter(x1,y, color = 'C0')\nplt.xlabel('SAT', fontsize = 20)\nplt.ylabel('Admitted', fontsize = 20)\nplt.plot(x_score, f_scored, color = 'C8')\nplt.show()","83f9a6d8":"results_log.summary()","6ea31619":"raw_data = pd.read_csv('\/kaggle\/input\/studentrecordwithsatgenderadmitted\/2.02. Binary predictors.csv')\nraw_data","645a7f9f":"data= raw_data.copy()\ndata['Admitted'] = data['Admitted'].map({'Yes': 1, 'No' : 0})\ndata['Gender']  = data['Gender'].map({'Female' : 1, 'Male' : 0})\ndata","7f7a2d14":"y = data['Admitted']\nx1 = data[['Gender', 'SAT']]","76d8d0b5":"x = sm.add_constant(x1)\n\nreg_log= sm.Logit(y,x)\nresults_log = reg_log.fit()","cc40c65f":"results_log.summary() # accessing the accuracy indicator is 'Pseudo R-squ.' from the summary below","96f4fe6b":"results_log.predict()","4c07aa9c":"np.array(data['Admitted'])","cb2e1926":"results_log.pred_table()","24cddbf7":"#confusion matrix\n\ncm_df = pd.DataFrame(results_log.pred_table())\ncm_df.columns = ['Predicted 0', 'Prdicted 1']\ncm_df = cm_df.rename(index = {0 : 'Actual 0' , 1 : 'Actual 1' })\ncm_df","3dba7003":"#calculate accuracy\n\ncm = np.array(cm_df)\naccuracy_train = (cm[0,0] + cm[1,1]\/cm.sum())\naccuracy_train","5598e046":"test =  pd.read_csv('\/kaggle\/input\/testdataforchoosingstudent\/2.03. Test dataset.csv')\ntest","384809ff":"\ntest['Admitted'] = test['Admitted'].map({'Yes': 1, 'No' : 0})\ntest['Gender']  = test['Gender'].map({'Female' : 1, 'Male' : 0})\ntest","d7522e70":"test_actual  = test['Admitted']\ntest_data = test.drop(['Admitted'], axis=1)\ntest_data = sm.add_constant(test_data)\ntest_data","df2914f3":"# confusion matrix\n\ndef confusion_matrix(data, actual_values, model):\n    pred_values = model.predict(data)\n    bins= np.array([0,0.5,1])\n    cm = np.histogram2d(actual_values, pred_values, bins=bins)[0]\n    accuracy = (cm[0,0] + cm[1,1]\/cm.sum())\n    return cm, accuracy","ef35ae3a":"cm = confusion_matrix(test_data, test_actual, results_log)\ncm","86df1d5d":"cm_df = pd.DataFrame(cm[0])\ncm_df.columns = ['Predicted 0', 'Prdicted 1']\ncm_df = cm_df.rename(index = {0 : 'Actual 0' , 1 : 'Actual 1' })\ncm_df","519b9f15":"# Testing the model with new data","25bb7a9f":"In stats model maximm number if iterationis 35, after that it will stop trying\n"}}