{"cell_type":{"7c41c900":"code","904e91e8":"code","e65c506e":"code","5006fcdb":"markdown","cff31133":"markdown","7c6809b2":"markdown","fa896b65":"markdown","15dbfa23":"markdown","145011a3":"markdown","3d5af4a3":"markdown","e863ecba":"markdown","68abf7cc":"markdown","2c55bf17":"markdown"},"source":{"7c41c900":"import collections\n\ndef find_most_common(values):\n    \"\"\"\"Return the value of the most common item in a list\"\"\"\n    list_counts = collections.Counter(values)\n    top_two_values = list_counts.most_common(2)\n\n    # make sure we don't have a tie for most common\n    assert top_two_values[0][1] != top_two_values[1][1]\\\n        ,\"There's a tie for most common value\"\n    \n    return(top_two_values[0][0])","904e91e8":"values_list = [1, 2, 3, 4, 5, 5, 5]\n\nfind_most_common(values_list)","e65c506e":"values_list = [1, 2, 3, 4, 4, 4, 5, 5, 5]\n\nfind_most_common(values_list)","5006fcdb":"The single best thing you can do to make your code more professional is to make it **reusable**.\n\nWhat does \u201creusable\u201d mean? At some point in your data science career, you\u2019re going to write code that will be used more than just once or twice. Maybe you\u2019re running the same preprocessing pipeline on some different sets of image files, or you\u2019ve got a suite of evaluation techniques that you use to compare models. We\u2019ve all copied and pasted the same code, but **once you find yourself copying the same code more than once or twice, it\u2019s time to sink some time into making your code reusable**. Reusing well-written code isn\u2019t cheating or slacking: it\u2019s an efficient use of your time and [it\u2019s considered a best practice](https:\/\/en.wikipedia.org\/wiki\/Don%27t_repeat_yourself) in software engineering.\n\nThere are six central principles that I think 1) make it easy for you or your colleagues to reuse your code, 2) make your code look really polished and professional and, above all, 3) **save you time**.\n\n  * \ud83d\udce6 **Modular**: Code is broken into small, independent parts (like functions) that each do one thing. Code you\u2019re reusing lives in a single central place.\n  * \u2714\ufe0f **Correct**: Your code does what you say\/think it does.\n  * \ud83d\udcd6 **Readable**: It\u2019s easy to read the code and understand what it does. Variable names are informative and code has up-to-date comments and [docstrings](https:\/\/www.python.org\/dev\/peps\/pep-0257\/).\n  * \ud83d\udc85 **Stylish**: Code follows a single, consistent style (e.g. the [Tidyverse style guide](https:\/\/style.tidyverse.org\/) for R, [PEP 8](https:\/\/www.python.org\/dev\/peps\/pep-0008\/) for Python code)\n  * \ud83d\udee0\ufe0f **Versatile**: Solves a problem that will happen more than once and anticipates variation in the data.\n  * \ud83d\udca1 **Creative**: Solves a problem that hasn\u2019t already been solved or is a clear improvement over an existing solution.\n\nLet\u2019s go through each of these steps in a bit more detail.with a bit of sample code and see how they work in practice.\n","cff31133":"## \u2714\ufe0f Correct\n\nBy \u201ccorrect\u201d I mean that your code does what you say\/think it does. This can be tricky to check. One way to make sure your code is correct is through [code review](https:\/\/medium.com\/apteo\/code-reviewing-data-science-work-774747248e33).\n\n> **Code review** is a process where one of your colleagues carefully checks over your code to make sure that it works the way you think it does.\n\nUnfortunately, that\u2019s not always practical for data scientists. Especially if you\u2019re the only data scientists in a company, it would be tough to get someone without a statistics or machine learning background to the point where they could give you expert feedback on your code. As the field grows larger it may become more common for data science code to undergo code review\u2026 but the meantime you can help make sure your code is correct by including some tests.\n\n> **Tests** are little pieces of code you use check that your code is working correctly \n\nWriting tests doesn't have to be complex! Here, I\u2019m going to work through how to add a test to a function with just a single line of code.\n\n(The example I\u2019m going to work on here is in Python, if you\u2019re looking for an R example, or even just more discussion of where testing fits in the data science workflow, [check out this vignette by Hadley Wickham](http:\/\/r-pkgs.had.co.nz\/tests.html).)\n\nIn the Python function I wrote above, I returned the most common value\u2026 but what if there was more than one value tied for the most common? Currently our function will just return one of them, but if I really need to know if there\u2019s a tie my current function won\u2019t do that. \n\nSo let\u2019s include a test to let us know if there\u2019s a tie! `assert` is a method [built into Python](https:\/\/docs.python.org\/3\/reference\/simple_stmts.html#the-assert-statement) that will let us check that something is true. If it is, nothing happens. If it isn\u2019t, our function will stop and give us an error message.","7c6809b2":"We get an assertion error and the nice, helpful error message we wrote for ourselves earlier!\n\nWhile this is a pretty simple example, including some tests can help you make sure that your code is doing what you think it\u2019s doing. This is particularly important if you\u2019re importing other libraries and updating them regularly: just because you didn\u2019t change your code it doesn't mean that the code you\u2019re importing hasn\u2019t changed! Tests can help you find bugs before they end up creating problems. \n\n> Using tests to check that your code is correct can help you save time by catching bugs quickly.","fa896b65":"## \ud83d\udce6 Modular\n\nModular code means that your code is broken into small, independent parts (like functions) that each do one thing. \n\nEach function, whether in Python or R, has several parts:\n\n* A *name* for the function.\n* *Arguments* for your function. This is the information you\u2019ll pass into your function. \n* The *body* of your function. This is where you define what your function does. Generally, I\u2019ll write the code for my function and test with an existing data structure first and then put the code into a function. \n* A *return value*. This is what your function will send back after it\u2019s finished writing. In Python, you\u2019ll need to specify what you want to return by adding `return(thing_to_return)` at the bottom of your function. In R, by default the output of the last line of your function body will be returned. \n\nLet\u2019s look at some examples. Here are two sample functions, one in Python & one in R, that do the same thing (more or less).\n\n* They both have the same function name, `find_most_common`\n* They both have one argument, `values`\n* They both have a body that does roughly the same thing: count how many times each value in `values` shows up\n* They both return the same thing: the value(s) that is most common in the input argument `values`\n\n### Python Example\n\n```\n# define a function\ndef find_most_common(values):\n    list_counts = collections.Counter(values)\n    most_common_values = list_counts.most_common(1)\n    \n    return(most_common_values[0][0])\n\n# use the function\nfind_most_common([1, 2, 2, 3])\n```\n\n### R Example\n\n```\n# define the function\nfind_most_common <- function(values){\n  freq_table <- table(values)\n  most_common_values <- freq_table[which.max(freq_table)]\n\n  names(most_common_values)\n}\n\n# use the function\nfind_most _common(c(1, 2, 2, 3))\n```\nPretty straightforward, right? (Even if the syntax between the two languages is a little different). You can use this general principle of writing little functions that do one thing each to break your code up into smaller pieces. \n\n### Why functions? \n\nIf you have some more programming experience, you may be curious why I choose to talk about functions instead of classes or other related concepts from [object oriented programming]. I think functional programming tends to be a very natural fit for a lot of data science work so that\u2019s the general framework I\u2019m going to use to show you examples of modular code.\n\n> **Functional programming.**  \\A style of writing code where you pass one or more pieces of data into a function and the result you get back will be some sort of transformation of those pieces of data. This means that you wouldn\u2019t do things like modifying an existing variable in the body of a function. If you\u2019re interested in learning more, I\u2019d recommend [this talk on functional programming for data science](https:\/\/www.youtube.com\/watch?v=bzUmK0Y07ck). \n\nThe main reason that I like using a functional approach for data science is that it makes it easy to start chaining together multiple functions into a data processing pipeline: the output of one function becomes the input to the next. Something like this:\n\n> data -> function 1 -> function 2 -> function 3 -> transformed data\n\nThere are some very helpful tools to help you do this, including [pipes in R](https:\/\/magrittr.tidyverse.org) and [method chaining from the pyjanitor in Python](https:\/\/pyjanitor.readthedocs.io\/notebooks\/pyjanitor_intro.html#Clean-up-our-data-using-a-pyjanitor-method-chaining-pipeline).\n\n### Python example: chaining functions together\n\nThis example is based on one from [the pyjanitor documentation](https:\/\/pyjanitor.readthedocs.io\/notebooks\/pyjanitor_intro.html#Clean-up-our-data-using-a-pyjanitor-method-chaining-pipeline) and shows you how to set up a little data pipeline using existing Pandas functions.\n\nIt reads in a file (the `pd.read_excel('dirty_data.xlsx')` line) and then transforms it using a number of functions that clean the column names, remove missing data, renames one of the columns and converts one of the columns to datetime format. The output is also a dataframe.\n\n```\ncleaned_df = (\n    pd.read_excel('dirty_data.xlsx')\n    .clean_names()\n    .remove_empty()\n    .rename_column(\"full_time_\", \"full_time\")\n    .convert_excel_date(\"hire_date\")\n)\n\ncleaned_df\n```\n### R example: chaining functions together\n\nAnd here\u2019s an R example that does the same thing as the Python example. \n\n```\ncleaned_df <- read_excel('dirty_data.xlsx') %>%\n  clean_names() %>%\n  remove_empty() %>%\n  renames(\u201cfull_time\u201d, \u201cfull_time_\u201d) %>%\n  excel_numeric_to_date(\u201chire_date\u201d)\n```\n\n> Breaking your code apart into functions--particularly if each function just transforms the data that gets passed into it--can save you time by letting you reuse code and combine different functions into compact data pipelines,\n","15dbfa23":"The `assert` statement here is checking that the count of the most common value isn\u2019t the same as the count of the second most common value. If it is, the function stops and returns an error message.\n\nFirst, let\u2019s check that our function will work as expected if there\u2019s not a tie: \n","145011a3":"\n## \ud83d\udc85 Stylish\n\nWhen I say \u201cstylish\u201d here I literally mean \u201cfollowing a specific style\u201d. Styles are described and defined in documents called \u201cstyle guides\u201d. If you haven\u2019t used a style guide before, they\u2019re very handy! Following a specific style guide makes your code easier to read and helps you avoid common mistakes. (It can also help you avoid writing code with [code smells](https:\/\/en.wikipedia.org\/wiki\/Code_smell).)\n\nStyle guides will offer guidance on things like where to put white spaces, how to organize the structure of code within a file and how to name things like functions and files. Code that doesn\u2019t consistently follow a style guide may still run perfectly fine, but it will look a little odd and generally be hard to read.\n\n> Pro tip: You can actually use a program called a \u201clinter\u201d to automatically check if your code follows a specific style guide. Pylint for Python & lintr for R are two popuilar linters. You can see [an example of how to use a linter to check an R utility script here](https:\/\/www.kaggle.com\/rtatman\/linting-scripts-in-r).\n\nOnce you\u2019ve picked a style guide to follow, you should do your best to follow it consistently within your code. There are, of course, differences across style guides, but a couple things do tend to be the same across both Python and R style guides. A couple examples:\n\n* You should have all of your imports (`library(package_name)` or `import module_name`) at the top of your code file and only have one import per line.\n* Whether you indent with tabs or spaces will depend on your style guide, but you should never mix tabs and spaces (e.g. have some lines indented with two spaces and some lines indented with a tab).\n* Avoid having spaces at the ends of your lines\n* Function and variables names should all be lower case and have words seperated_by_underscores (unless you\u2019re working with existing code that follows another standard, in which case use that)\n* Try to keep your lines of code fairly short, ideally less than 80 characters long\n\nStyle guides can be a little overwhelming at first, but don\u2019t stress too much. As you read and write more code it will become easier and easier to follow a specific style guide. In the meantime, **even a few small improvements will make your code easier to follow and use**. \n\n### Example\n\nFor this example, we\u2019re going to be using some R code and modifying it to fit the [Tidyverse style guide](https:\/\/style.tidyverse.org).\n\n```\nCZS <- function(x) {\n   sd <- sd(x); m = mean(x)\n(x -m)\/sd}\n```\n\nThere are quite a few things we can fix here so that they follow the Tidyverse style guide. \n\n* The function name isn\u2019t informative and doesn\u2019t follow the Tidyverse conventions (lower_case_with_underscores).\n* We\u2019re using multiple assignment operators (<- and =).\n* We\u2019re using a mix of tabs and spaces.\n* We\u2019ve concatenated multiple lines using `;` (this is possible but *strongly discouraged* in both Python and R).\n* We don\u2019t have spaces around all our infix operators (mathematical symbols like `+`, `-`, `\\`, etc.).\n* We don\u2019t have the closing curly brace, `}`, on a new line.\n\nOnce we\u2019ve tidied these things up, our code now looks like this:\n\n```\ncalculate_z_score <- function(x) {\n    sd <- sd(x)\n    m <- mean(x)\n\n    (x - m) \/ sd\n}\n```\nI personally find this a lot easier to read than the first example, even though they do the exact same thing.  \n\n> Stylish code is generally faster to read and find bugs in. In addition, most style guides recommend best practices to help you avoid common bugs. All of this saves you and your colleagues time in debugging.\n","3d5af4a3":"## \ud83d\udee0\ufe0f Versatile\n\n\u201cVersatile\u201d means useful in a variety of situations. Versatile code solves a problem that will happen more than once and anticipates variation in the data. \n\n### Should I only ever write code if I\u2019m planning to reuse it?\n\nNo, of course not. There\u2019s nothing wrong with writing new code to solve a unique problem. Maybe you need to rename a batch of files quickly or someone\u2019s asked you to make a new, unique visualization for a one-off presentation. \n\nHowever, you probably don\u2019t want to go to all the trouble of making every single line of code you ever write totally polished and reusable. [While some folks would disagree with me](https:\/\/www.youtube.com\/watch?v=Sg6xJ0ACc78) **I personally think it\u2019s only worth spending a lot of time polishing code if you--or someone else--is actually going to reuse it**. \n\nData scientists have to do and know about a lot of different things: you\u2019ve probably got a better use for your time than carefully polishing every line of code you ever write. Investing time in polishing your code starts to make sense when you know the code is going to be reused. A little time spent making everything easier to follow and use while it\u2019s still fresh in your head can save a lot of time down the line.\n\n### Anticipating variation in the data\n\nBy \u201cvariation in the data\u201d I mean differences in the data that will break things down the line. For example, maybe you\u2019ve written a function that assumes that your dataframe has a column named `latitude`. If someone changes the name of the column to `lat` in the database next week, your code may break. \n\nIn order to make sure that you\u2019re getting the data in you expect to be getting in, you can use data validation. I have [a notebook here](https:\/\/www.kaggle.com\/rtatman\/automating-data-pipelines-day-2#Scripting-your-data-validation) that covers data validation in more detail if you\u2019re curious, but here are a few of my favorite tools.\n\n---\n\n**Python:**\n\n* I like the csvvalidator package, which [I\u2019ve previously written an introduction to](https:\/\/www.kaggle.com\/rtatman\/dashboarding-with-notebooks-day-5). \n* For JSON data in Python, the [Cerberus module](http:\/\/docs.python-cerberus.org\/en\/stable\/usage.html) is probably the most popular tool. \n* For visualizing missing data in particular, [the missingno package](https:\/\/github.com\/ResidentMario\/missingno) can be very handy. \n* To check the type of your file the [python-magic module](https:\/\/github.com\/ahupp\/python-magic) can be helpful.\n\n**R:**\n\n* For R, [the validate package](https:\/\/cran.r-project.org\/web\/packages\/validate\/vignettes\/introduction.html) for data validation ([which I\u2019ve previously written a tutorial for](https:\/\/www.kaggle.com\/rtatman\/dashboarding-with-notebooks-day-5-r)) is probably your best bet. It can handle tabular, hierarchical and just raw text data, which is nice. :)\n* To figure out the file type, [guess_types from the mime package](https:\/\/www.rforge.net\/doc\/packages\/mime\/guess_type.html) can be helpful.\n\n--- \n\n> Versatile code can be used in a variety of situations. This saves you time because you can apply the same code in multiple different places. \n","e863ecba":"## \ud83d\udcd6 Readable\n\n\u201cReadable\u201d code is code that is easy to read, even if it\u2019s the first time you\u2019ve seen it. In general, the more things like variable and function names are words that describe what they do\/are the easier it is to read the code. In addition, comments that describe what the code does at a high level or why you made specific choices can help you \n\n### Variable names\n\nVariable names are informative and code has up-to-date comments and [docstrings](https:\/\/www.python.org\/dev\/peps\/pep-0257\/).\n\nSome examples of not-very-readable variable names are:\n\n* **Single characters**, like `x` or `q`.  [There are a few exceptions](https:\/\/www.codereadability.com\/i-n-k-single-letter-variable-names\/), like using `i` for index or `x` for the x axis.\n* **All lower case names with no spaces between words** `likethisexample` or `somedatafromsomewhere`\n* **Uninformative or ambiguous names** `data2` doesn\u2019t tell you what\u2019s in the data or how it\u2019s different from `data1`. `df` tells you that something\u2019s a dataframe\u2026 but if you have multiple dataframes how can you tell which one?\n\nYou can improve names by following a couple of rules:\n\n* Use some way to **indicate the spaces between words** in variable names. Since you can\u2019t use actual spaces, some common ways to do this are `snake_case` and `camelCase`. Your style guide will probably recommend one. \n* Use the names to **describe what\u2019s in the variable or what a function does**. For example, `sales_data_jan` is more informative than just `data`, and `z_score_calculator` is more informative than just `calc` or `norm`. \n\nIt\u2019s ok to have not-ideal variable names when you\u2019re still figuring out how you\u2019re going to write a bit of code, but I\u2019d recommend going back and making the names better once you\u2019ve got it working.\n\n### Comments\n\nComments are blocks of natural language text in your code. In both Python and R, you can indicate that a line is a comment by starting it with a #. Some tips for writing better comments:\n\n* While some style guides recommend not including information on what a bit of code is doing, I actually think that it\u2019s often warranted in data science. I personally **include comments describing *what* my code is doing if**:\n  * I\u2019m using a relatively new method, especially for modelling. It can also be helpful to include a link to reference material for the method. (I look back to the papers\/blog posts I linked all the time.)\n  * My colleagues who are working with me on a project aren\u2019t familiar with the programming language I\u2019m using. (Not everyone knows Python or R!)\n* **If you change the code, remember to update the comment!**\n* If you\u2019re using an uncommon way of doing something it\u2019s worth adding a comment to explain why so someone (which could be you!) doesn\u2019t run into problems later if they try to update the code. For example: `# using tf 1, don\u2019t update to 2 until bug #1234 is closed or it will break the rest of the pipeline`\n* Some style guides will recommend only ever writing comments in English, but if you\u2019re working with folks who use another language I\u2019d personally suggest that you **write comments in whichever language will be easiest for everyone using the code to understand**.\n\n **Docstring:** In Python, a docstring is a comment that\u2019s the first bit of text in a function or class. If you\u2019re importing functions, you should include a docstring. This lets you, and anyone else using the function, quickly learn more about what the function does.\n\n```\ndef function(argument):\n\t\u201c\u201d\u201d This is the docstring. It should describe what the function will do when run\u201d\u201d\u201d\n```\nTo check the docstring for a function, you can use the syntax `function_name.__doc__`. \n\nIf you\u2019re an R user and what to add docstrings to your code, you can check out [the docstring package](https:\/\/cran.r-project.org\/web\/packages\/docstring\/vignettes\/docstring_intro.html). \n\n> Readable code is faster to read. This saves you time when you need to go back to a project or when you\u2019re encountering new code for the first time and need to understand what\u2019s going on.\n","68abf7cc":"## \ud83d\udca1 Creative\n\nBy \u201ccreative\u201d, I mean code that solves a problem that hasn\u2019t already been solved or is a clear improvement over an existing solution. The reason that I include this is to encourage you to seek out existing libraries or modules (or [Kaggle scripts](https:\/\/www.kaggle.com\/kernels?sortBy=hotness&group=everyone&pageSize=20&tagIds=16074)!) that already exist to solve your problem. If someone has already written the code you need, and it\u2019s under a license that allows you to use it, then you should probably just do that. \n\nI would only suggest writing a library that replicates the functionality of another one if you\u2019re making a clear improvement. For example, the [Python library flashtext](https:\/\/flashtext.readthedocs.io\/en\/latest\/). It allows you to do the same thing as you can with [regular expressions](https:\/\/en.wikipedia.org\/wiki\/Regular_expression)--like find, extract and replace text--but [much, much faster](https:\/\/github.com\/vi3k6i5\/flashtext#why-not-regex). \n\n> Only spending time writing code if there\u2019s no existing solution saves you time because you can build on existing work rather than starting over from scratch.","2c55bf17":"So far so good: there are more 5's than any other values. But what if there's a tie?"}}