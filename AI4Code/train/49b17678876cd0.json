{"cell_type":{"2e2fdb94":"code","59d43fee":"code","a558d111":"code","5bb06551":"code","727431b0":"code","a1ed8139":"code","b8d210f0":"code","b5bb8944":"code","9dc3991f":"code","ba943794":"code","891f9e9e":"code","6e91dd69":"code","b2992a82":"code","11776437":"code","f55c4ed7":"code","8b825692":"code","118b55fa":"code","95880fb5":"code","391629eb":"code","e1413402":"code","0f87a4e0":"code","05819da7":"code","6e8745e5":"code","e5e818d0":"code","f2ff7e45":"code","db3409be":"code","10ef115f":"code","49d8f448":"code","c760538f":"code","c2f9515a":"code","bbe35f94":"code","391be6a8":"code","8db9c637":"code","636cbade":"code","beec7527":"code","89d14b97":"code","edcef7b5":"code","f2edd0de":"code","ee9cf37e":"code","8d3c2c67":"code","5584c30f":"code","d58ff25c":"code","7267ca5a":"code","b530888c":"code","8e98a9cb":"code","a73d4796":"code","6979cad2":"code","e13adabb":"code","38ab2341":"code","d34c07fa":"code","ed166c5a":"code","8a7c9d13":"code","dedb8a6e":"code","62c714b7":"code","70a321cf":"code","de6d08d5":"code","b8d5631e":"code","78df345e":"code","833d1655":"code","1cb8220f":"code","7a63d2a7":"code","b45891a5":"code","fd774fd4":"code","ab30f8a2":"code","5264167c":"code","52b1cce6":"code","b8c01521":"code","54c3e0fd":"code","03752e09":"code","e6442702":"code","d313e376":"code","b4910191":"code","888e940c":"markdown","d1368668":"markdown","086b721c":"markdown","c9bf0459":"markdown","fde0da83":"markdown","3d2236ea":"markdown","5a5584b5":"markdown","82696124":"markdown","928b7da1":"markdown","ac3ca73c":"markdown","fd069ebb":"markdown","008c8933":"markdown","6d0ab116":"markdown","954ca2be":"markdown","af1fcec7":"markdown","c1f78677":"markdown","9ddab545":"markdown","3dbaaf8d":"markdown","8e726dfd":"markdown","89c0713c":"markdown","7bca5521":"markdown","9c9788dd":"markdown","00c293ed":"markdown","978ea2ba":"markdown","730b5fde":"markdown","67e9e280":"markdown","e20804aa":"markdown","acc6019d":"markdown","3ff6b326":"markdown","240138e2":"markdown","e7c464d7":"markdown","641ecaad":"markdown","c89ec028":"markdown","71dd7ac9":"markdown","53330425":"markdown","a1c64f61":"markdown","40129aa7":"markdown","2e0874a6":"markdown","a1f3db3b":"markdown"},"source":{"2e2fdb94":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","59d43fee":"import matplotlib.pyplot as plt\n\nimport plotly \nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.io as pio\npio.renderers.default = 'iframe'","a558d111":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\n\n\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n\nfrom sklearn.metrics import precision_score, recall_score, precision_recall_curve, accuracy_score, confusion_matrix\nfrom sklearn.metrics import roc_curve, f1_score, roc_auc_score, make_scorer\n\n\nfrom sklearn.impute import SimpleImputer","5bb06551":"import warnings\nwarnings.simplefilter('ignore')","727431b0":"initial_df = pd.read_csv('..\/input\/heart-failure-prediction\/heart.csv')","a1ed8139":"initial_df.head()","b8d210f0":"initial_df.shape","b5bb8944":"initial_df.info()","9dc3991f":"features = initial_df.drop('HeartDisease', axis='columns')\ntarget = initial_df['HeartDisease']","ba943794":"initial_df.head()","891f9e9e":"X_train, X_test, y_train, y_test  = train_test_split(features, target, test_size = 0.2, random_state=282)","6e91dd69":"numeric_cols = [col for col in X_train.columns if X_train[col].dtype in ['int64','float64']]","b2992a82":"numeric_cols","11776437":"axes = pd.plotting.scatter_matrix(X_train[numeric_cols],\n                                  figsize=(15,15), diagonal='kde', grid=True)\ncorr = X_train[numeric_cols].corr().values\nfor i, j in zip(*plt.np.triu_indices_from(axes, k=1)):\n    axes[i, j].annotate(\"%.3f\" %corr[i,j], (1.2, 1.2),\n                        xycoords='axes fraction', ha='center', va='center')\nplt.show()","f55c4ed7":"X_train[numeric_cols].corr()","8b825692":"X_train.columns","118b55fa":"X_train.head()","95880fb5":"X_train['Sex'].unique()","391629eb":"X_train['Sex'].value_counts()","e1413402":"print(X_train['ChestPainType'].nunique())\nprint(X_train['ChestPainType'].value_counts())","0f87a4e0":"print(X_train['RestingECG'].nunique())\nprint(X_train['RestingECG'].value_counts())","05819da7":"print(X_train['ST_Slope'].nunique())\nprint(X_train['ST_Slope'].value_counts())","6e8745e5":"print(X_train['ExerciseAngina'].nunique())\nprint(X_train['ExerciseAngina'].value_counts())","e5e818d0":"X_train.head()","f2ff7e45":"  X_train['ExerciseAngina'] = X_train['ExerciseAngina'].apply(lambda x: 0 if x=='N' else 1)\n","db3409be":"X_test['ExerciseAngina'] = X_test['ExerciseAngina'].apply(lambda x: 0 if x=='N' else 1)\n","10ef115f":"X_train.head()","49d8f448":"cols_to_ohe = [col for col in X_train.columns if X_train[col].dtype == 'object']","c760538f":"cols_to_ohe","c2f9515a":"for col in cols_to_ohe:\n    X_train = X_train.drop(col, axis='columns').merge(pd.get_dummies(X_train[col],drop_first=True),\n                                             left_index=True,\n                                             right_index=True,\n                                            how='left')\n    \n    X_test = X_test.drop(col, axis='columns').merge(pd.get_dummies(X_test[col],drop_first=True),\n                                         left_index=True,\n                                         right_index=True,\n                                        how='left')","bbe35f94":"X_train.head()","391be6a8":"X_test.head()","8db9c637":"my_scaler = StandardScaler()\ncols_to_scale = [col for col in X_train.columns if X_train[col].nunique()>2]","636cbade":"cols_to_scale","beec7527":"initial_df.head()","89d14b97":"scaled_X_train = pd.DataFrame(my_scaler.fit_transform(X_train[cols_to_scale]))\nscaled_X_test = pd.DataFrame(my_scaler.transform(X_test[cols_to_scale])) #only transform for test features\n\nscaled_X_train.columns = cols_to_scale\nscaled_X_train.index = X_train.index\n\nscaled_X_test.columns = cols_to_scale\nscaled_X_test.index = X_test.index\n\n\n\nX_train = X_train.drop(cols_to_scale, axis='columns').merge(scaled_X_train,\n                                                 left_index=True,\n                                                 right_index=True,\n                                                 how='left')\n\nX_test = X_test.drop(cols_to_scale, axis='columns').merge(scaled_X_test,\n                                                 left_index=True,\n                                                 right_index=True,\n                                                 how='left')","edcef7b5":"X_train.head()","f2edd0de":"X_train.info()","ee9cf37e":"y_train.value_counts()","8d3c2c67":"forest_model = RandomForestClassifier(random_state = 282,\n                                     class_weight = 'balanced') \n#will use balanced class weight to reduce disbalance influence","5584c30f":"forest_params = {'criterion':['gini','entropy'], #check criterion \n                'max_depth': range(1,11),\n                'max_features': range(4,len(X_train.columns)+1)} ","d58ff25c":"forest_grid = GridSearchCV(forest_model, forest_params,\n                           cv=5, n_jobs=-1,\n                           verbose=2,\n                           scoring='f1') #we are scoring f1 metric here, so dont forget to write it in the GridSearch parameters","7267ca5a":"#1200 fits in total,nearly 3 minutes using Kaggle internal kernel\n%time\nforest_grid.fit(X_train, y_train)","b530888c":"forest_grid.best_params_","8e98a9cb":"forest_grid.best_score_","a73d4796":"forest_grid.best_estimator_.get_params()","6979cad2":"forest_model = RandomForestClassifier(bootstrap= True,\n                                      class_weight='balanced',\n                                      criterion='gini',\n                                      max_depth=6,\n                                      max_features=4,\n                                      random_state=282)\n\nforest_params = {'n_estimators':range(20,120,10)} \n\nforest_grid = GridSearchCV(forest_model, forest_params,\n                           cv=5, n_jobs=-1,\n                           verbose=2,\n                           scoring='f1') ","e13adabb":"#50 fits, nearly 15 seconds\n%time\nforest_grid.fit(X_train, y_train)","38ab2341":"print(forest_grid.best_score_)\nprint(forest_grid.best_estimator_.get_params())","d34c07fa":"model = RandomForestClassifier(bootstrap= True,\n                                      class_weight='balanced',\n                                      criterion='gini',\n                                      max_depth=6,\n                                      max_features=4,\n                                      random_state=282,\n                                      n_estimators=70)","ed166c5a":"model.fit(X_train, y_train)","8a7c9d13":"test_prediction = model.predict(X_test)","dedb8a6e":"confusion_matrix(y_test, test_prediction)","62c714b7":"print('model precision value:',precision_score(y_test, test_prediction))\nprint('model recall value :',recall_score(y_test, test_prediction))\nprint('model f1 score:',f1_score(y_test, test_prediction))","70a321cf":"accuracy_score(y_test, test_prediction)","de6d08d5":"feature_importance_df = pd.DataFrame({'feature':list(X_test.columns),\n             'importance':list(forest_grid.best_estimator_.feature_importances_)})","b8d5631e":"px.bar(feature_importance_df.sort_values('importance',ascending=False), x='feature', y='importance',\n      title='model feature importance')","78df345e":"probabilities_one_test = forest_grid.predict_proba(X_test)[:,1]\n\nfpr, tpr, thresholds = roc_curve(y_test, probabilities_one_test) \n\nplt.figure()\n\nplt.plot(fpr, tpr)\n\nplt.plot([0, 1], [0, 1], linestyle='--')\n\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC-curve')\nplt.show()","833d1655":"auc_roc = roc_auc_score(y_test, probabilities_one_test)\n\nprint(auc_roc)","1cb8220f":"X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, random_state=282)","7a63d2a7":"def upsample(features, target, repeat):\n    \n    features_zeros = features[target.values == 0]\n    features_ones = features[target.values == 1]\n    #print(len(features_zeros))\n    #print(len(features_ones))\n    \n    target_zeros = target[target.values == 0]\n    target_ones = target[target.values == 1]\n    #print(len(target_zeros))\n    #print(len(target_ones))\n        \n    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n    \n    #features_upsampled = features_upsampled.reset_index(drop=True)\n    #target_upsampled = target_upsampled.reset_index(drop=True)\n    \n    return features_upsampled, target_upsampled\n\n","b45891a5":"X_train_upsampled, y_train_upsampled = upsample(X_train, pd.DataFrame(y_train), 2)","fd774fd4":"f1_results_on_valid_list = []\nrepeat_num_list = []\n\n\nfor repeat in range(1,15,1):\n    X_train_upsampled, y_train_upsampled = upsample(X_train, pd.DataFrame(y_train), repeat)\n    \n    model.fit(X_train_upsampled, y_train_upsampled)\n    \n    train_prediction = model.predict(X_valid)\n    \n    f1_results_on_valid_list.append(f1_score(y_valid, train_prediction))\n    repeat_num_list.append(repeat)","ab30f8a2":"f1_results_on_valid_list","5264167c":"X_train_upsampled, y_train_upsampled = upsample(X_train, pd.DataFrame(y_train), 10)","52b1cce6":"model.fit(X_train_upsampled, y_train_upsampled)","b8c01521":"probabilities_valid = model.predict_proba(X_valid)\nprobabilities_one_valid = probabilities_valid[:, 1]\n\n\nfor threshold in np.arange(0.45, 0.55, 0.01):\n    predicted_valid = model.predict(X_valid)\n    predicted_valid = probabilities_one_valid > threshold \n    \n    precision = precision_score(y_valid, predicted_valid)\n    recall = recall_score(y_valid, predicted_valid)\n    f1_metric = f1_score(y_valid, predicted_valid)\n    \n    print(\"threshold = {:.2f} | precision = {:.3f}, recall = {:.3f}, F1 = {:.3f}\".format(\n        threshold, precision, recall, f1_metric))","54c3e0fd":"model.fit(X_train_upsampled, y_train_upsampled)","03752e09":"test_prediction = model.predict(X_test)\n\nprint('model precision value:',precision_score(y_test, test_prediction))\nprint('model recall value :',recall_score(y_test, test_prediction))\nprint('model f1 score:',f1_score(y_test, test_prediction))\nprint('model auc_roc:',roc_auc_score(y_test, probabilities_one_test))\n\n","e6442702":"accuracy_score(y_test, test_prediction)","d313e376":"confusion_matrix(y_test, test_prediction)","b4910191":"probabilities_one_test = model.predict_proba(X_test)[:,1]\n\nfpr, tpr, thresholds = roc_curve(y_test, probabilities_one_test) \n\nplt.figure()\n\nplt.plot(fpr, tpr)\n\nplt.plot([0, 1], [0, 1], linestyle='--')\n\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC-curve')\nplt.show()","888e940c":"**On validation sample it seems that default 0.5 threshold gives best result, so we will not do anything with\nthis parameter**","d1368668":"For this dataset I am going to use RandomForest with GridSearch and Cross-Validation on train dataset\nOur main metric to optimise is actually F1 score, not accuracy, as we are solving classification problem.\n\nWhile model tuning we will tune F1 and ROC-AUC metrics","086b721c":"**ok, here we can a little bit improve our f1 metric with 10x upsampmling**\n","c9bf0459":"**Ok, here we have 12 columns, no NA values, 5 columns have object dtype, others are numeric**","fde0da83":"**Lets check our current model's roc and count roc-auc**","3d2236ea":"**So I implemented upsampling, lets check what are my final metrics:**\n\n* f1\n* precision\n* recall\n* roc-auc","5a5584b5":"# Train prediction and metrics evaluation","82696124":"**lets build feature importance bar plot to see which features are recognised as most important**","928b7da1":"**First of all lets take a look at our data**","ac3ca73c":"**first of all lets split  train sample for train and valid as I am not going to use GridSearch here**","fd069ebb":"**Ok, lets check than what will we see on train dataset**","008c8933":"# Data preparation and some EDA","6d0ab116":"**I will use OHE technic for ChestPainType, RestingECG, ST_Slope columns.\nAnd will just simply transform ExerciseAngina  column to numeric with 1 or 0 depends if current value Y or N**","954ca2be":"# Model tuning","af1fcec7":"**Ok, here we see best params using RandomForest**\n\n**Lets check best F1 score (please remember it is not accuracy (!))**","c1f78677":"**Lets check if I can improve my score simply using GridSearch on n_estimators parameter**","9ddab545":"**Accuracy score is 88, but, once again, in this problem it is not our main metric to tune**","3dbaaf8d":"**What about accuracy score?**","8e726dfd":"**As a next step I will build correlation matrix to check correlation between numeric features**","89c0713c":"**I will construct confusion matrix to understand which types of mistakes do my model have on train**","7bca5521":"# Final test prediction and metrics","9c9788dd":"**Lets take a look at our classifier metrics such as :**\n    \n         - Precision \n         - Recall\n         - F1 score","00c293ed":"**OK, done. Lets move forward and scale all non-boolean values using StandardScaler**","978ea2ba":"**Lets check non-numeric columns**","730b5fde":"**lets take a look at my best-on-cross-validation model**","67e9e280":"# Random forest Model training","e20804aa":"**Here we can read it as:**\n  - 0.88% of values which were evaluated by model as class 1 are really belongs to class 1, \n  - model found 90,5% of class 1 items ","acc6019d":"**firstly find all columns which we need to scale**","3ff6b326":"**lets try to tune our model**\n\n**I guess we can use several technics to improve our score:** \n\n    -upsampling\n    -moving threshold line\n    ","240138e2":"**How to read confusion matrix:**\n    \n    - Top left - True Negative Values\n    - Bottom left - False Negative Values (model predicted them as class 0, but actually they are class 1)\n    - Top right - False Positive Values (predicted as class 1, actually class 0)\n    - Bottom right - True Positive \n    \n**So we can see from actual numbers that model seems to equally do both types of mistakes:**\n\n    - False Positive - 12 values\n    - False Negative - 10 values \n    \n**In terms of heart failure prediction I guess that we better minimize False Negative mistakes**","e7c464d7":"**Ok, finally we prepared test and train datasets for model training,\nlets check y_train for disbalance**","641ecaad":"**With upsampling I didnt change final metrics of F1 and AUC-ROC, but as you can see from\nconfusion matrix types of mistakes have changed. Now 2\/3 of mistakes are False Positive mistakes.\nI guess that in terms of heart failure prediction it is better to have false positive mistakes neither false negative.**\n\n\n\n**Thank you for reading, looking forward for your comments**\n","c89ec028":"**Lets make a list of all columns for OHE**","71dd7ac9":"**lets split our dataset to train and test samples**","53330425":"**lets check what we can do with probability threshold**","a1c64f61":"**Ok, looks like disbalance is not as big as it could be, like 55% to 45%**","40129aa7":"**As you can see accuracy is lower than before upsampling, but recall is higher**","2e0874a6":"**Ok, with n_estimators = 70 we reached best f1 metric which is equal 0.89 on cross validation**","a1f3db3b":"**Looks like Age and MaxHR have some linear negative correlation, but it is not exceed -0.44, so in general\nI think we can keep all numeric features in our dataset**"}}