{"cell_type":{"bf558bed":"code","83994305":"code","c9bcfe0f":"code","47efaee6":"code","e94fe57b":"code","a529e710":"code","534db68e":"code","40399219":"code","bf24f891":"code","8f4926cb":"code","028bf2f4":"code","b08ccfd5":"code","83a4a529":"code","8d16376a":"code","0b99a2f3":"code","f69e7eee":"code","4a7e8be6":"code","81fb6cf8":"code","ff3dccf4":"code","c9daaa1b":"code","7d856dba":"code","5c3ab5bb":"code","4ace8a9f":"code","f198095f":"code","0ec19a48":"code","eb00231f":"markdown","697cb2d9":"markdown","a2684774":"markdown","1ccf7b9b":"markdown"},"source":{"bf558bed":"import numpy as np\nimport pandas as pd\nimport os\nimport gc\nimport cv2\nimport tensorflow as tf\nimport seaborn as sn\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras.layers import *\nfrom keras.models import Model\nfrom keras.utils import plot_model\nfrom keras.applications.resnet_v2 import ResNet50V2\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\n\n\nprint(tf.__version__)","83994305":"training = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/train.csv')\nprint(training.head(10))","c9bcfe0f":"print(training[\"target\"].value_counts())","47efaee6":"m = training[training[\"target\"]==1]\nb = training[training[\"target\"]==0].sample(3000)\ndf = pd.concat([m,b])        \ndf.reset_index(inplace=True)\ndf.drop(labels=[\"index\", \"patient_id\", \"sex\", \"age_approx\", \"anatom_site_general_challenge\", \"diagnosis\", \"benign_malignant\"], axis=1, inplace=True)\ndf[\"image_name\"] = \"..\/input\/images-siim-512x512\/train\/train_512x512\/\" + df[\"image_name\"].astype(str) + \".jpg\"\ndf.head()","e94fe57b":"imgs = []\nlabels = []\nfor index, row in tqdm(df.iterrows()):\n    img = cv2.imread(str(row[\"image_name\"]))\n    img = cv2.resize(img, (300,300))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    imgs.append(img)\n    labels.append(row[\"target\"])\nimgs = np.array(imgs)\nlabels = np.array(labels)\nprint(imgs.shape)\nprint(labels.shape)","a529e710":"with open(\"res_imgs4k.npz\", \"wb\") as file:\n    np.savez_compressed(file, images=imgs)","534db68e":"with open(\".\/res_imgs4k.npz\", \"rb\") as file:\n    imgs = np.load(file)[\"images\"]","40399219":"labels = np.concatenate([np.full(584,1),np.full(3000,0)])\nprint(imgs.shape)\nprint(labels.shape)","bf24f891":"trainX, valX, trainY, valY = train_test_split(imgs, labels, test_size=0.2, random_state=888)\nplt.imshow(trainX[0])\ndel imgs, labels\ngc.collect()","8f4926cb":"# trainX, valX, trainY, valY = train_test_split(\n#     df[\"image_name\"], \n#     df[\"target\"],\n#     test_size = 0.2, \n#     random_state = 888\n# )\n# train = list(zip(trainX, trainY))\n# train = pd.DataFrame(train, columns = [\"images\", \"target\"])\n# val = list(zip(valX, valY))\n# val = pd.DataFrame(val, columns = [\"images\", \"target\"])\n\n# train.head()","028bf2f4":"train_aug = ImageDataGenerator(rescale=1.\/255,\n                     rotation_range=80,\n                     width_shift_range=0.25, \n                     height_shift_range=0.25,\n                     shear_range=0.2,\n                     horizontal_flip=True,\n                     vertical_flip=True)\n\nval_aug = ImageDataGenerator(rescale=1.\/255)","b08ccfd5":"train_gen = train_aug.flow(trainX, trainY, batch_size = 12, shuffle = True)\nval_gen = val_aug.flow(valX, valY, batch_size = 12, shuffle = False)","83a4a529":"# train_gen = train_aug.flow_from_dataframe(train, x_col=\"images\", y_col=\"target\", batch_size = 8, target_size=(224,224),shuffle = True, class_mode=\"raw\")\n# val_gen = val_aug.flow_from_dataframe(val, x_col=\"images\", y_col=\"target\", batch_size = 8, target_size=(224,224),shuffle = False, class_mode=\"raw\")","8d16376a":"from tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nearly_stop = EarlyStopping(monitor='val_loss', patience=2)\ncheckpoint = ModelCheckpoint(\"{val_loss:.2f}-{epoch:02d}.hdf5\",monitor = 'val_loss',verbose = 1,save_best_only = True,mode = 'min')\n\ncallbacks = [early_stop, checkpoint]","0b99a2f3":"optimizer = keras.optimizers.Adam(lr=1e-3)\nauc = keras.metrics.AUC()","f69e7eee":"!pip install git+https:\/\/github.com\/qubvel\/efficientnet","4a7e8be6":"import efficientnet.keras as efn ","81fb6cf8":"effnet = efn.EfficientNetB3(\n    include_top=True,\n    weights=\"imagenet\",\n    input_shape=(300,300,3)\n)\n","ff3dccf4":"effnet.trainable=False\nflat = Flatten()(effnet.output)\n# gap = GlobalAveragePooling2D()(resnet.output)\nfinal = Dropout(0.2)(flat)\nfinal = Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001))(final)\nfinal = Dropout(0.2)(final)\nfinal = Dense(1, activation=\"sigmoid\")(final)\nmodel = Model(effnet.input,final)\nmodel.summary()","c9daaa1b":"model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n\nhistory = model.fit_generator(\n    train_gen,\n    steps_per_epoch = trainX.shape[0] \/\/ 12,\n    epochs = 3, \n    validation_data = val_gen,\n    validation_steps = valX.shape[0] \/\/ 12\n)\n\n# model.save('resnet2.h5')","7d856dba":"for layer in effnet.layers[120:]:\n   layer.trainable = True\nfor i, layer in enumerate(effnet.layers):\n   print(i, layer.name, layer.trainable)","5c3ab5bb":"opt = keras.optimizers.Adamax(learning_rate=1e-3)","4ace8a9f":"model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=opt)\n\nhistory = model.fit_generator(\n    train_gen,\n    steps_per_epoch = trainX.shape[0] \/\/ 12,\n    epochs = 5, \n    validation_data = val_gen,\n    validation_steps = valX.shape[0] \/\/ 12,\n)","f198095f":"history = model.fit_generator(\n    train_gen,\n    steps_per_epoch = trainX.shape[0] \/\/ 12,\n    epochs = 10, \n    validation_data = val_gen,\n    validation_steps = valX.shape[0] \/\/ 12,\n    callbacks = callbacks\n)","0ec19a48":"hist = pd.DataFrame(history.history)\nhist['epoch'] = history.epoch\n\nplt.figure()\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.plot(hist['epoch'], hist['loss'], label='Train Error')\nplt.plot(hist['epoch'], hist['val_loss'], label='Val Error')\nplt.ylim([0, 0.5])\nplt.legend()\n\nplt.figure()\nplt.xlabel('Epoch')\nplt.ylabel('accuracy')\nplt.plot(hist['epoch'], hist['accuracy'], label='Train Acc')\nplt.plot(hist['epoch'], hist['val_accuracy'], label='Val Acc')\nplt.ylim([0, 1])\nplt.legend()\nplt.show()","eb00231f":"Flow from dataframe reads in images from disk given the filepaths (stored under column \"images\").","697cb2d9":"Note that we set the random_state in the train-test split as 888. This means the model will be very lucky.","a2684774":"ResNet with our own top layer. ResNet is frozen.","1ccf7b9b":"We take a very small sample of the benign data to balance out the malignant data."}}