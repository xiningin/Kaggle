{"cell_type":{"1b6f8972":"code","c5c977f1":"code","991bc056":"code","d06c3429":"code","98cedc68":"code","8fc56db2":"code","ec2f0a57":"code","df58de4b":"code","e603ccf1":"code","0ef4d576":"code","71aa6ed1":"code","e8cd58c8":"code","57875d8b":"code","5f72eca1":"code","af75f87b":"code","6727f9da":"code","f35665e9":"code","b76dbb7d":"code","52d5ad78":"code","9b19affa":"markdown","8645d240":"markdown","f1f811ec":"markdown","12706152":"markdown","1582bbee":"markdown","c6cd2275":"markdown","ab92c7bb":"markdown","b01b2682":"markdown"},"source":{"1b6f8972":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.losses import categorical_crossentropy\nfrom keras.optimizers import Adam\n\nimport warnings\nwarnings.filterwarnings('ignore')","c5c977f1":"train = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv')\ntest = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv')","991bc056":"train.shape,test.shape","d06c3429":"train.label.nunique()","98cedc68":"train = np.array(train,dtype='float32')\ntest = np.array(test,dtype='float32')\n                 \ntrain.shape, test.shape","8fc56db2":"train_X = train[:,1:] \/ 255\ntest_X =  test[:,1:] \/ 255\n\ntrain_X = train_X.reshape(train_X.shape[0], 28,28)\ntest_X = test_X.reshape(test_X.shape[0], 28,28)\n\ntrain_y = train[:,0]\ntest_y = test[:,0]\n","ec2f0a57":"train_X = train_X.reshape(-1, 28,28, 1)\ntest_X = test_X.reshape(-1, 28,28, 1)\n\ntrain_Y_one_hot = to_categorical(train_y)\ntest_Y_one_hot = to_categorical(test_y)\n\ntrain_X.shape, test_X.shape","df58de4b":"X_train,X_valid,y_train,y_valid = train_test_split(train_X,train_Y_one_hot,test_size=0.3)\nX_train.shape,X_valid.shape,y_train.shape,y_valid.shape","e603ccf1":"plt.imshow( X_train[5850,:].reshape((28,28)))\nplt.show()","0ef4d576":"batch_size = 64\nepochs = 20\nnum_classes = 10","71aa6ed1":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='linear',padding='same',input_shape=(28,28,1)))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D((2, 2),padding='same'))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))                  \nmodel.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\nmodel.add(Dropout(0.4))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='linear'))\nmodel.add(LeakyReLU(alpha=0.1))           \nmodel.add(Dropout(0.3))\nmodel.add(Dense(num_classes, activation='softmax'))","e8cd58c8":"model.summary()","57875d8b":"model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])","5f72eca1":"model_dropout = model.fit(X_train,y_train, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(X_valid, y_valid))","af75f87b":"test_eval = model.evaluate(test_X, test_Y_one_hot, verbose=1)","6727f9da":"print(\"Loss=\",test_eval[0])\nprint(\"Accuracy=\",test_eval[1])","f35665e9":"predicted_classes = model.predict(test_X)\npredicted_classes = np.argmax(np.round(predicted_classes),axis=1)\npredicted_classes.shape, test_y.shape","b76dbb7d":"correct = np.where(predicted_classes==test_y)[0]\nprint( \"Found %d correct labels\" % len(correct))\nfor i, correct in enumerate(correct[:9]):\n    plt.subplot(3,3,i+1)\n    plt.imshow(test_X[correct].reshape(28,28), cmap='gray', interpolation='none')\n    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], test_y[correct]))\n    plt.tight_layout()","52d5ad78":"incorrect = np.where(predicted_classes!=test_y)[0]\nprint( \"Found %d incorrect labels\" % len(incorrect))\nfor i, incorrect in enumerate(incorrect[:9]):\n    plt.subplot(3,3,i+1)\n    plt.imshow(test_X[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], test_y[incorrect]))\n    plt.tight_layout()","9b19affa":"model.summary()","8645d240":"model_train = model.fit(X_train,y_train)","f1f811ec":"\nmodel = Sequential()\nmodel.add(Conv2D(32,kernel_size=(3,3),activation='linear',input_shape=(28,28,1),padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D((2,2),padding='same'))\n\nmodel.add(Conv2D(64,kernel_size=(3,3),activation='linear',input_shape=(28,28,1),padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D((2,2),padding='same'))\n\nmodel.add(Conv2D(128,kernel_size=(3,3),activation='linear',input_shape=(28,28,1),padding='same'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D((2,2),padding='same'))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(128,activation='linear'))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Dense(10,activation='softmax'))","12706152":"Convert the dataframe into a numpy array of type float32","1582bbee":"print(\"Loss=\",test_eval[0])\nprint(\"Accuracy=\",test_eval[1])","c6cd2275":"model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='Adam')","ab92c7bb":"test_eval = model.evaluate(test_X,test_Y_one_hot,verbose=0)","b01b2682":"CNN Model"}}