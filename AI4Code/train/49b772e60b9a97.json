{"cell_type":{"e2f01569":"code","922651ee":"code","0271fae9":"code","0770fe83":"code","d2ee5a0f":"code","93c42e93":"code","bdc56bb5":"code","66e46fe9":"code","cdff8d14":"code","da910497":"code","15fe9971":"code","662093a6":"code","18908a15":"code","46e9a508":"code","572f3345":"code","e5c63499":"code","fd288690":"code","5b6316c7":"code","001cff48":"code","e91411a6":"code","59170ac2":"code","13c862df":"code","3503c989":"code","7dba6584":"code","2e00b486":"code","c2236d43":"code","ba18783b":"markdown","b073f166":"markdown"},"source":{"e2f01569":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","922651ee":"train_df=pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv')","0271fae9":"train_df","0770fe83":"X_train=train_df.iloc[:,1:]\ny_train=train_df.iloc[:,0]","d2ee5a0f":"X_train","93c42e93":"y_train","bdc56bb5":"# from sklearn.model_selection import train_test_split","66e46fe9":"# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)","cdff8d14":"from xgboost import XGBClassifier","da910497":"clf=XGBClassifier(learning_rate=0.1, n_estimators=400, max_depth=6, base_score=1.0, colsample_bynode=1.0, colsample_bylevel=1.0, colsample_bytree=0.5, reg_lambda=7, subsample=0.75)","15fe9971":"clf.fit(X_train,y_train)","662093a6":"# clf1=XGBClassifier()\n# clf2=RandomForestClassifier()\n# clf3=GradientBoostingClassifier()","18908a15":"# clf1.fit(X_train,y_train)\n# clf2.fit(X_train,y_train)\n# clf3.fit(X_train,y_train)","46e9a508":"# y_pred=clf.predict(X_test)","572f3345":"# y_pred","e5c63499":"from sklearn.metrics import accuracy_score","fd288690":"# accuracy_score(y_test,y_pred)","5b6316c7":"test_df=pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv')","001cff48":"test_df","e91411a6":"X_test=test_df.iloc[:,1:]\ny_test=test_df.iloc[:,0]","59170ac2":"y_test","13c862df":"y_pred=clf.predict(X_test)","3503c989":"# hard_pred=model_hard.predict(X_test)","7dba6584":"# soft_pred=model_soft.predict(X_test)","2e00b486":"# print('Hard Voting: ',accuracy_score(y_test,hard_pred))\n# print('Soft Voting: ',accuracy_score(y_test,soft_pred))","c2236d43":"print('Accuracy score: ',accuracy_score(y_test,y_pred))","ba18783b":"# 91.39% Accuracy achieved","b073f166":"## Methods to be applied:\n* Apply each of the Algos to check accuracy\n* Stacking on XGBoost\n* Add RF in Stacking, GB"}}