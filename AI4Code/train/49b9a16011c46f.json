{"cell_type":{"426122f8":"code","e92f5437":"code","9517690b":"code","2eaef498":"code","a06e37c4":"code","e4b6c64d":"code","edb0833b":"code","45f31c8d":"code","886d7370":"code","790a7164":"code","48476d50":"code","9c0882e7":"code","b664afc3":"code","a6f2e30d":"code","05033e10":"code","f106a966":"code","0676bf14":"code","43a1ab88":"code","85817081":"code","efb51866":"code","b290dd59":"code","ed4da4d5":"code","7074be7e":"code","02ba785f":"code","5c09bd42":"code","c698c577":"code","806e17c9":"code","e0e1b665":"code","e87de104":"code","df157965":"code","5e5a11ad":"code","5eaae829":"code","abfc1d00":"code","d7562f2b":"code","8e1b7b4a":"code","896804be":"code","fbf7f11b":"code","09db7945":"code","26f152b0":"code","40eeb5b7":"code","e42c11e3":"markdown","7ea49a90":"markdown","83865ba7":"markdown","2a6025ea":"markdown","c5912320":"markdown","5f164e5c":"markdown","c3739bad":"markdown","95b3825f":"markdown","ef3de7de":"markdown","6cbf7b01":"markdown","a421f0d2":"markdown","705c37eb":"markdown","d3836e3c":"markdown","013d7dee":"markdown","68369ea3":"markdown","959f3083":"markdown","c4d37aa7":"markdown","c02df646":"markdown","ad178437":"markdown","2bc07f10":"markdown","e05c4cc8":"markdown","702f7d4f":"markdown","d1c935a9":"markdown","2e366b21":"markdown","a41da388":"markdown","28fad9da":"markdown","5f5934ec":"markdown","59f1c972":"markdown","97e4fe82":"markdown","e9ca8068":"markdown","807c181c":"markdown","aabfdca5":"markdown"},"source":{"426122f8":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport datetime\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom plotly.offline import init_notebook_mode\ninit_notebook_mode(connected=True)","e92f5437":"df = pd.read_csv('..\/input\/sales-forecasting\/train.csv')\ndf['Postal Code'] = df['Postal Code'].fillna(5401)\ndf['Order Date'] = pd.to_datetime(df['Order Date'])\ndf['Ship Date'] = pd.to_datetime(df['Ship Date'])\ndf['Order Week'] = df['Order Date'].apply(lambda x:f'{x.year}\/{x.isocalendar()[1]}')\ndf['Order Year'] = df['Order Date'].apply(lambda x:x.year)\ndf['Order Day number'] = df['Order Date'].apply(lambda x:x.isocalendar()[2])\ndf['Order Month'] = df['Order Date'].apply(lambda x:datetime.datetime(x.year,x.month,1).strftime('%b-%Y'))\ndf['Lead_Time']=(df['Ship Date']-df['Order Date']).apply(lambda x:x.days)\ndf.sort_values(['Order Date'],inplace=True)","9517690b":"df","2eaef498":"#Group sales per week : Order Week = Week number\/Year\nweekly_sales = pd.DataFrame(df.groupby('Order Week',sort=False)['Sales'].sum())\nweekly_sales.reset_index(inplace=True)\nweekly_sales['Order Year'] = weekly_sales['Order Week'].apply(lambda x:x.split('\/')[0])\n\n","a06e37c4":"#Time serie plot \nfig = go.Figure()\nfig.add_trace(go.Scatter(x=weekly_sales['Order Week'],\n                         y=weekly_sales['Sales'],text='ds'))","e4b6c64d":"import statsmodels.api as sm","edb0833b":"#Exclude year 2018\nY = np.array(weekly_sales[weekly_sales['Order Year']!='2018']['Sales'])\ncycle, trend = sm.tsa.filters.hpfilter(Y, 10052**2)\nfig = plt.figure(figsize=(12,6))\nax = fig.add_axes([0,0,1,1])\nax.plot(range(len(Y)),trend,label='Trend',c='r')\nax.plot(range(len(Y)),cycle,label='Cycle',c='g')\nax.plot(range(len(Y)),Y,label='Time series')\nax.legend()","45f31c8d":"#Or the variable cycle predefined in th HP filter part\nY_transformed = Y-trend","886d7370":"from statsmodels.tsa.stattools import adfuller","790a7164":"adf_resutls = adfuller(Y_transformed,maxlag=52)\nprint(f'ADF test results are :')\nprint('ADF Statistic: %f' % adf_resutls[0])\nprint('p-value: %f' % adf_resutls[1])\nprint('Critical Values:')\nfor key, value in adf_resutls[4].items():\n    print('\\t%s: %.3f' % (key, value))\nif adf_resutls[0]<=-2.9 :\n    print('==> Non-stationarity can be rejected')\nelse :\n    print('==> Non-stationarity cannot be rejected')","48476d50":"import statsmodels.graphics.tsaplots as tsaplots","9c0882e7":"#Seasonal subseries plot : Weeks are groupped by months (Year 2015\/2016\/2017)\n\n\nmonthly_subseries = pd.DataFrame(df[df['Order Year']!=2018].groupby(['Order Month','Order Week'],sort=False)['Sales'].sum())\n\nfig = plt.figure(figsize=(30,20))\naxes = fig.add_axes([0,0,1,1])\ntsaplots.seasonal_plot(monthly_subseries.groupby('Order Month')['Sales'],list(range(1,37)),ax=axes)\n\nfig.show()","b664afc3":"# Perform Fourier transform on cycle component using scipy \n#Fourier transform is used to map signals from the time domain to the frequency domain. \n#It gives the possibility to spot major signals(with high intensity) contained in the time serie. \nfrom scipy import fftpack\n#cycle = Y - trend\ny_fft = fftpack.fft(cycle)\n\n# Plot data\n\nfr = (round(157\/2)+1) * np.linspace(0,1,round(157\/2))\ny_m = 2\/(round(157\/2)+1) * np.abs(y_fft[:(round(157\/2))])**2\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\nax[0].plot(range(158), Y)    # plot time series\nax[1].stem(fr, y_m) # plot freq domain","a6f2e30d":"from statsmodels.graphics.tsaplots import plot_acf, plot_pacf","05033e10":"fig,axes = plt.subplots(nrows=1,ncols=2,figsize=(15,6))\nplot_pacf(cycle,lags=76,ax=axes[0])\nplot_acf(cycle,lags=76,ax=axes[1])\nfig.suptitle('Cycle composant')\nplt.show()","f106a966":"fig,axes = plt.subplots(nrows=1,ncols=2,figsize=(15,6))\nplot_pacf(trend,lags=76,ax=axes[0])\nplot_acf(trend,lags=76,ax=axes[1])\nfig.suptitle('Trend Composant')\nplt.show()","0676bf14":"#Cyclic component : \nmodel1_fit = sm.tsa.statespace.SARIMAX(cycle,order=([37,75],0,0),seasonal_order=(1,0,0,52),\n                                       trend='c',enforce_invertibility=False,enforce_stationarity=False).fit()\n\n","43a1ab88":"#Trend Component\nmodel2_fit = sm.tsa.statespace.SARIMAX(trend,order=(1,0,0),seasonal_order=(0,0,0,0),\n                                       trend='c',enforce_invertibility=False,enforce_stationarity=False).fit()","85817081":"#Predict training set\ncycle_training_predictions = model1_fit.fittedvalues\ntrend_training_predictions = model2_fit.fittedvalues\nsales_training_predictions = cycle_training_predictions + trend_training_predictions","efb51866":"#Plot training predictions\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=np.array(range(0,159)),y=Y,name='True values'))\nfig.add_trace(go.Scatter(x=np.array(range(75,159)),y=sales_training_predictions[75:],name='Predicted Values'))","b290dd59":"#Metrics\nfrom sklearn.metrics import mean_absolute_error,mean_squared_error\n\nRMSE = np.sqrt(mean_squared_error(Y[75:],sales_training_predictions[75:]))\nMAE = mean_absolute_error(Y[75:],sales_training_predictions[75:])\n\nprint(f'Train Root Mean Squared Error = {RMSE}')\nprint(f'Test Mean Absolute Error = {MAE}')","ed4da4d5":"#This function takes a set of data, split it into train and test sets, and predicts test set.\n#In order to predict, say 2 weeks, the function predicts one week, then integrate the real value of that week in the model to predict the second week\ndef week_prediction(X,Xtest_len=12,cycle_order=(0,0,0),cycle_seasonal_order=(2,0,1,12)):\n    predictions =[]\n    for j in range(Xtest_len):\n\n        X_train = X[0:len(X)-Xtest_len+j]\n        \n        cycle, trend = sm.tsa.filters.hpfilter(X_train, 10052**2)\n        \n        model1_fit =  sm.tsa.statespace.SARIMAX(cycle,order=cycle_order,seasonal_order=cycle_seasonal_order,\n                            enforce_invertibility=False,enforce_stationarity=False).fit()\n        \n        \n        model2_fit = sm.tsa.statespace.SARIMAX(trend,order=(1,0,0),seasonal_order=(0,0,0,0),\n                            enforce_invertibility=False,enforce_stationarity=False).fit()\n        \n        cycle_prediction_step = model1_fit.predict(start=len(X_train),end=len(X_train))\n        trend_prediction_step = model2_fit.predict(start=len(X_train),end=len(X_train))\n        sales_prediction_step = cycle_prediction_step + trend_prediction_step\n        predictions.append(sales_prediction_step)\n    predictions = np.reshape(predictions,((Xtest_len),))\n    RMSE = np.sqrt(mean_squared_error(X[len(X)-Xtest_len:],predictions))\n    MAE = mean_absolute_error(X[len(X)-Xtest_len:],predictions)\n    \n    return predictions , RMSE , MAE","7074be7e":"X = np.array(weekly_sales['Sales'])\n\nwarnings.filterwarnings('ignore')\npredictions,RMSE,MAE = week_prediction(X,52,cycle_order=([37,75],0,0),cycle_seasonal_order=(1,0,0,52))\n","02ba785f":"print(f'Train Root Mean Squared Error = {RMSE}')\nprint(f'Test Mean Absolute Error = {MAE}')\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=np.array(range(0,52)),y=X[-52:],name='True Values'))\nfig.add_trace(go.Scatter(x=np.array(range(0,52)),y=np.array(predictions),name='Predicted Values'))","5c09bd42":"#Train the model on all data\nwarnings.filterwarnings('ignore')\nX = np.array(weekly_sales['Sales'])\ncycle, trend = sm.tsa.filters.hpfilter(X, 10052**2) \n\nmodel1_fit = sm.tsa.statespace.SARIMAX(cycle,order=([37,75],0,0),seasonal_order=(1,0,0,52),trend='c',enforce_invertibility=False,\n                                      enforce_stationarity=False).fit()\nmodel2_fit = sm.tsa.statespace.SARIMAX(trend,order=(1,0,0),seasonal_order=(0,0,0,0),trend='c',enforce_invertibility=False,\n                                      enforce_stationarity=False).fit()\nfitted_values = model1_fit.fittedvalues + model2_fit.fittedvalues\n\n#Next week sales value :\nnext_week_prediction = model1_fit.predict(start=len(cycle),end=len(cycle)+3) + model2_fit.predict(start=len(trend),end=len(trend)+3)\nfor i in range(0,4):\n    print(f' Week +{1+i} sales value prediction is equal to : {round(next_week_prediction[i],2)} (cur)')","c698c577":"#Plot results\n\nfig = go.Figure()\ntransformed_fitted = np.exp(fitted_values)\nfig.add_trace(go.Scatter(x=np.array(range(200,212)),y=X[200:],name='True Values'))\nfig.add_trace(go.Scatter(x=np.array(range(200,212)),y=fitted_values[200:],name='Predicted Values'))\nfig.add_trace(go.Scatter(x=np.array(range(209,214)),y=np.concatenate((np.array(fitted_values[-1]).reshape(1,),next_week_prediction)),\n                         line = dict(color='red', width=4, dash='dash'),\n                         name='Next weeks prediction'))","806e17c9":"#Time series Data frame\nsales_category_week = pd.DataFrame(df.groupby(['Category','Order Week'],sort=False)['Sales'].sum())\nsales_category_week.reset_index(inplace=True)\n\n#Time series plot\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=sales_category_week[sales_category_week['Category']=='Office Supplies']['Order Week'],\n                         y=sales_category_week[sales_category_week['Category']=='Furniture']['Sales'],name='Furniture'))\nfig.add_trace(go.Scatter(x=sales_category_week[sales_category_week['Category']=='Office Supplies']['Order Week'],\n                         y=sales_category_week[sales_category_week['Category']=='Office Supplies']['Sales'],name='Office Supplies'))\nfig.add_trace(go.Scatter(x=sales_category_week[sales_category_week['Category']=='Office Supplies']['Order Week'],\n                         y=sales_category_week[sales_category_week['Category']=='Technology']['Sales'],name='Technology'))\nfig.update_layout(autosize=False,width=1200,height=600,title_x=0.5,title_text='Weekly sales per Category',\n                 xaxis_title='Date (Week number\/Year)',yaxis_title='Profit value')","e0e1b665":"#Furniture sales (2018 sales excluded)\nY = np.array(sales_category_week[sales_category_week['Category']=='Furniture']['Sales'])[:-52]\nY_detrend = np.diff(Y)","e87de104":"plt.plot(range(156),Y_detrend)\nplt.title('Furniture Sales first order difference')\nplt.show()","df157965":"adf_resutls = adfuller(Y_detrend,maxlag=52)\nprint(f'ADF test results are :')\nprint('ADF Statistic: %f' % adf_resutls[0])\nprint('p-value: %f' % adf_resutls[1])\nprint('Critical Values:')\nfor key, value in adf_resutls[4].items():\n    print('\\t%s: %.3f' % (key, value))\nif adf_resutls[0]<=-2.9 :\n    print('==> Non-stationarity can be rejected')\nelse :\n    print('==> Non-stationarity cannot be rejected')","5e5a11ad":"# Perform Fourier transform on cycle component using scipy \nfrom scipy import fftpack\n#Y_transformed = Y - trend\ny_fft = fftpack.fft(Y_detrend)\n\n# Plot data\n\nfr = (round(156\/2)) * np.linspace(0,1,round(156\/2))\ny_m = 2\/(round(156\/2)) * np.abs(y_fft[:(round(156\/2))])**2\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\nax[0].plot(range(157), Y)    # plot time series\nax[1].stem(fr, y_m) # plot freq domain","5eaae829":"fig,axes = plt.subplots(nrows=1,ncols=2,figsize=(15,6))\nplot_pacf(Y_detrend,lags=76,ax=axes[0])\nplot_acf(cycle,lags=76,ax=axes[1])\nfig.suptitle('Cycle composant')\nplt.show()","abfc1d00":"model1_fit = sm.tsa.statespace.SARIMAX(Y,order=([1,52,64],1,[1]),seasonal_order=(1,0,0,73),\n                                       trend='c',enforce_invertibility=False,enforce_stationarity=False).fit()","d7562f2b":"#Predict training set : \nsales_training_predictions = model1_fit.fittedvalues\n#Plot training predictions\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=np.array(range(0,159)),y=Y,name='True values'))\nfig.add_trace(go.Scatter(x=np.array(range(73,159)),y=sales_training_predictions[73:],name='Predicted Values'))","8e1b7b4a":"#Metrics\nfrom sklearn.metrics import mean_absolute_error,mean_squared_error\n\nRMSE = np.sqrt(mean_squared_error(Y[73:],sales_training_predictions[73:]))\nMAE = mean_absolute_error(Y[73:],sales_training_predictions[73:])\n\nprint(f'Train Root Mean Squared Error = {RMSE}')\nprint(f'Test Mean Absolute Error = {MAE}')","896804be":"#Same prediction method.\ndef week_prediction(X,Xtest_len=12,order=(0,0,0),seasonal_order=(2,0,1,12)):\n    predictions =[]\n    for j in range(Xtest_len):\n\n        X_train = X[0:len(X)-Xtest_len+j]\n        \n        model1_fit =  sm.tsa.statespace.SARIMAX(X_train,order=order,seasonal_order=seasonal_order,\n                            enforce_invertibility=False,enforce_stationarity=False).fit()\n        \n        \n        \n        prediction_step = model1_fit.predict(start=len(X_train),end=len(X_train))\n\n        predictions.append(prediction_step)\n    predictions = np.reshape(predictions,((Xtest_len),))\n    RMSE = np.sqrt(mean_squared_error(X[len(X)-Xtest_len:],predictions))\n    MAE = mean_absolute_error(X[len(X)-Xtest_len:],predictions)\n    \n    return predictions , RMSE , MAE","fbf7f11b":"X = np.array(sales_category_week[sales_category_week['Category']=='Furniture']['Sales'])\npredictions,RMSE,MAE = week_prediction(X,52,order=([1,52,64],1,[1]),seasonal_order=(1,0,0,73))","09db7945":"#Plot test results\nprint(f'Test Root Mean Squared Error = {RMSE}')\nprint(f'Test Mean Absolute Error = {MAE}')\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=np.array(range(0,52)),y=X[-52:],name='True Values'))\nfig.add_trace(go.Scatter(x=np.array(range(0,52)),y=np.array(predictions),name='Predicted Values'))","26f152b0":"#Train the model on all data\n\nmodel_fit = sm.tsa.statespace.SARIMAX(X,order=([1,52,64],1,[1]),seasonal_order=(1,0,0,73),trend='c',enforce_invertibility=False,\n                                      enforce_stationarity=False).fit()\nfitted_values = model_fit.fittedvalues \n\n#Next week sales value :\nnext_week_prediction = model_fit.predict(start=len(X),end=len(X)+3) \nfor i in range(1,5):\n    print(f'week + {i} sales value prediction is equal to : {round(next_week_prediction[i-1],2)} (cur)')","40eeb5b7":"#Plot results\n\nfig = go.Figure()\ntransformed_fitted = np.exp(fitted_values)\nfig.add_trace(go.Scatter(x=np.array(range(200,212)),y=X[200:],name='True Values'))\nfig.add_trace(go.Scatter(x=np.array(range(200,212)),y=fitted_values[200:],name='Predicted Values'))\nfig.add_trace(go.Scatter(x=np.array(range(208,214)),y=np.concatenate((np.array(fitted_values[-1]).reshape(1,),next_week_prediction)),\n                         line = dict(color='red', width=4, dash='dash'),\n                         name='Next weeks prediction'))","e42c11e3":"### Week sales Data frame and time series plot","7ea49a90":"### Autocorrelation Plots (ACF & PACF)","83865ba7":"==> Y_transformed is stationary","2a6025ea":"### Saisonality","c5912320":"### Furniture weekly sales ","5f164e5c":"### Fourier Transform","c3739bad":"### Evaluating the model ","95b3825f":"### Modeling and training :","ef3de7de":"==> There is no dominant spike, still, amplitude value reaches maximum at period 37 (weeks) and second maximum at period 75 wich is approximately equal to 37*2...","6cbf7b01":"### Stationarity test","a421f0d2":"## Sales per Categories :","705c37eb":"==> Two spikes, at 73 weeks period and in less degree at 62 weeks period.","d3836e3c":"For stationarity test, we consider only cycle component (Y - trend)","013d7dee":"In this part we follow the third area of improvement precited in the previous chapter. Instead of predicting global sales, we are going to predict sales per category and then aggregate them to find global sales prediction.","68369ea3":"### Stationarity test","959f3083":"==> In order to predict future trend terms the plots bellow indicates an AR(1) model.","c4d37aa7":"# Weekly predictions","c02df646":"==> Observations :  \n\n    1\/ The high variability of sales within months\n    2\/ Years 2015&2016 are similare in term of sales monthly mean value variation, at the beginning of the year, sales value is a bit stable and tends to fluctuate around a certain value, at September (Index 9 & 21) it spikes then decreases harshly to start reincreasing till the end of the year.\n    3\/ Year 2017 sale values behaves differently. Apparently, the main difference is that the september spikes is advanced to May(Index 29), sales value regain stability and start increasing by september till the end of the year.\n","ad178437":"### Modeling and training :","2bc07f10":"### Week sales Data frame and time series plot\n","e05c4cc8":"Since there are no apparent spikes, these plots give no insights about what model to use. But we had some good ideas according to previous plots, for example, seasonal subseries plot demonstrates that monthly sales tend to yearly seasonality, this characteristic can be transfered to our weekly model as a seasonality with period equal to 52 weeks.\nOn the other hand, we can integrate laggs 37 & 75 as AR terms","702f7d4f":"The goal of this step is to predict next week sales. There are different ways to proceed, we can either predict day by day sales on a window of seven days or directly predict weekly sales. If we work on weeks, we'll get less variability but also less observations since we will be grouping sales by weeks. From a different perspective, we can work on global sales time series or its subseries, for example predict sales for each category or even product. Working on different subseries might be beneficial if for example each subserie demonstrates some significative pattern such as seasonality.\n\n\nIn order to evaluate our models before predicting future sales, data will be splitted into training set containing years 2015\/2016\/2017 sales and test set containing year 2018 sales.","d1c935a9":"## Global Sales :","2e366b21":"### Evaluating the model ","a41da388":"==> In order to detect the presence of saisonality, we are going to subtract the trend we computed of sales time series.","28fad9da":"==> These results, are not convincing, the test data plot shows that the model doesn't really fit the data and fail to predict sales spikes. \n\nThis is because we failed to find a significant seasonality or relation with close laggs. Also, the signal behavior changes dratically between years.\n\nThere are several ways of improvement : \n\n    1\/ Ameliorate the signal decomposition, we used an HP-filter(lambda) to detrend the signal, hence tuning the lambda parameter might be of help. We can also use other decomposition methods such as moving averages or differencying the time series.\n    2\/ Predict monthly sales then split it on weeks, working on months reduces variability and helps in finding seasonal patterns.\n    3\/ Instead of working on global sales, work on sales per subcategories that demonstrates significant seasonal patterns and aggregate these sub-predictions to find global sales prediction. \n    4\/ Collect more data...","5f5934ec":"### Predicting next week sales","59f1c972":"### Next steps would be to redo the same process for other categories, predict sales for each one then aggregate all sales to get global sales value prediction. \n\n### Thank's for making it to the end of this notebook, please feel free to share your remarks and thoughts. ","97e4fe82":"### PACF & ACF ","e9ca8068":"### Trend detection HP-Filter","807c181c":"# Introduction","aabfdca5":"The HP filter removes a smooth trend, T, from the data x by solving\n\nmin sum((x[t] - T[t])**2 + lamb*((T[t+1] - T[t]) - (T[t] - T[t-1]))**2)\n\nLambda can be defined using the rule of thumb : \n\nLambda = 100*(number of periods in a year)^2\n\nIn this respect, for:\nAnnual data = 100*1^2 = 100\nQuarterly data = 100*4^2 = 1,600\nMonthly data = 100*12^2 = 14,400\nWeekly data = 100*52^2 = 270,400\n\nAn alternative is to use power 4 instead of 2 (See Ravn and Uhlig (2002))."}}