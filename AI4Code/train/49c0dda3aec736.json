{"cell_type":{"a2f8bae8":"code","fe5fe50c":"code","41187b73":"code","3a7192c6":"code","be82d765":"code","aa391903":"code","c0f1ee7e":"code","9195c3f0":"code","8cb4461b":"code","e21fd20a":"code","5cbf349f":"code","b7fdab77":"code","61b59f62":"code","4f50615b":"code","eb2c5958":"code","3a5d538b":"code","fdf4df7b":"code","6d7c834f":"code","63826d06":"code","90fa735f":"code","e400e89f":"code","faa62f6b":"code","fb46a1f5":"code","15a8bcd4":"code","6f8621af":"code","1e07ab09":"code","cde11b99":"code","9d5577a4":"code","ce56ea35":"code","407e48fb":"code","27cfb9e5":"markdown","d258a84e":"markdown","3fdc6790":"markdown","2611d7a1":"markdown","82aa6df1":"markdown"},"source":{"a2f8bae8":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","fe5fe50c":"from fastai.tabular import * ","41187b73":"# Define the path\npath = Path('\/kaggle\/input\/titanic')\npath.ls()","3a7192c6":"# Import the datasets\ntrain_df = pd.read_csv(path\/'train.csv')\ntest_df = pd.read_csv(path\/'test.csv')","be82d765":"# Check the length of the dataset\nprint(train_df.shape)\nprint(test_df.shape)","aa391903":"train_df.head()","c0f1ee7e":"test_df.head()","9195c3f0":"print(train_df.columns)","8cb4461b":"train_df.describe()","e21fd20a":"# We can see that some age value are lost, let's check for any null value\ntrain_df.isnull().sum()","5cbf349f":"# Let's check for the test set as well\ntest_df.isnull().sum()","b7fdab77":"# Fill missing \"Cabin\" values with \"N\" as there are too many missing values\ndef process_cabin(df):\n    df['Cabin'].fillna('N', inplace=True)","61b59f62":"# Fill missing \"Embarked\" values of dataset set with the most frequent value - mode\ndef process_embarked(df):\n    df['Embarked'].fillna(df['Embarked'].mode().iloc[0], inplace=True)","4f50615b":"# Fill the missing \"Age\" values with median\ndef process_age(df):\n    df['Age'].fillna(df['Age'].median(), inplace=True)","eb2c5958":"# Fill the missing \"Fare\" values with median\ndef process_fare(df):\n    df['Fare'].fillna(df['Fare'].median(), inplace=True)","3a5d538b":"# Extract some information about the name & tile\ndef process_title(df):\n    title_dict = {\n        \"Capt\":       \"Officer\",\n        \"Col\":        \"Officer\",\n        \"Major\":      \"Officer\",\n        \"Jonkheer\":   \"Royalty\",\n        \"Don\":        \"Royalty\",\n        \"Sir\" :       \"Royalty\",\n        \"Dr\":         \"Officer\",\n        \"Rev\":        \"Officer\",\n        \"the Countess\":\"Royalty\",\n        \"Dona\":       \"Royalty\",\n        \"Mme\":        \"Mrs\",\n        \"Mlle\":       \"Miss\",\n        \"Ms\":         \"Mrs\",\n        \"Mr\" :        \"Mr\",\n        \"Mrs\" :       \"Mrs\",\n        \"Miss\" :      \"Miss\",\n        \"Master\" :    \"Master\",\n        \"Lady\" :      \"Royalty\"\n    }\n    df['Title'] = df['Name'].map(lambda name: name.split(',')[1].split('.')[0].strip())\n    df['Title'] = df['Title'].map(title_dict)","fdf4df7b":"def process_df(df):\n    # Can add more feature engineering if you want\n    func_list = [process_title, process_age, process_fare, process_embarked, process_cabin]\n    for func in func_list:\n        func(df)","6d7c834f":"# Apply the feature engineering on both the training set and the testing set\nprocess_df(train_df)\nprocess_df(test_df)","63826d06":"# Let's check the training set again\nprint(train_df.isnull().sum())\ntrain_df.head()","90fa735f":"# Preprocessing \n# Actually, I didn't really need to manually process the missing data if using \"FillMissing\"\n# Let's try to remove the manual process later\nprocs = [FillMissing, Categorify, Normalize]","e400e89f":"# Split our variables into target, categorical and continuous variables\ndep_var = 'Survived'\n\n# There were too many missing \"Cabin\" values, so we will ignore that\n# The \"Name\" column has already been replaced by the \"Title\" column\ncat_names = train_df.drop(['Cabin', 'Name'], axis=1).select_dtypes(exclude='number').columns.tolist()\n\ncont_names = train_df.drop('Survived', axis=1).select_dtypes(include='number').columns.tolist()\n\nprint(cat_names)\nprint(cont_names)","faa62f6b":"test = TabularList.from_df(df=test_df, cat_names=cat_names, cont_names=cont_names, procs=procs)","fb46a1f5":"np.random.seed(42)\ndata = (TabularList.from_df(df=train_df, cat_names=cat_names, cont_names=cont_names, procs=procs)\n                   .split_by_rand_pct()\n                   .label_from_df(cols=dep_var)\n                   .add_test(test)\n                   .databunch())","15a8bcd4":"data.show_batch(10)","6f8621af":"learn = tabular_learner(data, layers=[200,100], metrics=accuracy)","1e07ab09":"learn.model_dir = '\/kaggle\/working'","cde11b99":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","9d5577a4":"min_grad_lr = learn.recorder.min_grad_lr\nlearn.fit_one_cycle(10, min_grad_lr)","ce56ea35":"learn.recorder.plot_losses()","407e48fb":"# Getting prediction\npreds, targets = learn.get_preds(DatasetType.Test)\nlabels = [p.argmax().item() for p in preds]\n\n# Create \"submission.csv\" file\nsubmission = pd.DataFrame({'PassengerId': test_df['PassengerId'], 'Survived': labels})\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","27cfb9e5":"* Now let's apply our knowledge to have some feature engineering ","d258a84e":"* Now let's explore the training set a little bit","3fdc6790":"* Now we can start building our model using FastAI Tabular Learner","2611d7a1":"* We can see that there are 4 columns that have missing values: **Age, Fare, Cabin, Embarked**","82aa6df1":"* Judging from the learning curve, our model seems to **overfit** a little bit!\n* In the end, our model was able to reach around **84%** acccuracy!"}}