{"cell_type":{"0d0d477f":"code","911967bd":"code","8540df34":"code","77f91498":"code","a4dcbeec":"code","b5ba1d91":"code","20a5aa64":"code","c4a10597":"code","bfb233b5":"code","3a2c9090":"code","eb6529f3":"code","164ae723":"markdown"},"source":{"0d0d477f":"!git clone https:\/\/github.com\/rwightman\/posenet-pytorch\n%cd posenet-pytorch","911967bd":"import os\nimport cv2\nimport torch\nimport posenet\nimport tensorflow as tf\nimport matplotlib.pyplot as plt","8540df34":"!pip install tfjs-graph-converter","77f91498":"import torch\nfrom posenet.constants import *\nfrom posenet.decode_multi import decode_multiple_poses\nfrom posenet.models.model_factory import load_model\nfrom posenet.utils import *\n\nnet = load_model(101)\nnet = net.cuda()\noutput_stride = net.output_stride\nscale_factor = 1.0","a4dcbeec":"def posenet_model(file):\n    input_image, draw_image, output_scale = posenet.read_imgfile(file, scale_factor=scale_factor, output_stride=output_stride)\n    with torch.no_grad():\n        input_image = torch.Tensor(input_image).cuda()\n\n        heatmaps_result, offsets_result, displacement_fwd_result, displacement_bwd_result = net(input_image)\n\n        pose_scores, keypoint_scores, keypoint_coords = posenet.decode_multiple_poses(\n            heatmaps_result.squeeze(0),\n            offsets_result.squeeze(0),\n            displacement_fwd_result.squeeze(0),\n            displacement_bwd_result.squeeze(0),\n            output_stride=output_stride,\n            max_pose_detections=10,\n            min_pose_score=0.25)\n        \n        #Find keypoints on the image\n        image = plt.imread(file)\n        poses = []\n        \n        for pi in range(len(pose_scores)):\n            if pose_scores[pi] != 0.:\n                print('Pose #%d, score = %f' % (pi, pose_scores[pi]))       \n                keypoints = keypoint_coords.astype(np.int32) \n                print(keypoints[pi])\n                poses.append(keypoints[pi])\n        \n        #Show keypoints on the image\n        img = plt.imread(file)\n        i=0\n        pose = poses[0]\n        plt.imshow(img)    \n        for y,x in pose:\n            plt.plot(x, y, 'w.') \n            plt.text(x, y, str(i), color='r', fontsize=10)\n            i+=1   \n        plt.show()","b5ba1d91":"file = '\/kaggle\/input\/yoga-poses-dataset\/DATASET\/TRAIN\/warrior2\/00000125.jpg'","20a5aa64":"import matplotlib.pyplot as plt\nimg = plt.imread(file)\nplt.imshow(img)\nplt.show()","c4a10597":"posenet_model(file)","bfb233b5":"file2 = '\/kaggle\/input\/yoga-poses-dataset\/DATASET\/TRAIN\/goddess\/00000100.jpg'\nfile3 = '\/kaggle\/input\/yoga-poses-dataset\/DATASET\/TRAIN\/tree\/00000077.jpg'","3a2c9090":"posenet_model(file2)","eb6529f3":"posenet_model(file3)","164ae723":"> POSENET\n\n**PoseNet** is a deep learning TensorFlow model is used in trackting human poses\n\nThis notebook highlights implementation computer vision technique in identifying keypoints and tracking the human posture in yoga poses. \n\nFeedback on this notebook will be highly appreciated."}}