{"cell_type":{"225126f9":"code","ea4c311d":"code","3593e6a3":"code","fccf5d3d":"code","939f0bce":"code","673aa5a4":"code","3b7fc425":"code","399abccf":"code","b8c5f75a":"code","2399da70":"code","52e85ad6":"code","49678f7e":"code","c7cf3981":"code","7d205ad7":"code","4fed968e":"code","9b754358":"code","e706d6ce":"code","3f2b4028":"code","ea2ba194":"code","a5073035":"markdown","980d149f":"markdown","07e1a355":"markdown","d7e87613":"markdown","bee5d749":"markdown"},"source":{"225126f9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ea4c311d":"base_path = '\/kaggle\/input\/zelda-game-levels\/dataset'","3593e6a3":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.xception import preprocess_input\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    validation_split=0.25) # set validation split\n\ntrain_dataset = train_datagen.flow_from_directory(\n    base_path,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    subset='training') # set as training data\n\ntest_dataset = train_datagen.flow_from_directory(\n    base_path, # same directory as training data\n    target_size=(224, 224),\n    batch_size=32,\n    shuffle='false',\n    class_mode='categorical',\n    subset='validation') # set as validation data\n\n","fccf5d3d":"import matplotlib.pyplot as plt\nimage, label = train_dataset[0]\nprint('Classes: ', test_dataset.class_indices.keys())\nprint('Size of batch: ',image.shape) #display the shape of batch, imageximage, number_of_channel\n\n%matplotlib inline\nnrows = 2\nncols = 4\nfig = plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\nfor i in range(4):\n    sp = plt.subplot(nrows, ncols, i + 1)\n    sp.axis('Off')\n\n    if train_dataset.classes[i] == 0:\n        sp.set_title('Playable')\n    else:\n        sp.set_title('Unplayable')\n    \n    \n    plt.imshow(image[i])","939f0bce":"from keras.models import Sequential, load_model\nfrom tensorflow import keras\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, GlobalAveragePooling2D\n#create model\nmodel = Sequential()\n#add model layers\nmodel.add(Conv2D(64,(3,3), activation=\"relu\", input_shape=(224,224,3)))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(32, (3,3), activation=\"relu\"))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(64, (3,3), activation=\"relu\"))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(128, (3,3), activation=\"relu\"))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Flatten())\nmodel.add(Dense(2, activation=\"softmax\"))\nmodel1 = model\nmodel1.summary()","673aa5a4":"model1.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nhistory1 = model1.fit_generator(train_dataset, validation_data = test_dataset, epochs=10)","3b7fc425":"#print(history1.history['val_accuracy'])\nplt.figure(1,figsize=(15, 8))\nplt.subplot(221)\nplt.plot(history1.history['accuracy'], label = 'train')\nplt.plot(history1.history['val_accuracy'], label = 'valid')\nplt.legend()\nplt.title('CNN Accuracy')\nplt.ylabel('Accuracy')  \nplt.xlabel('epoch')\nplt.legend(['train', 'valid']) \n\n\nplt.subplot(222)  \nplt.plot(history1.history['loss'])  \nplt.plot(history1.history['val_loss'])  \nplt.title('CNN loss')  \nplt.ylabel('loss')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'valid'])\nplt.show()","399abccf":"y_pred = model1.predict_generator(test_dataset, steps=np.ceil(len(test_dataset.classes)\/32))\nloss = keras.losses.sparse_categorical_crossentropy(test_dataset.classes, y_pred)","b8c5f75a":"from sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\ny_pred = model1.predict_generator(test_dataset, steps=np.ceil(len(test_dataset.classes)\/32))\ny_pred = np.argmax(y_pred, axis=1)\ncm = confusion_matrix(test_dataset.classes, y_pred)\nfrom sklearn.metrics import ConfusionMatrixDisplay\nlabels = ['Playabel', 'Unplayable']\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\ndisp.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","2399da70":"from keras.applications.xception import preprocess_input\ntrain_datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,    \n    #rescale=1.\/255,       #Image augmentation\n    #shear_range=0.2,\n    #zoom_range=0.2,\n    #horizontal_flip=True,\n    validation_split=0.20) # set validation split\n\ntrain_dataset = train_datagen.flow_from_directory(\n    base_path,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    subset='training') # set as training data\n\ntest_dataset = train_datagen.flow_from_directory(\n    base_path, # same directory as training data\n    target_size=(224, 224),\n    batch_size=408,\n    shuffle='false',\n    class_mode='categorical',\n    subset='validation') # set as validation data","52e85ad6":"import matplotlib.pyplot as plt\nimage, label = test_dataset[0]\nprint('Classes: ', train_dataset.class_indices.keys())\nprint('Size of batch: ',image.shape) #display the shape of batch, imageximage, number_of_channel\n\n%matplotlib inline\nnrows = 2\nncols = 4\nfig = plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\nfor i in range(4):\n    sp = plt.subplot(nrows, ncols, i + 1)\n    sp.axis('Off')\n\n    if test_dataset.classes[i] == 0:\n        sp.set_title('Playable')\n    else:\n        sp.set_title('Unplayable')\n    \n    \n    plt.imshow(image[i])","49678f7e":"from tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Flatten\nxception = Xception(include_top=False, input_shape=(224, 224, 3))\n\nfor layer in xception.layers:\n    layer.trainable=False\n    \nflat1 = Flatten()(xception.layers[-1].output)\nclass1 = Dense(256, activation='relu')(flat1)\noutput = Dense(2, activation='softmax')(class1)\n\nmodel = Model(inputs = xception.inputs, outputs = output)\nmodel2 = model","c7cf3981":"#Model Summary\nmodel2.summary()","7d205ad7":"from tensorflow.keras import optimizers\n\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=1e-2,\n    decay_steps=10000,\n    decay_rate=0.9)\nsgd = optimizers.SGD(learning_rate = lr_schedule)\n#sgd = optimizers.SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n\nmodel2.compile(loss = 'categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n\nhistory2 = model2.fit_generator(train_dataset,\n                    validation_data = test_dataset,\n                    epochs=100)","4fed968e":"#print(history1.history['val_accuracy'])\nplt.figure(1,figsize=(15, 8))\nplt.subplot(221)\nplt.plot(history2.history['accuracy'], label = 'train')\nplt.plot(history2.history['val_accuracy'], label = 'valid')\nplt.legend()\nplt.title('Xception Accuracy')\nplt.ylabel('Accuracy')  \nplt.xlabel('epoch')\nplt.legend(['train', 'valid']) \n\n\nplt.subplot(222)  \nplt.plot(history2.history['loss'])  \nplt.plot(history2.history['val_loss'])  \nplt.title('Xception loss')  \nplt.ylabel('loss')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'valid'])\nplt.show()","9b754358":"from sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\ny_pred = model2.predict_generator(test_dataset, steps=np.ceil(len(test_dataset.classes)\/32))\ny_pred = np.argmax(y_pred, axis=1)\ncm = confusion_matrix(test_dataset.classes, y_pred)\nfrom sklearn.metrics import ConfusionMatrixDisplay\nlabels = ['Playabel', 'Unplayable']\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\ndisp.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","e706d6ce":"y_pred = model2.predict_generator(test_dataset, steps=np.ceil(len(test_dataset.classes)\/32))\nloss_values = keras.losses.sparse_categorical_crossentropy(test_dataset.classes, y_pred, from_logits=True).numpy()                   ","3f2b4028":"def plot_top_losses(actual, pred,loss_values, k=9, figsize=(10,10)):\n  loss_values = loss_values\n  top_k = loss_values.argsort()[-k:][::-1]\n  cols = math.ceil(math.sqrt(k))\n  rows = math.ceil(k\/cols)\n  fig,axes = plt.subplots(rows, cols, figsize=figsize)\n  fig.suptitle('Prediction\/Actual\/Loss\/Prediction_Probability', weight='bold', size=14)\n  i =0\n  for index in top_k:\n    image = test_dataset[0][0][index]\n    if test_dataset.classes[index] == 0:\n        actual = 'Playable'\n    else:\n        actual = 'Unplayable'\n    \n    if np.argmax(pred[index]) == 0:\n        predicted = 'Playable'\n    else:\n        predicted = 'Unplayable'\n        \n    loss_value = loss_values[index]\n    prob = pred[index][np.argmax(pred[index])]\n    title = f'{predicted}\/{actual}\/{loss_value:.2f}\/{prob:.2f}'\n    ax = axes.flat[i]\n    i+=1\n    #image = np.squeeze(image,axis=2)\n    ax.imshow(image)\n    ax.set_title(title)","ea2ba194":"import math\nplot_top_losses(test_dataset.classes,y_pred,loss_values, k=9)","a5073035":"### TOP LOSSES","980d149f":"## Transfer Learning using Xception Model","07e1a355":"### PLOT OF MODEL ACCURACY AND LOSS","d7e87613":"# Baisc CNN Model","bee5d749":"### CONFUSION METRIX"}}