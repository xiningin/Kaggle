{"cell_type":{"daa84e22":"code","27e2f7d8":"code","e4b694fa":"code","98425562":"code","34d26e77":"code","b0c0bb6a":"code","0a569a9e":"code","1e6737c7":"code","71f926c9":"code","71444307":"code","195f4295":"code","fa60872e":"code","7c2de370":"code","403449dd":"markdown","628f3439":"markdown","f35cfe22":"markdown","a9122e81":"markdown","9c00b2ba":"markdown","f5f3ecc8":"markdown","d97d4b2a":"markdown","7c83ada9":"markdown","509cb50c":"markdown","59900510":"markdown","3442a811":"markdown","08f24a9f":"markdown","46c2124b":"markdown","e972914e":"markdown","93b5211e":"markdown","62bce60a":"markdown"},"source":{"daa84e22":"# Main imports\nimport numpy as np\nimport pandas as pd\nimport os\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n\n# Read data into pandas dataframe\ndf_jobs = pd.read_csv(\"\/kaggle\/input\/data-scientist-jobs\/DataScientist.csv\")\nprint(df_jobs.head())\nprint(df_jobs.info())","27e2f7d8":"# Remove Unnamed: 0 Column\ndf_jobs = df_jobs.drop(columns = \"Unnamed: 0\")\n\n\n# Parse Salary Info, Company Name, Size and Revenue\nHOURS_PER_WEEK = 40\nWEEKS_PER_YEAR = 52\n\nfor i in range(df_jobs.shape[0]):\n    salary_estimate = df_jobs.loc[i, \"Salary Estimate\"]\n    salary_estimate = salary_estimate.replace(\"$\", \"\")\n    if 'Per Hour' in salary_estimate:\n        lower, upper = salary_estimate.split('-')\n        upper, _ = upper.split(\"Per\")\n        upper = upper.strip()\n        lower = int(lower) * HOURS_PER_WEEK * WEEKS_PER_YEAR * (1\/1000)\n        upper = int(upper) * HOURS_PER_WEEK * WEEKS_PER_YEAR * (1\/1000)\n        df_jobs.loc[i, \"Salary Estimate Extrapolate\"] = True\n    else:\n        lower, upper = salary_estimate.split('-')\n        lower = lower.replace(\"K\", \"\")\n        upper, _ = upper.split(\"(\")\n        upper = upper.replace(\"K\", \"\")\n        upper = upper.strip()\n        df_jobs.loc[i, \"Salary Estimate Extrapolate\"] = False\n    lower = int(lower)\n    upper = int(upper)\n    df_jobs.loc[i, \"Salary Estimate Lower Bound\"] = lower\n    df_jobs.loc[i, \"Salary Estimate Upper Bound\"] = upper\n    name = df_jobs.loc[i, \"Company Name\"]\n    if '\\n' in name:\n        name, _ = name.split('\\n')\n    df_jobs.loc[i, \"Company Name\"] = name\n    size = df_jobs.loc[i, \"Size\"]\n    if 'to' in size:\n        lower, upper = size.split('to')\n        lower = lower.strip()\n        _, upper, _ = upper.split(' ')\n        upper = upper.strip()\n        lower = int(lower)\n        upper = int(upper)\n    elif '+' in size:\n        lower, _ = size.split('+')\n        lower = int(lower)\n        upper = np.inf\n    else:\n        lower = np.nan\n        upper = np.nan\n    df_jobs.loc[i, \"Size Lower Bound\"] = lower\n    df_jobs.loc[i, \"Size Upper Bound\"] = upper\n    revenue = str(df_jobs.loc[i, \"Revenue\"])\n    if \"$\" in revenue:\n        LOWER_MULT = 1\n        UPPER_MULT = 1\n        revenue = revenue.replace('$', \"\")\n        if 'to' in revenue:\n            lower, upper = revenue.split('to')\n            if 'million' in lower:\n                UPPER_MULT = 1000\n                lower = lower.strip(\" million\")\n            else:\n                if 'billion' in upper:\n                    UPPER_MULT = 1000\n                    LOWER_MULT = 1000\n            #lower, _ = lower.split(\" \")\n            _, upper, _, _ = upper.split(\" \")\n            upper = int(upper.strip()) * UPPER_MULT\n            lower = int(lower.strip()) * LOWER_MULT \n        elif 'Less' in revenue:\n            lower = 0\n            _, upper = revenue.split('than')\n            upper, _ = upper.split('million')\n            upper = int(upper)\n        else:\n            lower,_ = revenue.split('+')\n            lower = int(lower.strip())\n            upper = np.inf\n    else:\n        lower = np.nan\n        upper = np.nan\n    df_jobs.loc[i, \"Revenue Lower Bound\"] = lower\n    df_jobs.loc[i, \"Revenue Upper Bound\"] = upper\n    \n    \ndf_jobs = df_jobs.drop(columns = \"Salary Estimate\")\ndf_jobs = df_jobs.drop(columns = \"Size\")\ndf_jobs = df_jobs.drop(columns = \"Revenue\")\n\n# Replace -1's\ndf_jobs = df_jobs.replace([-1,'-1'], np.nan)\n","e4b694fa":"col_salary = df_jobs.loc[: , [\"Salary Estimate Lower Bound\", \"Salary Estimate Upper Bound\"]]\ndf_jobs['Salary Estimate Median'] = col_salary.mean(axis=1)\n\ncol_size = df_jobs.loc[: , [\"Size Lower Bound\", \"Size Upper Bound\"]]\ndf_jobs['Size Median'] = col_size.mean(axis=1)\n\ncol_revenue = df_jobs.loc[: , [\"Revenue Lower Bound\", \"Revenue Upper Bound\"]]\ndf_jobs['Revenue Median'] = col_revenue.mean(axis=1)","98425562":"sns.set(style=\"ticks\", color_codes=True)\nplt.style.use('fivethirtyeight')\n\n\ng = sns.catplot(x=\"Salary Estimate Lower Bound\", y=\"Industry\", kind=\"box\", data=df_jobs, order=df_jobs.Industry.value_counts().iloc[:25].index)\ng.set(xlim=(0, 250))\ng.fig.set_size_inches(30, 10)\ng.ax.set_xticks([50,75,100,125,150,175,200,225,250], minor=True)\nplt.title(\"Salary Lower Bound - Ordered by Most Common Industries\")\nplt.show()","34d26e77":"df_sal = df_jobs.groupby(\"Industry\").median().sort_values(by = 'Salary Estimate Lower Bound', ascending=False)\ng = sns.catplot(x=\"Salary Estimate Lower Bound\", y=\"Industry\", kind=\"box\", data=df_jobs, order=df_sal.iloc[:25].index)\ng.set(xlim=(0, 250))\ng.fig.set_size_inches(30, 10)\ng.ax.set_xticks([50,75,100,125,150,175,200,225,250], minor=True)\nplt.title(\"Salary Lower Bound - Ordered by Median Salary\")\nplt.show()","b0c0bb6a":"industry_counts = df_jobs.Industry.value_counts()\nCUTOFF = 20\n\ndroprows = []\nfor i in range(df_jobs.shape[0]):\n    industry = str(df_jobs.loc[i, \"Industry\"])\n    if industry != 'nan':\n        val = industry_counts[industry]\n        if val < CUTOFF:\n            droprows.append(i)\n        \ndf_trim = df_jobs.drop(droprows)\n\ndf_sal = df_trim.groupby(\"Industry\").median().sort_values(by = 'Salary Estimate Lower Bound', ascending=False)\ng = sns.catplot(x=\"Salary Estimate Lower Bound\", y=\"Industry\", kind=\"box\", data=df_jobs, order=df_sal.iloc[:25].index)\ng.set(xlim=(0, 250))\ng.fig.set_size_inches(30, 10)\ng.ax.set_xticks([50,75,100,125,150,175,200,225,250], minor=True)\nplt.title(\"Salary Lower Bound - Ordered by Median Salary (Excluding Low-Frequency Industries)\")\nplt.show()","0a569a9e":"g = sns.catplot(x=\"Salary Estimate Upper Bound\", y=\"Industry\", kind=\"box\", data=df_jobs, order=df_jobs.Industry.value_counts().iloc[:25].index)\ng.set(xlim=(50, 300))\ng.fig.set_size_inches(30, 10)\ng.ax.set_xticks([50,75,100,125,150,175,200,225,250,275,300], minor=True)\nplt.title(\"Salary Upper Bound - Ordered by Most Common Industries\")\nplt.show()\n\n\ndf_sal = df_jobs.groupby(\"Industry\").median().sort_values(by = 'Salary Estimate Upper Bound', ascending=False)\ng = sns.catplot(x=\"Salary Estimate Upper Bound\", y=\"Industry\", kind=\"box\", data=df_jobs, order=df_sal.iloc[:25].index)\ng.set(xlim=(50, 300))\ng.fig.set_size_inches(30, 10)\ng.ax.set_xticks([50,75,100,125,150,175,200,225,250,275,300], minor=True)\nplt.title(\"Salary Upper Bound - Ordered by Median Salary\")\nplt.show()\n\nindustry_counts = df_jobs.Industry.value_counts()\nCUTOFF = 20\n\ndroprows = []\nfor i in range(df_jobs.shape[0]):\n    industry = str(df_jobs.loc[i, \"Industry\"])\n    if industry != 'nan':\n        val = industry_counts[industry]\n        if val < CUTOFF:\n            droprows.append(i)\n        \ndf_trim = df_jobs.drop(droprows)\n\ndf_sal = df_trim.groupby(\"Industry\").median().sort_values(by = 'Salary Estimate Upper Bound', ascending=False)\ng = sns.catplot(x=\"Salary Estimate Upper Bound\", y=\"Industry\", kind=\"box\", data=df_jobs, order=df_sal.iloc[:25].index)\ng.set(xlim=(50, 300))\ng.fig.set_size_inches(30, 10)\ng.ax.set_xticks([50,75,100,125,150,175,200,225,250,275,300], minor=True)\nplt.title(\"Salary Upper Bound - Ordered by Median Salary (Excluding Low-Frequency Industries)\")\nplt.show()","1e6737c7":"from tqdm.notebook import tqdm\nfrom geopy.geocoders import Nominatim\n\ngeolocator = Nominatim(user_agent=\"jeff_braun\")\nunique_locs = df_jobs[\"Location\"].unique()\nlocs_dict = {}\n\ndf_jobs.replace('Northbrook, IL', 'Deerfield, IL')\n\nfor loc_name in unique_locs:\n    if str(loc_name) != 'nan':\n        if 'CA' in loc_name:\n            loc_name = loc_name.replace(\"CA\", \"California\")\n        if 'IL' in loc_name:\n            loc_name = loc_name.replace(\"IL\", \"Illinois\")\n        if 'PA' in loc_name:\n            loc_name = loc_name.replace(\"PA\", \"Pennsylvania\")\n        if 'Monaco,' in loc_name:\n            loc_name = 'Lawndale, California, United States'\n        location = geolocator.geocode(loc_name)\n        if location is not None:\n            lat = location.latitude\n            long = location.longitude\n            locs_dict[loc_name] = [lat, long]\n            \nfor i in range(df_jobs.shape[0]):\n    long = np.nan\n    lat = np.nan\n    my_loc = str(df_jobs.loc[i, 'Location'])\n    if 'CA' in my_loc:\n        my_loc = my_loc.replace('CA', 'California')\n    if 'IL' in my_loc:\n        my_loc = my_loc.replace(\"IL\", \"Illinois\")\n    if 'PA' in my_loc:\n        my_loc = my_loc.replace(\"PA\", \"Pennsylvania\")\n    if 'Monaco,' in my_loc:\n        my_loc = 'Lawndale, California, United States'\n    if my_loc != 'nan' and my_loc in locs_dict.keys():\n        coords = locs_dict[my_loc]\n        long = coords[1]\n        lat = coords[0]\n    df_jobs.loc[i, 'Location Longitude'] = long\n    df_jobs.loc[i, 'Location Latitude'] = lat\n","71f926c9":"import folium\nfrom folium import plugins\n\ndf_loc = df_jobs.copy()\ndf_loc = df_loc.dropna(subset=['Location Latitude'])\ndf_loc = df_loc.reset_index()\n\n# mark each station as a point\nm = folium.Map([41.8781, -87.6298], zoom_start=3)\n#for index, row in df_loc.iterrows():\n    #if str(row['Location Latitude']) != 'nan':\n        #folium.CircleMarker([row['Location Latitude'], row['Location Longitude']],\n                            #radius=15,\n                            #popup=row['Location'],\n                            #fill_color=\"#3db7e4\", # divvy color\n                           #).add_to(m)\n# convert to (n, 2) nd-array format for heatmap\nlocationArr = df_loc[['Location Latitude', 'Location Longitude']]\n\n# plot heatmap\nm.add_child(plugins.HeatMap(locationArr, radius=15))\nm","71444307":"from sklearn.cluster import KMeans\nfrom sklearn.datasets import make_blobs\nfrom yellowbrick.cluster import KElbowVisualizer\n\nX = df_loc[['Location Latitude', 'Location Longitude']]\n\n# Instantiate the clustering model and visualizer\nmodel = KMeans()\nvisualizer = KElbowVisualizer(model, k=(4,20))\n\nvisualizer.fit(X)        # Fit the data to the visualizer\nvisualizer.show() \n\nkmeans = KMeans(n_clusters = 8, random_state=0).fit(X)\nkmeans.cluster_centers_\n\nm = folium.Map([41.8781, -87.6298], zoom_start=3)\nfor i in range(kmeans.cluster_centers_.shape[0]):\n    num = sum(kmeans.labels_ == i)\n    folium.CircleMarker([kmeans.cluster_centers_[i,0], kmeans.cluster_centers_[i,1]],\n                        radius=15,\n                        popup=str(num) + ' Jobs Associated with this Cluster',\n                        fill_color=\"#3db7e4\", # divvy color\n                        ).add_to(m)\nm","195f4295":"my_colors = ['#E6B0AA', '#EC7063', '#AF7AC5', '#7D3C98', '#5499C7', '#AED6F1 ', '#A3E4D7', '#16A085', '#229954', '#58D68D', '#F7DC6F', '#F5B041', '#AF601A', '#6E2C00', '#7F8C8D' ]\n\nkmeans = KMeans(n_clusters = 14, random_state=0).fit(X)\nkmeans.cluster_centers_\n\nm = folium.Map([41.8781, -87.6298], zoom_start=3)\nfor i in range(kmeans.cluster_centers_.shape[0]):\n    num = sum(kmeans.labels_ == i)\n    folium.CircleMarker([kmeans.cluster_centers_[i,0], kmeans.cluster_centers_[i,1]],\n                        radius=30,\n                        popup=str(num) + ' Jobs Associated with Cluster ' + str(i),\n                        fill_color=my_colors[i],\n                        fill_opacity = 0.8,# divvy color\n                        ).add_to(m)\nfor i in range(df_loc.shape[0]):\n    folium.CircleMarker([df_loc.loc[i, 'Location Latitude'], df_loc.loc[i, 'Location Longitude']],\n                        radius=15,\n                        popup=df_loc.loc[i, 'Location'],\n                        fill_color=my_colors[kmeans.labels_[i]],\n                        fill_opacity = 1,# divvy color\n                        ).add_to(m)\nm","fa60872e":"metro_areas = ['San Diego, CA', 'Chicago, IL', 'Philadelphia, PA', 'Austin, TX', 'London, UK',  'San Francisco Bay, CA', 'Jacksonville, FL', 'Phoenix, AZ', 'Columbus, OH', 'Dallas, TX', 'Houston, TX',  'Los Angeles, CA', 'New York, NY', 'San Antonio, TX']\nfor i in range(df_loc.shape[0]):\n    cluster = kmeans.labels_[i]\n    df_loc.loc[i, 'Metro Area'] = metro_areas[cluster]\n    \nsns.set(style=\"ticks\", color_codes=True)\nplt.style.use('fivethirtyeight')\n\ng = sns.catplot(x=\"Salary Estimate Lower Bound\", y=\"Metro Area\", kind=\"box\", data=df_loc, order=df_loc['Metro Area'].value_counts().iloc[:15].index)\ng.set(xlim=(0, 250))\ng.fig.set_size_inches(30, 10)\ng.ax.set_xticks([50,75,100,125,150,175,200,225,250], minor=True)\nplt.title(\"Salary Lower Bound - Ordered by Most Common Metro Areas\")\nplt.show()\n\ndf_sal = df_loc.groupby(\"Metro Area\").median().sort_values(by = 'Salary Estimate Lower Bound', ascending=False)\ng = sns.catplot(x=\"Salary Estimate Lower Bound\", y=\"Metro Area\", kind=\"box\", data=df_loc, order=df_sal.iloc[:25].index)\ng.set(xlim=(0, 250))\ng.fig.set_size_inches(30, 10)\ng.ax.set_xticks([50,75,100,125,150,175,200,225,250], minor=True)\nplt.title(\"Salary Lower Bound - Ordered by Median Salary\")\nplt.show()\n    \ng = sns.catplot(x=\"Salary Estimate Upper Bound\", y=\"Metro Area\", kind=\"box\", data=df_loc, order=df_loc['Metro Area'].value_counts().iloc[:15].index)\ng.set(xlim=(50, 300))\ng.fig.set_size_inches(30, 10)\ng.ax.set_xticks([50,75,100,125,150,175,200,225,250,275,300], minor=True)\nplt.title(\"Salary Upper Bound - Ordered by Most Common Metro Areas\")\nplt.show()\n\ndf_sal = df_loc.groupby(\"Metro Area\").median().sort_values(by = 'Salary Estimate Upper Bound', ascending=False)\ng = sns.catplot(x=\"Salary Estimate Upper Bound\", y=\"Metro Area\", kind=\"box\", data=df_loc, order=df_sal.iloc[:25].index)\ng.set(xlim=(50, 300))\ng.fig.set_size_inches(30, 10)\ng.ax.set_xticks([50,75,100,125,150,175,200,225,250,275,300], minor=True)\nplt.title(\"Salary Upper Bound - Ordered by Median Salary\")\nplt.show()\n\n\n    ","7c2de370":"pol = [0.77, 0.91, 1, 1.1, 0.62, 0.55, 1.22, 1.12, 1.22, 1, 1.16, 0.75, 0.44, 1.23]\n\nfor i in range(df_loc.shape[0]):\n    ma = df_loc.loc[i, 'Metro Area']\n    index = metro_areas.index(ma)\n    pol_adjustment = pol[index]\n    df_loc.loc[i, 'Salary Lower Bound COL Adjusted'] = df_loc.loc[i, 'Salary Estimate Lower Bound'] * pol_adjustment\n    df_loc.loc[i, 'Salary Upper Bound COL Adjusted'] = df_loc.loc[i, 'Salary Estimate Upper Bound'] * pol_adjustment\n    \n\ndf_sal = df_loc.groupby(\"Metro Area\").median().sort_values(by = 'Salary Lower Bound COL Adjusted', ascending=False)\ng = sns.catplot(x=\"Salary Lower Bound COL Adjusted\", y=\"Metro Area\", kind=\"box\", data=df_loc, order=df_sal.iloc[:25].index)\ng.set(xlim=(0, 250))\ng.fig.set_size_inches(30, 10)\ng.ax.set_xticks([50,75,100,125,150,175,200,225,250], minor=True)\nplt.title(\"Salary Lower Bound COL Adjusted - Ordered by Median Salary\")\nplt.show()\n\ndf_sal = df_loc.groupby(\"Metro Area\").median().sort_values(by = 'Salary Upper Bound COL Adjusted', ascending=False)\ng = sns.catplot(x=\"Salary Upper Bound COL Adjusted\", y=\"Metro Area\", kind=\"box\", data=df_loc, order=df_sal.iloc[:25].index)\ng.set(xlim=(50, 300))\ng.fig.set_size_inches(30, 10)\ng.ax.set_xticks([50,75,100,125,150,175,200,225,250,275,300], minor=True)\nplt.title(\"Salary Upper Bound COL Adjusted - Ordered by Median Salary\")\nplt.show()","403449dd":"Let's generate the exact same series of plots for Salary Upper Bound.","628f3439":"## Location vs. Salary","f35cfe22":"Having Eight Clusters captures the different job 'regions'\n1. Southeastern Texas (1253 Jobs)\n2. Los Angeles and Soutern California (690 Jobs)\n3. New York and Northeast Corridor (678 Jobs)\n4. Chicago and Columbus (540 Jobs)\n5. San Fransisco and Northern California (379 Jobs)\n6. Phoenix and Southern Arizona (295 Jobs)\n7. Jacksonville (69 Jobs)\n8. London (4 Jobs)\n\nNow, let's make the clusters a bit more refined.\n","a9122e81":"# EDA \n","9c00b2ba":"We can see that data science jobs are clustered around a few American cities and London. Let's run KMeans to cluster the different jobs and then see where the cluster centers are as well as how many jobs are associated with each cluster. ","f5f3ecc8":"So here's where we see the dominance by the San Francisco Bay Area. Although Texas may have the most jobs, the highest paying jobs are in California. This natrually leads into the next analysis: what does this data look like when adjusted for cost of living? To do so, we'll use Dallas, TX as the base city and utilizing NerdWallet's cost of living comparison calculator. If anyone knows a better resource, please let me know, but for now this will suffice.\nhttps:\/\/www.nerdwallet.com\/cost-of-living-calculator\/compare\/dallas-tx-vs-san-francisco-ca\n\nTo get data for London, I used some data from this site and made sure it was consistent with the other costs of living. https:\/\/www.expatistan.com\/cost-of-living\/index\/north-america","d97d4b2a":"This is interesting, but it would probably be more helpful to order the Industries in a more useful manner, like by Median Salary.","7c83ada9":"Keep in mind that I'm not sure how accurate the cost of living data is. Regardless, this data helps explain why so many data science jobs are popping up in Southeastern Texas: the cost of living is lower than that of California and New York, so your salary goes a long way there.","509cb50c":"# Data Cleaning\nThere are a couple of things I'd like to clean up with this data set to lend itself to more thorough analysis:\n* Remove the Unnamed: 0 Column\n* Split Salary Estimate into Lower Bound Annual, Upper Bound Annual, and extrapolate per hour to annual salary \n* Clean Company Name (remove what appears to be the rating)\n* Split Size into Lower Bound and Upper Bound\n* Split Revenue into Lower Bound and Upper Bound\n* Replace -1 into more appropriate data\n\nApologies in advance for iterating through my dataframe\n","59900510":"Before we can work with the location data, we've got to parse longitude\/latitude data from the city name","3442a811":"## Salary vs. Industry\nLet's first look at the interplay between Industry and Salary.","08f24a9f":"Visualize the locations with a heat map","46c2124b":"We can see that the clusters now all correspond to cities, almost precisely (except the San Fransisco Bay area, but its probably best to lump them all together anyway). Here are the cluster centers ranked now:\n1. Dallas, TX (464 Jobs)\n2. San Fransisco Bay Area (379 Jobs)\n3. Chicago, IL (363 Jobs)\n4. Los Angeles, CA (360 Jobs)\n5. Austin, TX (357 Jobs)\n6. Philadelphia, PA (346 Jobs)\n7. New York, NY (332 Jobs)\n8. San Diego, CA (330 Jobs)\n9. Phoenix, AZ (295 Jobs)\n10. Houston, TX (241 Jobs)\n11. San Antonio, TX (191 Jobs)\n12. Columbus, OH (177 Jobs)\n13. Jacksonville, FL (69 Jobs)\n14. London, UK (4 Jobs)\n\nNow let's see how Job Location correlates with Salary\n","e972914e":"More to come...","93b5211e":"Before we do some preliminary visualizations, let's add the following columns:\n* Median Salary Estimate\n* Median Size\n* Median Revenue\n","62bce60a":"Let's exclude any Industries that don't have that much data; say, only industries with at least 20 different job postings."}}