{"cell_type":{"0cb8d7d9":"code","5eb9a172":"code","ae17dfc2":"code","7a9ed58b":"code","70f0578d":"code","ce18c55b":"code","a01cc7c3":"code","05d670d9":"code","31f1f7b1":"code","01cb7116":"code","43e8335a":"code","f5441dfa":"code","455d6896":"code","9db0afb1":"code","0311bbc2":"code","2b5d1487":"code","11bef534":"code","13d6fe5f":"code","ac21bcb5":"code","e0a06823":"code","aacc7e71":"code","774dffe0":"code","659dbeb4":"code","d78b25ae":"code","6f362cf7":"code","6f3fc357":"code","b03c734b":"code","a73ed7f7":"code","a26f5632":"code","a14a2b56":"code","690f6431":"code","213b31e6":"code","fcea54ae":"code","0f071d37":"code","758a4772":"code","65d81d0b":"code","e05c67e6":"code","e2252da1":"code","5a39d40f":"code","433dccff":"code","55028526":"code","ccbac54d":"code","b9618871":"code","3a7ce9d5":"code","a0133f8d":"code","ac59d6e0":"code","a1f98d28":"code","4a19c5c6":"code","2941d31a":"code","e90c66c9":"code","b57e2460":"code","95ebec67":"code","2341ea95":"code","7fc43b54":"code","0e744cd7":"code","7d5d58dc":"code","9b0a81c7":"code","3653cbd7":"code","91a82557":"code","d98860d7":"code","5268909d":"markdown","0e588edb":"markdown","91545e9a":"markdown","c6079695":"markdown","b7e89354":"markdown","5e45bff9":"markdown","f6e08029":"markdown","a8db1f77":"markdown","659ee4ea":"markdown","024ee890":"markdown","564e320c":"markdown"},"source":{"0cb8d7d9":"import pandas as pd\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport seaborn as sns\r\nprint(\"Priyatama is ready!\")","5eb9a172":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntrain.head()","ae17dfc2":"train.shape","7a9ed58b":"train_blank = (train.isnull().sum())\r\ntrain_blank=train_blank[train_blank>0]\r\ntrain_blank.sort_values(ascending=False)","70f0578d":"train2=train.copy()","ce18c55b":"train2.drop({'PoolQC','MiscFeature','Alley','Fence'},axis=1, inplace=True)\r\ntrain2_blank = (train2.isnull().sum())\r\ntrain2_blank=train2_blank[train2_blank>0]\r\ntrain2_blank.sort_values(ascending=False)","a01cc7c3":"train3=train2.copy()\r\ntrain3.FireplaceQu.value_counts()","05d670d9":"replace_fireplaceq = {'Ex' : 5, 'Gd' : 4, 'TA' : 3 , 'Fa':2,'Po':1}                                                                                          \r\ntrain3 = train3.replace({\"FireplaceQu\": replace_fireplaceq})\r\ntrain3['FireplaceQu'] = train3['FireplaceQu'].replace(np.nan, 0)\r\ntrain3.FireplaceQu.value_counts()","31f1f7b1":"train3_blank = (train3.isnull().sum())\r\ntrain3_blank=train3_blank[train3_blank>0]\r\ntrain3_blank.sort_values(ascending=False)","01cb7116":"train4 = train3.copy()\r\nfig, ax=plt.subplots(figsize=(20,5))\r\nplt.scatter(x=train4.LotArea, y=train4.LotFrontage)\r\nplt.xlabel('Lot Area', fontweight='bold', fontsize=10)\r\nplt.ylabel('Lot Frontage', fontweight='bold', fontsize=10)\r\nplt.title('Lot Area V\/S Lot Frontage', fontweight='bold', fontsize=15)","43e8335a":"train4.sort_values(by=['LotArea'],ascending=False).head(10)","f5441dfa":"train5 = train4[~(train4['LotArea'] >= 54000)]\r\ntrain5 = train4[~(train4['LotFrontage'] >= 200)]  ","455d6896":"fig, ax=plt.subplots(figsize=(20,5))\r\nplt.scatter(x=train5.LotArea, y=train5.LotFrontage)\r\nplt.xlabel('Lot Area', fontweight='bold', fontsize=10)\r\nplt.ylabel('Lot Frontage', fontweight='bold', fontsize=10)\r\nplt.title('Lot Area V\/S Lot Frontage New', fontweight='bold', fontsize=15)","9db0afb1":"train5.LotFrontage.isnull().sum()","0311bbc2":"train6=train5.copy()\r\ntrain6['LotFrontage']=train6.groupby(['LotArea'])['LotFrontage'].apply(lambda x:x.fillna(x.mean()))","2b5d1487":"train6.LotFrontage.isnull().sum()","11bef534":"train6['LotFrontage']=train6.groupby(['Neighborhood'])['LotFrontage'].apply(lambda x:x.fillna(x.median()))\r\ntrain6.LotFrontage.isnull().sum()","13d6fe5f":"sns.set(style=\"darkgrid\")\r\nfig, (ax1, ax2,ax3) = plt.subplots(3, 1, figsize=(15, 7))\r\nsns.scatterplot(x=train4.LotArea, y=train4.LotFrontage,color=\"skyblue\", ax=ax1)\r\nax1.set_xticks([])\r\nsns.scatterplot(x=train5.LotArea, y=train5.LotFrontage, color=\"olive\", ax=ax2)\r\nax2.set_xticks([])\r\nax2.set_xlabel(' ')\r\nsns.scatterplot(x=train6.LotArea, y=train6.LotFrontage, color=\"gold\", ax=ax3)\r\nplt.title(\"Lot Area v\/s Lot Frontage\", fontsize=15, fontweight='bold')","ac21bcb5":"lot_area_40K = train6[(train6['LotArea'] >= 40000)]\r\nprint(lot_area_40K.isnull().sum().any())\r\nprint(lot_area_40K.shape)\r\nprint(train6.shape)","e0a06823":"train7 = train6[~(train6['LotArea'] >= 40000)]\r\ntrain7_blank = (train7.isnull().sum())\r\ntrain7_blank=train7_blank[train7_blank>0]\r\ntrain7_blank.sort_values(ascending=False)","aacc7e71":"train7['GarageType'] = train7['GarageType'].replace(np.nan, 'No Garage')\r\ntrain7.GarageType.value_counts().plot(kind='barh')","774dffe0":"Types_2 = train7[(train7['GarageType'] == '2Types')]\r\nTypes_2","659dbeb4":"train8 = train7[~(train7['GarageType'] == '2Types')]\r\ntrain8_blank = (train8.isnull().sum())\r\ntrain8_blank=train8_blank[train8_blank>0]\r\ntrain8_blank.sort_values(ascending=False)","d78b25ae":"train8.drop({'GarageFinish','GarageQual','GarageCond','GarageYrBlt'},axis=1, inplace=True)\r\nprint('Done')","6f362cf7":"train9 = train8.copy()\r\ntrain9.dropna(axis=0, inplace=True)\r\ntrain9.isnull().sum().any()","6f3fc357":"train9.shape","b03c734b":"train9.describe()","a73ed7f7":"train10 = train9.copy()\r\ntrain10['Age']=train10['YrSold']-train10['YearBuilt']\r\ntrain10.drop({'MiscVal','MoSold','YrSold'}, axis=1, inplace=True)","a26f5632":"object_cols = [col for col in train10.columns if train10[col].dtype == \"object\"]\r\ntrain10_OBJ = train10[object_cols]\r\ntrain10_OBJ.shape","a14a2b56":"object_nunique = list(map(lambda col: train10[col].nunique(), object_cols))\r\nd = dict(zip(object_cols, object_nunique))\r\n\r\n# Print number of unique entries by column, in ascending order\r\nsorted(d.items(), key=lambda x: x[1])","690f6431":"train11  = pd.get_dummies(train10, drop_first = True)\r\ntrain11.isnull().sum().any()","213b31e6":"X = train11.drop({'Id','SalePrice'},axis = 1 )\r\ny=train11.SalePrice","fcea54ae":"from sklearn.model_selection import train_test_split\r\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.35, random_state=21)","0f071d37":"from sklearn.metrics import mean_absolute_error\r\nfrom sklearn.model_selection import GridSearchCV\r\nfrom sklearn.model_selection import cross_val_score, KFold,cross_val_predict\r\nfrom sklearn.model_selection import RepeatedStratifiedKFold","758a4772":"from sklearn.ensemble import RandomForestRegressor\r\nrf_model = RandomForestRegressor(random_state=1)\r\nrf_model.fit(X_train,y_train)\r\nval_preds = rf_model.predict(X_valid)\r\nrf_val_mae = mean_absolute_error(val_preds, y_valid)\r\n\r\nprint(\"Validation MAE for Random Forest Model: {}\".format(rf_val_mae))","65d81d0b":"rf_model_2 = RandomForestRegressor(n_estimators = 200,criterion='mse',max_features='sqrt')\r\nrf_model_2_val_preds = cross_val_predict(rf_model_2,X,y, cv=7)\r\nrf_model_2_val_mae = mean_absolute_error(rf_model_2_val_preds, y)\r\nprint(\"Validation MAE for Random Forest Model: {}\".format(rf_model_2_val_mae))","e05c67e6":"import xgboost as xgb\r\nxgbr = xgb.XGBRegressor(verbosity=0,n_estimators=200) ","e2252da1":"xgbr.fit(X_train, y_train)","5a39d40f":"ypred = xgbr.predict(X_valid)\r\nmae = mean_absolute_error(y_valid, ypred)\r\nprint(\"MAE: %.2f\" % mae)","433dccff":"x_ax = range(len(y_valid))\r\nplt.plot(x_ax, y_valid, label=\"original\")\r\nplt.plot(x_ax, ypred, label=\"predicted\")\r\nplt.title(\"Boston test and predicted data\")\r\nplt.legend()\r\nplt.show()","55028526":"cols = [col for col in train10.columns ]\r\nunwanted_col = {'SalePrice','Age'}\r\nfilter_cols = [ele for ele in cols if ele not in unwanted_col]","ccbac54d":"test=test[filter_cols]\r\ntest.head(2)","b9618871":"#object_cols = [col for col in train10.columns if train10[col].dtype == \"object\"]\r\n\r\ngood_label_cols = [col for col in object_cols if \r\n                   set(train10[col]).issubset(set(test[col]))]\r\n        \r\n# Problematic columns that will be dropped from the dataset\r\nbad_label_cols = list(set(object_cols)-set(good_label_cols))\r\n        \r\nprint('Categorical columns that ordinal encoded:', good_label_cols)\r\nprint('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)","3a7ce9d5":"test = test.replace(np.nan, 0)","a0133f8d":"object_nunique_train = list(map(lambda col: train10[col].nunique(), good_label_cols))\r\ntrain_d = dict(zip(good_label_cols, object_nunique_train))\r\ntrain_d2 = pd.DataFrame.from_dict(train_d,orient='index')\r\ntrain_d2.rename(columns={0: \"train\"}, inplace=True)\r\ntrain_d2.head()","ac59d6e0":"object_nunique_test = list(map(lambda col: test[col].nunique(), good_label_cols))\r\ntest_d = dict(zip(good_label_cols, object_nunique_test))\r\ntest_d2 = pd.DataFrame.from_dict(test_d,orient='index')\r\ntest_d2.rename(columns={0: \"test\"}, inplace=True)\r\ntest_d2.head()","a1f98d28":"cat_col = pd.concat([train_d2, test_d2],axis=1)\r\ncat_col['diff']=cat_col['train']-cat_col['test']\r\nbad_cat_col = cat_col.loc[cat_col['diff'] != 0]\r\nbad_cat_col = bad_cat_col.index.tolist()\r\nbad_cat_col","4a19c5c6":"final_cat_col = [x for x in good_label_cols if x not in bad_cat_col]","2941d31a":"final_remove = bad_label_cols + list(set(bad_cat_col) - set(bad_label_cols))","e90c66c9":"all_cols = [col for col in train10.columns]\r\n\r\nunwanted_col = {'Id','SalePrice','Age'}\r\nfilter_cols_final = [ele for ele in all_cols if ele not in unwanted_col]\r\nfinal_col = [ele for ele in filter_cols_final if ele not in final_remove]","b57e2460":"train13 = train10[final_col]\r\ntrain13.columns","95ebec67":"test3 = test[final_col]","2341ea95":"from sklearn.preprocessing import OneHotEncoder\r\nenc = OneHotEncoder(handle_unknown = 'ignore')\r\nenc.fit(train13)\r\ntrain13 = enc.transform(train13)\r\ntest3 = enc.transform(test3)","7fc43b54":"X_final = train13\r\ny_final = train11.SalePrice","0e744cd7":"X_train_f, X_valid_f, y_train_f, y_valid_f = train_test_split(X_final, y_final, test_size=0.35, random_state=21)","7d5d58dc":"rf_model_final = RandomForestRegressor(n_estimators = 200,criterion='mse',max_features='sqrt')\r\nrf_model_final = rf_model_final.fit(X_train_f,y_train_f)\r\nval_preds_final = rf_model_final.predict(X_valid_f)\r\nrf_val_mae_final = mean_absolute_error(val_preds_final, y_valid_f)\r\n\r\nprint(\"Validation MAE for Random Forest Model: {}\".format(rf_val_mae_final))","9b0a81c7":"xgb1 = xgb.XGBRegressor()\r\nparameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\r\n              'objective':['reg:linear'],\r\n              'learning_rate': [.03, 0.05, .07],\r\n              'max_depth': [5, 6, 7],\r\n              'min_child_weight': [4],\r\n              'silent': [1],\r\n              'subsample': [0.7],\r\n              'colsample_bytree': [0.7],\r\n              'n_estimators': range(0,500,100)}\r\n\r\nxgb_grid = GridSearchCV(xgb1,\r\n                        parameters,\r\n                        cv = 7,\r\n                        n_jobs = 5,\r\n                        verbose=True)\r\n","3653cbd7":"xgb_grid.fit(X_final,y_final)s_)","91a82557":"model =  xgb_grid.best_estimator_\r\nfinal_predict = xgb_grid.best_estimator_.predict(test3)\r\nsubmission = pd.DataFrame({\r\n        \"Id\": test[\"Id\"],\r\n        \"SalePrice\": final_predict\r\n    })\r\n\r\nsubmission.to_csv('submission.csv', index=False)","d98860d7":"submission.shape","5268909d":"# 1. Set up the environment.","0e588edb":"## 4.2. XGB Regressor.","91545e9a":"## 3.2. Data Filtering.","c6079695":"## 4.3. Categorical column encoding.","b7e89354":"# 3. Data Cleaning.","5e45bff9":"## 4.1. Random Forestt Regressor.","f6e08029":"## 4.4. XGB Regressor with Gridsearch CV.","a8db1f77":"# 5. Final Predection & Submission.","659ee4ea":"# 4. Model Designing.","024ee890":"## 3.1. Handeling missing values.","564e320c":"# 2. Reading the datasets."}}