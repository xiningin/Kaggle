{"cell_type":{"0e67a5e2":"code","f3362b3c":"code","b529cdb4":"code","0b74d7e4":"code","f2008afa":"code","69bb8477":"code","17ddd118":"code","9720a6b4":"code","7d706bf2":"code","5d446dd8":"code","ce56d798":"code","0ec6cb0a":"code","350df37a":"code","fae85377":"code","1d8cdaaf":"code","b536a7e2":"code","06320487":"code","c01e38f3":"code","a3f00d5d":"code","9fe0aae3":"code","50962c9c":"code","0983b889":"code","7785de12":"code","6a2373bd":"code","23f4970d":"code","c71f32ae":"code","09d71d60":"code","f302199a":"code","ccc62779":"code","8f291112":"markdown","cfe7c282":"markdown","9fe03c8b":"markdown","8ee1744f":"markdown","c0fb2697":"markdown","b4fce7fd":"markdown","a8e0764f":"markdown","1590cd93":"markdown","043a0bb2":"markdown","34b03f44":"markdown","972e8068":"markdown","b49c5aed":"markdown","f206e255":"markdown","50779abc":"markdown","31f04a60":"markdown","f042b31c":"markdown","6ea36600":"markdown","87249dc1":"markdown","a5d0d5df":"markdown"},"source":{"0e67a5e2":"import gc\nimport glob\nimport os\nimport time\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\ngc.enable()\n\npd.options.display.max_rows = 96\npd.options.display.max_columns = 128","f3362b3c":"input_dir = '..\/input\/'\ninput_files = sorted(glob.glob(input_dir + '*'))\n\ninput_files","b529cdb4":"%%time\n\ntrain = pd.read_csv('..\/input\/train.csv', parse_dates=['first_active_month'])\ntest = pd.read_csv('..\/input\/test.csv', parse_dates=['first_active_month'])\nsample_submission = pd.read_csv('..\/input\/sample_submission.csv')\n\n\nmerchant = pd.read_csv('..\/input\/merchants.csv')\nnew_merchant = pd.read_csv('..\/input\/new_merchant_transactions.csv')\n# historical = pd.read_csv('..\/input\/historical_transactions.csv')","0b74d7e4":"train.head()","f2008afa":"test.head()","69bb8477":"merchant.head()","17ddd118":"new_merchant.head()","9720a6b4":"print('Train NaN:\\n\\n{}\\n'.format(np.sum(pd.isnull(train))))\nprint('Test NaN:\\n\\n{}\\n'.format(np.sum(pd.isnull(test))))\nprint('Merchant NaN:\\n\\n{}\\n'.format(np.sum(pd.isnull(merchant))))\nprint('New Merchant NaN:\\n\\n{}\\n'.format(np.sum(pd.isnull(new_merchant))))","7d706bf2":"new_merchant = new_merchant.dropna(subset=['merchant_id'])","5d446dd8":"merchant_id_num = len(merchant['merchant_id'].unique())\nnew_merchant_id_num = len(new_merchant['merchant_id'].unique())\nmerchant_id_intersect = len(np.intersect1d(new_merchant.merchant_id, merchant.merchant_id))\n\nprint('Merchant IDs: {}'.format(merchant_id_num))\nprint('New merchant IDs: {}'.format(new_merchant_id_num))\nprint('Merchants ID intersection: {}'.format(merchant_id_intersect))","ce56d798":"train_card_id_num = len(train['card_id'].unique())\ntest_card_id_num = len(test['card_id'].unique())\ntrain_card_id_intersect = len(np.intersect1d(new_merchant.card_id, train.card_id))\ntest_card_id_intersect = len(np.intersect1d(new_merchant.card_id, test.card_id))\n\nprint('train card IDs: {}'.format(train_card_id_num))\nprint('test card IDs: {}'.format(test_card_id_num))\nprint('train card IDs intersection: {}'.format(train_card_id_intersect))\nprint('test card IDs intersection: {}'.format(test_card_id_intersect))","0ec6cb0a":"train_id_frac = train_card_id_intersect \/ train_card_id_num\ntest_id_frac = test_card_id_intersect \/ test_card_id_num\n\nprint('train frac: {:.3f}, test frac: {:.3f}'.format(train_id_frac, test_id_frac))","350df37a":"# Get columns of each type\ndef get_column_types(df):\n\n    categorical_columns = [\n        col for col in df.columns if df[col].dtype == 'object']\n    categorical_columns_int = [\n        col for col in df.columns if df[col].dtype == 'int']\n    numerical_columns = [\n        col for col in df.columns if df[col].dtype == 'float']\n\n    categorical_columns = [\n        x for x in categorical_columns if 'id' not in x]\n    categorical_columns_int = [\n        x for x in categorical_columns_int if 'id' not in x]\n\n    return categorical_columns, categorical_columns_int, numerical_columns\n\n\n# Rename columns after grouping for easy merge and access\ndef rename_columns(df):\n    \n    df.columns = pd.Index(['{}{}'.format(\n        c[0], c[1].upper()) for c in df.columns.tolist()])\n    \n    return df","fae85377":"merchant_cat_feats, merchant_catint_feats, merchant_num_feats = get_column_types(merchant)\n\nprint('Categorical features to encode: {}'.format(merchant_cat_feats))\nprint('\\nCategorical int features: {}'.format(merchant_catint_feats))\nprint('\\nNumerical features: {}'.format(merchant_num_feats))","1d8cdaaf":"new_merchant_cat_feats, new_merchant_catint_feats, new_merchant_num_feats = get_column_types(new_merchant)\n\nprint('Categorical features to encode: {}'.format(new_merchant_cat_feats))\nprint('\\nCategorical int features: {}'.format(new_merchant_catint_feats))\nprint('\\nNumerical features: {}'.format(new_merchant_num_feats))","b536a7e2":"# Let's create set of aggregates, which will be used for features grouping.\n# One for categorical and one for numerical features.\n\naggs_num_basic = ['mean', 'min', 'max', 'sum']\naggs_cat_basic = ['mean', 'sum', 'count']","06320487":"# Encode string features to numbers:\n# If encoding train and test separately, remember to keep the features mapping between the two!\n\nfor c in new_merchant_cat_feats:\n    print('Encoding: {}'.format(c))\n    new_merchant[c] = pd.factorize(new_merchant[c])[0]\n    \nfor c in merchant_cat_feats:\n    print('Encoding: {}'.format(c))\n    merchant[c] = pd.factorize(merchant[c])[0]\n    \nnew_merchant","c01e38f3":"merchant_card_id_cat = merchant.groupby(['merchant_id'])[merchant_cat_feats].agg(aggs_cat_basic)\nmerchant_card_id_num = merchant.groupby(['merchant_id'])[merchant_num_feats].agg(aggs_num_basic)\n\nmerchant_card_id_cat = rename_columns(merchant_card_id_cat)\nmerchant_card_id_num = rename_columns(merchant_card_id_num)","a3f00d5d":"merchant_card_id_cat.head()","9fe0aae3":"new_merchant_ = new_merchant.set_index('merchant_id').join(merchant_card_id_cat, how='left')\nnew_merchant_ = new_merchant_.join(merchant_card_id_num, how='left')","50962c9c":"_, new_merchant_catint_feats2, new_merchant_num_feats2 = get_column_types(new_merchant_)\n\nprint('\\nCategorical int features: {}'.format(new_merchant_catint_feats2))\nprint('\\nNumerical features: {}'.format(new_merchant_num_feats2))","0983b889":"new_merchant_card_id_cat = new_merchant_.groupby(['card_id'])[new_merchant_catint_feats2].agg(aggs_cat_basic)\nnew_merchant_card_id_num = new_merchant_.groupby(['card_id'])[new_merchant_num_feats2].agg(aggs_num_basic)\n\nnew_merchant_card_id_cat = rename_columns(new_merchant_card_id_cat)\nnew_merchant_card_id_num = rename_columns(new_merchant_card_id_num)","7785de12":"train_ = train.set_index('card_id').join(new_merchant_card_id_cat, how='left')\ntrain_ = train_.join(new_merchant_card_id_num, how='left')\n\ntest_ = test.set_index('card_id').join(new_merchant_card_id_cat, how='left')\ntest_ = test_.join(new_merchant_card_id_num, how='left')\n\n\ndel train, test\ngc.collect()","6a2373bd":"y = train_.target\nX = train_.drop(['target'], axis=1)\nX_test = test_.copy()\n\n\nfeatures_to_remove = ['first_active_month']\n\nX = X.drop(features_to_remove, axis=1)\nX_test = X_test.drop(features_to_remove, axis=1)\n\n\n# Assert that set of features is the same for both train and test DFs:\nassert np.all(X.columns == X_test.columns)\n\n\ndel train_, test_\ngc.collect()","23f4970d":"np.sum(pd.isnull(X)) \/ X.shape[0]","c71f32ae":"np.sum(pd.isnull(X_test)) \/ X_test.shape[0]","09d71d60":"# KFold splits\nkf = KFold(n_splits=5, shuffle=True, random_state=1337)\n# Column names:\ntrain_cols = X.columns.tolist()\n\n\n# LGB model parameters:\nparams = {'learning_rate': 0.03,\n          'boosting': 'gbdt', \n          'objective': 'regression', \n          'metric': 'rmse',\n          'num_leaves': 64,\n          'min_data_in_leaf': 6,\n          'max_bin': 255,\n          'bagging_fraction': 0.7,\n          'lambda_l2': 1e-4,\n          'max_depth': 12,\n          'seed': 1337,\n          'nthreads': 6}\n\n\n# Placeholders for out-of-fold predictions\noof_val = np.zeros((X.shape[0]))\noof_test = np.zeros((5, X_test.shape[0]))\n\n\ni = 0 # Placeholder for fold indexing\nfor tr, val in kf.split(X, y):\n    \n    print('Fold: {}'.format(i + 1))\n    \n    # Split into training and validation part\n    X_tr, y_tr = X.iloc[tr, :], y.iloc[tr]\n    X_val, y_val = X.iloc[val, :], y.iloc[val]\n    \n    # Create Dataset objects for lgb model\n    dtrain = lgb.Dataset(X_tr.values, y_tr.values, feature_name=train_cols)\n    dvalid = lgb.Dataset(X_val.values, y_val.values,\n                         feature_name=train_cols, reference=dtrain)\n    \n    # Train model\n    lgb_model = lgb.train(params, dtrain, \n                      num_boost_round=1000, \n                      valid_sets=(dvalid,), \n                      valid_names=('valid',), \n                      verbose_eval=25, \n                      early_stopping_rounds=20)\n    \n    # Save predictions for each fold\n    oof_val[val] = lgb_model.predict(X_val)\n    oof_test[i, :] = lgb_model.predict(X_test)\n    \n    i += 1","f302199a":"# Check RMSE for training set:\nvalid_rmse = mean_squared_error(y, oof_val) ** .5\n\nprint('Valid RMSE: {:.4f}'.format(valid_rmse))","ccc62779":"# Average test predcitions across folds:\ntest_preds = oof_test.mean(axis=0)\n\n# Create submission:\nsample_submission['target'] = test_preds\nsample_submission.to_csv(\"submission_trial.csv\", index=False)\nsample_submission.head()","8f291112":"### Quick look at other tables - _new merchant_:\n\n\n- Amount of features in this table is somewhere between train and merchant DFs\n- Good information is that it contains both `merchant_id` and `card_id`, to this may be a mean to connect `train`, `test` and `merchant` DFs","cfe7c282":"### Quick look at train and test data:\n\n- `card_id` is the ID of card, some of information from other DFs can be merged by those\n- only 3 features (anonymized) + information about month, according to the description: 'YYYY-MM', month of first purchase\n- `train.csv` contains target, which is the feature we will try to predict. This one is defined as: Loyalty numerical score calculated 2 months after historical and evaluation period","9fe03c8b":"After checking the intersection, we know that all merchants from new_merchant DF are covered, so this won't be an issue when merging with main train\/test DF.","8ee1744f":"### Feature engineering:\n\n\n### 1. Feature encoding\n\nIn order to know, which features must be encoded (to numerical values), let's create a reusable function to get different types of columns based on their data type. This may not work in 100% but will cover most of the cases.\nManual check is always worth a few minutes.","c0fb2697":"### Available inputs: \n\n\nFor this competition, dictionary containing information about dataset is available.\nThat's helpful for feature engineering, as it provides a possible direction of engineering for each feature.\nOne thing to keep in mind is that this set was created _artificially_:\n**_All data is simulated and fictitious, and is not real customer data_**\n\nKernel environment has it's memory and speed constraints, therefore `historical_transactions.csv` file will not be used, as it's the biggest one.\nWe will base our workflow on remaining set of files.","b4fce7fd":"### Prepare for training:","a8e0764f":"### join merchant features with new_merchant:","1590cd93":"### card_id intersection:","043a0bb2":"Coverage of train and test card IDs in new_merchant is almost the same, 89%.","34b03f44":"### Group new_merchant data by card_id:","972e8068":"### NaN structure:\n\n- no NaN in train and test, that's good\n- some NaNs in both merchants DF, especially `category_2` feature.","b49c5aed":"### KFold LGB model training:","f206e255":"### check NaN structure of new features:","50779abc":"### Quick look at other tables - _merchant_:\n\n\n- This table gives a richer set of features for possible exploration and feature engineering\n- Some of those contain NaN values (worth exploring!)\n- Some features contain already averaged information, for example _avg_sales_lag3 - Monthly average of revenue in last 3 months divided by revenue in last active month_\n- There is no card_id to merge this DF to train\/test set","31f04a60":"### Prepare submission:","f042b31c":"### Let's check how many of those occur in both and how many do not:\n\nWe must start with filling missing values in `merchant_id` with some value without meaning, like `NoID`.","6ea36600":"### Data loading:","87249dc1":"### Group merchant data by merchant_id:","a5d0d5df":"### join new_merchant with train\/test by card_id:"}}