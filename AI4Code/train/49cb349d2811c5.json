{"cell_type":{"25d5983c":"code","cbbb0171":"code","f8d35e9e":"code","d76ba1d0":"code","d7bc5a31":"code","b2cb6bc8":"code","2f077871":"code","bc29dc56":"markdown","ca03dd05":"markdown","4ca21178":"markdown"},"source":{"25d5983c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.datasets import make_classification\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split\n\ndataSet = pd.read_csv(\"\/kaggle\/input\/lower-back-pain-symptoms-dataset\/Dataset_spine.csv\")\ndataSet.head()","cbbb0171":"dataSet.pop('Unnamed: 13')\ndataSet.head()","f8d35e9e":"y = dataSet['Class_att']\nx = dataSet.drop(['Class_att'], axis=1)\n#x.head()","d76ba1d0":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.1, random_state=13)\nclassifier = MLPClassifier(max_iter=500, alpha=0.0001, verbose=True)\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_test)","d7bc5a31":"accuracy_score(y_test, y_pred)","b2cb6bc8":"report = classification_report(y_test, y_pred)\nprint(report)","2f077871":"y.value_counts()","bc29dc56":"Agora vamos separar o dataset em um dataset de treino e outro para teste numa propor\u00e7\u00e3o de 90% e 10% do dataset original respectivamente.","ca03dd05":"Como podemos ver acima, o dataset tem uma coluna \"extra\" que n\u00e3o agrega valor algum ao nosso objetivo neste projeto. Ent\u00e3o damos pop nela:","4ca21178":"Podemos ver que a precis\u00e3o da classifica\u00e7\u00e3o de casos normais \u00e9 menor. Isso possivelmente se d\u00e1 por conta do fato de existirem mais casos anormais na amostra, como mostrado abaixo. Testaremos esta hip\u00f3tese mais a frente."}}