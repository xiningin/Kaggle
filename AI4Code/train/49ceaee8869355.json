{"cell_type":{"fa99e282":"code","7049d171":"code","10ffba37":"code","266220f7":"code","02693d01":"code","c21a1e51":"code","06680ec2":"code","2cb4567c":"code","5aeb9dec":"code","8683b411":"code","11780dab":"code","bc37a513":"code","5036b04b":"code","a47921c4":"code","2cb48236":"code","ff16534f":"code","d97f788f":"code","aefc0c2d":"code","ddbc138d":"markdown","c3728106":"markdown","282c4d71":"markdown","8f358748":"markdown","be5003ce":"markdown","be65074c":"markdown","4bae31a0":"markdown","ee24e598":"markdown","8485eb09":"markdown","4566873f":"markdown","e29f5759":"markdown","e4c536ac":"markdown","e506269b":"markdown","04937204":"markdown"},"source":{"fa99e282":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","7049d171":"train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","10ffba37":"trainimg = train.to_numpy()\ntrainimg.shape","266220f7":"img = []\nfor i in range(8):\n  r = np.random.randint(0, len(trainimg))\n  img.append(trainimg[r , 1:].reshape((28,28)))\n  print(f'Digit: {trainimg[r ,0]}', r)\n\nf, ax = plt.subplots(2,4)\nfor i in range(2):\n  for j in range(4):\n    ax[i][j].imshow(img[4*i+j], cmap='gray')\n","02693d01":"test_img = test.to_numpy().reshape(28000,28,28,1)\ntest_img.shape","c21a1e51":"import tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\ntrain_x, train_y = train.to_numpy()[:,1:].reshape(42000,28,28,1), train.to_numpy()[:,0]\n\ntrainx, valx, trainy, valy = train_test_split(train_x, train_y, test_size=0.20)\n","06680ec2":"model = tf.keras.models.Sequential([\n        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n        tf.keras.layers.MaxPooling2D(2, 2),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dense(10, activation='softmax')\n    ])\n","2cb4567c":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nepoch = 10\nmodel_his = model.fit(\n        trainx, trainy, epochs=epoch\n    )","5aeb9dec":"x = np.arange(1, epoch + 1)\ntrain_acc = model_his.history['accuracy']\ntrain_loss = model_his.history['loss']","8683b411":"plt.plot(x , train_acc)\nplt.show()\nplt.plot(x , train_loss)\nplt.show()","11780dab":"prediction = model.predict(valx)\nfor i in range(len(prediction)):\n  n = np.argmax(prediction[i,:])\n  prediction[i,n] = 1\n  prediction[i,:] = prediction[i,:].round()","bc37a513":"val_true = np.zeros((len(valy),10))\n\nfor i,j in enumerate(valy):\n  val_true[i,j] = 1","5036b04b":"from sklearn.metrics import accuracy_score\n\nmy_accuracy = accuracy_score(val_true.astype('int32'), prediction.astype('int32'))\nprint('Accuracy: ', my_accuracy)\n","a47921c4":"prediction_test = model.predict(test_img)\nprediction_test.shape","2cb48236":"pred = np.zeros((28000,1))\n\nfor i in range(28000):\n  pred[i] = np.argmax(prediction_test[i,:])\n\npred.shape","ff16534f":"ind = pd.DataFrame(np.arange(1,28001), columns=['ImageId'])\n\npred_sub = pd.DataFrame(pred.astype('int32'), columns=['Label'])\nsubmission = [ind , pred_sub]\nsub = pd.concat(submission, axis=1)","d97f788f":"compression_opts = dict(method='zip',\n                        archive_name='submission.csv')  \n\nsub.to_csv('submission.zip', index=False, compression=compression_opts)","aefc0c2d":"pd.read_csv('submission.zip')","ddbc138d":"The first step is to import all of the libraries needed for the project. ","c3728106":"Next, we define the optimizer, the loss function and the metrics to review. Here we also train the model using the numpy array previously defined with a fixed number of epochs.","282c4d71":"## Data processing","8f358748":"# Handwritten digits recognizer with Convolutional Neaural Network (CNN)\n\nThis notebook presents a simple, but effective CNN applied to the MNIST handwritten digits dataset. The model to be used was built with TensorFlow.","be5003ce":"## Convolutional Neural Network\nHere is going to be used a CNN to classify the images of the MNIST handwritten digits database. To train the model we divide the the train set into the set of images and their respective labels. we also divide that set into two sets so we can use one of them to train the model and the other one to use as the validation set. ","be65074c":"Finally we compute the accuracy for the validation set.","4bae31a0":"Now we build the CNN. We are going to use one convolutional layer, a pooling layer, a hidden layer and an output layer. ","ee24e598":"We read the two .csv  given for the project: the train set and the test set. The train set has one extra (the first column) column with the label of its respective image, so we can properly train the model.","8485eb09":"Make the prediction for the instances from the test set. The next two cells create (or modify) the arrays so it can be used for the accuracy.","4566873f":"As we can see, the images have 28x28 flatten pixels (one row with the 784 pixels), therefore we have to reshape the array so we can use it. In the next cell we show 8 random images from the dataset.","e29f5759":"The following cell are used for the prediction of the test set (for the kaggle score).","e4c536ac":"To use the data we have to transform the information given by the csv files to numpy arrays.","e506269b":"we do the same reshape with the test set.","04937204":"We check the accuracy and loss behaviour through the training. "}}