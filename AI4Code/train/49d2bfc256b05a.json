{"cell_type":{"0fa0a895":"code","9759d9c7":"code","4fd0b471":"code","68b7b38f":"code","44331a46":"code","84597f3d":"code","6f543269":"code","34d84106":"code","e510cb07":"code","4191f17c":"code","bb00056a":"code","db474e0c":"code","89a95c84":"code","ae06862b":"code","6fa96fb6":"code","4a9fc84a":"code","5f338522":"code","bc1d0177":"code","5c31cbcc":"code","b5ba7d28":"code","16ce28f7":"code","3ed4e30f":"code","4d1ecdde":"code","9029cc21":"code","e2f266ca":"code","bec55922":"code","a857e972":"code","acb15951":"code","464c56cf":"code","75879b69":"code","4eea72fa":"code","05347332":"code","18f78eb6":"code","be300e5d":"code","fd7bdd46":"code","0bc7e8a2":"code","57923e08":"code","7fda181e":"code","8b37b9b3":"code","01a36384":"code","b40c369a":"code","5e432b4e":"code","e46b9cf3":"code","17475c9e":"code","4ac2e7bd":"code","4d5c98a6":"code","541aecd2":"code","762a6d2c":"code","7b8fada7":"code","726975a6":"code","b755aea6":"code","9cf46ca9":"markdown","da90969a":"markdown","4c477564":"markdown","1ec02abc":"markdown","e3ce2a65":"markdown","e08496a6":"markdown","347b1c60":"markdown","f8d1d414":"markdown","9ff22113":"markdown","d6b5141a":"markdown","d08f4e3a":"markdown","aaf8686f":"markdown","67df1467":"markdown","a1b76450":"markdown","fada05cf":"markdown","5519a32d":"markdown","851bfbdb":"markdown","d2beebc4":"markdown","42195617":"markdown","8071933f":"markdown","e7487148":"markdown","c6187f4f":"markdown","3088bffb":"markdown","f8c03334":"markdown"},"source":{"0fa0a895":"# For Analysis\nimport numpy as np\nimport pandas as pd\n\n# For Visualizations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# For Calculations\nfrom math import floor\n\n#For Modeling\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression , Lasso, Ridge\nfrom sklearn.ensemble import RandomForestRegressor\n\n# For Validation\nfrom sklearn.metrics import mean_squared_error, accuracy_score\n\n# For Storing Models\nimport pickle\n%matplotlib inline\n\n# For Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","9759d9c7":"#Reading data\nlistings = pd.read_csv('\/kaggle\/input\/seattle-listings\/listings.csv')\n#calendar = pd.read_csv('\/kaggle\/input\/seattle\/calendar.csv')\n#reviews = pd.read_csv('\/kaggle\/input\/seattle\/reviews.csv')\nneighscore = pd.read_csv('\/kaggle\/input\/seattle-neighborhood-scores\/Seattle_Scores.csv')","4fd0b471":"#get a small snapshot of the data\nlistings.head()","68b7b38f":"#Check for field information\nlistings.info()","44331a46":"#Check the statistical distribution for Numerical columns\nlistings.describe()","84597f3d":"#Check the distribution of Categorical and Text columns\nlistings.describe(include=[\"O\"])","6f543269":"#Listing columns\nlistings.columns","34d84106":"#Check the levels of some important listing related features\ncat_level=['property_type','room_type','bed_type','cancellation_policy']\n[listings[c].value_counts() for c in cat_level]","e510cb07":"#Function for showing columns with missing values\ndef show_missing_values(df):\n    missing_vals = df.isnull().sum().sort_values(ascending = False)\n    \n    return missing_vals.iloc[missing_vals.nonzero()[0]]","4191f17c":"show_missing_values(listings)","bb00056a":"#Function for handling missing values\ndef handle_missing_remove(df):\n    temp_df=df.copy()\n    #Fill 0 in place of missing records for number of bedrooms,bathrooms,beds\n    temp_df.beds.fillna(0,inplace=True)\n    temp_df.bedrooms.fillna(0,inplace=True)\n    temp_df.bathrooms.fillna(0,inplace=True)\n    \n    #Remove columns license and squarefeet which have more than 95% missing values\n    temp_df.drop(['license','square_feet'],axis=1,inplace=True)\n     \n    return temp_df","db474e0c":"listings=handle_missing_remove(listings)\nshow_missing_values(listings)","89a95c84":"def preprocess(df):\n    \n    temp_df = df.copy()\n    temp_df = temp_df.replace(\n            {\n            'host_has_profile_pic': {'t': True, 'f': False},\n            'host_identity_verified': {'t': True, 'f': False},\n            'instant_bookable': {'t': True, 'f': False},\n            }\n    )\n        \n    ## Recode property_type\n    def recode_prop(value):\n        if value not in ['House', 'Apartment','Condominium','Townhouse','Loft']:\n            return 'other_prop_type'\n        return value\n\n    temp_df['property_type'] = temp_df['property_type'].apply(recode_prop)\n\n    ## Recode bed_type\n    def recode_bed(value):\n        if value not in ['Real Bed']:\n            return 'other_bed_type'\n        return value\n\n    temp_df['bed_type'] = temp_df['bed_type'].apply(recode_bed)\n        \n    #Calculate the bedroom and bathroom share per person. Higher the share, more the comfort.\n    temp_df = temp_df.assign(\n        bedroom_share = temp_df.bedrooms\/temp_df.accommodates,\n        bathroom_share = temp_df.bathrooms\/temp_df.accommodates,\n        \n    )\n    \n    df=temp_df\n    print(\"Pre-processing completed...\")\n    return df","ae06862b":"#Preprocess the listings data\nlistings=preprocess(listings)","6fa96fb6":"#Create dummy columns by one-hot encoding\ndef create_dummies(df, columns = ['room_type', 'property_type', 'bed_type', 'cancellation_policy']):\n    for column in columns:\n        dummies = pd.get_dummies(df[column], prefix = column)\n        df = pd.concat([df,dummies], axis = 1)\n    return df","4a9fc84a":"# Create the required dummy columns\nlistings = create_dummies(listings)","5f338522":"#Blank missing values in Amenities column\nlistings.loc[listings['amenities'] == '{}','amenities'] = \"\"","bc1d0177":"#Remove the symbols and split the amenities with | as separator\nlistings['amenities'] = listings['amenities'].map(\n    lambda amns: \"|\".join([amn.replace(\"}\", \"\").replace(\"{\", \"\").replace('\"', \"\")\\\n                           for amn in amns.split(\",\")]))","5c31cbcc":"listings['amenities'].head()","b5ba7d28":"#Take the unique list of amenities across all listings\namenities = np.unique(np.concatenate(listings['amenities'].map(lambda amns: amns.split(\"|\")).values))\namenities","16ce28f7":"#Map the presence or absence of amenities for each listing\namenities_matrix = np.array([listings['amenities'].map(lambda amns: amn in amns).values for amn in amenities])\namenities_matrix","3ed4e30f":"#Make the amenities dataframe with boolean values\namen=pd.DataFrame(data=amenities_matrix.T, columns=amenities)\namen.head()","4d1ecdde":"#Concat the listing id to amen dataframe\nlistings_amenities = pd.concat([amen,listings['id']], axis=1)\nlistings_amenities.head()","9029cc21":"#Remove first column from listings_amenities whose name is \"\"\nlistings_amenities=listings_amenities.drop(\"\",axis=1)\nlistings_amenities.head()","e2f266ca":"listings_amenities.columns","bec55922":"amenity_recode={\n                'Air Conditioning':'Weather Control',\n                'Indoor Fireplace':'Weather Control',\n                'Heating':'Weather Control',\n        \n                'Carbon Monoxide Detector':'Safety Features',\n                'Fire Extinguisher':'Safety Features',\n                'First Aid Kit':'Safety Features',\n                'Smoke Detector':'Safety Features',\n                \n                'Buzzer\/Wireless Intercom':'Security Features',\n                'Doorman':'Security Features',\n                'Safety Card':'Security Features',\n                'Lock on Bedroom Door':'Security Features',\n                \n                'Cat(s)':'Pet Friendly',\n                'Dog(s)':'Pet Friendly',\n                'Pets Allowed':'Pet Friendly',\n                'Pets live on this property':'Pet Friendly',\n                'Other pet(s)':'Pet Friendly',\n                \n                'Elevator in Building':'Access Friendly',\n                'Wheelchair Accessible':'Access Friendly',\n                \n                'Essentials':'Essentials',\n                'Hair Dryer':'Essentials',\n                'Hangers':'Essentials',\n                'Iron':'Essentials',\n                'Shampoo':'Essentials',             \n                \n                'Cable TV':'TV',\n                'TV':'TV',\n                \n                'Internet':'Internet',\n                'Wireless Internet':'Internet',\n                'Laptop Friendly Workspace':'Internet',\n                \n                'Dryer':'Laundry Facility',\n                'Washer':'Laundry Facility',\n                'Washer \/ Dryer':'Laundry Facility',\n    \n                #Leaving amenities as such which cannot be grouped\n                #'Kitchen',\n                #'Family\/Kid Friendly', \n                #'Free Parking on Premises',\n                #'Breakfast',\n                #'24-Hour Check-in',\n                #'Hot Tub',\n                #'Pool',\n                #'Gym',\n                #'Smoking Allowed',\n                #'Suitable for Events'\n}","a857e972":"#Melt the amenities dataframe and recode from the dictionary\nlistings_amenities_melt = listings_amenities.melt(id_vars=['id'], var_name='amenity')\n\n#Recoding and putting in new column called amenity_modified\nlistings_amenities_melt = listings_amenities_melt.assign(\n    amenity_modified = listings_amenities_melt.amenity.replace(amenity_recode)\n)\n\nlistings_amenities_melt.head()","acb15951":"#Pivot the melted dataframe before merging with original dataframe\nlistings_amenities_pivot = listings_amenities_melt.pivot_table(\n    index='id',\n    columns='amenity_modified',\n    values='value', \n    aggfunc='max'\n)\n\nlistings_amenities_pivot.head()","464c56cf":"#Join the amenities dataframe back to the original listings dataframe\nlistings_joined=listings.join(listings_amenities_pivot,on=\"id\",how=\"inner\")\nlistings_joined.head()","75879b69":"# Generating viridis heatmap to check the correlation among the amenities\nlistings_selected_amenities=listings_joined[['24-Hour Check-in', 'Access Friendly', 'Breakfast', 'Essentials',\n       'Family\/Kid Friendly', 'Free Parking on Premises', 'Gym', 'Hot Tub',\n       'Internet', 'Kitchen', 'Laundry Facility', 'Pet Friendly', 'Pool',\n       'Safety Features', 'Security Features', 'Smoking Allowed',\n       'Suitable for Events', 'TV', 'Weather Control']]\nfig = plt.figure(figsize= (12,12))\nsns.heatmap(listings_selected_amenities.corr(), annot=False, vmax=1, cmap='viridis', square=False)","4eea72fa":"#listings_am_ns=listings_joined.join(neigh_score,on=\"id\",how=\"left\")\nlistings_am_ns=pd.merge(neighscore, listings_joined, how='right', left_on=['WSName'], right_on=['neighbourhood_cleansed'])","05347332":"listings_am_ns.dtypes","18f78eb6":"#Replace $ and , with \"\" in the price column and convert the price column to float\nlistings_am_ns.price=listings_am_ns.price.apply(lambda x: x.replace('$',''))\nlistings_am_ns.price=listings_am_ns.price.apply(lambda x: x.replace(',',''))\nlistings_am_ns.price=listings_am_ns.price.astype(float)","be300e5d":"#Distribution of target\nsns.distplot(listings_am_ns.price)","fd7bdd46":"listings_am_ns.shape","0bc7e8a2":"list(listings_am_ns)","57923e08":"## Generating the heatmap for visualization - using Seaborn\nlistings_selected_am_ns = listings_am_ns[[\n    'accommodates', \n    'beds','bathrooms',\n    'bedroom_share','bathroom_share',\n    'price'\n]]\nfig = plt.figure(figsize= (6,6))\nsns.heatmap(listings_selected_am_ns.corr(), annot=False, vmax=1, cmap='viridis', square=False)","7fda181e":"show_missing_values(listings_am_ns)","8b37b9b3":"#Creating the train and test split\nnp.random.seed(2018)\ntrain = np.random.choice([True, False], listings_am_ns.shape[0], replace=True, p=[0.8, 0.2])\nlistings_train = listings_am_ns.iloc[train,:]\nlistings_test = listings_am_ns.iloc[~train,:]","01a36384":"list(listings_train)","b40c369a":"def model_listing(regr,train_cols,target_col):\n    \n    x_train = listings_train[train_cols].values\n    x_test = listings_test[train_cols].values\n    y_train = listings_train[target_col].values\n    y_test = listings_test[target_col].values\n    \n    print(\"Shape of Train and Test data\")\n    print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n    print(\" ------------------------------------------ \")\n    \n    #Min Max Scaling\n\n    #scaler = MinMaxScaler()\n    #x_train = scaler.fit_transform(x_train)\n    #x_test = scaler.transform(x_test)\n    \n    # Declare an instance of the Linear Regression model.\n    rg = regr()\n\n    # Fit the model on to the training data( Train the model ).\n    rg.fit(x_train, y_train)\n    \n    # Use the model to predict values\n    y_pred = rg.predict(x_train)\n\n    # Calculate the Mean Squared Error using the mean_squared_error function.\n    print(\"Training Data\")\n    print(\"R^2 value using score fn: %.3f\" % rg.score(x_train,y_train))\n    print(\"Mean Squared Error : %0.3f\" % mean_squared_error(y_train,y_pred))\n    print(\"Root Mean Squared Error : %0.3f\" % (mean_squared_error(y_train,y_pred))**0.5)\n    print(\" ------------------------------------------ \")\n    # Use the model to predict values\n    y_pred = rg.predict(x_test)\n\n    # Calculate the Mean Squared Error using the mean_squared_error function.\n    print(\"Test Data\")\n    print(\"R^2 value using score fn: %.3f\" % rg.score(x_test,y_test))\n    print(\"Mean Squared Error : %0.3f\" % mean_squared_error(y_test,y_pred))\n    print(\"Root Mean Squared Error : %0.3f\" % (mean_squared_error(y_test,y_pred)**0.5))\n    print(\" ------------------------------------------ \")\n    #print(lm.intercept_, lm.coef_)\n    \n    lin_reg_coef = pd.DataFrame(list(zip(train_cols,(rg.coef_))),columns=['Feature','Coefficient'])\n    print(lin_reg_coef.sort_values(by='Coefficient',ascending=False))\n    print(\" ------------------------------------------ \")\n    \n    # Plot of model's residuals:\n    fig = plt.figure(figsize=(10,3))\n\n    sns.regplot(y_test,y_pred)\n    plt.title(\"Residuals for the model\")","5e432b4e":"#Include all features which are relevant to a new host","e46b9cf3":"train_cols = [\n    'accommodates', \n    'beds','bathrooms',\n    'bed_type_Real Bed',\n    'property_type_Condominium','property_type_Townhouse',\n    'room_type_Entire home\/apt', 'room_type_Private room',\n    'property_type_Apartment','property_type_House', \n    'cancellation_policy_flexible', 'cancellation_policy_moderate','instant_bookable'\n]\n\ntarget_col = 'price'\n\nmodel_listing(LinearRegression,train_cols,target_col)","17475c9e":"#Include all features which might be relevant for a new host + Neighbourhood scores","4ac2e7bd":"train_cols = [\n    'accommodates', \n    'beds','bathrooms',\n    'bed_type_Real Bed',\n    'property_type_Condominium','property_type_Townhouse',\n    'room_type_Entire home\/apt', 'room_type_Private room',\n    'property_type_Apartment','property_type_House', \n    'cancellation_policy_flexible', 'cancellation_policy_moderate','instant_bookable',\n    'Walk','Transit','Bike'\n]\n\ntarget_col = 'price'\n\nmodel_listing(LinearRegression,train_cols,target_col)","4d5c98a6":"#Include basic features + neighbourhood scores + amenities","541aecd2":"train_cols = [\n    'accommodates', \n    'beds','bathrooms',\n    'bed_type_Real Bed',\n    'property_type_Condominium','property_type_Townhouse',\n    'room_type_Entire home\/apt', 'room_type_Private room',\n    'property_type_Apartment','property_type_House', \n    'cancellation_policy_flexible', 'cancellation_policy_moderate','instant_bookable',\n    '24-Hour Check-in', 'Access Friendly', 'Breakfast', 'Essentials',\n       'Family\/Kid Friendly', 'Free Parking on Premises', 'Gym', 'Hot Tub',\n       'Internet', 'Kitchen', 'Laundry Facility', 'Pet Friendly', 'Pool',\n       'Safety Features', 'Security Features', 'Smoking Allowed',\n       'Suitable for Events', 'TV', 'Weather Control','Walk','Transit','Bike'\n    \n]\n\ntarget_col = 'price'\n\nmodel_listing(LinearRegression,train_cols,target_col)","762a6d2c":"# Function to calculate regularized cost given alpha, mse and the model coefficients\ndef reg_cost(alpha, mse, coeffs, model = None):\n    if model == \"lasso\":\n        return mse + alpha * np.sum(np.abs(coeffs))\n    elif model == \"ridge\":\n        return mse + alpha * np.linalg.norm(coeffs)\n    else:\n        return mse","7b8fada7":"alpha_levels = [0.01, 0.1, 1, 10, 100]\n\nx_train = listings_train[train_cols].values\nx_test = listings_test[train_cols].values\ny_train = listings_train[target_col].values\ny_test = listings_test[target_col].values\n\nfor alpha_level in alpha_levels:\n    print(\"\\n At alpha Level: %0.2f \"% alpha_level)\n\n    lasso_lm = Lasso(alpha= alpha_level)\n\n    # Fit the model on to the training data( Train the model ).\n    lasso_lm.fit(x_train, y_train)\n\n    # Use the model to predict values\n    #y_pred = np.expm1(lm.predict(x_test))\n    y_pred = lasso_lm.predict(x_test)\n\n    # Calculate the Mean Squared Error using the mean_squared_error function.\n    print(\"Test Data\")\n    print(\"R^2 value using score fn: %.3f\" % lasso_lm.score(x_test,y_test))\n    print(\"Mean Squared Error : %0.3f\" % mean_squared_error(y_test,y_pred))\n    print(\"Root Mean Squared Error : %0.3f\" % (mean_squared_error(y_test,y_pred))**0.5)\n       \n    # Get model complexity using the user defined fn\n    print(\"Model Complexity: %0.3f\" % reg_cost(mse = 0, alpha = 1, coeffs= lasso_lm.coef_, model= \"lasso\"))\n    \n    # Get Regularized Cost using the user defined fn\n    print(\"Regularized Cost: %0.3f\" % reg_cost(mse = mean_squared_error(y_test,y_pred), alpha = alpha_level, coeffs= lasso_lm.coef_, model= \"lasso\"))","726975a6":"train_cols = [\n    'accommodates', \n    'beds','bathrooms',\n    'bed_type_Real Bed',\n    'property_type_Condominium','property_type_Townhouse',\n    'room_type_Entire home\/apt', 'room_type_Private room',\n    'property_type_Apartment','property_type_House', \n    'cancellation_policy_flexible', 'cancellation_policy_moderate','instant_bookable',\n    '24-Hour Check-in', 'Access Friendly', 'Breakfast', 'Essentials',\n       'Family\/Kid Friendly', 'Free Parking on Premises', 'Gym', 'Hot Tub',\n       'Internet', 'Kitchen', 'Laundry Facility', 'Pet Friendly', 'Pool',\n       'Safety Features', 'Security Features', 'Smoking Allowed',\n       'Suitable for Events', 'TV', 'Weather Control','Walk','Transit','Bike'\n    \n]\n\ntarget_col = 'price'\n\nx_train = listings_train[train_cols].values\nx_test = listings_test[train_cols].values\ny_train = listings_train[target_col].values\ny_test = listings_test[target_col].values\n\nprint(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n\n#Create a random forest regressor\nclf = RandomForestRegressor(max_depth=10, n_estimators=100)\n\n#Train the regressor\nclf.fit(x_train, y_train)\n\n#Plot variable importances for the top 10 predictors\nimportances = clf.feature_importances_\nfeat_names = train_cols\ntree_result = pd.DataFrame({'feature': feat_names, 'importance': importances})\ntree_result.sort_values(by='importance',ascending=False)[:10].plot(x='feature', y='importance', kind='bar',color='blue')","b755aea6":"# Use the model to predict values\ny_pred = clf.predict(x_train)\n\n# Calculate the Mean Squared Error using the mean_squared_error function.\nprint(\"Training Data\")\nprint(\"R^2 value using score fn: %.3f\" % clf.score(x_train,y_train))\nprint(\"Mean Squared Error : %0.3f\" % mean_squared_error(y_train,y_pred))\nprint(\"Root Mean Squared Error : %0.3f\" % (mean_squared_error(y_train,y_pred))**0.5)\n\n\nprint(\" ------------------------------------------ \")\n\n# Use the model to predict values\ny_pred = clf.predict(x_test)\n\n# Calculate the Mean Squared Error using the mean_squared_error function.\nprint(\"Test Data\")\nprint(\"R^2 value using score fn: %.3f\" % clf.score(x_test,y_test))\nprint(\"Mean Squared Error : %0.3f\" % mean_squared_error(y_test,y_pred))\nprint(\"Root Mean Squared Error : %0.3f\" % (mean_squared_error(y_test,y_pred))**0.5)\n\nprint(\" ----------------------------------- \")\n\n# Plot of model's residuals:\nfig = plt.figure(figsize=(10,3))\n\nsns.regplot((y_test),(y_pred))\nplt.title(\"Residuals for the model\")","9cf46ca9":"### Model Comparison\n\n* Basic Linear Regression with engineered features performs best with highest R2 and lowest RMSE of 61.77.\n* Feature engineering improves R2 and reduces MSE by 52.\n* Linear models perform better than tree based model.\n* Engineered features have high variable importance (high coefficient)\n","da90969a":"### Data Preprocessing and Feature Engineering","4c477564":"#### Add neighbourhoor scores(walk, transit and bike) after scraping data from https:\/\/www.walkscore.com\/WA\/Seattle . These scores are stored in Seattle_Scores file. The features are joined to the listings dataframe using neighbourhood. These scores help in quantifying the location of the listing as none of the existing features quantify listing.","1ec02abc":"### Engineer neighbourhood score","e3ce2a65":"#### Categorizing amenities into meaningful groups by creating a dictionary","e08496a6":"#### Linear Regression - Basic + Score + Amenities","347b1c60":"## Airbnb Seattle - Pricing tip prediction for new hosts\n\n#### Authored by - Kaushik Jaganathan\n\nSetting the Scene:\n\n* The key stakeholders in Airbnb are the guests and the hosts. Airbnb goes by the tag \u2013 \u201cWhat you charge is always up to you\u201d. So, the hosts have freedom to set prices for their listings. Therefore while listing a new property, hosts tend to compare similar properties and put a price close to similar listings. This may not be very accurate as the price depends on a lot of factors. So, the challenge for the host is to put an optimal price for the listing.\n* Airbnb generates revenue from the host by charging a service fee = 3% of ( Nightly Rate + Cleaning Fee + Add. Guest fee) + VAT.\n* So, when a host is guided with pricing tips, the possibility of the host putting a very low or high price is less. This helps in the host increasing guests which in turn generates revenue for Airbnb.\n\nSolution:\n* Providing pricing tips for a new listing to assist hosts in accurately pricing their properties.\n* Pricing tips combines the information provided by the host along with the neighborhood scores to incorporate the importance of location.\n","f8d1d414":"#### Linear Regression - Basic + Scores","9ff22113":"#### Regularized cost function","d6b5141a":"#### Random Forest Regressor","d08f4e3a":"#### It is seen that no 2 amenities have high correlation among them.","aaf8686f":"### Linear Regression","67df1467":"### Model Building","a1b76450":"### Importing data and doing basic checks###\n\n* The datasets include listings, reviews and calendar. It gives a complete picture of Airbnb listings in Seattle. The listings dataset is considered for this analysis. \n* Each record is a unique listing and contains information about the listing.\n* The target is to predict optimal nightly price for a new listing and suggest to the host. So, nightly price is the target variable which is a continuous variable and requires regression techniques here.\n* There are a lot of features which give information about the host, property, location and reviews. All the host related features for existing listings cannot be used in the model because it is unknown for a new host.\n* The property and location related features can be used in the model. Since it\u2019s not possible to quantify location features, Neighborhood score is added to dataset(will be discussed later) and used in the model.\n* A new host has no reviews yet so no review related features can be used in the model.","fada05cf":"#### There are a lot of fields which have only one level and not useful for analysis. Instead of dropping these fields, only a subset of fields is considered for calculating optimal price.","5519a32d":"### Importing Libraries","851bfbdb":"### Regularization ","d2beebc4":"#### Linear regression basic","42195617":"#### Creating model function","8071933f":"### EDA observations\n\n* Price(target) has a right skewed distribution with median=100 and mean=128.\n* House and Apartment are the most popular property types . All property types with count less than 1% of total were grouped into Others. \n* Entire room\/apartment is the most popular room type present in 66% of listings .\n* There are a total of 87 neighborhoods in Seattle. Belltown and Broadway are the most popular neighborhoods in terms of count of Airbnb listings. \n* Each property has an average of 1.3 bedrooms, 1.25 bathrooms and can accommodate an average of 3.3 guests.\n* There are a total of 42 unique amenities offered across listings and there is no correlation among the amenity groups.\n\n\n","e7487148":"#### Function to preprocess features","c6187f4f":"### Model Results\n\n* Basic Linear Regression model with engineered features gives the best results due to lowest RMSE, so this model is used to interpret feature coefficients.\n* If the room type is Entire Home, the pricing tip of the listing increases by 68.95.\n* For every one unit increase in number of bathrooms, the pricing tip of listing increases by 40.62.\n* If the listing is access-friendly, there is an increase in 10.14 in the pricing tip.\n* For every additional person that can be accommodated in the property,  pricing tip increases by 16.01.\n* Pricing tip is not really influenced by whether a host provides breakfast or not.\n* If smoking is allowed, the pricing tip reduces by 11.32.\n* It is generally observed that engineered features play a important role in determining the pricing tip.\n","3088bffb":"#### Preprocess amenities","f8c03334":"#### Linear Regression - Basic"}}