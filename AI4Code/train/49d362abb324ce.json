{"cell_type":{"31d70b6a":"code","f5e52a15":"code","fcdb0012":"code","0d193e29":"code","61b4129e":"code","2f77df8c":"code","c63f2dc2":"code","1eefba55":"code","935312cd":"code","9a1b5c5b":"code","30209f87":"code","6faba552":"code","9ec759cf":"code","15c8e9b9":"code","54eb069a":"code","0ca9f9ba":"code","0308271c":"code","07e92496":"code","035d5f09":"code","f25cf5e7":"code","dcb33820":"code","2e14accb":"code","95894595":"code","77d57d13":"code","7e94f04d":"code","047fd69c":"code","05bfc75e":"code","1f0f35bc":"code","0e59545e":"code","a339eace":"code","ab75b394":"code","55f29134":"code","a564c905":"code","ad272068":"code","2d7247a8":"code","e05fada6":"code","2fee6fe0":"code","27dfb617":"code","ee5f0cf1":"code","3cd1545e":"code","a1a46ea9":"code","d53c2945":"code","9457d6bd":"code","534f37f3":"code","6541fcd6":"code","3f494b8e":"code","f8646cdf":"code","e6466af5":"code","27741d01":"code","455f3ceb":"code","b8afe3f7":"code","96260e8c":"code","48d48e7f":"code","ae1a27f1":"code","6657f8e6":"code","059b8533":"code","affb35b4":"code","6561b4fe":"code","3df63a33":"code","331fefdb":"code","51119277":"code","2bce6fad":"code","bbadbe50":"code","401c2180":"code","747baa0f":"code","363902ef":"code","e074e299":"code","fbb29f7d":"code","467e936a":"code","d4224867":"code","2cb86685":"code","84aaedf2":"code","9643831d":"code","15830996":"code","6268cca7":"code","9e14b4e6":"code","28564947":"code","ffd191d2":"code","1d2df190":"markdown","928d94cd":"markdown","67c65c53":"markdown","7f9ecf97":"markdown","d03f9e2e":"markdown","bc79d9b5":"markdown","243fd117":"markdown","e7f74654":"markdown","3a94439b":"markdown","3363a943":"markdown","4d2d2b51":"markdown","9968b48e":"markdown","0064edb5":"markdown","ff451055":"markdown","531febb2":"markdown","d25c56ec":"markdown"},"source":{"31d70b6a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","f5e52a15":"from pandas import DataFrame","fcdb0012":"term7=pd.read_csv(\"\/kaggle\/input\/instacart-term7-term30\/term7.csv\")\nterm30=pd.read_csv(\"\/kaggle\/input\/instacart-term7-term30\/term30.csv\")","0d193e29":"# term7 = term30\n# \uc774\ubc88\uc5d4 30\uc5d0 \ub300\ud574\uc11c\uc784","61b4129e":"term7.head()","2f77df8c":"# len(term7) #3586305","c63f2dc2":"# len(term30) #3477322","1eefba55":"from collections import Counter as cc\n\npro_name = cc(term7['product_name'])\nA = pro_name.most_common()[:10000]","935312cd":"A = DataFrame(A)\nA.columns = [\"product_name\",\"product_count\"]","9a1b5c5b":"A.head()","30209f87":"# print(A)","6faba552":"top7 = A.join(term7.set_index('product_name'), on='product_name')","9ec759cf":"len(top7)","15c8e9b9":"# print(top7)","54eb069a":"top7['user_order'] =top7['user_id'] + top7['order_number'] * 0.1","0ca9f9ba":"top7.drop(['eval_set', 'product_count', 'product_id', 'user_id', 'order_number'], axis='columns', inplace=True)\ntop7.head()","0308271c":"group7 = top7[\"product_name\"].groupby(top7['user_order'])\ngroup7 = pd.DataFrame(group7)","07e92496":"group7.columns = ['user_order','product_list']","035d5f09":"group7.head()","f25cf5e7":"product = [list(s) for s in group7.product_list]","dcb33820":"type(group7.user_order)","2e14accb":"print(group7.product_list[0])","95894595":"# product","77d57d13":"len(group7)","7e94f04d":"from gensim.models.word2vec import Word2Vec","047fd69c":"%%time\nmodel = Word2Vec(product)","05bfc75e":"model.init_sims(replace=True)","1f0f35bc":"model.wv.similarity('Banana', 'Bag of Organic Bananas')","0e59545e":"model.wv.most_similar(\"Organic Rolled Oats\")","a339eace":"model.wv.most_similar(\"Tart Cherry Yoghurt\")","ab75b394":"model.wv.most_similar(\"Yogurt, Strained Low-Fat, Coconut\")","55f29134":"model.wv.most_similar(\"Organic Strawberries\")","a564c905":"model.wv.most_similar(\"Organic Baby Spinach\")","ad272068":"model.wv.most_similar(\"Organic Hass Avocado\")","2d7247a8":"model.wv.most_similar(\"Organic Avocado\")","e05fada6":"model.wv.most_similar(\"Large Lemon\")","2fee6fe0":"model.wv.most_similar(\"Strawberries\")","27dfb617":"model.wv.most_similar(\"Organic Whole Milk\")","ee5f0cf1":"model.wv.most_similar(\"Limes\")","3cd1545e":"from sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\n\ndef tsne_plot(model):\n    labels = []\n    tokens = []\n\n    for word in model.wv.vocab:\n        tokens.append(model[word])\n        labels.append(word)\n    \n    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n    new_values = tsne_model.fit_transform(tokens)\n\n    x = []\n    y = []\n    for value in new_values:\n        x.append(value[0])\n        y.append(value[1])\n        \n    plt.figure(figsize=(128, 128)) \n    for i in range(len(x)):\n        plt.scatter(x[i],y[i])\n        plt.annotate(labels[i],\n                     xy=(x[i], y[i]),\n                     xytext=(5, 2),\n                     textcoords='offset points',\n                     ha='right',\n                     va='bottom')\n    plt.show()","a1a46ea9":"# tsne_plot(model)","d53c2945":"# model = Word2Vec(product, size=100, window=5, min_count=1, workers=4)\n# model.save('term7_top10000.model')","9457d6bd":"from gensim.models import Word2Vec","534f37f3":"model = Word2Vec(product, min_count=1)","6541fcd6":"print(model.similarity('Banana', 'Bag of Organic Bananas'))","3f494b8e":"print(model.most_similar(positive=['Banana'], negative=[], topn=2))","f8646cdf":"# print(list(model.wv.vocab))\n# print(len(list(model.wv.vocab)))","e6466af5":"X = model[model.wv.vocab]","27741d01":"from nltk.cluster import KMeansClusterer\nimport nltk\nNUM_CLUSTERS=3\nkclusterer = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance, repeats=25)\nassigned_clusters = kclusterer.cluster(X, assign_clusters=True)\n# print(assigned_clusters)\n# output = [2, 2, 2, 2, .... 1, 0, 1, 0]","455f3ceb":"words = list(model.wv.vocab)\n# for i, word in enumerate(words):\n#     print (word + \":\" + str(assigned_clusters[i]))","b8afe3f7":"# output =\n# Organic Avocado:2\n# Organic Whole String Cheese:2\n# Granny Smith Apples:2\n# Green Beans:2\n# .....","96260e8c":"df = pd.DataFrame()","48d48e7f":"df['product']=words","ae1a27f1":"df.head()","6657f8e6":"df = df.assign(labels=assigned_clusters)","059b8533":"df.to_csv(\"kmeans_7_10000.csv\", index=False)","affb35b4":"df.head()","6561b4fe":"k7_0 = df[df['labels'] == 0]","3df63a33":"k7_1 = df[df['labels'] == 1]","331fefdb":"k7_2 = df[df['labels'] == 2]","51119277":"# k7_3 = df[df['labels'] == 3]","2bce6fad":"# k7_4 = df[df['labels'] == 4]","bbadbe50":"print(len(k7_0),len(k7_1),len(k7_2))","401c2180":"model = Word2Vec(sentences = product, size = 100, window = 5, min_count = 500, workers = 4, sg = 1)  # skip_gram \ubc29\uc2dd\n# user_id \ubd84\uc11d\uc740 \uadf8\ub300\ub85c \ud588\uace0 \uc774\ubc88\uc5d0\ub294 \ud30c\ub77c\ubbf8\ud130\ub3c4 \uadf8\ub300\ub85c \ub4e4\uace0\uc640\ubcf4\uae30","747baa0f":"from sklearn.cluster import DBSCAN\nfrom gensim.models import Word2Vec\n\nimport pandas as pd\nimport re\n\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager as fm\n","363902ef":"# \uc6cc\ub4dc \ubca1\ud130\ub97c \ud074\ub7ec\uc2a4\ud130\ub9c1\ud558\uae30 \uc704\ud574\uc11c\nword_vector = model.wv.vectors\nword_vector\nmatch_index = model.wv.index2word\nmodel.init_sims(replace=True)\n","e074e299":"dbscan = DBSCAN(eps=0.75, min_samples=4)\nclusters = dbscan.fit_predict(word_vector) # \uc6cc\ub4dc \ubca1\ud130\ub97c \ud074\ub7ec\uc2a4\ud130\ub9c1 # fit_predict \ud568\uc218\ub294 \ud074\ub7ec\uc2a4\ud130\ub9c1 \ub41c \uacb0\uacfc\ub97c \ub9ac\uc2a4\ud2b8\ub85c \uc0b0\ucd9c\ud574\uc900\ub2e4. ","fbb29f7d":"df = pd.DataFrame(clusters, columns=[\"cluster\"], index=match_index).reset_index()\ndf.columns = [\"word\", \"cluster\"]\nprint(df.head())","467e936a":"# \ub178\uc774\uc988 \ud3ec\uc778\ud2b8 \uc81c\uac70\ndf = df[df[\"cluster\"] != -1] #-1\uc740 \ub178\uc774\uc988 \ud3ec\uc778\ud2b8","d4224867":"print(df.groupby([\"cluster\"]).count())","2cb86685":"min_cluster = df[\"cluster\"].min()\nmax_cluster = df[\"cluster\"].max()","84aaedf2":"print(min_cluster, max_cluster)","9643831d":"for df_num in range(min_cluster, max_cluster + 1):\n    df_index = df[df[\"cluster\"] == df_num].index\n    df.loc[df_index, \"value\"] = list(range(0, len(df_index) * 3, 3))","15830996":"df[\"cluster\"].nunique()","6268cca7":"# -- \ub370\uc774\ud130\ud504\ub808\uc784 \ucd9c\ub825 \uc804\uccb4\ud3ed\uc744 1000\uc790\ub85c \ud655\uc7a5\npd.set_option('display.width', 1000)\n\n# -- \ub370\uc774\ud130\ud504\ub808\uc784 \ucd9c\ub825 \uc804\uccb4\ud589\uc744 1000\uac1c\ub85c \ud655\uc7a5\n# pd.set_option('display.height', 1000)\n\n# -- \ub370\uc774\ud130\ud504\ub808\uc784 \uceec\ub7fc \uae38\uc774 \ucd9c\ub825 \uc81c\uc57d\uc744 \uc81c\uac70\npd.set_option('display.max_colwidth', -1)\n \npd.set_option('display.max_columns', None)\n\npd.set_option('display.max_rows', 500)","9e14b4e6":"grouped = df[\"word\"].groupby(df[\"cluster\"])\ngrouped = pd.DataFrame(grouped)\ngrouped.columns = ['cluster','word']\ngrouped","28564947":"font = fm.FontProperties(size=70)\nfig, ax = plt.subplots(figsize=(300, 225))\ndf.plot.scatter(x=\"cluster\", y=\"value\", ax=ax)\ndf[[\"cluster\", \"value\", \"word\"]].apply(lambda x: ax.text(*x, fontproperties=font), axis=1)\nplt.show()","ffd191d2":"grouped.to_csv(\"term7_4_10000_dbscan.csv\", index=False)","1d2df190":"**Word2Vec for term7**","928d94cd":"0 1 2<br>\n3680 4743 1577<br>\n<br>\n0 1 2 3 <br>\n3492 4244 1331 933<br>\n<br>\n0 1 2 3 4<br>\n3433 3859 1122 851 735","67c65c53":"![](http:\/\/)Word2Vec","7f9ecf97":"make dataset","d03f9e2e":"https:\/\/lovit.github.io\/nlp\/representation\/2018\/09\/28\/tsne\/","bc79d9b5":"**DBSCAN**","243fd117":"low_dim_embs \ub0b4\ubd80 \uac2f\uc218\uc640 n_components\uac00 \uac19\uc544\uc57c \ud55c\ub2e4.\n\nn_components : \ucc28\uc6d0. default\ub294 2.\n\nperplexity : \uac00\uc7a5 \uac00\uae4c\uc6b4 \uc774\uc6c3 \uac2f\uc218. \ubcf4\ud1b5 5~50. default\ub294 30.\n\nn_iter : \ucd5c\uc801\ud654\uc5d0 \uc0ac\uc6a9\ud560 \ubc18\ubcf5 \ud69f\uc218. \ucd5c\uc18c 200. default\ub294 1000.\n\ninit : embedding \ucd08\uae30\ud654 \ubc29\ubc95. random\uacfc pca \uc911\uc5d0\uc11c \uc120\ud0dd. pca\uac00 \ubcf4\ub2e4 \uc548\uc815\uc801. default\ub294 random.","e7f74654":"Plot","3a94439b":"getting Word2Vec","3363a943":"> **K-Means**","4d2d2b51":"https:\/\/ai.intelligentonlinetools.com\/ml\/k-means-clustering-example-word2vec\/","9968b48e":"visualize k-means","0064edb5":"\n0\tBanana\t59420<br>\n1\tBag of Organic Bananas\t44119<br>\n2\tOrganic Strawberries\t29586<br>\n3\tOrganic Baby Spinach\t27177<br>\n4\tOrganic Hass Avocado\t23841<br>\n5\tOrganic Avocado\t20513<br>\n6\tLarge Lemon\t17851<br>\n7\tStrawberries\t16851<br>\n8\tOrganic Whole Milk\t15885<br>\n9\tLimes\t15765<br>","ff451055":"'Word2Vec' object has no attribute 'vocab'\n<br> .wv\ud544\uc694","531febb2":"\uc704 \ucf54\ub4dc\ub85c user_order\uc640 user_order\uae30\uc900\uc73c\ub85c groupby\ub41c product_list\uac00 \uc21c\uc11c\ub300\ub85c \uc790\ub3d9\uc73c\ub85c \uc5f4\ub85c \ucd94\uac00\ub41c group7\uc774 \ub9cc\ub4e4\uc5b4\uc9c0\uace0<br>\n\uc5f4 \uc774\ub984\uc740 \uac1c\ub150\uc801\uc778 \uac83\uc774\uae30 \ub54c\ubb38\uc5d0, \uc9c0\uae08\uc740 0 1 \ub85c \uc778\ub371\uc2a4\ub9cc \uc801\ud600\uc788\uc5b4\uc11c .columns\ub85c \uc5f4 \uc774\ub984\uc744 \uc9c0\uc815\ud574\uc8fc\ub294\uac83","d25c56ec":"k means clustering with NLTK Library"}}