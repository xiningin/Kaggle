{"cell_type":{"45e16de1":"code","911977a6":"code","971ab6c3":"code","ec32f644":"code","793ea4b0":"code","9621041d":"code","1f1fdd91":"code","9547c339":"code","d2621c48":"code","d41613fc":"code","9d897802":"code","c6dc4807":"code","d9762b88":"code","fd6fee26":"code","7242128a":"code","a16dbfe4":"code","3e9fa154":"code","9347992c":"code","58a2fb9f":"code","2ade4e67":"code","7b7071f5":"code","404a1a53":"code","5ea9d966":"code","0ed1132c":"code","c283d2e2":"code","519e1583":"code","a38900bd":"code","579aa341":"code","49a2fb06":"code","2cebe6ea":"code","26c1da51":"code","aeb88662":"code","f2f33d15":"code","567db3dc":"code","e1e04fa8":"code","3142f2c7":"code","370ce5d0":"code","27dc0d76":"markdown","796b927f":"markdown","265add15":"markdown","adcadcf7":"markdown","d32e5344":"markdown","13a2dbce":"markdown","2e299c93":"markdown"},"source":{"45e16de1":"import pandas as pd\nimport numpy as np\nimport matplotlib\n%matplotlib inline\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom scipy.stats import mode\nimport matplotlib.pyplot as plt ","911977a6":"train = pd.read_csv(r'...\\train.csv')\ntest = pd.read_csv(r'....\\test.csv')\nfull = pd.concat([train, test], keys=['train','test'])\n#full = pd.concat([train, test])\nfull.head()\n","971ab6c3":"full['LastName'] = full.Name.str.split(',').apply(lambda x: x[0]).str.strip()\nfull['Title'] = full.Name.str.split(\"[\\,\\.]\").apply(lambda x: x[1]).str.strip()","ec32f644":"print(full.Title.value_counts())","793ea4b0":"##if the title is Dr and the sex is female, we'll update the Title as Miss\nfull.loc[(full.Title == 'Dr') & (full.Sex == 'female'), 'Title'] = 'Mrs'\n\n##if the title is in any of the following, we'll update the Title as Miss\nfull.loc[full.Title.isin(['Lady','Mme','the Countess','Dona']), 'Title'] = 'Mrs'\n\n##if the title is in any of the following, we'll update the Title as Miss\nfull.loc[full.Title.isin(['Ms','Mlle']), 'Title'] = 'Miss'\n\n##if the title is Dr and the sex is female, we'll update the Title as Mr\nfull.loc[(full.Title == 'Dr') & (full.Sex == 'male'), 'Title'] = 'Mr'\n\n##if the title is Rev and the sex is male, we'll update the Title as Mr\nfull.loc[(full.Title == 'Rev') & (full.Sex == 'male'), 'Title'] = 'Mr'\n\n## Setting all the Rev, Col, Major, Capt, Sir --> Mr\nfull.loc[full.Title.isin(['Rev','Col','Major','Capt','Sir','Don','Jonkheer']) & (full.Sex == 'male'), 'Title'] = 'Mr'","9621041d":"def passenger_type (row):\n   if row['Age'] < 2 :\n      return 'Infant'\n   elif (row['Age'] >= 2 and row['Age'] < 12):\n      return 'Child'\n   elif (row['Age'] >= 12 and row['Age'] < 18):\n      return 'Youth'\n   elif (row['Age'] >= 18 and row['Age'] < 65):\n      return 'Adult'\n   elif row['Age'] >= 65:\n      return 'Senior'\n   elif row['Title'] == 'Master':\n      return 'Child'\n   elif row['Title'] == 'Miss':\n      return 'Child'\n   elif row['Title'] == 'Mr' or row['Title'] == 'Mrs':\n      return 'Adult'\n   else:\n      return 'Unknown'\nfull['PassengerType'] = full.apply(lambda row: passenger_type(row),axis=1)","1f1fdd91":"full","9547c339":"#Now to see the distribution\nfull['PassengerType'].value_counts()","d2621c48":"#factorize the PassengerType to make it numeric values\nfull['PassengerType'] = pd.factorize(full['PassengerType'])[0]\nfull['PassengerType'].value_counts()\n#full = pd.get_dummies(full, columns=['PassengerType'])","d41613fc":"#factorize the PassengerType to make it numeric values\nfull['Title'] = pd.factorize(full['Title'])[0]\nfull['Title'].value_counts()","9d897802":"full['Fare'].isnull().sum()","c6dc4807":"full.loc[full.Fare.isnull()]\nfull.loc[full.Fare.isnull(), 'Fare'] = full.loc[(full.Embarked == 'S') & (full.Pclass == 3),'Fare'].median()","d9762b88":"full.head()","fd6fee26":"# Now let's check for nulls in the Embarked column.\nfull.Embarked.isnull().sum()","7242128a":"print(full.groupby(['Pclass', 'Embarked'])['Fare'].median())","a16dbfe4":"full.loc[full.Embarked.isnull(), 'Embarked'] = 'C'","3e9fa154":"# We'll now create a bin for the Fare ranges. splitting into 6 groups seems to be a reasonable split.","9347992c":"full['Fare_bin'] = pd.qcut(full['Fare'], 6)","58a2fb9f":"#Creating new family_size column\nfull['FamilySize'] = full['SibSp'] + full['Parch'] + 1","2ade4e67":"#The fare for the 2 rows is 80. Let's see which class and Embarked combination gives the closest Median Fare to 80\nprint(full.groupby(['Pclass', 'Embarked'])['Fare'].median())\n\n#Boxplot to show the median values for different groups. (1,c) has a median value of 80\nmedianprops = dict(linestyle='-', linewidth=1, color='k')\nfull.boxplot(column='Fare',by=['Pclass','Embarked'], medianprops=medianprops, showmeans=False, showfliers=False)","7b7071f5":"#full = pd.get_dummies(full, columns=['Embarked'])\nfull['Embarked'] = pd.factorize(full['Embarked'])[0]\nfull['Gender'] = pd.factorize(full['Sex'])[0]\nfull.info()","404a1a53":"full.rename(columns={\"Fare_[0, 7.75]\": \"Fare_1\"\n                                ,\"Fare_(7.75, 7.896]\": \"Fare_2\"\n                                ,\"Fare_(7.896, 9.844]\": \"Fare_3\"\n                                ,\"Fare_(9.844, 14.454]\": \"Fare_4\"\n                                ,\"Fare_(14.454, 24.15]\": \"Fare_5\"\n                                ,\"Fare_(24.15, 31.275]\": \"Fare_6\"\n                                ,\"Fare_(31.275, 69.55]\": \"Fare_7\"\n                                ,\"Fare_(69.55, 512.329]\": \"Fare_8\"}, inplace=True)\nfull.info()","5ea9d966":"cols = full.columns.tolist()\ncols","0ed1132c":"feature_cols = ['Fare', 'Parch', 'SibSp', 'Pclass', 'FamilySize', 'Title','PassengerType', 'Gender']","c283d2e2":"AgeNotNull = full.loc[full.Age.notnull(),:].copy()\nAgeNull = full.loc[full.Age.isnull(),:].copy()","519e1583":"X = AgeNotNull[feature_cols]\ny = AgeNotNull.Age\n\n# follow the usual sklearn pattern: import, instantiate, fit\nfrom sklearn.linear_model import LinearRegression\nlm = LinearRegression()\nlm.fit(X, y)\n","a38900bd":"p = lm.predict(AgeNotNull[feature_cols])\n\n# Now we can constuct a vector of errors\nerr = abs(p-y)\n#print(y[:10])\n#print(p[:10])\n# Let's see the error on the first 10 predictions\nprint (err[:10])","579aa341":"# predict for a new observation\np1 = lm.predict(AgeNull[feature_cols])\nprint(p1[:10])\np1.shape\nAgeNull.shape","49a2fb06":"AgeSer = full.loc[full.Age.notnull(),'Age']\nplt.hist(AgeSer)\nplt.ylabel(\"Count\")\nplt.xlabel(\"Age\")\nplt.show()","2cebe6ea":"full.loc[full.Age.isnull(), 'Age'] = p1","26c1da51":"train = full.loc['train']\ntest = full.loc['test']","aeb88662":"y = train.loc[:,'Survived']","f2f33d15":"X = train.loc[:,['PassengerId','Age','Fare', 'Pclass','Title','PassengerType','FamilySize','Embarked','Gender']]","567db3dc":"train_data = train.values\ntrain_X = X.values\ntrain_y = y.values","e1e04fa8":"from sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn.model_selection import GridSearchCV ,train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, roc_auc_score ,roc_curve,auc","3142f2c7":"logreg = LogisticRegression(class_weight='balanced')\nparam = {'C':[0.001,0.003,0.005,0.01,0.03,0.05,0.1,0.3,0.5,1,2,3,3,4,5,10,20]}\nclf = GridSearchCV(logreg,param,scoring='roc_auc',refit=True,cv=10)\nclf.fit(X,y)\nprint('Best roc_auc: {:.4}, with best C: {}'.format(clf.best_score_, clf.best_params_))","370ce5d0":"kf = StratifiedKFold(n_splits=5,shuffle=True,random_state=20)\npred_test_full =0\ncv_score =[]\ni=1\nfor train_index,test_index in kf.split(X,y):\n    print('{} of KFold {}'.format(i,kf.n_splits))\n    xtr,xvl = X.loc[train_index],X.loc[test_index]\n    ytr,yvl = y.loc[train_index],y.loc[test_index]\n    \n    #model\n    lr = LogisticRegression(C=2)\n    lr.fit(xtr,ytr)\n    score = roc_auc_score(yvl,lr.predict(xvl))\n    print('ROC AUC score:',score)\n    \n    i+=1","27dc0d76":"Load the test and Train datasets into Pandas Dataframe. There are missing values in both Test and Train sets. Once we train the model using the train set, we should be able to use the model to predict the test set. For that we need to make sure the structure of the train and test datasets are the same and all the features that we are creating is available in both the datasets. It's better to combine the test and train datasets and then split it before training the model.","796b927f":"Create a family size variable to see if there's any reason to believe that smaller families had a better chance of survival","265add15":"Now we will define a new column - PassengerType to categorize the passengers into Adults and Children","adcadcf7":"There is one Fare that is null. We'll update that to the median fare for the Class and Embarked Combination","d32e5344":"Mr 757; Miss 260; Mrs 197; Master 61; Dr 8; Rev 8; Col 4; Ms 2; Mlle 2; Major 2; Dona 1; Lady 1; Sir 1; Mme 1; the Countess 1; Don 1; Jonkheer 1; Capt 1; the Countess 1; Jonkheer 1\n\nAs you can see, there are too many titles. We'll try and consolidate the titles to the commonly used ones. We'll consolidate the titles into the main 4 categories - Mr, Mrs, Miss and Master","13a2dbce":"Split the Name column and create 2 new columns - LastName and Title. The Title column will come in handy later to guess the missing age values of the passengers","2e299c93":"The median fare for passengers embarked from \"C\" and have a First class ticket is $77. Close to the $80 that the two paasengers paid. Based on the median fare, we'll assume that they both Embarked from Port C"}}