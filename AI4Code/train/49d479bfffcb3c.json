{"cell_type":{"9e19528b":"code","60714d31":"code","27c79b51":"code","79dbe60c":"code","1cb0a9b0":"code","20a0a064":"code","afec1630":"code","f053d3b7":"code","53d2d5b4":"code","3f24f504":"markdown","ef5bff83":"markdown","248897fe":"markdown","551bc804":"markdown","0e39deed":"markdown","5f9a844b":"markdown","e4c32b64":"markdown","d015cbd5":"markdown","337d5e6e":"markdown","71390c6a":"markdown"},"source":{"9e19528b":"# Client instance\nfrom google.cloud import language\n\nclient = language.LanguageServiceClient()","60714d31":"text = u\"I'm really, really lucky!\"\n\n# Language code is optional. If not specified, the language is automatically detected.\n# For list of supported languages: https:\/\/cloud.google.com\/natural-language\/docs\/languages\nlanguage_code = \"en\"\n\n# Available document types: PLAIN_TEXT, HTML\ndocument = language.Document(content=text, language=language_code, type_=language.Document.Type.PLAIN_TEXT)\n\n# Encoding type also optional. Available values: NONE, UTF8, UTF16, UTF32\nencoding_type = language.EncodingType.UTF8\n\nsentiment = client.analyze_sentiment(request={'document': document, 'encoding_type': encoding_type}).document_sentiment\nprint(f\"Text: '{text}'\")\nprint(f\"Sentiment score: {sentiment.score}, magnitude {sentiment.magnitude}\")","27c79b51":"# Use dict to define document.\ndocument = {'gcs_content_uri': 'gs:\/\/cloud-samples-data\/language\/president.txt',\n            'language':'en',\n            'type_':'PLAIN_TEXT'}\n\nresponse = client.analyze_sentiment(request={'document': document})\n\n# Get overall sentiment of the input document\nprint(f\"    Document sentiment score: {response.document_sentiment.score}\")\nprint(f\"Document sentiment magnitude: {response.document_sentiment.magnitude}\\n\")\n\n# Get sentiment for all sentences in the document\nfor sentence in response.sentences:\n    print(f\"               Sentence text: '{sentence.text.content}'\")\n    print(f\"    Sentence sentiment score: {sentence.sentiment.score}\")\n    print(f\"Sentence sentiment magnitude: {sentence.sentiment.magnitude}\")","79dbe60c":"# Available types: PLAIN_TEXT, HTML\ntype_ = language.Document.Type.PLAIN_TEXT\ngcs_content_uri = 'gs:\/\/cloud-samples-data\/language\/classify-entertainment.txt'\ndocument = {\"gcs_content_uri\": gcs_content_uri, \"type_\": type_, \"language\": \"en\"}\n\nresponse = client.classify_text(request = {'document': document})\n# Loop through classified categories returned from the API\nfor category in response.categories:\n    # Get the name of the category representing the document. Confidence representing how certain the classifier\n    # is that this category represents the provided text.\n    print(f\"Category name: '{category.name}' Confidence: {category.confidence}\")\n","1cb0a9b0":"# Analyzing Entities in a String\ndocument = {'content': 'Nikola Tesla was a Serbian-American inventor, electrical engineer, mechanical engineer, and futurist.',\n            'type_': language.Document.Type.PLAIN_TEXT,\n            'language': 'en'}\n\nresponse = client.analyze_entities(request = {'document': document, 'encoding_type': language.EncodingType.UTF8})\nfor entity in response.entities:\n    for metadata_name, metadata_value in entity.metadata.items():\n        if metadata_name=='wikipedia_url':\n            print(f'Wikipedia link: {metadata_value}\\n')\n    print('=' * 20)\n    print('         name: {0}'.format(entity.name))\n    print('         type: {0}'.format(entity.type_))\n    print('     metadata: {0}'.format(entity.metadata))\n    print('     salience: {0}'.format(entity.salience))\n# To analyze full respone\n# print(response)","20a0a064":"gcs_content_uri = 'gs:\/\/cloud-samples-data\/language\/entity-sentiment.txt'\n\ndocument = {'gcs_content_uri': gcs_content_uri, 'type_': language.Document.Type.PLAIN_TEXT, 'language': 'en'}\nresponse = client.analyze_entity_sentiment(request = {'document': document, 'encoding_type': language.EncodingType.UTF8})\n\nfor entity in response.entities:\n    print(f\"Representative name for the entity: {entity.name}\")\n    # Get entity type, e.g. PERSON, LOCATION, ADDRESS, NUMBER, et al\n    print(f\"Entity type: {language.Entity.Type(entity.type_).name}\")\n    # Get the salience score associated with the entity in the [0, 1.0] range\n    print(f\"Salience score: {entity.salience}\")\n    # Get the aggregate sentiment expressed for this entity in the provided document.\n    sentiment = entity.sentiment\n    print(f\"Entity sentiment score: {sentiment.score} and magnitude: {sentiment.magnitude}\")\n\n    # Loop over the metadata associated with entity. For many known entities,\n    # the metadata is a Wikipedia URL (wikipedia_url) and Knowledge Graph MID (mid).\n    # Some entity types may have additional metadata, e.g. ADDRESS entities\n    # may have metadata for the address street_name, postal_code, et al.\n    for metadata_name, metadata_value in entity.metadata.items():\n        print(f\"{metadata_name} = {metadata_value}\")\n    # Loop over the mentions of this entity in the input document.\n    # The API currently supports proper noun mentions.\n    for mention in entity.mentions:\n        print(f\"\\tMention text: {mention.text.content}\")\n        # Get the mention type, e.g. PROPER for proper noun\n        print(f\"\\tMention type: {language.EntityMention.Type(mention.type_).name}\")\n    print()\n# Get the language of the text, which will be the same as\n# the language specified in the request or, if not specified,\n# the automatically-detected language.\nprint(f\"\\nLanguage of the text: {response.language}\")\n","afec1630":"gcs_content_uri = 'gs:\/\/cloud-samples-data\/language\/syntax-sentence.txt'\n\ndocument = {'gcs_content_uri': gcs_content_uri, 'type_': language.Document.Type.PLAIN_TEXT, 'language': 'en'}\nresponse = client.analyze_syntax(request = {'document': document, 'encoding_type': language.EncodingType.UTF8})\n\n# Loop through tokens returned from the API\nfor token in response.tokens:\n    # Get the text content of this token. Usually a word or punctuation.\n    text = token.text\n    print(f\"Token text: {text.content}\")\n    print(f\"Location of this token in overall document: {text.begin_offset}\")\n    # Get the part of speech information for this token.\n    # Parts of spech are as defined in:\n    # http:\/\/www.lrec-conf.org\/proceedings\/lrec2012\/pdf\/274_Paper.pdf\n    part_of_speech = token.part_of_speech\n    # Get the tag, e.g. NOUN, ADJ for Adjective, et al.\n    print(f\"Part of Speech tag: {language.PartOfSpeech.Tag(part_of_speech.tag).name}\")\n    # Get the voice, e.g. ACTIVE or PASSIVE\n    print(f\"Voice: {language.PartOfSpeech.Voice(part_of_speech.voice).name}\")\n    # Get the tense, e.g. PAST, FUTURE, PRESENT, et al.\n    print(f\"Tense: {language.PartOfSpeech.Tense(part_of_speech.tense).name}\")\n    # See API reference for additional Part of Speech information available\n    # Get the lemma of the token. Wikipedia lemma description\n    # https:\/\/en.wikipedia.org\/wiki\/Lemma_(morphology)\n    print(f\"Lemma: {token.lemma}\")\n    # Get the dependency tree parse information for this token.\n    # For more information on dependency labels:\n    # http:\/\/www.aclweb.org\/anthology\/P13-2017\n    dependency_edge = token.dependency_edge\n    print(f\"Head token index: {dependency_edge.head_token_index}\")\n    print(f\"Label: {language.DependencyEdge.Label(dependency_edge.label).name} \\n\")\n\n# Get the language of the text, which will be the same as\n# the language specified in the request or, if not specified,\n# the automatically-detected language.\nprint(f\"\\nLanguage of the text: {response.language}\")\n\n","f053d3b7":"gcs_content_uri = 'gs:\/\/cloud-samples-data\/language\/entity-sentiment.txt'\n\ndocument = {'gcs_content_uri': gcs_content_uri, 'type_': language.Document.Type.PLAIN_TEXT, 'language': 'en'}\nresponse = client.annotate_text(request = {\n    'document': document,\n    'encoding_type': language.EncodingType.UTF8,\n    'features': {\n        'extract_document_sentiment':True,\n        'extract_entities':True,\n        'extract_entity_sentiment':True,\n        'extract_syntax': False,\n        'classify_text': False\n        }\n    })\ndisplay(response)","53d2d5b4":"html_content = \"\"\"\\\n<html>\n    <head>\n        <title>Silvery autumn<\/title>\n    <\/head>\n    <body>\n        <p>Night was falling inside our world.<\/p>\n        <p>As night as fall on summer fields,<\/p>\n        <p>Gray cold reminds me of that,<\/p> \n        <p>I want back to you.<\/p>\n    <\/body>\n<\/html>\n\"\"\"\n\ndocument = {\n    'content': html_content,\n    'type_': language.Document.Type.HTML,\n    'language': 'en'\n    }\n\nresponse = client.analyze_sentiment(request={'document': document})\nfor sentence in response.sentences:\n    print(f\"               Sentence text: '{sentence.text.content}'\")\n    print(f\"    Sentence sentiment score: {sentence.sentiment.score}\")\n    print(f\"Sentence sentiment magnitude: {sentence.sentiment.magnitude}\\n\")","3f24f504":"## Entity analysis\nInspects the given text for known entities (Proper nouns such as public figures, landmarks, and so on. Common nouns such as restaurant, stadium, and so on.) and returns information about those entities.\nSee [guides](https:\/\/cloud.google.com\/natural-language\/docs\/analyzing-entities) for more details.","ef5bff83":"## Entity sentiment analysis\nInspects the given text for known entities (proper nouns and common nouns), returns information about those entities, and identifies the prevailing emotional opinion of the entity within the text, especially to determine a writer's attitude toward the entity as positive, negative, or neutral.\nSee [guides](https:\/\/cloud.google.com\/natural-language\/docs\/analyzing-entity-sentiment) for more details.\n","248897fe":"# Google Gloud Platform pretrained ML services Notebook series\n\nWelcome to this introduction level series about how to use Google Cloud pretrained ML services Python clients from Kaggle notebooks, without raw HTTP API calls. Four notebooks are prepared as reference guides:\n\n* [Cloud Translation quick start notebook](https:\/\/www.kaggle.com\/kornelregius\/google-cloud-translation-tutorial)\n* [Cloud Natural Language quick start notebook](https:\/\/www.kaggle.com\/kornelregius\/google-cloud-natural-language-tutorial)\n* [Cloud Video Intelligence quick start notebook](https:\/\/www.kaggle.com\/kornelregius\/google-cloud-video-intelligence-tutorial)\n* [Cloud Vision quick start notebook](https:\/\/www.kaggle.com\/kornelregius\/google-cloud-vision-tutorial)\n\n\n## Before start, please read these important notes\n\nFirstly, please note that <mark>Cloud Natural Language is a paid service<\/mark> and requires a GCP project with billing enabled to use. Please refer to [pricing page](https:\/\/cloud.google.com\/natural-language\/pricing). Also keep in mind, Cloud NL API apply a [quota limit](https:\/\/cloud.google.com\/natural-language\/quotas#requests) for requests\/minutes.\nLuckily, you're eligible for a $300 credit when creating the first GCP project.\n\nBefore you can start using any of these services, you must have a Google Cloud project that has the service API enabled.\n\n1. Select or create a GCP Project\n2. Enable Billing. Remember to understand pricing prior to this step.\n3. [Enable Cloud Natural Language API](https:\/\/console.cloud.google.com\/apis\/library\/language.googleapis.com)\n\nIn order to use Google Cloud Services from Kagge notebooks, you need to attach your Google Cloud Platform account to this notebbok. Select 'Add-ons' menu above then 'Google Cloud Services'.\n- If you have already attached Google Cloud account to your Kaggle account, please just attach it to this notebook as well.\n- Otherwise you need to attach your account to your profile (and this notebook) by selecting 'Google Cloud AI Platform' integration and adding an authorized account.\n\nMake sure you've **linked both 'Google Cloud AI Platform' and 'Cloud Storage'** for this tutorial.\n*Unsuccefull attachment, will cause \"Could not automatically determine credentials.\" error response when you want to instantiate a Python client.* \n\n## Google Cloud Platfrom [Natural Language](https:\/\/cloud.google.com\/natural-language)\n\nNatural Language uses machine learning to reveal the structure and meaning of text. You can extract information about people, places, and events, and better understand social media sentiment and customer conversations. Natural Language enables you to analyze text and also integrate it with your document storage on Cloud Storage.\n\nCloud NL available in [two versions](https:\/\/cloud.google.com\/natural-language#which-natural-language-product-is-right-for-you):\n* AutoML Natural Language\n* Natural Language API\n\nIn this introductional examples we are leveraging Natural Language API features only.\n\nRecommended reading about details of [basic concepts of NL API](https:\/\/cloud.google.com\/natural-language\/docs\/basics). In that page you get intuition about sentiment, entity and syntactic analysis capabilities.\n\nWhen passing a Natural Language API request, you specify the text to process in one of two ways:\n\n* Passing the text directly within a content field.\n* Passing a Google Cloud Storage URI within a 'gcsContentUri' or 'gcs_content_uri' field. Public [text examples are available in Cloud Storage](https:\/\/console.cloud.google.com\/storage\/browser\/cloud-samples-data\/language) bucket.","551bc804":"## Annotate text\nYou can perform multiple analysis using annotate_text() method providing required NL features. Setting each one to true will enable that specific analysis for the input. Analyzes a document and is intended for users who are familiar with machine learning and need in-depth text features to build upon.\n\n>Note not all feature works with the example text file","0e39deed":"### Create API client\nClient library reference: https:\/\/googleapis.dev\/python\/language\/latest\/usage.html","5f9a844b":"## Content classification\nAnalyzes text and returns a content category for the content. See [guides](https:\/\/cloud.google.com\/natural-language\/docs\/classifying-text) for more details.\n\nList of the predefined taxonomy of categories: https:\/\/cloud.google.com\/natural-language\/docs\/categories\n","e4c32b64":"## Sentiment analysis (provide a string directly)\nInspects the given text and identifies the prevailing emotional opinion within the text, especially to determine a writer's attitude as positive, negative, or neutral. See [guides](https:\/\/cloud.google.com\/natural-language\/docs\/analyzing-sentiment) for more details.\n\nSentiment is represented by numerical score and magnitude values.","d015cbd5":"## Sentiment analysis (provide file URI to Cloud Storage)\nSome example files in public Cloud Storage bucket:\n* Negative: gs:\/\/cloud-samples-data\/language\/sentiment-negative.txt\n* Positive: gs:\/\/cloud-samples-data\/language\/sentiment-positive.txt\n* Neutral: gs:\/\/cloud-samples-data\/language\/president.txt\n\n>Note: You can use Python dict to provide document request parameters","337d5e6e":"## Syntax analysis\nExtracts linguistic information, breaking up the given text into a series of sentences and tokens (generally, word boundaries), providing further analysis on those tokens.\nSee [guides](https:\/\/cloud.google.com\/natural-language\/docs\/analyzing-syntax) for more details.\n","71390c6a":"## HTML content\nTest NL API with HTML content."}}