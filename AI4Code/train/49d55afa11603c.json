{"cell_type":{"7a7919aa":"code","2fa1d624":"code","ba5bc373":"code","185142b6":"code","1ca72a67":"code","24082b0e":"code","1b69d20c":"code","9f0ff876":"code","fb336773":"code","114e709f":"code","58493238":"code","7f4a9b7a":"code","1b6fa462":"code","45ce4cd0":"code","09aacaf4":"code","0c433ea5":"code","0ca365e9":"code","3d4450a0":"code","a9a26dad":"code","127c1141":"markdown","ffc94b74":"markdown","f7cc7b07":"markdown","e55f97ee":"markdown","029da23a":"markdown","7fd4efab":"markdown","041b17de":"markdown","af892b3b":"markdown","a2f59b2b":"markdown","a70577a9":"markdown","2ebabcc6":"markdown","4f37df1d":"markdown","33de150d":"markdown","add1131e":"markdown","56773240":"markdown","1faef675":"markdown"},"source":{"7a7919aa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#   for filename in filenames:\n#       print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2fa1d624":"from pathlib import Path ","ba5bc373":"root = Path('..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset')","185142b6":"img_path = list(root.glob(r'**\/*.png'))\nimg_path = pd.Series(img_path).astype(str)\nimg_path[:5]","1ca72a67":"labels = list(map(lambda x:os.path.split(os.path.split(x)[0])[1],img_path))\nlabels = pd.Series(labels)\nlabels[:5]","24082b0e":"data = pd.concat([img_path,labels],axis=1)\ndata.sample(5)","1b69d20c":"data = data[data[1].apply(lambda x: x[-2:] != \"GT\")].reset_index(drop=True)\ndata.shape","9f0ff876":"import matplotlib.pyplot as plt\nimport seaborn as sns","fb336773":"plt.figure(figsize=(15,5))\nsns.countplot(x=data[1])","114e709f":"from sklearn.model_selection import train_test_split\ntrain_set , test_set = train_test_split(data,test_size=0.2,random_state=17)","58493238":"train_set.shape,test_set.shape","7f4a9b7a":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","1b6fa462":"train_gen = ImageDataGenerator(validation_split=0.1)\ntest_gen = ImageDataGenerator()\n\ntrain_data = train_gen.flow_from_dataframe(\n    dataframe = train_set,\n    x_col = 0,\n    y_col = 1,\n    target_size = (300,300),\n    color_mode = 'rgb',\n    class_mode = 'categorical',\n    shuffle = True,\n    subset = 'training'\n)\n\nval_data = train_gen.flow_from_dataframe(\n    dataframe = train_set,\n    x_col = 0,\n    y_col = 1,\n    target_size = (300,300),\n    color_mode = 'rgb',\n    class_mode = 'categorical',\n    shuffle = False,\n    subset = 'validation'\n)\n\ntest_data = test_gen.flow_from_dataframe(\n    dataframe = test_set,\n    x_col = 0,\n    y_col = 1,\n    target_size = (300,300),\n    color_mode = 'rgb',\n    class_mode = 'categorical',\n    shuffle = False\n)","45ce4cd0":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32,(3,3),padding='same',activation='relu',input_shape=(300,300,3)),\n    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n    tf.keras.layers.MaxPool2D((2,2)),\n    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n    tf.keras.layers.MaxPool2D((2,2)),\n    tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n    tf.keras.layers.MaxPool2D((2,2)),\n    tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n    tf.keras.layers.MaxPool2D((2,2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128,activation='relu'),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Dense(9,activation='softmax')\n])\n\nfrom tensorflow.keras.optimizers import RMSprop\n\nmodel.compile( \n    optimizer=RMSprop(lr=1e-4),\n    loss='categorical_crossentropy',\n    metrics=['accuracy'])\n\nmodel.summary()","09aacaf4":"model_history = model.fit(train_data,epochs=10,validation_data=val_data)","0c433ea5":"hist = model_history.history\nfig , ax = plt.subplots(1, 2, figsize=(20, 10))\nax[0].plot(hist['accuracy'] , label='training')\nax[0].plot(hist['val_accuracy'] , label='validation')\nax[0].set_title('Accuracy')\nax[0].legend()\nax[1].plot(hist['loss'] , label='training')\nax[1].plot(hist['val_loss'] , label='validation')\nax[1].set_title('Loss')\nax[1].legend()","0ca365e9":"y_pred = model.predict(test_data)\ny_pred = np.argmax(y_pred,axis=1)","3d4450a0":"from sklearn.metrics import classification_report\nprint(classification_report(test_data.labels,y_pred))","a9a26dad":"from sklearn.metrics import confusion_matrix\nprint(confusion_matrix(test_data.labels,y_pred))","127c1141":"## Converting to DataFrame","ffc94b74":"## Dropping Ground Truth Images","f7cc7b07":"# Creating our Sequential Model","e55f97ee":"## Plotting the training and validation curves","029da23a":"## Fitting Our training Set","7fd4efab":"## Confusion Matrix","041b17de":"## Classification Report","af892b3b":"# CNN from scratch for very large scale fish dataset","a2f59b2b":"# The End\n`If you liked the notebook then don't forget to upvote and suggestions are always welcomed.`\n`Follow me on Linkedin :` __[Atharva_Dumbre](https:\/\/www.linkedin.com\/in\/atharva-dumbre-208b5716b)__","a70577a9":"# Predictions for Test Set","2ebabcc6":"# Using ImageDataGenerator","4f37df1d":"## Importing Visualization Libraries","33de150d":"## Importing Tensorflow and ImageDataGenerator","add1131e":"## Splitting our Dataset","56773240":" ### Histogram shows a Balanced Dataset","1faef675":"## Data Loading"}}