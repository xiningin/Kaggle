{"cell_type":{"0154818b":"code","36f09c7d":"code","26e9bc21":"code","9b71839c":"code","693edf1b":"code","d54feeb1":"code","2392dfd8":"code","a6c3a5eb":"code","fbaaba63":"code","36aff1c0":"code","57dfac4d":"code","b7db1119":"code","51f23908":"code","c88346bd":"code","41ad4fb3":"code","b8b1a124":"code","d91f1b3b":"code","7b90fe93":"code","1913a90c":"code","f52cc1fe":"code","ddbec68e":"code","291584d9":"code","5dd71bae":"code","1ff5ca18":"code","256a6170":"code","57528071":"code","454997be":"code","4a0f99ce":"code","6f5fa6e3":"code","d58c8ccd":"code","2ed015b5":"code","72f24040":"code","2caca080":"markdown","da7731b9":"markdown","9292834a":"markdown","6ce62e2a":"markdown","be29391f":"markdown","1d617848":"markdown","48ba1653":"markdown","5f5c6bf9":"markdown","28f10b36":"markdown","496d78bb":"markdown","b7c3c050":"markdown","4bba4bb2":"markdown","66b9dfee":"markdown","a9cc3d77":"markdown","5d070f2e":"markdown","65cf18f0":"markdown","9bd3647e":"markdown","cbc36025":"markdown","97f7f948":"markdown","89158502":"markdown","e64e0b79":"markdown","d56fb4c7":"markdown","1fc33b58":"markdown","dffc78b1":"markdown","1332a53e":"markdown","258e28f5":"markdown","c8b843e7":"markdown","19fdbf5f":"markdown"},"source":{"0154818b":"import numpy as np\nimport pandas as pd\nimport re as re\n%matplotlib inline\n\n# targert dir for submission file\ntarget_dir = '\/kaggle\/working\/'\n%cd ..\/input\/titanic-machine-learning-from-disaster\/","36f09c7d":"train = pd.read_csv(\"train.csv\", header=0, dtype={\"Age\": np.float64})\ntest  = pd.read_csv(\"test.csv\", header=0, dtype={\"Age\": np.float64})\nfull_data = [train, test]\nPassengerId = test[\"PassengerId\"]","26e9bc21":"def load_dataset():\n    \"\"\"\n    Load Dataset\n    \"\"\"\n    train = pd.read_csv(\"train.csv\", header=0, dtype={\"Age\": np.float64})\n    test  = pd.read_csv(\"test.csv\", header = 0,dtype={\"Age\": np.float64})\n    \n    full_data = [train, test]\n    PassengerId = test[\"PassengerId\"]\n    display(train.info())\n    return train, test, full_data, PassengerId\n\n# revoked load_dataset()\ntrain, test, full_data, PassengerId = load_dataset()","9b71839c":"train[[\"Pclass\", \"Survived\"]].groupby(\"Pclass\", as_index=False).mean()","693edf1b":"def get_suvival_ratio(df, selectList:None, groupbyCol:None):\n    \"\"\"\n    \uc9d1\uacc4 \ud53c\ucc98\uc5d0 \ub300\ud574\uc11c \uc0dd\uc874\ub960\uc744 \ub9ac\ud134\n    \"\"\"\n    display(df[selectList].groupby([groupbyCol], as_index=False).mean())","d54feeb1":"get_suvival_ratio(train, [\"Pclass\",\"Survived\"], \"Pclass\")","2392dfd8":"#display(train[[\"Sex\", \"Survived\"]].groupby([\"Sex\"]).mean())\nget_suvival_ratio(train, [\"Sex\", \"Survived\"], \"Sex\")","a6c3a5eb":"for dataset in full_data:\n    dataset[\"FamilySize\"] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1\n    \nget_suvival_ratio(train, [\"FamilySize\", \"Survived\"], \"FamilySize\")","fbaaba63":"for dataset in full_data:\n    dataset[\"FamilySize\"] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1\n    \nget_suvival_ratio(train, [\"FamilySize\", \"Survived\"], \"FamilySize\")","36aff1c0":"for dataset in full_data:\n    dataset[\"IsAlone\"] = 0\n    dataset.loc[dataset[\"FamilySize\"]==1, \"IsAlone\"] = 1\n    \n# \ub3d9\uc2b9\uc5ec\ubd80\uc5d0 \ub530\ub978 \uc0dd\uc874\ub960\nget_suvival_ratio(train, [\"IsAlone\", \"Survived\"], \"IsAlone\")","57dfac4d":"display(train[\"Embarked\"].value_counts())  # 72\ud37c\uc13c\ud2b8 \uac00\uae4c\uc6b4 \uc2b9\uac1d\uc774 \uc0ac\uc6b0\uc2a4\ud584\ud2bc\ubc1c \uc2b9\uac1d\ndisplay(train[\"Embarked\"].isnull().sum())\n\ndisplay(train[\"Embarked\"].value_counts() \/ train.shape[0])","b7db1119":"# 2\uac1c\uc758 \ub110\uac12\uc744 \uc0ac\uc6b0\uc2a4\ud584\ud2bc\uc73c\ub85c \ub300\uce58\nfor dataset in full_data:\n    dataset[\"Embarked\"] = dataset[\"Embarked\"].fillna(\"S\")\n    \nget_suvival_ratio(train, [\"Embarked\", \"Survived\"], \"Embarked\")","51f23908":"display(train[\"Fare\"].isnull().sum())\n\n# \uc694\uae08\uc744 5\uac1c\uc758 \uad6c\uac04\uc73c\ub85c \ubd84\ud560\ndisplay(pd.cut(train[\"Fare\"], 5))\ndisplay(pd.cut(train[\"Fare\"], 5).value_counts())\ndisplay(\"NaN\uac12 \uccb4\ud06c : \", train[\"Fare\"].isna().sum())","c88346bd":"for dataset in full_data:\n    dataset[\"Fare\"] = dataset[\"Fare\"].fillna(train[\"Fare\"].median())\n    \n# \ubc94\uc8fc\ud615 Fare\ud53c\ucc98 \ntrain[\"CategoricalFare\"] = pd.cut(dataset[\"Fare\"], 5)\n\ndisplay(train[\"CategoricalFare\"].value_counts())","41ad4fb3":"# \ubc94\uc8fc\ud615 Fare\uc5d0 \ub300\ud55c \uc0dd\uc874\ub960 \ube44\uad50\nget_suvival_ratio(train, [\"CategoricalFare\", \"Survived\"], \"CategoricalFare\")","b8b1a124":"display(\"\ub098\uc774\uc815\ubcf4\uac00 \uc5c6\ub294 \uc2b9\uac1d : \", train[\"Age\"].isnull().sum())","d91f1b3b":"for dataset in full_data:\n    avg_age = dataset[\"Age\"].mean()\n    std_age = dataset[\"Age\"].std()\n    age_null_count = dataset[\"Age\"].isnull().sum()\n    \n    # np.random.randint(low, high, size) - low\uac12\uacfc hight\uac12\uc5d0\uc11c size\ub9cc\ud07c \ubb34\uc791\uc704\uc758 \uc22b\uc790\uac12 \ub9ac\ud134\n    age_null_random_list = np.random.randint(avg_age - std_age, avg_age + std_age, age_null_count)\n    dataset[\"Age\"][np.isnan(dataset[\"Age\"])] = age_null_random_list\n    dataset[\"Age\"] = dataset[\"Age\"].astype(int)\n    \n# Age\ub97c 5\uac1c \uad6c\uac04\uc73c\ub85c \ubd84\ud560\ntrain[\"CategoricalAge\"] = pd.cut(train[\"Age\"], 5)","7b90fe93":"get_suvival_ratio(train, [\"CategoricalAge\", \"Survived\"], \"CategoricalAge\")","1913a90c":"def get_title(name):\n    \"\"\"\n    \uc774\ub984\uc5d0\uc11c \ud574\ub2f9 \uc2b9\uac1d\uc758 \uc874\uce6d \uc815\ubcf4 \ucd94\ucd9c\n    \"\"\"\n    title = None\n    title_search = re.search('([A-Za-z]+)\\.', name)\n    \n    if title_search:\n        title = title_search.group(1)\n    return title\n\n# \uc874\uce6d \ucd94\ucd9c\nfor dataset in full_data:\n    dataset[\"Title\"] = dataset[\"Name\"].apply(get_title)","f52cc1fe":"pd.DataFrame(pd.crosstab(index = train[\"Title\"], columns=train[\"Sex\"]))","ddbec68e":"train[\"Title\"].nunique()  # 17\uac1c\uc758 \uc720\uc77c\ud55c \uac2f\uc218\ntitle_list = train[\"Title\"].value_counts().index.tolist()\n\nall_title = set(title_list)\nstnd_title = set([\"Mr\", \"Miss\", \"Mrs\", \"Mlle\", \"Mme\", \"Ms\"])\n\nrare_title = list(all_title.difference(stnd_title))","291584d9":"for dataset in full_data:\n    dataset[\"Title\"] = dataset[\"Title\"].replace(rare_title, 'Rare')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n\n    # \uc874\uce6d \ud0c0\uc774\ud2c0\ub85c \uc54c\uc544\ubcf4\ub294 \uc0dd\uc874\ub960\nget_suvival_ratio(train, [\"Title\", \"Survived\"], \"Title\")    ","5dd71bae":"display(train[\"CategoricalAge\"].value_counts())\ndisplay(train[\"Age\"].describe())\ndisplay(train[\"Fare\"].describe())","1ff5ca18":"train.head()","256a6170":"for dataset in full_data:    \n    try:        \n        # Mapping Sex\n        dataset[\"Sex\"] = dataset[\"Sex\"].map({\"female\": 0 , \"male\": 1}).astype(int)\n\n        # Mapping titles\n        title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n        dataset[\"Title\"] = dataset[\"Title\"].map(title_mapping)\n        dataset[\"Title\"] = dataset[\"Title\"].fillna(0)\n\n        # Mapping Embarked\n        dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\n        # Mapping Fare based on 1st quartile, 2nd quartile, 3rd quatile\n        dataset.loc[dataset[\"Fare\"] <= 7.91, 'Fare'] = 0\n        dataset.loc[(dataset[\"Fare\"] > 7.91) & (dataset[\"Fare\"] <= 14.454), \"Fare\"] = 1\n        dataset.loc[(dataset[\"Fare\"] > 14.454) & (dataset[\"Fare\"] <= 31), \"Fare\"] = 2\n        dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n        dataset['Fare'] = dataset['Fare'].astype(int)\n\n        # Mapping Age\n        dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n        dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n        dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n        dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n        dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\n    except ValueError:\n        pass\n    except IndexError:\n        pass\n\n# Feature drop\ndrop_elements = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\", \"SibSp\", \"Parch\", \"FamilySize\"]\ntrain = train.drop(drop_elements, axis = 1, errors = \"ignore\")\ntrain = train.drop([\"CategoricalAge\", \"CategoricalFare\"], axis = 1, errors = \"ignore\")\ntest  = test.drop(drop_elements, axis = 1, errors = \"ignore\")\n\ndisplay (train.head(n=3))\ndisplay(test.head(n=3))\n\ntrain = train.values\ntest  = test.values","57528071":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\n\n# classification\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\n# decomposition\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n\n#\ud68c\uadc0\nfrom sklearn.linear_model import LogisticRegression","454997be":"def train_predict(X, y, classifiers: list):\n    \"\"\"\n    \ud559\uc2b5 \ud53c\ucc98\uc640 \ub808\uc774\ube14 \uac12\uc744 \uc778\uc790\ub85c \ubc1b\uc544\uc11c  \uc815\ud655\ub3c4\uc640 \ubd84\ub958\uae30\ubcc4 \uc815\ud655\ub3c4\ub97c DataFrame\uc73c\ub85c \ub9ac\ud134\n    \"\"\"\n    # StratifiedKFold\uc640 ShuffleSplit\uc758 \uae30\ub2a5\uc744 \uac16\uace0\uc788\uc74c\n    # \uac80\uc99d \uc778\ub371\uc2a4\uc640 \ud559\uc2b5\uc778\ub371\uc2a4\ub97c \ub098\ub204\uc5b4\uc11c \ub9ac\ud134\ud568\n    # \uc778\uc790\ub294 \ud53c\ucc98\ubc30\uc5f4\uacfc \ub808\uc774\ube14 \ubc30\uc5f4\uc744 1\ucc28\uc6d0 \ubc30\uc5f4\uc758 \ud615\ud0dc\ub85c \uc804\ub2ec\n    sss = StratifiedShuffleSplit(n_splits = 10, test_size = .3, random_state=0)\n    \n    accuracy = {}\n    log_cols = ['Classifiers', 'Accuracy']\n    \n    for train_index, test_index in sss.split(X, y):\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n        \n        for clf in classifiers:\n            clf.fit(X_train, y_train)\n            train_prediction = clf.predict(X_test)\n            \n            acc = accuracy_score(y_test, train_prediction)\n            \n            model = clf.__class__.__name__\n            \n            if model in accuracy:\n                accuracy[model] += acc\n            else:\n                accuracy[model] = acc\n                \n    for k, _ in accuracy.items():\n        accuracy[k] = accuracy[k] \/ 10.0\n        \n    # \ub9ac\ud134\ud560 \ub370\uc774\ud130\ud504\ub808\uc784 \uc0dd\uc131    \n    accuracy_df = pd.DataFrame([[k, v] for k, v in accuracy.items()], columns = log_cols)\n    \n    return accuracy, accuracy_df\n\ndef visualize_accuracy(accuracy_df):\n    \"\"\"\n    \ubd84\ub958\uae30\ubcc4 \uc815\ud655\ub3c4\ub97c \uc2dc\uac01\ud654(barplot)\n    \"\"\"\n    # \uc2dc\uac01\ud654\n    plt.xlabel(\"Accuracy\")\n    plt.title(\"Accuracy by Classifiers\")\n\n    # color='b'\uc635\uc158\uc744 \uc8fc\uba74 \uc0c9\uc774 \ud30c\ub780\uc0c9 \ud558\ub098\ub85c \ud1b5\uc77c\n    sns.barplot(x = \"Accuracy\", y=\"Classifiers\", data = accuracy_df)\n    sns.set_color_codes(\"muted\")\ndef main_process(X, y, classifiers):\n    accuracy, accuracy_df = train_predict(X, y, classifiers)\n    visualize_accuracy(accuracy_df)","4a0f99ce":"classifiers = [\n    KNeighborsClassifier(n_neighbors = 10),\n    SVC(C = 0.05, gamma=\"auto\", probability=True),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(n_estimators=500),\n    AdaBoostClassifier(n_estimators=500, learning_rate = 0.5),\n    GradientBoostingClassifier(learning_rate=0.5, n_estimators = 500),\n    GaussianNB(),\n    LinearDiscriminantAnalysis(),\n    QuadraticDiscriminantAnalysis(),\n    LogisticRegression()\n]\n\nlog_cols = [\"Classifiers\", \"Accuracy\"]\n\n# train_index\uc640 test_index\ub97c \ub9ac\ud134\ud568\nsss= StratifiedShuffleSplit(n_splits = 10, test_size = .1, random_state = 0)\n\nX = train[:, 1:]\ny = train[:, 0]\n\naccuracy = {}\n\nfor train_idx, test_idx in sss.split(X, y):\n    X_train, X_test = X[train_idx], X[test_idx]\n    y_train, y_test = y[train_idx], y[test_idx]\n    \n    for clf in classifiers:\n        clf.fit(X_train, y_train)\n        train_prediction = clf.predict(X_test)\n        \n        acc = accuracy_score(y_test, train_prediction)\n        \n        model = clf.__class__.__name__\n        if model in accuracy:\n            accuracy[model] += acc\n        else:\n            accuracy[model] = acc\n\nfor k, _ in accuracy.items():\n    accuracy[k] = accuracy[k] \/ 10.0\n    \naccuracy_df = pd.DataFrame([[k, v] for k, v in accuracy.items()], columns = log_cols)","6f5fa6e3":"# \uc2dc\uac01\ud654\nplt.xlabel(\"Accuracy\")\nplt.title(\"Accuracy by Classifiers\")\n\n# color='b'\uc635\uc158\uc744 \uc8fc\uba74 \uc0c9\uc774 \ud30c\ub780\uc0c9 \ud558\ub098\ub85c \ud1b5\uc77c\nsns.barplot(x = \"Accuracy\", y=\"Classifiers\", data = accuracy_df)\nsns.set_color_codes(\"muted\")","d58c8ccd":"# \ud568\uc218\ub85c \uc7ac\uc791\uc131 \ud6c4 \uc218\ud589\nmain_process(X, y, classifiers)","2ed015b5":"final_clf = SVC()\nfinal_clf.fit(X, y)\n\nresult = final_clf.predict(test)\n\nfinal_submission = pd.DataFrame(data = {\"PassengerId\": PassengerId, \"Survived\": result})\n\ndisplay(final_submission.head(n=3))\n\nfinal_submission.to_csv(target_dir + \"titanic_survival_prediction.csv\")","72f24040":"survivor_prediction = pd.read_csv(target_dir + \"titanic_survival_prediction.csv\")\ndisplay(survivor_prediction.head(n=3))\ndisplay(survivor_prediction.tail(n=3))","2caca080":"**Miss, Mrs\uc758 \uc0dd\uc874\ub960\uc774 Mr\ubcf4\ub2e4 5\ubc30 \uac00\uae4c\uc774 \ub192\uc74c. \ud2b9\uc774\ud55c \uc810\uc740 Rare\uac00 Mr\ubcf4\ub2e4 \ub192\uc74c**\n\n**Miss, Mrs title has more chance to survive than Mr, Rare title by 5 times.**","da7731b9":"* Modulization\n* [StratifiedKFold Official Document](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.StratifiedShuffleSplit.html)","9292834a":"# \ubd84\ub958\uae30 \ube44\uad50 #\n## \uad00\ub828 \ub77c\uc774\ube0c\ub7ec\ub9ac","6ce62e2a":"## 2. Sex ##","be29391f":"**Read Evaluate Print Loop**","1d617848":"**IsAlone - 0(\ub3d9\ud589\uc2b9\uac1d\uc774 \uc5c6\ub294 \uacbd\uc6b0) - \uc0dd\uc874\ub960\uc774 \uadf8\ub807\uc9c0 \uc54a\uc740 \uacbd\uc6b0\ubcf4\ub2e4 \ub0ae\ub2e4.(\uc758\ubbf8\uc788\ub294 \uacb0\uacfc)**","48ba1653":" * Title\ud53c\ucc98\uc758 \ubc94\uc8fc\ud615 \ud53c\ucc98\ub85c \ubcc0\ud658 \ud6c4 \uc0dd\uc874\ub960 \ud655\uc778","5f5c6bf9":"## 4. Embarked ##","28f10b36":"# \ud53c\ucc98 \uc5d4\uc9c0\ub2c8\uc5b4\ub9c1 #","496d78bb":"## 7. Name ##\n\uc774\ub984\uc73c\ub85c \ubd80\ud130 \uc874\uce6d \uc815\ubcf4\ub97c \ucd94\ucd9c","b7c3c050":"## 6. Age ##\n\n\uacb0\uce21\uce58\ub97c \ub300\uce58\ud558\uae30 \uc704\ud574 \ud3c9\uade0\uac12\uacfc \ud45c\uc900\ud3b8\ucc28\ub97c \uc774\uc6a9\ud574\uc11c \ubb34\uc791\uc704\uc758 \uac12\uc744 \uacb0\uce21\uce58 \uac2f\uc218\ub9cc\ud07c \uc0dd\uc131\ud574\uc11c \ub300\uce58\ud568.\uc88b\uc740 \ubc29\ubc95!!\n\nAge\ud53c\ucc98\uc758 \ubc94\uc8fc\ud615 \uc22b\uc790\uac12\uc73c\ub85c \ubcc0\ud658\ud0a4\uc704\ud574 pd.cut()\uc774\uc6a9\ud574 5\uac1c \ubc94\uc704\ub85c \ubd84\ud560","4bba4bb2":"**\ud568\uc218**","66b9dfee":"* \ub3d9\ubc18\uc2b9\uac1d\uc5ec\ubd80 \ud53c\ucc98 \uc0dd\uc131 - IsAlone","a9cc3d77":"\uc694\uae08\ub300\uac00 384\ub2ec\ub7ec\uc5d0\uc11c 512\ub2ec\ub7ec\ub300\uc758 \uc2b9\uac1d\uc740 \uc804\ubd80 \uc0ac\ub9dd\ud588\uace0 \ub610\ud55c \uc694\uae08\ub300\uac00 128\ub2ec\ub7ec \uc774\ud558\uc778 \uc2b9\uac1d\ub4e4\uc758 \uc0dd\uc874\ub960\ub3c4 \ub192\uc9c0 \uc54a\ub2e4.","5d070f2e":"**\ud568\uc218 \ud638\ucd9c**","65cf18f0":"## \uc18c\uac1c ##\n\n\uba38\uc2e0\ub7ec\ub2dd\uc744 \uc5f0\uad6c\ud558\uae30 \uc704\ud574 \uc9c4\ud589\ud558\ub294 \uce90\uae00 \ud544\uc0ac \ud504\ub85c\uc81d\ud2b8\ub85c \uc774 \ucf00\uae00\uc758 \uc601\uac10\uc740 \uc544\ub798 \uae00\ub85c\ubd80\ud130 \uc5bb\uc5c8\uc2b5\ub2c8\ub2e4.\n\nR\uc744 \ube45\ub370\uc774\ud130 \ubd84\uc11d \uac15\uc758\ub97c \ub4e4\uc744\ub54c \uc774\ud6c4\uc5d0\ub294 \ub9cc\uc9c0\uc9c0 \uc54a\uc558\ub294\ub370 \uc2dc\uac04\uc774 \ub41c\ub2e4\uba74 R\ub85c\ub3c4 \ud574\ubcf4\uba74 \uad1c\ucc2e\uc744 \uac83 \uac19\uc2b5\ub2c8\ub2e4.\n\n\ud310\ub2e4\uc2a4\uc758 \uae30\ub2a5 \ub300\ubd80\ubd84\uc774 R\ub85c\ubd80\ud130 \ub098\uc628\uac83\uc774\uace0 , RDBMS\uc5d0\uc11c \uc81c\uacf5\ud558\ub294 \ubaa8\ub4e0 \ucffc\ub9ac\ubb38\uc758 \uae30\ub2a5\ub3c4 \ub2e4 R\uc5d0\uc11c \uc9c0\uc6d0\ub41c\ub2e4\uace0 \ubcf4\uba74 \ub429\ub2c8\ub2e4.\n\n[\"Exploring Survival on Titanic\" by Megan Risdal, a Kernel in R on Kaggle][1]\n\nI am going to try the following code on R tool as far as I could.\n\n  [1]: https:\/\/www.kaggle.com\/mrisdal\/titanic\/exploring-survival-on-the-titanic","9bd3647e":"\uac00\uc871\uc758 \uaddc\ubaa8\uac00 \ud074\uc218\ub85d \uc0dd\uc874\ub960\uc774 \ub5a8\uc5b4\uc9d0\uc744 \uc54c \uc218 \uc788\ub2e4.\n\nIt seems that the family size feature has a meaningful effect on the survival ratio.","cbc36025":"**REPL(Read Evaluate Print Loop)**","97f7f948":"## 5. Fare ##\nFare also has some missing value and we will replace it with the median. then we categorize it into 4 ranges.","89158502":"# Data Cleaning #\n\ub370\uc774\ud130\uc815\uc81c \ubc0f \ubc94\uc8fc\ud615 \ud0c0\uc785\uc758 \ub370\uc774\ud130\ub97c \uc22b\uc790\ud615\uc73c\ub85c \ubcc0\ud658","e64e0b79":"* \uac1d\uc2e4\ub4f1\uae09\ubcc4 \uc0dd\uc874\ub960","d56fb4c7":"# Prediction #\nSVM\ub97c \ucd5c\uc885 \uc0ac\uc6a9\ud574\uc11c \ud559\uc2b5 \ubc0f \uc608\uce21","1fc33b58":"## \ubcc0\uc218 \uc124\uba85 ##\n\n* Survived: \uc0dd\uc874 \uc5ec\ubd80 => 0 = No, 1 = Yes\n* pclass: \ud2f0\ucf13 \ub4f1\uae09 => 1 = 1st, 2 = 2nd, 3 = 3rd\n* Sex: \uc131\ubcc4\n* Age: \ub098\uc774\n* SibSp: \ud568\uaed8 \ud0d1\uc2b9\ud55c \ud615\uc81c\uc790\ub9e4(Siblings), \ubc30\uc6b0\uc790\uc758 \uc218(Spouse)\n* Parch: \ud568\uaed8 \ud0d1\uc2b9\ud55c \ubd80\ubaa8(Parents), \uc790\uc2dd\uc758 \uc218(Children)\n* Ticket: \ud2f0\ucf13 \ubc88\ud638\n* Fare: \uc6b4\uc784\n* Cabin: \uac1d\uc2e4 \ubc88\ud638\n* Embarked: \ud0d1\uc2b9 \ud56d\uad6c => C = Cherbourg, Q = Queenstown, S = Southampton","dffc78b1":"**\ubaa8\ub4c8\ud654**","1332a53e":"## 1. Pclass ##\n\ub110\uac12\uc774 \uc874\uc7ac\ud558\uc9c0 \uc54a\uc73c\uba70,\uc22b\uc790\ud615 \ud0c0\uc785","258e28f5":"* \uc0ac\uc6b0\uc2a4\ud584\ud2bc \ubc1c \uc2b9\uac1d\uc758 \uc0dd\uc874\ub960\uc774 \ud504\ub791\uc2a4 \uccb4\ub974\ubcf4\ub974\uadf8(C) \ubc0f \ub274\uc9c8\ub79c\ub4dc \ud038\uc988\ud0c0\uc6b4(Q) \ud56d\uad6c\uc5d0\uc11c \ud0d1\uc2b9\ud55c \uc2b9\uac1d\uc758 \uc0dd\uc874\ub960\ubcf4\ub2e4 \ub0ae\uc74c\uc744 \uc54c\uc218\uc788\ub2e4.","c8b843e7":"## 3. SibSp and Parch ##\nSibSp - \uc790\uc190 \ubc0f \ubc30\uc6b0\uc790, Parch - \uc544\uc774\ub4e4\/\ubd80\ubaa8\ub2d8 - \uc774 \ub450 \ud53c\ucc98\ub97c \uc774\uc6a9\ud574 \uac00\uc871\uc758 \uaddc\ubaa8\ub97c \uc720\ucd94\ud574\ubcfc \uc218 \uc788\ub294 FamilySize\ud53c\ucc98\ub97c \uc0dd\uc131","19fdbf5f":"**Age lower than 15 have more chance to survive than other Age band.**"}}