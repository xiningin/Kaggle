{"cell_type":{"857eb775":"code","5460259a":"code","de355eb9":"code","5ac3ca04":"code","652c4271":"code","564f06c6":"code","eaecf4ac":"code","183c17de":"code","ed8a2b27":"code","6317f6e5":"code","025a8cbc":"code","f63c4db6":"code","078ab968":"code","beb8a128":"code","b0b05886":"code","88f13d0f":"code","5512b345":"code","6f32b69f":"code","baf2d700":"code","6ec0f03d":"code","2594377b":"code","18294440":"code","e19ef2fe":"code","f54f209b":"code","dfdfa110":"code","9350fcfe":"code","a797b7f6":"code","b941289d":"code","be6462b9":"code","5ca4c6fb":"code","107c60df":"code","82541d88":"code","f971611a":"code","f3d2b4e3":"code","b093adec":"code","474c9b30":"code","89958b00":"code","87f202ee":"code","59008456":"code","1b9b1aa7":"code","aab89fa0":"code","8bbed32e":"code","9fa8583a":"code","f655f9c2":"markdown","279cceca":"markdown","fc90aa50":"markdown","6556f0ec":"markdown","ffad3247":"markdown","a70afb60":"markdown"},"source":{"857eb775":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","5460259a":"# Load the train data\ntitanic_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\n# Load the test data\ntitanic_test= pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_result=pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\n# Check the data\ntitanic_train","de355eb9":"# Check the test data\ntitanic_test","5ac3ca04":"titanic=[titanic_train,titanic_test]","652c4271":"# Descriptive statistics are very useful for initial exploration of the variables\n# By default, only descriptives for the numerical variables are shown\n# To include the categorical ones, you should specify this with an argument\ntitanic_train.describe(include='all')\n\n# Note that categorical variables don't have some types of numerical descriptives\n# and numerical variables don't have some types of categorical descriptives","564f06c6":"titanic_test.describe(include='all')","eaecf4ac":"#count rows and columns\ntitanic_train.shape","183c17de":"#No. of passengers died and survived\ntitanic_train.Survived.value_counts()","ed8a2b27":"sns.countplot(titanic_train.Survived)","6317f6e5":"titanic_train.columns","025a8cbc":"titanic_train.isnull().sum()","f63c4db6":"titanic_test.isnull().sum()","078ab968":"#delete the cabin feature\/column and others previously stated to exclude in train and test dataset\ndrop_column = ['PassengerId','Cabin', 'Ticket','Name']\nfor dataset in titanic:\n    dataset.drop(drop_column, axis=1, inplace = True)","beb8a128":"for dataset in titanic:\n#complete missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n\n#complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace = True)\n\n#complete missing fare with median\n    dataset['Fare'].fillna(dataset['Fare'].median(), inplace = True)","b0b05886":"titanic_train.isnull().sum()","88f13d0f":"titanic_test.isnull().sum()","5512b345":"titanic_train.describe(include='all')","6f32b69f":"titanic_test.describe(include='all')","baf2d700":"titanic_train.columns","6ec0f03d":"# Visualize the count of passengers survived for the columns 'Pclass','Sex','Age','SibSp','Parch','Fare','Embarked'\n\ncols=['Pclass','Sex','SibSp','Parch']\n\nn_rows=2\nn_cols=2\n\nfig,axs=plt.subplots(n_rows,n_cols,figsize=(n_rows*5,n_cols*5))\nfor r in range(n_rows):\n    for c in range(n_cols):\n        i=r*n_cols+c\n        ax=axs[r][c]\n        sns.countplot(titanic_train[cols[i]],hue=titanic_train.Survived,ax=ax)\n        ax.legend(title='survived',loc='upper right')\nplt.tight_layout","2594377b":"fig,axs=plt.subplots(1,1,figsize=(5,5))\nsns.countplot(y=titanic_train['Embarked'],hue=titanic_train.Survived,ax=axs)","18294440":"titanic_train.groupby('Sex')[['Survived']].mean()","e19ef2fe":"titanic_train.pivot_table('Survived',index='Sex',columns='Pclass')","f54f209b":"titanic_train.pivot_table('Survived',index='Sex',columns='Pclass').plot()","dfdfa110":"sns.barplot(x='Pclass',y='Survived',data=titanic_train)","9350fcfe":"age=pd.cut(titanic_train['Age'],[0,18,80])\ntitanic_train.pivot_table('Survived',['Sex',age],'Pclass')","a797b7f6":"sns.barplot(x=age,y='Survived',data=titanic_train)","b941289d":"Fare=pd.cut(titanic_train['Fare'],range(0,551,50))\ntitanic_train.pivot_table('Survived',['Sex',Fare],'Pclass')","be6462b9":"sns.barplot(x=Fare,y='Survived',data=titanic_train)","5ca4c6fb":"Class=titanic_train.Pclass.map({1:'First',2:'Second',3:'Third'})\nplt.scatter(titanic_train.Fare,Class,label='Passenger Paid')\nplt.ylabel('Class')\nplt.xlabel('Price')\n\nplt.title('Price of each class')\nplt.legend()\nplt.show()","107c60df":"#Visualized the train data\n#Final train data set\ntitanic_train.head()","82541d88":"titanic_train.shape","f971611a":"titanic_test.dtypes","f3d2b4e3":"#Labeling the object datas\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder=LabelEncoder()\nfor dataset in titanic:\n#Encode the Sex column\n    dataset.loc[:,'Sex']=labelencoder.fit_transform(dataset.loc[:,'Sex'].values)\n#Encode the Embarked column\n    dataset.loc[:,'Embarked']=labelencoder.fit_transform(dataset.loc[:,'Embarked'].values)","b093adec":"titanic_train","474c9b30":"# The target(s) (dependent variable) is 'Survived'\nY_train = titanic_train['Survived']\n\n# The inputs are everything BUT the dependent variable, so we can simply drop it\nX_train = titanic_train.drop(['Survived'],axis=1)\n\nX_test = titanic_test","89958b00":"#scale data\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nX_train=sc.fit_transform(X_train)\nX_test=sc.fit_transform(X_test)","87f202ee":"#create a fuction with many ml models\ndef models(X_train,Y_train):\n    # use logistic regression model\n    from sklearn.linear_model import LogisticRegression\n    log=LogisticRegression(random_state=0)\n    log.fit(X_train,Y_train)\n    \n    #use KNeighbors\n    from sklearn.neighbors import KNeighborsClassifier\n    knn=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\n    knn.fit(X_train,Y_train)\n    \n    #use SVC (linear kernel)\n    from sklearn.svm import SVC\n    svc_lin=SVC(kernel='linear',random_state=0)\n    svc_lin.fit(X_train,Y_train)\n    \n    #use SVC (RBF kernel)\n    from sklearn.svm import SVC\n    svc_rbf=SVC(kernel='rbf',random_state=0)\n    svc_rbf.fit(X_train,Y_train)\n    \n    #use GaussianNB\n    from sklearn.naive_bayes import GaussianNB\n    gauss=GaussianNB()\n    gauss.fit(X_train,Y_train)\n    \n    #use Decision Tree\n    from sklearn.tree import DecisionTreeClassifier\n    tree=DecisionTreeClassifier(criterion='entropy',random_state=0)\n    tree.fit(X_train,Y_train)\n    \n    #use Random forest classifier\n    from sklearn.ensemble import RandomForestClassifier\n    forest=RandomForestClassifier(n_estimators=10,criterion='entropy',random_state=0)\n    forest.fit(X_train,Y_train)\n    \n    \n    #print the training accuracy\n    print('[0]Logistic Regression Training Accuracy: ', log.score(X_train,Y_train))\n    print('[1]KNeighbors Training Accuracy: ', knn.score(X_train,Y_train))\n    print('[2]SVC Linear Training Accuracy: ', svc_lin.score(X_train,Y_train))\n    print('[3]SVC RBF Training Accuracy: ', svc_rbf.score(X_train,Y_train))\n    print('[4]Gaussian NB Training Accuracy: ', gauss.score(X_train,Y_train))\n    print('[5]Decision Tree Training Accuracy: ', tree.score(X_train,Y_train))\n    print('[6]Random Forest Training Accuracy: ', forest.score(X_train,Y_train))\n    \n    return log,knn,svc_lin,svc_rbf,gauss,tree,forest\n\n    ","59008456":"#train all the models\nmodel=models(X_train,Y_train)","1b9b1aa7":"Final_test=test_result.copy()","aab89fa0":"Final_test['Survived']=model[4].predict(X_test)","8bbed32e":"Final_test","9fa8583a":"Final_test.to_csv(r'C:\\Users\\trina\\Titanic1\\Final_test.csv',index=False)","f655f9c2":"# Machine Learning Model","279cceca":"# DATA IMPORT","fc90aa50":"# Some columns have missing data\n","6556f0ec":"# Visualizing the train data","ffad3247":"<h1 style=\"color:blue\" align=\"center\"> Titanic <\/h1>\n<br>\n\n![](http:\/\/media.giphy.com\/media\/1Nk9bIidJVTy0\/giphy.gif)\n\n\n- 10th April 1912, 6.35 p.m. The Titanic entered **Cherbourg harbour,** the largest artificial harbour in the world...\n\n- Cherbourg (full name Cherbourg-Octeville) is a city at the North-Eastern part of the France (Cotentin peninsula, to be precise). It's mention is important since it's the Titanic's first station after departing from Southampton.\n\n\n- **Queenstown** (today Cobh) is a city on the southwest of **Ireland.** It was the last port Titanic arrived on her maiden voyage to before heading towards **New York.**\n\n- The massive ship, which carried **2,200 passengers and crew,** had struck an iceberg two and half hours before.","a70afb60":"# Rich Adult Female Passenger who embarked on C, boarded on 1st Class and was travelling with one sibling\/spouse\/parent\/child had the best chance of surviving"}}