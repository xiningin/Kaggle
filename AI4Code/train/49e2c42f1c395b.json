{"cell_type":{"4c9276e9":"code","3e736086":"code","02314ae9":"code","050c7a3d":"code","c3ceae1e":"code","b578f315":"code","8e4e257f":"code","5cfe56ad":"code","3f5f5e17":"code","a3a9e41b":"code","f6a04b18":"code","ae7cdcc4":"code","b9d9d781":"code","87656b95":"code","82ba3729":"code","20b48fd7":"code","bb064302":"code","0c007ed5":"code","8fe03831":"code","a046e53b":"code","ffb43e7e":"code","7abbfbff":"code","33753655":"code","34412a02":"code","74ca285c":"code","ceb96c9b":"code","64529f2d":"code","52c8d41d":"code","184445d3":"code","29d9db3d":"code","94c00667":"code","21ac827f":"code","572d856f":"code","7cabd870":"code","7b97bee9":"code","bde63020":"code","706ce97f":"code","115cf48b":"code","6aa77008":"code","f356e8d2":"code","a663fead":"code","feb86410":"code","b787fe3c":"code","0390a25d":"code","bd7bf048":"code","b75fe5c0":"code","db5221e0":"code","0f6f58e7":"code","bf7e1b17":"code","0b91e730":"code","63595933":"code","e1f6aab7":"code","d3719675":"code","ff66a94b":"code","ec2effe7":"code","b32bec0b":"code","ff55c74a":"code","154450e0":"code","792ebc08":"code","7aa098f8":"code","9227880d":"code","9fadbc79":"code","f4c23c80":"code","c238d3a5":"code","37621c37":"code","0c0829d2":"code","91783754":"markdown","ab62a7fc":"markdown","b91f74e7":"markdown","6cf3b1e8":"markdown","dbe473fb":"markdown"},"source":{"4c9276e9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport seaborn as sns \n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3e736086":"df = pd.read_csv('\/kaggle\/input\/bank-customer-churn-modeling\/Churn_Modelling.csv')\ndf.head()","02314ae9":"df.info()","050c7a3d":"df.drop('RowNumber',axis = 1 , inplace = True)\ndf.head()","c3ceae1e":"plt.figure(figsize = (10,8))\nplt.bar(df['Exited'],df['Tenure'] )\nplt.xlabel('Exited')\nplt.ylabel('Tenure')\nplt.title('Tenure vs Exited Graph')\nplt.show()","b578f315":"def unique_values_and_length(df):\n    for column in df : \n        if df[column].dtypes == 'object':\n            print(f'{column}:{df[column].unique()}:{len(df[column].unique())}')\nunique_values_and_length(df)","8e4e257f":"s = (df.dtypes == 'object')\nobject_cols = list(s[s].index)\nprint('Categorical Variables: ', object_cols)","5cfe56ad":"df1 = df.copy() \n\nfrom sklearn.preprocessing import OrdinalEncoder\n\nencoder = OrdinalEncoder()\n\n\ndf1[object_cols] = encoder.fit_transform(df1[object_cols])\n\n\ndf1.head()","3f5f5e17":"scaled_columns = ['CreditScore','Age','Balance','EstimatedSalary']\n\nfrom sklearn.preprocessing import StandardScaler\n\nscalar = StandardScaler()\n\ndf1[scaled_columns] = scalar.fit_transform(df1[scaled_columns])\n\ndf1.head()\n","a3a9e41b":"features = df1.drop(['CustomerId','Exited'],axis = 1)\nlabel = df1['Exited']","f6a04b18":"from sklearn.model_selection import train_test_split\n\nx_train,x_test,y_train,y_test = train_test_split(features,label,test_size = 0.2 ,random_state = 1)\n\nprint('x train shape: ',x_train.shape)\nprint('y train shape: ',y_train.shape)\nprint('x test shape: ',x_test.shape)\nprint('y test shape: ',y_test.shape)","ae7cdcc4":"from sklearn.neural_network import MLPClassifier\n\nmodel = MLPClassifier()\n\nmodel.fit(x_train,y_train)\nmodel.score(x_test,y_test)","b9d9d781":"y_pred = model.predict(x_test)\ny_pred[:5]","87656b95":"y_test[:5]","82ba3729":"from sklearn.metrics import classification_report , accuracy_score , confusion_matrix\n\nprint(classification_report(y_test,y_pred))","20b48fd7":"score = accuracy_score(y_test,y_pred)\nprint('Accuracy Score : ', score)","bb064302":"df2 = df1.copy()","0c007ed5":"df2['Exited'].value_counts()","8fe03831":"exited_0 = df2[df2['Exited'] == 0]\nexited_1 = df2[df2['Exited'] == 1]\n\nprint('Shape of exited_0: ',exited_0.shape)\nprint('Shape of exited_1: ',exited_1.shape)","a046e53b":"exited_o_undersample = exited_0.sample(len(exited_1))\nprint(\"Exited_0 under sample: \",exited_o_undersample.shape)","ffb43e7e":"df2_exited = pd.concat([exited_1,exited_o_undersample],axis =0)\ndf2_exited['Exited'].value_counts()","7abbfbff":"df2_exited.head()","33753655":"df2_feature = df2_exited.drop(['CustomerId','Exited'],axis = 1)\ndf2_label = df2_exited['Exited']","34412a02":"df2_feature.shape","74ca285c":"df2_label.shape","ceb96c9b":"from sklearn.model_selection import train_test_split\n\ndf2_x_train,df2_x_test,df2_y_train,df2_y_test = train_test_split(df2_feature,df2_label,test_size = 0.2 ,random_state = 1,stratify = df2_label)\n\nprint('df2_x_train shape: ',df2_x_train.shape)\nprint('df2_y_train shape: ',df2_y_train.shape)\nprint('df2_x_test shape: ',df2_x_test.shape)\nprint('df2_y_test shape: ',df2_y_test.shape)","64529f2d":"from sklearn.neural_network import MLPClassifier\n\nmodel = MLPClassifier()\n\nmodel.fit(df2_x_train,df2_y_train)\nmodel.score(df2_x_test,df2_y_test)","52c8d41d":"df2_y_pred = model.predict(df2_x_test)","184445d3":"from sklearn.metrics import classification_report , accuracy_score , confusion_matrix\n\nprint(classification_report(df2_y_test,df2_y_pred))","29d9db3d":"df2['Exited'].value_counts()","94c00667":"df3 = df2.copy()","21ac827f":"exited_0 = df3[df3['Exited'] == 0]\nexited_1 = df3[df3['Exited'] == 1]\n\nprint('Shape of exited_0: ',exited_0.shape)\nprint('Shape of exited_1: ',exited_1.shape)","572d856f":"df3_exited_1_over = exited_1.sample(len(exited_0),replace = True)\ndf3_exited_1_over.shape","7cabd870":"df3 = pd.concat([exited_0,df3_exited_1_over],axis =0)\ndf3['Exited'].value_counts()","7b97bee9":"df3.head()","bde63020":"df3_feature = df3.drop(['CustomerId','Exited'],axis = 1)\ndf3_label = df3['Exited']","706ce97f":"df3_feature.shape","115cf48b":"df3_label.shape","6aa77008":"from sklearn.model_selection import train_test_split\n\ndf3_x_train,df3_x_test,df3_y_train,df3_y_test = train_test_split(df3_feature,df3_label,test_size = 0.2 ,random_state = 1,stratify = df3_label)\n\nprint('df3_x_train shape: ',df3_x_train.shape)\nprint('df3_y_train shape: ',df3_y_train.shape)\nprint('df3_x_test shape: ',df3_x_test.shape)\nprint('df3_y_test shape: ',df3_y_test.shape)","f356e8d2":"import tensorflow as tf \nfrom tensorflow import keras ","a663fead":"model = tf.keras.Sequential([\n    keras.layers.Dense(30,input_shape= (11,),activation = 'relu'),\n    keras.layers.Dense(30,activation = 'relu'),\n    keras.layers.Dense(1,activation = 'sigmoid')    \n])\n\nmodel.compile(\n    optimizer = 'adam',\n    loss = 'binary_crossentropy',\n    metrics = ['accuracy']\n)\n\n\nmodel.fit(df3_x_train,df3_y_train,epochs = 100)","feb86410":"model.evaluate(df3_x_test,df3_y_test)","b787fe3c":"df3_yp = model.predict(df3_x_test)","0390a25d":"df3_yp[:5]","bd7bf048":"df3_y_pred = []\n\nfor element in df3_yp : \n    if element > 0.5 : \n        df3_y_pred.append(1)\n    else : \n        df3_y_pred.append(0)","b75fe5c0":"df3_y_pred[:5]","db5221e0":"df3_y_test[:5]","0f6f58e7":"from sklearn.metrics import classification_report,accuracy_score\n\nprint(classification_report(df3_y_test,df3_y_pred))","bf7e1b17":"score = accuracy_score(df3_y_test,df3_y_pred)\nprint('Accuracy Score: ',score)","0b91e730":"df4_feature = features.copy()\ndf4_label = label.copy()","63595933":"df4_feature.sample(5)","e1f6aab7":"df4_label.sample(5)","d3719675":"df4_label.value_counts()","ff66a94b":"from imblearn.over_sampling import SMOTE    ","ec2effe7":"smote = SMOTE(sampling_strategy = 'minority')\nfeature_smote , label_smote = smote.fit_resample(df4_feature,df4_label)\n\nlabel_smote.value_counts()","b32bec0b":"from sklearn.model_selection import train_test_split\n\ndf4_x_train,df4_x_test,df4_y_train,df4_y_test = train_test_split(feature_smote,label_smote,test_size = 0.2 ,random_state = 1,stratify = df3_label)\n\nprint('df3_x_train shape: ',df3_x_train.shape)\nprint('df3_y_train shape: ',df3_y_train.shape)\nprint('df3_x_test shape: ',df3_x_test.shape)\nprint('df3_y_test shape: ',df3_y_test.shape)","ff55c74a":"import tensorflow as tf \nfrom tensorflow import keras ","154450e0":"model = tf.keras.Sequential([\n    keras.layers.Dense(30,input_shape= (11,),activation = 'relu'),\n    keras.layers.Dense(30,activation = 'relu'),\n    keras.layers.Dense(1,activation = 'sigmoid')    \n])\n\nmodel.compile(\n    optimizer = 'adam',\n    loss = 'binary_crossentropy',\n    metrics = ['accuracy']\n)\n\n\nmodel.fit(df4_x_train,df4_y_train,epochs = 200)","792ebc08":"model.evaluate(df4_x_test,df4_y_test)","7aa098f8":"df4_yp = model.predict(df4_x_test)\ndf4_yp[:10]","9227880d":"df4_y_pred = []\n\nfor element in df4_yp: \n    if element > 0.5 : \n        df4_y_pred.append(1)\n    else : \n        df4_y_pred.append(0)\n","9fadbc79":"print(df4_y_test[:5])","f4c23c80":"print(df4_y_pred[:5])","c238d3a5":"from sklearn.metrics import classification_report , accuracy_score , confusion_matrix\n\nprint(classification_report(df4_y_test,df4_y_pred))","37621c37":"cm = confusion_matrix(df4_y_test,df4_y_pred)\nplt.figure(figsize = (5,4))\nsns.heatmap(cm,annot = True)\n\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\n\nplt.show()","0c0829d2":"score = accuracy_score(df4_y_test,df4_y_pred)\nprint('Acc Score: ' , score)","91783754":"This is because , we have an imbalance dataset ,where in Exited we have '0': 7963 values,\nand '1' values are: 2037 . \nSo we can see model will create a biased opinion towards 0 .","ab62a7fc":"Now by this method we got less accuracy , so we will try second method of oversample the 1 values to the shape of 0 ","b91f74e7":"Problem with this model is , \nIn recall you will find 1's value as 0.24 which is bad simalarly the f1 score of 1 is bad . \n","6cf3b1e8":"Third method is SMOTE ","dbe473fb":"To solve this problem we have three techniques : \n1) Undersample the 0 values to the shape of 1 ,\ncheck the code below "}}