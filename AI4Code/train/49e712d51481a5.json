{"cell_type":{"9b3706ad":"code","e9baf8c2":"code","2e1f5e0a":"code","4010f5a4":"code","44cb6acb":"code","a60ee911":"code","083b2cb8":"code","889f7665":"code","9afe4124":"code","3edd9371":"code","b244c131":"code","f7078fed":"code","66e43ebc":"code","ac4c4a8e":"code","633c4b6e":"code","40a53c3a":"code","a4cc740d":"code","f26f7e45":"code","9111a81d":"code","156440a8":"code","326d34c6":"code","8fb01e88":"code","aad3c9af":"code","6e0e6157":"code","66bffca4":"code","6edb957a":"code","9a3d0ba2":"code","08830eeb":"code","8c708571":"code","14d0bd45":"code","bfa15ea2":"code","f447fdc8":"code","ff24f731":"code","82fa33e1":"code","e2bbd181":"code","0da60890":"code","97242700":"code","26c0039c":"code","e3325ee3":"code","a58bc384":"code","ac357491":"code","e72a1209":"code","51899d0e":"code","a96dda71":"code","0ea946d6":"code","060556f4":"code","e0978b2f":"code","c26c2120":"code","86840efa":"code","54a1c9f8":"code","44c2ec68":"code","43e1f38c":"code","05468b69":"code","0cef1192":"code","f1f30eb8":"code","a88d101d":"code","cd7a6783":"code","31322037":"code","1e60d727":"code","07179dd2":"markdown","a21fe269":"markdown","6d02ba43":"markdown","0686eb3f":"markdown","386112ac":"markdown","15689e39":"markdown","51867e90":"markdown","26a07d06":"markdown","94336187":"markdown","bf05843a":"markdown","4ebb8442":"markdown","3e785c4a":"markdown","99329f58":"markdown","48ddea91":"markdown","c11cc935":"markdown","df3a6933":"markdown","5171aeb9":"markdown","1108d665":"markdown","94f02acf":"markdown","3de5f89b":"markdown","1fa04180":"markdown","322d4ec1":"markdown","d99fc0f1":"markdown","d9035b4a":"markdown","a52f1a5e":"markdown","61825138":"markdown"},"source":{"9b3706ad":"# packages\n\n# standard\nimport numpy as np\nimport pandas as pd\nimport time\n\n# plots\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns","e9baf8c2":"# files\n!ls ..\/input\/the-depression-dataset\/data","2e1f5e0a":"data_path = '..\/input\/the-depression-dataset\/data\/'","4010f5a4":"# load score file\ndf = pd.read_csv(data_path + 'scores.csv')","44cb6acb":"# show file (it's quite small so it can be displayed at once)\ndf","a60ee911":"# add difference of scores (\"after activity recording\" minus \"before activity recording\")\ndf['DeltaMADRS'] = df.madrs2 - df.madrs1","083b2cb8":"# split in condition and control table\ndf_condition = df[df.number.str.contains('condition')].copy()\ndf_control = df[df.number.str.contains('control')].copy()","889f7665":"df_condition","9afe4124":"df_condition.shape","3edd9371":"# define standard text for missing values\ntxt_missing = '_MISSING_'","b244c131":"# prep melanch column\ndf_condition.melanch = df_condition.melanch.fillna(txt_missing)\ndf_condition.melanch = df_condition.melanch.astype('category') # convert to categorical\ndf_condition.melanch = df_condition.melanch.cat.rename_categories({-1 : txt_missing,\n                                                                   1.0 : '1',\n                                                                   2.0 : '2'})\n\n# age, gender => category\ndf_condition.age = df_condition.age.astype('category')\ndf_condition.gender = df_condition.gender.astype('category')\n\n# further type conversions (float => int => category)\ndf_condition.afftype = df_condition.afftype.astype(int).astype('category')\ndf_condition.inpatient = df_condition.inpatient.astype(int).astype('category')\ndf_condition.marriage = df_condition.marriage.astype(int).astype('category')\ndf_condition.work = df_condition.work.astype(int).astype('category')\n\n# imputation\ndf_condition.edu = df_condition.edu.astype('category')\ndf_condition.edu = df_condition.edu.cat.rename_categories({' ' : txt_missing})","f7078fed":"# let's check the cleaned data set\ndf_condition","66e43ebc":"# define numerical and categorical features\nfeatures_num = ['days','madrs1','madrs2','DeltaMADRS']\nfeatures_cat = ['age', 'gender', 'afftype', 'melanch', 'inpatient', 'edu', 'marriage', 'work']","ac4c4a8e":"# basic stats\ndf_condition[features_num].describe()","633c4b6e":"# barplot of MADRS scores (before\/after)\ntemp_plot_paras = plt.rcParams['figure.figsize']\n\nplt.rcParams['figure.figsize'] = (14,4)\ndf_condition.plot(x='number', y=['madrs1','madrs2'], kind='bar')\nplt.title('MADRS Development')\nplt.grid()\nplt.show()\n\nplt.rcParams['figure.figsize'] = temp_plot_paras","40a53c3a":"# plot distributions of numerical features\nfor f in features_num:\n    df_condition[f].plot(kind='hist')\n    plt.title(f)\n    plt.grid()\n    plt.show()","a4cc740d":"# scatter plot for each pair incl. regression line\nsns.pairplot(df_condition[features_num], kind='reg')\nplt.show()","f26f7e45":"# correlation matrix\ndf_condition[features_num].corr(method='pearson')","9111a81d":"# plot distributions of categorical features\nfor f in features_cat:\n    df_condition[f].value_counts().sort_index().plot(kind='bar')\n    plt.title(f)\n    plt.grid()\n    plt.show()","156440a8":"# impact of feature on score madrs1 (at begin of activity measurement)\nfor f in features_cat:\n    plt.figure(figsize=(10,4))\n    sns.violinplot(data=df_condition, x=f, y='madrs1')\n    plt.title('madrs1 vs ' + f)\n    plt.grid()\n    plt.show()","326d34c6":"# impact of feature on score madrs2 (at end of activity measurement)\nfor f in features_cat:\n    plt.figure(figsize=(10,4))\n    sns.violinplot(data=df_condition, x=f, y='madrs2')\n    plt.title('madrs2 vs ' + f)\n    plt.grid()\n    plt.show()","8fb01e88":"# impact of feature on score difference DeltaMADRS = madrs2 - madrs1\nfor f in features_cat:\n    plt.figure(figsize=(10,4))\n    sns.violinplot(data=df_condition, x=f, y='DeltaMADRS')\n    plt.title('DeltaMADRS vs ' + f)\n    plt.grid()\n    plt.show()","aad3c9af":"# distribution of days\ndf_control.days.plot(kind='hist')\nplt.title('days [control]')\nplt.grid()\nplt.show()","6e0e6157":"# type conversion\ndf_control.age = df_control.age.astype('category')\ndf_control.gender = df_control.gender.astype('category')","66bffca4":"# plot distributions of categorical features\ndf_control.gender.value_counts().sort_index().plot(kind='bar')\nplt.title('gender [control]')\nplt.grid()\nplt.show()\n\ndf_control.age.value_counts().sort_index().plot(kind='bar')\nplt.title('age [control]')\nplt.grid()\nplt.show()","6edb957a":"# load a specific file\nmy_file = data_path + 'condition\/condition_1.csv'\ndf_act = pd.read_csv(my_file)\ndf_act.head(10)","9a3d0ba2":"# dimensions\ndf_act.shape","08830eeb":"# basic stats of activity\ndf_act.activity.describe(percentiles=[0.01,0.1,0.25,0.5,0.75,0.9,0.99])","8c708571":"# add logarithmic version of activity\ndf_act['log1_act'] = np.log10(1+df_act.activity)\n\n# add non-zero indicator for activity\ndf_act['non_zero'] = (df_act.activity>0).astype(int)","14d0bd45":"# distribution of activity\nplt.figure(figsize=(10,4))\ndf_act.activity.plot(kind='hist', bins=100)\nplt.title('Activity - Histogram')\nplt.grid()\nplt.show()","bfa15ea2":"# distribution of activity - log transformation\nplt.figure(figsize=(10,4))\ndf_act.log1_act.plot(kind='hist', bins=100)\nplt.title('log10(1+Activity) - Histogram')\nplt.grid()\nplt.show()","f447fdc8":"# distribution of activity - log transformation - non zeroes only\nplt.figure(figsize=(10,4))\nnp.log10(df_act[df_act.non_zero==1].activity).plot(kind='hist', bins=100)\nplt.title('log10(Activity|Activity>0) - Histogram')\nplt.grid()\nplt.show()","ff24f731":"# plot full activity time series\nmy_alpha=0.25\nfig, ax = plt.subplots(figsize=(18,6))\nax.scatter(df_act.timestamp, df_act.activity , alpha=my_alpha)\nax.xaxis.set_major_locator(plt.MaxNLocator(20)) # reduce number of x-axis labels\nplt.title(my_file)\nplt.xticks(rotation=90)\nplt.grid()\nax.legend(loc='upper left')\nplt.show()","82fa33e1":"# zoom into a specific day\ndf_act_zoom = df_act[df_act.date=='2003-05-12']\nmy_alpha=0.25\nfig, ax = plt.subplots(figsize=(18,6))\nax.scatter(df_act_zoom.timestamp, df_act_zoom.activity, alpha=my_alpha)\nax.xaxis.set_major_locator(plt.MaxNLocator(20)) # reduce number of x-axis labels\nplt.title(my_file)\nplt.xticks(rotation=90)\nplt.grid()\nax.legend(loc='upper left')\nplt.show()","e2bbd181":"# group activity by date\nplt.subplots(figsize=(18,6))\nsns.boxplot(data=df_act, x='date', y='activity')\nplt.xticks(rotation=90)\nplt.title(my_file)\nplt.grid()\nplt.show()","0da60890":"# group by date\ndf_act_by_date = df_act.groupby(['date'], as_index=False).agg(\n    n = pd.NamedAgg(column='activity', aggfunc='count'),\n    n_non_zero = pd.NamedAgg(column='non_zero', aggfunc='sum'),\n    mean_act = pd.NamedAgg(column='activity', aggfunc='mean'),\n    q75_act = pd.NamedAgg(column='activity', aggfunc=lambda x : np.percentile(a=x, q=75)),\n    q90_act = pd.NamedAgg(column='activity', aggfunc=lambda x : np.percentile(a=x, q=90)),\n    q95_act = pd.NamedAgg(column='activity', aggfunc=lambda x : np.percentile(a=x, q=95)),\n    q99_act = pd.NamedAgg(column='activity', aggfunc=lambda x : np.percentile(a=x, q=99)),\n    max_act = pd.NamedAgg(column='activity', aggfunc='max'))\n\ndf_act_by_date","97242700":"# remove incomplete days from stats\ndf_act_by_date = df_act_by_date[df_act_by_date.n==1440] # 1440 = 24*60 minutes in a day\ndf_act_by_date","26c0039c":"# plot mean activity by day\nplt.figure(figsize=(14,4))\nplt.scatter(df_act_by_date.date, df_act_by_date.mean_act)\nplt.title('Mean Activity by Day')\nplt.xticks(rotation=90)\nplt.grid()\nplt.show()\n\nprint('Mean of daily means:', np.round(df_act_by_date.mean_act.mean(),2))\nprint('Stdev of daily means:', np.round(df_act_by_date.mean_act.std(),2))","e3325ee3":"# plot 99th percentile of activity by day\nplt.figure(figsize=(14,4))\nplt.scatter(df_act_by_date.date, df_act_by_date.q99_act)\nplt.title('99th Percentile of Activity by Day')\nplt.xticks(rotation=90)\nplt.grid()\nplt.show()\n\nprint('Mean of daily 99th percentile:', np.round(df_act_by_date.q99_act.mean(),2))\nprint('Stdev of daily 99th percentile:', np.round(df_act_by_date.q99_act.std(),2))","a58bc384":"# show all condition files\n!ls ..\/input\/the-depression-dataset\/data\/condition","ac357491":"# load and plot full activity time series\nmy_file = data_path + 'condition\/condition_2.csv'\ndf_temp = pd.read_csv(my_file)\n\nmy_alpha=0.25\nfig, ax = plt.subplots(figsize=(18,6))\nax.scatter(df_temp.timestamp, df_temp.activity , alpha=my_alpha)\nax.xaxis.set_major_locator(plt.MaxNLocator(20)) # reduce number of x-axis labels\nplt.title(my_file)\nplt.xticks(rotation=90)\nplt.grid()\nax.legend(loc='upper left')\nplt.show()","e72a1209":"# define (daily mean) threshold below which we consider the data as not usable\ndaily_threshold = 10","51899d0e":"# iterate over all files and extract statistics \nmean_list = []\nstd_list = []\nq99_list = []\nstd_q99_list = []\n\nfor i in range(23):\n    j = 1+i\n    my_file = data_path + 'condition\/condition_' + str(j) + '.csv'\n    print('Extracting from:', my_file)\n    df_temp = pd.read_csv(my_file)\n    \n    # group by date\n    df_temp_by_date = df_temp.groupby(['date'], as_index=False).agg(\n        n = pd.NamedAgg(column='activity', aggfunc='count'),\n        mean_act = pd.NamedAgg(column='activity', aggfunc='mean'),\n        q99_act = pd.NamedAgg(column='activity', aggfunc=lambda x : np.percentile(a=x, q=99)),\n        max_act = pd.NamedAgg(column='activity', aggfunc='max')\n    )\n\n    # remove incomplete days (24*60 minutes = 1440)\n    df_temp_by_date = df_temp_by_date[df_temp_by_date.n==1440]\n    # remove days with unreasonable low average daily activity\n    df_temp_by_date = df_temp_by_date[df_temp_by_date.mean_act > daily_threshold]\n    \n    print(df_temp_by_date)\n    print()\n    \n    # extract statistics\n    mean_temp = df_temp_by_date.mean_act.mean() # mean of mean daily activity\n    std_temp = df_temp_by_date.mean_act.std() # stdev of mean daily activity\n    mean_q99_temp = df_temp_by_date.q99_act.mean() # mean of 99th percentiles of daily activity\n    std_q99_temp = df_temp_by_date.q99_act.std() # stdev of 99th percentiles of daily activity\n    \n    # add results to lists\n    mean_list.append(mean_temp)\n    std_list.append(std_temp)\n    q99_list.append(mean_q99_temp)\n    std_q99_list.append(std_q99_temp)","a96dda71":"# store results in data frame\ncondition_stats = pd.DataFrame(zip(df_condition.number, mean_list, q99_list, std_list, std_q99_list), \n                               columns=['number','Mean_MeanAct','Mean_Q99Act','Std_MeanAct','Std_Q99Act'])\n# add coefficient of variation (stdev \/ mean)\ncondition_stats['CV_MeanAct'] = condition_stats.Std_MeanAct \/ condition_stats.Mean_MeanAct\ncondition_stats['CV_Q99Act'] = condition_stats.Std_Q99Act \/ condition_stats.Mean_Q99Act\ncondition_stats","0ea946d6":"# look at correlation of different metrics\ncondition_stats.corr()","060556f4":"# show all control files\n!ls ..\/input\/the-depression-dataset\/data\/control","e0978b2f":"# iterate over all files and extract statistics \nmean_list_control = []\nstd_list_control = []\nq99_list_control = []\nstd_q99_list_control = []\n\nfor i in range(32):\n    j = 1+i\n    my_file = data_path + 'control\/control_' + str(j) + '.csv'\n    print('Extracting from:', my_file)\n    df_temp = pd.read_csv(my_file)\n    \n    # group by date\n    df_temp_by_date = df_temp.groupby(['date'], as_index=False).agg(\n        n = pd.NamedAgg(column='activity', aggfunc='count'),\n        mean_act = pd.NamedAgg(column='activity', aggfunc='mean'),\n        q99_act = pd.NamedAgg(column='activity', aggfunc=lambda x : np.percentile(a=x, q=99)),\n        max_act = pd.NamedAgg(column='activity', aggfunc='max')\n    )\n\n    # remove incomplete days (24*60 minutes = 1440)\n    df_temp_by_date = df_temp_by_date[df_temp_by_date.n==1440]\n    # remove days with unreasonable low average daily activity\n    df_temp_by_date = df_temp_by_date[df_temp_by_date.mean_act > daily_threshold]\n    \n    print(df_temp_by_date)\n    print()\n    \n    # extract statistics\n    mean_temp = df_temp_by_date.mean_act.mean() # mean of mean daily activity\n    std_temp = df_temp_by_date.mean_act.std() # stdev of mean daily activity\n    mean_q99_temp = df_temp_by_date.q99_act.mean() # mean of 99th percentiles of daily activity\n    std_q99_temp = df_temp_by_date.q99_act.std() # stdev of 99th percentiles of daily activity\n\n    # add results to lists\n    mean_list_control.append(mean_temp)\n    std_list_control.append(std_temp)\n    q99_list_control.append(mean_q99_temp)\n    std_q99_list_control.append(std_q99_temp)","c26c2120":"# store results in data frame\ncontrol_stats =  pd.DataFrame(zip(df_control.number, mean_list_control, q99_list_control, std_list_control, std_q99_list_control), \n                               columns=['number','Mean_MeanAct','Mean_Q99Act','Std_MeanAct','Std_Q99Act'])\n# add coefficient of variation (stdev \/ mean)\ncontrol_stats['CV_MeanAct'] = control_stats.Std_MeanAct \/ control_stats.Mean_MeanAct\ncontrol_stats['CV_Q99Act'] = control_stats.Std_Q99Act \/ control_stats.Mean_Q99Act\ncontrol_stats","86840efa":"# look at correlation of different metrics\ncontrol_stats.corr()","54a1c9f8":"# basic stats of condition group\ncondition_stats.describe()","44c2ec68":"# basic stats of control group\ncontrol_stats.describe()","43e1f38c":"# combine statistics into one common data frame\ncondition_stats['Group'] = 'Condition'\ncontrol_stats['Group'] = 'Control'\ncombined_stats = pd.concat([condition_stats, control_stats])","05468b69":"# compare means of daily means for the two groups\nsns.boxplot(data=combined_stats, x='Group', y='Mean_MeanAct')\nplt.title('Compare Means of Daily Means')\nplt.grid()\nplt.show()\n\n# compare means of 99th percentiles\nsns.boxplot(data=combined_stats, x='Group', y='Mean_Q99Act')\nplt.title('Compare Means of Daily 99th Percentiles')\nplt.grid()\nplt.show()\n\n# compare stdevs of daily means\nsns.boxplot(data=combined_stats, x='Group', y='Std_MeanAct')\nplt.title('Compare Stdevs of Daily Means')\nplt.grid()\nplt.show()\n\n# compare CVs of daily means\nsns.boxplot(data=combined_stats, x='Group', y='CV_MeanAct')\nplt.title('Compare CVs of Daily Means')\nplt.grid()\nplt.show()\n\n# compare stdevs of 99th percentiles\nsns.boxplot(data=combined_stats, x='Group', y='Std_Q99Act')\nplt.title('Compare Stdevs of Daily 99th Percentiles')\nplt.grid()\nplt.show()\n\n# compare CVs of 99th percentiles\nsns.boxplot(data=combined_stats, x='Group', y='CV_Q99Act')\nplt.title('Compare CVs of Daily 99th Percentiles')\nplt.grid()\nplt.show()","0cef1192":"# compare two groups using scatter plot\nplt.figure(figsize=(8,6))\nplt.scatter(condition_stats.Mean_MeanAct, condition_stats.CV_MeanAct, label='Condition')\nplt.scatter(control_stats.Mean_MeanAct, control_stats.CV_MeanAct, label='Control')\nplt.legend(loc='lower right')\nplt.xlabel('Mean of Daily Means')\nplt.ylabel('Stdev of Daily Means')\nplt.title('Compare Groups using Mean and CV of Mean Daily Activity')\nplt.grid()\nplt.show()","f1f30eb8":"# compare two groups using scatter plot - now use quantile based metrics\nplt.figure(figsize=(8,6))\nplt.scatter(condition_stats.Mean_Q99Act, condition_stats.CV_Q99Act, label='Condition')\nplt.scatter(control_stats.Mean_Q99Act, control_stats.CV_Q99Act, label='Control')\nplt.legend(loc='lower right')\nplt.xlabel('Mean of Daily 99th Percentiles')\nplt.ylabel('Stdev of Daily 99th Percentiles')\nplt.title('Compare Groups using Mean and CV of 99th Percentiles of Daily Activity')\nplt.grid()\nplt.show()","a88d101d":"# interactive plot using additional \"quantile\" dimension\nfig = px.scatter_3d(combined_stats, x='Mean_MeanAct', y='Std_MeanAct', z='CV_Q99Act',\n                    color='Group',\n                    hover_data=['number'],\n                    opacity=0.5)\nfig.update_layout(title='Compare Groups using Mean\/Stdev of Mean Daily Activity and CV of Daily 99th Perc.')\nfig.show()","cd7a6783":"# add stats to original data frame (condition group) to get access to all features\ndf_condition_x = pd.concat([df_condition, condition_stats.drop('number', axis=1)], axis=1)\ndf_condition_x = df_condition_x.drop('Group', axis=1)\ndf_condition_x.head()","31322037":"# scatterplot, show afftype via color\nsns.scatterplot(data=df_condition_x,\n                x='Mean_MeanAct', y='CV_MeanAct',\n                hue='afftype')\nplt.grid()\nplt.show()","1e60d727":"# scatterplot, show afftype via color\nsns.scatterplot(data=df_condition_x,\n                x='Mean_Q99Act', y='CV_Q99Act',\n                hue='afftype')\nplt.grid()\nplt.show()","07179dd2":"#### Does afftype (1: bipolar II, 2: unipolar depressive, 3: bipolar I) make a difference within the condition group?","a21fe269":"### => Control group shows higher activity (Mean_MeanAct, Mean_Q99Act as well as Std_MeanAct and Std_Q99Act; CVs are however on similar level).\n### Let's visualize:","6d02ba43":"<a id='4'><\/a>\n# Activity Data - Exploration","0686eb3f":"## Categorical Features","386112ac":"## For plots of all time series see the additional notebook https:\/\/www.kaggle.com\/docxian\/depression-and-motor-activity-all-plots","15689e39":"<a id='5'><\/a>\n# Loop over files and extract info","51867e90":"## Numerical Features","26a07d06":"### Distribution","94336187":"### Impact of categorical features on scores","bf05843a":"### We observe a longer period (several days) where no\/almost no activity is recorded. This does not seem reasonable (maybe the sensor was offline\/not working properly in that phase). We will in the following remove days showing such extremely low activity.","4ebb8442":"## Control","3e785c4a":"### Correlations","99329f58":"<a id='1'><\/a>\n# Explore Score File","48ddea91":"<a id='2'><\/a>\n# Clean \/ Explore Condition Table","c11cc935":"#### The first and the last day in this example are incomplete. For the sake of comparability we will remove those incomplete days!","df3a6933":"### Evaluate by Date","5171aeb9":"# Evaluate motor activity of depression patients (and healthy control group)\n\nDepression is a severe illness which can lead to suicide. More than 264 million people worldwide suffer from depression. It is one of the main causes for disability and the second leading cause of death in the age group of 15-29-year-olds (Source: WHO; https:\/\/www.who.int\/news-room\/fact-sheets\/detail\/depression).\n\nFortunately, there are effective psychological and pharmacological treatments. **Measuring motor activity** could be one way to provide an diagnostic early warning system.\n\n***\n\nThe **underlying data sets** provide the motor activity of 23 patients with depression and 32 controls (healthy). The severity of the depression is assessed by experts using the Montgomery-Asberg Depression Rating Scale (MADRS). MADRS levels range from 0 to 60. Values above 30 represent a severe depression, values below 10 indicate a healthy state.\n\nOriginal paper see here: https:\/\/www.researchgate.net\/publication\/325021337_Depresjon_A_Motor_Activity_Database_of_Depression_Episodes_in_Unipolar_and_Bipolar_Patients\n\n***\n\n\n## <font color=blue>Table of Contents <\/font>\n* [Explore Score File](#1)\n* [Clean \/ Explore Condition Table](#2)\n* [Explore Control Table](#3)\n* [Activity Data - Exploration](#4)\n* [Loop over files and extract info](#5)\n* [Comparison Condition vs Control](#6)","1108d665":"#### Development of MADRS score (before activity recording \/ after activity recording):","94f02acf":"### Let's look at another example before automatically evaluating all files:","3de5f89b":"### Time Series","1fa04180":"#### Ok, at least nothing obvious...","322d4ec1":"<a id='3'><\/a>\n# Explore Control Table","d99fc0f1":"## Condition","d9035b4a":"<a id='6'><\/a>\n# Comparison Condition vs Control","a52f1a5e":"#### Control rows have empty columns except for number (id), days, gender and age. Therefore let's split between condition and control observations.","61825138":"### Look at individual observations:"}}