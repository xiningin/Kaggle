{"cell_type":{"96b47adb":"code","127a2a60":"code","34bd6a79":"code","ca40f211":"code","c5f7c549":"code","c7d10e91":"code","13479216":"code","7d2a7fe0":"code","a10c98b3":"code","f9e0bc47":"code","318eeac6":"code","6b8742ab":"code","ef5bfc02":"code","900af98e":"code","d44dfabc":"code","442c7e39":"code","eb4dc0bc":"code","460c7949":"code","9d0f6688":"code","96cbe6d9":"code","035c29fb":"code","6db6b5ae":"code","1efee31c":"code","1c0728e7":"code","cfff4249":"markdown","4bfbd9af":"markdown","6398fd7a":"markdown","4efc5594":"markdown","8a1b001c":"markdown","52133cc5":"markdown","3c284d09":"markdown","4284c780":"markdown","b4d48ada":"markdown","ab92f702":"markdown","4c20d097":"markdown","b240b98b":"markdown"},"source":{"96b47adb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n# Imported Libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA, TruncatedSVD\nimport matplotlib.patches as mpatches\nimport time\n\n# Classifier Libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport collections\n\n\n# Other Libraries\nfrom imblearn.datasets import fetch_datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import NearMiss\nfrom imblearn.metrics import classification_report_imbalanced\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\nfrom collections import Counter\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\ndf = pd.read_csv('..\/input\/creditcard.csv')\ndf.head()","127a2a60":"def feature_summary(df_fa):\n    print('DataFrame shape')\n    print('rows:',df_fa.shape[0])\n    print('cols:',df_fa.shape[1])\n    col_list=['Null','Unique_Count','Data_type','Max\/Min','Mean','Std','Skewness','Sample_values']\n    df=pd.DataFrame(index=df_fa.columns,columns=col_list)\n    df['Null']=list([len(df_fa[col][df_fa[col].isnull()]) for i,col in enumerate(df_fa.columns)])\n    #df['%_Null']=list([len(df_fa[col][df_fa[col].isnull()])\/df_fa.shape[0]*100 for i,col in enumerate(df_fa.columns)])\n    df['Unique_Count']=list([len(df_fa[col].unique()) for i,col in enumerate(df_fa.columns)])\n    df['Data_type']=list([df_fa[col].dtype for i,col in enumerate(df_fa.columns)])\n    for i,col in enumerate(df_fa.columns):\n        if 'float' in str(df_fa[col].dtype) or 'int' in str(df_fa[col].dtype):\n            df.at[col,'Max\/Min']=str(round(df_fa[col].max(),2))+'\/'+str(round(df_fa[col].min(),2))\n            df.at[col,'Mean']=df_fa[col].mean()\n            df.at[col,'Std']=df_fa[col].std()\n            df.at[col,'Skewness']=df_fa[col].skew()\n        df.at[col,'Sample_values']=list(df_fa[col].unique())\n           \n    return(df.fillna('-'))","34bd6a79":"feature_summary(df)","ca40f211":"# Since most of our data has already been scaled we should scale the columns that are left to scale (Amount and Time)\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\n\n# RobustScaler is less prone to outliers.\n\nstd_scaler = StandardScaler()\nrob_scaler = RobustScaler()\n\ndf['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\ndf['scaled_time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n\ndf.drop(['Time','Amount'], axis=1, inplace=True)","c5f7c549":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import StratifiedKFold\n\nprint('No Frauds', round(df['Class'].value_counts()[0]\/len(df) * 100,2), '% of the dataset')\nprint('Frauds', round(df['Class'].value_counts()[1]\/len(df) * 100,2), '% of the dataset')\n\nX = df.drop('Class', axis=1)\ny = df['Class']\n\nsss = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n\nfor train_index, test_index in sss.split(X, y):\n    print(\"Train:\", train_index, \"Test:\", test_index)\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n\n# We already have X_train and y_train for undersample data thats why I am using original to distinguish and to not overwrite these variables.\n# original_Xtrain, original_Xtest, original_ytrain, original_ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Check the Distribution of the labels","c7d10e91":"# Turn into an array\noriginal_Xtrain = X_train.values\noriginal_Xtest = X_test.values\noriginal_ytrain = y_train.values\noriginal_ytest = y_test.values\n\n# See if both the train and test label distribution are similarly distributed\ntrain_unique_label, train_counts_label = np.unique(original_ytrain, return_counts=True)\ntest_unique_label, test_counts_label = np.unique(original_ytest, return_counts=True)\nprint('-' * 100)\n\nprint('Label Distributions: \\n')\nprint(train_counts_label\/ len(original_ytrain))\nprint(test_counts_label\/ len(original_ytest))","13479216":"from imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n\nprint('Length of X (train): {} | Length of y (train): {}'.format(len(original_Xtrain), len(original_ytrain)))\nprint('Length of X (test): {} | Length of y (test): {}'.format(len(original_Xtest), len(original_ytest)))\n\n# List to append the score and then find the average\naccuracy_lst = []\nprecision_lst = []\nrecall_lst = []\nf1_lst = []\nauc_lst = []\n\n# Classifier with optimal parameters\n# log_reg_sm = grid_log_reg.best_estimator_\nlog_reg_sm = LogisticRegression()\n\nlog_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n\nrand_log_reg = RandomizedSearchCV(LogisticRegression(), log_reg_params, n_iter=4)","7d2a7fe0":"from imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n\nprint('Length of X (train): {} | Length of y (train): {}'.format(len(original_Xtrain), len(original_ytrain)))\nprint('Length of X (test): {} | Length of y (test): {}'.format(len(original_Xtest), len(original_ytest)))\n\n# List to append the score and then find the average\naccuracy_lst = []\nprecision_lst = []\nrecall_lst = []\nf1_lst = []\nauc_lst = []\n\n# Classifier with optimal parameters\n# log_reg_sm = grid_log_reg.best_estimator_\nlog_reg_sm = LogisticRegression()\n\nlog_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n\nrand_log_reg = RandomizedSearchCV(LogisticRegression(), log_reg_params, n_iter=4)","a10c98b3":"%%time\n# Implementing SMOTE Technique \n# Cross Validating the right way\n\nfor train, test in sss.split(original_Xtrain, original_ytrain):\n    pipeline = imbalanced_make_pipeline(SMOTE(sampling_strategy='minority'), rand_log_reg) \n    # SMOTE happens during Cross Validation not before..\n    model = pipeline.fit(original_Xtrain[train], original_ytrain[train])\n    best_est = rand_log_reg.best_estimator_\n    prediction = best_est.predict(original_Xtrain[test])\n    \n    accuracy_lst.append(pipeline.score(original_Xtrain[test], original_ytrain[test]))\n    precision_lst.append(precision_score(original_ytrain[test], prediction))\n    recall_lst.append(recall_score(original_ytrain[test], prediction))\n    f1_lst.append(f1_score(original_ytrain[test], prediction))\n    auc_lst.append(roc_auc_score(original_ytrain[test], prediction))\n    \nprint('---' * 35)\nprint('')\nprint(\"accuracy: {}\".format(np.mean(accuracy_lst)))\nprint(\"precision: {}\".format(np.mean(precision_lst)))\nprint(\"recall: {}\".format(np.mean(recall_lst)))\nprint(\"f1: {}\".format(np.mean(f1_lst)))\nprint('AUC: {}'.format(np.mean(auc_lst)))\nprint('---' * 35)","f9e0bc47":"labels = ['No Fraud', 'Fraud']\nsmote_prediction = best_est.predict(original_Xtest)\nprint(classification_report(original_ytest, smote_prediction, target_names=labels))","318eeac6":"import xgboost as xgb\nfrom xgboost import XGBClassifier","6b8742ab":"# %%time\n# GridSearchCV\n# from sklearn.model_selection import GridSearchCV\n\n# xgb_params = {\"eta\": [0.02,0.05,0.1], \n#              'min_child_weight': [50,100,200,300,360],\n#              'subsample':[0.5,0.7,0.8,0.9],\n#              \"colsample_bytree\":[0.3,0.5,0.7,0.9],\n#              \"max_depth\":[8,10,12,15],\n#              'objective':['binary:logistic',\"reg:linear\"]\n#             }\n\n#xgb_sm = XGBClassifier()\n#grid_xgb = GridSearchCV(xgb_sm, xgb_params)\n#grid_xgb.fit(X_train, y_train)\n#get the best estimator\n#best_est_grid = grid_xgb.best_estimator_","ef5bfc02":"%%time\n# RandomizedSearchCV\n# fit model no training data\n\nxgb_params = {\"eta\": [0.01,0.02,0.03,0.05,0.8,0.1], \n              'min_child_weight': [50,100,200,300,360,500],\n              'subsample':[0.5,0.7,0.8,0.9,0.95,0.99],\n              \"colsample_bytree\":[0.3,0.5,0.7,0.9,0.99],\n              \"max_depth\":[6,8,10,12]\n             }\n\nxgb_sm = XGBClassifier()\nrand_xgb = RandomizedSearchCV(xgb_sm, xgb_params, n_iter=6)\nrand_xgb.fit(X_train,y_train)\nbest_est_ran = rand_xgb.best_estimator_","900af98e":"best_xgb = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n       colsample_bytree=0.5, eta=0.8, gamma=0, learning_rate=0.1,\n       max_delta_step=0, max_depth=12, min_child_weight=50, missing=None,\n       n_estimators=100, n_jobs=1, nthread=None,\n       objective='binary:logistic', random_state=0, reg_alpha=0,\n       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n       subsample=0.7)","d44dfabc":"%%time\n# Implementing SMOTE Technique \n# Cross Validating the right way\n\nfor train, test in sss.split(original_Xtrain, original_ytrain):\n    pipeline = imbalanced_make_pipeline(SMOTE(sampling_strategy='minority'), best_xgb) \n    # SMOTE happens during Cross Validation not before..\n    model = pipeline.fit(original_Xtrain[train], original_ytrain[train])\n    prediction = best_xgb.predict(original_Xtrain[test])\n    \n    accuracy_lst.append(pipeline.score(original_Xtrain[test], original_ytrain[test]))\n    precision_lst.append(precision_score(original_ytrain[test], prediction))\n    recall_lst.append(recall_score(original_ytrain[test], prediction))\n    f1_lst.append(f1_score(original_ytrain[test], prediction))\n    auc_lst.append(roc_auc_score(original_ytrain[test], prediction))\n    \nprint('---' * 35)\nprint('')\nprint(\"accuracy: {}\".format(np.mean(accuracy_lst)))\nprint(\"precision: {}\".format(np.mean(precision_lst)))\nprint(\"recall: {}\".format(np.mean(recall_lst)))\nprint(\"f1: {}\".format(np.mean(f1_lst)))\nprint('AUC: {}'.format(np.mean(auc_lst)))\nprint('---' * 35)","442c7e39":"labels = ['No Fraud', 'Fraud']\nsmote_prediction = best_xgb.predict(original_Xtest)\nprint(classification_report(original_ytest, smote_prediction, target_names=labels))","eb4dc0bc":"import keras\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Activation\nfrom keras.layers.core import Dense\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\n\nn_inputs = X_train.shape[1]\n\noversample_model = Sequential([\n    Dense(n_inputs, input_shape=(n_inputs, ), activation='relu'),\n    Dense(32, activation='relu'),\n    Dense(2, activation='softmax')])\n\n# SMOTE Technique (OverSampling) After splitting and Cross Validating\nsm = SMOTE(ratio='minority', random_state=42)\n# Xsm_train, ysm_train = sm.fit_sample(X_train, y_train)\n\n\n# This will be the data were we are going to \nXsm_train, ysm_train = sm.fit_sample(original_Xtrain, original_ytrain)","460c7949":"oversample_model.compile(Adam(lr=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])","9d0f6688":"oversample_model.fit(Xsm_train, ysm_train, validation_split=0.2, batch_size=300, epochs=20, shuffle=True, verbose=2)","96cbe6d9":"oversample_predictions = oversample_model.predict(original_Xtest, batch_size=200, verbose=0)","035c29fb":"oversample_fraud_predictions = oversample_model.predict_classes(original_Xtest, batch_size=200, verbose=0)","6db6b5ae":"from sklearn.metrics import confusion_matrix\nimport itertools","1efee31c":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, fontsize=14)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","1c0728e7":"oversample_smote = confusion_matrix(original_ytest, oversample_fraud_predictions)\nactual_cm = confusion_matrix(original_ytest, original_ytest)\n\nlabels = ['No Fraud', 'Fraud']\n\nfig = plt.figure(figsize=(16,8))\n\nfig.add_subplot(221)\nplot_confusion_matrix(oversample_smote, labels, title=\"OverSample (SMOTE) \\n Confusion Matrix\", cmap=plt.cm.Oranges)\n\nfig.add_subplot(222)\nplot_confusion_matrix(actual_cm, labels, title=\"Confusion Matrix \\n (with 100% accuracy)\", cmap=plt.cm.Greens)","cfff4249":"#### Note: we should do the cross validation before SMOTE oversampling","4bfbd9af":"#### RandomizedSearchCV","6398fd7a":"### data","4efc5594":"#### GridSearchCV","8a1b001c":"### XGB with SMOTE","52133cc5":"#### EDA and other feature engineering skipped in this notebook","3c284d09":"#### without SMOTE to see the optimal paramaters","4284c780":"### Logistic Regression with SMOTE","b4d48ada":"#### Using SMOTE with optimal parameters","ab92f702":"### SMOTE oversampling","4c20d097":"### Keras with one hidden layer","b240b98b":"#### SMOTE:\n\n1. Solving the Class Imbalance: SMOTE creates synthetic points from the minority class in order to reach an equal balance between the minority and majority class.\n\n2. Location of the synthetic points: SMOTE picks the distance between the closest neighbors of the minority class, in between these distances it creates synthetic points.\n\n3. Final Effect: More information is retained since we didn't have to delete any rows unlike in random undersampling.\n\n4. Accuracy || Time Tradeoff: Although it is likely that SMOTE will be more accurate than random under-sampling, it will take more time to train since no rows are eliminated as previously stated."}}