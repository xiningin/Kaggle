{"cell_type":{"dbf1f021":"code","ad7742aa":"code","7b2e5e59":"code","af5f0d42":"code","c48b15e2":"code","e57b4d27":"code","9cc413aa":"code","e23c1b80":"code","cd215ea5":"code","9ae4500e":"code","95773ccf":"code","a6656315":"code","07875600":"code","271bf2bc":"code","b5d989cd":"code","6cb33727":"code","eef1bfc9":"code","1cf90bd9":"code","57c83be9":"code","f380d366":"markdown","6aaa3c8d":"markdown","68eb08b6":"markdown","2b6eec19":"markdown","168f4e53":"markdown","be786b33":"markdown","fa1d12fa":"markdown","08d3cd4b":"markdown","4e874882":"markdown","b5409070":"markdown","a0c360c5":"markdown","6a8c3224":"markdown","a5e9ca3b":"markdown","720cd3b5":"markdown","3bb7343a":"markdown","a0f8ca4c":"markdown"},"source":{"dbf1f021":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n\n# Libraries\n\nimport os\nimport math\nimport h5py\nimport scipy\n\n# numpy\nimport numpy as np\n\n# data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Charts\nimport matplotlib.pyplot as plt\n\n# Image IO\nimport skimage.io\nimport skimage.transform\nfrom PIL import Image\nfrom scipy import ndimage\n\n# Machine Learning\nimport tensorflow as tf\nfrom tensorflow.python.framework import ops\nfrom keras.preprocessing.image import ImageDataGenerator\n# from cnn_utils import *   \/\/ See below\n\n%matplotlib inline\n\n# Set random seed to make results reproducable\nnp.random.seed(1)\ntf.set_random_seed(1)\n\n# Input data files are available in the \"..\/input\/\" directory.\n\n# Any results you write to the current directory are saved as output.","ad7742aa":"# from cnn_utils import *\n\ndef random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n    \"\"\"\n    Creates a list of random minibatches from (X, Y)\n    \n    Arguments:\n    X -- input data, of shape (input size, number of examples) (m, Hi, Wi, Ci)\n    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) (m, n_y)\n    mini_batch_size - size of the mini-batches, integer\n    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n    \n    Returns:\n    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n    \"\"\"\n    \n    m = X.shape[0]                  # number of training examples\n    mini_batches = []\n    np.random.seed(seed)\n    \n    # Step 1: Shuffle (X, Y)\n    permutation = list(np.random.permutation(m))\n    shuffled_X = X[permutation,:,:,:]\n    shuffled_Y = Y[permutation,:]\n\n    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n    num_complete_minibatches = math.floor(m\/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n    for k in range(0, num_complete_minibatches):\n        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    # Handling the end case (last mini-batch < mini_batch_size)\n    if m % mini_batch_size != 0:\n        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    return mini_batches\n\n\ndef convert_to_one_hot(Y, C):\n    Y = np.eye(C)[Y.reshape(-1)].T\n    return Y\n\n\ndef forward_propagation_for_predict(X, parameters):\n    \"\"\"\n    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n    \n    Arguments:\n    X -- input dataset placeholder, of shape (input size, number of examples)\n    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n                  the shapes are given in initialize_parameters\n\n    Returns:\n    Z3 -- the output of the last LINEAR unit\n    \"\"\"\n    \n    # Retrieve the parameters from the dictionary \"parameters\" \n    W1 = parameters['W1']\n    b1 = parameters['b1']\n    W2 = parameters['W2']\n    b2 = parameters['b2']\n    W3 = parameters['W3']\n    b3 = parameters['b3'] \n                                                           # Numpy Equivalents:\n    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n    \n    return Z3\n\ndef predict(X, parameters):\n    \n    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n    \n    params = {\"W1\": W1,\n              \"b1\": b1,\n              \"W2\": W2,\n              \"b2\": b2,\n              \"W3\": W3,\n              \"b3\": b3}\n    \n    x = tf.placeholder(\"float\", [12288, 1])\n    \n    z3 = forward_propagation_for_predict(x, params)\n    p = tf.argmax(z3)\n    \n    sess = tf.Session()\n    prediction = sess.run(p, feed_dict = {x: X})\n        \n    return prediction\n\n#def predict(X, parameters):\n#    \n#    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n#    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n#    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n#    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n##    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n##    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n#    \n##    params = {\"W1\": W1,\n##              \"b1\": b1,\n##              \"W2\": W2,\n##              \"b2\": b2,\n##              \"W3\": W3,\n##              \"b3\": b3}\n#\n#    params = {\"W1\": W1,\n#              \"b1\": b1,\n#              \"W2\": W2,\n#              \"b2\": b2}    \n#    \n#    x = tf.placeholder(\"float\", [12288, 1])\n#    \n#    z3 = forward_propagation(x, params)\n#    p = tf.argmax(z3)\n#    \n#    with tf.Session() as sess:\n#        prediction = sess.run(p, feed_dict = {x: X})\n#        \n#    return prediction","7b2e5e59":"# Parameters\ntraining_dataset_path = \"..\/input\/dataset\/dataset_updated\/training_set\"\ntest_dataset_path = \"..\/input\/dataset\/dataset_updated\/validation_set\"\n\n# categories to use\ncategories = ['drawings', 'engraving', 'iconography', 'painting', 'sculpture']\nn_categories = len(categories)\ncategory_embeddings = {\n    'drawings': 0,\n    'engraving': 1,\n    'iconography': 2,\n    'painting': 3,\n    'sculpture': 4\n}\n\n# After computing the mean image size, we can set a default width and a default height to resize the images\nwidth = 64\nheight = 64\nn_channels = 3","af5f0d42":"# training dataset metadata\nn_imgs = []\nfor cat in categories:\n    files = os.listdir(os.path.join(training_dataset_path, cat))\n    n_imgs += [len(files)]\n    \nplt.bar([_ for _ in range(n_categories)], n_imgs, tick_label=categories)\nplt.show()","c48b15e2":"fig, axes = plt.subplots(nrows=1, ncols=n_categories, figsize=(15, 3))\n\ncat_cpt=0\nfor cat in categories:\n    category_path = os.path.join(training_dataset_path, cat)\n    img_name = os.listdir(category_path)[0]\n    img = skimage.io.imread(os.path.join(category_path, img_name))\n    img = skimage.transform.resize(img, (width, height, n_channels), mode='reflect')\n    axes[cat_cpt].imshow(img, resample=True)\n    axes[cat_cpt].set_title(cat, fontsize=8)\n    cat_cpt += 1\n\nplt.show()","e57b4d27":"training_data = []\nfor cat in categories:\n    files = os.listdir(os.path.join(training_dataset_path, cat))\n    for file in files:\n        training_data += [(os.path.join(cat, file), cat)]\n\ntest_data = []\nfor cat in categories:\n    files = os.listdir(os.path.join(test_dataset_path, cat))\n    for file in files:\n        test_data += [(os.path.join(cat, file), cat)]","9cc413aa":"def load_dataset(tuples_list, dataset_path):\n    indexes = np.arange(len(tuples_list))\n    np.random.shuffle(indexes)\n    \n    X = []\n    y = []\n    n_samples = len(indexes)\n    cpt = 0\n    for i in range(n_samples):\n        t = tuples_list[indexes[i]]\n        try:\n            img = skimage.io.imread(os.path.join(dataset_path, t[0]))\n            img = skimage.transform.resize(img, (width, height,n_channels), mode='reflect')\n            X += [img]\n            y_tmp = [0 for _ in range(n_categories)]\n            y_tmp[category_embeddings[t[1]]] = 1\n            y += [y_tmp]\n        except OSError:\n            pass\n        \n        cpt += 1\n        \n        if cpt % 1000 == 0:\n            print(\"Processed {} images\".format(cpt))\n\n    X = np.array(X)\n    y = np.array(y)\n    \n    return X, y","e23c1b80":"# Load the training and test datasets\nX_train, y_train = load_dataset(training_data, training_dataset_path)\nX_val, y_val = load_dataset(test_data, test_dataset_path)","cd215ea5":"print (\"number of training examples = \" + str(X_train.shape[0]))\nprint (\"number of test examples = \" + str(X_val.shape[0]))\nprint (\"X_train shape: \" + str(X_train.shape))\nprint (\"y_train shape: \" + str(y_train.shape))\nprint (\"X_val shape: \" + str(X_val.shape))\nprint (\"y_val shape: \" + str(y_val.shape))\nprint (\"Y categories in first row: \" + str(y_val[0]))\nconv_layers = {}","9ae4500e":"def create_placeholders(n_H0, n_W0, n_C0, n_y):\n    \"\"\"\n    Creates the placeholders for the tensorflow session.\n    \n    Arguments:\n    n_H0 -- scalar, height of an input image\n    n_W0 -- scalar, width of an input image\n    n_C0 -- scalar, number of channels of the input\n    n_y -- scalar, number of classes\n        \n    Returns:\n    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype \"float\"\n    Y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n    \"\"\"\n\n    X = tf.placeholder(dtype=\"float\", shape=[None, n_H0, n_W0, n_C0])\n    Y = tf.placeholder(dtype=\"float\", shape=[None, n_y])\n    \n    return X, Y","95773ccf":"## Test placehoider is working\nX, Y = create_placeholders(height, width, n_channels, n_categories)\nprint (\"X = \" + str(X))\nprint (\"Y = \" + str(Y))","a6656315":"def initialize_parameters():\n    \"\"\"\n    Initializes weight parameters to build a neural network with tensorflow. The shapes are:\n                        W1 : [4, 4, 3, 8]\n                        W2 : [2, 2, 8, 16]\n    Returns:\n    parameters -- a dictionary of tensors containing W1, W2\n    \"\"\"\n    tf.set_random_seed(1)\n\n    W1 = tf.get_variable(\"W1\", [4, 4, 3, 8], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n    W2 = tf.get_variable(\"W2\", [2, 2, 8, 16], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n\n    parameters = {\"W1\": W1,\n                  \"W2\": W2}\n    \n    return parameters","07875600":"# Test the initializing parameters\ntf.reset_default_graph()\nwith tf.Session() as sess_test:\n    parameters = initialize_parameters()\n    init = tf.global_variables_initializer()\n    sess_test.run(init)\n    print(\"W1 = \" + str(parameters[\"W1\"].eval()[1,1,1]))\n    print(\"W2 = \" + str(parameters[\"W2\"].eval()[1,1,1]))","271bf2bc":"def forward_propagation(X, parameters):\n    \"\"\"\n    Implements the forward propagation for the model:\n    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n    \n    Arguments:\n    X -- input dataset placeholder, of shape (input size, number of examples)\n    parameters -- python dictionary containing your parameters \"W1\", \"W2\"\n                  the shapes are given in initialize_parameters\n\n    Returns:\n    Z3 -- the output of the last LINEAR unit\n    \"\"\"\n    \n    # Retrieve the parameters from the dictionary \"parameters\" \n    W1 = parameters['W1']\n    W2 = parameters['W2']\n    \n    # CONV2D: stride of 1, padding 'SAME'\n    Z1 = tf.nn.conv2d(X,W1,strides=[1,1,1,1], padding='SAME')\n    # RELU\n    A1 = tf.nn.relu(Z1)\n    # MAXPOOL: window 8x8, stride 8, padding 'SAME'\n    P1 = tf.nn.max_pool(A1, ksize=[1,8,8,1], strides=[1,8,8,1], padding='SAME')\n    # CONV2D: filters W2, stride 1, padding 'SAME'\n    Z2 = tf.nn.conv2d(P1,W2,strides=[1,1,1,1], padding='SAME')\n    # RELU\n    A2 = tf.nn.relu(Z2)\n    # MAXPOOL: window 4x4, stride 4, padding 'SAME'\n    P2 = tf.nn.max_pool(A2, ksize=[1,4,4,1], strides=[1,4,4,1], padding='SAME')\n    # FLATTEN\n    P = tf.contrib.layers.flatten(P2)\n    # FULLY-CONNECTED without non-linear activation function (not not call softmax).\n    # 5 neurons in output layer. One of the arguments should be \"activation_fn=None\" \n    Z3 = tf.contrib.layers.fully_connected(P,n_categories,activation_fn=None)\n\n    return Z3","b5d989cd":"# Test the forward propogation is working\ntf.reset_default_graph()\n\nwith tf.Session() as sess:\n    np.random.seed(1)\n    X, Y = create_placeholders(height, width, n_channels, n_categories)\n    parameters = initialize_parameters()\n    Z3 = forward_propagation(X, parameters)\n    init = tf.global_variables_initializer()\n    sess.run(init)\n    a = sess.run(Z3, {X: np.random.randn(2,height,width,n_channels), Y: np.random.randn(2,n_categories)})\n    print(\"Z3 = \" + str(a))","6cb33727":"def compute_cost(Z3, Y):\n    \"\"\"\n    Computes the cost\n    \n    Arguments:\n    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n    Y -- \"true\" labels vector placeholder, same shape as Z3\n    \n    Returns:\n    cost - Tensor of the cost function\n    \"\"\"\n    \n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z3, labels=Y))\n    \n    return cost","eef1bfc9":"# Test the cost function\ntf.reset_default_graph()\n\nwith tf.Session() as sess:\n    np.random.seed(1)\n    X, Y = create_placeholders(height, width, n_channels, n_categories)\n    parameters = initialize_parameters()\n    Z3 = forward_propagation(X, parameters)\n    cost = compute_cost(Z3, Y)\n    init = tf.global_variables_initializer()\n    sess.run(init)\n    a = sess.run(cost, {X: np.random.randn(4,height,width,n_channels), Y: np.random.randn(4,n_categories)})\n    print(\"cost = \" + str(a))","1cf90bd9":"def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.009,\n          num_epochs = 100, minibatch_size = 64, print_cost = True):\n    \"\"\"\n    Implements a three-layer ConvNet in Tensorflow:\n    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n    \n    Arguments:\n    X_train -- training set, of shape (None, 128, 128, 3)\n    Y_train -- test set, of shape (None, n_y = 5)\n    X_test -- training set, of shape (None, 128, 128, 3)\n    Y_test -- test set, of shape (None, n_y = 5)\n    learning_rate -- learning rate of the optimization\n    num_epochs -- number of epochs of the optimization loop\n    minibatch_size -- size of a minibatch\n    print_cost -- True to print the cost every 100 epochs\n    \n    Returns:\n    train_accuracy -- real number, accuracy on the train set (X_train)\n    test_accuracy -- real number, testing accuracy on the test set (X_test)\n    parameters -- parameters learnt by the model. They can then be used to predict.\n    \"\"\"\n    \n    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n    seed = 3                                          # to keep results consistent (numpy seed)\n    (m, n_H0, n_W0, n_C0) = X_train.shape             \n    n_y = Y_train.shape[1]                            \n    costs = []                                        # To keep track of the cost\n    \n    # Create Placeholders of the correct shape\n    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)\n\n    # Initialize parameters\n    parameters = initialize_parameters()\n    \n    # Forward propagation: Build the forward propagation in the tensorflow graph\n    Z3 = forward_propagation(X, parameters)\n    \n    # Cost function: Add cost function to tensorflow graph\n    cost = compute_cost(Z3, Y)\n    \n    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n    \n    # Initialize all the variables globally\n    init = tf.global_variables_initializer()\n     \n    # Start the session to compute the tensorflow graph\n    with tf.Session() as sess:\n        \n        # Run the initialization\n        sess.run(init)\n        \n        # Do the training loop\n        for epoch in range(num_epochs):\n\n            minibatch_cost = 0.\n            num_minibatches = int(m \/ minibatch_size) # number of minibatches of size minibatch_size in the train set\n            seed = seed + 1\n            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n\n            for minibatch in minibatches:\n\n                # Select a minibatch\n                (minibatch_X, minibatch_Y) = minibatch\n                # IMPORTANT: The line that runs the graph on a minibatch.\n                # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n                _ , temp_cost = sess.run([optimizer, cost], feed_dict={X:minibatch_X, Y:minibatch_Y})\n                \n                minibatch_cost += temp_cost \/ num_minibatches\n                \n\n            # Print the cost every epoch\n            if print_cost == True and epoch % 5 == 0:\n                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n            if print_cost == True and epoch % 1 == 0:\n                costs.append(minibatch_cost)\n        \n        \n        # plot the cost\n        plt.plot(np.squeeze(costs))\n        plt.ylabel('cost')\n        plt.xlabel('iterations (per tens)')\n        plt.title(\"Learning rate =\" + str(learning_rate))\n        plt.show()\n\n        # Calculate the correct predictions\n        predict_op = tf.argmax(Z3, 1)\n        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n        \n        # Calculate accuracy on the test set\n        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n        print(accuracy)\n        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n        print(\"Train Accuracy:\", train_accuracy)\n        print(\"Test Accuracy:\", test_accuracy)\n                \n        return train_accuracy, test_accuracy, parameters","57c83be9":"# Run the model now it is created\n_, _, parameters = model(X_train, y_train, X_val, y_val)","f380d366":"## Initialize the Tensor Parameters","6aaa3c8d":"### Expected Output\n\nCost after epoch 0: 1.040116\nCost after epoch 5: 0.590800\n\nTensor(\"Mean_1:0\", shape=(), dtype=float32)\nTrain Accuracy: 0.8507965\nTest Accuracy: 0.78971964","68eb08b6":"## Set parameters and categories\nGather the training and validation datasets, create the embedded categories to use, and define the height and width of images to process.","2b6eec19":"### Expected result:\nZ3 = [[ 1.5836598   0.75720584 -0.97342306 -0.14359426  0.32579383]\n [ 1.4317374   1.0383936  -0.93356955 -0.11601364  0.27605867]]","168f4e53":"## Preprocessing of the training and test data sets","be786b33":"## Look at some images","fa1d12fa":"### This defines the cnn_utils codes","08d3cd4b":"### Expected Output\nX = Tensor(\"Placeholder:0\", shape=(?, 64, 64, 3), dtype=float32)\nY = Tensor(\"Placeholder_1:0\", shape=(?, 5), dtype=float32) ","4e874882":"## Match the metadata to the training set\nHere well have a look a the size of each category","b5409070":"## Create the placeholders for Tensorflow","a0c360c5":"## Examine the processed data\n\nLets examine the shape of the data","6a8c3224":"## Create the model and test","a5e9ca3b":"## Compute the cost\n\n\n* **tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y)**: computes the softmax entropy loss. This function both computes the softmax activation function as well as the resulting loss. You can check the full documentation [here](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/nn\/softmax_cross_entropy_with_logits).\n* **tf.reduce_mean**: computes the mean of elements across dimensions of a tensor. Use this to sum the losses over all the examples to get the overall cost. You can check the full documentation [here](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/reduce_mean).\n","720cd3b5":"## Forward propagation\n\nIn TensorFlow, there are built-in functions that carry out the convolution steps for you.\n\n* **tf.nn.conv2d(X,W1, strides = [1,s,s,1], padding = 'SAME')**: given an input XX and a group of filters W1W1, this function convolves W1W1's filters on X. The third input ([1,f,f,1]) represents the strides for each dimension of the input (m, n_H_prev, n_W_prev, n_C_prev). You can read the full documentation [here](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/nn\/conv2d)\n\n* **tf.nn.max_pool(A, ksize = [1,f,f,1], strides = [1,s,s,1], padding = 'SAME')**: given an input A, this function uses a window of size (f, f) and strides of size (s, s) to carry out max pooling over each window. You can read the full documentation [here](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/nn\/max_pool)\n\n* **tf.nn.relu(Z1)**: computes the elementwise ReLU of Z1 (which can be any shape). You can read the full documentation [here](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/nn\/relu).\n\n* **tf.contrib.layers.flatten(P)**: given an input P, this function flattens each example into a 1D vector it while maintaining the batch-size. It returns a flattened tensor with shape [batch_size, k]. You can read the full documentation [here](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/contrib\/layers\/flatten).\n\n*  **tf.contrib.layers.fully_connected(F, num_outputs)**: given a the flattened input F, it returns the output computed using a fully connected layer. You can read the full documentation [here](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/contrib\/layers\/fully_connected).\n\nIn the last function above (**tf.contrib.layers.fully_connected**), the fully connected layer automatically initializes weights in the graph and keeps on training them as you train the model. Hence, you do not need to initialize those weights when initializing the parameters.\n\nImplement the forward_propagation function below to build the following model: CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED.\n\nIn detail, we will use the following parameters for all the steps:\n\n - Conv2D: stride 1, padding is \"SAME\"\n - ReLU\n - Max pool: Use an 8 by 8 filter size and an 8 by 8 stride, padding is \"SAME\"\n - Conv2D: stride 1, padding is \"SAME\"\n - ReLU\n - Max pool: Use a 4 by 4 filter size and a 4 by 4 stride, padding is \"SAME\"\n - Flatten the previous output.\n - FULLYCONNECTED (FC) layer: Apply a fully connected layer without an non-linear activation function. Do not call the softmax here. This will result in 5 neurons in the output layer, which then get passed later to a softmax. In TensorFlow, the softmax and cost function are lumped together into a single function, which you'll call in a different function when computing the cost. \n","3bb7343a":"### Expected Output:\ncost = 0.044414163","a0f8ca4c":"### Expected output:\nW1 = [ 0.00131723  0.1417614  -0.04434952  0.09197326  0.14984085 -0.03514394\n -0.06847463  0.05245192]\nW2 = [-0.08566415  0.17750949  0.11974221  0.16773748 -0.0830943  -0.08058\n -0.00577033 -0.14643836  0.24162132 -0.05857408 -0.19055021  0.1345228\n -0.22779644 -0.1601823  -0.16117483 -0.10286498]"}}