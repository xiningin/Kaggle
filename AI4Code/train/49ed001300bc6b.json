{"cell_type":{"abbd1f8f":"code","4ddb1bac":"code","c27a4af3":"code","12498179":"code","2484f069":"code","8ffddcec":"code","b4ceb508":"code","ee445590":"code","7f6c5e80":"code","32e57b15":"code","a63d6cd8":"code","a509849f":"code","1bd13ac6":"code","e14b05f3":"code","d51940ea":"code","0047acb2":"code","7641576d":"code","279816d1":"code","46bb15c7":"code","d4442964":"code","401fad37":"code","f9b6a430":"code","1d530c8c":"code","c04b80cd":"code","0adee767":"code","30b4fd15":"code","72899b54":"code","e749e49f":"code","5f7eb28a":"code","f48aff5d":"markdown","a76e0cd1":"markdown","3f0a179e":"markdown","48f098bc":"markdown","9ee53568":"markdown","ba5723a3":"markdown","981d35dd":"markdown","f2219e09":"markdown","be79b97a":"markdown","493215ad":"markdown","4463faf1":"markdown"},"source":{"abbd1f8f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd\nimport sklearn #model building package\nimport re #package to clean text\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4ddb1bac":"data = pd.read_csv(\"..\/input\/ssr-tweets-dataset\/SSR_tweet_dataset.csv\")","c27a4af3":"data.head()","12498179":"data.tail()","2484f069":"data.sample(5)","8ffddcec":"#shape of dataset\ndata.shape","b4ceb508":"#statistical information of dataset\ndata.describe()","ee445590":"#full information of dataset\ndata.info()","7f6c5e80":"print(\"Column Names : \\n\"+'-'*25)\nprint(data.columns)","32e57b15":"data.dtypes","a63d6cd8":"data.nunique()","a509849f":"data.isnull().sum()","1bd13ac6":"#calculate the percentage of nulls or NA values in each column\n\nprint(\"Percentage null or na values in df\")\n((data.isnull() | df.isna()).sum() * 100 \/ df.index.size).round(2)","e14b05f3":"#user_url have more than 90% missing data. It will be better to delete these columns as they will not provide any constructive information.\ndel data['user_url']\ndf.head()","d51940ea":"nullCount = ((data.isna().sum() \/ data.shape[0])* 100).reset_index().rename(columns = {\"index\": \"Columns\", 0: \"missing value percentage\"})\nfig,axes = plt.subplots(1,2,figsize=(14,5))\nplt.suptitle(\"Missing Value percentage\",fontsize=18)\nsns.heatmap(data.isna(),ax=axes[0])\nsns.barplot(nullCount['Columns'],nullCount['missing value percentage'],ax=axes[1])\nplt.xticks(rotation=90)\nplt.show()","0047acb2":"# replace nan of user_location with INDIA\ndata['user_location'].fillna('India',inplace=True)\n# replace nan of user_description with NO DESCRIPTION\ndata['user_description'].fillna('No Description',inplace=True)\n#check for all null values\ndata.isnull().sum()\n\n\n\n#We do not have much outliers in our data.","7641576d":"data.boxplot()\nplt.xticks(rotation=90)\nplt.show()","279816d1":"import pickle\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nfrom matplotlib import ticker\nfrom wordcloud import WordCloud\n\nimport nltk \nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer","46bb15c7":"word_list = [word for line in df for word in line.split()]\n\nsns.set(style=\"darkgrid\")\ncounts = Counter(word_list).most_common(50)\ncounts_df = pd.DataFrame(counts)\ncounts_df\ncounts_df.columns = ['word', 'frequency']\n\nfig, ax = plt.subplots(figsize = (12, 12))\nax = sns.barplot(y=\"word\", x='frequency', ax = ax, data=counts_df)\nplt.savefig('wordcount_bar.png')","d4442964":"wordcloud = WordCloud(\n    background_color='black',\n    max_words=50,\n    max_font_size=40, \n    scale=5,\n    random_state=1,\n    collocations=False,\n    normalize_plurals=False\n).generate(' '.join(word_list))\n\n\nplt.figure(figsize = (12, 10), facecolor = None)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad = 0)","401fad37":"# splitting date and time\ndf = data\ndate=[]\ntime=[]\nfor i in data['created_at']:\n    date.append(i.split(' ')[0])\n    time.append(i.split(' ')[1])\ndf['created_on']=date\ndf['created_at']=time\ndf.head(3)","f9b6a430":"try:\n    data.drop('user_url',axis=1,inplace=True)\nexcept:\n    print(\"URL dropped\")","1d530c8c":"hashtags = []\nhashtags_count = []\nperson_tags = []\nperson_tags_count = []\nfor sen in data['text']:\n    hashes = []\n    tags = []\n    sen_list = sen.split(' ')\n    for word in sen_list:\n        if len(word)>1:\n            if word[0]=='#':\n                hashes.append(word)\n            if word[0]=='@':\n                tags.append(word)\n    hashtags.append(tuple(hashes))#converted to tuple as tuple is a hashable object\n    person_tags.append(tuple(tags))\n    hashtags_count.append(len(hashes))\n    person_tags_count.append(len(tags))\n      \nlen(person_tags),len(hashtags),len(hashtags_count),len(person_tags_count)","c04b80cd":"df['tagged_persons'] = tuple(person_tags)\ndf['hashtags'] = tuple(hashtags)\ndf['hashtags_count'] = hashtags_count\ndf['tagged_persons_count'] = person_tags_count\ndf.head(5)","0adee767":"print(\"Our dataset has {} persons tagged\".format(df['tagged_persons_count'].sum()))\nprint(\"In our dataset users used {} hashtags \".format(df['hashtags_count'].sum()))","30b4fd15":"hashData = df.hashtags.value_counts()[1:8].reset_index()\nfig,axes = plt.subplots(1,1,figsize=(14,5))\nplt.suptitle(\"Trending Hashtags Used\",fontsize=18)\nsns.barplot(data = hashData , y='index',x='hashtags')\nplt.show()","72899b54":"tagData = df.tagged_persons.value_counts()[1:8].reset_index()\nfig,axes = plt.subplots(1,1,figsize=(14,5))\nplt.suptitle(\"Most Tagged Persons\",fontsize=18)\nsns.barplot(data = tagData , y='index',x='tagged_persons')\nplt.show()","e749e49f":"df = data.user_location.value_counts()[:7].reset_index()\nfig,axes = plt.subplots(1,2,figsize=(14,5))\nplt.suptitle(\"Most Common Locations \",fontsize=18)\nsns.lineplot(x=df[\"index\"], y = df[\"user_location\"],ax=axes[1]) \nsns.barplot(y=df[\"index\"], x = df[\"user_location\"],ax=axes[0]) \nplt.xticks(rotation=90)\nplt.show()","5f7eb28a":"df = data.source.value_counts()[:7].reset_index()\nfig,axes = plt.subplots(1,2,figsize=(14,5))\nplt.suptitle(\"Common Sources Used by Users \",fontsize=18)\nsns.barplot(y=df[\"index\"], x = df[\"source\"],ax=axes[0]) \nsns.lineplot(x=df[\"index\"], y = df[\"source\"],ax=axes[1]) \nplt.xticks(rotation=90)\nplt.show()","f48aff5d":"# BOXPLOT","a76e0cd1":"Thank you","3f0a179e":"# References:\nhttps:\/\/seaborn.pydata.org\/ , https:\/\/towardsdatascience.com\/exploratory-data-analysis-in-python-c9a77dfa39ce","48f098bc":"# Clearing Null Values","9ee53568":"# Random five row","ba5723a3":"# CONCLUSION\n### The data do not have much outliers.\n### Users prefer to leave their descriptive information as the data has a lot of missing values in some columns(descriptive columns).\n### Most of the users are from India and a few from other countries too.","981d35dd":"# Reading CSV file","f2219e09":"# Last five row","be79b97a":"# First five row","493215ad":"# Overview\nDataset consists of 14 columns :\n#### 'id': Id of the tweet posted\n#### 'created_at': Date and Time of the tweet posted\n#### 'retweet_count': Count of how many times the same tweet is re-tweeted.\n#### 'source': From which platform the tweet was posted\n#### 'user_id': Id of the user posting the tweet\n#### 'user_name': Name of the user posting the tweet\n#### 'user_description': Description of the user posting the tweet\n#### 'userfollowercount': Count of how many followers does the user have\n#### 'userfriendscount': Count of how many friends does the user have\n#### 'user_location': Location from where the user posted the tweet\n#### 'user_verified': Is the user verified by Twitter or not\n#### 'user_url': URL of the user's profile\n#### 'tweet': Tweet posted by user\n#### 'lengthoftweet': The total length of the tweet posted by the user ( words ).","4463faf1":"# Import library"}}