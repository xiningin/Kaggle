{"cell_type":{"21c46c25":"code","55a64386":"code","54cd3b09":"code","ea7b91b3":"code","f9fff240":"code","3adcf54c":"code","255cdef1":"code","f764d2eb":"code","97766669":"code","3ca48029":"code","e7195f20":"code","bbe819ab":"code","0ff76c21":"code","6c60d744":"code","242c6217":"code","61bf1bbd":"code","0f2011e3":"code","f9a1b3b5":"code","60c2d56d":"code","14d7ad9d":"code","a06b9047":"code","e5dadeee":"code","665a6664":"code","707fb16b":"code","f66890a1":"code","270f1ae3":"code","ced268d8":"code","bfb4124b":"code","e67a2f76":"markdown","15ee4912":"markdown","7592fc9b":"markdown","013db067":"markdown","d23e75f4":"markdown","d3acbe6d":"markdown","0917cbf7":"markdown","776f5e72":"markdown","b74a02d7":"markdown","4a8874f9":"markdown"},"source":{"21c46c25":"!pip install -q efficientnet >> \/dev\/null","55a64386":"import os, glob, cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import get_custom_objects\nimport efficientnet.tfkeras as efn\nfrom tqdm import tqdm","54cd3b09":"SEED = 42\nEPOCHS = 100\nBATCH_SIZE = 32\nIMG_HEIGHT = 192\nIMG_WIDTH = 256\n\n# cataract dataset\nIMG_ROOT = '..\/input\/cataractdataset\/dataset\/'\nIMG_DIR = [IMG_ROOT+'1_normal', \n           IMG_ROOT+'2_cataract', \n           IMG_ROOT+'2_glaucoma', \n           IMG_ROOT+'3_retina_disease']\n\n# ocular-disease-recognition dataset\nOCU_IMG_ROOT = '..\/input\/ocular-disease-recognition-odir5k\/ODIR-5K\/Training Images\/'\nocu_df = pd.read_excel('..\/input\/ocular-disease-recognition-odir5k\/ODIR-5K\/data.xlsx')","ea7b91b3":"def seed_everything(seed):\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\n\nseed_everything(SEED)","f9fff240":"cat_df = pd.DataFrame(0, \n                  columns=['paths', \n                           'cataract'],\n                  index=range(601))\n\nfilepaths = glob.glob(IMG_ROOT + '*\/*')\n\n\nfor i, filepath in enumerate(filepaths):\n    filepath = os.path.split(filepath)\n    cat_df.iloc[i, 0] = filepath[0] + '\/' + filepath[1]\n    \n    if filepath[0] == IMG_DIR[0]:    # normal\n        cat_df.iloc[i, 1] = 0\n    elif filepath[0] == IMG_DIR[1]:  # cataract\n        cat_df.iloc[i, 1] = 1\n    elif filepath[0] == IMG_DIR[2]:  # glaucoma\n        cat_df.iloc[i, 1] = 2\n    elif filepath[0] == IMG_DIR[3]:  # retine_disease\n        cat_df.iloc[i, 1] = 3\n        \n# only sample normal and cataract        \ncat_df = cat_df.query('0 <= cataract < 2')\ncat_df","3adcf54c":"print('Number of normal and cataract images')\nprint(cat_df['cataract'].value_counts())","255cdef1":"ocu_df.head()","f764d2eb":"def has_cataract_mentioned(text):\n    if 'cataract' in text:\n        return 1\n    else:\n        return 0\n    \nocu_df['left_eye_cataract'] = ocu_df['Left-Diagnostic Keywords']\\\n                                 .apply(lambda x: has_cataract_mentioned(x))\nocu_df['right_eye_cataract'] = ocu_df['Right-Diagnostic Keywords']\\\n                                 .apply(lambda x: has_cataract_mentioned(x))","97766669":"le_df = ocu_df.loc[:, ['Left-Fundus', 'left_eye_cataract']]\\\n        .rename(columns={'left_eye_cataract':'cataract'})\nle_df['paths'] = OCU_IMG_ROOT + le_df['Left-Fundus']\nle_df = le_df.drop('Left-Fundus', axis=1)\n\n\nre_df = ocu_df.loc[:, ['Right-Fundus', 'right_eye_cataract']]\\\n        .rename(columns={'right_eye_cataract':'cataract'})\nre_df['paths'] = OCU_IMG_ROOT + re_df['Right-Fundus']\nre_df = re_df.drop('Right-Fundus', axis=1)","3ca48029":"le_df.head()","e7195f20":"re_df.head()","bbe819ab":"print('Number of left eye images')\nprint(le_df['cataract'].value_counts())\nprint('\\nNumber of right eye images')\nprint(re_df['cataract'].value_counts())","0ff76c21":"def downsample(df):\n    df = pd.concat([\n        df.query('cataract==1'),\n        df.query('cataract==0').sample(sum(df['cataract']), \n                                       random_state=SEED)\n    ])\n    return df\n\n\nle_df = downsample(le_df)\nre_df = downsample(re_df)\n\nprint('Number of left eye images')\nprint(le_df['cataract'].value_counts())\nprint('\\nNumber of right eye images')\nprint(re_df['cataract'].value_counts())","6c60d744":"ocu_df = pd.concat([le_df, re_df])\nocu_df.head()","242c6217":"df = pd.concat([cat_df, ocu_df], ignore_index=True)\ndf","61bf1bbd":"train_df, test_df = train_test_split(df, \n                                     test_size=0.2, \n                                     random_state=SEED, \n                                     stratify=df['cataract'])\n\ntrain_df, val_df = train_test_split(train_df,\n                                    test_size=0.15,\n                                    random_state=SEED,\n                                    stratify=train_df['cataract'])","0f2011e3":"def create_datasets(df, img_width, img_height):\n    imgs = []\n    for path in tqdm(df['paths']):\n        img = cv2.imread(path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (img_width, img_height))\n        imgs.append(img)\n        \n    imgs = np.array(imgs, dtype='float32')\n    df = pd.get_dummies(df['cataract'])\n    return imgs, df\n\n\ntrain_imgs, train_df = create_datasets(train_df, IMG_WIDTH, IMG_HEIGHT)\nval_imgs, val_df = create_datasets(val_df, IMG_WIDTH, IMG_HEIGHT)\ntest_imgs, test_df = create_datasets(test_df, IMG_WIDTH, IMG_HEIGHT)\n\ntrain_imgs = train_imgs \/ 255.0\nval_imgs = val_imgs \/ 255.0\ntest_imgs = test_imgs \/ 255.0","f9a1b3b5":"# plot the first 25 sheets of image data for training\n\nf, ax = plt.subplots(5, 5, figsize=(15,15))\nnorm_list = list(train_df[0][:25])\nfor i, img in enumerate(train_imgs[:25]):\n    ax[i\/\/5, i%5].imshow(img)\n    ax[i\/\/5, i%5].axis('off')\n    if norm_list[i] == 1:\n        ax[i\/\/5, i%5].set_title('TrainData: Normal')\n    else:\n        ax[i\/\/5, i%5].set_title('TrainData: Cataract')\nplt.show()","60c2d56d":"# plot the first 25 sheets of image data for Test\nf, ax = plt.subplots(5, 5, figsize=(15,15))\nnorm_list = list(test_df[0][:25])\nfor i, img in enumerate(test_imgs[:25]):\n    ax[i\/\/5, i%5].imshow(img)\n    ax[i\/\/5, i%5].axis('off')\n    if norm_list[i] == 1:\n        ax[i\/\/5, i%5].set_title('TestData: Normal')\n    else:\n        ax[i\/\/5, i%5].set_title('TestData: Cataract')\nplt.show()","14d7ad9d":"class Mish(tf.keras.layers.Layer):\n\n    def __init__(self, **kwargs):\n        super(Mish, self).__init__(**kwargs)\n        self.supports_masking = True\n\n    def call(self, inputs):\n        return inputs * K.tanh(K.softplus(inputs))\n\n    def get_config(self):\n        base_config = super(Mish, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\ndef mish(x):\n    return tf.keras.layers.Lambda(lambda x: x*K.tanh(K.softplus(x)))(x)\n \nget_custom_objects().update({'mish': Activation(mish)})","a06b9047":"input_shape = (IMG_HEIGHT, IMG_WIDTH, 3)\n\nmodel = Sequential()\nmodel.add(Conv2D(16, kernel_size=3, padding='same', \n                 input_shape=input_shape, activation='mish'))\nmodel.add(Conv2D(16, kernel_size=3, padding='same', activation='mish'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(3))\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(16, kernel_size=3, padding='same', activation='mish'))\nmodel.add(Conv2D(16, kernel_size=3, padding='same', activation='mish'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(3))\nmodel.add(Dropout(0.3))\nmodel.add(Flatten())\nmodel.add(Dense(2, activation='softmax'))\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n\nmodel.summary()","e5dadeee":"generator = ImageDataGenerator(horizontal_flip=True, \n                               height_shift_range=0.1,\n                               fill_mode='reflect') \n\n\n\nes_callback = tf.keras.callbacks.EarlyStopping(patience=20, \n                                               verbose=1, \n                                               restore_best_weights=True)\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=10, verbose=1)","665a6664":"history = model.fit(generator.flow(train_imgs, \n                                   train_df,\n                                   batch_size=BATCH_SIZE), \n                    epochs=EPOCHS,\n                    steps_per_epoch=len(train_imgs)\/BATCH_SIZE,\n                    callbacks=[es_callback, reduce_lr],\n                    validation_data=(val_imgs, val_df))\n\n\npd.DataFrame(history.history)[['accuracy', 'val_accuracy']].plot()\npd.DataFrame(history.history)[['loss', 'val_loss']].plot()\nplt.show()","707fb16b":"model.evaluate(test_imgs, test_df) ","f66890a1":"def build_model(img_height, img_width, n):\n    inp = Input(shape=(img_height,img_width,n))\n    efnet = efn.EfficientNetB0(\n        input_shape=(img_height,img_width,n), \n        weights='imagenet', \n        include_top=False\n    )\n    x = efnet(inp)\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(2, activation='softmax')(x)\n    model = tf.keras.Model(inputs=inp, outputs=x)\n    opt = tf.keras.optimizers.Adam(learning_rate=0.000003)\n    loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.01)\n    model.compile(optimizer=opt, loss=loss, metrics=['accuracy'])\n    return model\n\nmodel = build_model(IMG_HEIGHT, IMG_WIDTH, 3)\nmodel.summary()","270f1ae3":"generator = ImageDataGenerator(horizontal_flip=True, \n                               height_shift_range=0.1,\n                               fill_mode='reflect') \n\n\n\nes_callback = tf.keras.callbacks.EarlyStopping(patience=20, \n                                               verbose=1, \n                                               restore_best_weights=True)\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=10, verbose=1)","ced268d8":"history = model.fit(generator.flow(train_imgs, \n                                   train_df,\n                                   batch_size=BATCH_SIZE), \n                    epochs=EPOCHS,\n                    steps_per_epoch=len(train_imgs)\/BATCH_SIZE,\n                    callbacks=[es_callback, reduce_lr],\n                    validation_data=(val_imgs, val_df))\n\n\npd.DataFrame(history.history)[['accuracy', 'val_accuracy']].plot()\npd.DataFrame(history.history)[['loss', 'val_loss']].plot()\nplt.show()","bfb4124b":"model.evaluate(test_imgs, test_df) ","e67a2f76":"## Process Ocular disease recognition dataset <a name=\"process2\"> <\/a>","15ee4912":"## Create datasets <a name=\"create\"> <\/a>\nCombine the two metadata and use them to load the image data and create datasets.","7592fc9b":"Use some image data augmentation to generate randomly augmented image data from the ImageDataGenerator Object.","013db067":"There is a large bias in the dataset. So make it even.","d23e75f4":"<h1><font size=\"6\">Cataract Classification<\/font><\/h1>\n\nIn this notebook, uses two retina datasets to challenge the cataract classification.\n\n## Contents\n* [Import libraries](#import)\n* [Set configurations and read metadata](#set)\n* [Process Cataract dataset](#process1)\n* [Process Ocular disease recognition dataset](#process2)\n* [Create datasets](#create)\n* [Build the model(1)](#build1)\n* [Build the model(2)](#build2)","d3acbe6d":"## Build the model(1) <a name=\"build1\"> <\/a>","0917cbf7":"## Import libraries <a name=\"import\"> <\/a>","776f5e72":"## Set configurations and read metadata <a name=\"set\"> <\/a>","b74a02d7":"## Build the model(2) <a name=\"build2\"> <\/a>\nWe will train using a model that has been pre-trained.","4a8874f9":"## Process Cataract dataset <a name=\"process1\"> <\/a>"}}