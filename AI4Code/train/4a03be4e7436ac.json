{"cell_type":{"81830255":"code","d20da455":"code","05fed614":"code","2db57d4b":"code","2654819a":"code","4c565970":"code","a627f71d":"code","614d42fa":"code","6135e2b5":"code","7e163ea7":"code","4da58527":"code","38e9a3a2":"code","6a08670e":"code","d447484b":"code","3e32176f":"code","99f3e14c":"code","eaf332b1":"code","d0ffdc80":"code","51a2fa73":"code","1095adbf":"code","70b6f42a":"code","66bd30ee":"code","5f3366f7":"code","679113b0":"code","95c8f539":"code","aee2f682":"code","9778917c":"code","729f2c60":"code","53c083ff":"code","7d735a18":"code","d186198c":"code","2d33df1f":"code","93fc6fe6":"markdown","671c5d45":"markdown","f1b3d2c5":"markdown","7427a4f1":"markdown","fdb1e936":"markdown","b9352dc5":"markdown","3c730df1":"markdown","433cdea7":"markdown","2d096f05":"markdown","716d948a":"markdown","a253fdcb":"markdown","7b7b44ff":"markdown","17544c15":"markdown","0361286b":"markdown"},"source":{"81830255":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn as skl\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d20da455":"df = pd.read_csv(\"\/kaggle\/input\/heart.csv\")","05fed614":"df.head()","2db57d4b":"df.describe()","2654819a":"df.info()","4c565970":"nrows,ncols = 5,3\ncount = 0\nfig,axes = plt.subplots(nrows,ncols)\nfor i in range(nrows):\n    for j in range(ncols):\n        if i==nrows-1 and j==ncols-1:\n            break\n        df.iloc[:,count].plot.kde(ax = axes[i,j],figsize=(8,10),title=df.columns[count])\n        plt.tight_layout()\n        count+=1\n        ","a627f71d":"dependent_df = df.iloc[:,-1]\nindependent_df = df.iloc[:,:-1]\nindependent_df.head()","614d42fa":"df.corr()","6135e2b5":"plt.figure(figsize=(18,6))\nsns.heatmap(df.corr(),annot=True)\nplt.tight_layout()\nplt.show()","7e163ea7":"nan_percent = df.isna().mean()*100\nnan_count = df.isna().sum()\nnan_df = pd.concat([nan_percent.round().rename(\"Missing Percentage\"),nan_count.rename(\"Missing Count\")], axis = 1)\nnan_df","4da58527":"#using dropna to remove rows\nafter_drop_df = df.dropna(axis=0)\nafter_drop_df.isna().sum()","38e9a3a2":"zero_fill = df.fillna(0)\n#In back_fill the last column null values filled with 0,last but one with 1, then before that with 2 ans so on...\nback_fill =  df.fillna('bfill')\n#In forward fill the first column with 0, second with 1 and so on.\nforward_fill = df.fillna('ffill')","6a08670e":"#we can check for unique values of columns to decide for categorical since description is not available\ndf.cp.unique()\ncols = df.columns\nfor i in cols:\n    print(i)\n    print(df[i].unique())","d447484b":"#Now we traverse with column and fill with theirs means,medians and mode.\n#we have to do these based on column nature\n#Even though all are in float64 or int64 they doesn't mean numerical data\n#Like sex column is a categorical data still. Hence forth I use mode.so for every column it depends so we should do this filling column wise\ncols = df.columns\ncategorical_cols = ['sex','cp','fbs','restecg','exang','slope','ca','thal']\ndrop_row = ['target']\nfor i in cols:\n    if i in categorical_cols:\n        df[i] = df[i].fillna(df[i].mode())\n    elif i in drop_row:\n        df.dropna(axis=0,inplace=True)\n    else:\n        df[i] = df[i].fillna(df[i].mean())","3e32176f":"df.isna().sum()","99f3e14c":"#Let's know the each column's max and min to know th range\ncols = df.columns\nfor i in cols:\n    if i not in categorical_cols:\n        print(f\"{i} has min:{df[i].min()} and max:{df[i].max()}\")","eaf332b1":"#Even Though the ranges are still okay just for assignment \n#Purpose we are going to do min_max scaling\ndef minMaxScaler(df_i):\n    mini = df_i.min()\n    maxi = df_i.max()\n    df_i = (df_i-mini)\/(maxi-mini)\n    return df_i\nfor i in cols:\n    if i not in categorical_cols:\n        df[i] = minMaxScaler(df[i])","d0ffdc80":"#Let's check the range of those functions again!!!\nfor i in cols:\n    if i not in categorical_cols:\n        print(f\"{i} has min:{df[i].min()} and max:{df[i].max()}\")","51a2fa73":"for i in cols:\n    print(df[i].unique())","1095adbf":"categorical_cols","70b6f42a":"dfc = df[categorical_cols]","66bd30ee":"dfc = dfc.astype('category')","5f3366f7":"dfc.info()","679113b0":"def myOneHotEncoder(df,i):\n    newdf = pd.get_dummies(df[i],drop_first = True)\n    df.drop(labels=i,inplace=True,axis=1)\n    df = pd.concat([df,newdf],axis=1)\n    return df","95c8f539":"m = pd.get_dummies(dfc[['slope']])\nm","aee2f682":"dfc.drop('slope',axis=1)\ndfc = pd.concat([dfc,m],axis=1)\ndfc","9778917c":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(dependent_df, independent_df, test_size=0.33, random_state=42)","729f2c60":"dependent_df = df.iloc[:,:-1]\nindependent_df = df.iloc[:,-1]","53c083ff":"from sklearn.model_selection import KFold\nX = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\ny = np.array([1, 2, 3, 4])\nkf = KFold(n_splits=2)\nkf.get_n_splits(X)\n\nprint(kf)\n\nfor train_index, test_index in kf.split(X):\n    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]","7d735a18":"df.info()","d186198c":"\ndf.plot.scatter(x='age',y ='target')","2d33df1f":"plt.figure(figsize=(20,12))\ndf.plot.hist()\nplt.tight_layout()\nplt.show()","93fc6fe6":"*Finding Correlation*","671c5d45":"*Distribution of each class*","f1b3d2c5":"**Now we are doing inplace filling**","7427a4f1":"# Feature Scaling","fdb1e936":"# Handling Missing Values","b9352dc5":"**Count of nan column wise**","3c730df1":"# Knowing the DataSet","433cdea7":"*Removing nan values but not in-place*","2d096f05":"Now I decide that the below cols are categorical and I use mode to fill them\n\n<ul>sex<\/ul>\n<ul>cp<\/ul>\n<ul>fbs<\/ul>\n<ul>restecg<\/ul>\n<ul>exang<\/ul>\n<ul>slop<\/ul>\n<ul>ca<\/ul>\n<ul>thal<\/ul>\n<ul>target<\/ul>\n#we won't fill this value since it is independent but rather we remove rows with the null values in this column\n","716d948a":"# Categorical Data Encoding","a253fdcb":"*Normalization (Min-Max) Scaling*","7b7b44ff":"*Now Filling values still not in-place*","17544c15":"# Splitting of Data","0361286b":"*Splitting Into Dependent and Independent Attributes*"}}