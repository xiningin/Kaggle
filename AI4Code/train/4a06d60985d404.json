{"cell_type":{"271fc0bd":"code","ed42e842":"code","c9d55359":"code","0783abb8":"code","669f9bf5":"code","7822920f":"code","afd36a1e":"code","96b0b585":"code","cdac712a":"code","ed1412a8":"code","064d8163":"markdown","9ad52c4b":"markdown","a2591e78":"markdown","f9efe6b2":"markdown","75ebdc06":"markdown","be66f2d3":"markdown","dccfabb8":"markdown","6e755549":"markdown"},"source":{"271fc0bd":"import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport glob\nfrom PIL import Image\nimport hashlib\nfrom io import BytesIO\nfrom skimage import io\nimport contextlib2\nimport json\nimport cv2\nimport os, shutil  \nfrom functools import partial\n%matplotlib inline  ","ed42e842":"# A few helper functions for reading in image and masks (from json)\n\ndef read_tif_file(fname):\n    img = io.imread(fname)\n    img = np.squeeze(img)\n    if img.shape[0] == 3: # swap axes as required\n        img = img.swapaxes(0,1)\n        img = img.swapaxes(1,2)\n    return img\n\ndef read_mask_file(fname, mshape):\n    with open(fname) as f:\n        mdata = json.load(f)\n        polys = []\n        for index in range(mdata.__len__()):\n            if mdata[index]['properties']['classification']['name'] == 'glomerulus':\n                geom = np.array(mdata[index]['geometry']['coordinates'])\n                if geom.shape[0] == 1:\n                    polys.append(geom[0].astype('int32'))\n        mask = np.zeros(mshape, dtype=np.int8)\n        cv2.fillPoly(mask, polys, 1)\n        mask = mask.astype(bool, copy=False)\n    return mask","c9d55359":"# patches are stored as jpeg, masks as PNG\ndef create_tf_example(patch, m_patch, fid, x, y, size):\n    filename = fid+'.tiff'\n    height = size # Image height\n    width = size # Image width\n    buf= BytesIO()\n    im = Image.fromarray(np.uint8(patch))\n    im.save(buf, format= 'JPEG') # encode to jpeg in memory\n    encoded_image_data= buf.getvalue()\n    image_format = b'jpeg'\n    source_id = fid+'-'+str(x)+'-'+str(y) # must be unique\n    # A hash of the image is used in some frameworks\n    key = hashlib.sha256(encoded_image_data).hexdigest()\n    # Mask encoding\n    buf= BytesIO()\n    mim = Image.fromarray(np.uint8(m_patch))\n    mim.save(buf, format= 'PNG') # encode to png in memory\n    encoded_mask_data= buf.getvalue()\n    mask_format = b'png'\n    \n    tf_record = tf.train.Example(features=tf.train.Features(feature={\n        'image\/height': tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n        'image\/width': tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n        'image\/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename.encode()])),\n        'image\/source_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[source_id.encode()])),\n        'image\/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[encoded_image_data])),\n        'image\/key\/sha256': tf.train.Feature(bytes_list=tf.train.BytesList(value=[key.encode()])),\n        'image\/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_format])),\n        'image\/patch-x': tf.train.Feature(int64_list=tf.train.Int64List(value=[x])),\n        'image\/patch-y': tf.train.Feature(int64_list=tf.train.Int64List(value=[y])),\n        'mask\/patch-x': tf.train.Feature(int64_list=tf.train.Int64List(value=[x])),\n        'mask\/patch-y': tf.train.Feature(int64_list=tf.train.Int64List(value=[y])),\n        'mask\/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[encoded_mask_data])),\n        'mask\/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=[mask_format])),\n    }))\n    \n    return tf_record","0783abb8":"PATH = '\/kaggle\/input\/hubmap-kidney-segmentation\/train\/'\nfilelist = glob.glob(PATH+'*.tiff')\nfilelist","669f9bf5":"fnames = []\nfor f in filelist:\n    fnames.append(f.split('train\/')[-1].split('.')[0])\nfnames","7822920f":"#%%time\nPATH = '\/kaggle\/input\/hubmap-kidney-segmentation\/train\/'\nIMG_SIZE = 1024 # adjust according to desired tile size\nOVERLAP = IMG_SIZE\/\/2 # overlap between each tile\nSTEP = IMG_SIZE-OVERLAP\nSCALES = 2 # number of times to downscale each patch (generate SCALES+1 sets of images)\nSCALE_FACTOR = 2 # scale factor to use for each set, adjust according to needs\nBKGND_1_OF_X = 15 # add every n'th background image to the TFRecord\n\nimg_sizes = np.zeros(SCALES+1, dtype=int)\nimg_sizes[0] = IMG_SIZE\nfor i in range(SCALES):\n    img_sizes[i+1] = int(img_sizes[i]\/SCALE_FACTOR)\n\nfilelist = glob.glob(PATH+'*.tiff')\nFCNT = len(filelist)\n\ndef open_sharded_tfrecords(exit_stack, names, size):\n    tf_record_output_filenames = [\n        '{}-{}.tfrecord'.format(names[idx], size)\n        for idx in range(len(names))\n        ]\n    tfrecords = [\n        exit_stack.enter_context(tf.io.TFRecordWriter(file_name))\n        for file_name in tf_record_output_filenames\n    ]\n    return tfrecords\n\ngcnt = np.zeros(len(filelist), dtype=int)\n\n# A context2.ExitStack is used to automatically close all the TFRecords created \nwith contextlib2.ExitStack() as tf_record_close_stack:\n    # create list of TFRecords\n    output_tfrecords1 = []\n    for scnt in range(SCALES+1):\n        output_tfrecords1.append(open_sharded_tfrecords(tf_record_close_stack, fnames, img_sizes[scnt]))\n    # process images w\/overlapped tiles\n    output_shard_index = 0\n    for file in filelist:\n        print(file)\n        fid = file.replace('\\\\','.').replace('\/','.').split('.')[-2]        \n        img, mask = np.zeros(10), np.zeros(10) \n        img = read_tif_file(file)\n        dims = np.array(img.shape[:2])\n        mask = read_mask_file(file.split('.')[0]+'.json', dims)\n        bcnt = 0\n        for x in range((img.shape[0]-OVERLAP)\/\/STEP):\n            for y in range((img.shape[1]-OVERLAP)\/\/STEP):\n                # Extract patch\n                patch = img[x*STEP:x*STEP+IMG_SIZE, y*STEP:y*STEP+IMG_SIZE]\n                m_patch = mask[x*STEP:x*STEP+IMG_SIZE, y*STEP:y*STEP+IMG_SIZE]*255\n                # separate tissue from bakground by checking for non-zero pixels in mask\n                IsTissue = False\n                if np.max(m_patch) == 255:\n                    IsTissue = True;\n                tf_record = create_tf_example(patch, m_patch, fid, x, y, size=img_sizes[0])\n                if IsTissue:\n                    output_tfrecords1[0][output_shard_index].write(tf_record.SerializeToString())\n                    gcnt[output_shard_index] += 1\n                else:\n                    if bcnt == BKGND_1_OF_X:\n                        output_tfrecords1[0][output_shard_index].write(tf_record.SerializeToString())\n                        gcnt[output_shard_index] += 1\n                # create downscaled images\n                for s in range(SCALES): \n                    spatch = cv2.resize(patch, dsize=(img_sizes[s+1], img_sizes[s+1]), interpolation = cv2.INTER_AREA)\n                    sm_patch = cv2.resize(m_patch.astype(int), dsize=(img_sizes[s+1], img_sizes[s+1]), interpolation = cv2.INTER_NEAREST)\n                    tf_record = create_tf_example(spatch, sm_patch, fid, x, y, size=img_sizes[s+1])\n                    if IsTissue:\n                        output_tfrecords1[s+1][output_shard_index].write(tf_record.SerializeToString())\n                    else:\n                        if bcnt == BKGND_1_OF_X:\n                            output_tfrecords1[s+1][output_shard_index].write(tf_record.SerializeToString())\n                if bcnt == BKGND_1_OF_X:\n                    bcnt = 0\n                else:\n                    bcnt = bcnt + 1\n        output_shard_index += 1\n","afd36a1e":"dparams = {\n    \"IMG_SIZE\": IMG_SIZE,\n    \"SCALE_FACTOR\": SCALE_FACTOR}\nwith open(\"dparams.json\", \"w\") as json_file:\n    json_file.write(json.dumps(dparams, indent = 4))","96b0b585":"import pandas as pd\n\nrecsizes = []\nnum_shards = len(filelist)\nfor i in range(num_shards):\n    for j in range(len(img_sizes)):\n        recsizes.append(['{}-{}.tfrecord'.format(fnames[i], img_sizes[j]), gcnt[i]])\ndf = pd.DataFrame(recsizes, columns=['File', 'ImgCount'])\ndf.to_pickle('.\/record_stats.pkl')\ndf.head(5)","cdac712a":"def plot_imgs(dataset):\n    fig = plt.figure(figsize=(18,18))\n    idx=1\n    for raw_record in dataset.take(36):\n        axes = fig.add_subplot(6, 6, idx)\n        example = tf.train.Example()\n        example.ParseFromString(raw_record.numpy())\n        img_encoded=example.features.feature['image\/encoded'].bytes_list.value[0]\n        img = Image.open(BytesIO(img_encoded))\n        mask_encoded=example.features.feature['mask\/encoded'].bytes_list.value[0]\n        mask = Image.open(BytesIO(mask_encoded))\n        plt.setp(axes, xticks=[], yticks=[])\n        plt.imshow(img)\n        plt.imshow(mask, alpha=0.25)\n        idx=idx+1","ed1412a8":"fname='.\/095bf7a1f-256.tfrecord'\ndataset = tf.data.TFRecordDataset(fname)\ndataset = dataset.shuffle(2048, reshuffle_each_iteration=True)\nplot_imgs(dataset)","064d8163":"Create a .json file with a few useful parameters we might need during training\/inference:","9ad52c4b":"Export a table with number of images per TFRecord.","a2591e78":"## References\nThis notebook uses\/modifies some code snippets from these notebooks:\n* [Global Wheat to TFRecords](https:\/\/www.kaggle.com\/mistag\/global-wheat-to-tfrecords) (own work)\n* [HuBMap: Read data and build TFRecords](https:\/\/www.kaggle.com\/marcosnovaes\/hubmap-read-data-and-build-tfrecords)   \n\nIn addition some sample code from Keras documentation.","f9efe6b2":"# Check the output files\nThe final check is to load and plot a couple of TFRecords and verify that everything loads OK.","75ebdc06":"# TIF to TFRecords in multiple resolutions\nIn this notebook we will transform the huge train images into TFRecords format.\nWhen creating TFRecords of a dataset it is most efficient for the processing pipeline to have TFRecords of a certain size, generally >10MBytes, to benefit from I\/O prefetching.  \n\n**Updated with the latest dataset!**","be66f2d3":"The function below creates a TFRecord from a single patch. The image is stored as JPEG, while the mask is stored as PNG (lossless). We also put in some extra metadata.","dccfabb8":"# TFRecords creation using patches\nThe super-resolution cell scan images need to be split into patches (or tiles if you like).   \n\nHere we go for 1024x1024 as the primary tile (patch) size. Adjust the IMG_SIZE variable further below to suit needs. We also create downscaled versions of 512x512 and 256x256.   ","6e755549":"## Create TFRecord per image\nWe create a separate TFRecord file for each image. Well, actually two: One for tiles containing glomeruli (\"Tissue\") and one for the rest (\"Bkgnd\")."}}