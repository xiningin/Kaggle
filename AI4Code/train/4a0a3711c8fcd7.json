{"cell_type":{"86ea2289":"code","68a4a162":"code","3cbf18a8":"code","72b35e6b":"code","20f18ff1":"code","e7134762":"code","e5363088":"code","5c926102":"code","9f023bea":"code","8a082499":"code","32297d03":"code","2a0d45ae":"code","ef5d67ee":"code","085df27f":"code","06ae849f":"code","7b296d6e":"code","bdaf07bc":"code","ffcbb970":"code","b22595cc":"code","0c3137ff":"code","de3fce1e":"code","d26dfc3b":"code","d84a3026":"code","20a7242f":"code","6925aef9":"code","06527cfe":"code","27b8b3b2":"code","d29d7283":"code","8ce98d46":"code","a6e93c3c":"code","e7ae1cdb":"code","074d0c8e":"code","57425be5":"code","c21678d5":"code","a61c13cc":"code","4dd85b6e":"code","31e460f8":"code","5e4a2584":"code","2e5d8dce":"code","4156f72a":"code","6f18206b":"code","329d6bcb":"code","3b9d10e0":"code","54769134":"code","b3e5849a":"code","6f99d42b":"code","e7f2db00":"code","e52e98b5":"code","ac434333":"code","f513ffe0":"markdown","b3dad200":"markdown","39695a6d":"markdown","d7af4659":"markdown","84ec7c91":"markdown","db3733bd":"markdown","b7b4b8bc":"markdown","fdd502b3":"markdown","9ba833e0":"markdown","8c86532d":"markdown","ab7fed23":"markdown","92446f6e":"markdown"},"source":{"86ea2289":"# imports\nimport os\nfrom pathlib import Path\nimport warnings\n\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","68a4a162":"pd.options.display.max_rows = 100\npd.options.display.max_columns = 100\nplt.style.use('ggplot')\nwarnings.filterwarnings('ignore')","3cbf18a8":"path = Path('\/kaggle\/input\/tabular-playground-series-jun-2021\/')\ntrain_df = pd.read_csv(path\/'train.csv')\ntest_df = pd.read_csv(path\/'test.csv')\nsample_submission = pd.read_csv(path\/'sample_submission.csv')","72b35e6b":"sample_submission.head()","20f18ff1":"train_df.shape, test_df.shape","e7134762":"# remove unnecessary columns like id column\ntrain_ids = train_df.id\ntrain_df.drop('id', axis=1, inplace=True)\ntest_ids = test_df.id\ntest_df.drop('id', axis=1, inplace=True)","e5363088":"target = train_df.target\ntrain_df.drop('target', axis=1, inplace=True)","5c926102":"# Encode target variable\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_enc = LabelEncoder()\ntarget_labels = pd.Series(label_enc.fit_transform(target), name='target')\ntarget_labels[:5]","9f023bea":"train_df.shape, test_df.shape","8a082499":"# null value check\ntrain_df.isnull().sum().sum(), test_df.isnull().sum().sum()","32297d03":"# target distribution\ntarget_value_counts = target.value_counts()\ntarget_value_percent = target.value_counts()*100\/len(train_df)\n\nplt.figure(figsize=(10, 4))\nplt.bar(target_value_counts.keys(), target_value_counts.values)\nfor (label, value), percent in zip(target_value_counts.items(), target_value_percent.values):\n    plt.text(label, value+1000, f'{percent:.1f}%', ha='center')\nplt.ylim(0, 60000)\nplt.title('Target class counts')\nplt.xlabel('Target class')\nplt.ylabel('Count')\nplt.grid(False)\nplt.tight_layout()\nplt.show()","2a0d45ae":"def get_num_unique(x):\n    return len(x.unique())\n\nfeature_unique_df = train_df.apply(lambda x: get_num_unique(x), axis=0).to_frame('n_unique')\nzero_percent_df = train_df.apply(lambda x: x.value_counts()[0]*100\/len(train_df), axis=0).to_frame('per_zero')\n\ntrain_describe_df = pd.concat([\n    train_df.describe(percentiles=[0.25, 0.5, 0.75, 0.95]).T.drop('count', axis=1),\n    feature_unique_df,\n    zero_percent_df\n], axis=1)\ntrain_describe_df.head()","ef5d67ee":"train_describe_df.sort_values(by=['std','n_unique']) \\\n                 .style.bar(subset=['mean', 'per_zero']) \\\n                 .background_gradient(subset=['n_unique', 'std'])","085df27f":"drop_the_zero_features = 0\nzero_feature_columns = ['feature_15', 'feature_17', 'feature_22', 'feature_36', 'feature_47', 'feature_49', 'feature_66', 'feature_74']\nif drop_the_zero_features:\n    train_df.drop(zero_feature_columns, axis=1, inplace=True)\n    test_df.drop(zero_feature_columns, axis=1, inplace=True)\n\ntrain_df.shape, test_df.shape","06ae849f":"from sklearn.model_selection import train_test_split","7b296d6e":"X_train, X_test, y_train, y_test = train_test_split(train_df, target_labels, test_size=0.15, random_state=13,\n                                                    shuffle=True, stratify=target_labels)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","bdaf07bc":"from xgboost import XGBClassifier","ffcbb970":"xgb_baseline = XGBClassifier(n_estimators=1000,\n                             learning_rate=0.1,\n                             max_depth=5,\n                             min_child_weight=1,\n                             subsample=0.8,\n                             colsample_bytree=0.8,\n                             objective='multi:softprob',\n                             eval_metric='mlogloss',\n                             gamma=0,\n                             num_class=9,\n                             use_label_encoder=False,\n                             tree_method='gpu_hist',\n                             n_jobs=-1,\n                             seed=13)\nxgb_baseline.fit(X_train, y_train, early_stopping_rounds=10, verbose=False, eval_set=[(X_test, y_test)])","b22595cc":"# utility function to create submission csv for further predictions\ndef create_submission_df(test_ids, predictions):\n    columns = ['class_'+str(x) for x in range(1,10)]\n    predictions_df = pd.DataFrame(predictions, columns=columns)\n    submission_df = pd.concat([test_ids, predictions_df], axis=1)\n    return submission_df","0c3137ff":"test_pred = xgb_baseline.predict_proba(test_df)\nsubmission_df = create_submission_df(test_ids, test_pred)\nsubmission_df.head()","de3fce1e":"submission_df.to_csv('submission.csv', index=False)","d26dfc3b":"feature_importance_dict = {\n    'columns': train_df.columns,\n    'score': xgb_baseline.feature_importances_\n}\nfeature_importance_df = pd.DataFrame(feature_importance_dict, columns=['columns', 'score'])\nfeature_importance_df.head(3)","d84a3026":"feature_importance_df.sort_values('score').plot(kind='barh', figsize=(16, 18));","20a7242f":"# lets take top 30 features and do a grid search\ntop_columns = feature_importance_df.sort_values('score')['columns'][:30]\n# top_columns[:5]","6925aef9":"from sklearn.model_selection import GridSearchCV","06527cfe":"param_grid = {\n    'max_depth': range(3, 10, 2),  # maximum depth tree can reach from root to node\n    'min_child_weight': range(1, 6, 2),  # minimum no. of children in a node to make a split\n}","27b8b3b2":"grid_cv = GridSearchCV(xgb_baseline, param_grid=param_grid, cv=3, scoring='roc_auc_ovr', verbose=3)\ngrid_cv.fit(X_train, y_train)","d29d7283":"grid_cv.best_params_","8ce98d46":"xgb_grid_1 = XGBClassifier(n_estimators=1000,\n                               max_depth=3,\n                               min_child_weight=5,\n                               objective='multi:softprob',\n                               eval_metric='mlogloss',\n                               num_class=9,\n                               use_label_encoder=False,\n                               tree_method='gpu_hist',\n                               n_jobs=-1)\nxgb_grid_1.fit(X_train, y_train, early_stopping_rounds=10, verbose=0, eval_set=[(X_test, y_test)])","a6e93c3c":"xgb_grid_1.best_iteration, xgb_grid_1.best_score","e7ae1cdb":"param_grid = {\n    'gamma':[i\/10.0 for i in range(0,5)]\n}","074d0c8e":"grid_cv_2 = GridSearchCV(xgb_grid_1, param_grid, scoring='roc_auc_ovr', verbose=3, cv=5)\ngrid_cv_2.fit(X_train, y_train)","57425be5":"grid_cv_2.best_params_","c21678d5":"xgb_grid_2 = XGBClassifier(n_estimators=999,\n                           max_depth=3,\n                           min_child_weight=5,\n                           gamma=0.4,\n                           objective='multi:softprob',\n                           eval_metric='mlogloss',\n                           num_class=9,\n                           use_label_encoder=False,\n                           tree_method='gpu_hist',\n                           n_jobs=-1)\n\nxgb_grid_2.fit(X_train, y_train, early_stopping_rounds=10, verbose=0, eval_set=[(X_test, y_test)])","a61c13cc":"xgb_grid_2.best_iteration, xgb_grid_2.best_score","4dd85b6e":"param_grid = {\n    'subsample': [i\/10.0 for i in range(6,10)],  # fraction of data points to consider for building tree\n    'colsample_bytree': [i\/10.0 for i in range(6,10)],  # fraction of features to consider for building tree\n}","31e460f8":"grid_cv_3 = GridSearchCV(xgb_grid_2, param_grid, scoring='roc_auc_ovr', verbose=3, cv=5)\ngrid_cv_3.fit(X_train, y_train)","5e4a2584":"grid_cv_3.best_params_","2e5d8dce":"xgb_grid_3 = XGBClassifier(n_estimators=999,\n                           max_depth=3,\n                           min_child_weight=5,\n                           gamma=0.4,\n                           colsample_bytree=0.6,\n                           subsample=.9,\n                           objective='multi:softprob',\n                           eval_metric='mlogloss',\n                           num_class=9,\n                           use_label_encoder=False,\n                           tree_method='gpu_hist',\n                           n_jobs=-1)\n\nxgb_grid_3.fit(X_train, y_train, early_stopping_rounds=10, verbose=0, eval_set=[(X_test, y_test)])","4156f72a":"xgb_grid_3.best_iteration, xgb_grid_3.best_score","6f18206b":"param_grid = {\n    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100],\n}","329d6bcb":"grid_cv_4 = GridSearchCV(xgb_grid_3, param_grid, scoring='roc_auc_ovr', verbose=3, cv=5)\ngrid_cv_4.fit(X_train, y_train)","3b9d10e0":"grid_cv_4.best_params_","54769134":"xgb_grid_4 = XGBClassifier(n_estimators=1000,\n                           max_depth=3,\n                           min_child_weight=5,\n                           eta=0.1,\n                           gamma=0.4,\n                           subsample=.9,\n                           colsample_bytree=0.6,\n                           reg_alpha=100,\n                           num_class=9,\n                           use_label_encoder=False,\n                           tree_method='gpu_hist',\n                           objective='multi:softprob',\n                           eval_metric='mlogloss')\nxgb_grid_4.fit(X_train, y_train, verbose=False, early_stopping_rounds=10, eval_set=[(X_test, y_test)])","b3e5849a":"xgb_grid_4.best_iteration, xgb_grid_4.best_score","6f99d42b":"train_df.shape, test_df.shape, target_labels.shape","e7f2db00":"xgb_final = XGBClassifier(n_estimators=550,\n                           max_depth=3,\n                           min_child_weight=5,\n                           eta=0.1,\n                           subsample=.9,\n                           colsample_bytree=0.6,\n                           gamma=0.4,\n                           reg_alpha=100,\n                           num_class=9,\n                           use_label_encoder=False,\n                           tree_method='gpu_hist',\n                           objective='multi:softprob',\n                           eval_metric='mlogloss')\nxgb_final.fit(train_df, target_labels)","e52e98b5":"test_pred = xgb_grid_4.predict_proba(test_df)\nsubmission_df = create_submission_df(test_ids, test_pred)\nsubmission_df.head()","ac434333":"submission_df.to_csv('xgb_final.csv', index=False)","f513ffe0":"## Final XGBoost with best parameters","b3dad200":"## Data prep","39695a6d":"## Data load","d7af4659":"### Grid search on learning rate","84ec7c91":"### Feature importances","db3733bd":"*Seems no null values*","b7b4b8bc":"### Grid serach on subsample & colsample_by_tree","fdd502b3":"## XGBoost","9ba833e0":"### Grid search on gamma","8c86532d":"### In this notebook, I'm trying `XGBoost` extensively by finding right parameters using Grid search\n### Please upvote if you find it helpful. <br> Do comment if you find something can be improved, & what else to try next.","ab7fed23":"## EDA","92446f6e":"## Grid search\n### Grid search on max_depth & min_child_weight"}}