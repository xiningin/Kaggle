{"cell_type":{"f639a1d7":"code","1dc6ed34":"code","81c073bc":"code","55a04857":"code","02fe2a4c":"code","6dd33c91":"code","830a695d":"code","7c5601b6":"code","d416c7f4":"code","f4eee401":"code","31f31c44":"code","9a3963e1":"code","5b3716c6":"code","5a6b97eb":"markdown","e97b0a3c":"markdown","881f133e":"markdown","4836e824":"markdown","c1a519f4":"markdown","6fb4497c":"markdown","82d1b8cc":"markdown","c958ca86":"markdown","7e60b6c4":"markdown","07e6847e":"markdown","031edee4":"markdown","a5623fff":"markdown"},"source":{"f639a1d7":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport math\n\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom matplotlib import pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.utils import Sequence\nimport tensorflow.keras.layers as L","1dc6ed34":"# limit the GPU memory growth\ngpu = tf.config.list_physical_devices('GPU')\nprint(\"Num GPUs Available: \", len(gpu))\nif len(gpu) > 0:\n    tf.config.experimental.set_memory_growth(gpu[0], True)","81c073bc":"data_dir = Path('..\/input\/seti-breakthrough-listen\/')\ntrain_data_dir = data_dir \/ 'train'\ntest_data_dir = data_dir \/ 'test'\n\ntrain_label_file = data_dir \/ 'train_labels.csv'\nsample_file = data_dir \/ 'sample_submission.csv'","55a04857":"train_data_dir","02fe2a4c":"id_col = 'id'\ntarget_col = 'target'\n\nlabel = pd.read_csv(train_label_file, index_col=id_col)\nsub = pd.read_csv(sample_file, index_col=id_col)\n\nsub.shape","6dd33c91":"def id_to_path(s, train=True):\n    data_dir = train_data_dir if train else test_data_dir\n    return data_dir \/ s[0] \/ f'{s}.npy'","830a695d":"plt.figure(figsize=(24, 8))\nfor i in range(10):\n    image = np.load(id_to_path(label.index[i])) # (6, 273, 256)\n    image = image.astype(np.float32)\n    image = np.vstack(image).transpose((1, 0)) # (1638, 256) -> (256, 1638)\n    plt.subplot(5, 2, i + 1)\n    plt.imshow(image)\nplt.show()","7c5601b6":"# example of vertical shift image augmentation\nfrom numpy import expand_dims\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import ImageDataGenerator\n# load the image\n# convert to numpy array\ndata = img_to_array(image)\n# expand dimension to one sample\nsamples = expand_dims(data, 0)\n# create image data augmentation generator\ndatagen = ImageDataGenerator(height_shift_range=0.5)\n# prepare iterator\nit = datagen.flow(samples, batch_size=1)\n# generate samples and plot\nfor i in range(9):\n    # define subplot\n    plt.subplot(330 + 1 + i)\n    # generate batch of images\n    batch = it.next()\n    # convert to unsigned integers for viewing\n    image = batch[0].astype('uint8')\n    # plot raw pixel data\n    plt.imshow(data)\n# show the figure\nplt.show()","d416c7f4":"input_size = (273, 256, 3)\nBATCH_SIZE = 32\nn_epoch = 3\nseed = 42 \nVERBOSE= 0","f4eee401":"class SETISequence(Sequence):\n    def __init__(self, x_set, y_set=None, batch_size=32):\n        self.x, self.y = x_set, y_set\n        self.batch_size = batch_size\n        self.is_train = False if y_set is None else True\n    \n    def __len__(self):\n        return math.ceil(len(self.x) \/ self.batch_size)\n    \n    def __getitem__(self, idx):\n        batch_ids = self.x[idx * self.batch_size: (idx + 1) * self.batch_size]\n        if self.y is not None:\n            batch_y = self.y[idx * self.batch_size: (idx + 1) * self.batch_size]\n        \n        # taking channels \n        list_x = [np.load(id_to_path(x, self.is_train)) for x in batch_ids]\n        batch_x = np.moveaxis(list_x,1,-1)\n        #batch_x = batch_x.astype(\"float\") \/ 255\n        \n        if self.is_train:\n            return batch_x, batch_y\n        else:\n            return batch_x\n        ","31f31c44":"def create_model():\n    model = tf.keras.Sequential([\n            L.Conv2D(3,(3,3), strides=(1,1), padding=\"same\", activation='relu', input_shape=(273,256,6)),\n            L.GlobalAveragePooling2D(),\n            L.Dense(1, activation='sigmoid')\n            ])\n\n    #model.summary\n    model.compile(optimizer=keras.optimizers.Adam(learning_rate=5e-4),\n                  loss='binary_crossentropy', metrics=[keras.metrics.AUC()])\n    \n    return model","9a3963e1":"sub[target_col] = 0\n\nn_splits = 5\nskf = StratifiedKFold(n_splits = n_splits)\n\nx0 = label.index.values\ny0 = label[target_col].values\n\nx1 = sub.index.values\ntest = SETISequence(x1, batch_size=BATCH_SIZE)\n\n\nfor train_index,val_index in skf.split(x0,y0):\n    x_train, x_val = x0[train_index], x0[val_index]\n    y_train, y_val = y0[train_index], y0[val_index]\n\n    train = SETISequence(x_train, y_train, batch_size=BATCH_SIZE)\n    val = SETISequence(x_val, y_val, batch_size=BATCH_SIZE)\n    \n\n    model = create_model()\n    \n    print('training')\n    model.fit(train, validation_data=val, epochs=n_epoch)\n\n    prediction = model.predict(test).flatten()\n    sub[target_col] += prediction \/ n_splits","5b3716c6":"#prediction = model.predict(test).flatten()\n#sub[target_col] = prediction\n\nsub.to_csv('submission.csv')\nsub.shape","5a6b97eb":"### Vis\n","e97b0a3c":"## Convert Data ID to File Path","881f133e":"## Import Library","4836e824":"## Data File Path","c1a519f4":"## Train & Inferece with StratifiedKFold","6fb4497c":"### Sequence of Data\n\n[tf.keras.utlis.Sequnece](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/utils\/Sequence)","82d1b8cc":"### Parameters","c958ca86":"### References\n\n[\ud83d\udef8 Signal Search \ud83d\udc7d - Exploratory Data Analysis](https:\/\/www.kaggle.com\/ihelon\/signal-search-exploratory-data-analysis)\n\n[SETI Simple Code for Beginners(TensorFlow)](https:\/\/www.kaggle.com\/kenjirokiyono\/seti-simple-code-for-beginners-tensorflow)","7e60b6c4":"## Data ID","07e6847e":"### Data augmentation - Work in progress","031edee4":"## Building a model","a5623fff":"## Use GPU"}}