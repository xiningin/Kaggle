{"cell_type":{"f239b64a":"code","208d5eec":"code","7f3032f9":"code","5d76cf8f":"code","05b46015":"code","085ed5b0":"code","085b0b62":"code","a048a674":"code","ae8aa461":"code","e4816e22":"code","429c808e":"code","5190e20a":"code","a6152933":"code","ad487f0d":"code","9ae3cf7c":"code","bdf9fb99":"code","82d3b4ac":"code","6c08888c":"code","595fe90e":"code","b9e09a22":"code","a55507c6":"code","60e63034":"code","20daf565":"code","92a2e6f8":"code","62cdeefc":"code","3939660d":"code","26e24c8c":"code","6dc57c67":"code","628381b7":"code","66be470e":"code","aa47fcce":"code","356f9b5d":"code","dc189c62":"code","f848a32b":"code","b8435f0a":"code","f02d8f26":"code","3afa7d14":"code","a96c1a18":"code","1c88a97c":"code","9655c10f":"code","b2ae23d6":"code","650c392f":"code","07387640":"code","d80bd122":"code","1ecd1e5a":"code","28acf9ca":"code","cd1b69ec":"code","2746612e":"code","690fa668":"code","247614db":"code","aa5e7856":"code","7490f6ef":"code","edb8dab6":"code","0eeed805":"code","edb850b8":"code","0603675c":"code","922d157a":"code","3d86e6b4":"code","cac0f854":"code","172a8d25":"code","849faf60":"code","82884dc6":"code","fd5bf991":"code","f83d82bb":"code","5916d4e4":"code","6f3c0030":"code","97a6a3c4":"code","cdf95c3b":"code","d348cc8c":"code","94d4d91c":"code","e2f01c28":"code","1179eba9":"code","668745af":"code","f499c7f4":"code","12838859":"code","d18e08f9":"code","5235d556":"code","e8325cb7":"code","8355bb1f":"code","716cf838":"code","3c6467a6":"code","88387363":"markdown","d9c4eb51":"markdown","df6b054e":"markdown","e6465706":"markdown","7bc818eb":"markdown","6cb14937":"markdown","f9074b14":"markdown","902d9b17":"markdown","db89201f":"markdown","ffc2e85c":"markdown","da8812ad":"markdown","9b297377":"markdown","574575fe":"markdown","82f13df4":"markdown","c713d77c":"markdown","75ad89fa":"markdown","a66b4b0b":"markdown","3cfca406":"markdown","9ada6b48":"markdown","96f71f6a":"markdown","e31be511":"markdown","e47787ec":"markdown","52fa0338":"markdown","25c2caae":"markdown","cc265bd0":"markdown","c9fb0fe9":"markdown","5bb8396d":"markdown","b9b34078":"markdown","a15775c5":"markdown","fc0234a6":"markdown","c6f2e023":"markdown","a016ff74":"markdown","9b9f92ba":"markdown","cb46adfc":"markdown","44cd1635":"markdown","305294b0":"markdown","f5223807":"markdown","344e14f4":"markdown","c79ff387":"markdown","c8cf935d":"markdown","8e91b030":"markdown","4ba6018b":"markdown","6a693744":"markdown","602d36e3":"markdown","142cc81f":"markdown","58cf6d94":"markdown","482894bd":"markdown","dd3f5dd9":"markdown","7974870c":"markdown","721bf0b3":"markdown","57102dd6":"markdown","cbe36389":"markdown","ef417df8":"markdown","f04a1721":"markdown","2ce9c476":"markdown","5665135a":"markdown","619ed49f":"markdown","05a543d6":"markdown","215365d1":"markdown","6c81942b":"markdown","aac36e73":"markdown","32d00067":"markdown","ebafc156":"markdown","49ed9d65":"markdown","8d52d7b6":"markdown","113e8a16":"markdown","ce1fdc1c":"markdown","060d5568":"markdown","dfbbaeca":"markdown","5dc2e349":"markdown","59798cc4":"markdown","215ddcfb":"markdown","384257b4":"markdown","f0b91232":"markdown","7ca32e06":"markdown","1b30aa0f":"markdown","b771010b":"markdown","89f42a9c":"markdown","d476ddd7":"markdown","2e979523":"markdown","afc0b7c2":"markdown","43772ff0":"markdown","2ed68ad2":"markdown","bea863fb":"markdown","b47caec4":"markdown","58cd7c45":"markdown","4cd80a02":"markdown","048942ba":"markdown","d44692bf":"markdown","9494696c":"markdown","5f368367":"markdown","75179507":"markdown","a20a1109":"markdown","eaca7573":"markdown","f23dd20f":"markdown","72edac7b":"markdown","a63ab519":"markdown","451d024a":"markdown","a793cb89":"markdown","a5030155":"markdown","4bfb647a":"markdown","b6c348d5":"markdown","3ee95bb7":"markdown","52798dc4":"markdown","758daef1":"markdown","ec07e26c":"markdown","8e8dcae1":"markdown","ecd4e7af":"markdown","e3d66e94":"markdown"},"source":{"f239b64a":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.options.display.float_format = '{:.2f}'.format\n\n%matplotlib inline","208d5eec":"trainset = pd.read_csv('..\/input\/train.csv')\ntestset = pd.read_csv('..\/input\/test.csv')\ndataset = trainset.append(testset , ignore_index = True )\ntitanic = dataset[ :891 ]","7f3032f9":"trainset.head(2)","5d76cf8f":"testset.head(2)","05b46015":"dataset.head(2)","085ed5b0":"titanic.head(2)","085b0b62":"print('This DataSet has rows:', titanic.shape[0])\nprint('This DataSet has columns:', titanic.shape[1])","a048a674":"titanic.describe()","ae8aa461":"titanic.info()","e4816e22":"titanic.dtypes","429c808e":"titanic.count()","5190e20a":"titanic.mean()","a6152933":"titanic.std()","ad487f0d":"titanic.sem()","9ae3cf7c":"titanic.isnull()","bdf9fb99":"titanic.isnull().sum()","82d3b4ac":"titanic['Age'] = titanic['Age'].fillna(titanic['Age'].median())\ntitanic.head(5)","6c08888c":"titanic.fillna(0, inplace = True)\ntitanic.head(5)","595fe90e":"titanic.isnull().sum()","b9e09a22":"titanic.groupby(['Sex']).size().reset_index(name='Quantity')","a55507c6":"titanic.groupby(['Survived']).size().reset_index(name='Quantity')","60e63034":"titanic['Survived'].value_counts().plot.pie(colors=('tab:red', 'tab:green'), \n                                       title='Percentage of Surviving and Non-surviving Persons', \n                                       fontsize=12, shadow=True, startangle=90, autopct='%1.1f%%', \n                                       labels=('Not Survived','Survived')).set_ylabel('')","20daf565":"titanic['Not Survived'] = titanic['Survived'].map({0:1,1:0})\ntitanic.head(2)","92a2e6f8":"titanic[titanic['Sex'] == 'female'].groupby('Sex')['Not Survived'].apply(lambda x: np.sum(x == 1))","62cdeefc":"df_survive = titanic[titanic['Survived'] == 1].groupby('Sex')[['Survived']].count()\ndf_survive","3939660d":"plot = df_survive.apply(lambda x: (x \/ x.sum(axis=0))*100)['Survived']\nplot","26e24c8c":"plot.plot.pie(colors=('tab:red', 'tab:green'), \n                                       title='Percentage of passengers by Sex', \n                                       fontsize=12, shadow=True, startangle=90, autopct='%1.1f%%', \n                                       labels=('Woman','Men')).set_ylabel('')","6dc57c67":"print('Passengers without age filled:',titanic['Age'].isnull().sum())\nprint('Passengers with full age:',(~titanic['Age'].isnull()).sum())","628381b7":"titanic['Age'].value_counts().sort_values(ascending = [False]).nlargest(1)","66be470e":"plt.figure();\ntitanic.hist(column='Age', color=('green'), alpha=0.5, bins=10)\nplt.title('Age Histogram')\nplt.xlabel('Age')\nplt.ylabel('Frequency')","aa47fcce":"df_hist = pd.DataFrame({'Total': titanic['Age'],\n                           'Not Survived': titanic[titanic['Not Survived'] == 1]['Age'], \n                           'Survived':titanic[titanic['Survived'] == 1]['Age']},                       \n                    \n                          columns=['Total','Not Survived', 'Survived'])\n\nplt.figure();\n\ndf_hist.plot.hist(bins=10, alpha=0.5, figsize=(10,5), color=('red','tab:blue','green'), \n                     title='Histograms (Total, Survived and Not Survived) by Age')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.show()","356f9b5d":"ax = sns.kdeplot(df_hist['Not Survived'], shade=True, color=\"r\")\nax = sns.kdeplot(df_hist['Survived'], shade=True, color=\"g\")\nplt.title('Density of Survived and Not Survived by Age')\nplt.xlabel('Age')\nplt.ylabel('Density')\nplt.xticks((0, 10, 20, 30, 40, 50, 60, 70, 80))","dc189c62":"titanic[(titanic['Sex'] == 'male') & (titanic['Survived'] == 1)].groupby('Sex').mean()['Age']","f848a32b":"df_priority = (titanic['Age'] <= 15) & (titanic['Age'] > 0) | (titanic['Sex'] == 0)\ndf_priority = titanic[df_priority]\ndf_priority.head(2)","b8435f0a":"df_priority.groupby('Sex')['Survived'].apply(lambda x: np.mean(x ==  1)*100)","f02d8f26":"df_priority[df_priority['Age'] <= 15].groupby('Sex')['Survived'].apply(lambda x: np.mean(x == 1)*100)","3afa7d14":"pd.pivot_table(titanic, values='Name', index='Pclass', aggfunc='count')","a96c1a18":"pd.crosstab(titanic['Pclass'],titanic['Survived'])[[1]].apply(lambda x: (x \/ x.sum(axis=0))*100)","1c88a97c":"titanic.pivot_table(index='Pclass',  values='Name', aggfunc='count').plot(kind='bar', legend=None,\n                                                                     title='Number of people per Class', \n                                                                     color='blue', rot=0).set_xlabel('Class')\nplt.ylabel('Quantity')","9655c10f":"titanic[titanic['Survived'] == 1].groupby('Pclass').sum()['Survived'].plot(kind='bar',\n                                                      title='Number of survivors per Class', rot=0).set_xlabel('Classe')\nplt.ylabel('Quantity')","b2ae23d6":"titanic.pivot_table('Survived', [\"Pclass\"], 'Sex', aggfunc='count')","650c392f":"titanic.pivot_table('Not Survived', [\"Sex\",\"Pclass\"], 'Survived', aggfunc='count')","07387640":"titanic.pivot_table('PassengerId', ['Pclass'], 'Sex', aggfunc='count').sort_index().plot(kind='barh', stacked=True, \n                                            title='Number of Men and Women by Class').legend(bbox_to_anchor=(1.0, 1.0))\nplt.xlabel('Quantity')","d80bd122":"titanic[titanic['Survived'] == 1].pivot_table('PassengerId', ['Pclass'], 'Sex', aggfunc='count').plot(kind='barh', \n                                                              title='Number of Survivors Men and Women by Class')\\\n                                                              .legend(bbox_to_anchor=(1.0, 1.0))\nplt.xlabel('Quantity')","1ecd1e5a":"sns.heatmap(titanic.corr(),annot=True,cmap=sns.diverging_palette(220, 10, as_cmap = True),linewidths=0.2)\nfig=plt.gcf()\nfig.set_size_inches(10,8)\nplt.show()","28acf9ca":"titanic['Sex'] = titanic['Sex'].map({'female': 0,'male': 1})","cd1b69ec":"titanic.head(2)","2746612e":"sns.countplot(x = 'Sex', hue ='Survived',data = titanic, palette = 'viridis'); ","690fa668":"sns.countplot(x = 'Pclass', hue ='Survived',data = titanic, palette = 'viridis');","247614db":"sns.countplot(x = 'Pclass', hue ='Sex',data = titanic, palette = 'viridis');","aa5e7856":"embark = pd.get_dummies(dataset.Embarked , prefix='Embarked')","7490f6ef":"embark.head(2)","edb8dab6":"classify = pd.get_dummies(dataset.Pclass , prefix='Pclass')","0eeed805":"classify.head(2)","edb850b8":"gender = pd.Series(np.where(dataset.Sex == 'male' , 1 , 0) , name = 'Sex')","0603675c":"gender.head(2)","922d157a":"booth = pd.DataFrame()\nbooth['Cabin'] = dataset.Cabin.fillna('U')","3d86e6b4":"booth['Cabin'] = booth['Cabin'].map(lambda c : c[0])\nbooth = pd.get_dummies(booth['Cabin'] , prefix = 'Cabin')","cac0f854":"booth.head(2)","172a8d25":"entry = pd.DataFrame()\nentry['Age'] = dataset.Age.fillna(dataset.Age.mean())\nentry['Fare'] = dataset.Fare.fillna(dataset.Fare.mean())\nentry['SibSp'] = dataset.SibSp.fillna(dataset.SibSp.mean())\nentry['Parch'] = dataset.Parch.fillna(dataset.Parch.mean())","849faf60":"entry.head(2)","82884dc6":"featured_data = pd.concat([entry , embark , classify , gender, booth], axis=1)","fd5bf991":"featured_data.tail(2)","f83d82bb":"from sklearn.model_selection import train_test_split\n\nfeatured_data_final = featured_data.apply(lambda x:(x - np.mean(x)) \/ (np.max(x) - np.min(x)))\nfeatured_data['Age'] = featured_data_final['Age']\nfeatured_data['Fare'] = featured_data_final['Fare']\nfeatured_data['SibSp'] = featured_data_final['SibSp']\nfeatured_data['Parch'] = featured_data_final['Parch']","5916d4e4":"training_data_final = featured_data[0:891]\ntraining_data_valid = titanic.Survived\nfeaturing_data_test = featured_data[891:]\ntrain_data, test_data, train_labels, test_labels = train_test_split(training_data_final, training_data_valid, train_size=.7)","6f3c0030":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\n\ngaussian = GaussianNB()\ngaussian.fit(train_data, train_labels)\ny_pred = gaussian.predict(test_data)\nacc_gaussian = round(accuracy_score(y_pred, test_labels) * 100, 2)\nprint(acc_gaussian)","97a6a3c4":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg.fit(train_data, train_labels)\ny_pred = logreg.predict(test_data)\nacc_logreg = round(accuracy_score(y_pred, test_labels) * 100, 2)\nprint(acc_logreg)","cdf95c3b":"from sklearn.svm import SVC\n\nsvc = SVC()\nsvc.fit(train_data, train_labels)\ny_pred = svc.predict(test_data)\nacc_svc = round(accuracy_score(y_pred, test_labels) * 100, 2)\nprint(acc_svc)","d348cc8c":"from sklearn.svm import LinearSVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(train_data, train_labels)\ny_pred = linear_svc.predict(test_data)\nacc_linear_svc = round(accuracy_score(y_pred, test_labels) * 100, 2)\nprint(acc_linear_svc)","94d4d91c":"from sklearn.linear_model import Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(train_data, train_labels)\ny_pred = perceptron.predict(test_data)\nacc_perceptron = round(accuracy_score(y_pred, test_labels) * 100, 2)\nprint(acc_perceptron)","e2f01c28":"from sklearn.neural_network import MLPClassifier\n\nmlperceptron = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(6, 2), random_state=1)\nmlperceptron.fit(train_data, train_labels)\ny_pred = mlperceptron.predict(test_data)\nacc_mlperceptron = round(accuracy_score(y_pred, test_labels) * 100, 2)\nprint(acc_mlperceptron)","1179eba9":"from sklearn.tree import DecisionTreeClassifier\n\ndecisiontree = DecisionTreeClassifier()\ndecisiontree.fit(train_data, train_labels)\ny_pred = decisiontree.predict(test_data)\nacc_decisiontree = round(accuracy_score(y_pred, test_labels) * 100, 2)\nprint(acc_decisiontree)","668745af":"from sklearn.ensemble import AdaBoostClassifier\n\nadaboost = AdaBoostClassifier(n_estimators=50)\nadaboost.fit(train_data, train_labels)\ny_pred = adaboost.predict(test_data)\nacc_adaboost = round(accuracy_score(y_pred, test_labels) * 100, 2)\nprint(acc_adaboost)","f499c7f4":"from sklearn.ensemble import RandomForestClassifier\n\nrandomforest = RandomForestClassifier()\nrandomforest.fit(train_data, train_labels)\ny_pred = randomforest.predict(test_data)\nacc_randomforest = round(accuracy_score(y_pred, test_labels) * 100, 2)\nprint(acc_randomforest)","12838859":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\nknn.fit(train_data, train_labels)\ny_pred = knn.predict(test_data)\nacc_knn = round(accuracy_score(y_pred, test_labels) * 100, 2)\nprint(acc_knn)","d18e08f9":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.model_selection import cross_val_score\n\nbaggedknn = BaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=3),random_state=0,n_estimators=700)\nbaggedknn.fit(train_data, train_labels)\ny_pred = baggedknn.predict(test_data)\nresult = accuracy_score(y_pred, test_labels)\ncross = cross_val_score(baggedknn,train_data,train_labels,cv=10,scoring='accuracy')\nacc_baggedknn = (cross.mean() * 100)\nprint(acc_baggedknn)","5235d556":"from sklearn.linear_model import SGDClassifier\n\nsgd = SGDClassifier()\nsgd.fit(train_data, train_labels)\ny_pred = sgd.predict(test_data)\nacc_sgd = round(accuracy_score(y_pred, test_labels) * 100, 2)\nprint(acc_sgd)","e8325cb7":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbk = GradientBoostingClassifier()\ngbk.fit(train_data, train_labels)\ny_pred = gbk.predict(test_data)\nacc_gbk = round(accuracy_score(y_pred, test_labels) * 100, 2)\nprint(acc_gbk)","8355bb1f":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Bagged KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', 'Multi-layer Perception', 'Linear SVC', \n              'Decision Tree', 'Adaboost', 'Stochastic Gradient Descent', 'Gradient Boosting Classifier'],\n    'Score': [acc_svc, acc_knn, acc_baggedknn, acc_logreg, \n              acc_randomforest, acc_gaussian, acc_perceptron, acc_mlperceptron,\n              acc_linear_svc, acc_decisiontree, acc_adaboost,\n              acc_sgd, acc_gbk]})\nmodels.sort_values(by='Score', ascending=False)","716cf838":"test_final = featuring_data_test.as_matrix()\n\npredictions  = gbk.predict(test_final)\npredictions  = predictions.flatten().round().astype(int)\npassenger_id = dataset[891:].PassengerId\noutput = pd.DataFrame({'PassengerId': passenger_id, 'Survived': predictions })\noutput.shape\noutput.head()\noutput.to_csv('submission.csv', index = False)","3c6467a6":"pd.show_versions()","88387363":"In the original dataset the sex of the passengers is defined as:\n- male\n- female\n\nIn order to use this information in classifiers we will convert it to a numeric value. Being:\n\n- 1 = male\n- 0 = women","d9c4eb51":"### Peer Correlation.","df6b054e":"**Load dataset:**","e6465706":"**Creating a Dataframe that Contains Only Women and Children:**","7bc818eb":"**Cabin Feature:**","6cb14937":"It means that this database does not contain the information of all people aboard the Titanic. Contains information of only 891 people.","f9074b14":"**KNN:**","902d9b17":"**Gradient Boosting Classifier:**","db89201f":"**Visualization:**","ffc2e85c":"**Decision Tree:**","da8812ad":"Most of the passengers were approximately 18 and 32 years old.","9b297377":"### Comparing Model Pedictions:","574575fe":"**Visualization:**","82f13df4":"# Knowing the DataSet","c713d77c":"**Analyzing the data type:**","75ad89fa":"**Modifying the content of the field that identifies the Gender:**","a66b4b0b":"**Summary Feature:**","3cfca406":"**Logistic Regression:**","9ada6b48":"**Adaboost:**","96f71f6a":"**Class Feature:**","e31be511":"### Calculations involving numeric columns with missing data can be impacted. Is it possible to tell if there is missing data in the dataset? If so, what and how many would these data be? Filling the missing data in a way that does not influence future operations.","e47787ec":"- This is my first work of machine learning using Python. This is a kernel in progress.\n\n\n- In this challenge it is necessary to predict which people will survive or not based on actual data from the shipwreck.\n\n\n- This is a simplified analysis, but it does contain some relevance for the purpose of characterizing and exploring different data visualization and modeling tools that may be useful for others initiating data analysis and machine learning to gain insight into their own studies.\n\n\n- Comments, criticisms and suggestions are always welcome.\n\n\nWTFPL license","52fa0338":"**Visualization:**","25c2caae":"Creating submission file to upload to the Kaggle competition!","cc265bd0":"**Support Vector Machines:**","c9fb0fe9":"# Training Model","5bb8396d":"**Percentage of Survivors by Class (in relation to total survivors):**\n- 1.0 = Yes","b9b34078":"**Applying the ratio:**","a15775c5":"**How many passengers survived and how many did not survive:**\n- 0.00 = No \n- 1.00 = Yes","fc0234a6":"# Deployment","c6f2e023":"##### INSTALLED VERSIONS","a016ff74":"**Analyzing the dimensions of the dataset:**","9b9f92ba":"**Imports and Parameters:**","cb46adfc":"**Women Not Survivors**","44cd1635":"**Analyzing the amount of Survivors by Gender:**","305294b0":"**Linear SVC:**","f5223807":"# Preparing the Data","344e14f4":"# The Competition","c79ff387":"### How many women did not survive?","c8cf935d":"## DATA DICTIONARY:\n\n##### The **titanic** file contains actual information about the passengers organized as follows:\n\n- **Age:** Age in years.\n\n\n- **Cabin:** Cabin number.\n\n\n- **Embarked:** Port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton).\n\n\n- **Fare:** Passenger fare\n\n\n- **Name:** Passenger name. They contain titles and some people can share the same surname; indicating family relationships.\n\n\n- **Parch:** Number of parents \/ children on board\n\n\n- **PassengerId:** Race index and whether or not this passenger has survived (1) or not (0)\n\n\n- **Pclass:** Entry class 1 = 1st - Superior, 2 = 2nd - Medium, 3 = 3rd - lower\n\n\n- **Sex:** Sex of the passenger\n\n\n- **Sibsp:** Number of siblings \/ spouses on board\n\n\n- **Survived:** 0 = No, 1 = Yes\n\n\n- **Ticket:** Number of boarding pass","8e91b030":"***","4ba6018b":"**Embarked Feature:**","6a693744":"### How many passengers per class?","602d36e3":"### How many passengers survived and how many did not survive?","142cc81f":"***","58cf6d94":"**Multi-layer Perception:**","482894bd":"**As previously identified, checking for any unfilled ages:**","dd3f5dd9":"**Number of Survivors Men and Women by Class:**\n- 0.0 = No\n- 1.0 = Yes","7974870c":"We can observe that the age range from 0 to 10 has a high survival rate.","721bf0b3":"**Number people separated by Sex:**","57102dd6":"### Normalizing data:","cbe36389":"**Visualization:**","ef417df8":"### Proportionally, did more men or more women survive? ","f04a1721":"**Visualization:**","2ce9c476":"**Number of Men and Women by Class:**","5665135a":"### What is the average age of surviving men?","619ed49f":"**Gaussian Naive Bayes:**","05a543d6":"**Checking amount of null data:**","215365d1":"**Statistical summary of the DataFrame, with quartiles, median, among others:**","6c81942b":"# Processing Empty Data","aac36e73":"**Applying Normalizing:**","32d00067":"**Now we will visualize the amount of the highest number of deaths by age:**","ebafc156":"**Mapping each Cabin value with the cabin letter:**","49ed9d65":"### Demonstrating the number of survivors and non-survivors, grouped by sex and class.","8d52d7b6":"**Perceptron:**","113e8a16":"**Checking if there is any dependency relation between them.**","ce1fdc1c":"**Random Forest:**","060d5568":"### CONCLUSION (Insights):\n\n\nThe exploratory analysis aimed to identify attributes of some people to know if they had a greater chance of survival than others.\n\n\nWe identified factors such as Class, Gender, and Age that actually influenced the increase or decrease in survival chances.\n\n\nWomen were the ones that had the greatest chances of survival. In summary, the greatest chances of survival were for women in the first and second class. And the lowest chances of survival were for the third-class men.\n\n\nIt was also identified that the majority of people who did not survive were in the third class and the children in the third class 60% died.\n\n\nThis study can be continued with the analysis of other variables, exploring and finding new insights using the information from this base to generate new variables, such as for example to know if it is possible to identify the crew.\nAge itself as already commented could be explored through predictive techniques to better identify how this information impacted survival rate.\n\n\n***IMPORTANT:*** It is important to emphasize that the conclusions identified are not definitive, as we are not using statistical techniques to perform this study.","dfbbaeca":"### Taking into account priority passengers (women and children up to 15 years of age regardless of gender) what is the proportion of survivors by sex?","5dc2e349":"**Checking for null data:**","59798cc4":"We can see that the Age, Cabin, and Embarked columns are smaller than the other columns. Meaning that there are null values.","215ddcfb":"**Checking the number of values in each column:**","384257b4":"**Creating the dataset to train, validate, and test the models:**","f0b91232":"***","7ca32e06":"***","1b30aa0f":"***","b771010b":"# Introduction","89f42a9c":"Training using the MLP classifier with Gradient Stochastic Descending (SGD) algorithm and 6 neurons in the hidden layer.","d476ddd7":"**Sex Feature:**","2e979523":"# Converting String Values into Numeric","afc0b7c2":"**Peer correlation:**","43772ff0":"**Separating Normalized Data:**","2ed68ad2":"**Visualization:**","bea863fb":"According to the graph above, the age range between 0 and approximately 10 years was of all the range that had more survivors.","b47caec4":"**Grouping the data of women and children who survived:**","58cd7c45":"***","4cd80a02":"***","048942ba":"**Bagged KNN:**","d44692bf":"***","9494696c":"**Below the values are filled using a median:**","5f368367":"**Number of people per class:**","75179507":"# Data Visualization","a20a1109":"**Average Age of Man:**","eaca7573":"**Observe the dataset:**","f23dd20f":"***","72edac7b":"**Analyzing information about data type, including index and dtype, column types, non-null values, and memory usage:**","a63ab519":"**Before that was created a column did not survive to facilitate the questions below:**","451d024a":"# Testing Different Models","a793cb89":"**Changing Nan Data from Age to Mean of Existing Values:**","a5030155":"**Changing other Nan values to 0:**","4bfb647a":"### Given the age of the passengers, what is the age and number of people with the highest number of dead?","b6c348d5":"***","3ee95bb7":"**Replaces missing cabin data with U (unrecognized):**","52798dc4":"**Checking amount of null data:**","758daef1":"***","ec07e26c":"**Visualization:**","8e8dcae1":"### How many women and how many men were on board, according to the dataset?","ecd4e7af":"**Stochastic Gradient Descent:**","e3d66e94":"* As the Best Score being the Gradient Boosting Classifier. He was chosen for test data."}}