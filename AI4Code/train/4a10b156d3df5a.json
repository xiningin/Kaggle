{"cell_type":{"81d8b6f2":"code","68eddd87":"code","2f513ad0":"code","a7556813":"code","96b95d0f":"code","7447c554":"code","c9bc0b86":"code","4531f9e2":"code","58eec4f1":"code","f1499c6f":"code","a28874eb":"code","4d11989e":"code","433de213":"code","6a29df0b":"code","97a66360":"code","66101242":"code","2961293e":"code","f9f5a1d4":"code","5550a740":"code","7a303b01":"code","291fc3eb":"code","bcc29fdb":"code","609ae547":"code","ee4781b5":"code","67a61e69":"code","04a490e0":"code","379359b4":"code","ae8b97cb":"code","7528758f":"code","d2eb97e2":"code","ca917a78":"code","96802a88":"code","f3974aef":"code","bd6ef00e":"code","c4ac76eb":"code","a32396a9":"code","e3864f9b":"code","ee062599":"code","a80210be":"code","968bc29d":"code","64c8ce1d":"code","72f2f599":"code","b09c7f9c":"code","7de5acfc":"code","b9ad6588":"code","23d2dd86":"code","47858dd8":"code","47af807b":"code","0522e52a":"code","2cc2ba9f":"code","b36db28e":"code","5f4896ac":"code","80beb0b2":"code","3e2d81cb":"code","8fe4cbce":"code","27766816":"code","c59ebc40":"code","51662a84":"code","729f883c":"code","860438f3":"code","f71d1e01":"code","b183f713":"code","ca8f8376":"code","6903d4ea":"code","8e1a5be3":"code","8c734091":"code","a00a3246":"code","5d922ed7":"code","d165f753":"code","a3e6b888":"code","7afb4eca":"code","6ce199b6":"code","f8566024":"code","0758fc2a":"code","620ab2d3":"code","6e36ff61":"code","b7991471":"code","8ab5621f":"code","6f0b8b4d":"code","5d1762c6":"code","373b8ef3":"code","68136012":"code","99bffc35":"code","497a0cd5":"code","b19b5786":"code","8610fce5":"code","9d3fee82":"code","fc9ad218":"code","babc82c2":"code","332a175a":"code","87c4ad4a":"code","7d887cbe":"markdown","4a3ecf41":"markdown","ff07664c":"markdown","d80d80ca":"markdown","c72a17cd":"markdown","a153f19f":"markdown","b0ed437c":"markdown","20f9937b":"markdown","8ec8d45e":"markdown","99b60c7f":"markdown","19f7a2e7":"markdown","72efac01":"markdown","b3e8af9c":"markdown","f4e20481":"markdown","8e9a887c":"markdown","282fb3d5":"markdown","341e17f3":"markdown","e22d3d45":"markdown","20838bfe":"markdown","272d75e4":"markdown","2b4044cc":"markdown","ae9a32a9":"markdown","a71d1ea0":"markdown","ae739007":"markdown","a938a7ea":"markdown","ade245c2":"markdown","0d70fa1b":"markdown","c253a047":"markdown","afc767bf":"markdown","35f3b38f":"markdown","70dfa9d6":"markdown","53cd9cb6":"markdown","67e0ca28":"markdown","1735a1c0":"markdown","345de30a":"markdown","7dc19a93":"markdown","00692722":"markdown","6c20e97b":"markdown","0d8f55b1":"markdown","2f7fa204":"markdown","15a788d0":"markdown","25d854bc":"markdown"},"source":{"81d8b6f2":"from datetime import datetime, timedelta\nfrom dateutil.relativedelta import relativedelta\nimport os\nfrom pprint import pprint\nimport warnings\nfrom fbprophet import Prophet\nfrom fbprophet.plot import add_changepoints_to_plot\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport matplotlib\nfrom matplotlib.ticker import ScalarFormatter\n%matplotlib inline\nimport numpy as np\nimport optuna\noptuna.logging.disable_default_handler()\nimport pandas as pd\npd.plotting.register_matplotlib_converters()\nimport seaborn as sns\nfrom scipy.optimize import curve_fit\nfrom scipy.integrate import solve_ivp","68eddd87":"plt.style.use(\"seaborn-ticks\")\nplt.rcParams[\"xtick.direction\"] = \"in\"\nplt.rcParams[\"ytick.direction\"] = \"in\"\nplt.rcParams[\"font.size\"] = 11.0\nplt.rcParams[\"figure.figsize\"] = (9, 6)","2f513ad0":"def line_plot(df, title, ylabel=\"Cases\", h=None, v=None,\n              xlim=(None, None), ylim=(0, None), math_scale=True, y_logscale=False, y_integer=False):\n    \"\"\"\n    Show chlonological change of the data.\n    \"\"\"\n    ax = df.plot()\n    if math_scale:\n        ax.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n        ax.ticklabel_format(style=\"sci\",  axis=\"y\",scilimits=(0, 0))\n    if y_logscale:\n        ax.set_yscale(\"log\")\n    if y_integer:\n        fmt = matplotlib.ticker.ScalarFormatter(useOffset=False)\n        fmt.set_scientific(False)\n        ax.yaxis.set_major_formatter(fmt)\n    ax.set_title(title)\n    ax.set_xlabel(None)\n    ax.set_ylabel(ylabel)\n    ax.set_xlim(*xlim)\n    ax.set_ylim(*ylim)\n    ax.legend(bbox_to_anchor=(1.02, 0), loc=\"lower left\", borderaxespad=0)\n    if h is not None:\n        ax.axhline(y=h, color=\"black\", linestyle=\"--\")\n    if v is not None:\n        if not isinstance(v, list):\n            v = [v]\n        for value in v:\n            ax.axvline(x=value, color=\"black\", linestyle=\"--\")\n    plt.tight_layout()\n    plt.show()","a7556813":"for dirname, _, filenames in os.walk(\"\/kaggle\/input\"):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","96b95d0f":"train_raw = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-1\/train.csv\")\ntest_raw = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-1\/test.csv\")\nsubmission_sample_raw = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-1\/submission.csv\")\n# Population\npopulation_raw = pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-locations-population\/locations_population.csv\")","7447c554":"submission_sample_raw.head()","c9bc0b86":"df = pd.DataFrame(\n    {\n        \"Nunique_train\": train_raw.nunique(),\n        \"Nunique_test\": test_raw.nunique(),\n        \"Null_Train\": train_raw.isnull().sum(),\n        \"Null_Test\": test_raw.isnull().sum(),\n    }\n)\ndf.fillna(\"-\").T","4531f9e2":"population_raw.head()","58eec4f1":"df = population_raw.rename({\"Province.State\": \"Province\", \"Country.Region\": \"Country\"}, axis=1)\ndf[\"Country\/Province\"] = df[[\"Country\", \"Province\"]].apply(\n    lambda x: f\"{x[0]}\/{x[0]}\" if x[1] is np.nan else f\"{x[0]}\/{x[1]}\",\n    axis=1\n)\n# Culculate total value of each country\/province\ndf = df.groupby(\"Country\/Province\").sum()\n# Global population\ndf.loc[\"Global\", \"Population\"] = df[\"Population\"].sum()\n# DataFrame to dictionary\npopulation_dict = df.astype(np.int64).to_dict()[\"Population\"]\npopulation_dict","f1499c6f":"df = pd.merge(\n    train_raw.rename({\"Province\/State\": \"Province\", \"Country\/Region\": \"Country\"}, axis=1),\n    population_raw.rename({\"Province.State\": \"Province\", \"Country.Region\": \"Country\"}, axis=1),\n    on=[\"Country\", \"Province\"]\n)\n# Area: Country or Country\/Province\ndf[\"Area\"] = df[[\"Country\", \"Province\"]].apply(\n    lambda x: f\"{x[0]}\" if x[1] is np.nan else f\"{x[0]}\/{x[1]}\",\n    axis=1\n)\n# Date\ndf[\"Date\"] = pd.to_datetime(df[\"Date\"])\n# The number of cases\ndf = df.rename({\"ConfirmedCases\": \"Confirmed\", \"Fatalities\": \"Fatal\"}, axis=1)\ndf[[\"Confirmed\", \"Fatal\"]] = df[[\"Confirmed\", \"Fatal\"]].astype(np.int64)\n# Show data\ndf = df.loc[:, [\"Date\", \"Area\", \"Population\", \"Confirmed\", \"Fatal\"]]\ntrain_df = df.copy()\ntrain_df.tail()","a28874eb":"df = pd.merge(\n    test_raw.rename({\"Province\/State\": \"Province\", \"Country\/Region\": \"Country\"}, axis=1),\n    population_raw.rename({\"Province.State\": \"Province\", \"Country.Region\": \"Country\"}, axis=1),\n    on=[\"Country\", \"Province\"]\n)\ndf[\"Area\"] = df[[\"Country\", \"Province\"]].apply(\n    lambda x: f\"{x[0]}\" if x[1] is np.nan else f\"{x[0]}\/{x[1]}\",\n    axis=1\n)\ndf[\"Date\"] = pd.to_datetime(df[\"Date\"])\ndf = df.loc[:, [\"ForecastId\", \"Date\", \"Area\", \"Population\"]]\ntest_df = df.copy()\ntest_df.tail()","4d11989e":"train_df.describe(include=\"all\").fillna(\"-\").T","433de213":"total_df = train_df.drop(\"Population\", axis=1).groupby(\"Date\").sum()\ntotal_df.tail()","6a29df0b":"line_plot(total_df, \"Total: Cases over time\")","97a66360":"df = train_df.copy()\ndf = df.pivot_table(\n    index=\"Date\", columns=\"Area\", values=\"Confirmed\"\n).fillna(method=\"bfill\")\n# Growth factor: (delta Number_n) \/ (delta Number_n)\ndf = df.diff() \/ df.diff().shift(freq=\"D\")\ndf = df.rolling(7).mean()\ndf = df.iloc[2:-1, :]\ngrowth_df = df.copy()\ngrowth_df.tail(10)","66101242":"current_growth_df = growth_df.iloc[-1, :].T.reset_index()\ncurrent_growth_df.columns = [\"Area\", \"Growth_Factor\"]\ndf = train_df.loc[train_df[\"Date\"] == train_df[\"Date\"].max(), [\"Area\", \"Confirmed\", \"Fatal\"]]\ndf.columns = [\"Area\", \"Current_Confirmed\", \"Current_Fatal\"]\ncurrent_growth_df = pd.merge(current_growth_df, df, on=\"Area\")\ncurrent_growth_df.head()","2961293e":"current_growth_df[\"Group\"] = \"Others\"\ncurrent_growth_df.loc[current_growth_df[\"Growth_Factor\"] > 1, \"Group\"] = \"Outbreaking\"\ncurrent_growth_df.loc[current_growth_df[\"Area\"].str.contains(\"China\"), \"Group\"] = \"China\"","f9f5a1d4":"current_growth_df.nlargest(10, \"Growth_Factor\")","5550a740":"current_growth_df.loc[current_growth_df[\"Group\"] == \"China\", :].nlargest(10, \"Growth_Factor\")","7a303b01":"current_growth_df.nsmallest(10, \"Growth_Factor\")","291fc3eb":"df = pd.merge(train_df, current_growth_df, on=\"Area\")\ndf = df.pivot_table(\n    index=\"Date\", columns=\"Group\", values=[\"Population\", \"Confirmed\", \"Fatal\"],\n    aggfunc=\"sum\"\n)\ndf = df.T.swaplevel(0, 1).sort_index(ascending=False).T\ngrouped_train_df = df.copy()\ngrouped_train_df.tail()","bcc29fdb":"outbreak_df = grouped_train_df.loc[:, \"Outbreaking\"].reset_index()\noutbreak_df.tail()","609ae547":"line_plot(outbreak_df.drop(\"Population\", axis=1).set_index(\"Date\"), \"Cases over time in outbreaking group\")","ee4781b5":"def show_trend(df, group=\"Outbreaking group\", variable=\"Confirmed\", n_changepoints=2):\n    \"\"\"\n    Show trend of log10(@variable) using fbprophet package.\n    @df <pd.DataFrame>: time series data of the variable\n    @group <str>: Group name (to show figure title)\n    @variable <str>: variable name to analyse, Confirmed or Fatal\n    @n_changepoints <int>: max number of change points\n    \"\"\"\n    # Data arrangement\n    df = df.loc[:, [\"Date\", variable]]\n    df.columns = [\"ds\", \"y\"]\n    # Log10(x)\n    warnings.resetwarnings()\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        df[\"y\"] = np.log10(df[\"y\"]).replace([np.inf, -np.inf], 0)\n    # fbprophet\n    model = Prophet(growth=\"linear\", daily_seasonality=False, n_changepoints=n_changepoints)\n    model.fit(df)\n    future = model.make_future_dataframe(periods=0)\n    forecast = model.predict(future)\n    # Create figure\n    fig = model.plot(forecast)\n    _ = add_changepoints_to_plot(fig.gca(), model, forecast)\n    plt.title(f\"{group}: log10({variable}) over time and chainge points\")\n    plt.ylabel(f\"log10(the number of cases)\")\n    plt.xlabel(\"\")","67a61e69":"show_trend(outbreak_df, group=\"Outbreaking group\", variable=\"Confirmed\")","04a490e0":"show_trend(outbreak_df, group=\"Outbreaking group\", variable=\"Fatal\")","379359b4":"outbreak_group_start = \"15Feb2020\"","ae8b97cb":"china_df = grouped_train_df.loc[:, \"China\"].reset_index()\nchina_df.tail()","7528758f":"line_plot(china_df.drop(\"Population\", axis=1).set_index(\"Date\"), \"Cases over time in China\")","d2eb97e2":"show_trend(china_df, group=\"China\", variable=\"Confirmed\")","ca917a78":"show_trend(china_df, group=\"China\", variable=\"Fatal\")","96802a88":"china_start = \"26Jan2020\"\nchina_end = \"15Febn2020\"","f3974aef":"others_df = grouped_train_df.loc[:, \"Others\"].reset_index()\nothers_df.tail()","bd6ef00e":"line_plot(others_df.drop(\"Population\", axis=1).set_index(\"Date\"), \"Cases over time in the others\")","c4ac76eb":"show_trend(others_df, group=\"The others\", variable=\"Confirmed\")","a32396a9":"show_trend(others_df, group=\"The others\", variable=\"Fatal\")","e3864f9b":"others_start = \"15Feb2020\"\nothers_end = \"22Mar2020\"","ee062599":"def create_target_df(ncov_df, total_population, start_date=None, end_date=None, date_format=\"%d%b%Y\"):\n    \"\"\"\n    Calculate the number of susceptible people,\n     and calculate the elapsed time [day] from the start date of the target dataframe.\n    @noc_df <pd.DataFrame>: the cleaned training data\n    @total_population <int>: total population\n    @start_date <str>: the start date or None\n    @end_date <str>: the start date or None\n    @date_format <str>: format of @start_date\n    @return <tuple(2 objects)>:\n        - 1. start_date <pd.Timestamp>: the start date of the selected records\n        - 2. target_df <pd.DataFrame>:\n            - column T: elapsed time [min] from the start date of the dataset\n            - column Susceptible: the number of patients who are in the palces but not infected\/recovered\/fatal\n            - column Deaths: the number of death cases\n    \"\"\"\n    df = ncov_df.copy()\n    if start_date is not None:\n        df = df.loc[df[\"Date\"] >= datetime.strptime(start_date, date_format), :]\n    if end_date is not None:\n        df = df.loc[df[\"Date\"] <= datetime.strptime(end_date, date_format), :]\n    start_date = df.loc[df.index[0], \"Date\"]\n    # column T\n    df[\"T\"] = ((df[\"Date\"] - start_date).dt.total_seconds() \/ 60).astype(int)\n    # coluns except T\n    response_variables = [\"Susceptible\", \"Infected\", \"Recovered\", \"Fatal\"]\n    df[\"Susceptible\"] = total_population - df[\"Confirmed\"]\n    df[\"Infected\"] = 0\n    df.loc[df.index[0], \"Infected\"] = df.loc[df.index[0], \"Confirmed\"] - df.loc[df.index[0], \"Fatal\"]\n    df[\"Recovered\"] = 0\n    # Return\n    target_df = df.loc[:, [\"T\", *response_variables]]\n    return (start_date, target_df)","a80210be":"class ModelBase(object):\n    NAME = \"Model\"\n    VARIABLES = [\"x\"]\n    PRIORITIES = np.array([1])\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        \"\"\"\n        Define parameters without tau. This function should be overwritten.\n        @train_df_divided <pd.DataFrame>:\n            - column: t and non-dimensional variables\n        @q_range <list[float, float]>: quantile rage of the parameters calculated by the data\n        @return <dict[name]=(type, min, max):\n            @type <str>: \"float\" or \"int\"\n            @min <float\/int>: min value\n            @max <float\/int>: max value\n        \"\"\"\n        param_dict = dict()\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        \"\"\"\n        Calculate the variables of the model.\n        This function should be overwritten.\n        @df <pd.DataFrame>\n        @return <pd.DataFrame>\n        \"\"\"\n        return df\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        \"\"\"\n        Calculate measurable variables using the variables of the model.\n        This function should be overwritten.\n        @df <pd.DataFrame>\n        @return <pd.DataFrame>\n        \"\"\"\n        return df\n\n    @classmethod\n    def create_dataset(cls, ncov_df, total_population, start_date=None, end_date=None, date_format=\"%d%b%Y\"):\n        \"\"\"\n        Create dataset with the model-specific varibles.\n        The variables will be divided by total population.\n        The column names (not include T) will be lower letters.\n        @params: See the function named create_target_df()\n        @return <tuple(objects)>:\n            - start_date <pd.Timestamp>\n            - initials <tuple(float)>: the initial values\n            - Tend <int>: the last value of T\n            - df <pd.DataFrame>: the dataset\n        \"\"\"\n        start_date, target_df = create_target_df(\n            ncov_df, total_population, start_date=start_date, end_date=None, date_format=date_format\n        )\n        df = cls.calc_variables(target_df).set_index(\"T\") \/ total_population\n        df.columns = [n.lower() for n in df.columns]\n        initials = df.iloc[0, :].values\n        df = df.reset_index()\n        Tend = df.iloc[-1, 0]\n        return (start_date, initials, Tend, df)\n\n    def calc_r0(self):\n        \"\"\"\n        Calculate R0. This function should be overwritten.\n        \"\"\"\n        return None\n\n    def calc_days_dict(self, tau):\n        \"\"\"\n        Calculate 1\/beta [day] etc.\n        This function should be overwritten.\n        @param tau <int>: tau value [hour]\n        \"\"\"\n        return dict()","968bc29d":"class SIRF(ModelBase):\n    NAME = \"SIR-F\"\n    VARIABLES = [\"x\", \"y\", \"z\", \"w\"]\n    PRIORITIES = np.array([100, 0, 0, 1])\n\n    def __init__(self, theta, kappa, rho, sigma):\n        super().__init__()\n        self.theta = float(theta)\n        self.kappa = float(kappa)\n        self.rho = float(rho)\n        self.sigma = float(sigma)\n\n    def __call__(self, t, X):\n        # x, y, z, w = [X[i] for i in range(len(self.VARIABLES))]\n        # dxdt = - self.rho * x * y\n        # dydt = self.rho * (1 - self.theta) * x * y - (self.sigma + self.kappa) * y\n        # dzdt = self.sigma * y\n        # dwdt = self.rho * self.theta * x * y + self.kappa * y\n        dxdt = - self.rho * X[0] * X[1]\n        dydt = self.rho * (1 - self.theta) * X[0] * X[1] - (self.sigma + self.kappa) * X[1]\n        dzdt = self.sigma * X[1]\n        dwdt = self.rho * self.theta * X[0] * X[1] + self.kappa * X[1]\n        return np.array([dxdt, dydt, dzdt, dwdt])\n\n    @classmethod\n    def param_dict(cls, train_df_divided=None, q_range=None):\n        param_dict = super().param_dict()\n        param_dict[\"theta\"] = (\"float\", 0, 1)\n        param_dict[\"kappa\"] = (\"float\", 0, 1)\n        param_dict[\"rho\"] = (\"float\", 0, 1)\n        param_dict[\"sigma\"] = (\"float\", 0, 1)\n        return param_dict\n\n    @staticmethod\n    def calc_variables(df):\n        df[\"X\"] = df[\"Susceptible\"]\n        df[\"Y\"] = df[\"Infected\"]\n        df[\"Z\"] = df[\"Recovered\"]\n        df[\"W\"] = df[\"Fatal\"]\n        return df.loc[:, [\"T\", \"X\", \"Y\", \"Z\", \"W\"]]\n\n    @staticmethod\n    def calc_variables_reverse(df):\n        df[\"Susceptible\"] = df[\"X\"]\n        df[\"Infected\"] = df[\"Y\"]\n        df[\"Recovered\"] = df[\"Z\"]\n        df[\"Fatal\"] = df[\"W\"]\n        return df\n\n    def calc_r0(self):\n        try:\n            r0 = self.rho * (1 - self.theta) \/ (self.sigma + self.kappa)\n        except ZeroDivisionError:\n            return np.nan\n        return round(r0, 2)\n\n    def calc_days_dict(self, tau):\n        _dict = dict()\n        _dict[\"alpha1 [-]\"] = round(self.theta, 3)\n        if self.kappa == 0:\n            _dict[\"1\/alpha2 [day]\"] = 0\n        else:\n            _dict[\"1\/alpha2 [day]\"] = int(tau \/ 24 \/ 60 \/ self.kappa)\n        _dict[\"1\/beta [day]\"] = int(tau \/ 24 \/ 60 \/ self.rho)\n        if self.sigma == 0:\n            _dict[\"1\/gamma [day]\"] = 0\n        else:\n            _dict[\"1\/gamma [day]\"] = int(tau \/ 24 \/ 60 \/ self.sigma)\n        return _dict","64c8ce1d":"def simulation(model, initials, step_n, **params):\n    \"\"\"\n    Solve ODE of the model.\n    @model <ModelBase>: the model\n    @initials <tuple[float]>: the initial values\n    @step_n <int>: the number of steps\n    \"\"\"\n    tstart, dt, tend = 0, 1, step_n\n    sol = solve_ivp(\n        fun=model(**params),\n        t_span=[tstart, tend],\n        y0=np.array(initials, dtype=np.float64),\n        t_eval=np.arange(tstart, tend + dt, dt),\n        dense_output=True\n    )\n    t_df = pd.Series(data=sol[\"t\"], name=\"t\")\n    y_df = pd.DataFrame(data=sol[\"y\"].T.copy(), columns=model.VARIABLES)\n    sim_df = pd.concat([t_df, y_df], axis=1)\n    return sim_df","72f2f599":"eg_initials = np.array([1, 0.0001, 0, 0])\neg_param_dict = {\"theta\": 0.08, \"kappa\": 0.0001, \"sigma\": 0.02, \"rho\": 0.2}\neg_df = simulation(SIRF, eg_initials, step_n=300, **eg_param_dict)\neg_df.tail()","b09c7f9c":"line_plot(\n    eg_df.set_index(\"t\"),\n    title=r\"Example of SIR-F model: $R_0$={0}\".format(SIRF(**eg_param_dict).calc_r0()),\n    ylabel=\"\",\n    h=1\n)","7de5acfc":"outbreak_df.tail()","b9ad6588":"train_dataset = SIRF.create_dataset(outbreak_df, outbreak_df.loc[outbreak_df.index[-1], \"Population\"])\ntrain_start_date, train_initials, train_Tend, transformed_train_df = train_dataset\npprint([train_start_date.strftime(\"%d%b%Y\"), train_initials, train_Tend])","23d2dd86":"transformed_train_df.tail()","47858dd8":"class Estimator(object):\n    def __init__(self, model, ncov_df, total_population, name=None,\n                 start_date=None, end_date=None, date_format=\"%d%b%Y\", param_fold_range=(1, 1), **kwargs):\n        \"\"\"\n        Set training data.\n        @model <ModelBase>: the model\n        @name <str>: name of the area\n        @param_fold_range <tuple(float, float)>:\n            if we have fixed parameters (as kwargs), paramater range will be\n            from param_fold_range[0] * (fixed) to param_fold_range[1] * (fixed)\n        @kwargs: fixed parameter of the model\n        @the other params: See the function named create_target_df()\n        \"\"\"\n        if param_fold_range == (1, 1):\n            self.fixed_param_dict = kwargs.copy()\n            self.range_param_dict = dict()\n        else:\n            self.fixed_param_dict = dict()\n            fold_min, fold_max = param_fold_range\n            self.range_param_dict = {\n                name: (value * fold_min, value * fold_max)\n                for (name, value) in kwargs.items()\n            }\n        dataset = model.create_dataset(\n            ncov_df, total_population, start_date=start_date, end_date=end_date, date_format=date_format\n        )\n        self.start_time, self.initials, self.Tend, self.train_df = dataset\n        self.total_population = total_population\n        self.name = name\n        self.model = model\n        self.param_dict = dict()\n        self.study = None\n        self.optimize_df = None\n\n    def run(self, n_trials=500):\n        \"\"\"\n        Try estimation (optimization of parameters and tau).\n        @n_trials <int>: the number of trials\n        \"\"\"\n        if self.study is None:\n            self.study = optuna.create_study(direction=\"minimize\")\n        self.study.optimize(\n            lambda x: self.objective(x),\n            n_trials=n_trials,\n            n_jobs=-1\n        )\n        param_dict = self.study.best_params.copy()\n        param_dict.update(self.fixed_param_dict)\n        param_dict[\"R0\"] = self.calc_r0()\n        param_dict[\"score\"] = self.score()\n        param_dict.update(self.calc_days_dict())\n        self.param_dict = param_dict.copy()\n        return param_dict\n\n    def history_df(self):\n        \"\"\"\n        Return the hsitory of optimization.\n        @return <pd.DataFrame>\n        \"\"\"\n        optimize_df = self.study.trials_dataframe()\n        optimize_df[\"time[s]\"] = optimize_df[\"datetime_complete\"] - optimize_df[\"datetime_start\"]\n        optimize_df[\"time[s]\"] = optimize_df[\"time[s]\"].dt.total_seconds()\n        self.optimize_df = optimize_df.drop([\"datetime_complete\", \"datetime_start\"], axis=1)\n        return self.optimize_df.sort_values(\"value\", ascending=True)\n\n    def history_graph(self):\n        \"\"\"\n        Show the history of parameter search using pair-plot.\n        \"\"\"\n        if self.optimize_df is None:\n            self.history_df()\n        df = self.optimize_df.copy()\n        sns.pairplot(df.loc[:, df.columns.str.startswith(\"params_\")], diag_kind=\"kde\", markers=\"+\")\n        plt.show()\n\n    def objective(self, trial):\n        # Time\n        if \"tau\" in self.fixed_param_dict.keys():\n            tau = self.fixed_param_dict[\"tau\"]\n        else:\n            tau = trial.suggest_int(\"tau\", 1, 1440)\n        train_df_divided = self.train_df.copy()\n        train_df_divided[\"t\"] = (train_df_divided[\"T\"] \/ tau).astype(np.int64)\n        # Parameters\n        p_dict = dict()\n        for (name, info) in self.model.param_dict(train_df_divided).items():\n            if name in self.fixed_param_dict.keys():\n                param = self.fixed_param_dict[name]\n            else:\n                value_min, value_max = info[1:]\n                if name in self.range_param_dict.keys():\n                    range_min, range_max = self.range_param_dict[name]\n                    value_min = max(range_min, value_min)\n                    value_max = min(range_max, value_max)\n                if info[0] == \"float\":\n                    param = trial.suggest_uniform(name, value_min, value_max)\n                else:\n                    param = trial.suggest_int(name, value_min, value_max)\n            p_dict[name] = param\n        # Simulation\n        t_end = train_df_divided.loc[train_df_divided.index[-1], \"t\"]\n        sim_df = simulation(self.model, self.initials, step_n=t_end, **p_dict)\n        return self.error_f(train_df_divided, sim_df)\n\n    def error_f(self, train_df_divided, sim_df):\n        \"\"\"\n        We need to minimize the difference of the observed values and estimated values.\n        This function calculate the difference of the estimated value and obsereved value.\n        \"\"\"\n        df = pd.merge(train_df_divided, sim_df, on=\"t\", suffixes=(\"_observed\", \"_estimated\"))\n        # return self.rmsle(df)\n        diffs = [\n            # Weighted Average: the recent data is more important\n            abs(p) * np.average(\n                abs(df[f\"{v}_observed\"] - df[f\"{v}_estimated\"]) \/ (df[f\"{v}_observed\"] * self.total_population + 1),\n                weights=df[\"t\"]\n            )\n            for (p, v) in zip(self.model.PRIORITIES, self.model.VARIABLES)\n        ]\n        return sum(diffs) * self.total_population\n\n    def compare_df(self):\n        \"\"\"\n        Show the taining data and simulated data in one dataframe.\n        \n        \"\"\"\n        est_dict = self.study.best_params.copy()\n        est_dict.update(self.fixed_param_dict)\n        tau = est_dict[\"tau\"]\n        est_dict.pop(\"tau\")\n        observed_df = self.train_df.drop(\"T\", axis=1)\n        observed_df[\"t\"] = (self.train_df[\"T\"] \/ tau).astype(int)\n        t_end = observed_df.loc[observed_df.index[-1], \"t\"]\n        sim_df = simulation(self.model, self.initials, step_n=t_end, **est_dict)\n        df = pd.merge(observed_df, sim_df, on=\"t\", suffixes=(\"_observed\", \"_estimated\"))\n        df = df.set_index(\"t\")\n        return df\n\n    def compare_graph(self):\n        \"\"\"\n        Compare obsereved and estimated values in graphs.\n        \"\"\"\n        df = self.compare_df()\n        use_variables = [\n            v for (i, (p, v)) in enumerate(zip(self.model.PRIORITIES, self.model.VARIABLES))\n            if p != 0\n        ]\n        val_len = len(use_variables) + 1\n        fig, axes = plt.subplots(ncols=1, nrows=val_len, figsize=(9, 6 * val_len \/ 2))\n        for (ax, v) in zip(axes.ravel()[1:],use_variables):\n            df[[f\"{v}_observed\", f\"{v}_estimated\"]].plot.line(\n                ax=ax, ylim=(None, None), sharex=True,\n                title=f\"{self.model.NAME}: Comparison of observed\/estimated {v}(t)\"\n            )\n            ax.yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n            ax.ticklabel_format(style=\"sci\",  axis=\"y\",scilimits=(0, 0))\n            ax.legend(bbox_to_anchor=(1.02, 0), loc=\"lower left\", borderaxespad=0)\n        for v in use_variables:\n            df[f\"{v}_diff\"] = df[f\"{v}_observed\"] - df[f\"{v}_estimated\"]\n            df[f\"{v}_diff\"].plot.line(\n                ax=axes.ravel()[0], sharex=True,\n                title=f\"{self.model.NAME}: observed - estimated\"\n            )\n        axes.ravel()[0].axhline(y=0, color=\"black\", linestyle=\"--\")\n        axes.ravel()[0].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n        axes.ravel()[0].ticklabel_format(style=\"sci\",  axis=\"y\",scilimits=(0, 0))\n        axes.ravel()[0].legend(bbox_to_anchor=(1.02, 0), loc=\"lower left\", borderaxespad=0)\n        fig.tight_layout()\n        fig.show()\n    \n    def calc_r0(self):\n        \"\"\"\n        Calculate R0.\n        \"\"\"\n        est_dict = self.study.best_params.copy()\n        est_dict.update(self.fixed_param_dict)\n        est_dict.pop(\"tau\")\n        model_instance = self.model(**est_dict)\n        return model_instance.calc_r0()\n\n    def calc_days_dict(self):\n        \"\"\"\n        Calculate 1\/beta etc.\n        \"\"\"\n        est_dict = self.study.best_params.copy()\n        est_dict.update(self.fixed_param_dict)\n        tau = est_dict[\"tau\"]\n        est_dict.pop(\"tau\")\n        model_instance = self.model(**est_dict)\n        return model_instance.calc_days_dict(tau)\n\n    def predict_df(self, step_n):\n        \"\"\"\n        Predict the values in the future.\n        @step_n <int>: the number of steps\n        @return <pd.DataFrame>: predicted data for measurable variables.\n        \"\"\"\n        est_dict = self.study.best_params.copy()\n        est_dict.update(self.fixed_param_dict)\n        tau = est_dict[\"tau\"]\n        est_dict.pop(\"tau\")\n        df = simulation(self.model, self.initials, step_n=step_n, **est_dict)\n        df[\"Time\"] = (df[\"t\"] * tau).apply(lambda x: timedelta(minutes=x)) + self.start_time\n        df = df.set_index(\"Time\").drop(\"t\", axis=1)\n        df = (df * self.total_population).astype(np.int64)\n        upper_cols = [n.upper() for n in df.columns]\n        df.columns = upper_cols\n        df = self.model.calc_variables_reverse(df).drop(upper_cols, axis=1)\n        return df\n\n    def predict_graph(self, step_n, name=None, excluded_cols=None):\n        \"\"\"\n        Predict the values in the future and create a figure.\n        @step_n <int>: the number of steps\n        @name <str>: name of the area\n        @excluded_cols <list[str]>: the excluded columns in the figure\n        \"\"\"\n        if self.name is not None:\n            name = self.name\n        else:\n            name = str() if name is None else name\n        df = self.predict_df(step_n=step_n)\n        if excluded_cols is not None:\n            df = df.drop(excluded_cols, axis=1)\n        r0 = self.param_dict[\"R0\"]\n        title = f\"Prediction in {name} with {self.model.NAME} model: R0 = {r0}\"\n        line_plot(df, title, v= datetime.today(), h=self.total_population)\n\n    def rmsle(self, compare_df):\n        \"\"\"\n        Return the value of RMSLE.\n        @param compare_df <pd.DataFrame>\n        \"\"\"\n        df = compare_df.set_index(\"t\") * self.total_population\n        score = 0\n        for (priority, v) in zip(self.model.PRIORITIES, self.model.VARIABLES):\n            if priority == 0:\n                continue\n            observed, estimated = df[f\"{v}_observed\"], df[f\"{v}_estimated\"]\n            diff = (np.log(observed + 1) - np.log(estimated + 1))\n            score += (diff ** 2).sum()\n        rmsle = np.sqrt(score \/ len(df))\n        return rmsle\n\n    def score(self):\n        \"\"\"\n        Return the value of RMSLE.\n        \"\"\"\n        rmsle = self.rmsle(self.compare_df().reset_index(\"t\"))\n        return rmsle\n\n    def info(self):\n        \"\"\"\n        Return Estimater information.\n        @return <tupple[object]>:\n            - <ModelBase>: model\n            - <dict[str]=str>: name, total_population, start_time, tau\n            - <dict[str]=float>: values of parameters of model\n        \"\"\"\n        param_dict = self.study.best_params.copy()\n        param_dict.update(self.fixed_param_dict)\n        info_dict = {\n            \"name\": self.name,\n            \"total_population\": self.total_population,\n            \"start_time\": self.start_time,\n            \"tau\": param_dict[\"tau\"],\n            \"initials\": self.initials\n        }\n        param_dict.pop(\"tau\")\n        return (self.model, info_dict, param_dict)","47af807b":"%%time\noutbreak_estimator = Estimator(\n    SIRF, outbreak_df, outbreak_df.loc[outbreak_df.index[-1], \"Population\"],\n    name=\"Outbreaking group\", start_date=outbreak_group_start\n)\noutbreak_dict = outbreak_estimator.run()","0522e52a":"outbreak_estimator.history_df().head()","2cc2ba9f":"outbreak_estimator.history_graph()","b36db28e":"outbreak_estimator.compare_df()","5f4896ac":"outbreak_estimator.compare_graph()","80beb0b2":"pd.DataFrame.from_dict({\"Outbreaking group\": outbreak_dict}, orient=\"index\")","3e2d81cb":"outbreak_estimator.predict_graph(step_n=500)","8fe4cbce":"%%time\nchina_estimator = Estimator(\n    SIRF, china_df, china_df.loc[china_df.index[-1], \"Population\"],\n    name=\"China\", start_date=china_start, end_date=china_end\n)\nchina_dict = china_estimator.run()","27766816":"china_estimator.history_df().head()","c59ebc40":"china_estimator.history_graph()","51662a84":"china_estimator.compare_df()","729f883c":"china_estimator.compare_graph()","860438f3":"pd.DataFrame.from_dict({\"Outbreaking group\": outbreak_dict, \"China\": china_dict}, orient=\"index\")","f71d1e01":"china_estimator.predict_graph(step_n=500)","b183f713":"%%time\nothers_estimator = Estimator(\n    SIRF, others_df, others_df.loc[others_df.index[-1], \"Population\"],\n    name=\"The others\", start_date=others_start, end_date=others_end\n)\nothers_dict = others_estimator.run()","ca8f8376":"others_estimator.history_df().head()","6903d4ea":"others_estimator.history_graph()","8e1a5be3":"others_estimator.compare_df()","8c734091":"others_estimator.compare_graph()","a00a3246":"pd.DataFrame.from_dict({\"Outbreaking group\": outbreak_dict, \"China\": china_dict, \"The others\": others_dict}, orient=\"index\")","5d922ed7":"others_estimator.predict_graph(step_n=500)","d165f753":"class Predicter(object):\n    \"\"\"\n    Predict the future using models.\n    \"\"\"\n    def __init__(self, name, total_population, start_time, tau, initials, date_format=\"%d%b%Y\"):\n        \"\"\"\n        @name <str>: place name\n        @total_population <int>: total population\n        @start_time <datatime>: the start time\n        @tau <int>: tau value (time step)\n        @initials <list\/tupple\/np.array[float]>: initial values of the first model\n        @date_format <str>: date format to display in figures\n        \"\"\"\n        self.name = name\n        self.total_population = total_population\n        self.start_time = start_time\n        self.tau = tau\n        self.date_format = date_format\n        # Un-fixed\n        self.last_time = start_time\n        self.axvlines = list()\n        self.initials = initials\n        self.df = pd.DataFrame()\n        self.title_list = list()\n        self.reverse_f = lambda x: x\n\n    def add(self, model, end_day_n=None, count_from_last=False, vline=True, **param_dict):\n        \"\"\"\n        @model <ModelBase>: the epidemic model\n        @end_day_n <int\/None>: day number of the end date (0, 1, 2,...), or None (now)\n            - if @count_from_last <bool> is True, start point will be the last date registered to Predicter\n        @vline <bool>: if True, vertical line will be shown at the end date\n        @**param_dict <dict>: keyword arguments of the model\n        \"\"\"\n        # Validate day nubber, and calculate step number\n        if end_day_n is None:\n            end_time = datetime.now()\n        else:\n            if count_from_last:\n                end_time = self.last_time + timedelta(days=end_day_n)\n            else:\n                end_time = self.start_time + timedelta(days=end_day_n)\n        if end_time <= self.last_time:\n            raise Exception(f\"Model on {end_time.strftime(self.date_format)} has been registered!\")\n        step_n = int((end_time - self.last_time).total_seconds() \/ 60 \/ self.tau)\n        self.last_time = end_time\n        # Perform simulation\n        new_df = simulation(model, self.initials, step_n=step_n, **param_dict)\n        new_df[\"t\"] = new_df[\"t\"] + len(self.df)\n        self.df = pd.concat([self.df, new_df], axis=0).fillna(0)\n        self.initials = new_df.set_index(\"t\").iloc[-1, :]\n        # For title\n        if vline:\n            self.axvlines.append(end_time)\n            r0 = model(**param_dict).calc_r0()\n            self.title_list.append(\n                f\"{model.NAME}({r0}, -{end_time.strftime(self.date_format)})\"\n            )\n        # Update reverse function (X, Y,.. to Susceptible, Infected,...)\n        self.reverse_f = model.calc_variables_reverse\n        return self\n\n    def restore_df(self):\n        \"\"\"\n        Return the dimentional simulated data.\n        @return <pd.DataFrame>\n        \"\"\"\n        df = self.df.copy()\n        df[\"Time\"] = self.start_time + df[\"t\"].apply(lambda x: timedelta(minutes=x * self.tau))\n        df = df.drop(\"t\", axis=1).set_index(\"Time\") * self.total_population\n        df = df.astype(np.int64)\n        upper_cols = [n.upper() for n in df.columns]\n        df.columns = upper_cols\n        df = self.reverse_f(df).drop(upper_cols, axis=1)\n        return df\n\n    def restore_graph(self, drop_cols=None, **kwargs):\n        \"\"\"\n        Show the dimentional simulate data as a figure.\n        @drop_cols <list[str]>: the columns not to be shown\n        @kwargs: keyword arguments of line_plot() function\n        \"\"\"\n        df = self.restore_df()\n        if drop_cols is not None:\n            df = df.drop(drop_cols, axis=1)\n        axvlines = [datetime.now(), *self.axvlines] if len(self.axvlines) == 1 else self.axvlines[:]\n        line_plot(\n            df,\n            title=f\"{self.name}: {', '.join(self.title_list)}\",\n            v=axvlines[:-1],\n            h=self.total_population,\n            **kwargs\n        )","a3e6b888":"days_to_predict = int((test_df[\"Date\"].max() - datetime.today()).total_seconds() \/ 3600 \/ 24 + 1)\ndays_to_predict","7afb4eca":"_, outbreak_info_dict, outbreak_param_dict = outbreak_estimator.info()","6ce199b6":"predicter = Predicter(**outbreak_info_dict)\npredicter.add(SIRF, end_day_n=None, count_from_last=False, vline=False, **outbreak_param_dict)\npredicter.add(SIRF, end_day_n=days_to_predict, count_from_last=True, **outbreak_param_dict)\noutbreak_predict = predicter.restore_df()\npredicter.restore_graph(drop_cols=[\"Susceptible\"])","f8566024":"_, china_info_dict, china_param_dict = china_estimator.info()","0758fc2a":"predicter = Predicter(**china_info_dict)\npredicter.add(SIRF, end_day_n=None, count_from_last=False, vline=False, **china_param_dict)\npredicter.add(SIRF, end_day_n=days_to_predict, count_from_last=True, **china_param_dict)\nchina_predict = predicter.restore_df()\npredicter.restore_graph(drop_cols=[\"Susceptible\"])","620ab2d3":"_, others_info_dict, others_param_dict = others_estimator.info()","6e36ff61":"predicter = Predicter(**others_info_dict)\npredicter.add(SIRF, end_day_n=None, count_from_last=False, vline=False, **others_param_dict)\npredicter.add(SIRF, end_day_n=days_to_predict, count_from_last=True, **others_param_dict)\nothers_predict = predicter.restore_df()\npredicter.restore_graph(drop_cols=[\"Susceptible\"])","b7991471":"outbreak_predict","8ab5621f":"china_predict","6f0b8b4d":"others_predict","5d1762c6":"def organize_pred(df, group):\n    df = df.copy()\n    df[\"Group\"] = group\n    df[\"Date\"] = df.index.date\n    df = df.reset_index(drop=True).groupby(\"Date\").last()\n    df.index = pd.to_datetime(df.index)\n    return df\n\ndf = pd.concat(\n    [\n        organize_pred(outbreak_predict, \"Outbreaking\"),\n        organize_pred(china_predict, \"China\"),\n        organize_pred(others_predict, \"Others\")\n    ],\n    axis=0\n)\ndf[\"Confirmed\"] = df[\"Infected\"] + df[\"Recovered\"] + df[\"Fatal\"]\ngroup_predict_df = df.loc[:, [\"Group\", \"Confirmed\", \"Fatal\"]]\ngroup_predict_df.tail()","373b8ef3":"line_plot(group_predict_df.drop(\"Group\", axis=1), \"Predicted total values\")","68136012":"group_predict_df.reset_index().tail()","99bffc35":"current_growth_df.tail()","497a0cd5":"record_df = pd.DataFrame()\n\nfor i in range(len(group_predict_df)):\n    time, group, confirmed, fatal = group_predict_df.reset_index().iloc[i, :].tolist()\n    df = current_growth_df.copy()\n    df = df.loc[df[\"Group\"] == group, :]\n    df[\"Confirmed\"] = confirmed \/ (df[\"Current_Confirmed\"] + 1).max() * (df[\"Current_Confirmed\"] + 1)\n    df[\"Fatal\"] = fatal \/ (df[\"Current_Fatal\"] + 1).max() * (df[\"Current_Fatal\"] + 1)\n    df[\"Date\"] = time\n    record_df = pd.concat([record_df, df], axis=0)\n\nrecord_df = record_df.loc[:, [\"Date\", \"Area\", \"Confirmed\", \"Fatal\"]]\nrecord_df[[\"Confirmed\", \"Fatal\"]] = record_df[[\"Confirmed\", \"Fatal\"]].astype(np.int64)\nrecord_df.tail(20)","b19b5786":"test_df.tail()","8610fce5":"submission_sample_raw.head()","9d3fee82":"submission_sample_raw.tail()","fc9ad218":"submission_sample_raw.shape","babc82c2":"df = pd.merge(record_df, test_df, on=[\"Date\", \"Area\"])\ndf = df.sort_values(\"ForecastId\").reset_index()\ndf = df.loc[:, [\"ForecastId\", \"Confirmed\", \"Fatal\"]]\ndf = df.rename({\"Confirmed\": \"ConfirmedCases\", \"Fatal\": \"Fatalities\"}, axis=1)\nsubmission_df = df.copy()\nsubmission_df","332a175a":"submission_df.shape","87c4ad4a":"submission_df.to_csv(\"submission.csv\", index=False)","7d887cbe":"# Introduction\nUsing curve fitting method and SIR-F model, we will predict the number of confirmed cases and fatal cases with COVID-19 global data. SIR-F model was created in another notebook of an auther. Please refer to the references.  \n\nContents:\n* Arrangement of dataset\n* Grouping countries by curve fitting\n* Explanation of SIR-F model\n* Parameter estimaition of SIR-F model in each group\n* Prediction and data submission\n\nReferences:\n* [COVID-19 - Growth of Virus in Specific Countries](https:\/\/www.kaggle.com\/wjholst\/covid-19-growth-of-virus-in-specific-countries)\n* [COVID-19 data with SIR model](https:\/\/www.kaggle.com\/lisphilar\/covid-19-data-with-sir-model)","4a3ecf41":"## Functions","ff07664c":"## EDA of traing data","d80d80ca":"## Grouping areas with growth factor\n* Outbreaking group: growth factor > 1\n* China\n* The others: growth factor <= 1 or None","c72a17cd":"### Total","a153f19f":"## What is SIR-F model?\n* S: Susceptible\n* S$^\\ast$: Confirmed and un-categorized\n* I: Confirmed and categorized as I\n* R: Recovered\n* F: Fatal with confirmation\n\nMeasurable variables:  \nConfirmed = $I+R+F$  \nRecovered = $R$  \nDeaths = $F$  \n\nModel:  \nS $\\overset{\\beta \\mathrm{I}}{\\longrightarrow}$ S$^\\ast$ $\\overset{\\alpha_1}{\\longrightarrow}$ F  \nS $\\overset{\\beta \\mathrm{I}}{\\longrightarrow}$ S$^\\ast$ $\\overset{1 - \\alpha_1}{\\longrightarrow}$ I  \nI $\\overset{\\gamma}{\\longrightarrow}$ R  \nI $\\overset{\\alpha_2}{\\longrightarrow}$ F  \n\n$\\alpha_1$: Mortality rate of S$^\\ast$ cases [-]  \n$\\alpha_2$: Mortality rate of I cases [1\/min]  \n$\\beta$: Effective contact rate [1\/min]  \n$\\gamma$: Recovery rate [1\/min]  \n\nOrdinary Differential Equation (ODE):   \n$\\frac{\\mathrm{d}S}{\\mathrm{d}T}= - N^{-1}\\beta S I$  \n$\\frac{\\mathrm{d}I}{\\mathrm{d}T}= N^{-1}(1 - \\alpha_1) \\beta S I - (\\gamma + \\alpha_2) I$  \n$\\frac{\\mathrm{d}R}{\\mathrm{d}T}= \\gamma I$  \n$\\frac{\\mathrm{d}F}{\\mathrm{d}T}= N^{-1}\\alpha_1 \\beta S I + \\alpha_2 I$  \n\nWhere $N=S+I+R+F$ is the total population, $T$ is the elapsed time from the start date.","b0ed437c":"## Total value of China over time","20f9937b":"### Outbreaking group","8ec8d45e":"### The others","99b60c7f":"### Parameters of Outbreaking group","19f7a2e7":"## Raw data","72efac01":"# Parameter estimaition of SIR-F model in each group\nIn this section, we will estimate the non-dimensional model using training data in outbreaking group\/the others.","b3e8af9c":"### Parameters of China","f4e20481":"## Non-dimensional SIR-F model\n\nTo simplify the model, we will remove the units of the variables from ODE.\n\nSet $(S, I, R, F) = N \\times (x, y, z, w)$ and $(T, \\alpha_1, \\alpha_2, \\beta, \\gamma) = (\\tau t, \\theta, \\tau^{-1} \\kappa, \\tau^{-1} \\rho, \\tau^{-1} \\sigma)$.  \nThis results in the ODE  \n$\\frac{\\mathrm{d}x}{\\mathrm{d}t}= - \\rho x y$  \n$\\frac{\\mathrm{d}y}{\\mathrm{d}t}= \\rho (1-\\theta) x y - (\\sigma + \\kappa) y$  \n$\\frac{\\mathrm{d}z}{\\mathrm{d}t}= \\sigma y$  \n$\\frac{\\mathrm{d}w}{\\mathrm{d}t}= \\rho \\theta x y + \\kappa y$  \n\nWhere $N$ is the total population and $\\tau$ is a coefficient ([min], is an integer to simplify).  \n\nThe range of variables and parameters:  \n$0 < (x, y, z, w, \\theta, \\kappa, \\rho, \\sigma) < 1$  \n$1 \\leq \\tau \\leq 1440$  \n\nReproduction number can be defined as  \n$R_0 = \\rho (1 - \\theta) (\\sigma + \\kappa)^{-1} = \\beta (1 - \\alpha_1) (\\gamma + \\alpha_2)^{-1}$\n\nWhen $x=\\frac{1}{R_0}$, $\\frac{\\mathrm{d}y}{\\mathrm{d}t}=0$. This means that the max value of confirmed ($=y+z+w$) is $1-\\frac{1}{R_0}$.","8e9a887c":"### Add \"S + I $\\to$ F + I formula\nSome cases are reported as fatal cases before clinical diagnosis of COVID-19. To consider this issue, \"S + I $\\to$ Fatal + I\" will be added to the model.","282fb3d5":"## What is SIR model?\nSIR model is a simple mathematical model to understand outbreak of infectious diseases.  \n[The SIR epidemic model - Learning Scientific Programming with Python](https:\/\/scipython.com\/book\/chapter-8-scipy\/additional-examples\/the-sir-epidemic-model\/)\n\n * S: Susceptible (=Total population - Confirmed)\n * I: Infected\n * R: Recovered\n\nModel:  \nS + I $\\overset{\\beta}{\\longrightarrow}$ 2I  \nI $\\overset{\\gamma}{\\longrightarrow}$ R\n\n$\\beta$: Effective contact rate [1\/min]  \n$\\gamma$: Recovery rate [1\/min]  \n\nOrdinary Differential Equation (ODE):   \n$\\frac{\\mathrm{d}S}{\\mathrm{d}T}= - N^{-1}\\beta S I$  \n$\\frac{\\mathrm{d}I}{\\mathrm{d}T}= N^{-1}\\beta S I - \\gamma I$  \n$\\frac{\\mathrm{d}R}{\\mathrm{d}T}= \\gamma I$  \n\nWhere $N=S+I+R$ is the total population, $T$ is the elapsed time from the start date.","341e17f3":"### Country\/Province level","e22d3d45":"# Prediction and data submission\nWe will predict the future with the estimated parameters.","20838bfe":"## Total value of the others over time","272d75e4":"# Explanation of SIR-F model\nIn this section, we will create a mathematical model named SIR-F model. This model is derived from SIR model.","2b4044cc":"**For currently outbreaking group, we will use data from 15Feb2020.**","ae9a32a9":"**For currently outbreaking group, we will use data from 26Jan2020 to 15Feb2020.**","a71d1ea0":"### Submit data","ae739007":"## Calculate growth factor\n$\\mathrm{Growth\\ Factor} = \\cfrac{\\Delta \\mathrm{Confirmed}_{n}}{\\Delta \\mathrm{Confirmed}_{n-1}}$","a938a7ea":"### Replace R with (R, F)\nR in SIR model is \"Recovered and have immunity\", but mortality rate cannot be ignored in the real COVID-19 data. Furthermore, with this dataset, we know only the number of confirmed cases and fatal cases.","ade245c2":"# Arrangement of dataset\nData acquisition and EDA will be done in this section.","0d70fa1b":"## Data cleaning of training data","c253a047":"**Note: We cannot convert T to t because $\\tau$ has not been determined yet.**","afc767bf":"# Grouping countries by curve fitting\nThe number of confirmed cases is increasing in many countries, but there are two of countries.  \n\nIn a first-type country, growth factor is larger than 1 and the number of cases is rapidly increasing.In a second-type country, growth factor is less than 1.\n\nBecause China has low growth factor and many cases, China will be regard as an independent group.","35f3b38f":"## Total value of outbreaking group over time","70dfa9d6":"## Total population of each country","53cd9cb6":"## Data cleaning of test data","67e0ca28":"## Transform training data\n* T means elapsed time [min] from the start date.\n* The number of cases will be divided by total population.","1735a1c0":"## Hyper parameter optimization\nUsing Optuna package, $(\\theta, \\kappa, \\sigma, \\rho, \\tau)$ will be estimated by model fitting.","345de30a":"## Packages","7dc19a93":"## Predict the future","00692722":"**For the others, we will use data from 15Feb2020 to 22Mar2020.**","6c20e97b":"## Why we need SIR-F model?","0d8f55b1":"### Parameters of the others","2f7fa204":"### China","15a788d0":"## Example of non-dimensional SIR-F model\nNumerical simulation will be performed with scipy.integrate.solve_ivp function.  \nFor example, set $(\\theta, \\kappa, \\sigma, \\rho)=(0.08, 0.0001, 0.02, 0.2)$, initial values $(S_0, I_0, R_0, F_0)=(1, 0.0001, 0, 0)$.","25d854bc":"### Plotting"}}