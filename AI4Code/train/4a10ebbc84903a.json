{"cell_type":{"2d8c2fd8":"code","9e2735cb":"code","a5d01643":"code","1d0a51f1":"code","40705224":"code","0dfa0932":"code","d5f943a7":"code","44383b1c":"code","c33d8538":"code","e5da6742":"code","5aaefe56":"code","5551bff1":"code","37178420":"code","c9684523":"code","596116ca":"code","3a926c2d":"code","916c644a":"code","6c1091d6":"code","a30f653c":"code","db012ecc":"code","ff80ad4e":"code","7c61b9f9":"code","a991c061":"code","8a1503f5":"code","50f69696":"code","cff5278e":"code","ba205b1c":"code","d1054fd7":"code","6445eddc":"code","6ec9a0e0":"markdown","96966b3f":"markdown","c8b507fd":"markdown","04c36e1b":"markdown","8b7f171b":"markdown","f7b48ae1":"markdown","1b6b24af":"markdown","e13c9fe6":"markdown","032e66cf":"markdown","6ce9c8c7":"markdown","686e083a":"markdown"},"source":{"2d8c2fd8":"### General ###\nimport os\nimport math\nimport random\nimport warnings\nimport numpy as np\nimport pandas as pd\n\n### Visualization ###\nimport matplotlib as mpl\nfrom colorama import Fore\nimport matplotlib.pyplot as plt\n\n### Machine Learning Tools ###\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold, train_test_split\n\n### Deep Learning ###\nimport torch","9e2735cb":"seed = 42\n\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    \n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\nset_seed(seed)","a5d01643":"plt.style.use(\"bmh\")\nwarnings.filterwarnings(\"ignore\")\nmpl.rcParams[\"agg.path.chunksize\"] = 10000","1d0a51f1":"b_ = Fore.BLUE\nc_ = Fore.CYAN\ng_ = Fore.GREEN\nm_ = Fore.MAGENTA\nr_ = Fore.RED\ny_ = Fore.YELLOW","40705224":"df = pd.read_csv(\"..\/input\/covid19-in-india\/covid_19_india.csv\")\n\n# Replaces numerical NaN (NNs are bad with NaNs)\nfor col in df.columns:\n  if df[col].dtype not in [str, object]:\n    df[col] = df[col].fillna(0)\n\ndf.Date = pd.to_datetime(df.Date, format = \"%Y-%m-%d\")\ndf.set_index(\"Date\", drop = False, inplace = True)","0dfa0932":"df.Date.max()","d5f943a7":"df.Date.min()","44383b1c":"df.dtypes","c33d8538":"df[[\"Confirmed\"]].plot(figsize = (16, 5));","e5da6742":"df[[\"Cured\"]].plot(figsize = (16, 5));","5aaefe56":"df[[\"Deaths\"]].plot(figsize = (16, 5));","5551bff1":"train = df[df.Date < \"2021-07-11\"]\ntest = df[df.Date >= \"2021-07-11\"]","37178420":"X = train.drop([\"Date\", \"Time\", \"State\/UnionTerritory\", \"ConfirmedIndianNational\", \"ConfirmedForeignNational\", \"Confirmed\"],\n                    axis = 1)\ny = train[\"Confirmed\"]\n\nX_test = test.drop([\"Date\", \"Time\", \"State\/UnionTerritory\", \"ConfirmedIndianNational\", \"ConfirmedForeignNational\", \"Confirmed\"],\n                  axis = 1)\ny_test = test[\"Confirmed\"]","c9684523":"print(f\"{b_}X_train.shape: {r_}{X.shape}\")\nprint(f\"{b_}X_test.shape: {r_}{X_test.shape}\")\nprint(f\"{b_}y.shape: {r_}{y.shape}\")\nprint(f\"{b_}y_test.shape: {r_}{y_test.shape}\")","596116ca":"# Don't shuffle order matters or at least is what i know\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.20, random_state = 42, shuffle = False)","3a926c2d":"%%time\nxgb_reg = xgb.XGBRegressor(\n    tree_method = \"gpu_hist\", \n    n_estimators = 200, \n    random_state = 42,\n    learning_rate = 0.02,\n    max_depth = 20,\n    gamma = 0,\n    subsample = 1,\n    min_child_weight = 1,\n    nthread = 4,\n    colsample_bytree = 1\n)\nxgb_reg.fit(\n    X_train,\n    y_train,\n    eval_set = [(X_valid, y_valid)],\n    early_stopping_rounds = 10,\n    verbose = False\n)","916c644a":"xgb.plot_importance(xgb_reg, height = 0.9);","6c1091d6":"X_train, X_valid = X_train.to_numpy(), X_valid.to_numpy()\ny_train, y_valid = y_train.to_numpy(), y_valid.to_numpy()\nX_test = X_test.to_numpy()","a30f653c":"# Installing XBNet from GitHub\n!pip install --upgrade git+https:\/\/github.com\/tusharsarkar3\/XBNet.git","db012ecc":"from XBNet.run import run_XBNET\nfrom XBNet.models import XBNETRegressor\nfrom XBNet.training_utils import training, predict\n\nmodel = XBNETRegressor(\n    X_train,\n    y_train,\n    num_layers = 2\n)","ff80ad4e":"criterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.001)","7c61b9f9":"m, acc, lo, val_ac, val_lo = run_XBNET(\n    X_train,\n    X_valid,\n    y_train,\n    y_valid,\n    model,\n    criterion,\n    optimizer,\n    epochs = 100,\n    batch_size = 128\n)","a991c061":"plt.figure(figsize = (20,5))\n\nplt.subplot(1, 2, 1)\nplt.plot(acc,label = \"Training Accuracy\")\nplt.plot(val_ac,label = \"Validation Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.grid()\n\nplt.subplot(1, 2, 2)\nplt.plot(lo,label = \"Training loss\")\nplt.plot(val_lo,label = \"Validation loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend() \nplt.grid()","8a1503f5":"xbnet_preds = []\nfor i in range(0, len(y_test)):\n    xbnet_preds.append(predict(m, X_test[i, :]))\n\nxgb_preds = xgb_reg.predict(X_test)","50f69696":"mse0 = mean_squared_error(y_test, xbnet_preds)\nmse1 = mean_squared_error(y_test, xgb_preds)\n\nprint(f\"{b_}MSE (XBNet): {r_}{mse0:.4f}\")\nprint(f\"{b_}MSE (XGBoost): {r_}{mse1:.4f}\")","cff5278e":"mse1 > mse0","ba205b1c":"prom = np.mean([xbnet_preds, xgb_preds], axis = 0)","d1054fd7":"test[\"xgb_preds\"] = xgb_preds\ntest[\"xbnet_preds\"] = xbnet_preds\ntest[\"prom\"] = prom\n\ndf_new = pd.concat([train, test], sort = False)","6445eddc":"df_new[[\"Confirmed\", \"xbnet_preds\", \"prom\", \"xgb_preds\"]].plot(figsize = (16, 5), title = \"XBNet vs XGBoost Results\");","6ec9a0e0":"<h1 style=\"color:blue\">XBNet<\/h1>\n\n- [Useful example](https:\/\/www.kaggle.com\/mpwolke\/xbnet-creditability)\n- [Original paper](https:\/\/arxiv.org\/abs\/2106.05239)\n- [GitHub repo](https:\/\/github.com\/tusharsarkar3\/XBNet)","96966b3f":"<h2 style=\"color:red\">Re-spliting the Data<\/h2>\n\nThis time is to make a validation dataset, **i don't want to show test data to the model**. Many works that a saw do that to improve their \"amazing results\".","c8b507fd":"<h1 style=\"color:blue\">Results<\/h1>\n","04c36e1b":"<h1 style=\"color:blue\">Libraries<\/h1>","8b7f171b":"<h1 style=\"color:blue\">Preambule<\/h1>\n\n<div class=\"alert alert-block alert-info\">\n    Due the fact that there aren't too many tutorials that use <b>XBNet<\/b> (especially about regression with this architecture), i tried to do a simple one.These notebook is about <b>time series forecasting<\/b> of COVID-19 data from India.\n<\/div>","f7b48ae1":"<h1 style=\"color:blue\">Configuration<\/h1>","1b6b24af":"<h2 style=\"color:red\">Training<\/h2>\n","e13c9fe6":"<h1 style=\"color:blue\">Loading and Exploring the Data<\/h1>","032e66cf":"<h2 style=\"color:red\">Modelling<\/h2>\n\n~~~\nEnter dimensions of linear layers: \nEnter input dimensions of layer 1:  10\nEnter output dimensions of layer 1:  10\nSet bias as True or False:  False\nEnter input dimensions of layer 2:  10\nEnter output dimensions of layer 2:  1\nSet bias as True or False:  False\nEnter your last layer \n1. Sigmoid \n2. Softmax \n3. None \n 3\n ~~~~","6ce9c8c7":"<h1 style=\"color:blue\">XGBoost<\/h1>","686e083a":"<h2 style=\"color:red\">Spliting the Data<\/h2>\n\nTest dataset with one month of cases, i tried to avoid **data leakeage** with this."}}