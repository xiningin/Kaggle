{"cell_type":{"f483eef9":"code","155684fe":"code","3625e7f0":"code","12e5b183":"code","a3cc56f8":"code","f20d358c":"code","a8646114":"code","a5113d28":"code","f142149f":"code","6ee1253e":"code","53a0e330":"code","be8c9067":"code","b3b45ffe":"code","1627fae9":"code","7e1284c9":"code","1a4bb90f":"code","6c08f628":"code","3ee51351":"code","bdc41584":"code","80c5d204":"code","d710be88":"code","7ba8d60c":"code","49cb1b3f":"code","578101f8":"code","fd0c09b4":"code","aabe03dc":"code","8b3e2d0a":"code","03a23a09":"code","00f02db2":"code","f5fd6295":"code","269abf89":"code","7e9985db":"code","04982f91":"code","a7a47367":"code","c7c4e1d1":"code","3494b2c1":"code","140fc3f9":"code","c2be19b5":"code","65aa8816":"code","44234a76":"code","d1245cdb":"code","202b0dbd":"code","4cd4cc8d":"markdown","7307fcb0":"markdown","6aeb45ba":"markdown","eb7a396b":"markdown","63590f49":"markdown","783de733":"markdown","82647f0f":"markdown","afc5655d":"markdown","ab25dad6":"markdown","c1357fd1":"markdown","86664fca":"markdown","ff78680f":"markdown","c289486d":"markdown","96bb30fe":"markdown","b0ea00ff":"markdown"},"source":{"f483eef9":"import os\nimport numpy as np\nimport pandas as pd\nimport warnings\nimport cv2\nimport random\nfrom matplotlib import pyplot as plt\n\n%matplotlib inline\nwarnings.filterwarnings(\"ignore\")","155684fe":"print(os.getcwd())\nprint(os.listdir('..\/input'))","3625e7f0":"def show(img):\n#     plt.figure()\n    plt.imshow(img)\n#     plt.show()","12e5b183":"def rle_to_mask(rle_string, img):\n    \n    rows, cols = img.shape[0], img.shape[1]\n    img = np.zeros(rows*cols, dtype=np.uint8)\n\n    rle_numbers = [int(x) for x in rle_string.split(' ')]\n    rle_pairs = np.array(rle_numbers).reshape(-1,2)\n\n    for index, length in rle_pairs:\n        index -= 1\n        img[index:index+length] = 255\n    img = img.reshape(cols,rows)\n    img = img.T\n    img = image = np.expand_dims(img, axis=2)\n    \n    return img","a3cc56f8":"def ignore_background(img_mask, img_origin):\n    assert img_mask.shape == img_mask.shape\n    \n    result = img_mask.copy()\n    result[np.where(img_mask==255)] = img_origin[np.where(img_mask==255)]\n    \n    return result","f20d358c":"train_csv = pd.read_csv('..\/input\/understanding_cloud_organization\/train.csv')\nsub_csv = pd.read_csv('..\/input\/understanding_cloud_organization\/sample_submission.csv')","a8646114":"train_csv = train_csv.fillna(-1)\ntrain_csv.head()","a5113d28":"train_csv['ImageId'] = train_csv['Image_Label'].apply(lambda x: x.split('_')[0])\ntrain_csv['Label'] = train_csv['Image_Label'].apply(lambda x: x.split('_')[1])\ntrain_csv = train_csv.drop('Image_Label', axis=1)\ntrain_csv.head()","f142149f":"print('Total', len(train_csv['ImageId'].unique()),'Images for', len(train_csv['Label'].unique()), 'Types.')","6ee1253e":"fish = len(train_csv[train_csv['Label']=='Fish'][train_csv['EncodedPixels']!= -1])\nflower = len(train_csv[train_csv['Label']=='Flower'][train_csv['EncodedPixels']!= -1])\ngravel = len(train_csv[train_csv['Label']=='Gravel'][train_csv['EncodedPixels']!= -1])\nsugar = len(train_csv[train_csv['Label']=='Sugar'][train_csv['EncodedPixels']!= -1])\nprint('The amount of Fish:{0}, Flower:{1}, Gravel:{2}, Sugar:{3} .'.format(fish, flower, gravel, sugar))\nprint('Totally {} valid Images.'.format(fish+flower+gravel+sugar))","53a0e330":"plt.title(\"Total amount of images each type.\")\nplt.bar([1,2,3,4],[fish, flower, gravel, sugar], tick_label=['Fish', 'Flower', 'Graver', 'Sugar'])","be8c9067":"train_df = train_csv[train_csv['EncodedPixels']!=-1]\ntrain_df.shape","b3b45ffe":"types_per_image = train_df.groupby(by='ImageId', as_index=False).agg({'EncodedPixels': pd.Series.nunique})['EncodedPixels']","1627fae9":"per = np.histogram(list(types_per_image), bins=range(1, 6))","7e1284c9":"plt.title(\"Histogram of types per image.\")\nplt.bar([1,2,3,4], per[0])","1a4bb90f":"BASE_DIR = '..\/input\/understanding_cloud_organization\/train_images\/'","6c08f628":"train_df.head()","3ee51351":"img = cv2.imread(BASE_DIR + train_df['ImageId'][7])\nimg = cv2.resize(img, (512, 512))","bdc41584":"show(img);plt.axis('off')","80c5d204":"horizontal_img = cv2.flip( img, 0 )\nvertical_img = cv2.flip( img, 1 )\nboth_img = cv2.flip( img, -1 )","d710be88":"(h, w) = img.shape[:2] #10\ncenter = (w \/\/ 2, h \/\/ 2)\nM = cv2.getRotationMatrix2D(center, 40, 1.0) #12\nrotated = cv2.warpAffine(img, M, (w, h))","7ba8d60c":"\nlab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n\nlab_planes = cv2.split(lab)\n\nclahe = cv2.createCLAHE(clipLimit=2.0,tileGridSize=(8,8))\n\nlab_planes[0] = clahe.apply(lab_planes[0])\n\nlab = cv2.merge(lab_planes)\n\nbgr = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)","49cb1b3f":"plt.imshow(bgr);plt.axis('off')","578101f8":"img = cv2.imread(BASE_DIR + train_df['ImageId'][0])\nimg_mask = rle_to_mask(train_df['EncodedPixels'][0], img)\nimg_new0 = ignore_background(img_mask, img)\nimg_mask = rle_to_mask(train_df['EncodedPixels'][1], img)\nimg_new1 = ignore_background(img_mask, img)","fd0c09b4":"img_mask.shape","aabe03dc":"plt.subplots(figsize=(15, 6))\nplt.subplot(1,3,1); show(img);plt.title('orginal image');\nplt.subplot(1,3,2); show(img_new0);plt.title('Fish part');\nplt.subplot(1,3,3); show(img_new1);plt.title('Flower part');","8b3e2d0a":"show(img)","03a23a09":"train_df = train_df.reset_index(drop=True)\nfor i in range(100):\n    index = random.randint(0, 11835)\n    img = cv2.imread(BASE_DIR + train_df['ImageId'][index])\n    plt.subplots(figsize=(15, 6))\n    plt.subplot(1, 3, 1); show(img);\n    plt.title('Origin Image. Index: {} Type: {}'.format(index, train_df['Label'][index]))\n    plt.subplot(1, 3, 2); show(rle_to_mask(train_df['EncodedPixels'][index], img));\n    plt.title('Mask. Index: {} Type: {}'.format(index, train_df['Label'][index]))\n    plt.subplot(1, 3, 3); show(ignore_background(rle_to_mask(train_df['EncodedPixels'][index], img), img));\n    plt.title('Masked Image. Index: {} Type: {}'.format(index, train_df['Label'][index]))","00f02db2":"train_df.head()","f5fd6295":"image_id = list(train_df['ImageId'].unique())","269abf89":"warm = []\nfor x in image_id:\n    img = cv2.imread(BASE_DIR + x)\n    tmp = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n    types = list(train_df[train_df['ImageId']==x]['EncodedPixels'])\n    for y in types:\n        print(rle_to_mask(y, img).shape)\n        tmp = tmp + rle_to_mask(y, img)\/255.0\n    warm.append(np.max(tmp))","7e9985db":"plt.title('Amount of Types per Pixel has')\nplt.bar([1,2,3,4], np.histogram(warm, bins=range(1, 6))[0])","04982f91":"import pandas as pd\nensemble = pd.read_csv(\"..\/input\/ensemble\/ensemble.csv\")","a7a47367":"ensemble.head(30)","c7c4e1d1":"result = cv2.imread('..\/input\/understanding_cloud_organization\/test_images\/969f34b.jpg')\nresult = cv2.resize(result, (525, 350))","3494b2c1":"show(result)","140fc3f9":"img_mask = rle_to_mask(ensemble['EncodedPixels'][1], result)\nimg_new0 = ignore_background(img_mask, result)\nimg_mask = rle_to_mask(ensemble['EncodedPixels'][3], result)\nimg_new1 = ignore_background(img_mask, result)","c2be19b5":"plt.subplots(figsize=(15, 6))\nplt.subplot(1,3,1); show(result);plt.title('orginal image');\nplt.subplot(1,3,2); show(img_new0);plt.title('Flower part');\nplt.subplot(1,3,3); show(img_new1);plt.title('Sugar part');","65aa8816":"result = cv2.imread('..\/input\/understanding_cloud_organization\/test_images\/5a61caf.jpg')\nresult = cv2.resize(result, (525, 350))","44234a76":"show(result)","d1245cdb":"img_mask = rle_to_mask(ensemble['EncodedPixels'][21], result)\nimg_new0 = ignore_background(img_mask, result)\nimg_mask = rle_to_mask(ensemble['EncodedPixels'][22], result)\nimg_new1 = ignore_background(img_mask, result)\nimg_mask = rle_to_mask(ensemble['EncodedPixels'][23], result)\nimg_new2 = ignore_background(img_mask, result)","202b0dbd":"plt.subplots(figsize=(15, 6))\nplt.subplot(1,4,1); show(result);plt.title('orginal image');\nplt.subplot(1,4,2); show(img_new0);plt.title('Flower part');\nplt.subplot(1,4,3); show(img_new1);plt.title('Gravel part');\nplt.subplot(1,4,4); show(img_new2);plt.title('Sugar part');","4cd4cc8d":"# Analysis Data","7307fcb0":"Then I want to see if one pixel could have multi classes.","6aeb45ba":"By the way, because this will be used as my course project, so I do willing to know your feedback and suggestions, which will help to improve my project quality. I will appreciate it if you can help, thanks. <!--And if anyone want to team up, pls send me the message.-->","eb7a396b":"From here we can see, most images contain pixels that belong to 2 classes or less,and few pixels has 3 classes or more.<!-- So I think it's better to train models for each type, and then conbine them together. -->","63590f49":"To begin with, I want to see the balance of each type.","783de733":"So, most of the images contain 2 types, and only 266 images contain all of 4 types.","82647f0f":"Till now, I think I have done most of eda, https:\/\/www.kaggle.com\/ekhtiar\/eda-find-me-in-the-clouds?scriptVersionId=19089157 a great kernel, also contains some useful information I didn't work with. \nThen I will start to build my own model.","afc5655d":"Let's test one image first.","ab25dad6":"The balance seems ok, so then I want to see how many types each image has.","c1357fd1":"Here we can see, most of the masks are rectangular, or likely to be shaped as a rectangle. One thing that matters is that 'black zone', this always break the mask and should be regard as noise.\nIn this occation, I considere two ways to solve the problem, Image Segmentation or Object Detection, based on my experience, the first method is more likely to occur overfit while the second is underfit.","86664fca":"# Load Data","ff78680f":"# Visualize Mask","c289486d":"# Import Libraries & Functions","96bb30fe":"Then I want to see more data.","b0ea00ff":"Reference: https:\/\/www.kaggle.com\/ekhtiar\/eda-find-me-in-the-clouds, please also upvote this great kernel if you find it's useful.\nThis kernel shows basic eda about this competition, cause I decided to use this competition as a final project for one of my courses, so I will continue working and hope for your feedback, I will appreciate it."}}