{"cell_type":{"880c029d":"code","6b546852":"code","cbb2450b":"code","4136f973":"code","4cd9c29f":"code","c10f70a5":"code","ea086446":"code","e48a77f5":"markdown","6a0d32a9":"markdown","df7a698a":"markdown","942b651c":"markdown"},"source":{"880c029d":"# import libraries \n\nimport torch\nimport torchvision.models as models\nimport numpy as np\nimport pandas as pd\nimport random\nimport os\nimport pandas as pd\nimport cv2\n\nimport PIL\nfrom PIL import Image\n\nfrom torch import nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nfrom torchvision import datasets\nfrom torchvision import models as models\nfrom torchvision import transforms\nfrom torch.autograd import Variable\nfrom torchvision import transforms as T\n\n\ntorch.backends.cudnn.deterministic = True\n\nimport albumentations\nfrom sklearn import metrics, model_selection\n\n\npathtoimgs = \"..\/input\/cassava-leaf-disease-classification\/train_images\"  # Path to folder with train images\npathtocsv = \"..\/input\/cassava-leaf-disease-classification\/train.csv\"  # Path to csv-file with targets\npath = \"\"  # Working directory, the place where the logs and the weights will be saved\n\n# define parameters etc.\n\nn_folds = 5\nseed = 33\nscheduler_step = 20 \nscheduler_gamma = 5\nlr = 0.0001\nbatch_size = 32\nnum_classes = 5\nnum_epochs = 5\nnum_workers = 4","6b546852":"# create folds taken from https:\/\/www.kaggle.com\/khyeh0719\/pytorch-efficientnet-baseline-inference-tta\ndf = pd.read_csv(pathtocsv)\ndf[\"kfold\"] = -1    \ndf = df.sample(frac=1).reset_index(drop=True)\n\nkf = model_selection.StratifiedKFold(n_splits=n_folds, random_state = seed, shuffle=True)\n\nfor f, (t_, v_) in enumerate(kf.split(np.arange(df.shape[0]), df.label.values)):\n    df.loc[df.index.isin(v_), ['kfold']] = f\n    \ndf.to_csv(\"train_folds.csv\", index=False)\n\nN_CLASSES = df.label.nunique()\nLABELS = ['Cassava Bacterial Blight','Cassava Brown Streak Disease','Cassava Green Mottle','Cassava Mosaic Disease','Healthy']","cbb2450b":"\nclass ClassificationDataset:\n    def __init__(self, image_paths, targets):\n        self.image_paths = image_paths\n        self.targets = targets        \n        self.transforms = T.Compose([T.RandomResizedCrop(224),T.ToTensor(),\n                                T.Normalize([0.670, 0.464, 0.707], [0.146, 0.165, 0.111])]) # ImageNet values\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, item):\n        image = Image.open(self.image_paths[item]).convert('RGB')\n        image = self.transforms(image)\n        targets = self.targets[item]\n    \n        return image, targets \n\n","4136f973":"class DenseNetConv(torch.nn.Module): # https:\/\/www.kaggle.com\/renatobmlr\/pytorch-densenet-as-feature-extractor\n    def __init__(self):\n        super(DenseNetConv,self).__init__()\n        original_model = models.densenet161(pretrained=True)\n        self.features = torch.nn.Sequential(*list(original_model.children())[:-1])\n        for param in self.parameters():\n            param.requires_grad = False\n\n    def forward(self, x):\n        x = self.features(x)\n        #x = F.relu(x, inplace=True)\n        x = F.avg_pool2d(x, kernel_size=7).view(x.size(0), -1)\n        return x\n    ","4cd9c29f":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\ndensenet= DenseNetConv()\ndensenet.to(device)\nprint(densenet)","c10f70a5":"classifier = nn.Linear(2208, num_classes)\nclassifier.to(device)\n\ncriterion = nn.CrossEntropyLoss().to(device)\noptimizer = torch.optim.Adam(classifier.parameters(), lr=lr)\nscheduler = lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)\n","ea086446":"for fold in range(n_folds):\n    \n    training_data_path = pathtoimgs\n    df = pd.read_csv(\"train_folds.csv\")\n\n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n    \n    train_images = df_train.image_id.values.tolist()\n    train_images = [os.path.join(training_data_path, i ) for i in train_images]\n    train_targets = df_train.label.values\n\n    valid_images = df_valid.image_id.values.tolist()\n    valid_images = [os.path.join(training_data_path, i ) for i in valid_images]\n    valid_targets = df_valid.label.values\n    \n    \n    train_dict = ClassificationDataset(image_paths=train_images, targets=train_targets)    \n    train_loader = torch.utils.data.DataLoader(train_dict, batch_size=batch_size, shuffle=True, num_workers=num_workers) \n\n    val_dict = ClassificationDataset(image_paths=valid_images, targets=valid_targets)    \n    val_loader = torch.utils.data.DataLoader(val_dict, batch_size=batch_size, shuffle=True, num_workers=num_workers) \n\n   \n\n    for epoch in range(0, num_epochs + 1):\n        print('Epoch {}\/{}'.format(epoch, num_epochs))\n        print('-' * 60)\n\n        total_loss = 0\n        train_accuracy = 0\n        classifier.train()\n\n        for i, (inputs, labels) in enumerate(train_loader):\n            \n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n\n            x10 = densenet(inputs)\n        \n\n            optimizer.zero_grad()\n\n            # Forward pass to get output\/logits\n            outputs =  classifier(x10)\n           \n            # Calculate Loss: softmax --> cross entropy loss\n            loss = criterion(outputs, labels)\n            total_loss += loss.item()\n\n            _, pred = torch.max(outputs, 1)\n            equality_check = (labels.data == pred)\n            train_accuracy += equality_check.type(torch.FloatTensor).mean()\n\n            # Getting gradients w.r.t. parameters\n            loss.backward()\n            optimizer.step()\n\n        scheduler.step()\n\n        train_losses = total_loss \/ len(train_loader)\n        training_accuracy = train_accuracy\/ len(train_loader)\n\n        print(\"Epoch : {} Train Loss = {:.6f}, Train Accuracy = {:.6f}\".format(epoch, train_losses, training_accuracy))\n\n        \n        classifier.eval()\n        val_loss = 0\n        val_accuracy = 0\n\n        val_confusion_matrix = torch.zeros(num_classes, num_classes)\n\n        with torch.no_grad(): # Tell torch not to calculate gradients\n            for i, (inputs, labels) in enumerate(val_loader):\n                val_inputs10x = inputs.to(device)\n                val_labels = labels.to(device)\n\n                val_x10 = densenet(val_inputs10x)\n\n                val_outputs = classifier(val_x10)\n                val_loss += criterion(val_outputs, val_labels).item()\n\n                _val, val_pred = torch.max(val_outputs, 1)\n                val_equality_check = (val_labels.data == val_pred)\n                val_accuracy += val_equality_check.type(torch.FloatTensor).mean()\n\n                for t, p in zip(val_labels.view(-1), val_pred.view(-1)):\n                    val_confusion_matrix[t.long(), p.long()] += 1\n                    \n        # https:\/\/discuss.pytorch.org\/t\/class-wise-accuacy\/88141\/2\n        ele_wise_acc = val_confusion_matrix.diag() \/ val_confusion_matrix.sum(1)\n        class_wise_acc = ele_wise_acc.mean() * 100\n\n\n        # https:\/\/stackoverflow.com\/questions\/52176178\/pytorch-model-accuracy-test\n\n        val_losses = val_loss \/ len(val_loader)\n        validation_accuracy = val_accuracy\/ len(val_loader)\n\n\n        print(\"Epoch : {} Validation Loss = {:.6f}, Validation Accuracy = {:.6f}\".format(epoch, val_losses, validation_accuracy))\n","e48a77f5":"# Pretrained DenseNet161 PyTorch Baseline Train (5-fold)\n\n\nNewish to Kaggle, and this is my first ever notebook! \n\nI simply tried an ImageNet pretrained Densenet161 for **training** with 5 fold cross validation.  It appears this is not good enough (well in comparison to the other notebooks with much higher performances). I haven't added any augmentations and are resizing my images to 224 by 224 (see the dataset class). \n\nThis notebook is for simplicity and so I hope it is useful for those who want a bareback simple example to build on. I'm also big on ockhams razor so don't want to add complexity where it is not needed.\n\nFor future work, I will:\n* resize images to 512 by 512 pixels, \n* use an efficientnet architecture or se_resnext101 \n* add simple augmentations\n* a different loss function as it is also understood that there may be a lot of noise in the data (i.e. noisy labels).\n\nLet me know what you think. ","6a0d32a9":"Here I define the pretrained DenseNet161 feature extractor.","df7a698a":"The fully connected layer\/classifier is defined below. The DenseNet feature extractor should output 2208 features thus we define a linear layer that contains the number of features and classes.","942b651c":"Defining the Dataset class. I optdd for something quite simple. You can easily add "}}