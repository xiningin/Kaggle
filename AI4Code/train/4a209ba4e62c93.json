{"cell_type":{"ab9691c2":"code","4b8abea7":"code","9f0ca7b5":"code","4e1cfef1":"code","d00a2e13":"code","dfa3ed37":"code","f51ec918":"code","b4d162e0":"code","bb738f98":"code","15b069cb":"code","7a36e36a":"code","983e80ea":"code","1d7a0567":"markdown","a5a9c2a2":"markdown","b68dc0cf":"markdown","6960982c":"markdown","4d01846a":"markdown"},"source":{"ab9691c2":"import numpy as np \nimport pandas as pd\nimport plotly as py\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom plotly.offline import init_notebook_mode\ninit_notebook_mode(connected = True)\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\n\nfrom sklearn.model_selection import StratifiedKFold, KFold, LeaveOneGroupOut\n\nfrom sklearn.ensemble import VotingRegressor\n\nimport optuna\n\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\n\npd.set_option('display.max_columns', None)\n#########################################################\ntrain = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/test.csv')\nss = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv')","4b8abea7":"train.head(3)","9f0ca7b5":"train.info()","4e1cfef1":"for i in [train, test]:\n    i.drop('id', axis = 1, inplace = True)","d00a2e13":"fig = plt.figure(figsize = (15, 60))\nfor i in range(len(train.columns.tolist()[:100])):\n    plt.subplot(20,5,i+1)\n    sns.set_style(\"white\")\n    plt.title(train.columns.tolist()[:100][i], size = 12, fontname = 'monospace')\n    a = sns.kdeplot(train[train.columns.tolist()[:100][i]], color = '#34675c', shade = True, alpha = 0.9, linewidth = 1.5, edgecolor = 'black')\n    plt.ylabel('')\n    plt.xlabel('')\n    plt.xticks(fontname = 'monospace')\n    plt.yticks([])\n    for j in ['right', 'left', 'top']:\n        a.spines[j].set_visible(False)\n        a.spines['bottom'].set_linewidth(1.2)\n        \nfig.tight_layout(h_pad = 3)\n\nplt.show()","dfa3ed37":"matrix = np.triu(train.corr())\nplt.figure(figsize = (15, 12))\nsns.heatmap(train.corr(), annot = False, cmap = 'Greens', mask = matrix, vmin = -0.03, vmax = 0.03, linewidths = 0.1, linecolor = 'white', cbar = True)\nplt.xticks(size = 8, fontname = 'monospace')\nplt.yticks(size = 8, fontname = 'monospace')\nplt.figtext(0.77, 0.8, '''All 100 features and the target variable\nhave a very small\ncorrelation''', fontsize = 20, fontname = 'monospace', ha = 'right', color = '#34675c')\nplt.show()","f51ec918":"plt.figure(figsize = (14, 7))\nsns.set_style(\"white\")\nplt.title('Distribution of loss (target)', size = 25, y = 1.03, fontname = 'monospace', color = '#34675c')\nplt.grid(color = 'gray', linestyle = ':', axis = 'x', alpha = 0.8, zorder = 0,  dashes = (1,7))\na = sns.kdeplot(train['loss'], color = '#34675c', shade = True, alpha = 0.9, linewidth = 1.5, edgecolor = 'black')\nplt.ylabel('')\nplt.xlabel('')\nplt.xticks(fontname = 'monospace')\nplt.yticks([])\nfor j in ['right', 'left', 'top']:\n    a.spines[j].set_visible(False)\n    a.spines['bottom'].set_linewidth(1.2)","b4d162e0":"X = train.drop('loss', axis = 1)\ny = train['loss']\n\nsc = StandardScaler()\nX[X.columns.tolist()] = sc.fit_transform(X[X.columns.tolist()])\ntest[test.columns.tolist()] = sc.fit_transform(test[test.columns.tolist()])\n\nX.head(3)","bb738f98":"# esr = 500\n# Mean RMSE on 2 folds - 7.8466\nparamsCB = {'depth': 5, 'learning_rate': 0.011283180425637522, 'iterations': 19562, 'max_bin': 152, 'min_data_in_leaf': 273, 'l2_leaf_reg': 0.91729332782104, 'subsample': 0.6160764186759223, 'grow_policy': 'Depthwise', 'leaf_estimation_method': 'Newton',\n            'random_seed': 228,\n            'loss_function': 'RMSE',\n            'eval_metric': 'RMSE',\n            'bootstrap_type': 'Bernoulli',\n            'task_type': 'GPU'}\n# Solo result - 7.87348\n\n# esr = 500\n# Mean RMSE on 2 folds - 7.8471\nparamsLGBM = {'reg_alpha': 4.0695962262784615, 'reg_lambda': 9.190653872177396, 'num_leaves': 397, 'min_child_samples': 30, 'max_depth': 6, 'n_estimators': 8989, 'learning_rate': 0.010633230770718524, 'colsample_bytree': 0.4385122330057919, 'cat_smooth': 79, 'cat_l2': 12, 'min_data_per_group': 126,\n              'device_type': 'gpu',\n              'boosting_type': 'gbdt',\n              'random_state': 228,\n              'metric': 'rmse'\n              }\n# Solo result - 7.87401\n\n# esr = 500\n# Mean RMSE on 2 Folds - 7.8466\nparamsXGB = {'max_depth': 10, 'learning_rate': 0.010512283852839102, 'n_estimators': 2432, 'min_child_weight': 185, 'gamma': 0.00010339779073732135, 'alpha': 0.00573215966018785, 'lambda': 0.00013592165632140884, 'colsample_bytree': 0.5825502178882395, 'subsample': 0.6245584427453496,\n              'tree_method': 'gpu_hist',\n              'booster': 'gbtree',\n              'random_state': 228,\n              'use_label_encoder': False,\n              'eval_metric': 'rmse'}\n# Solo result - 7.87065","15b069cb":"cb_model = CatBoostRegressor(**paramsCB)\nlgbm_model = LGBMRegressor(**paramsLGBM)\nxgb_model = XGBRegressor(**paramsXGB)","7a36e36a":"folds = KFold(n_splits = 10, random_state = 228, shuffle = True)\n\npredictions = np.zeros(len(test))\n\nfor fold, (trn_idx, val_idx) in enumerate(folds.split(X)):\n    \n    X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n    y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n\n    model = VotingRegressor(\n            estimators = [\n                ('cb', cb_model),\n                ('lgbm', lgbm_model),\n                ('xgb', xgb_model)\n            ],\n            weights = [0.15, 0.15, 0.7],\n            n_jobs = -1\n        )\n   \n    model.fit(X_train, y_train)\n    \n    predictions += model.predict(test) \/ folds.n_splits \n    \nss['loss'] = predictions","983e80ea":"ss.to_csv('voting.csv', index = False)","1d7a0567":"# Voting time","a5a9c2a2":"# EDA","b68dc0cf":"# Best CB\/XGB\/LGBM parameters with Optuna","6960982c":"# Preprocessing","4d01846a":"# Basic information"}}