{"cell_type":{"74b84433":"code","adadfa89":"code","b6c2c904":"code","d09cdeef":"code","c37f7055":"code","1e1caaae":"code","99791202":"code","4aa04ab1":"code","6b7fe004":"code","96c0bd46":"code","5f64d763":"code","d27c89ed":"code","d351a864":"code","5438eb44":"code","9eb7a265":"code","d58d7504":"code","b19aed76":"code","e16359e4":"code","72a07040":"code","10ed0a90":"code","7bdd84ce":"code","875d9a63":"code","b1fbd747":"code","96ddfa10":"code","b1911650":"code","ce36800f":"code","05d7bfe9":"code","4a9a50dd":"code","aaab821e":"code","a46e4649":"code","c118fc7f":"code","f7df9dbe":"code","87c0d902":"code","3af61f1a":"code","d84a687c":"code","dae8691a":"code","7542d212":"code","460f7ae0":"code","e1cd910c":"code","b70c0fb4":"code","f5966342":"code","198e5089":"markdown","267fce8d":"markdown","c7d29069":"markdown","134f32e4":"markdown","9da9d951":"markdown","234c5f4b":"markdown","3a90222f":"markdown","69f8c63c":"markdown","2592844f":"markdown","772e83b5":"markdown","c61be416":"markdown","34774e26":"markdown","66ad92eb":"markdown","696fe49d":"markdown","436de8f7":"markdown","a939caef":"markdown","d309b359":"markdown","2e48ec8f":"markdown","f3fe6403":"markdown","94853a95":"markdown","06de0173":"markdown","6dfdba2e":"markdown","01053c21":"markdown","2ea47390":"markdown","b1a15c8c":"markdown","1330033c":"markdown","0f3fece7":"markdown","fe33e578":"markdown","743619a1":"markdown","c07afe74":"markdown","8143a07e":"markdown","2f798162":"markdown","d4690749":"markdown","2228b49d":"markdown","8a93e983":"markdown","da7bce8b":"markdown","07d167fb":"markdown"},"source":{"74b84433":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nplt.style.use('fivethirtyeight')\nimport matplotlib.dates as mpldate\nimport plotly.express as px\nfrom scipy.stats import levene, shapiro\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score, mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import set_config\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, LSTM\nfrom fbprophet import Prophet\nimport math\nimport warnings\nwarnings.filterwarnings('ignore')\nprint('Setup Complet!')","adadfa89":"df = pd.read_csv(\"..\/input\/jumia-stock-data-price-updated-all-time\/JMIA.csv\")","b6c2c904":"df.head()","d09cdeef":"df = df.drop(columns = 'Adj Close')","c37f7055":"df.describe()","1e1caaae":"df.isnull().sum()","99791202":"df.info()","4aa04ab1":"print(\"the shape of jumia stock data is: \", df.shape)\nprint(\"the size of jumia stock data is: \", df.size)","6b7fe004":"#checking the median of values:\nprint(\"The median of all numerical values is:\\n\\n\",np.round(df.median(), 2))","96c0bd46":"## Now we will convert the *Date* columns to datetime using to_datetime function\ndf['Date'] = pd.to_datetime(df['Date'])","5f64d763":"## describing Date column;\nprint('Start at : ', df.Date.min())\n\nprint('End at : ', df.Date.max())\n\nprint(\"We have approximately {} \".format(df.Date.max() - df.Date.min()))","d27c89ed":"colors = ['#FF9900','#000000']\nsns.set(palette = colors, font = \"Serif\", style = \"white\", rc = {\n    'axes.facecolor':'whitesmoke', 'figure.facecolor':'whitesmoke'\n})","d351a864":"fig = plt.figure(\n    figsize = (\n        20, \n        10\n    )\n)\nax = sns.lineplot(\n    data = df, \n    x = 'Date', \n    y = 'Open', \n    color = colors[0]\n)\nax = sns.lineplot(\n    data = df, \n    x = 'Date', \n    y = 'Close',\n    color = colors[1]\n);\nfor i in [\n    'left', 'right', 'top', 'bottom'\n]:\n    ax.spines[i].set_visible(False)\n    \nplt.title('Jumia Stock Value Changes Since 2019', size = 20, weight = \"bold\")\nplt.show()","5438eb44":"fig = px.line(df, x='Date', y=\"Close\",title='Jumia Close Prices All Time')\n\n\nfig.add_vline(x ='2020-11-16', line_dash='dot')\n\nfig.update_xaxes(rangeslider_visible=True)\nfig.update_traces(line=dict(color='gold'))\n\nfig.update_layout(margin={'b':0,'l':0,'r':0,},\n                  paper_bgcolor='rgb(248, 248, 255)',\n                  plot_bgcolor='rgb(248, 248, 255)',\n                  title={'font':{\n                             'family':'monospace',\n                             'size':22,\n                             'color': 'grey'\n                         },\n                        'x':0.45,'y':0.9})\n\nfig.show()","9eb7a265":"fig = go.Figure(data=[go.Candlestick(x=df['Date'],\n                                    open=df['Open'], \n                                    high=df['High'],\n                                    low=df['Low'],\n                                    close=df['Close'],\n                                    increasing_line_color = 'black',\n                                    decreasing_line_color = 'orange')\n                                    ])\n\nfig.update_layout(margin={'b':0,'l':0,'r':0,},\n                  paper_bgcolor='rgb(248, 248, 255)',\n                  plot_bgcolor='rgb(248, 248, 255)',\n                  title={'font':{\n                             'family':'monospace',\n                             'size':22,\n                             'color': 'grey'\n                         },\n                         'text': 'Jumia Prices All Time',\n                        'x':0.45,'y':0.9})\nfig.show()","d58d7504":"fig = plt.figure(\n    figsize = (\n        20, \n        10\n    ), \n    tight_layout = True\n)\nplt.suptitle(\n    \"Analyzing Numeric Features\", size = 20, weight = \"bold\"\n)\nax = fig.subplot_mosaic(\n    \"\"\"AB\n    CC\n    DE\"\"\"\n)\nsns.kdeplot(df['High'], ax = ax['A'], color = colors[0], fill = True, linewidth = 2)\nsns.kdeplot(df['Low'], ax = ax['B'], color = colors[1], fill = True, linewidth = 2)\nsns.kdeplot(df['Open'], ax = ax['C'], color = colors[0], fill = True, linewidth = 2)\nsns.kdeplot(df['Close'], ax = ax['D'], color = colors[1], fill = True, linewidth = 2)\nsns.kdeplot(df['Volume'], ax = ax['E'], color = colors[0], fill = True, linewidth = 2)\n\nax['B'].yaxis.set_visible(False)\nax['E'].yaxis.set_visible(False)\nax['A'].yaxis.label.set_alpha(0.5)\nax['C'].yaxis.label.set_alpha(0.5)\nax['A'].yaxis.label.set_alpha(0.5)\nax['C'].yaxis.label.set_alpha(0.5)\nax['D'].yaxis.label.set_alpha(0.5)\n\nfor i in ['left', 'right', 'top', 'bottom']:\n    ax['A'].spines[i].set_visible(False)\n    ax['B'].spines[i].set_visible(False)\n    ax['C'].spines[i].set_visible(False)\n    ax['D'].spines[i].set_visible(False)\n    ax['E'].spines[i].set_visible(False)","b19aed76":"fig = plt.figure(\n    figsize = (\n        20, \n        10\n    ), \n    tight_layout = True\n)\nplt.suptitle(\n    \"Boxplot the Numeric Features\", size = 20, weight = \"bold\"\n)\nax = fig.subplot_mosaic(\n    \"\"\"AB\n    CC\n    DE\"\"\"\n)\nsns.boxplot(df['High'], ax = ax['A'], color = colors[0])\nsns.boxplot(df['Low'], ax = ax['B'], color = colors[1])\nsns.boxplot(df['Open'], ax = ax['C'], color = colors[0])\nsns.boxplot(df['Close'], ax = ax['D'], color = colors[1])\nsns.boxplot(df['Volume'], ax = ax['E'], color = colors[0])\n\nax['B'].yaxis.set_visible(False)\nax['E'].yaxis.set_visible(False)\nax['A'].yaxis.label.set_alpha(0.5)\nax['C'].yaxis.label.set_alpha(0.5)\nax['A'].yaxis.label.set_alpha(0.5)\nax['C'].yaxis.label.set_alpha(0.5)\nax['D'].yaxis.label.set_alpha(0.5)\n\nfor i in ['left', 'right', 'top', 'bottom']:\n    ax['A'].spines[i].set_visible(False)\n    ax['B'].spines[i].set_visible(False)\n    ax['C'].spines[i].set_visible(False)\n    ax['D'].spines[i].set_visible(False)\n    ax['E'].spines[i].set_visible(False)","e16359e4":"sns.pairplot(df)","72a07040":"## check the correlation of features with *Close* features:\ndf.corr()['Close']","10ed0a90":"## Create list of numerical variables;\nnum_vars = [var for var in df.columns if df[var].dtypes != 'O']\nprint(num_vars)","7bdd84ce":"for i in num_vars:\n    _, p_value = shapiro(df[i])\n    if p_value < 0.05:\n        print('Feature {} is Normly distributed'.format(i))\n    else:\n        print('Feature {} is not Normaly distributed'.format(i))\n    print('Normality test p_value of feature  - {} is {}'.format(i, np.round(p_value, 2)))","875d9a63":"fig = plt.figure(figsize = (15, 8))\nsns.heatmap(df.corr(), annot = True, cmap = [colors[0], colors[1]], linecolor = 'white', linewidth = 3)","b1fbd747":"#Let's split this data into two pieces\nX = df[['Volume', 'Open']]\ny = df['Close']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42, shuffle = False)","96ddfa10":"#describe the data ;\nX_train.head()","b1911650":"y.head()","ce36800f":"#Now we we'll normalinzing the data, using standardscaler tool;\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","05d7bfe9":"## Let's create simple linear regression model \nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\nset_config(display = 'diagram')\npred = model.predict(X_test)\nscore = np.round(model.score(X_test, y_test), 2) * 100\nr2_sc = np.round(r2_score(y_test, pred), 2) * 100\nmse = np.round(mean_squared_error(y_test, pred), 2)\nmae = np.round(mean_absolute_error(y_test, pred), 2)","4a9a50dd":"#showing & display;\nprint('The score for validation data is : {}%'.format(score))\nprint('The Coefficient of determination is : {}%'.format(r2_sc))\nprint('Checking the mean squared error between actual values and predicted values is : {}'.format(mae))\nprint('The mean absolute error between actual values and predicted values is: {}'.format(mse))\nprint('-' * 50)\n\nprint(\"display the first rows of prediction values: \\n\", pred[:20])","aaab821e":"fig = plt.figure(figsize = (15, 9))\n#let's now compare our \npred_df = pd.Series(pred, index = y_test.index)\n#plot acutal values\nplt.plot(y_test)\nplt.plot(pred_df)\nplt.legend(['actual value', 'predected value'])\nplt.title('Comparison between test & predicted values', size = 20, weight = 'bold')\nplt.text(x = 575, y = 60, s = 'Accuracy Score: {}%'.format(score))\nplt.text(x = 575, y = 58, s = 'R2 Score: {}%'.format(r2_sc))\nplt.text(x = 575, y = 56, s = 'Mean Squared Error: {}'.format(mse))\nplt.text(x = 575, y = 54, s = \"Mean Absoulute Error: {}\".format(mae))","a46e4649":"## begenning with create data;\nX = df[['High', 'Open']]\ny = df['Close']\ntraining_set = X[:500].values\ntest_set = X[500:].values","c118fc7f":"## Features Scaling\nf_scale = MinMaxScaler(feature_range = (0, 1))\ntraining_set_scaled = f_scale.fit_transform(training_set)\ntest_set_scaled = f_scale.transform(test_set)\n\nX_train = []\ny_train = []\nfor i in range(100, len(training_set)):\n    X_train.append(training_set_scaled[i - 100:i, 0])\n    y_train.append(training_set_scaled[i, 0])\n\nX_train, y_train = np.array(X_train), np.array(y_train)\nX_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n\nX_test = []\ny_test = []\nfor i in range(100, len(test_set)):\n    X_test.append(test_set_scaled[i - 100:i, 0])\n    y_test.append(test_set_scaled[i, 0])\n    \nX_test, y_test = np.array(X_test), np.array(y_test)\nX_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))","f7df9dbe":"model = Sequential()\n## first layer\nmodel.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\nmodel.add(Dropout(0.2))\n\n## second layer\nmodel.add(LSTM(units = 50, return_sequences = True))\nmodel.add(Dropout(0.2))\n\n## third layer\nmodel.add(LSTM(units = 50, return_sequences = True))\nmodel.add(Dropout(0.2))\n\n## fourth layer\nmodel.add(LSTM(units = 50))\nmodel.add(Dropout(0.2))\n## output layer\nmodel.add(Dense(units = 1))\n\n## compile RNN\nmodel.compile(optimizer = 'adam', loss = 'mean_squared_error')\n\n## fitting the RNN to the training set\nmodel.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 100, batch_size = 32)","87c0d902":"loss = pd.DataFrame(model.history.history)\nfig = plt.figure(figsize = (15, 9))\nplt.title('Validation and training loss', size = 20, weight = 'bold')\nplt.plot(loss)","3af61f1a":"## predict the test values\npred = model.predict(X_test)\ntest_df = pd.DataFrame(columns = ['test', 'pred'])\ntest_df['test'] = y_test\ntest_df['pred'] = pred.flatten()\ntest_df","d84a687c":"## plotting the figure\nfig = plt.figure(figsize = (17, 9))\nplt.title(\"Compare Actual value with predicted values\", size = 20, weight = 'bold')\nplt.plot(test_df)\nplt.legend(['Acutal value', 'Predicted value'])\nr2_s = np.round(r2_score(y_test, pred), 2) * 100\nmae = np.round(mean_absolute_error(y_test, pred), 2)\nmse = np.round(mean_absolute_error(y_test, pred), 2)\nplt.text(x = 30, y = 0.29, s = 'R2 Score: {}%'.format(r2_s))\nplt.text(x = 30, y = 0.297, s = 'Mean Absolute Error: {}'.format(mae))\nplt.text(x = 30, y = 0.28, s = 'Mean Squared Error: {}'.format(mse))\nplt.show()","dae8691a":"from fbprophet import Prophet\ndf_fb = df[['Date', 'Close']]\ndf_fb.columns = ['ds', 'y']\n\n#splitting the data;\ns_df = df_fb.index.max() - 200 # split data\ntrain = df_fb.loc[df_fb.index <= s_df].copy() # training data\ntest = df_fb.loc[df_fb.index > s_df].copy() # testing data\ntrain.set_index('ds', inplace = True)\ntest.set_index('ds', inplace = True)\ntest.reset_index(inplace = True)\ntrain.reset_index(inplace = True)\n\n\nmodel = Prophet()\nmodel.fit(train)\npred = model.predict(test)\n","7542d212":"pred","460f7ae0":"from fbprophet import Prophet\ndf_p = df[['Date','Close']]\ndf_p.columns=['ds','y']\n\nsplit_data = df_p.index.max()-150\ntrain = df_p.loc[df_p.index<=split_data].copy()\ntest=df_p.loc[df_p.index>split_data].copy()\ntrain.set_index('ds',inplace=True)\ntest.set_index('ds',inplace=True)\ntrain.reset_index(inplace=True)\ntest.reset_index(inplace=True)\n\n#Model creation\nmodel=Prophet()\nmodel.fit(train)\n\n#model prediction\npred=model.predict(test)","e1cd910c":"test_pred = pd.DataFrame(columns = ['ds', 'test', 'predict', 'pred_lower', 'pred_higher'], \n                        index = test.index)\ntest_pred['test'] = test['y']\ntest_pred['ds'] = test['ds']\ntest_pred['predict'] = pred['yhat']\ntest_pred['pred_lower'] = pred['yhat_lower']\ntest_pred['pred_higher'] = pred['yhat_upper']","b70c0fb4":"## visualize the predicted and actual values;\nfig = plt.figure(figsize = (15, 9))\nplt.title('Predicted & Acutal values', weight = 'bold', size = 20)\nsns.lineplot(data = test_pred, x = 'ds', y = 'test')\nsns.lineplot(data = test_pred, x = 'ds', y = 'predict')\nr2_sc = np.round(r2_score(test_pred['test'], test_pred['predict']), 2)\nmse = np.round(mean_squared_error(test_pred['test'], test_pred['predict']), 2)\nmae = np.round(mean_absolute_error(test_pred['test'], test_pred['predict']), 2)\nplt.text(x = mpldate.datestr2num('2021-09'), y = 40, s = 'R2 Score: {}'.format(r2_sc))\nplt.text(x = mpldate.datestr2num('2021-09'), y = 38, s = 'Mean Squared Error: {}'.format(mse))\nplt.text(x = mpldate.datestr2num('2021-09'), y = 36, s = 'Mean Absolute Error: {}'.format(mae))\nplt.legend(['Test', 'Predicted'])\nplt.show()","f5966342":"fig = plt.figure(figsize = (16, 9))\nplt.title('Visualization the test and predicted values', weight = 'bold', size = 20)\nsns.lineplot(data = train, x = 'ds', y = 'y')\nsns.lineplot(data = test_pred, x = 'ds', y = 'predict')\nsns.lineplot(data = test_pred, x = 'ds', y = 'test', ls = '--', color = 'black', alpha = 0.5)\n\nr2_sc = np.round(r2_score(test_pred['test'], test_pred['predict']), 2)\nmse = np.round(mean_squared_error(test_pred['test'], test_pred['predict']), 2)\nmae = np.round(mean_absolute_error(test_pred['test'], test_pred['predict']), 2)\nplt.text(x = mpldate.datestr2num('2020-01'), y = 60, s = 'R2 Score: {}'.format(r2_sc))\nplt.text(x = mpldate.datestr2num('2020-01'), y = 58, s = 'Mean Squared Error: {}'.format(mse))\nplt.text(x = mpldate.datestr2num('2020-01'), y = 56, s = 'Mean Absolute Error: {}'.format(mae))\nplt.show()","198e5089":"#### *Checking for missing value*","267fce8d":"## **Now after we normalize the data, and fit the data let's create some models to predict the stock price prediction**","c7d29069":"### **Figure out the jumia's stock price, value since 2019**","134f32e4":"# <center style=\"font-family:Arial\">1- Introduction<\/center>","9da9d951":"#### *Loading the jumia dataset*","234c5f4b":"### Assalamu Alaikum \ud83d\ude00!\n\n**I'm Mohammed and inshallah through this notebook we will be looking at data from the stock market, particularly some technology stocks. We will learn how to use pandas to get stock information, visualize different aspects of it, and finally we will look at a few ways of analyzing the risk of a stock, based on its previous performance history. We will also be predicting future stock prices through FacebookProphet and Neural Network Algorithms**","3a90222f":"### **Analysing the numerical features of the jumia data using (KDE-plot)**","69f8c63c":"# <center>4- Exploratory Data Analysis<\/center>","2592844f":"*Plot and visualize the figure for get a good undrstood of the model*","772e83b5":"### **Notice that we have some outliers values in the boxplot figure above particularly in *Volume* & *Open* columns**","c61be416":"### So as shown in the above figure we saw that the mean absolute error is 1164, which is that need more data in order to make predictions in a way that brings us closer to the testing data\n### that's all","34774e26":"### **Analysing the numerical features of the jumia data using Box-plot**","66ad92eb":"##  *Linear Regression*","696fe49d":"**As shown above there is no null values in dataset of jumia**","436de8f7":"# <center>2- Load The Data & Libraries<center>","a939caef":"# <center>9. Spliting The Data Into Test and Train Datasets<\/center>","d309b359":"#### *Import All Required Libraries*","2e48ec8f":"# <center style=\"font-family:Arial\"> Jumia Stock Price \ud83d\udcca Prediction Using FacebookProphet and Neural Network and more.... <\/center>\n\n\n<p style=\"text-align:center;\"><img src=\"data:image\/png;base64,iVBORw0KGgoAAAANSUhEUgAAAX0AAACECAMAAABLTQsGAAABIFBMVEX\/\/\/8MCwsAAABoaGf5mygHBgbw8PDk5OTq6uq9vb0aGRmmpqb7+\/tbW1pfX19WVlaDgoJPT09JSEiurq4gHx+ZmJg3NzdiYmGJiYnQ0NCSkpJRUVC3trYuLi5BQEBGRkX1gC5zcnLY2NgjIyP2jCs7Ozt2dnbzeS\/1gi73kSr2iCzKysr4lSrd3d0UExOOjo780qv5mBr927T5ni7\/+vP96+H5lAD0iFL83sD7y536vYX6tXn+8+T4q2b6qUn70rb4mkz2gxH4rHn4mDL7uHD6r1j2jkT5pVX6x6b0dQb82sn1hD72ixH97+f3q4Pzch75wqn3nmn5uJH1mXH\/6dL0jl70hU33pXn4pGT7uof7xJX4lDv6tWj3mVj6oz36rU6FvHrqAAAUxklEQVR4nO2dfZ+bNrbHbTFge8CPGAN+rO3aSdfxOE5m0kmaJu026abbtN3NTW\/vTdPZ9\/8uVhIgHUCAIPbMdMrvj3wmthDiizg6OjrIlUqpUqVKlSpVqlSpUsV1fvn02VdfffXsw6PnN92Uv5rOL7\/+\/IsvvnjwYL\/fn5y8eFjegOvT+ctvvvXgP3hwQvTk8dOSfy5txibWmGiR78iLv3\/7t88\/J\/i\/e\/XixNOT15fHaebdlD4dDFZY0+l0NtppOY58+f39v\/n0\/3H+bO\/j3z\/+cLS23jlp3cmA4Z8O1vL43\/xwP6D\/9lHl+XcngZ58PGJ775ZqowmHP5sNGrIHvvzsM0b\/O\/z\/V3uGf\/\/s\/Igtvksy2n7f9+hP15LH\/fNHTv\/tQ\/zB8ycnXE+P2eS7pA2hj\/EPVoT+bCV31E9f3uP0X9Cu\/ox3\/pPH5dArKcMl2lijFaE\/2Eod9PMvgP5L+tHFY05\/\/6K0PfnU6NK+b8qUvfjlHqP\/xdc\/0c\/OYed\/UtqefDKGA0x\/2pEp+xukH4B+fwXwX+U5M1PaRzlrCL7I0Q5xzbKnyldNTI0Z6fx2Pbuuix\/v+fR\/\/\/6br5iRefri6urxCY05nOwfSbes0QlkBW00dPaZjBO2cFgN0GM2XN1xxotPuAGu6TimCyvQ1qxl8s75YrzrmBntWDQJ\/a7E5f7r3r0f\/\/j3z+\/evHwftu\/n7y8ffnj26vXV4\/0r6bbtUKBB0ECtyz6TeRbH1aD0FAxbdeeMfLTMgSkszTolFfQ7gFuNNQzVJKsxzIFEO4w5oT+bZ8cb8Jj72\/ufEr8+f\/70ZP9aOuAzRFVPqMfot9lnMvQbfTWogdM3HEQrQagr25KwjE5QAWhDLWhYVZq+HlQzSi3mrDD83qy586I+gRohYcN0\/j+\/3PvxTUpF76+w4Zd2Ojn90SHpu0gN6rBlmxKSFVSgVrk9yE9\/zNuROplqUPq93ox6\/viPbrc7Go3aWE2sFtEcX97Fr9js\/\/AusZ5LOvGSNvxHou8wTmpVypGLyD3joHkjctPX+rwd\/TSrXvfpE+rdEHUbS6Hq4L5\/8eU9Muq+S\/DpL6njv38oe5mcfvuQ9FkV+ONVzugt0QwcrzDLn5s+7wSknjTTTzz+dPo2iYJe\/C+l\/9k74Sh+eXVSlH7rkPRX0pct1A4e3mSOYF76bh\/Uo6JxStHOKpP+ENC\/\/\/+COh4F092bpj8Al11FlmxrWJUHoa8psBVVtEw5qDGA9EfA3ofpf+nT\/+HvMePz6MmtpK+ifLanPgrdu8L0zapahUq7nLrf93szQr7bDeg3Wx76gP6v94LZ1oeI8bnkwZ4Co65yNPp4TMlle5zwwUXpa9NQPem9QLOnlH6zUcPa7nqUfrNpbcn\/azrG7+B2\/IQ9Tp9+tPM\/ZcGGIh7n\/Hj0q8iRbQ+pEIW6bGH6nQh84v0mTnkNa0U9zkbw3xGFvwu+N21lTc75M6MfdTsfsb4vP9vaXQt9tZo24oVVP4vcuYL0tzH4VfUs2fttePSDc21bpPO3WbPduaKQJ+dfzPJE51zvrwKzLx9p6HD6wUdHoI\/dTokIFpWxjh5ajL5hx+njSU1iMxYjSt8NTrWm9HX29VyxyXPBo2xR8\/L8dUBfPsrWiZM+Bn08qEs2aBwZKovS50OuisDkQU8qX59PCf3ge82h9JnlIfRpHPJXP8L8fcy8fAwMv\/zyynXRl3U73WXsvhWiv2VDrlp1uA+lJh9oUfosHqFTw89ifJi+opCGBKsr3\/hfXDwNgp3+Ess+x+rK9dGfuCmVBDJa8QML0efzNdTUwDieHHYaU5fTDq5hTJ2edXAeQr9Fh+TfvJXF\/6MfXzw9ebt\/9Z7+7Tk9uVYWOX3mlhyHPr5uCbfTEhxXhP5C5XYHM2uCzp8U7nHbNLoWfL1pEfpK0GVo36cPBrb8hD6Z7D7\/8I+3Dx482F89I\/wv9zmtfqWyvjb6MrbHPT0Q\/R4vadMD4aMgPkRTZtDwLxTS+VvBzaD0Wxvy58vPMP1vH1bOn\/4e5HHuH796XjmnC1vPMi8S6Oj0+Riqok1GVfW26KYVoK\/zgmda+IPkTtAhhr+39s+2JfRbzOkhHqeieGs0bwj9y5e\/kzTaIIt2v\/\/wnHqbuTIaOP1h8NFB6asTcN2DdLfTGIKyn0K\/xme5vpNT57YHJWWOmCsa5\/GnBGMaaWj6y12G7kWZTToKv\/vh\/v0\/SBotyGHGBv\/xyf5jvnQSTp91iYPSRx0w38+oDwb1V+2z4vSHwM74B49P1axW1AaEfq9tudvtwvQMT6u5Hm9rNdfy4Cv+zXjDMgk5fdrzcyaRz49N36nxfqyitJUW4xQU1JmtyE+f30XEl1TAJC4p3DP1Ypw9EuMc8TWtYHXFw++d+J9\/xOnvr6Rjm4GUo\/d9bHN5t5ukRDshH5t7P7npG3z0ABeg8U7Al7AjDZgKIsx8bcsLdvrjwvmHb8L0seOT\/+0JTp\/NAg9NH4bZU6a84zN2k1S0\/QT6Jn+EVDDQ6OBj8SNIDH\/KyqKP3\/FPffHy67dv3xL8+\/3+yX+evpdgFdU10A\/NXxM9jm0PFNIrxekbfJwPnUwDA29XeHhNhj72+oPLPL+4\/PDq4+vXH589el4sefM66IPeiB1QsdtpzAF8Em4tTJ8bML5UTQU6AdqJbA\/x+CXoK03zU5P0ArGZPR8QD08fzDUxEqHbCR1yugxflP6GdX3Uj9xoHn1Qz0RhD2M49emT4bcd0MeT3hZHTz\/auYfhz0mzUPYR6C+g7RH1OzAZVb2nsCB9MMigTuREdT4HRE3RwWOPflcxNxvqchLUrU5j0+j4\/d\/uNNyNg5+G4SZ6FVqBG3I99LHtAUOqINJiw4eDflKQPkifWsVmVQ1wFlG4xx1R+nQZBd9Hz+NcE6r1oe0NuaQthkMWetcW8N9q404Rc3RN9OGaCUKxSAuc5HqhgYL0NRDQ6dRrEdXBHHglCPfU5tTf94P67ojQb3u3aeP1ff8\/1BI1\/RtYszp2025Jv\/YFxEmzo49Bv7KFEYd5pJu48Et\/\/ClGH6zlomlcEx51Ejlfxm5G6PsWS2sC+jTKpsy94cKjr\/jtasBZcD51r4k+NgnswqP+tjGCd8bvk4Xou32wMIbigt8OBLh0z\/J416GtCf2md5dC9E1qhoJXTHU7yDPMLeZlI+YFHId+Bc65wistoQ4bMClCP5I+lS60jhtqt03TZz1fyRi2id33LiBEnw4CNL+HnHRH\/5c3Y4xqdm306zDcBoPsGzgis6eiCH09nIuShT8+89Bsavj9qY9J6Sv07xD9NR2B\/WF2Qf+nyCdtAA2ujT4MM8IEnxqc5Crs4wL066scXZ\/YnngVa2p6\/FctNpS+9z4RpK\/Rv4NhduM5o0XMfiVY\/VBVdvix6FfAdFZlN9sAGbMIceNZgH48fSoDfzzBQZ8Sy9P0andb1OGnLYX0t57\/412B4Zn9qCMhJS14VkH08Wj0NdA3WYLPOGEmkJ\/+Iid80TrLdkXozzybtJ1Th5\/aFEh\/A8M9WoeaoV20Jhmx+Qfqses5Gv1QjqA\/E63BWTCcnOamb4iWJTPwR2fDeBwk9LueXaT07RYdT72VRYXeFhPSX9Cu3ypk9lnCKkiyz0l\/LE8f2gY\/uRB6QvCtu\/z0oxnLMvT7sXAPMfyj0Yg+hOMmpU8xe8QVHd+uekfh46zX9ZWm7HtkULy\/8GVdEIoFg2Cy2FXDuG0C\/VoXwD6th7yUyNsNeelv+esuqsDTF7v9qBnt\/OaU0m\/uGpthEONcm5tgZVEZbsbr4G9rg\/\/jB4AkQMXJsRUNsObHvWY0yU7B4TEEmCeeQL+ygYamV3FB5glPJKXKSd\/gaedoYJmp0vk6Tmypczv1IsyjbrfNIsz434C4zf9U+OeFvH2ewYEm3PkFMRnkZA7lJptewvzsJPrhd4IcGNSP5NnmpO+CDj2sZAjcqWWkf9Xt7Ph+XIWCPADzCLSCJ5Spp1lvO1tgyQJ03kT6Buj8KjoDf0fGrZz0Z8lA46rzN5NQxFnRnF4B+nZCkkqKNBv0l7BrAqCoHVfTRHswGIa2tQYwPxg8fon0sV8oHBxjT1k++nBxRuINVRCHnkRmvI0C9IOgg7SMhTmAkOHgv4B5gGQIW9nrzjAsp6N0+wjBgiqY7iXTF6VqhhzeaDEZ+jU+k8CjSbbgGsw8TE6zMP589O11romuttE7sNdiZw9+HX2BIdGHCAOEezul0K\/H05RFMZc89MGQm5wlG1KDGcDYAZppz9j76l2WXJIsxZK2O3UM3p5NIugiLQDJHfIKGe4U+uH3Qf1S81ipPPTBe7nRrpwk0PljO4Jp9XySCjKYk1NRoJs0QIlUMBdZhwz4LVhHGv247UGzOLIc9DWQsSz1lkAFhFjiA+9xhGc24i4dzzCrT\/LiD09U0+mD\/G6vjGgLhRz0QcKK\/MuRINezn99jyS89gaiqxmN9m9gLPBnwl2HDnU7fjdi9eLglD30NOL1V6RUmEI6WCqh8qhLoq8KTb1ZInj9Cy0j3SacfXgZBU5GplqcPl8ZyzDmB1xl79rSFu5C4j9oWF5MMLYvpo6p44xpt3Zfjjz2iVSxFJ4O+Jgz1hyRNHwziaJojyg7aEH6fxdgoMxJmUMbp+1m56yktZko9b0L6aJL4DmXDWUW9ShF61NPj7m4G\/coCJFuKBz1Z+sB1T9+FJCZgXeE6i2FNe+0mXavdpUUu9S4uRpIbWh2ZAGecPmbXTpkoGLXGepkRLhzprujcA1YgwaZuPL8LtyBh92mL1QDpM7GTmqAxObeimYOZCz\/SWpEsQi95SjQg+dJX5AFpecUk8Efo43P2JXbhM1x92CHxvDZUq6Wsd7qbeLW95cRTP8kJWXSp\/zuxEi5QX\/pVLBVGvz4Lzt8LPjMmXKucsS7tlB3aZ52ksZoy+oqdaBjcAS3m72CSdBHwehAkjybNXdZbbMVV2wZKvEFGY+g4eqLN1FgNqR3LqPFZT+5NmOC0KvhoPgD0ebZ4VOvBjNNXlGyf1aNPwwYTe9jYFEn\/ufPaTmDfD1IHY6o1Q\/QlFhZ1z8St1uNavUjC7V9Cbj9E304ImG56K0hfYnWlsR6aB8o7v7vaLKXoN6Yh+kqe\/YdKJcotRN8u6R9ECznL43bzWp5SEqpNpUZdzQ6PukXWdUvFZAxDHmfisrYF\/X1lXfqPh9G2Dei3EmdEWhfSL5TJlinD25JbZPw0s8j+ygeXYR7s9U1fDRpCoPSbiVNdbPmn04B+S2Kqm1OG1ulWg\/c\/4kP6GH+6vPnnTSctTGFURG6z222T1fT5OI3qQqHPiG0rBz4\/Vq1D1h+DHMH4+5VrlDekeAzRF9xlMu5ySTN3nY4zNDNiZ9qYFhNEeD9Vi15o\/SNOX0G5Ntk8klyyQIWWB79+Q6trErcUF8sfXJIQjc\/zAGw8BH876G+npHXLOzaBp9mWaKnoiWP+7aBf0SfLZfL60J9UJNEbTdMC0LeEfsXdbA5vd29WdEODdFeCruc5jagEJTfwe5EXUQ\/VIFpMTSvRaIQ3Isk6W6g5jdt458i74+pZ6pBP6Z+dRrVareETs+3MVn34\/dlgpYRwWa3VJFTD2WTQ0jXZEu707KwfNLTe6a6W4bMNFDgdqDm9cHNOl6uuU+S1k2Nqs1Sr6mnqaE7pqzGRQXAabN+xUGjaXKwACnqv5i3eCkrsMkt4acP4a9XP19\/OE0paWc2R+Y25a5QsfbHQmU6vdyPaEtVb13Ro3ZqSmDLhL5DDJHdhCZKR5iXxuNHfOuBn89bGEwuAF+RvhRbU8qSuVRL6wtxmip9cjfeeRLyAylI\/aOaxoBJagiLLLMHoa11xUVqS3p5JYoG8v41xZNEXa9N\/Hkzo8ywsZ0Iuh+59RxNyUH9ugYGgrg9XZAJN92ehWyap1d4ODu\/a2OqdIX+z8AVJlELVbnIJRl8PzgZSszTTmpKSCPECigU9g42l0Fysm5+1Q83p1XUWyQNSksepzemzXPFSZdEo\/kzvSHo62RJTrxL7JojVmaSbkhmerqaWGAL67YSz6UvVS5AnDyuaxdPmXLJBinirqpuS99o3moys0AsrFvetE\/39OqWuVYwBsV6CKQPd\/4683rNLfMAs1Uvpd5JL+N8w+rgLi39Nbu2VMOgURlSgge8PmohOcmNae\/Ywqsmg5xNPnm2RTb5w19YwffELbJY\/mXASJxVkPw1ivTJK2IA+bg0aiBJC\/RKa3yniWkxJwFB0khuTMTwV+SP0DtD+nEHf\/XT6TZn7I0+\/+yeiT\/JPBrGu792BU\/L8Hp9+dt+\/w\/Qr2mKj21CKn9KM+kZJ\/zpkhKRpOnWayZBZ0r8B0Y2kyHBX0r8JUXTdkv7NiOwigHpaSf9GVNK\/SY2vhX7\/8P4+HbBEkZM\/E31pu08jDX1B6NboZNI3VZVHGlJLSNP3AkGinXv+RPTpzxdK+Tz0p9VF78zRHyEgBRLZ0k2bSBQnu4Q8fRLvUU8Fr+htbx197NoLVK8Nq0E8Nps+fYkZrdxaqIr6nMzYUF\/z2Vqxk9QtlR65kCkhT3\/hhfoRUuZh2djM3S76jmhTlNbAX4uYyMx1K7UgUAfqak28cAX9BQTKdtqKnGTln6SpZZYw8tDHlaksVhVfgDkqznzaJrylW6WrQ6ckzJZNn6y5xi\/Xq4L+yDBduBKfxN8yKrtEDvqGE92ahetW0U\/cI4Nce4+OpIS+KqTfCuhX9DMUv2BShbeM7aScxFtpzS7B2OJ7It4dZheUIPsqC\/vUbev72krc99FgZvsLFOQFyKVwgwWSftv3\/qw5rUn0MRr01v5iVULPRoNp8JJydokG2Z2MdAICVvgTsrREsKpimPo8qtats\/sNXSjTZSvtmqnr4tdlNFyQLWkZbiNaBfO5qVVXzNhZ3IV8CQNXT5\/AGv5YmAbASiRpgZ2zoLv8hZTszcuXOIDI4nF4X7q\/hG6SPo+aW2Qj4\/T8jTupm6RvtrwFox4ddNHprUqnuhbdIP26Db1XFQ3v2BsAEnK4L5igzrHo18CPwCIk3Bfurovu2pH6yGeXKChNYd7rZKVIbiJ5t6Tpw2F6Bl92iaLa8ASx25ZAXqpUqVKlSpUqVapUqVKlMvVfBbwyeXxZ7u0AAAAASUVORK5CYII=\" alt=\"Logo\"><\/p>","f3fe6403":"# <center>10. Noramalizing The Data<\/center>","94853a95":"* *From the correlation above we notice that we saw **Low**, **High** and **Open** Features are Highly Correlated with **Close** Feature.*\n* *We can use either one of those Features for prediction to avoid multicollinearity*\n","06de0173":"-THE data is about 2 years-","6dfdba2e":"#### **Now we we'll check the correlation between the Features**","01053c21":"**Notice that the median of all numerical values are lesser than the mean, So that's similar to be right skewed**","2ea47390":"# <center>3- Data Exploration<center>","b1a15c8c":"- *Date: is an object data type*\n- *Volume: is an integer data type*\n- *The rest is float data type*","1330033c":"## *FacebookProphet*","0f3fece7":"# <center>5- Univariated Analysis<center>","fe33e578":"#### *Describing the dataset*","743619a1":"# <center>6- Bivariated & Multivariated Analysis<\/center>","c07afe74":"# <center>Assalamualaikum<center>","8143a07e":"* ### We need to predict the closing price of the stock.\n* ### Lets us consider 'Close' feature as the Target variable. \n","2f798162":"# <center>7. Normality Hypothesis Test<\/center>","d4690749":"##  *LSTM (Long short-term memory)*","2228b49d":"#### *Cheking dataypes*","8a93e983":"#### *Show the figure*","da7bce8b":"# <center>11. Modeling<\/center>","07d167fb":"# <center>8. Correlation<\/center>"}}