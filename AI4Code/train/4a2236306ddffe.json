{"cell_type":{"f3f2e06c":"code","e425d352":"code","5ecff249":"code","07264a6e":"code","179b878b":"code","16fd4915":"code","373744d0":"code","7c89df95":"code","d7f8211a":"code","612fd9f6":"code","433aeabb":"code","abd8ce4a":"code","e2ecd244":"code","6ca9d1bb":"code","7e521209":"code","cb9f4699":"code","30f2cde8":"code","e322e0b3":"code","713f4d7a":"code","66dc2805":"code","e08dfde5":"code","b0cc6be5":"code","fecb12d8":"code","cdaf5f8d":"code","bf7f786f":"markdown","6c6629be":"markdown","f3cb83e8":"markdown","89b66409":"markdown","41a36e7d":"markdown"},"source":{"f3f2e06c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e425d352":"df=pd.read_csv('..\/input\/fake-news\/train.csv')\n","5ecff249":"df.head()","07264a6e":"X=df.drop('label',axis=1)","179b878b":"X.head()","16fd4915":"y=df['label']","373744d0":"df=df.dropna()","7c89df95":"df.head(10)","d7f8211a":"message=df.copy()","612fd9f6":"message=message.reset_index()","433aeabb":"message.head(10)","abd8ce4a":"from nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nimport re","e2ecd244":"len(message)","6ca9d1bb":"corpus=[]\nfor i in range(0,len(message)):\n    text=re.sub('[^a-zA-Z]',' ', message['title'][i])\n    text=text.lower()\n    text=text.split()\n    text=[PorterStemmer().stem(word) for word in text if not word in stopwords.words('english')]\n    text=' '.join(text)\n    corpus.append(text)\n    ","7e521209":"y=message['label']","cb9f4699":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import one_hot","30f2cde8":"vocab_size=5000","e322e0b3":"\nonehot_representation=[one_hot(words,vocab_size) for words in corpus]\n","713f4d7a":"from tensorflow.keras.preprocessing.sequence import pad_sequences","66dc2805":"sent_length=20\nembedded_docs=pad_sequences(onehot_representation,padding='pre',maxlen=sent_length)","e08dfde5":"embedding_vector_features=40\nmodel=tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Embedding(vocab_size,embedding_vector_features,input_length=sent_length))\nmodel.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100)))\nmodel.add(tf.keras.layers.Dropout(0.2))\nmodel.add(tf.keras.layers.Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])\nprint(model.summary())","b0cc6be5":"X_final=np.array(embedded_docs)\ny_final=np.array(y)","fecb12d8":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X_final,y_final,test_size=0.33,random_state=42)","cdaf5f8d":"model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=20,batch_size=64,verbose=1)","bf7f786f":"### Loading the dataset","6c6629be":"# Creating model","f3cb83e8":"### Performing the text preprocessing","89b66409":"# Model Training","41a36e7d":"# Text Preprocessing and Embedding Representation"}}