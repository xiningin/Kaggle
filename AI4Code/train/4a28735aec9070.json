{"cell_type":{"22851c3b":"code","47a5d4d6":"code","797f5e77":"code","e9034534":"code","31b6accc":"code","42c0051f":"code","1e018914":"code","529336ff":"code","0d6ab259":"code","d18693a4":"code","8a1568dd":"code","f0151bb6":"code","1de6ff15":"code","8264cfff":"code","760376d1":"code","435526d1":"code","9f622220":"code","b246a68e":"code","4bf3ed46":"code","bcd31d21":"code","c13d2bca":"code","a8b9fc8c":"code","0e5dbd98":"code","9a90dfd3":"code","0145c6f3":"code","2f1e1669":"markdown","3d0ebcd2":"markdown","7e351bd0":"markdown","1ad274e3":"markdown","b45d2c5f":"markdown","562eb91e":"markdown","fb6c6d7f":"markdown","d84f8f91":"markdown","300d3ad5":"markdown","1ca5c334":"markdown"},"source":{"22851c3b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","47a5d4d6":"import keras\n\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n","797f5e77":"# Reading train and test CSV data \ntrain = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")","e9034534":"# checking shape of the data\ntrain.shape","31b6accc":"# Viewing\ntrain.sample(5, random_state=0)","42c0051f":"# Understanding total count of labels and their respective counts\nY_train = train['label']\n\n# Droping 'label' column from train\nX_train = train.drop(labels=[\"label\"], axis=1) # {0 or \u2018index\u2019, 1 or \u2018columns\u2019}\n\n# Deleting train DataFrame\ndel train\n\nsns.countplot(Y_train)\nY_train.value_counts()","1e018914":"# Check the train data\nprint(np.isnan(X_train).sum().sum())","529336ff":"X_train.isnull().any().describe()","0d6ab259":"# Check the train data\ntest.isnull().any().describe()","d18693a4":"# Normalize the data\nX_train = X_train \/ 255.0\ntest = test \/ 255.0","8a1568dd":"# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","f0151bb6":"fig1, ax1 = plt.subplots(1,10, figsize=(10,10))\nfor i in range(10):\n    # reshaping the images into 28*28 shape\n    ax1[i].imshow(X_train[i].reshape((28,28)))\n    ax1[i].axis('off')\n    ax1[i].set_title(Y_train[i]) ","1de6ff15":"Y_train = to_categorical(Y_train, num_classes=10)","8264cfff":"# Split the train and the validation set for the fitting\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.2, random_state=555)","760376d1":"# Printing shape of train and validation data\nprint(\"X_train Shape: \",X_train.shape)\nprint(\"X_val Shape: \",X_val.shape)\nprint(\"Y_train Shape: \",Y_train.shape)\nprint(\"Y_val Shape: \",Y_val.shape)","435526d1":"# Checking random image\ng = plt.imshow(X_train[35][:,:,0])","9f622220":"# The sequential API allows you to create models layer-by-layer for most problems. \n# It is limited in that it does not allow you to create models that share layers or have multiple inputs or outputs.\n\nmodel = Sequential() ","b246a68e":"# The first convolutional (Conv2D) layer is set as learnable filters.\n# set 32 filter and transform a part of the image using kernel filter.\n# The kernel filter matrix is applied on the whole image\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\n\n# The CNN can isolate features that are useful everywhere from these transformed\n# images(feature maps)\n\n# The Second important layer in CNN is the pooling(MaxPool2D) layer.\n# This layer simply acts as downsampling filter. \nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2))) # we have to choose the area size-\n# -pooled each time(pool_size) more the pooling dimension is high, more the\n# downsampling is important\n\n# Dropout is a regularization technique for neural network model.\n# A simple way to prevent neural network from overfitting\nmodel.add(Dropout(0.25))\n\n# Combining convolutional and pooling layers, CNN are able to combine local\n# features and learn more global features of the image\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\n# 'relu' is the rectifier(activation function = max(0,x)) is used to add \n# non-linearity to the network\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n# The Flatten layer is used to convert the final feature maps into \n# a one single 1D Vector\nmodel.add(Flatten())\n\n# Two Fully-connected(Dense =  10, activation = softmax) layers\n# the net outputs distribution of probability of each class\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))\n\n# In summary() we can understand the architechture we build and \n# we can understand about the totol number of parameters \nmodel.summary()\n\n# total_params = (filter_height * filter_width * input_image_channels + 1) * number_of_filters","4bf3ed46":"# Define the optimizer\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n\n# Compile the model\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","bcd31d21":"# Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","c13d2bca":"epochs = 40 \nbatch_size = 86","a8b9fc8c":"# With data augmentation to prevent overfitting\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X_train)","0e5dbd98":"# Fit the model\nhistory = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val),\n                              verbose = 2, steps_per_epoch=X_train.shape[0] \/\/ batch_size\n                              , callbacks=[learning_rate_reduction])","9a90dfd3":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","0145c6f3":"# Look at confusion matrix \n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10)) ","2f1e1669":"## Checking any Missing values in data","3d0ebcd2":"## Annealing Method\n\nIn order to make the optimizer coverage faster and closest to the global minimum of the loss function, here i used an annealing method of learing rate.\n\nThe learning rate is the step by which the optimizer walks through the 'loss landscape'. Higher leaning rate, bigger the steps and the quicker is the convergence.\n\nThe ReduceLROnPlateau function from Keras.callbacks, choose to reduce the LR by half if the accuracy is not improved after 3 epochs.\n","7e351bd0":"## Data Augmentation\n\nIn order to avoid overfitting problem, we need to extand artificially our handwritten digit dataset. The idea is to alter the training data with small transformation to reproduce the variations occur. \nApproaches that alter the training data in ways that change the array representation while keeping the label the same are known as data augmentation techniques. Some popular augmentations people use are grayscales, horizontal flips, vertical flips, random crops, color jitters, translations, rotations, and much more.\n\nBy applying just a couple of these transformations to out training data, we can easily double or triple the number of traning examples and create a very robust model.\n\n\n\n","1ad274e3":" ## Label Encoding\n \n Labels are 10 digits numbers from 0 to 9. We need to encode these lables to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0]).","b45d2c5f":"## Defining CNN model\n###  CNN Architechture is \n![CNN](https:\/\/i.imgur.com\/nME3ghU.jpg)\n                                                 Input --> [[Conv2D --> relu]* --> MaxPool2D --> Dropout]*2 -- Flatten --> Dense --> Dropout --> output","562eb91e":"## Split Train and Test data","fb6c6d7f":"###  Visualizing data ","d84f8f91":"There is no missing values in train and test data\n\n## Normalization\n\nTo reduce the effect of illumination's differences we perform a grayscale normalization\n\nComputation will be  faster on [0..1] data than on [0..255]","300d3ad5":"## Loss Function and Optimization\n\nOnce out layers is added to the model, we need to set up loss function, score function and an optimization algorithm to measure how poorly our model perfom on images with known label.\n\nwe define 'categorical_crossentropy' as our loss function and RMSprop as optimizer, similar to the gradient descent algorithm with momentum.","1ca5c334":"## Reshaping Images\n\nTrain and test images (28px x 28px) has been stock into pandas.Dataframe as 1D vectors of 784 values. We reshape all data to 28x28x1 3D matrices.\n\nKeras requires an extra dimension in the end which correspond to channels. MNIST images are gray scaled so it use only one channel. For RGB images, there is 3 channels, we would have reshaped 784px vectors to 28x28x3 3D matrices.[To understand the difference between 1D, 2D, and 3D convolutions in CNN ](https:\/\/stackoverflow.com\/a\/44628011\/9352979)"}}