{"cell_type":{"be914c65":"code","7b535357":"code","fd13b517":"code","39eac98b":"code","5a716a9f":"code","f3786f0a":"code","22924fea":"code","345d7322":"code","8ae4cbe0":"code","199714a4":"code","22fcda85":"code","7115e42d":"code","261af7b1":"code","ab3adcbe":"code","47a5b397":"code","b3bb299b":"code","073480dc":"code","6187bd97":"code","358a612d":"code","9e79ecb9":"code","50c441a4":"code","6bc084f4":"code","82bbcf1c":"code","663d5778":"code","c7503738":"code","ee20e8a9":"code","24a22fe8":"code","ff6f6989":"code","6780afb5":"code","6354921d":"code","651a67df":"code","46d36408":"code","83e0eb02":"code","94e4ab03":"code","dee58010":"code","413e0957":"code","bf99c801":"code","f11aee50":"code","d4161586":"markdown","fe907a2b":"markdown","8528a5ef":"markdown","1a6b7d0b":"markdown","3114a315":"markdown","e153f1fb":"markdown","b07ec4bf":"markdown","9e98bfd9":"markdown","13f1e156":"markdown","740434de":"markdown","b6b52faf":"markdown","584c4c9b":"markdown","f0e068b8":"markdown","f5f6144b":"markdown","7f390efa":"markdown","301c5f7d":"markdown","eec1a5e2":"markdown","0a31a2cc":"markdown","2fc405c7":"markdown","8a116d14":"markdown","3a627a2a":"markdown","8b02afbd":"markdown","59653d82":"markdown"},"source":{"be914c65":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.set_option('display.max_columns', None)\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\nimport pickle\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)\nprint('Done!')","7b535357":"# set up dask\n\n!pip install --upgrade --quiet pip\n!pip install --quiet dask-ml\nprint('Done!')","fd13b517":"from dask.distributed import Client\nimport dask.dataframe as dd\nimport joblib\n\nclient = Client(n_workers=4)\nclient","39eac98b":"def load_interim_df(folder):\n    \n    folder+='\/'\n    \n    print('WARNING: Loading Datasets...')\n    \n    names = os.listdir(folder)\n    datas = []\n    \n    for name in names:\n        filename=folder+name\n        data = pickle.load(open(filename, 'rb'))\n        datas.append(data)\n\n    return datas","5a716a9f":"folder='..\/input\/mar-tab-final\/'\n\n_, X_val, X_train, y_val = load_interim_df(folder)\n\nprint(f'x_train shape is {X_train.shape}')\nprint(f'x_val shape is {X_val.shape}')\nprint(f'y_val shape is {y_val.shape}')","f3786f0a":"folder='..\/input\/test-pkl'\ntest = load_interim_df(folder)[0]\nprint(f'test shape is {test.shape}')","22924fea":"folder='..\/input\/y-train-mar'\ny_train = load_interim_df(folder)[0]\nprint(f'y_train shape is {y_train.shape}')","345d7322":"try: # detect TPUs\n    tpu = None\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept Exception as e: # detect GPUs\n    #strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","8ae4cbe0":"from sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score, f1_score, log_loss\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom copy import deepcopy\n\nimport kerastuner as kt\nimport optuna\nfrom sklearn import linear_model\nfrom sklearn import model_selection\nprint('Imported!')","199714a4":"def objective(trial, xt=X_train, yt=y_train, xv=X_val, yv=y_val):\n    \n    base_params = {\n    'max_iter':2000,\n    'verbose':50,\n    'n_jobs':-1,\n    'random_state':123,\n    'early_stopping': True,\n    'class_weight': 'balanced',\n    'average': True\n    }\n\n    # Define Base Params\n    ###############################################################################################################\n    \n    base_params['loss'] = trial.suggest_categorical(\"loss\", [\"hinge\", 'log', 'modified_huber'])\n    base_params[\"alpha\"] = trial.suggest_float(\"alpha\", 0.0001, 0.01)\n    base_params['learning_rate'] = trial.suggest_categorical(\"learning_rate\", [\"invscaling\", \"constant\", \"optimal\", \"adaptive\"])\n\n    # Define Param for learning-rate\n    ###############################################################################################################\n    \n    if base_params['learning_rate'] != 'optimal':\n        base_params['eta0'] = trial.suggest_float('eta0', 1e-4, 1e-2)\n        if base_params['learning_rate'] == 'invscaling':\n            base_params['power_t'] = trial.suggest_float('power_t', 0.2, 0.8)\n        \n    # Define Param for loss and penalty\n    ###############################################################################################################\n    \n    if base_params['loss'] == 'hinge':\n        base_params['penalty'] = 'l2'\n    else:\n        base_params['penalty'] = trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\", \"elasticnet\"]) \n        if base_params['penalty'] == 'elasticnet':\n            base_params['l1_ratio'] = trial.suggest_float('l1_ratio', 0.1, 0.6)\n    \n    print()\n    print(base_params)\n    print()\n    \n    with strategy.scope():\n        clf = SGDClassifier(**base_params)\n        with joblib.parallel_backend('dask'):\n            clf.fit(xt, yt)\n            \n    # Make Prediction and Obtain Metric\n    ###############################################################################################################\n    \n    preds = clf.predict(xv)\n    preds = np.rint(preds).astype('int32')\n    \n    f1 = f1_score(yv, preds)\n    \n    return f1","22fcda85":"with strategy.scope():\n    with joblib.parallel_backend('dask'):\n        st=time.time()\n        study = optuna.create_study(direction='maximize')\n        study.optimize(objective, n_trials=1500, show_progress_bar=True)\n        print(\"Number of finished trials: \", len(study.trials))\n        print(\"Best trial:\")\n        trial = study.best_trial\n\n        print(\"  Value: {}\".format(trial.value))\n        print(\"  Params: \")\n        for key, value in trial.params.items():\n            print(\"    {}: {}\".format(key, value))\n        print(f'Process ran for {time.time()-st} secs!')","7115e42d":"best_params = trial.params\nbest_params","261af7b1":"# Create a dataframe from the study.\ndf = study.trials_dataframe()\ndf.sort_values(by='value', ascending=False, inplace=True)\ndf.head(10)","ab3adcbe":"best_params['early_stopping'] = True\nbest_params['max_iter'] = 20000\nbest_params['verbose'] = int(best_params['max_iter']*0.01)\nbest_params['random_state'] = 123\nbest_params['n_jobs'] = -1","47a5b397":"# Build a new model\n\nsgd = SGDClassifier(**best_params)\nsgd.get_params()","b3bb299b":"with strategy.scope():\n    with joblib.parallel_backend('dask'):\n        st=time.time()\n        sgd.fit(X_train, y_train)\n        print(f'Took {time.time()-st} secs!')","073480dc":"best_iter = sgd.n_iter_\nbest_iter","6187bd97":"best_params['max_iter'] = best_iter\nbest_params['early_stopping'] = False\nbest_params['verbose'] = True\n\n# Reinstantiate the model\nsgd = SGDClassifier(**best_params)\nsgd.get_params()","358a612d":"# Define the Kfold strategy\n\nfolds = KFold(n_splits=10, shuffle=True, random_state=231)\nprint('Done!')","9e79ecb9":"class AverageFoldsSGDC(object):\n    \n    def __init__(self, folds):\n        self.folds = folds\n        self.models = []\n        \n    def fit(self, X_train, y_train, model=sgd):\n        # create out-of-folds prediction template\n        \n        try:\n            assert isinstance(y_train, pd.Series)\n        except AssertionError:\n            y_train = pd.Series(y_train)\n            \n        oof_preds = np.zeros_like(y_train).reshape(-1,1)\n        \n        self.X_train = X_train\n        self.y_train = y_train\n        \n        for train_idx, val_idx in tqdm(folds.split(X_train)):\n            train_x, val_x = self.X_train.iloc[train_idx], self.X_train.iloc[val_idx]\n            train_y, val_y = self.y_train.iloc[train_idx], self.y_train.iloc[val_idx]\n            \n            model.fit(train_x,\n                      train_y.values.ravel())\n            \n            self.models.append(model)\n            \n            oof_pred = model.predict(val_x).reshape(-1, 1)\n            oof_pred = np.rint(oof_pred).astype('int32')\n            (unique, counts) = np.unique(oof_pred, return_counts=True)\n            print('unique is', unique)\n            \n            oof_preds[val_idx] = oof_pred\n            \n        self.oof_preds = oof_preds\n        \n        \n    def predict(self, X_test):\n        preds = []\n        for model in tqdm(self.models):\n            pred = model.predict(X_test)\n            preds.append(pred)\n        preds = np.mean(preds, axis=0)\n        preds = np.rint(preds).astype('int64')\n        \n        if preds.ndim >= 2:\n            preds = preds.flatten()\n        \n        return preds","50c441a4":"# from itertools import chain\n\n# best_params = dict(chain.from_iterable(d.items() for d in (best_params, base_params)))\n# best_params","6bc084f4":"with strategy.scope():\n    with joblib.parallel_backend('dask'):\n        st=time.time()\n        model = AverageFoldsSGDC(folds)\n        model.fit(X_train, y_train)\n        print(f'Took {time.time()-st} secs!')","82bbcf1c":"(unique, counts) = np.unique(model.oof_preds, return_counts=True)\nfrequencies = np.asarray((unique, counts)).T\nfrequencies","663d5778":"pred = model.predict(X_val)","c7503738":"f1_score(y_val, pred)","ee20e8a9":"accuracy_score(y_val, pred)","24a22fe8":"def distribution_plot(true, pred, true_name, pred_name, Title):\n    plt.figure(figsize=(5,4), dpi=100)\n    ax1 = sns.distplot(true, hist=False, color='r', label= true_name)\n    ax2 = sns.distplot(pred, hist=False, color='b', label= pred_name, ax=ax1)\n    \n    plt.title(Title)\n    plt.xlabel('Features')\n    plt.ylabel('Target')\n    \n    plt.show()\n    plt.close()","ff6f6989":"true = y_val\npred = pred\ntrue_name = 'Target'\npred_name = 'y_hat'\nTitle = 'Target Vs Predictions Plot: SGDClassifier'\n\ndistribution_plot(true, pred, true_name, pred_name, Title)","6780afb5":"if True:\n    prediction = model.predict(test)\n    print('Done!')","6354921d":"(unique, counts) = np.unique(prediction, return_counts=True)\nfrequencies = np.asarray((unique, counts)).T\nfrequencies","651a67df":"if True:\n    def submissions(prediction=prediction):\n        sample['target'] = prediction\n        sample.to_csv('submission.csv', index=False)","46d36408":"sample = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/sample_submission.csv')\nsample.head()","83e0eb02":"if True:\n    submissions()\n    display(pd.read_csv('submission.csv').head())","94e4ab03":"!pip install --quiet gs-wrap\nimport gswrap\nimport datetime as dt\nclient = gswrap.Client('vibrant-reach-282320')\nprint('gswrap ready for use!')","dee58010":"def save_to_gcp(df, folder_name, file_name):\n    try:\n        assert file_name.endswith('.csv')\n    except:\n        file_name+='.csv'\n    \n    t = str(dt.datetime.now()).replace(' ', '_').split('.')[0]\n    df.to_csv(file_name, index=False)\n    \n    with strategy.scope():\n        st=time.time()\n        print('Copying files...')\n        client.cp(src=f\".\/{file_name}\",\n                  dst=f\"gs:\/\/kaggle1980\/Kaggle\/GridSearch\/{folder_name}\/{file_name.split('.')[0]}_{t}.csv\",\n                  multithreaded=True)\n        ed=time.time()\n        memory = df.memory_usage().sum()\n        print(f'1 file of size {memory} bytes copied in {ed-st} seconds!')","413e0957":"try:\n    save_to_gcp(df, 'sgdc', 'sgd_grid')\nexcept Exception as e:\n    print(e)","bf99c801":"import pickle\n\n# save the model to disk\ntry:\n    filename = 'sgd_model.sav'\n    pickle.dump(model.models[0], open(filename, 'wb'))\nexcept Exception as e:\n    print(e)","f11aee50":"#Let's create a byte-stream placeholder object named 'xgb_params.pickle'\npickle_holder = open('sgd_params.pickle','wb')\n\n# Now let's dump the 'xgb_params' data into 'xgb_params.pickle'\npickle.dump(best_params, pickle_holder)\n\n# Finally, let's close the connection\npickle_holder.close()\nprint('Done!')","d4161586":"### Define a class of average folds to train a model with initial best-params","fe907a2b":"### Save The model","8528a5ef":"### train on the train set","1a6b7d0b":"### Define The objective function","3114a315":"### Save the Parameter-Search DataFrame for more analysis","e153f1fb":"### Accuracy","b07ec4bf":"### Call the submissions method and save the model","9e98bfd9":"### See spread of prediction","13f1e156":"### Extract The best Params","740434de":"### Save the Best Params","b6b52faf":"### Let' see the count of zeros and ones","584c4c9b":"### Let's see the top 10 runs","f0e068b8":"[SGD-LINK](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier)\n\n[optuna-searchcv](https:\/\/optuna.readthedocs.io\/en\/stable\/reference\/generated\/optuna.integration.OptunaSearchCV.html#optuna.integration.OptunaSearchCV)","f5f6144b":"### Set the best iter and re-instantiate the model","7f390efa":"### Define a Submissions method","301c5f7d":"### Deciding the most ideal Estimators to fit the Classifier","eec1a5e2":"### Optimizing SGDC with Optuna","0a31a2cc":"### Disribution Plot","2fc405c7":"### Make a Prediction on Test set","8a116d14":"### F1-score","3a627a2a":"### Extend best params with base params\n","8b02afbd":"### Use Kfold cross validation with best params on the data","59653d82":"### Extract the best iter"}}