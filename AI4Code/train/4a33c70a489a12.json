{"cell_type":{"f48d419b":"code","742878a9":"code","5a346fa1":"code","a3484a64":"code","c2707481":"code","01625ea0":"code","b75d414e":"code","85763103":"code","1b1824aa":"code","c447db82":"code","22da476d":"code","2bf36ceb":"code","d9cc7c1b":"code","e320a038":"code","4704b157":"code","1f309ef6":"code","359ee43f":"code","252b55f7":"code","3cee3dfb":"code","325c0d49":"code","591e3dc9":"code","1c14b63a":"code","82d57c32":"code","d1def90e":"code","57c889ea":"code","0596030e":"code","9e078ca9":"code","0ff5331e":"code","71b8dcbd":"code","a36e337d":"code","dc52d41f":"code","51c0b76e":"code","44c00757":"code","17959e5f":"code","6bcf17cf":"code","3bbe39be":"code","e5d4e4ae":"code","652a44d2":"code","482abffe":"code","f360cdfa":"code","e07865e3":"code","f2bcd0db":"code","5196e31c":"code","dbd7a456":"markdown","586a03f0":"markdown","f4916192":"markdown","fbde408f":"markdown","bd976dab":"markdown","215b7d89":"markdown","a53d3576":"markdown","0a362c38":"markdown","b9bf48d0":"markdown","d18d23c3":"markdown","4c766cec":"markdown","f8badf40":"markdown","4c793475":"markdown","a68d65dd":"markdown","f340b5b4":"markdown","454336be":"markdown","8a797c40":"markdown","a06d2f17":"markdown","7422479f":"markdown","132efe55":"markdown","8b374831":"markdown","c351e7c7":"markdown","f1e0423b":"markdown","2bdb161c":"markdown","4640ab12":"markdown","7562a88e":"markdown","65ec991e":"markdown","b58cecd6":"markdown","6e82201b":"markdown","a7d4f3ce":"markdown","04ca6287":"markdown","a24bb92f":"markdown","cc3da372":"markdown","bbce72aa":"markdown"},"source":{"f48d419b":"import warnings\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, \\\n    classification_report\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier","742878a9":"warnings.simplefilter(action='ignore', category=FutureWarning)\nnp.warnings.filterwarnings('ignore')\npd.pandas.set_option('display.max_columns', None)\npd.pandas.set_option('display.max_rows', None)\npd.set_option('display.float_format', lambda x: '%.3f' % x)","5a346fa1":"df = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')","a3484a64":"df.head()","c2707481":"df.info()","01625ea0":"# Numerical variables selected (Target Variable excluded)\ncols = [col for col in df.columns if df[col].dtypes != 'O' and col not in \"Outcome\"]","b75d414e":"df[cols].nunique()","85763103":"# Plotting each variables histograms\ndef hist_for_nums(data, numeric_cols):\n    for col in numeric_cols:\n        data[col].hist()\n        plt.xlabel(col)\n        plt.title(col)\n        plt.show()\n\nhist_for_nums(df, cols)","1b1824aa":"def boxplot_for_nums(data, numeric_cols):\n    for col in numeric_cols:\n        sns.boxplot(data[col])\n        plt.xlabel(col)\n        plt.title(col)\n        plt.show()\n\nboxplot_for_nums(df, cols)\n","c447db82":"df.describe().T","22da476d":"df.isnull().sum()","2bf36ceb":"df[df == 0]","d9cc7c1b":"df_zeros = ['Age','BloodPressure','BMI','Glucose','Insulin','SkinThickness']\n\ndf[df_zeros]= df[df_zeros].replace(0, np.NaN)","e320a038":"df.isnull().sum()","4704b157":"df.groupby(\"Outcome\")[\"Glucose\"].median()","1f309ef6":"df.loc[(df['Outcome'] == 0 ) & (df['Glucose'].isnull()), 'Glucose'] = 107\ndf.loc[(df['Outcome'] == 1 ) & (df['Glucose'].isnull()), 'Glucose'] = 140","359ee43f":"df.groupby(\"Outcome\")[\"BloodPressure\"].median()\n","252b55f7":"df.loc[(df['Outcome'] == 0 ) & (df['BloodPressure'].isnull()), 'BloodPressure'] = 70\ndf.loc[(df['Outcome'] == 1 ) & (df['BloodPressure'].isnull()), 'BloodPressure'] = 74.5","3cee3dfb":"df.groupby(\"Outcome\")[\"SkinThickness\"].median()","325c0d49":"df.loc[(df['Outcome'] == 0 ) & (df['SkinThickness'].isnull()), 'SkinThickness'] = 27\ndf.loc[(df['Outcome'] == 1 ) & (df['SkinThickness'].isnull()), 'SkinThickness'] = 32","591e3dc9":"df.groupby(\"Outcome\")[\"Insulin\"].median()","1c14b63a":"df.loc[(df['Outcome'] == 0 ) & (df['Insulin'].isnull()), 'Insulin'] = 102.500\ndf.loc[(df['Outcome'] == 1 ) & (df['Insulin'].isnull()), 'Insulin'] = 169.500","82d57c32":"df.groupby(\"Outcome\")[\"BMI\"].median()","d1def90e":"df.loc[(df['Outcome'] == 0 ) & (df['BMI'].isnull()), 'BMI'] = 30.100\ndf.loc[(df['Outcome'] == 1 ) & (df['BMI'].isnull()), 'BMI'] = 34.300","57c889ea":"df.isnull().sum()","0596030e":"# Determine Outlier Thresholds of each variable\ndef outlier_thresholds(dataframe, variable):\n    quartile1 = dataframe[variable].quantile(0.25)\n    quartile3 = dataframe[variable].quantile(0.75)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit","9e078ca9":"# Function prints the variables which have values lower than low_limit (Determined by outlier_thresholds function) and higher than high_limit (Determined by outlier_thresholds function).\ndef has_outliers(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    if dataframe[(dataframe[variable] < low_limit) | (dataframe[variable] > up_limit)].any(axis=None):\n        print(variable, \"yes\")\n\nfor col in cols:\n    has_outliers(df, col)\n","0ff5331e":"# Set outliers to low_limit and up_limit respectively\ndef replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n\nreplace_with_thresholds(df, 'BloodPressure')\nreplace_with_thresholds(df, 'DiabetesPedigreeFunction')","71b8dcbd":"# Set outliers which are only higher than up_limit to up_limit\ndef replace_with_thresholds_2(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n\nreplace_with_thresholds_2(df, 'Insulin')\nreplace_with_thresholds_2(df, 'SkinThickness')","a36e337d":"df[\"New_SkinThickness\"] = df[\"SkinThickness\"] * 4","dc52d41f":"# Body fat values are assigned according to skin thickness and age. Measurements are taken from the paper that is described above.\ndf.loc[(df['Age'] >= 21 ) & (df['Age'] <= 29) & (df[\"New_SkinThickness\"] < 34), 'New_Body_Fat'] = \"Underfat\"\ndf.loc[(df['Age'] >= 30 ) & (df['Age'] <= 39) & (df[\"New_SkinThickness\"] < 29), 'New_Body_Fat'] = \"Underfat\"\ndf.loc[(df['Age'] >= 40 ) & (df['Age'] <= 49) & (df[\"New_SkinThickness\"] < 23), 'New_Body_Fat'] = \"Underfat\"\ndf.loc[(df['Age'] >= 50 ) & (df[\"New_SkinThickness\"] < 20), 'New_Body_Fat'] = \"Underfat\"\n\ndf.loc[(df['Age'] >= 21 ) & (df['Age'] <= 29) & (df[\"New_SkinThickness\"] >= 34) & (df[\"New_SkinThickness\"] <= 79), 'New_Body_Fat'] = \"Healthy\"\ndf.loc[(df['Age'] >= 30 ) & (df['Age'] <= 39) & (df[\"New_SkinThickness\"] >= 29) & (df[\"New_SkinThickness\"] <= 73), 'New_Body_Fat'] = \"Healthy\"\ndf.loc[(df['Age'] >= 40 ) & (df['Age'] <= 49) & (df[\"New_SkinThickness\"] >= 23) & (df[\"New_SkinThickness\"] <= 59), 'New_Body_Fat'] = \"Healthy\"\ndf.loc[(df['Age'] >= 50 ) & (df[\"New_SkinThickness\"] >= 20) & (df[\"New_SkinThickness\"] <= 49), 'New_Body_Fat'] = \"Healthy\"\n\ndf.loc[(df['Age'] >= 21 ) & (df['Age'] <= 29) &( df[\"New_SkinThickness\"] > 79) & (df[\"New_SkinThickness\"] <= 120), 'New_Body_Fat'] = \"OverFat\"\ndf.loc[(df['Age'] >= 30) & (df['Age'] <= 39) & (df[\"New_SkinThickness\"] > 73) & (df[\"New_SkinThickness\"] <= 115), 'New_Body_Fat'] = \"OverFat\"\ndf.loc[(df['Age'] >= 40 ) & (df['Age'] <= 49) & (df[\"New_SkinThickness\"] > 59) & (df[\"New_SkinThickness\"] <= 95), 'New_Body_Fat'] = \"OverFat\"\ndf.loc[(df['Age'] >= 50 ) & (df[\"New_SkinThickness\"] > 49) & (df[\"New_SkinThickness\"] <= 77), 'New_Body_Fat'] = \"OverFat\"\n\ndf.loc[(df['Age'] >= 21 ) & (df['Age'] <= 29) & (df[\"New_SkinThickness\"] > 120), 'New_Body_Fat'] = \"Obese\"\ndf.loc[(df['Age'] >= 30 ) & (df['Age'] <= 39) & (df[\"New_SkinThickness\"] > 115) , 'New_Body_Fat'] = \"Obese\"\ndf.loc[(df['Age'] >= 40 ) & (df['Age'] <= 49) & (df[\"New_SkinThickness\"] > 95) , 'New_Body_Fat'] = \"Obese\"\ndf.loc[(df['Age'] >= 50 ) & (df[\"New_SkinThickness\"] > 77) , 'New_Body_Fat'] = \"Obese\"\n","51c0b76e":"df.drop([\"SkinThickness\",\"New_SkinThickness\"], axis =1, inplace=True)","44c00757":"# Glucose level under 140 are assigned as No_Risk and above 140 are assigned as Prediabetes.\ndf.loc[(df[\"Glucose\"] <= 140), \"New_Glucose\"] = \"No_Risk\"\ndf.loc[(df[\"Glucose\"] > 140), \"New_Glucose\"] = \"Prediabetes\"","17959e5f":"# Categorical variables are selected\ncat_cols = [col for col in df.columns if df[col].dtypes == 'O']","6bcf17cf":"# Categorical variables are encoded\ndef one_hot_encoder(dataframe,categorical_cols,nan_as_category=False):\n    original_columns = list(dataframe.columns)\n    dataframe = pd.get_dummies(dataframe,columns = categorical_cols,dummy_na = nan_as_category,drop_first = True)\n    new_columns = [c for c in dataframe.columns if c not in original_columns]\n    return dataframe,new_columns\n\ndf,new_cols_ohe = one_hot_encoder(df,cat_cols)","3bbe39be":"y = df[\"Outcome\"] # Target variable is assigned to y\nX = df.drop([\"Outcome\"], axis=1) # Control variables are assigned to X","e5d4e4ae":"# All models are assigned to models variable\nmodels = [('LR', LogisticRegression()),\n          ('KNN', KNeighborsClassifier()),\n          ('CART', DecisionTreeClassifier()),\n          ('RF', RandomForestClassifier()),\n          ('SVM', SVC(gamma='auto')),\n          ('GB', GradientBoostingClassifier()),\n          (\"LightGBM\", LGBMClassifier())] ","652a44d2":"# Dataset split into test and train (Holdout)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=46) # 80% train, 20% test ","482abffe":"results = []\nnames = []\n# K-fold cross validation applied into train dataset\nfor name, model in models:\n    kfold = KFold(n_splits=10, random_state=123456) # Train dataset is split into 10\n    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=\"accuracy\")\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)\n","f360cdfa":"# Boxplot Algorithm Comparison\nfig = plt.figure(figsize=(15, 10))\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","e07865e3":"# Test data set prediction\nfor name, model in models:\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    acc = accuracy_score(y_test, y_pred)\n    msg = \"%s: (%f)\" % (name, acc)\n    print(msg)","f2bcd0db":"# K-fold cross validation applied into train dataset\nfor name, model in models:\n    kfold = KFold(n_splits=10, random_state=123456) # Train dataset is split into 10\n    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=\"accuracy\")\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)\n","5196e31c":"sns.countplot(x = \"Outcome\", data = df)\nplt.show()\nprint(pd.DataFrame({col: df[\"Outcome\"].value_counts(),\n                           \"Ratio\": 100 * df[\"Outcome\"].value_counts()\/ len (df)}), end = \"\\n\\n\\n\")","dbd7a456":"* At first sight, it can be thought that there are no missing values in dataset.\n* However, variables such as Age, Blood Pressure, BMI, Glucose, Insulin, Skin Thickness contains 0. This is simply not possible. Those values need to be changed with NaNs.","586a03f0":"## 1.2 Import Libraries","f4916192":"* It seems that all variables except Glucose has outliers.","fbde408f":" ## 3.1 Missing Value Treatment\n","bd976dab":"## 3.2 Outlier Treatment","215b7d89":"# 5. Encoding","a53d3576":"## 1.1 General Description of the Dataset","0a362c38":"* __These outliers are set to those limits after several trial and error attempts.__","b9bf48d0":"__Insulin__","d18d23c3":"# 1. Introduction","4c766cec":"* There are several right-skewed(Age, Diabetes Pedigree Function, BMI, Insulin, SkinThickness, Pregnancies) and normally distributed (Blood Pressure, Glucose) variables. We may observe outliers at those right-skewed variables. Also, these variables may indicate a range boundary.","f8badf40":"* In order to fill missing values, we can group by each missing variables median values in accordance with the outcome variable and assign those values to missing values (Cited from Vincent Lugat's work. https:\/\/www.kaggle.com\/vincentlugat\/pima-indians-diabetes-eda-prediction-0-906)","4c793475":"# 2. Overview","a68d65dd":"* We can observe outliers by checking the boxplot of each variable.","f340b5b4":"# 3. Data Processing","454336be":"* According to the results, our best models are KNN, GB, LightGBM, RF.","8a797c40":"It seems that there aren't any categorical variables. However, there may be categorical variables as type of integer variable. We can observe it simply by checking unique values of each variable.","a06d2f17":"__Glucose__","7422479f":"__Glucose__","132efe55":"* Unique values of each variable are very high. It seems there aren't any categorical variables within numerical variables.","8b374831":"# 6. Modelling","c351e7c7":"* It seems that KNN, RF, GB and LightGMB models deviations are low. Therefore, those can be considered succesfull.","f1e0423b":"* In my point of view, this problem occurs because the dataset is an unbalanced dataset.","2bdb161c":"* It seems that cross validation scores are larger than models accuracy score. There is a risk of overfitting. However, scores are very close. Therefore, it can be negligible.","4640ab12":"__Introduction__\n\nThis dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage (by UCI Machine Learning).\n\n__Variables:__\n\n* Pregnancies: Number of times pregnant\n\n    Gestational diabetes is a type of diabetes that can develop during pregnancy in women who don\u2019t already have     diabetes. Having gestational diabetes can increase your risk of high blood pressure during pregnancy (Centers for Disease Control and Prevention. Gestational Diabetes. https:\/\/www.cdc.gov\/diabetes\/basics\/gestational.html)\n        \n* Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n\n* BloodPressure: Diastolic blood pressure (mm Hg)\n\n* SkinThickness: Triceps skin fold thickness (mm) - V\u00fccut ya\u011f oran\u0131n\u0131 g\u00f6sterir.\n\n   Below 20%  Under fat\n   \n   21-33%  Healthy\n   \n   34-39% Over fat\n   \n   Above 39  Obese\n   \n   \n* Insulin: 2-Hour serum insulin (mu U\/ml)\n* BMI: Body mass index (weight in kg\/(height in m)^2)\n    \n    BMI Categories:\n     \n     Underweight = <18.5\n     \n     Normal weight = 18.5\u201324.9\n     \n     Overweight = 25\u201329.9\n     \n     Obesity = BMI of 30 or greater\n\n\n\n* DiabetesPedigreeFunction: Diabetes pedigree function\n* Age: Age (years)\n* Outcome: Class variable(0 or 1) (Target Variable)\n","7562a88e":"* Unbalanced dataset is pretty common in disease data. Because most of the samples are healthy individuals. In our dataset, it is clear that 65% of control sample are healthy individuals.\n* This problem can be overcome by resampling methods or by collecting more data.","65ec991e":"__Settings__","b58cecd6":"* According to Durnin and Womersley, Skinfold Thickness can be converted into Body fat (Durnin, J., & Womersley, J.,1973). \n* Body fat can be measured from the sum of four skinfolds (biceps, triceps, subscapular, and supra-iliac) of males and females of different ages.\n* However, in this dataset we only have skinfold thickness of triceps.\n* In order to overcome this problem, the skin thickness variable is multiplied by 4.\n\nhttps:\/\/www.cambridge.org\/core\/services\/aop-cambridge-core\/content\/view\/DAC8BA25856FCEB30E22F60E0AF80D07\/S0007114574000614a.pdf\/body_fat_assessed_from_total_body_density_and_its_estimation_from_skinfold_thickness_measurements_on_481_men_and_women_aged_from_16_to_72_years.pdf","6e82201b":"__Skin Thickness__","a7d4f3ce":"# 4. Feature Engineering","04ca6287":"__Blood Pressure__","a24bb92f":"## 1.3 Read Data","cc3da372":"__New Body Fat__","bbce72aa":"__BMI__"}}