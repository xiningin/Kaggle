{"cell_type":{"f52f2b8c":"code","d0d77d46":"code","86516921":"code","2a3c639f":"code","b8c63ff7":"code","15777827":"code","887fae07":"code","b82369a3":"code","1ecede73":"code","89431dab":"code","6d55b8bf":"code","397f3d42":"code","3b5bc3b2":"code","3d90a1f4":"code","9d2588ea":"code","79b07f28":"code","fd13c228":"code","7a3e4655":"code","45c1d85e":"code","a92dce58":"code","abcafa37":"code","0c668b58":"code","2851a764":"code","1f52062a":"code","933c8d52":"code","dac74b32":"code","392e4d71":"code","f458a725":"code","db4f38e5":"code","4ab2b850":"code","4bdcbc99":"code","db3e0b89":"code","6b44828a":"code","c1c386f6":"markdown","3da052d2":"markdown","228dd7fa":"markdown","eb54ca8a":"markdown","1cf3558a":"markdown"},"source":{"f52f2b8c":"#importing libraies\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)","d0d77d46":"#loading data\ntrain1= pd.read_csv(r\"..\/input\/titanic\/train.csv\")\ntest= pd.read_csv(r\"..\/input\/titanic\/test.csv\")\ntrain1.head()","86516921":"train1.columns","2a3c639f":"sns.countplot(train1.Survived)","b8c63ff7":"sns.countplot(train1.Survived, hue=train1.Sex)","15777827":"sns.countplot(train1.Survived, hue=train1.Pclass)","887fae07":"sns.countplot(train1.Survived, hue=train1.Embarked)","b82369a3":"import seaborn as sns\nimport matplotlib.pyplot as plt\ngrid = sns.FacetGrid(train1, col='Survived', size=3.2)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend()","1ecede73":"#missing data in training data\nnull= train1.isna().sum()\nper_null= train1.isna().sum()\/train1.isna().count()*100\nper_null= round(per_null, 1)\nmissing_data= pd.concat([null, per_null], axis=1, keys=['number of missing values', '% of missig values'])\nmissing_data","89431dab":"#missing data in test data\nnull= test.isna().sum()\nper_null= test.isna().sum()\/test.isna().count()*100\nper_null= round(per_null, 1)\nmissing_data= pd.concat([null, per_null], axis=1, keys=['number of missing values', '% of missig values'])\nmissing_data","6d55b8bf":"#filling missing values of Embarked and Fare\ntrain1.Embarked.fillna(train1.Embarked.mode()[0], inplace=True)\ntest.Embarked.fillna(test.Embarked.mode()[0], inplace=True)\n\ntest.Fare.fillna(test.Fare.mean(), inplace=True)","397f3d42":"#creating new column by combining parch and sibsp\ntrain1[\"relatives\"] = train1[\"SibSp\"] + train1[\"Parch\"]\n\n#filling missing values of cabin and using them to create new column deck\ntrain1[\"Cabin\"]= train1[\"Cabin\"].fillna(\"C\")\ntrain1[\"Deck\"]= train1[\"Cabin\"].str[:1]\n\ntest[\"relatives\"] = test[\"SibSp\"] + test[\"Parch\"]\ntest[\"Cabin\"]= test[\"Cabin\"].fillna(\"C\")\ntest[\"Deck\"]= test[\"Cabin\"].str[:1]","3b5bc3b2":"sns.countplot(train1.Survived, hue=train1.relatives)\nplt.title('Survival count by number of Relatives')\nplt.legend(bbox_to_anchor=(1, 1), loc=2) ","3d90a1f4":"sns.countplot(train1.Survived, hue=train1.Deck)","9d2588ea":"#getting titles from name\ndataset= [train1, test]\nfor data in dataset:\n    data['Title']= data['Name'].str.extract(pat= ' ([A-Za-z]+)\\.')\n\ntrain1['Title'].unique()\n#try with just 4 titles","79b07f28":"pd.crosstab(train1.Sex, train1.Title)","fd13c228":"for data in dataset:\n    data.Title=data.Title.replace(['Ms', 'Mlle'], 'Miss')\n    data.Title=data.Title.replace(['Mme', 'Countess', 'Lady'], 'Mrs')\n    data.Title=data.Title.replace(['Dr', 'Rev', 'Sir', 'Col', 'Major',  'Capt', 'Jonkheer', 'Don'], 'Mr')\n\npd.crosstab(train1.Title, train1.Survived)\ntrain1[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","7a3e4655":"#filling age by mean of title groups\ntrain1.Age= train1.groupby('Title')['Age'].transform(lambda grp: grp.fillna(round(np.mean(grp), 0)))\ntest.Age= test.groupby('Title')['Age'].transform(lambda grp: grp.fillna(round(np.mean(grp), 0)))","45c1d85e":"train1.head()","a92dce58":"# drop Name, SibSp, Parch, Ticket, Sex, PassengerId, Cabin\nPid= test['PassengerId']\nfor data in dataset:\n    data.drop(columns=['Name', 'PassengerId', 'Cabin', 'Ticket', 'SibSp', 'Parch', 'Sex'], axis=1, inplace=True)\n","abcafa37":"train1.head(2)","0c668b58":"test.head(2)","2851a764":"from sklearn.preprocessing import LabelEncoder\n\nencoder = LabelEncoder()\n\ncol=['Embarked', 'Deck', 'Title']\nfor data in dataset:\n    data['Embarked']= encoder.fit_transform(data['Embarked'])\n    data['Deck']= encoder.fit_transform(data['Deck'])\n    data['Title']= encoder.fit_transform(data['Title'])\n    \n    ","1f52062a":"train1.head()","933c8d52":"sns.heatmap(train1.corr(), annot=True, cmap='Greens')\nfig=plt.gcf()\nfig.set_size_inches(10,8)","dac74b32":"train_lg= train1\ntest_lg= test","392e4d71":"from sklearn.preprocessing import MinMaxScaler\nscaler= MinMaxScaler()\n\nfeatures= ['Pclass', 'Fare', 'Age', 'Embarked', 'relatives', 'Deck', 'Title']\ntrain_lg[features]= scaler.fit_transform(train_lg[features])\ntest_lg[features]= scaler.fit_transform(test_lg[features])","f458a725":"train_lg.head(3)","db4f38e5":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\n\n\ny= train_lg.Survived\nx= train_lg\nx.drop(columns=['Survived'], axis=1, inplace=True)\nprint(x.head())","4ab2b850":"from sklearn.model_selection import KFold, cross_val_score\nskf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\ncnt=1\nfor train_index, test_index in skf.split(x, y):\n    print(f'Fold:{cnt}, Train set: {len(train_index)}, Test set:{len(test_index)}')\n    cnt+=1","4bdcbc99":"from sklearn.metrics import accuracy_score\nkf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n\naccuracy, y_preds = [],[]\ncv_train = np.zeros((len(x),))\n\nfor tr_idx, va_idx in kf.split(x, y):\n    tr_x, va_x = x.iloc[tr_idx], x.iloc[va_idx]\n    tr_y, va_y = y.iloc[tr_idx], y.iloc[va_idx]\n    \n    model = RandomForestClassifier(n_estimators=120, criterion='entropy', min_samples_split=10, min_samples_leaf=2)\n    model.fit(tr_x, tr_y)\n    \n    va_pred = model.predict(va_x)\n    cv_train[va_idx] = va_pred\n    \n    #va_pred = (va_pred > 0.5).astype(int)\n    print(accuracy_score(va_y, va_pred))\n    accuracy.append(accuracy_score(va_y, va_pred))\n    \n    #predict everytime\n    #reserve most common prediction for each index.\n\n    y_pred=model.predict(test)\n    y_preds.append(y_pred)\nprint(\"mean accuracy: \", np.mean(accuracy))","db3e0b89":"pred=[]\nfor i in range(0,len(y_preds[0])):\n    ele=[]\n    for j in range(0,10):\n        ele.append(y_preds[j][i])\n    #print(ele)\n    pred.append(max(set(ele), key = ele.count))\n\nresults= pd.concat([Pid, pd.Series(pred)], axis=1)\nresults.columns=[['PassengerId', 'Survived']]\nresults.head()","6b44828a":"results.to_csv(r\".\/RF_CrossVal_FeatureEngg.csv\", index=False)","c1c386f6":"## EDA","3da052d2":"## min max normalization","228dd7fa":"## Stratified k-fold cross validation and random forest","eb54ca8a":"## Changing categorical variables to ordinal","1cf3558a":"## Dealing with missing data And Feature Engineering"}}