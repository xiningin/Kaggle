{"cell_type":{"c130750f":"code","3a90e249":"code","dbce0748":"code","68ef50ae":"code","70553d80":"code","d98fe588":"code","7f6e5efa":"code","5b74b740":"code","2cf98e2f":"code","a3c9463b":"code","e44e1f3b":"code","339f8016":"code","65563e99":"code","b96615ca":"markdown","78c2da41":"markdown","d0d63c63":"markdown","e4c3e59d":"markdown","3abc03d9":"markdown","a3cd0c86":"markdown","635c71bf":"markdown","b047626c":"markdown","9af31341":"markdown","1205aa41":"markdown","a8e8bdfb":"markdown","00c86113":"markdown","d268c37c":"markdown","27d80215":"markdown","2c800e4a":"markdown","a82d87b3":"markdown","578ff3eb":"markdown"},"source":{"c130750f":"import pandas  as pd\nimport numpy as np\nimport time\nimport random\nimport os\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.metrics import roc_auc_score\nfrom catboost import CatBoostClassifier, Pool","3a90e249":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n\nseed_everything(666)","dbce0748":"train = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/test.csv\")","68ef50ae":"train[\"missing\"] = train.isnull().sum(axis = 1)\ntest[\"missing\"] = test.isnull().sum(axis = 1)","70553d80":"target = \"claim\"\npredictors = [x for x in train.columns if x not in [\"id\", target]]\n\nkf = KFold(n_splits = 5, shuffle = True, random_state = 666)","d98fe588":"train[predictors] = train[predictors].fillna(train.groupby(\"missing\")[predictors].transform(\"mean\"))\ntest[predictors] = test[predictors].fillna(train.groupby(\"missing\")[predictors].transform(\"mean\"))","7f6e5efa":"scaler = StandardScaler()\n\ntrain[predictors] = scaler.fit_transform(train[predictors])\ntest[predictors] = scaler.transform(test[predictors])","5b74b740":"X = train[predictors]\ny = train[target]\ntest = test[predictors]","2cf98e2f":"model_cb = CatBoostClassifier(\n    random_seed = 666,\n    thread_count = -1,\n    iterations = 2000,\n    learning_rate = 0.1,\n    eval_metric = \"AUC\",\n    task_type = \"GPU\"\n)","a3c9463b":"start = time.time()\n\noof_cb = np.zeros(len(X))\n\ni = 0\n\nwhile i < 5:\n    \n    for train_ix, test_ix in kf.split(X.values):\n    \n        train_X, train_y = X.iloc[train_ix], y.iloc[train_ix]\n        test_X, test_y = X.iloc[test_ix], y.iloc[test_ix]\n\n        model_cb.fit(\n            train_X, train_y,\n            eval_set = [(test_X, test_y)],\n            early_stopping_rounds = 50,\n            use_best_model = True,\n            verbose = 0,\n        )\n\n        oof_cb[test_ix] = oof_cb[test_ix] + model_cb.predict_proba(test_X)[:, 1]\n        \n    i += 1\n    \nprint(\"AUC score: \\033[1m{}\\033[0m\".format(round(roc_auc_score(y, oof_cb), 5)))\n\nelapsed_time = time.time() - start\n\nprint(\"\\nAverage Elapsed time for \\033[1mnumpy array\\033[0m input: \\t\\t \\033[1m{}\\033[0m\".format(elapsed_time \/ 5))","e44e1f3b":"?Pool","339f8016":"start = time.time()\n\ntrain_pool = Pool(X, label = y)\n\noof_cb = np.zeros(len(X))\n\ni = 0\n\nwhile i < 5:\n    \n    for train_ix, test_ix in kf.split(X.values):\n\n        tr_pool = train_pool.slice(train_ix)\n        val_pool = train_pool.slice(test_ix)\n\n        model_cb.fit(\n            tr_pool,\n            eval_set = [(val_pool)],\n            early_stopping_rounds = 50,\n            use_best_model = True,\n            verbose = 0,\n        )\n\n        oof_cb[test_ix] = oof_cb[test_ix] + model_cb.predict_proba(val_pool)[:, 1]\n        \n    i += 1\n    \nprint(\"AUC score: \\033[1m{}\\033[0m\".format(round(roc_auc_score(y, oof_cb), 5)))\n\nelapsed_time = time.time() - start\n\nprint(\"\\nAverage Elapsed time for \\033[1mCatboost Pool\\033[0m input: \\t\\t \\033[1m{}\\033[0m seconds\".format(elapsed_time \/ 5))","65563e99":"start = time.time()\n\ntrain_pool = Pool(X, label = y)\ntrain_pool.quantize(task_type = \"GPU\")\n\noof_cb = np.zeros(len(X))\n\ni = 0\n\nwhile i < 5:\n    \n    for train_ix, test_ix in kf.split(X.values):\n\n        tr_pool = train_pool.slice(train_ix)\n        val_pool = train_pool.slice(test_ix)\n\n        model_cb.fit(\n            tr_pool,\n            eval_set = [(val_pool)],\n            early_stopping_rounds = 50,\n            use_best_model = True,\n            verbose = 0,\n        )\n\n        oof_cb[test_ix] = oof_cb[test_ix] + model_cb.predict_proba(val_pool)[:, 1]\n    \n    i += 1\n    \nprint(\"AUC score: \\033[1m{}\\033[0m\".format(round(roc_auc_score(y, oof_cb), 5)))\n\nelapsed_time = time.time() - start\n\nprint(\"\\nAverage Elapsed time for \\033[1mCatboost Pool quantized\\033[0m input: \\t\\t \\033[1m{}\\033[0m seconds\".format(elapsed_time \/ 5))","b96615ca":"**Reusing quantized datasets outperforms other methods as mentioned** [here](https:\/\/catboost.ai\/docs\/concepts\/speed-up-training.html#reuzing-quantized-datasets) \n\n**You should use Pool for Catboost models. It improves performance drastically.**\n\n\n**Note**: Using catboost with GPU doesn't guarantee reproducibility. https:\/\/github.com\/catboost\/catboost\/issues\/546#issuecomment-440647874\n\n\n[take me to the top](#section-top)","78c2da41":"<a id=\"section-two-three\"><\/a>\n# 2.3 Catboost Pool with quantize\n\nhttps:\/\/catboost.ai\/docs\/concepts\/speed-up-training.html\n\n> **By default, the train and test datasets are quantized each time that the boosting is run.**\n","d0d63c63":"<a id=\"section-top\"><\/a>\n\n* [Introduction](#section-zero)\n* [Data Preparation](#section-one)\n* [Model Comparison](#section-two)\n\n    - [Input: Numpy Arrays](#section-two-one)\n    - [Input: Catboost Pool](#section-two-two)\n    - [Catboost Pool with quantize](#section-two-three)\n\n\n* [Conclusion](#section-three)\n* [More](#section-four)","e4c3e59d":"<a id=\"section-two-one\"><\/a>\n# 2.1 Input: Numpy Arrays","3abc03d9":"<a id=\"section-three\"><\/a>\n\n# 3. Conclusion","a3cd0c86":"[take me to the top](#section-top)","635c71bf":"[take me to the top](#section-top)","b047626c":"<a id=\"section-zero\"><\/a>\n# 0. Introduction\n\nIn this notebook, I will compare Catboost's speed with different inputs;\n\n**Numpy arrays**,\n\n**Catboost Pool**,\n\n**Catboost Pool w\/ quantize**\n","9af31341":"[take me to the top](#section-top)","1205aa41":"<a id=\"section-two\"><\/a>\n# 2. Model Comparison","a8e8bdfb":"[take me to the top](#section-top)","00c86113":"<a id=\"section-four\"><\/a>\n\n# 4. More\n\nCatboost GPU performance - https:\/\/github.com\/catboost\/catboost\/issues\/505#issuecomment-431484934\n\nCatboost GPU reproducibility - https:\/\/github.com\/catboost\/catboost\/issues\/546\n\nCatboost Pool documentation - https:\/\/catboost.ai\/docs\/concepts\/python-reference_pool.html\n\nCatboost speeding up training suggestions - https:\/\/catboost.ai\/docs\/concepts\/speed-up-training.html\n\n\n\n**My notebooks similar to this one:**\n\nhttps:\/\/www.kaggle.com\/mustafacicek\/subsample-for-boosting-models\n\nhttps:\/\/www.kaggle.com\/mustafacicek\/xgboost-train-and-fit-comparison\n\n\n[take me to the top](#section-top)","d268c37c":"<a id=\"section-one\"><\/a>\n# 1. Data Preparation","27d80215":"2000 iterations with 0.1 learning rate.\n\nOut of folds predictions for 5 folds.\n\n**Input is numpy arrays, generally all we did.**","2c800e4a":"<a id=\"section-two-two\"><\/a>\n# 2.2 Input: Catboost Pool\n\nhttps:\/\/catboost.ai\/docs\/concepts\/python-reference_pool.html\n\nCreate a Pool object simply\n\n> **Pool(data, label, ...)**\n\n*For example\n\nPool(X, label = y)","a82d87b3":"Simply, I just created new feature \"missing\", filled missing values and scaled the with standard scaler.","578ff3eb":"I define simple catboost classifier with default parameters. I only set iterations to 2000 for better comparison.\n\nFor comparison, I will use out of folds predictions."}}