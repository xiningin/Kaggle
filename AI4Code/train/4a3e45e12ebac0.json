{"cell_type":{"4984d322":"code","2cf85f0a":"code","bb0795c5":"code","f3e8ebcd":"code","ead65f01":"code","8587eb8d":"code","3d64d076":"code","5fa05802":"code","a10f5bec":"code","9125c71b":"code","d6b6cf04":"code","ca3d995a":"code","ae982524":"code","48388c03":"code","568fdd9a":"code","1b482651":"code","868c84fc":"code","0841dd24":"code","517078bb":"code","86275274":"code","39bc9357":"code","35fe4db5":"code","e5cc05cf":"code","faf8dc1e":"code","3dbdab0d":"code","ee89a976":"code","34d896fc":"code","304334c3":"code","74114385":"code","266830c8":"code","bf33a9a5":"code","0bc6ec16":"code","a53d78c0":"code","e49e17ef":"code","c9d74035":"code","414019ef":"code","98cc5609":"code","fd70bddf":"code","1fa5b74d":"code","1a3af442":"markdown","4ef122c1":"markdown","19891a27":"markdown","17f93343":"markdown","4f072508":"markdown","8cf851e1":"markdown","7a98da73":"markdown","42413ebb":"markdown"},"source":{"4984d322":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n#import pandas as pd\n#import numpy as np\nimport operator\nimport time\n#import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set(style=\"ticks\", color_codes=True)\n\n\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","2cf85f0a":"items=pd.read_csv('..\/input\/item_properties_part1.csv')\nitems1=pd.read_csv('..\/input\/item_properties_part2.csv')\nitems=pd.concat([items1,items])\n\nitems.head()","bb0795c5":"items.shape","f3e8ebcd":"import datetime\ntimes=[]\nfor i in items['timestamp']:\n    times.append(datetime.datetime.fromtimestamp(i\/\/1000.0))\n    ","ead65f01":"items['timestamp']=times","8587eb8d":"#items.to_csv('..\/input\/items.csv')\nitems.head()","3d64d076":"events=pd.read_csv('..\/input\/events.csv')","5fa05802":"events.head\nevents.shape","a10f5bec":"visitors=events[\"visitorid\"].unique()\nprint('Visitor count on actions:',events[\"visitorid\"].shape)\nprint('Total unique visitors :',visitors.shape)\n#unique visitors are almost half the number of total visitors","9125c71b":"events[\"event\"].unique()\n","d6b6cf04":"print(events[\"transactionid\"].dropna().unique().shape[0])\nprint(events[\"transactionid\"].dropna().shape[0])\n","ca3d995a":"print(events[\"itemid\"].unique().shape)\n#events[\"itemid\"].unique()","ae982524":"events_count=events[\"event\"].value_counts()\nfig, axs = plt.subplots(ncols=2,figsize=(15, 8))\nsns.barplot(events_count.index, events_count.values, ax=axs[0])\n\nevents_count=events[\"event\"].value_counts()[1:]\n#plt.title('Actions Vs Count')\ng=sns.barplot(events_count.index, events_count.values,ax=axs[1])\n#g.set_yscale('log')\nevents_count=events[\"event\"].value_counts()[1:]\nplt.title('Add-to-cart V\/s Transaction')\nsns.barplot(events_count.index, events_count.values)\n\nprint(events_count)","48388c03":"data = events.event.value_counts()\nlabels = data.index\nsizes = data.values\nexplode = (0, 0.05, 0.15)\nfig, ax = plt.subplots(figsize=(8,8))\n\npatches, texts, autotexts = ax.pie(sizes, labels=labels, explode=explode, autopct='%1.2f%%', shadow=False, startangle=0) \n\nax.axis('equal')\nplt.show()","568fdd9a":"#sns.factorplot(\"sex\", \"survival_rate\", col=\"class\", data=df, kind=\"bar\")\n","1b482651":"grouped=events.groupby('event')['itemid'].apply(list)\n","868c84fc":"views=grouped['view']\ncount_view={}\n#for item in set(views[:]):\n    #print(item)\n#    count_view[item]=views.count(item)\nviews=np.array(views[:])\n\nunique, counts = np.unique(views, return_counts=True)\ncount_view=dict(zip(unique, counts))\nsorted_count_view =sorted(count_view.items(), key=operator.itemgetter(1),reverse=True)\nx=[i[0] for i in sorted_count_view[:5]]\ny=[i[1] for i in sorted_count_view[:5]]\nsns.barplot(x,y,order=x)\n","0841dd24":"#the most addtocart itemid\naddtocart=grouped['addtocart']\ncount_addtocart={}\n# for item in set(addtocart[:]):\n#     #print(item)\n#     count_addtocart[item]=addtocart.count(item)\naddtocart=np.array(addtocart[:])\nunique, counts = np.unique(addtocart, return_counts=True)\ncount_addtocart=dict(zip(unique, counts))\n\nsorted_count_addtocart =sorted(count_addtocart.items(), key=operator.itemgetter(1),reverse=True)\nx=[i[0] for i in sorted_count_addtocart[:5]]\ny=[i[1] for i in sorted_count_addtocart[:5]]\ng=sns.barplot(x,y, order=x)","517078bb":"#the most transaction itemid\ntransaction=grouped['transaction']\ncount_transaction={}\n# for item in set(transaction[]):\n#     #print(item)\n#     count_transaction[item]=transaction.count(item)\ntransaction=np.array(transaction[:])\nunique, counts = np.unique(transaction, return_counts=True)\ncount_transaction=dict(zip(unique, counts))\n\nsorted_count_transaction =sorted(count_transaction.items(), key=operator.itemgetter(1),reverse=True)\nx=[i[0] for i in sorted_count_transaction[:5]]\ny=[i[1] for i in sorted_count_transaction[:5]]\ng=sns.barplot(x,y, order=x)","86275274":"items = events.itemid.value_counts()\nplt.figure(figsize=(16, 9))\nplt.hist(items.values, bins=10, log=True,color='red')\nplt.xlabel('Number of times item appeared', fontsize=16)\nplt.ylabel('Count of displays with item', fontsize=16)\nplt.show()\n","39bc9357":"#number of total views, number of avg view by top users(quantile 90% and also all users)\ngrouped=events.groupby('event')['visitorid'].apply(list)\nviews=grouped['view']\ncount_view={}\n# for item in set(views[:]):\n#     #print(item)\n#     count_view[item]=views.count(item)\n\nviews=np.array(views[:])\n\nunique, counts = np.unique(views, return_counts=True)\ncount_view=dict(zip(unique, counts))\n\nsorted_count_view =sorted(count_view.items(), key=operator.itemgetter(1),reverse=True)\nx=[i[0] for i in sorted_count_view[:5]]\ny=[i[1] for i in sorted_count_view[:5]]\nsns.barplot(x,y,order=x)","35fe4db5":"#number of total transactions, number of avg transactions by top users(quantile 90% and also all users)\ntransaction=grouped['transaction']\ncount_transaction={}\n# for item in set(transaction:\n#     #print(item)\n#     count_transaction[item]=transaction.count(item)\ntransaction=np.array(transaction[:])\nunique, counts = np.unique(transaction, return_counts=True)\ncount_transaction=dict(zip(unique, counts))\nsorted_count_transaction =sorted(count_transaction.items(), key=operator.itemgetter(1),reverse=True)\nx=[i[0] for i in sorted_count_transaction[:5]]\ny=[i[1] for i in sorted_count_transaction[:5]]\ng=sns.barplot(x,y, order=x)\n","e5cc05cf":"#number of total addtocart, number of avg addtocart by top users(quantile 90% and also all users)\naddtocart=grouped['addtocart']\ncount_addtocart={}\n# for item in set(addtocart[:]):\n#     #print(item)\n#     count_addtocart[item]=addtocart.count(item)\naddtocart=np.array(addtocart[:])\nunique, counts = np.unique(addtocart, return_counts=True)\ncount_addtocart=dict(zip(unique, counts))\nsorted_count_addtocart =sorted(count_addtocart.items(), key=operator.itemgetter(1),reverse=True)\nx=[i[0] for i in sorted_count_addtocart[:5]]\ny=[i[1] for i in sorted_count_addtocart[:5]]\ng=sns.barplot(x,y, order=x)","faf8dc1e":"items = events.visitorid.value_counts()\nplt.figure(figsize=(16, 9))\nplt.hist(items.values, bins=20, log=True,color='red')\nplt.xlabel('Number of times visitor appeared', fontsize=16)\nplt.ylabel('Count of displays with visitor', fontsize=16)\nplt.show()\n","3dbdab0d":"#most active user(s)   3 plot of each with view,add,transaction events\nallevents=list(events['visitorid'])\ncount_allevents={}\n# for item in set(allevents[:]):\n#    # print(item)\n#     count_allevents[item]=allevents.count(item)\nallevents=np.array(allevents)\nunique, counts = np.unique(allevents, return_counts=True)\ncount_allevents=dict(zip(unique, counts))\nsorted_count_allevents =sorted(count_allevents.items(), key=operator.itemgetter(1),reverse=True)\nx=[i[0] for i in sorted_count_allevents[:5]]\ny=[i[1] for i in sorted_count_allevents[:5]]\ng=sns.barplot(x,y, order=x)","ee89a976":"#most active item(s)   3 plot of each with view,add,transaction events\nallevents=list(events['itemid'])\ncount_allevents={}\n# for item in set(allevents[:]):\n#    # print(item)\n#     count_allevents[item]=allevents.count(item)\nallevents=np.array(allevents)\nunique, counts = np.unique(allevents, return_counts=True)\ncount_allevents=dict(zip(unique, counts))\nsorted_count_allevents =sorted(count_allevents.items(), key=operator.itemgetter(1),reverse=True)\nx=[i[0] for i in sorted_count_allevents[:5]]\ny=[i[1] for i in sorted_count_allevents[:5]]\ng=sns.barplot(x,y, order=x)","34d896fc":"#Create\n##########df= as below\n\n#visitorid event count\n#1   view 100\n#1   addtocart   50\n#1   transa    5\n#2   view 100\n#2   addtocart   50\n#2   transa    5\n#3   view 100\n#3   addtocart   50\n#3   transa    5\nprint(events.head())\nitems.head()\n#ax = sns.catplot(x=x, y='visitorid',hue=\"event\", data=events.iloc[:,:])\n\n##\n#x=[[1,2,3],[1,2,3],[12,1,2]]\n#y=[1,2,3]\n#sns.barplot(x,x)\n##\n#top 5-10 in each category plots and all category plots(stacked charts in all categories)\n\n","304334c3":"events.itemid.value_counts().describe()","74114385":"events[events.event == 'view'].itemid.value_counts().describe()","266830c8":"events[events.event == 'addtocart'].itemid.value_counts().describe()","bf33a9a5":"events[events.event == 'transaction'].itemid.value_counts().describe()","0bc6ec16":"corr = events[events.columns].corr()\nsns.heatmap(corr,annot = True)\n","a53d78c0":"#time vs event","e49e17ef":"import scipy.sparse as sp\nfrom scipy.sparse import vstack\nfrom scipy import sparse\nfrom scipy.sparse.linalg import spsolve\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nfrom sklearn.model_selection import train_test_split\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\nevents = pd.read_csv('..\/input\/events.csv')\ncategory_tree = pd.read_csv('..\/input\/category_tree.csv')\nitems1 = pd.read_csv('..\/input\/item_properties_part1.csv')\nitems2 = pd.read_csv('..\/input\/item_properties_part2.csv')\nitems = pd.concat([items1, items2])","c9d74035":"n_users = events['visitorid'].unique().shape[0]\nn_items = items['itemid'].max()\nprint (str(n_users) +\" \" +  str(n_items))\nuser_to_item_matrix = sp.dok_matrix((n_users+1, n_items+2), dtype=np.int8)","414019ef":"action_weights = [1,2,3]\nfor row in events.itertuples():\n#    if row[2] not in user_with_buy:\n#        continue\n#    mapped_user_key = user_with_buy[row[2]]\n    mapped_user_key = row[2]\n    if row.event == 'view':\n            user_to_item_matrix[mapped_user_key, row[4]] = action_weights[0]\n    elif row.event == 'addtocart':\n            user_to_item_matrix[mapped_user_key, row[4]] = action_weights[1]        \n    elif row.event == 'transaction':\n            user_to_item_matrix[mapped_user_key, row[4]] = action_weights[2]\nuser_to_item_matrix = user_to_item_matrix.tocsr()\nprint (user_to_item_matrix.shape)","98cc5609":"sparsity = float(len(user_to_item_matrix.nonzero()[0]))\nsparsity \/= (user_to_item_matrix.shape[0] * user_to_item_matrix.shape[1])\nsparsity *= 100\nprint (sparsity)\nX_train, X_test = train_test_split(user_to_item_matrix, test_size=0.20)\nX_train.shape\nX_test.shape","fd70bddf":"from sklearn.metrics.pairwise import cosine_similarity\n# TODO: this is user to user similarity. check item to item similarity as well\ncosine_similarity_matrix = cosine_similarity(X_train, X_train, dense_output=False)\ncosine_similarity_matrix.setdiag(0)\ncosine_similarity_matrix_ll=cosine_similarity_matrix.tolil()\ncosine_similarity_matrix.head()","1fa5b74d":"from datetime import datetime, timedelta\nfrom sklearn import preprocessing\nfrom lightfm import LightFM\nfrom scipy.sparse import csr_matrix \nfrom scipy.sparse import coo_matrix \nfrom sklearn.metrics import roc_auc_score\nimport time\nfrom lightfm.evaluation import auc_score\nimport pickle\n\ndef create_data(datapath,start_date,end_date):\n    df=pd.read_csv(datapath)\n    df=df.assign(date=pd.Series(datetime.fromtimestamp(a\/1000).date() for a in df.timestamp))\n    df=df.sort_values(by='date').reset_index(drop=True) # for some reasons RetailRocket did NOT sort data by date\n    df=df[(df.date>=datetime.strptime(start_date,'%Y-%m-%d').date())&(df.date<=datetime.strptime(end_date,'%Y-%m-%d').date())]\n    df=df[['visitorid','itemid','event']]\n    return df\n\ndef create_implicit_feedback_matrix(df, split_ratio):\n    # assume df.columns=['visitorid','itemid','event']\n    id_cols=['visitorid','itemid']\n    trans_cat=dict()\n    for k in id_cols:\n        cate_enc=preprocessing.LabelEncoder()\n        trans_cat[k]=cate_enc.fit_transform(df[k].values)\n    cate_enc=preprocessing.LabelEncoder()\n    ratings=cate_enc.fit_transform(df.event) \n    n_users=len(np.unique(trans_cat['visitorid']))\n    n_items=len(np.unique(trans_cat['itemid']))    \n    split_point=np.int(np.round(df.shape[0]*split_ratio))\n    \n    rate_matrix=dict()\n    rate_matrix['train']=coo_matrix((ratings[0:split_point],(trans_cat['visitorid'][0:split_point],\\\n                                              trans_cat['itemid'][0:split_point]))\\\n                             ,shape=(n_users,n_items))\n    rate_matrix['test']=coo_matrix((ratings[split_point+1::],(trans_cat['visitorid'][split_point+1::],\\\n                                              trans_cat['itemid'][split_point+1::]))\\\n                             ,shape=(n_users,n_items))\n    return rate_matrix\n\ndef create_implicit_feedback_matrix1(df, split_ratio):\n    # assume df.columns=['visitorid','itemid','event']\n    split_point=np.int(np.round(df.shape[0]*split_ratio))\n    df_train=df.iloc[0:split_point]\n    df_test=df.iloc[split_point::]\n    df_test=df_test[(df_test['visitorid'].isin(df_train['visitorid']))&\\\n                     (df_test['itemid'].isin(df_train['itemid']))]\n    id_cols=['visitorid','itemid']\n    trans_cat_train=dict()\n    trans_cat_test=dict()\n    for k in id_cols:\n        cate_enc=preprocessing.LabelEncoder()\n        trans_cat_train[k]=cate_enc.fit_transform(df_train[k].values)\n        trans_cat_test[k]=cate_enc.transform(df_test[k].values)\n    \n    # --- Encode ratings:\n    cate_enc=preprocessing.LabelEncoder()\n    ratings=dict()\n    ratings['train']=cate_enc.fit_transform(df_train.event)\n    ratings['test'] =cate_enc.transform(df_test.event)\n    \n    n_users=len(np.unique(trans_cat_train['visitorid']))\n    n_items=len(np.unique(trans_cat_train['itemid']))    \n    \n    \n    rate_matrix=dict()\n    rate_matrix['train']=coo_matrix((ratings['train'],(trans_cat_train['visitorid'],\\\n                                              trans_cat_train['itemid']))\\\n                             ,shape=(n_users,n_items))\n    rate_matrix['test']=coo_matrix((ratings['test'],(trans_cat_test['visitorid'],\\\n                                              trans_cat_test['itemid']))\\\n                             ,shape=(n_users,n_items))\n    return rate_matrix\n\nif __name__=='__main__':\n    start_time = time.time()\n    df=create_data('..\/input\/events.csv','2015-5-3','2015-5-18')\n    modelLoad=False\n    rating_matrix=create_implicit_feedback_matrix1(df,.8)\n    if(modelLoad):\n        with open('saved_model','rb') as f:\n            saved_model=pickle.load(f)\n            model=saved_model['model']\n    else:\n        model=LightFM(no_components=5,loss='warp')\n        model.fit(rating_matrix['train'],epochs=100,num_threads=1)\n        with open('saved_model','wb') as f:\n            saved_model={'model':model}\n            pickle.dump(saved_model, f)\n    auc_train = auc_score(model, rating_matrix['train']).mean()\n    auc_test = auc_score(model, rating_matrix['test']).mean()\n    \n    #df=df.assign(pred_score=model.predict(df['visitorid'],df['itemid']))\n    \n    #df_auc=df.groupby(by='visitorid').apply(lambda df: roc_auc_score(df['event'].values,df['pred_score'].values))\n    #print('Training auc %0.3f' % numpy.mean([i for i in df_auc.values if i > -1]))","1a3af442":"**Number of items (count unique itemid)**","4ef122c1":"We can see that: 78.6% data are single transactional sets.So MBA wont work well","19891a27":"**Count of Actions and its plot**","17f93343":"As View count is too much, o get a clear idea over add-to-cart and transaction actions I created a seperate plot","4f072508":"Event-wise Detailing","8cf851e1":"Types of actions\/events: ","7a98da73":"**The number of visitors is half the count of visitors who did some actions.**","42413ebb":"**Only 5 thousands of transactions repeated, rest 22457 were different so, Market basket analysis wouldnt be so perfect\n**"}}