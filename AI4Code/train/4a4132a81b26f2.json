{"cell_type":{"7a49c134":"code","8ef86974":"code","8924e520":"code","e4a05cfb":"code","d672f382":"code","c14592b3":"code","bf0056f5":"code","7cb556d7":"code","3d2801e8":"code","ac9cfcd9":"code","56b8e33d":"code","f2562fd1":"code","0e4c1dba":"code","add7a7b3":"code","57e89916":"code","28313858":"markdown","784bab0c":"markdown","6ac50613":"markdown","3bbe74c9":"markdown","324f2948":"markdown"},"source":{"7a49c134":"import torch \nimport torchvision\nimport numpy as np\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport torch.optim as optim\nimport torchvision.models as models\nfrom torchvision.utils import make_grid\n\nimport time\nimport os\nimport copy\nimport matplotlib.pyplot as plt\n%matplotlib inline","8ef86974":"# number of subprocesses to use for data loading\nnum_workers = 0\n# how many samples per batch to load\nbatch_size = 32\n# percentage of training set to use as validation\nvalid_size = 0.2\n\n#Using the mean and std of Imagenet is a common practice. They are calculated based on millions of images.\n#Using the Imagenet pretrianed model with its own mean and std is recommended.\nstats = ((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# convert data to a normalized torch.FloatTensor\ntrain_transforms = transforms.Compose([transforms.RandomRotation(30),\n                                       transforms.RandomResizedCrop(224),\n                                       transforms.RandomHorizontalFlip(),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize([0.485, 0.456, 0.406],\n                                                            [0.229, 0.224, 0.225])])\n\ntest_transforms = transforms.Compose([transforms.Resize(255),\n                                      transforms.CenterCrop(224),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406],\n                                                           [0.229, 0.224, 0.225])])","8924e520":"data_dir='..\/input\/flowers-recognition\/flowers\/flowers'\nprint(os.listdir(data_dir))","e4a05cfb":"dataset = datasets.ImageFolder(data_dir, transform=train_transforms)\n\nlen_train_set = int(0.8*len(dataset))\nlen_test_set = len(dataset) - len_train_set\n# repare datasets.train_data will be use for training,and test_data for final test\ntrain_data, test_data = torch.utils.data.random_split(dataset, [len_train_set, len_test_set])","d672f382":"num_train = len(train_data)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nsplit = int(np.floor(valid_size * num_train))\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\n# define samplers for obtaining training and validation batches\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\n# prepare data loaders (combine dataset and sampler)\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers,sampler=train_sampler)\nvalid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers,sampler=valid_sampler)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)","c14592b3":"# Function making denormalizing images\ndef denormalize(images, means, stds):\n    if len(images.shape) == 3:\n        images = images.unsqueeze(0)\n    means = torch.tensor(means).reshape(1, 3, 1, 1)\n    stds = torch.tensor(stds).reshape(1, 3, 1, 1)\n    return images * stds + means\n\ndef show_image(img_tensor, label):\n    print('Label:', dataset.classes[label], '(' + str(label) + ')')\n    img_tensor = denormalize(img_tensor, *stats)[0].permute((1, 2, 0))\n    plt.imshow(img_tensor)\n    \n\ndef show_batch(dl):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(12, 12))\n        ax.set_xticks([]); ax.set_yticks([])\n        images = denormalize(images, *stats)\n        ax.imshow(make_grid(images[:64], nrow=8).permute(1, 2, 0),)\n        print(' '.join('%15s' % dataset.classes[int(label)] for label in labels))\n        break","bf0056f5":"show_batch(train_loader)","7cb556d7":"show_image(*dataset[0])","3d2801e8":"# we are using  pretrained on ImageNet model resnet34\nmodel_conv = torchvision.models.resnet34(pretrained=True)\nfor param in model_conv.parameters():\n    param.requires_grad = False\n\n# Parameters of newly constructed modules have requires_grad=True by default\nnum_ftrs = model_conv.fc.in_features\nmodel_conv.fc = torch.nn.Linear(num_ftrs, 5)\n\nmodel_conv = model_conv.to(device)","ac9cfcd9":"optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\nexp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n\ncriterion = torch.nn.CrossEntropyLoss()\n\ndataloaders = {'train': train_loader, 'val': valid_loader}\ndataset_sizes = {x: len(dataloaders[x]) for x in ['train', 'val']}","56b8e33d":"def train_model(model, criterion, optimizer,scheduler, num_epochs=25):\n    since = time.time()\n    \n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","f2562fd1":"model_ft = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler,num_epochs=25)","0e4c1dba":"def visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['val']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images\/\/2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title('predicted: {}'.format(dataset.classes[preds[j]]))\n                plt.imshow(inputs[j].cpu().permute(1, 2, 0).clamp(0, 1))\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)","add7a7b3":"visualize_model(model_conv)","57e89916":"result = 0\ncounter = 0\nwith torch.no_grad():\n        for i, (inputs, labels) in enumerate(test_loader):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model_conv(inputs)\n            _, preds = torch.max(outputs, 1)\n            result += int(sum(labels == preds))\n            counter += len(labels)\n        \nprint('Correct_answers - {0}, Total_answers - {1}, Percent_corrects - {2}'.format(result, counter,result\/counter))","28313858":"# 4) Test stage","784bab0c":"# 3) Training stage","6ac50613":"# 1)Import necessary libraries","3bbe74c9":"# 2) Prepairing data,making dataloader","324f2948":"# Conclusion\n1) Our model has the final_score=85%.It's not bad\n2)We can try to use another model for training(efficientnet,googlenet e.g.)\n3)We can try another optimizer(Adam)\n4)We can try another scheduler"}}