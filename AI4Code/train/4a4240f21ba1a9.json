{"cell_type":{"de7782a6":"code","a9e7662e":"code","215f161c":"code","76779d4b":"code","da2dbf0e":"code","3459ce4c":"code","47fbf32e":"code","ac4f50e8":"code","7511c4e0":"markdown","abb81e42":"markdown","94404bb4":"markdown","927608ef":"markdown","a5984089":"markdown","dd86808d":"markdown","e8deeece":"markdown"},"source":{"de7782a6":"import sys\nsys.path.append(\"..\/input\/tez-lib\/\")\nsys.path.append(\"..\/input\/timmmaster\/\")","a9e7662e":"import tez\nimport albumentations\nimport pandas as pd\nimport cv2\nimport numpy as np\nimport timm\nimport torch.nn as nn\nfrom sklearn import metrics\nimport torch\nfrom tez.callbacks import EarlyStopping\nfrom tqdm import tqdm\nimport os","215f161c":"class args:\n    batch_size = 16\n    image_size = 224\n    epochs = 10\n    fold = 9","76779d4b":"class PawpularDataset:\n    def __init__(self, image_paths, targets, augmentations):\n        self.image_paths = image_paths\n        self.targets = targets\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):\n        try:\n            image = cv2.imread(self.image_paths[item])\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        except:\n            print(self.image_paths[item])\n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n            \n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        \n        targets = self.targets[item]\n        \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.float),\n        }","da2dbf0e":"class PawpularModel(tez.Model):\n    def __init__(self):\n        super().__init__()\n\n        self.model = timm.create_model(\"tf_efficientnet_b0_ns\", pretrained=True, in_chans=3)\n        self.model.classifier = nn.Linear(self.model.classifier.in_features, 128)\n        self.dropout = nn.Dropout(0.1)\n        self.dense1 = nn.Linear(128, 64)\n        self.dense2 = nn.Linear(64, 1)\n        self.sigmoid = nn.Sigmoid()\n\n        \n        self.step_scheduler_after = \"epoch\"\n\n    def monitor_metrics(self, outputs, targets):\n        outputs = outputs.cpu().detach().numpy()\n        targets = targets.cpu().detach().numpy()\n        rmse = metrics.mean_squared_error(targets, outputs, squared=False)\n        return {\"rmse\": rmse}\n\n    def fetch_scheduler(self):\n        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n            self.optimizer, T_0=10, T_mult=1, eta_min=1e-4, last_epoch=-1\n        )\n        return sch\n\n    def fetch_optimizer(self):\n        opt = torch.optim.Adam(self.parameters(), lr=1e-3)\n        return opt\n\n    def forward(self, image, targets=None):\n\n        x = self.model(image)\n        x = self.dropout(x)\n        x = self.dense1(x)\n        x = self.dense2(x)\n        x = self.sigmoid(x)\n        \n        if targets is not None:\n            loss = nn.MSELoss()(x, targets.view(-1, 1))\n            metrics = self.monitor_metrics(x, targets)\n            return x, loss, metrics\n        return x, 0, {}","3459ce4c":"train_aug = albumentations.Compose(\n    [\n        albumentations.Resize(args.image_size, args.image_size, p=1),\n        albumentations.HueSaturationValue(\n            hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5\n        ),\n        albumentations.HorizontalFlip(p = 0.5),\n        albumentations.VerticalFlip(p=0.5),\n        albumentations.RandomBrightnessContrast(\n            brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5\n        ),\n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)\n\n\nvalid_aug = albumentations.Compose(\n    [\n        albumentations.Resize(args.image_size, args.image_size, p=1),\n        albumentations.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n            max_pixel_value=255.0,\n            p=1.0,\n        ),\n    ],\n    p=1.0,\n)","47fbf32e":"df = pd.read_csv(\"..\/input\/fake-fold-10\/train_10folds.csv\")\ndf['Pawpularity'] = df['Pawpularity'] \/ 100\nvaccum = []\nfor path in df[\"PetID\"].values:\n    if os.path.exists(f\"..\/input\/petfinder-adoption-prediction\/train_images\/{path}-1.jpg\") == False:\n        vaccum.append(path)\n\ndel_index = df[df['PetID'].isin(vaccum)].index\ndf = df.drop(del_index)\ndf_train = df[df.kfold != args.fold].reset_index(drop=True)\ndf_valid = df[df.kfold == args.fold].reset_index(drop=True)","ac4f50e8":"for fold in range(10):\n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n    train_img_paths = [f\"..\/input\/petfinder-adoption-prediction\/train_images\/{x}-1.jpg\" for x in df_train[\"PetID\"].values]\n    valid_img_paths = [f\"..\/input\/petfinder-adoption-prediction\/train_images\/{x}-1.jpg\" for x in df_valid[\"PetID\"].values]\n    train_dataset = PawpularDataset(\n    image_paths=train_img_paths,\n    targets=df_train.Pawpularity.values,\n    augmentations=train_aug,\n    )\n\n    valid_dataset = PawpularDataset(\n        image_paths=valid_img_paths,\n        targets=df_valid.Pawpularity.values,\n        augmentations=valid_aug,\n    )\n    model = PawpularModel()\n    es = EarlyStopping(\n        monitor=\"valid_rmse\",\n        model_path=f\"model_f{fold}.bin\",\n        patience=10,\n        mode=\"min\",\n        save_weights_only=True,\n    )\n\n    model.fit(\n        train_dataset,\n        valid_dataset=valid_dataset,\n        train_bs=args.batch_size,\n        valid_bs=2*args.batch_size,\n        device=\"cuda\",\n        epochs=args.epochs,\n        callbacks=[es],\n        fp16=True,\n    )","7511c4e0":"# import the package","abb81e42":"# prepare the dataset and the model","94404bb4":"# My results:\n     I got bad score by doing this way. Hope anyone can make use of it and share me the way how to get a good score. XD","927608ef":"# Use external dataset","a5984089":"# augmentation","dd86808d":"# load the dataset","e8deeece":"This notebook use the dataset from the previous competitions.https:\/\/www.kaggle.com\/c\/petfinder-adoption-prediction\n\nThanks for Chris Deotte to share the idea. https:\/\/www.kaggle.com\/c\/petfinder-pawpularity-score\/discussion\/278925\n\nThanks for ABHISHEK THAKUR to share the notebook baseline. https:\/\/www.kaggle.com\/abhishek\n"}}