{"cell_type":{"63e567a8":"code","29c7e435":"code","cc58ca98":"code","1a73b50c":"code","9c5728a0":"code","4f8650af":"code","ba972398":"code","ecaada57":"code","2e781a29":"code","3a000cda":"code","380715e0":"code","f8bfbf19":"code","28a11508":"code","4a45e380":"markdown","ed67280f":"markdown","89e0d39a":"markdown","f3a8c94c":"markdown","fbf23db0":"markdown","df761be1":"markdown","ce12d6b3":"markdown","7445b9f0":"markdown"},"source":{"63e567a8":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport os","29c7e435":"classes = os.listdir(\"..\/input\/flowers-recognition\/flowers\")\nclasses","cc58ca98":"image_size = (64, 64)\nbatch_size = 32\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    \"..\/input\/flowers-recognition\/flowers\",\n    validation_split=0.2,\n    subset=\"training\",\n    seed=1337,\n    image_size=image_size,\n    batch_size=batch_size,\n    label_mode=\"categorical\",\n    class_names=classes\n)\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    \"..\/input\/flowers-recognition\/flowers\",\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=1337,\n    image_size=image_size,\n    batch_size=batch_size,\n    label_mode=\"categorical\",\n    class_names=classes\n)","1a73b50c":"import matplotlib.pyplot as plt\n\n#plt.figure(figsize=(20, 10))\nplt.figure()\nfor images, labels in train_ds.take(1):\n    for i in range(15):\n        ax = plt.subplot(3, 5, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(classes[np.argmax(labels[i])])\n        plt.axis(\"off\")\nplt.show()","9c5728a0":"from tensorflow.keras.applications.resnet import ResNet101\n\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n\n\nbase_model = ResNet101(weights='imagenet', include_top=False)\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(512, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dense(256, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\npredictions = Dense(len(classes), activation='softmax')(x)\n\n# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[\"accuracy\"],)","4f8650af":"# train the model on the new data for a few epochs\nhistory = model.fit(train_ds, epochs=50, validation_data=val_ds)","ba972398":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nxepochs = [x for x in range (len(history.history['loss']))]\n\nfig = make_subplots(rows=1, cols=2, subplot_titles=(\"Accuracy over time\", \"Loss over time\"))\n\nfor metric in ['accuracy', 'val_accuracy']:\n    fig.add_trace(go.Scatter(x=xepochs, y=history.history[metric], mode='lines+markers', name=metric), row=1, col=1)\n\nfor metric in ['loss', 'val_loss']:\n    fig.add_trace(go.Scatter(x=xepochs, y=history.history[metric], mode='lines+markers', name=metric), row=1, col=2)\n\nfig.update_xaxes(title_text=\"Epoch\", row=1, col=1)\nfig.update_xaxes(title_text=\"Epoch\", row=1, col=2)\n\nfig.update_yaxes(title_text=\"Accuracy\", row=1, col=1)\nfig.update_yaxes(title_text=\"Loss\", row=1, col=2)\n\nfig.show()","ecaada57":"val_samples = sum([y.shape[0] for [_, y] in val_ds])\nval_samples","2e781a29":"y_val = []\ny_val_pred = []\n\nfor images, targets in val_ds:\n    for image, target in zip(images, targets):\n        img_array = image.numpy().astype(\"uint8\")\n        prediction = model.predict(np.array([img_array]))\n        y_val_pred.append(np.argmax(prediction))\n        y_val.append(np.argmax(target))","3a000cda":"from sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_val, y_val_pred)","380715e0":"import plotly.express as px\n\nfig = px.imshow(\n    cm,\n    labels=dict(x=\"Predicted\", y=\"Real\"),\n    x=classes,\n    y=classes\n)\n\nfig.update_xaxes(side=\"top\")\nfig.show()","f8bfbf19":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_val, y_val_pred, target_names=classes))","28a11508":"plt.figure(figsize=(20, 10))\nfor images, labels in val_ds.take(1):\n    for i in range(15):\n        ax = plt.subplot(3, 5, i + 1)\n        \n        img_array = images[i].numpy().astype(\"uint8\")\n        prediction = model.predict(np.array([img_array]))\n        prediction_name = classes[np.argmax(prediction)]\n        real_name = classes[np.argmax(labels[i])]\n        \n        plt.imshow(img_array)\n        if prediction_name == real_name:\n            plt.title(f'real: {real_name}\\npred:{prediction_name}', fontdict={'color': 'g'})\n        else:\n            plt.title(f'real: {real_name}\\npred:{prediction_name}', fontdict={'color': 'r'})\n        \n        plt.axis(\"off\")","4a45e380":"First I, tried transfer learning with one layer of 512 neurons on top:\n\n|Model          |Epochs         |loss           |accuracy       |val_loss       |val_accuracy   |\n|---------------|---------------|---------------|---------------|---------------|---------------|\n|Xception       |50             |0.5634         |0.7793         |1.8187         |0.5174         |\n|ResNet50       |50             |0.0372         |0.9870         |0.8755         |0.8495         |\n|ResNet101      |50             |0.0484         |0.9846         |0.8446         |0.8391         |\n|VGG16          |50             |0.0720         |0.9765         |0.9366         |0.8090         |\n|VGG19          |50             |0.0861         |0.9687         |0.8472         |0.8053         |\n\nSo I, update my dense layer on the top.\n","ed67280f":"# History Plots","89e0d39a":"# Classification Report","f3a8c94c":"# Confusion Matrix","fbf23db0":"# Import Images","df761be1":"# Images","ce12d6b3":"# Keras Models","7445b9f0":"# Predictions"}}