{"cell_type":{"4d8923e7":"code","b5bb461e":"code","7d377788":"code","a6554c14":"code","c0308e1f":"code","3f22b036":"code","06020561":"code","574569a5":"code","9a285248":"code","f1177f3d":"code","b432c5de":"code","8ca34c83":"code","33cc9e72":"code","4609d8e2":"code","de531cfd":"code","1f264ce8":"code","534517a4":"code","638357c9":"code","1a2561ed":"code","ffd0c758":"code","68c407e3":"code","de34973b":"code","1f3547bf":"code","32298814":"code","56f0366a":"code","ea0d5985":"code","0ac2de48":"markdown","960a00f4":"markdown","c13c6386":"markdown","1011da55":"markdown","30466df5":"markdown","70974ebe":"markdown","90d140be":"markdown","bf5a06e2":"markdown","36bdf162":"markdown","1cf4e152":"markdown","1dce5f45":"markdown"},"source":{"4d8923e7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n#Import necessary Libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nfrom tqdm import tqdm\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Flatten,Dense\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b5bb461e":"os.listdir(\"..\/input\/intel-image-classification\")","7d377788":"os.listdir(\"\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\/\")","a6554c14":"buildings = \"\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\/buildings\/\"\nstreet = \"\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\/street\/\"\nmountain = \"\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\/mountain\/\"\nglacier = \"\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\/glacier\/\"\nsea = \"\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\/sea\/\"\nforest = \"\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\/forest\/\"","c0308e1f":"print(\"Number of images in Train Directory: \")\n\nprint(\"Buildings :\",len(os.listdir(\"\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\/buildings\/\")))\nprint(\"Street: \",len(os.listdir(\"\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\/street\/\")))\nprint(\"Mountain:\",len(os.listdir(\"\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\/mountain\/\")))\nprint(\"Glacier: \",len(os.listdir(\"\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\/glacier\/\")))\nprint(\"Sea: \",len(os.listdir(\"\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\/sea\/\")))\nprint(\"Forest: \",len(os.listdir(\"\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\/forest\/\")))\n","3f22b036":"x = []\ny = []\nimport cv2\ndef create_dataset(directory,label_name):\n    for i in tqdm(os.listdir(directory)):\n        full_path = os.path.join(directory,i)\n        try:\n            img = cv2.imread(full_path)\n            img = cv2.resize(img,(120,120))\n        except:\n            continue\n\n        x.append(img)\n        y.append(label_name)\n    return x,y","06020561":"x,y = create_dataset(buildings,\"buildings\")\nx,y = create_dataset(street,\"street\")\nx,y = create_dataset(mountain,\"mountain\")\nx,y = create_dataset(glacier,\"glacier\")\nx,y = create_dataset(sea,\"sea\")\nx,y = create_dataset(forest,\"forest\")","574569a5":"x = np.array(x)\ny = np.array(y)\nprint(x.shape,y.shape)","9a285248":"fig =plt.figure(figsize=(12,7))\nfor i in range(10):\n    sample = random.choice(range(len(x)))\n    plt.subplot(2,5,i+1)\n    plt.subplots_adjust(hspace=0.3)\n    plt.imshow(x[sample])\n    plt.xlabel(y[sample])\n    \nplt.tight_layout()\nplt.show()","f1177f3d":"unique,counts = np.unique(y,return_counts=True)\nprint(unique,counts)","b432c5de":"plt.style.use(\"ggplot\")\nplt.figure(figsize=(9,7))\nsns.countplot(y)\nplt.show()","8ca34c83":"from sklearn.preprocessing import LabelEncoder,LabelBinarizer\nle = LabelEncoder()\ny = le.fit_transform(y)\n\nlb = LabelBinarizer()\ny = lb.fit_transform(y)","33cc9e72":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)","4609d8e2":"img_size=120\nx_train = np.array(x_train)\/255.0\nx_test = np.array(x_test)\/255.0\n\nx_train = x_train.reshape(-1,img_size,img_size,3)\ny_train = np.array(y_train)\n\nx_test = x_test.reshape(-1,img_size,img_size,3)\ny_test = np.array(y_test)","de531cfd":"from tensorflow.keras.applications.vgg19 import VGG19\nvgg= VGG19(weights=\"imagenet\",include_top=False,input_shape = (img_size,img_size,3))","1f264ce8":"for layer in vgg.layers:\n    layer.trainable=False","534517a4":"model = Sequential()\nmodel.add(vgg)\nmodel.add(Flatten())\nmodel.add(Dense(6,activation = \"softmax\"))\n\nmodel.summary()","638357c9":"checkpoint = ModelCheckpoint(\"vgg19.h5\",monitor = \"val_accuracy\",save_best_only=True,\n                                 save_weights_only = False,verbose=1)\nearlystop = EarlyStopping(monitor='val_accuracy',patience=5,verbose=1)\n\nmodel.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","1a2561ed":"history = model.fit(x_train,y_train,batch_size=32,validation_data = (x_test,y_test),\n                    epochs=15,verbose=1,callbacks=[checkpoint,earlystop])","ffd0c758":"loss,accuracy = model.evaluate(x_test,y_test)\n\nprint(f\"Loss: {loss}\")\nprint(f\"Accuracy: {accuracy*100}\")","68c407e3":"from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\ny_pred = model.predict_classes(x_test)\ny_pred[:15]","de34973b":"y_test_le = np.argmax(y_test,axis=1)\ny_test_le[:15]","1f3547bf":"print(classification_report(y_test_le,y_pred))","32298814":"from mlxtend.plotting import plot_confusion_matrix\ncm = confusion_matrix(y_test_le,y_pred)\nplot_confusion_matrix(conf_mat = cm,figsize=(8,7),class_names=['glacier', 'sea', 'forest', 'street', 'mountain', 'buildings'],\n                     show_normed = True);","56f0366a":"plt.figure(figsize=(12,6))\nplt.style.use(\"ggplot\")\nepochs = range(1,12)\nplt.subplot(1,2,1)\nplt.plot(epochs,history.history[\"accuracy\"],\"go-\")\nplt.plot(epochs,history.history[\"val_accuracy\"],\"ro-\")\nplt.title(\"Model Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend([\"Train\",\"val\"],loc=\"upper left\")\n\nplt.subplot(1,2,2)\nplt.plot(epochs,history.history[\"loss\"],\"go-\")\nplt.plot(epochs,history.history[\"val_loss\"],\"ro-\")\nplt.title(\"Model Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend([\"Train\",\"val\"],loc=\"upper left\")\nplt.show()","ea0d5985":"fig =plt.figure(figsize=(12,7))\nfor i in range(10):\n    sample = random.choice(range(len(x_test)))\n    plt.subplot(2,5,i+1)\n    plt.subplots_adjust(hspace=0.3)\n    plt.imshow(x_test[sample])\n    plt.xlabel(f\"Actual:{y_test_le[sample]}\\n Predicted: {y_pred[sample]} \")\n    \nplt.tight_layout()\nplt.show()","0ac2de48":"><h3>Classification Report:<\/h3>","960a00f4":"- Dataset info:\n> This is image data of Natural Scenes around the world.\n\n- Content:\n>This Data contains around 25k images of size 150x150 distributed under 6 categories.\n\n>{'buildings' -> 0,\n'forest' -> 1,\n'glacier' -> 2,\n'mountain' -> 3,\n'sea' -> 4,\n'street' -> 5 }\n\n>The Train, Test and Prediction data is separated in each zip files. There are around 14k images in Train, 3k in Test and 7k in Prediction.\n\n- Inspiration:\n>Want to build powerful Neural network that can classify these images with more accuracy.","c13c6386":"> <h3> Model Performance<\/h3>","1011da55":"><h3>Model Building:<\/h3>","30466df5":"><h3>Directory:<\/h3>","70974ebe":"><h3>Creating Dataset:<\/h3>","90d140be":"---\n\n<h1 style=\"text-align: center;font-size: 20px;\">Thanks for Reading<\/h1>\n\n---","bf5a06e2":"><h3>Confusion Matrix:<\/h3>","36bdf162":"---\n\n<h1 style=\"text-align: center;font-size: 40px;\">Intel image Classification<\/h1>\n<h1 style=\"text-align: center;font-size: 38px;\">with VGG19<\/h1>\n\n\n---\n\n<center><img src=\"https:\/\/storage.googleapis.com\/kaggle-datasets-images\/111880\/269359\/a16c143f44e79d17f54d5e670f16e03b\/dataset-cover.jpg?t=2019-02-01-19-30-12\n\"width=\"1000\" height=\"600\"><\/center>\n\n---\n","1cf4e152":"><h3>Let's see some of the Images:<h3>","1dce5f45":"<h3>Learning Curve:<\/h3>"}}