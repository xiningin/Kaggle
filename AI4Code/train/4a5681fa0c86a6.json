{"cell_type":{"9b900f14":"code","e2ceed23":"code","80a01c54":"code","f8f4db71":"code","f93de337":"code","99ffa2ba":"code","8139baac":"code","5e30f9d5":"code","f81ad48c":"code","701fbcd7":"code","6f76dac7":"code","a6c709bc":"code","4a8a6ad5":"code","4db9350f":"code","7be773ae":"code","343557b2":"code","7d1cc82e":"code","459d865b":"code","24d8293b":"code","ec00320c":"code","38b9532e":"code","13d28eb8":"code","c2714fdb":"code","01803fa6":"code","ca234020":"markdown","69b09ce4":"markdown","00f10aea":"markdown","b643ed17":"markdown","1a3eb405":"markdown","93f3374b":"markdown","0aa11758":"markdown","cc5b7ee7":"markdown","9f18b8d9":"markdown","8fe144cb":"markdown","67fe5b83":"markdown","d0beaf1d":"markdown","32410e73":"markdown","62944327":"markdown","be0387db":"markdown","da02914e":"markdown","3206b152":"markdown"},"source":{"9b900f14":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport os\nfrom os import listdir\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n","e2ceed23":"!pip install tensorflow==2.0.0-beta1\n\nfrom tensorflow.python.ops import control_flow_util\ncontrol_flow_util.ENABLE_CONTROL_FLOW_V2 = True","80a01c54":"import tensorflow as tf\n","f8f4db71":"training_dir = '..\/input\/train\/train\/'\ntraining_imgs = listdir(training_dir)\nnum_training_imgs = len(training_imgs)\nnum_training_imgs","f93de337":"train_labels_df = pd.read_csv('..\/input\/train.csv', index_col = 'id')\nprint(\"total entries : \" + str(train_labels_df.size))\ntrain_labels_df.head()","99ffa2ba":"pd.value_counts(train_labels_df['has_cactus'])","8139baac":"def get_test_image_path(id):\n    return training_dir + id\n\ndef draw_cactus_image(id, ax):\n    path = get_test_image_path(id)\n    img = mpimg.imread(path)\n    plt.imshow(img)\n    ax.set_title('Label: ' + str(train_labels_df.loc[id]['has_cactus']))\n\nfig = plt.figure(figsize=(20,20))\nfor i in range(12):\n    ax = fig.add_subplot(3, 4, i + 1)\n    draw_cactus_image(training_imgs[i], ax)","5e30f9d5":"train_image_path = [training_dir + ti for ti in training_imgs ]\ntrain_image_labels = [ train_labels_df.loc[ti]['has_cactus'] for ti in training_imgs]\n\n\nfor i in range(10):\n    print(train_image_path[i], train_image_labels[i])","f81ad48c":"def img_to_tensor(img_path):\n    img_tensor = tf.cast(tf.image.decode_image(tf.io.read_file(img_path)), tf.float32)\n    img_tensor \/= 255.0 # normalized to [0,1]\n    return img_tensor\n\nimg_to_tensor(train_image_path[0])","701fbcd7":"from sklearn.model_selection import train_test_split","6f76dac7":"X_train, X_valid, y_train, y_valid = train_test_split(train_image_path, train_image_labels, test_size=0.2)\n\ndef process_image_in_record(path, label):\n    return img_to_tensor(path), label\n\ndef build_training_dataset(paths, labels, batch_size = 32):\n    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n    ds = ds.map(process_image_in_record)\n    ds = ds.shuffle(buffer_size = len(paths))\n    ds = ds.repeat()\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n    return ds\n\ndef build_validation_dataset(paths, labels, batch_size = 32):\n    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n    ds = ds.map(process_image_in_record)\n    ds = ds.batch(batch_size)\n    return ds\n\ntrain_ds = build_training_dataset(X_train, y_train)\nvalidation_ds = build_validation_dataset(X_valid, y_valid)","a6c709bc":"mini_train_ds = build_training_dataset(X_train[:5], y_train[:5], batch_size=2)\n# Fetch and print the first batch of 2 images\nfor images, labels in mini_train_ds.take(1):\n    print(images)\n    print(labels)","4a8a6ad5":"model = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(256, activation='relu'))\nmodel.add(tf.keras.layers.Dense(64, activation='relu'))\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid')) # because we are in a binary classification setup\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","4db9350f":"history = model.fit(train_ds, epochs=20, steps_per_epoch=400, validation_data=validation_ds)","7be773ae":"def plot_accuracies_and_losses(history):\n    plt.title('Accuracy')\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.legend(['training', 'validation'], loc='upper left')\n    plt.show()\n    \n    plt.title('Cross-entropy loss')\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.legend(['training', 'validation'], loc='upper left')\n    plt.show()\n\nplot_accuracies_and_losses(history)","343557b2":"cnn_model = tf.keras.Sequential()\n\ncnn_model.add(tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)))\ncnn_model.add(tf.keras.layers.MaxPooling2D((2,2)))\ncnn_model.add(tf.keras.layers.Conv2D(64, (3,3), activation='relu'))\ncnn_model.add(tf.keras.layers.MaxPooling2D((2,2)))\ncnn_model.add(tf.keras.layers.Conv2D(64, (3,3), activation='relu'))\n\ncnn_model.add(tf.keras.layers.Flatten())\ncnn_model.add(tf.keras.layers.Dense(64, activation='relu'))\ncnn_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n\ncnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","7d1cc82e":"cnn_model.summary()","459d865b":"history = cnn_model.fit(train_ds, epochs=20, steps_per_epoch=400, validation_data=validation_ds)","24d8293b":"test_dir = '..\/input\/test\/test\/'\ntest_imgs = listdir(test_dir)\nprint(len(test_imgs))\ntest_imgs[:5]","ec00320c":"def path_to_numpy_array(path):\n    tensor = img_to_tensor(path)\n    array = tensor.numpy()\n    return array\n\ntest_image_paths = [test_dir + ti for ti in test_imgs]\ntest_instances = np.asarray([path_to_numpy_array(tip) for tip in test_image_paths])\n\ntest_instances[:2]","38b9532e":"predictions = cnn_model.predict(test_instances)\nprint(len(predictions))","13d28eb8":"submission_data = pd.DataFrame({'id': test_imgs, 'has_cactus': predictions.flatten()})\nsubmission_data.head(20)","c2714fdb":"submission_data.to_csv('submission.csv', index=False)","01803fa6":"!head submission.csv","ca234020":"**Checking the data**","69b09ce4":"Nearly 3 times more pictures have cactus in them as compared to the pictures without cactus","00f10aea":"So this is how we can convert our example to tensor of shape (32,32,3)","b643ed17":" So there are 17500 images in the given data. The labels of these images are saved in 'train.csv' file","1a3eb405":"Calculating the pictures with cactus and without cactus","93f3374b":"**Loading the data**","0aa11758":"**Making a Submission**","cc5b7ee7":"Furthermore, we were using basic model till now, but CNN or convulated neural networks are the most preferred option when processing image data, so let's try using CNNs","9f18b8d9":"**Building a model**","8fe144cb":"To get from the image paths above to actual tf.Tensors we will combine tf.io.read_file and tf.image.decode_image. This very simple process is illustrated below for the first example:","67fe5b83":"This shows us that our model is learning something and getting better gradually, we didn't allow much overfitting to occur. This shows that we haven't made any errors in setting up our data pipeline and model","d0beaf1d":"**Making training and validation dataset from our data**","32410e73":"Now that we have created training and validation dataset, let's verify them by a small example","62944327":"**Importing relevant libraries**","be0387db":"We've reached 90% validation accurary and there was increase in the validation loss once.","da02914e":"It is really tough to differentiate between the images with cactus and without cactus, so we're going to rely on AI to do that","3206b152":"**Making a CNN model**"}}