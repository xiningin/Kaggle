{"cell_type":{"2c6a8839":"code","6afad0cf":"code","159db095":"code","d0dc04c3":"code","e0e83396":"code","320f6cea":"code","4eef33d2":"code","e5356b1f":"code","8d48294a":"code","6061e598":"code","2d2b8eb6":"code","a5a3a793":"code","c17295aa":"code","51e7a138":"code","5cd11406":"code","862ba958":"code","7569f2eb":"code","1666da43":"code","47a4718e":"code","df19f2c4":"code","8bd832c9":"code","c8772b4f":"code","9b418b01":"code","76ca5e54":"code","16d57a46":"code","a7bfde60":"code","223b43c9":"code","aef50407":"code","0d5d3d04":"code","8c7cf86f":"code","b7466ca5":"code","c6c1f829":"code","c63e684d":"markdown","e500202c":"markdown","51c0070e":"markdown","12549b0d":"markdown","64e6b5e9":"markdown","d71a1a3d":"markdown","20849aca":"markdown","df34ac50":"markdown","833debc8":"markdown","9926c8d5":"markdown","7f622efa":"markdown","b6ce05a8":"markdown","0c8a42e0":"markdown","b98ac133":"markdown","ed8f8bc7":"markdown","d8a21d55":"markdown","c5131e09":"markdown","f62be5ab":"markdown"},"source":{"2c6a8839":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nimport ast\nimport json\n\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom keras.utils import to_categorical\nfrom PIL import Image, ImageDraw\n\nfrom keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D ,Dropout, Flatten\nfrom keras.layers import Dense\nimport tensorflow as tf\n\n\n","6afad0cf":"import glob\n\npath = '\/kaggle\/input\/quickdraw-doodle-recognition\/train_simplified\/' # use your path\nall_files = glob.glob(path + \"\/*.csv\")\nnb_files=len(all_files)\nnb_mots=34\nn_sample_perfile=10000\nnb_lignes_sample=340000\ntest_size_val=0.33\n","159db095":"li = []\ncount=0\n\nfor filename in all_files[0:nb_mots]:\n    print(filename)\n    df_reduced = pd.read_csv(filename, index_col=None, header=0, nrows=50000)\n    df_reduced=df_reduced[df_reduced['recognized']==True].drop(['timestamp','recognized'], axis=1).sample(n=n_sample_perfile, random_state=24)\n    \n    count+=1\n    print(df_reduced.size,count ,'\/',nb_files)\n    li.append(df_reduced)\n\nprint('load done for',nb_mots,'files')\nframe = pd.concat(li, axis=0, ignore_index=True)\nframe = frame.sample(n=n_sample_perfile*nb_mots, random_state=24)\n\n\ndel li\n","d0dc04c3":"print(frame.shape)\nframe.head()","e0e83396":"#replace spaces in words by _\nframe['word'] = frame['word'].str.replace(' ','_')\n\n#transform drawing into arrays (can take some time)\nframe['drawing']=frame['drawing'].apply(json.loads)","320f6cea":"categories=frame['word'].unique()\nprint(categories)\nlabel_encoder = LabelEncoder()\ninteger_encoded = label_encoder.fit_transform(categories)\none_hot_encoded= to_categorical(integer_encoded,dtype='float32')\ndict_words_one_hot = dict(zip(categories, one_hot_encoded))\n#map one hot incoding in the DataFrame\nframe['word_encoded']=frame.word.map(dict_words_one_hot)","4eef33d2":"frame.head()","e5356b1f":"N=10\noverview_sample=frame.sample(n=100, random_state=24).reset_index()\n\n\nfig1, axes = plt.subplots(N,N ,sharex=True, sharey=True, figsize=(20, 15))\nfor index, rows in enumerate(overview_sample['drawing']):\n    word=overview_sample.iloc[index,4]\n    ax1 = axes[index \/\/ N, index % N]\n    \n    for x,y in rows:\n        \n        # -np.array is used to inverse the y-axis here\n        ax1.plot(x,-np.array(y),marker='o',markersize=3,linewidth=2)\n    ax1.axis('off')\n    ax1.set(title=str(index)+' - '+ word)\nplt.show()","8d48294a":"def convert_to_np_raw(drawing, width = 256, height = 256):\n    \"\"\"\n    INPUT:\n        drawing - drawing in initial format\n        width - width of the initial image\n        height - height of the initial image\n    OUTPUT:\n        img - drawing converted to the numpy array (28 X 28)\n    \"\"\"\n    # initialize empty numpy array\n    img = np.zeros((28, 28))\n    \n    # create a PIL image out of drawing\n    pil_img = convert_to_PIL(drawing)\n    \n    #resize to 28,28\n    pil_img.thumbnail((28,28), Image.ANTIALIAS)\n    \n    pil_img = pil_img.convert('RGB')\n    pixels = pil_img.load()\n    \n    # fill in numpy array with pixel values\n    for i in range(0, 28):\n        for j in range(0, 28):\n            img[i, j] = 1 - pixels[j, i][0] \/ 255\n    \n    return img","6061e598":"def convert_to_PIL(drawing, width = 256, height = 256):\n    \"\"\"\n    Function to convert from drawing to .\n    INPUT:\n        drawing - drawing from 'drawing' column\n        width - width of the initial image\n        height - height of the initial image\n    OUTPUT:\n        pil_img - (PIL Image) image\n    \"\"\"\n    \n    # initialize empty (white) PIL image\n    pil_img = Image.new('RGB', (width, height), 'white')\n    pixels = pil_img.load()\n            \n    draw = ImageDraw.Draw(pil_img)\n    \n    # draw strokes as lines\n    for x,y in drawing:\n        for i in range(1, len(x)):\n            draw.line((x[i-1], y[i-1], x[i], y[i]), fill=0)\n        \n    return pil_img","2d2b8eb6":"frame['drawing']=frame['drawing'].apply(convert_to_np_raw)","a5a3a793":"X_train, X_test, y_train, y_test = train_test_split(frame.drop(['countrycode','word','word_encoded','key_id'],axis=1), frame['word_encoded'], test_size=test_size_val, random_state=24)","c17295aa":"model = Sequential()\nmodel.add(Dense(10, activation='relu', input_shape=(784,)))\nmodel.add(Dense(10, activation='relu'))\nmodel.add(Dense(nb_mots,activation='softmax'))","51e7a138":"model.compile(optimizer='adam', \n           loss='categorical_crossentropy', \n           metrics=['accuracy'])","5cd11406":"train_data=X_train['drawing'].apply(lambda v: v.reshape(784))\ntest_data=X_test['drawing'].apply(lambda v: v.reshape(784))","862ba958":"#We convert the DF to numpy array\nX_train_stacked=np.stack(train_data.values)\ny_train_stacked=np.stack(y_train.values)\nX_test_stacked=np.stack(test_data.values)\ny_test_stacked=np.stack(y_test.values)","7569f2eb":"y_train=np.concatenate( y_train.to_numpy(), axis=0 ).reshape(y_train.shape[0],nb_mots)\ny_test=np.concatenate( y_test.to_numpy(), axis=0 ).reshape(y_test.shape[0],nb_mots)","1666da43":"model.fit(np.stack(train_data.values),y_train, validation_split=0.2, epochs=10)","47a4718e":"model.evaluate(np.stack(test_data.values), y_test_stacked)","df19f2c4":"#Here the images are reshaped to (28,28,1) array\nX_train_new=X_train['drawing'].apply(lambda v: v.reshape(28,28,1))\nX_test_new=X_test['drawing'].apply(lambda v: v.reshape(28,28,1))","8bd832c9":"model2 = Sequential()\nmodel2.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(28, 28, 1)))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel2.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel2.add(Dropout(0.2))\nmodel2.add(Flatten())\nmodel2.add(Dense(680, activation='relu'))\nmodel2.add(Dropout(0.5))\nmodel2.add(Dense(nb_mots, activation='softmax'))\nmodel2.summary()","c8772b4f":"model2.compile(optimizer='adam', \n           loss='categorical_crossentropy', \n           metrics=['accuracy'])","9b418b01":"model2.fit(np.stack(X_train_new.values),y_train, validation_split=0.2, epochs=5)","76ca5e54":"model2.evaluate(np.stack(X_test_new.values),y_test)","16d57a46":"model3 = Sequential()\nmodel3.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(28, 28, 1)))\nmodel3.add(Conv2D(16, 3, padding='same', activation='relu'))\nmodel3.add(MaxPooling2D())\nmodel3.add(Conv2D(32, 3, padding='same', activation='relu'))\nmodel3.add(MaxPooling2D())\nmodel3.add(Conv2D(64, 3, padding='same', activation='relu'))\nmodel3.add(MaxPooling2D())\nmodel3.add(Flatten())\nmodel3.add(Dense(128, activation='relu'))\nmodel3.add(Dense(nb_mots, activation='softmax'))\nmodel3.summary()","a7bfde60":"model3.compile(optimizer='adam', \n           loss='categorical_crossentropy', \n           metrics=['accuracy'])","223b43c9":"model3.fit(np.stack(X_train_new.values),y_train, validation_split=0.2, epochs=5)","aef50407":"model3.evaluate(np.stack(X_test_new.values),y_test)","0d5d3d04":"model4 = Sequential()\nmodel4.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(28, 28, 1)))\nmodel4.add(Conv2D(16, 3, padding='same', activation='relu'))\nmodel4.add(MaxPooling2D())\nmodel4.add(Conv2D(32, 3, padding='same', activation='relu'))\nmodel4.add(MaxPooling2D())\nmodel4.add(Conv2D(64, 3, padding='same', activation='relu'))\nmodel4.add(MaxPooling2D())\nmodel4.add(Flatten())\nmodel4.add(Dense(128, activation='relu'))\nmodel4.add(Dropout(0.4))\nmodel4.add(Dense(nb_mots, activation='softmax'))\nmodel4.summary()\n","8c7cf86f":"model4.compile(optimizer='adam', \n           loss='categorical_crossentropy', \n           metrics=['accuracy'])","b7466ca5":"model4.fit(np.stack(X_train_new.values),y_train, validation_split=0.2, epochs=5)","c6c1f829":"model4.evaluate(np.stack(X_test_new.values),y_test)","c63e684d":"# Next steps to go further:\n\nSeveral steps that I still want to try to implement: \n- Try to fit the model using more sample: BatchApproach\n- Try to parallelize bottleneck steps and apply functions\n- Optimization of layers and parameters and number of epoch\n- Use pre-models such as MobileNet to check their scores\n- Try to use LTSM layers in addition to Conv\/Pooling layers","e500202c":"I used adam as an ","51c0070e":"# Model 4 - Adding dropout to model 3","12549b0d":"# Prediction\n\nOne of the current limitation in this analysis is the number of samples and the number of words.","64e6b5e9":"# Model 3 - More classic but efficient ","d71a1a3d":" Then we need to convert the pictures into an np.array to be able to predict them.\n This is currently a bottleneck in the analysis, because the transformation takes a lot of time. The RAM usage is limitating the number of sample used. \n \n Solution could be to try to parallelize this line.","20849aca":"# Summary","df34ac50":"# Conversions fonctions\n\nUsed to convert the drawing into a img in a numpy array \n\nfunctions from: https:\/\/www.kaggle.com\/gaborfodor\/how-to-draw-an-owl-lb-0-002","833debc8":"# Load of the files\n\nI decided to look only to a few classes in this notebook. The dataset contains a total of 340 words. \n\nThe first step to load the files is to read the .csv file and load them in a DataFrame","9926c8d5":"# Overview of the data\n\nThis section is used to see an overview of the drawings, I added the name of each drawing as the legend of the plot","7f622efa":"# Model 1 - Very basic model but efficient","b6ce05a8":"> # Model 2 - Conv approach","0c8a42e0":" #  Data preprocessing:\n \nIn this section, I replace the words containing spaces by underscores.\nI convert then the category into a one hot.\n\nI tried first to use ast.litteral_eval. I changed to json.load which is much faster","b98ac133":"### Then we create the Train and Test Datasets\n\nI decided to drop all not useful columns, however it could be interessant to consider the countrycode as a feature. Some countries can have similar ways to draw doodles based on their location.","ed8f8bc7":"For this first model, I decided to use a very basic Neural Network using Dense layer with a 'relu' activation. And a softmax activation for the output layer. ","d8a21d55":"I then had to convert the y_train and y_test to numpy array with the right shape so they can be converted by Keras to Tensors","c5131e09":"# Imports of packages","f62be5ab":"### First we need to use the right shape for the values for the convolutional network"}}