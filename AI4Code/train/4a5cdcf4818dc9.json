{"cell_type":{"d74738ee":"code","a6a96246":"code","ea9ff330":"code","af8a0c5a":"code","c204da8a":"code","2c2b1d5e":"code","1f421ba8":"code","240a23c5":"code","31552c1d":"code","8492e8eb":"code","18ae7c1f":"code","c356affa":"code","7b82c2ee":"code","24a93744":"code","08fb0fb8":"code","430ce852":"markdown","b90e6ed8":"markdown","0ec41c2d":"markdown","b59a24fa":"markdown","b5b232bd":"markdown","d1d0e982":"markdown","4e062271":"markdown","df9dd6c1":"markdown","c42d94e0":"markdown","01f4e9e6":"markdown","63788a92":"markdown"},"source":{"d74738ee":"# 1.0 Call libraries\nimport numpy as np\nimport pandas as pd\nimport os\n# 1.2\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\n# 2.0 Check version of sklearn.\n#     There should not be any assertion error\nimport sklearn\nassert sklearn.__version__ >= \"0.20\"","a6a96246":"# 2.1 Display mulitple commands outputs from a cell\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","ea9ff330":"X = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')\nX.head()","af8a0c5a":"print(\"No of articles:\",X.shape[0])\nprint(\"No of columns associated to pixels(total columns-label column):\",X.shape[1]-1)","c204da8a":"y=X.pop('label')","2c2b1d5e":"#Split dataset. Default split test-size is 0.25\nX_train,X_test,y_train,y_test=train_test_split(X,y)","1f421ba8":"#Train PCA on dataset\npca = PCA()\npca.fit(X_train)","240a23c5":"#Get statistics from pca\n#     How much variance is explained by each principal component\npca.explained_variance_ratio_[:10]\n#     Cumulative sum of variance of each principal component\ncumsum = np.cumsum(pca.explained_variance_ratio_)\ncumsum[:10]","31552c1d":"#Get the column (principal component) number \n#      when cum explained variance threshold just exceeds 0.95\nd = np.argmax(cumsum >= 0.95) + 1\nd    ","8492e8eb":"#Let us also plot cumsum\n#     Saturation occurs are Elbow\n\nabc = plt.figure(figsize=(6,4))\nabc = plt.plot(cumsum, linewidth=3)\n#  Define axes limits\nabc = plt.axis([0, 400, 0, 1])\n#  Axes labels\nabc = plt.xlabel(\"Dimensions\")\nabc = plt.ylabel(\"Explained Variance\")\n# Draw a (vertical) line from (d,0) to (d,0.95)\n#       Should be black and dotted\nabc = plt.plot([d, d], [0, 0.95], \"k:\")\n#  Draw another dotted (horizontal) line \n#       from (0,0.95) to (d,0.95)\nabc = plt.plot([0, d], [0.95, 0.95], \"k:\")\n#  Draw a point at (d,0.95)\nabc = plt.plot(d, 0.95, \"ko\")\n# Annotate graph\nabc = plt.annotate(\n                   \"Elbow\",             # Text to publish\n                   xy=(65, 0.85),       # This parameter is the point (x, y) to annotate.\n                   xytext=(70, 0.7),    # The position (x, y) to place the text at.\n                   arrowprops=dict(arrowstyle=\"->\"), # A dictionary with properties used\n                                                     #  to draw an arrow between the\n                                                     #    positions xy and xytext.\n                   fontsize=16\n                  )\n#  Draw a grid\nplt.grid(True)\nplt.show()","18ae7c1f":"#Get transformed dataset upto 95%\n#       explained variance\npca = PCA(n_components=0.95)\nX_reduced = pca.fit_transform(X_train)","c356affa":"#shape of reduced data\npca.n_components_\nX_reduced.shape","7b82c2ee":"#Recheck sum of explained variance\nnp.sum(pca.explained_variance_ratio_)","24a93744":"#      dimensions back from reduced dimesionality\nX_recovered = pca.inverse_transform(X_reduced)\nX_recovered.shape     ","08fb0fb8":"#Plot few digits from original dataset\n#     Digit shapes\nfig,axe = plt.subplots(2,5)\naxe = axe.flatten()\nplt.title(\"A\")\nfor i in range(10):\n    abc = axe[i].imshow(X_train.iloc[i,:].to_numpy().reshape(28,28))\nplt.suptitle('Few Images from Original Dataset')\n# few images from compressed dataset\n#     And compare both\nfig,axe = plt.subplots(2,5)\naxe = axe.flatten()\nfor i in range(10):\n    abc = axe[i].imshow(X_recovered[i,:].reshape(28,28))\n    \nplt.suptitle('Few Images from compressed Dataset')","430ce852":"* **Observation** :  dimensionality of any image has been reduced  from 1 X 784 to 1 X 181","b90e6ed8":"### Content\nEach image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.\n\nTo locate a pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27. The pixel is located on row i and column j of a 28 x 28 matrix.\nFor example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below.","0ec41c2d":"#### Labels\n* 0 T-shirt\/top\n* 1 Trouser\n* 2 Pullover\n* 3 Dress\n* 4 Coat\n* 5 Sandal\n* 6 Shirt\n* 7 Sneaker\n* 8 Bag\n* 9 Ankle boot","b59a24fa":"#### Use PCA's function inverse_transform() to get origianl\n* we have reduced the dimensions from Use PCA's function inverse_transform() to get origianl.For comparing we will apply inverse_transform() to get dimesions of 1X784.\n* we're not reverting back to the original data, we're simply going back to the actual dimension of the original images so we can visualize them. - ","b5b232bd":"#### first column is the label(type of article) ,store it into Y and drop the column","d1d0e982":"* **Analysis** :Compressed images looks good but the finer details are missing, which is okay because images are recognizable\n* Dimensions has been reduced from 1X784 to 1X181","4e062271":"## What is Fashion MNIST Dataset?\nFashion-MNIST is a dataset of Zalando's article images\u2014consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n\nThe original MNIST dataset contains a lot of handwritten digits. Members of the AI\/ML\/Data Science community love this dataset and use it as a benchmark to validate their algorithms. In fact, MNIST is often the first dataset researchers try. \"If it doesn't work on MNIST, it won't work at all\", they said. \"Well, if it does work on MNIST, it may still fail on others.\"\n\nZalando seeks to replace the original MNIST dataset","df9dd6c1":"* Each row is a separate image\n* Column 1 is the class label.\n* Remaining columns are pixel numbers (784 total).\n* Each value is the darkness of the pixel (1 to 255)","c42d94e0":"#### we will reduced the size","01f4e9e6":"#### what is explained variance \n* The fraction of variance explained by a principal component is the ratio between the variance of that principal component and the total variance.\n* For several principal components, add up their variances and divide by the total variance.","63788a92":"## Set Directory\n"}}