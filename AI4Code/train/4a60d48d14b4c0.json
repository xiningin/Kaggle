{"cell_type":{"74ad5d41":"code","49b03aac":"code","d9ca6da6":"code","d4cc69f2":"code","b5d04c75":"code","d8648979":"code","69a9f654":"code","efc3eaa6":"code","49423145":"code","cb13438d":"code","5a784cbc":"code","008c7e32":"code","6de4e6a5":"code","095fdd3d":"code","affcd6e8":"code","bcdc5b57":"code","003224e5":"code","d13ddc4f":"code","9285d0e1":"code","7141434a":"code","10604f82":"code","9614a110":"code","1fcf1203":"code","701bfe18":"code","8fbbb1db":"code","a5b22be5":"code","6938d249":"code","d05de724":"code","5e8940ca":"code","a14255cd":"code","d77a2076":"code","3d134336":"code","da877a77":"code","6b09a276":"code","547d40bc":"code","cc42e9ce":"code","7c9e67c4":"code","a09d9dfd":"code","9486c5aa":"code","f3510768":"code","0ac1522d":"code","7e6198ba":"code","f650e686":"code","00f85257":"code","5467fe29":"code","62ddaec8":"code","64f80d88":"code","0dcd2ef0":"code","110478b5":"markdown","3227fe31":"markdown","8a807df1":"markdown","bab074ae":"markdown","4ee206c7":"markdown","c751ed92":"markdown","299c29ae":"markdown","2108489c":"markdown","c029ea78":"markdown","61f72aa0":"markdown","32c087c7":"markdown","7c12c32a":"markdown","0cdab6ce":"markdown","efa1470e":"markdown","ea5a9263":"markdown","e48dc40e":"markdown","50f14dea":"markdown","0151e730":"markdown","1e8d346d":"markdown","4f3de212":"markdown","406eb20f":"markdown","1a135550":"markdown","928a28a5":"markdown","142b3c34":"markdown","13090a3c":"markdown","4fd5cdb9":"markdown","edc82ae3":"markdown","701d1c28":"markdown","468f3332":"markdown","db875594":"markdown","679ce4ba":"markdown","1d595c2f":"markdown","d5e71ff1":"markdown","8d7c9e16":"markdown","1c096b92":"markdown","4be3a8c2":"markdown","957484d2":"markdown","76ff27b3":"markdown","c07d9ce6":"markdown","644462f3":"markdown","2e5f8582":"markdown","b030a731":"markdown","b41bf789":"markdown"},"source":{"74ad5d41":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","49b03aac":"# Importing Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nfrom sklearn.preprocessing import StandardScaler\nimport statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.model_selection import GridSearchCV\nimport warnings\nwarnings.filterwarnings('ignore')\n# display all columns of the dataframe\npd.options.display.max_columns = None\n\n# display all rows of the dataframe\npd.options.display.max_rows = None","d9ca6da6":"# Reading the data from csv file using pd.read_csv\nhouse_price_df = pd.read_csv('\/kaggle\/input\/bangalore\/banglore.csv')\n\n\n# Displaying the first 5 observation using .head()\nhouse_price_df.head()","d4cc69f2":"# use .shape to find the dimension of dataset\nprint(f'Number of Observation: {house_price_df.shape[0]}')\nprint(f'Number of Feature or Column:{house_price_df.shape[1]}')","b5d04c75":"# use .dtype to find the datatype for each column\nhouse_price_df.dtypes","d8648979":"# Renaming the Size column to BHK for better understanding\n# .rename to rename the column\nhouse_price_df = house_price_df.rename(columns={'size':'BHK'})","69a9f654":"# extracting only the numerical value from BHK column \ndef numerical_part(x):\n    try:\n        number = int(re.findall(r'\\d+',x)[0])\n        return number\n    except:\n        return x\n\n# Replacing value to numerical value   \nhouse_price_df.BHK = house_price_df.BHK.apply(lambda x:numerical_part(x))","efc3eaa6":"# As total_sqft is a categorically variable,checking for unique value or units \ndef units(x):\n    l1 = re.findall(r'\\D+\\D+',x)\n    try:\n        if l1[0]==' - ':\n            return 'Sqft'\n        else:\n            return l1[0]\n    except:\n        return 'Sqft'","49423145":"# unique value\/units in total_sqft\nhouse_price_df.total_sqft.apply(lambda x:units(x)).unique()","cb13438d":"house_price_df[house_price_df['total_sqft']=='1783 - 1878']","5a784cbc":"# function for converting into same units\ndef common_units(x):\n    tokens = x.split('-')\n    try:\n        if len(tokens) == 2:\n            return (float(tokens[0])+float(tokens[1]))\n        else:\n            tok = tokens[0]\n            units = re.findall(r'\\D+\\D+',tok)[0]\n            if units == 'Sq. Meter':\n                number = tok.split(units)[0]\n                return 10.7639*float(number)\n            elif units == 'Perch':\n                number = tok.split(units)[0]\n                return 272.25*float(number)\n            elif units == 'Sq. Yards':\n                number = tok.split(units)[0]\n                return 9*float(number)\n            elif units == 'Acres':\n                number = tok.split(units)[0]\n                return 43560*float(number)\n            elif units == 'Cents':\n                number = tok.split(units)[0]\n                return 435.6*float(number)\n            elif units == 'Guntha':\n                number = tok.split(units)[0]\n                return 1089*float(number)\n            elif units == 'Grounds':\n                number = tok.split(units)[0]\n                return 2400*float(number)\n            else:\n                return (tokens[0])\n    except:\n        return(tokens[0])","008c7e32":"## applying the fucntion to the column: - 'total_sqft'\nhouse_price_df.total_sqft = house_price_df.total_sqft.apply(common_units)","6de4e6a5":"# changing datatype for the column total_sqft from categorical to numerical\n# .astype() function for changing the datatype\nhouse_price_df.total_sqft = house_price_df.total_sqft.astype(float)","095fdd3d":"# Re-checking the datatype\nhouse_price_df.dtypes","affcd6e8":"# checking for duplicates value\nhouse_price_df.duplicated().sum()","bcdc5b57":"# dropping duplicate\nhouse_price_df.drop_duplicates(inplace=True)","003224e5":"# Summary Statistic for numerical variable\nhouse_price_df.select_dtypes(include=np.number).describe().T","d13ddc4f":"# Summary Statistic for categorically variable\nhouse_price_df.select_dtypes(include=object).describe()","9285d0e1":"# missing value for each column\nTotal = house_price_df.isnull().sum().sort_values(ascending=False) \n\n# Percenatge of missing value for each column\nPercent = (house_price_df.isnull().sum()*100\/house_price_df.isnull().count()).sort_values(ascending=False)   \n\n# concat the 'Total' and 'Percent' columns using 'concat' function\nmissing_data = pd.concat([Total, Percent], axis = 1, keys = ['Total', 'Percentage of Missing Values'])\n\n# print the missing data\nmissing_data","7141434a":"# visualization for missing value\nplt.figure(figsize=(15, 8))\n\n# plot heatmap to check null values\n\nsns.heatmap(house_price_df.isnull(), cbar=False)\n\n# display the plot\nplt.show()","10604f82":"# dropping Society and availablity column\nhouse_price_df = house_price_df.drop(['society','availability'],1)\n\n# droppinf null value for each column as very small percentage\nhouse_price_df.dropna(inplace=True)","9614a110":"# reseting index\nhouse_price_df.reset_index(drop=True,inplace=True)","1fcf1203":"# visualization for missing value\nplt.figure(figsize=(15, 8))\n\n# plot heatmap to check null values\n\nsns.heatmap(house_price_df.isnull(), cbar=False)\n\n# display the plot\nplt.show()","701bfe18":"# Frequency for each loaction\nlocation_freq = pd.Series(house_price_df.location.value_counts()).head(25)\nlocations = pd.DataFrame(location_freq).reset_index().rename(columns={'index':'location','location':'frequency'})","8fbbb1db":"# barplot\n\nplt.figure(figsize=(15,8))\n\nsns.barplot(locations['location'],locations['frequency'])\n\nplt.xticks(rotation=65)\n\nplt.show()","a5b22be5":"mylabels = ['Super built-up Area','Carpet Area','Plot Area','Built-up Area']\nplt.figure(figsize=(6,6))\n(house_price_df['area_type'].value_counts()).plot.pie(autopct=\"%.1f%%\",shadow=True,labels=mylabels,radius=2)\nplt.legend(loc ='best')\nplt.show()","6938d249":"# Summary Statistic for categorically variable\nhouse_price_df.select_dtypes(include=object).describe()","d05de724":"# Boxplot of price and location\nplt.figure(figsize=(15,8))\nsns.boxplot(house_price_df['area_type'],house_price_df['price'])","5e8940ca":"import plotly.express as px\nfig = px.box(house_price_df,x='location',y='price')\nfig.show()","a14255cd":"# balcony\nplt.figure(figsize=(15,8))\nplt.title('Frequency of Balcony')\nsns.countplot(house_price_df['balcony'])","d77a2076":"# BHK\nplt.figure(figsize=(15,8))\nplt.title('Frequency of BHK')\nsns.countplot(house_price_df['BHK'])","3d134336":"# scatterplot between price and total_sqft for whitfield area\nplt.figure(figsize=(15,8))\nplace = 'Whitefield'   # here location can be changed,as whitefield had highest number of house so selected it\ndf = house_price_df[house_price_df['location']== place]  \nsns.scatterplot(df['price'],df['total_sqft'],hue=df['area_type'])\nplt.title('Whitefield:-Total_Sqft VS Price')\nplt.xlabel('Price')","da877a77":"# Boxplot for outlier analysis\nplt.figure(figsize=(10,8))\nplt.title('Boxplot for Numerical Variable')\nhouse_price_df.boxplot()","6b09a276":"#1st Quantile\nq1 = house_price_df.quantile(0.25)\n\n#3rd Quantile\nq3 = house_price_df.quantile(0.75)\n\n#IQR\nIQR = q3-q1\nIQR\n\n#Removing IQR\nhouse_price_df = house_price_df[~((house_price_df < (q1 - 1.5 * IQR)) | (house_price_df > (q3 + 1.5 * IQR))).any(axis=1)]","547d40bc":"# resetting index\nhouse_price_df = house_price_df.reset_index(drop=True)","cc42e9ce":"corr = house_price_df.corr()\nplt.figure(figsize = (15,8))\n#correlation between variable\nplt.title('Correlation')\nsns.heatmap(corr,mask = corr<0.6 ,annot= True,cmap = 'Blues')","7c9e67c4":"# check the distribution of target variable using hist()\nhouse_price_df.price.hist()\n\nplt.figure(figsize=(15,8))\n# display the plot\nplt.show()","a09d9dfd":"house_price_df.head()","9486c5aa":"# filter the numerical features in the dataset using select_dtypes()\ndf_numeric_features = house_price_df.select_dtypes(include=np.number)","f3510768":"# selecting only categorically\ndf_cat = house_price_df.select_dtypes(include=object)","0ac1522d":"df_dum = pd.get_dummies(df_cat)","7e6198ba":"# concatenating df_num_scaled and df_dum\nhouse_price = pd.concat([df_numeric_features,df_dum],1)","f650e686":"# first 5 observation \nhouse_price.head()","00f85257":"# splitting data into train and test\n# add the intercept column to the dataset\nhouse_prediction = house_price.drop('price',1)\nX = sm.add_constant(house_prediction)\n\n# extract the target variable from the data set\ny = house_price['price']\n\n# split data into train subset and test subset for predictor and target variables\n# random_state: the seed used by the random number generator\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n\n# check the dimensions of the train & test subset for \n\n# print dimension of predictors train set\nprint(\"The shape of X_train is:\",X_train.shape)\n\n# print dimension of predictors test set\nprint(\"The shape of X_test is:\",X_test.shape)\n\n# print dimension of target train set\nprint(\"The shape of y_train is:\",y_train.shape)\n\n# print dimension of target test set\nprint(\"The shape of y_test is:\",y_test.shape)","5467fe29":"# build a full model using OLS()\nlinreg_full_model = sm.OLS(y_train, X_train).fit()\n\n# print the summary output\nprint(linreg_full_model.summary())","62ddaec8":"# FUnction for calculating error\ndef train_rmse(model):\n    y_pret = model.predict(X_train)\n    mse = mean_squared_error(y_train,y_pret)\n    rmse = np.sqrt(mse)\n    return rmse\n\ndef test_rmse(model):\n    y_pret = model.predict(X_test)\n    mse = mean_squared_error(y_test,y_pret)\n    rmse = np.sqrt(mse)\n    return rmse","64f80d88":"# create an empty dataframe to store the scores for various algorithms\nscore_card = pd.DataFrame(columns=['Model_Name', 'Alpha (Wherever Required)', 'l1-ratio', 'R-Squared',\n                                       'Adj. R-Squared', 'Train RMSE', 'Test RMSE','Train_RMSE - Test_RMSE'])","0dcd2ef0":"new_score=pd.Series({'Model_Name':'MLR full model',\n                    'Alpha (Wherever Required)':'-',\n                    'l1-ratio':'-',\n                    'R-Squared':linreg_full_model.rsquared,\n                    'Adj. R-Squared':linreg_full_model.rsquared_adj,\n                    'Train RMSE':train_rmse(linreg_full_model),\n                    'Test RMSE':test_rmse(linreg_full_model),\n                    'Train_RMSE - Test_RMSE':abs(train_rmse(linreg_full_model)-test_rmse(linreg_full_model))})\nscore_card = score_card.append(new_score,ignore_index=True)\nscore_card","110478b5":"- Most house are 2 or 3 BHK","3227fe31":"<a id='Summary_Statistics'><\/a>\n### 3.1.4 Summary Statistics","8a807df1":"- Society column has many 41% percentage of missing, we can drop it","bab074ae":"- Outlier are present in price with respect to location","4ee206c7":"<a id='LinearRegression'><\/a>\n## 4. Linear Regression (OLS)","c751ed92":"<a id='outliers'><\/a>\n### 3.1.8 Outlier Treatment Using IQR","299c29ae":"<a id='data_preparation'><\/a>\n## 3. Data Analysis and Preparation","2108489c":"<a id='withLog'><\/a>\n### 4.1 Multiple Linear Regression - Full Model","c029ea78":"<a id='Duplicate_Value'><\/a>\n### 3.1.3 Duplicate Values","61f72aa0":"- Presence of outlier in numerical variable except in balcony","32c087c7":"- All the datatype are fixed.","7c12c32a":"<a id='categorical'><\/a>\n### 3.1.6 Analyze Categorical Variables\n","0cdab6ce":"<a id='Data_Shape'><\/a>\n### 3.1.1 Data Dimension\nTo Know the dimension of Data:","efa1470e":"<a id='Read_Data'><\/a>\n## 2. Read Data\nRead and Display the first 5 observation:","ea5a9263":"- Most of house are ready to move\n- Whitefield has maximum number of house in bangalore that is for sale\n- Society has many missing value","e48dc40e":"- Whitefield followed by Sarjapur Road have highest number of house for sale.","50f14dea":"<a id='dummy'><\/a>\n### 3.2.2 Dummy Encoding of Categorical Variables","0151e730":"<a id='correlation'><\/a>\n### 3.1.9 Correlation","1e8d346d":"- As total area increase the price also increase","4f3de212":"## <font color = '#00008B'> Table of Contents\n\n1. **[Import Libraries](#import_lib)**\n2. **[Read Data](#Read_Data)**\n3. **[Data Analysis and Preparation](#data_preparation)**\n    - 3.1 - [Understand the Data](#Data_Understanding)\n        - 3.1.1 - [Data Dimension](#Data_Shape)\n        - 3.1.2 - [Data Types](#Data_Types)\n        - 3.1.3 - [Duplicate Values](#Duplicate_Value)\n        - 3.1.4 - [Summary Statistics](#Summary_Statistics)  \n        - 3.1.5 - [Missing Values](#Missing_Values)\n        - 3.1.6 - [Analyze Categorical Variables](#categorical)\n        - 3.1.7 - [Analyze Numerical Variable](#Numerical_Variable)\n        - 3.1.8 - [Outlier Treatment Using IQR](#outliers)\n        - 3.1.9 - [Correlations](#correlation)\n    - 3.2 - [Prepare the Data](#Data_Preparation)\n        - 3.2.1 - [Check for Normality](#Normality)\n        - 3.2.2 - [Dummy Encoding of Categorical Variables](#dummy)\n4. **[Linear Regression (OLS)](#LinearRegression)**","406eb20f":"- Price is heavily right skewed and not normally distributed","1a135550":"- Most house has 1 or 2 balcony","928a28a5":"- No Null value","142b3c34":"- As the units are of different scale need to replace it to common units that is sqft.","13090a3c":"- 65.8% constitute Super built up Area","4fd5cdb9":"- Some column has some missing value\n- BHK,total_sqft,bath,price has outlier present in it.\n- Some house are without balcony also","edc82ae3":"## <font color = '#00008B'> Data Definition<\/font>\n\n**AREA_TYPE :** Categories of Area\n\n**AVAILABILITY :** Propery Availability\n\n**LOCATION :** Property Location\n\n**SIZE :** Number of Bedrooms\n\n**SOCIETY :** Sociaty where Property\n\n**TOTAL_SQFT :** Total Square feet of the property\n\n**BATH :** Number of Bathrooms\n\n**BALCONY :** Number of Balconies\n\n**PRICE :** Price of the property in Lakhs","701d1c28":"- total_sqft should be numerical variable and units for it sqft \n- size column should be numerical","468f3332":"<a id='import_lib'><\/a>\n## 1. Import Libraries","db875594":"<a id='Data_Types'><\/a>\n### 3.1.2 Data Types\nChecking for datatype of each column and fixing the incorrect datatype.","679ce4ba":"## <font color = '#00008B'>Problem Statement\nMany People do intense search to buy the perfect house for themselves.Price is a major factor that people always consider before buying a house and Buying a house in the Silicon Valley of India,Bangalore can we challenging.So to ease this data about varies house located in different place were collected and using this  a supervised Machine Learning model was created.This model will help in predicting the price of the house based on the factor like BHK,Locality etc which help new buyers to get a rough idea on the price.","1d595c2f":"<a id='Data_Understanding'><\/a>\n### 3.1 Understand the Dataset","d5e71ff1":"- Correlation strong correlation between total_sqft and BHK","8d7c9e16":"<a id='Data_Preparation'><\/a>\n## 3.2 Prepare the Data","1c096b92":"![front-of-urban-houses-along-the-street-free-vector.jpg](attachment:front-of-urban-houses-along-the-street-free-vector.jpg)","4be3a8c2":"<a id='Numerical_Variable'><\/a>\n### 4.1.7 Analyze Numerical Variable","957484d2":"<a id='Normality'><\/a>\n### 3.2.1 Check for Normality","76ff27b3":"- Society,bath,balcony,BHK columns has null value","c07d9ce6":"- This model explains **75%** of the variation in dependent variable claim.\n- The Durbin-Watson test statistics is **1.991~2** and indicates that there is no autocorrelation. \n- The Condition Number  **3.81e+21** which is greater than 1000,suggests that there is severe collinearity.\n- Jarque-Bera test gives p_value less than **0.05**,which means that residual are not normally distributed.","644462f3":"<a id='Missing_Values'><\/a>\n### 3.1.5 Missing Values","2e5f8582":"- Presence of outlier in price with respect to Area-type","b030a731":"- Some Sqft are in range, So average of the 2 points will be taken.","b41bf789":" <h1   align = 'center'><font color = '#00008B'> Bangalore House Price Prediction<\/h1>"}}