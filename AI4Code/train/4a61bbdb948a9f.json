{"cell_type":{"c026f49b":"code","614d8e18":"code","609ad8da":"code","37dc9dc5":"code","9e104563":"code","493f3cc8":"code","c23ad7c0":"code","4c786db0":"code","e175a0e1":"code","3587f4d3":"code","e1082432":"code","c7eda721":"code","b3bc4be5":"code","a7f60fab":"code","012c666e":"code","c2543a11":"code","ea921e2f":"code","fdffdd19":"code","32056190":"markdown","2ab81906":"markdown","617f6c43":"markdown","2b72e3a6":"markdown","ef3d5bbe":"markdown","11c97851":"markdown","4d90c96b":"markdown"},"source":{"c026f49b":"#import libs are needed\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#list of files in \/input dir\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n#path to CSV file       \npath = \"\/kaggle\/input\/paysim1\/PS_20174392719_1491204439457_log.csv\"","614d8e18":"import gc #for garbage collection\n\nfrom sklearn.preprocessing import LabelEncoder #for categorial data\n\n#for AutoML\nimport h2o\nfrom h2o.automl import H2OAutoML\n\n#run the AutoML server\nh2o.init()","609ad8da":"%%time\ns = !wc -l {path}\nprint(s)","37dc9dc5":"!free #result is 16452768 KB of free RAM right now while using only CPU, kaggle shows 1.4GB using now before importing the data","9e104563":"df = pd.read_csv(path)\ndf.info()","493f3cc8":"!free #kaggle shows about 2.8GB of RAM is using now","c23ad7c0":"labelEncoder = LabelEncoder()\n\nfor col in df.columns:\n    df[col] = labelEncoder.fit_transform(df[col])\n\ndf = h2o.H2OFrame(df)\ndf = df.asfactor()","4c786db0":"!free","e175a0e1":"gc.collect()","3587f4d3":"!free","e1082432":"%%time\ntrain_ratio = 0.75\ntest_ratio  = 0.15\n\ntrain, test, valid = df.split_frame( ratios = [ train_ratio , test_ratio ] )","c7eda721":"#let's check our converted to numbers data:\ndf.describe()","b3bc4be5":"gc.collect()","a7f60fab":"#tune the AutoML object and run auto training\n#but we should choose target column y, which is \n\ny = \"isFraud\"\nx_train = train.columns #list of columns with features\nx_train.remove(y) #we left only features without target\n\n#run the automl learning\naml = H2OAutoML(max_runtime_secs=600, seed = 1)\n","012c666e":"aml.train(x = x_train, y = y, training_frame = train)","c2543a11":"#results, which algorithm is better\nlb = aml.leaderboard\nlb.head()","ea921e2f":"#other additional training info\naml.training_info","fdffdd19":"#let's predict results with better model\npreds = aml.predict(test)\npreds","32056190":"<H1>Let's check the size of the input data:<\/H1>","2ab81906":"Strangelly, we have less free memory after gc.collect()\nOK, let's split our H2OFrame to train and test datasets randomly with using expected values 0.75 and 0.15 ","617f6c43":"<H1>Let's read the data into dataframe:<\/H1>","2b72e3a6":"<H1>So, we have about 6 million lines in the input data<\/H1>","ef3d5bbe":"Now after running importing we have 14955664 KB free memory\nSo, actually we have 1.5GB RAM using only for this dataframe (real size of CSV file ~470MB). So, we see that RAM size for dataframe more then 3 times more then original one.\n\n<H1>Let's work with categorial data using LabelEncoder, every column will be changed to numbers and then we convert DataFrame to the H2OFrame for uning it in AutoML learning<\/H1>","11c97851":"RAM: free 15427996 KB after converting DataFrame to H2OFrame","4d90c96b":"<H1>Fraud detection dataset with categorical data<\/H1>\n\n<B>Name of competition:<\/B> Synthetic Financial Datasets For Fraud Detection\n<B>link:<\/B> https:\/\/www.kaggle.com\/ntnu-testimon\/paysim1\n\nfirstly, we add dataset from kaggle competition"}}