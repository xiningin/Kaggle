{"cell_type":{"55e9bc26":"code","0bca5086":"code","ce33225c":"code","c38b9cde":"code","255c0e0e":"markdown","5ef663e2":"markdown","f61684b8":"markdown","8628590b":"markdown"},"source":{"55e9bc26":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport sklearn \nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.naive_bayes import MultinomialNB, BernoulliNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nimport random\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint('\\n'.join(os.listdir(\"..\/input\")))\n\n# Any results you write to the current directory are saved as output.","0bca5086":"def read_tsv(data_file):\n    text_data = list()\n    labels = list()\n    infile = open(data_file, encoding='utf-8')\n    for line in infile:\n        if not line.strip():\n            continue\n        label, text = line.split('\\t')\n        text_data.append(text)\n        labels.append(label)\n    return text_data, labels\n\n###############################################################\n\ndef load(pos_train_file, neg_train_file, pos_test_file, neg_test_file):\n    pos_train_data, pos_train_labels = read_tsv(pos_train_file)\n    neg_train_data, neg_train_labels = read_tsv(neg_train_file)\n\n    pos_test_data, pos_test_labels = read_tsv(pos_test_file)\n    neg_test_data, neg_test_labels = read_tsv(neg_test_file)\n    print('------------------------------------')\n\n    sample_size = 5\n    print('{} random train tweets (positive) .... '.format(sample_size))\n    print(np.array(random.sample(pos_train_data, sample_size)))\n    print('------------------------------------')\n    print('{} random train tweets (negative) .... '.format(sample_size))\n    print(np.array(random.sample(neg_train_data, sample_size)))\n    print('------------------------------------')\n\n    x_train = pos_train_data + neg_train_data\n    y_train = pos_train_labels + neg_train_labels\n\n    x_test = pos_test_data + neg_test_data\n    y_test = pos_test_labels + neg_test_labels\n\n    print('train data size:{}\\ttest data size:{}'.format(len(y_train), len(y_test)))\n    print('train data: # of pos:{}\\t# of neg:{}\\t'.format(y_train.count('pos'), y_train.count('neg')))\n    print('test data: # of pos:{}\\t# of neg:{}\\t'.format(y_test.count('pos'), y_test.count('neg')))\n    print('------------------------------------')\n    return x_train, y_train, x_test, y_test\n\n###############################################################\n\ndef do_sa(n, my_classifier, name, my_data):\n    x_train, y_train, x_test, y_test = my_data\n    print('parameters')\n    print('n grams:', n)\n    print('classifier:', my_classifier.__class__.__name__)\n    print('------------------------------------')\n\n    pipeline = Pipeline([\n        ('vect', TfidfVectorizer(min_df=0.0001, max_df=0.95,\n                                 analyzer='word', lowercase=False,\n                                 ngram_range=(1, n))),\n        ('clf', my_classifier),\n    ])\n\n    pipeline.fit(x_train, y_train)\n    feature_names = pipeline.named_steps['vect'].get_feature_names()\n\n    y_predicted = pipeline.predict(x_test)\n\n    # Print the classification report\n    print(metrics.classification_report(y_test, y_predicted,\n                                        target_names=['pos', 'neg']))\n\n    # Print the confusion matrix\n    cm = metrics.confusion_matrix(y_test, y_predicted)\n    print(cm)\n    print('# of features:', len(feature_names))\n    print('sample of features:', random.sample(feature_names, 40))\n    accuracy = accuracy_score(y_test, y_predicted)\n    precision = precision_score(y_test, y_predicted, average='weighted')\n    recall =  recall_score(y_test, y_predicted, average='weighted')\n    return name, n, accuracy, precision, recall\n","ce33225c":"ngrams = (1, 2, 3)\nresults = []\npos_training = '..\/input\/train_Arabic_tweets_positive_20190413.tsv'\nneg_training = '..\/input\/train_Arabic_tweets_negative_20190413.tsv'\n\npos_testing = '..\/input\/test_Arabic_tweets_positive_20190413.tsv'\nneg_testing = '..\/input\/test_Arabic_tweets_negative_20190413.tsv'\n\nclassifiers = [LinearSVC(), SVC(), MultinomialNB(),\n               BernoulliNB(), SGDClassifier(), DecisionTreeClassifier(max_depth=5),\n               RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n               KNeighborsClassifier(3)\n               ]\nfor g in ngrams:\n    dataset = load(pos_training, neg_training, pos_testing, neg_testing)\n    for alg in classifiers:\n        alg_name = alg.__class__.__name__\n        r = do_sa(g, alg, alg_name, dataset)\n        results.append(r)\n        ","c38b9cde":"print('{0:25}{1:10}{2:10}{3:10}{4:10}'.format('algorithm', 'ngram', 'accuracy', 'precision', 'recall'))\nprint('---------------------------------------------------------------------')\nfor r in results:\n    print('{0:25}{1:10}{2:10.3f}{3:10.3f}{4:10.3f}'.format(r[0], r[1], r[2], r[3], r[4]))","255c0e0e":"# define functions","5ef663e2":"# Sentiment Analysis in Arabic tweets using sklearn ML algorithms and 1,2,3 gram features","f61684b8":"# Setup experiments ","8628590b":" #  Results Summary"}}