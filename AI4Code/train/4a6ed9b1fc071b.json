{"cell_type":{"dccd2851":"code","0644c0b4":"code","ea3870b4":"code","dca16776":"code","03d19e99":"code","421f5e6f":"code","3ad52348":"code","3af9c611":"code","c5f73b3a":"code","f3859374":"code","02a251d7":"code","cad3507e":"code","7f5fbf9c":"code","66aa5977":"code","a79e2c4a":"code","71c6fbf0":"code","68ee317d":"code","1f0825c6":"code","1558d765":"code","1a5ea506":"markdown","69faafc3":"markdown","65e8ddf3":"markdown","ec3fd341":"markdown"},"source":{"dccd2851":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0644c0b4":"import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error","ea3870b4":"# In this cell, Train and Test sets are loaded\ntrain=pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\ntest = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/test.csv')","dca16776":"train.head()","03d19e99":"test.head()","421f5e6f":"train['item_cnt_day']=abs(train['item_cnt_day'])","3ad52348":"train.drop(columns=['date','item_price'],axis=1,inplace=True)\ntrain.drop_duplicates(inplace=True,keep='first',ignore_index=True)","3af9c611":"train","c5f73b3a":"train1=pd.pivot_table(train,index=['shop_id','item_id'],columns='date_block_num',values='item_cnt_day',aggfunc=np.sum).reset_index()\ntrain1\n# Here the columns 0,1...33 have the items_per_month values","f3859374":"test1=test.merge(train1,how='left',on=['shop_id','item_id']).drop(columns=['shop_id','item_id']).fillna(value=0)\ntest1","02a251d7":"x_train=test1.iloc[:,1:-1]\ny_train=test1.iloc[:,-1]\nx_test=test1.iloc[:,2:]","cad3507e":"x_train","7f5fbf9c":"y_train","66aa5977":"x_test","a79e2c4a":"lr=LinearRegression()\nlr.fit(x_train,y_train)\nprint('Linear Regression model score is:',lr.score(x_train,y_train))\nprint('MSE: ',mean_squared_error(y_train,lr.predict(x_train)))\nlr.predict(x_test)","71c6fbf0":"dr=DecisionTreeRegressor()\ndr.fit(x_train,y_train)\nprint('DecisionTreeRegressor model score is:',dr.score(x_train,y_train))\nprint('MSE: ',mean_squared_error(y_train,dr.predict(x_train)))\ndr.predict(x_test)","68ee317d":"gb=GradientBoostingRegressor()\ngb.fit(x_train,y_train)\nprint('GradientBoostRegressor model score is:',gb.score(x_train,y_train))\nprint('MSE: ',mean_squared_error(y_train,gb.predict(x_train)))\ny_pred=gb.predict(x_test)","1f0825c6":"rr=RandomForestRegressor()\nrr.fit(x_train,y_train)\nprint('RandomForestRegressor model score is:',rr.score(x_train,y_train))\nprint('MSE: ',mean_squared_error(y_train,rr.predict(x_train)))\nrr.predict(x_test)","1558d765":"output = pd.DataFrame({'Id':test1.iloc[:,0],'item_cnt_month': [abs(i) for i in y_pred.tolist()]})\noutput.to_csv('mysubmission.csv', index=False)","1a5ea506":"Here i am submitting the GradientBoostingRegressor predictions as it is giving the best score among the above all.","69faafc3":"### Here the Target feature is 'item_cnt_day' which is a continuous quantity.\n### But the independent features ['shop_id','item_id'] are discrete\/labeled...\n### Hence we go for Pivoting to get the no. of items sold per month for the respective ['shop_id','item_id']","65e8ddf3":"### From the train set, we can observe that the feature 'date' is trivial as it infers the same as the feature 'date_block_num', hence i will drop this 'date' feature.\n### I will also drop the feature 'item_price' as it is not given in the test data, so what's the purpose of training our model considering this feature if we are not going to make predictions using this feature.","ec3fd341":"### In below step, we then merge train1 and test to convert the test[['shop_id','item_id']] into the number of the respected items\/sold\/month for the past 34 months."}}