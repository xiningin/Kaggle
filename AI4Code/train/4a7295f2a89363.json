{"cell_type":{"e557fb5f":"code","e3bb8117":"code","cf1904e9":"code","72b72208":"code","f49a9c61":"code","391cd045":"code","e90af44d":"code","d2fdecd2":"code","d657b383":"code","f0ecd852":"code","345ec8a5":"code","10e53f1f":"code","3bf5a4b0":"code","e653e681":"code","29be120b":"markdown","12e9f209":"markdown","b61720d2":"markdown","8dc2219f":"markdown","a84a9edd":"markdown","c0a9615f":"markdown","e329ea44":"markdown","af32524b":"markdown","f81ff3b6":"markdown","1a5df276":"markdown","d7857e68":"markdown","5825e9ed":"markdown"},"source":{"e557fb5f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #matplotlib for viewing images\nimport tensorflow as tf   ","e3bb8117":"mnist = tf.keras.datasets.mnist   #importing the dataset","cf1904e9":"(x_train,y_train),(x_test,y_test) = mnist.load_data()","72b72208":"print(x_train[1])       ","f49a9c61":"print(y_train[1])","391cd045":"plt.imshow(x_train[1], cmap='binary_r')     \nplt.show()","e90af44d":"model = tf.keras.Sequential()                    # Sequential groups a linear stack of layers into a model\n\n#Input Layer\nmodel.add(tf.keras.layers.Flatten())             # Flattens the input\n\n#Layers\nmodel.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))   # layer 1\nmodel.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))   # layer 2\nmodel.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))   # layer 3\n\n#Output Layers\nmodel.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))  ","d2fdecd2":"# Compiling the model\nmodel.compile(optimizer=\"adam\",loss='sparse_categorical_crossentropy',metrics=['accuracy'])","d657b383":"model.fit(x_train,y_train,epochs=5)     # Training, epochs:5 -> Cycles through the full training set for 5 times","f0ecd852":"loss,acc = model.evaluate(x_test,y_test)    # returns the loss and accuracy","345ec8a5":"pred = model.predict(x_test)     #storing the prediction result","10e53f1f":"pred[0]","3bf5a4b0":"np.argmax(pred[0])          # argmax() returns the index with the largest element","e653e681":"plt.imshow(x_test[0],cmap=\"binary_r\")         #Verfying the prediction by viewing the handwritten digit at x_test[0]\nplt.show","29be120b":"## Understanding the Data","12e9f209":"imshow() : visualize the pixel data points ,cmap: name of a registered colormap","b61720d2":"## Conclusion\n\nIn this notebook, we made a very simple model to predict hand-written digits from the MNIST Dataset. We used Tensorflow , which is an open source machine learning framework. In the notebook, Sub-topics like Understandig Data,  Model Creation were expressed in a well document way so that anyone who reads it can take away points from this notebook and work on it. Happy Learning!\n\n[Five PyTorch Functions you should know!](https:\/\/www.kaggle.com\/amartyanambiar\/5-pytorch-tensor-functions-you-should-know)\n\n[Brush up your NumPy Basics](https:\/\/www.kaggle.com\/amartyanambiar\/numpy-brush-up)","8dc2219f":"## Importing Libraries","a84a9edd":"The Hand-written digit is 0. Now let's convert the data into an image and verify it.","c0a9615f":"#### Splitting the dataset into training and testing sets","e329ea44":"Optimizer is used for optimizing the input weights by comparing the prediction and the loss function.\n\nLoss function is used to find error or deviation in the learning process. ","af32524b":"## MNIST Data Splitting","f81ff3b6":"## Model Training & Evaluation ","1a5df276":"## Prediction","d7857e68":"## Model Creation","5825e9ed":" Viewing the x_train set at index 1, this is how the image in encoded in pixel values of RGB"}}