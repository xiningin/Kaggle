{"cell_type":{"f7f9e508":"code","38f9e297":"code","729c196a":"code","53af9844":"code","8006683c":"code","9556bdf4":"code","ae07c7c5":"code","0e60ec5f":"code","3fb682e1":"code","7caad921":"code","882e539b":"code","d3d291d0":"code","dd3753b0":"code","2e7944fe":"code","108b931e":"code","9b98f010":"code","d95eb36c":"code","76025a20":"code","a78cb451":"code","c58e9859":"code","d8636636":"code","894cde15":"code","ae72f1ef":"code","43ad37e0":"code","25bc3707":"code","9e62625a":"code","71e06689":"code","4bddf5f0":"code","07e75a8e":"code","5607c5df":"code","13c59897":"code","2cdba9a0":"code","8c20577d":"code","deb7af0a":"code","769c0563":"code","1f21092f":"code","6fe908ca":"code","63626621":"code","e0708e81":"code","4972188c":"code","fc156914":"code","d7738fa1":"code","891876aa":"code","dea6a7e2":"code","0c85f345":"code","9ac49f4b":"code","b1ba0f23":"code","edcc3738":"code","90546c29":"code","62dd88af":"code","ff98bbb2":"code","ab876309":"code","88050c92":"code","65e1b8dc":"code","ce2c88e4":"code","81a874b8":"code","e4c56af4":"code","4fbc8fb5":"code","ef718b34":"code","99975c79":"code","0b0b3b31":"code","72f89642":"code","b054b813":"code","4c90b661":"code","d54b974c":"code","a76430b6":"code","c6346d27":"code","8a38aa3a":"code","ced67438":"code","fce2bb2e":"code","134bb5c6":"code","8575059b":"code","bc0482c1":"code","a75dce46":"code","1e8025c0":"code","df418308":"code","4009efac":"code","80c52d41":"code","e7aa62c6":"code","9d3fbe12":"code","767dadf7":"code","73652030":"code","156378bd":"code","7de40841":"markdown","bf8f5cea":"markdown","868ec05f":"markdown","3d76f741":"markdown","3725ef42":"markdown","e6f0ec38":"markdown","c78a41f7":"markdown","0492dcd6":"markdown","4be7358d":"markdown","5ec2f754":"markdown","c0153354":"markdown","7316c2b1":"markdown","171784f1":"markdown","80f8865e":"markdown","509fde7d":"markdown","7e40e8af":"markdown","a8801551":"markdown","e2cf39a5":"markdown","c0e7cebe":"markdown","0252f0e7":"markdown","eef40c5f":"markdown","08a37d84":"markdown"},"source":{"f7f9e508":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","38f9e297":"train_data=pd.read_csv('..\/input\/used-cars-price-prediction\/train-data.csv')\ntrain_data.head()","729c196a":"#Importing required packages for data manipulation, cleaning, and visualisation\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","53af9844":"#Browsing the data\n\ntrain_data.iloc[:10,:8]","8006683c":"# Columns of the data stored\n\ntrain_data.columns","9556bdf4":"train_data.info()","ae07c7c5":"# Dropping columns having a lot of null values and which are not significant also\n\ntrain_data = train_data.drop(columns = ['New_Price','Unnamed: 0'])","0e60ec5f":"train_data","3fb682e1":"# Dropping all the rows with null values\n\ntrain_data = train_data.dropna(axis = 0)","7caad921":"# Checking if null values are still left\n\ntrain_data.isnull().sum()","882e539b":"train_data = train_data.reset_index(drop=True)","d3d291d0":"for i in range(train_data.shape[0]):\n    train_data.at[i, 'Company'] = train_data['Name'][i].split()[0]\n    train_data.at[i, 'Mileage(km\/kg)'] = train_data['Mileage'][i].split()[0]\n    train_data.at[i, 'Engine(CC)'] = train_data['Engine'][i].split()[0]\n    train_data.at[i, 'Power(bhp)'] = train_data['Power'][i].split()[0]","dd3753b0":"train_data['Mileage(km\/kg)'] = train_data['Mileage(km\/kg)'].astype(float)\ntrain_data['Engine(CC)'] = train_data['Engine(CC)'].astype(float)","2e7944fe":"train_data['Power(bhp)'][76]","108b931e":"x = 'n'\ncount = 0\nposition = []\nfor i in range(train_data.shape[0]):\n    if train_data['Power(bhp)'][i]=='null':\n        x = 'Y'\n        count = count + 1\n        position.append(i)\nprint(x)\nprint(count)\nprint(position)","9b98f010":"train_data = train_data.drop(train_data.index[position])\ntrain_data = train_data.reset_index(drop=True)","d95eb36c":"train_data['Power(bhp)'] = train_data['Power(bhp)'].astype(float)","76025a20":"train_data","a78cb451":"train_data.drop([\"Name\"],axis=1,inplace=True)\ntrain_data.drop([\"Mileage\"],axis=1,inplace=True)\ntrain_data.drop([\"Engine\"],axis=1,inplace=True)\ntrain_data.drop([\"Power\"],axis=1,inplace=True)","c58e9859":"train_data","d8636636":"# Storing Target variable in Y\n\ny = train_data['Price']\ny.head(10)","894cde15":"train_data.columns","ae72f1ef":"# Changing Categorical data into Quantitative data using Get_dummies function\nX= train_data.drop(['Price'],axis=1)\nX = pd.get_dummies(X,columns=['Location', 'Year', 'Fuel_Type', 'Transmission',\n       'Owner_Type', 'Company'])","43ad37e0":"X.head()","25bc3707":"X.columns","9e62625a":"#Adding constant to the dataframe\n\nimport statsmodels.api as sm\n\nX = sm.add_constant(X)","71e06689":"# Checking shape of X\n\nX.shape","4bddf5f0":"# Checking shape of Y\n\ny.shape","07e75a8e":"#Splitting of X & Y for training & testing\n\nfrom sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=10)","5607c5df":"# Checking shape of all splitted data\n\nX_train.shape,X_test.shape,y_train.shape,y_test.shape","13c59897":"#fitting data into OLS model\n\npr_1 = sm.OLS(y_train,X_train)\npr_1 = pr_1.fit()","2cdba9a0":"# Getting Summary\n\npr_1.summary2()","8c20577d":"#Plotting correlation heatmap\n\nplt.figure(figsize=(50,50))\n\nsns.heatmap(abs(X.corr()>=0.7),annot=True);","deb7af0a":"X = X.drop(columns = ['Power(bhp)'])","769c0563":"# Rebuilding model\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=10)\n\n#Again Fitting the OLS model\n\npr_2 = sm.OLS(y_train,X_train)\n\npr_2 = pr_2.fit()\n\npr_2.summary2()","1f21092f":"X = X.drop(columns = ['Location_Ahmedabad', 'Location_Jaipur', 'Location_Pune', 'Year_1999', 'Year_2000', 'Year_2001', 'Year_2002', 'Year_2012', 'Fuel_Type_Diesel', 'Fuel_Type_CNG', 'Owner_Type_Fourth & Above', 'Owner_Type_Third', 'Owner_Type_Second', 'Company_Ambassador', 'Company_Bentley', 'Company_Isuzu', 'Company_Volvo'])","6fe908ca":"# Rebuilding model\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=10)\n\n#Again Fitting the OLS model\n\npr_3 = sm.OLS(y_train,X_train)\n\npr_3 = pr_3.fit()\n\npr_3.summary2()","63626621":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\ndef var_inf_factor(data):\n    vif = pd.DataFrame()\n    vif['Feature'] = data.columns\n    vif['Factor'] = [variance_inflation_factor(data.values,i) for i in range(data.shape[1])]\n    return(vif)","e0708e81":"vif_factors = var_inf_factor(X)","4972188c":"print(vif_factors)","fc156914":"# Getting Variables with VIF more than 4\n\ncolumns_with_large_vif = vif_factors[vif_factors.Factor > 4]","d7738fa1":"print(columns_with_large_vif)","891876aa":"X = X.drop(columns = ['Engine(CC)', 'Transmission_Automatic', 'Company_Audi', 'Company_BMW', 'Company_Chevrolet', 'Company_Ford', 'Company_Honda', 'Company_Hyundai', 'Company_Mahindra', 'Company_Maruti', 'Company_Mercedes-Benz', 'Company_Nissan', 'Company_Renault', 'Company_Skoda', 'Company_Tata', 'Company_Toyota', 'Company_Volkswagen'])","dea6a7e2":"# Rebuilding model\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=10)\n\n#Again Fitting the OLS model\n\npr_4 = sm.OLS(y_train,X_train)\n\npr_4 = pr_4.fit()\n\npr_4.summary2()","0c85f345":"vif_factors = var_inf_factor(X)\nprint(vif_factors)","9ac49f4b":"# Getting Variables with VIF more than 4\n\ncolumns_with_large_vif = vif_factors[vif_factors.Factor > 4]\n\nprint(columns_with_large_vif)","b1ba0f23":"X = X.drop(columns = ['const'])","edcc3738":"# Rebuilding model\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=10)\n\n#Again Fitting the OLS model\n\npr_5 = sm.OLS(y_train,X_train)\n\npr_5 = pr_5.fit()\n\npr_5.summary2()","90546c29":"vif_factors = var_inf_factor(X)\n\nprint(vif_factors)","62dd88af":"# Getting Variables with VIF more than 4\n\ncolumns_with_large_vif = vif_factors[vif_factors.Factor > 4]\n\nprint(columns_with_large_vif)","ff98bbb2":"X = X.drop(columns = ['Location_Kochi','Location_Kolkata','Year_1998','Year_2003','Year_2004','Year_2005','Year_2006','Year_2007','Year_2008','Year_2009','Fuel_Type_LPG','Company_Fiat','Company_Force','Company_ISUZU','Company_Mitsubishi'])","ab876309":"# Rebuilding model\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=10)\n\n#Again Fitting the OLS model\n\npr_6 = sm.OLS(y_train,X_train)\n\npr_6 = pr_6.fit()\n\npr_6.summary2()","88050c92":"X = X.drop(columns = ['Company_Datsun'])","65e1b8dc":"# Rebuilding model\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=10)\n\n#Again Fitting the OLS model\n\npr_7 = sm.OLS(y_train,X_train)\n\npr_7 = pr_7.fit()\n\npr_7.summary2()","ce2c88e4":"pr_final = pr_7\n\npr_final.summary2()","81a874b8":"# Finding Residues\n\npr_final_resid = pr_final.resid\npr_final_resid","e4c56af4":"# Plotting Density plot of residues\n\nsns.set(rc = {'figure.figsize':(15,15)})\nsns.distplot(pr_final_resid);","4fbc8fb5":"# Plotting PP Plot of residues\n\ndef draw_pp_plot(model):\n    probplot=sm.ProbPlot(model.resid)\n    plt.figure(figsize=(12,9))\n    probplot.ppplot(line='45')\n    plt.show();","ef718b34":"sns.set(rc = {'figure.figsize':(15,15)});\ndraw_pp_plot(pr_final);","99975c79":"# Defining a function for normalising the data\n\ndef standardisation(data):\n    return ((data-data.mean())\/data.std())\n\n# Defining a function for plotting a residual plot\n\ndef residual_plot(model):\n    plt.scatter(standardisation(model.fittedvalues),standardisation(model.resid));\n    plt.title('Residual Plot');\n    plt.xlabel('Standardised Fitted Values');\n    plt.ylabel('Standardised Residue Values');","0b0b3b31":"# Checking homoscedasticity\n\nsns.set(rc = {'figure.figsize':(15,15)})\nresidual_plot(pr_final)","72f89642":"X.shape","b054b813":"# No. of observations: n\nn = 5872\n\n# No. of features in the model created: k\nk = 27\nleverage_cutoff = 3*((k+1)\/n)\n\nprint('Leverage cut-off value:',leverage_cutoff)","4c90b661":"# Plotting Influence Plot\n\nfrom statsmodels.graphics.regressionplots import influence_plot\n\nsns.set(rc = {'figure.figsize':(20,20)});\ninfluence_plot(pr_final);","d54b974c":"#Finding Leverage distance of observations, for dropping outliers\n\nimport statsmodels.stats.outliers_influence as ssoi\n\not = ssoi.OLSInfluence(pr_final)","a76430b6":"# Showing Outliers with Leverage distance > Leverage Cutoff\n\nlev=ot.summary_frame()\nlev","c6346d27":"lev[lev['hat_diag']>leverage_cutoff]\npr_final_1=lev[lev['hat_diag']>leverage_cutoff]\npr_final_1.index","8a38aa3a":"#Dropping the Outliers\n\nX=X.drop(pr_final_1.index)\ny=y.drop(pr_final_1.index)","ced67438":"#New Target Variable Y\n\ny.head(10)\ny.shape","fce2bb2e":"# New X after removing outliers\n\nX.head(10)\nX.shape","134bb5c6":"#Splitting the data\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=10)\nX_train.shape,X_test.shape,y_train.shape,y_test.shape","8575059b":"# Fitting the OLS model\n\npr_mod_1 = sm.OLS(y_train,X_train)\n\npr_mod_1 = pr_mod_1.fit()\n\npr_mod_1.summary2()","bc0482c1":"X = X.drop(columns = ['Company_Jeep','Company_Lamborghini'])","a75dce46":"# Rebuilding model\n\n#Splitting the data\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=10)\nX_train.shape,X_test.shape,y_train.shape,y_test.shape\n\n# Fitting the OLS model\n\npr_mod_2 = sm.OLS(y_train,X_train)\n\npr_mod_2 = pr_mod_2.fit()\n\npr_mod_2.summary2()","1e8025c0":"y_pred = pr_mod_2.predict(X_test)\ny_pred.head()","df418308":"y_test.head()","4009efac":"#Finding R2 Score \n\nfrom sklearn.metrics import r2_score,mean_squared_error\n\npr_mod_2_r2 = r2_score(y_test,y_pred)\nprint('R2 Score of Price Model 2:', pr_mod_2_r2)","80c52d41":"#Finding Mean Square Error\n\npr_mod_2_mse=mean_squared_error(y_pred,y_test)\n\nprint('MSE of Price Model 2:', pr_mod_2_mse)","e7aa62c6":"# Convert y into: sqrt(y)\n\ny1 = np.sqrt(y)\ny1.head(10)","9d3fbe12":"# Defining X value\n\nX_trans_1 = X","767dadf7":"# Rebuilding model\n\n# Splitting data for Training and Testing\n\nX_train,X_test,y_train,y_test = train_test_split(X_trans_1,y1,test_size=0.2,random_state=10)\nX_train.shape,X_test.shape,y_train.shape,y_test.shape\n\n# Building the OLS Model\n\npr_trans_1 = sm.OLS(y_train,X_train)\n\npr_trans_1 = pr_trans_1.fit()\n\npr_trans_1.summary2()","73652030":"# Details required to predict lead Time for any future customer...\n\nDetails=X_trans_1.columns.tolist()\nDetails","156378bd":"# Coefficients of all the columns\n\nparameters=pr_trans_1.params\n\nCoeff=[]\nfor i in range(len(Details)):\n    Coeff.append(parameters[i])\nCoeff","7de40841":"## Removing Outliers","bf8f5cea":"Multiple Linear Regression\n\n\ud835\udc66=\ud835\udefd0+\ud835\udefd1.\ud835\udc4b1+\ud835\udefd2.\ud835\udc4b2+...+\ud835\udefd\ud835\udc5b.\ud835\udc4b\ud835\udc5b+\ud835\udf16","868ec05f":"## Splitting of the data into Training and Testing","3d76f741":"## Finding out the Target variable (y) i.e., Price","3725ef42":"## Preprocessing of the data","e6f0ec38":"#### We got R-Squared value = 0.921 (Model with highest efficiency)","c78a41f7":"## Transforming the Target Variable","0492dcd6":"#### Trying to increase R-square value by transforming target variable","4be7358d":"### Correlation between Features using Heatmap","5ec2f754":"#### Inference-\n\n* There are some observations with leverage value > leverage_cut off, therefore are Outliers\n\n* Hence, must be dropped","c0153354":"## Final Model Creation for future use...","7316c2b1":"## Modifying the Model After Removing Outliers","171784f1":"## Finding the Performance of the Model","80f8865e":"## Leverage Distance","509fde7d":"### Removing unnecessary columns on the basis of multicollinearity, correlation, p-value","7e40e8af":"### Residual Analysis Findings:\n\n* No funnel like shape\n\n* No heteroscedasticity\n\n* So, homoscedasticity is satisfied.","a8801551":"### Checking Multicollinearity","e2cf39a5":"## Building the Model","c0e7cebe":"## Residual Analysis","0252f0e7":"### Modifying the model with transformed Target Values","eef40c5f":"## The Final Model","08a37d84":"## Data Cleaning"}}