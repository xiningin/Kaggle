{"cell_type":{"aac9d2a8":"code","3892c670":"code","cf2f1ecb":"code","b2775946":"code","b52c4957":"code","a17c47a8":"code","fa0d5eac":"code","e7019ba3":"code","8d460b0c":"code","f35ae56e":"code","9d21e2e1":"code","121554f5":"code","ec8a9df4":"code","5cf8374c":"code","c1b42eb3":"code","82703b49":"code","be231f13":"code","a4e0e3a6":"code","66f8b208":"code","402b1c31":"code","bde0b3a5":"markdown","a2a53e0c":"markdown","c5e7000c":"markdown","7b63c2c9":"markdown","6add2ccb":"markdown","6b8a2051":"markdown","2513adf6":"markdown","d1e5bbfa":"markdown","c8a6f92b":"markdown","518feeec":"markdown","a09dd0b8":"markdown"},"source":{"aac9d2a8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","3892c670":"# !ls ..\/input\/train_images","cf2f1ecb":"# time\nimport time\n# import OpenCV\nimport cv2\n# random\nimport random\nrandom.seed(1331)\n# viz\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.applications.mobilenet_v2 import MobileNetV2\nconv_base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))","b2775946":"conv_base.summary()","b52c4957":"print(cv2.imread('..\/input\/train_images\/8132fabfd-10.jpg').shape)\nprint(cv2.imread('..\/input\/train_images\/beb0f98f7-1.jpg').shape)\nprint(cv2.imread('..\/input\/train_images\/d168549f2-4.jpg').shape)\nprint(cv2.imread('..\/input\/train_images\/9d6c6055b-2.jpg').shape)\nprint(cv2.imread('..\/input\/train_images\/a6593fb48-6.jpg').shape)\nprint(cv2.imread('..\/input\/train_images\/ea1736eec-4.jpg').shape)\nprint(cv2.imread('..\/input\/train_images\/f205b0649-6.jpg').shape)\nprint(cv2.imread('..\/input\/train_images\/f888d5f54-3.jpg').shape)\nprint(cv2.imread('..\/input\/train_images\/bcf546cb8-3.jpg').shape)\nprint(cv2.imread('..\/input\/train_images\/3fd545213-6.jpg').shape)","a17c47a8":"# read in image\nimg = cv2.imread('..\/input\/train_images\/0008c5398-1.jpg')\nimg = cv2.resize(img, (224,224))\n# show image\nplt.imshow(img)","fa0d5eac":"np.max(img)","e7019ba3":"# read in training dataset\ntrain_df = pd.read_csv('..\/input\/train\/train.csv')\n# only grab the ID and target\npet_ids_and_target = train_df[['PetID','AdoptionSpeed']]\n# Get one-hot representation using get_dummies\nonehottarget = pd.get_dummies(pet_ids_and_target['AdoptionSpeed'])\n# merge one-hot encodings back to our table\npet_ids_and_target = pet_ids_and_target.join(onehottarget)\n# show our final table\nprint(pet_ids_and_target.head())","8d460b0c":"# test out AdoptionSpeed extraction code\ngetrow = pet_ids_and_target.loc[pet_ids_and_target['PetID'] == 'bec2fe7ad']\nprint(getrow)\nprint(np.asarray(getrow[[0,1,2,3,4]].values[0], dtype=np.float32))","f35ae56e":"def MyAug(fiximg, shape):\n    auglist = [fiximg]\n    \n    # we can only fit so much into memory\n    # so every round we will randomly select an augmentation to apply for training\n    augshuf = random.randint(1,101)\n    \n    if augshuf in range(1,11):\n    \n        # Augmentation 1\n\n        # blur image using 25x25 kernel\n        blurred = cv2.blur(fiximg, ksize=(25,25))\n        # write out image\n        auglist.append(blurred)\n    \n    elif augshuf in range(11,21):\n    \n        # Augmentation 2\n\n        # covert to HSV\n        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n        # We're going to equalize the value channel\n        hsv[:,:,2] = cv2.equalizeHist(hsv[:,:,2])\n        # convert back to RGB\n        eq_color_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n        # write out image\n        auglist.append(eq_color_img)\n    \n    elif augshuf in range(21,31):\n    \n        # Augmentation 3\n\n        y_offsetp1 = int(fiximg.shape[0]*0.25)\n        y_offsetp2 = int(fiximg.shape[0]*0.75)\n        x_offsetp1 = int(fiximg.shape[1]*0.25)\n        x_offsetp2 = int(fiximg.shape[1]*0.75)\n        # crop\n        cropped_img = fiximg[y_offsetp1:y_offsetp2,x_offsetp1:x_offsetp2]\n        cropped_img = cv2.resize(cropped_img, shape)\n        # write out image\n        auglist.append(cropped_img)\n    \n    elif augshuf in range(31,41):\n    \n        # Augmentation 4\n\n        y_offsetp1 = int(fiximg.shape[0]*0)\n        y_offsetp2 = int(fiximg.shape[0]*0.6)\n        x_offsetp1 = int(fiximg.shape[1]*0)\n        x_offsetp2 = int(fiximg.shape[1]*0.6)\n        # crop\n        cropped_img = fiximg[y_offsetp1:y_offsetp2,x_offsetp1:x_offsetp2]\n        cropped_img = cv2.resize(cropped_img, shape)\n        # write out image\n        auglist.append(cropped_img)\n\n    elif augshuf in range(41,51):\n        \n        # Augmentation 5\n\n        y_offsetp1 = int(fiximg.shape[0]*0)\n        y_offsetp2 = int(fiximg.shape[0]*0.6)\n        x_offsetp1 = int(fiximg.shape[1]*0.4)\n        x_offsetp2 = int(fiximg.shape[1]*1)\n        # crop\n        cropped_img = fiximg[y_offsetp1:y_offsetp2,x_offsetp1:x_offsetp2]\n        cropped_img = cv2.resize(cropped_img, shape)\n        # write out image\n        auglist.append(cropped_img)\n    \n    elif augshuf in range(51,61):\n    \n        # Augmentation 6\n\n        y_offsetp1 = int(fiximg.shape[0]*0)\n        y_offsetp2 = int(fiximg.shape[0]*0.6)\n        x_offsetp1 = int(fiximg.shape[1]*0.4)\n        x_offsetp2 = int(fiximg.shape[1]*1)\n        # crop\n        cropped_img = fiximg[y_offsetp1:y_offsetp2,x_offsetp1:x_offsetp2]\n        cropped_img = cv2.resize(cropped_img, shape)\n        # write out image\n        auglist.append(cropped_img)\n    \n    elif augshuf in range(61,71):\n    \n        # Augmentation 7\n    \n        y_offsetp1 = int(fiximg.shape[0]*0.4)\n        y_offsetp2 = int(fiximg.shape[0]*1)\n        x_offsetp1 = int(fiximg.shape[1]*0.4)\n        x_offsetp2 = int(fiximg.shape[1]*1)\n        # crop\n        cropped_img = fiximg[y_offsetp1:y_offsetp2,x_offsetp1:x_offsetp2]\n        cropped_img = cv2.resize(cropped_img, shape)\n        # write out image\n        auglist.append(cropped_img)\n    \n    elif augshuf in range(71,81):\n    \n        # Augmentation 8\n\n        xp1 = min(.15,random.randint(1,100)\/100)\n        xp2 = max(.85,random.randint(1,100)\/100)\n        yp1 = min(.15,random.randint(1,100)\/100)\n        yp2 = max(.85,random.randint(1,100)\/100)\n        # create points\n        y_offsetp1 = int(fiximg.shape[0]*yp1)\n        y_offsetp2 = int(fiximg.shape[0]*yp2)\n        x_offsetp1 = int(fiximg.shape[1]*xp1)\n        x_offsetp2 = int(fiximg.shape[1]*xp2)\n        # crop\n        cropped_img = fiximg[y_offsetp1:y_offsetp2,x_offsetp1:x_offsetp2]\n        cropped_img = cv2.resize(cropped_img, shape)\n        # write out image\n        auglist.append(cropped_img)\n        \n    elif augshuf in range(81,91):\n    \n        # Augmentation 9\n        \n        rot = random.choice(np.arange(-180,179,1))\n        if rot ==0:\n            rot = 179\n        rows,cols,_ = fiximg.shape\n        M = cv2.getRotationMatrix2D((cols\/2,rows\/2),rot,1)\n        dst = cv2.warpAffine(fiximg,M,(cols,rows))\n        # write out image\n        auglist.append(dst)\n        \n    elif augshuf in range(91,101):\n        \n        # Augmentation 10\n\n        rows,cols,ch = fiximg.shape\n        pts1 = np.float32([[50,50],[200,50],[50,200]])\n        pts2 = np.float32([[10,100],[200,50],[100,250]])\n        M = cv2.getAffineTransform(pts1,pts2)\n        dst = cv2.warpAffine(fiximg,M,(cols,rows))\n        # write out image\n        auglist.append(dst)\n    \n    return auglist","9d21e2e1":"def LoadImagesAndTarget_Train(files, lookup_table, shape):\n    # initialize variables\n    i = 0\n    w = shape[0]\n    h = shape[1]\n    batch_images = np.zeros(((len(files) * 2),w,h,3))\n    targetvals = np.zeros(((len(files) * 2),5))\n    for file in files:\n        # read in image\n        img = cv2.imread('..\/input\/train_images\/' + file)\n        # resize\n        img = cv2.resize(img, shape)\n        # apply augmentation\n        newimages = MyAug(img, shape)\n        # normalize\n        newimages = np.array(newimages) \/ 255.0\n        # 'newimages' should have our original image and an augmented version\n        # so we're creating a new matrix with our original images and augmentations\n        # and we include our target value for each\n        for img in newimages:\n            # add image to batch set\n            batch_images[i] = img\n            # get the filename without extension\n            filename = os.path.splitext(file)[0]\n            # get the id from the filename\n            id_from_filename = filename[0:filename.find('-')]\n            # only keep the row from the lookup table that matches our id\n            getrow = lookup_table.loc[lookup_table['PetID'] == id_from_filename]\n            # change the format to one-hot encoded, and save to target dataset\n            targetvals[i] = np.asmatrix(getrow[[0,1,2,3,4]].values[0], dtype=np.float32)\n            # iterate i\n            i += 1\n    return batch_images, targetvals","121554f5":"def LoadImagesAndTarget_Test(files, lookup_table, shape):\n    # initialize variables\n    i = 0\n    w = shape[0]\n    h = shape[1]\n    batch_images = np.zeros(((len(files)),w,h,3))\n    targetvals = np.zeros(((len(files)),5))\n    for file in files:\n        # read in image\n        img = cv2.imread('..\/input\/train_images\/' + file)\n        # resize\n        img = cv2.resize(img, shape)\n        # in validation we don't apply augmentation\n        # normalize\n        img = np.array(img) \/ 255.0\n        batch_images[i] = img\n        # get the filename without extension\n        filename = os.path.splitext(file)[0]\n        # get the id from the filename\n        id_from_filename = filename[0:filename.find('-')]\n        # only keep the row from the lookup table that matches our id\n        getrow = lookup_table.loc[lookup_table['PetID'] == id_from_filename]\n        # change the format to one-hot encoded, and save to target dataset\n        targetvals[i] = np.asmatrix(getrow[[0,1,2,3,4]].values[0], dtype=np.float32)\n        # get target based on filename\n        i += 1\n    #print(\"returning batches ...\")\n    return batch_images, targetvals","ec8a9df4":"def KerasModelTrainer(files, batch_size, lookup_table, epochs, test_size, shape):\n    \n    # initialize variables for storing history and calculating batches\n    L = len(files)\n    rnds = L \/\/ batch_size\n    training_loss_history_e = []\n    test_loss_history_e = []\n    training_acc_history_e = []\n    test_acc_history_e = []\n\n    for epoch in range(1,epochs + 1):\n        \n        # initialize variables for storing history and calculating batch ranges\n        batch_start = 0\n        batch_end = batch_size\n        test_cases = int(batch_size * test_size)\n        training_loss_history = []\n        test_loss_history = []\n        training_acc_history = []\n        test_acc_history = []\n        mycnt = 0\n        start = time.time()\n        \n        print(\"Epoch {}\/{}\".format(epoch,epochs))\n        \n        while batch_start < L:\n            \n            # initialize variables for calculating batch ranges and printing results\n            mycnt += 1\n            pct = int((mycnt \/ rnds) * 100)\n            limit = min(batch_end, L)\n\n            # load train and test images for training with augmentation\n            Xtrain, Ytrain = LoadImagesAndTarget_Train(files[batch_start:(limit - test_cases)], lookup_table, shape)\n            Xtest, Ytest = LoadImagesAndTarget_Test(files[((limit - test_cases)):limit], lookup_table, shape)    \n\n            # train\n            model.train_on_batch(Xtrain,Ytrain)\n\n            # test on train\n            training_metrics = model.test_on_batch(Xtrain,Ytrain)\n            training_loss = training_metrics[0]\n            training_acc = training_metrics[1]\n            \n            # save model training metrics\n            training_loss_history.append(training_loss)\n            training_acc_history.append(training_acc)\n            \n            # test on test\n            test_metrics = model.test_on_batch(Xtest,Ytest)\n            test_loss = test_metrics[0]\n            test_acc = test_metrics[1]\n            \n            # save model test\\validation metrics\n            test_loss_history.append(test_loss)\n            test_acc_history.append(test_acc)\n            \n            # update batch window\n            batch_start += batch_size   \n            batch_end += batch_size\n            \n            # update overall performance\n            if np.isnan(np.mean(training_acc_history)) == False:\n                train_acc_mean = np.mean(training_acc_history)\n            if np.isnan(np.mean(test_acc_history)) == False:\n                test_acc_mean = np.mean(test_acc_history)\n            \n            # communicate training results so far\n            print(\"Training {}% [\".format(pct), \n                  \"#\" * int(pct\/5), \n                  \".\" * (20 - int(pct\/5)), \"]\", \n                  \" Train Acc: {0:.3f} | \".format(train_acc_mean), \n                  \" Test Acc: {0:.3f}\".format(test_acc_mean), end='\\r')\n        \n        end = time.time()\n        print(\"\")\n        print(\"Processing Time: {0:.2f} min\".format((end - start) \/ 60))\n        \n        # storing training history\n        test_loss_history_e.append(np.mean(test_loss_history))\n        test_acc_history_e.append(np.mean(test_acc_history))\n        training_loss_history_e.append(np.mean(training_loss_history))\n        training_acc_history_e.append(np.mean(training_acc_history))\n    \n    return model, training_loss_history_e, test_loss_history_e, training_acc_history_e, test_acc_history_e","5cf8374c":"#create model\nmodel = Sequential()\n#add model layers\nmodel.add(conv_base)\nmodel.add(Conv2D(60, kernel_size=2, activation='tanh', padding='same'))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(50, kernel_size=2, activation='tanh', padding='same'))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(40, kernel_size=2, activation='tanh', padding='same'))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(30, kernel_size=2, activation='tanh', padding='same'))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(20, kernel_size=2, activation='tanh', padding='same'))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(10, kernel_size=2, activation='tanh', padding='same'))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='tanh'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(5, activation='softmax'))","c1b42eb3":"conv_base.trainable = False","82703b49":"#compile model using accuracy to measure model performance\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nprint(model.summary())","be231f13":"# Get list of files\nfiles = os.listdir('..\/input\/train_images') ","a4e0e3a6":"epochs = 5\nmodel, train_loss_hist, test_loss_hist, train_acc_hist, test_acc_hist = KerasModelTrainer(files=files,\n                                                                                          batch_size=100,\n                                                                                          lookup_table=pet_ids_and_target, \n                                                                                          epochs=epochs, \n                                                                                          test_size=0.1, \n                                                                                          shape=(224,224))","66f8b208":"plt.plot(np.arange(1, epochs+1, 1), test_loss_hist)\nplt.plot(np.arange(1, epochs+1, 1), train_loss_hist)\nplt.xlabel('Rounds \/ Batches')\nplt.ylabel('Loss')\nplt.title('Train \/ Test Loss History')\nplt.legend(['test', 'train'], loc='upper left')\nplt.grid(True)\nplt.show()","402b1c31":"plt.plot(np.arange(1, epochs+1, 1), test_acc_hist)\nplt.plot(np.arange(1, epochs+1, 1), train_acc_hist)\nplt.xlabel('Rounds \/ Batches')\nplt.ylabel('Accuracy')\nplt.title('Train \/ Test Acc History')\nplt.legend(['test', 'train'], loc='upper left')\nplt.grid(True)\nplt.show()","bde0b3a5":"## References:\nhttps:\/\/www.kaggle.com\/myltykritik\/simple-lgbm-image-features\n\nhttps:\/\/stackoverflow.com\/questions\/47200146\/keras-load-images-batch-wise-for-large-dataset\n\nhttps:\/\/towardsdatascience.com\/building-a-convolutional-neural-network-cnn-in-keras-329fbbadc5f5\n\nhttps:\/\/keras.io\/models\/model\/\n\nhttps:\/\/www.pyimagesearch.com\/2018\/12\/24\/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial\/\n\nhttps:\/\/keras.io\/layers\/pooling\/\n\nhttps:\/\/towardsdatascience.com\/transfer-learning-and-image-classification-using-keras-on-kaggle-kernels-c76d3b030649\n","a2a53e0c":"## View an Image","c5e7000c":"## Run Model","7b63c2c9":"# Setting up PetID and AdoptionSpeed Lookup Table\n\n- So we want to create a table where we can call the ID# and get the target values\n- We'll also test that we can grab the target value via the ID#","6add2ccb":"# Training Plots","6b8a2051":"## My Data Augmentation Function\n\n- Here we're creating our own custom image augmentation code using OpenCV\n- We'll use this function to augment our images during training\n- With each batch we'll generate a random number which will indicate which augmentation we do.  We pick random augmentations with each batch mainly due to memory constraints.\n- You can customize this to include any augmentations that you want!  Change the random # range, include a new elif or alter the current elif's as you want!\n- You might want to do this if you have some contexual knowledge about the images you'd like to leverage but need more control over the augmentations.\n- Here we're mainly doing specific cropping, rotating, and blurring techniques based on knowledge of the images.","2513adf6":"## Imports","d1e5bbfa":"## Get as sense of the images shapes","c8a6f92b":"## Define Model","518feeec":"## Create Image Loader\n\n- We're using train_on_batch here because it gives us a bit more control and in this case had a better experience over trying to set up a generator.\n- This is pretty basic, we just have to build a lot from scratch since we're using train_on_batch\n- We set up epochs, batches, loading batches, running train_on_batch, printing feedback, storing results, etc.","a09dd0b8":"## Function to Load Images\n\n- The following functions will allow us to take a list of files (saw a batch of files\\images) read them using OpenCV, apply augmentation, grab the corresponding target values, and return for training.\n- In training we apply augmentation, but in validation we don't apply augmentation, so we have 2 functions, one for training and one for validation (with no augmentation)."}}