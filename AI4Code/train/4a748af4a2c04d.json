{"cell_type":{"e19b8f28":"code","00ae34d2":"code","f1a51016":"code","a0907b05":"code","bc92ce3e":"code","9cfe205e":"code","fcaeaec6":"code","c6781a60":"code","1610c2df":"code","5296d832":"code","1a8943ad":"markdown","5bcea121":"markdown","98231494":"markdown","c22a28e4":"markdown","fce09a53":"markdown","cbd234b5":"markdown","64261579":"markdown"},"source":{"e19b8f28":"import pandas as pd, numpy as np\nfrom matplotlib import pyplot as plt\nimport scipy.stats  as stats\npd.options.display.max_columns = 50","00ae34d2":"best = pd.read_csv(\"..\/input\/accuracy-subs\/based_witch_time_by_store.csv\") # read your submission from Accuracy\nbest.head()","f1a51016":"sales = pd.read_csv(\"..\/input\/m5-forecasting-uncertainty\/sales_train_evaluation.csv\")\nsales.head()","a0907b05":"sales[\"_all_\"] = \"Total\"\nsub = sales[[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\",\"_all_\"]].merge(best, on='id')\nsub.shape","bc92ce3e":"sub.head()","9cfe205e":"qs = np.array([0.005,0.025,0.165,0.25, 0.5, 0.75, 0.835, 0.975, 0.995])\n\ndef get_ratios(coef=0.15):\n    qs2 = np.log(qs\/(1-qs))*coef\n    ratios = stats.norm.cdf(qs2)\n    ratios \/= ratios[4]\n    ratios = pd.Series(ratios, index=qs)\n    return ratios.round(3)\n\n# coef between 0.03 and 0.25 is used, probably suboptimal values for now\n# If you're not sure about your Accuracy submission, you should make the distribution wider.\nlevel_coef_dict = {\n    \"_all_\": get_ratios(coef=0.03),\n    \"state_id\": get_ratios(coef=0.04),\n    \"store_id\": get_ratios(coef=0.05),\n    \"cat_id\": get_ratios(coef=0.04),\n    \"dept_id\": get_ratios(coef=0.05),\n    (\"state_id\", \"cat_id\"): get_ratios(coef=0.05),\n    (\"state_id\", \"dept_id\"): get_ratios(coef=0.07),\n    (\"store_id\",\"cat_id\"): get_ratios(coef=0.07),\n    (\"store_id\",\"dept_id\") : get_ratios(coef=0.08),\n    \"item_id\": get_ratios(coef=0.11),\n    (\"state_id\", \"item_id\"): get_ratios(coef=0.15),\n    \"id\": get_ratios(coef=0.25)\n}","fcaeaec6":"level_coef_dict[\"cat_id\"]","c6781a60":"level_coef_dict[\"id\"]","1610c2df":"def quantile_coefs(q, level):\n    ratios = level_coef_dict[level]\n    return ratios.loc[q].values\n\ndef get_group_preds(pred, level):\n    df = pred.groupby(level)[cols].sum()\n    q = np.repeat(qs, len(df))\n    df = pd.concat([df]*9, axis=0, sort=False)\n    df.reset_index(inplace = True)\n    df[cols] *= quantile_coefs(q, level)[:, None]\n    if level != \"id\":\n        df[\"id\"] = [f\"{lev}_X_{q:.3f}_evaluation\" for lev, q in zip(df[level].values, q)]\n    else:\n        df[\"id\"] = [f\"{lev.replace('_evaluation', '')}_{q:.3f}_evaluation\" for lev, q in zip(df[level].values, q)]\n    df = df[[\"id\"]+list(cols)]\n    return df\n\ndef get_couple_group_preds(pred, level1, level2):\n    df = pred.groupby([level1, level2])[cols].sum()\n    q = np.repeat(qs, len(df))\n    df = pd.concat([df]*9, axis=0, sort=False)\n    df.reset_index(inplace = True)\n    df[cols] *= quantile_coefs(q, (level1, level2))[:, None]\n    df[\"id\"] = [f\"{lev1}_{lev2}_{q:.3f}_evaluation\" for lev1,lev2, q in \n                zip(df[level1].values,df[level2].values, q)]\n    df = df[[\"id\"]+list(cols)]\n    return df\n\nlevels = [\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\", \"_all_\"]\ncouples = [(\"state_id\", \"item_id\"),  (\"state_id\", \"dept_id\"),(\"store_id\",\"dept_id\"),\n                            (\"state_id\", \"cat_id\"),(\"store_id\",\"cat_id\")]\ncols = [f\"F{i}\" for i in range(1, 29)]\n\ndf = []\nfor level in levels :\n    df.append(get_group_preds(sub, level))\nfor level1,level2 in couples:\n    df.append(get_couple_group_preds(sub, level1, level2))\ndf = pd.concat(df, axis=0, sort=False)\ndf.reset_index(drop=True, inplace=True)\ndf = pd.concat([df,df] , axis=0, sort=False)\ndf.reset_index(drop=True, inplace=True)\ndf.loc[df.index >= len(df.index)\/\/2, \"id\"] = df.loc[df.index >= len(df.index)\/\/2, \"id\"].str.replace(\n                                    \"_evaluation$\", \"_validation\")\n\ndf.to_csv(\"submission.csv\", index = False)","5296d832":"df.head()","1a8943ad":"Let's see how ranges differ!","5bcea121":"## Your Option1","98231494":"This notebook is based on [this](https:\/\/www.kaggle.com\/szmnkrisz97\/point-to-uncertainty-different-ranges-per-level).  \nThis is for Uncertainty submission from Accuracy submission.  ","c22a28e4":"### You only have two areas to work on.\n - Choose which submissions to read\n - Determines the width of the distribution.","fce09a53":"For the the lowest level (30490 series), the smallest and biggest quantiles are 20% and 180% of the point prediction.   \nFor categories (3 series), the model will be way more confident: the smallest quantile will be 83%, the biggest will be 117% of the point prediction.\nChanging this range could result in a good score.","cbd234b5":"## Your Option2","64261579":"## Different ratios for different aggregation levels\n\nThe higher the aggregation level, the more confident we are in the point prediction --> lower coef, relatively smaller range of quantiles"}}