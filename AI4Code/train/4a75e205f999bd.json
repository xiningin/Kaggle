{"cell_type":{"5703bbd6":"code","d3e3cef7":"code","947da10d":"code","b2c56105":"code","23d0c6ee":"code","1ffd9268":"code","b2f9bf44":"code","9cfcfb2d":"code","432a2e86":"code","f5d9a1a5":"code","ac7606e5":"code","ef099fdf":"code","89d3ad55":"code","53eb9294":"code","18939910":"code","643442f8":"code","87358b00":"code","704bd591":"code","32dd218a":"markdown","65a91534":"markdown","184f218a":"markdown","b680e5ac":"markdown","ce46c68a":"markdown","9a768409":"markdown","c8162ca8":"markdown","8764b4fd":"markdown"},"source":{"5703bbd6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport time, os, pickle, json, requests \nfrom tqdm import tqdm \nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\nfrom sklearn.preprocessing import RobustScaler\nfrom statistics import mean \nimport wandb \nfrom kaggle_secrets import UserSecretsClient\n\nimport torch \nimport torch.nn as nn \nfrom torch.utils.data import DataLoader, Dataset \nfrom torch import optim ","d3e3cef7":"params = dict(\n    hidden_dim = 128, \n    input_size = 58\n)\n\n\nconfig = dict(\n    project = \"covid19-transition\", \n    epoch = 100, \n    batch_size=4, \n    lr = 0.0006, \n    num_workers = 3, \n    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\", \n    model_name = \"bidirectional-LSTM\", \n    frame_work = \"pytorch\", \n    infra = \"kaggle\", \n    params = params \n)","947da10d":"\n# db \nuser_secrets = UserSecretsClient()\nwandb_api = user_secrets.get_secret(\"wandb_api\") \n\nwandb.login(key=wandb_api)\n\nrun = wandb.init(\n    project = config[\"project\"], \n    name = config[\"model_name\"], \n    config = config, \n    group = config[\"model_name\"], \n    job_type = \"train\"\n)\n\n\n# slack \nuser_secrets = UserSecretsClient()\nurl = user_secrets.get_secret(\"WEB_HOOK_URL\") \n\n\ndef slack(txt):\n    requests.post(url, data=json.dumps({\n        \"username\": \"kaggle\", \n        \"text\": txt \n    }))\n","b2c56105":"df = pd.read_csv(\"..\/input\/covid19-japan-time-series-transition\/step1\/train.csv\")\ndf[\"date\"] = pd.to_datetime(df.date)\ndf = df.fillna(0)\ndf.head()","23d0c6ee":"ims = []\npref = df.prefecture.unique()\n\nfor p in pref:\n    x = df.loc[df.prefecture == p, [\"newly_confirmed\", \"date\"]]\n    ims.append(go.Scatter(x=x[\"date\"], y=x[\"newly_confirmed\"], name=p))\n    \nlayout = go.Layout(title=\"Prefecture vs newly confirmed transition\", xaxis=dict(title=\"date\"), yaxis=dict(title=\"newly_confirmed\"))\nfig = go.Figure(data=ims, layout=layout)\niplot(fig)","1ffd9268":"ims = []\npref = df.prefecture.unique()\n\nfor p in pref:\n    x = df.loc[df.prefecture == p, [\"death\", \"date\"]]\n    ims.append(go.Scatter(x=x[\"date\"], y=x[\"death\"], name=p))\n    \nlayout = go.Layout(title=\"Prefecture vs death transition\", xaxis=dict(title=\"date\"), yaxis=dict(title=\"death\"))\nfig = go.Figure(data=ims, layout=layout)\niplot(fig)","b2f9bf44":"\n# add lag features \n\ndf = df.rename(columns={\"newly_confirmed\": \"newly_confirmed_current\"})\ndf[\"newly_confirmed\"] = df.groupby(\"prefecture\")[\"newly_confirmed_current\"].shift(-1)\n\nfor col in df.drop([\"newly_confirmed\", \"prefecture\", \"date\"], axis=1).columns:\n    df[col+\"_cumsum\"] = df.groupby(\"prefecture\")[col].cumsum()\n    df[col+\"_lag1\"] = df.groupby(\"prefecture\")[col].shift(1).fillna(0)\n    df[col+\"_lag7\"] = df.groupby(\"prefecture\")[col].shift(7).fillna(0)  \n    df[col+\"_lag30\"] = df.groupby(\"prefecture\")[col].shift(7).fillna(0)  \n    df[col+\"_avg7\"] = df.groupby(\"prefecture\")[col].rolling(window=7).mean().reset_index(drop=True).fillna(0)\n    \ndf[\"month\"] = df.date.dt.month \ndf[\"week\"] = df.date.dt.dayofweek \ndf[\"quarter\"] = df.date.dt.quarter \ndf[\"holiday\"] = df.week.apply(lambda x: 1 if x in [5, 6] else 0)\n\ndf.head()\n","9cfcfb2d":"fig, axes = plt.subplots(2, 2, figsize=(15, 8))\nax = axes.ravel()\n\nsns.barplot(data=df, x=\"week\", y=\"newly_confirmed\", ax=ax[0])\nax[0].set_title(\"Week vs newly confirmed counts\")\n\nsns.barplot(data=df, x=\"month\", y=\"newly_confirmed\", ax=ax[1])\nax[1].set_title(\"month vs newly confirmed counts\")\n\nsns.barplot(data=df, x=\"quarter\", y=\"newly_confirmed\", ax=ax[2])\nax[2].set_title(\"Quarter vs newly confirmed counts\")\n\nsns.barplot(data=df, x=\"holiday\", y=\"newly_confirmed\", ax=ax[3])\nax[3].set_title(\"Holiday vs newly confirmed counts\")\n\nplt.tight_layout()\nplt.show()","432a2e86":"use_col = [\"death\", \"newly_confirmed_current\", \"requiring_inpatient\", \"released_from_treatment\", \"tobe_confirmed\", \"severe\"]\n\n# group mean -> merge \n\npref = df.groupby(\"prefecture\").mean().loc[:, use_col]\npref.columns = [c+str(\"_pref\") for c in use_col]\ndf = pd.merge(df, pref, how=\"left\", left_on=\"prefecture\", right_index=True)\n\ndate = df.groupby(\"date\").mean().loc[:, use_col]\ndate.columns = [c + str(\"_date\") for c in use_col]\ndf = pd.merge(df, date, how=\"left\", left_on=\"date\", right_index=True)\n\npref_date = df.groupby([\"prefecture\", \"date\"]).mean().loc[:, use_col]\npref_date.columns = [c + str(\"_date_pref\") for c in use_col]\ndf = pd.merge(df, pref_date, how=\"left\", left_on=[\"prefecture\", \"date\"], right_index=True)\n\ndf.head()","f5d9a1a5":"\n\n'''\nFormat the data to make the final forecast according to the time series with one batch per month.\n\nEnter the aggregated data frame for each prefecture.\n'''\n\nclass CovidDataset(Dataset):\n    def __init__(self, df: pd.DataFrame):\n        '''input dataFrame: df.groupby(\"prefecture\")'''\n        df = df.reset_index(drop=True).drop(\"prefecture\", axis=1).sort_values(\"date\")\n        n_span = 30 \n        train = df.iloc[:(-1)*(n_span+1) , :] #   ~ 2021\/08\/31\n        val = df.iloc[(-1)*(n_span+1) :-1, :] #   2021\/09\/01 ~ 2021\/09\/30\n        test = df.iloc[(-1)*(n_span):, :]     #   2021\/09\/02 ~ 2021\/10\/01\n        self.train = []\n        self.val = []\n        self.test = []\n        \n        x_train, x_val, x_test = train.drop([\"date\", \"newly_confirmed\"], axis=1), val.drop([\"date\", \"newly_confirmed\"], axis=1), test.drop([\"date\", \"newly_confirmed\"], axis=1)\n        y_train, y_val = train[[\"newly_confirmed\"]], val[[\"newly_confirmed\"]]\n        \n        x_train, x_val, x_test = self._scaler(x_train, x_val, x_test)\n        \n        # create train dataset \n        for i in range(x_train.shape[0]-n_span):\n            input_data = {}\n            inputs = x_train[i:i+n_span]\n            inputs = torch.FloatTensor(inputs) # (30, feature)\n            target = y_train.iloc[i+n_span]\n            target = torch.tensor(target, dtype=torch.float) # (1, )\n            \n            input_data[\"inputs\"] = inputs \n            input_data[\"target\"] = target\n            self.train.append(input_data)\n            \n        # create val dataset \n        for i in range(n_span):\n            input_data = {}\n            inputs_tr = x_train[(-1)*n_span+i: :]  \n            inputs_val = x_val[:i, :] # add 1 days \n            inputs = np.concatenate([inputs_tr, inputs_val])\n            inputs = torch.FloatTensor(inputs)\n            target = y_val.iloc[i]\n            target = torch.tensor(target, dtype=torch.float)\n            \n            input_data[\"inputs\"] = inputs \n            input_data[\"target\"] = target \n            self.val.append(input_data)\n            \n        # create test dataset \n        input_data = {\"inputs\": torch.FloatTensor(x_test)}\n        self.test.append(input_data)\n        \n    \n    def _scaler(self, train, val, test):\n        s = RobustScaler()\n        return s.fit_transform(train), s.transform(val), s.transform(test)\n        \n        \n        ","ac7606e5":"a = CovidDataset(df[df.prefecture == \"Aichi\"])","ef099fdf":"print(f\"input shape: {a.train[0]['inputs'].size()}\")\nprint(f\"label shape: {a.train[0]['target'].size()}\")","89d3ad55":"class CovidModel(nn.Module):\n    def __init__(self, input_size, hidden_dim, out_size=1):\n        super(CovidModel, self).__init__()\n        self.fc0 = nn.Sequential(\n            nn.Linear(input_size, hidden_dim),\n            nn.ReLU(inplace=True)\n        )\n        self.lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.fc1 = nn.Sequential(\n            nn.Linear(hidden_dim+hidden_dim, hidden_dim), \n            nn.ReLU(inplace=True),\n            nn.LayerNorm(hidden_dim),\n            nn.Dropout(p=0.2),\n            nn.Linear(hidden_dim, out_size)\n        )\n        \n    def forward(self, x):\n        out = self.fc0(x)\n        hs, _ = self.lstm(out)\n        out = hs[:, -1, :]\n        return self.fc1(out)\n    ","53eb9294":"def train_loop(dl, model, criterion, optim, is_train=True):\n    if is_train:\n        model.train()\n    else:\n        model.eval()\n        \n    total_loss = []\n    for d in tqdm(dl):\n        inputs = d[\"inputs\"].to(config[\"device\"])\n        label = d[\"target\"].to(config[\"device\"])\n        \n        if is_train:\n            out = model(inputs)\n            \n            loss = criterion(out.view(-1), label)\n            optim.zero_grad()\n            loss.backward()\n            optim.step()\n            \n        else:\n            with torch.no_grad():\n                out = model(inputs)\n                loss = criterion(out.view(-1), label)\n        total_loss.append(loss.item())\n        \n        del d \n    return mean(total_loss)\n\ndef val_loop(dl, model):\n    with torch.no_grad():\n        predict = []\n        for d in tqdm(dl):\n            inputs = d[\"inputs\"].to(config[\"device\"])\n            \n            out = model(inputs)\n            out = out.view(-1).detach().cpu().numpy().tolist()\n            for o in out:\n                predict.append(o)\n            del d \n    del model \n    return predict \n\n\ndef test_loop(dl, model):\n    with torch.no_grad():\n        predict = []\n        for d in tqdm(dl):\n            inputs = d[\"inputs\"].to(config[\"device\"])\n            \n            out = model(inputs)\n            out = out.view(-1).detach().cpu().numpy().tolist()\n            for o in out:\n                predict.append(o)\n            del d \n    del model \n    return predict \n\n\ndef fit(train, val, pref):\n    model = CovidModel(params[\"input_size\"], params[\"hidden_dim\"])\n    model.to(config[\"device\"])\n    criterion = nn.L1Loss()\n    optim_ = optim.Adam(model.parameters(), lr=config[\"lr\"])\n    \n    loss_tr, loss_va = [], []\n    best_model, best_val_loss, best_epoch = None, np.inf, 0\n    for e in range(config[\"epoch\"]):\n        ts = time.time()\n        tr_loss = train_loop(train, model, criterion, optim_)\n        va_loss = train_loop(val, model, criterion, None, False)\n        \n        loss_tr.append(tr_loss)\n        loss_va.append(va_loss)\n        \n        if best_val_loss > va_loss:\n            best_model = model \n            best_val_loss = va_loss \n            best_epoch = e \n            \n        now = time.time()\n        print(f\"epoch {e} | train loss: {tr_loss:.3f} | val loss: {va_loss:.3f} | dilation {now-ts}s\")\n    print(f\"best val loss : {best_val_loss:.3f}\")\n    logger(pref, loss_tr, loss_va, best_epoch, best_val_loss)\n    \n    torch.cuda.empty_cache()\n    return best_model \n\n\ndef predict(dl, pref, is_test=False):\n    model = load_model(pref)\n    if is_test:\n        pred = test_loop(dl, model)\n    else:\n        pred = val_loop(dl, model)\n    return pred \n\n\ndef load_model(pref):\n    model = CovidModel(params[\"input_size\"], params[\"hidden_dim\"])\n    model.load_state_dict(torch.load(f\"models\/{pref}\/best.pth\", map_location={\"cuda:0\": \"cpu\"}))\n    model.eval()\n    model.to(config[\"device\"])\n    return model \n\n\ndef logger(pref, tr, va, e, best):\n    wandb.log({\n        \"prefecture\": pref , \n        \"train_loss\": tr,\n        \"val_loss\": va, \n        \"best_epoch\": e , \n        \"best_val_loss\": best\n    })\n    \ndef checkpoint(model, pref):\n    os.makedirs(f\"models\/{pref}\", exist_ok=True)\n    torch.save(model.state_dict(), f\"models\/{pref}\/best.pth\")\n    print(\"success saving model.\")\n    \n    \ndef mae(corr, pred):\n    return np.mean(np.abs(corr - pred))","18939910":"\ndfs_list = []\nresult_list = []\n\nfor pref in df.prefecture.unique():\n    df_ = df[df.prefecture == pref]\n    result = {}\n    my_data = CovidDataset(df_)\n    \n    train_ds, val_ds, test_ds = my_data.train, my_data.val, my_data.test \n    \n    train_dl = DataLoader(train_ds, \n                         batch_size=config[\"batch_size\"], \n                         shuffle=False, \n                         drop_last=False, \n                         pin_memory=True,\n                         num_workers=config[\"num_workers\"])\n    \n    val_dl = DataLoader(val_ds, \n                       batch_size=config[\"batch_size\"],\n                       shuffle=False, \n                       drop_last=False,\n                       pin_memory=True,\n                       num_workers=config[\"num_workers\"])\n    \n    test_dl = DataLoader(test_ds, \n                        batch_size=1)\n    \n    model = fit(train_dl, val_dl, pref)\n    wandb.watch(model)\n    checkpoint(model, pref)\n    pred_v = predict(val_dl, pref)\n    pred_t = predict(test_dl, pref, True)\n    \n    result[pref] = pred_t[0]\n    result_list.append(result)\n    \n    corr = []\n    \n    for i in range(len(val_ds)):\n        c = val_ds[i][\"target\"].item()\n        corr.append(c)\n        \n    err = mae(np.array(corr), np.array(pred_v))\n    print(f\"prefecture: {pref} mae: {err}\")\n    \n    dfs = pd.DataFrame({\"newly_confirmed\": corr, \"predict\": pred_v})\n    dfs[\"prefecture\"] = pref \n    dfs_list.append(dfs)\n\nslack(\"success Train.\")","643442f8":"def viz_predict(dfs):\n    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n    ax = axes.ravel()\n    \n    for i in range(9):\n        df = dfs[i]\n        pref = df[\"prefecture\"].values[0]\n        df.drop(\"prefecture\", axis=1).plot(ax=ax[i])\n        ax[i].set_title(pref)\n    plt.tight_layout()","87358b00":"viz_predict(dfs_list)","704bd591":"test_predict, test_pref = [], []\n\nfor result in result_list:\n    for k, v in result.items():\n        test_pref.append(k)\n        test_predict.append(v)\n        \npred_df = pd.DataFrame({\"prefecture\": test_pref, \"newly_confirmed\": test_predict})\nsub = pd.read_csv(\"..\/input\/covid19-japan-time-series-transition\/step1\/sample_submission.csv\", usecols=[\"prefecture\", \"date\"])\nsub = pd.merge(sub, pred_df, how=\"left\", on=\"prefecture\")\nsub.to_csv(\"submission.csv\", index=False)\n\nslack(\"done.\")","32dd218a":"# Train ","65a91534":"# Eval","184f218a":"# Model ","b680e5ac":"# Const ","ce46c68a":"# preprocess ","9a768409":"# Tools ","c8162ca8":"# Dataset ","8764b4fd":"# Submit "}}