{"cell_type":{"7c0c6d1f":"code","f8207e66":"code","584ed6b6":"code","c7f35291":"code","6c055762":"code","4e501400":"code","a21d17b0":"code","95f91514":"code","1f40c91d":"code","708648fe":"code","f989e1a8":"code","d95f35aa":"code","c2bb4c03":"code","255b8745":"code","596f0a6e":"code","00560afe":"code","5733015d":"code","9bb3ccc9":"code","b6f48ae9":"code","99fd0830":"code","fd0b7f72":"code","6b62afc0":"markdown","0cb4cf7d":"markdown","265b3eb1":"markdown","0eb43472":"markdown","5e7146b8":"markdown","abd5018b":"markdown","65008e85":"markdown","1ee6ecbf":"markdown","fde2a67b":"markdown"},"source":{"7c0c6d1f":"import pandas as pd\nimport numpy as np\nimport os\nimport random\nimport plotly.offline as offline\nimport plotly.plotly as py\nimport plotly.graph_objs as go\nfrom scipy import stats\nfrom sklearn.linear_model import LinearRegression\nfrom scipy.stats import chi2_contingency\n\n%matplotlib inline\noffline.init_notebook_mode(connected=True)","f8207e66":"jobs = pd.read_csv(\"..\/input\/Jobs_ML_DS.csv\")\nprint(jobs.shape)\ndisplay(jobs.head())","584ed6b6":"jobs.as_of_date = pd.to_datetime(jobs.as_of_date)\njobs.number_of_openings.value_counts()","c7f35291":"### Change # of openings Nan to 1 and outliers to 1\njobs.loc[jobs.number_of_openings.isna(),'number_of_openings'] = 1\njobs.loc[jobs.number_of_openings == 100,'number_of_openings'] = 1\njobs.number_of_openings.value_counts()","6c055762":"### sort by time\njobs = jobs.sort_values(by='as_of_date', ascending=True).reset_index(drop=True)\njobs.head()","4e501400":"### jobs for DS and ML positions\nDS = jobs[jobs.title.str.contains('Data Scientist')==True].reset_index(drop=True)\nML = jobs[jobs.title.str.contains('Machine Learning')==True].reset_index(drop=True)\nprint(DS.shape)\nprint(ML.shape)\ndisplay(DS.head())","a21d17b0":"###### Plot the time series job posting information\nDS_total = DS.groupby('as_of_date').sum()\nML_total = ML.groupby('as_of_date').sum()\ntrace1 = go.Scatter(\n    x = DS_total.index,\n    y = DS_total.number_of_openings,\n    name = 'Data Scientist'\n)\ntrace2 = go.Scatter(\n    x = ML_total.index,\n    y = ML_total.number_of_openings,\n    name = 'Machine Learning Engineer'\n)\nlayout = go.Layout(\n        title = \"Number of Openings\",\n        xaxis = dict(title='Day'),\n        yaxis = dict(title=\"Num\"),\n)\ndata = [trace1, trace2]\nfig = go.Figure(data=data, layout=layout)\noffline.iplot(fig, show_link=False)","95f91514":"### Count the State information\njobs['State'] = jobs.region\njobs['Type'] = 'ML'\njobs.loc[jobs.region.isin(['CA', 'Menlo Park', 'California', 'CA,California']), 'State'] = 'CA'\njobs.loc[jobs.region.isin(['WA', 'Seattle']), 'State'] = 'WA'\njobs.loc[jobs.region.isin(['VA', 'Virginia']), 'State'] = 'VA'\njobs.loc[jobs.region.isin(['MA', 'MA,Mass']), 'State'] = 'MA'\njobs.loc[jobs.title.str.contains('Data Scientist'), 'Type'] = 'DS'\n### Top 10 states\njobs.State.value_counts()[0:10]","1f40c91d":"job_state = jobs.groupby(['as_of_date', 'State']).sum()\njob_state.head()","708648fe":"##### Plotting number of openings by top states\ntrace1 = go.Scatter(\n    x = job_state.loc[pd.IndexSlice[:, 'CA'], :].index.get_level_values('as_of_date'),\n    y = job_state.loc[pd.IndexSlice[:, 'CA'], :].number_of_openings,\n    name = 'CA'\n)\ntrace2 = go.Scatter(\n    x = job_state.loc[pd.IndexSlice[:, 'WA'], :].index.get_level_values('as_of_date'),\n    y = job_state.loc[pd.IndexSlice[:, 'WA'], :].number_of_openings,\n    name = 'WA'\n)\ntrace3 = go.Scatter(\n    x = job_state.loc[pd.IndexSlice[:, 'MA'], :].index.get_level_values('as_of_date'),\n    y = job_state.loc[pd.IndexSlice[:, 'MA'], :].number_of_openings,\n    name = 'MA'\n)\ntrace4 = go.Scatter(\n    x = job_state.loc[pd.IndexSlice[:, 'VA'], :].index.get_level_values('as_of_date'),\n    y = job_state.loc[pd.IndexSlice[:, 'VA'], :].number_of_openings,\n    name = 'VA'\n)\ntrace5 = go.Scatter(\n    x = job_state.loc[pd.IndexSlice[:, 'TX'], :].index.get_level_values('as_of_date'),\n    y = job_state.loc[pd.IndexSlice[:, 'TX'], :].number_of_openings,\n    name = 'TX'\n)\ntrace6 = go.Scatter(\n    x = job_state.loc[pd.IndexSlice[:, 'IL'], :].index.get_level_values('as_of_date'),\n    y = job_state.loc[pd.IndexSlice[:, 'IL'], :].number_of_openings,\n    name = 'IL'\n)\nlayout = go.Layout(\n        title = \"Num of Openings by States\",\n        xaxis = dict(title='Date'),\n        yaxis = dict(title=\"Number\"),\n)\ndata = [trace1, trace2, trace3, trace4, trace5, trace6]\nfig = go.Figure(data=data, layout=layout)\noffline.iplot(fig, show_link=False)","f989e1a8":"jobs['Month_Y'] = jobs['as_of_date'].apply(lambda x: x.strftime('%m-%Y'))\nGR_State = jobs.groupby(['Month_Y', 'State']).sum()\nGR_Half = GR_State.loc[GR_State.index.get_level_values('State').isin(['CA', 'WA', 'MA', 'NY', 'VA', \n                                                                      'TX', 'IL', 'NJ', 'MD', 'PA',\n                                                                     'CO', 'GA'])]\nGR_Half_2017 = GR_Half.loc[GR_Half.index.get_level_values('Month_Y').isin(['01-2017', '02-2017', '03-2017', \n                                                                        '04-2017', '05-2017', '06-2017'])]\nGR_Half_2018 = GR_Half.loc[GR_Half.index.get_level_values('Month_Y').isin(['01-2018', '02-2018', '03-2018', \n                                                                        '04-2018', '05-2018', '06-2018'])]\nGR_Half_2018['GR']= (GR_Half_2018.number_of_openings.get_values() - GR_Half_2017.number_of_openings.\n get_values()) \/ GR_Half_2017.number_of_openings.get_values()","d95f35aa":"print(GR_Half_2018.GR.index.get_level_values('State')[0:12])\n### Year-over-year results of top 12 growing states\nGR_data = pd.DataFrame(np.asarray(GR_Half_2018.GR.get_values()).reshape(6,12))\nGR_data.columns = GR_Half_2018.GR.index.get_level_values('State')[0:12]\ndisplay(GR_data)","c2bb4c03":"###### Plot the growth rates by states\ntrace0 = go.Bar(\n    x = GR_data.columns[0:12],\n    y = GR_data.iloc[0,:].get_values(),\n    name = 'Jan'\n)\ntrace1 = go.Bar(\n    x = GR_data.columns[0:12],\n    y = GR_data.iloc[1,:].get_values(),\n    name = 'Feb'\n)\ntrace2 = go.Bar(\n    x = GR_data.columns[0:12],\n    y = GR_data.iloc[2,:].get_values(),\n    name = 'Mar'\n)\ntrace3 = go.Bar(\n    x = GR_data.columns[0:12],\n    y = GR_data.iloc[3,:].get_values(),\n    name = 'Apr'\n)\ntrace4 = go.Bar(\n    x = GR_data.columns[0:12],\n    y = GR_data.iloc[4,:].get_values(),\n    name = 'May'\n)\ntrace5 = go.Bar(\n    x = GR_data.columns[0:12],\n    y = GR_data.iloc[5,:].get_values(),\n    name = 'June'\n)\nlayout = go.Layout(\n        title = \"2017-2018 Year-over-Year Job Posting Growth Rate in Month by States\",\n        xaxis = dict(title='State'),\n        yaxis = dict(title=\"Growth Rate (%\/100)\",\n                     range=[-2, 18]),\n)\ndata = [trace0, trace1, trace2, trace3, trace4, trace5]\nfig = go.Figure(data=data, layout=layout)\noffline.iplot(fig, show_link=False)","255b8745":"### Load Package\nfrom fbprophet import Prophet","596f0a6e":"job_daily = jobs.groupby('as_of_date').sum().reset_index()\njob_daily = job_daily.iloc[:,[0,2]]\ndisplay(job_daily.tail())","00560afe":"### Define Prediction Functions\ndef Prediction(data, train_end: str='2018-06-20', future_days: int=30):\n    df = data\n    df.columns = ['ds', 'y']\n    training_time = train_end\n    lag = future_days\n    train_index = df.loc[(df.ds==str(training_time))].index.get_values()[0]\n    df_train, df_test = df[0:train_index], df[train_index:(train_index+int(lag))]\n    m = Prophet(holidays_prior_scale=0.5, seasonality_prior_scale=10, yearly_seasonality=True, interval_width=0.95)\n#    m.add_seasonality(name='weekly', period=7, fourier_order=80, prior_scale=50)\n    m.fit(df_train)\n    future = m.make_future_dataframe(periods=lag, include_history=False)\n    forecast = m.predict(future)\n    ffcast = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n    ffcast = ffcast.set_index(ffcast.ds)\n    df = df.set_index(df.ds)\n    ffcast['Orig'] = df.y\n    ffcast = ffcast.reset_index(drop=True)\n    ffcast.columns = ['date', 'yhat', 'yhat_lower', 'yhat_upper', 'True_Value']\n    return ffcast, df_train","5733015d":"ffcast, job_daily_orig = Prediction(job_daily, train_end='2018-06-20', future_days=26)","9bb3ccc9":"upper_bound = go.Scatter(\n    x=ffcast['date'],\n    y=ffcast['yhat_upper'],\n    line = dict(\n        color = \"#444\",\n        width = 1),\n    opacity=.5,\n    showlegend=False)\n\ntrace = go.Scatter(\n    name='Prediction',\n    x=ffcast['date'],\n    y=ffcast['yhat'],\n    mode='lines',\n    line = dict(\n        width = 2))\n\ntrace1 = go.Scatter(\n    name='True Volume',\n    x=job_daily['ds'],\n    y=job_daily['y'],\n    mode='lines',\n    line = dict(\n        width = 1.5))\n\nlower_bound = go.Scatter(\n    x=ffcast['date'],\n    y=ffcast['yhat_lower'],\n    line = dict(\n        color = \"#444\",\n        width = 1),\n    opacity=.5,\n    name='prediction bound')\n\n\ndata = [upper_bound, lower_bound, trace, trace1]\n\nlayout = go.Layout(\n    yaxis=dict(title='daily post volume'),\n    title='Job Posting Volume Prediction with 95% C.I.',\n    showlegend = True)\n\nfig = go.Figure(data=data, layout=layout)\noffline.iplot(fig, show_link=False)","b6f48ae9":"ds = jobs[jobs.Type == 'DS']\nml = jobs[jobs.Type == 'ML']\nds_daily = ds.groupby('as_of_date').sum().reset_index()\nds_daily = ds_daily.iloc[:,[0,2]]\nml_daily = ml.groupby('as_of_date').sum().reset_index()\nml_daily = ml_daily.iloc[:,[0,2]]\ndsfcast, ds_orig = Prediction(ds_daily, train_end='2018-06-20', future_days=26)\nmlfcast, ml_orig = Prediction(ml_daily, train_end='2018-06-20', future_days=26)","99fd0830":"### Only plotting the dates after 2018-01-01\nds_daily = ds_daily[ds_daily.ds >= '2018-01-01'].reset_index(drop=True)\nml_daily = ml_daily[ml_daily.ds >= '2018-01-01'].reset_index(drop=True)","fd0b7f72":"### Plot the 95% prediction C.I with original posting volume and predicted volume\nupper_bound_1 = go.Scatter(\n    x=dsfcast['date'],\n    y=dsfcast['yhat_upper'],\n    line = dict(\n        color = \"#444\",\n        width = 1),\n    opacity=.5,\n    showlegend=False)\ntrace1 = go.Scatter(\n    name='DS job posting prediction',\n    x=dsfcast['date'],\n    y=dsfcast['yhat'],\n    mode='lines',\n    line = dict(\n        width = 2))\ntrace2 = go.Scatter(\n    name='real DS job posting',\n    x=ds_daily['ds'],\n    y=ds_daily['y'],\n    mode='lines',\n    line = dict(\n        width = 1.5))\nlower_bound_1 = go.Scatter(\n    x=dsfcast['date'],\n    y=dsfcast['yhat_lower'],\n    line = dict(\n        color = \"#444\",\n        width = 1),\n    opacity=.5,\n    name='95% prediction bound')\nupper_bound_2 = go.Scatter(\n    x=mlfcast['date'],\n    y=mlfcast['yhat_upper'],\n    line = dict(\n        color = \"#444\",\n        width = 1),\n    opacity=.5,\n    showlegend=False)\ntrace3 = go.Scatter(\n    name='ML job posting prediction',\n    x=mlfcast['date'],\n    y=mlfcast['yhat'],\n    mode='lines',\n    line = dict(\n        width = 2,\n        color = 'rgb(145,191,219)'))\ntrace4 = go.Scatter(\n    name='real ML job posting',\n    x=ml_daily['ds'],\n    y=ml_daily['y'],\n    mode='lines',\n    line = dict(\n        width = 1.5,\n        color = 'rgb(252.0, 141.0, 89.0)'))\nlower_bound_2 = go.Scatter(\n    x=mlfcast['date'],\n    y=mlfcast['yhat_lower'],\n    line = dict(\n        color = \"#444\",\n        width = 1),\n    opacity=.5,\n    showlegend=False)\ndata = [upper_bound_1, lower_bound_1, trace1, trace2, upper_bound_2, lower_bound_2, trace3, trace4]\nlayout = go.Layout(\n    yaxis=dict(title='daily post volume'),\n    title='Job Posting Historical Volume and Prediction',\n    showlegend = True)\nfig = go.Figure(data=data, layout=layout)\noffline.iplot(fig, show_link=False)","6b62afc0":"<br>Table of Content:\n\n1. [Introduction](#1)\n1. [Loading the truncated dataset](#2)\n1. [Processing the data and plotting the time series histories](#3)\n1. [Geographic information](#4)\n1. [Geographic growth calculation and plotting](#5)\n1. [Prediction model for job postings](#6)\n1. [Plotting DS and ML short term trend with 95% C.I. bound](#7)\n1. [Future work](#8)","0cb4cf7d":"<a id=\"3\"><\/a> <br>\n### Processing the data and plotting the time series histories\n1. change the date to pd datetime format\n2. count the number of openings, all NAs are set to 1 as default","265b3eb1":"<a id=\"4\"><\/a> <br>\n### Geographic information","0eb43472":"<a id=\"2\"><\/a> <br>\n### Loading the truncated dataset\ndataset was pre-processed by mySQL to only select the job title[](http:\/\/) contains **Data Scientist and Machine Learning****[](http:\/\/)","5e7146b8":"<a id=\"8\"><\/a> <br>\n### Futher study \n1. To analyze which industry fields that have the fastest growing rates in these two job position postings\n2. By combining the Linked-in company field profile, to see if still the tech companys like Amazon, Apple, Facebook dominates or other sales companys like Costco, Walmarts have faster growing demands in those two positions.[](http:\/\/)","abd5018b":"<a id=\"7\"><\/a> <br>\n### Predicting DS and ML Seperately with 95% C.I. bound","65008e85":"<a id=\"6\"><\/a> <br>\n### Predicting future job postings\n1. By training on the historical posting information and predicting future 26 days\n2. In testing the model performance, I use all the dates before 2018-06-20, and using the next 30 days as validation set.\n3. Adding the 95% prediction C.I. bound","1ee6ecbf":"<a id=\"1\"><\/a> <br>\n## Introduction\n* In this kernel, I will put my capstone project and explorative figures here.\n\n* The goal in this capstone is to explore the followings:\n    1. The time series trajectories of Data Scientist and Machine Learning Engineer job posting volumes. (To see whether they are continue to expand rapidly or showing signs of slowing down)\n    2. The Geographic growth comparisons in those two job positions demand (To see where the future opportunities are)\n    3. Built a prediction model to predict the short term job demands in these two positions\n    4. Future work","fde2a67b":"<a id=\"5\"><\/a> <br>\n### Geographic growth calculation and plotting\n1. Calculate year-over-year monthly growth rates by states by $GR = \\frac{S_{2018i} - S_{2017i}}{S_{2017i}}$, where $S_{2018i}$ is the total job postings in month $i$ in year 2018\n"}}