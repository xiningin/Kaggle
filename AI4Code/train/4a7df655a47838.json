{"cell_type":{"971a82ef":"code","85524317":"code","d4f1c85c":"code","f21b2c2c":"code","230b7204":"code","7adcc417":"code","fa8e99fc":"code","1d686625":"code","5c8cd584":"code","0595fe12":"code","b3bbe12c":"code","901a7bd9":"code","56987a53":"code","a1c24fff":"code","1b717a3e":"code","6750c914":"code","ff537160":"code","3f2d46a1":"code","cd26bbf9":"code","7e75709e":"code","a0df3ca5":"code","2ec085cb":"code","0feb4834":"code","96588d9f":"markdown","682b737b":"markdown","8ddac84d":"markdown","c1b024c4":"markdown","3937e3c9":"markdown","0b1f5e1a":"markdown","49e1d2cf":"markdown","68cf2bd6":"markdown","68724434":"markdown"},"source":{"971a82ef":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\nsns.set_style('whitegrid')\n\nimport os\nfrom tqdm import tqdm\n\nimport tensorflow as tf\nimport tensorflow.keras.layers as layers\n\nimport PIL\nimport PIL.Image as pim\n\nfrom sklearn.model_selection import train_test_split","85524317":"#get the location of images\nbase_url = '..\/input\/flowers-recognition\/flowers'\nCATEGORIES = 'daisy dandelion rose sunflower tulip'.split()","d4f1c85c":"files_count = []\nfor i,f in enumerate(CATEGORIES):\n    folder_path = os.path.join(base_url, f)\n    for path in os.listdir(os.path.join(folder_path)):\n        files_count.append(['{}\/{}'.format(folder_path,path), f, i])\nflowers_df = pd.DataFrame(files_count, columns=['filepath', 'class_name', 'label'])\nflowers_df.head()","f21b2c2c":"flowers_df.class_name.value_counts()","230b7204":"SAMPLE_PER_CATEGORY = 500\nflowers_df = pd.concat([flowers_df[flowers_df['class_name']== i][:SAMPLE_PER_CATEGORY] for i in CATEGORIES])","7adcc417":"flowers_df.class_name.value_counts()","fa8e99fc":"pim.open(flowers_df.filepath[0])","1d686625":"#split the data\nX = flowers_df['filepath']\ny = flowers_df['label']\n\ntrain, test, label_train, label_test = train_test_split(X, y, test_size=0.2, random_state=101)","5c8cd584":"#convert data as a tensor\ntrain_paths = tf.convert_to_tensor(train.values, dtype=tf.string)\ntrain_labels = tf.convert_to_tensor(label_train.values)\n\ntest_paths = tf.convert_to_tensor(test.values, dtype=tf.string)\ntest_labels = tf.convert_to_tensor(label_test.values)","0595fe12":"#create a tensor data set\ntrain_data = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\ntest_data = tf.data.Dataset.from_tensor_slices((test_paths, test_labels))","b3bbe12c":"#function to load the image and convert them as an array\ndef map_fn(path, label):\n    image = tf.image.decode_jpeg(tf.io.read_file(path))\n\n    return image, label\n\n#apply the function\ntrain_data = train_data.map(map_fn)\ntest_data = test_data.map(map_fn)","901a7bd9":"fig, ax = plt.subplots(1,2, figsize = (15,5))\nfor i,l in train_data.take(1):\n    ax[0].set_title('SAMPLE IMAGE FROM TRAIN DATA');\n    ax[0].imshow(i);\nfor i,l in test_data.take(1):\n    ax[1].set_title('SAMPLE IMAGE FROM TEST DATA');\n    ax[1].imshow(i);","56987a53":"IMAGE_SIZE = 150\n#image preprocessing\ndef preprocessing(image, label):\n    \"\"\"\n    returns a image that is reshaped and normalized\n    \"\"\"\n    image = tf.cast(image, tf.float32)\n    image = image \/ 255.\n    image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n    \n    return image, label\n\n#apply the function\ntrain_data = train_data.map(preprocessing)\ntest_data = test_data.map(preprocessing)","a1c24fff":"#show the processed images\nfig, ax = plt.subplots(1,2, figsize = (15,5))\nfor i,l in train_data.take(1):\n    ax[0].set_title('SAMPLE IMAGE FROM TRAIN DATA');\n    ax[0].imshow(i);\nfor i,l in test_data.take(1):\n    ax[1].set_title('SAMPLE IMAGE FROM TEST DATA');\n    ax[1].imshow(i);","1b717a3e":"#batch the images\nBATCH_SIZE = 32\n\ntrain_batches = train_data.batch(BATCH_SIZE)\ntest_batches = test_data.batch(BATCH_SIZE)\n\nfor i, l in train_batches.take(1):\n    print('Train Data Shape',i.shape)\nfor i, l in test_batches.take(1):\n    print('Test Data Shape',i.shape)","6750c914":"#define input shape\ninp_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)\n\n#load a pretrained model for feature map extraction of images\nbase_model = tf.keras.applications.InceptionV3(input_shape=inp_shape,\n                                               include_top=False,\n                                               weights='imagenet')\nbase_model.summary()","ff537160":"#let's try to pass an image to the model to verify the output shape\nfor i,l in train_batches.take(1):\n    pass\nbase_model(i).shape","3f2d46a1":"#disable the training property (we dont want to change the convolutional base that was already trained)\nbase_model.trainable = False","cd26bbf9":"model = tf.keras.models.Sequential()\nmodel.add(base_model)\nmodel.add(layers.GlobalAveragePooling2D())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Dense(len(CATEGORIES), activation = 'sigmoid'))\nmodel.summary()","7e75709e":"#compile the model\nmodel.compile(optimizer='adam',\n              loss = 'sparse_categorical_crossentropy',\n              metrics=['accuracy'])","a0df3ca5":"#fit the model\nmodel.fit(train_batches,\n          epochs=20,\n          validation_data=(test_batches))","2ec085cb":"#lets create a function to communicate with the model\n\ndef predict(filepath, model):\n    #image processing\n    img = tf.image.decode_image(tf.io.read_file(filepath))\n    img = tf.cast(img, tf.float32)\n    img = img \/ 255.\n    img = tf.image.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n    \n    #convert to tensor\n    img = tf.convert_to_tensor(img)\n    img = tf.expand_dims(img, axis=0)\n    \n    #make a prediction\n    prediction = model.predict_classes(img)[0]\n    return (\"THAT'S A \" + str(CATEGORIES[prediction])).capitalize()","0feb4834":"#test the model\npredict(test.iloc[12], model)","96588d9f":"### SHOW SAMPLE IMAGE","682b737b":"### TRANSFER LEARNING","8ddac84d":"### ADD A DENSE LAYER FOR CLASSIFICATION","c1b024c4":"### GET ONLY 500 SAMPLES PER CATEGORY","3937e3c9":"### CREATE A DATAFRAME","0b1f5e1a":"### CREATE A TENSOR DATASET","49e1d2cf":"### IMAGE PROCESSING","68cf2bd6":"### BATCH THE IMAGES","68724434":"### WRAP UP!!\n\n#### REFERENCE\n* https:\/\/www.tensorflow.org\/"}}