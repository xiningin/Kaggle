{"cell_type":{"122990e0":"code","309a3870":"code","01fd9cf5":"code","2210e154":"code","fedddb5a":"code","7434735e":"code","3d377788":"code","82c70528":"code","600e38a2":"code","643440f8":"code","0974c069":"code","f8e1a44d":"code","68b5cc9a":"code","c9e4ff03":"code","6fe73a3a":"code","e1c799eb":"code","8797ab03":"code","b370dfe3":"code","08b86086":"code","0d6cc203":"code","ef5d997d":"markdown","7069e74e":"markdown","7cc6294f":"markdown","0fbbbf0b":"markdown","dc007aaa":"markdown","8c4ad3b2":"markdown","ee1f76ad":"markdown","6f4cd583":"markdown"},"source":{"122990e0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport time\nimport copy\n\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","309a3870":"#Import Pytorch\nimport torch\nimport torchvision\nfrom torchvision import transforms, models\n\n#Little commonly used shortcut\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn, optim\nfrom torch.optim import lr_scheduler\n\n\n# importing library\n\nfrom PIL import Image\n\n#We need the display function from IPython for Jupyter Notebook\/Colab\nfrom IPython.display import display\n\n#A package to make beautiful progress bars :) \nfrom tqdm.notebook import tqdm\n\n","01fd9cf5":"labels = []\nimg_list = []\ndf_dict = {}\nfile = open(\"..\/input\/polytech-ds-2020\/ip102_polytech_v2\/ip102_polytech\/train.txt\", 'r')\nlines = file.readlines()\nfile.close()\nfor line in lines:\n    img_name, label = line.strip().split(\" \")\n    label = int(label)\n    img_list.append(img_name)\n    labels.append(label)\n    df_dict[img_name] = label\n    \nprint(\"Total Nb labels\", len(labels))\nprint(\"Nb of unique labels\",len(np.unique(labels)))","2210e154":"df = pd.DataFrame.from_dict(df_dict, orient='index', columns=['label'])\ndf.head()","fedddb5a":"df.plot.hist(bins=102)","7434735e":"class InsectDataset(torch.utils.data.Dataset):\n\n    \"\"\"Insect dataset.\"\"\"\n\n    def __init__(self, text_info_path, image_info_path):\n        \"\"\"\n        Args:\n            \n        \"\"\"\n        self.text_info_path = text_info_path\n        self.image_info_path =image_info_path\n        \n        # pytorch transofrms\n        self.transform = transforms.Compose([ \n                                        transforms.Resize(256),\n                                        transforms.CenterCrop(224),\n                                        transforms.ToTensor(),\n                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n                                       ])\n        self.transform_2 = transforms.ToTensor()\n        \n        # Loading images names and labels\n        img_list = []\n        labels = []\n        \n        file = open(text_info_path, 'r')\n        lines = file.readlines()\n        file.close()\n        for line in lines:\n            img_name, label = line.strip().split(\" \")\n            img_list.append(img_name)\n            labels.append(label)\n            \n        self.img_list = img_list\n        self.labels = labels\n        self.classes = np.unique(self.labels)\n           \n    def __len__(self):\n        return len(self.labels)\n\n\n    def __getitem__(self, idx):\n        img = Image.open(self.image_info_path+self.img_list[idx]).convert(\"RGB\")\n        img= self.transform(img)\n        #labels = self.transform_2(self.labels[idx])\n        #sample = {'image': img, 'class': int(self.labels[idx])}\n        return img, int(self.labels[idx])\n    \n       \n        ","3d377788":"insect_train_data = InsectDataset(\"..\/input\/polytech-ds-2020\/ip102_polytech_v2\/ip102_polytech\/train.txt\",\"..\/input\/polytech-ds-2020\/ip102_polytech_v2\/ip102_polytech\/training_images\/\")\ninsect_val_data = InsectDataset(\"..\/input\/polytech-ds-2020\/ip102_polytech_v2\/ip102_polytech\/val.txt\",\"..\/input\/polytech-ds-2020\/ip102_polytech_v2\/ip102_polytech\/training_images\/\")\nimage_datasets = {}\nimage_datasets[\"train\"] = insect_train_data\nimage_datasets[\"val\"] = insect_val_data","82c70528":"dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n                                          shuffle=True, num_workers=2) for x in ['train', 'val']}","600e38a2":"\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names = image_datasets['train'].classes\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","643440f8":"def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in tqdm(dataloaders[phase]):\n                inputs = inputs.to(device)\n                #labels = torch.Tensor(np.array(labels))\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n            \n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","0974c069":"len(image_datasets[\"train\"].classes)","f8e1a44d":"def set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        for param in model.parameters():\n            param.requires_grad = False","68b5cc9a":"model_ft = None\n\n\ndef set_model(name):\n    if name == \"resnet101\":\n        model_ft = models.resnet101(pretrained=True)\n        for param in model_ft.parameters():\n            param.requires_grad = False\n        # Parameters of newly constructed modules have requires_grad=True by default\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs, len(image_datasets[\"train\"].classes))\n        model_ft = model_ft.to(device)\n        return model_ft\n    \n    if name == \"vgg19\":\n        \n        model_ft = models.vgg19_bn(pretrained= True)\n        for param in model_ft.parameters():\n            param.requires_grad = False\n        num_ftrs = model_ft.classifier[6].in_features\n        model_ft.classifier[6] = nn.Linear(num_ftrs,102)\n        input_size = 224\n        return model_ft\n    \n    if name == \"GoogleNet\":\n        print(\"google\")\n        model_ft = torch.hub.load('pytorch\/vision:v0.6.0', 'googlenet', pretrained=True)\n        return model_ft \n        \n        \n    if name == \"vgg16\":\n        model_ft = models.vgg16_bn(pretrained= True)\n        for param in model_ft.parameters():\n            param.requires_grad = False\n        num_ftrs = model_ft.classifier[6].in_features\n        model_ft.classifier[6] = nn.Linear(num_ftrs,102)\n        input_size = 224\n        return model_ft\n    else:\n        print(\"please, write the good name model\")\n\n        \n        \nmodel_ft= set_model(\"GoogleNet\")        \n\nmodel_ft = model_ft.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=1, gamma=0.1)\n\n        ","c9e4ff03":"\n\"\"\"\nfrom keras.layers import Dense, Activation, Flatten\nx = Flatten()(model_ft.output)\nx = Dense(102, activation='sigmoid')(x)\nmodel_ft_nv = Model(inputs=model_ft.inputs, ouputs=x)\nprint(model_ft_nv)\n\n\"\"\"","6fe73a3a":"model_ft, train_losses, val_losses = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=5)","e1c799eb":"import matplotlib.pyplot as plt\n\nplt.plot(train_losses, label='Training loss')\nplt.plot(val_losses, label='Validation loss')\nplt.legend(frameon=False)\nplt.show()","8797ab03":"# evaluation mode\nmodel_ft.eval()\n\n#transformations\nimage_transform = transforms.Compose([ \n                                        transforms.Resize(256),\n                                        transforms.CenterCrop(224),\n                                        transforms.ToTensor(),\n                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n\n# submission\nheaders = ['name','class']\nrows = []\n\n#test images\ndirectory = '..\/input\/polytech-ds-2020\/ip102_polytech_v2\/ip102_polytech\/test_images'\n\nfor filename in tqdm(os.listdir(directory)):\n    if filename.endswith(\".jpg\"):\n        img = Image.open(directory+ '\/' + filename).convert(\"RGB\")\n        test_value = image_transform(img)\n        # then put it on the GPU, make it float and insert a fake batch dimension\n        test_value = test_value.to(device)\n        test_value = test_value.float()\n        test_value = test_value.unsqueeze(0)\n        \n        # pass it through the model\n        prediction = model_ft(test_value)\n\n        # get the result out and reshape it\n        output = prediction.max(1)[1]\n        rows.append({'name':filename, 'class':output.item()})\n        continue\n    else:\n        print(\"not an image\")\n        continue","b370dfe3":"import csv\nwith open('test_predictions.csv','w',newline='') as f:\n    f_csv = csv.DictWriter(f,headers)\n    f_csv.writeheader()\n    f_csv.writerows(rows)","08b86086":"from IPython.display import FileLink, FileLinks\nFileLinks('.') #lists all downloadable files on server","0d6cc203":"df_test = pd.DataFrame.from_dict(rows, orient='index', columns=['label'])\ndf_test.head()","ef5d997d":"# Plottig training and validaion loss","7069e74e":"# Preprocessing\nThe idea here is to create different datasets with specifically sampled labels.\nWe will start with small number labels, mid numbered labels and labels with a lot of elements in them. See the distribution above","7cc6294f":"# Analysis of the prediction","0fbbbf0b":"# Prefictiions on the Test data","dc007aaa":"# Analysis of data","8c4ad3b2":"# In this part we are going to see how to train our model ?","ee1f76ad":"# Training and validation","6f4cd583":"we test the number of classes :"}}