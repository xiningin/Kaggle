{"cell_type":{"2d7b9974":"code","0fc8eb08":"code","7e552564":"code","3d635466":"code","c2afc095":"code","89d7fc4b":"code","d6ec0b9e":"code","55eec263":"code","192715ad":"code","8bdfa8d3":"code","75862ad1":"code","a1c87a11":"code","87c40906":"code","6dd6a9fd":"code","0333bc7a":"code","ed52bdf5":"code","13c62b97":"code","445a82d0":"code","bd54156d":"code","64407785":"code","5ed213e5":"code","113d772e":"code","677c7cf3":"code","f55658a2":"code","e74c4e01":"code","1836c773":"code","e41bdb67":"code","a67c5766":"code","f8034925":"code","55d55be5":"code","79a4098b":"code","ecf44e95":"code","f27179d5":"code","8fc1eadf":"code","2e0b6167":"code","24967969":"code","9e5277be":"code","7ec95381":"code","9bf52c85":"code","e30e690b":"code","a75f70e0":"code","b2255d02":"code","4257f1c4":"code","a1e13746":"code","6cddb421":"code","95c7616d":"code","e1be5de2":"code","ee190960":"code","ef77dab9":"code","4ecad4b5":"code","171e22ef":"code","027e75eb":"code","430d55f8":"code","4ed42059":"code","de0b3ebb":"code","067346fd":"code","c63b9947":"code","d73b97a7":"code","608a1c29":"code","b569d457":"code","b19f7928":"code","f21989ca":"code","2ea4d19d":"code","a2296262":"code","6f26dbd5":"code","ffa5e3b8":"code","d974be4a":"code","4d74f5c9":"code","da82c48f":"code","d7e4f19f":"code","85e75878":"code","8b304d8b":"code","79e49fb8":"code","70c3252e":"code","44b51144":"code","a5074f4d":"code","ed0fdaac":"code","3722cf9d":"code","646d9cd4":"code","8f7112dc":"code","ff033d0c":"code","9c62e95c":"code","03f77533":"code","708b79d4":"code","2d54fb62":"code","e279dad1":"code","d50ab415":"code","a618d504":"code","40fd5b61":"code","9c6fc4d6":"code","83f3193d":"code","0c31dbef":"code","63d3e33d":"code","27e551a1":"code","1b429c29":"code","af29c44f":"code","3f14bb83":"code","c73a5b83":"code","4e778aa5":"code","1f6f19a9":"code","152950e8":"code","c5f5bb64":"markdown","238f6640":"markdown","368b385b":"markdown","08dce5e9":"markdown","3885d6f4":"markdown","4448b445":"markdown","53782c24":"markdown","182e57ac":"markdown","b7ce5b28":"markdown","65fbd9fa":"markdown","270bd5cc":"markdown","16d334b3":"markdown","ce1da0e2":"markdown","ea07afe9":"markdown","aa1c051e":"markdown","c48b4b3c":"markdown","ea6497aa":"markdown","07f383fe":"markdown","34a08d8f":"markdown","9439a0c9":"markdown","ee111761":"markdown","94f70a82":"markdown","1c087706":"markdown","9c9aea4a":"markdown","ac5d24e6":"markdown","5e9ed04b":"markdown","78dfd261":"markdown","7b555146":"markdown","515750b8":"markdown","067cf320":"markdown","d6d20b86":"markdown","90b28ba3":"markdown","c68901e4":"markdown","a38dd233":"markdown","d1e7ae85":"markdown","bc18850f":"markdown","4f732852":"markdown","c367be03":"markdown","a3707058":"markdown","cc1f5589":"markdown"},"source":{"2d7b9974":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport scipy as sp\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\n\n# Standard plotly imports\n#import plotly.plotly as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nfrom plotly.offline import iplot, init_notebook_mode\n#import cufflinks\n#import cufflinks as cf\nimport plotly.figure_factory as ff\n\n# Using plotly + cufflinks in offline mode\ninit_notebook_mode(connected=True)\n#cufflinks.go_offline(connected=True)\n\n# Preprocessing, modelling and evaluating\nfrom sklearn import preprocessing\nfrom sklearn.metrics import confusion_matrix, roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score, KFold\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\n\n## Hyperopt modules\nfrom hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK, STATUS_RUNNING\nfrom functools import partial\n\nimport os\nimport gc\nprint(os.listdir(\"..\/input\"))","0fc8eb08":"df_id = pd.read_csv(\"..\/input\/train_identity.csv\")\ndf_trans = pd.read_csv(\"..\/input\/train_transaction.csv\")","7e552564":"df_id.head()","3d635466":"summary = pd.DataFrame(df_id.dtypes, columns=['dtypes'])\nsummary.head()","c2afc095":"summary = summary.reset_index()\nsummary.head()","89d7fc4b":"summary['Name'] = summary['index']\nsummary.head()","d6ec0b9e":"summary = summary[['Name', 'dtypes']]\nsummary.head()","55eec263":"summary['Missing'] = df_id.isnull().sum().values\nsummary.head()","192715ad":"summary['Uniques'] = df_id.nunique().values\nsummary.head()","8bdfa8d3":"summary['First Value'] = df_id.loc[0].values\nsummary.head()","75862ad1":"summary['Second Value'] = df_id.loc[1].values\nsummary.head()","a1c87a11":"summary['Third Value'] = df_id.loc[2].values\nsummary.head()","87c40906":"def resumetable(df):\n    print(f\"Dataset Shape: {df.shape}\")\n    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Name'] = summary['index']\n    summary = summary[['Name','dtypes']]\n    summary['Missing'] = df.isnull().sum().values    \n    summary['Uniques'] = df.nunique().values\n    summary['First Value'] = df.loc[0].values\n    summary['Second Value'] = df.loc[1].values\n    summary['Third Value'] = df.loc[2].values\n\n    for name in summary['Name'].value_counts().index:\n        summary.loc[summary['Name'] == name, 'Entropy'] = round(stats.entropy(df[name].value_counts(normalize=True), base=2),2) \n\n    return summary","6dd6a9fd":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']","0333bc7a":"start_mem = df_id.memory_usage().sum() \/  1024 ** 2\nstart_mem","ed52bdf5":"for col in df_id.columns:\n    break","13c62b97":"col_type = df_id[col].dtypes\ncol_type","445a82d0":"c_min = df_id[col].min()\nc_min","bd54156d":"str(col_type)","64407785":"np.iinfo(np.int32).max","5ed213e5":"df_id[col] = df_id[col].astype(np.int8)\ndf_id[col]","113d772e":"df_id[col]","677c7cf3":"## Function to reduce the DF size\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","f55658a2":"def CalcOutliers(df_num): \n\n    # calculating mean and std of the array\n    data_mean, data_std = np.mean(df_num), np.std(df_num)\n\n    # seting the cut line to both higher and lower values\n    # You can change this value\n    cut = data_std * 3\n\n    #Calculating the higher and lower cut values\n    lower, upper = data_mean - cut, data_mean + cut\n\n    # creating an array of lower, higher and total outlier values \n    outliers_lower = [x for x in df_num if x < lower]\n    outliers_higher = [x for x in df_num if x > upper]\n    outliers_total = [x for x in df_num if x < lower or x > upper]\n\n    # array without outlier values\n    outliers_removed = [x for x in df_num if x > lower and x < upper]\n    \n    print('Identified lowest outliers: %d' % len(outliers_lower)) # printing total number of values in lower cut of outliers\n    print('Identified upper outliers: %d' % len(outliers_higher)) # printing total number of values in higher cut of outliers\n    print('Total outlier observations: %d' % len(outliers_total)) # printing total number of values outliers of both sides\n    print('Non-outlier observations: %d' % len(outliers_removed)) # printing total number of non outlier values\n    print(\"Total percentual of Outliers: \", round((len(outliers_total) \/ len(outliers_removed) )*100, 4)) # Percentual of outliers in points\n    \n    return","e74c4e01":"# reducing memory\ndf_trans = reduce_mem_usage(df_trans)\ndf_id = reduce_mem_usage(df_id)","1836c773":"resumetable(df_trans)[:31]","e41bdb67":"df_trans['TransactionAmt'] = df_trans['TransactionAmt'].astype(float)\ntotal = len(df_trans)\ntotal_amt = df_trans.groupby(['isFraud'])['TransactionAmt'].sum().sum()","a67c5766":"plt.figure(figsize = (16,6))\nplt.subplot(121)\ng = sns.countplot(x = 'isFraud', data= df_trans)\ng.set_title('Fraud Transactions Distribution \\n# 0: No Fraud | 1: Fraud #', fontsize = 22)\ng.set_xlabel('Is fraud?', fontsize= 18)\ng.set_ylabel('Count', fontsize = 18)\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()\/2.,\n           height + 3,\n          '{:1.2f}%'.format(height\/total*100),\n          ha = 'center', fontsize = 15)\n    \nperc_amt = (df_trans.groupby(['isFraud'])['TransactionAmt'].sum())\nperc_amt = perc_amt.reset_index()\nplt.subplot(122)\ng1 = sns.barplot(x='isFraud', y='TransactionAmt',  dodge=True, data=perc_amt)\ng1.set_title(\"% Total Amount in Transaction Amt \\n# 0: No Fraud | 1: Fraud #\", fontsize=22)\ng1.set_xlabel(\"Is fraud?\", fontsize=18)\ng1.set_ylabel('Total Transaction Amount Scalar', fontsize=18)\nfor p in g1.patches:\n    height = p.get_height()\n    g1.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}%'.format(height\/total_amt * 100),\n            ha=\"center\", fontsize=15) ","f8034925":"df_trans['TransactionAmt'] = df_trans['TransactionAmt'].astype(float)\nprint(\"Transaction Amounts Quantiles:\")\nprint(df_trans['TransactionAmt'].quantile([.01, .025, .1, .25, .5, .75, .9, .975, .99]))","55d55be5":"plt.figure(figsize=(16,12))\nplt.suptitle('Transaction Values Distribution', fontsize=22)\nplt.subplot(221)\ng = sns.distplot(df_trans[df_trans['TransactionAmt'] <= 1000]['TransactionAmt'])\ng.set_title(\"Transaction Amount Distribuition <= 1000\", fontsize=18)\ng.set_xlabel(\"\")\ng.set_ylabel(\"Probability\", fontsize=15)\n\nplt.subplot(222)\ng1 = sns.distplot(np.log(df_trans['TransactionAmt']))\ng1.set_title('Transaction Amount (log) Distribution', fontsize = 18)\ng1.set_xlabel(\"\")\ng1.set_ylabel(\"Probabaility\", fontsize = 15)\n\n\n#df_trans[df_trans['isFraud']==0].shape[0] \uc758 shape[0]\uc740 \ub370\uc774\ud130 \uac1c\uc218, shape[1]\uc740 feature \uac1c\uc218 \nplt.figure(figsize=(16,12))\nplt.subplot(212)\ng4 = plt.scatter(range(df_trans[df_trans['isFraud']==0].shape[0]),\n                 np.sort(df_trans[df_trans['isFraud']==0]['TransactionAmt'].values),\n                label = 'NoFraud', alpha=.2)\n\ng4 = plt.scatter(range(df_trans[df_trans['isFraud'] == 1].shape[0]),\n                 np.sort(df_trans[df_trans['isFraud'] == 1]['TransactionAmt'].values), \n                 label='Fraud', alpha=.2)\ng4= plt.title(\"ECDF \\nFRAUD and NO FRAUD Transaction Amount Distribution\", fontsize=18)\ng4 = plt.xlabel(\"Index\")\ng4 = plt.ylabel(\"Amount Distribution\", fontsize=15)\ng4 = plt.legend()\n\nplt.figure(figsize=(16,12))\nplt.subplot(321)\ng = plt.scatter(range(df_trans[df_trans['isFraud'] == 1].shape[0]), \n                 np.sort(df_trans[df_trans['isFraud'] == 1]['TransactionAmt'].values), \n                label='isFraud', alpha=.4)\nplt.title(\"FRAUD - Transaction Amount ECDF\", fontsize=18)\nplt.xlabel(\"Index\")\nplt.ylabel(\"Amount Distribution\", fontsize=12)\n\nplt.subplot(322)\ng1 = plt.scatter(range(df_trans[df_trans['isFraud']==0].shape[0]),np.sort(df_trans[df_trans['isFraud']==0]['TransactionAmt'].values),\n                 label = 'NoFraud', alpha = .2)\ng1= plt.title(\"NO FRAUD - Transaction Amount ECDF\", fontsize=18)\ng1 = plt.xlabel(\"Index\")\ng1 = plt.ylabel(\"Amount Distribution\", fontsize=15)\n\nplt.suptitle('Individual ECDF Distribution', fontsize=22)\n\n","79a4098b":"pd.concat([df_trans[df_trans['isFraud'] == 1]['TransactionAmt']\\\n                 .quantile([.01, .1, .25, .5, .75, .9, .99])\\\n                 .reset_index(), \n                 df_trans[df_trans['isFraud'] == 0]['TransactionAmt']\\\n                 .quantile([.01, .1, .25, .5, .75, .9, .99])\\\n                 .reset_index()],\n                axis=1, keys=['Fraud', \"No Fraud\"])","ecf44e95":"CalcOutliers(df_trans['TransactionAmt'])","f27179d5":"df_trans['ProductCD']","8fc1eadf":"tmp = pd.crosstab(df_trans['ProductCD'], df_trans['isFraud'], normalize='index') * 100\ntmp = tmp.reset_index()\ntmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n","2e0b6167":"plt.figure(figsize = (14,10))\nplt.suptitle('ProductCD Distributions', fontsize = 22)\n\nplt.subplot(221)\ng = sns.countplot(x='ProductCD', data=df_trans)\n# plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\n\ng.set_title(\"ProductCD Distribution\", fontsize=19)\ng.set_xlabel(\"ProductCD Name\", fontsize=17)\ng.set_ylabel(\"Count\", fontsize=17)\ng.set_ylim(0,500000)\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}%'.format(height\/total*100),\n            ha=\"center\", fontsize=14) ","24967969":"#plt.subplot(222)\nplt.figure(figsize = (10,10))\ng1 = sns.countplot(x='ProductCD', hue='isFraud', data=df_trans)\nplt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])\ngt = g1.twinx()\ngt = sns.pointplot(x='ProductCD', y='Fraud', data=tmp, color='black', order=['W', 'H',\"C\", \"S\", \"R\"], legend=False)\ngt.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n\ng1.set_title(\"Product CD by Target(isFraud)\", fontsize=19)\ng1.set_xlabel(\"ProductCD Name\", fontsize=17)\ng1.set_ylabel(\"Count\", fontsize=17)\n","9e5277be":"plt.figure(figsize = (5,5))\ng3 = sns.boxenplot(x = 'ProductCD', y = 'TransactionAmt', hue = 'isFraud',\n                  data=df_trans[df_trans['TransactionAmt']<=2000])\ng3.set_title(\"Transaction Amount Distribuition by ProductCD and Target\", fontsize=20)\ng3.set_xlabel(\"ProductCD Name\", fontsize=17)\ng3.set_ylabel(\"Transaction Values\", fontsize=17)\n\nplt.subplots_adjust(hspace = 0.6, top = 0.85)\n","7ec95381":"resumetable(df_trans[['card1','card2','card3','card4','card5','card6']])","9bf52c85":"print(\"Card Features Quantiles: \")\nprint(df_trans[['card1','card2','card3', 'card5']].quantile([0.01, .025, .1, .25, .5, .75, .975, .99]))","e30e690b":"df_trans.loc[df_trans.card3.isin(df_trans.card3.value_counts()[df_trans.card3.value_counts()<200].index), 'card3'] = 'Others'\ndf_trans.loc[df_trans.card5.isin(df_trans.card5.value_counts()[df_trans.card5.value_counts() < 300].index), 'card5'] = \"Others\"","a75f70e0":"tmp = pd.crosstab(df_trans['card3'], df_trans['isFraud'], normalize = 'index') * 100\ntmp = tmp.reset_index()\ntmp.rename(columns = {0:'NoFraud', 1:'Fraud'}, inplace = True)\ntmp.head()","b2255d02":"tmp2 = pd.crosstab(df_trans['card5'], df_trans['isFraud'], normalize='index') * 100\ntmp2 = tmp2.reset_index()\ntmp2.rename(columns = {0:'NoFraud', 1:'Fraud'}, inplace = True)","4257f1c4":"plt.figure(figsize = (10,10))\ng = sns.distplot(df_trans[df_trans['isFraud']==1]['card1'], label = 'Fraud')\ng = sns.distplot(df_trans[df_trans['isFraud']==0]['card1'], label = 'NoFraud')\ng.legend()\ng.set_title(\"Card 1 Values Distribution by Target\", fontsize=20)\ng.set_xlabel(\"Card 1 Values\", fontsize=18)\ng.set_ylabel(\"Probability\", fontsize=18)","a1e13746":"plt.figure(figsize =(10,10))\ng1 = sns.distplot(df_trans[df_trans['isFraud'] == 1]['card2'].dropna(), label = 'Fraud')\ng1 = sns.distplot(df_trans[df_trans['isFraud'] == 0]['card2'].dropna(), label = 'NoFruad')\ng1.legend()\ng1.set_title(\"Card 2 Values Distribution by Target\", fontsize=20)\ng1.set_xlabel(\"Card 2 Values\", fontsize=18)\ng1.set_ylabel(\"Probability\", fontsize=18)","6cddb421":"plt.figure(figsize= (10,10))\ng2 = sns.countplot(x = 'card3', data = df_trans, order = list(tmp.card3.values))\ng22 = g2.twinx()\ngg2 = sns.pointplot(x = 'card3', y = 'Fraud', data = tmp,\n                   color = 'black', order = list(tmp.card3.values))\ngg2.set_ylabel('% of Fraud Transactions', fontsize = 16)\ng2.set_title('Card 3 Values Distribution and % of Transaction Frauds', fontsize = 20)\ng2.set_xlabel('Card 3 Values', fontsize = 18)\ng2.set_ylabel('Count', fontsize = 18)\nfor p in g2.patches:\n    height = p.get_height()\n    g2.text(p.get_x()+p.get_width()\/2.,\n           height + 25,\n           '{:1.2f}'.format(height\/total*100),\n            ha = 'center')","95c7616d":"plt.figure(figsize = (15,12))\ng3 = sns.countplot(x = 'card5', data = df_trans, order = list(tmp2.card5.values))\ng3t = g3.twinx()\ng3t = sns.pointplot(x = 'card5', y = 'Fraud', data = tmp2,\n                   color = 'black', order = list(tmp2.card5.values))\ng3t.set_ylabel('% of Fraud Transactions', fontsize = 16)\ng3.set_title('Card 5 Values Distribution and % of Transaction Frauds', fontsize = 20)\ng3.set_xticklabels(g3.get_xticklabels(), rotation = 90)\ng3.set_xlabel('Card 5 Value', fontsize = 18)\ng3.set_ylabel('Count', fontsize = 18)\nfor p in g3.patches:\n    height = p.get_height()\n    g3.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}%'.format(height\/total*100),\n            ha=\"center\",fontsize=11) \nplt.subplots_adjust(hspace = 0.6, top = 0.85)","e1be5de2":"tmp = pd.crosstab(df_trans['card4'], df_trans['isFraud'], normalize='index') * 100\ntmp = tmp.reset_index()\ntmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\ntmp.head()","ee190960":"plt.figure(figsize = (14,10))\nplt.suptitle('Card 4 Distributions', fontsize = 22)","ef77dab9":"g = sns.countplot(x = 'card4', data = df_trans)\ng.set_title('Card4 Distribution', fontsize = 19)\ng.set_ylim(0, 420000)\ng.set_xlabel('Card4 Category Names', fontsize = 17)\ng.set_ylabel('Count', fontsize = 17)\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()\/2.,\n            height + 3,\n            '{:1.2f}%'.format(height\/total*100),\n            ha=\"center\",fontsize=14) ","4ecad4b5":"g1 = sns.countplot(x='card4', hue='isFraud', data=df_trans)\nplt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])\ngt = g1.twinx()\ngt = sns.pointplot(x='card4', y='Fraud', data=tmp, \n                   color='black', legend=False, \n                   order=['discover', 'mastercard', 'visa', 'american express'])\ngt.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\ng1.set_title(\"Card4 by Target(isFraud)\", fontsize=19)\ng1.set_xlabel(\"Card4 Category Names\", fontsize=17)\ng1.set_ylabel(\"Count\", fontsize=17)","171e22ef":"g3 = sns.boxenplot(x = 'card4', y = 'TransactionAmt', hue = 'isFraud',\n                  data = df_trans[df_trans['TransactionAmt'] <= 2000])\ng3.set_title('Card 4 Distribution by ProductCD and Target', fontsize = 20)\ng3.set_xlabel('Card4 Category Names', fontsize = 17)\ng3.set_ylabel('Transaction Values', fontsize = 17)","027e75eb":"tmp = pd.crosstab(df_trans['card6'], df_trans['isFraud'], normalize='index') * 100\ntmp = tmp.reset_index()\ntmp.rename(columns = {0:'NoFraud', 1:'Fraud'}, inplace=True)","430d55f8":"g = sns.countplot(x = 'card6', data = df_trans, order = list(tmp.card6.values))\ng.set_title('Card6 Distribution', fontsize = 19)\ng.set_ylim(0, 480000)\ng.set_xlabel('Card6 Category Names', fontsize = 17)\ng.set_ylabel('Count', fontsize = 17)\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x() + p.get_width()\/2.,\n          height + 3,\n          '{:1.2f}%'.format(height\/total * 100),\n          ha = 'center', fontsize = 15)","4ed42059":"g1 = sns.countplot(x = 'card6', hue= 'isFraud', data = df_trans, order = list(tmp.card6.values))\nplt.legend(title = 'Fruad', loc = 'best', labels = ['No', 'Yes'])\ngt = g1.twinx()\ngt = sns.pointplot(x = 'card6', y = 'Fraud', data = tmp, order = list(tmp.card6.values),\n                  color = 'black', legend = False)\ngt.set_ylim(0,20)\ngt.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\ng1.set_title(\"Card6 by Target(isFraud)\", fontsize=19)\ng1.set_xlabel(\"Card6 Category Names\", fontsize=17)\ng1.set_ylabel(\"Count\", fontsize=17)","de0b3ebb":"plt.figure(figsize = (6,6))\ng3 = sns.boxenplot(x='card6', y='TransactionAmt', hue='isFraud', order=list(tmp.card6.values),\n              data=df_trans[df_trans['TransactionAmt'] <= 2000] )\ng3.set_title(\"Card 6 Distribuition by ProductCD and Target\", fontsize=20)\ng3.set_xlabel(\"Card6 Category Names\", fontsize=17)\ng3.set_ylabel(\"Transaction Values\", fontsize=17)\n","067346fd":"for col in ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']:\n    df_trans[col] = df_trans[col].fillna(\"Miss\")","c63b9947":"def ploting_dist_ratio(df, col, lim=2000):\n    tmp = pd.crosstab(df[col], df['isFraud'], normalize='index') * 100\n    tmp = tmp.reset_index()\n    tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\n    plt.figure(figsize=(20,5))\n    plt.suptitle(f'{col} Distributions ', fontsize=22)\n\n    plt.subplot(121)\n    g = sns.countplot(x=col, data=df, order=list(tmp[col].values))\n    # plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\n    g.set_title(f\"{col} Distribution\\nCound and %Fraud by each category\", fontsize=18)\n    g.set_ylim(0,400000)\n    gt = g.twinx()\n    gt = sns.pointplot(x=col, y='Fraud', data=tmp, order=list(tmp[col].values),\n                       color='black', legend=False, )\n    gt.set_ylim(0,20)\n    gt.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n    g.set_xlabel(f\"{col} Category Names\", fontsize=16)\n    g.set_ylabel(\"Count\", fontsize=17)\n    for p in gt.patches:\n        height = p.get_height()\n        gt.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(height\/total*100),\n                ha=\"center\",fontsize=14) \n        \n    perc_amt = (df_trans.groupby(['isFraud',col])['TransactionAmt'].sum() \/ total_amt * 100).unstack('isFraud')\n    perc_amt = perc_amt.reset_index()\n    perc_amt.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\n    plt.subplot(122)\n    g1 = sns.boxplot(x=col, y='TransactionAmt', hue='isFraud', \n                     data=df[df['TransactionAmt'] <= lim], order=list(tmp[col].values))\n    g1t = g1.twinx()\n    g1t = sns.pointplot(x=col, y='Fraud', data=perc_amt, order=list(tmp[col].values),\n                       color='black', legend=False, )\n    g1t.set_ylim(0,5)\n    g1t.set_ylabel(\"%Fraud Total Amount\", fontsize=16)\n    g1.set_title(f\"{col} by Transactions dist\", fontsize=18)\n    g1.set_xlabel(f\"{col} Category Names\", fontsize=16)\n    g1.set_ylabel(\"Transaction Amount(U$)\", fontsize=16)\n        \n    plt.subplots_adjust(hspace=.4, wspace = 0.35, top = 0.80)\n    ","d73b97a7":"for col in ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']:\n    ploting_dist_ratio(df_trans, col, lim = 2500)","608a1c29":"print('Card Features Quantitles:')\nprint(df_trans[['addr1','addr2']].quantile([0.01, .025, .1, .25, .75, .90, .975, .99]))","b569d457":"df_trans.loc[df_trans.addr1.isin(df_trans.addr1.value_counts()[df_trans.addr1.value_counts() <= 5000].index), 'addr1'] = \"Others\"\ndf_trans.loc[df_trans.addr2.isin(df_trans.addr2.value_counts()[df_trans.addr2.value_counts() <= 50].index), 'addr2'] = 'Others'","b19f7928":" def ploting_cnt_amt(df, col, lim=2000):\n    tmp = pd.crosstab(df[col], df['isFraud'], normalize='index') * 100\n    tmp = tmp.reset_index()\n    tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n    \n    plt.figure(figsize=(16,14))    \n    plt.suptitle(f'{col} Distributions ', fontsize=24)\n    \n    plt.subplot(211)\n    g = sns.countplot( x=col,  data=df, order=list(tmp[col].values))\n    gt = g.twinx()\n    gt = sns.pointplot(x=col, y='Fraud', data=tmp, order=list(tmp[col].values),\n                       color='black', legend=False, )\n    gt.set_ylim(0,tmp['Fraud'].max()*1.1)\n    gt.set_ylabel(\"%Fraud Transactions\", fontsize=16)\n    g.set_title(f\"Most Frequent {col} values and % Fraud Transactions\", fontsize=20)\n    g.set_xlabel(f\"{col} Category Names\", fontsize=16)\n    g.set_ylabel(\"Count\", fontsize=17)\n    g.set_xticklabels(g.get_xticklabels(),rotation=45)\n    sizes = []\n    for p in g.patches:\n        height = p.get_height()\n        sizes.append(height)\n        g.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(height\/total*100),\n                ha=\"center\",fontsize=12) \n        \n    g.set_ylim(0,max(sizes)*1.15)\n    \n    #########################################################################\n    perc_amt = (df.groupby(['isFraud',col])['TransactionAmt'].sum() \\\n                \/ df.groupby([col])['TransactionAmt'].sum() * 100).unstack('isFraud')\n    perc_amt = perc_amt.reset_index()\n    perc_amt.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n    amt = df.groupby([col])['TransactionAmt'].sum().reset_index()\n    perc_amt = perc_amt.fillna(0)\n    plt.subplot(212)\n    g1 = sns.barplot(x=col, y='TransactionAmt', \n                       data=amt, \n                       order=list(tmp[col].values))\n    g1t = g1.twinx()\n    g1t = sns.pointplot(x=col, y='Fraud', data=perc_amt, \n                        order=list(tmp[col].values),\n                       color='black', legend=False, )\n    g1t.set_ylim(0,perc_amt['Fraud'].max()*1.1)\n    g1t.set_ylabel(\"%Fraud Total Amount\", fontsize=16)\n    g.set_xticklabels(g.get_xticklabels(),rotation=45)\n    g1.set_title(f\"{col} by Transactions Total + %of total and %Fraud Transactions\", fontsize=20)\n    g1.set_xlabel(f\"{col} Category Names\", fontsize=16)\n    g1.set_ylabel(\"Transaction Total Amount(U$)\", fontsize=16)\n    g1.set_xticklabels(g.get_xticklabels(),rotation=45)    \n    \n    for p in g1.patches:\n        height = p.get_height()\n        g1.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(height\/total_amt*100),\n                ha=\"center\",fontsize=12) \n        \n    plt.subplots_adjust(hspace=.4, top = 0.9)\n    plt.show()","f21989ca":"ploting_cnt_amt(df_trans,'addr1', lim = 2500)","2ea4d19d":"ploting_cnt_amt(df_trans,'addr2')","a2296262":"df_trans.loc[df_trans['P_emaildomain'].isin(['gmail.com','gmail']),'P_emaildomain'] = 'Google'\ndf_trans.loc[df_trans['P_emaildomain'].isin(['yahoo.com','yahoo.com.mx','yahoo.co.uk','yahoo.co.jp','yahoo.de', 'yahoo.fr', 'yahoo.es']), 'P_emaildomain'] = 'Yahoo Mail'\ndf_trans.loc[df_trans['P_emaildomain'].isin(['hotmail.com','outlook.com','msn.com', 'live.com.mx', \n                                         'hotmail.es','hotmail.co.uk', 'hotmail.de',\n                                         'outlook.es', 'live.com', 'live.fr',\n                                         'hotmail.fr']), 'P_emaildomain'] = 'Microsoft'","6f26dbd5":"df_trans.loc[df_trans.P_emaildomain.isin(df_trans.P_emaildomain.value_counts()[df_trans.P_emaildomain.value_counts() <= 500].index), 'P_emaildomain'] = 'Others'\ndf_trans.P_emaildomain.fillna('NoInf', inplace = True)","ffa5e3b8":"ploting_cnt_amt(df_trans, 'P_emaildomain')","d974be4a":"df_trans.loc[df_trans['R_emaildomain'].isin(['gmail.com', 'gmail']),'R_emaildomain'] = 'Google'\n\ndf_trans.loc[df_trans['R_emaildomain'].isin(['yahoo.com', 'yahoo.com.mx',  'yahoo.co.uk',\n                                             'yahoo.co.jp', 'yahoo.de', 'yahoo.fr',\n                                             'yahoo.es']), 'R_emaildomain'] = 'Yahoo Mail'\ndf_trans.loc[df_trans['R_emaildomain'].isin(['hotmail.com','outlook.com','msn.com', 'live.com.mx', \n                                             'hotmail.es','hotmail.co.uk', 'hotmail.de',\n                                             'outlook.es', 'live.com', 'live.fr',\n                                             'hotmail.fr']), 'R_emaildomain'] = 'Microsoft'","4d74f5c9":"df_trans.loc[df_trans.R_emaildomain.isin(df_trans.R_emaildomain.value_counts()[df_trans.R_emaildomain.value_counts() <= 300].index), 'R_emaildomain'] = 'Others'\ndf_trans.R_emaildomain.fillna('NoInf', inplace = True)","da82c48f":"ploting_cnt_amt(df_trans, 'R_emaildomain')","d7e4f19f":"resumetable(df_trans[['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8','C9', 'C10', 'C11', 'C12', 'C13', 'C14']])","85e75878":"df_trans[['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8','C9', 'C10', 'C11', 'C12', 'C13', 'C14']].describe()","8b304d8b":"df_trans.loc[df_trans.C1.isin(df_trans.C1.value_counts()[df_trans.C1.value_counts()<=400].index), 'C1'] = 'Others'","79e49fb8":"ploting_cnt_amt(df_trans, 'C1')","70c3252e":"a=df_trans.loc[df_trans.C2.isin(df_trans.C2.value_counts()[df_trans.C2.value_counts()<=350].index),'C2'] = 'Others'","44b51144":"ploting_cnt_amt(df_trans, 'C2')","a5074f4d":"# https:\/\/www.kaggle.com\/c\/ieee-fraud-detection\/discussion\/100400#latest-579480\nSTART_DATE = '2017-12-01'\nstartdate = datetime.datetime.strptime(START_DATE, '%Y-%m-%d')\ndf_trans['Date'] = df_trans['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\n\ndf_trans['_Weekdays'] = df_trans['Date'].dt.dayofweek\ndf_trans['_Hours'] = df_trans['Date'].dt.hour\ndf_trans['_Days'] = df_trans['Date'].dt.day","ed0fdaac":"for day in ['_Weekdays','_Days','_Hours']:\n    ploting_cnt_amt(df_trans,day)","3722cf9d":"# Calling the function to transform the date column in datetime pandas object\n\n#seting some static color options\ncolor_op = ['#5527A0', '#BB93D7', '#834CF7', '#6C941E', '#93EAEA', '#7425FF', '#F2098A', '#7E87AC', \n            '#EBE36F', '#7FD394', '#49C35D', '#3058EE', '#44FDCF', '#A38F85', '#C4CEE0', '#B63A05', \n            '#4856BF', '#F0DB1B', '#9FDBD9', '#B123AC']\n\ndates_temp = df_trans.groupby(df_trans.Date.dt.date)['TransactionAmt'].count().reset_index()\ntrace = go.Scatter(x=dates_temp['Date'], y=dates_temp.TransactionAmt,\n                    opacity = 0.8, line = dict(color = color_op[7]), name= 'Total Transactions')","646d9cd4":"dates_temp_sum = df_trans.groupby(df_trans.Date.dt.date)['TransactionAmt'].sum().reset_index()","8f7112dc":"trace1 = go.Scatter(x = dates_temp_sum, line = dict(color = color_op[1]), name = 'Total Amount', y = dates_temp_sum['TransactionAmt'], opacity = 0.8, yaxis = 'y2')","ff033d0c":"layout = dict(\n    title= \"Total Transactions and Fraud Informations by Date\",\n    xaxis=dict(\n        rangeselector=dict(\n            buttons=list([\n                dict(count=1, label='1m', step='month', stepmode='backward'),\n                dict(count=3, label='3m', step='month', stepmode='backward'),\n                dict(count=6, label='6m', step='month', stepmode='backward'),\n                dict(step='all')\n            ])\n        ),\n        rangeslider=dict(visible = True),\n        type='date' ),\n    yaxis=dict(title='Total Transactions'),\n    yaxis2=dict(overlaying='y',\n                anchor='x', side='right',\n                zeroline=False, showgrid=False,\n                title='Total Transaction Amount')\n)","9c62e95c":"fig = dict(data = [trace,trace1,], layout = layout)\niplot(fig)","03f77533":"color_op = ['#5527A0', '#BB93D7', '#834CF7', '#6C941E', '#93EAEA', '#7425FF', '#F2098A', '#7E87AC', \n            '#EBE36F', '#7FD394', '#49C35D', '#3058EE', '#44FDCF', '#A38F85', '#C4CEE0', '#B63A05', \n            '#4856BF', '#F0DB1B', '#9FDBD9', '#B123AC']\n\ntmp_amt = df_trans.groupby([df_trans.Date.dt.date, 'isFraud'])['TransactionAmt'].sum().reset_index()\ntmp_trans = df_trans.groupby([df_trans.Date.dt.date, 'isFraud'])['TransactionAmt'].count().reset_index()\n\ntmp_trans_fraud = tmp_trans[tmp_trans['isFraud']==1]\ntmp_amt_fraud = tmp_amt[tmp_amt['isFraud']==1]\n\ndates_temp = df_trans.groupby(df_trans.Date.dt.date)['TransactionAmt'].count().reset_index()\ntrace = go.Scatter(x=tmp_trans_fraud['Date'], y = tmp_trans_fraud.TransactionAmt, opacity = 0.8, line=dict(color=color_op[1]), name = 'Fraud Transaction')\n\ntrace1 = go.Scatter(x=tmp_amt_fraud.Date, line = dict(color = color_op[7]), name=\"Fraud Amount\",y=tmp_amt_fraud['TransactionAmt'], opacity = 0.8, yaxis='y2')\n\n\nlayout = dict(\n    title= \"FRAUD TRANSACTIONS - Total Transactions and Fraud Informations by Date\",\n    xaxis=dict(\n        rangeselector=dict(\n            buttons=list([\n                dict(count=1, label='1m', step='month', stepmode='backward'),\n                dict(count=3, label='3m', step='month', stepmode='backward'),\n                dict(count=6, label='6m', step='month', stepmode='backward'),\n                dict(step='all')\n            ])\n        ),\n        rangeslider=dict(visible = True),\n        type='date' ),\n    yaxis=dict(title='Total Transactions'),\n    yaxis2=dict(overlaying='y',\n                anchor='x', side='right',\n                zeroline=False, showgrid=False,\n                title='Total Transaction Amount')\n)\n\n\nfig = dict(data = [trace,trace1], layout = layout)\niplot(fig)","708b79d4":"df_id[['id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18',\n       'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25',\n       'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32',\n       'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38']].describe(include='all')","2d54fb62":"df_train = df_trans.merge(df_id, how = 'left', left_index= True, right_index= True)","e279dad1":"def cat_feat_ploting(df, col):\n    tmp = pd.crosstab(df[col], df['isFraud'], normalize='index') * 100\n    tmp = tmp.reset_index()\n    tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\n    plt.figure(figsize=(14,10))\n    plt.suptitle(f'{col} Distributions', fontsize=22)\n\n    plt.subplot(221)\n    g = sns.countplot(x=col, data=df, order=tmp[col].values)\n    # plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\n\n    g.set_title(f\"{col} Distribution\", fontsize=19)\n    g.set_xlabel(f\"{col} Name\", fontsize=17)\n    g.set_ylabel(\"Count\", fontsize=17)\n    # g.set_ylim(0,500000)\n    for p in g.patches:\n        height = p.get_height()\n        g.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(height\/total*100),\n                ha=\"center\", fontsize=14) \n\n    plt.subplot(222)\n    g1 = sns.countplot(x=col, hue='isFraud', data=df, order=tmp[col].values)\n    plt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])\n    gt = g1.twinx()\n    gt = sns.pointplot(x=col, y='Fraud', data=tmp, color='black', order=tmp[col].values, legend=False)\n    gt.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n\n    g1.set_title(f\"{col} by Target(isFraud)\", fontsize=19)\n    g1.set_xlabel(f\"{col} Name\", fontsize=17)\n    g1.set_ylabel(\"Count\", fontsize=17)\n\n    plt.subplot(212)\n    g3 = sns.boxenplot(x=col, y='TransactionAmt', hue='isFraud', \n                       data=df[df['TransactionAmt'] <= 2000], order=tmp[col].values )\n    g3.set_title(\"Transaction Amount Distribuition by ProductCD and Target\", fontsize=20)\n    g3.set_xlabel(\"ProductCD Name\", fontsize=17)\n    g3.set_ylabel(\"Transaction Values\", fontsize=17)\n\n    plt.subplots_adjust(hspace = 0.4, top = 0.85)\n\n    plt.show()","d50ab415":"for col in ['id_12', 'id_15', 'id_16', 'id_23', 'id_27', 'id_28', 'id_29']:\n    df_train[col] = df_train[col].fillna('NaN')\n    cat_feat_ploting(df_train, col)","a618d504":"df_train.loc[df_train['id_30'].str.contains('Windos', na=False),'id_30'] = 'Windows'\ndf_train.loc[df_train['id_30'].str.contains('Windows', na=False), 'id_30'] = 'Windows'\ndf_train.loc[df_train['id_30'].str.contains('iOS', na=False), 'id_30'] = 'iOS'\ndf_train.loc[df_train['id_30'].str.contains('Mac OS', na=False), 'id_30'] = 'Mac'\ndf_train.loc[df_train['id_30'].str.contains('Android', na=False), 'id_30'] = 'Android'\ndf_train['id_30'].fillna(\"NAN\", inplace=True)","40fd5b61":"ploting_cnt_amt(df_train,'id_30')","9c6fc4d6":"df_train.loc[df_train['id_31'].str.contains('chrome', na=False), 'id_31'] = 'Chrome'\ndf_train.loc[df_train['id_31'].str.contains('firefox', na=False),'id_31'] = 'Firefox'\ndf_train.loc[df_train['id_31'].str.contains('safari', na=False), 'id_31'] = 'Safari'\ndf_train.loc[df_train['id_31'].str.contains('edge', na=False), 'id_31'] = 'Edge'\ndf_train.loc[df_train['id_31'].str.contains('ie', na=False), 'id_31'] = 'IE'\ndf_train.loc[df_train['id_31'].str.contains('samsung' , na=False), 'id_31'] = 'Samsung'\ndf_train.loc[df_train['id_31'].str.contains('opera', na=False),'id_31'] = 'Opera'\ndf_train['id_31'].fillna('NAN', inplace = True)\ndf_train.loc[df_train.id_31.isin(df_train.id_31.value_counts()[df_train.id_31.value_counts() < 200].index), 'id_31'] = \"Others\"","83f3193d":"ploting_cnt_amt(df_train, 'id_31')","0c31dbef":"df_trans = pd.read_csv('..\/input\/train_transaction.csv')\ndf_test_trans = pd.read_csv('..\/input\/test_transaction.csv')\n\ndf_id = pd.read_csv('..\/input\/train_identity.csv')\ndf_test_id = pd.read_csv('..\/input\/test_identity.csv')","63d3e33d":"sample_submission = pd.read_csv('..\/input\/sample_submission.csv', index_col='TransactionID')\n\ndf_train = df_trans.merge(df_id, how='left', left_index=True, right_index=True, on = 'TransactionID')\ndf_test = df_test_trans.merge(df_test_id, how='left', left_index = True, right_index = True, on = 'TransactionID')\n\nprint(df_train.shape)\nprint(df_test.shape)\n\ndel df_trans, df_id, df_test_trans, df_test_id","27e551a1":"df_train = reduce_mem_usage(df_train)\ndf_test = reduce_mem_usage(df_test)","1b429c29":"emails = {'gmail': 'google', 'att.net': 'att', 'twc.com': 'spectrum', \n          'scranton.edu': 'other', 'optonline.net': 'other', 'hotmail.co.uk': 'microsoft',\n          'comcast.net': 'other', 'yahoo.com.mx': 'yahoo', 'yahoo.fr': 'yahoo',\n          'yahoo.es': 'yahoo', 'charter.net': 'spectrum', 'live.com': 'microsoft', \n          'aim.com': 'aol', 'hotmail.de': 'microsoft', 'centurylink.net': 'centurylink',\n          'gmail.com': 'google', 'me.com': 'apple', 'earthlink.net': 'other', 'gmx.de': 'other',\n          'web.de': 'other', 'cfl.rr.com': 'other', 'hotmail.com': 'microsoft', \n          'protonmail.com': 'other', 'hotmail.fr': 'microsoft', 'windstream.net': 'other', \n          'outlook.es': 'microsoft', 'yahoo.co.jp': 'yahoo', 'yahoo.de': 'yahoo',\n          'servicios-ta.com': 'other', 'netzero.net': 'other', 'suddenlink.net': 'other',\n          'roadrunner.com': 'other', 'sc.rr.com': 'other', 'live.fr': 'microsoft',\n          'verizon.net': 'yahoo', 'msn.com': 'microsoft', 'q.com': 'centurylink', \n          'prodigy.net.mx': 'att', 'frontier.com': 'yahoo', 'anonymous.com': 'other', \n          'rocketmail.com': 'yahoo', 'sbcglobal.net': 'att', 'frontiernet.net': 'yahoo', \n          'ymail.com': 'yahoo', 'outlook.com': 'microsoft', 'mail.com': 'other', \n          'bellsouth.net': 'other', 'embarqmail.com': 'centurylink', 'cableone.net': 'other', \n          'hotmail.es': 'microsoft', 'mac.com': 'apple', 'yahoo.co.uk': 'yahoo', 'netzero.com': 'other', \n          'yahoo.com': 'yahoo', 'live.com.mx': 'microsoft', 'ptd.net': 'other', 'cox.net': 'other',\n          'aol.com': 'aol', 'juno.com': 'other', 'icloud.com': 'apple'}\n\nus_emails = ['gmail', 'net', 'edu']","af29c44f":"for c in ['P_emaildomain', 'R_emaildomain']:\n    df_train[c + '_bin'] = df_train[c].map(emails)\n    df_test[c + '_bin'] = df_test[c].map(emails)\n    \n    df_train[c + '_suffix'] = df_train[c].map(lambda x: str(x).split('.')[-1])\n    df_test[c + '_suffix'] = df_train[c + '_suffix'].map(lambda x: str(x).split('.')[-1])\n    \n    df_train[c + '_suffix'] = df_train[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')\n    df_test[c + '_suffix'] = df_test[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')","3f14bb83":"# Label Encoding\nfor f in df_train.drop('isFraud', axis=1).columns:\n    if df_train[f].dtype=='object' or df_test[f].dtype=='object': \n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(df_train[f].values) + list(df_test[f].values))\n        df_train[f] = lbl.transform(list(df_train[f].values))\n        df_test[f] = lbl.transform(list(df_test[f].values))   ","c73a5b83":"df_train['Trans_min_mean'] = df_train['TransactionAmt'] - df_train['TransactionAmt'].mean()\ndf_train['Trans_min_std'] = df_train['Trans_min_mean'] \/ df_train['TransactionAmt'].std()\n\ndf_test['Trans_min_mean'] = df_test['TransactionAmt'] - df_test['TransactionAmt'].mean()\ndf_test['Trans_min_std'] = df_test['Trans_min_mean'] \/ df_test['TransactionAmt'].std()","4e778aa5":"df_test['TransactionAmt_to_mean_card1'] = df_test['TransactionAmt'] \/ df_test.groupby(['card1'])['TransactionAmt'].transform('mean')\ndf_test['TransactionAmt_to_mean_card4'] = df_test['TransactionAmt'] \/ df_test.groupby(['card4'])['TransactionAmt'].transform('mean')\ndf_test['TransactionAmt_to_std_card1'] = df_test['TransactionAmt'] \/ df_test.groupby(['card1'])['TransactionAmt'].transform('std')\ndf_test['TransactionAmt_to_std_card4'] = df_test['TransactionAmt'] \/ df_test.groupby(['card4'])['TransactionAmt'].transform('std')","1f6f19a9":"df_train['TransactionAmt'] = np.log(df_train['TransactionAmt'])\ndf_test['TransactionAmt'] = np.log(df_test['TransactionAmt'])","152950e8":"df_test['isFraud'] = 'test'\ndf = pd.concat([df_train, df_test], axis = 0, sort = False)\ndf = df.reset_index()\ndf = df.drop('index', axis = 1)","c5f5bb64":"Cool and Very Meaningful information.\nIn Card3 we can see that 100 and 106 are the most common values in the column.\nWe have 4.95% of Frauds in 100 and 1.52% in 106; The values with highest Fraud Transactions are 185, 119 and 119;\n\nIn card5 the most frequent values are 226, 224, 166 that represents 73% of data, Also is possible to see high % of frauds in 137, 147, 141 that has\nfew entries for values.","238f6640":"### Id 31","368b385b":"## some feature engineering","08dce5e9":"# Card Features\n- Based on Competiotion Description, card features are categoricals\n- Lets understand the distribution of values\n- What's the different in transactions and % of Fraud for each values in these features\n- Card features has 6 columns, and 4 of them seems to be numericals, so lets see the quantiles and distributions","3885d6f4":"# reducing memory usage","4448b445":"# P emaildomain Distributions\n- i will group all e-mail domians by the respective enterprises.\n- Also, i will set as \"Others\" all values with less than 500 entries.","53782c24":"All data is Credit and Debit. We can see a high percentual of Frauds in Credit than Debit transactions.\nThe Distribution of Transaction Amount don't shows clear differences.","182e57ac":"# Seeing the Quantiles of Fraud and No Fraud Transactions","b7ce5b28":"Very cool! This graphs give us many interiesting intuition about the M features. Only in M4 the Missing values haven't the highest % of Fraud.","65fbd9fa":"# Ploting P-Email Domain","270bd5cc":"# Addr1 and Addr2","16d334b3":"# Now, let's known the Product Feature \n- Distribution Products\n- Distribution of Frauds by Product\n- Has Difference between Transaction Amounts in Products?","ce1da0e2":"## Mapping emails","ea07afe9":"Top 3 values are 1, 2 and 3 and is the same on Total Amounts. We see the same pattern on fraud ratios","aa1c051e":"# Exploring M1-M9 Features\n### M distributions : Count, %Fraud and Transaction Amount distribution","c48b4b3c":"- If we consider only values between >= 0 to 800 we will avoid the outliers and has more confidence in our distribution. \n- We have 10k rows with outliers that represents 1.74% of total rows.","ea6497aa":"i will set all values in Addr1 that has less than 5000 entries to \"Others\"\nIn Addr2 i will set as \"Others\" all values with less than 50 entries","07f383fe":"### Ploting columns with few unique value","34a08d8f":"- We can see that Card 1 and Card 2 has a large distribution of values, so maybe it will be better to get the log of these columns","9439a0c9":"# TimeDelta Feature\n- Let's see if the frauds have some specific hour that has highest % of frauds\n\n## Converting to Total Days, Weekdays and Hours\n- In discussion tab I read an excellent solution to Timedelta column, I will set the link below;\n- We will use the first date as 2017-12-01 and use the delta time to compute datetime features","ee111761":"- Card2 - Card6 has some missing values, We will need to due with it later","94f70a82":"# Transactions and Total Amount by each day","1c087706":"# Features [id_12 to id_38]\n- categorical features in training identity dataset","9c9aea4a":"# R-Email Domain plot distribution\n- i will group all e-mail domains by the respective enterprises.\n- i will set as \"Others\" all values with less than 300 entries.","ac5d24e6":"# Visualizing Card 1, Card 2, and Card 3 Distributions\n- As the Card 1 and 2 are numericals, i will plot the distribution of them\n- in Card 3, as we have many values with low frequencies, i decided to set value to 'Others'\n- Also, in Card 3 i set the % of Fraud ratio in yaxis2","5e9ed04b":"- W, C and R are the most frequent values,\n- We can note that in W, H and R the distribution of Fraud values are slightly higher than the Non-Fraud Transactions","78dfd261":"# Card6 - Categorical","7b555146":"# Target Distribution","515750b8":"# Card4 - Categorical","067cf320":"# Set function","d6d20b86":"## Modelling","90b28ba3":"# IEEE EDA process","c68901e4":"# Ploting Transaction Amount Values Distribution","a38dd233":"## Concating dfs to get PCA of V features","d1e7ae85":"- We can see that 97% of our data are in Mastercard(32%) and Visa(65%);\n  we have a highest value in discover(~8%) against ~3.5% of Mastercard and Visa and 2.87% in American Express","bc18850f":"We can see a very similar distribution in both email domain features.\nIt's interesting that we have high values in google and icloud frauds","4f732852":"# Transaction Amount Quantiles\n- Before Ploting the Transaction Amount, let's see the quantiles of Transaction Amount\n\n- quantile() -> \uadf8\ub8f9\ub0b4 \ubd84\uc704\uc218\ub97c \uad6c\ud568","c367be03":"# Numericals Feature Card Quantiles","a3707058":"## Encoding categorical features","cc1f5589":"# C1 - C14 features\n- Let's understand what this features are.\n- What's the distributions?"}}