{"cell_type":{"6cca4496":"code","79a3929f":"code","f7e7a674":"code","819240bd":"code","3e52b673":"code","38dce50f":"code","9baf936c":"code","edcd3b77":"code","3ac80a5f":"code","accc1803":"code","23dfb98d":"code","20774d91":"markdown","920a5204":"markdown","85765ac8":"markdown","9edd0fa0":"markdown","a65ad441":"markdown","4a99aa81":"markdown"},"source":{"6cca4496":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","79a3929f":"%%bash -e\nif ! [[ -f .\/spm_train ]]; then\n  wget https:\/\/github.com\/google\/sentencepiece\/archive\/v0.1.8.zip\n  echo '8799f4983608897e8eb3370385eda149180d309c7276db939f955d6507d53846  v0.1.8.zip' | sha256sum -c\n  unzip v0.1.8.zip\n  conda install -y cmake pkg-config\n  export SENTENCEPIECE_HOME=$(pwd)\/sentencepiece\n  export PKG_CONFIG_PATH=${SENTENCEPIECE_HOME}\/lib\/pkgconfig\n  (cd sentencepiece-0.1.8 && mkdir -p build)\n  (cd sentencepiece-0.1.8\/build && cmake -DCMAKE_INSTALL_PREFIX=${SENTENCEPIECE_HOME} ..  && make -j4 && make install)\n  (cd sentencepiece-0.1.8\/python && python setup.py install)\n  rm -rf sentencepiece-0.1.8 v0.1.8.zip\nfi","f7e7a674":"def read_train_text(filename='..\/input\/train.csv'):\n    return pd.read_csv(filename)\n\ndef write_cipher_text(texts, filename='spm_train.txt'):\n    with open(filename, 'w',encoding='utf-8') as f:\n        for text in texts:\n            f.write(text + \"\\n\")\n\ntrain_df = read_train_text()\ntest_df = read_train_text(filename='..\/input\/test.csv')\nciphertexts = list(train_df.ciphertext.values) + list(test_df.ciphertext.values)\nwrite_cipher_text(ciphertexts)","819240bd":"import sentencepiece as spm\nspm.SentencePieceTrainer.Train(\n        '--input=' + os.path.join('spm_train.txt') +\n        ' --model_prefix=train --vocab_size=1000')","3e52b673":"def encode_ciphertext(ciphertext):\n    sp = spm.SentencePieceProcessor()\n    sp.Load('train.model')\n    encodedtext = []\n    for text in ciphertext:\n        encodedtext.append(sp.encode_as_ids(text))\n    return encodedtext\n\ntrain_encoded = encode_ciphertext(train_df.ciphertext)\ntest_encoded = encode_ciphertext(test_df.ciphertext)","38dce50f":"from collections import defaultdict, Counter\n\nword_counter = defaultdict(int)\nfor text in train_encoded + test_encoded:\n    counter = Counter(text)\n    for l,c in counter.items():\n        word_counter[l] += c","9baf936c":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split","edcd3b77":"def build_df(word_counter, df, encodedtext):\n    keys = list(word_counter.keys())    \n    rows = []\n    for rowid, row in df.iterrows():\n        counter = Counter(encodedtext[rowid])\n        entry = [counter.get(k, 0) for k in keys]\n        entry += [row['difficulty']]\n        if 'target' in row:\n            entry += [row['target']]\n        rows.append(entry)\n    return pd.DataFrame(rows)\n\ntrain = build_df(word_counter, train_df, train_encoded)\ntest = build_df(word_counter, test_df, test_encoded)","3ac80a5f":"X = train.iloc[:, :-1]\nY = train.iloc[:, -1]\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)","accc1803":"rf = RandomForestClassifier(n_estimators=1000, n_jobs=-1)\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)\nacc = np.sum(y_pred == y_test) \/ len(y_test)\nprint(acc)","23dfb98d":"rf.fit(X, Y)\ny_pred = rf.predict(test)\nsubmission = pd.DataFrame(test_df.Id, columns=['Id'])\nsubmission['Predicted'] = y_pred\nsubmission.to_csv('submission.csv', index=False)","20774d91":"# Prepare input","920a5204":"# build sentencepiece\n\nNote: Internet must be enabled in kernel environment's settings for this step.\n\nDownload sentencepiece's source code and build the package.","85765ac8":"This notebook shows how to build and run Google sentencepiece package and tokenize the encoded text.","9edd0fa0":"# Train SentencePieceModel","a65ad441":"# Make submission","4a99aa81":"# Train Random Forest Model"}}