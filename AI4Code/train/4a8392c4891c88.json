{"cell_type":{"d2811ff0":"code","2714313d":"code","94850a16":"code","5a48b602":"code","1139b96c":"code","b0f546a1":"code","f6c988a7":"code","4c2f91ed":"code","3c378103":"code","ea2801b7":"code","d3a475bc":"code","354789d9":"code","c8212217":"code","34819c2a":"code","d929ea5e":"code","b3f9946e":"code","70b5a8df":"code","97f5095f":"code","f3da7d3c":"code","df576467":"markdown","213c55f7":"markdown","826919c1":"markdown","315e01de":"markdown","1be8ebb3":"markdown","918ea3e1":"markdown","b8270971":"markdown","ab1523c5":"markdown","3951d27a":"markdown","e83f5fd7":"markdown","12c1cc47":"markdown","f7460d0e":"markdown","176f62a4":"markdown","b14becaa":"markdown","347fa20c":"markdown","2084be9c":"markdown","7afa78fe":"markdown","81daa11d":"markdown"},"source":{"d2811ff0":"# Data Manipulation, Linear Algebra\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\n# Plots\r\nimport matplotlib.pyplot as plt\r\nimport seaborn as sns\r\nsns.set(style=\"darkgrid\", font_scale=1.5)\r\n\r\n# Machine Learning\r\nfrom sklearn.preprocessing import StandardScaler\r\nfrom sklearn.decomposition import PCA\r\n\r\nfrom sklearn.cluster import KMeans","2714313d":"data = pd.read_csv(\"..\/input\/wine-dataset-for-clustering\/wine-clustering.csv\")\r\ndata.head()","94850a16":"data.info()","5a48b602":"data.isnull().sum()","1139b96c":"data.describe()","b0f546a1":"plt.rcParams[\"figure.figsize\"] = (20, 20)\r\ndata.hist(bins=20)\r\nplt.show()","f6c988a7":"sns.pairplot(data)\r\nplt.show()","4c2f91ed":"plt.rcParams[\"figure.dpi\"] = 80\r\nplt.rcParams[\"figure.figsize\"] = (15, 10)\r\nsns.heatmap(data.corr())\r\nplt.title(\"Corelation Heatmap\")\r\nplt.show()","3c378103":"sc = StandardScaler()\r\nscaled_data = data.copy()\r\nscaled_data = sc.fit_transform(scaled_data)\r\ndata","ea2801b7":"# Reducing the Number of Features in the Dataset using PCA\r\npca = PCA(2)\r\npca_data = pca.fit_transform(data)","d3a475bc":"plt.rcParams[\"figure.figsize\"] = (12, 8)\r\nplt.rcParams[\"figure.dpi\"] = 80\r\nplt.scatter(x=pca_data[:,0], y=pca_data[:,1], lw=2)\r\nplt.xlabel(\"Principle Component 1\")\r\nplt.ylabel(\"Principle Component 2\")\r\nplt.title(\"Principle Components Analysis\")\r\nplt.show()","354789d9":"wcss = []\r\n\r\nfor i in range(1, 11):\r\n    kmeans = KMeans(\r\n        n_clusters = i,\r\n        init = 'k-means++',\r\n        random_state=42\r\n    )\r\n    kmeans.fit(data)\r\n    wcss.append([i, kmeans.inertia_]) # kmeans.inertial_ returns the calculated WCSS Values\r\n    \r\nwcss_dataframe = pd.DataFrame(wcss, columns=[\"clusters\", \"wcss value\"])\r\n\r\n# Plot for Elbow Method\r\nplt.rcParams[\"figure.figsize\"] = (12, 8)\r\nplt.rcParams[\"figure.dpi\"] = 80\r\nsns.lineplot(\r\n    x = wcss_dataframe.clusters.values,\r\n    y = wcss_dataframe[\"wcss value\"], marker=\"o\")\r\nplt.xticks(np.arange(1, 11))\r\nplt.xlabel(\"Clusters\")\r\nplt.ylabel(\"Wcss Values\")\r\nplt.title(\"Elbow Method Plot\")\r\nplt.show()","c8212217":"kmeans = KMeans(n_clusters = 3, init = 'k-means++', random_state = 42)\r\ny_kmeans = pd.Series(kmeans.fit_predict(data))\r\ny_kmeans","34819c2a":"y_kmeans.value_counts()","d929ea5e":"centroids = kmeans.cluster_centers_\r\ncentroids_pca = pca.transform(centroids)","b3f9946e":"pca_dataframe = pd.DataFrame(pca_data, columns=[\"PCA 1\", \"PCA 2\"])\r\npca_dataframe[\"Cluster\"] = y_kmeans\r\npca_dataframe.sample(10)","70b5a8df":"plt.rcParams[\"figure.figsize\"] = (12, 8)\r\nplt.rcParams[\"figure.dpi\"] = 80\r\nsns.scatterplot(x=\"PCA 1\", y=\"PCA 2\", hue=\"Cluster\", data=pca_dataframe, palette=['green','orange','brown'], s=100)\r\nplt.scatter(x=centroids_pca[:, 0], y=centroids_pca[:, 1], marker=\"+\", s=500, linewidths=3, lw=4, color=\"blue\", zorder=10)\r\nplt.title(\"Visualizing Clusters\")\r\nplt.show()","97f5095f":"data[\"Cluster\"] = y_kmeans\r\ndata.head()","f3da7d3c":"sns.pairplot(data, hue=\"Cluster\", palette=['green','orange','brown'])\r\nplt.show()","df576467":"## Feature Scaling using StandardScaler","213c55f7":"### From Elbow Method it is Clear that we have 3 Clusters","826919c1":"# KMeans Model","315e01de":"## Centeroids","1be8ebb3":"# Visualizing Clusters","918ea3e1":"## Simple Distribution Plots for all Features","b8270971":"## Pair Plot to Compare All Variables","ab1523c5":"# Importing Libraries","3951d27a":"## Loading Data and Preprocessing","e83f5fd7":"### It can be Observed and Predicted from the above plot that the data has 3 clusters","12c1cc47":"## Using Elbow Method to Find Appropriate number of clusters","f7460d0e":"## Checking for Null Values in the Dataset","176f62a4":"# EDA and Statistical Analysis","b14becaa":"# Preparing Data","347fa20c":"## Generating Our Dependent Variable using Kmeans","2084be9c":"## Applying Principal Compnent Analysis","7afa78fe":"### Great! We Dont have any Null values","81daa11d":"## Heat Map to Check for Corelation between Features"}}