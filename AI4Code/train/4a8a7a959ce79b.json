{"cell_type":{"e9f62765":"code","82d05d35":"code","491a9360":"code","7b0ff232":"code","c2edc9d2":"code","d472eb6d":"code","2e3eb074":"code","6b25739d":"code","550a4714":"code","434cd7ac":"code","70dd9c82":"code","0a1b343e":"code","4f5f8876":"code","b02efd24":"code","3d43fd97":"code","f79861cb":"code","d85ec113":"code","3435bd52":"code","787f7fad":"code","06bcfaf0":"code","bc23aa52":"code","ded6da31":"code","389af4ac":"code","423884ac":"code","1c5b6bec":"code","13c721ec":"code","bb4692c0":"code","c038bb62":"code","b5a8a364":"code","bd65f1b3":"code","e47043b9":"code","aa4b6849":"code","72f18423":"code","245af3a4":"code","95ec945b":"code","af37c742":"code","7d27a347":"code","bcaa99f8":"code","202bcea4":"code","d491c7be":"code","93ae2289":"code","abc783fa":"code","a710ae24":"code","c08a053a":"code","17dcf5f6":"code","3f819963":"code","a4af69d1":"code","bce768b2":"code","a1a0f1d7":"code","ae48817c":"code","a9e29424":"code","f3c94021":"code","ad195590":"code","3982d4c2":"code","4ff1731c":"code","e85f09ba":"code","a065313f":"code","bd34da35":"code","7493e4b8":"code","ac904ecf":"code","bd143936":"code","1a07fc7f":"code","e72a076a":"code","503b472b":"code","f9d43e1d":"code","7be8c0d0":"code","1278285b":"code","c28bb2a7":"code","6307ff02":"code","e499bd55":"code","aa7e2a8d":"code","c2691cf1":"code","c856bb51":"code","355d8385":"code","32e6f3e2":"code","9517e92f":"code","1889b633":"code","d677b02d":"code","1d1ac48b":"code","b6507afd":"code","50a982ea":"code","b8b4949e":"code","2f32184a":"code","2ca8053b":"code","ac67dcd8":"code","671b6a1a":"code","15f85f9b":"code","932a8b69":"code","f733d859":"code","14e52a7b":"code","f97dbc31":"code","fe7e6dd1":"code","1d333ad8":"code","da0123b7":"code","4c9ca1db":"code","3fbac5e7":"code","2965670a":"code","a674df7d":"code","8261d72d":"code","8e4a3584":"code","73b16809":"code","7e1d32dc":"code","2813fdd3":"code","be3d9e0a":"code","64fe1f4b":"code","95d191bb":"code","90e6776d":"code","9749f726":"code","7920db17":"code","d6d7ddf7":"code","ffc95df3":"code","0efa8609":"code","88659d47":"code","2bcae1c3":"code","1a815daa":"code","7d9b828e":"code","7c126f85":"code","d3868d18":"code","6f6918c0":"code","699fc156":"code","69584357":"code","7c8ff11b":"code","a4cf8772":"code","7e729d30":"code","48d08b72":"code","77a77267":"code","c247ffa3":"code","e04f8f92":"code","66ccbdfc":"code","826c67c4":"markdown","8b1d8bbd":"markdown","9fbf5041":"markdown","1bca76c0":"markdown","f8b213de":"markdown","8d4fa70d":"markdown","3396e190":"markdown","5fa22632":"markdown","c5d688ec":"markdown","57dc6576":"markdown","48d4fa8d":"markdown","ae4fabc7":"markdown","10545aeb":"markdown","72b8f075":"markdown","a670578c":"markdown","25e63897":"markdown","573c9c9f":"markdown","8c1e2275":"markdown","98e03fac":"markdown","4ba5db90":"markdown","c9004a54":"markdown","e39db4d7":"markdown","bac5828a":"markdown","782ab784":"markdown","7380442d":"markdown","2d38d000":"markdown","937f3681":"markdown","60476dc4":"markdown","36c18da9":"markdown","b28e3dda":"markdown","c68a6709":"markdown","5694465e":"markdown","d7393c65":"markdown","43c23602":"markdown","3e9b6ab7":"markdown","8923bcc2":"markdown","c3cfe359":"markdown","d6165cab":"markdown","acf02fb2":"markdown","c8c38e7f":"markdown","bd46447c":"markdown","6725828a":"markdown","9da227bb":"markdown","6ab15702":"markdown","b8a9899f":"markdown","995d9efc":"markdown","5201c410":"markdown","d7c406fb":"markdown","5d22856a":"markdown","2f858d62":"markdown","07180543":"markdown","f06b5245":"markdown","b0176086":"markdown","e9c93797":"markdown","77b81f44":"markdown","c825c8d4":"markdown","1b77f467":"markdown","134b5665":"markdown","dbde402a":"markdown","2638ccfa":"markdown","0fc1f64e":"markdown","b5ed20b2":"markdown","cfa8d277":"markdown","5074bd1a":"markdown","baca6c05":"markdown","7071cd07":"markdown","edc92bb5":"markdown","0a9ffa3f":"markdown","cbcaa18c":"markdown","46d043fa":"markdown","5bb07893":"markdown","cd56bc59":"markdown","c91c7a24":"markdown","8c4e2e09":"markdown","91032dc0":"markdown","1816e768":"markdown","fe19269b":"markdown","f5c7929d":"markdown","d0479314":"markdown","800f3b90":"markdown","4cfe15fa":"markdown","5b86fe00":"markdown","32a81e44":"markdown","e6a281d7":"markdown","5c8a6c7f":"markdown","355d3c97":"markdown","7330c2a1":"markdown","e114c9f1":"markdown","3d0a4c0d":"markdown","009e1f3a":"markdown","278df110":"markdown","6b6d8b80":"markdown","155a7ced":"markdown","c9bb5df4":"markdown","77a1c91b":"markdown","424c016c":"markdown","339a0cb8":"markdown","5d91865f":"markdown","59ede3ac":"markdown","64fdec8d":"markdown","6eb0d522":"markdown","edfa31e6":"markdown","5d34e26b":"markdown","d94e8754":"markdown","417f70c4":"markdown","d419cc62":"markdown","0406e577":"markdown","993d9e1c":"markdown","73273a1c":"markdown","f71e8fad":"markdown","702470fd":"markdown"},"source":{"e9f62765":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn-whitegrid\")   #we use whitegrid style in matplotlib library, it makes white background with grid whenever we execute matplotlib\n\nimport seaborn as sns\n\nfrom collections import Counter    #this helps us to count how many values we have in lists\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")    #this is how we dont see warnings, but we can see errors\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","82d05d35":"#an example to see how Counter works\na = [1,1,1,2,2,3,3,4,4,4,4,5,5,0]\nCounter(a)","491a9360":"#here is our datas\ntrain_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_PassengerId = test_df[\"PassengerId\"]\ntrain_df_len = len(train_df[\"Survived\"]) #891","7b0ff232":"Counter(train_df[\"Sex\"])","c2edc9d2":"#here is our main columns\ntrain_df.columns","d472eb6d":"#here is our first 5 datas\ntrain_df.head()","2e3eb074":"#here we have our datas statisctical values\ntrain_df.describe()","6b25739d":"#here we see our datas types\ntrain_df.info()","550a4714":"#by using value_counts we can counts values from dictionary types, for list type we use Counter\n#index of value_counts shows male, female; values of value_counts show 577, 314\ntrain_df[\"Sex\"].value_counts()","434cd7ac":"train_df[\"Sex\"]","70dd9c82":"def bar_plot(variable):\n    \n    #get feature\n    var = train_df[variable]\n    \n    #count number of categorical variable\n    varValue = var.value_counts()\n    \n    #lets visualize\n    plt.figure(figsize = (9,3))\n    plt.bar(varValue.index, varValue.values)  #index of value_counts shows male, female; values of value_counts show 577, 314\n    plt.xticks(varValue.index)\n    plt.ylabel(\"Frequency\")\n    plt.title(variable)\n    plt.show()\n    print(\"{}: \\n{}\".format(variable, varValue))","0a1b343e":"category1 = [\"Survived\",\"Sex\",\"Pclass\",\"Embarked\",\"SibSp\", \"Parch\"]\nfor c in category1:\n    bar_plot(c)","4f5f8876":"#these are values no need to show in figures\ncategory2 = [\"Cabin\", \"Name\", \"Ticket\"]\nfor c in category2:\n    print(\"{} \\n\".format(train_df[c].value_counts()))","b02efd24":"#now we will make a function to have histogram graph of our numerical variables\n\ndef hist_plot(variable):\n    \n    var = train_df[variable]\n    \n    plt.figure(figsize = (9,3))\n    plt.hist(var, bins = 50)  \n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"{} distribution with hist\".format(variable))\n    plt.show()\n    print(\"{}: \\n{}\".format(variable, var.value_counts()))","3d43fd97":"#no need to visualize passengerId but lets see it too and also we have 891 passengers, if we make bins = 891, we will see a straight graph in passengerId graph\nnumericVar = [\"Fare\", \"Age\",\"PassengerId\"]\nfor n in numericVar:\n    hist_plot(n)","f79861cb":"#Pclass - Survived, we are looking for mean values of survived people with respect to Pclass\ntrain_df[[\"Pclass\", \"Survived\"]].groupby([\"Pclass\"]).mean()","d85ec113":"#we can see also indexes\nPclass_survived = train_df[[\"Pclass\", \"Survived\"]].groupby([\"Pclass\"], as_index = False).mean()\nPclass_survived","3435bd52":"Pclass_survived = train_df[[\"Pclass\", \"Survived\"]].groupby([\"Pclass\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)\nPclass_survived[\"Pclass\"]","787f7fad":"plt.figure(figsize = (9,3))\nplt.bar(Pclass_survived[\"Pclass\"], Pclass_survived[\"Survived\"])\nplt.xticks(Pclass_survived[\"Pclass\"])\nplt.ylabel(\"Frequency\")\nplt.title(\"Survived people with respect to Pclass\")\nplt.show()\nprint(\"{}: \\n{}\".format(Pclass_survived[\"Pclass\"], Pclass_survived[\"Survived\"]))","06bcfaf0":"Sex_survived = train_df[[\"Sex\", \"Survived\"]].groupby([\"Sex\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)\nSex_survived","bc23aa52":"plt.figure(figsize = (9,3))\nplt.bar(Sex_survived[\"Sex\"], Sex_survived[\"Survived\"])\nplt.xticks(Sex_survived[\"Sex\"])\nplt.ylabel(\"Frequency\")\nplt.title(\"Survived people with respect to their gender\")\nplt.show()\nprint(\"{}: \\n{}\".format(Sex_survived[\"Sex\"], Sex_survived[\"Survived\"]))","ded6da31":"SibSp_survived = train_df[[\"SibSp\", \"Survived\"]].groupby([\"SibSp\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)\nSibSp_survived","389af4ac":"plt.figure(figsize = (9,3))\nplt.bar(SibSp_survived[\"SibSp\"], SibSp_survived[\"Survived\"])\nplt.xticks(SibSp_survived[\"SibSp\"])\nplt.ylabel(\"Frequency\")\nplt.title(\"Survived people with respect to their sibblings-spouses\")\nplt.show()\nprint(\"{}: \\n{}\".format(SibSp_survived[\"SibSp\"], SibSp_survived[\"Survived\"]))","423884ac":"Embarked_survived = train_df[[\"Embarked\", \"Survived\"]].groupby([\"Embarked\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)\nEmbarked_survived","1c5b6bec":"plt.figure(figsize = (9,3))\nplt.bar(Embarked_survived[\"Embarked\"], Embarked_survived[\"Survived\"])\nplt.xticks(Embarked_survived[\"Embarked\"])\nplt.ylabel(\"Frequency\")\nplt.title(\"Survived people with respect to their embarked place\")\nplt.show()\nprint(\"{}: \\n{}\".format(Embarked_survived[\"Embarked\"], Embarked_survived[\"Survived\"]))","13c721ec":"train_df[\"Embarked\"].value_counts()","bb4692c0":"train_df[\"Pclass\"].value_counts()","c038bb62":"Embarked_Pclass_S = train_df[train_df['Embarked'] == \"S\"].loc[:,:]\nEmbarked_Pclass_S","b5a8a364":"Embarked_Pclass_S[\"Pclass\"].value_counts()","bd65f1b3":"Embarked_Pclass_C = train_df[train_df['Embarked'] == \"C\"].loc[:,:]\nEmbarked_Pclass_C","e47043b9":"Embarked_Pclass_C[\"Pclass\"].value_counts()","aa4b6849":"Embarked_Pclass_Q = train_df[train_df['Embarked'] == \"Q\"].loc[:,:]\nEmbarked_Pclass_Q","72f18423":"Embarked_Pclass_Q[\"Pclass\"].value_counts()","245af3a4":"Embarked_survived = train_df[[\"Embarked\", \"Survived\"]].groupby([\"Embarked\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)\nEmbarked_survived ","95ec945b":"Parch_survived = train_df[[\"Parch\", \"Survived\"]].groupby([\"Parch\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)\nParch_survived","af37c742":"plt.figure(figsize = (9,3))\nplt.bar(Parch_survived[\"Parch\"], Parch_survived[\"Survived\"])\nplt.xticks(Parch_survived[\"Parch\"])\nplt.ylabel(\"Frequency\")\nplt.title(\"Survived people with respect to their parents-children\")\nplt.show()\nprint(\"{}: \\n{}\".format(Parch_survived[\"Parch\"], Parch_survived[\"Survived\"]))","7d27a347":"Embarked_Fare = train_df[[\"Embarked\", \"Fare\"]].groupby([\"Embarked\"], as_index = False).mean().sort_values(by = \"Fare\", ascending = False)\nEmbarked_Fare ","bcaa99f8":"plt.figure(figsize = (9,3))\nplt.bar(Embarked_Fare[\"Embarked\"], Embarked_Fare[\"Fare\"])\nplt.xticks(Embarked_Fare[\"Embarked\"])\nplt.ylabel(\"Frequency\")\nplt.title(\"Fare paid with respect to embarked place\")\nplt.show()\nprint(\"{}: \\n{}\".format(Embarked_Fare[\"Embarked\"], Embarked_Fare[\"Fare\"]))","202bcea4":"Pclass_Fare = train_df[[\"Pclass\", \"Fare\"]].groupby([\"Pclass\"], as_index = False).mean().sort_values(by = \"Fare\", ascending = False)\nPclass_Fare ","d491c7be":"plt.figure(figsize = (9,3))\nplt.bar(Pclass_Fare[\"Pclass\"], Pclass_Fare[\"Fare\"])\nplt.xticks(Pclass_Fare[\"Pclass\"])\nplt.ylabel(\"Frequency\")\nplt.title(\"Fare paid with respect to Pclass\")\nplt.show()\nprint(\"{}: \\n{}\".format(Pclass_Fare[\"Pclass\"], Pclass_Fare[\"Fare\"]))","93ae2289":"plt.figure(figsize = (9,3))\nplt.boxplot(train_df[\"Fare\"])\nplt.xlabel(\"Fare\")\nplt.ylabel(\"Frequency\")\nplt.show()","abc783fa":"def detect_outliers(df,features):\n    outlier_indices = []\n    \n    for c in features:\n        # 1st quartile\n        Q1 = np.percentile(df[c],25)\n        # 3rd quartile\n        Q3 = np.percentile(df[c],75)\n        # IQR\n        IQR = Q3 - Q1\n        # Outlier step\n        outlier_step = IQR * 1.5\n        # detect outlier and their indeces\n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n        # store indeces\n        outlier_indices.extend(outlier_list_col)\n    \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n    \n    return multiple_outliers","a710ae24":"train_df.loc[detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])]","c08a053a":"# drop outliers\ntrain_df = train_df.drop(detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"]),axis = 0).reset_index(drop = True)","17dcf5f6":"filtered_data = train_df[(train_df[\"Age\"] < 20) & (train_df[\"Sex\"] == \"female\")]\nfiltered_data","3f819963":"train_df = pd.concat([train_df, test_df], axis = 0).reset_index(drop = True)\ntrain_df","a4af69d1":"train_df.head()","bce768b2":"#in here we are finding which main columns have null values\ntrain_df.columns[train_df.isnull().any()]","a1a0f1d7":"#now we will see how many null values we have\ntrain_df.isnull().sum()","ae48817c":"#now we are finding null values of embarked datas\ntrain_df[train_df[\"Embarked\"].isnull()]","a9e29424":"train_df.boxplot(column=\"Fare\",by = \"Embarked\")\nplt.show()","f3c94021":"train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"C\")\ntrain_df.isnull().sum()","ad195590":"train_df[train_df[\"Fare\"].isnull()]","3982d4c2":"train_df[train_df[\"Pclass\"] == 3][\"Fare\"].mean()","4ff1731c":"#we can use fillna or as we write our codes below\n#train_df[\"Fare\"] = train_df[\"Fare\"].fillna(12.63)\ntrain_df[\"Fare\"] = train_df[\"Fare\"].fillna(train_df[train_df[\"Pclass\"] == 3][\"Fare\"].mean())\ntrain_df.isnull().sum()","e85f09ba":"#linewidth is the line width between columns and rows, annot shows the numbers on graphic, fmt show value after comma\n#we can't visualize object type values with heatmap\nlist1 = [\"SibSp\", \"Parch\", \"Age\", \"Fare\", \"Pclass\", \"Survived\"]\nsns.heatmap(train_df[list1].corr(), annot = True, linewidth = 3, fmt = \".2f\")  #we could write train_df.corr() too but we want to visualize only datas we want.\nplt.show()","a065313f":"#in here hue is divided by Sex of passengers, we dont need to use it, size means graphic size\ng = sns.factorplot(x = \"SibSp\", y = \"Survived\", hue = \"Sex\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","bd34da35":"#lets see the difference\n#the lines over graphs means standart devitation, for example for 1 value, values can change between like 0.46-0.6, for 2 value values distance gets more. \n#graphic bars shows us the mean values. If standart deviation is so high, its not a graphic we want to see. We want our values gets close to mean value for healthy calculation.\ng = sns.factorplot(x = \"SibSp\", y = \"Survived\", data = train_df, kind = \"bar\", size = 5)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","7493e4b8":"g = sns.factorplot(x = \"Parch\", y = \"Survived\", data = train_df, kind = \"bar\", size = 5)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","ac904ecf":"g = sns.factorplot(x = \"Pclass\", y = \"Survived\", data = train_df, kind = \"bar\", size = 5)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","bd143936":"g = sns.FacetGrid(train_df, col = \"Survived\")\ng.map(sns.distplot, \"Age\", bins = 25)\nplt.show()","1a07fc7f":"g = sns.FacetGrid(train_df, col = \"Survived\", row = \"Pclass\", size = 2)\ng.map(plt.hist, \"Age\", bins = 25)\ng.add_legend()\nplt.show()","e72a076a":"g = sns.FacetGrid(train_df, row = \"Embarked\", size = 2)\ng.map(sns.pointplot, \"Pclass\",\"Survived\",\"Sex\")\ng.add_legend()\nplt.show()","503b472b":"g = sns.FacetGrid(train_df, row = \"Embarked\", col = \"Survived\", size = 2.3)\ng.map(sns.barplot, \"Sex\", \"Fare\")\ng.add_legend()\nplt.show()","f9d43e1d":"train_df.isnull().sum()","7be8c0d0":"train_df[\"Age\"].isnull()","1278285b":"train_df[\"Age\"][train_df[\"Age\"].isnull()]","c28bb2a7":"#NOW LETS LOOK FOR SEX OF PASSENGERS AND CONNECTION WITH AGE\nsns.factorplot(x = \"Sex\", y = \"Age\", data = train_df, kind = \"box\")\nplt.show()","6307ff02":"#now lets look for Pclass value for age, we can use hue=sex for seeing all too\nsns.factorplot(x = \"Pclass\", y = \"Age\", hue = \"Sex\", data = train_df, kind = \"box\")\nplt.show()","e499bd55":"#now lets look for SibSp and Parch value for age\nsns.factorplot(x = \"SibSp\", y = \"Age\", data = train_df, kind = \"box\")\nsns.factorplot(x = \"Parch\", y = \"Age\", data = train_df, kind = \"box\")\nplt.show()","aa7e2a8d":"#first we have to change type of Sex value because its string, heatmap not working with string values\ntrain_df[\"Sex\"] = [1 if each == \"male\" else 0 for each in train_df[\"Sex\"]]\ntrain_df[\"Sex\"]","c2691cf1":"list1 = [\"Age\", \"Sex\", \"Parch\", \"SibSp\", \"Pclass\"]\nsns.heatmap(train_df[list1].corr(), annot = True)\nplt.show()","c856bb51":"#we took the nan values' indexes\nindex_nan_age = list(train_df[\"Age\"][train_df[\"Age\"].isnull()].index)\nindex_nan_age","355d8385":"#in here we took median of Sibsp, Parch and Pclass value for the index_nan_age and if there is no NaN value of age_prediction we equal it with train_df[\"Age\"], else\n#we use Age data median value\nfor i in index_nan_age:\n    age_prediction = train_df[\"Age\"][((train_df[\"SibSp\"] == train_df.iloc[i][\"SibSp\"]) & (train_df[\"Parch\"] == train_df.iloc[i][\"Parch\"]) & (train_df[\"Pclass\"] == train_df.iloc[i][\"Pclass\"]))].median()\n    age_median = train_df[\"Age\"].median()\n    \n    if not np.isnan(age_prediction):\n        train_df[\"Age\"].iloc[i] = age_prediction\n    else:\n        train_df[\"Age\"].iloc[i] = age_median\n        \ntrain_df[\"Age\"].isnull().sum()","32e6f3e2":"train_df[\"Age\"][5]","9517e92f":"train_df[\"Age\"][17]","1889b633":"train_df.head(10)","d677b02d":"train_df[\"Name\"].head(10)","1d1ac48b":"train_df[\"Name\"][0]","b6507afd":"train_df[\"Name\"][0].split(\".\")[0]","50a982ea":"train_df[\"Name\"][0].split(\".\")[0].split(\",\")[1]","b8b4949e":"train_df[\"Name\"][0].split(\".\")[0].split(\",\")[1].strip()","2f32184a":"train_df[\"Title\"] = [i.split(\".\")[0].split(\",\")[1].strip() for i in train_df[\"Name\"]]\ntrain_df[\"Title\"].head(10)","2ca8053b":"#now lets visualize how many title values we have\nsns.countplot(x = \"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","ac67dcd8":"train_df[\"Title\"] = train_df[\"Title\"].replace([\"Don\", \"Rev\", \"Dr\", \"Major\", \"Lady\", \"Sir\", \"Col\", \"Capt\", \"the Countess\", \"Jonkheer\", \"Dona\"], \"Others\")\ntrain_df[\"Title\"] = train_df[\"Title\"].replace([\"Miss\", \"Mlle\", \"Ms\", \"Mme\"], \"Mrs\")\nsns.countplot(x = \"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","671b6a1a":"g = sns.factorplot(x = \"Title\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival Probability\")\nplt.show()","15f85f9b":"train_df[\"Title\"] = [0 if each == \"Mr\" else 1 if each == \"Mrs\" else 2 if each == \"Master\" else 3 for each in train_df[\"Title\"]]\ntrain_df[\"Title\"].head(10)","932a8b69":"train_df.head(10)","f733d859":"sns.countplot(x = \"SibSp\", data = train_df)\nplt.show()","14e52a7b":"g = sns.factorplot(x = \"SibSp\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival Probability\")\nplt.show()","f97dbc31":"sns.countplot(x = \"Parch\", data = train_df)\nplt.show()","fe7e6dd1":"g = sns.factorplot(x = \"Parch\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival Probability\")\nplt.show()","1d333ad8":"# in here 1 is the person himself\/herself, it wouldn't be meaningful if we deny the person\ntrain_df[\"F_size\"] = train_df[\"Parch\"] + train_df[\"SibSp\"] + 1\ntrain_df.head(10)","da0123b7":"sns.countplot(x = \"F_size\", data = train_df)\nplt.show()","4c9ca1db":"g = sns.factorplot(x = \"F_size\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival Probability\")\nplt.show()","3fbac5e7":"train_df[\"F_size\"] = [0 if each == 2 or each == 3 or each == 4 else 1 if each == 1 or each == 7 else 2 if each == 5 else 3 for each in train_df[\"F_size\"]]\ntrain_df.head(10)","2965670a":"sns.countplot(x = \"F_size\", data = train_df)\nplt.show()","a674df7d":"sns.countplot(x = \"Embarked\", data = train_df)\nplt.show()","8261d72d":"train_df[\"Embarked\"] = [0 if each == \"S\" else 1 if each == \"C\" else 2 for each in train_df[\"Embarked\"]]\ntrain_df[\"Embarked\"].head(10)","8e4a3584":"train_df[\"Ticket\"].head(10)","73b16809":"tickets = []\n\nfor i in list(train_df[\"Ticket\"]):\n    if not i.isdigit():    #means if value doesnt start with a number\n        tickets.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0])\n    else:\n        tickets.append(\"x\")\ntrain_df[\"Ticket\"] = tickets\ntrain_df[\"Ticket\"].head(20)","7e1d32dc":"train_df = pd.get_dummies(train_df, columns=[\"Ticket\"], prefix=\"T\")  # in here we made columns with all different Ticket values and we use T instead of Ticket beginning of them\ntrain_df.head(10)","2813fdd3":"sns.countplot(x = \"Pclass\", data = train_df)\nplt.show()","be3d9e0a":"sns.countplot(x = \"Sex\", data = train_df)\nplt.show()","64fe1f4b":"g = sns.FacetGrid(train_df, col = \"Survived\")\ng.map(sns.distplot, \"Age\", bins = 25)\nplt.show()","95d191bb":"train_df['CategoricalAge'] = pd.qcut(train_df['Age'], 5)","90e6776d":"train_df['Age'].dtype","9749f726":"train_df[\"CategoricalAge\"].unique()","7920db17":"train_df.loc[train_df['Age'] <= 20, 'Age'] = 0\ntrain_df.loc[(train_df['Age'] > 20) & (train_df['Age'] <= 25), 'Age'] = 1\ntrain_df.loc[(train_df['Age'] > 25) & (train_df['Age'] <= 30), 'Age'] = 2\ntrain_df.loc[(train_df['Age'] > 30) & (train_df['Age'] <= 39), 'Age'] = 3\ntrain_df.loc[train_df['Age'] > 39, 'Age'] = 4 ;\ntrain_df['Age'] = train_df['Age'].astype(int)\ntrain_df['Age'].head(10)","d6d7ddf7":"train_df.drop(\"CategoricalAge\", axis = 1, inplace=True)\ntrain_df.head()","ffc95df3":"#we had this function above, so we will use it to see Fare values\nhist_plot(\"Fare\")\nplt.show()","0efa8609":"train_df['CategoricalFare'] = pd.qcut(train_df['Fare'], 4)\ntrain_df[\"CategoricalFare\"].unique()","88659d47":"train_df.loc[train_df['Fare'] <= 7.896, 'Fare'] = 0\ntrain_df.loc[(train_df['Fare'] > 7.896) & (train_df['Fare'] <= 14.454), 'Fare'] = 1\ntrain_df.loc[(train_df['Fare'] > 14.454) & (train_df['Fare'] <= 30.598), 'Fare'] = 2\ntrain_df.loc[train_df['Fare'] > 30.598, 'Fare'] = 3 ;\ntrain_df['Fare'] = train_df['Fare'].astype(int)\ntrain_df['Fare'].unique()","2bcae1c3":"train_df.drop(\"CategoricalFare\", axis = 1, inplace=True)\ntrain_df.head()","1a815daa":"train_df.drop(labels = [\"PassengerId\",\"Cabin\",\"Name\", \"SibSp\", \"Parch\"], axis = 1, inplace=True)\ntrain_df.columns              ","7d9b828e":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier","7c126f85":"train_df_len #we calculated this at the beginning of this project","d3868d18":"test = train_df[train_df_len:] #before we concat train_df and test_df for fill nan values, now we will divide them again\ntest.drop(\"Survived\", axis = 1, inplace = True)  #test data shouldnt have the target value(Survived in here)\ntest.head()","6f6918c0":"train = train_df[:train_df_len]  #we divided train_df and test_df and made train dataframe again\nCounter(train[\"Survived\"])","699fc156":"train = train.dropna()\nCounter(train[\"Survived\"])\ntrain[\"Survived\"] = train[\"Survived\"].astype(int)","69584357":"X_train = train.drop(\"Survived\" , axis = 1)\ny_train = train[\"Survived\"]\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.3, random_state = 42)\n# we splitted train data for make test and train, test_size = 0.3 means %30 train data split it for test and %70 for train, random_state = 42 means test similar data \n# for it doesnt give different results","7c8ff11b":"Counter(y_train)","a4cf8772":"#here we see how many datas are stored for train and test\nprint(\"X_train: \", len(X_train))\nprint(\"X_test: \", len(X_test))\nprint(\"y_train: \", len(y_train))\nprint(\"y_test: \", len(y_test))","7e729d30":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\nacc_log_train = round(logreg.score(X_train, y_train)*100,2)  #normally this score function gives value like 0.85, we want to see it as like 85.05, thats why we use round function\nacc_log_test = round(logreg.score(X_test, y_test)*100,2)\n\nprint(\"Training Accuracy: {}\".format(acc_log_train))\nprint(\"Test Accuracy: {}\".format(acc_log_test))","48d08b72":"#we are writing method's parameters for finding the best one by using GridSearchCV\nrandom_state = 42\nclassifier = [DecisionTreeClassifier(random_state = random_state),\n             SVC(random_state = random_state),\n             RandomForestClassifier(random_state = random_state),\n             LogisticRegression(random_state = random_state),\n             KNeighborsClassifier()]\n\ndt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\n\nsvc_param_grid = {\"kernel\" : [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1, 1],\n                 \"C\": [1,10,50,100,200,300,1000]}\n\nrf_param_grid = {\"max_features\": [1,3,10],\n                \"min_samples_split\":[2,3,10],\n                \"min_samples_leaf\":[1,3,10],\n                \"bootstrap\":[False],\n                \"n_estimators\":[100,300],\n                \"criterion\":[\"gini\"]}\n\nlogreg_param_grid = {\"C\":np.logspace(-3,3,7),\n                    \"penalty\": [\"l1\",\"l2\"]}\n\nknn_param_grid = {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(),\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\nclassifier_param = [dt_param_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   logreg_param_grid,\n                   knn_param_grid]                     ","77a77267":"cv_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n    clf.fit(X_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])","c247ffa3":"#now we will visualize results\n\ncv_results = pd.DataFrame({\"Cross Validation Means\": cv_result,\n                          \"ML Models\": [\"DecisionTreeClassifier\",\"SVC\",\"RandomForestClassifier\",\"LogisticRegression\",\"KNeighborsClassifier\"]})\n\ng = sns.barplot(\"Cross Validation Means\", \"ML Models\", data = cv_results)\ng.set_xlabel(\"Mean Accuracy\")\ng.set_title(\"Cross Validation Score\")\nplt.show()","e04f8f92":"votingC = VotingClassifier(estimators = [(\"dt\",best_estimators[0]),\n                                        (\"svc\",best_estimators[2]),\n                                        (\"knn\",best_estimators[4])],\n                                        voting = \"hard\", n_jobs = -1)\nvotingC = votingC.fit(X_train, y_train)\nprint(accuracy_score(votingC.predict(X_test),y_test))","66ccbdfc":"test_survived = pd.Series(votingC.predict(test), name = \"Survived\").astype(int)\nresults = pd.concat([test_PassengerId, test_survived],axis = 1)\nresults.to_csv(\"titanic.csv\", index = False)","826c67c4":"as we see these passengers were Pclass = 3 and embarked from S, so we will look for how many fare people paid mean value of Pclass 3","8b1d8bbd":"<a id = \"16\"><\/a><br>\n## Age -- Survived","9fbf5041":"# Introduction\nThe sinking of Titanic is one of the most notorious shipwrecks in the history. In 1912, during her voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew.\n\n<font color = 'blue'>\nContent: \n\n1. [Load and Check Data](#1)\n1. [Variable Description](#2)\n    * [Univariate Variable Analysis](#3)\n        * [Categorical Variable](#4)\n        * [Numerical Variable](#5)\n1. [Basic Data Analysis](#6)\n1. [Outlier Detection](#7)\n1. [Missing Value](#8)\n    * [Find Missing Value](#9)\n    * [Fill Missing Value](#10)\n1. [Visualization](#11)\n    * [Correlation Between Sibsp -- Parch -- Age -- Fare -- Survived](#12)\n    * [SibSp -- Survived](#13)\n    * [Parch -- Survived](#14)\n    * [Pclass -- Survived](#15)\n    * [Age -- Survived](#16)\n    * [Pclass -- Survived -- Age](#17)\n    * [Embarked -- Sex -- Pclass -- Survived](#18)\n    * [Embarked -- Sex -- Fare -- Survived](#19)\n    * [Fill Missing: Age Feature](#20)\n1. [Feature Engineering](#21)\n    * [Name -- Title](#22)\n    * [Family Size](#23)\n    * [Embarked](#24)\n    * [Ticket](#25)\n    * [Pclass](#26)\n    * [Sex](#27)\n    * [Age](#28)\n    * [Fare](#29)\n    * [Drop Passenger ID and Cabin](#30)\n1. [Modeling](#31)\n    * [Train - Test Split](#32)\n    * [Simple Logistic Regression](#33)\n    * [Hyperparameter Tuning -- Grid Search -- Cross Validation](#34) \n    * [Ensemble Modeling](#35)\n    * [Prediction and Submission](#36)\n    \nNOTE : Informations has been taken from DATAI Team","1bca76c0":"in here we can see that from Queenstown, mostly people stayed in 3rd Pclass","f8b213de":"* here we categorized our F_size values, we dont need SibSp and Parch now","8d4fa70d":"<a id = \"27\"><\/a><br>\n## Sex\n* Sex column that we can use directly, because before we made female as 0 and male as 1","3396e190":"<a id = \"29\"><\/a><br>\n## Fare\n* now we need to categorize fare values too ","5fa22632":"<a id  = \"2\"><\/a>\n## Variable Description\n1. PassengerId: unique id number to each passenger\n1. Survived: passenger survive(1) or died(0)\n1. Pclass: passenger class\n1. Name: name\n1. Sex: gender of passenger \n1. Age: age of passenger \n1. SibSp: number of siblings\/spouses\n1. Parch: number of parents\/children \n1. Ticket: ticket number \n1. Fare: amount of money spent on ticket\n1. Cabin: cabin category\n1. Embarked: port where passenger embarked (C = Cherbourg, Q = Queenstown, S = Southampton)","c5d688ec":"* we can see previous NaN values now have a median value","57dc6576":"as we see we filled Embarked values all","48d4fa8d":"* here we see our Family sizes, mostly people came alone to the ship","ae4fabc7":"<a id = \"18\"><\/a><br>\n## Embarked -- Sex -- Pclass -- Survived","10545aeb":"<a id = \"3\"><\/a><br>\n# Univariate Variable Analysis\n* Categorical Variable: Survived, Sex, Pclass, Embarked, Cabin, Name, Ticket, Sibsp and Parch\n* Numerical Variable: Fare, age and passengerId","72b8f075":"as summary, we see that if a passenger came from Cherbourg, this passenger went to 1st or 2nd class and this person is highly possible survived and from Queenstown, almost all people stayed in 3rd class and highly possible this passenger died and also from Southampton, most people went to 3rd Pclass and this person also highly possible died and less possible who went to 1st and 2nd class from Southampton stop can be survived","a670578c":"* here we see that A\/5 , PC , STON\/02 ... and NaN values, numbers not important, we can make a feature with ticket classes.","25e63897":"as we can see Pclass = 3 passengers paid mean value is 12.63...","573c9c9f":"<a id = \"33\"><\/a><\/br>\n## Simple Logistic Regression\n* in here we will use logistic regression method for seeing if our method is successful","8c1e2275":"* here we see as result for DecisionTreeClassifier = 0.836, SVC = 0.848, RandomForestClassifier = 0.835, LogisticRegression = 0.811, KNeighborsClassifier = 0.845","98e03fac":"<a id = \"14\"><\/a><br>\n## Parch -- Survived","4ba5db90":"* as we can see that 2-3-4 family size survival rate is higher than others, we can categorize it as 2-3-4 f_size = 0, 1-7 f_size = 1, 5 f_size = 2, others f_size = 3. We can use as its too.","c9004a54":"## Correlation Between Sibsp -- Parch -- Age -- Fare -- Pclass -- Survived\nin here we will see if there is a connection between upper values","e39db4d7":"<a id = \"30\"><\/a><\/br>\n## Drop Passenger ID and Cabin\n* now we will drop the values we dont need","bac5828a":"as we see, if we look for median values of C, Q, S; Q and S median values(lines in boxes) which tells us that S and Q medians are very low and C medians higher and also 80.0 fare value from upper table in the C graphic so that we can say this passengers embarked from C\n","782ab784":"<a id = \"32\"><\/a><\/br>\n## Train - Test Split","7380442d":"* now we will divide our datas according to [(0.169, 20.0] < (20.0, 25.0] < (25.0, 30.0] < (30.0, 39.0] < (39.0, 80.0]]  these category, we could divide it in pd.qcut section too but its better to see how this works.","2d38d000":"### Embarked-Fare","937f3681":"### Parch-Survived","60476dc4":"* we still have space before Mr, so that we will remove it too","36c18da9":"* now here we see that first Name value is above here, for taking only Mr value, first lets use . value and split our data as 2","b28e3dda":"* here we see there is no NaN value anymore","c68a6709":"* age <= 10 has a high survival rate,\n* oldest passengers (80) survived,\n* large number of 20 years old did not survived,\n* most passengers are in 15-35 age range,\n* mostly 20-30 years old people died,\n* mostly 35 years old people survived.\n\n* there are 2 np methods to divide Age feature. 1)np.cut(train_df[\"Age],5) this divides Age values (max.age - min.age)\/5 and makes 5 different groups. For example min.age = 0, max.age = 100 then 1st group between 0-20, 2nd 20-40, 3rd 40-60, 4th 60-80, 5th 80-10.    2)np.qcut(train_df[\"Age],5) this also divides Age values but this time uses quartile values and find median and Q1-Q3 quartiles values, thats why it divides ages according to intensity of Age values, thats why this method is better","5694465e":"<a id = \"22\"><\/a><br>\n## Name -- Title","d7393c65":"as we see who embarked from C paid more because as we saw before these passengers stayed in 1st or 2nd Pclass","43c23602":"* here we categorized Title column, we dont need Name column, later we will drop it","3e9b6ab7":"Now we see that 256 value of Age column has NaN value. How can we fill these values?\n1. We can use passengers' Sex and use females and males' mean value of ages\n1. We can use Pclass \n1. We can use Parch and SibSp\n1. We can use all and make an hybrid value\nNow let's try all","8923bcc2":"* here we see we have %80 success with logistic regression method","c3cfe359":"<a id = \"13\"><\/a><br>\n## SibSp -- Survived","d6165cab":"as we can see that we filled NaN values of Fare too","acf02fb2":"as we can see who has place in 1st class paid much more than other classes","c8c38e7f":"* as we can see that there are couple titles, we need to combine some of these titles.","bd46447c":"* here we categorized ticket values, we need to change them all as number categories.","6725828a":"* as we can see that we can use Pclass, Name(mr, miss.. part as title), Sex, Age(we will use thresholds), SibSp, Parch, Ticket(A\/5,PC.. values, we may not use them too), Fare(we will use thresholds), Embarked columns as categorical values. We dont need PassengerId, we will drop it later.","9da227bb":"<a id = \"8\"><\/a><br>\n# Missing Value\n* Find Missing Value\n* Fill Missing Value","6ab15702":"* lets also look for their survive rates","b8a9899f":"here we can see that sex and age correlation value is so little and parch, pclass, sibsp values have correlation with age -0.15, -0.24, -0.41. We can use them for fill ages' nan values","995d9efc":"* age <= 10 has a high survival rate,\n* oldest passengers (80) survived,\n* large number of 20 years old did not survived,\n* most passengers are in 15-35 age range,\n* mostly 20-30 years old people died,\n* mostly 35 years old people survived,\n* use age feature in training\n* use age distribution for missing value of age","5201c410":"* as we see in histogram graphic and the divide values, it fits to each other","d7c406fb":"<a id = \"4\"><\/a><br>\n## Categorical Variable","5d22856a":"* we removed nan values of Survived","2f858d62":"* Passsengers who pay higher fare have better survival. Fare can be used as categorical for training.\n* We can use categorical Embarked places for training too.","07180543":"<a id = \"10\"><\/a><br>\n## Fill Missing Value\n* Embarked has 2 missing value\n* Fare has only 3 missing values","f06b5245":"<a id = \"25\"><\/a><br>\n## Ticket","b0176086":"as we see females are highly ratio survived","e9c93797":"* Having a lot of SibSp have less chance to survive.\n* if sibsp == 0 or 1 or 2, passenger has more chance to survive.\n* we can consider a new feature describing these categories.\n* Parch == 3 has standart deviation high.","77b81f44":"Also in here we can see that passengers who embarked from C could survived with higher possibility than others which we said before passengers who embarked from C went to 1st or 2nd classes and from S also we said, they went to 3rd class mostly. We checked results double in here.","c825c8d4":"* now we will use np.qcut and divide our Fare values.","1b77f467":"* now as we see that we can combine them both and we can make a family size and see Parch and Sibsp as one feature or we can use them as one feature. It is better to use them as one feature to train our data and categorize it ","134b5665":"as we see who has 1-2-3 parents or children is more likely survived than others","dbde402a":"* now we will make meaningful new features for training our data","2638ccfa":"<a id = \"7\"><\/a><br>\n# Outlier Detection","0fc1f64e":"### Embarked-Pclass","b5ed20b2":"* float64(2): Fare and Age\n* int64(5): Pclass, sibsp, parch, passengerId and survived\n* object(5): Cabin, embarked, ticket, name and sex","cfa8d277":"<a id = \"28\"><\/a><br>\n## Age\n* now we need to categorize age values too ","5074bd1a":"* here we can see median value of both genders are similar, so that we cant use sex values for filling age.","baca6c05":"* now we can see our Mr value. Now we need to apply this for all Name values.","7071cd07":"* here we can see for SibSp values, ages can change and also for Parch values, ages can change and we can use these values for fill age values. We can look for embarked values too but no need of looking more.","edc92bb5":"<a id = \"35\"><\/a><\/br>\n## Ensemble Modelling\n* we will use votingclassifier for ensemble modelling, lets use our 3 medols","0a9ffa3f":"<a id = \"23\"><\/a><br>\n## Family Size\n* We have SibSp and Parch, lets visualize them first again","cbcaa18c":"as we see people who has 0-1-2 sibblings or spouses survived higher","46d043fa":"<a id = \"19\"><\/a><br>\n## Embarked -- Sex -- Fare -- Survived","5bb07893":"* as we can see first class passengers have higher value of surviving than other classes.","cd56bc59":"If correlation value is 0 then there is no connection between.\nIf correlation value is -1 then there is reverse connection between.\nIf correlation value is 1 then there is straight connection between.\n\nas we can see \nParch and Sibsp has **0.33** correlation between.<br>\nParch and Fare has **0.22** correlation between..<br>\nAge and Fare has **0.25** correlation between..<br>\nAge and Pclass has **-0.44** correlation between..<br>\nFare and Pclass has **-0.57** correlation between..<br>\nFare and Survived has **0.26** correlation between..<br>\nPclass and Survived has **-0.33** correlation between..<br>\n\nThe other correlation values are so little, so we will ignore and say no connection between them.\n\nNow we will look for features in detail.","c91c7a24":"* here we see that Mr survival rate is very low and Mrs and Master is high, we can categorize these like Mrs and Master as 1 and Mr and Others as 0 but lets make it all seperated as 0-1-2-3","8c4e2e09":"### Sex-Survived","91032dc0":"<a id = \"17\"><\/a><br>\n## Pclass -- Survived -- Age","1816e768":"### Pclass - Fare","fe19269b":"we dropped outlier values which means statiscally out of our boundries need to drop for our future calculations be healthy","f5c7929d":"in here we can see that from Southamptan, mostly people stayed in 3rd Pclass","d0479314":"<a id = \"31\"><\/a><\/br>\n# MODELLING\n* now we will split our data to Train-Test and make our models\n* first we will write our libraries which we will use for modelling","800f3b90":"as we see that if the Pclass(class of passengers' place) gets higher, survive ratio gets higher also","4cfe15fa":"* Now let's look for heatmap of Age, Sex, SibSp, Parch, Pclass and make sure which effects Age values","5b86fe00":"<a id = \"36\"><\/a><\/br>\n## Prediction and Submission","32a81e44":"in here, i wanted to show how we can make filter as we did while we were trying to find outlier_list_col","e6a281d7":"<a id = \"5\"><\/a><br>\n## Numerical Variable","5c8a6c7f":"* as we see SVC gives best score. now we will ensemble models and make an average value of all methods which will give us best meaningful score","355d3c97":"* Female passengers have much better survival rate than males.\n* males have better surv\u015fval rate in pclass 3 in C.\n* embarked and sex will be used in training.","7330c2a1":"<a id = \"9\"><\/a><br>\n## Find Missing Value","e114c9f1":"* here we see that 1st class people have like 40 years old, 2nd class is like 30 and 3rd class more like 25, so that we can use this value for filling age nan values. Also we can see that sex values not important for age value.","3d0a4c0d":"<a id = \"24\"><\/a><br>\n## Embarked\n* Embarked columns we can use it directly and categorizes it.","009e1f3a":"<a id = \"21\"><\/a><br>\n# Feature Engineering","278df110":"### SibSp-Survived","6b6d8b80":"* in here we made a new columns(feature) as title named and see only title values","155a7ced":"* now we will use test values for find our accuracy score and publish our data","c9bb5df4":"<a id = \"20\"><\/a><br>\n## Fill Missing: Age Feature","77a1c91b":"* and here we see that if a passenger has more than 2 sibblings or spouses has less chance to survive, who has less than 3 have more chance to survive.\n* so we can say use this information as new feature of our datas like if a passenger has more than 2 sibblings have 0 chance to survive and 0-1-2 has 1 chance to survive for future machine learning proses.\n* Our threshold value is 2","424c016c":"<a id = \"34\"><\/a><\/br>\n## Hyperparameter Tuning -- Grid Search -- Cross Validatoin\n* now we find best hyperparameters for our methods and use grid search for it, also use KFold cross validation for find a better score also validate our train datas\n* we will use 5 different Machine Learning Classifier. Decision Tree, SVM, RandomForest, KNN, Logistic Regression","339a0cb8":"### Embarked-Survived","5d91865f":"<a id  = \"1\"><\/a>\n\n## LOAD and CHECK","59ede3ac":"<a id = \"15\"><\/a><br>\n## Pclass -- Survived","64fdec8d":"as we see, who embarked ship from Cherbourg survived more, now lets see which Pclass passengers embarked from","6eb0d522":"<a id = \"11\"><\/a><br>\n# Visualization\n","edfa31e6":"### Pclass-Survived","5d34e26b":"<a id = \"6\"><\/a><br>\n# Basic Data Analysis\n* Pclass - Survived\n* Sex - Survived\n* SibSp - Survived\n* Embarked - Survived\n* Embarked - Pclass\n* Parch - Survived\n* Embarked - Fare\n* Pclass - Fare","d94e8754":"# we finished data science part and now we will visualize our datas","417f70c4":"* as we can see Pclass 3 has more passengers in general.\n* Pclass 3 death ratio is higher.\n* Pclass 2 death and survived ratios are in balance.\n* Pclass 1 survived ratio is higher.\n* These datas are important for training.","d419cc62":"* as we see that there are Mr. Miss. Mrs. Master. and other values, lets visualize these values and see how many of them we have. We need to see only Mr, Miss.. values so that we will split our Name datas.","0406e577":"in here we can see from Cherbourg, mostly people stayed in 1st and 2nd Pclass","993d9e1c":"* in here we split our data according to . and took the first part of it, now we will split it again with , value and take Mr value","73273a1c":"* we filled NaN datas of Fare and Embarked before but now we have 3 other NaN valued columns. Now we will fill them too.","f71e8fad":"<a id = \"26\"><\/a><br>\n## Pclass\n* Pclasses that we can use directly","702470fd":"in here we can see outliers which has high or low values than stastistacally calculated values as circles. "}}