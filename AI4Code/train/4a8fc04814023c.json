{"cell_type":{"564e44e5":"code","e34ff1dd":"code","e4d80882":"code","7eaff7db":"code","293955b4":"code","5c35e380":"code","1008aa62":"code","a9f48914":"code","5f660733":"code","ebea7dd8":"code","c35da7e8":"code","436006a2":"code","b08de41e":"code","2206ad7c":"code","71e671a0":"code","b9ca7b31":"code","2dc1e193":"code","72a29a9f":"code","1fb5f8ba":"code","689d5e29":"code","2a45fac8":"code","fd73eb41":"code","c7e3adef":"code","357df954":"markdown","820b13d2":"markdown","d8a3610e":"markdown","c1f9ff5b":"markdown","0227ecef":"markdown","e4634998":"markdown","19a56b34":"markdown","6fec9ca0":"markdown","974e9ae6":"markdown","5502699e":"markdown","c5d297dd":"markdown","1352c1d8":"markdown","24403411":"markdown","811514cb":"markdown","1bb825f6":"markdown","394c168a":"markdown","7ba0a4a0":"markdown","d681e3ba":"markdown","052023d4":"markdown","4f095b59":"markdown","4403910b":"markdown"},"source":{"564e44e5":"# Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Get version python\/keras\/tensorflow\/sklearn\nfrom platform import python_version\nimport sklearn\nimport keras\nimport tensorflow as tf\n\n# Folder manipulation\nimport os\n\n# Garbage collector\nimport gc\n\n# Linear algebra and data processing\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\n# Model evaluation\nfrom sklearn.metrics import mean_absolute_error\n\n# Visualisation of picture and graph\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Keras importation\nfrom keras.applications import DenseNet201\nfrom keras.models import Model, Sequential\nfrom keras.optimizers import Adam\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.layers import BatchNormalization, Dense\nfrom keras.regularizers import l1_l2\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom keras.utils import to_categorical","e34ff1dd":"print(os.listdir(\"..\/input\"))\nprint(\"Keras version : \" + keras.__version__)\nprint(\"Tensorflow version : \" + tf.__version__)\nprint(\"Python version : \" + python_version())\nprint(\"Sklearn version : \" + sklearn.__version__)","e4d80882":"MAIN_DIR = \"..\/input\/\"\nIMG_ROWS = 64\nIMG_COLS = 64\nCHANNELS = 3\nIMG_SHAPE = (IMG_ROWS, IMG_COLS, CHANNELS)\nLABELS = ['AnnualCrop', 'Forest', 'HerbaceousVegetation', \n        'Highway', 'Industrial', 'Pasture', 'PermanentCrop', \n        'Residential', 'River', 'SeaLake']\n\n# Set graph font size\nsns.set(font_scale=1.3)","7eaff7db":"def load_data():\n    X_total_train = np.load(MAIN_DIR + \"X_train.npy\")\n    X_train = X_total_train[:, :, :, :CHANNELS].copy()\n\n    # Free memory\n    del X_total_train\n    gc.collect()\n    \n    y_total_train = np.load(MAIN_DIR + \"y_train.npy\")\n    encoder = LabelEncoder()\n    y_train = encoder.fit_transform(y_total_train)\n\n    # Free memory\n    del y_total_train\n    gc.collect()\n\n    # One-hot encoding y_train\n    y_train = to_categorical(y_train)\n\n    # Free memory\n    gc.collect()\n    \n    return X_train, y_train, encoder","293955b4":"X_train, y_train, encoder = load_data()\nprint(f\"X shape : {X_train.shape}\")\nprint(f\"y shape : {y_train.shape}\")","5c35e380":"def plot_pictures(X, y, nb_rows=6, nb_cols=6, figsize=(14, 14)):\n    # Set up the grid\n    fig, ax = plt.subplots(nb_rows, nb_cols, figsize=figsize, gridspec_kw=None)\n    fig.subplots_adjust(wspace=0.4, hspace=0.4)\n\n    for i in range(0, nb_rows):\n        for j in range(0, nb_cols):\n            index = np.random.randint(0, X.shape[0])\n    \n            # Hide grid\n            ax[i, j].grid(False)\n            ax[i, j].axis('off')\n            \n            # Plot picture on grid\n            ax[i, j].imshow(X[index].astype(np.int))\n            ax[i, j].set_title(f\"{LABELS[np.where(y[index] == 1)[0][0]]}\")","1008aa62":"plot_pictures(X_train, y_train)","a9f48914":"def load_gen(X, y):\n    gen = ImageDataGenerator(\n            validation_split=0.1,\n            horizontal_flip=True,\n            vertical_flip=True,\n            fill_mode='nearest')\n\n    gen_train = gen.flow(X, y,\n                          batch_size=32, \n                          shuffle=True,\n                          subset='training')\n\n    gen_val = gen.flow(X, y,\n                         batch_size=32, \n                         shuffle=True, \n                         subset='validation')\n    \n    return gen_train, gen_val","5f660733":"def build_model():\n    model = Sequential()\n    \n    model.add(DenseNet201(input_shape=IMG_SHAPE, include_top=False, pooling='max'))\n    model.add(BatchNormalization())\n    model.add(Dense(2048, activation='relu',  kernel_regularizer=l1_l2(0.01)))\n    model.add(BatchNormalization())\n    model.add(Dense(2048, activation='relu',  kernel_regularizer=l1_l2(0.01)))\n    model.add(BatchNormalization())\n    model.add(Dense(2048, activation='relu',  kernel_regularizer=l1_l2(0.01)))\n    model.add(BatchNormalization())\n    model.add(Dense(1024, activation='relu', kernel_regularizer=l1_l2(0.01)))\n    model.add(BatchNormalization())\n    model.add(Dense(10, activation='softmax'))\n    \n    for layer in model.layers:\n        layer.trainable = True\n    \n    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy'])\n    \n    model.summary()\n    \n    return model","ebea7dd8":"def train_model(gen_train, gen_val):\n    model = build_model()\n\n    cbs = [ReduceLROnPlateau(monitor='loss', factor=0.5, patience=1, min_lr=1e-5, verbose=0),\n           EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=10, verbose=1, mode='auto')]\n\n    history = model.fit_generator(gen_train, \n                        steps_per_epoch=(gen_train.n\/\/gen_train.batch_size), \n                        epochs=200, \n                        validation_data=gen_val, \n                        validation_steps=len(gen_val), \n                        shuffle=True, \n                        callbacks=cbs, \n                        verbose=1)\n    return model, history","c35da7e8":"gc.collect()\ngen_train, gen_val = load_gen(X_train, y_train)\nmodel, history = train_model(gen_train, gen_val)","436006a2":"def plot_loss(history):\n    fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n    \n    # Plot train\/val accuracy\n    ax[0].plot(history.history['acc'])\n    ax[0].plot(history.history['val_acc'])\n    ax[0].set_title('Model accuracy')\n    ax[0].set_ylabel('Accuracy')\n    ax[0].set_xlabel('Epochs')\n    ax[0].legend(['Train', 'Test'], loc='lower right')\n    ax[0].set_ylim(0, 1.05)\n    \n    # Plot train\/val loss\n    ax[1].plot(history.history['loss'])\n    ax[1].plot(history.history['val_loss'])\n    ax[1].set_title('Model Loss')\n    ax[1].set_ylabel('Loss')\n    ax[1].set_xlabel('Epochs')\n    ax[1].legend(['Train', 'Test'], loc='upper right')","b08de41e":"plot_loss(history)","2206ad7c":"def print_results(history):\n    print(\"ACCURACY :\")\n    print(f\"Training accuracy : {history.history['acc'][-1]}\")\n    print(f\"Validation accuracy : {history.history['val_acc'][-1]}\")\n    \n    print(\"\\nLOSS :\")\n    print(f\"Training categorical crossentropy loss : {history.history['loss'][-1]}\")\n    print(f\"Validation categorical crossentropy loss : {history.history['val_loss'][-1]}\")","71e671a0":"print_results(history)","b9ca7b31":"def plot_lr(history):\n    fig, ax = plt.subplots(figsize=(7, 5))\n    \n    # Plot learning rate\n    ax.plot(history.history['lr'])\n    ax.set_title('Learning rate evolution')\n    ax.set_ylabel('Learning rate value')\n    ax.set_xlabel('Epochs')\n    ax.legend(['Train'], loc='upper right')","2dc1e193":"plot_lr(history)","72a29a9f":"def load_data_test():\n    X_total_test = np.load(MAIN_DIR + \"X_test.npy\")\n    X_test = X_total_test[:, :, :, :CHANNELS].copy()\n\n    # Free memory\n    del X_total_test\n    gc.collect()\n    \n    return X_test","1fb5f8ba":"X_test = load_data_test()\n\ny_pred = model.predict(X_test)\ny_pred = np.argmax(y_pred,axis=1)","689d5e29":"plot_pictures(X_test, to_categorical(y_pred))","2a45fac8":"def save_model(model):\n    # Serialize model to JSON\n    model_json = model.to_json()\n    with open(\"model.json\", \"w\") as json_file:\n        json_file.write(model_json)\n    \n    # Serialize weights to HDF5\n    model.save_weights(\"model.h5\")\n    print(\"Saved model to disk\")","fd73eb41":"def save_pred(y_pred):\n    y_pred = encoder.inverse_transform(y_pred)\n    np.save(\"label_test.predict\", y_pred)\n    print(\"Save prediction\")\n    #!mv label_test.predict.npy label_test.predict\n    #!zip -r submission.zip label_test.predict","c7e3adef":"save_pred(y_pred)\nsave_model(model)","357df954":"## 7.3 Save <a id=\"save\"><\/a>","820b13d2":"# 2. Importations <a id=\"importations\"><\/a>","d8a3610e":"## 5.1 Numpy array <a id=\"numpy_array\"><\/a>","c1f9ff5b":"## 5.2 Pictures <a id=\"pictures\"><\/a>","0227ecef":"## 7.1 Predict <a id=\"predict\"><\/a>","e4634998":"## Landcover classification with Keras DenseNet201 on EuroSAT data","19a56b34":"## 6.1 Learning <a id=\"learning\"><\/a>","6fec9ca0":"# 6. Modelisation <a id=\"modelisation\"><\/a>","974e9ae6":"<p style=\"text-align:center;\">\n    <img src=\"https:\/\/www.goodfreephotos.com\/cache\/other-landscapes\/beautiful-landscape-panoramic-of-the-mountaintops.jpg\" style=\"height:auto; width:100%\"\/>\n<\/p>","5502699e":"# 8. Conclusion <a id=\"conclusion\"><\/a>\n\n<p style=\"text-align:justify;\">Densenet201 seems to have better performance than GoogleLeNet or ResNet50 used in the paper. However it would be interesting to try bigger network (DenseNet269) or to use an other network architecture which perform better than DenseNet like ResNeXt, Xception, ...etc (see : <a href=\"https:\/\/keras.io\/applications\/\"> Keras Applications<\/a>) for example. Furthemore, I think it would be also a really interesting idea to try NAS (Network Archicture Search) in order to find the best architecture for tackling this problem.<\/p>","c5d297dd":"## 6.4 Learning rate <a id=\"learning_rate\"><\/a>","1352c1d8":"<p style=\"text-align:justify;\">The competition was organized on Codalab by CERFACS (Centre of basic and applied research specialized in modelling and numerical simulation), see more on : <a href=\"https:\/\/competitions.codalab.org\/competitions\/22820?secret_key=93fcb262-a531-431f-828d-dbb2111428ab\">Codalab<\/a>. This notebook show the the winning solution over 19 participants <b>(Public : 0.98686 and Private : 0.98714 on accuracy)<\/b>. This competition and the data (EuroSAT) associated are inspired from this paper : <a href=\"https:\/\/arxiv.org\/abs\/1709.00029\">https:\/\/arxiv.org\/abs\/1709.00029<\/a>.<\/p>\n\n<p style=\"text-align:justify;\"><b>This competition is about predicting the label of a satelite image among 10 possible ones.<\/b><\/p>","24403411":"## 6.3 Results <a id=\"results\"><\/a>","811514cb":"# 4. Set parameters <a id=\"set_parameters\"><\/a>","1bb825f6":"# 7. Prediction <a id=\"prediction\"><\/a>","394c168a":"# Table of Contents\n\n1. [Context](#context)  \n2. [Importations](#importations)  \n3. [Informations](#informations)\n4. [Set parameters](#set_parameters)\n5. [Data exploration](#data_exploration)  \n    5.1 [Numpy array](#numpy_array)  \n    5.2 [Pictures](#pictures)  \n6. [Modelisation](#modelisation)  \n    6.1 [Learning](#learning)    \n    6.2 [Learning curves](#learning_curves)  \n    6.3 [Results](#results)  \n    6.4 [Learning rate](#learning_rate)  \n7. [Prediction](#prediction)  \n    7.1 [Predict](#predict)    \n    7.2 [Visualize](#visualize)  \n    7.3 [Save](#save) \n8. [Conclusion](#conclusion)","7ba0a4a0":"# 5. Data exploration <a id=\"data_exploration\"><\/a>","d681e3ba":"## 7.2 Visualize <a id=\"visualize\"><\/a>","052023d4":"## 6.2 Learning curves <a id=\"learning_curves\"><\/a>","4f095b59":"# 3. Informations <a id=\"informations\"><\/a>","4403910b":"# 1. Context <a id=\"context\"><\/a>"}}