{"cell_type":{"56d0a3b2":"code","a68745b8":"code","017eb249":"code","237a3ad8":"code","066bb08f":"code","2773fd65":"code","fe82e540":"markdown","5a92f54d":"markdown","4e500c45":"markdown","9c14c8c2":"markdown","570d884b":"markdown"},"source":{"56d0a3b2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport csv\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn import linear_model\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a68745b8":"data = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\nprint(data)\n","017eb249":"data[\"new_column\"] = data['text'].str.replace('[^\\w\\s]','')\nprint(data['new_column'])","237a3ad8":"t = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')\nt[\"new_column\"] = t['text'].str.replace('[^\\w\\s]','')\nvectorizer = CountVectorizer(min_df=0, lowercase=True)\nvectorizer.fit(data['text'])\nx_train = vectorizer.transform(data['new_column']).toarray()\ny_train = np.asarray(data['target'])\nx_test = vectorizer.transform(t['new_column']).toarray()\n","066bb08f":"l = linear_model.LogisticRegression()\nl.fit(x_train, y_train)\nacc = l.predict(x_test)\nprint(acc)","2773fd65":"with open('pred.csv','w+') as f :\n    rows = []\n    y2 = t[\"id\"]\n    for i in range(len(y2)):\n        \n        row = []\n        row.append(y2[i])\n        row.append(acc[i])\n        rows.append(row)\n    field = ['id', 'target']\n    w = csv.writer(f)\n    w.writerow(field)\n    w.writerows(rows)","fe82e540":"# **Importing test data and vectorising both train and test data**","5a92f54d":"# **Removing all the punctuation from the data.**","4e500c45":"# **writing the predicted values in a csv file**","9c14c8c2":"# **Importing the train data**","570d884b":"# **Creating a Logistic Regression model and predicting it**"}}