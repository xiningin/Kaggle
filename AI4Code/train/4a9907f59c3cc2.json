{"cell_type":{"1e012365":"code","32ee0740":"code","5567a28f":"code","62674f20":"code","2fac00dc":"code","43cd2034":"code","7fa183e1":"code","c367ae27":"code","f264855b":"code","1bb2b10e":"code","79b33807":"code","21a647b7":"code","ccd443ab":"code","2aae9fcd":"markdown","2c3e6e54":"markdown","fec044a2":"markdown","990bd90d":"markdown","6185482b":"markdown"},"source":{"1e012365":"#from mpl_toolkits.mplot3d import Axes3D\n#from sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n","32ee0740":"print(sorted(os.listdir('..\/input')))","5567a28f":"len(os.listdir('..\/input\/2019\/data\/json\/2019'))","62674f20":"print(sorted(os.listdir('..\/input\/2019\/data\/json\/2019')))","2fac00dc":"# Read contents of one of the json files: 1_2019.json\ndf = pd.read_json(\"..\/input\/2019\/data\/json\/2019\/1_2019.json\")","43cd2034":"df.columns","7fa183e1":"df.describe(include=\"object\")","c367ae27":"df.dtypes","f264855b":"# Column `data` should be of type date:\ndf['data2'] = pd.to_datetime(df['data'])","1bb2b10e":"# Number of documents per month\ndf['data2'].groupby(df[\"data2\"].dt.month).count().plot(kind=\"bar\")","79b33807":"df['autoridade'].value_counts()","21a647b7":"df['facet-localidade'].value_counts()","ccd443ab":"df['facet-tipoDocumento'].value_counts()","2aae9fcd":"## Conclusion\nThis concludes your starter analysis! To go forward from here, click the blue \"Fork Notebook\" button at the top of this kernel. This will create a copy of the code and environment for you to edit. Delete, modify, and add code as you please. Happy Kaggling!","2c3e6e54":"It seems that each of the 136 json files from 2019 contains 1000 references to legal documents each.\n\nLet's do some basic exploring for columns 'autoridade', 'localidade' and 'tipoDocumento':","fec044a2":"## Exploratory Analysis\n\nThe default kaggle bot code wasn't plotting any of the data, due to its path location and use of json files.","990bd90d":"## Ideas for further analysis\n\n1. Read all the json files from a single year (or even the whole dataset) into a single dataframe for ease of use in getting aggregated statistics\n2. Create functions to access the text content from a referenced document by its url from LexML\n3. Publish some interesting results!","6185482b":"## Introduction\n\nI've forked the automatically-generated kernel from Kaggle bot to better explore some of the data from LexML.\nPlease do continue adding more useful functionnality to it by clicking the blue \"Fork Notebook\" button at the top of this kernel to begin editing."}}