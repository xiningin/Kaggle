{"cell_type":{"e9dd3362":"code","49fb3392":"code","79a22a59":"code","17b084fa":"code","95ac28a4":"code","265eb3a9":"code","738060bf":"code","ae955644":"code","61719a63":"code","2b341516":"code","3806d99e":"code","3ee7cc70":"code","0300338a":"code","7be81840":"code","9cdccf12":"code","6cb4d6f1":"code","a490d6fc":"code","b2bec4d0":"code","c59ff376":"code","80c32863":"code","0f923423":"code","bae158fe":"code","5a6cca88":"code","12a532b6":"code","c8fd0325":"code","a8b3f90b":"code","77041650":"code","7c01480e":"code","1159c102":"code","2553dc1a":"code","88e983d2":"code","dcdbe674":"code","dfa59bb4":"code","ede1965e":"code","2776e98f":"code","a00d62a5":"markdown","f6021cc3":"markdown"},"source":{"e9dd3362":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport os\n\nimport warnings\nimport joblib\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz, export_text, DecisionTreeRegressor\nfrom sklearn.metrics import classification_report, roc_auc_score\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, validation_curve\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\nfrom sklearn.model_selection import GridSearchCV, cross_validate, RandomizedSearchCV, validation_curve\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor, AdaBoostRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV \nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, plot_roc_curve\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, LogisticRegression\npd.set_option('display.max_columns', None)\nwarnings.simplefilter(action='ignore', category=Warning)\nfrom sklearn.svm import SVR\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler\n\n\nfrom sklearn.exceptions import ConvergenceWarning\nfrom warnings import simplefilter\n\nsimplefilter(action='ignore', category=FutureWarning)\nsimplefilter(\"ignore\", category=ConvergenceWarning)\n","49fb3392":"df = pd.read_csv(\"..\/input\/hittersdataset\/hitters.csv\")","79a22a59":"df.shape #20 de\u011fi\u015fken var.\ndf.head()","17b084fa":"def check_df(dataframe, head=5):\n    print(\"##################### Shape #####################\")\n    print(dataframe.shape)\n    print(\"##################### Types #####################\")\n    print(dataframe.dtypes)\n    print(\"##################### Head #####################\")\n    print(dataframe.head(head))\n    print(\"##################### Tail #####################\")\n    print(dataframe.tail(head))\n    print(\"##################### NA #####################\")\n    print(dataframe.isnull().sum())\n    print(\"##################### Quantiles #####################\")\n    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)\n\ncheck_df(df)","95ac28a4":"df.describe([0.05, 0.25, 0.50, 0.75, 0.95, 0.99]).T","265eb3a9":"def check_outlier(dataframe, col_name):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n        return True\n    else:\n        return False","738060bf":"def replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n","ae955644":"def outlier_thresholds(dataframe, col_name, q1=0.15, q3=0.85):\n    quartile1 = dataframe[col_name].quantile(q1)\n    quartile3 = dataframe[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit","61719a63":"def remove_outlier(dataframe, col_name):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    df_without_outliers = dataframe[~((dataframe[col_name] < low_limit) | (dataframe[col_name] > up_limit))]\n    return df_without_outliers","2b341516":"le = LabelEncoder()\n\ndef label_encoder(dataframe, binary_col):\n    labelencoder = LabelEncoder()\n    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n    return dataframe","3806d99e":"def grab_outliers(dataframe, col_name, index=False):\n    low, up = outlier_thresholds(dataframe, col_name)\n    if dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].shape[0] > 10:\n        print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].head())\n    else:\n        print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))])\n    if index:\n        outlier_index = dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].index\n        return outlier_index","3ee7cc70":"grab_outliers(df, \"Salary\")","0300338a":"check_outlier(df, \"Salary\")","7be81840":"df = remove_outlier(df,\"Salary\")","9cdccf12":"check_outlier(df, \"Salary\")","6cb4d6f1":"df[\"Salary\"].isnull().sum()  #Ba\u011f\u0131ml\u0131 de\u011fi\u015fkende 59 tane NaN de\u011feri var.","a490d6fc":"df[\"Salary\"].describe()","b2bec4d0":"df.head(25)","c59ff376":"#Kategorik,Say\u0131sal,Kardinal de\u011fi\u015fkenleri g\u00f6relim.\n\ndef grab_col_names(dataframe, cat_th=10, car_th=20):\n    # cat_cols, cat_but_car\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n    cat_cols = cat_cols + num_but_cat\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    # num_cols\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n    return cat_cols, num_cols, cat_but_car\n\ncat_cols, num_cols, cat_but_car = grab_col_names(df)","80c32863":"for col in num_cols:\n    print(col, check_outlier(df, col))","0f923423":"#eksik de\u011fer kontrol\u00fc\ndf.isnull().values.any()\ndf.dropna(inplace = True)\ndf.head()","bae158fe":"df.isnull().values.any() #eksik de\u011fer kalmad\u0131","5a6cca88":"# feature engineering\n\ndf[\"NEW_HITS\"] = df[\"Hits\"] \/ df[\"CHits\"]\ndf[\"NEW_RBI\"] = df[\"RBI\"] \/ df[\"CRBI\"]\n#df[\"NEW_WALKS\"] = df[\"Walks\"] \/ df[\"CWalks\"]\ndf[\"NEW_CAT_BAT\"] = df[\"CAtBat\"] \/ df[\"Years\"]\ndf[\"NEW_CRUNS\"] = df[\"CRuns\"] \/ df[\"Years\"]\ndf[\"NEW_CHITS\"] = df[\"CHits\"] \/ df[\"Years\"]\ndf[\"NEW_CHMRUN\"] = df[\"CHmRun\"] \/ df[\"Years\"]\ndf[\"NEW_CRBI\"] = df[\"CRBI\"] \/ df[\"Years\"]\ndf[\"NEW_CWALKS\"] = df[\"CWalks\"] \/ df[\"Years\"]\ndf['new_PutOutsYears'] = df['PutOuts'] * df['Years']","12a532b6":"df.loc[df[\"CWalks\"] != 0, \"NEW_WALKS\"] = df[\"Walks\"] \/ df[\"CWalks\"] # divide by 0 correction\ndf.loc[df[\"CWalks\"] == 0, \"NEW_WALKS\"] = 0","c8fd0325":"# kariyeri boyunca topa vurma say\u0131s\u0131 ile isabetli vuru\u015f aras\u0131ndaki ili\u015fki\ndf[\"NEW_SUCCESS\"] = (df[\"NEW_HITS\"]+1) * (df[\"NEW_CAT_BAT\"]+1)","a8b3f90b":"#OYUNCUNUN TAKIM ARKADA\u015eINLA YARDIMLA\u015eMASI VE \u0130SABETL\u0130 VURU\u015e SAYISI\ndf[\"NEW_PUT_CHITS\"] = (df[\"PutOuts\"]+0.01) * (df[\"CHits\"]+1)","77041650":"# asist ve tak\u0131m arkada\u015f\u0131\n\ndf[\"NEW_ASIST_PUT\"] = (df[\"Assists\"]+0.01) \/ (df[\"PutOuts\"]+1)\ndf.dropna(inplace = True)","7c01480e":"# hits- error\n\ndf[\"NEW_RUN_ERR\"] = df[\"Hits\"] - df[\"Errors\"]","1159c102":"check_df(df)","2553dc1a":"#kategorik de\u011fi\u015fkenlere d\u00f6n\u00fc\u015ft\u00fcrelim\nbinary_cols = [col for col in df.columns if df[col].dtype not in [int, float]\n               and df[col].nunique() == 2] \n    \nfor col in binary_cols:\n    df = label_encoder(df, col)","88e983d2":"cat_cols, num_cols, cat_but_car = grab_col_names(df)\n# SALARY'i d\u0131\u015far\u0131da b\u0131rakmak istersek:\nnum_cols = [col for col in num_cols if \"Salary\" not in col]","dcdbe674":"rb = RobustScaler()\ndf[num_cols] = rb.fit_transform(df[num_cols])","dfa59bb4":"y = df[\"Salary\"]\nX = df.drop([\"Salary\"], axis=1)","ede1965e":"models = [('LR', LinearRegression()),\n          (\"Ridge\", Ridge()),\n          (\"Lasso\", Lasso()),\n          (\"ElasticNet\", ElasticNet()),\n          ('KNN', KNeighborsRegressor()),\n          ('CART', DecisionTreeRegressor()),\n          ('RF', RandomForestRegressor()),\n          ('SVR', SVR()),\n          ('GBM', GradientBoostingRegressor()),\n          (\"XGBoost\", XGBRegressor(objective='reg:squarederror')),\n          (\"LightGBM\", LGBMRegressor())]\n\nfor name, regressor in models:\n    rmse = np.mean(np.sqrt(-cross_val_score(regressor, X, y, cv=10, scoring=\"neg_mean_squared_error\")))\n    print(f\"RMSE: {round(rmse, 4)} ({name}) \")\n","2776e98f":"cart_params = {'max_depth': range(1, 20), \n               \"min_samples_split\": range(2, 30)}\n\nrf_params = {\"max_depth\": [5, 8, 15, None],\n             \"max_features\": [5, 7, \"auto\"],\n             \"min_samples_split\": [3, 5, 8, 15, 20],\n             \"n_estimators\": [600, 650, 1000]}\n\nlightgbm_params = {\"learning_rate\": [0.001, 0.01, 0.1, 0.001],\n                   \"n_estimators\": [250, 300, 500, 1500, 2500,3000],\n                   \"colsample_bytree\": [0.1, 0.3, 0.5, 0.7, 1]}\n\nregressors = [(\"CART\", DecisionTreeRegressor(), cart_params),\n              (\"RF\", RandomForestRegressor(), rf_params),\n              ('LightGBM', LGBMRegressor(), lightgbm_params)]\n\nbest_models = {}\n\nfor name, regressor, params in regressors:\n    print(f\"########## {name} ##########\")\n    rmse = np.mean(np.sqrt(-cross_val_score(regressor, X, y, cv=10, scoring=\"neg_mean_squared_error\")))\n    print(f\"RMSE: {round(rmse, 4)} ({name}) \")\n\n    gs_best = GridSearchCV(regressor, params, cv=3, n_jobs=-1, verbose=False).fit(X, y)\n\n    final_model = regressor.set_params(**gs_best.best_params_)\n    rmse = np.mean(np.sqrt(-cross_val_score(final_model, X, y, cv=10, scoring=\"neg_mean_squared_error\")))\n    print(f\"RMSE (After): {round(rmse, 4)} ({name}) \")\n\n    print(f\"{name} best params: {gs_best.best_params_}\", end=\"\\n\\n\")\n\n    best_models[name] = final_model","a00d62a5":">  DE\u011e\u0130\u015eKENLER:\n*  AtBat: 1986-1987 sezonunda bir beyzbol sopas\u0131 ile topa yap\u0131lan vuru\u015f say\u0131s\u0131\n*  Hits: 1986-1987 sezonundaki isabet say\u0131s\u0131\n*  HmRun: 1986-1987 sezonundaki en de\u011ferli vuru\u015f say\u0131s\u0131\n*  Runs: 1986-1987 sezonunda tak\u0131m\u0131na kazand\u0131rd\u0131\u011f\u0131 say\u0131\n*  RBI: Bir vurucunun vuru\u015f yapt\u0131g\u0131nda ko\u015fu yapt\u0131rd\u0131\u011f\u0131 oyuncu say\u0131s\u0131\n*  Walks: Kar\u015f\u0131 oyuncuya yapt\u0131r\u0131lan hata say\u0131s\u0131\n*  Years: Oyuncunun major liginde oynama s\u00fcresi (sene)\n*  CAtBat: Oyuncunun kariyeri boyunca topa vurma say\u0131s\u0131\n*  CHits: Oyuncunun kariyeri boyunca yapt\u0131\u011f\u0131 isabetli vuru\u015f say\u0131s\u0131\n*  CHmRun: Oyucunun kariyeri boyunca yapt\u0131\u011f\u0131 en de\u011ferli say\u0131s\u0131\n*  CRuns: Oyuncunun kariyeri boyunca tak\u0131m\u0131na kazand\u0131rd\u0131\u011f\u0131 say\u0131\n*  CRBI: Oyuncunun kariyeri boyunca ko\u015fu yapt\u0131rd\u0131rd\u0131\u011f\u0131 oyuncu say\u0131s\u0131\n*  CWalks: Oyuncun kariyeri boyunca kar\u015f\u0131 oyuncuya yapt\u0131rd\u0131\u011f\u0131 hata say\u0131s\u0131\n*  League: Oyuncunun sezon sonuna kadar oynad\u0131\u011f\u0131 ligi g\u00f6steren A ve N seviyelerine sahip bir fakt\u00f6r\n*  Division: 1986 sonunda oyuncunun oynad\u0131\u011f\u0131 pozisyonu g\u00f6steren E ve W seviyelerine sahip bir fakt\u00f6r\n*  PutOuts: Oyun icinde tak\u0131m arkada\u015f\u0131nla yard\u0131mla\u015fma\n*  Assits: 1986-1987 sezonunda oyuncunun yapt\u0131\u011f\u0131 asist say\u0131s\u0131\n*  Errors: 1986-1987 sezonundaki oyuncunun hata say\u0131s\u0131\n*  Salary: Oyuncunun 1986-1987 sezonunda ald\u0131\u011f\u0131 maa\u015f(bin uzerinden)\n*  NewLeague: 1987 sezonunun ba\u015f\u0131nda oyuncunun ligini g\u00f6steren A ve N seviyelerine sahip bir fakt\u00f6r","f6021cc3":"# Automated Hyperparameter Optimization"}}