{"cell_type":{"7463edf2":"code","7049b3b9":"code","191f2ea3":"code","86867474":"code","0817240c":"code","dbc7e78b":"code","5cebe4bb":"code","c44305df":"code","c48d49e5":"code","f44342b0":"code","5992a51f":"code","e170d4b7":"code","669a21d7":"code","1eadcf98":"code","e4ade753":"markdown"},"source":{"7463edf2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","7049b3b9":"# Constants for FER2013 dataset\nFER2013_PATH = \"\/kaggle\/input\/facialexpressionrecognition\/fer2013.csv\"\nFER2013_WIDTH = 48\nFER2013_HEIGHT = 48","191f2ea3":"data = pd.read_csv(FER2013_PATH)\ndata.head()","86867474":"data.info()","0817240c":"data[\"Usage\"].value_counts()","dbc7e78b":"# Seperate training and public\/private test data\ndata_publ_test = data[data.Usage==\"PublicTest\"]\ndata_priv_test = data[data.Usage==\"PrivateTest\"]\ndata = data[data.Usage==\"Training\"]","5cebe4bb":"Emotions = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]  # indices 0 to 6","c44305df":"data[\"emotion\"].value_counts(sort=False)","c48d49e5":"def fer2013_show_instance(index):\n    \"\"\"Shows the image and the emotion label of the index's instance.\"\"\"\n    image = np.reshape(data.at[index, \"pixels\"].split(\" \"), (FER2013_WIDTH, FER2013_HEIGHT)).astype(\"float\")\n    image -= np.mean(image)\n    image \/= np.std(image)\n    print(Emotions[data.at[index, \"emotion\"]])\n    plt.imshow(image, cmap=\"gray\")","f44342b0":"fer2013_show_instance(np.random.randint(90,len(data)))","5992a51f":"def fer2013_to_X():\n    \"\"\"Transforms the (blank separated) pixel strings in the DataFrame to an 3-dimensional array \n    (1st dim: instances, 2nd and 3rd dims represent 2D image).\"\"\"\n    \n    X = []\n    pixels_list = data[\"pixels\"].values\n    \n    for pixels in pixels_list:\n        single_image = np.reshape(pixels.split(\" \"), (FER2013_WIDTH, FER2013_HEIGHT)).astype(\"float\")\n        X.append(single_image)\n        \n    # Convert list to 4D array:\n    X = np.expand_dims(np.array(X), -1)\n    \n    # Normalize image data:\n    X -= np.mean(X, axis=0)\n    X \/= np.std(X, axis=0)\n    \n    return X\n","e170d4b7":"# Get features (image data)\nX = fer2013_to_X()\nX.shape","669a21d7":"# Get labels (one-hot encoded)\ny = pd.get_dummies(data['emotion']).values\ny.shape","1eadcf98":"# Save data\nnp.save(\"fer2013_X\", X)\nnp.save(\"fer2013_y\", y)","e4ade753":" Import and preprocess data\nDatasets"}}