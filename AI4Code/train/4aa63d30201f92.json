{"cell_type":{"16446dc2":"code","ce5c20c2":"code","ce89da2d":"code","1fbc1950":"code","7ef80065":"code","2e334e9d":"code","83039c23":"code","e46fba02":"code","a8892be0":"code","6be8add5":"code","6e745d9b":"code","bcd7164f":"code","338b041f":"code","dbd1e057":"markdown","1442281b":"markdown","95309894":"markdown","b5807844":"markdown","f47278f7":"markdown","e28f2b03":"markdown","b5c1bbcd":"markdown","a70d9cb8":"markdown","b0f6ce07":"markdown"},"source":{"16446dc2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ce5c20c2":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Load Haberman dataset into panda dataframe\nhaberman = pd.read_csv(\"\/kaggle\/input\/habermans-survival-data-set\/haberman.csv\", names=[\"age\", \"op_year\", \"axil_nodes\", \"surv_status\"])\nhaberman['surv_status'] = haberman['surv_status'].map({1: True, 2: False})\nhaberman","ce89da2d":"# Data points and features\nprint(\"Shape of dataset: {}\".format(haberman.shape))\n\n# Column names in our haberman dataset\nprint(\"columns in dataset {}\".format(haberman.columns))\n\n# Data points for each survival status or\n# People with survival status as 1\/2\ncounts = haberman['surv_status'].value_counts()\nprint(\"Counts per category:\")\nprint(counts)\n\n# Its im-balanced dataset as number of datasets are different","1fbc1950":"# 2D Scatter Plot\nhaberman.plot(kind='scatter', x='age', y='axil_nodes')\nplt.show()","7ef80065":"# 2D scatter plot with color coding by survival status\n# sns: seaborn module\nsns.set_style('whitegrid');\nsns.FacetGrid(haberman, hue='surv_status', height=4).map(plt.scatter, 'age', 'axil_nodes').add_legend();\nplt.show();","2e334e9d":"# lets visualize each each feature.\n# Can be used when number of features are high\n# Cannot be used to visualize 3D, 4D or nD\n# Only 2D pattern can be visualized\n\nplt.close()\nsns.set_style('whitegrid')\nsns.pairplot(haberman, hue='surv_status', height=3)\nplt.show()","83039c23":"# PDF (univariant analysis):\nsns.FacetGrid(haberman, hue='surv_status', height=5).map(sns.distplot, 'axil_nodes').add_legend()\nplt.show()","e46fba02":"sns.FacetGrid(haberman, hue='surv_status', height=5).map(sns.distplot, 'op_year').add_legend()\nplt.show()","a8892be0":"sns.FacetGrid(haberman, hue='surv_status', height=5).map(sns.distplot, 'age').add_legend()\nplt.show()","6be8add5":"# lets ananlyze using CDF;\n# what percentage of patient have auxiliary node less than 2\n\nfor feature in (haberman.columns[:-1]):\n    counts, bin_edges = np.histogram(haberman[feature], bins = 10, density=True)\n    \n    #PDF\n    pdf = counts\/sum(counts)\n    \n    #CDF\n    cdf = np.cumsum(pdf)\n    \n    print(\"PDF: {}\".format(pdf))\n    print(\"CDF: {}\".format(cdf))\n    \n    plt.plot(bin_edges[1:], pdf, label=\"PDF\")\n    plt.plot(bin_edges[1:], cdf, label=\"CDF\")\n    plt.xlabel(feature)\n    plt.legend()\n    plt.show()","6e745d9b":"#Analysis using BOX-WHISKER PLOT\n#We can summarise the following insight using the plot:\n#1. Q1-1.5*IQR\n#2. Q1: 25th Percentile\n#3. Q2: 50th Percentile\n#4. Q3: 75th Percentile\n#5. Q3+1.5*IQR\n\nfig, axes = plt.subplots(1, 3, figsize=(16,5))\nfor idx, feature in enumerate(haberman.columns[:-1]):\n    sns.boxplot(x=haberman.columns[3], y=feature, data=haberman, ax=axes[idx])\nplt.show()","bcd7164f":"fig, axes = plt.subplots(1, 3, figsize=(16,5))\nfor idx, feature in enumerate(haberman.columns[:-1]):\n    sns.violinplot(x=haberman.columns[3], y=feature, data=haberman, ax=axes[idx])\nplt.show()","338b041f":"#Multivariant Analysis\nsns.jointplot(x= 'age',kind = 'kde', y='op_year', data = haberman)\nsns.jointplot(x= 'age',kind = 'kde', y='axil_nodes', data = haberman)\nplt.show()","dbd1e057":"**Observations:**\n1. From year 1959 to 1964 more number of patient with age 45 to 55 undergo opertions.\n1. Patients with age 42 to 65 have auxiliary nodes less\/equal 1.\n\n**Summary:**\n1. More patient have less number number of auxiliary nodes as we see survival status true has more spread observed from pdf and histogram.\n2. 80% patient have less\/equal to 5 positive auxialy node observed using CDF.\n3. 50% of auxiliary nodes are between 0 and 1, 75% of auxiliary nodes are less\/equal to 4.\n4. From 1958 to 1963 patients have slightly high survival rate and from 1963 to 1967 there is low survival rate.\n5. From year 1959 to 1964 more number of patient with age 45 to 55 undergo opertions.\n6. Patients with age 42 to 65 have auxiliary nodes less\/equal 1.\n\n**Conclusion:**\n1. The datasets are not balanced.\n2. There is less number of data points.\n3. Patients aged approx between 45 & 55 and operation in year approx between 1959 & 1963 have slightly high survival rate.\n4. The most informative feature is the auxiliary node.\n5. Patient with greater number of auxiliary node have high probability of death less than 5 years","1442281b":"Observation:<br>\nFrom the above distribution, we observe that,<br>\nMore patient have less number number of auxiliary nodes as we see survival status true has more spread","95309894":"Lets try to analyze the data using Histogram, PDF, CDF.\n\nHistogram: Frequency distribution-- how often each point in a data set occurs.\nPDF: Probability density function-- a statistical method that defines the probability distribution(likely hood of an item) of a descrete random variable. the area under the curve defines the probability of a random variable occuring under that area.\nCDF: Cumulative Density-- Describes that probability of random variable X for a give probability distributionn will be found at a value less than the value x.\nRandom Variable: set of possible values that occurs from a random experiment.","b5807844":"Obeservation:\n1. Total number of plots is 3C2, excluding column survival status which is bieng used to classify.\n2. Auxiliary nodes vs operation year does a better job as compared to other plots.\n3. Its really difficult to analyse as we see a lot of overlapping still.","f47278f7":"**Its im-balanced dataset as number of datasets are different**","e28f2b03":"**Observations:**\n\n1. For the survived patients the distribution is more dense and centered at 0.\n1. 50% of auxiliary nodes are between 0 and 1, 75% of auxiliary nodes are less\/equal to 4.\n1. From 1958 to 1963 patients have slightly high survival rate and from 1963 to 1967 there is low survival rate.","b5c1bbcd":"**Observation:**\n\nIts clear from the above plot, 80% patient have less\/equal to 5 positive auxialy node.","a70d9cb8":"<u><b>Observations:<\/b><\/u>\n1. using age and axi_nodes it's really difficult to distinguish the survival status\n2. Seperating these feature is really hard as they have lots of overlapping","b0f6ce07":"**Observations:**\n1. At point '0' there are lots of data point, hence we can say for most patient the auxiliary node is '0'.\n1. With the smae color it becomes difficult to distinguish, lets color by survival status."}}