{"cell_type":{"6bafc389":"code","33760137":"code","1b1bdc2a":"code","3af4f8f9":"code","4b1d8527":"code","6034f541":"code","e868d8b9":"code","8a7f7a2f":"code","2dba72b8":"code","f5a388ca":"code","ed5e9909":"code","2b2267d9":"code","1e97112d":"code","edb9985c":"code","c5564a1f":"code","f7e4d25f":"code","072523d4":"code","b3b3e0bc":"code","81e649d4":"code","6405b1c2":"code","2eb2d20c":"code","0893abfe":"code","caac2b07":"code","7968cf21":"code","76cefcbd":"code","c46a66c2":"code","84cf6d50":"code","11a46eef":"code","9559fa83":"code","8fc2780e":"code","c28ac5c0":"markdown","a83e681d":"markdown","8b23ea0a":"markdown","02c91085":"markdown","59d6baa1":"markdown","6a92abe9":"markdown","7705d85d":"markdown","21c158e4":"markdown","b22da4d9":"markdown","1d3944da":"markdown","550e4b2e":"markdown"},"source":{"6bafc389":"import pandas as pd #Analysis \nimport matplotlib.pyplot as plt #Visulization\nimport seaborn as sns #Visulization\nimport numpy as np #Analysis \nfrom scipy.stats import norm #Analysis \nfrom sklearn.preprocessing import StandardScaler #Analysis \nfrom scipy import stats #Analysis \nimport warnings \nwarnings.filterwarnings('ignore')\n%matplotlib inline\nimport gc\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error\nimport gc\nimport time\nfrom pandas.core.common import SettingWithCopyWarning\nimport warnings\nimport lightgbm as lgb\nfrom sklearn.model_selection import GroupKFold\n\n# I don't like SettingWithCopyWarnings ...\nwarnings.simplefilter('error', SettingWithCopyWarning)\ngc.enable()\n%matplotlib inline\nimport os","33760137":"df_train = pd.read_csv('..\/input\/week1-exploratory-data-analysis-with-pyhton\/train.csv')\ndf_test  = pd.read_csv('..\/input\/week1-exploratory-data-analysis-with-pyhton\/test.csv')","1b1bdc2a":"len_train = df_train.shape[0]\ndf_all = pd.concat([df_train,df_test])\ncategorical_features = df_all.select_dtypes(include = [\"object\"]).columns\n\nfrequency_encoding_all = df_all.copy()\ndel df_all\n\ndef frequency_encoding(frame, col):\n    freq_encoding = frame.groupby([col]).size()\/frame.shape[0] \n    freq_encoding = freq_encoding.reset_index().rename(columns={0:'{}_Frequency'.format(col)})\n    return frame.merge(freq_encoding, on=col, how='left')\n\nfor col in categorical_features:\n    frequency_encoding_all = frequency_encoding(frequency_encoding_all, col)\n    \nfrequency_encoding_all = frequency_encoding_all.drop(categorical_features ,axis=1, inplace=False)\nfrequency_encoding_train = frequency_encoding_all[:len_train]\nfrequency_encoding_test = frequency_encoding_all[len_train:]\n\ndel frequency_encoding_all;\n\ndef get_folds(df=None, n_splits=5):\n    \"\"\"Returns dataframe indices corresponding to Visitors Group KFold\"\"\"\n    # Get sorted unique visitors\n    unique_vis = np.array(sorted(df['Id'].unique()))\n\n    # Get folds\n    folds = GroupKFold(n_splits=n_splits)\n    fold_ids = []\n    ids = np.arange(df.shape[0])\n    for trn_vis, val_vis in folds.split(X=unique_vis, y=unique_vis, groups=unique_vis):\n        fold_ids.append(\n            [\n                ids[df['Id'].isin(unique_vis[trn_vis])],\n                ids[df['Id'].isin(unique_vis[val_vis])]\n            ]\n        )\n\n    return fold_ids\n\ny_reg = frequency_encoding_train['SalePrice']\ndel frequency_encoding_train['SalePrice']\n\nif 'SalePrice' in frequency_encoding_test.columns:\n    del frequency_encoding_test['SalePrice']\n    \nexcluded_features = ['Id','SalePrice'] \ntest_idx = frequency_encoding_test.Id\n\nsub_reg_preds = 0\nfolds = get_folds(df=frequency_encoding_train, n_splits=5)\n\ntrain_features = [_f for _f in frequency_encoding_train.columns if _f not in excluded_features]\nprint(train_features)\n\nimportances = pd.DataFrame()\noof_reg_preds = np.zeros(frequency_encoding_train.shape[0])\nsub_reg_preds = np.zeros(frequency_encoding_test.shape[0])\nfor fold_, (trn_, val_) in enumerate(folds):\n    trn_x, trn_y = frequency_encoding_train[train_features].iloc[trn_], y_reg.iloc[trn_]\n    val_x, val_y = frequency_encoding_train[train_features].iloc[val_], y_reg.iloc[val_]\n    \n    reg = lgb.LGBMRegressor(\n        num_leaves=31,\n        learning_rate=0.005,\n        n_estimators=5000,\n        subsample=.9,\n        colsample_bytree=.9,\n        random_state=1\n    )\n    reg.fit(\n        trn_x, np.log1p(trn_y),\n        eval_set=[(val_x, np.log1p(val_y))],\n        early_stopping_rounds=50,\n        verbose=100,\n        eval_metric='rmse'\n    )\n    imp_df = pd.DataFrame()\n    imp_df['feature'] = train_features\n    imp_df['gain'] = reg.booster_.feature_importance(importance_type='gain')\n    \n    imp_df['fold'] = fold_ + 1\n    importances = pd.concat([importances, imp_df], axis=0, sort=False)\n    \n    oof_reg_preds[val_] = reg.predict(val_x, num_iteration=reg.best_iteration_)\n    oof_reg_preds[oof_reg_preds < 0] = 0\n    _preds = reg.predict(frequency_encoding_test[train_features], num_iteration=reg.best_iteration_)\n    _preds[_preds < 0] = 0\n    sub_reg_preds += np.expm1(_preds) \/ len(folds)\n    \nmean_squared_error(np.log1p(y_reg), oof_reg_preds) ** .5","3af4f8f9":"frequency_encoding_train['SalePrice'] = y_reg\n\nfrequency_encoding_train.to_csv('Fre_mean_encoding_train.csv', index=False)\nfrequency_encoding_test.to_csv('Fre_mean_encoding_test.csv', index=False)","4b1d8527":"test_pred = pd.DataFrame({\"Id\":test_idx})\ntest_pred[\"SalePrice\"] = sub_reg_preds\ntest_pred.columns = [\"Id\", \"SalePrice\"]\ntest_pred.to_csv(\"Frequency_CV_0.127036.csv\", index=False) # submission","6034f541":"df_train = pd.read_csv('..\/input\/week1-exploratory-data-analysis-with-pyhton\/train.csv')\ndf_test  = pd.read_csv('..\/input\/week1-exploratory-data-analysis-with-pyhton\/test.csv')","e868d8b9":"from sklearn.preprocessing import OneHotEncoder\nlen_train = df_train.shape[0]\ndf_all = pd.concat([df_train,df_test])\ncategorical_features = df_all.select_dtypes(include = [\"object\"]).columns\n\none_hot_encoding = df_all.copy()\none_hot_encoding = pd.get_dummies(one_hot_encoding)\ndel df_all\n\none_hot_encoding_train = one_hot_encoding[:len_train]\none_hot_encoding_test = one_hot_encoding[len_train:]\ndel one_hot_encoding;\n\ndef get_folds(df=None, n_splits=5):\n    \"\"\"Returns dataframe indices corresponding to Visitors Group KFold\"\"\"\n    # Get sorted unique visitors\n    unique_vis = np.array(sorted(df['Id'].unique()))\n\n    # Get folds\n    folds = GroupKFold(n_splits=n_splits)\n    fold_ids = []\n    ids = np.arange(df.shape[0])\n    for trn_vis, val_vis in folds.split(X=unique_vis, y=unique_vis, groups=unique_vis):\n        fold_ids.append(\n            [\n                ids[df['Id'].isin(unique_vis[trn_vis])],\n                ids[df['Id'].isin(unique_vis[val_vis])]\n            ]\n        )\n\n    return fold_ids\n\ny_reg = one_hot_encoding_train['SalePrice']\ndel one_hot_encoding_train['SalePrice']\n\nif 'SalePrice' in one_hot_encoding_test.columns:\n    del one_hot_encoding_test['SalePrice']\n    \nexcluded_features = ['Id','SalePrice'] \ntest_idx = one_hot_encoding_test.Id\n\nsub_reg_preds = 0\nfolds = get_folds(df=one_hot_encoding_train, n_splits=5)\n\ntrain_features = [_f for _f in one_hot_encoding_train.columns if _f not in excluded_features]\nprint(train_features)\n\nimportances = pd.DataFrame()\noof_reg_preds = np.zeros(one_hot_encoding_train.shape[0])\nsub_reg_preds = np.zeros(one_hot_encoding_test.shape[0])\nfor fold_, (trn_, val_) in enumerate(folds):\n    trn_x, trn_y = one_hot_encoding_train[train_features].iloc[trn_], y_reg.iloc[trn_]\n    val_x, val_y = one_hot_encoding_train[train_features].iloc[val_], y_reg.iloc[val_]\n    \n    reg = lgb.LGBMRegressor(\n        num_leaves=31,\n        learning_rate=0.005,\n        n_estimators=5000,\n        subsample=.9,\n        colsample_bytree=.9,\n        random_state=1\n    )\n    reg.fit(\n        trn_x, np.log1p(trn_y),\n        eval_set=[(val_x, np.log1p(val_y))],\n        early_stopping_rounds=50,\n        verbose=100,\n        eval_metric='rmse'\n    )\n    imp_df = pd.DataFrame()\n    imp_df['feature'] = train_features\n    imp_df['gain'] = reg.booster_.feature_importance(importance_type='gain')\n    \n    imp_df['fold'] = fold_ + 1\n    importances = pd.concat([importances, imp_df], axis=0, sort=False)\n    \n    oof_reg_preds[val_] = reg.predict(val_x, num_iteration=reg.best_iteration_)\n    oof_reg_preds[oof_reg_preds < 0] = 0\n    _preds = reg.predict(one_hot_encoding_test[train_features], num_iteration=reg.best_iteration_)\n    _preds[_preds < 0] = 0\n    sub_reg_preds += np.expm1(_preds) \/ len(folds)\n    \nmean_squared_error(np.log1p(y_reg), oof_reg_preds) ** .5","8a7f7a2f":"test_pred = pd.DataFrame({\"Id\":test_idx})\ntest_pred[\"SalePrice\"] = sub_reg_preds\ntest_pred.columns = [\"Id\", \"SalePrice\"]\ntest_pred.to_csv(\"one_hot_encoding_cv_0.127957.csv\", index=False) # submission","2dba72b8":"df_train = pd.read_csv('..\/input\/week1-exploratory-data-analysis-with-pyhton\/train.csv')\ndf_test  = pd.read_csv('..\/input\/week1-exploratory-data-analysis-with-pyhton\/test.csv')","f5a388ca":"len_train = df_train.shape[0]\ndf_all = pd.concat([df_train,df_test])\ncategorical_features = df_all.select_dtypes(include = [\"object\"]).columns\n\nlabel_encoding = df_all.copy()\ndel df_all\nfor i in categorical_features:\n    label_encoding[i], indexer = pd.factorize(label_encoding[i])","ed5e9909":"label_encoding_train = label_encoding[:len_train]\nlabel_encoding_test = label_encoding[len_train:]\ndel label_encoding\n\ndef get_folds(df=None, n_splits=5):\n    \"\"\"Returns dataframe indices corresponding to Visitors Group KFold\"\"\"\n    # Get sorted unique visitors\n    unique_vis = np.array(sorted(df['Id'].unique()))\n\n    # Get folds\n    folds = GroupKFold(n_splits=n_splits)\n    fold_ids = []\n    ids = np.arange(df.shape[0])\n    for trn_vis, val_vis in folds.split(X=unique_vis, y=unique_vis, groups=unique_vis):\n        fold_ids.append(\n            [\n                ids[df['Id'].isin(unique_vis[trn_vis])],\n                ids[df['Id'].isin(unique_vis[val_vis])]\n            ]\n        )\n\n    return fold_ids\n\ny_reg = label_encoding_train['SalePrice']\ndel label_encoding_train['SalePrice']\n\nif 'SalePrice' in label_encoding_test.columns:\n    del label_encoding_test['SalePrice']\n    \nexcluded_features = ['Id','SalePrice'] \ntest_idx = label_encoding_test.Id\n\nsub_reg_preds = 0\nfolds = get_folds(df=label_encoding_train, n_splits=5)\n\ntrain_features = [_f for _f in label_encoding_train.columns if _f not in excluded_features]\nprint(train_features)\n\nimportances = pd.DataFrame()\noof_reg_preds = np.zeros(label_encoding_train.shape[0])\nsub_reg_preds = np.zeros(label_encoding_test.shape[0])\nfor fold_, (trn_, val_) in enumerate(folds):\n    trn_x, trn_y = label_encoding_train[train_features].iloc[trn_], y_reg.iloc[trn_]\n    val_x, val_y = label_encoding_train[train_features].iloc[val_], y_reg.iloc[val_]\n    \n    reg = lgb.LGBMRegressor(\n        num_leaves=31,\n        learning_rate=0.005,\n        n_estimators=5000,\n        subsample=.9,\n        colsample_bytree=.9,\n        random_state=1\n    )\n    reg.fit(\n        trn_x, np.log1p(trn_y),\n        eval_set=[(val_x, np.log1p(val_y))],\n        early_stopping_rounds=50,\n        verbose=100,\n        eval_metric='rmse'\n    )\n    imp_df = pd.DataFrame()\n    imp_df['feature'] = train_features\n    imp_df['gain'] = reg.booster_.feature_importance(importance_type='gain')\n    \n    imp_df['fold'] = fold_ + 1\n    importances = pd.concat([importances, imp_df], axis=0, sort=False)\n    \n    oof_reg_preds[val_] = reg.predict(val_x, num_iteration=reg.best_iteration_)\n    oof_reg_preds[oof_reg_preds < 0] = 0\n    _preds = reg.predict(label_encoding_test[train_features], num_iteration=reg.best_iteration_)\n    _preds[_preds < 0] = 0\n    sub_reg_preds += np.expm1(_preds) \/ len(folds)\n    \nmean_squared_error(np.log1p(y_reg), oof_reg_preds) ** .5","2b2267d9":"test_pred = pd.DataFrame({\"Id\":test_idx})\ntest_pred[\"SalePrice\"] = sub_reg_preds\ntest_pred.columns = [\"Id\", \"SalePrice\"]\ntest_pred.to_csv(\"label_encoding_cv_0.128804.csv\", index=False) # submission","1e97112d":"from sklearn.model_selection import KFold\n\ndef mean_k_fold_encoding(col, alpha):\n    target_name = 'SalePrice'\n    target_mean_global = df_train[target_name].mean()\n    \n    nrows_cat = df_train.groupby(col)[target_name].count()\n    target_means_cats = df_train.groupby(col)[target_name].mean()\n    target_means_cats_adj = (target_means_cats*nrows_cat + \n                             target_mean_global*alpha)\/(nrows_cat+alpha)\n    # Mapping means to test data\n    encoded_col_test = df_test[col].map(target_means_cats_adj)\n    #\uc784\uc758\ub85c \ucd94\uac00 \ud55c \ubd80\ubd84\n    encoded_col_test.fillna(target_mean_global, inplace=True)\n    encoded_col_test.sort_index(inplace=True)\n\n    kfold = KFold(n_splits=5, shuffle=True, random_state=1989)\n    parts = []\n    for trn_inx, val_idx in kfold.split(df_train):\n        df_for_estimation, df_estimated = df_train.iloc[trn_inx], df_train.iloc[val_idx]\n        nrows_cat = df_for_estimation.groupby(col)[target_name].count()\n        target_means_cats = df_for_estimation.groupby(col)[target_name].mean()\n\n        target_means_cats_adj = (target_means_cats * nrows_cat + \n                                target_mean_global * alpha) \/ (nrows_cat + alpha)\n\n        encoded_col_train_part = df_estimated[col].map(target_means_cats_adj)\n        parts.append(encoded_col_train_part)\n        \n    encoded_col_train = pd.concat(parts, axis=0)\n    encoded_col_train.fillna(target_mean_global, inplace=True)\n    encoded_col_train.sort_index(inplace=True)\n    \n    return encoded_col_train, encoded_col_test","edb9985c":"df_train = pd.read_csv('..\/input\/week1-exploratory-data-analysis-with-pyhton\/train.csv')\ndf_test  = pd.read_csv('..\/input\/week1-exploratory-data-analysis-with-pyhton\/test.csv')\nlen_train = df_train.shape[0]\ndf_all = pd.concat([df_train,df_test])\ncategorical_features = df_all.select_dtypes(include = [\"object\"]).columns\n\nmean_encoding = df_all.copy()\ndel df_all\n\nmean_encoding_train = mean_encoding[:len_train]\nmean_encoding_test = mean_encoding[len_train:]\ndel mean_encoding\n\n#del df_all; gc.collect()\nfor col in categorical_features:\n    temp_encoded_tr, temp_encoded_te = mean_k_fold_encoding(col, 5)\n    new_feat_name = 'mean_k_fold_{}'.format(col)\n    mean_encoding_train[new_feat_name] = temp_encoded_tr.values\n    mean_encoding_test[new_feat_name] = temp_encoded_te.values\n    \nmean_encoding_train = mean_encoding_train.drop(categorical_features, axis=1, inplace=False)\nmean_encoding_test = mean_encoding_test.drop(categorical_features, axis=1, inplace=False)\nmean_encoding_train.head()","c5564a1f":"def get_folds(df=None, n_splits=5):\n    \"\"\"Returns dataframe indices corresponding to Visitors Group KFold\"\"\"\n    # Get sorted unique visitors\n    unique_vis = np.array(sorted(df['Id'].unique()))\n\n    # Get folds\n    folds = GroupKFold(n_splits=n_splits)\n    fold_ids = []\n    ids = np.arange(df.shape[0])\n    for trn_vis, val_vis in folds.split(X=unique_vis, y=unique_vis, groups=unique_vis):\n        fold_ids.append(\n            [\n                ids[df['Id'].isin(unique_vis[trn_vis])],\n                ids[df['Id'].isin(unique_vis[val_vis])]\n            ]\n        )\n\n    return fold_ids\n\ny_reg = mean_encoding_train['SalePrice']\ndel mean_encoding_train['SalePrice']\n\nif 'SalePrice' in mean_encoding_test.columns:\n    del mean_encoding_test['SalePrice']\n    \nexcluded_features = ['Id','SalePrice'] \ntest_idx = mean_encoding_test.Id\n\nsub_reg_preds = 0\nfolds = get_folds(df=mean_encoding_train, n_splits=5)\n\ntrain_features = [_f for _f in mean_encoding_train.columns if _f not in excluded_features]\nprint(train_features)\n\nimportances = pd.DataFrame()\noof_reg_preds = np.zeros(mean_encoding_train.shape[0])\nsub_reg_preds = np.zeros(mean_encoding_test.shape[0])\nfor fold_, (trn_, val_) in enumerate(folds):\n    trn_x, trn_y = mean_encoding_train[train_features].iloc[trn_], y_reg.iloc[trn_]\n    val_x, val_y = mean_encoding_train[train_features].iloc[val_], y_reg.iloc[val_]\n    \n    reg = lgb.LGBMRegressor(\n        num_leaves=31,\n        learning_rate=0.005,\n        n_estimators=5000,\n        subsample=.9,\n        colsample_bytree=.9,\n        random_state=1\n    )\n    reg.fit(\n        trn_x, np.log1p(trn_y),\n        eval_set=[(val_x, np.log1p(val_y))],\n        early_stopping_rounds=50,\n        verbose=100,\n        eval_metric='rmse'\n    )\n    imp_df = pd.DataFrame()\n    imp_df['feature'] = train_features\n    imp_df['gain'] = reg.booster_.feature_importance(importance_type='gain')\n    \n    imp_df['fold'] = fold_ + 1\n    importances = pd.concat([importances, imp_df], axis=0, sort=False)\n    \n    oof_reg_preds[val_] = reg.predict(val_x, num_iteration=reg.best_iteration_)\n    oof_reg_preds[oof_reg_preds < 0] = 0\n    _preds = reg.predict(mean_encoding_test[train_features], num_iteration=reg.best_iteration_)\n    _preds[_preds < 0] = 0\n    sub_reg_preds += np.expm1(_preds) \/ len(folds)\n    \nmean_squared_error(np.log1p(y_reg), oof_reg_preds) ** .5","f7e4d25f":"test_pred = pd.DataFrame({\"Id\":test_idx})\ntest_pred[\"SalePrice\"] = sub_reg_preds\ntest_pred.columns = [\"Id\", \"SalePrice\"]\ntest_pred.to_csv(\"mean_encoding_cv_0.127619.csv\", index=False) # submission","072523d4":"df_train = pd.read_csv('..\/input\/week1-exploratory-data-analysis-with-pyhton\/train.csv')\ndf_test  = pd.read_csv('..\/input\/week1-exploratory-data-analysis-with-pyhton\/test.csv')\nlen_train = df_train.shape[0]\ndf_all = pd.concat([df_train,df_test])\ncategorical_features = df_all.select_dtypes(include = [\"object\"]).columns\n\nfrequency_encoding_all = df_all.copy()\ndel df_all\n\ndef frequency_encoding(frame, col):\n    freq_encoding = frame.groupby([col]).size()\/frame.shape[0] \n    freq_encoding = freq_encoding.reset_index().rename(columns={0:'{}_Frequency'.format(col)})\n    return frame.merge(freq_encoding, on=col, how='left')\n\nfor col in categorical_features:\n    frequency_encoding_all = frequency_encoding(frequency_encoding_all, col)\n    \n\nmean_encoding_train = frequency_encoding_all[:len_train]\nmean_encoding_test = frequency_encoding_all[len_train:]\ndel frequency_encoding_all\n\n#del df_all; gc.collect()\nfor col in categorical_features:\n    temp_encoded_tr, temp_encoded_te = mean_k_fold_encoding(col, 5)\n    new_feat_name = 'mean_k_fold_{}'.format(col)\n    mean_encoding_train[new_feat_name] = temp_encoded_tr.values\n    mean_encoding_test[new_feat_name] = temp_encoded_te.values\n    \nmean_encoding_train = mean_encoding_train.drop(categorical_features, axis=1, inplace=False)\nmean_encoding_test = mean_encoding_test.drop(categorical_features, axis=1, inplace=False)\nmean_encoding_train.head()","b3b3e0bc":"def get_folds(df=None, n_splits=5):\n    \"\"\"Returns dataframe indices corresponding to Visitors Group KFold\"\"\"\n    # Get sorted unique visitors\n    unique_vis = np.array(sorted(df['Id'].unique()))\n\n    # Get folds\n    folds = GroupKFold(n_splits=n_splits)\n    fold_ids = []\n    ids = np.arange(df.shape[0])\n    for trn_vis, val_vis in folds.split(X=unique_vis, y=unique_vis, groups=unique_vis):\n        fold_ids.append(\n            [\n                ids[df['Id'].isin(unique_vis[trn_vis])],\n                ids[df['Id'].isin(unique_vis[val_vis])]\n            ]\n        )\n\n    return fold_ids\n\ny_reg = mean_encoding_train['SalePrice']\ndel mean_encoding_train['SalePrice']\n\nif 'SalePrice' in mean_encoding_test.columns:\n    del mean_encoding_test['SalePrice']\n    \nexcluded_features = ['Id','SalePrice'] \ntest_idx = mean_encoding_test.Id\n\nsub_reg_preds = 0\nfolds = get_folds(df=mean_encoding_train, n_splits=5)\n\ntrain_features = [_f for _f in mean_encoding_train.columns if _f not in excluded_features]\nprint(train_features)\n\nimportances = pd.DataFrame()\noof_reg_preds = np.zeros(mean_encoding_train.shape[0])\nsub_reg_preds = np.zeros(mean_encoding_test.shape[0])\nfor fold_, (trn_, val_) in enumerate(folds):\n    trn_x, trn_y = mean_encoding_train[train_features].iloc[trn_], y_reg.iloc[trn_]\n    val_x, val_y = mean_encoding_train[train_features].iloc[val_], y_reg.iloc[val_]\n    \n    reg = lgb.LGBMRegressor(\n        num_leaves=31,\n        learning_rate=0.005,\n        n_estimators=5000,\n        subsample=.9,\n        colsample_bytree=.9,\n        random_state=1\n    )\n    reg.fit(\n        trn_x, np.log1p(trn_y),\n        eval_set=[(val_x, np.log1p(val_y))],\n        early_stopping_rounds=50,\n        verbose=100,\n        eval_metric='rmse'\n    )\n    imp_df = pd.DataFrame()\n    imp_df['feature'] = train_features\n    imp_df['gain'] = reg.booster_.feature_importance(importance_type='gain')\n    \n    imp_df['fold'] = fold_ + 1\n    importances = pd.concat([importances, imp_df], axis=0, sort=False)\n    \n    oof_reg_preds[val_] = reg.predict(val_x, num_iteration=reg.best_iteration_)\n    oof_reg_preds[oof_reg_preds < 0] = 0\n    _preds = reg.predict(mean_encoding_test[train_features], num_iteration=reg.best_iteration_)\n    _preds[_preds < 0] = 0\n    sub_reg_preds += np.expm1(_preds) \/ len(folds)\n    \nmean_squared_error(np.log1p(y_reg), oof_reg_preds) ** .5","81e649d4":"mean_encoding_train['SalePrice'] = y_reg\n\nmean_encoding_train.to_csv('Fre_mean_encoding_train.csv', index=False)\nmean_encoding_test.to_csv('Fre_mean_encoding_test.csv', index=False)","6405b1c2":"test_pred = pd.DataFrame({\"Id\":test_idx})\ntest_pred[\"SalePrice\"] = sub_reg_preds\ntest_pred.columns = [\"Id\", \"SalePrice\"]\ntest_pred.to_csv(\"Fre_mean_encoding_cv_0.127087.csv\", index=False) # submission","2eb2d20c":"df_train = pd.read_csv('..\/input\/week1-exploratory-data-analysis-with-pyhton\/train.csv')\ndf_test  = pd.read_csv('..\/input\/week1-exploratory-data-analysis-with-pyhton\/test.csv')","0893abfe":"len_train = df_train.shape[0]\ndf_all = pd.concat([df_train,df_test])\ncategorical_features = df_all.select_dtypes(include = [\"object\"]).columns\n\nfrequency_encoding_all = df_all.copy()\ndel df_all\n\ndef frequency_encoding(frame, col):\n    freq_encoding = frame.groupby([col]).size()\/frame.shape[0] \n    freq_encoding = freq_encoding.reset_index().rename(columns={0:'{}_Frequency'.format(col)})\n    return frame.merge(freq_encoding, on=col, how='left')\n\nfor col in categorical_features:\n    frequency_encoding_all = frequency_encoding(frequency_encoding_all, col)\n    \nfrequency_encoding_all = frequency_encoding_all.drop(categorical_features ,axis=1, inplace=False)\nfrequency_encoding_train = frequency_encoding_all[:len_train]\nfrequency_encoding_test = frequency_encoding_all[len_train:]\n\ndel frequency_encoding_all;\n\ndef get_folds(df=None, n_splits=10):\n    \"\"\"Returns dataframe indices corresponding to Visitors Group KFold\"\"\"\n    # Get sorted unique visitors\n    unique_vis = np.array(sorted(df['Id'].unique()))\n\n    # Get folds\n    folds = GroupKFold(n_splits=n_splits)\n    fold_ids = []\n    ids = np.arange(df.shape[0])\n    for trn_vis, val_vis in folds.split(X=unique_vis, y=unique_vis, groups=unique_vis):\n        fold_ids.append(\n            [\n                ids[df['Id'].isin(unique_vis[trn_vis])],\n                ids[df['Id'].isin(unique_vis[val_vis])]\n            ]\n        )\n\n    return fold_ids\n\ny_reg = frequency_encoding_train['SalePrice']\ndel frequency_encoding_train['SalePrice']\n\nif 'SalePrice' in frequency_encoding_test.columns:\n    del frequency_encoding_test['SalePrice']\n    \nexcluded_features = ['Id','SalePrice'] \ntest_idx = frequency_encoding_test.Id\n\nsub_reg_preds = 0\nfolds = get_folds(df=frequency_encoding_train, n_splits=10)\n\ntrain_features = [_f for _f in frequency_encoding_train.columns if _f not in excluded_features]\nprint(train_features)\n\nimportances = pd.DataFrame()\noof_reg_preds = np.zeros(frequency_encoding_train.shape[0])\nsub_reg_preds = np.zeros(frequency_encoding_test.shape[0])\nfor fold_, (trn_, val_) in enumerate(folds):\n    trn_x, trn_y = frequency_encoding_train[train_features].iloc[trn_], y_reg.iloc[trn_]\n    val_x, val_y = frequency_encoding_train[train_features].iloc[val_], y_reg.iloc[val_]\n    \n    reg = lgb.LGBMRegressor(\n        num_leaves=31,\n        learning_rate=0.005,\n        n_estimators=5000,\n        subsample=.9,\n        colsample_bytree=.9,\n        random_state=1\n    )\n    reg.fit(\n        trn_x, np.log1p(trn_y),\n        eval_set=[(val_x, np.log1p(val_y))],\n        early_stopping_rounds=50,\n        verbose=100,\n        eval_metric='rmse'\n    )\n    imp_df = pd.DataFrame()\n    imp_df['feature'] = train_features\n    imp_df['gain'] = reg.booster_.feature_importance(importance_type='gain')\n    \n    imp_df['fold'] = fold_ + 1\n    importances = pd.concat([importances, imp_df], axis=0, sort=False)\n    \n    oof_reg_preds[val_] = reg.predict(val_x, num_iteration=reg.best_iteration_)\n    oof_reg_preds[oof_reg_preds < 0] = 0\n    _preds = reg.predict(frequency_encoding_test[train_features], num_iteration=reg.best_iteration_)\n    _preds[_preds < 0] = 0\n    sub_reg_preds += np.expm1(_preds) \/ len(folds)\n    \nmean_squared_error(np.log1p(y_reg), oof_reg_preds) ** .5","caac2b07":"frequency_encoding_train['SalePrice'] = y_reg\n\nfrequency_encoding_train.to_csv('Fre_mean_encoding_train_10.csv', index=False)\nfrequency_encoding_test.to_csv('Fre_mean_encoding_test_10.csv', index=False)\n\ntest_pred = pd.DataFrame({\"Id\":test_idx})\ntest_pred[\"SalePrice\"] = sub_reg_preds\ntest_pred.columns = [\"Id\", \"SalePrice\"]\ntest_pred.to_csv(\"Frequency_CV_0.122660_10.csv\", index=False) # submission","7968cf21":"df_train = pd.read_csv('..\/input\/week1-exploratory-data-analysis-with-pyhton\/train.csv')\ndf_test  = pd.read_csv('..\/input\/week1-exploratory-data-analysis-with-pyhton\/test.csv')","76cefcbd":"from sklearn.preprocessing import OneHotEncoder\nlen_train = df_train.shape[0]\ndf_all = pd.concat([df_train,df_test])\ncategorical_features = df_all.select_dtypes(include = [\"object\"]).columns\n\none_hot_encoding = df_all.copy()\none_hot_encoding = pd.get_dummies(one_hot_encoding)\ndel df_all\n\none_hot_encoding_train = one_hot_encoding[:len_train]\none_hot_encoding_test = one_hot_encoding[len_train:]\ndel one_hot_encoding;\n\ndef get_folds(df=None, n_splits=10):\n    \"\"\"Returns dataframe indices corresponding to Visitors Group KFold\"\"\"\n    # Get sorted unique visitors\n    unique_vis = np.array(sorted(df['Id'].unique()))\n\n    # Get folds\n    folds = GroupKFold(n_splits=n_splits)\n    fold_ids = []\n    ids = np.arange(df.shape[0])\n    for trn_vis, val_vis in folds.split(X=unique_vis, y=unique_vis, groups=unique_vis):\n        fold_ids.append(\n            [\n                ids[df['Id'].isin(unique_vis[trn_vis])],\n                ids[df['Id'].isin(unique_vis[val_vis])]\n            ]\n        )\n\n    return fold_ids\n\ny_reg = one_hot_encoding_train['SalePrice']\ndel one_hot_encoding_train['SalePrice']\n\nif 'SalePrice' in one_hot_encoding_test.columns:\n    del one_hot_encoding_test['SalePrice']\n    \nexcluded_features = ['Id','SalePrice'] \ntest_idx = one_hot_encoding_test.Id\n\nsub_reg_preds = 0\nfolds = get_folds(df=one_hot_encoding_train, n_splits=10)\n\ntrain_features = [_f for _f in one_hot_encoding_train.columns if _f not in excluded_features]\nprint(train_features)\n\nimportances = pd.DataFrame()\noof_reg_preds = np.zeros(one_hot_encoding_train.shape[0])\nsub_reg_preds = np.zeros(one_hot_encoding_test.shape[0])\nfor fold_, (trn_, val_) in enumerate(folds):\n    trn_x, trn_y = one_hot_encoding_train[train_features].iloc[trn_], y_reg.iloc[trn_]\n    val_x, val_y = one_hot_encoding_train[train_features].iloc[val_], y_reg.iloc[val_]\n    \n    reg = lgb.LGBMRegressor(\n        num_leaves=31,\n        learning_rate=0.005,\n        n_estimators=5000,\n        subsample=.9,\n        colsample_bytree=.9,\n        random_state=1\n    )\n    reg.fit(\n        trn_x, np.log1p(trn_y),\n        eval_set=[(val_x, np.log1p(val_y))],\n        early_stopping_rounds=50,\n        verbose=100,\n        eval_metric='rmse'\n    )\n    imp_df = pd.DataFrame()\n    imp_df['feature'] = train_features\n    imp_df['gain'] = reg.booster_.feature_importance(importance_type='gain')\n    \n    imp_df['fold'] = fold_ + 1\n    importances = pd.concat([importances, imp_df], axis=0, sort=False)\n    \n    oof_reg_preds[val_] = reg.predict(val_x, num_iteration=reg.best_iteration_)\n    oof_reg_preds[oof_reg_preds < 0] = 0\n    _preds = reg.predict(one_hot_encoding_test[train_features], num_iteration=reg.best_iteration_)\n    _preds[_preds < 0] = 0\n    sub_reg_preds += np.expm1(_preds) \/ len(folds)\n    \nmean_squared_error(np.log1p(y_reg), oof_reg_preds) ** .5","c46a66c2":"test_pred = pd.DataFrame({\"Id\":test_idx})\ntest_pred[\"SalePrice\"] = sub_reg_preds\ntest_pred.columns = [\"Id\", \"SalePrice\"]\ntest_pred.to_csv(\"one_hot_encoding_cv_0.123044_10.csv\", index=False) # submission","84cf6d50":"df_train = pd.read_csv('..\/input\/week1-exploratory-data-analysis-with-pyhton\/train.csv')\ndf_test  = pd.read_csv('..\/input\/week1-exploratory-data-analysis-with-pyhton\/test.csv')","11a46eef":"len_train = df_train.shape[0]\ndf_all = pd.concat([df_train,df_test])\ncategorical_features = df_all.select_dtypes(include = [\"object\"]).columns\n\nlabel_encoding = df_all.copy()\ndel df_all\nfor i in categorical_features:\n    label_encoding[i], indexer = pd.factorize(label_encoding[i])\n    \nlabel_encoding_train = label_encoding[:len_train]\nlabel_encoding_test = label_encoding[len_train:]\ndel label_encoding\n\ndef get_folds(df=None, n_splits=10):\n    \"\"\"Returns dataframe indices corresponding to Visitors Group KFold\"\"\"\n    # Get sorted unique visitors\n    unique_vis = np.array(sorted(df['Id'].unique()))\n\n    # Get folds\n    folds = GroupKFold(n_splits=n_splits)\n    fold_ids = []\n    ids = np.arange(df.shape[0])\n    for trn_vis, val_vis in folds.split(X=unique_vis, y=unique_vis, groups=unique_vis):\n        fold_ids.append(\n            [\n                ids[df['Id'].isin(unique_vis[trn_vis])],\n                ids[df['Id'].isin(unique_vis[val_vis])]\n            ]\n        )\n\n    return fold_ids\n\ny_reg = label_encoding_train['SalePrice']\ndel label_encoding_train['SalePrice']\n\nif 'SalePrice' in label_encoding_test.columns:\n    del label_encoding_test['SalePrice']\n    \nexcluded_features = ['Id','SalePrice'] \ntest_idx = label_encoding_test.Id\n\nsub_reg_preds = 0\nfolds = get_folds(df=label_encoding_train, n_splits=10)\n\ntrain_features = [_f for _f in label_encoding_train.columns if _f not in excluded_features]\nprint(train_features)\n\nimportances = pd.DataFrame()\noof_reg_preds = np.zeros(label_encoding_train.shape[0])\nsub_reg_preds = np.zeros(label_encoding_test.shape[0])\nfor fold_, (trn_, val_) in enumerate(folds):\n    trn_x, trn_y = label_encoding_train[train_features].iloc[trn_], y_reg.iloc[trn_]\n    val_x, val_y = label_encoding_train[train_features].iloc[val_], y_reg.iloc[val_]\n    \n    reg = lgb.LGBMRegressor(\n        num_leaves=31,\n        learning_rate=0.005,\n        n_estimators=5000,\n        subsample=.9,\n        colsample_bytree=.9,\n        random_state=1\n    )\n    reg.fit(\n        trn_x, np.log1p(trn_y),\n        eval_set=[(val_x, np.log1p(val_y))],\n        early_stopping_rounds=50,\n        verbose=100,\n        eval_metric='rmse'\n    )\n    imp_df = pd.DataFrame()\n    imp_df['feature'] = train_features\n    imp_df['gain'] = reg.booster_.feature_importance(importance_type='gain')\n    \n    imp_df['fold'] = fold_ + 1\n    importances = pd.concat([importances, imp_df], axis=0, sort=False)\n    \n    oof_reg_preds[val_] = reg.predict(val_x, num_iteration=reg.best_iteration_)\n    oof_reg_preds[oof_reg_preds < 0] = 0\n    _preds = reg.predict(label_encoding_test[train_features], num_iteration=reg.best_iteration_)\n    _preds[_preds < 0] = 0\n    sub_reg_preds += np.expm1(_preds) \/ len(folds)\n    \nmean_squared_error(np.log1p(y_reg), oof_reg_preds) ** .5","9559fa83":"label_encoding_train['SalePrice'] = y_reg\n\nlabel_encoding_train.to_csv('label_encoding_train_10.csv', index=False)\nlabel_encoding_test.to_csv('label_encoding_test_10.csv', index=False)","8fc2780e":"test_pred = pd.DataFrame({\"Id\":test_idx})\ntest_pred[\"SalePrice\"] = sub_reg_preds\ntest_pred.columns = [\"Id\", \"SalePrice\"]\ntest_pred.to_csv(\"label_encoding_cv_0.125129_10.csv\", index=False) # submission","c28ac5c0":"### Label Encoding","a83e681d":"### One-hot-encoding","8b23ea0a":"### Frequency Encoding","02c91085":"### Mean encoding","59d6baa1":"# Fold 5 to 10","6a92abe9":"### Frequency + Mean","7705d85d":"### One-Hot-encoding","21c158e4":"|                 |    CV    |    LB   |\n|:---------------:|:--------:|:-------:|\n|    Frequency    | 0.127036 | 0.13041 |\n|     one-hot     | 0.127957 | 0.13068 |\n|       Mean      | 0.127619 | 0.13134 |\n|      Label      | 0.128804 | 0.13009 |\n| Frequency_Label | 0.127087 | 0.13015 |","b22da4d9":"### Frequency Encoding","1d3944da":"### Label Encoding","550e4b2e":"|                 |    CV    |    LB   |\n|:---------------:|:--------:|:-------:|\n|    Frequency    | 0.122660 |  |\n|     one-hot     | 0.123044 |  |\n|      Label      | 0.125129 |  |"}}