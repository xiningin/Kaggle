{"cell_type":{"4a242365":"code","69c0774e":"code","2acf318b":"code","631cdd2d":"code","3a4a582d":"code","00d54ec7":"code","d18ad489":"code","282d9001":"code","26889308":"code","a3f32303":"code","e3832832":"code","95a8bd14":"code","6bb6e457":"code","d9d2d96f":"code","1b97a357":"code","e8be3cd4":"code","f001ec20":"code","75f91e9f":"code","c8587302":"code","2ebef018":"code","e586b412":"code","071ae8e8":"code","ed91bf6a":"code","ea600783":"code","659aa792":"code","07053b96":"code","659dcce2":"code","83a8e6f9":"code","6146c847":"code","04bcdb28":"code","4c1fca66":"code","c51d8717":"code","a94a0c28":"code","0f225845":"code","9a3a27e2":"code","aed4cc1f":"code","856d0d58":"code","ab2085d0":"code","b8ed97f2":"code","3fcd43a4":"code","1dc9dfdd":"code","f315ca11":"code","acdacc4f":"code","e182a9de":"code","05ed269b":"code","49606edf":"code","19564752":"code","b83b8b07":"code","52325927":"code","54631fc6":"code","3972c6b3":"code","de6f118e":"code","7387018a":"code","5236273b":"code","f56f4290":"code","c0b73ac0":"code","25dd9cb4":"code","2b134628":"code","82401b03":"code","6ccf7b58":"code","32d3cf16":"code","2010538e":"code","be8ad0e7":"code","8637b22d":"code","d4792aec":"markdown","34293b04":"markdown","9802b70a":"markdown","fe65dbe3":"markdown","1094c913":"markdown","7848f5a8":"markdown","407c717a":"markdown","587ffcaf":"markdown","c9b3926f":"markdown","0a0795bd":"markdown","e18481b6":"markdown","201e27e6":"markdown","a5b4c46e":"markdown"},"source":{"4a242365":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","69c0774e":"preprocessed = pd.read_csv(\"\/kaggle\/input\/ufcdata\/preprocessed_data.csv\")\nraw_fight= pd.read_csv(\"\/kaggle\/input\/ufcdata\/raw_total_fight_data.csv\")\nraw_fighter= pd.read_csv(\"\/kaggle\/input\/ufcdata\/raw_fighter_details.csv\")\ndata = pd.read_csv(\"\/kaggle\/input\/ufcdata\/data.csv\")","2acf318b":"khabib_r = data['R_fighter'] == \"Khabib Nurmagomedov\"\n\n'''\nfor column in data.columns:\n    print(column)\n    print(data[khabib_r][:1][column])\n    print(\"\/n\/n\")\n'''","631cdd2d":"robert_r = data['R_fighter'] == \"Robert Whittaker\"\n\n'''\nfor column in data.columns:\n    print(column)\n    print(data[robert_r][:1][column])\n    print(\"\/n\/n\")\n'''","3a4a582d":"justin_b = data['B_fighter'] == \"Justin Gaethje\"\n\n'''\nfor column in data.columns:\n    print(column)\n    print(data[justin_b][:1][column])\n    print(\"\/n\/n\")\n'''","00d54ec7":"jared_b = data['B_fighter'] == \"Jared Cannonier\"\n\n'''\nfor column in data.columns:\n    print(column)\n    print(data[jared_b][:1][column])\n    print(\"\/n\/n\")\n'''","d18ad489":"alexander_b = data['B_fighter'] == \"Alexander Volkov\"\n\n'''\nfor column in data.columns:\n    print(data[alexander_b][:1][column])\n    print(\"\/n\/n\")\n'''","282d9001":"walt_r = data['R_fighter'] == \"Walt Harris\"\n\n'''\nfor column in data.columns:\n    print(data[walt_r][:1][column])\n    print(\"\/n\/n\")\n'''","26889308":"connor_b = data['B_fighter'] == \"Conor McGregor\"\n\n'''\nfor column in data.columns:\n    print(data[connor_r][:1][column])\n    print(\"\/n\/n\")\n'''","a3f32303":"dustin_b = data['B_fighter'] == \"Dustin Poirier\"\n\n'''\nfor column in data.columns:\n    print(data[dustin_r][:1][column])\n    print(\"\/n\/n\")\n'''\n","e3832832":"test_dict = {}\ntest_dict_2 = {}\ntest_dict_3 = {}\ntest_dict_4 = {}\n\nfor column in preprocessed.columns:\n    test_dict[column] = 0\n    test_dict_2[column] = 0\n    test_dict_3[column] = 0\n    test_dict_4[column] = 0","95a8bd14":"test_dict_2['title_bout'] = False\ntest_dict_2['no_of_rounds'] = 3\n\n\n\nfor column in preprocessed.columns[:69]:\n    if column in data[jared_b][:1].columns:\n        test_dict_2[column] = data[jared_b][:1][column].values[0]","6bb6e457":"test_dict_3['title_bout'] = False\ntest_dict_3['no_of_rounds'] = 3\n\n\n\nfor column in preprocessed.columns[:69]:\n    if column in data[alexander_b][:1].columns:\n        test_dict_3[column] = data[alexander_b][:1][column].values[0]","d9d2d96f":"test_dict['title_bout'] = True\ntest_dict['no_of_rounds'] = 5\n# Blue: Justin Gaethje.\ntest_dict['B_current_win_streak'] = 4\n\n\n\nfor column in preprocessed.columns[:69]:\n    if column in data[justin_b][:1].columns:\n        test_dict[column] = data[justin_b][:1][column].values[0]","1b97a357":"test_dict_4['title_bout'] = False\ntest_dict_4['no_of_rounds'] = 5\n\n\nfor column in preprocessed.columns[:69]:\n    if column in data[connor_b][:1].columns:\n        test_dict_4[column] = data[connor_b][:1][column].values[0]","e8be3cd4":"for column in preprocessed.columns[69:]:\n    if column in data[khabib_r][:1].columns:\n        test_dict[column] = data[khabib_r][:1][column].values[0]","f001ec20":"for column in preprocessed.columns[69:]:\n    if column in data[robert_r][:1].columns:\n        test_dict_2[column] = data[robert_r][:1][column].values[0]","75f91e9f":"for column in preprocessed.columns[69:]:\n    if column in data[walt_r][:1].columns:\n        test_dict_3[column] = data[walt_r][:1][column].values[0]","c8587302":"for column in preprocessed.columns[69:]:\n    \n    splitted = column.split(\"_\")\n    \n    if len(splitted)>1:\n        if splitted[0] == \"R\":\n            splitted[0] == \"B\"\n        \n        if splitted[0] == \"B\":\n            splitted[0] == \"R\"\n        \n    p_column = \"_\".join(splitted)\n            \n    if column in data[justin_b][:1].columns:\n        test_dict_4[p_column] = data[justin_b][:1][column].values[0]","2ebef018":"test_df = pd.DataFrame([test_dict])\n\ntest_df ","e586b412":"test_df_2 = pd.DataFrame([test_dict_2])\n\ntest_df_2","071ae8e8":"test_df_3 = pd.DataFrame([test_dict_3])\n\ntest_df_3","ed91bf6a":"test_df_4 = pd.DataFrame([test_dict_4])\n\ntest_df_4","ea600783":"test_df_3_x = test_df_3.drop([\"Winner\",\"title_bout\"], axis=1)\n\ntest_df_3_x","659aa792":"test_df_4_x = test_df_4.drop([\"Winner\",\"title_bout\"], axis=1)\n\ntest_df_4_x","07053b96":"test_df_x = test_df.drop([\"Winner\",\"title_bout\"], axis=1)\n\ntest_df_x","659dcce2":"test_df_2_x = test_df_2.drop([\"Winner\",\"title_bout\"], axis=1)\n\ntest_df_2_x","83a8e6f9":"preprocessed['Winner'].value_counts()\n","6146c847":"red = 2380\nblue = 1212","04bcdb28":"y = preprocessed[\"Winner\"]\n\ny_encoded = []\n\nfor label in y:\n    if label == \"Red\":\n        y_encoded.append(0)\n    else:\n        y_encoded.append(1)\n        \nfrom keras.utils import to_categorical\ny_one_hot = to_categorical(y_encoded)\n\nX = preprocessed.drop([\"Winner\",\"title_bout\"], axis=1)\n\n# Remove unneeded Columns\nfor column in preprocessed.columns[137:]:\n    test_df_x.drop([column], axis=1)\n    test_df_2_x.drop([column], axis=1)\n    test_df_3_x.drop([column], axis=1)\n    test_df_4_x.drop([column], axis=1)\n    X.drop([column], axis=1)\n\n\nprint(y_one_hot[:5])","4c1fca66":"print(test_df_x.shape)\nprint(test_df_2_x.shape)\nprint(X.shape)","c51d8717":"from sklearn.model_selection import train_test_split\n\nx_train,x_test,y_train,y_test=train_test_split(X,y_encoded,train_size=0.75)\n\nx_val, x_test, y_val, y_test = train_test_split(x_test,y_test,train_size=0.5)","a94a0c28":"# demonstrate data normalization with sklearn\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\n#feature_range=(0,1)\nscaler = StandardScaler()\n\nscaler.fit(x_train)\n","0f225845":"x_train = scaler.transform(x_train)\nx_val = scaler.transform(x_val)\nx_test = scaler.transform(x_test)\n\ntest_df_x = scaler.transform(test_df_x)\ntest_df_2_x = scaler.transform(test_df_2_x)\ntest_df_3_x = scaler.transform(test_df_3_x)","9a3a27e2":"x_train.shape[-1]","aed4cc1f":"import keras\n\nMETRICS = [\n      keras.metrics.TruePositives(name='tp'),\n      keras.metrics.FalsePositives(name='fp'),\n      keras.metrics.TrueNegatives(name='tn'),\n      keras.metrics.FalseNegatives(name='fn'), \n      keras.metrics.BinaryAccuracy(name='accuracy'),\n      keras.metrics.Precision(name='precision'),\n      keras.metrics.Recall(name='recall'),\n      keras.metrics.AUC(name='auc'),\n]\n","856d0d58":"# Scaling by total\/2 helps keep the loss to a similar magnitude.\n# The sum of the weights of all examples stays the same.\nweight_for_red = (1 \/ red)*(len(preprocessed))\/2.0 \nweight_for_blue = (1 \/ blue)*(len(preprocessed))\/2.0\n\nclass_weight = {0: weight_for_red, 1: weight_for_blue}\n\nprint('Weight for class Red: {:.2f}'.format(weight_for_red))\nprint('Weight for class Blue: {:.2f}'.format(weight_for_blue))\n","ab2085d0":"import tensorflow as tf\nimport keras\n#initializer = lambda i,  dtype, partition_info=None,shape=(x_train.shape[-1],): tf.keras.initializers.GlorotNormal()\n\ndef make_model(metrics = METRICS, output_bias=None, lambda_val= 0.02):\n  if output_bias is not None:\n    output_bias = tf.keras.initializers.Constant(output_bias)\n  model = keras.Sequential([\n      keras.layers.Dense(\n          64, activation='relu',\n          input_shape=(x_train.shape[-1],),\n          kernel_regularizer=keras.regularizers.l2(lambda_val)),\n      keras.layers.Dropout(0.5),\n      keras.layers.BatchNormalization(),\n      keras.layers.Dense(\n          64, activation='relu',\n          kernel_regularizer=keras.regularizers.l2(lambda_val)),\n      keras.layers.Dropout(0.5),\n      keras.layers.BatchNormalization(),\n      keras.layers.Dense(1, activation='sigmoid'),\n      \n  ])\n\n  model.compile(\n      optimizer=keras.optimizers.Adam(lr=0.0001),\n      loss=keras.losses.BinaryCrossentropy(),\n      metrics=metrics)\n\n  print(model.summary())\n  return model","b8ed97f2":"\nEPOCHS = 120\nBATCH_SIZE = 32\nVERBOSE = 1\n\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', \n    verbose=VERBOSE,\n    patience=8,\n    restore_best_weights=True)\n\nweighted_model = make_model()\n\nweighted_history = weighted_model.fit(\n    x_train,\n    y_train,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    callbacks = [early_stopping],\n    validation_data=(x_val, y_val),\n    # The class weights go here\n    class_weight=class_weight,\n    verbose=VERBOSE) \n","3fcd43a4":"\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\ncolors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n\n\ndef plot_loss(history, label, n):\n  # Use a log scale to show the wide range of values.\n  plt.semilogy(history.epoch,  history.history['loss'],\n               color=colors[n], label='Train '+label)\n  plt.semilogy(history.epoch,  history.history['val_loss'],\n          color=colors[n], label='Val '+label,\n          linestyle=\"--\")\n  plt.xlabel('Epoch')\n  plt.ylabel('Loss')\n  \n  plt.legend()\n","1dc9dfdd":"plot_loss(weighted_history, \"loss\", 0)","f315ca11":"def plot_metrics(history):\n  metrics =  ['loss', 'recall', 'precision', 'auc']\n  for n, metric in enumerate(metrics):\n    name = metric.replace(\"_\",\" \").capitalize()\n    plt.subplot(2,2,n+1)\n    plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n    plt.plot(history.epoch, history.history['val_'+metric],\n             color=colors[0], linestyle=\"--\", label='Val')\n    plt.xlabel('Epoch')\n    plt.ylabel(name)\n    if metric == 'loss':\n      plt.ylim([0, plt.ylim()[1]])\n    elif metric == 'auc':\n      plt.ylim([0.5,1])\n    else:\n      plt.ylim([0,1])\n\n    plt.legend()\n","acdacc4f":"plot_metrics(weighted_history)","e182a9de":"def plot_cm(labels, predictions, p=0.5):\n  cm = confusion_matrix(labels, predictions > p)\n  plt.figure(figsize=(5,5))\n  sns.heatmap(cm, annot=True, fmt=\"d\")\n  plt.title('Confusion matrix @{:.2f}'.format(p))\n  plt.ylabel('Actual label')\n  plt.xlabel('Predicted label')\n\n  print('Blue Wins Detected (True Negatives): ', cm[0][0])\n  print('Blue Wins Incorrectly Detected (False Positives): ', cm[0][1])\n  print('Red Win Missed (False Negatives): ', cm[1][0])\n  print('Red Win Detected (True Positives): ', cm[1][1])\n  print('Total Misclassification: ', np.sum(cm[1]))\n","05ed269b":"y_pred= weighted_model.predict(x_test)","49606edf":"\nfrom sklearn.metrics import confusion_matrix\nplot_cm(y_test, y_pred)\n\n","19564752":"baseline_results = weighted_model.evaluate(x_test, y_test,\n                                  batch_size=BATCH_SIZE, verbose=0)\nfor name, value in zip(weighted_model.metrics_names, baseline_results):\n  print(name, ': ', value)\nprint()\n","b83b8b07":"# apply threshold to positive probabilities to create labels\ndef to_labels(pos_probs, threshold):\n\treturn (pos_probs >= threshold).astype('int')","52325927":"from sklearn.metrics import f1_score\n\ny_pred_max = np.argmax(y_pred, axis = 1)\n#y_test_max = np.argmax(y_test, axis = 1)\n\nprint(f1_score(y_test,to_labels(y_pred, 0.5)))","54631fc6":"thresholds = []\nfor n in range(0,100):\n    thresholds.append(n\/100)\n\nscores = [f1_score(y_test, to_labels(y_pred, t)) for t in thresholds]","3972c6b3":"print(\"Best Threshold:\", thresholds[np.argmax(scores)])\nprint(\"Best F1:\",scores[np.argmax(scores)] )\n\nbest_threshold = thresholds[np.argmax(scores)]","de6f118e":"plot_cm(y_test, y_pred, p=best_threshold)","7387018a":"ind_pred = weighted_model.predict(test_df_x)","5236273b":"ind_pred[0][0]","f56f4290":"ind_pred_2 = weighted_model.predict(test_df_2_x)","c0b73ac0":"ind_pred_2","25dd9cb4":"ind_pred_3 = weighted_model.predict(test_df_3_x)","2b134628":"ind_pred_3","82401b03":"ind_pred_4 = weighted_model.predict(test_df_4_x)","6ccf7b58":"ind_pred_4","32d3cf16":"\nif ind_pred[0][0] < best_threshold:\n    print(\"Red Wins: Khabib Nurmagomedov wins over Justin Gaethje\")\nelse:\n    print(\"Blue Wins: Justin Gaethje wins over Khabib Nurmagomedov\")","2010538e":"\nif ind_pred_2[0][0] < best_threshold:\n    print(\"Red Wins: Robert Whittaker wins over Jared Cannonier\")\nelse:\n    print(\"Blue Wins: Jared Cannonier wins over Robert Whittaker\")","be8ad0e7":"\nif ind_pred_3[0][0] < best_threshold:\n    print(\"Red Wins: Walt Harris wins over Alexander Volkov\")\nelse:\n    print(\"Blue Wins: Alexander Volkov wins over Walt Harris\")","8637b22d":"if ind_pred_4[0][0] < best_threshold:\n    print(\"Red Wins: Dustin Poirier wins over Conor Mcgregor\")\nelse:\n    print(\"Blue Wins: Conor Mcgregor wins over Dustin Poirier\")","d4792aec":"### Set Class Weights (For class imbalance)","34293b04":"### Get ratio of class imbalance","9802b70a":"### Preparing Fighter's Data for predicting future events","fe65dbe3":"## Final Prediction\n\n**Note:** This is not a financial advice. The prediction made in this section is lacking fighter data from the year 2020. It is utilizing figther's data up to the year 2019.","1094c913":"### Feed Forward Neural Network","7848f5a8":"### UFC254: Robert vs Jared","407c717a":"### UFC254: Alexander vs Walt","587ffcaf":"### UFC254: Khabib vs Justin","c9b3926f":"### Train\/Val\/Test Split","0a0795bd":"### Unconfirmed Event: Connor vs Dustin","e18481b6":"### Normalize numerical values","201e27e6":"The Winner will be our Target Variable:","a5b4c46e":"### Model Architecture"}}