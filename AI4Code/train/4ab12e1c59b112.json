{"cell_type":{"344f8f38":"code","1b6e7a6b":"code","9e7ed390":"code","baa88c55":"code","4872e62a":"code","f80139b7":"code","a70bb764":"code","972f7003":"code","b31199c8":"code","2f496e5d":"code","7272f5dd":"code","b7e295ea":"code","db08e31b":"code","ef6bf66f":"code","77d8433f":"code","0c69d9c6":"code","6a60c767":"code","ffb954c8":"code","abe7364d":"code","3a15346d":"code","f1bee831":"code","26d634e5":"code","a8db5beb":"code","acf140ea":"code","6e470d95":"code","a203da56":"code","25d4f7b3":"code","bb9b4b5b":"code","8bf7e352":"code","5c06390c":"code","c593b2d3":"code","92de41a2":"code","dbcab254":"code","cb10c150":"code","510708c3":"code","34003768":"code","65597254":"code","5a8c9abc":"code","4a426eda":"code","7bcd6241":"code","b91d1292":"markdown","cb4cbfbf":"markdown","c111379b":"markdown","cd0a3bc6":"markdown","37359c3b":"markdown","f5cb6337":"markdown","b7024ff6":"markdown","c565c9d0":"markdown","9350c0b4":"markdown","c82d3d29":"markdown","bc543f74":"markdown","1f6c651b":"markdown","57c2bb05":"markdown","369c9eb5":"markdown","54d448fd":"markdown","07a47d69":"markdown","86f90634":"markdown","579f5f9b":"markdown","ce9d00b8":"markdown","5368493d":"markdown"},"source":{"344f8f38":"![ -d \/kaggle\/input\/release-2021-v1\/augeropendata ] && [ ! -d augeropendata ] && ln -s \/kaggle\/input\/release-2021-v1\/augeropendata augeropendata  # kaggle specific linking dataset to augeropendata directory","1b6e7a6b":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport math\nfrom scipy.optimize import curve_fit\nimport scipy.stats\nfrom IPython.display import HTML\nimport numpy.polynomial.polynomial as poly\nLegendFontSize=20\nLabelFontSize= 20\nTickFontSize= 15","9e7ed390":"# Jupyter\/ IPython formatting\nfrom IPython.display import Math, Latex, display","baa88c55":"# Default values for plots\nplt.rcParams[\"figure.figsize\"] = [11, 6.94] # figure width and height\nplt.rcParams[\"font.size\"] = 20","4872e62a":"# Data loading, encapsulated to make it less installation and OS dependant\nimport os.path\nfrom zipfile import ZipFile\ndef AugerOpen(fdir, file):\n    \"\"\"\n    Loads a file from the auger open data release. Can be either in the local directory,\n    in the parent directory or in the augeropendata directory.\n    File is identified by it directory *fdir* and filename *file* and can be found in the directory\n    or in a zip file.\n    \"\"\"\n    for loc in [\".\", \"..\", \"augeropendata\", \"data\"]:\n        fname = os.path.join(loc, fdir, file)\n        if os.path.isfile(fname):\n            return open(fname)\n        zname=os.path.join(loc, fdir + \".zip\")\n        if os.path.isfile(zname):\n            with ZipFile(zname) as myzip:\n                return myzip.open(os.path.join(fdir, file))\n    raise FileNotFoundError(os.path.join(fdir, file))","f80139b7":"data = pd.read_csv(AugerOpen('summary', 'dataSummary.csv'))\ndata['lgE'] = np.log10(data['fd_totalEnergy']) + 18 # units: lg(E\/eV)","a70bb764":"xmax_data = data[(data.fd_hdXmaxEye == 1)].copy() # copy so we can add columns later\n\ngrouped_xmax_data = xmax_data.groupby('id')\nunique_xmax_data = xmax_data.drop_duplicates('id').set_index('id')\n\nn_events = len(xmax_data)\nn_unique = len(unique_xmax_data)\n\ndisplay(Latex(f'''Read {n_events} Xmax events of which {n_unique} are unique.\n    The total number of FD events (counting multi-eye events as multiple events) is {n_events}.'''))","972f7003":"## Calculate weights: w = 1\/uncertainty^2\nxmax_data['fd_e_weight'] = 1 \/ np.square(xmax_data.fd_dtotalEnergy)\nxmax_data['fd_xmax_weight'] = 1 \/ np.square(xmax_data.fd_dxmax)\n## Calculate value * w\nxmax_data['fd_e_weighted'] = xmax_data.fd_totalEnergy * xmax_data.fd_e_weight\nxmax_data['fd_xmax_weighted'] = xmax_data.fd_xmax * xmax_data.fd_xmax_weight\n\n# average of energies\nsum_of_e_weights = grouped_xmax_data['fd_e_weight'].sum()\nfd_avg_e = grouped_xmax_data['fd_e_weighted'].sum() \/ sum_of_e_weights \nunique_xmax_data['fd_avg_lgE'] = np.log10(fd_avg_e*1e18)\nfd_davg_e = 1 \/ np.sqrt(sum_of_e_weights)\nfd_davg_lge = fd_davg_e \/ fd_avg_e \/ np.log(10.)\nunique_xmax_data['fd_davg_lgE'] = fd_davg_lge\n\n# average of Xmax\nsum_of_xmax_weights = grouped_xmax_data['fd_xmax_weight'].sum()\nfd_avg_xmax = grouped_xmax_data['fd_xmax_weighted'].sum() \/ sum_of_xmax_weights \nunique_xmax_data['fd_avg_xmax'] = fd_avg_xmax\nfd_davg_xmax = 1 \/ np.sqrt(sum_of_xmax_weights)\nunique_xmax_data['fd_davg_xmax'] = fd_davg_xmax","b31199c8":"fig = plt.figure()\n\nx = unique_xmax_data['fd_avg_lgE']\ny = unique_xmax_data['fd_avg_xmax'] \nxerr = unique_xmax_data['fd_davg_lgE']\nyerr = unique_xmax_data['fd_davg_xmax']\nplt.errorbar(x, y, xerr=xerr, yerr=yerr, label='both limits (default)', fmt='.',\n             color= 'black', ecolor='gray', mfc='white', alpha=0.8)\nplt.ylabel(r'$X_\\mathrm{max}$\/(g\/cm$^{2}$)')\nplt.xlabel(r'$\\lg(E\/\\mathrm{eV})$')\nplt.show()","2f496e5d":"lge_max = np.amax(unique_xmax_data['fd_avg_lgE'])\nEbins = [17.8, 17.9, 18.0, 18.1, 18.2, 18.3, 18.4, 18.5, 18.6, 18.7, 18.8, 18.9, 19.0, 19.2, 19.4, \n         (int(lge_max*10)+1)\/10.]\ndisplay(Latex(f'The maximum energy in this data set is lg(E\/eV) = {lge_max:7.2f}.'))","7272f5dd":"plt.figure(num=None, dpi=70, facecolor='w', edgecolor='k')\nplt.hist(unique_xmax_data['fd_avg_lgE'], bins=Ebins, color='black', histtype='step',\n         linewidth=2, label=f\"{len(unique_xmax_data['fd_avg_lgE'])} events\")\nplt.xlabel('lg(E\/eV)', fontsize=LabelFontSize)\nplt.xticks(fontsize=TickFontSize)\nplt.yticks(fontsize=TickFontSize)\nplt.legend(fontsize=LegendFontSize)\nplt.yscale('log')\nplt.show()","b7e295ea":"# look into numpyification\ndef GetRawXmaxMoments(Ebins,lgEList,XmaxList):\n    \"\"\"\n    Stores the list of Xmax values for each energy bin.\n    Calculates the raw Xmax moments and their errors.\n    Conveniently organize all the data in a Dictionary called 'Moments'.\n\n    'Moments' is a dictionary that contains for each energy bin:\n     \n   * A list of Xmax values\n   * Xmax moments and their errors (without correcting for the Xmax acceptance or resolution)\n   * number of events\n   * mean energy\n   * systematic uncertainties\n   \n    \"\"\"\n    \n    MeanXmaxList = []\n    SigmaList = []\n    MeanXmaxErrList = []\n    SigmaErrList = []\n    MeanLgEList = []\n    NevtsList = []\n    XmaxDistList = []\n  \n    \n    for E1, E2 in zip(Ebins[:-1], Ebins[1:]): \n        ECut = (E1 <= lgEList) & (lgEList < E2)\n        \n        lgEmean = lgEList[ECut].mean() \n        Nevts = len(lgEList[ECut])\n\n        XmaxMean = np.mean(XmaxList[ECut])\n        SigmaXmax = np.std(XmaxList[ECut])\n        MeanErr =  SigmaXmax \/ np.sqrt(Nevts)\n        \n        # uncertainty of the standard deviation\n        # (Gaussian approximation, a more accurate estimate uses the fourth\n        # central moment, see Particle Data Group)\n        SigmaErr = SigmaXmax \/ np.sqrt(2*Nevts)\n        \n        MeanLgEList.append(lgEmean)\n        NevtsList.append(Nevts)\n        \n        XmaxDistList.append(XmaxList[ECut])\n        \n        MeanXmaxList.append(XmaxMean)\n        SigmaList.append(SigmaXmax)\n        MeanXmaxErrList.append(MeanErr)\n        SigmaErrList.append(SigmaErr)\n        \n    Moments = {'raw':{'mean': np.asanyarray(MeanXmaxList), \n                      'meanErr': np.asanyarray(MeanXmaxErrList),\n                      'sigma': np.asanyarray(SigmaList),\n                      'sigmaErr': np.asanyarray(SigmaErrList),\n                      'Emean': np.asanyarray(MeanLgEList),\n                      'Nevts': np.asanyarray(NevtsList)\n                     },\n               'distributions': XmaxDistList\n              }\n        \n    return Moments","db08e31b":"Moments = GetRawXmaxMoments(Ebins,unique_xmax_data['fd_avg_lgE'],unique_xmax_data['fd_avg_xmax'])","ef6bf66f":"x = Moments['raw']['Emean'] \ny = Moments['raw']['mean'] \nyerr = Moments['raw']['meanErr']\n\nplt.errorbar(x, y, yerr, linestyle='none', marker='o', color='black')\nplt.ylabel(r'$\\langle X_\\mathrm{max}\\rangle$\/(g\/cm$^{2}$)')\nplt.xlabel(r'$\\lg(E\/\\mathrm{eV})$')\nplt.ylim(700, 820)\nplt.show()","77d8433f":"x = Moments['raw']['Emean'] \ny = Moments['raw']['sigma'] \nyerr = Moments['raw']['sigmaErr']\n\nplt.errorbar(x, y, yerr, linestyle='none', marker='o', color='black')\nplt.ylabel(r'$\\sigma_\\mathrm{raw}(X_\\mathrm{max})$\/(g\/cm$^{2}$)')\nplt.xlabel(r'$\\lg(E\/\\mathrm{eV})$')\nplt.ylim(0, 70)\nplt.show()","0c69d9c6":"StringEnergyRange1 = r'${} \\leq \\mathrm{{lg}}(E\/\\mathrm{{eV}})$'\nStringEnergyRange =  r'${} \\leq \\mathrm{{lg}}(E\/\\mathrm{{eV}}) < {}$'\n\n\ndef PlotXmaxdistributions(Moments,version,Ebins,mode):\n\n    \"\"\" Plot the Xmax distribution for each energy bin \"\"\"\n    \n    MeanLgEList = Moments[version]['Emean']\n    XmaxDist = Moments['distributions']\n    Nevts = Moments[version]['Nevts']\n    XmaxMean = Moments[version]['mean']\n    SigmaXmax = Moments[version]['sigma']\n    \n    BinSize = 20\n    XmaxMin = 320.\n    XmaxMax = 1400.\n    Nbins = np.int((XmaxMax - XmaxMin)\/BinSize)\n    \n\n\n    NEbins = len(Ebins) - 1\n    Ncol = 4\n    \n    if (NEbins % Ncol):\n        Nrows = 1 + int (NEbins\/Ncol)\n    else:\n        Nrows = NEbins \/ Ncol \n\n    \n    plt.figure(num=None, figsize=(18, Nrows*Ncol*0.6), dpi=80, facecolor='w', edgecolor='k')\n    plt.subplots_adjust(hspace=0.1) \n    for i, E1 in enumerate(MeanLgEList):\n        \n        plt.subplot(Nrows, Ncol, i+1)\n        HistWithCutsRecCorr = plt.hist(XmaxDist[i], density=False,\n                                       range=[XmaxMin, XmaxMax], bins=Nbins,\n                                       histtype='step', label='',\n                                       color='black', linewidth=2)\n        \n        if (mode == 'open'):  #open limit for last energy bin\n            if (i == len(MeanLgEList)-1):\n                PlotTitle = StringEnergyRange1.format(Ebins[i])\n            else:\n                PlotTitle = StringEnergyRange.format(Ebins[i], Ebins[i+1])\n        else:\n            PlotTitle = StringEnergyRange.format(Ebins[i], Ebins[i+1])\n            \n        \n        NEvtsString = f'N = {Nevts[i]}'\n    \n        ymax = 1.2 * HistWithCutsRecCorr[0].max()\n        plt.locator_params(axis='y', nbins=6)  \n        plt.ylim(0, 1.1*ymax)\n        plt.xlim(400, 1100)\n    \n        plt.text(500, 0.86*ymax, PlotTitle, \n                 verticalalignment='bottom', horizontalalignment='left',\n                 color='black', fontsize=15)\n    \n        plt.text(850, 0.55*ymax, NEvtsString,\n                 verticalalignment='bottom', horizontalalignment='left',\n                 color='black', fontsize=15)\n    \n       \n        plt.xticks(fontsize=15)\n        plt.yticks(fontsize=16)\n        plt.xlim(420, 1080)\n        if (i < NEbins - Ncol):\n            frame1 = plt.gca()\n            frame1.axes.xaxis.set_ticklabels([])\n            \n        if (i == Ncol*(int(Nrows\/2) - 0)): \n            plt.ylabel(r'entries \/ (20 g\/cm$^{2}$)', fontsize=25)\n            \n        if (i >= NEbins - Ncol):\n            for tick in frame1.axes.xaxis.get_major_ticks():\n                tick.label.set_fontsize(14) \n                tick.label.set_rotation('vertical')\n            \n            plt.xlabel(r'$\\mathrm{X_{max}} \\mathrm{[g\/cm^2]}$', fontsize=25 )\n           \n        plt.minorticks_on()\n\n    return","6a60c767":"#mode='open'   # open limits for last energy bin\nmode = 'close' # closed limits for last energy bin\nversion = 'raw'\nPlotXmaxdistributions(Moments, version, Ebins,mode)\nplt.show()","ffb954c8":"def BrokenLine(lgEArray, XBreak, slope1, slope2, lgE0):\n    slope = np.where(lgEArray < lgE0, slope1, slope2)\n    return XBreak + slope*(lgEArray - lgE0)\n\ndef PlotBrokenLineFit(Moments, version):\n    DataLabel = r'data $\\pm$ $\\sigma_{\\mathrm{stat}}$'    \n\n    MeanLgE = Moments[version]['Emean']\n    MeanXmax = Moments[version]['mean']\n    MeanXmaxErr = Moments[version]['meanErr'] \n    \n    plt.errorbar(MeanLgE, MeanXmax, MeanXmaxErr, linestyle='none', marker='o', color= 'black')\n    plt.ylabel(r'$\\langle X_\\mathrm{max}\\rangle$\/(g\/cm$^{2}$)')\n    plt.xlabel(r'$\\lg(E\/\\mathrm{eV})$')\n\n    \n\n    pIn=[750, 70., 25, 18.3]\n    poptX2, pcovX2 = curve_fit(BrokenLine, MeanLgE, MeanXmax,p0=pIn,\n                               sigma=MeanXmaxErr, absolute_sigma=True)\n    \n    pX2err = np.sqrt(np.diag(pcovX2))\n\n    XmaxAtBreak, ER1, ER2, E_break = poptX2\n    XmaxAtBreak_Err, ER1_Err, ER2_Err, E_break_Err = pX2err\n    \n    print( f'             ER1 = {ER1:5.0f} +- {ER1_Err:4.0f} g\/cm^2')\n    print( f'             ER2 = {ER2:5.0f} +- {ER2_Err:4.0f} g\/cm^2')\n    print( f'  lg(E_break\/eV) = {E_break:5.2f} +- {E_break_Err:4.2f}')\n    print( f'<Xmax> @ E_break = {XmaxAtBreak:5.0f} +- {XmaxAtBreak_Err:4.0f} g\/cm^2')\n    \n    #LabelER1 = f'ER$_1 = ({ER1} \\\\pm {ER1_Err})\\,\\mathrm{{g\/cm^2}}$\/decade'\n    LabelER1b = f'$({ER1:.0f} \\\\pm {ER1_Err:.0f})\\,\\mathrm{{g\/cm^2}}$\/decade'\n\n    #LabelER2 = f'ER$_2 = ({ER2} \\\\pm {ER2_Err})\\,\\mathrm{{g\/cm^2}}$\/decade'\n    LabelER2b = f'$({ER2:.0f} \\\\pm {ER2_Err:.0f})\\,\\mathrm{{g\/cm^2}}$\/decade'\n    \n    x = np.arange(17.2, 19.8, 0.01)\n    plt.plot(x, BrokenLine(x, *poptX2), '-', color='red', linewidth=2, label='broken line fit')\n  \n    plt.text(poptX2[3] - 0.8, poptX2[0]-40, LabelER1b, style='italic',\n             fontsize=15, color='red', rotation=40)\n    plt.text(poptX2[3] + 0.2,poptX2[0]+30, LabelER2b, style='italic',\n             fontsize=15, color='red', rotation=10)\n\n\n    plt.xticks(fontsize=TickFontSize)\n    plt.yticks(fontsize=TickFontSize)\n    \n    plt.legend(loc=1, fontsize=LegendFontSize, numpoints=1, ncol=1, frameon=False)\n    plt.tight_layout()\n\n    return","abe7364d":"version= \"raw\"\nBlackAndWhite = True\n\nPlotBrokenLineFit(Moments, version)\n\nplt.ylim(650, 850)\nplt.show()","3a15346d":"resolution = pd.read_csv(AugerOpen('auxiliary', 'fdXmaxResolution.csv'))","f1bee831":"# needs numpyification\ndef GetXmaxResolution(resolution):\n    \"\"\"\"\n    Reads the coefficients for the Xmax resolution parametrization at each energy bin\n    and calculates the resolution for each energy bin. It also calculates the uncertainty\n    bands for the resolution.\n    \n    \"\"\"\n    ResoList = []\n    ResoPlus = []\n    ResoMinus = []\n    EnBin = np.asanyarray(resolution['lgMinEnergy']) + 0.05 \n    \n    for ii, Ebin in enumerate(EnBin):\n        k = resolution['f'][ii]\n        sigma1 = resolution['sigma1'][ii]\n        sigma2 = resolution['sigma2'][ii]\n        V = k * sigma1*sigma1 + (1 - k) * sigma2*sigma2\n        reso = np.sqrt(V)\n        \n        sigma1Err = resolution['sigma1Err'][ii]\n        sigma2Err = resolution['sigma2Err'][ii]\n        \n        V_plus = k * (sigma1+sigma1Err)*(sigma1+sigma1Err) + \\\n            (1 - k) * (sigma2+sigma2Err)*(sigma2+sigma2Err) \n        reso_plus = np.sqrt(V_plus)\n        \n        V_minus = k * (sigma1-sigma1Err)*(sigma1-sigma1Err) + \\\n            (1 - k) * (sigma2-sigma2Err)*(sigma2-sigma2Err) \n        reso_minus=np.sqrt(V_minus)\n        \n        \n        ResoList.append(reso)\n        ResoPlus.append(reso_plus)\n        ResoMinus.append(reso_minus)\n    return [np.asanyarray(ResoList),  np.asanyarray(ResoPlus),\n            np.asanyarray(ResoMinus), EnBin]\n\ndef GetXmaxResoFunc(resolution):\n    \"\"\" Fits a function to the Xmax resolution Vs energy \"\"\"\n    ResoList = GetXmaxResolution(resolution)\n    Ebins = ResoList[3]\n    Reso = ResoList[0]\n    x = np.asanyarray(Ebins)\n    x = x.tolist()\n    x.append(20)\n    y = Reso\n    y = y.tolist()\n    y.append(Reso[-1])\n    y = np.asanyarray(y)\n    z = np.polyfit(x, y, 4)\n    z = z[::-1]\n    ResoFunc = poly.Polynomial(z)\n    return ResoFunc\n","26d634e5":"# The Xmax resolution as a function of energy\n\nResoFunc = GetXmaxResoFunc(resolution)\n\nplt.figure(num=None, figsize=(10, 5), dpi=80, facecolor='w', edgecolor='k')\n\nlgE = np.arange(17.8, 19.8, 0.05)\nplt.plot(lgE, ResoFunc(lgE), color='black', label='total')\nplt.legend(loc='best', fontsize=LegendFontSize, numpoints=1, ncol=2, frameon=False)\nplt.ylabel(r'$\\mathrm{X_{max}}$  resolution $\\mathrm{[g\/cm^2]}$', fontsize=LabelFontSize)\nplt.ylim(10, 30)\nplt.show()","a8db5beb":"def CorrectForResolution(MomentsDict, ResoFunc):\n    \"\"\" The Xmax resolution is substracted in quadrature from the raw sigma(Xmax) \"\"\"\n    \n    lgE = MomentsDict['raw']['Emean']\n    xmaxReso = ResoFunc(lgE)\n    sigma = MomentsDict['raw']['sigma']\n    sigmaErr = MomentsDict['raw']['sigmaErr']\n    sigmaCorrected = np.sqrt(sigma*sigma - xmaxReso*xmaxReso)\n    MomentsDict[version]['sigmaCorrected'] = sigmaCorrected\n    # error propgation for sigmaCorrected\n    MomentsDict[version]['sigmaCorrectedErr'] = sigmaErr\/sigmaCorrected*sigma\n    return MomentsDict","acf140ea":"Moments = CorrectForResolution(Moments, ResoFunc)\n\nx = Moments['raw']['Emean'] \ny = Moments['raw']['sigmaCorrected'] \nyerr = Moments['raw']['sigmaCorrectedErr']\n\nplt.errorbar(x, y, yerr, linestyle='none', marker='o', color='black', label='resolution corrected')\n\ny = Moments['raw']['sigma'] \n# shift slightly in lgE for less overlap\ndx = 0.005\nplt.errorbar(x+dx, y, yerr, linestyle='none', marker='o', color='red',\n             label=r'$\\sigma_\\mathrm{raw}(X_\\mathrm{max})$')\n\nplt.ylabel(r'$\\sigma(X_\\mathrm{max})$\/(g\/cm$^{2}$)')\nplt.xlabel(r'$\\lg(E\/\\mathrm{eV})$')\nplt.ylim(0, 90)\nplt.legend(loc='best',fontsize=LegendFontSize, numpoints=1, ncol=1, frameon=False)\nplt.show()","6e470d95":"# Parametrizations that define the Xmax systematic uncertainties according to:\n#  Phys. Rev. D 90, 122005 (2014)\n\ndef GetXmaxSystPRD2014plus(logE):\n    p = [-2.36491238e-01,   1.45720450e+01,  -2.95795729e+02,   1.98962627e+03]\n    p.reverse()\n    GetSystPlus = poly.Polynomial(p)\n    return GetSystPlus(logE)\n\ndef GetXmaxSystPRD2014minus(logE):\n    p =[ -1.66409503e+00,   9.34458055e+01,  -1.74598689e+03,   1.08461078e+04]\n    p.reverse()\n    GetSystMinus = poly.Polynomial(p)\n    return -GetSystMinus(logE)\n\n\ndef GetSigmaSystPRD2014plus(logE):\n    p = [  1.82312628e+00,  -1.02328993e+02,   1.91290162e+03,  -1.19078859e+04]\n    p.reverse()\n    GetSystPlus = poly.Polynomial(p)\n    return GetSystPlus(logE)\n\ndef GetSigmaSystPRD2014minus(logE):\n    p = [ -1.23332547e+00,   6.91907431e+01,  -1.29288430e+03,   8.04495403e+03]\n    p.reverse()\n    GetSystPlus = poly.Polynomial(p)\n    return -GetSystPlus(logE)\n\nMeanLgEList = Moments[version]['Emean']\nXmax_dataSystUp = GetXmaxSystPRD2014plus(MeanLgEList)\nXmax_dataSystDown = GetXmaxSystPRD2014plus(MeanLgEList)\nSigma_dataSystUp = GetSigmaSystPRD2014plus(MeanLgEList)\nSigma_dataSystDown = GetSigmaSystPRD2014plus(MeanLgEList)\n\nMoments['raw']['meanSystUp'] = Xmax_dataSystUp \nMoments['raw']['meanSystDown'] = Xmax_dataSystDown \nMoments['raw']['sigmaSystUp'] = Sigma_dataSystUp \nMoments['raw']['sigmaSystDown'] = Sigma_dataSystDown ","a203da56":"# Functions related to the expected $X_\\mathrm{max}$ moments according to the different models\n\ndef RailsFunc(lgE, p):\n    x = lgE\n    Rail = p[0] + p[1]*(x-18.) + p[2]*(x-18.)*(x-18.)\n    return Rail\n\n\ndef GetModelRails():\n    ModelTrails = {}\n    \n    ModelTrails['EPOS-LHC'] = {}\n    ModelTrails['EPOS-LHC']['H'] = {}\n    ModelTrails['EPOS-LHC']['H']['mean'] = [748.7824192267246, 57.72752933739214, -0.8492819413608501]\n    ModelTrails['EPOS-LHC']['H']['sigma']= [ 60.754568341320265, -4.523514085098007, 1.3561246418133817]\n    ModelTrails['EPOS-LHC']['Fe'] = {}\n    ModelTrails['EPOS-LHC']['Fe']['mean'] = [648.6042870553292, 63.12370268046462, -1.971476995005652]\n    ModelTrails['EPOS-LHC']['Fe']['sigma'] = [18.78185209432394, -1.5909852848013866, 0.3130051586485538]\n    \n    ModelTrails['QGSJetII-04'] = {}\n    ModelTrails['QGSJetII-04']['H'] = {}\n    ModelTrails['QGSJetII-04']['H']['mean'] = [733.3361855074645, 54.047662455592985, -0.16135288252029056]\n    ModelTrails['QGSJetII-04']['H']['sigma'] = [64.14678054632051, -5.60721479996932, 1.0494756541917634]\n    ModelTrails['QGSJetII-04']['Fe'] = {}\n    ModelTrails['QGSJetII-04']['Fe']['mean'] = [635.9311237461296, 59.70402610426705, -1.9779302901269205]\n    ModelTrails['QGSJetII-04']['Fe']['sigma'] = [23.662014632248354, -1.1934827895137259, -0.07813472862728368]\n    \n    ModelTrails['Sibyll2.3c'] = {}\n    ModelTrails['Sibyll2.3c']['H'] = {}\n    ModelTrails['Sibyll2.3c']['H']['mean'] = [761.9, 57.4, -8.07e-10]\n    ModelTrails['Sibyll2.3c']['H']['sigma'] = [66.6, -5.7, 0.76] \n    ModelTrails['Sibyll2.3c']['Fe'] = {}\n    ModelTrails['Sibyll2.3c']['Fe']['mean'] = [656.6, 60.1, -0.00016]\n    ModelTrails['Sibyll2.3c']['Fe']['sigma'] = [ 24.51, -2.13, 0.2824]\n    \n    return ModelTrails\n\n\ndef PlotModelRails(moment, PlotLegend, BandW):\n    ModelRails = GetModelRails()\n    Models = ['EPOS-LHC','Sibyll2.3c','QGSJetII-04']\n    Particles = ['H', 'Fe']\n    ModelLines = ['','--','-.']\n    if BandW == True:\n        ParticleColors = ['black','black']\n    else:\n        ParticleColors = ['red','blue']\n    Moments=['mean','sigma']\n    #MEAN PLOT\n\n    ModelPlot = {}\n    ModelPlots = []\n\n    LegendFontSize = 25\n    lgE = np.arange(17, 21, 0.1)\n    for ii, model in enumerate(Models):\n        for jj, Particle in enumerate (Particles):\n            par = ModelRails[model][Particle][moment]\n            plt.plot(lgE, RailsFunc(lgE,par), ModelLines[ii], color=ParticleColors[jj])\n        ModelPlot[model], = plt.plot(lgE[0], [800], ModelLines[ii], color='black', label=model)\n        ModelPlots.append(ModelPlot[model])\n\n    if moment == 'mean':\n        plt.text(19.4, 833, r'proton', verticalalignment='bottom', fontsize=LegendFontSize, rotation=25)\n        plt.text(19.7, 718, r'iron', verticalalignment='bottom', fontsize=LegendFontSize, rotation=25)\n        #plt.text(17.6, 819, '$\\pm\\;$ syst.', verticalalignment='center',horizontalalignment='left',fontsize=30, rotation=0)\n        # Create a legend for the models.\n    if PlotLegend:\n        first_legend = plt.legend(handles=ModelPlots, loc=4, fontsize=LegendFontSize,\n                                  numpoints=1,ncol=1, frameon=False,)\n        if moment=='sigma':\n            first_legend = plt.legend(handles=ModelPlots, loc=4, fontsize=LegendFontSize,\n                                      numpoints=1, ncol=2, frameon=False,)\n        # Add the legend manually to the current Axes.\n        ax = plt.gca().add_artist(first_legend)\n    return","25d4f7b3":"def PlotMoments(Moments, mode, PlotSyst, PlotModels, SetMoment, Label, TwinAxis, BandW):\n    lgE = Moments[mode]['Emean']\n\n    LgEmin = 17.7\n    LgEmax = 20.0\n    \n    \n    SystFontSize = 15\n    if (SetMoment == 'mean'):\n        Mean = Moments[mode]['mean']\n        StatErrDown = Moments[mode]['meanErr']\n        StatErrUp = Moments[mode]['meanErr']\n        SystPlus = Moments[mode]['meanSystUp']\n        SystMinus = Moments[mode]['meanSystDown']\n\n    if  (SetMoment == 'sigma'):\n        Mean = Moments[mode]['sigmaCorrected']\n        StatErrDown = Moments[mode]['sigmaCorrectedErr']\n        StatErrUp = Moments[mode]['sigmaCorrectedErr']\n        SystPlus = Moments[mode]['sigmaSystUp']\n        SystMinus = Moments[mode]['sigmaSystDown']\n        \n\n    EcutSigma=25\n    EnergyCut = lgE < 25\n    if SetMoment == 'mean':\n        plt.subplot(1,2,1)\n        EnergyCut = lgE < 25\n    if SetMoment == 'sigma':\n        plt.subplot(1, 2, 2)\n        SystPlus = SystPlus - 0.3\n        SystMinus = SystMinus + 2.3\n        EnergyCut = lgE < EcutSigma\n    \n    yErrors = [StatErrDown[EnergyCut], StatErrUp[EnergyCut]]\n    \n    data = plt.errorbar(lgE[EnergyCut], Mean[EnergyCut], yerr=yErrors, fmt='.',\n                        color='black', marker='o',\n                        fillstyle='full', markersize=8, capsize=0, label=Label)\n\n    \n    plt.minorticks_on()\n    plt.tick_params('both', length=10, width=1, which='major')\n    plt.tick_params('both', length=5, width=1, which='minor')\n\n    \n    if (SetMoment == 'mean' or SetMoment == 'meanBoth'):\n        plt.ylabel(r'$\\langle X_\\mathrm{max} \\rangle$  $[\\mathrm{g\/cm^2}]$ ',\n                   fontsize=LabelFontSize)\n    if (SetMoment == 'sigma' or  SetMoment == 'sigmaBoth' ):\n        plt.ylabel(r'$\\sigma(\\mathrm{X_{max}})$  $\\mathrm{[g\/cm^2]}$', \n                   fontsize=LabelFontSize)\n\n    plt.xlabel(r'$\\mathrm{lg(E\/eV)}$', fontsize=LabelFontSize)\n    plt.xticks(fontsize=TickFontSize)\n    plt.yticks(fontsize=TickFontSize)\n    plt.xlim(LgEmin, LgEmax)\n    #plt.grid()\n    \n    PlotLegend=True\n    if PlotModels:\n        if (SetMoment == 'sigma' or  SetMoment == 'sigmaBoth'):\n            PlotLegend = False\n        if (SetMoment == 'sigmaBoth'):\n            PlotModelRails('sigma', PlotLegend, BandW)\n        if (SetMoment == 'meanBoth'):\n            PlotModelRails('mean', PlotLegend, BandW)\n        if (SetMoment == 'mean' or SetMoment == 'sigma'):\n             PlotModelRails(SetMoment, PlotLegend, BandW)\n            \n    # Create another legend for the data.\n    #if (SetMoment=='mean' or SetMoment=='meanBoth'):\n    if Label:\n        plt.legend(handles=[data], loc=2,fontsize=LegendFontSize, \n                   numpoints=1, ncol=1, frameon=False)\n\n\n    if PlotSyst:\n    #-------------(lgE,Mean,StatErr,SystPlus,SystMinus,PlotModels\n        Xmax_dataSystUp = np.asanyarray(Mean + np.asanyarray(SystPlus))\n        Xmax_dataSystDown = np.asanyarray(Mean - np.asanyarray(SystMinus))\n\n\n        for ii, logE in enumerate(lgE):\n            if ( SetMoment == 'sigma' or SetMoment == 'sigmaBoth'):\n                if ( logE < EcutSigma):\n                    plt.text(logE-0.01, Xmax_dataSystUp[ii], r'[', \n                             verticalalignment='center', horizontalalignment='center',\n                             fontsize=15, rotation=-90, color='black')\n                    plt.text(logE, Xmax_dataSystDown[ii] + 3, r'[', verticalalignment='center',\n                             horizontalalignment='center', fontsize=15, rotation=90, color='black')\n            else:\n                plt.text(logE - 0.01, Xmax_dataSystUp[ii], r'[', verticalalignment='center',\n                         horizontalalignment='center', fontsize=15, rotation=-90, color='black')\n                plt.text(logE, Xmax_dataSystDown[ii] + 3, r'[', verticalalignment='center',\n                         horizontalalignment='center', fontsize=15, rotation=90, color='black')\n                \n        if (SetMoment == 'mean' or SetMoment == 'meanBoth'):\n            plt.text(LgEmin + 0.18, 820, r'[', verticalalignment='center',\n                     horizontalalignment='center',fontsize=SystFontSize, \n                     rotation=90, color='black')\n            plt.text(LgEmin + 0.175, 830, r'[', verticalalignment='center',\n                     horizontalalignment='center', fontsize=SystFontSize, \n                     rotation=-90, color='black')\n            plt.text(LgEmin + 0.27, 825, '$\\pm\\;$ syst.', verticalalignment='center',\n                     horizontalalignment='left', fontsize=LegendFontSize, rotation=0)\n\n\n    #---------------\n    if TwinAxis:\n        ax2 = plt.twiny()\n        #ax2.set_xscale(\"log\", nonposy='clip')\n        ax2.set_xscale(\"log\")\n        ax2.errorbar([pow(10, 17.14), pow(10, 19.87)], [600, 850], yerr=0, fmt='.',\n                     color='black', marker='o',\n                     fillstyle='full', markersize=0, capsize=0, label='')\n\n        ax2.set_xlabel('$\\mathrm{E[eV]}$', fontsize=LabelFontSize)\n        plt.minorticks_on()\n        plt.tick_params('both', length=10, width=1, which='major')\n        plt.tick_params('both', length=5, width=1, which='minor')\n\n        plt.xticks(fontsize=TickFontSize)\n        plt.yticks(fontsize=TickFontSize)\n        ax2.set_xlim(pow(10, LgEmin), pow(10, LgEmax))\n        \n        \n    if (SetMoment == 'mean' or SetMoment == 'meanBoth'):\n        plt.ylim(570,870)\n    if (SetMoment == 'sigma' or SetMoment == 'sigmaBoth'):\n        plt.ylim(1, 79)\n\n    return data","bb9b4b5b":"def PlotER(Moments, mode, PlotSyst, PlotModels, Label, BandW):\n    SetMoment = 'mean'\n    TwinAxis = True\n    plt.figure(num=None, figsize=(18, 9), dpi=60, facecolor='w', edgecolor='k')\n    PlotMoments(Moments, mode, PlotSyst, PlotModels, SetMoment, Label, TwinAxis, BandW)\n    return","8bf7e352":"# can select to plot with\/without:\n#  w\/o systematics, \n#  w\/o model expectations for proton and iron and \n#  a selection of black and white or coloured plot\n\nPlotSyst = True\nPlotModels = True\nBlackAndWhite = False\nMomentsType = 'raw'\nDataLabel = r'data $\\pm$ $\\sigma_{\\mathrm{stat}}$'\n\nLabel = DataLabel\nPlotER(Moments, MomentsType, PlotSyst, PlotModels, Label, BlackAndWhite)\n\nplt.tight_layout()\n\nplt.show()\n","5c06390c":"def PlotSigma(Moments, mode, PlotSyst, PlotModels, Label, BandW):\n    SetMoment = 'sigma'\n    TwinAxis = True\n    plt.figure(num=None, figsize=(18, 9), dpi=60, facecolor='w', edgecolor='k')\n    PlotMoments(Moments, mode, PlotSyst, PlotModels, SetMoment, Label, TwinAxis, BandW)\n    return","c593b2d3":"PlotSyst = True\nPlotModels = True\nBlackAndWhite = False\nMomentsType = 'raw'\nDataLabel = r'data $\\pm$ $\\sigma_{\\mathrm{stat}}$'\n\n\nLabel = ''\nPlotSigma(Moments, MomentsType, PlotSyst, PlotModels,\n               Label, BlackAndWhite)\n\nplt.tight_layout()\n\nplt.show()","92de41a2":"def PlotBothMoments(Moments, mode, PlotSyst, PlotModels, Label, BandW):\n    SetMoment = 'mean'\n    TwinAxis = True\n    plt.figure(num=None, figsize=(18, 9), dpi=60, facecolor='w', edgecolor='k')\n    PlotMoments(Moments, mode, PlotSyst, PlotModels, SetMoment, Label, TwinAxis, BandW)\n    \n    SetMoment = 'sigma'\n    Label = ''\n    PlotMoments(Moments, mode, PlotSyst, PlotModels, SetMoment, Label, TwinAxis, BandW)\n    \n    return","dbcab254":"PlotSyst = True\nPlotModels = True\nXmaxCorrection = 0\nSigmaCorrection = 0\nBlackAndWhite = False\nMomentsType = 'raw'\nDataLabel = r'data $\\pm$ $\\sigma_{\\mathrm{stat}}$'\n\nLabel = DataLabel\nPlotBothMoments(Moments, MomentsType, PlotSyst, PlotModels,\n              Label, BlackAndWhite)\n\nplt.tight_layout()\n\nplt.show()","cb10c150":"acceptance = pd.read_csv(AugerOpen('auxiliary', 'fdXmaxAcceptance.csv'))","510708c3":"# numpyify\ndef GetXmaxAccFunc(XmaxAcc):\n    \"\"\"\n    Fits a function (as a function of energy) for each coefficient of the \n    Xmax acceptance.\n    \"\"\"\n    x1 = XmaxAcc['Xacc1']\n    l1 = XmaxAcc['lambdaAcc1']\n    x2 = XmaxAcc['Xacc2']\n    l2 = XmaxAcc['lambdaAcc2']\n    Ebins = XmaxAcc['lgMinEnergy']+0.05\n    \n    AccFunc = []\n    for Acc in [x1, l1, x2, l2]:\n        x = np.asanyarray(Ebins)\n        x = x.tolist()\n        y = Acc\n        y = y.tolist()\n        y = np.asanyarray(y)\n        z = np.polyfit(x, y, 3)\n        z = z[::-1] \n        AccFunc.append(poly.Polynomial(z))\n    return tuple(AccFunc)","34003768":"x1Func, l1Func, x2Func, l2Func = GetXmaxAccFunc(acceptance)","65597254":"def Facc(xArr, l1, l2, x1, x2, N):\n    \"\"\" \n    Definition of the Xmax acceptance function\n    N is the normalization of the function. Usually N=1 \n    \"\"\" \n    returnList = []\n    for x in xArr:\n        if x <= x1:\n            Acc = N*math.exp((x-x1)\/l1)\n        elif (x>x1) & (x<=x2):\n            Acc = N\n        else: \n            Acc = N*math.exp(-(x-x2)\/l2)\n        returnList.append(Acc)\n        #print x, x1, x2, Acc\n    XmaxAcceptance = np.asanyarray(returnList)\n    return XmaxAcceptance\n    \n\n\ndef GetAcceptance(MeanlgE, XmaxList, x1F, l1F, x2F, l2F):\n    \"\"\"\n    Given the mean energy of the bin, it calculates the corresponding\n    Xmax acceptance as a function of Xmax\n    \"\"\"\n    AccW = []\n    normalization = 1    \n    pAcc = [l1F(MeanlgE), l2F(MeanlgE), \n            x1F(MeanlgE), x2F(MeanlgE), normalization]\n    \n    X=XmaxList\n    acceptance = Facc(X, *pAcc)\n    return acceptance\n","5a8c9abc":"def PlotXmaxAcceptance(XmaxData, EventBin, MeanBinEn, x1F, l1F, x2F, l2F):\n    \"\"\"\n    Plot the Xmax distributions for each energy bin and the corresponding\n    Xmax acceptance\n    \"\"\"\n    NBin = 0\n    XmaxMin = 500\n    XmaxMax = 1100\n    XmaxBinSize = 20\n    NoBins =  int((XmaxMax - XmaxMin) \/ XmaxBinSize) \n    XmaxMax = XmaxMin + NoBins*XmaxBinSize\n\n    XmaxRange = np.arange(XmaxMin, XmaxMax, 1)\n    \n    \n    Ncol = 3\n    \n    Nrows = int((len(Ebins)-1) \/ Ncol) \n    if (len(Ebins)-1) % Ncol > 0:\n        Nrows += 1\n   \n\n    Factor = 0.8  #regulate the size of the subplots\n\n    fig, axes = plt.subplots(Nrows, Ncol,\n            figsize = (Nrows*Ncol*Factor, Nrows*Ncol*Factor*0.9))\n    fig.subplots_adjust(hspace=-1.1) #0.05\n    for ax_row in (axes):\n        for ax in (ax_row):\n            \n            if ( NBin > len(Ebins)-2):\n                continue\n            # create a twin of the axis that shares the x-axis\n            ax2 = ax.twinx()\n            # plot Xmax distribution on each axis.\n            ax.hist(XmaxData[EventBin == NBin], range=[XmaxMin, XmaxMax],\n                    bins=NoBins, histtype='step', label='',\n                    color='black', linewidth=2)\n       \n            XmaxAcceptance =  GetAcceptance(MeanBinEn[NBin], XmaxRange, x1Func, l1Func, x2Func, l2Func)\n            ax2.plot(XmaxRange, XmaxAcceptance,'-', color='red')\n\n            ax.set_xlim(XmaxMin, XmaxMax)\n            ax2.set_ylim(0, 1.05)\n       \n            ax2.tick_params(axis='y', labelcolor='red', labelsize=TickFontSize)\n            ax.tick_params(axis='y', labelcolor='black', labelsize=TickFontSize)\n            ax.tick_params(axis='x', labelcolor='black', labelsize=TickFontSize)\n    \n        \n            if ( NBin < Ncol*Nrows - Ncol): \n                ax.xaxis.set_ticklabels([])\n            else:\n                ax.set_xlabel(r'$\\mathrm{X_{max}}$  $\\mathrm{[g\/cm^2]}$',\n                          fontsize=LabelFontSize )\n         \n            if (NBin==Ncol*int(Nrows\/Ncol) ): \n                ax.set_ylabel(r'entries \/ (20 g\/cm$^{2}$)',fontsize=LabelFontSize )\n                \n            if (NBin==Ncol*int(Nrows\/Ncol)+(Ncol-1)): \n                ax2.set_ylabel('relative efficiency ', fontsize=LabelFontSize,\n                           color='red')\n        \n            if ( NBin%Ncol < 2): \n                ax2.yaxis.set_ticklabels([])\n            NBin = NBin + 1\n        \n            #formatting ticks\n            ax.minorticks_on()\n            ax2.minorticks_on()\n            ax.tick_params(which='both', width=2)\n            ax2.tick_params(which='both', width=2)\n            ax.tick_params(which='major', length=7)\n            ax2.tick_params(which='major', length=7, color='r')\n            ax2.tick_params(which='minor', length=4, color='r')\n            ax.tick_params(which='minor', length=4)\n        \n        \n            plt.tight_layout()\n    return \n","4a426eda":"def GetEnergyBin(lgEList,Ebins):\n    \"\"\" Identify the energy bin that each event belongs \"\"\"\n    BinList = []\n    for lgE in lgEList:\n        for Nbin, binLgE in enumerate(Ebins):\n            if (lgE < binLgE):\n                BinList.append(Nbin - 1)\n                break\n    return(np.asanyarray(BinList))","7bcd6241":"MeanlgE = Moments['raw']['Emean'] \nBinList = GetEnergyBin(unique_xmax_data['fd_avg_lgE'], Ebins)\n\nPlotXmaxAcceptance(unique_xmax_data['fd_avg_xmax'] , BinList,MeanlgE, x1Func, l1Func, x2Func, l2Func)\nplt.show()","b91d1292":"## Correcting for the $X_\\mathrm{max}$ resolution\n\nTo convert $\\sigma_\\mathrm{raw}(X_\\text{max})$ to the actual $\\sigma(X_\\text{max})$, it is necessary to take into account the total reconstruction resolution of $X_\\mathrm{max}$.\n\nThe total reconstruction resolution of $X_\\mathrm{max}$ has been parametrized as a function of energy:\n\n* Coefficients for the $X_\\mathrm{max}$ resolution parametrization ([Section VI-D in Phys. Rev. D 90, 122005 (2014)](https:\/\/inspirehep.net\/literature\/1317612) )\n\nThe $X_\\mathrm{max}$ resolution make the $\\sigma(X_\\text{max})$ wider. In order to correct for this effect, the $X_\\mathrm{max}$  resolution is subtracted in quadrature from $\\sigma_\\mathrm{raw}(X_\\text{max})$.","cb4cbfbf":"## Plot the energy dependence of the average $X_\\mathrm{max}$ also known as $\\langle X_\\mathrm{max} \\rangle$\n\nThe mean of the shower maximum is proportional to the logarithm of the primary mass. The energy evolution of $X_\\text{max}$ gives thus an estimate of the change of composition with energy.","c111379b":"## Performing the elongation rate fit (fitting a broken line)\n\nThe **Elongation Rate** is defined as the rate of change of the mean $X_\\mathrm{max}$ per decade of energy. For a pure composition the elongation rate is approximately equal to $60\\,\\mathrm{g\/cm^2}$ per decade of energy. An elongation rate larger than $60\\,\\mathrm{g\/cm^2}$\/decade means that the composition is getting lighter with energy, and if smaller, it means that the composition is getting heavier with energy. This interpretation of the composition is almost model independent.  \n\n\nThe elongation rate fits (plot below) indicate that for energies below lgE < 18.24, the composition is getting lighter with energy and above this energy, the composition is becoming heavier with energy.","cd0a3bc6":"## Comparing observed $X_\\mathrm{max}$ moments with model expectations for proton and Iron","37359c3b":"## Plotting the second $X_\\mathrm{max}$ moment","f5cb6337":"## Displaying observed $X_\\mathrm{max}$ distributions with corresponding $X_\\mathrm{max}$ acceptance \n\n The following plots show the $X_\\mathrm{max}$ acceptance (red lines). They show that only within the $X_\\mathrm{max}$ distributions tails, the acceptance is lower. But, the acceptance is homogeneous over most of the $X_\\mathrm{max}$ range. Therefore, the $X_\\mathrm{max}$ acceptance correction is a second order correction. For simplicity we have not applied the $X_\\mathrm{max}$ acceptance correction when calculating the $X_\\mathrm{max}$ moments.  \n\nThe Xmax acceptance functions for each energy bin have been parametrized, and the coefficients are available at:\n\n   [Section V in Phys. Rev. D 90, 122005 (2014)](https:\/\/inspirehep.net\/literature\/1317612) \n \n \n ","b7024ff6":"## Merge multi-eye events\n\nAt high energies, a cosmic shower can be viewed over large distances and therefore be detected by more than one FD station. In the next step we merge these so-called stereo, triple and quadruple events and calculate a unique energy and $X_\\text{max}$ for each shower as the weighted average of all FD stations.","c565c9d0":"Prepare a data frame with unique events, i.e., with each `id` present only once. This dataframe gets indexed by event `id` to allow merging with data like averages from multi-eye events.\n\nThe flag **'fd_hdXmaxEye'** is used to select the events that are suitable for the $X_\\mathrm{max}$ analysis. The selected events have a range of geometries that allow to measure their $X_\\mathrm{max}$ with good resolution (better than $40$ g\/cm$^2$ for each event and better than $25$ g\/cm$^2$ on average) over a certain $X_\\mathrm{max}$ range. This $X_\\mathrm{max}$ range has been chosen so that most of the observed $X_\\mathrm{max}$ distribution (at each energy bin) is contained within this $X_\\mathrm{max}$ range. This is called 'the fiducial field of view\".  Such selection of geometries allow us to sample the $X_\\mathrm{max}$ distributions almost free of\ndetector acceptance effects.\n\nIn principle, we can request a good $X_\\mathrm{max}$ measurement over a large range of $X_\\mathrm{max}$ values removing entirely the detector effects when sampling the $X_\\mathrm{max}$ distributions. However, this will reduce dramatically the statistics. So, the selected fiducial $X_\\mathrm{max}$ range is a compromise between reducing the detector effects in the sampled $X_\\mathrm{max}$ distribution, while keeping a reasonably high statistics. Therefore, there are small residual detector effects in the tails of the $X_\\mathrm{max}$ distribution, that we will correct using a parametrization of the estimated detector $X_\\mathrm{max}$ acceptance.","9350c0b4":"## Energy distribution of selected events ##","c82d3d29":"##  Functions to return the coefficients of the $X_\\mathrm{max}$ acceptance  for any value of energy","bc543f74":"![PierreAugerObservatoryLogo.jpg](attachment:PierreAugerObservatoryLogo.jpg)\n#  Analysis of $X_\\mathrm{max}$ Measurements from the Fluorescence Detector of the Pierre Auger Observatory\n\n<i>Notebook released together with the Pierre Auger Observatory Open Data release 2021 (<a href=\"https:\/\/doi.org\/10.5281\/zenodo.4487613\">DOI 10.5281\/zenodo.4487613<\/a>). More information at the <a href=\"https:\/\/www.auger.org\/opendata\/\">Auger open data website<\/a>.<\/i>\n\n$X_\\mathrm{max}$ is the atmospheric depth at which the number of particles in an air shower reaches its maximum. It is the best measured shower observable that is correlated with the composition of the primary cosmic ray composition. $X_\\mathrm{max}$ is directly measured with the fluorescence detectors of the Pierre Auger Observatory by observing the longitudinal development of the air shower.\n\n Lighter primaries penetrate deeper in the atmosphere than heavier primaries. This is because heavier primaries are to good approximation a superposition of many less energetic light primaries. Therefore, heavier elements dissipate their energy faster and do not have the energy to penetrate deeper in the atmosphere. \n \n The aim of this analysis is to sample the $X_\\mathrm{max}$ distribution and the corresponding first two moments to estimate the composition. This is achieved by comparing the observations with predictions from high energy hadronic interaction models.  This notebook will show the different steps towards the calculation of the first two  moments of the $X_\\mathrm{max}$ distribution, the mean and standard deviation ($\\langle X_\\mathrm{max}\\rangle$ and $\\sigma(X_\\mathrm{max})$).\n \nNOTE: this is a **simplified version** of the $X_\\mathrm{max}$ analysis applied to data from the Pierre Auger Observatory. The sampled $X_\\mathrm{max}$ distributions are affected by the detector resolution and by the detector $X_\\mathrm{max}$ acceptance. Both effects need to be estimated and corrected for a precise  estimation of the $X_\\mathrm{max}$ moments. Here we will only show an approximate analysis for the mean shower maximum. Due to the fiducial event selection, this analysis agrees with the final one within a few g\/cm$^2$. We also present the raw standard deviation of $X_\\mathrm{max}$ without correction for the detector resolution and acceptance and show the resolution-corrected fluctuations. For how to proceed for a full analysis and correction for detector effects, please refer to [Phys. Rev. D 90, 122005 (2014)](https:\/\/inspirehep.net\/literature\/1317612). ","1f6c651b":"## Scatter plot of $X_\\text{max}$ vs. energy\n\nAfter this step, we can now plot the individual energies and shower maxima. Note that the error bars include only the statistical uncertainty of the measurement. The scattering of the data points is due to a combination of these uncertainties and shower-to-shower fluctuations. The latter are not accounted for in the error bars, but they are part of the physics observables used to study the composition of cosmic rays.","57c2bb05":"\n GetXmaxResolution(resolution): \n \n The parameters from the auxiliary file 'resolution.txt' are used to define the $X_\\mathrm{max}$ resolution for each energy bin as defined at [Section VI-D in Phys. Rev. D 90, 122005 (2014)](https:\/\/inspirehep.net\/literature\/1317612) .\n \n GetXmaxResoFunc(resolution):\n \n A fit to the $X_\\mathrm{max}$ resolution as function of energy is performed to obtain a function that returns the $X_\\mathrm{max}$ resolution for any value of energy. This function will be used to have more flexibility in the definition of the energy bins. This means that we don't need to use the same energy bin definition as in [Section VI-D in Phys. Rev. D 90, 122005 (2014)](https:\/\/inspirehep.net\/literature\/1317612) . ","369c9eb5":"## Plot the 'raw' standard deviation of $X_\\text{max}$ also known as  $\\sigma_\\mathrm{raw}(X_\\text{max})$","54d448fd":"## Load systematic uncertainty parameterizations for display","07a47d69":"## Plotting the first and second $X_\\mathrm{max}$ moments","86f90634":"## The $X_\\mathrm{max}$ distributions and the $X_\\mathrm{max}$ moments\n ","579f5f9b":"## Defining the energy bins\n\n Below we define the energy bin ranges. We will use the same energy bin ranges as in [Phys. Rev. Lett. 104 (2010) 091101](https:\/\/inspirehep.net\/literature\/845300), i.e. a binning that was used in an early publication of $X_\\text{max}$ with statistics comparable to this data release.","ce9d00b8":"This is the kaggle version of a Pierre Auger Observatory Open Data notebook. You can run it by clicking on \"Copy and Edit\" in the top right corner.","5368493d":"## Read the data file and select events for Xmax analysis "}}