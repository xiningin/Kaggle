{"cell_type":{"c178b76f":"code","c97ea27c":"code","74a462a6":"code","8266a87e":"code","69a19a2d":"code","268bf8e4":"code","7ed8c6b9":"code","bb971be9":"code","40b6ac70":"code","2fd5ad23":"code","7549084e":"code","5b54f9b6":"code","d7838874":"code","667c5808":"code","d76b353e":"code","f3f93f86":"code","fa4b1f98":"code","8f037ab5":"code","6580220a":"code","9ee8975f":"code","3b7cfbcf":"code","6259bc05":"code","2ade7adc":"code","68abbbcc":"code","9fd6dee1":"code","0b87c9d6":"code","e92309b1":"code","76cf6be7":"code","ccb2fe47":"markdown","d9ec250f":"markdown","14410dcd":"markdown","7b3c3b32":"markdown","6ba63594":"markdown","09b35266":"markdown"},"source":{"c178b76f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c97ea27c":"df = pd.read_csv('\/kaggle\/input\/placement-data-full-class\/Placement_data_full_class.csv')","74a462a6":"# checking for head of dataset\ndf.head()","8266a87e":"# checking for rows and columns\ndf.shape","69a19a2d":"# columns\ndf.columns","268bf8e4":"# no need of sl_no column so we will drop it\ndf.drop(\"sl_no\", axis=1, inplace=True)","7ed8c6b9":"df.info()","bb971be9":"df.dtypes","40b6ac70":"# description\ndf.describe()","2fd5ad23":"# checking for null values\ndf.isnull().sum()","7549084e":"# checking the number of peoples per 10th using gender\ndf.groupby(\"ssc_b\")['gender'].value_counts()","5b54f9b6":"# checking for hsc \ndf.groupby(\"hsc_b\")[\"gender\"].value_counts()","d7838874":"# checking hscs\ndf.groupby(\"hsc_s\")['gender'].value_counts()","667c5808":"# checking for correlation\ndf.corr()","d76b353e":"# checking for gender\nimport seaborn as sns\nsns.countplot('gender', hue='ssc_b', data=df);","f3f93f86":"sns.countplot('gender', hue='hsc_b', data=df);","fa4b1f98":"sns.countplot('gender', hue='hsc_s', data=df);","8f037ab5":"sns.pairplot(data=df)","6580220a":"# checking for the data using status balanced or not\nsns.countplot(\"gender\", hue=\"status\", data=df)","9ee8975f":"# IMPORTING SOME OF THE LIBRARIES\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import classification_report , confusion_matrix , accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\ntree = DecisionTreeClassifier(criterion= 'entropy')\nfrom sklearn.ensemble import RandomForestClassifier\nref = RandomForestClassifier(n_estimators=100)\nfrom sklearn.neighbors import KNeighborsClassifier \nknn = KNeighborsClassifier (n_neighbors=3)","3b7cfbcf":"# first of we need to change the datatype of each column\n# we will create a dictionary for gender\ngender = {\n    \"M\": 0,\n    \"F\": 1\n}\n# create a dictionary for \"12th Stream\"\nstream_12 = {\n    \"Commerce\":0,\n    \"Science\":1,\n    \"Arts\":2\n}\n# creating a dictionary for Degree stream\nDegree_stream  = {\n    \"Comm&Mgmt\":0,\n    \"Sci&Tech\":1,\n    \"Others\":2\n}\nwork_exp = {\n    \"No\":0, \n    \"Yes\":1\n}\n# creating a column for status\nstatus_dic = {\n    \"Placed\":1,\n    \"Not Placed\":0 \n}\n# columns for specilization\nspe_dic = {\n    \"Mkt&HR\":0, \n    \"Mkt&Fin\":1\n}\n# 'gender', 'ssc_p', 'ssc_b', 'hsc_p', 'hsc_b', 'hsc_s',\n#        'degree_p', 'degree_t', 'workex', 'etest_p', 'specialisation', 'mba_p'\ndf['gender'] = df['gender'].map(gender)\ndf['hsc_s'] = df['hsc_s'].map(stream_12)\ndf['degree_t'] = df['degree_t'].map(Degree_stream)\ndf[\"workex\"] = df['workex'].map(work_exp)\n    # mapping status\ndf['status'] = df['status'].map(status_dic)\ndf[\"specialisation\"] = df[\"specialisation\"].map(spe_dic)","6259bc05":"df.head(3)","2ade7adc":"# salary contains so will drop that column to\ndf.drop(\"salary\", axis=1, inplace=True)","68abbbcc":"df.columns","9fd6dee1":"# separating the columns\nX = df[['gender', 'ssc_p', 'hsc_p', 'hsc_s', 'degree_p','degree_t', 'workex', 'etest_p', 'specialisation', 'mba_p']]\ny = df['status']","0b87c9d6":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","e92309b1":"def models(X_train, y_train):\n    # Decision Tree\n    tree.fit(X_train, y_train)    \n    # Random Forest Classifier\n    ref.fit(X_train, y_train)\n    # knn\n    knn.fit(X_train, y_train)\n    # printing the model accuray\n    print('Decision Tree Model Accuracy: {:.4f}'.format(accuracy_score(y_test, tree.predict(X_test))*100))\n    print('Random Forest Model Accuracy: {:.4f}'.format(accuracy_score(y_test, ref.predict(X_test))*100))\n    print('K Nearest Neighobrs Classifier Model Accuracy: {:.4f}'.format(accuracy_score(y_test, knn.predict(X_test))*100))\n     \n    return tree, ref, knn","76cf6be7":"model = models(X_train, y_train)","ccb2fe47":"All the columns are data type of object and float 64","d9ec250f":"All the columns are have not null values but only salary column contain null values ","14410dcd":"There are 215 rows and 15 columns in the dataSet","7b3c3b32":"After dropping the sl_no columns","6ba63594":"# NOW GOING BACK LOGISTIC REGRESSION","09b35266":"# DataSet Summary"}}