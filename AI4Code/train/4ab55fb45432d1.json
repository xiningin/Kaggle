{"cell_type":{"5fa26c87":"code","03fbea0e":"code","54c526d9":"code","ba6ddff0":"code","62e0abf3":"code","05a92a49":"code","f842cf3d":"code","ca9179fd":"code","21bec55b":"code","acd1973f":"code","c5841dc6":"code","9736cb38":"code","92571cc3":"code","e8ea0607":"code","94f968ea":"code","d8d8c9d6":"code","e83ca3e8":"code","d87c8b60":"code","c45d7cb7":"code","00f66387":"code","1270475e":"code","ad5b9f57":"code","cc63801d":"code","b9145c94":"code","d977ca22":"code","1ac105cc":"markdown"},"source":{"5fa26c87":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","03fbea0e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","54c526d9":"train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv').drop('Id',axis=1)\n\n\ntest  = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntest_id = test['Id']\ntest  = test.drop('Id',axis=1)","ba6ddff0":"train = train.drop(['Utilities', 'Street', 'PoolQC',], axis=1)\ntest  = test.drop(['Utilities', 'Street', 'PoolQC',], axis=1)\n\nobj_col = train.select_dtypes('object').columns\nnum_col = train.select_dtypes(exclude='object').columns[:-1]","62e0abf3":"ohe_col = ['MSZoning','Alley','LotShape','LandContour','LotConfig','LandSlope','Neighborhood',\n           'Condition1','Condition2','BldgType','HouseStyle','RoofStyle','RoofMatl','Exterior1st','Exterior2nd',\n           'MasVnrType','Foundation','Heating','Electrical','Functional','GarageType','GarageFinish','PavedDrive',\n           'Fence','MiscFeature','SaleType','SaleCondition']\n\nord_col = ['ExterQual','ExterCond','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n           'HeatingQC','CentralAir','KitchenQual','FireplaceQu','GarageQual','GarageCond']","05a92a49":"for col in obj_col:\n    train[col] = train[col].fillna('No info')\n    test[col] = test[col].fillna(train[col].value_counts().index[0])","f842cf3d":"for col in num_col:\n    train[col] = train[col].fillna(train[col].mean())\n    test[col] = test[col].fillna((train[col].mean()+test[col].mean())\/2)","ca9179fd":"print(train.isna().sum()[train.isna().sum() != 0])\nprint(test.isna().sum()[test.isna().sum() != 0])","21bec55b":"train.SalePrice.hist(bins = 100)","acd1973f":"train['SalePrice']=train.SalePrice.apply(lambda x: np.log1p(x))","c5841dc6":"train.SalePrice.hist(bins = 100)","9736cb38":"#------------------------------------------------------------------------------\n# accept a dataframe, remove outliers, return cleaned data in a new dataframe\n# see http:\/\/www.itl.nist.gov\/div898\/handbook\/prc\/section1\/prc16.htm\n#------------------------------------------------------------------------------\ndef remove_outliers(df_in, col_name):\n    q1 = df_in[col_name].quantile(0.25)\n    q3 = df_in[col_name].quantile(0.75)\n    iqr = q3-q1 #Interquartile range\n    fence_low  = q1-1.5*iqr\n    fence_high = q3+1.5*iqr\n    df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high)]\n    return df_out\n\ntrain = remove_outliers(train,'SalePrice')\ntrain.SalePrice.hist(bins = 100)","92571cc3":"from sklearn.model_selection import train_test_split, cross_val_score,KFold, GridSearchCV\nfrom sklearn.metrics         import mean_squared_log_error, mean_squared_error\n\nfrom sklearn.pipeline        import make_pipeline\nfrom sklearn.compose         import make_column_transformer\n\nfrom sklearn.preprocessing   import OrdinalEncoder, OneHotEncoder\nfrom sklearn.preprocessing   import MinMaxScaler, StandardScaler, RobustScaler\n\nfrom sklearn.linear_model    import LinearRegression,Lasso,Ridge,LogisticRegression\nfrom sklearn.ensemble        import RandomForestRegressor,GradientBoostingRegressor\nfrom sklearn.ensemble        import StackingRegressor\nfrom sklearn.svm             import SVR\nimport xgboost                   as xgb","e8ea0607":"trans = make_column_transformer(\n                                (StandardScaler(),list(num_col)),\n                                (OrdinalEncoder(),list(ord_col)),\n                                (OneHotEncoder(), list(ohe_col)),\n                                remainder = 'passthrough'\n                                )\n\nX = train.drop(['SalePrice'],axis = 1)\ny = train['SalePrice']\n\nX = trans.fit_transform(X)\n\nX_train,X_val,y_train,y_val = train_test_split(X,y,\n                                               test_size = 0.001,\n                                               random_state = 42,\n                                               shuffle = True)","94f968ea":"\nmodel_gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4,\n                                max_features='sqrt', min_samples_leaf=15, min_samples_split=10,\n                                loss='huber', random_state =42)         \n\nmodel_xgb = xgb.XGBRegressor(learning_rate=0.01,n_estimators=3500,\n                                     max_depth=10, min_child_weight=0,\n                                     gamma=0, subsample=0.7,\n                                     colsample_bytree=0.7,\n                                     objective='reg:linear', nthread=-1,\n                                     scale_pos_weight=1, seed=27,\n                                     reg_alpha=0.00006)","d8d8c9d6":"folds = KFold(n_splits = 10, shuffle = True, random_state=42)\n#score_las = np.sqrt(-cross_val_score(Lasso(),X_train,y_train,scoring = 'neg_mean_squared_error', cv=folds))\n#score_rid = np.sqrt(-cross_val_score(Ridge(),X_train,y_train,scoring = 'neg_mean_squared_error', cv=folds))\n#score_svr = np.sqrt(-cross_val_score(SVR(),X_train,y_train,scoring = 'neg_mean_squared_error', cv=folds))\n\n#score_gbr = np.sqrt(-cross_val_score(model_gbr,X_train,y_train,scoring = 'neg_mean_squared_error', cv=folds))\n#score_xgb = np.sqrt(-cross_val_score(model_xgb,X_train,y_train,scoring = 'neg_mean_squared_error', cv=folds))\n\n#print('(LAS) Train CV mean score: ',np.mean(score_las),' STD: ',np.std(score_las))\n#print('(RID) Train CV mean score: ',np.mean(score_rid),' STD: ',np.std(score_rid))\n#print('(GBR) Train CV mean score: ',np.mean(score_gbr),' STD: ',np.std(score_gbr))\n#print('(XGB) Train CV mean score: ',np.mean(score_xgb),' STD: ',np.std(score_xgb))","e83ca3e8":"param_las = {'alpha':[0.0006,0.0007,0.0008,0.0009,0.001]}\nlas_cv = GridSearchCV(Lasso(random_state=42),param_las,scoring = 'neg_mean_squared_error',cv = folds)\nlas_cv.fit(X_train,y_train)\nprint('Best score: ',np.sqrt(-las_cv.best_score_),' With parameters: ',las_cv.best_params_)\nmodel_las = las_cv.best_estimator_","d87c8b60":"param_rid = {'alpha':range(20,30)}\nrid_cv = GridSearchCV(Ridge(random_state=42),param_rid,scoring = 'neg_mean_squared_error',cv = folds,)\nrid_cv.fit(X_train,y_train)\nprint('Best score: ',np.sqrt(-rid_cv.best_score_),' With parameters: ',rid_cv.best_params_)\nmodel_rid = rid_cv.best_estimator_","c45d7cb7":"param_svr = {'C':[1,2,3,5,7,9],\n             'gamma':[0.001,0.003,0.005,0.007]}\nsvr_cv = GridSearchCV(SVR(),param_svr,scoring = 'neg_mean_squared_error',cv = folds,)\nsvr_cv.fit(X_train,y_train)\nprint('Best score: ',np.sqrt(-svr_cv.best_score_),' With parameters: ',svr_cv.best_params_)\nmodel_svr = svr_cv.best_estimator_","00f66387":"model_las.fit(X,y)\nmodel_rid.fit(X,y)\nmodel_svr.fit(X,y)\nmodel_xgb.fit(X,y)\nmodel_gbr.fit(X,y)\n\n\nprint('(LAS) RMSE on VAL: ', np.sqrt(mean_squared_error(y_val,model_las.predict(X_val))))\nprint('(RID) RMSE on VAL: ', np.sqrt(mean_squared_error(y_val,model_rid.predict(X_val))))\nprint('(SVR) RMSE on VAL: ', np.sqrt(mean_squared_error(y_val,model_svr.predict(X_val))))\nprint('(XGB) RMSE on VAL: ', np.sqrt(mean_squared_error(y_val,model_xgb.predict(X_val))))\nprint('(GBR) RMSE on VAL: ', np.sqrt(mean_squared_error(y_val,model_gbr.predict(X_val))))","1270475e":"estimators = [('LAS', model_las),\n              ('RID', model_rid),\n              ('SVR', model_svr),\n              ('XGB',model_xgb),\n              ('GBR',model_gbr)]\n\nstack = StackingRegressor(estimators=estimators,final_estimator = model_xgb)\nstack.fit(X_train,y_train)","ad5b9f57":"def blend_models_predict(X):\n    return ((0.05 * model_las.predict(X)) + \\\n            (0.05 * model_rid.predict(X)) + \\\n            (0.1 * model_svr.predict(X)) + \\\n            (0.2 * model_xgb.predict(X)) + \\\n            (0.2 * model_gbr.predict(X)) + \\\n            (0.4 * stack.predict(X)))\nprint('Blend model RMSE on VAL: ', np.sqrt(mean_squared_error(y,blend_models_predict(X))))","cc63801d":"x = trans.transform(test)\npred = blend_models_predict(x)","b9145c94":"submis = pd.DataFrame({'Id':test_id,'SalePrice':pred})\nsubmis['SalePrice'] = np.expm1(submis['SalePrice'])\nsubmis.to_csv('\/kaggle\/working\/submission1.csv',index=False)","d977ca22":"submis","1ac105cc":"ohe_col = ['MSZoning','Street','Alley','LotShape','LandContour','LotConfig','LandSlope','Neighborhood',\n           'Condition1','Condition2','BldgType','HouseStyle','RoofStyle','RoofMatl','Exterior1st','Exterior2nd',\n           'MasVnrType','Foundation','Heating','Electrical','Functional','GarageType','GarageFinish','PavedDrive',\n           'Fence','MiscFeature','SaleType','SaleCondition']\n\nord_col = ['Utilities','ExterQual','ExterCond','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n           'HeatingQC','CentralAir','KitchenQual','FireplaceQu','GarageQual','GarageCond','PoolQC']"}}