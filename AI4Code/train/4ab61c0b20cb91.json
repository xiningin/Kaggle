{"cell_type":{"4d4a99b3":"code","a3bb60cc":"code","2faa794f":"code","3a889012":"code","e1886da6":"code","49f02b29":"code","84e250c7":"code","34c522e6":"code","e469b25b":"code","db446fff":"code","5f563a0a":"code","e6977e7b":"code","37a1be1d":"code","6b4e057e":"code","95f1ae0f":"code","2b80a263":"code","3784df1a":"code","4bedd807":"code","074c9c63":"code","42fd9494":"code","80676990":"code","cbaa489a":"code","972e0eea":"code","8efe19ae":"code","cee851d1":"code","0fe687f2":"code","135d2a50":"code","2b9b4fd2":"code","069075f0":"code","9b6057db":"code","b8ae3f75":"code","72b6997b":"code","a7ab1f91":"code","46de106c":"code","91678a7b":"code","f65ac96c":"code","616b7066":"code","e4b1c76f":"code","6720f313":"code","c031721c":"code","46d1d0ee":"code","396c187f":"code","426dffc7":"code","0a02a6c0":"code","efcc7c8a":"code","17de9439":"code","791ac4dd":"code","5ae041ae":"code","a6f9937f":"code","eb547e42":"code","64d1e014":"code","59f2c6d7":"code","95e1ac6c":"code","81285790":"code","2d92e6c7":"code","8a867eed":"code","b3127d32":"code","6b0bc599":"code","a12a599a":"code","75cc7ae6":"code","ada97f9b":"code","aa7e3692":"code","e10808c8":"code","2408a469":"code","2147b229":"code","dfc5dd27":"code","77d18f3c":"code","38f2679a":"code","312b4ceb":"code","d0a84e89":"code","530c582e":"code","4ab642d4":"code","1903721c":"code","76a48436":"code","9af8980c":"code","a34f7ddd":"code","8b29e8f9":"code","f1b56f55":"code","18ff290d":"code","331b16ba":"code","6553b7fa":"code","16c4bc3f":"code","f96a92bf":"code","61cebc34":"code","127f1fc4":"code","925d7f55":"code","81eef6a0":"code","2a9b762f":"code","03f82d2e":"code","47a38bee":"code","88bcb650":"code","91f63448":"code","e0e29869":"code","9714fd3f":"code","42b9bc0f":"code","c934919f":"code","94b18acd":"code","4a2c44c1":"code","b46c8ae6":"code","4bb12c49":"code","636753a3":"code","59291a8c":"code","fcb9e200":"code","c1b5af8b":"code","f4771b25":"code","c97419e5":"code","9cb3fb6f":"code","9db17a65":"code","d9faaf44":"code","bd9a58b0":"code","0caf0045":"code","b39fb2a2":"code","0157b813":"code","a2dcd356":"code","bd2430ee":"code","95946868":"code","392fd17d":"code","7433c92b":"code","2c5e2d31":"code","d1dc8868":"code","6e1870e5":"code","6ac7039d":"code","91a22d8c":"code","596a7750":"code","94958ef0":"code","f9a4fbe1":"code","b07f5bdc":"code","4e7284a9":"code","414859b6":"code","58bcc68e":"code","2c804557":"code","ee9aabea":"code","51c9f820":"code","131adb36":"code","b173b73d":"code","93213c98":"code","1734aaef":"code","61ecfd14":"code","2bd57921":"code","bcca4d27":"code","098d8338":"code","919dd713":"code","6d49dada":"code","e1e693d2":"code","41685017":"code","b362d8ed":"code","ecdd528c":"code","8a805b94":"code","7218d4a9":"code","595fdbab":"code","0d62702a":"code","0eade9ab":"code","865d45d0":"code","1da2dfd9":"code","e592581c":"code","3fa2c634":"code","9f9c9912":"code","6dabe92e":"code","beb8f3b5":"code","c50f3761":"code","313048e8":"code","24518955":"code","9691861f":"code","9032d94a":"code","a7105980":"code","162cfc05":"code","a96f44aa":"code","bc746188":"code","49c96077":"code","82b7b4ad":"code","3b32c22e":"code","892f9c2a":"code","0f74f174":"markdown","dc433333":"markdown","6e8f74da":"markdown","273790ea":"markdown","31e47efc":"markdown","12e893e0":"markdown","47e3905e":"markdown","423a1925":"markdown","b5b9fdbf":"markdown","816a8910":"markdown","3446717b":"markdown","d22a6ab8":"markdown","bde71dcf":"markdown","80ca753b":"markdown","3b2f1f5c":"markdown","51153494":"markdown","30bffd36":"markdown","f0e3dec4":"markdown","4bb55435":"markdown","3afc12cc":"markdown","b4845062":"markdown","7b149d55":"markdown","f3d719da":"markdown","55daae67":"markdown","a4ad20cb":"markdown","47c34c0b":"markdown","802a3247":"markdown","9ca4dbec":"markdown","56aa80a6":"markdown","5211246e":"markdown","0745915f":"markdown","bf97255f":"markdown","407ff76a":"markdown","ff1e7219":"markdown","8b4630a5":"markdown","08f11738":"markdown","aba459a3":"markdown","dd41e40b":"markdown","69ccb6de":"markdown","e7f766db":"markdown","1255af89":"markdown","b80c3842":"markdown","5a844a70":"markdown","f55841fe":"markdown","4c414105":"markdown","958281c9":"markdown","3c8b609b":"markdown","a9aa9fbd":"markdown","d0e9b574":"markdown","3e220329":"markdown","d0b5d866":"markdown","e8609f6a":"markdown","632a8d3b":"markdown","a91d9d53":"markdown","6b38c287":"markdown","8f9ab15a":"markdown","405ce533":"markdown","ee20a5ea":"markdown","4a1054e2":"markdown","67924848":"markdown","96a8bb92":"markdown","7ffb55e9":"markdown","80444645":"markdown","d26a612d":"markdown","5a63367f":"markdown","382b10e8":"markdown","ba8cca70":"markdown","c04d4eb2":"markdown"},"source":{"4d4a99b3":"# supress warnings\nimport warnings\nwarnings.filterwarnings('ignore')","a3bb60cc":"# import the required libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom matplotlib.pyplot import xticks","2faa794f":"# Display all columns\npd.set_option('display.max_columns',200)","3a889012":"# Read the csv file using 'read_csv'.\nleads = pd.read_csv(\"..\/input\/leadscore\/Leads.csv\")","e1886da6":"# Check the head of the dataset\nleads.head()","49f02b29":"# Check the number of rows and columns in the dataframe\nleads.shape","84e250c7":"# Types of all columns\nleads.info(verbose=True)","34c522e6":"# Check the summary for the numeric columns \nleads.describe()","e469b25b":"# Count the number of null values in each column\nleads.isnull().sum()","db446fff":"# Percentage of null values in each column\nnull_percentage = leads.isnull().sum() * 100 \/ len(leads)","5f563a0a":"# Top columns have highest percentages of null values\nnull_percentage.sort_values(ascending = False).head(50)","e6977e7b":"# List all of the columns having null values more than 30%\nnull_columns = null_percentage[null_percentage.values > 30].index\nnull_columns","37a1be1d":"# Remove those columns\nleads.drop(null_columns, axis=1, inplace=True)","6b4e057e":"# List of remaining columns which have null values\nnull_percentage = leads.isnull().sum() * 100 \/ len(leads)\nnull_percentage[null_percentage>0].sort_values(ascending = False)","95f1ae0f":"# Check the number of rows and columns in the dataframe\nleads.shape","2b80a263":"# Read the \"Country\" column to see what values it have\nleads[\"Country\"].value_counts()","3784df1a":"# Remove Country\nleads.drop(\"Country\", axis=1, inplace=True)","4bedd807":"# Drop City as well\nleads.drop(\"City\", axis=1, inplace=True)","074c9c63":"# View values of all columns\nfor c in leads:\n    print(leads[c].value_counts())\n    print(\"\\n\\n==============\\n\\n\")","42fd9494":"# Drop \"Specialization\", \"How did you hear about X Education\", \"Lead Profile\"\nleads.drop([\"How did you hear about X Education\", \"Lead Profile\"], axis=1, inplace=True)","80676990":"# Looking for columns still having \"Collect\" values\nyes_col = leads.columns[      \n    (leads == \"Collect\")        # mask \n    .any(axis=0)     # mask\n].values.tolist()\n\nyes_col\n# (Source: https:\/\/www.stackvidhya.com\/pandas-get-column-names\/)","cbaa489a":"# Drop \"Magazine\",\"Search\", \"Newspaper Article\", \"X Education Forums\", \"Newspaper\", \"Digital Advertisement\", \"Through Recommendations\", \"Receive More Updates About Our Courses\", \"Update me on Supply Chain Content\", \"Get updates on DM Content\", \"I agree to pay the amount through cheque\", \"What matters most to you in choosing a course\"\nleads.drop([\"Magazine\",\"Search\", \"Newspaper Article\", \"X Education Forums\", \"Newspaper\", \"Digital Advertisement\", \"Through Recommendations\", \"Receive More Updates About Our Courses\", \"Update me on Supply Chain Content\", \"Get updates on DM Content\", \"I agree to pay the amount through cheque\", \"What matters most to you in choosing a course\"], axis=1, inplace=True)","972e0eea":"# List of remaining columns which have null values\nnull_percentage = leads.isnull().sum() * 100 \/ len(leads)\nnull_percentage[null_percentage>0].sort_values(ascending = False)","8efe19ae":"# Read the \"What is your current occupation\" column to see what values it have\nleads[\"What is your current occupation\"].value_counts()","cee851d1":"# Drop the null rows of \"What is your current occupation\"\nleads = leads[~pd.isnull(leads[\"What is your current occupation\"])]","0fe687f2":"# Check the number of rows and columns in the dataframe\nleads.shape","135d2a50":"# List of remaining columns which have null values\nleads.isnull().sum().sort_values(ascending = False)","2b9b4fd2":"# Drop the null rows of \"TotalVisits\", \"Page Views Per Visit\"\nleads = leads[~pd.isnull(leads[\"TotalVisits\"])]\nleads = leads[~pd.isnull(leads[\"Page Views Per Visit\"])]\nleads = leads[~pd.isnull(leads[\"Last Activity\"])]\nleads = leads[~pd.isnull(leads[\"Lead Source\"])]","069075f0":"# List of remaining columns which have null values\nleads.isnull().sum().sort_values(ascending = False)","9b6057db":"# Check the number of rows and columns in the dataframe\nleads.shape","b8ae3f75":"# Recall the total number of columns\nleads.shape","72b6997b":"# Types of all columns\nleads.info(verbose=True)","a7ab1f91":"# Read the \"Prospect ID\" column to see what values it have\nleads[\"Prospect ID\"].value_counts()","46de106c":"# Read the \"Lead Source\" column to see what values it have\nleads[\"Lead Source\"].value_counts()","91678a7b":"# Replace \"google\" with \"Google\"\nleads[\"Lead Source\"].replace({\"google\": \"Google\"}, inplace=True)","f65ac96c":"# Read the \"Lead Source\" column to see what values it have\nleads[\"Lead Source\"].value_counts()","616b7066":"# Read the \"Lead Number\" column to see what values it have\nleads[\"Lead Number\"].value_counts()","e4b1c76f":"# Drop \"Lead Number\"\nleads.drop(columns=[\"Lead Number\"],inplace=True)","6720f313":"# Check columns types\nleads.info()","c031721c":"# Convert numeric values into categorical string values\nleads['Converted'] = leads['Converted'].map({1: 'Yes', 0: 'No'})","46d1d0ee":"# Check columns types\nleads.info()","396c187f":"# describe gives all numerical cols summary\nleads.describe()","426dffc7":"# Show all numerical columns\nleads.describe().columns","0a02a6c0":"leads[['TotalVisits', 'Total Time Spent on Website', 'Page Views Per Visit']].info()","efcc7c8a":"# Let's make a pairplot of all the numeric variables\nsns.pairplot(leads)\nplt.show()","17de9439":"# Correlation between numeric variables\ncor = leads[['TotalVisits', 'Total Time Spent on Website', 'Page Views Per Visit']].corr()\ncor","791ac4dd":"# Heatmap\nmask = np.array(cor)\nmask[np.tril_indices_from(mask)] = False\nsns.heatmap(cor, mask=mask, vmax=.8, square=True, annot=True);","5ae041ae":"# distplot for ['TotalVisits', 'Total Time Spent on Website'] -> Provide insights\nplt.figure(figsize=(20, 5))\nplt.subplot(1,2,1)\nsns.distplot(leads['TotalVisits'])\nplt.subplot(1,2,2)\nsns.distplot(leads['Total Time Spent on Website'])\nplt.show()","a6f9937f":"# distplot for 'Page Views Per Visit' -> Provide insights\nsns.distplot(leads['Page Views Per Visit'])\nplt.show()","eb547e42":"# Types of all columns\nleads.info()","64d1e014":"# Find all the categorical variables in the dataset\ndf_categorical = leads.select_dtypes(exclude=['float64','int64'])\ndf_categorical.columns","59f2c6d7":"# Function to plot distribution on a pie\ndef plot_univariate_pie(variable):\n    # Plot on a pie chart\n    fig, (ax1, ax2) = plt.subplots(1,2,figsize=(20,20))\n\n    # Not Converted\n    data_0 = leads[leads[\"Converted\"]==\"No\"][variable].value_counts()\n    labels = data_0.index\n    ax1.pie(data_0, autopct='%1.1f%%',\n            shadow=True, startangle=90)\n    ax1.set_title('Non-Converted')\n    ax1.legend(labels, loc=\"lower right\")\n\n    # Converted\n    data_1 = leads[leads[\"Converted\"]==\"Yes\"][variable].value_counts()\n    labels = data_1.index\n    ax2.pie(data_1, autopct='%1.1f%%',\n            shadow=True, startangle=90)\n    ax2.set_title('Converted')\n\n    ax2.legend(labels, loc=\"lower right\")\n\n    plt.show()","95e1ac6c":"def countplot(variable):\n    fig, axs = plt.subplots(figsize = (10,5))\n    sns.countplot(x = variable, hue = \"Converted\", data = leads)\n    xticks(rotation = 90)\n    plt.show()","81285790":"# Function to plot distribution on a pie\ndef plot_two_countplots(variable_1, variable_2):\n    plt.figure(figsize=(20,5))\n    plt.subplot(1,2,1)\n    xticks(rotation = 90)\n    sns.countplot(x = variable_1, hue = \"Converted\", data = leads)\n    plt.subplot(1,2,2)\n    sns.countplot(x = variable_2, hue = \"Converted\", data = leads)\n    xticks(rotation = 90)\n    plt.show()","2d92e6c7":"# Countplot for categorical variables\ncountplot('Lead Origin')","8a867eed":"# Countplot for categorical variables\ncountplot('Lead Source')","b3127d32":"# Replace blog, Pay per Click Ads, bing, Social Media, WeLearn, Click2call, Live Chat, welearnblog_Home, youtubechannel, testone, Press_Release, NC_EDM with \"others\"\nleads['Lead Source'] = leads['Lead Source'].replace(['blog', 'Pay per Click Ads', 'bing', 'Social Media', 'WeLearn', 'Click2call', 'Live Chat', 'welearnblog_Home', 'youtubechannel', 'testone', 'Press_Release', 'NC_EDM'], 'Others')","6b0bc599":"# Countplot for categorical variables\ncountplot('Lead Source')","a12a599a":"# Pie plot\nplot_univariate_pie('Lead Source')","75cc7ae6":"# Countplot for categorical variables\nplot_two_countplots('Do Not Email', 'Do Not Call')","ada97f9b":"# Countplot for categorical variables\nplot_two_countplots('Last Activity', 'Last Notable Activity')","aa7e3692":"# Countplot for categorical variables\nplot_two_countplots('Specialization', 'What is your current occupation')","e10808c8":"# Countplot for categorical variables\nsns.countplot(x = 'A free copy of Mastering The Interview', hue = \"Converted\", data = leads)\nplt.show()","2408a469":"# Pie plot\nplot_univariate_pie(\"A free copy of Mastering The Interview\")","2147b229":"# All columns\nleads.info(verbose=True)","dfc5dd27":"# Looking for columns having \"Yes\/No\" values\nyes_col = leads.columns[      \n    (leads == \"Yes\")        # mask \n    .any(axis=0)     # mask\n].values.tolist()\n\n# (Source: https:\/\/www.stackvidhya.com\/pandas-get-column-names\/)","77d18f3c":"# Defining the map function for Yes\/No to 1\/0\ndef binary_map(x):\n    return x.map({'Yes': 1, \"No\": 0})\n\n# Applying the function to the leads list\nleads[yes_col] = leads[yes_col].apply(binary_map)","38f2679a":"# View the data after converting\nleads[yes_col].head()","312b4ceb":"# Looking for categorical variables\nleads.select_dtypes(['object']).columns","d0a84e89":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy = pd.get_dummies(leads[['Lead Origin', 'Lead Source', 'Last Activity',\n       'What is your current occupation', 'Last Notable Activity']], drop_first=True)\n\n# Adding the results to the master dataframe\nleads = pd.concat([leads, dummy], axis=1)","530c582e":"leads.head()","4ab642d4":"# Creating a dummy variable for \"Specialization\" and dropping the first one.\ntemp = pd.get_dummies(leads[[\"Specialization\"]])\n\ntemp","1903721c":"# Drop the \"Specialization_Select\"\ntemp = temp.drop(['Specialization_Select'], 1)","76a48436":"# Concat temp with leads\nleads = pd.concat([leads,temp], axis = 1)","9af8980c":"# We have created dummies for the below variables, so we can drop them\nleads = leads.drop(['Lead Origin', 'Lead Source', 'Last Activity',\n       'What is your current occupation', 'Last Notable Activity', 'Specialization'], 1)","a34f7ddd":"# Import libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","8b29e8f9":"# Putting feature variable to X\nX = leads.drop(['Converted'], 1)\n\n# Putting response variable to y\ny = leads['Converted']","f1b56f55":"# View top rows of X\nX.head()","18ff290d":"# View top rows of y\ny.head()","331b16ba":"# Splitting the data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)","6553b7fa":"# Create places to store train & test data with Prospect ID\nX_train_data = X_train\nX_test_data = X_test","16c4bc3f":"# Make sure X_test_data having Prospect ID\nX_test_data","f96a92bf":"# Make sure X_train_data having Prospect ID\nX_train_data","61cebc34":"# Drop \"Prospect ID\"\nX_train = X_train.drop(columns=[\"Prospect ID\"])\nX_test = X_test.drop(columns=[\"Prospect ID\"])","127f1fc4":"# Show all numerical columns\nX_train.describe().columns","925d7f55":"# Scale features of X train set\nscaler = StandardScaler()\n\nX_train[['Do Not Email', 'Do Not Call', 'TotalVisits',\n       'Total Time Spent on Website', 'Page Views Per Visit',\n       'A free copy of Mastering The Interview',\n       'Lead Origin_Landing Page Submission', 'Lead Origin_Lead Add Form',\n       'Lead Origin_Lead Import', 'Lead Source_Facebook', 'Lead Source_Google',\n       'Lead Source_Olark Chat', 'Lead Source_Organic Search',\n       'Lead Source_Others', 'Lead Source_Reference',\n       'Lead Source_Referral Sites', 'Lead Source_Welingak Website',\n       'Last Activity_Converted to Lead', 'Last Activity_Email Bounced',\n       'Last Activity_Email Link Clicked', 'Last Activity_Email Marked Spam',\n       'Last Activity_Email Opened', 'Last Activity_Email Received',\n       'Last Activity_Form Submitted on Website',\n       'Last Activity_Had a Phone Conversation',\n       'Last Activity_Olark Chat Conversation',\n       'Last Activity_Page Visited on Website', 'Last Activity_SMS Sent',\n       'Last Activity_Unreachable', 'Last Activity_Unsubscribed',\n       'Last Activity_View in browser link Clicked',\n       'Last Activity_Visited Booth in Tradeshow',\n       'What is your current occupation_Housewife',\n       'What is your current occupation_Other',\n       'What is your current occupation_Student',\n       'What is your current occupation_Unemployed',\n       'What is your current occupation_Working Professional',\n       'Last Notable Activity_Email Bounced',\n       'Last Notable Activity_Email Link Clicked',\n       'Last Notable Activity_Email Marked Spam',\n       'Last Notable Activity_Email Opened',\n       'Last Notable Activity_Email Received',\n       'Last Notable Activity_Had a Phone Conversation',\n       'Last Notable Activity_Modified',\n       'Last Notable Activity_Olark Chat Conversation',\n       'Last Notable Activity_Page Visited on Website',\n       'Last Notable Activity_SMS Sent', 'Last Notable Activity_Unreachable',\n       'Last Notable Activity_Unsubscribed',\n       'Last Notable Activity_View in browser link Clicked',\n       'Specialization_Banking, Investment And Insurance',\n       'Specialization_Business Administration', 'Specialization_E-Business',\n       'Specialization_E-COMMERCE', 'Specialization_Finance Management',\n       'Specialization_Healthcare Management',\n       'Specialization_Hospitality Management',\n       'Specialization_Human Resource Management',\n       'Specialization_IT Projects Management',\n       'Specialization_International Business',\n       'Specialization_Marketing Management',\n       'Specialization_Media and Advertising',\n       'Specialization_Operations Management',\n       'Specialization_Retail Management',\n       'Specialization_Rural and Agribusiness',\n       'Specialization_Services Excellence',\n       'Specialization_Supply Chain Management',\n       'Specialization_Travel and Tourism']] = scaler.fit_transform(X_train[['Do Not Email', 'Do Not Call', 'TotalVisits',\n       'Total Time Spent on Website', 'Page Views Per Visit',\n       'A free copy of Mastering The Interview',\n       'Lead Origin_Landing Page Submission', 'Lead Origin_Lead Add Form',\n       'Lead Origin_Lead Import', 'Lead Source_Facebook', 'Lead Source_Google',\n       'Lead Source_Olark Chat', 'Lead Source_Organic Search',\n       'Lead Source_Others', 'Lead Source_Reference',\n       'Lead Source_Referral Sites', 'Lead Source_Welingak Website',\n       'Last Activity_Converted to Lead', 'Last Activity_Email Bounced',\n       'Last Activity_Email Link Clicked', 'Last Activity_Email Marked Spam',\n       'Last Activity_Email Opened', 'Last Activity_Email Received',\n       'Last Activity_Form Submitted on Website',\n       'Last Activity_Had a Phone Conversation',\n       'Last Activity_Olark Chat Conversation',\n       'Last Activity_Page Visited on Website', 'Last Activity_SMS Sent',\n       'Last Activity_Unreachable', 'Last Activity_Unsubscribed',\n       'Last Activity_View in browser link Clicked',\n       'Last Activity_Visited Booth in Tradeshow',\n       'What is your current occupation_Housewife',\n       'What is your current occupation_Other',\n       'What is your current occupation_Student',\n       'What is your current occupation_Unemployed',\n       'What is your current occupation_Working Professional',\n       'Last Notable Activity_Email Bounced',\n       'Last Notable Activity_Email Link Clicked',\n       'Last Notable Activity_Email Marked Spam',\n       'Last Notable Activity_Email Opened',\n       'Last Notable Activity_Email Received',\n       'Last Notable Activity_Had a Phone Conversation',\n       'Last Notable Activity_Modified',\n       'Last Notable Activity_Olark Chat Conversation',\n       'Last Notable Activity_Page Visited on Website',\n       'Last Notable Activity_SMS Sent', 'Last Notable Activity_Unreachable',\n       'Last Notable Activity_Unsubscribed',\n       'Last Notable Activity_View in browser link Clicked',\n       'Specialization_Banking, Investment And Insurance',\n       'Specialization_Business Administration', 'Specialization_E-Business',\n       'Specialization_E-COMMERCE', 'Specialization_Finance Management',\n       'Specialization_Healthcare Management',\n       'Specialization_Hospitality Management',\n       'Specialization_Human Resource Management',\n       'Specialization_IT Projects Management',\n       'Specialization_International Business',\n       'Specialization_Marketing Management',\n       'Specialization_Media and Advertising',\n       'Specialization_Operations Management',\n       'Specialization_Retail Management',\n       'Specialization_Rural and Agribusiness',\n       'Specialization_Services Excellence',\n       'Specialization_Supply Chain Management',\n       'Specialization_Travel and Tourism']])\n\nX_train.head()","81eef6a0":"### Checking the Converted Rate\nconverted_rate = (sum(leads['Converted'])\/len(leads['Converted'].index))*100\nconverted_rate","2a9b762f":"# Correlation matrix\nleads.corr()","03f82d2e":"# Let's see the correlation matrix \nplt.figure(figsize = (20,10))        # Size of the figure\nmask = np.array(leads.corr())\nmask[np.tril_indices_from(mask)] = False\nsns.heatmap(leads.corr(), mask=mask, vmax=.8, square=True, annot = True)\nplt.show()","47a38bee":"# Selecting strong correlation pairs (magnitude greater than 0.5)\ncorrelation_mat = leads.corr()\ncorr_pairs = correlation_mat.unstack()\nsorted_pairs = corr_pairs.sort_values(kind=\"quicksort\")\nstrong_pairs = sorted_pairs[abs(sorted_pairs) > 0.5]\n\nprint(\"Strong correlation pairs (magnitude greater than 0.5):\")\nprint(strong_pairs)\n\n# (Source: https:\/\/likegeeks.com\/python-correlation-matrix\/)","88bcb650":"# Remove duplicated pairs in the correlation table\ndef get_redundant_pairs(df):\n    '''Get diagonal and lower triangular pairs of correlation matrix'''\n    pairs_to_drop = set()\n    cols = df.columns\n    for i in range(0, df.shape[1]):\n        for j in range(0, i+1):\n            pairs_to_drop.add((cols[i], cols[j]))\n    return pairs_to_drop\n\n# Get top pairs\ndef get_top_abs_correlations(df, n=10):\n    corr_list = df.abs().unstack()\n    labels_to_drop = get_redundant_pairs(df)\n    corr_list = corr_list.drop(labels=labels_to_drop).sort_values(ascending=False)\n    return corr_list[0:n]\n\n#(Source: https:\/\/stackoverflow.com\/questions\/17778394\/list-highest-correlation-pairs-from-a-large-correlation-matrix-in-pandas)","91f63448":"# Get top 10 correlation pairs\nprint(\"Top 10 correlation pairs:\")\nget_top_abs_correlations(correlation_mat, 10)","e0e29869":"# Create object of Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()","9714fd3f":"## For the Subjective Questions\n# Import RFE and select 3 variables\n# from sklearn.feature_selection import RFE\n# rfe = RFE(logreg, 3)             # running RFE with 3 variables as output\n# rfe = rfe.fit(X_train, y_train)","42b9bc0f":"# All of the columns selected by RFE\n# col = X_train.columns[rfe.support_]\n# col","c934919f":"# Import RFE and select 15 variables\nfrom sklearn.feature_selection import RFE\nrfe = RFE(logreg, 15)             # running RFE with 15 variables as output\nrfe = rfe.fit(X_train, y_train)","94b18acd":"# See the RFE Ranking\nlist(zip(X_train.columns, rfe.support_, rfe.ranking_))","4a2c44c1":"# All of the columns selected by RFE\ncol = X_train.columns[rfe.support_]\ncol","b46c8ae6":"# See the columns not selected by RFE\nX_train.columns[~rfe.support_]","4bb12c49":"# New X_train = columns selected by RFE\nX_train = X_train[col]","636753a3":"# Import statsmodels\nimport statsmodels.api as sm\n\n# Assess the model with StatsModels\nX_train_sm = sm.add_constant(X_train)\nlogm1 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm1.fit()\nres.summary()","59291a8c":"# Check for the VIF values of the feature variables. \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","fcb9e200":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","c1b5af8b":"# Drop \"Lead Source_Reference\" and \"Lead Source_Welingak Website\"\nX_train = X_train.drop([\"Lead Source_Reference\", \"Lead Source_Welingak Website\"], 1)","f4771b25":"# View X_train\nX_train","c97419e5":"# Let's re-run the model using the selected variables\nX_train_sm = sm.add_constant(X_train)\nlogm2 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm2.fit()\nres.summary()","9cb3fb6f":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","9db17a65":"# Drop \"Last Notable Activity_Had a Phone Conversation\"\nX_train = X_train.drop(\"Last Notable Activity_Had a Phone Conversation\", 1)","d9faaf44":"# Let's re-run the model using the selected variables\nlogm3 = sm.GLM(y_train,sm.add_constant(X_train), family = sm.families.Binomial())\nlogm3.fit().summary()","bd9a58b0":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","0caf0045":"# Drop \"Last Activity_View in browser link Clicked\"\nX_train = X_train.drop(\"Last Activity_View in browser link Clicked\", 1)","b39fb2a2":"# Let's re-run the model using the selected variables\nlogm4 = sm.GLM(y_train,sm.add_constant(X_train), family = sm.families.Binomial())\nlogm4.fit().summary()","0157b813":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","a2dcd356":"# Drop \"What is your current occupation_Housewife\"\nX_train = X_train.drop(\"What is your current occupation_Housewife\", 1)","bd2430ee":"# Let's re-run the model using the selected variables\nX_train_sm = sm.add_constant(X_train)\nlogm4 = sm.GLM(y_train,X_train_sm, family = sm.families.Binomial())\nres = logm4.fit()\nres.summary()","95946868":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","392fd17d":"# Getting the predicted values on the train set\ny_train_pred = res.predict(X_train_sm)\ny_train_pred[:10]","7433c92b":"# Reshape it into an array\ny_train_pred = y_train_pred.values.reshape(-1)\ny_train_pred[:10]","2c5e2d31":"# Create dataframe with conversion flag and predicted probabilities\ny_train_pred_final = pd.DataFrame({'Converted':y_train.values, 'Converted_Prob':y_train_pred})\ny_train_pred_final.head()","d1dc8868":"# Creating new column 'predicted' with 1 if Converted_Prob > 0.5 else 0\ny_train_pred_final['predicted'] = y_train_pred_final.Converted_Prob.map(lambda x: 1 if x > 0.5 else 0)\n\n# Let's see the head\ny_train_pred_final.head()","6e1870e5":"# import metrics\nfrom sklearn import metrics","6ac7039d":"# Let's check the overall accuracy.\nprint(metrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.predicted))","91a22d8c":"# Confusion matrix \nconfusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.predicted )\nprint(confusion)","596a7750":"#Predicted     not_converted    converted\n#Actual\n#not_converted    1959         390\n#converted            565        1559 ","94958ef0":"# Evaluate other metrics\nTP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives","f9a4fbe1":"# Let's see the sensitivity of our logistic regression model\nTP \/ float(TP+FN)","b07f5bdc":"# Let us calculate specificity\nTN \/ float(TN+FP)","4e7284a9":"# ROC function\ndef draw_roc( actual, probs ):\n    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n                                              drop_intermediate = False )\n    auc_score = metrics.roc_auc_score( actual, probs )\n    plt.figure(figsize=(5, 5))\n    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return None","414859b6":"# Draw the ROC\ndraw_roc(y_train_pred_final.Converted, y_train_pred_final.Converted_Prob)","58bcc68e":"# Let's create columns with different probability cutoffs \nnumbers = [float(x)\/10 for x in range(10)]\nfor i in numbers:\n    y_train_pred_final[i]= y_train_pred_final.Converted_Prob.map(lambda x: 1 if x > i else 0)\ny_train_pred_final.head()","2c804557":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df = pd.DataFrame( columns = ['probability','accuracy','sensitivity','specificity'])\nfrom sklearn.metrics import confusion_matrix\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final[i] )\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])\/total1\n    \n    speci = cm1[0,0]\/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]\/(cm1[1,0]+cm1[1,1])\n    cutoff_df.loc[i] =[ i, accuracy, sensi, speci]\nprint(cutoff_df)","ee9aabea":"# Let's plot accuracy sensitivity and specificity for various probabilities.\ncutoff_df.plot.line(x='probability', y=['accuracy','sensitivity','specificity'])\nplt.show()","51c9f820":"# Creating new column 'predicted' with 1 if Converted_Prob > 0.42 else 0\ny_train_pred_final['final_predicted'] = y_train_pred_final.Converted_Prob.map( lambda x: 1 if x >= 0.42 else 0)\n\n# View top rows of y_train_pred_final\ny_train_pred_final.head()","131adb36":"# Let's check the overall accuracy.\nmetrics.accuracy_score(y_train_pred_final.Converted, y_train_pred_final.final_predicted)","b173b73d":"# Confusion matrix \nconfusion2 = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.final_predicted)\nprint(confusion2)","93213c98":"#Predicted     not_converted    converted\n#Actual\n#not_converted    1959         390\n#converted            565        1559 ","1734aaef":"# Evaluate other metrics\n\nTP = confusion2[1,1] # true positive \nTN = confusion2[0,0] # true negatives\nFP = confusion2[0,1] # false positives\nFN = confusion2[1,0] # false negatives","61ecfd14":"# Let's see the sensitivity of our logistic regression model\nTP \/ float(TP+FN)","2bd57921":"# Let us calculate specificity\nTN \/ float(TN+FP)","bcca4d27":"#Looking at the confusion matrix again with the original predicted value\nconfusion = metrics.confusion_matrix(y_train_pred_final.Converted, y_train_pred_final.predicted)\nconfusion","098d8338":"# Calculate Precision\nconfusion[1,1]\/(confusion[0,1]+confusion[1,1])","919dd713":"# Calculate Recall\nconfusion[1,1]\/(confusion[1,0]+confusion[1,1])","6d49dada":"# import precision_recall_curve\nfrom sklearn.metrics import precision_recall_curve","e1e693d2":"# Calculate precision & recall\np, r, thresholds = precision_recall_curve(y_train_pred_final.Converted, y_train_pred_final.Converted_Prob)","41685017":"# Plot precision & recall\nplt.plot(thresholds, p[:-1], \"g-\")\nplt.plot(thresholds, r[:-1], \"r-\")\nplt.show()","b362d8ed":"# Scale X_test\nX_test[['Do Not Email', 'Do Not Call', 'TotalVisits',\n       'Total Time Spent on Website', 'Page Views Per Visit',\n       'A free copy of Mastering The Interview',\n       'Lead Origin_Landing Page Submission', 'Lead Origin_Lead Add Form',\n       'Lead Origin_Lead Import', 'Lead Source_Facebook', 'Lead Source_Google',\n       'Lead Source_Olark Chat', 'Lead Source_Organic Search',\n       'Lead Source_Others', 'Lead Source_Reference',\n       'Lead Source_Referral Sites', 'Lead Source_Welingak Website',\n       'Last Activity_Converted to Lead', 'Last Activity_Email Bounced',\n       'Last Activity_Email Link Clicked', 'Last Activity_Email Marked Spam',\n       'Last Activity_Email Opened', 'Last Activity_Email Received',\n       'Last Activity_Form Submitted on Website',\n       'Last Activity_Had a Phone Conversation',\n       'Last Activity_Olark Chat Conversation',\n       'Last Activity_Page Visited on Website', 'Last Activity_SMS Sent',\n       'Last Activity_Unreachable', 'Last Activity_Unsubscribed',\n       'Last Activity_View in browser link Clicked',\n       'Last Activity_Visited Booth in Tradeshow',\n       'What is your current occupation_Housewife',\n       'What is your current occupation_Other',\n       'What is your current occupation_Student',\n       'What is your current occupation_Unemployed',\n       'What is your current occupation_Working Professional',\n       'Last Notable Activity_Email Bounced',\n       'Last Notable Activity_Email Link Clicked',\n       'Last Notable Activity_Email Marked Spam',\n       'Last Notable Activity_Email Opened',\n       'Last Notable Activity_Email Received',\n       'Last Notable Activity_Had a Phone Conversation',\n       'Last Notable Activity_Modified',\n       'Last Notable Activity_Olark Chat Conversation',\n       'Last Notable Activity_Page Visited on Website',\n       'Last Notable Activity_SMS Sent', 'Last Notable Activity_Unreachable',\n       'Last Notable Activity_Unsubscribed',\n       'Last Notable Activity_View in browser link Clicked',\n       'Specialization_Banking, Investment And Insurance',\n       'Specialization_Business Administration', 'Specialization_E-Business',\n       'Specialization_E-COMMERCE', 'Specialization_Finance Management',\n       'Specialization_Healthcare Management',\n       'Specialization_Hospitality Management',\n       'Specialization_Human Resource Management',\n       'Specialization_IT Projects Management',\n       'Specialization_International Business',\n       'Specialization_Marketing Management',\n       'Specialization_Media and Advertising',\n       'Specialization_Operations Management',\n       'Specialization_Retail Management',\n       'Specialization_Rural and Agribusiness',\n       'Specialization_Services Excellence',\n       'Specialization_Supply Chain Management',\n       'Specialization_Travel and Tourism']] = scaler.transform(X_test[['Do Not Email', 'Do Not Call', 'TotalVisits',\n       'Total Time Spent on Website', 'Page Views Per Visit',\n       'A free copy of Mastering The Interview',\n       'Lead Origin_Landing Page Submission', 'Lead Origin_Lead Add Form',\n       'Lead Origin_Lead Import', 'Lead Source_Facebook', 'Lead Source_Google',\n       'Lead Source_Olark Chat', 'Lead Source_Organic Search',\n       'Lead Source_Others', 'Lead Source_Reference',\n       'Lead Source_Referral Sites', 'Lead Source_Welingak Website',\n       'Last Activity_Converted to Lead', 'Last Activity_Email Bounced',\n       'Last Activity_Email Link Clicked', 'Last Activity_Email Marked Spam',\n       'Last Activity_Email Opened', 'Last Activity_Email Received',\n       'Last Activity_Form Submitted on Website',\n       'Last Activity_Had a Phone Conversation',\n       'Last Activity_Olark Chat Conversation',\n       'Last Activity_Page Visited on Website', 'Last Activity_SMS Sent',\n       'Last Activity_Unreachable', 'Last Activity_Unsubscribed',\n       'Last Activity_View in browser link Clicked',\n       'Last Activity_Visited Booth in Tradeshow',\n       'What is your current occupation_Housewife',\n       'What is your current occupation_Other',\n       'What is your current occupation_Student',\n       'What is your current occupation_Unemployed',\n       'What is your current occupation_Working Professional',\n       'Last Notable Activity_Email Bounced',\n       'Last Notable Activity_Email Link Clicked',\n       'Last Notable Activity_Email Marked Spam',\n       'Last Notable Activity_Email Opened',\n       'Last Notable Activity_Email Received',\n       'Last Notable Activity_Had a Phone Conversation',\n       'Last Notable Activity_Modified',\n       'Last Notable Activity_Olark Chat Conversation',\n       'Last Notable Activity_Page Visited on Website',\n       'Last Notable Activity_SMS Sent', 'Last Notable Activity_Unreachable',\n       'Last Notable Activity_Unsubscribed',\n       'Last Notable Activity_View in browser link Clicked',\n       'Specialization_Banking, Investment And Insurance',\n       'Specialization_Business Administration', 'Specialization_E-Business',\n       'Specialization_E-COMMERCE', 'Specialization_Finance Management',\n       'Specialization_Healthcare Management',\n       'Specialization_Hospitality Management',\n       'Specialization_Human Resource Management',\n       'Specialization_IT Projects Management',\n       'Specialization_International Business',\n       'Specialization_Marketing Management',\n       'Specialization_Media and Advertising',\n       'Specialization_Operations Management',\n       'Specialization_Retail Management',\n       'Specialization_Rural and Agribusiness',\n       'Specialization_Services Excellence',\n       'Specialization_Supply Chain Management',\n       'Specialization_Travel and Tourism']])","ecdd528c":"# Select the columns in X_train for X_test as well\nX_test = X_test[col]\nX_test.head()\nX_test.shape","8a805b94":"# Drop the required columns on X_test\nX_test.drop([\"Lead Source_Reference\", \"Lead Source_Welingak Website\", \"Last Activity_View in browser link Clicked\", \"What is your current occupation_Housewife\", \"Last Notable Activity_Had a Phone Conversation\"], 1, inplace=True)","7218d4a9":"X_test.columns","595fdbab":"# Make prediction on test set\ny_test_pred = res.predict(sm.add_constant(X_test))","0d62702a":"# View y_test_pred\ny_test_pred[:10]","0eade9ab":"# Converting y_pred to a dataframe which is an array\ny_pred_1 = pd.DataFrame(y_test_pred)","865d45d0":"# Let's see the head\ny_pred_1.head()","1da2dfd9":"# Converting y_test to dataframe\ny_test_df = pd.DataFrame(y_test)","e592581c":"# Removing index for both dataframes to append them side by side \ny_pred_1.reset_index(drop=True, inplace=True)\ny_test_df.reset_index(drop=True, inplace=True)","3fa2c634":"# Appending y_test_df and y_pred_1\ny_pred_final = pd.concat([y_test_df, y_pred_1],axis=1)","9f9c9912":"# Check y_pred_final\ny_pred_final.head()","6dabe92e":"# Renaming the column \ny_pred_final= y_pred_final.rename(columns={ 0 : 'Converted_Prob'})","beb8f3b5":"# Let's see the head of y_pred_final\ny_pred_final.head()","c50f3761":"# Calculate final_predicted with cutoff point 0.42\ny_pred_final['final_predicted'] = y_pred_final.Converted_Prob.map(lambda x: 1 if x > 0.42 else 0)","313048e8":"# View y_pred_final\ny_pred_final","24518955":"# Let's check the overall accuracy.\nmetrics.accuracy_score(y_pred_final.Converted, y_pred_final.final_predicted)","9691861f":"# Calculate confusion matrix\nconfusion2 = metrics.confusion_matrix(y_pred_final.Converted, y_pred_final.final_predicted)\nconfusion2","9032d94a":"# Calculate TP, TN, FP, FN\nTP = confusion2[1,1] # true positive \nTN = confusion2[0,0] # true negatives\nFP = confusion2[0,1] # false positives\nFN = confusion2[1,0] # false negatives","a7105980":"# Let's see the sensitivity of our logistic regression model\nTP \/ float(TP+FN)","162cfc05":"# Let's calculate specificity\nTN \/ float(TN+FP)","a96f44aa":"# Removing index for both dataframes to append them side by side \nX_test_data.reset_index(drop=True, inplace=True)\ny_pred_final.reset_index(drop=True, inplace=True)","bc746188":"# Assign Lead Score to test data\ntest_data = pd.DataFrame({\"Prospect ID\": X_test_data[\"Prospect ID\"], \"Lead Score\": y_pred_final['Converted_Prob'] * 100})","49c96077":"# Removing index for both dataframes to append them side by side \nX_train_data.reset_index(drop=True, inplace=True)\ny_train_pred_final.reset_index(drop=True, inplace=True)","82b7b4ad":"# Assign Lead Score to train data\ntrain_data = pd.DataFrame({\"Prospect ID\": X_train_data[\"Prospect ID\"], \"Lead Score\": y_train_pred_final['Converted_Prob'] * 100})","3b32c22e":"# Merge train & test data to a final result with lead score\nfinal_data = pd.concat([train_data, test_data],axis=0)","892f9c2a":"# Top 20 potential leads\nfinal_data.sort_values(by=['Lead Score'], ascending=False).head(20)","0f74f174":"### Visualising Categorical Variables","dc433333":"### Precision\nTP \/ TP + FP","6e8f74da":"From the list above, it can be seen that there are 7 columns having null values more than ~30%. Because they have a lot of missing values, we will remove them.","273790ea":"From the curve above, 0.42 is the optimum point to take it as a cutoff probability.","31e47efc":"Insights:\n- Most of the customers had less than 20 times visiting the website\n- Most of the customers viewed less than 5 pages per visit\n- Most of the total time spent on the website were less than 2,000.","12e893e0":"## Precision and Recall","47e3905e":"### For categorical variables with multiple levels, create dummy features (one-hot encoded)","423a1925":"## Assigning a lead score between 0 and 100 to each of the leads","b5b9fdbf":"Insights: p-values > 0.05:\n - Lead Source_Reference\n - Lead Source_Welingak Website\n - Last Activity_View in browser link Clicked\t\n - What is your current occupation_Housewife\n - Last Notable Activity_Had a Phone Conversation","816a8910":"VIFs are less than 5 -> Drop variables with high p-value, \"What is your current occupation_Housewife\"","3446717b":"### Metrics beyond simply accuracy","d22a6ab8":"## Test-Train Split","bde71dcf":"There are very few customers coming from blog, Pay per Click Ads, bing, Social Media, WeLearn, Click2call, Live Chat, welearnblog_Home, youtubechannel, testone, Press_Release, NC_EDM => Will replace those with \"Others\".","80ca753b":"### Evaluate Model","3b2f1f5c":"Insights:\n\n- Most of the customers are identified to be a lead (lead origin) from API, Landing Page Submission and Lead Add Form. Lead Add Form is the most correct identifier to determine Converted Customers.\n\n- Most customers are from Google and Direct Traffic. \"Reference\" and \"Welingak Website\" Source have more converted customers than non-converted customers.\n\n- Most customers selected \"Do not call\" and \"Do not email\", no matter they are converted or not.\n\n- Last activity and last notable activity of converted customers is \"Sent SMS\", while last activity of not-converted customers is \"Opened Email\".\n\n- Most customers are from unemployed.\n\n- Most customers did not choose their specialization. The others mainly work in management fields.\n\n- Most customers do not want A free copy of Mastering The Interview. Similar pattern for Converted and Not-converted customers.","51153494":"### Creating a dataframe with the actual conversion flag and the predicted probabilities","30bffd36":"Drop \"Lead Source_Reference\" and \"Lead Source_Welingak Website\" because they have high p-value and high VIF.","f0e3dec4":"## Making predictions on the test set","4bb55435":"### Creating new column 'predicted' with 1 if Converted_Prob > 0.42 else 0","3afc12cc":"**Lead Origin**","b4845062":"**Lead Source**","7b149d55":"Prospect ID has characters in its value => object type is correct.","f3d719da":"### Metrics beyond simply accuracy","55daae67":"### Recall\nTP \/ TP + FN","a4ad20cb":"By looking at the list above, it can be seen that there is no column having an inappropriate data types. There is no \"Date_of_birth\" \/ \"Birthday\", so we don't need to check and make sure that it is in the DATE TIME type.","47c34c0b":"**Occupation**","802a3247":"### Examine other columns","9ca4dbec":"We have almost 48% converted rate","56aa80a6":"Country seems not adding any values -> Drop it.","5211246e":"### Evaluate Model","0745915f":"This cutoff point seems good to go!","bf97255f":"VIFs are less than 5 -> Drop variables with high p-value, \"Last Activity_View in browser link Clicked\"","407ff76a":"### Deal with variables missing a lot of data","ff1e7219":"Cannot see anything clearly -> try another method as below:","8b4630a5":"## Data Preparation","08f11738":"## Data Cleaning","aba459a3":"## Looking at Correlations","dd41e40b":"### Deal with invalid and unnecessary data","69ccb6de":"## Model Evaluation","e7f766db":"Insights:\n- No multicollinear relationship","1255af89":"VIFs are less than 5 -> Drop variables with high p-value, starting with \"Last Notable Activity_Had a Phone Conversation\"","b80c3842":"### Creating new column 'predicted' with 1 if Converted_Prob > 0.5 else 0","5a844a70":"Insights: p-values > 0.05:\n - What is your current occupation_Housewife","f55841fe":"## Feature Selection","4c414105":"Insights: p-values > 0.05:\n - Last Activity_View in browser link Clicked\n - What is your current occupation_Housewife\n - Last Notable Activity_Had a Phone Conversation","958281c9":"<h1>Table of Contents<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Reading-and-Understanding-the-Data\" data-toc-modified-id=\"Reading-and-Understanding-the-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;<\/span>Reading and Understanding the Data<\/a><\/span><\/li><li><span><a href=\"#Data-Cleaning\" data-toc-modified-id=\"Data-Cleaning-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;<\/span>Data Cleaning<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Deal-with-variables-missing-a-lot-of-data\" data-toc-modified-id=\"Deal-with-variables-missing-a-lot-of-data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;<\/span>Deal with variables missing a lot of data<\/a><\/span><\/li><li><span><a href=\"#Examine-other-columns\" data-toc-modified-id=\"Examine-other-columns-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;<\/span>Examine other columns<\/a><\/span><\/li><li><span><a href=\"#Deal-with-invalid-and-unnecessary-data\" data-toc-modified-id=\"Deal-with-invalid-and-unnecessary-data-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;<\/span>Deal with invalid and unnecessary data<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Visualising-the-Data\" data-toc-modified-id=\"Visualising-the-Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;<\/span>Visualising the Data<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Visualising-Numeric-Variables\" data-toc-modified-id=\"Visualising-Numeric-Variables-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;<\/span>Visualising Numeric Variables<\/a><\/span><\/li><li><span><a href=\"#Visualising-Categorical-Variables\" data-toc-modified-id=\"Visualising-Categorical-Variables-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;<\/span>Visualising Categorical Variables<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Data-Preparation\" data-toc-modified-id=\"Data-Preparation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;<\/span>Data Preparation<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Converting-some-binary-variables-(Yes\/No)-to-0\/1\" data-toc-modified-id=\"Converting-some-binary-variables-(Yes\/No)-to-0\/1-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;<\/span>Converting some binary variables (Yes\/No) to 0\/1<\/a><\/span><\/li><li><span><a href=\"#For-categorical-variables-with-multiple-levels,-create-dummy-features-(one-hot-encoded)\" data-toc-modified-id=\"For-categorical-variables-with-multiple-levels,-create-dummy-features-(one-hot-encoded)-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;<\/span>For categorical variables with multiple levels, create dummy features (one-hot encoded)<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Test-Train-Split\" data-toc-modified-id=\"Test-Train-Split-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;<\/span>Test-Train Split<\/a><\/span><\/li><li><span><a href=\"#Feature-Scaling\" data-toc-modified-id=\"Feature-Scaling-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;<\/span>Feature Scaling<\/a><\/span><\/li><li><span><a href=\"#Looking-at-Correlations\" data-toc-modified-id=\"Looking-at-Correlations-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;<\/span>Looking at Correlations<\/a><\/span><\/li><li><span><a href=\"#Feature-Selection\" data-toc-modified-id=\"Feature-Selection-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;<\/span>Feature Selection<\/a><\/span><\/li><li><span><a href=\"#Assessing-the-model-with-StatsModels\" data-toc-modified-id=\"Assessing-the-model-with-StatsModels-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;<\/span>Assessing the model with StatsModels<\/a><\/span><\/li><li><span><a href=\"#Checking-VIFs\" data-toc-modified-id=\"Checking-VIFs-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;<\/span>Checking VIFs<\/a><\/span><\/li><li><span><a href=\"#Model-Evaluation\" data-toc-modified-id=\"Model-Evaluation-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;<\/span>Model Evaluation<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Creating-a-dataframe-with-the-actual-conversion-flag-and-the-predicted-probabilities\" data-toc-modified-id=\"Creating-a-dataframe-with-the-actual-conversion-flag-and-the-predicted-probabilities-11.1\"><span class=\"toc-item-num\">11.1&nbsp;&nbsp;<\/span>Creating a dataframe with the actual conversion flag and the predicted probabilities<\/a><\/span><\/li><li><span><a href=\"#Creating-new-column-'predicted'-with-1-if-Converted_Prob->-0.5-else-0\" data-toc-modified-id=\"Creating-new-column-'predicted'-with-1-if-Converted_Prob->-0.5-else-0-11.2\"><span class=\"toc-item-num\">11.2&nbsp;&nbsp;<\/span>Creating new column 'predicted' with 1 if Converted_Prob &gt; 0.5 else 0<\/a><\/span><\/li><li><span><a href=\"#Evaluate-Model\" data-toc-modified-id=\"Evaluate-Model-11.3\"><span class=\"toc-item-num\">11.3&nbsp;&nbsp;<\/span>Evaluate Model<\/a><\/span><\/li><li><span><a href=\"#Metrics-beyond-simply-accuracy\" data-toc-modified-id=\"Metrics-beyond-simply-accuracy-11.4\"><span class=\"toc-item-num\">11.4&nbsp;&nbsp;<\/span>Metrics beyond simply accuracy<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Finding-the-optimal-cut-off\" data-toc-modified-id=\"Finding-the-optimal-cut-off-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;<\/span>Finding the optimal cut off<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Creating-new-column-'predicted'-with-1-if-Converted_Prob->-0.42-else-0\" data-toc-modified-id=\"Creating-new-column-'predicted'-with-1-if-Converted_Prob->-0.42-else-0-12.1\"><span class=\"toc-item-num\">12.1&nbsp;&nbsp;<\/span>Creating new column 'predicted' with 1 if Converted_Prob &gt; 0.42 else 0<\/a><\/span><\/li><li><span><a href=\"#Evaluate-Model\" data-toc-modified-id=\"Evaluate-Model-12.2\"><span class=\"toc-item-num\">12.2&nbsp;&nbsp;<\/span>Evaluate Model<\/a><\/span><\/li><li><span><a href=\"#Metrics-beyond-simply-accuracy\" data-toc-modified-id=\"Metrics-beyond-simply-accuracy-12.3\"><span class=\"toc-item-num\">12.3&nbsp;&nbsp;<\/span>Metrics beyond simply accuracy<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Precision-and-Recall\" data-toc-modified-id=\"Precision-and-Recall-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;<\/span>Precision and Recall<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Precision\" data-toc-modified-id=\"Precision-13.1\"><span class=\"toc-item-num\">13.1&nbsp;&nbsp;<\/span>Precision<\/a><\/span><\/li><li><span><a href=\"#Recall\" data-toc-modified-id=\"Recall-13.2\"><span class=\"toc-item-num\">13.2&nbsp;&nbsp;<\/span>Recall<\/a><\/span><\/li><li><span><a href=\"#Precision-and-recall-tradeoff\" data-toc-modified-id=\"Precision-and-recall-tradeoff-13.3\"><span class=\"toc-item-num\">13.3&nbsp;&nbsp;<\/span>Precision and recall tradeoff<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Making-predictions-on-the-test-set\" data-toc-modified-id=\"Making-predictions-on-the-test-set-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;<\/span>Making predictions on the test set<\/a><\/span><\/li><li><span><a href=\"#Assigning-a-lead-score-between-0-and-100-to-each-of-the-leads\" data-toc-modified-id=\"Assigning-a-lead-score-between-0-and-100-to-each-of-the-leads-15\"><span class=\"toc-item-num\">15&nbsp;&nbsp;<\/span>Assigning a lead score between 0 and 100 to each of the leads<\/a><\/span><\/li><\/ul><\/div>","3c8b609b":"## Assessing the model with StatsModels","a9aa9fbd":"**A free copy of Mastering The Interview**","d0e9b574":"Insights: p-values > 0.05: No more","3e220329":"There are a few variables with high VIF. It's best to drop these variables as they aren't helping much with prediction and unnecessarily making the model complex.","d0b5d866":"### Visualising Numeric Variables","e8609f6a":"The area below the ROC curve is 0.86, which is very good -> We have a good model.\nCheck the sensitivity and specificity to find the optimal cutoff point.","632a8d3b":"### Precision and recall tradeoff","a91d9d53":"## Feature Scaling","6b38c287":"## Finding the optimal cut off","8f9ab15a":"## Visualising the Data","405ce533":"Insights: p-values > 0.05:\n - Last Activity_View in browser link Clicked\n - What is your current occupation_Housewife","ee20a5ea":"# Lead Scoring","4a1054e2":"**Countplot for categorical variables**","67924848":"## Checking VIFs","96a8bb92":"### Converting some binary variables (Yes\/No) to 0\/1","7ffb55e9":"**Do not email & Do not call**","80444645":"Inspect the various aspects of the dataframe","d26a612d":"**Pie plot for categorical variables**","5a63367f":"## Reading and Understanding the Data","382b10e8":"From the curve above, 0.42 is the optimum point to take it as a cutoff probability.","ba8cca70":"Insights:\n- \"How did you hear about X Education\", \"Lead Profile\" have a lot of \"Select\" values -> Drop them\n- All rows have the same value for the \"Magazine\" => Not very useful, do not give any insights => Drop it\n- Similar to \"Magazine\", drop \"Search\", \"Newspaper Article\", \"X Education Forums\", \"Newspaper\", \"Digital Advertisement\", \"Through Recommendations\", \"Receive More Updates About Our Courses\", \"Update me on Supply Chain Content\", \"Get updates on DM Content\", \"I agree to pay the amount through cheque\", \"What matters most to you in choosing a course\"","c04d4eb2":"**Last activity & Last notable activity**"}}