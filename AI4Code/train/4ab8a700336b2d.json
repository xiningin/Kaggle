{"cell_type":{"147b4931":"code","8fada7fd":"code","23192c33":"code","143bf321":"code","bdfb94a5":"code","af2754b9":"code","ef1aeabd":"code","c1841bce":"code","8c5c1532":"code","a1685cb3":"code","471161ae":"code","20905ef0":"code","6635e35a":"code","e5bd2450":"code","328a917f":"code","e65a7eae":"code","e7a23d39":"code","f8a8dc7e":"code","6780035d":"code","866fb744":"code","ac0105b4":"code","4b3d9f7f":"code","5fc7d9fb":"code","e5777d2a":"code","810eae3f":"code","c104b4a8":"code","8eb93bdb":"code","aa78ce6e":"code","0c54b5f7":"code","7b681156":"code","464fd223":"code","f5362772":"markdown","1abb9431":"markdown","de2bd752":"markdown","b2bca80d":"markdown","7e636650":"markdown"},"source":{"147b4931":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8fada7fd":"train=pd.read_csv('..\/input\/airbnb-recruiting-new-user-bookings\/train_users_2.csv.zip')\ntest = pd.read_csv('..\/input\/airbnb-recruiting-new-user-bookings\/test_users.csv.zip')","23192c33":"submissionid=test.id","143bf321":"\n# For identification purposes\ntrain.loc[:,'Train'] = 1\ntest.loc[:,'Train'] = 0\n\ntest['country_destination'] = 0\n\ndf = pd.concat([train,test], ignore_index=True)","bdfb94a5":"train=df[df['Train']==1]","af2754b9":"test=df[df['Train']==0]","ef1aeabd":"train['age'].fillna(train['age'].mean(), inplace=True)","c1841bce":"test['age'].fillna(train['age'].mean(), inplace=True)","8c5c1532":"train.isnull().sum()","a1685cb3":"test.isnull().sum()","471161ae":"train['first_affiliate_tracked'] = train['first_affiliate_tracked'].fillna('Unknown')\ntest['first_affiliate_tracked'] = test['first_affiliate_tracked'].fillna('Unknown')","20905ef0":"train.drop(['date_account_created','timestamp_first_active','date_first_booking','Train'],axis=1,inplace=True)","6635e35a":"test.drop(['date_account_created','timestamp_first_active','date_first_booking','country_destination','Train'],axis=1,inplace=True)","e5bd2450":"from sklearn.preprocessing import LabelEncoder \n","328a917f":"le = LabelEncoder() \n  \ntrain['gender']= le.fit_transform(train['gender'])\ntrain['signup_method']= le.fit_transform(train['signup_method']) \ntrain['first_affiliate_tracked']= le.fit_transform(train['first_affiliate_tracked']) \ntrain['signup_method']= le.fit_transform(train['signup_method']) \ntrain['language']= le.fit_transform(train['language'])\ntrain['affiliate_channel']= le.fit_transform(train['affiliate_channel'])\ntrain['affiliate_provider']= le.fit_transform(train['affiliate_provider'])\ntrain['signup_app']= le.fit_transform(train['signup_app'])\ntrain['first_device_type']= le.fit_transform(train['first_device_type'])\ntrain['first_browser']= le.fit_transform(train['first_browser'])\n","e65a7eae":"le = LabelEncoder() \n  \ntest['gender']= le.fit_transform(test['gender'])\ntest['signup_method']= le.fit_transform(test['signup_method']) \ntest['first_affiliate_tracked']= le.fit_transform(test['first_affiliate_tracked']) \ntest['signup_method']= le.fit_transform(test['signup_method']) \ntest['language']= le.fit_transform(test['language'])\ntest['affiliate_channel']= le.fit_transform(test['affiliate_channel'])\ntest['affiliate_provider']= le.fit_transform(test['affiliate_provider'])\ntest['signup_app']= le.fit_transform(test['signup_app'])\ntest['first_device_type']= le.fit_transform(test['first_device_type'])\ntest['first_browser']= le.fit_transform(test['first_browser'])\n","e7a23d39":"train.country_destination.replace('NDF',0,inplace=True)\ntrain.country_destination.replace('US',1,inplace=True)\ntrain.country_destination.replace('other',2,inplace=True)\ntrain.country_destination.replace('FR',3,inplace=True)\ntrain.country_destination.replace('CA',4,inplace=True)\ntrain.country_destination.replace('GB',5,inplace=True)\ntrain.country_destination.replace('ES',6,inplace=True)\ntrain.country_destination.replace('IT',7,inplace=True)\ntrain.country_destination.replace('PT',8,inplace=True)\ntrain.country_destination.replace('NL',9,inplace=True)\ntrain.country_destination.replace('DE',10,inplace=True)\ntrain.country_destination.replace('AU',11,inplace=True)","f8a8dc7e":"test","6780035d":"from sklearn.model_selection import train_test_split\ny=train['country_destination']\nX=train.drop(['country_destination','id'],axis=1)\n# split the dataset into train and test sets\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1,shuffle=True,stratify=y )","866fb744":"pred_country={0:\"NDF\", 1:\"US\", 2:\"other\", 3:\"FR\", 4:\"CA\", 5:\"GB\", 6:\"ES\", 7:\"IT\", 8:\"PT\", 9:\"DE\", 10:\"NL\", 11:\"AU\"}","ac0105b4":"#predictionsrf=rf.predict(test.drop(['id'],axis=1))","4b3d9f7f":"#results=[]\n#for i in predictionsrf:\n#    results.append(pred_country[i])\n#print(results)","5fc7d9fb":"#my_submissionrf = pd.DataFrame({'id': test.id, 'country':results})\n#my_submissionrf.to_csv('submission.csv', index=False)","e5777d2a":"from sklearn.model_selection import GridSearchCV\nparameters = {'solver': ['lbfgs'], 'max_iter': [1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000 ], 'alpha': 10.0 ** -np.arange(1, 10), 'hidden_layer_sizes':np.arange(10, 15), 'random_state':[0,1,2,3,4,5,6,7,8,9]}\nmlpgridsearch = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1)\nmlpgridsearch.fit(X_train,y_train)\npredsgridmlp = mlpgridsearch.predict(X_test)\n\nprint(mlpgridsearch.score(X_train, y_train))\nprint(mlpgridsearch.best_params_)","810eae3f":"from sklearn.neural_network import MLPClassifier\n#Generate prediction using Neural Net\n\n#mlp = MLPClassifier()\n#mlp.fit(X_train,y_train)\n#predsmlp = mlp.predict(X_test)\n#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n# Model Accuracy, how often is the classifier correct?\nprint(classification_report(y_test, predsgridmlp, target_names=target_names))","c104b4a8":"predictionsmlp=mlpgridsearch.predict(test.drop(['id'],axis=1))","8eb93bdb":"results=[]\nfor i in predictionmlp:\n    results.append(pred_country[i])\nprint(results)","aa78ce6e":"my_submissionmlp = pd.DataFrame({'id': test.id, 'country':results})\nmy_submissionmlp.to_csv('submission.csv', index=False)","0c54b5f7":"#predictionsxgb=xgb.predict(test.drop(['id'],axis=1))","7b681156":"#results=[]\n#for i in predictionsxgb:\n#    results.append(pred_country[i])\n#print(results)","464fd223":"#my_submissionxgb = pd.DataFrame({'id': test.id, 'country':results})\n#my_submissionxgb.to_csv('submission.csv', index=False)","f5362772":"---> Test datam ve Train datam\u0131 birle\u015ftirdim. Burada Train datas\u0131na, Train datas\u0131n\u0131n ortamalas\u0131 vs ile yapaca\u011f\u0131m imputation'lar\u0131 da tek seferde ekleyebilmek istedi\u011fim bu ad\u0131m\u0131 ger\u00e7ekle\u015ftirdim.","1abb9431":"MLP classifiyer en iyi sonucu verdi \u015fimdiye kadar. Ama rf ve xgb scoru aras\u0131nda pek bir fark oldugu s\u00f6ylenemez. 0.68 0.69 alabildi\u011fim en y\u00fcksek score. Grid searchle modelimi geli\u015ftirecek en uygun parametreleri se\u00e7meyi deneyebilirim.","de2bd752":"Gridsearch yap\u0131p xgboost denenebilir veya bir \u00f6nceki drafta nn kullanarak yapt\u0131g\u0131n modele gridsearch denenebilir. Zaten hepsinden iyi \u00e7al\u0131\u015ft\u0131. ba\u015fka boosting y\u00f6ntemleri denenebilir. Yeni \u00f6zellik eklenmeye \u00e7al\u0131\u015f\u0131labilir. Seasonal bir etki var \u00e7\u00fcnk\u00fc.","b2bca80d":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\n\nfrom sklearn.metrics import classification_report\ntarget_names = ['NDF', 'US', 'other', 'FR', 'CA', 'GB', 'ES', 'IT', 'PT', 'NL','DE', 'AU']\n\nrf=RandomForestClassifier(n_estimators=10)\n\n#Train the model using the training sets y_pred=rf.predict(X_test)\nrf.fit(X_train,y_train)\n\n# prediction on test set\ny_predrf=rf.predict(X_test)\n\n#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n# Model Accuracy, how often is the classifier correct?\nprint(classification_report(y_test, y_predrf, target_names=target_names))","7e636650":"import xgboost\nfrom xgboost import XGBClassifier\nxgb = XGBClassifier(max_depth=6, learning_rate=0.3, n_estimators=25,\n                    objective='multi:softprob', subsample=0.5, colsample_bytree=0.5, seed=0)                  \nxgb.fit(X_train, y_train)\ny_pred = xgb.predict_proba(X_test)\nprint(classification_report(y_test, y_predrf, target_names=target_names))"}}