{"cell_type":{"b761ca8f":"code","85e708e6":"code","45e1d2d0":"code","980bd801":"code","55f444e9":"code","fb7ad0f7":"code","d465cd0a":"code","01cae2ed":"code","83ba7cfc":"code","c874841a":"code","15b223fa":"code","28e2aafc":"code","6dc201c1":"code","73c7169f":"code","f1cde728":"code","d9eb0542":"code","a246a3aa":"code","5f00457d":"code","79d10e76":"code","7d457a87":"code","f84dcf3c":"code","6a362cb1":"code","e836e1ec":"code","be7735a1":"code","e3b01cf4":"code","4b4bb393":"code","929ac55f":"code","0d16b796":"code","f761e56f":"code","2965138d":"code","6fda8213":"code","3341967a":"code","524e69c3":"code","c758e563":"markdown","f9bdaf2b":"markdown","57847b01":"markdown","40c37d46":"markdown","e64ffa89":"markdown","46762382":"markdown","8f89628a":"markdown","e507e7c3":"markdown","3b6df332":"markdown","8152356a":"markdown","6b24e329":"markdown","0543079c":"markdown","0fb18082":"markdown","840f639c":"markdown","dbc035d1":"markdown","6ecb21e6":"markdown","c46d1df5":"markdown","e16a6d3b":"markdown","d68742dd":"markdown","63c7fbf1":"markdown","c40fa569":"markdown","b53e647b":"markdown","87ebf648":"markdown","d53ac959":"markdown","ef1a8ee2":"markdown","fc9b3edb":"markdown","d7f20c14":"markdown","33cb7644":"markdown"},"source":{"b761ca8f":"# import python library for data analysis\nimport numpy as np\nimport pandas as pd\n\n# data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# display image\nfrom IPython.display import Image\n\n# stat on data\nfrom scipy import stats\nfrom scipy.stats import norm, skew \nimport statsmodels.api as sm\n\n# # import library for machine learning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import preprocessing, model_selection, metrics\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score, mean_squared_error\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV","85e708e6":"# load the data\ndf_Auser = pd.read_csv(r\"..\/input\/acea-water-prediction\/Aquifer_Auser.csv\")\n\n# set date as index\ndf_Auser['Date'] = pd.to_datetime(df_Auser['Date'],format='%d\/%m\/%Y', errors='ignore')\ndf_Auser = df_Auser.set_index('Date')\n\n# Show the first 2 rows\ndf_Auser.head(2)","45e1d2d0":"def get_percentage_nan_values(data, thresh=20, color='black', edgecolor='black', width=15, height=3):\n    \"\"\"\n    visualize the percentage of missing values in each columns\n    SOURCE: https:\/\/www.kaggle.com\/amiiiney\/price-prediction-regularization-stacking\n    \"\"\"\n    \n    plt.figure(figsize=(width,height))\n    percentage=(data.isnull().mean())*100\n    percentage.sort_values(ascending=False).plot.bar(color=color, edgecolor=edgecolor)\n    plt.axhline(y=thresh, color='r', linestyle='-')\n    plt.title('Missing values percentage per column', fontsize=20, weight='bold' )\n    plt.text(len(data.isnull().sum()\/len(data))\/1.7, thresh+12.5, f'Columns with more than {thresh}% missing values', fontsize=12, color='crimson',\n         ha='left' ,va='top')\n    plt.text(len(data.isnull().sum()\/len(data))\/1.7, thresh - 5, f'Columns with less than {thresh} missing values', fontsize=12, color='green',\n         ha='left' ,va='top')\n    plt.xlabel('Columns', size=15, weight='bold')\n    plt.ylabel('Missing values percentage')\n    plt.yticks(weight ='bold')\n    \n    return plt.show()\n\ndef show_distribution_nan_values(df):\n    f, ax = plt.subplots(nrows=1, ncols=1, figsize=(16,5))\n    sns.heatmap(df.T.isna(), cmap='Blues')\n    ax.set_title('Fields with Missing Values', fontsize=16)\n    #for tick in ax.xaxis.get_major_ticks():\n    #    tick.label.set_fontsize(14) \n    for tick in ax.yaxis.get_major_ticks():\n        tick.label.set_fontsize(14)\n    return plt.show()","980bd801":"# show percentage and distribution missing values per columns\nget_percentage_nan_values(df_Auser, 20, color=sns.color_palette('Reds',15))\nshow_distribution_nan_values(df_Auser)","55f444e9":"# select data after 2006-01-01\ndf_Auser = df_Auser[df_Auser.index >='2006-01-01']","fb7ad0f7":"# look at the percentage and distribution of the missing value\nget_percentage_nan_values(df_Auser, 20, color=sns.color_palette('Reds',15))\nshow_distribution_nan_values(df_Auser)","d465cd0a":"# get columns names\ndf_Auser.columns","01cae2ed":"# create lists with same type of variables\nAuser_rainfall=['Rainfall_Gallicano', 'Rainfall_Pontetetto', 'Rainfall_Monte_Serra','Rainfall_Orentano', 'Rainfall_Borgo_a_Mozzano', 'Rainfall_Piaggione',\n       'Rainfall_Calavorno', 'Rainfall_Croce_Arcana','Rainfall_Tereglio_Coreglia_Antelminelli','Rainfall_Fabbriche_di_Vallico']\nAuser_Groundwater=['Depth_to_Groundwater_LT2','Depth_to_Groundwater_SAL', 'Depth_to_Groundwater_PAG','Depth_to_Groundwater_CoS', 'Depth_to_Groundwater_DIEC']\nAuser_Temperature=['Temperature_Orentano', 'Temperature_Monte_Serra','Temperature_Ponte_a_Moriano', 'Temperature_Lucca_Orto_Botanico']\nAuser_Volume = ['Volume_POL', 'Volume_CC1', 'Volume_CC2', 'Volume_CSA', 'Volume_CSAL']\nAuser_hydrometry=['Hydrometry_Monte_S_Quirico', 'Hydrometry_Piaggione']\n\n####  Here, I added these lines after plotting 'Auser_Volume'.              ###   \n####  We need to change the scale to logarithmic For data visualisation     ###\n# change the scale to logarithmic\ndf_Auser['Volume_POL_log10'] = -np.log10(abs(df_Auser['Volume_POL']))\ndf_Auser['Volume_CC1_log10'] = -np.log10(abs(df_Auser['Volume_CC1']))\ndf_Auser['Volume_CC2_log10'] = -np.log10(abs(df_Auser['Volume_CC2']))\ndf_Auser['Volume_CSA_log10'] = -np.log10(abs(df_Auser['Volume_CSA']))\ndf_Auser['Volume_CSAL_log10'] = -np.log10(abs(df_Auser['Volume_CSAL']))\n\n# create new list with columns names\nAuser_Volume_log = ['Volume_POL_log10', 'Volume_CC1_log10', 'Volume_CC2_log10', 'Volume_CSA_log10', 'Volume_CSAL_log10']\n\n# changing the scale may create infinite value so we replace 'inf' value by 'nan' values\ndf_Auser[Auser_Volume_log] = df_Auser[Auser_Volume_log].replace([np.inf, -np.inf], np.nan).fillna(0)\n","83ba7cfc":"# create function to plot the data per type of variables\ndef plot_data():\n    # Separate columns into smaller dataframes to perform visualisations\n    df_Auser_rainfall = df_Auser[Auser_rainfall]\n    df_Auser_Groundwater = df_Auser[Auser_Groundwater]\n    df_Auser_Temperature = df_Auser[Auser_Temperature]\n    df_Auser_Volume_log = df_Auser[Auser_Volume_log]\n    df_Auser_Volume = df_Auser[Auser_Volume]\n    df_Auser_hydrometry = df_Auser[Auser_hydrometry]\n\n    # plot data\n    ax = df_Auser_rainfall.plot(figsize=(12, 4), fontsize=12,linewidth=2)\n    ax.set_xlabel('Date', fontsize=16)\n    ax.set_ylabel('mm', fontsize=16)\n    ax.set_title('Auser Aquifer: Rainfall data', fontsize=16)\n    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n\n    ax1 = df_Auser_Groundwater.plot(figsize=(12, 4), fontsize=12,linewidth=2)\n    ax1.set_xlabel('Date', fontsize=16)\n    ax1.set_ylabel('m', fontsize=16)\n    ax1.set_title('Auser Aquifer: Groundwater Level data', fontsize=16)\n    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n\n    ax2 = df_Auser_Temperature.plot(figsize=(12, 4), fontsize=12,linewidth=2)\n    ax2.set_xlabel('Date', fontsize=16)\n    ax2.set_ylabel('C', fontsize=16)\n    ax2.set_title('Auser Aquifer: Temperature data', fontsize=16)\n    ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n\n    ax3 = df_Auser_Volume_log.plot(figsize=(12, 4), fontsize=12,linewidth=2,marker='o')\n    ax3.set_xlabel('Date', fontsize=16)\n    ax3.set_ylabel('m3', fontsize=16)\n    ax3.set_title('Auser Aquifer: Volume data', fontsize=16)\n    ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n\n    ax4 = df_Auser_hydrometry.plot(figsize=(12, 4), fontsize=12,linewidth=2)\n    ax4.set_xlabel('Date', fontsize=16)\n    ax4.set_ylabel('', fontsize=16)\n    ax4.set_title('Auser Aquifer: Monthly hydrometry', fontsize=16)\n    ax4.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n\n    plt.show()","c874841a":"plot_data()","15b223fa":"# here we just make sure the suspicious values observed in the plot are really equal to zero.\nprint(df_Auser['Depth_to_Groundwater_LT2'].sort_values(ascending=False).head(5))\nprint(df_Auser['Depth_to_Groundwater_CoS'].sort_values(ascending=False).head(5))\nprint(df_Auser['Depth_to_Groundwater_SAL'].sort_values(ascending=False).head(6))","28e2aafc":"# REPLACE missing value noted with '0' by the previous data\ndf_Auser['Depth_to_Groundwater_LT2'] = df_Auser['Depth_to_Groundwater_LT2'].replace(to_replace=0, method='ffill')\ndf_Auser['Depth_to_Groundwater_CoS'] = df_Auser['Depth_to_Groundwater_CoS'].replace(to_replace=0.00, method='ffill')\ndf_Auser['Depth_to_Groundwater_SAL'] = df_Auser['Depth_to_Groundwater_SAL'].replace(to_replace=0, method='ffill')\ndf_Auser['Depth_to_Groundwater_DIEC'] = df_Auser['Depth_to_Groundwater_DIEC'].replace(to_replace=0, method='ffill')","6dc201c1":"# create two column with the month and the year\ndf_Auser['Month'] = pd.DatetimeIndex(df_Auser.index).month\ndf_Auser['Year'] = pd.DatetimeIndex(df_Auser.index).year\n\n# replace nan value by the mean of the month of the year\ndf_Auser.fillna(df_Auser.groupby(['Month','Year']).transform('mean'), inplace=True)\n\n# Then if missing value  still present:\n# replace nan value by the mean of the month calculated over the entire dataframe\ndf_Auser.fillna(df_Auser.groupby(['Month']).transform('mean'), inplace=True)","73c7169f":"\ndf_csal = df_Auser.loc[df_Auser['Volume_CSAL_log10']!=0]\nvalue_to_remove = df_csal['Volume_CSAL_log10'].max()\ndf_Auser['Volume_CSAL_log10'] = df_Auser['Volume_CSAL_log10'].replace(to_replace=value_to_remove, method='ffill')\n\n# Remove second suspicious point\ndf_csal = df_Auser.loc[df_Auser['Volume_CSAL_log10']!=0]\nvalue_to_remove = df_csal['Volume_CSAL_log10'].max()\ndf_Auser['Volume_CSAL_log10'] = df_Auser['Volume_CSAL_log10'].replace(to_replace=value_to_remove, method='ffill')","f1cde728":"# select the last 14 years only\ndf_Auser = df_Auser[df_Auser.index <='2020-01-01']","d9eb0542":"# resample for monthly value\ndf_Auser = df_Auser.resample('M').mean()\n\n# see results\nplot_data()","a246a3aa":"# calculate monthly mean temperature and mean rainfall\ndf_Auser['mean_temperature'] = df_Auser[['Temperature_Orentano', 'Temperature_Monte_Serra', 'Temperature_Lucca_Orto_Botanico']].mean(axis=1)\ndf_Auser['mean_rainfall']  = df_Auser[Auser_rainfall].mean(axis=1)\n\n# calculate monthly total volume of pumping water\ndf_Auser['sum_volume_log']  = df_Auser[Auser_Volume_log].mean(axis=1)","5f00457d":"# plot mean temperature,mean rainfall, and water level\n# define figure size and space between subplots\nfig = plt.figure(figsize=(18,10))\nfig.subplots_adjust(hspace=0.4,wspace=0.3)\n\n# plot evolution of the average monthly temperature\nax1 = fig.add_subplot(3,1,1)\nax1 = sns.lineplot(x=df_Auser.index,y='mean_temperature',data=df_Auser,color='red')\nax1.set_title('Evolution of the average monthly temperature',size=14)\n\n# plot evolution of the average monthly rainfall\nax2 = fig.add_subplot(3,1,2)\nax2 = sns.lineplot(x=df_Auser.index,y='mean_rainfall',data=df_Auser,color='blue')\nax2.set_title('Evolution of the average monthly rainfall',size=14)\n\n\nplt.show()","79d10e76":"# calculate the percentage of evapotranspiration (range from 0 and 100%)\ndf_Auser.loc[:,'perct_evapo1'] = (df_Auser['mean_temperature']*100) \/ (df_Auser['mean_temperature'].max()\n                                                                       -df_Auser['mean_temperature'].min())\ndf_Auser.loc[:,'perct_evapo']= df_Auser['perct_evapo1'] - df_Auser['perct_evapo1'].min()\ndf_Auser = df_Auser.drop(columns=['perct_evapo1'])\n\n# calculate effective rainfall: rainfall minus evp\ndf_Auser.loc[:,'effective_rainfall'] = df_Auser['mean_rainfall'] -  \\\n                                       df_Auser['mean_rainfall']*df_Auser['perct_evapo']\/100","7d457a87":"# Set figure size and space between subplt\nfig = plt.figure(figsize=(18,10))\nfig.subplots_adjust(hspace=0.4,wspace=0.3)\n\n# Plot evolution of the 'mean_rainfall' and 'effective rainfall'\nax1 = fig.add_subplot(3,1,1)\nax1 = sns.lineplot(x=df_Auser.index,y='mean_rainfall',data=df_Auser,color='purple',label = 'mean_rainfall')\nax1 = sns.lineplot(x=df_Auser.index,y='effective_rainfall',data=df_Auser,color='green',label = 'effective_rainfall')\nax1.legend(fontsize=12)\n\nax2 = fig.add_subplot(3,1,2)\nax2 = sns.lineplot(x=df_Auser.index,y='Depth_to_Groundwater_PAG',data=df_Auser,linewidth=2.0,color='red')\nax3 = ax2.twinx()  # instantiate a second axes that shares the same x-axis\nax3 = sns.lineplot(x=df_Auser.index,y='effective_rainfall',data=df_Auser,color='green')\nax3.set_ylabel('effective_rainfall', color='green')\n\n# ax4 = fig.add_subplot(3,1,3)\n# ax4 = sns.lineplot(x=df_Auser.index,y='effective_rainfall_diff_s1',data=df_Auser,linewidth=2.0,color='red')\n# ax4 = sns.lineplot(x=df_Auser.index,y='effective_rainfall_diff_s2',data=df_Auser,linewidth=2.0,color='blue')\n# ax4 = sns.lineplot(x=df_Auser.index,y='effective_rainfall_diff_s3',data=df_Auser,linewidth=2.0,color='purple')\n# ax5 = ax4.twinx()  # instantiate a second axes that shares the same x-axis\n# ax5 = sns.lineplot(x=df_Auser.index,y='Depth_to_Groundwater_LT2',data=df_Auser,color='green')\n# ax5.set_ylabel('effective_rainfall', color='green')\n\nplt.show()","f84dcf3c":"df_Auser.loc[:,'Hydrometry_Monte_S_Quirico_s1'] = df_Auser['Hydrometry_Monte_S_Quirico'].shift(1)\ndf_Auser.loc[:,'Hydrometry_Piaggione_s1'] = df_Auser['Hydrometry_Piaggione'].shift(1)\n\ndf_Auser.loc[:,'Depth_to_Groundwater_PAG_s1'] = df_Auser['Depth_to_Groundwater_PAG'].shift(1)\ndf_Auser.loc[:,'Depth_to_Groundwater_DIEC_s1'] = df_Auser['Depth_to_Groundwater_DIEC'].shift(1)\n\n# lag versions of the effective_rainfall\ndf_Auser.loc[:,'effective_rainfall_s1'] = df_Auser['effective_rainfall'].shift(1)\ndf_Auser.loc[:,'effective_rainfall_s2'] = df_Auser['effective_rainfall'].shift(2)\ndf_Auser.loc[:,'effective_rainfall_s3'] = df_Auser['effective_rainfall'].shift(3)\ndf_Auser.loc[:,'effective_rainfall_s4'] = df_Auser['effective_rainfall'].shift(4)\n","6a362cb1":"df_Auser.loc[:,'Hydrometry_Monte_S_Quirico_s1'] = df_Auser['Hydrometry_Monte_S_Quirico'].shift(1)\ndf_Auser.loc[:,'Hydrometry_Piaggione_s1'] = df_Auser['Hydrometry_Piaggione'].shift(1)\n\ndf_Auser.loc[:,'Depth_to_Groundwater_PAG_s1'] = df_Auser['Depth_to_Groundwater_PAG'].shift(1)\ndf_Auser.loc[:,'Depth_to_Groundwater_DIEC_s1'] = df_Auser['Depth_to_Groundwater_DIEC'].shift(1)\n\ndf_Auser = df_Auser.dropna()","e836e1ec":"# # drop columns not needed anymore\ndf_Auser = df_Auser.drop(Auser_rainfall, axis=1)\ndf_Auser = df_Auser.drop(Auser_Temperature, axis=1)\ndf_Auser = df_Auser.drop(Auser_Volume, axis=1)\ndf_Auser = df_Auser.drop(Auser_hydrometry, axis=1)\ndf_Auser = df_Auser.drop(columns=['perct_evapo','mean_rainfall','mean_temperature','Month','Year',\n                                  'Depth_to_Groundwater_PAG','Depth_to_Groundwater_DIEC'])\ndf_Auser.shape","be7735a1":"corr = df_Auser.corr(method='pearson')\n\nfig, ax = plt.subplots(figsize=(17,17)) \n\nax = sns.heatmap(corr,annot=True,linewidths=.5, annot_kws={\"size\": 11},vmin=-1.0, vmax=1.0,square=True,cbar=True)\nax.set_title('Auser aquifer: correlation coefficients between variables',size=18,y=1.05)\nax.set_yticklabels(ax.get_yticklabels(), rotation=0,size=12) \nax.set_xticklabels(ax.get_xticklabels(), rotation=90,size=12)\nplt.show()","e3b01cf4":"# split the dataframe into a training and testing dataset\ndf_Auser_train = df_Auser[(df_Auser.index >='2005-01-01')&(df_Auser.index <'2017-01-01')]\ndf_Auser_test  = df_Auser[(df_Auser.index >='2017-01-01')]\n#     df = df[df.index >='2003-01-01']\nprint(\"the shape of the dataframe for training is {} :\".format(df_Auser_train.shape))\nprint(\"the shape of the dataframe for testing is {} :\".format(df_Auser_test.shape))\nprint(\"the train dataframe contain {}% of the data :\".format((df_Auser_train.shape[0]*100)\/df_Auser.shape[0]))","4b4bb393":"X_train_Auser = df_Auser_train.drop(columns=['Depth_to_Groundwater_SAL', 'Depth_to_Groundwater_CoS',\n                                            'Depth_to_Groundwater_LT2'],axis=1)\ny_train_sal = df_Auser_train['Depth_to_Groundwater_SAL'].values\ny_train_cos = df_Auser_train['Depth_to_Groundwater_CoS'].values\ny_train_lt2 = df_Auser_train['Depth_to_Groundwater_LT2'].values\n\nX_test_Auser = df_Auser_test.drop(columns=['Depth_to_Groundwater_SAL', 'Depth_to_Groundwater_CoS',\n                                            'Depth_to_Groundwater_LT2'],axis=1)\ny_test_sal = df_Auser_test['Depth_to_Groundwater_SAL'].values\ny_test_cos = df_Auser_test['Depth_to_Groundwater_CoS'].values\ny_test_lt2 = df_Auser_test['Depth_to_Groundwater_LT2'].values\n","929ac55f":"# from sklearn.preprocessing import StandardScaler\nscaler= StandardScaler()\n# transform \"x_train\"\nX_train = scaler.fit_transform(X_train_Auser)\n# transform \"x_test\"\nX_test = scaler.transform(X_test_Auser)","0d16b796":"import math\ndef score(y_pred,y_test):\n    return str(math.sqrt(mean_squared_error(y_test)))\n\ndef get_best_score(grid):\n    \n    best_score = np.sqrt(-grid.best_score_)\n    print(best_score)    \n    print(grid.best_params_)\n    print(grid.best_estimator_)\n    \n    return best_score\n\nfrom statsmodels.graphics.api import abline_plot\ndef model_evaluation(prediction,y_test):\n    r2 = round(metrics.r2_score(y_test, prediction), 2)\n    abs_perc_error = np.mean(np.abs((y_test-prediction)\/prediction))\n    mean_abs_err = metrics.mean_absolute_error(y_test, prediction)\n    rmse = np.sqrt(metrics.mean_squared_error(y_test, prediction))\n    print(\"R2 (explained variance):\",r2 )\n    print(\"Mean Absolute Perc Error (\u03a3(|y-pred|\/y)\/n):\", abs_perc_error)\n    print(\"Mean Absolute Error (\u03a3|y-pred|\/n):\", \"{:,f}\".format(mean_abs_err))\n    print(\"Root Mean Squared Error (sqrt(\u03a3(y-pred)^2\/n)):\", \"{:,f}\".format(rmse))\n    ## residuals\n#     prediction = prediction.reshape(len(prediction),1)\n    residuals = y_test - prediction\n    if abs(max(residuals)) > abs(min(residuals)):\n        max_error = max(residuals)  \n    else:\n        max_error = min(residuals) \n    max_idx = list(residuals).index(max(residuals)) if abs(max(residuals)) > abs(min(residuals)) else list(residuals).index(min(residuals))\n    # max_true = y_test[max_idx]\n    max_pred = prediction[max_idx]\n    print(\"Max Error:\", \"{}\".format(max_error))\n    \n    ## Plot predicted vs true\n    fig, ax = plt.subplots(nrows=1, ncols=2,figsize=(10,5))\n    ax[0].scatter(prediction, y_test, color=\"black\")\n    abline_plot(intercept=0, slope=1, color=\"red\", ax=ax[0])\n    # ax[0].vlines(x=max_pred, ymin=max_true, ymax=max_true-max_error, color='red', linestyle='--', alpha=0.7, label=\"max error\")\n    ax[0].grid(True)\n    ax[0].set(xlabel=\"Predicted\", ylabel=\"True\", title=\"Predicted vs True\")\n    ax[0].legend()\n\n    ## Plot predicted vs residuals\n    ax[1].scatter(prediction, residuals, color=\"red\")\n    ax[1].vlines(x=max_pred, ymin=0, ymax=max_error, color='black', linestyle='--', alpha=0.7, label=\"max error\")\n    ax[1].grid(True)\n    ax[1].set(xlabel=\"Predicted\", ylabel=\"Residuals\", title=\"Predicted vs Residuals\")\n    ax[1].hlines(y=0, xmin=np.min(prediction), xmax=np.max(prediction))\n    ax[1].legend()\n    plt.show()\n    \n    print('The model explains {}% of the variance of the target variable.'.format(r2*100))\n    print('On average, predictions have an error of {:,.2f}, or they\u2019re wrong by {:,.2f}%.'.format(mean_abs_err,(abs_perc_error)*100)) \n    print('The biggest error on the test set was over {:,.2f}.'.format(rmse))\n","f761e56f":"X_train2 = pd.DataFrame(X_train)\nX_train2.columns =[X_train_Auser.columns]\n\n#Backward Elimination\ncols = ['Volume_POL_log10', 'Volume_CC1_log10', 'Volume_CC2_log10',\n       'Volume_CSA_log10', 'Volume_CSAL_log10', 'sum_volume_log',\n       'effective_rainfall', 'effective_rainfall_s1', 'effective_rainfall_s2',\n       'effective_rainfall_s3', 'effective_rainfall_s4',\n       'Hydrometry_Monte_S_Quirico_s1', 'Hydrometry_Piaggione_s1',\n       'Depth_to_Groundwater_PAG_s1', 'Depth_to_Groundwater_DIEC_s1']\npmax = 1\nwhile (len(cols)>0):\n    p= []\n    X_1 = X_train2[cols]\n    X_1 = sm.add_constant(X_1)\n    model = sm.OLS(y_train_sal,X_1).fit()\n    p = pd.Series(model.pvalues.values[1:],index = cols)      \n    pmax = max(p)\n    feature_with_p_max = p.idxmax()\n    if(pmax>0.05):\n        cols.remove(feature_with_p_max)\n    else:\n        break\nselected_features_BE = cols\nprint(selected_features_BE)\n","2965138d":"X_train_sal_lr = X_train_Auser[selected_features_BE]\nX_test_sal_lr = X_test_Auser[selected_features_BE]\nlinreg = LinearRegression()\nparameters = {'fit_intercept':[True,False], 'normalize':[True,False], 'copy_X':[True, False]}\ngrid_linear = GridSearchCV(linreg, parameters, cv=12, verbose=1 , scoring = 'neg_mean_squared_error')\ngrid_linear.fit(X_train_sal_lr, y_train_sal)\n\nsc_linear = get_best_score(grid_linear)","6fda8213":"## call model 1 with all the variables\nmodel_LinReg = linear_model.LinearRegression(copy_X= True, fit_intercept= False, normalize= True)\nmodel_LinReg.fit(X_train_sal_lr, y_train_sal)\nprediction = model_LinReg.predict(X_test_sal_lr)\nmodel_evaluation(prediction,y_test_sal)","3341967a":"## Importing Ridge. \nfrom sklearn.linear_model import Ridge\nridge = Ridge()\nparameters = {'alpha':[1e-9,1e-8,1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,0.1,0.5,0.7,1], \n              'tol':[1e-9,1e-8,1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,1e-1]}\ngrid_ridge = GridSearchCV(ridge, parameters, cv=12, verbose=1, scoring = 'neg_mean_squared_error')\ngrid_ridge.fit(X_train, y_train_cos)\n\nsc_ridge = get_best_score(grid_ridge)","524e69c3":"## best fit: \nridge_bf = Ridge(alpha= 1, normalize=False,tol = 1e-9)\n## fit the model. \nridge_bf.fit(X_train, y_train_cos)\n## Predicting the target value based on \"Test_x\"\ny_pred = ridge_bf.predict(X_test)\n\nmodel_evaluation(y_pred,y_test_cos)","c758e563":"It appears to have a lot of missing values, so lets have a look at them.","f9bdaf2b":"### 1.1.4: remove missing data noted with 'zero' \nWaterlevel close to zero is highly suspicious. Here, we replace these value by the previous value.","57847b01":"Some columns contains a lot of missing data (between ~30 and ~60%), but fortunately these missing values seem to be located before 2006. So, I will select and work with the data obteined after 2006. ","40c37d46":"The result looks quite good!","e64ffa89":"#### calcule effective rainfall:\nWe know that a part of the rainfall is used by the vegetation, it is what is called the evapotranspiration (=EVP). So toconsider EVP, we made the following assumptiion. When the temperature is high all the rainfall is used by the vegetation\n(EVP = 100%). Inversely, when the temperature is low, EVP is low (EVP = 0 %) and all the rainfall infiltrate into the \nground","46762382":"### 1.3.4: evaluated the model","8f89628a":"#### using futur monitoring data of the water level to predict the waterlevel???\nIt seems not correct to use the monitoring data of the groundwater level in one well to predict the groundaterwater level in another well for the same period. Just do the measure directly! On the otherhand, we can use the groundaterwater level monitored the month before. \nFor these reasons we have created a lag version of 'Depth_to_Groundwater_PAG', 'Depth_to_Groundwater_DIEC, 'Hydrometry_Monte_S_Quirico' and 'Hydrometry_Piaggione'. \n","e507e7c3":"### 1.1.7: remove suspicious data observed in 2020","3b6df332":"### 1.1.2: Select an appropriate period to minimize the NAN values:","8152356a":"### 1.3.2 slipt into a training and testing data set","6b24e329":"## 1.2: feature engineering","0543079c":"This is much better. Almost all the columns have less than 20% of missing values. \nNow, lets have a look at these data to better understand how we can deal with the nan values. ","0fb18082":"We can compare the evolution of the monthly average rainfall with the monthly effective rainfall and with the evolution of the water table monitored in well SAL.","840f639c":"### 1.1.6: remove suspicious data observed at the end 2019 on Volume_CSAL_LOG10","dbc035d1":"### 1.3.5: Predict 'Depth_to_Groundwater_SAL'\n### 1.5.5.1: Linear regression\n#### Feature selection\n\n","6ecb21e6":"## 1.3: Machine learning\n### 1.3.1: test for multicolinearity","c46d1df5":"### 1.3.3: Scale the data\nWe use SdandartScaler to scale the data.","e16a6d3b":"<a id=\"top\"><\/a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:#7ca4cd; border:0' role=\"tab\" aria-controls=\"home\"><center> AUSER AQUIFER<\/center><\/h3>","d68742dd":"#### Best fit","63c7fbf1":"### 1.1.8: resample dataframe to work with monthly value","c40fa569":"#### lag time due to infiltration:\nBecause infiltration can occurs very suddently along cracks and fractures on the ground and\/on very slowly along micro-pores, we consider a period of four months during which the 'effective rainfall' may reached the aquifer.","b53e647b":"We can observe:\n    - the rainfall data seems to be OK,\n    - the goundwater level data have numerous missing data, and in 2020 several values are equal to zero. It is highly suspicious and these zero values may be considered as missing data.\n    - the temperature data seems to be OK, expected the temperature monitored at 'Ponte a Moriano'. This one can be drop.\n    - the volume data seems to be OK, expected in 2020. We won't use these data in the analyse.","87ebf648":"### 1.3.6: Predict 'Depth_to_Groundwater_CoS'","d53ac959":"Here, we load the data for the Auser aquifer, set the date as index and have a look at the dataframe.","ef1a8ee2":"## 1.1.3: How to process with the missing data\nNow, we can plot the data to give us a better idea on the way to clean the data.","fc9b3edb":"We can see the correlations between effective rainfall and groundwater levels are slihtly better than the correlation coefficients between mean rainfall and groundwater levels. ","d7f20c14":"### 1.1.5: remove missing data noted with 'Nan' \nHere, a missing value is replaced by the mean of the month of the year. In the case where no data are available for a month during a year, then the missing value is replaced by the mean of the month calculated from 2006 to 2020.","33cb7644":"> ## 1.1: Missing values\n### 1.1.1: Verify the NAN values percentage and distribution:"}}