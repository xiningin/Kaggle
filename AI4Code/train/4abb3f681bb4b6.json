{"cell_type":{"65284f67":"code","f49d1676":"code","a639a2ef":"code","af46700a":"code","07eb43c3":"code","c17361f9":"code","46f40c4f":"code","ef1e62da":"code","e02854f7":"code","5d947575":"code","2fd1bec9":"code","189e0719":"code","575d6803":"code","54c63524":"code","39469a22":"code","e22936c0":"code","4c50869e":"code","58536a08":"code","d2f24e1d":"code","b18f7507":"code","53cdb1ba":"code","c9c2602b":"code","4dafb21b":"code","e02eac68":"code","83a77e5b":"markdown","bfcc00ee":"markdown","d6894951":"markdown","77a1c7f1":"markdown","6e983eee":"markdown","2805f768":"markdown","8d22be17":"markdown","865550f0":"markdown","351f60d7":"markdown","5780eb20":"markdown","a17a0f84":"markdown","ffc07550":"markdown","8a79a2c1":"markdown","220a8a9c":"markdown","c129709a":"markdown","35f5e124":"markdown","5a3100bc":"markdown","64e67a7f":"markdown","28cb03cc":"markdown","0460074a":"markdown"},"source":{"65284f67":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical, normalize\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix","f49d1676":"df = pd.read_csv('..\/input\/weatherAUS.csv')\ndf.head()","a639a2ef":"df.count().sort_values()","af46700a":"df.drop(columns=['Sunshine','Evaporation','Cloud3pm','Cloud9am', 'RISK_MM'], axis=1, inplace=True)","07eb43c3":"df.dropna(inplace=True)\ndf.head()","c17361f9":"df['Date'] = pd.to_datetime(df['Date'])\ndf.set_index('Date', inplace=True)\ndf.sort_index(inplace=True)\ndf.head()","46f40c4f":"df['MaxTemp'].rolling(365).mean().plot()","ef1e62da":"df['Location'].unique()","e02854f7":"df['Location'] = df['Location'].astype('category').cat.codes\ndf['WindGustDir'] = df['WindGustDir'].astype('category').cat.codes\ndf['WindDir9am'] = df['WindDir9am'].astype('category').cat.codes\ndf['WindDir3pm'] = df['WindDir3pm'].astype('category').cat.codes\ndf['RainToday'] = df['RainToday'].astype('category').cat.codes\ndf['RainTomorrow'] = df['RainTomorrow'].astype('category').cat.codes","5d947575":"df.head()","2fd1bec9":"df.reset_index(drop=True, inplace=True)\ndf.head()","189e0719":"df = shuffle(df)\ndf.head()","575d6803":"X = df.drop('RainTomorrow', axis=1)\ny = df['RainTomorrow']","54c63524":"X.describe()","39469a22":"X = X.values\nX = normalize(X)","e22936c0":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2)\nX_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size = 0.5)","4c50869e":"X_train.shape","58536a08":"model = tf.keras.models.Sequential([\n       \n    tf.keras.layers.Dense(128, input_shape=(17,), activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.5),\n    \n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.5),\n    \n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.5),\n\n            \n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=Adam(0.00001),\n              metrics=['acc'])","d2f24e1d":"model.summary()","b18f7507":"history = model.fit(X_train, y_train,\n                    epochs=10,\n                    validation_data=(X_val, y_val),\n                    verbose=1,\n                   )","53cdb1ba":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","c9c2602b":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","4dafb21b":"loss, accuracy = model.evaluate(X_test, y_test)","e02eac68":"acc = accuracy * 100\nplt.bar(1, acc)\nplt.text(0.92,45,f'{acc:.2f}%', fontsize=20)\nplt.title('Accuracy')\nplt.xticks([])\nplt.ylabel('Percent')\nplt.show()","83a77e5b":"Back to machine learning.\n\nWe have a lot of \"strings\".\n\nConvert them to numbers.","bfcc00ee":"## Exploring data\nLoad the data and explore it.","d6894951":"## Training\nFinally, train the model.","77a1c7f1":"We definitely need to normalize the data.\n\nConvert it to np array and use normalize utils from keras.","6e983eee":"Explore the model.","2805f768":"## Evaluate the model\nPlot our accuracy and loss for understanding problems: \"high bias\" and \"high variance\".","8d22be17":"First 4 columns have a lot of nans, let's drop them and drop RISK_MM","865550f0":"Explore data","351f60d7":"And finally drop NaNs","5780eb20":"Split the dataset into three sets.\n\n\ntrain - 80% valid - 10% test - 10%","a17a0f84":"Looks like we have \"NaN\"s.\nLet's find out how many nans df have.","ffc07550":"Create train data and labels.","8a79a2c1":"<center>Thanks for reading.<\/center>\n\n<center>Vote if you like it.<\/center>","220a8a9c":"Much cleaner.\n\nConvert date column in DateTime format, set date as index and sort in.\n\nFor machine learning it's not necessary, it's just fun.","c129709a":"Drop the Date columm. We don't need it any more .","35f5e124":"Let's plot MaxTemp.","5a3100bc":"After finishing playing with model and we are happy with achieved accuracy, evaluate your model on the test set.","64e67a7f":"## Create the model.\nOur playground. Feel free to try a different variation","28cb03cc":"## Initial step\nImport required libraries","0460074a":"Since we sort the data we need to shuffle it.\n\nAnyway shuffling data it's always good practice. "}}