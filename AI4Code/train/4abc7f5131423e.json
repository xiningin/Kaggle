{"cell_type":{"f6a1eef6":"code","3c429945":"code","dfa912b4":"code","cd789e30":"code","ebbf72e3":"code","9db09c0a":"code","8c31fdb2":"code","31a5e782":"code","6bb4040f":"code","19de6500":"code","de85fc61":"code","2bbbd9a3":"code","26b02f7d":"code","a7571bd0":"code","ac1cfd2a":"code","f0172c65":"code","b6f280b6":"code","6b87a126":"code","64af61c0":"code","164d1f78":"code","0d33f48b":"code","92510501":"code","9efaf94d":"code","b167cd6d":"code","83410adf":"code","5040f722":"code","c2915271":"code","f313f16b":"code","cbf70667":"code","0d485f2e":"code","32aee32e":"code","79919850":"code","29634c4a":"code","e841d2e6":"markdown","efc77d8d":"markdown","f75b8304":"markdown","1fe82bb1":"markdown","bf46a53f":"markdown","2772fde2":"markdown","a959e417":"markdown","c215857a":"markdown","e4c06154":"markdown","274124d6":"markdown","6e846510":"markdown","3c7da3d0":"markdown","8da902c0":"markdown","516008f7":"markdown","6d106b9d":"markdown","04bae96e":"markdown","a0bc198a":"markdown","133e8e3b":"markdown"},"source":{"f6a1eef6":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nfrom xgboost import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score","3c429945":"train = pd.read_csv(\"..\/input\/loan-prediction-problem-dataset\/train_u6lujuX_CVtuZ9i.csv\")","dfa912b4":"train.head()","cd789e30":"train.describe()","ebbf72e3":"train.drop(\"Loan_ID\", axis = 1, inplace = True) #drop Loan_ID","9db09c0a":"train[\"Gender\"].unique()","8c31fdb2":"train.fillna(0, inplace = True)","31a5e782":"train.describe()","6bb4040f":"train.dtypes","19de6500":"train_encoded = pd.get_dummies(train, columns = [\"Dependents\", \"Property_Area\", \"Gender\", \"Married\", \"Education\", \"Self_Employed\"])","de85fc61":"train_encoded.head()","2bbbd9a3":"train_encoded.columns #to see list of column names","26b02f7d":"train_encoded.columns = train_encoded.columns.str.replace(\" \", \"_\")\ntrain_encoded.columns","a7571bd0":"train_encoded.columns.values[6] = \"Dependents_00\"\ntrain_encoded.columns","ac1cfd2a":"#from sklearn.feature_selection import SelectKBest, chi2, f_classif\n#features = pd.DataFrame(SelectKBest(f_classif, k=15).fit_transform(train_encoded.drop(\"Loan_Status\", axis = 1), train_encoded[\"Loan_Status\"]))","f0172c65":"features = train_encoded.drop(\"Loan_Status\", axis = 1)\nlabels = train_encoded[\"Loan_Status\"]","b6f280b6":"features.head()","6b87a126":"labels.head()","64af61c0":"labels.replace(\"N\", \"0\", inplace = True)\nlabels.replace(\"Y\", \"1\", inplace = True)\nlabels = labels.astype(int)","164d1f78":"X_train, X_test, y_train, y_test = train_test_split(features, labels, stratify = labels)","0d33f48b":"model = XGBClassifier(objective = \"binary:logistic\", missing = None)","92510501":"model.fit(X_train, y_train, verbose = True,\n         early_stopping_rounds = 10,\n         eval_metric = \"aucpr\",\n         eval_set = [(X_test, y_test)])","9efaf94d":"predictions = model.predict(X_test)\naccuracy_score(predictions, y_test) #on the train dataset","b167cd6d":"model2 = DecisionTreeClassifier() # testing for DecisionTreeClassifier\nmodel2.fit(X_train, y_train)\npredictions2 = model2.predict(X_test)\naccuracy_score(predictions2, y_test)","83410adf":"model3 = RandomForestClassifier() # testing for RandomForestClassifier\nmodel3.fit(X_train, y_train)\npredictions3 = model3.predict(X_test)\naccuracy_score(predictions3, y_test)","5040f722":"model4 = LogisticRegression() # tesing for LogisticRegression\nmodel4.fit(X_train, y_train)\npredictions4 = model4.predict(X_test)\naccuracy_score(predictions4, y_test)","c2915271":"model5 = KNeighborsClassifier(16) # KNN, tested from 1 to 200, the best result is 16\nmodel5.fit(X_train, y_train)\npredictions5 = model5.predict(X_test)\naccuracy_score(predictions5, y_test)","f313f16b":"test = pd.read_csv(\"..\/input\/loan-prediction-problem-dataset\/test_Y3wMUE5_7gLdaTN.csv\")\nID = test[\"Loan_ID\"]\ntest.drop(\"Loan_ID\", axis = 1, inplace = True)\ntest.fillna(0, inplace = True)\ntest_encoded = pd.get_dummies(test, columns = [\"Dependents\", \"Property_Area\", \"Gender\", \"Married\", \"Education\", \"Self_Employed\"])\ntest_encoded.columns = test_encoded.columns.str.replace(\" \", \"_\")\ntest_encoded.columns.values[5] = \"Dependents_00\"\ntest_encoded.insert(16, \"Married_0\", 0)\ntest_encoded.head()","cbf70667":"test_predictions = model.predict(test_encoded)\ntest_predictions = pd.DataFrame(test_predictions, columns = [\"Loan_Status\"])\ntest_predictions[\"Loan_ID\"] = ID\ntest_predictions[\"Loan_Status\"].replace(0, \"N\", inplace = True)\ntest_predictions[\"Loan_Status\"].replace(1, \"Y\", inplace = True)\nfinal_predictions = test_predictions[[\"Loan_ID\", \"Loan_Status\"]]\nfinal_predictions.to_csv(\".\/final_submission.csv\",index = False)\nfinal_predictions.head()","0d485f2e":"test_predictions2 = model2.predict(test_encoded)\ntest_predictions2 = pd.DataFrame(test_predictions2, columns = [\"Loan_Status\"])\ntest_predictions2[\"Loan_ID\"] = ID\ntest_predictions2[\"Loan_Status\"].replace(0, \"N\", inplace = True)\ntest_predictions2[\"Loan_Status\"].replace(1, \"Y\", inplace = True)\nfinal_predictions2 = test_predictions2[[\"Loan_ID\", \"Loan_Status\"]]\nfinal_predictions2.to_csv(\".\/final_submission2.csv\",index = False)\nfinal_predictions2.head()","32aee32e":"test_predictions3 = model3.predict(test_encoded)\ntest_predictions3 = pd.DataFrame(test_predictions3, columns = [\"Loan_Status\"])\ntest_predictions3[\"Loan_ID\"] = ID\ntest_predictions3[\"Loan_Status\"].replace(0, \"N\", inplace = True)\ntest_predictions3[\"Loan_Status\"].replace(1, \"Y\", inplace = True)\nfinal_predictions3 = test_predictions3[[\"Loan_ID\", \"Loan_Status\"]]\nfinal_predictions3.to_csv(\".\/final_submission3.csv\",index = False)\nfinal_predictions3.head()","79919850":"test_predictions4 = model4.predict(test_encoded)\ntest_predictions4 = pd.DataFrame(test_predictions4, columns = [\"Loan_Status\"])\ntest_predictions4[\"Loan_ID\"] = ID\ntest_predictions4[\"Loan_Status\"].replace(0, \"N\", inplace = True)\ntest_predictions4[\"Loan_Status\"].replace(1, \"Y\", inplace = True)\nfinal_predictions4 = test_predictions4[[\"Loan_ID\", \"Loan_Status\"]]\nfinal_predictions4.to_csv(\".\/final_submission4.csv\",index = False)\nfinal_predictions4.head()","29634c4a":"test_predictions5 = model5.predict(test_encoded)\ntest_predictions5 = pd.DataFrame(test_predictions5, columns = [\"Loan_Status\"])\ntest_predictions5[\"Loan_ID\"] = ID\ntest_predictions5[\"Loan_Status\"].replace(0, \"N\", inplace = True)\ntest_predictions5[\"Loan_Status\"].replace(1, \"Y\", inplace = True)\nfinal_predictions5 = test_predictions5[[\"Loan_ID\", \"Loan_Status\"]]\nfinal_predictions5.to_csv(\".\/final_submission5.csv\",index = False)\nfinal_predictions5.head()","e841d2e6":"# Importing libraries","efc77d8d":"We are all good! Now we need to apply one-hot encoding. Creating multiple columns with 1\/0 values. We select only categorical columns","f75b8304":"# EDA","1fe82bb1":"Replace empty spaces in column names so that XGBClassifier would work correctly","bf46a53f":"Let's download the test dataset and then check its accuracy on https:\/\/datahack.analyticsvidhya.com\/contest\/practice-problem-loan-prediction-iii","2772fde2":"If we check every column for NaN values, you will see some NaN values in object type columns also, for instance in Gender or Married","a959e417":"Check the types of all columns, so that there is no problems","c215857a":"Now, we see two equal column names: \"Dependents_0\", replace first one by \"Dependents_00\"","e4c06154":"Let's see some basic statistics","274124d6":"![Loan.png](attachment:Loan.png)","6e846510":"We can use SelectKBest to choose only specific columns, however after cheking k = 2,3,5,10,15, I came to the conclusion that we need to use all columns. Because the accuracy drops a bit for every k.","3c7da3d0":"Now, we can see 25 columns, and newly created columns have either 0 or 1, meaning for instance: **Gender_Female = 1** => this instance is a female.","8da902c0":"We can observe some null values in LoanAmount, Loan_Amount_Term, Credit_History","516008f7":"# Models testing","6d106b9d":"After submission of 4 solutions to the https:\/\/datahack.analyticsvidhya.com\/contest\/practice-problem-loan-prediction-iii\/#MySubmissions. I got the best 79% accuracy on XGBClassifier. That's great for the beginning","04bae96e":"# Read train file as pandas dataframe","a0bc198a":"So, XGBClassifier can deal with such missing values, we just need to replace them with 0's. If you want to drop all such rows with missing values, later when trying to validate the model on test file, you will find missing values in columns, hence your model will be not that good dealing with missing values.","133e8e3b":"![image.png](attachment:image.png)"}}