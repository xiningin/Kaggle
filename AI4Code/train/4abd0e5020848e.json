{"cell_type":{"c880407c":"code","9e813902":"code","93ba311f":"code","3177b22c":"code","8c9a6152":"code","dcad892d":"code","7fba7c41":"code","89e554c2":"code","a8581f19":"code","b9100560":"code","0591ef7d":"code","fd81f015":"code","30a15055":"code","b8b2509c":"code","1cc90a51":"code","795b96b3":"code","5730f72b":"code","a704503a":"code","01117286":"code","1b48d1e7":"code","b40e75c0":"code","14dfbb9b":"code","e1bdee49":"code","12b5315e":"code","9a6a35e3":"code","8abe7c1f":"code","3df03f07":"markdown","8356c1d1":"markdown"},"source":{"c880407c":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pickle\nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n\nfrom sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, \\\n    classification_report\n\nfrom scipy.stats import shapiro\n\nimport warnings\nimport missingno as msno\n\nwarnings.filterwarnings(\"ignore\")\n\npd.set_option(\"display.float_format\", lambda x: '%.2f' % x)\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nlow_q1 = 0.05\nupper_q3 = 0.95\ncorrelation_limit = 0.60\n","9e813902":"\ndef cat_summary(dataframe, categorical_columns, target, plot=False):\n    \"\"\"\n    -> Kategorik de\u011fi\u015fkenlerin s\u0131n\u0131flar\u0131n\u0131n oran\u0131n\u0131 ve targettaki medyan\u0131 g\u00f6sterir.\n\n    :param dataframe: \u0130\u015flem yap\u0131lacak dataframe\n    :param categorical_columns: Kategorik de\u011fi\u015fkenlerin adlar\u0131\n    :param target: Dataframe'de ilgilendi\u011fimiz de\u011fi\u015fken.\n    :param plot: Grafik \u00e7izdirmek i\u00e7in arg\u00fcman : True\/False\n\n    \"\"\"\n    for col in categorical_columns:\n        print(col, \" : \", dataframe[col].nunique(), \" unique classes.\\n\")\n\n        print(col, \" : \", dataframe[col].value_counts().sum(), \"\\n\")\n\n        print(pd.DataFrame({\"COUNT\": dataframe[col].value_counts(),\n                            \"RATIO ( % )\": 100 * dataframe[col].value_counts() \/ len(dataframe),\n                            \"TARGET_MEDIAN\": dataframe.groupby(col)[target].median(),\n                            \"TARGET_MEAN\": dataframe.groupby(col)[target].mean()}), end=\"\\n\\n\\n\")\n\n        if plot:\n            sns.countplot(x=col, data=dataframe)\n\n            plt.show()\n\n\ndef hist_for_numeric_columns(dataframe, numeric_columns):\n    \"\"\"\n    -> Say\u0131sal de\u011fi\u015fkenlerin histogram\u0131n\u0131 \u00e7izdirir.\n\n    :param dataframe: \u0130\u015flem yap\u0131lacak dataframe.\n    :param numeric_columns: Say\u0131sal de\u011fi\u015fkenlerin adlar\u0131\n\n    \"\"\"\n    col_counter = 0\n\n    data = dataframe.copy()\n\n    for col in numeric_columns:\n        data[col].hist(bins=20)\n\n        plt.xlabel(col)\n\n        plt.title(col)\n\n        plt.show()\n\n        col_counter += 1\n\n    print(col_counter, \"variables have been plotted!\")\n\n\ndef find_correlation(dataframe, numeric_columns, target, corr_limit=correlation_limit):\n    \"\"\"\n    -> Say\u0131sal de\u011fi\u015fkenlerin targetla olan korelasyonunu inceler.\n\n    :param dataframe: \u0130\u015flem yap\u0131lacak dataframe\n    :param numeric_columns: Say\u0131sal de\u011fi\u015fken adlar\u0131\n    :param target: Korelasyon ili\u015fkisinde bak\u0131lacak hedef de\u011fi\u015fken\n    :param corr_limit: Korelasyon s\u0131n\u0131r\u0131. S\u0131n\u0131rdan a\u015fa\u011f\u0131s\u0131 d\u00fc\u015f\u00fck, yukar\u0131s\u0131 y\u00fcksek korelasyon\n    :return: \u0130lk de\u011fer d\u00fc\u015f\u00fck korelasyona sahip de\u011fi\u015fkenler, ikinci de\u011fer y\u00fcksek korelasyona sahip de\u011fi\u015fkenler\n    \"\"\"\n    high_correlations = []\n\n    low_correlations = []\n\n    for col in numeric_columns:\n        if col == target:\n            pass\n\n        else:\n            correlation = dataframe[[col, target]].corr().loc[col, target]\n\n            if abs(correlation) > corr_limit:\n                high_correlations.append(col + \" : \" + str(correlation))\n\n            else:\n                low_correlations.append(col + \" : \" + str(correlation))\n\n    return low_correlations, high_correlations\n\n\ndef outlier_thresholds(dataframe, variable, low_quantile=low_q1, up_quantile=upper_q3):\n    \"\"\"\n    -> Verilen de\u011ferin alt ve \u00fcst ayk\u0131r\u0131 de\u011ferlerini hesaplar ve d\u00f6nd\u00fcr\u00fcr.\n\n    :param dataframe: \u0130\u015flem yap\u0131lacak dataframe\n    :param variable: Ayk\u0131r\u0131 de\u011feri yakalanacak de\u011fi\u015fkenin ad\u0131\n    :param low_quantile: Alt e\u015fik de\u011ferin hesaplanmas\u0131 i\u00e7in bak\u0131lan quantile de\u011feri\n    :param up_quantile: \u00dcst e\u015fik de\u011ferin hesaplanmas\u0131 i\u00e7in bak\u0131lan quantile de\u011feri\n    :return: \u0130lk de\u011fer olarak verilen de\u011fi\u015fkenin alt s\u0131n\u0131r de\u011ferini, ikinci de\u011fer olarak \u00fcst s\u0131n\u0131r de\u011ferini d\u00f6nd\u00fcr\u00fcr\n    \"\"\"\n    quantile_one = dataframe[variable].quantile(low_quantile)\n\n    quantile_three = dataframe[variable].quantile(up_quantile)\n\n    interquantile_range = quantile_three - quantile_one\n\n    up_limit = quantile_three + 1.5 * interquantile_range\n\n    low_limit = quantile_one - 1.5 * interquantile_range\n\n    return low_limit, up_limit\n\n\ndef has_outliers(dataframe, numeric_columns, plot=False):\n    \"\"\"\n    -> Say\u0131sal de\u011fi\u015fkenlerde ayk\u0131r\u0131 g\u00f6zlem var m\u0131?\n\n    -> Varsa iste\u011fe g\u00f6re box plot \u00e7izdirme g\u00f6revini yapar.\n\n    -> Ayr\u0131ca ayk\u0131r\u0131 g\u00f6zleme sahip de\u011fi\u015fkenlerin ismini g\u00f6nd\u00fcr\u00fcr.\n\n    :param dataframe:  \u0130\u015flem yap\u0131lacak dataframe\n    :param numeric_columns: Ayk\u0131r\u0131 de\u011ferleri bak\u0131lacak say\u0131sal de\u011fi\u015fken adlar\u0131\n    :param plot: Boxplot grafi\u011fini \u00e7izdirmek i\u00e7in bool de\u011fer al\u0131r. True\/False\n    :return: Ayk\u0131r\u0131 de\u011ferlere sahip de\u011fi\u015fkenlerin adlar\u0131n\u0131 d\u00f6ner\n    \"\"\"\n    variable_names = []\n\n    for col in numeric_columns:\n        low_limit, up_limit = outlier_thresholds(dataframe, col)\n\n        if dataframe[(dataframe[col] > up_limit) | (dataframe[col] < low_limit)].any(axis=None):\n            number_of_outliers = dataframe[(dataframe[col] > up_limit) | (dataframe[col] < low_limit)].shape[0]\n\n            print(col, \" : \", number_of_outliers, \" ayk\u0131r\u0131 g\u00f6zlem.\")\n\n            variable_names.append(col)\n\n            if plot:\n                sns.boxplot(x=dataframe[col])\n                plt.show()\n\n    return variable_names\n\n\ndef replace_with_thresholds(dataframe, numeric_columns):\n    \"\"\"\n    Bask\u0131lama y\u00f6ntemi\n\n    Silmemenin en iyi alternatifidir.\n\n    Loc kullan\u0131ld\u0131\u011f\u0131ndan dataframe i\u00e7inde i\u015flemi uygular.\n\n    :param dataframe: \u0130\u015flem yap\u0131lacak dataframe\n    :param numeric_columns: Ayk\u0131r\u0131 de\u011ferleri bask\u0131lanacak say\u0131sal de\u011fi\u015fkenlerin adlar\u0131\n    \"\"\"\n    for variable in numeric_columns:\n        low_limit, up_limit = outlier_thresholds(dataframe, variable)\n\n        dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n\n        dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n\n\n\n\n\ndef one_hot_encoder(dataframe, categorical_columns, nan_as_category=False):\n    \"\"\"\n    Drop_first do\u011frusal modellerde yap\u0131lmas\u0131 gerekli\n\n    A\u011fa\u00e7 modellerde gerekli de\u011fil ama yap\u0131labilir.\n\n    dummy_na eksik de\u011ferlerden de\u011fi\u015fken t\u00fcrettirir.\n\n    :param dataframe: \u0130\u015flem yap\u0131lacak dataframe\n    :param categorical_columns: One-Hot Encode uygulanacak kategorik de\u011fi\u015fken adlar\u0131\n    :param nan_as_category: NaN de\u011fi\u015fken olu\u015ftursun mu? True\/False\n    :return: One-Hot Encode yap\u0131lm\u0131\u015f dataframe ve bu i\u015flem sonras\u0131 olu\u015fan yeni de\u011fi\u015fken adlar\u0131n\u0131 d\u00f6nd\u00fcr\u00fcr.\n    \"\"\"\n    original_columns = list(dataframe.columns)\n\n    dataframe = pd.get_dummies(dataframe, columns=categorical_columns,\n                               dummy_na=nan_as_category, drop_first=False)\n\n    new_columns = [col for col in dataframe.columns if col not in original_columns]\n\n    return dataframe, new_columns\n\n\ndef rare_analyser(dataframe, categorical_columns, target, rare_perc):\n    \"\"\"\n     Data frame de\u011fi\u015fkenlerinin herhangi bir s\u0131n\u0131f\u0131, verilen e\u015fik de\u011ferden d\u00fc\u015f\u00fck frekansa sahipse bu de\u011fi\u015fkenleri g\u00f6sterir.\n\n    :param dataframe: \u0130\u015flem yap\u0131lacak dataframe\n    :param categorical_columns: Rare analizi yap\u0131lacak kategorik de\u011fi\u015fken adlar\u0131\n    :param target: Analizi yap\u0131lacak hedef de\u011fi\u015fken ad\u0131\n    :param rare_perc: Rare i\u00e7in s\u0131n\u0131r de\u011fer. Alt\u0131nda olanlar rare kategorisine girer.\n    :return:\n    \"\"\"\n    rare_columns = [col for col in categorical_columns\n                    if (dataframe[col].value_counts() \/ len(dataframe) < rare_perc).any(axis=None)]\n\n    for var in rare_columns:\n        print(var, \" : \", len(dataframe[var].value_counts()))\n\n        print(pd.DataFrame({\"COUNT\": dataframe[var].value_counts(),\n                            \"RATIO\": dataframe[var].value_counts() \/ len(dataframe),\n                            \"TARGET_MEAN\": dataframe.groupby(var)[target].mean(),\n                            \"TARGET_MEDIAN\": dataframe.groupby(var)[target].median()}),\n              end=\"\\n\\n\\n\")\n\n    print(len(rare_columns), \" adet rare s\u0131n\u0131fa sahip de\u011fi\u015fken var.\")\n\n\n\ndef robust_scaler(variable):\n    var_median = variable.median()\n    quartile1 = variable.quantile(0.01)\n    quartile3 = variable.quantile(0.99)\n    interquantile_range = quartile3 - quartile1\n    if int(interquantile_range) == 0:\n        quartile1 = variable.quantile(0.05)\n        quartile3 = variable.quantile(0.95)\n        interquantile_range = quartile3 - quartile1\n        if int(interquantile_range) == 0:\n            quartile1 = variable.quantile(0.25)\n            quartile3 = variable.quantile(0.75)\n            interquantile_range = quartile3 - quartile1\n            z = (variable - var_median) \/ interquantile_range\n            return round(z, 3)\n\n        z = (variable - var_median) \/ interquantile_range\n        return round(z, 3)\n    else:\n        z = (variable - var_median) \/ interquantile_range\n    return round(z, 3)\n","93ba311f":"# reading the data\ndf = pd.read_csv(\"..\/input\/churn-analysis\/churn.csv\")","3177b22c":"# Verinin ba\u015ftan ilk 5 g\u00f6zlemi\ndf.head()","8c9a6152":"# Verinin sondan ilk 5 g\u00f6zlemi\n\ndf.tail()","dcad892d":"# Ka\u00e7 farkl\u0131 m\u00fc\u015fteri var?\ndf[\"CustomerId\"].nunique()","7fba7c41":"# Anlams\u0131z de\u011fi\u015fkenlerin d\u00fc\u015f\u00fcr\u00fclmesi\nneed_drops = [\"RowNumber\", \"CustomerId\", \"Surname\"]\ndf.drop(need_drops, axis=1, inplace=True)","89e554c2":"# Eksik g\u00f6zlem kontrol\u00fc\ndf.isnull().sum()","a8581f19":"# Betimsel istatistiklere bakal\u0131m\ndf.describe([0.01, 0.05, 0.25, 0.50, 0.75, 0.95, 0.99]).T","b9100560":"# Kategorik de\u011fi\u015fkenlerin hedefle ili\u015fkisinin incelenmesi\ntemp_categorical = [\"Geography\", \"Gender\", \"Tenure\", \"NumOfProducts\", \"HasCrCard\", \"IsActiveMember\"]\ncat_summary(df, temp_categorical, \"Exited\")","0591ef7d":"# Say\u0131sal de\u011fi\u015fkenler i\u00e7in histogram incelenmesi\ntemp_numeric = [\"CreditScore\", \"Age\", \"Balance\", \"EstimatedSalary\"]\nhist_for_numeric_columns(df, temp_numeric)","fd81f015":"# Say\u0131sal de\u011fi\u015fkenlerin normallik varsay\u0131mlar\u0131\n# H0: Normal da\u011f\u0131l\u0131m varsay\u0131m\u0131 sa\u011flanmaktad\u0131r.\n# H1:... sa\u011flanmamaktad\u0131r.\n\n# p - value < ise 0.05'ten HO RED.\n# p - value < de\u011filse 0.05 H0 REDDED\u0130LEMEZ.\ncreditscore = df[[\"CreditScore\"]]\nbalance = df[[\"Balance\"]]\nsalary = df[[\"EstimatedSalary\"]]\nages = df[[\"Age\"]]\n\nshapiro(creditscore[\"CreditScore\"])[1] < 0.05","30a15055":"shapiro(balance[\"Balance\"])[1] < 0.05","b8b2509c":"shapiro(salary[\"EstimatedSalary\"])[1] < 0.05","1cc90a51":"shapiro(ages[\"Age\"])[1] < 0.05","795b96b3":"# Korelasyonlara bakal\u0131m\nlow_corr_list, up_corr_list = find_correlation(df, temp_numeric, \"Exited\")\nprint(\"Low Corr List\")\nfor i in low_corr_list:\n    print(i)\n\nprint(\"High Corr List\")\nfor i in up_corr_list:\n    print(i)","5730f72b":"# Feature Engineering\n\nbins = [15, 25, 40, 55, 100]\nnames = ['Young', 'Adult', 'Mature', 'Old']\ndf[\"NEW_Age_Range\"] = pd.cut(df['Age'], bins, labels=names)\n\n\n\nbins = [0, 2, 4, 6, 14]\nnames = ['New', 'Accustomed', 'Loyal', 'Constant']\ndf[\"NEW_Tenure_Status\"] = pd.cut(df['Tenure'], bins, labels=names)\n\n\nnames = ['CAT1', 'CAT2', 'CAT3', 'CAT4', 'CAT5']\ndf[\"NEW_CreditScore_Status\"] = pd.qcut(df['CreditScore'], 5, labels=names)\n\nnames = ['CAT1', 'CAT2', 'CAT3', 'CAT4', 'CAT5']\ndf[\"NEW_EstimatedSalary_Status\"] = pd.qcut(df['EstimatedSalary'], 5, labels=names)\n\n\ndf[\"NEW_Card_Member_Score\"] = df[\"HasCrCard\"] * df[\"IsActiveMember\"]\n\ndf[\"NEW_MemberStarts_Age\"] = df[\"Age\"] - df[\"Tenure\"]\n\n\nbins = [5, 25, 40, 55, 100]\nnames = ['Young', 'Adult', 'Mature', 'Old']\ndf[\"NEW_MemberStarts_Age_Range\"] = pd.cut(df[\"NEW_MemberStarts_Age\"], bins, labels=names)\n","a704503a":"\ncategorical_columns = [\"Geography\", \"Gender\", \"NumOfProducts\",\n                       \"NEW_Age_Range\", \"NEW_Tenure_Status\",\n                       \"NEW_CreditScore_Status\", \"NEW_EstimatedSalary_Status\",\n                       \"NEW_MemberStarts_Age_Range\"]\n\nnumerical_columns = [\"CreditScore\", \"Age\", \"Tenure\", \"Balance\",\n                     \"EstimatedSalary\",\n                     \"NEW_Card_Member_Score\", \"NEW_MemberStarts_Age\"]\n\n\nrare_analyser(df, categorical_columns, \"Exited\", 0.5)","01117286":"# Nadir s\u0131n\u0131flar silinecek\ndf = df.loc[~((df[\"NumOfProducts\"] == 3) | (df[\"NumOfProducts\"] == 4))]","1b48d1e7":"# One-Hot Encode\ndf, one_hot_columns = one_hot_encoder(df, categorical_columns)","b40e75c0":"# Robust Scale\nneed_scale_cols = [\"Balance\", \"EstimatedSalary\"]\nfor col in need_scale_cols:\n    df[col] = robust_scaler(df[col])","14dfbb9b":"df.describe([0.01, 0.05, 0.25, 0.50, 0.75, 0.95, 0.99]).T","e1bdee49":"# ****************************************************************#\n# Models\nX = df.drop(\"Exited\", axis=1)\ny = np.ravel(df[[\"Exited\"]])\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123)\n\nrf_params = {\"max_depth\": [3, 5, 8],\n             \"max_features\": [8, 15, 25],\n             \"n_estimators\": [200, 500, 1000],\n             \"min_samples_split\": [2, 5, 10]}\n\nlgbm_params = {\"learning_rate\": [0.01, 0.1],\n               \"n_estimators\": [200, 500, 1000],\n               \"max_depth\": [3, 5, 8],\n               \"colsample_bytree\": [1, 0.8, 0.5],\n               \"num_leaves\": [32, 64, 128]}\n\nxgb_params = {\"learning_rate\": [0.1, 0.01],\n              \"max_depth\": [3, 5, 8],\n              \"n_estimators\": [200, 500, 1000],\n              \"colsample_bytree\": [0.7, 1]}","12b5315e":"rf = RandomForestClassifier(random_state=123)\nlgbm = LGBMClassifier(random_state=123)\nxgb = XGBClassifier(random_state=123)","9a6a35e3":"gs_cv_rf = GridSearchCV(rf,\n                        rf_params,\n                        cv=10,\n                        n_jobs=-1,\n                        verbose=2).fit(X_train, y_train)\n\ngs_cv_lgbm = GridSearchCV(lgbm,\n                          lgbm_params,\n                          cv=10,\n                          n_jobs=-1,\n                          verbose=2).fit(X_train, y_train)\n\ngs_cv_xgb = GridSearchCV(xgb,\n                         xgb_params,\n                         cv=10,\n                         n_jobs=-1,\n                         verbose=2).fit(X_train, y_train)","8abe7c1f":"rf_tuned = RandomForestClassifier(**gs_cv_rf.best_params_, random_state=123).fit(X_train, y_train)\n\nlgbm_tuned = LGBMClassifier(**gs_cv_lgbm.best_params_, random_state=123).fit(X_train, y_train)\n\nxgb_tuned = XGBClassifier(**gs_cv_xgb.best_params_, random_state=123).fit(X_train, y_train)\n\n# Accuracy results\nmodels = [(\"RF\", rf_tuned),\n          (\"LGBM\", lgbm_tuned),\n          (\"XGB\", xgb_tuned)]\n\nfor name, model in models:\n    y_pred = model.predict(X_test)\n    acc = accuracy_score(y_test, y_pred)\n    msg = \"%s: (%f)\" % (name, acc)\n    print(msg)","3df03f07":"## Churn Prediction \n### A Machine Learning Model That Can Predict Customers Who Will Leave The Company\n\nThe aim is to predict whether a bank's customers leave the bank or not. If the Client has closed his\/her bank account, he\/she has left.\n\n## Dataset\n\n- **RowNumber:** corresponds to the record (row) number and has no effect on the output.\n- **CustomerId:** contains random values and has no effect on customer leaving the bank.\n- **Surname:** the surname of a customer has no impact on their decision to leave the bank.\n- **CreditScore:** can have an effect on customer churn, since a customer with a higher credit score is less likely to leave the bank.\n- **Geography:** a customer\u2019s location can affect their decision to leave the bank.\n- **Gender:** it\u2019s interesting to explore whether gender plays a role in a customer leaving the bank.\n- **Age:** this is certainly relevant, since older customers are less likely to leave their bank than younger ones.\n- **Tenure:** refers to the number of years that the customer has been a client of the bank. Normally, older clients are more loyal and less likely to leave a bank.\n- **Balance:** also a very good indicator of customer churn, as people with a higher balance in their accounts are less likely to leave the bank compared to those with lower balances.\n- **NumOfProducts:** refers to the number of products that a customer has purchased through the bank.\n- **HasCrCard:** denotes whether or not a customer has a credit card. This column is also relevant, since people with a credit card are less likely to leave the bank.\n- **IsActiveMember:** active customers are less likely to leave the bank.\n- **EstimatedSalary:** as with balance, people with lower salaries are more likely to leave the bank compared to those with higher salaries.\n- **Exited:** whether or not the customer left the bank.  (0=No,1=Yes)\n\n\n\n### The model created as a result of LightGBM hyperparameter optimization (0.867300)","8356c1d1":"\n### B\u00fct\u00fcn H0'lar reddedildi"}}