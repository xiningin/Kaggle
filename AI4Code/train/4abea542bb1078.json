{"cell_type":{"99a9b78e":"code","2c8ceed8":"code","d26407b4":"code","0eaf4fdd":"code","d5542b42":"code","b263e272":"code","efc3c21a":"code","24c89c97":"code","9163870b":"code","40cd49a8":"code","3b878270":"code","fc8a7315":"code","99d30907":"code","bfc2f277":"code","647a0cd6":"code","dd21bdd5":"code","8458b283":"code","d9cb5179":"code","5591ead3":"code","d677f287":"code","d6a2a985":"code","fe6de6a0":"code","14171be7":"code","32cfe83d":"code","4e214eab":"code","5e595d75":"code","b9a1d6a8":"code","6f7ed6a7":"code","de7fd3aa":"code","d2c7e9bc":"code","11c9d2d0":"code","3ee6a95d":"code","83ae21ef":"code","124b995d":"code","177d78d7":"code","5909b7bc":"code","914954b8":"code","1a30a070":"code","d9d787a5":"code","c3df46e3":"code","17178a7d":"code","43858646":"code","cc9f895e":"code","63a176f9":"code","e0abde6e":"code","b44ce71d":"code","13e70ccf":"code","fa840b8d":"code","a056928d":"code","20a7b701":"code","9230343a":"code","3597c124":"code","5db66ad1":"code","8308b312":"code","21ab037f":"code","8762c98f":"code","9794ba35":"code","14848f97":"code","d2b7a297":"code","0c1c6eab":"code","a89b3679":"markdown","d25c5ed4":"markdown","429e450b":"markdown","0766a6f8":"markdown","73c92862":"markdown","a9380994":"markdown","b89a3568":"markdown","a848e7cd":"markdown","a3d7b791":"markdown","52954eaa":"markdown","97726e28":"markdown","9607b808":"markdown","37d617f3":"markdown","1416dacc":"markdown","e05a143b":"markdown","36018431":"markdown","c64ad19e":"markdown"},"source":{"99a9b78e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib import style\nstyle.use(\"ggplot\")","2c8ceed8":"data = pd.read_csv('..\/input\/heart-disease-health-indicators-dataset\/heart_disease_health_indicators_BRFSS2015.csv')","d26407b4":"data.shape","0eaf4fdd":"data.drop_duplicates(inplace=True)","d5542b42":"data.shape","b263e272":"data.head()","efc3c21a":"data.info()","24c89c97":"data.isna().sum()","9163870b":"target=\"HeartDiseaseorAttack\"","40cd49a8":"fig, axes = plt.subplots(nrows=data.shape[1], ncols=1, figsize=(20,13*data.shape[1]))\nfor i in range(len(data.columns)):\n    col = data.columns[i]\n    sns.countplot(x=col, data=data, hue=target, palette=\"seismic\", ax=axes[i])\naxes[0].legend([])\nplt.show()","3b878270":"x = data.drop(target, axis=1)\ny = data[target]","fc8a7315":"from sklearn.preprocessing import RobustScaler\nrs = RobustScaler()","99d30907":"from sklearn.model_selection import train_test_split","bfc2f277":"xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.1, random_state=44)","647a0cd6":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report","dd21bdd5":"model = RandomForestClassifier()\n\nmodel.fit(xtrain, ytrain)\n\nypred_tr = model.predict(xtrain)\nypred_ts = model.predict(xtest)\n\nprint(\"Training Results:\\n\")\nprint(classification_report(ytrain, ypred_tr))\nprint(\"\\n\\nTesting Results:\")\nprint(classification_report(ytest, ypred_ts))","8458b283":"model = RandomForestClassifier(max_depth=20)\n\nmodel.fit(xtrain, ytrain)\n\nypred_tr = model.predict(xtrain)\nypred_ts = model.predict(xtest)\n\nprint(\"Training Results:\\n\")\nprint(classification_report(ytrain, ypred_tr))\nprint(\"\\n\\nTesting Results:\\n\")\nprint(classification_report(ytest, ypred_ts))","d9cb5179":"from imblearn.under_sampling import RandomUnderSampler","5591ead3":"sampler = RandomUnderSampler(random_state=11)","d677f287":"xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.1, stratify=y, random_state=45)","d6a2a985":"xs, ys = sampler.fit_resample(xtrain, ytrain)","fe6de6a0":"forest = RandomForestClassifier(random_state=11)\nforest.fit(xs, ys)\n\nypred_tr = forest.predict(xs)\nypred_ts = forest.predict(xtest)\n\nprint(\"Training Results:\\n\")\nprint(classification_report(ys, ypred_tr))\nprint(\"\\n\\nTesting Results:\\n\")\nprint(classification_report(ytest, ypred_ts))","14171be7":"forest = RandomForestClassifier(max_depth=25, min_samples_leaf=3, max_samples=0.5, random_state=11)\nforest.fit(xs, ys)\n\nypred_tr = forest.predict(xs)\nypred_ts = forest.predict(xtest)\n\nprint(\"Training Results:\\n\")\nprint(classification_report(ys, ypred_tr))\nprint(\"\\n\\nTesting Results:\\n\")\nprint(classification_report(ytest, ypred_ts))","32cfe83d":"xsmall = x.sample(n=15000)\nysmall = y[xsmall.index]","4e214eab":"from imblearn.under_sampling import ClusterCentroids","5e595d75":"sampler = ClusterCentroids(random_state=55, voting='hard')","b9a1d6a8":"xtrain, xtest, ytrain, ytest = train_test_split(xsmall, ysmall, test_size=0.1, stratify=ysmall, random_state=45)","6f7ed6a7":"xtrain = rs.fit_transform(xtrain)\nxtest = rs.transform(xtest)","de7fd3aa":"xs, ys = sampler.fit_resample(xtrain, ytrain)","d2c7e9bc":"forest = RandomForestClassifier(random_state=11)\nforest.fit(xs, ys)\n\nypred_tr = forest.predict(xs)\nypred_ts = forest.predict(xtest)\n\nprint(\"Training Results:\\n\")\nprint(classification_report(ys, ypred_tr))\nprint(\"\\n\\nTesting Results:\\n\")\nprint(classification_report(ytest, ypred_ts))","11c9d2d0":"forest = RandomForestClassifier(max_depth=17, min_samples_leaf=3, max_samples=0.5, random_state=11)\nforest.fit(xs, ys)\n\nypred_tr = forest.predict(xs)\nypred_ts = forest.predict(xtest)\n\nprint(\"Training Results:\\n\")\nprint(classification_report(ys, ypred_tr))\nprint(\"\\n\\nTesting Results:\\n\")\nprint(classification_report(ytest, ypred_ts))","3ee6a95d":"from imblearn.over_sampling import RandomOverSampler","83ae21ef":"sampler = RandomOverSampler(random_state=11)","124b995d":"xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.1, random_state=45)","177d78d7":"xs, ys = sampler.fit_resample(xtrain, ytrain)","5909b7bc":"forest = RandomForestClassifier(random_state=11)\nforest.fit(xs, ys)\n\nypred_tr = forest.predict(xs)\nypred_ts = forest.predict(xtest)\n\nprint(\"Training Results:\\n\")\nprint(classification_report(ys, ypred_tr))\nprint(\"\\n\\nTesting Results:\\n\")\nprint(classification_report(ytest, ypred_ts))","914954b8":"forest = RandomForestClassifier(n_estimators=300, max_depth=30, min_samples_leaf=3, max_samples=0.8, random_state=11)\nforest.fit(xs, ys)\n\nypred_tr = forest.predict(xs)\nypred_ts = forest.predict(xtest)\n\nprint(\"Training Results:\\n\")\nprint(classification_report(ys, ypred_tr))\nprint(\"\\n\\nTesting Results:\\n\")\nprint(classification_report(ytest, ypred_ts))","1a30a070":"from imblearn.over_sampling import SMOTE","d9d787a5":"sampler = SMOTE(k_neighbors=5, random_state=11)","c3df46e3":"xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.1, random_state=45)","17178a7d":"xtrain = rs.fit_transform(xtrain)\nxtest = rs.transform(xtest)","43858646":"xs, ys = sampler.fit_resample(xtrain, ytrain)","cc9f895e":"forest = RandomForestClassifier(random_state=11, n_jobs=-1)\nforest.fit(xs, ys)\n\nypred_tr = forest.predict(xs)\nypred_ts = forest.predict(xtest)\n\nprint(\"Training Results:\\n\")\nprint(classification_report(ys, ypred_tr))\nprint(\"\\n\\nTesting Results:\\n\")\nprint(classification_report(ytest, ypred_ts))","63a176f9":"forest = RandomForestClassifier(n_estimators=200, max_depth=25, min_samples_leaf=3, max_samples=0.8, random_state=11, n_jobs=-1)\nforest.fit(xs, ys)\n\nypred_tr = forest.predict(xs)\nypred_ts = forest.predict(xtest)\n\nprint(\"Training Results:\\n\")\nprint(classification_report(ys, ypred_tr))\nprint(\"\\n\\nTesting Results:\\n\")\nprint(classification_report(ytest, ypred_ts))","e0abde6e":"from imblearn.over_sampling import BorderlineSMOTE","b44ce71d":"sampler = BorderlineSMOTE(k_neighbors=5, random_state=11)","13e70ccf":"xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.1, random_state=45)","fa840b8d":"xtrain = rs.fit_transform(xtrain)\nxtest = rs.transform(xtest)","a056928d":"xs, ys = sampler.fit_resample(xtrain, ytrain)","20a7b701":"forest = RandomForestClassifier(random_state=11, n_jobs=-1)\nforest.fit(xs, ys)\n\nypred_tr = forest.predict(xs)\nypred_ts = forest.predict(xtest)\n\nprint(\"Training Results:\\n\")\nprint(classification_report(ys, ypred_tr))\nprint(\"\\n\\nTesting Results:\\n\")\nprint(classification_report(ytest, ypred_ts))","9230343a":"forest = RandomForestClassifier(n_estimators=200, max_depth=25, min_samples_leaf=3, max_samples=0.8, random_state=11, n_jobs=-1)\nforest.fit(xs, ys)\n\nypred_tr = forest.predict(xs)\nypred_ts = forest.predict(xtest)\n\nprint(\"Training Results:\\n\")\nprint(classification_report(ys, ypred_tr))\nprint(\"\\n\\nTesting Results:\\n\")\nprint(classification_report(ytest, ypred_ts))","3597c124":"!pip install smote-variants","5db66ad1":"import smote_variants as sv","8308b312":"from smote_variants import DBSMOTE","21ab037f":"oversampler = DBSMOTE(min_samples=10)","8762c98f":"xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.1, random_state=45)","9794ba35":"xtrain = rs.fit_transform(xtrain)\nxtest = rs.transform(xtest)","14848f97":"xs, ys = oversampler.sample(xtrain, ytrain)","d2b7a297":"forest = RandomForestClassifier(random_state=11, n_jobs=-1)\nforest.fit(xs, ys)\n\nypred_tr = forest.predict(xs)\nypred_ts = forest.predict(xtest)\n\nprint(\"Training Results:\\n\")\nprint(classification_report(ys, ypred_tr))\nprint(\"\\n\\nTesting Results:\\n\")\nprint(classification_report(ytest, ypred_ts))","0c1c6eab":"forest = RandomForestClassifier(n_estimators=200, max_depth=25, min_samples_leaf=3, max_samples=0.8, random_state=11, n_jobs=-1)\nforest.fit(xs, ys)\n\nypred_tr = forest.predict(xs)\nypred_ts = forest.predict(xtest)\n\nprint(\"Training Results:\\n\")\nprint(classification_report(ys, ypred_tr))\nprint(\"\\n\\nTesting Results:\\n\")\nprint(classification_report(ytest, ypred_ts))","a89b3679":"![](https:\/\/dataaspirant.com\/wp-content\/uploads\/2020\/08\/10-oversampling.png)","d25c5ed4":"![](https:\/\/storage.googleapis.com\/kagglesdsdata\/datasets\/1909739\/3134576\/clustercentroids.png?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=databundle-worker-v2%40kaggle-161607.iam.gserviceaccount.com%2F20220203%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20220203T155426Z&X-Goog-Expires=345599&X-Goog-SignedHeaders=host&X-Goog-Signature=1a3d0cc455cb234d8f06d5366e2e2be27fa85f39415141ea0ca9e3d39ca614f51f62338b8c44a087b31a81ddd8f996d3cc081bd10757f9d91dca38b54bdc50cc5f6279babdacbb44f91bee92f6c2a6c12dadefa6add0c606c788bf946b27f086f82a14d9e91d28ed9b0d7378ea89ccc41afe1c543460101140b7a8622b099edd083e5a5186ad913cddf2e6424c3d119121e84ed80c0f50644c1aacc063a2ed51b13b044fb91a375cd2b5fefca5dbcdd475fdbb65925bbfcac59d677aebb420e0cbd2de47342894389bcb0fa51a5c5b6e251566fd30e21c2c5e604106a2cfb6f0eb4a0792a182f2394627ba20aa1fbfdb9594fa56c6a7a087db67060a92c81a73)\npicture from [here](https:\/\/towardsdatascience.com\/k-means-a-complete-introduction-1702af9cd8c) with edits","429e450b":"# Oversampling","0766a6f8":"## 1) Random Oversampling","73c92862":"![](https:\/\/i.stack.imgur.com\/FEOjd.jpg)","a9380994":"# Undersampling","b89a3568":"![](https:\/\/miro.medium.com\/max\/734\/1*yRumRhn89acByodBz0H7oA.png)","a848e7cd":"# Metrics to be considered","a3d7b791":"## 4) DBSMOTE\n### using the \"smote-variants\" library","52954eaa":"![](https:\/\/www.researchgate.net\/publication\/336402347\/figure\/fig3\/AS:812472659349505@1570719985505\/Calculation-of-Precision-Recall-and-Accuracy-in-the-confusion-matrix.ppm)\n\n![](https:\/\/datascience103579984.files.wordpress.com\/2019\/04\/capture3-24.png)","97726e28":"## 2) Cluster Centroid Undersampling","9607b808":"# Resampling Methods for Imbalanced Classification","37d617f3":"## 2) SMOTE - Synthetic Minority Oversampling TEchnique","1416dacc":"# Processing, Analysis & Baseline Model","e05a143b":"## 1) Random Undersampling","36018431":"![](https:\/\/miro.medium.com\/max\/335\/1*YH_vPYQEDIW0JoUYMeLz_A.png)","c64ad19e":"## 3) Borderline SMOTE"}}