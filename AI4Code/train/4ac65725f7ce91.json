{"cell_type":{"35898b78":"code","0029344a":"code","eecb7001":"code","01403d9e":"code","ab800a61":"code","c4b5845c":"code","3a027bc1":"code","3b37635f":"code","0316b72d":"code","efe6a41e":"code","b45b2487":"code","1d5d458a":"code","d4679b8d":"code","6211770b":"code","eab53dba":"code","3a463e91":"code","b3b03ae9":"code","840a4e53":"code","d5043809":"code","8bb3a884":"code","9e0c5372":"code","9c2c84c4":"code","017831e4":"code","adacf859":"code","11128fba":"code","4cd1e6b1":"code","693932b0":"code","008274b8":"code","ebf68ce3":"code","4ff5f22f":"code","66d43ae0":"code","7ab43023":"code","f0d1f271":"code","82a6628f":"code","d094113b":"markdown","3ae2ea50":"markdown"},"source":{"35898b78":"# Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.pyplot as plt\n\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_curve  \nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split","0029344a":"# Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","eecb7001":"# Load Data\ndataset=pd.read_csv('..\/input\/diabetes-prediction\/diabetes.csv')\ndataset.head(5)","01403d9e":"# Variables and info about type of data\ndataset.info()","ab800a61":"dataset[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = dataset[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0, np.NaN)\ndataset.isnull().sum()","c4b5845c":"def median_target(var):   \n    temp = dataset[dataset[var].notnull()]\n    temp = temp[[var, 'Outcome']].groupby(['Outcome'])[[var]].median().reset_index()\n    return temp\ncolumns = dataset.columns\ncolumns = columns.drop(\"Outcome\")\nfor col in columns:\n    dataset.loc[(dataset['Outcome'] == 0 ) & (dataset[col].isnull()), col] = median_target(col)[col][0]\n    dataset.loc[(dataset['Outcome'] == 1 ) & (dataset[col].isnull()), col] = median_target(col)[col][1]","3a027bc1":"# Correlation Pearson Matrix\ncorrelation=dataset.corr()\ncorrelation","3b37635f":"correlation['Outcome'].sort_values()","0316b72d":"# Describe outcome  - Frequency\ndataset['Outcome'].value_counts()","efe6a41e":"aux=pd.DataFrame(dataset['Outcome'],columns=['Outcome'])","b45b2487":"variable='Glucose'\ncortes=[dataset[variable].min()-1,\n        np.percentile(dataset[variable],13),        \n        np.percentile(dataset[variable],30),\n        np.percentile(dataset[variable],40),\n        np.percentile(dataset[variable],50),\n        np.percentile(dataset[variable],62),\n        np.percentile(dataset[variable],69),\n        np.percentile(dataset[variable],76),\n        np.percentile(dataset[variable],80),       \n        np.percentile(dataset[variable],89), \n        dataset[variable].max()]\naux['var_'+variable]=pd.cut(dataset[variable],cortes)\naux.groupby('var_'+variable).mean().plot()\nprint('\\nODF:')\nprint(aux.groupby('var_'+variable).mean())\nprint('\\nN\u00famero de casos:')\nprint(aux.groupby('var_'+variable).count()['Outcome'],'\\n')","1d5d458a":"variable='BMI'\ncortes=[dataset[variable].min()-1,\n        np.percentile(dataset[variable],5),\n        np.percentile(dataset[variable],14),\n        np.percentile(dataset[variable],20),\n        np.percentile(dataset[variable],30),\n        np.percentile(dataset[variable],40),        \n        np.percentile(dataset[variable],90),         \n        dataset[variable].max()]\naux['var_'+variable]=pd.cut(dataset[variable],cortes)\naux.groupby('var_'+variable).mean().plot()\nprint('\\nODF:')\nprint(aux.groupby('var_'+variable).mean())\nprint('\\nN\u00famero de casos:')\nprint(aux.groupby('var_'+variable).count()['Outcome'],'\\n')","d4679b8d":"variable='Age'\ncortes=[dataset[variable].min()-1,\n        np.percentile(dataset[variable],5),\n        np.percentile(dataset[variable],10),\n        np.percentile(dataset[variable],20),\n        np.percentile(dataset[variable],30),\n        np.percentile(dataset[variable],40),\n        dataset[variable].max()]\naux['var_'+variable]=pd.cut(dataset[variable],cortes)\naux.groupby('var_'+variable).mean().plot()\nprint('\\nODF:')\nprint(aux.groupby('var_'+variable).mean())\nprint('\\nN\u00famero de casos:')\nprint(aux.groupby('var_'+variable).count()['Outcome'],'\\n')","6211770b":"variable='Pregnancies'\ncortes=[dataset[variable].min()-1,\n        np.percentile(dataset[variable],50),\n        np.percentile(dataset[variable],60),\n        np.percentile(dataset[variable],70),\n        np.percentile(dataset[variable],80), \n        np.percentile(dataset[variable],95), \n        dataset[variable].max()]\naux['var_'+variable]=pd.cut(dataset[variable],cortes)\naux.groupby('var_'+variable).mean().plot()\nprint('\\nODF:')\nprint(aux.groupby('var_'+variable).mean())\nprint('\\nN\u00famero de casos:')\nprint(aux.groupby('var_'+variable).count()['Outcome'],'\\n')","eab53dba":"variable='DiabetesPedigreeFunction'\ncortes=[dataset[variable].min()-1,\n        np.percentile(dataset[variable],3),\n        np.percentile(dataset[variable],20),               \n        np.percentile(dataset[variable],60),\n        np.percentile(dataset[variable],70),\n        np.percentile(dataset[variable],80),\n        np.percentile(dataset[variable],85),  \n        np.percentile(dataset[variable],96),  \n        dataset[variable].max()]\naux['var_'+variable]=pd.cut(dataset[variable],cortes)\naux.groupby('var_'+variable).mean().plot()\nprint('\\nODF:')\nprint(aux.groupby('var_'+variable).mean())\nprint('\\nN\u00famero de casos:')\nprint(aux.groupby('var_'+variable).count()['Outcome'],'\\n')","3a463e91":"variable='Insulin'\ncortes=[dataset[variable].min()-1,      \n        np.percentile(dataset[variable],80),       \n        np.percentile(dataset[variable],90),\n        np.percentile(dataset[variable],95),        \n        dataset[variable].max()]\naux['var_'+variable]=pd.cut(dataset[variable],cortes)\naux.groupby('var_'+variable).mean().plot()\nprint('\\nODF:')\nprint(aux.groupby('var_'+variable).mean())\nprint('\\nN\u00famero de casos:')\nprint(aux.groupby('var_'+variable).count()['Outcome'],'\\n')","b3b03ae9":"variable='SkinThickness'\ncortes=[dataset[variable].min()-1,          \n        np.percentile(dataset[variable],40),     \n        dataset[variable].max()]\naux['var_'+variable]=pd.cut(dataset[variable],cortes)\naux.groupby('var_'+variable).mean().plot()\nprint('\\nODF:')\nprint(aux.groupby('var_'+variable).mean())\nprint('\\nN\u00famero de casos:')\nprint(aux.groupby('var_'+variable).count()['Outcome'],'\\n')","840a4e53":"variable='BloodPressure'\ncortes=[dataset[variable].min()-1,        \n        np.percentile(dataset[variable],40),     \n        np.percentile(dataset[variable],80),\n        np.percentile(dataset[variable],90),          \n        dataset[variable].max()]\naux['var_'+variable]=pd.cut(dataset[variable],cortes)\naux.groupby('var_'+variable).mean().plot()\nprint('\\nODF:')\nprint(aux.groupby('var_'+variable).mean())\nprint('\\nN\u00famero de casos:')\nprint(aux.groupby('var_'+variable).count()['Outcome'],'\\n')","d5043809":"aux","8bb3a884":"# Conversi\u00f3n en n\u00famericas\ndf4=aux.Outcome\nfor i in aux.columns[1:]:\n    spd1=pd.DataFrame(aux.groupby(aux[i]).mean().Outcome)\n    auxiliar=spd1.to_dict()\n    spd2=aux[i].map(auxiliar.get('Outcome'))\n    df4=pd.DataFrame(df4).join(pd.DataFrame(spd2))\ndataset=df4\ndataset","9e0c5372":"dataset=dataset.astype(float)\ndataset.info()\ncorrelation=dataset.corr()","9c2c84c4":"correlation.Outcome.sort_values()","017831e4":"# Inputs and Target\nx_train=dataset[dataset.columns[1:]]\ny_train=dataset['Outcome']","adacf859":"import statsmodels.api as sm\nlista=['const','var_Glucose','var_Age','var_BMI','var_DiabetesPedigreeFunction','var_Pregnancies','var_SkinThickness']\nx_train=sm.add_constant(x_train)\nx_train=x_train[lista]\n\n# Building the model and fitting the data\nlogit= sm.Logit(y_train,x_train)\nlog_reg = logit.fit()\n\n# Printing the summary table\nprint(log_reg.summary())","11128fba":"data=pd.DataFrame(log_reg.predict(x_train),columns=['prob'])\ndata['y']= y_train\n\ndata.prob[(data.y==1)].plot.density(color='green',grid=True)\nplt.title('Density Plot for Tip')\n\ndata.prob[(data.y==0)].plot.density(color='red',grid=True)\nplt.title('Density Plot for Tip')\nplt.show()","4cd1e6b1":"lista=[]\nfor i in range(1000):\n    data['y_pred']=data['prob'].map(lambda x: 0 if (x<i*0.001) else 1)\n    accuracy_score=metrics.accuracy_score(data.y,data.y_pred)\n    lista.append([i,accuracy_score])\nresult=pd.DataFrame(lista,columns=['Step','Accurary'])\nax=result['Accurary'].plot(grid=True)\nax.set_xlabel(\"Step\")\nax.set_ylabel(\"Accurary\")\nresult[result.Accurary==result.Accurary.max()]\noptimo=result[result.Accurary==result.Accurary.max()].Step.values[0]\nresult.Accurary.max()","693932b0":"# Results: precision & recall\ndata['y_pred']=data['prob'].map(lambda x: 0 if (x<=0.001*optimo) else 1)\nprint(classification_report(y_train, data.y_pred))","008274b8":"from sklearn.model_selection import GridSearchCV\nimport xgboost as xgb\nfrom xgboost import plot_importance\n\n# Algorithm and Hyperparameters\ngrid_params = {\n    \"objective\": ['binary:logistic'],\n    \"eval_metric\":['logloss'],\n    \"learning_rate\": [0.01],\n    \"max_depth\":[5],\n    \"subsample\":[0.5],\n    \"n_estimators\": [1500]}\n\n\nobject=GridSearchCV(estimator = xgb.XGBClassifier(), param_grid = grid_params, scoring = 'accuracy', cv = 5, n_jobs = -1)\nobject.fit(x_train, y_train)\noptimo=object.best_params_\noptimo","ebf68ce3":"# Definitive model\nclf=xgb.XGBClassifier(**optimo) \nmodel=clf.fit(x_train,y_train)\ny_pred=model.predict(x_train)","4ff5f22f":"# Confusion matrix\nfrom sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(model, x_train, y_train)  \nplt.show()","66d43ae0":"# Results: precision & recall\nprint(classification_report(y_train, y_pred))","7ab43023":"data=pd.DataFrame(model.predict_proba(x_train),columns=['prob0','prob1'])\ndata['y']= y_train\n\ndata.prob1[(data.y==1)].plot.density(color='green',grid=True)\nplt.title('Density Plot for Tip')\n\ndata.prob1[(data.y==0)].plot.density(color='red',grid=True)\nplt.title('Density Plot for Tip')\nplt.show()","f0d1f271":"metrics.accuracy_score(y_train,y_pred)","82a6628f":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\nkfold = KFold(n_splits = 10, random_state = 12345)\ncv_results = cross_val_score(model, x_train, y_train, cv = 10, scoring= \"accuracy\")\nresults=cv_results\nmsg = \"%s: %f\" % (cv_results.mean(), cv_results.std())\nprint(msg)\n        \n# boxplot algorithm comparison\nfig = plt.figure(figsize=(15,10))\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nplt.show()","d094113b":"**Probit - Model 1**","3ae2ea50":"**GBM - Model 2**"}}