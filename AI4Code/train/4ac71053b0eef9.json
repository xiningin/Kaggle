{"cell_type":{"d4343a2f":"code","28846d7a":"code","51fdc605":"code","1de124fa":"code","26ce0de3":"code","174f9b6d":"code","bb61acfc":"code","8081521e":"code","9020bff2":"code","a287e66a":"code","efbfe1a7":"code","af401904":"code","5952d1e5":"code","30c19fce":"code","42266962":"code","6eb9bca3":"code","f2d3a12d":"code","9bd9ee45":"code","cd140916":"code","530e1070":"code","810f25ea":"code","cb2282e6":"code","fb76e611":"code","73aca15e":"code","c9cabdc6":"code","c802db98":"code","bf4c10a4":"code","e8bf1432":"code","eeb1a5e3":"code","732a481a":"code","cec4c50b":"code","1ac5b623":"code","ecfe7031":"code","49c0b443":"code","c4ee3e87":"code","14c7a830":"code","f759fac0":"code","6b3c34c5":"code","7293d43c":"code","028789d2":"code","a329e7db":"code","15a88230":"code","41650a21":"code","ec3bcd4e":"code","858abc93":"code","d89f0776":"markdown","84b6685d":"markdown","3fc95a31":"markdown","e40d0ff4":"markdown","a2d178b1":"markdown","9d65d995":"markdown","6d852ef9":"markdown","42640f85":"markdown","f71186cd":"markdown","8b441689":"markdown","fa14401a":"markdown","460bd9bd":"markdown","984972cc":"markdown"},"source":{"d4343a2f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import confusion_matrix,mean_squared_error,accuracy_score\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split# Any results you write to the current directory are saved as output.","28846d7a":"df=pd.read_csv(\"\/kaggle\/input\/heart-disease-uci\/heart.csv\")","51fdc605":"df.columns=['age','gender','paintype','bp','cholestoral','blood_sugar','electrocardiographic_results','max_heartrate','angina','oldpeak','slope','no_of_vessels','thal','target']","1de124fa":"df['slope'].value_counts()","26ce0de3":"df.head(10)","174f9b6d":"df.dtypes","bb61acfc":"df.isnull().sum()","8081521e":"sns.countplot(x='target', data=df)","9020bff2":"df['target'].value_counts()","a287e66a":"sns.countplot(x='gender', data=df)","efbfe1a7":"df['gender'].value_counts()","af401904":"sns.countplot(x='paintype', data=df)","5952d1e5":"df['paintype'].value_counts()","30c19fce":"sns.countplot(x='thal', data=df)","42266962":"df['thal'].value_counts()","6eb9bca3":"sns.countplot(x='slope', data=df)","f2d3a12d":"df['slope'].value_counts()","9bd9ee45":"df.groupby(['gender', 'target']).size().reset_index().pivot(columns='target', index='gender', values=0).plot(kind='bar', stacked=True)","cd140916":"sns.scatterplot(x=\"bp\", y=\"max_heartrate\", data=df)","530e1070":"ax=sns.scatterplot(x=\"cholestoral\", y=\"max_heartrate\", data=df)\nax.set(xticks=np.arange(0, 500, 200),\n      yticks=np.arange(100, 300, 100))","810f25ea":"sns.scatterplot(x=\"bp\", y=\"cholestoral\", data=df)","cb2282e6":"a = pd.get_dummies(df['paintype'], prefix = \"paintype\")\nb = pd.get_dummies(df['thal'], prefix = \"thal\")\nc = pd.get_dummies(df['slope'], prefix = \"slope\")\nframes = [df, a, b, c]\ndf = pd.concat(frames, axis = 1)\ndf.head()\ndf = df.drop(columns = ['paintype', 'thal', 'slope'])\ndf.head()","fb76e611":"X = df.copy().drop(\"target\",axis=1)\ny = df[\"target\"]\n\n## Split the data into trainx, testx, trainy, testy with test_size = 0.20 using sklearn\ntrainx, testx, trainy, testy = train_test_split(X, y, test_size=0.20)\n\n## Print the shape of X_train, X_test, y_train, y_test\nprint(trainx.shape)\nprint(testx.shape)\nprint(trainy.shape)\nprint(testy.shape)","73aca15e":"from sklearn.preprocessing import StandardScaler\n\n## Scale the numeric attributes\nscaler = StandardScaler()\nscaler.fit(trainx.iloc[:,:5])\n\ntrainx.iloc[:,:5] = scaler.transform(trainx.iloc[:,:5])\ntestx.iloc[:,:5] = scaler.transform(testx.iloc[:,:5])","c9cabdc6":"ax=sns.scatterplot(x=\"cholestoral\", y=\"max_heartrate\", data=trainx)","c802db98":"X = trainx\ny = trainy\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score \nmodel = LogisticRegression()\nmodel.fit(X , y)\npredicted_classes = model.predict(X)\naccuracy = accuracy_score(y,predicted_classes)\nparameters = model.coef_","bf4c10a4":"print(accuracy)\nprint(parameters)\nprint(model)","e8bf1432":"predicted_classes_test = model.predict(testx)\naccuracy = accuracy_score(testy,predicted_classes_test)\nprint(accuracy)","eeb1a5e3":"from sklearn.metrics import confusion_matrix\ndata = confusion_matrix(testy,predicted_classes_test)\ndf_cm = pd.DataFrame(data, columns=np.unique(testy), index = np.unique(predicted_classes_test))\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\nplt.figure(figsize = (10,7))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 15})# font size","732a481a":"tp=data[1][1]\ntn=data[0][0]\nfp=data[0][1]\nfn=data[1][0]\nprint('tp=',tp)\nprint('tn=',tn)\nprint('fp=',fp)\nprint('fn=',fn)","cec4c50b":"print('recall=',tp\/(tp+fn))\nprint('precision=',tp\/(tp+fp))\nprint('accuracy=',(tp+tn)\/(tp+tn+fp+fn))","1ac5b623":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier()\nprint(rfc)","ecfe7031":"rfc.fit(trainx,trainy)\n## Predict\nrfc_train_predictions = rfc.predict(trainx)\nrfc_test_predictions = rfc.predict(testx)\n\n### Train data accuracy\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(trainy,rfc_train_predictions))\n      \n### Test data accuracy\nprint(accuracy_score(testy,rfc_test_predictions))","49c0b443":"data = confusion_matrix(testy,rfc_test_predictions)\ndf_cm = pd.DataFrame(data, columns=np.unique(testy), index = np.unique(rfc_test_predictions))\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\nplt.figure(figsize = (10,7))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 15})# font size","c4ee3e87":"tp=data[1][1]\ntn=data[0][0]\nfp=data[0][1]\nfn=data[1][0]\nprint('tp=',tp)\nprint('tn=',tn)\nprint('fp=',fp)\nprint('fn=',fn)","14c7a830":"print('recall=',tp\/(tp+fn))\nprint('precision=',tp\/(tp+fp))\nprint('accuracy=',(tp+tn)\/(tp+tn+fp+fn))","f759fac0":"from sklearn.naive_bayes import GaussianNB\n\nNB = GaussianNB()\n\nNB.fit(X , y)\n\nNB_train_pred = NB.predict(X)\nprint(accuracy_score(y,NB_train_pred))\n\nNB_test_pred = NB.predict(testx)\nprint(accuracy_score(testy,NB_test_pred))","6b3c34c5":"data = confusion_matrix(testy,NB_test_pred)\ndf_cm = pd.DataFrame(data, columns=np.unique(testy), index = np.unique(NB_test_pred))\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\nplt.figure(figsize = (10,7))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 15})# font size","7293d43c":"tp=data[1][1]\ntn=data[0][0]\nfp=data[0][1]\nfn=data[1][0]\nprint('tp=',tp)\nprint('tn=',tn)\nprint('fp=',fp)\nprint('fn=',fn)","028789d2":"print('recall=',tp\/(tp+fn))\nprint('precision=',tp\/(tp+fp))\nprint('accuracy=',(tp+tn)\/(tp+tn+fp+fn))","a329e7db":"knn_classifier = KNeighborsClassifier(algorithm='brute',weights='distance')\nparams = {'n_neighbors':[1,11,25],'metric':[\"euclidean\",'cityblock']}\ngrid = GridSearchCV(knn_classifier,param_grid=params,scoring='accuracy',cv=10)\ngrid.fit(trainx,trainy)\nprint(grid.best_score_)\nprint(grid.best_params_)","15a88230":"best_knn = grid.best_estimator_\npred_train = best_knn.predict(trainx) \npred_test = best_knn.predict(testx)\nprint(\"Accuracy on train is:\",accuracy_score(trainy,pred_train))\nprint(\"Accuracy on test is:\",accuracy_score(testy,pred_test))","41650a21":"data = confusion_matrix(testy,pred_test)\ndf_cm = pd.DataFrame(data, columns=np.unique(testy), index = np.unique(pred_test))\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\nplt.figure(figsize = (10,7))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 15})# font size","ec3bcd4e":"tp=data[1][1]\ntn=data[0][0]\nfp=data[0][1]\nfn=data[1][0]\nprint('tp=',tp)\nprint('tn=',tn)\nprint('fp=',fp)\nprint('fn=',fn)","858abc93":"print('recall=',tp\/(tp+fn))\nprint('precision=',tp\/(tp+fp))\nprint('accuracy=',(tp+tn)\/(tp+tn+fp+fn))","d89f0776":"**Reading the dataset**","84b6685d":"splitting the dataframe into traint and test","3fc95a31":"*univariate analysis*","e40d0ff4":"**Naive Bayes**","a2d178b1":"**Data types**","9d65d995":"**KNN Classifier**","6d852ef9":"scaling numeric features","42640f85":"*bivariate analysis*","f71186cd":"**importing the libraries**","8b441689":"converting categorical columns to dummies","fa14401a":"**Random forest**","460bd9bd":"**Exploring the data**","984972cc":"**Logistic Regression**"}}