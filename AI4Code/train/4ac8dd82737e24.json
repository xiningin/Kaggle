{"cell_type":{"c521231e":"code","2b72f8c4":"code","caf6dba4":"code","1636fef0":"code","4d6246d6":"code","daf25312":"code","1558e739":"code","e26f0d76":"code","a649cb54":"code","c4103b43":"code","f7bdb7e0":"code","49648403":"code","1fe51157":"code","cdaa069d":"code","89ad8409":"code","bcbd1aa3":"code","103afa1c":"code","c5df3abe":"code","49f52e20":"code","30d8230f":"code","bd9d83d5":"code","d5fb0166":"code","95977c9e":"code","18ec5491":"code","bdc7dce8":"code","0f9d39a6":"code","e48d721c":"code","b13e6bac":"code","83efc74a":"code","57748905":"code","44de6abf":"code","39881baf":"code","767bef9d":"code","3ce6bc22":"code","3a4fc9a8":"code","c20dc139":"code","0e689117":"code","70cb511f":"code","c65d44d3":"code","0fc7ff91":"code","97b71145":"code","6f6f5683":"code","91e9213f":"code","01df5c62":"code","1f7a4b92":"code","c2e46310":"code","264c7fc3":"code","89758f04":"code","28fc6715":"code","9286e6d5":"code","108fdee7":"code","02101ba9":"code","4a9f3185":"code","df0edbdf":"code","898b0041":"code","ed8c4725":"code","8574b17c":"code","33a387a4":"code","e55ac14d":"code","45f90972":"code","cfdeaeb7":"code","14f9b5a5":"code","7a2966b6":"code","c0ad4e76":"code","04dc2ed7":"code","f8bc3307":"code","10f4015b":"code","5ff87f18":"code","b0fdb473":"code","d484670d":"code","ff69da84":"code","aedb675c":"code","c1073cef":"code","a7de93d4":"code","d8f8a19e":"code","61064e07":"code","7a40a55c":"code","19a5c18e":"code","ced1e49c":"code","e5dbee11":"code","28e47fbb":"code","d3bfbaea":"code","32b1c6d9":"code","2a86ebd5":"code","016c9015":"code","436879d4":"code","7e847c26":"code","d42a1039":"code","e354c180":"code","a88bca15":"code","bd8105db":"code","ae765269":"code","5fe57007":"code","f4efd818":"code","f6619a60":"code","99f1c8f9":"code","1751cb8f":"code","fcc76184":"code","2dc7a1dc":"code","2a0f5942":"code","ccff63bb":"markdown","008d50f8":"markdown","89dfa598":"markdown","ec52dc86":"markdown","0bcacaca":"markdown","be5feed8":"markdown","4b521b75":"markdown","f2c642ac":"markdown","2e07450f":"markdown","d275750e":"markdown","7c24f96e":"markdown","a399f9d8":"markdown","ed0f5dd8":"markdown","43efced1":"markdown","8f97b24a":"markdown","ecc1cdeb":"markdown","87a4415e":"markdown","567e4bea":"markdown","16c85581":"markdown","97986fa9":"markdown","84c8a878":"markdown","810b1930":"markdown","4d2f4428":"markdown","4af7a88a":"markdown","00b1e67b":"markdown","91baeb11":"markdown","76151f4e":"markdown","f3179928":"markdown","3ad90c60":"markdown","a7b4c8cc":"markdown","9dcc22fe":"markdown","844d1171":"markdown","711d47db":"markdown","d2b42ab0":"markdown","9f79b8d4":"markdown","1d88662b":"markdown","d8a78277":"markdown","93ddcba8":"markdown","309803a8":"markdown","24766077":"markdown","31f58002":"markdown","68769452":"markdown","b733c081":"markdown","149ea095":"markdown","33d688bc":"markdown","2f41b375":"markdown","1db3446b":"markdown","6be41bd2":"markdown","d5d5da89":"markdown","e7ad8dcf":"markdown","a7e63dcf":"markdown","3b1d1474":"markdown","0219a056":"markdown","c1e95a80":"markdown","07391ac4":"markdown","70daf5ad":"markdown","de2bd935":"markdown","e7759238":"markdown","97c17dbf":"markdown","788417f1":"markdown","81903d8d":"markdown","b863efe3":"markdown","2faceb1a":"markdown","6c19b661":"markdown","8cfdcd38":"markdown","cd0a6516":"markdown","5822a707":"markdown","e4e79b6c":"markdown","f7b79d94":"markdown","a9e402b0":"markdown","045f64a5":"markdown","0d134ccd":"markdown","d7b4fc8d":"markdown","46f6591b":"markdown","df8f294d":"markdown","cb829a15":"markdown","5ab44231":"markdown","eaf0d3fb":"markdown","bef58736":"markdown","cb93b22e":"markdown","7f25d2d0":"markdown","83ebc8e5":"markdown","b96386e7":"markdown","796c571b":"markdown","f04abb16":"markdown","d728ba0f":"markdown","e315b11e":"markdown","b5098859":"markdown","26ee1af9":"markdown","45fa3ae6":"markdown","3974333b":"markdown"},"source":{"c521231e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(rc={'figure.figsize':(15,10)})","2b72f8c4":"import warnings\nwarnings.filterwarnings('ignore')","caf6dba4":"import statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","1636fef0":"import sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.feature_selection import RFE","4d6246d6":"import datetime\nfrom scipy.stats import pearsonr","daf25312":"day = pd.read_csv('..\/input\/bike-sharing\/day.csv', index_col='instant')","1558e739":"data_import_shape = day.shape\ndata_import_shape","e26f0d76":"day.head()","a649cb54":"day.info()","c4103b43":"def bar_graph_plot_function(data, graph_title, x_axis_label, y_axis_label, data_label='horizontal', x_label_rotation=0, x_text=None):\n    population_graph = sns.barplot(x=data.index, y=data.values)\n    label_deviation_above_y_axis = data.max() * 0.015\n    for index, value in enumerate(data.iteritems()):\n        population_graph.text(index, value[1] + label_deviation_above_y_axis, round(value[1], 2), color='black', ha=\"center\", rotation=data_label)       \n    if x_text is None:\n        population_graph.set_xticklabels(population_graph.get_xticklabels(), rotation=x_label_rotation)\n    else:\n        population_graph.set_xticklabels(x_text, rotation=x_label_rotation)\n    plt.title(graph_title, fontdict={'fontsize': 20})\n    plt.xlabel(x_axis_label)\n    plt.ylabel(y_axis_label)\n    plt.show()","f7bdb7e0":"day['dteday'].describe()","49648403":"day['dteday'].apply(lambda x: int(x.split('-')[0])).describe()","1fe51157":"day['dteday'].apply(lambda x: int(x.split('-')[1])).describe()","cdaa069d":"day['dteday'].apply(lambda x: int(x.split('-')[2])).describe()","89ad8409":"day['dteday'] = day['dteday'].apply(lambda x: int(x.split('-')[0]))","bcbd1aa3":"day = day.rename(columns={\"dteday\": \"date\"})","103afa1c":"date_dist = round(day.groupby(by='date').cnt.mean()\/1000, 2)","c5df3abe":"bar_graph_plot_function(data=date_dist, graph_title='Average Ride Count VS Date', x_axis_label='Date',\n                        y_axis_label='Ride Count (In Thousand)', data_label='vertical', x_label_rotation=0)","49f52e20":"day.season.describe()","30d8230f":"day['season'] = day['season'].map({1: 'spring', 2: 'summer', 3: 'fall', 4: 'winter'})","bd9d83d5":"season_dist = day.groupby(by='season').cnt.mean().sort_values()","d5fb0166":"bar_graph_plot_function(data=season_dist, graph_title='Average Ride Count Vs. Season', x_axis_label='Season',\n                        y_axis_label='Ride Count', data_label='horizontal', x_label_rotation=0)","95977c9e":"day.yr.describe()","18ec5491":"year_dist = day.groupby(by='yr').cnt.mean()","bdc7dce8":"bar_graph_plot_function(data=year_dist, graph_title='Average Ride Count Vs. Year', x_axis_label='Year',\n                        y_axis_label='Ride Count', data_label='horizontal', x_label_rotation=0,\n                        x_text=['2018', '2019'])","0f9d39a6":"day.mnth.describe()","e48d721c":"month_dist = day.groupby(by='mnth').cnt.mean()","b13e6bac":"bar_graph_plot_function(data=month_dist, graph_title='Average Ride Count Vs. Month', x_axis_label='Month',\n                        y_axis_label='Ride Count', data_label='horizontal', x_label_rotation=0, \n                        x_text=[datetime.date(1900, i , 1).strftime('%B') for i in range(1, 13)])","83efc74a":"day.mnth = day.mnth.apply(lambda x: datetime.date(1900, x , 1).strftime('%B'))","57748905":"day.holiday.describe()","44de6abf":"holiday_dist = day.groupby(by='holiday').cnt.mean()","39881baf":"bar_graph_plot_function(data=holiday_dist, graph_title='Average Ride Count Vs. Holiday\/WorkDay', x_axis_label='Holiday\/Workday',\n                        y_axis_label='Ride Count', data_label='horizontal', x_label_rotation=0, \n                        x_text=['Holiday', 'Not Holiday'])","767bef9d":"day.weekday.describe()","3ce6bc22":"day.groupby(by='weekday').weekday.count()","3a4fc9a8":"weekday_dist = day.groupby(by='weekday').cnt.mean()","c20dc139":"bar_graph_plot_function(data=weekday_dist, graph_title='Average Ride Count Vs. Weekday', x_axis_label='Weekday',\n                        y_axis_label='Ride Count', data_label='horizontal', x_label_rotation=0, \n                        x_text=['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'])","0e689117":"day['weekday'] = day.weekday.map({0: 'sunday', 1: 'monday', 2: 'tuesday', 3: 'wednesday', 4: 'thursday', 5: 'friday', 6: 'saturday'})","70cb511f":"day.groupby(by='weekday').weekday.count()","c65d44d3":"day.workingday.describe()","0fc7ff91":"day.groupby(by='workingday').workingday.count()","97b71145":"workingday_dist = day.groupby(by='workingday').cnt.mean()","6f6f5683":"bar_graph_plot_function(data=workingday_dist, graph_title='Average Ride Count Vs. Workday', x_axis_label='Workday',\n                        y_axis_label='Ride Count', data_label='horizontal', x_label_rotation=0, \n                        x_text=['Either Weekend \/ Holiday', 'Working Day'])","91e9213f":"day.weathersit.describe()","01df5c62":"day.groupby(by='weathersit').weathersit.count().sort_values(ascending=False)","1f7a4b92":"day['weathersit'] = day.weathersit.map({1: 'clear', 2: 'mist', 3: 'light', 4: 'heavy'})","c2e46310":"day.groupby(by='weathersit').weathersit.count().sort_values(ascending=False)","264c7fc3":"weathersit_dist = day.groupby(by='weathersit').cnt.mean()","89758f04":"bar_graph_plot_function(data=weathersit_dist, graph_title='Average Ride Count Vs. Weather', x_axis_label='Weather',\n                        y_axis_label='Ride Count', data_label='horizontal', x_label_rotation=0)","28fc6715":"headers = ['Temperature', 'Adjusted Temperature']\npd.DataFrame(np.corrcoef(day['temp'], day[\"atemp\"]), index=headers, columns=headers)  ","9286e6d5":"day = day.drop(columns=['atemp'])","108fdee7":"day.temp.describe()","02101ba9":"plt.figure(figsize=(15, 5))\nsns.boxplot(data=day, x='temp')\nplt.title('Temperature Box Plot', fontdict={'fontsize': 20})\nplt.xlabel('Temperature', fontdict={'fontsize': 15})","4a9f3185":"day.hum.describe()","df0edbdf":"plt.figure(figsize=(15, 5))\nsns.boxplot(data=day, x='hum')\nplt.title('Humidity Box Plot', fontdict={'fontsize': 20})\nplt.xlabel('Humidity', fontdict={'fontsize': 15})","898b0041":"day[day['hum'] == 0]","ed8c4725":"humidity_check_df = day[(day.index > int(69*0.8)) & (day.index < int(69*1.2))]\nhumidity_check_df","8574b17c":"graph = sns.barplot(y=humidity_check_df.hum, x=humidity_check_df.index)\nplt.title('Humidity Plot Around the Zero Value', fontdict={'fontsize': 20})\nplt.xlabel('Index', fontdict={'fontsize': 15})\nplt.ylabel('Humidity', fontdict={'fontsize': 15})\ncounter = 0\nfor index, row in humidity_check_df.iterrows():\n    graph.text(counter, row.hum*1.01, round(row.hum, 2), color='black', ha=\"center\")\n    counter+=1\nplt.show()","33a387a4":"mean_value = humidity_check_df.hum.mean()\nmean_value","e55ac14d":"day.at[int(day[day['hum'] == 0.0].hum.index.values), \"hum\"] = mean_value","45f90972":"day[day.hum < 10]","cfdeaeb7":"humidity_check_post_df = day[(day.index > int(69*0.8)) & (day.index < int(69*1.2))]\nhumidity_check_post_df","14f9b5a5":"day.windspeed.describe()","7a2966b6":"day = day.drop(columns=['casual', 'registered'])","c0ad4e76":"plot_data = pd.read_csv('..\/input\/bike-sharing\/day.csv', index_col='instant')","04dc2ed7":"plot_data['dteday'] = plot_data['dteday'].apply(lambda x: int(x.split('-')[0]))\nplot_data = plot_data.rename(columns={\"dteday\": \"date\"})\nplot_data['yr'] = plot_data['yr'].map({0: 2018, 1:2019})\nplot_data = plot_data.drop(columns=['atemp', 'casual', 'registered'])\nplot_data.at[int(plot_data[plot_data['hum'] == 0.0].hum.index.values), \"hum\"] = mean_value","f8bc3307":"plot_data.head(17)","10f4015b":"sns.pairplot(plot_data)\nplt.figure(figsize=[40,30])","5ff87f18":"dummy_variables_columns = ['mnth', 'season', 'weekday', 'weathersit']","b0fdb473":"status = pd.get_dummies(day[dummy_variables_columns], drop_first=True)\nstatus.head()","d484670d":"day = pd.concat([day, status], axis=1)","ff69da84":"day = day.drop(columns=dummy_variables_columns)","aedb675c":"df_train, df_test = train_test_split(day, train_size=0.7, random_state=100)","c1073cef":"df_train.shape","a7de93d4":"df_test.shape","d8f8a19e":"numerical_variables = ['date', 'temp', 'hum', 'windspeed', 'cnt']","61064e07":"scaler = MinMaxScaler()","7a40a55c":"df_train[numerical_variables] = scaler.fit_transform(df_train[numerical_variables])\ndf_train.head()","19a5c18e":"df_train.corr()\nplt.figure(figsize=(16, 10))\nsns.heatmap(round(df_train.corr(), 1), annot=True, cmap='Greens')\nplt.show()","ced1e49c":"y_train = df_train.pop('cnt')","e5dbee11":"X_train = df_train","28e47fbb":"def general(local_df):\n    vif_df = pd.DataFrame()\n    vif_df['Features'] = local_df.columns\n    vif_df['VIF'] = [variance_inflation_factor(local_df.values, i) for i in range(local_df.shape[1])]\n    vif_df['VIF'] = round(vif_df['VIF'], 2)\n    vif_df = vif_df.sort_values(by='VIF', ascending=False)\n    vif_df = vif_df.reset_index(drop=True)\n    return vif_df","d3bfbaea":"lm = LinearRegression()\nlm.fit(X_train, y_train)\nrfe = RFE(lm, 15)\nrfe = rfe.fit(X_train, y_train)","32b1c6d9":"rfe_df = pd.DataFrame({'Predictor': X_train.columns, 'Select Status': rfe.support_, 'Ranking': rfe.ranking_})\nrfe_df.sort_values(by='Ranking')","2a86ebd5":"col = X_train.columns[rfe.support_]\nprint(col)\nX_train_rfe = X_train[col]\nX_train_sm = sm.add_constant(X_train_rfe)\nlr = sm.OLS(y_train, X_train_sm)\nlr_model = lr.fit()\nlr_model.summary()","016c9015":"general(X_train_rfe)","436879d4":"col = col.drop(['hum'])\n\nX_train_rfe = X_train[col]\nX_train_sm = sm.add_constant(X_train_rfe)\nlr = sm.OLS(y_train, X_train_sm)\nlr_model = lr.fit()\nlr_model.summary()","7e847c26":"general(X_train_rfe)","d42a1039":"y_train_pred = lr_model.predict(X_train_sm)\nresidual = y_train_pred - y_train\nsns.distplot(residual)\nplt.xlabel('Residual (Error Term)', fontdict={'fontsize': 20})\nplt.title('Error Distribution', fontdict={'fontsize': 25})\nplt.show()","e354c180":"sns.regplot(x=y_train_pred, y=residual)\nplt.title('Residual Vs. Predicted Values (Pattern Indentification)', fontdict={'fontsize': 20})\nplt.xlabel('Predicted Values', fontdict={'fontsize': 15})\nplt.ylabel('Residuals', fontdict={'fontsize': 15})\nplt.show()","a88bca15":"print(\"Pearson Value for Predicted Value Against Residual ==>\", pearsonr(y_train_pred, residual)[0])","bd8105db":"sns.regplot(x=y_train, y=y_train_pred)\nplt.title('Predicted Points Vs. Actual Points', fontdict={'fontsize': 20})\nplt.xlabel('Actual Points', fontdict={'fontsize': 15})\nplt.ylabel('Predicted Points', fontdict={'fontsize': 15})\nplt.show()","ae765269":"general(X_train_rfe)","5fe57007":"corr_dict = {index: round(pearsonr(y_train, X_train_rfe[index])[0], 2) for index in X_train_rfe.columns}\ncorr_df = pd.DataFrame(corr_dict.values(), index=corr_dict.keys(), columns=['Correlation_Coefficient'])\ncorr_df.iloc[(-corr_df['Correlation_Coefficient'].abs()).argsort()]","f4efd818":"df_test[numerical_variables] = scaler.transform(df_test[numerical_variables])\ndf_test.head()","f6619a60":"y_test = df_test.pop('cnt')","99f1c8f9":"X_test = df_test","1751cb8f":"X_test_new = X_test[X_train_rfe.columns]\nX_test_new = sm.add_constant(X_test_new)","fcc76184":"y_pred = lr_model.predict(X_test_new)","2dc7a1dc":"corr_plot = sns.regplot(x=y_test, y=y_pred)\nplt.title('Predicted Test Points Vs. Actual Test Points', fontdict={'fontsize': 20})\nplt.xlabel('Actual Test Points', fontdict={'fontsize': 15})\nplt.ylabel('Predicted Test Points', fontdict={'fontsize': 15})\nplt.show()","2a0f5942":"from sklearn.metrics import r2_score\nr2_score(y_test, y_pred)","ccff63bb":"**11.2. Fixing Test Feature(s) Variable**","008d50f8":"We see that, Ride Count has increases comparatively in 2019 as compared to 2018. This can also be decisive factor for predicting target (output).","89dfa598":"In the above model we see that P-Value of \"Holiday\" feature is more than 0.05, which make its co-efficient insignificant.\n\nSo, we will proceed ahead with dropping this feature and designing model again.\n\n**9.3. Model Building Process - 2**\n\nDropping humidity feature and designing model again.","ec52dc86":"**10.2. Assumption of Error Terms Being Independent**","0bcacaca":"Wind speed seems to be in legitimate range, hence we can proceed ahead with this column without dropping \/ changing any records.\n\n**3.12 Casual, Registered Count & Total Count.**\n\nOur aim for this assignment is to predict the final count (irrespective of casual & registered count)\nAs these columns are not required, we will go ahead dropping these.","be5feed8":"Season column is varied between 1 to 4 which are properly defined in data dictionary, hence we can proceed ahead with this column without dropping \/ changing any records.\n\nSeason column is categorical column with each value corresponding to specific season.\n\nWe need to map these numbers to respectie seasons, so that these column values will be further used to generate dummy variable as it is a Categorical Nominal Type Data.\n\nWe should map this column as follows:\n\n* spring\n* summer\n* fall\n* winter","4b521b75":"Let's plot distrubution of Ride Count Mean Across the days of weeks (Ex. Sunday, Monday etc.)","f2c642ac":"# 1. Importing Libraries\n\n**1.1. Importing Required Libraries**","2e07450f":"**3.2. Season**","d275750e":"Evaluating Correlation Co-efficients of Predictors Impacting Target Variable (Individually)","7c24f96e":"# 8. Defining Target & Feature Variables for Iterative Modelling Process\n**8.1. Fixing Trained Target Variable**","a399f9d8":"**11.1. Fixing Test Target Variable**","ed0f5dd8":"From the above graph, we see that there is almost no relation between Residual & Predicted Value. This is what we had expected from our model to have no specific pattern.","43efced1":"We see that, distribution is quite different for respective seasons. This might act as a decisive factor.","8f97b24a":"Weekday column is varied between 1 and 6 which are properly defined in data dictionary, hence we can proceed ahead with this column without dropping \/ changing any records","ecc1cdeb":"# 7. Manual Analysis of Variable (using Correlaion-Co-efficient)","87a4415e":"# 5. Data Splitting\nHere, we will split the data into 2 parts.\n* Train Data (On which model will be build and is almost 70% of total data)\n* Test Data (On which build model will be tested and is almost 30% of total data)","567e4bea":"**11.4 Predicting Test Data Using Developed Model**","16c85581":"Following are the few assumptions that can hold up from the pairplot with respect to Count as Target Variable:\n\n* Date Column seems to be scattered evenly across all the points. Unable to make out any pattern when predicting Ride Count from the Date column alone.\n* Ride Count Seems to be in maximum in Fall (Autumn) followed by Summer, Spring & Winter respectively.\n* Ride Count has increased drastically in 2019 as compared to 2018\n* Ride Count seems to increase between May to October which are comparatively Fall(Autumn) & Summer Season in US\n* Ride Count is lesser on Holidays as compared to other days.\n* Working Day \/ Non-Working Day shows almost similar behaviour (after just visualising the data)\n* Ride Count is more on Clear & Misty Days as compared to Light Snow \/ Rainfall\n* Ride Count seems to be very much linearly dependent on Temperature\n* Humidity & windspeed does not indicate any specific behaviour on just visualising the data.","97986fa9":"From the above Correlation Coefficient Heatmap, we see that no variable is highly correlated with another variable in any way. So, we can further proceed and check Multi-Collinearity while creating models itself.","84c8a878":"Let's plot distrubution of Ride Count Mean Across all the Seasons","810b1930":"**3.5 Holiday**","4d2f4428":"Holiday column is varied between 0 and 1 which are properly defined in data dictionary, hence we can proceed ahead with this column without dropping \/ changing any records.\n\n\nLet's plot distrubution of Ride Count Mean Across the days which are counted either as holidays or working day","4af7a88a":"**3.13 Pair-plot**\n\nWe will create a Pairplot to get an overal gist of the entire data set.\n\nBut, since many of the columns are alredy mapped to some category, we will import the csv file again and do a few altercations confined to pair-plot graph only.","00b1e67b":"Let's plot distrubution of Ride Count Mean Across all the days.","91baeb11":"We see that there is high correlation that appears between Temperature & Adjusted Temperature by just visualising the columns.","76151f4e":"Working Day column is varied between 0 and 1 which are properly defined in data dictionary, hence we can proceed ahead with this column without dropping \/ changing any records.","f3179928":"**1.4. Importing Scikit Library for evaluating requirement\nspecific parameters and performing preprocessing\nsteps (like Splitting & Scaling)**","3ad90c60":"We will check if any of the month range is outside certain limit.","a7b4c8cc":"**11.3 Filtering Test Input (& Reserving Required Features Only)**","9dcc22fe":"Weather Situation column is varied between 1 to 3 which are properly defined in data dictionary, hence we can proceed ahead with this column without dropping \/ changing any records.","844d1171":"So, we have adjusted the zero (or missing) value of Humidity successfully.","711d47db":"Validating if the imputed value is present or not?","d2b42ab0":"On analysing date column we can see that all the attributes of date except for day are comfortably covered under month & year column.\n\nSo, we will extract only the date part from this column and use it.","9f79b8d4":"**3.4 Month**","1d88662b":"# 9. Iterative Modeling Process\n\nCurrently, we have almost 30 Predictors to Predict our outcome. Analysing these many predictors can be very hectic.\n\nTo simplify this process, we will use RFE (Recursive Feature Elimination) method to which will provide us with set of variables ranked in an order of importance (of impacting outcome).\n\nWe will pass an arbitary number (here 15), which means the method will rank first 15 predictors as 1 & remaining as 0.\n\nCreating a generalised function for evaluating Variance Inflation Factor.","d8a78277":"**2.2. Printing CSV Data shape**","93ddcba8":"To check if this a typo or invalid data from source, we will pick 20% of values prior to specific date & 20% of values after the specific date and generate a plot to check the behaviour.","309803a8":"RFE method has successfully evaluated top 15 predictors which will impact our outcome.\n\nBut, we will not rely on this enitirely and continue validating this 15 features manually by building model one by one and elimating any feature which does not satisfy our requirements.\n\n**9.2. Model Building Process - 1**","24766077":"Year column is varied between 0 and 1 which are properly defined in data dictionary, hence we can proceed ahead with this column without dropping \/ changing any records.\nYear column consist of 2 values with 0 corresponding to 2018 & 1 corresponding to 2019.\nWe will keep this values as it is, because normalising column consisting of only 0 & 1 will have no effect.\n\nLet's plot distrubution of Ride Count Mean Year-Wise.","31f58002":"Working Day is a Categorical Nomimal Variable. But there are only 2 values, \"Yes\" or \"No\" mapped to \"1\" & \"0\" respectively.\nSo, we will leave this as it is.\n\nLet's plot distrubution of Ride Count Mean Across the days which are working days or not.","68769452":"Holiday is a Categorical Nomimal Variable. But there are only 2 values, \"Yes\" or \"No\" mapped to \"1\" & \"0\" respectively.\nSo, we will leave this as it is.","b733c081":"Temperature column is varied between a range which seems to be valid range, hence we can proceed ahead with this column without dropping \/ changing any records.","149ea095":"Month column is varied between 1 and 12 which are properly defined in data dictionary, hence we can proceed ahead with this column without dropping \/ changing any records.\n\nLet's plot distrubution of Ride Count Mean Across all the months","33d688bc":"All the range of date, month & year are in the valid range, hence we can proceed ahead with this column without dropping \/ changing any records.","2f41b375":"# 2. Data Sourcing.\n**2.1. Importing CSV Data from file**","1db3446b":"Above Scatter Plot Shows Linear Relationship between Actual Test Data Points & Predicted Test Data Points.","6be41bd2":"By simply visualising the Date Column, we dont se any significant impact of this on Ride Count.","d5d5da89":"We will go ahead and drop \"Adjusted Temperature\" column as any one can be dropped since they are highly correlated and provide almost same explanatio","e7ad8dcf":"![](https:\/\/cdn.dribbble.com\/users\/449626\/screenshots\/3679748\/bike_sharing.gif)","a7e63dcf":"**2.3. Checking for Null Values**","3b1d1474":"# 4. Data Transformation (Using One Hot Encoder Method)\nFollowing Columns are Categorical Nominal Variables which needs to encoded using One Hot Encoder Method (i.e. Creating Dummy Variables):\n\n* Month\n* Season\n* Weekday\n* Weather Situation","0219a056":"From the above graph we can say that, the value of humidity as 0 should be adjusted as humidity if 0 is practically impossible. This could have been possible during recording the data if not done properly.\n\nThis can be done by taking numerical mean of all the records before and after this value upto a specifc range making to make sure there is no abrupt change in the season that will again deem oour redicted value to be wrong.","c1e95a80":"From the above observations, we see that the p-values of all features are under control. So we will proceed ahead to VIF table.\n\nIn the VIF table, we see that Working Day column seems to be explained by some other feature. So we will again drop this humidity feature and design our model.","07391ac4":"**3.10 Humidity Column**","70daf5ad":"# Hello everyone!!\n\n \n","de2bd935":"Let's plot distrubution of Ride Count Mean Across Weather Situation.","e7759238":"# 3. Data Preparation\n\nDefining set of fucntions which can be useful to plot graph \/ charts","97c17dbf":"**3.9 Temperate & Adjusted Temperature**","788417f1":"**3.3 Year**","81903d8d":"# Conclusions\nI hope this notebook is useful and feel free to send in your suggestions and comments. ","b863efe3":"# 10. Proof for Linear Regrssion Assumptions\n\n\n**10.1. Assumption of Normally Distributed Error Terms**\n\n\nAfter building model, we cannot finalise untill we prove the residual analysis wherein we check whether the distribution of Error is around 0 or not.","2faceb1a":"**1.2. Importing Warning Library to ignore warnings from\ndisplaying on UI**","6c19b661":"From the above graph, we can say that residuals are equal distributed across predicted value.\n\nThis means we see equal variance and we do NOT observe high concentration of data points in certain region & low conecentarion in certain regions.\n\nThis proves Homoscedasticity of Error Terms.","8cfdcd38":"Note: From the above graph it is evident that Error Distribution Is Normallly Distributed Across 0, which indicates that our model has handled the assumption of Error Normal Distribution properly.","cd0a6516":"We see that number of Ride Count drastically increases between May to October which are comparatively Summer & Fall Season in US.\n\nMonth column is categorical column with each value corresponding to specific month.\n\nMapping numbers to respective Month Name.","5822a707":"We will check if any of the date range is outside certain limit.","e4e79b6c":"**9.1. RFE (Recursive Feature Elimination) Application**","f7b79d94":"Weather Situation is a Categorical Nomimal Variable where every number is mapped as follows:\n\n1: Clear, Few clouds, Partly cloudy, Partly cloudy\n\n2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n\n\n3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds.\n\n4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n\nAs per the explanation, we will map each number with a shorter version\n\n1: clear\n\n2: mist\n\n3: light\n\nAfter analysing the column we see that, there are no values corersponding to Heavy Rain. So, after mapping, this value will be completely cancelled out during one hot encoding process.","a9e402b0":"**3.8 Weather Situation**","045f64a5":"Welcome to this Notebook on Bike-sharing demand prediction. \n\nThe dataset is received from GitHub.In this Notebook, we will go through simple but effective pre-processing steps and then we will dig deeper into the data and apply various machine learning regression techniques followed by Hyperparameter tunning and then we will try to check the accuracy of the model.\n\nIn the end, we will see how to include the whole code in python using functions for better efficiency. I hope, you will like it.","0d134ccd":"**1.3. Importing StatsModel Library for displaying\ndetailed information about model**","d7b4fc8d":"**3.6 Weekday**","46f6591b":"Here, we complete proper data transformation of required columns and also dropping the columns which are are redundant and are of no use in predicting outcome.","df8f294d":"# 12. Generating R-Square","cb829a15":"We will check if any of the year range is outside certain limit.","5ab44231":"# 11. Predicting on Test Data","eaf0d3fb":"**10.4 Multicorrelation**\n\n\nThis asumption is already taken care of while building model by calculating VIF of every predictor. Following is the final VIF value of all the predictors used in the model.","bef58736":"Imputing the mean value at the zero humidity level.","cb93b22e":"**3.11 Windspeed Column**","7f25d2d0":"As per United States, it is usually considered that 1st day of week is Sunday.\nAnd also from \"Working Day Column\", we can see that \"Working Day\" is marked as \"1\" for values of 1, 2, 3, 4, 5 in \"Week day\".\n\nFrom this we can infer that, for weekday column, Sunday is mapped to 0, Monday is mapped to 1 and so on","83ebc8e5":"Also, we will rename the column name from 'dteday' to 'date'.","b96386e7":"# Dataset:-\n\n- instant: record index\n- dteday : date\n- season : season (1:springer, 2:summer, 3:fall, 4:winter)\n- yr : year (0: 2011, 1:2012)\n- mnth : month ( 1 to 12)\n- hr : hour (0 to 23)\n- holiday : weather day is holiday or not (extracted from http:\/\/dchr.dc.gov\/page\/holiday-schedule)\n- weekday : day of the week\n- workingday : if day is neither weekend nor holiday is 1, otherwise is 0.\n+ weathersit : \n    - 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n    - 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n    - 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n    - 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n- temp : Normalized temperature in Celsius. The values are divided to 41 (max)\n- atemp: Normalized feeling temperature in Celsius. The values are divided to 50 (max)\n- hum: Normalized humidity. The values are divided to 100 (max)\n- windspeed: Normalized wind speed. The values are divided to 67 (max)\n- casual: count of casual users\n- registered: count of registered users\n- cnt: count of total rental bikes including both casual and registered","796c571b":"**8.2. Fixing Trained Feature(s) Variable**","f04abb16":"**3.7 Working Day**","d728ba0f":"**3.1. Date**","e315b11e":"**10.3. Homoscedasticity**","b5098859":"Please feel free to comment and take a moment to vote up it will motivate me.\n\n\nAlso, you can check my profile for reference.","26ee1af9":"**1.5. Other Misc Libraries (needed at runtime)**","45fa3ae6":"No Null value found in any column","3974333b":"#  6. Data Transformation (Normalising)\n**6.1 Defining Numerical Variable Columns that should be scaled directly**\n\nFollowing Columns are Numerical which needs to be Normalised:\n* Date\n* Temperature\n* Humidity\n* Windspeed"}}