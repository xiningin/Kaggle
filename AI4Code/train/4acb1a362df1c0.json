{"cell_type":{"7c8ca13d":"code","a0eaae7e":"code","84220af7":"code","14b8b28e":"code","bffb9a3f":"code","55fc1937":"code","a1f170fe":"code","cf47f7a6":"code","86f8f22b":"code","191f4246":"code","83e2f4fc":"code","612c2aa5":"code","113800a0":"code","98a42ee8":"code","b0605764":"code","98a3be6b":"code","69fa98fb":"code","b1218686":"code","f24b9469":"code","74090e11":"code","5a801b19":"code","90e38b01":"code","f678769b":"code","544de61f":"code","b0190ae7":"code","1253775e":"code","9c6353bf":"code","ea0a2f52":"markdown","7c6378c2":"markdown","768a5bf2":"markdown","03118c42":"markdown","f9e45136":"markdown","4ec4ba3d":"markdown","0c8d1d96":"markdown","13fbbd91":"markdown","69c9234f":"markdown","7b12a416":"markdown","cb5094b7":"markdown","811bdd23":"markdown","ced4e309":"markdown"},"source":{"7c8ca13d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a0eaae7e":"df=pd.read_csv('\/kaggle\/input\/indianeedsoxygen-tweets\/IndiaWantsOxygen.csv')","84220af7":"df","14b8b28e":"df.isnull().sum()","bffb9a3f":"df.dropna(subset=['user_name'])","55fc1937":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings(\"ignore\")","a1f170fe":"df.groupby('user_location')['user_location'].count().sort_values(ascending=False).head(30).plot.bar(figsize=(10,5))","cf47f7a6":"df.groupby('user_name')['user_name'].count().sort_values(ascending=False).head(20).plot.bar(figsize=(10,5))","86f8f22b":"df.groupby('user_name')['user_followers'].sum().sort_values(ascending=False).head(20).plot.bar(figsize=(10,5))","191f4246":"df.groupby('user_name')['user_friends'].sum().sort_values(ascending=False).head(20).plot.bar(figsize=(10,5))","83e2f4fc":"df.groupby('user_name')['user_favourites'].sum().sort_values(ascending=False).head(20).plot.bar(figsize=(10,5))","612c2aa5":"df.groupby('source')['source'].count().sort_values(ascending=False).head(20).plot.bar(figsize=(10,5))","113800a0":"from datetime import datetime\ndf['date'] = pd.to_datetime(df['date'])","98a42ee8":"df['date2']=df['date'].dt.date","b0605764":"df['hour']=df['date'].dt.hour","98a3be6b":"df.groupby('date2')['date2'].count().plot.bar(figsize=(10,5))","69fa98fb":"df.groupby('hour')['hour'].count().plot.bar(figsize=(10,5))","b1218686":"df.groupby(['date2','hour'])['hour'].count().plot(figsize=(10,5))","f24b9469":"#this is the data which I got from website.https:\/\/www3.nhk.or.jp\/news\/special\/coronavirus\/world-data\/\n\nlist=[295158,314644,332921,346786,349691,352991,323023,360927]\ndf_infection=pd.DataFrame(list)\ndf_infection.index=['0420','0421','0422','0423','0424','0425','0426','0427']","74090e11":"df_infection = df_infection.rename(columns={0: 'number of infection'})","5a801b19":"df_infection.plot(label='number of infection',figsize=(10,5))","90e38b01":"from nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom string import punctuation\nimport string\n\nlist_stopwords = set(stopwords.words('english'))\ndf2= df[['text']]\ndf2['text'] = df2['text'].str.lower()\ndf2['text'] = df2['text'].apply(word_tokenize)\ndf2['text'] = df2['text'].apply(lambda x: [word for word in x if word not in list_stopwords])\ndf2['text'] = df2['text'].apply(lambda x : [word.translate(str.maketrans('', '', string.punctuation)) for word in x])\ndf2['text'] = df2['text'].apply(lambda x : [word for word in x if len(word) > 1])","f678769b":"df2","544de61f":"df3=df2['text'].explode()","b0190ae7":"df3=pd.DataFrame(df3)","1253775e":"df3","9c6353bf":"pd.set_option('display.max_rows',30)\ndf3.groupby('text')['text'].count().sort_values(ascending=False).head(30).plot.bar(figsize=(10,5))","ea0a2f52":"**I tried to search the infcetion numbers in India around 22nd to 24th in April.**","7c6378c2":"trend by hours","768a5bf2":"day by day","03118c42":"Top 20 user names by friends","f9e45136":"Time series analysis","4ec4ba3d":"Top 20 user names by favourites","0c8d1d96":"Top 20 user names","13fbbd91":"Top 20 sources","69c9234f":"trend by hour and day","7b12a416":"Tokenize by NLTK","cb5094b7":"Top 30 location","811bdd23":"Top 20 user names by followers","ced4e309":"**Actually, the infection is increasing rapidly between 20th and 23rd and down on 26th.**"}}