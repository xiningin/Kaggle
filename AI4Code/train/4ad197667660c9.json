{"cell_type":{"3596c4b2":"code","ca07001e":"code","60b36a39":"code","8b9c92bc":"code","6c41d42d":"code","9f866643":"code","bc406c14":"code","811eaf81":"code","7419d545":"code","fa0238e5":"code","b81af4ee":"code","f9056755":"code","d3923131":"code","2cc21a98":"code","f19825a4":"code","6528035b":"code","3f93ccdc":"code","c30743c7":"code","7fd7741c":"code","e1d6989e":"code","17ebfc49":"code","2f97f0d2":"code","60fc1600":"code","419e1786":"code","c94a2938":"code","58cd88bb":"code","aae08767":"code","6471e372":"code","40c39215":"code","b984326b":"code","5db0f53c":"code","ea9d67d5":"code","8cf14bcf":"code","5b7776a7":"code","e2741f87":"code","56283aca":"code","c0266872":"code","9f82ea40":"code","3c493604":"code","26c17118":"code","1a73a065":"code","cb10f239":"code","4168001d":"code","d68f5a0c":"code","20457a11":"code","589f50f9":"code","e0a04bb6":"code","ac049367":"code","feb546a2":"code","38a52336":"code","c282c203":"code","edd7dad9":"code","2d9b05a6":"code","3b4843ad":"markdown","a5ad5c50":"markdown","3c42cc4b":"markdown","84a8957e":"markdown","fe1e7be5":"markdown","37e2dac6":"markdown","a91a8f7b":"markdown","cdc6ea28":"markdown","d98ddc3b":"markdown","4de32b58":"markdown","8550dedc":"markdown","263d35d2":"markdown","01706c59":"markdown","40027d84":"markdown","ab2561b1":"markdown","ef60226a":"markdown","0b2b1fa8":"markdown","da1cd1ca":"markdown","48127c51":"markdown","939d8204":"markdown","81c2010b":"markdown","45009bd2":"markdown","c7ce65c2":"markdown","0447e4dd":"markdown","380e9c15":"markdown","1b02ec43":"markdown","24cebf7d":"markdown","0e9eb7a6":"markdown","9dd35b2b":"markdown","93991c35":"markdown","2ea2cf68":"markdown","57b2ba48":"markdown","480ab573":"markdown","fbaa93e7":"markdown","407c2075":"markdown","6ee081cd":"markdown","6e8787a2":"markdown","278fcd49":"markdown","e4e3dc23":"markdown","4bc6bcd7":"markdown","25970e36":"markdown","61e51881":"markdown","84758e68":"markdown","c6e79867":"markdown","101a38ff":"markdown","ad4b705b":"markdown","260c1b49":"markdown"},"source":{"3596c4b2":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom scipy.stats import norm, boxcox\nfrom scipy import stats\nfrom pandas_profiling import ProfileReport\nimport plotly.express as px\nfrom sklearn.cluster import AgglomerativeClustering\nfrom sklearn.cluster import KMeans\nimport scipy.cluster.hierarchy as sch\nimport warnings\nwarnings.simplefilter(action='ignore', category=Warning)\n","ca07001e":"dataset = pd.read_csv('..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv', index_col=0)\n","60b36a39":"dataset.head()","8b9c92bc":"dataset.shape","6c41d42d":"dataset.describe()\n","9f866643":"dataset.info()","bc406c14":"dataset.isnull().values.any()\n","811eaf81":"sns.set_style('whitegrid')\nplt.figure(figsize=(20, 7))\nsns.countplot(x=\"Annual Income (k$)\", data=dataset, palette='husl');\n","7419d545":"plt.figure(figsize=(10, 7))\nmatrix = np.triu(dataset.corr())\nsns.heatmap(dataset.corr(), annot=True,linewidth=.8, mask=matrix, cmap=\"rocket\");\n","fa0238e5":"def distributionPlot(columnName):\n    if not columnName == 'Gender':\n        plt.figure()\n        sns.distplot(dataset[columnName], color=\"lightcoral\", rug=True);\n","b81af4ee":"for column in dataset.columns:\n    distributionPlot(column)","f9056755":"values = dataset['Gender'].value_counts()\nlabels = ['Male', 'Female']\n\nfig, ax = plt.subplots(figsize=(4, 4), dpi=100)\nexplode = (0, 0.06)\n\npatches, texts, autotexts = ax.pie(values, labels=labels, autopct='%1.2f%%', shadow=True,\n                                   startangle=90, explode=explode)\n\nplt.setp(texts, color='black')\nplt.setp(autotexts, size=12, color='white')\nautotexts[1].set_color('black')\nplt.show()\n","d3923131":"fig, ax = plt.subplots(1, 3, figsize=(20, 5))\nsdat = dataset.groupby(by='Gender')\nsdat.get_group(\"Male\").plot(kind='hist', ax=ax, subplots=True, bins=40);\n","2cc21a98":"sns.pairplot(sdat.get_group(\"Male\"));\n","f19825a4":"fig, ax = plt.subplots(1, 3, figsize=(20, 5))\nsdat = dataset.groupby(by='Gender')\nsdat.get_group(\"Female\").plot(kind='hist', ax=ax, subplots=True, bins=40);\n","6528035b":"sns.pairplot(sdat.get_group(\"Female\"));\n","3f93ccdc":"def skewnessCorrector(columnName):\n    print('''Before Correcting''')\n    (mu, sigma) = norm.fit(dataset[columnName])\n    print(\"Mu before correcting {} : {}, Sigma before correcting {} : {}\".format(\n        columnName.capitalize(), mu, columnName.capitalize(), sigma))\n    plt.figure(figsize=(20, 10))\n    plt.subplot(1, 2, 1)\n    sns.distplot(dataset[columnName], fit=norm, color=\"lightcoral\");\n    plt.title(columnName.capitalize() +\n              \" Distplot before Skewness Correction\", color=\"black\")\n    plt.subplot(1, 2, 2)\n    stats.probplot(dataset[columnName], plot=plt)\n    plt.show()\n    dataset[columnName], lam_fixed_acidity = boxcox(\n        dataset[columnName])\n    print('''After Correcting''')\n    print(\"Mu after correcting {} : {}, Sigma after correcting {} : {}\".format(\n        columnName.capitalize(), mu, columnName.capitalize(), sigma))\n    plt.figure(figsize=(20, 10))\n    plt.subplot(1, 2, 1)\n    sns.distplot(dataset[columnName], fit=norm, color=\"orange\");\n    plt.title(columnName.capitalize() +\n              \" Distplot After Skewness Correction\", color=\"black\")\n    plt.subplot(1, 2, 2)\n    stats.probplot(dataset[columnName], plot=plt)\n    plt.show()\n","c30743c7":"skewColumnList = ['Age',\n                  'Annual Income (k$)', 'Spending Score (1-100)']\nfor columns in skewColumnList:\n    skewnessCorrector(columns)\n","7fd7741c":"# pip install pandas_profiling","e1d6989e":"ProfileReport(dataset)","17ebfc49":"def elbowOptimizer(data):\n    \"\"\"Plots a Elbow Chart on the data provided\"\"\"\n    wcss = []\n    for i in range(1, 11):\n        kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n        kmeans.fit(data)\n        wcss.append(kmeans.inertia_)\n    plt.plot(range(1, 11), wcss)\n    plt.title('The Elbow Method')\n    plt.xlabel('Number of clusters')\n    plt.ylabel('WCSS')\n    plt.show();\n","2f97f0d2":"def dendoOptimizer(data):\n    \"\"\"Plots a Dendogram Plot on the data provided\"\"\"\n    sch.dendrogram(sch.linkage(data, method='ward'))\n    plt.title('Dendrogram')\n    plt.xlabel('Customers')\n    plt.ylabel('Euclidean distances')\n    plt.show()\n","60fc1600":"def kmeansTrainer(numberOfClusters, data):\n    \"\"\"\n    Trains KMeans Clustering Algorithm on data with\n    number of clusters provided and Returns corresponding Model and Labels\n    \"\"\"\n    kmeans = KMeans(n_clusters=numberOfClusters, init='k-means++', random_state=42)\n    labels = kmeans.fit_predict(data)\n    return (kmeans,labels)\n","419e1786":"def heirarchicalTrainer(noOfClusters, data):\n    \"\"\"\n    Trains Agglomerative Clustering Algorithm on data with\n    number of clusters provided and Returns corresponding Model and Labels\n    \"\"\"\n    hc = AgglomerativeClustering(\n        n_clusters=noOfClusters, affinity='euclidean', linkage='ward')\n    hc_labels = hc.fit_predict(data)\n    return (hc, hc_labels)\n","c94a2938":"def clusterVisualiser(data, model, noOfClusters, labels, xlabel, ylabel, model_type):\n    \"\"\"Plots Scatter Plot for the clusters on the Data given\"\"\"\n    color= ['red', 'blue', 'green', 'cyan', 'magenta','purple']\n    for i in range(0, noOfClusters):\n        plt.scatter(data[labels == i, 0], data[labels == i, 1 ], s=100, c=color[i], label ='Cluster '+str(i+1))\n    if model_type == 'KMeans Clustering':\n        plt.scatter(model.cluster_centers_[:, 0], model.cluster_centers_[\n                    :, 1], s=300, c='yellow', label='Centroids')   \n    plt.title('Clusters of customers using '+model_type)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.legend()\n    plt.show()\n","58cd88bb":"X1 = dataset.iloc[:, [2, 3]].values","aae08767":"elbowOptimizer(X1)","6471e372":"dendoOptimizer(X1)","40c39215":"kmeans, labels = kmeansTrainer(5, X1)","b984326b":"hc, hc_labels = heirarchicalTrainer(5, X1)","5db0f53c":"clusterVisualiser(X1, kmeans, 5, labels,\n                  'Annual Income (k$)', 'Spending Score (1-100)', 'KMeans Clustering')\n","ea9d67d5":"clusterVisualiser(X1, hc, 5, hc_labels,\n                  'Annual Income (k$)', 'Spending Score (1-100)', 'Heirarchical Clustering')\n","8cf14bcf":"X2 = dataset.iloc[:, [1, 3]].values\n","5b7776a7":"elbowOptimizer(X2)","e2741f87":"dendoOptimizer(X2)","56283aca":"kmeans, labels = kmeansTrainer(4, X2)","c0266872":"hc, hc_labels = heirarchicalTrainer(4, X2)","9f82ea40":"clusterVisualiser(X2, kmeans, 4, labels,\n                  'Age', 'Spending Score (1-100)', 'KMeans Clustering')","3c493604":"clusterVisualiser(X2, hc, 4, hc_labels,\n                  'Age', 'Spending Score (1-100)', 'Heirarchical Clustering')\n","26c17118":"X3 = dataset.iloc[:, [1,2]].values","1a73a065":"elbowOptimizer(X3)","cb10f239":"dendoOptimizer(X3)","4168001d":"kmeans, labels = kmeansTrainer(5, X3)","d68f5a0c":"hc, hc_labels = heirarchicalTrainer(5, X3)","20457a11":"clusterVisualiser(X3, kmeans, 5, labels,\n                  'Age', 'Annual Income', 'KMeans Clustering')","589f50f9":"clusterVisualiser(X3, hc, 5, hc_labels,\n                  'Age', 'Annual Income', 'Heirarchical Clustering')\n","e0a04bb6":"X4 = dataset.iloc[:, 1:]","ac049367":"elbowOptimizer(X4)","feb546a2":"dendoOptimizer(X4)","38a52336":"kmeans, labels = kmeansTrainer(6, X4)\nX4['label'] = labels\n","c282c203":"hc, hc_labels = heirarchicalTrainer(6, X4)\nX4['hc_labels'] = hc_labels","edd7dad9":"fig = px.scatter_3d(X4, x=\"Annual Income (k$)\", y=\"Spending Score (1-100)\", z=\"Age\",\n                    color='label', size='label')\nfig.show()\n","2d9b05a6":"fig = px.scatter_3d(X4, x=\"Annual Income (k$)\", y=\"Spending Score (1-100)\", z=\"Age\",\n                    color='hc_labels', size='hc_labels')\nfig.show()\n","3b4843ad":"## Visualising the clusters for Age, Annual Income and Spending Score (KMeans Model)","a5ad5c50":"## Plotting Count for Annual Income","3c42cc4b":"# Training Clustering Models on Dataset","84a8957e":"## Visualising the clusters for Age and Annual Score (Heirarchical Model)","fe1e7be5":"## Function to find the optimal number of clusters using elbow method","37e2dac6":"## Using the elbow method to find the optimal number of clusters for Age, Annual Income and Spending Score","a91a8f7b":"## Training the Heirarchical model on Annual Income and Spending Score","cdc6ea28":"## Function for Training  Hierarchical Clustering model on given data","d98ddc3b":"## Plotting Distribution of Males in dataset","4de32b58":"## Function for visualising 2-d Clusters","8550dedc":"## Using the dendrogram to find the optimal number of clusters for Annual Income and Spending Score","263d35d2":"# **Please Give Feedback by Commenting below and if you like my work please Consider Upvoting.** ","01706c59":"## Skewness Correction\nI found out there were some columns with skewness in the dataset. Here, I'm trying to correct that Skewness","40027d84":"## Plotting Distribution for each Column in dataset","ab2561b1":"## Function to find optimal numbers of clusters using Dendograms","ef60226a":"## Training K-Means Model on Age and Annual Income ","0b2b1fa8":"## Using the elbow method to find Optimal Clusters for Annual Income and Spending Score ","da1cd1ca":"# 2) Using Pandas Profiling","48127c51":"## Using dendogram to find the optimal number of clusters for Age and Annual Income","939d8204":"## Plotting Distribution of Females in dataset","81c2010b":"## Finding Correlation among the variables","45009bd2":"## Visualising the clusters for Annual Income and Spending Score (Kmeans Model)","c7ce65c2":"# Clustering the dataset on Age and Spending Score","0447e4dd":"## Distribution of Males and Females in dataset","380e9c15":"## Training the Heirarchical model on Age and Spending Score","1b02ec43":"## Using the elbow method to find the optimal number of clusters for Age and Spending Score","24cebf7d":"## Using the dendrogram to find the optimal number of clusters for Annual Income and Spending Score","0e9eb7a6":"## Function for Training K-Means Model on Given Data","9dd35b2b":"## Visualising the clusters for Age, Annual Income and Spending Score (Heirarchical Model)","93991c35":"## Visualising the clusters for Age and Spending Score (Heirarchical Model)","2ea2cf68":"## Visualising the clusters for Age and Spending Score (Kmeans Model)","57b2ba48":"# Exploratory Data Analysis\n","480ab573":"## Training Heirarchical Model on Age, Annual Income and Spending Score","fbaa93e7":"## Using the dendogram method to find the optimal number of clusters for Age, Annual Income and Spending Score","407c2075":"# Clustering the dataset on Age, Annual Income and Spending Score","6ee081cd":"# Importing Libraries","6e8787a2":"## Training the K-Means model on Annual Income and Spending Score","278fcd49":"## Using the elbow method to find the optimal number of clusters for Age and Annual Income","e4e3dc23":"## Training Heirarchical Clustering on Age and Annual Income","4bc6bcd7":"## Visualising the clusters for Age and Annual Income (KMeans Model)","25970e36":"# Clustering dataset on Annual Income and Spending Score","61e51881":"## Visualising the clusters for Annual Income and Spending Score (Heirarchical Model)","84758e68":"# Clustering the dataset on Age and Annual Income ","c6e79867":"# Loading Dataset","101a38ff":"## 1) Using Manual Methods","ad4b705b":"## Training K-Means Model on Age and Spending Score","260c1b49":"## Training K-Means Model on Age, Annual Income and Spending Score"}}