{"cell_type":{"38efc9fc":"code","7d33209c":"code","f069ddcf":"code","227f207e":"code","cdee936a":"code","a22a2431":"code","563fc1e4":"code","aa554b0a":"code","15974a10":"code","f2808882":"code","fcba1edd":"code","7e939140":"code","a5ea25d3":"code","d73b5f12":"code","59750fa2":"code","f3308421":"code","65f00a60":"code","3f315167":"markdown","ec7a402a":"markdown","0a1868e3":"markdown","d2903e9d":"markdown","817df1ff":"markdown"},"source":{"38efc9fc":"# !pip install git+https:\/\/github.com\/huggingface\/datasets.git@master\n# !pip install sentencepiece","7d33209c":"# from datasets import load_dataset\n# from transformers import (\n#     MBartForConditionalGeneration, MBartTokenizer, \n#     Seq2SeqTrainingArguments, Seq2SeqTrainer\n#   )\n\n# import torch\n# from torch.utils.data import random_split","f069ddcf":"# since \ud83e\udd17 dataset is yet to merge PR for IITB Parallel corpus\n# # we will be downloading dataset from link directly ...\n# !wget -c \"http:\/\/www.cfilt.iitb.ac.in\/iitb_parallel\/iitb_corpus_download\/parallel.tgz\"","227f207e":"# # extracting from .tgz file\n# import tarfile\n# my_tar = tarfile.open('parallel.tgz')\n# my_tar.extractall('.') # specify which folder to extract to\n# my_tar.close()","cdee936a":"# data = []\n# with open(\"parallel\/IITB.en-hi.en\") as f2, open(\"parallel\/IITB.en-hi.hi\") as f1:\n#     for src, tgt in zip(f1, f2):\n#       data.append(\n#           {\n#               \"translation\": {\n#                   \"hi\": src.strip(),\n#                   \"en\": tgt.strip()\n#               }\n#           }\n#       )\n# print(f'total size of data is {len(data)}')","a22a2431":"# # splitting dataset into train, validation\n# split = 0.99\n# train_dataset, eval_dataset = random_split(data, lengths=[int((1-split)*len(data))+1, int(split*len(data))])","563fc1e4":"# defining collator functioon for preparing batches on the fly ..\n\n# def data_collator(features:list):\n\n#   labels = [f[\"translation\"][\"en\"] for f in features]\n#   inputs = [f[\"translation\"][\"hi\"] for f in features]\n\n#   batch = tokenizer.prepare_seq2seq_batch(src_texts=inputs, src_lang=\"hi_IN\", tgt_lang=\"en_XX\", tgt_texts=labels, max_length=32, max_target_length=32)\n\n#   for k in batch:\n#     batch[k] = torch.tensor(batch[k])\n\n#   return batch","aa554b0a":"# # initiating model, tokenizer\n# model = MBartForConditionalGeneration.from_pretrained(\"facebook\/mbart-large-cc25\")\n# tokenizer = MBartTokenizer.from_pretrained(\"facebook\/mbart-large-cc25\")\n\n","15974a10":"# args = Seq2SeqTrainingArguments(output_dir=\".\/mbart_HindiToEnglish\/\",\n#                         do_train=True,\n# #                         do_eval=True,\n# #                         evaluation_strategy=\"epoch\",\n#                         per_device_train_batch_size=16,\n# #                         per_device_eval_batch_size=16,\n#                         learning_rate=5e-5,\n#                         num_train_epochs=1,\n#                         logging_dir=\"\/logs\")","f2808882":"# tokenizer.save_pretrained('.\/mbart_HindiToEnglish\/')","fcba1edd":"# defining trainer using \ud83e\udd17\n# trainer = Seq2SeqTrainer(model=model, \n#                 args=args, \n#                 data_collator=data_collator, \n#                 train_dataset=train_dataset, \n#                 eval_dataset=eval_dataset)","7e939140":"trainer.train()\n# It will take hours to train this model on this dataset","a5ea25d3":"# !ls ..\/working\/mbart_HindiToEnglis","d73b5f12":"# tokenizer = tokenizer.from_pretrained('.\/mbart_HindiToEnglish\/')","59750fa2":"# model =  MBartForConditionalGeneration.from_pretrained('.\/mbart_HindiToEnglish\/')","f3308421":"# from transformers import pipeline\n\n# # model_id = \"vasudevgupta\/mbart-iitb-hin-eng\"\n# translator = pipeline(\"translation_hi_to_en\", model=model, tokenizer=tokenizer)","65f00a60":"# # lets see how our model performs\n# inputs = \"\u0905\u0902\u0924\u093f\u092e \u092a\u094d\u0930\u0935\u093f\u0937\u094d\u091f \u0918\u091f\u0928\u093e \u0915\u094b \u0939\u093e\u0907\u0932\u093e\u0907\u091f \u0915\u0930\u094b\"\n\n# translation = translator(inputs, return_text=True)\n# translation = [t[\"translation_text\"] for t in translation]\n# print(translation)","3f315167":"# ****One epoch training will take 1.5 hours gpu with 0.1 training data","ec7a402a":"## Training time","0a1868e3":"****https:\/\/huggingface.co\/facebook\/mbart-large-cc25","d2903e9d":"## Preparing data\n\nWe will be using IITB parallel corpus (hi - en) for this example .","817df1ff":"## Initiating model and trainer for training"}}