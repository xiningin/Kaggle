{"cell_type":{"c8bed93a":"code","dad4d59e":"code","c6ba83f5":"code","2eee4c2f":"code","4bac2675":"code","dc46cfe6":"code","7dab86e6":"code","4df55f2d":"code","1bb7f4c9":"code","e8f09c3b":"code","30e2ef01":"code","8ef941ea":"code","d716a658":"code","ce270f60":"code","07c4df89":"code","860c927b":"code","3a90df1e":"code","61ee8996":"code","4a8f04b7":"code","76644d49":"code","ff306cd8":"code","5a775f57":"code","0449a885":"code","a8f34166":"code","50cd1edf":"code","aef8b9c9":"code","3ae05ceb":"code","7c58d797":"code","b39048b8":"code","f997dce8":"code","715db68e":"code","3658d369":"code","a616919f":"code","19dc2462":"code","ad5d0b50":"code","9a9c213a":"code","1dc766d2":"code","ecc5bb3f":"code","c57d9980":"code","0aef1203":"code","c74a56fd":"code","f32c1560":"code","831f4842":"code","8a6bff13":"code","6780f56b":"code","f59e6c98":"code","ea573557":"code","da2de415":"code","215d29c8":"code","bce2b4a9":"markdown","1754e1de":"markdown","794af8e8":"markdown","7f67b2ea":"markdown","77211952":"markdown","bcddad82":"markdown","dc2aed81":"markdown","791b3a5f":"markdown","d9a7101a":"markdown","5e89e4a2":"markdown","023806ec":"markdown","e5cfe8db":"markdown","241a0029":"markdown","e9bca0eb":"markdown","b4d124d1":"markdown","2e26b3aa":"markdown","2bc53d35":"markdown","270d0bd3":"markdown","c8ace6b4":"markdown","4bd3315e":"markdown","07d05d95":"markdown","b9f33ad3":"markdown","86e96910":"markdown","4aab84e8":"markdown","54ed1f25":"markdown","64f3656d":"markdown","2b189e24":"markdown","66785d47":"markdown","cd8e4c3e":"markdown","988558fc":"markdown","549998cf":"markdown","74b35e4b":"markdown","5c25d24c":"markdown","6187b3d7":"markdown","4a9d79fc":"markdown","1c4cc9f9":"markdown","c98537a9":"markdown","495c9fc8":"markdown","0f7d25d4":"markdown","ac3edc1d":"markdown","7d9beb3a":"markdown","207127d2":"markdown","58e6ea93":"markdown","aba91cef":"markdown","4f48fc3d":"markdown","2248762e":"markdown","9ea5e37b":"markdown","b8540e6a":"markdown","c8c4e772":"markdown","dcad5cb5":"markdown","250c5e04":"markdown","a577f297":"markdown","9d63249e":"markdown","3876abe5":"markdown","67a175cc":"markdown","e72ad12f":"markdown","7827af26":"markdown","c0e9ece3":"markdown","c49e4e3f":"markdown","151111ee":"markdown","ef162dab":"markdown","d0032974":"markdown","bea1b78b":"markdown","398ab100":"markdown","f365a253":"markdown","763e8dac":"markdown","57e9a7f2":"markdown","9a793ffa":"markdown","e84d7fa8":"markdown","0d3840b6":"markdown"},"source":{"c8bed93a":"\nimport numpy as np \nimport pandas as pd \nimport pandas_profiling\nimport matplotlib.pyplot as plt \nimport plotly.express as px \nimport seaborn as sns \nsns.set()\n\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import OneHotEncoder   \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n    \nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve,auc\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import classification_report, balanced_accuracy_score\n\n\n\n# Color Palette\n\ncustom_colors = [\"#85CEDA\",\"#D2A7D8\", \"#A67BC5\", \"#BB1C8B\", \"#05A4C0\"]\ncustomPalette = sns.set_palette(sns.color_palette(custom_colors))\n\n# Set size\n\nsns.palplot(sns.color_palette(custom_colors),size=1)\nplt.tick_params(axis='both', labelsize=0, length = 0)","dad4d59e":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest  = pd.read_csv(\"..\/input\/titanic\/test.csv\")","c6ba83f5":"print (train.columns.values)","2eee4c2f":"train.info()\ntest.info()","4bac2675":"train.describe()","dc46cfe6":"survived_summary = train.groupby(\"Sex\")\nsurvived_summary.mean().reset_index()","7dab86e6":"# Correlation Map\n\ntrain.corr\nf,ax = plt.subplots(figsize=(15,10))\nsns.heatmap(train.corr(), annot =True, linewidth =\".5\", fmt =\".2f\", cmap=custom_colors)\nplt.show()","4df55f2d":"profile = pandas_profiling.ProfileReport(train)","1bb7f4c9":"profile","e8f09c3b":"train[\"Survived\"].value_counts()","30e2ef01":"fig = px.bar(train.Survived.value_counts(), width=900, height=400)\nfig.update_traces(marker_color='orchid')\nfig.show()","8ef941ea":"# BarPlot\n\n\nplt.figure(figsize=(10,8))\nplt.title(\"Survived people based on gender\")\nsns.barplot(x=\"Survived\",y=\"Age\", data =train,palette='mako_r')","d716a658":"def hist(x,title):\n    plt.figure(figsize = (10,8))\n    ax = sns.distplot(x, \n                 kde=False);\n    values = np.array([rec.get_height() for rec in ax.patches])\n    norm = plt.Normalize(values.min(), values.max())\n    colors = plt.cm.jet(norm(values))\n    for rec, col in zip(ax.patches, colors):\n        rec.set_color(col)\n    plt.title(title)","ce270f60":"hist(train['Age'],'Distribution of Age')\n","07c4df89":"hist(train['Fare'],'Distribution of Fare') \n","860c927b":"# BarPlot\n\n# Set the width and the height of the figure\nplt.figure(figsize=(12,8))\n\n# Add the title\nplt.title(\"Survived people based on gender\")\n\n# Draw a barplot of survival people by sex\nsns.barplot(x=\"Sex\",y=\"Survived\", data =train,palette=(custom_colors))\n\n# Print percentage of males vs females that are survived \nprint(\"Percentage of females who survived :\",  train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts(normalize = True)[1]*100)\nprint (\"Percentage of males who survived :\",  train[\"Survived\"][train[\"Sex\"]==  'male'].value_counts(normalize= True)[1]*100)","3a90df1e":"# swarmplot\n\nplt.figure(figsize=(15,9))\n\nsns.swarmplot(x=train['Age'], y=train['Sex'], hue='Survived', data =train,palette =custom_colors)","61ee8996":"# Barplot\nplt.figure(figsize=(15,9))\nsns.barplot(x=\"Parch\", y=\"Survived\", data = train, palette=custom_colors)\nplt.show","4a8f04b7":"# Barplot\n\nplt.figure(figsize=(15,9))\nsns.barplot(x=\"SibSp\", y=\"Survived\", data=train, palette= 'RdPu_r')\nplt.show","76644d49":"# Violinplot\n\nfig = plt.figure(figsize=(25, 7))\nsns.violinplot(x =\"Embarked\", y =\"Fare\", hue =\"Survived\", data=train, split =True , palette = {0: \"#3498db\", 1:\"#2ecc71\"});","ff306cd8":"fig, ax = plt.subplots(figsize = (10,7))\nax = sns.countplot(x = 'Survived', hue = 'Pclass', data = train, palette = custom_colors)\nax.set_xlabel('Survived')\nax.set_title('Survival Rate for Passenger Classes', fontsize = 14, fontweight='bold');","5a775f57":"# let's take more detaild look of what data is actually missing\n\ntotal = train.isnull().sum().sort_values(ascending=False)\npercent_1 = train.isnull().sum()\/train.isnull().count()*100\npercent_2 = (round(percent_1, 1)).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\nmissing_data.head(5)","0449a885":"train.isnull().any()","a8f34166":"test.isnull().any()","50cd1edf":"#Age\n\n\ntrain[\"Age\"] = train[\"Age\"]. fillna(train[\"Age\"].mean())\n\ntest[\"Age\"]  = test[\"Age\"] . fillna(test[\"Age\"].mean())\n\n\n#Fare\n\ntest[\"Fare\"] = test [\"Fare\"]. fillna(test[\"Fare\"].mean())\n\n\n#Embarked\n\ntrain[\"Embarked\"].fillna(\"S\", inplace = True)","aef8b9c9":"train.loc[train[\"Sex\"] == \"male\" , \"Sex\"] = 0\ntrain.loc[train[\"Sex\"] == \"female\",\"Sex\"] = 1\n\n\ntest.loc[test[\"Sex\"] == \"male\", \"Sex\"] = 0\ntest.loc[test[\"Sex\"] == \"female\", \"Sex\"] = 1","3ae05ceb":"train.loc[train[\"Embarked\"] == \"S\", \"Embarked\"] = 0\ntrain.loc[train[\"Embarked\"] == \"C\", \"Embarked\"] = 1\ntrain.loc[train[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n\n\ntest.loc[test[\"Embarked\"]  == \"S\", \"Embarked\"] = 0\ntest.loc[test[\"Embarked\"]  == \"C\", \"Embarked\"] = 1\ntest.loc[test[\"Embarked\"]  == \"Q\", \"Embarked\"] = 2","7c58d797":"train[\"FamSize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\ntest[\"FamSize\"]  =  test[\"SibSp\"] + test[\"Parch\"]  + 1","b39048b8":"train[\"IsAlone\"] = train.FamSize.apply(lambda x: 1 if x == 1 else 0)\ntest[\"IsAlone\"]  = test.FamSize.apply( lambda x: 1 if x == 1 else 0)","f997dce8":"for name in train[\"Name\"]:\n    train[\"Title\"] = train[\"Name\"].str.extract(\"([A-Za-z]+)\\.\",expand=True)\n    \nfor name in test[\"Name\"]:\n    test[\"Title\"] = test[\"Name\"].str.extract(\"([A-Za-z]+)\\.\",expand=True)\n    \ntitle_replacements = {\"Mlle\": \"Other\", \"Major\": \"Other\", \"Col\": \"Other\", \"Sir\": \"Other\", \"Don\": \"Other\", \"Mme\": \"Other\",\n          \"Jonkheer\": \"Other\", \"Lady\": \"Other\", \"Capt\": \"Other\", \"Countess\": \"Other\", \"Ms\": \"Other\", \"Dona\": \"Other\", \"Rev\": \"Other\", \"Dr\": \"Other\"}\n\ntrain.replace({\"Title\": title_replacements}, inplace=True)\ntest.replace({\"Title\": title_replacements}, inplace=True)\n\ntrain.loc[train[\"Title\"] == \"Miss\", \"Title\"] = 0\ntrain.loc[train[\"Title\"] == \"Mr\", \"Title\"] = 1\ntrain.loc[train[\"Title\"] == \"Mrs\", \"Title\"] = 2\ntrain.loc[train[\"Title\"] == \"Master\", \"Title\"] = 3\ntrain.loc[train[\"Title\"] == \"Other\", \"Title\"] = 4\n\ntest.loc[test[\"Title\"] == \"Miss\", \"Title\"] = 0\ntest.loc[test[\"Title\"] == \"Mr\", \"Title\"] = 1\ntest.loc[test[\"Title\"] == \"Mrs\", \"Title\"] = 2\ntest.loc[test[\"Title\"] == \"Master\", \"Title\"] = 3\ntest.loc[test[\"Title\"] == \"Other\", \"Title\"] = 4","715db68e":"print(set(train[\"Title\"]))","3658d369":"features_drop = ['Ticket', 'SibSp', 'Parch', \"Name\", \"Cabin\", \"Fare\", \"PassengerId\"]\n\ntrain = train.drop(features_drop, axis=1)\n\ntest = test.drop(features_drop, axis=1)","a616919f":"train = pd.get_dummies(train, columns=['Pclass','Sex','Embarked','Title'], \n                       drop_first=False)\n\ntest = pd.get_dummies(test, columns=['Pclass','Sex','Embarked','Title'],\n                      drop_first=False)","19dc2462":"X = train.drop('Survived', axis=1)\n\ny = train['Survived']\n\nX.shape,y.shape","ad5d0b50":"\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.2, random_state= 1)","9a9c213a":"RF = RandomForestClassifier(criterion='gini',\n                                           n_estimators=1750,\n                                           max_depth=7,\n                                           min_samples_split=6,\n                                           min_samples_leaf=6,\n                                           max_features='auto',\n                                           oob_score=True,\n                                           random_state=42,\n                                           n_jobs=-1,\n                                           verbose=1) \nRF.fit(X_train, y_train)","1dc766d2":"y_pred_train = RF.predict(X_train)\n\ny_pred_test = RF.predict(X_test)","ecc5bb3f":"accu = RF.score(X_train, y_train)\nprint( \"Model Prediction Score\", (accu * 100).round(2))","c57d9980":"print(\"Training accuracy: \", accuracy_score(y_train, y_pred_train))\nprint(\"Testing accuracy: \", accuracy_score(y_test, y_pred_test))","0aef1203":"cm = np.array(confusion_matrix(y_test, y_pred_test, labels=[1,0]))\n\nconfusion_mat= pd.DataFrame(cm, index = [\"Not-Survived\", \"Survived\"],\n                           columns =[\"Predicted Not Survived\", \"Predicted Survived\"])\n\nconfusion_mat","c74a56fd":"sns.heatmap(cm,annot=True,fmt='g',cmap='Set3')","f32c1560":"accuracy_score(y_test, y_pred_test)","831f4842":"precision_score(y_test, y_pred_test)","8a6bff13":"print(classification_report(y_test, y_pred_test))","6780f56b":"fpr, tpr, _ = roc_curve(y_test, y_pred_test)\nroc_auc = auc(fpr, tpr)\nprint(\"\\nROC AUC on evaluation set\",roc_auc )","f59e6c98":"plt.figure()\nplt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc,color=custom_colors[0])\nplt.plot([0, 1], [0, 1], 'k--',color=custom_colors[1])\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc=\"lower right\")\nplt.show()","ea573557":"passenger_IDs = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")[[\"PassengerId\"]].values\npreds = RF.predict(test.values)\npreds","da2de415":"df = {'PassengerId': passenger_IDs.ravel(), 'Survived': preds}\ndf_predictions = pd.DataFrame(df).set_index(['PassengerId'])\ndf_predictions.head(10)","215d29c8":"df_predictions.to_csv('\/kaggle\/working\/Predictions.csv')","bce2b4a9":"-`PassengerId` is the unique id of the row and it doesn't have any effect on target\n\n- `Name` \n\n- `Sex` \n\n- `Age`\n\n-`Survived` is the target variable we are trying to predict (0 or 1):\n     \n      1 = Survived\n      0 = Not Survived\n-`Pclass` (Passenger Class) is the socio-economic status of the passenger and it is a categorical ordinal feature which has 3 unique values (1, 2 or 3):\n      \n      1 = Upper Class\n      2 = Middle Class\n      3 = Lower Class\n\n-`SibSp` is the total number of the passengers' siblings and spouse.\n\n-`Parch` is the total number of the passengers' parents and children.\n\n-`Ticket` is the ticket number of the passenger.\n\n-`Fare` is the passenger fare.\n\n-`Cabin` is the cabin number of the passenger.\n\n-`Embarked` is port of embarkation and it is a categorical feature which has 3 unique values (C, Q or S):\n      \n     C = Cherbourg\n     Q = Queenstown\n     S = Southampton","1754e1de":"* **Extraction the passengers titles**","794af8e8":"* **Passenger Class**","7f67b2ea":"\n ## Libraries \ud83d\udcda","77211952":"* **Accuracy of the model**","bcddad82":"### 2.5 Creating dummy variables","dc2aed81":"### 2.1 Filling missing Values","791b3a5f":"* **PARCH feature vs Survived feature**","d9a7101a":"### 5- Evaluating the performance of the model","5e89e4a2":"* **Missing values in test data**","023806ec":"* **Variables** ","e5cfe8db":"## 2. Feature Engineering","241a0029":"- According to this graph, we can notice that womens are more likely to survive.","e9bca0eb":"* **What are the data types for various features?**","b4d124d1":"- The next option is to cerate IsAlone feature to check wheter a person traveling alolne is more likely to survived or died","2e26b3aa":"- People with SibSp or spouses were less likely to survive, therefore people with no children were more less likely to survived than those with one children or two.","2bc53d35":"* **pandas_profiling**","270d0bd3":"* **Numerical Features** : Continous: Age, Fare. Discrete: SibSp, Parch.","c8ace6b4":"## 3 Pre-Modeling Tasks","4bd3315e":"* **Predict our model**","07d05d95":"* **Training the Random Forest model** ","b9f33ad3":"### Submission","86e96910":"\n* Before we fit the data into a machine learning algorithm, there is a step very crucial is that we make sure to encode categorical variables\n\n  correctly We will change Sex to binary, as either 1 for female and 0 for male. We do the same for Embarked. We do this same process on  \n\n  both the training and testing set to prepare our data for Machine Learning.","4aab84e8":"* **Age**","54ed1f25":"* **Categorical Features** : Survived,Embarked and Sex \n Ordinal: Pclass.","64f3656d":"![ ](https:\/\/scontent-arn2-2.xx.fbcdn.net\/v\/t1.0-9\/57429716_2030860760555937_2750062083545497600_n.jpg?_nc_cat=100&ccb=2&_nc_sid=8bfeb9&_nc_ohc=y5d_WudgJy0AX9PNi5o&_nc_ht=scontent-arn2-2.xx&oh=a630ca82a715594c37e77c981b2f0b12&oe=6004F26F)\n                                   ","2b189e24":"* **IsAlone**","66785d47":"### 3.2 Splitting the training data \n","cd8e4c3e":"### 2.2 Bining Categorical variables","988558fc":"* **SibSp Feature** ","549998cf":"# Useful resources","74b35e4b":"Distribution of survivals : 1 is for survival and 0 is for not","5c25d24c":"- [How to Build a Machine Learning Model](https:\/\/towardsdatascience.com\/how-to-build-a-machine-learning-model-439ab8fb3fb1)\n\n- [How to find optimal parameters using GridSearchCV?](https:\/\/www.dezyre.com\/recipes\/find-optimal-parameters-using-gridsearchcv)","6187b3d7":"* **Family size**","4a9d79fc":"# 1. EXPLORATORY DATA ANALYSIS","1c4cc9f9":"- Then, introducing new features as Family size (to join these Parch and SibSp)","c98537a9":"* **Inspect the missing values** ","495c9fc8":"* **Accuracy_score**","0f7d25d4":"* **Processing Embarked**","ac3edc1d":"*** ROC Curve**","7d9beb3a":"* **Training Accuracy\\ Testing Accuracy**","207127d2":"![](https:\/\/glassboxmedicine.files.wordpress.com\/2019\/02\/roc-curve-v2.png?w=576)","58e6ea93":"* **Sex feature vs Survived feature**","aba91cef":"* If we have a quick look in the names of the passengers we will notice that each name has a title in it, so it can be a useful information \n\n  for our analyze. Therefore we can extract this title from the name of each passenger and then encode it like we did for Sex and Embarked.","4f48fc3d":"* **Confusion Matrix**","2248762e":"* **Statistical info about the numerical variables** :","9ea5e37b":"* **Precision_score**","b8540e6a":"* **Survived feature**","c8c4e772":"### 2.4 Removing irrelevant variables","dcad5cb5":"- People with less than four parents or childrens aboard more likely to survive.","250c5e04":"## 4- Modeling ","a577f297":"![](https:\/\/i1.wp.com\/interviewbubble.com\/wp-content\/uploads\/2019\/03\/1pOtBHai4jFd-ujaNXPilRg.png?resize=936%2C340&ssl=1)","9d63249e":"* The next step is dropping the less relevant features because, The problem with less important features is that they create more noise\n \n  and actually take over the importance of real features like Sex and Pclass.","3876abe5":"* The next step we'll do some descriptive statistics, this one helps us to describe and understand the features of a specific data by giving short summaries about the sample and measures of the data.\n","67a175cc":"* **Survived by Age**","e72ad12f":"### 1.3 Descriptive Statistics","7827af26":"### 1.2 Acquire data","c0e9ece3":"* **classification_report**","c49e4e3f":"* **Embarked and fare features**","151111ee":"\n 1. EXPLORATORY DATA ANALYSIS\n   \n   - 1.1 Libraries\n   \n   - 1.2 Acquire the data\n  \n   - 1.3 Descriptive statistics\n  \n   - 1.4 Data visualisation\n   \n\n2. Feature Engineering\n\n   - 2.1 Filling missing Values\n  \n   - 2.2 Binning the categorical features\n  \n   - 2.3 Creating New Features\n   \n   - 2.4 Removing irrelevant variables\n   \n   - 2.4 Creating dummy variables\n   \n  \n\n3. Pre-Modeling Tasks\n\n\n   -  3.1 Defining Features in Training\/Test Set\n   \n   -  3.2 Splitting the dataset\n   \n\n4. Modeling\n \n  \n   - Random Forest Model\n   \n   \n5. Evaluating the performance of the model\n     \n     - Confusion Matrix\n     - Classificarion Report\n     - Accuracy Score\n     - Precision Score\n     - ROC Curve\n     \n6. Submission\n\n\n- Useful resources\n  ","ef162dab":"* Total samples are 891 or 40% of the actual number of passengers on board the Titanic (2,224).\n* only 38% passenger survived \n* 74% female passenger survived, and only 19% male passenger survived.\n* About 75% of passengers did not travel with their children or parents.\n* Around 30% of the passengers had siblings aboard\n","d0032974":"* So first we need to know **which variables are available in the dataset** ?","bea1b78b":"### 2.3 Creating New Features","398ab100":"Let's now see how the embarkation site affects the survival.","f365a253":"* **Checking for the correlation**","763e8dac":"* **Preprocessing Sex**","57e9a7f2":"### 3.1 Separating the independant and the dependant variable","9a793ffa":"### 1.4 Data Visualization \ud83d\udcca\ud83d\udcc8","e84d7fa8":"* **Fare**","0d3840b6":"* **Missing values in train data**"}}