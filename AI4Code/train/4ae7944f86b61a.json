{"cell_type":{"15581c6c":"code","6bcd73fc":"code","8246ac23":"code","a33bc40b":"code","a48433f2":"code","5ac1ef2e":"code","48365a7a":"code","35d8d2f9":"code","4c78b102":"code","d94e8fea":"code","5ad94bf1":"code","e21ad0da":"code","691d4607":"code","6dde9469":"code","0845cf96":"code","f96f5fe8":"code","9e52ef82":"code","284ff623":"code","9a68da17":"code","75ec91b1":"code","e3676ce2":"code","a4ff8c79":"code","4681a04c":"code","619fa39f":"code","861ef845":"code","9f84b4e9":"code","8ef2e7ec":"code","d246ded7":"code","ce6cf586":"code","8de6f384":"code","907291b0":"code","10e90dcc":"code","0ccaeaee":"code","4e111066":"code","72cf13e3":"code","9d0b76f2":"markdown","29a48757":"markdown","3c84ee6b":"markdown","4d6141f5":"markdown","d80717e6":"markdown","928082d8":"markdown","e60571f2":"markdown"},"source":{"15581c6c":"import re\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nimport contractions\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras import backend as K \nfrom tensorflow.python.keras.layers import Layer\n","6bcd73fc":"#Kaggle\ndata_path = '..\/input\/news-summary\/news_summary_more.csv'\ndata = pd.read_csv(data_path)\ndata.head()","8246ac23":"data.drop_duplicates(subset=['headlines'],inplace=True)\ndata.reset_index(inplace=True, drop=True)","a33bc40b":"stop_words = stopwords.words('english')\n\ndef preprocess(text):\n    text = text.lower()\n    text = ' '.join([contractions.fix(word) for word in text.split(\" \")])    \n    \n    tokens = [w for w in text.split() if not w in stop_words]\n    text = \" \".join(tokens)\n    text = text.replace(\"'s\",'')\n    text = text.replace(\".\",'')\n    text = re.sub(r'\\(.*\\)','',text)\n    text = re.sub(r'[^a-zA-Z0-9. ]',' ',text)\n    text = re.sub(r'\\.','. ',text)\n    text = re.sub(r'\\s+', ' ', text)\n    return text\n","a48433f2":"data['headlines'] = data['headlines'].apply(preprocess)\ndata['text'] = data['text'].apply(preprocess)\ndata['headlines'] = data['headlines'].apply(lambda x : '_START_ '+ x + ' _END_')\n\nfor i in range(2):\n    print('Summary:', data['headlines'][i],'Text:', data['text'][i], sep='\\n')\n    print()","5ac1ef2e":"headlines_length = [len(x.split()) for x in data.headlines]\ntext_length = [len(x.split()) for x in data.text]","48365a7a":"fig, (ax1, ax2) = plt.subplots(1,2, figsize = (10,5))\nax1.hist(headlines_length, bins = 20)\nax2.hist(text_length, bins = 20)\n\nax1.title.set_text(\"Words in Headlines\")\nax2.title.set_text(\"Words in Text\")\nplt.show()","35d8d2f9":"glove_size = 300\nf = open('..\/input\/glove42b300dtxt\/glove.42B.300d.txt')","4c78b102":"embeddings_index = dict()\nfor line in f:\n    values = line.split()\n    embeddings_index[values[0]] = np.asarray(values[1:], dtype='float32')\nf.close()","d94e8fea":"words_source_train = []\nfor i in data['text'] :\n  words_source_train.extend(i.split(' '))\n\nprint(\"all the words in the corpus\", len(words_source_train))\nwords_source_train = set(words_source_train)\nprint(\"the unique words in the corpus\", len(words_source_train))\ninter_words = set(embeddings_index.keys()).intersection(words_source_train)\nprint(\"The number of words that are present in both glove vectors and our corpus are {} which \\\nis nearly {}% \".format(len(inter_words), np.round((float(len(inter_words))\/len(words_source_train))\n*100)))\n\nwords_corpus_source_train = {}\nwords_glove = set(embeddings_index.keys())\nfor i in words_source_train:\n  if i in words_glove:\n    words_corpus_source_train[i] = embeddings_index[i]\nprint(\"word 2 vec length\", len(words_corpus_source_train))","5ad94bf1":"print(list(words_source_train - inter_words)[:20])","e21ad0da":"def num(text):\n  words = [w for w in text.split() if not w in inter_words]\n  return len(words)\n\ndata['unique_words'] = data['text'].apply(num)","691d4607":"data['unique_words'].value_counts()","6dde9469":"data = data[data['unique_words'] < 4]\ndata.reset_index(inplace=True, drop=True)","0845cf96":"data","f96f5fe8":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(data['text'], data['headlines'], test_size = 0.2, random_state = 20)\nX_test, X_val, y_test, y_val = train_test_split(X_val, y_val, test_size = 0.5, random_state = 20)","9e52ef82":"max_length_x = max(text_length)\nmax_length_y = max(headlines_length)","284ff623":"x_t = Tokenizer()\nx_t.fit_on_texts(data['text'] + data['headlines'])\nx_vocab_size = len(x_t.word_index) + 1\n\nencoded_xtrain = x_t.texts_to_sequences(X_train)\nencoded_xval = x_t.texts_to_sequences(X_val)\nencoded_xtest = x_t.texts_to_sequences(X_test)\n\npadded_xtrain = pad_sequences(encoded_xtrain, maxlen=max_length_x, padding='post')\npadded_xval = pad_sequences(encoded_xval, maxlen=max_length_x, padding='post')\npadded_xtest = pad_sequences(encoded_xtest, maxlen=max_length_x, padding='post')","9a68da17":"y_t = Tokenizer()\ny_t.fit_on_texts(data['headlines'])\ny_vocab_size = len(y_t.word_index) + 1\n\nencoded_ytrain = y_t.texts_to_sequences(y_train)\nencoded_yval = y_t.texts_to_sequences(y_val)\nencoded_ytest = y_t.texts_to_sequences(y_test)\n\npadded_ytrain = pad_sequences(encoded_ytrain, maxlen=max_length_y, padding='post')\npadded_yval = pad_sequences(encoded_yval, maxlen=max_length_y, padding='post')\npadded_ytest = pad_sequences(encoded_ytest, maxlen=max_length_y, padding='post')","75ec91b1":"print('Loaded %s word vectors.' % len(embeddings_index))\n\nembedding_matrix = np.zeros((x_vocab_size, glove_size))\nfor word, i in x_t.word_index.items():\n\tembedding_vector = embeddings_index.get(word)\n\tif embedding_vector is not None:\n\t\tembedding_matrix[i] = embedding_vector","e3676ce2":"class AttentionLayer(Layer):\n\n    def __init__(self, **kwargs):\n        super(AttentionLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n\n        self.W_a = self.add_weight(name='W_a',\n                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n                                   initializer='uniform',\n                                   trainable=True)\n        self.U_a = self.add_weight(name='U_a',\n                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n                                   initializer='uniform',\n                                   trainable=True)\n        self.V_a = self.add_weight(name='V_a',\n                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n                                   initializer='uniform',\n                                   trainable=True)\n\n        super(AttentionLayer, self).build(input_shape)\n\n    def call(self, inputs):\n        encoder_out_seq, decoder_out_seq = inputs\n\n        def energy_step(inputs, states):\n          \n            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n            de_hidden = inputs.shape[-1]\n\n            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  \n            \n            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n            e_i = K.softmax(e_i)\n\n            return e_i, [e_i]\n\n        def context_step(inputs, states):\n            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n            return c_i, [c_i]\n\n        def create_inital_state(inputs, hidden_size):\n            \n            fake_state = K.zeros_like(inputs)  \n            fake_state = K.sum(fake_state, axis=[1, 2])  \n            fake_state = K.expand_dims(fake_state)  \n            fake_state = K.tile(fake_state, [1, hidden_size])  \n            return fake_state\n\n        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  \n\n        last_out, e_outputs, _ = K.rnn(\n            energy_step, decoder_out_seq, [fake_state_e],\n        )\n\n        last_out, c_outputs, _ = K.rnn(\n            context_step, e_outputs, [fake_state_c],\n        )\n        return c_outputs, e_outputs\n\n    def compute_output_shape(self, input_shape):\n        return [\n            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n        ]\n","a4ff8c79":"latent_dim=500\n\nK.clear_session() \n\nencoder_inputs = Input(shape=(max_length_x,)) \nenc_emb = Embedding(x_vocab_size, glove_size, weights=[embedding_matrix],input_length=max_length_x, trainable=False)(encoder_inputs) \n\n#LSTM \nencoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \nencoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \nencoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \nencoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \nencoder_lstm3 = LSTM(latent_dim, return_state=True, return_sequences=True) \nencoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n\n# Decoder. \ndecoder_inputs = Input(shape=(None,)) \ndec_emb_layer = Embedding(x_vocab_size, glove_size, weights=[embedding_matrix],input_length=max_length_x, trainable=False) \ndec_emb = dec_emb_layer(decoder_inputs) \n\n#LSTM using encoder_states as initial state\ndecoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \ndecoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n\n#Attention Layer\nattn_layer = AttentionLayer(name='attention_layer') \nattn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n\ndecoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\ndecoder_dense = TimeDistributed(Dense(y_vocab_size, activation='softmax')) \ndecoder_outputs = decoder_dense(decoder_concat_input) \n\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs) \nprint(model.summary())","4681a04c":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\ncheckpoint_filepath = '.\/model.{epoch:02d}-{val_loss:.2f}.h5'\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,save_weights_only=True,monitor='val_loss',mode='min',save_best_only=True, save_freq = \"epoch\")\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=1)\nhistory=model.fit([padded_xtrain,padded_ytrain[:,:-1]], padded_ytrain.reshape(padded_ytrain.shape[0],padded_ytrain.shape[1], 1)[:,1:] ,epochs=10,batch_size=512, validation_data=([padded_xval,padded_yval[:,:-1]], padded_yval.reshape(padded_yval.shape[0],padded_yval.shape[1], 1)[:,1:]), callbacks=[es, model_checkpoint_callback])","619fa39f":"model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\nmodel.load_weights(\".\/model.27-3.27.h5\")\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy')","861ef845":"from matplotlib import pyplot \npyplot.plot(history.history['loss'], label='train') \npyplot.plot(history.history['val_loss'], label='test') \npyplot.legend() \npyplot.show()","9f84b4e9":"reverse_target_word_index = y_t.index_word \nreverse_source_word_index = x_t.index_word \ntarget_word_index = y_t.word_index","8ef2e7ec":"encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\ndecoder_state_input_h = Input(shape=(latent_dim,))\ndecoder_state_input_c = Input(shape=(latent_dim,))\ndecoder_hidden_state_input = Input(shape=(max_length_x,latent_dim))\n\ndec_emb2= dec_emb_layer(decoder_inputs)\ndecoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n\nattn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\ndecoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n\ndecoder_outputs2 = decoder_dense(decoder_inf_concat)\n\ndecoder_model = Model(\n[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n[decoder_outputs2] + [state_h2, state_c2])","d246ded7":"def decode_sequence(input_seq):\n    input_seq= input_seq.reshape(1,max_length_x)\n    e_out, e_h, e_c = encoder_model.predict(input_seq)\n    target_seq = np.zeros((1,1))\n    target_seq[0, 0] = target_word_index['start']\n\n    stop_condition = False\n    decoded_sentence = ''\n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_token = reverse_target_word_index[sampled_token_index]\n  \n        if(sampled_token!='end'):\n            decoded_sentence += ' '+sampled_token\n \n        if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_length_y-1)):\n                stop_condition = True\n\n        target_seq = np.zeros((1,1))\n        target_seq[0, 0] = sampled_token_index\n        e_h, e_c = h, c\n\n    return decoded_sentence","ce6cf586":"def seq2summary(input_seq):\n    newString=''\n    for i in input_seq:\n      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n        newString=newString+reverse_target_word_index[i]+' '\n    return newString\n\ndef seq2text(input_seq):\n    newString=''\n    for i in input_seq:\n      if(i!=0):\n        newString=newString+reverse_source_word_index[i]+' '\n    return newString","8de6f384":"for i in range(10):\n  print(\"Review:\",seq2text(padded_xtest[i]))\n  print(\"Original summary:\",seq2summary(padded_ytest[i]))\n  print(\"Predicted summary:\",decode_sequence(padded_xtest[i]))\n  print(\"\\n\")","907291b0":"def BLEU_Score(y_test, y_pred):\n    references = [[seq2summary(y_test).split(\" \")]]\n    candidates = [decode_sequence(y_pred.reshape(1,max_length_x)).split(\" \")]\n    return corpus_bleu(references, candidates)\n","10e90dcc":"from nltk.translate.bleu_score import corpus_bleu\nscores=[]\nfor i in range(0,500):\n    scores.append(BLEU_Score(padded_ytest[i],padded_xtest[i]))\n    \nprint(np.mean(scores))","0ccaeaee":"import tensorflow_hub as hub\nfrom scipy import spatial\nmodule_url = \"https:\/\/tfhub.dev\/google\/universal-sentence-encoder\/4\" \nsentence_encoder = hub.load(module_url)\nprint (\"module %s loaded\" % module_url)","4e111066":"def cosine_similarity(padded_xval, padded_yval):\n  scores = []\n  for i in range(len(padded_xval)):\n    \n    str1 = seq2summary(padded_yval[i])\n    str2 = decode_sequence(padded_xval[i])\n    embeddings = sentence_encoder([str1, str2]).numpy()\n    result = 1 - spatial.distance.cosine(embeddings[0], embeddings[1])\n    scores.append(result)\n  return scores","72cf13e3":"scores = cosine_similarity(padded_xtest[:500],padded_ytest[:500] )\nnp.mean(scores)","9d0b76f2":"### Importing Data","29a48757":"# Text Summarization - Encoder Decoder with Attention Mechanism","3c84ee6b":"### Building Model","4d6141f5":"### Evaluation","d80717e6":"### Embedding Matrix from Glove\n","928082d8":"### Importing Basic libraries","e60571f2":"### Inference"}}