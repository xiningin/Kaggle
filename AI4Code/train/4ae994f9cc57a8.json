{"cell_type":{"b21cd589":"code","b6612911":"code","777e3bf3":"code","e8f6d61a":"code","89c15390":"code","4a336b81":"code","d9ed2f2c":"code","d079bdb0":"code","ad13507d":"code","fddeaad3":"code","2bd83139":"code","e5355fc8":"code","03c68865":"code","3be54103":"code","e194b168":"code","9f2be47a":"code","9d24c177":"code","1566026e":"code","4273ac0b":"code","e028e2fe":"code","22cb535c":"code","7c30b22f":"code","d88289ca":"code","65674e88":"code","d8be79b7":"code","052976f3":"code","5b197885":"code","f6d108fa":"code","2a19dc9f":"code","d94a185c":"code","3018f278":"code","c2d3ab7f":"code","e2f88923":"code","156348b4":"code","dae91890":"code","5516ae4d":"code","ee9402f2":"code","75415106":"code","d6949564":"code","fc498172":"code","48fe806e":"markdown","785ea848":"markdown","5bf76f69":"markdown","96c52f75":"markdown","6d9477d0":"markdown","35ce3544":"markdown","4c9ffe98":"markdown","a3b8b15b":"markdown","1656e851":"markdown","53bfc414":"markdown","8bfef45f":"markdown","06afad80":"markdown"},"source":{"b21cd589":"#import modules\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os","b6612911":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","777e3bf3":"train_path = '..\/input\/titanic\/train.csv'\ntest_path = '..\/input\/titanic\/test.csv'\n\n# Read a comma-separated values (csv) file into pandas DataFrame\ntrain = pd.read_csv(train_path)\ntest = pd.read_csv(test_path)\n\n# shape of tha data\nprint('Train shape: ', train.shape)\nprint('Test shape: ', test.shape)","e8f6d61a":"train.columns","89c15390":"#Check for duplicates\nprint(train.duplicated().value_counts())\nprint(\"There are no duplicates.\")","4a336b81":"train.head(5)","d9ed2f2c":"train.describe()\n#Apparently only 38% Survived","d079bdb0":"test.head(5)","ad13507d":"X_train = train.drop(['Survived'], axis=1)\ny_train = train['Survived']","fddeaad3":"#Checking nulls\nX_train.info()","2bd83139":"X_train.describe()","e5355fc8":"y_train.value_counts()\n# 0: not survived\n# 1: survived","03c68865":"#Let's look at Pclass's distribution\nax = sns.countplot(x=y_train, palette=\"husl\")\nplt.title(\"Count of Survived\")\nplt.show()","3be54103":"print(\"Percentage of survived:\", round(len(y_train[y_train==1])\/len(y_train), 2)*100)","e194b168":"#Pclass\nX_train['Pclass'].value_counts()","9f2be47a":"#Let's look at Pclass's distribution\nax = sns.countplot(x=\"Pclass\", data=X_train, palette=\"husl\")\nplt.title(\"Count of Pclass\")\nplt.show()","9d24c177":"sur = train[train[\"Survived\"]==1]\nprint(\"Percentage of survivals in class 1:\", round(len(sur[sur[\"Pclass\"]==1])\/len(train[train.Pclass == 1].Survived), 2))\nprint(\"Percentage of survivals in class 2:\", round(len(sur[sur[\"Pclass\"]==2])\/len(train[train.Pclass == 2].Survived), 2))\nprint(\"Percentage of survivals in class 3:\", round(len(sur[sur[\"Pclass\"]==3])\/len(train[train.Pclass == 3].Survived), 2))","1566026e":"X_train['Sex'].value_counts()","4273ac0b":"#Let's look at sex's distribution\nax = sns.countplot(x=\"Sex\", data=X_train, palette=\"husl\")\nplt.title(\"Count of sex\")\nplt.show()","e028e2fe":"sur = train[train[\"Survived\"]==1]\nprint(\"Percentage of female survivals:\", round(len(sur[sur[\"Sex\"]==\"female\"])\/len(train[train.Sex == 'female'].Survived), 2))\nprint(\"Percentage of male survivals:\", round(len(sur[sur[\"Sex\"]==\"male\"])\/len(train[train.Sex == 'male'].Survived), 2))","22cb535c":"def age_group_convert(df):\n    return pd.DataFrame(pd.cut(df.Age, [0, 15, 30, 50, 100], labels=[\"0-15\", \"15-30\", \"30-50\", \"50-100\"]))\n\ntrain[\"Age_bins\"] = age_group_convert(train)","7c30b22f":"train[\"Age_bins\"].value_counts()","d88289ca":"#Let's look at age's distribution\nax = sns.countplot(x=\"Age_bins\", data=train, palette=\"husl\")\nplt.title(\"Count of sex\")\nplt.show()","65674e88":"sur = train[train[\"Survived\"]==1]\nprint(\"Percentage of 0-15 year survivals:\", round(len(sur[sur[\"Age_bins\"]==\"0-15\"])\/len(train[train.Age_bins == \"0-15\"].Survived), 2))\nprint(\"Percentage of 15-30 year survivals:\", round(len(sur[sur[\"Age_bins\"]==\"15-30\"])\/len(train[train.Age_bins == \"15-30\"].Survived), 2))\nprint(\"Percentage of 30-50 year survivals:\", round(len(sur[sur[\"Age_bins\"]==\"30-50\"])\/len(train[train.Age_bins == \"30-50\"].Survived), 2))\nprint(\"Percentage of 50-100 year survivals:\", round(len(sur[sur[\"Age_bins\"]==\"50-100\"])\/len(train[train.Age_bins == \"50-100\"].Survived), 2))","d8be79b7":"train[\"SibSp\"].value_counts()","052976f3":"#Let's look at sibSp's distribution\nax = sns.countplot(x=\"SibSp\", data=train, palette=\"husl\")\nplt.title(\"Count of sex\")\nplt.show()","5b197885":"sur = train[train[\"Survived\"]==1]\nprint(\"Percentage of survivals of SibSp equal to 0 :\", round(len(sur[sur[\"SibSp\"]==0])\/len(train[train.SibSp == 0].Survived), 2))\nprint(\"Percentage of survivals of SibSp equal to 1:\", round(len(sur[sur[\"SibSp\"]==1])\/len(train[train.SibSp == 1].Survived), 2))\n","f6d108fa":"train[\"Embarked\"].value_counts()","2a19dc9f":"#Let's look at Embarked's distribution\nax = sns.countplot(x=\"Embarked\", data=train, palette=\"husl\")\nplt.title(\"Count of sex\")\nplt.show()","d94a185c":"sur = train[train[\"Survived\"]==1]\nprint(\"Percentage of survivals of Embarked in Southampton:\", round(len(sur[sur[\"Embarked\"]==\"S\"])\/len(train[train.Embarked == \"S\"].Survived), 2))\nprint(\"Percentage of survivals of  Embarked in Cherbourg:\", round(len(sur[sur[\"Embarked\"]==\"C\"])\/len(train[train.Embarked == \"C\"].Survived), 2))\nprint(\"Percentage of survivals of Embarked in Queenstown:\", round(len(sur[sur[\"Embarked\"]==\"Q\"])\/len(train[train.Embarked == \"Q\"].Survived), 2))\n","3018f278":"display(train.corr().style.background_gradient(cmap='YlGnBu'))","c2d3ab7f":"from sklearn import set_config; set_config(display='diagram')\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, FunctionTransformer, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.compose import make_column_selector\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import FeatureUnion\nimport pickle\nimport joblib\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.cluster import KMeans","e2f88923":"#When having numerical and categorical features they need different transformations\nfrom sklearn import set_config; set_config(display='diagram')\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, FunctionTransformer, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.compose import make_column_selector\nfrom sklearn.impute import SimpleImputer\n\nnumeric_features = [ 'Fare', 'Age']\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_features = ['Embarked', 'Sex', 'Pclass']\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown=\"ignore\"))\n])\n\npreprocessor= ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)\n    ])","156348b4":"data_prepared = preprocessor.fit_transform(train)\ndf = pd.DataFrame(data_prepared)\ndf.head(5)","dae91890":"df.shape","5516ae4d":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\n\n#Use it with a classifier\/regressor\nlogit_model_pipeline = Pipeline([\n    ('preprocessor', preprocessor),\n    ('logit', LogisticRegression())\n])\n\nlogit_model_pipeline","ee9402f2":"from sklearn.metrics import precision_score, recall_score, f1_score\n\nlogit_model_pipeline.fit(X_train, y_train)\ny_pred = logit_model_pipeline.predict(X_train)\n\nprint(\"The precision score of Logit model is {}\".format(precision_score(y_train, y_pred)))\nprint(\"The recall score of Logit model is {}\".format(recall_score(y_train, y_pred)))\nprint(\"The f1 score of Logit model is {}\".format(f1_score(y_train, y_pred)))","75415106":"#An example\nX_new = pd.DataFrame({\n    'PassengerId': 892,\n    'Pclass': 1,\n    'Name': 'Marie',\n    'Sex': 'female',\n    'Age': 24,\n    'SibSp': 0,\n    'Parch': 0,\n    'Ticket': 'PC 15990',\n    'Fare': 8,\n    'Cabin': 'C100',\n    'Embarked': 'C'}, index=[0])\nX_new","d6949564":"logit_model_pipeline.predict(X_new)\n#It was predicted as survived.","fc498172":"print(\"Thank you for your time :) \")","48fe806e":"#### Sex","785ea848":"#### SibSp","5bf76f69":"## Train the Model","96c52f75":"63% of 1st class passengers survived, which is higher than the other classes, but not that much.","6d9477d0":"#### Pclass","35ce3544":"#### Correlations","4c9ffe98":"Apparently, 54% of the passegenrs that survived have 1 siblings \/ spouses aboard the Titanic","a3b8b15b":"Seems like people between 0 and 15 years survived almost 60%. From the 30-50, 42% survived.","1656e851":"#### Survived (Target variable)","53bfc414":"From the survivals, 74% were woman.","8bfef45f":"#### Embarked","06afad80":"#### Age"}}