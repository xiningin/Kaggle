{"cell_type":{"047c4480":"code","df87cd7d":"code","f098b631":"code","aa4b17e3":"code","2f6771f4":"code","ac6f9406":"code","98fce736":"code","c09bd5b3":"code","16974e35":"code","04426f16":"code","0bb82e1b":"code","471bb83d":"code","824c9315":"code","fed14b3e":"code","b1c8e1c1":"markdown"},"source":{"047c4480":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom keras import utils\nfrom keras.layers import Dropout\nfrom keras.models import Sequential\nfrom keras.initializers import RandomNormal\nfrom keras.layers import Dense, Activation, Dropout\nfrom keras.layers.normalization import BatchNormalization\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","df87cd7d":"# Reading train and test data\ntrain_df = pd.read_csv(\"..\/input\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/test.csv\")","f098b631":"# Shape of train and test data\nprint(\"Train data shape: {}\\n Test data shape: {}\".format(train_df.shape, test_df.shape))","aa4b17e3":"train_df.head()","2f6771f4":"X_train = train_df.drop(\"label\", axis = 1)\nY_train = train_df[\"label\"]\nX_test = test_df\nprint(X_train.shape, Y_train.shape, X_test.shape)","ac6f9406":"# If we observe each cell value is between 0-255 so we need to normalize it.\ntrain_df[41970:41980] ","98fce736":"# Normalization \n# x = x - min(x) \/ max(x) - min(x)\nX_train = X_train\/255\nX_test = X_test\/255","c09bd5b3":"# Here, we have class name(0- 9) for each image\nprint(\"Class label for 4th image is: \", Y_train[4])\n# We need to convert it into 10 dimension vector\nY_train = utils.to_categorical(Y_train, 10)\nprint(\"After converting output into 10 dim is: \", Y_train[4])","16974e35":"# Define model parameter\ninput_dim = X_train.shape[1]\noutput_dim = 10\nbatch_size = 128\nnb_epoch = 20","04426f16":"# 2 hidden layer with batch normalization and dropout layer\n# MLP + relu + BN + Dropout \nmodel = Sequential()\n\nmodel.add(Dense(434, activation = \"relu\", input_shape = (input_dim,), kernel_initializer = RandomNormal(mean = 0.0, stddev = 0.039, seed = None)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0,5))\n\nmodel.add(Dense(391, activation = \"relu\", input_shape = (input_dim,), kernel_initializer = RandomNormal(mean = 0.0, stddev = 0.039, seed = None)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(141, activation = \"relu\", input_shape = (input_dim,), kernel_initializer = RandomNormal(mean = 0.0, stddev = 0.039, seed = None)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(output_dim, activation = \"softmax\"))\n\nmodel.summary()","0bb82e1b":"# Training\nmodel.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\nmodel_fit = model.fit(X_train, Y_train, batch_size = batch_size, epochs = nb_epoch, verbose = 1)","471bb83d":"# Test Prediction\npred = model.predict_classes(X_test, verbose=0)\npred","824c9315":"# Train Score\nscore = model.evaluate(X_train, Y_train, verbose = 0) \nprint(score)\nprint('Train score:', score[0]) \nprint('Train accuracy:', score[1])","fed14b3e":"# Submission\nsample_submission = pd.DataFrame({\"ImageId\": list(range(1, len(pred) + 1)), \"Label\" : pred})\nsample_submission.to_csv(\"sample_submission.csv\", index=False)","b1c8e1c1":"**NOTE:-** This kernel just shows very basic implementation of MLP on MNIST using keras but will update it soon for more accurate prediction. If you like this kernel please upvote and have any question please comment below in comment box I would love to answer your question."}}