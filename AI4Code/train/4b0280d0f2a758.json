{"cell_type":{"e0971884":"code","ba1ae49d":"code","d5d80c9a":"code","6d5f1706":"code","77455fe4":"code","e42fecbc":"code","a6ef9c4b":"code","e21d30bf":"code","f2965614":"code","c3314b3b":"code","8d2ccdbb":"code","88f939f5":"code","dd9644d5":"code","38218824":"code","0229daac":"code","10817254":"code","bf84aefb":"code","5b78ac4e":"code","973cc3bf":"code","e46dbd40":"code","f065e07a":"code","dea8eb10":"code","a5c6aa3c":"code","7dacaaf0":"code","848be802":"code","2762c4be":"code","a6dd682c":"code","aa036abb":"code","2d02c82a":"code","72611e85":"code","335d6cf2":"code","8423fadf":"code","69dcb6ea":"code","90cdb6c5":"code","dafaf80d":"code","51402820":"code","91f91b23":"markdown","093d7a1a":"markdown","1d4e4b1e":"markdown","e5142222":"markdown","4589d42e":"markdown","767ec0e7":"markdown","e551aba8":"markdown","3072eed3":"markdown","5b84badc":"markdown","2f331002":"markdown","00d93db9":"markdown","2fe6c400":"markdown","a1c818ad":"markdown","ee82dc23":"markdown","fa98117d":"markdown"},"source":{"e0971884":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport datetime\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ba1ae49d":"df = pd.read_csv(\"..\/input\/argentina-venta-de-propiedades\/ar_properties.csv\",index_col=\"id\").dropna(subset=[\"price\",\"currency\"])","d5d80c9a":"df_alq_ar = df[(df[\"operation_type\"]==\"Alquiler\") & (df[\"l1\"]==\"Argentina\")]","6d5f1706":"df_alq_ar.columns","77455fe4":"df_alq_ar[df_alq_ar[\"currency\"]==\"USD\"]\n","e42fecbc":"features = [\"created_on\",\"lat\", \"lon\", \"rooms\", \n\"bathrooms\", \"surface_covered\", \"surface_total\", \"price_period\", \"property_type\",\"price\", \"currency\"]\ndf_alq_ar_reducido = df_alq_ar[features]","a6ef9c4b":"df_alq_ar_reducido.isnull().sum()\/df_alq_ar_reducido.shape[0]","e21d30bf":"df_alq_ar_reducido[\"price_period\"].value_counts()","f2965614":"df_alq_ar_reducido = df_alq_ar_reducido.drop(\"price_period\",axis=1)","c3314b3b":"df_alq_ar_reducido.info(verbose=True)","8d2ccdbb":"df_alq_ar_reducido.loc[:,\"created_on\"] = pd.to_datetime(df_alq_ar_reducido[\"created_on\"],format=\"%Y-%m-%d\")\ndf_alq_ar_reducido = df_alq_ar_reducido.sort_values(\"created_on\")","88f939f5":"df_alq_ar_reducido","dd9644d5":"min_date = df_alq_ar_reducido[\"created_on\"][0]\nmax_date = df_alq_ar_reducido[\"created_on\"].tail(1)[0]\nprint(\"First recorded date: \", min_date, \"Last recorded date: \", max_date)\nyear_diff_to_end = df_alq_ar_reducido[\"created_on\"].apply(lambda x: x.year)-max_date.year\nmonth_diff_to_end = df_alq_ar_reducido[\"created_on\"].apply(lambda x: x.month) - max_date.month\n\nmonth_diff = month_diff_to_end + year_diff_to_end * 12\nprint(\"Month differences to last date: \\n\", month_diff.values)","38218824":"df_alq_ar_reducido[\"created_on\"]=-month_diff","0229daac":"df_alq_ar_reducido = df_alq_ar_reducido.rename(columns={\"created_on\":\"mo_dist_to_last\"})","10817254":"index_inDollars = (df_alq_ar_reducido[\"currency\"]==\"USD\")\ndf_alq_ar_reducido.loc[index_inDollars, \"price\"] = df_alq_ar_reducido.loc[index_inDollars,\"price\"]*150\ndf_alq_ar_reducido = df_alq_ar_reducido.rename(columns={\"currency\":\"original_currency\"})\ndf_alq_ar_reducido = df_alq_ar_reducido[(df_alq_ar_reducido[\"original_currency\"]==\"ARS\") | (df_alq_ar_reducido[\"original_currency\"]==\"USD\") ]\ndf_alq_ar_reducido[\"original_currency\"][(df_alq_ar_reducido[\"original_currency\"]==\"USD\")] = 1\ndf_alq_ar_reducido[\"original_currency\"][(df_alq_ar_reducido[\"original_currency\"]==\"ARS\")] = 0","bf84aefb":"df_alq_ar_reducido[\"original_currency\"] = df_alq_ar_reducido[\"original_currency\"].astype(\"int\")","5b78ac4e":"df_alq_ar_reducido[df_alq_ar_reducido[\"original_currency\"]==\"USD\"]","973cc3bf":"df_alq_ar_reducido[df_alq_ar_reducido[\"mo_dist_to_last\"]<3]","e46dbd40":"df_alq_ar_reducido.info()","f065e07a":"df_alq_ar_reducido[\"original_currency\"].value_counts()","dea8eb10":"df_alq_ar_reducido.dropna(subset=[\"lat\", \"lon\", \"surface_covered\"]).isnull().sum()\/df_alq_ar_reducido.dropna(subset=[\"lat\", \"lon\", \"rooms\", \"bathrooms\"]).shape[0]","a5c6aa3c":"df0 = df_alq_ar_reducido[[\"mo_dist_to_last\",\"lat\", \"lon\", \"rooms\", \"bathrooms\",\"surface_covered\",\"surface_total\",\"original_currency\", \"property_type\",\"price\"]]\ndf1 = df0\ndf2 = df_alq_ar_reducido[[\"mo_dist_to_last\",\"lat\", \"lon\", \"rooms\", \"bathrooms\",\"surface_covered\",\"original_currency\", \"property_type\",\"price\"]]\ndf3 = df2\ndf4 = df_alq_ar_reducido[[\"mo_dist_to_last\",\"lat\", \"lon\", \"rooms\", \"bathrooms\",\"original_currency\", \"property_type\",\"price\"]]\ndf5 = df4","7dacaaf0":"from sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\ndef potentialTrainingDataGenerator(df, colsToDrop, colsToImpute, categoricalCols, nMonthsConsidered):\n    \"\"\"Given a dataframe with missing values on some rows, remove the rows or impute them as indicated by the parameters, \n    then return the data ready to be used for training\"\"\"\n    ##Drop rows with missing...\n    df = df.dropna(subset=colsToDrop)\n    df = df[df[\"mo_dist_to_last\"]<nMonthsConsidered]\n    ## Split into train and test for posterior imputation\n    X = df.drop(columns=[\"price\"])\n    y = df[\"price\"]\n    X_train, X_test, y_train, y_test = train_test_split(X, y)\n    ## Encode\n    encoder = OneHotEncoder(handle_unknown=\"ignore\",sparse=False)\n    X_train_encoded_cat = pd.DataFrame(encoder.fit_transform(X_train[categoricalCols]))\n    X_test_encoded_cat = pd.DataFrame(encoder.transform(X_test[categoricalCols]))\n    ## recover indexes\n    X_train_encoded_cat.index = X_train[categoricalCols].index\n    X_test_encoded_cat.index = X_test[categoricalCols].index\n    \n    ## reinsert encoded\n    X_train = X_train.drop(categoricalCols, axis=1)\n    X_test = X_test.drop(categoricalCols, axis=1)\n    \n    X_train = pd.concat([X_train, X_train_encoded_cat], axis=1)\n    X_test = pd.concat([X_test, X_test_encoded_cat], axis=1)\n    ## impute missing values for the median\n    imputer = SimpleImputer(strategy='median')\n    \n    X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), index = X_train.index)\n    X_test_imputed = pd.DataFrame(imputer.transform(X_test), index = X_test.index)\n    \n    X_train_imputed.columns = X_train.columns\n    X_test_imputed.columns = X_train.columns\n    \n    return X_train_imputed, X_test_imputed, y_train, y_test","848be802":"X_train_5a, X_test_5a, y_train_5a, y_test_5a = potentialTrainingDataGenerator(df5, [\"lat\", \"lon\", \"rooms\",\"bathrooms\"], [], [\"property_type\"], 3)\n\nX_train_5b, X_test_5b, y_train_5b, y_test_5b = potentialTrainingDataGenerator(df5, [\"lat\", \"lon\", \"rooms\", \"bathrooms\"], [], [\"property_type\"], 14)","2762c4be":"X_train_5a","a6dd682c":"X_train_4a, X_test_4a, y_train_4a, y_test_4a = potentialTrainingDataGenerator(df4, [\"lat\", \"lon\", \"rooms\"], [\"bathrooms\"], [\"property_type\"], 3)\n\nX_train_4b, X_test_4b, y_train_4b, y_test_4b = potentialTrainingDataGenerator(df4, [\"lat\", \"lon\", \"rooms\"], [\"bathrooms\"], [\"property_type\"], 14)","aa036abb":"X_train_3a, X_test_3a, y_train_3a, y_test_3a = potentialTrainingDataGenerator(df3, [\"lat\", \"lon\", \"rooms\", \"surface_covered\"], [\"bathrooms\"], [\"property_type\"], 3)\n\nX_train_3b, X_test_3b, y_train_3b, y_test_3b = potentialTrainingDataGenerator(df3, [\"lat\", \"lon\", \"rooms\", \"surface_covered\"], [\"bathrooms\"], [\"property_type\"], 14)","2d02c82a":"X_train_2a, X_test_2a, y_train_2a, y_test_2a = potentialTrainingDataGenerator(df2, [\"lat\", \"lon\", \"surface_covered\"], [\"bathrooms\",\"rooms\"], [\"property_type\"], 3)\n\nX_train_2b, X_test_2b, y_train_2b, y_test_2b = potentialTrainingDataGenerator(df2, [\"lat\", \"lon\", \"surface_covered\"], [\"bathrooms\", \"rooms\"], [\"property_type\"], 14)","72611e85":"X_train_1a, X_test_1a, y_train_1a, y_test_1a = potentialTrainingDataGenerator(df1, [\"lat\", \"lon\",\"surface_total\"], [\"bathrooms\",\"rooms\",\"surface_covered\"], [\"property_type\"], 3)\n\nX_train_1b, X_test_1b, y_train_1b, y_test_1b = potentialTrainingDataGenerator(df1, [\"lat\", \"lon\", \"surface_total\"], [\"bathrooms\", \"rooms\",\"surface_covered\"], [\"property_type\"], 14)","335d6cf2":"X_train_1a","8423fadf":"X_train_0a, X_test_0a, y_train_0a, y_test_0a = potentialTrainingDataGenerator(df0, [\"lat\", \"lon\", \"surface_covered\",\"surface_total\"], [\"bathrooms\",\"rooms\"], [\"property_type\"], 3)\n\nX_train_0b, X_test_0b, y_train_0b, y_test_0b = potentialTrainingDataGenerator(df0, [\"lat\", \"lon\", \"surface_covered\",\"surface_total\"], [\"bathrooms\", \"rooms\"], [\"property_type\"], 14)","69dcb6ea":"# def adjustByInflation(df):\n    ","90cdb6c5":"import pickle","dafaf80d":"cero_a = [(X_train_0a,\"X_train_0a\"), (X_test_0a,\"X_test_0a\"), (y_train_0a,\"y_train_0a\"), (y_test_0a,\"y_test_0a\")]\none_a = [(X_train_1a,\"X_train_1a\"), (X_test_1a,\"X_test_1a\"), (y_train_1a,\"y_train_1a\"), (y_test_1a,\"y_test_1a\")]\ntwo_a = [(X_train_2a,\"X_train_2a\"), (X_test_2a,\"X_test_2a\"), (y_train_2a,\"y_train_2a\"), (y_test_2a,\"y_test_2a\")]\nthree_a = [(X_train_3a,\"X_train_3a\"), (X_test_3a,\"X_test_3a\"), (y_train_3a,\"y_train_3a\"), (y_test_3a,\"y_test_3a\")]\nfour_a = [(X_train_4a,\"X_train_4a\"), (X_test_4a,\"X_test_4a\"), (y_train_4a,\"y_train_4a\"), (y_test_4a,\"y_test_4a\")]\nfive_a = [(X_train_5a,\"X_train_5a\"), (X_test_5a,\"X_test_5a\"), (y_train_5a,\"y_train_5a\"), (y_test_5a,\"y_test_5a\")]\nA = [cero_a,one_a,two_a,three_a,four_a,five_a]\ncero_b = [(X_train_0b,\"X_train_0b\"), (X_test_0b,\"X_test_0b\"), (y_train_0b,\"y_train_0b\"), (y_test_0b,\"y_test_0b\")]\none_b = [(X_train_1b,\"X_train_1b\"), (X_test_1b,\"X_test_1b\"), (y_train_1b,\"y_train_1b\"), (y_test_1b,\"y_test_1b\")]\ntwo_b = [(X_train_2b,\"X_train_2b\"), (X_test_2b,\"X_test_2b\"), (y_train_2b,\"y_train_2b\"), (y_test_2b,\"y_test_2b\")]\nthree_b = [(X_train_3b,\"X_train_3b\"), (X_test_3b,\"X_test_3b\"), (y_train_3b,\"y_train_3b\"), (y_test_3b,\"y_test_3b\")]\nfour_b = [(X_train_4b,\"X_train_4b\"), (X_test_4b,\"X_test_4b\"), (y_train_4b,\"y_train_4b\"), (y_test_4b,\"y_test_4b\")]\nfive_b = [(X_train_5b,\"X_train_5b\"), (X_test_5b,\"X_test_5b\"), (y_train_5b,\"y_train_5b\"), (y_test_5b,\"y_test_5b\")]\nB = [cero_b,one_b,two_b,three_b,four_b,five_b]\n","51402820":"for k in A:\n    for i in k:\n        i[0].to_csv(i[1]+\".csv\")","91f91b23":"# Data import, visualization and initial feature selection <a id=\"divaifs\"><\/a>","093d7a1a":"Todos los alquileres son mensuales y es costumbre que as\u00ed lo sea en Ar, por eso voy a imputar los valores faltantes de \"price_period\" por mensual. Esto es lo mismo que directamente tirar la columna.","1d4e4b1e":"*Table of contents*\n\n1. [Data import, analysis and initial feature selection](#divaifs)\n2. [Datetime conversion and currency conversion](#dcarva)\n3. [Variations of training dataframes (real value adjustments (by inflation)?)](#ptd)\n4. [<font color=\"red\">Adjustment by inflation<\/font>](#abi)\n5. [Data export](#de)","e5142222":"We'll rename the dataframe to make it more simple...","4589d42e":"S\u00f3lo tenemos una columna no-num\u00e9rica y es el tipo de propiedad... Que adem\u00e1s no tiene datos faltantes en absoluto lo cual viene muy bien.","767ec0e7":"# Cleaning & adjusting geolocated data for regressor house rent estimators","e551aba8":"0. \"mo_dist_to_last\",\"lat\", \"lon\", \"original_currency\",\"rooms\", \"bathrooms\", \"surface_covered\", \"surface_total\", \"property_type\" (drop missing surfaces & lat\/lon, impute for the mean in everything else) \n1. \"mo_dist_to_last\",\"lat\", \"lon\", \"original_currency\", \"rooms\", \"bathrooms\", \"surface_covered\", \"surface_total\", \"property_type\" (drop lat, lon and surface total misising, impute covered, rooms andbathrooms)","3072eed3":"# Datetime conversion and real value adjustments <a id=\"dcarva\"><\/a>","5b84badc":"## We'll:\n    1. Convert to datetime\n    2. Sort by date\n    3. replace column for \"months away from last one registered\" (pick a better name)\nThe reason for this is that we may want to adjust by domain inflation all of the prices, so that all of the rent values are updated.","2f331002":"# Variations of training dataframes <a id=\"ptd\"><\/a>\n\nDifferent dataframes to be tested:  \nA: Only last 3 months\n\nB: All months considered\n\n0. \"mo_dist_to_last\",\"lat\", \"lon\", \"original_currency\",\"rooms\", \"bathrooms\", \"surface_covered\", \"surface_total\", \"property_type\" (drop missing surfaces & lat\/lon, impute for the mean in everything else) \n1. \"mo_dist_to_last\",\"lat\", \"lon\", \"original_currency\", \"rooms\", \"bathrooms\", \"surface_covered\", \"surface_total\", \"property_type\" (drop lat, lon and surface total misising, impute covered, rooms andbathrooms)\n2. \"mo_dist_to_last\",\"lat\", \"lon\", \"original_currency\", \"rooms\", \"bathrooms\", \"surface_covered\", \"property_type\"(drop lat\/lon and surface missing, imputation on the mean for rooms and bathrooms)\n3. \"mo_dist_to_last\",\"lat\", \"lon\", \"original_currency\", \"rooms\", \"bathrooms\", \"surface_covered\", \"property_type\"(drop lat\/lon, rooms and surface missing, imputation on the median for bathrooms)\n4. \"mo_dist_to_last\",\"lat\", \"lon\", \"original_currency\", \"rooms\", \"bathrooms\", \"property_type\" (drop lat\/lon and rooms missing, impute missing bathrooms for the median)\n5. \"mo_dist_to_last\",\"lat\", \"lon\", \"original_currency\", \"rooms\", \"bathrooms\", \"property_type\" (drop lat\/lon, rooms and bathrooms missing)\n\n\n<font color=\"red\">Idea de ajuste de precios: convertir todo a dolares del mes al que pertenecen y multiplicar por valor actual del dolar paralelo<\/font>","00d93db9":"## First feature selection  \nImportant features: lat, lon, rooms, bathrooms, surface_covered, \u00bfsurface total? (correlated to covered), price period, property type, currency.  \n\nWe picked lat\/lon because we'll perform predictions with a KNN algorithm. This information is more than enough to drop all of the rest location-related columns. The advantage of this is that if we instead pick the labeled categorical locations we will end up unnecesarily creating hundreds of new columns when converting categoricals to numerical values. Bedrooms are not important since this info is very highly correlated to rooms and bathrooms and Argentines do not value it as a metric (domain specific knowledge).","2fe6c400":"This wasn't yet done because I'll assume that the model can detect inflationary patterns from the \"mo_dist_to_last\" column\n\nidea:\n1. map locations to regions\n2. ","a1c818ad":"# Adjustment by inflation <a id=\"abi\"><\/a>","ee82dc23":"Different dataframes to be tested:  \n0. \"created_on\",\"lat\", \"lon\", \"rooms\", \"bathrooms\", \"surface_covered\", \"surface_total\", \"price_period\", \"property_type\" (drop missing surfaces, impute for the mean in everything else) \n1. \"created_on\",\"lat\", \"lon\", \"rooms\", \"bathrooms\", \"surface_covered\", \"surface_total\", \"price_period\", \"property_type\"  \n2. \"created_on\",\"lat\", \"lon\", \"rooms\", \"bathrooms\", \"surface_covered\", \"price_period\", \"property_type\"(drop lat\/lon missing, imputation on the mean for rooms, bathrooms and surface)\n3. \"created_on\",\"lat\", \"lon\", \"rooms\", \"bathrooms\", \"surface_covered\", \"price_period\", \"property_type\"(drop lat\/lon &rooms missing, imputation on the mean for bathrooms)\n4. \"created_on\",\"lat\", \"lon\", \"rooms\", \"bathrooms\", \"price_period\", \"property_type\" (drop lat\/lon missing)  ","fa98117d":"# Data export <a id=\"de\"><\/a>"}}