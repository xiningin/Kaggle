{"cell_type":{"61c70d52":"code","87bb6922":"code","f7949554":"code","92906f79":"code","7e7494e0":"code","9e3d978e":"code","4d1cc8c9":"code","b799a3da":"code","9eb69ef0":"code","6440d009":"code","fbdd97d6":"code","3b569090":"code","339bfcc8":"code","38a56d78":"code","a921bc96":"code","e2ae6a93":"code","f643a61c":"code","58b6ddeb":"code","45ba6049":"code","14d70b79":"code","5a27d5ca":"code","223da7f5":"code","b16dbbd1":"code","b481d47b":"markdown","627efab5":"markdown","e276fc76":"markdown","61e4f45c":"markdown","7216c32c":"markdown","8117ba3f":"markdown","223dd90b":"markdown","08251cb1":"markdown","069d4fd8":"markdown","3097128e":"markdown","69f9fc86":"markdown","3d501a26":"markdown","f4bcf74b":"markdown","e4d1cd53":"markdown","cf7abfb4":"markdown","df1706e0":"markdown","a61a59da":"markdown","df1af9c0":"markdown","0376ea2a":"markdown"},"source":{"61c70d52":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport matplotlib.pyplot as plt\n\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","87bb6922":"calendar = pd.read_csv('..\/input\/calendar.csv')\ncalendar.head()","f7949554":"calendar['date']=pd.to_datetime(calendar['date'])\ncalendar.head()","92906f79":"calendar_available = calendar[calendar['available']=='t']\ncalendar_available['price_cleaned'] = calendar_available['price'].str.replace('$','').apply(pd.to_numeric, errors='coerce')\ncalendar_available.index = calendar_available['date']\ncalendar_available = calendar_available.drop(columns=['date','available','price'])","7e7494e0":"mean_price = calendar_available.groupby(calendar_available.index).mean().drop(columns='listing_id')\nmean_price.plot()\nax = plt.ylabel('mean price ($)')","9e3d978e":"from dateutil.relativedelta import relativedelta\nimport statsmodels.api as sm  \nfrom statsmodels.tsa.stattools import acf  \nfrom statsmodels.tsa.stattools import pacf\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\ndecomposition = seasonal_decompose(mean_price) \ndecomposition.plot()\nplt.show()","4d1cc8c9":"from statsmodels.tsa.stattools import adfuller\n\ndef test_stationarity(timeseries):\n    \n    #Determing rolling statistics\n    rolmean = timeseries.rolling(window=7).mean()\n    rolstd = timeseries.rolling(window=7).std()\n\n    #Plot rolling statistics:\n    fig = plt.figure(figsize=(12, 8))\n    orig = plt.plot(timeseries, color='blue',label='Original')\n    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n    plt.legend(loc='best')\n    plt.title('Rolling Mean & Standard Deviation')\n    plt.show()\n    \n    #Perform Dickey-Fuller test:\n    print('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print(dfoutput)","b799a3da":"test_stationarity(mean_price.price_cleaned)","9eb69ef0":"price_diff = mean_price.diff().dropna()\ntest_stationarity(price_diff.price_cleaned)","6440d009":"import itertools\nimport warnings\n\ndef parameter_search_sarimax(timeseries,s):\n    lowest_aic = None\n    lowest_parm = None\n    lowest_param_seasonal = None\n    \n    p = D = q = range(0, 3)\n    d = [1, 2]\n    pdq = list(itertools.product(p, d, q))\n    seasonal_pdq = [(x[0], x[1], x[2], s) for x in list(itertools.product(p, D, q))]\n\n    warnings.filterwarnings('ignore') # specify to ignore warning messages\n\n    for param in pdq:\n        for param_seasonal in seasonal_pdq:\n            try:\n                mod = sm.tsa.statespace.SARIMAX(timeseries,\n                                                order=param,\n                                                seasonal_order=param_seasonal,\n                                                enforce_stationarity=False,\n                                                enforce_invertibility=False)\n\n                results = mod.fit()\n                \n                # Store results\n                current_aic = results.aic\n                # Set baseline for aic\n                if (lowest_aic == None):\n                    lowest_aic = results.aic\n                # Compare results\n                if (current_aic <= lowest_aic):\n                    lowest_aic = current_aic\n                    lowest_parm = param\n                    lowest_param_seasonal = param_seasonal\n\n                print('SARIMA{}x{} - AIC:{}'.format(param, param_seasonal, results.aic))\n            except:\n                continue\n            \n    print('The best model is: SARIMA{}x{} - AIC:{}'.format(lowest_parm, lowest_param_seasonal, lowest_aic))","fbdd97d6":"parameter_search_sarimax(mean_price,12)","3b569090":"def model_run_validate(parameter):\n\n    mod = sm.tsa.statespace.SARIMAX(mean_price,\n                                    order=(parameter[0], parameter[1], parameter[2]),\n                                    seasonal_order=(parameter[3], parameter[4], parameter[5], parameter[6]),\n                                    enforce_stationarity=False,\n                                    enforce_invertibility=False)\n\n    results = mod.fit(maxiter=200)\n\n    print(results.summary().tables[1])\n\n    results.plot_diagnostics(figsize=(15, 12))\n\n    pred_start_date = '2016-12-20'\n    pred_dynamic = results.get_prediction(start=pd.to_datetime(pred_start_date), dynamic=True, full_results=True)\n    pred_dynamic_ci = pred_dynamic.conf_int()\n\n    ax = mean_price.plot(label='Observed', figsize=(20, 15))\n    pred_dynamic.predicted_mean.plot(label='Dynamic Forecast', ax=ax)\n\n    ax.fill_between(pred_dynamic_ci.index,\n                    pred_dynamic_ci.iloc[:, 0],\n                    pred_dynamic_ci.iloc[:, 1], color='k', alpha=.25)\n\n    ax.fill_betweenx(ax.get_ylim(), pd.to_datetime(pred_start_date), mean_price.index[-1],\n                     alpha=.1, zorder=-1)\n\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Mean Price ($)')\n    ax.legend()","339bfcc8":"parameter = [2,1,2,2,1,1,12]\nmodel_run_validate(parameter)","38a56d78":"parameter_search_sarimax(mean_price,7)","a921bc96":"parameter = [0,1,2,2,1,2,7]\nmodel_run_validate(parameter)","e2ae6a93":"parameter = [2,1,1,2,1,2,7]\nmodel_run_validate(parameter)","f643a61c":"def run_model_forecast(parameter):\n    \n    mod = sm.tsa.statespace.SARIMAX(mean_price,\n                                    order=(parameter[0], parameter[1], parameter[2]),\n                                    seasonal_order=(parameter[3], parameter[4], parameter[5], parameter[6]),\n                                    enforce_stationarity=False,\n                                    enforce_invertibility=False)\n\n    results = mod.fit(maxiter=200)\n    \n    pred_uc = results.get_forecast(steps=60)\n    pred_ci = pred_uc.conf_int()\n    \n    ax = mean_price.price_cleaned.plot(label='Observed', figsize=(20, 15))\n    pred_uc.predicted_mean.plot(ax=ax, label='Forecast')\n    ax.fill_between(pred_ci.index,\n                    pred_ci.iloc[:, 0],\n                    pred_ci.iloc[:, 1], color='k', alpha=.25)\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Mean Price ($)')\n    ax.legend()","58b6ddeb":"parameter = [2,1,1,2,1,2,7]\nrun_model_forecast(parameter)","45ba6049":"parameter = [0,1,2,2,1,2,7]\nrun_model_forecast(parameter)","14d70b79":"parameter = [2,1,2,1,1,2,28]\nmodel_run_validate(parameter)","5a27d5ca":"run_model_forecast(parameter)","223da7f5":"parameter = [2,1,0,2,2,0,84]\nmodel_run_validate(parameter)","b16dbbd1":"run_model_forecast(parameter)","b481d47b":"There are many possible ways to have a good representation of the price data in any given day. Let us try with average\/mean from all listings.","627efab5":"After we got the \"optimum\" parameters, it is necessary to validate the model. Here, we will predict part of the time series starting from mid December 2016. We also check if the assumption made by SARIMA model were met for the particular parameter.","e276fc76":"Let us forecast the next 2 months (60 steps) based on the model parameter.","61e4f45c":"# Time series data pre-processing\n\nThe price time series is only available from calendar.csv, so let us concern with that particular data for now.","7216c32c":"Not bad. Still plausible. How about using s=84?","8117ba3f":"From above test, the test statistics is larger than the critical value. Hence, we can't reject the null hypotheses. In other words, the time series is not stationary.\n\nOne way to make the data stationary is to difference the time series.","223dd90b":"For s, or seasonality, parameter we can give a test for different values. Let us try with 12 as many other examples used.","08251cb1":"Here the test statistics is less than critical values. So, first order differencing is actually sufficient for the data.\n\n# Time Series Forecasting\n\nTo do forecasting, we would like to use SARIMA model. This is available in statsmodel package as sarimax. However, It is quite tedious to find the optimum model parameters manually, since there are 6 + 1 parameters needed. We can write the parameter space as (p, d, q) x (P, D, Q, s).\n\nTo do it in a more automated fashion, let us test using Akaike Information Criterion (AIC) as the objective function. In other words, the lower the AIC value, the better the parameters because the model fits better to the data. AIC is preferred over measure such as root mean square error (RMSE) because AIC has penalty for model complexity. The more complex the data, the higher the AIC value. With this approach, we hope that the best bias vs variance tradeoff can be achieved.\n\nNote that we have checked that at least first order differencing is necessary for the data to be stationary. Since SARIMA assume time series stationarity, we can set d parameter search only from 1, not from zero.","069d4fd8":"Let us convert date from string\/object to pandas datetime for easy handling later.","3097128e":"Price is also still in string\/object, hence let us change it into numeric. It is also useful to set the date as index, and later clean up the columns not needed.\n\nFor now, we only take the price when it is available.","69f9fc86":"It appears that by choosing s as 7, the residual is not much correlated anymore. However, the model may be too simple since it use p=0. It would be interesting to try the parameters with the second lowest AIC.\n\nSARIMA(2, 1, 1)x(2, 1, 2, 7) - AIC:841.5884052299125","3d501a26":"First try with the last retrieved parameter, and second try with the previously simpler model.","f4bcf74b":"Not too bad. The fit is good. Residual is almost normally distributed, too. However, from correlogram, it is apparent that the autocorrelation reveals that the residual is still quite correlated. This invalidates one of the assumption for SARIMA model.\n\nTime lag of 7 days shows the strongest correlation. It is suggestive that the period of seasonality is 7 days. Hence, let us try with s=7.","e4d1cd53":"Unfortunately, the trend during the validated part is a mismatch of the observed trend. The residual is also correlated quite strongly now.\n\nThe forecast below also does not look good.","cf7abfb4":"It is apparent that the time series is not stationary. A more formal way rather than visual inspection is by using statistics test, e.g. Dickey-Fuller test, to check whether is it appropriate to reject null hypothesis of the data is not stationary.","df1706e0":"So it seems monthly seasonality, s=28, works well and includes also weekly, s=7, seasonality. But 3-monthly is not.\n\nHowever, we noted that the data is limited to only one year. Hence, year by year trend is not available to be learnt from the data. We should take the forecasting result with a grain of salt and make the model relearn if a more complete data is available. If at least 2 years data is available, we can try annual seasonality.","a61a59da":"# Time series stationarity\n\nIt is obvious that there is a seasonal trend. However, let us look at the decomposed time series to be clear.","df1af9c0":"Not too bad fit. Using s=28 also takes care the 7 days seasonality, since the autocorrelation is still low. Let us see how the forecast goes.","0376ea2a":"Both seems plausible. \n\nIt would be interesting to check integer multiplication of this weekly seasonality.\nWe can run again the parameter_search_sarimax using monthly seasonality, i.e. s=28. It is also interesting to check 3monthly, s= 84. To save on running[](http:\/\/) time, we only do validation and forecast using the retrieved parameter values and skip the parameter search from this kernel."}}