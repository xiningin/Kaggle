{"cell_type":{"61b17b25":"code","68fddf57":"code","e88ecdb3":"code","d087c6c3":"code","f8257fd7":"code","30eaa8a8":"code","5b6cf321":"code","2e34a88f":"code","dc358ec3":"code","84ee8854":"code","0735efb4":"code","b158fa89":"code","cac93355":"code","c18e0da8":"code","fcd18540":"code","9a65bc4d":"code","2f23f4f8":"code","ae79eb21":"code","59982fe0":"code","6ca3884d":"code","9faabeae":"code","97725c8b":"code","df361286":"code","de5a52ee":"code","bd9cfc03":"code","b2b4bea5":"code","89220425":"code","138366cb":"code","00e4513c":"code","73714dec":"code","bb2b970d":"code","89f85809":"code","9bcbf1eb":"code","4ff951b8":"code","71599ed0":"code","8e525f94":"code","fe12583e":"code","7e5bbc51":"code","c08cc2b2":"markdown","747d473d":"markdown","d23c28f7":"markdown","1963cde0":"markdown","d041c383":"markdown","6d203967":"markdown","67b20124":"markdown","5bd12e9e":"markdown","2b6b4e82":"markdown","d45b633f":"markdown","162a5355":"markdown","bed6d632":"markdown","cfd79ea9":"markdown","237fc48d":"markdown","3fd103b9":"markdown","0bdcf944":"markdown","739a318a":"markdown","591d96bd":"markdown","b0326440":"markdown","832e0c53":"markdown","5ba3f608":"markdown","83f41d90":"markdown","7d3e13ef":"markdown","a8d7928e":"markdown","3f72204f":"markdown","b30f204f":"markdown","680cad7b":"markdown","c3f25888":"markdown"},"source":{"61b17b25":"# import required libraries for dataframe and visualization\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime as dt\n\n# import required libraries for clustering\nimport sklearn\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score","68fddf57":"# Read data\ndata = pd.read_csv('..\/input\/online-retail-customer-clustering\/OnlineRetail.csv',encoding=\"ISO-8859-1\")\nprint(data.head())","e88ecdb3":"# shape\nprint(data.shape)","d087c6c3":"# data description\nprint(data.describe())","f8257fd7":"# Calculate missing values % in original data\ndata_null = round(100 * (data.isnull().sum()) \/ len(data), 2)\nprint(data_null)","30eaa8a8":"# Drop rows with missing values\ndata = data.dropna()\nprint(data.shape)","5b6cf321":"# Change data type of Customer Id; they are not numeric in essence\ndata['CustomerID'] = data['CustomerID'].astype(str)","2e34a88f":"# New Attribute : Recency\n# Reformat datetime\ndata['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'], format='%d-%m-%Y %H:%M')\nprint(data['InvoiceDate'])","dc358ec3":"# Compute the difference between most recent date and transaction date\ndata['Diff'] = max(data['InvoiceDate']) - data['InvoiceDate']\nprint(data.head())","84ee8854":"# Compute last transaction date to get the recency of customers\nrfm_r = data.groupby('CustomerID', as_index=False)['Diff'].min()","0735efb4":"# Extract number of days only\nrfm_r['Diff'] = rfm_r['Diff'].dt.days\nrfm_r.columns = ['CustomerID', 'Recency']\nprint(rfm_r.head())","b158fa89":"# New Attribute : Frequency\nrfm_f = data.groupby('CustomerID', as_index=False)['InvoiceNo'].count()\nrfm_f.columns = ['CustomerID', 'Frequency']\nprint(rfm_f.head())","cac93355":"# New Attribute : Monetary\ndata['Amount'] = data['Quantity'] * data['UnitPrice']\nrfm_m = data.groupby('CustomerID', as_index=False)['Amount'].sum()\nrfm_m.columns = ['CustomerID', 'Amount']\nprint(rfm_m.head())","c18e0da8":"# Combine R, F, M\nrfm = pd.concat((rfm_r['Recency'], rfm_f['Frequency'], rfm_m['Amount']), axis=1)\nprint(rfm.head())","fcd18540":"# Remove negative amounts (excluding goods refund)\nrfm = rfm[rfm.Amount > 0]","9a65bc4d":"# Standardize data\nfrom sklearn.preprocessing import StandardScaler\n\n# Store original column names and data\nkeys = rfm.keys()\nrfm_unscaled = rfm\n\n# Scale rfm\nscaler = StandardScaler()\nrfm = scaler.fit_transform(rfm)\nrfm = pd.DataFrame(rfm, columns=keys)\nprint(rfm.head())","2f23f4f8":"# Remove values outside mean +\/- 3 std range\nfor key in rfm.keys():\n    mean = np.mean(rfm[key])\n    std = np.std(rfm[key])\n    rfm = rfm[np.abs(rfm[key] - mean) \/ std <= 3]","ae79eb21":"# Draw elbow curve to find optimal K value\n# 2 <= i <= 10\ninertia = {}\nfor i in range(2, 11):\n    kmeans = KMeans(n_clusters=i, max_iter=1000)\n    kmeans.fit(rfm)\n    inertia[i] = kmeans.inertia_\n\nfor k, v in inertia.items():\n    print(str(k), ': ', str(v))","59982fe0":"# Plot for each K value\nplt.subplots()\nplt.plot(list(inertia.values()), 'b+-')\nplt.show()","6ca3884d":"# # Silhouette analysis\nfor num_clusters in range(2,10):\n    kmeans = KMeans(n_clusters=num_clusters, max_iter=1000)\n    kmeans.fit(rfm)\n    cluster_labels = kmeans.labels_\n    \n    silhouette_avg = silhouette_score(rfm, cluster_labels)\n    print(\"For n_clusters={0}, the silhouette score is {1:.4f}\".format(num_clusters, silhouette_avg))","9faabeae":"# Final model with k=3\nkmeans = KMeans(n_clusters=3, max_iter=1000)\nkmeans.fit(rfm)\nprint(kmeans.labels_)","97725c8b":"# Assign label\nrfm['Cluster_Id'] = kmeans.labels_\nprint(rfm.head())\nprint(rfm.shape)","df361286":"# Scatter plot\nplt.subplots()\nplt.scatter(x=rfm['Recency'], y=rfm['Amount'], c=rfm['Cluster_Id'], alpha=0.4)\nplt.xlabel('Recency')\nplt.ylabel('Amount')\nplt.title(\"Clustering: Recency vs Amount\")\n\nplt.subplots()\nplt.scatter(x=rfm['Frequency'], y=rfm['Amount'], c=rfm['Cluster_Id'], alpha=0.4)\nplt.xlabel('Frequency')\nplt.ylabel('Amount')\nplt.title(\"Clustering: Frequency vs Amount\")\n\nplt.subplots()\nplt.scatter(x=rfm['Frequency'], y=rfm['Recency'], c=rfm['Cluster_Id'], alpha=0.4)\nplt.xlabel('Frequency')\nplt.ylabel('Recency')\nplt.title(\"Clustering: Frequency vs Recency\")","de5a52ee":"# Create 3D scatter plot\nfrom mpl_toolkits.mplot3d import Axes3D\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(xs=rfm['Recency'], ys=rfm['Frequency'], zs=rfm['Amount'], c=rfm['Cluster_Id'])\n\nplt.title('RFM Clustering')\nax.set_xlabel('Recency')\nax.set_ylabel('Frequency')\nax.set_zlabel('Amount')","bd9cfc03":"# Restore rfm\nrfm = rfm_unscaled\nprint(rfm.head())\n\n","b2b4bea5":"# Remove values outside mean +\/- 3 std range\nfor key in rfm.keys():\n    mean = np.mean(rfm[key])\n    std = np.std(rfm[key])\n    rfm = rfm[np.abs(rfm[key] - mean) \/ std <= 3]\n","89220425":"# Refit model with k=3 to unscaled rfm\nkmeans = KMeans(n_clusters=3, max_iter=1000)\nkmeans.fit(rfm)\nprint(kmeans.labels_)","138366cb":"# Assign label\nrfm['Cluster_Id'] = kmeans.labels_\nprint(rfm.head())\nprint(rfm.shape)","00e4513c":"# Create a new data frame for cluster analysis\ncluster_sale = rfm.groupby('Cluster_Id', as_index=False)['Amount'].sum()\ncluster_sale.columns = ['ClusterId', 'Revenue']","73714dec":"# Count the number of customers by their cluster id\ncluster_sale['CustomerCount'] = rfm['Cluster_Id'].value_counts()\ncluster_sale['Customer%'] = cluster_sale['CustomerCount'] \/ sum(cluster_sale['CustomerCount'])","bb2b970d":"# Calculate the average recency of customers\ncluster_sale['MeanRecency'] = rfm.groupby('Cluster_Id', as_index=False)['Recency'].mean()['Recency']","89f85809":"# Calculate the number of transactions done by clusters\ncluster_sale['TransactionCount'] = rfm.groupby('Cluster_Id', as_index=False)['Frequency'].sum()['Frequency']\ncluster_sale['Transaction%'] = cluster_sale['TransactionCount'] \/ sum(cluster_sale['TransactionCount'])","9bcbf1eb":"# Calculate the average number of times customers do shopping\ncluster_sale['MeanFrequency'] = cluster_sale['TransactionCount'] \/ cluster_sale['CustomerCount']","4ff951b8":"# Calculate the percentage of total revenue by clusters\ncluster_sale['Revenue%'] = cluster_sale['Revenue'] \/ sum(cluster_sale['Revenue'])","71599ed0":"# Calculate average revenue per transaction\ncluster_sale['ARPT'] = cluster_sale['Revenue'] \/ cluster_sale['TransactionCount']","8e525f94":"# Calculate average revenue per customer\ncluster_sale['ARPC'] = cluster_sale['Revenue'] \/ cluster_sale['CustomerCount']","fe12583e":"# Reorganize columns for easier reading\ncluster_sale = cluster_sale[\n    ['ClusterId', 'CustomerCount', 'Customer%', 'MeanRecency', 'MeanFrequency', 'Revenue', 'Revenue%',\n     'TransactionCount', 'Transaction%', 'ARPT', 'ARPC']]","7e5bbc51":"print(cluster_sale.head())","c08cc2b2":"Calculate amount (monetary)","747d473d":"<a id=\"1\"><\/a> <br>\n## Step 1 : Reading and Understanding Data","d23c28f7":"The elbow curve is close to a linear function after K value of 3, which indicates that adding more centroids may not result in better clustering outcomes. Therefore, K should be set to 3 according to the elbow curve.","1963cde0":"#### We are going to analysis the Customers based on below 3 factors:\n- R (Recency): Number of days since last purchase\n- F (Frequency): Number of transactions\n- M (Monetary): Total spending by customers (revenue)","d041c383":"We can also draw scatter plots with colored clusters","6d203967":"<a id=\"5\"><\/a> <br>\n## Step 5 : Business Insight","67b20124":"However, just looking at the elbow curve above can only give us an imprecise estimation of K value. To have more comfort in the K value of 3 that we have selected, we can do a Silhouette analysis.","5bd12e9e":"This notebook is based on the work of Manish Kumar's [Kaggle kernel](https:\/\/www.kaggle.com\/hellbuoy\/online-retail-k-means-hierarchical-clustering). He has done a great job in the organization of the whole kernel. ","2b6b4e82":"<a id=\"3\"><\/a> <br>\n## Step 3 : Data Preparation","d45b633f":"# Qualitative Analysis of Clustering Result\nThis 3D scatter graph clearly shows that our K-Means clustering algorithm has successfully segmented all customers into three distinct categories:\n\n* Category 1: \n\nColor: green\n\nNumber: quite a lot\n\nPurchase frequency: low\n\nAmount of spending: low\n\nRecency: vary\n\n* Category 2:\n\nColor: purple\n\nNumber: many\n\nPurchase frequency: low to mid\n\nAmount of spending: low to mid\n\nRecency: low\n\n\n* Category 3:\n\nColor: yellow\n\nNumber: few\n\nPurchase frequency: vary\n\nAmount of spending: high\n\nRecency: low\n","162a5355":"#### Elbow Curve to get the right number of Clusters\nA fundamental step for any unsupervised algorithm is to determine the optimal number of clusters into which the data may be clustered. The Elbow Method is one of the most popular methods to determine this optimal value of k.","bed6d632":"Well, these 2D plots may not be intutive enough for you guys. So, why not draw a 3D plot to visualize which group our customers belong to, after we computing three variables of R, F, and M? ","cfd79ea9":"If this Notebook helps you get a better understanding of K-Means clustering and unsupervised learning, please give me a <font color=\"orange\"><b>UPVOTE<\/b><\/font>. ","237fc48d":"### Finding the Optimal Number of Clusters","3fd103b9":"<a id=\"4\"><\/a> <br>\n## Step 4 : Building K-Means Model","0bdcf944":"K-means clustering is one of the simplest and popular unsupervised machine learning algorithms.<br>\n\nThe algorithm works as follows:\n\n1. Randomly initialize k points as the center of clustering (\"centroid\")\n2. Categorize each data point to the closest centroid\n3. For each centroid, update its coordinate to be the average of all points categorized to it. \n3. Repeat step 2&3 for a given number of iterations and use the centroid location with the lowest error (sum of distance from all data points in a cluster to the cluster centroid), as the optimal choice of centroid location and final output. ","739a318a":"Calculate frequency","591d96bd":"We have already learned that a small number of large customers have contributed a great portion of sale revenue, and it is worth our time and some further coding to explore our customer structure in terms of three clusters.","b0326440":"We remove outliers that are outside 3-sigma range, as part of data preprocessing","832e0c53":"Calculate recency","5ba3f608":"### K-Means Clustering","83f41d90":"These box plots show our algorithm actually works quite well in that there is only small overlap between clusters, which means none of three clusters is redundant.","7d3e13ef":"# Interpretation of result\n\n**Cluster 0 are mostly one-time, infrequent customers**\n\n1. They are the great majority of customers (83%) but only contribute slightly more than 40% of total revenue. Their transaction amount per invoice is quite low, at 13 dollars.\n\n2. On average, the last time they shop online is about 102 days ago. \n\n3. They only shop occasionally in that during the period studied, a typical class-0 customer places about 50 orders in total.\n\n**Cluster 1 are general customers**\n\n1. They are about 14% of all customers and the second largest source of income (40%)\n\n2. Average recency is about 30 days ago. \n\n3. They shop often with average 210 orders per person.\n\n**Cluster 2 are frequent, high-value customers\/wholesalers**\n\n1. There are only 93 cluster-2 customers who makes up just 2% of total customers and 9% of total transactions, but more than 18% of total revenue come from them. \n\n2. They also love shopping and spend much more in total. Their average purchase amount per transaction is about 36 dollars, which is the highest among all three customer groups. Their mean total spending amount is more than 11,500 dollars. \n\n3. They buy quite often with 17 days mean recency. They shop almost every day: an average class-2 customer shop 321 times in the past year. ","a8d7928e":"If this Notebook helps you get a better understanding of K-Means clustering and unsupervised learning, please give me a <font color=\"orange\"><b>UPVOTE<\/b><\/font>. ","3f72204f":"<a id=\"2\"><\/a> <br>\n## Step 2 : Data Cleaning","b30f204f":"### Silhouette Analysis\n\n$$\\text{silhouette score}=\\frac{p-q}{max(p,q)}$$\n\n$p$ is the mean distance to the points in the nearest cluster that the data point is not a part of\n\n$q$ is the mean intra-cluster distance to all the points in its own cluster.\n\n* The value of the silhouette score range lies between -1 to 1. \n\n* A score closer to 1 indicates that the data point is very similar to other data points in the cluster, \n\n* A score closer to -1 indicates that the data point is not similar to the data points in its cluster.\n\n**Rule: Higher score is better.**","680cad7b":"## Project Overview\nOnline retail is a Kaggle data set<\/a> which contains all the transactions occurring between 01\/12\/2010 and 09\/12\/2011 for a UK-based and registered online-only retail. The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.\n\n## Our Goal\nWe will conduct a RFM analysis on the company's customers and thus better understand our customers' buying preference.\n\n#### The steps are broadly divided into:\n\n1. [Step 1: Reading and Understanding Data](#1)\n1. [Step 2: Data Cleaning](#2)\n1. [Step 3: Data Preparation](#3)\n1. [Step 4: Building K-Means Model](#4)\n1. [Step 5: Business Insight](#5)","c3f25888":"Although K=2 is the number of K with the highest score, from the perspective of business and for easier interpretation, we continue to adopt 3 as the K value. \nYou will see how K=3 works out in the later sections of this article."}}