{"cell_type":{"bad627c2":"code","5bfef7fd":"code","e5340cb7":"code","a02a0106":"code","1589e41d":"code","ac764090":"code","00d2b41c":"code","6e9805fd":"code","177c449d":"code","0048d323":"code","7d2074ff":"code","9cb4bfee":"code","64f4022d":"code","3055ff2a":"code","6b457d51":"code","8f8ad929":"code","dba4a4ad":"code","c86e26d1":"code","4b658e4b":"code","534ee066":"code","d8bbdcd5":"code","552e2df0":"code","4463ef3a":"code","7797847c":"markdown","59c2c16a":"markdown","906fdb49":"markdown","dfa83c76":"markdown","4341a5dd":"markdown","32fba420":"markdown","8fa64839":"markdown","f02eaedd":"markdown","e9d427dd":"markdown","9fc90ed6":"markdown","21f470f1":"markdown","ef67175a":"markdown","6977d0b9":"markdown"},"source":{"bad627c2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5bfef7fd":"os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\n\nassert tf.__version__=='2.6.0' , 'This notebook was made with tensorflow version 2.6.0. If you still decide to run notebook then some features may break.'","e5340cb7":"data = pd.read_csv('\/kaggle\/input\/az-handwritten-alphabets-in-csv-format\/A_Z Handwritten Data.csv', dtype='float32')\ndata.columns  = ['labels'] + [i for i in range(1, 784+1)]","a02a0106":"data.head()","1589e41d":"data.describe()","ac764090":"data.info(verbose=False, show_counts=True)","00d2b41c":"current_image_no = 1\nno_samples, no_columns = 2, 8\nno_rows = 26\/no_columns*no_samples +1\nfig = plt.figure(figsize=(28*no_columns, 28*no_rows))\n\n\nfor char_label in range(0, 26):    \n    for sample_image in data[data.iloc[0:, 0]==char_label].sample(n=no_samples).iloc[0:, 1:].to_numpy(): #data[data.iloc[0:, 0]==char_label].iloc[0:no_samples, 1:].to_numpy()\n        sample_image = sample_image.reshape(28, 28)\n        fig.add_subplot(no_rows,\n                        no_columns,\n                        current_image_no)\n        plt.title(chr(ord('A') + char_label), fontsize=40)\n        plt.imshow(sample_image)\n        current_image_no += 1\n        \nplt.show()\n        ","6e9805fd":"x = data['labels'].astype('int16').value_counts()#.sort_values(axis='index')\nlabels=[]\nfor i in x.index:\n    label = chr(ord('A') + i)\n    labels.append(label)\nx.index = labels\n\nplt.figure(figsize=[15, 5])\nsns.barplot(x=x.index, y=x.values)\n\nplt.show()","177c449d":"plt.figure(figsize=[10, 10])\nplt.pie(x.values, labels=x.index, startangle=90, shadow=False, explode=(0.1,)*23 + (0.5, 0.7, 0.8),)\nplt.show()","0048d323":"train_set, val_test_set = train_test_split(data, stratify=data['labels'], test_size=0.3, random_state=42)\nval_set, test_set = train_test_split(val_test_set, stratify=val_test_set['labels'], test_size=0.4, random_state=42)","7d2074ff":"del data, val_test_set","9cb4bfee":"BATCH_SIZE = 20\nAUTO = tf.data.AUTOTUNE\n\ntrain_set = tf.data.Dataset.from_tensor_slices((train_set.iloc[0:, 1:], train_set.iloc[0:, 0])).batch(BATCH_SIZE).prefetch(AUTO)\nval_set = tf.data.Dataset.from_tensor_slices((val_set.iloc[0:, 1:], val_set.iloc[0:, 0])).batch(BATCH_SIZE).prefetch(AUTO)\ntest_set = tf.data.Dataset.from_tensor_slices((test_set.iloc[0:, 1:], test_set.iloc[0:, 0])).batch(BATCH_SIZE).prefetch(AUTO)","64f4022d":"print(f'Length of Training set:  {len(train_set)}')\nprint(f'Length of Validation set:  {len(val_set)}')\nprint(f'Length of Test set:  {len(test_set)}')","3055ff2a":"def squash(vector, axis=-1, epsilon=1e-7):\n    squared_norm = tf.math.reduce_sum(tf.square(vector), axis=axis, keepdims=True)\n    norm = tf.sqrt(squared_norm + epsilon)\n    unit_vector = vector\/norm\n    return squared_norm\/(1 + squared_norm) * unit_vector\n\nclass CapsuleLayer(tf.keras.layers.Layer):\n    \n    '''\n        params:\n            num_caps - no of capsule in this layer\n            dim_caps - dimesion of each capsule\n            routing_rounds - no of routing rounds\n            initializer - intializer used to intialize weights of this layer\n    '''\n    def __init__(self, num_caps, dim_caps, routing_rounds=3, initializer='glorot_uniform', **kwargs):\n        super(CapsuleLayer, self).__init__(**kwargs)\n        self.num_caps = num_caps\n        self.dim_caps = dim_caps \n        self.routing_rounds = routing_rounds\n        self.initializer = tf.keras.initializers.get(initializer)\n    \n    \n    def build(self, input_shape):\n        self.batch_size = input_shape[0]\n        self.num_in_caps = input_shape[1] # no of capsule in previous layer\n        self.dim_in_caps = input_shape[2] # dimension of capsules in previous layer\n        \n        self.weight = self.add_weight(shape=[1, self.num_in_caps, self.num_caps,\n                                            self.dim_caps, self.dim_in_caps],\n                                     initializer=self.initializer,\n                                     trainable=True, name='W')\n    \n   \n    def call(self, inputs):                          # input shape = [None, num_in_caps, dim_in_caps]\n        inputs_ = tf.expand_dims(inputs, -2)         # shape = [None, num_in_caps, 1, dim_in_caps]\n        inputs_ = tf.expand_dims(inputs_, -1)        # shape = [None, num_in_caps, 1, dim_in_caps, 1]\n        input_hats = tf.matmul(self.weight, inputs_) # shape = [None, num_in_caps, num_caps, dim_caps, 1]\n        \n        raw_weights = tf.zeros(shape=[tf.shape(inputs)[0], self.num_in_caps, self.num_caps, 1, 1])\n        for _ in range(self.routing_rounds):\n            routing_weights = tf.math.softmax(raw_weights)\n            weighted_sum = tf.math.reduce_sum(\n                        tf.math.multiply(routing_weights, input_hats),\n                        axis=1,\n                        keepdims=True) # shape = [None, 1, num_caps, dim_caps, 1]\n            output = squash(weighted_sum, axis=-2)\n            raw_weights+=output\n           \n        return tf.squeeze(output) # shape = [None, num_caps, dim_caps]\n    \n    def compute_output_shape(self, input_shape):\n        return tuple([None, self.num_caps, self.dim_caps])\n    \n    def get_config(self):\n        config = {\n            'num_caps': self.num_caps,\n            'dim_caps': self.dim_caps,\n            'routing_rounds': self.routing_rounds, \n            'initializer': self.initializer\n        }\n        base_config = super(CapsuleLayer, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n        \n    ","6b457d51":"def safe_norm(vector, axis=-1, epsilon=1e-7, keep_dims=False):\n    squared_norm = tf.math.reduce_sum(tf.math.square(vector), axis=axis, keepdims=keep_dims)\n    return tf.math.sqrt(squared_norm + epsilon)\n\nclass CustomPredictionLayer(tf.keras.layers.Layer):\n    def call(self, inputs):\n        y_prob = safe_norm(inputs, axis=-1)\n        y_prob_max = tf.math.argmax(y_prob, axis=1)\n        return y_prob_max","8f8ad929":"class Classifier(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super().__init__(self, **kwargs)\n        self.input_layer = tf.keras.layers.InputLayer(input_shape=(784), batch_size=BATCH_SIZE)\n        self.conv_layer_1 = tf.keras.layers.Conv2D(filters=256, kernel_size=9, strides=1,\n                                                   padding='valid', activation='relu')\n        self.conv_layer_2 = tf.keras.layers.Conv2D(filters=32 * 8, kernel_size=9, strides=2,\n                                                   padding='valid', activation='relu')\n        self.caps_layer = CapsuleLayer(num_caps=26, dim_caps=16) \n        \n    \n    def call(self, inputs, training=None):\n        input_ = self.input_layer(inputs)\n        reshaped = tf.reshape(input_, shape=[-1, 28, 28, 1])\n        \n        conv1 = self.conv_layer_1(reshaped, training=training)\n        conv2 = self.conv_layer_2(conv1, training=training)\n        \n        reshaped = tf.reshape(conv2, shape=[-1, 1152, 8]) \n        squashed = squash(reshaped)\n        final_caps_layer_output = self.caps_layer(squashed, training=training)\n        return final_caps_layer_output","dba4a4ad":"class Masking(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super().__init__(self, **kwargs)\n        self.custom_pred_layer = CustomPredictionLayer()\n    \n    def call(self, inputs, training=None):\n        if training:\n            pre_model_out = inputs[0]\n            labels = inputs[1]\n        else: \n            pre_model_out = inputs\n            labels = self.custom_pred_layer(inputs)\n        \n        pre_model_out = tf.reshape(pre_model_out, shape=[-1, 26, 16])\n        mask = tf.one_hot(tf.cast(labels, dtype='int64'), 26)\n        mask = tf.reshape(mask,shape=[-1, 26, 1])\n\n        return tf.reshape(tf.multiply(pre_model_out, mask), shape=[-1, 26*16])\n         ","c86e26d1":"class Decoder(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.masking = Masking()\n        self.dense1 = tf.keras.layers.Dense(600, activation='elu')\n        self.dense2 = tf.keras.layers.Dense(1500, activation='elu')\n        self.dense3 = tf.keras.layers.Dense(784, activation='elu')\n                        \n    def call(self, inputs, training=None):\n        z = self.masking(inputs, training=training)\n        z = self.dense1(z, training=training)\n        z = self.dense2(z, training=training)\n        return self.dense3(z, training=training)","4b658e4b":"loss_tracker = tf.keras.metrics.Mean()\nacc_metric = tf.keras.metrics.Accuracy()\n\nclass CapsNets(tf.keras.Model):\n    def __init__(self, **kwargs):\n        super(CapsNets, self).__init__(**kwargs)\n        self.classifier = Classifier()\n        self.decoder = Decoder()\n        self.predict_class_layer = CustomPredictionLayer()\n     \n    def __margin_loss(self, labels, previous_caplayer_output, m_plus=0.9, m_minus=0.1, lambda_=0.5):\n        out = previous_caplayer_output\n        out_norm = safe_norm(out, keep_dims=True)\n        labels = tf.cast(labels, dtype='int64')\n        \n        caps_last_layer = tf.shape(previous_caplayer_output)[1]\n        one_hot = tf.one_hot(labels, depth=caps_last_layer)\n        \n        present_error_raw = tf.square(tf.maximum(0., m_plus - out_norm),)\n        present_error = tf.reshape(present_error_raw, shape=(-1, tf.shape(out)[1])) \n        \n        absent_error_raw = tf.square(tf.maximum(0., out_norm - m_minus))\n        absent_error = tf.reshape(absent_error_raw, shape=(-1, tf.shape(out)[1]))\n        \n        L = tf.add(one_hot * present_error, lambda_ * (1.0 - one_hot) * absent_error)\n        return tf.reduce_mean(tf.reduce_sum(L, axis=1)) \n    \n    \n    def __reconstruction_loss(self, org, reconstruction):\n        org_flat = tf.reshape(org, [-1, 784])\n        squared_diff = tf.math.square(org_flat-reconstruction)\n        return tf.math.reduce_mean(squared_diff)\n    \n    \n    \n    def __final_loss(self, mar_loss, rec_loss, alpha=0.0005):\n        return tf.math.add(mar_loss, alpha*rec_loss)\n    \n    def train_step(self, data):\n        x, y = data\n        \n        with tf.GradientTape() as tape:\n            classifier_output = self.classifier(x, training=True)\n            mar_loss = self.__margin_loss(y, classifier_output)\n            \n            y_pred = self.predict_class_layer(classifier_output)\n            \n            decoder_output = self.decoder((classifier_output, y), training=True)\n            rec_loss = self.__reconstruction_loss(x, decoder_output)\n            \n            final_loss = self.__final_loss(mar_loss, rec_loss)\n        \n        trainable_vars = self.trainable_variables\n        gradients = tape.gradient(final_loss, trainable_vars)\n        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n        \n        loss_tracker.update_state(final_loss)\n        acc_metric.update_state(y, y_pred)\n        return {\"loss\": loss_tracker.result(), \"acc\": acc_metric.result()}\n\n    @property\n    def metrics(self):\n        return [loss_tracker, acc_metric]\n    \n    def test_step(self, data):\n        x, y = data\n        classifier_output = self.classifier(x, training=False)\n        y_pred = self.predict_class_layer(classifier_output)\n        decoder_output = self.decoder(classifier_output, training=False)\n        \n        mar_loss = self.__margin_loss(y, classifier_output)\n        rec_loss = self.__reconstruction_loss(x, decoder_output)  \n        final_loss = self.__final_loss(mar_loss, rec_loss)\n        \n        loss_tracker.update_state(final_loss)\n        acc_metric.update_state(y, y_pred)\n        return {\"loss\": loss_tracker.result(), \"acc\": acc_metric.result()}\n    \n    def predict(self, image):\n        classifier_output = self.classifier(image)\n        if (tf.shape(tf.shape(classifier_output))<=2):\n            classifier_output = tf.expand_dims(classifier_output, 0)\n        label = self.predict_class_layer(classifier_output)\n        reconstruction = self.decoder(classifier_output)\n        return label, reconstruction","534ee066":"gpus = tf.config.list_logical_devices('GPU')\nstrategy = tf.distribute.MirroredStrategy(gpus)\nwith strategy.scope():\n    model = CapsNets()\n    optimizer = tf.keras.optimizers.Adam()\n    model.compile(optimizer=optimizer)","d8bbdcd5":"early_stopping = tf.keras.callbacks.EarlyStopping(patience=1, restore_best_weights=True)\nhistory = model.fit(train_set, epochs=3, validation_data=val_set.take(len(val_set)-1), callbacks=[early_stopping])","552e2df0":"model.evaluate(test_set)","4463ef3a":"for image, label in test_set.unbatch().shuffle(2000).take(20):\n    image = tf.reshape(image, shape=[1, 28, 28 ,1])\n    label, reconstructed_image = model.predict(image)\n    print(f\"Predicted Label is: {chr(ord('A') + label)}\")\n    image = tf.reshape(image, shape=[28, 28])\n    plt.imshow(image)\n    plt.title('Orignal Image')\n    plt.show()\n    reconstructed_image = tf.reshape(reconstructed_image, shape=[28, 28])\n    plt.imshow(reconstructed_image)\n    plt.title('Reconstructed Image')\n    plt.show()\n    print('**************************************************************************************\\n**************************************************************************************\\n')","7797847c":"The data set does not have any null value. You see it yourself by setting the verbose to true.","59c2c16a":"# Visualization","906fdb49":"The code below will show print label, orginal image and reconstructed image for 20 random image from test set","dfa83c76":"The code below will show random images from each category. The number of images from each category is equal to variable no_sample.","4341a5dd":"#### Capsule Layer ","32fba420":"# Model","8fa64839":"#### Masking","f02eaedd":"# Model Components","e9d427dd":"#### Decoder","9fc90ed6":"The bar graph below will represent the number of images in each category.","21f470f1":"# Loading data ","ef67175a":"Just so to know the proportion of each category to each other more easily. We are going to use a pie plot.","6977d0b9":"# Spliting the data"}}