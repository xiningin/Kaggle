{"cell_type":{"aaf87f37":"code","18709a99":"code","bfd344c5":"code","841b20e2":"code","9c2f0549":"code","f2ad9ec8":"code","12fe7468":"code","46e7fdce":"code","71921aaf":"code","6efedaa2":"code","7337b2e7":"code","5b59abc5":"code","62a3251e":"code","85e9e811":"code","d0a07a8f":"code","e4ca0f7f":"code","07e44b06":"code","165b81d9":"code","99528d93":"code","80a004a1":"code","a6849bff":"code","1a246e88":"code","2476ab19":"code","98d2d997":"code","462494a5":"code","446da2c9":"code","acb2b27c":"code","55747f6b":"code","bf8a8f31":"code","7e65a1eb":"code","c554ce70":"code","30768235":"code","4fffa7d6":"code","a08c15f4":"code","d5a6de2f":"code","cc2451cc":"markdown","15ff1ef6":"markdown","76d192d7":"markdown","9493f7e3":"markdown","2377e156":"markdown","3f65f689":"markdown","efeafc81":"markdown","6410c297":"markdown","131cb832":"markdown","b23f3f3b":"markdown","4dc4492d":"markdown","d1705b2b":"markdown","af110c77":"markdown","2613c3d4":"markdown","7e71d1d0":"markdown","10ffda78":"markdown","9e9e6cd9":"markdown","d7a9ea91":"markdown","1a0ed047":"markdown","89afd531":"markdown","1e707059":"markdown","7aeb4d59":"markdown","612cd29b":"markdown","04ef1864":"markdown","99f2b0ca":"markdown","d1d7125e":"markdown","6950fb0d":"markdown","e22844bf":"markdown","72023a50":"markdown"},"source":{"aaf87f37":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","18709a99":"df = pd.read_csv('..\/input\/avacado-price-prediction\/Avocado.csv')","bfd344c5":"df.shape","841b20e2":"df.head()","9c2f0549":"# Drop unnecessary feature\n\ndf = df.drop('Unnamed: 0', axis=1)","f2ad9ec8":"# Check Null Values\n\ndf.isnull().sum()","12fe7468":"df.describe()","46e7fdce":"background_color = '#F8EDF4'\ncolor_palette = ['#F78904', '#00C73C', '#D2125E', '#693AF9', '#B20600', '#007CDE', '#994936', '#886A00', '#39BBC2']","71921aaf":"fig = plt.figure(figsize=(15, 12))\ngs = fig.add_gridspec(3, 2)\ngs.update(hspace=0.2, wspace=0.3)\n\nax0 = fig.add_subplot(gs[0, 0])\nax1 = fig.add_subplot(gs[0, 1])\nax2 = fig.add_subplot(gs[1, 0])\nax3 = fig.add_subplot(gs[1, 1])\nax4 = fig.add_subplot(gs[2, 0])\nax5 = fig.add_subplot(gs[2, 1])\nfig.patch.set_facecolor(background_color)\n\naxes = [ax0, ax1, ax2, ax3, ax4, ax5]\n\n\n# Title1\nax0.text(0.5, 0.5, 'Distribution of AveragePrice\\n____________________',\n        horizontalalignment='center',\n        verticalalignment='center',\n        fontsize=18, fontweight='bold', fontfamily='serif')\n\n# Graph1\nsns.kdeplot(x='AveragePrice', data=df, fill=True, ax=ax1, color=color_palette[0])\n\n\n\n# Title2\nax2.text(0.5, 0.5, 'Distribution of AveragePrice\\nby Type\\n____________________',\n        horizontalalignment='center',\n        verticalalignment='center',\n        fontsize=18, fontweight='bold', fontfamily='serif')\n\n# Graph2\nsns.kdeplot(x='AveragePrice', data=df, fill=True, hue='type', ax=ax3, palette=color_palette[:2])\n\n\n\n# Title3\nax4.text(0.5, 0.5, 'Distribution of AveragePrice\\nby Year\\n____________________',\n        horizontalalignment='center',\n        verticalalignment='center',\n        fontsize=18, fontweight='bold', fontfamily='serif')\n\n# Graph3\nsns.kdeplot(x='AveragePrice', data=df, fill=True, hue='year', ax=ax5, palette=color_palette[:4])\n\n\n\n# Settings\nfor ax in axes:\n    ax.set_facecolor(background_color)\n    for s in ['top', 'right', 'left']:\n        ax.spines[s].set_visible(False)\n\nfor ax in [ax0, ax2, ax4]:\n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    ax.tick_params(left=False, bottom=False)\n    ax.spines[['bottom']].set_visible(False)\n        \nfor ax in [ax1, ax3, ax5]:\n    ax.grid(color='#000000', linestyle=':', axis='y', zorder=0, dashes=(1,5))\n    ax.set_xlabel('')\n    ax.set_ylabel('')","6efedaa2":"cont_features = ['Total Volume', '4046', '4225', '4770', 'Total Bags', 'Small Bags', 'Large Bags', 'XLarge Bags']","7337b2e7":"fig = plt.figure(figsize=(20, 15))\ngs = fig.add_gridspec(3, 3)\ngs.update(wspace=0.4, hspace=0.5)\n\nax0 = fig.add_subplot(gs[0, 0])\nax1 = fig.add_subplot(gs[0, 1])\nax2 = fig.add_subplot(gs[0, 2])\nax3 = fig.add_subplot(gs[1, 0])\nax4 = fig.add_subplot(gs[1, 1])\nax5 = fig.add_subplot(gs[1, 2])\nax6 = fig.add_subplot(gs[2, 0])\nax7 = fig.add_subplot(gs[2, 1])\nax8 = fig.add_subplot(gs[2, 2])\naxes = [ax0, ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8]\n\nfig.patch.set_facecolor(background_color)\n\n# Title\nax0.text(0.5, 0.5, 'Distribution of Continuous Features\\n_______________________',\n        fontsize=18, fontfamily='serif', fontweight='bold',\n        horizontalalignment='center',\n        verticalalignment='center')\n\n# Graphs\nfor i, ax in enumerate(axes):\n    for s in ['top', 'right', 'left']:\n        ax.spines[s].set_visible(False)\n        \n    ax.set_facecolor(background_color)\n    \n    if i == 0:\n        ax.set_xticklabels([])\n        ax.set_yticklabels([])\n        ax.tick_params(left=False, bottom=False)\n        ax.spines[['bottom']].set_visible(False)\n    else:\n        ax.set_title(cont_features[i-1], fontsize=14, fontfamily='serif', fontweight='bold')\n        ax.grid(color='#000000', linestyle=':', axis='y', zorder=0, dashes=(1,5))\n    \n        sns.kdeplot(x=cont_features[i-1], data=df, ax=ax, color=color_palette[i-1], fill=True)\n        ax.set_xlabel('')\n        ax.set_ylabel('')\n    \n","5b59abc5":"df[cont_features].skew()","62a3251e":"np.sqrt(df[cont_features]).skew()","85e9e811":"(df[cont_features] ** (1\/6)).skew()","d0a07a8f":"fig = plt.figure(figsize=(20, 15))\ngs = fig.add_gridspec(3, 3)\ngs.update(wspace=0.4, hspace=0.5)\n\nax0 = fig.add_subplot(gs[0, 0])\nax1 = fig.add_subplot(gs[0, 1])\nax2 = fig.add_subplot(gs[0, 2])\nax3 = fig.add_subplot(gs[1, 0])\nax4 = fig.add_subplot(gs[1, 1])\nax5 = fig.add_subplot(gs[1, 2])\nax6 = fig.add_subplot(gs[2, 0])\nax7 = fig.add_subplot(gs[2, 1])\nax8 = fig.add_subplot(gs[2, 2])\naxes = [ax0, ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8]\n\nfig.patch.set_facecolor(background_color)\n\n# Title\nax0.text(0.5, 0.5, 'Distribution of Continuous Features\\nAfter Removing Skewness\\n_______________________',\n        fontsize=18, fontfamily='serif', fontweight='bold',\n        horizontalalignment='center',\n        verticalalignment='center')\n\n# Graphs\nfor i, ax in enumerate(axes):\n    for s in ['top', 'right', 'left']:\n        ax.spines[s].set_visible(False)\n        \n    ax.set_facecolor(background_color)\n    \n    if i == 0:\n        ax.set_xticklabels([])\n        ax.set_yticklabels([])\n        ax.tick_params(left=False, bottom=False)\n        ax.spines[['bottom']].set_visible(False)\n    else:\n        ax.set_title(cont_features[i-1], fontsize=14, fontfamily='serif', fontweight='bold')\n        ax.grid(color='#000000', linestyle=':', axis='y', zorder=0, dashes=(1,5))\n    \n        sns.kdeplot(x=df[cont_features[i-1]]**(1\/6), ax=ax, color=color_palette[i-1], fill=True)\n        ax.set_xlabel('')\n        ax.set_ylabel('')","e4ca0f7f":"fig = plt.figure(figsize=(20, 15))\ngs = fig.add_gridspec(3, 3)\ngs.update(wspace=0.4, hspace=0.5)\n\nax0 = fig.add_subplot(gs[0, 0])\nax1 = fig.add_subplot(gs[0, 1])\nax2 = fig.add_subplot(gs[0, 2])\nax3 = fig.add_subplot(gs[1, 0])\nax4 = fig.add_subplot(gs[1, 1])\nax5 = fig.add_subplot(gs[1, 2])\nax6 = fig.add_subplot(gs[2, 0])\nax7 = fig.add_subplot(gs[2, 1])\nax8 = fig.add_subplot(gs[2, 2])\naxes = [ax0, ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8]\n\nfig.patch.set_facecolor(background_color)\n\n# Title\nax0.text(0.5, 0.5, 'Distribution of Continuous Features\\nby Type\\n_______________________',\n        fontsize=18, fontfamily='serif', fontweight='bold',\n        horizontalalignment='center',\n        verticalalignment='center')\n\n# Graphs\nfor i, ax in enumerate(axes):\n    for s in ['top', 'right', 'left']:\n        ax.spines[s].set_visible(False)\n        \n    ax.set_facecolor(background_color)\n    \n    if i == 0:\n        ax.set_xticklabels([])\n        ax.set_yticklabels([])\n        ax.tick_params(left=False, bottom=False)\n        ax.spines[['bottom']].set_visible(False)\n    else:\n        ax.set_title(cont_features[i-1], fontsize=14, fontfamily='serif', fontweight='bold')\n        ax.grid(color='#000000', linestyle=':', axis='y', zorder=0, dashes=(1,5))\n    \n        sns.kdeplot(x=df[cont_features[i-1]]**(1\/6), ax=ax, palette=color_palette[0:2], fill=True, hue=df['type'])\n        ax.set_xlabel('')\n        ax.set_ylabel('')","07e44b06":"df.corr()","165b81d9":"f, ax = plt.subplots(1, 1, figsize=(10, 10))\n\nmask = np.triu(np.ones_like(df.corr()))\nax.text(2.5, -0.1, 'Correlation Matrix', fontsize=18, fontweight='bold', fontfamily='serif')\nsns.heatmap(df.corr(), annot=True, fmt='.2f', cmap='RdBu', \n            square=True, mask=mask, linewidth=0.7, ax=ax)","99528d93":"from sklearn.preprocessing import LabelEncoder\n\nlabel = LabelEncoder()\ndf['type'] = label.fit_transform(df['type'])\ndf['region'] = label.fit_transform(df['region'])","80a004a1":"df['Month'] = pd.to_datetime(df['Date']).dt.month\ndf.drop('Date', axis=1, inplace=True)","a6849bff":"from sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n\nX = df.drop('AveragePrice', axis=1)\ny = df['AveragePrice']\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=0)","1a246e88":"model = LinearRegression()\nmodel.fit(X_train, y_train)\nprint('Train Score : {:.4f}'.format(model.score(X_train, y_train)))\nprint('Test Score : {:.4f}'.format(model.score(X_test, y_test)))","2476ab19":"model = Ridge()\nmodel.fit(X_train, y_train)\nprint('Train Score : {:.4f}'.format(model.score(X_train, y_train)))\nprint('Test Score : {:.4f}'.format(model.score(X_test, y_test)))","98d2d997":"model = GradientBoostingRegressor()\nmodel.fit(X_train, y_train)\nprint('Train Score : {:.4f}'.format(model.score(X_train, y_train)))\nprint('Test Score : {:.4f}'.format(model.score(X_test, y_test)))","462494a5":"model = KNeighborsRegressor()\nmodel.fit(X_train, y_train)\nprint('Train Score : {:.4f}'.format(model.score(X_train, y_train)))\nprint('Test Score : {:.4f}'.format(model.score(X_test, y_test)))","446da2c9":"model = RandomForestRegressor()\n\nmodel.fit(X_train, y_train)\nprint('Train Score : {:.4f}'.format(model.score(X_train, y_train)))\nprint('Test Score : {:.4f}'.format(model.score(X_test, y_test)))","acb2b27c":"model = DecisionTreeRegressor()\n\nmodel.fit(X_train, y_train)\nprint('Train Score : {:.4f}'.format(model.score(X_train, y_train)))\nprint('Test Score : {:.4f}'.format(model.score(X_test, y_test)))","55747f6b":"from sklearn.model_selection import GridSearchCV\n\nmodels = []\nscores = []","bf8a8f31":"param_grid = {'alpha' : [0.0001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100]}\nmodel = Ridge()\n\ngrid_search = GridSearchCV(model, param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\nridge_score = grid_search.score(X_test, y_test)\n\nprint('Test Score : {:.4f}'.format(ridge_score))\nprint('Best Parameters :', grid_search.best_params_)\nprint('Best CV Score : {:.4f}'.format(grid_search.best_score_))\n\nmodels.append('Ridge')\nscores.append(ridge_score)","7e65a1eb":"param_grid = {'max_depth' : [2, 3, 4, 5, 6, 7, 8, 9]}\nmodel = GradientBoostingRegressor()\n\ngrid_search = GridSearchCV(model, param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\ngb_score = grid_search.score(X_test, y_test)\n\nprint('Test Score : {:.4f}'.format(gb_score))\nprint('Best Parameters :', grid_search.best_params_)\nprint('Best CV Score : {:.4f}'.format(grid_search.best_score_))\n\nmodels.append('Gradient Boost')\nscores.append(gb_score)","c554ce70":"param_grid = {'n_neighbors' : range(1, 20)}\nmodel = KNeighborsRegressor()\n\ngrid_search = GridSearchCV(model, param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\nknr_score = grid_search.score(X_test, y_test)\n\nprint('Test Score : {:.4f}'.format(knr_score))\nprint('Best Parameters :', grid_search.best_params_)\nprint('Best CV Score : {:.4f}'.format(grid_search.best_score_))\n\nmodels.append('K-Nearest Neighbors')\nscores.append(knr_score)","30768235":"param_grid = {'max_depth' : [5, 10, 15, 20, 25, 30]}\nmodel = RandomForestRegressor()\n\ngrid_search = GridSearchCV(model, param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\nrf_score = grid_search.score(X_test, y_test)\n\nprint('Test Score : {:.4f}'.format(rf_score))\nprint('Best Parameters :', grid_search.best_params_)\nprint('Best CV Score : {:.4f}'.format(grid_search.best_score_))\n\nmodels.append('Random Forest')\nscores.append(rf_score)","4fffa7d6":"param_grid = {'max_depth' : range(2, 20), \"min_samples_leaf\" : range(2, 10)}\nmodel = DecisionTreeRegressor()\n\ngrid_search = GridSearchCV(model, param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\ndt_score = grid_search.score(X_test, y_test)\n\nprint('Test Score : {:.4f}'.format(dt_score))\nprint('Best Parameters :', grid_search.best_params_)\nprint('Best CV Score : {:.4f}'.format(grid_search.best_score_))\n\nmodels.append('Decision Tree')\nscores.append(dt_score)","a08c15f4":"df_result = pd.DataFrame({'Model' : models, 'Score' : scores})\ndf_result","d5a6de2f":"fig = plt.figure(figsize=(15, 4))\ngs = fig.add_gridspec(1, 2)\ngs.update(wspace=0.2)\n\nax0 = fig.add_subplot(gs[0, 0])\nax1 = fig.add_subplot(gs[0, 1])\n\n# Title\nax0.text(0.5, 0.5, 'Score of Models\\n ___________',\n        horizontalalignment='center',\n        verticalalignment='center',\n        fontsize=18, fontfamily='serif', fontweight='bold')\nax0.set_xticklabels([])\nax0.set_yticklabels([])\nax0.tick_params(left=False, bottom=False)\nax0.spines['left'].set_visible(False)\n\n\n# Graph\nax1.grid(color='#000000', linestyle=':', axis='y', zorder=0, dashes=(1,5))\nsns.barplot(x='Score', y='Model', data=df_result, palette=color_palette, ax=ax1)\nax1.set_xlabel('')\nax1.set_ylabel('')\n\n\nfig.patch.set_facecolor(background_color)\naxes = [ax0, ax1]\n\nfor ax in axes:\n    ax.set_facecolor(background_color)\n    for s in ['top', 'right', 'bottom']:\n        ax.spines[s].set_visible(False)","cc2451cc":"### Ridge","15ff1ef6":"### Ridge","76d192d7":"### K-Nearest Neighbors","9493f7e3":"### Random Forest","2377e156":"### Linear Regression","3f65f689":"Hopefully, we have no null values!","efeafc81":"### About Features\n\n* Date - the date of the observation\n* AveragePrice - the average price of a single avocado\n* type - conventional or organic\n* year - the year\n* Region - the city or region of the observation\n* Total Volume - Total number of avocados sold\n* 4046 - Total number of avocados with PLU 4046 sold\n* 4225 - Total number of avocados with PLU 4225 sold\n* 4770 - Total number of avocados with PLU 4770 sold\n\n\n**Our task is to predict the Average Price.**","6410c297":"### Thank you!\n### Please Upvote if you like my notebook \ud83d\udc4d","131cb832":"'Label Encoding' for the categorical features.","b23f3f3b":"# Hyperparameter Tuning","4dc4492d":"### Gradient Boost","d1705b2b":"# EDA","af110c77":"'XLarge Bags' is still skewed, but the others look much better.\n\nWe can also see the ditribution of continuous features by the 'type'.","2613c3d4":"### Decision Tree","7e71d1d0":"## Result","10ffda78":"### K-Nearest Neighbors","9e9e6cd9":"Get month from 'Date' and drop the column.","d7a9ea91":"### Decision Tree","1a0ed047":"Oops! They are highly skewed!\nLet's check skewness of the dataset.","89afd531":"# Modeling","1e707059":"### Distribution of Target (AveragePrice)","7aeb4d59":"Usually, it's a great way to use 'sqrt' to remove skewness.","612cd29b":"### Correlation Matrix","04ef1864":"### Gradient Boost","99f2b0ca":"When we use 6th root, it's much better.\n\nLet's see the distribution again.","d1d7125e":"It works! But... still skewed....\n\nLet's try higher root.","6950fb0d":"### Distribution of Continuous Features","e22844bf":"### Random Forest","72023a50":"# Preprocessing"}}