{"cell_type":{"87bca11f":"code","7d6a6d90":"code","bbd07622":"code","ce9692d2":"code","96ac4704":"code","a87bca74":"code","d5b1b110":"code","27e0df31":"code","84e3b201":"code","871353a9":"code","7e107d20":"code","d9555ae0":"code","8b4ce047":"code","0f696e5e":"code","6c7b8906":"code","10a4073f":"code","5ebd79e5":"code","79ff5cf1":"code","1e94292a":"code","74fc28e8":"code","1314cef4":"code","7dce47e7":"code","50d789c7":"code","52e4c95e":"code","f8f9430f":"code","2135da64":"code","8cc4feca":"code","5ccf51b1":"code","64330e30":"code","6899729b":"code","edaa1236":"code","782cc6db":"code","bea43f2c":"code","b280202e":"code","6159d4ee":"code","05d8abd2":"code","0b903044":"code","7aa3c73f":"code","2a8c704c":"code","b2f257d1":"code","dd29a17a":"code","2f82e7bc":"code","9e2c52d6":"code","3f3faba7":"code","c7ea9634":"code","8cb10cc8":"code","e21a07fb":"code","3ccc2c00":"code","6891a887":"code","1701f7c8":"markdown","fc6d7561":"markdown","ceb49cd0":"markdown","6db4dc28":"markdown","eeea5ba0":"markdown","cdd5f3c2":"markdown","a528e5ca":"markdown","f2826404":"markdown","ead7f4cc":"markdown"},"source":{"87bca11f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7d6a6d90":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_theme()\nsns.set_palette(\"twilight\")\n%matplotlib inline","bbd07622":"train_df = pd.read_csv(r\"..\/input\/titanic\/train.csv\")","ce9692d2":"#train copy\ntrain = train_df.copy()\n\ntrain.head()","96ac4704":"train.describe()","a87bca74":"train.shape","d5b1b110":"test_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest = test_df.copy()\ntest.head()","27e0df31":"test.describe()","84e3b201":"test.info()","871353a9":"train.dtypes","7e107d20":"train.info()","d9555ae0":"cat_feature = [\"Survived\", \"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\"]","8b4ce047":"plt.figure(figsize = (15,15))\nplt.suptitle(\"Countplot of Categorical Features\", fontsize=18)\nfor i in cat_feature: \n    plt.subplot(3,2,cat_feature.index(i)+1)\n    sns.countplot(data = train, x = i, hue = \"Survived\", palette=\"twilight\")\n    plt.ylabel(\"\")\n    plt.legend(['Not Survived', 'Survived'], loc='upper center', prop={'size': 10})\nplt.tight_layout()\nplt.show()","0f696e5e":"num_feature = [\"Age\", \"Fare\"]","6c7b8906":"plt.figure(figsize=(20,10))\nplt.suptitle(\"Distribution of Outliers of Numerical Data\", fontsize=20)\n\n# Box-plot\nfor i in num_feature:\n    plt.subplot(1,4,num_feature.index(i)+1)\n    sns.boxplot(data = train[i], palette=\"twilight\")\n    plt.xlabel(str(i))\n    \n# Histogram    \nfor i in num_feature:\n    plt.subplot(1,4,num_feature.index(i)+3)\n    sns.histplot(data = train[i], palette=\"twilight\", bins=15)\n    plt.xlabel(str(i))\n    \nplt.tight_layout()\nplt.show()","10a4073f":"train.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\",\"Cabin\"], inplace=True)\nPassengerId_test =test[\"PassengerId\"]\ntest.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\",\"Cabin\"], inplace=True)\n","5ebd79e5":"train.head()","79ff5cf1":"train.info()","1e94292a":"data = [train, test]\nfor dataset in data:\n    dataset['relatives'] = dataset['SibSp'] + dataset['Parch']\n    dataset.loc[dataset['relatives'] > 0, 'travelled_alone'] = 'No'\n    dataset.loc[dataset['relatives'] == 0, 'travelled_alone'] = 'Yes'","74fc28e8":"y_train = train[\"Survived\"]\nx_train = train.drop(columns=[\"Survived\"])","1314cef4":"from sklearn.model_selection import train_test_split\nX_train, X_vald, y_train, y_vald = train_test_split(x_train, y_train, \n                                                    test_size=0.2, random_state=0)","7dce47e7":"X_train.head()","50d789c7":"X_train.shape","52e4c95e":"X_vald.head()","f8f9430f":"X_vald.shape","2135da64":"test.head()","8cc4feca":"from sklearn.pipeline import make_pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder,LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.pipeline import Pipeline","5ccf51b1":"import missingno as msno\nmsno.matrix(train , color=(0.50,0.30,0.80))\nplt.show()\nx = train.isnull().sum()\nprint(\"Total Missing Values in dataset :\",x)\nprint(\"Data Type of x : \",type(x))\nfor a, b in x.items():\n    if b > 0:\n        print(f\"There are {b} missing values in column: {a}\")","64330e30":"# X_train[\"Cabin\"].fillna(\"undefined\", inplace=True)\n# X_vald[\"Cabin\"].fillna(\"undefined\", inplace=True)\n# test[\"Cabin\"].fillna(\"undefined\", inplace=True)","6899729b":"X_train.isnull().sum()","edaa1236":"X_vald.isnull().sum()","782cc6db":"test.isnull().sum()","bea43f2c":"X_train.info()","b280202e":"X_train.isnull().sum()","6159d4ee":"X_train['SibSp'].value_counts()","05d8abd2":"numeric_features = ['Age', 'Fare']\n# Define a pipeline for numeric features\nnumeric_features_pipeline = Pipeline(steps= [\n    ('imputer', SimpleImputer(strategy = 'median')), # Impute with median value for missing\n    ('scaler', StandardScaler())])","0b903044":"categorical_features = ['Embarked', 'Sex','travelled_alone']\n# Define a pipeline for categorical features\ncategorical_features_pipeline = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value = 'missing')), # Impute with the word 'missing' for missing values\n    ('onehot', OneHotEncoder(sparse=False, handle_unknown=\"ignore\"))])","7aa3c73f":"ordinal_features = ['Pclass']\n# Define a pipline for ordinal features \nordinal_features_pipeline = Pipeline(steps=[\n    ('ordinal', OrdinalEncoder())\n])","2a8c704c":"preprocessor = ColumnTransformer(transformers= [\n    ('num', numeric_features_pipeline, numeric_features),        # transformer with name 'num' that will apply 'numeric_features_pipeline' to numeric_features\n    ('cat', categorical_features_pipeline, categorical_features), # transformer with name 'cat' that will apply 'categorical_features_pipeline' to categorical_features\n    ('ord', ordinal_features_pipeline, ordinal_features)\n])","b2f257d1":"clf = Pipeline(steps=[('preprocessor', preprocessor),\n                     ('classifier', LogisticRegression(solver = 'lbfgs'))])","dd29a17a":"clf.fit(X_train, y_train)","2f82e7bc":"X_vald['Pclass'].value_counts()","9e2c52d6":"y_pred = clf.predict(X_vald)\ny_pred","3f3faba7":"from sklearn.metrics import accuracy_score\nc = accuracy_score(y_vald, y_pred)\nc","c7ea9634":"y_pred2 = clf.predict(test)","8cb10cc8":"y_pred2","e21a07fb":"output = pd.DataFrame({'PassengerId': PassengerId_test, 'Survived': y_pred2})\noutput.to_csv('submission.csv', index=False)\n","3ccc2c00":"output.head(10)","6891a887":"output.shape","1701f7c8":"# EDA\n","fc6d7561":"# Filling null values","ceb49cd0":"# Import Libraries","6db4dc28":"# Test Data","eeea5ba0":"# remove unimportant columns\n\n","cdd5f3c2":"# Feature Engineering ","a528e5ca":"# Import Dataset\n","f2826404":"# Prediction and Accuracy Score","ead7f4cc":"# Build pipeline of models"}}