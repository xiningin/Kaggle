{"cell_type":{"070cb4cd":"code","8cffc5c6":"code","fe9b2228":"code","9c8e17f2":"code","26430d74":"code","586033fa":"code","66322c89":"code","d5964cd2":"code","077adc6f":"code","860d9d8f":"code","eefe6d44":"code","2031ac25":"code","c5ab8608":"code","ecea74cf":"code","3d936dec":"code","b778d19d":"code","72ee77df":"markdown","dab812f6":"markdown","e7b5341d":"markdown","23eb08c7":"markdown","89f62fcb":"markdown"},"source":{"070cb4cd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8cffc5c6":"import pandas as pd\nimport numpy as np\nimport random\nimport re","fe9b2228":"orig_netflix = pd.read_csv(\"\/kaggle\/input\/netflix-shows\/netflix_titles.csv\")\nprint(orig_netflix.shape)\norig_netflix.head()","9c8e17f2":"orig_netflix = orig_netflix[orig_netflix[\"type\"] == \"Movie\"].reset_index()\nnetflix = orig_netflix[[\"title\", \"listed_in\", \"description\"]].copy()\nnetflix.head()","26430d74":"netflix.isnull().sum()","586033fa":"def preprocessing(desc):\n    desc = desc.lower()\n    desc = re.sub('[-=+,#\/\\?:^$.@*\\\"\u203b~&%\u318d!\u300f\\\\\u2018|\\(\\)\\[\\]\\<\\>`\\'\u2026\u300b]', ' ', desc)\n    desc = \" \".join(desc.split())\n    \n    return desc","66322c89":"netflix[\"new_description\"] = netflix[\"description\"].apply(lambda x: preprocessing(x))\nprint(netflix.shape)\nnetflix.head()","d5964cd2":"print(netflix[\"description\"].iloc[0])\nprint(netflix[\"new_description\"].iloc[0])","077adc6f":"from gensim.models.fasttext import FastText as FT_gensim\n\ncorpus = netflix[\"new_description\"].tolist()\nsentences = [re.split(' ', str(sentence)) for sentence in corpus]\nprint(corpus[0])\nprint(sentences[0])","860d9d8f":"embedding_size = 30\n\nFT_model = FT_gensim(vector_size=embedding_size, min_count=2, min_n=2, max_n=5, sg=1, negative=10,\n                         sample=0.001, window=5, alpha=0.025, min_alpha=0.0001, epochs=50)\n\nFT_model.build_vocab(sentences)\n\nprint('corpus_count: ', FT_model.corpus_count)\nprint('corpus_total_words: ', FT_model.corpus_total_words)\n\nFT_model.train(sentences,\n    epochs=FT_model.epochs,\n    total_examples=FT_model.corpus_count, total_words=FT_model.corpus_total_words)\n\nprint(FT_model)","eefe6d44":"FT_vector = []\n\nfor item in corpus:\n    FT_vector.append(FT_model.wv[str(item)])\nFT_vector = np.asarray(FT_vector)","2031ac25":"from sklearn.cluster import KMeans\nfrom scipy.spatial.distance import cdist\n\nkmeanModel = KMeans(n_clusters=50, random_state=42).fit(FT_vector)\ncluster_id = kmeanModel.predict(FT_vector)\nnetflix[\"cluster_id\"] = cluster_id","c5ab8608":"netflix.head()","ecea74cf":"def recommendation_system(title_name):\n    top_k = 5\n    title_row = netflix[netflix[\"title\"] == title_name].copy()\n    search_df = netflix[netflix[\"cluster_id\"].isin(title_row[\"cluster_id\"])].copy()\n    search_df = search_df.drop(search_df[search_df[\"title\"] == title_name].index)\n    \n    search_df[\"Similarity\"] = search_df.apply(lambda x: FT_model.wv.similarity(title_row[\"new_description\"], x[\"new_description\"]), axis=1)\n    search_df.sort_values(by=[\"Similarity\"], ascending=False, inplace=True)\n    \n    return search_df[[\"title\", \"Similarity\"]].head(top_k)","3d936dec":"recommendation_system(\"Aakhri Adaalat\")","b778d19d":"recommendation_system(\"National Parks Adventure\")","72ee77df":"### 4. Recommendation system\nSearching similarity of new description between source movie and target movie in same cluster<br\/>\nSorting dataframe with similarity and return title of most similar movie with number of top_k","dab812f6":"## Movie Recommendation system using K-means and Fasttext embedding","e7b5341d":"### 2. Embedding\nSplit each sentence to make the corpus<br\/>\nEmbedding the corpus with Fasttext method<br\/>\nTransform sentences to featrue vector","23eb08c7":"### 3. K-means Clustering\nTrain k-means clustering with feature vector<br\/>\nAdd cluster_id on dataframe ","89f62fcb":"### 1.Preprocessing\nSelect rows which is movie type and nessecary columns<br\/>\nRemove special character and transform to lower case"}}