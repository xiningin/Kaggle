{"cell_type":{"7d51e5f9":"code","e93fb16f":"code","8f9121a4":"code","50ecd0c9":"code","bc01206d":"code","c59976a8":"code","424f3e19":"code","6abfcac3":"code","7c8152f5":"code","50323de5":"code","5ac1507b":"code","6100a05b":"code","69f8d7be":"code","0dd54c14":"code","eb778eab":"code","21e2b47d":"code","de1bccf0":"code","6bc7f799":"code","278aab19":"code","7c7cd4b0":"code","98317a38":"code","1d5e369b":"markdown"},"source":{"7d51e5f9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e93fb16f":"train=pd.read_csv(\"\/kaggle\/input\/sejong-ai-2021-19011824\/train.csv\")\ntest=pd.read_csv(\"\/kaggle\/input\/sejong-ai-2021-19011824\/test.csv\")\nsubmit=pd.read_csv(\"\/kaggle\/input\/sejong-ai-2021-19011824\/Submission.csv\")","8f9121a4":"train","50ecd0c9":"test=test.drop([\"Unnamed: 0\"],axis=1)\nx=train.drop([\"Unnamed: 0\",\"Tsu\",\"Eq\"],axis=1)","bc01206d":"label=[]\ntsu=train[\"Tsu\"]\nEq=train[\"Eq\"]\n\nfor i in range(len(train)):\n  if tsu[i]==1 and Eq[i]==1:\n    label.append(3)\n  elif tsu[i]==1 and Eq[i]==0:\n    label.append(2)\n  elif tsu[i]==0 and Eq[i]==1:\n    label.append(1)\n  else:\n    label.append(0)\n\nlabel=pd.DataFrame(label)\ny=label[0]","c59976a8":"np.unique(x[\"Agent\"].astype(str))","424f3e19":"x[\"Agent\"] = x[\"Agent\"].astype(str) # \ub370\uc774\ud130 \ud0c0\uc785\uc744 string\uc73c\ub85c \uc124\uc815 \nx[\"Agent\"] = x[\"Agent\"].replace(\",\",\"\",regex=True) # \uc27c\ud45c \uc81c\uac70\ntest[\"Agent\"] = test[\"Agent\"].astype(str)\ntest[\"Agent\"] = test[\"Agent\"].replace(',','',regex=True)\n\nnp.unique(x[\"Agent\"])\n# \ucc98\uc74c \uc54c\ud30c\ubcb3 \uc21c\uc11c\ub85c sort \ud574\ubcf4\uc558\uc73c\ub098 \ud2b8\ub808\uc778 \ub370\uc774\ud130 \uc131\ub2a5\uc774 \ub5a8\uc5b4\uc838 \uc81c\uac70\ud558\uc600\uc74c \n# \ub744\uc5b4\uc4f0\uae30 \uc720\ubb34 \uc758\ubbf8\ub97c \ubaa8\ub974\uaca0\uc74c\n# \uc54c\ud30c\ubcb3 \uc21c\uc11c\uc5d0\ub3c4 \uc758\ubbf8\uac00 \uc788\uc9c0\uc54a\ub098 \ud558\ub294 \ucd94\uce21","6abfcac3":"# x['W'] = 0\n# x['S'] = 0 \n# test['W'] = 0\n# test['S'] = 0","7c8152f5":"con_list=[\"Name\",\"Location\",\"Country\",\"Type\",\"Agent\"]\n\nfrom sklearn import preprocessing\n\nlable_encoder=pd.concat([x,test])\n\nfor i in con_list:\n    le = preprocessing.LabelEncoder()\n    lable_encoder[i]=lable_encoder[i].astype(\"str\")\n    x[i]=x[i].astype(\"str\")\n    test[i]=test[i].astype(\"str\")\n    le.fit(lable_encoder[i])\n    x[i]=le.transform(x[i])\n    test[i]=le.transform(test[i])","50323de5":"from sklearn.preprocessing import RobustScaler,StandardScaler,MinMaxScaler\n\ntransformer =  StandardScaler().fit(x)\nx=transformer.transform(x)\ntest=transformer.transform(test)","5ac1507b":"from sklearn.impute import SimpleImputer\nimp_mean = SimpleImputer(missing_values=np.nan, strategy='constant',fill_value=0)\nimp_mean.fit(x)\nx=imp_mean.transform(x)\ntest=imp_mean.transform(test)","6100a05b":"import torch\nseed=0\ntorch.manual_seed(seed)\n\ndevice='cuda' if torch.cuda.is_available() else 'CPU'\n\nif device=='cuda':\n    torch.cuda.manual_seed_all(seed)\n\nx=np.array(x)\ny=np.array(y)\ntest=np.array(test)\n\nx=torch.FloatTensor(x)\ny=torch.LongTensor(y)\ntest=torch.FloatTensor(test)","69f8d7be":"linear1=torch.nn.Linear(len(x[0]),128)\nlinear2=torch.nn.Linear(128,128)\nlinear3=torch.nn.Linear(128,64)\nlinear4=torch.nn.Linear(64,4)\n\ntorch.nn.init.xavier_uniform_(linear1.weight)\ntorch.nn.init.xavier_uniform_(linear2.weight)\ntorch.nn.init.xavier_uniform_(linear3.weight)\ntorch.nn.init.xavier_uniform_(linear4.weight)\n\nrelu=torch.nn.ReLU()\n\ndropout=torch.nn.Dropout(p=0.1)","0dd54c14":"model=torch.nn.Sequential(linear1,relu,dropout,linear2,relu,dropout,linear3,relu,dropout,linear4)\noptimizer = torch.optim.Adam(params= model.parameters(), lr=0.001)\nloss=torch.nn.CrossEntropyLoss()","eb778eab":"model.train()\nfor stop in range(1000+100):\n    optimizer.zero_grad()\n    h=model(x)\n    cost=loss(h,y)\n    cost.backward()\n    optimizer.step()\n    if stop%100==0:\n        print(stop,cost.item())","21e2b47d":"pred=list()\nwith torch.no_grad():\n  \n    model.eval()\n    test_y=model(test)\n    a,b=torch.max(test_y,dim=1)\n    pred.extend(b.tolist())","de1bccf0":"submit[\"label\"]=pred\nsubmit.to_csv(\"submit.csv\",index=False)","6bc7f799":"nt = pd.read_csv(\"..\/input\/sejong-ai-2021-19011824\/test.csv\")\nnt = nt.astype(str)","278aab19":"for i in range(len(test)):\n    if submit['label'][i]==0 :\n        if 'W' in nt['Agent'][i]:\n            print\n            submit['label'][i] = '2'\n    elif submit['label'][i]==1 :\n        if 'W' in nt['Agent'][i]:\n            submit['label'][i] = '3'","7c7cd4b0":"for i in range(len(test)):\n    if submit['label'][i]==0 :\n        if 'S' in nt['Agent'][i]:\n            print\n            submit['label'][i] = '1'\n    elif submit['label'][i]==2 :\n        if 'S' in nt['Agent'][i]:\n            submit['label'][i] = '3'","98317a38":"submit.to_csv(\"submit.csv\",index=False)\nsubmit","1d5e369b":"[https:\/\/www.ngdc.noaa.gov\/hazel\/view\/hazards\/volcano\/event-data](http:\/\/)\n\n![image.png](attachment:74156b0c-2b9d-4589-be12-cb891dfae657.png)"}}