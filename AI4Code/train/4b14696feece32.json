{"cell_type":{"ca8dc986":"code","f055fc86":"code","71b2bc7c":"code","0875677f":"code","2f00b279":"code","05431d41":"code","b26c5158":"code","48563167":"code","8fec9756":"code","6fe42582":"code","b33daed2":"code","1ea20920":"code","69569270":"code","b5c67122":"code","65c17060":"code","314df146":"markdown","91b70ec5":"markdown","2b712240":"markdown","fea2c5ae":"markdown","fa30b5f5":"markdown","17698599":"markdown","40e9691a":"markdown","7583e13d":"markdown"},"source":{"ca8dc986":"import os\nimport os.path\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tqdm\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_absolute_error","f055fc86":"INPUT_DIR = '..\/input\/m5-forecasting-accuracy\/'\ntrain_df = pd.read_csv(os.path.join(INPUT_DIR, 'sales_train_evaluation.csv'))\nprice_df = pd.read_csv(os.path.join(INPUT_DIR, 'sell_prices.csv'))\ncalender_df = pd.read_csv(os.path.join(INPUT_DIR, 'calendar.csv'))\n\ncalender_df['date'] = pd.to_datetime(calender_df['date'])","71b2bc7c":"train_df.head(3)","0875677f":"calender_df","2f00b279":"price_df.head(3)","05431d41":"price_dfs = {\n    'CA_1': price_df[price_df['store_id'] == 'CA_1'],\n    'CA_2': price_df[price_df['store_id'] == 'CA_2'],\n    'CA_3': price_df[price_df['store_id'] == 'CA_3'],\n    'CA_4': price_df[price_df['store_id'] == 'CA_4'],\n    'TX_1': price_df[price_df['store_id'] == 'TX_1'],\n    'TX_2': price_df[price_df['store_id'] == 'TX_2'],\n    'TX_3': price_df[price_df['store_id'] == 'TX_3'],\n    'WI_1': price_df[price_df['store_id'] == 'WI_1'],\n    'WI_2': price_df[price_df['store_id'] == 'WI_2'],\n    'WI_3': price_df[price_df['store_id'] == 'WI_3']\n}","b26c5158":"price_df = None","48563167":"def transform_d_dates_to_dates(d_dates):\n    return calender_df.set_index('d').loc[d_dates]['date']\n\n\ndef transform_dates_to_d_dates(dates):\n    return calender_df.set_index('date').loc[dates]['d']\n\n\ndef transform_dates_to_wm_yr_wk(dates):\n    return calender_df.set_index('date').loc[dates]['wm_yr_wk']\n\n\ndef get_avg_item_n_sold_prev_month(item_id, store_id, dates_df):\n    assert len(item_id.split('_')) == 3\n    assert store_id in ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\n    assert dates_df.shape == (1604, 14)\n    \n    d_dates_month_ago = transform_dates_to_d_dates(dates_df['date'] - pd.DateOffset(days=28))\n    assert d_dates_month_ago.shape == (dates_df.shape[0],)\n    \n    first_day = int(d_dates_month_ago.iloc[0].split('_')[1]) - 28\n    last_day = int(d_dates_month_ago.iloc[-1].split('_')[1])\n    assert first_day == 310 and last_day == 1941\n    \n    tmp = train_df[\n        (train_df['item_id'] == item_id) &\n        (train_df['store_id'] == store_id)\n    ][['d_' + str(i) for i in range(first_day, last_day + 1)]]\n    assert tmp.shape == (1, dates_df.shape[0] + 28)\n    return tmp.iloc[0].rolling(28).mean().iloc[28:].to_numpy()\n\n\ndef get_item_n_sold_year_ago(item_id, store_id, dates_df):\n    assert len(item_id.split('_')) == 3\n    assert store_id in ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\n    assert dates_df.shape == (1604, 14)\n    \n    d_dates_year_ago = transform_dates_to_d_dates(dates_df['date'] - pd.DateOffset(years=1))\n    assert d_dates_year_ago.shape == (dates_df.shape[0],)\n    \n    tmp = train_df[\n        (train_df['item_id'] == item_id) &\n        (train_df['store_id'] == store_id)\n    ][d_dates_year_ago]\n    assert tmp.shape == (1, dates_df.shape[0])\n    return tmp.iloc[0].to_numpy()\n\n\ndef get_item_price(item_id, store_id, dates_df):\n    assert len(item_id.split('_')) == 3\n    assert store_id in ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\n    assert dates_df.shape == (1604, 14)\n    \n    wm_yr_wk = transform_dates_to_wm_yr_wk(dates_df['date']).to_numpy()\n    assert wm_yr_wk.shape == (dates_df.shape[0],)\n    \n    week_to_price = price_dfs[store_id][\n        (price_dfs[store_id]['item_id'] == item_id)\n    ].set_index('wm_yr_wk')['sell_price'].to_dict()\n    \n    price = np.full(dates_df.shape[0], np.nan)\n    for i in range(wm_yr_wk.shape[0]):\n        week = wm_yr_wk[i]\n        if week in week_to_price:\n            price[i] = week_to_price[week]\n    \n    item_price_df = pd.DataFrame(data={'price': price})\n    item_price_df = item_price_df.fillna(method='ffill').fillna(method='bfill')\n\n    assert item_price_df['price'].isna().sum() == 0\n    assert item_price_df.shape == (dates_df.shape[0], 1)\n\n    # norm_price = item_price_df['price']\n    # item_price_df['price'] \/= np.linspace(1.00, 1.05, num=item_price_df.shape[0])  # inflation\n    norm_price = item_price_df['price'].to_numpy()\n    \n    assert norm_price.shape == (dates_df.shape[0],)\n    return norm_price\n\n\ndef get_is_snap(item_id, store_id, dates_df):\n    assert 'FOODS' in item_id\n    assert len(item_id.split('_')) == 3\n    assert store_id in ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\n    assert dates_df.shape == (1604, 14)\n    \n    if store_id in ['CA_1', 'CA_2', 'CA_3', 'CA_4']:\n        return dates_df['snap_CA'].to_numpy()\n    elif store_id in ['TX_1', 'TX_2', 'TX_3']:\n        return dates_df['snap_TX'].to_numpy()\n    elif store_id in ['WI_1', 'WI_2', 'WI_3']:\n        return dates_df['snap_WI'].to_numpy()\n\n    assert False\n    return None\n    \n    \ndef get_week_days_features(item_id, store_id, dates_df):\n    assert len(item_id.split('_')) == 3\n    assert store_id in ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\n    assert dates_df.shape == (1604, 14)\n    \n    return pd.DataFrame(\n        index=dates_df['d'],\n        data={\n            'is_Monday': (dates_df['weekday'] == 'Monday').astype(int).to_numpy(),\n            'is_Tuesday': (dates_df['weekday'] == 'Tuesday').astype(int).to_numpy(),\n            'is_Wednesday': (dates_df['weekday'] == 'Wednesday').astype(int).to_numpy(),\n            'is_Thursday': (dates_df['weekday'] == 'Thursday').astype(int).to_numpy(),\n            'is_Friday': (dates_df['weekday'] == 'Friday').astype(int).to_numpy(),\n            'is_Saturday': (dates_df['weekday'] == 'Saturday').astype(int).to_numpy()\n        }\n    )\n    \n    \ndef get_event_features(item_id, store_id, dates_df):\n    assert len(item_id.split('_')) == 3\n    assert store_id in ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\n    assert dates_df.shape == (1604, 14)\n    \n    events_df = dates_df[['date', 'd', 'event_type_1', 'event_type_2']].copy()\n    events_df['tomorrow_event_type_1'] = events_df['event_type_1'].shift(periods=-1)\n    events_df['tomorrow_event_type_2'] = events_df['event_type_2'].shift(periods=-1)\n    \n    return pd.DataFrame(\n        index=events_df['d'],\n        data={\n            'is_today_religious': (\n                (events_df['event_type_1'] == 'Religious') |\n                (events_df['event_type_2'] == 'Religious')\n            ).astype(int).to_numpy(),\n            'is_today_national': (\n                (events_df['event_type_1'] == 'National') |\n                (events_df['event_type_2'] == 'National')\n            ).astype(int).to_numpy(),\n            'is_today_cultural': (\n                (events_df['event_type_1'] == 'Cultural') |\n                (events_df['event_type_2'] == 'Cultural')\n            ).astype(int).to_numpy(),\n            'is_today_sporting': (\n                (events_df['event_type_1'] == 'Sporting') |\n                (events_df['event_type_2'] == 'Sporting')\n            ).astype(int).to_numpy(),\n            'is_tomorrow_religious': (\n                (events_df['tomorrow_event_type_1'] == 'Religious') |\n                (events_df['tomorrow_event_type_2'] == 'Religious')\n            ).astype(int).to_numpy(),\n            'is_tomorrow_national': (\n                (events_df['tomorrow_event_type_1'] == 'National') |\n                (events_df['tomorrow_event_type_2'] == 'National')\n            ).astype(int).to_numpy(),\n            'is_tomorrow_cultural': (\n                (events_df['tomorrow_event_type_1'] == 'Cultural') |\n                (events_df['tomorrow_event_type_2'] == 'Cultural')\n            ).astype(int).to_numpy(),\n            'is_tomorrow_sporting': (\n                (events_df['tomorrow_event_type_1'] == 'Sporting') |\n                (events_df['tomorrow_event_type_2'] == 'Sporting')\n            ).astype(int).to_numpy()\n        }\n    )\n\n\ndef get_item_X_y(item, is_debug):\n    assert len(item.split('_')) == 5\n    \n    dates_df = calender_df.iloc[365:]\n    \n    item_parts = item.split('_')\n    item_id = item_parts[0] + '_' + item_parts[1] + '_' + item_parts[2]\n    store_id = item_parts[3] + '_' + item_parts[4]\n    \n    df = pd.DataFrame(\n        index=dates_df['d'].to_numpy(),\n        data={\n            'avg_item_n_sold_prev_month': get_avg_item_n_sold_prev_month(item_id, store_id, dates_df),\n            'item_n_sold_year_ago': get_item_n_sold_year_ago(item_id, store_id, dates_df),\n            'price': get_item_price(item_id, store_id, dates_df)\n        }\n    )\n    \n    if 'FOODS' in item:\n        df['is_snap'] = get_is_snap(item_id, store_id, dates_df)\n        \n    df = pd.concat([\n        df,\n        get_week_days_features(item_id, store_id, dates_df),\n        get_event_features(item_id, store_id, dates_df)\n    ], axis=1)\n    assert df.isna().sum().sum() == 0\n    \n    features_to_drop = []\n    for feature in df.columns:\n        if len(df[feature].unique()) <= 1:\n            features_to_drop.append(feature)\n    df = df.drop(features_to_drop, axis=1)\n    if is_debug:\n        print('Features', features_to_drop, 'have been dropped')\n    \n    target = train_df[\n        train_df['id'] == item + '_evaluation'\n    ][\n        ['d_' + str(i) for i in range(366, 1942)]\n    ].to_numpy()[0]\n    assert target.shape == (1576,)\n    target = np.concatenate([target, np.full(28, np.nan)])\n    df['target'] = target\n\n    return df","8fec9756":"def plot_feature_importances(model, features):\n    assert len(model.coef_) == len(features)\n    plt.figure(figsize=(12, 4))\n    plt.title('FEATURE IMPORTANCES')\n    sns.barplot(x=model.coef_, y=features)\n    \n    \ndef plot_public_test(y_true, y_pred):\n    assert y_true.shape == y_pred.shape == (28,)\n    plt.figure(figsize=(14, 3))\n    plt.title('PUBLIC TEST')\n    plt.plot([i for i in range(1, 29)], y_true, label='true')\n    plt.plot([i for i in range(1, 29)], y_pred, label='pred')\n    plt.legend()\n\n\ndef train_item_model(item, is_debug):\n    df = get_item_X_y(item, is_debug)\n    assert df.shape[0] == 1604\n\n    X = df.drop(['target'], axis=1)\n    y = df['target']\n    \n    X_train = X.loc[['d_' + str(i) for i in range(366, 1914)]]  # train\n    y_train = y.loc[['d_' + str(i) for i in range(366, 1914)]]  # train\n    assert X_train.shape[0] == y_train.shape[0] == 1548\n    \n    X_valid = X.loc[['d_' + str(i) for i in range(1914, 1942)]]  # public test\n    y_valid = y.loc[['d_' + str(i) for i in range(1914, 1942)]]  # public test\n    X_test = X.loc[['d_' + str(i) for i in range(1942, 1970)]]  # private test\n    assert X_valid.shape[0] == y_valid.shape[0] == X_test.shape[0] == 28\n    \n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)  # train\n    X_valid = scaler.transform(X_valid)  # public test\n    X_test = scaler.transform(X_test)  # private test\n    \n    model = Ridge()\n    model.fit(X_train, y_train)\n    \n    y_valid_pred = model.predict(X_valid)\n    y_valid_pred[y_valid_pred < 0] = 0\n    y_valid_pred[y_valid_pred > y.max()] = y.max()\n    \n    y_test_pred = model.predict(X_test)\n    y_test_pred[y_test_pred < 0] = 0\n    y_test_pred[y_test_pred > y.max()] = y.max()\n    \n    if is_debug:\n        plot_feature_importances(model, X.columns)\n        plot_public_test(y_valid, y_valid_pred)\n        print('PUBLIC TEST: mean_absolute_error =', mean_absolute_error(y_valid, y_valid_pred))\n    \n    return y_valid_pred, y_test_pred","6fe42582":"get_item_X_y('HOBBIES_1_004_CA_1', is_debug=True)","b33daed2":"train_item_model('HOBBIES_1_004_CA_1', is_debug=True)","1ea20920":"submission = pd.read_csv(os.path.join(INPUT_DIR, 'sample_submission.csv'))","69569270":"for i in tqdm.tqdm(range(train_df.shape[0])):\n    item = train_df.iloc[i]['item_id'] + '_' + train_df.iloc[i]['store_id']\n    public_test_y, private_test_y = train_item_model(item, is_debug=False)\n\n    submission.loc[\n        submission[submission['id'] == item + '_validation'].index,\n        ['F' + str(i) for i in range(1, 29)]\n    ] = public_test_y\n\n    submission.loc[\n        submission[submission['id'] == item + '_evaluation'].index,\n        ['F' + str(i) for i in range(1, 29)]\n    ] = private_test_y","b5c67122":"submission","65c17060":"submission.to_csv('submission.csv', index=False)","314df146":"Split *price_df* into 10 dataframes (one dataframe for each store) just to speed up the function *get_item_price* (see below):","91b70ec5":"Let's take a look at one random dataframe:","2b712240":"Functions to train a model (one model for each item):","fea2c5ae":"# **Models for all items**","fa30b5f5":"# **Load data**","17698599":"Drop the variable which we don't need anymore:","40e9691a":"Some functions to prepare a dataframe for one item:","7583e13d":"# **Model for one random item**"}}