{"cell_type":{"1e510a7c":"code","203caf2e":"code","559549ac":"code","824758bb":"code","a9ddc8e3":"code","445bd9d5":"code","f4cb8904":"code","984e480c":"code","6dd3d3ff":"code","200eadb5":"code","ab47991d":"code","760720d4":"code","344ee495":"markdown"},"source":{"1e510a7c":"import pandas as pd","203caf2e":"dataset_train1 = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/train.csv', index_col='id')\ndataset_test1 = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/test.csv', index_col='id')\ny = dataset_train1.target\ny = pd.DataFrame(y)\ndataset_train = dataset_train1.drop(['target'], axis=1)","559549ac":"for col in dataset_train.columns:\n    if dataset_train[col].dtype == 'float64':\n        dataset_train[col] = dataset_train[col].astype('float32')\n        dataset_test1[col] = dataset_test1[col].astype('float32')\n    if dataset_train[col].dtype == 'int64':\n        dataset_train[col] = dataset_train[col].astype('int8')\n        dataset_test1[col] = dataset_test1[col].astype('int8')","824758bb":"dataset_train['ones_count'] = dataset_train[dataset_train == 1].sum(axis=1)","a9ddc8e3":"dataset_test1['ones_count'] = dataset_test1[dataset_test1 == 1].sum(axis=1)","445bd9d5":"import tensorflow as tf","f4cb8904":"# Detect TPU, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","984e480c":"from sklearn.preprocessing import QuantileTransformer, KBinsDiscretizer, PowerTransformer","6dd3d3ff":"from sklearn.preprocessing import MinMaxScaler\nx_scaler = MinMaxScaler()\ndataset_train_sc = x_scaler.fit_transform(dataset_train)\ndataset_test_sc = x_scaler.transform(dataset_test1)","200eadb5":"from tensorflow import keras\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Embedding\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Reshape\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Conv1D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import load_model\n#from tensorflow.keras.engine.input_layer import Input\nfrom tensorflow.keras.layers import MaxPooling1D\nfrom tensorflow.keras.layers import BatchNormalization","ab47991d":"with strategy.scope():\n    model = load_model('..\/input\/tps1021\/best_85294.h5')","760720d4":"preds = model.predict(dataset_test_sc)\noutput = pd.DataFrame({'Id': dataset_test1.index,'target': preds[:,0]})\npath = 'sample_submission.csv'\noutput.to_csv(path, index=False)\noutput ","344ee495":"reduce memory usage"}}