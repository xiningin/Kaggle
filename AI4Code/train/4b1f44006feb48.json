{"cell_type":{"4f3cb0e3":"code","d8d568d5":"code","942d0f5d":"code","16fec8cc":"code","ca3f6346":"code","acb5bf2b":"code","17a8117b":"code","48409f73":"code","cb8f9996":"code","fc9746ae":"code","9d241971":"code","602fc6d2":"code","52753aa7":"code","58c31842":"code","3d3d8476":"code","0df368f7":"code","614250ea":"code","680a3413":"code","90b5f080":"code","4c971b89":"code","402294e1":"code","42959353":"code","a75ad27f":"code","4bb38439":"code","031a1a95":"code","1fb21bfa":"code","8c6bd58d":"code","5bbf1678":"code","924d22fc":"code","a0a8d2d8":"code","46440c96":"code","7c4964fa":"code","33681d45":"code","28c4015b":"code","7f964b79":"code","68c289da":"code","f589911a":"code","abd84a8d":"code","ee4d7e0e":"code","54ab39b7":"code","b3d7bd29":"code","3d00bd72":"code","665a1a88":"code","6632cbc6":"code","a40470f2":"code","45999311":"markdown","0c07bdf1":"markdown","c24e7d69":"markdown","b1b68279":"markdown","ce6715c0":"markdown","3868723e":"markdown","28cd5763":"markdown","b5cc7f28":"markdown","d3ebfb7b":"markdown","fad81292":"markdown","50c4f652":"markdown","78c31190":"markdown","efbb9550":"markdown","f3fc4621":"markdown"},"source":{"4f3cb0e3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d8d568d5":"# read the data to pandas dataframe\n\nretail = pd.read_csv('..\/input\/online-retail-customer-clustering\/OnlineRetail.csv', sep=\",\", encoding=\"ISO-8859-1\", header=0)\nretail.head()","942d0f5d":"# shape of df\n\nretail.shape","16fec8cc":"# df info\n\nretail.info()","ca3f6346":"type_counts = retail['Country'].value_counts()\nCountry=pd.DataFrame(type_counts)\nCountry.head()","acb5bf2b":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(20,10))\nCountry=Country.head()\nax = sns.barplot(y='Country',x=Country.index, data=Country.head())\nplt.xticks(rotation=45)","17a8117b":"retail=retail[retail['Country']=='United Kingdom']\nretail.shape","48409f73":"# Calculating the Missing Values % contribution in DF\n\ndf_null = round(100*(retail.isnull().sum())\/len(retail), 2)\ndf_null","cb8f9996":"# Droping rows having missing values\n\nretail = retail.dropna()\nretail.shape","fc9746ae":"# Changing the datatype of Customer Id as per Business understanding\n\nretail['CustomerID'] = retail['CustomerID'].astype(str)","9d241971":"# New Attribute : Recency\n\n# Convert to datetime to proper datatype\n\nretail['InvoiceDate'] = pd.to_datetime(retail['InvoiceDate'],format='%d-%m-%Y %H:%M')","602fc6d2":"# Compute the maximum date to know the last transaction date\n\nmax_date = max(retail['InvoiceDate'])\nmax_date","52753aa7":"# Compute the difference between max date and transaction date\n\nretail['Diff'] = max_date - retail['InvoiceDate']\nretail.head()","58c31842":"# Compute last transaction date to get the recency of customers\n\nrfm_r = retail.groupby('CustomerID')['Diff'].min().reset_index()\nrfm_r.head()","3d3d8476":"# Extract number of days only\n\nrfm_r['Diff'] = rfm_r['Diff'].dt.days\nrfm_r.columns = ['CustomerID','Recency']\nrfm_r.head()","0df368f7":"### New Attribute : Frequency\n\nrfm_f = retail.groupby('CustomerID')['InvoiceNo'].count().reset_index()\nrfm_f.columns = ['CustomerID', 'Frequency']\nrfm_f.head()","614250ea":"# New Attribute : Monetary\n\nretail['Amount'] = retail['Quantity']*retail['UnitPrice']\nrfm_m = retail.groupby('CustomerID')['Amount'].sum().reset_index()\nrfm_m.head()","680a3413":"rfm = rfm_r.merge(rfm_f,how='inner',on=['CustomerID'])\nrfm =rfm.merge(rfm_m,how='inner',on=['CustomerID'])\nrfm.head()","90b5f080":"# Outlier Analysis of Amount Frequency and Recency\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nattributes = ['Recency','Frequency','Amount',]\nplt.rcParams['figure.figsize'] = [10,8]\nsns.boxplot(data = rfm[attributes], orient=\"v\", palette=\"Set2\" ,whis=1.5,saturation=1, width=0.7)\nplt.title(\"Outliers Variable Distribution\", fontsize = 14, fontweight = 'bold')\nplt.ylabel(\"Range\", fontweight = 'bold')\nplt.xlabel(\"Attributes\", fontweight = 'bold')","4c971b89":"# Removing (statistical) outliers for Amount\nQ1 = rfm.Amount.quantile(0.05)\nQ3 = rfm.Amount.quantile(0.95)\nIQR = Q3 - Q1\nrfm = rfm[(rfm.Amount >= Q1 - 1.5*IQR) & (rfm.Amount <= Q3 + 1.5*IQR)]\n\n# Removing (statistical) outliers for Recency\nQ1 = rfm.Recency.quantile(0.05)\nQ3 = rfm.Recency.quantile(0.95)\nIQR = Q3 - Q1\nrfm = rfm[(rfm.Recency >= Q1 - 1.5*IQR) & (rfm.Recency <= Q3 + 1.5*IQR)]\n\n# Removing (statistical) outliers for Frequency\nQ1 = rfm.Frequency.quantile(0.05)\nQ3 = rfm.Frequency.quantile(0.95)\nIQR = Q3 - Q1\nrfm = rfm[(rfm.Frequency >= Q1 - 1.5*IQR) & (rfm.Frequency <= Q3 + 1.5*IQR)]","402294e1":"# Rescaling the attributes\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\n\nrfm_df = rfm[['Recency','Frequency', 'Amount']]\n\n# Instantiate\nscaler = StandardScaler()\n\n# fit_transform\nrfm_df_scaled = scaler.fit_transform(rfm_df)\nrfm_df_scaled.shape","42959353":"rfm_df_scaled = pd.DataFrame(rfm_df_scaled)\nrfm_df_scaled.columns = ['Amount', 'Frequency', 'Recency']\nrfm_df_scaled.head()","a75ad27f":"# k-means with some arbitrary k\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=4, max_iter=50)\nkmeans.fit(rfm_df_scaled)\n# assign the label\nrfm['Cluster_Id'] = kmeans.labels_\nrfm.head()","4bb38439":"### visualize the result\nimport plotly.express as px\nrfm[\"Cluster_Id\"] = rfm[\"Cluster_Id\"].astype(str) #convert to string\nfig = px.scatter_3d(rfm, x='Recency', y='Frequency', z='Amount',\n              color='Cluster_Id')\nfig.show()","031a1a95":"from yellowbrick.cluster import KElbowVisualizer\nmodel = KMeans()\nvisualizer = KElbowVisualizer(\n    model, k=(2,9), metric='distortion')\n\nvisualizer.fit(rfm_df_scaled)        # Fit the data to the visualizer\nvisualizer.show() ","1fb21bfa":"from yellowbrick.cluster import KElbowVisualizer\nmodel = KMeans()\nvisualizer = KElbowVisualizer(\n    model, k=(2,9), metric='silhouette')\n\nvisualizer.fit(rfm_df_scaled)        # Fit the data to the visualizer\nvisualizer.show()        # Finalize and render the figure","8c6bd58d":"from yellowbrick.cluster import KElbowVisualizer\nmodel = KMeans()\nvisualizer = KElbowVisualizer(\n    model, k=(2,9), metric='calinski_harabasz')\n\nvisualizer.fit(rfm_df_scaled)        # Fit the data to the visualizer\nvisualizer.show()        # Finalize and render the figure","5bbf1678":"# k-means with some arbitrary k\nk=3\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=k, max_iter=50)\nkmeans.fit(rfm_df_scaled)\n# assign the label\nrfm['Cluster_Id'] = kmeans.labels_\nrfm.head()","924d22fc":"### visualize the result\nimport plotly.express as px\nrfm[\"Cluster_Id\"] = rfm[\"Cluster_Id\"].astype(str) #convert to string\nfig = px.scatter_3d(rfm, x='Recency', y='Frequency', z='Amount',\n              color='Cluster_Id')\nfig.show()","a0a8d2d8":"# Box plot to visualize Cluster Id vs Frequency\nimport seaborn as sns\n\nsns.boxplot(x='Cluster_Id', y='Recency', data=rfm)","46440c96":"# Box plot to visualize Cluster Id vs Frequency\nimport seaborn as sns\n\nsns.boxplot(x='Cluster_Id', y='Frequency', data=rfm)","7c4964fa":"# Box plot to visualize Cluster Id vs Frequency\nimport seaborn as sns\n\nsns.boxplot(x='Cluster_Id', y='Amount', data=rfm)","33681d45":"Target_Customer = rfm[rfm['Cluster_Id']=='2']\nTarget_Customer.head()","28c4015b":"Target_Customer.count()","7f964b79":"from scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree","68c289da":"# Single linkage: \n\nmergings = linkage(rfm_df_scaled, method=\"single\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","f589911a":"# Complete linkage\n\nmergings = linkage(rfm_df_scaled, method=\"complete\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","abd84a8d":"# Average linkage\n\nmergings = linkage(rfm_df_scaled, method=\"average\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","ee4d7e0e":"# 3 clusters\nk=3\ncluster_labels = cut_tree(mergings, n_clusters=k).reshape(-1, )\nrfm['Cluster_Labels'] = cluster_labels\nrfm.head()","54ab39b7":"### visualize the result\nimport plotly.express as px\nrfm[\"Cluster_Labels\"] = rfm[\"Cluster_Labels\"].astype(str) #convert to string\nfig = px.scatter_3d(rfm, x='Recency', y='Frequency', z='Amount',\n              color='Cluster_Labels')\nfig.show()","b3d7bd29":"# Box plot to visualize Cluster Id vs Frequency\nimport seaborn as sns\n\nsns.boxplot(x='Cluster_Labels', y='Recency', data=rfm)","3d00bd72":"# Box plot to visualize Cluster Id vs Frequency\nimport seaborn as sns\n\nsns.boxplot(x='Cluster_Labels', y='Frequency', data=rfm)","665a1a88":"# Box plot to visualize Cluster Id vs Frequency\nimport seaborn as sns\n\nsns.boxplot(x='Cluster_Labels', y='Amount', data=rfm)","6632cbc6":"Target_Customer2 = rfm[rfm['Cluster_Labels']=='2']\nTarget_Customer2.head()","a40470f2":"Target_Customer2.count()","45999311":"5. Rescaling the Attributes by Standardisation (mean-0, sigma-1)","0c07bdf1":"1. Calculating Recency","c24e7d69":"4. Remove Outliers","b1b68279":"2. Calculating Frequency","ce6715c0":"**2. Finding the best K: A fundamental step for any unsupervised algorithm is to determine the optimal number of clusters into which the data may be clustered. **","3868723e":"# **Step 3: K-Means Clustering**","28cd5763":"# **Step 4: Hierarchical Clustering**","b5cc7f28":"1. Initial Cluster Given K","d3ebfb7b":"3. Calculating Monetary","fad81292":"# **Step 1: Import and Examine the data**","50c4f652":"1. Visualize Tree by Linkage Methods","78c31190":"Method 1: Finding the elbow point for (inertia_) \"Sum of squared distances of samples to their closest cluster center\".","efbb9550":"# **Step 3: Data Preparation for RFM Factors**","f3fc4621":"# **Step 2: Data Cleaning**"}}