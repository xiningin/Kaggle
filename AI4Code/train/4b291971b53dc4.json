{"cell_type":{"aeebcec6":"code","21035ccc":"code","c976f1a7":"code","c68c0b6c":"code","5033ad36":"code","90a5a8d9":"code","100279b1":"code","dac23e98":"code","4f0b5257":"code","7cd26b01":"code","6c3847f8":"code","d9ecc88d":"code","868d9833":"code","70a40327":"code","3a351249":"code","fcfc8930":"code","e8947a8a":"code","530e3543":"code","6933b3de":"code","f3a515cd":"code","29447636":"code","3f40d4bb":"code","9eb67d3a":"code","8f7ca580":"code","fbdaa7e1":"code","417f7cf8":"code","f16f3d83":"code","6a6b9912":"code","436fa3b7":"code","6ae2deaf":"code","f4020249":"code","ac2f1950":"code","608cb2a1":"code","d0722d47":"code","f79e92b4":"code","0550d432":"code","931c5c60":"code","f76ec961":"code","013e1382":"code","e4596ca1":"code","7ab3b4f3":"code","c5d660d2":"code","c0e092ad":"code","9a6bf228":"code","b27e6edf":"code","7e4ebcfb":"code","46fce24b":"code","b5c77364":"code","d995b04d":"code","ff0740da":"code","361aae5c":"code","f338d831":"code","7c6aaebf":"code","ec75b0fb":"code","be01f2b3":"code","a4fc47fb":"code","5b80fb76":"code","1c09f172":"code","ef6259b9":"code","20b2154b":"code","d9ea2bc9":"code","b06974bb":"code","9226cf90":"code","bb8804ae":"code","8d0e468e":"code","d48114c0":"code","f9892f41":"code","d6a6bd38":"code","b8c804c0":"code","f4b68029":"code","7ac726ba":"code","ea372bb5":"code","1a83a3fa":"code","24dbe561":"code","a4c3b96c":"code","81f8f4fa":"code","c1803a66":"code","a51e7093":"code","5fe28e06":"code","b4ccb69b":"code","54b5ba00":"code","2a0763c0":"code","f10a244d":"code","20d6ff05":"code","a06a929a":"code","a74e54b7":"code","e0cc3545":"code","78178113":"code","96891c06":"code","9976251d":"code","ab8cc1f2":"code","a22badb9":"code","0ba0fdbc":"code","86daf81a":"code","13e48563":"code","a538ab12":"code","ad093e24":"code","0e869fac":"code","c55ed007":"code","1593e54e":"code","b7088329":"code","d443758f":"code","a5a0adb6":"code","63aaa87e":"code","37e7881b":"code","cd907cf5":"code","388dce1d":"code","7f986c8b":"code","5f096cc6":"code","9eea91d1":"code","0ee49d2f":"code","09edb297":"code","ab533df0":"code","86ffd0b1":"code","6fbe8d76":"code","2a95e537":"code","a3cc34ad":"code","c2a62a5c":"code","b7d57427":"markdown","4aaa8762":"markdown","80f3db73":"markdown","ecec6863":"markdown","61674a6a":"markdown","3a7fdfe9":"markdown","63304d16":"markdown","20155b3e":"markdown","e7c680d5":"markdown","05a51641":"markdown","1d97dbe9":"markdown","2e06999e":"markdown","78b62248":"markdown","44487787":"markdown","659bce89":"markdown","e3b5d9d6":"markdown","12365580":"markdown","74a4db80":"markdown","9a2c1f0a":"markdown","f90676f0":"markdown","02045dd1":"markdown","727a05d6":"markdown","127ec47f":"markdown","b5d56f9c":"markdown","983c94d8":"markdown","d72fc610":"markdown","15a4900a":"markdown","19d718c5":"markdown","3b00562c":"markdown","6e97ee29":"markdown","9d953a24":"markdown","00e73425":"markdown","b27ca744":"markdown","1fe0a669":"markdown","7a6aec49":"markdown","a7b6fd9e":"markdown","994e80cb":"markdown","1de269e7":"markdown","db06b109":"markdown","b9dce79b":"markdown","960d6af9":"markdown","3cea9de3":"markdown","614497d3":"markdown","9da43b46":"markdown","125fe04c":"markdown","4025b1c6":"markdown","4e2b3510":"markdown","9a7ec38b":"markdown","dd17ee81":"markdown","138f574b":"markdown","c2fe302a":"markdown","05c8e7f6":"markdown","851e2962":"markdown","f648d03a":"markdown","cb6ec066":"markdown","09b8ee79":"markdown","9de2d16c":"markdown","dec60076":"markdown","4c5d7af7":"markdown","be988136":"markdown","23fa3374":"markdown","4bab2011":"markdown","cb03acb1":"markdown","3585b67e":"markdown","b57bf173":"markdown","dd9f54ef":"markdown","a27f0efd":"markdown","da06fa24":"markdown","fe378e93":"markdown","b4ca89fe":"markdown","ba3b52f0":"markdown","b74f075a":"markdown","5fed3315":"markdown","026b88fa":"markdown","e63c275a":"markdown","e792ceb8":"markdown","e749b462":"markdown","b56bf3ed":"markdown","7ef46b93":"markdown","3d224686":"markdown","fee37d1b":"markdown","a54319b2":"markdown","6784dc38":"markdown","dec73d2b":"markdown","c74df15e":"markdown","9c5c5d24":"markdown","20aa363d":"markdown","9fcd9915":"markdown","219e3291":"markdown","71e5b24b":"markdown","494be027":"markdown","6419a69b":"markdown","691cdaba":"markdown","bc3e787d":"markdown","1b0a666c":"markdown","b2479121":"markdown","008580fa":"markdown","bd8f2411":"markdown","ba3d6a50":"markdown","01753120":"markdown"},"source":{"aeebcec6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","21035ccc":"import glob\nimport sys\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom tqdm.notebook import tqdm_notebook as tq\nimport plotly.graph_objects as go\n","c976f1a7":"# #\nproducts=pd.read_csv('..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv')\ndistricts=pd.read_csv('..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv')\n\n\n#to access all the engament datasets, we create a helper function to combine all of them into one huge dataset\n\nfor i in tq(range(1),desc=\"Testing\"):\n    pass","c68c0b6c":"home_dir=os.getcwd()","5033ad36":"#to access all the engament datasets, we create a helper function to combine all of them into one huge dataset\ndef get_all():\n    try:\n        os.chdir(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data\") \n        for i in tq(range(1),desc=\"Loading data\") :\n            folder='..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data\/'\n            extension='csv'\n            all_files = [i for i in glob.glob('*.{}'.format(extension))]\n\n            all_data=pd.concat([pd.read_csv(f) for f in all_files ])\n#             print(all_files)\n\n        os.chdir(home_dir)\n        return all_data\n        \n    except Exception as e:\n        \n        print (\"System error\")\n        sys.exit(1)","90a5a8d9":"data=get_all()","100279b1":"data","dac23e98":"data.shape","4f0b5257":"products","7cd26b01":"districts","6c3847f8":"#we define a couple of scripts that we shall implement\ndef null_values(df):\n    \n    #get the number of null values in the system\n    try:\n        print(\" #### Calculating Missing Values ##### \\n\")\n        for i in tq(range(1),desc=\"Fetching data\"):\n        \n            \n            \n            sumofNull=df.isna().sum()\n            percentage=sumofNull\/len(df)*100\n        print(\" #### Done #### \\n \")\n            \n            \n        \n        print(\"#### Creating data frame #### \\n \")\n        \n        for i in tq(range(1),desc=\"Creating DataFrame\"):\n            valuesdf=pd.DataFrame(data=[sumofNull,percentage])\n            valuesdf=valuesdf.T\n            valuesdf.columns=[\"Total Missing\",\"Percentage Missing\"]\n        print(\" #### Done #### \")\n        \n\n        return valuesdf\n            \n    except Exception as e:\n        \n        print(\" !!! Error File Not Found  !!!!! \\n\")\n        print(\" !!! Program Failed !!!!! \\n\")\n        \n        print(\"Safely exiting the program\")\n        sys.exit(1)\n\ndef dropDuplicates(data):\n        try:\n            \n            for i in tq(range(1),desc=\"Detecting duplicates\"):\n                data=data.drop_duplicates()\n            for i in tq(range(1),desc=\"Report on Duplicates \"):\n                dupCount=len(data)-len(data.drop_duplicates())\n                \n            print (\"There are {} duplicates in the dataset\\n\".format(dupCount))\n            logging.info(\"Number of duplicates in the datset are {} \".format(dupCount))\n\n            \n\n            return data \n        except Exception as e:\n\n            print(\"The following error occured {} \".format(e.__class__))","d9ecc88d":"districts","868d9833":"districts.info()","70a40327":"null_values(districts)","3a351249":"test=districts[(districts['state'].notnull())& (districts['locale'].notnull())]","fcfc8930":"test","e8947a8a":"null_values(test)","530e3543":"test","6933b3de":"nulls=test[(test['pct_black\/hispanic'].isnull()) | (test['pct_free\/reduced'].isnull())]\n\nnulls","f3a515cd":"data_massachets=test[test['state']=='Massachusetts']\ndata_massachets","29447636":"test['pct_free\/reduced'].fillna('[0.4, 0.6[',inplace=True)\ntest","3f40d4bb":"null_values(test)","9eb67d3a":"pct_null=test[test['pp_total_raw'].isnull()]\npct_null","8f7ca580":"test[test['state']=='Connecticut']","fbdaa7e1":"# r=test[(test['state']=='Connecticut')&(test['pp_total_raw'].isnull())]['pp_total_raw'].fillna('[14000, 16000[')\n# r\ntest['pp_total_raw']=np.where(test['state']=='Connecticut','[14000, 16000[' , test.\tpp_total_raw)\ntest","417f7cf8":"null_values(test)","f16f3d83":"test[test['state']=='Connecticut']","6a6b9912":"test[test['state']=='California']","436fa3b7":"test['pp_total_raw']=np.where(test['state']=='California','[11000, 13000[' , test.pp_total_raw)\ntest","6ae2deaf":"null_values(test)","f4020249":"#we get the state abbrevations to use in potting graphs\nstate_abb = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District Of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}\n\ndistricts['state_abb'] = districts['state'].map(state_abb)\n\n\n","ac2f1950":"def count_plot(data,colr,title):\n    plt.figure(figsize=(10,8))\n    ax=sns.countplot(x=data,palette=colr,order=data.value_counts().index)\n    plt.xticks(rotation=90)\n    plt.title(title)\n    for p in ax.patches:\n        ax.text (p.get_x() + p.get_width()  \/ 2,p.get_height()+ 0.75,p.get_height(), fontsize = 11)\n#         ax.text('%{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+50))\ndef count_plot_xy(data,colr,title,data2):\n    plt.figure(figsize=(10,8))\n    ax=sns.countplot(x=data,y=data2,palette=colr,order=data.value_counts().index)\n    plt.xticks(rotation=90)\n    plt.title(title)\n    for p in ax.patches:\n        ax.text (p.get_x() + p.get_width()  \/ 2,p.get_height()+ 0.75,p.get_height(), fontsize = 11)\n#         ax.text('%{:.1f}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+50))\ndef geo_map(title,state_abb,colorscheme):\n    fig = go.Figure()\n    layout = dict(title_text = title,title_font = dict(family = \"monospace\",size = 25,color = \"black\"),geo_scope = 'usa')\n\n    fig.add_trace(go.Choropleth(locations = state_abb.value_counts().to_frame().reset_index()['index'],\n            zmax = 1,\n            z = state_abb.value_counts().to_frame().reset_index()['state_abb'],\n            locationmode = 'USA-states',\n            marker_line_color = 'white',\n            geo = 'geo',\n            colorscale = colorscheme, \n        )\n    )\n\n    fig.update_layout(layout)   \n    fig.show()\n","608cb2a1":"geo_map(\"Count of districts in the available States\",districts['state_abb'],\"dense\")","d0722d47":"# fig = go.Figure()\n# layout = dict(\n#     title_text = \"Count of districts in the available States\",\n#     title_font = dict(\n#             family = \"monospace\",\n#             size = 25,\n#             color = \"black\"\n#             ),\n#     geo_scope = 'usa'\n# )\n\n# fig.add_trace(\n#     go.Choropleth(\n#         locations = districts['state_abb'].value_counts().to_frame().reset_index()['index'],\n#         zmax = 1,\n#         z = districts['state_abb'].value_counts().to_frame().reset_index()['state_abb'],\n#         locationmode = 'USA-states',\n#         marker_line_color = 'white',\n#         geo = 'geo',\n#         colorscale = \"cividis\", \n#     )\n# )\n            \n# fig.update_layout(layout)   \n# fig.show()\n","f79e92b4":"count_plot(districts['state'],'RdYlGn',\"State representation\")","0550d432":"plt.figure(figsize = (15, 8))\nsns.set_style(\"white\")\na = sns.barplot(data = districts['state'].value_counts().reset_index(), x = 'state', y = 'index', color = '#90afc5')\nplt.xticks([])\nplt.yticks(fontsize = 14, color = '#283655')\nplt.ylabel('')\nplt.xlabel('')\n\na.spines['left'].set_linewidth(1.5)\nfor w in ['right', 'top', 'bottom']:\n    a.spines[w].set_visible(False)\n    \nfor p in a.patches:\n    width = p.get_width()\n    plt.text(0.5 + width, p.get_y() + 0.55 * p.get_height(), f'{int(width)}',\n             ha = 'center', va = 'center',  fontsize = 15, color = '#283655')\n\nplt.show()","931c5c60":"count_plot(districts['locale'],'Blues','locale representation') ","f76ec961":"plt.figure(figsize=(20,10))\nax=sns.countplot(data=districts,x='state',hue='locale',palette='Blues')\nplt.xticks(rotation=90)\nplt.title(\"State vs Locality\")\nfor p in ax.patches:\n    ax.text (p.get_x() + p.get_width()  \/ 2,p.get_height()+ 0.75,p.get_height(), fontsize = 11)\n","013e1382":"distcrict_copy=districts.copy()\ndistricts.dropna(inplace=True)","e4596ca1":"\ndistricts['pct_black\/hispanic']=districts['pct_black\/hispanic'].apply(lambda x :float(x.split(',')[0][1:])+0.1)\n\ndistricts['pct_free\/reduced']=districts['pct_free\/reduced'].apply(lambda x :float(x.split(',')[0][1:])+0.1)","7ab3b4f3":"districts=districts.reset_index()","c5d660d2":"districts.drop(labels='index',inplace=True,axis=1)","c0e092ad":"districts","9a6bf228":"districts['pp_total_raw']=districts['pp_total_raw'].apply(lambda x :float(x.split(',')[0][1:])+1000)\ndistricts['county_connections_ratio']=districts['county_connections_ratio'].apply(lambda x: float(x.split(',')[0][1:])+0.1)\n\ndistricts\n","b27e6edf":"state_locale_df=districts.groupby(['state_abb','locale']).agg({'pct_black\/hispanic':np.mean,'pct_free\/reduced':np.mean,'pp_total_raw':np.mean})\nstate_locale_df=state_locale_df.reset_index()\nstate_locale_df","7e4ebcfb":"state_pct=districts.groupby('state').agg({'pct_black\/hispanic':np.mean,'pct_free\/reduced':np.mean,'pp_total_raw':np.mean})","46fce24b":"state_pct=state_pct.reset_index()","b5c77364":"state_pct['state_abb']=state_pct['state'].map(state_abb)","d995b04d":"#is there a relationship between the two ratios?\nsns.heatmap(state_pct.corr(),annot=True)","ff0740da":"fig = px.bar_polar(state_pct, r=\"pct_black\/hispanic\", theta=\"state\", \n            color_discrete_sequence= px.colors.sequential.thermal)\nfig.show()","361aae5c":"# sample funnel graph showing the percentage of black\/hispanic students in each state\n\nfig = px.funnel(state_pct, x='pct_black\/hispanic', y='state')\nfig.show()","f338d831":"fig = px.bar_polar(state_pct, r=\"pct_free\/reduced\", theta=\"state\", template=\"plotly_dark\",\n            color_discrete_sequence= px.colors.sequential.Plasma_r)\nfig.show()","7c6aaebf":"#create a locale \nlocale_df=districts.groupby('locale').agg({'pct_black\/hispanic':np.mean,'pct_free\/reduced':np.mean})","ec75b0fb":"locale_df=locale_df.reset_index()","be01f2b3":"plt.figure(figsize=(15,9))\nax=sns.barplot(x=\"locale\", y=\"pct_black\/hispanic\", data=state_locale_df,palette=\"magma\")\n\nplt.xticks(rotation=90)\nplt.title(\"Percentage of blacks and hispanic in the locales\")\n\n\n\n\n","a4fc47fb":"\ndef geo_map_z(title,loc,param,col):\n    \n    fig = go.Figure()\n    layout = dict(\n        title_text = title,\n        title_font = dict(family = \"monospace\",size = 25,color = \"black\"),geo_scope = 'usa') \n\n    fig.add_trace(\n        go.Choropleth(\n            locations = loc.value_counts().to_frame().reset_index()['index'],\n            zmax = 1,\n            z = param,\n            locationmode = 'USA-states',\n            marker_line_color = 'white',\n            geo = 'geo',\n            colorscale = col, \n        )\n        \n    )\n\n    fig.update_layout(layout)   \n    fig.show()\n\n# geo_map(\"Count of districts in the available States\",districts['state_abb'],\"dense\")\ngeo_map_z(\"Percentage of blacks per state\",state_locale_df['state_abb'],state_locale_df['pct_black\/hispanic'],\"picnic\")","5b80fb76":"geo_map_z(\"Free or reduced lunch in State\",state_locale_df['state_abb'],state_locale_df['pct_free\/reduced'],\"Reds\")","1c09f172":"plt.figure(figsize = (15, 8))\nsns.set_style(\"white\")\na = sns.barplot(data = state_pct, y = 'state', x = 'pct_free\/reduced', color = '#90afc5')\n# plt.xticks([])\nplt.yticks(fontsize = 14, color = '#283655')\nplt.ylabel('Pct_free\/Reduced fee')\nplt.xlabel('State')\n\na.spines['left'].set_linewidth(1.5)\nfor w in ['right', 'top', 'bottom']:\n    a.spines[w].set_visible(False)\n    \n    \n# for p in a.patches:\n#     ax.text (p.get_x() + p.get_width()  \/ 2,p.get_height()+ 0.75,p.get_height(), fontsize = 11)\n\nplt.show()","ef6259b9":"plt.figure(figsize=(15,15))\nsns.catplot(y=\"pct_free\/reduced\", x=\"state\",hue=\"locale\",palette=\"rocket\",data=districts, kind=\"bar\",height=7,aspect=2)\nplt.xticks(rotation=90);\nplt.title(\"Distribution of state percentage of reduced and free lunches\")","20b2154b":"# fig = go.Figure()\n# layout = dict(\n#         title_text = \"test\",\n#         title_font = dict(family = \"monospace\",size = 25,color = \"black\"),geo_scope = 'usa') \n\n# fig.add_trace(\n#         go.Choropleth(\n#             locations = loc.value_counts().to_frame().reset_index()['index'],\n#             zmax = 1,\n#             z = param,\n#             locationmode = 'USA-states',\n#             marker_line_color = 'white',\n#             geo = 'geo',\n#             colorscale = col, \n#         )\n        \n#     )\n\n# fig.update_layout(layout)   \n# fig.show()","d9ea2bc9":"# fig = go.Figure()\n# layout = dict(\n#     title_text = \"Percentage reduced fees per state\",\n#     title_font = dict(\n#             family = \"monospace\",\n#             size = 25,\n#             color = \"black\"\n#             ),\n#     geo_scope = 'usa'\n# )\n\n# fig.add_trace(\n#     go.Choropleth(\n#         locations = state_pct['state_abb'].value_counts().to_frame().reset_index()['index'],\n#         zmax = 1,\n#         z = state_pct['pct_free\/reduced'],\n#         locationmode = 'USA-states',\n#         marker_line_color = 'white',\n#         geo = 'geo',\n#         colorscale = \"peach\", \n#     )\n# )\n            \n# fig.update_layout(layout)   \n# fig.show()\n","b06974bb":"fig = px.bar_polar(state_pct, r=\"pp_total_raw\", theta=\"state\", template=\"plotly_dark\",\n            color_discrete_sequence= px.colors.sequential.Plasma_r)\nfig.show()","9226cf90":"state_locale_df","bb8804ae":"plt.figure(figsize=(15,15))\nsns.catplot(y=\"pp_total_raw\", x=\"state_abb\",hue=\"locale\",palette=\"rocket\",data=state_locale_df, kind=\"bar\",height=7,aspect=2)\nplt.xticks(rotation=90);\nplt.title(\"Distribution of state percentage of reduced and free lunches\")","8d0e468e":"plt.figure(figsize=(15,9))\nax=sns.barplot(x=\"locale\", y=\"pp_total_raw\", data=state_locale_df,palette=\"magma\")\n\nplt.xticks(rotation=90)\nplt.title(\"Percentage of blacks and hispanic in the locales\")","d48114c0":"#Does having a increasing percentage of free lunch students affect expenditure per students?\nfig = px.bar_polar(state_locale_df, color=\"pct_free\/reduced\", theta=\"state_abb\", r=\"pp_total_raw\",template=\"plotly_dark\",\n            color_discrete_sequence= px.colors.sequential.Plasma_r)\nfig.show()","f9892f41":"products","d6a6bd38":"products.shape","b8c804c0":"products.info()","f4b68029":"products","7ac726ba":"null_values(products)","ea372bb5":"products[products['Sector(s)'].isna()]","1a83a3fa":"products['Sector(s)'].value_counts()","24dbe561":"products['Sector(s)']=np.where(products['Sector(s)'].isna(),'Multipurpose',products['Sector(s)'])\nproducts","a4c3b96c":"products['Primary Essential Function'].value_counts()","81f8f4fa":"products['Primary Essential Function']=np.where(products['Primary Essential Function'].isna(),'GP - General Purpose',products['Primary Essential Function'])\nproducts","c1803a66":"null_values(products)","a51e7093":"products[products['Provider\/Company Name'].isna()]","5fe28e06":"products['Provider\/Company Name']=np.where(products['Provider\/Company Name'].isna(),'PowerSchool Group LLC',products['Provider\/Company Name'])\nproducts","b4ccb69b":"null_values(products)","54b5ba00":"products['Function Class']=products['Primary Essential Function'].apply(lambda x : x.split('-')[0])\nproducts['Function Desc']=products['Primary Essential Function'].apply(lambda x : x.split('-')[1])\n\nproducts","2a0763c0":"products.drop(labels=['Primary Essential Function'],axis=1,inplace=True)\nproducts","f10a244d":"products.info()","20d6ff05":"products['Product Name'].value_counts()","a06a929a":"#we get the top ten provider companies \nproducts['Provider\/Company Name'].value_counts()[:10].index","a74e54b7":"\nplt.figure(figsize=(12,8))\nax=sns.countplot(products['Provider\/Company Name'],palette='cool_r',order=products['Provider\/Company Name'].value_counts()[:10].index)\nplt.title(\"Top 10 Ownership share of company and products\")\nplt.xticks(rotation=90);\nfor p in ax.patches:\n    ax.text (p.get_x() + p.get_width()  \/ 2,p.get_height()+ 0.75,p.get_height(), fontsize = 11)\n","e0cc3545":"fig = px.pie(products['Provider\/Company Name'].value_counts().reset_index().rename(columns = {'Provider\/Company Name': 'count'}).head(10), values = 'count', names = 'index', width = 700, height = 700)\n\nfig.update_traces(textposition = 'inside', \n                  textinfo = 'percent + label', \n                  hole = 0.7, \n                  marker = dict(colors = ['#90afc5','#336b87','#2a3132','#763626', 'a43820'], line = dict(color = 'white', width = 2)))\n\nfig.update_layout(annotations = [dict(text = 'Company Market Share', \n                                      x = 0.5, y = 0.5, font_size = 26, showarrow = False, \n                                      font_family = 'monospace',\n                                      font_color = '#283655')],\n                  showlegend = False)\n                  \nfig.show()","78178113":"products['Sector(s)'].value_counts()","96891c06":"\nplt.figure(figsize=(12,8))\nax=sns.countplot(products['Sector(s)'],palette='cubehelix_r',order=products['Sector(s)'].value_counts()[:10].index)\nplt.title(\"Top 10 Sectors\")\nplt.xticks(rotation=90);\nfor p in ax.patches:\n    ax.text (p.get_x() + p.get_width()  \/ 2,p.get_height()+ 0.75,p.get_height(), fontsize = 11)\n","9976251d":"fig = px.pie(products['Sector(s)'].value_counts().reset_index().rename(columns = {'Sector(s)': 'count'}).head(10), values = 'count', names = 'index', width = 700, height = 700)\n\nfig.update_traces(textposition = 'inside', \n                  textinfo = 'percent + label', \n                  hole = 0.7, \n                  marker = dict(colors = ['#90afc5','#336b87','#2a3132','#763626', 'a43820'], line = dict(color = 'white', width = 2)))\n\nfig.update_layout(annotations = [dict(text = 'Sector Usage', \n                                      x = 0.5, y = 0.5, font_size = 26, showarrow = False, \n                                      font_family = 'monospace',\n                                      font_color = '#283655')],\n                  showlegend = False)\n                  \nfig.show()","ab8cc1f2":"products['Function Class'].value_counts()","a22badb9":"\nplt.figure(figsize=(12,8))\nax=sns.countplot(products['Function Class'],palette='cubehelix_r',order=products['Function Class'].value_counts().index)\nplt.title(\"Top 10 Sectors\")\nplt.xticks(rotation=90);\nfor p in ax.patches:\n    ax.text (p.get_x() + p.get_width()  \/ 2,p.get_height()+ 0.75,p.get_height(), fontsize = 11)\n","0ba0fdbc":"\nplt.figure(figsize=(12,8))\nax=sns.countplot(products['Function Desc'],palette='cubehelix',order=products['Function Desc'].value_counts().index)\nplt.title(\"Function Descriptions\")\nplt.xticks(rotation=90);\nfor p in ax.patches:\n    ax.text (p.get_x() + p.get_width()  \/ 2,p.get_height()+ 0.75,p.get_height(), fontsize = 11)\n","86daf81a":"data","13e48563":"data.info()","a538ab12":"data.shape","ad093e24":"null_values(data)","0e869fac":"data.dropna(inplace=True)","c55ed007":"data.reset_index(drop=True,inplace=True)","1593e54e":"data","b7088329":"data.info()","d443758f":"data['time']=pd.to_datetime(data['time'])","a5a0adb6":"data.info()","63aaa87e":"#since the year was the same 2021 we don't require the year column\ndata['month'] = data['time'].dt.month\ndata['date']=data['time'].dt.day\ndata['date_week']=data['time'].dt.weekday","37e7881b":"data","cd907cf5":"#we aggreagte the data by date to get some insights for now\ndate_agg=data.groupby(['date','month','date_week']).agg({'engagement_index':np.mean,'pct_access':np.mean})\ndate_agg","388dce1d":"date_agg=date_agg.reset_index()","7f986c8b":"date_agg","5f096cc6":"plt.figure(figsize=(15,11))\nsns.lineplot(y=date_agg['pct_access'],x=date_agg[\"month\"],palette='rocket')\nplt.title(\"Average access per month\")\n","9eea91d1":"plt.figure(figsize=(15,11))\nsns.lineplot(y=date_agg['engagement_index'],x=date_agg[\"month\"],palette='rocket')\nplt.title(\"Average Engagemnet Index per month\")\n","0ee49d2f":"# plt.figure(figsize=(15,11))\n# sns.lineplot(y=date_agg['engagement_index'],x=date_agg[\"month\"],palette='rocket')\n# sns.lineplot(y=date_agg['pct_access'],x=date_agg[\"month\"],palette='rocket')\n# plt.title(\"Average Engagemnet Index per month\")\n","09edb297":"plt.figure(figsize=(15,11))\nsns.lineplot(hue=date_agg['date_week'],y=date_agg['pct_access'],x=date_agg[\"month\"],palette='rocket')\nplt.title(\"Average access per month per day\")\n","ab533df0":"plt.figure(figsize=(15,11))\nsns.lineplot(hue=date_agg['date_week'],y=date_agg['engagement_index'],x=date_agg[\"month\"],palette='twilight_shifted')\nplt.title(\"Average access per month per day\")\n","86ffd0b1":"plt.figure(figsize=(15,10))\nsns.lineplot(y=date_agg['engagement_index'],x=date_agg[\"date_week\"])","6fbe8d76":"plt.figure(figsize=(15,10))\nsns.lineplot(y=date_agg['pct_access'],x=date_agg[\"date_week\"])","2a95e537":"finaldf=pd.merge(products,data,left_on='LP ID',right_on='lp_id')","a3cc34ad":"finaldf","c2a62a5c":"# finaldf['district_id']=finaldf['district_id'].astype('int')","b7d57427":"We can then drop the Primary Essential Function column since we have already extracted the features we require","4aaa8762":"## Understanding the Nulls","80f3db73":"## EDA","ecec6863":"### Date of the week","61674a6a":"Connecticut has the most number of district representation with 30 district counts in the dataset closely followed by Utah","3a7fdfe9":"Most of the missing values appear in the sectors and primary Essential Functions.. My intuition tells me that if one is missing the other is also missing..\n\nLest find out\n","63304d16":"### Sector","20155b3e":"**Unique Values**","e7c680d5":"We also discover that all Connecticut states have null values in their percentage expenidure per pupil, we can investigate more on the internet\n\nFrom this article [here](http:\/\/https:\/\/yankeeinstitute.org\/2020\/05\/18\/connecticut-has-third-highest-spending-per-public-school-student-in-the-country\/) Connecticut spends $20,635 on per pupil expenditure so we impute those for the missing values","05a51641":"We have one more null value which is in the provider\/Company Name so lets resolve that\n","1d97dbe9":"### Percentage of Blacks and Hispanic","2e06999e":"# Background","78b62248":"### Expenditure used per pupil","44487787":"## Districts","659bce89":"A couple of things to note\n1. 0 is Monday and 6 is sunday\n2. we see interaction is quite low on the weekends\n3. We see a large dip in the month of July where almost all engagements went close to zero\n4. Engagement reached peek in months of January and September, the trend starts dipping From february","e3b5d9d6":"Most products fall in the LC category lets have a look at the sub-category that has the most products","12365580":"## Merge the Data","74a4db80":"## District data","9a2c1f0a":"Finally Done lets continue shall we...","f90676f0":"Google seems to have the hghest share of products used with 30 of them , Microsoft has the second most products in the market with 6 tied with Houghton Mifflin Harcourt","02045dd1":"**Lets deal with values that are missing from both state and locale**\n\nThis is because we can not examine a state\/locale we don't know ","727a05d6":"We investigate the number of locality found in different states","127ec47f":"Localities in the Suburbs and rural areas generally Suburbs and Rural locales","b5d56f9c":"# Data","983c94d8":"Every district under the state of Massachusetts didn't record any values in the amount of percentage of students eliglble for free or reduced lunch. Lets investiagte the web to analyze the findings...\n\nWe find out thet Massachusetts do have a free lunch policy in their state and has been implementing it since 1984, google stats shows that the state offers free lunch to 51% of their students.\nHence we can fill in the missing columns with between 40 and 50 %","d72fc610":"1. Black\/Hispanic representation in Texas, North Cal and Florida\n2. Why city locales have the highest number of black\/hispanic rep\n3. Do locales affect percentage fees reduced\n4. Does having higher percentage of free\/reduced lunch affect the amount expenditure per pupil\n","15a4900a":"We aggeregate by state and find the percentages features. But first a quick look at the column we do realize that the column is made of intervals.\n\nA quick intro to interval notation:\n\n***]a,b[ := {: a<x <b }*** : **open Real interval**\n\n***[a,b[ := {a<= x <b}***  :  **Half-open on the right**\n\n***]a,b] := {a<xb<=b}*** : **Half-open on the left**","19d718c5":"The dataset has 372 records and 6 features","3b00562c":"New york seems to have the highest number of expenditure per pupil, we also do notice that the states that had higher pct_ofblacks\/hispanic has a lower expenditure per pupil","6e97ee29":"A couple of states are missing this column and hence lets dive deep and understand whether there is any relationship between this and missing values","9d953a24":"With the size of our data hence we can't start investigating 5378409 missing values and hence for this we drop them","00e73425":"## Pct_Black and Hispanics","b27ca744":"Can this be affected by the locale of a district , lets viusialize and see if it affects that","1fe0a669":"Lets have a look at all the available data","7a6aec49":"### Percentage Free Lunch","a7b6fd9e":"# Exploratory Data Analysis","994e80cb":"Most of the products are just singles so we move and see if any company owns mulitple services","1de269e7":"We however have to impute the values first before carrying on with the analysis\n","db06b109":"The reamining values seem to be a small percentage of the data and we can hence use techniques to impute this values, we can handle the missing values through. We drop rows that all the values are null and see if we can narrow down on our null values ","b9dce79b":"Prek has the highest products under its sector, we should keep this in mind for future analysis","960d6af9":"### Products","3cea9de3":"## Locales distribution in districts","614497d3":"We can create something off the time feature so that we can have more insights genrated","9da43b46":"## Understanding the data","125fe04c":"As we had earlier read in the article New York has the highest number of per pupil expenditure and New-Jersey close by","4025b1c6":"New Jersey and and New York only have Suburbs and Rural settings can this be a confounder in the amount of expenditure used by governements","4e2b3510":"The products column includes 372 entries and 6 features","9a7ec38b":"**Columns**\nThe data features in the dataset are \n1. district_id : The respective district identification number\n2. State : The state that the district belongs to \n3. locale : The locale the given district is located\n4. pc_black\/hispanic : The percntage of students that identify as black\/hispanic\n5. pct_free\/reduced : percentage of students eliglble for free or reduced lunch\n6. county_connections_ratio : ratio of high internet speeds \n7. pp_total_raw : sum of local and federal expenditure per pupil ","dd17ee81":"Highest percentage of blacks and hispanics can be found in City with towns having the least number of black\/ hispanic representation","138f574b":"## Understanding States","c2fe302a":"## Function Class","05c8e7f6":"With that done lets do some pre-processing and feature extraction to the data","851e2962":"Texas has the highest number of black\/hispanic representation\nQuick review of the polar chart we spot that it doesn't have any clean relationship between pct_black\/hispanic and pct_free\/reduced ","f648d03a":"### What to look for?","cb6ec066":"### Understanding the Missing Values","09b8ee79":"## products","9de2d16c":"## Engagement Data","dec60076":"### Fixing the interval columns","4c5d7af7":"A great number of the education insituions are located in the Suburbs \n**but does this result in bettter education \nHow do they compare to the other locales**?","be988136":"We notice that cities have the highest percentage of black\/hispanic students while rural locales have the least percentage.\nUtah also has the highest percentage but can this be due to the high representation of districts in the datset","23fa3374":"The districts column has 233 records with 7 feature columns","4bab2011":"Covid-19 can possibly be the largest global distater of the decade with current number of reported cases standing at 217 Million. The effects are massive and not only on health but on daily lives. We have had to adapt to this norm as we can't let it stop us from living. Technology has been at the forefront in combating the spread of this virus, be it from medical research,global prediction and response equipment among many others. \n\nEducation has been a major field of our lives that has been majorly hit. In the past most of the education involved in-person communication; i.e student and teacher are in the same physical location and space. Countries shut-down most educational institiuions at the begining of lockdown measures, as they aimed at limiting public gatherings and interactions\nThis by itself created a major setback on learning. Students had to adjust to learning using collaborative spaces and video-conferecning platforms. \n\nThis has escaleted the ibalance in the education space, especially in how students access and the quality of education they do get. Factors such as socio-economic status, learning ability, envioronment all play a crucial role in determining the access to education.  \n\nThis analysis therefore aims at analysing this common factors that bring about inequality in the education system, and through that come up woth positive policies and solutions to how better not only governments but also schools can play their part in bridging the educational divide especially during this covid period \n","cb03acb1":"We now investiagte the percentage of expenidture per pupil in the missing values","3585b67e":"We aggregate the data by state and hopeully understand what goes on there","b57bf173":"Its only fair that Digital Learning Platforms get the top spot for products used as during the pandemic most of studies happened online","dd9f54ef":"### Monthly Engagement","a27f0efd":"## Questions that arise","da06fa24":"we address this by spliting by the , and taking the values ","fe378e93":"We can discover that if the state data is missing then locale and pc_black\/hispanic records are probably also missing.\nWe see that ppl_total_raw has roughly 49% null values which isn't that good for our anlysis","b4ca89fe":"We have merged the engagement data into a single csv. It contains 22324190 records and four features.","ba3b52f0":"## Sector","b74f075a":"We stumble upon an interesting finding most of the null values in the pct_free\/reduced column are from Massachusetts, is it that the whole state didn't record it or they actually don't have that lets find out ","5fed3315":"We create a new essential function called MT=Multipurpose this is for the new imputed values ","026b88fa":"## Preprocessing","e63c275a":"### Engagement","e792ceb8":"1. We find that most of the states expect califronia are made up of the suburbs,\n2. california is made up of mainly tow locales, Arizona only has twin locales \n3. NorthDakota has Rural locales \n4. New Hempshire as well\n5. Tennessee is made up of rural and town locales","e749b462":"From the quick summary above we can tell we have quite a number of null values. From the description the null values are meant to create a form of anonymity,hence most of the data is structurally missing.\n\nLets calculate the missing values","b56bf3ed":"Seems like there's a trend, we assume the break is due to the summer break that was there from June to Mid August","7ef46b93":"## Pre Processing","3d224686":"As expected there is more engagment at the begining of the week and it slowly drops as we get to the weekend , with Tuesday having the highest number of  average engagment ","fee37d1b":"A quick google search can provide the parent company of True North Logic, which happens to be PowerSchool Group LLC so we impute the missing value there","a54319b2":"## Feture Generation","6784dc38":"As with Connecticut we experience the same issue with California and hence we head back to our article to find answers\nand we do find out that it has $12,498 per pupil spending expenditure\n\nHence we impute the missing values with the interval close to that","dec73d2b":"We are making progress huh?","c74df15e":"This follows a similar curve as the engagment_index","9c5c5d24":"## Loading Data","20aa363d":"## Visaulize","9fcd9915":"From the look of things we do have lots of products here,lets start of by undetsanding what each column contains\n\n1. **LP_ID-** Unique product identifier \n2. **URL**-Url of the product\n3. **Product Name** - Name of the product\n4. **Provider\/ Company Name** - Owner of the product\n5. **Sector(s)**- Sector the product falls under\n6. **Primary Essential Function**- The main purpose the product serves: LC= learning Curriculum, CM=Classroom Managment SDO= School & District Operations","219e3291":"The dataset has 2.2 Million records and 4 features that is huge for sure","71e5b24b":"Most of the states mainly consist of Suburb locales. This locales seem to have the highest number of pct of hispanic and blacks except in Illinois and North Carolina. ","494be027":"lets review the data","6419a69b":"Lets get some insights on the trend","691cdaba":"The data used comes from LearnPlatform, an educational Technology company that aims to expand equitable access to education technology for all stdents and teachers. It generates evidence basis for what is currently working and enacting it to benefit of the parties involved.\n\nThe data collected comprised of 233 school districts toatllying 22 M datapoints to investiagte.\nThe data gives insights to educational\/ learning platforoms used within the period of 1st January 2020 to 31st Decemeber 2020. This is was the begining and first and second wave of global spread, this generated lot's of activity on this platform\n\nThe dataset used is split into three categories\n1. district_info.csv - which gives information about the educational district \n2. Products_info.csv -Which contains more description on the platforms used \n3. Engagement data -This is a folder that holds datasets that explain the enagement of the user and the varius platforms based on their distrcits\n\n","bc3e787d":"Yup thought so, so we could actually run through the null values and see what we can use to impute them since some of the products are commonly used platforms","1b0a666c":"Seems like we get a different graph as the one above, engament spikes up in the fourth month during which we experience the most engagment on Mondays,\n\nHowever there's something interesting about Wednesdays it has a quite amusing graph. That needs to be investigated soon","b2479121":"We look at the distribution of locales per area","008580fa":"Whats the most Used products ?","bd8f2411":"Most of the missing values are platforms that are used for multipurpose as they fit in all the sectors. Hence impute using new multiPurpose entry","ba3d6a50":"Seems like the first month was slow in the engagement index, lets check on that ","01753120":"What was the main sector of interest for the users?"}}