{"cell_type":{"8d785b2f":"code","a0f1ca95":"code","22851da1":"code","9c74b17b":"code","c1ed8431":"code","6667c708":"code","171bcd1f":"code","95201f67":"code","6d05943f":"markdown","0cbb0370":"markdown","adb8f8fd":"markdown"},"source":{"8d785b2f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a0f1ca95":"train = pd.read_csv('\/kaggle\/input\/mmp2021\/xxx_train.csv')\ntest = pd.read_csv('\/kaggle\/input\/mmp2021\/xxx_test.csv')\nsubm =  pd.read_csv('\/kaggle\/input\/mmp2021\/xxx_submission.csv')\n\nprint (train.shape, test.shape, subm.shape)","22851da1":"train.sample(5)","9c74b17b":"y = train.pop('y') # \u0438\u0437\u0432\u043b\u0435\u0447\u0435\u043d\u0438\u0435 \u0446\u0435\u043b\u0435\u0432\u043e\u0433\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430","c1ed8431":"lgb_params = {'learning_rate': 0.3,\n              'objective': 'regression',\n              'metric': 'mae',\n              # 'feature_fraction': 0.75,\n              # 'bagging_fraction': 0.75,\n              'num_leaves': 7}\n\nlcv = lgb.cv(params=lgb_params, train_set=lgb.Dataset(train, y), num_boost_round=1000)","6667c708":"import matplotlib.pyplot as plt\nplt.plot(lcv['l1-mean'])\nplt.xlabel('\u0438\u0442\u0435\u0440\u0430\u0446\u0438\u0438')\nplt.ylabel('MAE')\nprint (f\"\u043c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u0430\u044f \u043e\u0448\u0438\u0431\u043a\u0430 = {np.mean(lcv['l1-mean'])}\")","171bcd1f":"import lightgbm as lgb\n\nmodel = lgb.LGBMRegressor(boosting_type='gbdt',num_leaves=7)\n\nmodel.fit(train, y)\na = model.predict(test)","95201f67":"subm['y'] = np.round(a)\n\nsubm.to_csv('submission.csv', index=False)","6d05943f":"## \u0420\u0435\u0448\u0435\u043d\u0438\u0435","0cbb0370":"## \u043c\u043e\u0434\u0435\u043b\u044c: \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u044b \u0441 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438","adb8f8fd":"## \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445"}}