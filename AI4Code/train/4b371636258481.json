{"cell_type":{"c6d409a9":"code","d0f3af5a":"code","231d05ed":"code","53f1b8c9":"code","c80d77c7":"code","ba1031a0":"code","0d9a017b":"code","b71777f1":"code","6b619d30":"code","b291870d":"code","c03dd50e":"code","51449e96":"code","d4b6e91c":"code","ae7cbb83":"code","ee6e6d16":"code","03c0f054":"code","4629a388":"code","32ae2b5c":"markdown","352d8138":"markdown","86866a23":"markdown","eacec9a3":"markdown","a44a9d13":"markdown","bb4d223d":"markdown","a0798b56":"markdown","2a437046":"markdown","1d829d87":"markdown"},"source":{"c6d409a9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\ntrain = pd.read_csv(\"..\/input\/train.csv\")\ntest=pd.read_csv(\"..\/input\/test.csv\")","d0f3af5a":"train.head()\n","231d05ed":"test.head()","53f1b8c9":"\n# taking 2nd Row of Dataframe\nimg=train.iloc[1][1:785].values\nlabel=train.iloc[1][0]\n# we are Excluding Coloum 0 because it indicates labels we are just taking coloums from 1 to 785\nprint(\"Shape of Image \",img.shape)\n# Images are aleays in 3 Diminsioon\n# 1st diminsion represents width of the image\n# 2nd diminsion represents height of the image\n# 3rd represents is it a colored image or Grayscale Image\n# IF the value of 3rd diminsion is 1 it means it is Gray Scale \n# If the value if 3rd diminsion is 3 it means it is Colored because it indicates 3 values\n# i.e (red,blue,green) Colours are always the combination of Red blue green. \n\n# For example Image diminsion is (32,32,3) etc like that means 32 height 32 width and 3 \n#means colorful Image\n\n# So now to Visualize Image we have to convert our image to 3 diminsions. basic Diminsion of \n# Mnist image is 28*28*1=784 means 28 height 28 width and 1 means grayScale Images\n\nimg=img.reshape(28,28)\n# if we didnt write 1 thats not a problem in grayscale image but if you are working on color images\n# must write 3\nprint(\"28*28 is 784\")\nprint(\"New Diminsion of Image\" ,img.shape)\n\n","c80d77c7":"import matplotlib.pyplot as plt\n\nfig = plt.figure()\nplt.imshow(img,cmap='gray')\nfig.suptitle(\"Label of this Image is: \"+ str(label))\n\nplt.show()","ba1031a0":"for i in range(0,10) :   \n    img=train.iloc[i][1:785].values\n    label=train.iloc[i][0]\n    img=img.reshape(28,28)\n    fig = plt.figure()\n    plt.imshow(img,cmap='gray')\n    fig.suptitle(\"Label of this Image is: \"+ str(label))\n    \n    plt.show()","0d9a017b":"# import the necessary packages\nfrom keras.models import Sequential\n\nfrom keras.layers.convolutional import Convolution2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers import Dropout\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dense\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import datasets\nfrom keras.optimizers import adam\nfrom keras.utils import np_utils\nimport numpy as np\nimport cv2\n \n","b71777f1":"#copying all the values to X except coloum 1 because those are our labels which we will\n# copy in y\nX = (train.iloc[:,1:].values)\n#We separate the target variable\ny = train.iloc[:,0].values\n#We get the test data\ntest = test","6b619d30":"#We reshape the train set\nX = X.reshape((X.shape[0], 28, 28))\nX = X[:, :, :, np.newaxis]\ny=np_utils.to_categorical(y, 10)\n#We reshape the test set\ntest=np.asarray(test)\ntest = test.reshape((test.shape[0], 28, 28))\n#test = test[:, :, :, np.newaxis]\n\nprint(\"Shape of X\",X.shape)\nprint (\"Shape of y\",y.shape)\nprint(\"Shape of Test\",test.shape)","b291870d":"#We split the train set and test set so that we can evaluate our model\nX_train, X_test, y_train, y_test=train_test_split(\n    X , y, test_size=0.33)\nX_train =X_train\/ 255\nX_test = X_test\/255","c03dd50e":"# initialize the model\nheight=28\nwidth=28\ndepth=1\nclasses=10\n\n\nmodel = Sequential()\n# first set of CONV => RELU => POOL\nmodel.add(Convolution2D(20, 2, 2, border_mode=\"same\",input_shape=(height, width,depth)))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n# second set of CONV => RELU => POOL\nmodel.add(Convolution2D(50, 2, 2, border_mode=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n# Third set of CONV => RELU => POOL\nmodel.add(Convolution2D(100, 2, 2, border_mode=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.4))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n# set of FC => RELU layers\nmodel.add(Flatten())\nmodel.add(Dense(500))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(250))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(100))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dense(50))\nmodel.add(Dropout(0.3))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dense(32))\nmodel.add(Dropout(0.2))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dense(classes))\nmodel.add(Activation(\"softmax\"))\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",\nmetrics=[\"accuracy\"])\n        \n        \n\n\n","51449e96":"\n\n \n# show the accuracy on the testing set\nhistory=model.fit(X_train,y_train, epochs = 70 ,batch_size = 128,validation_data=(X_test,y_test))\n\n\n","d4b6e91c":"\n\n\n# Plot training & validation accuracy values\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\n\n\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\n\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","ae7cbb83":"from sklearn.metrics import confusion_matrix\nimport itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\nY_pred = model.predict(X_test)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(y_test,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10)) ","ee6e6d16":"X=X\/225\nmodel.fit(X,y, epochs = 100 ,batch_size = 128,verbose=0)","03c0f054":"# Display some error results \n\n# Errors are difference between predicted labels and true labels\nerrors = (Y_pred_classes - Y_true != 0)\n\nY_pred_classes_errors = Y_pred_classes[errors]\nY_pred_errors = Y_pred[errors]\nY_true_errors = Y_true[errors]\nX_val_errors = X_test[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 3\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n\n# Probabilities of the wrong predicted numbers\nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 6 errors \nmost_important_errors = sorted_dela_errors[-6:]\n\n# Show the top 6 errors\ndisplay_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)","4629a388":"# predict results\ntest=test.reshape(-1,28,28,1)\ntest=test\/225\nresults = model.predict(test)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"submission.csv\",index=False)","32ae2b5c":"**Train CSV**","352d8138":"**model is performing good its prediction time**\nFirst we train our all train data on model and than predict the test data because at the time of training we split some data in test and train to see ourselves performance on data now we train our model on that data to","86866a23":"**Test CSV**","eacec9a3":"# Perdiction Time","a44a9d13":"# Visuzalizing Image","bb4d223d":"# Deep Learning","a0798b56":"To explore Multiple You can do","2a437046":"**Source of Code:** This class is presented and explained [here](https:\/\/www.pyimagesearch.com\/2016\/08\/01\/lenet-convolutional-neural-network-in-python\/):","1d829d87":"# Introduction:\nMnist is the hello world of deep learning. It is the basic problem we have to solve when we are starting our work on deep learning. So lets solve this.\n\n**Introduction of Dataset:**\n\nDataset includes two csv files.\n\n1: Train File\n2: Test File\n\n**Train File:**\nTrain file have total 785 coloums. 2 to 785 coloums  indicades a pixel value e.g this is the dataset of gray scale images the value of pixel will be 0 to 255. 0 is black and other than 0 is brighter color than black. We will later explore these Images.  and the first coloums have 10 label values (0,1,2,3,4,5,6,7,8,9) Indicates this image have 1 or 2 or 3 or so on written on it. \n\n**Test File:**\nTest file includes only 784 coloums which are just pixel values and we have to predict their numbers.\n\n# **Algorithm Approach:**\n\nI am Going to work on CNN Model Smaller Artitecture of LEnet.  "}}