{"cell_type":{"0531d340":"code","d10979ab":"code","4a871cf6":"code","5b16b3cd":"code","e3379d17":"code","b60f11f5":"code","ddcb7d0f":"code","afa65869":"code","7ec46f35":"code","1be42258":"code","34314699":"code","6f4ae97a":"code","51419f6b":"code","6083604d":"code","601dfc6f":"code","cc9a6910":"code","4b5be184":"code","93c149cb":"code","86e782ff":"code","919ed7b7":"code","95c2f23e":"code","bd346631":"code","56f7b9be":"markdown","d82f8d85":"markdown","21c0af87":"markdown","0b78f75c":"markdown","7edd82cb":"markdown","64c28b1a":"markdown","b6f93e3f":"markdown"},"source":{"0531d340":"from os import listdir\nfrom os.path import isfile, join\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport pandas as pd\nimport numpy as np\nimport pylab as pl\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier,\n                              AdaBoostClassifier)\nfrom sklearn.svm import SVC\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n# Any results you write to the current directory are saved as output.\nimport os\nsounds = os.listdir(\"\/kaggle\/input\/audio-cats-and-dogs\/cats_dogs\/\")\nprint(os.listdir(\"\/kaggle\/input\/audio-cats-and-dogs\/\"))\nimport warnings\nwarnings.filterwarnings(\"ignore\")","d10979ab":"import glob\nimport ntpath\n# List the wav files\nROOT_DIR_TEST = glob.glob('\/kaggle\/input\/audio-cats-and-dogs\/cats_dogs\/test')[0]\nROOT_DIR_TRAIN = glob.glob('\/kaggle\/input\/audio-cats-and-dogs\/cats_dogs\/train')[0]\n\n\nX_path = glob.glob(ROOT_DIR_TEST + \"\/test\/*\") # test = dogs in this case ! (wrong name of directory was given when it was created)\nX_path = X_path + glob.glob(ROOT_DIR_TEST + \"\/cats\/*\")\nX_path = X_path + glob.glob(ROOT_DIR_TRAIN + \"\/dog\/*\")\nX_path = X_path + glob.glob(ROOT_DIR_TRAIN + \"\/cat\/*\")\nprint (len(X_path))","4a871cf6":"y = np.empty((0, 1, ))\nfor f in X_path:\n    if 'cat' in ntpath.basename(f):\n        resp = np.array([0])\n        resp = resp.reshape(1, 1, )\n        y = np.vstack((y, resp))\n    elif 'dog' in ntpath.basename(f):\n        resp = np.array([1])\n        resp = resp.reshape(1, 1, )\n        y = np.vstack((y, resp))\nprint (f)","5b16b3cd":"\n# Split train and test\nX_train, X_test, y_train, y_test = train_test_split(X_path, y, test_size=0.33)\n\nprint(\"in X, there is {} cats and {} dogs\".format(len(y) - sum(y), sum(y)))\nprint(\"in X_train, there is {} cats and {} dogs\".format(len(y_train) - sum(y_train), sum(y_train)))\nprint(\"in X_test, there is {} cats and {} dogs\".format(len(y_test) - sum(y_test), sum(y_test)))\nprint(\"len(y_train)\",len(y_train))\nprint(\"len(y_test)\",len(y_test))\nprint(y_test.shape)\nprint(y_train.shape)","e3379d17":"from scipy.io import wavfile\nimport IPython.display as ipd \n\n#look and some data and hear a sound\n\nw = wavfile.read('\/kaggle\/input\/audio-cats-and-dogs\/cats_dogs\/'+sounds[0])\nplt.plot(w[1])\nplt.show()\nprint(sounds[0])\nipd.Audio('\/kaggle\/input\/audio-cats-and-dogs\/cats_dogs\/'+sounds[0])\n\nprint(w)","b60f11f5":"def read_wav_files(wav_files):\n    '''Returns a list of audio waves\n    Params:\n        wav_files: List of .wav paths\n    \n    Returns:\n        List of audio signals\n    '''\n    if not isinstance(wav_files, list):\n        wav_files = [wav_files]\n    return [sci_wav.read(f)[1] for f in wav_files]","ddcb7d0f":"def librosa_read_wav_files(wav_files):\n    if not isinstance(wav_files, list):\n        wav_files = [wav_files]\n    return [librosa.load(f)[0] for f in wav_files]","afa65869":"import librosa\nwav_rate = librosa.load(X_train[0])[1]\nX_train = librosa_read_wav_files(X_train)\nX_test  = librosa_read_wav_files(X_test)","7ec46f35":"import matplotlib.pyplot as plt\n\nfig, axs = plt.subplots(2, 2, figsize=(16,7))\naxs[0][0].plot(X_train[0])\naxs[0][1].plot(X_train[1])\naxs[1][0].plot(X_train[2])\naxs[1][1].plot(X_train[3])\nplt.show()","1be42258":"import IPython.display as ipd\nipd.Audio('\/kaggle\/input\/audio-cats-and-dogs\/cats_dogs\/dog_barking_27.wav')\n#ipd.Audio(X_train[7],  rate=wav_rate)","34314699":"# function to extract all the features needed for the classification\ndef extract_features(audio_samples, sample_rate):\n    extracted_features = np.empty((0, 41, ))\n    if not isinstance(audio_samples, list):\n        audio_samples = [audio_samples]\n        \n    for sample in audio_samples:\n        # calculate the zero-crossing feature\n        zero_cross_feat = librosa.feature.zero_crossing_rate(sample).mean()\n        \n        # calculate the mfccs features\n        mfccs = librosa.feature.mfcc(y=sample, sr=sample_rate, n_mfcc=40)\n        mfccsscaled = np.mean(mfccs.T,axis=0)\n\n        # add zero crossing feature to the feature list\n        mfccsscaled = np.append(mfccsscaled, zero_cross_feat)\n        mfccsscaled = mfccsscaled.reshape(1, 41, )\n        \n        extracted_features = np.vstack((extracted_features, mfccsscaled))\n\n    # return the extracted features\n    return extracted_features","6f4ae97a":"features = ((extract_features(X_train[0], wav_rate)))\n\nprint (len(features))\nprint (features.shape)\nplt.plot(features[0])","51419f6b":"X_train_features = extract_features(X_train, wav_rate)\nX_test_features  = extract_features(X_test, wav_rate)\nprint(\"Image array shape: \", X_train_features.shape)\nprint(\"Image array shape: \", X_test_features.shape)\nprint(\"Label array shape: \", y_train.shape)\nprint(\"Label array shape: \", y_test.shape)","6083604d":"from keras import layers\nfrom keras import models\nfrom keras import optimizers\nfrom keras import losses\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping","601dfc6f":"#Convert the labels to match what our model will expect\nfrom keras.utils import to_categorical\ntrain_labels = to_categorical(y_train)\ntest_labels = to_categorical(y_test)","cc9a6910":"model = models.Sequential()\n\nmodel.add(layers.Dense(100, activation = 'relu', input_shape = (41, )))\nmodel.add(layers.Dense(50, activation = 'relu'))\nmodel.add(layers.Dense(2, activation = 'softmax'))\n\nmodel.summary()","4b5be184":"#Choose the parameters to train the neural network\nbest_model_weights = '.\/base.model'\ncheckpoint = ModelCheckpoint(\n    best_model_weights,\n    monitor='val_acc',\n    verbose=1,\n    save_best_only=True,\n    mode='min',\n    save_weights_only=False,\n    period=1\n)\n\ncallbacks = [checkpoint]\n\nmodel.compile(optimizer='adam',\n              loss=losses.categorical_crossentropy,\n              metrics=['accuracy'])","93c149cb":"history = model.fit(\n    X_train_features,\n    train_labels,\n    validation_data=(X_test_features,test_labels),\n    epochs = 200, \n    verbose = 1,\n    callbacks=callbacks,\n)","86e782ff":"#Save the model\nmodel.save_weights('model_wieghts.h5')\nmodel.save('model_keras.h5')","919ed7b7":"# list all data in history\nprint(history.history.keys())\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nepochs = range(1, len(acc)+1)\n\nplt.plot(epochs, acc, 'b', label = \"training accuracy\")\nplt.plot(epochs, val_acc, 'r', label = \"validation accuracy\")\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.show()","95c2f23e":"nr_to_predict = 50\npred = model.predict(X_test_features[nr_to_predict].reshape(1, 41,))\n\nprint(\"Cat: {} Dog: {}\".format(pred[0][0], pred[0][1]))\n\nif (y_test[nr_to_predict] == 0):\n    print (\"The label says that it is a Cat!\")\nelse:\n    print (\"The label says that it is a Dog!\")\n    \nplt.plot(X_test_features[nr_to_predict])\nipd.Audio(X_test[nr_to_predict],  rate=wav_rate)","bd346631":"nr_to_predict = 30\npred = model.predict(X_test_features[nr_to_predict].reshape(1, 41,))\n\nprint(\"Cat: {} Dog: {}\".format(pred[0][0], pred[0][1]))\n\nif (y_test[nr_to_predict] == 0):\n    print (\"The label says that it is a Cat!\")\nelse:\n    print (\"The label says that it is a Dog!\")\n    \nplt.plot(X_test_features[nr_to_predict])\nipd.Audio(X_test[nr_to_predict],  rate=wav_rate)","56f7b9be":"**extract_features**","d82f8d85":"***Import the data and explore it***","21c0af87":"**Get the features for all input data**","0b78f75c":"**Create the model\u00b6**","7edd82cb":"**Validate the model**","64c28b1a":"**Read the audio files**","b6f93e3f":"**Train the model**"}}