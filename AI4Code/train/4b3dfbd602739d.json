{"cell_type":{"2325a222":"code","e814a7d4":"code","2fa59567":"code","c61b4e2d":"code","85a2e6cd":"code","eed0aba7":"code","5cefd5f6":"code","6cd49e63":"code","52c77aae":"code","b0bf20e7":"code","66030643":"code","98d5ae3e":"code","e27ec2fb":"code","05d9be13":"code","b9d6e4d3":"code","d6fb9b3e":"code","ecd7e05b":"markdown","36e71ab6":"markdown","4b4700d3":"markdown","784f35be":"markdown","8ca2d605":"markdown","c527b527":"markdown","24eb35f2":"markdown","dc0a46da":"markdown","64ec12fa":"markdown","ddee2ff2":"markdown","c2c27d4b":"markdown","d27936ae":"markdown","7ded707e":"markdown","a842f5b8":"markdown"},"source":{"2325a222":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras import applications\nfrom sklearn.metrics import pairwise_distances\nimport requests\nfrom PIL import Image\nimport pickle\nfrom datetime import datetime\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\nimport plotly.figure_factory as ff\nimport plotly.graph_objects as go\nimport plotly.express as px\n#import streamlit as st\n#use the below library while displaying the images in jupyter notebook\nfrom IPython.display import display, Image\n\nfashion_df = pd.read_csv(\"\/kaggle\/input\/fashion-images\/data\/fashion.csv\")\nfashion_df","e814a7d4":"print(\"Total number of products : \", fashion_df.shape[0])\nprint(\"Total number of unique subcategories : \", fashion_df[\"SubCategory\"].nunique())\nprint(\"Total number of unique gender types : \", fashion_df[\"Gender\"].nunique())","2fa59567":"fashion_df[\"Gender\"].value_counts()","c61b4e2d":"plot = sns.countplot(fashion_df[\"Gender\"])\nplt.title(\"Distribution of articles gender-wise\")\nplt.xlabel(\"Gender type\")\nplt.ylabel(\"Number of products\")\nplot.set_xticklabels(plot.get_xticklabels())\nplt.show()","85a2e6cd":"apparel_boys = fashion_df[fashion_df[\"Gender\"]==\"Boys\"]\napparel_girls = fashion_df[fashion_df[\"Gender\"]==\"Girls\"]\nfootwear_men = fashion_df[fashion_df[\"Gender\"]==\"Men\"]\nfootwear_women = fashion_df[fashion_df[\"Gender\"]==\"Women\"]","eed0aba7":"img_width, img_height = 224, 224\n\n#top_model_weights_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\ntrain_data_dir = \"\/kaggle\/input\/fashion-images\/data\/Footwear\/Men\/Images\/\"\n\nnb_train_samples = 811\nepochs = 50\nbatch_size = 1\n\ndef extract_features():\n    Itemcodes = []\n    datagen = ImageDataGenerator(rescale=1. \/ 255)\n    model = applications.ResNet50(include_top=False, weights='imagenet')\n    generator = datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_width, img_height),\n        batch_size=batch_size,\n        class_mode=None,\n        shuffle=False)\n    for i in generator.filenames:\n        Itemcodes.append(i[(i.find(\"\/\")+1):i.find(\".\")])\n    extracted_features = model.predict_generator(generator, nb_train_samples \/\/ batch_size)\n    extracted_features = extracted_features.reshape((811, 100352))\n    \n    np.save(open('.\/Men_ResNet_features.npy', 'wb'), extracted_features)\n    np.save(open('.\/Men_ResNet_feature_product_ids.npy', 'wb'), np.array(Itemcodes))\n    \na = datetime.now()\nextract_features()\nprint(\"Time taken in feature extraction\", datetime.now()-a)","5cefd5f6":"extracted_features = np.load('\/kaggle\/working\/Men_ResNet_features.npy')\nProductids = np.load('\/kaggle\/working\/Men_ResNet_feature_product_ids.npy')\nmen = footwear_men.copy()\n#men = pd.read_csv('.\/footwear_men.csv')\ndf_Productids = list(men['ProductId'])\nProductids = list(Productids)","6cd49e63":"def get_similar_products_cnn(product_id, num_results):\n    doc_id = Productids.index(product_id)\n    pairwise_dist = pairwise_distances(extracted_features, extracted_features[doc_id].reshape(1,-1))\n    indices = np.argsort(pairwise_dist.flatten())[0:num_results]\n    pdists  = np.sort(pairwise_dist.flatten())[0:num_results]\n    print(\"=\"*20, \"input product image\", \"=\"*20)\n    ip_row = men[['ImageURL','ProductTitle']].loc[men['ProductId']==int(Productids[indices[0]])]\n    #print(ip_row.head())\n    for indx, row in ip_row.iterrows():\n        display(Image(url=row['ImageURL'], width = 224, height = 224,embed=True))\n        print('Product Title: ', row['ProductTitle'])\n    print(\"\\n\",\"=\"*20, \"Recommended products\", \"=\"*20)\n    for i in range(1,len(indices)):\n        rows = men[['ImageURL','ProductTitle']].loc[men['ProductId']==int(Productids[indices[i]])]\n        for indx, row in rows.iterrows():\n            display(Image(url=row['ImageURL'], width = 224, height = 224,embed=True))\n            print('Product Title: ', row['ProductTitle'])\n            print('Euclidean Distance from input image:', pdists[i])\n\nget_similar_products_cnn('13683', 5)","52c77aae":"img_width, img_height = 224, 224\n\n\n#top_model_weights_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\ntrain_data_dir = \"\/kaggle\/input\/fashion-images\/data\/Footwear\/Women\/Images\/\"\n\nnb_train_samples = 769\nepochs = 50\nbatch_size = 1\n\ndef extract_features():\n    Itemcodes = []\n    datagen = ImageDataGenerator(rescale=1. \/ 255)\n    model = applications.ResNet50(include_top=False, weights='imagenet')\n    generator = datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_width, img_height),\n        batch_size=batch_size,\n        class_mode=None,\n        shuffle=False)\n    for i in generator.filenames:\n        Itemcodes.append(i[(i.find(\"\/\")+1):i.find(\".\")])\n    extracted_features = model.predict_generator(generator, nb_train_samples \/\/ batch_size)\n    extracted_features = extracted_features.reshape((769, 100352))\n    \n    np.save(open('.\/Women_ResNet_features.npy', 'wb'), extracted_features)\n    np.save(open('.\/Women_ResNet_feature_product_ids.npy', 'wb'), np.array(Itemcodes))\n    \na = datetime.now()\nextract_features()\nprint(\"Time taken in feature extraction\", datetime.now()-a)","b0bf20e7":"img_width, img_height = 224, 224\n\n\n#top_model_weights_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\ntrain_data_dir = \"\/kaggle\/input\/fashion-images\/data\/Apparel\/Boys\/Images\"\n\nnb_train_samples = 759\nepochs = 50\nbatch_size = 1\n\ndef extract_features():\n    Itemcodes = []\n    datagen = ImageDataGenerator(rescale=1. \/ 255)\n    model = applications.ResNet50(include_top=False, weights='imagenet')\n    generator = datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_width, img_height),\n        batch_size=batch_size,\n        class_mode=None,\n        shuffle=False)\n    for i in generator.filenames:\n        Itemcodes.append(i[(i.find(\"\/\")+1):i.find(\".\")])\n    extracted_features = model.predict_generator(generator, nb_train_samples \/\/ batch_size)\n    extracted_features = extracted_features.reshape((759, 100352))\n    \n    np.save(open('.\/Boys_ResNet_features.npy', 'wb'), extracted_features)\n    np.save(open('.\/Boys_ResNet_feature_product_ids.npy', 'wb'), np.array(Itemcodes))\n    \na = datetime.now()\nextract_features()\nprint(\"Time taken in feature extraction\", datetime.now()-a)","66030643":"img_width, img_height = 224, 224\n\n\n#top_model_weights_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\ntrain_data_dir = \"\/kaggle\/input\/fashion-images\/data\/Apparel\/Girls\/Images\"\n\nnb_train_samples = 567\nepochs = 50\nbatch_size = 1\n\ndef extract_features():\n    Itemcodes = []\n    datagen = ImageDataGenerator(rescale=1. \/ 255)\n    model = applications.ResNet50(include_top=False, weights='imagenet')\n    generator = datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_width, img_height),\n        batch_size=batch_size,\n        class_mode=None,\n        shuffle=False)\n    for i in generator.filenames:\n        Itemcodes.append(i[(i.find(\"\/\")+1):i.find(\".\")])\n    extracted_features = model.predict_generator(generator, nb_train_samples \/\/ batch_size)\n    extracted_features = extracted_features.reshape((567, 100352))\n    \n    np.save(open('.\/Girls_ResNet_features.npy', 'wb'), extracted_features)\n    np.save(open('.\/Girls_ResNet_feature_product_ids.npy', 'wb'), np.array(Itemcodes))\n    \na = datetime.now()\nextract_features()\nprint(\"Time taken in feature extraction\", datetime.now()-a)","98d5ae3e":"boys_extracted_features = np.load('\/kaggle\/working\/Boys_ResNet_features.npy')\nboys_Productids = np.load('\/kaggle\/working\/Boys_ResNet_feature_product_ids.npy')\ngirls_extracted_features = np.load('\/kaggle\/working\/Girls_ResNet_features.npy')\ngirls_Productids = np.load('\/kaggle\/working\/Girls_ResNet_feature_product_ids.npy')\nmen_extracted_features = np.load('\/kaggle\/working\/Men_ResNet_features.npy')\nmen_Productids = np.load('\/kaggle\/working\/Men_ResNet_feature_product_ids.npy')\nwomen_extracted_features = np.load('\/kaggle\/working\/Women_ResNet_features.npy')\nwomen_Productids = np.load('\/kaggle\/working\/Women_ResNet_feature_product_ids.npy')\nfashion_df[\"ProductId\"] = fashion_df[\"ProductId\"].astype(str)","e27ec2fb":"def get_similar_products_cnn(product_id, num_results):\n    if(fashion_df[fashion_df['ProductId']==product_id]['Gender'].values[0]==\"Boys\"):\n        extracted_features = boys_extracted_features\n        Productids = boys_Productids\n    elif(fashion_df[fashion_df['ProductId']==product_id]['Gender'].values[0]==\"Girls\"):\n        extracted_features = girls_extracted_features\n        Productids = girls_Productids\n    elif(fashion_df[fashion_df['ProductId']==product_id]['Gender'].values[0]==\"Men\"):\n        extracted_features = men_extracted_features\n        Productids = men_Productids\n    elif(fashion_df[fashion_df['ProductId']==product_id]['Gender'].values[0]==\"Women\"):\n        extracted_features = women_extracted_features\n        Productids = women_Productids\n    Productids = list(Productids)\n    doc_id = Productids.index(product_id)\n    pairwise_dist = pairwise_distances(extracted_features, extracted_features[doc_id].reshape(1,-1))\n    indices = np.argsort(pairwise_dist.flatten())[0:num_results]\n    pdists  = np.sort(pairwise_dist.flatten())[0:num_results]\n    print(\"=\"*20, \"input product details\", \"=\"*20)\n    ip_row = fashion_df[['ImageURL','ProductTitle']].loc[fashion_df['ProductId']==Productids[indices[0]]]\n    for indx, row in ip_row.iterrows():\n        display(Image(url=row['ImageURL'], width = 224, height = 224,embed=True))\n        print('Product Title: ', row['ProductTitle'])\n    print(\"\\n\",\"=\"*20, \"Recommended products\", \"=\"*20)\n    for i in range(1,len(indices)):\n        rows = fashion_df[['ImageURL','ProductTitle']].loc[fashion_df['ProductId']==Productids[indices[i]]]\n        for indx, row in rows.iterrows():\n            display(Image(url=row['ImageURL'], width = 224, height = 224,embed=True))\n            print('Product Title: ', row['ProductTitle'])\n            print('Euclidean Distance from input image:', pdists[i])","05d9be13":"get_similar_products_cnn('21030', 5)","b9d6e4d3":"get_similar_products_cnn('18181', 5)","d6fb9b3e":"get_similar_products_cnn('37633', 5)","ecd7e05b":"**NOTE** - The above feature extraction process can be repeated for other genders (Women, Boys and Girls) as well. So let's extract for each one by one.\n\n**For Gender - Women**","36e71ab6":"### 4. Computing the Euclidean distance and recommending similar products\n\n#### 4.1 Loading the extracted features","4b4700d3":"**Tip** - The solution can be deployed using ***streamlit***.\n\nThe complete deployment code can be downloaded from [here](https:\/\/drive.google.com\/file\/d\/123XGxKvRY7sk2pnTmVOyLp9FH-iFL5oN\/view).","784f35be":"### 2. Data Preparation","8ca2d605":"## Notebook - Table of Contents\n\n\n1. [**Basic Data Analysis**](#1.-Basic-Data-Analysis)  \n    1.1 [**Importing the necessary libraries & loading the data**](#1.1-Importing-the-necessary-libraries-&-loading-the-data)    \n    1.2 [**Basic statistics - Number of products, subcategories & gender**](#1.2-Basic-statistics---Number-of-products,-subcategories-&-gender)      \n    1.3 [**Frequency of each gender**](#1.3-Frequency-of-each-gender)      \n    1.4 [**Distribution of products gender-wise**](#1.4-Distribution-of-products-gender-wise)     \n2. [**Data Preparation**](#2.-Data-Preparation) \n3. [**Feature extraction using ResNet**](#3.-Feature-extraction-using-ResNet)  \n4. [**Computing the Euclidean distance and recommending similar products**](#4.-Computing-the-Euclidean-distance-and-recommending-similar-products)                         \n    4.1 [**Loading the extracted features**](#4.1-Loading-the-extracted-features)  \n    4.2 [**Distance computation and Recommendation**](#4.2-Distance-computation-and-Recommendation)  \n5. [**Deploying the solution**](#5.-Deploying-the-solution)  ","c527b527":"### 3. Feature extraction using ResNet\n\n**For Gender - Men**","24eb35f2":"#### 1.3 Frequency of each gender","dc0a46da":"**For Gender - Girls**","64ec12fa":"**For Gender - Boys**","ddee2ff2":"### 5. Deploying the solution","c2c27d4b":"#### 1.2 Basic statistics - Number of products, subcategories & gender","d27936ae":"#### 4.2 Distance computation and Recommendation","7ded707e":"#### 1.4 Distribution of products gender-wise","a842f5b8":"### Basic Data Analysis\n\n#### 1.1 Importing the necessary libraries & loading the data"}}