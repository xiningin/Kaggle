{"cell_type":{"9b2c6875":"code","f6da6950":"code","529b535a":"code","7b9ded1f":"code","d48aee09":"code","e8482ae4":"code","436e84e2":"code","3b281860":"code","f625a62c":"code","8b07b9ad":"code","bad2c529":"code","cc8b0f87":"code","7d4043b0":"code","9a6634a4":"code","95121bd8":"code","ac0bd3d5":"code","b2c35b2a":"code","ea19fb7f":"code","69d1dbf3":"code","9e36bb5c":"code","be9e71d1":"code","47a5ffda":"code","763764b5":"code","eb7d2549":"code","8ac13ec7":"code","1606604f":"code","89ba59b3":"code","973b170d":"code","00f312ce":"code","1dde12c1":"code","f5b8c079":"code","6b874080":"code","91f784e7":"code","e3befdbf":"code","cf3591b8":"code","81238943":"code","270d45c5":"code","1697cbe3":"code","01a295ae":"code","7dceeb10":"code","62cf9077":"code","e4ed69ea":"code","51e705b9":"code","962a6a38":"code","91fa2fc6":"code","5f01c7a8":"code","2618abd9":"code","8171877b":"code","00314ab0":"code","c224cf0b":"code","9457fbef":"markdown","761fc470":"markdown","662920fe":"markdown","bbd779a3":"markdown","0d1859fc":"markdown","01c8e454":"markdown","d25bf4cd":"markdown","f59b5603":"markdown","a5eba128":"markdown","30c2913f":"markdown","40b949ab":"markdown","532b08c8":"markdown","76d41caf":"markdown","0d99602f":"markdown","1abf3576":"markdown","7271aabe":"markdown","3daa3350":"markdown","218da859":"markdown","a6be8dfd":"markdown","b011e071":"markdown","890d7cf9":"markdown","ce1dc7d5":"markdown","1a133a0a":"markdown","980f18fb":"markdown","8de86446":"markdown"},"source":{"9b2c6875":"# Importing the required Libraries.\nimport pandas as pd\nimport numpy as np\nimport sys\nimport os\nimport time\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')","f6da6950":"#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\n#Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#Configure Visualization Defaults\n#%matplotlib inline = show plots in Jupyter Notebook browser\n%matplotlib inline\nsns.set_style('white')\n\nfrom sklearn.model_selection import cross_val_score","529b535a":"df = pd.read_csv('..\/input\/indianliver\/indian_liver_patient.csv')\ndf.describe()","7b9ded1f":"print(df.columns)\nprint('*'*50)\nfor i in df.columns :\n    print(i)\n    print(df[i].describe())\n    print('*'*50)","d48aee09":"df.info()","e8482ae4":"df[df['Albumin_and_Globulin_Ratio'].isnull()]","436e84e2":"# Re-naming the columns\ndf =  df.rename(columns={'Dataset':'Liver_disease','Alamine_Aminotransferase':'Alanine_Aminotransferase'}, inplace=False)","3b281860":"# Renaming Done\ndf.describe()","f625a62c":"# Dropping Null Values\ndf = df.dropna()\n# Changing the values in \"Liver_Disease\" column \ndf['Liver_disease'] = df['Liver_disease'] - 1 \n# Converting Gender column into categorical data \nLabelEncoder = LabelEncoder()\ndf['Is_male'] = LabelEncoder.fit_transform(df['Gender'])\ndf = df.drop(columns='Gender')","8b07b9ad":"X = df[['Age', 'Total_Bilirubin', \n        'Direct_Bilirubin',\n        'Alkaline_Phosphotase',\n        'Alanine_Aminotransferase', 'Aspartate_Aminotransferase',\n       'Total_Protiens', 'Albumin', 'Albumin_and_Globulin_Ratio', 'Is_male']]\ny = df['Liver_disease']","bad2c529":"# Validate each class to understand if the dataset is imbalanced.\n\nprint ('Total Unhealthy Livers :  {} and its percentage is {} %'.format(df.Liver_disease.value_counts()[0], round(df.Liver_disease.value_counts()[0]\/df.Liver_disease.value_counts().sum()*100,2)) )\nprint ('Total Healthy Livers :  {} and its percentage is {} %'.format(df.Liver_disease.value_counts()[1], round(df.Liver_disease.value_counts()[1]\/df.Liver_disease.value_counts().sum()*100,2)) )","cc8b0f87":"df.skew(axis = 0, skipna = True) ","7d4043b0":"# Plotting the box plots \nplt.figure(figsize=[16,12])\n\nplt.subplot(231)\nplt.boxplot(x = X['Age'], showmeans = True, meanline = True)\nplt.title('Age Boxplot')\nplt.ylabel('Age (years)')\n\nplt.subplot(232)\nplt.boxplot(X['Total_Bilirubin'], showmeans = True, meanline = True)\nplt.title('Total Bilirubin Boxplot')\nplt.ylabel('Total Bilirubin (mg\/dL)')\n\nplt.subplot(233)\nplt.boxplot(X['Direct_Bilirubin'], showmeans = True, meanline = True)\nplt.title('Direct Bilirubin Boxplot')\nplt.ylabel('Direct Bilirubin (mg\/dL)')\n\nplt.subplot(234)\nplt.hist(x = [X[y==1]['Is_male'], X[y ==0]['Is_male']], \n         stacked=True, color = ['g','r'],label = ['Healthy','Patient'])\nplt.title('Gender Histogram by patients')\nplt.xlabel('Gender [0 - female : 1 - male]')\nplt.ylabel('# of people')\nplt.legend()\n\nplt.subplot(235)\nplt.boxplot(x = X['Alkaline_Phosphotase'], showmeans = True, meanline = True)\nplt.title('Alkaline Phosphotase')\nplt.ylabel('Alkaline Phosphotase (International Units \/Litre)')\n\nplt.subplot(236)\nplt.boxplot(X['Alanine_Aminotransferase'], showmeans = True, meanline = True)\nplt.title('Alanine Aminotransferase Boxplot')\nplt.ylabel('Alanine Aminotransferase (units\/L)')","9a6634a4":"plt.figure(figsize=[16,12])\nplt.subplot(231)\nplt.boxplot(X['Aspartate_Aminotransferase'], showmeans = True, meanline = True)\nplt.title('Aspartate Aminotransferase Boxplot')\nplt.ylabel('Aspartate_Aminotransferase (units\/L)')\n\n\nplt.subplot(232)\nplt.boxplot(X['Total_Protiens'], showmeans = True, meanline = True)\nplt.title('Total Protiens Boxplot')\nplt.ylabel('Total Protiens (g\/dL)')\n\nplt.subplot(233)\nplt.boxplot(X['Albumin'], showmeans = True, meanline = True)\nplt.title('Albumin Boxplot')\nplt.ylabel('Albumin (g\/dL)')","95121bd8":"fig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(y = 'Alanine_Aminotransferase', x = 'Liver_disease', data=df, ax = saxis[0,0])\nsns.pointplot(y = 'Total_Bilirubin', x = 'Liver_disease', data=df, ax = saxis[0,1])\nsns.pointplot(y = 'Direct_Bilirubin', x = 'Liver_disease', data=df, ax = saxis[0,2])\n\n\nsns.barplot(y = 'Alkaline_Phosphotase', x = 'Liver_disease', data=df, ax = saxis[1,0])\nsns.barplot(y = 'Aspartate_Aminotransferase', x = 'Liver_disease', data=df, ax = saxis[1,1])\nsns.boxplot(y = 'Total_Protiens', x = 'Liver_disease', data=df, ax = saxis[1,2])","ac0bd3d5":"def correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorrelation_heatmap(df)","b2c35b2a":"from sklearn import preprocessing\nX_scaler = preprocessing.normalize(X)","ea19fb7f":"# Splitting the data \nX_train, X_test, y_train, y_test = model_selection.train_test_split(X_scaler, y, random_state = 0)\n\nprint(\"Train Shape: {}\".format(X_train.shape))\nprint(\"Test Shape: {}\".format(X_test.shape))\n","69d1dbf3":"# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(X_train,y_train)\ny_pred = lr.predict(X_test)","9e36bb5c":"# Use score method to get accuracy of model\nscore = lr.score(X_test, y_test)\nprint(\"Score of the model is - \",score)\nprint(\"Report card of this model - \")\nprint(metrics.classification_report(y_test, y_pred, digits=3))\nprint(\"Accuracy score - \", metrics.accuracy_score(y_test,y_pred))","be9e71d1":"from sklearn.metrics import roc_auc_score\ntest_roc_auc = roc_auc_score(y_test, y_pred)\n\n# Print test_roc_auc\nprint('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))","47a5ffda":"cm1 = metrics.confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(9,9))\nsns.heatmap(cm1, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues');\nplt.ylabel('Actual label');\nplt.xlabel('Predicted label');\nall_sample_title = 'Accuracy Score: {0}'.format(score)\nplt.title(all_sample_title, size = 15)","763764b5":"# Naives Bayes\nfrom sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb.fit(X_train,y_train)\ny_pred_nb = nb.predict(X_test)","eb7d2549":"score = nb.score(X_test, y_test)\nprint(\"Score of the model is - \",score)\nprint(\"Report card of this model - \")\nprint(metrics.classification_report(y_test, y_pred_nb, digits=3))\nprint(\"Accuracy score - \", metrics.accuracy_score(y_test,y_pred_nb))","8ac13ec7":"from sklearn.metrics import roc_auc_score\ntest_roc_auc = roc_auc_score(y_test, y_pred_nb)\n\n# Print test_roc_auc\nprint('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))","1606604f":"cm2 = metrics.confusion_matrix(y_test, y_pred_nb)\nplt.figure(figsize=(9,9))\nsns.heatmap(cm2, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Wistia');\nplt.ylabel('Actual label');\nplt.xlabel('Predicted label');\nall_sample_title = 'Accuracy Score: {0}'.format(score)\nplt.title(all_sample_title, size = 15)","89ba59b3":"# Stochastic Gradient Descent\nfrom sklearn.linear_model import SGDClassifier\nsg = SGDClassifier()\nsg.fit(X_train,y_train)\ny_pred_sg = sg.predict(X_test)","973b170d":"score = sg.score(X_test, y_test)\nprint(\"Score of the model is - \",score)\nprint(\"Report card of this model - \")\nprint(metrics.classification_report(y_test, y_pred_sg, digits=3))\nprint(\"Accuracy score - \", metrics.accuracy_score(y_test,y_pred_sg))","00f312ce":"from sklearn.metrics import roc_auc_score\ntest_roc_auc = roc_auc_score(y_test, y_pred_sg)\n\n# Print test_roc_auc\nprint('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))","1dde12c1":"cm3 = metrics.confusion_matrix(y_test, y_pred_sg)\nplt.figure(figsize=(9,9))\nsns.heatmap(cm3, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Greens');\nplt.ylabel('Actual label');\nplt.xlabel('Predicted label');\nall_sample_title = 'Accuracy Score: {0}'.format(score)\nplt.title(all_sample_title, size = 15)","f5b8c079":"# KNN Model\nfrom sklearn.neighbors import KNeighborsClassifier\nhist = []\nfor i in range(1,10):\n    clf = KNeighborsClassifier(n_neighbors=i)\n    cross_val = cross_val_score(clf, X_scaler, y, cv=5)\n    hist.append(np.mean(cross_val))\nplt.plot(hist)\nplt.title('Cross Validations score for KNeighborsClassifier')\nplt.xlabel('n_neighbors')\nplt.ylabel('Accuracy')\nplt.grid()\nplt.show()","6b874080":"knn = KNeighborsClassifier(n_neighbors = 7)\nknn.fit(X_train,y_train)\ny_pred_knn = knn.predict(X_test)","91f784e7":"score = knn.score(X_test, y_test)\nprint(\"Score of the model is - \",score)\nprint(\"Report card of this model - \")\nprint(metrics.classification_report(y_test, y_pred_knn, digits=3))\nprint(\"Accuracy score - \", metrics.accuracy_score(y_test,y_pred_knn))","e3befdbf":"from sklearn.metrics import roc_auc_score\ntest_roc_auc = roc_auc_score(y_test, y_pred_knn)\n# Print test_roc_auc\nprint('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))","cf3591b8":"cm4 = metrics.confusion_matrix(y_test, y_pred_knn)\nplt.figure(figsize=(9,9))\nsns.heatmap(cm4, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Accent');\nplt.ylabel('Actual label');\nplt.xlabel('Predicted label');\nall_sample_title = 'Accuracy Score: {0}'.format(score)\nplt.title(all_sample_title, size = 15)","81238943":"from sklearn.tree import DecisionTreeClassifier\ndtree = DecisionTreeClassifier(max_depth = None , random_state = 1 , max_features = None, min_samples_leaf =20)\ndtree.fit(X_train,y_train)\ny_pred_dtree = dtree.predict(X_test)","270d45c5":"score = dtree.score(X_test, y_test)\nprint(\"Score of the model is - \",score)\nprint(\"Report card of this model - \")\nprint(metrics.classification_report(y_test, y_pred_dtree, digits=3))\nprint(\"Accuracy score - \", metrics.accuracy_score(y_test,y_pred_dtree))","1697cbe3":"from sklearn.metrics import roc_auc_score\ntest_roc_auc = roc_auc_score(y_test, y_pred_dtree)\n\n# Print test_roc_auc\nprint('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))","01a295ae":"cm5 = metrics.confusion_matrix(y_test, y_pred_dtree)\nplt.figure(figsize=(9,9))\nsns.heatmap(cm5, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'viridis');\nplt.ylabel('Actual label');\nplt.xlabel('Predicted label');\nall_sample_title = 'Accuracy Score: {0}'.format(score)\nplt.title(all_sample_title, size = 15)","7dceeb10":"# Random Forest \nfrom sklearn.ensemble import RandomForestClassifier\n\nhist1 = []\nfor i in range(1,10):\n    clf = RandomForestClassifier(n_estimators=80, max_depth=i, random_state=0)\n    cross_val = cross_val_score(clf, X_train, y_train, cv=5)\n    hist1.append(np.mean(cross_val))\nplt.plot(hist1)\nplt.title('Cross Validations score for RandomForestClassifier')\nplt.xlabel('Max_depth')\nplt.ylabel('Accuracy')\nplt.grid()","62cf9077":"ran_for = RandomForestClassifier(n_estimators=80, max_depth=8, random_state=0)\nran_for.fit(X_train,y_train)\ny_pred_ran = ran_for.predict(X_test)","e4ed69ea":"score = ran_for.score(X_test, y_test)\nprint(\"Score of the model is - \",score)\nprint(\"Report card of this model - \")\nprint(metrics.classification_report(y_test, y_pred_ran, digits=3))\nprint(\"Accuracy score - \", metrics.accuracy_score(y_test,y_pred_ran))","51e705b9":"from sklearn.metrics import roc_auc_score\ntest_roc_auc = roc_auc_score(y_test, y_pred_ran)\n\n# Print test_roc_auc\nprint('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))","962a6a38":"cm6 = metrics.confusion_matrix(y_test, y_pred_ran)\nplt.figure(figsize=(9,9))\nsns.heatmap(cm6, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'viridis');\nplt.ylabel('Actual label');\nplt.xlabel('Predicted label');\nall_sample_title = 'Accuracy Score: {0}'.format(score)\nplt.title(all_sample_title, size = 15)","91fa2fc6":"# Support Vector machine Model\nfrom sklearn.svm import SVC\ngrid = [0.00001, 0.0001, 0.001, 0.01, 0.1]\nhist = []\nfor val in grid:\n    clf = SVC(gamma=val)\n    cross_val = cross_val_score(clf, X, y, cv=5)\n    hist.append(np.mean(cross_val))\nplt.plot([str(i) for i in grid], hist)\nplt.title('Cross Validations score for SVC')\nplt.xlabel('gamma')\nplt.ylabel('Accuracy')\nplt.grid()\nplt.show()\n","5f01c7a8":"svm = SVC(kernel= \"linear\",C=0.025, random_state = 0 , gamma=0.01)\nsvm.fit(X_train,y_train)\ny_pred_svm = svm.predict(X_test)","2618abd9":"score = svm.score(X_test, y_test)\nprint(\"Score of the model is - \",score)\nprint(\"Report card of this model - \")\nprint(metrics.classification_report(y_test, y_pred_svm, digits=3))\nprint(\"Accuracy score - \", metrics.accuracy_score(y_test,y_pred_svm))","8171877b":"from sklearn.metrics import roc_auc_score\ntest_roc_auc = roc_auc_score(y_test, y_pred_svm)\n\n# Print test_roc_auc\nprint('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))","00314ab0":"cm7 = metrics.confusion_matrix(y_test, y_pred_ran)\nplt.figure(figsize=(9,9))\nsns.heatmap(cm7, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Accent_r');\nplt.ylabel('Actual label');\nplt.xlabel('Predicted label');\nall_sample_title = 'Accuracy Score: {0}'.format(score)\nplt.title(all_sample_title, size = 15)","c224cf0b":"#print the true and predicted values\ndictionary = {'Actual values': y_test, 'Predicted values': y_pred_dtree}\npd.DataFrame.from_dict(dictionary)","9457fbef":"#### Here in column name \"Liver_disease\" **0** *indicate that the the person has some kind of Liver Disease or the liver of the patient is unhealthy* and **1** *represents that the person's liver is healthy.*","761fc470":"So, now we have a better understanding of the dataset let's first make the changes that are required to be made","662920fe":"Now seeing all those graphs I'm sure you are pretty bored. Don't worry we will now coming to the most intersting part.\n\n<centre>THE MODELLING!!!!<\/centre>\n\nNo? not interested? You don't want to see how can this dataset can help us? \nIf yes, continue to read...","bbd779a3":"**Conclusion** - Maximum accuracy of 75.17% can be achieved. This accuracy has been achieved by Decision Tree Model ","0d1859fc":"As we can see higher the values of individual test, the more risk you have of having one or more liver related diseases. So eat healthy guys!!","01c8e454":"**Decision Tree Model will be used as it has the highest accuracies among the other models that were used.**","d25bf4cd":"As we can see from Gender histogram Number of Males having liver diseases are way more than the females. Ladies you can relax a little bit. \n        \n        ME - Wanna grab a coffee sometime? \n        Google - Coffee is a brewed drink prep....\n        ME - I did not ask you!!!","f59b5603":"### Naives Bayes Model","a5eba128":"### Stochastic Gradient Descent","30c2913f":"## Problem Context\n\nPatients with Liver disease have been continuously increasing because of excessive consumption of alcohol, inhale of harmful gases, intake of contaminated food, pickles and drugs. This dataset was used to evaluate prediction algorithms in an effort to reduce burden on doctors.","40b949ab":"### Random Forest Classifier","532b08c8":"**Little Note** - When it comes to data modeling, the beginner\u2019s question is always, \"what is the best machine learning algorithm?\" To this the beginner must learn, the [No Free Lunch Theorem (NFLT)](http:\/\/robertmarks.org\/Classes\/ENGR5358\/Papers\/NFL_4_Dummies.pdf) of Machine Learning. In short, NFLT states, there is no super algorithm, that works best in all situations, for all datasets. So the best approach is to try multiple MLAs, tune them, and compare them for your specific scenario.","76d41caf":"### Decision Tree Classifier","0d99602f":"## Importing the required Libraries.","1abf3576":" ### K-Nearest Neighbours","7271aabe":"So, column \"Albumin_and_Globulin_ratio\" has some data missing in it.","3daa3350":"As we can see, many boxplots tells us that there are many outliers present. But these cannot be ignored as they are still possible. A person can has high levels of Alanine Aminotransferase, this clearly indicates that the person has liver problems.\n\nThis will be pretty much clear in the following plots.","218da859":"## Model The Data","a6be8dfd":"Let's do some research on the data set and try to understand what each column is telling us. Afterall, we data scientists love stories.","b011e071":"### Support Vector Machine","890d7cf9":"So, after a long journey of data visulaisation, data cleaning, data modelling etc., we have finally got our model that we can use.\n\n>     So, the next question is - Is this the end?\n>     The answer is - I don't know. I'm no expert guys as I'm also learning. So, if anyone reading this knows what can be done more, kindly help me out here.\n    \nTill then, Have a good day!!","ce1dc7d5":"### Logistic Regression","1a133a0a":"**Before Modelling let us split the data into train and test data**","980f18fb":"## A Little bit of cleaning is required","8de86446":"### Column Name\n\n**Age** - Tells the person's age.\n        \n>         Google - This we all know....duh\n\n**Gender** - (Male or Female) Tells the person's gender. This is a very controversial column as we now know that there can be a spectrum of genders. But here we will only consider two genders.\n            \n>          ME - My sincere apologies to the people who do not orient themselves as \"Male\" or \"Female\". I hope in near future we will have a dataset where the spectrum of genders are included.            \n         Google - Oh my! you knew that gender is not binary but a spectrum. Impressive..\n         ME - Thank you google.\n\n**Total_Bilirubin** - Well, I'm a mechancial engineer and not a doctor. So obviously I have no clue what this means. Let's ask google baba.\n\n>         Google - A bilirubin test measures the amount of bilirubin in your blood. It\u2019s used to help find the cause of health conditions like jaundice, anemia, and liver disease.\n>         Bilirubin is an orange-yellow pigment that occurs normally when part of your red blood cells break down. Your liver takes the bilirubin from your blood and changes its chemical make-up so that most of it is passed through your poop as bile.\n>         If your bilirubin levels are higher than normal, it\u2019s a sign that either your red blood cells are breaking down at an unusual rate or that your liver isn\u2019t breaking down waste properly and clearing the bilirubin from your blood.Another option is that there\u2019s a problem somewhere along the pathway that gets the bilirubin out of your liver and into your stool. \n        \n>         ME - Thank you Google. So fellows, I think now you have some knowledge on this as I do. And if you knew it already, you are awesome.\n        \n**Direct_Bilirubin** - It's technically the same as \"Total_Bilirubin\". The difference will be given us by our own google.\n        \n>         Google - Bilirubin attached by the liver to glucuronic acid, a glucose-derived acid, is called direct, or conjugated, bilirubin. Bilirubin not attached to glucuronic acid is called indirect, or unconjugated, bilirubin. All the bilirubin in your blood together is called total bilirubin. \n>         \n>         ME - Damn you google, how much information do you have.....\n        \n**Alkaline_Phosphotase** - .......\n\n>         Google - Alkaline phosphatase (ALP) is an enzyme in a person's blood that helps break down proteins. The body uses ALP for a wide range of processes, and it plays a particularly important role in liver function and bone development.Using an ALP test, it is possible to measure how much of this enzyme is circulating in a person\u2019s blood.\n>         \n>         ME - I knew this....\n>         Google - No, you don't\n>         Me - Yeah.....you know everything....\n\n**Alamine_Aminotransferase** - First of all it is \"Alanine\" and not \"Alamine\" . Rest our friend google will tell.\n\n>         Google - Alanine aminotransferase (ALT) is an enzyme found primarily in the liver and kidney. It was originally referred to as serum glutamic pyruvic transaminase (SGPT). Normally, a low level of ALT exists in the serum. ALT is increased with liver damage and is used to screen for and\/or monitor liver disease. Alanine aminotransferase (ALT) is usually measured concurrently with AST as part of a liver function panel to determine the source of organ damage. \n>         \n>         ME - So, we need to change the column name to aviod confusion.\n        \n**Aspartate_Aminotransferase** - Help Google.....\n\n>         Google - AST (aspartate aminotransferase) is an enzyme that is found mostly in the liver, but also in muscles. When your liver is damaged, it releases AST into your bloodstream. An AST blood test measures the amount of AST in your blood. The test can help your health care provider diagnose liver damage or disease.\n>         \n>         ME - WOOAAAHHH.......\n        \n**Total_protein** - Albumin and globulin are two types of protein in your body. The total protein test measures the total amount albumin and globulin in your body. It's used as part of your routine health checkup. It may also be used if you have unexpected weight loss, fatigue, or the symptoms of a kidney or liver disease.\n        \n>         ME - Atlast, something I knew.        \n>         Google - You googled it. Don't play smart with me.\n>         ME - uughhhh........There's no pleasing you.\n        \n**Albumin** - I think it's related to the protein in our bodies....\n            \n>         Google - Albumin is a protein made by your liver. Albumin helps keep fluid in your bloodstream so it doesn't leak into other tissues. It is also carries various substances throughout your body, including hormones, vitamins, and enzymes. Low albumin levels can indicate a problem with your liver or kidneys.\n>         \n>         ME - Close enough!!...\n>         Google - *Face palms*\n\n**Albumin_and_Globulin_Ratio** - This one's pretty eas......\n\n>         Google - The Albumin to Globulin ratio (A:G) is the ratio of albumin present in serum in relation to the amount of globulin. The ratio can be interpreted only in light of the total protein concentration. Very generally speaking, the normal ratio in most species approximates 1:1.\n>         \n>         ME - I give up....\n>         Google - Who made you a data scientist\n>         ME - heyyy!! That's mean..\n>         Google - The Arithmetic Mean is the average of the numbe....\n>         ME - I know THAT...\n\n**Dataset** - This is labelled incorrectly. From my perspective it should be \"Liver_Disease\" indicating that the patient has liver disease or not "}}