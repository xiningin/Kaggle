{"cell_type":{"6456efb9":"code","e2d6991a":"code","828783e9":"code","02e21714":"code","eb00e2c0":"code","1bcbbee9":"code","4a99a232":"code","23605b94":"code","6bdc9f89":"code","00635d1b":"code","35cdfd7f":"code","19ea1e78":"code","b94ace0f":"code","5835fd2d":"code","a3d8302e":"code","6e421853":"code","db199c4c":"code","45206452":"code","b82f7f58":"code","30484343":"code","faede2f5":"code","67e18308":"code","2735581e":"code","950a9aca":"code","1a2c0cfd":"code","57be8a8f":"markdown","34b4749e":"markdown"},"source":{"6456efb9":"# \u5bfc\u5165\u6570\u636e\u5206\u6790\u5e38\u7528\u5e93\uff0c\u8be5\u90e8\u5206\u6a21\u5757\u53ef\u7528\u4e8e\u6570\u636e\u96c6\u7684\u5206\u6790\u548c\u53ef\u89c6\u5316\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","e2d6991a":"# \u5bfc\u5165sklearn\u76f8\u5173\u5e93+(xgboost)\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.pipeline import make_pipeline, Pipeline\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier","828783e9":"# \u5bfc\u5165csv\u6570\u636e\n# df_train = pd.read_csv(r'F:\\Python\\datasets\\kaggle\\started\\digit-recognizer\\train.csv')\n# df_test = pd.read_csv(r'F:\\Python\\datasets\\kaggle\\started\\digit-recognizer\\test.csv')\n\ndf_train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","02e21714":"# \u67e5\u770b\u6570\u636e\u96c6\u76f8\u5173\u4fe1\u606f\n# \u901a\u8fc7info()\u51fd\u6570\u53ef\u4ee5\u5f97\u77e5\u6570\u636e\u96c6\u6ca1\u6709\u4e3aNone\u7684\u60c5\u51b5\uff0c\u53ef\u4ee5\u8df3\u8fc7\u6570\u636e\u6e05\u6d17\u73af\u8282\ndf_train.info()\ndf_test.info()","eb00e2c0":"# \u67e5\u770b\u6570\u636e\uff0c(42000, 785)\uff0c42000\u4e2a\u6837\u672c\uff0c\u6bcf\u4e2a\u6837\u672c\u4e3a28*28=785\u4e2a\u7279\u5f81\uff0c\u537328*28\u50cf\u7d20\u7684\u56fe\u7247\uff0c\u6bcf\u4e00\u4e2a\u503c\u4e3a0~255\nprint(df_train.shape)","1bcbbee9":"# \u8f6c\u6362\u6210narray y\/255.0 \u5c06\u6570\u636e\u7f29\u653e\u52300~1\u4e4b\u95f4\nX = np.array(df_train.drop(['label'], axis=1)).astype(np.float32)\/255.0\ny = np.array(df_train['label'])","4a99a232":"# \u6253\u5370\u90e8\u5206\u624b\u5199\u4f53\u56fe\u7247\nfig, axes = plt.subplots(5, 5, figsize=(10, 10))\naxes = axes.flatten()\n\nfor ax, x, label in zip(axes, X[:25], y[:25]):\n    img = x.reshape(28, 28)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.imshow(img, cmap='Greys')\n    ax.set_title(label)","23605b94":"# \u62c6\u5206\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\nX_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, random_state=10)","6bdc9f89":"# \u6784\u5efa\u903b\u8f91\u56de\u5f52\u6a21\u578b\nmodel = LogisticRegression(max_iter=1000)\nmodel.fit(X_train, y_train)\n\ntrain_score = model.score(X_train, y_train)\ntest_score = model.score(X_test, y_test)\nprint('Train score:{} Test score:{}'.format(train_score, test_score))\n# Train score:0.9473015873015873 Test score:0.9161904761904762\n# executed in 39.7s, finished 08:23:30 2021-04-13","00635d1b":"# \u6784\u5efa\u968f\u673a\u68ee\u6797\u6a21\u578b RandomForestClassifier\nmodel = RandomForestClassifier()\nmodel.fit(X_train, y_train)\n\ntrain_score = model.score(X_train, y_train)\ntest_score = model.score(X_test, y_test)\nprint('Train score:{} Test score:{}'.format(train_score, test_score))\n# Train score:1.0 Test score:0.9642857142857143\n# executed in 22.5s, finished 08:23:57 2021-04-13","35cdfd7f":"# xgboost XGBRFClassifier\nmodel = XGBClassifier(use_label_encoder=False)\nmodel.fit(X_train, y_train)\n\ntrain_score = model.score(X_train, y_train)\ntest_score = model.score(X_test, y_test)\nprint('Train score:{} Test score:{}'.format(train_score, test_score))\n# Train score:1.0 Test score:0.974\n# executed in 3m 56s, finished 09:13:44 2021-04-13","19ea1e78":"# \u53ef\u4ee5\u53d1\u73b0XGBClassifier\u8017\u65f6\u66f4\u4e45\uff0c\u4f46\u5f97\u5230\u4e86\u66f4\u597d\u7684\u51c6\u786e\u5ea6\n# \u5982\u4e0b\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u5904\u7406\u624b\u5199\u4f53\u5206\u7c7b\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import SGD\n\nsgd = SGD(learning_rate=.01, momentum=.9)\n\nmodel = Sequential()\nmodel.add(Dense(units=64, activation='relu', input_dim=(28*28)))\nmodel.add(Dense(units=128, activation='relu'))\nmodel.add(Dense(units=10, activation='softmax'))\n\nmodel.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(\n    x=X_train, y=y_train,\n    batch_size=128,\n    epochs=20\n)\n\n# \u6a21\u578b\u8bc4\u4f30\nloss, accuracy = model.evaluate(X_test, y_test)\nprint('loss:{} accuracy:{}'.format(loss, accuracy))\n# loss:0.10486899316310883 accuracy:0.966952383518219\n# executed in 23.5s, finished 09:08:35 2021-04-13","b94ace0f":"# \u5148\u5c06y\u8f6c\u6362\u6210categorical\u683c\u5f0f\uff0c\u53732-->[0010000000]\nfrom tensorflow.keras.utils import to_categorical\nY_train = y_train.copy()\nY_test = y_test.copy()\n\ny_train = to_categorical(y_train, num_classes = 10)\ny_test = to_categorical(y_test, num_classes = 10)","5835fd2d":"from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPool2D\nfrom tensorflow.keras.models import Sequential\n\n# \u521b\u5efa\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","a3d8302e":"from tensorflow.keras.optimizers import RMSprop\n\n# \u6a21\u578b\u7f16\u8bd1\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","6e421853":"# \u6309\u7167\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u66f4\u65b0\u6837\u672c\u6570\u636e\u7684shape\nX_train = X_train.reshape(-1,28,28,1)\nX_test = X_test.reshape(-1, 28, 28, 1)","db199c4c":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# \u521b\u5efa\u56fe\u7247\u589e\u5f3a\u751f\u6210\u5668\ndatagen = ImageDataGenerator(\n    featurewise_center=False,  # set input mean to 0 over the dataset\n    samplewise_center=False,  # set each sample mean to 0\n    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n    samplewise_std_normalization=False,  # divide each input by its std\n    zca_whitening=False,  # apply ZCA whitening\n    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n    zoom_range = 0.1, # Randomly zoom image \n    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n    horizontal_flip=False,  # randomly flip images\n    vertical_flip=False  # randomly flip images\n)\n\nbatch_size = 32\nepochs = 30\n\ntrain_gen = datagen.flow(\n    x=X_train, y=y_train,\n    batch_size=batch_size\n)\n\ntest_gen = datagen.flow(\n    x=X_test, y=y_test,\n    batch_size=batch_size\n)","45206452":"from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n# \u5f53\u6807\u51c6\u8bc4\u4f30\u505c\u6b62\u63d0\u5347\u65f6\uff0c\u964d\u4f4e\u5b66\u4e60\u901f\u7387\u3002\n# \u5f53\u5b66\u4e60\u505c\u6b62\u65f6\uff0c\u6a21\u578b\u603b\u662f\u4f1a\u53d7\u76ca\u4e8e\u964d\u4f4e 2-10 \u500d\u7684\u5b66\u4e60\u901f\u7387\n# \u8fd9\u4e2a\u56de\u8c03\u51fd\u6570\u76d1\u6d4b\u4e00\u4e2a\u6570\u636e\u5e76\u4e14\u5f53\u8fd9\u4e2a\u6570\u636e\u5728\u4e00\u5b9a\u300c\u6709\u8010\u5fc3\u300d\u7684\u8bad\u7ec3\u8f6e\u4e4b\u540e\u8fd8\u6ca1\u6709\u8fdb\u6b65\uff0c\u90a3\u4e48\u5b66\u4e60\u901f\u7387\u5c31\u4f1a\u88ab\u964d\u4f4e\n# Set a learning rate annealer\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n                              patience=2, verbose=1, min_lr=0.00001)\n\n# model_check = ModelCheckpoint(\n#     filepath='D:\/desktop\/ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}_accuracy{accuracy:.4f}_val_accuracy{accuracy:.4f}.h5',\n#     save_best_only=True\n# )","b82f7f58":"# \u6a21\u578b\u8bad\u7ec3\nhistory = model.fit(\n    x=X_train,\n    y=y_train,\n    batch_size=batch_size,\n    epochs=2, # \u5982\u679c\u518d\u672c\u5730\u53ef\u4ee5\u4f7f\u7528\u9ad8\u6027\u80fdgpu\uff0c\u53ef\u4ee5\u8bbe\u7f6eepochs=30\uff0c\u4ee5\u5bfc\u523099%+\u7684\u51c6\u786e\u7387\n#     epochs=epochs,\n#   callbacks=[reduce_lr, model_check],\n    callbacks=[reduce_lr],\n    validation_data=(X_test, y_test),\n    steps_per_epoch=X_train.shape[0]\/\/batch_size+1,\n)\n# train:31414\/31500- ETA: 0s - loss: 0.0281 - accuracy: 0.9926 - \n# test:val_loss: 0.0412 - val_accuracy: 0.9914\n# executed in 6m 28s, finished 13:03:05 2021-04-13","30484343":"# \u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u53ef\u4ee5\u83b7\u5f9799%+\u7684\u51c6\u786e\u7387\uff0c\u6548\u679c\u8fbe\u5230\u53ef\u7528\u6c34\u5e73\uff0c\u63a5\u4e0b\u6765\u901a\u8fc7\u6df7\u6dc6\u77e9\u9635\u67e5\u770b\u5177\u4f53\u8bc6\u522b\u9519\u8bef\u7684\u60c5\u51b5\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_true=Y_test, y_pred=np.argmax(model.predict(X_test), axis=1))","faede2f5":"cm_df = pd.DataFrame(cm)\n\nplt.figure(figsize=(10, 7))\nsns.heatmap(data=cm_df, cmap=plt.cm.Blues, center=0.5, annot=True, fmt='.0f', linewidths=.3)","67e18308":"# \u83b7\u53d6\u6a21\u578b\u9519\u8bef\u8bc6\u522b\u7684\u6570\u636e\ny_pred = np.argmax(model.predict(X_test), axis=1)\nerros = (y_pred - Y_test) != 0\n\nX_erros = X_test[erros]\ny_erros = Y_test[erros]\ny_erros_pred = y_pred[erros]","2735581e":"# \u753b\u51fa\u90e8\u5206\u9519\u8bef\u8bc6\u522b\u7684\u4f8b\u5b50\nfig, axes = plt.subplots(5, 5, figsize=(20, 20))\naxes = axes.flatten()\nfor ax, x, y, y_pred in zip(axes, X_erros, y_erros, y_erros_pred):\n    x = x.reshape(28, 28)\n    ax.imshow(x, cmap='Greys')\n    ax.set_title('right:{} wrong:{}'.format(y, y_pred))\n    ax.set_xticks([])\n    ax.set_yticks([])","950a9aca":"# \u53ef\u4ee5\u770b\u51fa\uff0c\u8fd9\u90e8\u5206\u7684\u786e\u662f\u56e0\u4e3a\u624b\u5199\u975e\u5e38\u5f02\u5e38\u5bfc\u81f4\u7684\u9519\u8bef\uff0c\u6216\u8bb8\u76f4\u63a5\u7531\u4eba\u90fd\u65e0\u6cd5\u5206\u8fa8\n# \u901a\u8fc7\u4e0a\u9762\u6211\u4eec\u53ef\u4ee5\u5f97\u5230\u901a\u8fc7cnn\u6a21\u578b\u53ef\u4ee5\u83b7\u53d6\u6700\u4f73\u7684\u6548\u679c\uff0c\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u5c06\u8be5\u6a21\u578b\u8fdb\u884c\u4fdd\u5b58","1a2c0cfd":"# \u6a21\u578b\u4fdd\u5b58\nmodel.save(\"..\/output\/kaggle\/working\/mnist_99_cnn_model.h5\")","57be8a8f":"# cnn\u5728minist\u6570\u636e\u96c6\u5f97\u520699+%","34b4749e":"\u4ece\u4e0a\u9762\u53ef\u4ee5\u770b\u51fa\uff0cxgboost\u7684\u6548\u679c\u66f4\u597d\uff0c\u4f46\u8bad\u7ec3\u7684\u65f6\u95f4\u4e5f\u66f4\u957f\uff0c\u795e\u7ecf\u7f51\u7edc\u548c\u968f\u673a\u68ee\u6797\u6548\u679c\u90fd\u4e0d\u9519\uff0c\u5728\u6d4b\u8bd5\u6570\u636e\u96c6\u4e0a\u51c6\u786e\u7387\u8fbe\u5230\u4e8696%+\uff0cminist\u6570\u636e\u96c6\u662f\u4e00\u4efd\u8f83\u7b80\u5355\u6570\u636e\u96c6\uff0c\u6216\u8bb8\u53ef\u4ee5\u6709\u66f4\u597d\u7684\u8868\u73b0\uff0c\u73b0\u5728\u6211\u4eec\u901a\u8fc7\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u63a2\u7d22\u4e00\u4e0b\u662f\u5426\u53ef\u4ee5\u7ee7\u7eed\u63d0\u5347\u51c6\u786e\u7387"}}