{"cell_type":{"7134798f":"code","4b368d81":"code","79ff3359":"code","e945d11a":"code","b874b258":"code","dda06407":"code","3d375fcf":"code","0f321808":"code","2bf3ae33":"code","a75af9e5":"code","f64e5116":"code","6c1eb808":"code","e8b862ca":"code","168df76d":"code","ce80acab":"code","c95b7dc6":"code","67338bc7":"code","77d8b36f":"code","c22c0266":"code","9defa206":"code","ea050d74":"code","33115a25":"code","acc233cb":"code","68675192":"code","70098227":"code","1cc72711":"markdown","9029fba7":"markdown","323b666b":"markdown","2d336355":"markdown","eaa1609a":"markdown","4cb3b84a":"markdown","7748decb":"markdown","42a974ad":"markdown","e6cf7698":"markdown","c9775312":"markdown","f48ffe7a":"markdown","85f8ec7a":"markdown","d31c797b":"markdown","dfe3c30b":"markdown","81af191e":"markdown","1c161630":"markdown","c1399bab":"markdown","cc1d3cfc":"markdown","abb953f1":"markdown","4181693e":"markdown","fe725d44":"markdown","5b7c5428":"markdown","cc724bbf":"markdown","7b87e980":"markdown","31e9f90a":"markdown"},"source":{"7134798f":"import os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport textwrap as tw\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import FuncFormatter\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom keras.models import Sequential\nfrom keras.layers import Activation, BatchNormalization, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom keras.applications.resnet import preprocess_input\nfrom keras_preprocessing.image import ImageDataGenerator","4b368d81":"# print all columns\npd.set_option('display.max_columns', None)\n\n# inhibit graphics card runs out of memory\ngpu_devices = tf.config.experimental.list_physical_devices('GPU')\nfor device in gpu_devices:\n    tf.config.experimental.set_memory_growth(device, True)\n\n# default parameter\nsns.set_theme(style=\"ticks\")","79ff3359":"def load_data(path: str):\n    dir = Path(path)\n    # list of all filepathes\n    filepaths = list(dir.glob(r'**\/*.jpg'))\n    # list of labels extracted from last foldername of filepath\n    labels = list(map(lambda l: os.path.split(os.path.split(l)[0])[1], filepaths))\n    # series of string filepathes\n    filepaths = pd.Series(filepaths, name='FilePaths').astype(str)\n    # series of string labels\n    labels = pd.Series(labels, name='Labels').astype(str)\n    # merge series to dataframe df\n    df = pd.merge(filepaths, labels, right_index=True, left_index=True)\n    # Resampling complete rows and reset the index\n    return df.sample(frac=1).reset_index(drop=True)\n\n\ndf = load_data('..\/input\/skin-cancer9-classesisic\/Skin cancer ISIC The International Skin Imaging Collaboration\/Train')","e945d11a":"df.head(3)","b874b258":"df.info()","dda06407":"# ordered count of rows per unique label\nlabels_count = df['Labels'].value_counts(ascending=True)\n\nf = plt.figure(figsize=(15, 6))\ns = sns.barplot(labels_count.index,labels_count.values)\nsns.despine()\ns.set_xticklabels(s.get_xticklabels(), rotation = 30)","3d375fcf":"def plot_images_per_label(df, label, cols: int, size: tuple):\n    fig, axs = plt.subplots(nrows=1, ncols=cols, figsize=size)\n\n    cntMax = cols\n    cntCur = 0\n    for index, row in df.iterrows():\n        if(row['Labels'] == label and cntCur < cntMax):\n            axs[cntCur].imshow(plt.imread(df.FilePaths[index]))\n            axs[cntCur].set_title(df.Labels[index])\n\n            cntCur += 1\n        else:\n            if(cntCur >= cntMax):\n                break\n    \n    plt.tight_layout()\n    plt.show()\n\n\n# unique labels\nlabels = sorted(df['Labels'].unique())\n# loop through labels\nfor label in labels:\n    plot_images_per_label(df, label, 3, (12,9))","0f321808":"# stratified train and val (20%) datasets\nX_train, X_val = train_test_split(df, test_size=0.2, stratify=df['Labels'], random_state=1)\n\nprint('Train Data: ', X_train.shape)\nprint('Val Data: ', X_val.shape)","2bf3ae33":"# number of samples\/images per iteration\nBATCH_SIZE = 32\n# input image size\nIMG_SIZE = (224, 224)\n# count of epchos\nEPOCHS = 15\n\n# image preprocessing\nimg_data_gen = ImageDataGenerator(shear_range=0.2,\n                                  zoom_range=0.2,\n                                  horizontal_flip=True,\n                                  preprocessing_function=preprocess_input)\n\nX_train = img_data_gen.flow_from_dataframe(dataframe=X_train,\n                                           x_col='FilePaths',\n                                           y_col='Labels',\n                                           target_size=IMG_SIZE,\n                                           color_mode='rgb',\n                                           class_mode='categorical',\n                                           batch_size=BATCH_SIZE,\n                                           seed=1)\n\nX_val = img_data_gen.flow_from_dataframe(dataframe=X_val,\n                                         x_col='FilePaths',\n                                         y_col='Labels',\n                                         target_size=IMG_SIZE,\n                                         color_mode='rgb',\n                                         class_mode='categorical',\n                                         batch_size=BATCH_SIZE,\n                                         seed=1)","a75af9e5":"fit, ax = plt.subplots(nrows=3, ncols=3, figsize=(12,9))\n\nfor i, a in enumerate(ax.flat):\n    img, label = X_train.next()\n    a.imshow(img[0],)\n    a.set_title(label[0])\n\nplt.tight_layout()\nplt.show()","f64e5116":"model = Sequential()\n# scale image size to 0..1\nmodel.add(tf.keras.layers.experimental.preprocessing.Rescaling(1.\/255))\n\n# 1. Conv2D layer\nmodel.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', input_shape=(224, 224, 3)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n\n# 2. Conv2D layer\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n\n# 3. Conv2D layer\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=2, padding='valid'))\n\n# scale to 1 dimensional input for NN\nmodel.add(Flatten())\n\n# hidden fully connected layer\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\n\n# inhibit overfitting\nmodel.add(Dropout(0.2))\n\n# output fully connected layer\nmodel.add(Dense(9))\nmodel.add(Activation('softmax'))\n\n# compile model\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","6c1eb808":"# stop training when accuracy has stopped improving \n# cb = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3)\n# hst = model.fit(X_train, validation_data=X_val, epochs=EPOCHS, callbacks=cb)\n# train model \nhst = model.fit(X_train, validation_data=X_val, epochs=EPOCHS)","e8b862ca":"# model.save_weights('model',save_format='tf')","168df76d":"# model.load_weights('model')","ce80acab":"model.summary()","c95b7dc6":"accuracy = hst.history['accuracy']\nloss = hst.history['loss']\nval_loss = hst.history['val_loss']\nval_accuracy = hst.history['val_accuracy']\n\nplt.figure(figsize=(17, 17))\nplt.subplot(2, 2, 1)\nplt.plot(range(EPOCHS), accuracy, label='Training Accuracy')\nplt.plot(range(EPOCHS), val_accuracy, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Accuracy : Training vs. Validation ')\n\nplt.subplot(2, 2, 2)\nplt.plot(range(EPOCHS), loss, label='Training Loss')\nplt.plot(range(EPOCHS), val_loss, label='Validation Loss')\nplt.title('Loss : Training vs. Validation ')\nplt.legend(loc='upper right')\nplt.show()","67338bc7":"X_test = load_data('..\/input\/skin-cancer9-classesisic\/Skin cancer ISIC The International Skin Imaging Collaboration\/Test')","77d8b36f":"X_test.head(3)","c22c0266":"print('Test Data: ', X_test.shape)\n\n# ordered count of rows per unique label\nX_test['Labels'].value_counts(ascending=True)","9defa206":"# image preprocessing\nX_test = img_data_gen.flow_from_dataframe(dataframe=X_test,\n                                          x_col='FilePaths',\n                                          y_col='Labels',\n                                          target_size=IMG_SIZE,\n                                          color_mode='rgb',\n                                          class_mode='categorical',\n                                          batch_size=BATCH_SIZE,\n                                          shuffle=False, # necessary fpr confusion matrix\n                                          seed=1)","ea050d74":"res = model.evaluate(X_test)","33115a25":"# accuracy\nprint(f'Train Accuracy: {hst.history[\"accuracy\"][-1:][0] * 100:.2f}')\nprint(f'Val Accuracy: {hst.history[\"val_accuracy\"][-1:][0] * 100:.2f}')\nprint(f'Test Accuracy: {res[1] * 100:.2f}')\n# loss\nprint(f'Train Loss: {hst.history[\"loss\"][-1:][0] * 100:.2f}')\nprint(f'Val Loss: {hst.history[\"val_loss\"][-1:][0] * 100:.2f}')\nprint(f'Test Loss: {res[0] * 100:.2f}')","acc233cb":"# predicted labels\nY_pred = model.predict(X_test)\nprint(\"Y_pred\", Y_pred.shape)\n# rounded labels\ny_pred = np.argmax(Y_pred, axis=1)\nprint(\"y_pred\", y_pred.size)","68675192":"# true labels\ny_true = X_test.classes\nprint(\"y_pred\", len(y_pred))\n# label classes\nclass_labels = list(X_test.class_indices.keys())\nprint(\"labels\", len(class_labels))","70098227":"# compare with true labels\ncfm = confusion_matrix(y_pred, y_true, normalize='true')\n\n# plot size\nfig, ax = plt.subplots(figsize=(18,18))\n# print confusion matrix\ns = sns.heatmap(cfm,\n               annot=True,\n               cmap=['#ff0000', '#09AA00'],\n               center=0.8,\n               fmt='.1%',\n               linewidths=.5,\n               cbar_kws={'format': FuncFormatter(lambda x, pos: '{:.0%}'.format(x))}, #'label': 'Percentage' \n               linecolor='white',\n               ax=ax)\n# set labels\ns.set(xlabel='Predict', ylabel='True')\ns.set(title='Confusion Matrix')\ns.set_yticklabels([tw.fill(e, 10) for e in class_labels])\ns.set_xticklabels([tw.fill(e, 10) for e in class_labels])","1cc72711":"### -> bad test dataset","9029fba7":"### Train model","323b666b":"### Create and compile CNN model","2d336355":"### Load the model","eaa1609a":"### Print confusion matrix","4cb3b84a":"### Import modules","7748decb":"### Split the dataset into Train- and Val-datasets","42a974ad":"### Plot images after preprocessing","e6cf7698":"### Print a short summary of the dataset","c9775312":"### Accuracies and results","f48ffe7a":"### Test model","85f8ec7a":"### Shape of Test Data and ordered count of rows per unique label","d31c797b":"### Load Test Data","dfe3c30b":"### Print model summary ","81af191e":"### Print first rows","1c161630":"### Training vs. Validation","c1399bab":"### Settings","cc1d3cfc":"### Save the model","abb953f1":"### Plot 3 images per label ","4181693e":"### Print unique labels","fe725d44":"### Preprocess images","5b7c5428":"### Preprocess test images","cc724bbf":"### Load data","7b87e980":"### Calc y_true","31e9f90a":"### Calc y_pred"}}