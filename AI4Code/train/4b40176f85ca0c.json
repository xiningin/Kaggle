{"cell_type":{"1a214dec":"code","3b506c27":"code","da3c4f78":"code","961d167b":"code","07b3f323":"code","5c8e14a4":"code","89aee789":"code","c5927cec":"code","b4afd38a":"code","2aa7ce48":"code","3e4807a4":"code","cbd755e1":"code","65c11566":"code","b7bf10d7":"code","4d7e00a9":"code","5913cf27":"code","24303271":"code","ac0c98de":"code","8ff8d0f3":"code","ed7b31cf":"code","7759afab":"code","a502da52":"code","4d3643e8":"code","a9b52d09":"code","8b4cb56b":"code","be54e6c8":"code","300aec15":"code","28398d0c":"code","d7c315ba":"code","d18bbcde":"code","2c8a6965":"code","aa34c8a9":"code","f8ed3bfe":"code","ccee7ae6":"code","ba60ef28":"code","056c98aa":"code","74774981":"code","41328e9a":"code","f513d66f":"code","0a658598":"code","6c6a9daf":"code","4f477a29":"code","b4259262":"code","26b64e65":"code","0b2551e7":"code","99d12498":"code","ec16e2d7":"code","d0cff4cc":"code","999bab9f":"code","f3acd08e":"code","2d567736":"markdown","5bedd702":"markdown","d7adb800":"markdown","f78a78cf":"markdown","f401a70f":"markdown","78cf080f":"markdown","f787d022":"markdown","834669be":"markdown","ddb64de9":"markdown","6fc8e1a5":"markdown","fc5b81e3":"markdown","5bc6bbd6":"markdown","e69071b1":"markdown","06d66fbc":"markdown","8075a424":"markdown","468a57d6":"markdown","7cdc14c2":"markdown","4551fff7":"markdown","6e15464a":"markdown","a966d40c":"markdown"},"source":{"1a214dec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3b506c27":"import matplotlib.pyplot as plt\nimport seaborn as sns # Data Visualisation and EDA","da3c4f78":"# Loading the data from the CSV file to Pandas Data Frame\npath = '\/kaggle\/input\/usa-housing\/USA_Housing.csv'\nHousingDF = pd.read_csv(path)","961d167b":"# First 5 rows of the Data Frame\nHousingDF.head()","07b3f323":"# Number of Rows and Columns\nHousingDF.shape","5c8e14a4":"# Information about the dataset\nHousingDF.info()","89aee789":"# Categorical Feature: Address","c5927cec":"print('Rows             :', HousingDF.shape[0])\nprint('Columns          :', HousingDF.shape[1])\nprint('\\nFeatures       :' , HousingDF.columns.tolist())\nprint('\\nMissingValues  :' , HousingDF.isnull().values.sum())\nprint('\\nUnique values  :' , HousingDF.nunique())","b4afd38a":"# Checking for any Missing Values\nHousingDF.isnull().sum()","2aa7ce48":"# Zero Missing Values in the Data Set","3e4807a4":"# Statistical Measures of the dataset\nHousingDF.describe()","cbd755e1":"# Average Area Income Distribution\nsns.set()\nplt.figure(figsize = (6, 6))\nsns.displot(HousingDF['Avg. Area Income'])\nplt.title('Avg. Area Income Distribution')\nplt.show()","65c11566":"# Average Area House Age Distribution\nsns.set()\nplt.figure(figsize = (6, 6))\nsns.displot(HousingDF['Avg. Area House Age'])\nplt.title('Avg. Area House Age Distribution')\nplt.show()","b7bf10d7":"# Average Area Number of Rooms Distribution\nsns.set()\nplt.figure(figsize = (6, 6))\nsns.displot(HousingDF['Avg. Area Number of Rooms'])\nplt.title('Avg. Area Number of Rooms Distribution')\nplt.show()","4d7e00a9":"# Average Area Number of Bedrooms Distribution\nsns.set()\nplt.figure(figsize = (6, 6))\nsns.displot(HousingDF['Avg. Area Number of Bedrooms'])\nplt.title('Avg. Area Number of Bedrooms Distribution')\nplt.show()","5913cf27":"# Area Population Distribution\nsns.set()\nplt.figure(figsize = (6, 6))\nsns.displot(HousingDF['Area Population'])\nplt.title('Area Population Distribution')\nplt.show()","24303271":"# Price Distribution\nsns.set()\nplt.figure(figsize = (6, 6))\nsns.displot(HousingDF['Price'])\nplt.title('Price Distribution')\nplt.show()","ac0c98de":"sns.heatmap(HousingDF.corr(), annot = True)","8ff8d0f3":"# LS = 0.05: meaning we are 95% confident that the correlation between attribute variables is significant\nfrom scipy import stats","ed7b31cf":"pearson_coef, p_value = stats.pearsonr(HousingDF['Avg. Area Income'], HousingDF['Price'])\nprint(\"The Pearsons Correlation Coefficint is :\" , pearson_coef , \"with a p-valye of p = \", p_value)","7759afab":"# A moderate Strong positive correlation Coefficient and p-value = 0 < 0.001 hence a\n# Strong evidence that correlation is significant","a502da52":"pearson_coef, p_value = stats.pearsonr(HousingDF['Avg. Area House Age'], HousingDF['Price'])\nprint(\"The Pearsons Correlation Coefficint is :\" , pearson_coef , \"with a p-valye of p = \", p_value)","4d3643e8":"# A fine Strong positive correlation Coefficient and p-value = 0 < 0.001 hence a\n# Strong evidence that correlation is significant","a9b52d09":"pearson_coef, p_value = stats.pearsonr(HousingDF['Avg. Area Number of Rooms'], HousingDF['Price'])\nprint(\"The Pearsons Correlation Coefficint is :\" , pearson_coef , \"with a p-valye of p = \", p_value)","8b4cb56b":"# A weak Strong positive correlation Coefficient and p-value = 0 < 0.001 hence a\n# Strong evidence that correlation is significant","be54e6c8":"pearson_coef, p_value = stats.pearsonr(HousingDF['Avg. Area Number of Bedrooms'], HousingDF['Price'])\nprint(\"The Pearsons Correlation Coefficint is :\" , pearson_coef , \"with a p-valye of p = \", p_value)","300aec15":"# Very weak positive correlation Coefficient and p-value = 0 < 0.001 hence a\n# Strong evidence that correlation is significant","28398d0c":"pearson_coef, p_value = stats.pearsonr(HousingDF['Area Population'], HousingDF['Price'])\nprint(\"The Pearsons Correlation Coefficint is :\" , pearson_coef , \"with a p-valye of p = \", p_value)","d7c315ba":"# A fine Strong positive correlation Coefficient and p-value = 0 < 0.001 hence a\n# Strong evidence that correlation is significant","d18bbcde":"sns.pairplot(HousingDF)","2c8a6965":"# Encoding Categorical Variable - Address\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\nle.fit(HousingDF.Address.drop_duplicates())\nHousingDF.Address = le.transform(HousingDF.Address)","aa34c8a9":"# Checking the correlation of features with our traget variable\nprint(HousingDF.corr()['Price'].sort_values())\nf, ax = plt.subplots(figsize = (10, 8))\ncorr = HousingDF.corr()\nsns.heatmap(HousingDF.corr(), annot = True)","f8ed3bfe":"# A Strong Correlation between Price and Avg. Area Income","ccee7ae6":"# How Avg. Area Income affects the Price\nplt.figure(figsize=(15,6))\nplt.title(\"Distribution of Avg. Area Income\")\nax = sns.distplot(HousingDF['Avg. Area Income'])","ba60ef28":"# We can See that Avg. Area Income is ~ 70,000","056c98aa":"# How Avg. Area House Age affects the Price\nplt.figure(figsize=(15,6))\nplt.title(\"Distribution of Avg. Area House Age\")\nax = sns.distplot(HousingDF['Avg. Area House Age'])","74774981":"# How Avg. Area Number of Rooms affects the Price\nplt.figure(figsize=(15,6))\nplt.title(\"Distribution of Avg. Area Number of Rooms\")\nax = sns.distplot(HousingDF['Avg. Area Number of Rooms'])","41328e9a":"# How Avg. Area Number of Bedrooms affects the Price\nplt.figure(figsize=(15,6))\nplt.title(\"Distribution of Avg. Area Number of Bedrooms\")\nax = sns.distplot(HousingDF['Avg. Area Number of Bedrooms'])","f513d66f":"# How Area Population affects the Price\nplt.figure(figsize=(15,6))\nplt.title(\"Distribution of Area Population\")\nax = sns.distplot(HousingDF['Area Population'])","0a658598":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score, mean_absolute_error\nfrom sklearn import metrics\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV , cross_val_score\n\n# Splitting the data into Training Set and Test Set\nx = HousingDF.drop(['Price'], axis = 1)\ny = HousingDF.Price\nx_train, x_test, y_train, y_test = train_test_split(x, y, \n                                                    test_size = 0.25,  \n                                                    random_state = 101)","6c6a9daf":"print(x_train)","4f477a29":"print(x_test)","b4259262":"print(y_train)","26b64e65":"print(y_test)","0b2551e7":"# Training\nlin_reg = LinearRegression()\nlin_reg.fit(x_train, y_train)\n\n# Predicting the Test Set Results\ny_pred = lin_reg.predict(x_test)\nprint( ' ')\n\n# Accuracy\naccuracies = cross_val_score(estimator = lin_reg, \n                             X = x_train, y = y_train, \n                             cv = 10)\nprint( accuracies)\nprint('Mean score: %0.3f'% accuracies.mean())\nprint('------------------------------------------------------')\n\n# Evaluation\nr2_lm = r2_score(y_test, y_pred)\nmae_lm = mean_absolute_error(y_test, y_pred)\nmse_lm = metrics.mean_squared_error(y_test, y_pred)\nrmse_lm = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\nprint(' R2       :%0.2f' % r2_lm)\nprint(' MAE      :%0.2f' % mae_lm)\nprint(' MSE      :%0.2f' % mse_lm)\nprint(' RMSE     :%0.2f' % rmse_lm)","99d12498":"# Training \npoly_reg = PolynomialFeatures(degree = 4)\nx_poly = poly_reg.fit_transform(x_train)\nreg_poly = LinearRegression()\nreg_poly.fit(x_poly, y_train)\n\n# Predicting the Test Set Results\ny_pred2 = reg_poly.predict(poly_reg.transform(x_test))\nprint( ' ')\n\n# Accuracy\naccuracies = cross_val_score(estimator = reg_poly, \n                             X = x_train, y = y_train, \n                             cv = 10)\nprint( accuracies)\nprint('Mean score: %0.3f'% accuracies.mean())\nprint('-------------------------------------------------------')\n\n# Evaluation\nr2_poly = r2_score(y_test, y_pred2)\nmae_poly = metrics.mean_absolute_error(y_test, y_pred2)\nmse_poly = metrics.mean_squared_error(y_test, y_pred2)\nrmse_poly = np.sqrt(metrics.mean_squared_error(y_test, y_pred2))\nprint(' R2       :%0.2f' % r2_poly)\nprint(' MAE      :%0.2f' % mae_poly)\nprint(' MSE      :%0.2f' % mse_poly)\nprint(' RMSE     :%0.2f' % rmse_poly)","ec16e2d7":"# Splitting\nx = HousingDF.drop(['Price'], axis = 1)\ny = HousingDF.Price\ny = y.values.reshape(-1, 1)\nx_train, x_test, y_train, y_test = train_test_split(x, y,\n                                                    test_size = 0.25, \n                                                    random_state = 101)\n\n# Feature Scaling\nsc_x = StandardScaler()\nsc_y = StandardScaler()\nx_train = sc_x.fit_transform(x_train)\ny_train = sc_y.fit_transform(y_train)\n\n# Training\nfrom sklearn.svm import SVR\nSVR_reg = SVR(kernel = 'rbf')\nSVR_reg.fit(x_train, y_train)\n\n# Predicting\ny_pred3 = sc_y.inverse_transform(SVR_reg.predict(sc_x.transform(x_test)))\n\n# Accuracy\naccuracies = cross_val_score(estimator = SVR_reg, X = x_train, \n                             y = y_train, cv = 10)\nprint( accuracies)\nprint('Mean score: %0.3f'% accuracies.mean())\nprint('---------------------------------------------------------')\n\n# Evaluation\nr2_svr = r2_score(y_test, y_pred3)\nmae_svr = mean_absolute_error(y_test, y_pred3)\nmse_svr = metrics.mean_squared_error(y_test, y_pred3)\nrmse_svr = np.sqrt(metrics.mean_squared_error(y_test, y_pred3))\nprint(' R2       :%0.2f' % r2_svr)\nprint(' MAE      :%0.2f' % mae_svr)\nprint(' MSE      :%0.2f' % mse_svr)\nprint(' RMSE     :%0.2f' % rmse_svr)","d0cff4cc":"# Splitting the data into training and test set\nx = HousingDF.drop(['Price'], axis = 1)\ny = HousingDF.Price\nx_train, x_test, y_train, y_test = train_test_split(x, y, \n                                                    test_size = 0.25, \n                                                    random_state = 101)\n\n# Training\nDTree_reg = DecisionTreeRegressor(random_state = 42)\nDTree_reg.fit(x_train, y_train)\n\n# Prediction\ny_pred4 = DTree_reg.predict(x_test)\n\n# Accuracy\naccuracies = cross_val_score(estimator = DTree_reg, \n                             X = x_train, y = y_train, \n                             cv = 10)\nprint( accuracies)\nprint('Mean score: %0.3f'% accuracies.mean())\nprint('-------------------------------------------------------')\n\n# Evaluation\nr2_DTree = r2_score(y_test, y_pred4)\nmae_DTree = mean_absolute_error(y_test, y_pred4)\nmse_DTree = metrics.mean_squared_error(y_test, y_pred4)\nrmse_DTree = np.sqrt(metrics.mean_squared_error(y_test, y_pred4))\nprint(' R2       :%0.2f' % r2_DTree)\nprint(' MAE      :%0.2f' % mae_DTree)\nprint(' MSE      :%0.2f' % mse_DTree)\nprint(' RMSE     :%0.2f' % rmse_DTree)","999bab9f":"# Training\nrf_reg = RandomForestRegressor()\nrf_reg.fit(x_train, y_train)\n\n# Prediction\ny_pred5 = rf_reg.predict(x_test)\n\n# Accuracy\naccuracies = cross_val_score(estimator = rf_reg, \n                             X = x_train, y = y_train, \n                             cv = 10)\nprint( accuracies)\nprint('Mean score: %0.3f'% accuracies.mean())\nprint('--------------------------------------------------------')\n\n# Evaluation\nr2_ranForrest = r2_score(y_test, y_pred5)\nmae_ranForrest = mean_absolute_error(y_test, y_pred5)\nmse_ranForrest = metrics.mean_squared_error(y_test, y_pred5)\nrmse_ranForrest = np.sqrt(metrics.mean_squared_error(y_test, y_pred5))\nprint(' R2       :%0.2f' % r2_ranForrest)\nprint(' MAE      :%0.2f' % mae_ranForrest)\nprint(' MSE      :%0.2f' % mse_ranForrest)\nprint(' RMSE     :%0.2f' % rmse_ranForrest)","f3acd08e":"models = pd.DataFrame({\n    'Model': ['Multiple Linear Regression', 'Polynomial Regression', \n              'Support Vector Regression', \n              'Decision Tree Regression', 'Random Forest Regression'],\n    'r-squared': [r2_lm, r2_poly, r2_svr, r2_DTree, r2_ranForrest],\n    'Mean Absolute Error'     :    [mae_lm, mae_poly, mae_svr, \n                                   mae_DTree, mae_ranForrest],\n    'Mean Squared Error'      :    [mse_lm, mse_poly, mse_svr, \n                                   mse_DTree , mse_ranForrest],\n    'Root Mean Squared Error' :    [rmse_lm, rmse_poly, rmse_svr,\n                                   rmse_DTree, rmse_ranForrest]\n    })\nmodels.sort_values(by='r-squared',ascending=False)","2d567736":"## DATA PREPROCESSING","5bedd702":"SUPPORT VECTOR REGRESSION MODEL","d7adb800":"## APPLYING MACHINE LEARNING ALGORITHMS","f78a78cf":"Avg. Area House Age VS Price","f401a70f":"## DATA COLLECTION","78cf080f":"## RESULTS","f787d022":"DECISION TREE REGRESSION MODEL","834669be":"Best model: Multiple Linear Regression Model for this scenario","ddb64de9":"Avg. Area Number of Rooms VS Price","6fc8e1a5":"Distribution of Price for different Features related to Price","fc5b81e3":"P- Value: The probability value that correlation between these two variables is statistically significant.\n<\/p>\nWhen the p-value if < 0.001: Strong evidence that correlation is significantt\n<\/p>\nWhen the p-value is < 0.005: Moderate evidence that correlation is significant\n<\/p>\nWhen the p-value is < 0.1: Weak evidence that correlation is significant\n<\/p>\nWhen the p-value is > 0.1: No evidence that correlation is significant","5bc6bbd6":"## CORRELATION BETWEEN NUMERICAL ATTRIBUTES","e69071b1":"Avg. Area Number of Bedrooms VS Price","06d66fbc":"MULTIPLE LINEAR REGRESSION MODEL","8075a424":"POLYNOMIAL REGRESSION MODEL","468a57d6":"Avg. Area Income VS Price","7cdc14c2":"## DESCRIPTIVE STATISTICS","4551fff7":"RANDOM FOREST REGRESSION MODEL","6e15464a":"## DATA ANALYSIS","a966d40c":"Area Population VS Price"}}