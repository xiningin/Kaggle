{"cell_type":{"3ffab047":"code","e1df73bb":"code","9755b665":"code","d3637355":"code","0176d200":"code","1f6caa54":"code","3a1f3b95":"code","8934ccea":"code","d3342b9d":"code","12f5b9ae":"code","bb0c64fd":"code","57bea9c5":"code","65d299a4":"code","4841efde":"code","3f8f3eaf":"code","d242a1bf":"code","756681fb":"code","0ae6ca9a":"code","3d265aea":"code","30cb613e":"code","b8a56024":"code","cf18f8c0":"code","cd444cea":"code","b41141aa":"code","a90836a9":"code","1b20e46e":"code","62b8b809":"code","eee67e1c":"markdown","b491c48a":"markdown","dbb38ea1":"markdown","deaa39aa":"markdown","671dd914":"markdown","9edc2cfb":"markdown","e2291930":"markdown","ac0ac0c1":"markdown","23a10ba9":"markdown","89e40e92":"markdown","392968a1":"markdown","d9d7b467":"markdown","68e9632d":"markdown"},"source":{"3ffab047":"!du -sh ..\/input\/*","e1df73bb":"import math\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline","9755b665":"df = pd.read_csv('..\/input\/train.csv')\ndf.head()","d3637355":"from IPython.display import Audio\nfile = '786ee883.wav'\npath = '..\/input\/audio_train\/audio_train\/'\nAudio(filename=path+file)","0176d200":"# Vamos a definir una funcion para extraer la duracion de un audio en segundos\nimport wave\n\ndef get_length(file):\n    audio = wave.open(path+file)\n    return audio.getnframes() \/ audio.getframerate()\n\nget_length(file)","1f6caa54":"# Vamos a procesar en paralelo la funcion en todos los archivos\nfrom joblib import Parallel, delayed\n\nwith Parallel(n_jobs=10, prefer='threads', verbose=1) as ex:\n    lengths = ex(delayed(get_length)(e) for e in df.fname)","3a1f3b95":"df['length'] = lengths\ndf.head()","8934ccea":"df = df.query('length <= 6').reset_index(drop=True)\nprint(df.shape)\ndf.head()","d3342b9d":"import librosa\n\ny, sr = librosa.load(path+file)\n# y : audio data\n# sr: sample rate\n\nplt.plot(y)\nplt.title(f'Sample rate = {sr}', size=18);","12f5b9ae":"# Ahora obtengamos la representacion MFCC\nmfcc = librosa.feature.mfcc(y, sr, n_mfcc=40)\nprint(mfcc.shape)\n\nplt.figure(figsize=(10,5))\nplt.imshow(mfcc, cmap='hot');","bb0c64fd":"# Definimos una funcion para obtener los features\ndef obtain_mfcc(file, features=40):\n    y, sr = librosa.load(path+file, res_type='kaiser_fast')\n    return librosa.feature.mfcc(y, sr, n_mfcc=features)","57bea9c5":"obtain_mfcc(file).shape","65d299a4":"mfcc.shape","4841efde":"def get_mfcc(file, n_mfcc=40, padding=None):\n    y, sr = librosa.load(path+file, res_type='kaiser_fast')\n    mfcc = librosa.feature.mfcc(y, sr, n_mfcc=n_mfcc)\n    if padding: mfcc = np.pad(mfcc, ((0, 0), (0, max(0, padding-mfcc.shape[1]))), 'constant')\n    return mfcc.astype(np.float32)\n\nmfcc = get_mfcc(file, padding=200)\nprint(mfcc.shape)\nplt.figure(figsize=(12,5))\nplt.imshow(mfcc, cmap='hot');","3f8f3eaf":"# Veamos cuanto padding necesitamos para el archivo de mayor duracion\nprint(get_mfcc(df.sort_values('length').fname.iloc[-1]).shape)","d242a1bf":"from functools import partial\n\nn_mfcc = 40\npadding = 259\nfun = partial(get_mfcc, n_mfcc=n_mfcc, padding=padding)\n\nwith Parallel(n_jobs=10, prefer='threads', verbose=1) as ex:\n    mfcc_data = ex(delayed(partial(fun))(e) for e in df.fname)\n    \n# Juntamos la data en un solo array y agregamos una dimension\nmfcc_data = np.stack(mfcc_data)[..., None]\nmfcc_data.shape","756681fb":"lbl2idx = {lbl:idx for idx,lbl in enumerate(df.label.unique())}\nidx2lbl = {idx:lbl for lbl,idx in lbl2idx.items()}\nn_categories = len(lbl2idx)\nlbl2idx","0ae6ca9a":"n_categories = len(lbl2idx)","3d265aea":"df['y'] = df.label.map(lbl2idx)\ndf.head()","30cb613e":"from sklearn.model_selection import train_test_split\n\nx_train, x_val, y_train, y_val = train_test_split(mfcc_data, df.y, test_size=0.2, random_state=42)\nx_train.shape, x_val.shape","b8a56024":"from keras.models import Model\nfrom keras.layers import Dense, Conv2D, BatchNormalization, Dropout, Input, GlobalAvgPool2D, GlobalMaxPool2D, concatenate\nfrom keras.optimizers import Adam, SGD\nimport keras.backend as K","cf18f8c0":"bs = 128\nlr = 0.003\n\nm_in = Input([n_mfcc, padding, 1])\nx = BatchNormalization()(m_in)\n\nlayers = [10, 20, 50, 100]\nfor i,l in enumerate(layers):\n    strides = 1 if i == 0 else (2,2)\n    x = Conv2D(l, 3, strides=strides, activation='relu', padding='same',\n               use_bias=False, kernel_initializer='he_uniform')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.02)(x)\n\nx_avg = GlobalAvgPool2D()(x)\nx_max = GlobalMaxPool2D()(x)\n\nx = concatenate([x_avg, x_max])\nx = Dense(1000, activation='relu', use_bias=False, kernel_initializer='he_uniform')(x)\nx = Dropout(0.2)(x)\nm_out = Dense(n_categories, activation='softmax')(x)\n\nmodel = Model(m_in, m_out)\nmodel.compile(Adam(lr), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","cd444cea":"log1 = model.fit(x_train, y_train, bs, 15, validation_data=[x_val, y_val])","b41141aa":"K.eval(model.optimizer.lr.assign(lr\/10))\nlog2 = model.fit(x_train, y_train, bs, 10, validation_data=[x_val, y_val])","a90836a9":"def show_results(*logs):\n    trn_loss, val_loss, trn_acc, val_acc = [], [], [], []\n    \n    for log in logs:\n        trn_loss += log.history['loss']\n        val_loss += log.history['val_loss']\n        trn_acc += log.history['acc']\n        val_acc += log.history['val_acc']\n    \n    fig, axes = plt.subplots(1, 2, figsize=(14,4))\n    ax1, ax2 = axes\n    ax1.plot(trn_loss, label='train')\n    ax1.plot(val_loss, label='validation')\n    ax1.set_xlabel('epoch'); ax1.set_ylabel('loss')\n    ax2.plot(trn_acc, label='train')\n    ax2.plot(val_acc, label='validation')\n    ax2.set_xlabel('epoch'); ax2.set_ylabel('accuracy')\n    for ax,title in zip(axes, ['Train', 'Accuracy']):\n        ax.set_title(title, size=14)\n        ax.legend()","1b20e46e":"show_results(log1, log2)","62b8b809":"sample = df.sample()\nsample_file = sample.fname.iloc[0]\nsample_label = sample.label.iloc[0]\n\nmfcc = get_mfcc(sample_file, n_mfcc, padding)[None, ..., None]\ny_ = model.predict(mfcc)\npred = idx2lbl[np.argmax(y_)]\n\nprint(f'True       = {sample_label}')\nprint(f'Prediction = {pred}')\nAudio(path + sample_file)","eee67e1c":"# Clasificaci\u00f3n de Audio","b491c48a":"# Train validation split","dbb38ea1":"# Modelo","deaa39aa":"Vamos a filtrar solo los audios que duran 6 segundos o menos.","671dd914":"# Veamos las categorias","9edc2cfb":"La segunda tama\u00f1o de la dimension (160) depende de la duracion del audio. Para poder tener los resultados del mismo tama\u00f1o, vamos a a\u00f1adir un offset a la funcion.","e2291930":"https:\/\/www.kaggle.com\/c\/freesound-audio-tagging","ac0ac0c1":"# Results","23a10ba9":"Necesitamos la matriz en esta forma (5843, 40, 259, 1), dado que vamos a utilizar convoluciones 2D, como si fuera una imagen.","89e40e92":"# MFCC (Mel-Frequency Cepstral Coefficients)","392968a1":"Detalles:\n- http:\/\/www.speech.cs.cmu.edu\/15-492\/slides\/03_mfcc.pdf\n- http:\/\/practicalcryptography.com\/miscellaneous\/machine-learning\/guide-mel-frequency-cepstral-coefficients-mfccs\n\nVamos a usar la libreria librosa: https:\/\/librosa.github.io\/librosa","d9d7b467":"# Preprocesando audio","68e9632d":"# Training"}}