{"cell_type":{"c168f246":"code","d9d4f758":"code","1f6cfdb5":"code","351b95d8":"code","c38ffc01":"code","8b97647e":"code","a3d88db4":"code","73933983":"code","6cfb5175":"code","759fada8":"code","e24b2959":"code","7b999c4d":"code","1f548af8":"code","24c13bfa":"code","4f96c600":"code","fef7f390":"code","4969d0ec":"code","3b8fde62":"code","59fee98e":"code","c1c61810":"code","b6195b6a":"code","c9999718":"code","6a40aaf5":"code","03dfda80":"code","0cb178d9":"code","fc8a011f":"code","f39f3194":"code","fdbabc2a":"code","094c109e":"code","67ec837c":"code","5ef8a309":"code","8ea11594":"code","cb223712":"code","1c48145a":"code","44f8dfab":"code","a8105050":"code","570c9b2c":"code","105cc455":"code","e3873746":"code","c2cc177c":"code","c384a036":"code","1f98604a":"code","05a5d5b8":"code","95928c4c":"code","d26f9ae3":"code","0b9943bf":"code","d40851c9":"code","bbdf85f0":"code","30de92ab":"code","f1b77e39":"code","f711e01f":"code","058cc67f":"code","9134fbf5":"code","b3bf37dd":"code","57b050c7":"code","9bbebac7":"code","b670fc98":"markdown","cba8b383":"markdown","86c74855":"markdown","f5cb4352":"markdown","03a8146c":"markdown","4c5b0373":"markdown","be081de8":"markdown","ca7ca5a0":"markdown","65498201":"markdown","2a69f00e":"markdown","65398443":"markdown","1d9da953":"markdown","371d9013":"markdown","28c8014c":"markdown","e1d0e736":"markdown","0a19e14f":"markdown","1321fb13":"markdown","d8fcae46":"markdown","323e0be2":"markdown","ac9ec541":"markdown","fb5290e2":"markdown","a5e0a35d":"markdown","950146a8":"markdown","66513eaa":"markdown","70ef117b":"markdown","13ac245d":"markdown","5f6657c6":"markdown","d6e39fc1":"markdown","60b15465":"markdown","6a918c90":"markdown","adca6ceb":"markdown","3d65eae5":"markdown","afaef002":"markdown","cc11c235":"markdown","0fec201c":"markdown","8cc1a5a9":"markdown","b57947e6":"markdown","d9883cc4":"markdown","f20d559e":"markdown"},"source":{"c168f246":"import pandas as pd\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nplt.style.use(\"Solarize_Light2\")\n%matplotlib inline\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import roc_curve, roc_auc_score, auc\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","d9d4f758":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","1f6cfdb5":"data = pd.read_csv('\/kaggle\/input\/employee-future-prediction\/Employee.csv')","351b95d8":"data","c38ffc01":"data.isnull().sum()","8b97647e":"data.nunique()","a3d88db4":"data.columns","73933983":"x_col = data.columns\nnum=0\nplt.figure(figsize=(15, 15))\nfor i in x_col:\n    \n    num += 1\n    plt.subplot(3, 3, num)\n    sns.countplot(data=data, x=i, hue='LeaveOrNot').set_title(i)\n    \n\nplt.show()","6cfb5175":"data.head()","759fada8":"col_bi = ['Gender', 'EverBenched']\nlabelencoder = LabelEncoder()\nfor i in col_bi:\n    data[i] = labelencoder.fit_transform(data[i])","e24b2959":"data = pd.get_dummies(data, columns=['Education', 'City', 'PaymentTier'])","7b999c4d":"data.JoiningYear = 2021 - data.JoiningYear","1f548af8":"data.groupby('LeaveOrNot').agg('mean').T","24c13bfa":"data_LeaveOrNot = data.groupby('LeaveOrNot').agg('mean')","4f96c600":"data_LeaveOrNot = data_LeaveOrNot.reset_index()","fef7f390":"x_col = list(data_LeaveOrNot.columns)\nx_col.remove('LeaveOrNot')","4969d0ec":"num=0\nplt.figure(figsize=(15, 15))\nfor i in x_col:\n    \n    num += 1\n    plt.subplot(3, 5, num)\n    sns.barplot(data=data_LeaveOrNot, y=i, x='LeaveOrNot').set_title(i)\n    \n\nplt.show()","3b8fde62":"data.columns","59fee98e":"data[data['Education_Bachelors'] == 1]\\\n    .groupby(['Gender', 'Education_Bachelors'])\\\n    [['PaymentTier_1', 'PaymentTier_2', 'PaymentTier_3']]\\\n    .agg(['count','mean'])","c1c61810":"data[data['Education_Masters'] == 1]\\\n    .groupby(['Gender', 'Education_Masters'])\\\n    [['PaymentTier_1', 'PaymentTier_2', 'PaymentTier_3']]\\\n    .agg(['count','mean'])","b6195b6a":"data[data['Education_PHD'] == 1]\\\n    .groupby(['Gender', 'Education_PHD'])\\\n    [['PaymentTier_1', 'PaymentTier_2', 'PaymentTier_3']]\\\n    .agg(['count','mean'])","c9999718":"data[(data['City_Bangalore'] == 1) & (data['Education_Bachelors'] == 1)]\\\n    .groupby(['Gender'])\\\n    [['PaymentTier_1', 'PaymentTier_2', 'PaymentTier_3']]\\\n    .agg(['mean']).plot.bar(subplots=True, figsize=(15, 5), layout=(1, 3), stacked=True)","6a40aaf5":"data[(data['City_Bangalore'] == 1) & (data['Education_Bachelors'] == 1)]\\\n    .groupby(['LeaveOrNot', 'Gender'])\\\n    [['PaymentTier_1', 'PaymentTier_2', 'PaymentTier_3']]\\\n    .agg(['mean'])","03dfda80":"data[(data['City_Bangalore'] == 1) & (data['Education_Masters'] == 1)]\\\n    .groupby(['Gender'])\\\n    [['PaymentTier_1', 'PaymentTier_2', 'PaymentTier_3']]\\\n    .agg(['mean']).plot.bar(subplots=True, figsize=(15, 5), layout=(1, 3), stacked=True)","0cb178d9":"data[(data['City_Bangalore'] == 1) & (data['Education_PHD'] == 1)]\\\n    .groupby(['Gender'])\\\n    [['PaymentTier_1', 'PaymentTier_2', 'PaymentTier_3']]\\\n    .agg(['mean']).plot.bar(subplots=True, figsize=(15, 15), layout=(3, 3), stacked=True)","fc8a011f":"data[(data['City_New Delhi'] == 1) & (data['Education_Bachelors'] == 1)]\\\n    .groupby(['Gender'])\\\n    [['PaymentTier_1', 'PaymentTier_2', 'PaymentTier_3']]\\\n    .agg(['mean']).plot.bar(subplots=True, figsize=(15, 15), layout=(3, 3), stacked=True)","f39f3194":"data[(data['City_New Delhi'] == 1) & (data['Education_Masters'] == 1)]\\\n    .groupby(['Gender'])\\\n    [['PaymentTier_1', 'PaymentTier_2', 'PaymentTier_3']]\\\n    .agg(['mean']).plot.bar(subplots=True, figsize=(15, 15), layout=(3, 3), stacked=True)","fdbabc2a":"data[(data['City_New Delhi'] == 1) & (data['Education_PHD'] == 1)]\\\n    .groupby(['Gender'])\\\n    [['PaymentTier_1', 'PaymentTier_2', 'PaymentTier_3']]\\\n    .agg(['mean']).plot.bar(subplots=True, figsize=(15, 15), layout=(3, 3), stacked=True)","094c109e":"data[(data['City_Pune'] == 1) & (data['Education_Bachelors'] == 1)]\\\n    .groupby(['Gender'])\\\n    [['PaymentTier_1', 'PaymentTier_2', 'PaymentTier_3']]\\\n    .agg(['mean']).plot.bar(subplots=True, figsize=(15, 15), layout=(3, 3), stacked=True)","67ec837c":"data[(data['City_Pune'] == 1) & (data['Education_Masters'] == 1)]\\\n    .groupby(['Gender'])\\\n    [['PaymentTier_1', 'PaymentTier_2', 'PaymentTier_3']]\\\n    .agg(['mean']).plot.bar(subplots=True, figsize=(15, 15), layout=(3, 3), stacked=True)","5ef8a309":"data[(data['City_Pune'] == 1) & (data['Education_PHD'] == 1)]\\\n    .groupby(['Gender'])\\\n    [['PaymentTier_1', 'PaymentTier_2', 'PaymentTier_3']]\\\n    .agg(['mean']).plot.bar(subplots=True, figsize=(15, 15), layout=(3, 3), stacked=True)","8ea11594":"data[(data['City_Pune'] == 1)]\\\n    .groupby(['LeaveOrNot', 'Gender'])\\\n    [['PaymentTier_1', 'PaymentTier_2', 'PaymentTier_3']]\\\n    .agg(['count', 'mean'])","cb223712":"data\\\n    .groupby(['LeaveOrNot', 'Gender'])\\\n    [['PaymentTier_1', 'PaymentTier_2', 'PaymentTier_3', 'ExperienceInCurrentDomain', 'JoiningYear']]\\\n    .agg(['mean'])","1c48145a":"data.groupby(['JoiningYear']).agg(\"mean\").T","44f8dfab":"data[(data['JoiningYear'] == 3) & data['LeaveOrNot'] == 1].groupby('JoiningYear').agg(['mean']).T","a8105050":"data.groupby('PaymentTier_3').agg(['mean']).T","570c9b2c":"data.corr()['LeaveOrNot']","105cc455":"data","e3873746":"X = data.drop(['LeaveOrNot'], axis=1)\ny = data['LeaveOrNot']\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)","c2cc177c":"numerical = ['JoiningYear', 'Age', 'ExperienceInCurrentDomain']","c384a036":"scaler = StandardScaler()\n\nx_train_scaler = scaler.fit_transform(x_train[numerical])\nx_test_scaler = scaler.transform(x_test[numerical])\n\nx_train[numerical] = x_train_scaler\nx_test[numerical] = x_test_scaler","1f98604a":"x_train","05a5d5b8":"def quality_report(actual, prediction):\n    print(\"Accuracy: {:.3f}\\nPrecision: {:.3f}\\nRecall: {:.3f}\\nf1_score: {:.3f}\\nRoc_auc: {:.3f}\".format(\n        accuracy_score(actual, prediction),\n        precision_score(actual, prediction),\n        recall_score(actual, prediction),\n        f1_score(actual, prediction),\n        roc_auc_score(actual, prediction)))","95928c4c":"def plot_features(clf):\n    feature_importances = clf.feature_importances_\n    pd.DataFrame({'features': x_train.columns,\n                                           'feature_importances': feature_importances})\\\n    .sort_values('feature_importances', ascending=False).plot.barh(x ='features', figsize=(10, 7))","d26f9ae3":"def data_features(clf):\n    feature_importances = clf.feature_importances_\n    return pd.DataFrame({'features': x_train.columns,\n                                           'feature_importances': feature_importances})\\\n    .sort_values('feature_importances', ascending=False)","0b9943bf":"def con_matrix(actual, prediction):\n    tn, fp, fn, tp = confusion_matrix(actual, prediction).ravel()\n    print('True Positive', tp, ' - employees who were correctly predicted to be fired')\n    print('False Negative', fn, ' - employees who were supposed to work but quit')\n    print('True Negative', tn, ' - employees who were supposed to work and are working')\n    print('False Positive', fp, ' - employees who were incorrectly predicted to be fired')","d40851c9":"rnd_clf = RandomForestClassifier(n_estimators=100, max_leaf_nodes=16, n_jobs=-1, random_state=42)\n\nrnd_clf.fit(x_train, y_train)\n\npredict_rnd = rnd_clf.predict(x_test)\n\nprint('\\nTest quality: \\n')\nquality_report(y_test, predict_rnd)\nprint('\\nThe confusion matrix : \\n')\ncon_matrix(y_test, predict_rnd)\n","bbdf85f0":"data_features(rnd_clf)","30de92ab":"plot_features(rnd_clf)","f1b77e39":"ex_clf = ExtraTreesClassifier(n_estimators=200, max_leaf_nodes=14, n_jobs=-1,  random_state=42)\n\nex_clf.fit(x_train, y_train)\n\npredict_ex = ex_clf.predict(x_test)\n\nprint('\\nTest quality: \\n')\nquality_report(y_test, predict_ex)\nprint('\\nThe confusion matrix : \\n')\ncon_matrix(y_test, predict_ex)","f711e01f":"data_features(ex_clf)","058cc67f":"plot_features(ex_clf)","9134fbf5":"gdc_clf = GradientBoostingClassifier(n_estimators=100, max_features='auto', max_depth = 4, random_state = 42) \n\ngdc_clf.fit(x_train, y_train)\n\npredict_gbc = gdc_clf.predict(x_test)\n\nprint('\\nTest quality: \\n')\nquality_report(y_test, predict_gbc)\nprint('\\nThe confusion matrix : \\n')\ncon_matrix(y_test, predict_gbc)","b3bf37dd":"data_features(gdc_clf)","57b050c7":"plot_features(gdc_clf)","9bbebac7":"y_predicted_prob_rnd = rnd_clf.predict_proba(x_test)\ny_predicted_prob_ex = ex_clf.predict_proba(x_test)\ny_predicted_prob_gdc = gdc_clf.predict_proba(x_test)\n\nfpr_rnd, tpr_rnd, thresholds_rnd = roc_curve(y_test, y_predicted_prob_rnd[:,1])\nfpr_ex, tpr_ex, thresholds_ex = roc_curve(y_test, y_predicted_prob_ex[:,1])\nfpr_gdc, tpr_gdc, thresholds_gdc = roc_curve(y_test, y_predicted_prob_gdc[:,1])\n\nplt.figure(figsize=(13,8))\nplt.plot(fpr_rnd, tpr_rnd, color='darkblue', label='RandomForest (area = %0.3f)' % auc(fpr_rnd, tpr_rnd))\nplt.plot(fpr_ex, tpr_ex, color='darkorange', label='ExtraTrees (area = %0.3f)' % auc(fpr_ex, tpr_ex))\nplt.plot(fpr_gdc, tpr_gdc, color='darkred', label='GradientBoosting (area = %0.3f)' % auc(fpr_gdc, tpr_gdc))\nplt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n\nplt.xlim([-0.01, 1.0])\nplt.ylim([-0.01, 1.05])\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n\nplt.title('ROC AUC: RandomForest = {:.3f} \/\/ ExtraTrees = {:.3f} \/\/ GradientBoosting = {:.3f}'\\\n          .format(roc_auc_score(y_test, predict_rnd),\n                  roc_auc_score(y_test, predict_ex),\n                  roc_auc_score(y_test, predict_gbc)))\nplt.legend(loc=\"lower right\", title_fontsize='xx-large')\n\nplt.show()","b670fc98":"If we look at the distribution of income levels, then in all cases women receive less than men with the same education\nand.\n\n**Let's compare wages in different cities.**","cba8b383":"In `Bangalore`, women receive a lower salary than men for `PHD` education. There are no women with average pay, but there are many with minimal.","86c74855":"****Now these histograms tell us more. Among those who quit (Leave Or Not == 1), a large proportion:**\n+ women || `Gender` == 0\n+ employees with an average salary level || `PaymentTier_2`\n+ those sitting on the bench || `EverBenched`\n+ with Education Masters || `Education_Masters`\n+ from the city of Pune || `City_Pune`","f5cb4352":"### City_New Delhi","03a8146c":"## JoiningYear & LeaveOrNot","4c5b0373":"`ExperienceInCurrentDomain` and `JoiningYear` are not affected by the fact of dismissal.\n\nWhat do we have? The fact of dismissal depends on `Gender` and `City`, because there is a high imbalance of `PaymentTier` wages among women in `Pune`. We also saw an imbalance in other cities, but it is much smaller. 491 women quit at Pune, 105 stayed to work, 148 men quit and 524 remained to work. I am sure these data will greatly affect our training.","be081de8":"No missing values","ca7ca5a0":"If we compare those who work and those who quit, compare the level of wages, then those who were dismissed received less.","65498201":"## ExtraTreesClassifier","2a69f00e":"In `Bangalore`, with `Masters` education, more men receive 1 level of salary, the remaining levels are equal.","65398443":"In the value of `JoiningYear` == 3 (ex 2018), there is a lot of `LeaveOrNot` == 1, as well as a large proportion of `PaymentTier_3` - almost 1.","1d9da953":"## GradientBoostingClassifier","371d9013":"In `New Delhi`, the minimum wage for women with the same education. Somewhere the same salaries.","28c8014c":"### City_Pune","e1d0e736":"# Importing Necessary Libraries","0a19e14f":"Convert categorical variables into single columns. We cannot simply number such signs as `Education`, even though `Bachelors`, `Masters`, `PHD` correspond well to 1, 2 and 3. But the average 2 is `Masters * 2` or `Bachelors + PHD`, and this is not the same thing.","1321fb13":"### City_Bangalore","d8fcae46":"Define the functions","323e0be2":"# EDA","ac9ec541":"## \u041e\u0431\u0437\u043e\u0440 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430 LeaveOrNot","fb5290e2":"# Data overview","a5e0a35d":"# ROC Curves and AUC","950146a8":"There are no strong correlations.","66513eaa":"# Split and Scaler","70ef117b":"What does our result say? If a company spends huge resources on training and adapting new employees, but there are not many such employees in the labor market, the company needs to know for sure that a person will leave, then our algorithm copes with this task perfectly and if it determines that a person will leave, then he will definitely leave. If it is important for us to find all those who can leave, then our model will cope poorly with this task, because the model has a low `recall`.","13ac245d":"## Female & Education","5f6657c6":"Also interesting observation, all those who quit received high wages, were hired in the last year in 2018 - `JoiningYear` == 3. 71% had `Bachelors`, 20% had `Education_Masters` and 8% had `Education_PHD`. And almost all of them received a high salary `PaymentTier_3`. Perhaps a new department was opened, and then it was reduced. Or it's just an anomaly in the data, but they will greatly affect our learning.","d6e39fc1":"In `Pune`, the salary of men is higher than the salary of women. The skew is clearly visible on the charts. In all other cities, it was clear that men received more than women, but there were also equal levels of wages.","60b15465":"How did I get the result `precision: 0.944` and `precision:0.974` without `stratify`?  \n  \nIf you are interested in learning only transformations on features and want to compare with your result, then the operations were as follows:\n\n+ using `LabelEncoder()` converted `Gender`, `EverBenched`  \n+ using `pd.get_dummies` converted `Education`, `City`, `PaymentTier`  \n+ from 2021 subtracted the `JoiningYear` value, updated the attribute.  \n  \nThen I divided it into `train` and `test`, using `stratify=y` so that the proportions of 1 and 0 in the target variable were the same, both in `train` and in `test`.\n\nThen I scaled the variables of `JoiningYear`, `Age` and `ExperienceInCurrentDomain`.\n\nTrained on `RandomForestClassifier`, `ExtraTreesClassifier` and `GradientBoostingClassifier`.\n\nUnfortunately, I have high `precision` and low `recall`. If you have a `recall` greater than 0.8, then please leave a link to your laptop in the comments - it will be interesting for me to see.","6a918c90":"I split the `PaymentTier` variable into 3 single columns, since it is a categorical variable, although there is a dependence on gradation. But we do not know for sure whether the difference between category `1` and `2` in the amount of the actual salary is 2 times or not.\n\nI have brought the variable `JoiningYear` to the current value by subtracting from 2021.","adca6ceb":"##  Features preprocessing","3d65eae5":"Those who quit had lower wages than those who work.","afaef002":"# Train the model","cc11c235":"Values of 1 are less than 0, then let's pay attention to the histograms where they are the same height or feature 1 is higher than feature 0:  \n  \n+ `Education` == Masters\n+ `JoiningYear` == 2018\n+ `City` == Pune\n+ `PaymentTier` == 2\n+ `Gender` == Female\n\nMaybe these values in the signs will play a role in our learning\n\n**Let's do the same, but only take the average value for all categories.**","0fec201c":"In `Bangalore`, when `Bachelors` are educated, women have a large share of the 1st and 2nd salary levels, therefore men are closer to the 3rd level.","8cc1a5a9":"**Distribution of mean values of features by 1 and 0. Let's make it a graph**","b57947e6":"Let's look at the number of unique values in each of the variables, let's group by `LeaveOrNot`","d9883cc4":"## RandomForestClassifier","f20d559e":"## City & Female & Education"}}