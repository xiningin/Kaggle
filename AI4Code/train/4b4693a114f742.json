{"cell_type":{"05dabef2":"code","a12cafe6":"code","937f18fb":"code","fe0e9efa":"code","99f0eb38":"code","7168b924":"code","3fbbf263":"code","af0db118":"code","d130ba02":"code","db9d37a6":"code","4a219e03":"code","f0f69708":"code","ca7fcc01":"code","2261d898":"code","b0f14db5":"code","8f330f56":"code","90785e8e":"code","387ca928":"markdown","87baa382":"markdown","a6e47819":"markdown","8e7a3eed":"markdown","1f568e5b":"markdown","3053b6d2":"markdown","410473ec":"markdown","23ba4492":"markdown","3252c8e6":"markdown","694ea207":"markdown","88ac853d":"markdown","4e994df3":"markdown","0175dc82":"markdown"},"source":{"05dabef2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport random\nimport os\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a12cafe6":"os.listdir(\"\/kaggle\/input\/tomato\/new plant diseases dataset(augmented)\/New Plant Diseases Dataset(Augmented)\")","937f18fb":"disease_list = os.listdir(\"\/kaggle\/input\/tomato\/new plant diseases dataset(augmented)\/New Plant Diseases Dataset(Augmented)\/train\")\ndisease_list","fe0e9efa":"train_dir = \"\/kaggle\/input\/tomato\/new plant diseases dataset(augmented)\/New Plant Diseases Dataset(Augmented)\/train\"\nvalidation_dir = \"\/kaggle\/input\/tomato\/new plant diseases dataset(augmented)\/New Plant Diseases Dataset(Augmented)\/valid\"","99f0eb38":"from tensorflow.keras.preprocessing.image import load_img\nfig = plt.figure(figsize=(12,9))\nfig.set_size_inches(18,18)\nplt.style.use(\"ggplot\")\ni = 0\nleaf = []\ndisease_name = []\nleaf_img = []\n\nfor disease in disease_list:\n    sample = random.sample(os.listdir(train_dir+\"\/\"+disease),1)\n    leaf.append(sample)\n    disease_name.append(disease)\n    \nfor image in leaf:\n    leaf_img.append(image[0]) \n    \ni=0    \nfor image in leaf_img:\n    img = load_img(train_dir+\"\/\"+disease_name[i]+\"\/\"+image)\n    plt.subplot(2,5,i+1)\n    plt.imshow(img)\n    plt.xlabel(disease_name[i])\n    #plt.yticks([])\n    i+=1\nplt.tight_layout()","7168b924":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input\nimage_height = 224\nimage_width = 224\ntr_datagen  = ImageDataGenerator(rescale = 1\/255.,\n                                zoom_range = 0.2,shear_range=0.2,\n                                horizontal_flip = True)#preprocessing_function = preprocess_input,,rotation_range = 0.2\nval_datagen = ImageDataGenerator(rescale= 1\/255.)\n\ntrain_datagenerator = tr_datagen.flow_from_directory(directory = train_dir,target_size=(image_width , image_height),\n                                                    class_mode =\"categorical\",batch_size=32)\n\nvalidation_datagenerator = val_datagen.flow_from_directory(directory =validation_dir,target_size=(image_width , image_height),\n                                                           class_mode=\"categorical\",batch_size=32)","3fbbf263":"from tensorflow.keras.applications.inception_v3 import InceptionV3\ninceptionv3 = InceptionV3(weights = 'imagenet',include_top = False,input_shape = (224,224,3))","af0db118":"for layers in inceptionv3.layers:\n    layers.trainable = False","d130ba02":"from tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Flatten,Dense,Dropout\nfrom tensorflow.keras.models import Model\n\nx = inceptionv3.output\nx = Flatten()(x)\n#x = Dense(128,activation = \"relu\")(x)\n#x = Dropout(0.5)(x)\npredictions = Dense(10,activation = \"softmax\")(x)\nmodel = Model(inputs = inceptionv3.input,outputs = predictions)","db9d37a6":"model.summary()","4a219e03":"model.compile(optimizer =\"adam\",loss = \"categorical_crossentropy\",metrics =[\"accuracy\"])\n\nhistory = model.fit_generator(generator = train_datagenerator,steps_per_epoch = len(train_datagenerator),\n                              validation_data = validation_datagenerator,validation_steps = len(validation_datagenerator),\n                             epochs = 10,verbose = 1)","f0f69708":"def plot_learning_curve(history,epochs):\n    epochs = np.arange(epochs+1)\n    plt.plot(history.history[\"accuracy\"])\n    plt.plot(history.history[\"val_accuracy\"])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend([\"Train\",\"val\"],loc = \"upper left\")\n    plt.show()\n    \n    plt.plot(history.history[\"loss\"])\n    plt.plot(history.history[\"val_loss\"])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend([\"Train\",\"val\"],loc = \"upper left\")\n    plt.show()","ca7fcc01":"plot_learning_curve(history,10)","2261d898":"disease = os.listdir(validation_dir)\nfor dis\n\nfor image in leaf_img:\n    img = load_img(train_dir+\"\/\"+disease_name[i]+\"\/\"+image)\n    plt.subplot(2,5,i+1)\n    plt.imshow(img)\n    plt.xlabel(disease_name[i])\n    #plt.yticks([])\n    i+=1\nplt.tight_layout()","b0f14db5":"model.evaluate(validation_datagenerator)","8f330f56":"from tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing import image\nfig = plt.figure(figsize=(16,9))\nfig.set_size_inches(20,20)\nplt.style.use(\"ggplot\")\ni = 0\nleaf = []\n#disease_name = []\nleaf_img = []\ndisease_name = os.listdir(validation_dir)\n#for disease in disease_list:\nsample = random.sample(os.listdir(validation_dir+\"\/\"+\"Tomato___healthy\"),10)\nleaf.append(sample)\n#disease_name.append(disease)\n    \nfor image in leaf[0]:\n    leaf_img.append(image) \n    \nfrom tensorflow.keras.preprocessing import image\ni=0    \nfor img in leaf_img:\n    img = load_img(validation_dir+\"\/\"+\"Tomato___healthy\"+\"\/\"+str(img),target_size=(224, 224))\n    \n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    #x = preprocess_input(x)\n    preds = model.predict(x)\n    index = np.argmax(preds)\n    \n    plt.subplot(2,5,i+1)\n    plt.imshow(img)\n    plt.xlabel(\"Actual Disease: {}\\n Predicted Disease : {}\".format(\"Tomato___healthy\",disease_name[index]))\n    #plt.yticks([])\n    i+=1\nplt.tight_layout()","90785e8e":"from tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing import image\nfig = plt.figure(figsize=(16,9))\nfig.set_size_inches(20,20)\nplt.style.use(\"ggplot\")\ni = 0\nleaf = []\ndisease_name = os.listdir(validation_dir)\nleaf_img = []\n\n#for disease in disease_list:\nsample = random.sample(os.listdir(validation_dir+\"\/\"+\"Tomato___Bacterial_spot\"),10)\nleaf.append(sample)\n#disease_name.append(disease)\n    \nfor image in leaf[0]:\n    leaf_img.append(image) #[0]\n    \nfrom tensorflow.keras.preprocessing import image\ni=0    \nfor img in leaf_img:\n    img = load_img(validation_dir+\"\/\"+\"Tomato___Bacterial_spot\"+\"\/\"+str(img),target_size=(224, 224))\n    #img_path = image.load_img(validation_dir+\"\/\"+disease_name[i]+\"\/\"+\"{}\".format(img), target_size=(224, 224))\n    \n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    #x = preprocess_input(x)\n    preds = model.predict(x)\n    index = np.argmax(preds)\n    \n    plt.subplot(2,5,i+1)\n    plt.imshow(img)\n    plt.xlabel(\"Actual Disease: {}\\n Predicted Disease : {}\".format(\"Tomato___Bacterial_spot\",disease_name[index]))\n    #plt.yticks([])\n    i+=1\nplt.tight_layout()","387ca928":"><h3>Data Augmentation<\/h3>","87baa382":"> <h4>2. Tomato___Bacterial_spot<\/h4>","a6e47819":"> <h4>InceptionV3 architecture:<\/h4>","8e7a3eed":">Importing Necessary Libraries","1f568e5b":"><h3>Learning Curve<\/h3>","3053b6d2":"> Here i'm gonna apply \"include_top = False\" because we're not gonna use the Fully connected layer of InceptionV3,because it is trained on 1000 classes & here our number of classes are 10,so by applying \"include_top = False\",it's gonna exclude Fully connected layer from the InceptionV3 model ","410473ec":"---\n\n<h1 style=\"text-align: center;font-size: 40px;\">Tomato Plant Disease Detection<\/h1>\n\n---","23ba4492":"\n<center><img src=\"https:\/\/camo.githubusercontent.com\/8b243e646673dd9234f39cf8bdd5da1c6f051fd9\/68747470733a2f2f7777772e50657465724d6f7373416d6c416c6c52657365617263682e636f6d2f6d656469612f696d616765732f7265706f7369746f726965732f5472616e736665722d4c6561726e696e672e6a7067\n\"><\/center>\n\n---","3252c8e6":"><h3> Here i'm gonna apply Transfer Learning Model Inception V3<\/h3>","694ea207":"><h3>Let's see some of the images<\/h3>","88ac853d":">All Transfer learning models are already trained so we don't need to train those layers again,we can train it again,but it takes a lot of time,so we are not going to train those layers again,that's why i'm going to set \"layers.trainable = False\"","4e994df3":">## Let's compare our result for specefic Diseases\n>> 1.Tomato___healthy","0175dc82":"---\n\n<h1 style=\"text-align: center;font-size: 20px;\">Thanks for Reading<\/h1>\n\n---"}}