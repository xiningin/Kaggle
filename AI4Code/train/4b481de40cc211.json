{"cell_type":{"00f897a3":"code","5950fbaf":"code","b62dec56":"code","278c9003":"code","d19f7cee":"code","364e6238":"code","e085f950":"code","d034bed3":"code","98269637":"code","e107885e":"code","d092fe18":"code","0197e61c":"code","c78fee3a":"code","34abaccb":"code","fcd0f090":"code","ccf7562c":"code","24105aeb":"code","e1c90a59":"markdown","7d9143df":"markdown","0e76c3ed":"markdown","673b7ab3":"markdown","de83391c":"markdown","2c82bd2c":"markdown","be64ec1e":"markdown","01bb905a":"markdown","65c71a0e":"markdown","1c307411":"markdown","958c24fe":"markdown","41771af1":"markdown","5ce2a4d7":"markdown","7a6d4b58":"markdown","d5324f33":"markdown","7027e726":"markdown","4405fd0a":"markdown","2dd3e771":"markdown","446ab229":"markdown","da372a83":"markdown","e59ff24b":"markdown","15b6929e":"markdown","cf43df41":"markdown","e49a120c":"markdown","5d1187fc":"markdown","eb2f5d6a":"markdown","6774ec84":"markdown","24c31478":"markdown"},"source":{"00f897a3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5950fbaf":"# importing all neccessary libraries for Exploratory Data Analysis and visualization\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.offline as py\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objects as go\nimport plotly.express as px\niris = pd.read_csv(\"..\/input\/iris\/Iris.csv\")\n","b62dec56":"#getting idea of dataset\niris.head(2),iris.shape,iris.dtypes","278c9003":"iris.drop('Id',axis=1,inplace=True)\niris.columns  # to check that the column 'Id' is Dropped","d19f7cee":"labels=iris['Species'].unique()\nvalues=iris['Species'].value_counts()\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.3)])\npy.iplot(fig)","364e6238":"sns.pairplot(iris,hue='Species')","e085f950":"\nfrom plotly.subplots import make_subplots\nfig = make_subplots(\n    rows=2, cols=2)\nfig.add_trace(go.Violin(x=iris['Species'],y=iris['PetalWidthCm'],box_visible=True,meanline_visible=True,name='PetalWidth'),row=1,col=1)\nfig.add_trace(go.Violin(x=iris['Species'],y=iris['PetalLengthCm'],box_visible=True,meanline_visible=True,name='PetalLength'),row=1,col=2)\nfig.add_trace(go.Violin(x=iris['Species'],y=iris['SepalWidthCm'],box_visible=True,meanline_visible=True,name='SepalWidth'),row=2,col=1)\nfig.add_trace(go.Violin(x=iris['Species'],y=iris['SepalLengthCm'],box_visible=True,meanline_visible=True,name='SepalLength'),row=2,col=2)\nfig.update_layout(height=600, width=1000, title_text=\"Length and Width variation of Sepals and Petals according to the species\")\npy.iplot(fig)","d034bed3":"#heatmap\nsns.heatmap(iris.corr(),annot=True)","98269637":"#importing neccessary libraries and fuctions for machine learning\nfrom sklearn.model_selection import train_test_split\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import svm\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nimport warnings  \nwarnings.filterwarnings('ignore')","e107885e":"#splitting the data into training data and testing data\nx=iris.drop('Species',axis=1)\ny=iris['Species']\nx_train, x_test, y_train, y_test = train_test_split(x, y)","d092fe18":"lr_model = LogisticRegression() #select the algorithm\nlr_model.fit(x_train,y_train) # we train the algorithm with the training data and the training output\nlr_predict = lr_model.predict(x_test) #now we pass the testing data to the trained algorithm\nprint('Accuracy obtained using Logistic Regression - ',round(accuracy_score(lr_predict,y_test)*100,2),'%') #now we check the accuracy of the algorithm. \n#we pass the predicted output by the model and the actual output","0197e61c":"knn_model = KNeighborsClassifier()\nknn_model.fit(x_train,y_train)\nknn_predict=knn_model.predict(x_test)\nprint('Accuracy obtained using K Nearest Neighbours (KNN) - ',round(accuracy_score(knn_predict,y_test)*100,2),'%')","c78fee3a":"dt_model=DecisionTreeClassifier()\ndt_model.fit(x_train,y_train)\ndt_predict=dt_model.predict(x_test)\nprint('Accuracy obtained using Decision Tree - ',round(accuracy_score(dt_predict,y_test)*100,2),'%')","34abaccb":"xgb_model = XGBClassifier()\nxgb_model.fit(x_train, y_train)\npredict=xgb_model.predict(x_test)\naccuracy_score(predict,y_test)\nprint('Accuracy obtained using XGBoost - ',round(accuracy_score(predict,y_test)*100,2),'%')","fcd0f090":"svc_model = svm.SVC()\nsvc_model.fit(x_train,y_train)\nsvc_predict=svc_model.predict(x_test)\nprint('Accuracy obtained using Support Vector Classifier (SVC) -',round(accuracy_score(svc_predict,y_test)*100,2),'%')","ccf7562c":"x1=iris.drop(['Species','PetalWidthCm'],axis=1)  # dropping PetalWidthCm also\ny1=iris['Species'] \nx1_train, x1_test, y1_train, y1_test = train_test_split(x1, y1)","24105aeb":"xgb_model = XGBClassifier()\nxgb_model.fit(x1_train, y1_train)\npredict=xgb_model.predict(x1_test)\naccuracy_score(predict,y1_test)\nprint('Accuracy obtained using XGBoost - ',round(accuracy_score(predict,y1_test)*100,2),'%')","e1c90a59":"# IRIS Dataset\n\nThis is perhaps the best known dataset to be found in the pattern recognition literature. The data set contains 3 classes of 50 instances each, where each class refers to a type of iris flower. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other.\nLet dive deep into Analysis of data to predict the type of Iris flower based on the length and width of sepals and petals.\n\n\n![](http:\/\/s3.amazonaws.com\/assets.datacamp.com\/blog_assets\/Machine+Learning+R\/iris-machinelearning.png)\n","7d9143df":"**Reading Dataset features like : shape of dataset, features(columns) of dataset and data type of each feature.**","0e76c3ed":"***From context, it's clear that out of Classification and Regression, this is a classification problem.***\n\n***As we have to predict based on the independent features that which type\/class of Iris flower it is.***\n","673b7ab3":"Now firstly, we need to check the relation between various independant columns and also with the dependant one.\n\nTip : Instead of building multiple individual graphs between 2 variables it's better to go for pairplot.\nTo know more about Pairplot [click here](http:\/\/seaborn.pydata.org\/generated\/seaborn.pairplot.html)","de83391c":"***Insights:* **\nWe have five features - Id,Sepal Length, Sepal Width, Petal Length, and Petal Width and one target field : Species.One column (Id) is of no use for us. So now we will drop that column permanently(using inplace= True).\nSo now we have to predict the species (dependant column) based on the values of other 4 columns (independant columns).\nAlso by checking Datatypes of columns, we find out that there is no need to change the datatype of the numerical columns.","2c82bd2c":"# Classification Algorithms we'll cover here:","be64ec1e":"From Pairplot, we can see that :\n* Iris-setosa is linearly distinguished from other two kinds of iris flower(Versicolor and Virginica).","01bb905a":"# Let's start with predicting of type of Iris flower.","65c71a0e":"# XGBoost","1c307411":"Now to check that IRIS dataset is a balanced dataset or an imbalanced dataset,We are plotting piechart to see distribution among various classes of dataset.\n\n*To know more about Balanced and Imbalanced Datasets [click here](http:\/\/medium.com\/analytics-vidhya\/what-is-balance-and-imbalance-dataset-89e8d7f46bc5).*","958c24fe":"# Observations:","41771af1":"**From above Pie chart it's clear that our dataset is *perfectly balanced dataset***","5ce2a4d7":"# Decision Tree","7a6d4b58":"**Hello Kagglers!!!** \n\nThis notebook deals with Exploratory Data Analysis and Visualization using Matplotlib,Seaborn and Plotly. \nAlong with this we build model with various classification alogorithms and finally check accuracy of each model.\n\nIf you are a complete begginer or want a crisp understanding of EDA and advanced Visualizations, stay tuned!!!\n\nPress \"**Fork**\" at the top-right of this screen to run this notebook yourself and to try experimenting.\n\n*If this notebook to be useful, **Please Upvote!!!***\n","d5324f33":"**Here instead of using  separately Histogram for Probability distribution function and Boxplot for statistical data based on the minimum, first quartile, median, third quartile, and maximum we can use Violin plot alone because it represents all the features that are represented by both histogram and boxplot separately.**\n\nHover mouse over plot to get more info.\n\n***The thinner part denotes that there is less density whereas the fatter part conveys higher density.***\n\n*To explore more about Violin plots [click here](http:\/\/https:\/\/towardsdatascience.com\/violin-plots-explained-fb1d115e023d).*","7027e726":"# Let's Begin Exploratory Data Analysis","4405fd0a":"# K Nearest Neighbours (KNN)","2dd3e771":"**Here, We tried by dropping Petal Width feature from the dataset and then applied XGBoost. You can see that accuracy is almost same and even for other algorithms or by dropping Petal Length you find that accuracy will be approximately same with +\/-(2-3%) variation due to very high correlation between both parameters.**","446ab229":"**Now we'll try building by dropping one of the petal length or petal width as they are highly correlated to each other(refer to heatmap above) and check the accuracy**","da372a83":"**Now let us see how the length and width of petals and sepals vary according to the species**","e59ff24b":"**1. Iris Dataset is a Balanced dataset.**\n\n**2. Iris Setosa is clearly differentiable from Virginica and Versicolor.**\n**3. Petal Length and Petal Width are highly correlated to each other.**\n\n**4. By dropping one of Petal Length or Petal Width, prediction accuracy is not affected much.**\n\n**5. Support Vector Classifier (SVC) performed best for classification amongst other algorithms of Classification.**\n\n\n\n\n.","15b6929e":"# Logistic Regression","cf43df41":"*  Logistic Regression\n* K Nearest Neighbours (KNN)\n* Decision Tree\n* Support Vector Classifier (SVC)\n* XGBoost","e49a120c":"# Support Vector Classifier (SVC)","5d1187fc":"# This Notebook demonstrates Exploratory Data Analysis and Visualization along with Prediction on Iris Dataset","eb2f5d6a":"**Let's see correlation between each column of dataset by plotting HeatMap.**","6774ec84":"**From Above Heatmap it is clear that Petal length and Petal Width are highly correlated to each other.** \n\nSo both features contribute approximately same in prediction of Species.\n\nSo, we will try in both the ways i.e. by taking both columns and by dropping one of them to check how much they affect the accuracy of prediction.","24c31478":"\n\n**Thus we have just implemented almost every classification algorithm and along with EDA and visualization.**\n\nAlthough this dataset is small and basic one with no missing values or categorical fields, so I'm not able to cover major portion of Data Cleansing,Feature Engineering,Feature Selection or Feature scaling and will try to do these same in my other notebooks.\n\nI hope the notebook was useful to you to get started with Machine Learning\/ Data Analysis.\n\n***If find this notebook useful, Please Upvote!!!(It really motivates :)***\n\n*Thank You!!!*\n"}}