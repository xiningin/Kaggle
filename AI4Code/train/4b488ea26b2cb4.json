{"cell_type":{"d508a621":"code","5625eab2":"code","288f4a71":"code","d429b7b9":"code","3dba9a77":"code","506b1617":"code","f649cd63":"code","f04ced0d":"code","8d301662":"code","64c8ec80":"code","b549caad":"code","fabe2049":"code","47d100e1":"code","f70e87be":"code","082af97a":"code","95228681":"code","b2d20e2b":"code","5b1912f4":"code","61b25856":"code","e0c4d3ce":"markdown","07d9c56c":"markdown","1cdf8c59":"markdown","13d2c64e":"markdown","725c0f10":"markdown","cf680261":"markdown","586c7072":"markdown","a168af42":"markdown","d9a1d76d":"markdown","afbb2539":"markdown","56fcd992":"markdown","2644d262":"markdown","a2cbb7b0":"markdown","7b9db89a":"markdown","9842081b":"markdown","65a9ad93":"markdown","1d875d44":"markdown","33e67dba":"markdown","c85e2205":"markdown","25c848dc":"markdown","a5dc97da":"markdown","8e5b9efb":"markdown","8eecb9f3":"markdown","10600f95":"markdown","f8246973":"markdown","00c042e4":"markdown","926638e1":"markdown","b202f308":"markdown","edc0ddc7":"markdown"},"source":{"d508a621":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\n\nimport time\nimport os \nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.preprocessing import RobustScaler\n\n#import optuna # for new tests\n\ntrain = pd.read_csv('..\/input\/ventilator-pressure-prediction\/train.csv')\ntest = pd.read_csv('..\/input\/ventilator-pressure-prediction\/test.csv')\nsubmission = pd.read_csv('..\/input\/ventilator-pressure-prediction\/sample_submission.csv')","5625eab2":"train.head(2)","288f4a71":"'''\n# detect and init the tpu\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n'''\n\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n  # Restrict TensorFlow to only use the first GPU\n    try:\n        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n        print(tf.test.gpu_device_name())\n    except RuntimeError as e:\n        # Visible devices must be set at program startup\n        print(e)\n","d429b7b9":"init = time.time()\n\ndef add_features(df):\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    \n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    \n    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n    df = df.fillna(0)\n    \n    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n    \n    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n    \n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    \n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    \n    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n    df['cross']= df['u_in']*df['u_out']\n    df['cross2']= df['time_step']*df['u_out']\n    \n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df = pd.get_dummies(df)\n    return df\n\ntrain = add_features(train)\ntest = add_features(test)\n\nprint('Elapsed time (s): ', time.time() - init)","3dba9a77":"train.describe()","506b1617":"init = time.time()\ntrain_corr_mat = train.dropna(how='any').corr()\nprint('Elapsed time (s): ', time.time() - init)","f649cd63":"train_corr_mat = train.drop(['breath_id__u_out__max'], axis=1).corr() # the breath_id__u_out__max corr has NaN\n#train_corr_mat","f04ced0d":"g = sns.clustermap(train_corr_mat.sort_values(by='pressure'), figsize=(15, 10), cmap='Greens',\n                   vmin=-1, vmax=1, annot=False, row_cluster=False,\n                   dendrogram_ratio=(.05, .2), cbar_pos=(0, 0.4, 0.01, 0.31))","8d301662":"targets = train[['pressure']].to_numpy().reshape(-1, 80)\ntrain.drop(['pressure', 'id', 'breath_id'], axis=1, inplace=True)\ntest = test.drop(['id', 'breath_id'], axis=1)\n\nRS = RobustScaler()\ntrain = RS.fit_transform(train)\ntest = RS.transform(test)\n\ntrain = train.reshape(-1, 80, train.shape[-1])\ntest = test.reshape(-1, 80, train.shape[-1])","64c8ec80":"#idx_len = round(0.80*len(train))\nidx_len = round(0.80*len(train))\nX_train, X_valid = train[0:idx_len], train[idx_len:]\ny_train, y_valid = targets[0:idx_len], targets[idx_len:]","b549caad":"#EPOCH = 300\n#BATCH_SIZE = 128\n### => score ~ 0.18\n\n#EPOCH = 500\n#BATCH_SIZE = 64 \n### => score ~ 0.30\n\nEPOCH = 500\nBATCH_SIZE = 256\n\nlr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, verbose=1)\nes = EarlyStopping(monitor=\"val_loss\", patience=50, verbose=1, mode=\"min\", restore_best_weights=True)","fabe2049":"init = time.time()\n\n'''\nwith tpu_strategy.scope():\n    \n    model = keras.models.Sequential([\n    keras.layers.Input(shape=train.shape[-2:]),    \n    keras.layers.Bidirectional(keras.layers.LSTM(512, return_sequences=True)),\n    keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True)),\n    keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)),\n    keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True)),\n    keras.layers.Dense(64, activation='selu'),\n    keras.layers.Dense(1),\n])\n\n    model.compile(optimizer=\"adam\", loss=\"mae\")\n\n    history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), \n                        epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr, es])\n'''\n\n    \nmodel = keras.models.Sequential([\nkeras.layers.Input(shape=train.shape[-2:]),    \nkeras.layers.Bidirectional(keras.layers.LSTM(512, return_sequences=True)),\nkeras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True)),\nkeras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)),\nkeras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True)),\nkeras.layers.Dense(64, activation='selu'),\nkeras.layers.Dense(1),\n])\n\nmodel.compile(optimizer=\"adam\", loss=\"mae\")\n\nhistory = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), \n                    epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr, es])\n\nprint('Elapsed time (min): ', (time.time() - init)\/60)","47d100e1":"plt.figure(figsize=(15,3))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.show()","f70e87be":"model.save('bidirectional_lstm_model[500epochs_gpu_bacth256].h5')","082af97a":"#model_cpu = tf.keras.models.load_model('lstm_model.h5')","95228681":"model.summary()\n#model_cpu.summary()","b2d20e2b":"#test_pred = model_cpu.predict(test, batch_size=BATCH_SIZE)\ntest_pred = model.predict(test, batch_size=BATCH_SIZE)","5b1912f4":"# save for submission\nsubmission['pressure'] = test_pred.squeeze().reshape(-1, 1).squeeze()\nsubmission.to_csv('bidirectional_lstm_model[500epochs_gpu_bacth256].csv', index=False)","61b25856":"submission.head()","e0c4d3ce":"## Data description\n\n![image.png](attachment:image.png)","07d9c56c":"### Training model","1cdf8c59":"### Note:\n\n#### Maybe we can consider review the new features based on the original matrix correlation of training set and the above.","13d2c64e":"<a id='3'><\/a>\n\n# 2. Next steps:\n\n* Create a hyperparameter search and use Optuna to automate hyperparameter search.\n\n\n* Review actual features and add new features based on correlation matrix.\n\n\n* Test new models and architeture of LSTM for GPUs.\n\n","725c0f10":"## Define Model LSTM or Bidirectional LSTM","cf680261":"## Prediction","586c7072":"### Split dataset","a168af42":"### Load trainde model","d9a1d76d":"<a id='2'><\/a>\n\n# 1. PREDICTION","afbb2539":"***init: 21-out-2021***","56fcd992":"#### Drop NaN of Coorelation matrix","2644d262":"### Refs:\n\nensemble-folds-with-median-0-153.ipynb\n\n","a2cbb7b0":"_______\n\n## Summary\n\n\n#### [The problem](#0)\n\n#### [1. Prediction](#2)\n\n#### [2. Next steps](#3)\n\n_______","7b9db89a":"### Define some hyperparameters","9842081b":"_________","65a9ad93":"## Define target and Scale dataset","1d875d44":"![image.png](attachment:image.png)\n\nhttps:\/\/www.kaggle.com\/c\/ventilator-pressure-prediction\/data","33e67dba":"### Model summary ","c85e2205":"### Set GPU (or TPU)","25c848dc":"## Submission","a5dc97da":"### Save trained model","8e5b9efb":"### Links:\n#### 1. Open-source ventilator (Software + Hardware): https:\/\/www.peoplesvent.org\/en\/latest\/\nWritten entirely in Python 3.7\n\n#### 2. Artificial bellows test lung via a respiratory circuit.: https:\/\/www.ingmarmed.com\/product\/quicklung\/\nVentilator performance verification: combine with any flow\/volume\/ pressure analyzer for a complete ventilator testing system\n\n#### 3. Open Source Ventilator Project System Integration Test:\nhttps:\/\/www.youtube.com\/watch?v=KhgUCOhOCNM\n\n_________\n\n### <font color='green'>Hint from video of link 3:<\/font>\n\n<u>Some usual configurations:<\/u>\n\nRespRate: 10, 15, 30*\n\nI:E Ratio 1:2; 1:3; 1:4\n\nI:E Ratio 2:1; 1:1; 1:2","8eecb9f3":"<a id='0'><\/a>\n\n# The Problem\n","10600f95":"![image-2.png](attachment:image-2.png)","f8246973":"### Correlation Matrix","00c042e4":"### References:\n\n* i-am-groot-tpu-war.ipynb (https:\/\/www.kaggle.com\/shivansh002\/i-am-groot-tpu-war)\n\n* deep-learning-starter-simple-lstm.ipynb (https:\/\/www.kaggle.com\/theoviel\/deep-learning-starter-simple-lstm)\n\n\n\n* ensemble-folds-with-median-0-153.ipynb (https:\/\/www.kaggle.com\/manabendrarout\/single-bi-lstm-model-pressure-predict-gpu-infer)\n\n\n\n* ensemble-folds-with-median-0-153.ipynb (https:\/\/www.kaggle.com\/cdeotte\/ensemble-folds-with-median-0-153)\n\n\n\n* finetune-of-tensorflow-bidirectional-lstm.ipynb (https:\/\/www.kaggle.com\/tenffe\/finetune-of-tensorflow-bidirectional-lstm)","926638e1":"________","b202f308":"## Add New Features","edc0ddc7":"### Google Brain - Ventilator Pressure Prediction\n\n> Current simulators are trained as an ensemble, where each model simulates a single lung setting. However, lungs and their attributes form a continuous space, so a parametric approach must be explored that would consider the differences in patient lungs. \n\n\n> In this competition, you\u2019ll simulate a ventilator connected to a sedated patient's lung. The best submissions will take lung attributes compliance and resistance into account.\n\n\n#### Timeline:\n\n* September 22, 2021 - Start Date.\n\n* October 27, 2021 - Entry Deadline. You must accept the competition rules before this date in order to compete.\n\n* October 27, 2021 - Team Merger Deadline. This is the last day participants may join or merge teams.\n\n* November 3, 2021 - Final Submission Deadline.\n\n\nhttps:\/\/www.kaggle.com\/c\/ventilator-pressure-prediction\/overview\n\n\n_________"}}