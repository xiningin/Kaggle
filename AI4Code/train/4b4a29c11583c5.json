{"cell_type":{"1817f61e":"code","bd4527f1":"code","5f2b8d6d":"code","3cd9f0a2":"code","28c23e46":"code","d164f023":"code","4ca82bfc":"code","725e02eb":"code","f06c9036":"code","b9611f00":"code","ca82e3a5":"code","1692eaf8":"code","d62771ba":"code","a1ba2ab7":"code","55719942":"code","eb70c2ae":"code","7bc54cf6":"code","c1699fd4":"code","48a7177c":"code","c1a9fced":"markdown","1428f461":"markdown","308a314c":"markdown","bfa27c63":"markdown","b9ac510a":"markdown"},"source":{"1817f61e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n\n#sklearn imports\nfrom sklearn import (datasets, metrics, model_selection as skms, naive_bayes, neighbors, linear_model)\n\n#warning off\nimport warnings\n\nwarnings.filterwarnings('ignore')\nnp.random.seed(42)\n\npd.options.display.float_format = '{:20,.4f}'.format","bd4527f1":"diabetis = datasets.load_diabetes()\ntts = skms.train_test_split(diabetis.data, diabetis.target, test_size = .30)\n(diabetis_train_ftrs, diabetis_test_ftrs,\ndiabetis_train_tgt, diabetis_test_tgt) = tts","5f2b8d6d":"diabetis_df = pd.DataFrame(diabetis.data, columns=diabetis.feature_names)\ndiabetis_df['target'] = diabetis.target\ndiabetis_df.head()","3cd9f0a2":"sns.pairplot(diabetis_df[['age', 'sex', 'bmi', 'bp', 's1']], \n             height=1.5,\n             hue='sex',\n             plot_kws={'alpha':.2})","28c23e46":"rolls = np.array([1,6,6,6,2,3,4,3,1])\nnp.mean(rolls) # middle part\n","d164f023":"np.median(rolls)","4ca82bfc":"distance = np.array([4.0,2.0, 2.0])\ncloseness = 1.0\/distance\ncloseness","725e02eb":"weights = closeness\/ closeness.sum()\nweights","f06c9036":"neigh_values = np.array([79.1, 88.3, 101.2])\nnp.dot(neigh_values, weights)","b9611f00":"knn = neighbors.KNeighborsRegressor(n_neighbors=3)\nfit = knn.fit(diabetis_train_ftrs, diabetis_train_tgt)\npreds = knn.predict(diabetis_test_ftrs)\n\n\nmetrics.mean_squared_error(diabetis_test_tgt,preds)","ca82e3a5":"#range\n\ndiabetis_df['target'].max() - diabetis_df['target'].min()","1692eaf8":"np.sqrt(3764.2305764411026)","d62771ba":"def axis_helper(ax, lims):\n    'clean up axes'\n    ax.set_xlim(lims); ax.set_xticks([])\n    ax.set_ylim(lims); ax.set_yticks([])\n    ax.set_aspect('equal')","a1ba2ab7":"def process(D,model, ax):\n    x ,y = D[:,0], D[:,1]\n    m,b = model # y = mx + b\n    \n    axis_helper(ax, (0,8))\n    \n    #draws the data\n    ax.plot(x,y,'ro')\n    \n    #drawing the line\n    helper_xs = np.array([0,8])\n    helper_line  = m * helper_xs + b\n    ax.plot(helper_xs, helper_line, color = 'y')\n    \n    #calculate the errors \n    predictions = m*x + b\n    errors = y - predictions\n    \n    #plot\n    ax.values(x, predictions, y)\n    \n    #return the results\n    sse = np.dot(errors, errors) # will give sum of sqared errors\n    return (errors, errors.sum(), sse,np.sqrt(sse))","55719942":"D = np.array([[3,5],\n              [4,2]])\n\n#create very simple horizantal lines\n# y = mx + b if m =0 , it's horizantal\nbs = np.array([1,2,3,3.5,4,5])\nhorizontal_lines  = np.c_[np.zeros_like(bs), bs]\nhorizontal_lines","eb70c2ae":"import matplotlib\ncol_labels = ['Raw Errors', 'Sum', 'SSE', 'TotalDist']\nfig = matplotlib.pyplot.figure()\nfig, axes = fig.add_subplot(1,6)\n\nrecords = [process(D, mod, ax) for mod, ax in zip(horizontal_lines, \n                                                 axes.flat)]\ndf = pd.DataFrame.from_records(records, columns=col_labels)","7bc54cf6":"df","c1699fd4":"line_mb = np.array([[1,1],\n                    [1,1],\n                    [1,2],\n                    [-1,8],\n                    [-3, 14]])\n\ncol_labels = ['Raw Errors', 'Sum', 'SSE', 'TotalDist']\nfig, axes = plt.subplots(1,5,figsize=(10,5))\nrecords = [process(D, mod, ax) for mod, ax in zip(line_mb, \n                                                 axes.flat)]\ndf = pd.DataFrame.from_records(records, columns=col_labels)","48a7177c":"lr = linear_model.LinearRegression()\nfit = lr.fit(diabetis_train_ftrs, diabetis_train_tgt)\npreds = fit.predict(diabetis_test_ftrs)\n\nresult = metrics.mean_squared_error(diabetis_test_tgt, preds)\nresult, np.sqrt(result)","c1a9fced":"# Diabetis Datasets","1428f461":"# So What is regression? and What is the differences with classification?\n\n--> Regression is trying to predict the outcome \n--> It's Numeric\n--> Can be multiple answers\n--> Is it going to be rain tomorrow? If yes, what are the chances ? 60% , 10% , 40% ?\n\nSo, the difference with Classification\n\n --> Always used in label\n \n --> like is a image of dog or cat?\n \n --> only two valuse --> like 0 or 1 \n \n --> zero being false and 1 being true","308a314c":"# What is the center of set of data","bfa27c63":"# kNN Regression","b9ac510a":"# linear Regression Model"}}