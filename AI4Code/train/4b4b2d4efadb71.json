{"cell_type":{"39bedcd4":"code","dff9be02":"code","849c7f0d":"code","a8f16fd7":"code","c444d4a9":"code","aa08455f":"code","435d5351":"code","0387aa05":"markdown","a73b673f":"markdown","f50bfeac":"markdown","8e7c7fb2":"markdown","b5961226":"markdown","a54a7c3c":"markdown","a4e0d2ac":"markdown","75881505":"markdown"},"source":{"39bedcd4":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport os, ast, glob\nfrom PIL import Image, ImageFont, ImageDraw\nimport hashlib\nfrom io import BytesIO\n%matplotlib inline","dff9be02":"LABEL='Wheat'\ndf=pd.read_csv(\"\/kaggle\/input\/global-wheat-detection\/train.csv\")\ndf.bbox = df.bbox.apply(ast.literal_eval)\nfor i in range(len(df)):\n    df.bbox.iloc[i][2]=df.bbox.iloc[i][0]+df.bbox.iloc[i][2]\n    df.bbox.iloc[i][3]=df.bbox.iloc[i][1]+df.bbox.iloc[i][3]\ndf.sample(5)","849c7f0d":"def create_tf_example(imagedf, longest_edge=1024):  \n    fname = '\/kaggle\/input\/global-wheat-detection\/train\/'+imagedf.image_id.iloc[0]+'.jpg'\n    filename=fname.split('\/')[-1] # exclude path\n    img = Image.open(fname, \"r\")\n    # resize image if larger that longest edge while keeping aspect ratio\n    if max(img.size) > longest_edge:\n        img.thumbnail((longest_edge, longest_edge), Image.ANTIALIAS)\n    height = img.size[1] # Image height\n    width = img.size[0] # Image width\n    buf= BytesIO()\n    img.save(buf, format= 'JPEG') # encode to jpeg in memory\n    encoded_image_data= buf.getvalue()\n    image_format = b'jpeg'\n    source_id = filename.split('.')[0] # must be unique\n    # A hash of the image is used in some frameworks\n    key = hashlib.sha256(encoded_image_data).hexdigest()   \n    # object bounding boxes \n    boxes = np.array(imagedf['bbox'].tolist())\n    xmins = boxes[:,0]\/width # List of normalized left x coordinates in bounding box (1 per box)\n    ymins = boxes[:,1]\/height # List of normalized top y coordinates in bounding box (1 per box)\n    xmaxs = boxes[:,2]\/width # List of normalized right x coordinates in bounding box\n    ymaxs = boxes[:,3]\/height # List of normalized bottom y coordinates in bounding box\n    # List of string class name & id of bounding box (1 per box)\n    object_cnt = len(imagedf)\n    classes_text = []\n    classes = []\n    cname = LABEL\n    for i in range(object_cnt):\n        classes_text.append(cname.encode())\n        classes.append(1)\n    # unused features from Open Image \n    depiction = np.zeros(object_cnt, dtype=int)\n    group_of = np.zeros(object_cnt, dtype=int)\n    occluded = np.zeros(object_cnt, dtype=int) #also Pascal VOC\n    truncated = np.zeros(object_cnt, dtype=int) # also Pascal VOC\n    # Pascal VOC\n    view_text = []\n    for i in range(object_cnt):\n        view_text.append('frontal'.encode())\n    difficult = np.zeros(object_cnt, dtype=int)\n\n    tf_record = tf.train.Example(features=tf.train.Features(feature={\n        'image\/height': tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n        'image\/width': tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n        'image\/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename.encode()])),\n        'image\/source_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[source_id.encode()])),\n        'image\/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[encoded_image_data])),\n        'image\/key\/sha256': tf.train.Feature(bytes_list=tf.train.BytesList(value=[key.encode()])),\n        'image\/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_format])),\n        'image\/object\/bbox\/xmin': tf.train.Feature(float_list=tf.train.FloatList(value=xmins)),\n        'image\/object\/bbox\/xmax': tf.train.Feature(float_list=tf.train.FloatList(value=xmaxs)),\n        'image\/object\/bbox\/ymin': tf.train.Feature(float_list=tf.train.FloatList(value=ymins)),\n        'image\/object\/bbox\/ymax': tf.train.Feature(float_list=tf.train.FloatList(value=ymaxs)),\n        'image\/object\/class\/text': tf.train.Feature(bytes_list=tf.train.BytesList(value=classes_text)),\n        'image\/object\/class\/label': tf.train.Feature(int64_list=tf.train.Int64List(value=classes)),\n        'image\/object\/depiction': tf.train.Feature(int64_list=tf.train.Int64List(value=depiction)),\n        'image\/object\/group_of': tf.train.Feature(int64_list=tf.train.Int64List(value=group_of)),\n        'image\/object\/occluded': tf.train.Feature(int64_list=tf.train.Int64List(value=occluded)),\n        'image\/object\/truncated': tf.train.Feature(int64_list=tf.train.Int64List(value=truncated)),\n        'image\/object\/difficult': tf.train.Feature(int64_list=tf.train.Int64List(value=difficult)),\n        'image\/object\/view': tf.train.Feature(bytes_list=tf.train.BytesList(value=view_text))\n    }))\n    return tf_record","a8f16fd7":"labels=[LABEL]\npbfile=open('.\/labels.pbtxt', 'w') \nfor i in range (len(labels)): \n    pbfile.write('item {{\\n id: {}\\n name:\\'{}\\'\\n}}\\n\\n'.format(i+1, labels[i])) \npbfile.close()","c444d4a9":"def bbox(img, xmin, ymin, xmax, ymax, color, width):\n    draw = ImageDraw.Draw(img)\n    xres, yres = img.size[0], img.size[1]\n    box = np.multiply([xmin, ymin, xmax, ymax], [xres, yres, xres, yres]).astype(int).tolist()\n    draw.rectangle(box, outline=color, width=width)\n           \ndef plot_img(img, axes, xmin, ymin, xmax, ymax, classes, class_label, by):\n    for i in range(len(xmin)):\n        #color=hex_to_rgb(colors[class_label[i]-1])\n        color='#e81123'\n        bbox(img, xmin[i], ymin[i], xmax[i], ymax[i], color, 5)\n    plt.setp(axes, xticks=[], yticks=[])\n    axes.set_title(by)\n    plt.imshow(img)","aa08455f":"%%time\nimport contextlib2\n\nfilelist = glob.glob('\/kaggle\/input\/global-wheat-detection\/train\/*')\n\ndef open_sharded_tfrecords(exit_stack, base_path, num_shards):\n    tf_record_output_filenames = [\n        '{}-{:04d}-of-{:04d}.tfrecord'.format(base_path, idx, num_shards)\n        for idx in range(num_shards)\n        ]\n    tfrecords = [\n        exit_stack.enter_context(tf.io.TFRecordWriter(file_name))\n        for file_name in tf_record_output_filenames\n    ]\n    return tfrecords\n\nnum_shards=20\noutput_filebase='.\/Wheat'\n\n# A context2.ExitStack is used to automatically close all the TFRecords created \nwith contextlib2.ExitStack() as tf_record_close_stack:\n    output_tfrecords = open_sharded_tfrecords(tf_record_close_stack, output_filebase, num_shards)\n    for i in range(len(filelist)):\n        fid = filelist[i].replace('\/kaggle\/input\/global-wheat-detection\/train\/','').split('.')[0]\n        ldf=df[df.image_id == fid].reset_index()\n        if len(ldf) > 0:\n            tf_record = create_tf_example(ldf, longest_edge=1024)\n            output_shard_index = i % num_shards\n            output_tfrecords[output_shard_index].write(tf_record.SerializeToString())","435d5351":"fname='.\/Wheat-0005-of-0020.tfrecord'\ndataset3 = tf.data.TFRecordDataset(fname)\nfig = plt.figure(figsize=(12,18))\nidx=1\nfor raw_record in dataset3.take(6):\n    axes = fig.add_subplot(3, 2, idx)\n    example = tf.train.Example()\n    example.ParseFromString(raw_record.numpy())\n    xmin=example.features.feature['image\/object\/bbox\/xmin'].float_list.value[:]\n    xmax=example.features.feature['image\/object\/bbox\/xmax'].float_list.value[:]\n    ymin=example.features.feature['image\/object\/bbox\/ymin'].float_list.value[:]\n    ymax=example.features.feature['image\/object\/bbox\/ymax'].float_list.value[:]\n    classes=example.features.feature['image\/object\/class\/text'].bytes_list.value[:]\n    class_label=example.features.feature['image\/object\/class\/label'].int64_list.value[:]\n    img_encoded=example.features.feature['image\/encoded'].bytes_list.value[0]\n    img = Image.open(BytesIO(img_encoded))\n    plot_img(img, axes, xmin, ymin, xmax, ymax, classes, class_label, '')\n    idx=idx+1","0387aa05":"## TFRecords creation\nThe function below creates TFRecords with all the bells and whistles.","a73b673f":"## Read annotation data","f50bfeac":"## Create TFRecords\nSo we will convert the Global Wheat Detection dataset to TFRecords, for use in TensorFlow-based models.","8e7c7fb2":"Yup - everything OK!","b5961226":"## Check the output\nThe last step is to check a few records to see that everything went OK:","a54a7c3c":"## Helper functions\nA few helper functions are defined below for visualizing images.","a4e0d2ac":"## Create sharded TFRecords\nWe create a sharded dataset here, 20 shards will give a granularity of 5% for train\/validate split.","75881505":"We also need a labels.pbtxt file with the labels (only one)."}}