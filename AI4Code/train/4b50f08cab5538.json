{"cell_type":{"49b65a19":"code","0fd4542c":"code","c8ba142d":"code","6b794b4d":"code","a34902d2":"code","518a6e80":"code","ac539758":"code","a003a7b7":"code","99be56bd":"code","a09ddb9b":"code","039d0ea7":"code","5e05f014":"code","e5afc8de":"code","56ebc249":"code","e8626861":"code","2074916e":"code","a5665af6":"code","e0e93a6e":"code","50e03e3c":"code","2ff54ad2":"code","3d553c92":"code","a1371a66":"code","8d46dee2":"markdown","46e1a644":"markdown","02edfd38":"markdown","286c21cc":"markdown","fd2462f7":"markdown","b1f80f01":"markdown"},"source":{"49b65a19":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0fd4542c":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","c8ba142d":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","6b794b4d":"women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)","a34902d2":"men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived:\", rate_men)","518a6e80":"# Use XGboost for prediction\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error","ac539758":"# Show All features\ntrain_data.columns","a003a7b7":"# Select features that are important\n# Is name important for surivial?\nselected_features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\nX_train, y_train = train_data.loc[:, selected_features], train_data['Survived']\nX_test = test_data.loc[:, selected_features]","99be56bd":"# Check if each col have nan value\n# In face XGBosst work on it automatically\nfor i in range(7):\n    print(X_train.iloc[:, i].isnull().values.any())","a09ddb9b":"# Many Age field is missing\nX_train.loc[X_train.loc[:, 'Age'].isnull()]","039d0ea7":"X_train.loc[X_train.loc[:, 'Embarked'].isnull()]","5e05f014":"# Create new DataFrame with copy\nimport copy\nX_train_mod = copy.deepcopy(X_train)\nX_test_mod = copy.deepcopy(X_test)","e5afc8de":"# Treat missing data as one category\nX_train_mod.at[X_train_mod.loc[:, 'Embarked'].isnull(), 'Embarked'] = 'N'\nX_test_mod.at[X_test_mod.loc[:, 'Embarked'].isnull(), 'Embarked'] = 'N'\nX_train_mod.loc[[61, 829], :]","56ebc249":"# Encoding for Categorical data\n# Is this good encoding method?\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\n# Different kind of encoder\nlabel_encoder = LabelEncoder()\nonehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n\nfeature = label_encoder.fit_transform(X_train_mod.loc[:, 'Sex'])\nprint(feature)\nprint(X_train_mod.loc[:, 'Sex'].values)","e8626861":"# One hot Encoding for Categorical data\n# Is this good encoding method?\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\n# Different kind of encoder\nlabel_encoder = LabelEncoder()\nonehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n\nfeature = onehot_encoder.fit_transform(X_train_mod.loc[:, ['Embarked']])\nprint(onehot_encoder.categories_)\n\nprint(feature[55:65, :])\nprint(X_train_mod.loc[55:64, 'Embarked'].values)","2074916e":"cat_labels = ['Pclass', 'Sex', 'Embarked']\nencoded_X_train = None\nencoded_X_test = None\n\nfor label in X_train_mod.columns:\n    if label not in cat_labels:\n        feature_train = X_train_mod[label].values.reshape(-1, 1)\n        feature_test = X_test_mod[label].values.reshape(-1, 1)\n    else:\n        onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n        onehot_encoder = onehot_encoder.fit(X_train_mod[[label]])\n        \n        feature_train = onehot_encoder.transform(X_train_mod[[label]])\n        feature_test = onehot_encoder.transform(X_test_mod[[label]])\n        \n    if encoded_X_train is None:\n        encoded_X_train = feature_train\n        encoded_X_test = feature_test\n    else:\n        encoded_X_train = np.concatenate((encoded_X_train, feature_train), axis=1)\n        encoded_X_test = np.concatenate((encoded_X_test, feature_test), axis=1)\n\n# Note the one hot encoding here expand the number of col\nprint(encoded_X_train[:5, :])\nprint(X_train_mod.head())\nprint(encoded_X_test[:5, :])\nprint(X_test_mod.head())","a5665af6":"print(encoded_X_train.shape)\nprint(encoded_X_test.shape)","e0e93a6e":"# Let us transform y value as well\n# One hot or just ordinary integer?\n\nlabel_encoder = LabelEncoder()\nlabel_encoder = label_encoder.fit(y_train)\nencoded_y_train = label_encoder.transform(y_train)\n\nencoded_y_train","50e03e3c":"# Wait... we still have missing data in Age field\n\nfrom xgboost import XGBClassifier\n\nmodel = XGBClassifier()\nmodel.fit(encoded_X_train, encoded_y_train)","2ff54ad2":"from sklearn.metrics import accuracy_score\n\ny_pred = model.predict(encoded_X_train)\naccuracy = accuracy_score(encoded_y_train, y_pred)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","3d553c92":"# One line implementation\n# What about Pclass?\npd.get_dummies(X_train_mod)","a1371a66":"print(encoded_X_test.shape)\nprint(encoded_X_train.shape)\npredictions = model.predict(encoded_X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","8d46dee2":"# Now we can build the model using our transformed data","46e1a644":"# Some data Cleaning (is it good or bad?)","02edfd38":"# Decide which features are important to the prediction","286c21cc":"# Create a dataframe that XGBoost can read and process","fd2462f7":"# Save the result","b1f80f01":"# Check training set"}}