{"cell_type":{"a05d53e6":"code","9e5a07bc":"code","9d53327d":"code","34370e3d":"code","70ba45f9":"code","3e2c7b13":"code","8fd3c01b":"code","f565ded7":"code","8a43ded7":"code","32a22f22":"code","1346668c":"code","974133cd":"code","4662f14a":"code","5b2d85af":"code","a549f8e7":"code","b953cf2f":"code","3d9399dc":"code","b8741e59":"code","e0790fbb":"code","f14ca899":"code","bb21492f":"code","916fc037":"code","ad68a39c":"code","726c7f4e":"code","0f1cc981":"code","af36664d":"code","15660e46":"markdown","41f735df":"markdown","2a139935":"markdown","7f1ded9e":"markdown","b2267b43":"markdown","3ba57e78":"markdown","7008220f":"markdown","2458b426":"markdown","2d64dad6":"markdown","5d45c54a":"markdown","d8858f4b":"markdown","2f19932a":"markdown","76e88940":"markdown","8c747d3d":"markdown","e8b387dc":"markdown"},"source":{"a05d53e6":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-pastel')\n\n# Misc\nfrom sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import confusion_matrix\n\n# Models\nimport xgboost as xgb\nfrom sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, VotingClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.pipeline import Pipeline\nimport lightgbm\nfrom lightgbm import LGBMClassifier\n\n# aesthetics\nfrom colorama import Fore, Back, Style\ng_ = Fore.GREEN\nm_ = Fore.MAGENTA\nsr_ = Style.RESET_ALL","9e5a07bc":"# colnames = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeF', 'Age', 'Outcome']\n# df = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv', names = colnames, header = None)\n\ndf = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')\ndf","9d53327d":"df.isnull().values.any()","34370e3d":"df.dtypes","70ba45f9":"df.hist(figsize = (12,8));","3e2c7b13":"class CFG:\n    debug = False\n    n_folds = 15\n    seeds = [85, 12]","8fd3c01b":"if CFG.debug:\n    df = df.head(300)","f565ded7":"features_names = [c for c in df.columns if c != 'Outcome']\ntarget_name = 'Outcome'\n\nfeatures = df.loc[:, features_names]\ntarget = df.loc[:, target_name]","8a43ded7":"scaler = MinMaxScaler() # RobustScaler()\n\n# Scale only features. do not scale target\nscaler.fit(features)\nfeatures_scaled = scaler.transform(features)","32a22f22":"# Creating variables to store the results\nall_models = np.array([])\nall_scores = np.array([])","1346668c":"def get_preds_etr(X = features_scaled, y = np.array(target),\n                  nfolds = CFG.n_folds,\n                  n_estimators = 100):\n    \n    seeds_avg = list()\n    etr_models = []\n\n    for seed in CFG.seeds:\n      scores = list()\n      \n      kfold = KFold(n_splits = CFG.n_folds, shuffle=True, random_state = seed)\n\n      for k, (train_idx,valid_idx) in enumerate(kfold.split(X, y)):\n\n          model = ExtraTreesClassifier(n_estimators = n_estimators, random_state = seed)\n\n          X_train, y_train = X[train_idx], y[train_idx]\n          X_valid, y_valid = X[valid_idx], y[valid_idx]\n\n          prediction = np.zeros((X_valid.shape[0]))\n\n          model.fit(X_train, y_train) # train\n          etr_models.append(model)\n          prediction = model.predict(X_valid) # predict\n\n          score = round(accuracy_score(prediction, y_valid), 4)\n          print(f'Seed {seed} | Fold {k} | Accuracy score: {score}')\n          scores.append(score)\n          \n      print(f\"{m_}\\nMean Accuracy for seed {seed} : {round(np.mean(scores), 4)}{sr_}\\n\")\n\n      seeds_avg.append(round(np.mean(scores), 4))\n\n    print(f\"{g_}Average score: {round(np.mean(seeds_avg), 4)}{sr_}\")\n\n    return round(np.mean(seeds_avg), 4), etr_models, y_valid, np.array(prediction), X_train, y_train # for the last fold","974133cd":"%%time\nscore_etr, etr_models, y_valid, y_pred, X_train, y_train = get_preds_etr()","4662f14a":"def get_preds_rf(X = features_scaled, y = np.array(target),\n                 nfolds = CFG.n_folds,\n                 n_estimators = 100,\n                 max_depth = 5):\n    \n    seeds_avg = list()\n    rf_models = []\n\n    for seed in CFG.seeds:\n      scores = list()\n      \n      kfold = KFold(n_splits = CFG.n_folds, shuffle=True, random_state = seed)\n\n      for k, (train_idx,valid_idx) in enumerate(kfold.split(X, y)):\n\n          model = RandomForestClassifier(n_estimators = n_estimators, max_depth = max_depth, random_state = seed)\n\n          X_train, y_train = X[train_idx], y[train_idx]\n          X_valid, y_valid = X[valid_idx], y[valid_idx]\n\n          prediction = np.zeros((X_valid.shape[0]))\n          \n          model.fit(X_train, y_train) # train\n          rf_models.append(model)\n          prediction = model.predict(X_valid) # predict\n\n          score = round(accuracy_score(prediction, y_valid), 4)\n          print(f'Seed {seed} | Fold {k} | Accuracy score: {score}')\n          scores.append(score)\n          \n      print(f\"{m_}\\nMean Accuracy for seed {seed} : {round(np.mean(scores), 4)}{sr_}\\n\")\n\n      seeds_avg.append(round(np.mean(scores), 4))\n\n    print(f\"{g_}Average score: {round(np.mean(seeds_avg), 4)}{sr_}\")\n\n    return round(np.mean(seeds_avg), 4), rf_models, y_valid, np.array(prediction) # y_valid e y_pred for the last fold","5b2d85af":"%%time\nscore_rf, rf_models, y_valid, y_pred = get_preds_rf(n_estimators = 100,\n                                                    max_depth = 15)","a549f8e7":"def get_preds_xgb(X = features_scaled, y = np.array(target),\n                  nfolds = CFG.n_folds,\n                  n_estimators = 100):\n    \n    seeds_avg = list()\n    xgb_models = []\n\n    for seed in CFG.seeds:\n      scores = list()\n      \n      kfold = KFold(n_splits = CFG.n_folds, shuffle=True, random_state = seed)\n\n      for k, (train_idx,valid_idx) in enumerate(kfold.split(X, y)):\n\n          model = xgb.XGBClassifier(n_estimators = n_estimators,\n                                    random_state = seed) # use tree_method='gpu_hist' to enable gpu\n\n          X_train, y_train = X[train_idx], y[train_idx]\n          X_valid, y_valid = X[valid_idx], y[valid_idx]\n\n          prediction = np.zeros((X_valid.shape[0]))\n          \n          model.fit(X_train, y_train) # train\n          xgb_models.append(model)\n          prediction = model.predict(X_valid) # predict\n\n          score = round(accuracy_score(prediction, y_valid), 4)\n          print(f'Seed {seed} | Fold {k} | Accuracy score: {score}')\n          scores.append(score)\n          \n      print(f\"{m_}\\nMean Accuracy for seed {seed} : {round(np.mean(scores), 4)}{sr_}\\n\")\n\n      seeds_avg.append(round(np.mean(scores), 4))\n\n    print(f\"{g_}Average score: {round(np.mean(seeds_avg), 4)}{sr_}\")\n\n    return round(np.mean(seeds_avg), 4), xgb_models, X_valid, y_valid, np.array(prediction) # y_valid e y_pred for the last fold","b953cf2f":"%%time\nscore_xgb, xgb_models, X_valid, y_valid, y_pred = get_preds_xgb()","3d9399dc":"features_importances = xgb_models[-1].feature_importances_ # for model trained on the last fold\nargsort = np.argsort(features_importances)\nfeatures_importances_sorted = features_importances[argsort]\n\nfeature_names = features.columns\nfeatures_sorted = feature_names[argsort]\n\n# plot feature importances\nplt.figure(figsize = (8, 10))\nplt.barh(features_sorted, features_importances_sorted)\nplt.title(\"Feature Importances\");","b8741e59":"def get_preds_lgbm(X = features_scaled, y = np.array(target),\n                   nfolds = CFG.n_folds,\n                   n_estimators = 100):\n    \n    seeds_avg = list()\n    lgbm_models = []\n\n    for seed in CFG.seeds:\n      scores = list()\n      \n      kfold = KFold(n_splits = CFG.n_folds, shuffle=True, random_state = seed)\n\n      for k, (train_idx,valid_idx) in enumerate(kfold.split(X, y)):\n\n          model = LGBMClassifier(random_state = seed)\n\n          X_train, y_train = X[train_idx], y[train_idx]\n          X_valid, y_valid = X[valid_idx], y[valid_idx]\n\n          prediction = np.zeros((X_valid.shape[0]))\n          \n          model.fit(X_train, y_train) # train\n          lgbm_models.append(model)\n          prediction = model.predict(X_valid) # predict\n\n          score = round(accuracy_score(prediction, y_valid), 4)\n          print(f'Seed {seed} | Fold {k} | Accuracy score: {score}')\n          scores.append(score)\n          \n      print(f\"{m_}\\nMean Accuracy for seed {seed} : {round(np.mean(scores), 4)}{sr_}\\n\")\n\n      seeds_avg.append(round(np.mean(scores), 4))\n\n    print(f\"{g_}Average score: {round(np.mean(seeds_avg), 4)}{sr_}\")\n\n    return round(np.mean(seeds_avg), 4), lgbm_models, X_valid, y_valid, np.array(prediction) # y_valid e y_pred for the last fold","e0790fbb":"%%time\nscore_lgbm, lgbm_models, X_valid, y_valid, y_pred = get_preds_lgbm()","f14ca899":"ens = VotingClassifier(estimators=[('etr', etr_models[-1]),\n                                   ('rf', rf_models[-1]),\n                                   ('xgb', xgb_models[-1]),\n                                   ('lgbm', lgbm_models[-1])],\n                       voting = 'hard') # 'hard', 'soft'\n\nens.fit(X_train, y_train) # last fold models","bb21492f":"# ExtraTrees last fold score\ny_pred = 0\ny_pred = etr_models[-1].predict(X_valid)\n\nscore = 0\nscore = round(accuracy_score(y_pred, y_valid), 4)\n\nprint('ETR score: ', score)\n\n# updating results\nall_models = np.append(all_models, \"ETR\")\nall_scores = np.append(all_scores, score)\n\ncm = confusion_matrix(y_pred, y_valid)\ncm","916fc037":"# Random Forest last fold score\ny_pred = 0\ny_pred = rf_models[-1].predict(X_valid)\n\nscore = 0\nscore = round(accuracy_score(y_pred, y_valid), 4)\n\nprint('RF score: ', score)\n\n# updating results\nall_models = np.append(all_models, \"RF\")\nall_scores = np.append(all_scores, score)\n\ncm = confusion_matrix(y_pred, y_valid)\ncm","ad68a39c":"# XGB last fold score\ny_pred = 0\ny_pred = xgb_models[-1].predict(X_valid)\n\nscore = 0\nscore = round(accuracy_score(y_pred, y_valid), 4)\n\nprint('XGB score: ', score)\n\n# updating results\nall_models = np.append(all_models, \"XGB\")\nall_scores = np.append(all_scores, score)\n\ncm = confusion_matrix(y_pred, y_valid)\ncm","726c7f4e":"# LGBM last fold score\ny_pred = 0\ny_pred = lgbm_models[-1].predict(X_valid)\n\nscore = 0\nscore = round(accuracy_score(y_pred, y_valid), 4)\n\nprint('LGBM score: ', score)\n\n# updating results\nall_models = np.append(all_models, \"LGBM\")\nall_scores = np.append(all_scores, score)\n\ncm = confusion_matrix(y_pred, y_valid)\ncm","0f1cc981":"# ensemble last fold score\ny_pred = 0\ny_pred = ens.predict(X_valid)\n\nscore = 0\nscore = round(accuracy_score(y_pred, y_valid), 4)\n\nprint('ENS score: ', score)\n\n# updating results\nall_models = np.append(all_models, \"ENS\")\nall_scores = np.append(all_scores, score)\n\ncm = confusion_matrix(y_pred, y_valid)\ncm","af36664d":"names = all_models\nvalues = all_scores\n\nplt.figure(figsize = (8, 5))\nbar1 = plt.bar(np.arange(len(values)), values)\nplt.xticks(range(len(names)), names)\nplt.title('Last fold: Model x Accuracy')\nplt.ylim(0, 1)\nplt.axhline(y = np.array(values).mean(), color = 'r', linestyle = 'dashed', label = 'mean value')\nfor rect in bar1:\n    height = rect.get_height()\n    plt.text(rect.get_x() + rect.get_width()\/2.0, height, '%.4f' % float(height), ha='center', va='bottom', fontsize = 12, fontweight = 'bold')\nplt.tight_layout()","15660e46":"# Features and Target\n\n- features: columns the classifier will use to predict\n- Outcome = 0 : healthy\n- Outcome = 1 : diabetes predicted \ud83d\ude25","41f735df":"# Ensemble\n\nNo fit, just predict and ensemble.","2a139935":"# XGBClassifier\n\n[Link for documentation](https:\/\/xgboost.readthedocs.io\/en\/latest\/python\/python_api.html#module-xgboost.sklearn)","7f1ded9e":"# Random Forest Classifier\n\n[Link for documentation](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html)","b2267b43":"# XGB feature importances","3ba57e78":"# Extra Trees Classifier\n\n[Link for documentation](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.ExtraTreesClassifier.html)","7008220f":"# CFG","2458b426":"# Imports","2d64dad6":"# LGBM\n\n[LGBM docs](https:\/\/lightgbm.readthedocs.io\/en\/latest\/Python-API.html)","5d45c54a":"# Evaluating predictions\n\nPredict classes with the model: \nclass 0 : no diabetes \nclass 1 : diabetes predicted \ud83d\ude25\n    \n\nX_valid is the validation features from the last fold, and the last models (from the last fold of each function, index -1) did not see y_valid data. So they can be used for evaluation.","d8858f4b":"# Load data","2f19932a":"# About this notebook\n\nIn this notebook I am predicting if a person has diabetes or not. The goal is to compare some models and find out which features have high prediction value. It is contained: \n\n- Training for some models\n- Feature importances for diabetes classification\n- Plot accuracy from models\n- Predictions\n- Ensemble: voting classifier\n- Models comparison","76e88940":"- Since the dataset is very small (only 768 rows), the results can be somewhat instable and very dependant on seed (train\/val split) and number of folds. This can be seen on the logs\/prints of the functions that train the models.\n\n- In this scenario the ensemble does not always improve the performance, but probably still makes a more robust model that might generalize better.\n\n- It is also worth noticing that the best accuracies come from the average of folds (stratifief k-fold) and the plot above is only for the last fold, so we can compare the models with the ensemble. These higher accuracies are expected because these kfold averages use all data to train the models.\n\nUpvote if you found value in this notebook! \ud83d\ude00","8c747d3d":"# Scaling","e8b387dc":"# Final results"}}