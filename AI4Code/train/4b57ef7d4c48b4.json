{"cell_type":{"3d538f6b":"code","a78d2550":"code","8fb4da87":"code","09c75b80":"code","9986e2e8":"code","ba2ebb00":"code","28275e42":"code","e1106699":"code","3ee3b628":"code","fd2d445a":"code","df9afdf0":"code","c5d4da23":"code","c799fba5":"code","22946ab4":"code","aef37c17":"code","1e1fa72c":"code","894584ce":"code","d48ce662":"code","1cff7d10":"code","dcbf5bc4":"markdown","b12f851c":"markdown","270a48ce":"markdown","9e1fd72d":"markdown"},"source":{"3d538f6b":"import gc\nfrom itertools import cycle\nimport random\n\nimport matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom scipy import interp\nimport seaborn as sns\nfrom sklearn.metrics import f1_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\n\nfrom optuna.integration import lightgbm as lgb\n#import lightgbm as lgb","a78d2550":"def fix_seed(seed):\n    # random\n    random.seed(seed)\n    # Numpy\n    np.random.seed(seed)\n\nSEED = 42\nfix_seed(SEED)","8fb4da87":"!ls ..\/input\/tabular-playground-series-feb-2021","09c75b80":"DATA = \"..\/input\/tabular-playground-series-feb-2021\/\"\ntrain = pd.read_csv(DATA + \"train.csv\")\ntest = pd.read_csv(DATA + \"test.csv\")\n\nsub = pd.read_csv(DATA + \"sample_submission.csv\")","9986e2e8":"train.info()","ba2ebb00":"train.head()","28275e42":"test.info()","e1106699":"test.head()","3ee3b628":"dataset = pd.concat([train, test])","fd2d445a":"train_cat_cols = [f\"cat{i}\" for i in range(10)]\ntrain_num_col = [f\"cont{i}\" for i in range(14)]","df9afdf0":"for col in train_cat_cols:\n    le = LabelEncoder()\n    le.fit(dataset[col])\n    train[col] = le.transform(train[col])\n    test[col] = le.transform(test[col])","c5d4da23":"X = train[[col for col in train.columns if col in (train_cat_cols + train_num_col)]]\ny = train[\"target\"]","c799fba5":"X, X_test, y, y_test = train_test_split(X, y, test_size=0.33, random_state=SEED)\nX = X.reset_index(drop=True)\ny = y.reset_index(drop=True)\nX_test = X_test.reset_index(drop=True) \ny_test = y_test.reset_index(drop=True)","22946ab4":"params = {\n    \"objective\": \"regression\",\n    \"boosting\": \"gbdt\",\n    \"num_leaves\": 40,\n    \"learning_rate\": 0.05,\n    \"feature_fraction\": 0.85,\n    \"reg_lambda\": 2,\n    \"metric\": \"rmse\"\n}","aef37c17":"d_training = lgb.Dataset(X, label=y,\n                         categorical_feature=train_cat_cols, free_raw_data=False)\nd_test = lgb.Dataset(X_test, label=y_test,\n                         categorical_feature=train_cat_cols, free_raw_data=False)","1e1fa72c":"model = lgb.train(params, train_set=d_training, num_boost_round=1000, valid_sets=[d_test], verbose_eval=25, early_stopping_rounds=50)","894584ce":"def print_tuned_params(model):\n    print(\"---------------------\")\n    print(\"params:\", model.params)\n    print(\"best_iteration:\", model.best_iteration)\n    print(\"best_score:\", model.best_score)    \n    print(\"---------------------\")\n\nprint_tuned_params(model)","d48ce662":"lgb.plot_importance(model, max_num_features=15, figsize=(10,10))\nplt.show()","1cff7d10":"pred = model.predict(test[(train_cat_cols + train_num_col)])\nsub[\"target\"] = pred\nsub.to_csv('sub.csv', index=False)","dcbf5bc4":"# Feature engineering","b12f851c":"# Train","270a48ce":"# Load data","9e1fd72d":"# Inference"}}