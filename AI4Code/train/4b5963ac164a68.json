{"cell_type":{"a92e1c5c":"code","94e39000":"code","55d29a6d":"code","8eaa75f1":"code","1dfb35ce":"code","c9d3b9e0":"code","3491822a":"code","612cc609":"code","f45eb70a":"code","140e153f":"code","34980147":"code","2220f931":"code","21d47d92":"code","2c48a6e6":"code","222e4143":"code","56c1ccad":"code","a7346bce":"code","9e1312e1":"code","f42967f7":"code","2ed9644d":"code","63b02219":"code","ef62c538":"code","073bdbd5":"code","eac62b76":"code","636bbf0a":"code","56657995":"code","2b04b2e5":"code","ae3365b9":"code","afb128b5":"code","ebfdec3a":"code","a4e18e2e":"code","649641f6":"code","8c217d30":"code","8937161b":"code","7e4f3fa7":"code","c0838fdc":"code","af953c91":"code","5a1f966f":"code","1ba6273b":"code","2dd5ee16":"code","6bc04b37":"code","2004c3fd":"code","cf4029cb":"code","c6f14f6b":"code","b28d0f7b":"code","6ab255b0":"code","b43b0bb9":"code","074ffe27":"code","f5efc0c4":"code","bd86a7a6":"code","dc26bb8f":"code","e8a925d8":"code","a06e3788":"markdown","f79b5e85":"markdown","25c494f5":"markdown","1d49fccd":"markdown","3d8fdaec":"markdown","1407ac4f":"markdown","54badb07":"markdown","25e2c1a7":"markdown","0fa36fe3":"markdown","324d4d2c":"markdown","cc170c3d":"markdown","bd783f6a":"markdown","f5575ccd":"markdown","1c6fcb91":"markdown","a8aa5d68":"markdown"},"source":{"a92e1c5c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","94e39000":"df_train=pd.read_csv(\"..\/input\/titanic\/train.csv\")\ndf_test=pd.read_csv(\"..\/input\/titanic\/test.csv\")\ndf_test1=pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")","55d29a6d":"# Reading & understanding Training Dataset\nprint(df_train.shape)\ndf_train.head()","8eaa75f1":"# Reading & understanding Testing Dataset\nprint(df_test.shape)\ndf_test.head()","1dfb35ce":"# Training Set\na=df_train.isnull().sum()\/len(df_train.index)\nb=a*100\nc=round(b,2)\nc","c9d3b9e0":"# Dropping column 'Cabin' as more than 75 percent values are NaN, so won't help in contributing\ndf_train=df_train.drop(['Cabin'] , axis=1)\ndf_train.head()","3491822a":"# Testing Set\na=df_test.isnull().sum()\/len(df_test.index)\nb=a*100\nc=round(b,2)\nc","612cc609":"# Dropping column 'Cabin' as more than 75 percent values are NaN, so won't help in contributing\ndf_test=df_test.drop(['Cabin'] , axis=1)\ndf_test.head()\n","f45eb70a":"df_train.describe()","140e153f":"df_test.describe()","34980147":"df_train['Age'].mode()","2220f931":"df_test['Age'].mode()","21d47d92":"df_train['Age'].fillna(24, inplace = True) ","2c48a6e6":"df_test['Age'].fillna(21, inplace = True)","222e4143":"a=df_train.isnull().sum()\/len(df_train.index)\nb=a*100\nc=round(b,2)\nc","56c1ccad":"df_test['Fare'].mean()","a7346bce":"df_test['Fare'].fillna(35.63, inplace = True)","9e1312e1":"a=df_test.isnull().sum()\/len(df_test.index)\nb=a*100\nc=round(b,2)\nc","f42967f7":"gender = {'male': 1,'female': 0} ","2ed9644d":"df_train.Sex = [gender[item] for item in df_train.Sex]\ndf_test.Sex  = [gender[item] for item in df_test.Sex]","63b02219":"df_train.head()\ndf_test.head()","ef62c538":"dummy_train=pd.get_dummies(df_train[['Embarked']], drop_first=True)\ndf_train=pd.concat([df_train, dummy_train],axis=1)","073bdbd5":"dummy_test= pd.get_dummies(df_test[['Embarked']], drop_first= True)\ndf_test=pd.concat([df_test, dummy_test], axis=1)","eac62b76":"df_test.head()","636bbf0a":"# Dropping original column 'Embarked'\ndf_train=df_train.drop(['Embarked'], axis=1)\ndf_test =df_test.drop(['Embarked'], axis=1)\n\ndf_test.head()","56657995":"df_train=df_train.drop(['Name'], axis=1)\ndf_test=df_test.drop(['Name'], axis=1)\ndf_train.head()","2b04b2e5":"df_train['Close Family Member']=\"\"","ae3365b9":"for ind in df_train.index: \n    df_train['Close Family Member'][ind]= 0 if (df_train['SibSp'][ind]==0 and df_train['Parch'][ind]==0) else 1","afb128b5":"df_test['Close Family Member']=\"\"","ebfdec3a":"for ind in df_test.index: \n    df_test['Close Family Member'][ind]= 0 if (df_test['SibSp'][ind]==0 and df_test['Parch'][ind]==0) else 1","a4e18e2e":"y_train=df_train['Survived']\ny_train.head()","649641f6":"X_train=df_train.drop(['PassengerId','Survived'], axis=1)\nX_train.head()","8c217d30":"X_test=df_test.drop(['PassengerId'], axis=1)\nX_test.head()","8937161b":"# It helps in faster convergence of Gradient Descent\nfrom sklearn.preprocessing import StandardScaler","7e4f3fa7":"scaler=StandardScaler()\nX_train[['Age','Fare']]=scaler.fit_transform(X_train[['Age','Fare']])\nX_train.head()","c0838fdc":"X_test[['Age','Fare']]=scaler.fit_transform(X_test[['Age','Fare']])\nX_test.head()","af953c91":"X_train=X_train.drop(['Ticket'], axis=1)\nX_train.head()","5a1f966f":"X_test=X_test.drop(['Ticket'], axis=1)\nX_test.head()\n","1ba6273b":"import matplotlib.pyplot as plt\nimport seaborn as sns","2dd5ee16":"plt.figure(figsize=(20,10))\nsns.heatmap(X_train.corr(), annot=True)\nplt.show","6bc04b37":"# Highest co-relation is -0.55, so need not drop any column","2004c3fd":"###","cf4029cb":"from sklearn.linear_model import LogisticRegression\nLR = LogisticRegression()","c6f14f6b":"LR.fit(X_train, y_train)","b28d0f7b":"# Predict churn on test data using the model just built\ny_pred = LR.predict(X_test)","6ab255b0":"print(type(y_pred))\ny_pred=pd.Series(y_pred)\nprint(type(y_pred))\ny_pred.head()","b43b0bb9":"y_test=df_test1['Survived']\nprint(type(y_test))\ny_test.head()","074ffe27":"print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(LR.score(X_test, y_test)))","f5efc0c4":"from sklearn.metrics import confusion_matrix\nconfusion_matrix = confusion_matrix(y_test, y_pred)\nprint(confusion_matrix)\n","bd86a7a6":"y_pred","dc26bb8f":"df = pd.DataFrame({'PassengerId': [ x for x in range(892, 1310)],\n                   'Survived': y_pred,\n                  })\n# df.to_csv(index=False)","e8a925d8":"df.to_csv('\/kaggle\/working\/submission.csv', index = False)","a06e3788":"## 1. Importing Dataset Properly","f79b5e85":"sibsp - no. of siblings \/ spouses aboard the Titanic","25c494f5":"### i) Dropping Ticket column as it has prefix letters","1d49fccd":"### g) Splitting df_train into X_train & y_train (PassengerId column is dropped)\n###    Splitting df_test into X_test             (Survived column is not present, so no y_test)","3d8fdaec":"### c) Converting Male & Female values to 1 & 0 ","1407ac4f":"## 2. Cleaning Dataset","54badb07":"### h) Feature Scaling","25e2c1a7":"### e) Logically thinking, column 'Name' would not be a key factor in determining who got survived, hence dropping it","0fa36fe3":"### d) For Categorical Variable 'Embarked column' with multiple independent values, create dummy features","324d4d2c":"### b) Imputing missing values of column Age in train & test sets & of column Fare in test set","cc170c3d":"### f) Creating additional Feature 'Close Family Members' from columns : SibSp & Parch","bd783f6a":"If each of both values of a column are 0, then values of 'Close Family Members' will be 0 ; otherwise 1","f5575ccd":"## 3) Looking at Correlations","1c6fcb91":"###  a) Finding missing values in any column : If % of NaN values in a column exceeeds 75%, delete that column","a8aa5d68":"parch - no. of parents \/ children aboard the Titanic"}}