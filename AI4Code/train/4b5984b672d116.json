{"cell_type":{"6ad6b19a":"code","34ad4b74":"code","2eeb0f07":"code","26dbc55c":"code","3efd518c":"code","8e45ccd6":"code","e9e8fee4":"code","34469882":"code","976cfe8c":"code","9e7d3124":"code","3a6e9065":"code","80dd3c61":"code","3b444876":"code","d028a38a":"code","0b7aa06d":"code","902fd7ef":"code","5e4392f4":"code","6a1147ca":"code","bf25eb5b":"code","65c0ea5a":"code","588ef68d":"code","4e618f93":"code","252ced4d":"code","7a3ae3f8":"code","2895f804":"code","c67effe1":"code","e1e63b58":"code","67bb4944":"code","1bd91103":"code","765d1994":"code","f5f910d5":"code","8a550461":"code","b728ae8b":"code","e529b39a":"code","ef9fcb13":"code","251261e3":"code","d71a887b":"code","577a291a":"code","c9d914b7":"code","542bb34e":"code","7825bab9":"code","df1cc506":"code","72e34158":"code","d9665c8a":"code","1e07a171":"code","6b5f7cb3":"code","4b8c34e2":"code","c4ad6a81":"code","1b35ce95":"code","7741608c":"code","c7cc1aec":"code","90bda0dc":"code","b40eb3f6":"code","09be9186":"code","26b7ed99":"code","4aed71c4":"code","6d98b416":"code","deba9697":"markdown","c21bebb6":"markdown","f2a6a0d7":"markdown","b6e1aada":"markdown","ebc891f3":"markdown","c3d99719":"markdown","e1f9db13":"markdown","be82b177":"markdown","44a1da34":"markdown","87c2600d":"markdown","8d6859d7":"markdown","f5c64b15":"markdown","e99c837f":"markdown","e077b48e":"markdown","413935e6":"markdown","558a4667":"markdown","ba085435":"markdown","9786c045":"markdown","4d492700":"markdown","f3dde044":"markdown","5ec3fca6":"markdown","aaf3ee32":"markdown","c21430d1":"markdown","f7ca6474":"markdown","a5087e04":"markdown","23fc8d9d":"markdown","a8f5b28e":"markdown","944d912f":"markdown"},"source":{"6ad6b19a":"import os\nimport gc\nimport re\nimport cv2\nimport sys\nimport glob\nfrom glob import glob\nimport tensorflow as tf\nimport keras\n\nimport numpy  as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.style  as style\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve\nimport plotly.graph_objects as go\n\nfrom tqdm  import tqdm\nfrom keras import backend\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras import layers\nfrom sklearn.metrics     import accuracy_score, roc_auc_score\nfrom keras.layers        import Dense, Dropout, Flatten, BatchNormalization, GlobalMaxPooling2D\nfrom keras.models        import Sequential, Model, load_model\nfrom keras.callbacks     import ModelCheckpoint,ReduceLROnPlateau, CSVLogger\nfrom keras.activations   import elu\nfrom keras.engine        import Layer, InputSpec\nfrom keras.applications  import MobileNetV2\nfrom keras.optimizers    import Adam\nfrom keras.preprocessing import image\nfrom sklearn.model_selection   import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator","34ad4b74":"# Compose filenames\nfilelist_mt = glob('..\/input\/pulmonary-chest-xray-abnormalities\/Montgomery\/MontgomerySet\/CXR_png\/*.png')\nfilelist_shenzen     = glob('..\/input\/pulmonary-chest-xray-abnormalities\/ChinaSet_AllFiles\/ChinaSet_AllFiles\/CXR_png\/*.png')\nfilelist             = filelist_mt + filelist_shenzen","2eeb0f07":"j = 0\nfor i in filelist:\n    print(i)\n    if j == 5:\n        break\n    j+=1","26dbc55c":"def extract_label(file_list):\n    '''\n    Label Extraction Function\n    Reads a filename and extracts label from it\n    '''\n    labels = []\n    for file in tqdm(file_list):\n        current_label = re.findall('[0-9]{4}_(.+?).png', file)\n#         print(current_label)\n        labels.append(current_label[0])\n    return(labels)","3efd518c":"label = extract_label(filelist)","8e45ccd6":"len(label)","e9e8fee4":"df = pd.DataFrame(filelist, columns = ['Path'])\ndf['Label'] = label\n\ny = df['Label']\nX = df.drop(['Label'], axis = 1)\nX.shape, y.shape","34469882":"#80% Training 20% Testing\ndf_train, X_test, label_train, y_test = train_test_split(X,\n                                                         y,\n                                                         stratify = y,\n                                                         random_state = 19,\n                                                         test_size = 0.2)","976cfe8c":"# 80% Training 20% Validation\nX_train, X_valid, y_train, y_valid = train_test_split(df_train,\n                                                     label_train,\n                                                     stratify = label_train,\n                                                     random_state = 19,\n                                                     test_size = 0.2)","9e7d3124":"\nprint('Train size')\nprint(X_train.shape, y_train.shape)\nprint('Validation Size')\nprint(X_valid.shape, y_valid.shape)\nprint('Testing Size')\nprint(X_test.shape, y_test.shape)","3a6e9065":"\n# Train\ntrain_df = X_train.copy()\ntrain_df['Label'] = y_train\n\n\n#Valid\nvalid_df = X_valid.copy()\nvalid_df['Label'] = y_valid\n\n\n#Test\ntest_df = X_test.copy()\ntest_df['Label'] = y_test","80dd3c61":"train_df.head()","3b444876":"print(\"Train Value Counts\")\nprint(train_df['Label'].value_counts())\nprint(\"Validation DF Value Counts\")\nprint(valid_df['Label'].value_counts())\nprint(\"Test DF Value Counts\")\nprint(test_df['Label'].value_counts())","d028a38a":"def plot_multiple_images(image_dataframe, rows = 4, columns = 4, figsize = (16, 20), resize=(1024,1024), preprocessing=None):\n    '''\n    Plots Multiple Images\n    Reads, resizes, applies preprocessing if desired and plots multiple images from a given dataframe\n    '''\n    image_dataframe = image_dataframe.reset_index(drop=True)\n    fig, ax = plt.subplots(rows, columns, figsize=figsize)\n#     print(image_dataframe)\n    i = 1\n    for j in range(rows):\n        for k in range(columns):\n            img = plt.imread(image_dataframe.loc[i-1,'Path'])\n            img = cv2.resize(img, resize)\n            if preprocessing:\n                img = preprocessing(img)\n            ax[j][k].set_title(\"Xray \"+str(i))\n            a = image_dataframe.loc[i-1, 'Label']\n            if int(a) == 0:\n                ax[j][k].set_xlabel('Normal')\n            else:\n                ax[j][k].set_xlabel('Tuberculosis')  \n                \n            ax[j][k].imshow(img, alpha=1, cmap='gray')\n            i+=1\n            \n        if(i == (rows*columns)):\n            break\n    plt.show()","0b7aa06d":"#Plotting Train images\nplot_multiple_images(train_df)","902fd7ef":"#Plotting Test Images\nplot_multiple_images(valid_df)","5e4392f4":"BATCH = 32\nIMAGE_INPUT = (224, 224)","6a1147ca":"def cal_steps(num_images, batch_size):\n   # calculates steps for generator\n   steps = num_images \/\/ batch_size\n\n   # adds 1 to the generator steps if the steps multiplied by\n   # the batch size is less than the total training samples\n   return steps + 1 if (steps * batch_size) < num_images else steps","bf25eb5b":"#Creating Training Data Generator\ntf.random.set_seed(19)\ntrain_generator = ImageDataGenerator(rescale = 1.\/255,)\n\n# Create Validation data generator\ntest_generator  = ImageDataGenerator(rescale = 1.\/255,)","65c0ea5a":"#Training Data\ntrain_aug_generator = ImageDataGenerator(rescale = 1.\/255,\n                                     zoom_range      = 0.05,\n                                     shear_range     = 0,\n                                     width_shift_range  = 0.05,\n                                     height_shift_range = 0.05,\n                                     )\n","588ef68d":"train = train_generator.flow_from_dataframe(dataframe = train_df,\n                                    class_mode  = 'binary',\n                                    x_col       = 'Path',\n                                    y_col       = 'Label',\n                                    shuffle     = True,\n                                    batch_size  = BATCH,\n                                    target_size = IMAGE_INPUT,\n                                    seed=19)\n\ntrain_aug = train_aug_generator.flow_from_dataframe(dataframe = train_df,\n                                    class_mode  = 'binary',\n                                    x_col       = 'Path',\n                                    y_col       = 'Label',\n                                    shuffle     = True,\n                                    batch_size  = BATCH,\n                                    target_size = IMAGE_INPUT,\n                                    seed=19)\n#Validation Data\nvalid = train_generator.flow_from_dataframe(dataframe = valid_df,\n                                    class_mode  = 'binary',\n                                    x_col       = 'Path',\n                                    y_col       = 'Label',\n                                    shuffle     = True,\n                                    batch_size  = BATCH,\n                                    target_size = IMAGE_INPUT,\n                                    seed=19)\nvalid2 = train_generator.flow_from_dataframe(dataframe = valid_df,\n                                    class_mode  = 'binary',\n                                    x_col       = 'Path',\n                                    y_col       = 'Label',\n                                    shuffle     = False,\n                                    batch_size  = BATCH,\n                                    target_size = IMAGE_INPUT,\n                                    seed=19)\n#Testing Data\ntest = test_generator.flow_from_dataframe(dataframe = test_df,\n                                    class_mode  = 'binary',\n                                    x_col       = 'Path',\n                                    y_col       = 'Label',\n                                    shuffle     = False,\n                                    batch_size  = BATCH,\n                                    target_size = IMAGE_INPUT)","4e618f93":"\ndef plot_training_hist(keras_model):\n    '''\n    Plot training History\n    Creates two plots of model training logs\n    '''\n    hist = keras_model.history\n    style.use('fivethirtyeight')\n    \n    # Loss Plot\n    fig = plt.figure(figsize=(8,3))\n    plt.title('Loss Plot')\n    plt.plot(hist['loss'], '#07e9ed')\n    plt.plot(hist['val_loss'], '#0791ed')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.ylim([0,1.2 * max(max(hist['loss'], hist['val_loss']))])\n    plt.legend(['train', 'validation'], loc='lower right')\n    plt.show()\n    \n    # Accuracy Plot\n    fig = plt.figure(figsize=(8,3))\n    plt.title('Accuracy Plot')\n    plt.plot(hist['accuracy'], '#07e9ed')\n    plt.plot(hist['val_accuracy'], '#0791ed')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')    \n    plt.legend(['train', 'validation'], loc='lower right')\n    plt.ylim([0,1])\n    \n    #ROC Plot\n    fig = plt.figure(figsize=(8,3))\n    plt.title('Recall Plot')\n    plt.plot(hist['recall'], '#07e9ed')\n    plt.plot(hist['val_recall'], '#0791ed')\n    plt.xlabel('Epochs')\n    plt.ylabel('Recall Score')    \n    plt.legend(['train', 'validation'], loc='lower right')\n    plt.ylim([0,1])\n    # Show Plot, reset style\n    plt.show()\n    style.use('default')","252ced4d":"class PrintValTrainRatioCallback(keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs): \n    print(\"val \/ train : {:.2f}\".format(logs['val_loss']\/logs['loss']))\n    \n#Another Additional callbacks (Checkpoint, Early Stopping)\ncheckpoint_cb = keras.callbacks.ModelCheckpoint(\"baseline_model.h5\")\nearly_stopping_cb = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True) \ncallbacks = [checkpoint_cb, early_stopping_cb, PrintValTrainRatioCallback()]","7a3ae3f8":"#Defining Metrics\nmetrics = ['accuracy', keras.metrics.AUC(), keras.metrics.Recall()]","2895f804":"# Making Resnet Model\nkeras.backend.clear_session()\ntf.random.set_seed(42)\nnp.random.seed(42)\nresnet50_url = 'https:\/\/tfhub.dev\/google\/imagenet\/resnet_v2_50\/feature_vector\/5'\nfeature_extractor_layer = hub.KerasLayer(resnet50_url,\n                                           trainable=False, # freeze the underlying patterns\n                                           name='feature_extraction_layer',\n                                           input_shape=IMAGE_INPUT+(3,)) # define the input image shap\n\nresnet_model = keras.Sequential([\n    feature_extractor_layer,\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.2),\n    keras.layers.Dense(1, activation = 'sigmoid'),\n])\n\n\nresnet_model.compile(loss='binary_crossentropy',\n                    metrics = [metrics],\n                    optimizer = keras.optimizers.Adam(learning_rate = 5e-4))","c67effe1":"resnet_model.summary()","e1e63b58":"resnet_history = resnet_model.fit(train_aug,\n                                 validation_data = valid,\n                                 steps_per_epoch =len(train_aug),\n                                 validation_steps =  len(valid),\n                                 epochs = 30,\n                                 callbacks = [callbacks])","67bb4944":"plot_training_hist(resnet_history)","1bd91103":"# Making Resnet Model\nkeras.backend.clear_session()\ntf.random.set_seed(42)\nnp.random.seed(42)\nresnet50_url = 'https:\/\/tfhub.dev\/google\/imagenet\/resnet_v2_50\/feature_vector\/5'\nfeature_extractor_layer = hub.KerasLayer(resnet50_url,\n                                           trainable=False, # freeze the underlying patterns\n                                           name='feature_extraction_layer',\n                                           input_shape=IMAGE_INPUT+(3,)) # define the input image shap\n\nresnet_model2 = keras.Sequential([\n    feature_extractor_layer,\n    keras.layers.BatchNormalization(),\n    keras.layers.Dense(80, activation = 'elu', kernel_initializer = 'he_normal'),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.3),\n    keras.layers.Dense(80, activation = 'elu', kernel_initializer = 'he_normal'),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.3),\n    keras.layers.Dense(1, activation = 'sigmoid'),\n])\n\nresnet_model2.compile(loss='binary_crossentropy',\n                    metrics = [metrics],\n                    optimizer = keras.optimizers.Adam(learning_rate = 5e-4))","765d1994":"resnet_model2.summary()","f5f910d5":"feature_extractor_layer.output_shape","8a550461":"resnet_history2 = resnet_model2.fit(train_aug,\n                                 validation_data = valid,\n                                steps_per_epoch = len(train_aug),\n                                 validation_steps =  len(valid),\n                                 epochs = 30,\n                                 callbacks = [callbacks])","b728ae8b":"plot_training_hist(resnet_history2)","e529b39a":"from tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.datasets import fashion_mnist\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import backend as K\nfrom sklearn.metrics import classification_report\nimport keras_tuner as kt\nimport numpy as np","ef9fcb13":"def model_builder(hp):\n    model = keras.Sequential()\n    resnet50_url = 'https:\/\/tfhub.dev\/google\/imagenet\/resnet_v2_50\/feature_vector\/5'\n    feature_extractor_layer = hub.KerasLayer(resnet50_url,\n                                           trainable=False, # freeze the underlying patterns\n                                           name='feature_extraction_layer',\n                                           input_shape=IMAGE_INPUT+(3,)) # define the input image shap\n\n    hp_units = hp.Int('units', min_value=80, max_value=160, step=40)\n    hp_dropout = hp.Choice('dropoutRate', values=[0.2, 0.3, 0.4])\n    hp_activation = hp.Choice('activation', values = ['elu', 'relu'])\n    model = keras.Sequential([\n    feature_extractor_layer,\n    keras.layers.BatchNormalization(),\n    keras.layers.Dense(units = hp_units, activation = hp_activation, kernel_initializer = 'he_normal'),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(hp_dropout),\n    keras.layers.Dense(units = hp_units, activation = hp_activation, kernel_initializer = 'he_normal'),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(hp_dropout),\n    keras.layers.Dense(1, activation = 'sigmoid'),\n    ])\n    \n    hp_learning_rate = hp.Choice('learning_rate', values=[5e-3, 5e-4, 5e-5])\n    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n                loss='binary_crossentropy',\n                metrics=[metrics])\n\n    return model","251261e3":"tuner = kt.Hyperband(model_builder,\n                     objective='val_accuracy',\n                     max_epochs=20,\n                     factor=3,\n                     directory='my_dir',\n                     project_name='tuning_model',\n                    seed = 19)","d71a887b":"#Searching for best parameter\n#Using only early_stopping callback(patience = 5)\nstop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n\ntuner.search(train_aug, validation_data = valid, epochs = 20, callbacks = [stop_early])","577a291a":"best_hyperparameters = tuner.get_best_hyperparameters(1)[0]\nbest_hyperparameters.values","c9d914b7":"# We can also use customized callback, where we customize them on our own\nclass PrintValTrainRatioCallback(keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs): \n    print(\"val \/ train : {:.2f}\".format(logs['val_loss']\/logs['loss']))\n    \n#Another Additional callbacks (Checkpoint, Early Stopping)\ncheckpoint_cb = keras.callbacks.ModelCheckpoint(\"tuned_model.h5\")\nearly_stopping_cb = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True) \ncallbacks = [checkpoint_cb, early_stopping_cb, PrintValTrainRatioCallback()]","542bb34e":"# Making Resnet Model\nkeras.backend.clear_session()\ntf.random.set_seed(42)\nnp.random.seed(42)\nresnet50_url = 'https:\/\/tfhub.dev\/google\/imagenet\/resnet_v2_50\/feature_vector\/5'\nfeature_extractor_layer = hub.KerasLayer(resnet50_url,\n                                           trainable=False, # freeze the underlying patterns\n                                           name='feature_extraction_layer',\n                                           input_shape=IMAGE_INPUT+(3,)) # define the input image shap\n\nresnet_model3 = keras.Sequential([\n    feature_extractor_layer,\n    keras.layers.BatchNormalization(),\n    keras.layers.Dense(160, activation = 'elu', kernel_initializer = 'he_normal'),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.3),\n    keras.layers.Dense(160, activation = 'elu', kernel_initializer = 'he_normal'),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.3),\n    keras.layers.Dense(1, activation = 'sigmoid'),\n])\n\nresnet_model3.compile(loss='binary_crossentropy',\n                    metrics = [metrics],\n                    optimizer = keras.optimizers.Adam(learning_rate = 5e-4))","7825bab9":"resnet_history3 = resnet_model3.fit(train_aug,\n                 validation_data = valid,\n                 steps_per_epoch = len(train),\n                validation_steps = len(valid),\n                  epochs = 20,\n        callbacks = [callbacks])","df1cc506":"resnet_model3.save_weights('final_model.h5')","72e34158":"plot_training_hist(resnet_history3)","d9665c8a":"def plot_roc_curve(*datas):\n  fig = go.Figure()\n  for data in datas:\n    name = data[0]\n    y_true = data[1]\n    pred = data[2]\n\n    fpr, tpr, _ = roc_curve(y_true, pred)\n    fig.add_trace(go.Scatter(x=fpr, y=tpr, name=name))\n    \n  fig.update_yaxes(title_text=\"TPR\")\n  fig.update_xaxes(title_text=\"FPR\")\n  fig.update_layout(title_text=\"ROC Curve\")\n  fig.show()","1e07a171":"def predictValues(model, valid, y_real):\n    pred = model.predict(valid)\n    a =[]\n    for i in pred:\n        if i > 0.5:\n            a.append(int(1))\n        else:\n            a.append(int(0))\n    print(\"Accuracy score : \", accuracy_score(y_real, a))\n    print(\"Recall score : \", recall_score(y_real, a, average = 'weighted'))\n    return a","6b5f7cb3":"resnet_model3.evaluate(valid)","4b8c34e2":"y_true = valid_df['Label']\ny_true = y_true.astype('int')\npred = predictValues(resnet_model3, valid2, y_true)","c4ad6a81":"print(classification_report(y_true, pred, labels=[0,1], zero_division=1))","1b35ce95":"plot_roc_curve(['resnet_model3', y_true, pred])","7741608c":"# Get label\ny_real = test_df['Label']","c7cc1aec":"#Change the datatype to int\ny_real = y_real.astype('int')","90bda0dc":"loss, acc, auc, recall = resnet_model3.evaluate(test)","b40eb3f6":"def predictUnseenValues(model, test):\n    pred = model.predict(test)\n    a =[]\n    for i in pred:\n        if i > 0.33:\n            a.append(int(1))\n        else:\n            a.append(int(0))\n    print(\"Accuracy score : \", accuracy_score(y_real, a))\n    print(\"Recall score : \", recall_score(y_real, a, average = 'weighted'))\n    return a","09be9186":"final_pred= predictUnseenValues(resnet_model3,test)","26b7ed99":"print(classification_report(y_real, final_pred, labels=[0,1], zero_division=1))","4aed71c4":"a = confusion_matrix(y_real, final_pred)\na","6d98b416":"plot_roc_curve(['resnet_model3', y_real, final_pred])","deba9697":"## Setting up Callbacks","c21bebb6":"# Data Preparation\n\nWe will use the codes from previous notebook to extract all the data, images, dataframes and also the functions for modelling and also plotting","f2a6a0d7":"# Evaluation on Unseen Data","b6e1aada":"## ResNet50 V2\n![image.png](attachment:6bbbdf3b-f6eb-4c0f-a778-4bcf74220739.png)![image.png](attachment:da13518d-77ff-40b0-9833-d8764b9d826e.png)\n\n","ebc891f3":"We will focus on val_accuracy, because on the previous hyperparameter tuning, making the objective into val_recall will make the model focus too much on the recall, causing it to be underfitting when it tried to predict unseen data","c3d99719":"We get a recall of 0.86! It is a really great improvement","e1f9db13":"- True Positive : 64\n- False Negative : 17\n- False Positive : 11\n- True Negative : 68\n","be82b177":"## Experiment 1","44a1da34":"## Experiment 2","87c2600d":"I will be using HyperBand as the tuning algorithm. Hyperband is a relatively new method for tuning iterative algorithms. It performs random sampling and attempts to gain an edge by using time spent optimizing in the best way. It's faster and better than Randomized tuning algorithm.","8d6859d7":"We'll cutdown the Image Input size to 224,224 to reduce time computation, and batch-size = 32 ","f5c64b15":"We got the best parameters! Now lets continue to final fitting for evaluation","e99c837f":"Still the same from out previous notebook, we will give some augmentation to the training data. This is done to prevent overfitting, and give challenges to our model to overcome","e077b48e":"We will now create a function which return our model. The keras api used for hyperparameter requires a function which return a model for parameter searching","413935e6":"We could get a 86% recall rate, which can save the doctor's time by a lot!","558a4667":"After the searching is finished, we can extract the model parameters and see the compositions","ba085435":"We will manually input the parameters gained from the tuner, and create a model for evaluation","9786c045":"# Modelling","4d492700":"# HyperParameter Tuning with HyperBand","f3dde044":"ResNet, short for a Residual Networks are usually used for many Computer Vision Tasks. It is able to perform greatly on unseen data, which also won the ImageNet Challenge in 2015. After going through many comparison between ResNet50, EfficientNetB0, EfficientNetb1, and DenseNet121, This pretrained model shows a stability amongst all model. Hence, this model is chosen for further modelling, tuning and evaluation","5ec3fca6":"We will be using the threshold of 0.33 instead of 0.5, to increase our recall for the unseen dataset","aaf3ee32":"We will convert it into dataframe, to ease the process using the ImageDataGenerator by Keras","c21430d1":"For the first experiment with the ResNet50 V2, we tried adding batchnormalization and Dropout layers","f7ca6474":"The model seems to have improved, and we will move on to the next experiment","a5087e04":"## Setting up Train, Valid, Test Data from ImageDataGenerator","23fc8d9d":"On the second experiment, the model looks to have improved by a lot! We will use this model architecture for further parameter tuning and evaluation","a8f5b28e":"## Data Splitting\n\nAs what we have done before, we will split the data into 80:20 for training and testing, and 80:20 for training and validation","944d912f":"The previous one is really a good model, compared without any batchnormalization and dropout. We will try to add more dense layers and change the activation function of the layers and see how it affects the performance of the model"}}