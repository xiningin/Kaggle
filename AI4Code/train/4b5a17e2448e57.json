{"cell_type":{"f62ee9dc":"code","0afad6dc":"code","31641d44":"code","247b3146":"code","156df5a9":"code","6ab3336d":"code","7ca70f8b":"code","bb37b856":"code","c9b3a1ee":"code","a5ccf9fa":"code","efc1e7c9":"code","d14d8322":"code","87350b56":"code","a3e0c692":"code","b7a0e9cc":"code","5aa96376":"code","c20ef943":"code","aa945837":"code","eab11439":"markdown","8f1b51a8":"markdown","51d18477":"markdown","ad270e51":"markdown","692d96bd":"markdown","7c295bc8":"markdown","fecdadf2":"markdown","9a49232d":"markdown","c0e744c7":"markdown","415aeb60":"markdown"},"source":{"f62ee9dc":"import pandas as pd\nimport numpy as np\nimport json\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nsns.set(context='notebook', style='darkgrid') ","0afad6dc":"df=pd.read_csv(\"..\/input\/taylorswiftlyricsfeatures\/TaylorSwiftLyricsFeatureSet.csv\")\ndf=df.rename(columns={\"Album\":\"track_album\",\"Artist\":\"track_artist\",\"Track\":\"track_title\",\"TrackURI\":\"track_uri\" , \"TrackID\":\"track_id\" ,\"Lyrics\":\"track_lyric\"})","31641d44":"data = df.drop(columns=[\"track_lyric\"],axis=0)\ndata.head()","247b3146":"XtoPredict = data.loc[data['genres'].isnull(),:].drop(columns=['track_uri','track_id']).reset_index(drop=True)\nFeatureSet = data.loc[data['genres'].notnull(),:].drop(columns=['track_uri','track_id']).reset_index(drop=True)\nFeatureSet.head()","156df5a9":"print(len(FeatureSet.genres.unique()))\n\ncountry = ['Country Pop','Country','Folk Pop','Blue grass','Contemporary Country']\npop = ['Pop','Electropop','Synth Pop','Dance Pop','Dream Pop']\nrock = ['Pop Rock','Pop Punk','Alternative Rock','Soft Rock','R&B','Country Rock',]\n\nprint(len(rock)+len(country)+len(pop))","6ab3336d":"genre_broad = []\nfor index,i in enumerate(FeatureSet.genres):\n    if i in country:\n        genre_broad.append('country')\n    \n    if i in rock:\n        genre_broad.append('rock')\n    \n    if i in pop:\n        genre_broad.append('pop')\n        \nFeatureSet['genre_broad']=genre_broad","7ca70f8b":"FeatureSet.groupby('genre_broad').count()['track_title'].plot.bar()","bb37b856":"fig = plt.figure(figsize=(7,5))\nsns.boxplot(x='duration_ms',data=FeatureSet)\nplt.title(\"Duration (to check outliers)\")","c9b3a1ee":"fig = plt.figure(figsize=(15,15))\n\ncorr =df.loc[:,'danceability':'time_signature'].corr()\nmask = np.triu(np.ones_like(corr, dtype=np.bool)) #For Lower Triangle, removes TriU\n\nsns.heatmap(corr,annot=True,mask=mask,cmap='RdBu')","a5ccf9fa":"genre_rel= FeatureSet.groupby('genres').median().loc[:,'danceability':'time_signature']\n\ncorr=genre_rel.transpose().corr('kendall')\nmask = np.triu(np.ones_like(corr, dtype=np.bool)) #For Lower Triangle, removes TriU\n\nfig = plt.figure(figsize=(15,15))\nsns.heatmap(corr,annot=True,mask=mask,cmap='RdBu')","efc1e7c9":"genre_rel= FeatureSet.groupby('genre_broad').median().loc[:,'danceability':'time_signature']\n\ncorr=genre_rel.transpose().corr('kendall')\n#mask = np.triu(np.ones_like(corr, dtype=np.bool)) #For Lower Triangle, removes TriU\n\nfig = plt.figure(figsize=(5,5))\nsns.heatmap(corr,annot=True,cmap='RdBu')","d14d8322":"fig = plt.figure(figsize=(15,7))\n\nfig.add_subplot(2,4,1)\nsns.distplot(data.danceability)\n\nfig.add_subplot(2,4,2)\nsns.distplot(data.energy)\n\nfig.add_subplot(2,4,3)\nsns.distplot(data.key)\n\nfig.add_subplot(2,4,4)\nsns.distplot(data.loudness)\n\nfig.add_subplot(2,4,5)\nsns.distplot(data.speechiness)\n\nfig.add_subplot(2,4,6)\nsns.distplot(data.acousticness)\n\nfig.add_subplot(2,4,7)\nsns.distplot(data.valence)\n\nfig.add_subplot(2,4,8)\nsns.distplot(data.tempo)","87350b56":"from sklearn.datasets import load_iris\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import plot_tree\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.tree import export_graphviz","a3e0c692":"X = FeatureSet.loc[:,'danceability':'duration_ms'].drop(columns=['loudness','mode'])\ny = FeatureSet.loc[:,'genre_broad']\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.25)","b7a0e9cc":"dt = DecisionTreeClassifier(min_samples_leaf=1)\ndt.fit(X_train, y_train)\n\nfig = plt.figure(figsize=(25,10))\n#tree.plot_tree(dt);\n\na = plot_tree(dt, \n              feature_names=X.columns, \n              class_names=y.unique(), \n              label={\"root\"},\n              proportion=True,\n              filled=True, \n              impurity=False,\n              rounded=True, \n              fontsize=15)\n\nyhat=dt.predict(X_test)\ndt.score(X_test,y_test)","5aa96376":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(criterion='gini',\n                             n_estimators=100)\nclf.fit(X_train, y_train)\nclf.score(X_test, y_test)","c20ef943":"from sklearn.naive_bayes import GaussianNB, MultinomialNB, CategoricalNB\ngnb = GaussianNB()\ny_pred = gnb.fit(X_train, y_train).predict(X_test)\nprint(gnb.score(X_test, y_test))\n\nmnb = MultinomialNB(alpha=1000)\nprint((mnb.fit(X_train, y_train)).score(X_test, y_test))","aa945837":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\nlr.fit(X_train, y_train)\nlr.score(X_test,y_test)","eab11439":"## Modelling Classifiers\nWe will now model our classifiers. But first we must split our train and test sets","8f1b51a8":"FeatureSet will be the one that is used to train and test out our Model.","51d18477":"### Decision Tree Classifier","ad270e51":"### Logistic Regression","692d96bd":"We see there are a few duration outliers. But they wont matter for now.  \nNext we will see the correlation between the different features","7c295bc8":"Here, We see that Loudness and Energy are the most correlated. Thus, We can remove loudness parameter altogether\nLet us now analyse how the genres correlate to each other","fecdadf2":"### Random Forrest Classifier","9a49232d":"### Distribution Plots\nWe will see the distribution of all the parametres of the spotify audio features.","c0e744c7":"### Naive Bayes","415aeb60":"## Exploratory Data Analysis\nWe will now do EDA on the data set which starts with splitting the problem(target) set and Feature Set"}}