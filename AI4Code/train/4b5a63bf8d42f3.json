{"cell_type":{"00b2bb37":"code","a7ffc21c":"code","7c1c54d6":"code","5646b037":"code","db37a316":"code","b66664ed":"code","a5d2371b":"code","1de1e84a":"code","e5415021":"code","a2df090f":"code","e6c31ac0":"code","0a457326":"code","166a5e31":"code","d2229165":"code","0a7471ed":"code","7b074732":"code","41a6424e":"code","828a57cc":"code","3b8553f9":"markdown","fa3a85af":"markdown","16ac1312":"markdown","8d56f21a":"markdown","70a234c8":"markdown","4b46419b":"markdown","5fbe3a20":"markdown","9b0c3fe0":"markdown","f87be3d0":"markdown","409c9d3d":"markdown","bbb84c3f":"markdown","b349fa29":"markdown","17b70313":"markdown","cb47b433":"markdown","2fcaa357":"markdown","6a3036c1":"markdown","dd141748":"markdown","5ab6be5a":"markdown","19ee1367":"markdown","c87e2450":"markdown","021f97d0":"markdown","92c5127b":"markdown","4236038c":"markdown"},"source":{"00b2bb37":"pip install textfeatures","a7ffc21c":"import textfeatures as tf","7c1c54d6":"import pandas as pd","5646b037":"#enconding is applicable for this dataset.\ndf = pd.read_csv(\"..\/input\/covid19-tweets\/COVID-19_Tweets.csv\",encoding=\"latin\")\ndf.head()\n","db37a316":"tf.word_count(df,\"Tweets\",\"word_cnt\")\ndf[[\"Tweets\",\"word_cnt\"]].head()","b66664ed":"tf.char_count(df,\"Tweets\",\"char_len\")\ndf[[\"Tweets\",\"char_len\"]].head()","a5d2371b":"tf.avg_word_length(df,\"Tweets\",\"avg_wrd_length\")\ndf[[\"Tweets\",\"avg_wrd_length\"]].head()","1de1e84a":"tf.stopwords_count(df,\"Tweets\",\"stopwords_cnt\")\ndf[[\"Tweets\",\"stopwords_cnt\"]].head()","e5415021":"tf.stopwords(df,\"Tweets\",\"stopwords\")\ndf[[\"Tweets\",\"stopwords\"]].head()","a2df090f":"tf.hashtags_count(df,\"Tweets\",\"hashtags_count\")\ndf[[\"Tweets\",\"hashtags_count\"]].head()","e6c31ac0":"tf.hashtags(df,\"Tweets\",\"hashtags\")\ndf[[\"Tweets\",\"hashtags\"]].head()","0a457326":"tf.links_count(df,\"Tweets\",\"links_count\")\ndf[[\"Tweets\",\"links_count\"]].head()","166a5e31":"tf.links(df,\"Tweets\",\"Links\")\ndf[[\"Tweets\",\"Links\"]].head()","d2229165":"tf.numerics_count(df,\"Tweets\",\"num_len\")\ndf[[\"Tweets\",\"num_len\"]].head()","0a7471ed":"tf.user_mentions_count(df,\"Tweets\",\"user_mentions_cnt\")\ndf[[\"Tweets\",\"user_mentions_cnt\"]].head(5)","7b074732":"tf.user_mentions(df,\"Tweets\",\"user_mentions\")\ndf[[\"Tweets\",\"user_mentions\"]].head()","41a6424e":"tf.clean(df,\"Tweets\",\"Clean_tweets\")\ndf[[\"Tweets\",\"Clean_tweets\"]].head()","828a57cc":"df.head()","3b8553f9":"The best way to install the text2feature package is using pip.","fa3a85af":"\n\n## 2. char_count()\n\n*   We calculate the number of characters in every row of the dataset.\n*   This can be accomplished by calculating the length of the tweet.\n\n","16ac1312":"## 11. user_mentions_count()\n\n\n*   While handling twitter data, we always come in contact with user mentions(@). We are curious about this type of data features, it helps us to analyse the data and undersstand it's importance more effectively.\n\n\n*   We are finding the count of user mentions here. \n\n\n\n","8d56f21a":"## 4. stopwords_count()\n\n*   For processing any natural language processing problem, we always try to clean our data. So to find the stowords is the primary task to follow.\n*   We will find the count of stopwords present in the text data.\n\n","70a234c8":"# Key Takeaways\n* [Package](https:\/\/pypi.org\/project\/textfeatures\/)\n* [Github Repository](https:\/\/github.com\/Amey23\/textfeatures)","4b46419b":"# 1. word_count()\n\n\n*   That's the very first task of feature extraction.\n*   we calculate the word count in every row of dataset.\n\n","5fbe3a20":"## Let's look at the complete dataframe","9b0c3fe0":"import the necessary libraries that you require to build your model. ","f87be3d0":"**Let's understand the syntax and functionalities provided by textfeatures package.**\nWe are using the [COVID-19 Tweets dataset](https:\/\/www.kaggle.com\/ameyband\/covid19-tweets) hosted on kaggle.","409c9d3d":"Read the data csv file using pandas and define it with a dataframe. Take a preview of the dataset.","bbb84c3f":"## 6. hashtags_count()\n\n\n*   It's the most interesting task to find out the hashtags in the data because hashtags help us to reach the maximum viewers so that your post or tweeet will get the maximum response also.\n*   we will calculate the count of hashtags first.\n\n","b349fa29":"## 12. user_mentions() \n\n*   Let's find out the user mentions, store it in the list and use it for informative visualization.\n\n","17b70313":"# Conclusion\nI hope that you understand the basic functionalities provided by this library. Now it\u2019s time for you to design some interesting implementations. If you want to contribute then kindly fork the repository on GitHub and keep doing good work.","cb47b433":"## 7. hashtags()\n\n\n*   Now we will extract the hashtags and store it into the list for more pre-processing and visualization of data.\n","2fcaa357":"# **What will textfeatures serve you?**\n\n**1. word_count():-** give the total words count present in text data.\n\n**2. char_count():-** give the characters count.\n\n**3. avg_word_length():-** give the average word length.\n\n**4. stopwords_count()**:- give the stopwords count.\n\n**5. stopwords()**:- extract the stopwords from the text data.\n\n**6. hashtags_count():-** give the hashtags count.\n\n**7. hashtags():-** extract the hashtags from text data.\n\n**8. links_count():-** give the embedded links count from text data.\n\n**9. links():-** extract the links from the text data.\n\n**10. numeric_count():-** give the numeric digits count.\n\n**11. user_mentions_count():-** give the user mentions count from text data.\n\n**12. user_mentions():-** extract the user mentions from text data.\n\n**13. clean():-** give the pre-processed data after removal for unnecessary material in text data. \n","6a3036c1":"## 8. links_count()\n\n\n*   For finding more insights from the data, we find the embedded links also.\n*   We will find the count of links.\n\n","dd141748":"## 3. avg_word_length()\n\n*   To understand more about the data, we will find the average word length.\n*   We calculate it by simply taking the sum of the length of all the words and divide it by the total length of the tweet.\n\n","5ab6be5a":"# **Introduction: textfeatures**\nWhen we handle the text data, we always have concerns about the data features, pre-processing of data and more likely the predictions. To improve our model, it is important to understand the data and find the more interesting features in the data like hashtags, links and many more.","19ee1367":"## 9. links()\n\n\n*   Let's find out the links embedded in text data, store it in the list and use it for further analysis.\n\n","c87e2450":"## **What is textfeatures?**\n\nThis is a python package that helps you to extract the basic features from the text data such as hashtags, stopwords, numerics which will help you to understand the data and improve your model more effectively.\n\n## **Function call structure:**\n\n## function_name(dataframe, \u201dtext_column\u201d, \u201dnew_column\u201d)\n\n**dataframe:- name of dataframe**\n\n**text_column:- name of the column from which features are to be extracted.**\n\n**new_column:- new column derived by feature extraction from text_column.**\n\n","021f97d0":"## 10. numerics_count()\n\n*   Just like we searched for words, hashtags, links and many more things we will find the count of numeric also.\n*   It will definitely help us in processing of text data.\n\n","92c5127b":"## 13. clean()\n\n\n*   After extracting all the meaningful features, it's our need to clean data for further sentiment analysis.\n*   So we have a clean() funtion which will give you the pre-processed data after removing unwanted material like numerics, stopwords, punctuations and links.\n\n","4236038c":"## 5. stopwords()\n\n*   We find the stopwords in the text data and store it in a list so that you can find the noise in the data and make it more interactive.\n\n"}}