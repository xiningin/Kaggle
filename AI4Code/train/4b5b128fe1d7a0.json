{"cell_type":{"d2dc8919":"code","1044615b":"code","52b78417":"code","48e33890":"code","c4047619":"code","0fe9d31d":"code","b3be39c6":"code","af8362f7":"code","4df1d123":"code","1e3f42a3":"code","bcd91784":"code","14c18616":"code","6917db12":"code","e0582e8a":"code","2aefa1ab":"code","b977c1e7":"code","aefb706d":"code","2a3ea05c":"code","923e1414":"code","e6ad4ec4":"code","92ff431d":"code","9c2efc59":"code","4ecd9cd6":"code","6ff74cc0":"code","31410ed5":"code","7c64498a":"code","d37cc398":"code","c5f46f93":"code","af040713":"code","29ce63c5":"code","2ce866e7":"code","d7e801c3":"code","aab10422":"code","ded7b7cb":"code","3d0d9955":"code","350a6537":"code","0c0155d3":"code","2c66471b":"code","4e0e346f":"code","cda8d81f":"code","24bf5653":"code","2194dc87":"code","9ab800cb":"code","691408eb":"code","f69b038c":"code","e6e28f8e":"code","847801a6":"code","ab591c53":"code","515ce6f9":"code","12bcbc28":"code","a618ac33":"markdown","3c10c063":"markdown","9ea22c2e":"markdown","1c22d30b":"markdown","8d7f8d12":"markdown","1dfb7155":"markdown","6aa9d56d":"markdown"},"source":{"d2dc8919":"#import libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline ","1044615b":"train=pd.read_csv('..\/input\/bike-sharing-demand\/train.csv') ##Loading the training data\ntest=pd.read_csv(\"..\/input\/bike-sharing-demand\/test.csv\") ##Loading the testing data","52b78417":"train.head() ","48e33890":"train.groupby(['workingday']).sum()['count'] ","c4047619":"sns.relplot(x='season',y='count',data=train,hue='workingday') \nsns.relplot(x='weather',y='count',data=train,hue='workingday')","0fe9d31d":"sns.relplot(x='temp',y='count',data=train,hue='workingday')\nsns.relplot(x='atemp',y='count',data=train,hue='workingday')","b3be39c6":"sns.relplot(x='humidity',y='count',data=train,hue='workingday')\nsns.relplot(x='windspeed',y='count',data=train,hue='workingday')\nsns.relplot(x='casual',y='count',data=train,hue='workingday')","af8362f7":"cols = ['temp','atemp','humidity','windspeed','casual','registered']\nfig, axes = plt.subplots(2,3,figsize = (10,5))\n\ncount=0\nfor i in range(2):\n    for j in range(3):\n        x = cols[count+j]\n        sns.distplot(train[x].values, ax = axes[i][j],bins = 30)\n        axes[i][j].set_title(x,fontsize=15)\n        fig.set_size_inches(15,7)\n        plt.tight_layout()\n    count = count+j+1 \n","4df1d123":"train.info()","1e3f42a3":"train.describe()","bcd91784":"print(\"Shape of training dataset is: \",train.shape)\nprint(\"Does the traing dataset have null values ? -\",train.isnull().values.any())","14c18616":"visual_df = train.copy()","6917db12":"train['datetime'] = pd.to_datetime(train['datetime'] )#changing the dtype of datetime field to datetime\ntrain['year']=train.datetime.dt.year\ntrain['month']=train.datetime.dt.month\ntrain['day']=train.datetime.dt.day\ntrain['hour']=train.datetime.dt.hour\ntrain['minute']=train.datetime.dt.minute","e0582e8a":"visual_df['datetime'] = pd.to_datetime(visual_df['datetime'] )#changing the dtype of datetime field to datetime","2aefa1ab":"# method for creating the count plot based on hour for a given year \ndef plot_by_month(data,aggre,title):\n    d2 = data\n    d2['year'] = d2.datetime.dt.year\n    d2['month'] = d2.datetime.dt.month\n    d2['hour'] = d2.datetime.dt.hour\n    \n    by_year = d2.groupby([aggre,'year'])['count'].sum().unstack() # groupby hour and working day\n    \n    return by_year.plot(kind='bar', figsize=(15,5), width=0.9, title=title) # returning the figure grouped by hour\n\nplot_by_month(visual_df,'month', \"Seasonal trend: There must be high demand during summer season, when temperature is good enough to ride cycle and low demand during winter.\")  \nplot_by_month(visual_df,'hour', \"Hourly trend: There must be high demand during office timings. Early morning and late evening can have moderate trend (cyclist) and low demand during 10:00 pm to 4:00 am.\") ","b977c1e7":"# method for creating the count plot based on hour for a given year \ndef plot_by_hour(data, year):\n    d1 = data\n    d1['hour'] = d1.datetime.dt.hour\n    \n    by_hour = d1.groupby(['hour', 'workingday'])['count'].sum().unstack() # groupby hour and working day\n    \n    return by_hour.plot(kind='bar', figsize=(15,5), width=0.9, title=\"Hourly pattern based on working days. High trend during hours when peope start to office and leave to home.Year = {0}\".format(year)) # returning the figure grouped by hour\n\n\nplot_by_hour(visual_df, year=2011) # plotting the count plot based on hour for 2011 \nplot_by_hour(visual_df, year=2012) # plotting the count plot based on hour for 2012","aefb706d":"def plot_hours(data, message):\n    d2 = data.copy()\n    d2['hour'] = data.datetime.dt.hour # extratcing the hour\n    \n    hours = {}\n\n    for hour in range(24):\n        hours[hour] = d2[ d2.hour == hour ]['count'].values\n\n    \n    plt.figure(figsize=(20,10))\n    plt.ylabel(\"Count rent\")\n    plt.xlabel(\"Hours\")\n    plt.title(\"count vs hours\\n\" + message)\n    plt.boxplot( [hours[hour] for hour in range(24)] )\n    plt.grid()\n    \n\nplot_hours( visual_df[visual_df.datetime.dt.year == 2011], 'year 2011') # box plot for hourly count for the mentioned year\nplot_hours( visual_df[visual_df.datetime.dt.year == 2012], 'year 2012') # box plot for hourly count for the mentioned year\n ","2a3ea05c":"\nplot_hours( visual_df[visual_df.workingday == 0], 'Non-working days') # box plot for hourly count for the mentioned year\nplot_hours( visual_df[visual_df.workingday == 1], 'Working days') # box plot for hourly count for the mentioned year","923e1414":"train.columns","e6ad4ec4":"from sklearn.linear_model import Lasso,Ridge\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.model_selection import cross_val_score,GridSearchCV,train_test_split","92ff431d":"from sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import r2_score,mean_squared_error\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor","9c2efc59":"train.head()","4ecd9cd6":"train['count'] = np.log(train['count']+1)","6ff74cc0":"y_train = train['count'] ## Capture the dependent feature\nx_train = train.drop(['datetime','count'],axis=1) ## Capture the independent feature","31410ed5":"x_train.head()","7c64498a":"test.head(2)","d37cc398":"x_train1 = x_train.drop(['casual','registered'],axis=1) # Removing casual and registered as its not available in test data","c5f46f93":"x_train_pred,x_test_pred,y_train_pred,y_test_pred = train_test_split(x_train1,y_train, test_size=0.3, random_state=42)","af040713":"x_train_pred.head(2)","29ce63c5":"models=[RandomForestRegressor(),Lasso(alpha=0.01),DecisionTreeRegressor(),SVR(),KNeighborsRegressor()]\nmodel_names=['RandomForestRegressor','Lasso','DecisionTreeRegressor','SVR','KNeighborsRegressor']\nrmse=[]\nr_squared=[]\ndic={}\nfor model in range (len(models)):\n    alg=models[model]\n    alg.fit(x_train_pred,y_train_pred)\n    alg_y_pred=alg.predict(x_test_pred)\n    rmse.append(np.sqrt(mean_squared_error(y_test_pred,alg_y_pred)))\n    r_squared.append(r2_score(y_test_pred,alg_y_pred))\ndic={'Modelling Algorithms':model_names,'RMSE':rmse,'R-Squared':r_squared}   \nmodel_performances= pd.DataFrame(dic)\n\nmodel_performances","2ce866e7":"plt.figure(figsize = (10,5))\nsns.barplot(x='Modelling Algorithms',y='RMSE',data=model_performances)\nplt.title(\"Algorithms vs RMSE\")","d7e801c3":"plt.figure(figsize = (10,5))\nsns.barplot(x='Modelling Algorithms',y='R-Squared',data=model_performances)\nplt.title(\"Algorithms vs R-Squared\")","aab10422":"from sklearn.model_selection import RandomizedSearchCV\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 20, stop = 200, num = 5)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(1, 45, num = 3)]\n# Minimum number of samples required to split a node\nmin_samples_split = [5, 10]\n\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split}","ded7b7cb":"random_grid","3d0d9955":"rF_random = RandomizedSearchCV(estimator = RandomForestRegressor(), param_distributions = random_grid, n_iter = 10, cv = 10, verbose=2, random_state=42, n_jobs = -1, scoring='neg_mean_squared_error')\n# Fit the random search model\nrF_random.fit(x_train_pred,y_train_pred)","350a6537":"rF_random.best_params_","0c0155d3":"# Performance Comparison\nbest_fit= rF_random.best_estimator_.predict(x_test_pred)\nprint(\"RMSE and R-Squared after hyperparameter tuning :\\n\")\nprint(\"Modelling algorithm: RandomForestRegressor \")\nprint(\"RMSE value is: \",np.sqrt(mean_squared_error(y_test_pred,best_fit)))\nprint(\"R-Squared value is \",r2_score(y_test_pred,best_fit))","2c66471b":"test.head(2)","4e0e346f":"test['datetime'] = pd.to_datetime(test['datetime'])\ntest['year']=test.datetime.dt.year\ntest['month']=test.datetime.dt.month\ntest['day']=test.datetime.dt.day\ntest['hour']=test.datetime.dt.hour\ntest['minute']=test.datetime.dt.minute","cda8d81f":"test_val = test.drop(['datetime'],axis=1)","24bf5653":"test_val.head(2)","2194dc87":"predictions = rF_random.best_estimator_.predict(test_val)","9ab800cb":"predictions_exp = np.exp(predictions)-1","691408eb":"predictions_exp","f69b038c":"submission = pd.DataFrame({'datetime':test['datetime'],'count': predictions_exp})","e6e28f8e":"submission.head()","847801a6":"submission_viz=submission.copy()","ab591c53":"submission_viz['datetime'] = pd.to_datetime(submission_viz['datetime'])","515ce6f9":"def plot_by_month_pred(data,aggre,title):\n    d2 = data\n    d2['year'] = d2.datetime.dt.year\n    d2['month'] = d2.datetime.dt.month\n    d2['hour'] = d2.datetime.dt.hour\n    \n    by_year = d2.groupby([aggre,'year'])['count'].sum().unstack() # groupby hour and working day\n    \n    return by_year.plot(kind='bar', figsize=(15,5), width=0.9, title=title) # returning the figure grouped by hour\n\n\nplot_by_month_pred(submission_viz,'month', \"Testing Data - Seasonal trend: There must be high demand during summer season,\\n when temperature is good enough to ride cycle and low demand during winter.\")  \nplot_by_month_pred(submission_viz,'hour', \"Testing Data - Hourly trend: There must be high demand during office timings.\\n Early morning and late evening can have moderate trend (cyclist) and low demand during 10:00 pm to 4:00 am.\") ","12bcbc28":"submission.to_csv(\"sampleSubmission.csv\",index=False)","a618ac33":"From above we can conclude that RandomForestRegressor fits good compared to other models taken into consideration. So lets fine tune RandomForestRegressor using randomized search.","3c10c063":" The below barplot shows that test data prediction matchs that of the training data pattern.","9ea22c2e":"# Model Training","1c22d30b":"# Testing","8d7f8d12":"#           Please upvote if you find useful","1dfb7155":"# Hyperparameter Tuning","6aa9d56d":"Problem Statement-\nBike-sharing system are meant to rent the bicycle and return to the different place for the bike sharing purpose in Washington DC.\nYou are provided with rental data spanning for 2 years. You must predict the total count of bikes rented during each hour covered by the test set, using only information available prior to the rental period."}}