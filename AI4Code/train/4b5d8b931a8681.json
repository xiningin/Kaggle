{"cell_type":{"b03b3516":"code","3977680c":"code","6f5158a4":"code","e3f91d34":"code","bdaa64c3":"code","13da7121":"code","3768a7aa":"code","685e4b02":"code","ffffbbf1":"code","d416060e":"code","1572ce6a":"code","bbc9e109":"code","727d7fb3":"code","7af321ba":"code","5bec31a9":"code","4b226827":"code","ebb01c36":"code","d1690615":"code","1e537618":"markdown","ea0653de":"markdown","a251ea9e":"markdown","ff0faa1a":"markdown","48758c33":"markdown","b93f7bca":"markdown"},"source":{"b03b3516":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\nfrom random import sample\nimport time\n\nimport os\nfrom tqdm.notebook import tqdm\n\nimport tensorflow as tf\nimport keras.backend as K\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Input, Concatenate\nfrom keras.layers import Embedding, LSTM, Dense, Dropout\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.layers.merge import concatenate\n\nfrom sklearn.model_selection import train_test_split\nfrom textblob import TextBlob","3977680c":"df = pd.read_csv(\"..\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv\")\n\ntoxic = 1.0\nsevere_toxic = 2.0\nobscene = 2.0\nthreat = 1.0\ninsult = 1.0\nidentity_hate = 2.0\n\ndf['y'] = toxic*df['toxic'] +  severe_toxic*df['severe_toxic'] + obscene*df['obscene'] + threat*df['threat'] + insult*df['insult'] + identity_hate*df['identity_hate']\ndf = df[['comment_text', 'y']].rename(columns={'comment_text': 'text'})\n\n#undersample non toxic comments  on Toxic Comment Classification Challenge\n\nmin_len = (df['y'] >= 1).sum()\ndf_y0_undersample = df[df['y'] == 0].sample(n=min_len, random_state=201)\ndf = pd.concat([df[df['y'] >= 1], df_y0_undersample])\ndf['y'].value_counts()","6f5158a4":"toxic_text = df['text'].values\ntarget = df['y'].values","e3f91d34":"print(\"Text list length: \", len(toxic_text))\nprint(\"Target list length: \", len(target))","bdaa64c3":"plt.hist(target, label='training target distribution');\nplt.legend();","13da7121":"PATH = '\/kaggle\/input\/jigsaw-toxic-severity-rating\/'\ncomment_data = pd.read_csv(PATH + 'comments_to_score.csv')\nsub = pd.read_csv(PATH + 'sample_submission.csv')","3768a7aa":"MAX_LENGTH = 512\n\n# tokenize the sentences\ntokenizer = Tokenizer(lower=True)\ntokenizer.fit_on_texts(toxic_text)\n\ntext_seq = tokenizer.texts_to_sequences(toxic_text)\n\n# pad the sequences\ntext_vec = pad_sequences(text_seq, maxlen=MAX_LENGTH)\n\ntext_vec.shape","685e4b02":"print('Number of Tokens:', len(tokenizer.word_index))","ffffbbf1":"x_input = Input(shape=(MAX_LENGTH,))\n\nx = Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100,)(x_input)\n\n#x = LSTM(units=128, return_sequences=True)(x)\n#x = Dropout(0.2)(x)\n\nx = LSTM(units=64, return_sequences=False)(x)\nx = Dropout(0.2)(x)\n\nx = Dense(64, activation='relu')(x)\nx = Dropout(0.25)(x)\n\noutputs = Dense(1)(x)\n\nmodel = Model(inputs=x_input, outputs=outputs)\n\nmodel.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0025))","d416060e":"tf.keras.utils.plot_model(\n    model,\n    to_file=\"model.png\",\n    show_shapes=False,\n    show_dtype=False,\n    show_layer_names=True,\n    rankdir=\"TB\",\n    expand_nested=False,\n    dpi=96,\n    layer_range=None,\n)","1572ce6a":"# Model hyperparameters \nBATCH_SIZE = 256\nEPOCHS = 20\n\n# model drive\ncp_file = '.\/lstm_model.h5'\ncp = ModelCheckpoint(cp_file, \n                     monitor='loss', \n                     verbose=0, \n                     save_best_only=True, mode='min')\n\nes = EarlyStopping(patience=3, \n                   monitor='loss', \n                   #restore_best_weights=True, \n                   mode='min', \n                   verbose=1)\n\n# model train\nhistory = model.fit(text_vec, target,\n                    batch_size=BATCH_SIZE, \n                    epochs=EPOCHS,\n                    validation_split=0.1,\n                    callbacks=[es, cp],\n                    shuffle=True,\n                    )","bbc9e109":"pd.DataFrame(history.history).plot(figsize=(12, 6));","727d7fb3":"test_ids = comment_data['comment_id']\ntest_text = comment_data['text']\n\ntest_text_seq = tokenizer.texts_to_sequences(test_text)\n\n# pad the sequences\ntest_text_vec = pad_sequences(test_text_seq, maxlen=MAX_LENGTH)","7af321ba":"test_length = len(test_text_vec)\n\npreds = model.predict(test_text_vec)","5bec31a9":"plt.hist(preds, label='test prediction distribution');\nplt.legend();","4b226827":"sub['score'] = preds\nsub['score'] = sub['score'].rank(method='first')","ebb01c36":"sub.to_csv('submission.csv', index=False)","d1690615":"sub","1e537618":"## Prediction","ea0653de":"## Imports","a251ea9e":"# Jigsaw Rate Severity - Simple LSTM\n\n**Work:**\n - Forked https:\/\/www.kaggle.com\/elcaiseri\/jigsaw-keras-embedding-lstm\n - Revised data prep and model architecture to run with single input (text) and get single score (relative severity of toxicity)\n     - Using data from Toxic Comment Classification Challenge\n - Revised optimizer and manually tuned learning rate for better performance\n\n**References and Acknowledgements:**\n - https:\/\/www.kaggle.com\/steubk\/jrsotc-ridgeregression\n - https:\/\/www.kaggle.com\/elcaiseri\/jigsaw-keras-embedding-lstm\n - https:\/\/www.kaggle.com\/elcaiseri\n - https:\/\/www.kaggle.com\/c\/jigsaw-toxic-severity-rating\/overview\n - https:\/\/github.com\/tensorflow\/tensorflow\/issues\/38613\n - https:\/\/www.kaggle.com\/yeayates21\/commonlit-text-augmentation-eng-to-fre-to-eng\/notebook","ff0faa1a":"### Text Preprocessing for Deep Learning","48758c33":"## Data Wrangling","b93f7bca":"## Model"}}